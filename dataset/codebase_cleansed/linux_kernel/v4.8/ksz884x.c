static inline void hw_ack_intr(struct ksz_hw *hw, uint interrupt)\r\n{\r\nwritel(interrupt, hw->io + KS884X_INTERRUPTS_STATUS);\r\n}\r\nstatic inline void hw_dis_intr(struct ksz_hw *hw)\r\n{\r\nhw->intr_blocked = hw->intr_mask;\r\nwritel(0, hw->io + KS884X_INTERRUPTS_ENABLE);\r\nhw->intr_set = readl(hw->io + KS884X_INTERRUPTS_ENABLE);\r\n}\r\nstatic inline void hw_set_intr(struct ksz_hw *hw, uint interrupt)\r\n{\r\nhw->intr_set = interrupt;\r\nwritel(interrupt, hw->io + KS884X_INTERRUPTS_ENABLE);\r\n}\r\nstatic inline void hw_ena_intr(struct ksz_hw *hw)\r\n{\r\nhw->intr_blocked = 0;\r\nhw_set_intr(hw, hw->intr_mask);\r\n}\r\nstatic inline void hw_dis_intr_bit(struct ksz_hw *hw, uint bit)\r\n{\r\nhw->intr_mask &= ~(bit);\r\n}\r\nstatic inline void hw_turn_off_intr(struct ksz_hw *hw, uint interrupt)\r\n{\r\nu32 read_intr;\r\nread_intr = readl(hw->io + KS884X_INTERRUPTS_ENABLE);\r\nhw->intr_set = read_intr & ~interrupt;\r\nwritel(hw->intr_set, hw->io + KS884X_INTERRUPTS_ENABLE);\r\nhw_dis_intr_bit(hw, interrupt);\r\n}\r\nstatic void hw_turn_on_intr(struct ksz_hw *hw, u32 bit)\r\n{\r\nhw->intr_mask |= bit;\r\nif (!hw->intr_blocked)\r\nhw_set_intr(hw, hw->intr_mask);\r\n}\r\nstatic inline void hw_ena_intr_bit(struct ksz_hw *hw, uint interrupt)\r\n{\r\nu32 read_intr;\r\nread_intr = readl(hw->io + KS884X_INTERRUPTS_ENABLE);\r\nhw->intr_set = read_intr | interrupt;\r\nwritel(hw->intr_set, hw->io + KS884X_INTERRUPTS_ENABLE);\r\n}\r\nstatic inline void hw_read_intr(struct ksz_hw *hw, uint *status)\r\n{\r\n*status = readl(hw->io + KS884X_INTERRUPTS_STATUS);\r\n*status = *status & hw->intr_set;\r\n}\r\nstatic inline void hw_restore_intr(struct ksz_hw *hw, uint interrupt)\r\n{\r\nif (interrupt)\r\nhw_ena_intr(hw);\r\n}\r\nstatic uint hw_block_intr(struct ksz_hw *hw)\r\n{\r\nuint interrupt = 0;\r\nif (!hw->intr_blocked) {\r\nhw_dis_intr(hw);\r\ninterrupt = hw->intr_blocked;\r\n}\r\nreturn interrupt;\r\n}\r\nstatic inline void reset_desc(struct ksz_desc *desc, union desc_stat status)\r\n{\r\nstatus.rx.hw_owned = 0;\r\ndesc->phw->ctrl.data = cpu_to_le32(status.data);\r\n}\r\nstatic inline void release_desc(struct ksz_desc *desc)\r\n{\r\ndesc->sw.ctrl.tx.hw_owned = 1;\r\nif (desc->sw.buf_size != desc->sw.buf.data) {\r\ndesc->sw.buf_size = desc->sw.buf.data;\r\ndesc->phw->buf.data = cpu_to_le32(desc->sw.buf.data);\r\n}\r\ndesc->phw->ctrl.data = cpu_to_le32(desc->sw.ctrl.data);\r\n}\r\nstatic void get_rx_pkt(struct ksz_desc_info *info, struct ksz_desc **desc)\r\n{\r\n*desc = &info->ring[info->last];\r\ninfo->last++;\r\ninfo->last &= info->mask;\r\ninfo->avail--;\r\n(*desc)->sw.buf.data &= ~KS_DESC_RX_MASK;\r\n}\r\nstatic inline void set_rx_buf(struct ksz_desc *desc, u32 addr)\r\n{\r\ndesc->phw->addr = cpu_to_le32(addr);\r\n}\r\nstatic inline void set_rx_len(struct ksz_desc *desc, u32 len)\r\n{\r\ndesc->sw.buf.rx.buf_size = len;\r\n}\r\nstatic inline void get_tx_pkt(struct ksz_desc_info *info,\r\nstruct ksz_desc **desc)\r\n{\r\n*desc = &info->ring[info->next];\r\ninfo->next++;\r\ninfo->next &= info->mask;\r\ninfo->avail--;\r\n(*desc)->sw.buf.data &= ~KS_DESC_TX_MASK;\r\n}\r\nstatic inline void set_tx_buf(struct ksz_desc *desc, u32 addr)\r\n{\r\ndesc->phw->addr = cpu_to_le32(addr);\r\n}\r\nstatic inline void set_tx_len(struct ksz_desc *desc, u32 len)\r\n{\r\ndesc->sw.buf.tx.buf_size = len;\r\n}\r\nstatic void sw_r_table(struct ksz_hw *hw, int table, u16 addr, u32 *data)\r\n{\r\nu16 ctrl_addr;\r\nuint interrupt;\r\nctrl_addr = (((table << TABLE_SEL_SHIFT) | TABLE_READ) << 8) | addr;\r\ninterrupt = hw_block_intr(hw);\r\nwritew(ctrl_addr, hw->io + KS884X_IACR_OFFSET);\r\nHW_DELAY(hw, KS884X_IACR_OFFSET);\r\n*data = readl(hw->io + KS884X_ACC_DATA_0_OFFSET);\r\nhw_restore_intr(hw, interrupt);\r\n}\r\nstatic void sw_w_table_64(struct ksz_hw *hw, int table, u16 addr, u32 data_hi,\r\nu32 data_lo)\r\n{\r\nu16 ctrl_addr;\r\nuint interrupt;\r\nctrl_addr = ((table << TABLE_SEL_SHIFT) << 8) | addr;\r\ninterrupt = hw_block_intr(hw);\r\nwritel(data_hi, hw->io + KS884X_ACC_DATA_4_OFFSET);\r\nwritel(data_lo, hw->io + KS884X_ACC_DATA_0_OFFSET);\r\nwritew(ctrl_addr, hw->io + KS884X_IACR_OFFSET);\r\nHW_DELAY(hw, KS884X_IACR_OFFSET);\r\nhw_restore_intr(hw, interrupt);\r\n}\r\nstatic void sw_w_sta_mac_table(struct ksz_hw *hw, u16 addr, u8 *mac_addr,\r\nu8 ports, int override, int valid, int use_fid, u8 fid)\r\n{\r\nu32 data_hi;\r\nu32 data_lo;\r\ndata_lo = ((u32) mac_addr[2] << 24) |\r\n((u32) mac_addr[3] << 16) |\r\n((u32) mac_addr[4] << 8) | mac_addr[5];\r\ndata_hi = ((u32) mac_addr[0] << 8) | mac_addr[1];\r\ndata_hi |= (u32) ports << STATIC_MAC_FWD_PORTS_SHIFT;\r\nif (override)\r\ndata_hi |= STATIC_MAC_TABLE_OVERRIDE;\r\nif (use_fid) {\r\ndata_hi |= STATIC_MAC_TABLE_USE_FID;\r\ndata_hi |= (u32) fid << STATIC_MAC_FID_SHIFT;\r\n}\r\nif (valid)\r\ndata_hi |= STATIC_MAC_TABLE_VALID;\r\nsw_w_table_64(hw, TABLE_STATIC_MAC, addr, data_hi, data_lo);\r\n}\r\nstatic int sw_r_vlan_table(struct ksz_hw *hw, u16 addr, u16 *vid, u8 *fid,\r\nu8 *member)\r\n{\r\nu32 data;\r\nsw_r_table(hw, TABLE_VLAN, addr, &data);\r\nif (data & VLAN_TABLE_VALID) {\r\n*vid = (u16)(data & VLAN_TABLE_VID);\r\n*fid = (u8)((data & VLAN_TABLE_FID) >> VLAN_TABLE_FID_SHIFT);\r\n*member = (u8)((data & VLAN_TABLE_MEMBERSHIP) >>\r\nVLAN_TABLE_MEMBERSHIP_SHIFT);\r\nreturn 0;\r\n}\r\nreturn -1;\r\n}\r\nstatic void port_r_mib_cnt(struct ksz_hw *hw, int port, u16 addr, u64 *cnt)\r\n{\r\nu32 data;\r\nu16 ctrl_addr;\r\nuint interrupt;\r\nint timeout;\r\nctrl_addr = addr + PORT_COUNTER_NUM * port;\r\ninterrupt = hw_block_intr(hw);\r\nctrl_addr |= (((TABLE_MIB << TABLE_SEL_SHIFT) | TABLE_READ) << 8);\r\nwritew(ctrl_addr, hw->io + KS884X_IACR_OFFSET);\r\nHW_DELAY(hw, KS884X_IACR_OFFSET);\r\nfor (timeout = 100; timeout > 0; timeout--) {\r\ndata = readl(hw->io + KS884X_ACC_DATA_0_OFFSET);\r\nif (data & MIB_COUNTER_VALID) {\r\nif (data & MIB_COUNTER_OVERFLOW)\r\n*cnt += MIB_COUNTER_VALUE + 1;\r\n*cnt += data & MIB_COUNTER_VALUE;\r\nbreak;\r\n}\r\n}\r\nhw_restore_intr(hw, interrupt);\r\n}\r\nstatic void port_r_mib_pkt(struct ksz_hw *hw, int port, u32 *last, u64 *cnt)\r\n{\r\nu32 cur;\r\nu32 data;\r\nu16 ctrl_addr;\r\nuint interrupt;\r\nint index;\r\nindex = KS_MIB_PACKET_DROPPED_RX_0 + port;\r\ndo {\r\ninterrupt = hw_block_intr(hw);\r\nctrl_addr = (u16) index;\r\nctrl_addr |= (((TABLE_MIB << TABLE_SEL_SHIFT) | TABLE_READ)\r\n<< 8);\r\nwritew(ctrl_addr, hw->io + KS884X_IACR_OFFSET);\r\nHW_DELAY(hw, KS884X_IACR_OFFSET);\r\ndata = readl(hw->io + KS884X_ACC_DATA_0_OFFSET);\r\nhw_restore_intr(hw, interrupt);\r\ndata &= MIB_PACKET_DROPPED;\r\ncur = *last;\r\nif (data != cur) {\r\n*last = data;\r\nif (data < cur)\r\ndata += MIB_PACKET_DROPPED + 1;\r\ndata -= cur;\r\n*cnt += data;\r\n}\r\n++last;\r\n++cnt;\r\nindex -= KS_MIB_PACKET_DROPPED_TX -\r\nKS_MIB_PACKET_DROPPED_TX_0 + 1;\r\n} while (index >= KS_MIB_PACKET_DROPPED_TX_0 + port);\r\n}\r\nstatic int port_r_cnt(struct ksz_hw *hw, int port)\r\n{\r\nstruct ksz_port_mib *mib = &hw->port_mib[port];\r\nif (mib->mib_start < PORT_COUNTER_NUM)\r\nwhile (mib->cnt_ptr < PORT_COUNTER_NUM) {\r\nport_r_mib_cnt(hw, port, mib->cnt_ptr,\r\n&mib->counter[mib->cnt_ptr]);\r\n++mib->cnt_ptr;\r\n}\r\nif (hw->mib_cnt > PORT_COUNTER_NUM)\r\nport_r_mib_pkt(hw, port, mib->dropped,\r\n&mib->counter[PORT_COUNTER_NUM]);\r\nmib->cnt_ptr = 0;\r\nreturn 0;\r\n}\r\nstatic void port_init_cnt(struct ksz_hw *hw, int port)\r\n{\r\nstruct ksz_port_mib *mib = &hw->port_mib[port];\r\nmib->cnt_ptr = 0;\r\nif (mib->mib_start < PORT_COUNTER_NUM)\r\ndo {\r\nport_r_mib_cnt(hw, port, mib->cnt_ptr,\r\n&mib->counter[mib->cnt_ptr]);\r\n++mib->cnt_ptr;\r\n} while (mib->cnt_ptr < PORT_COUNTER_NUM);\r\nif (hw->mib_cnt > PORT_COUNTER_NUM)\r\nport_r_mib_pkt(hw, port, mib->dropped,\r\n&mib->counter[PORT_COUNTER_NUM]);\r\nmemset((void *) mib->counter, 0, sizeof(u64) * TOTAL_PORT_COUNTER_NUM);\r\nmib->cnt_ptr = 0;\r\n}\r\nstatic int port_chk(struct ksz_hw *hw, int port, int offset, u16 bits)\r\n{\r\nu32 addr;\r\nu16 data;\r\nPORT_CTRL_ADDR(port, addr);\r\naddr += offset;\r\ndata = readw(hw->io + addr);\r\nreturn (data & bits) == bits;\r\n}\r\nstatic void port_cfg(struct ksz_hw *hw, int port, int offset, u16 bits,\r\nint set)\r\n{\r\nu32 addr;\r\nu16 data;\r\nPORT_CTRL_ADDR(port, addr);\r\naddr += offset;\r\ndata = readw(hw->io + addr);\r\nif (set)\r\ndata |= bits;\r\nelse\r\ndata &= ~bits;\r\nwritew(data, hw->io + addr);\r\n}\r\nstatic int port_chk_shift(struct ksz_hw *hw, int port, u32 addr, int shift)\r\n{\r\nu16 data;\r\nu16 bit = 1 << port;\r\ndata = readw(hw->io + addr);\r\ndata >>= shift;\r\nreturn (data & bit) == bit;\r\n}\r\nstatic void port_cfg_shift(struct ksz_hw *hw, int port, u32 addr, int shift,\r\nint set)\r\n{\r\nu16 data;\r\nu16 bits = 1 << port;\r\ndata = readw(hw->io + addr);\r\nbits <<= shift;\r\nif (set)\r\ndata |= bits;\r\nelse\r\ndata &= ~bits;\r\nwritew(data, hw->io + addr);\r\n}\r\nstatic void port_r8(struct ksz_hw *hw, int port, int offset, u8 *data)\r\n{\r\nu32 addr;\r\nPORT_CTRL_ADDR(port, addr);\r\naddr += offset;\r\n*data = readb(hw->io + addr);\r\n}\r\nstatic void port_r16(struct ksz_hw *hw, int port, int offset, u16 *data)\r\n{\r\nu32 addr;\r\nPORT_CTRL_ADDR(port, addr);\r\naddr += offset;\r\n*data = readw(hw->io + addr);\r\n}\r\nstatic void port_w16(struct ksz_hw *hw, int port, int offset, u16 data)\r\n{\r\nu32 addr;\r\nPORT_CTRL_ADDR(port, addr);\r\naddr += offset;\r\nwritew(data, hw->io + addr);\r\n}\r\nstatic int sw_chk(struct ksz_hw *hw, u32 addr, u16 bits)\r\n{\r\nu16 data;\r\ndata = readw(hw->io + addr);\r\nreturn (data & bits) == bits;\r\n}\r\nstatic void sw_cfg(struct ksz_hw *hw, u32 addr, u16 bits, int set)\r\n{\r\nu16 data;\r\ndata = readw(hw->io + addr);\r\nif (set)\r\ndata |= bits;\r\nelse\r\ndata &= ~bits;\r\nwritew(data, hw->io + addr);\r\n}\r\nstatic inline void port_cfg_broad_storm(struct ksz_hw *hw, int p, int set)\r\n{\r\nport_cfg(hw, p,\r\nKS8842_PORT_CTRL_1_OFFSET, PORT_BROADCAST_STORM, set);\r\n}\r\nstatic inline int port_chk_broad_storm(struct ksz_hw *hw, int p)\r\n{\r\nreturn port_chk(hw, p,\r\nKS8842_PORT_CTRL_1_OFFSET, PORT_BROADCAST_STORM);\r\n}\r\nstatic void sw_cfg_broad_storm(struct ksz_hw *hw, u8 percent)\r\n{\r\nu16 data;\r\nu32 value = ((u32) BROADCAST_STORM_VALUE * (u32) percent / 100);\r\nif (value > BROADCAST_STORM_RATE)\r\nvalue = BROADCAST_STORM_RATE;\r\ndata = readw(hw->io + KS8842_SWITCH_CTRL_3_OFFSET);\r\ndata &= ~(BROADCAST_STORM_RATE_LO | BROADCAST_STORM_RATE_HI);\r\ndata |= ((value & 0x00FF) << 8) | ((value & 0xFF00) >> 8);\r\nwritew(data, hw->io + KS8842_SWITCH_CTRL_3_OFFSET);\r\n}\r\nstatic void sw_get_broad_storm(struct ksz_hw *hw, u8 *percent)\r\n{\r\nint num;\r\nu16 data;\r\ndata = readw(hw->io + KS8842_SWITCH_CTRL_3_OFFSET);\r\nnum = (data & BROADCAST_STORM_RATE_HI);\r\nnum <<= 8;\r\nnum |= (data & BROADCAST_STORM_RATE_LO) >> 8;\r\nnum = (num * 100 + BROADCAST_STORM_VALUE / 2) / BROADCAST_STORM_VALUE;\r\n*percent = (u8) num;\r\n}\r\nstatic void sw_dis_broad_storm(struct ksz_hw *hw, int port)\r\n{\r\nport_cfg_broad_storm(hw, port, 0);\r\n}\r\nstatic void sw_ena_broad_storm(struct ksz_hw *hw, int port)\r\n{\r\nsw_cfg_broad_storm(hw, hw->ksz_switch->broad_per);\r\nport_cfg_broad_storm(hw, port, 1);\r\n}\r\nstatic void sw_init_broad_storm(struct ksz_hw *hw)\r\n{\r\nint port;\r\nhw->ksz_switch->broad_per = 1;\r\nsw_cfg_broad_storm(hw, hw->ksz_switch->broad_per);\r\nfor (port = 0; port < TOTAL_PORT_NUM; port++)\r\nsw_dis_broad_storm(hw, port);\r\nsw_cfg(hw, KS8842_SWITCH_CTRL_2_OFFSET, MULTICAST_STORM_DISABLE, 1);\r\n}\r\nstatic void hw_cfg_broad_storm(struct ksz_hw *hw, u8 percent)\r\n{\r\nif (percent > 100)\r\npercent = 100;\r\nsw_cfg_broad_storm(hw, percent);\r\nsw_get_broad_storm(hw, &percent);\r\nhw->ksz_switch->broad_per = percent;\r\n}\r\nstatic void sw_dis_prio_rate(struct ksz_hw *hw, int port)\r\n{\r\nu32 addr;\r\nPORT_CTRL_ADDR(port, addr);\r\naddr += KS8842_PORT_IN_RATE_OFFSET;\r\nwritel(0, hw->io + addr);\r\n}\r\nstatic void sw_init_prio_rate(struct ksz_hw *hw)\r\n{\r\nint port;\r\nint prio;\r\nstruct ksz_switch *sw = hw->ksz_switch;\r\nfor (port = 0; port < TOTAL_PORT_NUM; port++) {\r\nfor (prio = 0; prio < PRIO_QUEUES; prio++) {\r\nsw->port_cfg[port].rx_rate[prio] =\r\nsw->port_cfg[port].tx_rate[prio] = 0;\r\n}\r\nsw_dis_prio_rate(hw, port);\r\n}\r\n}\r\nstatic inline void port_cfg_back_pressure(struct ksz_hw *hw, int p, int set)\r\n{\r\nport_cfg(hw, p,\r\nKS8842_PORT_CTRL_2_OFFSET, PORT_BACK_PRESSURE, set);\r\n}\r\nstatic inline void port_cfg_force_flow_ctrl(struct ksz_hw *hw, int p, int set)\r\n{\r\nport_cfg(hw, p,\r\nKS8842_PORT_CTRL_2_OFFSET, PORT_FORCE_FLOW_CTRL, set);\r\n}\r\nstatic inline int port_chk_back_pressure(struct ksz_hw *hw, int p)\r\n{\r\nreturn port_chk(hw, p,\r\nKS8842_PORT_CTRL_2_OFFSET, PORT_BACK_PRESSURE);\r\n}\r\nstatic inline int port_chk_force_flow_ctrl(struct ksz_hw *hw, int p)\r\n{\r\nreturn port_chk(hw, p,\r\nKS8842_PORT_CTRL_2_OFFSET, PORT_FORCE_FLOW_CTRL);\r\n}\r\nstatic inline void port_cfg_rx(struct ksz_hw *hw, int p, int set)\r\n{\r\nport_cfg(hw, p,\r\nKS8842_PORT_CTRL_2_OFFSET, PORT_RX_ENABLE, set);\r\n}\r\nstatic inline void port_cfg_tx(struct ksz_hw *hw, int p, int set)\r\n{\r\nport_cfg(hw, p,\r\nKS8842_PORT_CTRL_2_OFFSET, PORT_TX_ENABLE, set);\r\n}\r\nstatic inline void sw_cfg_fast_aging(struct ksz_hw *hw, int set)\r\n{\r\nsw_cfg(hw, KS8842_SWITCH_CTRL_1_OFFSET, SWITCH_FAST_AGING, set);\r\n}\r\nstatic inline void sw_flush_dyn_mac_table(struct ksz_hw *hw)\r\n{\r\nif (!(hw->overrides & FAST_AGING)) {\r\nsw_cfg_fast_aging(hw, 1);\r\nmdelay(1);\r\nsw_cfg_fast_aging(hw, 0);\r\n}\r\n}\r\nstatic inline void port_cfg_ins_tag(struct ksz_hw *hw, int p, int insert)\r\n{\r\nport_cfg(hw, p,\r\nKS8842_PORT_CTRL_1_OFFSET, PORT_INSERT_TAG, insert);\r\n}\r\nstatic inline void port_cfg_rmv_tag(struct ksz_hw *hw, int p, int remove)\r\n{\r\nport_cfg(hw, p,\r\nKS8842_PORT_CTRL_1_OFFSET, PORT_REMOVE_TAG, remove);\r\n}\r\nstatic inline int port_chk_ins_tag(struct ksz_hw *hw, int p)\r\n{\r\nreturn port_chk(hw, p,\r\nKS8842_PORT_CTRL_1_OFFSET, PORT_INSERT_TAG);\r\n}\r\nstatic inline int port_chk_rmv_tag(struct ksz_hw *hw, int p)\r\n{\r\nreturn port_chk(hw, p,\r\nKS8842_PORT_CTRL_1_OFFSET, PORT_REMOVE_TAG);\r\n}\r\nstatic inline void port_cfg_dis_non_vid(struct ksz_hw *hw, int p, int set)\r\n{\r\nport_cfg(hw, p,\r\nKS8842_PORT_CTRL_2_OFFSET, PORT_DISCARD_NON_VID, set);\r\n}\r\nstatic inline void port_cfg_in_filter(struct ksz_hw *hw, int p, int set)\r\n{\r\nport_cfg(hw, p,\r\nKS8842_PORT_CTRL_2_OFFSET, PORT_INGRESS_VLAN_FILTER, set);\r\n}\r\nstatic inline int port_chk_dis_non_vid(struct ksz_hw *hw, int p)\r\n{\r\nreturn port_chk(hw, p,\r\nKS8842_PORT_CTRL_2_OFFSET, PORT_DISCARD_NON_VID);\r\n}\r\nstatic inline int port_chk_in_filter(struct ksz_hw *hw, int p)\r\n{\r\nreturn port_chk(hw, p,\r\nKS8842_PORT_CTRL_2_OFFSET, PORT_INGRESS_VLAN_FILTER);\r\n}\r\nstatic inline void port_cfg_mirror_sniffer(struct ksz_hw *hw, int p, int set)\r\n{\r\nport_cfg(hw, p,\r\nKS8842_PORT_CTRL_2_OFFSET, PORT_MIRROR_SNIFFER, set);\r\n}\r\nstatic inline void port_cfg_mirror_rx(struct ksz_hw *hw, int p, int set)\r\n{\r\nport_cfg(hw, p,\r\nKS8842_PORT_CTRL_2_OFFSET, PORT_MIRROR_RX, set);\r\n}\r\nstatic inline void port_cfg_mirror_tx(struct ksz_hw *hw, int p, int set)\r\n{\r\nport_cfg(hw, p,\r\nKS8842_PORT_CTRL_2_OFFSET, PORT_MIRROR_TX, set);\r\n}\r\nstatic inline void sw_cfg_mirror_rx_tx(struct ksz_hw *hw, int set)\r\n{\r\nsw_cfg(hw, KS8842_SWITCH_CTRL_2_OFFSET, SWITCH_MIRROR_RX_TX, set);\r\n}\r\nstatic void sw_init_mirror(struct ksz_hw *hw)\r\n{\r\nint port;\r\nfor (port = 0; port < TOTAL_PORT_NUM; port++) {\r\nport_cfg_mirror_sniffer(hw, port, 0);\r\nport_cfg_mirror_rx(hw, port, 0);\r\nport_cfg_mirror_tx(hw, port, 0);\r\n}\r\nsw_cfg_mirror_rx_tx(hw, 0);\r\n}\r\nstatic inline void sw_cfg_unk_def_deliver(struct ksz_hw *hw, int set)\r\n{\r\nsw_cfg(hw, KS8842_SWITCH_CTRL_7_OFFSET,\r\nSWITCH_UNK_DEF_PORT_ENABLE, set);\r\n}\r\nstatic inline int sw_cfg_chk_unk_def_deliver(struct ksz_hw *hw)\r\n{\r\nreturn sw_chk(hw, KS8842_SWITCH_CTRL_7_OFFSET,\r\nSWITCH_UNK_DEF_PORT_ENABLE);\r\n}\r\nstatic inline void sw_cfg_unk_def_port(struct ksz_hw *hw, int port, int set)\r\n{\r\nport_cfg_shift(hw, port, KS8842_SWITCH_CTRL_7_OFFSET, 0, set);\r\n}\r\nstatic inline int sw_chk_unk_def_port(struct ksz_hw *hw, int port)\r\n{\r\nreturn port_chk_shift(hw, port, KS8842_SWITCH_CTRL_7_OFFSET, 0);\r\n}\r\nstatic inline void port_cfg_diffserv(struct ksz_hw *hw, int p, int set)\r\n{\r\nport_cfg(hw, p,\r\nKS8842_PORT_CTRL_1_OFFSET, PORT_DIFFSERV_ENABLE, set);\r\n}\r\nstatic inline void port_cfg_802_1p(struct ksz_hw *hw, int p, int set)\r\n{\r\nport_cfg(hw, p,\r\nKS8842_PORT_CTRL_1_OFFSET, PORT_802_1P_ENABLE, set);\r\n}\r\nstatic inline void port_cfg_replace_vid(struct ksz_hw *hw, int p, int set)\r\n{\r\nport_cfg(hw, p,\r\nKS8842_PORT_CTRL_2_OFFSET, PORT_USER_PRIORITY_CEILING, set);\r\n}\r\nstatic inline void port_cfg_prio(struct ksz_hw *hw, int p, int set)\r\n{\r\nport_cfg(hw, p,\r\nKS8842_PORT_CTRL_1_OFFSET, PORT_PRIO_QUEUE_ENABLE, set);\r\n}\r\nstatic inline int port_chk_diffserv(struct ksz_hw *hw, int p)\r\n{\r\nreturn port_chk(hw, p,\r\nKS8842_PORT_CTRL_1_OFFSET, PORT_DIFFSERV_ENABLE);\r\n}\r\nstatic inline int port_chk_802_1p(struct ksz_hw *hw, int p)\r\n{\r\nreturn port_chk(hw, p,\r\nKS8842_PORT_CTRL_1_OFFSET, PORT_802_1P_ENABLE);\r\n}\r\nstatic inline int port_chk_replace_vid(struct ksz_hw *hw, int p)\r\n{\r\nreturn port_chk(hw, p,\r\nKS8842_PORT_CTRL_2_OFFSET, PORT_USER_PRIORITY_CEILING);\r\n}\r\nstatic inline int port_chk_prio(struct ksz_hw *hw, int p)\r\n{\r\nreturn port_chk(hw, p,\r\nKS8842_PORT_CTRL_1_OFFSET, PORT_PRIO_QUEUE_ENABLE);\r\n}\r\nstatic void sw_dis_diffserv(struct ksz_hw *hw, int port)\r\n{\r\nport_cfg_diffserv(hw, port, 0);\r\n}\r\nstatic void sw_dis_802_1p(struct ksz_hw *hw, int port)\r\n{\r\nport_cfg_802_1p(hw, port, 0);\r\n}\r\nstatic void sw_cfg_replace_null_vid(struct ksz_hw *hw, int set)\r\n{\r\nsw_cfg(hw, KS8842_SWITCH_CTRL_3_OFFSET, SWITCH_REPLACE_NULL_VID, set);\r\n}\r\nstatic void sw_cfg_replace_vid(struct ksz_hw *hw, int port, int set)\r\n{\r\nport_cfg_replace_vid(hw, port, set);\r\n}\r\nstatic void sw_cfg_port_based(struct ksz_hw *hw, int port, u8 prio)\r\n{\r\nu16 data;\r\nif (prio > PORT_BASED_PRIORITY_BASE)\r\nprio = PORT_BASED_PRIORITY_BASE;\r\nhw->ksz_switch->port_cfg[port].port_prio = prio;\r\nport_r16(hw, port, KS8842_PORT_CTRL_1_OFFSET, &data);\r\ndata &= ~PORT_BASED_PRIORITY_MASK;\r\ndata |= prio << PORT_BASED_PRIORITY_SHIFT;\r\nport_w16(hw, port, KS8842_PORT_CTRL_1_OFFSET, data);\r\n}\r\nstatic void sw_dis_multi_queue(struct ksz_hw *hw, int port)\r\n{\r\nport_cfg_prio(hw, port, 0);\r\n}\r\nstatic void sw_init_prio(struct ksz_hw *hw)\r\n{\r\nint port;\r\nint tos;\r\nstruct ksz_switch *sw = hw->ksz_switch;\r\nsw->p_802_1p[0] = 0;\r\nsw->p_802_1p[1] = 0;\r\nsw->p_802_1p[2] = 1;\r\nsw->p_802_1p[3] = 1;\r\nsw->p_802_1p[4] = 2;\r\nsw->p_802_1p[5] = 2;\r\nsw->p_802_1p[6] = 3;\r\nsw->p_802_1p[7] = 3;\r\nfor (tos = 0; tos < DIFFSERV_ENTRIES; tos++)\r\nsw->diffserv[tos] = 0;\r\nfor (port = 0; port < TOTAL_PORT_NUM; port++) {\r\nsw_dis_multi_queue(hw, port);\r\nsw_dis_diffserv(hw, port);\r\nsw_dis_802_1p(hw, port);\r\nsw_cfg_replace_vid(hw, port, 0);\r\nsw->port_cfg[port].port_prio = 0;\r\nsw_cfg_port_based(hw, port, sw->port_cfg[port].port_prio);\r\n}\r\nsw_cfg_replace_null_vid(hw, 0);\r\n}\r\nstatic void port_get_def_vid(struct ksz_hw *hw, int port, u16 *vid)\r\n{\r\nu32 addr;\r\nPORT_CTRL_ADDR(port, addr);\r\naddr += KS8842_PORT_CTRL_VID_OFFSET;\r\n*vid = readw(hw->io + addr);\r\n}\r\nstatic void sw_init_vlan(struct ksz_hw *hw)\r\n{\r\nint port;\r\nint entry;\r\nstruct ksz_switch *sw = hw->ksz_switch;\r\nfor (entry = 0; entry < VLAN_TABLE_ENTRIES; entry++) {\r\nsw_r_vlan_table(hw, entry,\r\n&sw->vlan_table[entry].vid,\r\n&sw->vlan_table[entry].fid,\r\n&sw->vlan_table[entry].member);\r\n}\r\nfor (port = 0; port < TOTAL_PORT_NUM; port++) {\r\nport_get_def_vid(hw, port, &sw->port_cfg[port].vid);\r\nsw->port_cfg[port].member = PORT_MASK;\r\n}\r\n}\r\nstatic void sw_cfg_port_base_vlan(struct ksz_hw *hw, int port, u8 member)\r\n{\r\nu32 addr;\r\nu8 data;\r\nPORT_CTRL_ADDR(port, addr);\r\naddr += KS8842_PORT_CTRL_2_OFFSET;\r\ndata = readb(hw->io + addr);\r\ndata &= ~PORT_VLAN_MEMBERSHIP;\r\ndata |= (member & PORT_MASK);\r\nwriteb(data, hw->io + addr);\r\nhw->ksz_switch->port_cfg[port].member = member;\r\n}\r\nstatic inline void sw_get_addr(struct ksz_hw *hw, u8 *mac_addr)\r\n{\r\nint i;\r\nfor (i = 0; i < 6; i += 2) {\r\nmac_addr[i] = readb(hw->io + KS8842_MAC_ADDR_0_OFFSET + i);\r\nmac_addr[1 + i] = readb(hw->io + KS8842_MAC_ADDR_1_OFFSET + i);\r\n}\r\n}\r\nstatic void sw_set_addr(struct ksz_hw *hw, u8 *mac_addr)\r\n{\r\nint i;\r\nfor (i = 0; i < 6; i += 2) {\r\nwriteb(mac_addr[i], hw->io + KS8842_MAC_ADDR_0_OFFSET + i);\r\nwriteb(mac_addr[1 + i], hw->io + KS8842_MAC_ADDR_1_OFFSET + i);\r\n}\r\n}\r\nstatic void sw_set_global_ctrl(struct ksz_hw *hw)\r\n{\r\nu16 data;\r\ndata = readw(hw->io + KS8842_SWITCH_CTRL_3_OFFSET);\r\ndata |= SWITCH_FLOW_CTRL;\r\nwritew(data, hw->io + KS8842_SWITCH_CTRL_3_OFFSET);\r\ndata = readw(hw->io + KS8842_SWITCH_CTRL_1_OFFSET);\r\ndata |= SWITCH_AGGR_BACKOFF;\r\ndata |= SWITCH_AGING_ENABLE;\r\ndata |= SWITCH_LINK_AUTO_AGING;\r\nif (hw->overrides & FAST_AGING)\r\ndata |= SWITCH_FAST_AGING;\r\nelse\r\ndata &= ~SWITCH_FAST_AGING;\r\nwritew(data, hw->io + KS8842_SWITCH_CTRL_1_OFFSET);\r\ndata = readw(hw->io + KS8842_SWITCH_CTRL_2_OFFSET);\r\ndata |= NO_EXC_COLLISION_DROP;\r\nwritew(data, hw->io + KS8842_SWITCH_CTRL_2_OFFSET);\r\n}\r\nstatic void port_set_stp_state(struct ksz_hw *hw, int port, int state)\r\n{\r\nu16 data;\r\nport_r16(hw, port, KS8842_PORT_CTRL_2_OFFSET, &data);\r\nswitch (state) {\r\ncase STP_STATE_DISABLED:\r\ndata &= ~(PORT_TX_ENABLE | PORT_RX_ENABLE);\r\ndata |= PORT_LEARN_DISABLE;\r\nbreak;\r\ncase STP_STATE_LISTENING:\r\ndata &= ~PORT_TX_ENABLE;\r\ndata |= PORT_RX_ENABLE;\r\ndata |= PORT_LEARN_DISABLE;\r\nbreak;\r\ncase STP_STATE_LEARNING:\r\ndata &= ~PORT_TX_ENABLE;\r\ndata |= PORT_RX_ENABLE;\r\ndata &= ~PORT_LEARN_DISABLE;\r\nbreak;\r\ncase STP_STATE_FORWARDING:\r\ndata |= (PORT_TX_ENABLE | PORT_RX_ENABLE);\r\ndata &= ~PORT_LEARN_DISABLE;\r\nbreak;\r\ncase STP_STATE_BLOCKED:\r\ndata &= ~(PORT_TX_ENABLE | PORT_RX_ENABLE);\r\ndata |= PORT_LEARN_DISABLE;\r\nbreak;\r\ncase STP_STATE_SIMPLE:\r\ndata |= (PORT_TX_ENABLE | PORT_RX_ENABLE);\r\ndata |= PORT_LEARN_DISABLE;\r\nbreak;\r\n}\r\nport_w16(hw, port, KS8842_PORT_CTRL_2_OFFSET, data);\r\nhw->ksz_switch->port_cfg[port].stp_state = state;\r\n}\r\nstatic void sw_clr_sta_mac_table(struct ksz_hw *hw)\r\n{\r\nstruct ksz_mac_table *entry;\r\nint i;\r\nfor (i = 0; i < STATIC_MAC_TABLE_ENTRIES; i++) {\r\nentry = &hw->ksz_switch->mac_table[i];\r\nsw_w_sta_mac_table(hw, i,\r\nentry->mac_addr, entry->ports,\r\nentry->override, 0,\r\nentry->use_fid, entry->fid);\r\n}\r\n}\r\nstatic void sw_init_stp(struct ksz_hw *hw)\r\n{\r\nstruct ksz_mac_table *entry;\r\nentry = &hw->ksz_switch->mac_table[STP_ENTRY];\r\nentry->mac_addr[0] = 0x01;\r\nentry->mac_addr[1] = 0x80;\r\nentry->mac_addr[2] = 0xC2;\r\nentry->mac_addr[3] = 0x00;\r\nentry->mac_addr[4] = 0x00;\r\nentry->mac_addr[5] = 0x00;\r\nentry->ports = HOST_MASK;\r\nentry->override = 1;\r\nentry->valid = 1;\r\nsw_w_sta_mac_table(hw, STP_ENTRY,\r\nentry->mac_addr, entry->ports,\r\nentry->override, entry->valid,\r\nentry->use_fid, entry->fid);\r\n}\r\nstatic void sw_block_addr(struct ksz_hw *hw)\r\n{\r\nstruct ksz_mac_table *entry;\r\nint i;\r\nfor (i = BROADCAST_ENTRY; i <= IPV6_ADDR_ENTRY; i++) {\r\nentry = &hw->ksz_switch->mac_table[i];\r\nentry->valid = 0;\r\nsw_w_sta_mac_table(hw, i,\r\nentry->mac_addr, entry->ports,\r\nentry->override, entry->valid,\r\nentry->use_fid, entry->fid);\r\n}\r\n}\r\nstatic inline void hw_r_phy_ctrl(struct ksz_hw *hw, int phy, u16 *data)\r\n{\r\n*data = readw(hw->io + phy + KS884X_PHY_CTRL_OFFSET);\r\n}\r\nstatic inline void hw_w_phy_ctrl(struct ksz_hw *hw, int phy, u16 data)\r\n{\r\nwritew(data, hw->io + phy + KS884X_PHY_CTRL_OFFSET);\r\n}\r\nstatic inline void hw_r_phy_link_stat(struct ksz_hw *hw, int phy, u16 *data)\r\n{\r\n*data = readw(hw->io + phy + KS884X_PHY_STATUS_OFFSET);\r\n}\r\nstatic inline void hw_r_phy_auto_neg(struct ksz_hw *hw, int phy, u16 *data)\r\n{\r\n*data = readw(hw->io + phy + KS884X_PHY_AUTO_NEG_OFFSET);\r\n}\r\nstatic inline void hw_w_phy_auto_neg(struct ksz_hw *hw, int phy, u16 data)\r\n{\r\nwritew(data, hw->io + phy + KS884X_PHY_AUTO_NEG_OFFSET);\r\n}\r\nstatic inline void hw_r_phy_rem_cap(struct ksz_hw *hw, int phy, u16 *data)\r\n{\r\n*data = readw(hw->io + phy + KS884X_PHY_REMOTE_CAP_OFFSET);\r\n}\r\nstatic inline void hw_r_phy_crossover(struct ksz_hw *hw, int phy, u16 *data)\r\n{\r\n*data = readw(hw->io + phy + KS884X_PHY_CTRL_OFFSET);\r\n}\r\nstatic inline void hw_w_phy_crossover(struct ksz_hw *hw, int phy, u16 data)\r\n{\r\nwritew(data, hw->io + phy + KS884X_PHY_CTRL_OFFSET);\r\n}\r\nstatic inline void hw_r_phy_polarity(struct ksz_hw *hw, int phy, u16 *data)\r\n{\r\n*data = readw(hw->io + phy + KS884X_PHY_PHY_CTRL_OFFSET);\r\n}\r\nstatic inline void hw_w_phy_polarity(struct ksz_hw *hw, int phy, u16 data)\r\n{\r\nwritew(data, hw->io + phy + KS884X_PHY_PHY_CTRL_OFFSET);\r\n}\r\nstatic inline void hw_r_phy_link_md(struct ksz_hw *hw, int phy, u16 *data)\r\n{\r\n*data = readw(hw->io + phy + KS884X_PHY_LINK_MD_OFFSET);\r\n}\r\nstatic inline void hw_w_phy_link_md(struct ksz_hw *hw, int phy, u16 data)\r\n{\r\nwritew(data, hw->io + phy + KS884X_PHY_LINK_MD_OFFSET);\r\n}\r\nstatic void hw_r_phy(struct ksz_hw *hw, int port, u16 reg, u16 *val)\r\n{\r\nint phy;\r\nphy = KS884X_PHY_1_CTRL_OFFSET + port * PHY_CTRL_INTERVAL + reg;\r\n*val = readw(hw->io + phy);\r\n}\r\nstatic void hw_w_phy(struct ksz_hw *hw, int port, u16 reg, u16 val)\r\n{\r\nint phy;\r\nphy = KS884X_PHY_1_CTRL_OFFSET + port * PHY_CTRL_INTERVAL + reg;\r\nwritew(val, hw->io + phy);\r\n}\r\nstatic inline void drop_gpio(struct ksz_hw *hw, u8 gpio)\r\n{\r\nu16 data;\r\ndata = readw(hw->io + KS884X_EEPROM_CTRL_OFFSET);\r\ndata &= ~gpio;\r\nwritew(data, hw->io + KS884X_EEPROM_CTRL_OFFSET);\r\n}\r\nstatic inline void raise_gpio(struct ksz_hw *hw, u8 gpio)\r\n{\r\nu16 data;\r\ndata = readw(hw->io + KS884X_EEPROM_CTRL_OFFSET);\r\ndata |= gpio;\r\nwritew(data, hw->io + KS884X_EEPROM_CTRL_OFFSET);\r\n}\r\nstatic inline u8 state_gpio(struct ksz_hw *hw, u8 gpio)\r\n{\r\nu16 data;\r\ndata = readw(hw->io + KS884X_EEPROM_CTRL_OFFSET);\r\nreturn (u8)(data & gpio);\r\n}\r\nstatic void eeprom_clk(struct ksz_hw *hw)\r\n{\r\nraise_gpio(hw, EEPROM_SERIAL_CLOCK);\r\nudelay(EEPROM_DELAY);\r\ndrop_gpio(hw, EEPROM_SERIAL_CLOCK);\r\nudelay(EEPROM_DELAY);\r\n}\r\nstatic u16 spi_r(struct ksz_hw *hw)\r\n{\r\nint i;\r\nu16 temp = 0;\r\nfor (i = 15; i >= 0; i--) {\r\nraise_gpio(hw, EEPROM_SERIAL_CLOCK);\r\nudelay(EEPROM_DELAY);\r\ntemp |= (state_gpio(hw, EEPROM_DATA_IN)) ? 1 << i : 0;\r\ndrop_gpio(hw, EEPROM_SERIAL_CLOCK);\r\nudelay(EEPROM_DELAY);\r\n}\r\nreturn temp;\r\n}\r\nstatic void spi_w(struct ksz_hw *hw, u16 data)\r\n{\r\nint i;\r\nfor (i = 15; i >= 0; i--) {\r\n(data & (0x01 << i)) ? raise_gpio(hw, EEPROM_DATA_OUT) :\r\ndrop_gpio(hw, EEPROM_DATA_OUT);\r\neeprom_clk(hw);\r\n}\r\n}\r\nstatic void spi_reg(struct ksz_hw *hw, u8 data, u8 reg)\r\n{\r\nint i;\r\nraise_gpio(hw, EEPROM_DATA_OUT);\r\neeprom_clk(hw);\r\nfor (i = 1; i >= 0; i--) {\r\n(data & (0x01 << i)) ? raise_gpio(hw, EEPROM_DATA_OUT) :\r\ndrop_gpio(hw, EEPROM_DATA_OUT);\r\neeprom_clk(hw);\r\n}\r\nfor (i = 5; i >= 0; i--) {\r\n(reg & (0x01 << i)) ? raise_gpio(hw, EEPROM_DATA_OUT) :\r\ndrop_gpio(hw, EEPROM_DATA_OUT);\r\neeprom_clk(hw);\r\n}\r\n}\r\nstatic u16 eeprom_read(struct ksz_hw *hw, u8 reg)\r\n{\r\nu16 data;\r\nraise_gpio(hw, EEPROM_ACCESS_ENABLE | EEPROM_CHIP_SELECT);\r\nspi_reg(hw, AT93C_READ, reg);\r\ndata = spi_r(hw);\r\ndrop_gpio(hw, EEPROM_ACCESS_ENABLE | EEPROM_CHIP_SELECT);\r\nreturn data;\r\n}\r\nstatic void eeprom_write(struct ksz_hw *hw, u8 reg, u16 data)\r\n{\r\nint timeout;\r\nraise_gpio(hw, EEPROM_ACCESS_ENABLE | EEPROM_CHIP_SELECT);\r\nspi_reg(hw, AT93C_CODE, AT93C_WR_ON);\r\ndrop_gpio(hw, EEPROM_CHIP_SELECT);\r\nudelay(1);\r\nraise_gpio(hw, EEPROM_CHIP_SELECT);\r\nspi_reg(hw, AT93C_ERASE, reg);\r\ndrop_gpio(hw, EEPROM_CHIP_SELECT);\r\nudelay(1);\r\nraise_gpio(hw, EEPROM_CHIP_SELECT);\r\ntimeout = 8;\r\nmdelay(2);\r\ndo {\r\nmdelay(1);\r\n} while (!state_gpio(hw, EEPROM_DATA_IN) && --timeout);\r\ndrop_gpio(hw, EEPROM_CHIP_SELECT);\r\nudelay(1);\r\nraise_gpio(hw, EEPROM_CHIP_SELECT);\r\nspi_reg(hw, AT93C_WRITE, reg);\r\nspi_w(hw, data);\r\ndrop_gpio(hw, EEPROM_CHIP_SELECT);\r\nudelay(1);\r\nraise_gpio(hw, EEPROM_CHIP_SELECT);\r\ntimeout = 8;\r\nmdelay(2);\r\ndo {\r\nmdelay(1);\r\n} while (!state_gpio(hw, EEPROM_DATA_IN) && --timeout);\r\ndrop_gpio(hw, EEPROM_CHIP_SELECT);\r\nudelay(1);\r\nraise_gpio(hw, EEPROM_CHIP_SELECT);\r\nspi_reg(hw, AT93C_CODE, AT93C_WR_OFF);\r\ndrop_gpio(hw, EEPROM_ACCESS_ENABLE | EEPROM_CHIP_SELECT);\r\n}\r\nstatic u16 advertised_flow_ctrl(struct ksz_port *port, u16 ctrl)\r\n{\r\nctrl &= ~PORT_AUTO_NEG_SYM_PAUSE;\r\nswitch (port->flow_ctrl) {\r\ncase PHY_FLOW_CTRL:\r\nctrl |= PORT_AUTO_NEG_SYM_PAUSE;\r\nbreak;\r\ncase PHY_TX_ONLY:\r\ncase PHY_RX_ONLY:\r\ndefault:\r\nbreak;\r\n}\r\nreturn ctrl;\r\n}\r\nstatic void set_flow_ctrl(struct ksz_hw *hw, int rx, int tx)\r\n{\r\nu32 rx_cfg;\r\nu32 tx_cfg;\r\nrx_cfg = hw->rx_cfg;\r\ntx_cfg = hw->tx_cfg;\r\nif (rx)\r\nhw->rx_cfg |= DMA_RX_FLOW_ENABLE;\r\nelse\r\nhw->rx_cfg &= ~DMA_RX_FLOW_ENABLE;\r\nif (tx)\r\nhw->tx_cfg |= DMA_TX_FLOW_ENABLE;\r\nelse\r\nhw->tx_cfg &= ~DMA_TX_FLOW_ENABLE;\r\nif (hw->enabled) {\r\nif (rx_cfg != hw->rx_cfg)\r\nwritel(hw->rx_cfg, hw->io + KS_DMA_RX_CTRL);\r\nif (tx_cfg != hw->tx_cfg)\r\nwritel(hw->tx_cfg, hw->io + KS_DMA_TX_CTRL);\r\n}\r\n}\r\nstatic void determine_flow_ctrl(struct ksz_hw *hw, struct ksz_port *port,\r\nu16 local, u16 remote)\r\n{\r\nint rx;\r\nint tx;\r\nif (hw->overrides & PAUSE_FLOW_CTRL)\r\nreturn;\r\nrx = tx = 0;\r\nif (port->force_link)\r\nrx = tx = 1;\r\nif (remote & PHY_AUTO_NEG_SYM_PAUSE) {\r\nif (local & PHY_AUTO_NEG_SYM_PAUSE) {\r\nrx = tx = 1;\r\n} else if ((remote & PHY_AUTO_NEG_ASYM_PAUSE) &&\r\n(local & PHY_AUTO_NEG_PAUSE) ==\r\nPHY_AUTO_NEG_ASYM_PAUSE) {\r\ntx = 1;\r\n}\r\n} else if (remote & PHY_AUTO_NEG_ASYM_PAUSE) {\r\nif ((local & PHY_AUTO_NEG_PAUSE) == PHY_AUTO_NEG_PAUSE)\r\nrx = 1;\r\n}\r\nif (!hw->ksz_switch)\r\nset_flow_ctrl(hw, rx, tx);\r\n}\r\nstatic inline void port_cfg_change(struct ksz_hw *hw, struct ksz_port *port,\r\nstruct ksz_port_info *info, u16 link_status)\r\n{\r\nif ((hw->features & HALF_DUPLEX_SIGNAL_BUG) &&\r\n!(hw->overrides & PAUSE_FLOW_CTRL)) {\r\nu32 cfg = hw->tx_cfg;\r\nif (1 == info->duplex)\r\nhw->tx_cfg &= ~DMA_TX_FLOW_ENABLE;\r\nif (hw->enabled && cfg != hw->tx_cfg)\r\nwritel(hw->tx_cfg, hw->io + KS_DMA_TX_CTRL);\r\n}\r\n}\r\nstatic void port_get_link_speed(struct ksz_port *port)\r\n{\r\nuint interrupt;\r\nstruct ksz_port_info *info;\r\nstruct ksz_port_info *linked = NULL;\r\nstruct ksz_hw *hw = port->hw;\r\nu16 data;\r\nu16 status;\r\nu8 local;\r\nu8 remote;\r\nint i;\r\nint p;\r\nint change = 0;\r\ninterrupt = hw_block_intr(hw);\r\nfor (i = 0, p = port->first_port; i < port->port_cnt; i++, p++) {\r\ninfo = &hw->port_info[p];\r\nport_r16(hw, p, KS884X_PORT_CTRL_4_OFFSET, &data);\r\nport_r16(hw, p, KS884X_PORT_STATUS_OFFSET, &status);\r\nremote = status & (PORT_AUTO_NEG_COMPLETE |\r\nPORT_STATUS_LINK_GOOD);\r\nlocal = (u8) data;\r\nif (local == info->advertised && remote == info->partner)\r\ncontinue;\r\ninfo->advertised = local;\r\ninfo->partner = remote;\r\nif (status & PORT_STATUS_LINK_GOOD) {\r\nif (!linked)\r\nlinked = info;\r\ninfo->tx_rate = 10 * TX_RATE_UNIT;\r\nif (status & PORT_STATUS_SPEED_100MBIT)\r\ninfo->tx_rate = 100 * TX_RATE_UNIT;\r\ninfo->duplex = 1;\r\nif (status & PORT_STATUS_FULL_DUPLEX)\r\ninfo->duplex = 2;\r\nif (media_connected != info->state) {\r\nhw_r_phy(hw, p, KS884X_PHY_AUTO_NEG_OFFSET,\r\n&data);\r\nhw_r_phy(hw, p, KS884X_PHY_REMOTE_CAP_OFFSET,\r\n&status);\r\ndetermine_flow_ctrl(hw, port, data, status);\r\nif (hw->ksz_switch) {\r\nport_cfg_back_pressure(hw, p,\r\n(1 == info->duplex));\r\n}\r\nchange |= 1 << i;\r\nport_cfg_change(hw, port, info, status);\r\n}\r\ninfo->state = media_connected;\r\n} else {\r\nif (media_disconnected != info->state) {\r\nchange |= 1 << i;\r\nhw->port_mib[p].link_down = 1;\r\n}\r\ninfo->state = media_disconnected;\r\n}\r\nhw->port_mib[p].state = (u8) info->state;\r\n}\r\nif (linked && media_disconnected == port->linked->state)\r\nport->linked = linked;\r\nhw_restore_intr(hw, interrupt);\r\n}\r\nstatic void port_set_link_speed(struct ksz_port *port)\r\n{\r\nstruct ksz_port_info *info;\r\nstruct ksz_hw *hw = port->hw;\r\nu16 data;\r\nu16 cfg;\r\nu8 status;\r\nint i;\r\nint p;\r\nfor (i = 0, p = port->first_port; i < port->port_cnt; i++, p++) {\r\ninfo = &hw->port_info[p];\r\nport_r16(hw, p, KS884X_PORT_CTRL_4_OFFSET, &data);\r\nport_r8(hw, p, KS884X_PORT_STATUS_OFFSET, &status);\r\ncfg = 0;\r\nif (status & PORT_STATUS_LINK_GOOD)\r\ncfg = data;\r\ndata |= PORT_AUTO_NEG_ENABLE;\r\ndata = advertised_flow_ctrl(port, data);\r\ndata |= PORT_AUTO_NEG_100BTX_FD | PORT_AUTO_NEG_100BTX |\r\nPORT_AUTO_NEG_10BT_FD | PORT_AUTO_NEG_10BT;\r\nif (port->speed || port->duplex) {\r\nif (10 == port->speed)\r\ndata &= ~(PORT_AUTO_NEG_100BTX_FD |\r\nPORT_AUTO_NEG_100BTX);\r\nelse if (100 == port->speed)\r\ndata &= ~(PORT_AUTO_NEG_10BT_FD |\r\nPORT_AUTO_NEG_10BT);\r\nif (1 == port->duplex)\r\ndata &= ~(PORT_AUTO_NEG_100BTX_FD |\r\nPORT_AUTO_NEG_10BT_FD);\r\nelse if (2 == port->duplex)\r\ndata &= ~(PORT_AUTO_NEG_100BTX |\r\nPORT_AUTO_NEG_10BT);\r\n}\r\nif (data != cfg) {\r\ndata |= PORT_AUTO_NEG_RESTART;\r\nport_w16(hw, p, KS884X_PORT_CTRL_4_OFFSET, data);\r\n}\r\n}\r\n}\r\nstatic void port_force_link_speed(struct ksz_port *port)\r\n{\r\nstruct ksz_hw *hw = port->hw;\r\nu16 data;\r\nint i;\r\nint phy;\r\nint p;\r\nfor (i = 0, p = port->first_port; i < port->port_cnt; i++, p++) {\r\nphy = KS884X_PHY_1_CTRL_OFFSET + p * PHY_CTRL_INTERVAL;\r\nhw_r_phy_ctrl(hw, phy, &data);\r\ndata &= ~PHY_AUTO_NEG_ENABLE;\r\nif (10 == port->speed)\r\ndata &= ~PHY_SPEED_100MBIT;\r\nelse if (100 == port->speed)\r\ndata |= PHY_SPEED_100MBIT;\r\nif (1 == port->duplex)\r\ndata &= ~PHY_FULL_DUPLEX;\r\nelse if (2 == port->duplex)\r\ndata |= PHY_FULL_DUPLEX;\r\nhw_w_phy_ctrl(hw, phy, data);\r\n}\r\n}\r\nstatic void port_set_power_saving(struct ksz_port *port, int enable)\r\n{\r\nstruct ksz_hw *hw = port->hw;\r\nint i;\r\nint p;\r\nfor (i = 0, p = port->first_port; i < port->port_cnt; i++, p++)\r\nport_cfg(hw, p,\r\nKS884X_PORT_CTRL_4_OFFSET, PORT_POWER_DOWN, enable);\r\n}\r\nstatic int hw_chk_wol_pme_status(struct ksz_hw *hw)\r\n{\r\nstruct dev_info *hw_priv = container_of(hw, struct dev_info, hw);\r\nstruct pci_dev *pdev = hw_priv->pdev;\r\nu16 data;\r\nif (!pdev->pm_cap)\r\nreturn 0;\r\npci_read_config_word(pdev, pdev->pm_cap + PCI_PM_CTRL, &data);\r\nreturn (data & PCI_PM_CTRL_PME_STATUS) == PCI_PM_CTRL_PME_STATUS;\r\n}\r\nstatic void hw_clr_wol_pme_status(struct ksz_hw *hw)\r\n{\r\nstruct dev_info *hw_priv = container_of(hw, struct dev_info, hw);\r\nstruct pci_dev *pdev = hw_priv->pdev;\r\nu16 data;\r\nif (!pdev->pm_cap)\r\nreturn;\r\npci_read_config_word(pdev, pdev->pm_cap + PCI_PM_CTRL, &data);\r\ndata |= PCI_PM_CTRL_PME_STATUS;\r\npci_write_config_word(pdev, pdev->pm_cap + PCI_PM_CTRL, data);\r\n}\r\nstatic void hw_cfg_wol_pme(struct ksz_hw *hw, int set)\r\n{\r\nstruct dev_info *hw_priv = container_of(hw, struct dev_info, hw);\r\nstruct pci_dev *pdev = hw_priv->pdev;\r\nu16 data;\r\nif (!pdev->pm_cap)\r\nreturn;\r\npci_read_config_word(pdev, pdev->pm_cap + PCI_PM_CTRL, &data);\r\ndata &= ~PCI_PM_CTRL_STATE_MASK;\r\nif (set)\r\ndata |= PCI_PM_CTRL_PME_ENABLE | PCI_D3hot;\r\nelse\r\ndata &= ~PCI_PM_CTRL_PME_ENABLE;\r\npci_write_config_word(pdev, pdev->pm_cap + PCI_PM_CTRL, data);\r\n}\r\nstatic void hw_cfg_wol(struct ksz_hw *hw, u16 frame, int set)\r\n{\r\nu16 data;\r\ndata = readw(hw->io + KS8841_WOL_CTRL_OFFSET);\r\nif (set)\r\ndata |= frame;\r\nelse\r\ndata &= ~frame;\r\nwritew(data, hw->io + KS8841_WOL_CTRL_OFFSET);\r\n}\r\nstatic void hw_set_wol_frame(struct ksz_hw *hw, int i, uint mask_size,\r\nconst u8 *mask, uint frame_size, const u8 *pattern)\r\n{\r\nint bits;\r\nint from;\r\nint len;\r\nint to;\r\nu32 crc;\r\nu8 data[64];\r\nu8 val = 0;\r\nif (frame_size > mask_size * 8)\r\nframe_size = mask_size * 8;\r\nif (frame_size > 64)\r\nframe_size = 64;\r\ni *= 0x10;\r\nwritel(0, hw->io + KS8841_WOL_FRAME_BYTE0_OFFSET + i);\r\nwritel(0, hw->io + KS8841_WOL_FRAME_BYTE2_OFFSET + i);\r\nbits = len = from = to = 0;\r\ndo {\r\nif (bits) {\r\nif ((val & 1))\r\ndata[to++] = pattern[from];\r\nval >>= 1;\r\n++from;\r\n--bits;\r\n} else {\r\nval = mask[len];\r\nwriteb(val, hw->io + KS8841_WOL_FRAME_BYTE0_OFFSET + i\r\n+ len);\r\n++len;\r\nif (val)\r\nbits = 8;\r\nelse\r\nfrom += 8;\r\n}\r\n} while (from < (int) frame_size);\r\nif (val) {\r\nbits = mask[len - 1];\r\nval <<= (from % 8);\r\nbits &= ~val;\r\nwriteb(bits, hw->io + KS8841_WOL_FRAME_BYTE0_OFFSET + i + len -\r\n1);\r\n}\r\ncrc = ether_crc(to, data);\r\nwritel(crc, hw->io + KS8841_WOL_FRAME_CRC_OFFSET + i);\r\n}\r\nstatic void hw_add_wol_arp(struct ksz_hw *hw, const u8 *ip_addr)\r\n{\r\nstatic const u8 mask[6] = { 0x3F, 0xF0, 0x3F, 0x00, 0xC0, 0x03 };\r\nu8 pattern[42] = {\r\n0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF,\r\n0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\r\n0x08, 0x06,\r\n0x00, 0x01, 0x08, 0x00, 0x06, 0x04, 0x00, 0x01,\r\n0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\r\n0x00, 0x00, 0x00, 0x00,\r\n0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\r\n0x00, 0x00, 0x00, 0x00 };\r\nmemcpy(&pattern[38], ip_addr, 4);\r\nhw_set_wol_frame(hw, 3, 6, mask, 42, pattern);\r\n}\r\nstatic void hw_add_wol_bcast(struct ksz_hw *hw)\r\n{\r\nstatic const u8 mask[] = { 0x3F };\r\nstatic const u8 pattern[] = { 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF };\r\nhw_set_wol_frame(hw, 2, 1, mask, ETH_ALEN, pattern);\r\n}\r\nstatic void hw_add_wol_mcast(struct ksz_hw *hw)\r\n{\r\nstatic const u8 mask[] = { 0x3F };\r\nu8 pattern[] = { 0x33, 0x33, 0xFF, 0x00, 0x00, 0x00 };\r\nmemcpy(&pattern[3], &hw->override_addr[3], 3);\r\nhw_set_wol_frame(hw, 1, 1, mask, 6, pattern);\r\n}\r\nstatic void hw_add_wol_ucast(struct ksz_hw *hw)\r\n{\r\nstatic const u8 mask[] = { 0x3F };\r\nhw_set_wol_frame(hw, 0, 1, mask, ETH_ALEN, hw->override_addr);\r\n}\r\nstatic void hw_enable_wol(struct ksz_hw *hw, u32 wol_enable, const u8 *net_addr)\r\n{\r\nhw_cfg_wol(hw, KS8841_WOL_MAGIC_ENABLE, (wol_enable & WAKE_MAGIC));\r\nhw_cfg_wol(hw, KS8841_WOL_FRAME0_ENABLE, (wol_enable & WAKE_UCAST));\r\nhw_add_wol_ucast(hw);\r\nhw_cfg_wol(hw, KS8841_WOL_FRAME1_ENABLE, (wol_enable & WAKE_MCAST));\r\nhw_add_wol_mcast(hw);\r\nhw_cfg_wol(hw, KS8841_WOL_FRAME2_ENABLE, (wol_enable & WAKE_BCAST));\r\nhw_cfg_wol(hw, KS8841_WOL_FRAME3_ENABLE, (wol_enable & WAKE_ARP));\r\nhw_add_wol_arp(hw, net_addr);\r\n}\r\nstatic int hw_init(struct ksz_hw *hw)\r\n{\r\nint rc = 0;\r\nu16 data;\r\nu16 revision;\r\nwritew(BUS_SPEED_125_MHZ, hw->io + KS884X_BUS_CTRL_OFFSET);\r\ndata = readw(hw->io + KS884X_CHIP_ID_OFFSET);\r\nrevision = (data & KS884X_REVISION_MASK) >> KS884X_REVISION_SHIFT;\r\ndata &= KS884X_CHIP_ID_MASK_41;\r\nif (REG_CHIP_ID_41 == data)\r\nrc = 1;\r\nelse if (REG_CHIP_ID_42 == data)\r\nrc = 2;\r\nelse\r\nreturn 0;\r\nif (revision <= 1) {\r\nhw->features |= SMALL_PACKET_TX_BUG;\r\nif (1 == rc)\r\nhw->features |= HALF_DUPLEX_SIGNAL_BUG;\r\n}\r\nreturn rc;\r\n}\r\nstatic void hw_reset(struct ksz_hw *hw)\r\n{\r\nwritew(GLOBAL_SOFTWARE_RESET, hw->io + KS884X_GLOBAL_CTRL_OFFSET);\r\nmdelay(10);\r\nwritew(0, hw->io + KS884X_GLOBAL_CTRL_OFFSET);\r\n}\r\nstatic void hw_setup(struct ksz_hw *hw)\r\n{\r\n#if SET_DEFAULT_LED\r\nu16 data;\r\ndata = readw(hw->io + KS8842_SWITCH_CTRL_5_OFFSET);\r\ndata &= ~LED_MODE;\r\ndata |= SET_DEFAULT_LED;\r\nwritew(data, hw->io + KS8842_SWITCH_CTRL_5_OFFSET);\r\n#endif\r\nhw->tx_cfg = (DMA_TX_PAD_ENABLE | DMA_TX_CRC_ENABLE |\r\n(DMA_BURST_DEFAULT << DMA_BURST_SHIFT) | DMA_TX_ENABLE);\r\nhw->rx_cfg = (DMA_RX_BROADCAST | DMA_RX_UNICAST |\r\n(DMA_BURST_DEFAULT << DMA_BURST_SHIFT) | DMA_RX_ENABLE);\r\nhw->rx_cfg |= KS884X_DMA_RX_MULTICAST;\r\nhw->rx_cfg |= (DMA_RX_CSUM_TCP | DMA_RX_CSUM_IP);\r\nif (hw->all_multi)\r\nhw->rx_cfg |= DMA_RX_ALL_MULTICAST;\r\nif (hw->promiscuous)\r\nhw->rx_cfg |= DMA_RX_PROMISCUOUS;\r\n}\r\nstatic void hw_setup_intr(struct ksz_hw *hw)\r\n{\r\nhw->intr_mask = KS884X_INT_MASK | KS884X_INT_RX_OVERRUN;\r\n}\r\nstatic void ksz_check_desc_num(struct ksz_desc_info *info)\r\n{\r\n#define MIN_DESC_SHIFT 2\r\nint alloc = info->alloc;\r\nint shift;\r\nshift = 0;\r\nwhile (!(alloc & 1)) {\r\nshift++;\r\nalloc >>= 1;\r\n}\r\nif (alloc != 1 || shift < MIN_DESC_SHIFT) {\r\npr_alert("Hardware descriptor numbers not right!\n");\r\nwhile (alloc) {\r\nshift++;\r\nalloc >>= 1;\r\n}\r\nif (shift < MIN_DESC_SHIFT)\r\nshift = MIN_DESC_SHIFT;\r\nalloc = 1 << shift;\r\ninfo->alloc = alloc;\r\n}\r\ninfo->mask = info->alloc - 1;\r\n}\r\nstatic void hw_init_desc(struct ksz_desc_info *desc_info, int transmit)\r\n{\r\nint i;\r\nu32 phys = desc_info->ring_phys;\r\nstruct ksz_hw_desc *desc = desc_info->ring_virt;\r\nstruct ksz_desc *cur = desc_info->ring;\r\nstruct ksz_desc *previous = NULL;\r\nfor (i = 0; i < desc_info->alloc; i++) {\r\ncur->phw = desc++;\r\nphys += desc_info->size;\r\nprevious = cur++;\r\nprevious->phw->next = cpu_to_le32(phys);\r\n}\r\nprevious->phw->next = cpu_to_le32(desc_info->ring_phys);\r\nprevious->sw.buf.rx.end_of_ring = 1;\r\nprevious->phw->buf.data = cpu_to_le32(previous->sw.buf.data);\r\ndesc_info->avail = desc_info->alloc;\r\ndesc_info->last = desc_info->next = 0;\r\ndesc_info->cur = desc_info->ring;\r\n}\r\nstatic void hw_set_desc_base(struct ksz_hw *hw, u32 tx_addr, u32 rx_addr)\r\n{\r\nwritel(tx_addr, hw->io + KS_DMA_TX_ADDR);\r\nwritel(rx_addr, hw->io + KS_DMA_RX_ADDR);\r\n}\r\nstatic void hw_reset_pkts(struct ksz_desc_info *info)\r\n{\r\ninfo->cur = info->ring;\r\ninfo->avail = info->alloc;\r\ninfo->last = info->next = 0;\r\n}\r\nstatic inline void hw_resume_rx(struct ksz_hw *hw)\r\n{\r\nwritel(DMA_START, hw->io + KS_DMA_RX_START);\r\n}\r\nstatic void hw_start_rx(struct ksz_hw *hw)\r\n{\r\nwritel(hw->rx_cfg, hw->io + KS_DMA_RX_CTRL);\r\nhw->intr_mask |= KS884X_INT_RX_STOPPED;\r\nwritel(DMA_START, hw->io + KS_DMA_RX_START);\r\nhw_ack_intr(hw, KS884X_INT_RX_STOPPED);\r\nhw->rx_stop++;\r\nif (0 == hw->rx_stop)\r\nhw->rx_stop = 2;\r\n}\r\nstatic void hw_stop_rx(struct ksz_hw *hw)\r\n{\r\nhw->rx_stop = 0;\r\nhw_turn_off_intr(hw, KS884X_INT_RX_STOPPED);\r\nwritel((hw->rx_cfg & ~DMA_RX_ENABLE), hw->io + KS_DMA_RX_CTRL);\r\n}\r\nstatic void hw_start_tx(struct ksz_hw *hw)\r\n{\r\nwritel(hw->tx_cfg, hw->io + KS_DMA_TX_CTRL);\r\n}\r\nstatic void hw_stop_tx(struct ksz_hw *hw)\r\n{\r\nwritel((hw->tx_cfg & ~DMA_TX_ENABLE), hw->io + KS_DMA_TX_CTRL);\r\n}\r\nstatic void hw_disable(struct ksz_hw *hw)\r\n{\r\nhw_stop_rx(hw);\r\nhw_stop_tx(hw);\r\nhw->enabled = 0;\r\n}\r\nstatic void hw_enable(struct ksz_hw *hw)\r\n{\r\nhw_start_tx(hw);\r\nhw_start_rx(hw);\r\nhw->enabled = 1;\r\n}\r\nstatic int hw_alloc_pkt(struct ksz_hw *hw, int length, int physical)\r\n{\r\nif (hw->tx_desc_info.avail <= 1)\r\nreturn 0;\r\nget_tx_pkt(&hw->tx_desc_info, &hw->tx_desc_info.cur);\r\nhw->tx_desc_info.cur->sw.buf.tx.first_seg = 1;\r\n++hw->tx_int_cnt;\r\nhw->tx_size += length;\r\nif (hw->tx_size >= MAX_TX_HELD_SIZE)\r\nhw->tx_int_cnt = hw->tx_int_mask + 1;\r\nif (physical > hw->tx_desc_info.avail)\r\nreturn 1;\r\nreturn hw->tx_desc_info.avail;\r\n}\r\nstatic void hw_send_pkt(struct ksz_hw *hw)\r\n{\r\nstruct ksz_desc *cur = hw->tx_desc_info.cur;\r\ncur->sw.buf.tx.last_seg = 1;\r\nif (hw->tx_int_cnt > hw->tx_int_mask) {\r\ncur->sw.buf.tx.intr = 1;\r\nhw->tx_int_cnt = 0;\r\nhw->tx_size = 0;\r\n}\r\ncur->sw.buf.tx.dest_port = hw->dst_ports;\r\nrelease_desc(cur);\r\nwritel(0, hw->io + KS_DMA_TX_START);\r\n}\r\nstatic int empty_addr(u8 *addr)\r\n{\r\nu32 *addr1 = (u32 *) addr;\r\nu16 *addr2 = (u16 *) &addr[4];\r\nreturn 0 == *addr1 && 0 == *addr2;\r\n}\r\nstatic void hw_set_addr(struct ksz_hw *hw)\r\n{\r\nint i;\r\nfor (i = 0; i < ETH_ALEN; i++)\r\nwriteb(hw->override_addr[MAC_ADDR_ORDER(i)],\r\nhw->io + KS884X_ADDR_0_OFFSET + i);\r\nsw_set_addr(hw, hw->override_addr);\r\n}\r\nstatic void hw_read_addr(struct ksz_hw *hw)\r\n{\r\nint i;\r\nfor (i = 0; i < ETH_ALEN; i++)\r\nhw->perm_addr[MAC_ADDR_ORDER(i)] = readb(hw->io +\r\nKS884X_ADDR_0_OFFSET + i);\r\nif (!hw->mac_override) {\r\nmemcpy(hw->override_addr, hw->perm_addr, ETH_ALEN);\r\nif (empty_addr(hw->override_addr)) {\r\nmemcpy(hw->perm_addr, DEFAULT_MAC_ADDRESS, ETH_ALEN);\r\nmemcpy(hw->override_addr, DEFAULT_MAC_ADDRESS,\r\nETH_ALEN);\r\nhw->override_addr[5] += hw->id;\r\nhw_set_addr(hw);\r\n}\r\n}\r\n}\r\nstatic void hw_ena_add_addr(struct ksz_hw *hw, int index, u8 *mac_addr)\r\n{\r\nint i;\r\nu32 mac_addr_lo;\r\nu32 mac_addr_hi;\r\nmac_addr_hi = 0;\r\nfor (i = 0; i < 2; i++) {\r\nmac_addr_hi <<= 8;\r\nmac_addr_hi |= mac_addr[i];\r\n}\r\nmac_addr_hi |= ADD_ADDR_ENABLE;\r\nmac_addr_lo = 0;\r\nfor (i = 2; i < 6; i++) {\r\nmac_addr_lo <<= 8;\r\nmac_addr_lo |= mac_addr[i];\r\n}\r\nindex *= ADD_ADDR_INCR;\r\nwritel(mac_addr_lo, hw->io + index + KS_ADD_ADDR_0_LO);\r\nwritel(mac_addr_hi, hw->io + index + KS_ADD_ADDR_0_HI);\r\n}\r\nstatic void hw_set_add_addr(struct ksz_hw *hw)\r\n{\r\nint i;\r\nfor (i = 0; i < ADDITIONAL_ENTRIES; i++) {\r\nif (empty_addr(hw->address[i]))\r\nwritel(0, hw->io + ADD_ADDR_INCR * i +\r\nKS_ADD_ADDR_0_HI);\r\nelse\r\nhw_ena_add_addr(hw, i, hw->address[i]);\r\n}\r\n}\r\nstatic int hw_add_addr(struct ksz_hw *hw, u8 *mac_addr)\r\n{\r\nint i;\r\nint j = ADDITIONAL_ENTRIES;\r\nif (ether_addr_equal(hw->override_addr, mac_addr))\r\nreturn 0;\r\nfor (i = 0; i < hw->addr_list_size; i++) {\r\nif (ether_addr_equal(hw->address[i], mac_addr))\r\nreturn 0;\r\nif (ADDITIONAL_ENTRIES == j && empty_addr(hw->address[i]))\r\nj = i;\r\n}\r\nif (j < ADDITIONAL_ENTRIES) {\r\nmemcpy(hw->address[j], mac_addr, ETH_ALEN);\r\nhw_ena_add_addr(hw, j, hw->address[j]);\r\nreturn 0;\r\n}\r\nreturn -1;\r\n}\r\nstatic int hw_del_addr(struct ksz_hw *hw, u8 *mac_addr)\r\n{\r\nint i;\r\nfor (i = 0; i < hw->addr_list_size; i++) {\r\nif (ether_addr_equal(hw->address[i], mac_addr)) {\r\neth_zero_addr(hw->address[i]);\r\nwritel(0, hw->io + ADD_ADDR_INCR * i +\r\nKS_ADD_ADDR_0_HI);\r\nreturn 0;\r\n}\r\n}\r\nreturn -1;\r\n}\r\nstatic void hw_clr_multicast(struct ksz_hw *hw)\r\n{\r\nint i;\r\nfor (i = 0; i < HW_MULTICAST_SIZE; i++) {\r\nhw->multi_bits[i] = 0;\r\nwriteb(0, hw->io + KS884X_MULTICAST_0_OFFSET + i);\r\n}\r\n}\r\nstatic void hw_set_grp_addr(struct ksz_hw *hw)\r\n{\r\nint i;\r\nint index;\r\nint position;\r\nint value;\r\nmemset(hw->multi_bits, 0, sizeof(u8) * HW_MULTICAST_SIZE);\r\nfor (i = 0; i < hw->multi_list_size; i++) {\r\nposition = (ether_crc(6, hw->multi_list[i]) >> 26) & 0x3f;\r\nindex = position >> 3;\r\nvalue = 1 << (position & 7);\r\nhw->multi_bits[index] |= (u8) value;\r\n}\r\nfor (i = 0; i < HW_MULTICAST_SIZE; i++)\r\nwriteb(hw->multi_bits[i], hw->io + KS884X_MULTICAST_0_OFFSET +\r\ni);\r\n}\r\nstatic void hw_set_multicast(struct ksz_hw *hw, u8 multicast)\r\n{\r\nhw_stop_rx(hw);\r\nif (multicast)\r\nhw->rx_cfg |= DMA_RX_ALL_MULTICAST;\r\nelse\r\nhw->rx_cfg &= ~DMA_RX_ALL_MULTICAST;\r\nif (hw->enabled)\r\nhw_start_rx(hw);\r\n}\r\nstatic void hw_set_promiscuous(struct ksz_hw *hw, u8 prom)\r\n{\r\nhw_stop_rx(hw);\r\nif (prom)\r\nhw->rx_cfg |= DMA_RX_PROMISCUOUS;\r\nelse\r\nhw->rx_cfg &= ~DMA_RX_PROMISCUOUS;\r\nif (hw->enabled)\r\nhw_start_rx(hw);\r\n}\r\nstatic void sw_enable(struct ksz_hw *hw, int enable)\r\n{\r\nint port;\r\nfor (port = 0; port < SWITCH_PORT_NUM; port++) {\r\nif (hw->dev_count > 1) {\r\nsw_cfg_port_base_vlan(hw, port,\r\nHOST_MASK | (1 << port));\r\nport_set_stp_state(hw, port, STP_STATE_DISABLED);\r\n} else {\r\nsw_cfg_port_base_vlan(hw, port, PORT_MASK);\r\nport_set_stp_state(hw, port, STP_STATE_FORWARDING);\r\n}\r\n}\r\nif (hw->dev_count > 1)\r\nport_set_stp_state(hw, SWITCH_PORT_NUM, STP_STATE_SIMPLE);\r\nelse\r\nport_set_stp_state(hw, SWITCH_PORT_NUM, STP_STATE_FORWARDING);\r\nif (enable)\r\nenable = KS8842_START;\r\nwritew(enable, hw->io + KS884X_CHIP_ID_OFFSET);\r\n}\r\nstatic void sw_setup(struct ksz_hw *hw)\r\n{\r\nint port;\r\nsw_set_global_ctrl(hw);\r\nsw_init_broad_storm(hw);\r\nhw_cfg_broad_storm(hw, BROADCAST_STORM_PROTECTION_RATE);\r\nfor (port = 0; port < SWITCH_PORT_NUM; port++)\r\nsw_ena_broad_storm(hw, port);\r\nsw_init_prio(hw);\r\nsw_init_mirror(hw);\r\nsw_init_prio_rate(hw);\r\nsw_init_vlan(hw);\r\nif (hw->features & STP_SUPPORT)\r\nsw_init_stp(hw);\r\nif (!sw_chk(hw, KS8842_SWITCH_CTRL_1_OFFSET,\r\nSWITCH_TX_FLOW_CTRL | SWITCH_RX_FLOW_CTRL))\r\nhw->overrides |= PAUSE_FLOW_CTRL;\r\nsw_enable(hw, 1);\r\n}\r\nstatic void ksz_start_timer(struct ksz_timer_info *info, int time)\r\n{\r\ninfo->cnt = 0;\r\ninfo->timer.expires = jiffies + time;\r\nadd_timer(&info->timer);\r\ninfo->max = -1;\r\n}\r\nstatic void ksz_stop_timer(struct ksz_timer_info *info)\r\n{\r\nif (info->max) {\r\ninfo->max = 0;\r\ndel_timer_sync(&info->timer);\r\n}\r\n}\r\nstatic void ksz_init_timer(struct ksz_timer_info *info, int period,\r\nvoid (*function)(unsigned long), void *data)\r\n{\r\ninfo->max = 0;\r\ninfo->period = period;\r\nsetup_timer(&info->timer, function, (unsigned long)data);\r\n}\r\nstatic void ksz_update_timer(struct ksz_timer_info *info)\r\n{\r\n++info->cnt;\r\nif (info->max > 0) {\r\nif (info->cnt < info->max) {\r\ninfo->timer.expires = jiffies + info->period;\r\nadd_timer(&info->timer);\r\n} else\r\ninfo->max = 0;\r\n} else if (info->max < 0) {\r\ninfo->timer.expires = jiffies + info->period;\r\nadd_timer(&info->timer);\r\n}\r\n}\r\nstatic int ksz_alloc_soft_desc(struct ksz_desc_info *desc_info, int transmit)\r\n{\r\ndesc_info->ring = kzalloc(sizeof(struct ksz_desc) * desc_info->alloc,\r\nGFP_KERNEL);\r\nif (!desc_info->ring)\r\nreturn 1;\r\nhw_init_desc(desc_info, transmit);\r\nreturn 0;\r\n}\r\nstatic int ksz_alloc_desc(struct dev_info *adapter)\r\n{\r\nstruct ksz_hw *hw = &adapter->hw;\r\nint offset;\r\nadapter->desc_pool.alloc_size =\r\nhw->rx_desc_info.size * hw->rx_desc_info.alloc +\r\nhw->tx_desc_info.size * hw->tx_desc_info.alloc +\r\nDESC_ALIGNMENT;\r\nadapter->desc_pool.alloc_virt =\r\npci_zalloc_consistent(adapter->pdev,\r\nadapter->desc_pool.alloc_size,\r\n&adapter->desc_pool.dma_addr);\r\nif (adapter->desc_pool.alloc_virt == NULL) {\r\nadapter->desc_pool.alloc_size = 0;\r\nreturn 1;\r\n}\r\noffset = (((ulong) adapter->desc_pool.alloc_virt % DESC_ALIGNMENT) ?\r\n(DESC_ALIGNMENT -\r\n((ulong) adapter->desc_pool.alloc_virt % DESC_ALIGNMENT)) : 0);\r\nadapter->desc_pool.virt = adapter->desc_pool.alloc_virt + offset;\r\nadapter->desc_pool.phys = adapter->desc_pool.dma_addr + offset;\r\nhw->rx_desc_info.ring_virt = (struct ksz_hw_desc *)\r\nadapter->desc_pool.virt;\r\nhw->rx_desc_info.ring_phys = adapter->desc_pool.phys;\r\noffset = hw->rx_desc_info.alloc * hw->rx_desc_info.size;\r\nhw->tx_desc_info.ring_virt = (struct ksz_hw_desc *)\r\n(adapter->desc_pool.virt + offset);\r\nhw->tx_desc_info.ring_phys = adapter->desc_pool.phys + offset;\r\nif (ksz_alloc_soft_desc(&hw->rx_desc_info, 0))\r\nreturn 1;\r\nif (ksz_alloc_soft_desc(&hw->tx_desc_info, 1))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic void free_dma_buf(struct dev_info *adapter, struct ksz_dma_buf *dma_buf,\r\nint direction)\r\n{\r\npci_unmap_single(adapter->pdev, dma_buf->dma, dma_buf->len, direction);\r\ndev_kfree_skb(dma_buf->skb);\r\ndma_buf->skb = NULL;\r\ndma_buf->dma = 0;\r\n}\r\nstatic void ksz_init_rx_buffers(struct dev_info *adapter)\r\n{\r\nint i;\r\nstruct ksz_desc *desc;\r\nstruct ksz_dma_buf *dma_buf;\r\nstruct ksz_hw *hw = &adapter->hw;\r\nstruct ksz_desc_info *info = &hw->rx_desc_info;\r\nfor (i = 0; i < hw->rx_desc_info.alloc; i++) {\r\nget_rx_pkt(info, &desc);\r\ndma_buf = DMA_BUFFER(desc);\r\nif (dma_buf->skb && dma_buf->len != adapter->mtu)\r\nfree_dma_buf(adapter, dma_buf, PCI_DMA_FROMDEVICE);\r\ndma_buf->len = adapter->mtu;\r\nif (!dma_buf->skb)\r\ndma_buf->skb = alloc_skb(dma_buf->len, GFP_ATOMIC);\r\nif (dma_buf->skb && !dma_buf->dma)\r\ndma_buf->dma = pci_map_single(\r\nadapter->pdev,\r\nskb_tail_pointer(dma_buf->skb),\r\ndma_buf->len,\r\nPCI_DMA_FROMDEVICE);\r\nset_rx_buf(desc, dma_buf->dma);\r\nset_rx_len(desc, dma_buf->len);\r\nrelease_desc(desc);\r\n}\r\n}\r\nstatic int ksz_alloc_mem(struct dev_info *adapter)\r\n{\r\nstruct ksz_hw *hw = &adapter->hw;\r\nhw->rx_desc_info.alloc = NUM_OF_RX_DESC;\r\nhw->tx_desc_info.alloc = NUM_OF_TX_DESC;\r\nhw->tx_int_cnt = 0;\r\nhw->tx_int_mask = NUM_OF_TX_DESC / 4;\r\nif (hw->tx_int_mask > 8)\r\nhw->tx_int_mask = 8;\r\nwhile (hw->tx_int_mask) {\r\nhw->tx_int_cnt++;\r\nhw->tx_int_mask >>= 1;\r\n}\r\nif (hw->tx_int_cnt) {\r\nhw->tx_int_mask = (1 << (hw->tx_int_cnt - 1)) - 1;\r\nhw->tx_int_cnt = 0;\r\n}\r\nhw->rx_desc_info.size =\r\n(((sizeof(struct ksz_hw_desc) + DESC_ALIGNMENT - 1) /\r\nDESC_ALIGNMENT) * DESC_ALIGNMENT);\r\nhw->tx_desc_info.size =\r\n(((sizeof(struct ksz_hw_desc) + DESC_ALIGNMENT - 1) /\r\nDESC_ALIGNMENT) * DESC_ALIGNMENT);\r\nif (hw->rx_desc_info.size != sizeof(struct ksz_hw_desc))\r\npr_alert("Hardware descriptor size not right!\n");\r\nksz_check_desc_num(&hw->rx_desc_info);\r\nksz_check_desc_num(&hw->tx_desc_info);\r\nif (ksz_alloc_desc(adapter))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic void ksz_free_desc(struct dev_info *adapter)\r\n{\r\nstruct ksz_hw *hw = &adapter->hw;\r\nhw->rx_desc_info.ring_virt = NULL;\r\nhw->tx_desc_info.ring_virt = NULL;\r\nhw->rx_desc_info.ring_phys = 0;\r\nhw->tx_desc_info.ring_phys = 0;\r\nif (adapter->desc_pool.alloc_virt)\r\npci_free_consistent(\r\nadapter->pdev,\r\nadapter->desc_pool.alloc_size,\r\nadapter->desc_pool.alloc_virt,\r\nadapter->desc_pool.dma_addr);\r\nadapter->desc_pool.alloc_size = 0;\r\nadapter->desc_pool.alloc_virt = NULL;\r\nkfree(hw->rx_desc_info.ring);\r\nhw->rx_desc_info.ring = NULL;\r\nkfree(hw->tx_desc_info.ring);\r\nhw->tx_desc_info.ring = NULL;\r\n}\r\nstatic void ksz_free_buffers(struct dev_info *adapter,\r\nstruct ksz_desc_info *desc_info, int direction)\r\n{\r\nint i;\r\nstruct ksz_dma_buf *dma_buf;\r\nstruct ksz_desc *desc = desc_info->ring;\r\nfor (i = 0; i < desc_info->alloc; i++) {\r\ndma_buf = DMA_BUFFER(desc);\r\nif (dma_buf->skb)\r\nfree_dma_buf(adapter, dma_buf, direction);\r\ndesc++;\r\n}\r\n}\r\nstatic void ksz_free_mem(struct dev_info *adapter)\r\n{\r\nksz_free_buffers(adapter, &adapter->hw.tx_desc_info,\r\nPCI_DMA_TODEVICE);\r\nksz_free_buffers(adapter, &adapter->hw.rx_desc_info,\r\nPCI_DMA_FROMDEVICE);\r\nksz_free_desc(adapter);\r\n}\r\nstatic void get_mib_counters(struct ksz_hw *hw, int first, int cnt,\r\nu64 *counter)\r\n{\r\nint i;\r\nint mib;\r\nint port;\r\nstruct ksz_port_mib *port_mib;\r\nmemset(counter, 0, sizeof(u64) * TOTAL_PORT_COUNTER_NUM);\r\nfor (i = 0, port = first; i < cnt; i++, port++) {\r\nport_mib = &hw->port_mib[port];\r\nfor (mib = port_mib->mib_start; mib < hw->mib_cnt; mib++)\r\ncounter[mib] += port_mib->counter[mib];\r\n}\r\n}\r\nstatic void send_packet(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct ksz_desc *desc;\r\nstruct ksz_desc *first;\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nstruct ksz_desc_info *info = &hw->tx_desc_info;\r\nstruct ksz_dma_buf *dma_buf;\r\nint len;\r\nint last_frag = skb_shinfo(skb)->nr_frags;\r\nif (hw->dev_count > 1)\r\nhw->dst_ports = 1 << priv->port.first_port;\r\nlen = skb->len;\r\nfirst = info->cur;\r\ndesc = first;\r\ndma_buf = DMA_BUFFER(desc);\r\nif (last_frag) {\r\nint frag;\r\nskb_frag_t *this_frag;\r\ndma_buf->len = skb_headlen(skb);\r\ndma_buf->dma = pci_map_single(\r\nhw_priv->pdev, skb->data, dma_buf->len,\r\nPCI_DMA_TODEVICE);\r\nset_tx_buf(desc, dma_buf->dma);\r\nset_tx_len(desc, dma_buf->len);\r\nfrag = 0;\r\ndo {\r\nthis_frag = &skb_shinfo(skb)->frags[frag];\r\nget_tx_pkt(info, &desc);\r\n++hw->tx_int_cnt;\r\ndma_buf = DMA_BUFFER(desc);\r\ndma_buf->len = skb_frag_size(this_frag);\r\ndma_buf->dma = pci_map_single(\r\nhw_priv->pdev,\r\nskb_frag_address(this_frag),\r\ndma_buf->len,\r\nPCI_DMA_TODEVICE);\r\nset_tx_buf(desc, dma_buf->dma);\r\nset_tx_len(desc, dma_buf->len);\r\nfrag++;\r\nif (frag == last_frag)\r\nbreak;\r\nrelease_desc(desc);\r\n} while (1);\r\ninfo->cur = desc;\r\nrelease_desc(first);\r\n} else {\r\ndma_buf->len = len;\r\ndma_buf->dma = pci_map_single(\r\nhw_priv->pdev, skb->data, dma_buf->len,\r\nPCI_DMA_TODEVICE);\r\nset_tx_buf(desc, dma_buf->dma);\r\nset_tx_len(desc, dma_buf->len);\r\n}\r\nif (skb->ip_summed == CHECKSUM_PARTIAL) {\r\n(desc)->sw.buf.tx.csum_gen_tcp = 1;\r\n(desc)->sw.buf.tx.csum_gen_udp = 1;\r\n}\r\ndma_buf->skb = skb;\r\nhw_send_pkt(hw);\r\ndev->stats.tx_packets++;\r\ndev->stats.tx_bytes += len;\r\n}\r\nstatic void transmit_cleanup(struct dev_info *hw_priv, int normal)\r\n{\r\nint last;\r\nunion desc_stat status;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nstruct ksz_desc_info *info = &hw->tx_desc_info;\r\nstruct ksz_desc *desc;\r\nstruct ksz_dma_buf *dma_buf;\r\nstruct net_device *dev = NULL;\r\nspin_lock_irq(&hw_priv->hwlock);\r\nlast = info->last;\r\nwhile (info->avail < info->alloc) {\r\ndesc = &info->ring[last];\r\nstatus.data = le32_to_cpu(desc->phw->ctrl.data);\r\nif (status.tx.hw_owned) {\r\nif (normal)\r\nbreak;\r\nelse\r\nreset_desc(desc, status);\r\n}\r\ndma_buf = DMA_BUFFER(desc);\r\npci_unmap_single(\r\nhw_priv->pdev, dma_buf->dma, dma_buf->len,\r\nPCI_DMA_TODEVICE);\r\nif (dma_buf->skb) {\r\ndev = dma_buf->skb->dev;\r\ndev_kfree_skb_irq(dma_buf->skb);\r\ndma_buf->skb = NULL;\r\n}\r\nlast++;\r\nlast &= info->mask;\r\ninfo->avail++;\r\n}\r\ninfo->last = last;\r\nspin_unlock_irq(&hw_priv->hwlock);\r\nif (dev)\r\nnetif_trans_update(dev);\r\n}\r\nstatic void tx_done(struct dev_info *hw_priv)\r\n{\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nint port;\r\ntransmit_cleanup(hw_priv, 1);\r\nfor (port = 0; port < hw->dev_count; port++) {\r\nstruct net_device *dev = hw->port_info[port].pdev;\r\nif (netif_running(dev) && netif_queue_stopped(dev))\r\nnetif_wake_queue(dev);\r\n}\r\n}\r\nstatic inline void copy_old_skb(struct sk_buff *old, struct sk_buff *skb)\r\n{\r\nskb->dev = old->dev;\r\nskb->protocol = old->protocol;\r\nskb->ip_summed = old->ip_summed;\r\nskb->csum = old->csum;\r\nskb_set_network_header(skb, ETH_HLEN);\r\ndev_consume_skb_any(old);\r\n}\r\nstatic netdev_tx_t netdev_tx(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nint left;\r\nint num = 1;\r\nint rc = 0;\r\nif (hw->features & SMALL_PACKET_TX_BUG) {\r\nstruct sk_buff *org_skb = skb;\r\nif (skb->len <= 48) {\r\nif (skb_end_pointer(skb) - skb->data >= 50) {\r\nmemset(&skb->data[skb->len], 0, 50 - skb->len);\r\nskb->len = 50;\r\n} else {\r\nskb = netdev_alloc_skb(dev, 50);\r\nif (!skb)\r\nreturn NETDEV_TX_BUSY;\r\nmemcpy(skb->data, org_skb->data, org_skb->len);\r\nmemset(&skb->data[org_skb->len], 0,\r\n50 - org_skb->len);\r\nskb->len = 50;\r\ncopy_old_skb(org_skb, skb);\r\n}\r\n}\r\n}\r\nspin_lock_irq(&hw_priv->hwlock);\r\nnum = skb_shinfo(skb)->nr_frags + 1;\r\nleft = hw_alloc_pkt(hw, skb->len, num);\r\nif (left) {\r\nif (left < num ||\r\n(CHECKSUM_PARTIAL == skb->ip_summed &&\r\nskb->protocol == htons(ETH_P_IPV6))) {\r\nstruct sk_buff *org_skb = skb;\r\nskb = netdev_alloc_skb(dev, org_skb->len);\r\nif (!skb) {\r\nrc = NETDEV_TX_BUSY;\r\ngoto unlock;\r\n}\r\nskb_copy_and_csum_dev(org_skb, skb->data);\r\norg_skb->ip_summed = CHECKSUM_NONE;\r\nskb->len = org_skb->len;\r\ncopy_old_skb(org_skb, skb);\r\n}\r\nsend_packet(skb, dev);\r\nif (left <= num)\r\nnetif_stop_queue(dev);\r\n} else {\r\nnetif_stop_queue(dev);\r\nrc = NETDEV_TX_BUSY;\r\n}\r\nunlock:\r\nspin_unlock_irq(&hw_priv->hwlock);\r\nreturn rc;\r\n}\r\nstatic void netdev_tx_timeout(struct net_device *dev)\r\n{\r\nstatic unsigned long last_reset;\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nint port;\r\nif (hw->dev_count > 1) {\r\nif (time_before_eq(jiffies, last_reset + dev->watchdog_timeo))\r\nhw_priv = NULL;\r\n}\r\nlast_reset = jiffies;\r\nif (hw_priv) {\r\nhw_dis_intr(hw);\r\nhw_disable(hw);\r\ntransmit_cleanup(hw_priv, 0);\r\nhw_reset_pkts(&hw->rx_desc_info);\r\nhw_reset_pkts(&hw->tx_desc_info);\r\nksz_init_rx_buffers(hw_priv);\r\nhw_reset(hw);\r\nhw_set_desc_base(hw,\r\nhw->tx_desc_info.ring_phys,\r\nhw->rx_desc_info.ring_phys);\r\nhw_set_addr(hw);\r\nif (hw->all_multi)\r\nhw_set_multicast(hw, hw->all_multi);\r\nelse if (hw->multi_list_size)\r\nhw_set_grp_addr(hw);\r\nif (hw->dev_count > 1) {\r\nhw_set_add_addr(hw);\r\nfor (port = 0; port < SWITCH_PORT_NUM; port++) {\r\nstruct net_device *port_dev;\r\nport_set_stp_state(hw, port,\r\nSTP_STATE_DISABLED);\r\nport_dev = hw->port_info[port].pdev;\r\nif (netif_running(port_dev))\r\nport_set_stp_state(hw, port,\r\nSTP_STATE_SIMPLE);\r\n}\r\n}\r\nhw_enable(hw);\r\nhw_ena_intr(hw);\r\n}\r\nnetif_trans_update(dev);\r\nnetif_wake_queue(dev);\r\n}\r\nstatic inline void csum_verified(struct sk_buff *skb)\r\n{\r\nunsigned short protocol;\r\nstruct iphdr *iph;\r\nprotocol = skb->protocol;\r\nskb_reset_network_header(skb);\r\niph = (struct iphdr *) skb_network_header(skb);\r\nif (protocol == htons(ETH_P_8021Q)) {\r\nprotocol = iph->tot_len;\r\nskb_set_network_header(skb, VLAN_HLEN);\r\niph = (struct iphdr *) skb_network_header(skb);\r\n}\r\nif (protocol == htons(ETH_P_IP)) {\r\nif (iph->protocol == IPPROTO_TCP)\r\nskb->ip_summed = CHECKSUM_UNNECESSARY;\r\n}\r\n}\r\nstatic inline int rx_proc(struct net_device *dev, struct ksz_hw* hw,\r\nstruct ksz_desc *desc, union desc_stat status)\r\n{\r\nint packet_len;\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_dma_buf *dma_buf;\r\nstruct sk_buff *skb;\r\nint rx_status;\r\npacket_len = status.rx.frame_len - 4;\r\ndma_buf = DMA_BUFFER(desc);\r\npci_dma_sync_single_for_cpu(\r\nhw_priv->pdev, dma_buf->dma, packet_len + 4,\r\nPCI_DMA_FROMDEVICE);\r\ndo {\r\nskb = netdev_alloc_skb(dev, packet_len + 2);\r\nif (!skb) {\r\ndev->stats.rx_dropped++;\r\nreturn -ENOMEM;\r\n}\r\nskb_reserve(skb, 2);\r\nmemcpy(skb_put(skb, packet_len),\r\ndma_buf->skb->data, packet_len);\r\n} while (0);\r\nskb->protocol = eth_type_trans(skb, dev);\r\nif (hw->rx_cfg & (DMA_RX_CSUM_UDP | DMA_RX_CSUM_TCP))\r\ncsum_verified(skb);\r\ndev->stats.rx_packets++;\r\ndev->stats.rx_bytes += packet_len;\r\nrx_status = netif_rx(skb);\r\nreturn 0;\r\n}\r\nstatic int dev_rcv_packets(struct dev_info *hw_priv)\r\n{\r\nint next;\r\nunion desc_stat status;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nstruct net_device *dev = hw->port_info[0].pdev;\r\nstruct ksz_desc_info *info = &hw->rx_desc_info;\r\nint left = info->alloc;\r\nstruct ksz_desc *desc;\r\nint received = 0;\r\nnext = info->next;\r\nwhile (left--) {\r\ndesc = &info->ring[next];\r\nstatus.data = le32_to_cpu(desc->phw->ctrl.data);\r\nif (status.rx.hw_owned)\r\nbreak;\r\nif (status.rx.last_desc && status.rx.first_desc) {\r\nif (rx_proc(dev, hw, desc, status))\r\ngoto release_packet;\r\nreceived++;\r\n}\r\nrelease_packet:\r\nrelease_desc(desc);\r\nnext++;\r\nnext &= info->mask;\r\n}\r\ninfo->next = next;\r\nreturn received;\r\n}\r\nstatic int port_rcv_packets(struct dev_info *hw_priv)\r\n{\r\nint next;\r\nunion desc_stat status;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nstruct net_device *dev = hw->port_info[0].pdev;\r\nstruct ksz_desc_info *info = &hw->rx_desc_info;\r\nint left = info->alloc;\r\nstruct ksz_desc *desc;\r\nint received = 0;\r\nnext = info->next;\r\nwhile (left--) {\r\ndesc = &info->ring[next];\r\nstatus.data = le32_to_cpu(desc->phw->ctrl.data);\r\nif (status.rx.hw_owned)\r\nbreak;\r\nif (hw->dev_count > 1) {\r\nint p = HW_TO_DEV_PORT(status.rx.src_port);\r\ndev = hw->port_info[p].pdev;\r\nif (!netif_running(dev))\r\ngoto release_packet;\r\n}\r\nif (status.rx.last_desc && status.rx.first_desc) {\r\nif (rx_proc(dev, hw, desc, status))\r\ngoto release_packet;\r\nreceived++;\r\n}\r\nrelease_packet:\r\nrelease_desc(desc);\r\nnext++;\r\nnext &= info->mask;\r\n}\r\ninfo->next = next;\r\nreturn received;\r\n}\r\nstatic int dev_rcv_special(struct dev_info *hw_priv)\r\n{\r\nint next;\r\nunion desc_stat status;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nstruct net_device *dev = hw->port_info[0].pdev;\r\nstruct ksz_desc_info *info = &hw->rx_desc_info;\r\nint left = info->alloc;\r\nstruct ksz_desc *desc;\r\nint received = 0;\r\nnext = info->next;\r\nwhile (left--) {\r\ndesc = &info->ring[next];\r\nstatus.data = le32_to_cpu(desc->phw->ctrl.data);\r\nif (status.rx.hw_owned)\r\nbreak;\r\nif (hw->dev_count > 1) {\r\nint p = HW_TO_DEV_PORT(status.rx.src_port);\r\ndev = hw->port_info[p].pdev;\r\nif (!netif_running(dev))\r\ngoto release_packet;\r\n}\r\nif (status.rx.last_desc && status.rx.first_desc) {\r\nif (!status.rx.error || (status.data &\r\nKS_DESC_RX_ERROR_COND) ==\r\nKS_DESC_RX_ERROR_TOO_LONG) {\r\nif (rx_proc(dev, hw, desc, status))\r\ngoto release_packet;\r\nreceived++;\r\n} else {\r\nstruct dev_priv *priv = netdev_priv(dev);\r\npriv->port.counter[OID_COUNTER_RCV_ERROR]++;\r\n}\r\n}\r\nrelease_packet:\r\nrelease_desc(desc);\r\nnext++;\r\nnext &= info->mask;\r\n}\r\ninfo->next = next;\r\nreturn received;\r\n}\r\nstatic void rx_proc_task(unsigned long data)\r\n{\r\nstruct dev_info *hw_priv = (struct dev_info *) data;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nif (!hw->enabled)\r\nreturn;\r\nif (unlikely(!hw_priv->dev_rcv(hw_priv))) {\r\nhw_resume_rx(hw);\r\nspin_lock_irq(&hw_priv->hwlock);\r\nhw_turn_on_intr(hw, KS884X_INT_RX_MASK);\r\nspin_unlock_irq(&hw_priv->hwlock);\r\n} else {\r\nhw_ack_intr(hw, KS884X_INT_RX);\r\ntasklet_schedule(&hw_priv->rx_tasklet);\r\n}\r\n}\r\nstatic void tx_proc_task(unsigned long data)\r\n{\r\nstruct dev_info *hw_priv = (struct dev_info *) data;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nhw_ack_intr(hw, KS884X_INT_TX_MASK);\r\ntx_done(hw_priv);\r\nspin_lock_irq(&hw_priv->hwlock);\r\nhw_turn_on_intr(hw, KS884X_INT_TX);\r\nspin_unlock_irq(&hw_priv->hwlock);\r\n}\r\nstatic inline void handle_rx_stop(struct ksz_hw *hw)\r\n{\r\nif (0 == hw->rx_stop)\r\nhw->intr_mask &= ~KS884X_INT_RX_STOPPED;\r\nelse if (hw->rx_stop > 1) {\r\nif (hw->enabled && (hw->rx_cfg & DMA_RX_ENABLE)) {\r\nhw_start_rx(hw);\r\n} else {\r\nhw->intr_mask &= ~KS884X_INT_RX_STOPPED;\r\nhw->rx_stop = 0;\r\n}\r\n} else\r\nhw->rx_stop++;\r\n}\r\nstatic irqreturn_t netdev_intr(int irq, void *dev_id)\r\n{\r\nuint int_enable = 0;\r\nstruct net_device *dev = (struct net_device *) dev_id;\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nspin_lock(&hw_priv->hwlock);\r\nhw_read_intr(hw, &int_enable);\r\nif (!int_enable) {\r\nspin_unlock(&hw_priv->hwlock);\r\nreturn IRQ_NONE;\r\n}\r\ndo {\r\nhw_ack_intr(hw, int_enable);\r\nint_enable &= hw->intr_mask;\r\nif (unlikely(int_enable & KS884X_INT_TX_MASK)) {\r\nhw_dis_intr_bit(hw, KS884X_INT_TX_MASK);\r\ntasklet_schedule(&hw_priv->tx_tasklet);\r\n}\r\nif (likely(int_enable & KS884X_INT_RX)) {\r\nhw_dis_intr_bit(hw, KS884X_INT_RX);\r\ntasklet_schedule(&hw_priv->rx_tasklet);\r\n}\r\nif (unlikely(int_enable & KS884X_INT_RX_OVERRUN)) {\r\ndev->stats.rx_fifo_errors++;\r\nhw_resume_rx(hw);\r\n}\r\nif (unlikely(int_enable & KS884X_INT_PHY)) {\r\nstruct ksz_port *port = &priv->port;\r\nhw->features |= LINK_INT_WORKING;\r\nport_get_link_speed(port);\r\n}\r\nif (unlikely(int_enable & KS884X_INT_RX_STOPPED)) {\r\nhandle_rx_stop(hw);\r\nbreak;\r\n}\r\nif (unlikely(int_enable & KS884X_INT_TX_STOPPED)) {\r\nu32 data;\r\nhw->intr_mask &= ~KS884X_INT_TX_STOPPED;\r\npr_info("Tx stopped\n");\r\ndata = readl(hw->io + KS_DMA_TX_CTRL);\r\nif (!(data & DMA_TX_ENABLE))\r\npr_info("Tx disabled\n");\r\nbreak;\r\n}\r\n} while (0);\r\nhw_ena_intr(hw);\r\nspin_unlock(&hw_priv->hwlock);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void netdev_netpoll(struct net_device *dev)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nhw_dis_intr(&hw_priv->hw);\r\nnetdev_intr(dev->irq, dev);\r\n}\r\nstatic void bridge_change(struct ksz_hw *hw)\r\n{\r\nint port;\r\nu8 member;\r\nstruct ksz_switch *sw = hw->ksz_switch;\r\nif (!sw->member) {\r\nport_set_stp_state(hw, SWITCH_PORT_NUM, STP_STATE_SIMPLE);\r\nsw_block_addr(hw);\r\n}\r\nfor (port = 0; port < SWITCH_PORT_NUM; port++) {\r\nif (STP_STATE_FORWARDING == sw->port_cfg[port].stp_state)\r\nmember = HOST_MASK | sw->member;\r\nelse\r\nmember = HOST_MASK | (1 << port);\r\nif (member != sw->port_cfg[port].member)\r\nsw_cfg_port_base_vlan(hw, port, member);\r\n}\r\n}\r\nstatic int netdev_close(struct net_device *dev)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_port *port = &priv->port;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nint pi;\r\nnetif_stop_queue(dev);\r\nksz_stop_timer(&priv->monitor_timer_info);\r\nif (hw->dev_count > 1) {\r\nport_set_stp_state(hw, port->first_port, STP_STATE_DISABLED);\r\nif (hw->features & STP_SUPPORT) {\r\npi = 1 << port->first_port;\r\nif (hw->ksz_switch->member & pi) {\r\nhw->ksz_switch->member &= ~pi;\r\nbridge_change(hw);\r\n}\r\n}\r\n}\r\nif (port->first_port > 0)\r\nhw_del_addr(hw, dev->dev_addr);\r\nif (!hw_priv->wol_enable)\r\nport_set_power_saving(port, true);\r\nif (priv->multicast)\r\n--hw->all_multi;\r\nif (priv->promiscuous)\r\n--hw->promiscuous;\r\nhw_priv->opened--;\r\nif (!(hw_priv->opened)) {\r\nksz_stop_timer(&hw_priv->mib_timer_info);\r\nflush_work(&hw_priv->mib_read);\r\nhw_dis_intr(hw);\r\nhw_disable(hw);\r\nhw_clr_multicast(hw);\r\nmsleep(2000 / HZ);\r\ntasklet_kill(&hw_priv->rx_tasklet);\r\ntasklet_kill(&hw_priv->tx_tasklet);\r\nfree_irq(dev->irq, hw_priv->dev);\r\ntransmit_cleanup(hw_priv, 0);\r\nhw_reset_pkts(&hw->rx_desc_info);\r\nhw_reset_pkts(&hw->tx_desc_info);\r\nif (hw->features & STP_SUPPORT)\r\nsw_clr_sta_mac_table(hw);\r\n}\r\nreturn 0;\r\n}\r\nstatic void hw_cfg_huge_frame(struct dev_info *hw_priv, struct ksz_hw *hw)\r\n{\r\nif (hw->ksz_switch) {\r\nu32 data;\r\ndata = readw(hw->io + KS8842_SWITCH_CTRL_2_OFFSET);\r\nif (hw->features & RX_HUGE_FRAME)\r\ndata |= SWITCH_HUGE_PACKET;\r\nelse\r\ndata &= ~SWITCH_HUGE_PACKET;\r\nwritew(data, hw->io + KS8842_SWITCH_CTRL_2_OFFSET);\r\n}\r\nif (hw->features & RX_HUGE_FRAME) {\r\nhw->rx_cfg |= DMA_RX_ERROR;\r\nhw_priv->dev_rcv = dev_rcv_special;\r\n} else {\r\nhw->rx_cfg &= ~DMA_RX_ERROR;\r\nif (hw->dev_count > 1)\r\nhw_priv->dev_rcv = port_rcv_packets;\r\nelse\r\nhw_priv->dev_rcv = dev_rcv_packets;\r\n}\r\n}\r\nstatic int prepare_hardware(struct net_device *dev)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nint rc = 0;\r\nhw_priv->dev = dev;\r\nrc = request_irq(dev->irq, netdev_intr, IRQF_SHARED, dev->name, dev);\r\nif (rc)\r\nreturn rc;\r\ntasklet_init(&hw_priv->rx_tasklet, rx_proc_task,\r\n(unsigned long) hw_priv);\r\ntasklet_init(&hw_priv->tx_tasklet, tx_proc_task,\r\n(unsigned long) hw_priv);\r\nhw->promiscuous = 0;\r\nhw->all_multi = 0;\r\nhw->multi_list_size = 0;\r\nhw_reset(hw);\r\nhw_set_desc_base(hw,\r\nhw->tx_desc_info.ring_phys, hw->rx_desc_info.ring_phys);\r\nhw_set_addr(hw);\r\nhw_cfg_huge_frame(hw_priv, hw);\r\nksz_init_rx_buffers(hw_priv);\r\nreturn 0;\r\n}\r\nstatic void set_media_state(struct net_device *dev, int media_state)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nif (media_state == priv->media_state)\r\nnetif_carrier_on(dev);\r\nelse\r\nnetif_carrier_off(dev);\r\nnetif_info(priv, link, dev, "link %s\n",\r\nmedia_state == priv->media_state ? "on" : "off");\r\n}\r\nstatic int netdev_open(struct net_device *dev)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nstruct ksz_port *port = &priv->port;\r\nint i;\r\nint p;\r\nint rc = 0;\r\npriv->multicast = 0;\r\npriv->promiscuous = 0;\r\nmemset(&dev->stats, 0, sizeof(struct net_device_stats));\r\nmemset((void *) port->counter, 0,\r\n(sizeof(u64) * OID_COUNTER_LAST));\r\nif (!(hw_priv->opened)) {\r\nrc = prepare_hardware(dev);\r\nif (rc)\r\nreturn rc;\r\nfor (i = 0; i < hw->mib_port_cnt; i++) {\r\nif (next_jiffies < jiffies)\r\nnext_jiffies = jiffies + HZ * 2;\r\nelse\r\nnext_jiffies += HZ * 1;\r\nhw_priv->counter[i].time = next_jiffies;\r\nhw->port_mib[i].state = media_disconnected;\r\nport_init_cnt(hw, i);\r\n}\r\nif (hw->ksz_switch)\r\nhw->port_mib[HOST_PORT].state = media_connected;\r\nelse {\r\nhw_add_wol_bcast(hw);\r\nhw_cfg_wol_pme(hw, 0);\r\nhw_clr_wol_pme_status(&hw_priv->hw);\r\n}\r\n}\r\nport_set_power_saving(port, false);\r\nfor (i = 0, p = port->first_port; i < port->port_cnt; i++, p++) {\r\nhw->port_info[p].partner = 0xFF;\r\nhw->port_info[p].state = media_disconnected;\r\n}\r\nif (hw->dev_count > 1) {\r\nport_set_stp_state(hw, port->first_port, STP_STATE_SIMPLE);\r\nif (port->first_port > 0)\r\nhw_add_addr(hw, dev->dev_addr);\r\n}\r\nport_get_link_speed(port);\r\nif (port->force_link)\r\nport_force_link_speed(port);\r\nelse\r\nport_set_link_speed(port);\r\nif (!(hw_priv->opened)) {\r\nhw_setup_intr(hw);\r\nhw_enable(hw);\r\nhw_ena_intr(hw);\r\nif (hw->mib_port_cnt)\r\nksz_start_timer(&hw_priv->mib_timer_info,\r\nhw_priv->mib_timer_info.period);\r\n}\r\nhw_priv->opened++;\r\nksz_start_timer(&priv->monitor_timer_info,\r\npriv->monitor_timer_info.period);\r\npriv->media_state = port->linked->state;\r\nset_media_state(dev, media_connected);\r\nnetif_start_queue(dev);\r\nreturn 0;\r\n}\r\nstatic struct net_device_stats *netdev_query_statistics(struct net_device *dev)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct ksz_port *port = &priv->port;\r\nstruct ksz_hw *hw = &priv->adapter->hw;\r\nstruct ksz_port_mib *mib;\r\nint i;\r\nint p;\r\ndev->stats.rx_errors = port->counter[OID_COUNTER_RCV_ERROR];\r\ndev->stats.tx_errors = port->counter[OID_COUNTER_XMIT_ERROR];\r\ndev->stats.multicast = 0;\r\ndev->stats.collisions = 0;\r\ndev->stats.rx_length_errors = 0;\r\ndev->stats.rx_crc_errors = 0;\r\ndev->stats.rx_frame_errors = 0;\r\ndev->stats.tx_window_errors = 0;\r\nfor (i = 0, p = port->first_port; i < port->mib_port_cnt; i++, p++) {\r\nmib = &hw->port_mib[p];\r\ndev->stats.multicast += (unsigned long)\r\nmib->counter[MIB_COUNTER_RX_MULTICAST];\r\ndev->stats.collisions += (unsigned long)\r\nmib->counter[MIB_COUNTER_TX_TOTAL_COLLISION];\r\ndev->stats.rx_length_errors += (unsigned long)(\r\nmib->counter[MIB_COUNTER_RX_UNDERSIZE] +\r\nmib->counter[MIB_COUNTER_RX_FRAGMENT] +\r\nmib->counter[MIB_COUNTER_RX_OVERSIZE] +\r\nmib->counter[MIB_COUNTER_RX_JABBER]);\r\ndev->stats.rx_crc_errors += (unsigned long)\r\nmib->counter[MIB_COUNTER_RX_CRC_ERR];\r\ndev->stats.rx_frame_errors += (unsigned long)(\r\nmib->counter[MIB_COUNTER_RX_ALIGNMENT_ERR] +\r\nmib->counter[MIB_COUNTER_RX_SYMBOL_ERR]);\r\ndev->stats.tx_window_errors += (unsigned long)\r\nmib->counter[MIB_COUNTER_TX_LATE_COLLISION];\r\n}\r\nreturn &dev->stats;\r\n}\r\nstatic int netdev_set_mac_address(struct net_device *dev, void *addr)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nstruct sockaddr *mac = addr;\r\nuint interrupt;\r\nif (priv->port.first_port > 0)\r\nhw_del_addr(hw, dev->dev_addr);\r\nelse {\r\nhw->mac_override = 1;\r\nmemcpy(hw->override_addr, mac->sa_data, ETH_ALEN);\r\n}\r\nmemcpy(dev->dev_addr, mac->sa_data, ETH_ALEN);\r\ninterrupt = hw_block_intr(hw);\r\nif (priv->port.first_port > 0)\r\nhw_add_addr(hw, dev->dev_addr);\r\nelse\r\nhw_set_addr(hw);\r\nhw_restore_intr(hw, interrupt);\r\nreturn 0;\r\n}\r\nstatic void dev_set_promiscuous(struct net_device *dev, struct dev_priv *priv,\r\nstruct ksz_hw *hw, int promiscuous)\r\n{\r\nif (promiscuous != priv->promiscuous) {\r\nu8 prev_state = hw->promiscuous;\r\nif (promiscuous)\r\n++hw->promiscuous;\r\nelse\r\n--hw->promiscuous;\r\npriv->promiscuous = promiscuous;\r\nif (hw->promiscuous <= 1 && prev_state <= 1)\r\nhw_set_promiscuous(hw, hw->promiscuous);\r\nif ((hw->features & STP_SUPPORT) && !promiscuous &&\r\n(dev->priv_flags & IFF_BRIDGE_PORT)) {\r\nstruct ksz_switch *sw = hw->ksz_switch;\r\nint port = priv->port.first_port;\r\nport_set_stp_state(hw, port, STP_STATE_DISABLED);\r\nport = 1 << port;\r\nif (sw->member & port) {\r\nsw->member &= ~port;\r\nbridge_change(hw);\r\n}\r\n}\r\n}\r\n}\r\nstatic void dev_set_multicast(struct dev_priv *priv, struct ksz_hw *hw,\r\nint multicast)\r\n{\r\nif (multicast != priv->multicast) {\r\nu8 all_multi = hw->all_multi;\r\nif (multicast)\r\n++hw->all_multi;\r\nelse\r\n--hw->all_multi;\r\npriv->multicast = multicast;\r\nif (hw->all_multi <= 1 && all_multi <= 1)\r\nhw_set_multicast(hw, hw->all_multi);\r\n}\r\n}\r\nstatic void netdev_set_rx_mode(struct net_device *dev)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nstruct netdev_hw_addr *ha;\r\nint multicast = (dev->flags & IFF_ALLMULTI);\r\ndev_set_promiscuous(dev, priv, hw, (dev->flags & IFF_PROMISC));\r\nif (hw_priv->hw.dev_count > 1)\r\nmulticast |= (dev->flags & IFF_MULTICAST);\r\ndev_set_multicast(priv, hw, multicast);\r\nif (hw_priv->hw.dev_count > 1)\r\nreturn;\r\nif ((dev->flags & IFF_MULTICAST) && !netdev_mc_empty(dev)) {\r\nint i = 0;\r\nif (netdev_mc_count(dev) > MAX_MULTICAST_LIST) {\r\nif (MAX_MULTICAST_LIST != hw->multi_list_size) {\r\nhw->multi_list_size = MAX_MULTICAST_LIST;\r\n++hw->all_multi;\r\nhw_set_multicast(hw, hw->all_multi);\r\n}\r\nreturn;\r\n}\r\nnetdev_for_each_mc_addr(ha, dev) {\r\nif (i >= MAX_MULTICAST_LIST)\r\nbreak;\r\nmemcpy(hw->multi_list[i++], ha->addr, ETH_ALEN);\r\n}\r\nhw->multi_list_size = (u8) i;\r\nhw_set_grp_addr(hw);\r\n} else {\r\nif (MAX_MULTICAST_LIST == hw->multi_list_size) {\r\n--hw->all_multi;\r\nhw_set_multicast(hw, hw->all_multi);\r\n}\r\nhw->multi_list_size = 0;\r\nhw_clr_multicast(hw);\r\n}\r\n}\r\nstatic int netdev_change_mtu(struct net_device *dev, int new_mtu)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nint hw_mtu;\r\nif (netif_running(dev))\r\nreturn -EBUSY;\r\nif (hw->dev_count > 1)\r\nif (dev != hw_priv->dev)\r\nreturn 0;\r\nif (new_mtu < 60)\r\nreturn -EINVAL;\r\nif (dev->mtu != new_mtu) {\r\nhw_mtu = new_mtu + ETHERNET_HEADER_SIZE + 4;\r\nif (hw_mtu > MAX_RX_BUF_SIZE)\r\nreturn -EINVAL;\r\nif (hw_mtu > REGULAR_RX_BUF_SIZE) {\r\nhw->features |= RX_HUGE_FRAME;\r\nhw_mtu = MAX_RX_BUF_SIZE;\r\n} else {\r\nhw->features &= ~RX_HUGE_FRAME;\r\nhw_mtu = REGULAR_RX_BUF_SIZE;\r\n}\r\nhw_mtu = (hw_mtu + 3) & ~3;\r\nhw_priv->mtu = hw_mtu;\r\ndev->mtu = new_mtu;\r\n}\r\nreturn 0;\r\n}\r\nstatic int netdev_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nstruct ksz_port *port = &priv->port;\r\nint result = 0;\r\nstruct mii_ioctl_data *data = if_mii(ifr);\r\nif (down_interruptible(&priv->proc_sem))\r\nreturn -ERESTARTSYS;\r\nswitch (cmd) {\r\ncase SIOCGMIIPHY:\r\ndata->phy_id = priv->id;\r\ncase SIOCGMIIREG:\r\nif (data->phy_id != priv->id || data->reg_num >= 6)\r\nresult = -EIO;\r\nelse\r\nhw_r_phy(hw, port->linked->port_id, data->reg_num,\r\n&data->val_out);\r\nbreak;\r\ncase SIOCSMIIREG:\r\nif (!capable(CAP_NET_ADMIN))\r\nresult = -EPERM;\r\nelse if (data->phy_id != priv->id || data->reg_num >= 6)\r\nresult = -EIO;\r\nelse\r\nhw_w_phy(hw, port->linked->port_id, data->reg_num,\r\ndata->val_in);\r\nbreak;\r\ndefault:\r\nresult = -EOPNOTSUPP;\r\n}\r\nup(&priv->proc_sem);\r\nreturn result;\r\n}\r\nstatic int mdio_read(struct net_device *dev, int phy_id, int reg_num)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct ksz_port *port = &priv->port;\r\nstruct ksz_hw *hw = port->hw;\r\nu16 val_out;\r\nhw_r_phy(hw, port->linked->port_id, reg_num << 1, &val_out);\r\nreturn val_out;\r\n}\r\nstatic void mdio_write(struct net_device *dev, int phy_id, int reg_num, int val)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct ksz_port *port = &priv->port;\r\nstruct ksz_hw *hw = port->hw;\r\nint i;\r\nint pi;\r\nfor (i = 0, pi = port->first_port; i < port->port_cnt; i++, pi++)\r\nhw_w_phy(hw, pi, reg_num << 1, val);\r\n}\r\nstatic int netdev_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nmutex_lock(&hw_priv->lock);\r\nmii_ethtool_gset(&priv->mii_if, cmd);\r\ncmd->advertising |= SUPPORTED_TP;\r\nmutex_unlock(&hw_priv->lock);\r\npriv->advertising = cmd->advertising;\r\nreturn 0;\r\n}\r\nstatic int netdev_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_port *port = &priv->port;\r\nu32 speed = ethtool_cmd_speed(cmd);\r\nint rc;\r\nif (cmd->autoneg && priv->advertising == cmd->advertising) {\r\ncmd->advertising |= ADVERTISED_ALL;\r\nif (10 == speed)\r\ncmd->advertising &=\r\n~(ADVERTISED_100baseT_Full |\r\nADVERTISED_100baseT_Half);\r\nelse if (100 == speed)\r\ncmd->advertising &=\r\n~(ADVERTISED_10baseT_Full |\r\nADVERTISED_10baseT_Half);\r\nif (0 == cmd->duplex)\r\ncmd->advertising &=\r\n~(ADVERTISED_100baseT_Full |\r\nADVERTISED_10baseT_Full);\r\nelse if (1 == cmd->duplex)\r\ncmd->advertising &=\r\n~(ADVERTISED_100baseT_Half |\r\nADVERTISED_10baseT_Half);\r\n}\r\nmutex_lock(&hw_priv->lock);\r\nif (cmd->autoneg &&\r\n(cmd->advertising & ADVERTISED_ALL) ==\r\nADVERTISED_ALL) {\r\nport->duplex = 0;\r\nport->speed = 0;\r\nport->force_link = 0;\r\n} else {\r\nport->duplex = cmd->duplex + 1;\r\nif (1000 != speed)\r\nport->speed = speed;\r\nif (cmd->autoneg)\r\nport->force_link = 0;\r\nelse\r\nport->force_link = 1;\r\n}\r\nrc = mii_ethtool_sset(&priv->mii_if, cmd);\r\nmutex_unlock(&hw_priv->lock);\r\nreturn rc;\r\n}\r\nstatic int netdev_nway_reset(struct net_device *dev)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nint rc;\r\nmutex_lock(&hw_priv->lock);\r\nrc = mii_nway_restart(&priv->mii_if);\r\nmutex_unlock(&hw_priv->lock);\r\nreturn rc;\r\n}\r\nstatic u32 netdev_get_link(struct net_device *dev)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nint rc;\r\nrc = mii_link_ok(&priv->mii_if);\r\nreturn rc;\r\n}\r\nstatic void netdev_get_drvinfo(struct net_device *dev,\r\nstruct ethtool_drvinfo *info)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstrlcpy(info->driver, DRV_NAME, sizeof(info->driver));\r\nstrlcpy(info->version, DRV_VERSION, sizeof(info->version));\r\nstrlcpy(info->bus_info, pci_name(hw_priv->pdev),\r\nsizeof(info->bus_info));\r\n}\r\nstatic int netdev_get_regs_len(struct net_device *dev)\r\n{\r\nstruct hw_regs *range = hw_regs_range;\r\nint regs_len = 0x10 * sizeof(u32);\r\nwhile (range->end > range->start) {\r\nregs_len += (range->end - range->start + 3) / 4 * 4;\r\nrange++;\r\n}\r\nreturn regs_len;\r\n}\r\nstatic void netdev_get_regs(struct net_device *dev, struct ethtool_regs *regs,\r\nvoid *ptr)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nint *buf = (int *) ptr;\r\nstruct hw_regs *range = hw_regs_range;\r\nint len;\r\nmutex_lock(&hw_priv->lock);\r\nregs->version = 0;\r\nfor (len = 0; len < 0x40; len += 4) {\r\npci_read_config_dword(hw_priv->pdev, len, buf);\r\nbuf++;\r\n}\r\nwhile (range->end > range->start) {\r\nfor (len = range->start; len < range->end; len += 4) {\r\n*buf = readl(hw->io + len);\r\nbuf++;\r\n}\r\nrange++;\r\n}\r\nmutex_unlock(&hw_priv->lock);\r\n}\r\nstatic void netdev_get_wol(struct net_device *dev,\r\nstruct ethtool_wolinfo *wol)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nwol->supported = hw_priv->wol_support;\r\nwol->wolopts = hw_priv->wol_enable;\r\nmemset(&wol->sopass, 0, sizeof(wol->sopass));\r\n}\r\nstatic int netdev_set_wol(struct net_device *dev,\r\nstruct ethtool_wolinfo *wol)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstatic const u8 net_addr[] = { 192, 168, 1, 1 };\r\nif (wol->wolopts & ~hw_priv->wol_support)\r\nreturn -EINVAL;\r\nhw_priv->wol_enable = wol->wolopts;\r\nif (wol->wolopts)\r\nhw_priv->wol_enable |= WAKE_PHY;\r\nhw_enable_wol(&hw_priv->hw, hw_priv->wol_enable, net_addr);\r\nreturn 0;\r\n}\r\nstatic u32 netdev_get_msglevel(struct net_device *dev)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nreturn priv->msg_enable;\r\n}\r\nstatic void netdev_set_msglevel(struct net_device *dev, u32 value)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\npriv->msg_enable = value;\r\n}\r\nstatic int netdev_get_eeprom_len(struct net_device *dev)\r\n{\r\nreturn EEPROM_SIZE * 2;\r\n}\r\nstatic int netdev_get_eeprom(struct net_device *dev,\r\nstruct ethtool_eeprom *eeprom, u8 *data)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nu8 *eeprom_byte = (u8 *) eeprom_data;\r\nint i;\r\nint len;\r\nlen = (eeprom->offset + eeprom->len + 1) / 2;\r\nfor (i = eeprom->offset / 2; i < len; i++)\r\neeprom_data[i] = eeprom_read(&hw_priv->hw, i);\r\neeprom->magic = EEPROM_MAGIC;\r\nmemcpy(data, &eeprom_byte[eeprom->offset], eeprom->len);\r\nreturn 0;\r\n}\r\nstatic int netdev_set_eeprom(struct net_device *dev,\r\nstruct ethtool_eeprom *eeprom, u8 *data)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nu16 eeprom_word[EEPROM_SIZE];\r\nu8 *eeprom_byte = (u8 *) eeprom_word;\r\nint i;\r\nint len;\r\nif (eeprom->magic != EEPROM_MAGIC)\r\nreturn -EINVAL;\r\nlen = (eeprom->offset + eeprom->len + 1) / 2;\r\nfor (i = eeprom->offset / 2; i < len; i++)\r\neeprom_data[i] = eeprom_read(&hw_priv->hw, i);\r\nmemcpy(eeprom_word, eeprom_data, EEPROM_SIZE * 2);\r\nmemcpy(&eeprom_byte[eeprom->offset], data, eeprom->len);\r\nfor (i = 0; i < EEPROM_SIZE; i++)\r\nif (eeprom_word[i] != eeprom_data[i]) {\r\neeprom_data[i] = eeprom_word[i];\r\neeprom_write(&hw_priv->hw, i, eeprom_data[i]);\r\n}\r\nreturn 0;\r\n}\r\nstatic void netdev_get_pauseparam(struct net_device *dev,\r\nstruct ethtool_pauseparam *pause)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\npause->autoneg = (hw->overrides & PAUSE_FLOW_CTRL) ? 0 : 1;\r\nif (!hw->ksz_switch) {\r\npause->rx_pause =\r\n(hw->rx_cfg & DMA_RX_FLOW_ENABLE) ? 1 : 0;\r\npause->tx_pause =\r\n(hw->tx_cfg & DMA_TX_FLOW_ENABLE) ? 1 : 0;\r\n} else {\r\npause->rx_pause =\r\n(sw_chk(hw, KS8842_SWITCH_CTRL_1_OFFSET,\r\nSWITCH_RX_FLOW_CTRL)) ? 1 : 0;\r\npause->tx_pause =\r\n(sw_chk(hw, KS8842_SWITCH_CTRL_1_OFFSET,\r\nSWITCH_TX_FLOW_CTRL)) ? 1 : 0;\r\n}\r\n}\r\nstatic int netdev_set_pauseparam(struct net_device *dev,\r\nstruct ethtool_pauseparam *pause)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nstruct ksz_port *port = &priv->port;\r\nmutex_lock(&hw_priv->lock);\r\nif (pause->autoneg) {\r\nif (!pause->rx_pause && !pause->tx_pause)\r\nport->flow_ctrl = PHY_NO_FLOW_CTRL;\r\nelse\r\nport->flow_ctrl = PHY_FLOW_CTRL;\r\nhw->overrides &= ~PAUSE_FLOW_CTRL;\r\nport->force_link = 0;\r\nif (hw->ksz_switch) {\r\nsw_cfg(hw, KS8842_SWITCH_CTRL_1_OFFSET,\r\nSWITCH_RX_FLOW_CTRL, 1);\r\nsw_cfg(hw, KS8842_SWITCH_CTRL_1_OFFSET,\r\nSWITCH_TX_FLOW_CTRL, 1);\r\n}\r\nport_set_link_speed(port);\r\n} else {\r\nhw->overrides |= PAUSE_FLOW_CTRL;\r\nif (hw->ksz_switch) {\r\nsw_cfg(hw, KS8842_SWITCH_CTRL_1_OFFSET,\r\nSWITCH_RX_FLOW_CTRL, pause->rx_pause);\r\nsw_cfg(hw, KS8842_SWITCH_CTRL_1_OFFSET,\r\nSWITCH_TX_FLOW_CTRL, pause->tx_pause);\r\n} else\r\nset_flow_ctrl(hw, pause->rx_pause, pause->tx_pause);\r\n}\r\nmutex_unlock(&hw_priv->lock);\r\nreturn 0;\r\n}\r\nstatic void netdev_get_ringparam(struct net_device *dev,\r\nstruct ethtool_ringparam *ring)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nring->tx_max_pending = (1 << 9);\r\nring->tx_pending = hw->tx_desc_info.alloc;\r\nring->rx_max_pending = (1 << 9);\r\nring->rx_pending = hw->rx_desc_info.alloc;\r\n}\r\nstatic void netdev_get_strings(struct net_device *dev, u32 stringset, u8 *buf)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nif (ETH_SS_STATS == stringset)\r\nmemcpy(buf, &ethtool_stats_keys,\r\nETH_GSTRING_LEN * hw->mib_cnt);\r\n}\r\nstatic int netdev_get_sset_count(struct net_device *dev, int sset)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nswitch (sset) {\r\ncase ETH_SS_STATS:\r\nreturn hw->mib_cnt;\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nstatic void netdev_get_ethtool_stats(struct net_device *dev,\r\nstruct ethtool_stats *stats, u64 *data)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nstruct ksz_port *port = &priv->port;\r\nint n_stats = stats->n_stats;\r\nint i;\r\nint n;\r\nint p;\r\nint rc;\r\nu64 counter[TOTAL_PORT_COUNTER_NUM];\r\nmutex_lock(&hw_priv->lock);\r\nn = SWITCH_PORT_NUM;\r\nfor (i = 0, p = port->first_port; i < port->mib_port_cnt; i++, p++) {\r\nif (media_connected == hw->port_mib[p].state) {\r\nhw_priv->counter[p].read = 1;\r\nif (n == SWITCH_PORT_NUM)\r\nn = p;\r\n}\r\n}\r\nmutex_unlock(&hw_priv->lock);\r\nif (n < SWITCH_PORT_NUM)\r\nschedule_work(&hw_priv->mib_read);\r\nif (1 == port->mib_port_cnt && n < SWITCH_PORT_NUM) {\r\np = n;\r\nrc = wait_event_interruptible_timeout(\r\nhw_priv->counter[p].counter,\r\n2 == hw_priv->counter[p].read,\r\nHZ * 1);\r\n} else\r\nfor (i = 0, p = n; i < port->mib_port_cnt - n; i++, p++) {\r\nif (0 == i) {\r\nrc = wait_event_interruptible_timeout(\r\nhw_priv->counter[p].counter,\r\n2 == hw_priv->counter[p].read,\r\nHZ * 2);\r\n} else if (hw->port_mib[p].cnt_ptr) {\r\nrc = wait_event_interruptible_timeout(\r\nhw_priv->counter[p].counter,\r\n2 == hw_priv->counter[p].read,\r\nHZ * 1);\r\n}\r\n}\r\nget_mib_counters(hw, port->first_port, port->mib_port_cnt, counter);\r\nn = hw->mib_cnt;\r\nif (n > n_stats)\r\nn = n_stats;\r\nn_stats -= n;\r\nfor (i = 0; i < n; i++)\r\n*data++ = counter[i];\r\n}\r\nstatic int netdev_set_features(struct net_device *dev,\r\nnetdev_features_t features)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nmutex_lock(&hw_priv->lock);\r\nif (features & NETIF_F_RXCSUM)\r\nhw->rx_cfg |= DMA_RX_CSUM_TCP | DMA_RX_CSUM_IP;\r\nelse\r\nhw->rx_cfg &= ~(DMA_RX_CSUM_TCP | DMA_RX_CSUM_IP);\r\nif (hw->enabled)\r\nwritel(hw->rx_cfg, hw->io + KS_DMA_RX_CTRL);\r\nmutex_unlock(&hw_priv->lock);\r\nreturn 0;\r\n}\r\nstatic void update_link(struct net_device *dev, struct dev_priv *priv,\r\nstruct ksz_port *port)\r\n{\r\nif (priv->media_state != port->linked->state) {\r\npriv->media_state = port->linked->state;\r\nif (netif_running(dev))\r\nset_media_state(dev, media_connected);\r\n}\r\n}\r\nstatic void mib_read_work(struct work_struct *work)\r\n{\r\nstruct dev_info *hw_priv =\r\ncontainer_of(work, struct dev_info, mib_read);\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nstruct ksz_port_mib *mib;\r\nint i;\r\nnext_jiffies = jiffies;\r\nfor (i = 0; i < hw->mib_port_cnt; i++) {\r\nmib = &hw->port_mib[i];\r\nif (mib->cnt_ptr || 1 == hw_priv->counter[i].read) {\r\nif (port_r_cnt(hw, i))\r\nbreak;\r\nhw_priv->counter[i].read = 0;\r\nif (0 == mib->cnt_ptr) {\r\nhw_priv->counter[i].read = 2;\r\nwake_up_interruptible(\r\n&hw_priv->counter[i].counter);\r\n}\r\n} else if (time_after_eq(jiffies, hw_priv->counter[i].time)) {\r\nif (media_connected == mib->state)\r\nhw_priv->counter[i].read = 1;\r\nnext_jiffies += HZ * 1 * hw->mib_port_cnt;\r\nhw_priv->counter[i].time = next_jiffies;\r\n} else if (mib->link_down) {\r\nmib->link_down = 0;\r\nhw_priv->counter[i].read = 1;\r\n}\r\n}\r\n}\r\nstatic void mib_monitor(unsigned long ptr)\r\n{\r\nstruct dev_info *hw_priv = (struct dev_info *) ptr;\r\nmib_read_work(&hw_priv->mib_read);\r\nif (hw_priv->pme_wait) {\r\nif (time_is_before_eq_jiffies(hw_priv->pme_wait)) {\r\nhw_clr_wol_pme_status(&hw_priv->hw);\r\nhw_priv->pme_wait = 0;\r\n}\r\n} else if (hw_chk_wol_pme_status(&hw_priv->hw)) {\r\nhw_priv->pme_wait = jiffies + HZ * 2;\r\n}\r\nksz_update_timer(&hw_priv->mib_timer_info);\r\n}\r\nstatic void dev_monitor(unsigned long ptr)\r\n{\r\nstruct net_device *dev = (struct net_device *) ptr;\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nstruct dev_info *hw_priv = priv->adapter;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nstruct ksz_port *port = &priv->port;\r\nif (!(hw->features & LINK_INT_WORKING))\r\nport_get_link_speed(port);\r\nupdate_link(dev, priv, port);\r\nksz_update_timer(&priv->monitor_timer_info);\r\n}\r\nstatic int __init netdev_init(struct net_device *dev)\r\n{\r\nstruct dev_priv *priv = netdev_priv(dev);\r\nksz_init_timer(&priv->monitor_timer_info, 500 * HZ / 1000,\r\ndev_monitor, dev);\r\ndev->watchdog_timeo = HZ / 2;\r\ndev->hw_features = NETIF_F_IP_CSUM | NETIF_F_SG | NETIF_F_RXCSUM;\r\ndev->hw_features |= NETIF_F_IPV6_CSUM;\r\ndev->features |= dev->hw_features;\r\nsema_init(&priv->proc_sem, 1);\r\npriv->mii_if.phy_id_mask = 0x1;\r\npriv->mii_if.reg_num_mask = 0x7;\r\npriv->mii_if.dev = dev;\r\npriv->mii_if.mdio_read = mdio_read;\r\npriv->mii_if.mdio_write = mdio_write;\r\npriv->mii_if.phy_id = priv->port.first_port + 1;\r\npriv->msg_enable = netif_msg_init(msg_enable,\r\n(NETIF_MSG_DRV | NETIF_MSG_PROBE | NETIF_MSG_LINK));\r\nreturn 0;\r\n}\r\nstatic void netdev_free(struct net_device *dev)\r\n{\r\nif (dev->watchdog_timeo)\r\nunregister_netdev(dev);\r\nfree_netdev(dev);\r\n}\r\nstatic void get_mac_addr(struct dev_info *hw_priv, u8 *macaddr, int port)\r\n{\r\nint i;\r\nint j;\r\nint got_num;\r\nint num;\r\ni = j = num = got_num = 0;\r\nwhile (j < ETH_ALEN) {\r\nif (macaddr[i]) {\r\nint digit;\r\ngot_num = 1;\r\ndigit = hex_to_bin(macaddr[i]);\r\nif (digit >= 0)\r\nnum = num * 16 + digit;\r\nelse if (':' == macaddr[i])\r\ngot_num = 2;\r\nelse\r\nbreak;\r\n} else if (got_num)\r\ngot_num = 2;\r\nelse\r\nbreak;\r\nif (2 == got_num) {\r\nif (MAIN_PORT == port) {\r\nhw_priv->hw.override_addr[j++] = (u8) num;\r\nhw_priv->hw.override_addr[5] +=\r\nhw_priv->hw.id;\r\n} else {\r\nhw_priv->hw.ksz_switch->other_addr[j++] =\r\n(u8) num;\r\nhw_priv->hw.ksz_switch->other_addr[5] +=\r\nhw_priv->hw.id;\r\n}\r\nnum = got_num = 0;\r\n}\r\ni++;\r\n}\r\nif (ETH_ALEN == j) {\r\nif (MAIN_PORT == port)\r\nhw_priv->hw.mac_override = 1;\r\n}\r\n}\r\nstatic void read_other_addr(struct ksz_hw *hw)\r\n{\r\nint i;\r\nu16 data[3];\r\nstruct ksz_switch *sw = hw->ksz_switch;\r\nfor (i = 0; i < 3; i++)\r\ndata[i] = eeprom_read(hw, i + EEPROM_DATA_OTHER_MAC_ADDR);\r\nif ((data[0] || data[1] || data[2]) && data[0] != 0xffff) {\r\nsw->other_addr[5] = (u8) data[0];\r\nsw->other_addr[4] = (u8)(data[0] >> 8);\r\nsw->other_addr[3] = (u8) data[1];\r\nsw->other_addr[2] = (u8)(data[1] >> 8);\r\nsw->other_addr[1] = (u8) data[2];\r\nsw->other_addr[0] = (u8)(data[2] >> 8);\r\n}\r\n}\r\nstatic int pcidev_init(struct pci_dev *pdev, const struct pci_device_id *id)\r\n{\r\nstruct net_device *dev;\r\nstruct dev_priv *priv;\r\nstruct dev_info *hw_priv;\r\nstruct ksz_hw *hw;\r\nstruct platform_info *info;\r\nstruct ksz_port *port;\r\nunsigned long reg_base;\r\nunsigned long reg_len;\r\nint cnt;\r\nint i;\r\nint mib_port_count;\r\nint pi;\r\nint port_count;\r\nint result;\r\nchar banner[sizeof(version)];\r\nstruct ksz_switch *sw = NULL;\r\nresult = pci_enable_device(pdev);\r\nif (result)\r\nreturn result;\r\nresult = -ENODEV;\r\nif (pci_set_dma_mask(pdev, DMA_BIT_MASK(32)) ||\r\npci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32)))\r\nreturn result;\r\nreg_base = pci_resource_start(pdev, 0);\r\nreg_len = pci_resource_len(pdev, 0);\r\nif ((pci_resource_flags(pdev, 0) & IORESOURCE_IO) != 0)\r\nreturn result;\r\nif (!request_mem_region(reg_base, reg_len, DRV_NAME))\r\nreturn result;\r\npci_set_master(pdev);\r\nresult = -ENOMEM;\r\ninfo = kzalloc(sizeof(struct platform_info), GFP_KERNEL);\r\nif (!info)\r\ngoto pcidev_init_dev_err;\r\nhw_priv = &info->dev_info;\r\nhw_priv->pdev = pdev;\r\nhw = &hw_priv->hw;\r\nhw->io = ioremap(reg_base, reg_len);\r\nif (!hw->io)\r\ngoto pcidev_init_io_err;\r\ncnt = hw_init(hw);\r\nif (!cnt) {\r\nif (msg_enable & NETIF_MSG_PROBE)\r\npr_alert("chip not detected\n");\r\nresult = -ENODEV;\r\ngoto pcidev_init_alloc_err;\r\n}\r\nsnprintf(banner, sizeof(banner), "%s", version);\r\nbanner[13] = cnt + '0';\r\ndev_info(&hw_priv->pdev->dev, "%s\n", banner);\r\ndev_dbg(&hw_priv->pdev->dev, "Mem = %p; IRQ = %d\n", hw->io, pdev->irq);\r\nhw->dev_count = 1;\r\nport_count = 1;\r\nmib_port_count = 1;\r\nhw->addr_list_size = 0;\r\nhw->mib_cnt = PORT_COUNTER_NUM;\r\nhw->mib_port_cnt = 1;\r\nif (2 == cnt) {\r\nif (fast_aging)\r\nhw->overrides |= FAST_AGING;\r\nhw->mib_cnt = TOTAL_PORT_COUNTER_NUM;\r\nif (multi_dev) {\r\nhw->dev_count = SWITCH_PORT_NUM;\r\nhw->addr_list_size = SWITCH_PORT_NUM - 1;\r\n}\r\nif (1 == hw->dev_count) {\r\nport_count = SWITCH_PORT_NUM;\r\nmib_port_count = SWITCH_PORT_NUM;\r\n}\r\nhw->mib_port_cnt = TOTAL_PORT_NUM;\r\nhw->ksz_switch = kzalloc(sizeof(struct ksz_switch), GFP_KERNEL);\r\nif (!hw->ksz_switch)\r\ngoto pcidev_init_alloc_err;\r\nsw = hw->ksz_switch;\r\n}\r\nfor (i = 0; i < hw->mib_port_cnt; i++)\r\nhw->port_mib[i].mib_start = 0;\r\nhw->parent = hw_priv;\r\nhw_priv->mtu = (REGULAR_RX_BUF_SIZE + 3) & ~3;\r\nif (ksz_alloc_mem(hw_priv))\r\ngoto pcidev_init_mem_err;\r\nhw_priv->hw.id = net_device_present;\r\nspin_lock_init(&hw_priv->hwlock);\r\nmutex_init(&hw_priv->lock);\r\nfor (i = 0; i < TOTAL_PORT_NUM; i++)\r\ninit_waitqueue_head(&hw_priv->counter[i].counter);\r\nif (macaddr[0] != ':')\r\nget_mac_addr(hw_priv, macaddr, MAIN_PORT);\r\nhw_read_addr(hw);\r\nif (hw->dev_count > 1) {\r\nmemcpy(sw->other_addr, hw->override_addr, ETH_ALEN);\r\nread_other_addr(hw);\r\nif (mac1addr[0] != ':')\r\nget_mac_addr(hw_priv, mac1addr, OTHER_PORT);\r\n}\r\nhw_setup(hw);\r\nif (hw->ksz_switch)\r\nsw_setup(hw);\r\nelse {\r\nhw_priv->wol_support = WOL_SUPPORT;\r\nhw_priv->wol_enable = 0;\r\n}\r\nINIT_WORK(&hw_priv->mib_read, mib_read_work);\r\nksz_init_timer(&hw_priv->mib_timer_info, 500 * HZ / 1000,\r\nmib_monitor, hw_priv);\r\nfor (i = 0; i < hw->dev_count; i++) {\r\ndev = alloc_etherdev(sizeof(struct dev_priv));\r\nif (!dev)\r\ngoto pcidev_init_reg_err;\r\nSET_NETDEV_DEV(dev, &pdev->dev);\r\ninfo->netdev[i] = dev;\r\npriv = netdev_priv(dev);\r\npriv->adapter = hw_priv;\r\npriv->id = net_device_present++;\r\nport = &priv->port;\r\nport->port_cnt = port_count;\r\nport->mib_port_cnt = mib_port_count;\r\nport->first_port = i;\r\nport->flow_ctrl = PHY_FLOW_CTRL;\r\nport->hw = hw;\r\nport->linked = &hw->port_info[port->first_port];\r\nfor (cnt = 0, pi = i; cnt < port_count; cnt++, pi++) {\r\nhw->port_info[pi].port_id = pi;\r\nhw->port_info[pi].pdev = dev;\r\nhw->port_info[pi].state = media_disconnected;\r\n}\r\ndev->mem_start = (unsigned long) hw->io;\r\ndev->mem_end = dev->mem_start + reg_len - 1;\r\ndev->irq = pdev->irq;\r\nif (MAIN_PORT == i)\r\nmemcpy(dev->dev_addr, hw_priv->hw.override_addr,\r\nETH_ALEN);\r\nelse {\r\nmemcpy(dev->dev_addr, sw->other_addr, ETH_ALEN);\r\nif (ether_addr_equal(sw->other_addr, hw->override_addr))\r\ndev->dev_addr[5] += port->first_port;\r\n}\r\ndev->netdev_ops = &netdev_ops;\r\ndev->ethtool_ops = &netdev_ethtool_ops;\r\nif (register_netdev(dev))\r\ngoto pcidev_init_reg_err;\r\nport_set_power_saving(port, true);\r\n}\r\npci_dev_get(hw_priv->pdev);\r\npci_set_drvdata(pdev, info);\r\nreturn 0;\r\npcidev_init_reg_err:\r\nfor (i = 0; i < hw->dev_count; i++) {\r\nif (info->netdev[i]) {\r\nnetdev_free(info->netdev[i]);\r\ninfo->netdev[i] = NULL;\r\n}\r\n}\r\npcidev_init_mem_err:\r\nksz_free_mem(hw_priv);\r\nkfree(hw->ksz_switch);\r\npcidev_init_alloc_err:\r\niounmap(hw->io);\r\npcidev_init_io_err:\r\nkfree(info);\r\npcidev_init_dev_err:\r\nrelease_mem_region(reg_base, reg_len);\r\nreturn result;\r\n}\r\nstatic void pcidev_exit(struct pci_dev *pdev)\r\n{\r\nint i;\r\nstruct platform_info *info = pci_get_drvdata(pdev);\r\nstruct dev_info *hw_priv = &info->dev_info;\r\nrelease_mem_region(pci_resource_start(pdev, 0),\r\npci_resource_len(pdev, 0));\r\nfor (i = 0; i < hw_priv->hw.dev_count; i++) {\r\nif (info->netdev[i])\r\nnetdev_free(info->netdev[i]);\r\n}\r\nif (hw_priv->hw.io)\r\niounmap(hw_priv->hw.io);\r\nksz_free_mem(hw_priv);\r\nkfree(hw_priv->hw.ksz_switch);\r\npci_dev_put(hw_priv->pdev);\r\nkfree(info);\r\n}\r\nstatic int pcidev_resume(struct pci_dev *pdev)\r\n{\r\nint i;\r\nstruct platform_info *info = pci_get_drvdata(pdev);\r\nstruct dev_info *hw_priv = &info->dev_info;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\npci_set_power_state(pdev, PCI_D0);\r\npci_restore_state(pdev);\r\npci_enable_wake(pdev, PCI_D0, 0);\r\nif (hw_priv->wol_enable)\r\nhw_cfg_wol_pme(hw, 0);\r\nfor (i = 0; i < hw->dev_count; i++) {\r\nif (info->netdev[i]) {\r\nstruct net_device *dev = info->netdev[i];\r\nif (netif_running(dev)) {\r\nnetdev_open(dev);\r\nnetif_device_attach(dev);\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int pcidev_suspend(struct pci_dev *pdev, pm_message_t state)\r\n{\r\nint i;\r\nstruct platform_info *info = pci_get_drvdata(pdev);\r\nstruct dev_info *hw_priv = &info->dev_info;\r\nstruct ksz_hw *hw = &hw_priv->hw;\r\nstatic const u8 net_addr[] = { 192, 168, 1, 1 };\r\nfor (i = 0; i < hw->dev_count; i++) {\r\nif (info->netdev[i]) {\r\nstruct net_device *dev = info->netdev[i];\r\nif (netif_running(dev)) {\r\nnetif_device_detach(dev);\r\nnetdev_close(dev);\r\n}\r\n}\r\n}\r\nif (hw_priv->wol_enable) {\r\nhw_enable_wol(hw, hw_priv->wol_enable, net_addr);\r\nhw_cfg_wol_pme(hw, 1);\r\n}\r\npci_save_state(pdev);\r\npci_enable_wake(pdev, pci_choose_state(pdev, state), 1);\r\npci_set_power_state(pdev, pci_choose_state(pdev, state));\r\nreturn 0;\r\n}
