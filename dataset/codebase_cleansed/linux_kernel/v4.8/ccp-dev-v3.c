static int ccp_do_cmd(struct ccp_op *op, u32 *cr, unsigned int cr_count)\r\n{\r\nstruct ccp_cmd_queue *cmd_q = op->cmd_q;\r\nstruct ccp_device *ccp = cmd_q->ccp;\r\nvoid __iomem *cr_addr;\r\nu32 cr0, cmd;\r\nunsigned int i;\r\nint ret = 0;\r\ncmd_q->free_slots--;\r\ncr0 = (cmd_q->id << REQ0_CMD_Q_SHIFT)\r\n| (op->jobid << REQ0_JOBID_SHIFT)\r\n| REQ0_WAIT_FOR_WRITE;\r\nif (op->soc)\r\ncr0 |= REQ0_STOP_ON_COMPLETE\r\n| REQ0_INT_ON_COMPLETE;\r\nif (op->ioc || !cmd_q->free_slots)\r\ncr0 |= REQ0_INT_ON_COMPLETE;\r\ncr_addr = ccp->io_regs + CMD_REQ0 + CMD_REQ_INCR;\r\nmutex_lock(&ccp->req_mutex);\r\nfor (i = 0; i < cr_count; i++, cr_addr += CMD_REQ_INCR)\r\niowrite32(*(cr + i), cr_addr);\r\nwmb();\r\niowrite32(cr0, ccp->io_regs + CMD_REQ0);\r\nmutex_unlock(&ccp->req_mutex);\r\nif (cr0 & REQ0_INT_ON_COMPLETE) {\r\nret = wait_event_interruptible(cmd_q->int_queue,\r\ncmd_q->int_rcvd);\r\nif (ret || cmd_q->cmd_error) {\r\ncmd = (cmd_q->id << DEL_Q_ID_SHIFT)\r\n| op->jobid;\r\niowrite32(cmd, ccp->io_regs + DEL_CMD_Q_JOB);\r\nif (!ret)\r\nret = -EIO;\r\n} else if (op->soc) {\r\ncmd = DEL_Q_ACTIVE\r\n| (cmd_q->id << DEL_Q_ID_SHIFT)\r\n| op->jobid;\r\niowrite32(cmd, ccp->io_regs + DEL_CMD_Q_JOB);\r\n}\r\ncmd_q->free_slots = CMD_Q_DEPTH(cmd_q->q_status);\r\ncmd_q->int_rcvd = 0;\r\n}\r\nreturn ret;\r\n}\r\nstatic int ccp_perform_aes(struct ccp_op *op)\r\n{\r\nu32 cr[6];\r\ncr[0] = (CCP_ENGINE_AES << REQ1_ENGINE_SHIFT)\r\n| (op->u.aes.type << REQ1_AES_TYPE_SHIFT)\r\n| (op->u.aes.mode << REQ1_AES_MODE_SHIFT)\r\n| (op->u.aes.action << REQ1_AES_ACTION_SHIFT)\r\n| (op->ksb_key << REQ1_KEY_KSB_SHIFT);\r\ncr[1] = op->src.u.dma.length - 1;\r\ncr[2] = ccp_addr_lo(&op->src.u.dma);\r\ncr[3] = (op->ksb_ctx << REQ4_KSB_SHIFT)\r\n| (CCP_MEMTYPE_SYSTEM << REQ4_MEMTYPE_SHIFT)\r\n| ccp_addr_hi(&op->src.u.dma);\r\ncr[4] = ccp_addr_lo(&op->dst.u.dma);\r\ncr[5] = (CCP_MEMTYPE_SYSTEM << REQ6_MEMTYPE_SHIFT)\r\n| ccp_addr_hi(&op->dst.u.dma);\r\nif (op->u.aes.mode == CCP_AES_MODE_CFB)\r\ncr[0] |= ((0x7f) << REQ1_AES_CFB_SIZE_SHIFT);\r\nif (op->eom)\r\ncr[0] |= REQ1_EOM;\r\nif (op->init)\r\ncr[0] |= REQ1_INIT;\r\nreturn ccp_do_cmd(op, cr, ARRAY_SIZE(cr));\r\n}\r\nstatic int ccp_perform_xts_aes(struct ccp_op *op)\r\n{\r\nu32 cr[6];\r\ncr[0] = (CCP_ENGINE_XTS_AES_128 << REQ1_ENGINE_SHIFT)\r\n| (op->u.xts.action << REQ1_AES_ACTION_SHIFT)\r\n| (op->u.xts.unit_size << REQ1_XTS_AES_SIZE_SHIFT)\r\n| (op->ksb_key << REQ1_KEY_KSB_SHIFT);\r\ncr[1] = op->src.u.dma.length - 1;\r\ncr[2] = ccp_addr_lo(&op->src.u.dma);\r\ncr[3] = (op->ksb_ctx << REQ4_KSB_SHIFT)\r\n| (CCP_MEMTYPE_SYSTEM << REQ4_MEMTYPE_SHIFT)\r\n| ccp_addr_hi(&op->src.u.dma);\r\ncr[4] = ccp_addr_lo(&op->dst.u.dma);\r\ncr[5] = (CCP_MEMTYPE_SYSTEM << REQ6_MEMTYPE_SHIFT)\r\n| ccp_addr_hi(&op->dst.u.dma);\r\nif (op->eom)\r\ncr[0] |= REQ1_EOM;\r\nif (op->init)\r\ncr[0] |= REQ1_INIT;\r\nreturn ccp_do_cmd(op, cr, ARRAY_SIZE(cr));\r\n}\r\nstatic int ccp_perform_sha(struct ccp_op *op)\r\n{\r\nu32 cr[6];\r\ncr[0] = (CCP_ENGINE_SHA << REQ1_ENGINE_SHIFT)\r\n| (op->u.sha.type << REQ1_SHA_TYPE_SHIFT)\r\n| REQ1_INIT;\r\ncr[1] = op->src.u.dma.length - 1;\r\ncr[2] = ccp_addr_lo(&op->src.u.dma);\r\ncr[3] = (op->ksb_ctx << REQ4_KSB_SHIFT)\r\n| (CCP_MEMTYPE_SYSTEM << REQ4_MEMTYPE_SHIFT)\r\n| ccp_addr_hi(&op->src.u.dma);\r\nif (op->eom) {\r\ncr[0] |= REQ1_EOM;\r\ncr[4] = lower_32_bits(op->u.sha.msg_bits);\r\ncr[5] = upper_32_bits(op->u.sha.msg_bits);\r\n} else {\r\ncr[4] = 0;\r\ncr[5] = 0;\r\n}\r\nreturn ccp_do_cmd(op, cr, ARRAY_SIZE(cr));\r\n}\r\nstatic int ccp_perform_rsa(struct ccp_op *op)\r\n{\r\nu32 cr[6];\r\ncr[0] = (CCP_ENGINE_RSA << REQ1_ENGINE_SHIFT)\r\n| (op->u.rsa.mod_size << REQ1_RSA_MOD_SIZE_SHIFT)\r\n| (op->ksb_key << REQ1_KEY_KSB_SHIFT)\r\n| REQ1_EOM;\r\ncr[1] = op->u.rsa.input_len - 1;\r\ncr[2] = ccp_addr_lo(&op->src.u.dma);\r\ncr[3] = (op->ksb_ctx << REQ4_KSB_SHIFT)\r\n| (CCP_MEMTYPE_SYSTEM << REQ4_MEMTYPE_SHIFT)\r\n| ccp_addr_hi(&op->src.u.dma);\r\ncr[4] = ccp_addr_lo(&op->dst.u.dma);\r\ncr[5] = (CCP_MEMTYPE_SYSTEM << REQ6_MEMTYPE_SHIFT)\r\n| ccp_addr_hi(&op->dst.u.dma);\r\nreturn ccp_do_cmd(op, cr, ARRAY_SIZE(cr));\r\n}\r\nstatic int ccp_perform_passthru(struct ccp_op *op)\r\n{\r\nu32 cr[6];\r\ncr[0] = (CCP_ENGINE_PASSTHRU << REQ1_ENGINE_SHIFT)\r\n| (op->u.passthru.bit_mod << REQ1_PT_BW_SHIFT)\r\n| (op->u.passthru.byte_swap << REQ1_PT_BS_SHIFT);\r\nif (op->src.type == CCP_MEMTYPE_SYSTEM)\r\ncr[1] = op->src.u.dma.length - 1;\r\nelse\r\ncr[1] = op->dst.u.dma.length - 1;\r\nif (op->src.type == CCP_MEMTYPE_SYSTEM) {\r\ncr[2] = ccp_addr_lo(&op->src.u.dma);\r\ncr[3] = (CCP_MEMTYPE_SYSTEM << REQ4_MEMTYPE_SHIFT)\r\n| ccp_addr_hi(&op->src.u.dma);\r\nif (op->u.passthru.bit_mod != CCP_PASSTHRU_BITWISE_NOOP)\r\ncr[3] |= (op->ksb_key << REQ4_KSB_SHIFT);\r\n} else {\r\ncr[2] = op->src.u.ksb * CCP_KSB_BYTES;\r\ncr[3] = (CCP_MEMTYPE_KSB << REQ4_MEMTYPE_SHIFT);\r\n}\r\nif (op->dst.type == CCP_MEMTYPE_SYSTEM) {\r\ncr[4] = ccp_addr_lo(&op->dst.u.dma);\r\ncr[5] = (CCP_MEMTYPE_SYSTEM << REQ6_MEMTYPE_SHIFT)\r\n| ccp_addr_hi(&op->dst.u.dma);\r\n} else {\r\ncr[4] = op->dst.u.ksb * CCP_KSB_BYTES;\r\ncr[5] = (CCP_MEMTYPE_KSB << REQ6_MEMTYPE_SHIFT);\r\n}\r\nif (op->eom)\r\ncr[0] |= REQ1_EOM;\r\nreturn ccp_do_cmd(op, cr, ARRAY_SIZE(cr));\r\n}\r\nstatic int ccp_perform_ecc(struct ccp_op *op)\r\n{\r\nu32 cr[6];\r\ncr[0] = REQ1_ECC_AFFINE_CONVERT\r\n| (CCP_ENGINE_ECC << REQ1_ENGINE_SHIFT)\r\n| (op->u.ecc.function << REQ1_ECC_FUNCTION_SHIFT)\r\n| REQ1_EOM;\r\ncr[1] = op->src.u.dma.length - 1;\r\ncr[2] = ccp_addr_lo(&op->src.u.dma);\r\ncr[3] = (CCP_MEMTYPE_SYSTEM << REQ4_MEMTYPE_SHIFT)\r\n| ccp_addr_hi(&op->src.u.dma);\r\ncr[4] = ccp_addr_lo(&op->dst.u.dma);\r\ncr[5] = (CCP_MEMTYPE_SYSTEM << REQ6_MEMTYPE_SHIFT)\r\n| ccp_addr_hi(&op->dst.u.dma);\r\nreturn ccp_do_cmd(op, cr, ARRAY_SIZE(cr));\r\n}\r\nstatic int ccp_trng_read(struct hwrng *rng, void *data, size_t max, bool wait)\r\n{\r\nstruct ccp_device *ccp = container_of(rng, struct ccp_device, hwrng);\r\nu32 trng_value;\r\nint len = min_t(int, sizeof(trng_value), max);\r\ntrng_value = ioread32(ccp->io_regs + TRNG_OUT_REG);\r\nif (!trng_value) {\r\nif (ccp->hwrng_retries++ > TRNG_RETRIES)\r\nreturn -EIO;\r\nreturn 0;\r\n}\r\nccp->hwrng_retries = 0;\r\nmemcpy(data, &trng_value, len);\r\nreturn len;\r\n}\r\nstatic int ccp_init(struct ccp_device *ccp)\r\n{\r\nstruct device *dev = ccp->dev;\r\nstruct ccp_cmd_queue *cmd_q;\r\nstruct dma_pool *dma_pool;\r\nchar dma_pool_name[MAX_DMAPOOL_NAME_LEN];\r\nunsigned int qmr, qim, i;\r\nint ret;\r\nqim = 0;\r\nqmr = ioread32(ccp->io_regs + Q_MASK_REG);\r\nfor (i = 0; i < MAX_HW_QUEUES; i++) {\r\nif (!(qmr & (1 << i)))\r\ncontinue;\r\nsnprintf(dma_pool_name, sizeof(dma_pool_name), "%s_q%d",\r\nccp->name, i);\r\ndma_pool = dma_pool_create(dma_pool_name, dev,\r\nCCP_DMAPOOL_MAX_SIZE,\r\nCCP_DMAPOOL_ALIGN, 0);\r\nif (!dma_pool) {\r\ndev_err(dev, "unable to allocate dma pool\n");\r\nret = -ENOMEM;\r\ngoto e_pool;\r\n}\r\ncmd_q = &ccp->cmd_q[ccp->cmd_q_count];\r\nccp->cmd_q_count++;\r\ncmd_q->ccp = ccp;\r\ncmd_q->id = i;\r\ncmd_q->dma_pool = dma_pool;\r\ncmd_q->ksb_key = KSB_START + ccp->ksb_start++;\r\ncmd_q->ksb_ctx = KSB_START + ccp->ksb_start++;\r\nccp->ksb_count -= 2;\r\ncmd_q->reg_status = ccp->io_regs + CMD_Q_STATUS_BASE +\r\n(CMD_Q_STATUS_INCR * i);\r\ncmd_q->reg_int_status = ccp->io_regs + CMD_Q_INT_STATUS_BASE +\r\n(CMD_Q_STATUS_INCR * i);\r\ncmd_q->int_ok = 1 << (i * 2);\r\ncmd_q->int_err = 1 << ((i * 2) + 1);\r\ncmd_q->free_slots = CMD_Q_DEPTH(ioread32(cmd_q->reg_status));\r\ninit_waitqueue_head(&cmd_q->int_queue);\r\nqim |= cmd_q->int_ok | cmd_q->int_err;\r\n#ifdef CONFIG_ARM64\r\niowrite32(ccp->axcache, ccp->io_regs + CMD_Q_CACHE_BASE +\r\n(CMD_Q_CACHE_INC * i));\r\n#endif\r\ndev_dbg(dev, "queue #%u available\n", i);\r\n}\r\nif (ccp->cmd_q_count == 0) {\r\ndev_notice(dev, "no command queues available\n");\r\nret = -EIO;\r\ngoto e_pool;\r\n}\r\ndev_notice(dev, "%u command queues available\n", ccp->cmd_q_count);\r\niowrite32(0x00, ccp->io_regs + IRQ_MASK_REG);\r\nfor (i = 0; i < ccp->cmd_q_count; i++) {\r\ncmd_q = &ccp->cmd_q[i];\r\nioread32(cmd_q->reg_int_status);\r\nioread32(cmd_q->reg_status);\r\n}\r\niowrite32(qim, ccp->io_regs + IRQ_STATUS_REG);\r\nret = ccp->get_irq(ccp);\r\nif (ret) {\r\ndev_err(dev, "unable to allocate an IRQ\n");\r\ngoto e_pool;\r\n}\r\ninit_waitqueue_head(&ccp->ksb_queue);\r\ninit_waitqueue_head(&ccp->suspend_queue);\r\nfor (i = 0; i < ccp->cmd_q_count; i++) {\r\nstruct task_struct *kthread;\r\ncmd_q = &ccp->cmd_q[i];\r\nkthread = kthread_create(ccp_cmd_queue_thread, cmd_q,\r\n"%s-q%u", ccp->name, cmd_q->id);\r\nif (IS_ERR(kthread)) {\r\ndev_err(dev, "error creating queue thread (%ld)\n",\r\nPTR_ERR(kthread));\r\nret = PTR_ERR(kthread);\r\ngoto e_kthread;\r\n}\r\ncmd_q->kthread = kthread;\r\nwake_up_process(kthread);\r\n}\r\nccp->hwrng.name = ccp->rngname;\r\nccp->hwrng.read = ccp_trng_read;\r\nret = hwrng_register(&ccp->hwrng);\r\nif (ret) {\r\ndev_err(dev, "error registering hwrng (%d)\n", ret);\r\ngoto e_kthread;\r\n}\r\nret = ccp_dmaengine_register(ccp);\r\nif (ret)\r\ngoto e_hwrng;\r\nccp_add_device(ccp);\r\niowrite32(qim, ccp->io_regs + IRQ_MASK_REG);\r\nreturn 0;\r\ne_hwrng:\r\nhwrng_unregister(&ccp->hwrng);\r\ne_kthread:\r\nfor (i = 0; i < ccp->cmd_q_count; i++)\r\nif (ccp->cmd_q[i].kthread)\r\nkthread_stop(ccp->cmd_q[i].kthread);\r\nccp->free_irq(ccp);\r\ne_pool:\r\nfor (i = 0; i < ccp->cmd_q_count; i++)\r\ndma_pool_destroy(ccp->cmd_q[i].dma_pool);\r\nreturn ret;\r\n}\r\nstatic void ccp_destroy(struct ccp_device *ccp)\r\n{\r\nstruct ccp_cmd_queue *cmd_q;\r\nstruct ccp_cmd *cmd;\r\nunsigned int qim, i;\r\nccp_del_device(ccp);\r\nccp_dmaengine_unregister(ccp);\r\nhwrng_unregister(&ccp->hwrng);\r\nfor (i = 0; i < ccp->cmd_q_count; i++)\r\nif (ccp->cmd_q[i].kthread)\r\nkthread_stop(ccp->cmd_q[i].kthread);\r\nqim = 0;\r\nfor (i = 0; i < ccp->cmd_q_count; i++) {\r\ncmd_q = &ccp->cmd_q[i];\r\nqim |= cmd_q->int_ok | cmd_q->int_err;\r\n}\r\niowrite32(0x00, ccp->io_regs + IRQ_MASK_REG);\r\nfor (i = 0; i < ccp->cmd_q_count; i++) {\r\ncmd_q = &ccp->cmd_q[i];\r\nioread32(cmd_q->reg_int_status);\r\nioread32(cmd_q->reg_status);\r\n}\r\niowrite32(qim, ccp->io_regs + IRQ_STATUS_REG);\r\nccp->free_irq(ccp);\r\nfor (i = 0; i < ccp->cmd_q_count; i++)\r\ndma_pool_destroy(ccp->cmd_q[i].dma_pool);\r\nwhile (!list_empty(&ccp->cmd)) {\r\ncmd = list_first_entry(&ccp->cmd, struct ccp_cmd, entry);\r\nlist_del(&cmd->entry);\r\ncmd->callback(cmd->data, -ENODEV);\r\n}\r\nwhile (!list_empty(&ccp->backlog)) {\r\ncmd = list_first_entry(&ccp->backlog, struct ccp_cmd, entry);\r\nlist_del(&cmd->entry);\r\ncmd->callback(cmd->data, -ENODEV);\r\n}\r\n}\r\nstatic irqreturn_t ccp_irq_handler(int irq, void *data)\r\n{\r\nstruct device *dev = data;\r\nstruct ccp_device *ccp = dev_get_drvdata(dev);\r\nstruct ccp_cmd_queue *cmd_q;\r\nu32 q_int, status;\r\nunsigned int i;\r\nstatus = ioread32(ccp->io_regs + IRQ_STATUS_REG);\r\nfor (i = 0; i < ccp->cmd_q_count; i++) {\r\ncmd_q = &ccp->cmd_q[i];\r\nq_int = status & (cmd_q->int_ok | cmd_q->int_err);\r\nif (q_int) {\r\ncmd_q->int_status = status;\r\ncmd_q->q_status = ioread32(cmd_q->reg_status);\r\ncmd_q->q_int_status = ioread32(cmd_q->reg_int_status);\r\nif ((q_int & cmd_q->int_err) && !cmd_q->cmd_error)\r\ncmd_q->cmd_error = CMD_Q_ERROR(cmd_q->q_status);\r\ncmd_q->int_rcvd = 1;\r\niowrite32(q_int, ccp->io_regs + IRQ_STATUS_REG);\r\nwake_up_interruptible(&cmd_q->int_queue);\r\n}\r\n}\r\nreturn IRQ_HANDLED;\r\n}
