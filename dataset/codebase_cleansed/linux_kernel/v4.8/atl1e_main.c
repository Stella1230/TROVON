static inline void atl1e_irq_enable(struct atl1e_adapter *adapter)\r\n{\r\nif (likely(atomic_dec_and_test(&adapter->irq_sem))) {\r\nAT_WRITE_REG(&adapter->hw, REG_ISR, 0);\r\nAT_WRITE_REG(&adapter->hw, REG_IMR, IMR_NORMAL_MASK);\r\nAT_WRITE_FLUSH(&adapter->hw);\r\n}\r\n}\r\nstatic inline void atl1e_irq_disable(struct atl1e_adapter *adapter)\r\n{\r\natomic_inc(&adapter->irq_sem);\r\nAT_WRITE_REG(&adapter->hw, REG_IMR, 0);\r\nAT_WRITE_FLUSH(&adapter->hw);\r\nsynchronize_irq(adapter->pdev->irq);\r\n}\r\nstatic inline void atl1e_irq_reset(struct atl1e_adapter *adapter)\r\n{\r\natomic_set(&adapter->irq_sem, 0);\r\nAT_WRITE_REG(&adapter->hw, REG_ISR, 0);\r\nAT_WRITE_REG(&adapter->hw, REG_IMR, 0);\r\nAT_WRITE_FLUSH(&adapter->hw);\r\n}\r\nstatic void atl1e_phy_config(unsigned long data)\r\n{\r\nstruct atl1e_adapter *adapter = (struct atl1e_adapter *) data;\r\nstruct atl1e_hw *hw = &adapter->hw;\r\nunsigned long flags;\r\nspin_lock_irqsave(&adapter->mdio_lock, flags);\r\natl1e_restart_autoneg(hw);\r\nspin_unlock_irqrestore(&adapter->mdio_lock, flags);\r\n}\r\nvoid atl1e_reinit_locked(struct atl1e_adapter *adapter)\r\n{\r\nWARN_ON(in_interrupt());\r\nwhile (test_and_set_bit(__AT_RESETTING, &adapter->flags))\r\nmsleep(1);\r\natl1e_down(adapter);\r\natl1e_up(adapter);\r\nclear_bit(__AT_RESETTING, &adapter->flags);\r\n}\r\nstatic void atl1e_reset_task(struct work_struct *work)\r\n{\r\nstruct atl1e_adapter *adapter;\r\nadapter = container_of(work, struct atl1e_adapter, reset_task);\r\natl1e_reinit_locked(adapter);\r\n}\r\nstatic int atl1e_check_link(struct atl1e_adapter *adapter)\r\n{\r\nstruct atl1e_hw *hw = &adapter->hw;\r\nstruct net_device *netdev = adapter->netdev;\r\nint err = 0;\r\nu16 speed, duplex, phy_data;\r\natl1e_read_phy_reg(hw, MII_BMSR, &phy_data);\r\natl1e_read_phy_reg(hw, MII_BMSR, &phy_data);\r\nif ((phy_data & BMSR_LSTATUS) == 0) {\r\nif (netif_carrier_ok(netdev)) {\r\nu32 value;\r\nvalue = AT_READ_REG(hw, REG_MAC_CTRL);\r\nvalue &= ~MAC_CTRL_RX_EN;\r\nAT_WRITE_REG(hw, REG_MAC_CTRL, value);\r\nadapter->link_speed = SPEED_0;\r\nnetif_carrier_off(netdev);\r\nnetif_stop_queue(netdev);\r\n}\r\n} else {\r\nerr = atl1e_get_speed_and_duplex(hw, &speed, &duplex);\r\nif (unlikely(err))\r\nreturn err;\r\nif (adapter->link_speed != speed ||\r\nadapter->link_duplex != duplex) {\r\nadapter->link_speed = speed;\r\nadapter->link_duplex = duplex;\r\natl1e_setup_mac_ctrl(adapter);\r\nnetdev_info(netdev,\r\n"NIC Link is Up <%d Mbps %s Duplex>\n",\r\nadapter->link_speed,\r\nadapter->link_duplex == FULL_DUPLEX ?\r\n"Full" : "Half");\r\n}\r\nif (!netif_carrier_ok(netdev)) {\r\nnetif_carrier_on(netdev);\r\nnetif_wake_queue(netdev);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void atl1e_link_chg_task(struct work_struct *work)\r\n{\r\nstruct atl1e_adapter *adapter;\r\nunsigned long flags;\r\nadapter = container_of(work, struct atl1e_adapter, link_chg_task);\r\nspin_lock_irqsave(&adapter->mdio_lock, flags);\r\natl1e_check_link(adapter);\r\nspin_unlock_irqrestore(&adapter->mdio_lock, flags);\r\n}\r\nstatic void atl1e_link_chg_event(struct atl1e_adapter *adapter)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nu16 phy_data = 0;\r\nu16 link_up = 0;\r\nspin_lock(&adapter->mdio_lock);\r\natl1e_read_phy_reg(&adapter->hw, MII_BMSR, &phy_data);\r\natl1e_read_phy_reg(&adapter->hw, MII_BMSR, &phy_data);\r\nspin_unlock(&adapter->mdio_lock);\r\nlink_up = phy_data & BMSR_LSTATUS;\r\nif (!link_up) {\r\nif (netif_carrier_ok(netdev)) {\r\nnetdev_info(netdev, "NIC Link is Down\n");\r\nadapter->link_speed = SPEED_0;\r\nnetif_stop_queue(netdev);\r\n}\r\n}\r\nschedule_work(&adapter->link_chg_task);\r\n}\r\nstatic void atl1e_del_timer(struct atl1e_adapter *adapter)\r\n{\r\ndel_timer_sync(&adapter->phy_config_timer);\r\n}\r\nstatic void atl1e_cancel_work(struct atl1e_adapter *adapter)\r\n{\r\ncancel_work_sync(&adapter->reset_task);\r\ncancel_work_sync(&adapter->link_chg_task);\r\n}\r\nstatic void atl1e_tx_timeout(struct net_device *netdev)\r\n{\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\nschedule_work(&adapter->reset_task);\r\n}\r\nstatic void atl1e_set_multi(struct net_device *netdev)\r\n{\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\nstruct atl1e_hw *hw = &adapter->hw;\r\nstruct netdev_hw_addr *ha;\r\nu32 mac_ctrl_data = 0;\r\nu32 hash_value;\r\nmac_ctrl_data = AT_READ_REG(hw, REG_MAC_CTRL);\r\nif (netdev->flags & IFF_PROMISC) {\r\nmac_ctrl_data |= MAC_CTRL_PROMIS_EN;\r\n} else if (netdev->flags & IFF_ALLMULTI) {\r\nmac_ctrl_data |= MAC_CTRL_MC_ALL_EN;\r\nmac_ctrl_data &= ~MAC_CTRL_PROMIS_EN;\r\n} else {\r\nmac_ctrl_data &= ~(MAC_CTRL_PROMIS_EN | MAC_CTRL_MC_ALL_EN);\r\n}\r\nAT_WRITE_REG(hw, REG_MAC_CTRL, mac_ctrl_data);\r\nAT_WRITE_REG(hw, REG_RX_HASH_TABLE, 0);\r\nAT_WRITE_REG_ARRAY(hw, REG_RX_HASH_TABLE, 1, 0);\r\nnetdev_for_each_mc_addr(ha, netdev) {\r\nhash_value = atl1e_hash_mc_addr(hw, ha->addr);\r\natl1e_hash_set(hw, hash_value);\r\n}\r\n}\r\nstatic void __atl1e_rx_mode(netdev_features_t features, u32 *mac_ctrl_data)\r\n{\r\nif (features & NETIF_F_RXALL) {\r\n*mac_ctrl_data |= MAC_CTRL_DBG;\r\n} else {\r\n*mac_ctrl_data &= ~MAC_CTRL_DBG;\r\n}\r\n}\r\nstatic void atl1e_rx_mode(struct net_device *netdev,\r\nnetdev_features_t features)\r\n{\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\nu32 mac_ctrl_data = 0;\r\nnetdev_dbg(adapter->netdev, "%s\n", __func__);\r\natl1e_irq_disable(adapter);\r\nmac_ctrl_data = AT_READ_REG(&adapter->hw, REG_MAC_CTRL);\r\n__atl1e_rx_mode(features, &mac_ctrl_data);\r\nAT_WRITE_REG(&adapter->hw, REG_MAC_CTRL, mac_ctrl_data);\r\natl1e_irq_enable(adapter);\r\n}\r\nstatic void __atl1e_vlan_mode(netdev_features_t features, u32 *mac_ctrl_data)\r\n{\r\nif (features & NETIF_F_HW_VLAN_CTAG_RX) {\r\n*mac_ctrl_data |= MAC_CTRL_RMV_VLAN;\r\n} else {\r\n*mac_ctrl_data &= ~MAC_CTRL_RMV_VLAN;\r\n}\r\n}\r\nstatic void atl1e_vlan_mode(struct net_device *netdev,\r\nnetdev_features_t features)\r\n{\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\nu32 mac_ctrl_data = 0;\r\nnetdev_dbg(adapter->netdev, "%s\n", __func__);\r\natl1e_irq_disable(adapter);\r\nmac_ctrl_data = AT_READ_REG(&adapter->hw, REG_MAC_CTRL);\r\n__atl1e_vlan_mode(features, &mac_ctrl_data);\r\nAT_WRITE_REG(&adapter->hw, REG_MAC_CTRL, mac_ctrl_data);\r\natl1e_irq_enable(adapter);\r\n}\r\nstatic void atl1e_restore_vlan(struct atl1e_adapter *adapter)\r\n{\r\nnetdev_dbg(adapter->netdev, "%s\n", __func__);\r\natl1e_vlan_mode(adapter->netdev, adapter->netdev->features);\r\n}\r\nstatic int atl1e_set_mac_addr(struct net_device *netdev, void *p)\r\n{\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\nstruct sockaddr *addr = p;\r\nif (!is_valid_ether_addr(addr->sa_data))\r\nreturn -EADDRNOTAVAIL;\r\nif (netif_running(netdev))\r\nreturn -EBUSY;\r\nmemcpy(netdev->dev_addr, addr->sa_data, netdev->addr_len);\r\nmemcpy(adapter->hw.mac_addr, addr->sa_data, netdev->addr_len);\r\natl1e_hw_set_mac_addr(&adapter->hw);\r\nreturn 0;\r\n}\r\nstatic netdev_features_t atl1e_fix_features(struct net_device *netdev,\r\nnetdev_features_t features)\r\n{\r\nif (features & NETIF_F_HW_VLAN_CTAG_RX)\r\nfeatures |= NETIF_F_HW_VLAN_CTAG_TX;\r\nelse\r\nfeatures &= ~NETIF_F_HW_VLAN_CTAG_TX;\r\nreturn features;\r\n}\r\nstatic int atl1e_set_features(struct net_device *netdev,\r\nnetdev_features_t features)\r\n{\r\nnetdev_features_t changed = netdev->features ^ features;\r\nif (changed & NETIF_F_HW_VLAN_CTAG_RX)\r\natl1e_vlan_mode(netdev, features);\r\nif (changed & NETIF_F_RXALL)\r\natl1e_rx_mode(netdev, features);\r\nreturn 0;\r\n}\r\nstatic int atl1e_change_mtu(struct net_device *netdev, int new_mtu)\r\n{\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\nint old_mtu = netdev->mtu;\r\nint max_frame = new_mtu + ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN;\r\nif ((max_frame < ETH_ZLEN + ETH_FCS_LEN) ||\r\n(max_frame > MAX_JUMBO_FRAME_SIZE)) {\r\nnetdev_warn(adapter->netdev, "invalid MTU setting\n");\r\nreturn -EINVAL;\r\n}\r\nif (old_mtu != new_mtu && netif_running(netdev)) {\r\nwhile (test_and_set_bit(__AT_RESETTING, &adapter->flags))\r\nmsleep(1);\r\nnetdev->mtu = new_mtu;\r\nadapter->hw.max_frame_size = new_mtu;\r\nadapter->hw.rx_jumbo_th = (max_frame + 7) >> 3;\r\natl1e_down(adapter);\r\natl1e_up(adapter);\r\nclear_bit(__AT_RESETTING, &adapter->flags);\r\n}\r\nreturn 0;\r\n}\r\nstatic int atl1e_mdio_read(struct net_device *netdev, int phy_id, int reg_num)\r\n{\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\nu16 result;\r\natl1e_read_phy_reg(&adapter->hw, reg_num & MDIO_REG_ADDR_MASK, &result);\r\nreturn result;\r\n}\r\nstatic void atl1e_mdio_write(struct net_device *netdev, int phy_id,\r\nint reg_num, int val)\r\n{\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\natl1e_write_phy_reg(&adapter->hw, reg_num & MDIO_REG_ADDR_MASK, val);\r\n}\r\nstatic int atl1e_mii_ioctl(struct net_device *netdev,\r\nstruct ifreq *ifr, int cmd)\r\n{\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\nstruct mii_ioctl_data *data = if_mii(ifr);\r\nunsigned long flags;\r\nint retval = 0;\r\nif (!netif_running(netdev))\r\nreturn -EINVAL;\r\nspin_lock_irqsave(&adapter->mdio_lock, flags);\r\nswitch (cmd) {\r\ncase SIOCGMIIPHY:\r\ndata->phy_id = 0;\r\nbreak;\r\ncase SIOCGMIIREG:\r\nif (atl1e_read_phy_reg(&adapter->hw, data->reg_num & 0x1F,\r\n&data->val_out)) {\r\nretval = -EIO;\r\ngoto out;\r\n}\r\nbreak;\r\ncase SIOCSMIIREG:\r\nif (data->reg_num & ~(0x1F)) {\r\nretval = -EFAULT;\r\ngoto out;\r\n}\r\nnetdev_dbg(adapter->netdev, "<atl1e_mii_ioctl> write %x %x\n",\r\ndata->reg_num, data->val_in);\r\nif (atl1e_write_phy_reg(&adapter->hw,\r\ndata->reg_num, data->val_in)) {\r\nretval = -EIO;\r\ngoto out;\r\n}\r\nbreak;\r\ndefault:\r\nretval = -EOPNOTSUPP;\r\nbreak;\r\n}\r\nout:\r\nspin_unlock_irqrestore(&adapter->mdio_lock, flags);\r\nreturn retval;\r\n}\r\nstatic int atl1e_ioctl(struct net_device *netdev, struct ifreq *ifr, int cmd)\r\n{\r\nswitch (cmd) {\r\ncase SIOCGMIIPHY:\r\ncase SIOCGMIIREG:\r\ncase SIOCSMIIREG:\r\nreturn atl1e_mii_ioctl(netdev, ifr, cmd);\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nstatic void atl1e_setup_pcicmd(struct pci_dev *pdev)\r\n{\r\nu16 cmd;\r\npci_read_config_word(pdev, PCI_COMMAND, &cmd);\r\ncmd &= ~(PCI_COMMAND_INTX_DISABLE | PCI_COMMAND_IO);\r\ncmd |= (PCI_COMMAND_MEMORY | PCI_COMMAND_MASTER);\r\npci_write_config_word(pdev, PCI_COMMAND, cmd);\r\npci_write_config_dword(pdev, REG_PM_CTRLSTAT, 0);\r\nmsleep(1);\r\n}\r\nstatic int atl1e_alloc_queues(struct atl1e_adapter *adapter)\r\n{\r\nreturn 0;\r\n}\r\nstatic int atl1e_sw_init(struct atl1e_adapter *adapter)\r\n{\r\nstruct atl1e_hw *hw = &adapter->hw;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nu32 phy_status_data = 0;\r\nadapter->wol = 0;\r\nadapter->link_speed = SPEED_0;\r\nadapter->link_duplex = FULL_DUPLEX;\r\nadapter->num_rx_queues = 1;\r\nhw->vendor_id = pdev->vendor;\r\nhw->device_id = pdev->device;\r\nhw->subsystem_vendor_id = pdev->subsystem_vendor;\r\nhw->subsystem_id = pdev->subsystem_device;\r\nhw->revision_id = pdev->revision;\r\npci_read_config_word(pdev, PCI_COMMAND, &hw->pci_cmd_word);\r\nphy_status_data = AT_READ_REG(hw, REG_PHY_STATUS);\r\nif (hw->revision_id >= 0xF0) {\r\nhw->nic_type = athr_l2e_revB;\r\n} else {\r\nif (phy_status_data & PHY_STATUS_100M)\r\nhw->nic_type = athr_l1e;\r\nelse\r\nhw->nic_type = athr_l2e_revA;\r\n}\r\nphy_status_data = AT_READ_REG(hw, REG_PHY_STATUS);\r\nif (phy_status_data & PHY_STATUS_EMI_CA)\r\nhw->emi_ca = true;\r\nelse\r\nhw->emi_ca = false;\r\nhw->phy_configured = false;\r\nhw->preamble_len = 7;\r\nhw->max_frame_size = adapter->netdev->mtu;\r\nhw->rx_jumbo_th = (hw->max_frame_size + ETH_HLEN +\r\nVLAN_HLEN + ETH_FCS_LEN + 7) >> 3;\r\nhw->rrs_type = atl1e_rrs_disable;\r\nhw->indirect_tab = 0;\r\nhw->base_cpu = 0;\r\nhw->ict = 50000;\r\nhw->smb_timer = 200000;\r\nhw->tpd_burst = 5;\r\nhw->rrd_thresh = 1;\r\nhw->tpd_thresh = adapter->tx_ring.count / 2;\r\nhw->rx_count_down = 4;\r\nhw->tx_count_down = hw->imt * 4 / 3;\r\nhw->dmar_block = atl1e_dma_req_1024;\r\nhw->dmaw_block = atl1e_dma_req_1024;\r\nhw->dmar_dly_cnt = 15;\r\nhw->dmaw_dly_cnt = 4;\r\nif (atl1e_alloc_queues(adapter)) {\r\nnetdev_err(adapter->netdev, "Unable to allocate memory for queues\n");\r\nreturn -ENOMEM;\r\n}\r\natomic_set(&adapter->irq_sem, 1);\r\nspin_lock_init(&adapter->mdio_lock);\r\nset_bit(__AT_DOWN, &adapter->flags);\r\nreturn 0;\r\n}\r\nstatic void atl1e_clean_tx_ring(struct atl1e_adapter *adapter)\r\n{\r\nstruct atl1e_tx_ring *tx_ring = &adapter->tx_ring;\r\nstruct atl1e_tx_buffer *tx_buffer = NULL;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nu16 index, ring_count;\r\nif (tx_ring->desc == NULL || tx_ring->tx_buffer == NULL)\r\nreturn;\r\nring_count = tx_ring->count;\r\nfor (index = 0; index < ring_count; index++) {\r\ntx_buffer = &tx_ring->tx_buffer[index];\r\nif (tx_buffer->dma) {\r\nif (tx_buffer->flags & ATL1E_TX_PCIMAP_SINGLE)\r\npci_unmap_single(pdev, tx_buffer->dma,\r\ntx_buffer->length, PCI_DMA_TODEVICE);\r\nelse if (tx_buffer->flags & ATL1E_TX_PCIMAP_PAGE)\r\npci_unmap_page(pdev, tx_buffer->dma,\r\ntx_buffer->length, PCI_DMA_TODEVICE);\r\ntx_buffer->dma = 0;\r\n}\r\n}\r\nfor (index = 0; index < ring_count; index++) {\r\ntx_buffer = &tx_ring->tx_buffer[index];\r\nif (tx_buffer->skb) {\r\ndev_kfree_skb_any(tx_buffer->skb);\r\ntx_buffer->skb = NULL;\r\n}\r\n}\r\nmemset(tx_ring->desc, 0, sizeof(struct atl1e_tpd_desc) *\r\nring_count);\r\nmemset(tx_ring->tx_buffer, 0, sizeof(struct atl1e_tx_buffer) *\r\nring_count);\r\n}\r\nstatic void atl1e_clean_rx_ring(struct atl1e_adapter *adapter)\r\n{\r\nstruct atl1e_rx_ring *rx_ring =\r\n&adapter->rx_ring;\r\nstruct atl1e_rx_page_desc *rx_page_desc = rx_ring->rx_page_desc;\r\nu16 i, j;\r\nif (adapter->ring_vir_addr == NULL)\r\nreturn;\r\nfor (i = 0; i < adapter->num_rx_queues; i++) {\r\nfor (j = 0; j < AT_PAGE_NUM_PER_QUEUE; j++) {\r\nif (rx_page_desc[i].rx_page[j].addr != NULL) {\r\nmemset(rx_page_desc[i].rx_page[j].addr, 0,\r\nrx_ring->real_page_size);\r\n}\r\n}\r\n}\r\n}\r\nstatic void atl1e_cal_ring_size(struct atl1e_adapter *adapter, u32 *ring_size)\r\n{\r\n*ring_size = ((u32)(adapter->tx_ring.count *\r\nsizeof(struct atl1e_tpd_desc) + 7\r\n+ adapter->rx_ring.real_page_size * AT_PAGE_NUM_PER_QUEUE *\r\nadapter->num_rx_queues + 31\r\n+ (1 + AT_PAGE_NUM_PER_QUEUE * adapter->num_rx_queues) *\r\nsizeof(u32) + 3));\r\n}\r\nstatic void atl1e_init_ring_resources(struct atl1e_adapter *adapter)\r\n{\r\nstruct atl1e_rx_ring *rx_ring = NULL;\r\nrx_ring = &adapter->rx_ring;\r\nrx_ring->real_page_size = adapter->rx_ring.page_size\r\n+ adapter->hw.max_frame_size\r\n+ ETH_HLEN + VLAN_HLEN\r\n+ ETH_FCS_LEN;\r\nrx_ring->real_page_size = roundup(rx_ring->real_page_size, 32);\r\natl1e_cal_ring_size(adapter, &adapter->ring_size);\r\nadapter->ring_vir_addr = NULL;\r\nadapter->rx_ring.desc = NULL;\r\nrwlock_init(&adapter->tx_ring.tx_lock);\r\n}\r\nstatic void atl1e_init_ring_ptrs(struct atl1e_adapter *adapter)\r\n{\r\nstruct atl1e_tx_ring *tx_ring = NULL;\r\nstruct atl1e_rx_ring *rx_ring = NULL;\r\nstruct atl1e_rx_page_desc *rx_page_desc = NULL;\r\nint i, j;\r\ntx_ring = &adapter->tx_ring;\r\nrx_ring = &adapter->rx_ring;\r\nrx_page_desc = rx_ring->rx_page_desc;\r\ntx_ring->next_to_use = 0;\r\natomic_set(&tx_ring->next_to_clean, 0);\r\nfor (i = 0; i < adapter->num_rx_queues; i++) {\r\nrx_page_desc[i].rx_using = 0;\r\nrx_page_desc[i].rx_nxseq = 0;\r\nfor (j = 0; j < AT_PAGE_NUM_PER_QUEUE; j++) {\r\n*rx_page_desc[i].rx_page[j].write_offset_addr = 0;\r\nrx_page_desc[i].rx_page[j].read_offset = 0;\r\n}\r\n}\r\n}\r\nstatic void atl1e_free_ring_resources(struct atl1e_adapter *adapter)\r\n{\r\nstruct pci_dev *pdev = adapter->pdev;\r\natl1e_clean_tx_ring(adapter);\r\natl1e_clean_rx_ring(adapter);\r\nif (adapter->ring_vir_addr) {\r\npci_free_consistent(pdev, adapter->ring_size,\r\nadapter->ring_vir_addr, adapter->ring_dma);\r\nadapter->ring_vir_addr = NULL;\r\n}\r\nif (adapter->tx_ring.tx_buffer) {\r\nkfree(adapter->tx_ring.tx_buffer);\r\nadapter->tx_ring.tx_buffer = NULL;\r\n}\r\n}\r\nstatic int atl1e_setup_ring_resources(struct atl1e_adapter *adapter)\r\n{\r\nstruct pci_dev *pdev = adapter->pdev;\r\nstruct atl1e_tx_ring *tx_ring;\r\nstruct atl1e_rx_ring *rx_ring;\r\nstruct atl1e_rx_page_desc *rx_page_desc;\r\nint size, i, j;\r\nu32 offset = 0;\r\nint err = 0;\r\nif (adapter->ring_vir_addr != NULL)\r\nreturn 0;\r\ntx_ring = &adapter->tx_ring;\r\nrx_ring = &adapter->rx_ring;\r\nsize = adapter->ring_size;\r\nadapter->ring_vir_addr = pci_zalloc_consistent(pdev, adapter->ring_size,\r\n&adapter->ring_dma);\r\nif (adapter->ring_vir_addr == NULL) {\r\nnetdev_err(adapter->netdev,\r\n"pci_alloc_consistent failed, size = D%d\n", size);\r\nreturn -ENOMEM;\r\n}\r\nrx_page_desc = rx_ring->rx_page_desc;\r\ntx_ring->dma = roundup(adapter->ring_dma, 8);\r\noffset = tx_ring->dma - adapter->ring_dma;\r\ntx_ring->desc = adapter->ring_vir_addr + offset;\r\nsize = sizeof(struct atl1e_tx_buffer) * (tx_ring->count);\r\ntx_ring->tx_buffer = kzalloc(size, GFP_KERNEL);\r\nif (tx_ring->tx_buffer == NULL) {\r\nerr = -ENOMEM;\r\ngoto failed;\r\n}\r\noffset += (sizeof(struct atl1e_tpd_desc) * tx_ring->count);\r\noffset = roundup(offset, 32);\r\nfor (i = 0; i < adapter->num_rx_queues; i++) {\r\nfor (j = 0; j < AT_PAGE_NUM_PER_QUEUE; j++) {\r\nrx_page_desc[i].rx_page[j].dma =\r\nadapter->ring_dma + offset;\r\nrx_page_desc[i].rx_page[j].addr =\r\nadapter->ring_vir_addr + offset;\r\noffset += rx_ring->real_page_size;\r\n}\r\n}\r\ntx_ring->cmb_dma = adapter->ring_dma + offset;\r\ntx_ring->cmb = adapter->ring_vir_addr + offset;\r\noffset += sizeof(u32);\r\nfor (i = 0; i < adapter->num_rx_queues; i++) {\r\nfor (j = 0; j < AT_PAGE_NUM_PER_QUEUE; j++) {\r\nrx_page_desc[i].rx_page[j].write_offset_dma =\r\nadapter->ring_dma + offset;\r\nrx_page_desc[i].rx_page[j].write_offset_addr =\r\nadapter->ring_vir_addr + offset;\r\noffset += sizeof(u32);\r\n}\r\n}\r\nif (unlikely(offset > adapter->ring_size)) {\r\nnetdev_err(adapter->netdev, "offset(%d) > ring size(%d) !!\n",\r\noffset, adapter->ring_size);\r\nerr = -1;\r\ngoto failed;\r\n}\r\nreturn 0;\r\nfailed:\r\nif (adapter->ring_vir_addr != NULL) {\r\npci_free_consistent(pdev, adapter->ring_size,\r\nadapter->ring_vir_addr, adapter->ring_dma);\r\nadapter->ring_vir_addr = NULL;\r\n}\r\nreturn err;\r\n}\r\nstatic inline void atl1e_configure_des_ring(struct atl1e_adapter *adapter)\r\n{\r\nstruct atl1e_hw *hw = &adapter->hw;\r\nstruct atl1e_rx_ring *rx_ring = &adapter->rx_ring;\r\nstruct atl1e_tx_ring *tx_ring = &adapter->tx_ring;\r\nstruct atl1e_rx_page_desc *rx_page_desc = NULL;\r\nint i, j;\r\nAT_WRITE_REG(hw, REG_DESC_BASE_ADDR_HI,\r\n(u32)((adapter->ring_dma & AT_DMA_HI_ADDR_MASK) >> 32));\r\nAT_WRITE_REG(hw, REG_TPD_BASE_ADDR_LO,\r\n(u32)((tx_ring->dma) & AT_DMA_LO_ADDR_MASK));\r\nAT_WRITE_REG(hw, REG_TPD_RING_SIZE, (u16)(tx_ring->count));\r\nAT_WRITE_REG(hw, REG_HOST_TX_CMB_LO,\r\n(u32)((tx_ring->cmb_dma) & AT_DMA_LO_ADDR_MASK));\r\nrx_page_desc = rx_ring->rx_page_desc;\r\nfor (i = 0; i < AT_MAX_RECEIVE_QUEUE; i++) {\r\nAT_WRITE_REG(hw, atl1e_rx_page_hi_addr_regs[i],\r\n(u32)((adapter->ring_dma &\r\nAT_DMA_HI_ADDR_MASK) >> 32));\r\nfor (j = 0; j < AT_PAGE_NUM_PER_QUEUE; j++) {\r\nu32 page_phy_addr;\r\nu32 offset_phy_addr;\r\npage_phy_addr = rx_page_desc[i].rx_page[j].dma;\r\noffset_phy_addr =\r\nrx_page_desc[i].rx_page[j].write_offset_dma;\r\nAT_WRITE_REG(hw, atl1e_rx_page_lo_addr_regs[i][j],\r\npage_phy_addr & AT_DMA_LO_ADDR_MASK);\r\nAT_WRITE_REG(hw, atl1e_rx_page_write_offset_regs[i][j],\r\noffset_phy_addr & AT_DMA_LO_ADDR_MASK);\r\nAT_WRITE_REGB(hw, atl1e_rx_page_vld_regs[i][j], 1);\r\n}\r\n}\r\nAT_WRITE_REG(hw, REG_HOST_RXFPAGE_SIZE, rx_ring->page_size);\r\nAT_WRITE_REG(hw, REG_LOAD_PTR, 1);\r\n}\r\nstatic inline void atl1e_configure_tx(struct atl1e_adapter *adapter)\r\n{\r\nstruct atl1e_hw *hw = &adapter->hw;\r\nu32 dev_ctrl_data = 0;\r\nu32 max_pay_load = 0;\r\nu32 jumbo_thresh = 0;\r\nu32 extra_size = 0;\r\nif (hw->nic_type != athr_l2e_revB) {\r\nextra_size = ETH_HLEN + VLAN_HLEN + ETH_FCS_LEN;\r\nif (hw->max_frame_size <= 1500) {\r\njumbo_thresh = hw->max_frame_size + extra_size;\r\n} else if (hw->max_frame_size < 6*1024) {\r\njumbo_thresh =\r\n(hw->max_frame_size + extra_size) * 2 / 3;\r\n} else {\r\njumbo_thresh = (hw->max_frame_size + extra_size) / 2;\r\n}\r\nAT_WRITE_REG(hw, REG_TX_EARLY_TH, (jumbo_thresh + 7) >> 3);\r\n}\r\ndev_ctrl_data = AT_READ_REG(hw, REG_DEVICE_CTRL);\r\nmax_pay_load = ((dev_ctrl_data >> DEVICE_CTRL_MAX_PAYLOAD_SHIFT)) &\r\nDEVICE_CTRL_MAX_PAYLOAD_MASK;\r\nhw->dmaw_block = min_t(u32, max_pay_load, hw->dmaw_block);\r\nmax_pay_load = ((dev_ctrl_data >> DEVICE_CTRL_MAX_RREQ_SZ_SHIFT)) &\r\nDEVICE_CTRL_MAX_RREQ_SZ_MASK;\r\nhw->dmar_block = min_t(u32, max_pay_load, hw->dmar_block);\r\nif (hw->nic_type != athr_l2e_revB)\r\nAT_WRITE_REGW(hw, REG_TXQ_CTRL + 2,\r\natl1e_pay_load_size[hw->dmar_block]);\r\nAT_WRITE_REGW(hw, REG_TXQ_CTRL,\r\n(((u16)hw->tpd_burst & TXQ_CTRL_NUM_TPD_BURST_MASK)\r\n<< TXQ_CTRL_NUM_TPD_BURST_SHIFT)\r\n| TXQ_CTRL_ENH_MODE | TXQ_CTRL_EN);\r\n}\r\nstatic inline void atl1e_configure_rx(struct atl1e_adapter *adapter)\r\n{\r\nstruct atl1e_hw *hw = &adapter->hw;\r\nu32 rxf_len = 0;\r\nu32 rxf_low = 0;\r\nu32 rxf_high = 0;\r\nu32 rxf_thresh_data = 0;\r\nu32 rxq_ctrl_data = 0;\r\nif (hw->nic_type != athr_l2e_revB) {\r\nAT_WRITE_REGW(hw, REG_RXQ_JMBOSZ_RRDTIM,\r\n(u16)((hw->rx_jumbo_th & RXQ_JMBOSZ_TH_MASK) <<\r\nRXQ_JMBOSZ_TH_SHIFT |\r\n(1 & RXQ_JMBO_LKAH_MASK) <<\r\nRXQ_JMBO_LKAH_SHIFT));\r\nrxf_len = AT_READ_REG(hw, REG_SRAM_RXF_LEN);\r\nrxf_high = rxf_len * 4 / 5;\r\nrxf_low = rxf_len / 5;\r\nrxf_thresh_data = ((rxf_high & RXQ_RXF_PAUSE_TH_HI_MASK)\r\n<< RXQ_RXF_PAUSE_TH_HI_SHIFT) |\r\n((rxf_low & RXQ_RXF_PAUSE_TH_LO_MASK)\r\n<< RXQ_RXF_PAUSE_TH_LO_SHIFT);\r\nAT_WRITE_REG(hw, REG_RXQ_RXF_PAUSE_THRESH, rxf_thresh_data);\r\n}\r\nAT_WRITE_REG(hw, REG_IDT_TABLE, hw->indirect_tab);\r\nAT_WRITE_REG(hw, REG_BASE_CPU_NUMBER, hw->base_cpu);\r\nif (hw->rrs_type & atl1e_rrs_ipv4)\r\nrxq_ctrl_data |= RXQ_CTRL_HASH_TYPE_IPV4;\r\nif (hw->rrs_type & atl1e_rrs_ipv4_tcp)\r\nrxq_ctrl_data |= RXQ_CTRL_HASH_TYPE_IPV4_TCP;\r\nif (hw->rrs_type & atl1e_rrs_ipv6)\r\nrxq_ctrl_data |= RXQ_CTRL_HASH_TYPE_IPV6;\r\nif (hw->rrs_type & atl1e_rrs_ipv6_tcp)\r\nrxq_ctrl_data |= RXQ_CTRL_HASH_TYPE_IPV6_TCP;\r\nif (hw->rrs_type != atl1e_rrs_disable)\r\nrxq_ctrl_data |=\r\n(RXQ_CTRL_HASH_ENABLE | RXQ_CTRL_RSS_MODE_MQUESINT);\r\nrxq_ctrl_data |= RXQ_CTRL_IPV6_XSUM_VERIFY_EN | RXQ_CTRL_PBA_ALIGN_32 |\r\nRXQ_CTRL_CUT_THRU_EN | RXQ_CTRL_EN;\r\nAT_WRITE_REG(hw, REG_RXQ_CTRL, rxq_ctrl_data);\r\n}\r\nstatic inline void atl1e_configure_dma(struct atl1e_adapter *adapter)\r\n{\r\nstruct atl1e_hw *hw = &adapter->hw;\r\nu32 dma_ctrl_data = 0;\r\ndma_ctrl_data = DMA_CTRL_RXCMB_EN;\r\ndma_ctrl_data |= (((u32)hw->dmar_block) & DMA_CTRL_DMAR_BURST_LEN_MASK)\r\n<< DMA_CTRL_DMAR_BURST_LEN_SHIFT;\r\ndma_ctrl_data |= (((u32)hw->dmaw_block) & DMA_CTRL_DMAW_BURST_LEN_MASK)\r\n<< DMA_CTRL_DMAW_BURST_LEN_SHIFT;\r\ndma_ctrl_data |= DMA_CTRL_DMAR_REQ_PRI | DMA_CTRL_DMAR_OUT_ORDER;\r\ndma_ctrl_data |= (((u32)hw->dmar_dly_cnt) & DMA_CTRL_DMAR_DLY_CNT_MASK)\r\n<< DMA_CTRL_DMAR_DLY_CNT_SHIFT;\r\ndma_ctrl_data |= (((u32)hw->dmaw_dly_cnt) & DMA_CTRL_DMAW_DLY_CNT_MASK)\r\n<< DMA_CTRL_DMAW_DLY_CNT_SHIFT;\r\nAT_WRITE_REG(hw, REG_DMA_CTRL, dma_ctrl_data);\r\n}\r\nstatic void atl1e_setup_mac_ctrl(struct atl1e_adapter *adapter)\r\n{\r\nu32 value;\r\nstruct atl1e_hw *hw = &adapter->hw;\r\nstruct net_device *netdev = adapter->netdev;\r\nvalue = MAC_CTRL_TX_EN |\r\nMAC_CTRL_RX_EN ;\r\nif (FULL_DUPLEX == adapter->link_duplex)\r\nvalue |= MAC_CTRL_DUPLX;\r\nvalue |= ((u32)((SPEED_1000 == adapter->link_speed) ?\r\nMAC_CTRL_SPEED_1000 : MAC_CTRL_SPEED_10_100) <<\r\nMAC_CTRL_SPEED_SHIFT);\r\nvalue |= (MAC_CTRL_TX_FLOW | MAC_CTRL_RX_FLOW);\r\nvalue |= (MAC_CTRL_ADD_CRC | MAC_CTRL_PAD);\r\nvalue |= (((u32)adapter->hw.preamble_len &\r\nMAC_CTRL_PRMLEN_MASK) << MAC_CTRL_PRMLEN_SHIFT);\r\n__atl1e_vlan_mode(netdev->features, &value);\r\nvalue |= MAC_CTRL_BC_EN;\r\nif (netdev->flags & IFF_PROMISC)\r\nvalue |= MAC_CTRL_PROMIS_EN;\r\nif (netdev->flags & IFF_ALLMULTI)\r\nvalue |= MAC_CTRL_MC_ALL_EN;\r\nif (netdev->features & NETIF_F_RXALL)\r\nvalue |= MAC_CTRL_DBG;\r\nAT_WRITE_REG(hw, REG_MAC_CTRL, value);\r\n}\r\nstatic int atl1e_configure(struct atl1e_adapter *adapter)\r\n{\r\nstruct atl1e_hw *hw = &adapter->hw;\r\nu32 intr_status_data = 0;\r\nAT_WRITE_REG(hw, REG_ISR, ~0);\r\natl1e_hw_set_mac_addr(hw);\r\nAT_WRITE_REG(hw, REG_WOL_CTRL, 0);\r\natl1e_configure_des_ring(adapter);\r\nAT_WRITE_REGW(hw, REG_IRQ_MODU_TIMER_INIT, hw->imt);\r\nAT_WRITE_REGW(hw, REG_IRQ_MODU_TIMER2_INIT, hw->imt);\r\nAT_WRITE_REG(hw, REG_MASTER_CTRL, MASTER_CTRL_LED_MODE |\r\nMASTER_CTRL_ITIMER_EN | MASTER_CTRL_ITIMER2_EN);\r\nAT_WRITE_REGW(hw, REG_TRIG_RRD_THRESH, hw->rrd_thresh);\r\nAT_WRITE_REGW(hw, REG_TRIG_TPD_THRESH, hw->tpd_thresh);\r\nAT_WRITE_REGW(hw, REG_TRIG_RXTIMER, hw->rx_count_down);\r\nAT_WRITE_REGW(hw, REG_TRIG_TXTIMER, hw->tx_count_down);\r\nAT_WRITE_REGW(hw, REG_CMBDISDMA_TIMER, hw->ict);\r\nAT_WRITE_REG(hw, REG_MTU, hw->max_frame_size + ETH_HLEN +\r\nVLAN_HLEN + ETH_FCS_LEN);\r\natl1e_configure_tx(adapter);\r\natl1e_configure_rx(adapter);\r\natl1e_configure_dma(adapter);\r\nAT_WRITE_REG(hw, REG_SMB_STAT_TIMER, hw->smb_timer);\r\nintr_status_data = AT_READ_REG(hw, REG_ISR);\r\nif (unlikely((intr_status_data & ISR_PHY_LINKDOWN) != 0)) {\r\nnetdev_err(adapter->netdev,\r\n"atl1e_configure failed, PCIE phy link down\n");\r\nreturn -1;\r\n}\r\nAT_WRITE_REG(hw, REG_ISR, 0x7fffffff);\r\nreturn 0;\r\n}\r\nstatic struct net_device_stats *atl1e_get_stats(struct net_device *netdev)\r\n{\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\nstruct atl1e_hw_stats *hw_stats = &adapter->hw_stats;\r\nstruct net_device_stats *net_stats = &netdev->stats;\r\nnet_stats->rx_bytes = hw_stats->rx_byte_cnt;\r\nnet_stats->tx_bytes = hw_stats->tx_byte_cnt;\r\nnet_stats->multicast = hw_stats->rx_mcast;\r\nnet_stats->collisions = hw_stats->tx_1_col +\r\nhw_stats->tx_2_col +\r\nhw_stats->tx_late_col +\r\nhw_stats->tx_abort_col;\r\nnet_stats->rx_errors = hw_stats->rx_frag +\r\nhw_stats->rx_fcs_err +\r\nhw_stats->rx_len_err +\r\nhw_stats->rx_sz_ov +\r\nhw_stats->rx_rrd_ov +\r\nhw_stats->rx_align_err +\r\nhw_stats->rx_rxf_ov;\r\nnet_stats->rx_fifo_errors = hw_stats->rx_rxf_ov;\r\nnet_stats->rx_length_errors = hw_stats->rx_len_err;\r\nnet_stats->rx_crc_errors = hw_stats->rx_fcs_err;\r\nnet_stats->rx_frame_errors = hw_stats->rx_align_err;\r\nnet_stats->rx_dropped = hw_stats->rx_rrd_ov;\r\nnet_stats->tx_errors = hw_stats->tx_late_col +\r\nhw_stats->tx_abort_col +\r\nhw_stats->tx_underrun +\r\nhw_stats->tx_trunc;\r\nnet_stats->tx_fifo_errors = hw_stats->tx_underrun;\r\nnet_stats->tx_aborted_errors = hw_stats->tx_abort_col;\r\nnet_stats->tx_window_errors = hw_stats->tx_late_col;\r\nnet_stats->rx_packets = hw_stats->rx_ok + net_stats->rx_errors;\r\nnet_stats->tx_packets = hw_stats->tx_ok + net_stats->tx_errors;\r\nreturn net_stats;\r\n}\r\nstatic void atl1e_update_hw_stats(struct atl1e_adapter *adapter)\r\n{\r\nu16 hw_reg_addr = 0;\r\nunsigned long *stats_item = NULL;\r\nhw_reg_addr = REG_MAC_RX_STATUS_BIN;\r\nstats_item = &adapter->hw_stats.rx_ok;\r\nwhile (hw_reg_addr <= REG_MAC_RX_STATUS_END) {\r\n*stats_item += AT_READ_REG(&adapter->hw, hw_reg_addr);\r\nstats_item++;\r\nhw_reg_addr += 4;\r\n}\r\nhw_reg_addr = REG_MAC_TX_STATUS_BIN;\r\nstats_item = &adapter->hw_stats.tx_ok;\r\nwhile (hw_reg_addr <= REG_MAC_TX_STATUS_END) {\r\n*stats_item += AT_READ_REG(&adapter->hw, hw_reg_addr);\r\nstats_item++;\r\nhw_reg_addr += 4;\r\n}\r\n}\r\nstatic inline void atl1e_clear_phy_int(struct atl1e_adapter *adapter)\r\n{\r\nu16 phy_data;\r\nspin_lock(&adapter->mdio_lock);\r\natl1e_read_phy_reg(&adapter->hw, MII_INT_STATUS, &phy_data);\r\nspin_unlock(&adapter->mdio_lock);\r\n}\r\nstatic bool atl1e_clean_tx_irq(struct atl1e_adapter *adapter)\r\n{\r\nstruct atl1e_tx_ring *tx_ring = &adapter->tx_ring;\r\nstruct atl1e_tx_buffer *tx_buffer = NULL;\r\nu16 hw_next_to_clean = AT_READ_REGW(&adapter->hw, REG_TPD_CONS_IDX);\r\nu16 next_to_clean = atomic_read(&tx_ring->next_to_clean);\r\nwhile (next_to_clean != hw_next_to_clean) {\r\ntx_buffer = &tx_ring->tx_buffer[next_to_clean];\r\nif (tx_buffer->dma) {\r\nif (tx_buffer->flags & ATL1E_TX_PCIMAP_SINGLE)\r\npci_unmap_single(adapter->pdev, tx_buffer->dma,\r\ntx_buffer->length, PCI_DMA_TODEVICE);\r\nelse if (tx_buffer->flags & ATL1E_TX_PCIMAP_PAGE)\r\npci_unmap_page(adapter->pdev, tx_buffer->dma,\r\ntx_buffer->length, PCI_DMA_TODEVICE);\r\ntx_buffer->dma = 0;\r\n}\r\nif (tx_buffer->skb) {\r\ndev_kfree_skb_irq(tx_buffer->skb);\r\ntx_buffer->skb = NULL;\r\n}\r\nif (++next_to_clean == tx_ring->count)\r\nnext_to_clean = 0;\r\n}\r\natomic_set(&tx_ring->next_to_clean, next_to_clean);\r\nif (netif_queue_stopped(adapter->netdev) &&\r\nnetif_carrier_ok(adapter->netdev)) {\r\nnetif_wake_queue(adapter->netdev);\r\n}\r\nreturn true;\r\n}\r\nstatic irqreturn_t atl1e_intr(int irq, void *data)\r\n{\r\nstruct net_device *netdev = data;\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\nstruct atl1e_hw *hw = &adapter->hw;\r\nint max_ints = AT_MAX_INT_WORK;\r\nint handled = IRQ_NONE;\r\nu32 status;\r\ndo {\r\nstatus = AT_READ_REG(hw, REG_ISR);\r\nif ((status & IMR_NORMAL_MASK) == 0 ||\r\n(status & ISR_DIS_INT) != 0) {\r\nif (max_ints != AT_MAX_INT_WORK)\r\nhandled = IRQ_HANDLED;\r\nbreak;\r\n}\r\nif (status & ISR_GPHY)\r\natl1e_clear_phy_int(adapter);\r\nAT_WRITE_REG(hw, REG_ISR, status | ISR_DIS_INT);\r\nhandled = IRQ_HANDLED;\r\nif (status & ISR_PHY_LINKDOWN) {\r\nnetdev_err(adapter->netdev,\r\n"pcie phy linkdown %x\n", status);\r\nif (netif_running(adapter->netdev)) {\r\natl1e_irq_reset(adapter);\r\nschedule_work(&adapter->reset_task);\r\nbreak;\r\n}\r\n}\r\nif (status & (ISR_DMAR_TO_RST | ISR_DMAW_TO_RST)) {\r\nnetdev_err(adapter->netdev,\r\n"PCIE DMA RW error (status = 0x%x)\n",\r\nstatus);\r\natl1e_irq_reset(adapter);\r\nschedule_work(&adapter->reset_task);\r\nbreak;\r\n}\r\nif (status & ISR_SMB)\r\natl1e_update_hw_stats(adapter);\r\nif (status & (ISR_GPHY | ISR_MANUAL)) {\r\nnetdev->stats.tx_carrier_errors++;\r\natl1e_link_chg_event(adapter);\r\nbreak;\r\n}\r\nif (status & ISR_TX_EVENT)\r\natl1e_clean_tx_irq(adapter);\r\nif (status & ISR_RX_EVENT) {\r\nAT_WRITE_REG(hw, REG_IMR,\r\nIMR_NORMAL_MASK & ~ISR_RX_EVENT);\r\nAT_WRITE_FLUSH(hw);\r\nif (likely(napi_schedule_prep(\r\n&adapter->napi)))\r\n__napi_schedule(&adapter->napi);\r\n}\r\n} while (--max_ints > 0);\r\nAT_WRITE_REG(&adapter->hw, REG_ISR, 0);\r\nreturn handled;\r\n}\r\nstatic inline void atl1e_rx_checksum(struct atl1e_adapter *adapter,\r\nstruct sk_buff *skb, struct atl1e_recv_ret_status *prrs)\r\n{\r\nu8 *packet = (u8 *)(prrs + 1);\r\nstruct iphdr *iph;\r\nu16 head_len = ETH_HLEN;\r\nu16 pkt_flags;\r\nu16 err_flags;\r\nskb_checksum_none_assert(skb);\r\npkt_flags = prrs->pkt_flag;\r\nerr_flags = prrs->err_flag;\r\nif (((pkt_flags & RRS_IS_IPV4) || (pkt_flags & RRS_IS_IPV6)) &&\r\n((pkt_flags & RRS_IS_TCP) || (pkt_flags & RRS_IS_UDP))) {\r\nif (pkt_flags & RRS_IS_IPV4) {\r\nif (pkt_flags & RRS_IS_802_3)\r\nhead_len += 8;\r\niph = (struct iphdr *) (packet + head_len);\r\nif (iph->frag_off != 0 && !(pkt_flags & RRS_IS_IP_DF))\r\ngoto hw_xsum;\r\n}\r\nif (!(err_flags & (RRS_ERR_IP_CSUM | RRS_ERR_L4_CSUM))) {\r\nskb->ip_summed = CHECKSUM_UNNECESSARY;\r\nreturn;\r\n}\r\n}\r\nhw_xsum :\r\nreturn;\r\n}\r\nstatic struct atl1e_rx_page *atl1e_get_rx_page(struct atl1e_adapter *adapter,\r\nu8 que)\r\n{\r\nstruct atl1e_rx_page_desc *rx_page_desc =\r\n(struct atl1e_rx_page_desc *) adapter->rx_ring.rx_page_desc;\r\nu8 rx_using = rx_page_desc[que].rx_using;\r\nreturn &(rx_page_desc[que].rx_page[rx_using]);\r\n}\r\nstatic void atl1e_clean_rx_irq(struct atl1e_adapter *adapter, u8 que,\r\nint *work_done, int work_to_do)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct atl1e_rx_ring *rx_ring = &adapter->rx_ring;\r\nstruct atl1e_rx_page_desc *rx_page_desc =\r\n(struct atl1e_rx_page_desc *) rx_ring->rx_page_desc;\r\nstruct sk_buff *skb = NULL;\r\nstruct atl1e_rx_page *rx_page = atl1e_get_rx_page(adapter, que);\r\nu32 packet_size, write_offset;\r\nstruct atl1e_recv_ret_status *prrs;\r\nwrite_offset = *(rx_page->write_offset_addr);\r\nif (likely(rx_page->read_offset < write_offset)) {\r\ndo {\r\nif (*work_done >= work_to_do)\r\nbreak;\r\n(*work_done)++;\r\nprrs = (struct atl1e_recv_ret_status *) (rx_page->addr +\r\nrx_page->read_offset);\r\nif (prrs->seq_num != rx_page_desc[que].rx_nxseq) {\r\nnetdev_err(netdev,\r\n"rx sequence number error (rx=%d) (expect=%d)\n",\r\nprrs->seq_num,\r\nrx_page_desc[que].rx_nxseq);\r\nrx_page_desc[que].rx_nxseq++;\r\nAT_WRITE_REG(&adapter->hw, REG_DEBUG_DATA0,\r\n(((u32)prrs->seq_num) << 16) |\r\nrx_page_desc[que].rx_nxseq);\r\ngoto fatal_err;\r\n}\r\nrx_page_desc[que].rx_nxseq++;\r\nif ((prrs->pkt_flag & RRS_IS_ERR_FRAME) &&\r\n!(netdev->features & NETIF_F_RXALL)) {\r\nif (prrs->err_flag & (RRS_ERR_BAD_CRC |\r\nRRS_ERR_DRIBBLE | RRS_ERR_CODE |\r\nRRS_ERR_TRUNC)) {\r\nnetdev_err(netdev,\r\n"rx packet desc error %x\n",\r\n*((u32 *)prrs + 1));\r\ngoto skip_pkt;\r\n}\r\n}\r\npacket_size = ((prrs->word1 >> RRS_PKT_SIZE_SHIFT) &\r\nRRS_PKT_SIZE_MASK);\r\nif (likely(!(netdev->features & NETIF_F_RXFCS)))\r\npacket_size -= 4;\r\nskb = netdev_alloc_skb_ip_align(netdev, packet_size);\r\nif (skb == NULL)\r\ngoto skip_pkt;\r\nmemcpy(skb->data, (u8 *)(prrs + 1), packet_size);\r\nskb_put(skb, packet_size);\r\nskb->protocol = eth_type_trans(skb, netdev);\r\natl1e_rx_checksum(adapter, skb, prrs);\r\nif (prrs->pkt_flag & RRS_IS_VLAN_TAG) {\r\nu16 vlan_tag = (prrs->vtag >> 4) |\r\n((prrs->vtag & 7) << 13) |\r\n((prrs->vtag & 8) << 9);\r\nnetdev_dbg(netdev,\r\n"RXD VLAN TAG<RRD>=0x%04x\n",\r\nprrs->vtag);\r\n__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vlan_tag);\r\n}\r\nnetif_receive_skb(skb);\r\nskip_pkt:\r\nrx_page->read_offset +=\r\n(((u32)((prrs->word1 >> RRS_PKT_SIZE_SHIFT) &\r\nRRS_PKT_SIZE_MASK) +\r\nsizeof(struct atl1e_recv_ret_status) + 31) &\r\n0xFFFFFFE0);\r\nif (rx_page->read_offset >= rx_ring->page_size) {\r\nu16 reg_addr;\r\nu8 rx_using;\r\nrx_page->read_offset =\r\n*(rx_page->write_offset_addr) = 0;\r\nrx_using = rx_page_desc[que].rx_using;\r\nreg_addr =\r\natl1e_rx_page_vld_regs[que][rx_using];\r\nAT_WRITE_REGB(&adapter->hw, reg_addr, 1);\r\nrx_page_desc[que].rx_using ^= 1;\r\nrx_page = atl1e_get_rx_page(adapter, que);\r\n}\r\nwrite_offset = *(rx_page->write_offset_addr);\r\n} while (rx_page->read_offset < write_offset);\r\n}\r\nreturn;\r\nfatal_err:\r\nif (!test_bit(__AT_DOWN, &adapter->flags))\r\nschedule_work(&adapter->reset_task);\r\n}\r\nstatic int atl1e_clean(struct napi_struct *napi, int budget)\r\n{\r\nstruct atl1e_adapter *adapter =\r\ncontainer_of(napi, struct atl1e_adapter, napi);\r\nu32 imr_data;\r\nint work_done = 0;\r\nif (!netif_carrier_ok(adapter->netdev))\r\ngoto quit_polling;\r\natl1e_clean_rx_irq(adapter, 0, &work_done, budget);\r\nif (work_done < budget) {\r\nquit_polling:\r\nnapi_complete(napi);\r\nimr_data = AT_READ_REG(&adapter->hw, REG_IMR);\r\nAT_WRITE_REG(&adapter->hw, REG_IMR, imr_data | ISR_RX_EVENT);\r\nif (test_bit(__AT_DOWN, &adapter->flags)) {\r\natomic_dec(&adapter->irq_sem);\r\nnetdev_err(adapter->netdev,\r\n"atl1e_clean is called when AT_DOWN\n");\r\n}\r\n}\r\nreturn work_done;\r\n}\r\nstatic void atl1e_netpoll(struct net_device *netdev)\r\n{\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\ndisable_irq(adapter->pdev->irq);\r\natl1e_intr(adapter->pdev->irq, netdev);\r\nenable_irq(adapter->pdev->irq);\r\n}\r\nstatic inline u16 atl1e_tpd_avail(struct atl1e_adapter *adapter)\r\n{\r\nstruct atl1e_tx_ring *tx_ring = &adapter->tx_ring;\r\nu16 next_to_use = 0;\r\nu16 next_to_clean = 0;\r\nnext_to_clean = atomic_read(&tx_ring->next_to_clean);\r\nnext_to_use = tx_ring->next_to_use;\r\nreturn (u16)(next_to_clean > next_to_use) ?\r\n(next_to_clean - next_to_use - 1) :\r\n(tx_ring->count + next_to_clean - next_to_use - 1);\r\n}\r\nstatic struct atl1e_tpd_desc *atl1e_get_tpd(struct atl1e_adapter *adapter)\r\n{\r\nstruct atl1e_tx_ring *tx_ring = &adapter->tx_ring;\r\nu16 next_to_use = 0;\r\nnext_to_use = tx_ring->next_to_use;\r\nif (++tx_ring->next_to_use == tx_ring->count)\r\ntx_ring->next_to_use = 0;\r\nmemset(&tx_ring->desc[next_to_use], 0, sizeof(struct atl1e_tpd_desc));\r\nreturn &tx_ring->desc[next_to_use];\r\n}\r\nstatic struct atl1e_tx_buffer *\r\natl1e_get_tx_buffer(struct atl1e_adapter *adapter, struct atl1e_tpd_desc *tpd)\r\n{\r\nstruct atl1e_tx_ring *tx_ring = &adapter->tx_ring;\r\nreturn &tx_ring->tx_buffer[tpd - tx_ring->desc];\r\n}\r\nstatic u16 atl1e_cal_tdp_req(const struct sk_buff *skb)\r\n{\r\nint i = 0;\r\nu16 tpd_req = 1;\r\nu16 fg_size = 0;\r\nu16 proto_hdr_len = 0;\r\nfor (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {\r\nfg_size = skb_frag_size(&skb_shinfo(skb)->frags[i]);\r\ntpd_req += ((fg_size + MAX_TX_BUF_LEN - 1) >> MAX_TX_BUF_SHIFT);\r\n}\r\nif (skb_is_gso(skb)) {\r\nif (skb->protocol == htons(ETH_P_IP) ||\r\n(skb_shinfo(skb)->gso_type == SKB_GSO_TCPV6)) {\r\nproto_hdr_len = skb_transport_offset(skb) +\r\ntcp_hdrlen(skb);\r\nif (proto_hdr_len < skb_headlen(skb)) {\r\ntpd_req += ((skb_headlen(skb) - proto_hdr_len +\r\nMAX_TX_BUF_LEN - 1) >>\r\nMAX_TX_BUF_SHIFT);\r\n}\r\n}\r\n}\r\nreturn tpd_req;\r\n}\r\nstatic int atl1e_tso_csum(struct atl1e_adapter *adapter,\r\nstruct sk_buff *skb, struct atl1e_tpd_desc *tpd)\r\n{\r\nunsigned short offload_type;\r\nu8 hdr_len;\r\nu32 real_len;\r\nif (skb_is_gso(skb)) {\r\nint err;\r\nerr = skb_cow_head(skb, 0);\r\nif (err < 0)\r\nreturn err;\r\noffload_type = skb_shinfo(skb)->gso_type;\r\nif (offload_type & SKB_GSO_TCPV4) {\r\nreal_len = (((unsigned char *)ip_hdr(skb) - skb->data)\r\n+ ntohs(ip_hdr(skb)->tot_len));\r\nif (real_len < skb->len)\r\npskb_trim(skb, real_len);\r\nhdr_len = (skb_transport_offset(skb) + tcp_hdrlen(skb));\r\nif (unlikely(skb->len == hdr_len)) {\r\nnetdev_warn(adapter->netdev,\r\n"IPV4 tso with zero data??\n");\r\ngoto check_sum;\r\n} else {\r\nip_hdr(skb)->check = 0;\r\nip_hdr(skb)->tot_len = 0;\r\ntcp_hdr(skb)->check = ~csum_tcpudp_magic(\r\nip_hdr(skb)->saddr,\r\nip_hdr(skb)->daddr,\r\n0, IPPROTO_TCP, 0);\r\ntpd->word3 |= (ip_hdr(skb)->ihl &\r\nTDP_V4_IPHL_MASK) <<\r\nTPD_V4_IPHL_SHIFT;\r\ntpd->word3 |= ((tcp_hdrlen(skb) >> 2) &\r\nTPD_TCPHDRLEN_MASK) <<\r\nTPD_TCPHDRLEN_SHIFT;\r\ntpd->word3 |= ((skb_shinfo(skb)->gso_size) &\r\nTPD_MSS_MASK) << TPD_MSS_SHIFT;\r\ntpd->word3 |= 1 << TPD_SEGMENT_EN_SHIFT;\r\n}\r\nreturn 0;\r\n}\r\n}\r\ncheck_sum:\r\nif (likely(skb->ip_summed == CHECKSUM_PARTIAL)) {\r\nu8 css, cso;\r\ncso = skb_checksum_start_offset(skb);\r\nif (unlikely(cso & 0x1)) {\r\nnetdev_err(adapter->netdev,\r\n"payload offset should not ant event number\n");\r\nreturn -1;\r\n} else {\r\ncss = cso + skb->csum_offset;\r\ntpd->word3 |= (cso & TPD_PLOADOFFSET_MASK) <<\r\nTPD_PLOADOFFSET_SHIFT;\r\ntpd->word3 |= (css & TPD_CCSUMOFFSET_MASK) <<\r\nTPD_CCSUMOFFSET_SHIFT;\r\ntpd->word3 |= 1 << TPD_CC_SEGMENT_EN_SHIFT;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int atl1e_tx_map(struct atl1e_adapter *adapter,\r\nstruct sk_buff *skb, struct atl1e_tpd_desc *tpd)\r\n{\r\nstruct atl1e_tpd_desc *use_tpd = NULL;\r\nstruct atl1e_tx_buffer *tx_buffer = NULL;\r\nu16 buf_len = skb_headlen(skb);\r\nu16 map_len = 0;\r\nu16 mapped_len = 0;\r\nu16 hdr_len = 0;\r\nu16 nr_frags;\r\nu16 f;\r\nint segment;\r\nint ring_start = adapter->tx_ring.next_to_use;\r\nint ring_end;\r\nnr_frags = skb_shinfo(skb)->nr_frags;\r\nsegment = (tpd->word3 >> TPD_SEGMENT_EN_SHIFT) & TPD_SEGMENT_EN_MASK;\r\nif (segment) {\r\nmap_len = hdr_len = skb_transport_offset(skb) + tcp_hdrlen(skb);\r\nuse_tpd = tpd;\r\ntx_buffer = atl1e_get_tx_buffer(adapter, use_tpd);\r\ntx_buffer->length = map_len;\r\ntx_buffer->dma = pci_map_single(adapter->pdev,\r\nskb->data, hdr_len, PCI_DMA_TODEVICE);\r\nif (dma_mapping_error(&adapter->pdev->dev, tx_buffer->dma))\r\nreturn -ENOSPC;\r\nATL1E_SET_PCIMAP_TYPE(tx_buffer, ATL1E_TX_PCIMAP_SINGLE);\r\nmapped_len += map_len;\r\nuse_tpd->buffer_addr = cpu_to_le64(tx_buffer->dma);\r\nuse_tpd->word2 = (use_tpd->word2 & (~TPD_BUFLEN_MASK)) |\r\n((cpu_to_le32(tx_buffer->length) &\r\nTPD_BUFLEN_MASK) << TPD_BUFLEN_SHIFT);\r\n}\r\nwhile (mapped_len < buf_len) {\r\nif (mapped_len == 0) {\r\nuse_tpd = tpd;\r\n} else {\r\nuse_tpd = atl1e_get_tpd(adapter);\r\nmemcpy(use_tpd, tpd, sizeof(struct atl1e_tpd_desc));\r\n}\r\ntx_buffer = atl1e_get_tx_buffer(adapter, use_tpd);\r\ntx_buffer->skb = NULL;\r\ntx_buffer->length = map_len =\r\n((buf_len - mapped_len) >= MAX_TX_BUF_LEN) ?\r\nMAX_TX_BUF_LEN : (buf_len - mapped_len);\r\ntx_buffer->dma =\r\npci_map_single(adapter->pdev, skb->data + mapped_len,\r\nmap_len, PCI_DMA_TODEVICE);\r\nif (dma_mapping_error(&adapter->pdev->dev, tx_buffer->dma)) {\r\nring_end = adapter->tx_ring.next_to_use;\r\nadapter->tx_ring.next_to_use = ring_start;\r\nwhile (adapter->tx_ring.next_to_use != ring_end) {\r\ntpd = atl1e_get_tpd(adapter);\r\ntx_buffer = atl1e_get_tx_buffer(adapter, tpd);\r\npci_unmap_single(adapter->pdev, tx_buffer->dma,\r\ntx_buffer->length, PCI_DMA_TODEVICE);\r\n}\r\nadapter->tx_ring.next_to_use = ring_start;\r\nreturn -ENOSPC;\r\n}\r\nATL1E_SET_PCIMAP_TYPE(tx_buffer, ATL1E_TX_PCIMAP_SINGLE);\r\nmapped_len += map_len;\r\nuse_tpd->buffer_addr = cpu_to_le64(tx_buffer->dma);\r\nuse_tpd->word2 = (use_tpd->word2 & (~TPD_BUFLEN_MASK)) |\r\n((cpu_to_le32(tx_buffer->length) &\r\nTPD_BUFLEN_MASK) << TPD_BUFLEN_SHIFT);\r\n}\r\nfor (f = 0; f < nr_frags; f++) {\r\nconst struct skb_frag_struct *frag;\r\nu16 i;\r\nu16 seg_num;\r\nfrag = &skb_shinfo(skb)->frags[f];\r\nbuf_len = skb_frag_size(frag);\r\nseg_num = (buf_len + MAX_TX_BUF_LEN - 1) / MAX_TX_BUF_LEN;\r\nfor (i = 0; i < seg_num; i++) {\r\nuse_tpd = atl1e_get_tpd(adapter);\r\nmemcpy(use_tpd, tpd, sizeof(struct atl1e_tpd_desc));\r\ntx_buffer = atl1e_get_tx_buffer(adapter, use_tpd);\r\nBUG_ON(tx_buffer->skb);\r\ntx_buffer->skb = NULL;\r\ntx_buffer->length =\r\n(buf_len > MAX_TX_BUF_LEN) ?\r\nMAX_TX_BUF_LEN : buf_len;\r\nbuf_len -= tx_buffer->length;\r\ntx_buffer->dma = skb_frag_dma_map(&adapter->pdev->dev,\r\nfrag,\r\n(i * MAX_TX_BUF_LEN),\r\ntx_buffer->length,\r\nDMA_TO_DEVICE);\r\nif (dma_mapping_error(&adapter->pdev->dev, tx_buffer->dma)) {\r\nring_end = adapter->tx_ring.next_to_use;\r\nadapter->tx_ring.next_to_use = ring_start;\r\nwhile (adapter->tx_ring.next_to_use != ring_end) {\r\ntpd = atl1e_get_tpd(adapter);\r\ntx_buffer = atl1e_get_tx_buffer(adapter, tpd);\r\ndma_unmap_page(&adapter->pdev->dev, tx_buffer->dma,\r\ntx_buffer->length, DMA_TO_DEVICE);\r\n}\r\nadapter->tx_ring.next_to_use = ring_start;\r\nreturn -ENOSPC;\r\n}\r\nATL1E_SET_PCIMAP_TYPE(tx_buffer, ATL1E_TX_PCIMAP_PAGE);\r\nuse_tpd->buffer_addr = cpu_to_le64(tx_buffer->dma);\r\nuse_tpd->word2 = (use_tpd->word2 & (~TPD_BUFLEN_MASK)) |\r\n((cpu_to_le32(tx_buffer->length) &\r\nTPD_BUFLEN_MASK) << TPD_BUFLEN_SHIFT);\r\n}\r\n}\r\nif ((tpd->word3 >> TPD_SEGMENT_EN_SHIFT) & TPD_SEGMENT_EN_MASK)\r\ntpd->word3 |= 1 << TPD_HDRFLAG_SHIFT;\r\nuse_tpd->word3 |= 1 << TPD_EOP_SHIFT;\r\ntx_buffer->skb = skb;\r\nreturn 0;\r\n}\r\nstatic void atl1e_tx_queue(struct atl1e_adapter *adapter, u16 count,\r\nstruct atl1e_tpd_desc *tpd)\r\n{\r\nstruct atl1e_tx_ring *tx_ring = &adapter->tx_ring;\r\nwmb();\r\nAT_WRITE_REG(&adapter->hw, REG_MB_TPD_PROD_IDX, tx_ring->next_to_use);\r\n}\r\nstatic netdev_tx_t atl1e_xmit_frame(struct sk_buff *skb,\r\nstruct net_device *netdev)\r\n{\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\nu16 tpd_req = 1;\r\nstruct atl1e_tpd_desc *tpd;\r\nif (test_bit(__AT_DOWN, &adapter->flags)) {\r\ndev_kfree_skb_any(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nif (unlikely(skb->len <= 0)) {\r\ndev_kfree_skb_any(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\ntpd_req = atl1e_cal_tdp_req(skb);\r\nif (atl1e_tpd_avail(adapter) < tpd_req) {\r\nnetif_stop_queue(netdev);\r\nreturn NETDEV_TX_BUSY;\r\n}\r\ntpd = atl1e_get_tpd(adapter);\r\nif (skb_vlan_tag_present(skb)) {\r\nu16 vlan_tag = skb_vlan_tag_get(skb);\r\nu16 atl1e_vlan_tag;\r\ntpd->word3 |= 1 << TPD_INS_VL_TAG_SHIFT;\r\nAT_VLAN_TAG_TO_TPD_TAG(vlan_tag, atl1e_vlan_tag);\r\ntpd->word2 |= (atl1e_vlan_tag & TPD_VLANTAG_MASK) <<\r\nTPD_VLAN_SHIFT;\r\n}\r\nif (skb->protocol == htons(ETH_P_8021Q))\r\ntpd->word3 |= 1 << TPD_VL_TAGGED_SHIFT;\r\nif (skb_network_offset(skb) != ETH_HLEN)\r\ntpd->word3 |= 1 << TPD_ETHTYPE_SHIFT;\r\nif (atl1e_tso_csum(adapter, skb, tpd) != 0) {\r\ndev_kfree_skb_any(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nif (atl1e_tx_map(adapter, skb, tpd)) {\r\ndev_kfree_skb_any(skb);\r\ngoto out;\r\n}\r\natl1e_tx_queue(adapter, tpd_req, tpd);\r\nout:\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void atl1e_free_irq(struct atl1e_adapter *adapter)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nfree_irq(adapter->pdev->irq, netdev);\r\n}\r\nstatic int atl1e_request_irq(struct atl1e_adapter *adapter)\r\n{\r\nstruct pci_dev *pdev = adapter->pdev;\r\nstruct net_device *netdev = adapter->netdev;\r\nint err = 0;\r\nerr = request_irq(pdev->irq, atl1e_intr, IRQF_SHARED, netdev->name,\r\nnetdev);\r\nif (err) {\r\nnetdev_dbg(adapter->netdev,\r\n"Unable to allocate interrupt Error: %d\n", err);\r\nreturn err;\r\n}\r\nnetdev_dbg(netdev, "atl1e_request_irq OK\n");\r\nreturn err;\r\n}\r\nint atl1e_up(struct atl1e_adapter *adapter)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nint err = 0;\r\nu32 val;\r\nerr = atl1e_init_hw(&adapter->hw);\r\nif (err) {\r\nerr = -EIO;\r\nreturn err;\r\n}\r\natl1e_init_ring_ptrs(adapter);\r\natl1e_set_multi(netdev);\r\natl1e_restore_vlan(adapter);\r\nif (atl1e_configure(adapter)) {\r\nerr = -EIO;\r\ngoto err_up;\r\n}\r\nclear_bit(__AT_DOWN, &adapter->flags);\r\nnapi_enable(&adapter->napi);\r\natl1e_irq_enable(adapter);\r\nval = AT_READ_REG(&adapter->hw, REG_MASTER_CTRL);\r\nAT_WRITE_REG(&adapter->hw, REG_MASTER_CTRL,\r\nval | MASTER_CTRL_MANUAL_INT);\r\nerr_up:\r\nreturn err;\r\n}\r\nvoid atl1e_down(struct atl1e_adapter *adapter)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nset_bit(__AT_DOWN, &adapter->flags);\r\nnetif_stop_queue(netdev);\r\natl1e_reset_hw(&adapter->hw);\r\nmsleep(1);\r\nnapi_disable(&adapter->napi);\r\natl1e_del_timer(adapter);\r\natl1e_irq_disable(adapter);\r\nnetif_carrier_off(netdev);\r\nadapter->link_speed = SPEED_0;\r\nadapter->link_duplex = -1;\r\natl1e_clean_tx_ring(adapter);\r\natl1e_clean_rx_ring(adapter);\r\n}\r\nstatic int atl1e_open(struct net_device *netdev)\r\n{\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\nint err;\r\nif (test_bit(__AT_TESTING, &adapter->flags))\r\nreturn -EBUSY;\r\natl1e_init_ring_resources(adapter);\r\nerr = atl1e_setup_ring_resources(adapter);\r\nif (unlikely(err))\r\nreturn err;\r\nerr = atl1e_request_irq(adapter);\r\nif (unlikely(err))\r\ngoto err_req_irq;\r\nerr = atl1e_up(adapter);\r\nif (unlikely(err))\r\ngoto err_up;\r\nreturn 0;\r\nerr_up:\r\natl1e_free_irq(adapter);\r\nerr_req_irq:\r\natl1e_free_ring_resources(adapter);\r\natl1e_reset_hw(&adapter->hw);\r\nreturn err;\r\n}\r\nstatic int atl1e_close(struct net_device *netdev)\r\n{\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\nWARN_ON(test_bit(__AT_RESETTING, &adapter->flags));\r\natl1e_down(adapter);\r\natl1e_free_irq(adapter);\r\natl1e_free_ring_resources(adapter);\r\nreturn 0;\r\n}\r\nstatic int atl1e_suspend(struct pci_dev *pdev, pm_message_t state)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\nstruct atl1e_hw *hw = &adapter->hw;\r\nu32 ctrl = 0;\r\nu32 mac_ctrl_data = 0;\r\nu32 wol_ctrl_data = 0;\r\nu16 mii_advertise_data = 0;\r\nu16 mii_bmsr_data = 0;\r\nu16 mii_intr_status_data = 0;\r\nu32 wufc = adapter->wol;\r\nu32 i;\r\n#ifdef CONFIG_PM\r\nint retval = 0;\r\n#endif\r\nif (netif_running(netdev)) {\r\nWARN_ON(test_bit(__AT_RESETTING, &adapter->flags));\r\natl1e_down(adapter);\r\n}\r\nnetif_device_detach(netdev);\r\n#ifdef CONFIG_PM\r\nretval = pci_save_state(pdev);\r\nif (retval)\r\nreturn retval;\r\n#endif\r\nif (wufc) {\r\natl1e_read_phy_reg(hw, MII_BMSR, &mii_bmsr_data);\r\natl1e_read_phy_reg(hw, MII_BMSR, &mii_bmsr_data);\r\nmii_advertise_data = ADVERTISE_10HALF;\r\nif ((atl1e_write_phy_reg(hw, MII_CTRL1000, 0) != 0) ||\r\n(atl1e_write_phy_reg(hw,\r\nMII_ADVERTISE, mii_advertise_data) != 0) ||\r\n(atl1e_phy_commit(hw)) != 0) {\r\nnetdev_dbg(adapter->netdev, "set phy register failed\n");\r\ngoto wol_dis;\r\n}\r\nhw->phy_configured = false;\r\nif (wufc & AT_WUFC_MAG)\r\nwol_ctrl_data |= WOL_MAGIC_EN | WOL_MAGIC_PME_EN;\r\nif (wufc & AT_WUFC_LNKC) {\r\nif (mii_bmsr_data & BMSR_LSTATUS) {\r\nfor (i = 0; i < AT_SUSPEND_LINK_TIMEOUT; i++) {\r\nmsleep(100);\r\natl1e_read_phy_reg(hw, MII_BMSR,\r\n&mii_bmsr_data);\r\nif (mii_bmsr_data & BMSR_LSTATUS)\r\nbreak;\r\n}\r\nif ((mii_bmsr_data & BMSR_LSTATUS) == 0)\r\nnetdev_dbg(adapter->netdev,\r\n"Link may change when suspend\n");\r\n}\r\nwol_ctrl_data |= WOL_LINK_CHG_EN | WOL_LINK_CHG_PME_EN;\r\nif (atl1e_write_phy_reg(hw, MII_INT_CTRL, 0x400) != 0) {\r\nnetdev_dbg(adapter->netdev,\r\n"read write phy register failed\n");\r\ngoto wol_dis;\r\n}\r\n}\r\natl1e_read_phy_reg(hw, MII_INT_STATUS, &mii_intr_status_data);\r\nmac_ctrl_data = MAC_CTRL_RX_EN;\r\nmac_ctrl_data |= MAC_CTRL_SPEED_10_100 << MAC_CTRL_SPEED_SHIFT;\r\nmac_ctrl_data |= (((u32)adapter->hw.preamble_len &\r\nMAC_CTRL_PRMLEN_MASK) <<\r\nMAC_CTRL_PRMLEN_SHIFT);\r\n__atl1e_vlan_mode(netdev->features, &mac_ctrl_data);\r\nif (wufc & AT_WUFC_MAG)\r\nmac_ctrl_data |= MAC_CTRL_BC_EN;\r\nnetdev_dbg(adapter->netdev, "suspend MAC=0x%x\n",\r\nmac_ctrl_data);\r\nAT_WRITE_REG(hw, REG_WOL_CTRL, wol_ctrl_data);\r\nAT_WRITE_REG(hw, REG_MAC_CTRL, mac_ctrl_data);\r\nctrl = AT_READ_REG(hw, REG_PCIE_PHYMISC);\r\nctrl |= PCIE_PHYMISC_FORCE_RCV_DET;\r\nAT_WRITE_REG(hw, REG_PCIE_PHYMISC, ctrl);\r\npci_enable_wake(pdev, pci_choose_state(pdev, state), 1);\r\ngoto suspend_exit;\r\n}\r\nwol_dis:\r\nAT_WRITE_REG(hw, REG_WOL_CTRL, 0);\r\nctrl = AT_READ_REG(hw, REG_PCIE_PHYMISC);\r\nctrl |= PCIE_PHYMISC_FORCE_RCV_DET;\r\nAT_WRITE_REG(hw, REG_PCIE_PHYMISC, ctrl);\r\natl1e_force_ps(hw);\r\nhw->phy_configured = false;\r\npci_enable_wake(pdev, pci_choose_state(pdev, state), 0);\r\nsuspend_exit:\r\nif (netif_running(netdev))\r\natl1e_free_irq(adapter);\r\npci_disable_device(pdev);\r\npci_set_power_state(pdev, pci_choose_state(pdev, state));\r\nreturn 0;\r\n}\r\nstatic int atl1e_resume(struct pci_dev *pdev)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\nu32 err;\r\npci_set_power_state(pdev, PCI_D0);\r\npci_restore_state(pdev);\r\nerr = pci_enable_device(pdev);\r\nif (err) {\r\nnetdev_err(adapter->netdev,\r\n"Cannot enable PCI device from suspend\n");\r\nreturn err;\r\n}\r\npci_set_master(pdev);\r\nAT_READ_REG(&adapter->hw, REG_WOL_CTRL);\r\npci_enable_wake(pdev, PCI_D3hot, 0);\r\npci_enable_wake(pdev, PCI_D3cold, 0);\r\nAT_WRITE_REG(&adapter->hw, REG_WOL_CTRL, 0);\r\nif (netif_running(netdev)) {\r\nerr = atl1e_request_irq(adapter);\r\nif (err)\r\nreturn err;\r\n}\r\natl1e_reset_hw(&adapter->hw);\r\nif (netif_running(netdev))\r\natl1e_up(adapter);\r\nnetif_device_attach(netdev);\r\nreturn 0;\r\n}\r\nstatic void atl1e_shutdown(struct pci_dev *pdev)\r\n{\r\natl1e_suspend(pdev, PMSG_SUSPEND);\r\n}\r\nstatic int atl1e_init_netdev(struct net_device *netdev, struct pci_dev *pdev)\r\n{\r\nSET_NETDEV_DEV(netdev, &pdev->dev);\r\npci_set_drvdata(pdev, netdev);\r\nnetdev->netdev_ops = &atl1e_netdev_ops;\r\nnetdev->watchdog_timeo = AT_TX_WATCHDOG;\r\natl1e_set_ethtool_ops(netdev);\r\nnetdev->hw_features = NETIF_F_SG | NETIF_F_HW_CSUM | NETIF_F_TSO |\r\nNETIF_F_HW_VLAN_CTAG_RX;\r\nnetdev->features = netdev->hw_features | NETIF_F_HW_VLAN_CTAG_TX;\r\nnetdev->hw_features |= NETIF_F_RXALL | NETIF_F_RXFCS;\r\nreturn 0;\r\n}\r\nstatic int atl1e_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\r\n{\r\nstruct net_device *netdev;\r\nstruct atl1e_adapter *adapter = NULL;\r\nstatic int cards_found;\r\nint err = 0;\r\nerr = pci_enable_device(pdev);\r\nif (err) {\r\ndev_err(&pdev->dev, "cannot enable PCI device\n");\r\nreturn err;\r\n}\r\nif ((pci_set_dma_mask(pdev, DMA_BIT_MASK(32)) != 0) ||\r\n(pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32)) != 0)) {\r\ndev_err(&pdev->dev, "No usable DMA configuration,aborting\n");\r\ngoto err_dma;\r\n}\r\nerr = pci_request_regions(pdev, atl1e_driver_name);\r\nif (err) {\r\ndev_err(&pdev->dev, "cannot obtain PCI resources\n");\r\ngoto err_pci_reg;\r\n}\r\npci_set_master(pdev);\r\nnetdev = alloc_etherdev(sizeof(struct atl1e_adapter));\r\nif (netdev == NULL) {\r\nerr = -ENOMEM;\r\ngoto err_alloc_etherdev;\r\n}\r\nerr = atl1e_init_netdev(netdev, pdev);\r\nif (err) {\r\nnetdev_err(netdev, "init netdevice failed\n");\r\ngoto err_init_netdev;\r\n}\r\nadapter = netdev_priv(netdev);\r\nadapter->bd_number = cards_found;\r\nadapter->netdev = netdev;\r\nadapter->pdev = pdev;\r\nadapter->hw.adapter = adapter;\r\nadapter->hw.hw_addr = pci_iomap(pdev, BAR_0, 0);\r\nif (!adapter->hw.hw_addr) {\r\nerr = -EIO;\r\nnetdev_err(netdev, "cannot map device registers\n");\r\ngoto err_ioremap;\r\n}\r\nadapter->mii.dev = netdev;\r\nadapter->mii.mdio_read = atl1e_mdio_read;\r\nadapter->mii.mdio_write = atl1e_mdio_write;\r\nadapter->mii.phy_id_mask = 0x1f;\r\nadapter->mii.reg_num_mask = MDIO_REG_ADDR_MASK;\r\nnetif_napi_add(netdev, &adapter->napi, atl1e_clean, 64);\r\nsetup_timer(&adapter->phy_config_timer, atl1e_phy_config,\r\n(unsigned long)adapter);\r\natl1e_check_options(adapter);\r\natl1e_setup_pcicmd(pdev);\r\nerr = atl1e_sw_init(adapter);\r\nif (err) {\r\nnetdev_err(netdev, "net device private data init failed\n");\r\ngoto err_sw_init;\r\n}\r\natl1e_phy_init(&adapter->hw);\r\nerr = atl1e_reset_hw(&adapter->hw);\r\nif (err) {\r\nerr = -EIO;\r\ngoto err_reset;\r\n}\r\nif (atl1e_read_mac_addr(&adapter->hw) != 0) {\r\nerr = -EIO;\r\nnetdev_err(netdev, "get mac address failed\n");\r\ngoto err_eeprom;\r\n}\r\nmemcpy(netdev->dev_addr, adapter->hw.mac_addr, netdev->addr_len);\r\nnetdev_dbg(netdev, "mac address : %pM\n", adapter->hw.mac_addr);\r\nINIT_WORK(&adapter->reset_task, atl1e_reset_task);\r\nINIT_WORK(&adapter->link_chg_task, atl1e_link_chg_task);\r\nnetif_set_gso_max_size(netdev, MAX_TSO_SEG_SIZE);\r\nerr = register_netdev(netdev);\r\nif (err) {\r\nnetdev_err(netdev, "register netdevice failed\n");\r\ngoto err_register;\r\n}\r\nnetif_stop_queue(netdev);\r\nnetif_carrier_off(netdev);\r\ncards_found++;\r\nreturn 0;\r\nerr_reset:\r\nerr_register:\r\nerr_sw_init:\r\nerr_eeprom:\r\npci_iounmap(pdev, adapter->hw.hw_addr);\r\nerr_init_netdev:\r\nerr_ioremap:\r\nfree_netdev(netdev);\r\nerr_alloc_etherdev:\r\npci_release_regions(pdev);\r\nerr_pci_reg:\r\nerr_dma:\r\npci_disable_device(pdev);\r\nreturn err;\r\n}\r\nstatic void atl1e_remove(struct pci_dev *pdev)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\nset_bit(__AT_DOWN, &adapter->flags);\r\natl1e_del_timer(adapter);\r\natl1e_cancel_work(adapter);\r\nunregister_netdev(netdev);\r\natl1e_free_ring_resources(adapter);\r\natl1e_force_ps(&adapter->hw);\r\npci_iounmap(pdev, adapter->hw.hw_addr);\r\npci_release_regions(pdev);\r\nfree_netdev(netdev);\r\npci_disable_device(pdev);\r\n}\r\nstatic pci_ers_result_t\r\natl1e_io_error_detected(struct pci_dev *pdev, pci_channel_state_t state)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\nnetif_device_detach(netdev);\r\nif (state == pci_channel_io_perm_failure)\r\nreturn PCI_ERS_RESULT_DISCONNECT;\r\nif (netif_running(netdev))\r\natl1e_down(adapter);\r\npci_disable_device(pdev);\r\nreturn PCI_ERS_RESULT_NEED_RESET;\r\n}\r\nstatic pci_ers_result_t atl1e_io_slot_reset(struct pci_dev *pdev)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\nif (pci_enable_device(pdev)) {\r\nnetdev_err(adapter->netdev,\r\n"Cannot re-enable PCI device after reset\n");\r\nreturn PCI_ERS_RESULT_DISCONNECT;\r\n}\r\npci_set_master(pdev);\r\npci_enable_wake(pdev, PCI_D3hot, 0);\r\npci_enable_wake(pdev, PCI_D3cold, 0);\r\natl1e_reset_hw(&adapter->hw);\r\nreturn PCI_ERS_RESULT_RECOVERED;\r\n}\r\nstatic void atl1e_io_resume(struct pci_dev *pdev)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct atl1e_adapter *adapter = netdev_priv(netdev);\r\nif (netif_running(netdev)) {\r\nif (atl1e_up(adapter)) {\r\nnetdev_err(adapter->netdev,\r\n"can't bring device back up after reset\n");\r\nreturn;\r\n}\r\n}\r\nnetif_device_attach(netdev);\r\n}
