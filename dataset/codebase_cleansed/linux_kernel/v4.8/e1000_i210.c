static s32 igb_get_hw_semaphore_i210(struct e1000_hw *hw)\r\n{\r\nu32 swsm;\r\ns32 timeout = hw->nvm.word_size + 1;\r\ns32 i = 0;\r\nwhile (i < timeout) {\r\nswsm = rd32(E1000_SWSM);\r\nif (!(swsm & E1000_SWSM_SMBI))\r\nbreak;\r\nudelay(50);\r\ni++;\r\n}\r\nif (i == timeout) {\r\nif (hw->dev_spec._82575.clear_semaphore_once) {\r\nhw->dev_spec._82575.clear_semaphore_once = false;\r\nigb_put_hw_semaphore(hw);\r\nfor (i = 0; i < timeout; i++) {\r\nswsm = rd32(E1000_SWSM);\r\nif (!(swsm & E1000_SWSM_SMBI))\r\nbreak;\r\nudelay(50);\r\n}\r\n}\r\nif (i == timeout) {\r\nhw_dbg("Driver can't access device - SMBI bit is set.\n");\r\nreturn -E1000_ERR_NVM;\r\n}\r\n}\r\nfor (i = 0; i < timeout; i++) {\r\nswsm = rd32(E1000_SWSM);\r\nwr32(E1000_SWSM, swsm | E1000_SWSM_SWESMBI);\r\nif (rd32(E1000_SWSM) & E1000_SWSM_SWESMBI)\r\nbreak;\r\nudelay(50);\r\n}\r\nif (i == timeout) {\r\nigb_put_hw_semaphore(hw);\r\nhw_dbg("Driver can't access the NVM\n");\r\nreturn -E1000_ERR_NVM;\r\n}\r\nreturn 0;\r\n}\r\nstatic s32 igb_acquire_nvm_i210(struct e1000_hw *hw)\r\n{\r\nreturn igb_acquire_swfw_sync_i210(hw, E1000_SWFW_EEP_SM);\r\n}\r\nstatic void igb_release_nvm_i210(struct e1000_hw *hw)\r\n{\r\nigb_release_swfw_sync_i210(hw, E1000_SWFW_EEP_SM);\r\n}\r\ns32 igb_acquire_swfw_sync_i210(struct e1000_hw *hw, u16 mask)\r\n{\r\nu32 swfw_sync;\r\nu32 swmask = mask;\r\nu32 fwmask = mask << 16;\r\ns32 ret_val = 0;\r\ns32 i = 0, timeout = 200;\r\nwhile (i < timeout) {\r\nif (igb_get_hw_semaphore_i210(hw)) {\r\nret_val = -E1000_ERR_SWFW_SYNC;\r\ngoto out;\r\n}\r\nswfw_sync = rd32(E1000_SW_FW_SYNC);\r\nif (!(swfw_sync & (fwmask | swmask)))\r\nbreak;\r\nigb_put_hw_semaphore(hw);\r\nmdelay(5);\r\ni++;\r\n}\r\nif (i == timeout) {\r\nhw_dbg("Driver can't access resource, SW_FW_SYNC timeout.\n");\r\nret_val = -E1000_ERR_SWFW_SYNC;\r\ngoto out;\r\n}\r\nswfw_sync |= swmask;\r\nwr32(E1000_SW_FW_SYNC, swfw_sync);\r\nigb_put_hw_semaphore(hw);\r\nout:\r\nreturn ret_val;\r\n}\r\nvoid igb_release_swfw_sync_i210(struct e1000_hw *hw, u16 mask)\r\n{\r\nu32 swfw_sync;\r\nwhile (igb_get_hw_semaphore_i210(hw))\r\n;\r\nswfw_sync = rd32(E1000_SW_FW_SYNC);\r\nswfw_sync &= ~mask;\r\nwr32(E1000_SW_FW_SYNC, swfw_sync);\r\nigb_put_hw_semaphore(hw);\r\n}\r\nstatic s32 igb_read_nvm_srrd_i210(struct e1000_hw *hw, u16 offset, u16 words,\r\nu16 *data)\r\n{\r\ns32 status = 0;\r\nu16 i, count;\r\nfor (i = 0; i < words; i += E1000_EERD_EEWR_MAX_COUNT) {\r\ncount = (words - i) / E1000_EERD_EEWR_MAX_COUNT > 0 ?\r\nE1000_EERD_EEWR_MAX_COUNT : (words - i);\r\nif (!(hw->nvm.ops.acquire(hw))) {\r\nstatus = igb_read_nvm_eerd(hw, offset, count,\r\ndata + i);\r\nhw->nvm.ops.release(hw);\r\n} else {\r\nstatus = E1000_ERR_SWFW_SYNC;\r\n}\r\nif (status)\r\nbreak;\r\n}\r\nreturn status;\r\n}\r\nstatic s32 igb_write_nvm_srwr(struct e1000_hw *hw, u16 offset, u16 words,\r\nu16 *data)\r\n{\r\nstruct e1000_nvm_info *nvm = &hw->nvm;\r\nu32 i, k, eewr = 0;\r\nu32 attempts = 100000;\r\ns32 ret_val = 0;\r\nif ((offset >= nvm->word_size) || (words > (nvm->word_size - offset)) ||\r\n(words == 0)) {\r\nhw_dbg("nvm parameter(s) out of bounds\n");\r\nret_val = -E1000_ERR_NVM;\r\ngoto out;\r\n}\r\nfor (i = 0; i < words; i++) {\r\neewr = ((offset+i) << E1000_NVM_RW_ADDR_SHIFT) |\r\n(data[i] << E1000_NVM_RW_REG_DATA) |\r\nE1000_NVM_RW_REG_START;\r\nwr32(E1000_SRWR, eewr);\r\nfor (k = 0; k < attempts; k++) {\r\nif (E1000_NVM_RW_REG_DONE &\r\nrd32(E1000_SRWR)) {\r\nret_val = 0;\r\nbreak;\r\n}\r\nudelay(5);\r\n}\r\nif (ret_val) {\r\nhw_dbg("Shadow RAM write EEWR timed out\n");\r\nbreak;\r\n}\r\n}\r\nout:\r\nreturn ret_val;\r\n}\r\nstatic s32 igb_write_nvm_srwr_i210(struct e1000_hw *hw, u16 offset, u16 words,\r\nu16 *data)\r\n{\r\ns32 status = 0;\r\nu16 i, count;\r\nfor (i = 0; i < words; i += E1000_EERD_EEWR_MAX_COUNT) {\r\ncount = (words - i) / E1000_EERD_EEWR_MAX_COUNT > 0 ?\r\nE1000_EERD_EEWR_MAX_COUNT : (words - i);\r\nif (!(hw->nvm.ops.acquire(hw))) {\r\nstatus = igb_write_nvm_srwr(hw, offset, count,\r\ndata + i);\r\nhw->nvm.ops.release(hw);\r\n} else {\r\nstatus = E1000_ERR_SWFW_SYNC;\r\n}\r\nif (status)\r\nbreak;\r\n}\r\nreturn status;\r\n}\r\nstatic s32 igb_read_invm_word_i210(struct e1000_hw *hw, u8 address, u16 *data)\r\n{\r\ns32 status = -E1000_ERR_INVM_VALUE_NOT_FOUND;\r\nu32 invm_dword;\r\nu16 i;\r\nu8 record_type, word_address;\r\nfor (i = 0; i < E1000_INVM_SIZE; i++) {\r\ninvm_dword = rd32(E1000_INVM_DATA_REG(i));\r\nrecord_type = INVM_DWORD_TO_RECORD_TYPE(invm_dword);\r\nif (record_type == E1000_INVM_UNINITIALIZED_STRUCTURE)\r\nbreak;\r\nif (record_type == E1000_INVM_CSR_AUTOLOAD_STRUCTURE)\r\ni += E1000_INVM_CSR_AUTOLOAD_DATA_SIZE_IN_DWORDS;\r\nif (record_type == E1000_INVM_RSA_KEY_SHA256_STRUCTURE)\r\ni += E1000_INVM_RSA_KEY_SHA256_DATA_SIZE_IN_DWORDS;\r\nif (record_type == E1000_INVM_WORD_AUTOLOAD_STRUCTURE) {\r\nword_address = INVM_DWORD_TO_WORD_ADDRESS(invm_dword);\r\nif (word_address == address) {\r\n*data = INVM_DWORD_TO_WORD_DATA(invm_dword);\r\nhw_dbg("Read INVM Word 0x%02x = %x\n",\r\naddress, *data);\r\nstatus = 0;\r\nbreak;\r\n}\r\n}\r\n}\r\nif (status)\r\nhw_dbg("Requested word 0x%02x not found in OTP\n", address);\r\nreturn status;\r\n}\r\nstatic s32 igb_read_invm_i210(struct e1000_hw *hw, u16 offset,\r\nu16 words __always_unused, u16 *data)\r\n{\r\ns32 ret_val = 0;\r\nswitch (offset) {\r\ncase NVM_MAC_ADDR:\r\nret_val = igb_read_invm_word_i210(hw, (u8)offset, &data[0]);\r\nret_val |= igb_read_invm_word_i210(hw, (u8)offset+1,\r\n&data[1]);\r\nret_val |= igb_read_invm_word_i210(hw, (u8)offset+2,\r\n&data[2]);\r\nif (ret_val)\r\nhw_dbg("MAC Addr not found in iNVM\n");\r\nbreak;\r\ncase NVM_INIT_CTRL_2:\r\nret_val = igb_read_invm_word_i210(hw, (u8)offset, data);\r\nif (ret_val) {\r\n*data = NVM_INIT_CTRL_2_DEFAULT_I211;\r\nret_val = 0;\r\n}\r\nbreak;\r\ncase NVM_INIT_CTRL_4:\r\nret_val = igb_read_invm_word_i210(hw, (u8)offset, data);\r\nif (ret_val) {\r\n*data = NVM_INIT_CTRL_4_DEFAULT_I211;\r\nret_val = 0;\r\n}\r\nbreak;\r\ncase NVM_LED_1_CFG:\r\nret_val = igb_read_invm_word_i210(hw, (u8)offset, data);\r\nif (ret_val) {\r\n*data = NVM_LED_1_CFG_DEFAULT_I211;\r\nret_val = 0;\r\n}\r\nbreak;\r\ncase NVM_LED_0_2_CFG:\r\nret_val = igb_read_invm_word_i210(hw, (u8)offset, data);\r\nif (ret_val) {\r\n*data = NVM_LED_0_2_CFG_DEFAULT_I211;\r\nret_val = 0;\r\n}\r\nbreak;\r\ncase NVM_ID_LED_SETTINGS:\r\nret_val = igb_read_invm_word_i210(hw, (u8)offset, data);\r\nif (ret_val) {\r\n*data = ID_LED_RESERVED_FFFF;\r\nret_val = 0;\r\n}\r\nbreak;\r\ncase NVM_SUB_DEV_ID:\r\n*data = hw->subsystem_device_id;\r\nbreak;\r\ncase NVM_SUB_VEN_ID:\r\n*data = hw->subsystem_vendor_id;\r\nbreak;\r\ncase NVM_DEV_ID:\r\n*data = hw->device_id;\r\nbreak;\r\ncase NVM_VEN_ID:\r\n*data = hw->vendor_id;\r\nbreak;\r\ndefault:\r\nhw_dbg("NVM word 0x%02x is not mapped.\n", offset);\r\n*data = NVM_RESERVED_WORD;\r\nbreak;\r\n}\r\nreturn ret_val;\r\n}\r\ns32 igb_read_invm_version(struct e1000_hw *hw,\r\nstruct e1000_fw_version *invm_ver) {\r\nu32 *record = NULL;\r\nu32 *next_record = NULL;\r\nu32 i = 0;\r\nu32 invm_dword = 0;\r\nu32 invm_blocks = E1000_INVM_SIZE - (E1000_INVM_ULT_BYTES_SIZE /\r\nE1000_INVM_RECORD_SIZE_IN_BYTES);\r\nu32 buffer[E1000_INVM_SIZE];\r\ns32 status = -E1000_ERR_INVM_VALUE_NOT_FOUND;\r\nu16 version = 0;\r\nfor (i = 0; i < E1000_INVM_SIZE; i++) {\r\ninvm_dword = rd32(E1000_INVM_DATA_REG(i));\r\nbuffer[i] = invm_dword;\r\n}\r\nfor (i = 1; i < invm_blocks; i++) {\r\nrecord = &buffer[invm_blocks - i];\r\nnext_record = &buffer[invm_blocks - i + 1];\r\nif ((i == 1) && ((*record & E1000_INVM_VER_FIELD_ONE) == 0)) {\r\nversion = 0;\r\nstatus = 0;\r\nbreak;\r\n}\r\nelse if ((i == 1) &&\r\n((*record & E1000_INVM_VER_FIELD_TWO) == 0)) {\r\nversion = (*record & E1000_INVM_VER_FIELD_ONE) >> 3;\r\nstatus = 0;\r\nbreak;\r\n}\r\nelse if ((((*record & E1000_INVM_VER_FIELD_ONE) == 0) &&\r\n((*record & 0x3) == 0)) || (((*record & 0x3) != 0) &&\r\n(i != 1))) {\r\nversion = (*next_record & E1000_INVM_VER_FIELD_TWO)\r\n>> 13;\r\nstatus = 0;\r\nbreak;\r\n}\r\nelse if (((*record & E1000_INVM_VER_FIELD_TWO) == 0) &&\r\n((*record & 0x3) == 0)) {\r\nversion = (*record & E1000_INVM_VER_FIELD_ONE) >> 3;\r\nstatus = 0;\r\nbreak;\r\n}\r\n}\r\nif (!status) {\r\ninvm_ver->invm_major = (version & E1000_INVM_MAJOR_MASK)\r\n>> E1000_INVM_MAJOR_SHIFT;\r\ninvm_ver->invm_minor = version & E1000_INVM_MINOR_MASK;\r\n}\r\nfor (i = 1; i < invm_blocks; i++) {\r\nrecord = &buffer[invm_blocks - i];\r\nnext_record = &buffer[invm_blocks - i + 1];\r\nif ((i == 1) && ((*record & E1000_INVM_IMGTYPE_FIELD) == 0)) {\r\ninvm_ver->invm_img_type = 0;\r\nstatus = 0;\r\nbreak;\r\n}\r\nelse if ((((*record & 0x3) == 0) &&\r\n((*record & E1000_INVM_IMGTYPE_FIELD) == 0)) ||\r\n((((*record & 0x3) != 0) && (i != 1)))) {\r\ninvm_ver->invm_img_type =\r\n(*next_record & E1000_INVM_IMGTYPE_FIELD) >> 23;\r\nstatus = 0;\r\nbreak;\r\n}\r\n}\r\nreturn status;\r\n}\r\nstatic s32 igb_validate_nvm_checksum_i210(struct e1000_hw *hw)\r\n{\r\ns32 status = 0;\r\ns32 (*read_op_ptr)(struct e1000_hw *, u16, u16, u16 *);\r\nif (!(hw->nvm.ops.acquire(hw))) {\r\nread_op_ptr = hw->nvm.ops.read;\r\nhw->nvm.ops.read = igb_read_nvm_eerd;\r\nstatus = igb_validate_nvm_checksum(hw);\r\nhw->nvm.ops.read = read_op_ptr;\r\nhw->nvm.ops.release(hw);\r\n} else {\r\nstatus = E1000_ERR_SWFW_SYNC;\r\n}\r\nreturn status;\r\n}\r\nstatic s32 igb_update_nvm_checksum_i210(struct e1000_hw *hw)\r\n{\r\ns32 ret_val = 0;\r\nu16 checksum = 0;\r\nu16 i, nvm_data;\r\nret_val = igb_read_nvm_eerd(hw, 0, 1, &nvm_data);\r\nif (ret_val) {\r\nhw_dbg("EEPROM read failed\n");\r\ngoto out;\r\n}\r\nif (!(hw->nvm.ops.acquire(hw))) {\r\nfor (i = 0; i < NVM_CHECKSUM_REG; i++) {\r\nret_val = igb_read_nvm_eerd(hw, i, 1, &nvm_data);\r\nif (ret_val) {\r\nhw->nvm.ops.release(hw);\r\nhw_dbg("NVM Read Error while updating checksum.\n");\r\ngoto out;\r\n}\r\nchecksum += nvm_data;\r\n}\r\nchecksum = (u16) NVM_SUM - checksum;\r\nret_val = igb_write_nvm_srwr(hw, NVM_CHECKSUM_REG, 1,\r\n&checksum);\r\nif (ret_val) {\r\nhw->nvm.ops.release(hw);\r\nhw_dbg("NVM Write Error while updating checksum.\n");\r\ngoto out;\r\n}\r\nhw->nvm.ops.release(hw);\r\nret_val = igb_update_flash_i210(hw);\r\n} else {\r\nret_val = -E1000_ERR_SWFW_SYNC;\r\n}\r\nout:\r\nreturn ret_val;\r\n}\r\nstatic s32 igb_pool_flash_update_done_i210(struct e1000_hw *hw)\r\n{\r\ns32 ret_val = -E1000_ERR_NVM;\r\nu32 i, reg;\r\nfor (i = 0; i < E1000_FLUDONE_ATTEMPTS; i++) {\r\nreg = rd32(E1000_EECD);\r\nif (reg & E1000_EECD_FLUDONE_I210) {\r\nret_val = 0;\r\nbreak;\r\n}\r\nudelay(5);\r\n}\r\nreturn ret_val;\r\n}\r\nbool igb_get_flash_presence_i210(struct e1000_hw *hw)\r\n{\r\nu32 eec = 0;\r\nbool ret_val = false;\r\neec = rd32(E1000_EECD);\r\nif (eec & E1000_EECD_FLASH_DETECTED_I210)\r\nret_val = true;\r\nreturn ret_val;\r\n}\r\nstatic s32 igb_update_flash_i210(struct e1000_hw *hw)\r\n{\r\ns32 ret_val = 0;\r\nu32 flup;\r\nret_val = igb_pool_flash_update_done_i210(hw);\r\nif (ret_val == -E1000_ERR_NVM) {\r\nhw_dbg("Flash update time out\n");\r\ngoto out;\r\n}\r\nflup = rd32(E1000_EECD) | E1000_EECD_FLUPD_I210;\r\nwr32(E1000_EECD, flup);\r\nret_val = igb_pool_flash_update_done_i210(hw);\r\nif (ret_val)\r\nhw_dbg("Flash update complete\n");\r\nelse\r\nhw_dbg("Flash update time out\n");\r\nout:\r\nreturn ret_val;\r\n}\r\ns32 igb_valid_led_default_i210(struct e1000_hw *hw, u16 *data)\r\n{\r\ns32 ret_val;\r\nret_val = hw->nvm.ops.read(hw, NVM_ID_LED_SETTINGS, 1, data);\r\nif (ret_val) {\r\nhw_dbg("NVM Read Error\n");\r\ngoto out;\r\n}\r\nif (*data == ID_LED_RESERVED_0000 || *data == ID_LED_RESERVED_FFFF) {\r\nswitch (hw->phy.media_type) {\r\ncase e1000_media_type_internal_serdes:\r\n*data = ID_LED_DEFAULT_I210_SERDES;\r\nbreak;\r\ncase e1000_media_type_copper:\r\ndefault:\r\n*data = ID_LED_DEFAULT_I210;\r\nbreak;\r\n}\r\n}\r\nout:\r\nreturn ret_val;\r\n}\r\nstatic s32 __igb_access_xmdio_reg(struct e1000_hw *hw, u16 address,\r\nu8 dev_addr, u16 *data, bool read)\r\n{\r\ns32 ret_val = 0;\r\nret_val = hw->phy.ops.write_reg(hw, E1000_MMDAC, dev_addr);\r\nif (ret_val)\r\nreturn ret_val;\r\nret_val = hw->phy.ops.write_reg(hw, E1000_MMDAAD, address);\r\nif (ret_val)\r\nreturn ret_val;\r\nret_val = hw->phy.ops.write_reg(hw, E1000_MMDAC, E1000_MMDAC_FUNC_DATA |\r\ndev_addr);\r\nif (ret_val)\r\nreturn ret_val;\r\nif (read)\r\nret_val = hw->phy.ops.read_reg(hw, E1000_MMDAAD, data);\r\nelse\r\nret_val = hw->phy.ops.write_reg(hw, E1000_MMDAAD, *data);\r\nif (ret_val)\r\nreturn ret_val;\r\nret_val = hw->phy.ops.write_reg(hw, E1000_MMDAC, 0);\r\nif (ret_val)\r\nreturn ret_val;\r\nreturn ret_val;\r\n}\r\ns32 igb_read_xmdio_reg(struct e1000_hw *hw, u16 addr, u8 dev_addr, u16 *data)\r\n{\r\nreturn __igb_access_xmdio_reg(hw, addr, dev_addr, data, true);\r\n}\r\ns32 igb_write_xmdio_reg(struct e1000_hw *hw, u16 addr, u8 dev_addr, u16 data)\r\n{\r\nreturn __igb_access_xmdio_reg(hw, addr, dev_addr, &data, false);\r\n}\r\ns32 igb_init_nvm_params_i210(struct e1000_hw *hw)\r\n{\r\ns32 ret_val = 0;\r\nstruct e1000_nvm_info *nvm = &hw->nvm;\r\nnvm->ops.acquire = igb_acquire_nvm_i210;\r\nnvm->ops.release = igb_release_nvm_i210;\r\nnvm->ops.valid_led_default = igb_valid_led_default_i210;\r\nif (igb_get_flash_presence_i210(hw)) {\r\nhw->nvm.type = e1000_nvm_flash_hw;\r\nnvm->ops.read = igb_read_nvm_srrd_i210;\r\nnvm->ops.write = igb_write_nvm_srwr_i210;\r\nnvm->ops.validate = igb_validate_nvm_checksum_i210;\r\nnvm->ops.update = igb_update_nvm_checksum_i210;\r\n} else {\r\nhw->nvm.type = e1000_nvm_invm;\r\nnvm->ops.read = igb_read_invm_i210;\r\nnvm->ops.write = NULL;\r\nnvm->ops.validate = NULL;\r\nnvm->ops.update = NULL;\r\n}\r\nreturn ret_val;\r\n}\r\ns32 igb_pll_workaround_i210(struct e1000_hw *hw)\r\n{\r\ns32 ret_val;\r\nu32 wuc, mdicnfg, ctrl, ctrl_ext, reg_val;\r\nu16 nvm_word, phy_word, pci_word, tmp_nvm;\r\nint i;\r\nwuc = rd32(E1000_WUC);\r\nmdicnfg = rd32(E1000_MDICNFG);\r\nreg_val = mdicnfg & ~E1000_MDICNFG_EXT_MDIO;\r\nwr32(E1000_MDICNFG, reg_val);\r\nret_val = igb_read_invm_word_i210(hw, E1000_INVM_AUTOLOAD,\r\n&nvm_word);\r\nif (ret_val)\r\nnvm_word = E1000_INVM_DEFAULT_AL;\r\ntmp_nvm = nvm_word | E1000_INVM_PLL_WO_VAL;\r\nigb_write_phy_reg_82580(hw, I347AT4_PAGE_SELECT, E1000_PHY_PLL_FREQ_PAGE);\r\nfor (i = 0; i < E1000_MAX_PLL_TRIES; i++) {\r\nigb_read_phy_reg_82580(hw, E1000_PHY_PLL_FREQ_REG, &phy_word);\r\nif ((phy_word & E1000_PHY_PLL_UNCONF)\r\n!= E1000_PHY_PLL_UNCONF) {\r\nret_val = 0;\r\nbreak;\r\n} else {\r\nret_val = -E1000_ERR_PHY;\r\n}\r\nctrl = rd32(E1000_CTRL);\r\nwr32(E1000_CTRL, ctrl|E1000_CTRL_PHY_RST);\r\nctrl_ext = rd32(E1000_CTRL_EXT);\r\nctrl_ext |= (E1000_CTRL_EXT_PHYPDEN | E1000_CTRL_EXT_SDLPE);\r\nwr32(E1000_CTRL_EXT, ctrl_ext);\r\nwr32(E1000_WUC, 0);\r\nreg_val = (E1000_INVM_AUTOLOAD << 4) | (tmp_nvm << 16);\r\nwr32(E1000_EEARBC_I210, reg_val);\r\nigb_read_pci_cfg(hw, E1000_PCI_PMCSR, &pci_word);\r\npci_word |= E1000_PCI_PMCSR_D3;\r\nigb_write_pci_cfg(hw, E1000_PCI_PMCSR, &pci_word);\r\nusleep_range(1000, 2000);\r\npci_word &= ~E1000_PCI_PMCSR_D3;\r\nigb_write_pci_cfg(hw, E1000_PCI_PMCSR, &pci_word);\r\nreg_val = (E1000_INVM_AUTOLOAD << 4) | (nvm_word << 16);\r\nwr32(E1000_EEARBC_I210, reg_val);\r\nwr32(E1000_WUC, wuc);\r\n}\r\nigb_write_phy_reg_82580(hw, I347AT4_PAGE_SELECT, 0);\r\nwr32(E1000_MDICNFG, mdicnfg);\r\nreturn ret_val;\r\n}\r\ns32 igb_get_cfg_done_i210(struct e1000_hw *hw)\r\n{\r\ns32 timeout = PHY_CFG_TIMEOUT;\r\nu32 mask = E1000_NVM_CFG_DONE_PORT_0;\r\nwhile (timeout) {\r\nif (rd32(E1000_EEMNGCTL_I210) & mask)\r\nbreak;\r\nusleep_range(1000, 2000);\r\ntimeout--;\r\n}\r\nif (!timeout)\r\nhw_dbg("MNG configuration cycle has not completed.\n");\r\nreturn 0;\r\n}
