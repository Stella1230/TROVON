static void sh_sir_write(struct sh_sir_self *self, u32 offset, u16 data)\r\n{\r\niowrite16(data, self->membase + offset);\r\n}\r\nstatic u16 sh_sir_read(struct sh_sir_self *self, u32 offset)\r\n{\r\nreturn ioread16(self->membase + offset);\r\n}\r\nstatic void sh_sir_update_bits(struct sh_sir_self *self, u32 offset,\r\nu16 mask, u16 data)\r\n{\r\nu16 old, new;\r\nold = sh_sir_read(self, offset);\r\nnew = (old & ~mask) | data;\r\nif (old != new)\r\nsh_sir_write(self, offset, new);\r\n}\r\nstatic void sh_sir_crc_reset(struct sh_sir_self *self)\r\n{\r\nsh_sir_write(self, IRIF_CRC0, CRC_RST);\r\n}\r\nstatic void sh_sir_crc_add(struct sh_sir_self *self, u8 data)\r\n{\r\nsh_sir_write(self, IRIF_CRC1, (u16)data);\r\n}\r\nstatic u16 sh_sir_crc_cnt(struct sh_sir_self *self)\r\n{\r\nreturn CRC_CT_MASK & sh_sir_read(self, IRIF_CRC0);\r\n}\r\nstatic u16 sh_sir_crc_out(struct sh_sir_self *self)\r\n{\r\nreturn sh_sir_read(self, IRIF_CRC4);\r\n}\r\nstatic int sh_sir_crc_init(struct sh_sir_self *self)\r\n{\r\nstruct device *dev = &self->ndev->dev;\r\nint ret = -EIO;\r\nu16 val;\r\nsh_sir_crc_reset(self);\r\nsh_sir_crc_add(self, 0xCC);\r\nsh_sir_crc_add(self, 0xF5);\r\nsh_sir_crc_add(self, 0xF1);\r\nsh_sir_crc_add(self, 0xA7);\r\nval = sh_sir_crc_cnt(self);\r\nif (4 != val) {\r\ndev_err(dev, "CRC count error %x\n", val);\r\ngoto crc_init_out;\r\n}\r\nval = sh_sir_crc_out(self);\r\nif (0x51DF != val) {\r\ndev_err(dev, "CRC result error%x\n", val);\r\ngoto crc_init_out;\r\n}\r\nret = 0;\r\ncrc_init_out:\r\nsh_sir_crc_reset(self);\r\nreturn ret;\r\n}\r\nstatic u32 sh_sir_find_sclk(struct clk *irda_clk)\r\n{\r\nstruct cpufreq_frequency_table *freq_table = irda_clk->freq_table;\r\nstruct cpufreq_frequency_table *pos;\r\nstruct clk *pclk = clk_get(NULL, "peripheral_clk");\r\nu32 limit, min = 0xffffffff, tmp;\r\nint index = 0;\r\nlimit = clk_get_rate(pclk);\r\nclk_put(pclk);\r\ncpufreq_for_each_valid_entry(pos, freq_table) {\r\nu32 freq = pos->frequency;\r\nif (freq > limit)\r\ncontinue;\r\ntmp = freq % SCLK_BASE;\r\nif (tmp < min) {\r\nmin = tmp;\r\nindex = pos - freq_table;\r\n}\r\n}\r\nreturn freq_table[index].frequency;\r\n}\r\nstatic int sh_sir_set_baudrate(struct sh_sir_self *self, u32 baudrate)\r\n{\r\nstruct clk *clk;\r\nstruct device *dev = &self->ndev->dev;\r\nu32 rate;\r\nu16 uabca, uabc;\r\nu16 irbca, irbc;\r\nu32 min, rerr, tmp;\r\nint i;\r\nu32 rate_err_array[] = {\r\n0, 625, 1250, 1875,\r\n2500, 3125, 3750, 4375,\r\n5000, 5625, 6250, 6875,\r\n7500, 8125, 8750, 9375,\r\n};\r\nswitch (baudrate) {\r\ncase 9600:\r\nbreak;\r\ndefault:\r\ndev_err(dev, "un-supported baudrate %d\n", baudrate);\r\nreturn -EIO;\r\n}\r\nclk = clk_get(NULL, "irda_clk");\r\nif (IS_ERR(clk)) {\r\ndev_err(dev, "can not get irda_clk\n");\r\nreturn -EIO;\r\n}\r\nclk_set_rate(clk, sh_sir_find_sclk(clk));\r\nrate = clk_get_rate(clk);\r\nclk_put(clk);\r\ndev_dbg(dev, "selected sclk = %d\n", rate);\r\nirbc = rate / SCLK_BASE;\r\ntmp = rate - (SCLK_BASE * irbc);\r\ntmp *= 10000;\r\nrerr = tmp / SCLK_BASE;\r\nmin = 0xffffffff;\r\nirbca = 0;\r\nfor (i = 0; i < ARRAY_SIZE(rate_err_array); i++) {\r\ntmp = abs(rate_err_array[i] - rerr);\r\nif (min > tmp) {\r\nmin = tmp;\r\nirbca = i;\r\n}\r\n}\r\ntmp = rate / (irbc + ERR_ROUNDING(rate_err_array[irbca]));\r\nif ((SCLK_BASE / 100) < abs(tmp - SCLK_BASE))\r\ndev_warn(dev, "IrDA freq error margin over %d\n", tmp);\r\ndev_dbg(dev, "target = %d, result = %d, infrared = %d.%d\n",\r\nSCLK_BASE, tmp, irbc, rate_err_array[irbca]);\r\nirbca = (irbca & 0xF) << 4;\r\nirbc = (irbc - 1) & 0xF;\r\nif (!irbc) {\r\ndev_err(dev, "sh_sir can not set 0 in IRIF_SIR2\n");\r\nreturn -EIO;\r\n}\r\nsh_sir_write(self, IRIF_SIR0, IRTPW | IRERRC);\r\nsh_sir_write(self, IRIF_SIR1, irbca);\r\nsh_sir_write(self, IRIF_SIR2, irbc);\r\nuabc = rate / baudrate;\r\nuabc = (uabc / 16) - 1;\r\nuabc = (uabc + 1) * 16;\r\ntmp = rate - (uabc * baudrate);\r\ntmp *= 10000;\r\nrerr = tmp / baudrate;\r\nmin = 0xffffffff;\r\nuabca = 0;\r\nfor (i = 0; i < ARRAY_SIZE(rate_err_array); i++) {\r\ntmp = abs(rate_err_array[i] - rerr);\r\nif (min > tmp) {\r\nmin = tmp;\r\nuabca = i;\r\n}\r\n}\r\ntmp = rate / (uabc + ERR_ROUNDING(rate_err_array[uabca]));\r\nif ((baudrate / 100) < abs(tmp - baudrate))\r\ndev_warn(dev, "UART freq error margin over %d\n", tmp);\r\ndev_dbg(dev, "target = %d, result = %d, uart = %d.%d\n",\r\nbaudrate, tmp,\r\nuabc, rate_err_array[uabca]);\r\nuabca = (uabca & 0xF) << 4;\r\nuabc = (uabc / 16) - 1;\r\nsh_sir_write(self, IRIF_UART6, uabca);\r\nsh_sir_write(self, IRIF_UART7, uabc);\r\nreturn 0;\r\n}\r\nstatic int __sh_sir_init_iobuf(iobuff_t *io, int size)\r\n{\r\nio->head = kmalloc(size, GFP_KERNEL);\r\nif (!io->head)\r\nreturn -ENOMEM;\r\nio->truesize = size;\r\nio->in_frame = FALSE;\r\nio->state = OUTSIDE_FRAME;\r\nio->data = io->head;\r\nreturn 0;\r\n}\r\nstatic void sh_sir_remove_iobuf(struct sh_sir_self *self)\r\n{\r\nkfree(self->rx_buff.head);\r\nkfree(self->tx_buff.head);\r\nself->rx_buff.head = NULL;\r\nself->tx_buff.head = NULL;\r\n}\r\nstatic int sh_sir_init_iobuf(struct sh_sir_self *self, int rxsize, int txsize)\r\n{\r\nint err = -ENOMEM;\r\nif (self->rx_buff.head ||\r\nself->tx_buff.head) {\r\ndev_err(&self->ndev->dev, "iobuff has already existed.");\r\nreturn err;\r\n}\r\nerr = __sh_sir_init_iobuf(&self->rx_buff, rxsize);\r\nif (err)\r\ngoto iobuf_err;\r\nerr = __sh_sir_init_iobuf(&self->tx_buff, txsize);\r\niobuf_err:\r\nif (err)\r\nsh_sir_remove_iobuf(self);\r\nreturn err;\r\n}\r\nstatic void sh_sir_clear_all_err(struct sh_sir_self *self)\r\n{\r\nsh_sir_update_bits(self, IRIF_SIR0, IRERRC, IRERRC);\r\nsh_sir_write(self, IRIF_SIR_FLG, 0xffff);\r\nsh_sir_write(self, IRIF_UART_STS2, 0);\r\n}\r\nstatic void sh_sir_set_phase(struct sh_sir_self *self, int phase)\r\n{\r\nu16 uart5 = 0;\r\nu16 uart0 = 0;\r\nswitch (phase) {\r\ncase TX_PHASE:\r\nuart5 = TBEIM;\r\nuart0 = TBEC | TIE;\r\nbreak;\r\ncase TX_COMP_PHASE:\r\nuart5 = TSBEIM;\r\nuart0 = TIE;\r\nbreak;\r\ncase RX_PHASE:\r\nuart5 = RX_MASK;\r\nuart0 = RIE;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nsh_sir_write(self, IRIF_UART5, uart5);\r\nsh_sir_write(self, IRIF_UART0, uart0);\r\n}\r\nstatic int sh_sir_is_which_phase(struct sh_sir_self *self)\r\n{\r\nu16 val = sh_sir_read(self, IRIF_UART5);\r\nif (val & TBEIM)\r\nreturn TX_PHASE;\r\nif (val & TSBEIM)\r\nreturn TX_COMP_PHASE;\r\nif (val & RX_MASK)\r\nreturn RX_PHASE;\r\nreturn NONE_PHASE;\r\n}\r\nstatic void sh_sir_tx(struct sh_sir_self *self, int phase)\r\n{\r\nswitch (phase) {\r\ncase TX_PHASE:\r\nif (0 >= self->tx_buff.len) {\r\nsh_sir_set_phase(self, TX_COMP_PHASE);\r\n} else {\r\nsh_sir_write(self, IRIF_UART3, self->tx_buff.data[0]);\r\nself->tx_buff.len--;\r\nself->tx_buff.data++;\r\n}\r\nbreak;\r\ncase TX_COMP_PHASE:\r\nsh_sir_set_phase(self, RX_PHASE);\r\nnetif_wake_queue(self->ndev);\r\nbreak;\r\ndefault:\r\ndev_err(&self->ndev->dev, "should not happen\n");\r\nbreak;\r\n}\r\n}\r\nstatic int sh_sir_read_data(struct sh_sir_self *self)\r\n{\r\nu16 val = 0;\r\nint timeout = 1024;\r\nwhile (timeout--) {\r\nval = sh_sir_read(self, IRIF_UART1);\r\nif (val & RBF) {\r\nif (val & (URSME | UROVE | URFRE | URPRE))\r\nbreak;\r\nreturn (int)sh_sir_read(self, IRIF_UART4);\r\n}\r\nudelay(1);\r\n}\r\ndev_err(&self->ndev->dev, "UART1 %04x : STATUS %04x\n",\r\nval, sh_sir_read(self, IRIF_UART_STS2));\r\nsh_sir_read(self, IRIF_UART4);\r\nreturn -1;\r\n}\r\nstatic void sh_sir_rx(struct sh_sir_self *self)\r\n{\r\nint timeout = 1024;\r\nint data;\r\nwhile (timeout--) {\r\ndata = sh_sir_read_data(self);\r\nif (data < 0)\r\nbreak;\r\nasync_unwrap_char(self->ndev, &self->ndev->stats,\r\n&self->rx_buff, (u8)data);\r\nself->ndev->last_rx = jiffies;\r\nif (EOFD & sh_sir_read(self, IRIF_SIR_FRM))\r\ncontinue;\r\nbreak;\r\n}\r\n}\r\nstatic irqreturn_t sh_sir_irq(int irq, void *dev_id)\r\n{\r\nstruct sh_sir_self *self = dev_id;\r\nstruct device *dev = &self->ndev->dev;\r\nint phase = sh_sir_is_which_phase(self);\r\nswitch (phase) {\r\ncase TX_COMP_PHASE:\r\ncase TX_PHASE:\r\nsh_sir_tx(self, phase);\r\nbreak;\r\ncase RX_PHASE:\r\nif (sh_sir_read(self, IRIF_SIR3))\r\ndev_err(dev, "rcv pulse width error occurred\n");\r\nsh_sir_rx(self);\r\nsh_sir_clear_all_err(self);\r\nbreak;\r\ndefault:\r\ndev_err(dev, "unknown interrupt\n");\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int sh_sir_hard_xmit(struct sk_buff *skb, struct net_device *ndev)\r\n{\r\nstruct sh_sir_self *self = netdev_priv(ndev);\r\nint speed = irda_get_next_speed(skb);\r\nif ((0 < speed) &&\r\n(9600 != speed)) {\r\ndev_err(&ndev->dev, "support 9600 only (%d)\n", speed);\r\nreturn -EIO;\r\n}\r\nnetif_stop_queue(ndev);\r\nself->tx_buff.data = self->tx_buff.head;\r\nself->tx_buff.len = 0;\r\nif (skb->len)\r\nself->tx_buff.len = async_wrap_skb(skb, self->tx_buff.data,\r\nself->tx_buff.truesize);\r\nsh_sir_set_phase(self, TX_PHASE);\r\ndev_kfree_skb(skb);\r\nreturn 0;\r\n}\r\nstatic int sh_sir_ioctl(struct net_device *ndev, struct ifreq *ifreq, int cmd)\r\n{\r\nreturn 0;\r\n}\r\nstatic struct net_device_stats *sh_sir_stats(struct net_device *ndev)\r\n{\r\nstruct sh_sir_self *self = netdev_priv(ndev);\r\nreturn &self->ndev->stats;\r\n}\r\nstatic int sh_sir_open(struct net_device *ndev)\r\n{\r\nstruct sh_sir_self *self = netdev_priv(ndev);\r\nint err;\r\nclk_enable(self->clk);\r\nerr = sh_sir_crc_init(self);\r\nif (err)\r\ngoto open_err;\r\nsh_sir_set_baudrate(self, 9600);\r\nself->irlap = irlap_open(ndev, &self->qos, DRIVER_NAME);\r\nif (!self->irlap) {\r\nerr = -ENODEV;\r\ngoto open_err;\r\n}\r\nsh_sir_update_bits(self, IRIF_SIR_FRM, FRP, FRP);\r\nsh_sir_read(self, IRIF_UART1);\r\nsh_sir_read(self, IRIF_UART4);\r\nsh_sir_set_phase(self, RX_PHASE);\r\nnetif_start_queue(ndev);\r\ndev_info(&self->ndev->dev, "opened\n");\r\nreturn 0;\r\nopen_err:\r\nclk_disable(self->clk);\r\nreturn err;\r\n}\r\nstatic int sh_sir_stop(struct net_device *ndev)\r\n{\r\nstruct sh_sir_self *self = netdev_priv(ndev);\r\nif (self->irlap) {\r\nirlap_close(self->irlap);\r\nself->irlap = NULL;\r\n}\r\nnetif_stop_queue(ndev);\r\ndev_info(&ndev->dev, "stopped\n");\r\nreturn 0;\r\n}\r\nstatic int sh_sir_probe(struct platform_device *pdev)\r\n{\r\nstruct net_device *ndev;\r\nstruct sh_sir_self *self;\r\nstruct resource *res;\r\nchar clk_name[8];\r\nint irq;\r\nint err = -ENOMEM;\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nirq = platform_get_irq(pdev, 0);\r\nif (!res || irq < 0) {\r\ndev_err(&pdev->dev, "Not enough platform resources.\n");\r\ngoto exit;\r\n}\r\nndev = alloc_irdadev(sizeof(*self));\r\nif (!ndev)\r\ngoto exit;\r\nself = netdev_priv(ndev);\r\nself->membase = ioremap_nocache(res->start, resource_size(res));\r\nif (!self->membase) {\r\nerr = -ENXIO;\r\ndev_err(&pdev->dev, "Unable to ioremap.\n");\r\ngoto err_mem_1;\r\n}\r\nerr = sh_sir_init_iobuf(self, IRDA_SKB_MAX_MTU, IRDA_SIR_MAX_FRAME);\r\nif (err)\r\ngoto err_mem_2;\r\nsnprintf(clk_name, sizeof(clk_name), "irda%d", pdev->id);\r\nself->clk = clk_get(&pdev->dev, clk_name);\r\nif (IS_ERR(self->clk)) {\r\ndev_err(&pdev->dev, "cannot get clock \"%s\"\n", clk_name);\r\nerr = -ENODEV;\r\ngoto err_mem_3;\r\n}\r\nirda_init_max_qos_capabilies(&self->qos);\r\nndev->netdev_ops = &sh_sir_ndo;\r\nndev->irq = irq;\r\nself->ndev = ndev;\r\nself->qos.baud_rate.bits &= IR_9600;\r\nself->qos.min_turn_time.bits = 1;\r\nirda_qos_bits_to_value(&self->qos);\r\nerr = register_netdev(ndev);\r\nif (err)\r\ngoto err_mem_4;\r\nplatform_set_drvdata(pdev, ndev);\r\nerr = devm_request_irq(&pdev->dev, irq, sh_sir_irq, 0, "sh_sir", self);\r\nif (err) {\r\ndev_warn(&pdev->dev, "Unable to attach sh_sir interrupt\n");\r\ngoto err_mem_4;\r\n}\r\ndev_info(&pdev->dev, "SuperH IrDA probed\n");\r\ngoto exit;\r\nerr_mem_4:\r\nclk_put(self->clk);\r\nerr_mem_3:\r\nsh_sir_remove_iobuf(self);\r\nerr_mem_2:\r\niounmap(self->membase);\r\nerr_mem_1:\r\nfree_netdev(ndev);\r\nexit:\r\nreturn err;\r\n}\r\nstatic int sh_sir_remove(struct platform_device *pdev)\r\n{\r\nstruct net_device *ndev = platform_get_drvdata(pdev);\r\nstruct sh_sir_self *self = netdev_priv(ndev);\r\nif (!self)\r\nreturn 0;\r\nunregister_netdev(ndev);\r\nclk_put(self->clk);\r\nsh_sir_remove_iobuf(self);\r\niounmap(self->membase);\r\nfree_netdev(ndev);\r\nreturn 0;\r\n}
