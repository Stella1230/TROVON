bool notrace __rcu_is_watching(void)\r\n{\r\nreturn true;\r\n}\r\nstatic int rcu_qsctr_help(struct rcu_ctrlblk *rcp)\r\n{\r\nRCU_TRACE(reset_cpu_stall_ticks(rcp));\r\nif (rcp->donetail != rcp->curtail) {\r\nrcp->donetail = rcp->curtail;\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nvoid rcu_sched_qs(void)\r\n{\r\nunsigned long flags;\r\nlocal_irq_save(flags);\r\nif (rcu_qsctr_help(&rcu_sched_ctrlblk) +\r\nrcu_qsctr_help(&rcu_bh_ctrlblk))\r\nraise_softirq(RCU_SOFTIRQ);\r\nlocal_irq_restore(flags);\r\n}\r\nvoid rcu_bh_qs(void)\r\n{\r\nunsigned long flags;\r\nlocal_irq_save(flags);\r\nif (rcu_qsctr_help(&rcu_bh_ctrlblk))\r\nraise_softirq(RCU_SOFTIRQ);\r\nlocal_irq_restore(flags);\r\n}\r\nvoid rcu_check_callbacks(int user)\r\n{\r\nRCU_TRACE(check_cpu_stalls());\r\nif (user)\r\nrcu_sched_qs();\r\nelse if (!in_softirq())\r\nrcu_bh_qs();\r\nif (user)\r\nrcu_note_voluntary_context_switch(current);\r\n}\r\nstatic void __rcu_process_callbacks(struct rcu_ctrlblk *rcp)\r\n{\r\nconst char *rn = NULL;\r\nstruct rcu_head *next, *list;\r\nunsigned long flags;\r\nRCU_TRACE(int cb_count = 0);\r\nlocal_irq_save(flags);\r\nif (rcp->donetail == &rcp->rcucblist) {\r\nlocal_irq_restore(flags);\r\nreturn;\r\n}\r\nRCU_TRACE(trace_rcu_batch_start(rcp->name, 0, rcp->qlen, -1));\r\nlist = rcp->rcucblist;\r\nrcp->rcucblist = *rcp->donetail;\r\n*rcp->donetail = NULL;\r\nif (rcp->curtail == rcp->donetail)\r\nrcp->curtail = &rcp->rcucblist;\r\nrcp->donetail = &rcp->rcucblist;\r\nlocal_irq_restore(flags);\r\nRCU_TRACE(rn = rcp->name);\r\nwhile (list) {\r\nnext = list->next;\r\nprefetch(next);\r\ndebug_rcu_head_unqueue(list);\r\nlocal_bh_disable();\r\n__rcu_reclaim(rn, list);\r\nlocal_bh_enable();\r\nlist = next;\r\nRCU_TRACE(cb_count++);\r\n}\r\nRCU_TRACE(rcu_trace_sub_qlen(rcp, cb_count));\r\nRCU_TRACE(trace_rcu_batch_end(rcp->name,\r\ncb_count, 0, need_resched(),\r\nis_idle_task(current),\r\nfalse));\r\n}\r\nstatic void rcu_process_callbacks(struct softirq_action *unused)\r\n{\r\n__rcu_process_callbacks(&rcu_sched_ctrlblk);\r\n__rcu_process_callbacks(&rcu_bh_ctrlblk);\r\n}\r\nvoid synchronize_sched(void)\r\n{\r\nRCU_LOCKDEP_WARN(lock_is_held(&rcu_bh_lock_map) ||\r\nlock_is_held(&rcu_lock_map) ||\r\nlock_is_held(&rcu_sched_lock_map),\r\n"Illegal synchronize_sched() in RCU read-side critical section");\r\ncond_resched();\r\n}\r\nstatic void __call_rcu(struct rcu_head *head,\r\nrcu_callback_t func,\r\nstruct rcu_ctrlblk *rcp)\r\n{\r\nunsigned long flags;\r\ndebug_rcu_head_queue(head);\r\nhead->func = func;\r\nhead->next = NULL;\r\nlocal_irq_save(flags);\r\n*rcp->curtail = head;\r\nrcp->curtail = &head->next;\r\nRCU_TRACE(rcp->qlen++);\r\nlocal_irq_restore(flags);\r\nif (unlikely(is_idle_task(current))) {\r\nresched_cpu(0);\r\n}\r\n}\r\nvoid call_rcu_sched(struct rcu_head *head, rcu_callback_t func)\r\n{\r\n__call_rcu(head, func, &rcu_sched_ctrlblk);\r\n}\r\nvoid call_rcu_bh(struct rcu_head *head, rcu_callback_t func)\r\n{\r\n__call_rcu(head, func, &rcu_bh_ctrlblk);\r\n}\r\nvoid __init rcu_init(void)\r\n{\r\nopen_softirq(RCU_SOFTIRQ, rcu_process_callbacks);\r\nRCU_TRACE(reset_cpu_stall_ticks(&rcu_sched_ctrlblk));\r\nRCU_TRACE(reset_cpu_stall_ticks(&rcu_bh_ctrlblk));\r\nrcu_early_boot_tests();\r\n}
