int kfd_chardev_init(void)\r\n{\r\nint err = 0;\r\nkfd_char_dev_major = register_chrdev(0, kfd_dev_name, &kfd_fops);\r\nerr = kfd_char_dev_major;\r\nif (err < 0)\r\ngoto err_register_chrdev;\r\nkfd_class = class_create(THIS_MODULE, kfd_dev_name);\r\nerr = PTR_ERR(kfd_class);\r\nif (IS_ERR(kfd_class))\r\ngoto err_class_create;\r\nkfd_device = device_create(kfd_class, NULL,\r\nMKDEV(kfd_char_dev_major, 0),\r\nNULL, kfd_dev_name);\r\nerr = PTR_ERR(kfd_device);\r\nif (IS_ERR(kfd_device))\r\ngoto err_device_create;\r\nreturn 0;\r\nerr_device_create:\r\nclass_destroy(kfd_class);\r\nerr_class_create:\r\nunregister_chrdev(kfd_char_dev_major, kfd_dev_name);\r\nerr_register_chrdev:\r\nreturn err;\r\n}\r\nvoid kfd_chardev_exit(void)\r\n{\r\ndevice_destroy(kfd_class, MKDEV(kfd_char_dev_major, 0));\r\nclass_destroy(kfd_class);\r\nunregister_chrdev(kfd_char_dev_major, kfd_dev_name);\r\n}\r\nstruct device *kfd_chardev(void)\r\n{\r\nreturn kfd_device;\r\n}\r\nstatic int kfd_open(struct inode *inode, struct file *filep)\r\n{\r\nstruct kfd_process *process;\r\nbool is_32bit_user_mode;\r\nif (iminor(inode) != 0)\r\nreturn -ENODEV;\r\nis_32bit_user_mode = in_compat_syscall();\r\nif (is_32bit_user_mode) {\r\ndev_warn(kfd_device,\r\n"Process %d (32-bit) failed to open /dev/kfd\n"\r\n"32-bit processes are not supported by amdkfd\n",\r\ncurrent->pid);\r\nreturn -EPERM;\r\n}\r\nprocess = kfd_create_process(current);\r\nif (IS_ERR(process))\r\nreturn PTR_ERR(process);\r\ndev_dbg(kfd_device, "process %d opened, compat mode (32 bit) - %d\n",\r\nprocess->pasid, process->is_32bit_user_mode);\r\nreturn 0;\r\n}\r\nstatic int kfd_ioctl_get_version(struct file *filep, struct kfd_process *p,\r\nvoid *data)\r\n{\r\nstruct kfd_ioctl_get_version_args *args = data;\r\nargs->major_version = KFD_IOCTL_MAJOR_VERSION;\r\nargs->minor_version = KFD_IOCTL_MINOR_VERSION;\r\nreturn 0;\r\n}\r\nstatic int set_queue_properties_from_user(struct queue_properties *q_properties,\r\nstruct kfd_ioctl_create_queue_args *args)\r\n{\r\nif (args->queue_percentage > KFD_MAX_QUEUE_PERCENTAGE) {\r\npr_err("kfd: queue percentage must be between 0 to KFD_MAX_QUEUE_PERCENTAGE\n");\r\nreturn -EINVAL;\r\n}\r\nif (args->queue_priority > KFD_MAX_QUEUE_PRIORITY) {\r\npr_err("kfd: queue priority must be between 0 to KFD_MAX_QUEUE_PRIORITY\n");\r\nreturn -EINVAL;\r\n}\r\nif ((args->ring_base_address) &&\r\n(!access_ok(VERIFY_WRITE,\r\n(const void __user *) args->ring_base_address,\r\nsizeof(uint64_t)))) {\r\npr_err("kfd: can't access ring base address\n");\r\nreturn -EFAULT;\r\n}\r\nif (!is_power_of_2(args->ring_size) && (args->ring_size != 0)) {\r\npr_err("kfd: ring size must be a power of 2 or 0\n");\r\nreturn -EINVAL;\r\n}\r\nif (!access_ok(VERIFY_WRITE,\r\n(const void __user *) args->read_pointer_address,\r\nsizeof(uint32_t))) {\r\npr_err("kfd: can't access read pointer\n");\r\nreturn -EFAULT;\r\n}\r\nif (!access_ok(VERIFY_WRITE,\r\n(const void __user *) args->write_pointer_address,\r\nsizeof(uint32_t))) {\r\npr_err("kfd: can't access write pointer\n");\r\nreturn -EFAULT;\r\n}\r\nif (args->eop_buffer_address &&\r\n!access_ok(VERIFY_WRITE,\r\n(const void __user *) args->eop_buffer_address,\r\nsizeof(uint32_t))) {\r\npr_debug("kfd: can't access eop buffer");\r\nreturn -EFAULT;\r\n}\r\nif (args->ctx_save_restore_address &&\r\n!access_ok(VERIFY_WRITE,\r\n(const void __user *) args->ctx_save_restore_address,\r\nsizeof(uint32_t))) {\r\npr_debug("kfd: can't access ctx save restore buffer");\r\nreturn -EFAULT;\r\n}\r\nq_properties->is_interop = false;\r\nq_properties->queue_percent = args->queue_percentage;\r\nq_properties->priority = args->queue_priority;\r\nq_properties->queue_address = args->ring_base_address;\r\nq_properties->queue_size = args->ring_size;\r\nq_properties->read_ptr = (uint32_t *) args->read_pointer_address;\r\nq_properties->write_ptr = (uint32_t *) args->write_pointer_address;\r\nq_properties->eop_ring_buffer_address = args->eop_buffer_address;\r\nq_properties->eop_ring_buffer_size = args->eop_buffer_size;\r\nq_properties->ctx_save_restore_area_address =\r\nargs->ctx_save_restore_address;\r\nq_properties->ctx_save_restore_area_size = args->ctx_save_restore_size;\r\nif (args->queue_type == KFD_IOC_QUEUE_TYPE_COMPUTE ||\r\nargs->queue_type == KFD_IOC_QUEUE_TYPE_COMPUTE_AQL)\r\nq_properties->type = KFD_QUEUE_TYPE_COMPUTE;\r\nelse if (args->queue_type == KFD_IOC_QUEUE_TYPE_SDMA)\r\nq_properties->type = KFD_QUEUE_TYPE_SDMA;\r\nelse\r\nreturn -ENOTSUPP;\r\nif (args->queue_type == KFD_IOC_QUEUE_TYPE_COMPUTE_AQL)\r\nq_properties->format = KFD_QUEUE_FORMAT_AQL;\r\nelse\r\nq_properties->format = KFD_QUEUE_FORMAT_PM4;\r\npr_debug("Queue Percentage (%d, %d)\n",\r\nq_properties->queue_percent, args->queue_percentage);\r\npr_debug("Queue Priority (%d, %d)\n",\r\nq_properties->priority, args->queue_priority);\r\npr_debug("Queue Address (0x%llX, 0x%llX)\n",\r\nq_properties->queue_address, args->ring_base_address);\r\npr_debug("Queue Size (0x%llX, %u)\n",\r\nq_properties->queue_size, args->ring_size);\r\npr_debug("Queue r/w Pointers (0x%llX, 0x%llX)\n",\r\n(uint64_t) q_properties->read_ptr,\r\n(uint64_t) q_properties->write_ptr);\r\npr_debug("Queue Format (%d)\n", q_properties->format);\r\npr_debug("Queue EOP (0x%llX)\n", q_properties->eop_ring_buffer_address);\r\npr_debug("Queue CTX save arex (0x%llX)\n",\r\nq_properties->ctx_save_restore_area_address);\r\nreturn 0;\r\n}\r\nstatic int kfd_ioctl_create_queue(struct file *filep, struct kfd_process *p,\r\nvoid *data)\r\n{\r\nstruct kfd_ioctl_create_queue_args *args = data;\r\nstruct kfd_dev *dev;\r\nint err = 0;\r\nunsigned int queue_id;\r\nstruct kfd_process_device *pdd;\r\nstruct queue_properties q_properties;\r\nmemset(&q_properties, 0, sizeof(struct queue_properties));\r\npr_debug("kfd: creating queue ioctl\n");\r\nerr = set_queue_properties_from_user(&q_properties, args);\r\nif (err)\r\nreturn err;\r\npr_debug("kfd: looking for gpu id 0x%x\n", args->gpu_id);\r\ndev = kfd_device_by_id(args->gpu_id);\r\nif (dev == NULL) {\r\npr_debug("kfd: gpu id 0x%x was not found\n", args->gpu_id);\r\nreturn -EINVAL;\r\n}\r\nmutex_lock(&p->mutex);\r\npdd = kfd_bind_process_to_device(dev, p);\r\nif (IS_ERR(pdd)) {\r\nerr = -ESRCH;\r\ngoto err_bind_process;\r\n}\r\npr_debug("kfd: creating queue for PASID %d on GPU 0x%x\n",\r\np->pasid,\r\ndev->id);\r\nerr = pqm_create_queue(&p->pqm, dev, filep, &q_properties,\r\n0, q_properties.type, &queue_id);\r\nif (err != 0)\r\ngoto err_create_queue;\r\nargs->queue_id = queue_id;\r\nargs->doorbell_offset = (KFD_MMAP_DOORBELL_MASK | args->gpu_id);\r\nargs->doorbell_offset <<= PAGE_SHIFT;\r\nmutex_unlock(&p->mutex);\r\npr_debug("kfd: queue id %d was created successfully\n", args->queue_id);\r\npr_debug("ring buffer address == 0x%016llX\n",\r\nargs->ring_base_address);\r\npr_debug("read ptr address == 0x%016llX\n",\r\nargs->read_pointer_address);\r\npr_debug("write ptr address == 0x%016llX\n",\r\nargs->write_pointer_address);\r\nreturn 0;\r\nerr_create_queue:\r\nerr_bind_process:\r\nmutex_unlock(&p->mutex);\r\nreturn err;\r\n}\r\nstatic int kfd_ioctl_destroy_queue(struct file *filp, struct kfd_process *p,\r\nvoid *data)\r\n{\r\nint retval;\r\nstruct kfd_ioctl_destroy_queue_args *args = data;\r\npr_debug("kfd: destroying queue id %d for PASID %d\n",\r\nargs->queue_id,\r\np->pasid);\r\nmutex_lock(&p->mutex);\r\nretval = pqm_destroy_queue(&p->pqm, args->queue_id);\r\nmutex_unlock(&p->mutex);\r\nreturn retval;\r\n}\r\nstatic int kfd_ioctl_update_queue(struct file *filp, struct kfd_process *p,\r\nvoid *data)\r\n{\r\nint retval;\r\nstruct kfd_ioctl_update_queue_args *args = data;\r\nstruct queue_properties properties;\r\nif (args->queue_percentage > KFD_MAX_QUEUE_PERCENTAGE) {\r\npr_err("kfd: queue percentage must be between 0 to KFD_MAX_QUEUE_PERCENTAGE\n");\r\nreturn -EINVAL;\r\n}\r\nif (args->queue_priority > KFD_MAX_QUEUE_PRIORITY) {\r\npr_err("kfd: queue priority must be between 0 to KFD_MAX_QUEUE_PRIORITY\n");\r\nreturn -EINVAL;\r\n}\r\nif ((args->ring_base_address) &&\r\n(!access_ok(VERIFY_WRITE,\r\n(const void __user *) args->ring_base_address,\r\nsizeof(uint64_t)))) {\r\npr_err("kfd: can't access ring base address\n");\r\nreturn -EFAULT;\r\n}\r\nif (!is_power_of_2(args->ring_size) && (args->ring_size != 0)) {\r\npr_err("kfd: ring size must be a power of 2 or 0\n");\r\nreturn -EINVAL;\r\n}\r\nproperties.queue_address = args->ring_base_address;\r\nproperties.queue_size = args->ring_size;\r\nproperties.queue_percent = args->queue_percentage;\r\nproperties.priority = args->queue_priority;\r\npr_debug("kfd: updating queue id %d for PASID %d\n",\r\nargs->queue_id, p->pasid);\r\nmutex_lock(&p->mutex);\r\nretval = pqm_update_queue(&p->pqm, args->queue_id, &properties);\r\nmutex_unlock(&p->mutex);\r\nreturn retval;\r\n}\r\nstatic int kfd_ioctl_set_memory_policy(struct file *filep,\r\nstruct kfd_process *p, void *data)\r\n{\r\nstruct kfd_ioctl_set_memory_policy_args *args = data;\r\nstruct kfd_dev *dev;\r\nint err = 0;\r\nstruct kfd_process_device *pdd;\r\nenum cache_policy default_policy, alternate_policy;\r\nif (args->default_policy != KFD_IOC_CACHE_POLICY_COHERENT\r\n&& args->default_policy != KFD_IOC_CACHE_POLICY_NONCOHERENT) {\r\nreturn -EINVAL;\r\n}\r\nif (args->alternate_policy != KFD_IOC_CACHE_POLICY_COHERENT\r\n&& args->alternate_policy != KFD_IOC_CACHE_POLICY_NONCOHERENT) {\r\nreturn -EINVAL;\r\n}\r\ndev = kfd_device_by_id(args->gpu_id);\r\nif (dev == NULL)\r\nreturn -EINVAL;\r\nmutex_lock(&p->mutex);\r\npdd = kfd_bind_process_to_device(dev, p);\r\nif (IS_ERR(pdd)) {\r\nerr = -ESRCH;\r\ngoto out;\r\n}\r\ndefault_policy = (args->default_policy == KFD_IOC_CACHE_POLICY_COHERENT)\r\n? cache_policy_coherent : cache_policy_noncoherent;\r\nalternate_policy =\r\n(args->alternate_policy == KFD_IOC_CACHE_POLICY_COHERENT)\r\n? cache_policy_coherent : cache_policy_noncoherent;\r\nif (!dev->dqm->ops.set_cache_memory_policy(dev->dqm,\r\n&pdd->qpd,\r\ndefault_policy,\r\nalternate_policy,\r\n(void __user *)args->alternate_aperture_base,\r\nargs->alternate_aperture_size))\r\nerr = -EINVAL;\r\nout:\r\nmutex_unlock(&p->mutex);\r\nreturn err;\r\n}\r\nstatic int kfd_ioctl_dbg_register(struct file *filep,\r\nstruct kfd_process *p, void *data)\r\n{\r\nstruct kfd_ioctl_dbg_register_args *args = data;\r\nstruct kfd_dev *dev;\r\nstruct kfd_dbgmgr *dbgmgr_ptr;\r\nstruct kfd_process_device *pdd;\r\nbool create_ok;\r\nlong status = 0;\r\ndev = kfd_device_by_id(args->gpu_id);\r\nif (dev == NULL)\r\nreturn -EINVAL;\r\nif (dev->device_info->asic_family == CHIP_CARRIZO) {\r\npr_debug("kfd_ioctl_dbg_register not supported on CZ\n");\r\nreturn -EINVAL;\r\n}\r\nmutex_lock(kfd_get_dbgmgr_mutex());\r\nmutex_lock(&p->mutex);\r\npdd = kfd_bind_process_to_device(dev, p);\r\nif (IS_ERR(pdd)) {\r\nmutex_unlock(&p->mutex);\r\nmutex_unlock(kfd_get_dbgmgr_mutex());\r\nreturn PTR_ERR(pdd);\r\n}\r\nif (dev->dbgmgr == NULL) {\r\ncreate_ok = kfd_dbgmgr_create(&dbgmgr_ptr, dev);\r\nif (create_ok) {\r\nstatus = kfd_dbgmgr_register(dbgmgr_ptr, p);\r\nif (status != 0)\r\nkfd_dbgmgr_destroy(dbgmgr_ptr);\r\nelse\r\ndev->dbgmgr = dbgmgr_ptr;\r\n}\r\n} else {\r\npr_debug("debugger already registered\n");\r\nstatus = -EINVAL;\r\n}\r\nmutex_unlock(&p->mutex);\r\nmutex_unlock(kfd_get_dbgmgr_mutex());\r\nreturn status;\r\n}\r\nstatic int kfd_ioctl_dbg_unrgesiter(struct file *filep,\r\nstruct kfd_process *p, void *data)\r\n{\r\nstruct kfd_ioctl_dbg_unregister_args *args = data;\r\nstruct kfd_dev *dev;\r\nlong status;\r\ndev = kfd_device_by_id(args->gpu_id);\r\nif (dev == NULL)\r\nreturn -EINVAL;\r\nif (dev->device_info->asic_family == CHIP_CARRIZO) {\r\npr_debug("kfd_ioctl_dbg_unrgesiter not supported on CZ\n");\r\nreturn -EINVAL;\r\n}\r\nmutex_lock(kfd_get_dbgmgr_mutex());\r\nstatus = kfd_dbgmgr_unregister(dev->dbgmgr, p);\r\nif (status == 0) {\r\nkfd_dbgmgr_destroy(dev->dbgmgr);\r\ndev->dbgmgr = NULL;\r\n}\r\nmutex_unlock(kfd_get_dbgmgr_mutex());\r\nreturn status;\r\n}\r\nstatic int kfd_ioctl_dbg_address_watch(struct file *filep,\r\nstruct kfd_process *p, void *data)\r\n{\r\nstruct kfd_ioctl_dbg_address_watch_args *args = data;\r\nstruct kfd_dev *dev;\r\nstruct dbg_address_watch_info aw_info;\r\nunsigned char *args_buff;\r\nlong status;\r\nvoid __user *cmd_from_user;\r\nuint64_t watch_mask_value = 0;\r\nunsigned int args_idx = 0;\r\nmemset((void *) &aw_info, 0, sizeof(struct dbg_address_watch_info));\r\ndev = kfd_device_by_id(args->gpu_id);\r\nif (dev == NULL)\r\nreturn -EINVAL;\r\nif (dev->device_info->asic_family == CHIP_CARRIZO) {\r\npr_debug("kfd_ioctl_dbg_wave_control not supported on CZ\n");\r\nreturn -EINVAL;\r\n}\r\ncmd_from_user = (void __user *) args->content_ptr;\r\nif ((args->buf_size_in_bytes > MAX_ALLOWED_AW_BUFF_SIZE) ||\r\n(args->buf_size_in_bytes <= sizeof(*args) + sizeof(int) * 2) ||\r\n(cmd_from_user == NULL))\r\nreturn -EINVAL;\r\nargs_buff = memdup_user(cmd_from_user,\r\nargs->buf_size_in_bytes - sizeof(*args));\r\nif (IS_ERR(args_buff))\r\nreturn PTR_ERR(args_buff);\r\naw_info.process = p;\r\naw_info.num_watch_points = *((uint32_t *)(&args_buff[args_idx]));\r\nargs_idx += sizeof(aw_info.num_watch_points);\r\naw_info.watch_mode = (enum HSA_DBG_WATCH_MODE *) &args_buff[args_idx];\r\nargs_idx += sizeof(enum HSA_DBG_WATCH_MODE) * aw_info.num_watch_points;\r\naw_info.watch_address = (uint64_t *) &args_buff[args_idx];\r\nargs_idx += sizeof(aw_info.watch_address) * aw_info.num_watch_points;\r\nif (args_idx >= args->buf_size_in_bytes - sizeof(*args)) {\r\nkfree(args_buff);\r\nreturn -EINVAL;\r\n}\r\nwatch_mask_value = (uint64_t) args_buff[args_idx];\r\nif (watch_mask_value > 0) {\r\naw_info.watch_mask = (uint64_t *) &args_buff[args_idx];\r\nargs_idx += sizeof(aw_info.watch_mask) *\r\naw_info.num_watch_points;\r\n} else {\r\naw_info.watch_mask = NULL;\r\nargs_idx += sizeof(aw_info.watch_mask);\r\n}\r\nif (args_idx >= args->buf_size_in_bytes - sizeof(args)) {\r\nkfree(args_buff);\r\nreturn -EINVAL;\r\n}\r\naw_info.watch_event = NULL;\r\nmutex_lock(kfd_get_dbgmgr_mutex());\r\nstatus = kfd_dbgmgr_address_watch(dev->dbgmgr, &aw_info);\r\nmutex_unlock(kfd_get_dbgmgr_mutex());\r\nkfree(args_buff);\r\nreturn status;\r\n}\r\nstatic int kfd_ioctl_dbg_wave_control(struct file *filep,\r\nstruct kfd_process *p, void *data)\r\n{\r\nstruct kfd_ioctl_dbg_wave_control_args *args = data;\r\nstruct kfd_dev *dev;\r\nstruct dbg_wave_control_info wac_info;\r\nunsigned char *args_buff;\r\nuint32_t computed_buff_size;\r\nlong status;\r\nvoid __user *cmd_from_user;\r\nunsigned int args_idx = 0;\r\nmemset((void *) &wac_info, 0, sizeof(struct dbg_wave_control_info));\r\ncomputed_buff_size = sizeof(*args) +\r\nsizeof(wac_info.mode) +\r\nsizeof(wac_info.operand) +\r\nsizeof(wac_info.dbgWave_msg.DbgWaveMsg) +\r\nsizeof(wac_info.dbgWave_msg.MemoryVA) +\r\nsizeof(wac_info.trapId);\r\ndev = kfd_device_by_id(args->gpu_id);\r\nif (dev == NULL)\r\nreturn -EINVAL;\r\nif (dev->device_info->asic_family == CHIP_CARRIZO) {\r\npr_debug("kfd_ioctl_dbg_wave_control not supported on CZ\n");\r\nreturn -EINVAL;\r\n}\r\nif (args->buf_size_in_bytes != computed_buff_size) {\r\npr_debug("size mismatch, computed : actual %u : %u\n",\r\nargs->buf_size_in_bytes, computed_buff_size);\r\nreturn -EINVAL;\r\n}\r\ncmd_from_user = (void __user *) args->content_ptr;\r\nif (cmd_from_user == NULL)\r\nreturn -EINVAL;\r\nargs_buff = memdup_user(cmd_from_user,\r\nargs->buf_size_in_bytes - sizeof(*args));\r\nif (IS_ERR(args_buff))\r\nreturn PTR_ERR(args_buff);\r\nwac_info.process = p;\r\nwac_info.operand = *((enum HSA_DBG_WAVEOP *)(&args_buff[args_idx]));\r\nargs_idx += sizeof(wac_info.operand);\r\nwac_info.mode = *((enum HSA_DBG_WAVEMODE *)(&args_buff[args_idx]));\r\nargs_idx += sizeof(wac_info.mode);\r\nwac_info.trapId = *((uint32_t *)(&args_buff[args_idx]));\r\nargs_idx += sizeof(wac_info.trapId);\r\nwac_info.dbgWave_msg.DbgWaveMsg.WaveMsgInfoGen2.Value =\r\n*((uint32_t *)(&args_buff[args_idx]));\r\nwac_info.dbgWave_msg.MemoryVA = NULL;\r\nmutex_lock(kfd_get_dbgmgr_mutex());\r\npr_debug("Calling dbg manager process %p, operand %u, mode %u, trapId %u, message %u\n",\r\nwac_info.process, wac_info.operand,\r\nwac_info.mode, wac_info.trapId,\r\nwac_info.dbgWave_msg.DbgWaveMsg.WaveMsgInfoGen2.Value);\r\nstatus = kfd_dbgmgr_wave_control(dev->dbgmgr, &wac_info);\r\npr_debug("Returned status of dbg manager is %ld\n", status);\r\nmutex_unlock(kfd_get_dbgmgr_mutex());\r\nkfree(args_buff);\r\nreturn status;\r\n}\r\nstatic int kfd_ioctl_get_clock_counters(struct file *filep,\r\nstruct kfd_process *p, void *data)\r\n{\r\nstruct kfd_ioctl_get_clock_counters_args *args = data;\r\nstruct kfd_dev *dev;\r\nstruct timespec64 time;\r\ndev = kfd_device_by_id(args->gpu_id);\r\nif (dev == NULL)\r\nreturn -EINVAL;\r\nargs->gpu_clock_counter =\r\ndev->kfd2kgd->get_gpu_clock_counter(dev->kgd);\r\ngetrawmonotonic64(&time);\r\nargs->cpu_clock_counter = (uint64_t)timespec64_to_ns(&time);\r\nget_monotonic_boottime64(&time);\r\nargs->system_clock_counter = (uint64_t)timespec64_to_ns(&time);\r\nargs->system_clock_freq = 1000000000;\r\nreturn 0;\r\n}\r\nstatic int kfd_ioctl_get_process_apertures(struct file *filp,\r\nstruct kfd_process *p, void *data)\r\n{\r\nstruct kfd_ioctl_get_process_apertures_args *args = data;\r\nstruct kfd_process_device_apertures *pAperture;\r\nstruct kfd_process_device *pdd;\r\ndev_dbg(kfd_device, "get apertures for PASID %d", p->pasid);\r\nargs->num_of_nodes = 0;\r\nmutex_lock(&p->mutex);\r\nif (kfd_has_process_device_data(p)) {\r\npdd = kfd_get_first_process_device_data(p);\r\ndo {\r\npAperture =\r\n&args->process_apertures[args->num_of_nodes];\r\npAperture->gpu_id = pdd->dev->id;\r\npAperture->lds_base = pdd->lds_base;\r\npAperture->lds_limit = pdd->lds_limit;\r\npAperture->gpuvm_base = pdd->gpuvm_base;\r\npAperture->gpuvm_limit = pdd->gpuvm_limit;\r\npAperture->scratch_base = pdd->scratch_base;\r\npAperture->scratch_limit = pdd->scratch_limit;\r\ndev_dbg(kfd_device,\r\n"node id %u\n", args->num_of_nodes);\r\ndev_dbg(kfd_device,\r\n"gpu id %u\n", pdd->dev->id);\r\ndev_dbg(kfd_device,\r\n"lds_base %llX\n", pdd->lds_base);\r\ndev_dbg(kfd_device,\r\n"lds_limit %llX\n", pdd->lds_limit);\r\ndev_dbg(kfd_device,\r\n"gpuvm_base %llX\n", pdd->gpuvm_base);\r\ndev_dbg(kfd_device,\r\n"gpuvm_limit %llX\n", pdd->gpuvm_limit);\r\ndev_dbg(kfd_device,\r\n"scratch_base %llX\n", pdd->scratch_base);\r\ndev_dbg(kfd_device,\r\n"scratch_limit %llX\n", pdd->scratch_limit);\r\nargs->num_of_nodes++;\r\n} while ((pdd = kfd_get_next_process_device_data(p, pdd)) != NULL &&\r\n(args->num_of_nodes < NUM_OF_SUPPORTED_GPUS));\r\n}\r\nmutex_unlock(&p->mutex);\r\nreturn 0;\r\n}\r\nstatic int kfd_ioctl_create_event(struct file *filp, struct kfd_process *p,\r\nvoid *data)\r\n{\r\nstruct kfd_ioctl_create_event_args *args = data;\r\nint err;\r\nerr = kfd_event_create(filp, p, args->event_type,\r\nargs->auto_reset != 0, args->node_id,\r\n&args->event_id, &args->event_trigger_data,\r\n&args->event_page_offset,\r\n&args->event_slot_index);\r\nreturn err;\r\n}\r\nstatic int kfd_ioctl_destroy_event(struct file *filp, struct kfd_process *p,\r\nvoid *data)\r\n{\r\nstruct kfd_ioctl_destroy_event_args *args = data;\r\nreturn kfd_event_destroy(p, args->event_id);\r\n}\r\nstatic int kfd_ioctl_set_event(struct file *filp, struct kfd_process *p,\r\nvoid *data)\r\n{\r\nstruct kfd_ioctl_set_event_args *args = data;\r\nreturn kfd_set_event(p, args->event_id);\r\n}\r\nstatic int kfd_ioctl_reset_event(struct file *filp, struct kfd_process *p,\r\nvoid *data)\r\n{\r\nstruct kfd_ioctl_reset_event_args *args = data;\r\nreturn kfd_reset_event(p, args->event_id);\r\n}\r\nstatic int kfd_ioctl_wait_events(struct file *filp, struct kfd_process *p,\r\nvoid *data)\r\n{\r\nstruct kfd_ioctl_wait_events_args *args = data;\r\nenum kfd_event_wait_result wait_result;\r\nint err;\r\nerr = kfd_wait_on_events(p, args->num_events,\r\n(void __user *)args->events_ptr,\r\n(args->wait_for_all != 0),\r\nargs->timeout, &wait_result);\r\nargs->wait_result = wait_result;\r\nreturn err;\r\n}\r\nstatic long kfd_ioctl(struct file *filep, unsigned int cmd, unsigned long arg)\r\n{\r\nstruct kfd_process *process;\r\namdkfd_ioctl_t *func;\r\nconst struct amdkfd_ioctl_desc *ioctl = NULL;\r\nunsigned int nr = _IOC_NR(cmd);\r\nchar stack_kdata[128];\r\nchar *kdata = NULL;\r\nunsigned int usize, asize;\r\nint retcode = -EINVAL;\r\nif (nr >= AMDKFD_CORE_IOCTL_COUNT)\r\ngoto err_i1;\r\nif ((nr >= AMDKFD_COMMAND_START) && (nr < AMDKFD_COMMAND_END)) {\r\nu32 amdkfd_size;\r\nioctl = &amdkfd_ioctls[nr];\r\namdkfd_size = _IOC_SIZE(ioctl->cmd);\r\nusize = asize = _IOC_SIZE(cmd);\r\nif (amdkfd_size > asize)\r\nasize = amdkfd_size;\r\ncmd = ioctl->cmd;\r\n} else\r\ngoto err_i1;\r\ndev_dbg(kfd_device, "ioctl cmd 0x%x (#%d), arg 0x%lx\n", cmd, nr, arg);\r\nprocess = kfd_get_process(current);\r\nif (IS_ERR(process)) {\r\ndev_dbg(kfd_device, "no process\n");\r\ngoto err_i1;\r\n}\r\nfunc = ioctl->func;\r\nif (unlikely(!func)) {\r\ndev_dbg(kfd_device, "no function\n");\r\nretcode = -EINVAL;\r\ngoto err_i1;\r\n}\r\nif (cmd & (IOC_IN | IOC_OUT)) {\r\nif (asize <= sizeof(stack_kdata)) {\r\nkdata = stack_kdata;\r\n} else {\r\nkdata = kmalloc(asize, GFP_KERNEL);\r\nif (!kdata) {\r\nretcode = -ENOMEM;\r\ngoto err_i1;\r\n}\r\n}\r\nif (asize > usize)\r\nmemset(kdata + usize, 0, asize - usize);\r\n}\r\nif (cmd & IOC_IN) {\r\nif (copy_from_user(kdata, (void __user *)arg, usize) != 0) {\r\nretcode = -EFAULT;\r\ngoto err_i1;\r\n}\r\n} else if (cmd & IOC_OUT) {\r\nmemset(kdata, 0, usize);\r\n}\r\nretcode = func(filep, process, kdata);\r\nif (cmd & IOC_OUT)\r\nif (copy_to_user((void __user *)arg, kdata, usize) != 0)\r\nretcode = -EFAULT;\r\nerr_i1:\r\nif (!ioctl)\r\ndev_dbg(kfd_device, "invalid ioctl: pid=%d, cmd=0x%02x, nr=0x%02x\n",\r\ntask_pid_nr(current), cmd, nr);\r\nif (kdata != stack_kdata)\r\nkfree(kdata);\r\nif (retcode)\r\ndev_dbg(kfd_device, "ret = %d\n", retcode);\r\nreturn retcode;\r\n}\r\nstatic int kfd_mmap(struct file *filp, struct vm_area_struct *vma)\r\n{\r\nstruct kfd_process *process;\r\nprocess = kfd_get_process(current);\r\nif (IS_ERR(process))\r\nreturn PTR_ERR(process);\r\nif ((vma->vm_pgoff & KFD_MMAP_DOORBELL_MASK) ==\r\nKFD_MMAP_DOORBELL_MASK) {\r\nvma->vm_pgoff = vma->vm_pgoff ^ KFD_MMAP_DOORBELL_MASK;\r\nreturn kfd_doorbell_mmap(process, vma);\r\n} else if ((vma->vm_pgoff & KFD_MMAP_EVENTS_MASK) ==\r\nKFD_MMAP_EVENTS_MASK) {\r\nvma->vm_pgoff = vma->vm_pgoff ^ KFD_MMAP_EVENTS_MASK;\r\nreturn kfd_event_mmap(process, vma);\r\n}\r\nreturn -EFAULT;\r\n}
