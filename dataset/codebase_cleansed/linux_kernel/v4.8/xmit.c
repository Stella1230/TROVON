void ath_txq_lock(struct ath_softc *sc, struct ath_txq *txq)\r\n__acquires(&txq->axq_lock\r\nvoid ath_txq_unlock(struct ath_softc *sc, struct ath_txq *txq)\r\n__releases(&txq->axq_lock\r\nvoid ath_txq_unlock_complete(struct ath_softc *sc, struct ath_txq *txq)\r\n__releases(&txq->axq_lock\r\nstatic void ath_tx_queue_tid(struct ath_softc *sc, struct ath_txq *txq,\r\nstruct ath_atx_tid *tid)\r\n{\r\nstruct list_head *list;\r\nstruct ath_vif *avp = (struct ath_vif *) tid->an->vif->drv_priv;\r\nstruct ath_chanctx *ctx = avp->chanctx;\r\nif (!ctx)\r\nreturn;\r\nlist = &ctx->acq[TID_TO_WME_AC(tid->tidno)];\r\nif (list_empty(&tid->list))\r\nlist_add_tail(&tid->list, list);\r\n}\r\nstatic struct ath_frame_info *get_frame_info(struct sk_buff *skb)\r\n{\r\nstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\r\nBUILD_BUG_ON(sizeof(struct ath_frame_info) >\r\nsizeof(tx_info->rate_driver_data));\r\nreturn (struct ath_frame_info *) &tx_info->rate_driver_data[0];\r\n}\r\nstatic void ath_send_bar(struct ath_atx_tid *tid, u16 seqno)\r\n{\r\nif (!tid->an->sta)\r\nreturn;\r\nieee80211_send_bar(tid->an->vif, tid->an->sta->addr, tid->tidno,\r\nseqno << IEEE80211_SEQ_SEQ_SHIFT);\r\n}\r\nstatic void ath_set_rates(struct ieee80211_vif *vif, struct ieee80211_sta *sta,\r\nstruct ath_buf *bf)\r\n{\r\nieee80211_get_tx_rates(vif, sta, bf->bf_mpdu, bf->rates,\r\nARRAY_SIZE(bf->rates));\r\n}\r\nstatic void ath_txq_skb_done(struct ath_softc *sc, struct ath_txq *txq,\r\nstruct sk_buff *skb)\r\n{\r\nstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);\r\nstruct ath_frame_info *fi = get_frame_info(skb);\r\nint q = fi->txq;\r\nif (q < 0)\r\nreturn;\r\ntxq = sc->tx.txq_map[q];\r\nif (WARN_ON(--txq->pending_frames < 0))\r\ntxq->pending_frames = 0;\r\nif (txq->stopped &&\r\ntxq->pending_frames < sc->tx.txq_max_pending[q]) {\r\nif (ath9k_is_chanctx_enabled())\r\nieee80211_wake_queue(sc->hw, info->hw_queue);\r\nelse\r\nieee80211_wake_queue(sc->hw, q);\r\ntxq->stopped = false;\r\n}\r\n}\r\nstatic struct ath_atx_tid *\r\nath_get_skb_tid(struct ath_softc *sc, struct ath_node *an, struct sk_buff *skb)\r\n{\r\nu8 tidno = skb->priority & IEEE80211_QOS_CTL_TID_MASK;\r\nreturn ATH_AN_2_TID(an, tidno);\r\n}\r\nstatic bool ath_tid_has_buffered(struct ath_atx_tid *tid)\r\n{\r\nreturn !skb_queue_empty(&tid->buf_q) || !skb_queue_empty(&tid->retry_q);\r\n}\r\nstatic struct sk_buff *ath_tid_dequeue(struct ath_atx_tid *tid)\r\n{\r\nstruct sk_buff *skb;\r\nskb = __skb_dequeue(&tid->retry_q);\r\nif (!skb)\r\nskb = __skb_dequeue(&tid->buf_q);\r\nreturn skb;\r\n}\r\nstatic void\r\nath_tx_tid_change_state(struct ath_softc *sc, struct ath_atx_tid *tid)\r\n{\r\nstruct ath_txq *txq = tid->txq;\r\nstruct ieee80211_tx_info *tx_info;\r\nstruct sk_buff *skb, *tskb;\r\nstruct ath_buf *bf;\r\nstruct ath_frame_info *fi;\r\nskb_queue_walk_safe(&tid->buf_q, skb, tskb) {\r\nfi = get_frame_info(skb);\r\nbf = fi->bf;\r\ntx_info = IEEE80211_SKB_CB(skb);\r\ntx_info->flags &= ~IEEE80211_TX_CTL_AMPDU;\r\nif (bf)\r\ncontinue;\r\nbf = ath_tx_setup_buffer(sc, txq, tid, skb);\r\nif (!bf) {\r\n__skb_unlink(skb, &tid->buf_q);\r\nath_txq_skb_done(sc, txq, skb);\r\nieee80211_free_txskb(sc->hw, skb);\r\ncontinue;\r\n}\r\n}\r\n}\r\nstatic void ath_tx_flush_tid(struct ath_softc *sc, struct ath_atx_tid *tid)\r\n{\r\nstruct ath_txq *txq = tid->txq;\r\nstruct sk_buff *skb;\r\nstruct ath_buf *bf;\r\nstruct list_head bf_head;\r\nstruct ath_tx_status ts;\r\nstruct ath_frame_info *fi;\r\nbool sendbar = false;\r\nINIT_LIST_HEAD(&bf_head);\r\nmemset(&ts, 0, sizeof(ts));\r\nwhile ((skb = __skb_dequeue(&tid->retry_q))) {\r\nfi = get_frame_info(skb);\r\nbf = fi->bf;\r\nif (!bf) {\r\nath_txq_skb_done(sc, txq, skb);\r\nieee80211_free_txskb(sc->hw, skb);\r\ncontinue;\r\n}\r\nif (fi->baw_tracked) {\r\nath_tx_update_baw(sc, tid, bf->bf_state.seqno);\r\nsendbar = true;\r\n}\r\nlist_add_tail(&bf->list, &bf_head);\r\nath_tx_complete_buf(sc, bf, txq, &bf_head, &ts, 0);\r\n}\r\nif (sendbar) {\r\nath_txq_unlock(sc, txq);\r\nath_send_bar(tid, tid->seq_start);\r\nath_txq_lock(sc, txq);\r\n}\r\n}\r\nstatic void ath_tx_update_baw(struct ath_softc *sc, struct ath_atx_tid *tid,\r\nint seqno)\r\n{\r\nint index, cindex;\r\nindex = ATH_BA_INDEX(tid->seq_start, seqno);\r\ncindex = (tid->baw_head + index) & (ATH_TID_MAX_BUFS - 1);\r\n__clear_bit(cindex, tid->tx_buf);\r\nwhile (tid->baw_head != tid->baw_tail && !test_bit(tid->baw_head, tid->tx_buf)) {\r\nINCR(tid->seq_start, IEEE80211_SEQ_MAX);\r\nINCR(tid->baw_head, ATH_TID_MAX_BUFS);\r\nif (tid->bar_index >= 0)\r\ntid->bar_index--;\r\n}\r\n}\r\nstatic void ath_tx_addto_baw(struct ath_softc *sc, struct ath_atx_tid *tid,\r\nstruct ath_buf *bf)\r\n{\r\nstruct ath_frame_info *fi = get_frame_info(bf->bf_mpdu);\r\nu16 seqno = bf->bf_state.seqno;\r\nint index, cindex;\r\nindex = ATH_BA_INDEX(tid->seq_start, seqno);\r\ncindex = (tid->baw_head + index) & (ATH_TID_MAX_BUFS - 1);\r\n__set_bit(cindex, tid->tx_buf);\r\nfi->baw_tracked = 1;\r\nif (index >= ((tid->baw_tail - tid->baw_head) &\r\n(ATH_TID_MAX_BUFS - 1))) {\r\ntid->baw_tail = cindex;\r\nINCR(tid->baw_tail, ATH_TID_MAX_BUFS);\r\n}\r\n}\r\nstatic void ath_tid_drain(struct ath_softc *sc, struct ath_txq *txq,\r\nstruct ath_atx_tid *tid)\r\n{\r\nstruct sk_buff *skb;\r\nstruct ath_buf *bf;\r\nstruct list_head bf_head;\r\nstruct ath_tx_status ts;\r\nstruct ath_frame_info *fi;\r\nmemset(&ts, 0, sizeof(ts));\r\nINIT_LIST_HEAD(&bf_head);\r\nwhile ((skb = ath_tid_dequeue(tid))) {\r\nfi = get_frame_info(skb);\r\nbf = fi->bf;\r\nif (!bf) {\r\nath_tx_complete(sc, skb, ATH_TX_ERROR, txq);\r\ncontinue;\r\n}\r\nlist_add_tail(&bf->list, &bf_head);\r\nath_tx_complete_buf(sc, bf, txq, &bf_head, &ts, 0);\r\n}\r\n}\r\nstatic void ath_tx_set_retry(struct ath_softc *sc, struct ath_txq *txq,\r\nstruct sk_buff *skb, int count)\r\n{\r\nstruct ath_frame_info *fi = get_frame_info(skb);\r\nstruct ath_buf *bf = fi->bf;\r\nstruct ieee80211_hdr *hdr;\r\nint prev = fi->retries;\r\nTX_STAT_INC(txq->axq_qnum, a_retries);\r\nfi->retries += count;\r\nif (prev > 0)\r\nreturn;\r\nhdr = (struct ieee80211_hdr *)skb->data;\r\nhdr->frame_control |= cpu_to_le16(IEEE80211_FCTL_RETRY);\r\ndma_sync_single_for_device(sc->dev, bf->bf_buf_addr,\r\nsizeof(*hdr), DMA_TO_DEVICE);\r\n}\r\nstatic struct ath_buf *ath_tx_get_buffer(struct ath_softc *sc)\r\n{\r\nstruct ath_buf *bf = NULL;\r\nspin_lock_bh(&sc->tx.txbuflock);\r\nif (unlikely(list_empty(&sc->tx.txbuf))) {\r\nspin_unlock_bh(&sc->tx.txbuflock);\r\nreturn NULL;\r\n}\r\nbf = list_first_entry(&sc->tx.txbuf, struct ath_buf, list);\r\nlist_del(&bf->list);\r\nspin_unlock_bh(&sc->tx.txbuflock);\r\nreturn bf;\r\n}\r\nstatic void ath_tx_return_buffer(struct ath_softc *sc, struct ath_buf *bf)\r\n{\r\nspin_lock_bh(&sc->tx.txbuflock);\r\nlist_add_tail(&bf->list, &sc->tx.txbuf);\r\nspin_unlock_bh(&sc->tx.txbuflock);\r\n}\r\nstatic struct ath_buf* ath_clone_txbuf(struct ath_softc *sc, struct ath_buf *bf)\r\n{\r\nstruct ath_buf *tbf;\r\ntbf = ath_tx_get_buffer(sc);\r\nif (WARN_ON(!tbf))\r\nreturn NULL;\r\nATH_TXBUF_RESET(tbf);\r\ntbf->bf_mpdu = bf->bf_mpdu;\r\ntbf->bf_buf_addr = bf->bf_buf_addr;\r\nmemcpy(tbf->bf_desc, bf->bf_desc, sc->sc_ah->caps.tx_desc_len);\r\ntbf->bf_state = bf->bf_state;\r\ntbf->bf_state.stale = false;\r\nreturn tbf;\r\n}\r\nstatic void ath_tx_count_frames(struct ath_softc *sc, struct ath_buf *bf,\r\nstruct ath_tx_status *ts, int txok,\r\nint *nframes, int *nbad)\r\n{\r\nstruct ath_frame_info *fi;\r\nu16 seq_st = 0;\r\nu32 ba[WME_BA_BMP_SIZE >> 5];\r\nint ba_index;\r\nint isaggr = 0;\r\n*nbad = 0;\r\n*nframes = 0;\r\nisaggr = bf_isaggr(bf);\r\nif (isaggr) {\r\nseq_st = ts->ts_seqnum;\r\nmemcpy(ba, &ts->ba_low, WME_BA_BMP_SIZE >> 3);\r\n}\r\nwhile (bf) {\r\nfi = get_frame_info(bf->bf_mpdu);\r\nba_index = ATH_BA_INDEX(seq_st, bf->bf_state.seqno);\r\n(*nframes)++;\r\nif (!txok || (isaggr && !ATH_BA_ISSET(ba, ba_index)))\r\n(*nbad)++;\r\nbf = bf->bf_next;\r\n}\r\n}\r\nstatic void ath_tx_complete_aggr(struct ath_softc *sc, struct ath_txq *txq,\r\nstruct ath_buf *bf, struct list_head *bf_q,\r\nstruct ath_tx_status *ts, int txok)\r\n{\r\nstruct ath_node *an = NULL;\r\nstruct sk_buff *skb;\r\nstruct ieee80211_sta *sta;\r\nstruct ieee80211_hw *hw = sc->hw;\r\nstruct ieee80211_hdr *hdr;\r\nstruct ieee80211_tx_info *tx_info;\r\nstruct ath_atx_tid *tid = NULL;\r\nstruct ath_buf *bf_next, *bf_last = bf->bf_lastbf;\r\nstruct list_head bf_head;\r\nstruct sk_buff_head bf_pending;\r\nu16 seq_st = 0, acked_cnt = 0, txfail_cnt = 0, seq_first;\r\nu32 ba[WME_BA_BMP_SIZE >> 5];\r\nint isaggr, txfail, txpending, sendbar = 0, needreset = 0, nbad = 0;\r\nbool rc_update = true, isba;\r\nstruct ieee80211_tx_rate rates[4];\r\nstruct ath_frame_info *fi;\r\nint nframes;\r\nbool flush = !!(ts->ts_status & ATH9K_TX_FLUSH);\r\nint i, retries;\r\nint bar_index = -1;\r\nskb = bf->bf_mpdu;\r\nhdr = (struct ieee80211_hdr *)skb->data;\r\ntx_info = IEEE80211_SKB_CB(skb);\r\nmemcpy(rates, bf->rates, sizeof(rates));\r\nretries = ts->ts_longretry + 1;\r\nfor (i = 0; i < ts->ts_rateindex; i++)\r\nretries += rates[i].count;\r\nrcu_read_lock();\r\nsta = ieee80211_find_sta_by_ifaddr(hw, hdr->addr1, hdr->addr2);\r\nif (!sta) {\r\nrcu_read_unlock();\r\nINIT_LIST_HEAD(&bf_head);\r\nwhile (bf) {\r\nbf_next = bf->bf_next;\r\nif (!bf->bf_state.stale || bf_next != NULL)\r\nlist_move_tail(&bf->list, &bf_head);\r\nath_tx_complete_buf(sc, bf, txq, &bf_head, ts, 0);\r\nbf = bf_next;\r\n}\r\nreturn;\r\n}\r\nan = (struct ath_node *)sta->drv_priv;\r\ntid = ath_get_skb_tid(sc, an, skb);\r\nseq_first = tid->seq_start;\r\nisba = ts->ts_flags & ATH9K_TX_BA;\r\nif (isba && tid->tidno != ts->tid)\r\ntxok = false;\r\nisaggr = bf_isaggr(bf);\r\nmemset(ba, 0, WME_BA_BMP_SIZE >> 3);\r\nif (isaggr && txok) {\r\nif (ts->ts_flags & ATH9K_TX_BA) {\r\nseq_st = ts->ts_seqnum;\r\nmemcpy(ba, &ts->ba_low, WME_BA_BMP_SIZE >> 3);\r\n} else {\r\nif (sc->sc_ah->opmode == NL80211_IFTYPE_STATION)\r\nneedreset = 1;\r\n}\r\n}\r\n__skb_queue_head_init(&bf_pending);\r\nath_tx_count_frames(sc, bf, ts, txok, &nframes, &nbad);\r\nwhile (bf) {\r\nu16 seqno = bf->bf_state.seqno;\r\ntxfail = txpending = sendbar = 0;\r\nbf_next = bf->bf_next;\r\nskb = bf->bf_mpdu;\r\ntx_info = IEEE80211_SKB_CB(skb);\r\nfi = get_frame_info(skb);\r\nif (!BAW_WITHIN(tid->seq_start, tid->baw_size, seqno) ||\r\n!tid->active) {\r\ntxfail = 1;\r\n} else if (ATH_BA_ISSET(ba, ATH_BA_INDEX(seq_st, seqno))) {\r\nacked_cnt++;\r\n} else if (!isaggr && txok) {\r\nacked_cnt++;\r\n} else if (flush) {\r\ntxpending = 1;\r\n} else if (fi->retries < ATH_MAX_SW_RETRIES) {\r\nif (txok || !an->sleeping)\r\nath_tx_set_retry(sc, txq, bf->bf_mpdu,\r\nretries);\r\ntxpending = 1;\r\n} else {\r\ntxfail = 1;\r\ntxfail_cnt++;\r\nbar_index = max_t(int, bar_index,\r\nATH_BA_INDEX(seq_first, seqno));\r\n}\r\nINIT_LIST_HEAD(&bf_head);\r\nif (bf_next != NULL || !bf_last->bf_state.stale)\r\nlist_move_tail(&bf->list, &bf_head);\r\nif (!txpending) {\r\nath_tx_update_baw(sc, tid, seqno);\r\nif (rc_update && (acked_cnt == 1 || txfail_cnt == 1)) {\r\nmemcpy(tx_info->control.rates, rates, sizeof(rates));\r\nath_tx_rc_status(sc, bf, ts, nframes, nbad, txok);\r\nrc_update = false;\r\nif (bf == bf->bf_lastbf)\r\nath_dynack_sample_tx_ts(sc->sc_ah,\r\nbf->bf_mpdu,\r\nts);\r\n}\r\nath_tx_complete_buf(sc, bf, txq, &bf_head, ts,\r\n!txfail);\r\n} else {\r\nif (tx_info->flags & IEEE80211_TX_STATUS_EOSP) {\r\ntx_info->flags &= ~IEEE80211_TX_STATUS_EOSP;\r\nieee80211_sta_eosp(sta);\r\n}\r\nif (bf->bf_next == NULL && bf_last->bf_state.stale) {\r\nstruct ath_buf *tbf;\r\ntbf = ath_clone_txbuf(sc, bf_last);\r\nif (!tbf) {\r\nath_tx_update_baw(sc, tid, seqno);\r\nath_tx_complete_buf(sc, bf, txq,\r\n&bf_head, ts, 0);\r\nbar_index = max_t(int, bar_index,\r\nATH_BA_INDEX(seq_first, seqno));\r\nbreak;\r\n}\r\nfi->bf = tbf;\r\n}\r\n__skb_queue_tail(&bf_pending, skb);\r\n}\r\nbf = bf_next;\r\n}\r\nif (!skb_queue_empty(&bf_pending)) {\r\nif (an->sleeping)\r\nieee80211_sta_set_buffered(sta, tid->tidno, true);\r\nskb_queue_splice_tail(&bf_pending, &tid->retry_q);\r\nif (!an->sleeping) {\r\nath_tx_queue_tid(sc, txq, tid);\r\nif (ts->ts_status & (ATH9K_TXERR_FILT | ATH9K_TXERR_XRETRY))\r\ntid->clear_ps_filter = true;\r\n}\r\n}\r\nif (bar_index >= 0) {\r\nu16 bar_seq = ATH_BA_INDEX2SEQ(seq_first, bar_index);\r\nif (BAW_WITHIN(tid->seq_start, tid->baw_size, bar_seq))\r\ntid->bar_index = ATH_BA_INDEX(tid->seq_start, bar_seq);\r\nath_txq_unlock(sc, txq);\r\nath_send_bar(tid, ATH_BA_INDEX2SEQ(seq_first, bar_index + 1));\r\nath_txq_lock(sc, txq);\r\n}\r\nrcu_read_unlock();\r\nif (needreset)\r\nath9k_queue_reset(sc, RESET_TYPE_TX_ERROR);\r\n}\r\nstatic bool bf_is_ampdu_not_probing(struct ath_buf *bf)\r\n{\r\nstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(bf->bf_mpdu);\r\nreturn bf_isampdu(bf) && !(info->flags & IEEE80211_TX_CTL_RATE_CTRL_PROBE);\r\n}\r\nstatic void ath_tx_process_buffer(struct ath_softc *sc, struct ath_txq *txq,\r\nstruct ath_tx_status *ts, struct ath_buf *bf,\r\nstruct list_head *bf_head)\r\n{\r\nstruct ieee80211_tx_info *info;\r\nbool txok, flush;\r\ntxok = !(ts->ts_status & ATH9K_TXERR_MASK);\r\nflush = !!(ts->ts_status & ATH9K_TX_FLUSH);\r\ntxq->axq_tx_inprogress = false;\r\ntxq->axq_depth--;\r\nif (bf_is_ampdu_not_probing(bf))\r\ntxq->axq_ampdu_depth--;\r\nts->duration = ath9k_hw_get_duration(sc->sc_ah, bf->bf_desc,\r\nts->ts_rateindex);\r\nif (!bf_isampdu(bf)) {\r\nif (!flush) {\r\ninfo = IEEE80211_SKB_CB(bf->bf_mpdu);\r\nmemcpy(info->control.rates, bf->rates,\r\nsizeof(info->control.rates));\r\nath_tx_rc_status(sc, bf, ts, 1, txok ? 0 : 1, txok);\r\nath_dynack_sample_tx_ts(sc->sc_ah, bf->bf_mpdu, ts);\r\n}\r\nath_tx_complete_buf(sc, bf, txq, bf_head, ts, txok);\r\n} else\r\nath_tx_complete_aggr(sc, txq, bf, bf_head, ts, txok);\r\nif (!flush)\r\nath_txq_schedule(sc, txq);\r\n}\r\nstatic bool ath_lookup_legacy(struct ath_buf *bf)\r\n{\r\nstruct sk_buff *skb;\r\nstruct ieee80211_tx_info *tx_info;\r\nstruct ieee80211_tx_rate *rates;\r\nint i;\r\nskb = bf->bf_mpdu;\r\ntx_info = IEEE80211_SKB_CB(skb);\r\nrates = tx_info->control.rates;\r\nfor (i = 0; i < 4; i++) {\r\nif (!rates[i].count || rates[i].idx < 0)\r\nbreak;\r\nif (!(rates[i].flags & IEEE80211_TX_RC_MCS))\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic u32 ath_lookup_rate(struct ath_softc *sc, struct ath_buf *bf,\r\nstruct ath_atx_tid *tid)\r\n{\r\nstruct sk_buff *skb;\r\nstruct ieee80211_tx_info *tx_info;\r\nstruct ieee80211_tx_rate *rates;\r\nu32 max_4ms_framelen, frmlen;\r\nu16 aggr_limit, bt_aggr_limit, legacy = 0;\r\nint q = tid->txq->mac80211_qnum;\r\nint i;\r\nskb = bf->bf_mpdu;\r\ntx_info = IEEE80211_SKB_CB(skb);\r\nrates = bf->rates;\r\nmax_4ms_framelen = ATH_AMPDU_LIMIT_MAX;\r\nfor (i = 0; i < 4; i++) {\r\nint modeidx;\r\nif (!rates[i].count)\r\ncontinue;\r\nif (!(rates[i].flags & IEEE80211_TX_RC_MCS)) {\r\nlegacy = 1;\r\nbreak;\r\n}\r\nif (rates[i].flags & IEEE80211_TX_RC_40_MHZ_WIDTH)\r\nmodeidx = MCS_HT40;\r\nelse\r\nmodeidx = MCS_HT20;\r\nif (rates[i].flags & IEEE80211_TX_RC_SHORT_GI)\r\nmodeidx++;\r\nfrmlen = sc->tx.max_aggr_framelen[q][modeidx][rates[i].idx];\r\nmax_4ms_framelen = min(max_4ms_framelen, frmlen);\r\n}\r\nif (tx_info->flags & IEEE80211_TX_CTL_RATE_CTRL_PROBE || legacy)\r\nreturn 0;\r\naggr_limit = min(max_4ms_framelen, (u32)ATH_AMPDU_LIMIT_MAX);\r\nbt_aggr_limit = ath9k_btcoex_aggr_limit(sc, max_4ms_framelen);\r\nif (bt_aggr_limit)\r\naggr_limit = bt_aggr_limit;\r\nif (tid->an->maxampdu)\r\naggr_limit = min(aggr_limit, tid->an->maxampdu);\r\nreturn aggr_limit;\r\n}\r\nstatic int ath_compute_num_delims(struct ath_softc *sc, struct ath_atx_tid *tid,\r\nstruct ath_buf *bf, u16 frmlen,\r\nbool first_subfrm)\r\n{\r\n#define FIRST_DESC_NDELIMS 60\r\nu32 nsymbits, nsymbols;\r\nu16 minlen;\r\nu8 flags, rix;\r\nint width, streams, half_gi, ndelim, mindelim;\r\nstruct ath_frame_info *fi = get_frame_info(bf->bf_mpdu);\r\nndelim = ATH_AGGR_GET_NDELIM(frmlen);\r\nif ((fi->keyix != ATH9K_TXKEYIX_INVALID) &&\r\n!(sc->sc_ah->caps.hw_caps & ATH9K_HW_CAP_EDMA))\r\nndelim += ATH_AGGR_ENCRYPTDELIM;\r\nif (first_subfrm && !AR_SREV_9580_10_OR_LATER(sc->sc_ah) &&\r\n(sc->sc_ah->ent_mode & AR_ENT_OTP_MIN_PKT_SIZE_DISABLE))\r\nndelim = max(ndelim, FIRST_DESC_NDELIMS);\r\nif (tid->an->mpdudensity == 0)\r\nreturn ndelim;\r\nrix = bf->rates[0].idx;\r\nflags = bf->rates[0].flags;\r\nwidth = (flags & IEEE80211_TX_RC_40_MHZ_WIDTH) ? 1 : 0;\r\nhalf_gi = (flags & IEEE80211_TX_RC_SHORT_GI) ? 1 : 0;\r\nif (half_gi)\r\nnsymbols = NUM_SYMBOLS_PER_USEC_HALFGI(tid->an->mpdudensity);\r\nelse\r\nnsymbols = NUM_SYMBOLS_PER_USEC(tid->an->mpdudensity);\r\nif (nsymbols == 0)\r\nnsymbols = 1;\r\nstreams = HT_RC_2_STREAMS(rix);\r\nnsymbits = bits_per_symbol[rix % 8][width] * streams;\r\nminlen = (nsymbols * nsymbits) / BITS_PER_BYTE;\r\nif (frmlen < minlen) {\r\nmindelim = (minlen - frmlen) / ATH_AGGR_DELIM_SZ;\r\nndelim = max(mindelim, ndelim);\r\n}\r\nreturn ndelim;\r\n}\r\nstatic struct ath_buf *\r\nath_tx_get_tid_subframe(struct ath_softc *sc, struct ath_txq *txq,\r\nstruct ath_atx_tid *tid, struct sk_buff_head **q)\r\n{\r\nstruct ieee80211_tx_info *tx_info;\r\nstruct ath_frame_info *fi;\r\nstruct sk_buff *skb;\r\nstruct ath_buf *bf;\r\nu16 seqno;\r\nwhile (1) {\r\n*q = &tid->retry_q;\r\nif (skb_queue_empty(*q))\r\n*q = &tid->buf_q;\r\nskb = skb_peek(*q);\r\nif (!skb)\r\nbreak;\r\nfi = get_frame_info(skb);\r\nbf = fi->bf;\r\nif (!fi->bf)\r\nbf = ath_tx_setup_buffer(sc, txq, tid, skb);\r\nelse\r\nbf->bf_state.stale = false;\r\nif (!bf) {\r\n__skb_unlink(skb, *q);\r\nath_txq_skb_done(sc, txq, skb);\r\nieee80211_free_txskb(sc->hw, skb);\r\ncontinue;\r\n}\r\nbf->bf_next = NULL;\r\nbf->bf_lastbf = bf;\r\ntx_info = IEEE80211_SKB_CB(skb);\r\ntx_info->flags &= ~IEEE80211_TX_CTL_CLEAR_PS_FILT;\r\nif (!tid->active)\r\ntx_info->flags &= ~IEEE80211_TX_CTL_AMPDU;\r\nif (!(tx_info->flags & IEEE80211_TX_CTL_AMPDU)) {\r\nbf->bf_state.bf_type = 0;\r\nreturn bf;\r\n}\r\nbf->bf_state.bf_type = BUF_AMPDU | BUF_AGGR;\r\nseqno = bf->bf_state.seqno;\r\nif (!BAW_WITHIN(tid->seq_start, tid->baw_size, seqno))\r\nbreak;\r\nif (tid->bar_index > ATH_BA_INDEX(tid->seq_start, seqno)) {\r\nstruct ath_tx_status ts = {};\r\nstruct list_head bf_head;\r\nINIT_LIST_HEAD(&bf_head);\r\nlist_add(&bf->list, &bf_head);\r\n__skb_unlink(skb, *q);\r\nath_tx_update_baw(sc, tid, seqno);\r\nath_tx_complete_buf(sc, bf, txq, &bf_head, &ts, 0);\r\ncontinue;\r\n}\r\nreturn bf;\r\n}\r\nreturn NULL;\r\n}\r\nstatic bool\r\nath_tx_form_aggr(struct ath_softc *sc, struct ath_txq *txq,\r\nstruct ath_atx_tid *tid, struct list_head *bf_q,\r\nstruct ath_buf *bf_first, struct sk_buff_head *tid_q,\r\nint *aggr_len)\r\n{\r\n#define PADBYTES(_len) ((4 - ((_len) % 4)) % 4)\r\nstruct ath_buf *bf = bf_first, *bf_prev = NULL;\r\nint nframes = 0, ndelim;\r\nu16 aggr_limit = 0, al = 0, bpad = 0,\r\nal_delta, h_baw = tid->baw_size / 2;\r\nstruct ieee80211_tx_info *tx_info;\r\nstruct ath_frame_info *fi;\r\nstruct sk_buff *skb;\r\nbool closed = false;\r\nbf = bf_first;\r\naggr_limit = ath_lookup_rate(sc, bf, tid);\r\ndo {\r\nskb = bf->bf_mpdu;\r\nfi = get_frame_info(skb);\r\nal_delta = ATH_AGGR_DELIM_SZ + fi->framelen;\r\nif (nframes) {\r\nif (aggr_limit < al + bpad + al_delta ||\r\nath_lookup_legacy(bf) || nframes >= h_baw)\r\nbreak;\r\ntx_info = IEEE80211_SKB_CB(bf->bf_mpdu);\r\nif ((tx_info->flags & IEEE80211_TX_CTL_RATE_CTRL_PROBE) ||\r\n!(tx_info->flags & IEEE80211_TX_CTL_AMPDU))\r\nbreak;\r\n}\r\nal += bpad + al_delta;\r\nndelim = ath_compute_num_delims(sc, tid, bf_first, fi->framelen,\r\n!nframes);\r\nbpad = PADBYTES(al_delta) + (ndelim << 2);\r\nnframes++;\r\nbf->bf_next = NULL;\r\nif (!fi->baw_tracked)\r\nath_tx_addto_baw(sc, tid, bf);\r\nbf->bf_state.ndelim = ndelim;\r\n__skb_unlink(skb, tid_q);\r\nlist_add_tail(&bf->list, bf_q);\r\nif (bf_prev)\r\nbf_prev->bf_next = bf;\r\nbf_prev = bf;\r\nbf = ath_tx_get_tid_subframe(sc, txq, tid, &tid_q);\r\nif (!bf) {\r\nclosed = true;\r\nbreak;\r\n}\r\n} while (ath_tid_has_buffered(tid));\r\nbf = bf_first;\r\nbf->bf_lastbf = bf_prev;\r\nif (bf == bf_prev) {\r\nal = get_frame_info(bf->bf_mpdu)->framelen;\r\nbf->bf_state.bf_type = BUF_AMPDU;\r\n} else {\r\nTX_STAT_INC(txq->axq_qnum, a_aggr);\r\n}\r\n*aggr_len = al;\r\nreturn closed;\r\n#undef PADBYTES\r\n}\r\nstatic u32 ath_pkt_duration(struct ath_softc *sc, u8 rix, int pktlen,\r\nint width, int half_gi, bool shortPreamble)\r\n{\r\nu32 nbits, nsymbits, duration, nsymbols;\r\nint streams;\r\nstreams = HT_RC_2_STREAMS(rix);\r\nnbits = (pktlen << 3) + OFDM_PLCP_BITS;\r\nnsymbits = bits_per_symbol[rix % 8][width] * streams;\r\nnsymbols = (nbits + nsymbits - 1) / nsymbits;\r\nif (!half_gi)\r\nduration = SYMBOL_TIME(nsymbols);\r\nelse\r\nduration = SYMBOL_TIME_HALFGI(nsymbols);\r\nduration += L_STF + L_LTF + L_SIG + HT_SIG + HT_STF + HT_LTF(streams);\r\nreturn duration;\r\n}\r\nstatic int ath_max_framelen(int usec, int mcs, bool ht40, bool sgi)\r\n{\r\nint streams = HT_RC_2_STREAMS(mcs);\r\nint symbols, bits;\r\nint bytes = 0;\r\nusec -= L_STF + L_LTF + L_SIG + HT_SIG + HT_STF + HT_LTF(streams);\r\nsymbols = sgi ? TIME_SYMBOLS_HALFGI(usec) : TIME_SYMBOLS(usec);\r\nbits = symbols * bits_per_symbol[mcs % 8][ht40] * streams;\r\nbits -= OFDM_PLCP_BITS;\r\nbytes = bits / 8;\r\nif (bytes > 65532)\r\nbytes = 65532;\r\nreturn bytes;\r\n}\r\nvoid ath_update_max_aggr_framelen(struct ath_softc *sc, int queue, int txop)\r\n{\r\nu16 *cur_ht20, *cur_ht20_sgi, *cur_ht40, *cur_ht40_sgi;\r\nint mcs;\r\nif (!txop || txop > 4096)\r\ntxop = 4096;\r\ncur_ht20 = sc->tx.max_aggr_framelen[queue][MCS_HT20];\r\ncur_ht20_sgi = sc->tx.max_aggr_framelen[queue][MCS_HT20_SGI];\r\ncur_ht40 = sc->tx.max_aggr_framelen[queue][MCS_HT40];\r\ncur_ht40_sgi = sc->tx.max_aggr_framelen[queue][MCS_HT40_SGI];\r\nfor (mcs = 0; mcs < 32; mcs++) {\r\ncur_ht20[mcs] = ath_max_framelen(txop, mcs, false, false);\r\ncur_ht20_sgi[mcs] = ath_max_framelen(txop, mcs, false, true);\r\ncur_ht40[mcs] = ath_max_framelen(txop, mcs, true, false);\r\ncur_ht40_sgi[mcs] = ath_max_framelen(txop, mcs, true, true);\r\n}\r\n}\r\nstatic u8 ath_get_rate_txpower(struct ath_softc *sc, struct ath_buf *bf,\r\nu8 rateidx, bool is_40, bool is_cck)\r\n{\r\nu8 max_power;\r\nstruct sk_buff *skb;\r\nstruct ath_frame_info *fi;\r\nstruct ieee80211_tx_info *info;\r\nstruct ath_hw *ah = sc->sc_ah;\r\nif (sc->tx99_state || !ah->tpc_enabled)\r\nreturn MAX_RATE_POWER;\r\nskb = bf->bf_mpdu;\r\nfi = get_frame_info(skb);\r\ninfo = IEEE80211_SKB_CB(skb);\r\nif (!AR_SREV_9300_20_OR_LATER(ah)) {\r\nint txpower = fi->tx_power;\r\nif (is_40) {\r\nu8 power_ht40delta;\r\nstruct ar5416_eeprom_def *eep = &ah->eeprom.def;\r\nif (AR5416_VER_MASK >= AR5416_EEP_MINOR_VER_2) {\r\nbool is_2ghz;\r\nstruct modal_eep_header *pmodal;\r\nis_2ghz = info->band == NL80211_BAND_2GHZ;\r\npmodal = &eep->modalHeader[is_2ghz];\r\npower_ht40delta = pmodal->ht40PowerIncForPdadc;\r\n} else {\r\npower_ht40delta = 2;\r\n}\r\ntxpower += power_ht40delta;\r\n}\r\nif (AR_SREV_9287(ah) || AR_SREV_9285(ah) ||\r\nAR_SREV_9271(ah)) {\r\ntxpower -= 2 * AR9287_PWR_TABLE_OFFSET_DB;\r\n} else if (AR_SREV_9280_20_OR_LATER(ah)) {\r\ns8 power_offset;\r\npower_offset = ah->eep_ops->get_eeprom(ah,\r\nEEP_PWR_TABLE_OFFSET);\r\ntxpower -= 2 * power_offset;\r\n}\r\nif (OLC_FOR_AR9280_20_LATER && is_cck)\r\ntxpower -= 2;\r\ntxpower = max(txpower, 0);\r\nmax_power = min_t(u8, ah->tx_power[rateidx], txpower);\r\nif (!max_power && !AR_SREV_9280_20_OR_LATER(ah))\r\nmax_power = 1;\r\n} else if (!bf->bf_state.bfs_paprd) {\r\nif (rateidx < 8 && (info->flags & IEEE80211_TX_CTL_STBC))\r\nmax_power = min_t(u8, ah->tx_power_stbc[rateidx],\r\nfi->tx_power);\r\nelse\r\nmax_power = min_t(u8, ah->tx_power[rateidx],\r\nfi->tx_power);\r\n} else {\r\nmax_power = ah->paprd_training_power;\r\n}\r\nreturn max_power;\r\n}\r\nstatic void ath_buf_set_rate(struct ath_softc *sc, struct ath_buf *bf,\r\nstruct ath_tx_info *info, int len, bool rts)\r\n{\r\nstruct ath_hw *ah = sc->sc_ah;\r\nstruct ath_common *common = ath9k_hw_common(ah);\r\nstruct sk_buff *skb;\r\nstruct ieee80211_tx_info *tx_info;\r\nstruct ieee80211_tx_rate *rates;\r\nconst struct ieee80211_rate *rate;\r\nstruct ieee80211_hdr *hdr;\r\nstruct ath_frame_info *fi = get_frame_info(bf->bf_mpdu);\r\nu32 rts_thresh = sc->hw->wiphy->rts_threshold;\r\nint i;\r\nu8 rix = 0;\r\nskb = bf->bf_mpdu;\r\ntx_info = IEEE80211_SKB_CB(skb);\r\nrates = bf->rates;\r\nhdr = (struct ieee80211_hdr *)skb->data;\r\ninfo->dur_update = !ieee80211_is_pspoll(hdr->frame_control);\r\ninfo->rtscts_rate = fi->rtscts_rate;\r\nfor (i = 0; i < ARRAY_SIZE(bf->rates); i++) {\r\nbool is_40, is_sgi, is_sp, is_cck;\r\nint phy;\r\nif (!rates[i].count || (rates[i].idx < 0))\r\ncontinue;\r\nrix = rates[i].idx;\r\ninfo->rates[i].Tries = rates[i].count;\r\nif (bf_isampdu(bf) && !bf_isaggr(bf) &&\r\n(rates[i].flags & IEEE80211_TX_RC_MCS) &&\r\nunlikely(rts_thresh != (u32) -1)) {\r\nif (!rts_thresh || (len > rts_thresh))\r\nrts = true;\r\n}\r\nif (rts || rates[i].flags & IEEE80211_TX_RC_USE_RTS_CTS) {\r\ninfo->rates[i].RateFlags |= ATH9K_RATESERIES_RTS_CTS;\r\ninfo->flags |= ATH9K_TXDESC_RTSENA;\r\n} else if (rates[i].flags & IEEE80211_TX_RC_USE_CTS_PROTECT) {\r\ninfo->rates[i].RateFlags |= ATH9K_RATESERIES_RTS_CTS;\r\ninfo->flags |= ATH9K_TXDESC_CTSENA;\r\n}\r\nif (rates[i].flags & IEEE80211_TX_RC_40_MHZ_WIDTH)\r\ninfo->rates[i].RateFlags |= ATH9K_RATESERIES_2040;\r\nif (rates[i].flags & IEEE80211_TX_RC_SHORT_GI)\r\ninfo->rates[i].RateFlags |= ATH9K_RATESERIES_HALFGI;\r\nis_sgi = !!(rates[i].flags & IEEE80211_TX_RC_SHORT_GI);\r\nis_40 = !!(rates[i].flags & IEEE80211_TX_RC_40_MHZ_WIDTH);\r\nis_sp = !!(rates[i].flags & IEEE80211_TX_RC_USE_SHORT_PREAMBLE);\r\nif (rates[i].flags & IEEE80211_TX_RC_MCS) {\r\ninfo->rates[i].Rate = rix | 0x80;\r\ninfo->rates[i].ChSel = ath_txchainmask_reduction(sc,\r\nah->txchainmask, info->rates[i].Rate);\r\ninfo->rates[i].PktDuration = ath_pkt_duration(sc, rix, len,\r\nis_40, is_sgi, is_sp);\r\nif (rix < 8 && (tx_info->flags & IEEE80211_TX_CTL_STBC))\r\ninfo->rates[i].RateFlags |= ATH9K_RATESERIES_STBC;\r\ninfo->txpower[i] = ath_get_rate_txpower(sc, bf, rix,\r\nis_40, false);\r\ncontinue;\r\n}\r\nrate = &common->sbands[tx_info->band].bitrates[rates[i].idx];\r\nif ((tx_info->band == NL80211_BAND_2GHZ) &&\r\n!(rate->flags & IEEE80211_RATE_ERP_G))\r\nphy = WLAN_RC_PHY_CCK;\r\nelse\r\nphy = WLAN_RC_PHY_OFDM;\r\ninfo->rates[i].Rate = rate->hw_value;\r\nif (rate->hw_value_short) {\r\nif (rates[i].flags & IEEE80211_TX_RC_USE_SHORT_PREAMBLE)\r\ninfo->rates[i].Rate |= rate->hw_value_short;\r\n} else {\r\nis_sp = false;\r\n}\r\nif (bf->bf_state.bfs_paprd)\r\ninfo->rates[i].ChSel = ah->txchainmask;\r\nelse\r\ninfo->rates[i].ChSel = ath_txchainmask_reduction(sc,\r\nah->txchainmask, info->rates[i].Rate);\r\ninfo->rates[i].PktDuration = ath9k_hw_computetxtime(sc->sc_ah,\r\nphy, rate->bitrate * 100, len, rix, is_sp);\r\nis_cck = IS_CCK_RATE(info->rates[i].Rate);\r\ninfo->txpower[i] = ath_get_rate_txpower(sc, bf, rix, false,\r\nis_cck);\r\n}\r\nif (bf_isaggr(bf) && (len > sc->sc_ah->caps.rts_aggr_limit))\r\ninfo->flags &= ~ATH9K_TXDESC_RTSENA;\r\nif (info->flags & ATH9K_TXDESC_RTSENA)\r\ninfo->flags &= ~ATH9K_TXDESC_CTSENA;\r\n}\r\nstatic enum ath9k_pkt_type get_hw_packet_type(struct sk_buff *skb)\r\n{\r\nstruct ieee80211_hdr *hdr;\r\nenum ath9k_pkt_type htype;\r\n__le16 fc;\r\nhdr = (struct ieee80211_hdr *)skb->data;\r\nfc = hdr->frame_control;\r\nif (ieee80211_is_beacon(fc))\r\nhtype = ATH9K_PKT_TYPE_BEACON;\r\nelse if (ieee80211_is_probe_resp(fc))\r\nhtype = ATH9K_PKT_TYPE_PROBE_RESP;\r\nelse if (ieee80211_is_atim(fc))\r\nhtype = ATH9K_PKT_TYPE_ATIM;\r\nelse if (ieee80211_is_pspoll(fc))\r\nhtype = ATH9K_PKT_TYPE_PSPOLL;\r\nelse\r\nhtype = ATH9K_PKT_TYPE_NORMAL;\r\nreturn htype;\r\n}\r\nstatic void ath_tx_fill_desc(struct ath_softc *sc, struct ath_buf *bf,\r\nstruct ath_txq *txq, int len)\r\n{\r\nstruct ath_hw *ah = sc->sc_ah;\r\nstruct ath_buf *bf_first = NULL;\r\nstruct ath_tx_info info;\r\nu32 rts_thresh = sc->hw->wiphy->rts_threshold;\r\nbool rts = false;\r\nmemset(&info, 0, sizeof(info));\r\ninfo.is_first = true;\r\ninfo.is_last = true;\r\ninfo.qcu = txq->axq_qnum;\r\nwhile (bf) {\r\nstruct sk_buff *skb = bf->bf_mpdu;\r\nstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\r\nstruct ath_frame_info *fi = get_frame_info(skb);\r\nbool aggr = !!(bf->bf_state.bf_type & BUF_AGGR);\r\ninfo.type = get_hw_packet_type(skb);\r\nif (bf->bf_next)\r\ninfo.link = bf->bf_next->bf_daddr;\r\nelse\r\ninfo.link = (sc->tx99_state) ? bf->bf_daddr : 0;\r\nif (!bf_first) {\r\nbf_first = bf;\r\nif (!sc->tx99_state)\r\ninfo.flags = ATH9K_TXDESC_INTREQ;\r\nif ((tx_info->flags & IEEE80211_TX_CTL_CLEAR_PS_FILT) ||\r\ntxq == sc->tx.uapsdq)\r\ninfo.flags |= ATH9K_TXDESC_CLRDMASK;\r\nif (tx_info->flags & IEEE80211_TX_CTL_NO_ACK)\r\ninfo.flags |= ATH9K_TXDESC_NOACK;\r\nif (tx_info->flags & IEEE80211_TX_CTL_LDPC)\r\ninfo.flags |= ATH9K_TXDESC_LDPC;\r\nif (bf->bf_state.bfs_paprd)\r\ninfo.flags |= (u32) bf->bf_state.bfs_paprd <<\r\nATH9K_TXDESC_PAPRD_S;\r\nif (aggr && (bf == bf_first) &&\r\nunlikely(rts_thresh != (u32) -1)) {\r\nif (!rts_thresh || (len > rts_thresh))\r\nrts = true;\r\n}\r\nif (!aggr)\r\nlen = fi->framelen;\r\nath_buf_set_rate(sc, bf, &info, len, rts);\r\n}\r\ninfo.buf_addr[0] = bf->bf_buf_addr;\r\ninfo.buf_len[0] = skb->len;\r\ninfo.pkt_len = fi->framelen;\r\ninfo.keyix = fi->keyix;\r\ninfo.keytype = fi->keytype;\r\nif (aggr) {\r\nif (bf == bf_first)\r\ninfo.aggr = AGGR_BUF_FIRST;\r\nelse if (bf == bf_first->bf_lastbf)\r\ninfo.aggr = AGGR_BUF_LAST;\r\nelse\r\ninfo.aggr = AGGR_BUF_MIDDLE;\r\ninfo.ndelim = bf->bf_state.ndelim;\r\ninfo.aggr_len = len;\r\n}\r\nif (bf == bf_first->bf_lastbf)\r\nbf_first = NULL;\r\nath9k_hw_set_txdesc(ah, bf->bf_desc, &info);\r\nbf = bf->bf_next;\r\n}\r\n}\r\nstatic void\r\nath_tx_form_burst(struct ath_softc *sc, struct ath_txq *txq,\r\nstruct ath_atx_tid *tid, struct list_head *bf_q,\r\nstruct ath_buf *bf_first, struct sk_buff_head *tid_q)\r\n{\r\nstruct ath_buf *bf = bf_first, *bf_prev = NULL;\r\nstruct sk_buff *skb;\r\nint nframes = 0;\r\ndo {\r\nstruct ieee80211_tx_info *tx_info;\r\nskb = bf->bf_mpdu;\r\nnframes++;\r\n__skb_unlink(skb, tid_q);\r\nlist_add_tail(&bf->list, bf_q);\r\nif (bf_prev)\r\nbf_prev->bf_next = bf;\r\nbf_prev = bf;\r\nif (nframes >= 2)\r\nbreak;\r\nbf = ath_tx_get_tid_subframe(sc, txq, tid, &tid_q);\r\nif (!bf)\r\nbreak;\r\ntx_info = IEEE80211_SKB_CB(bf->bf_mpdu);\r\nif (tx_info->flags & IEEE80211_TX_CTL_AMPDU)\r\nbreak;\r\nath_set_rates(tid->an->vif, tid->an->sta, bf);\r\n} while (1);\r\n}\r\nstatic bool ath_tx_sched_aggr(struct ath_softc *sc, struct ath_txq *txq,\r\nstruct ath_atx_tid *tid, bool *stop)\r\n{\r\nstruct ath_buf *bf;\r\nstruct ieee80211_tx_info *tx_info;\r\nstruct sk_buff_head *tid_q;\r\nstruct list_head bf_q;\r\nint aggr_len = 0;\r\nbool aggr, last = true;\r\nif (!ath_tid_has_buffered(tid))\r\nreturn false;\r\nINIT_LIST_HEAD(&bf_q);\r\nbf = ath_tx_get_tid_subframe(sc, txq, tid, &tid_q);\r\nif (!bf)\r\nreturn false;\r\ntx_info = IEEE80211_SKB_CB(bf->bf_mpdu);\r\naggr = !!(tx_info->flags & IEEE80211_TX_CTL_AMPDU);\r\nif ((aggr && txq->axq_ampdu_depth >= ATH_AGGR_MIN_QDEPTH) ||\r\n(!aggr && txq->axq_depth >= ATH_NON_AGGR_MIN_QDEPTH)) {\r\n*stop = true;\r\nreturn false;\r\n}\r\nath_set_rates(tid->an->vif, tid->an->sta, bf);\r\nif (aggr)\r\nlast = ath_tx_form_aggr(sc, txq, tid, &bf_q, bf,\r\ntid_q, &aggr_len);\r\nelse\r\nath_tx_form_burst(sc, txq, tid, &bf_q, bf, tid_q);\r\nif (list_empty(&bf_q))\r\nreturn false;\r\nif (tid->clear_ps_filter || tid->an->no_ps_filter) {\r\ntid->clear_ps_filter = false;\r\ntx_info->flags |= IEEE80211_TX_CTL_CLEAR_PS_FILT;\r\n}\r\nath_tx_fill_desc(sc, bf, txq, aggr_len);\r\nath_tx_txqaddbuf(sc, txq, &bf_q, false);\r\nreturn true;\r\n}\r\nint ath_tx_aggr_start(struct ath_softc *sc, struct ieee80211_sta *sta,\r\nu16 tid, u16 *ssn)\r\n{\r\nstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\r\nstruct ath_atx_tid *txtid;\r\nstruct ath_txq *txq;\r\nstruct ath_node *an;\r\nu8 density;\r\nath_dbg(common, XMIT, "%s called\n", __func__);\r\nan = (struct ath_node *)sta->drv_priv;\r\ntxtid = ATH_AN_2_TID(an, tid);\r\ntxq = txtid->txq;\r\nath_txq_lock(sc, txq);\r\nif (sta->ht_cap.ht_supported) {\r\nan->maxampdu = (1 << (IEEE80211_HT_MAX_AMPDU_FACTOR +\r\nsta->ht_cap.ampdu_factor)) - 1;\r\ndensity = ath9k_parse_mpdudensity(sta->ht_cap.ampdu_density);\r\nan->mpdudensity = density;\r\n}\r\nath_tx_tid_change_state(sc, txtid);\r\ntxtid->active = true;\r\n*ssn = txtid->seq_start = txtid->seq_next;\r\ntxtid->bar_index = -1;\r\nmemset(txtid->tx_buf, 0, sizeof(txtid->tx_buf));\r\ntxtid->baw_head = txtid->baw_tail = 0;\r\nath_txq_unlock_complete(sc, txq);\r\nreturn 0;\r\n}\r\nvoid ath_tx_aggr_stop(struct ath_softc *sc, struct ieee80211_sta *sta, u16 tid)\r\n{\r\nstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\r\nstruct ath_node *an = (struct ath_node *)sta->drv_priv;\r\nstruct ath_atx_tid *txtid = ATH_AN_2_TID(an, tid);\r\nstruct ath_txq *txq = txtid->txq;\r\nath_dbg(common, XMIT, "%s called\n", __func__);\r\nath_txq_lock(sc, txq);\r\ntxtid->active = false;\r\nath_tx_flush_tid(sc, txtid);\r\nath_tx_tid_change_state(sc, txtid);\r\nath_txq_unlock_complete(sc, txq);\r\n}\r\nvoid ath_tx_aggr_sleep(struct ieee80211_sta *sta, struct ath_softc *sc,\r\nstruct ath_node *an)\r\n{\r\nstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\r\nstruct ath_atx_tid *tid;\r\nstruct ath_txq *txq;\r\nbool buffered;\r\nint tidno;\r\nath_dbg(common, XMIT, "%s called\n", __func__);\r\nfor (tidno = 0, tid = &an->tid[tidno];\r\ntidno < IEEE80211_NUM_TIDS; tidno++, tid++) {\r\ntxq = tid->txq;\r\nath_txq_lock(sc, txq);\r\nif (list_empty(&tid->list)) {\r\nath_txq_unlock(sc, txq);\r\ncontinue;\r\n}\r\nbuffered = ath_tid_has_buffered(tid);\r\nlist_del_init(&tid->list);\r\nath_txq_unlock(sc, txq);\r\nieee80211_sta_set_buffered(sta, tidno, buffered);\r\n}\r\n}\r\nvoid ath_tx_aggr_wakeup(struct ath_softc *sc, struct ath_node *an)\r\n{\r\nstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\r\nstruct ath_atx_tid *tid;\r\nstruct ath_txq *txq;\r\nint tidno;\r\nath_dbg(common, XMIT, "%s called\n", __func__);\r\nfor (tidno = 0, tid = &an->tid[tidno];\r\ntidno < IEEE80211_NUM_TIDS; tidno++, tid++) {\r\ntxq = tid->txq;\r\nath_txq_lock(sc, txq);\r\ntid->clear_ps_filter = true;\r\nif (ath_tid_has_buffered(tid)) {\r\nath_tx_queue_tid(sc, txq, tid);\r\nath_txq_schedule(sc, txq);\r\n}\r\nath_txq_unlock_complete(sc, txq);\r\n}\r\n}\r\nvoid ath_tx_aggr_resume(struct ath_softc *sc, struct ieee80211_sta *sta,\r\nu16 tidno)\r\n{\r\nstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\r\nstruct ath_atx_tid *tid;\r\nstruct ath_node *an;\r\nstruct ath_txq *txq;\r\nath_dbg(common, XMIT, "%s called\n", __func__);\r\nan = (struct ath_node *)sta->drv_priv;\r\ntid = ATH_AN_2_TID(an, tidno);\r\ntxq = tid->txq;\r\nath_txq_lock(sc, txq);\r\ntid->baw_size = IEEE80211_MIN_AMPDU_BUF << sta->ht_cap.ampdu_factor;\r\nif (ath_tid_has_buffered(tid)) {\r\nath_tx_queue_tid(sc, txq, tid);\r\nath_txq_schedule(sc, txq);\r\n}\r\nath_txq_unlock_complete(sc, txq);\r\n}\r\nvoid ath9k_release_buffered_frames(struct ieee80211_hw *hw,\r\nstruct ieee80211_sta *sta,\r\nu16 tids, int nframes,\r\nenum ieee80211_frame_release_type reason,\r\nbool more_data)\r\n{\r\nstruct ath_softc *sc = hw->priv;\r\nstruct ath_node *an = (struct ath_node *)sta->drv_priv;\r\nstruct ath_txq *txq = sc->tx.uapsdq;\r\nstruct ieee80211_tx_info *info;\r\nstruct list_head bf_q;\r\nstruct ath_buf *bf_tail = NULL, *bf;\r\nstruct sk_buff_head *tid_q;\r\nint sent = 0;\r\nint i;\r\nINIT_LIST_HEAD(&bf_q);\r\nfor (i = 0; tids && nframes; i++, tids >>= 1) {\r\nstruct ath_atx_tid *tid;\r\nif (!(tids & 1))\r\ncontinue;\r\ntid = ATH_AN_2_TID(an, i);\r\nath_txq_lock(sc, tid->txq);\r\nwhile (nframes > 0) {\r\nbf = ath_tx_get_tid_subframe(sc, sc->tx.uapsdq, tid, &tid_q);\r\nif (!bf)\r\nbreak;\r\n__skb_unlink(bf->bf_mpdu, tid_q);\r\nlist_add_tail(&bf->list, &bf_q);\r\nath_set_rates(tid->an->vif, tid->an->sta, bf);\r\nif (bf_isampdu(bf)) {\r\nath_tx_addto_baw(sc, tid, bf);\r\nbf->bf_state.bf_type &= ~BUF_AGGR;\r\n}\r\nif (bf_tail)\r\nbf_tail->bf_next = bf;\r\nbf_tail = bf;\r\nnframes--;\r\nsent++;\r\nTX_STAT_INC(txq->axq_qnum, a_queued_hw);\r\nif (an->sta && !ath_tid_has_buffered(tid))\r\nieee80211_sta_set_buffered(an->sta, i, false);\r\n}\r\nath_txq_unlock_complete(sc, tid->txq);\r\n}\r\nif (list_empty(&bf_q))\r\nreturn;\r\ninfo = IEEE80211_SKB_CB(bf_tail->bf_mpdu);\r\ninfo->flags |= IEEE80211_TX_STATUS_EOSP;\r\nbf = list_first_entry(&bf_q, struct ath_buf, list);\r\nath_txq_lock(sc, txq);\r\nath_tx_fill_desc(sc, bf, txq, 0);\r\nath_tx_txqaddbuf(sc, txq, &bf_q, false);\r\nath_txq_unlock(sc, txq);\r\n}\r\nstruct ath_txq *ath_txq_setup(struct ath_softc *sc, int qtype, int subtype)\r\n{\r\nstruct ath_hw *ah = sc->sc_ah;\r\nstruct ath9k_tx_queue_info qi;\r\nstatic const int subtype_txq_to_hwq[] = {\r\n[IEEE80211_AC_BE] = ATH_TXQ_AC_BE,\r\n[IEEE80211_AC_BK] = ATH_TXQ_AC_BK,\r\n[IEEE80211_AC_VI] = ATH_TXQ_AC_VI,\r\n[IEEE80211_AC_VO] = ATH_TXQ_AC_VO,\r\n};\r\nint axq_qnum, i;\r\nmemset(&qi, 0, sizeof(qi));\r\nqi.tqi_subtype = subtype_txq_to_hwq[subtype];\r\nqi.tqi_aifs = ATH9K_TXQ_USEDEFAULT;\r\nqi.tqi_cwmin = ATH9K_TXQ_USEDEFAULT;\r\nqi.tqi_cwmax = ATH9K_TXQ_USEDEFAULT;\r\nqi.tqi_physCompBuf = 0;\r\nif (ah->caps.hw_caps & ATH9K_HW_CAP_EDMA) {\r\nqi.tqi_qflags = TXQ_FLAG_TXINT_ENABLE;\r\n} else {\r\nif (qtype == ATH9K_TX_QUEUE_UAPSD)\r\nqi.tqi_qflags = TXQ_FLAG_TXDESCINT_ENABLE;\r\nelse\r\nqi.tqi_qflags = TXQ_FLAG_TXEOLINT_ENABLE |\r\nTXQ_FLAG_TXDESCINT_ENABLE;\r\n}\r\naxq_qnum = ath9k_hw_setuptxqueue(ah, qtype, &qi);\r\nif (axq_qnum == -1) {\r\nreturn NULL;\r\n}\r\nif (!ATH_TXQ_SETUP(sc, axq_qnum)) {\r\nstruct ath_txq *txq = &sc->tx.txq[axq_qnum];\r\ntxq->axq_qnum = axq_qnum;\r\ntxq->mac80211_qnum = -1;\r\ntxq->axq_link = NULL;\r\n__skb_queue_head_init(&txq->complete_q);\r\nINIT_LIST_HEAD(&txq->axq_q);\r\nspin_lock_init(&txq->axq_lock);\r\ntxq->axq_depth = 0;\r\ntxq->axq_ampdu_depth = 0;\r\ntxq->axq_tx_inprogress = false;\r\nsc->tx.txqsetup |= 1<<axq_qnum;\r\ntxq->txq_headidx = txq->txq_tailidx = 0;\r\nfor (i = 0; i < ATH_TXFIFO_DEPTH; i++)\r\nINIT_LIST_HEAD(&txq->txq_fifo[i]);\r\n}\r\nreturn &sc->tx.txq[axq_qnum];\r\n}\r\nint ath_txq_update(struct ath_softc *sc, int qnum,\r\nstruct ath9k_tx_queue_info *qinfo)\r\n{\r\nstruct ath_hw *ah = sc->sc_ah;\r\nint error = 0;\r\nstruct ath9k_tx_queue_info qi;\r\nBUG_ON(sc->tx.txq[qnum].axq_qnum != qnum);\r\nath9k_hw_get_txq_props(ah, qnum, &qi);\r\nqi.tqi_aifs = qinfo->tqi_aifs;\r\nqi.tqi_cwmin = qinfo->tqi_cwmin;\r\nqi.tqi_cwmax = qinfo->tqi_cwmax;\r\nqi.tqi_burstTime = qinfo->tqi_burstTime;\r\nqi.tqi_readyTime = qinfo->tqi_readyTime;\r\nif (!ath9k_hw_set_txq_props(ah, qnum, &qi)) {\r\nath_err(ath9k_hw_common(sc->sc_ah),\r\n"Unable to update hardware queue %u!\n", qnum);\r\nerror = -EIO;\r\n} else {\r\nath9k_hw_resettxqueue(ah, qnum);\r\n}\r\nreturn error;\r\n}\r\nint ath_cabq_update(struct ath_softc *sc)\r\n{\r\nstruct ath9k_tx_queue_info qi;\r\nstruct ath_beacon_config *cur_conf = &sc->cur_chan->beacon;\r\nint qnum = sc->beacon.cabq->axq_qnum;\r\nath9k_hw_get_txq_props(sc->sc_ah, qnum, &qi);\r\nqi.tqi_readyTime = (TU_TO_USEC(cur_conf->beacon_interval) *\r\nATH_CABQ_READY_TIME) / 100;\r\nath_txq_update(sc, qnum, &qi);\r\nreturn 0;\r\n}\r\nstatic void ath_drain_txq_list(struct ath_softc *sc, struct ath_txq *txq,\r\nstruct list_head *list)\r\n{\r\nstruct ath_buf *bf, *lastbf;\r\nstruct list_head bf_head;\r\nstruct ath_tx_status ts;\r\nmemset(&ts, 0, sizeof(ts));\r\nts.ts_status = ATH9K_TX_FLUSH;\r\nINIT_LIST_HEAD(&bf_head);\r\nwhile (!list_empty(list)) {\r\nbf = list_first_entry(list, struct ath_buf, list);\r\nif (bf->bf_state.stale) {\r\nlist_del(&bf->list);\r\nath_tx_return_buffer(sc, bf);\r\ncontinue;\r\n}\r\nlastbf = bf->bf_lastbf;\r\nlist_cut_position(&bf_head, list, &lastbf->list);\r\nath_tx_process_buffer(sc, txq, &ts, bf, &bf_head);\r\n}\r\n}\r\nvoid ath_draintxq(struct ath_softc *sc, struct ath_txq *txq)\r\n{\r\nath_txq_lock(sc, txq);\r\nif (sc->sc_ah->caps.hw_caps & ATH9K_HW_CAP_EDMA) {\r\nint idx = txq->txq_tailidx;\r\nwhile (!list_empty(&txq->txq_fifo[idx])) {\r\nath_drain_txq_list(sc, txq, &txq->txq_fifo[idx]);\r\nINCR(idx, ATH_TXFIFO_DEPTH);\r\n}\r\ntxq->txq_tailidx = idx;\r\n}\r\ntxq->axq_link = NULL;\r\ntxq->axq_tx_inprogress = false;\r\nath_drain_txq_list(sc, txq, &txq->axq_q);\r\nath_txq_unlock_complete(sc, txq);\r\n}\r\nbool ath_drain_all_txq(struct ath_softc *sc)\r\n{\r\nstruct ath_hw *ah = sc->sc_ah;\r\nstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\r\nstruct ath_txq *txq;\r\nint i;\r\nu32 npend = 0;\r\nif (test_bit(ATH_OP_INVALID, &common->op_flags))\r\nreturn true;\r\nath9k_hw_abort_tx_dma(ah);\r\nfor (i = 0; i < ATH9K_NUM_TX_QUEUES; i++) {\r\nif (!ATH_TXQ_SETUP(sc, i))\r\ncontinue;\r\nif (!sc->tx.txq[i].axq_depth)\r\ncontinue;\r\nif (ath9k_hw_numtxpending(ah, sc->tx.txq[i].axq_qnum))\r\nnpend |= BIT(i);\r\n}\r\nif (npend) {\r\nRESET_STAT_INC(sc, RESET_TX_DMA_ERROR);\r\nath_dbg(common, RESET,\r\n"Failed to stop TX DMA, queues=0x%03x!\n", npend);\r\n}\r\nfor (i = 0; i < ATH9K_NUM_TX_QUEUES; i++) {\r\nif (!ATH_TXQ_SETUP(sc, i))\r\ncontinue;\r\ntxq = &sc->tx.txq[i];\r\ntxq->stopped = false;\r\nath_draintxq(sc, txq);\r\n}\r\nreturn !npend;\r\n}\r\nvoid ath_tx_cleanupq(struct ath_softc *sc, struct ath_txq *txq)\r\n{\r\nath9k_hw_releasetxqueue(sc->sc_ah, txq->axq_qnum);\r\nsc->tx.txqsetup &= ~(1<<txq->axq_qnum);\r\n}\r\nvoid ath_txq_schedule(struct ath_softc *sc, struct ath_txq *txq)\r\n{\r\nstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\r\nstruct ath_atx_tid *tid, *last_tid;\r\nstruct list_head *tid_list;\r\nbool sent = false;\r\nif (txq->mac80211_qnum < 0)\r\nreturn;\r\nif (test_bit(ATH_OP_HW_RESET, &common->op_flags))\r\nreturn;\r\nspin_lock_bh(&sc->chan_lock);\r\ntid_list = &sc->cur_chan->acq[txq->mac80211_qnum];\r\nif (list_empty(tid_list)) {\r\nspin_unlock_bh(&sc->chan_lock);\r\nreturn;\r\n}\r\nrcu_read_lock();\r\nlast_tid = list_entry(tid_list->prev, struct ath_atx_tid, list);\r\nwhile (!list_empty(tid_list)) {\r\nbool stop = false;\r\nif (sc->cur_chan->stopped)\r\nbreak;\r\ntid = list_first_entry(tid_list, struct ath_atx_tid, list);\r\nlist_del_init(&tid->list);\r\nif (ath_tx_sched_aggr(sc, txq, tid, &stop))\r\nsent = true;\r\nif (ath_tid_has_buffered(tid))\r\nath_tx_queue_tid(sc, txq, tid);\r\nif (stop)\r\nbreak;\r\nif (tid == last_tid) {\r\nif (!sent)\r\nbreak;\r\nsent = false;\r\nlast_tid = list_entry(tid_list->prev,\r\nstruct ath_atx_tid, list);\r\n}\r\n}\r\nrcu_read_unlock();\r\nspin_unlock_bh(&sc->chan_lock);\r\n}\r\nvoid ath_txq_schedule_all(struct ath_softc *sc)\r\n{\r\nstruct ath_txq *txq;\r\nint i;\r\nfor (i = 0; i < IEEE80211_NUM_ACS; i++) {\r\ntxq = sc->tx.txq_map[i];\r\nspin_lock_bh(&txq->axq_lock);\r\nath_txq_schedule(sc, txq);\r\nspin_unlock_bh(&txq->axq_lock);\r\n}\r\n}\r\nstatic void ath_tx_txqaddbuf(struct ath_softc *sc, struct ath_txq *txq,\r\nstruct list_head *head, bool internal)\r\n{\r\nstruct ath_hw *ah = sc->sc_ah;\r\nstruct ath_common *common = ath9k_hw_common(ah);\r\nstruct ath_buf *bf, *bf_last;\r\nbool puttxbuf = false;\r\nbool edma;\r\nif (list_empty(head))\r\nreturn;\r\nedma = !!(ah->caps.hw_caps & ATH9K_HW_CAP_EDMA);\r\nbf = list_first_entry(head, struct ath_buf, list);\r\nbf_last = list_entry(head->prev, struct ath_buf, list);\r\nath_dbg(common, QUEUE, "qnum: %d, txq depth: %d\n",\r\ntxq->axq_qnum, txq->axq_depth);\r\nif (edma && list_empty(&txq->txq_fifo[txq->txq_headidx])) {\r\nlist_splice_tail_init(head, &txq->txq_fifo[txq->txq_headidx]);\r\nINCR(txq->txq_headidx, ATH_TXFIFO_DEPTH);\r\nputtxbuf = true;\r\n} else {\r\nlist_splice_tail_init(head, &txq->axq_q);\r\nif (txq->axq_link) {\r\nath9k_hw_set_desc_link(ah, txq->axq_link, bf->bf_daddr);\r\nath_dbg(common, XMIT, "link[%u] (%p)=%llx (%p)\n",\r\ntxq->axq_qnum, txq->axq_link,\r\nito64(bf->bf_daddr), bf->bf_desc);\r\n} else if (!edma)\r\nputtxbuf = true;\r\ntxq->axq_link = bf_last->bf_desc;\r\n}\r\nif (puttxbuf) {\r\nTX_STAT_INC(txq->axq_qnum, puttxbuf);\r\nath9k_hw_puttxbuf(ah, txq->axq_qnum, bf->bf_daddr);\r\nath_dbg(common, XMIT, "TXDP[%u] = %llx (%p)\n",\r\ntxq->axq_qnum, ito64(bf->bf_daddr), bf->bf_desc);\r\n}\r\nif (!edma || sc->tx99_state) {\r\nTX_STAT_INC(txq->axq_qnum, txstart);\r\nath9k_hw_txstart(ah, txq->axq_qnum);\r\n}\r\nif (!internal) {\r\nwhile (bf) {\r\ntxq->axq_depth++;\r\nif (bf_is_ampdu_not_probing(bf))\r\ntxq->axq_ampdu_depth++;\r\nbf_last = bf->bf_lastbf;\r\nbf = bf_last->bf_next;\r\nbf_last->bf_next = NULL;\r\n}\r\n}\r\n}\r\nstatic void ath_tx_send_normal(struct ath_softc *sc, struct ath_txq *txq,\r\nstruct ath_atx_tid *tid, struct sk_buff *skb)\r\n{\r\nstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\r\nstruct ath_frame_info *fi = get_frame_info(skb);\r\nstruct list_head bf_head;\r\nstruct ath_buf *bf = fi->bf;\r\nINIT_LIST_HEAD(&bf_head);\r\nlist_add_tail(&bf->list, &bf_head);\r\nbf->bf_state.bf_type = 0;\r\nif (tid && (tx_info->flags & IEEE80211_TX_CTL_AMPDU)) {\r\nbf->bf_state.bf_type = BUF_AMPDU;\r\nath_tx_addto_baw(sc, tid, bf);\r\n}\r\nbf->bf_next = NULL;\r\nbf->bf_lastbf = bf;\r\nath_tx_fill_desc(sc, bf, txq, fi->framelen);\r\nath_tx_txqaddbuf(sc, txq, &bf_head, false);\r\nTX_STAT_INC(txq->axq_qnum, queued);\r\n}\r\nstatic void setup_frame_info(struct ieee80211_hw *hw,\r\nstruct ieee80211_sta *sta,\r\nstruct sk_buff *skb,\r\nint framelen)\r\n{\r\nstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\r\nstruct ieee80211_key_conf *hw_key = tx_info->control.hw_key;\r\nstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *)skb->data;\r\nconst struct ieee80211_rate *rate;\r\nstruct ath_frame_info *fi = get_frame_info(skb);\r\nstruct ath_node *an = NULL;\r\nenum ath9k_key_type keytype;\r\nbool short_preamble = false;\r\nu8 txpower;\r\nif (tx_info->control.vif &&\r\ntx_info->control.vif->bss_conf.use_short_preamble)\r\nshort_preamble = true;\r\nrate = ieee80211_get_rts_cts_rate(hw, tx_info);\r\nkeytype = ath9k_cmn_get_hw_crypto_keytype(skb);\r\nif (sta)\r\nan = (struct ath_node *) sta->drv_priv;\r\nif (tx_info->control.vif) {\r\nstruct ieee80211_vif *vif = tx_info->control.vif;\r\ntxpower = 2 * vif->bss_conf.txpower;\r\n} else {\r\nstruct ath_softc *sc = hw->priv;\r\ntxpower = sc->cur_chan->cur_txpower;\r\n}\r\nmemset(fi, 0, sizeof(*fi));\r\nfi->txq = -1;\r\nif (hw_key)\r\nfi->keyix = hw_key->hw_key_idx;\r\nelse if (an && ieee80211_is_data(hdr->frame_control) && an->ps_key > 0)\r\nfi->keyix = an->ps_key;\r\nelse\r\nfi->keyix = ATH9K_TXKEYIX_INVALID;\r\nfi->keytype = keytype;\r\nfi->framelen = framelen;\r\nfi->tx_power = txpower;\r\nif (!rate)\r\nreturn;\r\nfi->rtscts_rate = rate->hw_value;\r\nif (short_preamble)\r\nfi->rtscts_rate |= rate->hw_value_short;\r\n}\r\nu8 ath_txchainmask_reduction(struct ath_softc *sc, u8 chainmask, u32 rate)\r\n{\r\nstruct ath_hw *ah = sc->sc_ah;\r\nstruct ath9k_channel *curchan = ah->curchan;\r\nif ((ah->caps.hw_caps & ATH9K_HW_CAP_APM) && IS_CHAN_5GHZ(curchan) &&\r\n(chainmask == 0x7) && (rate < 0x90))\r\nreturn 0x3;\r\nelse if (AR_SREV_9462(ah) && ath9k_hw_btcoex_is_enabled(ah) &&\r\nIS_CCK_RATE(rate))\r\nreturn 0x2;\r\nelse\r\nreturn chainmask;\r\n}\r\nstatic struct ath_buf *ath_tx_setup_buffer(struct ath_softc *sc,\r\nstruct ath_txq *txq,\r\nstruct ath_atx_tid *tid,\r\nstruct sk_buff *skb)\r\n{\r\nstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\r\nstruct ath_frame_info *fi = get_frame_info(skb);\r\nstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *)skb->data;\r\nstruct ath_buf *bf;\r\nint fragno;\r\nu16 seqno;\r\nbf = ath_tx_get_buffer(sc);\r\nif (!bf) {\r\nath_dbg(common, XMIT, "TX buffers are full\n");\r\nreturn NULL;\r\n}\r\nATH_TXBUF_RESET(bf);\r\nif (tid && ieee80211_is_data_present(hdr->frame_control)) {\r\nfragno = le16_to_cpu(hdr->seq_ctrl) & IEEE80211_SCTL_FRAG;\r\nseqno = tid->seq_next;\r\nhdr->seq_ctrl = cpu_to_le16(tid->seq_next << IEEE80211_SEQ_SEQ_SHIFT);\r\nif (fragno)\r\nhdr->seq_ctrl |= cpu_to_le16(fragno);\r\nif (!ieee80211_has_morefrags(hdr->frame_control))\r\nINCR(tid->seq_next, IEEE80211_SEQ_MAX);\r\nbf->bf_state.seqno = seqno;\r\n}\r\nbf->bf_mpdu = skb;\r\nbf->bf_buf_addr = dma_map_single(sc->dev, skb->data,\r\nskb->len, DMA_TO_DEVICE);\r\nif (unlikely(dma_mapping_error(sc->dev, bf->bf_buf_addr))) {\r\nbf->bf_mpdu = NULL;\r\nbf->bf_buf_addr = 0;\r\nath_err(ath9k_hw_common(sc->sc_ah),\r\n"dma_mapping_error() on TX\n");\r\nath_tx_return_buffer(sc, bf);\r\nreturn NULL;\r\n}\r\nfi->bf = bf;\r\nreturn bf;\r\n}\r\nvoid ath_assign_seq(struct ath_common *common, struct sk_buff *skb)\r\n{\r\nstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *) skb->data;\r\nstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);\r\nstruct ieee80211_vif *vif = info->control.vif;\r\nstruct ath_vif *avp;\r\nif (!(info->flags & IEEE80211_TX_CTL_ASSIGN_SEQ))\r\nreturn;\r\nif (!vif)\r\nreturn;\r\navp = (struct ath_vif *)vif->drv_priv;\r\nif (info->flags & IEEE80211_TX_CTL_FIRST_FRAGMENT)\r\navp->seq_no += 0x10;\r\nhdr->seq_ctrl &= cpu_to_le16(IEEE80211_SCTL_FRAG);\r\nhdr->seq_ctrl |= cpu_to_le16(avp->seq_no);\r\n}\r\nstatic int ath_tx_prepare(struct ieee80211_hw *hw, struct sk_buff *skb,\r\nstruct ath_tx_control *txctl)\r\n{\r\nstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *) skb->data;\r\nstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);\r\nstruct ieee80211_sta *sta = txctl->sta;\r\nstruct ieee80211_vif *vif = info->control.vif;\r\nstruct ath_vif *avp;\r\nstruct ath_softc *sc = hw->priv;\r\nint frmlen = skb->len + FCS_LEN;\r\nint padpos, padsize;\r\nif (sta)\r\ntxctl->an = (struct ath_node *)sta->drv_priv;\r\nelse if (vif && ieee80211_is_data(hdr->frame_control)) {\r\navp = (void *)vif->drv_priv;\r\ntxctl->an = &avp->mcast_node;\r\n}\r\nif (info->control.hw_key)\r\nfrmlen += info->control.hw_key->icv_len;\r\nath_assign_seq(ath9k_hw_common(sc->sc_ah), skb);\r\nif ((vif && vif->type != NL80211_IFTYPE_AP &&\r\nvif->type != NL80211_IFTYPE_AP_VLAN) ||\r\n!ieee80211_is_data(hdr->frame_control))\r\ninfo->flags |= IEEE80211_TX_CTL_CLEAR_PS_FILT;\r\npadpos = ieee80211_hdrlen(hdr->frame_control);\r\npadsize = padpos & 3;\r\nif (padsize && skb->len > padpos) {\r\nif (skb_headroom(skb) < padsize)\r\nreturn -ENOMEM;\r\nskb_push(skb, padsize);\r\nmemmove(skb->data, skb->data + padsize, padpos);\r\n}\r\nsetup_frame_info(hw, sta, skb, frmlen);\r\nreturn 0;\r\n}\r\nint ath_tx_start(struct ieee80211_hw *hw, struct sk_buff *skb,\r\nstruct ath_tx_control *txctl)\r\n{\r\nstruct ieee80211_hdr *hdr;\r\nstruct ieee80211_tx_info *info = IEEE80211_SKB_CB(skb);\r\nstruct ieee80211_sta *sta = txctl->sta;\r\nstruct ieee80211_vif *vif = info->control.vif;\r\nstruct ath_frame_info *fi = get_frame_info(skb);\r\nstruct ath_vif *avp = NULL;\r\nstruct ath_softc *sc = hw->priv;\r\nstruct ath_txq *txq = txctl->txq;\r\nstruct ath_atx_tid *tid = NULL;\r\nstruct ath_buf *bf;\r\nbool queue, skip_uapsd = false, ps_resp;\r\nint q, ret;\r\nif (vif)\r\navp = (void *)vif->drv_priv;\r\nif (info->flags & IEEE80211_TX_CTL_TX_OFFCHAN)\r\ntxctl->force_channel = true;\r\nps_resp = !!(info->control.flags & IEEE80211_TX_CTRL_PS_RESPONSE);\r\nret = ath_tx_prepare(hw, skb, txctl);\r\nif (ret)\r\nreturn ret;\r\nhdr = (struct ieee80211_hdr *) skb->data;\r\nq = skb_get_queue_mapping(skb);\r\nath_txq_lock(sc, txq);\r\nif (txq == sc->tx.txq_map[q]) {\r\nfi->txq = q;\r\nif (++txq->pending_frames > sc->tx.txq_max_pending[q] &&\r\n!txq->stopped) {\r\nif (ath9k_is_chanctx_enabled())\r\nieee80211_stop_queue(sc->hw, info->hw_queue);\r\nelse\r\nieee80211_stop_queue(sc->hw, q);\r\ntxq->stopped = true;\r\n}\r\n}\r\nqueue = ieee80211_is_data_present(hdr->frame_control);\r\nif (ath9k_is_chanctx_enabled() &&\r\nieee80211_is_nullfunc(hdr->frame_control) &&\r\n!txctl->force_channel)\r\nqueue = true;\r\nif (((avp && avp->chanctx != sc->cur_chan) ||\r\nsc->cur_chan->stopped) && !txctl->force_channel) {\r\nif (!txctl->an)\r\ntxctl->an = &avp->mcast_node;\r\nqueue = true;\r\nskip_uapsd = true;\r\n}\r\nif (txctl->an && queue)\r\ntid = ath_get_skb_tid(sc, txctl->an, skb);\r\nif (!skip_uapsd && ps_resp) {\r\nath_txq_unlock(sc, txq);\r\ntxq = sc->tx.uapsdq;\r\nath_txq_lock(sc, txq);\r\n} else if (txctl->an && queue) {\r\nWARN_ON(tid->txq != txctl->txq);\r\nif (info->flags & IEEE80211_TX_CTL_CLEAR_PS_FILT)\r\ntid->clear_ps_filter = true;\r\nTX_STAT_INC(txq->axq_qnum, a_queued_sw);\r\n__skb_queue_tail(&tid->buf_q, skb);\r\nif (!txctl->an->sleeping)\r\nath_tx_queue_tid(sc, txq, tid);\r\nath_txq_schedule(sc, txq);\r\ngoto out;\r\n}\r\nbf = ath_tx_setup_buffer(sc, txq, tid, skb);\r\nif (!bf) {\r\nath_txq_skb_done(sc, txq, skb);\r\nif (txctl->paprd)\r\ndev_kfree_skb_any(skb);\r\nelse\r\nieee80211_free_txskb(sc->hw, skb);\r\ngoto out;\r\n}\r\nbf->bf_state.bfs_paprd = txctl->paprd;\r\nif (txctl->paprd)\r\nbf->bf_state.bfs_paprd_timestamp = jiffies;\r\nath_set_rates(vif, sta, bf);\r\nath_tx_send_normal(sc, txq, tid, skb);\r\nout:\r\nath_txq_unlock(sc, txq);\r\nreturn 0;\r\n}\r\nvoid ath_tx_cabq(struct ieee80211_hw *hw, struct ieee80211_vif *vif,\r\nstruct sk_buff *skb)\r\n{\r\nstruct ath_softc *sc = hw->priv;\r\nstruct ath_tx_control txctl = {\r\n.txq = sc->beacon.cabq\r\n};\r\nstruct ath_tx_info info = {};\r\nstruct ieee80211_hdr *hdr;\r\nstruct ath_buf *bf_tail = NULL;\r\nstruct ath_buf *bf;\r\nLIST_HEAD(bf_q);\r\nint duration = 0;\r\nint max_duration;\r\nmax_duration =\r\nsc->cur_chan->beacon.beacon_interval * 1000 *\r\nsc->cur_chan->beacon.dtim_period / ATH_BCBUF;\r\ndo {\r\nstruct ath_frame_info *fi = get_frame_info(skb);\r\nif (ath_tx_prepare(hw, skb, &txctl))\r\nbreak;\r\nbf = ath_tx_setup_buffer(sc, txctl.txq, NULL, skb);\r\nif (!bf)\r\nbreak;\r\nbf->bf_lastbf = bf;\r\nath_set_rates(vif, NULL, bf);\r\nath_buf_set_rate(sc, bf, &info, fi->framelen, false);\r\nduration += info.rates[0].PktDuration;\r\nif (bf_tail)\r\nbf_tail->bf_next = bf;\r\nlist_add_tail(&bf->list, &bf_q);\r\nbf_tail = bf;\r\nskb = NULL;\r\nif (duration > max_duration)\r\nbreak;\r\nskb = ieee80211_get_buffered_bc(hw, vif);\r\n} while(skb);\r\nif (skb)\r\nieee80211_free_txskb(hw, skb);\r\nif (list_empty(&bf_q))\r\nreturn;\r\nbf = list_first_entry(&bf_q, struct ath_buf, list);\r\nhdr = (struct ieee80211_hdr *) bf->bf_mpdu->data;\r\nif (hdr->frame_control & cpu_to_le16(IEEE80211_FCTL_MOREDATA)) {\r\nhdr->frame_control &= ~cpu_to_le16(IEEE80211_FCTL_MOREDATA);\r\ndma_sync_single_for_device(sc->dev, bf->bf_buf_addr,\r\nsizeof(*hdr), DMA_TO_DEVICE);\r\n}\r\nath_txq_lock(sc, txctl.txq);\r\nath_tx_fill_desc(sc, bf, txctl.txq, 0);\r\nath_tx_txqaddbuf(sc, txctl.txq, &bf_q, false);\r\nTX_STAT_INC(txctl.txq->axq_qnum, queued);\r\nath_txq_unlock(sc, txctl.txq);\r\n}\r\nstatic void ath_tx_complete(struct ath_softc *sc, struct sk_buff *skb,\r\nint tx_flags, struct ath_txq *txq)\r\n{\r\nstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\r\nstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\r\nstruct ieee80211_hdr * hdr = (struct ieee80211_hdr *)skb->data;\r\nint padpos, padsize;\r\nunsigned long flags;\r\nath_dbg(common, XMIT, "TX complete: skb: %p\n", skb);\r\nif (sc->sc_ah->caldata)\r\nset_bit(PAPRD_PACKET_SENT, &sc->sc_ah->caldata->cal_flags);\r\nif (!(tx_flags & ATH_TX_ERROR)) {\r\nif (tx_info->flags & IEEE80211_TX_CTL_NO_ACK)\r\ntx_info->flags |= IEEE80211_TX_STAT_NOACK_TRANSMITTED;\r\nelse\r\ntx_info->flags |= IEEE80211_TX_STAT_ACK;\r\n}\r\npadpos = ieee80211_hdrlen(hdr->frame_control);\r\npadsize = padpos & 3;\r\nif (padsize && skb->len>padpos+padsize) {\r\nmemmove(skb->data + padsize, skb->data, padpos);\r\nskb_pull(skb, padsize);\r\n}\r\nspin_lock_irqsave(&sc->sc_pm_lock, flags);\r\nif ((sc->ps_flags & PS_WAIT_FOR_TX_ACK) && !txq->axq_depth) {\r\nsc->ps_flags &= ~PS_WAIT_FOR_TX_ACK;\r\nath_dbg(common, PS,\r\n"Going back to sleep after having received TX status (0x%lx)\n",\r\nsc->ps_flags & (PS_WAIT_FOR_BEACON |\r\nPS_WAIT_FOR_CAB |\r\nPS_WAIT_FOR_PSPOLL_DATA |\r\nPS_WAIT_FOR_TX_ACK));\r\n}\r\nspin_unlock_irqrestore(&sc->sc_pm_lock, flags);\r\n__skb_queue_tail(&txq->complete_q, skb);\r\nath_txq_skb_done(sc, txq, skb);\r\n}\r\nstatic void ath_tx_complete_buf(struct ath_softc *sc, struct ath_buf *bf,\r\nstruct ath_txq *txq, struct list_head *bf_q,\r\nstruct ath_tx_status *ts, int txok)\r\n{\r\nstruct sk_buff *skb = bf->bf_mpdu;\r\nstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\r\nunsigned long flags;\r\nint tx_flags = 0;\r\nif (!txok)\r\ntx_flags |= ATH_TX_ERROR;\r\nif (ts->ts_status & ATH9K_TXERR_FILT)\r\ntx_info->flags |= IEEE80211_TX_STAT_TX_FILTERED;\r\ndma_unmap_single(sc->dev, bf->bf_buf_addr, skb->len, DMA_TO_DEVICE);\r\nbf->bf_buf_addr = 0;\r\nif (sc->tx99_state)\r\ngoto skip_tx_complete;\r\nif (bf->bf_state.bfs_paprd) {\r\nif (time_after(jiffies,\r\nbf->bf_state.bfs_paprd_timestamp +\r\nmsecs_to_jiffies(ATH_PAPRD_TIMEOUT)))\r\ndev_kfree_skb_any(skb);\r\nelse\r\ncomplete(&sc->paprd_complete);\r\n} else {\r\nath_debug_stat_tx(sc, bf, ts, txq, tx_flags);\r\nath_tx_complete(sc, skb, tx_flags, txq);\r\n}\r\nskip_tx_complete:\r\nbf->bf_mpdu = NULL;\r\nspin_lock_irqsave(&sc->tx.txbuflock, flags);\r\nlist_splice_tail_init(bf_q, &sc->tx.txbuf);\r\nspin_unlock_irqrestore(&sc->tx.txbuflock, flags);\r\n}\r\nstatic void ath_tx_rc_status(struct ath_softc *sc, struct ath_buf *bf,\r\nstruct ath_tx_status *ts, int nframes, int nbad,\r\nint txok)\r\n{\r\nstruct sk_buff *skb = bf->bf_mpdu;\r\nstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *)skb->data;\r\nstruct ieee80211_tx_info *tx_info = IEEE80211_SKB_CB(skb);\r\nstruct ieee80211_hw *hw = sc->hw;\r\nstruct ath_hw *ah = sc->sc_ah;\r\nu8 i, tx_rateindex;\r\nif (txok)\r\ntx_info->status.ack_signal = ts->ts_rssi;\r\ntx_rateindex = ts->ts_rateindex;\r\nWARN_ON(tx_rateindex >= hw->max_rates);\r\nif (tx_info->flags & IEEE80211_TX_CTL_AMPDU) {\r\ntx_info->flags |= IEEE80211_TX_STAT_AMPDU;\r\nBUG_ON(nbad > nframes);\r\n}\r\ntx_info->status.ampdu_len = nframes;\r\ntx_info->status.ampdu_ack_len = nframes - nbad;\r\nif ((ts->ts_status & ATH9K_TXERR_FILT) == 0 &&\r\n(tx_info->flags & IEEE80211_TX_CTL_NO_ACK) == 0) {\r\nif (unlikely(ts->ts_flags & (ATH9K_TX_DATA_UNDERRUN |\r\nATH9K_TX_DELIM_UNDERRUN)) &&\r\nieee80211_is_data(hdr->frame_control) &&\r\nah->tx_trig_level >= sc->sc_ah->config.max_txtrig_level)\r\ntx_info->status.rates[tx_rateindex].count =\r\nhw->max_rate_tries;\r\n}\r\nfor (i = tx_rateindex + 1; i < hw->max_rates; i++) {\r\ntx_info->status.rates[i].count = 0;\r\ntx_info->status.rates[i].idx = -1;\r\n}\r\ntx_info->status.rates[tx_rateindex].count = ts->ts_longretry + 1;\r\n}\r\nstatic void ath_tx_processq(struct ath_softc *sc, struct ath_txq *txq)\r\n{\r\nstruct ath_hw *ah = sc->sc_ah;\r\nstruct ath_common *common = ath9k_hw_common(ah);\r\nstruct ath_buf *bf, *lastbf, *bf_held = NULL;\r\nstruct list_head bf_head;\r\nstruct ath_desc *ds;\r\nstruct ath_tx_status ts;\r\nint status;\r\nath_dbg(common, QUEUE, "tx queue %d (%x), link %p\n",\r\ntxq->axq_qnum, ath9k_hw_gettxbuf(sc->sc_ah, txq->axq_qnum),\r\ntxq->axq_link);\r\nath_txq_lock(sc, txq);\r\nfor (;;) {\r\nif (test_bit(ATH_OP_HW_RESET, &common->op_flags))\r\nbreak;\r\nif (list_empty(&txq->axq_q)) {\r\ntxq->axq_link = NULL;\r\nath_txq_schedule(sc, txq);\r\nbreak;\r\n}\r\nbf = list_first_entry(&txq->axq_q, struct ath_buf, list);\r\nbf_held = NULL;\r\nif (bf->bf_state.stale) {\r\nbf_held = bf;\r\nif (list_is_last(&bf_held->list, &txq->axq_q))\r\nbreak;\r\nbf = list_entry(bf_held->list.next, struct ath_buf,\r\nlist);\r\n}\r\nlastbf = bf->bf_lastbf;\r\nds = lastbf->bf_desc;\r\nmemset(&ts, 0, sizeof(ts));\r\nstatus = ath9k_hw_txprocdesc(ah, ds, &ts);\r\nif (status == -EINPROGRESS)\r\nbreak;\r\nTX_STAT_INC(txq->axq_qnum, txprocdesc);\r\nlastbf->bf_state.stale = true;\r\nINIT_LIST_HEAD(&bf_head);\r\nif (!list_is_singular(&lastbf->list))\r\nlist_cut_position(&bf_head,\r\n&txq->axq_q, lastbf->list.prev);\r\nif (bf_held) {\r\nlist_del(&bf_held->list);\r\nath_tx_return_buffer(sc, bf_held);\r\n}\r\nath_tx_process_buffer(sc, txq, &ts, bf, &bf_head);\r\n}\r\nath_txq_unlock_complete(sc, txq);\r\n}\r\nvoid ath_tx_tasklet(struct ath_softc *sc)\r\n{\r\nstruct ath_hw *ah = sc->sc_ah;\r\nu32 qcumask = ((1 << ATH9K_NUM_TX_QUEUES) - 1) & ah->intr_txqs;\r\nint i;\r\nfor (i = 0; i < ATH9K_NUM_TX_QUEUES; i++) {\r\nif (ATH_TXQ_SETUP(sc, i) && (qcumask & (1 << i)))\r\nath_tx_processq(sc, &sc->tx.txq[i]);\r\n}\r\n}\r\nvoid ath_tx_edma_tasklet(struct ath_softc *sc)\r\n{\r\nstruct ath_tx_status ts;\r\nstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\r\nstruct ath_hw *ah = sc->sc_ah;\r\nstruct ath_txq *txq;\r\nstruct ath_buf *bf, *lastbf;\r\nstruct list_head bf_head;\r\nstruct list_head *fifo_list;\r\nint status;\r\nfor (;;) {\r\nif (test_bit(ATH_OP_HW_RESET, &common->op_flags))\r\nbreak;\r\nstatus = ath9k_hw_txprocdesc(ah, NULL, (void *)&ts);\r\nif (status == -EINPROGRESS)\r\nbreak;\r\nif (status == -EIO) {\r\nath_dbg(common, XMIT, "Error processing tx status\n");\r\nbreak;\r\n}\r\nif (ts.qid == sc->beacon.beaconq) {\r\nsc->beacon.tx_processed = true;\r\nsc->beacon.tx_last = !(ts.ts_status & ATH9K_TXERR_MASK);\r\nif (ath9k_is_chanctx_enabled()) {\r\nath_chanctx_event(sc, NULL,\r\nATH_CHANCTX_EVENT_BEACON_SENT);\r\n}\r\nath9k_csa_update(sc);\r\ncontinue;\r\n}\r\ntxq = &sc->tx.txq[ts.qid];\r\nath_txq_lock(sc, txq);\r\nTX_STAT_INC(txq->axq_qnum, txprocdesc);\r\nfifo_list = &txq->txq_fifo[txq->txq_tailidx];\r\nif (list_empty(fifo_list)) {\r\nath_txq_unlock(sc, txq);\r\nreturn;\r\n}\r\nbf = list_first_entry(fifo_list, struct ath_buf, list);\r\nif (bf->bf_state.stale) {\r\nlist_del(&bf->list);\r\nath_tx_return_buffer(sc, bf);\r\nbf = list_first_entry(fifo_list, struct ath_buf, list);\r\n}\r\nlastbf = bf->bf_lastbf;\r\nINIT_LIST_HEAD(&bf_head);\r\nif (list_is_last(&lastbf->list, fifo_list)) {\r\nlist_splice_tail_init(fifo_list, &bf_head);\r\nINCR(txq->txq_tailidx, ATH_TXFIFO_DEPTH);\r\nif (!list_empty(&txq->axq_q)) {\r\nstruct list_head bf_q;\r\nINIT_LIST_HEAD(&bf_q);\r\ntxq->axq_link = NULL;\r\nlist_splice_tail_init(&txq->axq_q, &bf_q);\r\nath_tx_txqaddbuf(sc, txq, &bf_q, true);\r\n}\r\n} else {\r\nlastbf->bf_state.stale = true;\r\nif (bf != lastbf)\r\nlist_cut_position(&bf_head, fifo_list,\r\nlastbf->list.prev);\r\n}\r\nath_tx_process_buffer(sc, txq, &ts, bf, &bf_head);\r\nath_txq_unlock_complete(sc, txq);\r\n}\r\n}\r\nstatic int ath_txstatus_setup(struct ath_softc *sc, int size)\r\n{\r\nstruct ath_descdma *dd = &sc->txsdma;\r\nu8 txs_len = sc->sc_ah->caps.txs_len;\r\ndd->dd_desc_len = size * txs_len;\r\ndd->dd_desc = dmam_alloc_coherent(sc->dev, dd->dd_desc_len,\r\n&dd->dd_desc_paddr, GFP_KERNEL);\r\nif (!dd->dd_desc)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nstatic int ath_tx_edma_init(struct ath_softc *sc)\r\n{\r\nint err;\r\nerr = ath_txstatus_setup(sc, ATH_TXSTATUS_RING_SIZE);\r\nif (!err)\r\nath9k_hw_setup_statusring(sc->sc_ah, sc->txsdma.dd_desc,\r\nsc->txsdma.dd_desc_paddr,\r\nATH_TXSTATUS_RING_SIZE);\r\nreturn err;\r\n}\r\nint ath_tx_init(struct ath_softc *sc, int nbufs)\r\n{\r\nstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\r\nint error = 0;\r\nspin_lock_init(&sc->tx.txbuflock);\r\nerror = ath_descdma_setup(sc, &sc->tx.txdma, &sc->tx.txbuf,\r\n"tx", nbufs, 1, 1);\r\nif (error != 0) {\r\nath_err(common,\r\n"Failed to allocate tx descriptors: %d\n", error);\r\nreturn error;\r\n}\r\nerror = ath_descdma_setup(sc, &sc->beacon.bdma, &sc->beacon.bbuf,\r\n"beacon", ATH_BCBUF, 1, 1);\r\nif (error != 0) {\r\nath_err(common,\r\n"Failed to allocate beacon descriptors: %d\n", error);\r\nreturn error;\r\n}\r\nINIT_DELAYED_WORK(&sc->tx_complete_work, ath_tx_complete_poll_work);\r\nif (sc->sc_ah->caps.hw_caps & ATH9K_HW_CAP_EDMA)\r\nerror = ath_tx_edma_init(sc);\r\nreturn error;\r\n}\r\nvoid ath_tx_node_init(struct ath_softc *sc, struct ath_node *an)\r\n{\r\nstruct ath_atx_tid *tid;\r\nint tidno, acno;\r\nfor (tidno = 0, tid = &an->tid[tidno];\r\ntidno < IEEE80211_NUM_TIDS;\r\ntidno++, tid++) {\r\ntid->an = an;\r\ntid->tidno = tidno;\r\ntid->seq_start = tid->seq_next = 0;\r\ntid->baw_size = WME_MAX_BA;\r\ntid->baw_head = tid->baw_tail = 0;\r\ntid->active = false;\r\ntid->clear_ps_filter = true;\r\n__skb_queue_head_init(&tid->buf_q);\r\n__skb_queue_head_init(&tid->retry_q);\r\nINIT_LIST_HEAD(&tid->list);\r\nacno = TID_TO_WME_AC(tidno);\r\ntid->txq = sc->tx.txq_map[acno];\r\n}\r\n}\r\nvoid ath_tx_node_cleanup(struct ath_softc *sc, struct ath_node *an)\r\n{\r\nstruct ath_atx_tid *tid;\r\nstruct ath_txq *txq;\r\nint tidno;\r\nfor (tidno = 0, tid = &an->tid[tidno];\r\ntidno < IEEE80211_NUM_TIDS; tidno++, tid++) {\r\ntxq = tid->txq;\r\nath_txq_lock(sc, txq);\r\nif (!list_empty(&tid->list))\r\nlist_del_init(&tid->list);\r\nath_tid_drain(sc, txq, tid);\r\ntid->active = false;\r\nath_txq_unlock(sc, txq);\r\n}\r\n}\r\nint ath9k_tx99_send(struct ath_softc *sc, struct sk_buff *skb,\r\nstruct ath_tx_control *txctl)\r\n{\r\nstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *) skb->data;\r\nstruct ath_frame_info *fi = get_frame_info(skb);\r\nstruct ath_common *common = ath9k_hw_common(sc->sc_ah);\r\nstruct ath_buf *bf;\r\nint padpos, padsize;\r\npadpos = ieee80211_hdrlen(hdr->frame_control);\r\npadsize = padpos & 3;\r\nif (padsize && skb->len > padpos) {\r\nif (skb_headroom(skb) < padsize) {\r\nath_dbg(common, XMIT,\r\n"tx99 padding failed\n");\r\nreturn -EINVAL;\r\n}\r\nskb_push(skb, padsize);\r\nmemmove(skb->data, skb->data + padsize, padpos);\r\n}\r\nfi->keyix = ATH9K_TXKEYIX_INVALID;\r\nfi->framelen = skb->len + FCS_LEN;\r\nfi->keytype = ATH9K_KEY_TYPE_CLEAR;\r\nbf = ath_tx_setup_buffer(sc, txctl->txq, NULL, skb);\r\nif (!bf) {\r\nath_dbg(common, XMIT, "tx99 buffer setup failed\n");\r\nreturn -EINVAL;\r\n}\r\nath_set_rates(sc->tx99_vif, NULL, bf);\r\nath9k_hw_set_desc_link(sc->sc_ah, bf->bf_desc, bf->bf_daddr);\r\nath9k_hw_tx99_start(sc->sc_ah, txctl->txq->axq_qnum);\r\nath_tx_send_normal(sc, txctl->txq, NULL, skb);\r\nreturn 0;\r\n}
