static int lan78xx_read_reg(struct lan78xx_net *dev, u32 index, u32 *data)\r\n{\r\nu32 *buf = kmalloc(sizeof(u32), GFP_KERNEL);\r\nint ret;\r\nif (!buf)\r\nreturn -ENOMEM;\r\nret = usb_control_msg(dev->udev, usb_rcvctrlpipe(dev->udev, 0),\r\nUSB_VENDOR_REQUEST_READ_REGISTER,\r\nUSB_DIR_IN | USB_TYPE_VENDOR | USB_RECIP_DEVICE,\r\n0, index, buf, 4, USB_CTRL_GET_TIMEOUT);\r\nif (likely(ret >= 0)) {\r\nle32_to_cpus(buf);\r\n*data = *buf;\r\n} else {\r\nnetdev_warn(dev->net,\r\n"Failed to read register index 0x%08x. ret = %d",\r\nindex, ret);\r\n}\r\nkfree(buf);\r\nreturn ret;\r\n}\r\nstatic int lan78xx_write_reg(struct lan78xx_net *dev, u32 index, u32 data)\r\n{\r\nu32 *buf = kmalloc(sizeof(u32), GFP_KERNEL);\r\nint ret;\r\nif (!buf)\r\nreturn -ENOMEM;\r\n*buf = data;\r\ncpu_to_le32s(buf);\r\nret = usb_control_msg(dev->udev, usb_sndctrlpipe(dev->udev, 0),\r\nUSB_VENDOR_REQUEST_WRITE_REGISTER,\r\nUSB_DIR_OUT | USB_TYPE_VENDOR | USB_RECIP_DEVICE,\r\n0, index, buf, 4, USB_CTRL_SET_TIMEOUT);\r\nif (unlikely(ret < 0)) {\r\nnetdev_warn(dev->net,\r\n"Failed to write register index 0x%08x. ret = %d",\r\nindex, ret);\r\n}\r\nkfree(buf);\r\nreturn ret;\r\n}\r\nstatic int lan78xx_read_stats(struct lan78xx_net *dev,\r\nstruct lan78xx_statstage *data)\r\n{\r\nint ret = 0;\r\nint i;\r\nstruct lan78xx_statstage *stats;\r\nu32 *src;\r\nu32 *dst;\r\nstats = kmalloc(sizeof(*stats), GFP_KERNEL);\r\nif (!stats)\r\nreturn -ENOMEM;\r\nret = usb_control_msg(dev->udev,\r\nusb_rcvctrlpipe(dev->udev, 0),\r\nUSB_VENDOR_REQUEST_GET_STATS,\r\nUSB_DIR_IN | USB_TYPE_VENDOR | USB_RECIP_DEVICE,\r\n0,\r\n0,\r\n(void *)stats,\r\nsizeof(*stats),\r\nUSB_CTRL_SET_TIMEOUT);\r\nif (likely(ret >= 0)) {\r\nsrc = (u32 *)stats;\r\ndst = (u32 *)data;\r\nfor (i = 0; i < sizeof(*stats)/sizeof(u32); i++) {\r\nle32_to_cpus(&src[i]);\r\ndst[i] = src[i];\r\n}\r\n} else {\r\nnetdev_warn(dev->net,\r\n"Failed to read stat ret = 0x%x", ret);\r\n}\r\nkfree(stats);\r\nreturn ret;\r\n}\r\nstatic void lan78xx_check_stat_rollover(struct lan78xx_net *dev,\r\nstruct lan78xx_statstage *stats)\r\n{\r\ncheck_counter_rollover(stats, dev->stats, rx_fcs_errors);\r\ncheck_counter_rollover(stats, dev->stats, rx_alignment_errors);\r\ncheck_counter_rollover(stats, dev->stats, rx_fragment_errors);\r\ncheck_counter_rollover(stats, dev->stats, rx_jabber_errors);\r\ncheck_counter_rollover(stats, dev->stats, rx_undersize_frame_errors);\r\ncheck_counter_rollover(stats, dev->stats, rx_oversize_frame_errors);\r\ncheck_counter_rollover(stats, dev->stats, rx_dropped_frames);\r\ncheck_counter_rollover(stats, dev->stats, rx_unicast_byte_count);\r\ncheck_counter_rollover(stats, dev->stats, rx_broadcast_byte_count);\r\ncheck_counter_rollover(stats, dev->stats, rx_multicast_byte_count);\r\ncheck_counter_rollover(stats, dev->stats, rx_unicast_frames);\r\ncheck_counter_rollover(stats, dev->stats, rx_broadcast_frames);\r\ncheck_counter_rollover(stats, dev->stats, rx_multicast_frames);\r\ncheck_counter_rollover(stats, dev->stats, rx_pause_frames);\r\ncheck_counter_rollover(stats, dev->stats, rx_64_byte_frames);\r\ncheck_counter_rollover(stats, dev->stats, rx_65_127_byte_frames);\r\ncheck_counter_rollover(stats, dev->stats, rx_128_255_byte_frames);\r\ncheck_counter_rollover(stats, dev->stats, rx_256_511_bytes_frames);\r\ncheck_counter_rollover(stats, dev->stats, rx_512_1023_byte_frames);\r\ncheck_counter_rollover(stats, dev->stats, rx_1024_1518_byte_frames);\r\ncheck_counter_rollover(stats, dev->stats, rx_greater_1518_byte_frames);\r\ncheck_counter_rollover(stats, dev->stats, eee_rx_lpi_transitions);\r\ncheck_counter_rollover(stats, dev->stats, eee_rx_lpi_time);\r\ncheck_counter_rollover(stats, dev->stats, tx_fcs_errors);\r\ncheck_counter_rollover(stats, dev->stats, tx_excess_deferral_errors);\r\ncheck_counter_rollover(stats, dev->stats, tx_carrier_errors);\r\ncheck_counter_rollover(stats, dev->stats, tx_bad_byte_count);\r\ncheck_counter_rollover(stats, dev->stats, tx_single_collisions);\r\ncheck_counter_rollover(stats, dev->stats, tx_multiple_collisions);\r\ncheck_counter_rollover(stats, dev->stats, tx_excessive_collision);\r\ncheck_counter_rollover(stats, dev->stats, tx_late_collisions);\r\ncheck_counter_rollover(stats, dev->stats, tx_unicast_byte_count);\r\ncheck_counter_rollover(stats, dev->stats, tx_broadcast_byte_count);\r\ncheck_counter_rollover(stats, dev->stats, tx_multicast_byte_count);\r\ncheck_counter_rollover(stats, dev->stats, tx_unicast_frames);\r\ncheck_counter_rollover(stats, dev->stats, tx_broadcast_frames);\r\ncheck_counter_rollover(stats, dev->stats, tx_multicast_frames);\r\ncheck_counter_rollover(stats, dev->stats, tx_pause_frames);\r\ncheck_counter_rollover(stats, dev->stats, tx_64_byte_frames);\r\ncheck_counter_rollover(stats, dev->stats, tx_65_127_byte_frames);\r\ncheck_counter_rollover(stats, dev->stats, tx_128_255_byte_frames);\r\ncheck_counter_rollover(stats, dev->stats, tx_256_511_bytes_frames);\r\ncheck_counter_rollover(stats, dev->stats, tx_512_1023_byte_frames);\r\ncheck_counter_rollover(stats, dev->stats, tx_1024_1518_byte_frames);\r\ncheck_counter_rollover(stats, dev->stats, tx_greater_1518_byte_frames);\r\ncheck_counter_rollover(stats, dev->stats, eee_tx_lpi_transitions);\r\ncheck_counter_rollover(stats, dev->stats, eee_tx_lpi_time);\r\nmemcpy(&dev->stats.saved, stats, sizeof(struct lan78xx_statstage));\r\n}\r\nstatic void lan78xx_update_stats(struct lan78xx_net *dev)\r\n{\r\nu32 *p, *count, *max;\r\nu64 *data;\r\nint i;\r\nstruct lan78xx_statstage lan78xx_stats;\r\nif (usb_autopm_get_interface(dev->intf) < 0)\r\nreturn;\r\np = (u32 *)&lan78xx_stats;\r\ncount = (u32 *)&dev->stats.rollover_count;\r\nmax = (u32 *)&dev->stats.rollover_max;\r\ndata = (u64 *)&dev->stats.curr_stat;\r\nmutex_lock(&dev->stats.access_lock);\r\nif (lan78xx_read_stats(dev, &lan78xx_stats) > 0)\r\nlan78xx_check_stat_rollover(dev, &lan78xx_stats);\r\nfor (i = 0; i < (sizeof(lan78xx_stats) / (sizeof(u32))); i++)\r\ndata[i] = (u64)p[i] + ((u64)count[i] * ((u64)max[i] + 1));\r\nmutex_unlock(&dev->stats.access_lock);\r\nusb_autopm_put_interface(dev->intf);\r\n}\r\nstatic int lan78xx_phy_wait_not_busy(struct lan78xx_net *dev)\r\n{\r\nunsigned long start_time = jiffies;\r\nu32 val;\r\nint ret;\r\ndo {\r\nret = lan78xx_read_reg(dev, MII_ACC, &val);\r\nif (unlikely(ret < 0))\r\nreturn -EIO;\r\nif (!(val & MII_ACC_MII_BUSY_))\r\nreturn 0;\r\n} while (!time_after(jiffies, start_time + HZ));\r\nreturn -EIO;\r\n}\r\nstatic inline u32 mii_access(int id, int index, int read)\r\n{\r\nu32 ret;\r\nret = ((u32)id << MII_ACC_PHY_ADDR_SHIFT_) & MII_ACC_PHY_ADDR_MASK_;\r\nret |= ((u32)index << MII_ACC_MIIRINDA_SHIFT_) & MII_ACC_MIIRINDA_MASK_;\r\nif (read)\r\nret |= MII_ACC_MII_READ_;\r\nelse\r\nret |= MII_ACC_MII_WRITE_;\r\nret |= MII_ACC_MII_BUSY_;\r\nreturn ret;\r\n}\r\nstatic int lan78xx_wait_eeprom(struct lan78xx_net *dev)\r\n{\r\nunsigned long start_time = jiffies;\r\nu32 val;\r\nint ret;\r\ndo {\r\nret = lan78xx_read_reg(dev, E2P_CMD, &val);\r\nif (unlikely(ret < 0))\r\nreturn -EIO;\r\nif (!(val & E2P_CMD_EPC_BUSY_) ||\r\n(val & E2P_CMD_EPC_TIMEOUT_))\r\nbreak;\r\nusleep_range(40, 100);\r\n} while (!time_after(jiffies, start_time + HZ));\r\nif (val & (E2P_CMD_EPC_TIMEOUT_ | E2P_CMD_EPC_BUSY_)) {\r\nnetdev_warn(dev->net, "EEPROM read operation timeout");\r\nreturn -EIO;\r\n}\r\nreturn 0;\r\n}\r\nstatic int lan78xx_eeprom_confirm_not_busy(struct lan78xx_net *dev)\r\n{\r\nunsigned long start_time = jiffies;\r\nu32 val;\r\nint ret;\r\ndo {\r\nret = lan78xx_read_reg(dev, E2P_CMD, &val);\r\nif (unlikely(ret < 0))\r\nreturn -EIO;\r\nif (!(val & E2P_CMD_EPC_BUSY_))\r\nreturn 0;\r\nusleep_range(40, 100);\r\n} while (!time_after(jiffies, start_time + HZ));\r\nnetdev_warn(dev->net, "EEPROM is busy");\r\nreturn -EIO;\r\n}\r\nstatic int lan78xx_read_raw_eeprom(struct lan78xx_net *dev, u32 offset,\r\nu32 length, u8 *data)\r\n{\r\nu32 val;\r\nu32 saved;\r\nint i, ret;\r\nint retval;\r\nret = lan78xx_read_reg(dev, HW_CFG, &val);\r\nsaved = val;\r\nif (dev->chipid == ID_REV_CHIP_ID_7800_) {\r\nval &= ~(HW_CFG_LED1_EN_ | HW_CFG_LED0_EN_);\r\nret = lan78xx_write_reg(dev, HW_CFG, val);\r\n}\r\nretval = lan78xx_eeprom_confirm_not_busy(dev);\r\nif (retval)\r\nreturn retval;\r\nfor (i = 0; i < length; i++) {\r\nval = E2P_CMD_EPC_BUSY_ | E2P_CMD_EPC_CMD_READ_;\r\nval |= (offset & E2P_CMD_EPC_ADDR_MASK_);\r\nret = lan78xx_write_reg(dev, E2P_CMD, val);\r\nif (unlikely(ret < 0)) {\r\nretval = -EIO;\r\ngoto exit;\r\n}\r\nretval = lan78xx_wait_eeprom(dev);\r\nif (retval < 0)\r\ngoto exit;\r\nret = lan78xx_read_reg(dev, E2P_DATA, &val);\r\nif (unlikely(ret < 0)) {\r\nretval = -EIO;\r\ngoto exit;\r\n}\r\ndata[i] = val & 0xFF;\r\noffset++;\r\n}\r\nretval = 0;\r\nexit:\r\nif (dev->chipid == ID_REV_CHIP_ID_7800_)\r\nret = lan78xx_write_reg(dev, HW_CFG, saved);\r\nreturn retval;\r\n}\r\nstatic int lan78xx_read_eeprom(struct lan78xx_net *dev, u32 offset,\r\nu32 length, u8 *data)\r\n{\r\nu8 sig;\r\nint ret;\r\nret = lan78xx_read_raw_eeprom(dev, 0, 1, &sig);\r\nif ((ret == 0) && (sig == EEPROM_INDICATOR))\r\nret = lan78xx_read_raw_eeprom(dev, offset, length, data);\r\nelse\r\nret = -EINVAL;\r\nreturn ret;\r\n}\r\nstatic int lan78xx_write_raw_eeprom(struct lan78xx_net *dev, u32 offset,\r\nu32 length, u8 *data)\r\n{\r\nu32 val;\r\nu32 saved;\r\nint i, ret;\r\nint retval;\r\nret = lan78xx_read_reg(dev, HW_CFG, &val);\r\nsaved = val;\r\nif (dev->chipid == ID_REV_CHIP_ID_7800_) {\r\nval &= ~(HW_CFG_LED1_EN_ | HW_CFG_LED0_EN_);\r\nret = lan78xx_write_reg(dev, HW_CFG, val);\r\n}\r\nretval = lan78xx_eeprom_confirm_not_busy(dev);\r\nif (retval)\r\ngoto exit;\r\nval = E2P_CMD_EPC_BUSY_ | E2P_CMD_EPC_CMD_EWEN_;\r\nret = lan78xx_write_reg(dev, E2P_CMD, val);\r\nif (unlikely(ret < 0)) {\r\nretval = -EIO;\r\ngoto exit;\r\n}\r\nretval = lan78xx_wait_eeprom(dev);\r\nif (retval < 0)\r\ngoto exit;\r\nfor (i = 0; i < length; i++) {\r\nval = data[i];\r\nret = lan78xx_write_reg(dev, E2P_DATA, val);\r\nif (ret < 0) {\r\nretval = -EIO;\r\ngoto exit;\r\n}\r\nval = E2P_CMD_EPC_BUSY_ | E2P_CMD_EPC_CMD_WRITE_;\r\nval |= (offset & E2P_CMD_EPC_ADDR_MASK_);\r\nret = lan78xx_write_reg(dev, E2P_CMD, val);\r\nif (ret < 0) {\r\nretval = -EIO;\r\ngoto exit;\r\n}\r\nretval = lan78xx_wait_eeprom(dev);\r\nif (retval < 0)\r\ngoto exit;\r\noffset++;\r\n}\r\nretval = 0;\r\nexit:\r\nif (dev->chipid == ID_REV_CHIP_ID_7800_)\r\nret = lan78xx_write_reg(dev, HW_CFG, saved);\r\nreturn retval;\r\n}\r\nstatic int lan78xx_read_raw_otp(struct lan78xx_net *dev, u32 offset,\r\nu32 length, u8 *data)\r\n{\r\nint i;\r\nint ret;\r\nu32 buf;\r\nunsigned long timeout;\r\nret = lan78xx_read_reg(dev, OTP_PWR_DN, &buf);\r\nif (buf & OTP_PWR_DN_PWRDN_N_) {\r\nret = lan78xx_write_reg(dev, OTP_PWR_DN, 0);\r\ntimeout = jiffies + HZ;\r\ndo {\r\nusleep_range(1, 10);\r\nret = lan78xx_read_reg(dev, OTP_PWR_DN, &buf);\r\nif (time_after(jiffies, timeout)) {\r\nnetdev_warn(dev->net,\r\n"timeout on OTP_PWR_DN");\r\nreturn -EIO;\r\n}\r\n} while (buf & OTP_PWR_DN_PWRDN_N_);\r\n}\r\nfor (i = 0; i < length; i++) {\r\nret = lan78xx_write_reg(dev, OTP_ADDR1,\r\n((offset + i) >> 8) & OTP_ADDR1_15_11);\r\nret = lan78xx_write_reg(dev, OTP_ADDR2,\r\n((offset + i) & OTP_ADDR2_10_3));\r\nret = lan78xx_write_reg(dev, OTP_FUNC_CMD, OTP_FUNC_CMD_READ_);\r\nret = lan78xx_write_reg(dev, OTP_CMD_GO, OTP_CMD_GO_GO_);\r\ntimeout = jiffies + HZ;\r\ndo {\r\nudelay(1);\r\nret = lan78xx_read_reg(dev, OTP_STATUS, &buf);\r\nif (time_after(jiffies, timeout)) {\r\nnetdev_warn(dev->net,\r\n"timeout on OTP_STATUS");\r\nreturn -EIO;\r\n}\r\n} while (buf & OTP_STATUS_BUSY_);\r\nret = lan78xx_read_reg(dev, OTP_RD_DATA, &buf);\r\ndata[i] = (u8)(buf & 0xFF);\r\n}\r\nreturn 0;\r\n}\r\nstatic int lan78xx_write_raw_otp(struct lan78xx_net *dev, u32 offset,\r\nu32 length, u8 *data)\r\n{\r\nint i;\r\nint ret;\r\nu32 buf;\r\nunsigned long timeout;\r\nret = lan78xx_read_reg(dev, OTP_PWR_DN, &buf);\r\nif (buf & OTP_PWR_DN_PWRDN_N_) {\r\nret = lan78xx_write_reg(dev, OTP_PWR_DN, 0);\r\ntimeout = jiffies + HZ;\r\ndo {\r\nudelay(1);\r\nret = lan78xx_read_reg(dev, OTP_PWR_DN, &buf);\r\nif (time_after(jiffies, timeout)) {\r\nnetdev_warn(dev->net,\r\n"timeout on OTP_PWR_DN completion");\r\nreturn -EIO;\r\n}\r\n} while (buf & OTP_PWR_DN_PWRDN_N_);\r\n}\r\nret = lan78xx_write_reg(dev, OTP_PRGM_MODE, OTP_PRGM_MODE_BYTE_);\r\nfor (i = 0; i < length; i++) {\r\nret = lan78xx_write_reg(dev, OTP_ADDR1,\r\n((offset + i) >> 8) & OTP_ADDR1_15_11);\r\nret = lan78xx_write_reg(dev, OTP_ADDR2,\r\n((offset + i) & OTP_ADDR2_10_3));\r\nret = lan78xx_write_reg(dev, OTP_PRGM_DATA, data[i]);\r\nret = lan78xx_write_reg(dev, OTP_TST_CMD, OTP_TST_CMD_PRGVRFY_);\r\nret = lan78xx_write_reg(dev, OTP_CMD_GO, OTP_CMD_GO_GO_);\r\ntimeout = jiffies + HZ;\r\ndo {\r\nudelay(1);\r\nret = lan78xx_read_reg(dev, OTP_STATUS, &buf);\r\nif (time_after(jiffies, timeout)) {\r\nnetdev_warn(dev->net,\r\n"Timeout on OTP_STATUS completion");\r\nreturn -EIO;\r\n}\r\n} while (buf & OTP_STATUS_BUSY_);\r\n}\r\nreturn 0;\r\n}\r\nstatic int lan78xx_read_otp(struct lan78xx_net *dev, u32 offset,\r\nu32 length, u8 *data)\r\n{\r\nu8 sig;\r\nint ret;\r\nret = lan78xx_read_raw_otp(dev, 0, 1, &sig);\r\nif (ret == 0) {\r\nif (sig == OTP_INDICATOR_1)\r\noffset = offset;\r\nelse if (sig == OTP_INDICATOR_2)\r\noffset += 0x100;\r\nelse\r\nret = -EINVAL;\r\nret = lan78xx_read_raw_otp(dev, offset, length, data);\r\n}\r\nreturn ret;\r\n}\r\nstatic int lan78xx_dataport_wait_not_busy(struct lan78xx_net *dev)\r\n{\r\nint i, ret;\r\nfor (i = 0; i < 100; i++) {\r\nu32 dp_sel;\r\nret = lan78xx_read_reg(dev, DP_SEL, &dp_sel);\r\nif (unlikely(ret < 0))\r\nreturn -EIO;\r\nif (dp_sel & DP_SEL_DPRDY_)\r\nreturn 0;\r\nusleep_range(40, 100);\r\n}\r\nnetdev_warn(dev->net, "lan78xx_dataport_wait_not_busy timed out");\r\nreturn -EIO;\r\n}\r\nstatic int lan78xx_dataport_write(struct lan78xx_net *dev, u32 ram_select,\r\nu32 addr, u32 length, u32 *buf)\r\n{\r\nstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\r\nu32 dp_sel;\r\nint i, ret;\r\nif (usb_autopm_get_interface(dev->intf) < 0)\r\nreturn 0;\r\nmutex_lock(&pdata->dataport_mutex);\r\nret = lan78xx_dataport_wait_not_busy(dev);\r\nif (ret < 0)\r\ngoto done;\r\nret = lan78xx_read_reg(dev, DP_SEL, &dp_sel);\r\ndp_sel &= ~DP_SEL_RSEL_MASK_;\r\ndp_sel |= ram_select;\r\nret = lan78xx_write_reg(dev, DP_SEL, dp_sel);\r\nfor (i = 0; i < length; i++) {\r\nret = lan78xx_write_reg(dev, DP_ADDR, addr + i);\r\nret = lan78xx_write_reg(dev, DP_DATA, buf[i]);\r\nret = lan78xx_write_reg(dev, DP_CMD, DP_CMD_WRITE_);\r\nret = lan78xx_dataport_wait_not_busy(dev);\r\nif (ret < 0)\r\ngoto done;\r\n}\r\ndone:\r\nmutex_unlock(&pdata->dataport_mutex);\r\nusb_autopm_put_interface(dev->intf);\r\nreturn ret;\r\n}\r\nstatic void lan78xx_set_addr_filter(struct lan78xx_priv *pdata,\r\nint index, u8 addr[ETH_ALEN])\r\n{\r\nu32 temp;\r\nif ((pdata) && (index > 0) && (index < NUM_OF_MAF)) {\r\ntemp = addr[3];\r\ntemp = addr[2] | (temp << 8);\r\ntemp = addr[1] | (temp << 8);\r\ntemp = addr[0] | (temp << 8);\r\npdata->pfilter_table[index][1] = temp;\r\ntemp = addr[5];\r\ntemp = addr[4] | (temp << 8);\r\ntemp |= MAF_HI_VALID_ | MAF_HI_TYPE_DST_;\r\npdata->pfilter_table[index][0] = temp;\r\n}\r\n}\r\nstatic inline u32 lan78xx_hash(char addr[ETH_ALEN])\r\n{\r\nreturn (ether_crc(ETH_ALEN, addr) >> 23) & 0x1ff;\r\n}\r\nstatic void lan78xx_deferred_multicast_write(struct work_struct *param)\r\n{\r\nstruct lan78xx_priv *pdata =\r\ncontainer_of(param, struct lan78xx_priv, set_multicast);\r\nstruct lan78xx_net *dev = pdata->dev;\r\nint i;\r\nint ret;\r\nnetif_dbg(dev, drv, dev->net, "deferred multicast write 0x%08x\n",\r\npdata->rfe_ctl);\r\nlan78xx_dataport_write(dev, DP_SEL_RSEL_VLAN_DA_, DP_SEL_VHF_VLAN_LEN,\r\nDP_SEL_VHF_HASH_LEN, pdata->mchash_table);\r\nfor (i = 1; i < NUM_OF_MAF; i++) {\r\nret = lan78xx_write_reg(dev, MAF_HI(i), 0);\r\nret = lan78xx_write_reg(dev, MAF_LO(i),\r\npdata->pfilter_table[i][1]);\r\nret = lan78xx_write_reg(dev, MAF_HI(i),\r\npdata->pfilter_table[i][0]);\r\n}\r\nret = lan78xx_write_reg(dev, RFE_CTL, pdata->rfe_ctl);\r\n}\r\nstatic void lan78xx_set_multicast(struct net_device *netdev)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(netdev);\r\nstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\r\nunsigned long flags;\r\nint i;\r\nspin_lock_irqsave(&pdata->rfe_ctl_lock, flags);\r\npdata->rfe_ctl &= ~(RFE_CTL_UCAST_EN_ | RFE_CTL_MCAST_EN_ |\r\nRFE_CTL_DA_PERFECT_ | RFE_CTL_MCAST_HASH_);\r\nfor (i = 0; i < DP_SEL_VHF_HASH_LEN; i++)\r\npdata->mchash_table[i] = 0;\r\nfor (i = 1; i < NUM_OF_MAF; i++) {\r\npdata->pfilter_table[i][0] =\r\npdata->pfilter_table[i][1] = 0;\r\n}\r\npdata->rfe_ctl |= RFE_CTL_BCAST_EN_;\r\nif (dev->net->flags & IFF_PROMISC) {\r\nnetif_dbg(dev, drv, dev->net, "promiscuous mode enabled");\r\npdata->rfe_ctl |= RFE_CTL_MCAST_EN_ | RFE_CTL_UCAST_EN_;\r\n} else {\r\nif (dev->net->flags & IFF_ALLMULTI) {\r\nnetif_dbg(dev, drv, dev->net,\r\n"receive all multicast enabled");\r\npdata->rfe_ctl |= RFE_CTL_MCAST_EN_;\r\n}\r\n}\r\nif (netdev_mc_count(dev->net)) {\r\nstruct netdev_hw_addr *ha;\r\nint i;\r\nnetif_dbg(dev, drv, dev->net, "receive multicast hash filter");\r\npdata->rfe_ctl |= RFE_CTL_DA_PERFECT_;\r\ni = 1;\r\nnetdev_for_each_mc_addr(ha, netdev) {\r\nif (i < 33) {\r\nlan78xx_set_addr_filter(pdata, i, ha->addr);\r\n} else {\r\nu32 bitnum = lan78xx_hash(ha->addr);\r\npdata->mchash_table[bitnum / 32] |=\r\n(1 << (bitnum % 32));\r\npdata->rfe_ctl |= RFE_CTL_MCAST_HASH_;\r\n}\r\ni++;\r\n}\r\n}\r\nspin_unlock_irqrestore(&pdata->rfe_ctl_lock, flags);\r\nschedule_work(&pdata->set_multicast);\r\n}\r\nstatic int lan78xx_update_flowcontrol(struct lan78xx_net *dev, u8 duplex,\r\nu16 lcladv, u16 rmtadv)\r\n{\r\nu32 flow = 0, fct_flow = 0;\r\nint ret;\r\nu8 cap;\r\nif (dev->fc_autoneg)\r\ncap = mii_resolve_flowctrl_fdx(lcladv, rmtadv);\r\nelse\r\ncap = dev->fc_request_control;\r\nif (cap & FLOW_CTRL_TX)\r\nflow |= (FLOW_CR_TX_FCEN_ | 0xFFFF);\r\nif (cap & FLOW_CTRL_RX)\r\nflow |= FLOW_CR_RX_FCEN_;\r\nif (dev->udev->speed == USB_SPEED_SUPER)\r\nfct_flow = 0x817;\r\nelse if (dev->udev->speed == USB_SPEED_HIGH)\r\nfct_flow = 0x211;\r\nnetif_dbg(dev, link, dev->net, "rx pause %s, tx pause %s",\r\n(cap & FLOW_CTRL_RX ? "enabled" : "disabled"),\r\n(cap & FLOW_CTRL_TX ? "enabled" : "disabled"));\r\nret = lan78xx_write_reg(dev, FCT_FLOW, fct_flow);\r\nret = lan78xx_write_reg(dev, FLOW, flow);\r\nreturn 0;\r\n}\r\nstatic int lan78xx_link_reset(struct lan78xx_net *dev)\r\n{\r\nstruct phy_device *phydev = dev->net->phydev;\r\nstruct ethtool_cmd ecmd = { .cmd = ETHTOOL_GSET };\r\nint ladv, radv, ret;\r\nu32 buf;\r\nret = phy_read(phydev, LAN88XX_INT_STS);\r\nif (unlikely(ret < 0))\r\nreturn -EIO;\r\nret = lan78xx_write_reg(dev, INT_STS, INT_STS_PHY_INT_);\r\nif (unlikely(ret < 0))\r\nreturn -EIO;\r\nphy_read_status(phydev);\r\nif (!phydev->link && dev->link_on) {\r\ndev->link_on = false;\r\nret = lan78xx_read_reg(dev, MAC_CR, &buf);\r\nif (unlikely(ret < 0))\r\nreturn -EIO;\r\nbuf |= MAC_CR_RST_;\r\nret = lan78xx_write_reg(dev, MAC_CR, buf);\r\nif (unlikely(ret < 0))\r\nreturn -EIO;\r\nphy_mac_interrupt(phydev, 0);\r\ndel_timer(&dev->stat_monitor);\r\n} else if (phydev->link && !dev->link_on) {\r\ndev->link_on = true;\r\nphy_ethtool_gset(phydev, &ecmd);\r\nret = phy_read(phydev, LAN88XX_INT_STS);\r\nif (dev->udev->speed == USB_SPEED_SUPER) {\r\nif (ethtool_cmd_speed(&ecmd) == 1000) {\r\nret = lan78xx_read_reg(dev, USB_CFG1, &buf);\r\nbuf &= ~USB_CFG1_DEV_U2_INIT_EN_;\r\nret = lan78xx_write_reg(dev, USB_CFG1, buf);\r\nret = lan78xx_read_reg(dev, USB_CFG1, &buf);\r\nbuf |= USB_CFG1_DEV_U1_INIT_EN_;\r\nret = lan78xx_write_reg(dev, USB_CFG1, buf);\r\n} else {\r\nret = lan78xx_read_reg(dev, USB_CFG1, &buf);\r\nbuf |= USB_CFG1_DEV_U2_INIT_EN_;\r\nbuf |= USB_CFG1_DEV_U1_INIT_EN_;\r\nret = lan78xx_write_reg(dev, USB_CFG1, buf);\r\n}\r\n}\r\nladv = phy_read(phydev, MII_ADVERTISE);\r\nif (ladv < 0)\r\nreturn ladv;\r\nradv = phy_read(phydev, MII_LPA);\r\nif (radv < 0)\r\nreturn radv;\r\nnetif_dbg(dev, link, dev->net,\r\n"speed: %u duplex: %d anadv: 0x%04x anlpa: 0x%04x",\r\nethtool_cmd_speed(&ecmd), ecmd.duplex, ladv, radv);\r\nret = lan78xx_update_flowcontrol(dev, ecmd.duplex, ladv, radv);\r\nphy_mac_interrupt(phydev, 1);\r\nif (!timer_pending(&dev->stat_monitor)) {\r\ndev->delta = 1;\r\nmod_timer(&dev->stat_monitor,\r\njiffies + STAT_UPDATE_TIMER);\r\n}\r\n}\r\nreturn ret;\r\n}\r\nvoid lan78xx_defer_kevent(struct lan78xx_net *dev, int work)\r\n{\r\nset_bit(work, &dev->flags);\r\nif (!schedule_delayed_work(&dev->wq, 0))\r\nnetdev_err(dev->net, "kevent %d may have been dropped\n", work);\r\n}\r\nstatic void lan78xx_status(struct lan78xx_net *dev, struct urb *urb)\r\n{\r\nu32 intdata;\r\nif (urb->actual_length != 4) {\r\nnetdev_warn(dev->net,\r\n"unexpected urb length %d", urb->actual_length);\r\nreturn;\r\n}\r\nmemcpy(&intdata, urb->transfer_buffer, 4);\r\nle32_to_cpus(&intdata);\r\nif (intdata & INT_ENP_PHY_INT) {\r\nnetif_dbg(dev, link, dev->net, "PHY INTR: 0x%08x\n", intdata);\r\nlan78xx_defer_kevent(dev, EVENT_LINK_RESET);\r\n} else\r\nnetdev_warn(dev->net,\r\n"unexpected interrupt: 0x%08x\n", intdata);\r\n}\r\nstatic int lan78xx_ethtool_get_eeprom_len(struct net_device *netdev)\r\n{\r\nreturn MAX_EEPROM_SIZE;\r\n}\r\nstatic int lan78xx_ethtool_get_eeprom(struct net_device *netdev,\r\nstruct ethtool_eeprom *ee, u8 *data)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(netdev);\r\nee->magic = LAN78XX_EEPROM_MAGIC;\r\nreturn lan78xx_read_raw_eeprom(dev, ee->offset, ee->len, data);\r\n}\r\nstatic int lan78xx_ethtool_set_eeprom(struct net_device *netdev,\r\nstruct ethtool_eeprom *ee, u8 *data)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(netdev);\r\nif ((ee->magic == LAN78XX_EEPROM_MAGIC) &&\r\n(ee->offset == 0) &&\r\n(ee->len == 512) &&\r\n(data[0] == EEPROM_INDICATOR))\r\nreturn lan78xx_write_raw_eeprom(dev, ee->offset, ee->len, data);\r\nelse if ((ee->magic == LAN78XX_OTP_MAGIC) &&\r\n(ee->offset == 0) &&\r\n(ee->len == 512) &&\r\n(data[0] == OTP_INDICATOR_1))\r\nreturn lan78xx_write_raw_otp(dev, ee->offset, ee->len, data);\r\nreturn -EINVAL;\r\n}\r\nstatic void lan78xx_get_strings(struct net_device *netdev, u32 stringset,\r\nu8 *data)\r\n{\r\nif (stringset == ETH_SS_STATS)\r\nmemcpy(data, lan78xx_gstrings, sizeof(lan78xx_gstrings));\r\n}\r\nstatic int lan78xx_get_sset_count(struct net_device *netdev, int sset)\r\n{\r\nif (sset == ETH_SS_STATS)\r\nreturn ARRAY_SIZE(lan78xx_gstrings);\r\nelse\r\nreturn -EOPNOTSUPP;\r\n}\r\nstatic void lan78xx_get_stats(struct net_device *netdev,\r\nstruct ethtool_stats *stats, u64 *data)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(netdev);\r\nlan78xx_update_stats(dev);\r\nmutex_lock(&dev->stats.access_lock);\r\nmemcpy(data, &dev->stats.curr_stat, sizeof(dev->stats.curr_stat));\r\nmutex_unlock(&dev->stats.access_lock);\r\n}\r\nstatic void lan78xx_get_wol(struct net_device *netdev,\r\nstruct ethtool_wolinfo *wol)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(netdev);\r\nint ret;\r\nu32 buf;\r\nstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\r\nif (usb_autopm_get_interface(dev->intf) < 0)\r\nreturn;\r\nret = lan78xx_read_reg(dev, USB_CFG0, &buf);\r\nif (unlikely(ret < 0)) {\r\nwol->supported = 0;\r\nwol->wolopts = 0;\r\n} else {\r\nif (buf & USB_CFG_RMT_WKP_) {\r\nwol->supported = WAKE_ALL;\r\nwol->wolopts = pdata->wol;\r\n} else {\r\nwol->supported = 0;\r\nwol->wolopts = 0;\r\n}\r\n}\r\nusb_autopm_put_interface(dev->intf);\r\n}\r\nstatic int lan78xx_set_wol(struct net_device *netdev,\r\nstruct ethtool_wolinfo *wol)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(netdev);\r\nstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\r\nint ret;\r\nret = usb_autopm_get_interface(dev->intf);\r\nif (ret < 0)\r\nreturn ret;\r\npdata->wol = 0;\r\nif (wol->wolopts & WAKE_UCAST)\r\npdata->wol |= WAKE_UCAST;\r\nif (wol->wolopts & WAKE_MCAST)\r\npdata->wol |= WAKE_MCAST;\r\nif (wol->wolopts & WAKE_BCAST)\r\npdata->wol |= WAKE_BCAST;\r\nif (wol->wolopts & WAKE_MAGIC)\r\npdata->wol |= WAKE_MAGIC;\r\nif (wol->wolopts & WAKE_PHY)\r\npdata->wol |= WAKE_PHY;\r\nif (wol->wolopts & WAKE_ARP)\r\npdata->wol |= WAKE_ARP;\r\ndevice_set_wakeup_enable(&dev->udev->dev, (bool)wol->wolopts);\r\nphy_ethtool_set_wol(netdev->phydev, wol);\r\nusb_autopm_put_interface(dev->intf);\r\nreturn ret;\r\n}\r\nstatic int lan78xx_get_eee(struct net_device *net, struct ethtool_eee *edata)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(net);\r\nstruct phy_device *phydev = net->phydev;\r\nint ret;\r\nu32 buf;\r\nret = usb_autopm_get_interface(dev->intf);\r\nif (ret < 0)\r\nreturn ret;\r\nret = phy_ethtool_get_eee(phydev, edata);\r\nif (ret < 0)\r\ngoto exit;\r\nret = lan78xx_read_reg(dev, MAC_CR, &buf);\r\nif (buf & MAC_CR_EEE_EN_) {\r\nedata->eee_enabled = true;\r\nedata->eee_active = !!(edata->advertised &\r\nedata->lp_advertised);\r\nedata->tx_lpi_enabled = true;\r\nret = lan78xx_read_reg(dev, EEE_TX_LPI_REQ_DLY, &buf);\r\nedata->tx_lpi_timer = buf;\r\n} else {\r\nedata->eee_enabled = false;\r\nedata->eee_active = false;\r\nedata->tx_lpi_enabled = false;\r\nedata->tx_lpi_timer = 0;\r\n}\r\nret = 0;\r\nexit:\r\nusb_autopm_put_interface(dev->intf);\r\nreturn ret;\r\n}\r\nstatic int lan78xx_set_eee(struct net_device *net, struct ethtool_eee *edata)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(net);\r\nint ret;\r\nu32 buf;\r\nret = usb_autopm_get_interface(dev->intf);\r\nif (ret < 0)\r\nreturn ret;\r\nif (edata->eee_enabled) {\r\nret = lan78xx_read_reg(dev, MAC_CR, &buf);\r\nbuf |= MAC_CR_EEE_EN_;\r\nret = lan78xx_write_reg(dev, MAC_CR, buf);\r\nphy_ethtool_set_eee(net->phydev, edata);\r\nbuf = (u32)edata->tx_lpi_timer;\r\nret = lan78xx_write_reg(dev, EEE_TX_LPI_REQ_DLY, buf);\r\n} else {\r\nret = lan78xx_read_reg(dev, MAC_CR, &buf);\r\nbuf &= ~MAC_CR_EEE_EN_;\r\nret = lan78xx_write_reg(dev, MAC_CR, buf);\r\n}\r\nusb_autopm_put_interface(dev->intf);\r\nreturn 0;\r\n}\r\nstatic u32 lan78xx_get_link(struct net_device *net)\r\n{\r\nphy_read_status(net->phydev);\r\nreturn net->phydev->link;\r\n}\r\nint lan78xx_nway_reset(struct net_device *net)\r\n{\r\nreturn phy_start_aneg(net->phydev);\r\n}\r\nstatic void lan78xx_get_drvinfo(struct net_device *net,\r\nstruct ethtool_drvinfo *info)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(net);\r\nstrncpy(info->driver, DRIVER_NAME, sizeof(info->driver));\r\nstrncpy(info->version, DRIVER_VERSION, sizeof(info->version));\r\nusb_make_path(dev->udev, info->bus_info, sizeof(info->bus_info));\r\n}\r\nstatic u32 lan78xx_get_msglevel(struct net_device *net)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(net);\r\nreturn dev->msg_enable;\r\n}\r\nstatic void lan78xx_set_msglevel(struct net_device *net, u32 level)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(net);\r\ndev->msg_enable = level;\r\n}\r\nstatic int lan78xx_get_mdix_status(struct net_device *net)\r\n{\r\nstruct phy_device *phydev = net->phydev;\r\nint buf;\r\nphy_write(phydev, LAN88XX_EXT_PAGE_ACCESS, LAN88XX_EXT_PAGE_SPACE_1);\r\nbuf = phy_read(phydev, LAN88XX_EXT_MODE_CTRL);\r\nphy_write(phydev, LAN88XX_EXT_PAGE_ACCESS, LAN88XX_EXT_PAGE_SPACE_0);\r\nreturn buf;\r\n}\r\nstatic void lan78xx_set_mdix_status(struct net_device *net, __u8 mdix_ctrl)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(net);\r\nstruct phy_device *phydev = net->phydev;\r\nint buf;\r\nif (mdix_ctrl == ETH_TP_MDI) {\r\nphy_write(phydev, LAN88XX_EXT_PAGE_ACCESS,\r\nLAN88XX_EXT_PAGE_SPACE_1);\r\nbuf = phy_read(phydev, LAN88XX_EXT_MODE_CTRL);\r\nbuf &= ~LAN88XX_EXT_MODE_CTRL_MDIX_MASK_;\r\nphy_write(phydev, LAN88XX_EXT_MODE_CTRL,\r\nbuf | LAN88XX_EXT_MODE_CTRL_MDI_);\r\nphy_write(phydev, LAN88XX_EXT_PAGE_ACCESS,\r\nLAN88XX_EXT_PAGE_SPACE_0);\r\n} else if (mdix_ctrl == ETH_TP_MDI_X) {\r\nphy_write(phydev, LAN88XX_EXT_PAGE_ACCESS,\r\nLAN88XX_EXT_PAGE_SPACE_1);\r\nbuf = phy_read(phydev, LAN88XX_EXT_MODE_CTRL);\r\nbuf &= ~LAN88XX_EXT_MODE_CTRL_MDIX_MASK_;\r\nphy_write(phydev, LAN88XX_EXT_MODE_CTRL,\r\nbuf | LAN88XX_EXT_MODE_CTRL_MDI_X_);\r\nphy_write(phydev, LAN88XX_EXT_PAGE_ACCESS,\r\nLAN88XX_EXT_PAGE_SPACE_0);\r\n} else if (mdix_ctrl == ETH_TP_MDI_AUTO) {\r\nphy_write(phydev, LAN88XX_EXT_PAGE_ACCESS,\r\nLAN88XX_EXT_PAGE_SPACE_1);\r\nbuf = phy_read(phydev, LAN88XX_EXT_MODE_CTRL);\r\nbuf &= ~LAN88XX_EXT_MODE_CTRL_MDIX_MASK_;\r\nphy_write(phydev, LAN88XX_EXT_MODE_CTRL,\r\nbuf | LAN88XX_EXT_MODE_CTRL_AUTO_MDIX_);\r\nphy_write(phydev, LAN88XX_EXT_PAGE_ACCESS,\r\nLAN88XX_EXT_PAGE_SPACE_0);\r\n}\r\ndev->mdix_ctrl = mdix_ctrl;\r\n}\r\nstatic int lan78xx_get_settings(struct net_device *net, struct ethtool_cmd *cmd)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(net);\r\nstruct phy_device *phydev = net->phydev;\r\nint ret;\r\nint buf;\r\nret = usb_autopm_get_interface(dev->intf);\r\nif (ret < 0)\r\nreturn ret;\r\nret = phy_ethtool_gset(phydev, cmd);\r\nbuf = lan78xx_get_mdix_status(net);\r\nbuf &= LAN88XX_EXT_MODE_CTRL_MDIX_MASK_;\r\nif (buf == LAN88XX_EXT_MODE_CTRL_AUTO_MDIX_) {\r\ncmd->eth_tp_mdix = ETH_TP_MDI_AUTO;\r\ncmd->eth_tp_mdix_ctrl = ETH_TP_MDI_AUTO;\r\n} else if (buf == LAN88XX_EXT_MODE_CTRL_MDI_) {\r\ncmd->eth_tp_mdix = ETH_TP_MDI;\r\ncmd->eth_tp_mdix_ctrl = ETH_TP_MDI;\r\n} else if (buf == LAN88XX_EXT_MODE_CTRL_MDI_X_) {\r\ncmd->eth_tp_mdix = ETH_TP_MDI_X;\r\ncmd->eth_tp_mdix_ctrl = ETH_TP_MDI_X;\r\n}\r\nusb_autopm_put_interface(dev->intf);\r\nreturn ret;\r\n}\r\nstatic int lan78xx_set_settings(struct net_device *net, struct ethtool_cmd *cmd)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(net);\r\nstruct phy_device *phydev = net->phydev;\r\nint ret = 0;\r\nint temp;\r\nret = usb_autopm_get_interface(dev->intf);\r\nif (ret < 0)\r\nreturn ret;\r\nif (dev->mdix_ctrl != cmd->eth_tp_mdix_ctrl) {\r\nlan78xx_set_mdix_status(net, cmd->eth_tp_mdix_ctrl);\r\n}\r\nret = phy_ethtool_sset(phydev, cmd);\r\nif (!cmd->autoneg) {\r\ntemp = phy_read(phydev, MII_BMCR);\r\nphy_write(phydev, MII_BMCR, temp | BMCR_LOOPBACK);\r\nmdelay(1);\r\nphy_write(phydev, MII_BMCR, temp);\r\n}\r\nusb_autopm_put_interface(dev->intf);\r\nreturn ret;\r\n}\r\nstatic void lan78xx_get_pause(struct net_device *net,\r\nstruct ethtool_pauseparam *pause)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(net);\r\nstruct phy_device *phydev = net->phydev;\r\nstruct ethtool_cmd ecmd = { .cmd = ETHTOOL_GSET };\r\nphy_ethtool_gset(phydev, &ecmd);\r\npause->autoneg = dev->fc_autoneg;\r\nif (dev->fc_request_control & FLOW_CTRL_TX)\r\npause->tx_pause = 1;\r\nif (dev->fc_request_control & FLOW_CTRL_RX)\r\npause->rx_pause = 1;\r\n}\r\nstatic int lan78xx_set_pause(struct net_device *net,\r\nstruct ethtool_pauseparam *pause)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(net);\r\nstruct phy_device *phydev = net->phydev;\r\nstruct ethtool_cmd ecmd = { .cmd = ETHTOOL_GSET };\r\nint ret;\r\nphy_ethtool_gset(phydev, &ecmd);\r\nif (pause->autoneg && !ecmd.autoneg) {\r\nret = -EINVAL;\r\ngoto exit;\r\n}\r\ndev->fc_request_control = 0;\r\nif (pause->rx_pause)\r\ndev->fc_request_control |= FLOW_CTRL_RX;\r\nif (pause->tx_pause)\r\ndev->fc_request_control |= FLOW_CTRL_TX;\r\nif (ecmd.autoneg) {\r\nu32 mii_adv;\r\necmd.advertising &= ~(ADVERTISED_Pause | ADVERTISED_Asym_Pause);\r\nmii_adv = (u32)mii_advertise_flowctrl(dev->fc_request_control);\r\necmd.advertising |= mii_adv_to_ethtool_adv_t(mii_adv);\r\nphy_ethtool_sset(phydev, &ecmd);\r\n}\r\ndev->fc_autoneg = pause->autoneg;\r\nret = 0;\r\nexit:\r\nreturn ret;\r\n}\r\nstatic int lan78xx_ioctl(struct net_device *netdev, struct ifreq *rq, int cmd)\r\n{\r\nif (!netif_running(netdev))\r\nreturn -EINVAL;\r\nreturn phy_mii_ioctl(netdev->phydev, rq, cmd);\r\n}\r\nstatic void lan78xx_init_mac_address(struct lan78xx_net *dev)\r\n{\r\nu32 addr_lo, addr_hi;\r\nint ret;\r\nu8 addr[6];\r\nret = lan78xx_read_reg(dev, RX_ADDRL, &addr_lo);\r\nret = lan78xx_read_reg(dev, RX_ADDRH, &addr_hi);\r\naddr[0] = addr_lo & 0xFF;\r\naddr[1] = (addr_lo >> 8) & 0xFF;\r\naddr[2] = (addr_lo >> 16) & 0xFF;\r\naddr[3] = (addr_lo >> 24) & 0xFF;\r\naddr[4] = addr_hi & 0xFF;\r\naddr[5] = (addr_hi >> 8) & 0xFF;\r\nif (!is_valid_ether_addr(addr)) {\r\nif ((lan78xx_read_eeprom(dev, EEPROM_MAC_OFFSET, ETH_ALEN,\r\naddr) == 0) ||\r\n(lan78xx_read_otp(dev, EEPROM_MAC_OFFSET, ETH_ALEN,\r\naddr) == 0)) {\r\nif (is_valid_ether_addr(addr)) {\r\nnetif_dbg(dev, ifup, dev->net,\r\n"MAC address read from EEPROM");\r\n} else {\r\nrandom_ether_addr(addr);\r\nnetif_dbg(dev, ifup, dev->net,\r\n"MAC address set to random addr");\r\n}\r\naddr_lo = addr[0] | (addr[1] << 8) |\r\n(addr[2] << 16) | (addr[3] << 24);\r\naddr_hi = addr[4] | (addr[5] << 8);\r\nret = lan78xx_write_reg(dev, RX_ADDRL, addr_lo);\r\nret = lan78xx_write_reg(dev, RX_ADDRH, addr_hi);\r\n} else {\r\nrandom_ether_addr(addr);\r\nnetif_dbg(dev, ifup, dev->net,\r\n"MAC address set to random addr");\r\n}\r\n}\r\nret = lan78xx_write_reg(dev, MAF_LO(0), addr_lo);\r\nret = lan78xx_write_reg(dev, MAF_HI(0), addr_hi | MAF_HI_VALID_);\r\nether_addr_copy(dev->net->dev_addr, addr);\r\n}\r\nstatic int lan78xx_mdiobus_read(struct mii_bus *bus, int phy_id, int idx)\r\n{\r\nstruct lan78xx_net *dev = bus->priv;\r\nu32 val, addr;\r\nint ret;\r\nret = usb_autopm_get_interface(dev->intf);\r\nif (ret < 0)\r\nreturn ret;\r\nmutex_lock(&dev->phy_mutex);\r\nret = lan78xx_phy_wait_not_busy(dev);\r\nif (ret < 0)\r\ngoto done;\r\naddr = mii_access(phy_id, idx, MII_READ);\r\nret = lan78xx_write_reg(dev, MII_ACC, addr);\r\nret = lan78xx_phy_wait_not_busy(dev);\r\nif (ret < 0)\r\ngoto done;\r\nret = lan78xx_read_reg(dev, MII_DATA, &val);\r\nret = (int)(val & 0xFFFF);\r\ndone:\r\nmutex_unlock(&dev->phy_mutex);\r\nusb_autopm_put_interface(dev->intf);\r\nreturn ret;\r\n}\r\nstatic int lan78xx_mdiobus_write(struct mii_bus *bus, int phy_id, int idx,\r\nu16 regval)\r\n{\r\nstruct lan78xx_net *dev = bus->priv;\r\nu32 val, addr;\r\nint ret;\r\nret = usb_autopm_get_interface(dev->intf);\r\nif (ret < 0)\r\nreturn ret;\r\nmutex_lock(&dev->phy_mutex);\r\nret = lan78xx_phy_wait_not_busy(dev);\r\nif (ret < 0)\r\ngoto done;\r\nval = (u32)regval;\r\nret = lan78xx_write_reg(dev, MII_DATA, val);\r\naddr = mii_access(phy_id, idx, MII_WRITE);\r\nret = lan78xx_write_reg(dev, MII_ACC, addr);\r\nret = lan78xx_phy_wait_not_busy(dev);\r\nif (ret < 0)\r\ngoto done;\r\ndone:\r\nmutex_unlock(&dev->phy_mutex);\r\nusb_autopm_put_interface(dev->intf);\r\nreturn 0;\r\n}\r\nstatic int lan78xx_mdio_init(struct lan78xx_net *dev)\r\n{\r\nint ret;\r\ndev->mdiobus = mdiobus_alloc();\r\nif (!dev->mdiobus) {\r\nnetdev_err(dev->net, "can't allocate MDIO bus\n");\r\nreturn -ENOMEM;\r\n}\r\ndev->mdiobus->priv = (void *)dev;\r\ndev->mdiobus->read = lan78xx_mdiobus_read;\r\ndev->mdiobus->write = lan78xx_mdiobus_write;\r\ndev->mdiobus->name = "lan78xx-mdiobus";\r\nsnprintf(dev->mdiobus->id, MII_BUS_ID_SIZE, "usb-%03d:%03d",\r\ndev->udev->bus->busnum, dev->udev->devnum);\r\nswitch (dev->chipid) {\r\ncase ID_REV_CHIP_ID_7800_:\r\ncase ID_REV_CHIP_ID_7850_:\r\ndev->mdiobus->phy_mask = ~(1 << 1);\r\nbreak;\r\n}\r\nret = mdiobus_register(dev->mdiobus);\r\nif (ret) {\r\nnetdev_err(dev->net, "can't register MDIO bus\n");\r\ngoto exit1;\r\n}\r\nnetdev_dbg(dev->net, "registered mdiobus bus %s\n", dev->mdiobus->id);\r\nreturn 0;\r\nexit1:\r\nmdiobus_free(dev->mdiobus);\r\nreturn ret;\r\n}\r\nstatic void lan78xx_remove_mdio(struct lan78xx_net *dev)\r\n{\r\nmdiobus_unregister(dev->mdiobus);\r\nmdiobus_free(dev->mdiobus);\r\n}\r\nstatic void lan78xx_link_status_change(struct net_device *net)\r\n{\r\nstruct phy_device *phydev = net->phydev;\r\nint ret, temp;\r\nif (!phydev->autoneg && (phydev->speed == 100)) {\r\ntemp = phy_read(phydev, LAN88XX_INT_MASK);\r\ntemp &= ~LAN88XX_INT_MASK_MDINTPIN_EN_;\r\nret = phy_write(phydev, LAN88XX_INT_MASK, temp);\r\ntemp = phy_read(phydev, MII_BMCR);\r\ntemp &= ~(BMCR_SPEED100 | BMCR_SPEED1000);\r\nphy_write(phydev, MII_BMCR, temp);\r\ntemp |= BMCR_SPEED100;\r\nphy_write(phydev, MII_BMCR, temp);\r\ntemp = phy_read(phydev, LAN88XX_INT_STS);\r\ntemp = phy_read(phydev, LAN88XX_INT_MASK);\r\ntemp |= LAN88XX_INT_MASK_MDINTPIN_EN_;\r\nret = phy_write(phydev, LAN88XX_INT_MASK, temp);\r\n}\r\n}\r\nstatic int lan78xx_phy_init(struct lan78xx_net *dev)\r\n{\r\nint ret;\r\nu32 mii_adv;\r\nstruct phy_device *phydev = dev->net->phydev;\r\nphydev = phy_find_first(dev->mdiobus);\r\nif (!phydev) {\r\nnetdev_err(dev->net, "no PHY found\n");\r\nreturn -EIO;\r\n}\r\nret = phy_read(phydev, LAN88XX_INT_STS);\r\nret = phy_write(phydev, LAN88XX_INT_MASK,\r\nLAN88XX_INT_MASK_MDINTPIN_EN_ |\r\nLAN88XX_INT_MASK_LINK_CHANGE_);\r\nphydev->irq = PHY_IGNORE_INTERRUPT;\r\nret = phy_connect_direct(dev->net, phydev,\r\nlan78xx_link_status_change,\r\nPHY_INTERFACE_MODE_GMII);\r\nif (ret) {\r\nnetdev_err(dev->net, "can't attach PHY to %s\n",\r\ndev->mdiobus->id);\r\nreturn -EIO;\r\n}\r\nlan78xx_set_mdix_status(dev->net, ETH_TP_MDI_AUTO);\r\nphydev->supported &= ~SUPPORTED_1000baseT_Half;\r\ndev->fc_request_control = (FLOW_CTRL_RX | FLOW_CTRL_TX);\r\nphydev->advertising &= ~(ADVERTISED_Pause | ADVERTISED_Asym_Pause);\r\nmii_adv = (u32)mii_advertise_flowctrl(dev->fc_request_control);\r\nphydev->advertising |= mii_adv_to_ethtool_adv_t(mii_adv);\r\ngenphy_config_aneg(phydev);\r\ndev->fc_autoneg = phydev->autoneg;\r\nphy_start(phydev);\r\nnetif_dbg(dev, ifup, dev->net, "phy initialised successfully");\r\nreturn 0;\r\n}\r\nstatic int lan78xx_set_rx_max_frame_length(struct lan78xx_net *dev, int size)\r\n{\r\nint ret = 0;\r\nu32 buf;\r\nbool rxenabled;\r\nret = lan78xx_read_reg(dev, MAC_RX, &buf);\r\nrxenabled = ((buf & MAC_RX_RXEN_) != 0);\r\nif (rxenabled) {\r\nbuf &= ~MAC_RX_RXEN_;\r\nret = lan78xx_write_reg(dev, MAC_RX, buf);\r\n}\r\nbuf &= ~MAC_RX_MAX_SIZE_MASK_;\r\nbuf |= (((size + 4) << MAC_RX_MAX_SIZE_SHIFT_) & MAC_RX_MAX_SIZE_MASK_);\r\nret = lan78xx_write_reg(dev, MAC_RX, buf);\r\nif (rxenabled) {\r\nbuf |= MAC_RX_RXEN_;\r\nret = lan78xx_write_reg(dev, MAC_RX, buf);\r\n}\r\nreturn 0;\r\n}\r\nstatic int unlink_urbs(struct lan78xx_net *dev, struct sk_buff_head *q)\r\n{\r\nstruct sk_buff *skb;\r\nunsigned long flags;\r\nint count = 0;\r\nspin_lock_irqsave(&q->lock, flags);\r\nwhile (!skb_queue_empty(q)) {\r\nstruct skb_data *entry;\r\nstruct urb *urb;\r\nint ret;\r\nskb_queue_walk(q, skb) {\r\nentry = (struct skb_data *)skb->cb;\r\nif (entry->state != unlink_start)\r\ngoto found;\r\n}\r\nbreak;\r\nfound:\r\nentry->state = unlink_start;\r\nurb = entry->urb;\r\nusb_get_urb(urb);\r\nspin_unlock_irqrestore(&q->lock, flags);\r\nret = usb_unlink_urb(urb);\r\nif (ret != -EINPROGRESS && ret != 0)\r\nnetdev_dbg(dev->net, "unlink urb err, %d\n", ret);\r\nelse\r\ncount++;\r\nusb_put_urb(urb);\r\nspin_lock_irqsave(&q->lock, flags);\r\n}\r\nspin_unlock_irqrestore(&q->lock, flags);\r\nreturn count;\r\n}\r\nstatic int lan78xx_change_mtu(struct net_device *netdev, int new_mtu)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(netdev);\r\nint ll_mtu = new_mtu + netdev->hard_header_len;\r\nint old_hard_mtu = dev->hard_mtu;\r\nint old_rx_urb_size = dev->rx_urb_size;\r\nint ret;\r\nif (new_mtu > MAX_SINGLE_PACKET_SIZE)\r\nreturn -EINVAL;\r\nif (new_mtu <= 0)\r\nreturn -EINVAL;\r\nif ((ll_mtu % dev->maxpacket) == 0)\r\nreturn -EDOM;\r\nret = lan78xx_set_rx_max_frame_length(dev, new_mtu + ETH_HLEN);\r\nnetdev->mtu = new_mtu;\r\ndev->hard_mtu = netdev->mtu + netdev->hard_header_len;\r\nif (dev->rx_urb_size == old_hard_mtu) {\r\ndev->rx_urb_size = dev->hard_mtu;\r\nif (dev->rx_urb_size > old_rx_urb_size) {\r\nif (netif_running(dev->net)) {\r\nunlink_urbs(dev, &dev->rxq);\r\ntasklet_schedule(&dev->bh);\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint lan78xx_set_mac_addr(struct net_device *netdev, void *p)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(netdev);\r\nstruct sockaddr *addr = p;\r\nu32 addr_lo, addr_hi;\r\nint ret;\r\nif (netif_running(netdev))\r\nreturn -EBUSY;\r\nif (!is_valid_ether_addr(addr->sa_data))\r\nreturn -EADDRNOTAVAIL;\r\nether_addr_copy(netdev->dev_addr, addr->sa_data);\r\naddr_lo = netdev->dev_addr[0] |\r\nnetdev->dev_addr[1] << 8 |\r\nnetdev->dev_addr[2] << 16 |\r\nnetdev->dev_addr[3] << 24;\r\naddr_hi = netdev->dev_addr[4] |\r\nnetdev->dev_addr[5] << 8;\r\nret = lan78xx_write_reg(dev, RX_ADDRL, addr_lo);\r\nret = lan78xx_write_reg(dev, RX_ADDRH, addr_hi);\r\nreturn 0;\r\n}\r\nstatic int lan78xx_set_features(struct net_device *netdev,\r\nnetdev_features_t features)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(netdev);\r\nstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\r\nunsigned long flags;\r\nint ret;\r\nspin_lock_irqsave(&pdata->rfe_ctl_lock, flags);\r\nif (features & NETIF_F_RXCSUM) {\r\npdata->rfe_ctl |= RFE_CTL_TCPUDP_COE_ | RFE_CTL_IP_COE_;\r\npdata->rfe_ctl |= RFE_CTL_ICMP_COE_ | RFE_CTL_IGMP_COE_;\r\n} else {\r\npdata->rfe_ctl &= ~(RFE_CTL_TCPUDP_COE_ | RFE_CTL_IP_COE_);\r\npdata->rfe_ctl &= ~(RFE_CTL_ICMP_COE_ | RFE_CTL_IGMP_COE_);\r\n}\r\nif (features & NETIF_F_HW_VLAN_CTAG_RX)\r\npdata->rfe_ctl |= RFE_CTL_VLAN_FILTER_;\r\nelse\r\npdata->rfe_ctl &= ~RFE_CTL_VLAN_FILTER_;\r\nspin_unlock_irqrestore(&pdata->rfe_ctl_lock, flags);\r\nret = lan78xx_write_reg(dev, RFE_CTL, pdata->rfe_ctl);\r\nreturn 0;\r\n}\r\nstatic void lan78xx_deferred_vlan_write(struct work_struct *param)\r\n{\r\nstruct lan78xx_priv *pdata =\r\ncontainer_of(param, struct lan78xx_priv, set_vlan);\r\nstruct lan78xx_net *dev = pdata->dev;\r\nlan78xx_dataport_write(dev, DP_SEL_RSEL_VLAN_DA_, 0,\r\nDP_SEL_VHF_VLAN_LEN, pdata->vlan_table);\r\n}\r\nstatic int lan78xx_vlan_rx_add_vid(struct net_device *netdev,\r\n__be16 proto, u16 vid)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(netdev);\r\nstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\r\nu16 vid_bit_index;\r\nu16 vid_dword_index;\r\nvid_dword_index = (vid >> 5) & 0x7F;\r\nvid_bit_index = vid & 0x1F;\r\npdata->vlan_table[vid_dword_index] |= (1 << vid_bit_index);\r\nschedule_work(&pdata->set_vlan);\r\nreturn 0;\r\n}\r\nstatic int lan78xx_vlan_rx_kill_vid(struct net_device *netdev,\r\n__be16 proto, u16 vid)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(netdev);\r\nstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\r\nu16 vid_bit_index;\r\nu16 vid_dword_index;\r\nvid_dword_index = (vid >> 5) & 0x7F;\r\nvid_bit_index = vid & 0x1F;\r\npdata->vlan_table[vid_dword_index] &= ~(1 << vid_bit_index);\r\nschedule_work(&pdata->set_vlan);\r\nreturn 0;\r\n}\r\nstatic void lan78xx_init_ltm(struct lan78xx_net *dev)\r\n{\r\nint ret;\r\nu32 buf;\r\nu32 regs[6] = { 0 };\r\nret = lan78xx_read_reg(dev, USB_CFG1, &buf);\r\nif (buf & USB_CFG1_LTM_ENABLE_) {\r\nu8 temp[2];\r\nif (lan78xx_read_eeprom(dev, 0x3F, 2, temp) == 0) {\r\nif (temp[0] == 24) {\r\nret = lan78xx_read_raw_eeprom(dev,\r\ntemp[1] * 2,\r\n24,\r\n(u8 *)regs);\r\nif (ret < 0)\r\nreturn;\r\n}\r\n} else if (lan78xx_read_otp(dev, 0x3F, 2, temp) == 0) {\r\nif (temp[0] == 24) {\r\nret = lan78xx_read_raw_otp(dev,\r\ntemp[1] * 2,\r\n24,\r\n(u8 *)regs);\r\nif (ret < 0)\r\nreturn;\r\n}\r\n}\r\n}\r\nlan78xx_write_reg(dev, LTM_BELT_IDLE0, regs[0]);\r\nlan78xx_write_reg(dev, LTM_BELT_IDLE1, regs[1]);\r\nlan78xx_write_reg(dev, LTM_BELT_ACT0, regs[2]);\r\nlan78xx_write_reg(dev, LTM_BELT_ACT1, regs[3]);\r\nlan78xx_write_reg(dev, LTM_INACTIVE0, regs[4]);\r\nlan78xx_write_reg(dev, LTM_INACTIVE1, regs[5]);\r\n}\r\nstatic int lan78xx_reset(struct lan78xx_net *dev)\r\n{\r\nstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\r\nu32 buf;\r\nint ret = 0;\r\nunsigned long timeout;\r\nret = lan78xx_read_reg(dev, HW_CFG, &buf);\r\nbuf |= HW_CFG_LRST_;\r\nret = lan78xx_write_reg(dev, HW_CFG, buf);\r\ntimeout = jiffies + HZ;\r\ndo {\r\nmdelay(1);\r\nret = lan78xx_read_reg(dev, HW_CFG, &buf);\r\nif (time_after(jiffies, timeout)) {\r\nnetdev_warn(dev->net,\r\n"timeout on completion of LiteReset");\r\nreturn -EIO;\r\n}\r\n} while (buf & HW_CFG_LRST_);\r\nlan78xx_init_mac_address(dev);\r\nret = lan78xx_read_reg(dev, ID_REV, &buf);\r\ndev->chipid = (buf & ID_REV_CHIP_ID_MASK_) >> 16;\r\ndev->chiprev = buf & ID_REV_CHIP_REV_MASK_;\r\nret = lan78xx_read_reg(dev, USB_CFG0, &buf);\r\nbuf |= USB_CFG_BIR_;\r\nret = lan78xx_write_reg(dev, USB_CFG0, buf);\r\nlan78xx_init_ltm(dev);\r\ndev->net->hard_header_len += TX_OVERHEAD;\r\ndev->hard_mtu = dev->net->mtu + dev->net->hard_header_len;\r\nif (dev->udev->speed == USB_SPEED_SUPER) {\r\nbuf = DEFAULT_BURST_CAP_SIZE / SS_USB_PKT_SIZE;\r\ndev->rx_urb_size = DEFAULT_BURST_CAP_SIZE;\r\ndev->rx_qlen = 4;\r\ndev->tx_qlen = 4;\r\n} else if (dev->udev->speed == USB_SPEED_HIGH) {\r\nbuf = DEFAULT_BURST_CAP_SIZE / HS_USB_PKT_SIZE;\r\ndev->rx_urb_size = DEFAULT_BURST_CAP_SIZE;\r\ndev->rx_qlen = RX_MAX_QUEUE_MEMORY / dev->rx_urb_size;\r\ndev->tx_qlen = RX_MAX_QUEUE_MEMORY / dev->hard_mtu;\r\n} else {\r\nbuf = DEFAULT_BURST_CAP_SIZE / FS_USB_PKT_SIZE;\r\ndev->rx_urb_size = DEFAULT_BURST_CAP_SIZE;\r\ndev->rx_qlen = 4;\r\n}\r\nret = lan78xx_write_reg(dev, BURST_CAP, buf);\r\nret = lan78xx_write_reg(dev, BULK_IN_DLY, DEFAULT_BULK_IN_DELAY);\r\nret = lan78xx_read_reg(dev, HW_CFG, &buf);\r\nbuf |= HW_CFG_MEF_;\r\nret = lan78xx_write_reg(dev, HW_CFG, buf);\r\nret = lan78xx_read_reg(dev, USB_CFG0, &buf);\r\nbuf |= USB_CFG_BCE_;\r\nret = lan78xx_write_reg(dev, USB_CFG0, buf);\r\nbuf = (MAX_RX_FIFO_SIZE - 512) / 512;\r\nret = lan78xx_write_reg(dev, FCT_RX_FIFO_END, buf);\r\nbuf = (MAX_TX_FIFO_SIZE - 512) / 512;\r\nret = lan78xx_write_reg(dev, FCT_TX_FIFO_END, buf);\r\nret = lan78xx_write_reg(dev, INT_STS, INT_STS_CLEAR_ALL_);\r\nret = lan78xx_write_reg(dev, FLOW, 0);\r\nret = lan78xx_write_reg(dev, FCT_FLOW, 0);\r\nret = lan78xx_read_reg(dev, RFE_CTL, &pdata->rfe_ctl);\r\npdata->rfe_ctl |= RFE_CTL_BCAST_EN_ | RFE_CTL_DA_PERFECT_;\r\nret = lan78xx_write_reg(dev, RFE_CTL, pdata->rfe_ctl);\r\nlan78xx_set_features(dev->net, dev->net->features);\r\nlan78xx_set_multicast(dev->net);\r\nret = lan78xx_read_reg(dev, PMT_CTL, &buf);\r\nbuf |= PMT_CTL_PHY_RST_;\r\nret = lan78xx_write_reg(dev, PMT_CTL, buf);\r\ntimeout = jiffies + HZ;\r\ndo {\r\nmdelay(1);\r\nret = lan78xx_read_reg(dev, PMT_CTL, &buf);\r\nif (time_after(jiffies, timeout)) {\r\nnetdev_warn(dev->net, "timeout waiting for PHY Reset");\r\nreturn -EIO;\r\n}\r\n} while ((buf & PMT_CTL_PHY_RST_) || !(buf & PMT_CTL_READY_));\r\nret = lan78xx_read_reg(dev, MAC_CR, &buf);\r\nbuf |= MAC_CR_AUTO_DUPLEX_ | MAC_CR_AUTO_SPEED_;\r\nret = lan78xx_write_reg(dev, MAC_CR, buf);\r\nret = lan78xx_read_reg(dev, INT_EP_CTL, &buf);\r\nbuf |= INT_ENP_PHY_INT;\r\nret = lan78xx_write_reg(dev, INT_EP_CTL, buf);\r\nret = lan78xx_read_reg(dev, MAC_TX, &buf);\r\nbuf |= MAC_TX_TXEN_;\r\nret = lan78xx_write_reg(dev, MAC_TX, buf);\r\nret = lan78xx_read_reg(dev, FCT_TX_CTL, &buf);\r\nbuf |= FCT_TX_CTL_EN_;\r\nret = lan78xx_write_reg(dev, FCT_TX_CTL, buf);\r\nret = lan78xx_set_rx_max_frame_length(dev, dev->net->mtu + ETH_HLEN);\r\nret = lan78xx_read_reg(dev, MAC_RX, &buf);\r\nbuf |= MAC_RX_RXEN_;\r\nret = lan78xx_write_reg(dev, MAC_RX, buf);\r\nret = lan78xx_read_reg(dev, FCT_RX_CTL, &buf);\r\nbuf |= FCT_RX_CTL_EN_;\r\nret = lan78xx_write_reg(dev, FCT_RX_CTL, buf);\r\nreturn 0;\r\n}\r\nstatic void lan78xx_init_stats(struct lan78xx_net *dev)\r\n{\r\nu32 *p;\r\nint i;\r\np = (u32 *)&dev->stats.rollover_max;\r\nfor (i = 0; i < (sizeof(dev->stats.rollover_max) / (sizeof(u32))); i++)\r\np[i] = 0xFFFFF;\r\ndev->stats.rollover_max.rx_unicast_byte_count = 0xFFFFFFFF;\r\ndev->stats.rollover_max.rx_broadcast_byte_count = 0xFFFFFFFF;\r\ndev->stats.rollover_max.rx_multicast_byte_count = 0xFFFFFFFF;\r\ndev->stats.rollover_max.eee_rx_lpi_transitions = 0xFFFFFFFF;\r\ndev->stats.rollover_max.eee_rx_lpi_time = 0xFFFFFFFF;\r\ndev->stats.rollover_max.tx_unicast_byte_count = 0xFFFFFFFF;\r\ndev->stats.rollover_max.tx_broadcast_byte_count = 0xFFFFFFFF;\r\ndev->stats.rollover_max.tx_multicast_byte_count = 0xFFFFFFFF;\r\ndev->stats.rollover_max.eee_tx_lpi_transitions = 0xFFFFFFFF;\r\ndev->stats.rollover_max.eee_tx_lpi_time = 0xFFFFFFFF;\r\nlan78xx_defer_kevent(dev, EVENT_STAT_UPDATE);\r\n}\r\nstatic int lan78xx_open(struct net_device *net)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(net);\r\nint ret;\r\nret = usb_autopm_get_interface(dev->intf);\r\nif (ret < 0)\r\ngoto out;\r\nret = lan78xx_reset(dev);\r\nif (ret < 0)\r\ngoto done;\r\nret = lan78xx_phy_init(dev);\r\nif (ret < 0)\r\ngoto done;\r\nif (dev->urb_intr) {\r\nret = usb_submit_urb(dev->urb_intr, GFP_KERNEL);\r\nif (ret < 0) {\r\nnetif_err(dev, ifup, dev->net,\r\n"intr submit %d\n", ret);\r\ngoto done;\r\n}\r\n}\r\nlan78xx_init_stats(dev);\r\nset_bit(EVENT_DEV_OPEN, &dev->flags);\r\nnetif_start_queue(net);\r\ndev->link_on = false;\r\nlan78xx_defer_kevent(dev, EVENT_LINK_RESET);\r\ndone:\r\nusb_autopm_put_interface(dev->intf);\r\nout:\r\nreturn ret;\r\n}\r\nstatic void lan78xx_terminate_urbs(struct lan78xx_net *dev)\r\n{\r\nDECLARE_WAIT_QUEUE_HEAD_ONSTACK(unlink_wakeup);\r\nDECLARE_WAITQUEUE(wait, current);\r\nint temp;\r\nadd_wait_queue(&unlink_wakeup, &wait);\r\nset_current_state(TASK_UNINTERRUPTIBLE);\r\ndev->wait = &unlink_wakeup;\r\ntemp = unlink_urbs(dev, &dev->txq) + unlink_urbs(dev, &dev->rxq);\r\nwhile (!skb_queue_empty(&dev->rxq) &&\r\n!skb_queue_empty(&dev->txq) &&\r\n!skb_queue_empty(&dev->done)) {\r\nschedule_timeout(msecs_to_jiffies(UNLINK_TIMEOUT_MS));\r\nset_current_state(TASK_UNINTERRUPTIBLE);\r\nnetif_dbg(dev, ifdown, dev->net,\r\n"waited for %d urb completions\n", temp);\r\n}\r\nset_current_state(TASK_RUNNING);\r\ndev->wait = NULL;\r\nremove_wait_queue(&unlink_wakeup, &wait);\r\n}\r\nint lan78xx_stop(struct net_device *net)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(net);\r\nif (timer_pending(&dev->stat_monitor))\r\ndel_timer_sync(&dev->stat_monitor);\r\nphy_stop(net->phydev);\r\nphy_disconnect(net->phydev);\r\nnet->phydev = NULL;\r\nclear_bit(EVENT_DEV_OPEN, &dev->flags);\r\nnetif_stop_queue(net);\r\nnetif_info(dev, ifdown, dev->net,\r\n"stop stats: rx/tx %lu/%lu, errs %lu/%lu\n",\r\nnet->stats.rx_packets, net->stats.tx_packets,\r\nnet->stats.rx_errors, net->stats.tx_errors);\r\nlan78xx_terminate_urbs(dev);\r\nusb_kill_urb(dev->urb_intr);\r\nskb_queue_purge(&dev->rxq_pause);\r\ndev->flags = 0;\r\ncancel_delayed_work_sync(&dev->wq);\r\ntasklet_kill(&dev->bh);\r\nusb_autopm_put_interface(dev->intf);\r\nreturn 0;\r\n}\r\nstatic int lan78xx_linearize(struct sk_buff *skb)\r\n{\r\nreturn skb_linearize(skb);\r\n}\r\nstatic struct sk_buff *lan78xx_tx_prep(struct lan78xx_net *dev,\r\nstruct sk_buff *skb, gfp_t flags)\r\n{\r\nu32 tx_cmd_a, tx_cmd_b;\r\nif (skb_headroom(skb) < TX_OVERHEAD) {\r\nstruct sk_buff *skb2;\r\nskb2 = skb_copy_expand(skb, TX_OVERHEAD, 0, flags);\r\ndev_kfree_skb_any(skb);\r\nskb = skb2;\r\nif (!skb)\r\nreturn NULL;\r\n}\r\nif (lan78xx_linearize(skb) < 0)\r\nreturn NULL;\r\ntx_cmd_a = (u32)(skb->len & TX_CMD_A_LEN_MASK_) | TX_CMD_A_FCS_;\r\nif (skb->ip_summed == CHECKSUM_PARTIAL)\r\ntx_cmd_a |= TX_CMD_A_IPE_ | TX_CMD_A_TPE_;\r\ntx_cmd_b = 0;\r\nif (skb_is_gso(skb)) {\r\nu16 mss = max(skb_shinfo(skb)->gso_size, TX_CMD_B_MSS_MIN_);\r\ntx_cmd_b = (mss << TX_CMD_B_MSS_SHIFT_) & TX_CMD_B_MSS_MASK_;\r\ntx_cmd_a |= TX_CMD_A_LSO_;\r\n}\r\nif (skb_vlan_tag_present(skb)) {\r\ntx_cmd_a |= TX_CMD_A_IVTG_;\r\ntx_cmd_b |= skb_vlan_tag_get(skb) & TX_CMD_B_VTAG_MASK_;\r\n}\r\nskb_push(skb, 4);\r\ncpu_to_le32s(&tx_cmd_b);\r\nmemcpy(skb->data, &tx_cmd_b, 4);\r\nskb_push(skb, 4);\r\ncpu_to_le32s(&tx_cmd_a);\r\nmemcpy(skb->data, &tx_cmd_a, 4);\r\nreturn skb;\r\n}\r\nstatic enum skb_state defer_bh(struct lan78xx_net *dev, struct sk_buff *skb,\r\nstruct sk_buff_head *list, enum skb_state state)\r\n{\r\nunsigned long flags;\r\nenum skb_state old_state;\r\nstruct skb_data *entry = (struct skb_data *)skb->cb;\r\nspin_lock_irqsave(&list->lock, flags);\r\nold_state = entry->state;\r\nentry->state = state;\r\n__skb_unlink(skb, list);\r\nspin_unlock(&list->lock);\r\nspin_lock(&dev->done.lock);\r\n__skb_queue_tail(&dev->done, skb);\r\nif (skb_queue_len(&dev->done) == 1)\r\ntasklet_schedule(&dev->bh);\r\nspin_unlock_irqrestore(&dev->done.lock, flags);\r\nreturn old_state;\r\n}\r\nstatic void tx_complete(struct urb *urb)\r\n{\r\nstruct sk_buff *skb = (struct sk_buff *)urb->context;\r\nstruct skb_data *entry = (struct skb_data *)skb->cb;\r\nstruct lan78xx_net *dev = entry->dev;\r\nif (urb->status == 0) {\r\ndev->net->stats.tx_packets += entry->num_of_packet;\r\ndev->net->stats.tx_bytes += entry->length;\r\n} else {\r\ndev->net->stats.tx_errors++;\r\nswitch (urb->status) {\r\ncase -EPIPE:\r\nlan78xx_defer_kevent(dev, EVENT_TX_HALT);\r\nbreak;\r\ncase -ECONNRESET:\r\ncase -ESHUTDOWN:\r\nbreak;\r\ncase -EPROTO:\r\ncase -ETIME:\r\ncase -EILSEQ:\r\nnetif_stop_queue(dev->net);\r\nbreak;\r\ndefault:\r\nnetif_dbg(dev, tx_err, dev->net,\r\n"tx err %d\n", entry->urb->status);\r\nbreak;\r\n}\r\n}\r\nusb_autopm_put_interface_async(dev->intf);\r\ndefer_bh(dev, skb, &dev->txq, tx_done);\r\n}\r\nstatic void lan78xx_queue_skb(struct sk_buff_head *list,\r\nstruct sk_buff *newsk, enum skb_state state)\r\n{\r\nstruct skb_data *entry = (struct skb_data *)newsk->cb;\r\n__skb_queue_tail(list, newsk);\r\nentry->state = state;\r\n}\r\nnetdev_tx_t lan78xx_start_xmit(struct sk_buff *skb, struct net_device *net)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(net);\r\nstruct sk_buff *skb2 = NULL;\r\nif (skb) {\r\nskb_tx_timestamp(skb);\r\nskb2 = lan78xx_tx_prep(dev, skb, GFP_ATOMIC);\r\n}\r\nif (skb2) {\r\nskb_queue_tail(&dev->txq_pend, skb2);\r\nif ((dev->udev->speed < USB_SPEED_SUPER) &&\r\n(skb_queue_len(&dev->txq_pend) > 10))\r\nnetif_stop_queue(net);\r\n} else {\r\nnetif_dbg(dev, tx_err, dev->net,\r\n"lan78xx_tx_prep return NULL\n");\r\ndev->net->stats.tx_errors++;\r\ndev->net->stats.tx_dropped++;\r\n}\r\ntasklet_schedule(&dev->bh);\r\nreturn NETDEV_TX_OK;\r\n}\r\nint lan78xx_get_endpoints(struct lan78xx_net *dev, struct usb_interface *intf)\r\n{\r\nint tmp;\r\nstruct usb_host_interface *alt = NULL;\r\nstruct usb_host_endpoint *in = NULL, *out = NULL;\r\nstruct usb_host_endpoint *status = NULL;\r\nfor (tmp = 0; tmp < intf->num_altsetting; tmp++) {\r\nunsigned ep;\r\nin = NULL;\r\nout = NULL;\r\nstatus = NULL;\r\nalt = intf->altsetting + tmp;\r\nfor (ep = 0; ep < alt->desc.bNumEndpoints; ep++) {\r\nstruct usb_host_endpoint *e;\r\nint intr = 0;\r\ne = alt->endpoint + ep;\r\nswitch (e->desc.bmAttributes) {\r\ncase USB_ENDPOINT_XFER_INT:\r\nif (!usb_endpoint_dir_in(&e->desc))\r\ncontinue;\r\nintr = 1;\r\ncase USB_ENDPOINT_XFER_BULK:\r\nbreak;\r\ndefault:\r\ncontinue;\r\n}\r\nif (usb_endpoint_dir_in(&e->desc)) {\r\nif (!intr && !in)\r\nin = e;\r\nelse if (intr && !status)\r\nstatus = e;\r\n} else {\r\nif (!out)\r\nout = e;\r\n}\r\n}\r\nif (in && out)\r\nbreak;\r\n}\r\nif (!alt || !in || !out)\r\nreturn -EINVAL;\r\ndev->pipe_in = usb_rcvbulkpipe(dev->udev,\r\nin->desc.bEndpointAddress &\r\nUSB_ENDPOINT_NUMBER_MASK);\r\ndev->pipe_out = usb_sndbulkpipe(dev->udev,\r\nout->desc.bEndpointAddress &\r\nUSB_ENDPOINT_NUMBER_MASK);\r\ndev->ep_intr = status;\r\nreturn 0;\r\n}\r\nstatic int lan78xx_bind(struct lan78xx_net *dev, struct usb_interface *intf)\r\n{\r\nstruct lan78xx_priv *pdata = NULL;\r\nint ret;\r\nint i;\r\nret = lan78xx_get_endpoints(dev, intf);\r\ndev->data[0] = (unsigned long)kzalloc(sizeof(*pdata), GFP_KERNEL);\r\npdata = (struct lan78xx_priv *)(dev->data[0]);\r\nif (!pdata) {\r\nnetdev_warn(dev->net, "Unable to allocate lan78xx_priv");\r\nreturn -ENOMEM;\r\n}\r\npdata->dev = dev;\r\nspin_lock_init(&pdata->rfe_ctl_lock);\r\nmutex_init(&pdata->dataport_mutex);\r\nINIT_WORK(&pdata->set_multicast, lan78xx_deferred_multicast_write);\r\nfor (i = 0; i < DP_SEL_VHF_VLAN_LEN; i++)\r\npdata->vlan_table[i] = 0;\r\nINIT_WORK(&pdata->set_vlan, lan78xx_deferred_vlan_write);\r\ndev->net->features = 0;\r\nif (DEFAULT_TX_CSUM_ENABLE)\r\ndev->net->features |= NETIF_F_HW_CSUM;\r\nif (DEFAULT_RX_CSUM_ENABLE)\r\ndev->net->features |= NETIF_F_RXCSUM;\r\nif (DEFAULT_TSO_CSUM_ENABLE)\r\ndev->net->features |= NETIF_F_TSO | NETIF_F_TSO6 | NETIF_F_SG;\r\ndev->net->hw_features = dev->net->features;\r\nret = lan78xx_reset(dev);\r\nlan78xx_mdio_init(dev);\r\ndev->net->flags |= IFF_MULTICAST;\r\npdata->wol = WAKE_MAGIC;\r\nreturn 0;\r\n}\r\nstatic void lan78xx_unbind(struct lan78xx_net *dev, struct usb_interface *intf)\r\n{\r\nstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\r\nlan78xx_remove_mdio(dev);\r\nif (pdata) {\r\nnetif_dbg(dev, ifdown, dev->net, "free pdata");\r\nkfree(pdata);\r\npdata = NULL;\r\ndev->data[0] = 0;\r\n}\r\n}\r\nstatic void lan78xx_rx_csum_offload(struct lan78xx_net *dev,\r\nstruct sk_buff *skb,\r\nu32 rx_cmd_a, u32 rx_cmd_b)\r\n{\r\nif (!(dev->net->features & NETIF_F_RXCSUM) ||\r\nunlikely(rx_cmd_a & RX_CMD_A_ICSM_)) {\r\nskb->ip_summed = CHECKSUM_NONE;\r\n} else {\r\nskb->csum = ntohs((u16)(rx_cmd_b >> RX_CMD_B_CSUM_SHIFT_));\r\nskb->ip_summed = CHECKSUM_COMPLETE;\r\n}\r\n}\r\nvoid lan78xx_skb_return(struct lan78xx_net *dev, struct sk_buff *skb)\r\n{\r\nint status;\r\nif (test_bit(EVENT_RX_PAUSED, &dev->flags)) {\r\nskb_queue_tail(&dev->rxq_pause, skb);\r\nreturn;\r\n}\r\ndev->net->stats.rx_packets++;\r\ndev->net->stats.rx_bytes += skb->len;\r\nskb->protocol = eth_type_trans(skb, dev->net);\r\nnetif_dbg(dev, rx_status, dev->net, "< rx, len %zu, type 0x%x\n",\r\nskb->len + sizeof(struct ethhdr), skb->protocol);\r\nmemset(skb->cb, 0, sizeof(struct skb_data));\r\nif (skb_defer_rx_timestamp(skb))\r\nreturn;\r\nstatus = netif_rx(skb);\r\nif (status != NET_RX_SUCCESS)\r\nnetif_dbg(dev, rx_err, dev->net,\r\n"netif_rx status %d\n", status);\r\n}\r\nstatic int lan78xx_rx(struct lan78xx_net *dev, struct sk_buff *skb)\r\n{\r\nif (skb->len < dev->net->hard_header_len)\r\nreturn 0;\r\nwhile (skb->len > 0) {\r\nu32 rx_cmd_a, rx_cmd_b, align_count, size;\r\nu16 rx_cmd_c;\r\nstruct sk_buff *skb2;\r\nunsigned char *packet;\r\nmemcpy(&rx_cmd_a, skb->data, sizeof(rx_cmd_a));\r\nle32_to_cpus(&rx_cmd_a);\r\nskb_pull(skb, sizeof(rx_cmd_a));\r\nmemcpy(&rx_cmd_b, skb->data, sizeof(rx_cmd_b));\r\nle32_to_cpus(&rx_cmd_b);\r\nskb_pull(skb, sizeof(rx_cmd_b));\r\nmemcpy(&rx_cmd_c, skb->data, sizeof(rx_cmd_c));\r\nle16_to_cpus(&rx_cmd_c);\r\nskb_pull(skb, sizeof(rx_cmd_c));\r\npacket = skb->data;\r\nsize = (rx_cmd_a & RX_CMD_A_LEN_MASK_);\r\nalign_count = (4 - ((size + RXW_PADDING) % 4)) % 4;\r\nif (unlikely(rx_cmd_a & RX_CMD_A_RED_)) {\r\nnetif_dbg(dev, rx_err, dev->net,\r\n"Error rx_cmd_a=0x%08x", rx_cmd_a);\r\n} else {\r\nif (skb->len == size) {\r\nlan78xx_rx_csum_offload(dev, skb,\r\nrx_cmd_a, rx_cmd_b);\r\nskb_trim(skb, skb->len - 4);\r\nskb->truesize = size + sizeof(struct sk_buff);\r\nreturn 1;\r\n}\r\nskb2 = skb_clone(skb, GFP_ATOMIC);\r\nif (unlikely(!skb2)) {\r\nnetdev_warn(dev->net, "Error allocating skb");\r\nreturn 0;\r\n}\r\nskb2->len = size;\r\nskb2->data = packet;\r\nskb_set_tail_pointer(skb2, size);\r\nlan78xx_rx_csum_offload(dev, skb2, rx_cmd_a, rx_cmd_b);\r\nskb_trim(skb2, skb2->len - 4);\r\nskb2->truesize = size + sizeof(struct sk_buff);\r\nlan78xx_skb_return(dev, skb2);\r\n}\r\nskb_pull(skb, size);\r\nif (skb->len)\r\nskb_pull(skb, align_count);\r\n}\r\nreturn 1;\r\n}\r\nstatic inline void rx_process(struct lan78xx_net *dev, struct sk_buff *skb)\r\n{\r\nif (!lan78xx_rx(dev, skb)) {\r\ndev->net->stats.rx_errors++;\r\ngoto done;\r\n}\r\nif (skb->len) {\r\nlan78xx_skb_return(dev, skb);\r\nreturn;\r\n}\r\nnetif_dbg(dev, rx_err, dev->net, "drop\n");\r\ndev->net->stats.rx_errors++;\r\ndone:\r\nskb_queue_tail(&dev->done, skb);\r\n}\r\nstatic int rx_submit(struct lan78xx_net *dev, struct urb *urb, gfp_t flags)\r\n{\r\nstruct sk_buff *skb;\r\nstruct skb_data *entry;\r\nunsigned long lockflags;\r\nsize_t size = dev->rx_urb_size;\r\nint ret = 0;\r\nskb = netdev_alloc_skb_ip_align(dev->net, size);\r\nif (!skb) {\r\nusb_free_urb(urb);\r\nreturn -ENOMEM;\r\n}\r\nentry = (struct skb_data *)skb->cb;\r\nentry->urb = urb;\r\nentry->dev = dev;\r\nentry->length = 0;\r\nusb_fill_bulk_urb(urb, dev->udev, dev->pipe_in,\r\nskb->data, size, rx_complete, skb);\r\nspin_lock_irqsave(&dev->rxq.lock, lockflags);\r\nif (netif_device_present(dev->net) &&\r\nnetif_running(dev->net) &&\r\n!test_bit(EVENT_RX_HALT, &dev->flags) &&\r\n!test_bit(EVENT_DEV_ASLEEP, &dev->flags)) {\r\nret = usb_submit_urb(urb, GFP_ATOMIC);\r\nswitch (ret) {\r\ncase 0:\r\nlan78xx_queue_skb(&dev->rxq, skb, rx_start);\r\nbreak;\r\ncase -EPIPE:\r\nlan78xx_defer_kevent(dev, EVENT_RX_HALT);\r\nbreak;\r\ncase -ENODEV:\r\nnetif_dbg(dev, ifdown, dev->net, "device gone\n");\r\nnetif_device_detach(dev->net);\r\nbreak;\r\ncase -EHOSTUNREACH:\r\nret = -ENOLINK;\r\nbreak;\r\ndefault:\r\nnetif_dbg(dev, rx_err, dev->net,\r\n"rx submit, %d\n", ret);\r\ntasklet_schedule(&dev->bh);\r\n}\r\n} else {\r\nnetif_dbg(dev, ifdown, dev->net, "rx: stopped\n");\r\nret = -ENOLINK;\r\n}\r\nspin_unlock_irqrestore(&dev->rxq.lock, lockflags);\r\nif (ret) {\r\ndev_kfree_skb_any(skb);\r\nusb_free_urb(urb);\r\n}\r\nreturn ret;\r\n}\r\nstatic void rx_complete(struct urb *urb)\r\n{\r\nstruct sk_buff *skb = (struct sk_buff *)urb->context;\r\nstruct skb_data *entry = (struct skb_data *)skb->cb;\r\nstruct lan78xx_net *dev = entry->dev;\r\nint urb_status = urb->status;\r\nenum skb_state state;\r\nskb_put(skb, urb->actual_length);\r\nstate = rx_done;\r\nentry->urb = NULL;\r\nswitch (urb_status) {\r\ncase 0:\r\nif (skb->len < dev->net->hard_header_len) {\r\nstate = rx_cleanup;\r\ndev->net->stats.rx_errors++;\r\ndev->net->stats.rx_length_errors++;\r\nnetif_dbg(dev, rx_err, dev->net,\r\n"rx length %d\n", skb->len);\r\n}\r\nusb_mark_last_busy(dev->udev);\r\nbreak;\r\ncase -EPIPE:\r\ndev->net->stats.rx_errors++;\r\nlan78xx_defer_kevent(dev, EVENT_RX_HALT);\r\ncase -ECONNRESET:\r\ncase -ESHUTDOWN:\r\nnetif_dbg(dev, ifdown, dev->net,\r\n"rx shutdown, code %d\n", urb_status);\r\nstate = rx_cleanup;\r\nentry->urb = urb;\r\nurb = NULL;\r\nbreak;\r\ncase -EPROTO:\r\ncase -ETIME:\r\ncase -EILSEQ:\r\ndev->net->stats.rx_errors++;\r\nstate = rx_cleanup;\r\nentry->urb = urb;\r\nurb = NULL;\r\nbreak;\r\ncase -EOVERFLOW:\r\ndev->net->stats.rx_over_errors++;\r\ndefault:\r\nstate = rx_cleanup;\r\ndev->net->stats.rx_errors++;\r\nnetif_dbg(dev, rx_err, dev->net, "rx status %d\n", urb_status);\r\nbreak;\r\n}\r\nstate = defer_bh(dev, skb, &dev->rxq, state);\r\nif (urb) {\r\nif (netif_running(dev->net) &&\r\n!test_bit(EVENT_RX_HALT, &dev->flags) &&\r\nstate != unlink_start) {\r\nrx_submit(dev, urb, GFP_ATOMIC);\r\nreturn;\r\n}\r\nusb_free_urb(urb);\r\n}\r\nnetif_dbg(dev, rx_err, dev->net, "no read resubmitted\n");\r\n}\r\nstatic void lan78xx_tx_bh(struct lan78xx_net *dev)\r\n{\r\nint length;\r\nstruct urb *urb = NULL;\r\nstruct skb_data *entry;\r\nunsigned long flags;\r\nstruct sk_buff_head *tqp = &dev->txq_pend;\r\nstruct sk_buff *skb, *skb2;\r\nint ret;\r\nint count, pos;\r\nint skb_totallen, pkt_cnt;\r\nskb_totallen = 0;\r\npkt_cnt = 0;\r\ncount = 0;\r\nlength = 0;\r\nfor (skb = tqp->next; pkt_cnt < tqp->qlen; skb = skb->next) {\r\nif (skb_is_gso(skb)) {\r\nif (pkt_cnt) {\r\nbreak;\r\n}\r\ncount = 1;\r\nlength = skb->len - TX_OVERHEAD;\r\nskb2 = skb_dequeue(tqp);\r\ngoto gso_skb;\r\n}\r\nif ((skb_totallen + skb->len) > MAX_SINGLE_PACKET_SIZE)\r\nbreak;\r\nskb_totallen = skb->len + roundup(skb_totallen, sizeof(u32));\r\npkt_cnt++;\r\n}\r\nskb = alloc_skb(skb_totallen, GFP_ATOMIC);\r\nif (!skb)\r\ngoto drop;\r\nskb_put(skb, skb_totallen);\r\nfor (count = pos = 0; count < pkt_cnt; count++) {\r\nskb2 = skb_dequeue(tqp);\r\nif (skb2) {\r\nlength += (skb2->len - TX_OVERHEAD);\r\nmemcpy(skb->data + pos, skb2->data, skb2->len);\r\npos += roundup(skb2->len, sizeof(u32));\r\ndev_kfree_skb(skb2);\r\n}\r\n}\r\ngso_skb:\r\nurb = usb_alloc_urb(0, GFP_ATOMIC);\r\nif (!urb) {\r\nnetif_dbg(dev, tx_err, dev->net, "no urb\n");\r\ngoto drop;\r\n}\r\nentry = (struct skb_data *)skb->cb;\r\nentry->urb = urb;\r\nentry->dev = dev;\r\nentry->length = length;\r\nentry->num_of_packet = count;\r\nspin_lock_irqsave(&dev->txq.lock, flags);\r\nret = usb_autopm_get_interface_async(dev->intf);\r\nif (ret < 0) {\r\nspin_unlock_irqrestore(&dev->txq.lock, flags);\r\ngoto drop;\r\n}\r\nusb_fill_bulk_urb(urb, dev->udev, dev->pipe_out,\r\nskb->data, skb->len, tx_complete, skb);\r\nif (length % dev->maxpacket == 0) {\r\nurb->transfer_flags |= URB_ZERO_PACKET;\r\n}\r\n#ifdef CONFIG_PM\r\nif (test_bit(EVENT_DEV_ASLEEP, &dev->flags)) {\r\nusb_anchor_urb(urb, &dev->deferred);\r\nnetif_stop_queue(dev->net);\r\nusb_put_urb(urb);\r\nspin_unlock_irqrestore(&dev->txq.lock, flags);\r\nnetdev_dbg(dev->net, "Delaying transmission for resumption\n");\r\nreturn;\r\n}\r\n#endif\r\nret = usb_submit_urb(urb, GFP_ATOMIC);\r\nswitch (ret) {\r\ncase 0:\r\nnetif_trans_update(dev->net);\r\nlan78xx_queue_skb(&dev->txq, skb, tx_start);\r\nif (skb_queue_len(&dev->txq) >= dev->tx_qlen)\r\nnetif_stop_queue(dev->net);\r\nbreak;\r\ncase -EPIPE:\r\nnetif_stop_queue(dev->net);\r\nlan78xx_defer_kevent(dev, EVENT_TX_HALT);\r\nusb_autopm_put_interface_async(dev->intf);\r\nbreak;\r\ndefault:\r\nusb_autopm_put_interface_async(dev->intf);\r\nnetif_dbg(dev, tx_err, dev->net,\r\n"tx: submit urb err %d\n", ret);\r\nbreak;\r\n}\r\nspin_unlock_irqrestore(&dev->txq.lock, flags);\r\nif (ret) {\r\nnetif_dbg(dev, tx_err, dev->net, "drop, code %d\n", ret);\r\ndrop:\r\ndev->net->stats.tx_dropped++;\r\nif (skb)\r\ndev_kfree_skb_any(skb);\r\nusb_free_urb(urb);\r\n} else\r\nnetif_dbg(dev, tx_queued, dev->net,\r\n"> tx, len %d, type 0x%x\n", length, skb->protocol);\r\n}\r\nstatic void lan78xx_rx_bh(struct lan78xx_net *dev)\r\n{\r\nstruct urb *urb;\r\nint i;\r\nif (skb_queue_len(&dev->rxq) < dev->rx_qlen) {\r\nfor (i = 0; i < 10; i++) {\r\nif (skb_queue_len(&dev->rxq) >= dev->rx_qlen)\r\nbreak;\r\nurb = usb_alloc_urb(0, GFP_ATOMIC);\r\nif (urb)\r\nif (rx_submit(dev, urb, GFP_ATOMIC) == -ENOLINK)\r\nreturn;\r\n}\r\nif (skb_queue_len(&dev->rxq) < dev->rx_qlen)\r\ntasklet_schedule(&dev->bh);\r\n}\r\nif (skb_queue_len(&dev->txq) < dev->tx_qlen)\r\nnetif_wake_queue(dev->net);\r\n}\r\nstatic void lan78xx_bh(unsigned long param)\r\n{\r\nstruct lan78xx_net *dev = (struct lan78xx_net *)param;\r\nstruct sk_buff *skb;\r\nstruct skb_data *entry;\r\nwhile ((skb = skb_dequeue(&dev->done))) {\r\nentry = (struct skb_data *)(skb->cb);\r\nswitch (entry->state) {\r\ncase rx_done:\r\nentry->state = rx_cleanup;\r\nrx_process(dev, skb);\r\ncontinue;\r\ncase tx_done:\r\nusb_free_urb(entry->urb);\r\ndev_kfree_skb(skb);\r\ncontinue;\r\ncase rx_cleanup:\r\nusb_free_urb(entry->urb);\r\ndev_kfree_skb(skb);\r\ncontinue;\r\ndefault:\r\nnetdev_dbg(dev->net, "skb state %d\n", entry->state);\r\nreturn;\r\n}\r\n}\r\nif (netif_device_present(dev->net) && netif_running(dev->net)) {\r\nif (timer_pending(&dev->stat_monitor) && (dev->delta != 1)) {\r\ndev->delta = 1;\r\nmod_timer(&dev->stat_monitor,\r\njiffies + STAT_UPDATE_TIMER);\r\n}\r\nif (!skb_queue_empty(&dev->txq_pend))\r\nlan78xx_tx_bh(dev);\r\nif (!timer_pending(&dev->delay) &&\r\n!test_bit(EVENT_RX_HALT, &dev->flags))\r\nlan78xx_rx_bh(dev);\r\n}\r\n}\r\nstatic void lan78xx_delayedwork(struct work_struct *work)\r\n{\r\nint status;\r\nstruct lan78xx_net *dev;\r\ndev = container_of(work, struct lan78xx_net, wq.work);\r\nif (test_bit(EVENT_TX_HALT, &dev->flags)) {\r\nunlink_urbs(dev, &dev->txq);\r\nstatus = usb_autopm_get_interface(dev->intf);\r\nif (status < 0)\r\ngoto fail_pipe;\r\nstatus = usb_clear_halt(dev->udev, dev->pipe_out);\r\nusb_autopm_put_interface(dev->intf);\r\nif (status < 0 &&\r\nstatus != -EPIPE &&\r\nstatus != -ESHUTDOWN) {\r\nif (netif_msg_tx_err(dev))\r\nfail_pipe:\r\nnetdev_err(dev->net,\r\n"can't clear tx halt, status %d\n",\r\nstatus);\r\n} else {\r\nclear_bit(EVENT_TX_HALT, &dev->flags);\r\nif (status != -ESHUTDOWN)\r\nnetif_wake_queue(dev->net);\r\n}\r\n}\r\nif (test_bit(EVENT_RX_HALT, &dev->flags)) {\r\nunlink_urbs(dev, &dev->rxq);\r\nstatus = usb_autopm_get_interface(dev->intf);\r\nif (status < 0)\r\ngoto fail_halt;\r\nstatus = usb_clear_halt(dev->udev, dev->pipe_in);\r\nusb_autopm_put_interface(dev->intf);\r\nif (status < 0 &&\r\nstatus != -EPIPE &&\r\nstatus != -ESHUTDOWN) {\r\nif (netif_msg_rx_err(dev))\r\nfail_halt:\r\nnetdev_err(dev->net,\r\n"can't clear rx halt, status %d\n",\r\nstatus);\r\n} else {\r\nclear_bit(EVENT_RX_HALT, &dev->flags);\r\ntasklet_schedule(&dev->bh);\r\n}\r\n}\r\nif (test_bit(EVENT_LINK_RESET, &dev->flags)) {\r\nint ret = 0;\r\nclear_bit(EVENT_LINK_RESET, &dev->flags);\r\nstatus = usb_autopm_get_interface(dev->intf);\r\nif (status < 0)\r\ngoto skip_reset;\r\nif (lan78xx_link_reset(dev) < 0) {\r\nusb_autopm_put_interface(dev->intf);\r\nskip_reset:\r\nnetdev_info(dev->net, "link reset failed (%d)\n",\r\nret);\r\n} else {\r\nusb_autopm_put_interface(dev->intf);\r\n}\r\n}\r\nif (test_bit(EVENT_STAT_UPDATE, &dev->flags)) {\r\nlan78xx_update_stats(dev);\r\nclear_bit(EVENT_STAT_UPDATE, &dev->flags);\r\nmod_timer(&dev->stat_monitor,\r\njiffies + (STAT_UPDATE_TIMER * dev->delta));\r\ndev->delta = min((dev->delta * 2), 50);\r\n}\r\n}\r\nstatic void intr_complete(struct urb *urb)\r\n{\r\nstruct lan78xx_net *dev = urb->context;\r\nint status = urb->status;\r\nswitch (status) {\r\ncase 0:\r\nlan78xx_status(dev, urb);\r\nbreak;\r\ncase -ENOENT:\r\ncase -ESHUTDOWN:\r\nnetif_dbg(dev, ifdown, dev->net,\r\n"intr shutdown, code %d\n", status);\r\nreturn;\r\ndefault:\r\nnetdev_dbg(dev->net, "intr status %d\n", status);\r\nbreak;\r\n}\r\nif (!netif_running(dev->net))\r\nreturn;\r\nmemset(urb->transfer_buffer, 0, urb->transfer_buffer_length);\r\nstatus = usb_submit_urb(urb, GFP_ATOMIC);\r\nif (status != 0)\r\nnetif_err(dev, timer, dev->net,\r\n"intr resubmit --> %d\n", status);\r\n}\r\nstatic void lan78xx_disconnect(struct usb_interface *intf)\r\n{\r\nstruct lan78xx_net *dev;\r\nstruct usb_device *udev;\r\nstruct net_device *net;\r\ndev = usb_get_intfdata(intf);\r\nusb_set_intfdata(intf, NULL);\r\nif (!dev)\r\nreturn;\r\nudev = interface_to_usbdev(intf);\r\nnet = dev->net;\r\nunregister_netdev(net);\r\ncancel_delayed_work_sync(&dev->wq);\r\nusb_scuttle_anchored_urbs(&dev->deferred);\r\nlan78xx_unbind(dev, intf);\r\nusb_kill_urb(dev->urb_intr);\r\nusb_free_urb(dev->urb_intr);\r\nfree_netdev(net);\r\nusb_put_dev(udev);\r\n}\r\nvoid lan78xx_tx_timeout(struct net_device *net)\r\n{\r\nstruct lan78xx_net *dev = netdev_priv(net);\r\nunlink_urbs(dev, &dev->txq);\r\ntasklet_schedule(&dev->bh);\r\n}\r\nstatic void lan78xx_stat_monitor(unsigned long param)\r\n{\r\nstruct lan78xx_net *dev;\r\ndev = (struct lan78xx_net *)param;\r\nlan78xx_defer_kevent(dev, EVENT_STAT_UPDATE);\r\n}\r\nstatic int lan78xx_probe(struct usb_interface *intf,\r\nconst struct usb_device_id *id)\r\n{\r\nstruct lan78xx_net *dev;\r\nstruct net_device *netdev;\r\nstruct usb_device *udev;\r\nint ret;\r\nunsigned maxp;\r\nunsigned period;\r\nu8 *buf = NULL;\r\nudev = interface_to_usbdev(intf);\r\nudev = usb_get_dev(udev);\r\nret = -ENOMEM;\r\nnetdev = alloc_etherdev(sizeof(struct lan78xx_net));\r\nif (!netdev) {\r\ndev_err(&intf->dev, "Error: OOM\n");\r\ngoto out1;\r\n}\r\nSET_NETDEV_DEV(netdev, &intf->dev);\r\ndev = netdev_priv(netdev);\r\ndev->udev = udev;\r\ndev->intf = intf;\r\ndev->net = netdev;\r\ndev->msg_enable = netif_msg_init(msg_level, NETIF_MSG_DRV\r\n| NETIF_MSG_PROBE | NETIF_MSG_LINK);\r\nskb_queue_head_init(&dev->rxq);\r\nskb_queue_head_init(&dev->txq);\r\nskb_queue_head_init(&dev->done);\r\nskb_queue_head_init(&dev->rxq_pause);\r\nskb_queue_head_init(&dev->txq_pend);\r\nmutex_init(&dev->phy_mutex);\r\ntasklet_init(&dev->bh, lan78xx_bh, (unsigned long)dev);\r\nINIT_DELAYED_WORK(&dev->wq, lan78xx_delayedwork);\r\ninit_usb_anchor(&dev->deferred);\r\nnetdev->netdev_ops = &lan78xx_netdev_ops;\r\nnetdev->watchdog_timeo = TX_TIMEOUT_JIFFIES;\r\nnetdev->ethtool_ops = &lan78xx_ethtool_ops;\r\ndev->stat_monitor.function = lan78xx_stat_monitor;\r\ndev->stat_monitor.data = (unsigned long)dev;\r\ndev->delta = 1;\r\ninit_timer(&dev->stat_monitor);\r\nmutex_init(&dev->stats.access_lock);\r\nret = lan78xx_bind(dev, intf);\r\nif (ret < 0)\r\ngoto out2;\r\nstrcpy(netdev->name, "eth%d");\r\nif (netdev->mtu > (dev->hard_mtu - netdev->hard_header_len))\r\nnetdev->mtu = dev->hard_mtu - netdev->hard_header_len;\r\ndev->ep_blkin = (intf->cur_altsetting)->endpoint + 0;\r\ndev->ep_blkout = (intf->cur_altsetting)->endpoint + 1;\r\ndev->ep_intr = (intf->cur_altsetting)->endpoint + 2;\r\ndev->pipe_in = usb_rcvbulkpipe(udev, BULK_IN_PIPE);\r\ndev->pipe_out = usb_sndbulkpipe(udev, BULK_OUT_PIPE);\r\ndev->pipe_intr = usb_rcvintpipe(dev->udev,\r\ndev->ep_intr->desc.bEndpointAddress &\r\nUSB_ENDPOINT_NUMBER_MASK);\r\nperiod = dev->ep_intr->desc.bInterval;\r\nmaxp = usb_maxpacket(dev->udev, dev->pipe_intr, 0);\r\nbuf = kmalloc(maxp, GFP_KERNEL);\r\nif (buf) {\r\ndev->urb_intr = usb_alloc_urb(0, GFP_KERNEL);\r\nif (!dev->urb_intr) {\r\nkfree(buf);\r\ngoto out3;\r\n} else {\r\nusb_fill_int_urb(dev->urb_intr, dev->udev,\r\ndev->pipe_intr, buf, maxp,\r\nintr_complete, dev, period);\r\n}\r\n}\r\ndev->maxpacket = usb_maxpacket(dev->udev, dev->pipe_out, 1);\r\nintf->needs_remote_wakeup = 1;\r\nret = register_netdev(netdev);\r\nif (ret != 0) {\r\nnetif_err(dev, probe, netdev, "couldn't register the device\n");\r\ngoto out2;\r\n}\r\nusb_set_intfdata(intf, dev);\r\nret = device_set_wakeup_enable(&udev->dev, true);\r\npm_runtime_set_autosuspend_delay(&udev->dev,\r\nDEFAULT_AUTOSUSPEND_DELAY);\r\nreturn 0;\r\nout3:\r\nlan78xx_unbind(dev, intf);\r\nout2:\r\nfree_netdev(netdev);\r\nout1:\r\nusb_put_dev(udev);\r\nreturn ret;\r\n}\r\nstatic u16 lan78xx_wakeframe_crc16(const u8 *buf, int len)\r\n{\r\nconst u16 crc16poly = 0x8005;\r\nint i;\r\nu16 bit, crc, msb;\r\nu8 data;\r\ncrc = 0xFFFF;\r\nfor (i = 0; i < len; i++) {\r\ndata = *buf++;\r\nfor (bit = 0; bit < 8; bit++) {\r\nmsb = crc >> 15;\r\ncrc <<= 1;\r\nif (msb ^ (u16)(data & 1)) {\r\ncrc ^= crc16poly;\r\ncrc |= (u16)0x0001U;\r\n}\r\ndata >>= 1;\r\n}\r\n}\r\nreturn crc;\r\n}\r\nstatic int lan78xx_set_suspend(struct lan78xx_net *dev, u32 wol)\r\n{\r\nu32 buf;\r\nint ret;\r\nint mask_index;\r\nu16 crc;\r\nu32 temp_wucsr;\r\nu32 temp_pmt_ctl;\r\nconst u8 ipv4_multicast[3] = { 0x01, 0x00, 0x5E };\r\nconst u8 ipv6_multicast[3] = { 0x33, 0x33 };\r\nconst u8 arp_type[2] = { 0x08, 0x06 };\r\nret = lan78xx_read_reg(dev, MAC_TX, &buf);\r\nbuf &= ~MAC_TX_TXEN_;\r\nret = lan78xx_write_reg(dev, MAC_TX, buf);\r\nret = lan78xx_read_reg(dev, MAC_RX, &buf);\r\nbuf &= ~MAC_RX_RXEN_;\r\nret = lan78xx_write_reg(dev, MAC_RX, buf);\r\nret = lan78xx_write_reg(dev, WUCSR, 0);\r\nret = lan78xx_write_reg(dev, WUCSR2, 0);\r\nret = lan78xx_write_reg(dev, WK_SRC, 0xFFF1FF1FUL);\r\ntemp_wucsr = 0;\r\ntemp_pmt_ctl = 0;\r\nret = lan78xx_read_reg(dev, PMT_CTL, &temp_pmt_ctl);\r\ntemp_pmt_ctl &= ~PMT_CTL_RES_CLR_WKP_EN_;\r\ntemp_pmt_ctl |= PMT_CTL_RES_CLR_WKP_STS_;\r\nfor (mask_index = 0; mask_index < NUM_OF_WUF_CFG; mask_index++)\r\nret = lan78xx_write_reg(dev, WUF_CFG(mask_index), 0);\r\nmask_index = 0;\r\nif (wol & WAKE_PHY) {\r\ntemp_pmt_ctl |= PMT_CTL_PHY_WAKE_EN_;\r\ntemp_pmt_ctl |= PMT_CTL_WOL_EN_;\r\ntemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\r\ntemp_pmt_ctl |= PMT_CTL_SUS_MODE_0_;\r\n}\r\nif (wol & WAKE_MAGIC) {\r\ntemp_wucsr |= WUCSR_MPEN_;\r\ntemp_pmt_ctl |= PMT_CTL_WOL_EN_;\r\ntemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\r\ntemp_pmt_ctl |= PMT_CTL_SUS_MODE_3_;\r\n}\r\nif (wol & WAKE_BCAST) {\r\ntemp_wucsr |= WUCSR_BCST_EN_;\r\ntemp_pmt_ctl |= PMT_CTL_WOL_EN_;\r\ntemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\r\ntemp_pmt_ctl |= PMT_CTL_SUS_MODE_0_;\r\n}\r\nif (wol & WAKE_MCAST) {\r\ntemp_wucsr |= WUCSR_WAKE_EN_;\r\ncrc = lan78xx_wakeframe_crc16(ipv4_multicast, 3);\r\nret = lan78xx_write_reg(dev, WUF_CFG(mask_index),\r\nWUF_CFGX_EN_ |\r\nWUF_CFGX_TYPE_MCAST_ |\r\n(0 << WUF_CFGX_OFFSET_SHIFT_) |\r\n(crc & WUF_CFGX_CRC16_MASK_));\r\nret = lan78xx_write_reg(dev, WUF_MASK0(mask_index), 7);\r\nret = lan78xx_write_reg(dev, WUF_MASK1(mask_index), 0);\r\nret = lan78xx_write_reg(dev, WUF_MASK2(mask_index), 0);\r\nret = lan78xx_write_reg(dev, WUF_MASK3(mask_index), 0);\r\nmask_index++;\r\ncrc = lan78xx_wakeframe_crc16(ipv6_multicast, 2);\r\nret = lan78xx_write_reg(dev, WUF_CFG(mask_index),\r\nWUF_CFGX_EN_ |\r\nWUF_CFGX_TYPE_MCAST_ |\r\n(0 << WUF_CFGX_OFFSET_SHIFT_) |\r\n(crc & WUF_CFGX_CRC16_MASK_));\r\nret = lan78xx_write_reg(dev, WUF_MASK0(mask_index), 3);\r\nret = lan78xx_write_reg(dev, WUF_MASK1(mask_index), 0);\r\nret = lan78xx_write_reg(dev, WUF_MASK2(mask_index), 0);\r\nret = lan78xx_write_reg(dev, WUF_MASK3(mask_index), 0);\r\nmask_index++;\r\ntemp_pmt_ctl |= PMT_CTL_WOL_EN_;\r\ntemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\r\ntemp_pmt_ctl |= PMT_CTL_SUS_MODE_0_;\r\n}\r\nif (wol & WAKE_UCAST) {\r\ntemp_wucsr |= WUCSR_PFDA_EN_;\r\ntemp_pmt_ctl |= PMT_CTL_WOL_EN_;\r\ntemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\r\ntemp_pmt_ctl |= PMT_CTL_SUS_MODE_0_;\r\n}\r\nif (wol & WAKE_ARP) {\r\ntemp_wucsr |= WUCSR_WAKE_EN_;\r\ncrc = lan78xx_wakeframe_crc16(arp_type, 2);\r\nret = lan78xx_write_reg(dev, WUF_CFG(mask_index),\r\nWUF_CFGX_EN_ |\r\nWUF_CFGX_TYPE_ALL_ |\r\n(0 << WUF_CFGX_OFFSET_SHIFT_) |\r\n(crc & WUF_CFGX_CRC16_MASK_));\r\nret = lan78xx_write_reg(dev, WUF_MASK0(mask_index), 0x3000);\r\nret = lan78xx_write_reg(dev, WUF_MASK1(mask_index), 0);\r\nret = lan78xx_write_reg(dev, WUF_MASK2(mask_index), 0);\r\nret = lan78xx_write_reg(dev, WUF_MASK3(mask_index), 0);\r\nmask_index++;\r\ntemp_pmt_ctl |= PMT_CTL_WOL_EN_;\r\ntemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\r\ntemp_pmt_ctl |= PMT_CTL_SUS_MODE_0_;\r\n}\r\nret = lan78xx_write_reg(dev, WUCSR, temp_wucsr);\r\nif (hweight_long((unsigned long)wol) > 1) {\r\ntemp_pmt_ctl |= PMT_CTL_WOL_EN_;\r\ntemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\r\ntemp_pmt_ctl |= PMT_CTL_SUS_MODE_0_;\r\n}\r\nret = lan78xx_write_reg(dev, PMT_CTL, temp_pmt_ctl);\r\nret = lan78xx_read_reg(dev, PMT_CTL, &buf);\r\nbuf |= PMT_CTL_WUPS_MASK_;\r\nret = lan78xx_write_reg(dev, PMT_CTL, buf);\r\nret = lan78xx_read_reg(dev, MAC_RX, &buf);\r\nbuf |= MAC_RX_RXEN_;\r\nret = lan78xx_write_reg(dev, MAC_RX, buf);\r\nreturn 0;\r\n}\r\nint lan78xx_suspend(struct usb_interface *intf, pm_message_t message)\r\n{\r\nstruct lan78xx_net *dev = usb_get_intfdata(intf);\r\nstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\r\nu32 buf;\r\nint ret;\r\nint event;\r\nevent = message.event;\r\nif (!dev->suspend_count++) {\r\nspin_lock_irq(&dev->txq.lock);\r\nif ((skb_queue_len(&dev->txq) ||\r\nskb_queue_len(&dev->txq_pend)) &&\r\nPMSG_IS_AUTO(message)) {\r\nspin_unlock_irq(&dev->txq.lock);\r\nret = -EBUSY;\r\ngoto out;\r\n} else {\r\nset_bit(EVENT_DEV_ASLEEP, &dev->flags);\r\nspin_unlock_irq(&dev->txq.lock);\r\n}\r\nret = lan78xx_read_reg(dev, MAC_TX, &buf);\r\nbuf &= ~MAC_TX_TXEN_;\r\nret = lan78xx_write_reg(dev, MAC_TX, buf);\r\nret = lan78xx_read_reg(dev, MAC_RX, &buf);\r\nbuf &= ~MAC_RX_RXEN_;\r\nret = lan78xx_write_reg(dev, MAC_RX, buf);\r\nnetif_device_detach(dev->net);\r\nlan78xx_terminate_urbs(dev);\r\nusb_kill_urb(dev->urb_intr);\r\nnetif_device_attach(dev->net);\r\n}\r\nif (test_bit(EVENT_DEV_ASLEEP, &dev->flags)) {\r\ndel_timer(&dev->stat_monitor);\r\nif (PMSG_IS_AUTO(message)) {\r\nret = lan78xx_read_reg(dev, MAC_TX, &buf);\r\nbuf &= ~MAC_TX_TXEN_;\r\nret = lan78xx_write_reg(dev, MAC_TX, buf);\r\nret = lan78xx_read_reg(dev, MAC_RX, &buf);\r\nbuf &= ~MAC_RX_RXEN_;\r\nret = lan78xx_write_reg(dev, MAC_RX, buf);\r\nret = lan78xx_write_reg(dev, WUCSR, 0);\r\nret = lan78xx_write_reg(dev, WUCSR2, 0);\r\nret = lan78xx_write_reg(dev, WK_SRC, 0xFFF1FF1FUL);\r\nret = lan78xx_read_reg(dev, WUCSR, &buf);\r\nbuf |= WUCSR_RFE_WAKE_EN_;\r\nbuf |= WUCSR_STORE_WAKE_;\r\nret = lan78xx_write_reg(dev, WUCSR, buf);\r\nret = lan78xx_read_reg(dev, PMT_CTL, &buf);\r\nbuf &= ~PMT_CTL_RES_CLR_WKP_EN_;\r\nbuf |= PMT_CTL_RES_CLR_WKP_STS_;\r\nbuf |= PMT_CTL_PHY_WAKE_EN_;\r\nbuf |= PMT_CTL_WOL_EN_;\r\nbuf &= ~PMT_CTL_SUS_MODE_MASK_;\r\nbuf |= PMT_CTL_SUS_MODE_3_;\r\nret = lan78xx_write_reg(dev, PMT_CTL, buf);\r\nret = lan78xx_read_reg(dev, PMT_CTL, &buf);\r\nbuf |= PMT_CTL_WUPS_MASK_;\r\nret = lan78xx_write_reg(dev, PMT_CTL, buf);\r\nret = lan78xx_read_reg(dev, MAC_RX, &buf);\r\nbuf |= MAC_RX_RXEN_;\r\nret = lan78xx_write_reg(dev, MAC_RX, buf);\r\n} else {\r\nlan78xx_set_suspend(dev, pdata->wol);\r\n}\r\n}\r\nret = 0;\r\nout:\r\nreturn ret;\r\n}\r\nint lan78xx_resume(struct usb_interface *intf)\r\n{\r\nstruct lan78xx_net *dev = usb_get_intfdata(intf);\r\nstruct sk_buff *skb;\r\nstruct urb *res;\r\nint ret;\r\nu32 buf;\r\nif (!timer_pending(&dev->stat_monitor)) {\r\ndev->delta = 1;\r\nmod_timer(&dev->stat_monitor,\r\njiffies + STAT_UPDATE_TIMER);\r\n}\r\nif (!--dev->suspend_count) {\r\nif (dev->urb_intr && test_bit(EVENT_DEV_OPEN, &dev->flags))\r\nusb_submit_urb(dev->urb_intr, GFP_NOIO);\r\nspin_lock_irq(&dev->txq.lock);\r\nwhile ((res = usb_get_from_anchor(&dev->deferred))) {\r\nskb = (struct sk_buff *)res->context;\r\nret = usb_submit_urb(res, GFP_ATOMIC);\r\nif (ret < 0) {\r\ndev_kfree_skb_any(skb);\r\nusb_free_urb(res);\r\nusb_autopm_put_interface_async(dev->intf);\r\n} else {\r\nnetif_trans_update(dev->net);\r\nlan78xx_queue_skb(&dev->txq, skb, tx_start);\r\n}\r\n}\r\nclear_bit(EVENT_DEV_ASLEEP, &dev->flags);\r\nspin_unlock_irq(&dev->txq.lock);\r\nif (test_bit(EVENT_DEV_OPEN, &dev->flags)) {\r\nif (!(skb_queue_len(&dev->txq) >= dev->tx_qlen))\r\nnetif_start_queue(dev->net);\r\ntasklet_schedule(&dev->bh);\r\n}\r\n}\r\nret = lan78xx_write_reg(dev, WUCSR2, 0);\r\nret = lan78xx_write_reg(dev, WUCSR, 0);\r\nret = lan78xx_write_reg(dev, WK_SRC, 0xFFF1FF1FUL);\r\nret = lan78xx_write_reg(dev, WUCSR2, WUCSR2_NS_RCD_ |\r\nWUCSR2_ARP_RCD_ |\r\nWUCSR2_IPV6_TCPSYN_RCD_ |\r\nWUCSR2_IPV4_TCPSYN_RCD_);\r\nret = lan78xx_write_reg(dev, WUCSR, WUCSR_EEE_TX_WAKE_ |\r\nWUCSR_EEE_RX_WAKE_ |\r\nWUCSR_PFDA_FR_ |\r\nWUCSR_RFE_WAKE_FR_ |\r\nWUCSR_WUFR_ |\r\nWUCSR_MPR_ |\r\nWUCSR_BCST_FR_);\r\nret = lan78xx_read_reg(dev, MAC_TX, &buf);\r\nbuf |= MAC_TX_TXEN_;\r\nret = lan78xx_write_reg(dev, MAC_TX, buf);\r\nreturn 0;\r\n}\r\nint lan78xx_reset_resume(struct usb_interface *intf)\r\n{\r\nstruct lan78xx_net *dev = usb_get_intfdata(intf);\r\nlan78xx_reset(dev);\r\nlan78xx_phy_init(dev);\r\nreturn lan78xx_resume(intf);\r\n}
