static int enh_desc_get_tx_status(void *data, struct stmmac_extra_stats *x,\r\nstruct dma_desc *p, void __iomem *ioaddr)\r\n{\r\nstruct net_device_stats *stats = (struct net_device_stats *)data;\r\nunsigned int tdes0 = p->des0;\r\nint ret = tx_done;\r\nif (unlikely(tdes0 & ETDES0_OWN))\r\nreturn tx_dma_own;\r\nif (likely(!(tdes0 & ETDES0_LAST_SEGMENT)))\r\nreturn tx_not_ls;\r\nif (unlikely(tdes0 & ETDES0_ERROR_SUMMARY)) {\r\nif (unlikely(tdes0 & ETDES0_JABBER_TIMEOUT))\r\nx->tx_jabber++;\r\nif (unlikely(tdes0 & ETDES0_FRAME_FLUSHED)) {\r\nx->tx_frame_flushed++;\r\ndwmac_dma_flush_tx_fifo(ioaddr);\r\n}\r\nif (unlikely(tdes0 & ETDES0_LOSS_CARRIER)) {\r\nx->tx_losscarrier++;\r\nstats->tx_carrier_errors++;\r\n}\r\nif (unlikely(tdes0 & ETDES0_NO_CARRIER)) {\r\nx->tx_carrier++;\r\nstats->tx_carrier_errors++;\r\n}\r\nif (unlikely((tdes0 & ETDES0_LATE_COLLISION) ||\r\n(tdes0 & ETDES0_EXCESSIVE_COLLISIONS)))\r\nstats->collisions +=\r\n(tdes0 & ETDES0_COLLISION_COUNT_MASK) >> 3;\r\nif (unlikely(tdes0 & ETDES0_EXCESSIVE_DEFERRAL))\r\nx->tx_deferred++;\r\nif (unlikely(tdes0 & ETDES0_UNDERFLOW_ERROR)) {\r\ndwmac_dma_flush_tx_fifo(ioaddr);\r\nx->tx_underflow++;\r\n}\r\nif (unlikely(tdes0 & ETDES0_IP_HEADER_ERROR))\r\nx->tx_ip_header_error++;\r\nif (unlikely(tdes0 & ETDES0_PAYLOAD_ERROR)) {\r\nx->tx_payload_error++;\r\ndwmac_dma_flush_tx_fifo(ioaddr);\r\n}\r\nret = tx_err;\r\n}\r\nif (unlikely(tdes0 & ETDES0_DEFERRED))\r\nx->tx_deferred++;\r\n#ifdef STMMAC_VLAN_TAG_USED\r\nif (tdes0 & ETDES0_VLAN_FRAME)\r\nx->tx_vlan++;\r\n#endif\r\nreturn ret;\r\n}\r\nstatic int enh_desc_get_tx_len(struct dma_desc *p)\r\n{\r\nreturn (p->des1 & ETDES1_BUFFER1_SIZE_MASK);\r\n}\r\nstatic int enh_desc_coe_rdes0(int ipc_err, int type, int payload_err)\r\n{\r\nint ret = good_frame;\r\nu32 status = (type << 2 | ipc_err << 1 | payload_err) & 0x7;\r\nif (status == 0x0)\r\nret = llc_snap;\r\nelse if (status == 0x4)\r\nret = good_frame;\r\nelse if (status == 0x5)\r\nret = csum_none;\r\nelse if (status == 0x6)\r\nret = csum_none;\r\nelse if (status == 0x7)\r\nret = csum_none;\r\nelse if (status == 0x1)\r\nret = discard_frame;\r\nelse if (status == 0x3)\r\nret = discard_frame;\r\nreturn ret;\r\n}\r\nstatic void enh_desc_get_ext_status(void *data, struct stmmac_extra_stats *x,\r\nstruct dma_extended_desc *p)\r\n{\r\nunsigned int rdes0 = p->basic.des0;\r\nunsigned int rdes4 = p->des4;\r\nif (unlikely(rdes0 & ERDES0_RX_MAC_ADDR)) {\r\nint message_type = (rdes4 & ERDES4_MSG_TYPE_MASK) >> 8;\r\nif (rdes4 & ERDES4_IP_HDR_ERR)\r\nx->ip_hdr_err++;\r\nif (rdes4 & ERDES4_IP_PAYLOAD_ERR)\r\nx->ip_payload_err++;\r\nif (rdes4 & ERDES4_IP_CSUM_BYPASSED)\r\nx->ip_csum_bypassed++;\r\nif (rdes4 & ERDES4_IPV4_PKT_RCVD)\r\nx->ipv4_pkt_rcvd++;\r\nif (rdes4 & ERDES4_IPV6_PKT_RCVD)\r\nx->ipv6_pkt_rcvd++;\r\nif (message_type == RDES_EXT_SYNC)\r\nx->rx_msg_type_sync++;\r\nelse if (message_type == RDES_EXT_FOLLOW_UP)\r\nx->rx_msg_type_follow_up++;\r\nelse if (message_type == RDES_EXT_DELAY_REQ)\r\nx->rx_msg_type_delay_req++;\r\nelse if (message_type == RDES_EXT_DELAY_RESP)\r\nx->rx_msg_type_delay_resp++;\r\nelse if (message_type == RDES_EXT_PDELAY_REQ)\r\nx->rx_msg_type_pdelay_req++;\r\nelse if (message_type == RDES_EXT_PDELAY_RESP)\r\nx->rx_msg_type_pdelay_resp++;\r\nelse if (message_type == RDES_EXT_PDELAY_FOLLOW_UP)\r\nx->rx_msg_type_pdelay_follow_up++;\r\nelse\r\nx->rx_msg_type_ext_no_ptp++;\r\nif (rdes4 & ERDES4_PTP_FRAME_TYPE)\r\nx->ptp_frame_type++;\r\nif (rdes4 & ERDES4_PTP_VER)\r\nx->ptp_ver++;\r\nif (rdes4 & ERDES4_TIMESTAMP_DROPPED)\r\nx->timestamp_dropped++;\r\nif (rdes4 & ERDES4_AV_PKT_RCVD)\r\nx->av_pkt_rcvd++;\r\nif (rdes4 & ERDES4_AV_TAGGED_PKT_RCVD)\r\nx->av_tagged_pkt_rcvd++;\r\nif ((rdes4 & ERDES4_VLAN_TAG_PRI_VAL_MASK) >> 18)\r\nx->vlan_tag_priority_val++;\r\nif (rdes4 & ERDES4_L3_FILTER_MATCH)\r\nx->l3_filter_match++;\r\nif (rdes4 & ERDES4_L4_FILTER_MATCH)\r\nx->l4_filter_match++;\r\nif ((rdes4 & ERDES4_L3_L4_FILT_NO_MATCH_MASK) >> 26)\r\nx->l3_l4_filter_no_match++;\r\n}\r\n}\r\nstatic int enh_desc_get_rx_status(void *data, struct stmmac_extra_stats *x,\r\nstruct dma_desc *p)\r\n{\r\nstruct net_device_stats *stats = (struct net_device_stats *)data;\r\nunsigned int rdes0 = p->des0;\r\nint ret = good_frame;\r\nif (unlikely(rdes0 & RDES0_OWN))\r\nreturn dma_own;\r\nif (unlikely(rdes0 & RDES0_ERROR_SUMMARY)) {\r\nif (unlikely(rdes0 & RDES0_DESCRIPTOR_ERROR)) {\r\nx->rx_desc++;\r\nstats->rx_length_errors++;\r\n}\r\nif (unlikely(rdes0 & RDES0_OVERFLOW_ERROR))\r\nx->rx_gmac_overflow++;\r\nif (unlikely(rdes0 & RDES0_IPC_CSUM_ERROR))\r\npr_err("\tIPC Csum Error/Giant frame\n");\r\nif (unlikely(rdes0 & RDES0_COLLISION))\r\nstats->collisions++;\r\nif (unlikely(rdes0 & RDES0_RECEIVE_WATCHDOG))\r\nx->rx_watchdog++;\r\nif (unlikely(rdes0 & RDES0_MII_ERROR))\r\nx->rx_mii++;\r\nif (unlikely(rdes0 & RDES0_CRC_ERROR)) {\r\nx->rx_crc++;\r\nstats->rx_crc_errors++;\r\n}\r\nret = discard_frame;\r\n}\r\nret = enh_desc_coe_rdes0(!!(rdes0 & RDES0_IPC_CSUM_ERROR),\r\n!!(rdes0 & RDES0_FRAME_TYPE),\r\n!!(rdes0 & ERDES0_RX_MAC_ADDR));\r\nif (unlikely(rdes0 & RDES0_DRIBBLING))\r\nx->dribbling_bit++;\r\nif (unlikely(rdes0 & RDES0_SA_FILTER_FAIL)) {\r\nx->sa_rx_filter_fail++;\r\nret = discard_frame;\r\n}\r\nif (unlikely(rdes0 & RDES0_DA_FILTER_FAIL)) {\r\nx->da_rx_filter_fail++;\r\nret = discard_frame;\r\n}\r\nif (unlikely(rdes0 & RDES0_LENGTH_ERROR)) {\r\nx->rx_length++;\r\nret = discard_frame;\r\n}\r\n#ifdef STMMAC_VLAN_TAG_USED\r\nif (rdes0 & RDES0_VLAN_TAG)\r\nx->rx_vlan++;\r\n#endif\r\nreturn ret;\r\n}\r\nstatic void enh_desc_init_rx_desc(struct dma_desc *p, int disable_rx_ic,\r\nint mode, int end)\r\n{\r\np->des0 |= RDES0_OWN;\r\np->des1 |= ((BUF_SIZE_8KiB - 1) & ERDES1_BUFFER1_SIZE_MASK);\r\nif (mode == STMMAC_CHAIN_MODE)\r\nehn_desc_rx_set_on_chain(p);\r\nelse\r\nehn_desc_rx_set_on_ring(p, end);\r\nif (disable_rx_ic)\r\np->des1 |= ERDES1_DISABLE_IC;\r\n}\r\nstatic void enh_desc_init_tx_desc(struct dma_desc *p, int mode, int end)\r\n{\r\np->des0 &= ~ETDES0_OWN;\r\nif (mode == STMMAC_CHAIN_MODE)\r\nenh_desc_end_tx_desc_on_chain(p);\r\nelse\r\nenh_desc_end_tx_desc_on_ring(p, end);\r\n}\r\nstatic int enh_desc_get_tx_owner(struct dma_desc *p)\r\n{\r\nreturn (p->des0 & ETDES0_OWN) >> 31;\r\n}\r\nstatic void enh_desc_set_tx_owner(struct dma_desc *p)\r\n{\r\np->des0 |= ETDES0_OWN;\r\n}\r\nstatic void enh_desc_set_rx_owner(struct dma_desc *p)\r\n{\r\np->des0 |= RDES0_OWN;\r\n}\r\nstatic int enh_desc_get_tx_ls(struct dma_desc *p)\r\n{\r\nreturn (p->des0 & ETDES0_LAST_SEGMENT) >> 29;\r\n}\r\nstatic void enh_desc_release_tx_desc(struct dma_desc *p, int mode)\r\n{\r\nint ter = (p->des0 & ETDES0_END_RING) >> 21;\r\nmemset(p, 0, offsetof(struct dma_desc, des2));\r\nif (mode == STMMAC_CHAIN_MODE)\r\nenh_desc_end_tx_desc_on_chain(p);\r\nelse\r\nenh_desc_end_tx_desc_on_ring(p, ter);\r\n}\r\nstatic void enh_desc_prepare_tx_desc(struct dma_desc *p, int is_fs, int len,\r\nbool csum_flag, int mode, bool tx_own,\r\nbool ls)\r\n{\r\nunsigned int tdes0 = p->des0;\r\nif (mode == STMMAC_CHAIN_MODE)\r\nenh_set_tx_desc_len_on_chain(p, len);\r\nelse\r\nenh_set_tx_desc_len_on_ring(p, len);\r\nif (is_fs)\r\ntdes0 |= ETDES0_FIRST_SEGMENT;\r\nelse\r\ntdes0 &= ~ETDES0_FIRST_SEGMENT;\r\nif (likely(csum_flag))\r\ntdes0 |= (TX_CIC_FULL << ETDES0_CHECKSUM_INSERTION_SHIFT);\r\nelse\r\ntdes0 &= ~(TX_CIC_FULL << ETDES0_CHECKSUM_INSERTION_SHIFT);\r\nif (ls)\r\ntdes0 |= ETDES0_LAST_SEGMENT;\r\nif (tx_own)\r\ntdes0 |= ETDES0_OWN;\r\nif (is_fs & tx_own)\r\nwmb();\r\np->des0 = tdes0;\r\n}\r\nstatic void enh_desc_set_tx_ic(struct dma_desc *p)\r\n{\r\np->des0 |= ETDES0_INTERRUPT;\r\n}\r\nstatic int enh_desc_get_rx_frame_len(struct dma_desc *p, int rx_coe_type)\r\n{\r\nunsigned int csum = 0;\r\nif (rx_coe_type == STMMAC_RX_COE_TYPE1)\r\ncsum = 2;\r\nreturn (((p->des0 & RDES0_FRAME_LEN_MASK) >> RDES0_FRAME_LEN_SHIFT) -\r\ncsum);\r\n}\r\nstatic void enh_desc_enable_tx_timestamp(struct dma_desc *p)\r\n{\r\np->des0 |= ETDES0_TIME_STAMP_ENABLE;\r\n}\r\nstatic int enh_desc_get_tx_timestamp_status(struct dma_desc *p)\r\n{\r\nreturn (p->des0 & ETDES0_TIME_STAMP_STATUS) >> 17;\r\n}\r\nstatic u64 enh_desc_get_timestamp(void *desc, u32 ats)\r\n{\r\nu64 ns;\r\nif (ats) {\r\nstruct dma_extended_desc *p = (struct dma_extended_desc *)desc;\r\nns = p->des6;\r\nns += p->des7 * 1000000000ULL;\r\n} else {\r\nstruct dma_desc *p = (struct dma_desc *)desc;\r\nns = p->des2;\r\nns += p->des3 * 1000000000ULL;\r\n}\r\nreturn ns;\r\n}\r\nstatic int enh_desc_get_rx_timestamp_status(void *desc, u32 ats)\r\n{\r\nif (ats) {\r\nstruct dma_extended_desc *p = (struct dma_extended_desc *)desc;\r\nreturn (p->basic.des0 & RDES0_IPC_CSUM_ERROR) >> 7;\r\n} else {\r\nstruct dma_desc *p = (struct dma_desc *)desc;\r\nif ((p->des2 == 0xffffffff) && (p->des3 == 0xffffffff))\r\nreturn 0;\r\nelse\r\nreturn 1;\r\n}\r\n}\r\nstatic void enh_desc_display_ring(void *head, unsigned int size, bool rx)\r\n{\r\nstruct dma_extended_desc *ep = (struct dma_extended_desc *)head;\r\nint i;\r\npr_info("Extended %s descriptor ring:\n", rx ? "RX" : "TX");\r\nfor (i = 0; i < size; i++) {\r\nu64 x;\r\nx = *(u64 *)ep;\r\npr_info("%d [0x%x]: 0x%x 0x%x 0x%x 0x%x\n",\r\ni, (unsigned int)virt_to_phys(ep),\r\n(unsigned int)x, (unsigned int)(x >> 32),\r\nep->basic.des2, ep->basic.des3);\r\nep++;\r\n}\r\npr_info("\n");\r\n}
