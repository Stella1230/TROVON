static u64 vmballoon_batch_get_pa(struct vmballoon_batch_page *batch, int idx)\r\n{\r\nreturn batch->pages[idx] & VMW_BALLOON_BATCH_PAGE_MASK;\r\n}\r\nstatic int vmballoon_batch_get_status(struct vmballoon_batch_page *batch,\r\nint idx)\r\n{\r\nreturn (int)(batch->pages[idx] & VMW_BALLOON_BATCH_STATUS_MASK);\r\n}\r\nstatic void vmballoon_batch_set_pa(struct vmballoon_batch_page *batch, int idx,\r\nu64 pa)\r\n{\r\nbatch->pages[idx] = pa;\r\n}\r\nstatic bool vmballoon_send_start(struct vmballoon *b, unsigned long req_caps)\r\n{\r\nunsigned long status, capabilities, dummy = 0;\r\nbool success;\r\nSTATS_INC(b->stats.start);\r\nstatus = VMWARE_BALLOON_CMD(START, req_caps, dummy, capabilities);\r\nswitch (status) {\r\ncase VMW_BALLOON_SUCCESS_WITH_CAPABILITIES:\r\nb->capabilities = capabilities;\r\nsuccess = true;\r\nbreak;\r\ncase VMW_BALLOON_SUCCESS:\r\nb->capabilities = VMW_BALLOON_BASIC_CMDS;\r\nsuccess = true;\r\nbreak;\r\ndefault:\r\nsuccess = false;\r\n}\r\nif (b->capabilities & VMW_BALLOON_BATCHED_2M_CMDS)\r\nb->supported_page_sizes = 2;\r\nelse\r\nb->supported_page_sizes = 1;\r\nif (!success) {\r\npr_debug("%s - failed, hv returns %ld\n", __func__, status);\r\nSTATS_INC(b->stats.start_fail);\r\n}\r\nreturn success;\r\n}\r\nstatic bool vmballoon_check_status(struct vmballoon *b, unsigned long status)\r\n{\r\nswitch (status) {\r\ncase VMW_BALLOON_SUCCESS:\r\nreturn true;\r\ncase VMW_BALLOON_ERROR_RESET:\r\nb->reset_required = true;\r\ndefault:\r\nreturn false;\r\n}\r\n}\r\nstatic bool vmballoon_send_guest_id(struct vmballoon *b)\r\n{\r\nunsigned long status, dummy = 0;\r\nstatus = VMWARE_BALLOON_CMD(GUEST_ID, VMW_BALLOON_GUEST_ID, dummy,\r\ndummy);\r\nSTATS_INC(b->stats.guest_type);\r\nif (vmballoon_check_status(b, status))\r\nreturn true;\r\npr_debug("%s - failed, hv returns %ld\n", __func__, status);\r\nSTATS_INC(b->stats.guest_type_fail);\r\nreturn false;\r\n}\r\nstatic u16 vmballoon_page_size(bool is_2m_page)\r\n{\r\nif (is_2m_page)\r\nreturn 1 << VMW_BALLOON_2M_SHIFT;\r\nreturn 1;\r\n}\r\nstatic bool vmballoon_send_get_target(struct vmballoon *b, u32 *new_target)\r\n{\r\nunsigned long status;\r\nunsigned long target;\r\nunsigned long limit;\r\nunsigned long dummy = 0;\r\nu32 limit32;\r\nsi_meminfo(&b->sysinfo);\r\nlimit = b->sysinfo.totalram;\r\nlimit32 = (u32)limit;\r\nif (limit != limit32)\r\nreturn false;\r\nSTATS_INC(b->stats.target);\r\nstatus = VMWARE_BALLOON_CMD(GET_TARGET, limit, dummy, target);\r\nif (vmballoon_check_status(b, status)) {\r\n*new_target = target;\r\nreturn true;\r\n}\r\npr_debug("%s - failed, hv returns %ld\n", __func__, status);\r\nSTATS_INC(b->stats.target_fail);\r\nreturn false;\r\n}\r\nstatic int vmballoon_send_lock_page(struct vmballoon *b, unsigned long pfn,\r\nunsigned int *hv_status, unsigned int *target)\r\n{\r\nunsigned long status, dummy = 0;\r\nu32 pfn32;\r\npfn32 = (u32)pfn;\r\nif (pfn32 != pfn)\r\nreturn -1;\r\nSTATS_INC(b->stats.lock[false]);\r\n*hv_status = status = VMWARE_BALLOON_CMD(LOCK, pfn, dummy, *target);\r\nif (vmballoon_check_status(b, status))\r\nreturn 0;\r\npr_debug("%s - ppn %lx, hv returns %ld\n", __func__, pfn, status);\r\nSTATS_INC(b->stats.lock_fail[false]);\r\nreturn 1;\r\n}\r\nstatic int vmballoon_send_batched_lock(struct vmballoon *b,\r\nunsigned int num_pages, bool is_2m_pages, unsigned int *target)\r\n{\r\nunsigned long status;\r\nunsigned long pfn = page_to_pfn(b->page);\r\nSTATS_INC(b->stats.lock[is_2m_pages]);\r\nif (is_2m_pages)\r\nstatus = VMWARE_BALLOON_CMD(BATCHED_2M_LOCK, pfn, num_pages,\r\n*target);\r\nelse\r\nstatus = VMWARE_BALLOON_CMD(BATCHED_LOCK, pfn, num_pages,\r\n*target);\r\nif (vmballoon_check_status(b, status))\r\nreturn 0;\r\npr_debug("%s - batch ppn %lx, hv returns %ld\n", __func__, pfn, status);\r\nSTATS_INC(b->stats.lock_fail[is_2m_pages]);\r\nreturn 1;\r\n}\r\nstatic bool vmballoon_send_unlock_page(struct vmballoon *b, unsigned long pfn,\r\nunsigned int *target)\r\n{\r\nunsigned long status, dummy = 0;\r\nu32 pfn32;\r\npfn32 = (u32)pfn;\r\nif (pfn32 != pfn)\r\nreturn false;\r\nSTATS_INC(b->stats.unlock[false]);\r\nstatus = VMWARE_BALLOON_CMD(UNLOCK, pfn, dummy, *target);\r\nif (vmballoon_check_status(b, status))\r\nreturn true;\r\npr_debug("%s - ppn %lx, hv returns %ld\n", __func__, pfn, status);\r\nSTATS_INC(b->stats.unlock_fail[false]);\r\nreturn false;\r\n}\r\nstatic bool vmballoon_send_batched_unlock(struct vmballoon *b,\r\nunsigned int num_pages, bool is_2m_pages, unsigned int *target)\r\n{\r\nunsigned long status;\r\nunsigned long pfn = page_to_pfn(b->page);\r\nSTATS_INC(b->stats.unlock[is_2m_pages]);\r\nif (is_2m_pages)\r\nstatus = VMWARE_BALLOON_CMD(BATCHED_2M_UNLOCK, pfn, num_pages,\r\n*target);\r\nelse\r\nstatus = VMWARE_BALLOON_CMD(BATCHED_UNLOCK, pfn, num_pages,\r\n*target);\r\nif (vmballoon_check_status(b, status))\r\nreturn true;\r\npr_debug("%s - batch ppn %lx, hv returns %ld\n", __func__, pfn, status);\r\nSTATS_INC(b->stats.unlock_fail[is_2m_pages]);\r\nreturn false;\r\n}\r\nstatic struct page *vmballoon_alloc_page(gfp_t flags, bool is_2m_page)\r\n{\r\nif (is_2m_page)\r\nreturn alloc_pages(flags, VMW_BALLOON_2M_SHIFT);\r\nreturn alloc_page(flags);\r\n}\r\nstatic void vmballoon_free_page(struct page *page, bool is_2m_page)\r\n{\r\nif (is_2m_page)\r\n__free_pages(page, VMW_BALLOON_2M_SHIFT);\r\nelse\r\n__free_page(page);\r\n}\r\nstatic void vmballoon_pop(struct vmballoon *b)\r\n{\r\nstruct page *page, *next;\r\nunsigned is_2m_pages;\r\nfor (is_2m_pages = 0; is_2m_pages < VMW_BALLOON_NUM_PAGE_SIZES;\r\nis_2m_pages++) {\r\nstruct vmballoon_page_size *page_size =\r\n&b->page_sizes[is_2m_pages];\r\nu16 size_per_page = vmballoon_page_size(is_2m_pages);\r\nlist_for_each_entry_safe(page, next, &page_size->pages, lru) {\r\nlist_del(&page->lru);\r\nvmballoon_free_page(page, is_2m_pages);\r\nSTATS_INC(b->stats.free[is_2m_pages]);\r\nb->size -= size_per_page;\r\ncond_resched();\r\n}\r\n}\r\nif (b->batch_page) {\r\nvunmap(b->batch_page);\r\nb->batch_page = NULL;\r\n}\r\nif (b->page) {\r\n__free_page(b->page);\r\nb->page = NULL;\r\n}\r\n}\r\nstatic int vmballoon_lock_page(struct vmballoon *b, unsigned int num_pages,\r\nbool is_2m_pages, unsigned int *target)\r\n{\r\nint locked, hv_status;\r\nstruct page *page = b->page;\r\nstruct vmballoon_page_size *page_size = &b->page_sizes[false];\r\nlocked = vmballoon_send_lock_page(b, page_to_pfn(page), &hv_status,\r\ntarget);\r\nif (locked > 0) {\r\nSTATS_INC(b->stats.refused_alloc[false]);\r\nif (hv_status == VMW_BALLOON_ERROR_RESET ||\r\nhv_status == VMW_BALLOON_ERROR_PPN_NOTNEEDED) {\r\nvmballoon_free_page(page, false);\r\nreturn -EIO;\r\n}\r\nif (page_size->n_refused_pages < VMW_BALLOON_MAX_REFUSED) {\r\npage_size->n_refused_pages++;\r\nlist_add(&page->lru, &page_size->refused_pages);\r\n} else {\r\nvmballoon_free_page(page, false);\r\n}\r\nreturn -EIO;\r\n}\r\nlist_add(&page->lru, &page_size->pages);\r\nb->size++;\r\nreturn 0;\r\n}\r\nstatic int vmballoon_lock_batched_page(struct vmballoon *b,\r\nunsigned int num_pages, bool is_2m_pages, unsigned int *target)\r\n{\r\nint locked, i;\r\nu16 size_per_page = vmballoon_page_size(is_2m_pages);\r\nlocked = vmballoon_send_batched_lock(b, num_pages, is_2m_pages,\r\ntarget);\r\nif (locked > 0) {\r\nfor (i = 0; i < num_pages; i++) {\r\nu64 pa = vmballoon_batch_get_pa(b->batch_page, i);\r\nstruct page *p = pfn_to_page(pa >> PAGE_SHIFT);\r\nvmballoon_free_page(p, is_2m_pages);\r\n}\r\nreturn -EIO;\r\n}\r\nfor (i = 0; i < num_pages; i++) {\r\nu64 pa = vmballoon_batch_get_pa(b->batch_page, i);\r\nstruct page *p = pfn_to_page(pa >> PAGE_SHIFT);\r\nstruct vmballoon_page_size *page_size =\r\n&b->page_sizes[is_2m_pages];\r\nlocked = vmballoon_batch_get_status(b->batch_page, i);\r\nswitch (locked) {\r\ncase VMW_BALLOON_SUCCESS:\r\nlist_add(&p->lru, &page_size->pages);\r\nb->size += size_per_page;\r\nbreak;\r\ncase VMW_BALLOON_ERROR_PPN_PINNED:\r\ncase VMW_BALLOON_ERROR_PPN_INVALID:\r\nif (page_size->n_refused_pages\r\n< VMW_BALLOON_MAX_REFUSED) {\r\nlist_add(&p->lru, &page_size->refused_pages);\r\npage_size->n_refused_pages++;\r\nbreak;\r\n}\r\ncase VMW_BALLOON_ERROR_RESET:\r\ncase VMW_BALLOON_ERROR_PPN_NOTNEEDED:\r\nvmballoon_free_page(p, is_2m_pages);\r\nbreak;\r\ndefault:\r\nWARN_ON_ONCE(true);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int vmballoon_unlock_page(struct vmballoon *b, unsigned int num_pages,\r\nbool is_2m_pages, unsigned int *target)\r\n{\r\nstruct page *page = b->page;\r\nstruct vmballoon_page_size *page_size = &b->page_sizes[false];\r\nif (!vmballoon_send_unlock_page(b, page_to_pfn(page), target)) {\r\nlist_add(&page->lru, &page_size->pages);\r\nreturn -EIO;\r\n}\r\nvmballoon_free_page(page, false);\r\nSTATS_INC(b->stats.free[false]);\r\nb->size--;\r\nreturn 0;\r\n}\r\nstatic int vmballoon_unlock_batched_page(struct vmballoon *b,\r\nunsigned int num_pages, bool is_2m_pages,\r\nunsigned int *target)\r\n{\r\nint locked, i, ret = 0;\r\nbool hv_success;\r\nu16 size_per_page = vmballoon_page_size(is_2m_pages);\r\nhv_success = vmballoon_send_batched_unlock(b, num_pages, is_2m_pages,\r\ntarget);\r\nif (!hv_success)\r\nret = -EIO;\r\nfor (i = 0; i < num_pages; i++) {\r\nu64 pa = vmballoon_batch_get_pa(b->batch_page, i);\r\nstruct page *p = pfn_to_page(pa >> PAGE_SHIFT);\r\nstruct vmballoon_page_size *page_size =\r\n&b->page_sizes[is_2m_pages];\r\nlocked = vmballoon_batch_get_status(b->batch_page, i);\r\nif (!hv_success || locked != VMW_BALLOON_SUCCESS) {\r\nlist_add(&p->lru, &page_size->pages);\r\n} else {\r\nvmballoon_free_page(p, is_2m_pages);\r\nSTATS_INC(b->stats.free[is_2m_pages]);\r\nb->size -= size_per_page;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic void vmballoon_release_refused_pages(struct vmballoon *b,\r\nbool is_2m_pages)\r\n{\r\nstruct page *page, *next;\r\nstruct vmballoon_page_size *page_size =\r\n&b->page_sizes[is_2m_pages];\r\nlist_for_each_entry_safe(page, next, &page_size->refused_pages, lru) {\r\nlist_del(&page->lru);\r\nvmballoon_free_page(page, is_2m_pages);\r\nSTATS_INC(b->stats.refused_free[is_2m_pages]);\r\n}\r\npage_size->n_refused_pages = 0;\r\n}\r\nstatic void vmballoon_add_page(struct vmballoon *b, int idx, struct page *p)\r\n{\r\nb->page = p;\r\n}\r\nstatic void vmballoon_add_batched_page(struct vmballoon *b, int idx,\r\nstruct page *p)\r\n{\r\nvmballoon_batch_set_pa(b->batch_page, idx,\r\n(u64)page_to_pfn(p) << PAGE_SHIFT);\r\n}\r\nstatic void vmballoon_inflate(struct vmballoon *b)\r\n{\r\nunsigned rate;\r\nunsigned int allocations = 0;\r\nunsigned int num_pages = 0;\r\nint error = 0;\r\ngfp_t flags = VMW_PAGE_ALLOC_NOSLEEP;\r\nbool is_2m_pages;\r\npr_debug("%s - size: %d, target %d\n", __func__, b->size, b->target);\r\nif (b->slow_allocation_cycles) {\r\nrate = b->rate_alloc;\r\nis_2m_pages = false;\r\n} else {\r\nrate = UINT_MAX;\r\nis_2m_pages =\r\nb->supported_page_sizes == VMW_BALLOON_NUM_PAGE_SIZES;\r\n}\r\npr_debug("%s - goal: %d, no-sleep rate: %u, sleep rate: %d\n",\r\n__func__, b->target - b->size, rate, b->rate_alloc);\r\nwhile (!b->reset_required &&\r\nb->size + num_pages * vmballoon_page_size(is_2m_pages)\r\n< b->target) {\r\nstruct page *page;\r\nif (flags == VMW_PAGE_ALLOC_NOSLEEP)\r\nSTATS_INC(b->stats.alloc[is_2m_pages]);\r\nelse\r\nSTATS_INC(b->stats.sleep_alloc);\r\npage = vmballoon_alloc_page(flags, is_2m_pages);\r\nif (!page) {\r\nSTATS_INC(b->stats.alloc_fail[is_2m_pages]);\r\nif (is_2m_pages) {\r\nb->ops->lock(b, num_pages, true, &b->target);\r\nnum_pages = 0;\r\nis_2m_pages = false;\r\ncontinue;\r\n}\r\nif (flags == VMW_PAGE_ALLOC_CANSLEEP) {\r\nb->rate_alloc = max(b->rate_alloc / 2,\r\nVMW_BALLOON_RATE_ALLOC_MIN);\r\nSTATS_INC(b->stats.sleep_alloc_fail);\r\nbreak;\r\n}\r\nb->slow_allocation_cycles = VMW_BALLOON_SLOW_CYCLES;\r\nif (allocations >= b->rate_alloc)\r\nbreak;\r\nflags = VMW_PAGE_ALLOC_CANSLEEP;\r\nrate = b->rate_alloc;\r\ncontinue;\r\n}\r\nb->ops->add_page(b, num_pages++, page);\r\nif (num_pages == b->batch_max_pages) {\r\nerror = b->ops->lock(b, num_pages, is_2m_pages,\r\n&b->target);\r\nnum_pages = 0;\r\nif (error)\r\nbreak;\r\n}\r\ncond_resched();\r\nif (allocations >= rate) {\r\nbreak;\r\n}\r\n}\r\nif (num_pages > 0)\r\nb->ops->lock(b, num_pages, is_2m_pages, &b->target);\r\nif (error == 0 && allocations >= b->rate_alloc) {\r\nunsigned int mult = allocations / b->rate_alloc;\r\nb->rate_alloc =\r\nmin(b->rate_alloc + mult * VMW_BALLOON_RATE_ALLOC_INC,\r\nVMW_BALLOON_RATE_ALLOC_MAX);\r\n}\r\nvmballoon_release_refused_pages(b, true);\r\nvmballoon_release_refused_pages(b, false);\r\n}\r\nstatic void vmballoon_deflate(struct vmballoon *b)\r\n{\r\nunsigned is_2m_pages;\r\npr_debug("%s - size: %d, target %d\n", __func__, b->size, b->target);\r\nfor (is_2m_pages = 0; is_2m_pages < b->supported_page_sizes;\r\nis_2m_pages++) {\r\nstruct page *page, *next;\r\nunsigned int num_pages = 0;\r\nstruct vmballoon_page_size *page_size =\r\n&b->page_sizes[is_2m_pages];\r\nlist_for_each_entry_safe(page, next, &page_size->pages, lru) {\r\nif (b->reset_required ||\r\n(b->target > 0 &&\r\nb->size - num_pages\r\n* vmballoon_page_size(is_2m_pages)\r\n< b->target + vmballoon_page_size(true)))\r\nbreak;\r\nlist_del(&page->lru);\r\nb->ops->add_page(b, num_pages++, page);\r\nif (num_pages == b->batch_max_pages) {\r\nint error;\r\nerror = b->ops->unlock(b, num_pages,\r\nis_2m_pages, &b->target);\r\nnum_pages = 0;\r\nif (error)\r\nreturn;\r\n}\r\ncond_resched();\r\n}\r\nif (num_pages > 0)\r\nb->ops->unlock(b, num_pages, is_2m_pages, &b->target);\r\n}\r\n}\r\nstatic bool vmballoon_init_batching(struct vmballoon *b)\r\n{\r\nb->page = alloc_page(VMW_PAGE_ALLOC_NOSLEEP);\r\nif (!b->page)\r\nreturn false;\r\nb->batch_page = vmap(&b->page, 1, VM_MAP, PAGE_KERNEL);\r\nif (!b->batch_page) {\r\n__free_page(b->page);\r\nreturn false;\r\n}\r\nreturn true;\r\n}\r\nstatic void vmballoon_doorbell(void *client_data)\r\n{\r\nstruct vmballoon *b = client_data;\r\nSTATS_INC(b->stats.doorbell);\r\nmod_delayed_work(system_freezable_wq, &b->dwork, 0);\r\n}\r\nstatic void vmballoon_vmci_cleanup(struct vmballoon *b)\r\n{\r\nint error;\r\nVMWARE_BALLOON_CMD(VMCI_DOORBELL_SET, VMCI_INVALID_ID,\r\nVMCI_INVALID_ID, error);\r\nSTATS_INC(b->stats.doorbell_unset);\r\nif (!vmci_handle_is_invalid(b->vmci_doorbell)) {\r\nvmci_doorbell_destroy(b->vmci_doorbell);\r\nb->vmci_doorbell = VMCI_INVALID_HANDLE;\r\n}\r\n}\r\nstatic int vmballoon_vmci_init(struct vmballoon *b)\r\n{\r\nint error = 0;\r\nif ((b->capabilities & VMW_BALLOON_SIGNALLED_WAKEUP_CMD) != 0) {\r\nerror = vmci_doorbell_create(&b->vmci_doorbell,\r\nVMCI_FLAG_DELAYED_CB,\r\nVMCI_PRIVILEGE_FLAG_RESTRICTED,\r\nvmballoon_doorbell, b);\r\nif (error == VMCI_SUCCESS) {\r\nVMWARE_BALLOON_CMD(VMCI_DOORBELL_SET,\r\nb->vmci_doorbell.context,\r\nb->vmci_doorbell.resource, error);\r\nSTATS_INC(b->stats.doorbell_set);\r\n}\r\n}\r\nif (error != 0) {\r\nvmballoon_vmci_cleanup(b);\r\nreturn -EIO;\r\n}\r\nreturn 0;\r\n}\r\nstatic void vmballoon_reset(struct vmballoon *b)\r\n{\r\nint error;\r\nvmballoon_vmci_cleanup(b);\r\nvmballoon_pop(b);\r\nif (!vmballoon_send_start(b, VMW_BALLOON_CAPABILITIES))\r\nreturn;\r\nif ((b->capabilities & VMW_BALLOON_BATCHED_CMDS) != 0) {\r\nb->ops = &vmballoon_batched_ops;\r\nb->batch_max_pages = VMW_BALLOON_BATCH_MAX_PAGES;\r\nif (!vmballoon_init_batching(b)) {\r\nvmballoon_send_start(b, 0);\r\nreturn;\r\n}\r\n} else if ((b->capabilities & VMW_BALLOON_BASIC_CMDS) != 0) {\r\nb->ops = &vmballoon_basic_ops;\r\nb->batch_max_pages = 1;\r\n}\r\nb->reset_required = false;\r\nerror = vmballoon_vmci_init(b);\r\nif (error)\r\npr_err("failed to initialize vmci doorbell\n");\r\nif (!vmballoon_send_guest_id(b))\r\npr_err("failed to send guest ID to the host\n");\r\n}\r\nstatic void vmballoon_work(struct work_struct *work)\r\n{\r\nstruct delayed_work *dwork = to_delayed_work(work);\r\nstruct vmballoon *b = container_of(dwork, struct vmballoon, dwork);\r\nunsigned int target;\r\nSTATS_INC(b->stats.timer);\r\nif (b->reset_required)\r\nvmballoon_reset(b);\r\nif (b->slow_allocation_cycles > 0)\r\nb->slow_allocation_cycles--;\r\nif (!b->reset_required && vmballoon_send_get_target(b, &target)) {\r\nb->target = target;\r\nif (b->size < target)\r\nvmballoon_inflate(b);\r\nelse if (target == 0 ||\r\nb->size > target + vmballoon_page_size(true))\r\nvmballoon_deflate(b);\r\n}\r\nqueue_delayed_work(system_freezable_wq,\r\ndwork, round_jiffies_relative(HZ));\r\n}\r\nstatic int vmballoon_debug_show(struct seq_file *f, void *offset)\r\n{\r\nstruct vmballoon *b = f->private;\r\nstruct vmballoon_stats *stats = &b->stats;\r\nseq_printf(f,\r\n"balloon capabilities: %#4x\n"\r\n"used capabilities: %#4lx\n"\r\n"is resetting: %c\n",\r\nVMW_BALLOON_CAPABILITIES, b->capabilities,\r\nb->reset_required ? 'y' : 'n');\r\nseq_printf(f,\r\n"target: %8d pages\n"\r\n"current: %8d pages\n",\r\nb->target, b->size);\r\nseq_printf(f,\r\n"rateSleepAlloc: %8d pages/sec\n",\r\nb->rate_alloc);\r\nseq_printf(f,\r\n"\n"\r\n"timer: %8u\n"\r\n"doorbell: %8u\n"\r\n"start: %8u (%4u failed)\n"\r\n"guestType: %8u (%4u failed)\n"\r\n"2m-lock: %8u (%4u failed)\n"\r\n"lock: %8u (%4u failed)\n"\r\n"2m-unlock: %8u (%4u failed)\n"\r\n"unlock: %8u (%4u failed)\n"\r\n"target: %8u (%4u failed)\n"\r\n"prim2mAlloc: %8u (%4u failed)\n"\r\n"primNoSleepAlloc: %8u (%4u failed)\n"\r\n"primCanSleepAlloc: %8u (%4u failed)\n"\r\n"prim2mFree: %8u\n"\r\n"primFree: %8u\n"\r\n"err2mAlloc: %8u\n"\r\n"errAlloc: %8u\n"\r\n"err2mFree: %8u\n"\r\n"errFree: %8u\n"\r\n"doorbellSet: %8u\n"\r\n"doorbellUnset: %8u\n",\r\nstats->timer,\r\nstats->doorbell,\r\nstats->start, stats->start_fail,\r\nstats->guest_type, stats->guest_type_fail,\r\nstats->lock[true], stats->lock_fail[true],\r\nstats->lock[false], stats->lock_fail[false],\r\nstats->unlock[true], stats->unlock_fail[true],\r\nstats->unlock[false], stats->unlock_fail[false],\r\nstats->target, stats->target_fail,\r\nstats->alloc[true], stats->alloc_fail[true],\r\nstats->alloc[false], stats->alloc_fail[false],\r\nstats->sleep_alloc, stats->sleep_alloc_fail,\r\nstats->free[true],\r\nstats->free[false],\r\nstats->refused_alloc[true], stats->refused_alloc[false],\r\nstats->refused_free[true], stats->refused_free[false],\r\nstats->doorbell_set, stats->doorbell_unset);\r\nreturn 0;\r\n}\r\nstatic int vmballoon_debug_open(struct inode *inode, struct file *file)\r\n{\r\nreturn single_open(file, vmballoon_debug_show, inode->i_private);\r\n}\r\nstatic int __init vmballoon_debugfs_init(struct vmballoon *b)\r\n{\r\nint error;\r\nb->dbg_entry = debugfs_create_file("vmmemctl", S_IRUGO, NULL, b,\r\n&vmballoon_debug_fops);\r\nif (IS_ERR(b->dbg_entry)) {\r\nerror = PTR_ERR(b->dbg_entry);\r\npr_err("failed to create debugfs entry, error: %d\n", error);\r\nreturn error;\r\n}\r\nreturn 0;\r\n}\r\nstatic void __exit vmballoon_debugfs_exit(struct vmballoon *b)\r\n{\r\ndebugfs_remove(b->dbg_entry);\r\n}\r\nstatic inline int vmballoon_debugfs_init(struct vmballoon *b)\r\n{\r\nreturn 0;\r\n}\r\nstatic inline void vmballoon_debugfs_exit(struct vmballoon *b)\r\n{\r\n}\r\nstatic int __init vmballoon_init(void)\r\n{\r\nint error;\r\nunsigned is_2m_pages;\r\nif (x86_hyper != &x86_hyper_vmware)\r\nreturn -ENODEV;\r\nfor (is_2m_pages = 0; is_2m_pages < VMW_BALLOON_NUM_PAGE_SIZES;\r\nis_2m_pages++) {\r\nINIT_LIST_HEAD(&balloon.page_sizes[is_2m_pages].pages);\r\nINIT_LIST_HEAD(&balloon.page_sizes[is_2m_pages].refused_pages);\r\n}\r\nballoon.rate_alloc = VMW_BALLOON_RATE_ALLOC_MAX;\r\nINIT_DELAYED_WORK(&balloon.dwork, vmballoon_work);\r\nerror = vmballoon_debugfs_init(&balloon);\r\nif (error)\r\nreturn error;\r\nballoon.vmci_doorbell = VMCI_INVALID_HANDLE;\r\nballoon.batch_page = NULL;\r\nballoon.page = NULL;\r\nballoon.reset_required = true;\r\nqueue_delayed_work(system_freezable_wq, &balloon.dwork, 0);\r\nreturn 0;\r\n}\r\nstatic void __exit vmballoon_exit(void)\r\n{\r\nvmballoon_vmci_cleanup(&balloon);\r\ncancel_delayed_work_sync(&balloon.dwork);\r\nvmballoon_debugfs_exit(&balloon);\r\nvmballoon_send_start(&balloon, 0);\r\nvmballoon_pop(&balloon);\r\n}
