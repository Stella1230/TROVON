static int epic_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)\r\n{\r\nstatic int card_idx = -1;\r\nvoid __iomem *ioaddr;\r\nint chip_idx = (int) ent->driver_data;\r\nint irq;\r\nstruct net_device *dev;\r\nstruct epic_private *ep;\r\nint i, ret, option = 0, duplex = 0;\r\nvoid *ring_space;\r\ndma_addr_t ring_dma;\r\n#ifndef MODULE\r\npr_info_once("%s%s\n", version, version2);\r\n#endif\r\ncard_idx++;\r\nret = pci_enable_device(pdev);\r\nif (ret)\r\ngoto out;\r\nirq = pdev->irq;\r\nif (pci_resource_len(pdev, 0) < EPIC_TOTAL_SIZE) {\r\ndev_err(&pdev->dev, "no PCI region space\n");\r\nret = -ENODEV;\r\ngoto err_out_disable;\r\n}\r\npci_set_master(pdev);\r\nret = pci_request_regions(pdev, DRV_NAME);\r\nif (ret < 0)\r\ngoto err_out_disable;\r\nret = -ENOMEM;\r\ndev = alloc_etherdev(sizeof (*ep));\r\nif (!dev)\r\ngoto err_out_free_res;\r\nSET_NETDEV_DEV(dev, &pdev->dev);\r\nioaddr = pci_iomap(pdev, EPIC_BAR, 0);\r\nif (!ioaddr) {\r\ndev_err(&pdev->dev, "ioremap failed\n");\r\ngoto err_out_free_netdev;\r\n}\r\npci_set_drvdata(pdev, dev);\r\nep = netdev_priv(dev);\r\nep->ioaddr = ioaddr;\r\nep->mii.dev = dev;\r\nep->mii.mdio_read = mdio_read;\r\nep->mii.mdio_write = mdio_write;\r\nep->mii.phy_id_mask = 0x1f;\r\nep->mii.reg_num_mask = 0x1f;\r\nring_space = pci_alloc_consistent(pdev, TX_TOTAL_SIZE, &ring_dma);\r\nif (!ring_space)\r\ngoto err_out_iounmap;\r\nep->tx_ring = ring_space;\r\nep->tx_ring_dma = ring_dma;\r\nring_space = pci_alloc_consistent(pdev, RX_TOTAL_SIZE, &ring_dma);\r\nif (!ring_space)\r\ngoto err_out_unmap_tx;\r\nep->rx_ring = ring_space;\r\nep->rx_ring_dma = ring_dma;\r\nif (dev->mem_start) {\r\noption = dev->mem_start;\r\nduplex = (dev->mem_start & 16) ? 1 : 0;\r\n} else if (card_idx >= 0 && card_idx < MAX_UNITS) {\r\nif (options[card_idx] >= 0)\r\noption = options[card_idx];\r\nif (full_duplex[card_idx] >= 0)\r\nduplex = full_duplex[card_idx];\r\n}\r\nspin_lock_init(&ep->lock);\r\nspin_lock_init(&ep->napi_lock);\r\nep->reschedule_in_poll = 0;\r\new32(GENCTL, 0x4200);\r\nfor (i = 16; i > 0; i--)\r\new32(TEST1, 0x0008);\r\new32(MIICfg, 0x12);\r\nif (chip_idx == 1)\r\new32(NVCTL, (er32(NVCTL) & ~0x003c) | 0x4800);\r\new32(GENCTL, 0x0200);\r\nfor (i = 0; i < 3; i++)\r\n((__le16 *)dev->dev_addr)[i] = cpu_to_le16(er16(LAN0 + i*4));\r\nif (debug > 2) {\r\ndev_dbg(&pdev->dev, "EEPROM contents:\n");\r\nfor (i = 0; i < 64; i++)\r\npr_cont(" %4.4x%s", read_eeprom(ep, i),\r\ni % 16 == 15 ? "\n" : "");\r\n}\r\nep->pci_dev = pdev;\r\nep->chip_id = chip_idx;\r\nep->chip_flags = pci_id_tbl[chip_idx].drv_flags;\r\nep->irq_mask =\r\n(ep->chip_flags & TYPE2_INTR ? PCIBusErr175 : PCIBusErr170)\r\n| CntFull | TxUnderrun | EpicNapiEvent;\r\n{\r\nint phy, phy_idx = 0;\r\nfor (phy = 1; phy < 32 && phy_idx < sizeof(ep->phys); phy++) {\r\nint mii_status = mdio_read(dev, phy, MII_BMSR);\r\nif (mii_status != 0xffff && mii_status != 0x0000) {\r\nep->phys[phy_idx++] = phy;\r\ndev_info(&pdev->dev,\r\n"MII transceiver #%d control "\r\n"%4.4x status %4.4x.\n",\r\nphy, mdio_read(dev, phy, 0), mii_status);\r\n}\r\n}\r\nep->mii_phy_cnt = phy_idx;\r\nif (phy_idx != 0) {\r\nphy = ep->phys[0];\r\nep->mii.advertising = mdio_read(dev, phy, MII_ADVERTISE);\r\ndev_info(&pdev->dev,\r\n"Autonegotiation advertising %4.4x link "\r\n"partner %4.4x.\n",\r\nep->mii.advertising, mdio_read(dev, phy, 5));\r\n} else if ( ! (ep->chip_flags & NO_MII)) {\r\ndev_warn(&pdev->dev,\r\n"***WARNING***: No MII transceiver found!\n");\r\nep->phys[0] = 3;\r\n}\r\nep->mii.phy_id = ep->phys[0];\r\n}\r\nif (ep->chip_flags & MII_PWRDWN)\r\new32(NVCTL, er32(NVCTL) & ~0x483c);\r\new32(GENCTL, 0x0008);\r\nif (duplex) {\r\nep->mii.force_media = ep->mii.full_duplex = 1;\r\ndev_info(&pdev->dev, "Forced full duplex requested.\n");\r\n}\r\ndev->if_port = ep->default_port = option;\r\ndev->netdev_ops = &epic_netdev_ops;\r\ndev->ethtool_ops = &netdev_ethtool_ops;\r\ndev->watchdog_timeo = TX_TIMEOUT;\r\nnetif_napi_add(dev, &ep->napi, epic_poll, 64);\r\nret = register_netdev(dev);\r\nif (ret < 0)\r\ngoto err_out_unmap_rx;\r\nnetdev_info(dev, "%s at %lx, IRQ %d, %pM\n",\r\npci_id_tbl[chip_idx].name,\r\n(long)pci_resource_start(pdev, EPIC_BAR), pdev->irq,\r\ndev->dev_addr);\r\nout:\r\nreturn ret;\r\nerr_out_unmap_rx:\r\npci_free_consistent(pdev, RX_TOTAL_SIZE, ep->rx_ring, ep->rx_ring_dma);\r\nerr_out_unmap_tx:\r\npci_free_consistent(pdev, TX_TOTAL_SIZE, ep->tx_ring, ep->tx_ring_dma);\r\nerr_out_iounmap:\r\npci_iounmap(pdev, ioaddr);\r\nerr_out_free_netdev:\r\nfree_netdev(dev);\r\nerr_out_free_res:\r\npci_release_regions(pdev);\r\nerr_out_disable:\r\npci_disable_device(pdev);\r\ngoto out;\r\n}\r\nstatic void epic_disable_int(struct net_device *dev, struct epic_private *ep)\r\n{\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\new32(INTMASK, 0x00000000);\r\n}\r\nstatic inline void __epic_pci_commit(void __iomem *ioaddr)\r\n{\r\n#ifndef USE_IO_OPS\r\ner32(INTMASK);\r\n#endif\r\n}\r\nstatic inline void epic_napi_irq_off(struct net_device *dev,\r\nstruct epic_private *ep)\r\n{\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\new32(INTMASK, ep->irq_mask & ~EpicNapiEvent);\r\n__epic_pci_commit(ioaddr);\r\n}\r\nstatic inline void epic_napi_irq_on(struct net_device *dev,\r\nstruct epic_private *ep)\r\n{\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\new32(INTMASK, ep->irq_mask | EpicNapiEvent);\r\n}\r\nstatic int read_eeprom(struct epic_private *ep, int location)\r\n{\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\nint i;\r\nint retval = 0;\r\nint read_cmd = location |\r\n(er32(EECTL) & 0x40 ? EE_READ64_CMD : EE_READ256_CMD);\r\new32(EECTL, EE_ENB & ~EE_CS);\r\new32(EECTL, EE_ENB);\r\nfor (i = 12; i >= 0; i--) {\r\nshort dataval = (read_cmd & (1 << i)) ? EE_WRITE_1 : EE_WRITE_0;\r\new32(EECTL, EE_ENB | dataval);\r\neeprom_delay();\r\new32(EECTL, EE_ENB | dataval | EE_SHIFT_CLK);\r\neeprom_delay();\r\n}\r\new32(EECTL, EE_ENB);\r\nfor (i = 16; i > 0; i--) {\r\new32(EECTL, EE_ENB | EE_SHIFT_CLK);\r\neeprom_delay();\r\nretval = (retval << 1) | ((er32(EECTL) & EE_DATA_READ) ? 1 : 0);\r\new32(EECTL, EE_ENB);\r\neeprom_delay();\r\n}\r\new32(EECTL, EE_ENB & ~EE_CS);\r\nreturn retval;\r\n}\r\nstatic int mdio_read(struct net_device *dev, int phy_id, int location)\r\n{\r\nstruct epic_private *ep = netdev_priv(dev);\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\nint read_cmd = (phy_id << 9) | (location << 4) | MII_READOP;\r\nint i;\r\new32(MIICtrl, read_cmd);\r\nfor (i = 400; i > 0; i--) {\r\nbarrier();\r\nif ((er32(MIICtrl) & MII_READOP) == 0) {\r\nif (phy_id == 1 && location < 6 &&\r\ner16(MIIData) == 0xffff) {\r\new32(MIICtrl, read_cmd);\r\ncontinue;\r\n}\r\nreturn er16(MIIData);\r\n}\r\n}\r\nreturn 0xffff;\r\n}\r\nstatic void mdio_write(struct net_device *dev, int phy_id, int loc, int value)\r\n{\r\nstruct epic_private *ep = netdev_priv(dev);\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\nint i;\r\new16(MIIData, value);\r\new32(MIICtrl, (phy_id << 9) | (loc << 4) | MII_WRITEOP);\r\nfor (i = 10000; i > 0; i--) {\r\nbarrier();\r\nif ((er32(MIICtrl) & MII_WRITEOP) == 0)\r\nbreak;\r\n}\r\n}\r\nstatic int epic_open(struct net_device *dev)\r\n{\r\nstruct epic_private *ep = netdev_priv(dev);\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\nconst int irq = ep->pci_dev->irq;\r\nint rc, i;\r\new32(GENCTL, 0x4001);\r\nnapi_enable(&ep->napi);\r\nrc = request_irq(irq, epic_interrupt, IRQF_SHARED, dev->name, dev);\r\nif (rc) {\r\nnapi_disable(&ep->napi);\r\nreturn rc;\r\n}\r\nepic_init_ring(dev);\r\new32(GENCTL, 0x4000);\r\nfor (i = 16; i > 0; i--)\r\new32(TEST1, 0x0008);\r\n#if 0\r\new32(MIICfg, dev->if_port == 1 ? 0x13 : 0x12);\r\n#endif\r\nif (ep->chip_flags & MII_PWRDWN)\r\new32(NVCTL, (er32(NVCTL) & ~0x003c) | 0x4800);\r\n#ifdef __BIG_ENDIAN\r\new32(GENCTL, 0x4432 | (RX_FIFO_THRESH << 8));\r\ner32(GENCTL);\r\new32(GENCTL, 0x0432 | (RX_FIFO_THRESH << 8));\r\n#else\r\new32(GENCTL, 0x4412 | (RX_FIFO_THRESH << 8));\r\ner32(GENCTL);\r\new32(GENCTL, 0x0412 | (RX_FIFO_THRESH << 8));\r\n#endif\r\nudelay(20);\r\nfor (i = 0; i < 3; i++)\r\new32(LAN0 + i*4, le16_to_cpu(((__le16*)dev->dev_addr)[i]));\r\nep->tx_threshold = TX_FIFO_THRESH;\r\new32(TxThresh, ep->tx_threshold);\r\nif (media2miictl[dev->if_port & 15]) {\r\nif (ep->mii_phy_cnt)\r\nmdio_write(dev, ep->phys[0], MII_BMCR, media2miictl[dev->if_port&15]);\r\nif (dev->if_port == 1) {\r\nif (debug > 1)\r\nnetdev_info(dev, "Using the 10base2 transceiver, MII status %4.4x.\n",\r\nmdio_read(dev, ep->phys[0], MII_BMSR));\r\n}\r\n} else {\r\nint mii_lpa = mdio_read(dev, ep->phys[0], MII_LPA);\r\nif (mii_lpa != 0xffff) {\r\nif ((mii_lpa & LPA_100FULL) || (mii_lpa & 0x01C0) == LPA_10FULL)\r\nep->mii.full_duplex = 1;\r\nelse if (! (mii_lpa & LPA_LPACK))\r\nmdio_write(dev, ep->phys[0], MII_BMCR, BMCR_ANENABLE|BMCR_ANRESTART);\r\nif (debug > 1)\r\nnetdev_info(dev, "Setting %s-duplex based on MII xcvr %d register read of %4.4x.\n",\r\nep->mii.full_duplex ? "full"\r\n: "half",\r\nep->phys[0], mii_lpa);\r\n}\r\n}\r\new32(TxCtrl, ep->mii.full_duplex ? 0x7f : 0x79);\r\new32(PRxCDAR, ep->rx_ring_dma);\r\new32(PTxCDAR, ep->tx_ring_dma);\r\nset_rx_mode(dev);\r\new32(COMMAND, StartRx | RxQueued);\r\nnetif_start_queue(dev);\r\new32(INTMASK, RxError | RxHeader | EpicNapiEvent | CntFull |\r\n((ep->chip_flags & TYPE2_INTR) ? PCIBusErr175 : PCIBusErr170) |\r\nTxUnderrun);\r\nif (debug > 1) {\r\nnetdev_dbg(dev, "epic_open() ioaddr %p IRQ %d status %4.4x %s-duplex.\n",\r\nioaddr, irq, er32(GENCTL),\r\nep->mii.full_duplex ? "full" : "half");\r\n}\r\ninit_timer(&ep->timer);\r\nep->timer.expires = jiffies + 3*HZ;\r\nep->timer.data = (unsigned long)dev;\r\nep->timer.function = epic_timer;\r\nadd_timer(&ep->timer);\r\nreturn rc;\r\n}\r\nstatic void epic_pause(struct net_device *dev)\r\n{\r\nstruct net_device_stats *stats = &dev->stats;\r\nstruct epic_private *ep = netdev_priv(dev);\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\nnetif_stop_queue (dev);\r\new32(INTMASK, 0x00000000);\r\new16(COMMAND, StopRx | StopTxDMA | StopRxDMA);\r\nif (er16(COMMAND) != 0xffff) {\r\nstats->rx_missed_errors += er8(MPCNT);\r\nstats->rx_frame_errors += er8(ALICNT);\r\nstats->rx_crc_errors += er8(CRCCNT);\r\n}\r\nepic_rx(dev, RX_RING_SIZE);\r\n}\r\nstatic void epic_restart(struct net_device *dev)\r\n{\r\nstruct epic_private *ep = netdev_priv(dev);\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\nint i;\r\new32(GENCTL, 0x4001);\r\nnetdev_dbg(dev, "Restarting the EPIC chip, Rx %d/%d Tx %d/%d.\n",\r\nep->cur_rx, ep->dirty_rx, ep->dirty_tx, ep->cur_tx);\r\nudelay(1);\r\nfor (i = 16; i > 0; i--)\r\new32(TEST1, 0x0008);\r\n#ifdef __BIG_ENDIAN\r\new32(GENCTL, 0x0432 | (RX_FIFO_THRESH << 8));\r\n#else\r\new32(GENCTL, 0x0412 | (RX_FIFO_THRESH << 8));\r\n#endif\r\new32(MIICfg, dev->if_port == 1 ? 0x13 : 0x12);\r\nif (ep->chip_flags & MII_PWRDWN)\r\new32(NVCTL, (er32(NVCTL) & ~0x003c) | 0x4800);\r\nfor (i = 0; i < 3; i++)\r\new32(LAN0 + i*4, le16_to_cpu(((__le16*)dev->dev_addr)[i]));\r\nep->tx_threshold = TX_FIFO_THRESH;\r\new32(TxThresh, ep->tx_threshold);\r\new32(TxCtrl, ep->mii.full_duplex ? 0x7f : 0x79);\r\new32(PRxCDAR, ep->rx_ring_dma +\r\n(ep->cur_rx % RX_RING_SIZE) * sizeof(struct epic_rx_desc));\r\new32(PTxCDAR, ep->tx_ring_dma +\r\n(ep->dirty_tx % TX_RING_SIZE) * sizeof(struct epic_tx_desc));\r\nset_rx_mode(dev);\r\new32(COMMAND, StartRx | RxQueued);\r\new32(INTMASK, RxError | RxHeader | EpicNapiEvent | CntFull |\r\n((ep->chip_flags & TYPE2_INTR) ? PCIBusErr175 : PCIBusErr170) |\r\nTxUnderrun);\r\nnetdev_dbg(dev, "epic_restart() done, cmd status %4.4x, ctl %4.4x interrupt %4.4x.\n",\r\ner32(COMMAND), er32(GENCTL), er32(INTSTAT));\r\n}\r\nstatic void check_media(struct net_device *dev)\r\n{\r\nstruct epic_private *ep = netdev_priv(dev);\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\nint mii_lpa = ep->mii_phy_cnt ? mdio_read(dev, ep->phys[0], MII_LPA) : 0;\r\nint negotiated = mii_lpa & ep->mii.advertising;\r\nint duplex = (negotiated & 0x0100) || (negotiated & 0x01C0) == 0x0040;\r\nif (ep->mii.force_media)\r\nreturn;\r\nif (mii_lpa == 0xffff)\r\nreturn;\r\nif (ep->mii.full_duplex != duplex) {\r\nep->mii.full_duplex = duplex;\r\nnetdev_info(dev, "Setting %s-duplex based on MII #%d link partner capability of %4.4x.\n",\r\nep->mii.full_duplex ? "full" : "half",\r\nep->phys[0], mii_lpa);\r\new32(TxCtrl, ep->mii.full_duplex ? 0x7F : 0x79);\r\n}\r\n}\r\nstatic void epic_timer(unsigned long data)\r\n{\r\nstruct net_device *dev = (struct net_device *)data;\r\nstruct epic_private *ep = netdev_priv(dev);\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\nint next_tick = 5*HZ;\r\nif (debug > 3) {\r\nnetdev_dbg(dev, "Media monitor tick, Tx status %8.8x.\n",\r\ner32(TxSTAT));\r\nnetdev_dbg(dev, "Other registers are IntMask %4.4x IntStatus %4.4x RxStatus %4.4x.\n",\r\ner32(INTMASK), er32(INTSTAT), er32(RxSTAT));\r\n}\r\ncheck_media(dev);\r\nep->timer.expires = jiffies + next_tick;\r\nadd_timer(&ep->timer);\r\n}\r\nstatic void epic_tx_timeout(struct net_device *dev)\r\n{\r\nstruct epic_private *ep = netdev_priv(dev);\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\nif (debug > 0) {\r\nnetdev_warn(dev, "Transmit timeout using MII device, Tx status %4.4x.\n",\r\ner16(TxSTAT));\r\nif (debug > 1) {\r\nnetdev_dbg(dev, "Tx indices: dirty_tx %d, cur_tx %d.\n",\r\nep->dirty_tx, ep->cur_tx);\r\n}\r\n}\r\nif (er16(TxSTAT) & 0x10) {\r\ndev->stats.tx_fifo_errors++;\r\new32(COMMAND, RestartTx);\r\n} else {\r\nepic_restart(dev);\r\new32(COMMAND, TxQueued);\r\n}\r\nnetif_trans_update(dev);\r\ndev->stats.tx_errors++;\r\nif (!ep->tx_full)\r\nnetif_wake_queue(dev);\r\n}\r\nstatic void epic_init_ring(struct net_device *dev)\r\n{\r\nstruct epic_private *ep = netdev_priv(dev);\r\nint i;\r\nep->tx_full = 0;\r\nep->dirty_tx = ep->cur_tx = 0;\r\nep->cur_rx = ep->dirty_rx = 0;\r\nep->rx_buf_sz = (dev->mtu <= 1500 ? PKT_BUF_SZ : dev->mtu + 32);\r\nfor (i = 0; i < RX_RING_SIZE; i++) {\r\nep->rx_ring[i].rxstatus = 0;\r\nep->rx_ring[i].buflength = ep->rx_buf_sz;\r\nep->rx_ring[i].next = ep->rx_ring_dma +\r\n(i+1)*sizeof(struct epic_rx_desc);\r\nep->rx_skbuff[i] = NULL;\r\n}\r\nep->rx_ring[i-1].next = ep->rx_ring_dma;\r\nfor (i = 0; i < RX_RING_SIZE; i++) {\r\nstruct sk_buff *skb = netdev_alloc_skb(dev, ep->rx_buf_sz + 2);\r\nep->rx_skbuff[i] = skb;\r\nif (skb == NULL)\r\nbreak;\r\nskb_reserve(skb, 2);\r\nep->rx_ring[i].bufaddr = pci_map_single(ep->pci_dev,\r\nskb->data, ep->rx_buf_sz, PCI_DMA_FROMDEVICE);\r\nep->rx_ring[i].rxstatus = DescOwn;\r\n}\r\nep->dirty_rx = (unsigned int)(i - RX_RING_SIZE);\r\nfor (i = 0; i < TX_RING_SIZE; i++) {\r\nep->tx_skbuff[i] = NULL;\r\nep->tx_ring[i].txstatus = 0x0000;\r\nep->tx_ring[i].next = ep->tx_ring_dma +\r\n(i+1)*sizeof(struct epic_tx_desc);\r\n}\r\nep->tx_ring[i-1].next = ep->tx_ring_dma;\r\n}\r\nstatic netdev_tx_t epic_start_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct epic_private *ep = netdev_priv(dev);\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\nint entry, free_count;\r\nu32 ctrl_word;\r\nunsigned long flags;\r\nif (skb_padto(skb, ETH_ZLEN))\r\nreturn NETDEV_TX_OK;\r\nspin_lock_irqsave(&ep->lock, flags);\r\nfree_count = ep->cur_tx - ep->dirty_tx;\r\nentry = ep->cur_tx % TX_RING_SIZE;\r\nep->tx_skbuff[entry] = skb;\r\nep->tx_ring[entry].bufaddr = pci_map_single(ep->pci_dev, skb->data,\r\nskb->len, PCI_DMA_TODEVICE);\r\nif (free_count < TX_QUEUE_LEN/2) {\r\nctrl_word = 0x100000;\r\n} else if (free_count == TX_QUEUE_LEN/2) {\r\nctrl_word = 0x140000;\r\n} else if (free_count < TX_QUEUE_LEN - 1) {\r\nctrl_word = 0x100000;\r\n} else {\r\nctrl_word = 0x140000;\r\nep->tx_full = 1;\r\n}\r\nep->tx_ring[entry].buflength = ctrl_word | skb->len;\r\nep->tx_ring[entry].txstatus =\r\n((skb->len >= ETH_ZLEN ? skb->len : ETH_ZLEN) << 16)\r\n| DescOwn;\r\nep->cur_tx++;\r\nif (ep->tx_full)\r\nnetif_stop_queue(dev);\r\nspin_unlock_irqrestore(&ep->lock, flags);\r\new32(COMMAND, TxQueued);\r\nif (debug > 4)\r\nnetdev_dbg(dev, "Queued Tx packet size %d to slot %d, flag %2.2x Tx status %8.8x.\n",\r\nskb->len, entry, ctrl_word, er32(TxSTAT));\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void epic_tx_error(struct net_device *dev, struct epic_private *ep,\r\nint status)\r\n{\r\nstruct net_device_stats *stats = &dev->stats;\r\n#ifndef final_version\r\nif (debug > 1)\r\nnetdev_dbg(dev, "Transmit error, Tx status %8.8x.\n",\r\nstatus);\r\n#endif\r\nstats->tx_errors++;\r\nif (status & 0x1050)\r\nstats->tx_aborted_errors++;\r\nif (status & 0x0008)\r\nstats->tx_carrier_errors++;\r\nif (status & 0x0040)\r\nstats->tx_window_errors++;\r\nif (status & 0x0010)\r\nstats->tx_fifo_errors++;\r\n}\r\nstatic void epic_tx(struct net_device *dev, struct epic_private *ep)\r\n{\r\nunsigned int dirty_tx, cur_tx;\r\ncur_tx = ep->cur_tx;\r\nfor (dirty_tx = ep->dirty_tx; cur_tx - dirty_tx > 0; dirty_tx++) {\r\nstruct sk_buff *skb;\r\nint entry = dirty_tx % TX_RING_SIZE;\r\nint txstatus = ep->tx_ring[entry].txstatus;\r\nif (txstatus & DescOwn)\r\nbreak;\r\nif (likely(txstatus & 0x0001)) {\r\ndev->stats.collisions += (txstatus >> 8) & 15;\r\ndev->stats.tx_packets++;\r\ndev->stats.tx_bytes += ep->tx_skbuff[entry]->len;\r\n} else\r\nepic_tx_error(dev, ep, txstatus);\r\nskb = ep->tx_skbuff[entry];\r\npci_unmap_single(ep->pci_dev, ep->tx_ring[entry].bufaddr,\r\nskb->len, PCI_DMA_TODEVICE);\r\ndev_kfree_skb_irq(skb);\r\nep->tx_skbuff[entry] = NULL;\r\n}\r\n#ifndef final_version\r\nif (cur_tx - dirty_tx > TX_RING_SIZE) {\r\nnetdev_warn(dev, "Out-of-sync dirty pointer, %d vs. %d, full=%d.\n",\r\ndirty_tx, cur_tx, ep->tx_full);\r\ndirty_tx += TX_RING_SIZE;\r\n}\r\n#endif\r\nep->dirty_tx = dirty_tx;\r\nif (ep->tx_full && cur_tx - dirty_tx < TX_QUEUE_LEN - 4) {\r\nep->tx_full = 0;\r\nnetif_wake_queue(dev);\r\n}\r\n}\r\nstatic irqreturn_t epic_interrupt(int irq, void *dev_instance)\r\n{\r\nstruct net_device *dev = dev_instance;\r\nstruct epic_private *ep = netdev_priv(dev);\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\nunsigned int handled = 0;\r\nint status;\r\nstatus = er32(INTSTAT);\r\new32(INTSTAT, status & EpicNormalEvent);\r\nif (debug > 4) {\r\nnetdev_dbg(dev, "Interrupt, status=%#8.8x new intstat=%#8.8x.\n",\r\nstatus, er32(INTSTAT));\r\n}\r\nif ((status & IntrSummary) == 0)\r\ngoto out;\r\nhandled = 1;\r\nif ((status & EpicNapiEvent) && !ep->reschedule_in_poll) {\r\nspin_lock(&ep->napi_lock);\r\nif (napi_schedule_prep(&ep->napi)) {\r\nepic_napi_irq_off(dev, ep);\r\n__napi_schedule(&ep->napi);\r\n} else\r\nep->reschedule_in_poll++;\r\nspin_unlock(&ep->napi_lock);\r\n}\r\nstatus &= ~EpicNapiEvent;\r\nif (status & (CntFull | TxUnderrun | PCIBusErr170 | PCIBusErr175)) {\r\nstruct net_device_stats *stats = &dev->stats;\r\nif (status == EpicRemoved)\r\ngoto out;\r\nstats->rx_missed_errors += er8(MPCNT);\r\nstats->rx_frame_errors += er8(ALICNT);\r\nstats->rx_crc_errors += er8(CRCCNT);\r\nif (status & TxUnderrun) {\r\nstats->tx_fifo_errors++;\r\new32(TxThresh, ep->tx_threshold += 128);\r\new32(COMMAND, RestartTx);\r\n}\r\nif (status & PCIBusErr170) {\r\nnetdev_err(dev, "PCI Bus Error! status %4.4x.\n",\r\nstatus);\r\nepic_pause(dev);\r\nepic_restart(dev);\r\n}\r\new32(INTSTAT, status & 0x7f18);\r\n}\r\nout:\r\nif (debug > 3) {\r\nnetdev_dbg(dev, "exit interrupt, intr_status=%#4.4x.\n",\r\nstatus);\r\n}\r\nreturn IRQ_RETVAL(handled);\r\n}\r\nstatic int epic_rx(struct net_device *dev, int budget)\r\n{\r\nstruct epic_private *ep = netdev_priv(dev);\r\nint entry = ep->cur_rx % RX_RING_SIZE;\r\nint rx_work_limit = ep->dirty_rx + RX_RING_SIZE - ep->cur_rx;\r\nint work_done = 0;\r\nif (debug > 4)\r\nnetdev_dbg(dev, " In epic_rx(), entry %d %8.8x.\n", entry,\r\nep->rx_ring[entry].rxstatus);\r\nif (rx_work_limit > budget)\r\nrx_work_limit = budget;\r\nwhile ((ep->rx_ring[entry].rxstatus & DescOwn) == 0) {\r\nint status = ep->rx_ring[entry].rxstatus;\r\nif (debug > 4)\r\nnetdev_dbg(dev, " epic_rx() status was %8.8x.\n",\r\nstatus);\r\nif (--rx_work_limit < 0)\r\nbreak;\r\nif (status & 0x2006) {\r\nif (debug > 2)\r\nnetdev_dbg(dev, "epic_rx() error status was %8.8x.\n",\r\nstatus);\r\nif (status & 0x2000) {\r\nnetdev_warn(dev, "Oversized Ethernet frame spanned multiple buffers, status %4.4x!\n",\r\nstatus);\r\ndev->stats.rx_length_errors++;\r\n} else if (status & 0x0006)\r\ndev->stats.rx_errors++;\r\n} else {\r\nshort pkt_len = (status >> 16) - 4;\r\nstruct sk_buff *skb;\r\nif (pkt_len > PKT_BUF_SZ - 4) {\r\nnetdev_err(dev, "Oversized Ethernet frame, status %x %d bytes.\n",\r\nstatus, pkt_len);\r\npkt_len = 1514;\r\n}\r\nif (pkt_len < rx_copybreak &&\r\n(skb = netdev_alloc_skb(dev, pkt_len + 2)) != NULL) {\r\nskb_reserve(skb, 2);\r\npci_dma_sync_single_for_cpu(ep->pci_dev,\r\nep->rx_ring[entry].bufaddr,\r\nep->rx_buf_sz,\r\nPCI_DMA_FROMDEVICE);\r\nskb_copy_to_linear_data(skb, ep->rx_skbuff[entry]->data, pkt_len);\r\nskb_put(skb, pkt_len);\r\npci_dma_sync_single_for_device(ep->pci_dev,\r\nep->rx_ring[entry].bufaddr,\r\nep->rx_buf_sz,\r\nPCI_DMA_FROMDEVICE);\r\n} else {\r\npci_unmap_single(ep->pci_dev,\r\nep->rx_ring[entry].bufaddr,\r\nep->rx_buf_sz, PCI_DMA_FROMDEVICE);\r\nskb_put(skb = ep->rx_skbuff[entry], pkt_len);\r\nep->rx_skbuff[entry] = NULL;\r\n}\r\nskb->protocol = eth_type_trans(skb, dev);\r\nnetif_receive_skb(skb);\r\ndev->stats.rx_packets++;\r\ndev->stats.rx_bytes += pkt_len;\r\n}\r\nwork_done++;\r\nentry = (++ep->cur_rx) % RX_RING_SIZE;\r\n}\r\nfor (; ep->cur_rx - ep->dirty_rx > 0; ep->dirty_rx++) {\r\nentry = ep->dirty_rx % RX_RING_SIZE;\r\nif (ep->rx_skbuff[entry] == NULL) {\r\nstruct sk_buff *skb;\r\nskb = ep->rx_skbuff[entry] = netdev_alloc_skb(dev, ep->rx_buf_sz + 2);\r\nif (skb == NULL)\r\nbreak;\r\nskb_reserve(skb, 2);\r\nep->rx_ring[entry].bufaddr = pci_map_single(ep->pci_dev,\r\nskb->data, ep->rx_buf_sz, PCI_DMA_FROMDEVICE);\r\nwork_done++;\r\n}\r\nep->rx_ring[entry].rxstatus = DescOwn;\r\n}\r\nreturn work_done;\r\n}\r\nstatic void epic_rx_err(struct net_device *dev, struct epic_private *ep)\r\n{\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\nint status;\r\nstatus = er32(INTSTAT);\r\nif (status == EpicRemoved)\r\nreturn;\r\nif (status & RxOverflow)\r\ndev->stats.rx_errors++;\r\nif (status & (RxOverflow | RxFull))\r\new16(COMMAND, RxQueued);\r\n}\r\nstatic int epic_poll(struct napi_struct *napi, int budget)\r\n{\r\nstruct epic_private *ep = container_of(napi, struct epic_private, napi);\r\nstruct net_device *dev = ep->mii.dev;\r\nint work_done = 0;\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\nrx_action:\r\nepic_tx(dev, ep);\r\nwork_done += epic_rx(dev, budget);\r\nepic_rx_err(dev, ep);\r\nif (work_done < budget) {\r\nunsigned long flags;\r\nint more;\r\nspin_lock_irqsave(&ep->napi_lock, flags);\r\nmore = ep->reschedule_in_poll;\r\nif (!more) {\r\n__napi_complete(napi);\r\new32(INTSTAT, EpicNapiEvent);\r\nepic_napi_irq_on(dev, ep);\r\n} else\r\nep->reschedule_in_poll--;\r\nspin_unlock_irqrestore(&ep->napi_lock, flags);\r\nif (more)\r\ngoto rx_action;\r\n}\r\nreturn work_done;\r\n}\r\nstatic int epic_close(struct net_device *dev)\r\n{\r\nstruct epic_private *ep = netdev_priv(dev);\r\nstruct pci_dev *pdev = ep->pci_dev;\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\nstruct sk_buff *skb;\r\nint i;\r\nnetif_stop_queue(dev);\r\nnapi_disable(&ep->napi);\r\nif (debug > 1)\r\nnetdev_dbg(dev, "Shutting down ethercard, status was %2.2x.\n",\r\ner32(INTSTAT));\r\ndel_timer_sync(&ep->timer);\r\nepic_disable_int(dev, ep);\r\nfree_irq(pdev->irq, dev);\r\nepic_pause(dev);\r\nfor (i = 0; i < RX_RING_SIZE; i++) {\r\nskb = ep->rx_skbuff[i];\r\nep->rx_skbuff[i] = NULL;\r\nep->rx_ring[i].rxstatus = 0;\r\nep->rx_ring[i].buflength = 0;\r\nif (skb) {\r\npci_unmap_single(pdev, ep->rx_ring[i].bufaddr,\r\nep->rx_buf_sz, PCI_DMA_FROMDEVICE);\r\ndev_kfree_skb(skb);\r\n}\r\nep->rx_ring[i].bufaddr = 0xBADF00D0;\r\n}\r\nfor (i = 0; i < TX_RING_SIZE; i++) {\r\nskb = ep->tx_skbuff[i];\r\nep->tx_skbuff[i] = NULL;\r\nif (!skb)\r\ncontinue;\r\npci_unmap_single(pdev, ep->tx_ring[i].bufaddr, skb->len,\r\nPCI_DMA_TODEVICE);\r\ndev_kfree_skb(skb);\r\n}\r\new32(GENCTL, 0x0008);\r\nreturn 0;\r\n}\r\nstatic struct net_device_stats *epic_get_stats(struct net_device *dev)\r\n{\r\nstruct epic_private *ep = netdev_priv(dev);\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\nif (netif_running(dev)) {\r\nstruct net_device_stats *stats = &dev->stats;\r\nstats->rx_missed_errors += er8(MPCNT);\r\nstats->rx_frame_errors += er8(ALICNT);\r\nstats->rx_crc_errors += er8(CRCCNT);\r\n}\r\nreturn &dev->stats;\r\n}\r\nstatic void set_rx_mode(struct net_device *dev)\r\n{\r\nstruct epic_private *ep = netdev_priv(dev);\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\nunsigned char mc_filter[8];\r\nint i;\r\nif (dev->flags & IFF_PROMISC) {\r\new32(RxCtrl, 0x002c);\r\nmemset(mc_filter, 0xff, sizeof(mc_filter));\r\n} else if ((!netdev_mc_empty(dev)) || (dev->flags & IFF_ALLMULTI)) {\r\nmemset(mc_filter, 0xff, sizeof(mc_filter));\r\new32(RxCtrl, 0x000c);\r\n} else if (netdev_mc_empty(dev)) {\r\new32(RxCtrl, 0x0004);\r\nreturn;\r\n} else {\r\nstruct netdev_hw_addr *ha;\r\nmemset(mc_filter, 0, sizeof(mc_filter));\r\nnetdev_for_each_mc_addr(ha, dev) {\r\nunsigned int bit_nr =\r\nether_crc_le(ETH_ALEN, ha->addr) & 0x3f;\r\nmc_filter[bit_nr >> 3] |= (1 << bit_nr);\r\n}\r\n}\r\nif (memcmp(mc_filter, ep->mc_filter, sizeof(mc_filter))) {\r\nfor (i = 0; i < 4; i++)\r\new16(MC0 + i*4, ((u16 *)mc_filter)[i]);\r\nmemcpy(ep->mc_filter, mc_filter, sizeof(mc_filter));\r\n}\r\n}\r\nstatic void netdev_get_drvinfo (struct net_device *dev, struct ethtool_drvinfo *info)\r\n{\r\nstruct epic_private *np = netdev_priv(dev);\r\nstrlcpy(info->driver, DRV_NAME, sizeof(info->driver));\r\nstrlcpy(info->version, DRV_VERSION, sizeof(info->version));\r\nstrlcpy(info->bus_info, pci_name(np->pci_dev), sizeof(info->bus_info));\r\n}\r\nstatic int netdev_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)\r\n{\r\nstruct epic_private *np = netdev_priv(dev);\r\nint rc;\r\nspin_lock_irq(&np->lock);\r\nrc = mii_ethtool_gset(&np->mii, cmd);\r\nspin_unlock_irq(&np->lock);\r\nreturn rc;\r\n}\r\nstatic int netdev_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)\r\n{\r\nstruct epic_private *np = netdev_priv(dev);\r\nint rc;\r\nspin_lock_irq(&np->lock);\r\nrc = mii_ethtool_sset(&np->mii, cmd);\r\nspin_unlock_irq(&np->lock);\r\nreturn rc;\r\n}\r\nstatic int netdev_nway_reset(struct net_device *dev)\r\n{\r\nstruct epic_private *np = netdev_priv(dev);\r\nreturn mii_nway_restart(&np->mii);\r\n}\r\nstatic u32 netdev_get_link(struct net_device *dev)\r\n{\r\nstruct epic_private *np = netdev_priv(dev);\r\nreturn mii_link_ok(&np->mii);\r\n}\r\nstatic u32 netdev_get_msglevel(struct net_device *dev)\r\n{\r\nreturn debug;\r\n}\r\nstatic void netdev_set_msglevel(struct net_device *dev, u32 value)\r\n{\r\ndebug = value;\r\n}\r\nstatic int ethtool_begin(struct net_device *dev)\r\n{\r\nstruct epic_private *ep = netdev_priv(dev);\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\nif (!netif_running(dev)) {\r\new32(GENCTL, 0x0200);\r\new32(NVCTL, (er32(NVCTL) & ~0x003c) | 0x4800);\r\n}\r\nreturn 0;\r\n}\r\nstatic void ethtool_complete(struct net_device *dev)\r\n{\r\nstruct epic_private *ep = netdev_priv(dev);\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\nif (!netif_running(dev)) {\r\new32(GENCTL, 0x0008);\r\new32(NVCTL, (er32(NVCTL) & ~0x483c) | 0x0000);\r\n}\r\n}\r\nstatic int netdev_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)\r\n{\r\nstruct epic_private *np = netdev_priv(dev);\r\nvoid __iomem *ioaddr = np->ioaddr;\r\nstruct mii_ioctl_data *data = if_mii(rq);\r\nint rc;\r\nif (! netif_running(dev)) {\r\new32(GENCTL, 0x0200);\r\new32(NVCTL, (er32(NVCTL) & ~0x003c) | 0x4800);\r\n}\r\nspin_lock_irq(&np->lock);\r\nrc = generic_mii_ioctl(&np->mii, data, cmd, NULL);\r\nspin_unlock_irq(&np->lock);\r\nif (! netif_running(dev)) {\r\new32(GENCTL, 0x0008);\r\new32(NVCTL, (er32(NVCTL) & ~0x483c) | 0x0000);\r\n}\r\nreturn rc;\r\n}\r\nstatic void epic_remove_one(struct pci_dev *pdev)\r\n{\r\nstruct net_device *dev = pci_get_drvdata(pdev);\r\nstruct epic_private *ep = netdev_priv(dev);\r\npci_free_consistent(pdev, TX_TOTAL_SIZE, ep->tx_ring, ep->tx_ring_dma);\r\npci_free_consistent(pdev, RX_TOTAL_SIZE, ep->rx_ring, ep->rx_ring_dma);\r\nunregister_netdev(dev);\r\npci_iounmap(pdev, ep->ioaddr);\r\npci_release_regions(pdev);\r\nfree_netdev(dev);\r\npci_disable_device(pdev);\r\n}\r\nstatic int epic_suspend (struct pci_dev *pdev, pm_message_t state)\r\n{\r\nstruct net_device *dev = pci_get_drvdata(pdev);\r\nstruct epic_private *ep = netdev_priv(dev);\r\nvoid __iomem *ioaddr = ep->ioaddr;\r\nif (!netif_running(dev))\r\nreturn 0;\r\nepic_pause(dev);\r\new32(GENCTL, 0x0008);\r\nreturn 0;\r\n}\r\nstatic int epic_resume (struct pci_dev *pdev)\r\n{\r\nstruct net_device *dev = pci_get_drvdata(pdev);\r\nif (!netif_running(dev))\r\nreturn 0;\r\nepic_restart(dev);\r\nreturn 0;\r\n}\r\nstatic int __init epic_init (void)\r\n{\r\n#ifdef MODULE\r\npr_info("%s%s\n", version, version2);\r\n#endif\r\nreturn pci_register_driver(&epic_driver);\r\n}\r\nstatic void __exit epic_cleanup (void)\r\n{\r\npci_unregister_driver (&epic_driver);\r\n}
