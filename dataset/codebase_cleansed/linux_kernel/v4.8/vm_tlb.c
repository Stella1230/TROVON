void flush_tlb_range(struct vm_area_struct *vma, unsigned long start,\r\nunsigned long end)\r\n{\r\nstruct mm_struct *mm = vma->vm_mm;\r\nif (mm->context.ptbase == current->active_mm->context.ptbase)\r\n__vmclrmap((void *)start, end - start);\r\n}\r\nvoid flush_tlb_one(unsigned long vaddr)\r\n{\r\n__vmclrmap((void *)vaddr, PAGE_SIZE);\r\n}\r\nvoid tlb_flush_all(void)\r\n{\r\n__vmclrmap(0, 0xffff0000);\r\n}\r\nvoid flush_tlb_mm(struct mm_struct *mm)\r\n{\r\nif (current->active_mm->context.ptbase == mm->context.ptbase)\r\ntlb_flush_all();\r\n}\r\nvoid flush_tlb_page(struct vm_area_struct *vma, unsigned long vaddr)\r\n{\r\nstruct mm_struct *mm = vma->vm_mm;\r\nif (mm->context.ptbase == current->active_mm->context.ptbase)\r\n__vmclrmap((void *)vaddr, PAGE_SIZE);\r\n}\r\nvoid flush_tlb_kernel_range(unsigned long start, unsigned long end)\r\n{\r\n__vmclrmap((void *)start, end - start);\r\n}
