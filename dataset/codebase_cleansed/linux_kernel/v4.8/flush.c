void flush_cache_range(struct vm_area_struct *vma, unsigned long start,\r\nunsigned long end)\r\n{\r\nif (vma->vm_flags & VM_EXEC)\r\n__flush_icache_all();\r\n}\r\nstatic void sync_icache_aliases(void *kaddr, unsigned long len)\r\n{\r\nunsigned long addr = (unsigned long)kaddr;\r\nif (icache_is_aliasing()) {\r\n__clean_dcache_area_pou(kaddr, len);\r\n__flush_icache_all();\r\n} else {\r\nflush_icache_range(addr, addr + len);\r\n}\r\n}\r\nstatic void flush_ptrace_access(struct vm_area_struct *vma, struct page *page,\r\nunsigned long uaddr, void *kaddr,\r\nunsigned long len)\r\n{\r\nif (vma->vm_flags & VM_EXEC)\r\nsync_icache_aliases(kaddr, len);\r\n}\r\nvoid copy_to_user_page(struct vm_area_struct *vma, struct page *page,\r\nunsigned long uaddr, void *dst, const void *src,\r\nunsigned long len)\r\n{\r\nmemcpy(dst, src, len);\r\nflush_ptrace_access(vma, page, uaddr, dst, len);\r\n}\r\nvoid __sync_icache_dcache(pte_t pte, unsigned long addr)\r\n{\r\nstruct page *page = pte_page(pte);\r\nif (!test_and_set_bit(PG_dcache_clean, &page->flags))\r\nsync_icache_aliases(page_address(page),\r\nPAGE_SIZE << compound_order(page));\r\nelse if (icache_is_aivivt())\r\n__flush_icache_all();\r\n}\r\nvoid flush_dcache_page(struct page *page)\r\n{\r\nif (test_bit(PG_dcache_clean, &page->flags))\r\nclear_bit(PG_dcache_clean, &page->flags);\r\n}
