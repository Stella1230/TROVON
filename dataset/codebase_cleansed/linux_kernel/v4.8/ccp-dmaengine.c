static void ccp_free_cmd_resources(struct ccp_device *ccp,\r\nstruct list_head *list)\r\n{\r\nstruct ccp_dma_cmd *cmd, *ctmp;\r\nlist_for_each_entry_safe(cmd, ctmp, list, entry) {\r\nlist_del(&cmd->entry);\r\nkmem_cache_free(ccp->dma_cmd_cache, cmd);\r\n}\r\n}\r\nstatic void ccp_free_desc_resources(struct ccp_device *ccp,\r\nstruct list_head *list)\r\n{\r\nstruct ccp_dma_desc *desc, *dtmp;\r\nlist_for_each_entry_safe(desc, dtmp, list, entry) {\r\nccp_free_cmd_resources(ccp, &desc->active);\r\nccp_free_cmd_resources(ccp, &desc->pending);\r\nlist_del(&desc->entry);\r\nkmem_cache_free(ccp->dma_desc_cache, desc);\r\n}\r\n}\r\nstatic void ccp_free_chan_resources(struct dma_chan *dma_chan)\r\n{\r\nstruct ccp_dma_chan *chan = container_of(dma_chan, struct ccp_dma_chan,\r\ndma_chan);\r\nunsigned long flags;\r\ndev_dbg(chan->ccp->dev, "%s - chan=%p\n", __func__, chan);\r\nspin_lock_irqsave(&chan->lock, flags);\r\nccp_free_desc_resources(chan->ccp, &chan->complete);\r\nccp_free_desc_resources(chan->ccp, &chan->active);\r\nccp_free_desc_resources(chan->ccp, &chan->pending);\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\n}\r\nstatic void ccp_cleanup_desc_resources(struct ccp_device *ccp,\r\nstruct list_head *list)\r\n{\r\nstruct ccp_dma_desc *desc, *dtmp;\r\nlist_for_each_entry_safe_reverse(desc, dtmp, list, entry) {\r\nif (!async_tx_test_ack(&desc->tx_desc))\r\ncontinue;\r\ndev_dbg(ccp->dev, "%s - desc=%p\n", __func__, desc);\r\nccp_free_cmd_resources(ccp, &desc->active);\r\nccp_free_cmd_resources(ccp, &desc->pending);\r\nlist_del(&desc->entry);\r\nkmem_cache_free(ccp->dma_desc_cache, desc);\r\n}\r\n}\r\nstatic void ccp_do_cleanup(unsigned long data)\r\n{\r\nstruct ccp_dma_chan *chan = (struct ccp_dma_chan *)data;\r\nunsigned long flags;\r\ndev_dbg(chan->ccp->dev, "%s - chan=%s\n", __func__,\r\ndma_chan_name(&chan->dma_chan));\r\nspin_lock_irqsave(&chan->lock, flags);\r\nccp_cleanup_desc_resources(chan->ccp, &chan->complete);\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\n}\r\nstatic int ccp_issue_next_cmd(struct ccp_dma_desc *desc)\r\n{\r\nstruct ccp_dma_cmd *cmd;\r\nint ret;\r\ncmd = list_first_entry(&desc->pending, struct ccp_dma_cmd, entry);\r\nlist_move(&cmd->entry, &desc->active);\r\ndev_dbg(desc->ccp->dev, "%s - tx %d, cmd=%p\n", __func__,\r\ndesc->tx_desc.cookie, cmd);\r\nret = ccp_enqueue_cmd(&cmd->ccp_cmd);\r\nif (!ret || (ret == -EINPROGRESS) || (ret == -EBUSY))\r\nreturn 0;\r\ndev_dbg(desc->ccp->dev, "%s - error: ret=%d, tx %d, cmd=%p\n", __func__,\r\nret, desc->tx_desc.cookie, cmd);\r\nreturn ret;\r\n}\r\nstatic void ccp_free_active_cmd(struct ccp_dma_desc *desc)\r\n{\r\nstruct ccp_dma_cmd *cmd;\r\ncmd = list_first_entry_or_null(&desc->active, struct ccp_dma_cmd,\r\nentry);\r\nif (!cmd)\r\nreturn;\r\ndev_dbg(desc->ccp->dev, "%s - freeing tx %d cmd=%p\n",\r\n__func__, desc->tx_desc.cookie, cmd);\r\nlist_del(&cmd->entry);\r\nkmem_cache_free(desc->ccp->dma_cmd_cache, cmd);\r\n}\r\nstatic struct ccp_dma_desc *__ccp_next_dma_desc(struct ccp_dma_chan *chan,\r\nstruct ccp_dma_desc *desc)\r\n{\r\nif (desc)\r\nlist_move(&desc->entry, &chan->complete);\r\ndesc = list_first_entry_or_null(&chan->active, struct ccp_dma_desc,\r\nentry);\r\nreturn desc;\r\n}\r\nstatic struct ccp_dma_desc *ccp_handle_active_desc(struct ccp_dma_chan *chan,\r\nstruct ccp_dma_desc *desc)\r\n{\r\nstruct dma_async_tx_descriptor *tx_desc;\r\nunsigned long flags;\r\ndo {\r\nif (desc) {\r\nccp_free_active_cmd(desc);\r\nif (!list_empty(&desc->pending)) {\r\nif (desc->status != DMA_ERROR)\r\nreturn desc;\r\nccp_free_cmd_resources(desc->ccp,\r\n&desc->pending);\r\n}\r\ntx_desc = &desc->tx_desc;\r\n} else {\r\ntx_desc = NULL;\r\n}\r\nspin_lock_irqsave(&chan->lock, flags);\r\nif (desc) {\r\nif (desc->status != DMA_ERROR)\r\ndesc->status = DMA_COMPLETE;\r\ndev_dbg(desc->ccp->dev,\r\n"%s - tx %d complete, status=%u\n", __func__,\r\ndesc->tx_desc.cookie, desc->status);\r\ndma_cookie_complete(tx_desc);\r\n}\r\ndesc = __ccp_next_dma_desc(chan, desc);\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nif (tx_desc) {\r\nif (tx_desc->callback &&\r\n(tx_desc->flags & DMA_PREP_INTERRUPT))\r\ntx_desc->callback(tx_desc->callback_param);\r\ndma_run_dependencies(tx_desc);\r\n}\r\n} while (desc);\r\nreturn NULL;\r\n}\r\nstatic struct ccp_dma_desc *__ccp_pending_to_active(struct ccp_dma_chan *chan)\r\n{\r\nstruct ccp_dma_desc *desc;\r\nif (list_empty(&chan->pending))\r\nreturn NULL;\r\ndesc = list_empty(&chan->active)\r\n? list_first_entry(&chan->pending, struct ccp_dma_desc, entry)\r\n: NULL;\r\nlist_splice_tail_init(&chan->pending, &chan->active);\r\nreturn desc;\r\n}\r\nstatic void ccp_cmd_callback(void *data, int err)\r\n{\r\nstruct ccp_dma_desc *desc = data;\r\nstruct ccp_dma_chan *chan;\r\nint ret;\r\nif (err == -EINPROGRESS)\r\nreturn;\r\nchan = container_of(desc->tx_desc.chan, struct ccp_dma_chan,\r\ndma_chan);\r\ndev_dbg(chan->ccp->dev, "%s - tx %d callback, err=%d\n",\r\n__func__, desc->tx_desc.cookie, err);\r\nif (err)\r\ndesc->status = DMA_ERROR;\r\nwhile (true) {\r\ndesc = ccp_handle_active_desc(chan, desc);\r\nif (!desc || (chan->status == DMA_PAUSED))\r\nbreak;\r\nret = ccp_issue_next_cmd(desc);\r\nif (!ret)\r\nbreak;\r\ndesc->status = DMA_ERROR;\r\n}\r\ntasklet_schedule(&chan->cleanup_tasklet);\r\n}\r\nstatic dma_cookie_t ccp_tx_submit(struct dma_async_tx_descriptor *tx_desc)\r\n{\r\nstruct ccp_dma_desc *desc = container_of(tx_desc, struct ccp_dma_desc,\r\ntx_desc);\r\nstruct ccp_dma_chan *chan;\r\ndma_cookie_t cookie;\r\nunsigned long flags;\r\nchan = container_of(tx_desc->chan, struct ccp_dma_chan, dma_chan);\r\nspin_lock_irqsave(&chan->lock, flags);\r\ncookie = dma_cookie_assign(tx_desc);\r\nlist_add_tail(&desc->entry, &chan->pending);\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\ndev_dbg(chan->ccp->dev, "%s - added tx descriptor %d to pending list\n",\r\n__func__, cookie);\r\nreturn cookie;\r\n}\r\nstatic struct ccp_dma_cmd *ccp_alloc_dma_cmd(struct ccp_dma_chan *chan)\r\n{\r\nstruct ccp_dma_cmd *cmd;\r\ncmd = kmem_cache_alloc(chan->ccp->dma_cmd_cache, GFP_NOWAIT);\r\nif (cmd)\r\nmemset(cmd, 0, sizeof(*cmd));\r\nreturn cmd;\r\n}\r\nstatic struct ccp_dma_desc *ccp_alloc_dma_desc(struct ccp_dma_chan *chan,\r\nunsigned long flags)\r\n{\r\nstruct ccp_dma_desc *desc;\r\ndesc = kmem_cache_alloc(chan->ccp->dma_desc_cache, GFP_NOWAIT);\r\nif (!desc)\r\nreturn NULL;\r\nmemset(desc, 0, sizeof(*desc));\r\ndma_async_tx_descriptor_init(&desc->tx_desc, &chan->dma_chan);\r\ndesc->tx_desc.flags = flags;\r\ndesc->tx_desc.tx_submit = ccp_tx_submit;\r\ndesc->ccp = chan->ccp;\r\nINIT_LIST_HEAD(&desc->pending);\r\nINIT_LIST_HEAD(&desc->active);\r\ndesc->status = DMA_IN_PROGRESS;\r\nreturn desc;\r\n}\r\nstatic struct ccp_dma_desc *ccp_create_desc(struct dma_chan *dma_chan,\r\nstruct scatterlist *dst_sg,\r\nunsigned int dst_nents,\r\nstruct scatterlist *src_sg,\r\nunsigned int src_nents,\r\nunsigned long flags)\r\n{\r\nstruct ccp_dma_chan *chan = container_of(dma_chan, struct ccp_dma_chan,\r\ndma_chan);\r\nstruct ccp_device *ccp = chan->ccp;\r\nstruct ccp_dma_desc *desc;\r\nstruct ccp_dma_cmd *cmd;\r\nstruct ccp_cmd *ccp_cmd;\r\nstruct ccp_passthru_nomap_engine *ccp_pt;\r\nunsigned int src_offset, src_len;\r\nunsigned int dst_offset, dst_len;\r\nunsigned int len;\r\nunsigned long sflags;\r\nsize_t total_len;\r\nif (!dst_sg || !src_sg)\r\nreturn NULL;\r\nif (!dst_nents || !src_nents)\r\nreturn NULL;\r\ndesc = ccp_alloc_dma_desc(chan, flags);\r\nif (!desc)\r\nreturn NULL;\r\ntotal_len = 0;\r\nsrc_len = sg_dma_len(src_sg);\r\nsrc_offset = 0;\r\ndst_len = sg_dma_len(dst_sg);\r\ndst_offset = 0;\r\nwhile (true) {\r\nif (!src_len) {\r\nsrc_nents--;\r\nif (!src_nents)\r\nbreak;\r\nsrc_sg = sg_next(src_sg);\r\nif (!src_sg)\r\nbreak;\r\nsrc_len = sg_dma_len(src_sg);\r\nsrc_offset = 0;\r\ncontinue;\r\n}\r\nif (!dst_len) {\r\ndst_nents--;\r\nif (!dst_nents)\r\nbreak;\r\ndst_sg = sg_next(dst_sg);\r\nif (!dst_sg)\r\nbreak;\r\ndst_len = sg_dma_len(dst_sg);\r\ndst_offset = 0;\r\ncontinue;\r\n}\r\nlen = min(dst_len, src_len);\r\ncmd = ccp_alloc_dma_cmd(chan);\r\nif (!cmd)\r\ngoto err;\r\nccp_cmd = &cmd->ccp_cmd;\r\nccp_pt = &ccp_cmd->u.passthru_nomap;\r\nccp_cmd->flags = CCP_CMD_MAY_BACKLOG;\r\nccp_cmd->flags |= CCP_CMD_PASSTHRU_NO_DMA_MAP;\r\nccp_cmd->engine = CCP_ENGINE_PASSTHRU;\r\nccp_pt->bit_mod = CCP_PASSTHRU_BITWISE_NOOP;\r\nccp_pt->byte_swap = CCP_PASSTHRU_BYTESWAP_NOOP;\r\nccp_pt->src_dma = sg_dma_address(src_sg) + src_offset;\r\nccp_pt->dst_dma = sg_dma_address(dst_sg) + dst_offset;\r\nccp_pt->src_len = len;\r\nccp_pt->final = 1;\r\nccp_cmd->callback = ccp_cmd_callback;\r\nccp_cmd->data = desc;\r\nlist_add_tail(&cmd->entry, &desc->pending);\r\ndev_dbg(ccp->dev,\r\n"%s - cmd=%p, src=%pad, dst=%pad, len=%llu\n", __func__,\r\ncmd, &ccp_pt->src_dma,\r\n&ccp_pt->dst_dma, ccp_pt->src_len);\r\ntotal_len += len;\r\nsrc_len -= len;\r\nsrc_offset += len;\r\ndst_len -= len;\r\ndst_offset += len;\r\n}\r\ndesc->len = total_len;\r\nif (list_empty(&desc->pending))\r\ngoto err;\r\ndev_dbg(ccp->dev, "%s - desc=%p\n", __func__, desc);\r\nspin_lock_irqsave(&chan->lock, sflags);\r\nlist_add_tail(&desc->entry, &chan->pending);\r\nspin_unlock_irqrestore(&chan->lock, sflags);\r\nreturn desc;\r\nerr:\r\nccp_free_cmd_resources(ccp, &desc->pending);\r\nkmem_cache_free(ccp->dma_desc_cache, desc);\r\nreturn NULL;\r\n}\r\nstatic struct dma_async_tx_descriptor *ccp_prep_dma_memcpy(\r\nstruct dma_chan *dma_chan, dma_addr_t dst, dma_addr_t src, size_t len,\r\nunsigned long flags)\r\n{\r\nstruct ccp_dma_chan *chan = container_of(dma_chan, struct ccp_dma_chan,\r\ndma_chan);\r\nstruct ccp_dma_desc *desc;\r\nstruct scatterlist dst_sg, src_sg;\r\ndev_dbg(chan->ccp->dev,\r\n"%s - src=%pad, dst=%pad, len=%zu, flags=%#lx\n",\r\n__func__, &src, &dst, len, flags);\r\nsg_init_table(&dst_sg, 1);\r\nsg_dma_address(&dst_sg) = dst;\r\nsg_dma_len(&dst_sg) = len;\r\nsg_init_table(&src_sg, 1);\r\nsg_dma_address(&src_sg) = src;\r\nsg_dma_len(&src_sg) = len;\r\ndesc = ccp_create_desc(dma_chan, &dst_sg, 1, &src_sg, 1, flags);\r\nif (!desc)\r\nreturn NULL;\r\nreturn &desc->tx_desc;\r\n}\r\nstatic struct dma_async_tx_descriptor *ccp_prep_dma_sg(\r\nstruct dma_chan *dma_chan, struct scatterlist *dst_sg,\r\nunsigned int dst_nents, struct scatterlist *src_sg,\r\nunsigned int src_nents, unsigned long flags)\r\n{\r\nstruct ccp_dma_chan *chan = container_of(dma_chan, struct ccp_dma_chan,\r\ndma_chan);\r\nstruct ccp_dma_desc *desc;\r\ndev_dbg(chan->ccp->dev,\r\n"%s - src=%p, src_nents=%u dst=%p, dst_nents=%u, flags=%#lx\n",\r\n__func__, src_sg, src_nents, dst_sg, dst_nents, flags);\r\ndesc = ccp_create_desc(dma_chan, dst_sg, dst_nents, src_sg, src_nents,\r\nflags);\r\nif (!desc)\r\nreturn NULL;\r\nreturn &desc->tx_desc;\r\n}\r\nstatic struct dma_async_tx_descriptor *ccp_prep_dma_interrupt(\r\nstruct dma_chan *dma_chan, unsigned long flags)\r\n{\r\nstruct ccp_dma_chan *chan = container_of(dma_chan, struct ccp_dma_chan,\r\ndma_chan);\r\nstruct ccp_dma_desc *desc;\r\ndesc = ccp_alloc_dma_desc(chan, flags);\r\nif (!desc)\r\nreturn NULL;\r\nreturn &desc->tx_desc;\r\n}\r\nstatic void ccp_issue_pending(struct dma_chan *dma_chan)\r\n{\r\nstruct ccp_dma_chan *chan = container_of(dma_chan, struct ccp_dma_chan,\r\ndma_chan);\r\nstruct ccp_dma_desc *desc;\r\nunsigned long flags;\r\ndev_dbg(chan->ccp->dev, "%s\n", __func__);\r\nspin_lock_irqsave(&chan->lock, flags);\r\ndesc = __ccp_pending_to_active(chan);\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nif (desc)\r\nccp_cmd_callback(desc, 0);\r\n}\r\nstatic enum dma_status ccp_tx_status(struct dma_chan *dma_chan,\r\ndma_cookie_t cookie,\r\nstruct dma_tx_state *state)\r\n{\r\nstruct ccp_dma_chan *chan = container_of(dma_chan, struct ccp_dma_chan,\r\ndma_chan);\r\nstruct ccp_dma_desc *desc;\r\nenum dma_status ret;\r\nunsigned long flags;\r\nif (chan->status == DMA_PAUSED) {\r\nret = DMA_PAUSED;\r\ngoto out;\r\n}\r\nret = dma_cookie_status(dma_chan, cookie, state);\r\nif (ret == DMA_COMPLETE) {\r\nspin_lock_irqsave(&chan->lock, flags);\r\nlist_for_each_entry(desc, &chan->complete, entry) {\r\nif (desc->tx_desc.cookie != cookie)\r\ncontinue;\r\nret = desc->status;\r\nbreak;\r\n}\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\n}\r\nout:\r\ndev_dbg(chan->ccp->dev, "%s - %u\n", __func__, ret);\r\nreturn ret;\r\n}\r\nstatic int ccp_pause(struct dma_chan *dma_chan)\r\n{\r\nstruct ccp_dma_chan *chan = container_of(dma_chan, struct ccp_dma_chan,\r\ndma_chan);\r\nchan->status = DMA_PAUSED;\r\nreturn 0;\r\n}\r\nstatic int ccp_resume(struct dma_chan *dma_chan)\r\n{\r\nstruct ccp_dma_chan *chan = container_of(dma_chan, struct ccp_dma_chan,\r\ndma_chan);\r\nstruct ccp_dma_desc *desc;\r\nunsigned long flags;\r\nspin_lock_irqsave(&chan->lock, flags);\r\ndesc = list_first_entry_or_null(&chan->active, struct ccp_dma_desc,\r\nentry);\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nchan->status = DMA_IN_PROGRESS;\r\nif (desc)\r\nccp_cmd_callback(desc, 0);\r\nreturn 0;\r\n}\r\nstatic int ccp_terminate_all(struct dma_chan *dma_chan)\r\n{\r\nstruct ccp_dma_chan *chan = container_of(dma_chan, struct ccp_dma_chan,\r\ndma_chan);\r\nunsigned long flags;\r\ndev_dbg(chan->ccp->dev, "%s\n", __func__);\r\nspin_lock_irqsave(&chan->lock, flags);\r\nccp_free_desc_resources(chan->ccp, &chan->active);\r\nccp_free_desc_resources(chan->ccp, &chan->pending);\r\nspin_unlock_irqrestore(&chan->lock, flags);\r\nreturn 0;\r\n}\r\nint ccp_dmaengine_register(struct ccp_device *ccp)\r\n{\r\nstruct ccp_dma_chan *chan;\r\nstruct dma_device *dma_dev = &ccp->dma_dev;\r\nstruct dma_chan *dma_chan;\r\nchar *dma_cmd_cache_name;\r\nchar *dma_desc_cache_name;\r\nunsigned int i;\r\nint ret;\r\nccp->ccp_dma_chan = devm_kcalloc(ccp->dev, ccp->cmd_q_count,\r\nsizeof(*(ccp->ccp_dma_chan)),\r\nGFP_KERNEL);\r\nif (!ccp->ccp_dma_chan)\r\nreturn -ENOMEM;\r\ndma_cmd_cache_name = devm_kasprintf(ccp->dev, GFP_KERNEL,\r\n"%s-dmaengine-cmd-cache",\r\nccp->name);\r\nif (!dma_cmd_cache_name)\r\nreturn -ENOMEM;\r\nccp->dma_cmd_cache = kmem_cache_create(dma_cmd_cache_name,\r\nsizeof(struct ccp_dma_cmd),\r\nsizeof(void *),\r\nSLAB_HWCACHE_ALIGN, NULL);\r\nif (!ccp->dma_cmd_cache)\r\nreturn -ENOMEM;\r\ndma_desc_cache_name = devm_kasprintf(ccp->dev, GFP_KERNEL,\r\n"%s-dmaengine-desc-cache",\r\nccp->name);\r\nif (!dma_cmd_cache_name)\r\nreturn -ENOMEM;\r\nccp->dma_desc_cache = kmem_cache_create(dma_desc_cache_name,\r\nsizeof(struct ccp_dma_desc),\r\nsizeof(void *),\r\nSLAB_HWCACHE_ALIGN, NULL);\r\nif (!ccp->dma_desc_cache) {\r\nret = -ENOMEM;\r\ngoto err_cache;\r\n}\r\ndma_dev->dev = ccp->dev;\r\ndma_dev->src_addr_widths = CCP_DMA_WIDTH(dma_get_mask(ccp->dev));\r\ndma_dev->dst_addr_widths = CCP_DMA_WIDTH(dma_get_mask(ccp->dev));\r\ndma_dev->directions = DMA_MEM_TO_MEM;\r\ndma_dev->residue_granularity = DMA_RESIDUE_GRANULARITY_DESCRIPTOR;\r\ndma_cap_set(DMA_MEMCPY, dma_dev->cap_mask);\r\ndma_cap_set(DMA_SG, dma_dev->cap_mask);\r\ndma_cap_set(DMA_INTERRUPT, dma_dev->cap_mask);\r\nINIT_LIST_HEAD(&dma_dev->channels);\r\nfor (i = 0; i < ccp->cmd_q_count; i++) {\r\nchan = ccp->ccp_dma_chan + i;\r\ndma_chan = &chan->dma_chan;\r\nchan->ccp = ccp;\r\nspin_lock_init(&chan->lock);\r\nINIT_LIST_HEAD(&chan->pending);\r\nINIT_LIST_HEAD(&chan->active);\r\nINIT_LIST_HEAD(&chan->complete);\r\ntasklet_init(&chan->cleanup_tasklet, ccp_do_cleanup,\r\n(unsigned long)chan);\r\ndma_chan->device = dma_dev;\r\ndma_cookie_init(dma_chan);\r\nlist_add_tail(&dma_chan->device_node, &dma_dev->channels);\r\n}\r\ndma_dev->device_free_chan_resources = ccp_free_chan_resources;\r\ndma_dev->device_prep_dma_memcpy = ccp_prep_dma_memcpy;\r\ndma_dev->device_prep_dma_sg = ccp_prep_dma_sg;\r\ndma_dev->device_prep_dma_interrupt = ccp_prep_dma_interrupt;\r\ndma_dev->device_issue_pending = ccp_issue_pending;\r\ndma_dev->device_tx_status = ccp_tx_status;\r\ndma_dev->device_pause = ccp_pause;\r\ndma_dev->device_resume = ccp_resume;\r\ndma_dev->device_terminate_all = ccp_terminate_all;\r\nret = dma_async_device_register(dma_dev);\r\nif (ret)\r\ngoto err_reg;\r\nreturn 0;\r\nerr_reg:\r\nkmem_cache_destroy(ccp->dma_desc_cache);\r\nerr_cache:\r\nkmem_cache_destroy(ccp->dma_cmd_cache);\r\nreturn ret;\r\n}\r\nvoid ccp_dmaengine_unregister(struct ccp_device *ccp)\r\n{\r\nstruct dma_device *dma_dev = &ccp->dma_dev;\r\ndma_async_device_unregister(dma_dev);\r\nkmem_cache_destroy(ccp->dma_desc_cache);\r\nkmem_cache_destroy(ccp->dma_cmd_cache);\r\n}
