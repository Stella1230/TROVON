static u64 bgx_reg_read(struct bgx *bgx, u8 lmac, u64 offset)\r\n{\r\nvoid __iomem *addr = bgx->reg_base + ((u32)lmac << 20) + offset;\r\nreturn readq_relaxed(addr);\r\n}\r\nstatic void bgx_reg_write(struct bgx *bgx, u8 lmac, u64 offset, u64 val)\r\n{\r\nvoid __iomem *addr = bgx->reg_base + ((u32)lmac << 20) + offset;\r\nwriteq_relaxed(val, addr);\r\n}\r\nstatic void bgx_reg_modify(struct bgx *bgx, u8 lmac, u64 offset, u64 val)\r\n{\r\nvoid __iomem *addr = bgx->reg_base + ((u32)lmac << 20) + offset;\r\nwriteq_relaxed(val | readq_relaxed(addr), addr);\r\n}\r\nstatic int bgx_poll_reg(struct bgx *bgx, u8 lmac, u64 reg, u64 mask, bool zero)\r\n{\r\nint timeout = 100;\r\nu64 reg_val;\r\nwhile (timeout) {\r\nreg_val = bgx_reg_read(bgx, lmac, reg);\r\nif (zero && !(reg_val & mask))\r\nreturn 0;\r\nif (!zero && (reg_val & mask))\r\nreturn 0;\r\nusleep_range(1000, 2000);\r\ntimeout--;\r\n}\r\nreturn 1;\r\n}\r\nunsigned bgx_get_map(int node)\r\n{\r\nint i;\r\nunsigned map = 0;\r\nfor (i = 0; i < MAX_BGX_PER_CN88XX; i++) {\r\nif (bgx_vnic[(node * MAX_BGX_PER_CN88XX) + i])\r\nmap |= (1 << i);\r\n}\r\nreturn map;\r\n}\r\nint bgx_get_lmac_count(int node, int bgx_idx)\r\n{\r\nstruct bgx *bgx;\r\nbgx = bgx_vnic[(node * MAX_BGX_PER_CN88XX) + bgx_idx];\r\nif (bgx)\r\nreturn bgx->lmac_count;\r\nreturn 0;\r\n}\r\nvoid bgx_get_lmac_link_state(int node, int bgx_idx, int lmacid, void *status)\r\n{\r\nstruct bgx_link_status *link = (struct bgx_link_status *)status;\r\nstruct bgx *bgx;\r\nstruct lmac *lmac;\r\nbgx = bgx_vnic[(node * MAX_BGX_PER_CN88XX) + bgx_idx];\r\nif (!bgx)\r\nreturn;\r\nlmac = &bgx->lmac[lmacid];\r\nlink->link_up = lmac->link_up;\r\nlink->duplex = lmac->last_duplex;\r\nlink->speed = lmac->last_speed;\r\n}\r\nconst u8 *bgx_get_lmac_mac(int node, int bgx_idx, int lmacid)\r\n{\r\nstruct bgx *bgx = bgx_vnic[(node * MAX_BGX_PER_CN88XX) + bgx_idx];\r\nif (bgx)\r\nreturn bgx->lmac[lmacid].mac;\r\nreturn NULL;\r\n}\r\nvoid bgx_set_lmac_mac(int node, int bgx_idx, int lmacid, const u8 *mac)\r\n{\r\nstruct bgx *bgx = bgx_vnic[(node * MAX_BGX_PER_CN88XX) + bgx_idx];\r\nif (!bgx)\r\nreturn;\r\nether_addr_copy(bgx->lmac[lmacid].mac, mac);\r\n}\r\nvoid bgx_lmac_rx_tx_enable(int node, int bgx_idx, int lmacid, bool enable)\r\n{\r\nstruct bgx *bgx = bgx_vnic[(node * MAX_BGX_PER_CN88XX) + bgx_idx];\r\nu64 cfg;\r\nif (!bgx)\r\nreturn;\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_CMRX_CFG);\r\nif (enable)\r\ncfg |= CMR_PKT_RX_EN | CMR_PKT_TX_EN;\r\nelse\r\ncfg &= ~(CMR_PKT_RX_EN | CMR_PKT_TX_EN);\r\nbgx_reg_write(bgx, lmacid, BGX_CMRX_CFG, cfg);\r\n}\r\nstatic void bgx_sgmii_change_link_state(struct lmac *lmac)\r\n{\r\nstruct bgx *bgx = lmac->bgx;\r\nu64 cmr_cfg;\r\nu64 port_cfg = 0;\r\nu64 misc_ctl = 0;\r\ncmr_cfg = bgx_reg_read(bgx, lmac->lmacid, BGX_CMRX_CFG);\r\ncmr_cfg &= ~CMR_EN;\r\nbgx_reg_write(bgx, lmac->lmacid, BGX_CMRX_CFG, cmr_cfg);\r\nport_cfg = bgx_reg_read(bgx, lmac->lmacid, BGX_GMP_GMI_PRTX_CFG);\r\nmisc_ctl = bgx_reg_read(bgx, lmac->lmacid, BGX_GMP_PCS_MISCX_CTL);\r\nif (lmac->link_up) {\r\nmisc_ctl &= ~PCS_MISC_CTL_GMX_ENO;\r\nport_cfg &= ~GMI_PORT_CFG_DUPLEX;\r\nport_cfg |= (lmac->last_duplex << 2);\r\n} else {\r\nmisc_ctl |= PCS_MISC_CTL_GMX_ENO;\r\n}\r\nswitch (lmac->last_speed) {\r\ncase 10:\r\nport_cfg &= ~GMI_PORT_CFG_SPEED;\r\nport_cfg |= GMI_PORT_CFG_SPEED_MSB;\r\nport_cfg &= ~GMI_PORT_CFG_SLOT_TIME;\r\nmisc_ctl &= ~PCS_MISC_CTL_SAMP_PT_MASK;\r\nmisc_ctl |= 50;\r\nbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_GMI_TXX_SLOT, 64);\r\nbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_GMI_TXX_BURST, 0);\r\nbreak;\r\ncase 100:\r\nport_cfg &= ~GMI_PORT_CFG_SPEED;\r\nport_cfg &= ~GMI_PORT_CFG_SPEED_MSB;\r\nport_cfg &= ~GMI_PORT_CFG_SLOT_TIME;\r\nmisc_ctl &= ~PCS_MISC_CTL_SAMP_PT_MASK;\r\nmisc_ctl |= 5;\r\nbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_GMI_TXX_SLOT, 64);\r\nbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_GMI_TXX_BURST, 0);\r\nbreak;\r\ncase 1000:\r\nport_cfg |= GMI_PORT_CFG_SPEED;\r\nport_cfg &= ~GMI_PORT_CFG_SPEED_MSB;\r\nport_cfg |= GMI_PORT_CFG_SLOT_TIME;\r\nmisc_ctl &= ~PCS_MISC_CTL_SAMP_PT_MASK;\r\nmisc_ctl |= 1;\r\nbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_GMI_TXX_SLOT, 512);\r\nif (lmac->last_duplex)\r\nbgx_reg_write(bgx, lmac->lmacid,\r\nBGX_GMP_GMI_TXX_BURST, 0);\r\nelse\r\nbgx_reg_write(bgx, lmac->lmacid,\r\nBGX_GMP_GMI_TXX_BURST, 8192);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_PCS_MISCX_CTL, misc_ctl);\r\nbgx_reg_write(bgx, lmac->lmacid, BGX_GMP_GMI_PRTX_CFG, port_cfg);\r\nport_cfg = bgx_reg_read(bgx, lmac->lmacid, BGX_GMP_GMI_PRTX_CFG);\r\ncmr_cfg |= CMR_EN;\r\nbgx_reg_write(bgx, lmac->lmacid, BGX_CMRX_CFG, cmr_cfg);\r\n}\r\nstatic void bgx_lmac_handler(struct net_device *netdev)\r\n{\r\nstruct lmac *lmac = container_of(netdev, struct lmac, netdev);\r\nstruct phy_device *phydev;\r\nint link_changed = 0;\r\nif (!lmac)\r\nreturn;\r\nphydev = lmac->phydev;\r\nif (!phydev->link && lmac->last_link)\r\nlink_changed = -1;\r\nif (phydev->link &&\r\n(lmac->last_duplex != phydev->duplex ||\r\nlmac->last_link != phydev->link ||\r\nlmac->last_speed != phydev->speed)) {\r\nlink_changed = 1;\r\n}\r\nlmac->last_link = phydev->link;\r\nlmac->last_speed = phydev->speed;\r\nlmac->last_duplex = phydev->duplex;\r\nif (!link_changed)\r\nreturn;\r\nif (link_changed > 0)\r\nlmac->link_up = true;\r\nelse\r\nlmac->link_up = false;\r\nif (lmac->is_sgmii)\r\nbgx_sgmii_change_link_state(lmac);\r\nelse\r\nbgx_xaui_check_link(lmac);\r\n}\r\nu64 bgx_get_rx_stats(int node, int bgx_idx, int lmac, int idx)\r\n{\r\nstruct bgx *bgx;\r\nbgx = bgx_vnic[(node * MAX_BGX_PER_CN88XX) + bgx_idx];\r\nif (!bgx)\r\nreturn 0;\r\nif (idx > 8)\r\nlmac = 0;\r\nreturn bgx_reg_read(bgx, lmac, BGX_CMRX_RX_STAT0 + (idx * 8));\r\n}\r\nu64 bgx_get_tx_stats(int node, int bgx_idx, int lmac, int idx)\r\n{\r\nstruct bgx *bgx;\r\nbgx = bgx_vnic[(node * MAX_BGX_PER_CN88XX) + bgx_idx];\r\nif (!bgx)\r\nreturn 0;\r\nreturn bgx_reg_read(bgx, lmac, BGX_CMRX_TX_STAT0 + (idx * 8));\r\n}\r\nstatic void bgx_flush_dmac_addrs(struct bgx *bgx, int lmac)\r\n{\r\nu64 offset;\r\nwhile (bgx->lmac[lmac].dmac > 0) {\r\noffset = ((bgx->lmac[lmac].dmac - 1) * sizeof(u64)) +\r\n(lmac * MAX_DMAC_PER_LMAC * sizeof(u64));\r\nbgx_reg_write(bgx, 0, BGX_CMR_RX_DMACX_CAM + offset, 0);\r\nbgx->lmac[lmac].dmac--;\r\n}\r\n}\r\nvoid bgx_lmac_internal_loopback(int node, int bgx_idx,\r\nint lmac_idx, bool enable)\r\n{\r\nstruct bgx *bgx;\r\nstruct lmac *lmac;\r\nu64 cfg;\r\nbgx = bgx_vnic[(node * MAX_BGX_PER_CN88XX) + bgx_idx];\r\nif (!bgx)\r\nreturn;\r\nlmac = &bgx->lmac[lmac_idx];\r\nif (lmac->is_sgmii) {\r\ncfg = bgx_reg_read(bgx, lmac_idx, BGX_GMP_PCS_MRX_CTL);\r\nif (enable)\r\ncfg |= PCS_MRX_CTL_LOOPBACK1;\r\nelse\r\ncfg &= ~PCS_MRX_CTL_LOOPBACK1;\r\nbgx_reg_write(bgx, lmac_idx, BGX_GMP_PCS_MRX_CTL, cfg);\r\n} else {\r\ncfg = bgx_reg_read(bgx, lmac_idx, BGX_SPUX_CONTROL1);\r\nif (enable)\r\ncfg |= SPU_CTL_LOOPBACK;\r\nelse\r\ncfg &= ~SPU_CTL_LOOPBACK;\r\nbgx_reg_write(bgx, lmac_idx, BGX_SPUX_CONTROL1, cfg);\r\n}\r\n}\r\nstatic int bgx_lmac_sgmii_init(struct bgx *bgx, int lmacid)\r\n{\r\nu64 cfg;\r\nbgx_reg_modify(bgx, lmacid, BGX_GMP_GMI_TXX_THRESH, 0x30);\r\nbgx_reg_modify(bgx, lmacid, BGX_GMP_GMI_RXX_JABBER, MAX_FRAME_SIZE);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_GMP_GMI_TXX_APPEND);\r\nif (cfg & 1)\r\nbgx_reg_write(bgx, lmacid, BGX_GMP_GMI_TXX_SGMII_CTL, 0);\r\nbgx_reg_modify(bgx, lmacid, BGX_CMRX_CFG, CMR_EN);\r\nbgx_reg_modify(bgx, lmacid, BGX_GMP_PCS_MRX_CTL, PCS_MRX_CTL_RESET);\r\nif (bgx_poll_reg(bgx, lmacid, BGX_GMP_PCS_MRX_CTL,\r\nPCS_MRX_CTL_RESET, true)) {\r\ndev_err(&bgx->pdev->dev, "BGX PCS reset not completed\n");\r\nreturn -1;\r\n}\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_GMP_PCS_MRX_CTL);\r\ncfg &= ~PCS_MRX_CTL_PWR_DN;\r\ncfg |= (PCS_MRX_CTL_RST_AN | PCS_MRX_CTL_AN_EN);\r\nbgx_reg_write(bgx, lmacid, BGX_GMP_PCS_MRX_CTL, cfg);\r\nif (bgx_poll_reg(bgx, lmacid, BGX_GMP_PCS_MRX_STATUS,\r\nPCS_MRX_STATUS_AN_CPT, false)) {\r\ndev_err(&bgx->pdev->dev, "BGX AN_CPT not completed\n");\r\nreturn -1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int bgx_lmac_xaui_init(struct bgx *bgx, int lmacid, int lmac_type)\r\n{\r\nu64 cfg;\r\nbgx_reg_modify(bgx, lmacid, BGX_SPUX_CONTROL1, SPU_CTL_RESET);\r\nif (bgx_poll_reg(bgx, lmacid, BGX_SPUX_CONTROL1, SPU_CTL_RESET, true)) {\r\ndev_err(&bgx->pdev->dev, "BGX SPU reset not completed\n");\r\nreturn -1;\r\n}\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_CMRX_CFG);\r\ncfg &= ~CMR_EN;\r\nbgx_reg_write(bgx, lmacid, BGX_CMRX_CFG, cfg);\r\nbgx_reg_modify(bgx, lmacid, BGX_SPUX_CONTROL1, SPU_CTL_LOW_POWER);\r\nif (bgx->lmac_type != BGX_MODE_RXAUI)\r\nbgx_reg_modify(bgx, lmacid,\r\nBGX_SPUX_MISC_CONTROL, SPU_MISC_CTL_RX_DIS);\r\nelse\r\nbgx_reg_modify(bgx, lmacid, BGX_SPUX_MISC_CONTROL,\r\nSPU_MISC_CTL_RX_DIS | SPU_MISC_CTL_INTLV_RDISP);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_RX_INT);\r\nbgx_reg_write(bgx, lmacid, BGX_SMUX_RX_INT, cfg);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_TX_INT);\r\nbgx_reg_write(bgx, lmacid, BGX_SMUX_TX_INT, cfg);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_INT);\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_INT, cfg);\r\nif (bgx->use_training) {\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_BR_PMD_LP_CUP, 0x00);\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_BR_PMD_LD_CUP, 0x00);\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_BR_PMD_LD_REP, 0x00);\r\nbgx_reg_modify(bgx, lmacid,\r\nBGX_SPUX_BR_PMD_CRTL, SPU_PMD_CRTL_TRAIN_EN);\r\n}\r\nbgx_reg_modify(bgx, lmacid, BGX_SMUX_TX_APPEND, SMU_TX_APPEND_FCS_D);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_FEC_CONTROL);\r\ncfg &= ~SPU_FEC_CTL_FEC_EN;\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_FEC_CONTROL, cfg);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_AN_CONTROL);\r\ncfg = cfg & ~(SPU_AN_CTL_AN_EN | SPU_AN_CTL_XNP_EN);\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_AN_CONTROL, cfg);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_AN_ADV);\r\nif (bgx->lmac_type == BGX_MODE_10G_KR)\r\ncfg |= (1 << 23);\r\nelse if (bgx->lmac_type == BGX_MODE_40G_KR)\r\ncfg |= (1 << 24);\r\nelse\r\ncfg &= ~((1 << 23) | (1 << 24));\r\ncfg = cfg & (~((1ULL << 25) | (1ULL << 22) | (1ULL << 12)));\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_AN_ADV, cfg);\r\ncfg = bgx_reg_read(bgx, 0, BGX_SPU_DBG_CONTROL);\r\ncfg &= ~SPU_DBG_CTL_AN_ARB_LINK_CHK_EN;\r\nbgx_reg_write(bgx, 0, BGX_SPU_DBG_CONTROL, cfg);\r\nbgx_reg_modify(bgx, lmacid, BGX_CMRX_CFG, CMR_EN);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_CONTROL1);\r\ncfg &= ~SPU_CTL_LOW_POWER;\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_CONTROL1, cfg);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_TX_CTL);\r\ncfg &= ~SMU_TX_CTL_UNI_EN;\r\ncfg |= SMU_TX_CTL_DIC_EN;\r\nbgx_reg_write(bgx, lmacid, BGX_SMUX_TX_CTL, cfg);\r\nbgx_reg_modify(bgx, lmacid, BGX_SMUX_TX_THRESH, (0x100 - 1));\r\nbgx_reg_modify(bgx, lmacid, BGX_SMUX_RX_JABBER, MAX_FRAME_SIZE);\r\nreturn 0;\r\n}\r\nstatic int bgx_xaui_check_link(struct lmac *lmac)\r\n{\r\nstruct bgx *bgx = lmac->bgx;\r\nint lmacid = lmac->lmacid;\r\nint lmac_type = bgx->lmac_type;\r\nu64 cfg;\r\nbgx_reg_modify(bgx, lmacid, BGX_SPUX_MISC_CONTROL, SPU_MISC_CTL_RX_DIS);\r\nif (bgx->use_training) {\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_INT);\r\nif (!(cfg & (1ull << 13))) {\r\ncfg = (1ull << 13) | (1ull << 14);\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_INT, cfg);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_BR_PMD_CRTL);\r\ncfg |= (1ull << 0);\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_BR_PMD_CRTL, cfg);\r\nreturn -1;\r\n}\r\n}\r\nif (bgx_poll_reg(bgx, lmacid, BGX_SPUX_CONTROL1, SPU_CTL_RESET, true)) {\r\ndev_err(&bgx->pdev->dev, "BGX SPU reset not completed\n");\r\nreturn -1;\r\n}\r\nif ((lmac_type == BGX_MODE_10G_KR) || (lmac_type == BGX_MODE_XFI) ||\r\n(lmac_type == BGX_MODE_40G_KR) || (lmac_type == BGX_MODE_XLAUI)) {\r\nif (bgx_poll_reg(bgx, lmacid, BGX_SPUX_BR_STATUS1,\r\nSPU_BR_STATUS_BLK_LOCK, false)) {\r\ndev_err(&bgx->pdev->dev,\r\n"SPU_BR_STATUS_BLK_LOCK not completed\n");\r\nreturn -1;\r\n}\r\n} else {\r\nif (bgx_poll_reg(bgx, lmacid, BGX_SPUX_BX_STATUS,\r\nSPU_BX_STATUS_RX_ALIGN, false)) {\r\ndev_err(&bgx->pdev->dev,\r\n"SPU_BX_STATUS_RX_ALIGN not completed\n");\r\nreturn -1;\r\n}\r\n}\r\nif (bgx_reg_read(bgx, lmacid, BGX_SPUX_STATUS2) & SPU_STATUS2_RCVFLT)\r\nbgx_reg_modify(bgx, lmacid,\r\nBGX_SPUX_STATUS2, SPU_STATUS2_RCVFLT);\r\nif (bgx_reg_read(bgx, lmacid, BGX_SPUX_STATUS2) & SPU_STATUS2_RCVFLT) {\r\ndev_err(&bgx->pdev->dev, "Receive fault, retry training\n");\r\nif (bgx->use_training) {\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_INT);\r\nif (!(cfg & (1ull << 13))) {\r\ncfg = (1ull << 13) | (1ull << 14);\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_INT, cfg);\r\ncfg = bgx_reg_read(bgx, lmacid,\r\nBGX_SPUX_BR_PMD_CRTL);\r\ncfg |= (1ull << 0);\r\nbgx_reg_write(bgx, lmacid,\r\nBGX_SPUX_BR_PMD_CRTL, cfg);\r\nreturn -1;\r\n}\r\n}\r\nreturn -1;\r\n}\r\nif (bgx_poll_reg(bgx, lmacid, BGX_SMUX_CTL, SMU_CTL_RX_IDLE, false)) {\r\ndev_err(&bgx->pdev->dev, "SMU RX not idle\n");\r\nreturn -1;\r\n}\r\nif (bgx_poll_reg(bgx, lmacid, BGX_SMUX_CTL, SMU_CTL_TX_IDLE, false)) {\r\ndev_err(&bgx->pdev->dev, "SMU TX not idle\n");\r\nreturn -1;\r\n}\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SPUX_MISC_CONTROL);\r\ncfg &= ~SPU_MISC_CTL_RX_DIS;\r\nbgx_reg_write(bgx, lmacid, BGX_SPUX_MISC_CONTROL, cfg);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_RX_CTL);\r\ncfg &= SMU_RX_CTL_STATUS;\r\nif (!cfg)\r\nreturn 0;\r\nbgx_lmac_xaui_init(bgx, lmacid, bgx->lmac_type);\r\nreturn -1;\r\n}\r\nstatic void bgx_poll_for_link(struct work_struct *work)\r\n{\r\nstruct lmac *lmac;\r\nu64 spu_link, smu_link;\r\nlmac = container_of(work, struct lmac, dwork.work);\r\nbgx_reg_modify(lmac->bgx, lmac->lmacid,\r\nBGX_SPUX_STATUS1, SPU_STATUS1_RCV_LNK);\r\nbgx_poll_reg(lmac->bgx, lmac->lmacid, BGX_SPUX_STATUS1,\r\nSPU_STATUS1_RCV_LNK, false);\r\nspu_link = bgx_reg_read(lmac->bgx, lmac->lmacid, BGX_SPUX_STATUS1);\r\nsmu_link = bgx_reg_read(lmac->bgx, lmac->lmacid, BGX_SMUX_RX_CTL);\r\nif ((spu_link & SPU_STATUS1_RCV_LNK) &&\r\n!(smu_link & SMU_RX_CTL_STATUS)) {\r\nlmac->link_up = 1;\r\nif (lmac->bgx->lmac_type == BGX_MODE_XLAUI)\r\nlmac->last_speed = 40000;\r\nelse\r\nlmac->last_speed = 10000;\r\nlmac->last_duplex = 1;\r\n} else {\r\nlmac->link_up = 0;\r\nlmac->last_speed = SPEED_UNKNOWN;\r\nlmac->last_duplex = DUPLEX_UNKNOWN;\r\n}\r\nif (lmac->last_link != lmac->link_up) {\r\nif (lmac->link_up) {\r\nif (bgx_xaui_check_link(lmac)) {\r\nlmac->link_up = 0;\r\nlmac->last_speed = SPEED_UNKNOWN;\r\nlmac->last_duplex = DUPLEX_UNKNOWN;\r\n}\r\n}\r\nlmac->last_link = lmac->link_up;\r\n}\r\nqueue_delayed_work(lmac->check_link, &lmac->dwork, HZ * 2);\r\n}\r\nstatic int bgx_lmac_enable(struct bgx *bgx, u8 lmacid)\r\n{\r\nstruct lmac *lmac;\r\nu64 cfg;\r\nlmac = &bgx->lmac[lmacid];\r\nlmac->bgx = bgx;\r\nif (bgx->lmac_type == BGX_MODE_SGMII) {\r\nlmac->is_sgmii = 1;\r\nif (bgx_lmac_sgmii_init(bgx, lmacid))\r\nreturn -1;\r\n} else {\r\nlmac->is_sgmii = 0;\r\nif (bgx_lmac_xaui_init(bgx, lmacid, bgx->lmac_type))\r\nreturn -1;\r\n}\r\nif (lmac->is_sgmii) {\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_GMP_GMI_TXX_APPEND);\r\ncfg |= ((1ull << 2) | (1ull << 1));\r\nbgx_reg_modify(bgx, lmacid, BGX_GMP_GMI_TXX_APPEND, cfg);\r\nbgx_reg_write(bgx, lmacid, BGX_GMP_GMI_TXX_MIN_PKT, 60 - 1);\r\n} else {\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_SMUX_TX_APPEND);\r\ncfg |= ((1ull << 2) | (1ull << 1));\r\nbgx_reg_modify(bgx, lmacid, BGX_SMUX_TX_APPEND, cfg);\r\nbgx_reg_write(bgx, lmacid, BGX_SMUX_TX_MIN_PKT, 60 + 4);\r\n}\r\nbgx_reg_modify(bgx, lmacid, BGX_CMRX_CFG, CMR_EN);\r\nbgx_reg_write(bgx, lmacid, BGX_CMRX_RX_DMAC_CTL, 0x03);\r\nif ((bgx->lmac_type != BGX_MODE_XFI) &&\r\n(bgx->lmac_type != BGX_MODE_XLAUI) &&\r\n(bgx->lmac_type != BGX_MODE_40G_KR) &&\r\n(bgx->lmac_type != BGX_MODE_10G_KR)) {\r\nif (!lmac->phydev)\r\nreturn -ENODEV;\r\nlmac->phydev->dev_flags = 0;\r\nif (phy_connect_direct(&lmac->netdev, lmac->phydev,\r\nbgx_lmac_handler,\r\nPHY_INTERFACE_MODE_SGMII))\r\nreturn -ENODEV;\r\nphy_start_aneg(lmac->phydev);\r\n} else {\r\nlmac->check_link = alloc_workqueue("check_link", WQ_UNBOUND |\r\nWQ_MEM_RECLAIM, 1);\r\nif (!lmac->check_link)\r\nreturn -ENOMEM;\r\nINIT_DELAYED_WORK(&lmac->dwork, bgx_poll_for_link);\r\nqueue_delayed_work(lmac->check_link, &lmac->dwork, 0);\r\n}\r\nreturn 0;\r\n}\r\nstatic void bgx_lmac_disable(struct bgx *bgx, u8 lmacid)\r\n{\r\nstruct lmac *lmac;\r\nu64 cfg;\r\nlmac = &bgx->lmac[lmacid];\r\nif (lmac->check_link) {\r\ncancel_delayed_work_sync(&lmac->dwork);\r\ndestroy_workqueue(lmac->check_link);\r\n}\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_CMRX_CFG);\r\ncfg &= ~CMR_PKT_RX_EN;\r\nbgx_reg_write(bgx, lmacid, BGX_CMRX_CFG, cfg);\r\nbgx_poll_reg(bgx, lmacid, BGX_CMRX_RX_FIFO_LEN, (u64)0x1FFF, true);\r\nbgx_poll_reg(bgx, lmacid, BGX_CMRX_TX_FIFO_LEN, (u64)0x3FFF, true);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_CMRX_CFG);\r\ncfg &= ~CMR_PKT_TX_EN;\r\nbgx_reg_write(bgx, lmacid, BGX_CMRX_CFG, cfg);\r\nif (!lmac->is_sgmii)\r\nbgx_reg_modify(bgx, lmacid,\r\nBGX_SPUX_CONTROL1, SPU_CTL_LOW_POWER);\r\nelse\r\nbgx_reg_modify(bgx, lmacid,\r\nBGX_GMP_PCS_MRX_CTL, PCS_MRX_CTL_PWR_DN);\r\ncfg = bgx_reg_read(bgx, lmacid, BGX_CMRX_CFG);\r\ncfg &= ~CMR_EN;\r\nbgx_reg_write(bgx, lmacid, BGX_CMRX_CFG, cfg);\r\nbgx_flush_dmac_addrs(bgx, lmacid);\r\nif ((bgx->lmac_type != BGX_MODE_XFI) &&\r\n(bgx->lmac_type != BGX_MODE_XLAUI) &&\r\n(bgx->lmac_type != BGX_MODE_40G_KR) &&\r\n(bgx->lmac_type != BGX_MODE_10G_KR) && lmac->phydev)\r\nphy_disconnect(lmac->phydev);\r\nlmac->phydev = NULL;\r\n}\r\nstatic void bgx_set_num_ports(struct bgx *bgx)\r\n{\r\nu64 lmac_count;\r\nswitch (bgx->qlm_mode) {\r\ncase QLM_MODE_SGMII:\r\nbgx->lmac_count = 4;\r\nbgx->lmac_type = BGX_MODE_SGMII;\r\nbgx->lane_to_sds = 0;\r\nbreak;\r\ncase QLM_MODE_XAUI_1X4:\r\nbgx->lmac_count = 1;\r\nbgx->lmac_type = BGX_MODE_XAUI;\r\nbgx->lane_to_sds = 0xE4;\r\nbreak;\r\ncase QLM_MODE_RXAUI_2X2:\r\nbgx->lmac_count = 2;\r\nbgx->lmac_type = BGX_MODE_RXAUI;\r\nbgx->lane_to_sds = 0xE4;\r\nbreak;\r\ncase QLM_MODE_XFI_4X1:\r\nbgx->lmac_count = 4;\r\nbgx->lmac_type = BGX_MODE_XFI;\r\nbgx->lane_to_sds = 0;\r\nbreak;\r\ncase QLM_MODE_XLAUI_1X4:\r\nbgx->lmac_count = 1;\r\nbgx->lmac_type = BGX_MODE_XLAUI;\r\nbgx->lane_to_sds = 0xE4;\r\nbreak;\r\ncase QLM_MODE_10G_KR_4X1:\r\nbgx->lmac_count = 4;\r\nbgx->lmac_type = BGX_MODE_10G_KR;\r\nbgx->lane_to_sds = 0;\r\nbgx->use_training = 1;\r\nbreak;\r\ncase QLM_MODE_40G_KR4_1X4:\r\nbgx->lmac_count = 1;\r\nbgx->lmac_type = BGX_MODE_40G_KR;\r\nbgx->lane_to_sds = 0xE4;\r\nbgx->use_training = 1;\r\nbreak;\r\ndefault:\r\nbgx->lmac_count = 0;\r\nbreak;\r\n}\r\nlmac_count = bgx_reg_read(bgx, 0, BGX_CMR_RX_LMACS) & 0x7;\r\nif (lmac_count != 4)\r\nbgx->lmac_count = lmac_count;\r\n}\r\nstatic void bgx_init_hw(struct bgx *bgx)\r\n{\r\nint i;\r\nbgx_set_num_ports(bgx);\r\nbgx_reg_modify(bgx, 0, BGX_CMR_GLOBAL_CFG, CMR_GLOBAL_CFG_FCS_STRIP);\r\nif (bgx_reg_read(bgx, 0, BGX_CMR_BIST_STATUS))\r\ndev_err(&bgx->pdev->dev, "BGX%d BIST failed\n", bgx->bgx_id);\r\nfor (i = 0; i < bgx->lmac_count; i++) {\r\nif (bgx->lmac_type == BGX_MODE_RXAUI) {\r\nif (i)\r\nbgx->lane_to_sds = 0x0e;\r\nelse\r\nbgx->lane_to_sds = 0x04;\r\nbgx_reg_write(bgx, i, BGX_CMRX_CFG,\r\n(bgx->lmac_type << 8) | bgx->lane_to_sds);\r\ncontinue;\r\n}\r\nbgx_reg_write(bgx, i, BGX_CMRX_CFG,\r\n(bgx->lmac_type << 8) | (bgx->lane_to_sds + i));\r\nbgx->lmac[i].lmacid_bd = lmac_count;\r\nlmac_count++;\r\n}\r\nbgx_reg_write(bgx, 0, BGX_CMR_TX_LMACS, bgx->lmac_count);\r\nbgx_reg_write(bgx, 0, BGX_CMR_RX_LMACS, bgx->lmac_count);\r\nfor (i = 0; i < bgx->lmac_count; i++)\r\nbgx_reg_modify(bgx, 0, BGX_CMR_CHAN_MSK_AND,\r\n((1ULL << MAX_BGX_CHANS_PER_LMAC) - 1) <<\r\n(i * MAX_BGX_CHANS_PER_LMAC));\r\nfor (i = 0; i < RX_DMAC_COUNT; i++)\r\nbgx_reg_write(bgx, 0, BGX_CMR_RX_DMACX_CAM + (i * 8), 0x00);\r\nfor (i = 0; i < RX_TRAFFIC_STEER_RULE_COUNT; i++)\r\nbgx_reg_write(bgx, 0, BGX_CMR_RX_STREERING + (i * 8), 0x00);\r\n}\r\nstatic void bgx_get_qlm_mode(struct bgx *bgx)\r\n{\r\nstruct device *dev = &bgx->pdev->dev;\r\nint lmac_type;\r\nint train_en;\r\nlmac_type = bgx_reg_read(bgx, 0, BGX_CMRX_CFG);\r\nlmac_type = (lmac_type >> 8) & 0x07;\r\ntrain_en = bgx_reg_read(bgx, 0, BGX_SPUX_BR_PMD_CRTL) &\r\nSPU_PMD_CRTL_TRAIN_EN;\r\nswitch (lmac_type) {\r\ncase BGX_MODE_SGMII:\r\nbgx->qlm_mode = QLM_MODE_SGMII;\r\ndev_info(dev, "BGX%d QLM mode: SGMII\n", bgx->bgx_id);\r\nbreak;\r\ncase BGX_MODE_XAUI:\r\nbgx->qlm_mode = QLM_MODE_XAUI_1X4;\r\ndev_info(dev, "BGX%d QLM mode: XAUI\n", bgx->bgx_id);\r\nbreak;\r\ncase BGX_MODE_RXAUI:\r\nbgx->qlm_mode = QLM_MODE_RXAUI_2X2;\r\ndev_info(dev, "BGX%d QLM mode: RXAUI\n", bgx->bgx_id);\r\nbreak;\r\ncase BGX_MODE_XFI:\r\nif (!train_en) {\r\nbgx->qlm_mode = QLM_MODE_XFI_4X1;\r\ndev_info(dev, "BGX%d QLM mode: XFI\n", bgx->bgx_id);\r\n} else {\r\nbgx->qlm_mode = QLM_MODE_10G_KR_4X1;\r\ndev_info(dev, "BGX%d QLM mode: 10G_KR\n", bgx->bgx_id);\r\n}\r\nbreak;\r\ncase BGX_MODE_XLAUI:\r\nif (!train_en) {\r\nbgx->qlm_mode = QLM_MODE_XLAUI_1X4;\r\ndev_info(dev, "BGX%d QLM mode: XLAUI\n", bgx->bgx_id);\r\n} else {\r\nbgx->qlm_mode = QLM_MODE_40G_KR4_1X4;\r\ndev_info(dev, "BGX%d QLM mode: 40G_KR4\n", bgx->bgx_id);\r\n}\r\nbreak;\r\ndefault:\r\nbgx->qlm_mode = QLM_MODE_SGMII;\r\ndev_info(dev, "BGX%d QLM default mode: SGMII\n", bgx->bgx_id);\r\n}\r\n}\r\nstatic int acpi_get_mac_address(struct device *dev, struct acpi_device *adev,\r\nu8 *dst)\r\n{\r\nu8 mac[ETH_ALEN];\r\nint ret;\r\nret = fwnode_property_read_u8_array(acpi_fwnode_handle(adev),\r\n"mac-address", mac, ETH_ALEN);\r\nif (ret)\r\ngoto out;\r\nif (!is_valid_ether_addr(mac)) {\r\ndev_err(dev, "MAC address invalid: %pM\n", mac);\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\ndev_info(dev, "MAC address set to: %pM\n", mac);\r\nmemcpy(dst, mac, ETH_ALEN);\r\nout:\r\nreturn ret;\r\n}\r\nstatic acpi_status bgx_acpi_register_phy(acpi_handle handle,\r\nu32 lvl, void *context, void **rv)\r\n{\r\nstruct bgx *bgx = context;\r\nstruct device *dev = &bgx->pdev->dev;\r\nstruct acpi_device *adev;\r\nif (acpi_bus_get_device(handle, &adev))\r\ngoto out;\r\nacpi_get_mac_address(dev, adev, bgx->lmac[bgx->lmac_count].mac);\r\nSET_NETDEV_DEV(&bgx->lmac[bgx->lmac_count].netdev, dev);\r\nbgx->lmac[bgx->lmac_count].lmacid = bgx->lmac_count;\r\nout:\r\nbgx->lmac_count++;\r\nreturn AE_OK;\r\n}\r\nstatic acpi_status bgx_acpi_match_id(acpi_handle handle, u32 lvl,\r\nvoid *context, void **ret_val)\r\n{\r\nstruct acpi_buffer string = { ACPI_ALLOCATE_BUFFER, NULL };\r\nstruct bgx *bgx = context;\r\nchar bgx_sel[5];\r\nsnprintf(bgx_sel, 5, "BGX%d", bgx->bgx_id);\r\nif (ACPI_FAILURE(acpi_get_name(handle, ACPI_SINGLE_NAME, &string))) {\r\npr_warn("Invalid link device\n");\r\nreturn AE_OK;\r\n}\r\nif (strncmp(string.pointer, bgx_sel, 4))\r\nreturn AE_OK;\r\nacpi_walk_namespace(ACPI_TYPE_DEVICE, handle, 1,\r\nbgx_acpi_register_phy, NULL, bgx, NULL);\r\nkfree(string.pointer);\r\nreturn AE_CTRL_TERMINATE;\r\n}\r\nstatic int bgx_init_acpi_phy(struct bgx *bgx)\r\n{\r\nacpi_get_devices(NULL, bgx_acpi_match_id, bgx, (void **)NULL);\r\nreturn 0;\r\n}\r\nstatic int bgx_init_acpi_phy(struct bgx *bgx)\r\n{\r\nreturn -ENODEV;\r\n}\r\nstatic int bgx_init_of_phy(struct bgx *bgx)\r\n{\r\nstruct fwnode_handle *fwn;\r\nstruct device_node *node = NULL;\r\nu8 lmac = 0;\r\ndevice_for_each_child_node(&bgx->pdev->dev, fwn) {\r\nstruct phy_device *pd;\r\nstruct device_node *phy_np;\r\nconst char *mac;\r\nnode = to_of_node(fwn);\r\nif (!node)\r\nbreak;\r\nmac = of_get_mac_address(node);\r\nif (mac)\r\nether_addr_copy(bgx->lmac[lmac].mac, mac);\r\nSET_NETDEV_DEV(&bgx->lmac[lmac].netdev, &bgx->pdev->dev);\r\nbgx->lmac[lmac].lmacid = lmac;\r\nphy_np = of_parse_phandle(node, "phy-handle", 0);\r\nif (phy_np &&\r\n!of_device_is_compatible(phy_np, "cortina,cs4223-slice")) {\r\npd = of_phy_find_device(phy_np);\r\nif (!pd)\r\ngoto defer;\r\nbgx->lmac[lmac].phydev = pd;\r\n}\r\nlmac++;\r\nif (lmac == MAX_LMAC_PER_BGX) {\r\nof_node_put(node);\r\nbreak;\r\n}\r\n}\r\nreturn 0;\r\ndefer:\r\nwhile (lmac) {\r\nif (bgx->lmac[lmac].phydev) {\r\nput_device(&bgx->lmac[lmac].phydev->mdio.dev);\r\nbgx->lmac[lmac].phydev = NULL;\r\n}\r\nlmac--;\r\n}\r\nof_node_put(node);\r\nreturn -EPROBE_DEFER;\r\n}\r\nstatic int bgx_init_of_phy(struct bgx *bgx)\r\n{\r\nreturn -ENODEV;\r\n}\r\nstatic int bgx_init_phy(struct bgx *bgx)\r\n{\r\nif (!acpi_disabled)\r\nreturn bgx_init_acpi_phy(bgx);\r\nreturn bgx_init_of_phy(bgx);\r\n}\r\nstatic int bgx_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\r\n{\r\nint err;\r\nstruct device *dev = &pdev->dev;\r\nstruct bgx *bgx = NULL;\r\nu8 lmac;\r\nbgx = devm_kzalloc(dev, sizeof(*bgx), GFP_KERNEL);\r\nif (!bgx)\r\nreturn -ENOMEM;\r\nbgx->pdev = pdev;\r\npci_set_drvdata(pdev, bgx);\r\nerr = pci_enable_device(pdev);\r\nif (err) {\r\ndev_err(dev, "Failed to enable PCI device\n");\r\npci_set_drvdata(pdev, NULL);\r\nreturn err;\r\n}\r\nerr = pci_request_regions(pdev, DRV_NAME);\r\nif (err) {\r\ndev_err(dev, "PCI request regions failed 0x%x\n", err);\r\ngoto err_disable_device;\r\n}\r\nbgx->reg_base = pcim_iomap(pdev, PCI_CFG_REG_BAR_NUM, 0);\r\nif (!bgx->reg_base) {\r\ndev_err(dev, "BGX: Cannot map CSR memory space, aborting\n");\r\nerr = -ENOMEM;\r\ngoto err_release_regions;\r\n}\r\nbgx->bgx_id = (pci_resource_start(pdev, PCI_CFG_REG_BAR_NUM) >> 24) & 1;\r\nbgx->bgx_id += nic_get_node_id(pdev) * MAX_BGX_PER_CN88XX;\r\nbgx_vnic[bgx->bgx_id] = bgx;\r\nbgx_get_qlm_mode(bgx);\r\nerr = bgx_init_phy(bgx);\r\nif (err)\r\ngoto err_enable;\r\nbgx_init_hw(bgx);\r\nfor (lmac = 0; lmac < bgx->lmac_count; lmac++) {\r\nerr = bgx_lmac_enable(bgx, lmac);\r\nif (err) {\r\ndev_err(dev, "BGX%d failed to enable lmac%d\n",\r\nbgx->bgx_id, lmac);\r\ngoto err_enable;\r\n}\r\n}\r\nreturn 0;\r\nerr_enable:\r\nbgx_vnic[bgx->bgx_id] = NULL;\r\nerr_release_regions:\r\npci_release_regions(pdev);\r\nerr_disable_device:\r\npci_disable_device(pdev);\r\npci_set_drvdata(pdev, NULL);\r\nreturn err;\r\n}\r\nstatic void bgx_remove(struct pci_dev *pdev)\r\n{\r\nstruct bgx *bgx = pci_get_drvdata(pdev);\r\nu8 lmac;\r\nfor (lmac = 0; lmac < bgx->lmac_count; lmac++)\r\nbgx_lmac_disable(bgx, lmac);\r\nbgx_vnic[bgx->bgx_id] = NULL;\r\npci_release_regions(pdev);\r\npci_disable_device(pdev);\r\npci_set_drvdata(pdev, NULL);\r\n}\r\nstatic int __init bgx_init_module(void)\r\n{\r\npr_info("%s, ver %s\n", DRV_NAME, DRV_VERSION);\r\nreturn pci_register_driver(&bgx_driver);\r\n}\r\nstatic void __exit bgx_cleanup_module(void)\r\n{\r\npci_unregister_driver(&bgx_driver);\r\n}
