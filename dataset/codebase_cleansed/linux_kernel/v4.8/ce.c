static inline void ath10k_ce_dest_ring_write_index_set(struct ath10k *ar,\r\nu32 ce_ctrl_addr,\r\nunsigned int n)\r\n{\r\nath10k_pci_write32(ar, ce_ctrl_addr + DST_WR_INDEX_ADDRESS, n);\r\n}\r\nstatic inline u32 ath10k_ce_dest_ring_write_index_get(struct ath10k *ar,\r\nu32 ce_ctrl_addr)\r\n{\r\nreturn ath10k_pci_read32(ar, ce_ctrl_addr + DST_WR_INDEX_ADDRESS);\r\n}\r\nstatic inline void ath10k_ce_src_ring_write_index_set(struct ath10k *ar,\r\nu32 ce_ctrl_addr,\r\nunsigned int n)\r\n{\r\nath10k_pci_write32(ar, ce_ctrl_addr + SR_WR_INDEX_ADDRESS, n);\r\n}\r\nstatic inline u32 ath10k_ce_src_ring_write_index_get(struct ath10k *ar,\r\nu32 ce_ctrl_addr)\r\n{\r\nreturn ath10k_pci_read32(ar, ce_ctrl_addr + SR_WR_INDEX_ADDRESS);\r\n}\r\nstatic inline u32 ath10k_ce_src_ring_read_index_get(struct ath10k *ar,\r\nu32 ce_ctrl_addr)\r\n{\r\nreturn ath10k_pci_read32(ar, ce_ctrl_addr + CURRENT_SRRI_ADDRESS);\r\n}\r\nstatic inline void ath10k_ce_src_ring_base_addr_set(struct ath10k *ar,\r\nu32 ce_ctrl_addr,\r\nunsigned int addr)\r\n{\r\nath10k_pci_write32(ar, ce_ctrl_addr + SR_BA_ADDRESS, addr);\r\n}\r\nstatic inline void ath10k_ce_src_ring_size_set(struct ath10k *ar,\r\nu32 ce_ctrl_addr,\r\nunsigned int n)\r\n{\r\nath10k_pci_write32(ar, ce_ctrl_addr + SR_SIZE_ADDRESS, n);\r\n}\r\nstatic inline void ath10k_ce_src_ring_dmax_set(struct ath10k *ar,\r\nu32 ce_ctrl_addr,\r\nunsigned int n)\r\n{\r\nu32 ctrl1_addr = ath10k_pci_read32((ar),\r\n(ce_ctrl_addr) + CE_CTRL1_ADDRESS);\r\nath10k_pci_write32(ar, ce_ctrl_addr + CE_CTRL1_ADDRESS,\r\n(ctrl1_addr & ~CE_CTRL1_DMAX_LENGTH_MASK) |\r\nCE_CTRL1_DMAX_LENGTH_SET(n));\r\n}\r\nstatic inline void ath10k_ce_src_ring_byte_swap_set(struct ath10k *ar,\r\nu32 ce_ctrl_addr,\r\nunsigned int n)\r\n{\r\nu32 ctrl1_addr = ath10k_pci_read32(ar, ce_ctrl_addr + CE_CTRL1_ADDRESS);\r\nath10k_pci_write32(ar, ce_ctrl_addr + CE_CTRL1_ADDRESS,\r\n(ctrl1_addr & ~CE_CTRL1_SRC_RING_BYTE_SWAP_EN_MASK) |\r\nCE_CTRL1_SRC_RING_BYTE_SWAP_EN_SET(n));\r\n}\r\nstatic inline void ath10k_ce_dest_ring_byte_swap_set(struct ath10k *ar,\r\nu32 ce_ctrl_addr,\r\nunsigned int n)\r\n{\r\nu32 ctrl1_addr = ath10k_pci_read32(ar, ce_ctrl_addr + CE_CTRL1_ADDRESS);\r\nath10k_pci_write32(ar, ce_ctrl_addr + CE_CTRL1_ADDRESS,\r\n(ctrl1_addr & ~CE_CTRL1_DST_RING_BYTE_SWAP_EN_MASK) |\r\nCE_CTRL1_DST_RING_BYTE_SWAP_EN_SET(n));\r\n}\r\nstatic inline u32 ath10k_ce_dest_ring_read_index_get(struct ath10k *ar,\r\nu32 ce_ctrl_addr)\r\n{\r\nreturn ath10k_pci_read32(ar, ce_ctrl_addr + CURRENT_DRRI_ADDRESS);\r\n}\r\nstatic inline void ath10k_ce_dest_ring_base_addr_set(struct ath10k *ar,\r\nu32 ce_ctrl_addr,\r\nu32 addr)\r\n{\r\nath10k_pci_write32(ar, ce_ctrl_addr + DR_BA_ADDRESS, addr);\r\n}\r\nstatic inline void ath10k_ce_dest_ring_size_set(struct ath10k *ar,\r\nu32 ce_ctrl_addr,\r\nunsigned int n)\r\n{\r\nath10k_pci_write32(ar, ce_ctrl_addr + DR_SIZE_ADDRESS, n);\r\n}\r\nstatic inline void ath10k_ce_src_ring_highmark_set(struct ath10k *ar,\r\nu32 ce_ctrl_addr,\r\nunsigned int n)\r\n{\r\nu32 addr = ath10k_pci_read32(ar, ce_ctrl_addr + SRC_WATERMARK_ADDRESS);\r\nath10k_pci_write32(ar, ce_ctrl_addr + SRC_WATERMARK_ADDRESS,\r\n(addr & ~SRC_WATERMARK_HIGH_MASK) |\r\nSRC_WATERMARK_HIGH_SET(n));\r\n}\r\nstatic inline void ath10k_ce_src_ring_lowmark_set(struct ath10k *ar,\r\nu32 ce_ctrl_addr,\r\nunsigned int n)\r\n{\r\nu32 addr = ath10k_pci_read32(ar, ce_ctrl_addr + SRC_WATERMARK_ADDRESS);\r\nath10k_pci_write32(ar, ce_ctrl_addr + SRC_WATERMARK_ADDRESS,\r\n(addr & ~SRC_WATERMARK_LOW_MASK) |\r\nSRC_WATERMARK_LOW_SET(n));\r\n}\r\nstatic inline void ath10k_ce_dest_ring_highmark_set(struct ath10k *ar,\r\nu32 ce_ctrl_addr,\r\nunsigned int n)\r\n{\r\nu32 addr = ath10k_pci_read32(ar, ce_ctrl_addr + DST_WATERMARK_ADDRESS);\r\nath10k_pci_write32(ar, ce_ctrl_addr + DST_WATERMARK_ADDRESS,\r\n(addr & ~DST_WATERMARK_HIGH_MASK) |\r\nDST_WATERMARK_HIGH_SET(n));\r\n}\r\nstatic inline void ath10k_ce_dest_ring_lowmark_set(struct ath10k *ar,\r\nu32 ce_ctrl_addr,\r\nunsigned int n)\r\n{\r\nu32 addr = ath10k_pci_read32(ar, ce_ctrl_addr + DST_WATERMARK_ADDRESS);\r\nath10k_pci_write32(ar, ce_ctrl_addr + DST_WATERMARK_ADDRESS,\r\n(addr & ~DST_WATERMARK_LOW_MASK) |\r\nDST_WATERMARK_LOW_SET(n));\r\n}\r\nstatic inline void ath10k_ce_copy_complete_inter_enable(struct ath10k *ar,\r\nu32 ce_ctrl_addr)\r\n{\r\nu32 host_ie_addr = ath10k_pci_read32(ar,\r\nce_ctrl_addr + HOST_IE_ADDRESS);\r\nath10k_pci_write32(ar, ce_ctrl_addr + HOST_IE_ADDRESS,\r\nhost_ie_addr | HOST_IE_COPY_COMPLETE_MASK);\r\n}\r\nstatic inline void ath10k_ce_copy_complete_intr_disable(struct ath10k *ar,\r\nu32 ce_ctrl_addr)\r\n{\r\nu32 host_ie_addr = ath10k_pci_read32(ar,\r\nce_ctrl_addr + HOST_IE_ADDRESS);\r\nath10k_pci_write32(ar, ce_ctrl_addr + HOST_IE_ADDRESS,\r\nhost_ie_addr & ~HOST_IE_COPY_COMPLETE_MASK);\r\n}\r\nstatic inline void ath10k_ce_watermark_intr_disable(struct ath10k *ar,\r\nu32 ce_ctrl_addr)\r\n{\r\nu32 host_ie_addr = ath10k_pci_read32(ar,\r\nce_ctrl_addr + HOST_IE_ADDRESS);\r\nath10k_pci_write32(ar, ce_ctrl_addr + HOST_IE_ADDRESS,\r\nhost_ie_addr & ~CE_WATERMARK_MASK);\r\n}\r\nstatic inline void ath10k_ce_error_intr_enable(struct ath10k *ar,\r\nu32 ce_ctrl_addr)\r\n{\r\nu32 misc_ie_addr = ath10k_pci_read32(ar,\r\nce_ctrl_addr + MISC_IE_ADDRESS);\r\nath10k_pci_write32(ar, ce_ctrl_addr + MISC_IE_ADDRESS,\r\nmisc_ie_addr | CE_ERROR_MASK);\r\n}\r\nstatic inline void ath10k_ce_error_intr_disable(struct ath10k *ar,\r\nu32 ce_ctrl_addr)\r\n{\r\nu32 misc_ie_addr = ath10k_pci_read32(ar,\r\nce_ctrl_addr + MISC_IE_ADDRESS);\r\nath10k_pci_write32(ar, ce_ctrl_addr + MISC_IE_ADDRESS,\r\nmisc_ie_addr & ~CE_ERROR_MASK);\r\n}\r\nstatic inline void ath10k_ce_engine_int_status_clear(struct ath10k *ar,\r\nu32 ce_ctrl_addr,\r\nunsigned int mask)\r\n{\r\nath10k_pci_write32(ar, ce_ctrl_addr + HOST_IS_ADDRESS, mask);\r\n}\r\nint ath10k_ce_send_nolock(struct ath10k_ce_pipe *ce_state,\r\nvoid *per_transfer_context,\r\nu32 buffer,\r\nunsigned int nbytes,\r\nunsigned int transfer_id,\r\nunsigned int flags)\r\n{\r\nstruct ath10k *ar = ce_state->ar;\r\nstruct ath10k_ce_ring *src_ring = ce_state->src_ring;\r\nstruct ce_desc *desc, sdesc;\r\nunsigned int nentries_mask = src_ring->nentries_mask;\r\nunsigned int sw_index = src_ring->sw_index;\r\nunsigned int write_index = src_ring->write_index;\r\nu32 ctrl_addr = ce_state->ctrl_addr;\r\nu32 desc_flags = 0;\r\nint ret = 0;\r\nif (nbytes > ce_state->src_sz_max)\r\nath10k_warn(ar, "%s: send more we can (nbytes: %d, max: %d)\n",\r\n__func__, nbytes, ce_state->src_sz_max);\r\nif (unlikely(CE_RING_DELTA(nentries_mask,\r\nwrite_index, sw_index - 1) <= 0)) {\r\nret = -ENOSR;\r\ngoto exit;\r\n}\r\ndesc = CE_SRC_RING_TO_DESC(src_ring->base_addr_owner_space,\r\nwrite_index);\r\ndesc_flags |= SM(transfer_id, CE_DESC_FLAGS_META_DATA);\r\nif (flags & CE_SEND_FLAG_GATHER)\r\ndesc_flags |= CE_DESC_FLAGS_GATHER;\r\nif (flags & CE_SEND_FLAG_BYTE_SWAP)\r\ndesc_flags |= CE_DESC_FLAGS_BYTE_SWAP;\r\nsdesc.addr = __cpu_to_le32(buffer);\r\nsdesc.nbytes = __cpu_to_le16(nbytes);\r\nsdesc.flags = __cpu_to_le16(desc_flags);\r\n*desc = sdesc;\r\nsrc_ring->per_transfer_context[write_index] = per_transfer_context;\r\nwrite_index = CE_RING_IDX_INCR(nentries_mask, write_index);\r\nif (!(flags & CE_SEND_FLAG_GATHER))\r\nath10k_ce_src_ring_write_index_set(ar, ctrl_addr, write_index);\r\nsrc_ring->write_index = write_index;\r\nexit:\r\nreturn ret;\r\n}\r\nvoid __ath10k_ce_send_revert(struct ath10k_ce_pipe *pipe)\r\n{\r\nstruct ath10k *ar = pipe->ar;\r\nstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\r\nstruct ath10k_ce_ring *src_ring = pipe->src_ring;\r\nu32 ctrl_addr = pipe->ctrl_addr;\r\nlockdep_assert_held(&ar_pci->ce_lock);\r\nif (WARN_ON_ONCE(src_ring->write_index == src_ring->sw_index))\r\nreturn;\r\nif (WARN_ON_ONCE(src_ring->write_index ==\r\nath10k_ce_src_ring_write_index_get(ar, ctrl_addr)))\r\nreturn;\r\nsrc_ring->write_index--;\r\nsrc_ring->write_index &= src_ring->nentries_mask;\r\nsrc_ring->per_transfer_context[src_ring->write_index] = NULL;\r\n}\r\nint ath10k_ce_send(struct ath10k_ce_pipe *ce_state,\r\nvoid *per_transfer_context,\r\nu32 buffer,\r\nunsigned int nbytes,\r\nunsigned int transfer_id,\r\nunsigned int flags)\r\n{\r\nstruct ath10k *ar = ce_state->ar;\r\nstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\r\nint ret;\r\nspin_lock_bh(&ar_pci->ce_lock);\r\nret = ath10k_ce_send_nolock(ce_state, per_transfer_context,\r\nbuffer, nbytes, transfer_id, flags);\r\nspin_unlock_bh(&ar_pci->ce_lock);\r\nreturn ret;\r\n}\r\nint ath10k_ce_num_free_src_entries(struct ath10k_ce_pipe *pipe)\r\n{\r\nstruct ath10k *ar = pipe->ar;\r\nstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\r\nint delta;\r\nspin_lock_bh(&ar_pci->ce_lock);\r\ndelta = CE_RING_DELTA(pipe->src_ring->nentries_mask,\r\npipe->src_ring->write_index,\r\npipe->src_ring->sw_index - 1);\r\nspin_unlock_bh(&ar_pci->ce_lock);\r\nreturn delta;\r\n}\r\nint __ath10k_ce_rx_num_free_bufs(struct ath10k_ce_pipe *pipe)\r\n{\r\nstruct ath10k *ar = pipe->ar;\r\nstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\r\nstruct ath10k_ce_ring *dest_ring = pipe->dest_ring;\r\nunsigned int nentries_mask = dest_ring->nentries_mask;\r\nunsigned int write_index = dest_ring->write_index;\r\nunsigned int sw_index = dest_ring->sw_index;\r\nlockdep_assert_held(&ar_pci->ce_lock);\r\nreturn CE_RING_DELTA(nentries_mask, write_index, sw_index - 1);\r\n}\r\nint __ath10k_ce_rx_post_buf(struct ath10k_ce_pipe *pipe, void *ctx, u32 paddr)\r\n{\r\nstruct ath10k *ar = pipe->ar;\r\nstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\r\nstruct ath10k_ce_ring *dest_ring = pipe->dest_ring;\r\nunsigned int nentries_mask = dest_ring->nentries_mask;\r\nunsigned int write_index = dest_ring->write_index;\r\nunsigned int sw_index = dest_ring->sw_index;\r\nstruct ce_desc *base = dest_ring->base_addr_owner_space;\r\nstruct ce_desc *desc = CE_DEST_RING_TO_DESC(base, write_index);\r\nu32 ctrl_addr = pipe->ctrl_addr;\r\nlockdep_assert_held(&ar_pci->ce_lock);\r\nif ((pipe->id != 5) &&\r\nCE_RING_DELTA(nentries_mask, write_index, sw_index - 1) == 0)\r\nreturn -ENOSPC;\r\ndesc->addr = __cpu_to_le32(paddr);\r\ndesc->nbytes = 0;\r\ndest_ring->per_transfer_context[write_index] = ctx;\r\nwrite_index = CE_RING_IDX_INCR(nentries_mask, write_index);\r\nath10k_ce_dest_ring_write_index_set(ar, ctrl_addr, write_index);\r\ndest_ring->write_index = write_index;\r\nreturn 0;\r\n}\r\nvoid ath10k_ce_rx_update_write_idx(struct ath10k_ce_pipe *pipe, u32 nentries)\r\n{\r\nstruct ath10k *ar = pipe->ar;\r\nstruct ath10k_ce_ring *dest_ring = pipe->dest_ring;\r\nunsigned int nentries_mask = dest_ring->nentries_mask;\r\nunsigned int write_index = dest_ring->write_index;\r\nu32 ctrl_addr = pipe->ctrl_addr;\r\nwrite_index = CE_RING_IDX_ADD(nentries_mask, write_index, nentries);\r\nath10k_ce_dest_ring_write_index_set(ar, ctrl_addr, write_index);\r\ndest_ring->write_index = write_index;\r\n}\r\nint ath10k_ce_rx_post_buf(struct ath10k_ce_pipe *pipe, void *ctx, u32 paddr)\r\n{\r\nstruct ath10k *ar = pipe->ar;\r\nstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\r\nint ret;\r\nspin_lock_bh(&ar_pci->ce_lock);\r\nret = __ath10k_ce_rx_post_buf(pipe, ctx, paddr);\r\nspin_unlock_bh(&ar_pci->ce_lock);\r\nreturn ret;\r\n}\r\nint ath10k_ce_completed_recv_next_nolock(struct ath10k_ce_pipe *ce_state,\r\nvoid **per_transfer_contextp,\r\nunsigned int *nbytesp)\r\n{\r\nstruct ath10k_ce_ring *dest_ring = ce_state->dest_ring;\r\nunsigned int nentries_mask = dest_ring->nentries_mask;\r\nunsigned int sw_index = dest_ring->sw_index;\r\nstruct ce_desc *base = dest_ring->base_addr_owner_space;\r\nstruct ce_desc *desc = CE_DEST_RING_TO_DESC(base, sw_index);\r\nstruct ce_desc sdesc;\r\nu16 nbytes;\r\nsdesc = *desc;\r\nnbytes = __le16_to_cpu(sdesc.nbytes);\r\nif (nbytes == 0) {\r\nreturn -EIO;\r\n}\r\ndesc->nbytes = 0;\r\n*nbytesp = nbytes;\r\nif (per_transfer_contextp)\r\n*per_transfer_contextp =\r\ndest_ring->per_transfer_context[sw_index];\r\nif (ce_state->id != 5)\r\ndest_ring->per_transfer_context[sw_index] = NULL;\r\nsw_index = CE_RING_IDX_INCR(nentries_mask, sw_index);\r\ndest_ring->sw_index = sw_index;\r\nreturn 0;\r\n}\r\nint ath10k_ce_completed_recv_next(struct ath10k_ce_pipe *ce_state,\r\nvoid **per_transfer_contextp,\r\nunsigned int *nbytesp)\r\n{\r\nstruct ath10k *ar = ce_state->ar;\r\nstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\r\nint ret;\r\nspin_lock_bh(&ar_pci->ce_lock);\r\nret = ath10k_ce_completed_recv_next_nolock(ce_state,\r\nper_transfer_contextp,\r\nnbytesp);\r\nspin_unlock_bh(&ar_pci->ce_lock);\r\nreturn ret;\r\n}\r\nint ath10k_ce_revoke_recv_next(struct ath10k_ce_pipe *ce_state,\r\nvoid **per_transfer_contextp,\r\nu32 *bufferp)\r\n{\r\nstruct ath10k_ce_ring *dest_ring;\r\nunsigned int nentries_mask;\r\nunsigned int sw_index;\r\nunsigned int write_index;\r\nint ret;\r\nstruct ath10k *ar;\r\nstruct ath10k_pci *ar_pci;\r\ndest_ring = ce_state->dest_ring;\r\nif (!dest_ring)\r\nreturn -EIO;\r\nar = ce_state->ar;\r\nar_pci = ath10k_pci_priv(ar);\r\nspin_lock_bh(&ar_pci->ce_lock);\r\nnentries_mask = dest_ring->nentries_mask;\r\nsw_index = dest_ring->sw_index;\r\nwrite_index = dest_ring->write_index;\r\nif (write_index != sw_index) {\r\nstruct ce_desc *base = dest_ring->base_addr_owner_space;\r\nstruct ce_desc *desc = CE_DEST_RING_TO_DESC(base, sw_index);\r\n*bufferp = __le32_to_cpu(desc->addr);\r\nif (per_transfer_contextp)\r\n*per_transfer_contextp =\r\ndest_ring->per_transfer_context[sw_index];\r\ndest_ring->per_transfer_context[sw_index] = NULL;\r\ndesc->nbytes = 0;\r\nsw_index = CE_RING_IDX_INCR(nentries_mask, sw_index);\r\ndest_ring->sw_index = sw_index;\r\nret = 0;\r\n} else {\r\nret = -EIO;\r\n}\r\nspin_unlock_bh(&ar_pci->ce_lock);\r\nreturn ret;\r\n}\r\nint ath10k_ce_completed_send_next_nolock(struct ath10k_ce_pipe *ce_state,\r\nvoid **per_transfer_contextp)\r\n{\r\nstruct ath10k_ce_ring *src_ring = ce_state->src_ring;\r\nu32 ctrl_addr = ce_state->ctrl_addr;\r\nstruct ath10k *ar = ce_state->ar;\r\nunsigned int nentries_mask = src_ring->nentries_mask;\r\nunsigned int sw_index = src_ring->sw_index;\r\nunsigned int read_index;\r\nif (src_ring->hw_index == sw_index) {\r\nread_index = ath10k_ce_src_ring_read_index_get(ar, ctrl_addr);\r\nif (read_index == 0xffffffff)\r\nreturn -ENODEV;\r\nread_index &= nentries_mask;\r\nsrc_ring->hw_index = read_index;\r\n}\r\nread_index = src_ring->hw_index;\r\nif (read_index == sw_index)\r\nreturn -EIO;\r\nif (per_transfer_contextp)\r\n*per_transfer_contextp =\r\nsrc_ring->per_transfer_context[sw_index];\r\nsrc_ring->per_transfer_context[sw_index] = NULL;\r\nsw_index = CE_RING_IDX_INCR(nentries_mask, sw_index);\r\nsrc_ring->sw_index = sw_index;\r\nreturn 0;\r\n}\r\nint ath10k_ce_cancel_send_next(struct ath10k_ce_pipe *ce_state,\r\nvoid **per_transfer_contextp,\r\nu32 *bufferp,\r\nunsigned int *nbytesp,\r\nunsigned int *transfer_idp)\r\n{\r\nstruct ath10k_ce_ring *src_ring;\r\nunsigned int nentries_mask;\r\nunsigned int sw_index;\r\nunsigned int write_index;\r\nint ret;\r\nstruct ath10k *ar;\r\nstruct ath10k_pci *ar_pci;\r\nsrc_ring = ce_state->src_ring;\r\nif (!src_ring)\r\nreturn -EIO;\r\nar = ce_state->ar;\r\nar_pci = ath10k_pci_priv(ar);\r\nspin_lock_bh(&ar_pci->ce_lock);\r\nnentries_mask = src_ring->nentries_mask;\r\nsw_index = src_ring->sw_index;\r\nwrite_index = src_ring->write_index;\r\nif (write_index != sw_index) {\r\nstruct ce_desc *base = src_ring->base_addr_owner_space;\r\nstruct ce_desc *desc = CE_SRC_RING_TO_DESC(base, sw_index);\r\n*bufferp = __le32_to_cpu(desc->addr);\r\n*nbytesp = __le16_to_cpu(desc->nbytes);\r\n*transfer_idp = MS(__le16_to_cpu(desc->flags),\r\nCE_DESC_FLAGS_META_DATA);\r\nif (per_transfer_contextp)\r\n*per_transfer_contextp =\r\nsrc_ring->per_transfer_context[sw_index];\r\nsrc_ring->per_transfer_context[sw_index] = NULL;\r\nsw_index = CE_RING_IDX_INCR(nentries_mask, sw_index);\r\nsrc_ring->sw_index = sw_index;\r\nret = 0;\r\n} else {\r\nret = -EIO;\r\n}\r\nspin_unlock_bh(&ar_pci->ce_lock);\r\nreturn ret;\r\n}\r\nint ath10k_ce_completed_send_next(struct ath10k_ce_pipe *ce_state,\r\nvoid **per_transfer_contextp)\r\n{\r\nstruct ath10k *ar = ce_state->ar;\r\nstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\r\nint ret;\r\nspin_lock_bh(&ar_pci->ce_lock);\r\nret = ath10k_ce_completed_send_next_nolock(ce_state,\r\nper_transfer_contextp);\r\nspin_unlock_bh(&ar_pci->ce_lock);\r\nreturn ret;\r\n}\r\nvoid ath10k_ce_per_engine_service(struct ath10k *ar, unsigned int ce_id)\r\n{\r\nstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\r\nstruct ath10k_ce_pipe *ce_state = &ar_pci->ce_states[ce_id];\r\nu32 ctrl_addr = ce_state->ctrl_addr;\r\nspin_lock_bh(&ar_pci->ce_lock);\r\nath10k_ce_engine_int_status_clear(ar, ctrl_addr,\r\nHOST_IS_COPY_COMPLETE_MASK);\r\nspin_unlock_bh(&ar_pci->ce_lock);\r\nif (ce_state->recv_cb)\r\nce_state->recv_cb(ce_state);\r\nif (ce_state->send_cb)\r\nce_state->send_cb(ce_state);\r\nspin_lock_bh(&ar_pci->ce_lock);\r\nath10k_ce_engine_int_status_clear(ar, ctrl_addr, CE_WATERMARK_MASK);\r\nspin_unlock_bh(&ar_pci->ce_lock);\r\n}\r\nvoid ath10k_ce_per_engine_service_any(struct ath10k *ar)\r\n{\r\nint ce_id;\r\nu32 intr_summary;\r\nintr_summary = CE_INTERRUPT_SUMMARY(ar);\r\nfor (ce_id = 0; intr_summary && (ce_id < CE_COUNT); ce_id++) {\r\nif (intr_summary & (1 << ce_id))\r\nintr_summary &= ~(1 << ce_id);\r\nelse\r\ncontinue;\r\nath10k_ce_per_engine_service(ar, ce_id);\r\n}\r\n}\r\nstatic void ath10k_ce_per_engine_handler_adjust(struct ath10k_ce_pipe *ce_state)\r\n{\r\nu32 ctrl_addr = ce_state->ctrl_addr;\r\nstruct ath10k *ar = ce_state->ar;\r\nbool disable_copy_compl_intr = ce_state->attr_flags & CE_ATTR_DIS_INTR;\r\nif ((!disable_copy_compl_intr) &&\r\n(ce_state->send_cb || ce_state->recv_cb))\r\nath10k_ce_copy_complete_inter_enable(ar, ctrl_addr);\r\nelse\r\nath10k_ce_copy_complete_intr_disable(ar, ctrl_addr);\r\nath10k_ce_watermark_intr_disable(ar, ctrl_addr);\r\n}\r\nint ath10k_ce_disable_interrupts(struct ath10k *ar)\r\n{\r\nint ce_id;\r\nfor (ce_id = 0; ce_id < CE_COUNT; ce_id++) {\r\nu32 ctrl_addr = ath10k_ce_base_address(ar, ce_id);\r\nath10k_ce_copy_complete_intr_disable(ar, ctrl_addr);\r\nath10k_ce_error_intr_disable(ar, ctrl_addr);\r\nath10k_ce_watermark_intr_disable(ar, ctrl_addr);\r\n}\r\nreturn 0;\r\n}\r\nvoid ath10k_ce_enable_interrupts(struct ath10k *ar)\r\n{\r\nstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\r\nint ce_id;\r\nfor (ce_id = 0; ce_id < CE_COUNT - 1; ce_id++)\r\nath10k_ce_per_engine_handler_adjust(&ar_pci->ce_states[ce_id]);\r\n}\r\nstatic int ath10k_ce_init_src_ring(struct ath10k *ar,\r\nunsigned int ce_id,\r\nconst struct ce_attr *attr)\r\n{\r\nstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\r\nstruct ath10k_ce_pipe *ce_state = &ar_pci->ce_states[ce_id];\r\nstruct ath10k_ce_ring *src_ring = ce_state->src_ring;\r\nu32 nentries, ctrl_addr = ath10k_ce_base_address(ar, ce_id);\r\nnentries = roundup_pow_of_two(attr->src_nentries);\r\nmemset(src_ring->base_addr_owner_space, 0,\r\nnentries * sizeof(struct ce_desc));\r\nsrc_ring->sw_index = ath10k_ce_src_ring_read_index_get(ar, ctrl_addr);\r\nsrc_ring->sw_index &= src_ring->nentries_mask;\r\nsrc_ring->hw_index = src_ring->sw_index;\r\nsrc_ring->write_index =\r\nath10k_ce_src_ring_write_index_get(ar, ctrl_addr);\r\nsrc_ring->write_index &= src_ring->nentries_mask;\r\nath10k_ce_src_ring_base_addr_set(ar, ctrl_addr,\r\nsrc_ring->base_addr_ce_space);\r\nath10k_ce_src_ring_size_set(ar, ctrl_addr, nentries);\r\nath10k_ce_src_ring_dmax_set(ar, ctrl_addr, attr->src_sz_max);\r\nath10k_ce_src_ring_byte_swap_set(ar, ctrl_addr, 0);\r\nath10k_ce_src_ring_lowmark_set(ar, ctrl_addr, 0);\r\nath10k_ce_src_ring_highmark_set(ar, ctrl_addr, nentries);\r\nath10k_dbg(ar, ATH10K_DBG_BOOT,\r\n"boot init ce src ring id %d entries %d base_addr %p\n",\r\nce_id, nentries, src_ring->base_addr_owner_space);\r\nreturn 0;\r\n}\r\nstatic int ath10k_ce_init_dest_ring(struct ath10k *ar,\r\nunsigned int ce_id,\r\nconst struct ce_attr *attr)\r\n{\r\nstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\r\nstruct ath10k_ce_pipe *ce_state = &ar_pci->ce_states[ce_id];\r\nstruct ath10k_ce_ring *dest_ring = ce_state->dest_ring;\r\nu32 nentries, ctrl_addr = ath10k_ce_base_address(ar, ce_id);\r\nnentries = roundup_pow_of_two(attr->dest_nentries);\r\nmemset(dest_ring->base_addr_owner_space, 0,\r\nnentries * sizeof(struct ce_desc));\r\ndest_ring->sw_index = ath10k_ce_dest_ring_read_index_get(ar, ctrl_addr);\r\ndest_ring->sw_index &= dest_ring->nentries_mask;\r\ndest_ring->write_index =\r\nath10k_ce_dest_ring_write_index_get(ar, ctrl_addr);\r\ndest_ring->write_index &= dest_ring->nentries_mask;\r\nath10k_ce_dest_ring_base_addr_set(ar, ctrl_addr,\r\ndest_ring->base_addr_ce_space);\r\nath10k_ce_dest_ring_size_set(ar, ctrl_addr, nentries);\r\nath10k_ce_dest_ring_byte_swap_set(ar, ctrl_addr, 0);\r\nath10k_ce_dest_ring_lowmark_set(ar, ctrl_addr, 0);\r\nath10k_ce_dest_ring_highmark_set(ar, ctrl_addr, nentries);\r\nath10k_dbg(ar, ATH10K_DBG_BOOT,\r\n"boot ce dest ring id %d entries %d base_addr %p\n",\r\nce_id, nentries, dest_ring->base_addr_owner_space);\r\nreturn 0;\r\n}\r\nstatic struct ath10k_ce_ring *\r\nath10k_ce_alloc_src_ring(struct ath10k *ar, unsigned int ce_id,\r\nconst struct ce_attr *attr)\r\n{\r\nstruct ath10k_ce_ring *src_ring;\r\nu32 nentries = attr->src_nentries;\r\ndma_addr_t base_addr;\r\nnentries = roundup_pow_of_two(nentries);\r\nsrc_ring = kzalloc(sizeof(*src_ring) +\r\n(nentries *\r\nsizeof(*src_ring->per_transfer_context)),\r\nGFP_KERNEL);\r\nif (src_ring == NULL)\r\nreturn ERR_PTR(-ENOMEM);\r\nsrc_ring->nentries = nentries;\r\nsrc_ring->nentries_mask = nentries - 1;\r\nsrc_ring->base_addr_owner_space_unaligned =\r\ndma_alloc_coherent(ar->dev,\r\n(nentries * sizeof(struct ce_desc) +\r\nCE_DESC_RING_ALIGN),\r\n&base_addr, GFP_KERNEL);\r\nif (!src_ring->base_addr_owner_space_unaligned) {\r\nkfree(src_ring);\r\nreturn ERR_PTR(-ENOMEM);\r\n}\r\nsrc_ring->base_addr_ce_space_unaligned = base_addr;\r\nsrc_ring->base_addr_owner_space = PTR_ALIGN(\r\nsrc_ring->base_addr_owner_space_unaligned,\r\nCE_DESC_RING_ALIGN);\r\nsrc_ring->base_addr_ce_space = ALIGN(\r\nsrc_ring->base_addr_ce_space_unaligned,\r\nCE_DESC_RING_ALIGN);\r\nreturn src_ring;\r\n}\r\nstatic struct ath10k_ce_ring *\r\nath10k_ce_alloc_dest_ring(struct ath10k *ar, unsigned int ce_id,\r\nconst struct ce_attr *attr)\r\n{\r\nstruct ath10k_ce_ring *dest_ring;\r\nu32 nentries;\r\ndma_addr_t base_addr;\r\nnentries = roundup_pow_of_two(attr->dest_nentries);\r\ndest_ring = kzalloc(sizeof(*dest_ring) +\r\n(nentries *\r\nsizeof(*dest_ring->per_transfer_context)),\r\nGFP_KERNEL);\r\nif (dest_ring == NULL)\r\nreturn ERR_PTR(-ENOMEM);\r\ndest_ring->nentries = nentries;\r\ndest_ring->nentries_mask = nentries - 1;\r\ndest_ring->base_addr_owner_space_unaligned =\r\ndma_alloc_coherent(ar->dev,\r\n(nentries * sizeof(struct ce_desc) +\r\nCE_DESC_RING_ALIGN),\r\n&base_addr, GFP_KERNEL);\r\nif (!dest_ring->base_addr_owner_space_unaligned) {\r\nkfree(dest_ring);\r\nreturn ERR_PTR(-ENOMEM);\r\n}\r\ndest_ring->base_addr_ce_space_unaligned = base_addr;\r\nmemset(dest_ring->base_addr_owner_space_unaligned, 0,\r\nnentries * sizeof(struct ce_desc) + CE_DESC_RING_ALIGN);\r\ndest_ring->base_addr_owner_space = PTR_ALIGN(\r\ndest_ring->base_addr_owner_space_unaligned,\r\nCE_DESC_RING_ALIGN);\r\ndest_ring->base_addr_ce_space = ALIGN(\r\ndest_ring->base_addr_ce_space_unaligned,\r\nCE_DESC_RING_ALIGN);\r\nreturn dest_ring;\r\n}\r\nint ath10k_ce_init_pipe(struct ath10k *ar, unsigned int ce_id,\r\nconst struct ce_attr *attr)\r\n{\r\nint ret;\r\nif (attr->src_nentries) {\r\nret = ath10k_ce_init_src_ring(ar, ce_id, attr);\r\nif (ret) {\r\nath10k_err(ar, "Failed to initialize CE src ring for ID: %d (%d)\n",\r\nce_id, ret);\r\nreturn ret;\r\n}\r\n}\r\nif (attr->dest_nentries) {\r\nret = ath10k_ce_init_dest_ring(ar, ce_id, attr);\r\nif (ret) {\r\nath10k_err(ar, "Failed to initialize CE dest ring for ID: %d (%d)\n",\r\nce_id, ret);\r\nreturn ret;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void ath10k_ce_deinit_src_ring(struct ath10k *ar, unsigned int ce_id)\r\n{\r\nu32 ctrl_addr = ath10k_ce_base_address(ar, ce_id);\r\nath10k_ce_src_ring_base_addr_set(ar, ctrl_addr, 0);\r\nath10k_ce_src_ring_size_set(ar, ctrl_addr, 0);\r\nath10k_ce_src_ring_dmax_set(ar, ctrl_addr, 0);\r\nath10k_ce_src_ring_highmark_set(ar, ctrl_addr, 0);\r\n}\r\nstatic void ath10k_ce_deinit_dest_ring(struct ath10k *ar, unsigned int ce_id)\r\n{\r\nu32 ctrl_addr = ath10k_ce_base_address(ar, ce_id);\r\nath10k_ce_dest_ring_base_addr_set(ar, ctrl_addr, 0);\r\nath10k_ce_dest_ring_size_set(ar, ctrl_addr, 0);\r\nath10k_ce_dest_ring_highmark_set(ar, ctrl_addr, 0);\r\n}\r\nvoid ath10k_ce_deinit_pipe(struct ath10k *ar, unsigned int ce_id)\r\n{\r\nath10k_ce_deinit_src_ring(ar, ce_id);\r\nath10k_ce_deinit_dest_ring(ar, ce_id);\r\n}\r\nint ath10k_ce_alloc_pipe(struct ath10k *ar, int ce_id,\r\nconst struct ce_attr *attr)\r\n{\r\nstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\r\nstruct ath10k_ce_pipe *ce_state = &ar_pci->ce_states[ce_id];\r\nint ret;\r\nBUILD_BUG_ON(2 * TARGET_NUM_MSDU_DESC >\r\n(CE_HTT_H2T_MSG_SRC_NENTRIES - 1));\r\nBUILD_BUG_ON(2 * TARGET_10X_NUM_MSDU_DESC >\r\n(CE_HTT_H2T_MSG_SRC_NENTRIES - 1));\r\nBUILD_BUG_ON(2 * TARGET_TLV_NUM_MSDU_DESC >\r\n(CE_HTT_H2T_MSG_SRC_NENTRIES - 1));\r\nce_state->ar = ar;\r\nce_state->id = ce_id;\r\nce_state->ctrl_addr = ath10k_ce_base_address(ar, ce_id);\r\nce_state->attr_flags = attr->flags;\r\nce_state->src_sz_max = attr->src_sz_max;\r\nif (attr->src_nentries)\r\nce_state->send_cb = attr->send_cb;\r\nif (attr->dest_nentries)\r\nce_state->recv_cb = attr->recv_cb;\r\nif (attr->src_nentries) {\r\nce_state->src_ring = ath10k_ce_alloc_src_ring(ar, ce_id, attr);\r\nif (IS_ERR(ce_state->src_ring)) {\r\nret = PTR_ERR(ce_state->src_ring);\r\nath10k_err(ar, "failed to allocate copy engine source ring %d: %d\n",\r\nce_id, ret);\r\nce_state->src_ring = NULL;\r\nreturn ret;\r\n}\r\n}\r\nif (attr->dest_nentries) {\r\nce_state->dest_ring = ath10k_ce_alloc_dest_ring(ar, ce_id,\r\nattr);\r\nif (IS_ERR(ce_state->dest_ring)) {\r\nret = PTR_ERR(ce_state->dest_ring);\r\nath10k_err(ar, "failed to allocate copy engine destination ring %d: %d\n",\r\nce_id, ret);\r\nce_state->dest_ring = NULL;\r\nreturn ret;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nvoid ath10k_ce_free_pipe(struct ath10k *ar, int ce_id)\r\n{\r\nstruct ath10k_pci *ar_pci = ath10k_pci_priv(ar);\r\nstruct ath10k_ce_pipe *ce_state = &ar_pci->ce_states[ce_id];\r\nif (ce_state->src_ring) {\r\ndma_free_coherent(ar->dev,\r\n(ce_state->src_ring->nentries *\r\nsizeof(struct ce_desc) +\r\nCE_DESC_RING_ALIGN),\r\nce_state->src_ring->base_addr_owner_space,\r\nce_state->src_ring->base_addr_ce_space);\r\nkfree(ce_state->src_ring);\r\n}\r\nif (ce_state->dest_ring) {\r\ndma_free_coherent(ar->dev,\r\n(ce_state->dest_ring->nentries *\r\nsizeof(struct ce_desc) +\r\nCE_DESC_RING_ALIGN),\r\nce_state->dest_ring->base_addr_owner_space,\r\nce_state->dest_ring->base_addr_ce_space);\r\nkfree(ce_state->dest_ring);\r\n}\r\nce_state->src_ring = NULL;\r\nce_state->dest_ring = NULL;\r\n}
