static void ni65_set_performance(struct priv *p)\r\n{\r\nwritereg(CSR0_STOP | CSR0_CLRALL,CSR0);\r\nif( !(cards[p->cardno].config & 0x02) )\r\nreturn;\r\noutw(80,PORT+L_ADDRREG);\r\nif(inw(PORT+L_ADDRREG) != 80)\r\nreturn;\r\nwritereg( (csr80 & 0x3fff) ,80);\r\noutw(0,PORT+L_ADDRREG);\r\noutw((short)isa0,PORT+L_BUSIF);\r\noutw(1,PORT+L_ADDRREG);\r\noutw((short)isa1,PORT+L_BUSIF);\r\noutw(CSR0,PORT+L_ADDRREG);\r\n}\r\nstatic int ni65_open(struct net_device *dev)\r\n{\r\nstruct priv *p = dev->ml_priv;\r\nint irqval = request_irq(dev->irq, ni65_interrupt,0,\r\ncards[p->cardno].cardname,dev);\r\nif (irqval) {\r\nprintk(KERN_ERR "%s: unable to get IRQ %d (irqval=%d).\n",\r\ndev->name,dev->irq, irqval);\r\nreturn -EAGAIN;\r\n}\r\nif(ni65_lance_reinit(dev))\r\n{\r\nnetif_start_queue(dev);\r\nreturn 0;\r\n}\r\nelse\r\n{\r\nfree_irq(dev->irq,dev);\r\nreturn -EAGAIN;\r\n}\r\n}\r\nstatic int ni65_close(struct net_device *dev)\r\n{\r\nstruct priv *p = dev->ml_priv;\r\nnetif_stop_queue(dev);\r\noutw(inw(PORT+L_RESET),PORT+L_RESET);\r\n#ifdef XMT_VIA_SKB\r\n{\r\nint i;\r\nfor(i=0;i<TMDNUM;i++)\r\n{\r\nif(p->tmd_skb[i]) {\r\ndev_kfree_skb(p->tmd_skb[i]);\r\np->tmd_skb[i] = NULL;\r\n}\r\n}\r\n}\r\n#endif\r\nfree_irq(dev->irq,dev);\r\nreturn 0;\r\n}\r\nstatic void cleanup_card(struct net_device *dev)\r\n{\r\nstruct priv *p = dev->ml_priv;\r\ndisable_dma(dev->dma);\r\nfree_dma(dev->dma);\r\nrelease_region(dev->base_addr, cards[p->cardno].total_size);\r\nni65_free_buffer(p);\r\n}\r\nstruct net_device * __init ni65_probe(int unit)\r\n{\r\nstruct net_device *dev = alloc_etherdev(0);\r\nstatic const int ports[] = { 0x360, 0x300, 0x320, 0x340, 0 };\r\nconst int *port;\r\nint err = 0;\r\nif (!dev)\r\nreturn ERR_PTR(-ENOMEM);\r\nif (unit >= 0) {\r\nsprintf(dev->name, "eth%d", unit);\r\nnetdev_boot_setup_check(dev);\r\nirq = dev->irq;\r\ndma = dev->dma;\r\n} else {\r\ndev->base_addr = io;\r\n}\r\nif (dev->base_addr > 0x1ff) {\r\nerr = ni65_probe1(dev, dev->base_addr);\r\n} else if (dev->base_addr > 0) {\r\nerr = -ENXIO;\r\n} else {\r\nfor (port = ports; *port && ni65_probe1(dev, *port); port++)\r\n;\r\nif (!*port)\r\nerr = -ENODEV;\r\n}\r\nif (err)\r\ngoto out;\r\nerr = register_netdev(dev);\r\nif (err)\r\ngoto out1;\r\nreturn dev;\r\nout1:\r\ncleanup_card(dev);\r\nout:\r\nfree_netdev(dev);\r\nreturn ERR_PTR(err);\r\n}\r\nstatic int __init ni65_probe1(struct net_device *dev,int ioaddr)\r\n{\r\nint i,j;\r\nstruct priv *p;\r\nunsigned long flags;\r\ndev->irq = irq;\r\ndev->dma = dma;\r\nfor(i=0;i<NUM_CARDS;i++) {\r\nif(!request_region(ioaddr, cards[i].total_size, cards[i].cardname))\r\ncontinue;\r\nif(cards[i].id_offset >= 0) {\r\nif(inb(ioaddr+cards[i].id_offset+0) != cards[i].id0 ||\r\ninb(ioaddr+cards[i].id_offset+1) != cards[i].id1) {\r\nrelease_region(ioaddr, cards[i].total_size);\r\ncontinue;\r\n}\r\n}\r\nif(cards[i].vendor_id) {\r\nfor(j=0;j<3;j++)\r\nif(inb(ioaddr+cards[i].addr_offset+j) != cards[i].vendor_id[j]) {\r\nrelease_region(ioaddr, cards[i].total_size);\r\ncontinue;\r\n}\r\n}\r\nbreak;\r\n}\r\nif(i == NUM_CARDS)\r\nreturn -ENODEV;\r\nfor(j=0;j<6;j++)\r\ndev->dev_addr[j] = inb(ioaddr+cards[i].addr_offset+j);\r\nif( (j=ni65_alloc_buffer(dev)) < 0) {\r\nrelease_region(ioaddr, cards[i].total_size);\r\nreturn j;\r\n}\r\np = dev->ml_priv;\r\np->cmdr_addr = ioaddr + cards[i].cmd_offset;\r\np->cardno = i;\r\nspin_lock_init(&p->ring_lock);\r\nprintk(KERN_INFO "%s: %s found at %#3x, ", dev->name, cards[p->cardno].cardname , ioaddr);\r\noutw(inw(PORT+L_RESET),PORT+L_RESET);\r\nif( (j=readreg(CSR0)) != 0x4) {\r\nprintk("failed.\n");\r\nprintk(KERN_ERR "%s: Can't RESET card: %04x\n", dev->name, j);\r\nni65_free_buffer(p);\r\nrelease_region(ioaddr, cards[p->cardno].total_size);\r\nreturn -EAGAIN;\r\n}\r\noutw(88,PORT+L_ADDRREG);\r\nif(inw(PORT+L_ADDRREG) == 88) {\r\nunsigned long v;\r\nv = inw(PORT+L_DATAREG);\r\nv <<= 16;\r\noutw(89,PORT+L_ADDRREG);\r\nv |= inw(PORT+L_DATAREG);\r\nprintk("Version %#08lx, ",v);\r\np->features = INIT_RING_BEFORE_START;\r\n}\r\nelse {\r\nprintk("ancient LANCE, ");\r\np->features = 0x0;\r\n}\r\nif(test_bit(0,&cards[i].config)) {\r\ndev->irq = irqtab[(inw(ioaddr+L_CONFIG)>>2)&3];\r\ndev->dma = dmatab[inw(ioaddr+L_CONFIG)&3];\r\nprintk("IRQ %d (from card), DMA %d (from card).\n",dev->irq,dev->dma);\r\n}\r\nelse {\r\nif(dev->dma == 0) {\r\nunsigned long dma_channels =\r\n((inb(DMA1_STAT_REG) >> 4) & 0x0f)\r\n| (inb(DMA2_STAT_REG) & 0xf0);\r\nfor(i=1;i<5;i++) {\r\nint dma = dmatab[i];\r\nif(test_bit(dma,&dma_channels) || request_dma(dma,"ni6510"))\r\ncontinue;\r\nflags=claim_dma_lock();\r\ndisable_dma(dma);\r\nset_dma_mode(dma,DMA_MODE_CASCADE);\r\nenable_dma(dma);\r\nrelease_dma_lock(flags);\r\nni65_init_lance(p,dev->dev_addr,0,0);\r\nflags=claim_dma_lock();\r\ndisable_dma(dma);\r\nfree_dma(dma);\r\nrelease_dma_lock(flags);\r\nif(readreg(CSR0) & CSR0_IDON)\r\nbreak;\r\n}\r\nif(i == 5) {\r\nprintk("failed.\n");\r\nprintk(KERN_ERR "%s: Can't detect DMA channel!\n", dev->name);\r\nni65_free_buffer(p);\r\nrelease_region(ioaddr, cards[p->cardno].total_size);\r\nreturn -EAGAIN;\r\n}\r\ndev->dma = dmatab[i];\r\nprintk("DMA %d (autodetected), ",dev->dma);\r\n}\r\nelse\r\nprintk("DMA %d (assigned), ",dev->dma);\r\nif(dev->irq < 2)\r\n{\r\nunsigned long irq_mask;\r\nni65_init_lance(p,dev->dev_addr,0,0);\r\nirq_mask = probe_irq_on();\r\nwritereg(CSR0_INIT|CSR0_INEA,CSR0);\r\nmsleep(20);\r\ndev->irq = probe_irq_off(irq_mask);\r\nif(!dev->irq)\r\n{\r\nprintk("Failed to detect IRQ line!\n");\r\nni65_free_buffer(p);\r\nrelease_region(ioaddr, cards[p->cardno].total_size);\r\nreturn -EAGAIN;\r\n}\r\nprintk("IRQ %d (autodetected).\n",dev->irq);\r\n}\r\nelse\r\nprintk("IRQ %d (assigned).\n",dev->irq);\r\n}\r\nif(request_dma(dev->dma, cards[p->cardno].cardname ) != 0)\r\n{\r\nprintk(KERN_ERR "%s: Can't request dma-channel %d\n",dev->name,(int) dev->dma);\r\nni65_free_buffer(p);\r\nrelease_region(ioaddr, cards[p->cardno].total_size);\r\nreturn -EAGAIN;\r\n}\r\ndev->base_addr = ioaddr;\r\ndev->netdev_ops = &ni65_netdev_ops;\r\ndev->watchdog_timeo = HZ/2;\r\nreturn 0;\r\n}\r\nstatic void ni65_init_lance(struct priv *p,unsigned char *daddr,int filter,int mode)\r\n{\r\nint i;\r\nu32 pib;\r\nwritereg(CSR0_CLRALL|CSR0_STOP,CSR0);\r\nfor(i=0;i<6;i++)\r\np->ib.eaddr[i] = daddr[i];\r\nfor(i=0;i<8;i++)\r\np->ib.filter[i] = filter;\r\np->ib.mode = mode;\r\np->ib.trp = (u32) isa_virt_to_bus(p->tmdhead) | TMDNUMMASK;\r\np->ib.rrp = (u32) isa_virt_to_bus(p->rmdhead) | RMDNUMMASK;\r\nwritereg(0,CSR3);\r\npib = (u32) isa_virt_to_bus(&p->ib);\r\nwritereg(pib & 0xffff,CSR1);\r\nwritereg(pib >> 16,CSR2);\r\nwritereg(CSR0_INIT,CSR0);\r\nfor(i=0;i<32;i++)\r\n{\r\nmdelay(4);\r\nif(inw(PORT+L_DATAREG) & (CSR0_IDON | CSR0_MERR) )\r\nbreak;\r\n}\r\n}\r\nstatic void *ni65_alloc_mem(struct net_device *dev,char *what,int size,int type)\r\n{\r\nstruct sk_buff *skb=NULL;\r\nunsigned char *ptr;\r\nvoid *ret;\r\nif(type) {\r\nret = skb = alloc_skb(2+16+size,GFP_KERNEL|GFP_DMA);\r\nif(!skb) {\r\nprintk(KERN_WARNING "%s: unable to allocate %s memory.\n",dev->name,what);\r\nreturn NULL;\r\n}\r\nskb_reserve(skb,2+16);\r\nskb_put(skb,R_BUF_SIZE);\r\nptr = skb->data;\r\n}\r\nelse {\r\nret = ptr = kmalloc(T_BUF_SIZE,GFP_KERNEL | GFP_DMA);\r\nif(!ret)\r\nreturn NULL;\r\n}\r\nif( (u32) virt_to_phys(ptr+size) > 0x1000000) {\r\nprintk(KERN_WARNING "%s: unable to allocate %s memory in lower 16MB!\n",dev->name,what);\r\nif(type)\r\nkfree_skb(skb);\r\nelse\r\nkfree(ptr);\r\nreturn NULL;\r\n}\r\nreturn ret;\r\n}\r\nstatic int ni65_alloc_buffer(struct net_device *dev)\r\n{\r\nunsigned char *ptr;\r\nstruct priv *p;\r\nint i;\r\nptr = ni65_alloc_mem(dev,"BUFFER",sizeof(struct priv)+8,0);\r\nif(!ptr)\r\nreturn -ENOMEM;\r\np = dev->ml_priv = (struct priv *) (((unsigned long) ptr + 7) & ~0x7);\r\nmemset((char *)p, 0, sizeof(struct priv));\r\np->self = ptr;\r\nfor(i=0;i<TMDNUM;i++)\r\n{\r\n#ifdef XMT_VIA_SKB\r\np->tmd_skb[i] = NULL;\r\n#endif\r\np->tmdbounce[i] = ni65_alloc_mem(dev,"XMIT",T_BUF_SIZE,0);\r\nif(!p->tmdbounce[i]) {\r\nni65_free_buffer(p);\r\nreturn -ENOMEM;\r\n}\r\n}\r\nfor(i=0;i<RMDNUM;i++)\r\n{\r\n#ifdef RCV_VIA_SKB\r\np->recv_skb[i] = ni65_alloc_mem(dev,"RECV",R_BUF_SIZE,1);\r\nif(!p->recv_skb[i]) {\r\nni65_free_buffer(p);\r\nreturn -ENOMEM;\r\n}\r\n#else\r\np->recvbounce[i] = ni65_alloc_mem(dev,"RECV",R_BUF_SIZE,0);\r\nif(!p->recvbounce[i]) {\r\nni65_free_buffer(p);\r\nreturn -ENOMEM;\r\n}\r\n#endif\r\n}\r\nreturn 0;\r\n}\r\nstatic void ni65_free_buffer(struct priv *p)\r\n{\r\nint i;\r\nif(!p)\r\nreturn;\r\nfor(i=0;i<TMDNUM;i++) {\r\nkfree(p->tmdbounce[i]);\r\n#ifdef XMT_VIA_SKB\r\nif(p->tmd_skb[i])\r\ndev_kfree_skb(p->tmd_skb[i]);\r\n#endif\r\n}\r\nfor(i=0;i<RMDNUM;i++)\r\n{\r\n#ifdef RCV_VIA_SKB\r\nif(p->recv_skb[i])\r\ndev_kfree_skb(p->recv_skb[i]);\r\n#else\r\nkfree(p->recvbounce[i]);\r\n#endif\r\n}\r\nkfree(p->self);\r\n}\r\nstatic void ni65_stop_start(struct net_device *dev,struct priv *p)\r\n{\r\nint csr0 = CSR0_INEA;\r\nwritedatareg(CSR0_STOP);\r\nif(debuglevel > 1)\r\nprintk(KERN_DEBUG "ni65_stop_start\n");\r\nif(p->features & INIT_RING_BEFORE_START) {\r\nint i;\r\n#ifdef XMT_VIA_SKB\r\nstruct sk_buff *skb_save[TMDNUM];\r\n#endif\r\nunsigned long buffer[TMDNUM];\r\nshort blen[TMDNUM];\r\nif(p->xmit_queued) {\r\nwhile(1) {\r\nif((p->tmdhead[p->tmdlast].u.s.status & XMIT_OWN))\r\nbreak;\r\np->tmdlast = (p->tmdlast + 1) & (TMDNUM-1);\r\nif(p->tmdlast == p->tmdnum)\r\nbreak;\r\n}\r\n}\r\nfor(i=0;i<TMDNUM;i++) {\r\nstruct tmd *tmdp = p->tmdhead + i;\r\n#ifdef XMT_VIA_SKB\r\nskb_save[i] = p->tmd_skb[i];\r\n#endif\r\nbuffer[i] = (u32) isa_bus_to_virt(tmdp->u.buffer);\r\nblen[i] = tmdp->blen;\r\ntmdp->u.s.status = 0x0;\r\n}\r\nfor(i=0;i<RMDNUM;i++) {\r\nstruct rmd *rmdp = p->rmdhead + i;\r\nrmdp->u.s.status = RCV_OWN;\r\n}\r\np->tmdnum = p->xmit_queued = 0;\r\nwritedatareg(CSR0_STRT | csr0);\r\nfor(i=0;i<TMDNUM;i++) {\r\nint num = (i + p->tmdlast) & (TMDNUM-1);\r\np->tmdhead[i].u.buffer = (u32) isa_virt_to_bus((char *)buffer[num]);\r\np->tmdhead[i].blen = blen[num];\r\nif(p->tmdhead[i].u.s.status & XMIT_OWN) {\r\np->tmdnum = (p->tmdnum + 1) & (TMDNUM-1);\r\np->xmit_queued = 1;\r\nwritedatareg(CSR0_TDMD | CSR0_INEA | csr0);\r\n}\r\n#ifdef XMT_VIA_SKB\r\np->tmd_skb[i] = skb_save[num];\r\n#endif\r\n}\r\np->rmdnum = p->tmdlast = 0;\r\nif(!p->lock)\r\nif (p->tmdnum || !p->xmit_queued)\r\nnetif_wake_queue(dev);\r\nnetif_trans_update(dev);\r\n}\r\nelse\r\nwritedatareg(CSR0_STRT | csr0);\r\n}\r\nstatic int ni65_lance_reinit(struct net_device *dev)\r\n{\r\nint i;\r\nstruct priv *p = dev->ml_priv;\r\nunsigned long flags;\r\np->lock = 0;\r\np->xmit_queued = 0;\r\nflags=claim_dma_lock();\r\ndisable_dma(dev->dma);\r\nset_dma_mode(dev->dma,DMA_MODE_CASCADE);\r\nenable_dma(dev->dma);\r\nrelease_dma_lock(flags);\r\noutw(inw(PORT+L_RESET),PORT+L_RESET);\r\nif( (i=readreg(CSR0) ) != 0x4)\r\n{\r\nprintk(KERN_ERR "%s: can't RESET %s card: %04x\n",dev->name,\r\ncards[p->cardno].cardname,(int) i);\r\nflags=claim_dma_lock();\r\ndisable_dma(dev->dma);\r\nrelease_dma_lock(flags);\r\nreturn 0;\r\n}\r\np->rmdnum = p->tmdnum = p->tmdlast = p->tmdbouncenum = 0;\r\nfor(i=0;i<TMDNUM;i++)\r\n{\r\nstruct tmd *tmdp = p->tmdhead + i;\r\n#ifdef XMT_VIA_SKB\r\nif(p->tmd_skb[i]) {\r\ndev_kfree_skb(p->tmd_skb[i]);\r\np->tmd_skb[i] = NULL;\r\n}\r\n#endif\r\ntmdp->u.buffer = 0x0;\r\ntmdp->u.s.status = XMIT_START | XMIT_END;\r\ntmdp->blen = tmdp->status2 = 0;\r\n}\r\nfor(i=0;i<RMDNUM;i++)\r\n{\r\nstruct rmd *rmdp = p->rmdhead + i;\r\n#ifdef RCV_VIA_SKB\r\nrmdp->u.buffer = (u32) isa_virt_to_bus(p->recv_skb[i]->data);\r\n#else\r\nrmdp->u.buffer = (u32) isa_virt_to_bus(p->recvbounce[i]);\r\n#endif\r\nrmdp->blen = -(R_BUF_SIZE-8);\r\nrmdp->mlen = 0;\r\nrmdp->u.s.status = RCV_OWN;\r\n}\r\nif(dev->flags & IFF_PROMISC)\r\nni65_init_lance(p,dev->dev_addr,0x00,M_PROM);\r\nelse if (netdev_mc_count(dev) || dev->flags & IFF_ALLMULTI)\r\nni65_init_lance(p,dev->dev_addr,0xff,0x0);\r\nelse\r\nni65_init_lance(p,dev->dev_addr,0x00,0x00);\r\nif(inw(PORT+L_DATAREG) & CSR0_IDON) {\r\nni65_set_performance(p);\r\nwritedatareg(CSR0_CLRALL | CSR0_INEA | CSR0_STRT);\r\nreturn 1;\r\n}\r\nprintk(KERN_ERR "%s: can't init lance, status: %04x\n",dev->name,(int) inw(PORT+L_DATAREG));\r\nflags=claim_dma_lock();\r\ndisable_dma(dev->dma);\r\nrelease_dma_lock(flags);\r\nreturn 0;\r\n}\r\nstatic irqreturn_t ni65_interrupt(int irq, void * dev_id)\r\n{\r\nint csr0 = 0;\r\nstruct net_device *dev = dev_id;\r\nstruct priv *p;\r\nint bcnt = 32;\r\np = dev->ml_priv;\r\nspin_lock(&p->ring_lock);\r\nwhile(--bcnt) {\r\ncsr0 = inw(PORT+L_DATAREG);\r\n#if 0\r\nwritedatareg( (csr0 & CSR0_CLRALL) );\r\n#else\r\nwritedatareg( (csr0 & CSR0_CLRALL) | CSR0_INEA );\r\n#endif\r\nif(!(csr0 & (CSR0_ERR | CSR0_RINT | CSR0_TINT)))\r\nbreak;\r\nif(csr0 & CSR0_RINT)\r\nni65_recv_intr(dev,csr0);\r\nif(csr0 & CSR0_TINT)\r\nni65_xmit_intr(dev,csr0);\r\nif(csr0 & CSR0_ERR)\r\n{\r\nif(debuglevel > 1)\r\nprintk(KERN_ERR "%s: general error: %04x.\n",dev->name,csr0);\r\nif(csr0 & CSR0_BABL)\r\ndev->stats.tx_errors++;\r\nif(csr0 & CSR0_MISS) {\r\nint i;\r\nfor(i=0;i<RMDNUM;i++)\r\nprintk("%02x ",p->rmdhead[i].u.s.status);\r\nprintk("\n");\r\ndev->stats.rx_errors++;\r\n}\r\nif(csr0 & CSR0_MERR) {\r\nif(debuglevel > 1)\r\nprintk(KERN_ERR "%s: Ooops .. memory error: %04x.\n",dev->name,csr0);\r\nni65_stop_start(dev,p);\r\n}\r\n}\r\n}\r\n#ifdef RCV_PARANOIA_CHECK\r\n{\r\nint j;\r\nfor(j=0;j<RMDNUM;j++)\r\n{\r\nint i, num2;\r\nfor(i=RMDNUM-1;i>0;i--) {\r\nnum2 = (p->rmdnum + i) & (RMDNUM-1);\r\nif(!(p->rmdhead[num2].u.s.status & RCV_OWN))\r\nbreak;\r\n}\r\nif(i) {\r\nint k, num1;\r\nfor(k=0;k<RMDNUM;k++) {\r\nnum1 = (p->rmdnum + k) & (RMDNUM-1);\r\nif(!(p->rmdhead[num1].u.s.status & RCV_OWN))\r\nbreak;\r\n}\r\nif(!k)\r\nbreak;\r\nif(debuglevel > 0)\r\n{\r\nchar buf[256],*buf1;\r\nbuf1 = buf;\r\nfor(k=0;k<RMDNUM;k++) {\r\nsprintf(buf1,"%02x ",(p->rmdhead[k].u.s.status));\r\nbuf1 += 3;\r\n}\r\n*buf1 = 0;\r\nprintk(KERN_ERR "%s: Ooops, receive ring corrupted %2d %2d | %s\n",dev->name,p->rmdnum,i,buf);\r\n}\r\np->rmdnum = num1;\r\nni65_recv_intr(dev,csr0);\r\nif((p->rmdhead[num2].u.s.status & RCV_OWN))\r\nbreak;\r\n}\r\nelse\r\nbreak;\r\n}\r\n}\r\n#endif\r\nif( (csr0 & (CSR0_RXON | CSR0_TXON)) != (CSR0_RXON | CSR0_TXON) ) {\r\nprintk(KERN_DEBUG "%s: RX or TX was offline -> restart\n",dev->name);\r\nni65_stop_start(dev,p);\r\n}\r\nelse\r\nwritedatareg(CSR0_INEA);\r\nspin_unlock(&p->ring_lock);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void ni65_xmit_intr(struct net_device *dev,int csr0)\r\n{\r\nstruct priv *p = dev->ml_priv;\r\nwhile(p->xmit_queued)\r\n{\r\nstruct tmd *tmdp = p->tmdhead + p->tmdlast;\r\nint tmdstat = tmdp->u.s.status;\r\nif(tmdstat & XMIT_OWN)\r\nbreak;\r\nif(tmdstat & XMIT_ERR)\r\n{\r\n#if 0\r\nif(tmdp->status2 & XMIT_TDRMASK && debuglevel > 3)\r\nprintk(KERN_ERR "%s: tdr-problems (e.g. no resistor)\n",dev->name);\r\n#endif\r\nif(tmdp->status2 & XMIT_RTRY)\r\ndev->stats.tx_aborted_errors++;\r\nif(tmdp->status2 & XMIT_LCAR)\r\ndev->stats.tx_carrier_errors++;\r\nif(tmdp->status2 & (XMIT_BUFF | XMIT_UFLO )) {\r\ndev->stats.tx_fifo_errors++;\r\nif(debuglevel > 0)\r\nprintk(KERN_ERR "%s: Xmit FIFO/BUFF error\n",dev->name);\r\nif(p->features & INIT_RING_BEFORE_START) {\r\ntmdp->u.s.status = XMIT_OWN | XMIT_START | XMIT_END;\r\nni65_stop_start(dev,p);\r\nbreak;\r\n}\r\nelse\r\nni65_stop_start(dev,p);\r\n}\r\nif(debuglevel > 2)\r\nprintk(KERN_ERR "%s: xmit-error: %04x %02x-%04x\n",dev->name,csr0,(int) tmdstat,(int) tmdp->status2);\r\nif(!(csr0 & CSR0_BABL))\r\ndev->stats.tx_errors++;\r\ntmdp->status2 = 0;\r\n}\r\nelse {\r\ndev->stats.tx_bytes -= (short)(tmdp->blen);\r\ndev->stats.tx_packets++;\r\n}\r\n#ifdef XMT_VIA_SKB\r\nif(p->tmd_skb[p->tmdlast]) {\r\ndev_kfree_skb_irq(p->tmd_skb[p->tmdlast]);\r\np->tmd_skb[p->tmdlast] = NULL;\r\n}\r\n#endif\r\np->tmdlast = (p->tmdlast + 1) & (TMDNUM-1);\r\nif(p->tmdlast == p->tmdnum)\r\np->xmit_queued = 0;\r\n}\r\nnetif_wake_queue(dev);\r\n}\r\nstatic void ni65_recv_intr(struct net_device *dev,int csr0)\r\n{\r\nstruct rmd *rmdp;\r\nint rmdstat,len;\r\nint cnt=0;\r\nstruct priv *p = dev->ml_priv;\r\nrmdp = p->rmdhead + p->rmdnum;\r\nwhile(!( (rmdstat = rmdp->u.s.status) & RCV_OWN))\r\n{\r\ncnt++;\r\nif( (rmdstat & (RCV_START | RCV_END | RCV_ERR)) != (RCV_START | RCV_END) )\r\n{\r\nif(!(rmdstat & RCV_ERR)) {\r\nif(rmdstat & RCV_START)\r\n{\r\ndev->stats.rx_length_errors++;\r\nprintk(KERN_ERR "%s: recv, packet too long: %d\n",dev->name,rmdp->mlen & 0x0fff);\r\n}\r\n}\r\nelse {\r\nif(debuglevel > 2)\r\nprintk(KERN_ERR "%s: receive-error: %04x, lance-status: %04x/%04x\n",\r\ndev->name,(int) rmdstat,csr0,(int) inw(PORT+L_DATAREG) );\r\nif(rmdstat & RCV_FRAM)\r\ndev->stats.rx_frame_errors++;\r\nif(rmdstat & RCV_OFLO)\r\ndev->stats.rx_over_errors++;\r\nif(rmdstat & RCV_CRC)\r\ndev->stats.rx_crc_errors++;\r\nif(rmdstat & RCV_BUF_ERR)\r\ndev->stats.rx_fifo_errors++;\r\n}\r\nif(!(csr0 & CSR0_MISS))\r\ndev->stats.rx_errors++;\r\n}\r\nelse if( (len = (rmdp->mlen & 0x0fff) - 4) >= 60)\r\n{\r\n#ifdef RCV_VIA_SKB\r\nstruct sk_buff *skb = alloc_skb(R_BUF_SIZE+2+16,GFP_ATOMIC);\r\nif (skb)\r\nskb_reserve(skb,16);\r\n#else\r\nstruct sk_buff *skb = netdev_alloc_skb(dev, len + 2);\r\n#endif\r\nif(skb)\r\n{\r\nskb_reserve(skb,2);\r\n#ifdef RCV_VIA_SKB\r\nif( (unsigned long) (skb->data + R_BUF_SIZE) > 0x1000000) {\r\nskb_put(skb,len);\r\nskb_copy_to_linear_data(skb, (unsigned char *)(p->recv_skb[p->rmdnum]->data),len);\r\n}\r\nelse {\r\nstruct sk_buff *skb1 = p->recv_skb[p->rmdnum];\r\nskb_put(skb,R_BUF_SIZE);\r\np->recv_skb[p->rmdnum] = skb;\r\nrmdp->u.buffer = (u32) isa_virt_to_bus(skb->data);\r\nskb = skb1;\r\nskb_trim(skb,len);\r\n}\r\n#else\r\nskb_put(skb,len);\r\nskb_copy_to_linear_data(skb, (unsigned char *) p->recvbounce[p->rmdnum],len);\r\n#endif\r\ndev->stats.rx_packets++;\r\ndev->stats.rx_bytes += len;\r\nskb->protocol=eth_type_trans(skb,dev);\r\nnetif_rx(skb);\r\n}\r\nelse\r\n{\r\nprintk(KERN_ERR "%s: can't alloc new sk_buff\n",dev->name);\r\ndev->stats.rx_dropped++;\r\n}\r\n}\r\nelse {\r\nprintk(KERN_INFO "%s: received runt packet\n",dev->name);\r\ndev->stats.rx_errors++;\r\n}\r\nrmdp->blen = -(R_BUF_SIZE-8);\r\nrmdp->mlen = 0;\r\nrmdp->u.s.status = RCV_OWN;\r\np->rmdnum = (p->rmdnum + 1) & (RMDNUM-1);\r\nrmdp = p->rmdhead + p->rmdnum;\r\n}\r\n}\r\nstatic void ni65_timeout(struct net_device *dev)\r\n{\r\nint i;\r\nstruct priv *p = dev->ml_priv;\r\nprintk(KERN_ERR "%s: xmitter timed out, try to restart!\n",dev->name);\r\nfor(i=0;i<TMDNUM;i++)\r\nprintk("%02x ",p->tmdhead[i].u.s.status);\r\nprintk("\n");\r\nni65_lance_reinit(dev);\r\nnetif_trans_update(dev);\r\nnetif_wake_queue(dev);\r\n}\r\nstatic netdev_tx_t ni65_send_packet(struct sk_buff *skb,\r\nstruct net_device *dev)\r\n{\r\nstruct priv *p = dev->ml_priv;\r\nnetif_stop_queue(dev);\r\nif (test_and_set_bit(0, (void*)&p->lock)) {\r\nprintk(KERN_ERR "%s: Queue was locked.\n", dev->name);\r\nreturn NETDEV_TX_BUSY;\r\n}\r\n{\r\nshort len = ETH_ZLEN < skb->len ? skb->len : ETH_ZLEN;\r\nstruct tmd *tmdp;\r\nunsigned long flags;\r\n#ifdef XMT_VIA_SKB\r\nif( (unsigned long) (skb->data + skb->len) > 0x1000000) {\r\n#endif\r\nskb_copy_from_linear_data(skb, p->tmdbounce[p->tmdbouncenum],\r\nskb->len > T_BUF_SIZE ? T_BUF_SIZE :\r\nskb->len);\r\nif (len > skb->len)\r\nmemset((char *)p->tmdbounce[p->tmdbouncenum]+skb->len, 0, len-skb->len);\r\ndev_kfree_skb (skb);\r\nspin_lock_irqsave(&p->ring_lock, flags);\r\ntmdp = p->tmdhead + p->tmdnum;\r\ntmdp->u.buffer = (u32) isa_virt_to_bus(p->tmdbounce[p->tmdbouncenum]);\r\np->tmdbouncenum = (p->tmdbouncenum + 1) & (TMDNUM - 1);\r\n#ifdef XMT_VIA_SKB\r\n}\r\nelse {\r\nspin_lock_irqsave(&p->ring_lock, flags);\r\ntmdp = p->tmdhead + p->tmdnum;\r\ntmdp->u.buffer = (u32) isa_virt_to_bus(skb->data);\r\np->tmd_skb[p->tmdnum] = skb;\r\n}\r\n#endif\r\ntmdp->blen = -len;\r\ntmdp->u.s.status = XMIT_OWN | XMIT_START | XMIT_END;\r\nwritedatareg(CSR0_TDMD | CSR0_INEA);\r\np->xmit_queued = 1;\r\np->tmdnum = (p->tmdnum + 1) & (TMDNUM-1);\r\nif(p->tmdnum != p->tmdlast)\r\nnetif_wake_queue(dev);\r\np->lock = 0;\r\nspin_unlock_irqrestore(&p->ring_lock, flags);\r\n}\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void set_multicast_list(struct net_device *dev)\r\n{\r\nif(!ni65_lance_reinit(dev))\r\nprintk(KERN_ERR "%s: Can't switch card into MC mode!\n",dev->name);\r\nnetif_wake_queue(dev);\r\n}\r\nint __init init_module(void)\r\n{\r\ndev_ni65 = ni65_probe(-1);\r\nreturn PTR_ERR_OR_ZERO(dev_ni65);\r\n}\r\nvoid __exit cleanup_module(void)\r\n{\r\nunregister_netdev(dev_ni65);\r\ncleanup_card(dev_ni65);\r\nfree_netdev(dev_ni65);\r\n}
