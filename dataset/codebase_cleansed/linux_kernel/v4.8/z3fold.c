static int size_to_chunks(size_t size)\r\n{\r\nreturn (size + CHUNK_SIZE - 1) >> CHUNK_SHIFT;\r\n}\r\nstatic struct z3fold_header *init_z3fold_page(struct page *page)\r\n{\r\nstruct z3fold_header *zhdr = page_address(page);\r\nINIT_LIST_HEAD(&page->lru);\r\nclear_bit(UNDER_RECLAIM, &page->private);\r\nclear_bit(PAGE_HEADLESS, &page->private);\r\nclear_bit(MIDDLE_CHUNK_MAPPED, &page->private);\r\nzhdr->first_chunks = 0;\r\nzhdr->middle_chunks = 0;\r\nzhdr->last_chunks = 0;\r\nzhdr->first_num = 0;\r\nzhdr->start_middle = 0;\r\nINIT_LIST_HEAD(&zhdr->buddy);\r\nreturn zhdr;\r\n}\r\nstatic void free_z3fold_page(struct z3fold_header *zhdr)\r\n{\r\n__free_page(virt_to_page(zhdr));\r\n}\r\nstatic unsigned long encode_handle(struct z3fold_header *zhdr, enum buddy bud)\r\n{\r\nunsigned long handle;\r\nhandle = (unsigned long)zhdr;\r\nif (bud != HEADLESS)\r\nhandle += (bud + zhdr->first_num) & BUDDY_MASK;\r\nreturn handle;\r\n}\r\nstatic struct z3fold_header *handle_to_z3fold_header(unsigned long handle)\r\n{\r\nreturn (struct z3fold_header *)(handle & PAGE_MASK);\r\n}\r\nstatic enum buddy handle_to_buddy(unsigned long handle)\r\n{\r\nstruct z3fold_header *zhdr = handle_to_z3fold_header(handle);\r\nreturn (handle - zhdr->first_num) & BUDDY_MASK;\r\n}\r\nstatic int num_free_chunks(struct z3fold_header *zhdr)\r\n{\r\nint nfree;\r\nif (zhdr->middle_chunks != 0) {\r\nint nfree_before = zhdr->first_chunks ?\r\n0 : zhdr->start_middle - 1;\r\nint nfree_after = zhdr->last_chunks ?\r\n0 : NCHUNKS - zhdr->start_middle - zhdr->middle_chunks;\r\nnfree = max(nfree_before, nfree_after);\r\n} else\r\nnfree = NCHUNKS - zhdr->first_chunks - zhdr->last_chunks;\r\nreturn nfree;\r\n}\r\nstatic struct z3fold_pool *z3fold_create_pool(gfp_t gfp,\r\nconst struct z3fold_ops *ops)\r\n{\r\nstruct z3fold_pool *pool;\r\nint i;\r\npool = kzalloc(sizeof(struct z3fold_pool), gfp);\r\nif (!pool)\r\nreturn NULL;\r\nspin_lock_init(&pool->lock);\r\nfor_each_unbuddied_list(i, 0)\r\nINIT_LIST_HEAD(&pool->unbuddied[i]);\r\nINIT_LIST_HEAD(&pool->buddied);\r\nINIT_LIST_HEAD(&pool->lru);\r\npool->pages_nr = 0;\r\npool->ops = ops;\r\nreturn pool;\r\n}\r\nstatic void z3fold_destroy_pool(struct z3fold_pool *pool)\r\n{\r\nkfree(pool);\r\n}\r\nstatic int z3fold_compact_page(struct z3fold_header *zhdr)\r\n{\r\nstruct page *page = virt_to_page(zhdr);\r\nvoid *beg = zhdr;\r\nif (!test_bit(MIDDLE_CHUNK_MAPPED, &page->private) &&\r\nzhdr->middle_chunks != 0 &&\r\nzhdr->first_chunks == 0 && zhdr->last_chunks == 0) {\r\nmemmove(beg + ZHDR_SIZE_ALIGNED,\r\nbeg + (zhdr->start_middle << CHUNK_SHIFT),\r\nzhdr->middle_chunks << CHUNK_SHIFT);\r\nzhdr->first_chunks = zhdr->middle_chunks;\r\nzhdr->middle_chunks = 0;\r\nzhdr->start_middle = 0;\r\nzhdr->first_num++;\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int z3fold_alloc(struct z3fold_pool *pool, size_t size, gfp_t gfp,\r\nunsigned long *handle)\r\n{\r\nint chunks = 0, i, freechunks;\r\nstruct z3fold_header *zhdr = NULL;\r\nenum buddy bud;\r\nstruct page *page;\r\nif (!size || (gfp & __GFP_HIGHMEM))\r\nreturn -EINVAL;\r\nif (size > PAGE_SIZE)\r\nreturn -ENOSPC;\r\nif (size > PAGE_SIZE - ZHDR_SIZE_ALIGNED - CHUNK_SIZE)\r\nbud = HEADLESS;\r\nelse {\r\nchunks = size_to_chunks(size);\r\nspin_lock(&pool->lock);\r\nzhdr = NULL;\r\nfor_each_unbuddied_list(i, chunks) {\r\nif (!list_empty(&pool->unbuddied[i])) {\r\nzhdr = list_first_entry(&pool->unbuddied[i],\r\nstruct z3fold_header, buddy);\r\npage = virt_to_page(zhdr);\r\nif (zhdr->first_chunks == 0) {\r\nif (zhdr->middle_chunks != 0 &&\r\nchunks >= zhdr->start_middle)\r\nbud = LAST;\r\nelse\r\nbud = FIRST;\r\n} else if (zhdr->last_chunks == 0)\r\nbud = LAST;\r\nelse if (zhdr->middle_chunks == 0)\r\nbud = MIDDLE;\r\nelse {\r\npr_err("No free chunks in unbuddied\n");\r\nWARN_ON(1);\r\ncontinue;\r\n}\r\nlist_del(&zhdr->buddy);\r\ngoto found;\r\n}\r\n}\r\nbud = FIRST;\r\nspin_unlock(&pool->lock);\r\n}\r\npage = alloc_page(gfp);\r\nif (!page)\r\nreturn -ENOMEM;\r\nspin_lock(&pool->lock);\r\npool->pages_nr++;\r\nzhdr = init_z3fold_page(page);\r\nif (bud == HEADLESS) {\r\nset_bit(PAGE_HEADLESS, &page->private);\r\ngoto headless;\r\n}\r\nfound:\r\nif (bud == FIRST)\r\nzhdr->first_chunks = chunks;\r\nelse if (bud == LAST)\r\nzhdr->last_chunks = chunks;\r\nelse {\r\nzhdr->middle_chunks = chunks;\r\nzhdr->start_middle = zhdr->first_chunks + 1;\r\n}\r\nif (zhdr->first_chunks == 0 || zhdr->last_chunks == 0 ||\r\nzhdr->middle_chunks == 0) {\r\nfreechunks = num_free_chunks(zhdr);\r\nlist_add(&zhdr->buddy, &pool->unbuddied[freechunks]);\r\n} else {\r\nlist_add(&zhdr->buddy, &pool->buddied);\r\n}\r\nheadless:\r\nif (!list_empty(&page->lru))\r\nlist_del(&page->lru);\r\nlist_add(&page->lru, &pool->lru);\r\n*handle = encode_handle(zhdr, bud);\r\nspin_unlock(&pool->lock);\r\nreturn 0;\r\n}\r\nstatic void z3fold_free(struct z3fold_pool *pool, unsigned long handle)\r\n{\r\nstruct z3fold_header *zhdr;\r\nint freechunks;\r\nstruct page *page;\r\nenum buddy bud;\r\nspin_lock(&pool->lock);\r\nzhdr = handle_to_z3fold_header(handle);\r\npage = virt_to_page(zhdr);\r\nif (test_bit(PAGE_HEADLESS, &page->private)) {\r\nbud = HEADLESS;\r\n} else {\r\nbud = handle_to_buddy(handle);\r\nswitch (bud) {\r\ncase FIRST:\r\nzhdr->first_chunks = 0;\r\nbreak;\r\ncase MIDDLE:\r\nzhdr->middle_chunks = 0;\r\nzhdr->start_middle = 0;\r\nbreak;\r\ncase LAST:\r\nzhdr->last_chunks = 0;\r\nbreak;\r\ndefault:\r\npr_err("%s: unknown bud %d\n", __func__, bud);\r\nWARN_ON(1);\r\nspin_unlock(&pool->lock);\r\nreturn;\r\n}\r\n}\r\nif (test_bit(UNDER_RECLAIM, &page->private)) {\r\nspin_unlock(&pool->lock);\r\nreturn;\r\n}\r\nif (bud != HEADLESS) {\r\nlist_del(&zhdr->buddy);\r\n}\r\nif (bud == HEADLESS ||\r\n(zhdr->first_chunks == 0 && zhdr->middle_chunks == 0 &&\r\nzhdr->last_chunks == 0)) {\r\nlist_del(&page->lru);\r\nclear_bit(PAGE_HEADLESS, &page->private);\r\nfree_z3fold_page(zhdr);\r\npool->pages_nr--;\r\n} else {\r\nz3fold_compact_page(zhdr);\r\nfreechunks = num_free_chunks(zhdr);\r\nlist_add(&zhdr->buddy, &pool->unbuddied[freechunks]);\r\n}\r\nspin_unlock(&pool->lock);\r\n}\r\nstatic int z3fold_reclaim_page(struct z3fold_pool *pool, unsigned int retries)\r\n{\r\nint i, ret = 0, freechunks;\r\nstruct z3fold_header *zhdr;\r\nstruct page *page;\r\nunsigned long first_handle = 0, middle_handle = 0, last_handle = 0;\r\nspin_lock(&pool->lock);\r\nif (!pool->ops || !pool->ops->evict || list_empty(&pool->lru) ||\r\nretries == 0) {\r\nspin_unlock(&pool->lock);\r\nreturn -EINVAL;\r\n}\r\nfor (i = 0; i < retries; i++) {\r\npage = list_last_entry(&pool->lru, struct page, lru);\r\nlist_del(&page->lru);\r\nset_bit(UNDER_RECLAIM, &page->private);\r\nzhdr = page_address(page);\r\nif (!test_bit(PAGE_HEADLESS, &page->private)) {\r\nlist_del(&zhdr->buddy);\r\nfirst_handle = 0;\r\nlast_handle = 0;\r\nmiddle_handle = 0;\r\nif (zhdr->first_chunks)\r\nfirst_handle = encode_handle(zhdr, FIRST);\r\nif (zhdr->middle_chunks)\r\nmiddle_handle = encode_handle(zhdr, MIDDLE);\r\nif (zhdr->last_chunks)\r\nlast_handle = encode_handle(zhdr, LAST);\r\n} else {\r\nfirst_handle = encode_handle(zhdr, HEADLESS);\r\nlast_handle = middle_handle = 0;\r\n}\r\nspin_unlock(&pool->lock);\r\nif (middle_handle) {\r\nret = pool->ops->evict(pool, middle_handle);\r\nif (ret)\r\ngoto next;\r\n}\r\nif (first_handle) {\r\nret = pool->ops->evict(pool, first_handle);\r\nif (ret)\r\ngoto next;\r\n}\r\nif (last_handle) {\r\nret = pool->ops->evict(pool, last_handle);\r\nif (ret)\r\ngoto next;\r\n}\r\nnext:\r\nspin_lock(&pool->lock);\r\nclear_bit(UNDER_RECLAIM, &page->private);\r\nif ((test_bit(PAGE_HEADLESS, &page->private) && ret == 0) ||\r\n(zhdr->first_chunks == 0 && zhdr->last_chunks == 0 &&\r\nzhdr->middle_chunks == 0)) {\r\nclear_bit(PAGE_HEADLESS, &page->private);\r\nfree_z3fold_page(zhdr);\r\npool->pages_nr--;\r\nspin_unlock(&pool->lock);\r\nreturn 0;\r\n} else if (!test_bit(PAGE_HEADLESS, &page->private)) {\r\nif (zhdr->first_chunks != 0 &&\r\nzhdr->last_chunks != 0 &&\r\nzhdr->middle_chunks != 0) {\r\nlist_add(&zhdr->buddy, &pool->buddied);\r\n} else {\r\nz3fold_compact_page(zhdr);\r\nfreechunks = num_free_chunks(zhdr);\r\nlist_add(&zhdr->buddy,\r\n&pool->unbuddied[freechunks]);\r\n}\r\n}\r\nlist_add(&page->lru, &pool->lru);\r\n}\r\nspin_unlock(&pool->lock);\r\nreturn -EAGAIN;\r\n}\r\nstatic void *z3fold_map(struct z3fold_pool *pool, unsigned long handle)\r\n{\r\nstruct z3fold_header *zhdr;\r\nstruct page *page;\r\nvoid *addr;\r\nenum buddy buddy;\r\nspin_lock(&pool->lock);\r\nzhdr = handle_to_z3fold_header(handle);\r\naddr = zhdr;\r\npage = virt_to_page(zhdr);\r\nif (test_bit(PAGE_HEADLESS, &page->private))\r\ngoto out;\r\nbuddy = handle_to_buddy(handle);\r\nswitch (buddy) {\r\ncase FIRST:\r\naddr += ZHDR_SIZE_ALIGNED;\r\nbreak;\r\ncase MIDDLE:\r\naddr += zhdr->start_middle << CHUNK_SHIFT;\r\nset_bit(MIDDLE_CHUNK_MAPPED, &page->private);\r\nbreak;\r\ncase LAST:\r\naddr += PAGE_SIZE - (zhdr->last_chunks << CHUNK_SHIFT);\r\nbreak;\r\ndefault:\r\npr_err("unknown buddy id %d\n", buddy);\r\nWARN_ON(1);\r\naddr = NULL;\r\nbreak;\r\n}\r\nout:\r\nspin_unlock(&pool->lock);\r\nreturn addr;\r\n}\r\nstatic void z3fold_unmap(struct z3fold_pool *pool, unsigned long handle)\r\n{\r\nstruct z3fold_header *zhdr;\r\nstruct page *page;\r\nenum buddy buddy;\r\nspin_lock(&pool->lock);\r\nzhdr = handle_to_z3fold_header(handle);\r\npage = virt_to_page(zhdr);\r\nif (test_bit(PAGE_HEADLESS, &page->private)) {\r\nspin_unlock(&pool->lock);\r\nreturn;\r\n}\r\nbuddy = handle_to_buddy(handle);\r\nif (buddy == MIDDLE)\r\nclear_bit(MIDDLE_CHUNK_MAPPED, &page->private);\r\nspin_unlock(&pool->lock);\r\n}\r\nstatic u64 z3fold_get_pool_size(struct z3fold_pool *pool)\r\n{\r\nreturn pool->pages_nr;\r\n}\r\nstatic int z3fold_zpool_evict(struct z3fold_pool *pool, unsigned long handle)\r\n{\r\nif (pool->zpool && pool->zpool_ops && pool->zpool_ops->evict)\r\nreturn pool->zpool_ops->evict(pool->zpool, handle);\r\nelse\r\nreturn -ENOENT;\r\n}\r\nstatic void *z3fold_zpool_create(const char *name, gfp_t gfp,\r\nconst struct zpool_ops *zpool_ops,\r\nstruct zpool *zpool)\r\n{\r\nstruct z3fold_pool *pool;\r\npool = z3fold_create_pool(gfp, zpool_ops ? &z3fold_zpool_ops : NULL);\r\nif (pool) {\r\npool->zpool = zpool;\r\npool->zpool_ops = zpool_ops;\r\n}\r\nreturn pool;\r\n}\r\nstatic void z3fold_zpool_destroy(void *pool)\r\n{\r\nz3fold_destroy_pool(pool);\r\n}\r\nstatic int z3fold_zpool_malloc(void *pool, size_t size, gfp_t gfp,\r\nunsigned long *handle)\r\n{\r\nreturn z3fold_alloc(pool, size, gfp, handle);\r\n}\r\nstatic void z3fold_zpool_free(void *pool, unsigned long handle)\r\n{\r\nz3fold_free(pool, handle);\r\n}\r\nstatic int z3fold_zpool_shrink(void *pool, unsigned int pages,\r\nunsigned int *reclaimed)\r\n{\r\nunsigned int total = 0;\r\nint ret = -EINVAL;\r\nwhile (total < pages) {\r\nret = z3fold_reclaim_page(pool, 8);\r\nif (ret < 0)\r\nbreak;\r\ntotal++;\r\n}\r\nif (reclaimed)\r\n*reclaimed = total;\r\nreturn ret;\r\n}\r\nstatic void *z3fold_zpool_map(void *pool, unsigned long handle,\r\nenum zpool_mapmode mm)\r\n{\r\nreturn z3fold_map(pool, handle);\r\n}\r\nstatic void z3fold_zpool_unmap(void *pool, unsigned long handle)\r\n{\r\nz3fold_unmap(pool, handle);\r\n}\r\nstatic u64 z3fold_zpool_total_size(void *pool)\r\n{\r\nreturn z3fold_get_pool_size(pool) * PAGE_SIZE;\r\n}\r\nstatic int __init init_z3fold(void)\r\n{\r\nBUILD_BUG_ON(sizeof(struct z3fold_header) > ZHDR_SIZE_ALIGNED);\r\nzpool_register_driver(&z3fold_zpool_driver);\r\nreturn 0;\r\n}\r\nstatic void __exit exit_z3fold(void)\r\n{\r\nzpool_unregister_driver(&z3fold_zpool_driver);\r\n}
