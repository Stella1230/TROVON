void subpage_prot_free(struct mm_struct *mm)\r\n{\r\nstruct subpage_prot_table *spt = &mm->context.spt;\r\nunsigned long i, j, addr;\r\nu32 **p;\r\nfor (i = 0; i < 4; ++i) {\r\nif (spt->low_prot[i]) {\r\nfree_page((unsigned long)spt->low_prot[i]);\r\nspt->low_prot[i] = NULL;\r\n}\r\n}\r\naddr = 0;\r\nfor (i = 0; i < 2; ++i) {\r\np = spt->protptrs[i];\r\nif (!p)\r\ncontinue;\r\nspt->protptrs[i] = NULL;\r\nfor (j = 0; j < SBP_L2_COUNT && addr < spt->maxaddr;\r\n++j, addr += PAGE_SIZE)\r\nif (p[j])\r\nfree_page((unsigned long)p[j]);\r\nfree_page((unsigned long)p);\r\n}\r\nspt->maxaddr = 0;\r\n}\r\nvoid subpage_prot_init_new_context(struct mm_struct *mm)\r\n{\r\nstruct subpage_prot_table *spt = &mm->context.spt;\r\nmemset(spt, 0, sizeof(*spt));\r\n}\r\nstatic void hpte_flush_range(struct mm_struct *mm, unsigned long addr,\r\nint npages)\r\n{\r\npgd_t *pgd;\r\npud_t *pud;\r\npmd_t *pmd;\r\npte_t *pte;\r\nspinlock_t *ptl;\r\npgd = pgd_offset(mm, addr);\r\nif (pgd_none(*pgd))\r\nreturn;\r\npud = pud_offset(pgd, addr);\r\nif (pud_none(*pud))\r\nreturn;\r\npmd = pmd_offset(pud, addr);\r\nif (pmd_none(*pmd))\r\nreturn;\r\npte = pte_offset_map_lock(mm, pmd, addr, &ptl);\r\narch_enter_lazy_mmu_mode();\r\nfor (; npages > 0; --npages) {\r\npte_update(mm, addr, pte, 0, 0, 0);\r\naddr += PAGE_SIZE;\r\n++pte;\r\n}\r\narch_leave_lazy_mmu_mode();\r\npte_unmap_unlock(pte - 1, ptl);\r\n}\r\nstatic void subpage_prot_clear(unsigned long addr, unsigned long len)\r\n{\r\nstruct mm_struct *mm = current->mm;\r\nstruct subpage_prot_table *spt = &mm->context.spt;\r\nu32 **spm, *spp;\r\nunsigned long i;\r\nsize_t nw;\r\nunsigned long next, limit;\r\ndown_write(&mm->mmap_sem);\r\nlimit = addr + len;\r\nif (limit > spt->maxaddr)\r\nlimit = spt->maxaddr;\r\nfor (; addr < limit; addr = next) {\r\nnext = pmd_addr_end(addr, limit);\r\nif (addr < 0x100000000UL) {\r\nspm = spt->low_prot;\r\n} else {\r\nspm = spt->protptrs[addr >> SBP_L3_SHIFT];\r\nif (!spm)\r\ncontinue;\r\n}\r\nspp = spm[(addr >> SBP_L2_SHIFT) & (SBP_L2_COUNT - 1)];\r\nif (!spp)\r\ncontinue;\r\nspp += (addr >> PAGE_SHIFT) & (SBP_L1_COUNT - 1);\r\ni = (addr >> PAGE_SHIFT) & (PTRS_PER_PTE - 1);\r\nnw = PTRS_PER_PTE - i;\r\nif (addr + (nw << PAGE_SHIFT) > next)\r\nnw = (next - addr) >> PAGE_SHIFT;\r\nmemset(spp, 0, nw * sizeof(u32));\r\nhpte_flush_range(mm, addr, nw);\r\n}\r\nup_write(&mm->mmap_sem);\r\n}\r\nstatic int subpage_walk_pmd_entry(pmd_t *pmd, unsigned long addr,\r\nunsigned long end, struct mm_walk *walk)\r\n{\r\nstruct vm_area_struct *vma = walk->vma;\r\nsplit_huge_pmd(vma, pmd, addr);\r\nreturn 0;\r\n}\r\nstatic void subpage_mark_vma_nohuge(struct mm_struct *mm, unsigned long addr,\r\nunsigned long len)\r\n{\r\nstruct vm_area_struct *vma;\r\nstruct mm_walk subpage_proto_walk = {\r\n.mm = mm,\r\n.pmd_entry = subpage_walk_pmd_entry,\r\n};\r\nvma = find_vma(mm, addr);\r\nif (vma && ((addr + len) <= vma->vm_start))\r\nreturn;\r\nwhile (vma) {\r\nif (vma->vm_start >= (addr + len))\r\nbreak;\r\nvma->vm_flags |= VM_NOHUGEPAGE;\r\nwalk_page_vma(vma, &subpage_proto_walk);\r\nvma = vma->vm_next;\r\n}\r\n}\r\nstatic void subpage_mark_vma_nohuge(struct mm_struct *mm, unsigned long addr,\r\nunsigned long len)\r\n{\r\nreturn;\r\n}\r\nlong sys_subpage_prot(unsigned long addr, unsigned long len, u32 __user *map)\r\n{\r\nstruct mm_struct *mm = current->mm;\r\nstruct subpage_prot_table *spt = &mm->context.spt;\r\nu32 **spm, *spp;\r\nunsigned long i;\r\nsize_t nw;\r\nunsigned long next, limit;\r\nint err;\r\nif ((addr & ~PAGE_MASK) || (len & ~PAGE_MASK) ||\r\naddr >= TASK_SIZE || len >= TASK_SIZE || addr + len > TASK_SIZE)\r\nreturn -EINVAL;\r\nif (is_hugepage_only_range(mm, addr, len))\r\nreturn -EINVAL;\r\nif (!map) {\r\nsubpage_prot_clear(addr, len);\r\nreturn 0;\r\n}\r\nif (!access_ok(VERIFY_READ, map, (len >> PAGE_SHIFT) * sizeof(u32)))\r\nreturn -EFAULT;\r\ndown_write(&mm->mmap_sem);\r\nsubpage_mark_vma_nohuge(mm, addr, len);\r\nfor (limit = addr + len; addr < limit; addr = next) {\r\nnext = pmd_addr_end(addr, limit);\r\nerr = -ENOMEM;\r\nif (addr < 0x100000000UL) {\r\nspm = spt->low_prot;\r\n} else {\r\nspm = spt->protptrs[addr >> SBP_L3_SHIFT];\r\nif (!spm) {\r\nspm = (u32 **)get_zeroed_page(GFP_KERNEL);\r\nif (!spm)\r\ngoto out;\r\nspt->protptrs[addr >> SBP_L3_SHIFT] = spm;\r\n}\r\n}\r\nspm += (addr >> SBP_L2_SHIFT) & (SBP_L2_COUNT - 1);\r\nspp = *spm;\r\nif (!spp) {\r\nspp = (u32 *)get_zeroed_page(GFP_KERNEL);\r\nif (!spp)\r\ngoto out;\r\n*spm = spp;\r\n}\r\nspp += (addr >> PAGE_SHIFT) & (SBP_L1_COUNT - 1);\r\nlocal_irq_disable();\r\ndemote_segment_4k(mm, addr);\r\nlocal_irq_enable();\r\ni = (addr >> PAGE_SHIFT) & (PTRS_PER_PTE - 1);\r\nnw = PTRS_PER_PTE - i;\r\nif (addr + (nw << PAGE_SHIFT) > next)\r\nnw = (next - addr) >> PAGE_SHIFT;\r\nup_write(&mm->mmap_sem);\r\nerr = -EFAULT;\r\nif (__copy_from_user(spp, map, nw * sizeof(u32)))\r\ngoto out2;\r\nmap += nw;\r\ndown_write(&mm->mmap_sem);\r\nhpte_flush_range(mm, addr, nw);\r\n}\r\nif (limit > spt->maxaddr)\r\nspt->maxaddr = limit;\r\nerr = 0;\r\nout:\r\nup_write(&mm->mmap_sem);\r\nout2:\r\nreturn err;\r\n}
