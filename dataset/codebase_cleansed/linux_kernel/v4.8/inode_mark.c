void fsnotify_recalc_inode_mask(struct inode *inode)\r\n{\r\nspin_lock(&inode->i_lock);\r\ninode->i_fsnotify_mask = fsnotify_recalc_mask(&inode->i_fsnotify_marks);\r\nspin_unlock(&inode->i_lock);\r\n__fsnotify_update_child_dentry_flags(inode);\r\n}\r\nvoid fsnotify_destroy_inode_mark(struct fsnotify_mark *mark)\r\n{\r\nstruct inode *inode = mark->inode;\r\nBUG_ON(!mutex_is_locked(&mark->group->mark_mutex));\r\nassert_spin_locked(&mark->lock);\r\nspin_lock(&inode->i_lock);\r\nhlist_del_init_rcu(&mark->obj_list);\r\nmark->inode = NULL;\r\ninode->i_fsnotify_mask = fsnotify_recalc_mask(&inode->i_fsnotify_marks);\r\nspin_unlock(&inode->i_lock);\r\n}\r\nvoid fsnotify_clear_inode_marks_by_group(struct fsnotify_group *group)\r\n{\r\nfsnotify_clear_marks_by_group_flags(group, FSNOTIFY_MARK_FLAG_INODE);\r\n}\r\nstruct fsnotify_mark *fsnotify_find_inode_mark(struct fsnotify_group *group,\r\nstruct inode *inode)\r\n{\r\nstruct fsnotify_mark *mark;\r\nspin_lock(&inode->i_lock);\r\nmark = fsnotify_find_mark(&inode->i_fsnotify_marks, group);\r\nspin_unlock(&inode->i_lock);\r\nreturn mark;\r\n}\r\nvoid fsnotify_set_inode_mark_mask_locked(struct fsnotify_mark *mark,\r\n__u32 mask)\r\n{\r\nstruct inode *inode;\r\nassert_spin_locked(&mark->lock);\r\nif (mask &&\r\nmark->inode &&\r\n!(mark->flags & FSNOTIFY_MARK_FLAG_OBJECT_PINNED)) {\r\nmark->flags |= FSNOTIFY_MARK_FLAG_OBJECT_PINNED;\r\ninode = igrab(mark->inode);\r\nBUG_ON(!inode);\r\n}\r\n}\r\nint fsnotify_add_inode_mark(struct fsnotify_mark *mark,\r\nstruct fsnotify_group *group, struct inode *inode,\r\nint allow_dups)\r\n{\r\nint ret;\r\nmark->flags |= FSNOTIFY_MARK_FLAG_INODE;\r\nBUG_ON(!mutex_is_locked(&group->mark_mutex));\r\nassert_spin_locked(&mark->lock);\r\nspin_lock(&inode->i_lock);\r\nmark->inode = inode;\r\nret = fsnotify_add_mark_list(&inode->i_fsnotify_marks, mark,\r\nallow_dups);\r\ninode->i_fsnotify_mask = fsnotify_recalc_mask(&inode->i_fsnotify_marks);\r\nspin_unlock(&inode->i_lock);\r\nreturn ret;\r\n}\r\nvoid fsnotify_unmount_inodes(struct super_block *sb)\r\n{\r\nstruct inode *inode, *next_i, *need_iput = NULL;\r\nspin_lock(&sb->s_inode_list_lock);\r\nlist_for_each_entry_safe(inode, next_i, &sb->s_inodes, i_sb_list) {\r\nstruct inode *need_iput_tmp;\r\nspin_lock(&inode->i_lock);\r\nif (inode->i_state & (I_FREEING|I_WILL_FREE|I_NEW)) {\r\nspin_unlock(&inode->i_lock);\r\ncontinue;\r\n}\r\nif (!atomic_read(&inode->i_count)) {\r\nspin_unlock(&inode->i_lock);\r\ncontinue;\r\n}\r\nneed_iput_tmp = need_iput;\r\nneed_iput = NULL;\r\nif (inode != need_iput_tmp)\r\n__iget(inode);\r\nelse\r\nneed_iput_tmp = NULL;\r\nspin_unlock(&inode->i_lock);\r\nwhile (&next_i->i_sb_list != &sb->s_inodes) {\r\nspin_lock(&next_i->i_lock);\r\nif (!(next_i->i_state & (I_FREEING | I_WILL_FREE)) &&\r\natomic_read(&next_i->i_count)) {\r\n__iget(next_i);\r\nneed_iput = next_i;\r\nspin_unlock(&next_i->i_lock);\r\nbreak;\r\n}\r\nspin_unlock(&next_i->i_lock);\r\nnext_i = list_next_entry(next_i, i_sb_list);\r\n}\r\nspin_unlock(&sb->s_inode_list_lock);\r\nif (need_iput_tmp)\r\niput(need_iput_tmp);\r\nfsnotify(inode, FS_UNMOUNT, inode, FSNOTIFY_EVENT_INODE, NULL, 0);\r\nfsnotify_inode_delete(inode);\r\niput(inode);\r\nspin_lock(&sb->s_inode_list_lock);\r\n}\r\nspin_unlock(&sb->s_inode_list_lock);\r\n}
