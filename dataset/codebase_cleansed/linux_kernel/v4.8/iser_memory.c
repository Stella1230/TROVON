void iser_reg_comp(struct ib_cq *cq, struct ib_wc *wc)\r\n{\r\niser_err_comp(wc, "memreg");\r\n}\r\nint iser_assign_reg_ops(struct iser_device *device)\r\n{\r\nstruct ib_device *ib_dev = device->ib_device;\r\nif (ib_dev->alloc_fmr && ib_dev->dealloc_fmr &&\r\nib_dev->map_phys_fmr && ib_dev->unmap_fmr) {\r\niser_info("FMR supported, using FMR for registration\n");\r\ndevice->reg_ops = &fmr_ops;\r\n} else if (ib_dev->attrs.device_cap_flags & IB_DEVICE_MEM_MGT_EXTENSIONS) {\r\niser_info("FastReg supported, using FastReg for registration\n");\r\ndevice->reg_ops = &fastreg_ops;\r\ndevice->remote_inv_sup = iser_always_reg;\r\n} else {\r\niser_err("IB device does not support FMRs nor FastRegs, can't register memory\n");\r\nreturn -1;\r\n}\r\nreturn 0;\r\n}\r\nstruct iser_fr_desc *\r\niser_reg_desc_get_fr(struct ib_conn *ib_conn)\r\n{\r\nstruct iser_fr_pool *fr_pool = &ib_conn->fr_pool;\r\nstruct iser_fr_desc *desc;\r\nunsigned long flags;\r\nspin_lock_irqsave(&fr_pool->lock, flags);\r\ndesc = list_first_entry(&fr_pool->list,\r\nstruct iser_fr_desc, list);\r\nlist_del(&desc->list);\r\nspin_unlock_irqrestore(&fr_pool->lock, flags);\r\nreturn desc;\r\n}\r\nvoid\r\niser_reg_desc_put_fr(struct ib_conn *ib_conn,\r\nstruct iser_fr_desc *desc)\r\n{\r\nstruct iser_fr_pool *fr_pool = &ib_conn->fr_pool;\r\nunsigned long flags;\r\nspin_lock_irqsave(&fr_pool->lock, flags);\r\nlist_add(&desc->list, &fr_pool->list);\r\nspin_unlock_irqrestore(&fr_pool->lock, flags);\r\n}\r\nstruct iser_fr_desc *\r\niser_reg_desc_get_fmr(struct ib_conn *ib_conn)\r\n{\r\nstruct iser_fr_pool *fr_pool = &ib_conn->fr_pool;\r\nreturn list_first_entry(&fr_pool->list,\r\nstruct iser_fr_desc, list);\r\n}\r\nvoid\r\niser_reg_desc_put_fmr(struct ib_conn *ib_conn,\r\nstruct iser_fr_desc *desc)\r\n{\r\n}\r\nstatic void iser_data_buf_dump(struct iser_data_buf *data,\r\nstruct ib_device *ibdev)\r\n{\r\nstruct scatterlist *sg;\r\nint i;\r\nfor_each_sg(data->sg, sg, data->dma_nents, i)\r\niser_dbg("sg[%d] dma_addr:0x%lX page:0x%p "\r\n"off:0x%x sz:0x%x dma_len:0x%x\n",\r\ni, (unsigned long)ib_sg_dma_address(ibdev, sg),\r\nsg_page(sg), sg->offset,\r\nsg->length, ib_sg_dma_len(ibdev, sg));\r\n}\r\nstatic void iser_dump_page_vec(struct iser_page_vec *page_vec)\r\n{\r\nint i;\r\niser_err("page vec npages %d data length %d\n",\r\npage_vec->npages, page_vec->fake_mr.length);\r\nfor (i = 0; i < page_vec->npages; i++)\r\niser_err("vec[%d]: %llx\n", i, page_vec->pages[i]);\r\n}\r\nint iser_dma_map_task_data(struct iscsi_iser_task *iser_task,\r\nstruct iser_data_buf *data,\r\nenum iser_data_dir iser_dir,\r\nenum dma_data_direction dma_dir)\r\n{\r\nstruct ib_device *dev;\r\niser_task->dir[iser_dir] = 1;\r\ndev = iser_task->iser_conn->ib_conn.device->ib_device;\r\ndata->dma_nents = ib_dma_map_sg(dev, data->sg, data->size, dma_dir);\r\nif (data->dma_nents == 0) {\r\niser_err("dma_map_sg failed!!!\n");\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nvoid iser_dma_unmap_task_data(struct iscsi_iser_task *iser_task,\r\nstruct iser_data_buf *data,\r\nenum dma_data_direction dir)\r\n{\r\nstruct ib_device *dev;\r\ndev = iser_task->iser_conn->ib_conn.device->ib_device;\r\nib_dma_unmap_sg(dev, data->sg, data->size, dir);\r\n}\r\nstatic int\r\niser_reg_dma(struct iser_device *device, struct iser_data_buf *mem,\r\nstruct iser_mem_reg *reg)\r\n{\r\nstruct scatterlist *sg = mem->sg;\r\nreg->sge.lkey = device->pd->local_dma_lkey;\r\nreg->rkey = device->mr ? device->mr->rkey : 0;\r\nreg->sge.addr = ib_sg_dma_address(device->ib_device, &sg[0]);\r\nreg->sge.length = ib_sg_dma_len(device->ib_device, &sg[0]);\r\niser_dbg("Single DMA entry: lkey=0x%x, rkey=0x%x, addr=0x%llx,"\r\n" length=0x%x\n", reg->sge.lkey, reg->rkey,\r\nreg->sge.addr, reg->sge.length);\r\nreturn 0;\r\n}\r\nstatic int iser_set_page(struct ib_mr *mr, u64 addr)\r\n{\r\nstruct iser_page_vec *page_vec =\r\ncontainer_of(mr, struct iser_page_vec, fake_mr);\r\npage_vec->pages[page_vec->npages++] = addr;\r\nreturn 0;\r\n}\r\nstatic\r\nint iser_fast_reg_fmr(struct iscsi_iser_task *iser_task,\r\nstruct iser_data_buf *mem,\r\nstruct iser_reg_resources *rsc,\r\nstruct iser_mem_reg *reg)\r\n{\r\nstruct ib_conn *ib_conn = &iser_task->iser_conn->ib_conn;\r\nstruct iser_device *device = ib_conn->device;\r\nstruct iser_page_vec *page_vec = rsc->page_vec;\r\nstruct ib_fmr_pool *fmr_pool = rsc->fmr_pool;\r\nstruct ib_pool_fmr *fmr;\r\nint ret, plen;\r\npage_vec->npages = 0;\r\npage_vec->fake_mr.page_size = SIZE_4K;\r\nplen = ib_sg_to_pages(&page_vec->fake_mr, mem->sg,\r\nmem->size, NULL, iser_set_page);\r\nif (unlikely(plen < mem->size)) {\r\niser_err("page vec too short to hold this SG\n");\r\niser_data_buf_dump(mem, device->ib_device);\r\niser_dump_page_vec(page_vec);\r\nreturn -EINVAL;\r\n}\r\nfmr = ib_fmr_pool_map_phys(fmr_pool, page_vec->pages,\r\npage_vec->npages, page_vec->pages[0]);\r\nif (IS_ERR(fmr)) {\r\nret = PTR_ERR(fmr);\r\niser_err("ib_fmr_pool_map_phys failed: %d\n", ret);\r\nreturn ret;\r\n}\r\nreg->sge.lkey = fmr->fmr->lkey;\r\nreg->rkey = fmr->fmr->rkey;\r\nreg->sge.addr = page_vec->fake_mr.iova;\r\nreg->sge.length = page_vec->fake_mr.length;\r\nreg->mem_h = fmr;\r\niser_dbg("fmr reg: lkey=0x%x, rkey=0x%x, addr=0x%llx,"\r\n" length=0x%x\n", reg->sge.lkey, reg->rkey,\r\nreg->sge.addr, reg->sge.length);\r\nreturn 0;\r\n}\r\nvoid iser_unreg_mem_fmr(struct iscsi_iser_task *iser_task,\r\nenum iser_data_dir cmd_dir)\r\n{\r\nstruct iser_mem_reg *reg = &iser_task->rdma_reg[cmd_dir];\r\nint ret;\r\nif (!reg->mem_h)\r\nreturn;\r\niser_dbg("PHYSICAL Mem.Unregister mem_h %p\n", reg->mem_h);\r\nret = ib_fmr_pool_unmap((struct ib_pool_fmr *)reg->mem_h);\r\nif (ret)\r\niser_err("ib_fmr_pool_unmap failed %d\n", ret);\r\nreg->mem_h = NULL;\r\n}\r\nvoid iser_unreg_mem_fastreg(struct iscsi_iser_task *iser_task,\r\nenum iser_data_dir cmd_dir)\r\n{\r\nstruct iser_device *device = iser_task->iser_conn->ib_conn.device;\r\nstruct iser_mem_reg *reg = &iser_task->rdma_reg[cmd_dir];\r\nif (!reg->mem_h)\r\nreturn;\r\ndevice->reg_ops->reg_desc_put(&iser_task->iser_conn->ib_conn,\r\nreg->mem_h);\r\nreg->mem_h = NULL;\r\n}\r\nstatic void\r\niser_set_dif_domain(struct scsi_cmnd *sc, struct ib_sig_attrs *sig_attrs,\r\nstruct ib_sig_domain *domain)\r\n{\r\ndomain->sig_type = IB_SIG_TYPE_T10_DIF;\r\ndomain->sig.dif.pi_interval = scsi_prot_interval(sc);\r\ndomain->sig.dif.ref_tag = scsi_prot_ref_tag(sc);\r\ndomain->sig.dif.apptag_check_mask = 0xffff;\r\ndomain->sig.dif.app_escape = true;\r\ndomain->sig.dif.ref_escape = true;\r\nif (sc->prot_flags & SCSI_PROT_REF_INCREMENT)\r\ndomain->sig.dif.ref_remap = true;\r\n}\r\nstatic int\r\niser_set_sig_attrs(struct scsi_cmnd *sc, struct ib_sig_attrs *sig_attrs)\r\n{\r\nswitch (scsi_get_prot_op(sc)) {\r\ncase SCSI_PROT_WRITE_INSERT:\r\ncase SCSI_PROT_READ_STRIP:\r\nsig_attrs->mem.sig_type = IB_SIG_TYPE_NONE;\r\niser_set_dif_domain(sc, sig_attrs, &sig_attrs->wire);\r\nsig_attrs->wire.sig.dif.bg_type = IB_T10DIF_CRC;\r\nbreak;\r\ncase SCSI_PROT_READ_INSERT:\r\ncase SCSI_PROT_WRITE_STRIP:\r\nsig_attrs->wire.sig_type = IB_SIG_TYPE_NONE;\r\niser_set_dif_domain(sc, sig_attrs, &sig_attrs->mem);\r\nsig_attrs->mem.sig.dif.bg_type = sc->prot_flags & SCSI_PROT_IP_CHECKSUM ?\r\nIB_T10DIF_CSUM : IB_T10DIF_CRC;\r\nbreak;\r\ncase SCSI_PROT_READ_PASS:\r\ncase SCSI_PROT_WRITE_PASS:\r\niser_set_dif_domain(sc, sig_attrs, &sig_attrs->wire);\r\nsig_attrs->wire.sig.dif.bg_type = IB_T10DIF_CRC;\r\niser_set_dif_domain(sc, sig_attrs, &sig_attrs->mem);\r\nsig_attrs->mem.sig.dif.bg_type = sc->prot_flags & SCSI_PROT_IP_CHECKSUM ?\r\nIB_T10DIF_CSUM : IB_T10DIF_CRC;\r\nbreak;\r\ndefault:\r\niser_err("Unsupported PI operation %d\n",\r\nscsi_get_prot_op(sc));\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic inline void\r\niser_set_prot_checks(struct scsi_cmnd *sc, u8 *mask)\r\n{\r\n*mask = 0;\r\nif (sc->prot_flags & SCSI_PROT_REF_CHECK)\r\n*mask |= ISER_CHECK_REFTAG;\r\nif (sc->prot_flags & SCSI_PROT_GUARD_CHECK)\r\n*mask |= ISER_CHECK_GUARD;\r\n}\r\nstatic inline void\r\niser_inv_rkey(struct ib_send_wr *inv_wr,\r\nstruct ib_mr *mr,\r\nstruct ib_cqe *cqe)\r\n{\r\ninv_wr->opcode = IB_WR_LOCAL_INV;\r\ninv_wr->wr_cqe = cqe;\r\ninv_wr->ex.invalidate_rkey = mr->rkey;\r\ninv_wr->send_flags = 0;\r\ninv_wr->num_sge = 0;\r\n}\r\nstatic int\r\niser_reg_sig_mr(struct iscsi_iser_task *iser_task,\r\nstruct iser_pi_context *pi_ctx,\r\nstruct iser_mem_reg *data_reg,\r\nstruct iser_mem_reg *prot_reg,\r\nstruct iser_mem_reg *sig_reg)\r\n{\r\nstruct iser_tx_desc *tx_desc = &iser_task->desc;\r\nstruct ib_sig_attrs *sig_attrs = &tx_desc->sig_attrs;\r\nstruct ib_cqe *cqe = &iser_task->iser_conn->ib_conn.reg_cqe;\r\nstruct ib_sig_handover_wr *wr;\r\nstruct ib_mr *mr = pi_ctx->sig_mr;\r\nint ret;\r\nmemset(sig_attrs, 0, sizeof(*sig_attrs));\r\nret = iser_set_sig_attrs(iser_task->sc, sig_attrs);\r\nif (ret)\r\ngoto err;\r\niser_set_prot_checks(iser_task->sc, &sig_attrs->check_mask);\r\nif (pi_ctx->sig_mr_valid)\r\niser_inv_rkey(iser_tx_next_wr(tx_desc), mr, cqe);\r\nib_update_fast_reg_key(mr, ib_inc_rkey(mr->rkey));\r\nwr = sig_handover_wr(iser_tx_next_wr(tx_desc));\r\nwr->wr.opcode = IB_WR_REG_SIG_MR;\r\nwr->wr.wr_cqe = cqe;\r\nwr->wr.sg_list = &data_reg->sge;\r\nwr->wr.num_sge = 1;\r\nwr->wr.send_flags = 0;\r\nwr->sig_attrs = sig_attrs;\r\nwr->sig_mr = mr;\r\nif (scsi_prot_sg_count(iser_task->sc))\r\nwr->prot = &prot_reg->sge;\r\nelse\r\nwr->prot = NULL;\r\nwr->access_flags = IB_ACCESS_LOCAL_WRITE |\r\nIB_ACCESS_REMOTE_READ |\r\nIB_ACCESS_REMOTE_WRITE;\r\npi_ctx->sig_mr_valid = 1;\r\nsig_reg->sge.lkey = mr->lkey;\r\nsig_reg->rkey = mr->rkey;\r\nsig_reg->sge.addr = 0;\r\nsig_reg->sge.length = scsi_transfer_length(iser_task->sc);\r\niser_dbg("lkey=0x%x rkey=0x%x addr=0x%llx length=%u\n",\r\nsig_reg->sge.lkey, sig_reg->rkey, sig_reg->sge.addr,\r\nsig_reg->sge.length);\r\nerr:\r\nreturn ret;\r\n}\r\nstatic int iser_fast_reg_mr(struct iscsi_iser_task *iser_task,\r\nstruct iser_data_buf *mem,\r\nstruct iser_reg_resources *rsc,\r\nstruct iser_mem_reg *reg)\r\n{\r\nstruct iser_tx_desc *tx_desc = &iser_task->desc;\r\nstruct ib_cqe *cqe = &iser_task->iser_conn->ib_conn.reg_cqe;\r\nstruct ib_mr *mr = rsc->mr;\r\nstruct ib_reg_wr *wr;\r\nint n;\r\nif (rsc->mr_valid)\r\niser_inv_rkey(iser_tx_next_wr(tx_desc), mr, cqe);\r\nib_update_fast_reg_key(mr, ib_inc_rkey(mr->rkey));\r\nn = ib_map_mr_sg(mr, mem->sg, mem->size, NULL, SIZE_4K);\r\nif (unlikely(n != mem->size)) {\r\niser_err("failed to map sg (%d/%d)\n",\r\nn, mem->size);\r\nreturn n < 0 ? n : -EINVAL;\r\n}\r\nwr = reg_wr(iser_tx_next_wr(tx_desc));\r\nwr->wr.opcode = IB_WR_REG_MR;\r\nwr->wr.wr_cqe = cqe;\r\nwr->wr.send_flags = 0;\r\nwr->wr.num_sge = 0;\r\nwr->mr = mr;\r\nwr->key = mr->rkey;\r\nwr->access = IB_ACCESS_LOCAL_WRITE |\r\nIB_ACCESS_REMOTE_WRITE |\r\nIB_ACCESS_REMOTE_READ;\r\nrsc->mr_valid = 1;\r\nreg->sge.lkey = mr->lkey;\r\nreg->rkey = mr->rkey;\r\nreg->sge.addr = mr->iova;\r\nreg->sge.length = mr->length;\r\niser_dbg("lkey=0x%x rkey=0x%x addr=0x%llx length=0x%x\n",\r\nreg->sge.lkey, reg->rkey, reg->sge.addr, reg->sge.length);\r\nreturn 0;\r\n}\r\nstatic int\r\niser_reg_prot_sg(struct iscsi_iser_task *task,\r\nstruct iser_data_buf *mem,\r\nstruct iser_fr_desc *desc,\r\nbool use_dma_key,\r\nstruct iser_mem_reg *reg)\r\n{\r\nstruct iser_device *device = task->iser_conn->ib_conn.device;\r\nif (use_dma_key)\r\nreturn iser_reg_dma(device, mem, reg);\r\nreturn device->reg_ops->reg_mem(task, mem, &desc->pi_ctx->rsc, reg);\r\n}\r\nstatic int\r\niser_reg_data_sg(struct iscsi_iser_task *task,\r\nstruct iser_data_buf *mem,\r\nstruct iser_fr_desc *desc,\r\nbool use_dma_key,\r\nstruct iser_mem_reg *reg)\r\n{\r\nstruct iser_device *device = task->iser_conn->ib_conn.device;\r\nif (use_dma_key)\r\nreturn iser_reg_dma(device, mem, reg);\r\nreturn device->reg_ops->reg_mem(task, mem, &desc->rsc, reg);\r\n}\r\nint iser_reg_rdma_mem(struct iscsi_iser_task *task,\r\nenum iser_data_dir dir,\r\nbool all_imm)\r\n{\r\nstruct ib_conn *ib_conn = &task->iser_conn->ib_conn;\r\nstruct iser_device *device = ib_conn->device;\r\nstruct iser_data_buf *mem = &task->data[dir];\r\nstruct iser_mem_reg *reg = &task->rdma_reg[dir];\r\nstruct iser_mem_reg *data_reg;\r\nstruct iser_fr_desc *desc = NULL;\r\nbool use_dma_key;\r\nint err;\r\nuse_dma_key = mem->dma_nents == 1 && (all_imm || !iser_always_reg) &&\r\nscsi_get_prot_op(task->sc) == SCSI_PROT_NORMAL;\r\nif (!use_dma_key) {\r\ndesc = device->reg_ops->reg_desc_get(ib_conn);\r\nreg->mem_h = desc;\r\n}\r\nif (scsi_get_prot_op(task->sc) == SCSI_PROT_NORMAL)\r\ndata_reg = reg;\r\nelse\r\ndata_reg = &task->desc.data_reg;\r\nerr = iser_reg_data_sg(task, mem, desc, use_dma_key, data_reg);\r\nif (unlikely(err))\r\ngoto err_reg;\r\nif (scsi_get_prot_op(task->sc) != SCSI_PROT_NORMAL) {\r\nstruct iser_mem_reg *prot_reg = &task->desc.prot_reg;\r\nif (scsi_prot_sg_count(task->sc)) {\r\nmem = &task->prot[dir];\r\nerr = iser_reg_prot_sg(task, mem, desc,\r\nuse_dma_key, prot_reg);\r\nif (unlikely(err))\r\ngoto err_reg;\r\n}\r\nerr = iser_reg_sig_mr(task, desc->pi_ctx, data_reg,\r\nprot_reg, reg);\r\nif (unlikely(err))\r\ngoto err_reg;\r\ndesc->pi_ctx->sig_protected = 1;\r\n}\r\nreturn 0;\r\nerr_reg:\r\nif (desc)\r\ndevice->reg_ops->reg_desc_put(ib_conn, desc);\r\nreturn err;\r\n}\r\nvoid iser_unreg_rdma_mem(struct iscsi_iser_task *task,\r\nenum iser_data_dir dir)\r\n{\r\nstruct iser_device *device = task->iser_conn->ib_conn.device;\r\ndevice->reg_ops->unreg_mem(task, dir);\r\n}
