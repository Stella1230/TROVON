int rv770_set_uvd_clocks(struct radeon_device *rdev, u32 vclk, u32 dclk)\r\n{\r\nunsigned fb_div = 0, vclk_div = 0, dclk_div = 0;\r\nint r;\r\nif (rdev->family == CHIP_RV740)\r\nreturn evergreen_set_uvd_clocks(rdev, vclk, dclk);\r\nWREG32_P(CG_UPLL_FUNC_CNTL_2,\r\nVCLK_SRC_SEL(1) | DCLK_SRC_SEL(1),\r\n~(VCLK_SRC_SEL_MASK | DCLK_SRC_SEL_MASK));\r\nif (!vclk || !dclk) {\r\nWREG32_P(CG_UPLL_FUNC_CNTL, UPLL_SLEEP_MASK, ~UPLL_SLEEP_MASK);\r\nreturn 0;\r\n}\r\nr = radeon_uvd_calc_upll_dividers(rdev, vclk, dclk, 50000, 160000,\r\n43663, 0x03FFFFFE, 1, 30, ~0,\r\n&fb_div, &vclk_div, &dclk_div);\r\nif (r)\r\nreturn r;\r\nfb_div |= 1;\r\nvclk_div -= 1;\r\ndclk_div -= 1;\r\nWREG32_P(CG_UPLL_FUNC_CNTL_3, UPLL_FB_DIV(0x50000), ~UPLL_FB_DIV_MASK);\r\nWREG32_P(CG_UPLL_FUNC_CNTL, 0, ~(UPLL_RESET_MASK | UPLL_SLEEP_MASK));\r\nWREG32_P(CG_UPLL_FUNC_CNTL, UPLL_BYPASS_EN_MASK, ~UPLL_BYPASS_EN_MASK);\r\nWREG32_P(CG_UPLL_FUNC_CNTL_3, UPLL_FB_DIV(1), ~UPLL_FB_DIV(1));\r\nr = radeon_uvd_send_upll_ctlreq(rdev, CG_UPLL_FUNC_CNTL);\r\nif (r)\r\nreturn r;\r\nWREG32_P(CG_UPLL_FUNC_CNTL, UPLL_RESET_MASK, ~UPLL_RESET_MASK);\r\nWREG32_P(CG_UPLL_FUNC_CNTL, UPLL_REF_DIV(1), ~UPLL_REF_DIV_MASK);\r\nWREG32_P(CG_UPLL_FUNC_CNTL_2,\r\nUPLL_SW_HILEN(vclk_div >> 1) |\r\nUPLL_SW_LOLEN((vclk_div >> 1) + (vclk_div & 1)) |\r\nUPLL_SW_HILEN2(dclk_div >> 1) |\r\nUPLL_SW_LOLEN2((dclk_div >> 1) + (dclk_div & 1)),\r\n~UPLL_SW_MASK);\r\nWREG32_P(CG_UPLL_FUNC_CNTL_3, UPLL_FB_DIV(fb_div),\r\n~UPLL_FB_DIV_MASK);\r\nmdelay(15);\r\nWREG32_P(CG_UPLL_FUNC_CNTL, 0, ~UPLL_RESET_MASK);\r\nmdelay(15);\r\nWREG32_P(CG_UPLL_FUNC_CNTL, 0, ~UPLL_BYPASS_EN_MASK);\r\nWREG32_P(CG_UPLL_FUNC_CNTL_3, 0, ~UPLL_FB_DIV(1));\r\nr = radeon_uvd_send_upll_ctlreq(rdev, CG_UPLL_FUNC_CNTL);\r\nif (r)\r\nreturn r;\r\nWREG32_P(CG_UPLL_FUNC_CNTL_2,\r\nVCLK_SRC_SEL(2) | DCLK_SRC_SEL(2),\r\n~(VCLK_SRC_SEL_MASK | DCLK_SRC_SEL_MASK));\r\nmdelay(100);\r\nreturn 0;\r\n}\r\nstatic void rv770_init_golden_registers(struct radeon_device *rdev)\r\n{\r\nswitch (rdev->family) {\r\ncase CHIP_RV770:\r\nradeon_program_register_sequence(rdev,\r\nr7xx_golden_registers,\r\n(const u32)ARRAY_SIZE(r7xx_golden_registers));\r\nradeon_program_register_sequence(rdev,\r\nr7xx_golden_dyn_gpr_registers,\r\n(const u32)ARRAY_SIZE(r7xx_golden_dyn_gpr_registers));\r\nif (rdev->pdev->device == 0x994e)\r\nradeon_program_register_sequence(rdev,\r\nrv770ce_golden_registers,\r\n(const u32)ARRAY_SIZE(rv770ce_golden_registers));\r\nelse\r\nradeon_program_register_sequence(rdev,\r\nrv770_golden_registers,\r\n(const u32)ARRAY_SIZE(rv770_golden_registers));\r\nradeon_program_register_sequence(rdev,\r\nrv770_mgcg_init,\r\n(const u32)ARRAY_SIZE(rv770_mgcg_init));\r\nbreak;\r\ncase CHIP_RV730:\r\nradeon_program_register_sequence(rdev,\r\nr7xx_golden_registers,\r\n(const u32)ARRAY_SIZE(r7xx_golden_registers));\r\nradeon_program_register_sequence(rdev,\r\nr7xx_golden_dyn_gpr_registers,\r\n(const u32)ARRAY_SIZE(r7xx_golden_dyn_gpr_registers));\r\nradeon_program_register_sequence(rdev,\r\nrv730_golden_registers,\r\n(const u32)ARRAY_SIZE(rv730_golden_registers));\r\nradeon_program_register_sequence(rdev,\r\nrv730_mgcg_init,\r\n(const u32)ARRAY_SIZE(rv730_mgcg_init));\r\nbreak;\r\ncase CHIP_RV710:\r\nradeon_program_register_sequence(rdev,\r\nr7xx_golden_registers,\r\n(const u32)ARRAY_SIZE(r7xx_golden_registers));\r\nradeon_program_register_sequence(rdev,\r\nr7xx_golden_dyn_gpr_registers,\r\n(const u32)ARRAY_SIZE(r7xx_golden_dyn_gpr_registers));\r\nradeon_program_register_sequence(rdev,\r\nrv710_golden_registers,\r\n(const u32)ARRAY_SIZE(rv710_golden_registers));\r\nradeon_program_register_sequence(rdev,\r\nrv710_mgcg_init,\r\n(const u32)ARRAY_SIZE(rv710_mgcg_init));\r\nbreak;\r\ncase CHIP_RV740:\r\nradeon_program_register_sequence(rdev,\r\nrv740_golden_registers,\r\n(const u32)ARRAY_SIZE(rv740_golden_registers));\r\nradeon_program_register_sequence(rdev,\r\nrv740_mgcg_init,\r\n(const u32)ARRAY_SIZE(rv740_mgcg_init));\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nu32 rv770_get_xclk(struct radeon_device *rdev)\r\n{\r\nu32 reference_clock = rdev->clock.spll.reference_freq;\r\nu32 tmp = RREG32(CG_CLKPIN_CNTL);\r\nif (tmp & MUX_TCLK_TO_XCLK)\r\nreturn TCLK;\r\nif (tmp & XTALIN_DIVIDE)\r\nreturn reference_clock / 4;\r\nreturn reference_clock;\r\n}\r\nvoid rv770_page_flip(struct radeon_device *rdev, int crtc_id, u64 crtc_base, bool async)\r\n{\r\nstruct radeon_crtc *radeon_crtc = rdev->mode_info.crtcs[crtc_id];\r\nu32 tmp = RREG32(AVIVO_D1GRPH_UPDATE + radeon_crtc->crtc_offset);\r\nint i;\r\ntmp |= AVIVO_D1GRPH_UPDATE_LOCK;\r\nWREG32(AVIVO_D1GRPH_UPDATE + radeon_crtc->crtc_offset, tmp);\r\nWREG32(AVIVO_D1GRPH_FLIP_CONTROL + radeon_crtc->crtc_offset,\r\nasync ? AVIVO_D1GRPH_SURFACE_UPDATE_H_RETRACE_EN : 0);\r\nif (radeon_crtc->crtc_id) {\r\nWREG32(D2GRPH_SECONDARY_SURFACE_ADDRESS_HIGH, upper_32_bits(crtc_base));\r\nWREG32(D2GRPH_PRIMARY_SURFACE_ADDRESS_HIGH, upper_32_bits(crtc_base));\r\n} else {\r\nWREG32(D1GRPH_SECONDARY_SURFACE_ADDRESS_HIGH, upper_32_bits(crtc_base));\r\nWREG32(D1GRPH_PRIMARY_SURFACE_ADDRESS_HIGH, upper_32_bits(crtc_base));\r\n}\r\nWREG32(D1GRPH_SECONDARY_SURFACE_ADDRESS + radeon_crtc->crtc_offset,\r\n(u32)crtc_base);\r\nWREG32(D1GRPH_PRIMARY_SURFACE_ADDRESS + radeon_crtc->crtc_offset,\r\n(u32)crtc_base);\r\nfor (i = 0; i < rdev->usec_timeout; i++) {\r\nif (RREG32(AVIVO_D1GRPH_UPDATE + radeon_crtc->crtc_offset) & AVIVO_D1GRPH_SURFACE_UPDATE_PENDING)\r\nbreak;\r\nudelay(1);\r\n}\r\nDRM_DEBUG("Update pending now high. Unlocking vupdate_lock.\n");\r\ntmp &= ~AVIVO_D1GRPH_UPDATE_LOCK;\r\nWREG32(AVIVO_D1GRPH_UPDATE + radeon_crtc->crtc_offset, tmp);\r\n}\r\nbool rv770_page_flip_pending(struct radeon_device *rdev, int crtc_id)\r\n{\r\nstruct radeon_crtc *radeon_crtc = rdev->mode_info.crtcs[crtc_id];\r\nreturn !!(RREG32(AVIVO_D1GRPH_UPDATE + radeon_crtc->crtc_offset) &\r\nAVIVO_D1GRPH_SURFACE_UPDATE_PENDING);\r\n}\r\nint rv770_get_temp(struct radeon_device *rdev)\r\n{\r\nu32 temp = (RREG32(CG_MULT_THERMAL_STATUS) & ASIC_T_MASK) >>\r\nASIC_T_SHIFT;\r\nint actual_temp;\r\nif (temp & 0x400)\r\nactual_temp = -256;\r\nelse if (temp & 0x200)\r\nactual_temp = 255;\r\nelse if (temp & 0x100) {\r\nactual_temp = temp & 0x1ff;\r\nactual_temp |= ~0x1ff;\r\n} else\r\nactual_temp = temp & 0xff;\r\nreturn (actual_temp * 1000) / 2;\r\n}\r\nvoid rv770_pm_misc(struct radeon_device *rdev)\r\n{\r\nint req_ps_idx = rdev->pm.requested_power_state_index;\r\nint req_cm_idx = rdev->pm.requested_clock_mode_index;\r\nstruct radeon_power_state *ps = &rdev->pm.power_state[req_ps_idx];\r\nstruct radeon_voltage *voltage = &ps->clock_info[req_cm_idx].voltage;\r\nif ((voltage->type == VOLTAGE_SW) && voltage->voltage) {\r\nif (voltage->voltage == 0xff01)\r\nreturn;\r\nif (voltage->voltage != rdev->pm.current_vddc) {\r\nradeon_atom_set_voltage(rdev, voltage->voltage, SET_VOLTAGE_TYPE_ASIC_VDDC);\r\nrdev->pm.current_vddc = voltage->voltage;\r\nDRM_DEBUG("Setting: v: %d\n", voltage->voltage);\r\n}\r\n}\r\n}\r\nstatic int rv770_pcie_gart_enable(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\nint r, i;\r\nif (rdev->gart.robj == NULL) {\r\ndev_err(rdev->dev, "No VRAM object for PCIE GART.\n");\r\nreturn -EINVAL;\r\n}\r\nr = radeon_gart_table_vram_pin(rdev);\r\nif (r)\r\nreturn r;\r\nWREG32(VM_L2_CNTL, ENABLE_L2_CACHE | ENABLE_L2_FRAGMENT_PROCESSING |\r\nENABLE_L2_PTE_CACHE_LRU_UPDATE_BY_WRITE |\r\nEFFECTIVE_L2_QUEUE_SIZE(7));\r\nWREG32(VM_L2_CNTL2, 0);\r\nWREG32(VM_L2_CNTL3, BANK_SELECT(0) | CACHE_UPDATE_MODE(2));\r\ntmp = ENABLE_L1_TLB | ENABLE_L1_FRAGMENT_PROCESSING |\r\nSYSTEM_ACCESS_MODE_NOT_IN_SYS |\r\nSYSTEM_APERTURE_UNMAPPED_ACCESS_PASS_THRU |\r\nEFFECTIVE_L1_TLB_SIZE(5) | EFFECTIVE_L1_QUEUE_SIZE(5);\r\nWREG32(MC_VM_MD_L1_TLB0_CNTL, tmp);\r\nWREG32(MC_VM_MD_L1_TLB1_CNTL, tmp);\r\nWREG32(MC_VM_MD_L1_TLB2_CNTL, tmp);\r\nif (rdev->family == CHIP_RV740)\r\nWREG32(MC_VM_MD_L1_TLB3_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB0_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB1_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB2_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB3_CNTL, tmp);\r\nWREG32(VM_CONTEXT0_PAGE_TABLE_START_ADDR, rdev->mc.gtt_start >> 12);\r\nWREG32(VM_CONTEXT0_PAGE_TABLE_END_ADDR, rdev->mc.gtt_end >> 12);\r\nWREG32(VM_CONTEXT0_PAGE_TABLE_BASE_ADDR, rdev->gart.table_addr >> 12);\r\nWREG32(VM_CONTEXT0_CNTL, ENABLE_CONTEXT | PAGE_TABLE_DEPTH(0) |\r\nRANGE_PROTECTION_FAULT_ENABLE_DEFAULT);\r\nWREG32(VM_CONTEXT0_PROTECTION_FAULT_DEFAULT_ADDR,\r\n(u32)(rdev->dummy_page.addr >> 12));\r\nfor (i = 1; i < 7; i++)\r\nWREG32(VM_CONTEXT0_CNTL + (i * 4), 0);\r\nr600_pcie_gart_tlb_flush(rdev);\r\nDRM_INFO("PCIE GART of %uM enabled (table at 0x%016llX).\n",\r\n(unsigned)(rdev->mc.gtt_size >> 20),\r\n(unsigned long long)rdev->gart.table_addr);\r\nrdev->gart.ready = true;\r\nreturn 0;\r\n}\r\nstatic void rv770_pcie_gart_disable(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\nint i;\r\nfor (i = 0; i < 7; i++)\r\nWREG32(VM_CONTEXT0_CNTL + (i * 4), 0);\r\nWREG32(VM_L2_CNTL, ENABLE_L2_FRAGMENT_PROCESSING |\r\nEFFECTIVE_L2_QUEUE_SIZE(7));\r\nWREG32(VM_L2_CNTL2, 0);\r\nWREG32(VM_L2_CNTL3, BANK_SELECT(0) | CACHE_UPDATE_MODE(2));\r\ntmp = EFFECTIVE_L1_TLB_SIZE(5) | EFFECTIVE_L1_QUEUE_SIZE(5);\r\nWREG32(MC_VM_MD_L1_TLB0_CNTL, tmp);\r\nWREG32(MC_VM_MD_L1_TLB1_CNTL, tmp);\r\nWREG32(MC_VM_MD_L1_TLB2_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB0_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB1_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB2_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB3_CNTL, tmp);\r\nradeon_gart_table_vram_unpin(rdev);\r\n}\r\nstatic void rv770_pcie_gart_fini(struct radeon_device *rdev)\r\n{\r\nradeon_gart_fini(rdev);\r\nrv770_pcie_gart_disable(rdev);\r\nradeon_gart_table_vram_free(rdev);\r\n}\r\nstatic void rv770_agp_enable(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\nint i;\r\nWREG32(VM_L2_CNTL, ENABLE_L2_CACHE | ENABLE_L2_FRAGMENT_PROCESSING |\r\nENABLE_L2_PTE_CACHE_LRU_UPDATE_BY_WRITE |\r\nEFFECTIVE_L2_QUEUE_SIZE(7));\r\nWREG32(VM_L2_CNTL2, 0);\r\nWREG32(VM_L2_CNTL3, BANK_SELECT(0) | CACHE_UPDATE_MODE(2));\r\ntmp = ENABLE_L1_TLB | ENABLE_L1_FRAGMENT_PROCESSING |\r\nSYSTEM_ACCESS_MODE_NOT_IN_SYS |\r\nSYSTEM_APERTURE_UNMAPPED_ACCESS_PASS_THRU |\r\nEFFECTIVE_L1_TLB_SIZE(5) | EFFECTIVE_L1_QUEUE_SIZE(5);\r\nWREG32(MC_VM_MD_L1_TLB0_CNTL, tmp);\r\nWREG32(MC_VM_MD_L1_TLB1_CNTL, tmp);\r\nWREG32(MC_VM_MD_L1_TLB2_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB0_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB1_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB2_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB3_CNTL, tmp);\r\nfor (i = 0; i < 7; i++)\r\nWREG32(VM_CONTEXT0_CNTL + (i * 4), 0);\r\n}\r\nstatic void rv770_mc_program(struct radeon_device *rdev)\r\n{\r\nstruct rv515_mc_save save;\r\nu32 tmp;\r\nint i, j;\r\nfor (i = 0, j = 0; i < 32; i++, j += 0x18) {\r\nWREG32((0x2c14 + j), 0x00000000);\r\nWREG32((0x2c18 + j), 0x00000000);\r\nWREG32((0x2c1c + j), 0x00000000);\r\nWREG32((0x2c20 + j), 0x00000000);\r\nWREG32((0x2c24 + j), 0x00000000);\r\n}\r\ntmp = RREG32(HDP_DEBUG1);\r\nrv515_mc_stop(rdev, &save);\r\nif (r600_mc_wait_for_idle(rdev)) {\r\ndev_warn(rdev->dev, "Wait for MC idle timedout !\n");\r\n}\r\nWREG32(VGA_HDP_CONTROL, VGA_MEMORY_DISABLE);\r\nif (rdev->flags & RADEON_IS_AGP) {\r\nif (rdev->mc.vram_start < rdev->mc.gtt_start) {\r\nWREG32(MC_VM_SYSTEM_APERTURE_LOW_ADDR,\r\nrdev->mc.vram_start >> 12);\r\nWREG32(MC_VM_SYSTEM_APERTURE_HIGH_ADDR,\r\nrdev->mc.gtt_end >> 12);\r\n} else {\r\nWREG32(MC_VM_SYSTEM_APERTURE_LOW_ADDR,\r\nrdev->mc.gtt_start >> 12);\r\nWREG32(MC_VM_SYSTEM_APERTURE_HIGH_ADDR,\r\nrdev->mc.vram_end >> 12);\r\n}\r\n} else {\r\nWREG32(MC_VM_SYSTEM_APERTURE_LOW_ADDR,\r\nrdev->mc.vram_start >> 12);\r\nWREG32(MC_VM_SYSTEM_APERTURE_HIGH_ADDR,\r\nrdev->mc.vram_end >> 12);\r\n}\r\nWREG32(MC_VM_SYSTEM_APERTURE_DEFAULT_ADDR, rdev->vram_scratch.gpu_addr >> 12);\r\ntmp = ((rdev->mc.vram_end >> 24) & 0xFFFF) << 16;\r\ntmp |= ((rdev->mc.vram_start >> 24) & 0xFFFF);\r\nWREG32(MC_VM_FB_LOCATION, tmp);\r\nWREG32(HDP_NONSURFACE_BASE, (rdev->mc.vram_start >> 8));\r\nWREG32(HDP_NONSURFACE_INFO, (2 << 7));\r\nWREG32(HDP_NONSURFACE_SIZE, 0x3FFFFFFF);\r\nif (rdev->flags & RADEON_IS_AGP) {\r\nWREG32(MC_VM_AGP_TOP, rdev->mc.gtt_end >> 16);\r\nWREG32(MC_VM_AGP_BOT, rdev->mc.gtt_start >> 16);\r\nWREG32(MC_VM_AGP_BASE, rdev->mc.agp_base >> 22);\r\n} else {\r\nWREG32(MC_VM_AGP_BASE, 0);\r\nWREG32(MC_VM_AGP_TOP, 0x0FFFFFFF);\r\nWREG32(MC_VM_AGP_BOT, 0x0FFFFFFF);\r\n}\r\nif (r600_mc_wait_for_idle(rdev)) {\r\ndev_warn(rdev->dev, "Wait for MC idle timedout !\n");\r\n}\r\nrv515_mc_resume(rdev, &save);\r\nrv515_vga_render_disable(rdev);\r\n}\r\nvoid r700_cp_stop(struct radeon_device *rdev)\r\n{\r\nif (rdev->asic->copy.copy_ring_index == RADEON_RING_TYPE_GFX_INDEX)\r\nradeon_ttm_set_active_vram_size(rdev, rdev->mc.visible_vram_size);\r\nWREG32(CP_ME_CNTL, (CP_ME_HALT | CP_PFP_HALT));\r\nWREG32(SCRATCH_UMSK, 0);\r\nrdev->ring[RADEON_RING_TYPE_GFX_INDEX].ready = false;\r\n}\r\nstatic int rv770_cp_load_microcode(struct radeon_device *rdev)\r\n{\r\nconst __be32 *fw_data;\r\nint i;\r\nif (!rdev->me_fw || !rdev->pfp_fw)\r\nreturn -EINVAL;\r\nr700_cp_stop(rdev);\r\nWREG32(CP_RB_CNTL,\r\n#ifdef __BIG_ENDIAN\r\nBUF_SWAP_32BIT |\r\n#endif\r\nRB_NO_UPDATE | RB_BLKSZ(15) | RB_BUFSZ(3));\r\nWREG32(GRBM_SOFT_RESET, SOFT_RESET_CP);\r\nRREG32(GRBM_SOFT_RESET);\r\nmdelay(15);\r\nWREG32(GRBM_SOFT_RESET, 0);\r\nfw_data = (const __be32 *)rdev->pfp_fw->data;\r\nWREG32(CP_PFP_UCODE_ADDR, 0);\r\nfor (i = 0; i < R700_PFP_UCODE_SIZE; i++)\r\nWREG32(CP_PFP_UCODE_DATA, be32_to_cpup(fw_data++));\r\nWREG32(CP_PFP_UCODE_ADDR, 0);\r\nfw_data = (const __be32 *)rdev->me_fw->data;\r\nWREG32(CP_ME_RAM_WADDR, 0);\r\nfor (i = 0; i < R700_PM4_UCODE_SIZE; i++)\r\nWREG32(CP_ME_RAM_DATA, be32_to_cpup(fw_data++));\r\nWREG32(CP_PFP_UCODE_ADDR, 0);\r\nWREG32(CP_ME_RAM_WADDR, 0);\r\nWREG32(CP_ME_RAM_RADDR, 0);\r\nreturn 0;\r\n}\r\nvoid r700_cp_fini(struct radeon_device *rdev)\r\n{\r\nstruct radeon_ring *ring = &rdev->ring[RADEON_RING_TYPE_GFX_INDEX];\r\nr700_cp_stop(rdev);\r\nradeon_ring_fini(rdev, ring);\r\nradeon_scratch_free(rdev, ring->rptr_save_reg);\r\n}\r\nvoid rv770_set_clk_bypass_mode(struct radeon_device *rdev)\r\n{\r\nu32 tmp, i;\r\nif (rdev->flags & RADEON_IS_IGP)\r\nreturn;\r\ntmp = RREG32(CG_SPLL_FUNC_CNTL_2);\r\ntmp &= SCLK_MUX_SEL_MASK;\r\ntmp |= SCLK_MUX_SEL(1) | SCLK_MUX_UPDATE;\r\nWREG32(CG_SPLL_FUNC_CNTL_2, tmp);\r\nfor (i = 0; i < rdev->usec_timeout; i++) {\r\nif (RREG32(CG_SPLL_STATUS) & SPLL_CHG_STATUS)\r\nbreak;\r\nudelay(1);\r\n}\r\ntmp &= ~SCLK_MUX_UPDATE;\r\nWREG32(CG_SPLL_FUNC_CNTL_2, tmp);\r\ntmp = RREG32(MPLL_CNTL_MODE);\r\nif ((rdev->family == CHIP_RV710) || (rdev->family == CHIP_RV730))\r\ntmp &= ~RV730_MPLL_MCLK_SEL;\r\nelse\r\ntmp &= ~MPLL_MCLK_SEL;\r\nWREG32(MPLL_CNTL_MODE, tmp);\r\n}\r\nstatic void rv770_gpu_init(struct radeon_device *rdev)\r\n{\r\nint i, j, num_qd_pipes;\r\nu32 ta_aux_cntl;\r\nu32 sx_debug_1;\r\nu32 smx_dc_ctl0;\r\nu32 db_debug3;\r\nu32 num_gs_verts_per_thread;\r\nu32 vgt_gs_per_es;\r\nu32 gs_prim_buffer_depth = 0;\r\nu32 sq_ms_fifo_sizes;\r\nu32 sq_config;\r\nu32 sq_thread_resource_mgmt;\r\nu32 hdp_host_path_cntl;\r\nu32 sq_dyn_gpr_size_simd_ab_0;\r\nu32 gb_tiling_config = 0;\r\nu32 cc_gc_shader_pipe_config = 0;\r\nu32 mc_arb_ramcfg;\r\nu32 db_debug4, tmp;\r\nu32 inactive_pipes, shader_pipe_config;\r\nu32 disabled_rb_mask;\r\nunsigned active_number;\r\nrdev->config.rv770.tiling_group_size = 256;\r\nswitch (rdev->family) {\r\ncase CHIP_RV770:\r\nrdev->config.rv770.max_pipes = 4;\r\nrdev->config.rv770.max_tile_pipes = 8;\r\nrdev->config.rv770.max_simds = 10;\r\nrdev->config.rv770.max_backends = 4;\r\nrdev->config.rv770.max_gprs = 256;\r\nrdev->config.rv770.max_threads = 248;\r\nrdev->config.rv770.max_stack_entries = 512;\r\nrdev->config.rv770.max_hw_contexts = 8;\r\nrdev->config.rv770.max_gs_threads = 16 * 2;\r\nrdev->config.rv770.sx_max_export_size = 128;\r\nrdev->config.rv770.sx_max_export_pos_size = 16;\r\nrdev->config.rv770.sx_max_export_smx_size = 112;\r\nrdev->config.rv770.sq_num_cf_insts = 2;\r\nrdev->config.rv770.sx_num_of_sets = 7;\r\nrdev->config.rv770.sc_prim_fifo_size = 0xF9;\r\nrdev->config.rv770.sc_hiz_tile_fifo_size = 0x30;\r\nrdev->config.rv770.sc_earlyz_tile_fifo_fize = 0x130;\r\nbreak;\r\ncase CHIP_RV730:\r\nrdev->config.rv770.max_pipes = 2;\r\nrdev->config.rv770.max_tile_pipes = 4;\r\nrdev->config.rv770.max_simds = 8;\r\nrdev->config.rv770.max_backends = 2;\r\nrdev->config.rv770.max_gprs = 128;\r\nrdev->config.rv770.max_threads = 248;\r\nrdev->config.rv770.max_stack_entries = 256;\r\nrdev->config.rv770.max_hw_contexts = 8;\r\nrdev->config.rv770.max_gs_threads = 16 * 2;\r\nrdev->config.rv770.sx_max_export_size = 256;\r\nrdev->config.rv770.sx_max_export_pos_size = 32;\r\nrdev->config.rv770.sx_max_export_smx_size = 224;\r\nrdev->config.rv770.sq_num_cf_insts = 2;\r\nrdev->config.rv770.sx_num_of_sets = 7;\r\nrdev->config.rv770.sc_prim_fifo_size = 0xf9;\r\nrdev->config.rv770.sc_hiz_tile_fifo_size = 0x30;\r\nrdev->config.rv770.sc_earlyz_tile_fifo_fize = 0x130;\r\nif (rdev->config.rv770.sx_max_export_pos_size > 16) {\r\nrdev->config.rv770.sx_max_export_pos_size -= 16;\r\nrdev->config.rv770.sx_max_export_smx_size += 16;\r\n}\r\nbreak;\r\ncase CHIP_RV710:\r\nrdev->config.rv770.max_pipes = 2;\r\nrdev->config.rv770.max_tile_pipes = 2;\r\nrdev->config.rv770.max_simds = 2;\r\nrdev->config.rv770.max_backends = 1;\r\nrdev->config.rv770.max_gprs = 256;\r\nrdev->config.rv770.max_threads = 192;\r\nrdev->config.rv770.max_stack_entries = 256;\r\nrdev->config.rv770.max_hw_contexts = 4;\r\nrdev->config.rv770.max_gs_threads = 8 * 2;\r\nrdev->config.rv770.sx_max_export_size = 128;\r\nrdev->config.rv770.sx_max_export_pos_size = 16;\r\nrdev->config.rv770.sx_max_export_smx_size = 112;\r\nrdev->config.rv770.sq_num_cf_insts = 1;\r\nrdev->config.rv770.sx_num_of_sets = 7;\r\nrdev->config.rv770.sc_prim_fifo_size = 0x40;\r\nrdev->config.rv770.sc_hiz_tile_fifo_size = 0x30;\r\nrdev->config.rv770.sc_earlyz_tile_fifo_fize = 0x130;\r\nbreak;\r\ncase CHIP_RV740:\r\nrdev->config.rv770.max_pipes = 4;\r\nrdev->config.rv770.max_tile_pipes = 4;\r\nrdev->config.rv770.max_simds = 8;\r\nrdev->config.rv770.max_backends = 4;\r\nrdev->config.rv770.max_gprs = 256;\r\nrdev->config.rv770.max_threads = 248;\r\nrdev->config.rv770.max_stack_entries = 512;\r\nrdev->config.rv770.max_hw_contexts = 8;\r\nrdev->config.rv770.max_gs_threads = 16 * 2;\r\nrdev->config.rv770.sx_max_export_size = 256;\r\nrdev->config.rv770.sx_max_export_pos_size = 32;\r\nrdev->config.rv770.sx_max_export_smx_size = 224;\r\nrdev->config.rv770.sq_num_cf_insts = 2;\r\nrdev->config.rv770.sx_num_of_sets = 7;\r\nrdev->config.rv770.sc_prim_fifo_size = 0x100;\r\nrdev->config.rv770.sc_hiz_tile_fifo_size = 0x30;\r\nrdev->config.rv770.sc_earlyz_tile_fifo_fize = 0x130;\r\nif (rdev->config.rv770.sx_max_export_pos_size > 16) {\r\nrdev->config.rv770.sx_max_export_pos_size -= 16;\r\nrdev->config.rv770.sx_max_export_smx_size += 16;\r\n}\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nj = 0;\r\nfor (i = 0; i < 32; i++) {\r\nWREG32((0x2c14 + j), 0x00000000);\r\nWREG32((0x2c18 + j), 0x00000000);\r\nWREG32((0x2c1c + j), 0x00000000);\r\nWREG32((0x2c20 + j), 0x00000000);\r\nWREG32((0x2c24 + j), 0x00000000);\r\nj += 0x18;\r\n}\r\nWREG32(GRBM_CNTL, GRBM_READ_TIMEOUT(0xff));\r\nmc_arb_ramcfg = RREG32(MC_ARB_RAMCFG);\r\nshader_pipe_config = RREG32(CC_GC_SHADER_PIPE_CONFIG);\r\ninactive_pipes = (shader_pipe_config & INACTIVE_QD_PIPES_MASK) >> INACTIVE_QD_PIPES_SHIFT;\r\nfor (i = 0, tmp = 1, active_number = 0; i < R7XX_MAX_PIPES; i++) {\r\nif (!(inactive_pipes & tmp)) {\r\nactive_number++;\r\n}\r\ntmp <<= 1;\r\n}\r\nif (active_number == 1) {\r\nWREG32(SPI_CONFIG_CNTL, DISABLE_INTERP_1);\r\n} else {\r\nWREG32(SPI_CONFIG_CNTL, 0);\r\n}\r\ncc_gc_shader_pipe_config = RREG32(CC_GC_SHADER_PIPE_CONFIG) & 0xffffff00;\r\ntmp = rdev->config.rv770.max_simds -\r\nr600_count_pipe_bits((cc_gc_shader_pipe_config >> 16) & R7XX_MAX_SIMDS_MASK);\r\nrdev->config.rv770.active_simds = tmp;\r\nswitch (rdev->config.rv770.max_tile_pipes) {\r\ncase 1:\r\ndefault:\r\ngb_tiling_config = PIPE_TILING(0);\r\nbreak;\r\ncase 2:\r\ngb_tiling_config = PIPE_TILING(1);\r\nbreak;\r\ncase 4:\r\ngb_tiling_config = PIPE_TILING(2);\r\nbreak;\r\ncase 8:\r\ngb_tiling_config = PIPE_TILING(3);\r\nbreak;\r\n}\r\nrdev->config.rv770.tiling_npipes = rdev->config.rv770.max_tile_pipes;\r\ndisabled_rb_mask = (RREG32(CC_RB_BACKEND_DISABLE) >> 16) & R7XX_MAX_BACKENDS_MASK;\r\ntmp = 0;\r\nfor (i = 0; i < rdev->config.rv770.max_backends; i++)\r\ntmp |= (1 << i);\r\nif ((disabled_rb_mask & tmp) == tmp) {\r\nfor (i = 0; i < rdev->config.rv770.max_backends; i++)\r\ndisabled_rb_mask &= ~(1 << i);\r\n}\r\ntmp = (gb_tiling_config & PIPE_TILING__MASK) >> PIPE_TILING__SHIFT;\r\ntmp = r6xx_remap_render_backend(rdev, tmp, rdev->config.rv770.max_backends,\r\nR7XX_MAX_BACKENDS, disabled_rb_mask);\r\ngb_tiling_config |= tmp << 16;\r\nrdev->config.rv770.backend_map = tmp;\r\nif (rdev->family == CHIP_RV770)\r\ngb_tiling_config |= BANK_TILING(1);\r\nelse {\r\nif ((mc_arb_ramcfg & NOOFBANK_MASK) >> NOOFBANK_SHIFT)\r\ngb_tiling_config |= BANK_TILING(1);\r\nelse\r\ngb_tiling_config |= BANK_TILING(0);\r\n}\r\nrdev->config.rv770.tiling_nbanks = 4 << ((gb_tiling_config >> 4) & 0x3);\r\ngb_tiling_config |= GROUP_SIZE((mc_arb_ramcfg & BURSTLENGTH_MASK) >> BURSTLENGTH_SHIFT);\r\nif (((mc_arb_ramcfg & NOOFROWS_MASK) >> NOOFROWS_SHIFT) > 3) {\r\ngb_tiling_config |= ROW_TILING(3);\r\ngb_tiling_config |= SAMPLE_SPLIT(3);\r\n} else {\r\ngb_tiling_config |=\r\nROW_TILING(((mc_arb_ramcfg & NOOFROWS_MASK) >> NOOFROWS_SHIFT));\r\ngb_tiling_config |=\r\nSAMPLE_SPLIT(((mc_arb_ramcfg & NOOFROWS_MASK) >> NOOFROWS_SHIFT));\r\n}\r\ngb_tiling_config |= BANK_SWAPS(1);\r\nrdev->config.rv770.tile_config = gb_tiling_config;\r\nWREG32(GB_TILING_CONFIG, gb_tiling_config);\r\nWREG32(DCP_TILING_CONFIG, (gb_tiling_config & 0xffff));\r\nWREG32(HDP_TILING_CONFIG, (gb_tiling_config & 0xffff));\r\nWREG32(DMA_TILING_CONFIG, (gb_tiling_config & 0xffff));\r\nWREG32(DMA_TILING_CONFIG2, (gb_tiling_config & 0xffff));\r\nif (rdev->family == CHIP_RV730) {\r\nWREG32(UVD_UDEC_DB_TILING_CONFIG, (gb_tiling_config & 0xffff));\r\nWREG32(UVD_UDEC_DBW_TILING_CONFIG, (gb_tiling_config & 0xffff));\r\nWREG32(UVD_UDEC_TILING_CONFIG, (gb_tiling_config & 0xffff));\r\n}\r\nWREG32(CGTS_SYS_TCC_DISABLE, 0);\r\nWREG32(CGTS_TCC_DISABLE, 0);\r\nWREG32(CGTS_USER_SYS_TCC_DISABLE, 0);\r\nWREG32(CGTS_USER_TCC_DISABLE, 0);\r\nnum_qd_pipes = R7XX_MAX_PIPES - r600_count_pipe_bits((cc_gc_shader_pipe_config & INACTIVE_QD_PIPES_MASK) >> 8);\r\nWREG32(VGT_OUT_DEALLOC_CNTL, (num_qd_pipes * 4) & DEALLOC_DIST_MASK);\r\nWREG32(VGT_VERTEX_REUSE_BLOCK_CNTL, ((num_qd_pipes * 4) - 2) & VTX_REUSE_DEPTH_MASK);\r\nWREG32(CP_QUEUE_THRESHOLDS, (ROQ_IB1_START(0x16) |\r\nROQ_IB2_START(0x2b)));\r\nWREG32(CP_MEQ_THRESHOLDS, STQ_SPLIT(0x30));\r\nta_aux_cntl = RREG32(TA_CNTL_AUX);\r\nWREG32(TA_CNTL_AUX, ta_aux_cntl | DISABLE_CUBE_ANISO);\r\nsx_debug_1 = RREG32(SX_DEBUG_1);\r\nsx_debug_1 |= ENABLE_NEW_SMX_ADDRESS;\r\nWREG32(SX_DEBUG_1, sx_debug_1);\r\nsmx_dc_ctl0 = RREG32(SMX_DC_CTL0);\r\nsmx_dc_ctl0 &= ~CACHE_DEPTH(0x1ff);\r\nsmx_dc_ctl0 |= CACHE_DEPTH((rdev->config.rv770.sx_num_of_sets * 64) - 1);\r\nWREG32(SMX_DC_CTL0, smx_dc_ctl0);\r\nif (rdev->family != CHIP_RV740)\r\nWREG32(SMX_EVENT_CTL, (ES_FLUSH_CTL(4) |\r\nGS_FLUSH_CTL(4) |\r\nACK_FLUSH_CTL(3) |\r\nSYNC_FLUSH_CTL));\r\nif (rdev->family != CHIP_RV770)\r\nWREG32(SMX_SAR_CTL0, 0x00003f3f);\r\ndb_debug3 = RREG32(DB_DEBUG3);\r\ndb_debug3 &= ~DB_CLK_OFF_DELAY(0x1f);\r\nswitch (rdev->family) {\r\ncase CHIP_RV770:\r\ncase CHIP_RV740:\r\ndb_debug3 |= DB_CLK_OFF_DELAY(0x1f);\r\nbreak;\r\ncase CHIP_RV710:\r\ncase CHIP_RV730:\r\ndefault:\r\ndb_debug3 |= DB_CLK_OFF_DELAY(2);\r\nbreak;\r\n}\r\nWREG32(DB_DEBUG3, db_debug3);\r\nif (rdev->family != CHIP_RV770) {\r\ndb_debug4 = RREG32(DB_DEBUG4);\r\ndb_debug4 |= DISABLE_TILE_COVERED_FOR_PS_ITER;\r\nWREG32(DB_DEBUG4, db_debug4);\r\n}\r\nWREG32(SX_EXPORT_BUFFER_SIZES, (COLOR_BUFFER_SIZE((rdev->config.rv770.sx_max_export_size / 4) - 1) |\r\nPOSITION_BUFFER_SIZE((rdev->config.rv770.sx_max_export_pos_size / 4) - 1) |\r\nSMX_BUFFER_SIZE((rdev->config.rv770.sx_max_export_smx_size / 4) - 1)));\r\nWREG32(PA_SC_FIFO_SIZE, (SC_PRIM_FIFO_SIZE(rdev->config.rv770.sc_prim_fifo_size) |\r\nSC_HIZ_TILE_FIFO_SIZE(rdev->config.rv770.sc_hiz_tile_fifo_size) |\r\nSC_EARLYZ_TILE_FIFO_SIZE(rdev->config.rv770.sc_earlyz_tile_fifo_fize)));\r\nWREG32(PA_SC_MULTI_CHIP_CNTL, 0);\r\nWREG32(VGT_NUM_INSTANCES, 1);\r\nWREG32(SPI_CONFIG_CNTL_1, VTX_DONE_DELAY(4));\r\nWREG32(CP_PERFMON_CNTL, 0);\r\nsq_ms_fifo_sizes = (CACHE_FIFO_SIZE(16 * rdev->config.rv770.sq_num_cf_insts) |\r\nDONE_FIFO_HIWATER(0xe0) |\r\nALU_UPDATE_FIFO_HIWATER(0x8));\r\nswitch (rdev->family) {\r\ncase CHIP_RV770:\r\ncase CHIP_RV730:\r\ncase CHIP_RV710:\r\nsq_ms_fifo_sizes |= FETCH_FIFO_HIWATER(0x1);\r\nbreak;\r\ncase CHIP_RV740:\r\ndefault:\r\nsq_ms_fifo_sizes |= FETCH_FIFO_HIWATER(0x4);\r\nbreak;\r\n}\r\nWREG32(SQ_MS_FIFO_SIZES, sq_ms_fifo_sizes);\r\nsq_config = RREG32(SQ_CONFIG);\r\nsq_config &= ~(PS_PRIO(3) |\r\nVS_PRIO(3) |\r\nGS_PRIO(3) |\r\nES_PRIO(3));\r\nsq_config |= (DX9_CONSTS |\r\nVC_ENABLE |\r\nEXPORT_SRC_C |\r\nPS_PRIO(0) |\r\nVS_PRIO(1) |\r\nGS_PRIO(2) |\r\nES_PRIO(3));\r\nif (rdev->family == CHIP_RV710)\r\nsq_config &= ~VC_ENABLE;\r\nWREG32(SQ_CONFIG, sq_config);\r\nWREG32(SQ_GPR_RESOURCE_MGMT_1, (NUM_PS_GPRS((rdev->config.rv770.max_gprs * 24)/64) |\r\nNUM_VS_GPRS((rdev->config.rv770.max_gprs * 24)/64) |\r\nNUM_CLAUSE_TEMP_GPRS(((rdev->config.rv770.max_gprs * 24)/64)/2)));\r\nWREG32(SQ_GPR_RESOURCE_MGMT_2, (NUM_GS_GPRS((rdev->config.rv770.max_gprs * 7)/64) |\r\nNUM_ES_GPRS((rdev->config.rv770.max_gprs * 7)/64)));\r\nsq_thread_resource_mgmt = (NUM_PS_THREADS((rdev->config.rv770.max_threads * 4)/8) |\r\nNUM_VS_THREADS((rdev->config.rv770.max_threads * 2)/8) |\r\nNUM_ES_THREADS((rdev->config.rv770.max_threads * 1)/8));\r\nif (((rdev->config.rv770.max_threads * 1) / 8) > rdev->config.rv770.max_gs_threads)\r\nsq_thread_resource_mgmt |= NUM_GS_THREADS(rdev->config.rv770.max_gs_threads);\r\nelse\r\nsq_thread_resource_mgmt |= NUM_GS_THREADS((rdev->config.rv770.max_gs_threads * 1)/8);\r\nWREG32(SQ_THREAD_RESOURCE_MGMT, sq_thread_resource_mgmt);\r\nWREG32(SQ_STACK_RESOURCE_MGMT_1, (NUM_PS_STACK_ENTRIES((rdev->config.rv770.max_stack_entries * 1)/4) |\r\nNUM_VS_STACK_ENTRIES((rdev->config.rv770.max_stack_entries * 1)/4)));\r\nWREG32(SQ_STACK_RESOURCE_MGMT_2, (NUM_GS_STACK_ENTRIES((rdev->config.rv770.max_stack_entries * 1)/4) |\r\nNUM_ES_STACK_ENTRIES((rdev->config.rv770.max_stack_entries * 1)/4)));\r\nsq_dyn_gpr_size_simd_ab_0 = (SIMDA_RING0((rdev->config.rv770.max_gprs * 38)/64) |\r\nSIMDA_RING1((rdev->config.rv770.max_gprs * 38)/64) |\r\nSIMDB_RING0((rdev->config.rv770.max_gprs * 38)/64) |\r\nSIMDB_RING1((rdev->config.rv770.max_gprs * 38)/64));\r\nWREG32(SQ_DYN_GPR_SIZE_SIMD_AB_0, sq_dyn_gpr_size_simd_ab_0);\r\nWREG32(SQ_DYN_GPR_SIZE_SIMD_AB_1, sq_dyn_gpr_size_simd_ab_0);\r\nWREG32(SQ_DYN_GPR_SIZE_SIMD_AB_2, sq_dyn_gpr_size_simd_ab_0);\r\nWREG32(SQ_DYN_GPR_SIZE_SIMD_AB_3, sq_dyn_gpr_size_simd_ab_0);\r\nWREG32(SQ_DYN_GPR_SIZE_SIMD_AB_4, sq_dyn_gpr_size_simd_ab_0);\r\nWREG32(SQ_DYN_GPR_SIZE_SIMD_AB_5, sq_dyn_gpr_size_simd_ab_0);\r\nWREG32(SQ_DYN_GPR_SIZE_SIMD_AB_6, sq_dyn_gpr_size_simd_ab_0);\r\nWREG32(SQ_DYN_GPR_SIZE_SIMD_AB_7, sq_dyn_gpr_size_simd_ab_0);\r\nWREG32(PA_SC_FORCE_EOV_MAX_CNTS, (FORCE_EOV_MAX_CLK_CNT(4095) |\r\nFORCE_EOV_MAX_REZ_CNT(255)));\r\nif (rdev->family == CHIP_RV710)\r\nWREG32(VGT_CACHE_INVALIDATION, (CACHE_INVALIDATION(TC_ONLY) |\r\nAUTO_INVLD_EN(ES_AND_GS_AUTO)));\r\nelse\r\nWREG32(VGT_CACHE_INVALIDATION, (CACHE_INVALIDATION(VC_AND_TC) |\r\nAUTO_INVLD_EN(ES_AND_GS_AUTO)));\r\nswitch (rdev->family) {\r\ncase CHIP_RV770:\r\ncase CHIP_RV730:\r\ncase CHIP_RV740:\r\ngs_prim_buffer_depth = 384;\r\nbreak;\r\ncase CHIP_RV710:\r\ngs_prim_buffer_depth = 128;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nnum_gs_verts_per_thread = rdev->config.rv770.max_pipes * 16;\r\nvgt_gs_per_es = gs_prim_buffer_depth + num_gs_verts_per_thread;\r\nif (vgt_gs_per_es > 256)\r\nvgt_gs_per_es = 256;\r\nWREG32(VGT_ES_PER_GS, 128);\r\nWREG32(VGT_GS_PER_ES, vgt_gs_per_es);\r\nWREG32(VGT_GS_PER_VS, 2);\r\nWREG32(VGT_GS_VERTEX_REUSE, 16);\r\nWREG32(PA_SC_LINE_STIPPLE_STATE, 0);\r\nWREG32(VGT_STRMOUT_EN, 0);\r\nWREG32(SX_MISC, 0);\r\nWREG32(PA_SC_MODE_CNTL, 0);\r\nWREG32(PA_SC_EDGERULE, 0xaaaaaaaa);\r\nWREG32(PA_SC_AA_CONFIG, 0);\r\nWREG32(PA_SC_CLIPRECT_RULE, 0xffff);\r\nWREG32(PA_SC_LINE_STIPPLE, 0);\r\nWREG32(SPI_INPUT_Z, 0);\r\nWREG32(SPI_PS_IN_CONTROL_0, NUM_INTERP(2));\r\nWREG32(CB_COLOR7_FRAG, 0);\r\nWREG32(CB_COLOR0_BASE, 0);\r\nWREG32(CB_COLOR1_BASE, 0);\r\nWREG32(CB_COLOR2_BASE, 0);\r\nWREG32(CB_COLOR3_BASE, 0);\r\nWREG32(CB_COLOR4_BASE, 0);\r\nWREG32(CB_COLOR5_BASE, 0);\r\nWREG32(CB_COLOR6_BASE, 0);\r\nWREG32(CB_COLOR7_BASE, 0);\r\nWREG32(TCP_CNTL, 0);\r\nhdp_host_path_cntl = RREG32(HDP_HOST_PATH_CNTL);\r\nWREG32(HDP_HOST_PATH_CNTL, hdp_host_path_cntl);\r\nWREG32(PA_SC_MULTI_CHIP_CNTL, 0);\r\nWREG32(PA_CL_ENHANCE, (CLIP_VTX_REORDER_ENA |\r\nNUM_CLIP_SEQ(3)));\r\nWREG32(VC_ENHANCE, 0);\r\n}\r\nvoid r700_vram_gtt_location(struct radeon_device *rdev, struct radeon_mc *mc)\r\n{\r\nu64 size_bf, size_af;\r\nif (mc->mc_vram_size > 0xE0000000) {\r\ndev_warn(rdev->dev, "limiting VRAM\n");\r\nmc->real_vram_size = 0xE0000000;\r\nmc->mc_vram_size = 0xE0000000;\r\n}\r\nif (rdev->flags & RADEON_IS_AGP) {\r\nsize_bf = mc->gtt_start;\r\nsize_af = mc->mc_mask - mc->gtt_end;\r\nif (size_bf > size_af) {\r\nif (mc->mc_vram_size > size_bf) {\r\ndev_warn(rdev->dev, "limiting VRAM\n");\r\nmc->real_vram_size = size_bf;\r\nmc->mc_vram_size = size_bf;\r\n}\r\nmc->vram_start = mc->gtt_start - mc->mc_vram_size;\r\n} else {\r\nif (mc->mc_vram_size > size_af) {\r\ndev_warn(rdev->dev, "limiting VRAM\n");\r\nmc->real_vram_size = size_af;\r\nmc->mc_vram_size = size_af;\r\n}\r\nmc->vram_start = mc->gtt_end + 1;\r\n}\r\nmc->vram_end = mc->vram_start + mc->mc_vram_size - 1;\r\ndev_info(rdev->dev, "VRAM: %lluM 0x%08llX - 0x%08llX (%lluM used)\n",\r\nmc->mc_vram_size >> 20, mc->vram_start,\r\nmc->vram_end, mc->real_vram_size >> 20);\r\n} else {\r\nradeon_vram_location(rdev, &rdev->mc, 0);\r\nrdev->mc.gtt_base_align = 0;\r\nradeon_gtt_location(rdev, mc);\r\n}\r\n}\r\nstatic int rv770_mc_init(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\nint chansize, numchan;\r\nrdev->mc.vram_is_ddr = true;\r\ntmp = RREG32(MC_ARB_RAMCFG);\r\nif (tmp & CHANSIZE_OVERRIDE) {\r\nchansize = 16;\r\n} else if (tmp & CHANSIZE_MASK) {\r\nchansize = 64;\r\n} else {\r\nchansize = 32;\r\n}\r\ntmp = RREG32(MC_SHARED_CHMAP);\r\nswitch ((tmp & NOOFCHAN_MASK) >> NOOFCHAN_SHIFT) {\r\ncase 0:\r\ndefault:\r\nnumchan = 1;\r\nbreak;\r\ncase 1:\r\nnumchan = 2;\r\nbreak;\r\ncase 2:\r\nnumchan = 4;\r\nbreak;\r\ncase 3:\r\nnumchan = 8;\r\nbreak;\r\n}\r\nrdev->mc.vram_width = numchan * chansize;\r\nrdev->mc.aper_base = pci_resource_start(rdev->pdev, 0);\r\nrdev->mc.aper_size = pci_resource_len(rdev->pdev, 0);\r\nrdev->mc.mc_vram_size = RREG32(CONFIG_MEMSIZE);\r\nrdev->mc.real_vram_size = RREG32(CONFIG_MEMSIZE);\r\nrdev->mc.visible_vram_size = rdev->mc.aper_size;\r\nr700_vram_gtt_location(rdev, &rdev->mc);\r\nradeon_update_bandwidth_info(rdev);\r\nreturn 0;\r\n}\r\nstatic void rv770_uvd_init(struct radeon_device *rdev)\r\n{\r\nint r;\r\nif (!rdev->has_uvd)\r\nreturn;\r\nr = radeon_uvd_init(rdev);\r\nif (r) {\r\ndev_err(rdev->dev, "failed UVD (%d) init.\n", r);\r\nrdev->has_uvd = 0;\r\nreturn;\r\n}\r\nrdev->ring[R600_RING_TYPE_UVD_INDEX].ring_obj = NULL;\r\nr600_ring_init(rdev, &rdev->ring[R600_RING_TYPE_UVD_INDEX], 4096);\r\n}\r\nstatic void rv770_uvd_start(struct radeon_device *rdev)\r\n{\r\nint r;\r\nif (!rdev->has_uvd)\r\nreturn;\r\nr = uvd_v2_2_resume(rdev);\r\nif (r) {\r\ndev_err(rdev->dev, "failed UVD resume (%d).\n", r);\r\ngoto error;\r\n}\r\nr = radeon_fence_driver_start_ring(rdev, R600_RING_TYPE_UVD_INDEX);\r\nif (r) {\r\ndev_err(rdev->dev, "failed initializing UVD fences (%d).\n", r);\r\ngoto error;\r\n}\r\nreturn;\r\nerror:\r\nrdev->ring[R600_RING_TYPE_UVD_INDEX].ring_size = 0;\r\n}\r\nstatic void rv770_uvd_resume(struct radeon_device *rdev)\r\n{\r\nstruct radeon_ring *ring;\r\nint r;\r\nif (!rdev->has_uvd || !rdev->ring[R600_RING_TYPE_UVD_INDEX].ring_size)\r\nreturn;\r\nring = &rdev->ring[R600_RING_TYPE_UVD_INDEX];\r\nr = radeon_ring_init(rdev, ring, ring->ring_size, 0, RADEON_CP_PACKET2);\r\nif (r) {\r\ndev_err(rdev->dev, "failed initializing UVD ring (%d).\n", r);\r\nreturn;\r\n}\r\nr = uvd_v1_0_init(rdev);\r\nif (r) {\r\ndev_err(rdev->dev, "failed initializing UVD (%d).\n", r);\r\nreturn;\r\n}\r\n}\r\nstatic int rv770_startup(struct radeon_device *rdev)\r\n{\r\nstruct radeon_ring *ring;\r\nint r;\r\nrv770_pcie_gen2_enable(rdev);\r\nr = r600_vram_scratch_init(rdev);\r\nif (r)\r\nreturn r;\r\nrv770_mc_program(rdev);\r\nif (rdev->flags & RADEON_IS_AGP) {\r\nrv770_agp_enable(rdev);\r\n} else {\r\nr = rv770_pcie_gart_enable(rdev);\r\nif (r)\r\nreturn r;\r\n}\r\nrv770_gpu_init(rdev);\r\nr = radeon_wb_init(rdev);\r\nif (r)\r\nreturn r;\r\nr = radeon_fence_driver_start_ring(rdev, RADEON_RING_TYPE_GFX_INDEX);\r\nif (r) {\r\ndev_err(rdev->dev, "failed initializing CP fences (%d).\n", r);\r\nreturn r;\r\n}\r\nr = radeon_fence_driver_start_ring(rdev, R600_RING_TYPE_DMA_INDEX);\r\nif (r) {\r\ndev_err(rdev->dev, "failed initializing DMA fences (%d).\n", r);\r\nreturn r;\r\n}\r\nrv770_uvd_start(rdev);\r\nif (!rdev->irq.installed) {\r\nr = radeon_irq_kms_init(rdev);\r\nif (r)\r\nreturn r;\r\n}\r\nr = r600_irq_init(rdev);\r\nif (r) {\r\nDRM_ERROR("radeon: IH init failed (%d).\n", r);\r\nradeon_irq_kms_fini(rdev);\r\nreturn r;\r\n}\r\nr600_irq_set(rdev);\r\nring = &rdev->ring[RADEON_RING_TYPE_GFX_INDEX];\r\nr = radeon_ring_init(rdev, ring, ring->ring_size, RADEON_WB_CP_RPTR_OFFSET,\r\nRADEON_CP_PACKET2);\r\nif (r)\r\nreturn r;\r\nring = &rdev->ring[R600_RING_TYPE_DMA_INDEX];\r\nr = radeon_ring_init(rdev, ring, ring->ring_size, R600_WB_DMA_RPTR_OFFSET,\r\nDMA_PACKET(DMA_PACKET_NOP, 0, 0, 0));\r\nif (r)\r\nreturn r;\r\nr = rv770_cp_load_microcode(rdev);\r\nif (r)\r\nreturn r;\r\nr = r600_cp_resume(rdev);\r\nif (r)\r\nreturn r;\r\nr = r600_dma_resume(rdev);\r\nif (r)\r\nreturn r;\r\nrv770_uvd_resume(rdev);\r\nr = radeon_ib_pool_init(rdev);\r\nif (r) {\r\ndev_err(rdev->dev, "IB initialization failed (%d).\n", r);\r\nreturn r;\r\n}\r\nr = radeon_audio_init(rdev);\r\nif (r) {\r\nDRM_ERROR("radeon: audio init failed\n");\r\nreturn r;\r\n}\r\nreturn 0;\r\n}\r\nint rv770_resume(struct radeon_device *rdev)\r\n{\r\nint r;\r\natom_asic_init(rdev->mode_info.atom_context);\r\nrv770_init_golden_registers(rdev);\r\nif (rdev->pm.pm_method == PM_METHOD_DPM)\r\nradeon_pm_resume(rdev);\r\nrdev->accel_working = true;\r\nr = rv770_startup(rdev);\r\nif (r) {\r\nDRM_ERROR("r600 startup failed on resume\n");\r\nrdev->accel_working = false;\r\nreturn r;\r\n}\r\nreturn r;\r\n}\r\nint rv770_suspend(struct radeon_device *rdev)\r\n{\r\nradeon_pm_suspend(rdev);\r\nradeon_audio_fini(rdev);\r\nif (rdev->has_uvd) {\r\nuvd_v1_0_fini(rdev);\r\nradeon_uvd_suspend(rdev);\r\n}\r\nr700_cp_stop(rdev);\r\nr600_dma_stop(rdev);\r\nr600_irq_suspend(rdev);\r\nradeon_wb_disable(rdev);\r\nrv770_pcie_gart_disable(rdev);\r\nreturn 0;\r\n}\r\nint rv770_init(struct radeon_device *rdev)\r\n{\r\nint r;\r\nif (!radeon_get_bios(rdev)) {\r\nif (ASIC_IS_AVIVO(rdev))\r\nreturn -EINVAL;\r\n}\r\nif (!rdev->is_atom_bios) {\r\ndev_err(rdev->dev, "Expecting atombios for R600 GPU\n");\r\nreturn -EINVAL;\r\n}\r\nr = radeon_atombios_init(rdev);\r\nif (r)\r\nreturn r;\r\nif (!radeon_card_posted(rdev)) {\r\nif (!rdev->bios) {\r\ndev_err(rdev->dev, "Card not posted and no BIOS - ignoring\n");\r\nreturn -EINVAL;\r\n}\r\nDRM_INFO("GPU not posted. posting now...\n");\r\natom_asic_init(rdev->mode_info.atom_context);\r\n}\r\nrv770_init_golden_registers(rdev);\r\nr600_scratch_init(rdev);\r\nradeon_surface_init(rdev);\r\nradeon_get_clock_info(rdev->ddev);\r\nr = radeon_fence_driver_init(rdev);\r\nif (r)\r\nreturn r;\r\nif (rdev->flags & RADEON_IS_AGP) {\r\nr = radeon_agp_init(rdev);\r\nif (r)\r\nradeon_agp_disable(rdev);\r\n}\r\nr = rv770_mc_init(rdev);\r\nif (r)\r\nreturn r;\r\nr = radeon_bo_init(rdev);\r\nif (r)\r\nreturn r;\r\nif (!rdev->me_fw || !rdev->pfp_fw || !rdev->rlc_fw) {\r\nr = r600_init_microcode(rdev);\r\nif (r) {\r\nDRM_ERROR("Failed to load firmware!\n");\r\nreturn r;\r\n}\r\n}\r\nradeon_pm_init(rdev);\r\nrdev->ring[RADEON_RING_TYPE_GFX_INDEX].ring_obj = NULL;\r\nr600_ring_init(rdev, &rdev->ring[RADEON_RING_TYPE_GFX_INDEX], 1024 * 1024);\r\nrdev->ring[R600_RING_TYPE_DMA_INDEX].ring_obj = NULL;\r\nr600_ring_init(rdev, &rdev->ring[R600_RING_TYPE_DMA_INDEX], 64 * 1024);\r\nrv770_uvd_init(rdev);\r\nrdev->ih.ring_obj = NULL;\r\nr600_ih_ring_init(rdev, 64 * 1024);\r\nr = r600_pcie_gart_init(rdev);\r\nif (r)\r\nreturn r;\r\nrdev->accel_working = true;\r\nr = rv770_startup(rdev);\r\nif (r) {\r\ndev_err(rdev->dev, "disabling GPU acceleration\n");\r\nr700_cp_fini(rdev);\r\nr600_dma_fini(rdev);\r\nr600_irq_fini(rdev);\r\nradeon_wb_fini(rdev);\r\nradeon_ib_pool_fini(rdev);\r\nradeon_irq_kms_fini(rdev);\r\nrv770_pcie_gart_fini(rdev);\r\nrdev->accel_working = false;\r\n}\r\nreturn 0;\r\n}\r\nvoid rv770_fini(struct radeon_device *rdev)\r\n{\r\nradeon_pm_fini(rdev);\r\nr700_cp_fini(rdev);\r\nr600_dma_fini(rdev);\r\nr600_irq_fini(rdev);\r\nradeon_wb_fini(rdev);\r\nradeon_ib_pool_fini(rdev);\r\nradeon_irq_kms_fini(rdev);\r\nuvd_v1_0_fini(rdev);\r\nradeon_uvd_fini(rdev);\r\nrv770_pcie_gart_fini(rdev);\r\nr600_vram_scratch_fini(rdev);\r\nradeon_gem_fini(rdev);\r\nradeon_fence_driver_fini(rdev);\r\nradeon_agp_fini(rdev);\r\nradeon_bo_fini(rdev);\r\nradeon_atombios_fini(rdev);\r\nkfree(rdev->bios);\r\nrdev->bios = NULL;\r\n}\r\nstatic void rv770_pcie_gen2_enable(struct radeon_device *rdev)\r\n{\r\nu32 link_width_cntl, lanes, speed_cntl, tmp;\r\nu16 link_cntl2;\r\nif (radeon_pcie_gen2 == 0)\r\nreturn;\r\nif (rdev->flags & RADEON_IS_IGP)\r\nreturn;\r\nif (!(rdev->flags & RADEON_IS_PCIE))\r\nreturn;\r\nif (ASIC_IS_X2(rdev))\r\nreturn;\r\nif ((rdev->pdev->bus->max_bus_speed != PCIE_SPEED_5_0GT) &&\r\n(rdev->pdev->bus->max_bus_speed != PCIE_SPEED_8_0GT))\r\nreturn;\r\nDRM_INFO("enabling PCIE gen 2 link speeds, disable with radeon.pcie_gen2=0\n");\r\nlink_width_cntl = RREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL);\r\nlink_width_cntl &= ~LC_UPCONFIGURE_DIS;\r\nWREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL, link_width_cntl);\r\nlink_width_cntl = RREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL);\r\nif (link_width_cntl & LC_RENEGOTIATION_SUPPORT) {\r\nlanes = (link_width_cntl & LC_LINK_WIDTH_RD_MASK) >> LC_LINK_WIDTH_RD_SHIFT;\r\nlink_width_cntl &= ~(LC_LINK_WIDTH_MASK |\r\nLC_RECONFIG_ARC_MISSING_ESCAPE);\r\nlink_width_cntl |= lanes | LC_RECONFIG_NOW |\r\nLC_RENEGOTIATE_EN | LC_UPCONFIGURE_SUPPORT;\r\nWREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL, link_width_cntl);\r\n} else {\r\nlink_width_cntl |= LC_UPCONFIGURE_DIS;\r\nWREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL, link_width_cntl);\r\n}\r\nspeed_cntl = RREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL);\r\nif ((speed_cntl & LC_OTHER_SIDE_EVER_SENT_GEN2) &&\r\n(speed_cntl & LC_OTHER_SIDE_SUPPORTS_GEN2)) {\r\ntmp = RREG32(0x541c);\r\nWREG32(0x541c, tmp | 0x8);\r\nWREG32(MM_CFGREGS_CNTL, MM_WR_TO_CFG_EN);\r\nlink_cntl2 = RREG16(0x4088);\r\nlink_cntl2 &= ~TARGET_LINK_SPEED_MASK;\r\nlink_cntl2 |= 0x2;\r\nWREG16(0x4088, link_cntl2);\r\nWREG32(MM_CFGREGS_CNTL, 0);\r\nspeed_cntl = RREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL);\r\nspeed_cntl &= ~LC_TARGET_LINK_SPEED_OVERRIDE_EN;\r\nWREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL, speed_cntl);\r\nspeed_cntl = RREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL);\r\nspeed_cntl |= LC_CLR_FAILED_SPD_CHANGE_CNT;\r\nWREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL, speed_cntl);\r\nspeed_cntl = RREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL);\r\nspeed_cntl &= ~LC_CLR_FAILED_SPD_CHANGE_CNT;\r\nWREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL, speed_cntl);\r\nspeed_cntl = RREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL);\r\nspeed_cntl |= LC_GEN2_EN_STRAP;\r\nWREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL, speed_cntl);\r\n} else {\r\nlink_width_cntl = RREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL);\r\nif (1)\r\nlink_width_cntl |= LC_UPCONFIGURE_DIS;\r\nelse\r\nlink_width_cntl &= ~LC_UPCONFIGURE_DIS;\r\nWREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL, link_width_cntl);\r\n}\r\n}
