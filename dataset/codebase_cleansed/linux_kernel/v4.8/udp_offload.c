struct sk_buff *skb_udp_tunnel_segment(struct sk_buff *skb,\r\nnetdev_features_t features,\r\nbool is_ipv6)\r\n{\r\n__be16 protocol = skb->protocol;\r\nconst struct net_offload **offloads;\r\nconst struct net_offload *ops;\r\nstruct sk_buff *segs = ERR_PTR(-EINVAL);\r\nstruct sk_buff *(*gso_inner_segment)(struct sk_buff *skb,\r\nnetdev_features_t features);\r\nrcu_read_lock();\r\nswitch (skb->inner_protocol_type) {\r\ncase ENCAP_TYPE_ETHER:\r\nprotocol = skb->inner_protocol;\r\ngso_inner_segment = skb_mac_gso_segment;\r\nbreak;\r\ncase ENCAP_TYPE_IPPROTO:\r\noffloads = is_ipv6 ? inet6_offloads : inet_offloads;\r\nops = rcu_dereference(offloads[skb->inner_ipproto]);\r\nif (!ops || !ops->callbacks.gso_segment)\r\ngoto out_unlock;\r\ngso_inner_segment = ops->callbacks.gso_segment;\r\nbreak;\r\ndefault:\r\ngoto out_unlock;\r\n}\r\nsegs = __skb_udp_tunnel_segment(skb, features, gso_inner_segment,\r\nprotocol, is_ipv6);\r\nout_unlock:\r\nrcu_read_unlock();\r\nreturn segs;\r\n}\r\nstatic struct sk_buff *udp4_ufo_fragment(struct sk_buff *skb,\r\nnetdev_features_t features)\r\n{\r\nstruct sk_buff *segs = ERR_PTR(-EINVAL);\r\nunsigned int mss;\r\n__wsum csum;\r\nstruct udphdr *uh;\r\nstruct iphdr *iph;\r\nif (skb->encapsulation &&\r\n(skb_shinfo(skb)->gso_type &\r\n(SKB_GSO_UDP_TUNNEL|SKB_GSO_UDP_TUNNEL_CSUM))) {\r\nsegs = skb_udp_tunnel_segment(skb, features, false);\r\ngoto out;\r\n}\r\nif (!pskb_may_pull(skb, sizeof(struct udphdr)))\r\ngoto out;\r\nmss = skb_shinfo(skb)->gso_size;\r\nif (unlikely(skb->len <= mss))\r\ngoto out;\r\nif (skb_gso_ok(skb, features | NETIF_F_GSO_ROBUST)) {\r\nskb_shinfo(skb)->gso_segs = DIV_ROUND_UP(skb->len, mss);\r\nsegs = NULL;\r\ngoto out;\r\n}\r\nuh = udp_hdr(skb);\r\niph = ip_hdr(skb);\r\nuh->check = 0;\r\ncsum = skb_checksum(skb, 0, skb->len, 0);\r\nuh->check = udp_v4_check(skb->len, iph->saddr, iph->daddr, csum);\r\nif (uh->check == 0)\r\nuh->check = CSUM_MANGLED_0;\r\nskb->ip_summed = CHECKSUM_NONE;\r\nif (!skb->encap_hdr_csum)\r\nfeatures |= NETIF_F_HW_CSUM;\r\nsegs = skb_segment(skb, features);\r\nout:\r\nreturn segs;\r\n}\r\nstruct sk_buff **udp_gro_receive(struct sk_buff **head, struct sk_buff *skb,\r\nstruct udphdr *uh, udp_lookup_t lookup)\r\n{\r\nstruct sk_buff *p, **pp = NULL;\r\nstruct udphdr *uh2;\r\nunsigned int off = skb_gro_offset(skb);\r\nint flush = 1;\r\nstruct sock *sk;\r\nif (NAPI_GRO_CB(skb)->encap_mark ||\r\n(skb->ip_summed != CHECKSUM_PARTIAL &&\r\nNAPI_GRO_CB(skb)->csum_cnt == 0 &&\r\n!NAPI_GRO_CB(skb)->csum_valid))\r\ngoto out;\r\nNAPI_GRO_CB(skb)->encap_mark = 1;\r\nrcu_read_lock();\r\nsk = (*lookup)(skb, uh->source, uh->dest);\r\nif (sk && udp_sk(sk)->gro_receive)\r\ngoto unflush;\r\ngoto out_unlock;\r\nunflush:\r\nflush = 0;\r\nfor (p = *head; p; p = p->next) {\r\nif (!NAPI_GRO_CB(p)->same_flow)\r\ncontinue;\r\nuh2 = (struct udphdr *)(p->data + off);\r\nif ((*(u32 *)&uh->source != *(u32 *)&uh2->source) ||\r\n(!uh->check ^ !uh2->check)) {\r\nNAPI_GRO_CB(p)->same_flow = 0;\r\ncontinue;\r\n}\r\n}\r\nskb_gro_pull(skb, sizeof(struct udphdr));\r\nskb_gro_postpull_rcsum(skb, uh, sizeof(struct udphdr));\r\npp = udp_sk(sk)->gro_receive(sk, head, skb);\r\nout_unlock:\r\nrcu_read_unlock();\r\nout:\r\nNAPI_GRO_CB(skb)->flush |= flush;\r\nreturn pp;\r\n}\r\nstatic struct sk_buff **udp4_gro_receive(struct sk_buff **head,\r\nstruct sk_buff *skb)\r\n{\r\nstruct udphdr *uh = udp_gro_udphdr(skb);\r\nif (unlikely(!uh))\r\ngoto flush;\r\nif (NAPI_GRO_CB(skb)->flush)\r\ngoto skip;\r\nif (skb_gro_checksum_validate_zero_check(skb, IPPROTO_UDP, uh->check,\r\ninet_gro_compute_pseudo))\r\ngoto flush;\r\nelse if (uh->check)\r\nskb_gro_checksum_try_convert(skb, IPPROTO_UDP, uh->check,\r\ninet_gro_compute_pseudo);\r\nskip:\r\nNAPI_GRO_CB(skb)->is_ipv6 = 0;\r\nreturn udp_gro_receive(head, skb, uh, udp4_lib_lookup_skb);\r\nflush:\r\nNAPI_GRO_CB(skb)->flush = 1;\r\nreturn NULL;\r\n}\r\nint udp_gro_complete(struct sk_buff *skb, int nhoff,\r\nudp_lookup_t lookup)\r\n{\r\n__be16 newlen = htons(skb->len - nhoff);\r\nstruct udphdr *uh = (struct udphdr *)(skb->data + nhoff);\r\nint err = -ENOSYS;\r\nstruct sock *sk;\r\nuh->len = newlen;\r\nskb->encapsulation = 1;\r\nrcu_read_lock();\r\nsk = (*lookup)(skb, uh->source, uh->dest);\r\nif (sk && udp_sk(sk)->gro_complete)\r\nerr = udp_sk(sk)->gro_complete(sk, skb,\r\nnhoff + sizeof(struct udphdr));\r\nrcu_read_unlock();\r\nif (skb->remcsum_offload)\r\nskb_shinfo(skb)->gso_type |= SKB_GSO_TUNNEL_REMCSUM;\r\nreturn err;\r\n}\r\nstatic int udp4_gro_complete(struct sk_buff *skb, int nhoff)\r\n{\r\nconst struct iphdr *iph = ip_hdr(skb);\r\nstruct udphdr *uh = (struct udphdr *)(skb->data + nhoff);\r\nif (uh->check) {\r\nskb_shinfo(skb)->gso_type |= SKB_GSO_UDP_TUNNEL_CSUM;\r\nuh->check = ~udp_v4_check(skb->len - nhoff, iph->saddr,\r\niph->daddr, 0);\r\n} else {\r\nskb_shinfo(skb)->gso_type |= SKB_GSO_UDP_TUNNEL;\r\n}\r\nreturn udp_gro_complete(skb, nhoff, udp4_lib_lookup_skb);\r\n}\r\nint __init udpv4_offload_init(void)\r\n{\r\nreturn inet_add_offload(&udpv4_offload, IPPROTO_UDP);\r\n}
