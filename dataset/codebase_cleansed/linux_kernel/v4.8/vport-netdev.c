static void netdev_port_receive(struct sk_buff *skb)\r\n{\r\nstruct vport *vport;\r\nvport = ovs_netdev_get_vport(skb->dev);\r\nif (unlikely(!vport))\r\ngoto error;\r\nif (unlikely(skb_warn_if_lro(skb)))\r\ngoto error;\r\nskb = skb_share_check(skb, GFP_ATOMIC);\r\nif (unlikely(!skb))\r\nreturn;\r\nskb_push(skb, ETH_HLEN);\r\nskb_postpush_rcsum(skb, skb->data, ETH_HLEN);\r\novs_vport_receive(vport, skb, skb_tunnel_info(skb));\r\nreturn;\r\nerror:\r\nkfree_skb(skb);\r\n}\r\nstatic rx_handler_result_t netdev_frame_hook(struct sk_buff **pskb)\r\n{\r\nstruct sk_buff *skb = *pskb;\r\nif (unlikely(skb->pkt_type == PACKET_LOOPBACK))\r\nreturn RX_HANDLER_PASS;\r\nnetdev_port_receive(skb);\r\nreturn RX_HANDLER_CONSUMED;\r\n}\r\nstatic struct net_device *get_dpdev(const struct datapath *dp)\r\n{\r\nstruct vport *local;\r\nlocal = ovs_vport_ovsl(dp, OVSP_LOCAL);\r\nBUG_ON(!local);\r\nreturn local->dev;\r\n}\r\nstruct vport *ovs_netdev_link(struct vport *vport, const char *name)\r\n{\r\nint err;\r\nvport->dev = dev_get_by_name(ovs_dp_get_net(vport->dp), name);\r\nif (!vport->dev) {\r\nerr = -ENODEV;\r\ngoto error_free_vport;\r\n}\r\nif (vport->dev->flags & IFF_LOOPBACK ||\r\nvport->dev->type != ARPHRD_ETHER ||\r\novs_is_internal_dev(vport->dev)) {\r\nerr = -EINVAL;\r\ngoto error_put;\r\n}\r\nrtnl_lock();\r\nerr = netdev_master_upper_dev_link(vport->dev,\r\nget_dpdev(vport->dp), NULL, NULL);\r\nif (err)\r\ngoto error_unlock;\r\nerr = netdev_rx_handler_register(vport->dev, netdev_frame_hook,\r\nvport);\r\nif (err)\r\ngoto error_master_upper_dev_unlink;\r\ndev_disable_lro(vport->dev);\r\ndev_set_promiscuity(vport->dev, 1);\r\nvport->dev->priv_flags |= IFF_OVS_DATAPATH;\r\nrtnl_unlock();\r\nreturn vport;\r\nerror_master_upper_dev_unlink:\r\nnetdev_upper_dev_unlink(vport->dev, get_dpdev(vport->dp));\r\nerror_unlock:\r\nrtnl_unlock();\r\nerror_put:\r\ndev_put(vport->dev);\r\nerror_free_vport:\r\novs_vport_free(vport);\r\nreturn ERR_PTR(err);\r\n}\r\nstatic struct vport *netdev_create(const struct vport_parms *parms)\r\n{\r\nstruct vport *vport;\r\nvport = ovs_vport_alloc(0, &ovs_netdev_vport_ops, parms);\r\nif (IS_ERR(vport))\r\nreturn vport;\r\nreturn ovs_netdev_link(vport, parms->name);\r\n}\r\nstatic void vport_netdev_free(struct rcu_head *rcu)\r\n{\r\nstruct vport *vport = container_of(rcu, struct vport, rcu);\r\nif (vport->dev)\r\ndev_put(vport->dev);\r\novs_vport_free(vport);\r\n}\r\nvoid ovs_netdev_detach_dev(struct vport *vport)\r\n{\r\nASSERT_RTNL();\r\nvport->dev->priv_flags &= ~IFF_OVS_DATAPATH;\r\nnetdev_rx_handler_unregister(vport->dev);\r\nnetdev_upper_dev_unlink(vport->dev,\r\nnetdev_master_upper_dev_get(vport->dev));\r\ndev_set_promiscuity(vport->dev, -1);\r\n}\r\nstatic void netdev_destroy(struct vport *vport)\r\n{\r\nrtnl_lock();\r\nif (vport->dev->priv_flags & IFF_OVS_DATAPATH)\r\novs_netdev_detach_dev(vport);\r\nrtnl_unlock();\r\ncall_rcu(&vport->rcu, vport_netdev_free);\r\n}\r\nvoid ovs_netdev_tunnel_destroy(struct vport *vport)\r\n{\r\nrtnl_lock();\r\nif (vport->dev->priv_flags & IFF_OVS_DATAPATH)\r\novs_netdev_detach_dev(vport);\r\nif (vport->dev->reg_state == NETREG_REGISTERED)\r\nrtnl_delete_link(vport->dev);\r\ndev_put(vport->dev);\r\nvport->dev = NULL;\r\nrtnl_unlock();\r\ncall_rcu(&vport->rcu, vport_netdev_free);\r\n}\r\nstruct vport *ovs_netdev_get_vport(struct net_device *dev)\r\n{\r\nif (likely(dev->priv_flags & IFF_OVS_DATAPATH))\r\nreturn (struct vport *)\r\nrcu_dereference_rtnl(dev->rx_handler_data);\r\nelse\r\nreturn NULL;\r\n}\r\nint __init ovs_netdev_init(void)\r\n{\r\nreturn ovs_vport_ops_register(&ovs_netdev_vport_ops);\r\n}\r\nvoid ovs_netdev_exit(void)\r\n{\r\novs_vport_ops_unregister(&ovs_netdev_vport_ops);\r\n}
