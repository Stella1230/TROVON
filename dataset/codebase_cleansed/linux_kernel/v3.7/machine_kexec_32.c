static void set_idt(void *newidt, __u16 limit)\r\n{\r\nstruct desc_ptr curidt;\r\ncuridt.size = limit;\r\ncuridt.address = (unsigned long)newidt;\r\nload_idt(&curidt);\r\n}\r\nstatic void set_gdt(void *newgdt, __u16 limit)\r\n{\r\nstruct desc_ptr curgdt;\r\ncurgdt.size = limit;\r\ncurgdt.address = (unsigned long)newgdt;\r\nload_gdt(&curgdt);\r\n}\r\nstatic void load_segments(void)\r\n{\r\n#define __STR(X) #X\r\n#define STR(X) __STR(X)\r\n__asm__ __volatile__ (\r\n"\tljmp $"STR(__KERNEL_CS)",$1f\n"\r\n"\t1:\n"\r\n"\tmovl $"STR(__KERNEL_DS)",%%eax\n"\r\n"\tmovl %%eax,%%ds\n"\r\n"\tmovl %%eax,%%es\n"\r\n"\tmovl %%eax,%%fs\n"\r\n"\tmovl %%eax,%%gs\n"\r\n"\tmovl %%eax,%%ss\n"\r\n: : : "eax", "memory");\r\n#undef STR\r\n#undef __STR\r\n}\r\nstatic void machine_kexec_free_page_tables(struct kimage *image)\r\n{\r\nfree_page((unsigned long)image->arch.pgd);\r\n#ifdef CONFIG_X86_PAE\r\nfree_page((unsigned long)image->arch.pmd0);\r\nfree_page((unsigned long)image->arch.pmd1);\r\n#endif\r\nfree_page((unsigned long)image->arch.pte0);\r\nfree_page((unsigned long)image->arch.pte1);\r\n}\r\nstatic int machine_kexec_alloc_page_tables(struct kimage *image)\r\n{\r\nimage->arch.pgd = (pgd_t *)get_zeroed_page(GFP_KERNEL);\r\n#ifdef CONFIG_X86_PAE\r\nimage->arch.pmd0 = (pmd_t *)get_zeroed_page(GFP_KERNEL);\r\nimage->arch.pmd1 = (pmd_t *)get_zeroed_page(GFP_KERNEL);\r\n#endif\r\nimage->arch.pte0 = (pte_t *)get_zeroed_page(GFP_KERNEL);\r\nimage->arch.pte1 = (pte_t *)get_zeroed_page(GFP_KERNEL);\r\nif (!image->arch.pgd ||\r\n#ifdef CONFIG_X86_PAE\r\n!image->arch.pmd0 || !image->arch.pmd1 ||\r\n#endif\r\n!image->arch.pte0 || !image->arch.pte1) {\r\nmachine_kexec_free_page_tables(image);\r\nreturn -ENOMEM;\r\n}\r\nreturn 0;\r\n}\r\nstatic void machine_kexec_page_table_set_one(\r\npgd_t *pgd, pmd_t *pmd, pte_t *pte,\r\nunsigned long vaddr, unsigned long paddr)\r\n{\r\npud_t *pud;\r\npgd += pgd_index(vaddr);\r\n#ifdef CONFIG_X86_PAE\r\nif (!(pgd_val(*pgd) & _PAGE_PRESENT))\r\nset_pgd(pgd, __pgd(__pa(pmd) | _PAGE_PRESENT));\r\n#endif\r\npud = pud_offset(pgd, vaddr);\r\npmd = pmd_offset(pud, vaddr);\r\nif (!(pmd_val(*pmd) & _PAGE_PRESENT))\r\nset_pmd(pmd, __pmd(__pa(pte) | _PAGE_TABLE));\r\npte = pte_offset_kernel(pmd, vaddr);\r\nset_pte(pte, pfn_pte(paddr >> PAGE_SHIFT, PAGE_KERNEL_EXEC));\r\n}\r\nstatic void machine_kexec_prepare_page_tables(struct kimage *image)\r\n{\r\nvoid *control_page;\r\npmd_t *pmd = NULL;\r\ncontrol_page = page_address(image->control_code_page);\r\n#ifdef CONFIG_X86_PAE\r\npmd = image->arch.pmd0;\r\n#endif\r\nmachine_kexec_page_table_set_one(\r\nimage->arch.pgd, pmd, image->arch.pte0,\r\n(unsigned long)control_page, __pa(control_page));\r\n#ifdef CONFIG_X86_PAE\r\npmd = image->arch.pmd1;\r\n#endif\r\nmachine_kexec_page_table_set_one(\r\nimage->arch.pgd, pmd, image->arch.pte1,\r\n__pa(control_page), __pa(control_page));\r\n}\r\nint machine_kexec_prepare(struct kimage *image)\r\n{\r\nint error;\r\nset_pages_x(image->control_code_page, 1);\r\nerror = machine_kexec_alloc_page_tables(image);\r\nif (error)\r\nreturn error;\r\nmachine_kexec_prepare_page_tables(image);\r\nreturn 0;\r\n}\r\nvoid machine_kexec_cleanup(struct kimage *image)\r\n{\r\nset_pages_nx(image->control_code_page, 1);\r\nmachine_kexec_free_page_tables(image);\r\n}\r\nvoid machine_kexec(struct kimage *image)\r\n{\r\nunsigned long page_list[PAGES_NR];\r\nvoid *control_page;\r\nint save_ftrace_enabled;\r\nasmlinkage unsigned long\r\n(*relocate_kernel_ptr)(unsigned long indirection_page,\r\nunsigned long control_page,\r\nunsigned long start_address,\r\nunsigned int has_pae,\r\nunsigned int preserve_context);\r\n#ifdef CONFIG_KEXEC_JUMP\r\nif (image->preserve_context)\r\nsave_processor_state();\r\n#endif\r\nsave_ftrace_enabled = __ftrace_enabled_save();\r\nlocal_irq_disable();\r\nhw_breakpoint_disable();\r\nif (image->preserve_context) {\r\n#ifdef CONFIG_X86_IO_APIC\r\ndisable_IO_APIC();\r\n#endif\r\n}\r\ncontrol_page = page_address(image->control_code_page);\r\nmemcpy(control_page, relocate_kernel, KEXEC_CONTROL_CODE_MAX_SIZE);\r\nrelocate_kernel_ptr = control_page;\r\npage_list[PA_CONTROL_PAGE] = __pa(control_page);\r\npage_list[VA_CONTROL_PAGE] = (unsigned long)control_page;\r\npage_list[PA_PGD] = __pa(image->arch.pgd);\r\nif (image->type == KEXEC_TYPE_DEFAULT)\r\npage_list[PA_SWAP_PAGE] = (page_to_pfn(image->swap_page)\r\n<< PAGE_SHIFT);\r\nload_segments();\r\nset_gdt(phys_to_virt(0), 0);\r\nset_idt(phys_to_virt(0), 0);\r\nimage->start = relocate_kernel_ptr((unsigned long)image->head,\r\n(unsigned long)page_list,\r\nimage->start, cpu_has_pae,\r\nimage->preserve_context);\r\n#ifdef CONFIG_KEXEC_JUMP\r\nif (image->preserve_context)\r\nrestore_processor_state();\r\n#endif\r\n__ftrace_enabled_restore(save_ftrace_enabled);\r\n}\r\nvoid arch_crash_save_vmcoreinfo(void)\r\n{\r\n#ifdef CONFIG_NUMA\r\nVMCOREINFO_SYMBOL(node_data);\r\nVMCOREINFO_LENGTH(node_data, MAX_NUMNODES);\r\n#endif\r\n#ifdef CONFIG_X86_PAE\r\nVMCOREINFO_CONFIG(X86_PAE);\r\n#endif\r\n}
