static inline void\r\ndbdma_st32(volatile __u32 __iomem *a, unsigned long x)\r\n{\r\n__asm__ volatile( "stwbrx %0,0,%1" : : "r" (x), "r" (a) : "memory");\r\n}\r\nstatic inline unsigned long\r\ndbdma_ld32(volatile __u32 __iomem *a)\r\n{\r\n__u32 swap;\r\n__asm__ volatile ("lwbrx %0,0,%1" : "=r" (swap) : "r" (a));\r\nreturn swap;\r\n}\r\nstatic void\r\ndbdma_continue(volatile struct dbdma_regs __iomem *dmap)\r\n{\r\ndbdma_st32(&dmap->control,\r\nDBDMA_SET(RUN|WAKE) | DBDMA_CLEAR(PAUSE|DEAD));\r\neieio();\r\n}\r\nstatic void\r\ndbdma_reset(volatile struct dbdma_regs __iomem *dmap)\r\n{\r\ndbdma_st32(&dmap->control,\r\nDBDMA_CLEAR(ACTIVE|DEAD|WAKE|FLUSH|PAUSE|RUN));\r\neieio();\r\nwhile (dbdma_ld32(&dmap->status) & RUN)\r\neieio();\r\n}\r\nstatic void\r\ndbdma_setcmd(volatile struct dbdma_cmd *cp,\r\nunsigned short cmd, unsigned count, unsigned long addr,\r\nunsigned long cmd_dep)\r\n{\r\nout_le16(&cp->command, cmd);\r\nout_le16(&cp->req_count, count);\r\nout_le32(&cp->phy_addr, addr);\r\nout_le32(&cp->cmd_dep, cmd_dep);\r\nout_le16(&cp->xfer_status, 0);\r\nout_le16(&cp->res_count, 0);\r\n}\r\nstatic inline\r\nvoid bmwrite(struct net_device *dev, unsigned long reg_offset, unsigned data )\r\n{\r\nout_le16((void __iomem *)dev->base_addr + reg_offset, data);\r\n}\r\nstatic inline\r\nunsigned short bmread(struct net_device *dev, unsigned long reg_offset )\r\n{\r\nreturn in_le16((void __iomem *)dev->base_addr + reg_offset);\r\n}\r\nstatic void\r\nbmac_enable_and_reset_chip(struct net_device *dev)\r\n{\r\nstruct bmac_data *bp = netdev_priv(dev);\r\nvolatile struct dbdma_regs __iomem *rd = bp->rx_dma;\r\nvolatile struct dbdma_regs __iomem *td = bp->tx_dma;\r\nif (rd)\r\ndbdma_reset(rd);\r\nif (td)\r\ndbdma_reset(td);\r\npmac_call_feature(PMAC_FTR_BMAC_ENABLE, macio_get_of_node(bp->mdev), 0, 1);\r\n}\r\nstatic unsigned int\r\nbmac_mif_readbits(struct net_device *dev, int nb)\r\n{\r\nunsigned int val = 0;\r\nwhile (--nb >= 0) {\r\nbmwrite(dev, MIFCSR, 0);\r\nMIFDELAY;\r\nif (bmread(dev, MIFCSR) & 8)\r\nval |= 1 << nb;\r\nbmwrite(dev, MIFCSR, 1);\r\nMIFDELAY;\r\n}\r\nbmwrite(dev, MIFCSR, 0);\r\nMIFDELAY;\r\nbmwrite(dev, MIFCSR, 1);\r\nMIFDELAY;\r\nreturn val;\r\n}\r\nstatic void\r\nbmac_mif_writebits(struct net_device *dev, unsigned int val, int nb)\r\n{\r\nint b;\r\nwhile (--nb >= 0) {\r\nb = (val & (1 << nb))? 6: 4;\r\nbmwrite(dev, MIFCSR, b);\r\nMIFDELAY;\r\nbmwrite(dev, MIFCSR, b|1);\r\nMIFDELAY;\r\n}\r\n}\r\nstatic unsigned int\r\nbmac_mif_read(struct net_device *dev, unsigned int addr)\r\n{\r\nunsigned int val;\r\nbmwrite(dev, MIFCSR, 4);\r\nMIFDELAY;\r\nbmac_mif_writebits(dev, ~0U, 32);\r\nbmac_mif_writebits(dev, 6, 4);\r\nbmac_mif_writebits(dev, addr, 10);\r\nbmwrite(dev, MIFCSR, 2);\r\nMIFDELAY;\r\nbmwrite(dev, MIFCSR, 1);\r\nMIFDELAY;\r\nval = bmac_mif_readbits(dev, 17);\r\nbmwrite(dev, MIFCSR, 4);\r\nMIFDELAY;\r\nreturn val;\r\n}\r\nstatic void\r\nbmac_mif_write(struct net_device *dev, unsigned int addr, unsigned int val)\r\n{\r\nbmwrite(dev, MIFCSR, 4);\r\nMIFDELAY;\r\nbmac_mif_writebits(dev, ~0U, 32);\r\nbmac_mif_writebits(dev, 5, 4);\r\nbmac_mif_writebits(dev, addr, 10);\r\nbmac_mif_writebits(dev, 2, 2);\r\nbmac_mif_writebits(dev, val, 16);\r\nbmac_mif_writebits(dev, 3, 2);\r\n}\r\nstatic void\r\nbmac_init_registers(struct net_device *dev)\r\n{\r\nstruct bmac_data *bp = netdev_priv(dev);\r\nvolatile unsigned short regValue;\r\nunsigned short *pWord16;\r\nint i;\r\nbmwrite(dev, RXRST, RxResetValue);\r\nbmwrite(dev, TXRST, TxResetBit);\r\ni = 100;\r\ndo {\r\n--i;\r\nudelay(10000);\r\nregValue = bmread(dev, TXRST);\r\n} while ((regValue & TxResetBit) && i > 0);\r\nif (!bp->is_bmac_plus) {\r\nregValue = bmread(dev, XCVRIF);\r\nregValue |= ClkBit | SerialMode | COLActiveLow;\r\nbmwrite(dev, XCVRIF, regValue);\r\nudelay(10000);\r\n}\r\nbmwrite(dev, RSEED, (unsigned short)0x1968);\r\nregValue = bmread(dev, XIFC);\r\nregValue |= TxOutputEnable;\r\nbmwrite(dev, XIFC, regValue);\r\nbmread(dev, PAREG);\r\nbmwrite(dev, NCCNT, 0);\r\nbmwrite(dev, NTCNT, 0);\r\nbmwrite(dev, EXCNT, 0);\r\nbmwrite(dev, LTCNT, 0);\r\nbmwrite(dev, FRCNT, 0);\r\nbmwrite(dev, LECNT, 0);\r\nbmwrite(dev, AECNT, 0);\r\nbmwrite(dev, FECNT, 0);\r\nbmwrite(dev, RXCV, 0);\r\nbmwrite(dev, TXTH, 4);\r\nbmwrite(dev, TXFIFOCSR, 0);\r\nbmwrite(dev, TXFIFOCSR, TxFIFOEnable );\r\nbmwrite(dev, RXFIFOCSR, 0);\r\nbmwrite(dev, RXFIFOCSR, RxFIFOEnable );\r\nbmread(dev, STATUS);\r\nfor (i=0; i<4; i++) bp->hash_table_mask[i] = 0;\r\nbmwrite(dev, BHASH3, bp->hash_table_mask[0]);\r\nbmwrite(dev, BHASH2, bp->hash_table_mask[1]);\r\nbmwrite(dev, BHASH1, bp->hash_table_mask[2]);\r\nbmwrite(dev, BHASH0, bp->hash_table_mask[3]);\r\npWord16 = (unsigned short *)dev->dev_addr;\r\nbmwrite(dev, MADD0, *pWord16++);\r\nbmwrite(dev, MADD1, *pWord16++);\r\nbmwrite(dev, MADD2, *pWord16);\r\nbmwrite(dev, RXCFG, RxCRCNoStrip | RxHashFilterEnable | RxRejectOwnPackets);\r\nbmwrite(dev, INTDISABLE, EnableNormal);\r\n}\r\nstatic void\r\nbmac_start_chip(struct net_device *dev)\r\n{\r\nstruct bmac_data *bp = netdev_priv(dev);\r\nvolatile struct dbdma_regs __iomem *rd = bp->rx_dma;\r\nunsigned short oldConfig;\r\ndbdma_continue(rd);\r\noldConfig = bmread(dev, TXCFG);\r\nbmwrite(dev, TXCFG, oldConfig | TxMACEnable );\r\noldConfig = bmread(dev, RXCFG);\r\nbmwrite(dev, RXCFG, oldConfig | RxMACEnable );\r\nudelay(20000);\r\n}\r\nstatic void\r\nbmac_init_phy(struct net_device *dev)\r\n{\r\nunsigned int addr;\r\nstruct bmac_data *bp = netdev_priv(dev);\r\nprintk(KERN_DEBUG "phy registers:");\r\nfor (addr = 0; addr < 32; ++addr) {\r\nif ((addr & 7) == 0)\r\nprintk(KERN_DEBUG);\r\nprintk(KERN_CONT " %.4x", bmac_mif_read(dev, addr));\r\n}\r\nprintk(KERN_CONT "\n");\r\nif (bp->is_bmac_plus) {\r\nunsigned int capable, ctrl;\r\nctrl = bmac_mif_read(dev, 0);\r\ncapable = ((bmac_mif_read(dev, 1) & 0xf800) >> 6) | 1;\r\nif (bmac_mif_read(dev, 4) != capable ||\r\n(ctrl & 0x1000) == 0) {\r\nbmac_mif_write(dev, 4, capable);\r\nbmac_mif_write(dev, 0, 0x1200);\r\n} else\r\nbmac_mif_write(dev, 0, 0x1000);\r\n}\r\n}\r\nstatic void bmac_init_chip(struct net_device *dev)\r\n{\r\nbmac_init_phy(dev);\r\nbmac_init_registers(dev);\r\n}\r\nstatic int bmac_suspend(struct macio_dev *mdev, pm_message_t state)\r\n{\r\nstruct net_device* dev = macio_get_drvdata(mdev);\r\nstruct bmac_data *bp = netdev_priv(dev);\r\nunsigned long flags;\r\nunsigned short config;\r\nint i;\r\nnetif_device_detach(dev);\r\nspin_lock_irqsave(&bp->lock, flags);\r\nif (bp->timeout_active) {\r\ndel_timer(&bp->tx_timeout);\r\nbp->timeout_active = 0;\r\n}\r\ndisable_irq(dev->irq);\r\ndisable_irq(bp->tx_dma_intr);\r\ndisable_irq(bp->rx_dma_intr);\r\nbp->sleeping = 1;\r\nspin_unlock_irqrestore(&bp->lock, flags);\r\nif (bp->opened) {\r\nvolatile struct dbdma_regs __iomem *rd = bp->rx_dma;\r\nvolatile struct dbdma_regs __iomem *td = bp->tx_dma;\r\nconfig = bmread(dev, RXCFG);\r\nbmwrite(dev, RXCFG, (config & ~RxMACEnable));\r\nconfig = bmread(dev, TXCFG);\r\nbmwrite(dev, TXCFG, (config & ~TxMACEnable));\r\nbmwrite(dev, INTDISABLE, DisableAll);\r\nst_le32(&rd->control, DBDMA_CLEAR(RUN|PAUSE|FLUSH|WAKE));\r\nst_le32(&td->control, DBDMA_CLEAR(RUN|PAUSE|FLUSH|WAKE));\r\nfor (i=0; i<N_RX_RING; i++) {\r\nif (bp->rx_bufs[i] != NULL) {\r\ndev_kfree_skb(bp->rx_bufs[i]);\r\nbp->rx_bufs[i] = NULL;\r\n}\r\n}\r\nfor (i = 0; i<N_TX_RING; i++) {\r\nif (bp->tx_bufs[i] != NULL) {\r\ndev_kfree_skb(bp->tx_bufs[i]);\r\nbp->tx_bufs[i] = NULL;\r\n}\r\n}\r\n}\r\npmac_call_feature(PMAC_FTR_BMAC_ENABLE, macio_get_of_node(bp->mdev), 0, 0);\r\nreturn 0;\r\n}\r\nstatic int bmac_resume(struct macio_dev *mdev)\r\n{\r\nstruct net_device* dev = macio_get_drvdata(mdev);\r\nstruct bmac_data *bp = netdev_priv(dev);\r\nif (bp->opened)\r\nbmac_reset_and_enable(dev);\r\nenable_irq(dev->irq);\r\nenable_irq(bp->tx_dma_intr);\r\nenable_irq(bp->rx_dma_intr);\r\nnetif_device_attach(dev);\r\nreturn 0;\r\n}\r\nstatic int bmac_set_address(struct net_device *dev, void *addr)\r\n{\r\nstruct bmac_data *bp = netdev_priv(dev);\r\nunsigned char *p = addr;\r\nunsigned short *pWord16;\r\nunsigned long flags;\r\nint i;\r\nXXDEBUG(("bmac: enter set_address\n"));\r\nspin_lock_irqsave(&bp->lock, flags);\r\nfor (i = 0; i < 6; ++i) {\r\ndev->dev_addr[i] = p[i];\r\n}\r\npWord16 = (unsigned short *)dev->dev_addr;\r\nbmwrite(dev, MADD0, *pWord16++);\r\nbmwrite(dev, MADD1, *pWord16++);\r\nbmwrite(dev, MADD2, *pWord16);\r\nspin_unlock_irqrestore(&bp->lock, flags);\r\nXXDEBUG(("bmac: exit set_address\n"));\r\nreturn 0;\r\n}\r\nstatic inline void bmac_set_timeout(struct net_device *dev)\r\n{\r\nstruct bmac_data *bp = netdev_priv(dev);\r\nunsigned long flags;\r\nspin_lock_irqsave(&bp->lock, flags);\r\nif (bp->timeout_active)\r\ndel_timer(&bp->tx_timeout);\r\nbp->tx_timeout.expires = jiffies + TX_TIMEOUT;\r\nbp->tx_timeout.function = bmac_tx_timeout;\r\nbp->tx_timeout.data = (unsigned long) dev;\r\nadd_timer(&bp->tx_timeout);\r\nbp->timeout_active = 1;\r\nspin_unlock_irqrestore(&bp->lock, flags);\r\n}\r\nstatic void\r\nbmac_construct_xmt(struct sk_buff *skb, volatile struct dbdma_cmd *cp)\r\n{\r\nvoid *vaddr;\r\nunsigned long baddr;\r\nunsigned long len;\r\nlen = skb->len;\r\nvaddr = skb->data;\r\nbaddr = virt_to_bus(vaddr);\r\ndbdma_setcmd(cp, (OUTPUT_LAST | INTR_ALWAYS | WAIT_IFCLR), len, baddr, 0);\r\n}\r\nstatic void\r\nbmac_construct_rxbuff(struct sk_buff *skb, volatile struct dbdma_cmd *cp)\r\n{\r\nunsigned char *addr = skb? skb->data: bmac_emergency_rxbuf;\r\ndbdma_setcmd(cp, (INPUT_LAST | INTR_ALWAYS), RX_BUFLEN,\r\nvirt_to_bus(addr), 0);\r\n}\r\nstatic void\r\nbmac_init_tx_ring(struct bmac_data *bp)\r\n{\r\nvolatile struct dbdma_regs __iomem *td = bp->tx_dma;\r\nmemset((char *)bp->tx_cmds, 0, (N_TX_RING+1) * sizeof(struct dbdma_cmd));\r\nbp->tx_empty = 0;\r\nbp->tx_fill = 0;\r\nbp->tx_fullup = 0;\r\ndbdma_setcmd(&bp->tx_cmds[N_TX_RING],\r\n(DBDMA_NOP | BR_ALWAYS), 0, 0, virt_to_bus(bp->tx_cmds));\r\ndbdma_reset(td);\r\nout_le32(&td->wait_sel, 0x00200020);\r\nout_le32(&td->cmdptr, virt_to_bus(bp->tx_cmds));\r\n}\r\nstatic int\r\nbmac_init_rx_ring(struct net_device *dev)\r\n{\r\nstruct bmac_data *bp = netdev_priv(dev);\r\nvolatile struct dbdma_regs __iomem *rd = bp->rx_dma;\r\nint i;\r\nstruct sk_buff *skb;\r\nmemset((char *)bp->rx_cmds, 0,\r\n(N_RX_RING + 1) * sizeof(struct dbdma_cmd));\r\nfor (i = 0; i < N_RX_RING; i++) {\r\nif ((skb = bp->rx_bufs[i]) == NULL) {\r\nbp->rx_bufs[i] = skb = netdev_alloc_skb(dev, RX_BUFLEN + 2);\r\nif (skb != NULL)\r\nskb_reserve(skb, 2);\r\n}\r\nbmac_construct_rxbuff(skb, &bp->rx_cmds[i]);\r\n}\r\nbp->rx_empty = 0;\r\nbp->rx_fill = i;\r\ndbdma_setcmd(&bp->rx_cmds[N_RX_RING],\r\n(DBDMA_NOP | BR_ALWAYS), 0, 0, virt_to_bus(bp->rx_cmds));\r\ndbdma_reset(rd);\r\nout_le32(&rd->cmdptr, virt_to_bus(bp->rx_cmds));\r\nreturn 1;\r\n}\r\nstatic int bmac_transmit_packet(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct bmac_data *bp = netdev_priv(dev);\r\nvolatile struct dbdma_regs __iomem *td = bp->tx_dma;\r\nint i;\r\ni = bp->tx_fill + 1;\r\nif (i >= N_TX_RING)\r\ni = 0;\r\nif (i == bp->tx_empty) {\r\nnetif_stop_queue(dev);\r\nbp->tx_fullup = 1;\r\nXXDEBUG(("bmac_transmit_packet: tx ring full\n"));\r\nreturn -1;\r\n}\r\ndbdma_setcmd(&bp->tx_cmds[i], DBDMA_STOP, 0, 0, 0);\r\nbmac_construct_xmt(skb, &bp->tx_cmds[bp->tx_fill]);\r\nbp->tx_bufs[bp->tx_fill] = skb;\r\nbp->tx_fill = i;\r\ndev->stats.tx_bytes += skb->len;\r\ndbdma_continue(td);\r\nreturn 0;\r\n}\r\nstatic irqreturn_t bmac_rxdma_intr(int irq, void *dev_id)\r\n{\r\nstruct net_device *dev = (struct net_device *) dev_id;\r\nstruct bmac_data *bp = netdev_priv(dev);\r\nvolatile struct dbdma_regs __iomem *rd = bp->rx_dma;\r\nvolatile struct dbdma_cmd *cp;\r\nint i, nb, stat;\r\nstruct sk_buff *skb;\r\nunsigned int residual;\r\nint last;\r\nunsigned long flags;\r\nspin_lock_irqsave(&bp->lock, flags);\r\nif (++rxintcount < 10) {\r\nXXDEBUG(("bmac_rxdma_intr\n"));\r\n}\r\nlast = -1;\r\ni = bp->rx_empty;\r\nwhile (1) {\r\ncp = &bp->rx_cmds[i];\r\nstat = ld_le16(&cp->xfer_status);\r\nresidual = ld_le16(&cp->res_count);\r\nif ((stat & ACTIVE) == 0)\r\nbreak;\r\nnb = RX_BUFLEN - residual - 2;\r\nif (nb < (ETHERMINPACKET - ETHERCRC)) {\r\nskb = NULL;\r\ndev->stats.rx_length_errors++;\r\ndev->stats.rx_errors++;\r\n} else {\r\nskb = bp->rx_bufs[i];\r\nbp->rx_bufs[i] = NULL;\r\n}\r\nif (skb != NULL) {\r\nnb -= ETHERCRC;\r\nskb_put(skb, nb);\r\nskb->protocol = eth_type_trans(skb, dev);\r\nnetif_rx(skb);\r\n++dev->stats.rx_packets;\r\ndev->stats.rx_bytes += nb;\r\n} else {\r\n++dev->stats.rx_dropped;\r\n}\r\nif ((skb = bp->rx_bufs[i]) == NULL) {\r\nbp->rx_bufs[i] = skb = netdev_alloc_skb(dev, RX_BUFLEN + 2);\r\nif (skb != NULL)\r\nskb_reserve(bp->rx_bufs[i], 2);\r\n}\r\nbmac_construct_rxbuff(skb, &bp->rx_cmds[i]);\r\nst_le16(&cp->res_count, 0);\r\nst_le16(&cp->xfer_status, 0);\r\nlast = i;\r\nif (++i >= N_RX_RING) i = 0;\r\n}\r\nif (last != -1) {\r\nbp->rx_fill = last;\r\nbp->rx_empty = i;\r\n}\r\ndbdma_continue(rd);\r\nspin_unlock_irqrestore(&bp->lock, flags);\r\nif (rxintcount < 10) {\r\nXXDEBUG(("bmac_rxdma_intr done\n"));\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t bmac_txdma_intr(int irq, void *dev_id)\r\n{\r\nstruct net_device *dev = (struct net_device *) dev_id;\r\nstruct bmac_data *bp = netdev_priv(dev);\r\nvolatile struct dbdma_cmd *cp;\r\nint stat;\r\nunsigned long flags;\r\nspin_lock_irqsave(&bp->lock, flags);\r\nif (txintcount++ < 10) {\r\nXXDEBUG(("bmac_txdma_intr\n"));\r\n}\r\nwhile (1) {\r\ncp = &bp->tx_cmds[bp->tx_empty];\r\nstat = ld_le16(&cp->xfer_status);\r\nif (txintcount < 10) {\r\nXXDEBUG(("bmac_txdma_xfer_stat=%#0x\n", stat));\r\n}\r\nif (!(stat & ACTIVE)) {\r\nif (cp == bus_to_virt(in_le32(&bp->tx_dma->cmdptr)))\r\nbreak;\r\n}\r\nif (bp->tx_bufs[bp->tx_empty]) {\r\n++dev->stats.tx_packets;\r\ndev_kfree_skb_irq(bp->tx_bufs[bp->tx_empty]);\r\n}\r\nbp->tx_bufs[bp->tx_empty] = NULL;\r\nbp->tx_fullup = 0;\r\nnetif_wake_queue(dev);\r\nif (++bp->tx_empty >= N_TX_RING)\r\nbp->tx_empty = 0;\r\nif (bp->tx_empty == bp->tx_fill)\r\nbreak;\r\n}\r\nspin_unlock_irqrestore(&bp->lock, flags);\r\nif (txintcount < 10) {\r\nXXDEBUG(("bmac_txdma_intr done->bmac_start\n"));\r\n}\r\nbmac_start(dev);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic unsigned int\r\ncrc416(unsigned int curval, unsigned short nxtval)\r\n{\r\nregister unsigned int counter, cur = curval, next = nxtval;\r\nregister int high_crc_set, low_data_set;\r\nnext = ((next & 0x00FF) << 8) | (next >> 8);\r\nfor (counter = 0; counter < 16; ++counter) {\r\nif ((cur & 0x80000000) == 0) high_crc_set = 0;\r\nelse high_crc_set = 1;\r\ncur = cur << 1;\r\nif ((next & 0x0001) == 0) low_data_set = 0;\r\nelse low_data_set = 1;\r\nnext = next >> 1;\r\nif (high_crc_set ^ low_data_set) cur = cur ^ ENET_CRCPOLY;\r\n}\r\nreturn cur;\r\n}\r\nstatic unsigned int\r\nbmac_crc(unsigned short *address)\r\n{\r\nunsigned int newcrc;\r\nXXDEBUG(("bmac_crc: addr=%#04x, %#04x, %#04x\n", *address, address[1], address[2]));\r\nnewcrc = crc416(0xffffffff, *address);\r\nnewcrc = crc416(newcrc, address[1]);\r\nnewcrc = crc416(newcrc, address[2]);\r\nreturn(newcrc);\r\n}\r\nstatic void\r\nbmac_addhash(struct bmac_data *bp, unsigned char *addr)\r\n{\r\nunsigned int crc;\r\nunsigned short mask;\r\nif (!(*addr)) return;\r\ncrc = bmac_crc((unsigned short *)addr) & 0x3f;\r\ncrc = reverse6[crc];\r\nif (bp->hash_use_count[crc]++) return;\r\nmask = crc % 16;\r\nmask = (unsigned char)1 << mask;\r\nbp->hash_use_count[crc/16] |= mask;\r\n}\r\nstatic void\r\nbmac_removehash(struct bmac_data *bp, unsigned char *addr)\r\n{\r\nunsigned int crc;\r\nunsigned char mask;\r\ncrc = bmac_crc((unsigned short *)addr) & 0x3f;\r\ncrc = reverse6[crc];\r\nif (bp->hash_use_count[crc] == 0) return;\r\nif (--bp->hash_use_count[crc]) return;\r\nmask = crc % 16;\r\nmask = ((unsigned char)1 << mask) ^ 0xffff;\r\nbp->hash_table_mask[crc/16] &= mask;\r\n}\r\nstatic void\r\nbmac_rx_off(struct net_device *dev)\r\n{\r\nunsigned short rx_cfg;\r\nrx_cfg = bmread(dev, RXCFG);\r\nrx_cfg &= ~RxMACEnable;\r\nbmwrite(dev, RXCFG, rx_cfg);\r\ndo {\r\nrx_cfg = bmread(dev, RXCFG);\r\n} while (rx_cfg & RxMACEnable);\r\n}\r\nunsigned short\r\nbmac_rx_on(struct net_device *dev, int hash_enable, int promisc_enable)\r\n{\r\nunsigned short rx_cfg;\r\nrx_cfg = bmread(dev, RXCFG);\r\nrx_cfg |= RxMACEnable;\r\nif (hash_enable) rx_cfg |= RxHashFilterEnable;\r\nelse rx_cfg &= ~RxHashFilterEnable;\r\nif (promisc_enable) rx_cfg |= RxPromiscEnable;\r\nelse rx_cfg &= ~RxPromiscEnable;\r\nbmwrite(dev, RXRST, RxResetValue);\r\nbmwrite(dev, RXFIFOCSR, 0);\r\nbmwrite(dev, RXFIFOCSR, RxFIFOEnable );\r\nbmwrite(dev, RXCFG, rx_cfg );\r\nreturn rx_cfg;\r\n}\r\nstatic void\r\nbmac_update_hash_table_mask(struct net_device *dev, struct bmac_data *bp)\r\n{\r\nbmwrite(dev, BHASH3, bp->hash_table_mask[0]);\r\nbmwrite(dev, BHASH2, bp->hash_table_mask[1]);\r\nbmwrite(dev, BHASH1, bp->hash_table_mask[2]);\r\nbmwrite(dev, BHASH0, bp->hash_table_mask[3]);\r\n}\r\nstatic void bmac_set_multicast(struct net_device *dev)\r\n{\r\nstruct netdev_hw_addr *ha;\r\nstruct bmac_data *bp = netdev_priv(dev);\r\nint num_addrs = netdev_mc_count(dev);\r\nunsigned short rx_cfg;\r\nint i;\r\nif (bp->sleeping)\r\nreturn;\r\nXXDEBUG(("bmac: enter bmac_set_multicast, n_addrs=%d\n", num_addrs));\r\nif((dev->flags & IFF_ALLMULTI) || (netdev_mc_count(dev) > 64)) {\r\nfor (i=0; i<4; i++) bp->hash_table_mask[i] = 0xffff;\r\nbmac_update_hash_table_mask(dev, bp);\r\nrx_cfg = bmac_rx_on(dev, 1, 0);\r\nXXDEBUG(("bmac: all multi, rx_cfg=%#08x\n"));\r\n} else if ((dev->flags & IFF_PROMISC) || (num_addrs < 0)) {\r\nrx_cfg = bmread(dev, RXCFG);\r\nrx_cfg |= RxPromiscEnable;\r\nbmwrite(dev, RXCFG, rx_cfg);\r\nrx_cfg = bmac_rx_on(dev, 0, 1);\r\nXXDEBUG(("bmac: promisc mode enabled, rx_cfg=%#08x\n", rx_cfg));\r\n} else {\r\nfor (i=0; i<4; i++) bp->hash_table_mask[i] = 0;\r\nfor (i=0; i<64; i++) bp->hash_use_count[i] = 0;\r\nif (num_addrs == 0) {\r\nrx_cfg = bmac_rx_on(dev, 0, 0);\r\nXXDEBUG(("bmac: multi disabled, rx_cfg=%#08x\n", rx_cfg));\r\n} else {\r\nnetdev_for_each_mc_addr(ha, dev)\r\nbmac_addhash(bp, ha->addr);\r\nbmac_update_hash_table_mask(dev, bp);\r\nrx_cfg = bmac_rx_on(dev, 1, 0);\r\nXXDEBUG(("bmac: multi enabled, rx_cfg=%#08x\n", rx_cfg));\r\n}\r\n}\r\n}\r\nstatic void bmac_set_multicast(struct net_device *dev)\r\n{\r\nstruct netdev_hw_addr *ha;\r\nint i;\r\nunsigned short rx_cfg;\r\nu32 crc;\r\nif((dev->flags & IFF_ALLMULTI) || (netdev_mc_count(dev) > 64)) {\r\nbmwrite(dev, BHASH0, 0xffff);\r\nbmwrite(dev, BHASH1, 0xffff);\r\nbmwrite(dev, BHASH2, 0xffff);\r\nbmwrite(dev, BHASH3, 0xffff);\r\n} else if(dev->flags & IFF_PROMISC) {\r\nrx_cfg = bmread(dev, RXCFG);\r\nrx_cfg |= RxPromiscEnable;\r\nbmwrite(dev, RXCFG, rx_cfg);\r\n} else {\r\nu16 hash_table[4];\r\nrx_cfg = bmread(dev, RXCFG);\r\nrx_cfg &= ~RxPromiscEnable;\r\nbmwrite(dev, RXCFG, rx_cfg);\r\nfor(i = 0; i < 4; i++) hash_table[i] = 0;\r\nnetdev_for_each_mc_addr(ha, dev) {\r\ncrc = ether_crc_le(6, ha->addr);\r\ncrc >>= 26;\r\nhash_table[crc >> 4] |= 1 << (crc & 0xf);\r\n}\r\nbmwrite(dev, BHASH0, hash_table[0]);\r\nbmwrite(dev, BHASH1, hash_table[1]);\r\nbmwrite(dev, BHASH2, hash_table[2]);\r\nbmwrite(dev, BHASH3, hash_table[3]);\r\n}\r\n}\r\nstatic irqreturn_t bmac_misc_intr(int irq, void *dev_id)\r\n{\r\nstruct net_device *dev = (struct net_device *) dev_id;\r\nunsigned int status = bmread(dev, STATUS);\r\nif (miscintcount++ < 10) {\r\nXXDEBUG(("bmac_misc_intr\n"));\r\n}\r\nif (status & RxErrorMask) dev->stats.rx_errors++;\r\nif (status & RxCRCCntExp) dev->stats.rx_crc_errors++;\r\nif (status & RxLenCntExp) dev->stats.rx_length_errors++;\r\nif (status & RxOverFlow) dev->stats.rx_over_errors++;\r\nif (status & RxAlignCntExp) dev->stats.rx_frame_errors++;\r\nif (status & TxErrorMask) dev->stats.tx_errors++;\r\nif (status & TxUnderrun) dev->stats.tx_fifo_errors++;\r\nif (status & TxNormalCollExp) dev->stats.collisions++;\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic unsigned char\r\nbmac_clock_out_bit(struct net_device *dev)\r\n{\r\nunsigned short data;\r\nunsigned short val;\r\nbmwrite(dev, SROMCSR, ChipSelect | Clk);\r\nudelay(DelayValue);\r\ndata = bmread(dev, SROMCSR);\r\nudelay(DelayValue);\r\nval = (data >> SD0ShiftCount) & 1;\r\nbmwrite(dev, SROMCSR, ChipSelect);\r\nudelay(DelayValue);\r\nreturn val;\r\n}\r\nstatic void\r\nbmac_clock_in_bit(struct net_device *dev, unsigned int val)\r\n{\r\nunsigned short data;\r\nif (val != 0 && val != 1) return;\r\ndata = (val << SDIShiftCount);\r\nbmwrite(dev, SROMCSR, data | ChipSelect );\r\nudelay(DelayValue);\r\nbmwrite(dev, SROMCSR, data | ChipSelect | Clk );\r\nudelay(DelayValue);\r\nbmwrite(dev, SROMCSR, data | ChipSelect);\r\nudelay(DelayValue);\r\n}\r\nstatic void\r\nreset_and_select_srom(struct net_device *dev)\r\n{\r\nbmwrite(dev, SROMCSR, 0);\r\nudelay(DelayValue);\r\nbmac_clock_in_bit(dev, 1);\r\nbmac_clock_in_bit(dev, 1);\r\nbmac_clock_in_bit(dev, 0);\r\n}\r\nstatic unsigned short\r\nread_srom(struct net_device *dev, unsigned int addr, unsigned int addr_len)\r\n{\r\nunsigned short data, val;\r\nint i;\r\nfor (i = 0; i < addr_len; i++) {\r\nval = addr >> (addr_len-i-1);\r\nbmac_clock_in_bit(dev, val & 1);\r\n}\r\ndata = 0;\r\nfor (i = 0; i < 16; i++) {\r\nval = bmac_clock_out_bit(dev);\r\ndata <<= 1;\r\ndata |= val;\r\n}\r\nbmwrite(dev, SROMCSR, 0);\r\nreturn data;\r\n}\r\nstatic int\r\nbmac_verify_checksum(struct net_device *dev)\r\n{\r\nunsigned short data, storedCS;\r\nreset_and_select_srom(dev);\r\ndata = read_srom(dev, 3, SROMAddressBits);\r\nstoredCS = ((data >> 8) & 0x0ff) | ((data << 8) & 0xff00);\r\nreturn 0;\r\n}\r\nstatic void\r\nbmac_get_station_address(struct net_device *dev, unsigned char *ea)\r\n{\r\nint i;\r\nunsigned short data;\r\nfor (i = 0; i < 6; i++)\r\n{\r\nreset_and_select_srom(dev);\r\ndata = read_srom(dev, i + EnetAddressOffset/2, SROMAddressBits);\r\nea[2*i] = bitrev8(data & 0x0ff);\r\nea[2*i+1] = bitrev8((data >> 8) & 0x0ff);\r\n}\r\n}\r\nstatic void bmac_reset_and_enable(struct net_device *dev)\r\n{\r\nstruct bmac_data *bp = netdev_priv(dev);\r\nunsigned long flags;\r\nstruct sk_buff *skb;\r\nunsigned char *data;\r\nspin_lock_irqsave(&bp->lock, flags);\r\nbmac_enable_and_reset_chip(dev);\r\nbmac_init_tx_ring(bp);\r\nbmac_init_rx_ring(dev);\r\nbmac_init_chip(dev);\r\nbmac_start_chip(dev);\r\nbmwrite(dev, INTDISABLE, EnableNormal);\r\nbp->sleeping = 0;\r\nskb = netdev_alloc_skb(dev, ETHERMINPACKET);\r\nif (skb != NULL) {\r\ndata = skb_put(skb, ETHERMINPACKET);\r\nmemset(data, 0, ETHERMINPACKET);\r\nmemcpy(data, dev->dev_addr, 6);\r\nmemcpy(data+6, dev->dev_addr, 6);\r\nbmac_transmit_packet(skb, dev);\r\n}\r\nspin_unlock_irqrestore(&bp->lock, flags);\r\n}\r\nstatic int __devinit bmac_probe(struct macio_dev *mdev, const struct of_device_id *match)\r\n{\r\nint j, rev, ret;\r\nstruct bmac_data *bp;\r\nconst unsigned char *prop_addr;\r\nunsigned char addr[6];\r\nstruct net_device *dev;\r\nint is_bmac_plus = ((int)match->data) != 0;\r\nif (macio_resource_count(mdev) != 3 || macio_irq_count(mdev) != 3) {\r\nprintk(KERN_ERR "BMAC: can't use, need 3 addrs and 3 intrs\n");\r\nreturn -ENODEV;\r\n}\r\nprop_addr = of_get_property(macio_get_of_node(mdev),\r\n"mac-address", NULL);\r\nif (prop_addr == NULL) {\r\nprop_addr = of_get_property(macio_get_of_node(mdev),\r\n"local-mac-address", NULL);\r\nif (prop_addr == NULL) {\r\nprintk(KERN_ERR "BMAC: Can't get mac-address\n");\r\nreturn -ENODEV;\r\n}\r\n}\r\nmemcpy(addr, prop_addr, sizeof(addr));\r\ndev = alloc_etherdev(PRIV_BYTES);\r\nif (!dev)\r\nreturn -ENOMEM;\r\nbp = netdev_priv(dev);\r\nSET_NETDEV_DEV(dev, &mdev->ofdev.dev);\r\nmacio_set_drvdata(mdev, dev);\r\nbp->mdev = mdev;\r\nspin_lock_init(&bp->lock);\r\nif (macio_request_resources(mdev, "bmac")) {\r\nprintk(KERN_ERR "BMAC: can't request IO resource !\n");\r\ngoto out_free;\r\n}\r\ndev->base_addr = (unsigned long)\r\nioremap(macio_resource_start(mdev, 0), macio_resource_len(mdev, 0));\r\nif (dev->base_addr == 0)\r\ngoto out_release;\r\ndev->irq = macio_irq(mdev, 0);\r\nbmac_enable_and_reset_chip(dev);\r\nbmwrite(dev, INTDISABLE, DisableAll);\r\nrev = addr[0] == 0 && addr[1] == 0xA0;\r\nfor (j = 0; j < 6; ++j)\r\ndev->dev_addr[j] = rev ? bitrev8(addr[j]): addr[j];\r\nbmac_enable_and_reset_chip(dev);\r\nbmwrite(dev, INTDISABLE, DisableAll);\r\ndev->netdev_ops = &bmac_netdev_ops;\r\ndev->ethtool_ops = &bmac_ethtool_ops;\r\nbmac_get_station_address(dev, addr);\r\nif (bmac_verify_checksum(dev) != 0)\r\ngoto err_out_iounmap;\r\nbp->is_bmac_plus = is_bmac_plus;\r\nbp->tx_dma = ioremap(macio_resource_start(mdev, 1), macio_resource_len(mdev, 1));\r\nif (!bp->tx_dma)\r\ngoto err_out_iounmap;\r\nbp->tx_dma_intr = macio_irq(mdev, 1);\r\nbp->rx_dma = ioremap(macio_resource_start(mdev, 2), macio_resource_len(mdev, 2));\r\nif (!bp->rx_dma)\r\ngoto err_out_iounmap_tx;\r\nbp->rx_dma_intr = macio_irq(mdev, 2);\r\nbp->tx_cmds = (volatile struct dbdma_cmd *) DBDMA_ALIGN(bp + 1);\r\nbp->rx_cmds = bp->tx_cmds + N_TX_RING + 1;\r\nbp->queue = (struct sk_buff_head *)(bp->rx_cmds + N_RX_RING + 1);\r\nskb_queue_head_init(bp->queue);\r\ninit_timer(&bp->tx_timeout);\r\nret = request_irq(dev->irq, bmac_misc_intr, 0, "BMAC-misc", dev);\r\nif (ret) {\r\nprintk(KERN_ERR "BMAC: can't get irq %d\n", dev->irq);\r\ngoto err_out_iounmap_rx;\r\n}\r\nret = request_irq(bp->tx_dma_intr, bmac_txdma_intr, 0, "BMAC-txdma", dev);\r\nif (ret) {\r\nprintk(KERN_ERR "BMAC: can't get irq %d\n", bp->tx_dma_intr);\r\ngoto err_out_irq0;\r\n}\r\nret = request_irq(bp->rx_dma_intr, bmac_rxdma_intr, 0, "BMAC-rxdma", dev);\r\nif (ret) {\r\nprintk(KERN_ERR "BMAC: can't get irq %d\n", bp->rx_dma_intr);\r\ngoto err_out_irq1;\r\n}\r\ndisable_irq(dev->irq);\r\npmac_call_feature(PMAC_FTR_BMAC_ENABLE, macio_get_of_node(bp->mdev), 0, 0);\r\nif (register_netdev(dev) != 0) {\r\nprintk(KERN_ERR "BMAC: Ethernet registration failed\n");\r\ngoto err_out_irq2;\r\n}\r\nprintk(KERN_INFO "%s: BMAC%s at %pM",\r\ndev->name, (is_bmac_plus ? "+" : ""), dev->dev_addr);\r\nXXDEBUG((", base_addr=%#0lx", dev->base_addr));\r\nprintk("\n");\r\nreturn 0;\r\nerr_out_irq2:\r\nfree_irq(bp->rx_dma_intr, dev);\r\nerr_out_irq1:\r\nfree_irq(bp->tx_dma_intr, dev);\r\nerr_out_irq0:\r\nfree_irq(dev->irq, dev);\r\nerr_out_iounmap_rx:\r\niounmap(bp->rx_dma);\r\nerr_out_iounmap_tx:\r\niounmap(bp->tx_dma);\r\nerr_out_iounmap:\r\niounmap((void __iomem *)dev->base_addr);\r\nout_release:\r\nmacio_release_resources(mdev);\r\nout_free:\r\npmac_call_feature(PMAC_FTR_BMAC_ENABLE, macio_get_of_node(bp->mdev), 0, 0);\r\nfree_netdev(dev);\r\nreturn -ENODEV;\r\n}\r\nstatic int bmac_open(struct net_device *dev)\r\n{\r\nstruct bmac_data *bp = netdev_priv(dev);\r\nbp->opened = 1;\r\nbmac_reset_and_enable(dev);\r\nenable_irq(dev->irq);\r\nreturn 0;\r\n}\r\nstatic int bmac_close(struct net_device *dev)\r\n{\r\nstruct bmac_data *bp = netdev_priv(dev);\r\nvolatile struct dbdma_regs __iomem *rd = bp->rx_dma;\r\nvolatile struct dbdma_regs __iomem *td = bp->tx_dma;\r\nunsigned short config;\r\nint i;\r\nbp->sleeping = 1;\r\nconfig = bmread(dev, RXCFG);\r\nbmwrite(dev, RXCFG, (config & ~RxMACEnable));\r\nconfig = bmread(dev, TXCFG);\r\nbmwrite(dev, TXCFG, (config & ~TxMACEnable));\r\nbmwrite(dev, INTDISABLE, DisableAll);\r\nst_le32(&rd->control, DBDMA_CLEAR(RUN|PAUSE|FLUSH|WAKE));\r\nst_le32(&td->control, DBDMA_CLEAR(RUN|PAUSE|FLUSH|WAKE));\r\nXXDEBUG(("bmac: free rx bufs\n"));\r\nfor (i=0; i<N_RX_RING; i++) {\r\nif (bp->rx_bufs[i] != NULL) {\r\ndev_kfree_skb(bp->rx_bufs[i]);\r\nbp->rx_bufs[i] = NULL;\r\n}\r\n}\r\nXXDEBUG(("bmac: free tx bufs\n"));\r\nfor (i = 0; i<N_TX_RING; i++) {\r\nif (bp->tx_bufs[i] != NULL) {\r\ndev_kfree_skb(bp->tx_bufs[i]);\r\nbp->tx_bufs[i] = NULL;\r\n}\r\n}\r\nXXDEBUG(("bmac: all bufs freed\n"));\r\nbp->opened = 0;\r\ndisable_irq(dev->irq);\r\npmac_call_feature(PMAC_FTR_BMAC_ENABLE, macio_get_of_node(bp->mdev), 0, 0);\r\nreturn 0;\r\n}\r\nstatic void\r\nbmac_start(struct net_device *dev)\r\n{\r\nstruct bmac_data *bp = netdev_priv(dev);\r\nint i;\r\nstruct sk_buff *skb;\r\nunsigned long flags;\r\nif (bp->sleeping)\r\nreturn;\r\nspin_lock_irqsave(&bp->lock, flags);\r\nwhile (1) {\r\ni = bp->tx_fill + 1;\r\nif (i >= N_TX_RING)\r\ni = 0;\r\nif (i == bp->tx_empty)\r\nbreak;\r\nskb = skb_dequeue(bp->queue);\r\nif (skb == NULL)\r\nbreak;\r\nbmac_transmit_packet(skb, dev);\r\n}\r\nspin_unlock_irqrestore(&bp->lock, flags);\r\n}\r\nstatic int\r\nbmac_output(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct bmac_data *bp = netdev_priv(dev);\r\nskb_queue_tail(bp->queue, skb);\r\nbmac_start(dev);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void bmac_tx_timeout(unsigned long data)\r\n{\r\nstruct net_device *dev = (struct net_device *) data;\r\nstruct bmac_data *bp = netdev_priv(dev);\r\nvolatile struct dbdma_regs __iomem *td = bp->tx_dma;\r\nvolatile struct dbdma_regs __iomem *rd = bp->rx_dma;\r\nvolatile struct dbdma_cmd *cp;\r\nunsigned long flags;\r\nunsigned short config, oldConfig;\r\nint i;\r\nXXDEBUG(("bmac: tx_timeout called\n"));\r\nspin_lock_irqsave(&bp->lock, flags);\r\nbp->timeout_active = 0;\r\ncp = &bp->tx_cmds[bp->tx_empty];\r\nconfig = bmread(dev, RXCFG);\r\nbmwrite(dev, RXCFG, (config & ~RxMACEnable));\r\nconfig = bmread(dev, TXCFG);\r\nbmwrite(dev, TXCFG, (config & ~TxMACEnable));\r\nout_le32(&td->control, DBDMA_CLEAR(RUN|PAUSE|FLUSH|WAKE|ACTIVE|DEAD));\r\nprintk(KERN_ERR "bmac: transmit timeout - resetting\n");\r\nbmac_enable_and_reset_chip(dev);\r\ncp = bus_to_virt(ld_le32(&rd->cmdptr));\r\nout_le32(&rd->control, DBDMA_CLEAR(RUN|PAUSE|FLUSH|WAKE|ACTIVE|DEAD));\r\nout_le16(&cp->xfer_status, 0);\r\nout_le32(&rd->cmdptr, virt_to_bus(cp));\r\nout_le32(&rd->control, DBDMA_SET(RUN|WAKE));\r\nXXDEBUG((KERN_DEBUG "bmac: tx empty=%d fill=%d fullup=%d\n",\r\nbp->tx_empty, bp->tx_fill, bp->tx_fullup));\r\ni = bp->tx_empty;\r\n++dev->stats.tx_errors;\r\nif (i != bp->tx_fill) {\r\ndev_kfree_skb(bp->tx_bufs[i]);\r\nbp->tx_bufs[i] = NULL;\r\nif (++i >= N_TX_RING) i = 0;\r\nbp->tx_empty = i;\r\n}\r\nbp->tx_fullup = 0;\r\nnetif_wake_queue(dev);\r\nif (i != bp->tx_fill) {\r\ncp = &bp->tx_cmds[i];\r\nout_le16(&cp->xfer_status, 0);\r\nout_le16(&cp->command, OUTPUT_LAST);\r\nout_le32(&td->cmdptr, virt_to_bus(cp));\r\nout_le32(&td->control, DBDMA_SET(RUN));\r\nXXDEBUG((KERN_DEBUG "bmac: starting %d\n", i));\r\n}\r\noldConfig = bmread(dev, RXCFG);\r\nbmwrite(dev, RXCFG, oldConfig | RxMACEnable );\r\noldConfig = bmread(dev, TXCFG);\r\nbmwrite(dev, TXCFG, oldConfig | TxMACEnable );\r\nspin_unlock_irqrestore(&bp->lock, flags);\r\n}\r\nstatic int __devexit bmac_remove(struct macio_dev *mdev)\r\n{\r\nstruct net_device *dev = macio_get_drvdata(mdev);\r\nstruct bmac_data *bp = netdev_priv(dev);\r\nunregister_netdev(dev);\r\nfree_irq(dev->irq, dev);\r\nfree_irq(bp->tx_dma_intr, dev);\r\nfree_irq(bp->rx_dma_intr, dev);\r\niounmap((void __iomem *)dev->base_addr);\r\niounmap(bp->tx_dma);\r\niounmap(bp->rx_dma);\r\nmacio_release_resources(mdev);\r\nfree_netdev(dev);\r\nreturn 0;\r\n}\r\nstatic int __init bmac_init(void)\r\n{\r\nif (bmac_emergency_rxbuf == NULL) {\r\nbmac_emergency_rxbuf = kmalloc(RX_BUFLEN, GFP_KERNEL);\r\nif (bmac_emergency_rxbuf == NULL)\r\nreturn -ENOMEM;\r\n}\r\nreturn macio_register_driver(&bmac_driver);\r\n}\r\nstatic void __exit bmac_exit(void)\r\n{\r\nmacio_unregister_driver(&bmac_driver);\r\nkfree(bmac_emergency_rxbuf);\r\nbmac_emergency_rxbuf = NULL;\r\n}
