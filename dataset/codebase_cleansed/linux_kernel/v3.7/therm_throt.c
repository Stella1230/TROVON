static int therm_throt_process(bool new_event, int event, int level)\r\n{\r\nstruct _thermal_state *state;\r\nunsigned int this_cpu = smp_processor_id();\r\nbool old_event;\r\nu64 now;\r\nstruct thermal_state *pstate = &per_cpu(thermal_state, this_cpu);\r\nnow = get_jiffies_64();\r\nif (level == CORE_LEVEL) {\r\nif (event == THERMAL_THROTTLING_EVENT)\r\nstate = &pstate->core_throttle;\r\nelse if (event == POWER_LIMIT_EVENT)\r\nstate = &pstate->core_power_limit;\r\nelse\r\nreturn 0;\r\n} else if (level == PACKAGE_LEVEL) {\r\nif (event == THERMAL_THROTTLING_EVENT)\r\nstate = &pstate->package_throttle;\r\nelse if (event == POWER_LIMIT_EVENT)\r\nstate = &pstate->package_power_limit;\r\nelse\r\nreturn 0;\r\n} else\r\nreturn 0;\r\nold_event = state->new_event;\r\nstate->new_event = new_event;\r\nif (new_event)\r\nstate->count++;\r\nif (time_before64(now, state->next_check) &&\r\nstate->count != state->last_count)\r\nreturn 0;\r\nstate->next_check = now + CHECK_INTERVAL;\r\nstate->last_count = state->count;\r\nif (new_event) {\r\nif (event == THERMAL_THROTTLING_EVENT)\r\nprintk(KERN_CRIT "CPU%d: %s temperature above threshold, cpu clock throttled (total events = %lu)\n",\r\nthis_cpu,\r\nlevel == CORE_LEVEL ? "Core" : "Package",\r\nstate->count);\r\nelse\r\nprintk(KERN_CRIT "CPU%d: %s power limit notification (total events = %lu)\n",\r\nthis_cpu,\r\nlevel == CORE_LEVEL ? "Core" : "Package",\r\nstate->count);\r\nreturn 1;\r\n}\r\nif (old_event) {\r\nif (event == THERMAL_THROTTLING_EVENT)\r\nprintk(KERN_INFO "CPU%d: %s temperature/speed normal\n",\r\nthis_cpu,\r\nlevel == CORE_LEVEL ? "Core" : "Package");\r\nelse\r\nprintk(KERN_INFO "CPU%d: %s power limit normal\n",\r\nthis_cpu,\r\nlevel == CORE_LEVEL ? "Core" : "Package");\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int thresh_event_valid(int event)\r\n{\r\nstruct _thermal_state *state;\r\nunsigned int this_cpu = smp_processor_id();\r\nstruct thermal_state *pstate = &per_cpu(thermal_state, this_cpu);\r\nu64 now = get_jiffies_64();\r\nstate = (event == 0) ? &pstate->core_thresh0 : &pstate->core_thresh1;\r\nif (time_before64(now, state->next_check))\r\nreturn 0;\r\nstate->next_check = now + CHECK_INTERVAL;\r\nreturn 1;\r\n}\r\nstatic __cpuinit int thermal_throttle_add_dev(struct device *dev,\r\nunsigned int cpu)\r\n{\r\nint err;\r\nstruct cpuinfo_x86 *c = &cpu_data(cpu);\r\nerr = sysfs_create_group(&dev->kobj, &thermal_attr_group);\r\nif (err)\r\nreturn err;\r\nif (cpu_has(c, X86_FEATURE_PLN))\r\nerr = sysfs_add_file_to_group(&dev->kobj,\r\n&dev_attr_core_power_limit_count.attr,\r\nthermal_attr_group.name);\r\nif (cpu_has(c, X86_FEATURE_PTS)) {\r\nerr = sysfs_add_file_to_group(&dev->kobj,\r\n&dev_attr_package_throttle_count.attr,\r\nthermal_attr_group.name);\r\nif (cpu_has(c, X86_FEATURE_PLN))\r\nerr = sysfs_add_file_to_group(&dev->kobj,\r\n&dev_attr_package_power_limit_count.attr,\r\nthermal_attr_group.name);\r\n}\r\nreturn err;\r\n}\r\nstatic __cpuinit void thermal_throttle_remove_dev(struct device *dev)\r\n{\r\nsysfs_remove_group(&dev->kobj, &thermal_attr_group);\r\n}\r\nstatic __cpuinit int\r\nthermal_throttle_cpu_callback(struct notifier_block *nfb,\r\nunsigned long action,\r\nvoid *hcpu)\r\n{\r\nunsigned int cpu = (unsigned long)hcpu;\r\nstruct device *dev;\r\nint err = 0;\r\ndev = get_cpu_device(cpu);\r\nswitch (action) {\r\ncase CPU_UP_PREPARE:\r\ncase CPU_UP_PREPARE_FROZEN:\r\nmutex_lock(&therm_cpu_lock);\r\nerr = thermal_throttle_add_dev(dev, cpu);\r\nmutex_unlock(&therm_cpu_lock);\r\nWARN_ON(err);\r\nbreak;\r\ncase CPU_UP_CANCELED:\r\ncase CPU_UP_CANCELED_FROZEN:\r\ncase CPU_DEAD:\r\ncase CPU_DEAD_FROZEN:\r\nmutex_lock(&therm_cpu_lock);\r\nthermal_throttle_remove_dev(dev);\r\nmutex_unlock(&therm_cpu_lock);\r\nbreak;\r\n}\r\nreturn notifier_from_errno(err);\r\n}\r\nstatic __init int thermal_throttle_init_device(void)\r\n{\r\nunsigned int cpu = 0;\r\nint err;\r\nif (!atomic_read(&therm_throt_en))\r\nreturn 0;\r\nregister_hotcpu_notifier(&thermal_throttle_cpu_notifier);\r\n#ifdef CONFIG_HOTPLUG_CPU\r\nmutex_lock(&therm_cpu_lock);\r\n#endif\r\nfor_each_online_cpu(cpu) {\r\nerr = thermal_throttle_add_dev(get_cpu_device(cpu), cpu);\r\nWARN_ON(err);\r\n}\r\n#ifdef CONFIG_HOTPLUG_CPU\r\nmutex_unlock(&therm_cpu_lock);\r\n#endif\r\nreturn 0;\r\n}\r\nstatic void notify_thresholds(__u64 msr_val)\r\n{\r\nif (!platform_thermal_notify)\r\nreturn;\r\nif ((msr_val & THERM_LOG_THRESHOLD0) && thresh_event_valid(0))\r\nplatform_thermal_notify(msr_val);\r\nif ((msr_val & THERM_LOG_THRESHOLD1) && thresh_event_valid(1))\r\nplatform_thermal_notify(msr_val);\r\n}\r\nstatic void intel_thermal_interrupt(void)\r\n{\r\n__u64 msr_val;\r\nrdmsrl(MSR_IA32_THERM_STATUS, msr_val);\r\nnotify_thresholds(msr_val);\r\nif (therm_throt_process(msr_val & THERM_STATUS_PROCHOT,\r\nTHERMAL_THROTTLING_EVENT,\r\nCORE_LEVEL) != 0)\r\nmce_log_therm_throt_event(msr_val);\r\nif (this_cpu_has(X86_FEATURE_PLN))\r\ntherm_throt_process(msr_val & THERM_STATUS_POWER_LIMIT,\r\nPOWER_LIMIT_EVENT,\r\nCORE_LEVEL);\r\nif (this_cpu_has(X86_FEATURE_PTS)) {\r\nrdmsrl(MSR_IA32_PACKAGE_THERM_STATUS, msr_val);\r\ntherm_throt_process(msr_val & PACKAGE_THERM_STATUS_PROCHOT,\r\nTHERMAL_THROTTLING_EVENT,\r\nPACKAGE_LEVEL);\r\nif (this_cpu_has(X86_FEATURE_PLN))\r\ntherm_throt_process(msr_val &\r\nPACKAGE_THERM_STATUS_POWER_LIMIT,\r\nPOWER_LIMIT_EVENT,\r\nPACKAGE_LEVEL);\r\n}\r\n}\r\nstatic void unexpected_thermal_interrupt(void)\r\n{\r\nprintk(KERN_ERR "CPU%d: Unexpected LVT thermal interrupt!\n",\r\nsmp_processor_id());\r\n}\r\nasmlinkage void smp_thermal_interrupt(struct pt_regs *regs)\r\n{\r\nirq_enter();\r\nexit_idle();\r\ninc_irq_stat(irq_thermal_count);\r\nsmp_thermal_vector();\r\nirq_exit();\r\nack_APIC_irq();\r\n}\r\nstatic int intel_thermal_supported(struct cpuinfo_x86 *c)\r\n{\r\nif (!cpu_has_apic)\r\nreturn 0;\r\nif (!cpu_has(c, X86_FEATURE_ACPI) || !cpu_has(c, X86_FEATURE_ACC))\r\nreturn 0;\r\nreturn 1;\r\n}\r\nvoid __init mcheck_intel_therm_init(void)\r\n{\r\nif (intel_thermal_supported(&boot_cpu_data))\r\nlvtthmr_init = apic_read(APIC_LVTTHMR);\r\n}\r\nvoid intel_init_thermal(struct cpuinfo_x86 *c)\r\n{\r\nunsigned int cpu = smp_processor_id();\r\nint tm2 = 0;\r\nu32 l, h;\r\nif (!intel_thermal_supported(c))\r\nreturn;\r\nrdmsr(MSR_IA32_MISC_ENABLE, l, h);\r\nh = lvtthmr_init;\r\nif ((h & APIC_DM_FIXED_MASK) != APIC_DM_FIXED)\r\napic_write(APIC_LVTTHMR, lvtthmr_init);\r\nif ((l & MSR_IA32_MISC_ENABLE_TM1) && (h & APIC_DM_SMI)) {\r\nprintk(KERN_DEBUG\r\n"CPU%d: Thermal monitoring handled by SMI\n", cpu);\r\nreturn;\r\n}\r\nif (h & APIC_VECTOR_MASK) {\r\nprintk(KERN_DEBUG\r\n"CPU%d: Thermal LVT vector (%#x) already installed\n",\r\ncpu, (h & APIC_VECTOR_MASK));\r\nreturn;\r\n}\r\nif (cpu_has(c, X86_FEATURE_TM2)) {\r\nif (c->x86 == 6 && (c->x86_model == 9 || c->x86_model == 13)) {\r\nrdmsr(MSR_THERM2_CTL, l, h);\r\nif (l & MSR_THERM2_CTL_TM_SELECT)\r\ntm2 = 1;\r\n} else if (l & MSR_IA32_MISC_ENABLE_TM2)\r\ntm2 = 1;\r\n}\r\nh = THERMAL_APIC_VECTOR | APIC_DM_FIXED | APIC_LVT_MASKED;\r\napic_write(APIC_LVTTHMR, h);\r\nrdmsr(MSR_IA32_THERM_INTERRUPT, l, h);\r\nif (cpu_has(c, X86_FEATURE_PLN))\r\nwrmsr(MSR_IA32_THERM_INTERRUPT,\r\nl | (THERM_INT_LOW_ENABLE\r\n| THERM_INT_HIGH_ENABLE | THERM_INT_PLN_ENABLE), h);\r\nelse\r\nwrmsr(MSR_IA32_THERM_INTERRUPT,\r\nl | (THERM_INT_LOW_ENABLE | THERM_INT_HIGH_ENABLE), h);\r\nif (cpu_has(c, X86_FEATURE_PTS)) {\r\nrdmsr(MSR_IA32_PACKAGE_THERM_INTERRUPT, l, h);\r\nif (cpu_has(c, X86_FEATURE_PLN))\r\nwrmsr(MSR_IA32_PACKAGE_THERM_INTERRUPT,\r\nl | (PACKAGE_THERM_INT_LOW_ENABLE\r\n| PACKAGE_THERM_INT_HIGH_ENABLE\r\n| PACKAGE_THERM_INT_PLN_ENABLE), h);\r\nelse\r\nwrmsr(MSR_IA32_PACKAGE_THERM_INTERRUPT,\r\nl | (PACKAGE_THERM_INT_LOW_ENABLE\r\n| PACKAGE_THERM_INT_HIGH_ENABLE), h);\r\n}\r\nsmp_thermal_vector = intel_thermal_interrupt;\r\nrdmsr(MSR_IA32_MISC_ENABLE, l, h);\r\nwrmsr(MSR_IA32_MISC_ENABLE, l | MSR_IA32_MISC_ENABLE_TM1, h);\r\nl = apic_read(APIC_LVTTHMR);\r\napic_write(APIC_LVTTHMR, l & ~APIC_LVT_MASKED);\r\nprintk_once(KERN_INFO "CPU0: Thermal monitoring enabled (%s)\n",\r\ntm2 ? "TM2" : "TM1");\r\natomic_set(&therm_throt_en, 1);\r\n}
