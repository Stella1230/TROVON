int enic_is_dynamic(struct enic *enic)\r\n{\r\nreturn enic->pdev->device == PCI_DEVICE_ID_CISCO_VIC_ENET_DYN;\r\n}\r\nint enic_sriov_enabled(struct enic *enic)\r\n{\r\nreturn (enic->priv_flags & ENIC_SRIOV_ENABLED) ? 1 : 0;\r\n}\r\nstatic int enic_is_sriov_vf(struct enic *enic)\r\n{\r\nreturn enic->pdev->device == PCI_DEVICE_ID_CISCO_VIC_ENET_VF;\r\n}\r\nint enic_is_valid_vf(struct enic *enic, int vf)\r\n{\r\n#ifdef CONFIG_PCI_IOV\r\nreturn vf >= 0 && vf < enic->num_vfs;\r\n#else\r\nreturn 0;\r\n#endif\r\n}\r\nstatic inline unsigned int enic_cq_rq(struct enic *enic, unsigned int rq)\r\n{\r\nreturn rq;\r\n}\r\nstatic inline unsigned int enic_cq_wq(struct enic *enic, unsigned int wq)\r\n{\r\nreturn enic->rq_count + wq;\r\n}\r\nstatic inline unsigned int enic_legacy_io_intr(void)\r\n{\r\nreturn 0;\r\n}\r\nstatic inline unsigned int enic_legacy_err_intr(void)\r\n{\r\nreturn 1;\r\n}\r\nstatic inline unsigned int enic_legacy_notify_intr(void)\r\n{\r\nreturn 2;\r\n}\r\nstatic inline unsigned int enic_msix_rq_intr(struct enic *enic, unsigned int rq)\r\n{\r\nreturn enic->cq[enic_cq_rq(enic, rq)].interrupt_offset;\r\n}\r\nstatic inline unsigned int enic_msix_wq_intr(struct enic *enic, unsigned int wq)\r\n{\r\nreturn enic->cq[enic_cq_wq(enic, wq)].interrupt_offset;\r\n}\r\nstatic inline unsigned int enic_msix_err_intr(struct enic *enic)\r\n{\r\nreturn enic->rq_count + enic->wq_count;\r\n}\r\nstatic inline unsigned int enic_msix_notify_intr(struct enic *enic)\r\n{\r\nreturn enic->rq_count + enic->wq_count + 1;\r\n}\r\nstatic int enic_get_settings(struct net_device *netdev,\r\nstruct ethtool_cmd *ecmd)\r\n{\r\nstruct enic *enic = netdev_priv(netdev);\r\necmd->supported = (SUPPORTED_10000baseT_Full | SUPPORTED_FIBRE);\r\necmd->advertising = (ADVERTISED_10000baseT_Full | ADVERTISED_FIBRE);\r\necmd->port = PORT_FIBRE;\r\necmd->transceiver = XCVR_EXTERNAL;\r\nif (netif_carrier_ok(netdev)) {\r\nethtool_cmd_speed_set(ecmd, vnic_dev_port_speed(enic->vdev));\r\necmd->duplex = DUPLEX_FULL;\r\n} else {\r\nethtool_cmd_speed_set(ecmd, -1);\r\necmd->duplex = -1;\r\n}\r\necmd->autoneg = AUTONEG_DISABLE;\r\nreturn 0;\r\n}\r\nstatic void enic_get_drvinfo(struct net_device *netdev,\r\nstruct ethtool_drvinfo *drvinfo)\r\n{\r\nstruct enic *enic = netdev_priv(netdev);\r\nstruct vnic_devcmd_fw_info *fw_info;\r\nenic_dev_fw_info(enic, &fw_info);\r\nstrlcpy(drvinfo->driver, DRV_NAME, sizeof(drvinfo->driver));\r\nstrlcpy(drvinfo->version, DRV_VERSION, sizeof(drvinfo->version));\r\nstrlcpy(drvinfo->fw_version, fw_info->fw_version,\r\nsizeof(drvinfo->fw_version));\r\nstrlcpy(drvinfo->bus_info, pci_name(enic->pdev),\r\nsizeof(drvinfo->bus_info));\r\n}\r\nstatic void enic_get_strings(struct net_device *netdev, u32 stringset, u8 *data)\r\n{\r\nunsigned int i;\r\nswitch (stringset) {\r\ncase ETH_SS_STATS:\r\nfor (i = 0; i < enic_n_tx_stats; i++) {\r\nmemcpy(data, enic_tx_stats[i].name, ETH_GSTRING_LEN);\r\ndata += ETH_GSTRING_LEN;\r\n}\r\nfor (i = 0; i < enic_n_rx_stats; i++) {\r\nmemcpy(data, enic_rx_stats[i].name, ETH_GSTRING_LEN);\r\ndata += ETH_GSTRING_LEN;\r\n}\r\nbreak;\r\n}\r\n}\r\nstatic int enic_get_sset_count(struct net_device *netdev, int sset)\r\n{\r\nswitch (sset) {\r\ncase ETH_SS_STATS:\r\nreturn enic_n_tx_stats + enic_n_rx_stats;\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nstatic void enic_get_ethtool_stats(struct net_device *netdev,\r\nstruct ethtool_stats *stats, u64 *data)\r\n{\r\nstruct enic *enic = netdev_priv(netdev);\r\nstruct vnic_stats *vstats;\r\nunsigned int i;\r\nenic_dev_stats_dump(enic, &vstats);\r\nfor (i = 0; i < enic_n_tx_stats; i++)\r\n*(data++) = ((u64 *)&vstats->tx)[enic_tx_stats[i].offset];\r\nfor (i = 0; i < enic_n_rx_stats; i++)\r\n*(data++) = ((u64 *)&vstats->rx)[enic_rx_stats[i].offset];\r\n}\r\nstatic u32 enic_get_msglevel(struct net_device *netdev)\r\n{\r\nstruct enic *enic = netdev_priv(netdev);\r\nreturn enic->msg_enable;\r\n}\r\nstatic void enic_set_msglevel(struct net_device *netdev, u32 value)\r\n{\r\nstruct enic *enic = netdev_priv(netdev);\r\nenic->msg_enable = value;\r\n}\r\nstatic int enic_get_coalesce(struct net_device *netdev,\r\nstruct ethtool_coalesce *ecmd)\r\n{\r\nstruct enic *enic = netdev_priv(netdev);\r\necmd->tx_coalesce_usecs = enic->tx_coalesce_usecs;\r\necmd->rx_coalesce_usecs = enic->rx_coalesce_usecs;\r\nreturn 0;\r\n}\r\nstatic int enic_set_coalesce(struct net_device *netdev,\r\nstruct ethtool_coalesce *ecmd)\r\n{\r\nstruct enic *enic = netdev_priv(netdev);\r\nu32 tx_coalesce_usecs;\r\nu32 rx_coalesce_usecs;\r\nunsigned int i, intr;\r\ntx_coalesce_usecs = min_t(u32, ecmd->tx_coalesce_usecs,\r\nvnic_dev_get_intr_coal_timer_max(enic->vdev));\r\nrx_coalesce_usecs = min_t(u32, ecmd->rx_coalesce_usecs,\r\nvnic_dev_get_intr_coal_timer_max(enic->vdev));\r\nswitch (vnic_dev_get_intr_mode(enic->vdev)) {\r\ncase VNIC_DEV_INTR_MODE_INTX:\r\nif (tx_coalesce_usecs != rx_coalesce_usecs)\r\nreturn -EINVAL;\r\nintr = enic_legacy_io_intr();\r\nvnic_intr_coalescing_timer_set(&enic->intr[intr],\r\ntx_coalesce_usecs);\r\nbreak;\r\ncase VNIC_DEV_INTR_MODE_MSI:\r\nif (tx_coalesce_usecs != rx_coalesce_usecs)\r\nreturn -EINVAL;\r\nvnic_intr_coalescing_timer_set(&enic->intr[0],\r\ntx_coalesce_usecs);\r\nbreak;\r\ncase VNIC_DEV_INTR_MODE_MSIX:\r\nfor (i = 0; i < enic->wq_count; i++) {\r\nintr = enic_msix_wq_intr(enic, i);\r\nvnic_intr_coalescing_timer_set(&enic->intr[intr],\r\ntx_coalesce_usecs);\r\n}\r\nfor (i = 0; i < enic->rq_count; i++) {\r\nintr = enic_msix_rq_intr(enic, i);\r\nvnic_intr_coalescing_timer_set(&enic->intr[intr],\r\nrx_coalesce_usecs);\r\n}\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nenic->tx_coalesce_usecs = tx_coalesce_usecs;\r\nenic->rx_coalesce_usecs = rx_coalesce_usecs;\r\nreturn 0;\r\n}\r\nstatic void enic_free_wq_buf(struct vnic_wq *wq, struct vnic_wq_buf *buf)\r\n{\r\nstruct enic *enic = vnic_dev_priv(wq->vdev);\r\nif (buf->sop)\r\npci_unmap_single(enic->pdev, buf->dma_addr,\r\nbuf->len, PCI_DMA_TODEVICE);\r\nelse\r\npci_unmap_page(enic->pdev, buf->dma_addr,\r\nbuf->len, PCI_DMA_TODEVICE);\r\nif (buf->os_buf)\r\ndev_kfree_skb_any(buf->os_buf);\r\n}\r\nstatic void enic_wq_free_buf(struct vnic_wq *wq,\r\nstruct cq_desc *cq_desc, struct vnic_wq_buf *buf, void *opaque)\r\n{\r\nenic_free_wq_buf(wq, buf);\r\n}\r\nstatic int enic_wq_service(struct vnic_dev *vdev, struct cq_desc *cq_desc,\r\nu8 type, u16 q_number, u16 completed_index, void *opaque)\r\n{\r\nstruct enic *enic = vnic_dev_priv(vdev);\r\nspin_lock(&enic->wq_lock[q_number]);\r\nvnic_wq_service(&enic->wq[q_number], cq_desc,\r\ncompleted_index, enic_wq_free_buf,\r\nopaque);\r\nif (netif_queue_stopped(enic->netdev) &&\r\nvnic_wq_desc_avail(&enic->wq[q_number]) >=\r\n(MAX_SKB_FRAGS + ENIC_DESC_MAX_SPLITS))\r\nnetif_wake_queue(enic->netdev);\r\nspin_unlock(&enic->wq_lock[q_number]);\r\nreturn 0;\r\n}\r\nstatic void enic_log_q_error(struct enic *enic)\r\n{\r\nunsigned int i;\r\nu32 error_status;\r\nfor (i = 0; i < enic->wq_count; i++) {\r\nerror_status = vnic_wq_error_status(&enic->wq[i]);\r\nif (error_status)\r\nnetdev_err(enic->netdev, "WQ[%d] error_status %d\n",\r\ni, error_status);\r\n}\r\nfor (i = 0; i < enic->rq_count; i++) {\r\nerror_status = vnic_rq_error_status(&enic->rq[i]);\r\nif (error_status)\r\nnetdev_err(enic->netdev, "RQ[%d] error_status %d\n",\r\ni, error_status);\r\n}\r\n}\r\nstatic void enic_msglvl_check(struct enic *enic)\r\n{\r\nu32 msg_enable = vnic_dev_msg_lvl(enic->vdev);\r\nif (msg_enable != enic->msg_enable) {\r\nnetdev_info(enic->netdev, "msg lvl changed from 0x%x to 0x%x\n",\r\nenic->msg_enable, msg_enable);\r\nenic->msg_enable = msg_enable;\r\n}\r\n}\r\nstatic void enic_mtu_check(struct enic *enic)\r\n{\r\nu32 mtu = vnic_dev_mtu(enic->vdev);\r\nstruct net_device *netdev = enic->netdev;\r\nif (mtu && mtu != enic->port_mtu) {\r\nenic->port_mtu = mtu;\r\nif (enic_is_dynamic(enic) || enic_is_sriov_vf(enic)) {\r\nmtu = max_t(int, ENIC_MIN_MTU,\r\nmin_t(int, ENIC_MAX_MTU, mtu));\r\nif (mtu != netdev->mtu)\r\nschedule_work(&enic->change_mtu_work);\r\n} else {\r\nif (mtu < netdev->mtu)\r\nnetdev_warn(netdev,\r\n"interface MTU (%d) set higher "\r\n"than switch port MTU (%d)\n",\r\nnetdev->mtu, mtu);\r\n}\r\n}\r\n}\r\nstatic void enic_link_check(struct enic *enic)\r\n{\r\nint link_status = vnic_dev_link_status(enic->vdev);\r\nint carrier_ok = netif_carrier_ok(enic->netdev);\r\nif (link_status && !carrier_ok) {\r\nnetdev_info(enic->netdev, "Link UP\n");\r\nnetif_carrier_on(enic->netdev);\r\n} else if (!link_status && carrier_ok) {\r\nnetdev_info(enic->netdev, "Link DOWN\n");\r\nnetif_carrier_off(enic->netdev);\r\n}\r\n}\r\nstatic void enic_notify_check(struct enic *enic)\r\n{\r\nenic_msglvl_check(enic);\r\nenic_mtu_check(enic);\r\nenic_link_check(enic);\r\n}\r\nstatic irqreturn_t enic_isr_legacy(int irq, void *data)\r\n{\r\nstruct net_device *netdev = data;\r\nstruct enic *enic = netdev_priv(netdev);\r\nunsigned int io_intr = enic_legacy_io_intr();\r\nunsigned int err_intr = enic_legacy_err_intr();\r\nunsigned int notify_intr = enic_legacy_notify_intr();\r\nu32 pba;\r\nvnic_intr_mask(&enic->intr[io_intr]);\r\npba = vnic_intr_legacy_pba(enic->legacy_pba);\r\nif (!pba) {\r\nvnic_intr_unmask(&enic->intr[io_intr]);\r\nreturn IRQ_NONE;\r\n}\r\nif (ENIC_TEST_INTR(pba, notify_intr)) {\r\nvnic_intr_return_all_credits(&enic->intr[notify_intr]);\r\nenic_notify_check(enic);\r\n}\r\nif (ENIC_TEST_INTR(pba, err_intr)) {\r\nvnic_intr_return_all_credits(&enic->intr[err_intr]);\r\nenic_log_q_error(enic);\r\nschedule_work(&enic->reset);\r\nreturn IRQ_HANDLED;\r\n}\r\nif (ENIC_TEST_INTR(pba, io_intr)) {\r\nif (napi_schedule_prep(&enic->napi[0]))\r\n__napi_schedule(&enic->napi[0]);\r\n} else {\r\nvnic_intr_unmask(&enic->intr[io_intr]);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t enic_isr_msi(int irq, void *data)\r\n{\r\nstruct enic *enic = data;\r\nnapi_schedule(&enic->napi[0]);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t enic_isr_msix_rq(int irq, void *data)\r\n{\r\nstruct napi_struct *napi = data;\r\nnapi_schedule(napi);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t enic_isr_msix_wq(int irq, void *data)\r\n{\r\nstruct enic *enic = data;\r\nunsigned int cq = enic_cq_wq(enic, 0);\r\nunsigned int intr = enic_msix_wq_intr(enic, 0);\r\nunsigned int wq_work_to_do = -1;\r\nunsigned int wq_work_done;\r\nwq_work_done = vnic_cq_service(&enic->cq[cq],\r\nwq_work_to_do, enic_wq_service, NULL);\r\nvnic_intr_return_credits(&enic->intr[intr],\r\nwq_work_done,\r\n1 ,\r\n1 );\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t enic_isr_msix_err(int irq, void *data)\r\n{\r\nstruct enic *enic = data;\r\nunsigned int intr = enic_msix_err_intr(enic);\r\nvnic_intr_return_all_credits(&enic->intr[intr]);\r\nenic_log_q_error(enic);\r\nschedule_work(&enic->reset);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t enic_isr_msix_notify(int irq, void *data)\r\n{\r\nstruct enic *enic = data;\r\nunsigned int intr = enic_msix_notify_intr(enic);\r\nvnic_intr_return_all_credits(&enic->intr[intr]);\r\nenic_notify_check(enic);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic inline void enic_queue_wq_skb_cont(struct enic *enic,\r\nstruct vnic_wq *wq, struct sk_buff *skb,\r\nunsigned int len_left, int loopback)\r\n{\r\nconst skb_frag_t *frag;\r\nfor (frag = skb_shinfo(skb)->frags; len_left; frag++) {\r\nlen_left -= skb_frag_size(frag);\r\nenic_queue_wq_desc_cont(wq, skb,\r\nskb_frag_dma_map(&enic->pdev->dev,\r\nfrag, 0, skb_frag_size(frag),\r\nDMA_TO_DEVICE),\r\nskb_frag_size(frag),\r\n(len_left == 0),\r\nloopback);\r\n}\r\n}\r\nstatic inline void enic_queue_wq_skb_vlan(struct enic *enic,\r\nstruct vnic_wq *wq, struct sk_buff *skb,\r\nint vlan_tag_insert, unsigned int vlan_tag, int loopback)\r\n{\r\nunsigned int head_len = skb_headlen(skb);\r\nunsigned int len_left = skb->len - head_len;\r\nint eop = (len_left == 0);\r\nenic_queue_wq_desc(wq, skb,\r\npci_map_single(enic->pdev, skb->data,\r\nhead_len, PCI_DMA_TODEVICE),\r\nhead_len,\r\nvlan_tag_insert, vlan_tag,\r\neop, loopback);\r\nif (!eop)\r\nenic_queue_wq_skb_cont(enic, wq, skb, len_left, loopback);\r\n}\r\nstatic inline void enic_queue_wq_skb_csum_l4(struct enic *enic,\r\nstruct vnic_wq *wq, struct sk_buff *skb,\r\nint vlan_tag_insert, unsigned int vlan_tag, int loopback)\r\n{\r\nunsigned int head_len = skb_headlen(skb);\r\nunsigned int len_left = skb->len - head_len;\r\nunsigned int hdr_len = skb_checksum_start_offset(skb);\r\nunsigned int csum_offset = hdr_len + skb->csum_offset;\r\nint eop = (len_left == 0);\r\nenic_queue_wq_desc_csum_l4(wq, skb,\r\npci_map_single(enic->pdev, skb->data,\r\nhead_len, PCI_DMA_TODEVICE),\r\nhead_len,\r\ncsum_offset,\r\nhdr_len,\r\nvlan_tag_insert, vlan_tag,\r\neop, loopback);\r\nif (!eop)\r\nenic_queue_wq_skb_cont(enic, wq, skb, len_left, loopback);\r\n}\r\nstatic inline void enic_queue_wq_skb_tso(struct enic *enic,\r\nstruct vnic_wq *wq, struct sk_buff *skb, unsigned int mss,\r\nint vlan_tag_insert, unsigned int vlan_tag, int loopback)\r\n{\r\nunsigned int frag_len_left = skb_headlen(skb);\r\nunsigned int len_left = skb->len - frag_len_left;\r\nunsigned int hdr_len = skb_transport_offset(skb) + tcp_hdrlen(skb);\r\nint eop = (len_left == 0);\r\nunsigned int len;\r\ndma_addr_t dma_addr;\r\nunsigned int offset = 0;\r\nskb_frag_t *frag;\r\nif (skb->protocol == cpu_to_be16(ETH_P_IP)) {\r\nip_hdr(skb)->check = 0;\r\ntcp_hdr(skb)->check = ~csum_tcpudp_magic(ip_hdr(skb)->saddr,\r\nip_hdr(skb)->daddr, 0, IPPROTO_TCP, 0);\r\n} else if (skb->protocol == cpu_to_be16(ETH_P_IPV6)) {\r\ntcp_hdr(skb)->check = ~csum_ipv6_magic(&ipv6_hdr(skb)->saddr,\r\n&ipv6_hdr(skb)->daddr, 0, IPPROTO_TCP, 0);\r\n}\r\nwhile (frag_len_left) {\r\nlen = min(frag_len_left, (unsigned int)WQ_ENET_MAX_DESC_LEN);\r\ndma_addr = pci_map_single(enic->pdev, skb->data + offset,\r\nlen, PCI_DMA_TODEVICE);\r\nenic_queue_wq_desc_tso(wq, skb,\r\ndma_addr,\r\nlen,\r\nmss, hdr_len,\r\nvlan_tag_insert, vlan_tag,\r\neop && (len == frag_len_left), loopback);\r\nfrag_len_left -= len;\r\noffset += len;\r\n}\r\nif (eop)\r\nreturn;\r\nfor (frag = skb_shinfo(skb)->frags; len_left; frag++) {\r\nlen_left -= skb_frag_size(frag);\r\nfrag_len_left = skb_frag_size(frag);\r\noffset = 0;\r\nwhile (frag_len_left) {\r\nlen = min(frag_len_left,\r\n(unsigned int)WQ_ENET_MAX_DESC_LEN);\r\ndma_addr = skb_frag_dma_map(&enic->pdev->dev, frag,\r\noffset, len,\r\nDMA_TO_DEVICE);\r\nenic_queue_wq_desc_cont(wq, skb,\r\ndma_addr,\r\nlen,\r\n(len_left == 0) &&\r\n(len == frag_len_left),\r\nloopback);\r\nfrag_len_left -= len;\r\noffset += len;\r\n}\r\n}\r\n}\r\nstatic inline void enic_queue_wq_skb(struct enic *enic,\r\nstruct vnic_wq *wq, struct sk_buff *skb)\r\n{\r\nunsigned int mss = skb_shinfo(skb)->gso_size;\r\nunsigned int vlan_tag = 0;\r\nint vlan_tag_insert = 0;\r\nint loopback = 0;\r\nif (vlan_tx_tag_present(skb)) {\r\nvlan_tag_insert = 1;\r\nvlan_tag = vlan_tx_tag_get(skb);\r\n} else if (enic->loop_enable) {\r\nvlan_tag = enic->loop_tag;\r\nloopback = 1;\r\n}\r\nif (mss)\r\nenic_queue_wq_skb_tso(enic, wq, skb, mss,\r\nvlan_tag_insert, vlan_tag, loopback);\r\nelse if (skb->ip_summed == CHECKSUM_PARTIAL)\r\nenic_queue_wq_skb_csum_l4(enic, wq, skb,\r\nvlan_tag_insert, vlan_tag, loopback);\r\nelse\r\nenic_queue_wq_skb_vlan(enic, wq, skb,\r\nvlan_tag_insert, vlan_tag, loopback);\r\n}\r\nstatic netdev_tx_t enic_hard_start_xmit(struct sk_buff *skb,\r\nstruct net_device *netdev)\r\n{\r\nstruct enic *enic = netdev_priv(netdev);\r\nstruct vnic_wq *wq = &enic->wq[0];\r\nunsigned long flags;\r\nif (skb->len <= 0) {\r\ndev_kfree_skb(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nif (skb_shinfo(skb)->gso_size == 0 &&\r\nskb_shinfo(skb)->nr_frags + 1 > ENIC_NON_TSO_MAX_DESC &&\r\nskb_linearize(skb)) {\r\ndev_kfree_skb(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nspin_lock_irqsave(&enic->wq_lock[0], flags);\r\nif (vnic_wq_desc_avail(wq) <\r\nskb_shinfo(skb)->nr_frags + ENIC_DESC_MAX_SPLITS) {\r\nnetif_stop_queue(netdev);\r\nnetdev_err(netdev, "BUG! Tx ring full when queue awake!\n");\r\nspin_unlock_irqrestore(&enic->wq_lock[0], flags);\r\nreturn NETDEV_TX_BUSY;\r\n}\r\nenic_queue_wq_skb(enic, wq, skb);\r\nif (vnic_wq_desc_avail(wq) < MAX_SKB_FRAGS + ENIC_DESC_MAX_SPLITS)\r\nnetif_stop_queue(netdev);\r\nspin_unlock_irqrestore(&enic->wq_lock[0], flags);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic struct rtnl_link_stats64 *enic_get_stats(struct net_device *netdev,\r\nstruct rtnl_link_stats64 *net_stats)\r\n{\r\nstruct enic *enic = netdev_priv(netdev);\r\nstruct vnic_stats *stats;\r\nenic_dev_stats_dump(enic, &stats);\r\nnet_stats->tx_packets = stats->tx.tx_frames_ok;\r\nnet_stats->tx_bytes = stats->tx.tx_bytes_ok;\r\nnet_stats->tx_errors = stats->tx.tx_errors;\r\nnet_stats->tx_dropped = stats->tx.tx_drops;\r\nnet_stats->rx_packets = stats->rx.rx_frames_ok;\r\nnet_stats->rx_bytes = stats->rx.rx_bytes_ok;\r\nnet_stats->rx_errors = stats->rx.rx_errors;\r\nnet_stats->multicast = stats->rx.rx_multicast_frames_ok;\r\nnet_stats->rx_over_errors = enic->rq_truncated_pkts;\r\nnet_stats->rx_crc_errors = enic->rq_bad_fcs;\r\nnet_stats->rx_dropped = stats->rx.rx_no_bufs + stats->rx.rx_drop;\r\nreturn net_stats;\r\n}\r\nvoid enic_reset_addr_lists(struct enic *enic)\r\n{\r\nenic->mc_count = 0;\r\nenic->uc_count = 0;\r\nenic->flags = 0;\r\n}\r\nstatic int enic_set_mac_addr(struct net_device *netdev, char *addr)\r\n{\r\nstruct enic *enic = netdev_priv(netdev);\r\nif (enic_is_dynamic(enic) || enic_is_sriov_vf(enic)) {\r\nif (!is_valid_ether_addr(addr) && !is_zero_ether_addr(addr))\r\nreturn -EADDRNOTAVAIL;\r\n} else {\r\nif (!is_valid_ether_addr(addr))\r\nreturn -EADDRNOTAVAIL;\r\n}\r\nmemcpy(netdev->dev_addr, addr, netdev->addr_len);\r\nnetdev->addr_assign_type &= ~NET_ADDR_RANDOM;\r\nreturn 0;\r\n}\r\nstatic int enic_set_mac_address_dynamic(struct net_device *netdev, void *p)\r\n{\r\nstruct enic *enic = netdev_priv(netdev);\r\nstruct sockaddr *saddr = p;\r\nchar *addr = saddr->sa_data;\r\nint err;\r\nif (netif_running(enic->netdev)) {\r\nerr = enic_dev_del_station_addr(enic);\r\nif (err)\r\nreturn err;\r\n}\r\nerr = enic_set_mac_addr(netdev, addr);\r\nif (err)\r\nreturn err;\r\nif (netif_running(enic->netdev)) {\r\nerr = enic_dev_add_station_addr(enic);\r\nif (err)\r\nreturn err;\r\n}\r\nreturn err;\r\n}\r\nstatic int enic_set_mac_address(struct net_device *netdev, void *p)\r\n{\r\nstruct sockaddr *saddr = p;\r\nchar *addr = saddr->sa_data;\r\nstruct enic *enic = netdev_priv(netdev);\r\nint err;\r\nerr = enic_dev_del_station_addr(enic);\r\nif (err)\r\nreturn err;\r\nerr = enic_set_mac_addr(netdev, addr);\r\nif (err)\r\nreturn err;\r\nreturn enic_dev_add_station_addr(enic);\r\n}\r\nstatic void enic_update_multicast_addr_list(struct enic *enic)\r\n{\r\nstruct net_device *netdev = enic->netdev;\r\nstruct netdev_hw_addr *ha;\r\nunsigned int mc_count = netdev_mc_count(netdev);\r\nu8 mc_addr[ENIC_MULTICAST_PERFECT_FILTERS][ETH_ALEN];\r\nunsigned int i, j;\r\nif (mc_count > ENIC_MULTICAST_PERFECT_FILTERS) {\r\nnetdev_warn(netdev, "Registering only %d out of %d "\r\n"multicast addresses\n",\r\nENIC_MULTICAST_PERFECT_FILTERS, mc_count);\r\nmc_count = ENIC_MULTICAST_PERFECT_FILTERS;\r\n}\r\ni = 0;\r\nnetdev_for_each_mc_addr(ha, netdev) {\r\nif (i == mc_count)\r\nbreak;\r\nmemcpy(mc_addr[i++], ha->addr, ETH_ALEN);\r\n}\r\nfor (i = 0; i < enic->mc_count; i++) {\r\nfor (j = 0; j < mc_count; j++)\r\nif (ether_addr_equal(enic->mc_addr[i], mc_addr[j]))\r\nbreak;\r\nif (j == mc_count)\r\nenic_dev_del_addr(enic, enic->mc_addr[i]);\r\n}\r\nfor (i = 0; i < mc_count; i++) {\r\nfor (j = 0; j < enic->mc_count; j++)\r\nif (ether_addr_equal(mc_addr[i], enic->mc_addr[j]))\r\nbreak;\r\nif (j == enic->mc_count)\r\nenic_dev_add_addr(enic, mc_addr[i]);\r\n}\r\nfor (i = 0; i < mc_count; i++)\r\nmemcpy(enic->mc_addr[i], mc_addr[i], ETH_ALEN);\r\nenic->mc_count = mc_count;\r\n}\r\nstatic void enic_update_unicast_addr_list(struct enic *enic)\r\n{\r\nstruct net_device *netdev = enic->netdev;\r\nstruct netdev_hw_addr *ha;\r\nunsigned int uc_count = netdev_uc_count(netdev);\r\nu8 uc_addr[ENIC_UNICAST_PERFECT_FILTERS][ETH_ALEN];\r\nunsigned int i, j;\r\nif (uc_count > ENIC_UNICAST_PERFECT_FILTERS) {\r\nnetdev_warn(netdev, "Registering only %d out of %d "\r\n"unicast addresses\n",\r\nENIC_UNICAST_PERFECT_FILTERS, uc_count);\r\nuc_count = ENIC_UNICAST_PERFECT_FILTERS;\r\n}\r\ni = 0;\r\nnetdev_for_each_uc_addr(ha, netdev) {\r\nif (i == uc_count)\r\nbreak;\r\nmemcpy(uc_addr[i++], ha->addr, ETH_ALEN);\r\n}\r\nfor (i = 0; i < enic->uc_count; i++) {\r\nfor (j = 0; j < uc_count; j++)\r\nif (ether_addr_equal(enic->uc_addr[i], uc_addr[j]))\r\nbreak;\r\nif (j == uc_count)\r\nenic_dev_del_addr(enic, enic->uc_addr[i]);\r\n}\r\nfor (i = 0; i < uc_count; i++) {\r\nfor (j = 0; j < enic->uc_count; j++)\r\nif (ether_addr_equal(uc_addr[i], enic->uc_addr[j]))\r\nbreak;\r\nif (j == enic->uc_count)\r\nenic_dev_add_addr(enic, uc_addr[i]);\r\n}\r\nfor (i = 0; i < uc_count; i++)\r\nmemcpy(enic->uc_addr[i], uc_addr[i], ETH_ALEN);\r\nenic->uc_count = uc_count;\r\n}\r\nstatic void enic_set_rx_mode(struct net_device *netdev)\r\n{\r\nstruct enic *enic = netdev_priv(netdev);\r\nint directed = 1;\r\nint multicast = (netdev->flags & IFF_MULTICAST) ? 1 : 0;\r\nint broadcast = (netdev->flags & IFF_BROADCAST) ? 1 : 0;\r\nint promisc = (netdev->flags & IFF_PROMISC) ||\r\nnetdev_uc_count(netdev) > ENIC_UNICAST_PERFECT_FILTERS;\r\nint allmulti = (netdev->flags & IFF_ALLMULTI) ||\r\nnetdev_mc_count(netdev) > ENIC_MULTICAST_PERFECT_FILTERS;\r\nunsigned int flags = netdev->flags |\r\n(allmulti ? IFF_ALLMULTI : 0) |\r\n(promisc ? IFF_PROMISC : 0);\r\nif (enic->flags != flags) {\r\nenic->flags = flags;\r\nenic_dev_packet_filter(enic, directed,\r\nmulticast, broadcast, promisc, allmulti);\r\n}\r\nif (!promisc) {\r\nenic_update_unicast_addr_list(enic);\r\nif (!allmulti)\r\nenic_update_multicast_addr_list(enic);\r\n}\r\n}\r\nstatic void enic_tx_timeout(struct net_device *netdev)\r\n{\r\nstruct enic *enic = netdev_priv(netdev);\r\nschedule_work(&enic->reset);\r\n}\r\nstatic int enic_set_vf_mac(struct net_device *netdev, int vf, u8 *mac)\r\n{\r\nstruct enic *enic = netdev_priv(netdev);\r\nstruct enic_port_profile *pp;\r\nint err;\r\nENIC_PP_BY_INDEX(enic, vf, pp, &err);\r\nif (err)\r\nreturn err;\r\nif (is_valid_ether_addr(mac) || is_zero_ether_addr(mac)) {\r\nif (vf == PORT_SELF_VF) {\r\nmemcpy(pp->vf_mac, mac, ETH_ALEN);\r\nreturn 0;\r\n} else {\r\nENIC_DEVCMD_PROXY_BY_INDEX(vf, err, enic,\r\nvnic_dev_set_mac_addr, mac);\r\nreturn enic_dev_status_to_errno(err);\r\n}\r\n} else\r\nreturn -EINVAL;\r\n}\r\nstatic int enic_set_vf_port(struct net_device *netdev, int vf,\r\nstruct nlattr *port[])\r\n{\r\nstruct enic *enic = netdev_priv(netdev);\r\nstruct enic_port_profile prev_pp;\r\nstruct enic_port_profile *pp;\r\nint err = 0, restore_pp = 1;\r\nENIC_PP_BY_INDEX(enic, vf, pp, &err);\r\nif (err)\r\nreturn err;\r\nif (!port[IFLA_PORT_REQUEST])\r\nreturn -EOPNOTSUPP;\r\nmemcpy(&prev_pp, pp, sizeof(*enic->pp));\r\nmemset(pp, 0, sizeof(*enic->pp));\r\npp->set |= ENIC_SET_REQUEST;\r\npp->request = nla_get_u8(port[IFLA_PORT_REQUEST]);\r\nif (port[IFLA_PORT_PROFILE]) {\r\npp->set |= ENIC_SET_NAME;\r\nmemcpy(pp->name, nla_data(port[IFLA_PORT_PROFILE]),\r\nPORT_PROFILE_MAX);\r\n}\r\nif (port[IFLA_PORT_INSTANCE_UUID]) {\r\npp->set |= ENIC_SET_INSTANCE;\r\nmemcpy(pp->instance_uuid,\r\nnla_data(port[IFLA_PORT_INSTANCE_UUID]), PORT_UUID_MAX);\r\n}\r\nif (port[IFLA_PORT_HOST_UUID]) {\r\npp->set |= ENIC_SET_HOST;\r\nmemcpy(pp->host_uuid,\r\nnla_data(port[IFLA_PORT_HOST_UUID]), PORT_UUID_MAX);\r\n}\r\nif (vf == PORT_SELF_VF) {\r\nif (!is_zero_ether_addr(prev_pp.vf_mac))\r\nmemcpy(pp->mac_addr, prev_pp.vf_mac, ETH_ALEN);\r\nif (is_zero_ether_addr(netdev->dev_addr))\r\neth_hw_addr_random(netdev);\r\n} else {\r\nENIC_DEVCMD_PROXY_BY_INDEX(vf, err, enic,\r\nvnic_dev_get_mac_addr, pp->mac_addr);\r\nif (err) {\r\nnetdev_err(netdev, "Error getting mac for vf %d\n", vf);\r\nmemcpy(pp, &prev_pp, sizeof(*pp));\r\nreturn enic_dev_status_to_errno(err);\r\n}\r\n}\r\nerr = enic_process_set_pp_request(enic, vf, &prev_pp, &restore_pp);\r\nif (err) {\r\nif (restore_pp) {\r\nmemcpy(pp, &prev_pp, sizeof(*pp));\r\n} else {\r\nmemset(pp, 0, sizeof(*pp));\r\nif (vf == PORT_SELF_VF)\r\nmemset(netdev->dev_addr, 0, ETH_ALEN);\r\n}\r\n} else {\r\npp->set |= ENIC_PORT_REQUEST_APPLIED;\r\nif (pp->request == PORT_REQUEST_DISASSOCIATE) {\r\nmemset(pp->mac_addr, 0, ETH_ALEN);\r\nif (vf == PORT_SELF_VF)\r\nmemset(netdev->dev_addr, 0, ETH_ALEN);\r\n}\r\n}\r\nif (vf == PORT_SELF_VF)\r\nmemset(pp->vf_mac, 0, ETH_ALEN);\r\nreturn err;\r\n}\r\nstatic int enic_get_vf_port(struct net_device *netdev, int vf,\r\nstruct sk_buff *skb)\r\n{\r\nstruct enic *enic = netdev_priv(netdev);\r\nu16 response = PORT_PROFILE_RESPONSE_SUCCESS;\r\nstruct enic_port_profile *pp;\r\nint err;\r\nENIC_PP_BY_INDEX(enic, vf, pp, &err);\r\nif (err)\r\nreturn err;\r\nif (!(pp->set & ENIC_PORT_REQUEST_APPLIED))\r\nreturn -ENODATA;\r\nerr = enic_process_get_pp_request(enic, vf, pp->request, &response);\r\nif (err)\r\nreturn err;\r\nif (nla_put_u16(skb, IFLA_PORT_REQUEST, pp->request) ||\r\nnla_put_u16(skb, IFLA_PORT_RESPONSE, response) ||\r\n((pp->set & ENIC_SET_NAME) &&\r\nnla_put(skb, IFLA_PORT_PROFILE, PORT_PROFILE_MAX, pp->name)) ||\r\n((pp->set & ENIC_SET_INSTANCE) &&\r\nnla_put(skb, IFLA_PORT_INSTANCE_UUID, PORT_UUID_MAX,\r\npp->instance_uuid)) ||\r\n((pp->set & ENIC_SET_HOST) &&\r\nnla_put(skb, IFLA_PORT_HOST_UUID, PORT_UUID_MAX, pp->host_uuid)))\r\ngoto nla_put_failure;\r\nreturn 0;\r\nnla_put_failure:\r\nreturn -EMSGSIZE;\r\n}\r\nstatic void enic_free_rq_buf(struct vnic_rq *rq, struct vnic_rq_buf *buf)\r\n{\r\nstruct enic *enic = vnic_dev_priv(rq->vdev);\r\nif (!buf->os_buf)\r\nreturn;\r\npci_unmap_single(enic->pdev, buf->dma_addr,\r\nbuf->len, PCI_DMA_FROMDEVICE);\r\ndev_kfree_skb_any(buf->os_buf);\r\n}\r\nstatic int enic_rq_alloc_buf(struct vnic_rq *rq)\r\n{\r\nstruct enic *enic = vnic_dev_priv(rq->vdev);\r\nstruct net_device *netdev = enic->netdev;\r\nstruct sk_buff *skb;\r\nunsigned int len = netdev->mtu + VLAN_ETH_HLEN;\r\nunsigned int os_buf_index = 0;\r\ndma_addr_t dma_addr;\r\nskb = netdev_alloc_skb_ip_align(netdev, len);\r\nif (!skb)\r\nreturn -ENOMEM;\r\ndma_addr = pci_map_single(enic->pdev, skb->data,\r\nlen, PCI_DMA_FROMDEVICE);\r\nenic_queue_rq_desc(rq, skb, os_buf_index,\r\ndma_addr, len);\r\nreturn 0;\r\n}\r\nstatic void enic_rq_indicate_buf(struct vnic_rq *rq,\r\nstruct cq_desc *cq_desc, struct vnic_rq_buf *buf,\r\nint skipped, void *opaque)\r\n{\r\nstruct enic *enic = vnic_dev_priv(rq->vdev);\r\nstruct net_device *netdev = enic->netdev;\r\nstruct sk_buff *skb;\r\nu8 type, color, eop, sop, ingress_port, vlan_stripped;\r\nu8 fcoe, fcoe_sof, fcoe_fc_crc_ok, fcoe_enc_error, fcoe_eof;\r\nu8 tcp_udp_csum_ok, udp, tcp, ipv4_csum_ok;\r\nu8 ipv6, ipv4, ipv4_fragment, fcs_ok, rss_type, csum_not_calc;\r\nu8 packet_error;\r\nu16 q_number, completed_index, bytes_written, vlan_tci, checksum;\r\nu32 rss_hash;\r\nif (skipped)\r\nreturn;\r\nskb = buf->os_buf;\r\nprefetch(skb->data - NET_IP_ALIGN);\r\npci_unmap_single(enic->pdev, buf->dma_addr,\r\nbuf->len, PCI_DMA_FROMDEVICE);\r\ncq_enet_rq_desc_dec((struct cq_enet_rq_desc *)cq_desc,\r\n&type, &color, &q_number, &completed_index,\r\n&ingress_port, &fcoe, &eop, &sop, &rss_type,\r\n&csum_not_calc, &rss_hash, &bytes_written,\r\n&packet_error, &vlan_stripped, &vlan_tci, &checksum,\r\n&fcoe_sof, &fcoe_fc_crc_ok, &fcoe_enc_error,\r\n&fcoe_eof, &tcp_udp_csum_ok, &udp, &tcp,\r\n&ipv4_csum_ok, &ipv6, &ipv4, &ipv4_fragment,\r\n&fcs_ok);\r\nif (packet_error) {\r\nif (!fcs_ok) {\r\nif (bytes_written > 0)\r\nenic->rq_bad_fcs++;\r\nelse if (bytes_written == 0)\r\nenic->rq_truncated_pkts++;\r\n}\r\ndev_kfree_skb_any(skb);\r\nreturn;\r\n}\r\nif (eop && bytes_written > 0) {\r\nskb_put(skb, bytes_written);\r\nskb->protocol = eth_type_trans(skb, netdev);\r\nif ((netdev->features & NETIF_F_RXCSUM) && !csum_not_calc) {\r\nskb->csum = htons(checksum);\r\nskb->ip_summed = CHECKSUM_COMPLETE;\r\n}\r\nif (vlan_stripped)\r\n__vlan_hwaccel_put_tag(skb, vlan_tci);\r\nif (netdev->features & NETIF_F_GRO)\r\nnapi_gro_receive(&enic->napi[q_number], skb);\r\nelse\r\nnetif_receive_skb(skb);\r\n} else {\r\ndev_kfree_skb_any(skb);\r\n}\r\n}\r\nstatic int enic_rq_service(struct vnic_dev *vdev, struct cq_desc *cq_desc,\r\nu8 type, u16 q_number, u16 completed_index, void *opaque)\r\n{\r\nstruct enic *enic = vnic_dev_priv(vdev);\r\nvnic_rq_service(&enic->rq[q_number], cq_desc,\r\ncompleted_index, VNIC_RQ_RETURN_DESC,\r\nenic_rq_indicate_buf, opaque);\r\nreturn 0;\r\n}\r\nstatic int enic_poll(struct napi_struct *napi, int budget)\r\n{\r\nstruct net_device *netdev = napi->dev;\r\nstruct enic *enic = netdev_priv(netdev);\r\nunsigned int cq_rq = enic_cq_rq(enic, 0);\r\nunsigned int cq_wq = enic_cq_wq(enic, 0);\r\nunsigned int intr = enic_legacy_io_intr();\r\nunsigned int rq_work_to_do = budget;\r\nunsigned int wq_work_to_do = -1;\r\nunsigned int work_done, rq_work_done, wq_work_done;\r\nint err;\r\nrq_work_done = vnic_cq_service(&enic->cq[cq_rq],\r\nrq_work_to_do, enic_rq_service, NULL);\r\nwq_work_done = vnic_cq_service(&enic->cq[cq_wq],\r\nwq_work_to_do, enic_wq_service, NULL);\r\nwork_done = rq_work_done + wq_work_done;\r\nif (work_done > 0)\r\nvnic_intr_return_credits(&enic->intr[intr],\r\nwork_done,\r\n0 ,\r\n0 );\r\nerr = vnic_rq_fill(&enic->rq[0], enic_rq_alloc_buf);\r\nif (err)\r\nrq_work_done = rq_work_to_do;\r\nif (rq_work_done < rq_work_to_do) {\r\nnapi_complete(napi);\r\nvnic_intr_unmask(&enic->intr[intr]);\r\n}\r\nreturn rq_work_done;\r\n}\r\nstatic int enic_poll_msix(struct napi_struct *napi, int budget)\r\n{\r\nstruct net_device *netdev = napi->dev;\r\nstruct enic *enic = netdev_priv(netdev);\r\nunsigned int rq = (napi - &enic->napi[0]);\r\nunsigned int cq = enic_cq_rq(enic, rq);\r\nunsigned int intr = enic_msix_rq_intr(enic, rq);\r\nunsigned int work_to_do = budget;\r\nunsigned int work_done;\r\nint err;\r\nwork_done = vnic_cq_service(&enic->cq[cq],\r\nwork_to_do, enic_rq_service, NULL);\r\nif (work_done > 0)\r\nvnic_intr_return_credits(&enic->intr[intr],\r\nwork_done,\r\n0 ,\r\n0 );\r\nerr = vnic_rq_fill(&enic->rq[rq], enic_rq_alloc_buf);\r\nif (err)\r\nwork_done = work_to_do;\r\nif (work_done < work_to_do) {\r\nnapi_complete(napi);\r\nvnic_intr_unmask(&enic->intr[intr]);\r\n}\r\nreturn work_done;\r\n}\r\nstatic void enic_notify_timer(unsigned long data)\r\n{\r\nstruct enic *enic = (struct enic *)data;\r\nenic_notify_check(enic);\r\nmod_timer(&enic->notify_timer,\r\nround_jiffies(jiffies + ENIC_NOTIFY_TIMER_PERIOD));\r\n}\r\nstatic void enic_free_intr(struct enic *enic)\r\n{\r\nstruct net_device *netdev = enic->netdev;\r\nunsigned int i;\r\nswitch (vnic_dev_get_intr_mode(enic->vdev)) {\r\ncase VNIC_DEV_INTR_MODE_INTX:\r\nfree_irq(enic->pdev->irq, netdev);\r\nbreak;\r\ncase VNIC_DEV_INTR_MODE_MSI:\r\nfree_irq(enic->pdev->irq, enic);\r\nbreak;\r\ncase VNIC_DEV_INTR_MODE_MSIX:\r\nfor (i = 0; i < ARRAY_SIZE(enic->msix); i++)\r\nif (enic->msix[i].requested)\r\nfree_irq(enic->msix_entry[i].vector,\r\nenic->msix[i].devid);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nstatic int enic_request_intr(struct enic *enic)\r\n{\r\nstruct net_device *netdev = enic->netdev;\r\nunsigned int i, intr;\r\nint err = 0;\r\nswitch (vnic_dev_get_intr_mode(enic->vdev)) {\r\ncase VNIC_DEV_INTR_MODE_INTX:\r\nerr = request_irq(enic->pdev->irq, enic_isr_legacy,\r\nIRQF_SHARED, netdev->name, netdev);\r\nbreak;\r\ncase VNIC_DEV_INTR_MODE_MSI:\r\nerr = request_irq(enic->pdev->irq, enic_isr_msi,\r\n0, netdev->name, enic);\r\nbreak;\r\ncase VNIC_DEV_INTR_MODE_MSIX:\r\nfor (i = 0; i < enic->rq_count; i++) {\r\nintr = enic_msix_rq_intr(enic, i);\r\nsprintf(enic->msix[intr].devname,\r\n"%.11s-rx-%d", netdev->name, i);\r\nenic->msix[intr].isr = enic_isr_msix_rq;\r\nenic->msix[intr].devid = &enic->napi[i];\r\n}\r\nfor (i = 0; i < enic->wq_count; i++) {\r\nintr = enic_msix_wq_intr(enic, i);\r\nsprintf(enic->msix[intr].devname,\r\n"%.11s-tx-%d", netdev->name, i);\r\nenic->msix[intr].isr = enic_isr_msix_wq;\r\nenic->msix[intr].devid = enic;\r\n}\r\nintr = enic_msix_err_intr(enic);\r\nsprintf(enic->msix[intr].devname,\r\n"%.11s-err", netdev->name);\r\nenic->msix[intr].isr = enic_isr_msix_err;\r\nenic->msix[intr].devid = enic;\r\nintr = enic_msix_notify_intr(enic);\r\nsprintf(enic->msix[intr].devname,\r\n"%.11s-notify", netdev->name);\r\nenic->msix[intr].isr = enic_isr_msix_notify;\r\nenic->msix[intr].devid = enic;\r\nfor (i = 0; i < ARRAY_SIZE(enic->msix); i++)\r\nenic->msix[i].requested = 0;\r\nfor (i = 0; i < enic->intr_count; i++) {\r\nerr = request_irq(enic->msix_entry[i].vector,\r\nenic->msix[i].isr, 0,\r\nenic->msix[i].devname,\r\nenic->msix[i].devid);\r\nif (err) {\r\nenic_free_intr(enic);\r\nbreak;\r\n}\r\nenic->msix[i].requested = 1;\r\n}\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn err;\r\n}\r\nstatic void enic_synchronize_irqs(struct enic *enic)\r\n{\r\nunsigned int i;\r\nswitch (vnic_dev_get_intr_mode(enic->vdev)) {\r\ncase VNIC_DEV_INTR_MODE_INTX:\r\ncase VNIC_DEV_INTR_MODE_MSI:\r\nsynchronize_irq(enic->pdev->irq);\r\nbreak;\r\ncase VNIC_DEV_INTR_MODE_MSIX:\r\nfor (i = 0; i < enic->intr_count; i++)\r\nsynchronize_irq(enic->msix_entry[i].vector);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nstatic int enic_dev_notify_set(struct enic *enic)\r\n{\r\nint err;\r\nspin_lock(&enic->devcmd_lock);\r\nswitch (vnic_dev_get_intr_mode(enic->vdev)) {\r\ncase VNIC_DEV_INTR_MODE_INTX:\r\nerr = vnic_dev_notify_set(enic->vdev,\r\nenic_legacy_notify_intr());\r\nbreak;\r\ncase VNIC_DEV_INTR_MODE_MSIX:\r\nerr = vnic_dev_notify_set(enic->vdev,\r\nenic_msix_notify_intr(enic));\r\nbreak;\r\ndefault:\r\nerr = vnic_dev_notify_set(enic->vdev, -1 );\r\nbreak;\r\n}\r\nspin_unlock(&enic->devcmd_lock);\r\nreturn err;\r\n}\r\nstatic void enic_notify_timer_start(struct enic *enic)\r\n{\r\nswitch (vnic_dev_get_intr_mode(enic->vdev)) {\r\ncase VNIC_DEV_INTR_MODE_MSI:\r\nmod_timer(&enic->notify_timer, jiffies);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nstatic int enic_open(struct net_device *netdev)\r\n{\r\nstruct enic *enic = netdev_priv(netdev);\r\nunsigned int i;\r\nint err;\r\nerr = enic_request_intr(enic);\r\nif (err) {\r\nnetdev_err(netdev, "Unable to request irq.\n");\r\nreturn err;\r\n}\r\nerr = enic_dev_notify_set(enic);\r\nif (err) {\r\nnetdev_err(netdev,\r\n"Failed to alloc notify buffer, aborting.\n");\r\ngoto err_out_free_intr;\r\n}\r\nfor (i = 0; i < enic->rq_count; i++) {\r\nvnic_rq_fill(&enic->rq[i], enic_rq_alloc_buf);\r\nif (vnic_rq_desc_used(&enic->rq[i]) == 0) {\r\nnetdev_err(netdev, "Unable to alloc receive buffers\n");\r\nerr = -ENOMEM;\r\ngoto err_out_notify_unset;\r\n}\r\n}\r\nfor (i = 0; i < enic->wq_count; i++)\r\nvnic_wq_enable(&enic->wq[i]);\r\nfor (i = 0; i < enic->rq_count; i++)\r\nvnic_rq_enable(&enic->rq[i]);\r\nif (!enic_is_dynamic(enic) && !enic_is_sriov_vf(enic))\r\nenic_dev_add_station_addr(enic);\r\nenic_set_rx_mode(netdev);\r\nnetif_wake_queue(netdev);\r\nfor (i = 0; i < enic->rq_count; i++)\r\nnapi_enable(&enic->napi[i]);\r\nenic_dev_enable(enic);\r\nfor (i = 0; i < enic->intr_count; i++)\r\nvnic_intr_unmask(&enic->intr[i]);\r\nenic_notify_timer_start(enic);\r\nreturn 0;\r\nerr_out_notify_unset:\r\nenic_dev_notify_unset(enic);\r\nerr_out_free_intr:\r\nenic_free_intr(enic);\r\nreturn err;\r\n}\r\nstatic int enic_stop(struct net_device *netdev)\r\n{\r\nstruct enic *enic = netdev_priv(netdev);\r\nunsigned int i;\r\nint err;\r\nfor (i = 0; i < enic->intr_count; i++) {\r\nvnic_intr_mask(&enic->intr[i]);\r\n(void)vnic_intr_masked(&enic->intr[i]);\r\n}\r\nenic_synchronize_irqs(enic);\r\ndel_timer_sync(&enic->notify_timer);\r\nenic_dev_disable(enic);\r\nfor (i = 0; i < enic->rq_count; i++)\r\nnapi_disable(&enic->napi[i]);\r\nnetif_carrier_off(netdev);\r\nnetif_tx_disable(netdev);\r\nif (!enic_is_dynamic(enic) && !enic_is_sriov_vf(enic))\r\nenic_dev_del_station_addr(enic);\r\nfor (i = 0; i < enic->wq_count; i++) {\r\nerr = vnic_wq_disable(&enic->wq[i]);\r\nif (err)\r\nreturn err;\r\n}\r\nfor (i = 0; i < enic->rq_count; i++) {\r\nerr = vnic_rq_disable(&enic->rq[i]);\r\nif (err)\r\nreturn err;\r\n}\r\nenic_dev_notify_unset(enic);\r\nenic_free_intr(enic);\r\nfor (i = 0; i < enic->wq_count; i++)\r\nvnic_wq_clean(&enic->wq[i], enic_free_wq_buf);\r\nfor (i = 0; i < enic->rq_count; i++)\r\nvnic_rq_clean(&enic->rq[i], enic_free_rq_buf);\r\nfor (i = 0; i < enic->cq_count; i++)\r\nvnic_cq_clean(&enic->cq[i]);\r\nfor (i = 0; i < enic->intr_count; i++)\r\nvnic_intr_clean(&enic->intr[i]);\r\nreturn 0;\r\n}\r\nstatic int enic_change_mtu(struct net_device *netdev, int new_mtu)\r\n{\r\nstruct enic *enic = netdev_priv(netdev);\r\nint running = netif_running(netdev);\r\nif (new_mtu < ENIC_MIN_MTU || new_mtu > ENIC_MAX_MTU)\r\nreturn -EINVAL;\r\nif (enic_is_dynamic(enic) || enic_is_sriov_vf(enic))\r\nreturn -EOPNOTSUPP;\r\nif (running)\r\nenic_stop(netdev);\r\nnetdev->mtu = new_mtu;\r\nif (netdev->mtu > enic->port_mtu)\r\nnetdev_warn(netdev,\r\n"interface MTU (%d) set higher than port MTU (%d)\n",\r\nnetdev->mtu, enic->port_mtu);\r\nif (running)\r\nenic_open(netdev);\r\nreturn 0;\r\n}\r\nstatic void enic_change_mtu_work(struct work_struct *work)\r\n{\r\nstruct enic *enic = container_of(work, struct enic, change_mtu_work);\r\nstruct net_device *netdev = enic->netdev;\r\nint new_mtu = vnic_dev_mtu(enic->vdev);\r\nint err;\r\nunsigned int i;\r\nnew_mtu = max_t(int, ENIC_MIN_MTU, min_t(int, ENIC_MAX_MTU, new_mtu));\r\nrtnl_lock();\r\ndel_timer_sync(&enic->notify_timer);\r\nfor (i = 0; i < enic->rq_count; i++)\r\nnapi_disable(&enic->napi[i]);\r\nvnic_intr_mask(&enic->intr[0]);\r\nenic_synchronize_irqs(enic);\r\nerr = vnic_rq_disable(&enic->rq[0]);\r\nif (err) {\r\nnetdev_err(netdev, "Unable to disable RQ.\n");\r\nreturn;\r\n}\r\nvnic_rq_clean(&enic->rq[0], enic_free_rq_buf);\r\nvnic_cq_clean(&enic->cq[0]);\r\nvnic_intr_clean(&enic->intr[0]);\r\nnetdev->mtu = new_mtu;\r\nvnic_rq_fill(&enic->rq[0], enic_rq_alloc_buf);\r\nif (vnic_rq_desc_used(&enic->rq[0]) == 0) {\r\nnetdev_err(netdev, "Unable to alloc receive buffers.\n");\r\nreturn;\r\n}\r\nvnic_rq_enable(&enic->rq[0]);\r\nnapi_enable(&enic->napi[0]);\r\nvnic_intr_unmask(&enic->intr[0]);\r\nenic_notify_timer_start(enic);\r\nrtnl_unlock();\r\nnetdev_info(netdev, "interface MTU set as %d\n", netdev->mtu);\r\n}\r\nstatic void enic_poll_controller(struct net_device *netdev)\r\n{\r\nstruct enic *enic = netdev_priv(netdev);\r\nstruct vnic_dev *vdev = enic->vdev;\r\nunsigned int i, intr;\r\nswitch (vnic_dev_get_intr_mode(vdev)) {\r\ncase VNIC_DEV_INTR_MODE_MSIX:\r\nfor (i = 0; i < enic->rq_count; i++) {\r\nintr = enic_msix_rq_intr(enic, i);\r\nenic_isr_msix_rq(enic->msix_entry[intr].vector,\r\n&enic->napi[i]);\r\n}\r\nfor (i = 0; i < enic->wq_count; i++) {\r\nintr = enic_msix_wq_intr(enic, i);\r\nenic_isr_msix_wq(enic->msix_entry[intr].vector, enic);\r\n}\r\nbreak;\r\ncase VNIC_DEV_INTR_MODE_MSI:\r\nenic_isr_msi(enic->pdev->irq, enic);\r\nbreak;\r\ncase VNIC_DEV_INTR_MODE_INTX:\r\nenic_isr_legacy(enic->pdev->irq, netdev);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nstatic int enic_dev_wait(struct vnic_dev *vdev,\r\nint (*start)(struct vnic_dev *, int),\r\nint (*finished)(struct vnic_dev *, int *),\r\nint arg)\r\n{\r\nunsigned long time;\r\nint done;\r\nint err;\r\nBUG_ON(in_interrupt());\r\nerr = start(vdev, arg);\r\nif (err)\r\nreturn err;\r\ntime = jiffies + (HZ * 2);\r\ndo {\r\nerr = finished(vdev, &done);\r\nif (err)\r\nreturn err;\r\nif (done)\r\nreturn 0;\r\nschedule_timeout_uninterruptible(HZ / 10);\r\n} while (time_after(time, jiffies));\r\nreturn -ETIMEDOUT;\r\n}\r\nstatic int enic_dev_open(struct enic *enic)\r\n{\r\nint err;\r\nerr = enic_dev_wait(enic->vdev, vnic_dev_open,\r\nvnic_dev_open_done, 0);\r\nif (err)\r\ndev_err(enic_get_dev(enic), "vNIC device open failed, err %d\n",\r\nerr);\r\nreturn err;\r\n}\r\nstatic int enic_dev_hang_reset(struct enic *enic)\r\n{\r\nint err;\r\nerr = enic_dev_wait(enic->vdev, vnic_dev_hang_reset,\r\nvnic_dev_hang_reset_done, 0);\r\nif (err)\r\nnetdev_err(enic->netdev, "vNIC hang reset failed, err %d\n",\r\nerr);\r\nreturn err;\r\n}\r\nstatic int enic_set_rsskey(struct enic *enic)\r\n{\r\ndma_addr_t rss_key_buf_pa;\r\nunion vnic_rss_key *rss_key_buf_va = NULL;\r\nunion vnic_rss_key rss_key = {\r\n.key[0].b = {85, 67, 83, 97, 119, 101, 115, 111, 109, 101},\r\n.key[1].b = {80, 65, 76, 79, 117, 110, 105, 113, 117, 101},\r\n.key[2].b = {76, 73, 78, 85, 88, 114, 111, 99, 107, 115},\r\n.key[3].b = {69, 78, 73, 67, 105, 115, 99, 111, 111, 108},\r\n};\r\nint err;\r\nrss_key_buf_va = pci_alloc_consistent(enic->pdev,\r\nsizeof(union vnic_rss_key), &rss_key_buf_pa);\r\nif (!rss_key_buf_va)\r\nreturn -ENOMEM;\r\nmemcpy(rss_key_buf_va, &rss_key, sizeof(union vnic_rss_key));\r\nspin_lock(&enic->devcmd_lock);\r\nerr = enic_set_rss_key(enic,\r\nrss_key_buf_pa,\r\nsizeof(union vnic_rss_key));\r\nspin_unlock(&enic->devcmd_lock);\r\npci_free_consistent(enic->pdev, sizeof(union vnic_rss_key),\r\nrss_key_buf_va, rss_key_buf_pa);\r\nreturn err;\r\n}\r\nstatic int enic_set_rsscpu(struct enic *enic, u8 rss_hash_bits)\r\n{\r\ndma_addr_t rss_cpu_buf_pa;\r\nunion vnic_rss_cpu *rss_cpu_buf_va = NULL;\r\nunsigned int i;\r\nint err;\r\nrss_cpu_buf_va = pci_alloc_consistent(enic->pdev,\r\nsizeof(union vnic_rss_cpu), &rss_cpu_buf_pa);\r\nif (!rss_cpu_buf_va)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < (1 << rss_hash_bits); i++)\r\n(*rss_cpu_buf_va).cpu[i/4].b[i%4] = i % enic->rq_count;\r\nspin_lock(&enic->devcmd_lock);\r\nerr = enic_set_rss_cpu(enic,\r\nrss_cpu_buf_pa,\r\nsizeof(union vnic_rss_cpu));\r\nspin_unlock(&enic->devcmd_lock);\r\npci_free_consistent(enic->pdev, sizeof(union vnic_rss_cpu),\r\nrss_cpu_buf_va, rss_cpu_buf_pa);\r\nreturn err;\r\n}\r\nstatic int enic_set_niccfg(struct enic *enic, u8 rss_default_cpu,\r\nu8 rss_hash_type, u8 rss_hash_bits, u8 rss_base_cpu, u8 rss_enable)\r\n{\r\nconst u8 tso_ipid_split_en = 0;\r\nconst u8 ig_vlan_strip_en = 1;\r\nint err;\r\nspin_lock(&enic->devcmd_lock);\r\nerr = enic_set_nic_cfg(enic,\r\nrss_default_cpu, rss_hash_type,\r\nrss_hash_bits, rss_base_cpu,\r\nrss_enable, tso_ipid_split_en,\r\nig_vlan_strip_en);\r\nspin_unlock(&enic->devcmd_lock);\r\nreturn err;\r\n}\r\nstatic int enic_set_rss_nic_cfg(struct enic *enic)\r\n{\r\nstruct device *dev = enic_get_dev(enic);\r\nconst u8 rss_default_cpu = 0;\r\nconst u8 rss_hash_type = NIC_CFG_RSS_HASH_TYPE_IPV4 |\r\nNIC_CFG_RSS_HASH_TYPE_TCP_IPV4 |\r\nNIC_CFG_RSS_HASH_TYPE_IPV6 |\r\nNIC_CFG_RSS_HASH_TYPE_TCP_IPV6;\r\nconst u8 rss_hash_bits = 7;\r\nconst u8 rss_base_cpu = 0;\r\nu8 rss_enable = ENIC_SETTING(enic, RSS) && (enic->rq_count > 1);\r\nif (rss_enable) {\r\nif (!enic_set_rsskey(enic)) {\r\nif (enic_set_rsscpu(enic, rss_hash_bits)) {\r\nrss_enable = 0;\r\ndev_warn(dev, "RSS disabled, "\r\n"Failed to set RSS cpu indirection table.");\r\n}\r\n} else {\r\nrss_enable = 0;\r\ndev_warn(dev, "RSS disabled, Failed to set RSS key.\n");\r\n}\r\n}\r\nreturn enic_set_niccfg(enic, rss_default_cpu, rss_hash_type,\r\nrss_hash_bits, rss_base_cpu, rss_enable);\r\n}\r\nstatic void enic_reset(struct work_struct *work)\r\n{\r\nstruct enic *enic = container_of(work, struct enic, reset);\r\nif (!netif_running(enic->netdev))\r\nreturn;\r\nrtnl_lock();\r\nenic_dev_hang_notify(enic);\r\nenic_stop(enic->netdev);\r\nenic_dev_hang_reset(enic);\r\nenic_reset_addr_lists(enic);\r\nenic_init_vnic_resources(enic);\r\nenic_set_rss_nic_cfg(enic);\r\nenic_dev_set_ig_vlan_rewrite_mode(enic);\r\nenic_open(enic->netdev);\r\nrtnl_unlock();\r\n}\r\nstatic int enic_set_intr_mode(struct enic *enic)\r\n{\r\nunsigned int n = min_t(unsigned int, enic->rq_count, ENIC_RQ_MAX);\r\nunsigned int m = min_t(unsigned int, enic->wq_count, ENIC_WQ_MAX);\r\nunsigned int i;\r\nBUG_ON(ARRAY_SIZE(enic->msix_entry) < n + m + 2);\r\nfor (i = 0; i < n + m + 2; i++)\r\nenic->msix_entry[i].entry = i;\r\nif (ENIC_SETTING(enic, RSS) &&\r\nenic->config.intr_mode < 1 &&\r\nenic->rq_count >= n &&\r\nenic->wq_count >= m &&\r\nenic->cq_count >= n + m &&\r\nenic->intr_count >= n + m + 2) {\r\nif (!pci_enable_msix(enic->pdev, enic->msix_entry, n + m + 2)) {\r\nenic->rq_count = n;\r\nenic->wq_count = m;\r\nenic->cq_count = n + m;\r\nenic->intr_count = n + m + 2;\r\nvnic_dev_set_intr_mode(enic->vdev,\r\nVNIC_DEV_INTR_MODE_MSIX);\r\nreturn 0;\r\n}\r\n}\r\nif (enic->config.intr_mode < 1 &&\r\nenic->rq_count >= 1 &&\r\nenic->wq_count >= m &&\r\nenic->cq_count >= 1 + m &&\r\nenic->intr_count >= 1 + m + 2) {\r\nif (!pci_enable_msix(enic->pdev, enic->msix_entry, 1 + m + 2)) {\r\nenic->rq_count = 1;\r\nenic->wq_count = m;\r\nenic->cq_count = 1 + m;\r\nenic->intr_count = 1 + m + 2;\r\nvnic_dev_set_intr_mode(enic->vdev,\r\nVNIC_DEV_INTR_MODE_MSIX);\r\nreturn 0;\r\n}\r\n}\r\nif (enic->config.intr_mode < 2 &&\r\nenic->rq_count >= 1 &&\r\nenic->wq_count >= 1 &&\r\nenic->cq_count >= 2 &&\r\nenic->intr_count >= 1 &&\r\n!pci_enable_msi(enic->pdev)) {\r\nenic->rq_count = 1;\r\nenic->wq_count = 1;\r\nenic->cq_count = 2;\r\nenic->intr_count = 1;\r\nvnic_dev_set_intr_mode(enic->vdev, VNIC_DEV_INTR_MODE_MSI);\r\nreturn 0;\r\n}\r\nif (enic->config.intr_mode < 3 &&\r\nenic->rq_count >= 1 &&\r\nenic->wq_count >= 1 &&\r\nenic->cq_count >= 2 &&\r\nenic->intr_count >= 3) {\r\nenic->rq_count = 1;\r\nenic->wq_count = 1;\r\nenic->cq_count = 2;\r\nenic->intr_count = 3;\r\nvnic_dev_set_intr_mode(enic->vdev, VNIC_DEV_INTR_MODE_INTX);\r\nreturn 0;\r\n}\r\nvnic_dev_set_intr_mode(enic->vdev, VNIC_DEV_INTR_MODE_UNKNOWN);\r\nreturn -EINVAL;\r\n}\r\nstatic void enic_clear_intr_mode(struct enic *enic)\r\n{\r\nswitch (vnic_dev_get_intr_mode(enic->vdev)) {\r\ncase VNIC_DEV_INTR_MODE_MSIX:\r\npci_disable_msix(enic->pdev);\r\nbreak;\r\ncase VNIC_DEV_INTR_MODE_MSI:\r\npci_disable_msi(enic->pdev);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nvnic_dev_set_intr_mode(enic->vdev, VNIC_DEV_INTR_MODE_UNKNOWN);\r\n}\r\nstatic void enic_dev_deinit(struct enic *enic)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < enic->rq_count; i++)\r\nnetif_napi_del(&enic->napi[i]);\r\nenic_free_vnic_resources(enic);\r\nenic_clear_intr_mode(enic);\r\n}\r\nstatic int enic_dev_init(struct enic *enic)\r\n{\r\nstruct device *dev = enic_get_dev(enic);\r\nstruct net_device *netdev = enic->netdev;\r\nunsigned int i;\r\nint err;\r\nerr = enic_dev_intr_coal_timer_info(enic);\r\nif (err) {\r\ndev_warn(dev, "Using default conversion factor for "\r\n"interrupt coalesce timer\n");\r\nvnic_dev_intr_coal_timer_info_default(enic->vdev);\r\n}\r\nerr = enic_get_vnic_config(enic);\r\nif (err) {\r\ndev_err(dev, "Get vNIC configuration failed, aborting\n");\r\nreturn err;\r\n}\r\nenic_get_res_counts(enic);\r\nerr = enic_set_intr_mode(enic);\r\nif (err) {\r\ndev_err(dev, "Failed to set intr mode based on resource "\r\n"counts and system capabilities, aborting\n");\r\nreturn err;\r\n}\r\nerr = enic_alloc_vnic_resources(enic);\r\nif (err) {\r\ndev_err(dev, "Failed to alloc vNIC resources, aborting\n");\r\ngoto err_out_free_vnic_resources;\r\n}\r\nenic_init_vnic_resources(enic);\r\nerr = enic_set_rss_nic_cfg(enic);\r\nif (err) {\r\ndev_err(dev, "Failed to config nic, aborting\n");\r\ngoto err_out_free_vnic_resources;\r\n}\r\nswitch (vnic_dev_get_intr_mode(enic->vdev)) {\r\ndefault:\r\nnetif_napi_add(netdev, &enic->napi[0], enic_poll, 64);\r\nbreak;\r\ncase VNIC_DEV_INTR_MODE_MSIX:\r\nfor (i = 0; i < enic->rq_count; i++)\r\nnetif_napi_add(netdev, &enic->napi[i],\r\nenic_poll_msix, 64);\r\nbreak;\r\n}\r\nreturn 0;\r\nerr_out_free_vnic_resources:\r\nenic_clear_intr_mode(enic);\r\nenic_free_vnic_resources(enic);\r\nreturn err;\r\n}\r\nstatic void enic_iounmap(struct enic *enic)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < ARRAY_SIZE(enic->bar); i++)\r\nif (enic->bar[i].vaddr)\r\niounmap(enic->bar[i].vaddr);\r\n}\r\nstatic int __devinit enic_probe(struct pci_dev *pdev,\r\nconst struct pci_device_id *ent)\r\n{\r\nstruct device *dev = &pdev->dev;\r\nstruct net_device *netdev;\r\nstruct enic *enic;\r\nint using_dac = 0;\r\nunsigned int i;\r\nint err;\r\n#ifdef CONFIG_PCI_IOV\r\nint pos = 0;\r\n#endif\r\nint num_pps = 1;\r\nnetdev = alloc_etherdev(sizeof(struct enic));\r\nif (!netdev)\r\nreturn -ENOMEM;\r\npci_set_drvdata(pdev, netdev);\r\nSET_NETDEV_DEV(netdev, &pdev->dev);\r\nenic = netdev_priv(netdev);\r\nenic->netdev = netdev;\r\nenic->pdev = pdev;\r\nerr = pci_enable_device_mem(pdev);\r\nif (err) {\r\ndev_err(dev, "Cannot enable PCI device, aborting\n");\r\ngoto err_out_free_netdev;\r\n}\r\nerr = pci_request_regions(pdev, DRV_NAME);\r\nif (err) {\r\ndev_err(dev, "Cannot request PCI regions, aborting\n");\r\ngoto err_out_disable_device;\r\n}\r\npci_set_master(pdev);\r\nerr = pci_set_dma_mask(pdev, DMA_BIT_MASK(40));\r\nif (err) {\r\nerr = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (err) {\r\ndev_err(dev, "No usable DMA configuration, aborting\n");\r\ngoto err_out_release_regions;\r\n}\r\nerr = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (err) {\r\ndev_err(dev, "Unable to obtain %u-bit DMA "\r\n"for consistent allocations, aborting\n", 32);\r\ngoto err_out_release_regions;\r\n}\r\n} else {\r\nerr = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(40));\r\nif (err) {\r\ndev_err(dev, "Unable to obtain %u-bit DMA "\r\n"for consistent allocations, aborting\n", 40);\r\ngoto err_out_release_regions;\r\n}\r\nusing_dac = 1;\r\n}\r\nfor (i = 0; i < ARRAY_SIZE(enic->bar); i++) {\r\nif (!(pci_resource_flags(pdev, i) & IORESOURCE_MEM))\r\ncontinue;\r\nenic->bar[i].len = pci_resource_len(pdev, i);\r\nenic->bar[i].vaddr = pci_iomap(pdev, i, enic->bar[i].len);\r\nif (!enic->bar[i].vaddr) {\r\ndev_err(dev, "Cannot memory-map BAR %d, aborting\n", i);\r\nerr = -ENODEV;\r\ngoto err_out_iounmap;\r\n}\r\nenic->bar[i].bus_addr = pci_resource_start(pdev, i);\r\n}\r\nenic->vdev = vnic_dev_register(NULL, enic, pdev, enic->bar,\r\nARRAY_SIZE(enic->bar));\r\nif (!enic->vdev) {\r\ndev_err(dev, "vNIC registration failed, aborting\n");\r\nerr = -ENODEV;\r\ngoto err_out_iounmap;\r\n}\r\n#ifdef CONFIG_PCI_IOV\r\npos = pci_find_ext_capability(pdev, PCI_EXT_CAP_ID_SRIOV);\r\nif (pos) {\r\npci_read_config_word(pdev, pos + PCI_SRIOV_TOTAL_VF,\r\n&enic->num_vfs);\r\nif (enic->num_vfs) {\r\nerr = pci_enable_sriov(pdev, enic->num_vfs);\r\nif (err) {\r\ndev_err(dev, "SRIOV enable failed, aborting."\r\n" pci_enable_sriov() returned %d\n",\r\nerr);\r\ngoto err_out_vnic_unregister;\r\n}\r\nenic->priv_flags |= ENIC_SRIOV_ENABLED;\r\nnum_pps = enic->num_vfs;\r\n}\r\n}\r\n#endif\r\nenic->pp = kcalloc(num_pps, sizeof(*enic->pp), GFP_KERNEL);\r\nif (!enic->pp) {\r\nerr = -ENOMEM;\r\ngoto err_out_disable_sriov_pp;\r\n}\r\nerr = enic_dev_open(enic);\r\nif (err) {\r\ndev_err(dev, "vNIC dev open failed, aborting\n");\r\ngoto err_out_disable_sriov;\r\n}\r\nspin_lock_init(&enic->devcmd_lock);\r\nerr = enic_dev_set_ig_vlan_rewrite_mode(enic);\r\nif (err) {\r\ndev_err(dev,\r\n"Failed to set ingress vlan rewrite mode, aborting.\n");\r\ngoto err_out_dev_close;\r\n}\r\nnetif_carrier_off(netdev);\r\nif (!enic_is_dynamic(enic)) {\r\nerr = vnic_dev_init(enic->vdev, 0);\r\nif (err) {\r\ndev_err(dev, "vNIC dev init failed, aborting\n");\r\ngoto err_out_dev_close;\r\n}\r\n}\r\nerr = enic_dev_init(enic);\r\nif (err) {\r\ndev_err(dev, "Device initialization failed, aborting\n");\r\ngoto err_out_dev_close;\r\n}\r\ninit_timer(&enic->notify_timer);\r\nenic->notify_timer.function = enic_notify_timer;\r\nenic->notify_timer.data = (unsigned long)enic;\r\nINIT_WORK(&enic->reset, enic_reset);\r\nINIT_WORK(&enic->change_mtu_work, enic_change_mtu_work);\r\nfor (i = 0; i < enic->wq_count; i++)\r\nspin_lock_init(&enic->wq_lock[i]);\r\nenic->port_mtu = enic->config.mtu;\r\n(void)enic_change_mtu(netdev, enic->port_mtu);\r\nerr = enic_set_mac_addr(netdev, enic->mac_addr);\r\nif (err) {\r\ndev_err(dev, "Invalid MAC address, aborting\n");\r\ngoto err_out_dev_deinit;\r\n}\r\nenic->tx_coalesce_usecs = enic->config.intr_timer_usec;\r\nenic->rx_coalesce_usecs = enic->tx_coalesce_usecs;\r\nif (enic_is_dynamic(enic) || enic_is_sriov_vf(enic))\r\nnetdev->netdev_ops = &enic_netdev_dynamic_ops;\r\nelse\r\nnetdev->netdev_ops = &enic_netdev_ops;\r\nnetdev->watchdog_timeo = 2 * HZ;\r\nnetdev->ethtool_ops = &enic_ethtool_ops;\r\nnetdev->features |= NETIF_F_HW_VLAN_TX | NETIF_F_HW_VLAN_RX;\r\nif (ENIC_SETTING(enic, LOOP)) {\r\nnetdev->features &= ~NETIF_F_HW_VLAN_TX;\r\nenic->loop_enable = 1;\r\nenic->loop_tag = enic->config.loop_tag;\r\ndev_info(dev, "loopback tag=0x%04x\n", enic->loop_tag);\r\n}\r\nif (ENIC_SETTING(enic, TXCSUM))\r\nnetdev->hw_features |= NETIF_F_SG | NETIF_F_HW_CSUM;\r\nif (ENIC_SETTING(enic, TSO))\r\nnetdev->hw_features |= NETIF_F_TSO |\r\nNETIF_F_TSO6 | NETIF_F_TSO_ECN;\r\nif (ENIC_SETTING(enic, RXCSUM))\r\nnetdev->hw_features |= NETIF_F_RXCSUM;\r\nnetdev->features |= netdev->hw_features;\r\nif (using_dac)\r\nnetdev->features |= NETIF_F_HIGHDMA;\r\nnetdev->priv_flags |= IFF_UNICAST_FLT;\r\nerr = register_netdev(netdev);\r\nif (err) {\r\ndev_err(dev, "Cannot register net device, aborting\n");\r\ngoto err_out_dev_deinit;\r\n}\r\nreturn 0;\r\nerr_out_dev_deinit:\r\nenic_dev_deinit(enic);\r\nerr_out_dev_close:\r\nvnic_dev_close(enic->vdev);\r\nerr_out_disable_sriov:\r\nkfree(enic->pp);\r\nerr_out_disable_sriov_pp:\r\n#ifdef CONFIG_PCI_IOV\r\nif (enic_sriov_enabled(enic)) {\r\npci_disable_sriov(pdev);\r\nenic->priv_flags &= ~ENIC_SRIOV_ENABLED;\r\n}\r\nerr_out_vnic_unregister:\r\n#endif\r\nvnic_dev_unregister(enic->vdev);\r\nerr_out_iounmap:\r\nenic_iounmap(enic);\r\nerr_out_release_regions:\r\npci_release_regions(pdev);\r\nerr_out_disable_device:\r\npci_disable_device(pdev);\r\nerr_out_free_netdev:\r\npci_set_drvdata(pdev, NULL);\r\nfree_netdev(netdev);\r\nreturn err;\r\n}\r\nstatic void __devexit enic_remove(struct pci_dev *pdev)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nif (netdev) {\r\nstruct enic *enic = netdev_priv(netdev);\r\ncancel_work_sync(&enic->reset);\r\ncancel_work_sync(&enic->change_mtu_work);\r\nunregister_netdev(netdev);\r\nenic_dev_deinit(enic);\r\nvnic_dev_close(enic->vdev);\r\n#ifdef CONFIG_PCI_IOV\r\nif (enic_sriov_enabled(enic)) {\r\npci_disable_sriov(pdev);\r\nenic->priv_flags &= ~ENIC_SRIOV_ENABLED;\r\n}\r\n#endif\r\nkfree(enic->pp);\r\nvnic_dev_unregister(enic->vdev);\r\nenic_iounmap(enic);\r\npci_release_regions(pdev);\r\npci_disable_device(pdev);\r\npci_set_drvdata(pdev, NULL);\r\nfree_netdev(netdev);\r\n}\r\n}\r\nstatic int __init enic_init_module(void)\r\n{\r\npr_info("%s, ver %s\n", DRV_DESCRIPTION, DRV_VERSION);\r\nreturn pci_register_driver(&enic_driver);\r\n}\r\nstatic void __exit enic_cleanup_module(void)\r\n{\r\npci_unregister_driver(&enic_driver);\r\n}
