static void ntoh_seq(struct ip_vs_seq *no, struct ip_vs_seq *ho)\r\n{\r\nho->init_seq = get_unaligned_be32(&no->init_seq);\r\nho->delta = get_unaligned_be32(&no->delta);\r\nho->previous_delta = get_unaligned_be32(&no->previous_delta);\r\n}\r\nstatic void hton_seq(struct ip_vs_seq *ho, struct ip_vs_seq *no)\r\n{\r\nput_unaligned_be32(ho->init_seq, &no->init_seq);\r\nput_unaligned_be32(ho->delta, &no->delta);\r\nput_unaligned_be32(ho->previous_delta, &no->previous_delta);\r\n}\r\nstatic inline struct ip_vs_sync_buff *\r\nsb_dequeue(struct netns_ipvs *ipvs, struct ipvs_master_sync_state *ms)\r\n{\r\nstruct ip_vs_sync_buff *sb;\r\nspin_lock_bh(&ipvs->sync_lock);\r\nif (list_empty(&ms->sync_queue)) {\r\nsb = NULL;\r\n__set_current_state(TASK_INTERRUPTIBLE);\r\n} else {\r\nsb = list_entry(ms->sync_queue.next, struct ip_vs_sync_buff,\r\nlist);\r\nlist_del(&sb->list);\r\nms->sync_queue_len--;\r\nif (!ms->sync_queue_len)\r\nms->sync_queue_delay = 0;\r\n}\r\nspin_unlock_bh(&ipvs->sync_lock);\r\nreturn sb;\r\n}\r\nstatic inline struct ip_vs_sync_buff *\r\nip_vs_sync_buff_create(struct netns_ipvs *ipvs)\r\n{\r\nstruct ip_vs_sync_buff *sb;\r\nif (!(sb=kmalloc(sizeof(struct ip_vs_sync_buff), GFP_ATOMIC)))\r\nreturn NULL;\r\nsb->mesg = kmalloc(ipvs->send_mesg_maxlen, GFP_ATOMIC);\r\nif (!sb->mesg) {\r\nkfree(sb);\r\nreturn NULL;\r\n}\r\nsb->mesg->reserved = 0;\r\nsb->mesg->version = SYNC_PROTO_VER;\r\nsb->mesg->syncid = ipvs->master_syncid;\r\nsb->mesg->size = sizeof(struct ip_vs_sync_mesg);\r\nsb->mesg->nr_conns = 0;\r\nsb->mesg->spare = 0;\r\nsb->head = (unsigned char *)sb->mesg + sizeof(struct ip_vs_sync_mesg);\r\nsb->end = (unsigned char *)sb->mesg + ipvs->send_mesg_maxlen;\r\nsb->firstuse = jiffies;\r\nreturn sb;\r\n}\r\nstatic inline void ip_vs_sync_buff_release(struct ip_vs_sync_buff *sb)\r\n{\r\nkfree(sb->mesg);\r\nkfree(sb);\r\n}\r\nstatic inline void sb_queue_tail(struct netns_ipvs *ipvs,\r\nstruct ipvs_master_sync_state *ms)\r\n{\r\nstruct ip_vs_sync_buff *sb = ms->sync_buff;\r\nspin_lock(&ipvs->sync_lock);\r\nif (ipvs->sync_state & IP_VS_STATE_MASTER &&\r\nms->sync_queue_len < sysctl_sync_qlen_max(ipvs)) {\r\nif (!ms->sync_queue_len)\r\nschedule_delayed_work(&ms->master_wakeup_work,\r\nmax(IPVS_SYNC_SEND_DELAY, 1));\r\nms->sync_queue_len++;\r\nlist_add_tail(&sb->list, &ms->sync_queue);\r\nif ((++ms->sync_queue_delay) == IPVS_SYNC_WAKEUP_RATE)\r\nwake_up_process(ms->master_thread);\r\n} else\r\nip_vs_sync_buff_release(sb);\r\nspin_unlock(&ipvs->sync_lock);\r\n}\r\nstatic inline struct ip_vs_sync_buff *\r\nget_curr_sync_buff(struct netns_ipvs *ipvs, struct ipvs_master_sync_state *ms,\r\nunsigned long time)\r\n{\r\nstruct ip_vs_sync_buff *sb;\r\nspin_lock_bh(&ipvs->sync_buff_lock);\r\nsb = ms->sync_buff;\r\nif (sb && time_after_eq(jiffies - sb->firstuse, time)) {\r\nms->sync_buff = NULL;\r\n__set_current_state(TASK_RUNNING);\r\n} else\r\nsb = NULL;\r\nspin_unlock_bh(&ipvs->sync_buff_lock);\r\nreturn sb;\r\n}\r\nstatic inline int\r\nselect_master_thread_id(struct netns_ipvs *ipvs, struct ip_vs_conn *cp)\r\n{\r\nreturn ((long) cp >> (1 + ilog2(sizeof(*cp)))) & ipvs->threads_mask;\r\n}\r\nstatic inline struct ip_vs_sync_buff *\r\nip_vs_sync_buff_create_v0(struct netns_ipvs *ipvs)\r\n{\r\nstruct ip_vs_sync_buff *sb;\r\nstruct ip_vs_sync_mesg_v0 *mesg;\r\nif (!(sb=kmalloc(sizeof(struct ip_vs_sync_buff), GFP_ATOMIC)))\r\nreturn NULL;\r\nsb->mesg = kmalloc(ipvs->send_mesg_maxlen, GFP_ATOMIC);\r\nif (!sb->mesg) {\r\nkfree(sb);\r\nreturn NULL;\r\n}\r\nmesg = (struct ip_vs_sync_mesg_v0 *)sb->mesg;\r\nmesg->nr_conns = 0;\r\nmesg->syncid = ipvs->master_syncid;\r\nmesg->size = sizeof(struct ip_vs_sync_mesg_v0);\r\nsb->head = (unsigned char *)mesg + sizeof(struct ip_vs_sync_mesg_v0);\r\nsb->end = (unsigned char *)mesg + ipvs->send_mesg_maxlen;\r\nsb->firstuse = jiffies;\r\nreturn sb;\r\n}\r\nstatic int ip_vs_sync_conn_needed(struct netns_ipvs *ipvs,\r\nstruct ip_vs_conn *cp, int pkts)\r\n{\r\nunsigned long orig = ACCESS_ONCE(cp->sync_endtime);\r\nunsigned long now = jiffies;\r\nunsigned long n = (now + cp->timeout) & ~3UL;\r\nunsigned int sync_refresh_period;\r\nint sync_period;\r\nint force;\r\nif (unlikely(cp->flags & IP_VS_CONN_F_TEMPLATE))\r\nforce = 0;\r\nelse if (likely(cp->protocol == IPPROTO_TCP)) {\r\nif (!((1 << cp->state) &\r\n((1 << IP_VS_TCP_S_ESTABLISHED) |\r\n(1 << IP_VS_TCP_S_FIN_WAIT) |\r\n(1 << IP_VS_TCP_S_CLOSE) |\r\n(1 << IP_VS_TCP_S_CLOSE_WAIT) |\r\n(1 << IP_VS_TCP_S_TIME_WAIT))))\r\nreturn 0;\r\nforce = cp->state != cp->old_state;\r\nif (force && cp->state != IP_VS_TCP_S_ESTABLISHED)\r\ngoto set;\r\n} else if (unlikely(cp->protocol == IPPROTO_SCTP)) {\r\nif (!((1 << cp->state) &\r\n((1 << IP_VS_SCTP_S_ESTABLISHED) |\r\n(1 << IP_VS_SCTP_S_CLOSED) |\r\n(1 << IP_VS_SCTP_S_SHUT_ACK_CLI) |\r\n(1 << IP_VS_SCTP_S_SHUT_ACK_SER))))\r\nreturn 0;\r\nforce = cp->state != cp->old_state;\r\nif (force && cp->state != IP_VS_SCTP_S_ESTABLISHED)\r\ngoto set;\r\n} else {\r\nforce = 0;\r\n}\r\nsync_refresh_period = sysctl_sync_refresh_period(ipvs);\r\nif (sync_refresh_period > 0) {\r\nlong diff = n - orig;\r\nlong min_diff = max(cp->timeout >> 1, 10UL * HZ);\r\nif (abs(diff) < min_t(long, sync_refresh_period, min_diff)) {\r\nint retries = orig & 3;\r\nif (retries >= sysctl_sync_retries(ipvs))\r\nreturn 0;\r\nif (time_before(now, orig - cp->timeout +\r\n(sync_refresh_period >> 3)))\r\nreturn 0;\r\nn |= retries + 1;\r\n}\r\n}\r\nsync_period = sysctl_sync_period(ipvs);\r\nif (sync_period > 0) {\r\nif (!(cp->flags & IP_VS_CONN_F_TEMPLATE) &&\r\npkts % sync_period != sysctl_sync_threshold(ipvs))\r\nreturn 0;\r\n} else if (sync_refresh_period <= 0 &&\r\npkts != sysctl_sync_threshold(ipvs))\r\nreturn 0;\r\nset:\r\ncp->old_state = cp->state;\r\nn = cmpxchg(&cp->sync_endtime, orig, n);\r\nreturn n == orig || force;\r\n}\r\nstatic void ip_vs_sync_conn_v0(struct net *net, struct ip_vs_conn *cp,\r\nint pkts)\r\n{\r\nstruct netns_ipvs *ipvs = net_ipvs(net);\r\nstruct ip_vs_sync_mesg_v0 *m;\r\nstruct ip_vs_sync_conn_v0 *s;\r\nstruct ip_vs_sync_buff *buff;\r\nstruct ipvs_master_sync_state *ms;\r\nint id;\r\nint len;\r\nif (unlikely(cp->af != AF_INET))\r\nreturn;\r\nif (cp->flags & IP_VS_CONN_F_ONE_PACKET)\r\nreturn;\r\nif (!ip_vs_sync_conn_needed(ipvs, cp, pkts))\r\nreturn;\r\nspin_lock(&ipvs->sync_buff_lock);\r\nif (!(ipvs->sync_state & IP_VS_STATE_MASTER)) {\r\nspin_unlock(&ipvs->sync_buff_lock);\r\nreturn;\r\n}\r\nid = select_master_thread_id(ipvs, cp);\r\nms = &ipvs->ms[id];\r\nbuff = ms->sync_buff;\r\nif (buff) {\r\nm = (struct ip_vs_sync_mesg_v0 *) buff->mesg;\r\nif (!m->nr_conns) {\r\nsb_queue_tail(ipvs, ms);\r\nms->sync_buff = NULL;\r\nbuff = NULL;\r\n}\r\n}\r\nif (!buff) {\r\nbuff = ip_vs_sync_buff_create_v0(ipvs);\r\nif (!buff) {\r\nspin_unlock(&ipvs->sync_buff_lock);\r\npr_err("ip_vs_sync_buff_create failed.\n");\r\nreturn;\r\n}\r\nms->sync_buff = buff;\r\n}\r\nlen = (cp->flags & IP_VS_CONN_F_SEQ_MASK) ? FULL_CONN_SIZE :\r\nSIMPLE_CONN_SIZE;\r\nm = (struct ip_vs_sync_mesg_v0 *) buff->mesg;\r\ns = (struct ip_vs_sync_conn_v0 *) buff->head;\r\ns->reserved = 0;\r\ns->protocol = cp->protocol;\r\ns->cport = cp->cport;\r\ns->vport = cp->vport;\r\ns->dport = cp->dport;\r\ns->caddr = cp->caddr.ip;\r\ns->vaddr = cp->vaddr.ip;\r\ns->daddr = cp->daddr.ip;\r\ns->flags = htons(cp->flags & ~IP_VS_CONN_F_HASHED);\r\ns->state = htons(cp->state);\r\nif (cp->flags & IP_VS_CONN_F_SEQ_MASK) {\r\nstruct ip_vs_sync_conn_options *opt =\r\n(struct ip_vs_sync_conn_options *)&s[1];\r\nmemcpy(opt, &cp->in_seq, sizeof(*opt));\r\n}\r\nm->nr_conns++;\r\nm->size += len;\r\nbuff->head += len;\r\nif (buff->head + FULL_CONN_SIZE > buff->end) {\r\nsb_queue_tail(ipvs, ms);\r\nms->sync_buff = NULL;\r\n}\r\nspin_unlock(&ipvs->sync_buff_lock);\r\ncp = cp->control;\r\nif (cp) {\r\nif (cp->flags & IP_VS_CONN_F_TEMPLATE)\r\npkts = atomic_add_return(1, &cp->in_pkts);\r\nelse\r\npkts = sysctl_sync_threshold(ipvs);\r\nip_vs_sync_conn(net, cp->control, pkts);\r\n}\r\n}\r\nvoid ip_vs_sync_conn(struct net *net, struct ip_vs_conn *cp, int pkts)\r\n{\r\nstruct netns_ipvs *ipvs = net_ipvs(net);\r\nstruct ip_vs_sync_mesg *m;\r\nunion ip_vs_sync_conn *s;\r\nstruct ip_vs_sync_buff *buff;\r\nstruct ipvs_master_sync_state *ms;\r\nint id;\r\n__u8 *p;\r\nunsigned int len, pe_name_len, pad;\r\nif (sysctl_sync_ver(ipvs) == 0) {\r\nip_vs_sync_conn_v0(net, cp, pkts);\r\nreturn;\r\n}\r\nif (cp->flags & IP_VS_CONN_F_ONE_PACKET)\r\ngoto control;\r\nsloop:\r\nif (!ip_vs_sync_conn_needed(ipvs, cp, pkts))\r\ngoto control;\r\npe_name_len = 0;\r\nif (cp->pe_data_len) {\r\nif (!cp->pe_data || !cp->dest) {\r\nIP_VS_ERR_RL("SYNC, connection pe_data invalid\n");\r\nreturn;\r\n}\r\npe_name_len = strnlen(cp->pe->name, IP_VS_PENAME_MAXLEN);\r\n}\r\nspin_lock(&ipvs->sync_buff_lock);\r\nif (!(ipvs->sync_state & IP_VS_STATE_MASTER)) {\r\nspin_unlock(&ipvs->sync_buff_lock);\r\nreturn;\r\n}\r\nid = select_master_thread_id(ipvs, cp);\r\nms = &ipvs->ms[id];\r\n#ifdef CONFIG_IP_VS_IPV6\r\nif (cp->af == AF_INET6)\r\nlen = sizeof(struct ip_vs_sync_v6);\r\nelse\r\n#endif\r\nlen = sizeof(struct ip_vs_sync_v4);\r\nif (cp->flags & IP_VS_CONN_F_SEQ_MASK)\r\nlen += sizeof(struct ip_vs_sync_conn_options) + 2;\r\nif (cp->pe_data_len)\r\nlen += cp->pe_data_len + 2;\r\nif (pe_name_len)\r\nlen += pe_name_len + 2;\r\npad = 0;\r\nbuff = ms->sync_buff;\r\nif (buff) {\r\nm = buff->mesg;\r\npad = (4 - (size_t) buff->head) & 3;\r\nif (buff->head + len + pad > buff->end || m->reserved) {\r\nsb_queue_tail(ipvs, ms);\r\nms->sync_buff = NULL;\r\nbuff = NULL;\r\npad = 0;\r\n}\r\n}\r\nif (!buff) {\r\nbuff = ip_vs_sync_buff_create(ipvs);\r\nif (!buff) {\r\nspin_unlock(&ipvs->sync_buff_lock);\r\npr_err("ip_vs_sync_buff_create failed.\n");\r\nreturn;\r\n}\r\nms->sync_buff = buff;\r\nm = buff->mesg;\r\n}\r\np = buff->head;\r\nbuff->head += pad + len;\r\nm->size += pad + len;\r\nwhile (pad--)\r\n*(p++) = 0;\r\ns = (union ip_vs_sync_conn *)p;\r\ns->v4.type = (cp->af == AF_INET6 ? STYPE_F_INET6 : 0);\r\ns->v4.ver_size = htons(len & SVER_MASK);\r\ns->v4.flags = htonl(cp->flags & ~IP_VS_CONN_F_HASHED);\r\ns->v4.state = htons(cp->state);\r\ns->v4.protocol = cp->protocol;\r\ns->v4.cport = cp->cport;\r\ns->v4.vport = cp->vport;\r\ns->v4.dport = cp->dport;\r\ns->v4.fwmark = htonl(cp->fwmark);\r\ns->v4.timeout = htonl(cp->timeout / HZ);\r\nm->nr_conns++;\r\n#ifdef CONFIG_IP_VS_IPV6\r\nif (cp->af == AF_INET6) {\r\np += sizeof(struct ip_vs_sync_v6);\r\ns->v6.caddr = cp->caddr.in6;\r\ns->v6.vaddr = cp->vaddr.in6;\r\ns->v6.daddr = cp->daddr.in6;\r\n} else\r\n#endif\r\n{\r\np += sizeof(struct ip_vs_sync_v4);\r\ns->v4.caddr = cp->caddr.ip;\r\ns->v4.vaddr = cp->vaddr.ip;\r\ns->v4.daddr = cp->daddr.ip;\r\n}\r\nif (cp->flags & IP_VS_CONN_F_SEQ_MASK) {\r\n*(p++) = IPVS_OPT_SEQ_DATA;\r\n*(p++) = sizeof(struct ip_vs_sync_conn_options);\r\nhton_seq((struct ip_vs_seq *)p, &cp->in_seq);\r\np += sizeof(struct ip_vs_seq);\r\nhton_seq((struct ip_vs_seq *)p, &cp->out_seq);\r\np += sizeof(struct ip_vs_seq);\r\n}\r\nif (cp->pe_data_len && cp->pe_data) {\r\n*(p++) = IPVS_OPT_PE_DATA;\r\n*(p++) = cp->pe_data_len;\r\nmemcpy(p, cp->pe_data, cp->pe_data_len);\r\np += cp->pe_data_len;\r\nif (pe_name_len) {\r\n*(p++) = IPVS_OPT_PE_NAME;\r\n*(p++) = pe_name_len;\r\nmemcpy(p, cp->pe->name, pe_name_len);\r\np += pe_name_len;\r\n}\r\n}\r\nspin_unlock(&ipvs->sync_buff_lock);\r\ncontrol:\r\ncp = cp->control;\r\nif (!cp)\r\nreturn;\r\nif (cp->flags & IP_VS_CONN_F_TEMPLATE)\r\npkts = atomic_add_return(1, &cp->in_pkts);\r\nelse\r\npkts = sysctl_sync_threshold(ipvs);\r\ngoto sloop;\r\n}\r\nstatic inline int\r\nip_vs_conn_fill_param_sync(struct net *net, int af, union ip_vs_sync_conn *sc,\r\nstruct ip_vs_conn_param *p,\r\n__u8 *pe_data, unsigned int pe_data_len,\r\n__u8 *pe_name, unsigned int pe_name_len)\r\n{\r\n#ifdef CONFIG_IP_VS_IPV6\r\nif (af == AF_INET6)\r\nip_vs_conn_fill_param(net, af, sc->v6.protocol,\r\n(const union nf_inet_addr *)&sc->v6.caddr,\r\nsc->v6.cport,\r\n(const union nf_inet_addr *)&sc->v6.vaddr,\r\nsc->v6.vport, p);\r\nelse\r\n#endif\r\nip_vs_conn_fill_param(net, af, sc->v4.protocol,\r\n(const union nf_inet_addr *)&sc->v4.caddr,\r\nsc->v4.cport,\r\n(const union nf_inet_addr *)&sc->v4.vaddr,\r\nsc->v4.vport, p);\r\nif (pe_data_len) {\r\nif (pe_name_len) {\r\nchar buff[IP_VS_PENAME_MAXLEN+1];\r\nmemcpy(buff, pe_name, pe_name_len);\r\nbuff[pe_name_len]=0;\r\np->pe = __ip_vs_pe_getbyname(buff);\r\nif (!p->pe) {\r\nIP_VS_DBG(3, "BACKUP, no %s engine found/loaded\n",\r\nbuff);\r\nreturn 1;\r\n}\r\n} else {\r\nIP_VS_ERR_RL("BACKUP, Invalid PE parameters\n");\r\nreturn 1;\r\n}\r\np->pe_data = kmemdup(pe_data, pe_data_len, GFP_ATOMIC);\r\nif (!p->pe_data) {\r\nif (p->pe->module)\r\nmodule_put(p->pe->module);\r\nreturn -ENOMEM;\r\n}\r\np->pe_data_len = pe_data_len;\r\n}\r\nreturn 0;\r\n}\r\nstatic void ip_vs_proc_conn(struct net *net, struct ip_vs_conn_param *param,\r\nunsigned int flags, unsigned int state,\r\nunsigned int protocol, unsigned int type,\r\nconst union nf_inet_addr *daddr, __be16 dport,\r\nunsigned long timeout, __u32 fwmark,\r\nstruct ip_vs_sync_conn_options *opt)\r\n{\r\nstruct ip_vs_dest *dest;\r\nstruct ip_vs_conn *cp;\r\nstruct netns_ipvs *ipvs = net_ipvs(net);\r\nif (!(flags & IP_VS_CONN_F_TEMPLATE))\r\ncp = ip_vs_conn_in_get(param);\r\nelse\r\ncp = ip_vs_ct_in_get(param);\r\nif (cp) {\r\nkfree(param->pe_data);\r\ndest = cp->dest;\r\nspin_lock(&cp->lock);\r\nif ((cp->flags ^ flags) & IP_VS_CONN_F_INACTIVE &&\r\n!(flags & IP_VS_CONN_F_TEMPLATE) && dest) {\r\nif (flags & IP_VS_CONN_F_INACTIVE) {\r\natomic_dec(&dest->activeconns);\r\natomic_inc(&dest->inactconns);\r\n} else {\r\natomic_inc(&dest->activeconns);\r\natomic_dec(&dest->inactconns);\r\n}\r\n}\r\nflags &= IP_VS_CONN_F_BACKUP_UPD_MASK;\r\nflags |= cp->flags & ~IP_VS_CONN_F_BACKUP_UPD_MASK;\r\ncp->flags = flags;\r\nspin_unlock(&cp->lock);\r\nif (!dest) {\r\ndest = ip_vs_try_bind_dest(cp);\r\nif (dest)\r\natomic_dec(&dest->refcnt);\r\n}\r\n} else {\r\ndest = ip_vs_find_dest(net, type, daddr, dport, param->vaddr,\r\nparam->vport, protocol, fwmark, flags);\r\ncp = ip_vs_conn_new(param, daddr, dport, flags, dest, fwmark);\r\nif (dest)\r\natomic_dec(&dest->refcnt);\r\nif (!cp) {\r\nif (param->pe_data)\r\nkfree(param->pe_data);\r\nIP_VS_DBG(2, "BACKUP, add new conn. failed\n");\r\nreturn;\r\n}\r\n}\r\nif (opt)\r\nmemcpy(&cp->in_seq, opt, sizeof(*opt));\r\natomic_set(&cp->in_pkts, sysctl_sync_threshold(ipvs));\r\ncp->state = state;\r\ncp->old_state = cp->state;\r\nif (timeout) {\r\nif (timeout > MAX_SCHEDULE_TIMEOUT / HZ)\r\ntimeout = MAX_SCHEDULE_TIMEOUT / HZ;\r\ncp->timeout = timeout*HZ;\r\n} else {\r\nstruct ip_vs_proto_data *pd;\r\npd = ip_vs_proto_data_get(net, protocol);\r\nif (!(flags & IP_VS_CONN_F_TEMPLATE) && pd && pd->timeout_table)\r\ncp->timeout = pd->timeout_table[state];\r\nelse\r\ncp->timeout = (3*60*HZ);\r\n}\r\nip_vs_conn_put(cp);\r\n}\r\nstatic void ip_vs_process_message_v0(struct net *net, const char *buffer,\r\nconst size_t buflen)\r\n{\r\nstruct ip_vs_sync_mesg_v0 *m = (struct ip_vs_sync_mesg_v0 *)buffer;\r\nstruct ip_vs_sync_conn_v0 *s;\r\nstruct ip_vs_sync_conn_options *opt;\r\nstruct ip_vs_protocol *pp;\r\nstruct ip_vs_conn_param param;\r\nchar *p;\r\nint i;\r\np = (char *)buffer + sizeof(struct ip_vs_sync_mesg_v0);\r\nfor (i=0; i<m->nr_conns; i++) {\r\nunsigned int flags, state;\r\nif (p + SIMPLE_CONN_SIZE > buffer+buflen) {\r\nIP_VS_ERR_RL("BACKUP v0, bogus conn\n");\r\nreturn;\r\n}\r\ns = (struct ip_vs_sync_conn_v0 *) p;\r\nflags = ntohs(s->flags) | IP_VS_CONN_F_SYNC;\r\nflags &= ~IP_VS_CONN_F_HASHED;\r\nif (flags & IP_VS_CONN_F_SEQ_MASK) {\r\nopt = (struct ip_vs_sync_conn_options *)&s[1];\r\np += FULL_CONN_SIZE;\r\nif (p > buffer+buflen) {\r\nIP_VS_ERR_RL("BACKUP v0, Dropping buffer bogus conn options\n");\r\nreturn;\r\n}\r\n} else {\r\nopt = NULL;\r\np += SIMPLE_CONN_SIZE;\r\n}\r\nstate = ntohs(s->state);\r\nif (!(flags & IP_VS_CONN_F_TEMPLATE)) {\r\npp = ip_vs_proto_get(s->protocol);\r\nif (!pp) {\r\nIP_VS_DBG(2, "BACKUP v0, Unsupported protocol %u\n",\r\ns->protocol);\r\ncontinue;\r\n}\r\nif (state >= pp->num_states) {\r\nIP_VS_DBG(2, "BACKUP v0, Invalid %s state %u\n",\r\npp->name, state);\r\ncontinue;\r\n}\r\n} else {\r\nif (state > 0) {\r\nIP_VS_DBG(2, "BACKUP v0, Invalid template state %u\n",\r\nstate);\r\nstate = 0;\r\n}\r\n}\r\nip_vs_conn_fill_param(net, AF_INET, s->protocol,\r\n(const union nf_inet_addr *)&s->caddr,\r\ns->cport,\r\n(const union nf_inet_addr *)&s->vaddr,\r\ns->vport, &param);\r\nip_vs_proc_conn(net, &param, flags, state, s->protocol, AF_INET,\r\n(union nf_inet_addr *)&s->daddr, s->dport,\r\n0, 0, opt);\r\n}\r\n}\r\nstatic inline int ip_vs_proc_seqopt(__u8 *p, unsigned int plen,\r\n__u32 *opt_flags,\r\nstruct ip_vs_sync_conn_options *opt)\r\n{\r\nstruct ip_vs_sync_conn_options *topt;\r\ntopt = (struct ip_vs_sync_conn_options *)p;\r\nif (plen != sizeof(struct ip_vs_sync_conn_options)) {\r\nIP_VS_DBG(2, "BACKUP, bogus conn options length\n");\r\nreturn -EINVAL;\r\n}\r\nif (*opt_flags & IPVS_OPT_F_SEQ_DATA) {\r\nIP_VS_DBG(2, "BACKUP, conn options found twice\n");\r\nreturn -EINVAL;\r\n}\r\nntoh_seq(&topt->in_seq, &opt->in_seq);\r\nntoh_seq(&topt->out_seq, &opt->out_seq);\r\n*opt_flags |= IPVS_OPT_F_SEQ_DATA;\r\nreturn 0;\r\n}\r\nstatic int ip_vs_proc_str(__u8 *p, unsigned int plen, unsigned int *data_len,\r\n__u8 **data, unsigned int maxlen,\r\n__u32 *opt_flags, __u32 flag)\r\n{\r\nif (plen > maxlen) {\r\nIP_VS_DBG(2, "BACKUP, bogus par.data len > %d\n", maxlen);\r\nreturn -EINVAL;\r\n}\r\nif (*opt_flags & flag) {\r\nIP_VS_DBG(2, "BACKUP, Par.data found twice 0x%x\n", flag);\r\nreturn -EINVAL;\r\n}\r\n*data_len = plen;\r\n*data = p;\r\n*opt_flags |= flag;\r\nreturn 0;\r\n}\r\nstatic inline int ip_vs_proc_sync_conn(struct net *net, __u8 *p, __u8 *msg_end)\r\n{\r\nstruct ip_vs_sync_conn_options opt;\r\nunion ip_vs_sync_conn *s;\r\nstruct ip_vs_protocol *pp;\r\nstruct ip_vs_conn_param param;\r\n__u32 flags;\r\nunsigned int af, state, pe_data_len=0, pe_name_len=0;\r\n__u8 *pe_data=NULL, *pe_name=NULL;\r\n__u32 opt_flags=0;\r\nint retc=0;\r\ns = (union ip_vs_sync_conn *) p;\r\nif (s->v6.type & STYPE_F_INET6) {\r\n#ifdef CONFIG_IP_VS_IPV6\r\naf = AF_INET6;\r\np += sizeof(struct ip_vs_sync_v6);\r\n#else\r\nIP_VS_DBG(3,"BACKUP, IPv6 msg received, and IPVS is not compiled for IPv6\n");\r\nretc = 10;\r\ngoto out;\r\n#endif\r\n} else if (!s->v4.type) {\r\naf = AF_INET;\r\np += sizeof(struct ip_vs_sync_v4);\r\n} else {\r\nreturn -10;\r\n}\r\nif (p > msg_end)\r\nreturn -20;\r\nwhile (p < msg_end) {\r\nint ptype;\r\nint plen;\r\nif (p+2 > msg_end)\r\nreturn -30;\r\nptype = *(p++);\r\nplen = *(p++);\r\nif (!plen || ((p + plen) > msg_end))\r\nreturn -40;\r\nswitch (ptype & ~IPVS_OPT_F_PARAM) {\r\ncase IPVS_OPT_SEQ_DATA:\r\nif (ip_vs_proc_seqopt(p, plen, &opt_flags, &opt))\r\nreturn -50;\r\nbreak;\r\ncase IPVS_OPT_PE_DATA:\r\nif (ip_vs_proc_str(p, plen, &pe_data_len, &pe_data,\r\nIP_VS_PEDATA_MAXLEN, &opt_flags,\r\nIPVS_OPT_F_PE_DATA))\r\nreturn -60;\r\nbreak;\r\ncase IPVS_OPT_PE_NAME:\r\nif (ip_vs_proc_str(p, plen,&pe_name_len, &pe_name,\r\nIP_VS_PENAME_MAXLEN, &opt_flags,\r\nIPVS_OPT_F_PE_NAME))\r\nreturn -70;\r\nbreak;\r\ndefault:\r\nif (!(ptype & IPVS_OPT_F_PARAM)) {\r\nIP_VS_DBG(3, "BACKUP, Unknown mandatory param %d found\n",\r\nptype & ~IPVS_OPT_F_PARAM);\r\nretc = 20;\r\ngoto out;\r\n}\r\n}\r\np += plen;\r\n}\r\nflags = ntohl(s->v4.flags) & IP_VS_CONN_F_BACKUP_MASK;\r\nflags |= IP_VS_CONN_F_SYNC;\r\nstate = ntohs(s->v4.state);\r\nif (!(flags & IP_VS_CONN_F_TEMPLATE)) {\r\npp = ip_vs_proto_get(s->v4.protocol);\r\nif (!pp) {\r\nIP_VS_DBG(3,"BACKUP, Unsupported protocol %u\n",\r\ns->v4.protocol);\r\nretc = 30;\r\ngoto out;\r\n}\r\nif (state >= pp->num_states) {\r\nIP_VS_DBG(3, "BACKUP, Invalid %s state %u\n",\r\npp->name, state);\r\nretc = 40;\r\ngoto out;\r\n}\r\n} else {\r\nif (state > 0) {\r\nIP_VS_DBG(3, "BACKUP, Invalid template state %u\n",\r\nstate);\r\nstate = 0;\r\n}\r\n}\r\nif (ip_vs_conn_fill_param_sync(net, af, s, &param, pe_data,\r\npe_data_len, pe_name, pe_name_len)) {\r\nretc = 50;\r\ngoto out;\r\n}\r\nif (af == AF_INET)\r\nip_vs_proc_conn(net, &param, flags, state, s->v4.protocol, af,\r\n(union nf_inet_addr *)&s->v4.daddr, s->v4.dport,\r\nntohl(s->v4.timeout), ntohl(s->v4.fwmark),\r\n(opt_flags & IPVS_OPT_F_SEQ_DATA ? &opt : NULL)\r\n);\r\n#ifdef CONFIG_IP_VS_IPV6\r\nelse\r\nip_vs_proc_conn(net, &param, flags, state, s->v6.protocol, af,\r\n(union nf_inet_addr *)&s->v6.daddr, s->v6.dport,\r\nntohl(s->v6.timeout), ntohl(s->v6.fwmark),\r\n(opt_flags & IPVS_OPT_F_SEQ_DATA ? &opt : NULL)\r\n);\r\n#endif\r\nreturn 0;\r\nout:\r\nIP_VS_DBG(2, "BACKUP, Single msg dropped err:%d\n", retc);\r\nreturn retc;\r\n}\r\nstatic void ip_vs_process_message(struct net *net, __u8 *buffer,\r\nconst size_t buflen)\r\n{\r\nstruct netns_ipvs *ipvs = net_ipvs(net);\r\nstruct ip_vs_sync_mesg *m2 = (struct ip_vs_sync_mesg *)buffer;\r\n__u8 *p, *msg_end;\r\nint i, nr_conns;\r\nif (buflen < sizeof(struct ip_vs_sync_mesg_v0)) {\r\nIP_VS_DBG(2, "BACKUP, message header too short\n");\r\nreturn;\r\n}\r\nm2->size = ntohs(m2->size);\r\nif (buflen != m2->size) {\r\nIP_VS_DBG(2, "BACKUP, bogus message size\n");\r\nreturn;\r\n}\r\nif (ipvs->backup_syncid != 0 && m2->syncid != ipvs->backup_syncid) {\r\nIP_VS_DBG(7, "BACKUP, Ignoring syncid = %d\n", m2->syncid);\r\nreturn;\r\n}\r\nif ((m2->version == SYNC_PROTO_VER) && (m2->reserved == 0)\r\n&& (m2->spare == 0)) {\r\nmsg_end = buffer + sizeof(struct ip_vs_sync_mesg);\r\nnr_conns = m2->nr_conns;\r\nfor (i=0; i<nr_conns; i++) {\r\nunion ip_vs_sync_conn *s;\r\nunsigned int size;\r\nint retc;\r\np = msg_end;\r\nif (p + sizeof(s->v4) > buffer+buflen) {\r\nIP_VS_ERR_RL("BACKUP, Dropping buffer, to small\n");\r\nreturn;\r\n}\r\ns = (union ip_vs_sync_conn *)p;\r\nsize = ntohs(s->v4.ver_size) & SVER_MASK;\r\nmsg_end = p + size;\r\nif (msg_end > buffer+buflen) {\r\nIP_VS_ERR_RL("BACKUP, Dropping buffer, msg > buffer\n");\r\nreturn;\r\n}\r\nif (ntohs(s->v4.ver_size) >> SVER_SHIFT) {\r\nIP_VS_ERR_RL("BACKUP, Dropping buffer, Unknown version %d\n",\r\nntohs(s->v4.ver_size) >> SVER_SHIFT);\r\nreturn;\r\n}\r\nretc = ip_vs_proc_sync_conn(net, p, msg_end);\r\nif (retc < 0) {\r\nIP_VS_ERR_RL("BACKUP, Dropping buffer, Err: %d in decoding\n",\r\nretc);\r\nreturn;\r\n}\r\nmsg_end = p + ((size + 3) & ~3);\r\n}\r\n} else {\r\nip_vs_process_message_v0(net, buffer, buflen);\r\nreturn;\r\n}\r\n}\r\nstatic void set_sock_size(struct sock *sk, int mode, int val)\r\n{\r\nlock_sock(sk);\r\nif (mode) {\r\nval = clamp_t(int, val, (SOCK_MIN_SNDBUF + 1) / 2,\r\nsysctl_wmem_max);\r\nsk->sk_sndbuf = val * 2;\r\nsk->sk_userlocks |= SOCK_SNDBUF_LOCK;\r\n} else {\r\nval = clamp_t(int, val, (SOCK_MIN_RCVBUF + 1) / 2,\r\nsysctl_rmem_max);\r\nsk->sk_rcvbuf = val * 2;\r\nsk->sk_userlocks |= SOCK_RCVBUF_LOCK;\r\n}\r\nrelease_sock(sk);\r\n}\r\nstatic void set_mcast_loop(struct sock *sk, u_char loop)\r\n{\r\nstruct inet_sock *inet = inet_sk(sk);\r\nlock_sock(sk);\r\ninet->mc_loop = loop ? 1 : 0;\r\nrelease_sock(sk);\r\n}\r\nstatic void set_mcast_ttl(struct sock *sk, u_char ttl)\r\n{\r\nstruct inet_sock *inet = inet_sk(sk);\r\nlock_sock(sk);\r\ninet->mc_ttl = ttl;\r\nrelease_sock(sk);\r\n}\r\nstatic int set_mcast_if(struct sock *sk, char *ifname)\r\n{\r\nstruct net_device *dev;\r\nstruct inet_sock *inet = inet_sk(sk);\r\nstruct net *net = sock_net(sk);\r\ndev = __dev_get_by_name(net, ifname);\r\nif (!dev)\r\nreturn -ENODEV;\r\nif (sk->sk_bound_dev_if && dev->ifindex != sk->sk_bound_dev_if)\r\nreturn -EINVAL;\r\nlock_sock(sk);\r\ninet->mc_index = dev->ifindex;\r\nrelease_sock(sk);\r\nreturn 0;\r\n}\r\nstatic int set_sync_mesg_maxlen(struct net *net, int sync_state)\r\n{\r\nstruct netns_ipvs *ipvs = net_ipvs(net);\r\nstruct net_device *dev;\r\nint num;\r\nif (sync_state == IP_VS_STATE_MASTER) {\r\ndev = __dev_get_by_name(net, ipvs->master_mcast_ifn);\r\nif (!dev)\r\nreturn -ENODEV;\r\nnum = (dev->mtu - sizeof(struct iphdr) -\r\nsizeof(struct udphdr) -\r\nSYNC_MESG_HEADER_LEN - 20) / SIMPLE_CONN_SIZE;\r\nipvs->send_mesg_maxlen = SYNC_MESG_HEADER_LEN +\r\nSIMPLE_CONN_SIZE * min(num, MAX_CONNS_PER_SYNCBUFF);\r\nIP_VS_DBG(7, "setting the maximum length of sync sending "\r\n"message %d.\n", ipvs->send_mesg_maxlen);\r\n} else if (sync_state == IP_VS_STATE_BACKUP) {\r\ndev = __dev_get_by_name(net, ipvs->backup_mcast_ifn);\r\nif (!dev)\r\nreturn -ENODEV;\r\nipvs->recv_mesg_maxlen = dev->mtu -\r\nsizeof(struct iphdr) - sizeof(struct udphdr);\r\nIP_VS_DBG(7, "setting the maximum length of sync receiving "\r\n"message %d.\n", ipvs->recv_mesg_maxlen);\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\njoin_mcast_group(struct sock *sk, struct in_addr *addr, char *ifname)\r\n{\r\nstruct net *net = sock_net(sk);\r\nstruct ip_mreqn mreq;\r\nstruct net_device *dev;\r\nint ret;\r\nmemset(&mreq, 0, sizeof(mreq));\r\nmemcpy(&mreq.imr_multiaddr, addr, sizeof(struct in_addr));\r\ndev = __dev_get_by_name(net, ifname);\r\nif (!dev)\r\nreturn -ENODEV;\r\nif (sk->sk_bound_dev_if && dev->ifindex != sk->sk_bound_dev_if)\r\nreturn -EINVAL;\r\nmreq.imr_ifindex = dev->ifindex;\r\nlock_sock(sk);\r\nret = ip_mc_join_group(sk, &mreq);\r\nrelease_sock(sk);\r\nreturn ret;\r\n}\r\nstatic int bind_mcastif_addr(struct socket *sock, char *ifname)\r\n{\r\nstruct net *net = sock_net(sock->sk);\r\nstruct net_device *dev;\r\n__be32 addr;\r\nstruct sockaddr_in sin;\r\ndev = __dev_get_by_name(net, ifname);\r\nif (!dev)\r\nreturn -ENODEV;\r\naddr = inet_select_addr(dev, 0, RT_SCOPE_UNIVERSE);\r\nif (!addr)\r\npr_err("You probably need to specify IP address on "\r\n"multicast interface.\n");\r\nIP_VS_DBG(7, "binding socket with (%s) %pI4\n",\r\nifname, &addr);\r\nsin.sin_family = AF_INET;\r\nsin.sin_addr.s_addr = addr;\r\nsin.sin_port = 0;\r\nreturn sock->ops->bind(sock, (struct sockaddr*)&sin, sizeof(sin));\r\n}\r\nstatic struct socket *make_send_sock(struct net *net, int id)\r\n{\r\nstruct netns_ipvs *ipvs = net_ipvs(net);\r\nstruct sockaddr_in mcast_addr = {\r\n.sin_family = AF_INET,\r\n.sin_port = cpu_to_be16(IP_VS_SYNC_PORT + id),\r\n.sin_addr.s_addr = cpu_to_be32(IP_VS_SYNC_GROUP),\r\n};\r\nstruct socket *sock;\r\nint result;\r\nresult = sock_create_kern(PF_INET, SOCK_DGRAM, IPPROTO_UDP, &sock);\r\nif (result < 0) {\r\npr_err("Error during creation of socket; terminating\n");\r\nreturn ERR_PTR(result);\r\n}\r\nsk_change_net(sock->sk, net);\r\nresult = set_mcast_if(sock->sk, ipvs->master_mcast_ifn);\r\nif (result < 0) {\r\npr_err("Error setting outbound mcast interface\n");\r\ngoto error;\r\n}\r\nset_mcast_loop(sock->sk, 0);\r\nset_mcast_ttl(sock->sk, 1);\r\nresult = sysctl_sync_sock_size(ipvs);\r\nif (result > 0)\r\nset_sock_size(sock->sk, 1, result);\r\nresult = bind_mcastif_addr(sock, ipvs->master_mcast_ifn);\r\nif (result < 0) {\r\npr_err("Error binding address of the mcast interface\n");\r\ngoto error;\r\n}\r\nresult = sock->ops->connect(sock, (struct sockaddr *) &mcast_addr,\r\nsizeof(struct sockaddr), 0);\r\nif (result < 0) {\r\npr_err("Error connecting to the multicast addr\n");\r\ngoto error;\r\n}\r\nreturn sock;\r\nerror:\r\nsk_release_kernel(sock->sk);\r\nreturn ERR_PTR(result);\r\n}\r\nstatic struct socket *make_receive_sock(struct net *net, int id)\r\n{\r\nstruct netns_ipvs *ipvs = net_ipvs(net);\r\nstruct sockaddr_in mcast_addr = {\r\n.sin_family = AF_INET,\r\n.sin_port = cpu_to_be16(IP_VS_SYNC_PORT + id),\r\n.sin_addr.s_addr = cpu_to_be32(IP_VS_SYNC_GROUP),\r\n};\r\nstruct socket *sock;\r\nint result;\r\nresult = sock_create_kern(PF_INET, SOCK_DGRAM, IPPROTO_UDP, &sock);\r\nif (result < 0) {\r\npr_err("Error during creation of socket; terminating\n");\r\nreturn ERR_PTR(result);\r\n}\r\nsk_change_net(sock->sk, net);\r\nsock->sk->sk_reuse = SK_CAN_REUSE;\r\nresult = sysctl_sync_sock_size(ipvs);\r\nif (result > 0)\r\nset_sock_size(sock->sk, 0, result);\r\nresult = sock->ops->bind(sock, (struct sockaddr *) &mcast_addr,\r\nsizeof(struct sockaddr));\r\nif (result < 0) {\r\npr_err("Error binding to the multicast addr\n");\r\ngoto error;\r\n}\r\nresult = join_mcast_group(sock->sk,\r\n(struct in_addr *) &mcast_addr.sin_addr,\r\nipvs->backup_mcast_ifn);\r\nif (result < 0) {\r\npr_err("Error joining to the multicast group\n");\r\ngoto error;\r\n}\r\nreturn sock;\r\nerror:\r\nsk_release_kernel(sock->sk);\r\nreturn ERR_PTR(result);\r\n}\r\nstatic int\r\nip_vs_send_async(struct socket *sock, const char *buffer, const size_t length)\r\n{\r\nstruct msghdr msg = {.msg_flags = MSG_DONTWAIT|MSG_NOSIGNAL};\r\nstruct kvec iov;\r\nint len;\r\nEnterFunction(7);\r\niov.iov_base = (void *)buffer;\r\niov.iov_len = length;\r\nlen = kernel_sendmsg(sock, &msg, &iov, 1, (size_t)(length));\r\nLeaveFunction(7);\r\nreturn len;\r\n}\r\nstatic int\r\nip_vs_send_sync_msg(struct socket *sock, struct ip_vs_sync_mesg *msg)\r\n{\r\nint msize;\r\nint ret;\r\nmsize = msg->size;\r\nmsg->size = htons(msg->size);\r\nret = ip_vs_send_async(sock, (char *)msg, msize);\r\nif (ret >= 0 || ret == -EAGAIN)\r\nreturn ret;\r\npr_err("ip_vs_send_async error %d\n", ret);\r\nreturn 0;\r\n}\r\nstatic int\r\nip_vs_receive(struct socket *sock, char *buffer, const size_t buflen)\r\n{\r\nstruct msghdr msg = {NULL,};\r\nstruct kvec iov;\r\nint len;\r\nEnterFunction(7);\r\niov.iov_base = buffer;\r\niov.iov_len = (size_t)buflen;\r\nlen = kernel_recvmsg(sock, &msg, &iov, 1, buflen, MSG_DONTWAIT);\r\nif (len < 0)\r\nreturn len;\r\nLeaveFunction(7);\r\nreturn len;\r\n}\r\nstatic void master_wakeup_work_handler(struct work_struct *work)\r\n{\r\nstruct ipvs_master_sync_state *ms =\r\ncontainer_of(work, struct ipvs_master_sync_state,\r\nmaster_wakeup_work.work);\r\nstruct netns_ipvs *ipvs = ms->ipvs;\r\nspin_lock_bh(&ipvs->sync_lock);\r\nif (ms->sync_queue_len &&\r\nms->sync_queue_delay < IPVS_SYNC_WAKEUP_RATE) {\r\nms->sync_queue_delay = IPVS_SYNC_WAKEUP_RATE;\r\nwake_up_process(ms->master_thread);\r\n}\r\nspin_unlock_bh(&ipvs->sync_lock);\r\n}\r\nstatic inline struct ip_vs_sync_buff *\r\nnext_sync_buff(struct netns_ipvs *ipvs, struct ipvs_master_sync_state *ms)\r\n{\r\nstruct ip_vs_sync_buff *sb;\r\nsb = sb_dequeue(ipvs, ms);\r\nif (sb)\r\nreturn sb;\r\nreturn get_curr_sync_buff(ipvs, ms, IPVS_SYNC_FLUSH_TIME);\r\n}\r\nstatic int sync_thread_master(void *data)\r\n{\r\nstruct ip_vs_sync_thread_data *tinfo = data;\r\nstruct netns_ipvs *ipvs = net_ipvs(tinfo->net);\r\nstruct ipvs_master_sync_state *ms = &ipvs->ms[tinfo->id];\r\nstruct sock *sk = tinfo->sock->sk;\r\nstruct ip_vs_sync_buff *sb;\r\npr_info("sync thread started: state = MASTER, mcast_ifn = %s, "\r\n"syncid = %d, id = %d\n",\r\nipvs->master_mcast_ifn, ipvs->master_syncid, tinfo->id);\r\nfor (;;) {\r\nsb = next_sync_buff(ipvs, ms);\r\nif (unlikely(kthread_should_stop()))\r\nbreak;\r\nif (!sb) {\r\nschedule_timeout(IPVS_SYNC_CHECK_PERIOD);\r\ncontinue;\r\n}\r\nwhile (ip_vs_send_sync_msg(tinfo->sock, sb->mesg) < 0) {\r\nint ret = 0;\r\n__wait_event_interruptible(*sk_sleep(sk),\r\nsock_writeable(sk) ||\r\nkthread_should_stop(),\r\nret);\r\nif (unlikely(kthread_should_stop()))\r\ngoto done;\r\n}\r\nip_vs_sync_buff_release(sb);\r\n}\r\ndone:\r\n__set_current_state(TASK_RUNNING);\r\nif (sb)\r\nip_vs_sync_buff_release(sb);\r\nwhile ((sb = sb_dequeue(ipvs, ms)))\r\nip_vs_sync_buff_release(sb);\r\n__set_current_state(TASK_RUNNING);\r\nsb = get_curr_sync_buff(ipvs, ms, 0);\r\nif (sb)\r\nip_vs_sync_buff_release(sb);\r\nsk_release_kernel(tinfo->sock->sk);\r\nkfree(tinfo);\r\nreturn 0;\r\n}\r\nstatic int sync_thread_backup(void *data)\r\n{\r\nstruct ip_vs_sync_thread_data *tinfo = data;\r\nstruct netns_ipvs *ipvs = net_ipvs(tinfo->net);\r\nint len;\r\npr_info("sync thread started: state = BACKUP, mcast_ifn = %s, "\r\n"syncid = %d, id = %d\n",\r\nipvs->backup_mcast_ifn, ipvs->backup_syncid, tinfo->id);\r\nwhile (!kthread_should_stop()) {\r\nwait_event_interruptible(*sk_sleep(tinfo->sock->sk),\r\n!skb_queue_empty(&tinfo->sock->sk->sk_receive_queue)\r\n|| kthread_should_stop());\r\nwhile (!skb_queue_empty(&(tinfo->sock->sk->sk_receive_queue))) {\r\nlen = ip_vs_receive(tinfo->sock, tinfo->buf,\r\nipvs->recv_mesg_maxlen);\r\nif (len <= 0) {\r\nif (len != -EAGAIN)\r\npr_err("receiving message error\n");\r\nbreak;\r\n}\r\nlocal_bh_disable();\r\nip_vs_process_message(tinfo->net, tinfo->buf, len);\r\nlocal_bh_enable();\r\n}\r\n}\r\nsk_release_kernel(tinfo->sock->sk);\r\nkfree(tinfo->buf);\r\nkfree(tinfo);\r\nreturn 0;\r\n}\r\nint start_sync_thread(struct net *net, int state, char *mcast_ifn, __u8 syncid)\r\n{\r\nstruct ip_vs_sync_thread_data *tinfo;\r\nstruct task_struct **array = NULL, *task;\r\nstruct socket *sock;\r\nstruct netns_ipvs *ipvs = net_ipvs(net);\r\nchar *name;\r\nint (*threadfn)(void *data);\r\nint id, count;\r\nint result = -ENOMEM;\r\nIP_VS_DBG(7, "%s(): pid %d\n", __func__, task_pid_nr(current));\r\nIP_VS_DBG(7, "Each ip_vs_sync_conn entry needs %Zd bytes\n",\r\nsizeof(struct ip_vs_sync_conn_v0));\r\nif (!ipvs->sync_state) {\r\ncount = clamp(sysctl_sync_ports(ipvs), 1, IPVS_SYNC_PORTS_MAX);\r\nipvs->threads_mask = count - 1;\r\n} else\r\ncount = ipvs->threads_mask + 1;\r\nif (state == IP_VS_STATE_MASTER) {\r\nif (ipvs->ms)\r\nreturn -EEXIST;\r\nstrlcpy(ipvs->master_mcast_ifn, mcast_ifn,\r\nsizeof(ipvs->master_mcast_ifn));\r\nipvs->master_syncid = syncid;\r\nname = "ipvs-m:%d:%d";\r\nthreadfn = sync_thread_master;\r\n} else if (state == IP_VS_STATE_BACKUP) {\r\nif (ipvs->backup_threads)\r\nreturn -EEXIST;\r\nstrlcpy(ipvs->backup_mcast_ifn, mcast_ifn,\r\nsizeof(ipvs->backup_mcast_ifn));\r\nipvs->backup_syncid = syncid;\r\nname = "ipvs-b:%d:%d";\r\nthreadfn = sync_thread_backup;\r\n} else {\r\nreturn -EINVAL;\r\n}\r\nif (state == IP_VS_STATE_MASTER) {\r\nstruct ipvs_master_sync_state *ms;\r\nipvs->ms = kzalloc(count * sizeof(ipvs->ms[0]), GFP_KERNEL);\r\nif (!ipvs->ms)\r\ngoto out;\r\nms = ipvs->ms;\r\nfor (id = 0; id < count; id++, ms++) {\r\nINIT_LIST_HEAD(&ms->sync_queue);\r\nms->sync_queue_len = 0;\r\nms->sync_queue_delay = 0;\r\nINIT_DELAYED_WORK(&ms->master_wakeup_work,\r\nmaster_wakeup_work_handler);\r\nms->ipvs = ipvs;\r\n}\r\n} else {\r\narray = kzalloc(count * sizeof(struct task_struct *),\r\nGFP_KERNEL);\r\nif (!array)\r\ngoto out;\r\n}\r\nset_sync_mesg_maxlen(net, state);\r\ntinfo = NULL;\r\nfor (id = 0; id < count; id++) {\r\nif (state == IP_VS_STATE_MASTER)\r\nsock = make_send_sock(net, id);\r\nelse\r\nsock = make_receive_sock(net, id);\r\nif (IS_ERR(sock)) {\r\nresult = PTR_ERR(sock);\r\ngoto outtinfo;\r\n}\r\ntinfo = kmalloc(sizeof(*tinfo), GFP_KERNEL);\r\nif (!tinfo)\r\ngoto outsocket;\r\ntinfo->net = net;\r\ntinfo->sock = sock;\r\nif (state == IP_VS_STATE_BACKUP) {\r\ntinfo->buf = kmalloc(ipvs->recv_mesg_maxlen,\r\nGFP_KERNEL);\r\nif (!tinfo->buf)\r\ngoto outtinfo;\r\n}\r\ntinfo->id = id;\r\ntask = kthread_run(threadfn, tinfo, name, ipvs->gen, id);\r\nif (IS_ERR(task)) {\r\nresult = PTR_ERR(task);\r\ngoto outtinfo;\r\n}\r\ntinfo = NULL;\r\nif (state == IP_VS_STATE_MASTER)\r\nipvs->ms[id].master_thread = task;\r\nelse\r\narray[id] = task;\r\n}\r\nif (state == IP_VS_STATE_BACKUP)\r\nipvs->backup_threads = array;\r\nspin_lock_bh(&ipvs->sync_buff_lock);\r\nipvs->sync_state |= state;\r\nspin_unlock_bh(&ipvs->sync_buff_lock);\r\nip_vs_use_count_inc();\r\nreturn 0;\r\noutsocket:\r\nsk_release_kernel(sock->sk);\r\nouttinfo:\r\nif (tinfo) {\r\nsk_release_kernel(tinfo->sock->sk);\r\nkfree(tinfo->buf);\r\nkfree(tinfo);\r\n}\r\ncount = id;\r\nwhile (count-- > 0) {\r\nif (state == IP_VS_STATE_MASTER)\r\nkthread_stop(ipvs->ms[count].master_thread);\r\nelse\r\nkthread_stop(array[count]);\r\n}\r\nkfree(array);\r\nout:\r\nif (!(ipvs->sync_state & IP_VS_STATE_MASTER)) {\r\nkfree(ipvs->ms);\r\nipvs->ms = NULL;\r\n}\r\nreturn result;\r\n}\r\nint stop_sync_thread(struct net *net, int state)\r\n{\r\nstruct netns_ipvs *ipvs = net_ipvs(net);\r\nstruct task_struct **array;\r\nint id;\r\nint retc = -EINVAL;\r\nIP_VS_DBG(7, "%s(): pid %d\n", __func__, task_pid_nr(current));\r\nif (state == IP_VS_STATE_MASTER) {\r\nif (!ipvs->ms)\r\nreturn -ESRCH;\r\nspin_lock_bh(&ipvs->sync_buff_lock);\r\nspin_lock(&ipvs->sync_lock);\r\nipvs->sync_state &= ~IP_VS_STATE_MASTER;\r\nspin_unlock(&ipvs->sync_lock);\r\nspin_unlock_bh(&ipvs->sync_buff_lock);\r\nretc = 0;\r\nfor (id = ipvs->threads_mask; id >= 0; id--) {\r\nstruct ipvs_master_sync_state *ms = &ipvs->ms[id];\r\nint ret;\r\npr_info("stopping master sync thread %d ...\n",\r\ntask_pid_nr(ms->master_thread));\r\ncancel_delayed_work_sync(&ms->master_wakeup_work);\r\nret = kthread_stop(ms->master_thread);\r\nif (retc >= 0)\r\nretc = ret;\r\n}\r\nkfree(ipvs->ms);\r\nipvs->ms = NULL;\r\n} else if (state == IP_VS_STATE_BACKUP) {\r\nif (!ipvs->backup_threads)\r\nreturn -ESRCH;\r\nipvs->sync_state &= ~IP_VS_STATE_BACKUP;\r\narray = ipvs->backup_threads;\r\nretc = 0;\r\nfor (id = ipvs->threads_mask; id >= 0; id--) {\r\nint ret;\r\npr_info("stopping backup sync thread %d ...\n",\r\ntask_pid_nr(array[id]));\r\nret = kthread_stop(array[id]);\r\nif (retc >= 0)\r\nretc = ret;\r\n}\r\nkfree(array);\r\nipvs->backup_threads = NULL;\r\n}\r\nip_vs_use_count_dec();\r\nreturn retc;\r\n}\r\nint __net_init ip_vs_sync_net_init(struct net *net)\r\n{\r\nstruct netns_ipvs *ipvs = net_ipvs(net);\r\n__mutex_init(&ipvs->sync_mutex, "ipvs->sync_mutex", &__ipvs_sync_key);\r\nspin_lock_init(&ipvs->sync_lock);\r\nspin_lock_init(&ipvs->sync_buff_lock);\r\nreturn 0;\r\n}\r\nvoid ip_vs_sync_net_cleanup(struct net *net)\r\n{\r\nint retc;\r\nstruct netns_ipvs *ipvs = net_ipvs(net);\r\nmutex_lock(&ipvs->sync_mutex);\r\nretc = stop_sync_thread(net, IP_VS_STATE_MASTER);\r\nif (retc && retc != -ESRCH)\r\npr_err("Failed to stop Master Daemon\n");\r\nretc = stop_sync_thread(net, IP_VS_STATE_BACKUP);\r\nif (retc && retc != -ESRCH)\r\npr_err("Failed to stop Backup Daemon\n");\r\nmutex_unlock(&ipvs->sync_mutex);\r\n}
