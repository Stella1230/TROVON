static inline void regcache_rbtree_get_base_top_reg(\r\nstruct regmap *map,\r\nstruct regcache_rbtree_node *rbnode,\r\nunsigned int *base, unsigned int *top)\r\n{\r\n*base = rbnode->base_reg;\r\n*top = rbnode->base_reg + ((rbnode->blklen - 1) * map->reg_stride);\r\n}\r\nstatic unsigned int regcache_rbtree_get_register(\r\nstruct regcache_rbtree_node *rbnode, unsigned int idx,\r\nunsigned int word_size)\r\n{\r\nreturn regcache_get_val(rbnode->block, idx, word_size);\r\n}\r\nstatic void regcache_rbtree_set_register(struct regcache_rbtree_node *rbnode,\r\nunsigned int idx, unsigned int val,\r\nunsigned int word_size)\r\n{\r\nregcache_set_val(rbnode->block, idx, val, word_size);\r\n}\r\nstatic struct regcache_rbtree_node *regcache_rbtree_lookup(struct regmap *map,\r\nunsigned int reg)\r\n{\r\nstruct regcache_rbtree_ctx *rbtree_ctx = map->cache;\r\nstruct rb_node *node;\r\nstruct regcache_rbtree_node *rbnode;\r\nunsigned int base_reg, top_reg;\r\nrbnode = rbtree_ctx->cached_rbnode;\r\nif (rbnode) {\r\nregcache_rbtree_get_base_top_reg(map, rbnode, &base_reg,\r\n&top_reg);\r\nif (reg >= base_reg && reg <= top_reg)\r\nreturn rbnode;\r\n}\r\nnode = rbtree_ctx->root.rb_node;\r\nwhile (node) {\r\nrbnode = container_of(node, struct regcache_rbtree_node, node);\r\nregcache_rbtree_get_base_top_reg(map, rbnode, &base_reg,\r\n&top_reg);\r\nif (reg >= base_reg && reg <= top_reg) {\r\nrbtree_ctx->cached_rbnode = rbnode;\r\nreturn rbnode;\r\n} else if (reg > top_reg) {\r\nnode = node->rb_right;\r\n} else if (reg < base_reg) {\r\nnode = node->rb_left;\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nstatic int regcache_rbtree_insert(struct regmap *map, struct rb_root *root,\r\nstruct regcache_rbtree_node *rbnode)\r\n{\r\nstruct rb_node **new, *parent;\r\nstruct regcache_rbtree_node *rbnode_tmp;\r\nunsigned int base_reg_tmp, top_reg_tmp;\r\nunsigned int base_reg;\r\nparent = NULL;\r\nnew = &root->rb_node;\r\nwhile (*new) {\r\nrbnode_tmp = container_of(*new, struct regcache_rbtree_node,\r\nnode);\r\nregcache_rbtree_get_base_top_reg(map, rbnode_tmp, &base_reg_tmp,\r\n&top_reg_tmp);\r\nbase_reg = rbnode->base_reg;\r\nparent = *new;\r\nif (base_reg >= base_reg_tmp &&\r\nbase_reg <= top_reg_tmp)\r\nreturn 0;\r\nelse if (base_reg > top_reg_tmp)\r\nnew = &((*new)->rb_right);\r\nelse if (base_reg < base_reg_tmp)\r\nnew = &((*new)->rb_left);\r\n}\r\nrb_link_node(&rbnode->node, parent, new);\r\nrb_insert_color(&rbnode->node, root);\r\nreturn 1;\r\n}\r\nstatic int rbtree_show(struct seq_file *s, void *ignored)\r\n{\r\nstruct regmap *map = s->private;\r\nstruct regcache_rbtree_ctx *rbtree_ctx = map->cache;\r\nstruct regcache_rbtree_node *n;\r\nstruct rb_node *node;\r\nunsigned int base, top;\r\nint nodes = 0;\r\nint registers = 0;\r\nint this_registers, average;\r\nmap->lock(map);\r\nfor (node = rb_first(&rbtree_ctx->root); node != NULL;\r\nnode = rb_next(node)) {\r\nn = container_of(node, struct regcache_rbtree_node, node);\r\nregcache_rbtree_get_base_top_reg(map, n, &base, &top);\r\nthis_registers = ((top - base) / map->reg_stride) + 1;\r\nseq_printf(s, "%x-%x (%d)\n", base, top, this_registers);\r\nnodes++;\r\nregisters += this_registers;\r\n}\r\nif (nodes)\r\naverage = registers / nodes;\r\nelse\r\naverage = 0;\r\nseq_printf(s, "%d nodes, %d registers, average %d registers\n",\r\nnodes, registers, average);\r\nmap->unlock(map);\r\nreturn 0;\r\n}\r\nstatic int rbtree_open(struct inode *inode, struct file *file)\r\n{\r\nreturn single_open(file, rbtree_show, inode->i_private);\r\n}\r\nstatic void rbtree_debugfs_init(struct regmap *map)\r\n{\r\ndebugfs_create_file("rbtree", 0400, map->debugfs, map, &rbtree_fops);\r\n}\r\nstatic void rbtree_debugfs_init(struct regmap *map)\r\n{\r\n}\r\nstatic int regcache_rbtree_init(struct regmap *map)\r\n{\r\nstruct regcache_rbtree_ctx *rbtree_ctx;\r\nint i;\r\nint ret;\r\nmap->cache = kmalloc(sizeof *rbtree_ctx, GFP_KERNEL);\r\nif (!map->cache)\r\nreturn -ENOMEM;\r\nrbtree_ctx = map->cache;\r\nrbtree_ctx->root = RB_ROOT;\r\nrbtree_ctx->cached_rbnode = NULL;\r\nfor (i = 0; i < map->num_reg_defaults; i++) {\r\nret = regcache_rbtree_write(map,\r\nmap->reg_defaults[i].reg,\r\nmap->reg_defaults[i].def);\r\nif (ret)\r\ngoto err;\r\n}\r\nrbtree_debugfs_init(map);\r\nreturn 0;\r\nerr:\r\nregcache_rbtree_exit(map);\r\nreturn ret;\r\n}\r\nstatic int regcache_rbtree_exit(struct regmap *map)\r\n{\r\nstruct rb_node *next;\r\nstruct regcache_rbtree_ctx *rbtree_ctx;\r\nstruct regcache_rbtree_node *rbtree_node;\r\nrbtree_ctx = map->cache;\r\nif (!rbtree_ctx)\r\nreturn 0;\r\nnext = rb_first(&rbtree_ctx->root);\r\nwhile (next) {\r\nrbtree_node = rb_entry(next, struct regcache_rbtree_node, node);\r\nnext = rb_next(&rbtree_node->node);\r\nrb_erase(&rbtree_node->node, &rbtree_ctx->root);\r\nkfree(rbtree_node->block);\r\nkfree(rbtree_node);\r\n}\r\nkfree(map->cache);\r\nmap->cache = NULL;\r\nreturn 0;\r\n}\r\nstatic int regcache_rbtree_read(struct regmap *map,\r\nunsigned int reg, unsigned int *value)\r\n{\r\nstruct regcache_rbtree_node *rbnode;\r\nunsigned int reg_tmp;\r\nrbnode = regcache_rbtree_lookup(map, reg);\r\nif (rbnode) {\r\nreg_tmp = (reg - rbnode->base_reg) / map->reg_stride;\r\n*value = regcache_rbtree_get_register(rbnode, reg_tmp,\r\nmap->cache_word_size);\r\n} else {\r\nreturn -ENOENT;\r\n}\r\nreturn 0;\r\n}\r\nstatic int regcache_rbtree_insert_to_block(struct regcache_rbtree_node *rbnode,\r\nunsigned int pos, unsigned int reg,\r\nunsigned int value, unsigned int word_size)\r\n{\r\nu8 *blk;\r\nblk = krealloc(rbnode->block,\r\n(rbnode->blklen + 1) * word_size, GFP_KERNEL);\r\nif (!blk)\r\nreturn -ENOMEM;\r\nmemmove(blk + (pos + 1) * word_size,\r\nblk + pos * word_size,\r\n(rbnode->blklen - pos) * word_size);\r\nrbnode->block = blk;\r\nrbnode->blklen++;\r\nif (!pos)\r\nrbnode->base_reg = reg;\r\nregcache_rbtree_set_register(rbnode, pos, value, word_size);\r\nreturn 0;\r\n}\r\nstatic int regcache_rbtree_write(struct regmap *map, unsigned int reg,\r\nunsigned int value)\r\n{\r\nstruct regcache_rbtree_ctx *rbtree_ctx;\r\nstruct regcache_rbtree_node *rbnode, *rbnode_tmp;\r\nstruct rb_node *node;\r\nunsigned int val;\r\nunsigned int reg_tmp;\r\nunsigned int pos;\r\nint i;\r\nint ret;\r\nrbtree_ctx = map->cache;\r\nrbnode = regcache_rbtree_lookup(map, reg);\r\nif (rbnode) {\r\nreg_tmp = (reg - rbnode->base_reg) / map->reg_stride;\r\nval = regcache_rbtree_get_register(rbnode, reg_tmp,\r\nmap->cache_word_size);\r\nif (val == value)\r\nreturn 0;\r\nregcache_rbtree_set_register(rbnode, reg_tmp, value,\r\nmap->cache_word_size);\r\n} else {\r\nfor (node = rb_first(&rbtree_ctx->root); node;\r\nnode = rb_next(node)) {\r\nrbnode_tmp = rb_entry(node, struct regcache_rbtree_node,\r\nnode);\r\nfor (i = 0; i < rbnode_tmp->blklen; i++) {\r\nreg_tmp = rbnode_tmp->base_reg +\r\n(i * map->reg_stride);\r\nif (abs(reg_tmp - reg) != map->reg_stride)\r\ncontinue;\r\nif (reg_tmp + map->reg_stride == reg)\r\npos = i + 1;\r\nelse\r\npos = i;\r\nret = regcache_rbtree_insert_to_block(rbnode_tmp, pos,\r\nreg, value,\r\nmap->cache_word_size);\r\nif (ret)\r\nreturn ret;\r\nrbtree_ctx->cached_rbnode = rbnode_tmp;\r\nreturn 0;\r\n}\r\n}\r\nrbnode = kzalloc(sizeof *rbnode, GFP_KERNEL);\r\nif (!rbnode)\r\nreturn -ENOMEM;\r\nrbnode->blklen = 1;\r\nrbnode->base_reg = reg;\r\nrbnode->block = kmalloc(rbnode->blklen * map->cache_word_size,\r\nGFP_KERNEL);\r\nif (!rbnode->block) {\r\nkfree(rbnode);\r\nreturn -ENOMEM;\r\n}\r\nregcache_rbtree_set_register(rbnode, 0, value, map->cache_word_size);\r\nregcache_rbtree_insert(map, &rbtree_ctx->root, rbnode);\r\nrbtree_ctx->cached_rbnode = rbnode;\r\n}\r\nreturn 0;\r\n}\r\nstatic int regcache_rbtree_sync(struct regmap *map, unsigned int min,\r\nunsigned int max)\r\n{\r\nstruct regcache_rbtree_ctx *rbtree_ctx;\r\nstruct rb_node *node;\r\nstruct regcache_rbtree_node *rbnode;\r\nunsigned int regtmp;\r\nunsigned int val;\r\nint ret;\r\nint i, base, end;\r\nrbtree_ctx = map->cache;\r\nfor (node = rb_first(&rbtree_ctx->root); node; node = rb_next(node)) {\r\nrbnode = rb_entry(node, struct regcache_rbtree_node, node);\r\nif (rbnode->base_reg < min)\r\ncontinue;\r\nif (rbnode->base_reg > max)\r\nbreak;\r\nif (rbnode->base_reg + rbnode->blklen < min)\r\ncontinue;\r\nif (min > rbnode->base_reg)\r\nbase = min - rbnode->base_reg;\r\nelse\r\nbase = 0;\r\nif (max < rbnode->base_reg + rbnode->blklen)\r\nend = rbnode->base_reg + rbnode->blklen - max;\r\nelse\r\nend = rbnode->blklen;\r\nfor (i = base; i < end; i++) {\r\nregtmp = rbnode->base_reg + (i * map->reg_stride);\r\nval = regcache_rbtree_get_register(rbnode, i,\r\nmap->cache_word_size);\r\nret = regcache_lookup_reg(map, regtmp);\r\nif (ret >= 0 && val == map->reg_defaults[ret].def)\r\ncontinue;\r\nmap->cache_bypass = 1;\r\nret = _regmap_write(map, regtmp, val);\r\nmap->cache_bypass = 0;\r\nif (ret)\r\nreturn ret;\r\ndev_dbg(map->dev, "Synced register %#x, value %#x\n",\r\nregtmp, val);\r\n}\r\n}\r\nreturn 0;\r\n}
