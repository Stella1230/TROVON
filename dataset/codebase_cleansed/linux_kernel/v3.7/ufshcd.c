static inline u32 ufshcd_get_ufs_version(struct ufs_hba *hba)\r\n{\r\nreturn readl(hba->mmio_base + REG_UFS_VERSION);\r\n}\r\nstatic inline int ufshcd_is_device_present(u32 reg_hcs)\r\n{\r\nreturn (DEVICE_PRESENT & reg_hcs) ? 1 : 0;\r\n}\r\nstatic inline int ufshcd_get_tr_ocs(struct ufshcd_lrb *lrbp)\r\n{\r\nreturn lrbp->utr_descriptor_ptr->header.dword_2 & MASK_OCS;\r\n}\r\nstatic inline int\r\nufshcd_get_tmr_ocs(struct utp_task_req_desc *task_req_descp)\r\n{\r\nreturn task_req_descp->header.dword_2 & MASK_OCS;\r\n}\r\nstatic inline int ufshcd_get_tm_free_slot(struct ufs_hba *hba)\r\n{\r\nreturn find_first_zero_bit(&hba->outstanding_tasks, hba->nutmrs);\r\n}\r\nstatic inline void ufshcd_utrl_clear(struct ufs_hba *hba, u32 pos)\r\n{\r\nwritel(~(1 << pos),\r\n(hba->mmio_base + REG_UTP_TRANSFER_REQ_LIST_CLEAR));\r\n}\r\nstatic inline int ufshcd_get_lists_status(u32 reg)\r\n{\r\nreturn (((reg) & (0xFF)) >> 1) ^ (0x07);\r\n}\r\nstatic inline int ufshcd_get_uic_cmd_result(struct ufs_hba *hba)\r\n{\r\nreturn readl(hba->mmio_base + REG_UIC_COMMAND_ARG_2) &\r\nMASK_UIC_COMMAND_RESULT;\r\n}\r\nstatic inline void ufshcd_free_hba_memory(struct ufs_hba *hba)\r\n{\r\nsize_t utmrdl_size, utrdl_size, ucdl_size;\r\nkfree(hba->lrb);\r\nif (hba->utmrdl_base_addr) {\r\nutmrdl_size = sizeof(struct utp_task_req_desc) * hba->nutmrs;\r\ndma_free_coherent(&hba->pdev->dev, utmrdl_size,\r\nhba->utmrdl_base_addr, hba->utmrdl_dma_addr);\r\n}\r\nif (hba->utrdl_base_addr) {\r\nutrdl_size =\r\n(sizeof(struct utp_transfer_req_desc) * hba->nutrs);\r\ndma_free_coherent(&hba->pdev->dev, utrdl_size,\r\nhba->utrdl_base_addr, hba->utrdl_dma_addr);\r\n}\r\nif (hba->ucdl_base_addr) {\r\nucdl_size =\r\n(sizeof(struct utp_transfer_cmd_desc) * hba->nutrs);\r\ndma_free_coherent(&hba->pdev->dev, ucdl_size,\r\nhba->ucdl_base_addr, hba->ucdl_dma_addr);\r\n}\r\n}\r\nstatic inline int\r\nufshcd_is_valid_req_rsp(struct utp_upiu_rsp *ucd_rsp_ptr)\r\n{\r\nreturn ((be32_to_cpu(ucd_rsp_ptr->header.dword_0) >> 24) ==\r\nUPIU_TRANSACTION_RESPONSE) ? 0 : DID_ERROR << 16;\r\n}\r\nstatic inline int\r\nufshcd_get_rsp_upiu_result(struct utp_upiu_rsp *ucd_rsp_ptr)\r\n{\r\nreturn be32_to_cpu(ucd_rsp_ptr->header.dword_1) & MASK_RSP_UPIU_RESULT;\r\n}\r\nstatic inline void\r\nufshcd_config_int_aggr(struct ufs_hba *hba, int option)\r\n{\r\nswitch (option) {\r\ncase INT_AGGR_RESET:\r\nwritel((INT_AGGR_ENABLE |\r\nINT_AGGR_COUNTER_AND_TIMER_RESET),\r\n(hba->mmio_base +\r\nREG_UTP_TRANSFER_REQ_INT_AGG_CONTROL));\r\nbreak;\r\ncase INT_AGGR_CONFIG:\r\nwritel((INT_AGGR_ENABLE |\r\nINT_AGGR_PARAM_WRITE |\r\nINT_AGGR_COUNTER_THRESHOLD_VALUE |\r\nINT_AGGR_TIMEOUT_VALUE),\r\n(hba->mmio_base +\r\nREG_UTP_TRANSFER_REQ_INT_AGG_CONTROL));\r\nbreak;\r\n}\r\n}\r\nstatic void ufshcd_enable_run_stop_reg(struct ufs_hba *hba)\r\n{\r\nwritel(UTP_TASK_REQ_LIST_RUN_STOP_BIT,\r\n(hba->mmio_base +\r\nREG_UTP_TASK_REQ_LIST_RUN_STOP));\r\nwritel(UTP_TRANSFER_REQ_LIST_RUN_STOP_BIT,\r\n(hba->mmio_base +\r\nREG_UTP_TRANSFER_REQ_LIST_RUN_STOP));\r\n}\r\nstatic inline void ufshcd_hba_stop(struct ufs_hba *hba)\r\n{\r\nwritel(CONTROLLER_DISABLE, (hba->mmio_base + REG_CONTROLLER_ENABLE));\r\n}\r\nstatic inline void ufshcd_hba_start(struct ufs_hba *hba)\r\n{\r\nwritel(CONTROLLER_ENABLE , (hba->mmio_base + REG_CONTROLLER_ENABLE));\r\n}\r\nstatic inline int ufshcd_is_hba_active(struct ufs_hba *hba)\r\n{\r\nreturn (readl(hba->mmio_base + REG_CONTROLLER_ENABLE) & 0x1) ? 0 : 1;\r\n}\r\nstatic inline\r\nvoid ufshcd_send_command(struct ufs_hba *hba, unsigned int task_tag)\r\n{\r\n__set_bit(task_tag, &hba->outstanding_reqs);\r\nwritel((1 << task_tag),\r\n(hba->mmio_base + REG_UTP_TRANSFER_REQ_DOOR_BELL));\r\n}\r\nstatic inline void ufshcd_copy_sense_data(struct ufshcd_lrb *lrbp)\r\n{\r\nint len;\r\nif (lrbp->sense_buffer) {\r\nlen = be16_to_cpu(lrbp->ucd_rsp_ptr->sense_data_len);\r\nmemcpy(lrbp->sense_buffer,\r\nlrbp->ucd_rsp_ptr->sense_data,\r\nmin_t(int, len, SCSI_SENSE_BUFFERSIZE));\r\n}\r\n}\r\nstatic inline void ufshcd_hba_capabilities(struct ufs_hba *hba)\r\n{\r\nhba->capabilities =\r\nreadl(hba->mmio_base + REG_CONTROLLER_CAPABILITIES);\r\nhba->nutrs = (hba->capabilities & MASK_TRANSFER_REQUESTS_SLOTS) + 1;\r\nhba->nutmrs =\r\n((hba->capabilities & MASK_TASK_MANAGEMENT_REQUEST_SLOTS) >> 16) + 1;\r\n}\r\nstatic inline void\r\nufshcd_send_uic_command(struct ufs_hba *hba, struct uic_command *uic_cmnd)\r\n{\r\nwritel(uic_cmnd->argument1,\r\n(hba->mmio_base + REG_UIC_COMMAND_ARG_1));\r\nwritel(uic_cmnd->argument2,\r\n(hba->mmio_base + REG_UIC_COMMAND_ARG_2));\r\nwritel(uic_cmnd->argument3,\r\n(hba->mmio_base + REG_UIC_COMMAND_ARG_3));\r\nwritel((uic_cmnd->command & COMMAND_OPCODE_MASK),\r\n(hba->mmio_base + REG_UIC_COMMAND));\r\n}\r\nstatic int ufshcd_map_sg(struct ufshcd_lrb *lrbp)\r\n{\r\nstruct ufshcd_sg_entry *prd_table;\r\nstruct scatterlist *sg;\r\nstruct scsi_cmnd *cmd;\r\nint sg_segments;\r\nint i;\r\ncmd = lrbp->cmd;\r\nsg_segments = scsi_dma_map(cmd);\r\nif (sg_segments < 0)\r\nreturn sg_segments;\r\nif (sg_segments) {\r\nlrbp->utr_descriptor_ptr->prd_table_length =\r\ncpu_to_le16((u16) (sg_segments));\r\nprd_table = (struct ufshcd_sg_entry *)lrbp->ucd_prdt_ptr;\r\nscsi_for_each_sg(cmd, sg, sg_segments, i) {\r\nprd_table[i].size =\r\ncpu_to_le32(((u32) sg_dma_len(sg))-1);\r\nprd_table[i].base_addr =\r\ncpu_to_le32(lower_32_bits(sg->dma_address));\r\nprd_table[i].upper_addr =\r\ncpu_to_le32(upper_32_bits(sg->dma_address));\r\n}\r\n} else {\r\nlrbp->utr_descriptor_ptr->prd_table_length = 0;\r\n}\r\nreturn 0;\r\n}\r\nstatic void ufshcd_int_config(struct ufs_hba *hba, u32 option)\r\n{\r\nswitch (option) {\r\ncase UFSHCD_INT_ENABLE:\r\nwritel(hba->int_enable_mask,\r\n(hba->mmio_base + REG_INTERRUPT_ENABLE));\r\nbreak;\r\ncase UFSHCD_INT_DISABLE:\r\nif (hba->ufs_version == UFSHCI_VERSION_10)\r\nwritel(INTERRUPT_DISABLE_MASK_10,\r\n(hba->mmio_base + REG_INTERRUPT_ENABLE));\r\nelse\r\nwritel(INTERRUPT_DISABLE_MASK_11,\r\n(hba->mmio_base + REG_INTERRUPT_ENABLE));\r\nbreak;\r\n}\r\n}\r\nstatic void ufshcd_compose_upiu(struct ufshcd_lrb *lrbp)\r\n{\r\nstruct utp_transfer_req_desc *req_desc;\r\nstruct utp_upiu_cmd *ucd_cmd_ptr;\r\nu32 data_direction;\r\nu32 upiu_flags;\r\nucd_cmd_ptr = lrbp->ucd_cmd_ptr;\r\nreq_desc = lrbp->utr_descriptor_ptr;\r\nswitch (lrbp->command_type) {\r\ncase UTP_CMD_TYPE_SCSI:\r\nif (lrbp->cmd->sc_data_direction == DMA_FROM_DEVICE) {\r\ndata_direction = UTP_DEVICE_TO_HOST;\r\nupiu_flags = UPIU_CMD_FLAGS_READ;\r\n} else if (lrbp->cmd->sc_data_direction == DMA_TO_DEVICE) {\r\ndata_direction = UTP_HOST_TO_DEVICE;\r\nupiu_flags = UPIU_CMD_FLAGS_WRITE;\r\n} else {\r\ndata_direction = UTP_NO_DATA_TRANSFER;\r\nupiu_flags = UPIU_CMD_FLAGS_NONE;\r\n}\r\nreq_desc->header.dword_0 =\r\ncpu_to_le32(data_direction | UTP_SCSI_COMMAND);\r\nreq_desc->header.dword_2 =\r\ncpu_to_le32(OCS_INVALID_COMMAND_STATUS);\r\nucd_cmd_ptr->header.dword_0 =\r\ncpu_to_be32(UPIU_HEADER_DWORD(UPIU_TRANSACTION_COMMAND,\r\nupiu_flags,\r\nlrbp->lun,\r\nlrbp->task_tag));\r\nucd_cmd_ptr->header.dword_1 =\r\ncpu_to_be32(\r\nUPIU_HEADER_DWORD(UPIU_COMMAND_SET_TYPE_SCSI,\r\n0,\r\n0,\r\n0));\r\nucd_cmd_ptr->header.dword_2 = 0;\r\nucd_cmd_ptr->exp_data_transfer_len =\r\ncpu_to_be32(lrbp->cmd->transfersize);\r\nmemcpy(ucd_cmd_ptr->cdb,\r\nlrbp->cmd->cmnd,\r\n(min_t(unsigned short,\r\nlrbp->cmd->cmd_len,\r\nMAX_CDB_SIZE)));\r\nbreak;\r\ncase UTP_CMD_TYPE_DEV_MANAGE:\r\nbreak;\r\ncase UTP_CMD_TYPE_UFS:\r\nbreak;\r\n}\r\n}\r\nstatic int ufshcd_queuecommand(struct Scsi_Host *host, struct scsi_cmnd *cmd)\r\n{\r\nstruct ufshcd_lrb *lrbp;\r\nstruct ufs_hba *hba;\r\nunsigned long flags;\r\nint tag;\r\nint err = 0;\r\nhba = shost_priv(host);\r\ntag = cmd->request->tag;\r\nif (hba->ufshcd_state != UFSHCD_STATE_OPERATIONAL) {\r\nerr = SCSI_MLQUEUE_HOST_BUSY;\r\ngoto out;\r\n}\r\nlrbp = &hba->lrb[tag];\r\nlrbp->cmd = cmd;\r\nlrbp->sense_bufflen = SCSI_SENSE_BUFFERSIZE;\r\nlrbp->sense_buffer = cmd->sense_buffer;\r\nlrbp->task_tag = tag;\r\nlrbp->lun = cmd->device->lun;\r\nlrbp->command_type = UTP_CMD_TYPE_SCSI;\r\nufshcd_compose_upiu(lrbp);\r\nerr = ufshcd_map_sg(lrbp);\r\nif (err)\r\ngoto out;\r\nspin_lock_irqsave(hba->host->host_lock, flags);\r\nufshcd_send_command(hba, tag);\r\nspin_unlock_irqrestore(hba->host->host_lock, flags);\r\nout:\r\nreturn err;\r\n}\r\nstatic int ufshcd_memory_alloc(struct ufs_hba *hba)\r\n{\r\nsize_t utmrdl_size, utrdl_size, ucdl_size;\r\nucdl_size = (sizeof(struct utp_transfer_cmd_desc) * hba->nutrs);\r\nhba->ucdl_base_addr = dma_alloc_coherent(&hba->pdev->dev,\r\nucdl_size,\r\n&hba->ucdl_dma_addr,\r\nGFP_KERNEL);\r\nif (!hba->ucdl_base_addr ||\r\nWARN_ON(hba->ucdl_dma_addr & (PAGE_SIZE - 1))) {\r\ndev_err(&hba->pdev->dev,\r\n"Command Descriptor Memory allocation failed\n");\r\ngoto out;\r\n}\r\nutrdl_size = (sizeof(struct utp_transfer_req_desc) * hba->nutrs);\r\nhba->utrdl_base_addr = dma_alloc_coherent(&hba->pdev->dev,\r\nutrdl_size,\r\n&hba->utrdl_dma_addr,\r\nGFP_KERNEL);\r\nif (!hba->utrdl_base_addr ||\r\nWARN_ON(hba->utrdl_dma_addr & (PAGE_SIZE - 1))) {\r\ndev_err(&hba->pdev->dev,\r\n"Transfer Descriptor Memory allocation failed\n");\r\ngoto out;\r\n}\r\nutmrdl_size = sizeof(struct utp_task_req_desc) * hba->nutmrs;\r\nhba->utmrdl_base_addr = dma_alloc_coherent(&hba->pdev->dev,\r\nutmrdl_size,\r\n&hba->utmrdl_dma_addr,\r\nGFP_KERNEL);\r\nif (!hba->utmrdl_base_addr ||\r\nWARN_ON(hba->utmrdl_dma_addr & (PAGE_SIZE - 1))) {\r\ndev_err(&hba->pdev->dev,\r\n"Task Management Descriptor Memory allocation failed\n");\r\ngoto out;\r\n}\r\nhba->lrb = kcalloc(hba->nutrs, sizeof(struct ufshcd_lrb), GFP_KERNEL);\r\nif (!hba->lrb) {\r\ndev_err(&hba->pdev->dev, "LRB Memory allocation failed\n");\r\ngoto out;\r\n}\r\nreturn 0;\r\nout:\r\nufshcd_free_hba_memory(hba);\r\nreturn -ENOMEM;\r\n}\r\nstatic void ufshcd_host_memory_configure(struct ufs_hba *hba)\r\n{\r\nstruct utp_transfer_cmd_desc *cmd_descp;\r\nstruct utp_transfer_req_desc *utrdlp;\r\ndma_addr_t cmd_desc_dma_addr;\r\ndma_addr_t cmd_desc_element_addr;\r\nu16 response_offset;\r\nu16 prdt_offset;\r\nint cmd_desc_size;\r\nint i;\r\nutrdlp = hba->utrdl_base_addr;\r\ncmd_descp = hba->ucdl_base_addr;\r\nresponse_offset =\r\noffsetof(struct utp_transfer_cmd_desc, response_upiu);\r\nprdt_offset =\r\noffsetof(struct utp_transfer_cmd_desc, prd_table);\r\ncmd_desc_size = sizeof(struct utp_transfer_cmd_desc);\r\ncmd_desc_dma_addr = hba->ucdl_dma_addr;\r\nfor (i = 0; i < hba->nutrs; i++) {\r\ncmd_desc_element_addr =\r\n(cmd_desc_dma_addr + (cmd_desc_size * i));\r\nutrdlp[i].command_desc_base_addr_lo =\r\ncpu_to_le32(lower_32_bits(cmd_desc_element_addr));\r\nutrdlp[i].command_desc_base_addr_hi =\r\ncpu_to_le32(upper_32_bits(cmd_desc_element_addr));\r\nutrdlp[i].response_upiu_offset =\r\ncpu_to_le16((response_offset >> 2));\r\nutrdlp[i].prd_table_offset =\r\ncpu_to_le16((prdt_offset >> 2));\r\nutrdlp[i].response_upiu_length =\r\ncpu_to_le16(ALIGNED_UPIU_SIZE);\r\nhba->lrb[i].utr_descriptor_ptr = (utrdlp + i);\r\nhba->lrb[i].ucd_cmd_ptr =\r\n(struct utp_upiu_cmd *)(cmd_descp + i);\r\nhba->lrb[i].ucd_rsp_ptr =\r\n(struct utp_upiu_rsp *)cmd_descp[i].response_upiu;\r\nhba->lrb[i].ucd_prdt_ptr =\r\n(struct ufshcd_sg_entry *)cmd_descp[i].prd_table;\r\n}\r\n}\r\nstatic int ufshcd_dme_link_startup(struct ufs_hba *hba)\r\n{\r\nstruct uic_command *uic_cmd;\r\nunsigned long flags;\r\nif (((readl(hba->mmio_base + REG_CONTROLLER_STATUS)) &\r\nUIC_COMMAND_READY) == 0x0) {\r\ndev_err(&hba->pdev->dev,\r\n"Controller not ready"\r\n" to accept UIC commands\n");\r\nreturn -EIO;\r\n}\r\nspin_lock_irqsave(hba->host->host_lock, flags);\r\nuic_cmd = &hba->active_uic_cmd;\r\nuic_cmd->command = UIC_CMD_DME_LINK_STARTUP;\r\nuic_cmd->argument1 = 0;\r\nuic_cmd->argument2 = 0;\r\nuic_cmd->argument3 = 0;\r\nhba->int_enable_mask |= UIC_COMMAND_COMPL;\r\nufshcd_int_config(hba, UFSHCD_INT_ENABLE);\r\nufshcd_send_uic_command(hba, uic_cmd);\r\nspin_unlock_irqrestore(hba->host->host_lock, flags);\r\nreturn 0;\r\n}\r\nstatic int ufshcd_make_hba_operational(struct ufs_hba *hba)\r\n{\r\nint err = 0;\r\nu32 reg;\r\nreg = readl((hba->mmio_base + REG_CONTROLLER_STATUS));\r\nif (!ufshcd_is_device_present(reg)) {\r\ndev_err(&hba->pdev->dev, "cc: Device not present\n");\r\nerr = -ENXIO;\r\ngoto out;\r\n}\r\nif (!(ufshcd_get_lists_status(reg))) {\r\nufshcd_enable_run_stop_reg(hba);\r\n} else {\r\ndev_err(&hba->pdev->dev,\r\n"Host controller not ready to process requests");\r\nerr = -EIO;\r\ngoto out;\r\n}\r\nhba->int_enable_mask |= (UTP_TRANSFER_REQ_COMPL |\r\nUIC_ERROR |\r\nUTP_TASK_REQ_COMPL |\r\nDEVICE_FATAL_ERROR |\r\nCONTROLLER_FATAL_ERROR |\r\nSYSTEM_BUS_FATAL_ERROR);\r\nufshcd_int_config(hba, UFSHCD_INT_ENABLE);\r\nufshcd_config_int_aggr(hba, INT_AGGR_CONFIG);\r\nif (hba->ufshcd_state == UFSHCD_STATE_RESET)\r\nscsi_unblock_requests(hba->host);\r\nhba->ufshcd_state = UFSHCD_STATE_OPERATIONAL;\r\nscsi_scan_host(hba->host);\r\nout:\r\nreturn err;\r\n}\r\nstatic int ufshcd_hba_enable(struct ufs_hba *hba)\r\n{\r\nint retry;\r\nif (!ufshcd_is_hba_active(hba)) {\r\nufshcd_hba_stop(hba);\r\nmsleep(5);\r\n}\r\nufshcd_hba_start(hba);\r\nmsleep(1);\r\nretry = 10;\r\nwhile (ufshcd_is_hba_active(hba)) {\r\nif (retry) {\r\nretry--;\r\n} else {\r\ndev_err(&hba->pdev->dev,\r\n"Controller enable failed\n");\r\nreturn -EIO;\r\n}\r\nmsleep(5);\r\n}\r\nreturn 0;\r\n}\r\nstatic int ufshcd_initialize_hba(struct ufs_hba *hba)\r\n{\r\nif (ufshcd_hba_enable(hba))\r\nreturn -EIO;\r\nwritel(lower_32_bits(hba->utrdl_dma_addr),\r\n(hba->mmio_base + REG_UTP_TRANSFER_REQ_LIST_BASE_L));\r\nwritel(upper_32_bits(hba->utrdl_dma_addr),\r\n(hba->mmio_base + REG_UTP_TRANSFER_REQ_LIST_BASE_H));\r\nwritel(lower_32_bits(hba->utmrdl_dma_addr),\r\n(hba->mmio_base + REG_UTP_TASK_REQ_LIST_BASE_L));\r\nwritel(upper_32_bits(hba->utmrdl_dma_addr),\r\n(hba->mmio_base + REG_UTP_TASK_REQ_LIST_BASE_H));\r\nreturn ufshcd_dme_link_startup(hba);\r\n}\r\nstatic int ufshcd_do_reset(struct ufs_hba *hba)\r\n{\r\nstruct ufshcd_lrb *lrbp;\r\nunsigned long flags;\r\nint tag;\r\nscsi_block_requests(hba->host);\r\nspin_lock_irqsave(hba->host->host_lock, flags);\r\nhba->ufshcd_state = UFSHCD_STATE_RESET;\r\nufshcd_hba_stop(hba);\r\nspin_unlock_irqrestore(hba->host->host_lock, flags);\r\nfor (tag = 0; tag < hba->nutrs; tag++) {\r\nif (test_bit(tag, &hba->outstanding_reqs)) {\r\nlrbp = &hba->lrb[tag];\r\nscsi_dma_unmap(lrbp->cmd);\r\nlrbp->cmd->result = DID_RESET << 16;\r\nlrbp->cmd->scsi_done(lrbp->cmd);\r\nlrbp->cmd = NULL;\r\n}\r\n}\r\nhba->outstanding_reqs = 0;\r\nhba->outstanding_tasks = 0;\r\nif (ufshcd_initialize_hba(hba)) {\r\ndev_err(&hba->pdev->dev,\r\n"Reset: Controller initialization failed\n");\r\nreturn FAILED;\r\n}\r\nreturn SUCCESS;\r\n}\r\nstatic int ufshcd_slave_alloc(struct scsi_device *sdev)\r\n{\r\nstruct ufs_hba *hba;\r\nhba = shost_priv(sdev->host);\r\nsdev->tagged_supported = 1;\r\nsdev->use_10_for_ms = 1;\r\nscsi_set_tag_type(sdev, MSG_SIMPLE_TAG);\r\nscsi_activate_tcq(sdev, hba->nutrs);\r\nreturn 0;\r\n}\r\nstatic void ufshcd_slave_destroy(struct scsi_device *sdev)\r\n{\r\nstruct ufs_hba *hba;\r\nhba = shost_priv(sdev->host);\r\nscsi_deactivate_tcq(sdev, hba->nutrs);\r\n}\r\nstatic int ufshcd_task_req_compl(struct ufs_hba *hba, u32 index)\r\n{\r\nstruct utp_task_req_desc *task_req_descp;\r\nstruct utp_upiu_task_rsp *task_rsp_upiup;\r\nunsigned long flags;\r\nint ocs_value;\r\nint task_result;\r\nspin_lock_irqsave(hba->host->host_lock, flags);\r\n__clear_bit(index, &hba->outstanding_tasks);\r\ntask_req_descp = hba->utmrdl_base_addr;\r\nocs_value = ufshcd_get_tmr_ocs(&task_req_descp[index]);\r\nif (ocs_value == OCS_SUCCESS) {\r\ntask_rsp_upiup = (struct utp_upiu_task_rsp *)\r\ntask_req_descp[index].task_rsp_upiu;\r\ntask_result = be32_to_cpu(task_rsp_upiup->header.dword_1);\r\ntask_result = ((task_result & MASK_TASK_RESPONSE) >> 8);\r\nif (task_result != UPIU_TASK_MANAGEMENT_FUNC_COMPL &&\r\ntask_result != UPIU_TASK_MANAGEMENT_FUNC_SUCCEEDED)\r\ntask_result = FAILED;\r\nelse\r\ntask_result = SUCCESS;\r\n} else {\r\ntask_result = FAILED;\r\ndev_err(&hba->pdev->dev,\r\n"trc: Invalid ocs = %x\n", ocs_value);\r\n}\r\nspin_unlock_irqrestore(hba->host->host_lock, flags);\r\nreturn task_result;\r\n}\r\nstatic void ufshcd_adjust_lun_qdepth(struct scsi_cmnd *cmd)\r\n{\r\nstruct ufs_hba *hba;\r\nint i;\r\nint lun_qdepth = 0;\r\nhba = shost_priv(cmd->device->host);\r\nfor (i = 0; i < hba->nutrs; i++) {\r\nif (test_bit(i, &hba->outstanding_reqs)) {\r\nif (cmd->device->lun == hba->lrb[i].lun)\r\nlun_qdepth++;\r\n}\r\n}\r\nscsi_adjust_queue_depth(cmd->device, MSG_SIMPLE_TAG, lun_qdepth - 1);\r\n}\r\nstatic inline int\r\nufshcd_scsi_cmd_status(struct ufshcd_lrb *lrbp, int scsi_status)\r\n{\r\nint result = 0;\r\nswitch (scsi_status) {\r\ncase SAM_STAT_GOOD:\r\nresult |= DID_OK << 16 |\r\nCOMMAND_COMPLETE << 8 |\r\nSAM_STAT_GOOD;\r\nbreak;\r\ncase SAM_STAT_CHECK_CONDITION:\r\nresult |= DID_OK << 16 |\r\nCOMMAND_COMPLETE << 8 |\r\nSAM_STAT_CHECK_CONDITION;\r\nufshcd_copy_sense_data(lrbp);\r\nbreak;\r\ncase SAM_STAT_BUSY:\r\nresult |= SAM_STAT_BUSY;\r\nbreak;\r\ncase SAM_STAT_TASK_SET_FULL:\r\nufshcd_adjust_lun_qdepth(lrbp->cmd);\r\nresult |= SAM_STAT_TASK_SET_FULL;\r\nbreak;\r\ncase SAM_STAT_TASK_ABORTED:\r\nresult |= SAM_STAT_TASK_ABORTED;\r\nbreak;\r\ndefault:\r\nresult |= DID_ERROR << 16;\r\nbreak;\r\n}\r\nreturn result;\r\n}\r\nstatic inline int\r\nufshcd_transfer_rsp_status(struct ufs_hba *hba, struct ufshcd_lrb *lrbp)\r\n{\r\nint result = 0;\r\nint scsi_status;\r\nint ocs;\r\nocs = ufshcd_get_tr_ocs(lrbp);\r\nswitch (ocs) {\r\ncase OCS_SUCCESS:\r\nresult = ufshcd_is_valid_req_rsp(lrbp->ucd_rsp_ptr);\r\nif (result) {\r\ndev_err(&hba->pdev->dev,\r\n"Invalid response = %x\n", result);\r\nbreak;\r\n}\r\nresult = ufshcd_get_rsp_upiu_result(lrbp->ucd_rsp_ptr);\r\nscsi_status = result & MASK_SCSI_STATUS;\r\nresult = ufshcd_scsi_cmd_status(lrbp, scsi_status);\r\nbreak;\r\ncase OCS_ABORTED:\r\nresult |= DID_ABORT << 16;\r\nbreak;\r\ncase OCS_INVALID_CMD_TABLE_ATTR:\r\ncase OCS_INVALID_PRDT_ATTR:\r\ncase OCS_MISMATCH_DATA_BUF_SIZE:\r\ncase OCS_MISMATCH_RESP_UPIU_SIZE:\r\ncase OCS_PEER_COMM_FAILURE:\r\ncase OCS_FATAL_ERROR:\r\ndefault:\r\nresult |= DID_ERROR << 16;\r\ndev_err(&hba->pdev->dev,\r\n"OCS error from controller = %x\n", ocs);\r\nbreak;\r\n}\r\nreturn result;\r\n}\r\nstatic void ufshcd_transfer_req_compl(struct ufs_hba *hba)\r\n{\r\nstruct ufshcd_lrb *lrb;\r\nunsigned long completed_reqs;\r\nu32 tr_doorbell;\r\nint result;\r\nint index;\r\nlrb = hba->lrb;\r\ntr_doorbell =\r\nreadl(hba->mmio_base + REG_UTP_TRANSFER_REQ_DOOR_BELL);\r\ncompleted_reqs = tr_doorbell ^ hba->outstanding_reqs;\r\nfor (index = 0; index < hba->nutrs; index++) {\r\nif (test_bit(index, &completed_reqs)) {\r\nresult = ufshcd_transfer_rsp_status(hba, &lrb[index]);\r\nif (lrb[index].cmd) {\r\nscsi_dma_unmap(lrb[index].cmd);\r\nlrb[index].cmd->result = result;\r\nlrb[index].cmd->scsi_done(lrb[index].cmd);\r\nlrb[index].cmd = NULL;\r\n}\r\n}\r\n}\r\nhba->outstanding_reqs ^= completed_reqs;\r\nufshcd_config_int_aggr(hba, INT_AGGR_RESET);\r\n}\r\nstatic void ufshcd_uic_cc_handler (struct work_struct *work)\r\n{\r\nstruct ufs_hba *hba;\r\nhba = container_of(work, struct ufs_hba, uic_workq);\r\nif ((hba->active_uic_cmd.command == UIC_CMD_DME_LINK_STARTUP) &&\r\n!(ufshcd_get_uic_cmd_result(hba))) {\r\nif (ufshcd_make_hba_operational(hba))\r\ndev_err(&hba->pdev->dev,\r\n"cc: hba not operational state\n");\r\nreturn;\r\n}\r\n}\r\nstatic void ufshcd_fatal_err_handler(struct work_struct *work)\r\n{\r\nstruct ufs_hba *hba;\r\nhba = container_of(work, struct ufs_hba, feh_workq);\r\nif (hba->ufshcd_state != UFSHCD_STATE_RESET)\r\nufshcd_do_reset(hba);\r\n}\r\nstatic void ufshcd_err_handler(struct ufs_hba *hba)\r\n{\r\nu32 reg;\r\nif (hba->errors & INT_FATAL_ERRORS)\r\ngoto fatal_eh;\r\nif (hba->errors & UIC_ERROR) {\r\nreg = readl(hba->mmio_base +\r\nREG_UIC_ERROR_CODE_PHY_ADAPTER_LAYER);\r\nif (reg & UIC_DATA_LINK_LAYER_ERROR_PA_INIT)\r\ngoto fatal_eh;\r\n}\r\nreturn;\r\nfatal_eh:\r\nhba->ufshcd_state = UFSHCD_STATE_ERROR;\r\nschedule_work(&hba->feh_workq);\r\n}\r\nstatic void ufshcd_tmc_handler(struct ufs_hba *hba)\r\n{\r\nu32 tm_doorbell;\r\ntm_doorbell = readl(hba->mmio_base + REG_UTP_TASK_REQ_DOOR_BELL);\r\nhba->tm_condition = tm_doorbell ^ hba->outstanding_tasks;\r\nwake_up_interruptible(&hba->ufshcd_tm_wait_queue);\r\n}\r\nstatic void ufshcd_sl_intr(struct ufs_hba *hba, u32 intr_status)\r\n{\r\nhba->errors = UFSHCD_ERROR_MASK & intr_status;\r\nif (hba->errors)\r\nufshcd_err_handler(hba);\r\nif (intr_status & UIC_COMMAND_COMPL)\r\nschedule_work(&hba->uic_workq);\r\nif (intr_status & UTP_TASK_REQ_COMPL)\r\nufshcd_tmc_handler(hba);\r\nif (intr_status & UTP_TRANSFER_REQ_COMPL)\r\nufshcd_transfer_req_compl(hba);\r\n}\r\nstatic irqreturn_t ufshcd_intr(int irq, void *__hba)\r\n{\r\nu32 intr_status;\r\nirqreturn_t retval = IRQ_NONE;\r\nstruct ufs_hba *hba = __hba;\r\nspin_lock(hba->host->host_lock);\r\nintr_status = readl(hba->mmio_base + REG_INTERRUPT_STATUS);\r\nif (intr_status) {\r\nufshcd_sl_intr(hba, intr_status);\r\nif (hba->ufs_version == UFSHCI_VERSION_10)\r\nwritel(intr_status,\r\n(hba->mmio_base + REG_INTERRUPT_STATUS));\r\nretval = IRQ_HANDLED;\r\n}\r\nspin_unlock(hba->host->host_lock);\r\nreturn retval;\r\n}\r\nstatic int\r\nufshcd_issue_tm_cmd(struct ufs_hba *hba,\r\nstruct ufshcd_lrb *lrbp,\r\nu8 tm_function)\r\n{\r\nstruct utp_task_req_desc *task_req_descp;\r\nstruct utp_upiu_task_req *task_req_upiup;\r\nstruct Scsi_Host *host;\r\nunsigned long flags;\r\nint free_slot = 0;\r\nint err;\r\nhost = hba->host;\r\nspin_lock_irqsave(host->host_lock, flags);\r\nfree_slot = ufshcd_get_tm_free_slot(hba);\r\nif (free_slot >= hba->nutmrs) {\r\nspin_unlock_irqrestore(host->host_lock, flags);\r\ndev_err(&hba->pdev->dev, "Task management queue full\n");\r\nerr = FAILED;\r\ngoto out;\r\n}\r\ntask_req_descp = hba->utmrdl_base_addr;\r\ntask_req_descp += free_slot;\r\ntask_req_descp->header.dword_0 = cpu_to_le32(UTP_REQ_DESC_INT_CMD);\r\ntask_req_descp->header.dword_2 =\r\ncpu_to_le32(OCS_INVALID_COMMAND_STATUS);\r\ntask_req_upiup =\r\n(struct utp_upiu_task_req *) task_req_descp->task_req_upiu;\r\ntask_req_upiup->header.dword_0 =\r\ncpu_to_be32(UPIU_HEADER_DWORD(UPIU_TRANSACTION_TASK_REQ, 0,\r\nlrbp->lun, lrbp->task_tag));\r\ntask_req_upiup->header.dword_1 =\r\ncpu_to_be32(UPIU_HEADER_DWORD(0, tm_function, 0, 0));\r\ntask_req_upiup->input_param1 = lrbp->lun;\r\ntask_req_upiup->input_param1 =\r\ncpu_to_be32(task_req_upiup->input_param1);\r\ntask_req_upiup->input_param2 = lrbp->task_tag;\r\ntask_req_upiup->input_param2 =\r\ncpu_to_be32(task_req_upiup->input_param2);\r\n__set_bit(free_slot, &hba->outstanding_tasks);\r\nwritel((1 << free_slot),\r\n(hba->mmio_base + REG_UTP_TASK_REQ_DOOR_BELL));\r\nspin_unlock_irqrestore(host->host_lock, flags);\r\nerr =\r\nwait_event_interruptible_timeout(hba->ufshcd_tm_wait_queue,\r\n(test_bit(free_slot,\r\n&hba->tm_condition) != 0),\r\n60 * HZ);\r\nif (!err) {\r\ndev_err(&hba->pdev->dev,\r\n"Task management command timed-out\n");\r\nerr = FAILED;\r\ngoto out;\r\n}\r\nclear_bit(free_slot, &hba->tm_condition);\r\nerr = ufshcd_task_req_compl(hba, free_slot);\r\nout:\r\nreturn err;\r\n}\r\nstatic int ufshcd_device_reset(struct scsi_cmnd *cmd)\r\n{\r\nstruct Scsi_Host *host;\r\nstruct ufs_hba *hba;\r\nunsigned int tag;\r\nu32 pos;\r\nint err;\r\nhost = cmd->device->host;\r\nhba = shost_priv(host);\r\ntag = cmd->request->tag;\r\nerr = ufshcd_issue_tm_cmd(hba, &hba->lrb[tag], UFS_LOGICAL_RESET);\r\nif (err == FAILED)\r\ngoto out;\r\nfor (pos = 0; pos < hba->nutrs; pos++) {\r\nif (test_bit(pos, &hba->outstanding_reqs) &&\r\n(hba->lrb[tag].lun == hba->lrb[pos].lun)) {\r\nufshcd_utrl_clear(hba, pos);\r\nclear_bit(pos, &hba->outstanding_reqs);\r\nif (hba->lrb[pos].cmd) {\r\nscsi_dma_unmap(hba->lrb[pos].cmd);\r\nhba->lrb[pos].cmd->result =\r\nDID_ABORT << 16;\r\nhba->lrb[pos].cmd->scsi_done(cmd);\r\nhba->lrb[pos].cmd = NULL;\r\n}\r\n}\r\n}\r\nout:\r\nreturn err;\r\n}\r\nstatic int ufshcd_host_reset(struct scsi_cmnd *cmd)\r\n{\r\nstruct ufs_hba *hba;\r\nhba = shost_priv(cmd->device->host);\r\nif (hba->ufshcd_state == UFSHCD_STATE_RESET)\r\nreturn SUCCESS;\r\nreturn ufshcd_do_reset(hba);\r\n}\r\nstatic int ufshcd_abort(struct scsi_cmnd *cmd)\r\n{\r\nstruct Scsi_Host *host;\r\nstruct ufs_hba *hba;\r\nunsigned long flags;\r\nunsigned int tag;\r\nint err;\r\nhost = cmd->device->host;\r\nhba = shost_priv(host);\r\ntag = cmd->request->tag;\r\nspin_lock_irqsave(host->host_lock, flags);\r\nif (!(test_bit(tag, &hba->outstanding_reqs))) {\r\nerr = FAILED;\r\nspin_unlock_irqrestore(host->host_lock, flags);\r\ngoto out;\r\n}\r\nspin_unlock_irqrestore(host->host_lock, flags);\r\nerr = ufshcd_issue_tm_cmd(hba, &hba->lrb[tag], UFS_ABORT_TASK);\r\nif (err == FAILED)\r\ngoto out;\r\nscsi_dma_unmap(cmd);\r\nspin_lock_irqsave(host->host_lock, flags);\r\nufshcd_utrl_clear(hba, tag);\r\n__clear_bit(tag, &hba->outstanding_reqs);\r\nhba->lrb[tag].cmd = NULL;\r\nspin_unlock_irqrestore(host->host_lock, flags);\r\nout:\r\nreturn err;\r\n}\r\nstatic void ufshcd_shutdown(struct pci_dev *pdev)\r\n{\r\nufshcd_hba_stop((struct ufs_hba *)pci_get_drvdata(pdev));\r\n}\r\nstatic int ufshcd_suspend(struct pci_dev *pdev, pm_message_t state)\r\n{\r\nreturn -ENOSYS;\r\n}\r\nstatic int ufshcd_resume(struct pci_dev *pdev)\r\n{\r\nreturn -ENOSYS;\r\n}\r\nstatic void ufshcd_hba_free(struct ufs_hba *hba)\r\n{\r\niounmap(hba->mmio_base);\r\nufshcd_free_hba_memory(hba);\r\npci_release_regions(hba->pdev);\r\n}\r\nstatic void ufshcd_remove(struct pci_dev *pdev)\r\n{\r\nstruct ufs_hba *hba = pci_get_drvdata(pdev);\r\nufshcd_int_config(hba, UFSHCD_INT_DISABLE);\r\nfree_irq(pdev->irq, hba);\r\nufshcd_hba_stop(hba);\r\nufshcd_hba_free(hba);\r\nscsi_remove_host(hba->host);\r\nscsi_host_put(hba->host);\r\npci_set_drvdata(pdev, NULL);\r\npci_clear_master(pdev);\r\npci_disable_device(pdev);\r\n}\r\nstatic int ufshcd_set_dma_mask(struct ufs_hba *hba)\r\n{\r\nint err;\r\nu64 dma_mask;\r\nif (hba->capabilities & MASK_64_ADDRESSING_SUPPORT)\r\ndma_mask = DMA_BIT_MASK(64);\r\nelse\r\ndma_mask = DMA_BIT_MASK(32);\r\nerr = pci_set_dma_mask(hba->pdev, dma_mask);\r\nif (err)\r\nreturn err;\r\nerr = pci_set_consistent_dma_mask(hba->pdev, dma_mask);\r\nreturn err;\r\n}\r\nstatic int __devinit\r\nufshcd_probe(struct pci_dev *pdev, const struct pci_device_id *id)\r\n{\r\nstruct Scsi_Host *host;\r\nstruct ufs_hba *hba;\r\nint err;\r\nerr = pci_enable_device(pdev);\r\nif (err) {\r\ndev_err(&pdev->dev, "pci_enable_device failed\n");\r\ngoto out_error;\r\n}\r\npci_set_master(pdev);\r\nhost = scsi_host_alloc(&ufshcd_driver_template,\r\nsizeof(struct ufs_hba));\r\nif (!host) {\r\ndev_err(&pdev->dev, "scsi_host_alloc failed\n");\r\nerr = -ENOMEM;\r\ngoto out_disable;\r\n}\r\nhba = shost_priv(host);\r\nerr = pci_request_regions(pdev, UFSHCD);\r\nif (err < 0) {\r\ndev_err(&pdev->dev, "request regions failed\n");\r\ngoto out_host_put;\r\n}\r\nhba->mmio_base = pci_ioremap_bar(pdev, 0);\r\nif (!hba->mmio_base) {\r\ndev_err(&pdev->dev, "memory map failed\n");\r\nerr = -ENOMEM;\r\ngoto out_release_regions;\r\n}\r\nhba->host = host;\r\nhba->pdev = pdev;\r\nufshcd_hba_capabilities(hba);\r\nhba->ufs_version = ufshcd_get_ufs_version(hba);\r\nerr = ufshcd_set_dma_mask(hba);\r\nif (err) {\r\ndev_err(&pdev->dev, "set dma mask failed\n");\r\ngoto out_iounmap;\r\n}\r\nerr = ufshcd_memory_alloc(hba);\r\nif (err) {\r\ndev_err(&pdev->dev, "Memory allocation failed\n");\r\ngoto out_iounmap;\r\n}\r\nufshcd_host_memory_configure(hba);\r\nhost->can_queue = hba->nutrs;\r\nhost->cmd_per_lun = hba->nutrs;\r\nhost->max_id = UFSHCD_MAX_ID;\r\nhost->max_lun = UFSHCD_MAX_LUNS;\r\nhost->max_channel = UFSHCD_MAX_CHANNEL;\r\nhost->unique_id = host->host_no;\r\nhost->max_cmd_len = MAX_CDB_SIZE;\r\ninit_waitqueue_head(&hba->ufshcd_tm_wait_queue);\r\nINIT_WORK(&hba->uic_workq, ufshcd_uic_cc_handler);\r\nINIT_WORK(&hba->feh_workq, ufshcd_fatal_err_handler);\r\nerr = request_irq(pdev->irq, ufshcd_intr, IRQF_SHARED, UFSHCD, hba);\r\nif (err) {\r\ndev_err(&pdev->dev, "request irq failed\n");\r\ngoto out_lrb_free;\r\n}\r\nerr = scsi_init_shared_tag_map(host, host->can_queue);\r\nif (err) {\r\ndev_err(&pdev->dev, "init shared queue failed\n");\r\ngoto out_free_irq;\r\n}\r\npci_set_drvdata(pdev, hba);\r\nerr = scsi_add_host(host, &pdev->dev);\r\nif (err) {\r\ndev_err(&pdev->dev, "scsi_add_host failed\n");\r\ngoto out_free_irq;\r\n}\r\nerr = ufshcd_initialize_hba(hba);\r\nif (err) {\r\ndev_err(&pdev->dev, "Initialization failed\n");\r\ngoto out_free_irq;\r\n}\r\nreturn 0;\r\nout_free_irq:\r\nfree_irq(pdev->irq, hba);\r\nout_lrb_free:\r\nufshcd_free_hba_memory(hba);\r\nout_iounmap:\r\niounmap(hba->mmio_base);\r\nout_release_regions:\r\npci_release_regions(pdev);\r\nout_host_put:\r\nscsi_host_put(host);\r\nout_disable:\r\npci_clear_master(pdev);\r\npci_disable_device(pdev);\r\nout_error:\r\nreturn err;\r\n}
