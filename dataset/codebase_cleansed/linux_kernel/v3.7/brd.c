static struct page *brd_lookup_page(struct brd_device *brd, sector_t sector)\r\n{\r\npgoff_t idx;\r\nstruct page *page;\r\nrcu_read_lock();\r\nidx = sector >> PAGE_SECTORS_SHIFT;\r\npage = radix_tree_lookup(&brd->brd_pages, idx);\r\nrcu_read_unlock();\r\nBUG_ON(page && page->index != idx);\r\nreturn page;\r\n}\r\nstatic struct page *brd_insert_page(struct brd_device *brd, sector_t sector)\r\n{\r\npgoff_t idx;\r\nstruct page *page;\r\ngfp_t gfp_flags;\r\npage = brd_lookup_page(brd, sector);\r\nif (page)\r\nreturn page;\r\ngfp_flags = GFP_NOIO | __GFP_ZERO;\r\n#ifndef CONFIG_BLK_DEV_XIP\r\ngfp_flags |= __GFP_HIGHMEM;\r\n#endif\r\npage = alloc_page(gfp_flags);\r\nif (!page)\r\nreturn NULL;\r\nif (radix_tree_preload(GFP_NOIO)) {\r\n__free_page(page);\r\nreturn NULL;\r\n}\r\nspin_lock(&brd->brd_lock);\r\nidx = sector >> PAGE_SECTORS_SHIFT;\r\nif (radix_tree_insert(&brd->brd_pages, idx, page)) {\r\n__free_page(page);\r\npage = radix_tree_lookup(&brd->brd_pages, idx);\r\nBUG_ON(!page);\r\nBUG_ON(page->index != idx);\r\n} else\r\npage->index = idx;\r\nspin_unlock(&brd->brd_lock);\r\nradix_tree_preload_end();\r\nreturn page;\r\n}\r\nstatic void brd_free_page(struct brd_device *brd, sector_t sector)\r\n{\r\nstruct page *page;\r\npgoff_t idx;\r\nspin_lock(&brd->brd_lock);\r\nidx = sector >> PAGE_SECTORS_SHIFT;\r\npage = radix_tree_delete(&brd->brd_pages, idx);\r\nspin_unlock(&brd->brd_lock);\r\nif (page)\r\n__free_page(page);\r\n}\r\nstatic void brd_zero_page(struct brd_device *brd, sector_t sector)\r\n{\r\nstruct page *page;\r\npage = brd_lookup_page(brd, sector);\r\nif (page)\r\nclear_highpage(page);\r\n}\r\nstatic void brd_free_pages(struct brd_device *brd)\r\n{\r\nunsigned long pos = 0;\r\nstruct page *pages[FREE_BATCH];\r\nint nr_pages;\r\ndo {\r\nint i;\r\nnr_pages = radix_tree_gang_lookup(&brd->brd_pages,\r\n(void **)pages, pos, FREE_BATCH);\r\nfor (i = 0; i < nr_pages; i++) {\r\nvoid *ret;\r\nBUG_ON(pages[i]->index < pos);\r\npos = pages[i]->index;\r\nret = radix_tree_delete(&brd->brd_pages, pos);\r\nBUG_ON(!ret || ret != pages[i]);\r\n__free_page(pages[i]);\r\n}\r\npos++;\r\n} while (nr_pages == FREE_BATCH);\r\n}\r\nstatic int copy_to_brd_setup(struct brd_device *brd, sector_t sector, size_t n)\r\n{\r\nunsigned int offset = (sector & (PAGE_SECTORS-1)) << SECTOR_SHIFT;\r\nsize_t copy;\r\ncopy = min_t(size_t, n, PAGE_SIZE - offset);\r\nif (!brd_insert_page(brd, sector))\r\nreturn -ENOMEM;\r\nif (copy < n) {\r\nsector += copy >> SECTOR_SHIFT;\r\nif (!brd_insert_page(brd, sector))\r\nreturn -ENOMEM;\r\n}\r\nreturn 0;\r\n}\r\nstatic void discard_from_brd(struct brd_device *brd,\r\nsector_t sector, size_t n)\r\n{\r\nwhile (n >= PAGE_SIZE) {\r\nif (0)\r\nbrd_free_page(brd, sector);\r\nelse\r\nbrd_zero_page(brd, sector);\r\nsector += PAGE_SIZE >> SECTOR_SHIFT;\r\nn -= PAGE_SIZE;\r\n}\r\n}\r\nstatic void copy_to_brd(struct brd_device *brd, const void *src,\r\nsector_t sector, size_t n)\r\n{\r\nstruct page *page;\r\nvoid *dst;\r\nunsigned int offset = (sector & (PAGE_SECTORS-1)) << SECTOR_SHIFT;\r\nsize_t copy;\r\ncopy = min_t(size_t, n, PAGE_SIZE - offset);\r\npage = brd_lookup_page(brd, sector);\r\nBUG_ON(!page);\r\ndst = kmap_atomic(page);\r\nmemcpy(dst + offset, src, copy);\r\nkunmap_atomic(dst);\r\nif (copy < n) {\r\nsrc += copy;\r\nsector += copy >> SECTOR_SHIFT;\r\ncopy = n - copy;\r\npage = brd_lookup_page(brd, sector);\r\nBUG_ON(!page);\r\ndst = kmap_atomic(page);\r\nmemcpy(dst, src, copy);\r\nkunmap_atomic(dst);\r\n}\r\n}\r\nstatic void copy_from_brd(void *dst, struct brd_device *brd,\r\nsector_t sector, size_t n)\r\n{\r\nstruct page *page;\r\nvoid *src;\r\nunsigned int offset = (sector & (PAGE_SECTORS-1)) << SECTOR_SHIFT;\r\nsize_t copy;\r\ncopy = min_t(size_t, n, PAGE_SIZE - offset);\r\npage = brd_lookup_page(brd, sector);\r\nif (page) {\r\nsrc = kmap_atomic(page);\r\nmemcpy(dst, src + offset, copy);\r\nkunmap_atomic(src);\r\n} else\r\nmemset(dst, 0, copy);\r\nif (copy < n) {\r\ndst += copy;\r\nsector += copy >> SECTOR_SHIFT;\r\ncopy = n - copy;\r\npage = brd_lookup_page(brd, sector);\r\nif (page) {\r\nsrc = kmap_atomic(page);\r\nmemcpy(dst, src, copy);\r\nkunmap_atomic(src);\r\n} else\r\nmemset(dst, 0, copy);\r\n}\r\n}\r\nstatic int brd_do_bvec(struct brd_device *brd, struct page *page,\r\nunsigned int len, unsigned int off, int rw,\r\nsector_t sector)\r\n{\r\nvoid *mem;\r\nint err = 0;\r\nif (rw != READ) {\r\nerr = copy_to_brd_setup(brd, sector, len);\r\nif (err)\r\ngoto out;\r\n}\r\nmem = kmap_atomic(page);\r\nif (rw == READ) {\r\ncopy_from_brd(mem + off, brd, sector, len);\r\nflush_dcache_page(page);\r\n} else {\r\nflush_dcache_page(page);\r\ncopy_to_brd(brd, mem + off, sector, len);\r\n}\r\nkunmap_atomic(mem);\r\nout:\r\nreturn err;\r\n}\r\nstatic void brd_make_request(struct request_queue *q, struct bio *bio)\r\n{\r\nstruct block_device *bdev = bio->bi_bdev;\r\nstruct brd_device *brd = bdev->bd_disk->private_data;\r\nint rw;\r\nstruct bio_vec *bvec;\r\nsector_t sector;\r\nint i;\r\nint err = -EIO;\r\nsector = bio->bi_sector;\r\nif (sector + (bio->bi_size >> SECTOR_SHIFT) >\r\nget_capacity(bdev->bd_disk))\r\ngoto out;\r\nif (unlikely(bio->bi_rw & REQ_DISCARD)) {\r\nerr = 0;\r\ndiscard_from_brd(brd, sector, bio->bi_size);\r\ngoto out;\r\n}\r\nrw = bio_rw(bio);\r\nif (rw == READA)\r\nrw = READ;\r\nbio_for_each_segment(bvec, bio, i) {\r\nunsigned int len = bvec->bv_len;\r\nerr = brd_do_bvec(brd, bvec->bv_page, len,\r\nbvec->bv_offset, rw, sector);\r\nif (err)\r\nbreak;\r\nsector += len >> SECTOR_SHIFT;\r\n}\r\nout:\r\nbio_endio(bio, err);\r\n}\r\nstatic int brd_direct_access(struct block_device *bdev, sector_t sector,\r\nvoid **kaddr, unsigned long *pfn)\r\n{\r\nstruct brd_device *brd = bdev->bd_disk->private_data;\r\nstruct page *page;\r\nif (!brd)\r\nreturn -ENODEV;\r\nif (sector & (PAGE_SECTORS-1))\r\nreturn -EINVAL;\r\nif (sector + PAGE_SECTORS > get_capacity(bdev->bd_disk))\r\nreturn -ERANGE;\r\npage = brd_insert_page(brd, sector);\r\nif (!page)\r\nreturn -ENOMEM;\r\n*kaddr = page_address(page);\r\n*pfn = page_to_pfn(page);\r\nreturn 0;\r\n}\r\nstatic int brd_ioctl(struct block_device *bdev, fmode_t mode,\r\nunsigned int cmd, unsigned long arg)\r\n{\r\nint error;\r\nstruct brd_device *brd = bdev->bd_disk->private_data;\r\nif (cmd != BLKFLSBUF)\r\nreturn -ENOTTY;\r\nmutex_lock(&brd_mutex);\r\nmutex_lock(&bdev->bd_mutex);\r\nerror = -EBUSY;\r\nif (bdev->bd_openers <= 1) {\r\nkill_bdev(bdev);\r\nbrd_free_pages(brd);\r\nerror = 0;\r\n}\r\nmutex_unlock(&bdev->bd_mutex);\r\nmutex_unlock(&brd_mutex);\r\nreturn error;\r\n}\r\nstatic int __init ramdisk_size(char *str)\r\n{\r\nrd_size = simple_strtol(str, NULL, 0);\r\nreturn 1;\r\n}\r\nstatic struct brd_device *brd_alloc(int i)\r\n{\r\nstruct brd_device *brd;\r\nstruct gendisk *disk;\r\nbrd = kzalloc(sizeof(*brd), GFP_KERNEL);\r\nif (!brd)\r\ngoto out;\r\nbrd->brd_number = i;\r\nspin_lock_init(&brd->brd_lock);\r\nINIT_RADIX_TREE(&brd->brd_pages, GFP_ATOMIC);\r\nbrd->brd_queue = blk_alloc_queue(GFP_KERNEL);\r\nif (!brd->brd_queue)\r\ngoto out_free_dev;\r\nblk_queue_make_request(brd->brd_queue, brd_make_request);\r\nblk_queue_max_hw_sectors(brd->brd_queue, 1024);\r\nblk_queue_bounce_limit(brd->brd_queue, BLK_BOUNCE_ANY);\r\nbrd->brd_queue->limits.discard_granularity = PAGE_SIZE;\r\nbrd->brd_queue->limits.max_discard_sectors = UINT_MAX;\r\nbrd->brd_queue->limits.discard_zeroes_data = 1;\r\nqueue_flag_set_unlocked(QUEUE_FLAG_DISCARD, brd->brd_queue);\r\ndisk = brd->brd_disk = alloc_disk(1 << part_shift);\r\nif (!disk)\r\ngoto out_free_queue;\r\ndisk->major = RAMDISK_MAJOR;\r\ndisk->first_minor = i << part_shift;\r\ndisk->fops = &brd_fops;\r\ndisk->private_data = brd;\r\ndisk->queue = brd->brd_queue;\r\ndisk->flags |= GENHD_FL_SUPPRESS_PARTITION_INFO;\r\nsprintf(disk->disk_name, "ram%d", i);\r\nset_capacity(disk, rd_size * 2);\r\nreturn brd;\r\nout_free_queue:\r\nblk_cleanup_queue(brd->brd_queue);\r\nout_free_dev:\r\nkfree(brd);\r\nout:\r\nreturn NULL;\r\n}\r\nstatic void brd_free(struct brd_device *brd)\r\n{\r\nput_disk(brd->brd_disk);\r\nblk_cleanup_queue(brd->brd_queue);\r\nbrd_free_pages(brd);\r\nkfree(brd);\r\n}\r\nstatic struct brd_device *brd_init_one(int i)\r\n{\r\nstruct brd_device *brd;\r\nlist_for_each_entry(brd, &brd_devices, brd_list) {\r\nif (brd->brd_number == i)\r\ngoto out;\r\n}\r\nbrd = brd_alloc(i);\r\nif (brd) {\r\nadd_disk(brd->brd_disk);\r\nlist_add_tail(&brd->brd_list, &brd_devices);\r\n}\r\nout:\r\nreturn brd;\r\n}\r\nstatic void brd_del_one(struct brd_device *brd)\r\n{\r\nlist_del(&brd->brd_list);\r\ndel_gendisk(brd->brd_disk);\r\nbrd_free(brd);\r\n}\r\nstatic struct kobject *brd_probe(dev_t dev, int *part, void *data)\r\n{\r\nstruct brd_device *brd;\r\nstruct kobject *kobj;\r\nmutex_lock(&brd_devices_mutex);\r\nbrd = brd_init_one(MINOR(dev) >> part_shift);\r\nkobj = brd ? get_disk(brd->brd_disk) : ERR_PTR(-ENOMEM);\r\nmutex_unlock(&brd_devices_mutex);\r\n*part = 0;\r\nreturn kobj;\r\n}\r\nstatic int __init brd_init(void)\r\n{\r\nint i, nr;\r\nunsigned long range;\r\nstruct brd_device *brd, *next;\r\npart_shift = 0;\r\nif (max_part > 0) {\r\npart_shift = fls(max_part);\r\nmax_part = (1UL << part_shift) - 1;\r\n}\r\nif ((1UL << part_shift) > DISK_MAX_PARTS)\r\nreturn -EINVAL;\r\nif (rd_nr > 1UL << (MINORBITS - part_shift))\r\nreturn -EINVAL;\r\nif (rd_nr) {\r\nnr = rd_nr;\r\nrange = rd_nr << part_shift;\r\n} else {\r\nnr = CONFIG_BLK_DEV_RAM_COUNT;\r\nrange = 1UL << MINORBITS;\r\n}\r\nif (register_blkdev(RAMDISK_MAJOR, "ramdisk"))\r\nreturn -EIO;\r\nfor (i = 0; i < nr; i++) {\r\nbrd = brd_alloc(i);\r\nif (!brd)\r\ngoto out_free;\r\nlist_add_tail(&brd->brd_list, &brd_devices);\r\n}\r\nlist_for_each_entry(brd, &brd_devices, brd_list)\r\nadd_disk(brd->brd_disk);\r\nblk_register_region(MKDEV(RAMDISK_MAJOR, 0), range,\r\nTHIS_MODULE, brd_probe, NULL, NULL);\r\nprintk(KERN_INFO "brd: module loaded\n");\r\nreturn 0;\r\nout_free:\r\nlist_for_each_entry_safe(brd, next, &brd_devices, brd_list) {\r\nlist_del(&brd->brd_list);\r\nbrd_free(brd);\r\n}\r\nunregister_blkdev(RAMDISK_MAJOR, "ramdisk");\r\nreturn -ENOMEM;\r\n}\r\nstatic void __exit brd_exit(void)\r\n{\r\nunsigned long range;\r\nstruct brd_device *brd, *next;\r\nrange = rd_nr ? rd_nr << part_shift : 1UL << MINORBITS;\r\nlist_for_each_entry_safe(brd, next, &brd_devices, brd_list)\r\nbrd_del_one(brd);\r\nblk_unregister_region(MKDEV(RAMDISK_MAJOR, 0), range);\r\nunregister_blkdev(RAMDISK_MAJOR, "ramdisk");\r\n}
