STATIC struct xfs_inode *\r\nxfs_inode_alloc(\r\nstruct xfs_mount *mp,\r\nxfs_ino_t ino)\r\n{\r\nstruct xfs_inode *ip;\r\nip = kmem_zone_alloc(xfs_inode_zone, KM_SLEEP);\r\nif (!ip)\r\nreturn NULL;\r\nif (inode_init_always(mp->m_super, VFS_I(ip))) {\r\nkmem_zone_free(xfs_inode_zone, ip);\r\nreturn NULL;\r\n}\r\nASSERT(atomic_read(&ip->i_pincount) == 0);\r\nASSERT(!spin_is_locked(&ip->i_flags_lock));\r\nASSERT(!xfs_isiflocked(ip));\r\nASSERT(ip->i_ino == 0);\r\nmrlock_init(&ip->i_iolock, MRLOCK_BARRIER, "xfsio", ip->i_ino);\r\nip->i_ino = ino;\r\nip->i_mount = mp;\r\nmemset(&ip->i_imap, 0, sizeof(struct xfs_imap));\r\nip->i_afp = NULL;\r\nmemset(&ip->i_df, 0, sizeof(xfs_ifork_t));\r\nip->i_flags = 0;\r\nip->i_delayed_blks = 0;\r\nmemset(&ip->i_d, 0, sizeof(xfs_icdinode_t));\r\nreturn ip;\r\n}\r\nSTATIC void\r\nxfs_inode_free_callback(\r\nstruct rcu_head *head)\r\n{\r\nstruct inode *inode = container_of(head, struct inode, i_rcu);\r\nstruct xfs_inode *ip = XFS_I(inode);\r\nkmem_zone_free(xfs_inode_zone, ip);\r\n}\r\nvoid\r\nxfs_inode_free(\r\nstruct xfs_inode *ip)\r\n{\r\nswitch (ip->i_d.di_mode & S_IFMT) {\r\ncase S_IFREG:\r\ncase S_IFDIR:\r\ncase S_IFLNK:\r\nxfs_idestroy_fork(ip, XFS_DATA_FORK);\r\nbreak;\r\n}\r\nif (ip->i_afp)\r\nxfs_idestroy_fork(ip, XFS_ATTR_FORK);\r\nif (ip->i_itemp) {\r\nASSERT(!(ip->i_itemp->ili_item.li_flags & XFS_LI_IN_AIL));\r\nxfs_inode_item_destroy(ip);\r\nip->i_itemp = NULL;\r\n}\r\nASSERT(atomic_read(&ip->i_pincount) == 0);\r\nASSERT(!spin_is_locked(&ip->i_flags_lock));\r\nASSERT(!xfs_isiflocked(ip));\r\nspin_lock(&ip->i_flags_lock);\r\nip->i_flags = XFS_IRECLAIM;\r\nip->i_ino = 0;\r\nspin_unlock(&ip->i_flags_lock);\r\ncall_rcu(&VFS_I(ip)->i_rcu, xfs_inode_free_callback);\r\n}\r\nstatic int\r\nxfs_iget_cache_hit(\r\nstruct xfs_perag *pag,\r\nstruct xfs_inode *ip,\r\nxfs_ino_t ino,\r\nint flags,\r\nint lock_flags) __releases(RCU)\r\n{\r\nstruct inode *inode = VFS_I(ip);\r\nstruct xfs_mount *mp = ip->i_mount;\r\nint error;\r\nspin_lock(&ip->i_flags_lock);\r\nif (ip->i_ino != ino) {\r\ntrace_xfs_iget_skip(ip);\r\nXFS_STATS_INC(xs_ig_frecycle);\r\nerror = EAGAIN;\r\ngoto out_error;\r\n}\r\nif (ip->i_flags & (XFS_INEW|XFS_IRECLAIM)) {\r\ntrace_xfs_iget_skip(ip);\r\nXFS_STATS_INC(xs_ig_frecycle);\r\nerror = EAGAIN;\r\ngoto out_error;\r\n}\r\nif (ip->i_d.di_mode == 0 && !(flags & XFS_IGET_CREATE)) {\r\nerror = ENOENT;\r\ngoto out_error;\r\n}\r\nif (ip->i_flags & XFS_IRECLAIMABLE) {\r\ntrace_xfs_iget_reclaim(ip);\r\nip->i_flags |= XFS_IRECLAIM;\r\nspin_unlock(&ip->i_flags_lock);\r\nrcu_read_unlock();\r\nerror = -inode_init_always(mp->m_super, inode);\r\nif (error) {\r\nrcu_read_lock();\r\nspin_lock(&ip->i_flags_lock);\r\nip->i_flags &= ~(XFS_INEW | XFS_IRECLAIM);\r\nASSERT(ip->i_flags & XFS_IRECLAIMABLE);\r\ntrace_xfs_iget_reclaim_fail(ip);\r\ngoto out_error;\r\n}\r\nspin_lock(&pag->pag_ici_lock);\r\nspin_lock(&ip->i_flags_lock);\r\nip->i_flags &= ~XFS_IRECLAIM_RESET_FLAGS;\r\nip->i_flags |= XFS_INEW;\r\n__xfs_inode_clear_reclaim_tag(mp, pag, ip);\r\ninode->i_state = I_NEW;\r\nASSERT(!rwsem_is_locked(&ip->i_iolock.mr_lock));\r\nmrlock_init(&ip->i_iolock, MRLOCK_BARRIER, "xfsio", ip->i_ino);\r\nspin_unlock(&ip->i_flags_lock);\r\nspin_unlock(&pag->pag_ici_lock);\r\n} else {\r\nif (!igrab(inode)) {\r\ntrace_xfs_iget_skip(ip);\r\nerror = EAGAIN;\r\ngoto out_error;\r\n}\r\nspin_unlock(&ip->i_flags_lock);\r\nrcu_read_unlock();\r\ntrace_xfs_iget_hit(ip);\r\n}\r\nif (lock_flags != 0)\r\nxfs_ilock(ip, lock_flags);\r\nxfs_iflags_clear(ip, XFS_ISTALE | XFS_IDONTCACHE);\r\nXFS_STATS_INC(xs_ig_found);\r\nreturn 0;\r\nout_error:\r\nspin_unlock(&ip->i_flags_lock);\r\nrcu_read_unlock();\r\nreturn error;\r\n}\r\nstatic int\r\nxfs_iget_cache_miss(\r\nstruct xfs_mount *mp,\r\nstruct xfs_perag *pag,\r\nxfs_trans_t *tp,\r\nxfs_ino_t ino,\r\nstruct xfs_inode **ipp,\r\nint flags,\r\nint lock_flags)\r\n{\r\nstruct xfs_inode *ip;\r\nint error;\r\nxfs_agino_t agino = XFS_INO_TO_AGINO(mp, ino);\r\nint iflags;\r\nip = xfs_inode_alloc(mp, ino);\r\nif (!ip)\r\nreturn ENOMEM;\r\nerror = xfs_iread(mp, tp, ip, flags);\r\nif (error)\r\ngoto out_destroy;\r\ntrace_xfs_iget_miss(ip);\r\nif ((ip->i_d.di_mode == 0) && !(flags & XFS_IGET_CREATE)) {\r\nerror = ENOENT;\r\ngoto out_destroy;\r\n}\r\nif (radix_tree_preload(GFP_NOFS)) {\r\nerror = EAGAIN;\r\ngoto out_destroy;\r\n}\r\nif (lock_flags) {\r\nif (!xfs_ilock_nowait(ip, lock_flags))\r\nBUG();\r\n}\r\niflags = XFS_INEW;\r\nif (flags & XFS_IGET_DONTCACHE)\r\niflags |= XFS_IDONTCACHE;\r\nip->i_udquot = ip->i_gdquot = NULL;\r\nxfs_iflags_set(ip, iflags);\r\nspin_lock(&pag->pag_ici_lock);\r\nerror = radix_tree_insert(&pag->pag_ici_root, agino, ip);\r\nif (unlikely(error)) {\r\nWARN_ON(error != -EEXIST);\r\nXFS_STATS_INC(xs_ig_dup);\r\nerror = EAGAIN;\r\ngoto out_preload_end;\r\n}\r\nspin_unlock(&pag->pag_ici_lock);\r\nradix_tree_preload_end();\r\n*ipp = ip;\r\nreturn 0;\r\nout_preload_end:\r\nspin_unlock(&pag->pag_ici_lock);\r\nradix_tree_preload_end();\r\nif (lock_flags)\r\nxfs_iunlock(ip, lock_flags);\r\nout_destroy:\r\n__destroy_inode(VFS_I(ip));\r\nxfs_inode_free(ip);\r\nreturn error;\r\n}\r\nint\r\nxfs_iget(\r\nxfs_mount_t *mp,\r\nxfs_trans_t *tp,\r\nxfs_ino_t ino,\r\nuint flags,\r\nuint lock_flags,\r\nxfs_inode_t **ipp)\r\n{\r\nxfs_inode_t *ip;\r\nint error;\r\nxfs_perag_t *pag;\r\nxfs_agino_t agino;\r\nASSERT((lock_flags & (XFS_IOLOCK_EXCL | XFS_IOLOCK_SHARED)) == 0);\r\nif (!ino || XFS_INO_TO_AGNO(mp, ino) >= mp->m_sb.sb_agcount)\r\nreturn EINVAL;\r\npag = xfs_perag_get(mp, XFS_INO_TO_AGNO(mp, ino));\r\nagino = XFS_INO_TO_AGINO(mp, ino);\r\nagain:\r\nerror = 0;\r\nrcu_read_lock();\r\nip = radix_tree_lookup(&pag->pag_ici_root, agino);\r\nif (ip) {\r\nerror = xfs_iget_cache_hit(pag, ip, ino, flags, lock_flags);\r\nif (error)\r\ngoto out_error_or_again;\r\n} else {\r\nrcu_read_unlock();\r\nXFS_STATS_INC(xs_ig_missed);\r\nerror = xfs_iget_cache_miss(mp, pag, tp, ino, &ip,\r\nflags, lock_flags);\r\nif (error)\r\ngoto out_error_or_again;\r\n}\r\nxfs_perag_put(pag);\r\n*ipp = ip;\r\nif (xfs_iflags_test(ip, XFS_INEW) && ip->i_d.di_mode != 0)\r\nxfs_setup_inode(ip);\r\nreturn 0;\r\nout_error_or_again:\r\nif (error == EAGAIN) {\r\ndelay(1);\r\ngoto again;\r\n}\r\nxfs_perag_put(pag);\r\nreturn error;\r\n}\r\nuint\r\nxfs_ilock_map_shared(\r\nxfs_inode_t *ip)\r\n{\r\nuint lock_mode;\r\nif ((ip->i_d.di_format == XFS_DINODE_FMT_BTREE) &&\r\n((ip->i_df.if_flags & XFS_IFEXTENTS) == 0)) {\r\nlock_mode = XFS_ILOCK_EXCL;\r\n} else {\r\nlock_mode = XFS_ILOCK_SHARED;\r\n}\r\nxfs_ilock(ip, lock_mode);\r\nreturn lock_mode;\r\n}\r\nvoid\r\nxfs_iunlock_map_shared(\r\nxfs_inode_t *ip,\r\nunsigned int lock_mode)\r\n{\r\nxfs_iunlock(ip, lock_mode);\r\n}\r\nvoid\r\nxfs_ilock(\r\nxfs_inode_t *ip,\r\nuint lock_flags)\r\n{\r\nASSERT((lock_flags & (XFS_IOLOCK_SHARED | XFS_IOLOCK_EXCL)) !=\r\n(XFS_IOLOCK_SHARED | XFS_IOLOCK_EXCL));\r\nASSERT((lock_flags & (XFS_ILOCK_SHARED | XFS_ILOCK_EXCL)) !=\r\n(XFS_ILOCK_SHARED | XFS_ILOCK_EXCL));\r\nASSERT((lock_flags & ~(XFS_LOCK_MASK | XFS_LOCK_DEP_MASK)) == 0);\r\nif (lock_flags & XFS_IOLOCK_EXCL)\r\nmrupdate_nested(&ip->i_iolock, XFS_IOLOCK_DEP(lock_flags));\r\nelse if (lock_flags & XFS_IOLOCK_SHARED)\r\nmraccess_nested(&ip->i_iolock, XFS_IOLOCK_DEP(lock_flags));\r\nif (lock_flags & XFS_ILOCK_EXCL)\r\nmrupdate_nested(&ip->i_lock, XFS_ILOCK_DEP(lock_flags));\r\nelse if (lock_flags & XFS_ILOCK_SHARED)\r\nmraccess_nested(&ip->i_lock, XFS_ILOCK_DEP(lock_flags));\r\ntrace_xfs_ilock(ip, lock_flags, _RET_IP_);\r\n}\r\nint\r\nxfs_ilock_nowait(\r\nxfs_inode_t *ip,\r\nuint lock_flags)\r\n{\r\nASSERT((lock_flags & (XFS_IOLOCK_SHARED | XFS_IOLOCK_EXCL)) !=\r\n(XFS_IOLOCK_SHARED | XFS_IOLOCK_EXCL));\r\nASSERT((lock_flags & (XFS_ILOCK_SHARED | XFS_ILOCK_EXCL)) !=\r\n(XFS_ILOCK_SHARED | XFS_ILOCK_EXCL));\r\nASSERT((lock_flags & ~(XFS_LOCK_MASK | XFS_LOCK_DEP_MASK)) == 0);\r\nif (lock_flags & XFS_IOLOCK_EXCL) {\r\nif (!mrtryupdate(&ip->i_iolock))\r\ngoto out;\r\n} else if (lock_flags & XFS_IOLOCK_SHARED) {\r\nif (!mrtryaccess(&ip->i_iolock))\r\ngoto out;\r\n}\r\nif (lock_flags & XFS_ILOCK_EXCL) {\r\nif (!mrtryupdate(&ip->i_lock))\r\ngoto out_undo_iolock;\r\n} else if (lock_flags & XFS_ILOCK_SHARED) {\r\nif (!mrtryaccess(&ip->i_lock))\r\ngoto out_undo_iolock;\r\n}\r\ntrace_xfs_ilock_nowait(ip, lock_flags, _RET_IP_);\r\nreturn 1;\r\nout_undo_iolock:\r\nif (lock_flags & XFS_IOLOCK_EXCL)\r\nmrunlock_excl(&ip->i_iolock);\r\nelse if (lock_flags & XFS_IOLOCK_SHARED)\r\nmrunlock_shared(&ip->i_iolock);\r\nout:\r\nreturn 0;\r\n}\r\nvoid\r\nxfs_iunlock(\r\nxfs_inode_t *ip,\r\nuint lock_flags)\r\n{\r\nASSERT((lock_flags & (XFS_IOLOCK_SHARED | XFS_IOLOCK_EXCL)) !=\r\n(XFS_IOLOCK_SHARED | XFS_IOLOCK_EXCL));\r\nASSERT((lock_flags & (XFS_ILOCK_SHARED | XFS_ILOCK_EXCL)) !=\r\n(XFS_ILOCK_SHARED | XFS_ILOCK_EXCL));\r\nASSERT((lock_flags & ~(XFS_LOCK_MASK | XFS_LOCK_DEP_MASK)) == 0);\r\nASSERT(lock_flags != 0);\r\nif (lock_flags & XFS_IOLOCK_EXCL)\r\nmrunlock_excl(&ip->i_iolock);\r\nelse if (lock_flags & XFS_IOLOCK_SHARED)\r\nmrunlock_shared(&ip->i_iolock);\r\nif (lock_flags & XFS_ILOCK_EXCL)\r\nmrunlock_excl(&ip->i_lock);\r\nelse if (lock_flags & XFS_ILOCK_SHARED)\r\nmrunlock_shared(&ip->i_lock);\r\ntrace_xfs_iunlock(ip, lock_flags, _RET_IP_);\r\n}\r\nvoid\r\nxfs_ilock_demote(\r\nxfs_inode_t *ip,\r\nuint lock_flags)\r\n{\r\nASSERT(lock_flags & (XFS_IOLOCK_EXCL|XFS_ILOCK_EXCL));\r\nASSERT((lock_flags & ~(XFS_IOLOCK_EXCL|XFS_ILOCK_EXCL)) == 0);\r\nif (lock_flags & XFS_ILOCK_EXCL)\r\nmrdemote(&ip->i_lock);\r\nif (lock_flags & XFS_IOLOCK_EXCL)\r\nmrdemote(&ip->i_iolock);\r\ntrace_xfs_ilock_demote(ip, lock_flags, _RET_IP_);\r\n}\r\nint\r\nxfs_isilocked(\r\nxfs_inode_t *ip,\r\nuint lock_flags)\r\n{\r\nif (lock_flags & (XFS_ILOCK_EXCL|XFS_ILOCK_SHARED)) {\r\nif (!(lock_flags & XFS_ILOCK_SHARED))\r\nreturn !!ip->i_lock.mr_writer;\r\nreturn rwsem_is_locked(&ip->i_lock.mr_lock);\r\n}\r\nif (lock_flags & (XFS_IOLOCK_EXCL|XFS_IOLOCK_SHARED)) {\r\nif (!(lock_flags & XFS_IOLOCK_SHARED))\r\nreturn !!ip->i_iolock.mr_writer;\r\nreturn rwsem_is_locked(&ip->i_iolock.mr_lock);\r\n}\r\nASSERT(0);\r\nreturn 0;\r\n}\r\nvoid\r\n__xfs_iflock(\r\nstruct xfs_inode *ip)\r\n{\r\nwait_queue_head_t *wq = bit_waitqueue(&ip->i_flags, __XFS_IFLOCK_BIT);\r\nDEFINE_WAIT_BIT(wait, &ip->i_flags, __XFS_IFLOCK_BIT);\r\ndo {\r\nprepare_to_wait_exclusive(wq, &wait.wait, TASK_UNINTERRUPTIBLE);\r\nif (xfs_isiflocked(ip))\r\nio_schedule();\r\n} while (!xfs_iflock_nowait(ip));\r\nfinish_wait(wq, &wait.wait);\r\n}
