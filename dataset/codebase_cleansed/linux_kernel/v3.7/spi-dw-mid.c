static bool mid_spi_dma_chan_filter(struct dma_chan *chan, void *param)\r\n{\r\nstruct dw_spi *dws = param;\r\nreturn dws->dmac && (&dws->dmac->dev == chan->device->dev);\r\n}\r\nstatic int mid_spi_dma_init(struct dw_spi *dws)\r\n{\r\nstruct mid_dma *dw_dma = dws->dma_priv;\r\nstruct intel_mid_dma_slave *rxs, *txs;\r\ndma_cap_mask_t mask;\r\ndws->dmac = pci_get_device(PCI_VENDOR_ID_INTEL, 0x0813, NULL);\r\nif (!dws->dmac)\r\ndws->dmac = pci_get_device(PCI_VENDOR_ID_INTEL, 0x0827, NULL);\r\ndma_cap_zero(mask);\r\ndma_cap_set(DMA_SLAVE, mask);\r\ndws->rxchan = dma_request_channel(mask, mid_spi_dma_chan_filter, dws);\r\nif (!dws->rxchan)\r\ngoto err_exit;\r\nrxs = &dw_dma->dmas_rx;\r\nrxs->hs_mode = LNW_DMA_HW_HS;\r\nrxs->cfg_mode = LNW_DMA_PER_TO_MEM;\r\ndws->rxchan->private = rxs;\r\ndws->txchan = dma_request_channel(mask, mid_spi_dma_chan_filter, dws);\r\nif (!dws->txchan)\r\ngoto free_rxchan;\r\ntxs = &dw_dma->dmas_tx;\r\ntxs->hs_mode = LNW_DMA_HW_HS;\r\ntxs->cfg_mode = LNW_DMA_MEM_TO_PER;\r\ndws->txchan->private = txs;\r\ndws->dma_inited = 1;\r\nreturn 0;\r\nfree_rxchan:\r\ndma_release_channel(dws->rxchan);\r\nerr_exit:\r\nreturn -1;\r\n}\r\nstatic void mid_spi_dma_exit(struct dw_spi *dws)\r\n{\r\ndma_release_channel(dws->txchan);\r\ndma_release_channel(dws->rxchan);\r\n}\r\nstatic void dw_spi_dma_done(void *arg)\r\n{\r\nstruct dw_spi *dws = arg;\r\nif (++dws->dma_chan_done != 2)\r\nreturn;\r\ndw_spi_xfer_done(dws);\r\n}\r\nstatic int mid_spi_dma_transfer(struct dw_spi *dws, int cs_change)\r\n{\r\nstruct dma_async_tx_descriptor *txdesc = NULL, *rxdesc = NULL;\r\nstruct dma_chan *txchan, *rxchan;\r\nstruct dma_slave_config txconf, rxconf;\r\nu16 dma_ctrl = 0;\r\nif (cs_change) {\r\nspi_enable_chip(dws, 0);\r\ndw_writew(dws, DW_SPI_DMARDLR, 0xf);\r\ndw_writew(dws, DW_SPI_DMATDLR, 0x10);\r\nif (dws->tx_dma)\r\ndma_ctrl |= 0x2;\r\nif (dws->rx_dma)\r\ndma_ctrl |= 0x1;\r\ndw_writew(dws, DW_SPI_DMACR, dma_ctrl);\r\nspi_enable_chip(dws, 1);\r\n}\r\ndws->dma_chan_done = 0;\r\ntxchan = dws->txchan;\r\nrxchan = dws->rxchan;\r\ntxconf.direction = DMA_MEM_TO_DEV;\r\ntxconf.dst_addr = dws->dma_addr;\r\ntxconf.dst_maxburst = LNW_DMA_MSIZE_16;\r\ntxconf.src_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;\r\ntxconf.dst_addr_width = DMA_SLAVE_BUSWIDTH_2_BYTES;\r\ntxconf.device_fc = false;\r\ntxchan->device->device_control(txchan, DMA_SLAVE_CONFIG,\r\n(unsigned long) &txconf);\r\nmemset(&dws->tx_sgl, 0, sizeof(dws->tx_sgl));\r\ndws->tx_sgl.dma_address = dws->tx_dma;\r\ndws->tx_sgl.length = dws->len;\r\ntxdesc = dmaengine_prep_slave_sg(txchan,\r\n&dws->tx_sgl,\r\n1,\r\nDMA_MEM_TO_DEV,\r\nDMA_PREP_INTERRUPT | DMA_COMPL_SKIP_DEST_UNMAP);\r\ntxdesc->callback = dw_spi_dma_done;\r\ntxdesc->callback_param = dws;\r\nrxconf.direction = DMA_DEV_TO_MEM;\r\nrxconf.src_addr = dws->dma_addr;\r\nrxconf.src_maxburst = LNW_DMA_MSIZE_16;\r\nrxconf.dst_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;\r\nrxconf.src_addr_width = DMA_SLAVE_BUSWIDTH_2_BYTES;\r\nrxconf.device_fc = false;\r\nrxchan->device->device_control(rxchan, DMA_SLAVE_CONFIG,\r\n(unsigned long) &rxconf);\r\nmemset(&dws->rx_sgl, 0, sizeof(dws->rx_sgl));\r\ndws->rx_sgl.dma_address = dws->rx_dma;\r\ndws->rx_sgl.length = dws->len;\r\nrxdesc = dmaengine_prep_slave_sg(rxchan,\r\n&dws->rx_sgl,\r\n1,\r\nDMA_DEV_TO_MEM,\r\nDMA_PREP_INTERRUPT | DMA_COMPL_SKIP_DEST_UNMAP);\r\nrxdesc->callback = dw_spi_dma_done;\r\nrxdesc->callback_param = dws;\r\nrxdesc->tx_submit(rxdesc);\r\ntxdesc->tx_submit(txdesc);\r\nreturn 0;\r\n}\r\nint dw_spi_mid_init(struct dw_spi *dws)\r\n{\r\nvoid __iomem *clk_reg;\r\nu32 clk_cdiv;\r\nclk_reg = ioremap_nocache(MRST_CLK_SPI0_REG, 16);\r\nif (!clk_reg)\r\nreturn -ENOMEM;\r\nclk_cdiv = (readl(clk_reg) & CLK_SPI_CDIV_MASK) >> CLK_SPI_CDIV_OFFSET;\r\ndws->max_freq = MRST_SPI_CLK_BASE / (clk_cdiv + 1);\r\niounmap(clk_reg);\r\ndws->num_cs = 16;\r\ndws->fifo_len = 40;\r\n#ifdef CONFIG_SPI_DW_MID_DMA\r\ndws->dma_priv = kzalloc(sizeof(struct mid_dma), GFP_KERNEL);\r\nif (!dws->dma_priv)\r\nreturn -ENOMEM;\r\ndws->dma_ops = &mid_dma_ops;\r\n#endif\r\nreturn 0;\r\n}
