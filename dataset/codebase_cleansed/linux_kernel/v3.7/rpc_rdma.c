static int\r\nrpcrdma_convert_iovs(struct xdr_buf *xdrbuf, unsigned int pos,\r\nenum rpcrdma_chunktype type, struct rpcrdma_mr_seg *seg, int nsegs)\r\n{\r\nint len, n = 0, p;\r\nint page_base;\r\nstruct page **ppages;\r\nif (pos == 0 && xdrbuf->head[0].iov_len) {\r\nseg[n].mr_page = NULL;\r\nseg[n].mr_offset = xdrbuf->head[0].iov_base;\r\nseg[n].mr_len = xdrbuf->head[0].iov_len;\r\n++n;\r\n}\r\nlen = xdrbuf->page_len;\r\nppages = xdrbuf->pages + (xdrbuf->page_base >> PAGE_SHIFT);\r\npage_base = xdrbuf->page_base & ~PAGE_MASK;\r\np = 0;\r\nwhile (len && n < nsegs) {\r\nseg[n].mr_page = ppages[p];\r\nseg[n].mr_offset = (void *)(unsigned long) page_base;\r\nseg[n].mr_len = min_t(u32, PAGE_SIZE - page_base, len);\r\nBUG_ON(seg[n].mr_len > PAGE_SIZE);\r\nlen -= seg[n].mr_len;\r\n++n;\r\n++p;\r\npage_base = 0;\r\n}\r\nif (len && n == nsegs)\r\nreturn 0;\r\nif (xdrbuf->tail[0].iov_len) {\r\nif (xdrbuf->tail[0].iov_len < 4 && xprt_rdma_pad_optimize)\r\nreturn n;\r\nif (n == nsegs)\r\nreturn 0;\r\nseg[n].mr_page = NULL;\r\nseg[n].mr_offset = xdrbuf->tail[0].iov_base;\r\nseg[n].mr_len = xdrbuf->tail[0].iov_len;\r\n++n;\r\n}\r\nreturn n;\r\n}\r\nstatic unsigned int\r\nrpcrdma_create_chunks(struct rpc_rqst *rqst, struct xdr_buf *target,\r\nstruct rpcrdma_msg *headerp, enum rpcrdma_chunktype type)\r\n{\r\nstruct rpcrdma_req *req = rpcr_to_rdmar(rqst);\r\nstruct rpcrdma_xprt *r_xprt = rpcx_to_rdmax(rqst->rq_task->tk_xprt);\r\nint nsegs, nchunks = 0;\r\nunsigned int pos;\r\nstruct rpcrdma_mr_seg *seg = req->rl_segments;\r\nstruct rpcrdma_read_chunk *cur_rchunk = NULL;\r\nstruct rpcrdma_write_array *warray = NULL;\r\nstruct rpcrdma_write_chunk *cur_wchunk = NULL;\r\n__be32 *iptr = headerp->rm_body.rm_chunks;\r\nif (type == rpcrdma_readch || type == rpcrdma_areadch) {\r\ncur_rchunk = (struct rpcrdma_read_chunk *) iptr;\r\n} else {\r\n*iptr++ = xdr_zero;\r\nif (type == rpcrdma_replych)\r\n*iptr++ = xdr_zero;\r\nwarray = (struct rpcrdma_write_array *) iptr;\r\ncur_wchunk = (struct rpcrdma_write_chunk *) (warray + 1);\r\n}\r\nif (type == rpcrdma_replych || type == rpcrdma_areadch)\r\npos = 0;\r\nelse\r\npos = target->head[0].iov_len;\r\nnsegs = rpcrdma_convert_iovs(target, pos, type, seg, RPCRDMA_MAX_SEGS);\r\nif (nsegs == 0)\r\nreturn 0;\r\ndo {\r\nint n = rpcrdma_register_external(seg, nsegs,\r\ncur_wchunk != NULL, r_xprt);\r\nif (n <= 0)\r\ngoto out;\r\nif (cur_rchunk) {\r\ncur_rchunk->rc_discrim = xdr_one;\r\ncur_rchunk->rc_position = htonl(pos);\r\ncur_rchunk->rc_target.rs_handle = htonl(seg->mr_rkey);\r\ncur_rchunk->rc_target.rs_length = htonl(seg->mr_len);\r\nxdr_encode_hyper(\r\n(__be32 *)&cur_rchunk->rc_target.rs_offset,\r\nseg->mr_base);\r\ndprintk("RPC: %s: read chunk "\r\n"elem %d@0x%llx:0x%x pos %u (%s)\n", __func__,\r\nseg->mr_len, (unsigned long long)seg->mr_base,\r\nseg->mr_rkey, pos, n < nsegs ? "more" : "last");\r\ncur_rchunk++;\r\nr_xprt->rx_stats.read_chunk_count++;\r\n} else {\r\ncur_wchunk->wc_target.rs_handle = htonl(seg->mr_rkey);\r\ncur_wchunk->wc_target.rs_length = htonl(seg->mr_len);\r\nxdr_encode_hyper(\r\n(__be32 *)&cur_wchunk->wc_target.rs_offset,\r\nseg->mr_base);\r\ndprintk("RPC: %s: %s chunk "\r\n"elem %d@0x%llx:0x%x (%s)\n", __func__,\r\n(type == rpcrdma_replych) ? "reply" : "write",\r\nseg->mr_len, (unsigned long long)seg->mr_base,\r\nseg->mr_rkey, n < nsegs ? "more" : "last");\r\ncur_wchunk++;\r\nif (type == rpcrdma_replych)\r\nr_xprt->rx_stats.reply_chunk_count++;\r\nelse\r\nr_xprt->rx_stats.write_chunk_count++;\r\nr_xprt->rx_stats.total_rdma_request += seg->mr_len;\r\n}\r\nnchunks++;\r\nseg += n;\r\nnsegs -= n;\r\n} while (nsegs);\r\nreq->rl_nchunks = nchunks;\r\nBUG_ON(nchunks == 0);\r\nBUG_ON((r_xprt->rx_ia.ri_memreg_strategy == RPCRDMA_FRMR)\r\n&& (nchunks > 3));\r\nif (cur_rchunk) {\r\niptr = (__be32 *) cur_rchunk;\r\n*iptr++ = xdr_zero;\r\n*iptr++ = xdr_zero;\r\n*iptr++ = xdr_zero;\r\n} else {\r\nwarray->wc_discrim = xdr_one;\r\nwarray->wc_nchunks = htonl(nchunks);\r\niptr = (__be32 *) cur_wchunk;\r\nif (type == rpcrdma_writech) {\r\n*iptr++ = xdr_zero;\r\n*iptr++ = xdr_zero;\r\n}\r\n}\r\nreturn (unsigned char *)iptr - (unsigned char *)headerp;\r\nout:\r\nfor (pos = 0; nchunks--;)\r\npos += rpcrdma_deregister_external(\r\n&req->rl_segments[pos], r_xprt, NULL);\r\nreturn 0;\r\n}\r\nstatic int\r\nrpcrdma_inline_pullup(struct rpc_rqst *rqst, int pad)\r\n{\r\nint i, npages, curlen;\r\nint copy_len;\r\nunsigned char *srcp, *destp;\r\nstruct rpcrdma_xprt *r_xprt = rpcx_to_rdmax(rqst->rq_xprt);\r\nint page_base;\r\nstruct page **ppages;\r\ndestp = rqst->rq_svec[0].iov_base;\r\ncurlen = rqst->rq_svec[0].iov_len;\r\ndestp += curlen;\r\npad -= (curlen + 36);\r\nif (pad < 0 || rqst->rq_slen - curlen < RPCRDMA_INLINE_PAD_THRESH)\r\npad = 0;\r\ndprintk("RPC: %s: pad %d destp 0x%p len %d hdrlen %d\n",\r\n__func__, pad, destp, rqst->rq_slen, curlen);\r\ncopy_len = rqst->rq_snd_buf.page_len;\r\nif (rqst->rq_snd_buf.tail[0].iov_len) {\r\ncurlen = rqst->rq_snd_buf.tail[0].iov_len;\r\nif (destp + copy_len != rqst->rq_snd_buf.tail[0].iov_base) {\r\nmemmove(destp + copy_len,\r\nrqst->rq_snd_buf.tail[0].iov_base, curlen);\r\nr_xprt->rx_stats.pullup_copy_count += curlen;\r\n}\r\ndprintk("RPC: %s: tail destp 0x%p len %d\n",\r\n__func__, destp + copy_len, curlen);\r\nrqst->rq_svec[0].iov_len += curlen;\r\n}\r\nr_xprt->rx_stats.pullup_copy_count += copy_len;\r\npage_base = rqst->rq_snd_buf.page_base;\r\nppages = rqst->rq_snd_buf.pages + (page_base >> PAGE_SHIFT);\r\npage_base &= ~PAGE_MASK;\r\nnpages = PAGE_ALIGN(page_base+copy_len) >> PAGE_SHIFT;\r\nfor (i = 0; copy_len && i < npages; i++) {\r\ncurlen = PAGE_SIZE - page_base;\r\nif (curlen > copy_len)\r\ncurlen = copy_len;\r\ndprintk("RPC: %s: page %d destp 0x%p len %d curlen %d\n",\r\n__func__, i, destp, copy_len, curlen);\r\nsrcp = kmap_atomic(ppages[i]);\r\nmemcpy(destp, srcp+page_base, curlen);\r\nkunmap_atomic(srcp);\r\nrqst->rq_svec[0].iov_len += curlen;\r\ndestp += curlen;\r\ncopy_len -= curlen;\r\npage_base = 0;\r\n}\r\nreturn pad;\r\n}\r\nint\r\nrpcrdma_marshal_req(struct rpc_rqst *rqst)\r\n{\r\nstruct rpc_xprt *xprt = rqst->rq_task->tk_xprt;\r\nstruct rpcrdma_xprt *r_xprt = rpcx_to_rdmax(xprt);\r\nstruct rpcrdma_req *req = rpcr_to_rdmar(rqst);\r\nchar *base;\r\nsize_t hdrlen, rpclen, padlen;\r\nenum rpcrdma_chunktype rtype, wtype;\r\nstruct rpcrdma_msg *headerp;\r\nbase = rqst->rq_svec[0].iov_base;\r\nrpclen = rqst->rq_svec[0].iov_len;\r\nheaderp = (struct rpcrdma_msg *) req->rl_base;\r\nheaderp->rm_xid = rqst->rq_xid;\r\nheaderp->rm_vers = xdr_one;\r\nheaderp->rm_credit = htonl(r_xprt->rx_buf.rb_max_requests);\r\nheaderp->rm_type = htonl(RDMA_MSG);\r\nif (rqst->rq_rcv_buf.buflen <= RPCRDMA_INLINE_READ_THRESHOLD(rqst))\r\nwtype = rpcrdma_noch;\r\nelse if (rqst->rq_rcv_buf.page_len == 0)\r\nwtype = rpcrdma_replych;\r\nelse if (rqst->rq_rcv_buf.flags & XDRBUF_READ)\r\nwtype = rpcrdma_writech;\r\nelse\r\nwtype = rpcrdma_replych;\r\nif (rqst->rq_snd_buf.len <= RPCRDMA_INLINE_WRITE_THRESHOLD(rqst))\r\nrtype = rpcrdma_noch;\r\nelse if (rqst->rq_snd_buf.page_len == 0)\r\nrtype = rpcrdma_areadch;\r\nelse\r\nrtype = rpcrdma_readch;\r\nif (rtype != rpcrdma_noch && wtype == rpcrdma_replych)\r\nwtype = rpcrdma_noch;\r\nBUG_ON(rtype != rpcrdma_noch && wtype != rpcrdma_noch);\r\nif (r_xprt->rx_ia.ri_memreg_strategy == RPCRDMA_BOUNCEBUFFERS &&\r\n(rtype != rpcrdma_noch || wtype != rpcrdma_noch)) {\r\ndprintk("RPC: %s: too much data (%d/%d) for inline\n",\r\n__func__, rqst->rq_rcv_buf.len, rqst->rq_snd_buf.len);\r\nreturn -1;\r\n}\r\nhdrlen = 28;\r\npadlen = 0;\r\nif (rtype == rpcrdma_noch) {\r\npadlen = rpcrdma_inline_pullup(rqst,\r\nRPCRDMA_INLINE_PAD_VALUE(rqst));\r\nif (padlen) {\r\nheaderp->rm_type = htonl(RDMA_MSGP);\r\nheaderp->rm_body.rm_padded.rm_align =\r\nhtonl(RPCRDMA_INLINE_PAD_VALUE(rqst));\r\nheaderp->rm_body.rm_padded.rm_thresh =\r\nhtonl(RPCRDMA_INLINE_PAD_THRESH);\r\nheaderp->rm_body.rm_padded.rm_pempty[0] = xdr_zero;\r\nheaderp->rm_body.rm_padded.rm_pempty[1] = xdr_zero;\r\nheaderp->rm_body.rm_padded.rm_pempty[2] = xdr_zero;\r\nhdrlen += 2 * sizeof(u32);\r\nBUG_ON(wtype != rpcrdma_noch);\r\n} else {\r\nheaderp->rm_body.rm_nochunks.rm_empty[0] = xdr_zero;\r\nheaderp->rm_body.rm_nochunks.rm_empty[1] = xdr_zero;\r\nheaderp->rm_body.rm_nochunks.rm_empty[2] = xdr_zero;\r\nrpclen = rqst->rq_svec[0].iov_len;\r\nif (wtype == rpcrdma_noch &&\r\nr_xprt->rx_ia.ri_memreg_strategy > RPCRDMA_REGISTER)\r\nwtype = rpcrdma_replych;\r\n}\r\n}\r\nif (rtype != rpcrdma_noch) {\r\nhdrlen = rpcrdma_create_chunks(rqst,\r\n&rqst->rq_snd_buf, headerp, rtype);\r\nwtype = rtype;\r\n} else if (wtype != rpcrdma_noch) {\r\nhdrlen = rpcrdma_create_chunks(rqst,\r\n&rqst->rq_rcv_buf, headerp, wtype);\r\n}\r\nif (hdrlen == 0)\r\nreturn -1;\r\ndprintk("RPC: %s: %s: hdrlen %zd rpclen %zd padlen %zd"\r\n" headerp 0x%p base 0x%p lkey 0x%x\n",\r\n__func__, transfertypes[wtype], hdrlen, rpclen, padlen,\r\nheaderp, base, req->rl_iov.lkey);\r\nreq->rl_send_iov[0].addr = req->rl_iov.addr;\r\nreq->rl_send_iov[0].length = hdrlen;\r\nreq->rl_send_iov[0].lkey = req->rl_iov.lkey;\r\nreq->rl_send_iov[1].addr = req->rl_iov.addr + (base - req->rl_base);\r\nreq->rl_send_iov[1].length = rpclen;\r\nreq->rl_send_iov[1].lkey = req->rl_iov.lkey;\r\nreq->rl_niovs = 2;\r\nif (padlen) {\r\nstruct rpcrdma_ep *ep = &r_xprt->rx_ep;\r\nreq->rl_send_iov[2].addr = ep->rep_pad.addr;\r\nreq->rl_send_iov[2].length = padlen;\r\nreq->rl_send_iov[2].lkey = ep->rep_pad.lkey;\r\nreq->rl_send_iov[3].addr = req->rl_send_iov[1].addr + rpclen;\r\nreq->rl_send_iov[3].length = rqst->rq_slen - rpclen;\r\nreq->rl_send_iov[3].lkey = req->rl_iov.lkey;\r\nreq->rl_niovs = 4;\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\nrpcrdma_count_chunks(struct rpcrdma_rep *rep, unsigned int max, int wrchunk, __be32 **iptrp)\r\n{\r\nunsigned int i, total_len;\r\nstruct rpcrdma_write_chunk *cur_wchunk;\r\ni = ntohl(**iptrp);\r\nif (i > max)\r\nreturn -1;\r\ncur_wchunk = (struct rpcrdma_write_chunk *) (*iptrp + 1);\r\ntotal_len = 0;\r\nwhile (i--) {\r\nstruct rpcrdma_segment *seg = &cur_wchunk->wc_target;\r\nifdebug(FACILITY) {\r\nu64 off;\r\nxdr_decode_hyper((__be32 *)&seg->rs_offset, &off);\r\ndprintk("RPC: %s: chunk %d@0x%llx:0x%x\n",\r\n__func__,\r\nntohl(seg->rs_length),\r\n(unsigned long long)off,\r\nntohl(seg->rs_handle));\r\n}\r\ntotal_len += ntohl(seg->rs_length);\r\n++cur_wchunk;\r\n}\r\nif (wrchunk) {\r\n__be32 *w = (__be32 *) cur_wchunk;\r\nif (*w++ != xdr_zero)\r\nreturn -1;\r\ncur_wchunk = (struct rpcrdma_write_chunk *) w;\r\n}\r\nif ((char *) cur_wchunk > rep->rr_base + rep->rr_len)\r\nreturn -1;\r\n*iptrp = (__be32 *) cur_wchunk;\r\nreturn total_len;\r\n}\r\nstatic void\r\nrpcrdma_inline_fixup(struct rpc_rqst *rqst, char *srcp, int copy_len, int pad)\r\n{\r\nint i, npages, curlen, olen;\r\nchar *destp;\r\nstruct page **ppages;\r\nint page_base;\r\ncurlen = rqst->rq_rcv_buf.head[0].iov_len;\r\nif (curlen > copy_len) {\r\ncurlen = copy_len;\r\nrqst->rq_rcv_buf.head[0].iov_len = curlen;\r\n}\r\ndprintk("RPC: %s: srcp 0x%p len %d hdrlen %d\n",\r\n__func__, srcp, copy_len, curlen);\r\nrqst->rq_rcv_buf.head[0].iov_base = srcp;\r\nsrcp += curlen;\r\ncopy_len -= curlen;\r\nolen = copy_len;\r\ni = 0;\r\nrpcx_to_rdmax(rqst->rq_xprt)->rx_stats.fixup_copy_count += olen;\r\npage_base = rqst->rq_rcv_buf.page_base;\r\nppages = rqst->rq_rcv_buf.pages + (page_base >> PAGE_SHIFT);\r\npage_base &= ~PAGE_MASK;\r\nif (copy_len && rqst->rq_rcv_buf.page_len) {\r\nnpages = PAGE_ALIGN(page_base +\r\nrqst->rq_rcv_buf.page_len) >> PAGE_SHIFT;\r\nfor (; i < npages; i++) {\r\ncurlen = PAGE_SIZE - page_base;\r\nif (curlen > copy_len)\r\ncurlen = copy_len;\r\ndprintk("RPC: %s: page %d"\r\n" srcp 0x%p len %d curlen %d\n",\r\n__func__, i, srcp, copy_len, curlen);\r\ndestp = kmap_atomic(ppages[i]);\r\nmemcpy(destp + page_base, srcp, curlen);\r\nflush_dcache_page(ppages[i]);\r\nkunmap_atomic(destp);\r\nsrcp += curlen;\r\ncopy_len -= curlen;\r\nif (copy_len == 0)\r\nbreak;\r\npage_base = 0;\r\n}\r\nrqst->rq_rcv_buf.page_len = olen - copy_len;\r\n} else\r\nrqst->rq_rcv_buf.page_len = 0;\r\nif (copy_len && rqst->rq_rcv_buf.tail[0].iov_len) {\r\ncurlen = copy_len;\r\nif (curlen > rqst->rq_rcv_buf.tail[0].iov_len)\r\ncurlen = rqst->rq_rcv_buf.tail[0].iov_len;\r\nif (rqst->rq_rcv_buf.tail[0].iov_base != srcp)\r\nmemmove(rqst->rq_rcv_buf.tail[0].iov_base, srcp, curlen);\r\ndprintk("RPC: %s: tail srcp 0x%p len %d curlen %d\n",\r\n__func__, srcp, copy_len, curlen);\r\nrqst->rq_rcv_buf.tail[0].iov_len = curlen;\r\ncopy_len -= curlen; ++i;\r\n} else\r\nrqst->rq_rcv_buf.tail[0].iov_len = 0;\r\nif (pad) {\r\nunsigned char *p = rqst->rq_rcv_buf.tail[0].iov_base;\r\nwhile (pad--)\r\np[rqst->rq_rcv_buf.tail[0].iov_len++] = 0;\r\n}\r\nif (copy_len)\r\ndprintk("RPC: %s: %d bytes in"\r\n" %d extra segments (%d lost)\n",\r\n__func__, olen, i, copy_len);\r\nrqst->rq_private_buf = rqst->rq_rcv_buf;\r\n}\r\nvoid\r\nrpcrdma_conn_func(struct rpcrdma_ep *ep)\r\n{\r\nstruct rpc_xprt *xprt = ep->rep_xprt;\r\nspin_lock_bh(&xprt->transport_lock);\r\nif (++xprt->connect_cookie == 0)\r\n++xprt->connect_cookie;\r\nif (ep->rep_connected > 0) {\r\nif (!xprt_test_and_set_connected(xprt))\r\nxprt_wake_pending_tasks(xprt, 0);\r\n} else {\r\nif (xprt_test_and_clear_connected(xprt))\r\nxprt_wake_pending_tasks(xprt, -ENOTCONN);\r\n}\r\nspin_unlock_bh(&xprt->transport_lock);\r\n}\r\nstatic void\r\nrpcrdma_unbind_func(struct rpcrdma_rep *rep)\r\n{\r\nwake_up(&rep->rr_unbind);\r\n}\r\nvoid\r\nrpcrdma_reply_handler(struct rpcrdma_rep *rep)\r\n{\r\nstruct rpcrdma_msg *headerp;\r\nstruct rpcrdma_req *req;\r\nstruct rpc_rqst *rqst;\r\nstruct rpc_xprt *xprt = rep->rr_xprt;\r\nstruct rpcrdma_xprt *r_xprt = rpcx_to_rdmax(xprt);\r\n__be32 *iptr;\r\nint i, rdmalen, status;\r\nif (rep->rr_len == ~0U) {\r\nrpcrdma_recv_buffer_put(rep);\r\nif (r_xprt->rx_ep.rep_connected == 1) {\r\nr_xprt->rx_ep.rep_connected = -EIO;\r\nrpcrdma_conn_func(&r_xprt->rx_ep);\r\n}\r\nreturn;\r\n}\r\nif (rep->rr_len < 28) {\r\ndprintk("RPC: %s: short/invalid reply\n", __func__);\r\ngoto repost;\r\n}\r\nheaderp = (struct rpcrdma_msg *) rep->rr_base;\r\nif (headerp->rm_vers != xdr_one) {\r\ndprintk("RPC: %s: invalid version %d\n",\r\n__func__, ntohl(headerp->rm_vers));\r\ngoto repost;\r\n}\r\nspin_lock(&xprt->transport_lock);\r\nrqst = xprt_lookup_rqst(xprt, headerp->rm_xid);\r\nif (rqst == NULL) {\r\nspin_unlock(&xprt->transport_lock);\r\ndprintk("RPC: %s: reply 0x%p failed "\r\n"to match any request xid 0x%08x len %d\n",\r\n__func__, rep, headerp->rm_xid, rep->rr_len);\r\nrepost:\r\nr_xprt->rx_stats.bad_reply_count++;\r\nrep->rr_func = rpcrdma_reply_handler;\r\nif (rpcrdma_ep_post_recv(&r_xprt->rx_ia, &r_xprt->rx_ep, rep))\r\nrpcrdma_recv_buffer_put(rep);\r\nreturn;\r\n}\r\nreq = rpcr_to_rdmar(rqst);\r\nif (req->rl_reply) {\r\nspin_unlock(&xprt->transport_lock);\r\ndprintk("RPC: %s: duplicate reply 0x%p to RPC "\r\n"request 0x%p: xid 0x%08x\n", __func__, rep, req,\r\nheaderp->rm_xid);\r\ngoto repost;\r\n}\r\ndprintk("RPC: %s: reply 0x%p completes request 0x%p\n"\r\n" RPC request 0x%p xid 0x%08x\n",\r\n__func__, rep, req, rqst, headerp->rm_xid);\r\nreq->rl_reply = rep;\r\nswitch (headerp->rm_type) {\r\ncase htonl(RDMA_MSG):\r\nif (headerp->rm_body.rm_chunks[0] != xdr_zero ||\r\n(headerp->rm_body.rm_chunks[1] == xdr_zero &&\r\nheaderp->rm_body.rm_chunks[2] != xdr_zero) ||\r\n(headerp->rm_body.rm_chunks[1] != xdr_zero &&\r\nreq->rl_nchunks == 0))\r\ngoto badheader;\r\nif (headerp->rm_body.rm_chunks[1] != xdr_zero) {\r\niptr = &headerp->rm_body.rm_chunks[2];\r\nrdmalen = rpcrdma_count_chunks(rep,\r\nreq->rl_nchunks, 1, &iptr);\r\nif (rdmalen < 0 || *iptr++ != xdr_zero)\r\ngoto badheader;\r\nrep->rr_len -=\r\n((unsigned char *)iptr - (unsigned char *)headerp);\r\nstatus = rep->rr_len + rdmalen;\r\nr_xprt->rx_stats.total_rdma_reply += rdmalen;\r\nif (rdmalen &= 3) {\r\nrdmalen = 4 - rdmalen;\r\nstatus += rdmalen;\r\n}\r\n} else {\r\nrdmalen = 0;\r\niptr = (__be32 *)((unsigned char *)headerp + 28);\r\nrep->rr_len -= 28;\r\nstatus = rep->rr_len;\r\n}\r\nrpcrdma_inline_fixup(rqst, (char *)iptr, rep->rr_len, rdmalen);\r\nbreak;\r\ncase htonl(RDMA_NOMSG):\r\nif (headerp->rm_body.rm_chunks[0] != xdr_zero ||\r\nheaderp->rm_body.rm_chunks[1] != xdr_zero ||\r\nheaderp->rm_body.rm_chunks[2] != xdr_one ||\r\nreq->rl_nchunks == 0)\r\ngoto badheader;\r\niptr = (__be32 *)((unsigned char *)headerp + 28);\r\nrdmalen = rpcrdma_count_chunks(rep, req->rl_nchunks, 0, &iptr);\r\nif (rdmalen < 0)\r\ngoto badheader;\r\nr_xprt->rx_stats.total_rdma_reply += rdmalen;\r\nstatus = rdmalen;\r\nbreak;\r\nbadheader:\r\ndefault:\r\ndprintk("%s: invalid rpcrdma reply header (type %d):"\r\n" chunks[012] == %d %d %d"\r\n" expected chunks <= %d\n",\r\n__func__, ntohl(headerp->rm_type),\r\nheaderp->rm_body.rm_chunks[0],\r\nheaderp->rm_body.rm_chunks[1],\r\nheaderp->rm_body.rm_chunks[2],\r\nreq->rl_nchunks);\r\nstatus = -EIO;\r\nr_xprt->rx_stats.bad_reply_count++;\r\nbreak;\r\n}\r\nif (req->rl_nchunks) switch (r_xprt->rx_ia.ri_memreg_strategy) {\r\ncase RPCRDMA_MEMWINDOWS:\r\nfor (i = 0; req->rl_nchunks-- > 1;)\r\ni += rpcrdma_deregister_external(\r\n&req->rl_segments[i], r_xprt, NULL);\r\nrep->rr_func = rpcrdma_unbind_func;\r\n(void) rpcrdma_deregister_external(&req->rl_segments[i],\r\nr_xprt, rep);\r\nbreak;\r\ncase RPCRDMA_MEMWINDOWS_ASYNC:\r\nfor (i = 0; req->rl_nchunks--;)\r\ni += rpcrdma_deregister_external(&req->rl_segments[i],\r\nr_xprt, NULL);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\ndprintk("RPC: %s: xprt_complete_rqst(0x%p, 0x%p, %d)\n",\r\n__func__, xprt, rqst, status);\r\nxprt_complete_rqst(rqst->rq_task, status);\r\nspin_unlock(&xprt->transport_lock);\r\n}
