void update_page_count(int level, unsigned long pages)\r\n{\r\nspin_lock(&pgd_lock);\r\ndirect_pages_count[level] += pages;\r\nspin_unlock(&pgd_lock);\r\n}\r\nstatic void split_page_count(int level)\r\n{\r\ndirect_pages_count[level]--;\r\ndirect_pages_count[level - 1] += PTRS_PER_PTE;\r\n}\r\nvoid arch_report_meminfo(struct seq_file *m)\r\n{\r\nseq_printf(m, "DirectMap4k: %8lu kB\n",\r\ndirect_pages_count[PG_LEVEL_4K] << 2);\r\n#if defined(CONFIG_X86_64) || defined(CONFIG_X86_PAE)\r\nseq_printf(m, "DirectMap2M: %8lu kB\n",\r\ndirect_pages_count[PG_LEVEL_2M] << 11);\r\n#else\r\nseq_printf(m, "DirectMap4M: %8lu kB\n",\r\ndirect_pages_count[PG_LEVEL_2M] << 12);\r\n#endif\r\n#ifdef CONFIG_X86_64\r\nif (direct_gbpages)\r\nseq_printf(m, "DirectMap1G: %8lu kB\n",\r\ndirect_pages_count[PG_LEVEL_1G] << 20);\r\n#endif\r\n}\r\nstatic inline void split_page_count(int level) { }\r\nstatic inline unsigned long highmap_start_pfn(void)\r\n{\r\nreturn __pa(_text) >> PAGE_SHIFT;\r\n}\r\nstatic inline unsigned long highmap_end_pfn(void)\r\n{\r\nreturn __pa(roundup(_brk_end, PMD_SIZE)) >> PAGE_SHIFT;\r\n}\r\nstatic inline int\r\nwithin(unsigned long addr, unsigned long start, unsigned long end)\r\n{\r\nreturn addr >= start && addr < end;\r\n}\r\nvoid clflush_cache_range(void *vaddr, unsigned int size)\r\n{\r\nvoid *vend = vaddr + size - 1;\r\nmb();\r\nfor (; vaddr < vend; vaddr += boot_cpu_data.x86_clflush_size)\r\nclflush(vaddr);\r\nclflush(vend);\r\nmb();\r\n}\r\nstatic void __cpa_flush_all(void *arg)\r\n{\r\nunsigned long cache = (unsigned long)arg;\r\n__flush_tlb_all();\r\nif (cache && boot_cpu_data.x86 >= 4)\r\nwbinvd();\r\n}\r\nstatic void cpa_flush_all(unsigned long cache)\r\n{\r\nBUG_ON(irqs_disabled());\r\non_each_cpu(__cpa_flush_all, (void *) cache, 1);\r\n}\r\nstatic void __cpa_flush_range(void *arg)\r\n{\r\n__flush_tlb_all();\r\n}\r\nstatic void cpa_flush_range(unsigned long start, int numpages, int cache)\r\n{\r\nunsigned int i, level;\r\nunsigned long addr;\r\nBUG_ON(irqs_disabled());\r\nWARN_ON(PAGE_ALIGN(start) != start);\r\non_each_cpu(__cpa_flush_range, NULL, 1);\r\nif (!cache)\r\nreturn;\r\nfor (i = 0, addr = start; i < numpages; i++, addr += PAGE_SIZE) {\r\npte_t *pte = lookup_address(addr, &level);\r\nif (pte && (pte_val(*pte) & _PAGE_PRESENT))\r\nclflush_cache_range((void *) addr, PAGE_SIZE);\r\n}\r\n}\r\nstatic void cpa_flush_array(unsigned long *start, int numpages, int cache,\r\nint in_flags, struct page **pages)\r\n{\r\nunsigned int i, level;\r\nunsigned long do_wbinvd = cache && numpages >= 1024;\r\nBUG_ON(irqs_disabled());\r\non_each_cpu(__cpa_flush_all, (void *) do_wbinvd, 1);\r\nif (!cache || do_wbinvd)\r\nreturn;\r\nfor (i = 0; i < numpages; i++) {\r\nunsigned long addr;\r\npte_t *pte;\r\nif (in_flags & CPA_PAGES_ARRAY)\r\naddr = (unsigned long)page_address(pages[i]);\r\nelse\r\naddr = start[i];\r\npte = lookup_address(addr, &level);\r\nif (pte && (pte_val(*pte) & _PAGE_PRESENT))\r\nclflush_cache_range((void *)addr, PAGE_SIZE);\r\n}\r\n}\r\nstatic inline pgprot_t static_protections(pgprot_t prot, unsigned long address,\r\nunsigned long pfn)\r\n{\r\npgprot_t forbidden = __pgprot(0);\r\n#ifdef CONFIG_PCI_BIOS\r\nif (pcibios_enabled && within(pfn, BIOS_BEGIN >> PAGE_SHIFT, BIOS_END >> PAGE_SHIFT))\r\npgprot_val(forbidden) |= _PAGE_NX;\r\n#endif\r\nif (within(address, (unsigned long)_text, (unsigned long)_etext))\r\npgprot_val(forbidden) |= _PAGE_NX;\r\nif (within(pfn, __pa((unsigned long)__start_rodata) >> PAGE_SHIFT,\r\n__pa((unsigned long)__end_rodata) >> PAGE_SHIFT))\r\npgprot_val(forbidden) |= _PAGE_RW;\r\n#if defined(CONFIG_X86_64) && defined(CONFIG_DEBUG_RODATA)\r\nif (kernel_set_to_readonly &&\r\nwithin(address, (unsigned long)_text,\r\n(unsigned long)__end_rodata_hpage_align)) {\r\nunsigned int level;\r\nif (lookup_address(address, &level) && (level != PG_LEVEL_4K))\r\npgprot_val(forbidden) |= _PAGE_RW;\r\n}\r\n#endif\r\nprot = __pgprot(pgprot_val(prot) & ~pgprot_val(forbidden));\r\nreturn prot;\r\n}\r\npte_t *lookup_address(unsigned long address, unsigned int *level)\r\n{\r\npgd_t *pgd = pgd_offset_k(address);\r\npud_t *pud;\r\npmd_t *pmd;\r\n*level = PG_LEVEL_NONE;\r\nif (pgd_none(*pgd))\r\nreturn NULL;\r\npud = pud_offset(pgd, address);\r\nif (pud_none(*pud))\r\nreturn NULL;\r\n*level = PG_LEVEL_1G;\r\nif (pud_large(*pud) || !pud_present(*pud))\r\nreturn (pte_t *)pud;\r\npmd = pmd_offset(pud, address);\r\nif (pmd_none(*pmd))\r\nreturn NULL;\r\n*level = PG_LEVEL_2M;\r\nif (pmd_large(*pmd) || !pmd_present(*pmd))\r\nreturn (pte_t *)pmd;\r\n*level = PG_LEVEL_4K;\r\nreturn pte_offset_kernel(pmd, address);\r\n}\r\nstatic void __set_pmd_pte(pte_t *kpte, unsigned long address, pte_t pte)\r\n{\r\nset_pte_atomic(kpte, pte);\r\n#ifdef CONFIG_X86_32\r\nif (!SHARED_KERNEL_PMD) {\r\nstruct page *page;\r\nlist_for_each_entry(page, &pgd_list, lru) {\r\npgd_t *pgd;\r\npud_t *pud;\r\npmd_t *pmd;\r\npgd = (pgd_t *)page_address(page) + pgd_index(address);\r\npud = pud_offset(pgd, address);\r\npmd = pmd_offset(pud, address);\r\nset_pte_atomic((pte_t *)pmd, pte);\r\n}\r\n}\r\n#endif\r\n}\r\nstatic int\r\ntry_preserve_large_page(pte_t *kpte, unsigned long address,\r\nstruct cpa_data *cpa)\r\n{\r\nunsigned long nextpage_addr, numpages, pmask, psize, addr, pfn;\r\npte_t new_pte, old_pte, *tmp;\r\npgprot_t old_prot, new_prot, req_prot;\r\nint i, do_split = 1;\r\nunsigned int level;\r\nif (cpa->force_split)\r\nreturn 1;\r\nspin_lock(&pgd_lock);\r\ntmp = lookup_address(address, &level);\r\nif (tmp != kpte)\r\ngoto out_unlock;\r\nswitch (level) {\r\ncase PG_LEVEL_2M:\r\npsize = PMD_PAGE_SIZE;\r\npmask = PMD_PAGE_MASK;\r\nbreak;\r\n#ifdef CONFIG_X86_64\r\ncase PG_LEVEL_1G:\r\npsize = PUD_PAGE_SIZE;\r\npmask = PUD_PAGE_MASK;\r\nbreak;\r\n#endif\r\ndefault:\r\ndo_split = -EINVAL;\r\ngoto out_unlock;\r\n}\r\nnextpage_addr = (address + psize) & pmask;\r\nnumpages = (nextpage_addr - address) >> PAGE_SHIFT;\r\nif (numpages < cpa->numpages)\r\ncpa->numpages = numpages;\r\nold_pte = *kpte;\r\nold_prot = new_prot = req_prot = pte_pgprot(old_pte);\r\npgprot_val(req_prot) &= ~pgprot_val(cpa->mask_clr);\r\npgprot_val(req_prot) |= pgprot_val(cpa->mask_set);\r\npfn = pte_pfn(old_pte) + ((address & (psize - 1)) >> PAGE_SHIFT);\r\ncpa->pfn = pfn;\r\nnew_prot = static_protections(req_prot, address, pfn);\r\naddr = address & pmask;\r\npfn = pte_pfn(old_pte);\r\nfor (i = 0; i < (psize >> PAGE_SHIFT); i++, addr += PAGE_SIZE, pfn++) {\r\npgprot_t chk_prot = static_protections(req_prot, addr, pfn);\r\nif (pgprot_val(chk_prot) != pgprot_val(new_prot))\r\ngoto out_unlock;\r\n}\r\nif (pgprot_val(new_prot) == pgprot_val(old_prot)) {\r\ndo_split = 0;\r\ngoto out_unlock;\r\n}\r\nif (address == (address & pmask) && cpa->numpages == (psize >> PAGE_SHIFT)) {\r\nnew_pte = pfn_pte(pte_pfn(old_pte), canon_pgprot(new_prot));\r\n__set_pmd_pte(kpte, address, new_pte);\r\ncpa->flags |= CPA_FLUSHTLB;\r\ndo_split = 0;\r\n}\r\nout_unlock:\r\nspin_unlock(&pgd_lock);\r\nreturn do_split;\r\n}\r\nstatic int split_large_page(pte_t *kpte, unsigned long address)\r\n{\r\nunsigned long pfn, pfninc = 1;\r\nunsigned int i, level;\r\npte_t *pbase, *tmp;\r\npgprot_t ref_prot;\r\nstruct page *base;\r\nif (!debug_pagealloc)\r\nspin_unlock(&cpa_lock);\r\nbase = alloc_pages(GFP_KERNEL | __GFP_NOTRACK, 0);\r\nif (!debug_pagealloc)\r\nspin_lock(&cpa_lock);\r\nif (!base)\r\nreturn -ENOMEM;\r\nspin_lock(&pgd_lock);\r\ntmp = lookup_address(address, &level);\r\nif (tmp != kpte)\r\ngoto out_unlock;\r\npbase = (pte_t *)page_address(base);\r\nparavirt_alloc_pte(&init_mm, page_to_pfn(base));\r\nref_prot = pte_pgprot(pte_clrhuge(*kpte));\r\nWARN_ON_ONCE(pgprot_val(ref_prot) & _PAGE_PAT_LARGE);\r\n#ifdef CONFIG_X86_64\r\nif (level == PG_LEVEL_1G) {\r\npfninc = PMD_PAGE_SIZE >> PAGE_SHIFT;\r\npgprot_val(ref_prot) |= _PAGE_PSE;\r\n}\r\n#endif\r\npfn = pte_pfn(*kpte);\r\nfor (i = 0; i < PTRS_PER_PTE; i++, pfn += pfninc)\r\nset_pte(&pbase[i], pfn_pte(pfn, ref_prot));\r\nif (address >= (unsigned long)__va(0) &&\r\naddress < (unsigned long)__va(max_low_pfn_mapped << PAGE_SHIFT))\r\nsplit_page_count(level);\r\n#ifdef CONFIG_X86_64\r\nif (address >= (unsigned long)__va(1UL<<32) &&\r\naddress < (unsigned long)__va(max_pfn_mapped << PAGE_SHIFT))\r\nsplit_page_count(level);\r\n#endif\r\n__set_pmd_pte(kpte, address, mk_pte(base, __pgprot(_KERNPG_TABLE)));\r\n__flush_tlb_all();\r\nbase = NULL;\r\nout_unlock:\r\nif (base)\r\n__free_page(base);\r\nspin_unlock(&pgd_lock);\r\nreturn 0;\r\n}\r\nstatic int __cpa_process_fault(struct cpa_data *cpa, unsigned long vaddr,\r\nint primary)\r\n{\r\nif (!primary)\r\nreturn 0;\r\nif (within(vaddr, PAGE_OFFSET,\r\nPAGE_OFFSET + (max_pfn_mapped << PAGE_SHIFT))) {\r\ncpa->numpages = 1;\r\ncpa->pfn = __pa(vaddr) >> PAGE_SHIFT;\r\nreturn 0;\r\n} else {\r\nWARN(1, KERN_WARNING "CPA: called for zero pte. "\r\n"vaddr = %lx cpa->vaddr = %lx\n", vaddr,\r\n*cpa->vaddr);\r\nreturn -EFAULT;\r\n}\r\n}\r\nstatic int __change_page_attr(struct cpa_data *cpa, int primary)\r\n{\r\nunsigned long address;\r\nint do_split, err;\r\nunsigned int level;\r\npte_t *kpte, old_pte;\r\nif (cpa->flags & CPA_PAGES_ARRAY) {\r\nstruct page *page = cpa->pages[cpa->curpage];\r\nif (unlikely(PageHighMem(page)))\r\nreturn 0;\r\naddress = (unsigned long)page_address(page);\r\n} else if (cpa->flags & CPA_ARRAY)\r\naddress = cpa->vaddr[cpa->curpage];\r\nelse\r\naddress = *cpa->vaddr;\r\nrepeat:\r\nkpte = lookup_address(address, &level);\r\nif (!kpte)\r\nreturn __cpa_process_fault(cpa, address, primary);\r\nold_pte = *kpte;\r\nif (!pte_val(old_pte))\r\nreturn __cpa_process_fault(cpa, address, primary);\r\nif (level == PG_LEVEL_4K) {\r\npte_t new_pte;\r\npgprot_t new_prot = pte_pgprot(old_pte);\r\nunsigned long pfn = pte_pfn(old_pte);\r\npgprot_val(new_prot) &= ~pgprot_val(cpa->mask_clr);\r\npgprot_val(new_prot) |= pgprot_val(cpa->mask_set);\r\nnew_prot = static_protections(new_prot, address, pfn);\r\nnew_pte = pfn_pte(pfn, canon_pgprot(new_prot));\r\ncpa->pfn = pfn;\r\nif (pte_val(old_pte) != pte_val(new_pte)) {\r\nset_pte_atomic(kpte, new_pte);\r\ncpa->flags |= CPA_FLUSHTLB;\r\n}\r\ncpa->numpages = 1;\r\nreturn 0;\r\n}\r\ndo_split = try_preserve_large_page(kpte, address, cpa);\r\nif (do_split <= 0)\r\nreturn do_split;\r\nerr = split_large_page(kpte, address);\r\nif (!err) {\r\nflush_tlb_all();\r\ngoto repeat;\r\n}\r\nreturn err;\r\n}\r\nstatic int cpa_process_alias(struct cpa_data *cpa)\r\n{\r\nstruct cpa_data alias_cpa;\r\nunsigned long laddr = (unsigned long)__va(cpa->pfn << PAGE_SHIFT);\r\nunsigned long vaddr;\r\nint ret;\r\nif (cpa->pfn >= max_pfn_mapped)\r\nreturn 0;\r\n#ifdef CONFIG_X86_64\r\nif (cpa->pfn >= max_low_pfn_mapped && cpa->pfn < (1UL<<(32-PAGE_SHIFT)))\r\nreturn 0;\r\n#endif\r\nif (cpa->flags & CPA_PAGES_ARRAY) {\r\nstruct page *page = cpa->pages[cpa->curpage];\r\nif (unlikely(PageHighMem(page)))\r\nreturn 0;\r\nvaddr = (unsigned long)page_address(page);\r\n} else if (cpa->flags & CPA_ARRAY)\r\nvaddr = cpa->vaddr[cpa->curpage];\r\nelse\r\nvaddr = *cpa->vaddr;\r\nif (!(within(vaddr, PAGE_OFFSET,\r\nPAGE_OFFSET + (max_pfn_mapped << PAGE_SHIFT)))) {\r\nalias_cpa = *cpa;\r\nalias_cpa.vaddr = &laddr;\r\nalias_cpa.flags &= ~(CPA_PAGES_ARRAY | CPA_ARRAY);\r\nret = __change_page_attr_set_clr(&alias_cpa, 0);\r\nif (ret)\r\nreturn ret;\r\n}\r\n#ifdef CONFIG_X86_64\r\nif (!within(vaddr, (unsigned long)_text, _brk_end) &&\r\nwithin(cpa->pfn, highmap_start_pfn(), highmap_end_pfn())) {\r\nunsigned long temp_cpa_vaddr = (cpa->pfn << PAGE_SHIFT) +\r\n__START_KERNEL_map - phys_base;\r\nalias_cpa = *cpa;\r\nalias_cpa.vaddr = &temp_cpa_vaddr;\r\nalias_cpa.flags &= ~(CPA_PAGES_ARRAY | CPA_ARRAY);\r\n__change_page_attr_set_clr(&alias_cpa, 0);\r\n}\r\n#endif\r\nreturn 0;\r\n}\r\nstatic int __change_page_attr_set_clr(struct cpa_data *cpa, int checkalias)\r\n{\r\nint ret, numpages = cpa->numpages;\r\nwhile (numpages) {\r\ncpa->numpages = numpages;\r\nif (cpa->flags & (CPA_ARRAY | CPA_PAGES_ARRAY))\r\ncpa->numpages = 1;\r\nif (!debug_pagealloc)\r\nspin_lock(&cpa_lock);\r\nret = __change_page_attr(cpa, checkalias);\r\nif (!debug_pagealloc)\r\nspin_unlock(&cpa_lock);\r\nif (ret)\r\nreturn ret;\r\nif (checkalias) {\r\nret = cpa_process_alias(cpa);\r\nif (ret)\r\nreturn ret;\r\n}\r\nBUG_ON(cpa->numpages > numpages);\r\nnumpages -= cpa->numpages;\r\nif (cpa->flags & (CPA_PAGES_ARRAY | CPA_ARRAY))\r\ncpa->curpage++;\r\nelse\r\n*cpa->vaddr += cpa->numpages * PAGE_SIZE;\r\n}\r\nreturn 0;\r\n}\r\nstatic inline int cache_attr(pgprot_t attr)\r\n{\r\nreturn pgprot_val(attr) &\r\n(_PAGE_PAT | _PAGE_PAT_LARGE | _PAGE_PWT | _PAGE_PCD);\r\n}\r\nstatic int change_page_attr_set_clr(unsigned long *addr, int numpages,\r\npgprot_t mask_set, pgprot_t mask_clr,\r\nint force_split, int in_flag,\r\nstruct page **pages)\r\n{\r\nstruct cpa_data cpa;\r\nint ret, cache, checkalias;\r\nunsigned long baddr = 0;\r\nmask_set = canon_pgprot(mask_set);\r\nmask_clr = canon_pgprot(mask_clr);\r\nif (!pgprot_val(mask_set) && !pgprot_val(mask_clr) && !force_split)\r\nreturn 0;\r\nif (in_flag & CPA_ARRAY) {\r\nint i;\r\nfor (i = 0; i < numpages; i++) {\r\nif (addr[i] & ~PAGE_MASK) {\r\naddr[i] &= PAGE_MASK;\r\nWARN_ON_ONCE(1);\r\n}\r\n}\r\n} else if (!(in_flag & CPA_PAGES_ARRAY)) {\r\nif (*addr & ~PAGE_MASK) {\r\n*addr &= PAGE_MASK;\r\nWARN_ON_ONCE(1);\r\n}\r\nbaddr = *addr;\r\n}\r\nkmap_flush_unused();\r\nvm_unmap_aliases();\r\ncpa.vaddr = addr;\r\ncpa.pages = pages;\r\ncpa.numpages = numpages;\r\ncpa.mask_set = mask_set;\r\ncpa.mask_clr = mask_clr;\r\ncpa.flags = 0;\r\ncpa.curpage = 0;\r\ncpa.force_split = force_split;\r\nif (in_flag & (CPA_ARRAY | CPA_PAGES_ARRAY))\r\ncpa.flags |= in_flag;\r\ncheckalias = (pgprot_val(mask_set) | pgprot_val(mask_clr)) != _PAGE_NX;\r\nret = __change_page_attr_set_clr(&cpa, checkalias);\r\nif (!(cpa.flags & CPA_FLUSHTLB))\r\ngoto out;\r\ncache = cache_attr(mask_set);\r\nif (!ret && cpu_has_clflush) {\r\nif (cpa.flags & (CPA_PAGES_ARRAY | CPA_ARRAY)) {\r\ncpa_flush_array(addr, numpages, cache,\r\ncpa.flags, pages);\r\n} else\r\ncpa_flush_range(baddr, numpages, cache);\r\n} else\r\ncpa_flush_all(cache);\r\nout:\r\nreturn ret;\r\n}\r\nstatic inline int change_page_attr_set(unsigned long *addr, int numpages,\r\npgprot_t mask, int array)\r\n{\r\nreturn change_page_attr_set_clr(addr, numpages, mask, __pgprot(0), 0,\r\n(array ? CPA_ARRAY : 0), NULL);\r\n}\r\nstatic inline int change_page_attr_clear(unsigned long *addr, int numpages,\r\npgprot_t mask, int array)\r\n{\r\nreturn change_page_attr_set_clr(addr, numpages, __pgprot(0), mask, 0,\r\n(array ? CPA_ARRAY : 0), NULL);\r\n}\r\nstatic inline int cpa_set_pages_array(struct page **pages, int numpages,\r\npgprot_t mask)\r\n{\r\nreturn change_page_attr_set_clr(NULL, numpages, mask, __pgprot(0), 0,\r\nCPA_PAGES_ARRAY, pages);\r\n}\r\nstatic inline int cpa_clear_pages_array(struct page **pages, int numpages,\r\npgprot_t mask)\r\n{\r\nreturn change_page_attr_set_clr(NULL, numpages, __pgprot(0), mask, 0,\r\nCPA_PAGES_ARRAY, pages);\r\n}\r\nint _set_memory_uc(unsigned long addr, int numpages)\r\n{\r\nreturn change_page_attr_set(&addr, numpages,\r\n__pgprot(_PAGE_CACHE_UC_MINUS), 0);\r\n}\r\nint set_memory_uc(unsigned long addr, int numpages)\r\n{\r\nint ret;\r\nret = reserve_memtype(__pa(addr), __pa(addr) + numpages * PAGE_SIZE,\r\n_PAGE_CACHE_UC_MINUS, NULL);\r\nif (ret)\r\ngoto out_err;\r\nret = _set_memory_uc(addr, numpages);\r\nif (ret)\r\ngoto out_free;\r\nreturn 0;\r\nout_free:\r\nfree_memtype(__pa(addr), __pa(addr) + numpages * PAGE_SIZE);\r\nout_err:\r\nreturn ret;\r\n}\r\nstatic int _set_memory_array(unsigned long *addr, int addrinarray,\r\nunsigned long new_type)\r\n{\r\nint i, j;\r\nint ret;\r\nfor (i = 0; i < addrinarray; i++) {\r\nret = reserve_memtype(__pa(addr[i]), __pa(addr[i]) + PAGE_SIZE,\r\nnew_type, NULL);\r\nif (ret)\r\ngoto out_free;\r\n}\r\nret = change_page_attr_set(addr, addrinarray,\r\n__pgprot(_PAGE_CACHE_UC_MINUS), 1);\r\nif (!ret && new_type == _PAGE_CACHE_WC)\r\nret = change_page_attr_set_clr(addr, addrinarray,\r\n__pgprot(_PAGE_CACHE_WC),\r\n__pgprot(_PAGE_CACHE_MASK),\r\n0, CPA_ARRAY, NULL);\r\nif (ret)\r\ngoto out_free;\r\nreturn 0;\r\nout_free:\r\nfor (j = 0; j < i; j++)\r\nfree_memtype(__pa(addr[j]), __pa(addr[j]) + PAGE_SIZE);\r\nreturn ret;\r\n}\r\nint set_memory_array_uc(unsigned long *addr, int addrinarray)\r\n{\r\nreturn _set_memory_array(addr, addrinarray, _PAGE_CACHE_UC_MINUS);\r\n}\r\nint set_memory_array_wc(unsigned long *addr, int addrinarray)\r\n{\r\nreturn _set_memory_array(addr, addrinarray, _PAGE_CACHE_WC);\r\n}\r\nint _set_memory_wc(unsigned long addr, int numpages)\r\n{\r\nint ret;\r\nunsigned long addr_copy = addr;\r\nret = change_page_attr_set(&addr, numpages,\r\n__pgprot(_PAGE_CACHE_UC_MINUS), 0);\r\nif (!ret) {\r\nret = change_page_attr_set_clr(&addr_copy, numpages,\r\n__pgprot(_PAGE_CACHE_WC),\r\n__pgprot(_PAGE_CACHE_MASK),\r\n0, 0, NULL);\r\n}\r\nreturn ret;\r\n}\r\nint set_memory_wc(unsigned long addr, int numpages)\r\n{\r\nint ret;\r\nif (!pat_enabled)\r\nreturn set_memory_uc(addr, numpages);\r\nret = reserve_memtype(__pa(addr), __pa(addr) + numpages * PAGE_SIZE,\r\n_PAGE_CACHE_WC, NULL);\r\nif (ret)\r\ngoto out_err;\r\nret = _set_memory_wc(addr, numpages);\r\nif (ret)\r\ngoto out_free;\r\nreturn 0;\r\nout_free:\r\nfree_memtype(__pa(addr), __pa(addr) + numpages * PAGE_SIZE);\r\nout_err:\r\nreturn ret;\r\n}\r\nint _set_memory_wb(unsigned long addr, int numpages)\r\n{\r\nreturn change_page_attr_clear(&addr, numpages,\r\n__pgprot(_PAGE_CACHE_MASK), 0);\r\n}\r\nint set_memory_wb(unsigned long addr, int numpages)\r\n{\r\nint ret;\r\nret = _set_memory_wb(addr, numpages);\r\nif (ret)\r\nreturn ret;\r\nfree_memtype(__pa(addr), __pa(addr) + numpages * PAGE_SIZE);\r\nreturn 0;\r\n}\r\nint set_memory_array_wb(unsigned long *addr, int addrinarray)\r\n{\r\nint i;\r\nint ret;\r\nret = change_page_attr_clear(addr, addrinarray,\r\n__pgprot(_PAGE_CACHE_MASK), 1);\r\nif (ret)\r\nreturn ret;\r\nfor (i = 0; i < addrinarray; i++)\r\nfree_memtype(__pa(addr[i]), __pa(addr[i]) + PAGE_SIZE);\r\nreturn 0;\r\n}\r\nint set_memory_x(unsigned long addr, int numpages)\r\n{\r\nif (!(__supported_pte_mask & _PAGE_NX))\r\nreturn 0;\r\nreturn change_page_attr_clear(&addr, numpages, __pgprot(_PAGE_NX), 0);\r\n}\r\nint set_memory_nx(unsigned long addr, int numpages)\r\n{\r\nif (!(__supported_pte_mask & _PAGE_NX))\r\nreturn 0;\r\nreturn change_page_attr_set(&addr, numpages, __pgprot(_PAGE_NX), 0);\r\n}\r\nint set_memory_ro(unsigned long addr, int numpages)\r\n{\r\nreturn change_page_attr_clear(&addr, numpages, __pgprot(_PAGE_RW), 0);\r\n}\r\nint set_memory_rw(unsigned long addr, int numpages)\r\n{\r\nreturn change_page_attr_set(&addr, numpages, __pgprot(_PAGE_RW), 0);\r\n}\r\nint set_memory_np(unsigned long addr, int numpages)\r\n{\r\nreturn change_page_attr_clear(&addr, numpages, __pgprot(_PAGE_PRESENT), 0);\r\n}\r\nint set_memory_4k(unsigned long addr, int numpages)\r\n{\r\nreturn change_page_attr_set_clr(&addr, numpages, __pgprot(0),\r\n__pgprot(0), 1, 0, NULL);\r\n}\r\nint set_pages_uc(struct page *page, int numpages)\r\n{\r\nunsigned long addr = (unsigned long)page_address(page);\r\nreturn set_memory_uc(addr, numpages);\r\n}\r\nstatic int _set_pages_array(struct page **pages, int addrinarray,\r\nunsigned long new_type)\r\n{\r\nunsigned long start;\r\nunsigned long end;\r\nint i;\r\nint free_idx;\r\nint ret;\r\nfor (i = 0; i < addrinarray; i++) {\r\nif (PageHighMem(pages[i]))\r\ncontinue;\r\nstart = page_to_pfn(pages[i]) << PAGE_SHIFT;\r\nend = start + PAGE_SIZE;\r\nif (reserve_memtype(start, end, new_type, NULL))\r\ngoto err_out;\r\n}\r\nret = cpa_set_pages_array(pages, addrinarray,\r\n__pgprot(_PAGE_CACHE_UC_MINUS));\r\nif (!ret && new_type == _PAGE_CACHE_WC)\r\nret = change_page_attr_set_clr(NULL, addrinarray,\r\n__pgprot(_PAGE_CACHE_WC),\r\n__pgprot(_PAGE_CACHE_MASK),\r\n0, CPA_PAGES_ARRAY, pages);\r\nif (ret)\r\ngoto err_out;\r\nreturn 0;\r\nerr_out:\r\nfree_idx = i;\r\nfor (i = 0; i < free_idx; i++) {\r\nif (PageHighMem(pages[i]))\r\ncontinue;\r\nstart = page_to_pfn(pages[i]) << PAGE_SHIFT;\r\nend = start + PAGE_SIZE;\r\nfree_memtype(start, end);\r\n}\r\nreturn -EINVAL;\r\n}\r\nint set_pages_array_uc(struct page **pages, int addrinarray)\r\n{\r\nreturn _set_pages_array(pages, addrinarray, _PAGE_CACHE_UC_MINUS);\r\n}\r\nint set_pages_array_wc(struct page **pages, int addrinarray)\r\n{\r\nreturn _set_pages_array(pages, addrinarray, _PAGE_CACHE_WC);\r\n}\r\nint set_pages_wb(struct page *page, int numpages)\r\n{\r\nunsigned long addr = (unsigned long)page_address(page);\r\nreturn set_memory_wb(addr, numpages);\r\n}\r\nint set_pages_array_wb(struct page **pages, int addrinarray)\r\n{\r\nint retval;\r\nunsigned long start;\r\nunsigned long end;\r\nint i;\r\nretval = cpa_clear_pages_array(pages, addrinarray,\r\n__pgprot(_PAGE_CACHE_MASK));\r\nif (retval)\r\nreturn retval;\r\nfor (i = 0; i < addrinarray; i++) {\r\nif (PageHighMem(pages[i]))\r\ncontinue;\r\nstart = page_to_pfn(pages[i]) << PAGE_SHIFT;\r\nend = start + PAGE_SIZE;\r\nfree_memtype(start, end);\r\n}\r\nreturn 0;\r\n}\r\nint set_pages_x(struct page *page, int numpages)\r\n{\r\nunsigned long addr = (unsigned long)page_address(page);\r\nreturn set_memory_x(addr, numpages);\r\n}\r\nint set_pages_nx(struct page *page, int numpages)\r\n{\r\nunsigned long addr = (unsigned long)page_address(page);\r\nreturn set_memory_nx(addr, numpages);\r\n}\r\nint set_pages_ro(struct page *page, int numpages)\r\n{\r\nunsigned long addr = (unsigned long)page_address(page);\r\nreturn set_memory_ro(addr, numpages);\r\n}\r\nint set_pages_rw(struct page *page, int numpages)\r\n{\r\nunsigned long addr = (unsigned long)page_address(page);\r\nreturn set_memory_rw(addr, numpages);\r\n}\r\nstatic int __set_pages_p(struct page *page, int numpages)\r\n{\r\nunsigned long tempaddr = (unsigned long) page_address(page);\r\nstruct cpa_data cpa = { .vaddr = &tempaddr,\r\n.numpages = numpages,\r\n.mask_set = __pgprot(_PAGE_PRESENT | _PAGE_RW),\r\n.mask_clr = __pgprot(0),\r\n.flags = 0};\r\nreturn __change_page_attr_set_clr(&cpa, 0);\r\n}\r\nstatic int __set_pages_np(struct page *page, int numpages)\r\n{\r\nunsigned long tempaddr = (unsigned long) page_address(page);\r\nstruct cpa_data cpa = { .vaddr = &tempaddr,\r\n.numpages = numpages,\r\n.mask_set = __pgprot(0),\r\n.mask_clr = __pgprot(_PAGE_PRESENT | _PAGE_RW),\r\n.flags = 0};\r\nreturn __change_page_attr_set_clr(&cpa, 0);\r\n}\r\nvoid kernel_map_pages(struct page *page, int numpages, int enable)\r\n{\r\nif (PageHighMem(page))\r\nreturn;\r\nif (!enable) {\r\ndebug_check_no_locks_freed(page_address(page),\r\nnumpages * PAGE_SIZE);\r\n}\r\nif (enable)\r\n__set_pages_p(page, numpages);\r\nelse\r\n__set_pages_np(page, numpages);\r\n__flush_tlb_all();\r\n}\r\nbool kernel_page_present(struct page *page)\r\n{\r\nunsigned int level;\r\npte_t *pte;\r\nif (PageHighMem(page))\r\nreturn false;\r\npte = lookup_address((unsigned long)page_address(page), &level);\r\nreturn (pte_val(*pte) & _PAGE_PRESENT);\r\n}
