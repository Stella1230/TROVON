static __init int init_emergency_pool(void)\r\n{\r\n#if defined(CONFIG_HIGHMEM) && !defined(CONFIG_MEMORY_HOTPLUG)\r\nif (max_pfn <= max_low_pfn)\r\nreturn 0;\r\n#endif\r\npage_pool = mempool_create_page_pool(POOL_SIZE, 0);\r\nBUG_ON(!page_pool);\r\nprintk("bounce pool size: %d pages\n", POOL_SIZE);\r\nreturn 0;\r\n}\r\nstatic void bounce_copy_vec(struct bio_vec *to, unsigned char *vfrom)\r\n{\r\nunsigned long flags;\r\nunsigned char *vto;\r\nlocal_irq_save(flags);\r\nvto = kmap_atomic(to->bv_page);\r\nmemcpy(vto + to->bv_offset, vfrom, to->bv_len);\r\nkunmap_atomic(vto);\r\nlocal_irq_restore(flags);\r\n}\r\nstatic void *mempool_alloc_pages_isa(gfp_t gfp_mask, void *data)\r\n{\r\nreturn mempool_alloc_pages(gfp_mask | GFP_DMA, data);\r\n}\r\nint init_emergency_isa_pool(void)\r\n{\r\nif (isa_page_pool)\r\nreturn 0;\r\nisa_page_pool = mempool_create(ISA_POOL_SIZE, mempool_alloc_pages_isa,\r\nmempool_free_pages, (void *) 0);\r\nBUG_ON(!isa_page_pool);\r\nprintk("isa bounce pool size: %d pages\n", ISA_POOL_SIZE);\r\nreturn 0;\r\n}\r\nstatic void copy_to_high_bio_irq(struct bio *to, struct bio *from)\r\n{\r\nunsigned char *vfrom;\r\nstruct bio_vec *tovec, *fromvec;\r\nint i;\r\n__bio_for_each_segment(tovec, to, i, 0) {\r\nfromvec = from->bi_io_vec + i;\r\nif (tovec->bv_page == fromvec->bv_page)\r\ncontinue;\r\nvfrom = page_address(fromvec->bv_page) + tovec->bv_offset;\r\nbounce_copy_vec(tovec, vfrom);\r\nflush_dcache_page(tovec->bv_page);\r\n}\r\n}\r\nstatic void bounce_end_io(struct bio *bio, mempool_t *pool, int err)\r\n{\r\nstruct bio *bio_orig = bio->bi_private;\r\nstruct bio_vec *bvec, *org_vec;\r\nint i;\r\nif (test_bit(BIO_EOPNOTSUPP, &bio->bi_flags))\r\nset_bit(BIO_EOPNOTSUPP, &bio_orig->bi_flags);\r\n__bio_for_each_segment(bvec, bio, i, 0) {\r\norg_vec = bio_orig->bi_io_vec + i;\r\nif (bvec->bv_page == org_vec->bv_page)\r\ncontinue;\r\ndec_zone_page_state(bvec->bv_page, NR_BOUNCE);\r\nmempool_free(bvec->bv_page, pool);\r\n}\r\nbio_endio(bio_orig, err);\r\nbio_put(bio);\r\n}\r\nstatic void bounce_end_io_write(struct bio *bio, int err)\r\n{\r\nbounce_end_io(bio, page_pool, err);\r\n}\r\nstatic void bounce_end_io_write_isa(struct bio *bio, int err)\r\n{\r\nbounce_end_io(bio, isa_page_pool, err);\r\n}\r\nstatic void __bounce_end_io_read(struct bio *bio, mempool_t *pool, int err)\r\n{\r\nstruct bio *bio_orig = bio->bi_private;\r\nif (test_bit(BIO_UPTODATE, &bio->bi_flags))\r\ncopy_to_high_bio_irq(bio_orig, bio);\r\nbounce_end_io(bio, pool, err);\r\n}\r\nstatic void bounce_end_io_read(struct bio *bio, int err)\r\n{\r\n__bounce_end_io_read(bio, page_pool, err);\r\n}\r\nstatic void bounce_end_io_read_isa(struct bio *bio, int err)\r\n{\r\n__bounce_end_io_read(bio, isa_page_pool, err);\r\n}\r\nstatic void __blk_queue_bounce(struct request_queue *q, struct bio **bio_orig,\r\nmempool_t *pool)\r\n{\r\nstruct page *page;\r\nstruct bio *bio = NULL;\r\nint i, rw = bio_data_dir(*bio_orig);\r\nstruct bio_vec *to, *from;\r\nbio_for_each_segment(from, *bio_orig, i) {\r\npage = from->bv_page;\r\nif (page_to_pfn(page) <= queue_bounce_pfn(q))\r\ncontinue;\r\nif (!bio) {\r\nunsigned int cnt = (*bio_orig)->bi_vcnt;\r\nbio = bio_alloc(GFP_NOIO, cnt);\r\nmemset(bio->bi_io_vec, 0, cnt * sizeof(struct bio_vec));\r\n}\r\nto = bio->bi_io_vec + i;\r\nto->bv_page = mempool_alloc(pool, q->bounce_gfp);\r\nto->bv_len = from->bv_len;\r\nto->bv_offset = from->bv_offset;\r\ninc_zone_page_state(to->bv_page, NR_BOUNCE);\r\nif (rw == WRITE) {\r\nchar *vto, *vfrom;\r\nflush_dcache_page(from->bv_page);\r\nvto = page_address(to->bv_page) + to->bv_offset;\r\nvfrom = kmap(from->bv_page) + from->bv_offset;\r\nmemcpy(vto, vfrom, to->bv_len);\r\nkunmap(from->bv_page);\r\n}\r\n}\r\nif (!bio)\r\nreturn;\r\ntrace_block_bio_bounce(q, *bio_orig);\r\n__bio_for_each_segment(from, *bio_orig, i, 0) {\r\nto = bio_iovec_idx(bio, i);\r\nif (!to->bv_page) {\r\nto->bv_page = from->bv_page;\r\nto->bv_len = from->bv_len;\r\nto->bv_offset = from->bv_offset;\r\n}\r\n}\r\nbio->bi_bdev = (*bio_orig)->bi_bdev;\r\nbio->bi_flags |= (1 << BIO_BOUNCED);\r\nbio->bi_sector = (*bio_orig)->bi_sector;\r\nbio->bi_rw = (*bio_orig)->bi_rw;\r\nbio->bi_vcnt = (*bio_orig)->bi_vcnt;\r\nbio->bi_idx = (*bio_orig)->bi_idx;\r\nbio->bi_size = (*bio_orig)->bi_size;\r\nif (pool == page_pool) {\r\nbio->bi_end_io = bounce_end_io_write;\r\nif (rw == READ)\r\nbio->bi_end_io = bounce_end_io_read;\r\n} else {\r\nbio->bi_end_io = bounce_end_io_write_isa;\r\nif (rw == READ)\r\nbio->bi_end_io = bounce_end_io_read_isa;\r\n}\r\nbio->bi_private = *bio_orig;\r\n*bio_orig = bio;\r\n}\r\nvoid blk_queue_bounce(struct request_queue *q, struct bio **bio_orig)\r\n{\r\nmempool_t *pool;\r\nif (!bio_has_data(*bio_orig))\r\nreturn;\r\nif (!(q->bounce_gfp & GFP_DMA)) {\r\nif (queue_bounce_pfn(q) >= blk_max_pfn)\r\nreturn;\r\npool = page_pool;\r\n} else {\r\nBUG_ON(!isa_page_pool);\r\npool = isa_page_pool;\r\n}\r\n__blk_queue_bounce(q, bio_orig, pool);\r\n}
