void ptlrpcd_wake(struct ptlrpc_request *req)\r\n{\r\nstruct ptlrpc_request_set *rq_set = req->rq_set;\r\nLASSERT(rq_set != NULL);\r\nwake_up(&rq_set->set_waitq);\r\n}\r\nstatic struct ptlrpcd_ctl *\r\nptlrpcd_select_pc(struct ptlrpc_request *req, pdl_policy_t policy, int index)\r\n{\r\nint idx = 0;\r\nif (req != NULL && req->rq_send_state != LUSTRE_IMP_FULL)\r\nreturn &ptlrpcds->pd_thread_rcv;\r\nswitch (policy) {\r\ncase PDL_POLICY_SAME:\r\nidx = smp_processor_id() % ptlrpcds->pd_nthreads;\r\nbreak;\r\ncase PDL_POLICY_LOCAL:\r\n# ifdef CFS_CPU_MODE_NUMA\r\n# warning "fix this code to use new CPU partition APIs"\r\n# endif\r\nindex = -1;\r\ncase PDL_POLICY_PREFERRED:\r\nif (index >= 0 && index < num_online_cpus()) {\r\nidx = index % ptlrpcds->pd_nthreads;\r\nbreak;\r\n}\r\ndefault:\r\ncase PDL_POLICY_ROUND:\r\nidx = ptlrpcds->pd_index + 1;\r\nif (idx == smp_processor_id())\r\nidx++;\r\nidx %= ptlrpcds->pd_nthreads;\r\nptlrpcds->pd_index = idx;\r\nbreak;\r\n}\r\nreturn &ptlrpcds->pd_threads[idx];\r\n}\r\nvoid ptlrpcd_add_rqset(struct ptlrpc_request_set *set)\r\n{\r\nstruct list_head *tmp, *pos;\r\nstruct ptlrpcd_ctl *pc;\r\nstruct ptlrpc_request_set *new;\r\nint count, i;\r\npc = ptlrpcd_select_pc(NULL, PDL_POLICY_LOCAL, -1);\r\nnew = pc->pc_set;\r\nlist_for_each_safe(pos, tmp, &set->set_requests) {\r\nstruct ptlrpc_request *req =\r\nlist_entry(pos, struct ptlrpc_request,\r\nrq_set_chain);\r\nLASSERT(req->rq_phase == RQ_PHASE_NEW);\r\nreq->rq_set = new;\r\nreq->rq_queued_time = cfs_time_current();\r\n}\r\nspin_lock(&new->set_new_req_lock);\r\nlist_splice_init(&set->set_requests, &new->set_new_requests);\r\ni = atomic_read(&set->set_remaining);\r\ncount = atomic_add_return(i, &new->set_new_count);\r\natomic_set(&set->set_remaining, 0);\r\nspin_unlock(&new->set_new_req_lock);\r\nif (count == i) {\r\nwake_up(&new->set_waitq);\r\nfor (i = 0; i < pc->pc_npartners; i++)\r\nwake_up(&pc->pc_partners[i]->pc_set->set_waitq);\r\n}\r\n}\r\nstatic int ptlrpcd_steal_rqset(struct ptlrpc_request_set *des,\r\nstruct ptlrpc_request_set *src)\r\n{\r\nstruct list_head *tmp, *pos;\r\nstruct ptlrpc_request *req;\r\nint rc = 0;\r\nspin_lock(&src->set_new_req_lock);\r\nif (likely(!list_empty(&src->set_new_requests))) {\r\nlist_for_each_safe(pos, tmp, &src->set_new_requests) {\r\nreq = list_entry(pos, struct ptlrpc_request,\r\nrq_set_chain);\r\nreq->rq_set = des;\r\n}\r\nlist_splice_init(&src->set_new_requests,\r\n&des->set_requests);\r\nrc = atomic_read(&src->set_new_count);\r\natomic_add(rc, &des->set_remaining);\r\natomic_set(&src->set_new_count, 0);\r\n}\r\nspin_unlock(&src->set_new_req_lock);\r\nreturn rc;\r\n}\r\nvoid ptlrpcd_add_req(struct ptlrpc_request *req, pdl_policy_t policy, int idx)\r\n{\r\nstruct ptlrpcd_ctl *pc;\r\nif (req->rq_reqmsg)\r\nlustre_msg_set_jobid(req->rq_reqmsg, NULL);\r\nspin_lock(&req->rq_lock);\r\nif (req->rq_invalid_rqset) {\r\nstruct l_wait_info lwi = LWI_TIMEOUT(cfs_time_seconds(5),\r\nback_to_sleep, NULL);\r\nreq->rq_invalid_rqset = 0;\r\nspin_unlock(&req->rq_lock);\r\nl_wait_event(req->rq_set_waitq, (req->rq_set == NULL), &lwi);\r\n} else if (req->rq_set) {\r\nLASSERT(req->rq_phase == RQ_PHASE_NEW);\r\nLASSERT(req->rq_send_state == LUSTRE_IMP_REPLAY);\r\natomic_inc(&req->rq_set->set_remaining);\r\nspin_unlock(&req->rq_lock);\r\nwake_up(&req->rq_set->set_waitq);\r\nreturn;\r\n} else {\r\nspin_unlock(&req->rq_lock);\r\n}\r\npc = ptlrpcd_select_pc(req, policy, idx);\r\nDEBUG_REQ(D_INFO, req, "add req [%p] to pc [%s:%d]",\r\nreq, pc->pc_name, pc->pc_index);\r\nptlrpc_set_add_new_req(pc, req);\r\n}\r\nstatic inline void ptlrpc_reqset_get(struct ptlrpc_request_set *set)\r\n{\r\natomic_inc(&set->set_refcount);\r\n}\r\nstatic int ptlrpcd_check(struct lu_env *env, struct ptlrpcd_ctl *pc)\r\n{\r\nstruct list_head *tmp, *pos;\r\nstruct ptlrpc_request *req;\r\nstruct ptlrpc_request_set *set = pc->pc_set;\r\nint rc = 0;\r\nint rc2;\r\nif (atomic_read(&set->set_new_count)) {\r\nspin_lock(&set->set_new_req_lock);\r\nif (likely(!list_empty(&set->set_new_requests))) {\r\nlist_splice_init(&set->set_new_requests,\r\n&set->set_requests);\r\natomic_add(atomic_read(&set->set_new_count),\r\n&set->set_remaining);\r\natomic_set(&set->set_new_count, 0);\r\nrc = 1;\r\n}\r\nspin_unlock(&set->set_new_req_lock);\r\n}\r\nrc2 = lu_env_refill(env);\r\nif (rc2 != 0) {\r\nCERROR("Failure to refill session: %d\n", rc2);\r\nreturn rc;\r\n}\r\nif (atomic_read(&set->set_remaining))\r\nrc |= ptlrpc_check_set(env, set);\r\nif (!list_empty(&set->set_requests)) {\r\nlist_for_each_safe(pos, tmp, &set->set_requests) {\r\nreq = list_entry(pos, struct ptlrpc_request,\r\nrq_set_chain);\r\nif (req->rq_phase != RQ_PHASE_COMPLETE)\r\ncontinue;\r\nlist_del_init(&req->rq_set_chain);\r\nreq->rq_set = NULL;\r\nptlrpc_req_finished(req);\r\n}\r\n}\r\nif (rc == 0) {\r\nrc = atomic_read(&set->set_new_count);\r\nif (rc == 0 && pc->pc_npartners > 0) {\r\nstruct ptlrpcd_ctl *partner;\r\nstruct ptlrpc_request_set *ps;\r\nint first = pc->pc_cursor;\r\ndo {\r\npartner = pc->pc_partners[pc->pc_cursor++];\r\nif (pc->pc_cursor >= pc->pc_npartners)\r\npc->pc_cursor = 0;\r\nif (partner == NULL)\r\ncontinue;\r\nspin_lock(&partner->pc_lock);\r\nps = partner->pc_set;\r\nif (ps == NULL) {\r\nspin_unlock(&partner->pc_lock);\r\ncontinue;\r\n}\r\nptlrpc_reqset_get(ps);\r\nspin_unlock(&partner->pc_lock);\r\nif (atomic_read(&ps->set_new_count)) {\r\nrc = ptlrpcd_steal_rqset(set, ps);\r\nif (rc > 0)\r\nCDEBUG(D_RPCTRACE, "transfer %d"\r\n" async RPCs [%d->%d]\n",\r\nrc, partner->pc_index,\r\npc->pc_index);\r\n}\r\nptlrpc_reqset_put(ps);\r\n} while (rc == 0 && pc->pc_cursor != first);\r\n}\r\n}\r\nreturn rc;\r\n}\r\nstatic int ptlrpcd(void *arg)\r\n{\r\nstruct ptlrpcd_ctl *pc = arg;\r\nstruct ptlrpc_request_set *set = pc->pc_set;\r\nstruct lu_env env = { .le_ses = NULL };\r\nint rc, exit = 0;\r\nunshare_fs_struct();\r\n#if defined(CONFIG_SMP)\r\nif (test_bit(LIOD_BIND, &pc->pc_flags)) {\r\nint index = pc->pc_index;\r\nif (index >= 0 && index < num_possible_cpus()) {\r\nwhile (!cpu_online(index)) {\r\nif (++index >= num_possible_cpus())\r\nindex = 0;\r\n}\r\nset_cpus_allowed_ptr(current,\r\ncpumask_of_node(cpu_to_node(index)));\r\n}\r\n}\r\n#endif\r\nrc = lu_context_init(&env.le_ctx,\r\nLCT_CL_THREAD|LCT_REMEMBER|LCT_NOREF);\r\ncomplete(&pc->pc_starting);\r\nif (rc != 0)\r\nreturn rc;\r\ndo {\r\nstruct l_wait_info lwi;\r\nint timeout;\r\ntimeout = ptlrpc_set_next_timeout(set);\r\nlwi = LWI_TIMEOUT(cfs_time_seconds(timeout ? timeout : 1),\r\nptlrpc_expired_set, set);\r\nlu_context_enter(&env.le_ctx);\r\nl_wait_event(set->set_waitq,\r\nptlrpcd_check(&env, pc), &lwi);\r\nlu_context_exit(&env.le_ctx);\r\nif (test_bit(LIOD_STOP, &pc->pc_flags)) {\r\nif (test_bit(LIOD_FORCE, &pc->pc_flags))\r\nptlrpc_abort_set(set);\r\nexit++;\r\n}\r\n} while (exit < 2);\r\nif (!list_empty(&set->set_requests))\r\nptlrpc_set_wait(set);\r\nlu_context_fini(&env.le_ctx);\r\ncomplete(&pc->pc_finishing);\r\nreturn 0;\r\n}\r\nstatic int ptlrpcd_bind(int index, int max)\r\n{\r\nstruct ptlrpcd_ctl *pc;\r\nint rc = 0;\r\n#if defined(CONFIG_NUMA)\r\ncpumask_t mask;\r\n#endif\r\nLASSERT(index <= max - 1);\r\npc = &ptlrpcds->pd_threads[index];\r\nswitch (ptlrpcd_bind_policy) {\r\ncase PDB_POLICY_NONE:\r\npc->pc_npartners = -1;\r\nbreak;\r\ncase PDB_POLICY_FULL:\r\npc->pc_npartners = 0;\r\nset_bit(LIOD_BIND, &pc->pc_flags);\r\nbreak;\r\ncase PDB_POLICY_PAIR:\r\nLASSERT(max % 2 == 0);\r\npc->pc_npartners = 1;\r\nbreak;\r\ncase PDB_POLICY_NEIGHBOR:\r\n#if defined(CONFIG_NUMA)\r\n{\r\nint i;\r\nmask = *cpumask_of_node(cpu_to_node(index));\r\nfor (i = max; i < num_online_cpus(); i++)\r\ncpu_clear(i, mask);\r\npc->pc_npartners = cpus_weight(mask) - 1;\r\nset_bit(LIOD_BIND, &pc->pc_flags);\r\n}\r\n#else\r\nLASSERT(max >= 3);\r\npc->pc_npartners = 2;\r\n#endif\r\nbreak;\r\ndefault:\r\nCERROR("unknown ptlrpcd bind policy %d\n", ptlrpcd_bind_policy);\r\nrc = -EINVAL;\r\n}\r\nif (rc == 0 && pc->pc_npartners > 0) {\r\nOBD_ALLOC(pc->pc_partners,\r\nsizeof(struct ptlrpcd_ctl *) * pc->pc_npartners);\r\nif (pc->pc_partners == NULL) {\r\npc->pc_npartners = 0;\r\nrc = -ENOMEM;\r\n} else {\r\nswitch (ptlrpcd_bind_policy) {\r\ncase PDB_POLICY_PAIR:\r\nif (index & 0x1) {\r\nset_bit(LIOD_BIND, &pc->pc_flags);\r\npc->pc_partners[0] = &ptlrpcds->\r\npd_threads[index - 1];\r\nptlrpcds->pd_threads[index - 1].\r\npc_partners[0] = pc;\r\n}\r\nbreak;\r\ncase PDB_POLICY_NEIGHBOR:\r\n#if defined(CONFIG_NUMA)\r\n{\r\nstruct ptlrpcd_ctl *ppc;\r\nint i, pidx;\r\nfor (pidx = 0, i = 0; i < index; i++) {\r\nif (cpu_isset(i, mask)) {\r\nppc = &ptlrpcds->pd_threads[i];\r\npc->pc_partners[pidx++] = ppc;\r\nppc->pc_partners[ppc->\r\npc_npartners++] = pc;\r\n}\r\n}\r\npc->pc_npartners = pidx;\r\n}\r\n#else\r\nif (index & 0x1)\r\nset_bit(LIOD_BIND, &pc->pc_flags);\r\nif (index > 0) {\r\npc->pc_partners[0] = &ptlrpcds->\r\npd_threads[index - 1];\r\nptlrpcds->pd_threads[index - 1].\r\npc_partners[1] = pc;\r\nif (index == max - 1) {\r\npc->pc_partners[1] =\r\n&ptlrpcds->pd_threads[0];\r\nptlrpcds->pd_threads[0].\r\npc_partners[0] = pc;\r\n}\r\n}\r\n#endif\r\nbreak;\r\n}\r\n}\r\n}\r\nreturn rc;\r\n}\r\nint ptlrpcd_start(int index, int max, const char *name, struct ptlrpcd_ctl *pc)\r\n{\r\nint rc;\r\nif (test_and_set_bit(LIOD_START, &pc->pc_flags)) {\r\nCWARN("Starting second thread (%s) for same pc %p\n",\r\nname, pc);\r\nreturn 0;\r\n}\r\npc->pc_index = index;\r\ninit_completion(&pc->pc_starting);\r\ninit_completion(&pc->pc_finishing);\r\nspin_lock_init(&pc->pc_lock);\r\nstrlcpy(pc->pc_name, name, sizeof(pc->pc_name));\r\npc->pc_set = ptlrpc_prep_set();\r\nif (pc->pc_set == NULL)\r\nGOTO(out, rc = -ENOMEM);\r\nrc = lu_context_init(&pc->pc_env.le_ctx, LCT_CL_THREAD|LCT_REMEMBER);\r\nif (rc != 0)\r\nGOTO(out_set, rc);\r\n{\r\nstruct task_struct *task;\r\nif (index >= 0) {\r\nrc = ptlrpcd_bind(index, max);\r\nif (rc < 0)\r\nGOTO(out_env, rc);\r\n}\r\ntask = kthread_run(ptlrpcd, pc, "%s", pc->pc_name);\r\nif (IS_ERR(task))\r\nGOTO(out_env, rc = PTR_ERR(task));\r\nwait_for_completion(&pc->pc_starting);\r\n}\r\nreturn 0;\r\nout_env:\r\nlu_context_fini(&pc->pc_env.le_ctx);\r\nout_set:\r\nif (pc->pc_set != NULL) {\r\nstruct ptlrpc_request_set *set = pc->pc_set;\r\nspin_lock(&pc->pc_lock);\r\npc->pc_set = NULL;\r\nspin_unlock(&pc->pc_lock);\r\nptlrpc_set_destroy(set);\r\n}\r\nclear_bit(LIOD_BIND, &pc->pc_flags);\r\nout:\r\nclear_bit(LIOD_START, &pc->pc_flags);\r\nreturn rc;\r\n}\r\nvoid ptlrpcd_stop(struct ptlrpcd_ctl *pc, int force)\r\n{\r\nif (!test_bit(LIOD_START, &pc->pc_flags)) {\r\nCWARN("Thread for pc %p was not started\n", pc);\r\nreturn;\r\n}\r\nset_bit(LIOD_STOP, &pc->pc_flags);\r\nif (force)\r\nset_bit(LIOD_FORCE, &pc->pc_flags);\r\nwake_up(&pc->pc_set->set_waitq);\r\n}\r\nvoid ptlrpcd_free(struct ptlrpcd_ctl *pc)\r\n{\r\nstruct ptlrpc_request_set *set = pc->pc_set;\r\nif (!test_bit(LIOD_START, &pc->pc_flags)) {\r\nCWARN("Thread for pc %p was not started\n", pc);\r\ngoto out;\r\n}\r\nwait_for_completion(&pc->pc_finishing);\r\nlu_context_fini(&pc->pc_env.le_ctx);\r\nspin_lock(&pc->pc_lock);\r\npc->pc_set = NULL;\r\nspin_unlock(&pc->pc_lock);\r\nptlrpc_set_destroy(set);\r\nclear_bit(LIOD_START, &pc->pc_flags);\r\nclear_bit(LIOD_STOP, &pc->pc_flags);\r\nclear_bit(LIOD_FORCE, &pc->pc_flags);\r\nclear_bit(LIOD_BIND, &pc->pc_flags);\r\nout:\r\nif (pc->pc_npartners > 0) {\r\nLASSERT(pc->pc_partners != NULL);\r\nOBD_FREE(pc->pc_partners,\r\nsizeof(struct ptlrpcd_ctl *) * pc->pc_npartners);\r\npc->pc_partners = NULL;\r\n}\r\npc->pc_npartners = 0;\r\n}\r\nstatic void ptlrpcd_fini(void)\r\n{\r\nint i;\r\nif (ptlrpcds != NULL) {\r\nfor (i = 0; i < ptlrpcds->pd_nthreads; i++)\r\nptlrpcd_stop(&ptlrpcds->pd_threads[i], 0);\r\nfor (i = 0; i < ptlrpcds->pd_nthreads; i++)\r\nptlrpcd_free(&ptlrpcds->pd_threads[i]);\r\nptlrpcd_stop(&ptlrpcds->pd_thread_rcv, 0);\r\nptlrpcd_free(&ptlrpcds->pd_thread_rcv);\r\nOBD_FREE(ptlrpcds, ptlrpcds->pd_size);\r\nptlrpcds = NULL;\r\n}\r\n}\r\nstatic int ptlrpcd_init(void)\r\n{\r\nint nthreads = num_online_cpus();\r\nchar name[16];\r\nint size, i = -1, j, rc = 0;\r\nif (max_ptlrpcds > 0 && max_ptlrpcds < nthreads)\r\nnthreads = max_ptlrpcds;\r\nif (nthreads < 2)\r\nnthreads = 2;\r\nif (nthreads < 3 && ptlrpcd_bind_policy == PDB_POLICY_NEIGHBOR)\r\nptlrpcd_bind_policy = PDB_POLICY_PAIR;\r\nelse if (nthreads % 2 != 0 && ptlrpcd_bind_policy == PDB_POLICY_PAIR)\r\nnthreads &= ~1;\r\nsize = offsetof(struct ptlrpcd, pd_threads[nthreads]);\r\nOBD_ALLOC(ptlrpcds, size);\r\nif (ptlrpcds == NULL)\r\nGOTO(out, rc = -ENOMEM);\r\nsnprintf(name, sizeof(name), "ptlrpcd_rcv");\r\nset_bit(LIOD_RECOVERY, &ptlrpcds->pd_thread_rcv.pc_flags);\r\nrc = ptlrpcd_start(-1, nthreads, name, &ptlrpcds->pd_thread_rcv);\r\nif (rc < 0)\r\nGOTO(out, rc);\r\nfor (i = 0; i < nthreads; i++) {\r\nsnprintf(name, sizeof(name), "ptlrpcd_%d", i);\r\nrc = ptlrpcd_start(i, nthreads, name, &ptlrpcds->pd_threads[i]);\r\nif (rc < 0)\r\nGOTO(out, rc);\r\n}\r\nptlrpcds->pd_size = size;\r\nptlrpcds->pd_index = 0;\r\nptlrpcds->pd_nthreads = nthreads;\r\nout:\r\nif (rc != 0 && ptlrpcds != NULL) {\r\nfor (j = 0; j <= i; j++)\r\nptlrpcd_stop(&ptlrpcds->pd_threads[j], 0);\r\nfor (j = 0; j <= i; j++)\r\nptlrpcd_free(&ptlrpcds->pd_threads[j]);\r\nptlrpcd_stop(&ptlrpcds->pd_thread_rcv, 0);\r\nptlrpcd_free(&ptlrpcds->pd_thread_rcv);\r\nOBD_FREE(ptlrpcds, size);\r\nptlrpcds = NULL;\r\n}\r\nreturn 0;\r\n}\r\nint ptlrpcd_addref(void)\r\n{\r\nint rc = 0;\r\nmutex_lock(&ptlrpcd_mutex);\r\nif (++ptlrpcd_users == 1)\r\nrc = ptlrpcd_init();\r\nmutex_unlock(&ptlrpcd_mutex);\r\nreturn rc;\r\n}\r\nvoid ptlrpcd_decref(void)\r\n{\r\nmutex_lock(&ptlrpcd_mutex);\r\nif (--ptlrpcd_users == 0)\r\nptlrpcd_fini();\r\nmutex_unlock(&ptlrpcd_mutex);\r\n}
