inline cfs_time_t round_timeout(cfs_time_t timeout)\r\n{\r\nreturn cfs_time_seconds((int)cfs_duration_sec(cfs_time_sub(timeout, 0)) + 1);\r\n}\r\nstatic inline unsigned int ldlm_get_rq_timeout(void)\r\n{\r\nunsigned int timeout = min(ldlm_timeout, obd_timeout / 3);\r\nreturn timeout < 1 ? 1 : timeout;\r\n}\r\nint ldlm_del_waiting_lock(struct ldlm_lock *lock)\r\n{\r\nreturn 0;\r\n}\r\nint ldlm_refresh_waiting_lock(struct ldlm_lock *lock, int timeout)\r\n{\r\nreturn 0;\r\n}\r\nvoid ldlm_handle_bl_callback(struct ldlm_namespace *ns,\r\nstruct ldlm_lock_desc *ld, struct ldlm_lock *lock)\r\n{\r\nint do_ast;\r\nLDLM_DEBUG(lock, "client blocking AST callback handler");\r\nlock_res_and_lock(lock);\r\nlock->l_flags |= LDLM_FL_CBPENDING;\r\nif (lock->l_flags & LDLM_FL_CANCEL_ON_BLOCK)\r\nlock->l_flags |= LDLM_FL_CANCEL;\r\ndo_ast = (!lock->l_readers && !lock->l_writers);\r\nunlock_res_and_lock(lock);\r\nif (do_ast) {\r\nCDEBUG(D_DLMTRACE, "Lock %p already unused, calling callback (%p)\n",\r\nlock, lock->l_blocking_ast);\r\nif (lock->l_blocking_ast != NULL)\r\nlock->l_blocking_ast(lock, ld, lock->l_ast_data,\r\nLDLM_CB_BLOCKING);\r\n} else {\r\nCDEBUG(D_DLMTRACE, "Lock %p is referenced, will be cancelled later\n",\r\nlock);\r\n}\r\nLDLM_DEBUG(lock, "client blocking callback handler END");\r\nLDLM_LOCK_RELEASE(lock);\r\n}\r\nstatic void ldlm_handle_cp_callback(struct ptlrpc_request *req,\r\nstruct ldlm_namespace *ns,\r\nstruct ldlm_request *dlm_req,\r\nstruct ldlm_lock *lock)\r\n{\r\nint lvb_len;\r\nLIST_HEAD(ast_list);\r\nint rc = 0;\r\nLDLM_DEBUG(lock, "client completion callback handler START");\r\nif (OBD_FAIL_CHECK(OBD_FAIL_LDLM_CANCEL_BL_CB_RACE)) {\r\nint to = cfs_time_seconds(1);\r\nwhile (to > 0) {\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nschedule_timeout(to);\r\nif (lock->l_granted_mode == lock->l_req_mode ||\r\nlock->l_flags & LDLM_FL_DESTROYED)\r\nbreak;\r\n}\r\n}\r\nlvb_len = req_capsule_get_size(&req->rq_pill, &RMF_DLM_LVB, RCL_CLIENT);\r\nif (lvb_len < 0) {\r\nLDLM_ERROR(lock, "Fail to get lvb_len, rc = %d", lvb_len);\r\nGOTO(out, rc = lvb_len);\r\n} else if (lvb_len > 0) {\r\nif (lock->l_lvb_len > 0) {\r\nLASSERT(lock->l_lvb_data != NULL);\r\nif (unlikely(lock->l_lvb_len < lvb_len)) {\r\nLDLM_ERROR(lock, "Replied LVB is larger than "\r\n"expectation, expected = %d, "\r\n"replied = %d",\r\nlock->l_lvb_len, lvb_len);\r\nGOTO(out, rc = -EINVAL);\r\n}\r\n} else if (ldlm_has_layout(lock)) {\r\nvoid *lvb_data;\r\nOBD_ALLOC(lvb_data, lvb_len);\r\nif (lvb_data == NULL) {\r\nLDLM_ERROR(lock, "No memory: %d.\n", lvb_len);\r\nGOTO(out, rc = -ENOMEM);\r\n}\r\nlock_res_and_lock(lock);\r\nLASSERT(lock->l_lvb_data == NULL);\r\nlock->l_lvb_type = LVB_T_LAYOUT;\r\nlock->l_lvb_data = lvb_data;\r\nlock->l_lvb_len = lvb_len;\r\nunlock_res_and_lock(lock);\r\n}\r\n}\r\nlock_res_and_lock(lock);\r\nif ((lock->l_flags & LDLM_FL_DESTROYED) ||\r\nlock->l_granted_mode == lock->l_req_mode) {\r\nunlock_res_and_lock(lock);\r\nLDLM_DEBUG(lock, "Double grant race happened");\r\nGOTO(out, rc = 0);\r\n}\r\nif (dlm_req->lock_desc.l_granted_mode != lock->l_req_mode) {\r\nlock->l_req_mode = dlm_req->lock_desc.l_granted_mode;\r\nLDLM_DEBUG(lock, "completion AST, new lock mode");\r\n}\r\nif (lock->l_resource->lr_type != LDLM_PLAIN) {\r\nldlm_convert_policy_to_local(req->rq_export,\r\ndlm_req->lock_desc.l_resource.lr_type,\r\n&dlm_req->lock_desc.l_policy_data,\r\n&lock->l_policy_data);\r\nLDLM_DEBUG(lock, "completion AST, new policy data");\r\n}\r\nldlm_resource_unlink_lock(lock);\r\nif (memcmp(&dlm_req->lock_desc.l_resource.lr_name,\r\n&lock->l_resource->lr_name,\r\nsizeof(lock->l_resource->lr_name)) != 0) {\r\nunlock_res_and_lock(lock);\r\nrc = ldlm_lock_change_resource(ns, lock,\r\n&dlm_req->lock_desc.l_resource.lr_name);\r\nif (rc < 0) {\r\nLDLM_ERROR(lock, "Failed to allocate resource");\r\nGOTO(out, rc);\r\n}\r\nLDLM_DEBUG(lock, "completion AST, new resource");\r\nCERROR("change resource!\n");\r\nlock_res_and_lock(lock);\r\n}\r\nif (dlm_req->lock_flags & LDLM_FL_AST_SENT) {\r\nldlm_lock_remove_from_lru(lock);\r\nlock->l_flags |= LDLM_FL_CBPENDING | LDLM_FL_BL_AST;\r\nLDLM_DEBUG(lock, "completion AST includes blocking AST");\r\n}\r\nif (lock->l_lvb_len > 0) {\r\nrc = ldlm_fill_lvb(lock, &req->rq_pill, RCL_CLIENT,\r\nlock->l_lvb_data, lvb_len);\r\nif (rc < 0) {\r\nunlock_res_and_lock(lock);\r\nGOTO(out, rc);\r\n}\r\n}\r\nldlm_grant_lock(lock, &ast_list);\r\nunlock_res_and_lock(lock);\r\nLDLM_DEBUG(lock, "callback handler finished, about to run_ast_work");\r\nOBD_FAIL_TIMEOUT(OBD_FAIL_OSC_CP_ENQ_RACE, 2);\r\nldlm_run_ast_work(ns, &ast_list, LDLM_WORK_CP_AST);\r\nLDLM_DEBUG_NOLOCK("client completion callback handler END (lock %p)",\r\nlock);\r\nGOTO(out, rc);\r\nout:\r\nif (rc < 0) {\r\nlock_res_and_lock(lock);\r\nlock->l_flags |= LDLM_FL_FAILED;\r\nunlock_res_and_lock(lock);\r\nwake_up(&lock->l_waitq);\r\n}\r\nLDLM_LOCK_RELEASE(lock);\r\n}\r\nstatic void ldlm_handle_gl_callback(struct ptlrpc_request *req,\r\nstruct ldlm_namespace *ns,\r\nstruct ldlm_request *dlm_req,\r\nstruct ldlm_lock *lock)\r\n{\r\nint rc = -ENOSYS;\r\nLDLM_DEBUG(lock, "client glimpse AST callback handler");\r\nif (lock->l_glimpse_ast != NULL)\r\nrc = lock->l_glimpse_ast(lock, req);\r\nif (req->rq_repmsg != NULL) {\r\nptlrpc_reply(req);\r\n} else {\r\nreq->rq_status = rc;\r\nptlrpc_error(req);\r\n}\r\nlock_res_and_lock(lock);\r\nif (lock->l_granted_mode == LCK_PW &&\r\n!lock->l_readers && !lock->l_writers &&\r\ncfs_time_after(cfs_time_current(),\r\ncfs_time_add(lock->l_last_used,\r\ncfs_time_seconds(10)))) {\r\nunlock_res_and_lock(lock);\r\nif (ldlm_bl_to_thread_lock(ns, NULL, lock))\r\nldlm_handle_bl_callback(ns, NULL, lock);\r\nreturn;\r\n}\r\nunlock_res_and_lock(lock);\r\nLDLM_LOCK_RELEASE(lock);\r\n}\r\nstatic int ldlm_callback_reply(struct ptlrpc_request *req, int rc)\r\n{\r\nif (req->rq_no_reply)\r\nreturn 0;\r\nreq->rq_status = rc;\r\nif (!req->rq_packed_final) {\r\nrc = lustre_pack_reply(req, 1, NULL, NULL);\r\nif (rc)\r\nreturn rc;\r\n}\r\nreturn ptlrpc_reply(req);\r\n}\r\nstatic int __ldlm_bl_to_thread(struct ldlm_bl_work_item *blwi,\r\nldlm_cancel_flags_t cancel_flags)\r\n{\r\nstruct ldlm_bl_pool *blp = ldlm_state->ldlm_bl_pool;\r\nspin_lock(&blp->blp_lock);\r\nif (blwi->blwi_lock &&\r\nblwi->blwi_lock->l_flags & LDLM_FL_DISCARD_DATA) {\r\nlist_add_tail(&blwi->blwi_entry, &blp->blp_prio_list);\r\n} else {\r\nlist_add_tail(&blwi->blwi_entry, &blp->blp_list);\r\n}\r\nspin_unlock(&blp->blp_lock);\r\nwake_up(&blp->blp_waitq);\r\nif (!(cancel_flags & LCF_ASYNC))\r\nwait_for_completion(&blwi->blwi_comp);\r\nreturn 0;\r\n}\r\nstatic inline void init_blwi(struct ldlm_bl_work_item *blwi,\r\nstruct ldlm_namespace *ns,\r\nstruct ldlm_lock_desc *ld,\r\nstruct list_head *cancels, int count,\r\nstruct ldlm_lock *lock,\r\nldlm_cancel_flags_t cancel_flags)\r\n{\r\ninit_completion(&blwi->blwi_comp);\r\nINIT_LIST_HEAD(&blwi->blwi_head);\r\nif (memory_pressure_get())\r\nblwi->blwi_mem_pressure = 1;\r\nblwi->blwi_ns = ns;\r\nblwi->blwi_flags = cancel_flags;\r\nif (ld != NULL)\r\nblwi->blwi_ld = *ld;\r\nif (count) {\r\nlist_add(&blwi->blwi_head, cancels);\r\nlist_del_init(cancels);\r\nblwi->blwi_count = count;\r\n} else {\r\nblwi->blwi_lock = lock;\r\n}\r\n}\r\nstatic int ldlm_bl_to_thread(struct ldlm_namespace *ns,\r\nstruct ldlm_lock_desc *ld,\r\nstruct ldlm_lock *lock,\r\nstruct list_head *cancels, int count,\r\nldlm_cancel_flags_t cancel_flags)\r\n{\r\nif (cancels && count == 0)\r\nreturn 0;\r\nif (cancel_flags & LCF_ASYNC) {\r\nstruct ldlm_bl_work_item *blwi;\r\nOBD_ALLOC(blwi, sizeof(*blwi));\r\nif (blwi == NULL)\r\nreturn -ENOMEM;\r\ninit_blwi(blwi, ns, ld, cancels, count, lock, cancel_flags);\r\nreturn __ldlm_bl_to_thread(blwi, cancel_flags);\r\n} else {\r\nstruct ldlm_bl_work_item blwi;\r\nmemset(&blwi, 0, sizeof(blwi));\r\ninit_blwi(&blwi, ns, ld, cancels, count, lock, cancel_flags);\r\nreturn __ldlm_bl_to_thread(&blwi, cancel_flags);\r\n}\r\n}\r\nint ldlm_bl_to_thread_lock(struct ldlm_namespace *ns, struct ldlm_lock_desc *ld,\r\nstruct ldlm_lock *lock)\r\n{\r\nreturn ldlm_bl_to_thread(ns, ld, lock, NULL, 0, LCF_ASYNC);\r\n}\r\nint ldlm_bl_to_thread_list(struct ldlm_namespace *ns, struct ldlm_lock_desc *ld,\r\nstruct list_head *cancels, int count,\r\nldlm_cancel_flags_t cancel_flags)\r\n{\r\nreturn ldlm_bl_to_thread(ns, ld, NULL, cancels, count, cancel_flags);\r\n}\r\nstatic int ldlm_handle_setinfo(struct ptlrpc_request *req)\r\n{\r\nstruct obd_device *obd = req->rq_export->exp_obd;\r\nchar *key;\r\nvoid *val;\r\nint keylen, vallen;\r\nint rc = -ENOSYS;\r\nDEBUG_REQ(D_HSM, req, "%s: handle setinfo\n", obd->obd_name);\r\nreq_capsule_set(&req->rq_pill, &RQF_OBD_SET_INFO);\r\nkey = req_capsule_client_get(&req->rq_pill, &RMF_SETINFO_KEY);\r\nif (key == NULL) {\r\nDEBUG_REQ(D_IOCTL, req, "no set_info key");\r\nreturn -EFAULT;\r\n}\r\nkeylen = req_capsule_get_size(&req->rq_pill, &RMF_SETINFO_KEY,\r\nRCL_CLIENT);\r\nval = req_capsule_client_get(&req->rq_pill, &RMF_SETINFO_VAL);\r\nif (val == NULL) {\r\nDEBUG_REQ(D_IOCTL, req, "no set_info val");\r\nreturn -EFAULT;\r\n}\r\nvallen = req_capsule_get_size(&req->rq_pill, &RMF_SETINFO_VAL,\r\nRCL_CLIENT);\r\nif (KEY_IS(KEY_HSM_COPYTOOL_SEND))\r\nrc = obd_set_info_async(req->rq_svc_thread->t_env,\r\nreq->rq_export,\r\nsizeof(KEY_HSM_COPYTOOL_SEND),\r\nKEY_HSM_COPYTOOL_SEND,\r\nvallen, val, NULL);\r\nelse\r\nDEBUG_REQ(D_WARNING, req, "ignoring unknown key %s", key);\r\nreturn rc;\r\n}\r\nstatic inline void ldlm_callback_errmsg(struct ptlrpc_request *req,\r\nconst char *msg, int rc,\r\nstruct lustre_handle *handle)\r\n{\r\nDEBUG_REQ((req->rq_no_reply || rc) ? D_WARNING : D_DLMTRACE, req,\r\n"%s: [nid %s] [rc %d] [lock "LPX64"]",\r\nmsg, libcfs_id2str(req->rq_peer), rc,\r\nhandle ? handle->cookie : 0);\r\nif (req->rq_no_reply)\r\nCWARN("No reply was sent, maybe cause bug 21636.\n");\r\nelse if (rc)\r\nCWARN("Send reply failed, maybe cause bug 21636.\n");\r\n}\r\nstatic int ldlm_handle_qc_callback(struct ptlrpc_request *req)\r\n{\r\nstruct obd_quotactl *oqctl;\r\nstruct client_obd *cli = &req->rq_export->exp_obd->u.cli;\r\noqctl = req_capsule_client_get(&req->rq_pill, &RMF_OBD_QUOTACTL);\r\nif (oqctl == NULL) {\r\nCERROR("Can't unpack obd_quotactl\n");\r\nreturn -EPROTO;\r\n}\r\noqctl->qc_stat = ptlrpc_status_ntoh(oqctl->qc_stat);\r\ncli->cl_qchk_stat = oqctl->qc_stat;\r\nreturn 0;\r\n}\r\nstatic int ldlm_callback_handler(struct ptlrpc_request *req)\r\n{\r\nstruct ldlm_namespace *ns;\r\nstruct ldlm_request *dlm_req;\r\nstruct ldlm_lock *lock;\r\nint rc;\r\nif (lustre_msg_get_opc(req->rq_reqmsg) == SEC_CTX_FINI)\r\nreturn 0;\r\nreq_capsule_init(&req->rq_pill, req, RCL_SERVER);\r\nif (req->rq_export == NULL) {\r\nrc = ldlm_callback_reply(req, -ENOTCONN);\r\nldlm_callback_errmsg(req, "Operate on unconnected server",\r\nrc, NULL);\r\nreturn 0;\r\n}\r\nLASSERT(req->rq_export != NULL);\r\nLASSERT(req->rq_export->exp_obd != NULL);\r\nswitch (lustre_msg_get_opc(req->rq_reqmsg)) {\r\ncase LDLM_BL_CALLBACK:\r\nif (OBD_FAIL_CHECK(OBD_FAIL_LDLM_BL_CALLBACK_NET))\r\nreturn 0;\r\nbreak;\r\ncase LDLM_CP_CALLBACK:\r\nif (OBD_FAIL_CHECK(OBD_FAIL_LDLM_CP_CALLBACK_NET))\r\nreturn 0;\r\nbreak;\r\ncase LDLM_GL_CALLBACK:\r\nif (OBD_FAIL_CHECK(OBD_FAIL_LDLM_GL_CALLBACK_NET))\r\nreturn 0;\r\nbreak;\r\ncase LDLM_SET_INFO:\r\nrc = ldlm_handle_setinfo(req);\r\nldlm_callback_reply(req, rc);\r\nreturn 0;\r\ncase OBD_QC_CALLBACK:\r\nreq_capsule_set(&req->rq_pill, &RQF_QC_CALLBACK);\r\nif (OBD_FAIL_CHECK(OBD_FAIL_OBD_QC_CALLBACK_NET))\r\nreturn 0;\r\nrc = ldlm_handle_qc_callback(req);\r\nldlm_callback_reply(req, rc);\r\nreturn 0;\r\ndefault:\r\nCERROR("unknown opcode %u\n",\r\nlustre_msg_get_opc(req->rq_reqmsg));\r\nldlm_callback_reply(req, -EPROTO);\r\nreturn 0;\r\n}\r\nns = req->rq_export->exp_obd->obd_namespace;\r\nLASSERT(ns != NULL);\r\nreq_capsule_set(&req->rq_pill, &RQF_LDLM_CALLBACK);\r\ndlm_req = req_capsule_client_get(&req->rq_pill, &RMF_DLM_REQ);\r\nif (dlm_req == NULL) {\r\nrc = ldlm_callback_reply(req, -EPROTO);\r\nldlm_callback_errmsg(req, "Operate without parameter", rc,\r\nNULL);\r\nreturn 0;\r\n}\r\nif (OBD_FAIL_CHECK(OBD_FAIL_LDLM_CANCEL_BL_CB_RACE) &&\r\nlustre_msg_get_opc(req->rq_reqmsg) == LDLM_BL_CALLBACK) {\r\nrc = ldlm_cli_cancel(&dlm_req->lock_handle[0], 0);\r\nif (rc < 0)\r\nCERROR("ldlm_cli_cancel: %d\n", rc);\r\n}\r\nlock = ldlm_handle2lock_long(&dlm_req->lock_handle[0], 0);\r\nif (!lock) {\r\nCDEBUG(D_DLMTRACE, "callback on lock "LPX64" - lock "\r\n"disappeared\n", dlm_req->lock_handle[0].cookie);\r\nrc = ldlm_callback_reply(req, -EINVAL);\r\nldlm_callback_errmsg(req, "Operate with invalid parameter", rc,\r\n&dlm_req->lock_handle[0]);\r\nreturn 0;\r\n}\r\nif ((lock->l_flags & LDLM_FL_FAIL_LOC) &&\r\nlustre_msg_get_opc(req->rq_reqmsg) == LDLM_BL_CALLBACK)\r\nOBD_RACE(OBD_FAIL_LDLM_CP_BL_RACE);\r\nlock_res_and_lock(lock);\r\nlock->l_flags |= ldlm_flags_from_wire(dlm_req->lock_flags &\r\nLDLM_AST_FLAGS);\r\nif (lustre_msg_get_opc(req->rq_reqmsg) == LDLM_BL_CALLBACK) {\r\nif (((lock->l_flags & LDLM_FL_CANCELING) &&\r\n(lock->l_flags & LDLM_FL_BL_DONE)) ||\r\n(lock->l_flags & LDLM_FL_FAILED)) {\r\nLDLM_DEBUG(lock, "callback on lock "\r\nLPX64" - lock disappeared\n",\r\ndlm_req->lock_handle[0].cookie);\r\nunlock_res_and_lock(lock);\r\nLDLM_LOCK_RELEASE(lock);\r\nrc = ldlm_callback_reply(req, -EINVAL);\r\nldlm_callback_errmsg(req, "Operate on stale lock", rc,\r\n&dlm_req->lock_handle[0]);\r\nreturn 0;\r\n}\r\nldlm_lock_remove_from_lru(lock);\r\nlock->l_flags |= LDLM_FL_BL_AST;\r\n}\r\nunlock_res_and_lock(lock);\r\nswitch (lustre_msg_get_opc(req->rq_reqmsg)) {\r\ncase LDLM_BL_CALLBACK:\r\nCDEBUG(D_INODE, "blocking ast\n");\r\nreq_capsule_extend(&req->rq_pill, &RQF_LDLM_BL_CALLBACK);\r\nif (!(lock->l_flags & LDLM_FL_CANCEL_ON_BLOCK)) {\r\nrc = ldlm_callback_reply(req, 0);\r\nif (req->rq_no_reply || rc)\r\nldlm_callback_errmsg(req, "Normal process", rc,\r\n&dlm_req->lock_handle[0]);\r\n}\r\nif (ldlm_bl_to_thread_lock(ns, &dlm_req->lock_desc, lock))\r\nldlm_handle_bl_callback(ns, &dlm_req->lock_desc, lock);\r\nbreak;\r\ncase LDLM_CP_CALLBACK:\r\nCDEBUG(D_INODE, "completion ast\n");\r\nreq_capsule_extend(&req->rq_pill, &RQF_LDLM_CP_CALLBACK);\r\nldlm_callback_reply(req, 0);\r\nldlm_handle_cp_callback(req, ns, dlm_req, lock);\r\nbreak;\r\ncase LDLM_GL_CALLBACK:\r\nCDEBUG(D_INODE, "glimpse ast\n");\r\nreq_capsule_extend(&req->rq_pill, &RQF_LDLM_GL_CALLBACK);\r\nldlm_handle_gl_callback(req, ns, dlm_req, lock);\r\nbreak;\r\ndefault:\r\nLBUG();\r\n}\r\nreturn 0;\r\n}\r\nstatic struct ldlm_bl_work_item *ldlm_bl_get_work(struct ldlm_bl_pool *blp)\r\n{\r\nstruct ldlm_bl_work_item *blwi = NULL;\r\nstatic unsigned int num_bl = 0;\r\nspin_lock(&blp->blp_lock);\r\nif (!list_empty(&blp->blp_list) &&\r\n(list_empty(&blp->blp_prio_list) || num_bl == 0))\r\nblwi = list_entry(blp->blp_list.next,\r\nstruct ldlm_bl_work_item, blwi_entry);\r\nelse\r\nif (!list_empty(&blp->blp_prio_list))\r\nblwi = list_entry(blp->blp_prio_list.next,\r\nstruct ldlm_bl_work_item,\r\nblwi_entry);\r\nif (blwi) {\r\nif (++num_bl >= atomic_read(&blp->blp_num_threads))\r\nnum_bl = 0;\r\nlist_del(&blwi->blwi_entry);\r\n}\r\nspin_unlock(&blp->blp_lock);\r\nreturn blwi;\r\n}\r\nstatic int ldlm_bl_thread_start(struct ldlm_bl_pool *blp)\r\n{\r\nstruct ldlm_bl_thread_data bltd = { .bltd_blp = blp };\r\nstruct task_struct *task;\r\ninit_completion(&bltd.bltd_comp);\r\nbltd.bltd_num = atomic_read(&blp->blp_num_threads);\r\nsnprintf(bltd.bltd_name, sizeof(bltd.bltd_name),\r\n"ldlm_bl_%02d", bltd.bltd_num);\r\ntask = kthread_run(ldlm_bl_thread_main, &bltd, "%s", bltd.bltd_name);\r\nif (IS_ERR(task)) {\r\nCERROR("cannot start LDLM thread ldlm_bl_%02d: rc %ld\n",\r\natomic_read(&blp->blp_num_threads), PTR_ERR(task));\r\nreturn PTR_ERR(task);\r\n}\r\nwait_for_completion(&bltd.bltd_comp);\r\nreturn 0;\r\n}\r\nstatic int ldlm_bl_thread_main(void *arg)\r\n{\r\nstruct ldlm_bl_pool *blp;\r\n{\r\nstruct ldlm_bl_thread_data *bltd = arg;\r\nblp = bltd->bltd_blp;\r\natomic_inc(&blp->blp_num_threads);\r\natomic_inc(&blp->blp_busy_threads);\r\ncomplete(&bltd->bltd_comp);\r\n}\r\nwhile (1) {\r\nstruct l_wait_info lwi = { 0 };\r\nstruct ldlm_bl_work_item *blwi = NULL;\r\nint busy;\r\nblwi = ldlm_bl_get_work(blp);\r\nif (blwi == NULL) {\r\natomic_dec(&blp->blp_busy_threads);\r\nl_wait_event_exclusive(blp->blp_waitq,\r\n(blwi = ldlm_bl_get_work(blp)) != NULL,\r\n&lwi);\r\nbusy = atomic_inc_return(&blp->blp_busy_threads);\r\n} else {\r\nbusy = atomic_read(&blp->blp_busy_threads);\r\n}\r\nif (blwi->blwi_ns == NULL)\r\nbreak;\r\nif (unlikely(busy < blp->blp_max_threads &&\r\nbusy >= atomic_read(&blp->blp_num_threads) &&\r\n!blwi->blwi_mem_pressure))\r\nldlm_bl_thread_start(blp);\r\nif (blwi->blwi_mem_pressure)\r\nmemory_pressure_set();\r\nif (blwi->blwi_count) {\r\nint count;\r\ncount = ldlm_cli_cancel_list_local(&blwi->blwi_head,\r\nblwi->blwi_count,\r\nLCF_BL_AST);\r\nldlm_cli_cancel_list(&blwi->blwi_head, count, NULL,\r\nblwi->blwi_flags);\r\n} else {\r\nldlm_handle_bl_callback(blwi->blwi_ns, &blwi->blwi_ld,\r\nblwi->blwi_lock);\r\n}\r\nif (blwi->blwi_mem_pressure)\r\nmemory_pressure_clr();\r\nif (blwi->blwi_flags & LCF_ASYNC)\r\nOBD_FREE(blwi, sizeof(*blwi));\r\nelse\r\ncomplete(&blwi->blwi_comp);\r\n}\r\natomic_dec(&blp->blp_busy_threads);\r\natomic_dec(&blp->blp_num_threads);\r\ncomplete(&blp->blp_comp);\r\nreturn 0;\r\n}\r\nint ldlm_get_ref(void)\r\n{\r\nint rc = 0;\r\nmutex_lock(&ldlm_ref_mutex);\r\nif (++ldlm_refcount == 1) {\r\nrc = ldlm_setup();\r\nif (rc)\r\nldlm_refcount--;\r\n}\r\nmutex_unlock(&ldlm_ref_mutex);\r\nreturn rc;\r\n}\r\nvoid ldlm_put_ref(void)\r\n{\r\nmutex_lock(&ldlm_ref_mutex);\r\nif (ldlm_refcount == 1) {\r\nint rc = ldlm_cleanup();\r\nif (rc)\r\nCERROR("ldlm_cleanup failed: %d\n", rc);\r\nelse\r\nldlm_refcount--;\r\n} else {\r\nldlm_refcount--;\r\n}\r\nmutex_unlock(&ldlm_ref_mutex);\r\n}\r\nstatic unsigned\r\nldlm_export_lock_hash(struct cfs_hash *hs, const void *key, unsigned mask)\r\n{\r\nreturn cfs_hash_u64_hash(((struct lustre_handle *)key)->cookie, mask);\r\n}\r\nstatic void *\r\nldlm_export_lock_key(struct hlist_node *hnode)\r\n{\r\nstruct ldlm_lock *lock;\r\nlock = hlist_entry(hnode, struct ldlm_lock, l_exp_hash);\r\nreturn &lock->l_remote_handle;\r\n}\r\nstatic void\r\nldlm_export_lock_keycpy(struct hlist_node *hnode, void *key)\r\n{\r\nstruct ldlm_lock *lock;\r\nlock = hlist_entry(hnode, struct ldlm_lock, l_exp_hash);\r\nlock->l_remote_handle = *(struct lustre_handle *)key;\r\n}\r\nstatic int\r\nldlm_export_lock_keycmp(const void *key, struct hlist_node *hnode)\r\n{\r\nreturn lustre_handle_equal(ldlm_export_lock_key(hnode), key);\r\n}\r\nstatic void *\r\nldlm_export_lock_object(struct hlist_node *hnode)\r\n{\r\nreturn hlist_entry(hnode, struct ldlm_lock, l_exp_hash);\r\n}\r\nstatic void\r\nldlm_export_lock_get(struct cfs_hash *hs, struct hlist_node *hnode)\r\n{\r\nstruct ldlm_lock *lock;\r\nlock = hlist_entry(hnode, struct ldlm_lock, l_exp_hash);\r\nLDLM_LOCK_GET(lock);\r\n}\r\nstatic void\r\nldlm_export_lock_put(struct cfs_hash *hs, struct hlist_node *hnode)\r\n{\r\nstruct ldlm_lock *lock;\r\nlock = hlist_entry(hnode, struct ldlm_lock, l_exp_hash);\r\nLDLM_LOCK_RELEASE(lock);\r\n}\r\nint ldlm_init_export(struct obd_export *exp)\r\n{\r\nint rc;\r\nexp->exp_lock_hash =\r\ncfs_hash_create(obd_uuid2str(&exp->exp_client_uuid),\r\nHASH_EXP_LOCK_CUR_BITS,\r\nHASH_EXP_LOCK_MAX_BITS,\r\nHASH_EXP_LOCK_BKT_BITS, 0,\r\nCFS_HASH_MIN_THETA, CFS_HASH_MAX_THETA,\r\n&ldlm_export_lock_ops,\r\nCFS_HASH_DEFAULT | CFS_HASH_REHASH_KEY |\r\nCFS_HASH_NBLK_CHANGE);\r\nif (!exp->exp_lock_hash)\r\nreturn -ENOMEM;\r\nrc = ldlm_init_flock_export(exp);\r\nif (rc)\r\nGOTO(err, rc);\r\nreturn 0;\r\nerr:\r\nldlm_destroy_export(exp);\r\nreturn rc;\r\n}\r\nvoid ldlm_destroy_export(struct obd_export *exp)\r\n{\r\ncfs_hash_putref(exp->exp_lock_hash);\r\nexp->exp_lock_hash = NULL;\r\nldlm_destroy_flock_export(exp);\r\n}\r\nstatic int ldlm_setup(void)\r\n{\r\nstatic struct ptlrpc_service_conf conf;\r\nstruct ldlm_bl_pool *blp = NULL;\r\nint rc = 0;\r\nint i;\r\nif (ldlm_state != NULL)\r\nreturn -EALREADY;\r\nOBD_ALLOC(ldlm_state, sizeof(*ldlm_state));\r\nif (ldlm_state == NULL)\r\nreturn -ENOMEM;\r\nrc = ldlm_proc_setup();\r\nif (rc != 0)\r\nGOTO(out, rc);\r\nmemset(&conf, 0, sizeof(conf));\r\nconf = (typeof(conf)) {\r\n.psc_name = "ldlm_cbd",\r\n.psc_watchdog_factor = 2,\r\n.psc_buf = {\r\n.bc_nbufs = LDLM_CLIENT_NBUFS,\r\n.bc_buf_size = LDLM_BUFSIZE,\r\n.bc_req_max_size = LDLM_MAXREQSIZE,\r\n.bc_rep_max_size = LDLM_MAXREPSIZE,\r\n.bc_req_portal = LDLM_CB_REQUEST_PORTAL,\r\n.bc_rep_portal = LDLM_CB_REPLY_PORTAL,\r\n},\r\n.psc_thr = {\r\n.tc_thr_name = "ldlm_cb",\r\n.tc_thr_factor = LDLM_THR_FACTOR,\r\n.tc_nthrs_init = LDLM_NTHRS_INIT,\r\n.tc_nthrs_base = LDLM_NTHRS_BASE,\r\n.tc_nthrs_max = LDLM_NTHRS_MAX,\r\n.tc_nthrs_user = ldlm_num_threads,\r\n.tc_cpu_affinity = 1,\r\n.tc_ctx_tags = LCT_MD_THREAD | LCT_DT_THREAD,\r\n},\r\n.psc_cpt = {\r\n.cc_pattern = ldlm_cpts,\r\n},\r\n.psc_ops = {\r\n.so_req_handler = ldlm_callback_handler,\r\n},\r\n};\r\nldlm_state->ldlm_cb_service = \\r\nptlrpc_register_service(&conf, ldlm_svc_proc_dir);\r\nif (IS_ERR(ldlm_state->ldlm_cb_service)) {\r\nCERROR("failed to start service\n");\r\nrc = PTR_ERR(ldlm_state->ldlm_cb_service);\r\nldlm_state->ldlm_cb_service = NULL;\r\nGOTO(out, rc);\r\n}\r\nOBD_ALLOC(blp, sizeof(*blp));\r\nif (blp == NULL)\r\nGOTO(out, rc = -ENOMEM);\r\nldlm_state->ldlm_bl_pool = blp;\r\nspin_lock_init(&blp->blp_lock);\r\nINIT_LIST_HEAD(&blp->blp_list);\r\nINIT_LIST_HEAD(&blp->blp_prio_list);\r\ninit_waitqueue_head(&blp->blp_waitq);\r\natomic_set(&blp->blp_num_threads, 0);\r\natomic_set(&blp->blp_busy_threads, 0);\r\nif (ldlm_num_threads == 0) {\r\nblp->blp_min_threads = LDLM_NTHRS_INIT;\r\nblp->blp_max_threads = LDLM_NTHRS_MAX;\r\n} else {\r\nblp->blp_min_threads = blp->blp_max_threads = \\r\nmin_t(int, LDLM_NTHRS_MAX, max_t(int, LDLM_NTHRS_INIT,\r\nldlm_num_threads));\r\n}\r\nfor (i = 0; i < blp->blp_min_threads; i++) {\r\nrc = ldlm_bl_thread_start(blp);\r\nif (rc < 0)\r\nGOTO(out, rc);\r\n}\r\nrc = ldlm_pools_init();\r\nif (rc) {\r\nCERROR("Failed to initialize LDLM pools: %d\n", rc);\r\nGOTO(out, rc);\r\n}\r\nreturn 0;\r\nout:\r\nldlm_cleanup();\r\nreturn rc;\r\n}\r\nstatic int ldlm_cleanup(void)\r\n{\r\nif (!list_empty(ldlm_namespace_list(LDLM_NAMESPACE_SERVER)) ||\r\n!list_empty(ldlm_namespace_list(LDLM_NAMESPACE_CLIENT))) {\r\nCERROR("ldlm still has namespaces; clean these up first.\n");\r\nldlm_dump_all_namespaces(LDLM_NAMESPACE_SERVER, D_DLMTRACE);\r\nldlm_dump_all_namespaces(LDLM_NAMESPACE_CLIENT, D_DLMTRACE);\r\nreturn -EBUSY;\r\n}\r\nldlm_pools_fini();\r\nif (ldlm_state->ldlm_bl_pool != NULL) {\r\nstruct ldlm_bl_pool *blp = ldlm_state->ldlm_bl_pool;\r\nwhile (atomic_read(&blp->blp_num_threads) > 0) {\r\nstruct ldlm_bl_work_item blwi = { .blwi_ns = NULL };\r\ninit_completion(&blp->blp_comp);\r\nspin_lock(&blp->blp_lock);\r\nlist_add_tail(&blwi.blwi_entry, &blp->blp_list);\r\nwake_up(&blp->blp_waitq);\r\nspin_unlock(&blp->blp_lock);\r\nwait_for_completion(&blp->blp_comp);\r\n}\r\nOBD_FREE(blp, sizeof(*blp));\r\n}\r\nif (ldlm_state->ldlm_cb_service != NULL)\r\nptlrpc_unregister_service(ldlm_state->ldlm_cb_service);\r\nldlm_proc_cleanup();\r\nOBD_FREE(ldlm_state, sizeof(*ldlm_state));\r\nldlm_state = NULL;\r\nreturn 0;\r\n}\r\nint ldlm_init(void)\r\n{\r\nmutex_init(&ldlm_ref_mutex);\r\nmutex_init(ldlm_namespace_lock(LDLM_NAMESPACE_SERVER));\r\nmutex_init(ldlm_namespace_lock(LDLM_NAMESPACE_CLIENT));\r\nldlm_resource_slab = kmem_cache_create("ldlm_resources",\r\nsizeof(struct ldlm_resource), 0,\r\nSLAB_HWCACHE_ALIGN, NULL);\r\nif (ldlm_resource_slab == NULL)\r\nreturn -ENOMEM;\r\nldlm_lock_slab = kmem_cache_create("ldlm_locks",\r\nsizeof(struct ldlm_lock), 0,\r\nSLAB_HWCACHE_ALIGN | SLAB_DESTROY_BY_RCU, NULL);\r\nif (ldlm_lock_slab == NULL) {\r\nkmem_cache_destroy(ldlm_resource_slab);\r\nreturn -ENOMEM;\r\n}\r\nldlm_interval_slab = kmem_cache_create("interval_node",\r\nsizeof(struct ldlm_interval),\r\n0, SLAB_HWCACHE_ALIGN, NULL);\r\nif (ldlm_interval_slab == NULL) {\r\nkmem_cache_destroy(ldlm_resource_slab);\r\nkmem_cache_destroy(ldlm_lock_slab);\r\nreturn -ENOMEM;\r\n}\r\n#if LUSTRE_TRACKS_LOCK_EXP_REFS\r\nclass_export_dump_hook = ldlm_dump_export_locks;\r\n#endif\r\nreturn 0;\r\n}\r\nvoid ldlm_exit(void)\r\n{\r\nif (ldlm_refcount)\r\nCERROR("ldlm_refcount is %d in ldlm_exit!\n", ldlm_refcount);\r\nkmem_cache_destroy(ldlm_resource_slab);\r\nsynchronize_rcu();\r\nkmem_cache_destroy(ldlm_lock_slab);\r\nkmem_cache_destroy(ldlm_interval_slab);\r\n}
