int radeon_ib_get(struct radeon_device *rdev, int ring,\r\nstruct radeon_ib *ib, struct radeon_vm *vm,\r\nunsigned size)\r\n{\r\nint r;\r\nr = radeon_sa_bo_new(rdev, &rdev->ring_tmp_bo, &ib->sa_bo, size, 256);\r\nif (r) {\r\ndev_err(rdev->dev, "failed to get a new IB (%d)\n", r);\r\nreturn r;\r\n}\r\nr = radeon_semaphore_create(rdev, &ib->semaphore);\r\nif (r) {\r\nreturn r;\r\n}\r\nib->ring = ring;\r\nib->fence = NULL;\r\nib->ptr = radeon_sa_bo_cpu_addr(ib->sa_bo);\r\nib->vm = vm;\r\nif (vm) {\r\nib->gpu_addr = ib->sa_bo->soffset + RADEON_VA_IB_OFFSET;\r\n} else {\r\nib->gpu_addr = radeon_sa_bo_gpu_addr(ib->sa_bo);\r\n}\r\nib->is_const_ib = false;\r\nreturn 0;\r\n}\r\nvoid radeon_ib_free(struct radeon_device *rdev, struct radeon_ib *ib)\r\n{\r\nradeon_semaphore_free(rdev, &ib->semaphore, ib->fence);\r\nradeon_sa_bo_free(rdev, &ib->sa_bo, ib->fence);\r\nradeon_fence_unref(&ib->fence);\r\n}\r\nint radeon_ib_schedule(struct radeon_device *rdev, struct radeon_ib *ib,\r\nstruct radeon_ib *const_ib)\r\n{\r\nstruct radeon_ring *ring = &rdev->ring[ib->ring];\r\nint r = 0;\r\nif (!ib->length_dw || !ring->ready) {\r\ndev_err(rdev->dev, "couldn't schedule ib\n");\r\nreturn -EINVAL;\r\n}\r\nr = radeon_ring_lock(rdev, ring, 64 + RADEON_NUM_SYNCS * 8);\r\nif (r) {\r\ndev_err(rdev->dev, "scheduling IB failed (%d).\n", r);\r\nreturn r;\r\n}\r\nif (ib->vm) {\r\nstruct radeon_fence *vm_id_fence;\r\nvm_id_fence = radeon_vm_grab_id(rdev, ib->vm, ib->ring);\r\nradeon_semaphore_sync_to(ib->semaphore, vm_id_fence);\r\n}\r\nr = radeon_semaphore_sync_rings(rdev, ib->semaphore, ib->ring);\r\nif (r) {\r\ndev_err(rdev->dev, "failed to sync rings (%d)\n", r);\r\nradeon_ring_unlock_undo(rdev, ring);\r\nreturn r;\r\n}\r\nif (ib->vm)\r\nradeon_vm_flush(rdev, ib->vm, ib->ring);\r\nif (const_ib) {\r\nradeon_ring_ib_execute(rdev, const_ib->ring, const_ib);\r\nradeon_semaphore_free(rdev, &const_ib->semaphore, NULL);\r\n}\r\nradeon_ring_ib_execute(rdev, ib->ring, ib);\r\nr = radeon_fence_emit(rdev, &ib->fence, ib->ring);\r\nif (r) {\r\ndev_err(rdev->dev, "failed to emit fence for new IB (%d)\n", r);\r\nradeon_ring_unlock_undo(rdev, ring);\r\nreturn r;\r\n}\r\nif (const_ib) {\r\nconst_ib->fence = radeon_fence_ref(ib->fence);\r\n}\r\nif (ib->vm)\r\nradeon_vm_fence(rdev, ib->vm, ib->fence);\r\nradeon_ring_unlock_commit(rdev, ring);\r\nreturn 0;\r\n}\r\nint radeon_ib_pool_init(struct radeon_device *rdev)\r\n{\r\nint r;\r\nif (rdev->ib_pool_ready) {\r\nreturn 0;\r\n}\r\nr = radeon_sa_bo_manager_init(rdev, &rdev->ring_tmp_bo,\r\nRADEON_IB_POOL_SIZE*64*1024,\r\nRADEON_GPU_PAGE_SIZE,\r\nRADEON_GEM_DOMAIN_GTT);\r\nif (r) {\r\nreturn r;\r\n}\r\nr = radeon_sa_bo_manager_start(rdev, &rdev->ring_tmp_bo);\r\nif (r) {\r\nreturn r;\r\n}\r\nrdev->ib_pool_ready = true;\r\nif (radeon_debugfs_sa_init(rdev)) {\r\ndev_err(rdev->dev, "failed to register debugfs file for SA\n");\r\n}\r\nreturn 0;\r\n}\r\nvoid radeon_ib_pool_fini(struct radeon_device *rdev)\r\n{\r\nif (rdev->ib_pool_ready) {\r\nradeon_sa_bo_manager_suspend(rdev, &rdev->ring_tmp_bo);\r\nradeon_sa_bo_manager_fini(rdev, &rdev->ring_tmp_bo);\r\nrdev->ib_pool_ready = false;\r\n}\r\n}\r\nint radeon_ib_ring_tests(struct radeon_device *rdev)\r\n{\r\nunsigned i;\r\nint r;\r\nfor (i = 0; i < RADEON_NUM_RINGS; ++i) {\r\nstruct radeon_ring *ring = &rdev->ring[i];\r\nif (!ring->ready)\r\ncontinue;\r\nr = radeon_ib_test(rdev, i, ring);\r\nif (r) {\r\nring->ready = false;\r\nrdev->needs_reset = false;\r\nif (i == RADEON_RING_TYPE_GFX_INDEX) {\r\nDRM_ERROR("radeon: failed testing IB on GFX ring (%d).\n", r);\r\nrdev->accel_working = false;\r\nreturn r;\r\n} else {\r\nDRM_ERROR("radeon: failed testing IB on ring %d (%d).\n", i, r);\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nvoid radeon_ring_write(struct radeon_ring *ring, uint32_t v)\r\n{\r\n#if DRM_DEBUG_CODE\r\nif (ring->count_dw <= 0) {\r\nDRM_ERROR("radeon: writing more dwords to the ring than expected!\n");\r\n}\r\n#endif\r\nring->ring[ring->wptr++] = v;\r\nring->wptr &= ring->ptr_mask;\r\nring->count_dw--;\r\nring->ring_free_dw--;\r\n}\r\nbool radeon_ring_supports_scratch_reg(struct radeon_device *rdev,\r\nstruct radeon_ring *ring)\r\n{\r\nswitch (ring->idx) {\r\ncase RADEON_RING_TYPE_GFX_INDEX:\r\ncase CAYMAN_RING_TYPE_CP1_INDEX:\r\ncase CAYMAN_RING_TYPE_CP2_INDEX:\r\nreturn true;\r\ndefault:\r\nreturn false;\r\n}\r\n}\r\nvoid radeon_ring_free_size(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\nuint32_t rptr = radeon_ring_get_rptr(rdev, ring);\r\nring->ring_free_dw = rptr + (ring->ring_size / 4);\r\nring->ring_free_dw -= ring->wptr;\r\nring->ring_free_dw &= ring->ptr_mask;\r\nif (!ring->ring_free_dw) {\r\nring->ring_free_dw = ring->ring_size / 4;\r\nradeon_ring_lockup_update(rdev, ring);\r\n}\r\n}\r\nint radeon_ring_alloc(struct radeon_device *rdev, struct radeon_ring *ring, unsigned ndw)\r\n{\r\nint r;\r\nif (ndw > (ring->ring_size / 4))\r\nreturn -ENOMEM;\r\nradeon_ring_free_size(rdev, ring);\r\nndw = (ndw + ring->align_mask) & ~ring->align_mask;\r\nwhile (ndw > (ring->ring_free_dw - 1)) {\r\nradeon_ring_free_size(rdev, ring);\r\nif (ndw < ring->ring_free_dw) {\r\nbreak;\r\n}\r\nr = radeon_fence_wait_next(rdev, ring->idx);\r\nif (r)\r\nreturn r;\r\n}\r\nring->count_dw = ndw;\r\nring->wptr_old = ring->wptr;\r\nreturn 0;\r\n}\r\nint radeon_ring_lock(struct radeon_device *rdev, struct radeon_ring *ring, unsigned ndw)\r\n{\r\nint r;\r\nmutex_lock(&rdev->ring_lock);\r\nr = radeon_ring_alloc(rdev, ring, ndw);\r\nif (r) {\r\nmutex_unlock(&rdev->ring_lock);\r\nreturn r;\r\n}\r\nreturn 0;\r\n}\r\nvoid radeon_ring_commit(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\nwhile (ring->wptr & ring->align_mask) {\r\nradeon_ring_write(ring, ring->nop);\r\n}\r\nmb();\r\nradeon_ring_set_wptr(rdev, ring);\r\n}\r\nvoid radeon_ring_unlock_commit(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\nradeon_ring_commit(rdev, ring);\r\nmutex_unlock(&rdev->ring_lock);\r\n}\r\nvoid radeon_ring_undo(struct radeon_ring *ring)\r\n{\r\nring->wptr = ring->wptr_old;\r\n}\r\nvoid radeon_ring_unlock_undo(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\nradeon_ring_undo(ring);\r\nmutex_unlock(&rdev->ring_lock);\r\n}\r\nvoid radeon_ring_lockup_update(struct radeon_device *rdev,\r\nstruct radeon_ring *ring)\r\n{\r\natomic_set(&ring->last_rptr, radeon_ring_get_rptr(rdev, ring));\r\natomic64_set(&ring->last_activity, jiffies_64);\r\n}\r\nbool radeon_ring_test_lockup(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\nuint32_t rptr = radeon_ring_get_rptr(rdev, ring);\r\nuint64_t last = atomic64_read(&ring->last_activity);\r\nuint64_t elapsed;\r\nif (rptr != atomic_read(&ring->last_rptr)) {\r\nradeon_ring_lockup_update(rdev, ring);\r\nreturn false;\r\n}\r\nelapsed = jiffies_to_msecs(jiffies_64 - last);\r\nif (radeon_lockup_timeout && elapsed >= radeon_lockup_timeout) {\r\ndev_err(rdev->dev, "ring %d stalled for more than %llumsec\n",\r\nring->idx, elapsed);\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nunsigned radeon_ring_backup(struct radeon_device *rdev, struct radeon_ring *ring,\r\nuint32_t **data)\r\n{\r\nunsigned size, ptr, i;\r\nmutex_lock(&rdev->ring_lock);\r\n*data = NULL;\r\nif (ring->ring_obj == NULL) {\r\nmutex_unlock(&rdev->ring_lock);\r\nreturn 0;\r\n}\r\nif (!radeon_fence_count_emitted(rdev, ring->idx)) {\r\nmutex_unlock(&rdev->ring_lock);\r\nreturn 0;\r\n}\r\nif (ring->rptr_save_reg)\r\nptr = RREG32(ring->rptr_save_reg);\r\nelse if (rdev->wb.enabled)\r\nptr = le32_to_cpu(*ring->next_rptr_cpu_addr);\r\nelse {\r\nmutex_unlock(&rdev->ring_lock);\r\nreturn 0;\r\n}\r\nsize = ring->wptr + (ring->ring_size / 4);\r\nsize -= ptr;\r\nsize &= ring->ptr_mask;\r\nif (size == 0) {\r\nmutex_unlock(&rdev->ring_lock);\r\nreturn 0;\r\n}\r\n*data = kmalloc_array(size, sizeof(uint32_t), GFP_KERNEL);\r\nif (!*data) {\r\nmutex_unlock(&rdev->ring_lock);\r\nreturn 0;\r\n}\r\nfor (i = 0; i < size; ++i) {\r\n(*data)[i] = ring->ring[ptr++];\r\nptr &= ring->ptr_mask;\r\n}\r\nmutex_unlock(&rdev->ring_lock);\r\nreturn size;\r\n}\r\nint radeon_ring_restore(struct radeon_device *rdev, struct radeon_ring *ring,\r\nunsigned size, uint32_t *data)\r\n{\r\nint i, r;\r\nif (!size || !data)\r\nreturn 0;\r\nr = radeon_ring_lock(rdev, ring, size);\r\nif (r)\r\nreturn r;\r\nfor (i = 0; i < size; ++i) {\r\nradeon_ring_write(ring, data[i]);\r\n}\r\nradeon_ring_unlock_commit(rdev, ring);\r\nkfree(data);\r\nreturn 0;\r\n}\r\nint radeon_ring_init(struct radeon_device *rdev, struct radeon_ring *ring, unsigned ring_size,\r\nunsigned rptr_offs, u32 nop)\r\n{\r\nint r;\r\nring->ring_size = ring_size;\r\nring->rptr_offs = rptr_offs;\r\nring->nop = nop;\r\nif (ring->ring_obj == NULL) {\r\nr = radeon_bo_create(rdev, ring->ring_size, PAGE_SIZE, true,\r\nRADEON_GEM_DOMAIN_GTT,\r\nNULL, &ring->ring_obj);\r\nif (r) {\r\ndev_err(rdev->dev, "(%d) ring create failed\n", r);\r\nreturn r;\r\n}\r\nr = radeon_bo_reserve(ring->ring_obj, false);\r\nif (unlikely(r != 0))\r\nreturn r;\r\nr = radeon_bo_pin(ring->ring_obj, RADEON_GEM_DOMAIN_GTT,\r\n&ring->gpu_addr);\r\nif (r) {\r\nradeon_bo_unreserve(ring->ring_obj);\r\ndev_err(rdev->dev, "(%d) ring pin failed\n", r);\r\nreturn r;\r\n}\r\nr = radeon_bo_kmap(ring->ring_obj,\r\n(void **)&ring->ring);\r\nradeon_bo_unreserve(ring->ring_obj);\r\nif (r) {\r\ndev_err(rdev->dev, "(%d) ring map failed\n", r);\r\nreturn r;\r\n}\r\n}\r\nring->ptr_mask = (ring->ring_size / 4) - 1;\r\nring->ring_free_dw = ring->ring_size / 4;\r\nif (rdev->wb.enabled) {\r\nu32 index = RADEON_WB_RING0_NEXT_RPTR + (ring->idx * 4);\r\nring->next_rptr_gpu_addr = rdev->wb.gpu_addr + index;\r\nring->next_rptr_cpu_addr = &rdev->wb.wb[index/4];\r\n}\r\nif (radeon_debugfs_ring_init(rdev, ring)) {\r\nDRM_ERROR("Failed to register debugfs file for rings !\n");\r\n}\r\nradeon_ring_lockup_update(rdev, ring);\r\nreturn 0;\r\n}\r\nvoid radeon_ring_fini(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\nint r;\r\nstruct radeon_bo *ring_obj;\r\nmutex_lock(&rdev->ring_lock);\r\nring_obj = ring->ring_obj;\r\nring->ready = false;\r\nring->ring = NULL;\r\nring->ring_obj = NULL;\r\nmutex_unlock(&rdev->ring_lock);\r\nif (ring_obj) {\r\nr = radeon_bo_reserve(ring_obj, false);\r\nif (likely(r == 0)) {\r\nradeon_bo_kunmap(ring_obj);\r\nradeon_bo_unpin(ring_obj);\r\nradeon_bo_unreserve(ring_obj);\r\n}\r\nradeon_bo_unref(&ring_obj);\r\n}\r\n}\r\nstatic int radeon_debugfs_ring_info(struct seq_file *m, void *data)\r\n{\r\nstruct drm_info_node *node = (struct drm_info_node *) m->private;\r\nstruct drm_device *dev = node->minor->dev;\r\nstruct radeon_device *rdev = dev->dev_private;\r\nint ridx = *(int*)node->info_ent->data;\r\nstruct radeon_ring *ring = &rdev->ring[ridx];\r\nuint32_t rptr, wptr, rptr_next;\r\nunsigned count, i, j;\r\nradeon_ring_free_size(rdev, ring);\r\ncount = (ring->ring_size / 4) - ring->ring_free_dw;\r\nwptr = radeon_ring_get_wptr(rdev, ring);\r\nseq_printf(m, "wptr: 0x%08x [%5d]\n",\r\nwptr, wptr);\r\nrptr = radeon_ring_get_rptr(rdev, ring);\r\nseq_printf(m, "rptr: 0x%08x [%5d]\n",\r\nrptr, rptr);\r\nif (ring->rptr_save_reg) {\r\nrptr_next = RREG32(ring->rptr_save_reg);\r\nseq_printf(m, "rptr next(0x%04x): 0x%08x [%5d]\n",\r\nring->rptr_save_reg, rptr_next, rptr_next);\r\n} else\r\nrptr_next = ~0;\r\nseq_printf(m, "driver's copy of the wptr: 0x%08x [%5d]\n",\r\nring->wptr, ring->wptr);\r\nseq_printf(m, "last semaphore signal addr : 0x%016llx\n",\r\nring->last_semaphore_signal_addr);\r\nseq_printf(m, "last semaphore wait addr : 0x%016llx\n",\r\nring->last_semaphore_wait_addr);\r\nseq_printf(m, "%u free dwords in ring\n", ring->ring_free_dw);\r\nseq_printf(m, "%u dwords in ring\n", count);\r\nif (!ring->ready)\r\nreturn 0;\r\ni = (rptr + ring->ptr_mask + 1 - 32) & ring->ptr_mask;\r\nfor (j = 0; j <= (count + 32); j++) {\r\nseq_printf(m, "r[%5d]=0x%08x", i, ring->ring[i]);\r\nif (rptr == i)\r\nseq_puts(m, " *");\r\nif (rptr_next == i)\r\nseq_puts(m, " #");\r\nseq_puts(m, "\n");\r\ni = (i + 1) & ring->ptr_mask;\r\n}\r\nreturn 0;\r\n}\r\nstatic int radeon_debugfs_sa_info(struct seq_file *m, void *data)\r\n{\r\nstruct drm_info_node *node = (struct drm_info_node *) m->private;\r\nstruct drm_device *dev = node->minor->dev;\r\nstruct radeon_device *rdev = dev->dev_private;\r\nradeon_sa_bo_dump_debug_info(&rdev->ring_tmp_bo, m);\r\nreturn 0;\r\n}\r\nstatic int radeon_debugfs_ring_init(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\n#if defined(CONFIG_DEBUG_FS)\r\nunsigned i;\r\nfor (i = 0; i < ARRAY_SIZE(radeon_debugfs_ring_info_list); ++i) {\r\nstruct drm_info_list *info = &radeon_debugfs_ring_info_list[i];\r\nint ridx = *(int*)radeon_debugfs_ring_info_list[i].data;\r\nunsigned r;\r\nif (&rdev->ring[ridx] != ring)\r\ncontinue;\r\nr = radeon_debugfs_add_files(rdev, info, 1);\r\nif (r)\r\nreturn r;\r\n}\r\n#endif\r\nreturn 0;\r\n}\r\nstatic int radeon_debugfs_sa_init(struct radeon_device *rdev)\r\n{\r\n#if defined(CONFIG_DEBUG_FS)\r\nreturn radeon_debugfs_add_files(rdev, radeon_debugfs_sa_list, 1);\r\n#else\r\nreturn 0;\r\n#endif\r\n}
