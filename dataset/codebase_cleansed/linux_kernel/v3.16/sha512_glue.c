static int sha512_sparc64_init(struct shash_desc *desc)\r\n{\r\nstruct sha512_state *sctx = shash_desc_ctx(desc);\r\nsctx->state[0] = SHA512_H0;\r\nsctx->state[1] = SHA512_H1;\r\nsctx->state[2] = SHA512_H2;\r\nsctx->state[3] = SHA512_H3;\r\nsctx->state[4] = SHA512_H4;\r\nsctx->state[5] = SHA512_H5;\r\nsctx->state[6] = SHA512_H6;\r\nsctx->state[7] = SHA512_H7;\r\nsctx->count[0] = sctx->count[1] = 0;\r\nreturn 0;\r\n}\r\nstatic int sha384_sparc64_init(struct shash_desc *desc)\r\n{\r\nstruct sha512_state *sctx = shash_desc_ctx(desc);\r\nsctx->state[0] = SHA384_H0;\r\nsctx->state[1] = SHA384_H1;\r\nsctx->state[2] = SHA384_H2;\r\nsctx->state[3] = SHA384_H3;\r\nsctx->state[4] = SHA384_H4;\r\nsctx->state[5] = SHA384_H5;\r\nsctx->state[6] = SHA384_H6;\r\nsctx->state[7] = SHA384_H7;\r\nsctx->count[0] = sctx->count[1] = 0;\r\nreturn 0;\r\n}\r\nstatic void __sha512_sparc64_update(struct sha512_state *sctx, const u8 *data,\r\nunsigned int len, unsigned int partial)\r\n{\r\nunsigned int done = 0;\r\nif ((sctx->count[0] += len) < len)\r\nsctx->count[1]++;\r\nif (partial) {\r\ndone = SHA512_BLOCK_SIZE - partial;\r\nmemcpy(sctx->buf + partial, data, done);\r\nsha512_sparc64_transform(sctx->state, sctx->buf, 1);\r\n}\r\nif (len - done >= SHA512_BLOCK_SIZE) {\r\nconst unsigned int rounds = (len - done) / SHA512_BLOCK_SIZE;\r\nsha512_sparc64_transform(sctx->state, data + done, rounds);\r\ndone += rounds * SHA512_BLOCK_SIZE;\r\n}\r\nmemcpy(sctx->buf, data + done, len - done);\r\n}\r\nstatic int sha512_sparc64_update(struct shash_desc *desc, const u8 *data,\r\nunsigned int len)\r\n{\r\nstruct sha512_state *sctx = shash_desc_ctx(desc);\r\nunsigned int partial = sctx->count[0] % SHA512_BLOCK_SIZE;\r\nif (partial + len < SHA512_BLOCK_SIZE) {\r\nif ((sctx->count[0] += len) < len)\r\nsctx->count[1]++;\r\nmemcpy(sctx->buf + partial, data, len);\r\n} else\r\n__sha512_sparc64_update(sctx, data, len, partial);\r\nreturn 0;\r\n}\r\nstatic int sha512_sparc64_final(struct shash_desc *desc, u8 *out)\r\n{\r\nstruct sha512_state *sctx = shash_desc_ctx(desc);\r\nunsigned int i, index, padlen;\r\n__be64 *dst = (__be64 *)out;\r\n__be64 bits[2];\r\nstatic const u8 padding[SHA512_BLOCK_SIZE] = { 0x80, };\r\nbits[1] = cpu_to_be64(sctx->count[0] << 3);\r\nbits[0] = cpu_to_be64(sctx->count[1] << 3 | sctx->count[0] >> 61);\r\nindex = sctx->count[0] % SHA512_BLOCK_SIZE;\r\npadlen = (index < 112) ? (112 - index) : ((SHA512_BLOCK_SIZE+112) - index);\r\nif (padlen <= 112) {\r\nif ((sctx->count[0] += padlen) < padlen)\r\nsctx->count[1]++;\r\nmemcpy(sctx->buf + index, padding, padlen);\r\n} else {\r\n__sha512_sparc64_update(sctx, padding, padlen, index);\r\n}\r\n__sha512_sparc64_update(sctx, (const u8 *)&bits, sizeof(bits), 112);\r\nfor (i = 0; i < 8; i++)\r\ndst[i] = cpu_to_be64(sctx->state[i]);\r\nmemset(sctx, 0, sizeof(*sctx));\r\nreturn 0;\r\n}\r\nstatic int sha384_sparc64_final(struct shash_desc *desc, u8 *hash)\r\n{\r\nu8 D[64];\r\nsha512_sparc64_final(desc, D);\r\nmemcpy(hash, D, 48);\r\nmemset(D, 0, 64);\r\nreturn 0;\r\n}\r\nstatic bool __init sparc64_has_sha512_opcode(void)\r\n{\r\nunsigned long cfr;\r\nif (!(sparc64_elf_hwcap & HWCAP_SPARC_CRYPTO))\r\nreturn false;\r\n__asm__ __volatile__("rd %%asr26, %0" : "=r" (cfr));\r\nif (!(cfr & CFR_SHA512))\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic int __init sha512_sparc64_mod_init(void)\r\n{\r\nif (sparc64_has_sha512_opcode()) {\r\nint ret = crypto_register_shash(&sha384);\r\nif (ret < 0)\r\nreturn ret;\r\nret = crypto_register_shash(&sha512);\r\nif (ret < 0) {\r\ncrypto_unregister_shash(&sha384);\r\nreturn ret;\r\n}\r\npr_info("Using sparc64 sha512 opcode optimized SHA-512/SHA-384 implementation\n");\r\nreturn 0;\r\n}\r\npr_info("sparc64 sha512 opcode not available.\n");\r\nreturn -ENODEV;\r\n}\r\nstatic void __exit sha512_sparc64_mod_fini(void)\r\n{\r\ncrypto_unregister_shash(&sha384);\r\ncrypto_unregister_shash(&sha512);\r\n}
