static inline void diff_timespec(struct timespec *r, struct timespec *a,\r\nstruct timespec *b)\r\n{\r\nr->tv_sec = a->tv_sec - b->tv_sec;\r\nif (a->tv_nsec < b->tv_nsec) {\r\nr->tv_nsec = a->tv_nsec + 1000000000L - b->tv_nsec;\r\nr->tv_sec--;\r\n} else {\r\nr->tv_nsec = a->tv_nsec - b->tv_nsec ;\r\n}\r\n}\r\nstatic inline struct cpu_map *perf_evsel__cpus(struct perf_evsel *evsel)\r\n{\r\nreturn (evsel->cpus && !target.cpu_list) ? evsel->cpus : evsel_list->cpus;\r\n}\r\nstatic inline int perf_evsel__nr_cpus(struct perf_evsel *evsel)\r\n{\r\nreturn perf_evsel__cpus(evsel)->nr;\r\n}\r\nstatic void perf_evsel__reset_stat_priv(struct perf_evsel *evsel)\r\n{\r\nint i;\r\nstruct perf_stat *ps = evsel->priv;\r\nfor (i = 0; i < 3; i++)\r\ninit_stats(&ps->res_stats[i]);\r\n}\r\nstatic int perf_evsel__alloc_stat_priv(struct perf_evsel *evsel)\r\n{\r\nevsel->priv = zalloc(sizeof(struct perf_stat));\r\nif (evsel == NULL)\r\nreturn -ENOMEM;\r\nperf_evsel__reset_stat_priv(evsel);\r\nreturn 0;\r\n}\r\nstatic void perf_evsel__free_stat_priv(struct perf_evsel *evsel)\r\n{\r\nzfree(&evsel->priv);\r\n}\r\nstatic int perf_evsel__alloc_prev_raw_counts(struct perf_evsel *evsel)\r\n{\r\nvoid *addr;\r\nsize_t sz;\r\nsz = sizeof(*evsel->counts) +\r\n(perf_evsel__nr_cpus(evsel) * sizeof(struct perf_counts_values));\r\naddr = zalloc(sz);\r\nif (!addr)\r\nreturn -ENOMEM;\r\nevsel->prev_raw_counts = addr;\r\nreturn 0;\r\n}\r\nstatic void perf_evsel__free_prev_raw_counts(struct perf_evsel *evsel)\r\n{\r\nzfree(&evsel->prev_raw_counts);\r\n}\r\nstatic void perf_evlist__free_stats(struct perf_evlist *evlist)\r\n{\r\nstruct perf_evsel *evsel;\r\nevlist__for_each(evlist, evsel) {\r\nperf_evsel__free_stat_priv(evsel);\r\nperf_evsel__free_counts(evsel);\r\nperf_evsel__free_prev_raw_counts(evsel);\r\n}\r\n}\r\nstatic int perf_evlist__alloc_stats(struct perf_evlist *evlist, bool alloc_raw)\r\n{\r\nstruct perf_evsel *evsel;\r\nevlist__for_each(evlist, evsel) {\r\nif (perf_evsel__alloc_stat_priv(evsel) < 0 ||\r\nperf_evsel__alloc_counts(evsel, perf_evsel__nr_cpus(evsel)) < 0 ||\r\n(alloc_raw && perf_evsel__alloc_prev_raw_counts(evsel) < 0))\r\ngoto out_free;\r\n}\r\nreturn 0;\r\nout_free:\r\nperf_evlist__free_stats(evlist);\r\nreturn -1;\r\n}\r\nstatic void perf_stat__reset_stats(struct perf_evlist *evlist)\r\n{\r\nstruct perf_evsel *evsel;\r\nevlist__for_each(evlist, evsel) {\r\nperf_evsel__reset_stat_priv(evsel);\r\nperf_evsel__reset_counts(evsel, perf_evsel__nr_cpus(evsel));\r\n}\r\nmemset(runtime_nsecs_stats, 0, sizeof(runtime_nsecs_stats));\r\nmemset(runtime_cycles_stats, 0, sizeof(runtime_cycles_stats));\r\nmemset(runtime_stalled_cycles_front_stats, 0, sizeof(runtime_stalled_cycles_front_stats));\r\nmemset(runtime_stalled_cycles_back_stats, 0, sizeof(runtime_stalled_cycles_back_stats));\r\nmemset(runtime_branches_stats, 0, sizeof(runtime_branches_stats));\r\nmemset(runtime_cacherefs_stats, 0, sizeof(runtime_cacherefs_stats));\r\nmemset(runtime_l1_dcache_stats, 0, sizeof(runtime_l1_dcache_stats));\r\nmemset(runtime_l1_icache_stats, 0, sizeof(runtime_l1_icache_stats));\r\nmemset(runtime_ll_cache_stats, 0, sizeof(runtime_ll_cache_stats));\r\nmemset(runtime_itlb_cache_stats, 0, sizeof(runtime_itlb_cache_stats));\r\nmemset(runtime_dtlb_cache_stats, 0, sizeof(runtime_dtlb_cache_stats));\r\nmemset(runtime_cycles_in_tx_stats, 0,\r\nsizeof(runtime_cycles_in_tx_stats));\r\nmemset(runtime_transaction_stats, 0,\r\nsizeof(runtime_transaction_stats));\r\nmemset(runtime_elision_stats, 0, sizeof(runtime_elision_stats));\r\nmemset(&walltime_nsecs_stats, 0, sizeof(walltime_nsecs_stats));\r\n}\r\nstatic int create_perf_stat_counter(struct perf_evsel *evsel)\r\n{\r\nstruct perf_event_attr *attr = &evsel->attr;\r\nif (scale)\r\nattr->read_format = PERF_FORMAT_TOTAL_TIME_ENABLED |\r\nPERF_FORMAT_TOTAL_TIME_RUNNING;\r\nattr->inherit = !no_inherit;\r\nif (target__has_cpu(&target))\r\nreturn perf_evsel__open_per_cpu(evsel, perf_evsel__cpus(evsel));\r\nif (!target__has_task(&target) && perf_evsel__is_group_leader(evsel)) {\r\nattr->disabled = 1;\r\nif (!initial_delay)\r\nattr->enable_on_exec = 1;\r\n}\r\nreturn perf_evsel__open_per_thread(evsel, evsel_list->threads);\r\n}\r\nstatic inline int nsec_counter(struct perf_evsel *evsel)\r\n{\r\nif (perf_evsel__match(evsel, SOFTWARE, SW_CPU_CLOCK) ||\r\nperf_evsel__match(evsel, SOFTWARE, SW_TASK_CLOCK))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic struct perf_evsel *nth_evsel(int n)\r\n{\r\nstatic struct perf_evsel **array;\r\nstatic int array_len;\r\nstruct perf_evsel *ev;\r\nint j;\r\nif (!array) {\r\nevlist__for_each(evsel_list, ev)\r\narray_len++;\r\narray = malloc(array_len * sizeof(void *));\r\nif (!array)\r\nexit(ENOMEM);\r\nj = 0;\r\nevlist__for_each(evsel_list, ev)\r\narray[j++] = ev;\r\n}\r\nif (n < array_len)\r\nreturn array[n];\r\nreturn NULL;\r\n}\r\nstatic void update_shadow_stats(struct perf_evsel *counter, u64 *count)\r\n{\r\nif (perf_evsel__match(counter, SOFTWARE, SW_TASK_CLOCK))\r\nupdate_stats(&runtime_nsecs_stats[0], count[0]);\r\nelse if (perf_evsel__match(counter, HARDWARE, HW_CPU_CYCLES))\r\nupdate_stats(&runtime_cycles_stats[0], count[0]);\r\nelse if (transaction_run &&\r\nperf_evsel__cmp(counter, nth_evsel(T_CYCLES_IN_TX)))\r\nupdate_stats(&runtime_cycles_in_tx_stats[0], count[0]);\r\nelse if (transaction_run &&\r\nperf_evsel__cmp(counter, nth_evsel(T_TRANSACTION_START)))\r\nupdate_stats(&runtime_transaction_stats[0], count[0]);\r\nelse if (transaction_run &&\r\nperf_evsel__cmp(counter, nth_evsel(T_ELISION_START)))\r\nupdate_stats(&runtime_elision_stats[0], count[0]);\r\nelse if (perf_evsel__match(counter, HARDWARE, HW_STALLED_CYCLES_FRONTEND))\r\nupdate_stats(&runtime_stalled_cycles_front_stats[0], count[0]);\r\nelse if (perf_evsel__match(counter, HARDWARE, HW_STALLED_CYCLES_BACKEND))\r\nupdate_stats(&runtime_stalled_cycles_back_stats[0], count[0]);\r\nelse if (perf_evsel__match(counter, HARDWARE, HW_BRANCH_INSTRUCTIONS))\r\nupdate_stats(&runtime_branches_stats[0], count[0]);\r\nelse if (perf_evsel__match(counter, HARDWARE, HW_CACHE_REFERENCES))\r\nupdate_stats(&runtime_cacherefs_stats[0], count[0]);\r\nelse if (perf_evsel__match(counter, HW_CACHE, HW_CACHE_L1D))\r\nupdate_stats(&runtime_l1_dcache_stats[0], count[0]);\r\nelse if (perf_evsel__match(counter, HW_CACHE, HW_CACHE_L1I))\r\nupdate_stats(&runtime_l1_icache_stats[0], count[0]);\r\nelse if (perf_evsel__match(counter, HW_CACHE, HW_CACHE_LL))\r\nupdate_stats(&runtime_ll_cache_stats[0], count[0]);\r\nelse if (perf_evsel__match(counter, HW_CACHE, HW_CACHE_DTLB))\r\nupdate_stats(&runtime_dtlb_cache_stats[0], count[0]);\r\nelse if (perf_evsel__match(counter, HW_CACHE, HW_CACHE_ITLB))\r\nupdate_stats(&runtime_itlb_cache_stats[0], count[0]);\r\n}\r\nstatic int read_counter_aggr(struct perf_evsel *counter)\r\n{\r\nstruct perf_stat *ps = counter->priv;\r\nu64 *count = counter->counts->aggr.values;\r\nint i;\r\nif (__perf_evsel__read(counter, perf_evsel__nr_cpus(counter),\r\nthread_map__nr(evsel_list->threads), scale) < 0)\r\nreturn -1;\r\nfor (i = 0; i < 3; i++)\r\nupdate_stats(&ps->res_stats[i], count[i]);\r\nif (verbose) {\r\nfprintf(output, "%s: %" PRIu64 " %" PRIu64 " %" PRIu64 "\n",\r\nperf_evsel__name(counter), count[0], count[1], count[2]);\r\n}\r\nupdate_shadow_stats(counter, count);\r\nreturn 0;\r\n}\r\nstatic int read_counter(struct perf_evsel *counter)\r\n{\r\nu64 *count;\r\nint cpu;\r\nfor (cpu = 0; cpu < perf_evsel__nr_cpus(counter); cpu++) {\r\nif (__perf_evsel__read_on_cpu(counter, cpu, 0, scale) < 0)\r\nreturn -1;\r\ncount = counter->counts->cpu[cpu].values;\r\nupdate_shadow_stats(counter, count);\r\n}\r\nreturn 0;\r\n}\r\nstatic void print_interval(void)\r\n{\r\nstatic int num_print_interval;\r\nstruct perf_evsel *counter;\r\nstruct perf_stat *ps;\r\nstruct timespec ts, rs;\r\nchar prefix[64];\r\nif (aggr_mode == AGGR_GLOBAL) {\r\nevlist__for_each(evsel_list, counter) {\r\nps = counter->priv;\r\nmemset(ps->res_stats, 0, sizeof(ps->res_stats));\r\nread_counter_aggr(counter);\r\n}\r\n} else {\r\nevlist__for_each(evsel_list, counter) {\r\nps = counter->priv;\r\nmemset(ps->res_stats, 0, sizeof(ps->res_stats));\r\nread_counter(counter);\r\n}\r\n}\r\nclock_gettime(CLOCK_MONOTONIC, &ts);\r\ndiff_timespec(&rs, &ts, &ref_time);\r\nsprintf(prefix, "%6lu.%09lu%s", rs.tv_sec, rs.tv_nsec, csv_sep);\r\nif (num_print_interval == 0 && !csv_output) {\r\nswitch (aggr_mode) {\r\ncase AGGR_SOCKET:\r\nfprintf(output, "# time socket cpus counts %*s events\n", unit_width, "unit");\r\nbreak;\r\ncase AGGR_CORE:\r\nfprintf(output, "# time core cpus counts %*s events\n", unit_width, "unit");\r\nbreak;\r\ncase AGGR_NONE:\r\nfprintf(output, "# time CPU counts %*s events\n", unit_width, "unit");\r\nbreak;\r\ncase AGGR_GLOBAL:\r\ndefault:\r\nfprintf(output, "# time counts %*s events\n", unit_width, "unit");\r\n}\r\n}\r\nif (++num_print_interval == 25)\r\nnum_print_interval = 0;\r\nswitch (aggr_mode) {\r\ncase AGGR_CORE:\r\ncase AGGR_SOCKET:\r\nprint_aggr(prefix);\r\nbreak;\r\ncase AGGR_NONE:\r\nevlist__for_each(evsel_list, counter)\r\nprint_counter(counter, prefix);\r\nbreak;\r\ncase AGGR_GLOBAL:\r\ndefault:\r\nevlist__for_each(evsel_list, counter)\r\nprint_counter_aggr(counter, prefix);\r\n}\r\nfflush(output);\r\n}\r\nstatic void handle_initial_delay(void)\r\n{\r\nstruct perf_evsel *counter;\r\nif (initial_delay) {\r\nconst int ncpus = cpu_map__nr(evsel_list->cpus),\r\nnthreads = thread_map__nr(evsel_list->threads);\r\nusleep(initial_delay * 1000);\r\nevlist__for_each(evsel_list, counter)\r\nperf_evsel__enable(counter, ncpus, nthreads);\r\n}\r\n}\r\nstatic void workload_exec_failed_signal(int signo __maybe_unused, siginfo_t *info,\r\nvoid *ucontext __maybe_unused)\r\n{\r\nworkload_exec_errno = info->si_value.sival_int;\r\n}\r\nstatic int __run_perf_stat(int argc, const char **argv)\r\n{\r\nchar msg[512];\r\nunsigned long long t0, t1;\r\nstruct perf_evsel *counter;\r\nstruct timespec ts;\r\nsize_t l;\r\nint status = 0;\r\nconst bool forks = (argc > 0);\r\nif (interval) {\r\nts.tv_sec = interval / 1000;\r\nts.tv_nsec = (interval % 1000) * 1000000;\r\n} else {\r\nts.tv_sec = 1;\r\nts.tv_nsec = 0;\r\n}\r\nif (forks) {\r\nif (perf_evlist__prepare_workload(evsel_list, &target, argv, false,\r\nworkload_exec_failed_signal) < 0) {\r\nperror("failed to prepare workload");\r\nreturn -1;\r\n}\r\nchild_pid = evsel_list->workload.pid;\r\n}\r\nif (group)\r\nperf_evlist__set_leader(evsel_list);\r\nevlist__for_each(evsel_list, counter) {\r\nif (create_perf_stat_counter(counter) < 0) {\r\nif (errno == EINVAL || errno == ENOSYS ||\r\nerrno == ENOENT || errno == EOPNOTSUPP ||\r\nerrno == ENXIO) {\r\nif (verbose)\r\nui__warning("%s event is not supported by the kernel.\n",\r\nperf_evsel__name(counter));\r\ncounter->supported = false;\r\ncontinue;\r\n}\r\nperf_evsel__open_strerror(counter, &target,\r\nerrno, msg, sizeof(msg));\r\nui__error("%s\n", msg);\r\nif (child_pid != -1)\r\nkill(child_pid, SIGTERM);\r\nreturn -1;\r\n}\r\ncounter->supported = true;\r\nl = strlen(counter->unit);\r\nif (l > unit_width)\r\nunit_width = l;\r\n}\r\nif (perf_evlist__apply_filters(evsel_list)) {\r\nerror("failed to set filter with %d (%s)\n", errno,\r\nstrerror(errno));\r\nreturn -1;\r\n}\r\nt0 = rdclock();\r\nclock_gettime(CLOCK_MONOTONIC, &ref_time);\r\nif (forks) {\r\nperf_evlist__start_workload(evsel_list);\r\nhandle_initial_delay();\r\nif (interval) {\r\nwhile (!waitpid(child_pid, &status, WNOHANG)) {\r\nnanosleep(&ts, NULL);\r\nprint_interval();\r\n}\r\n}\r\nwait(&status);\r\nif (workload_exec_errno) {\r\nconst char *emsg = strerror_r(workload_exec_errno, msg, sizeof(msg));\r\npr_err("Workload failed: %s\n", emsg);\r\nreturn -1;\r\n}\r\nif (WIFSIGNALED(status))\r\npsignal(WTERMSIG(status), argv[0]);\r\n} else {\r\nhandle_initial_delay();\r\nwhile (!done) {\r\nnanosleep(&ts, NULL);\r\nif (interval)\r\nprint_interval();\r\n}\r\n}\r\nt1 = rdclock();\r\nupdate_stats(&walltime_nsecs_stats, t1 - t0);\r\nif (aggr_mode == AGGR_GLOBAL) {\r\nevlist__for_each(evsel_list, counter) {\r\nread_counter_aggr(counter);\r\nperf_evsel__close_fd(counter, perf_evsel__nr_cpus(counter),\r\nthread_map__nr(evsel_list->threads));\r\n}\r\n} else {\r\nevlist__for_each(evsel_list, counter) {\r\nread_counter(counter);\r\nperf_evsel__close_fd(counter, perf_evsel__nr_cpus(counter), 1);\r\n}\r\n}\r\nreturn WEXITSTATUS(status);\r\n}\r\nstatic int run_perf_stat(int argc, const char **argv)\r\n{\r\nint ret;\r\nif (pre_cmd) {\r\nret = system(pre_cmd);\r\nif (ret)\r\nreturn ret;\r\n}\r\nif (sync_run)\r\nsync();\r\nret = __run_perf_stat(argc, argv);\r\nif (ret)\r\nreturn ret;\r\nif (post_cmd) {\r\nret = system(post_cmd);\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn ret;\r\n}\r\nstatic void print_noise_pct(double total, double avg)\r\n{\r\ndouble pct = rel_stddev_stats(total, avg);\r\nif (csv_output)\r\nfprintf(output, "%s%.2f%%", csv_sep, pct);\r\nelse if (pct)\r\nfprintf(output, " ( +-%6.2f%% )", pct);\r\n}\r\nstatic void print_noise(struct perf_evsel *evsel, double avg)\r\n{\r\nstruct perf_stat *ps;\r\nif (run_count == 1)\r\nreturn;\r\nps = evsel->priv;\r\nprint_noise_pct(stddev_stats(&ps->res_stats[0]), avg);\r\n}\r\nstatic void aggr_printout(struct perf_evsel *evsel, int id, int nr)\r\n{\r\nswitch (aggr_mode) {\r\ncase AGGR_CORE:\r\nfprintf(output, "S%d-C%*d%s%*d%s",\r\ncpu_map__id_to_socket(id),\r\ncsv_output ? 0 : -8,\r\ncpu_map__id_to_cpu(id),\r\ncsv_sep,\r\ncsv_output ? 0 : 4,\r\nnr,\r\ncsv_sep);\r\nbreak;\r\ncase AGGR_SOCKET:\r\nfprintf(output, "S%*d%s%*d%s",\r\ncsv_output ? 0 : -5,\r\nid,\r\ncsv_sep,\r\ncsv_output ? 0 : 4,\r\nnr,\r\ncsv_sep);\r\nbreak;\r\ncase AGGR_NONE:\r\nfprintf(output, "CPU%*d%s",\r\ncsv_output ? 0 : -4,\r\nperf_evsel__cpus(evsel)->map[id], csv_sep);\r\nbreak;\r\ncase AGGR_GLOBAL:\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nstatic void nsec_printout(int cpu, int nr, struct perf_evsel *evsel, double avg)\r\n{\r\ndouble msecs = avg / 1e6;\r\nconst char *fmt_v, *fmt_n;\r\nchar name[25];\r\nfmt_v = csv_output ? "%.6f%s" : "%18.6f%s";\r\nfmt_n = csv_output ? "%s" : "%-25s";\r\naggr_printout(evsel, cpu, nr);\r\nscnprintf(name, sizeof(name), "%s%s",\r\nperf_evsel__name(evsel), csv_output ? "" : " (msec)");\r\nfprintf(output, fmt_v, msecs, csv_sep);\r\nif (csv_output)\r\nfprintf(output, "%s%s", evsel->unit, csv_sep);\r\nelse\r\nfprintf(output, "%-*s%s", unit_width, evsel->unit, csv_sep);\r\nfprintf(output, fmt_n, name);\r\nif (evsel->cgrp)\r\nfprintf(output, "%s%s", csv_sep, evsel->cgrp->name);\r\nif (csv_output || interval)\r\nreturn;\r\nif (perf_evsel__match(evsel, SOFTWARE, SW_TASK_CLOCK))\r\nfprintf(output, " # %8.3f CPUs utilized ",\r\navg / avg_stats(&walltime_nsecs_stats));\r\nelse\r\nfprintf(output, " ");\r\n}\r\nstatic const char *get_ratio_color(enum grc_type type, double ratio)\r\n{\r\nstatic const double grc_table[GRC_MAX_NR][3] = {\r\n[GRC_STALLED_CYCLES_FE] = { 50.0, 30.0, 10.0 },\r\n[GRC_STALLED_CYCLES_BE] = { 75.0, 50.0, 20.0 },\r\n[GRC_CACHE_MISSES] = { 20.0, 10.0, 5.0 },\r\n};\r\nconst char *color = PERF_COLOR_NORMAL;\r\nif (ratio > grc_table[type][0])\r\ncolor = PERF_COLOR_RED;\r\nelse if (ratio > grc_table[type][1])\r\ncolor = PERF_COLOR_MAGENTA;\r\nelse if (ratio > grc_table[type][2])\r\ncolor = PERF_COLOR_YELLOW;\r\nreturn color;\r\n}\r\nstatic void print_stalled_cycles_frontend(int cpu,\r\nstruct perf_evsel *evsel\r\n__maybe_unused, double avg)\r\n{\r\ndouble total, ratio = 0.0;\r\nconst char *color;\r\ntotal = avg_stats(&runtime_cycles_stats[cpu]);\r\nif (total)\r\nratio = avg / total * 100.0;\r\ncolor = get_ratio_color(GRC_STALLED_CYCLES_FE, ratio);\r\nfprintf(output, " # ");\r\ncolor_fprintf(output, color, "%6.2f%%", ratio);\r\nfprintf(output, " frontend cycles idle ");\r\n}\r\nstatic void print_stalled_cycles_backend(int cpu,\r\nstruct perf_evsel *evsel\r\n__maybe_unused, double avg)\r\n{\r\ndouble total, ratio = 0.0;\r\nconst char *color;\r\ntotal = avg_stats(&runtime_cycles_stats[cpu]);\r\nif (total)\r\nratio = avg / total * 100.0;\r\ncolor = get_ratio_color(GRC_STALLED_CYCLES_BE, ratio);\r\nfprintf(output, " # ");\r\ncolor_fprintf(output, color, "%6.2f%%", ratio);\r\nfprintf(output, " backend cycles idle ");\r\n}\r\nstatic void print_branch_misses(int cpu,\r\nstruct perf_evsel *evsel __maybe_unused,\r\ndouble avg)\r\n{\r\ndouble total, ratio = 0.0;\r\nconst char *color;\r\ntotal = avg_stats(&runtime_branches_stats[cpu]);\r\nif (total)\r\nratio = avg / total * 100.0;\r\ncolor = get_ratio_color(GRC_CACHE_MISSES, ratio);\r\nfprintf(output, " # ");\r\ncolor_fprintf(output, color, "%6.2f%%", ratio);\r\nfprintf(output, " of all branches ");\r\n}\r\nstatic void print_l1_dcache_misses(int cpu,\r\nstruct perf_evsel *evsel __maybe_unused,\r\ndouble avg)\r\n{\r\ndouble total, ratio = 0.0;\r\nconst char *color;\r\ntotal = avg_stats(&runtime_l1_dcache_stats[cpu]);\r\nif (total)\r\nratio = avg / total * 100.0;\r\ncolor = get_ratio_color(GRC_CACHE_MISSES, ratio);\r\nfprintf(output, " # ");\r\ncolor_fprintf(output, color, "%6.2f%%", ratio);\r\nfprintf(output, " of all L1-dcache hits ");\r\n}\r\nstatic void print_l1_icache_misses(int cpu,\r\nstruct perf_evsel *evsel __maybe_unused,\r\ndouble avg)\r\n{\r\ndouble total, ratio = 0.0;\r\nconst char *color;\r\ntotal = avg_stats(&runtime_l1_icache_stats[cpu]);\r\nif (total)\r\nratio = avg / total * 100.0;\r\ncolor = get_ratio_color(GRC_CACHE_MISSES, ratio);\r\nfprintf(output, " # ");\r\ncolor_fprintf(output, color, "%6.2f%%", ratio);\r\nfprintf(output, " of all L1-icache hits ");\r\n}\r\nstatic void print_dtlb_cache_misses(int cpu,\r\nstruct perf_evsel *evsel __maybe_unused,\r\ndouble avg)\r\n{\r\ndouble total, ratio = 0.0;\r\nconst char *color;\r\ntotal = avg_stats(&runtime_dtlb_cache_stats[cpu]);\r\nif (total)\r\nratio = avg / total * 100.0;\r\ncolor = get_ratio_color(GRC_CACHE_MISSES, ratio);\r\nfprintf(output, " # ");\r\ncolor_fprintf(output, color, "%6.2f%%", ratio);\r\nfprintf(output, " of all dTLB cache hits ");\r\n}\r\nstatic void print_itlb_cache_misses(int cpu,\r\nstruct perf_evsel *evsel __maybe_unused,\r\ndouble avg)\r\n{\r\ndouble total, ratio = 0.0;\r\nconst char *color;\r\ntotal = avg_stats(&runtime_itlb_cache_stats[cpu]);\r\nif (total)\r\nratio = avg / total * 100.0;\r\ncolor = get_ratio_color(GRC_CACHE_MISSES, ratio);\r\nfprintf(output, " # ");\r\ncolor_fprintf(output, color, "%6.2f%%", ratio);\r\nfprintf(output, " of all iTLB cache hits ");\r\n}\r\nstatic void print_ll_cache_misses(int cpu,\r\nstruct perf_evsel *evsel __maybe_unused,\r\ndouble avg)\r\n{\r\ndouble total, ratio = 0.0;\r\nconst char *color;\r\ntotal = avg_stats(&runtime_ll_cache_stats[cpu]);\r\nif (total)\r\nratio = avg / total * 100.0;\r\ncolor = get_ratio_color(GRC_CACHE_MISSES, ratio);\r\nfprintf(output, " # ");\r\ncolor_fprintf(output, color, "%6.2f%%", ratio);\r\nfprintf(output, " of all LL-cache hits ");\r\n}\r\nstatic void abs_printout(int cpu, int nr, struct perf_evsel *evsel, double avg)\r\n{\r\ndouble total, ratio = 0.0, total2;\r\ndouble sc = evsel->scale;\r\nconst char *fmt;\r\nif (csv_output) {\r\nfmt = sc != 1.0 ? "%.2f%s" : "%.0f%s";\r\n} else {\r\nif (big_num)\r\nfmt = sc != 1.0 ? "%'18.2f%s" : "%'18.0f%s";\r\nelse\r\nfmt = sc != 1.0 ? "%18.2f%s" : "%18.0f%s";\r\n}\r\naggr_printout(evsel, cpu, nr);\r\nif (aggr_mode == AGGR_GLOBAL)\r\ncpu = 0;\r\nfprintf(output, fmt, avg, csv_sep);\r\nif (evsel->unit)\r\nfprintf(output, "%-*s%s",\r\ncsv_output ? 0 : unit_width,\r\nevsel->unit, csv_sep);\r\nfprintf(output, "%-*s", csv_output ? 0 : 25, perf_evsel__name(evsel));\r\nif (evsel->cgrp)\r\nfprintf(output, "%s%s", csv_sep, evsel->cgrp->name);\r\nif (csv_output || interval)\r\nreturn;\r\nif (perf_evsel__match(evsel, HARDWARE, HW_INSTRUCTIONS)) {\r\ntotal = avg_stats(&runtime_cycles_stats[cpu]);\r\nif (total) {\r\nratio = avg / total;\r\nfprintf(output, " # %5.2f insns per cycle ", ratio);\r\n}\r\ntotal = avg_stats(&runtime_stalled_cycles_front_stats[cpu]);\r\ntotal = max(total, avg_stats(&runtime_stalled_cycles_back_stats[cpu]));\r\nif (total && avg) {\r\nratio = total / avg;\r\nfprintf(output, "\n");\r\nif (aggr_mode == AGGR_NONE)\r\nfprintf(output, " ");\r\nfprintf(output, " # %5.2f stalled cycles per insn", ratio);\r\n}\r\n} else if (perf_evsel__match(evsel, HARDWARE, HW_BRANCH_MISSES) &&\r\nruntime_branches_stats[cpu].n != 0) {\r\nprint_branch_misses(cpu, evsel, avg);\r\n} else if (\r\nevsel->attr.type == PERF_TYPE_HW_CACHE &&\r\nevsel->attr.config == ( PERF_COUNT_HW_CACHE_L1D |\r\n((PERF_COUNT_HW_CACHE_OP_READ) << 8) |\r\n((PERF_COUNT_HW_CACHE_RESULT_MISS) << 16)) &&\r\nruntime_l1_dcache_stats[cpu].n != 0) {\r\nprint_l1_dcache_misses(cpu, evsel, avg);\r\n} else if (\r\nevsel->attr.type == PERF_TYPE_HW_CACHE &&\r\nevsel->attr.config == ( PERF_COUNT_HW_CACHE_L1I |\r\n((PERF_COUNT_HW_CACHE_OP_READ) << 8) |\r\n((PERF_COUNT_HW_CACHE_RESULT_MISS) << 16)) &&\r\nruntime_l1_icache_stats[cpu].n != 0) {\r\nprint_l1_icache_misses(cpu, evsel, avg);\r\n} else if (\r\nevsel->attr.type == PERF_TYPE_HW_CACHE &&\r\nevsel->attr.config == ( PERF_COUNT_HW_CACHE_DTLB |\r\n((PERF_COUNT_HW_CACHE_OP_READ) << 8) |\r\n((PERF_COUNT_HW_CACHE_RESULT_MISS) << 16)) &&\r\nruntime_dtlb_cache_stats[cpu].n != 0) {\r\nprint_dtlb_cache_misses(cpu, evsel, avg);\r\n} else if (\r\nevsel->attr.type == PERF_TYPE_HW_CACHE &&\r\nevsel->attr.config == ( PERF_COUNT_HW_CACHE_ITLB |\r\n((PERF_COUNT_HW_CACHE_OP_READ) << 8) |\r\n((PERF_COUNT_HW_CACHE_RESULT_MISS) << 16)) &&\r\nruntime_itlb_cache_stats[cpu].n != 0) {\r\nprint_itlb_cache_misses(cpu, evsel, avg);\r\n} else if (\r\nevsel->attr.type == PERF_TYPE_HW_CACHE &&\r\nevsel->attr.config == ( PERF_COUNT_HW_CACHE_LL |\r\n((PERF_COUNT_HW_CACHE_OP_READ) << 8) |\r\n((PERF_COUNT_HW_CACHE_RESULT_MISS) << 16)) &&\r\nruntime_ll_cache_stats[cpu].n != 0) {\r\nprint_ll_cache_misses(cpu, evsel, avg);\r\n} else if (perf_evsel__match(evsel, HARDWARE, HW_CACHE_MISSES) &&\r\nruntime_cacherefs_stats[cpu].n != 0) {\r\ntotal = avg_stats(&runtime_cacherefs_stats[cpu]);\r\nif (total)\r\nratio = avg * 100 / total;\r\nfprintf(output, " # %8.3f %% of all cache refs ", ratio);\r\n} else if (perf_evsel__match(evsel, HARDWARE, HW_STALLED_CYCLES_FRONTEND)) {\r\nprint_stalled_cycles_frontend(cpu, evsel, avg);\r\n} else if (perf_evsel__match(evsel, HARDWARE, HW_STALLED_CYCLES_BACKEND)) {\r\nprint_stalled_cycles_backend(cpu, evsel, avg);\r\n} else if (perf_evsel__match(evsel, HARDWARE, HW_CPU_CYCLES)) {\r\ntotal = avg_stats(&runtime_nsecs_stats[cpu]);\r\nif (total) {\r\nratio = avg / total;\r\nfprintf(output, " # %8.3f GHz ", ratio);\r\n}\r\n} else if (transaction_run &&\r\nperf_evsel__cmp(evsel, nth_evsel(T_CYCLES_IN_TX))) {\r\ntotal = avg_stats(&runtime_cycles_stats[cpu]);\r\nif (total)\r\nfprintf(output,\r\n" # %5.2f%% transactional cycles ",\r\n100.0 * (avg / total));\r\n} else if (transaction_run &&\r\nperf_evsel__cmp(evsel, nth_evsel(T_CYCLES_IN_TX_CP))) {\r\ntotal = avg_stats(&runtime_cycles_stats[cpu]);\r\ntotal2 = avg_stats(&runtime_cycles_in_tx_stats[cpu]);\r\nif (total2 < avg)\r\ntotal2 = avg;\r\nif (total)\r\nfprintf(output,\r\n" # %5.2f%% aborted cycles ",\r\n100.0 * ((total2-avg) / total));\r\n} else if (transaction_run &&\r\nperf_evsel__cmp(evsel, nth_evsel(T_TRANSACTION_START)) &&\r\navg > 0 &&\r\nruntime_cycles_in_tx_stats[cpu].n != 0) {\r\ntotal = avg_stats(&runtime_cycles_in_tx_stats[cpu]);\r\nif (total)\r\nratio = total / avg;\r\nfprintf(output, " # %8.0f cycles / transaction ", ratio);\r\n} else if (transaction_run &&\r\nperf_evsel__cmp(evsel, nth_evsel(T_ELISION_START)) &&\r\navg > 0 &&\r\nruntime_cycles_in_tx_stats[cpu].n != 0) {\r\ntotal = avg_stats(&runtime_cycles_in_tx_stats[cpu]);\r\nif (total)\r\nratio = total / avg;\r\nfprintf(output, " # %8.0f cycles / elision ", ratio);\r\n} else if (runtime_nsecs_stats[cpu].n != 0) {\r\nchar unit = 'M';\r\ntotal = avg_stats(&runtime_nsecs_stats[cpu]);\r\nif (total)\r\nratio = 1000.0 * avg / total;\r\nif (ratio < 0.001) {\r\nratio *= 1000;\r\nunit = 'K';\r\n}\r\nfprintf(output, " # %8.3f %c/sec ", ratio, unit);\r\n} else {\r\nfprintf(output, " ");\r\n}\r\n}\r\nstatic void print_aggr(char *prefix)\r\n{\r\nstruct perf_evsel *counter;\r\nint cpu, cpu2, s, s2, id, nr;\r\ndouble uval;\r\nu64 ena, run, val;\r\nif (!(aggr_map || aggr_get_id))\r\nreturn;\r\nfor (s = 0; s < aggr_map->nr; s++) {\r\nid = aggr_map->map[s];\r\nevlist__for_each(evsel_list, counter) {\r\nval = ena = run = 0;\r\nnr = 0;\r\nfor (cpu = 0; cpu < perf_evsel__nr_cpus(counter); cpu++) {\r\ncpu2 = perf_evsel__cpus(counter)->map[cpu];\r\ns2 = aggr_get_id(evsel_list->cpus, cpu2);\r\nif (s2 != id)\r\ncontinue;\r\nval += counter->counts->cpu[cpu].val;\r\nena += counter->counts->cpu[cpu].ena;\r\nrun += counter->counts->cpu[cpu].run;\r\nnr++;\r\n}\r\nif (prefix)\r\nfprintf(output, "%s", prefix);\r\nif (run == 0 || ena == 0) {\r\naggr_printout(counter, id, nr);\r\nfprintf(output, "%*s%s",\r\ncsv_output ? 0 : 18,\r\ncounter->supported ? CNTR_NOT_COUNTED : CNTR_NOT_SUPPORTED,\r\ncsv_sep);\r\nfprintf(output, "%-*s%s",\r\ncsv_output ? 0 : unit_width,\r\ncounter->unit, csv_sep);\r\nfprintf(output, "%*s",\r\ncsv_output ? 0 : -25,\r\nperf_evsel__name(counter));\r\nif (counter->cgrp)\r\nfprintf(output, "%s%s",\r\ncsv_sep, counter->cgrp->name);\r\nfputc('\n', output);\r\ncontinue;\r\n}\r\nuval = val * counter->scale;\r\nif (nsec_counter(counter))\r\nnsec_printout(id, nr, counter, uval);\r\nelse\r\nabs_printout(id, nr, counter, uval);\r\nif (!csv_output) {\r\nprint_noise(counter, 1.0);\r\nif (run != ena)\r\nfprintf(output, " (%.2f%%)",\r\n100.0 * run / ena);\r\n}\r\nfputc('\n', output);\r\n}\r\n}\r\n}\r\nstatic void print_counter_aggr(struct perf_evsel *counter, char *prefix)\r\n{\r\nstruct perf_stat *ps = counter->priv;\r\ndouble avg = avg_stats(&ps->res_stats[0]);\r\nint scaled = counter->counts->scaled;\r\ndouble uval;\r\nif (prefix)\r\nfprintf(output, "%s", prefix);\r\nif (scaled == -1) {\r\nfprintf(output, "%*s%s",\r\ncsv_output ? 0 : 18,\r\ncounter->supported ? CNTR_NOT_COUNTED : CNTR_NOT_SUPPORTED,\r\ncsv_sep);\r\nfprintf(output, "%-*s%s",\r\ncsv_output ? 0 : unit_width,\r\ncounter->unit, csv_sep);\r\nfprintf(output, "%*s",\r\ncsv_output ? 0 : -25,\r\nperf_evsel__name(counter));\r\nif (counter->cgrp)\r\nfprintf(output, "%s%s", csv_sep, counter->cgrp->name);\r\nfputc('\n', output);\r\nreturn;\r\n}\r\nuval = avg * counter->scale;\r\nif (nsec_counter(counter))\r\nnsec_printout(-1, 0, counter, uval);\r\nelse\r\nabs_printout(-1, 0, counter, uval);\r\nprint_noise(counter, avg);\r\nif (csv_output) {\r\nfputc('\n', output);\r\nreturn;\r\n}\r\nif (scaled) {\r\ndouble avg_enabled, avg_running;\r\navg_enabled = avg_stats(&ps->res_stats[1]);\r\navg_running = avg_stats(&ps->res_stats[2]);\r\nfprintf(output, " [%5.2f%%]", 100 * avg_running / avg_enabled);\r\n}\r\nfprintf(output, "\n");\r\n}\r\nstatic void print_counter(struct perf_evsel *counter, char *prefix)\r\n{\r\nu64 ena, run, val;\r\ndouble uval;\r\nint cpu;\r\nfor (cpu = 0; cpu < perf_evsel__nr_cpus(counter); cpu++) {\r\nval = counter->counts->cpu[cpu].val;\r\nena = counter->counts->cpu[cpu].ena;\r\nrun = counter->counts->cpu[cpu].run;\r\nif (prefix)\r\nfprintf(output, "%s", prefix);\r\nif (run == 0 || ena == 0) {\r\nfprintf(output, "CPU%*d%s%*s%s",\r\ncsv_output ? 0 : -4,\r\nperf_evsel__cpus(counter)->map[cpu], csv_sep,\r\ncsv_output ? 0 : 18,\r\ncounter->supported ? CNTR_NOT_COUNTED : CNTR_NOT_SUPPORTED,\r\ncsv_sep);\r\nfprintf(output, "%-*s%s",\r\ncsv_output ? 0 : unit_width,\r\ncounter->unit, csv_sep);\r\nfprintf(output, "%*s",\r\ncsv_output ? 0 : -25,\r\nperf_evsel__name(counter));\r\nif (counter->cgrp)\r\nfprintf(output, "%s%s",\r\ncsv_sep, counter->cgrp->name);\r\nfputc('\n', output);\r\ncontinue;\r\n}\r\nuval = val * counter->scale;\r\nif (nsec_counter(counter))\r\nnsec_printout(cpu, 0, counter, uval);\r\nelse\r\nabs_printout(cpu, 0, counter, uval);\r\nif (!csv_output) {\r\nprint_noise(counter, 1.0);\r\nif (run != ena)\r\nfprintf(output, " (%.2f%%)",\r\n100.0 * run / ena);\r\n}\r\nfputc('\n', output);\r\n}\r\n}\r\nstatic void print_stat(int argc, const char **argv)\r\n{\r\nstruct perf_evsel *counter;\r\nint i;\r\nfflush(stdout);\r\nif (!csv_output) {\r\nfprintf(output, "\n");\r\nfprintf(output, " Performance counter stats for ");\r\nif (target.system_wide)\r\nfprintf(output, "\'system wide");\r\nelse if (target.cpu_list)\r\nfprintf(output, "\'CPU(s) %s", target.cpu_list);\r\nelse if (!target__has_task(&target)) {\r\nfprintf(output, "\'%s", argv[0]);\r\nfor (i = 1; i < argc; i++)\r\nfprintf(output, " %s", argv[i]);\r\n} else if (target.pid)\r\nfprintf(output, "process id \'%s", target.pid);\r\nelse\r\nfprintf(output, "thread id \'%s", target.tid);\r\nfprintf(output, "\'");\r\nif (run_count > 1)\r\nfprintf(output, " (%d runs)", run_count);\r\nfprintf(output, ":\n\n");\r\n}\r\nswitch (aggr_mode) {\r\ncase AGGR_CORE:\r\ncase AGGR_SOCKET:\r\nprint_aggr(NULL);\r\nbreak;\r\ncase AGGR_GLOBAL:\r\nevlist__for_each(evsel_list, counter)\r\nprint_counter_aggr(counter, NULL);\r\nbreak;\r\ncase AGGR_NONE:\r\nevlist__for_each(evsel_list, counter)\r\nprint_counter(counter, NULL);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nif (!csv_output) {\r\nif (!null_run)\r\nfprintf(output, "\n");\r\nfprintf(output, " %17.9f seconds time elapsed",\r\navg_stats(&walltime_nsecs_stats)/1e9);\r\nif (run_count > 1) {\r\nfprintf(output, " ");\r\nprint_noise_pct(stddev_stats(&walltime_nsecs_stats),\r\navg_stats(&walltime_nsecs_stats));\r\n}\r\nfprintf(output, "\n\n");\r\n}\r\n}\r\nstatic void skip_signal(int signo)\r\n{\r\nif ((child_pid == -1) || interval)\r\ndone = 1;\r\nsignr = signo;\r\nchild_pid = -1;\r\n}\r\nstatic void sig_atexit(void)\r\n{\r\nsigset_t set, oset;\r\nsigemptyset(&set);\r\nsigaddset(&set, SIGCHLD);\r\nsigprocmask(SIG_BLOCK, &set, &oset);\r\nif (child_pid != -1)\r\nkill(child_pid, SIGTERM);\r\nsigprocmask(SIG_SETMASK, &oset, NULL);\r\nif (signr == -1)\r\nreturn;\r\nsignal(signr, SIG_DFL);\r\nkill(getpid(), signr);\r\n}\r\nstatic int stat__set_big_num(const struct option *opt __maybe_unused,\r\nconst char *s __maybe_unused, int unset)\r\n{\r\nbig_num_opt = unset ? 0 : 1;\r\nreturn 0;\r\n}\r\nstatic int perf_stat_init_aggr_mode(void)\r\n{\r\nswitch (aggr_mode) {\r\ncase AGGR_SOCKET:\r\nif (cpu_map__build_socket_map(evsel_list->cpus, &aggr_map)) {\r\nperror("cannot build socket map");\r\nreturn -1;\r\n}\r\naggr_get_id = cpu_map__get_socket;\r\nbreak;\r\ncase AGGR_CORE:\r\nif (cpu_map__build_core_map(evsel_list->cpus, &aggr_map)) {\r\nperror("cannot build core map");\r\nreturn -1;\r\n}\r\naggr_get_id = cpu_map__get_core;\r\nbreak;\r\ncase AGGR_NONE:\r\ncase AGGR_GLOBAL:\r\ndefault:\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nstatic int setup_events(const char * const *attrs, unsigned len)\r\n{\r\nunsigned i;\r\nfor (i = 0; i < len; i++) {\r\nif (parse_events(evsel_list, attrs[i]))\r\nreturn -1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int add_default_attributes(void)\r\n{\r\nstruct perf_event_attr default_attrs[] = {\r\n{ .type = PERF_TYPE_SOFTWARE, .config = PERF_COUNT_SW_TASK_CLOCK },\r\n{ .type = PERF_TYPE_SOFTWARE, .config = PERF_COUNT_SW_CONTEXT_SWITCHES },\r\n{ .type = PERF_TYPE_SOFTWARE, .config = PERF_COUNT_SW_CPU_MIGRATIONS },\r\n{ .type = PERF_TYPE_SOFTWARE, .config = PERF_COUNT_SW_PAGE_FAULTS },\r\n{ .type = PERF_TYPE_HARDWARE, .config = PERF_COUNT_HW_CPU_CYCLES },\r\n{ .type = PERF_TYPE_HARDWARE, .config = PERF_COUNT_HW_STALLED_CYCLES_FRONTEND },\r\n{ .type = PERF_TYPE_HARDWARE, .config = PERF_COUNT_HW_STALLED_CYCLES_BACKEND },\r\n{ .type = PERF_TYPE_HARDWARE, .config = PERF_COUNT_HW_INSTRUCTIONS },\r\n{ .type = PERF_TYPE_HARDWARE, .config = PERF_COUNT_HW_BRANCH_INSTRUCTIONS },\r\n{ .type = PERF_TYPE_HARDWARE, .config = PERF_COUNT_HW_BRANCH_MISSES },\r\n};\r\nstruct perf_event_attr detailed_attrs[] = {\r\n{ .type = PERF_TYPE_HW_CACHE,\r\n.config =\r\nPERF_COUNT_HW_CACHE_L1D << 0 |\r\n(PERF_COUNT_HW_CACHE_OP_READ << 8) |\r\n(PERF_COUNT_HW_CACHE_RESULT_ACCESS << 16) },\r\n{ .type = PERF_TYPE_HW_CACHE,\r\n.config =\r\nPERF_COUNT_HW_CACHE_L1D << 0 |\r\n(PERF_COUNT_HW_CACHE_OP_READ << 8) |\r\n(PERF_COUNT_HW_CACHE_RESULT_MISS << 16) },\r\n{ .type = PERF_TYPE_HW_CACHE,\r\n.config =\r\nPERF_COUNT_HW_CACHE_LL << 0 |\r\n(PERF_COUNT_HW_CACHE_OP_READ << 8) |\r\n(PERF_COUNT_HW_CACHE_RESULT_ACCESS << 16) },\r\n{ .type = PERF_TYPE_HW_CACHE,\r\n.config =\r\nPERF_COUNT_HW_CACHE_LL << 0 |\r\n(PERF_COUNT_HW_CACHE_OP_READ << 8) |\r\n(PERF_COUNT_HW_CACHE_RESULT_MISS << 16) },\r\n};\r\nstruct perf_event_attr very_detailed_attrs[] = {\r\n{ .type = PERF_TYPE_HW_CACHE,\r\n.config =\r\nPERF_COUNT_HW_CACHE_L1I << 0 |\r\n(PERF_COUNT_HW_CACHE_OP_READ << 8) |\r\n(PERF_COUNT_HW_CACHE_RESULT_ACCESS << 16) },\r\n{ .type = PERF_TYPE_HW_CACHE,\r\n.config =\r\nPERF_COUNT_HW_CACHE_L1I << 0 |\r\n(PERF_COUNT_HW_CACHE_OP_READ << 8) |\r\n(PERF_COUNT_HW_CACHE_RESULT_MISS << 16) },\r\n{ .type = PERF_TYPE_HW_CACHE,\r\n.config =\r\nPERF_COUNT_HW_CACHE_DTLB << 0 |\r\n(PERF_COUNT_HW_CACHE_OP_READ << 8) |\r\n(PERF_COUNT_HW_CACHE_RESULT_ACCESS << 16) },\r\n{ .type = PERF_TYPE_HW_CACHE,\r\n.config =\r\nPERF_COUNT_HW_CACHE_DTLB << 0 |\r\n(PERF_COUNT_HW_CACHE_OP_READ << 8) |\r\n(PERF_COUNT_HW_CACHE_RESULT_MISS << 16) },\r\n{ .type = PERF_TYPE_HW_CACHE,\r\n.config =\r\nPERF_COUNT_HW_CACHE_ITLB << 0 |\r\n(PERF_COUNT_HW_CACHE_OP_READ << 8) |\r\n(PERF_COUNT_HW_CACHE_RESULT_ACCESS << 16) },\r\n{ .type = PERF_TYPE_HW_CACHE,\r\n.config =\r\nPERF_COUNT_HW_CACHE_ITLB << 0 |\r\n(PERF_COUNT_HW_CACHE_OP_READ << 8) |\r\n(PERF_COUNT_HW_CACHE_RESULT_MISS << 16) },\r\n};\r\nstruct perf_event_attr very_very_detailed_attrs[] = {\r\n{ .type = PERF_TYPE_HW_CACHE,\r\n.config =\r\nPERF_COUNT_HW_CACHE_L1D << 0 |\r\n(PERF_COUNT_HW_CACHE_OP_PREFETCH << 8) |\r\n(PERF_COUNT_HW_CACHE_RESULT_ACCESS << 16) },\r\n{ .type = PERF_TYPE_HW_CACHE,\r\n.config =\r\nPERF_COUNT_HW_CACHE_L1D << 0 |\r\n(PERF_COUNT_HW_CACHE_OP_PREFETCH << 8) |\r\n(PERF_COUNT_HW_CACHE_RESULT_MISS << 16) },\r\n};\r\nif (null_run)\r\nreturn 0;\r\nif (transaction_run) {\r\nint err;\r\nif (pmu_have_event("cpu", "cycles-ct") &&\r\npmu_have_event("cpu", "el-start"))\r\nerr = setup_events(transaction_attrs,\r\nARRAY_SIZE(transaction_attrs));\r\nelse\r\nerr = setup_events(transaction_limited_attrs,\r\nARRAY_SIZE(transaction_limited_attrs));\r\nif (err < 0) {\r\nfprintf(stderr, "Cannot set up transaction events\n");\r\nreturn -1;\r\n}\r\nreturn 0;\r\n}\r\nif (!evsel_list->nr_entries) {\r\nif (perf_evlist__add_default_attrs(evsel_list, default_attrs) < 0)\r\nreturn -1;\r\n}\r\nif (detailed_run < 1)\r\nreturn 0;\r\nif (perf_evlist__add_default_attrs(evsel_list, detailed_attrs) < 0)\r\nreturn -1;\r\nif (detailed_run < 2)\r\nreturn 0;\r\nif (perf_evlist__add_default_attrs(evsel_list, very_detailed_attrs) < 0)\r\nreturn -1;\r\nif (detailed_run < 3)\r\nreturn 0;\r\nreturn perf_evlist__add_default_attrs(evsel_list, very_very_detailed_attrs);\r\n}\r\nint cmd_stat(int argc, const char **argv, const char *prefix __maybe_unused)\r\n{\r\nbool append_file = false;\r\nint output_fd = 0;\r\nconst char *output_name = NULL;\r\nconst struct option options[] = {\r\nOPT_BOOLEAN('T', "transaction", &transaction_run,\r\n"hardware transaction statistics"),\r\nOPT_CALLBACK('e', "event", &evsel_list, "event",\r\n"event selector. use 'perf list' to list available events",\r\nparse_events_option),\r\nOPT_CALLBACK(0, "filter", &evsel_list, "filter",\r\n"event filter", parse_filter),\r\nOPT_BOOLEAN('i', "no-inherit", &no_inherit,\r\n"child tasks do not inherit counters"),\r\nOPT_STRING('p', "pid", &target.pid, "pid",\r\n"stat events on existing process id"),\r\nOPT_STRING('t', "tid", &target.tid, "tid",\r\n"stat events on existing thread id"),\r\nOPT_BOOLEAN('a', "all-cpus", &target.system_wide,\r\n"system-wide collection from all CPUs"),\r\nOPT_BOOLEAN('g', "group", &group,\r\n"put the counters into a counter group"),\r\nOPT_BOOLEAN('c', "scale", &scale, "scale/normalize counters"),\r\nOPT_INCR('v', "verbose", &verbose,\r\n"be more verbose (show counter open errors, etc)"),\r\nOPT_INTEGER('r', "repeat", &run_count,\r\n"repeat command and print average + stddev (max: 100, forever: 0)"),\r\nOPT_BOOLEAN('n', "null", &null_run,\r\n"null run - dont start any counters"),\r\nOPT_INCR('d', "detailed", &detailed_run,\r\n"detailed run - start a lot of events"),\r\nOPT_BOOLEAN('S', "sync", &sync_run,\r\n"call sync() before starting a run"),\r\nOPT_CALLBACK_NOOPT('B', "big-num", NULL, NULL,\r\n"print large numbers with thousands\' separators",\r\nstat__set_big_num),\r\nOPT_STRING('C', "cpu", &target.cpu_list, "cpu",\r\n"list of cpus to monitor in system-wide"),\r\nOPT_SET_UINT('A', "no-aggr", &aggr_mode,\r\n"disable CPU count aggregation", AGGR_NONE),\r\nOPT_STRING('x', "field-separator", &csv_sep, "separator",\r\n"print counts with custom separator"),\r\nOPT_CALLBACK('G', "cgroup", &evsel_list, "name",\r\n"monitor event in cgroup name only", parse_cgroups),\r\nOPT_STRING('o', "output", &output_name, "file", "output file name"),\r\nOPT_BOOLEAN(0, "append", &append_file, "append to the output file"),\r\nOPT_INTEGER(0, "log-fd", &output_fd,\r\n"log output to fd, instead of stderr"),\r\nOPT_STRING(0, "pre", &pre_cmd, "command",\r\n"command to run prior to the measured command"),\r\nOPT_STRING(0, "post", &post_cmd, "command",\r\n"command to run after to the measured command"),\r\nOPT_UINTEGER('I', "interval-print", &interval,\r\n"print counts at regular interval in ms (>= 100)"),\r\nOPT_SET_UINT(0, "per-socket", &aggr_mode,\r\n"aggregate counts per processor socket", AGGR_SOCKET),\r\nOPT_SET_UINT(0, "per-core", &aggr_mode,\r\n"aggregate counts per physical processor core", AGGR_CORE),\r\nOPT_UINTEGER('D', "delay", &initial_delay,\r\n"ms to wait before starting measurement after program start"),\r\nOPT_END()\r\n};\r\nconst char * const stat_usage[] = {\r\n"perf stat [<options>] [<command>]",\r\nNULL\r\n};\r\nint status = -EINVAL, run_idx;\r\nconst char *mode;\r\nsetlocale(LC_ALL, "");\r\nevsel_list = perf_evlist__new();\r\nif (evsel_list == NULL)\r\nreturn -ENOMEM;\r\nargc = parse_options(argc, argv, options, stat_usage,\r\nPARSE_OPT_STOP_AT_NON_OPTION);\r\noutput = stderr;\r\nif (output_name && strcmp(output_name, "-"))\r\noutput = NULL;\r\nif (output_name && output_fd) {\r\nfprintf(stderr, "cannot use both --output and --log-fd\n");\r\nparse_options_usage(stat_usage, options, "o", 1);\r\nparse_options_usage(NULL, options, "log-fd", 0);\r\ngoto out;\r\n}\r\nif (output_fd < 0) {\r\nfprintf(stderr, "argument to --log-fd must be a > 0\n");\r\nparse_options_usage(stat_usage, options, "log-fd", 0);\r\ngoto out;\r\n}\r\nif (!output) {\r\nstruct timespec tm;\r\nmode = append_file ? "a" : "w";\r\noutput = fopen(output_name, mode);\r\nif (!output) {\r\nperror("failed to create output file");\r\nreturn -1;\r\n}\r\nclock_gettime(CLOCK_REALTIME, &tm);\r\nfprintf(output, "# started on %s\n", ctime(&tm.tv_sec));\r\n} else if (output_fd > 0) {\r\nmode = append_file ? "a" : "w";\r\noutput = fdopen(output_fd, mode);\r\nif (!output) {\r\nperror("Failed opening logfd");\r\nreturn -errno;\r\n}\r\n}\r\nif (csv_sep) {\r\ncsv_output = true;\r\nif (!strcmp(csv_sep, "\\t"))\r\ncsv_sep = "\t";\r\n} else\r\ncsv_sep = DEFAULT_SEPARATOR;\r\nif (csv_output) {\r\nif (big_num_opt == 1) {\r\nfprintf(stderr, "-B option not supported with -x\n");\r\nparse_options_usage(stat_usage, options, "B", 1);\r\nparse_options_usage(NULL, options, "x", 1);\r\ngoto out;\r\n} else\r\nbig_num = false;\r\n} else if (big_num_opt == 0)\r\nbig_num = false;\r\nif (!argc && target__none(&target))\r\nusage_with_options(stat_usage, options);\r\nif (run_count < 0) {\r\npr_err("Run count must be a positive number\n");\r\nparse_options_usage(stat_usage, options, "r", 1);\r\ngoto out;\r\n} else if (run_count == 0) {\r\nforever = true;\r\nrun_count = 1;\r\n}\r\nif ((aggr_mode != AGGR_GLOBAL || nr_cgroups) &&\r\n!target__has_cpu(&target)) {\r\nfprintf(stderr, "both cgroup and no-aggregation "\r\n"modes only available in system-wide mode\n");\r\nparse_options_usage(stat_usage, options, "G", 1);\r\nparse_options_usage(NULL, options, "A", 1);\r\nparse_options_usage(NULL, options, "a", 1);\r\ngoto out;\r\n}\r\nif (add_default_attributes())\r\ngoto out;\r\ntarget__validate(&target);\r\nif (perf_evlist__create_maps(evsel_list, &target) < 0) {\r\nif (target__has_task(&target)) {\r\npr_err("Problems finding threads of monitor\n");\r\nparse_options_usage(stat_usage, options, "p", 1);\r\nparse_options_usage(NULL, options, "t", 1);\r\n} else if (target__has_cpu(&target)) {\r\nperror("failed to parse CPUs map");\r\nparse_options_usage(stat_usage, options, "C", 1);\r\nparse_options_usage(NULL, options, "a", 1);\r\n}\r\ngoto out;\r\n}\r\nif (interval && interval < 100) {\r\npr_err("print interval must be >= 100ms\n");\r\nparse_options_usage(stat_usage, options, "I", 1);\r\ngoto out;\r\n}\r\nif (perf_evlist__alloc_stats(evsel_list, interval))\r\ngoto out;\r\nif (perf_stat_init_aggr_mode())\r\ngoto out;\r\natexit(sig_atexit);\r\nif (!forever)\r\nsignal(SIGINT, skip_signal);\r\nsignal(SIGCHLD, skip_signal);\r\nsignal(SIGALRM, skip_signal);\r\nsignal(SIGABRT, skip_signal);\r\nstatus = 0;\r\nfor (run_idx = 0; forever || run_idx < run_count; run_idx++) {\r\nif (run_count != 1 && verbose)\r\nfprintf(output, "[ perf stat: executing run #%d ... ]\n",\r\nrun_idx + 1);\r\nstatus = run_perf_stat(argc, argv);\r\nif (forever && status != -1) {\r\nprint_stat(argc, argv);\r\nperf_stat__reset_stats(evsel_list);\r\n}\r\n}\r\nif (!forever && status != -1 && !interval)\r\nprint_stat(argc, argv);\r\nperf_evlist__free_stats(evsel_list);\r\nout:\r\nperf_evlist__delete(evsel_list);\r\nreturn status;\r\n}
