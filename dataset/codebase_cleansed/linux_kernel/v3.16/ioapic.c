static unsigned long ioapic_read_indirect(struct kvm_ioapic *ioapic,\r\nunsigned long addr,\r\nunsigned long length)\r\n{\r\nunsigned long result = 0;\r\nswitch (ioapic->ioregsel) {\r\ncase IOAPIC_REG_VERSION:\r\nresult = ((((IOAPIC_NUM_PINS - 1) & 0xff) << 16)\r\n| (IOAPIC_VERSION_ID & 0xff));\r\nbreak;\r\ncase IOAPIC_REG_APIC_ID:\r\ncase IOAPIC_REG_ARB_ID:\r\nresult = ((ioapic->id & 0xf) << 24);\r\nbreak;\r\ndefault:\r\n{\r\nu32 redir_index = (ioapic->ioregsel - 0x10) >> 1;\r\nu64 redir_content;\r\nif (redir_index < IOAPIC_NUM_PINS)\r\nredir_content =\r\nioapic->redirtbl[redir_index].bits;\r\nelse\r\nredir_content = ~0ULL;\r\nresult = (ioapic->ioregsel & 0x1) ?\r\n(redir_content >> 32) & 0xffffffff :\r\nredir_content & 0xffffffff;\r\nbreak;\r\n}\r\n}\r\nreturn result;\r\n}\r\nstatic void rtc_irq_eoi_tracking_reset(struct kvm_ioapic *ioapic)\r\n{\r\nioapic->rtc_status.pending_eoi = 0;\r\nbitmap_zero(ioapic->rtc_status.dest_map, KVM_MAX_VCPUS);\r\n}\r\nstatic void rtc_status_pending_eoi_check_valid(struct kvm_ioapic *ioapic)\r\n{\r\nif (WARN_ON(ioapic->rtc_status.pending_eoi < 0))\r\nkvm_rtc_eoi_tracking_restore_all(ioapic);\r\n}\r\nstatic void __rtc_irq_eoi_tracking_restore_one(struct kvm_vcpu *vcpu)\r\n{\r\nbool new_val, old_val;\r\nstruct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;\r\nunion kvm_ioapic_redirect_entry *e;\r\ne = &ioapic->redirtbl[RTC_GSI];\r\nif (!kvm_apic_match_dest(vcpu, NULL, 0, e->fields.dest_id,\r\ne->fields.dest_mode))\r\nreturn;\r\nnew_val = kvm_apic_pending_eoi(vcpu, e->fields.vector);\r\nold_val = test_bit(vcpu->vcpu_id, ioapic->rtc_status.dest_map);\r\nif (new_val == old_val)\r\nreturn;\r\nif (new_val) {\r\n__set_bit(vcpu->vcpu_id, ioapic->rtc_status.dest_map);\r\nioapic->rtc_status.pending_eoi++;\r\n} else {\r\n__clear_bit(vcpu->vcpu_id, ioapic->rtc_status.dest_map);\r\nioapic->rtc_status.pending_eoi--;\r\nrtc_status_pending_eoi_check_valid(ioapic);\r\n}\r\n}\r\nvoid kvm_rtc_eoi_tracking_restore_one(struct kvm_vcpu *vcpu)\r\n{\r\nstruct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;\r\nspin_lock(&ioapic->lock);\r\n__rtc_irq_eoi_tracking_restore_one(vcpu);\r\nspin_unlock(&ioapic->lock);\r\n}\r\nstatic void kvm_rtc_eoi_tracking_restore_all(struct kvm_ioapic *ioapic)\r\n{\r\nstruct kvm_vcpu *vcpu;\r\nint i;\r\nif (RTC_GSI >= IOAPIC_NUM_PINS)\r\nreturn;\r\nrtc_irq_eoi_tracking_reset(ioapic);\r\nkvm_for_each_vcpu(i, vcpu, ioapic->kvm)\r\n__rtc_irq_eoi_tracking_restore_one(vcpu);\r\n}\r\nstatic void rtc_irq_eoi(struct kvm_ioapic *ioapic, struct kvm_vcpu *vcpu)\r\n{\r\nif (test_and_clear_bit(vcpu->vcpu_id, ioapic->rtc_status.dest_map)) {\r\n--ioapic->rtc_status.pending_eoi;\r\nrtc_status_pending_eoi_check_valid(ioapic);\r\n}\r\n}\r\nstatic bool rtc_irq_check_coalesced(struct kvm_ioapic *ioapic)\r\n{\r\nif (ioapic->rtc_status.pending_eoi > 0)\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic int ioapic_set_irq(struct kvm_ioapic *ioapic, unsigned int irq,\r\nint irq_level, bool line_status)\r\n{\r\nunion kvm_ioapic_redirect_entry entry;\r\nu32 mask = 1 << irq;\r\nu32 old_irr;\r\nint edge, ret;\r\nentry = ioapic->redirtbl[irq];\r\nedge = (entry.fields.trig_mode == IOAPIC_EDGE_TRIG);\r\nif (!irq_level) {\r\nioapic->irr &= ~mask;\r\nret = 1;\r\ngoto out;\r\n}\r\nif (irq == RTC_GSI && line_status &&\r\nrtc_irq_check_coalesced(ioapic)) {\r\nret = 0;\r\ngoto out;\r\n}\r\nold_irr = ioapic->irr;\r\nioapic->irr |= mask;\r\nif ((edge && old_irr == ioapic->irr) ||\r\n(!edge && entry.fields.remote_irr)) {\r\nret = 0;\r\ngoto out;\r\n}\r\nret = ioapic_service(ioapic, irq, line_status);\r\nout:\r\ntrace_kvm_ioapic_set_irq(entry.bits, irq, ret == 0);\r\nreturn ret;\r\n}\r\nstatic void kvm_ioapic_inject_all(struct kvm_ioapic *ioapic, unsigned long irr)\r\n{\r\nu32 idx;\r\nrtc_irq_eoi_tracking_reset(ioapic);\r\nfor_each_set_bit(idx, &irr, IOAPIC_NUM_PINS)\r\nioapic_set_irq(ioapic, idx, 1, true);\r\nkvm_rtc_eoi_tracking_restore_all(ioapic);\r\n}\r\nstatic void update_handled_vectors(struct kvm_ioapic *ioapic)\r\n{\r\nDECLARE_BITMAP(handled_vectors, 256);\r\nint i;\r\nmemset(handled_vectors, 0, sizeof(handled_vectors));\r\nfor (i = 0; i < IOAPIC_NUM_PINS; ++i)\r\n__set_bit(ioapic->redirtbl[i].fields.vector, handled_vectors);\r\nmemcpy(ioapic->handled_vectors, handled_vectors,\r\nsizeof(handled_vectors));\r\nsmp_wmb();\r\n}\r\nvoid kvm_ioapic_scan_entry(struct kvm_vcpu *vcpu, u64 *eoi_exit_bitmap,\r\nu32 *tmr)\r\n{\r\nstruct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;\r\nunion kvm_ioapic_redirect_entry *e;\r\nint index;\r\nspin_lock(&ioapic->lock);\r\nfor (index = 0; index < IOAPIC_NUM_PINS; index++) {\r\ne = &ioapic->redirtbl[index];\r\nif (!e->fields.mask &&\r\n(e->fields.trig_mode == IOAPIC_LEVEL_TRIG ||\r\nkvm_irq_has_notifier(ioapic->kvm, KVM_IRQCHIP_IOAPIC,\r\nindex) || index == RTC_GSI)) {\r\nif (kvm_apic_match_dest(vcpu, NULL, 0,\r\ne->fields.dest_id, e->fields.dest_mode)) {\r\n__set_bit(e->fields.vector,\r\n(unsigned long *)eoi_exit_bitmap);\r\nif (e->fields.trig_mode == IOAPIC_LEVEL_TRIG)\r\n__set_bit(e->fields.vector,\r\n(unsigned long *)tmr);\r\n}\r\n}\r\n}\r\nspin_unlock(&ioapic->lock);\r\n}\r\nvoid kvm_vcpu_request_scan_ioapic(struct kvm *kvm)\r\n{\r\nstruct kvm_ioapic *ioapic = kvm->arch.vioapic;\r\nif (!ioapic)\r\nreturn;\r\nkvm_make_scan_ioapic_request(kvm);\r\n}\r\nvoid kvm_vcpu_request_scan_ioapic(struct kvm *kvm)\r\n{\r\nreturn;\r\n}\r\nstatic void ioapic_write_indirect(struct kvm_ioapic *ioapic, u32 val)\r\n{\r\nunsigned index;\r\nbool mask_before, mask_after;\r\nunion kvm_ioapic_redirect_entry *e;\r\nswitch (ioapic->ioregsel) {\r\ncase IOAPIC_REG_VERSION:\r\nbreak;\r\ncase IOAPIC_REG_APIC_ID:\r\nioapic->id = (val >> 24) & 0xf;\r\nbreak;\r\ncase IOAPIC_REG_ARB_ID:\r\nbreak;\r\ndefault:\r\nindex = (ioapic->ioregsel - 0x10) >> 1;\r\nioapic_debug("change redir index %x val %x\n", index, val);\r\nif (index >= IOAPIC_NUM_PINS)\r\nreturn;\r\ne = &ioapic->redirtbl[index];\r\nmask_before = e->fields.mask;\r\nif (ioapic->ioregsel & 1) {\r\ne->bits &= 0xffffffff;\r\ne->bits |= (u64) val << 32;\r\n} else {\r\ne->bits &= ~0xffffffffULL;\r\ne->bits |= (u32) val;\r\ne->fields.remote_irr = 0;\r\n}\r\nupdate_handled_vectors(ioapic);\r\nmask_after = e->fields.mask;\r\nif (mask_before != mask_after)\r\nkvm_fire_mask_notifiers(ioapic->kvm, KVM_IRQCHIP_IOAPIC, index, mask_after);\r\nif (e->fields.trig_mode == IOAPIC_LEVEL_TRIG\r\n&& ioapic->irr & (1 << index))\r\nioapic_service(ioapic, index, false);\r\nkvm_vcpu_request_scan_ioapic(ioapic->kvm);\r\nbreak;\r\n}\r\n}\r\nstatic int ioapic_service(struct kvm_ioapic *ioapic, int irq, bool line_status)\r\n{\r\nunion kvm_ioapic_redirect_entry *entry = &ioapic->redirtbl[irq];\r\nstruct kvm_lapic_irq irqe;\r\nint ret;\r\nif (entry->fields.mask)\r\nreturn -1;\r\nioapic_debug("dest=%x dest_mode=%x delivery_mode=%x "\r\n"vector=%x trig_mode=%x\n",\r\nentry->fields.dest_id, entry->fields.dest_mode,\r\nentry->fields.delivery_mode, entry->fields.vector,\r\nentry->fields.trig_mode);\r\nirqe.dest_id = entry->fields.dest_id;\r\nirqe.vector = entry->fields.vector;\r\nirqe.dest_mode = entry->fields.dest_mode;\r\nirqe.trig_mode = entry->fields.trig_mode;\r\nirqe.delivery_mode = entry->fields.delivery_mode << 8;\r\nirqe.level = 1;\r\nirqe.shorthand = 0;\r\nif (irqe.trig_mode == IOAPIC_EDGE_TRIG)\r\nioapic->irr &= ~(1 << irq);\r\nif (irq == RTC_GSI && line_status) {\r\nBUG_ON(ioapic->rtc_status.pending_eoi != 0);\r\nret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe,\r\nioapic->rtc_status.dest_map);\r\nioapic->rtc_status.pending_eoi = (ret < 0 ? 0 : ret);\r\n} else\r\nret = kvm_irq_delivery_to_apic(ioapic->kvm, NULL, &irqe, NULL);\r\nif (ret && irqe.trig_mode == IOAPIC_LEVEL_TRIG)\r\nentry->fields.remote_irr = 1;\r\nreturn ret;\r\n}\r\nint kvm_ioapic_set_irq(struct kvm_ioapic *ioapic, int irq, int irq_source_id,\r\nint level, bool line_status)\r\n{\r\nint ret, irq_level;\r\nBUG_ON(irq < 0 || irq >= IOAPIC_NUM_PINS);\r\nspin_lock(&ioapic->lock);\r\nirq_level = __kvm_irq_line_state(&ioapic->irq_states[irq],\r\nirq_source_id, level);\r\nret = ioapic_set_irq(ioapic, irq, irq_level, line_status);\r\nspin_unlock(&ioapic->lock);\r\nreturn ret;\r\n}\r\nvoid kvm_ioapic_clear_all(struct kvm_ioapic *ioapic, int irq_source_id)\r\n{\r\nint i;\r\nspin_lock(&ioapic->lock);\r\nfor (i = 0; i < KVM_IOAPIC_NUM_PINS; i++)\r\n__clear_bit(irq_source_id, &ioapic->irq_states[i]);\r\nspin_unlock(&ioapic->lock);\r\n}\r\nstatic void __kvm_ioapic_update_eoi(struct kvm_vcpu *vcpu,\r\nstruct kvm_ioapic *ioapic, int vector, int trigger_mode)\r\n{\r\nint i;\r\nfor (i = 0; i < IOAPIC_NUM_PINS; i++) {\r\nunion kvm_ioapic_redirect_entry *ent = &ioapic->redirtbl[i];\r\nif (ent->fields.vector != vector)\r\ncontinue;\r\nif (i == RTC_GSI)\r\nrtc_irq_eoi(ioapic, vcpu);\r\nspin_unlock(&ioapic->lock);\r\nkvm_notify_acked_irq(ioapic->kvm, KVM_IRQCHIP_IOAPIC, i);\r\nspin_lock(&ioapic->lock);\r\nif (trigger_mode != IOAPIC_LEVEL_TRIG)\r\ncontinue;\r\nASSERT(ent->fields.trig_mode == IOAPIC_LEVEL_TRIG);\r\nent->fields.remote_irr = 0;\r\nif (ioapic->irr & (1 << i))\r\nioapic_service(ioapic, i, false);\r\n}\r\n}\r\nbool kvm_ioapic_handles_vector(struct kvm *kvm, int vector)\r\n{\r\nstruct kvm_ioapic *ioapic = kvm->arch.vioapic;\r\nsmp_rmb();\r\nreturn test_bit(vector, ioapic->handled_vectors);\r\n}\r\nvoid kvm_ioapic_update_eoi(struct kvm_vcpu *vcpu, int vector, int trigger_mode)\r\n{\r\nstruct kvm_ioapic *ioapic = vcpu->kvm->arch.vioapic;\r\nspin_lock(&ioapic->lock);\r\n__kvm_ioapic_update_eoi(vcpu, ioapic, vector, trigger_mode);\r\nspin_unlock(&ioapic->lock);\r\n}\r\nstatic inline struct kvm_ioapic *to_ioapic(struct kvm_io_device *dev)\r\n{\r\nreturn container_of(dev, struct kvm_ioapic, dev);\r\n}\r\nstatic inline int ioapic_in_range(struct kvm_ioapic *ioapic, gpa_t addr)\r\n{\r\nreturn ((addr >= ioapic->base_address &&\r\n(addr < ioapic->base_address + IOAPIC_MEM_LENGTH)));\r\n}\r\nstatic int ioapic_mmio_read(struct kvm_io_device *this, gpa_t addr, int len,\r\nvoid *val)\r\n{\r\nstruct kvm_ioapic *ioapic = to_ioapic(this);\r\nu32 result;\r\nif (!ioapic_in_range(ioapic, addr))\r\nreturn -EOPNOTSUPP;\r\nioapic_debug("addr %lx\n", (unsigned long)addr);\r\nASSERT(!(addr & 0xf));\r\naddr &= 0xff;\r\nspin_lock(&ioapic->lock);\r\nswitch (addr) {\r\ncase IOAPIC_REG_SELECT:\r\nresult = ioapic->ioregsel;\r\nbreak;\r\ncase IOAPIC_REG_WINDOW:\r\nresult = ioapic_read_indirect(ioapic, addr, len);\r\nbreak;\r\ndefault:\r\nresult = 0;\r\nbreak;\r\n}\r\nspin_unlock(&ioapic->lock);\r\nswitch (len) {\r\ncase 8:\r\n*(u64 *) val = result;\r\nbreak;\r\ncase 1:\r\ncase 2:\r\ncase 4:\r\nmemcpy(val, (char *)&result, len);\r\nbreak;\r\ndefault:\r\nprintk(KERN_WARNING "ioapic: wrong length %d\n", len);\r\n}\r\nreturn 0;\r\n}\r\nstatic int ioapic_mmio_write(struct kvm_io_device *this, gpa_t addr, int len,\r\nconst void *val)\r\n{\r\nstruct kvm_ioapic *ioapic = to_ioapic(this);\r\nu32 data;\r\nif (!ioapic_in_range(ioapic, addr))\r\nreturn -EOPNOTSUPP;\r\nioapic_debug("ioapic_mmio_write addr=%p len=%d val=%p\n",\r\n(void*)addr, len, val);\r\nASSERT(!(addr & 0xf));\r\nswitch (len) {\r\ncase 8:\r\ncase 4:\r\ndata = *(u32 *) val;\r\nbreak;\r\ncase 2:\r\ndata = *(u16 *) val;\r\nbreak;\r\ncase 1:\r\ndata = *(u8 *) val;\r\nbreak;\r\ndefault:\r\nprintk(KERN_WARNING "ioapic: Unsupported size %d\n", len);\r\nreturn 0;\r\n}\r\naddr &= 0xff;\r\nspin_lock(&ioapic->lock);\r\nswitch (addr) {\r\ncase IOAPIC_REG_SELECT:\r\nioapic->ioregsel = data & 0xFF;\r\nbreak;\r\ncase IOAPIC_REG_WINDOW:\r\nioapic_write_indirect(ioapic, data);\r\nbreak;\r\n#ifdef CONFIG_IA64\r\ncase IOAPIC_REG_EOI:\r\n__kvm_ioapic_update_eoi(NULL, ioapic, data, IOAPIC_LEVEL_TRIG);\r\nbreak;\r\n#endif\r\ndefault:\r\nbreak;\r\n}\r\nspin_unlock(&ioapic->lock);\r\nreturn 0;\r\n}\r\nstatic void kvm_ioapic_reset(struct kvm_ioapic *ioapic)\r\n{\r\nint i;\r\nfor (i = 0; i < IOAPIC_NUM_PINS; i++)\r\nioapic->redirtbl[i].fields.mask = 1;\r\nioapic->base_address = IOAPIC_DEFAULT_BASE_ADDRESS;\r\nioapic->ioregsel = 0;\r\nioapic->irr = 0;\r\nioapic->id = 0;\r\nrtc_irq_eoi_tracking_reset(ioapic);\r\nupdate_handled_vectors(ioapic);\r\n}\r\nint kvm_ioapic_init(struct kvm *kvm)\r\n{\r\nstruct kvm_ioapic *ioapic;\r\nint ret;\r\nioapic = kzalloc(sizeof(struct kvm_ioapic), GFP_KERNEL);\r\nif (!ioapic)\r\nreturn -ENOMEM;\r\nspin_lock_init(&ioapic->lock);\r\nkvm->arch.vioapic = ioapic;\r\nkvm_ioapic_reset(ioapic);\r\nkvm_iodevice_init(&ioapic->dev, &ioapic_mmio_ops);\r\nioapic->kvm = kvm;\r\nmutex_lock(&kvm->slots_lock);\r\nret = kvm_io_bus_register_dev(kvm, KVM_MMIO_BUS, ioapic->base_address,\r\nIOAPIC_MEM_LENGTH, &ioapic->dev);\r\nmutex_unlock(&kvm->slots_lock);\r\nif (ret < 0) {\r\nkvm->arch.vioapic = NULL;\r\nkfree(ioapic);\r\n}\r\nreturn ret;\r\n}\r\nvoid kvm_ioapic_destroy(struct kvm *kvm)\r\n{\r\nstruct kvm_ioapic *ioapic = kvm->arch.vioapic;\r\nif (ioapic) {\r\nkvm_io_bus_unregister_dev(kvm, KVM_MMIO_BUS, &ioapic->dev);\r\nkvm->arch.vioapic = NULL;\r\nkfree(ioapic);\r\n}\r\n}\r\nint kvm_get_ioapic(struct kvm *kvm, struct kvm_ioapic_state *state)\r\n{\r\nstruct kvm_ioapic *ioapic = ioapic_irqchip(kvm);\r\nif (!ioapic)\r\nreturn -EINVAL;\r\nspin_lock(&ioapic->lock);\r\nmemcpy(state, ioapic, sizeof(struct kvm_ioapic_state));\r\nspin_unlock(&ioapic->lock);\r\nreturn 0;\r\n}\r\nint kvm_set_ioapic(struct kvm *kvm, struct kvm_ioapic_state *state)\r\n{\r\nstruct kvm_ioapic *ioapic = ioapic_irqchip(kvm);\r\nif (!ioapic)\r\nreturn -EINVAL;\r\nspin_lock(&ioapic->lock);\r\nmemcpy(ioapic, state, sizeof(struct kvm_ioapic_state));\r\nioapic->irr = 0;\r\nupdate_handled_vectors(ioapic);\r\nkvm_vcpu_request_scan_ioapic(kvm);\r\nkvm_ioapic_inject_all(ioapic, state->irr);\r\nspin_unlock(&ioapic->lock);\r\nreturn 0;\r\n}
