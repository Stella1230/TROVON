static const char * enctype2str(__u32 enctype)\r\n{\r\nif (enctype < MAX_ENCTYPES && enctypes[enctype].ke_dispname)\r\nreturn enctypes[enctype].ke_dispname;\r\nreturn "unknown";\r\n}\r\nstatic\r\nint keyblock_init(struct krb5_keyblock *kb, char *alg_name, int alg_mode)\r\n{\r\nkb->kb_tfm = crypto_alloc_blkcipher(alg_name, alg_mode, 0);\r\nif (IS_ERR(kb->kb_tfm)) {\r\nCERROR("failed to alloc tfm: %s, mode %d\n",\r\nalg_name, alg_mode);\r\nreturn -1;\r\n}\r\nif (crypto_blkcipher_setkey(kb->kb_tfm, kb->kb_key.data, kb->kb_key.len)) {\r\nCERROR("failed to set %s key, len %d\n",\r\nalg_name, kb->kb_key.len);\r\nreturn -1;\r\n}\r\nreturn 0;\r\n}\r\nstatic\r\nint krb5_init_keys(struct krb5_ctx *kctx)\r\n{\r\nstruct krb5_enctype *ke;\r\nif (kctx->kc_enctype >= MAX_ENCTYPES ||\r\nenctypes[kctx->kc_enctype].ke_hash_size == 0) {\r\nCERROR("unsupported enctype %x\n", kctx->kc_enctype);\r\nreturn -1;\r\n}\r\nke = &enctypes[kctx->kc_enctype];\r\nif (kctx->kc_enctype != ENCTYPE_ARCFOUR_HMAC &&\r\nkeyblock_init(&kctx->kc_keye, ke->ke_enc_name, ke->ke_enc_mode))\r\nreturn -1;\r\nif (ke->ke_hash_hmac == 0 &&\r\nkeyblock_init(&kctx->kc_keyi, ke->ke_enc_name, ke->ke_enc_mode))\r\nreturn -1;\r\nif (ke->ke_hash_hmac == 0 &&\r\nkeyblock_init(&kctx->kc_keyc, ke->ke_enc_name, ke->ke_enc_mode))\r\nreturn -1;\r\nreturn 0;\r\n}\r\nstatic\r\nvoid keyblock_free(struct krb5_keyblock *kb)\r\n{\r\nrawobj_free(&kb->kb_key);\r\nif (kb->kb_tfm)\r\ncrypto_free_blkcipher(kb->kb_tfm);\r\n}\r\nstatic\r\nint keyblock_dup(struct krb5_keyblock *new, struct krb5_keyblock *kb)\r\n{\r\nreturn rawobj_dup(&new->kb_key, &kb->kb_key);\r\n}\r\nstatic\r\nint get_bytes(char **ptr, const char *end, void *res, int len)\r\n{\r\nchar *p, *q;\r\np = *ptr;\r\nq = p + len;\r\nif (q > end || q < p)\r\nreturn -1;\r\nmemcpy(res, p, len);\r\n*ptr = q;\r\nreturn 0;\r\n}\r\nstatic\r\nint get_rawobj(char **ptr, const char *end, rawobj_t *res)\r\n{\r\nchar *p, *q;\r\n__u32 len;\r\np = *ptr;\r\nif (get_bytes(&p, end, &len, sizeof(len)))\r\nreturn -1;\r\nq = p + len;\r\nif (q > end || q < p)\r\nreturn -1;\r\nOBD_ALLOC_LARGE(res->data, len);\r\nif (!res->data)\r\nreturn -1;\r\nres->len = len;\r\nmemcpy(res->data, p, len);\r\n*ptr = q;\r\nreturn 0;\r\n}\r\nstatic\r\nint get_keyblock(char **ptr, const char *end,\r\nstruct krb5_keyblock *kb, __u32 keysize)\r\n{\r\nchar *buf;\r\nOBD_ALLOC_LARGE(buf, keysize);\r\nif (buf == NULL)\r\nreturn -1;\r\nif (get_bytes(ptr, end, buf, keysize)) {\r\nOBD_FREE_LARGE(buf, keysize);\r\nreturn -1;\r\n}\r\nkb->kb_key.len = keysize;\r\nkb->kb_key.data = buf;\r\nreturn 0;\r\n}\r\nstatic\r\nvoid delete_context_kerberos(struct krb5_ctx *kctx)\r\n{\r\nrawobj_free(&kctx->kc_mech_used);\r\nkeyblock_free(&kctx->kc_keye);\r\nkeyblock_free(&kctx->kc_keyi);\r\nkeyblock_free(&kctx->kc_keyc);\r\n}\r\nstatic\r\n__u32 import_context_rfc1964(struct krb5_ctx *kctx, char *p, char *end)\r\n{\r\nunsigned int tmp_uint, keysize;\r\nif (get_bytes(&p, end, &tmp_uint, sizeof(tmp_uint)))\r\ngoto out_err;\r\nkctx->kc_seed_init = (tmp_uint != 0);\r\nif (get_bytes(&p, end, kctx->kc_seed, sizeof(kctx->kc_seed)))\r\ngoto out_err;\r\nif (get_bytes(&p, end, &tmp_uint, sizeof(tmp_uint)) ||\r\nget_bytes(&p, end, &tmp_uint, sizeof(tmp_uint)))\r\ngoto out_err;\r\nif (get_bytes(&p, end, &kctx->kc_endtime, sizeof(kctx->kc_endtime)))\r\ngoto out_err;\r\nif (get_bytes(&p, end, &tmp_uint, sizeof(tmp_uint)))\r\ngoto out_err;\r\nkctx->kc_seq_send = tmp_uint;\r\nif (get_rawobj(&p, end, &kctx->kc_mech_used))\r\ngoto out_err;\r\nif (get_bytes(&p, end, &kctx->kc_enctype, sizeof(kctx->kc_enctype)))\r\ngoto out_err;\r\nif (get_bytes(&p, end, &keysize, sizeof(keysize)))\r\ngoto out_err;\r\nif (get_keyblock(&p, end, &kctx->kc_keye, keysize))\r\ngoto out_err;\r\nif (get_bytes(&p, end, &tmp_uint, sizeof(tmp_uint)) ||\r\ntmp_uint != kctx->kc_enctype)\r\ngoto out_err;\r\nif (get_bytes(&p, end, &tmp_uint, sizeof(tmp_uint)) ||\r\ntmp_uint != keysize)\r\ngoto out_err;\r\nif (get_keyblock(&p, end, &kctx->kc_keyc, keysize))\r\ngoto out_err;\r\nif (keyblock_dup(&kctx->kc_keyi, &kctx->kc_keyc))\r\ngoto out_err;\r\nif (p != end)\r\ngoto out_err;\r\nCDEBUG(D_SEC, "successfully imported rfc1964 context\n");\r\nreturn 0;\r\nout_err:\r\nreturn GSS_S_FAILURE;\r\n}\r\nstatic\r\n__u32 import_context_rfc4121(struct krb5_ctx *kctx, char *p, char *end)\r\n{\r\nunsigned int tmp_uint, keysize;\r\nif (get_bytes(&p, end, &kctx->kc_endtime, sizeof(kctx->kc_endtime)))\r\ngoto out_err;\r\nif (get_bytes(&p, end, &tmp_uint, sizeof(tmp_uint)))\r\ngoto out_err;\r\nif (tmp_uint & KRB5_CTX_FLAG_INITIATOR)\r\nkctx->kc_initiate = 1;\r\nif (tmp_uint & KRB5_CTX_FLAG_CFX)\r\nkctx->kc_cfx = 1;\r\nif (tmp_uint & KRB5_CTX_FLAG_ACCEPTOR_SUBKEY)\r\nkctx->kc_have_acceptor_subkey = 1;\r\nif (get_bytes(&p, end, &kctx->kc_seq_send, sizeof(kctx->kc_seq_send)))\r\ngoto out_err;\r\nif (get_bytes(&p, end, &kctx->kc_enctype, sizeof(kctx->kc_enctype)))\r\ngoto out_err;\r\nif (get_bytes(&p, end, &keysize, sizeof(keysize)))\r\ngoto out_err;\r\nif (get_bytes(&p, end, &tmp_uint, sizeof(tmp_uint)))\r\ngoto out_err;\r\nif (tmp_uint != 3) {\r\nCERROR("Invalid number of keys: %u\n", tmp_uint);\r\ngoto out_err;\r\n}\r\nif (get_keyblock(&p, end, &kctx->kc_keye, keysize))\r\ngoto out_err;\r\nif (get_keyblock(&p, end, &kctx->kc_keyi, keysize))\r\ngoto out_err;\r\nif (get_keyblock(&p, end, &kctx->kc_keyc, keysize))\r\ngoto out_err;\r\nCDEBUG(D_SEC, "successfully imported v2 context\n");\r\nreturn 0;\r\nout_err:\r\nreturn GSS_S_FAILURE;\r\n}\r\nstatic\r\n__u32 gss_import_sec_context_kerberos(rawobj_t *inbuf,\r\nstruct gss_ctx *gctx)\r\n{\r\nstruct krb5_ctx *kctx;\r\nchar *p = (char *) inbuf->data;\r\nchar *end = (char *) (inbuf->data + inbuf->len);\r\nunsigned int tmp_uint, rc;\r\nif (get_bytes(&p, end, &tmp_uint, sizeof(tmp_uint))) {\r\nCERROR("Fail to read version\n");\r\nreturn GSS_S_FAILURE;\r\n}\r\nif (tmp_uint > 2) {\r\nCERROR("Invalid version %u\n", tmp_uint);\r\nreturn GSS_S_FAILURE;\r\n}\r\nOBD_ALLOC_PTR(kctx);\r\nif (!kctx)\r\nreturn GSS_S_FAILURE;\r\nif (tmp_uint == 0 || tmp_uint == 1) {\r\nkctx->kc_initiate = tmp_uint;\r\nrc = import_context_rfc1964(kctx, p, end);\r\n} else {\r\nrc = import_context_rfc4121(kctx, p, end);\r\n}\r\nif (rc == 0)\r\nrc = krb5_init_keys(kctx);\r\nif (rc) {\r\ndelete_context_kerberos(kctx);\r\nOBD_FREE_PTR(kctx);\r\nreturn GSS_S_FAILURE;\r\n}\r\ngctx->internal_ctx_id = kctx;\r\nreturn GSS_S_COMPLETE;\r\n}\r\nstatic\r\n__u32 gss_copy_reverse_context_kerberos(struct gss_ctx *gctx,\r\nstruct gss_ctx *gctx_new)\r\n{\r\nstruct krb5_ctx *kctx = gctx->internal_ctx_id;\r\nstruct krb5_ctx *knew;\r\nOBD_ALLOC_PTR(knew);\r\nif (!knew)\r\nreturn GSS_S_FAILURE;\r\nknew->kc_initiate = kctx->kc_initiate ? 0 : 1;\r\nknew->kc_cfx = kctx->kc_cfx;\r\nknew->kc_seed_init = kctx->kc_seed_init;\r\nknew->kc_have_acceptor_subkey = kctx->kc_have_acceptor_subkey;\r\nknew->kc_endtime = kctx->kc_endtime;\r\nmemcpy(knew->kc_seed, kctx->kc_seed, sizeof(kctx->kc_seed));\r\nknew->kc_seq_send = kctx->kc_seq_recv;\r\nknew->kc_seq_recv = kctx->kc_seq_send;\r\nknew->kc_enctype = kctx->kc_enctype;\r\nif (rawobj_dup(&knew->kc_mech_used, &kctx->kc_mech_used))\r\ngoto out_err;\r\nif (keyblock_dup(&knew->kc_keye, &kctx->kc_keye))\r\ngoto out_err;\r\nif (keyblock_dup(&knew->kc_keyi, &kctx->kc_keyi))\r\ngoto out_err;\r\nif (keyblock_dup(&knew->kc_keyc, &kctx->kc_keyc))\r\ngoto out_err;\r\nif (krb5_init_keys(knew))\r\ngoto out_err;\r\ngctx_new->internal_ctx_id = knew;\r\nCDEBUG(D_SEC, "successfully copied reverse context\n");\r\nreturn GSS_S_COMPLETE;\r\nout_err:\r\ndelete_context_kerberos(knew);\r\nOBD_FREE_PTR(knew);\r\nreturn GSS_S_FAILURE;\r\n}\r\nstatic\r\n__u32 gss_inquire_context_kerberos(struct gss_ctx *gctx,\r\nunsigned long *endtime)\r\n{\r\nstruct krb5_ctx *kctx = gctx->internal_ctx_id;\r\n*endtime = (unsigned long) ((__u32) kctx->kc_endtime);\r\nreturn GSS_S_COMPLETE;\r\n}\r\nstatic\r\nvoid gss_delete_sec_context_kerberos(void *internal_ctx)\r\n{\r\nstruct krb5_ctx *kctx = internal_ctx;\r\ndelete_context_kerberos(kctx);\r\nOBD_FREE_PTR(kctx);\r\n}\r\nstatic\r\nvoid buf_to_sg(struct scatterlist *sg, void *ptr, int len)\r\n{\r\nsg_set_buf(sg, ptr, len);\r\n}\r\nstatic\r\n__u32 krb5_encrypt(struct crypto_blkcipher *tfm,\r\nint decrypt,\r\nvoid * iv,\r\nvoid * in,\r\nvoid * out,\r\nint length)\r\n{\r\nstruct blkcipher_desc desc;\r\nstruct scatterlist sg;\r\n__u8 local_iv[16] = {0};\r\n__u32 ret = -EINVAL;\r\nLASSERT(tfm);\r\ndesc.tfm = tfm;\r\ndesc.info = local_iv;\r\ndesc.flags= 0;\r\nif (length % crypto_blkcipher_blocksize(tfm) != 0) {\r\nCERROR("output length %d mismatch blocksize %d\n",\r\nlength, crypto_blkcipher_blocksize(tfm));\r\ngoto out;\r\n}\r\nif (crypto_blkcipher_ivsize(tfm) > 16) {\r\nCERROR("iv size too large %d\n", crypto_blkcipher_ivsize(tfm));\r\ngoto out;\r\n}\r\nif (iv)\r\nmemcpy(local_iv, iv, crypto_blkcipher_ivsize(tfm));\r\nmemcpy(out, in, length);\r\nbuf_to_sg(&sg, out, length);\r\nif (decrypt)\r\nret = crypto_blkcipher_decrypt_iv(&desc, &sg, &sg, length);\r\nelse\r\nret = crypto_blkcipher_encrypt_iv(&desc, &sg, &sg, length);\r\nout:\r\nreturn(ret);\r\n}\r\nstatic inline\r\nint krb5_digest_hmac(struct crypto_hash *tfm,\r\nrawobj_t *key,\r\nstruct krb5_header *khdr,\r\nint msgcnt, rawobj_t *msgs,\r\nint iovcnt, lnet_kiov_t *iovs,\r\nrawobj_t *cksum)\r\n{\r\nstruct hash_desc desc;\r\nstruct scatterlist sg[1];\r\nint i;\r\ncrypto_hash_setkey(tfm, key->data, key->len);\r\ndesc.tfm = tfm;\r\ndesc.flags= 0;\r\ncrypto_hash_init(&desc);\r\nfor (i = 0; i < msgcnt; i++) {\r\nif (msgs[i].len == 0)\r\ncontinue;\r\nbuf_to_sg(sg, (char *) msgs[i].data, msgs[i].len);\r\ncrypto_hash_update(&desc, sg, msgs[i].len);\r\n}\r\nfor (i = 0; i < iovcnt; i++) {\r\nif (iovs[i].kiov_len == 0)\r\ncontinue;\r\nsg_set_page(&sg[0], iovs[i].kiov_page, iovs[i].kiov_len,\r\niovs[i].kiov_offset);\r\ncrypto_hash_update(&desc, sg, iovs[i].kiov_len);\r\n}\r\nif (khdr) {\r\nbuf_to_sg(sg, (char *) khdr, sizeof(*khdr));\r\ncrypto_hash_update(&desc, sg, sizeof(*khdr));\r\n}\r\nreturn crypto_hash_final(&desc, cksum->data);\r\n}\r\nstatic inline\r\nint krb5_digest_norm(struct crypto_hash *tfm,\r\nstruct krb5_keyblock *kb,\r\nstruct krb5_header *khdr,\r\nint msgcnt, rawobj_t *msgs,\r\nint iovcnt, lnet_kiov_t *iovs,\r\nrawobj_t *cksum)\r\n{\r\nstruct hash_desc desc;\r\nstruct scatterlist sg[1];\r\nint i;\r\nLASSERT(kb->kb_tfm);\r\ndesc.tfm = tfm;\r\ndesc.flags= 0;\r\ncrypto_hash_init(&desc);\r\nfor (i = 0; i < msgcnt; i++) {\r\nif (msgs[i].len == 0)\r\ncontinue;\r\nbuf_to_sg(sg, (char *) msgs[i].data, msgs[i].len);\r\ncrypto_hash_update(&desc, sg, msgs[i].len);\r\n}\r\nfor (i = 0; i < iovcnt; i++) {\r\nif (iovs[i].kiov_len == 0)\r\ncontinue;\r\nsg_set_page(&sg[0], iovs[i].kiov_page, iovs[i].kiov_len,\r\niovs[i].kiov_offset);\r\ncrypto_hash_update(&desc, sg, iovs[i].kiov_len);\r\n}\r\nif (khdr) {\r\nbuf_to_sg(sg, (char *) khdr, sizeof(*khdr));\r\ncrypto_hash_update(&desc, sg, sizeof(*khdr));\r\n}\r\ncrypto_hash_final(&desc, cksum->data);\r\nreturn krb5_encrypt(kb->kb_tfm, 0, NULL, cksum->data,\r\ncksum->data, cksum->len);\r\n}\r\nstatic\r\n__s32 krb5_make_checksum(__u32 enctype,\r\nstruct krb5_keyblock *kb,\r\nstruct krb5_header *khdr,\r\nint msgcnt, rawobj_t *msgs,\r\nint iovcnt, lnet_kiov_t *iovs,\r\nrawobj_t *cksum)\r\n{\r\nstruct krb5_enctype *ke = &enctypes[enctype];\r\nstruct crypto_hash *tfm;\r\n__u32 code = GSS_S_FAILURE;\r\nint rc;\r\ntfm = ll_crypto_alloc_hash(ke->ke_hash_name, 0, 0);\r\nif (!tfm) {\r\nCERROR("failed to alloc TFM: %s\n", ke->ke_hash_name);\r\nreturn GSS_S_FAILURE;\r\n}\r\ncksum->len = crypto_hash_digestsize(tfm);\r\nOBD_ALLOC_LARGE(cksum->data, cksum->len);\r\nif (!cksum->data) {\r\ncksum->len = 0;\r\ngoto out_tfm;\r\n}\r\nif (ke->ke_hash_hmac)\r\nrc = krb5_digest_hmac(tfm, &kb->kb_key,\r\nkhdr, msgcnt, msgs, iovcnt, iovs, cksum);\r\nelse\r\nrc = krb5_digest_norm(tfm, kb,\r\nkhdr, msgcnt, msgs, iovcnt, iovs, cksum);\r\nif (rc == 0)\r\ncode = GSS_S_COMPLETE;\r\nout_tfm:\r\ncrypto_free_hash(tfm);\r\nreturn code;\r\n}\r\nstatic void fill_krb5_header(struct krb5_ctx *kctx,\r\nstruct krb5_header *khdr,\r\nint privacy)\r\n{\r\nunsigned char acceptor_flag;\r\nacceptor_flag = kctx->kc_initiate ? 0 : FLAG_SENDER_IS_ACCEPTOR;\r\nif (privacy) {\r\nkhdr->kh_tok_id = cpu_to_be16(KG_TOK_WRAP_MSG);\r\nkhdr->kh_flags = acceptor_flag | FLAG_WRAP_CONFIDENTIAL;\r\nkhdr->kh_ec = cpu_to_be16(0);\r\nkhdr->kh_rrc = cpu_to_be16(0);\r\n} else {\r\nkhdr->kh_tok_id = cpu_to_be16(KG_TOK_MIC_MSG);\r\nkhdr->kh_flags = acceptor_flag;\r\nkhdr->kh_ec = cpu_to_be16(0xffff);\r\nkhdr->kh_rrc = cpu_to_be16(0xffff);\r\n}\r\nkhdr->kh_filler = 0xff;\r\nspin_lock(&krb5_seq_lock);\r\nkhdr->kh_seq = cpu_to_be64(kctx->kc_seq_send++);\r\nspin_unlock(&krb5_seq_lock);\r\n}\r\nstatic __u32 verify_krb5_header(struct krb5_ctx *kctx,\r\nstruct krb5_header *khdr,\r\nint privacy)\r\n{\r\nunsigned char acceptor_flag;\r\n__u16 tok_id, ec_rrc;\r\nacceptor_flag = kctx->kc_initiate ? FLAG_SENDER_IS_ACCEPTOR : 0;\r\nif (privacy) {\r\ntok_id = KG_TOK_WRAP_MSG;\r\nec_rrc = 0x0;\r\n} else {\r\ntok_id = KG_TOK_MIC_MSG;\r\nec_rrc = 0xffff;\r\n}\r\nif (be16_to_cpu(khdr->kh_tok_id) != tok_id) {\r\nCERROR("bad token id\n");\r\nreturn GSS_S_DEFECTIVE_TOKEN;\r\n}\r\nif ((khdr->kh_flags & FLAG_SENDER_IS_ACCEPTOR) != acceptor_flag) {\r\nCERROR("bad direction flag\n");\r\nreturn GSS_S_BAD_SIG;\r\n}\r\nif (privacy && (khdr->kh_flags & FLAG_WRAP_CONFIDENTIAL) == 0) {\r\nCERROR("missing confidential flag\n");\r\nreturn GSS_S_BAD_SIG;\r\n}\r\nif (khdr->kh_filler != 0xff) {\r\nCERROR("bad filler\n");\r\nreturn GSS_S_DEFECTIVE_TOKEN;\r\n}\r\nif (be16_to_cpu(khdr->kh_ec) != ec_rrc ||\r\nbe16_to_cpu(khdr->kh_rrc) != ec_rrc) {\r\nCERROR("bad EC or RRC\n");\r\nreturn GSS_S_DEFECTIVE_TOKEN;\r\n}\r\nreturn GSS_S_COMPLETE;\r\n}\r\nstatic\r\n__u32 gss_get_mic_kerberos(struct gss_ctx *gctx,\r\nint msgcnt,\r\nrawobj_t *msgs,\r\nint iovcnt,\r\nlnet_kiov_t *iovs,\r\nrawobj_t *token)\r\n{\r\nstruct krb5_ctx *kctx = gctx->internal_ctx_id;\r\nstruct krb5_enctype *ke = &enctypes[kctx->kc_enctype];\r\nstruct krb5_header *khdr;\r\nrawobj_t cksum = RAWOBJ_EMPTY;\r\nLASSERT(token->len >= sizeof(*khdr));\r\nkhdr = (struct krb5_header *) token->data;\r\nfill_krb5_header(kctx, khdr, 0);\r\nif (krb5_make_checksum(kctx->kc_enctype, &kctx->kc_keyc,\r\nkhdr, msgcnt, msgs, iovcnt, iovs, &cksum))\r\nreturn GSS_S_FAILURE;\r\nLASSERT(cksum.len >= ke->ke_hash_size);\r\nLASSERT(token->len >= sizeof(*khdr) + ke->ke_hash_size);\r\nmemcpy(khdr + 1, cksum.data + cksum.len - ke->ke_hash_size,\r\nke->ke_hash_size);\r\ntoken->len = sizeof(*khdr) + ke->ke_hash_size;\r\nrawobj_free(&cksum);\r\nreturn GSS_S_COMPLETE;\r\n}\r\nstatic\r\n__u32 gss_verify_mic_kerberos(struct gss_ctx *gctx,\r\nint msgcnt,\r\nrawobj_t *msgs,\r\nint iovcnt,\r\nlnet_kiov_t *iovs,\r\nrawobj_t *token)\r\n{\r\nstruct krb5_ctx *kctx = gctx->internal_ctx_id;\r\nstruct krb5_enctype *ke = &enctypes[kctx->kc_enctype];\r\nstruct krb5_header *khdr;\r\nrawobj_t cksum = RAWOBJ_EMPTY;\r\n__u32 major;\r\nif (token->len < sizeof(*khdr)) {\r\nCERROR("short signature: %u\n", token->len);\r\nreturn GSS_S_DEFECTIVE_TOKEN;\r\n}\r\nkhdr = (struct krb5_header *) token->data;\r\nmajor = verify_krb5_header(kctx, khdr, 0);\r\nif (major != GSS_S_COMPLETE) {\r\nCERROR("bad krb5 header\n");\r\nreturn major;\r\n}\r\nif (token->len < sizeof(*khdr) + ke->ke_hash_size) {\r\nCERROR("short signature: %u, require %d\n",\r\ntoken->len, (int) sizeof(*khdr) + ke->ke_hash_size);\r\nreturn GSS_S_FAILURE;\r\n}\r\nif (krb5_make_checksum(kctx->kc_enctype, &kctx->kc_keyc,\r\nkhdr, msgcnt, msgs, iovcnt, iovs, &cksum)) {\r\nCERROR("failed to make checksum\n");\r\nreturn GSS_S_FAILURE;\r\n}\r\nLASSERT(cksum.len >= ke->ke_hash_size);\r\nif (memcmp(khdr + 1, cksum.data + cksum.len - ke->ke_hash_size,\r\nke->ke_hash_size)) {\r\nCERROR("checksum mismatch\n");\r\nrawobj_free(&cksum);\r\nreturn GSS_S_BAD_SIG;\r\n}\r\nrawobj_free(&cksum);\r\nreturn GSS_S_COMPLETE;\r\n}\r\nstatic\r\nint add_padding(rawobj_t *msg, int msg_buflen, int blocksize)\r\n{\r\nint padding;\r\npadding = (blocksize - (msg->len & (blocksize - 1))) &\r\n(blocksize - 1);\r\nif (!padding)\r\nreturn 0;\r\nif (msg->len + padding > msg_buflen) {\r\nCERROR("bufsize %u too small: datalen %u, padding %u\n",\r\nmsg_buflen, msg->len, padding);\r\nreturn -EINVAL;\r\n}\r\nmemset(msg->data + msg->len, padding, padding);\r\nmsg->len += padding;\r\nreturn 0;\r\n}\r\nstatic\r\nint krb5_encrypt_rawobjs(struct crypto_blkcipher *tfm,\r\nint mode_ecb,\r\nint inobj_cnt,\r\nrawobj_t *inobjs,\r\nrawobj_t *outobj,\r\nint enc)\r\n{\r\nstruct blkcipher_desc desc;\r\nstruct scatterlist src, dst;\r\n__u8 local_iv[16] = {0}, *buf;\r\n__u32 datalen = 0;\r\nint i, rc;\r\nbuf = outobj->data;\r\ndesc.tfm = tfm;\r\ndesc.info = local_iv;\r\ndesc.flags = 0;\r\nfor (i = 0; i < inobj_cnt; i++) {\r\nLASSERT(buf + inobjs[i].len <= outobj->data + outobj->len);\r\nbuf_to_sg(&src, inobjs[i].data, inobjs[i].len);\r\nbuf_to_sg(&dst, buf, outobj->len - datalen);\r\nif (mode_ecb) {\r\nif (enc)\r\nrc = crypto_blkcipher_encrypt(\r\n&desc, &dst, &src, src.length);\r\nelse\r\nrc = crypto_blkcipher_decrypt(\r\n&desc, &dst, &src, src.length);\r\n} else {\r\nif (enc)\r\nrc = crypto_blkcipher_encrypt_iv(\r\n&desc, &dst, &src, src.length);\r\nelse\r\nrc = crypto_blkcipher_decrypt_iv(\r\n&desc, &dst, &src, src.length);\r\n}\r\nif (rc) {\r\nCERROR("encrypt error %d\n", rc);\r\nreturn rc;\r\n}\r\ndatalen += inobjs[i].len;\r\nbuf += inobjs[i].len;\r\n}\r\noutobj->len = datalen;\r\nreturn 0;\r\n}\r\nstatic\r\nint krb5_encrypt_bulk(struct crypto_blkcipher *tfm,\r\nstruct krb5_header *khdr,\r\nchar *confounder,\r\nstruct ptlrpc_bulk_desc *desc,\r\nrawobj_t *cipher,\r\nint adj_nob)\r\n{\r\nstruct blkcipher_desc ciph_desc;\r\n__u8 local_iv[16] = {0};\r\nstruct scatterlist src, dst;\r\nint blocksize, i, rc, nob = 0;\r\nLASSERT(desc->bd_iov_count);\r\nLASSERT(desc->bd_enc_iov);\r\nblocksize = crypto_blkcipher_blocksize(tfm);\r\nLASSERT(blocksize > 1);\r\nLASSERT(cipher->len == blocksize + sizeof(*khdr));\r\nciph_desc.tfm = tfm;\r\nciph_desc.info = local_iv;\r\nciph_desc.flags = 0;\r\nbuf_to_sg(&src, confounder, blocksize);\r\nbuf_to_sg(&dst, cipher->data, blocksize);\r\nrc = crypto_blkcipher_encrypt_iv(&ciph_desc, &dst, &src, blocksize);\r\nif (rc) {\r\nCERROR("error to encrypt confounder: %d\n", rc);\r\nreturn rc;\r\n}\r\nfor (i = 0; i < desc->bd_iov_count; i++) {\r\nsg_set_page(&src, desc->bd_iov[i].kiov_page,\r\n(desc->bd_iov[i].kiov_len + blocksize - 1) &\r\n(~(blocksize - 1)),\r\ndesc->bd_iov[i].kiov_offset);\r\nif (adj_nob)\r\nnob += src.length;\r\nsg_set_page(&dst, desc->bd_enc_iov[i].kiov_page, src.length,\r\nsrc.offset);\r\ndesc->bd_enc_iov[i].kiov_offset = dst.offset;\r\ndesc->bd_enc_iov[i].kiov_len = dst.length;\r\nrc = crypto_blkcipher_encrypt_iv(&ciph_desc, &dst, &src,\r\nsrc.length);\r\nif (rc) {\r\nCERROR("error to encrypt page: %d\n", rc);\r\nreturn rc;\r\n}\r\n}\r\nbuf_to_sg(&src, khdr, sizeof(*khdr));\r\nbuf_to_sg(&dst, cipher->data + blocksize, sizeof(*khdr));\r\nrc = crypto_blkcipher_encrypt_iv(&ciph_desc,\r\n&dst, &src, sizeof(*khdr));\r\nif (rc) {\r\nCERROR("error to encrypt krb5 header: %d\n", rc);\r\nreturn rc;\r\n}\r\nif (adj_nob)\r\ndesc->bd_nob = nob;\r\nreturn 0;\r\n}\r\nstatic\r\nint krb5_decrypt_bulk(struct crypto_blkcipher *tfm,\r\nstruct krb5_header *khdr,\r\nstruct ptlrpc_bulk_desc *desc,\r\nrawobj_t *cipher,\r\nrawobj_t *plain,\r\nint adj_nob)\r\n{\r\nstruct blkcipher_desc ciph_desc;\r\n__u8 local_iv[16] = {0};\r\nstruct scatterlist src, dst;\r\nint ct_nob = 0, pt_nob = 0;\r\nint blocksize, i, rc;\r\nLASSERT(desc->bd_iov_count);\r\nLASSERT(desc->bd_enc_iov);\r\nLASSERT(desc->bd_nob_transferred);\r\nblocksize = crypto_blkcipher_blocksize(tfm);\r\nLASSERT(blocksize > 1);\r\nLASSERT(cipher->len == blocksize + sizeof(*khdr));\r\nciph_desc.tfm = tfm;\r\nciph_desc.info = local_iv;\r\nciph_desc.flags = 0;\r\nif (desc->bd_nob_transferred % blocksize) {\r\nCERROR("odd transferred nob: %d\n", desc->bd_nob_transferred);\r\nreturn -EPROTO;\r\n}\r\nbuf_to_sg(&src, cipher->data, blocksize);\r\nbuf_to_sg(&dst, plain->data, blocksize);\r\nrc = crypto_blkcipher_decrypt_iv(&ciph_desc, &dst, &src, blocksize);\r\nif (rc) {\r\nCERROR("error to decrypt confounder: %d\n", rc);\r\nreturn rc;\r\n}\r\nfor (i = 0; i < desc->bd_iov_count && ct_nob < desc->bd_nob_transferred;\r\ni++) {\r\nif (desc->bd_enc_iov[i].kiov_offset % blocksize != 0 ||\r\ndesc->bd_enc_iov[i].kiov_len % blocksize != 0) {\r\nCERROR("page %d: odd offset %u len %u, blocksize %d\n",\r\ni, desc->bd_enc_iov[i].kiov_offset,\r\ndesc->bd_enc_iov[i].kiov_len, blocksize);\r\nreturn -EFAULT;\r\n}\r\nif (adj_nob) {\r\nif (ct_nob + desc->bd_enc_iov[i].kiov_len >\r\ndesc->bd_nob_transferred)\r\ndesc->bd_enc_iov[i].kiov_len =\r\ndesc->bd_nob_transferred - ct_nob;\r\ndesc->bd_iov[i].kiov_len = desc->bd_enc_iov[i].kiov_len;\r\nif (pt_nob + desc->bd_enc_iov[i].kiov_len >desc->bd_nob)\r\ndesc->bd_iov[i].kiov_len = desc->bd_nob -pt_nob;\r\n} else {\r\nLASSERT(ct_nob + desc->bd_enc_iov[i].kiov_len <=\r\ndesc->bd_nob_transferred);\r\nLASSERT(desc->bd_iov[i].kiov_len <=\r\ndesc->bd_enc_iov[i].kiov_len);\r\n}\r\nif (desc->bd_enc_iov[i].kiov_len == 0)\r\ncontinue;\r\nsg_set_page(&src, desc->bd_enc_iov[i].kiov_page,\r\ndesc->bd_enc_iov[i].kiov_len,\r\ndesc->bd_enc_iov[i].kiov_offset);\r\ndst = src;\r\nif (desc->bd_iov[i].kiov_len % blocksize == 0)\r\nsg_assign_page(&dst, desc->bd_iov[i].kiov_page);\r\nrc = crypto_blkcipher_decrypt_iv(&ciph_desc, &dst, &src,\r\nsrc.length);\r\nif (rc) {\r\nCERROR("error to decrypt page: %d\n", rc);\r\nreturn rc;\r\n}\r\nif (desc->bd_iov[i].kiov_len % blocksize != 0) {\r\nmemcpy(page_address(desc->bd_iov[i].kiov_page) +\r\ndesc->bd_iov[i].kiov_offset,\r\npage_address(desc->bd_enc_iov[i].kiov_page) +\r\ndesc->bd_iov[i].kiov_offset,\r\ndesc->bd_iov[i].kiov_len);\r\n}\r\nct_nob += desc->bd_enc_iov[i].kiov_len;\r\npt_nob += desc->bd_iov[i].kiov_len;\r\n}\r\nif (unlikely(ct_nob != desc->bd_nob_transferred)) {\r\nCERROR("%d cipher text transferred but only %d decrypted\n",\r\ndesc->bd_nob_transferred, ct_nob);\r\nreturn -EFAULT;\r\n}\r\nif (unlikely(!adj_nob && pt_nob != desc->bd_nob)) {\r\nCERROR("%d plain text expected but only %d received\n",\r\ndesc->bd_nob, pt_nob);\r\nreturn -EFAULT;\r\n}\r\nif (adj_nob)\r\nwhile (i < desc->bd_iov_count)\r\ndesc->bd_iov[i++].kiov_len = 0;\r\nbuf_to_sg(&src, cipher->data + blocksize, sizeof(*khdr));\r\nbuf_to_sg(&dst, cipher->data + blocksize, sizeof(*khdr));\r\nrc = crypto_blkcipher_decrypt_iv(&ciph_desc,\r\n&dst, &src, sizeof(*khdr));\r\nif (rc) {\r\nCERROR("error to decrypt tail: %d\n", rc);\r\nreturn rc;\r\n}\r\nif (memcmp(cipher->data + blocksize, khdr, sizeof(*khdr))) {\r\nCERROR("krb5 header doesn't match\n");\r\nreturn -EACCES;\r\n}\r\nreturn 0;\r\n}\r\nstatic\r\n__u32 gss_wrap_kerberos(struct gss_ctx *gctx,\r\nrawobj_t *gsshdr,\r\nrawobj_t *msg,\r\nint msg_buflen,\r\nrawobj_t *token)\r\n{\r\nstruct krb5_ctx *kctx = gctx->internal_ctx_id;\r\nstruct krb5_enctype *ke = &enctypes[kctx->kc_enctype];\r\nstruct krb5_header *khdr;\r\nint blocksize;\r\nrawobj_t cksum = RAWOBJ_EMPTY;\r\nrawobj_t data_desc[3], cipher;\r\n__u8 conf[GSS_MAX_CIPHER_BLOCK];\r\nint rc = 0;\r\nLASSERT(ke);\r\nLASSERT(ke->ke_conf_size <= GSS_MAX_CIPHER_BLOCK);\r\nLASSERT(kctx->kc_keye.kb_tfm == NULL ||\r\nke->ke_conf_size >=\r\ncrypto_blkcipher_blocksize(kctx->kc_keye.kb_tfm));\r\nLASSERT(token->len >= sizeof(*khdr));\r\nkhdr = (struct krb5_header *) token->data;\r\nfill_krb5_header(kctx, khdr, 1);\r\ncfs_get_random_bytes(conf, ke->ke_conf_size);\r\nif (kctx->kc_enctype == ENCTYPE_ARCFOUR_HMAC) {\r\nLASSERT(kctx->kc_keye.kb_tfm == NULL);\r\nblocksize = 1;\r\n} else {\r\nLASSERT(kctx->kc_keye.kb_tfm);\r\nblocksize = crypto_blkcipher_blocksize(kctx->kc_keye.kb_tfm);\r\n}\r\nLASSERT(blocksize <= ke->ke_conf_size);\r\nif (add_padding(msg, msg_buflen, blocksize))\r\nreturn GSS_S_FAILURE;\r\ndata_desc[0].data = conf;\r\ndata_desc[0].len = ke->ke_conf_size;\r\ndata_desc[1].data = gsshdr->data;\r\ndata_desc[1].len = gsshdr->len;\r\ndata_desc[2].data = msg->data;\r\ndata_desc[2].len = msg->len;\r\nif (krb5_make_checksum(kctx->kc_enctype, &kctx->kc_keyi,\r\nkhdr, 3, data_desc, 0, NULL, &cksum))\r\nreturn GSS_S_FAILURE;\r\nLASSERT(cksum.len >= ke->ke_hash_size);\r\ndata_desc[0].data = conf;\r\ndata_desc[0].len = ke->ke_conf_size;\r\ndata_desc[1].data = msg->data;\r\ndata_desc[1].len = msg->len;\r\ndata_desc[2].data = (__u8 *) khdr;\r\ndata_desc[2].len = sizeof(*khdr);\r\ncipher.data = (__u8 *) (khdr + 1);\r\ncipher.len = token->len - sizeof(*khdr);\r\nLASSERT(cipher.len >= ke->ke_conf_size + msg->len + sizeof(*khdr));\r\nif (kctx->kc_enctype == ENCTYPE_ARCFOUR_HMAC) {\r\nrawobj_t arc4_keye;\r\nstruct crypto_blkcipher *arc4_tfm;\r\nif (krb5_make_checksum(ENCTYPE_ARCFOUR_HMAC, &kctx->kc_keyi,\r\nNULL, 1, &cksum, 0, NULL, &arc4_keye)) {\r\nCERROR("failed to obtain arc4 enc key\n");\r\nGOTO(arc4_out, rc = -EACCES);\r\n}\r\narc4_tfm = crypto_alloc_blkcipher("ecb(arc4)", 0, 0);\r\nif (IS_ERR(arc4_tfm)) {\r\nCERROR("failed to alloc tfm arc4 in ECB mode\n");\r\nGOTO(arc4_out_key, rc = -EACCES);\r\n}\r\nif (crypto_blkcipher_setkey(arc4_tfm, arc4_keye.data,\r\narc4_keye.len)) {\r\nCERROR("failed to set arc4 key, len %d\n",\r\narc4_keye.len);\r\nGOTO(arc4_out_tfm, rc = -EACCES);\r\n}\r\nrc = krb5_encrypt_rawobjs(arc4_tfm, 1,\r\n3, data_desc, &cipher, 1);\r\narc4_out_tfm:\r\ncrypto_free_blkcipher(arc4_tfm);\r\narc4_out_key:\r\nrawobj_free(&arc4_keye);\r\narc4_out:\r\ndo {} while (0);\r\n} else {\r\nrc = krb5_encrypt_rawobjs(kctx->kc_keye.kb_tfm, 0,\r\n3, data_desc, &cipher, 1);\r\n}\r\nif (rc != 0) {\r\nrawobj_free(&cksum);\r\nreturn GSS_S_FAILURE;\r\n}\r\nLASSERT(token->len >= sizeof(*khdr) + cipher.len + ke->ke_hash_size);\r\nmemcpy((char *)(khdr + 1) + cipher.len,\r\ncksum.data + cksum.len - ke->ke_hash_size,\r\nke->ke_hash_size);\r\nrawobj_free(&cksum);\r\ntoken->len = sizeof(*khdr) + cipher.len + ke->ke_hash_size;\r\nreturn GSS_S_COMPLETE;\r\n}\r\nstatic\r\n__u32 gss_prep_bulk_kerberos(struct gss_ctx *gctx,\r\nstruct ptlrpc_bulk_desc *desc)\r\n{\r\nstruct krb5_ctx *kctx = gctx->internal_ctx_id;\r\nint blocksize, i;\r\nLASSERT(desc->bd_iov_count);\r\nLASSERT(desc->bd_enc_iov);\r\nLASSERT(kctx->kc_keye.kb_tfm);\r\nblocksize = crypto_blkcipher_blocksize(kctx->kc_keye.kb_tfm);\r\nfor (i = 0; i < desc->bd_iov_count; i++) {\r\nLASSERT(desc->bd_enc_iov[i].kiov_page);\r\nif (desc->bd_iov[i].kiov_offset & blocksize) {\r\nCERROR("odd offset %d in page %d\n",\r\ndesc->bd_iov[i].kiov_offset, i);\r\nreturn GSS_S_FAILURE;\r\n}\r\ndesc->bd_enc_iov[i].kiov_offset = desc->bd_iov[i].kiov_offset;\r\ndesc->bd_enc_iov[i].kiov_len = (desc->bd_iov[i].kiov_len +\r\nblocksize - 1) & (~(blocksize - 1));\r\n}\r\nreturn GSS_S_COMPLETE;\r\n}\r\nstatic\r\n__u32 gss_wrap_bulk_kerberos(struct gss_ctx *gctx,\r\nstruct ptlrpc_bulk_desc *desc,\r\nrawobj_t *token, int adj_nob)\r\n{\r\nstruct krb5_ctx *kctx = gctx->internal_ctx_id;\r\nstruct krb5_enctype *ke = &enctypes[kctx->kc_enctype];\r\nstruct krb5_header *khdr;\r\nint blocksize;\r\nrawobj_t cksum = RAWOBJ_EMPTY;\r\nrawobj_t data_desc[1], cipher;\r\n__u8 conf[GSS_MAX_CIPHER_BLOCK];\r\nint rc = 0;\r\nLASSERT(ke);\r\nLASSERT(ke->ke_conf_size <= GSS_MAX_CIPHER_BLOCK);\r\nLASSERT(token->len >= sizeof(*khdr));\r\nkhdr = (struct krb5_header *) token->data;\r\nfill_krb5_header(kctx, khdr, 1);\r\ncfs_get_random_bytes(conf, ke->ke_conf_size);\r\nif (kctx->kc_enctype == ENCTYPE_ARCFOUR_HMAC) {\r\nLASSERT(kctx->kc_keye.kb_tfm == NULL);\r\nblocksize = 1;\r\n} else {\r\nLASSERT(kctx->kc_keye.kb_tfm);\r\nblocksize = crypto_blkcipher_blocksize(kctx->kc_keye.kb_tfm);\r\n}\r\nLASSERT(blocksize <= ke->ke_conf_size);\r\nLASSERT(sizeof(*khdr) >= blocksize && sizeof(*khdr) % blocksize == 0);\r\nLASSERT(token->len >= sizeof(*khdr) + blocksize + sizeof(*khdr) + 16);\r\ndata_desc[0].data = conf;\r\ndata_desc[0].len = ke->ke_conf_size;\r\nif (krb5_make_checksum(kctx->kc_enctype, &kctx->kc_keyi,\r\nkhdr, 1, data_desc,\r\ndesc->bd_iov_count, desc->bd_iov,\r\n&cksum))\r\nreturn GSS_S_FAILURE;\r\nLASSERT(cksum.len >= ke->ke_hash_size);\r\ndata_desc[0].data = conf;\r\ndata_desc[0].len = ke->ke_conf_size;\r\ncipher.data = (__u8 *) (khdr + 1);\r\ncipher.len = blocksize + sizeof(*khdr);\r\nif (kctx->kc_enctype == ENCTYPE_ARCFOUR_HMAC) {\r\nLBUG();\r\nrc = 0;\r\n} else {\r\nrc = krb5_encrypt_bulk(kctx->kc_keye.kb_tfm, khdr,\r\nconf, desc, &cipher, adj_nob);\r\n}\r\nif (rc != 0) {\r\nrawobj_free(&cksum);\r\nreturn GSS_S_FAILURE;\r\n}\r\nLASSERT(token->len >= sizeof(*khdr) + cipher.len + ke->ke_hash_size);\r\nmemcpy((char *)(khdr + 1) + cipher.len,\r\ncksum.data + cksum.len - ke->ke_hash_size,\r\nke->ke_hash_size);\r\nrawobj_free(&cksum);\r\ntoken->len = sizeof(*khdr) + cipher.len + ke->ke_hash_size;\r\nreturn GSS_S_COMPLETE;\r\n}\r\nstatic\r\n__u32 gss_unwrap_kerberos(struct gss_ctx *gctx,\r\nrawobj_t *gsshdr,\r\nrawobj_t *token,\r\nrawobj_t *msg)\r\n{\r\nstruct krb5_ctx *kctx = gctx->internal_ctx_id;\r\nstruct krb5_enctype *ke = &enctypes[kctx->kc_enctype];\r\nstruct krb5_header *khdr;\r\nunsigned char *tmpbuf;\r\nint blocksize, bodysize;\r\nrawobj_t cksum = RAWOBJ_EMPTY;\r\nrawobj_t cipher_in, plain_out;\r\nrawobj_t hash_objs[3];\r\nint rc = 0;\r\n__u32 major;\r\nLASSERT(ke);\r\nif (token->len < sizeof(*khdr)) {\r\nCERROR("short signature: %u\n", token->len);\r\nreturn GSS_S_DEFECTIVE_TOKEN;\r\n}\r\nkhdr = (struct krb5_header *) token->data;\r\nmajor = verify_krb5_header(kctx, khdr, 1);\r\nif (major != GSS_S_COMPLETE) {\r\nCERROR("bad krb5 header\n");\r\nreturn major;\r\n}\r\nif (kctx->kc_enctype == ENCTYPE_ARCFOUR_HMAC) {\r\nLASSERT(kctx->kc_keye.kb_tfm == NULL);\r\nblocksize = 1;\r\n} else {\r\nLASSERT(kctx->kc_keye.kb_tfm);\r\nblocksize = crypto_blkcipher_blocksize(kctx->kc_keye.kb_tfm);\r\n}\r\nbodysize = token->len - sizeof(*khdr) - ke->ke_hash_size;\r\nif (bodysize % blocksize) {\r\nCERROR("odd bodysize %d\n", bodysize);\r\nreturn GSS_S_DEFECTIVE_TOKEN;\r\n}\r\nif (bodysize <= ke->ke_conf_size + sizeof(*khdr)) {\r\nCERROR("incomplete token: bodysize %d\n", bodysize);\r\nreturn GSS_S_DEFECTIVE_TOKEN;\r\n}\r\nif (msg->len < bodysize - ke->ke_conf_size - sizeof(*khdr)) {\r\nCERROR("buffer too small: %u, require %d\n",\r\nmsg->len, bodysize - ke->ke_conf_size);\r\nreturn GSS_S_FAILURE;\r\n}\r\nOBD_ALLOC_LARGE(tmpbuf, bodysize);\r\nif (!tmpbuf)\r\nreturn GSS_S_FAILURE;\r\nmajor = GSS_S_FAILURE;\r\ncipher_in.data = (__u8 *) (khdr + 1);\r\ncipher_in.len = bodysize;\r\nplain_out.data = tmpbuf;\r\nplain_out.len = bodysize;\r\nif (kctx->kc_enctype == ENCTYPE_ARCFOUR_HMAC) {\r\nrawobj_t arc4_keye;\r\nstruct crypto_blkcipher *arc4_tfm;\r\ncksum.data = token->data + token->len - ke->ke_hash_size;\r\ncksum.len = ke->ke_hash_size;\r\nif (krb5_make_checksum(ENCTYPE_ARCFOUR_HMAC, &kctx->kc_keyi,\r\nNULL, 1, &cksum, 0, NULL, &arc4_keye)) {\r\nCERROR("failed to obtain arc4 enc key\n");\r\nGOTO(arc4_out, rc = -EACCES);\r\n}\r\narc4_tfm = crypto_alloc_blkcipher("ecb(arc4)", 0, 0);\r\nif (IS_ERR(arc4_tfm)) {\r\nCERROR("failed to alloc tfm arc4 in ECB mode\n");\r\nGOTO(arc4_out_key, rc = -EACCES);\r\n}\r\nif (crypto_blkcipher_setkey(arc4_tfm,\r\narc4_keye.data, arc4_keye.len)) {\r\nCERROR("failed to set arc4 key, len %d\n",\r\narc4_keye.len);\r\nGOTO(arc4_out_tfm, rc = -EACCES);\r\n}\r\nrc = krb5_encrypt_rawobjs(arc4_tfm, 1,\r\n1, &cipher_in, &plain_out, 0);\r\narc4_out_tfm:\r\ncrypto_free_blkcipher(arc4_tfm);\r\narc4_out_key:\r\nrawobj_free(&arc4_keye);\r\narc4_out:\r\ncksum = RAWOBJ_EMPTY;\r\n} else {\r\nrc = krb5_encrypt_rawobjs(kctx->kc_keye.kb_tfm, 0,\r\n1, &cipher_in, &plain_out, 0);\r\n}\r\nif (rc != 0) {\r\nCERROR("error decrypt\n");\r\ngoto out_free;\r\n}\r\nLASSERT(plain_out.len == bodysize);\r\nif (memcmp(khdr, plain_out.data + plain_out.len - sizeof(*khdr),\r\nsizeof(*khdr))) {\r\nCERROR("decrypted krb5 header mismatch\n");\r\ngoto out_free;\r\n}\r\nhash_objs[0].len = ke->ke_conf_size;\r\nhash_objs[0].data = plain_out.data;\r\nhash_objs[1].len = gsshdr->len;\r\nhash_objs[1].data = gsshdr->data;\r\nhash_objs[2].len = plain_out.len - ke->ke_conf_size - sizeof(*khdr);\r\nhash_objs[2].data = plain_out.data + ke->ke_conf_size;\r\nif (krb5_make_checksum(kctx->kc_enctype, &kctx->kc_keyi,\r\nkhdr, 3, hash_objs, 0, NULL, &cksum))\r\ngoto out_free;\r\nLASSERT(cksum.len >= ke->ke_hash_size);\r\nif (memcmp((char *)(khdr + 1) + bodysize,\r\ncksum.data + cksum.len - ke->ke_hash_size,\r\nke->ke_hash_size)) {\r\nCERROR("checksum mismatch\n");\r\ngoto out_free;\r\n}\r\nmsg->len = bodysize - ke->ke_conf_size - sizeof(*khdr);\r\nmemcpy(msg->data, tmpbuf + ke->ke_conf_size, msg->len);\r\nmajor = GSS_S_COMPLETE;\r\nout_free:\r\nOBD_FREE_LARGE(tmpbuf, bodysize);\r\nrawobj_free(&cksum);\r\nreturn major;\r\n}\r\nstatic\r\n__u32 gss_unwrap_bulk_kerberos(struct gss_ctx *gctx,\r\nstruct ptlrpc_bulk_desc *desc,\r\nrawobj_t *token, int adj_nob)\r\n{\r\nstruct krb5_ctx *kctx = gctx->internal_ctx_id;\r\nstruct krb5_enctype *ke = &enctypes[kctx->kc_enctype];\r\nstruct krb5_header *khdr;\r\nint blocksize;\r\nrawobj_t cksum = RAWOBJ_EMPTY;\r\nrawobj_t cipher, plain;\r\nrawobj_t data_desc[1];\r\nint rc;\r\n__u32 major;\r\nLASSERT(ke);\r\nif (token->len < sizeof(*khdr)) {\r\nCERROR("short signature: %u\n", token->len);\r\nreturn GSS_S_DEFECTIVE_TOKEN;\r\n}\r\nkhdr = (struct krb5_header *) token->data;\r\nmajor = verify_krb5_header(kctx, khdr, 1);\r\nif (major != GSS_S_COMPLETE) {\r\nCERROR("bad krb5 header\n");\r\nreturn major;\r\n}\r\nif (kctx->kc_enctype == ENCTYPE_ARCFOUR_HMAC) {\r\nLASSERT(kctx->kc_keye.kb_tfm == NULL);\r\nblocksize = 1;\r\nLBUG();\r\n} else {\r\nLASSERT(kctx->kc_keye.kb_tfm);\r\nblocksize = crypto_blkcipher_blocksize(kctx->kc_keye.kb_tfm);\r\n}\r\nLASSERT(sizeof(*khdr) >= blocksize && sizeof(*khdr) % blocksize == 0);\r\nif (token->len < sizeof(*khdr) + blocksize + sizeof(*khdr) +\r\nke->ke_hash_size) {\r\nCERROR("short token size: %u\n", token->len);\r\nreturn GSS_S_DEFECTIVE_TOKEN;\r\n}\r\ncipher.data = (__u8 *) (khdr + 1);\r\ncipher.len = blocksize + sizeof(*khdr);\r\nplain.data = cipher.data;\r\nplain.len = cipher.len;\r\nrc = krb5_decrypt_bulk(kctx->kc_keye.kb_tfm, khdr,\r\ndesc, &cipher, &plain, adj_nob);\r\nif (rc)\r\nreturn GSS_S_DEFECTIVE_TOKEN;\r\ndata_desc[0].data = plain.data;\r\ndata_desc[0].len = blocksize;\r\nif (krb5_make_checksum(kctx->kc_enctype, &kctx->kc_keyi,\r\nkhdr, 1, data_desc,\r\ndesc->bd_iov_count, desc->bd_iov,\r\n&cksum))\r\nreturn GSS_S_FAILURE;\r\nLASSERT(cksum.len >= ke->ke_hash_size);\r\nif (memcmp(plain.data + blocksize + sizeof(*khdr),\r\ncksum.data + cksum.len - ke->ke_hash_size,\r\nke->ke_hash_size)) {\r\nCERROR("checksum mismatch\n");\r\nrawobj_free(&cksum);\r\nreturn GSS_S_BAD_SIG;\r\n}\r\nrawobj_free(&cksum);\r\nreturn GSS_S_COMPLETE;\r\n}\r\nint gss_display_kerberos(struct gss_ctx *ctx,\r\nchar *buf,\r\nint bufsize)\r\n{\r\nstruct krb5_ctx *kctx = ctx->internal_ctx_id;\r\nint written;\r\nwritten = snprintf(buf, bufsize, "krb5 (%s)",\r\nenctype2str(kctx->kc_enctype));\r\nreturn written;\r\n}\r\nint __init init_kerberos_module(void)\r\n{\r\nint status;\r\nspin_lock_init(&krb5_seq_lock);\r\nstatus = lgss_mech_register(&gss_kerberos_mech);\r\nif (status)\r\nCERROR("Failed to register kerberos gss mechanism!\n");\r\nreturn status;\r\n}\r\nvoid __exit cleanup_kerberos_module(void)\r\n{\r\nlgss_mech_unregister(&gss_kerberos_mech);\r\n}
