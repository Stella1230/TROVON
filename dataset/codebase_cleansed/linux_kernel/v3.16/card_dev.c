static int genwqe_open_files(struct genwqe_dev *cd)\r\n{\r\nint rc;\r\nunsigned long flags;\r\nspin_lock_irqsave(&cd->file_lock, flags);\r\nrc = list_empty(&cd->file_list);\r\nspin_unlock_irqrestore(&cd->file_lock, flags);\r\nreturn !rc;\r\n}\r\nstatic void genwqe_add_file(struct genwqe_dev *cd, struct genwqe_file *cfile)\r\n{\r\nunsigned long flags;\r\ncfile->owner = current;\r\nspin_lock_irqsave(&cd->file_lock, flags);\r\nlist_add(&cfile->list, &cd->file_list);\r\nspin_unlock_irqrestore(&cd->file_lock, flags);\r\n}\r\nstatic int genwqe_del_file(struct genwqe_dev *cd, struct genwqe_file *cfile)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&cd->file_lock, flags);\r\nlist_del(&cfile->list);\r\nspin_unlock_irqrestore(&cd->file_lock, flags);\r\nreturn 0;\r\n}\r\nstatic void genwqe_add_pin(struct genwqe_file *cfile, struct dma_mapping *m)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&cfile->pin_lock, flags);\r\nlist_add(&m->pin_list, &cfile->pin_list);\r\nspin_unlock_irqrestore(&cfile->pin_lock, flags);\r\n}\r\nstatic int genwqe_del_pin(struct genwqe_file *cfile, struct dma_mapping *m)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&cfile->pin_lock, flags);\r\nlist_del(&m->pin_list);\r\nspin_unlock_irqrestore(&cfile->pin_lock, flags);\r\nreturn 0;\r\n}\r\nstatic struct dma_mapping *genwqe_search_pin(struct genwqe_file *cfile,\r\nunsigned long u_addr,\r\nunsigned int size,\r\nvoid **virt_addr)\r\n{\r\nunsigned long flags;\r\nstruct dma_mapping *m;\r\nspin_lock_irqsave(&cfile->pin_lock, flags);\r\nlist_for_each_entry(m, &cfile->pin_list, pin_list) {\r\nif ((((u64)m->u_vaddr) <= (u_addr)) &&\r\n(((u64)m->u_vaddr + m->size) >= (u_addr + size))) {\r\nif (virt_addr)\r\n*virt_addr = m->k_vaddr +\r\n(u_addr - (u64)m->u_vaddr);\r\nspin_unlock_irqrestore(&cfile->pin_lock, flags);\r\nreturn m;\r\n}\r\n}\r\nspin_unlock_irqrestore(&cfile->pin_lock, flags);\r\nreturn NULL;\r\n}\r\nstatic void __genwqe_add_mapping(struct genwqe_file *cfile,\r\nstruct dma_mapping *dma_map)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&cfile->map_lock, flags);\r\nlist_add(&dma_map->card_list, &cfile->map_list);\r\nspin_unlock_irqrestore(&cfile->map_lock, flags);\r\n}\r\nstatic void __genwqe_del_mapping(struct genwqe_file *cfile,\r\nstruct dma_mapping *dma_map)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&cfile->map_lock, flags);\r\nlist_del(&dma_map->card_list);\r\nspin_unlock_irqrestore(&cfile->map_lock, flags);\r\n}\r\nstatic struct dma_mapping *__genwqe_search_mapping(struct genwqe_file *cfile,\r\nunsigned long u_addr,\r\nunsigned int size,\r\ndma_addr_t *dma_addr,\r\nvoid **virt_addr)\r\n{\r\nunsigned long flags;\r\nstruct dma_mapping *m;\r\nstruct pci_dev *pci_dev = cfile->cd->pci_dev;\r\nspin_lock_irqsave(&cfile->map_lock, flags);\r\nlist_for_each_entry(m, &cfile->map_list, card_list) {\r\nif ((((u64)m->u_vaddr) <= (u_addr)) &&\r\n(((u64)m->u_vaddr + m->size) >= (u_addr + size))) {\r\nif (dma_addr)\r\n*dma_addr = m->dma_addr +\r\n(u_addr - (u64)m->u_vaddr);\r\nif (virt_addr)\r\n*virt_addr = m->k_vaddr +\r\n(u_addr - (u64)m->u_vaddr);\r\nspin_unlock_irqrestore(&cfile->map_lock, flags);\r\nreturn m;\r\n}\r\n}\r\nspin_unlock_irqrestore(&cfile->map_lock, flags);\r\ndev_err(&pci_dev->dev,\r\n"[%s] Entry not found: u_addr=%lx, size=%x\n",\r\n__func__, u_addr, size);\r\nreturn NULL;\r\n}\r\nstatic void genwqe_remove_mappings(struct genwqe_file *cfile)\r\n{\r\nint i = 0;\r\nstruct list_head *node, *next;\r\nstruct dma_mapping *dma_map;\r\nstruct genwqe_dev *cd = cfile->cd;\r\nstruct pci_dev *pci_dev = cfile->cd->pci_dev;\r\nlist_for_each_safe(node, next, &cfile->map_list) {\r\ndma_map = list_entry(node, struct dma_mapping, card_list);\r\nlist_del_init(&dma_map->card_list);\r\ndev_err(&pci_dev->dev,\r\n"[%s] %d. cleanup mapping: u_vaddr=%p "\r\n"u_kaddr=%016lx dma_addr=%lx\n", __func__, i++,\r\ndma_map->u_vaddr, (unsigned long)dma_map->k_vaddr,\r\n(unsigned long)dma_map->dma_addr);\r\nif (dma_map->type == GENWQE_MAPPING_RAW) {\r\n__genwqe_free_consistent(cd, dma_map->size,\r\ndma_map->k_vaddr,\r\ndma_map->dma_addr);\r\nkfree(dma_map);\r\n} else if (dma_map->type == GENWQE_MAPPING_SGL_TEMP) {\r\ngenwqe_user_vunmap(cd, dma_map, NULL);\r\n}\r\n}\r\n}\r\nstatic void genwqe_remove_pinnings(struct genwqe_file *cfile)\r\n{\r\nstruct list_head *node, *next;\r\nstruct dma_mapping *dma_map;\r\nstruct genwqe_dev *cd = cfile->cd;\r\nlist_for_each_safe(node, next, &cfile->pin_list) {\r\ndma_map = list_entry(node, struct dma_mapping, pin_list);\r\nlist_del_init(&dma_map->pin_list);\r\ngenwqe_user_vunmap(cd, dma_map, NULL);\r\nkfree(dma_map);\r\n}\r\n}\r\nstatic int genwqe_kill_fasync(struct genwqe_dev *cd, int sig)\r\n{\r\nunsigned int files = 0;\r\nunsigned long flags;\r\nstruct genwqe_file *cfile;\r\nspin_lock_irqsave(&cd->file_lock, flags);\r\nlist_for_each_entry(cfile, &cd->file_list, list) {\r\nif (cfile->async_queue)\r\nkill_fasync(&cfile->async_queue, sig, POLL_HUP);\r\nfiles++;\r\n}\r\nspin_unlock_irqrestore(&cd->file_lock, flags);\r\nreturn files;\r\n}\r\nstatic int genwqe_force_sig(struct genwqe_dev *cd, int sig)\r\n{\r\nunsigned int files = 0;\r\nunsigned long flags;\r\nstruct genwqe_file *cfile;\r\nspin_lock_irqsave(&cd->file_lock, flags);\r\nlist_for_each_entry(cfile, &cd->file_list, list) {\r\nforce_sig(sig, cfile->owner);\r\nfiles++;\r\n}\r\nspin_unlock_irqrestore(&cd->file_lock, flags);\r\nreturn files;\r\n}\r\nstatic int genwqe_open(struct inode *inode, struct file *filp)\r\n{\r\nstruct genwqe_dev *cd;\r\nstruct genwqe_file *cfile;\r\nstruct pci_dev *pci_dev;\r\ncfile = kzalloc(sizeof(*cfile), GFP_KERNEL);\r\nif (cfile == NULL)\r\nreturn -ENOMEM;\r\ncd = container_of(inode->i_cdev, struct genwqe_dev, cdev_genwqe);\r\npci_dev = cd->pci_dev;\r\ncfile->cd = cd;\r\ncfile->filp = filp;\r\ncfile->client = NULL;\r\nspin_lock_init(&cfile->map_lock);\r\nINIT_LIST_HEAD(&cfile->map_list);\r\nspin_lock_init(&cfile->pin_lock);\r\nINIT_LIST_HEAD(&cfile->pin_list);\r\nfilp->private_data = cfile;\r\ngenwqe_add_file(cd, cfile);\r\nreturn 0;\r\n}\r\nstatic int genwqe_fasync(int fd, struct file *filp, int mode)\r\n{\r\nstruct genwqe_file *cdev = (struct genwqe_file *)filp->private_data;\r\nreturn fasync_helper(fd, filp, mode, &cdev->async_queue);\r\n}\r\nstatic int genwqe_release(struct inode *inode, struct file *filp)\r\n{\r\nstruct genwqe_file *cfile = (struct genwqe_file *)filp->private_data;\r\nstruct genwqe_dev *cd = cfile->cd;\r\ngenwqe_remove_mappings(cfile);\r\ngenwqe_remove_pinnings(cfile);\r\ngenwqe_fasync(-1, filp, 0);\r\ngenwqe_del_file(cd, cfile);\r\nkfree(cfile);\r\nreturn 0;\r\n}\r\nstatic void genwqe_vma_open(struct vm_area_struct *vma)\r\n{\r\n}\r\nstatic void genwqe_vma_close(struct vm_area_struct *vma)\r\n{\r\nunsigned long vsize = vma->vm_end - vma->vm_start;\r\nstruct inode *inode = vma->vm_file->f_dentry->d_inode;\r\nstruct dma_mapping *dma_map;\r\nstruct genwqe_dev *cd = container_of(inode->i_cdev, struct genwqe_dev,\r\ncdev_genwqe);\r\nstruct pci_dev *pci_dev = cd->pci_dev;\r\ndma_addr_t d_addr = 0;\r\nstruct genwqe_file *cfile = vma->vm_private_data;\r\ndma_map = __genwqe_search_mapping(cfile, vma->vm_start, vsize,\r\n&d_addr, NULL);\r\nif (dma_map == NULL) {\r\ndev_err(&pci_dev->dev,\r\n" [%s] err: mapping not found: v=%lx, p=%lx s=%lx\n",\r\n__func__, vma->vm_start, vma->vm_pgoff << PAGE_SHIFT,\r\nvsize);\r\nreturn;\r\n}\r\n__genwqe_del_mapping(cfile, dma_map);\r\n__genwqe_free_consistent(cd, dma_map->size, dma_map->k_vaddr,\r\ndma_map->dma_addr);\r\nkfree(dma_map);\r\n}\r\nstatic int genwqe_mmap(struct file *filp, struct vm_area_struct *vma)\r\n{\r\nint rc;\r\nunsigned long pfn, vsize = vma->vm_end - vma->vm_start;\r\nstruct genwqe_file *cfile = (struct genwqe_file *)filp->private_data;\r\nstruct genwqe_dev *cd = cfile->cd;\r\nstruct dma_mapping *dma_map;\r\nif (vsize == 0)\r\nreturn -EINVAL;\r\nif (get_order(vsize) > MAX_ORDER)\r\nreturn -ENOMEM;\r\ndma_map = kzalloc(sizeof(struct dma_mapping), GFP_ATOMIC);\r\nif (dma_map == NULL)\r\nreturn -ENOMEM;\r\ngenwqe_mapping_init(dma_map, GENWQE_MAPPING_RAW);\r\ndma_map->u_vaddr = (void *)vma->vm_start;\r\ndma_map->size = vsize;\r\ndma_map->nr_pages = DIV_ROUND_UP(vsize, PAGE_SIZE);\r\ndma_map->k_vaddr = __genwqe_alloc_consistent(cd, vsize,\r\n&dma_map->dma_addr);\r\nif (dma_map->k_vaddr == NULL) {\r\nrc = -ENOMEM;\r\ngoto free_dma_map;\r\n}\r\nif (capable(CAP_SYS_ADMIN) && (vsize > sizeof(dma_addr_t)))\r\n*(dma_addr_t *)dma_map->k_vaddr = dma_map->dma_addr;\r\npfn = virt_to_phys(dma_map->k_vaddr) >> PAGE_SHIFT;\r\nrc = remap_pfn_range(vma,\r\nvma->vm_start,\r\npfn,\r\nvsize,\r\nvma->vm_page_prot);\r\nif (rc != 0) {\r\nrc = -EFAULT;\r\ngoto free_dma_mem;\r\n}\r\nvma->vm_private_data = cfile;\r\nvma->vm_ops = &genwqe_vma_ops;\r\n__genwqe_add_mapping(cfile, dma_map);\r\nreturn 0;\r\nfree_dma_mem:\r\n__genwqe_free_consistent(cd, dma_map->size,\r\ndma_map->k_vaddr,\r\ndma_map->dma_addr);\r\nfree_dma_map:\r\nkfree(dma_map);\r\nreturn rc;\r\n}\r\nstatic int do_flash_update(struct genwqe_file *cfile,\r\nstruct genwqe_bitstream *load)\r\n{\r\nint rc = 0;\r\nint blocks_to_flash;\r\ndma_addr_t dma_addr;\r\nu64 flash = 0;\r\nsize_t tocopy = 0;\r\nu8 __user *buf;\r\nu8 *xbuf;\r\nu32 crc;\r\nu8 cmdopts;\r\nstruct genwqe_dev *cd = cfile->cd;\r\nstruct pci_dev *pci_dev = cd->pci_dev;\r\nif ((load->size & 0x3) != 0)\r\nreturn -EINVAL;\r\nif (((unsigned long)(load->data_addr) & ~PAGE_MASK) != 0)\r\nreturn -EINVAL;\r\nswitch ((char)load->partition) {\r\ncase '0':\r\ncmdopts = 0x14;\r\nbreak;\r\ncase '1':\r\ncmdopts = 0x1C;\r\nbreak;\r\ncase 'v':\r\ncmdopts = 0x0C;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nbuf = (u8 __user *)load->data_addr;\r\nxbuf = __genwqe_alloc_consistent(cd, FLASH_BLOCK, &dma_addr);\r\nif (xbuf == NULL)\r\nreturn -ENOMEM;\r\nblocks_to_flash = load->size / FLASH_BLOCK;\r\nwhile (load->size) {\r\nstruct genwqe_ddcb_cmd *req;\r\ntocopy = min_t(size_t, load->size, FLASH_BLOCK);\r\nrc = copy_from_user(xbuf, buf, tocopy);\r\nif (rc) {\r\nrc = -EFAULT;\r\ngoto free_buffer;\r\n}\r\ncrc = genwqe_crc32(xbuf, tocopy, 0xffffffff);\r\ndev_dbg(&pci_dev->dev,\r\n"[%s] DMA: %lx CRC: %08x SZ: %ld %d\n",\r\n__func__, (unsigned long)dma_addr, crc, tocopy,\r\nblocks_to_flash);\r\nreq = ddcb_requ_alloc();\r\nif (req == NULL) {\r\nrc = -ENOMEM;\r\ngoto free_buffer;\r\n}\r\nreq->cmd = SLCMD_MOVE_FLASH;\r\nreq->cmdopts = cmdopts;\r\nif (genwqe_get_slu_id(cd) <= 0x2) {\r\n*(__be64 *)&req->__asiv[0] = cpu_to_be64(dma_addr);\r\n*(__be64 *)&req->__asiv[8] = cpu_to_be64(tocopy);\r\n*(__be64 *)&req->__asiv[16] = cpu_to_be64(flash);\r\n*(__be32 *)&req->__asiv[24] = cpu_to_be32(0);\r\nreq->__asiv[24] = load->uid;\r\n*(__be32 *)&req->__asiv[28] = cpu_to_be32(crc);\r\n*(__be64 *)&req->__asiv[88] = cpu_to_be64(load->slu_id);\r\n*(__be64 *)&req->__asiv[96] = cpu_to_be64(load->app_id);\r\nreq->asiv_length = 32;\r\n} else {\r\n*(__be64 *)&req->asiv[0] = cpu_to_be64(dma_addr);\r\n*(__be32 *)&req->asiv[8] = cpu_to_be32(tocopy);\r\n*(__be32 *)&req->asiv[12] = cpu_to_be32(0);\r\n*(__be64 *)&req->asiv[16] = cpu_to_be64(flash);\r\n*(__be32 *)&req->asiv[24] = cpu_to_be32(load->uid<<24);\r\n*(__be32 *)&req->asiv[28] = cpu_to_be32(crc);\r\n*(__be64 *)&req->asiv[80] = cpu_to_be64(load->slu_id);\r\n*(__be64 *)&req->asiv[88] = cpu_to_be64(load->app_id);\r\nreq->ats = 0x4ULL << 44;\r\nreq->asiv_length = 40;\r\n}\r\nreq->asv_length = 8;\r\n*(u64 *)&req->asv[0] = 0ULL;\r\nrc = __genwqe_execute_raw_ddcb(cd, req);\r\nload->retc = req->retc;\r\nload->attn = req->attn;\r\nload->progress = req->progress;\r\nif (rc < 0) {\r\nddcb_requ_free(req);\r\ngoto free_buffer;\r\n}\r\nif (req->retc != DDCB_RETC_COMPLETE) {\r\nrc = -EIO;\r\nddcb_requ_free(req);\r\ngoto free_buffer;\r\n}\r\nload->size -= tocopy;\r\nflash += tocopy;\r\nbuf += tocopy;\r\nblocks_to_flash--;\r\nddcb_requ_free(req);\r\n}\r\nfree_buffer:\r\n__genwqe_free_consistent(cd, FLASH_BLOCK, xbuf, dma_addr);\r\nreturn rc;\r\n}\r\nstatic int do_flash_read(struct genwqe_file *cfile,\r\nstruct genwqe_bitstream *load)\r\n{\r\nint rc, blocks_to_flash;\r\ndma_addr_t dma_addr;\r\nu64 flash = 0;\r\nsize_t tocopy = 0;\r\nu8 __user *buf;\r\nu8 *xbuf;\r\nu8 cmdopts;\r\nstruct genwqe_dev *cd = cfile->cd;\r\nstruct pci_dev *pci_dev = cd->pci_dev;\r\nstruct genwqe_ddcb_cmd *cmd;\r\nif ((load->size & 0x3) != 0)\r\nreturn -EINVAL;\r\nif (((unsigned long)(load->data_addr) & ~PAGE_MASK) != 0)\r\nreturn -EINVAL;\r\nswitch ((char)load->partition) {\r\ncase '0':\r\ncmdopts = 0x12;\r\nbreak;\r\ncase '1':\r\ncmdopts = 0x1A;\r\nbreak;\r\ncase 'v':\r\ncmdopts = 0x0A;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nbuf = (u8 __user *)load->data_addr;\r\nxbuf = __genwqe_alloc_consistent(cd, FLASH_BLOCK, &dma_addr);\r\nif (xbuf == NULL)\r\nreturn -ENOMEM;\r\nblocks_to_flash = load->size / FLASH_BLOCK;\r\nwhile (load->size) {\r\ntocopy = min_t(size_t, load->size, FLASH_BLOCK);\r\ndev_dbg(&pci_dev->dev,\r\n"[%s] DMA: %lx SZ: %ld %d\n",\r\n__func__, (unsigned long)dma_addr, tocopy,\r\nblocks_to_flash);\r\ncmd = ddcb_requ_alloc();\r\nif (cmd == NULL) {\r\nrc = -ENOMEM;\r\ngoto free_buffer;\r\n}\r\ncmd->cmd = SLCMD_MOVE_FLASH;\r\ncmd->cmdopts = cmdopts;\r\nif (genwqe_get_slu_id(cd) <= 0x2) {\r\n*(__be64 *)&cmd->__asiv[0] = cpu_to_be64(dma_addr);\r\n*(__be64 *)&cmd->__asiv[8] = cpu_to_be64(tocopy);\r\n*(__be64 *)&cmd->__asiv[16] = cpu_to_be64(flash);\r\n*(__be32 *)&cmd->__asiv[24] = cpu_to_be32(0);\r\ncmd->__asiv[24] = load->uid;\r\n*(__be32 *)&cmd->__asiv[28] = cpu_to_be32(0) ;\r\ncmd->asiv_length = 32;\r\n} else {\r\n*(__be64 *)&cmd->asiv[0] = cpu_to_be64(dma_addr);\r\n*(__be32 *)&cmd->asiv[8] = cpu_to_be32(tocopy);\r\n*(__be32 *)&cmd->asiv[12] = cpu_to_be32(0);\r\n*(__be64 *)&cmd->asiv[16] = cpu_to_be64(flash);\r\n*(__be32 *)&cmd->asiv[24] = cpu_to_be32(load->uid<<24);\r\n*(__be32 *)&cmd->asiv[28] = cpu_to_be32(0);\r\ncmd->ats = 0x5ULL << 44;\r\ncmd->asiv_length = 40;\r\n}\r\ncmd->asv_length = 8;\r\n*(u64 *)&cmd->asv[0] = 0ULL;\r\nrc = __genwqe_execute_raw_ddcb(cd, cmd);\r\nload->retc = cmd->retc;\r\nload->attn = cmd->attn;\r\nload->progress = cmd->progress;\r\nif ((rc < 0) && (rc != -EBADMSG)) {\r\nddcb_requ_free(cmd);\r\ngoto free_buffer;\r\n}\r\nrc = copy_to_user(buf, xbuf, tocopy);\r\nif (rc) {\r\nrc = -EFAULT;\r\nddcb_requ_free(cmd);\r\ngoto free_buffer;\r\n}\r\nif (((cmd->retc == DDCB_RETC_FAULT) &&\r\n(cmd->attn != 0x02)) ||\r\n((cmd->retc == DDCB_RETC_COMPLETE) &&\r\n(cmd->attn != 0x00))) {\r\nrc = -EIO;\r\nddcb_requ_free(cmd);\r\ngoto free_buffer;\r\n}\r\nload->size -= tocopy;\r\nflash += tocopy;\r\nbuf += tocopy;\r\nblocks_to_flash--;\r\nddcb_requ_free(cmd);\r\n}\r\nrc = 0;\r\nfree_buffer:\r\n__genwqe_free_consistent(cd, FLASH_BLOCK, xbuf, dma_addr);\r\nreturn rc;\r\n}\r\nstatic int genwqe_pin_mem(struct genwqe_file *cfile, struct genwqe_mem *m)\r\n{\r\nint rc;\r\nstruct genwqe_dev *cd = cfile->cd;\r\nstruct pci_dev *pci_dev = cfile->cd->pci_dev;\r\nstruct dma_mapping *dma_map;\r\nunsigned long map_addr;\r\nunsigned long map_size;\r\nif ((m->addr == 0x0) || (m->size == 0))\r\nreturn -EINVAL;\r\nmap_addr = (m->addr & PAGE_MASK);\r\nmap_size = round_up(m->size + (m->addr & ~PAGE_MASK), PAGE_SIZE);\r\ndma_map = kzalloc(sizeof(struct dma_mapping), GFP_ATOMIC);\r\nif (dma_map == NULL)\r\nreturn -ENOMEM;\r\ngenwqe_mapping_init(dma_map, GENWQE_MAPPING_SGL_PINNED);\r\nrc = genwqe_user_vmap(cd, dma_map, (void *)map_addr, map_size, NULL);\r\nif (rc != 0) {\r\ndev_err(&pci_dev->dev,\r\n"[%s] genwqe_user_vmap rc=%d\n", __func__, rc);\r\nkfree(dma_map);\r\nreturn rc;\r\n}\r\ngenwqe_add_pin(cfile, dma_map);\r\nreturn 0;\r\n}\r\nstatic int genwqe_unpin_mem(struct genwqe_file *cfile, struct genwqe_mem *m)\r\n{\r\nstruct genwqe_dev *cd = cfile->cd;\r\nstruct dma_mapping *dma_map;\r\nunsigned long map_addr;\r\nunsigned long map_size;\r\nif (m->addr == 0x0)\r\nreturn -EINVAL;\r\nmap_addr = (m->addr & PAGE_MASK);\r\nmap_size = round_up(m->size + (m->addr & ~PAGE_MASK), PAGE_SIZE);\r\ndma_map = genwqe_search_pin(cfile, map_addr, map_size, NULL);\r\nif (dma_map == NULL)\r\nreturn -ENOENT;\r\ngenwqe_del_pin(cfile, dma_map);\r\ngenwqe_user_vunmap(cd, dma_map, NULL);\r\nkfree(dma_map);\r\nreturn 0;\r\n}\r\nstatic int ddcb_cmd_cleanup(struct genwqe_file *cfile, struct ddcb_requ *req)\r\n{\r\nunsigned int i;\r\nstruct dma_mapping *dma_map;\r\nstruct genwqe_dev *cd = cfile->cd;\r\nfor (i = 0; i < DDCB_FIXUPS; i++) {\r\ndma_map = &req->dma_mappings[i];\r\nif (dma_mapping_used(dma_map)) {\r\n__genwqe_del_mapping(cfile, dma_map);\r\ngenwqe_user_vunmap(cd, dma_map, req);\r\n}\r\nif (req->sgls[i].sgl != NULL)\r\ngenwqe_free_sync_sgl(cd, &req->sgls[i]);\r\n}\r\nreturn 0;\r\n}\r\nstatic int ddcb_cmd_fixups(struct genwqe_file *cfile, struct ddcb_requ *req)\r\n{\r\nint rc;\r\nunsigned int asiv_offs, i;\r\nstruct genwqe_dev *cd = cfile->cd;\r\nstruct genwqe_ddcb_cmd *cmd = &req->cmd;\r\nstruct dma_mapping *m;\r\nconst char *type = "UNKNOWN";\r\nfor (i = 0, asiv_offs = 0x00; asiv_offs <= 0x58;\r\ni++, asiv_offs += 0x08) {\r\nu64 u_addr;\r\ndma_addr_t d_addr;\r\nu32 u_size = 0;\r\nu64 ats_flags;\r\nats_flags = ATS_GET_FLAGS(cmd->ats, asiv_offs);\r\nswitch (ats_flags) {\r\ncase ATS_TYPE_DATA:\r\nbreak;\r\ncase ATS_TYPE_FLAT_RDWR:\r\ncase ATS_TYPE_FLAT_RD: {\r\nu_addr = be64_to_cpu(*((__be64 *)&cmd->\r\nasiv[asiv_offs]));\r\nu_size = be32_to_cpu(*((__be32 *)&cmd->\r\nasiv[asiv_offs + 0x08]));\r\nif (u_size == 0x0) {\r\n*((__be64 *)&cmd->asiv[asiv_offs]) =\r\ncpu_to_be64(0x0);\r\nbreak;\r\n}\r\nm = __genwqe_search_mapping(cfile, u_addr, u_size,\r\n&d_addr, NULL);\r\nif (m == NULL) {\r\nrc = -EFAULT;\r\ngoto err_out;\r\n}\r\n*((__be64 *)&cmd->asiv[asiv_offs]) =\r\ncpu_to_be64(d_addr);\r\nbreak;\r\n}\r\ncase ATS_TYPE_SGL_RDWR:\r\ncase ATS_TYPE_SGL_RD: {\r\nint page_offs;\r\nu_addr = be64_to_cpu(*((__be64 *)\r\n&cmd->asiv[asiv_offs]));\r\nu_size = be32_to_cpu(*((__be32 *)\r\n&cmd->asiv[asiv_offs + 0x08]));\r\nif (u_size == 0x0) {\r\n*((__be64 *)&cmd->asiv[asiv_offs]) =\r\ncpu_to_be64(0x0);\r\nbreak;\r\n}\r\nm = genwqe_search_pin(cfile, u_addr, u_size, NULL);\r\nif (m != NULL) {\r\ntype = "PINNING";\r\npage_offs = (u_addr -\r\n(u64)m->u_vaddr)/PAGE_SIZE;\r\n} else {\r\ntype = "MAPPING";\r\nm = &req->dma_mappings[i];\r\ngenwqe_mapping_init(m,\r\nGENWQE_MAPPING_SGL_TEMP);\r\nrc = genwqe_user_vmap(cd, m, (void *)u_addr,\r\nu_size, req);\r\nif (rc != 0)\r\ngoto err_out;\r\n__genwqe_add_mapping(cfile, m);\r\npage_offs = 0;\r\n}\r\nrc = genwqe_alloc_sync_sgl(cd, &req->sgls[i],\r\n(void __user *)u_addr,\r\nu_size);\r\nif (rc != 0)\r\ngoto err_out;\r\ngenwqe_setup_sgl(cd, &req->sgls[i],\r\n&m->dma_list[page_offs]);\r\n*((__be64 *)&cmd->asiv[asiv_offs]) =\r\ncpu_to_be64(req->sgls[i].sgl_dma_addr);\r\nbreak;\r\n}\r\ndefault:\r\nrc = -EINVAL;\r\ngoto err_out;\r\n}\r\n}\r\nreturn 0;\r\nerr_out:\r\nddcb_cmd_cleanup(cfile, req);\r\nreturn rc;\r\n}\r\nstatic int genwqe_execute_ddcb(struct genwqe_file *cfile,\r\nstruct genwqe_ddcb_cmd *cmd)\r\n{\r\nint rc;\r\nstruct genwqe_dev *cd = cfile->cd;\r\nstruct ddcb_requ *req = container_of(cmd, struct ddcb_requ, cmd);\r\nrc = ddcb_cmd_fixups(cfile, req);\r\nif (rc != 0)\r\nreturn rc;\r\nrc = __genwqe_execute_raw_ddcb(cd, cmd);\r\nddcb_cmd_cleanup(cfile, req);\r\nreturn rc;\r\n}\r\nstatic int do_execute_ddcb(struct genwqe_file *cfile,\r\nunsigned long arg, int raw)\r\n{\r\nint rc;\r\nstruct genwqe_ddcb_cmd *cmd;\r\nstruct ddcb_requ *req;\r\nstruct genwqe_dev *cd = cfile->cd;\r\ncmd = ddcb_requ_alloc();\r\nif (cmd == NULL)\r\nreturn -ENOMEM;\r\nreq = container_of(cmd, struct ddcb_requ, cmd);\r\nif (copy_from_user(cmd, (void __user *)arg, sizeof(*cmd))) {\r\nddcb_requ_free(cmd);\r\nreturn -EFAULT;\r\n}\r\nif (!raw)\r\nrc = genwqe_execute_ddcb(cfile, cmd);\r\nelse\r\nrc = __genwqe_execute_raw_ddcb(cd, cmd);\r\nif (copy_to_user((void __user *)arg, cmd,\r\nsizeof(*cmd) - DDCB_ASIV_LENGTH)) {\r\nddcb_requ_free(cmd);\r\nreturn -EFAULT;\r\n}\r\nddcb_requ_free(cmd);\r\nreturn rc;\r\n}\r\nstatic long genwqe_ioctl(struct file *filp, unsigned int cmd,\r\nunsigned long arg)\r\n{\r\nint rc = 0;\r\nstruct genwqe_file *cfile = (struct genwqe_file *)filp->private_data;\r\nstruct genwqe_dev *cd = cfile->cd;\r\nstruct genwqe_reg_io __user *io;\r\nu64 val;\r\nu32 reg_offs;\r\nif (_IOC_TYPE(cmd) != GENWQE_IOC_CODE)\r\nreturn -EINVAL;\r\nswitch (cmd) {\r\ncase GENWQE_GET_CARD_STATE:\r\nput_user(cd->card_state, (enum genwqe_card_state __user *)arg);\r\nreturn 0;\r\ncase GENWQE_READ_REG64: {\r\nio = (struct genwqe_reg_io __user *)arg;\r\nif (get_user(reg_offs, &io->num))\r\nreturn -EFAULT;\r\nif ((reg_offs >= cd->mmio_len) || (reg_offs & 0x7))\r\nreturn -EINVAL;\r\nval = __genwqe_readq(cd, reg_offs);\r\nput_user(val, &io->val64);\r\nreturn 0;\r\n}\r\ncase GENWQE_WRITE_REG64: {\r\nio = (struct genwqe_reg_io __user *)arg;\r\nif (!capable(CAP_SYS_ADMIN))\r\nreturn -EPERM;\r\nif ((filp->f_flags & O_ACCMODE) == O_RDONLY)\r\nreturn -EPERM;\r\nif (get_user(reg_offs, &io->num))\r\nreturn -EFAULT;\r\nif ((reg_offs >= cd->mmio_len) || (reg_offs & 0x7))\r\nreturn -EINVAL;\r\nif (get_user(val, &io->val64))\r\nreturn -EFAULT;\r\n__genwqe_writeq(cd, reg_offs, val);\r\nreturn 0;\r\n}\r\ncase GENWQE_READ_REG32: {\r\nio = (struct genwqe_reg_io __user *)arg;\r\nif (get_user(reg_offs, &io->num))\r\nreturn -EFAULT;\r\nif ((reg_offs >= cd->mmio_len) || (reg_offs & 0x3))\r\nreturn -EINVAL;\r\nval = __genwqe_readl(cd, reg_offs);\r\nput_user(val, &io->val64);\r\nreturn 0;\r\n}\r\ncase GENWQE_WRITE_REG32: {\r\nio = (struct genwqe_reg_io __user *)arg;\r\nif (!capable(CAP_SYS_ADMIN))\r\nreturn -EPERM;\r\nif ((filp->f_flags & O_ACCMODE) == O_RDONLY)\r\nreturn -EPERM;\r\nif (get_user(reg_offs, &io->num))\r\nreturn -EFAULT;\r\nif ((reg_offs >= cd->mmio_len) || (reg_offs & 0x3))\r\nreturn -EINVAL;\r\nif (get_user(val, &io->val64))\r\nreturn -EFAULT;\r\n__genwqe_writel(cd, reg_offs, val);\r\nreturn 0;\r\n}\r\ncase GENWQE_SLU_UPDATE: {\r\nstruct genwqe_bitstream load;\r\nif (!genwqe_is_privileged(cd))\r\nreturn -EPERM;\r\nif ((filp->f_flags & O_ACCMODE) == O_RDONLY)\r\nreturn -EPERM;\r\nif (copy_from_user(&load, (void __user *)arg,\r\nsizeof(load)))\r\nreturn -EFAULT;\r\nrc = do_flash_update(cfile, &load);\r\nif (copy_to_user((void __user *)arg, &load, sizeof(load)))\r\nreturn -EFAULT;\r\nreturn rc;\r\n}\r\ncase GENWQE_SLU_READ: {\r\nstruct genwqe_bitstream load;\r\nif (!genwqe_is_privileged(cd))\r\nreturn -EPERM;\r\nif (genwqe_flash_readback_fails(cd))\r\nreturn -ENOSPC;\r\nif (copy_from_user(&load, (void __user *)arg, sizeof(load)))\r\nreturn -EFAULT;\r\nrc = do_flash_read(cfile, &load);\r\nif (copy_to_user((void __user *)arg, &load, sizeof(load)))\r\nreturn -EFAULT;\r\nreturn rc;\r\n}\r\ncase GENWQE_PIN_MEM: {\r\nstruct genwqe_mem m;\r\nif (copy_from_user(&m, (void __user *)arg, sizeof(m)))\r\nreturn -EFAULT;\r\nreturn genwqe_pin_mem(cfile, &m);\r\n}\r\ncase GENWQE_UNPIN_MEM: {\r\nstruct genwqe_mem m;\r\nif (copy_from_user(&m, (void __user *)arg, sizeof(m)))\r\nreturn -EFAULT;\r\nreturn genwqe_unpin_mem(cfile, &m);\r\n}\r\ncase GENWQE_EXECUTE_DDCB:\r\nreturn do_execute_ddcb(cfile, arg, 0);\r\ncase GENWQE_EXECUTE_RAW_DDCB: {\r\nif (!capable(CAP_SYS_ADMIN))\r\nreturn -EPERM;\r\nreturn do_execute_ddcb(cfile, arg, 1);\r\n}\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn rc;\r\n}\r\nstatic long genwqe_compat_ioctl(struct file *filp, unsigned int cmd,\r\nunsigned long arg)\r\n{\r\nreturn genwqe_ioctl(filp, cmd, arg);\r\n}\r\nstatic int genwqe_device_initialized(struct genwqe_dev *cd)\r\n{\r\nreturn cd->dev != NULL;\r\n}\r\nint genwqe_device_create(struct genwqe_dev *cd)\r\n{\r\nint rc;\r\nstruct pci_dev *pci_dev = cd->pci_dev;\r\nrc = alloc_chrdev_region(&cd->devnum_genwqe, 0,\r\nGENWQE_MAX_MINOR, GENWQE_DEVNAME);\r\nif (rc < 0) {\r\ndev_err(&pci_dev->dev, "err: alloc_chrdev_region failed\n");\r\ngoto err_dev;\r\n}\r\ncdev_init(&cd->cdev_genwqe, &genwqe_fops);\r\ncd->cdev_genwqe.owner = THIS_MODULE;\r\nrc = cdev_add(&cd->cdev_genwqe, cd->devnum_genwqe, 1);\r\nif (rc < 0) {\r\ndev_err(&pci_dev->dev, "err: cdev_add failed\n");\r\ngoto err_add;\r\n}\r\ncd->dev = device_create_with_groups(cd->class_genwqe,\r\n&cd->pci_dev->dev,\r\ncd->devnum_genwqe, cd,\r\ngenwqe_attribute_groups,\r\nGENWQE_DEVNAME "%u_card",\r\ncd->card_idx);\r\nif (IS_ERR(cd->dev)) {\r\nrc = PTR_ERR(cd->dev);\r\ngoto err_cdev;\r\n}\r\nrc = genwqe_init_debugfs(cd);\r\nif (rc != 0)\r\ngoto err_debugfs;\r\nreturn 0;\r\nerr_debugfs:\r\ndevice_destroy(cd->class_genwqe, cd->devnum_genwqe);\r\nerr_cdev:\r\ncdev_del(&cd->cdev_genwqe);\r\nerr_add:\r\nunregister_chrdev_region(cd->devnum_genwqe, GENWQE_MAX_MINOR);\r\nerr_dev:\r\ncd->dev = NULL;\r\nreturn rc;\r\n}\r\nstatic int genwqe_inform_and_stop_processes(struct genwqe_dev *cd)\r\n{\r\nint rc;\r\nunsigned int i;\r\nstruct pci_dev *pci_dev = cd->pci_dev;\r\nif (!genwqe_open_files(cd))\r\nreturn 0;\r\ndev_warn(&pci_dev->dev, "[%s] send SIGIO and wait ...\n", __func__);\r\nrc = genwqe_kill_fasync(cd, SIGIO);\r\nif (rc > 0) {\r\nfor (i = 0; (i < genwqe_kill_timeout) &&\r\ngenwqe_open_files(cd); i++) {\r\ndev_info(&pci_dev->dev, " %d sec ...", i);\r\ncond_resched();\r\nmsleep(1000);\r\n}\r\nif (!genwqe_open_files(cd))\r\nreturn 0;\r\ndev_warn(&pci_dev->dev,\r\n"[%s] send SIGKILL and wait ...\n", __func__);\r\nrc = genwqe_force_sig(cd, SIGKILL);\r\nif (rc) {\r\nfor (i = 0; (i < genwqe_kill_timeout) &&\r\ngenwqe_open_files(cd); i++) {\r\ndev_warn(&pci_dev->dev, " %d sec ...", i);\r\ncond_resched();\r\nmsleep(1000);\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint genwqe_device_remove(struct genwqe_dev *cd)\r\n{\r\nint rc;\r\nstruct pci_dev *pci_dev = cd->pci_dev;\r\nif (!genwqe_device_initialized(cd))\r\nreturn 1;\r\ngenwqe_inform_and_stop_processes(cd);\r\nrc = atomic_read(&cd->cdev_genwqe.kobj.kref.refcount);\r\nif (rc != 1) {\r\ndev_err(&pci_dev->dev,\r\n"[%s] err: cdev_genwqe...refcount=%d\n", __func__, rc);\r\npanic("Fatal err: cannot free resources with pending references!");\r\n}\r\ngenqwe_exit_debugfs(cd);\r\ndevice_destroy(cd->class_genwqe, cd->devnum_genwqe);\r\ncdev_del(&cd->cdev_genwqe);\r\nunregister_chrdev_region(cd->devnum_genwqe, GENWQE_MAX_MINOR);\r\ncd->dev = NULL;\r\nreturn 0;\r\n}
