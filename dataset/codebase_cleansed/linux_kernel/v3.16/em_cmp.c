static inline int cmp_needs_transformation(struct tcf_em_cmp *cmp)\r\n{\r\nreturn unlikely(cmp->flags & TCF_EM_CMP_TRANS);\r\n}\r\nstatic int em_cmp_match(struct sk_buff *skb, struct tcf_ematch *em,\r\nstruct tcf_pkt_info *info)\r\n{\r\nstruct tcf_em_cmp *cmp = (struct tcf_em_cmp *) em->data;\r\nunsigned char *ptr = tcf_get_base_ptr(skb, cmp->layer) + cmp->off;\r\nu32 val = 0;\r\nif (!tcf_valid_offset(skb, ptr, cmp->align))\r\nreturn 0;\r\nswitch (cmp->align) {\r\ncase TCF_EM_ALIGN_U8:\r\nval = *ptr;\r\nbreak;\r\ncase TCF_EM_ALIGN_U16:\r\nval = get_unaligned_be16(ptr);\r\nif (cmp_needs_transformation(cmp))\r\nval = be16_to_cpu(val);\r\nbreak;\r\ncase TCF_EM_ALIGN_U32:\r\nval = get_unaligned_be32(ptr);\r\nif (cmp_needs_transformation(cmp))\r\nval = be32_to_cpu(val);\r\nbreak;\r\ndefault:\r\nreturn 0;\r\n}\r\nif (cmp->mask)\r\nval &= cmp->mask;\r\nswitch (cmp->opnd) {\r\ncase TCF_EM_OPND_EQ:\r\nreturn val == cmp->val;\r\ncase TCF_EM_OPND_LT:\r\nreturn val < cmp->val;\r\ncase TCF_EM_OPND_GT:\r\nreturn val > cmp->val;\r\n}\r\nreturn 0;\r\n}\r\nstatic int __init init_em_cmp(void)\r\n{\r\nreturn tcf_em_register(&em_cmp_ops);\r\n}\r\nstatic void __exit exit_em_cmp(void)\r\n{\r\ntcf_em_unregister(&em_cmp_ops);\r\n}
