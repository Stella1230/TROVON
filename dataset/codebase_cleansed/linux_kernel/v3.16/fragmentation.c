static void batadv_frag_clear_chain(struct hlist_head *head)\r\n{\r\nstruct batadv_frag_list_entry *entry;\r\nstruct hlist_node *node;\r\nhlist_for_each_entry_safe(entry, node, head, list) {\r\nhlist_del(&entry->list);\r\nkfree_skb(entry->skb);\r\nkfree(entry);\r\n}\r\n}\r\nvoid batadv_frag_purge_orig(struct batadv_orig_node *orig_node,\r\nbool (*check_cb)(struct batadv_frag_table_entry *))\r\n{\r\nstruct batadv_frag_table_entry *chain;\r\nuint8_t i;\r\nfor (i = 0; i < BATADV_FRAG_BUFFER_COUNT; i++) {\r\nchain = &orig_node->fragments[i];\r\nspin_lock_bh(&orig_node->fragments[i].lock);\r\nif (!check_cb || check_cb(chain)) {\r\nbatadv_frag_clear_chain(&orig_node->fragments[i].head);\r\norig_node->fragments[i].size = 0;\r\n}\r\nspin_unlock_bh(&orig_node->fragments[i].lock);\r\n}\r\n}\r\nstatic int batadv_frag_size_limit(void)\r\n{\r\nint limit = BATADV_FRAG_MAX_FRAG_SIZE;\r\nlimit -= sizeof(struct batadv_frag_packet);\r\nlimit *= BATADV_FRAG_MAX_FRAGMENTS;\r\nreturn limit;\r\n}\r\nstatic bool batadv_frag_init_chain(struct batadv_frag_table_entry *chain,\r\nuint16_t seqno)\r\n{\r\nif (chain->seqno == seqno)\r\nreturn false;\r\nif (!hlist_empty(&chain->head))\r\nbatadv_frag_clear_chain(&chain->head);\r\nchain->size = 0;\r\nchain->seqno = seqno;\r\nreturn true;\r\n}\r\nstatic bool batadv_frag_insert_packet(struct batadv_orig_node *orig_node,\r\nstruct sk_buff *skb,\r\nstruct hlist_head *chain_out)\r\n{\r\nstruct batadv_frag_table_entry *chain;\r\nstruct batadv_frag_list_entry *frag_entry_new = NULL, *frag_entry_curr;\r\nstruct batadv_frag_packet *frag_packet;\r\nuint8_t bucket;\r\nuint16_t seqno, hdr_size = sizeof(struct batadv_frag_packet);\r\nbool ret = false;\r\nif (skb_linearize(skb) < 0)\r\ngoto err;\r\nfrag_packet = (struct batadv_frag_packet *)skb->data;\r\nseqno = ntohs(frag_packet->seqno);\r\nbucket = seqno % BATADV_FRAG_BUFFER_COUNT;\r\nfrag_entry_new = kmalloc(sizeof(*frag_entry_new), GFP_ATOMIC);\r\nif (!frag_entry_new)\r\ngoto err;\r\nfrag_entry_new->skb = skb;\r\nfrag_entry_new->no = frag_packet->no;\r\nchain = &orig_node->fragments[bucket];\r\nspin_lock_bh(&chain->lock);\r\nif (batadv_frag_init_chain(chain, seqno)) {\r\nhlist_add_head(&frag_entry_new->list, &chain->head);\r\nchain->size = skb->len - hdr_size;\r\nchain->timestamp = jiffies;\r\nret = true;\r\ngoto out;\r\n}\r\nhlist_for_each_entry(frag_entry_curr, &chain->head, list) {\r\nif (frag_entry_curr->no == frag_entry_new->no)\r\ngoto err_unlock;\r\nif (frag_entry_curr->no < frag_entry_new->no) {\r\nhlist_add_before(&frag_entry_new->list,\r\n&frag_entry_curr->list);\r\nchain->size += skb->len - hdr_size;\r\nchain->timestamp = jiffies;\r\nret = true;\r\ngoto out;\r\n}\r\n}\r\nif (likely(frag_entry_curr)) {\r\nhlist_add_after(&frag_entry_curr->list, &frag_entry_new->list);\r\nchain->size += skb->len - hdr_size;\r\nchain->timestamp = jiffies;\r\nret = true;\r\n}\r\nout:\r\nif (chain->size > batadv_frag_size_limit() ||\r\nntohs(frag_packet->total_size) > batadv_frag_size_limit()) {\r\nbatadv_frag_clear_chain(&chain->head);\r\nchain->size = 0;\r\n} else if (ntohs(frag_packet->total_size) == chain->size) {\r\nhlist_move_list(&chain->head, chain_out);\r\nchain->size = 0;\r\n}\r\nerr_unlock:\r\nspin_unlock_bh(&chain->lock);\r\nerr:\r\nif (!ret)\r\nkfree(frag_entry_new);\r\nreturn ret;\r\n}\r\nstatic struct sk_buff *\r\nbatadv_frag_merge_packets(struct hlist_head *chain, struct sk_buff *skb)\r\n{\r\nstruct batadv_frag_packet *packet;\r\nstruct batadv_frag_list_entry *entry;\r\nstruct sk_buff *skb_out = NULL;\r\nint size, hdr_size = sizeof(struct batadv_frag_packet);\r\npacket = (struct batadv_frag_packet *)skb->data;\r\nsize = ntohs(packet->total_size);\r\nif (size > batadv_frag_size_limit())\r\ngoto free;\r\nentry = hlist_entry(chain->first, struct batadv_frag_list_entry, list);\r\nhlist_del(&entry->list);\r\nskb_out = entry->skb;\r\nkfree(entry);\r\nif (pskb_expand_head(skb_out, 0, size - skb->len, GFP_ATOMIC) < 0) {\r\nkfree_skb(skb_out);\r\nskb_out = NULL;\r\ngoto free;\r\n}\r\nskb_pull_rcsum(skb_out, hdr_size);\r\nmemmove(skb_out->data - ETH_HLEN, skb_mac_header(skb_out), ETH_HLEN);\r\nskb_set_mac_header(skb_out, -ETH_HLEN);\r\nskb_reset_network_header(skb_out);\r\nskb_reset_transport_header(skb_out);\r\nhlist_for_each_entry(entry, chain, list) {\r\nsize = entry->skb->len - hdr_size;\r\nmemcpy(skb_put(skb_out, size), entry->skb->data + hdr_size,\r\nsize);\r\n}\r\nfree:\r\nbatadv_frag_clear_chain(chain);\r\nreturn skb_out;\r\n}\r\nbool batadv_frag_skb_buffer(struct sk_buff **skb,\r\nstruct batadv_orig_node *orig_node_src)\r\n{\r\nstruct sk_buff *skb_out = NULL;\r\nstruct hlist_head head = HLIST_HEAD_INIT;\r\nbool ret = false;\r\nif (!batadv_frag_insert_packet(orig_node_src, *skb, &head))\r\ngoto out_err;\r\nif (hlist_empty(&head))\r\ngoto out;\r\nskb_out = batadv_frag_merge_packets(&head, *skb);\r\nif (!skb_out)\r\ngoto out_err;\r\nout:\r\n*skb = skb_out;\r\nret = true;\r\nout_err:\r\nreturn ret;\r\n}\r\nbool batadv_frag_skb_fwd(struct sk_buff *skb,\r\nstruct batadv_hard_iface *recv_if,\r\nstruct batadv_orig_node *orig_node_src)\r\n{\r\nstruct batadv_priv *bat_priv = netdev_priv(recv_if->soft_iface);\r\nstruct batadv_orig_node *orig_node_dst = NULL;\r\nstruct batadv_neigh_node *neigh_node = NULL;\r\nstruct batadv_frag_packet *packet;\r\nuint16_t total_size;\r\nbool ret = false;\r\npacket = (struct batadv_frag_packet *)skb->data;\r\norig_node_dst = batadv_orig_hash_find(bat_priv, packet->dest);\r\nif (!orig_node_dst)\r\ngoto out;\r\nneigh_node = batadv_find_router(bat_priv, orig_node_dst, recv_if);\r\nif (!neigh_node)\r\ngoto out;\r\ntotal_size = ntohs(packet->total_size);\r\nif (total_size > neigh_node->if_incoming->net_dev->mtu) {\r\nbatadv_inc_counter(bat_priv, BATADV_CNT_FRAG_FWD);\r\nbatadv_add_counter(bat_priv, BATADV_CNT_FRAG_FWD_BYTES,\r\nskb->len + ETH_HLEN);\r\npacket->ttl--;\r\nbatadv_send_skb_packet(skb, neigh_node->if_incoming,\r\nneigh_node->addr);\r\nret = true;\r\n}\r\nout:\r\nif (orig_node_dst)\r\nbatadv_orig_node_free_ref(orig_node_dst);\r\nif (neigh_node)\r\nbatadv_neigh_node_free_ref(neigh_node);\r\nreturn ret;\r\n}\r\nstatic struct sk_buff *batadv_frag_create(struct sk_buff *skb,\r\nstruct batadv_frag_packet *frag_head,\r\nunsigned int mtu)\r\n{\r\nstruct sk_buff *skb_fragment;\r\nunsigned header_size = sizeof(*frag_head);\r\nunsigned fragment_size = mtu - header_size;\r\nskb_fragment = netdev_alloc_skb(NULL, mtu + ETH_HLEN);\r\nif (!skb_fragment)\r\ngoto err;\r\nskb->priority = TC_PRIO_CONTROL;\r\nskb_reserve(skb_fragment, header_size + ETH_HLEN);\r\nskb_split(skb, skb_fragment, skb->len - fragment_size);\r\nskb_push(skb_fragment, header_size);\r\nmemcpy(skb_fragment->data, frag_head, header_size);\r\nerr:\r\nreturn skb_fragment;\r\n}\r\nbool batadv_frag_send_packet(struct sk_buff *skb,\r\nstruct batadv_orig_node *orig_node,\r\nstruct batadv_neigh_node *neigh_node)\r\n{\r\nstruct batadv_priv *bat_priv;\r\nstruct batadv_hard_iface *primary_if = NULL;\r\nstruct batadv_frag_packet frag_header;\r\nstruct sk_buff *skb_fragment;\r\nunsigned mtu = neigh_node->if_incoming->net_dev->mtu;\r\nunsigned header_size = sizeof(frag_header);\r\nunsigned max_fragment_size, max_packet_size;\r\nbool ret = false;\r\nmtu = min_t(unsigned, mtu, BATADV_FRAG_MAX_FRAG_SIZE);\r\nmax_fragment_size = (mtu - header_size - ETH_HLEN);\r\nmax_packet_size = max_fragment_size * BATADV_FRAG_MAX_FRAGMENTS;\r\nif (skb->len > max_packet_size)\r\ngoto out_err;\r\nbat_priv = orig_node->bat_priv;\r\nprimary_if = batadv_primary_if_get_selected(bat_priv);\r\nif (!primary_if)\r\ngoto out_err;\r\nfrag_header.packet_type = BATADV_UNICAST_FRAG;\r\nfrag_header.version = BATADV_COMPAT_VERSION;\r\nfrag_header.ttl = BATADV_TTL;\r\nfrag_header.seqno = htons(atomic_inc_return(&bat_priv->frag_seqno));\r\nfrag_header.reserved = 0;\r\nfrag_header.no = 0;\r\nfrag_header.total_size = htons(skb->len);\r\nether_addr_copy(frag_header.orig, primary_if->net_dev->dev_addr);\r\nether_addr_copy(frag_header.dest, orig_node->orig);\r\nwhile (skb->len > max_fragment_size) {\r\nskb_fragment = batadv_frag_create(skb, &frag_header, mtu);\r\nif (!skb_fragment)\r\ngoto out_err;\r\nbatadv_inc_counter(bat_priv, BATADV_CNT_FRAG_TX);\r\nbatadv_add_counter(bat_priv, BATADV_CNT_FRAG_TX_BYTES,\r\nskb_fragment->len + ETH_HLEN);\r\nbatadv_send_skb_packet(skb_fragment, neigh_node->if_incoming,\r\nneigh_node->addr);\r\nfrag_header.no++;\r\nif (frag_header.no == BATADV_FRAG_MAX_FRAGMENTS - 1)\r\ngoto out_err;\r\n}\r\nif (batadv_skb_head_push(skb, header_size) < 0 ||\r\npskb_expand_head(skb, header_size + ETH_HLEN, 0, GFP_ATOMIC) < 0)\r\ngoto out_err;\r\nmemcpy(skb->data, &frag_header, header_size);\r\nbatadv_inc_counter(bat_priv, BATADV_CNT_FRAG_TX);\r\nbatadv_add_counter(bat_priv, BATADV_CNT_FRAG_TX_BYTES,\r\nskb->len + ETH_HLEN);\r\nbatadv_send_skb_packet(skb, neigh_node->if_incoming, neigh_node->addr);\r\nret = true;\r\nout_err:\r\nif (primary_if)\r\nbatadv_hardif_free_ref(primary_if);\r\nreturn ret;\r\n}
