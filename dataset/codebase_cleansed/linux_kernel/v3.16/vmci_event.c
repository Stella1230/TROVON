int __init vmci_event_init(void)\r\n{\r\nint i;\r\nfor (i = 0; i < VMCI_EVENT_MAX; i++)\r\nINIT_LIST_HEAD(&subscriber_array[i]);\r\nreturn VMCI_SUCCESS;\r\n}\r\nvoid vmci_event_exit(void)\r\n{\r\nint e;\r\nfor (e = 0; e < VMCI_EVENT_MAX; e++) {\r\nstruct vmci_subscription *cur, *p2;\r\nlist_for_each_entry_safe(cur, p2, &subscriber_array[e], node) {\r\npr_warn("Unexpected free events occurring\n");\r\nlist_del(&cur->node);\r\nkfree(cur);\r\n}\r\n}\r\n}\r\nstatic struct vmci_subscription *event_find(u32 sub_id)\r\n{\r\nint e;\r\nfor (e = 0; e < VMCI_EVENT_MAX; e++) {\r\nstruct vmci_subscription *cur;\r\nlist_for_each_entry(cur, &subscriber_array[e], node) {\r\nif (cur->id == sub_id)\r\nreturn cur;\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nstatic void event_deliver(struct vmci_event_msg *event_msg)\r\n{\r\nstruct vmci_subscription *cur;\r\nstruct list_head *subscriber_list;\r\nrcu_read_lock();\r\nsubscriber_list = &subscriber_array[event_msg->event_data.event];\r\nlist_for_each_entry_rcu(cur, subscriber_list, node) {\r\ncur->callback(cur->id, &event_msg->event_data,\r\ncur->callback_data);\r\n}\r\nrcu_read_unlock();\r\n}\r\nint vmci_event_dispatch(struct vmci_datagram *msg)\r\n{\r\nstruct vmci_event_msg *event_msg = (struct vmci_event_msg *)msg;\r\nif (msg->payload_size < sizeof(u32) ||\r\nmsg->payload_size > sizeof(struct vmci_event_data_max))\r\nreturn VMCI_ERROR_INVALID_ARGS;\r\nif (!VMCI_EVENT_VALID(event_msg->event_data.event))\r\nreturn VMCI_ERROR_EVENT_UNKNOWN;\r\nevent_deliver(event_msg);\r\nreturn VMCI_SUCCESS;\r\n}\r\nint vmci_event_subscribe(u32 event,\r\nvmci_event_cb callback,\r\nvoid *callback_data,\r\nu32 *new_subscription_id)\r\n{\r\nstruct vmci_subscription *sub;\r\nint attempts;\r\nint retval;\r\nbool have_new_id = false;\r\nif (!new_subscription_id) {\r\npr_devel("%s: Invalid subscription (NULL)\n", __func__);\r\nreturn VMCI_ERROR_INVALID_ARGS;\r\n}\r\nif (!VMCI_EVENT_VALID(event) || !callback) {\r\npr_devel("%s: Failed to subscribe to event (type=%d) (callback=%p) (data=%p)\n",\r\n__func__, event, callback, callback_data);\r\nreturn VMCI_ERROR_INVALID_ARGS;\r\n}\r\nsub = kzalloc(sizeof(*sub), GFP_KERNEL);\r\nif (!sub)\r\nreturn VMCI_ERROR_NO_MEM;\r\nsub->id = VMCI_EVENT_MAX;\r\nsub->event = event;\r\nsub->callback = callback;\r\nsub->callback_data = callback_data;\r\nINIT_LIST_HEAD(&sub->node);\r\nmutex_lock(&subscriber_mutex);\r\nfor (attempts = 0; attempts < VMCI_EVENT_MAX_ATTEMPTS; attempts++) {\r\nstatic u32 subscription_id;\r\nif (!event_find(++subscription_id)) {\r\nsub->id = subscription_id;\r\nhave_new_id = true;\r\nbreak;\r\n}\r\n}\r\nif (have_new_id) {\r\nlist_add_rcu(&sub->node, &subscriber_array[event]);\r\nretval = VMCI_SUCCESS;\r\n} else {\r\nretval = VMCI_ERROR_NO_RESOURCES;\r\n}\r\nmutex_unlock(&subscriber_mutex);\r\n*new_subscription_id = sub->id;\r\nreturn retval;\r\n}\r\nint vmci_event_unsubscribe(u32 sub_id)\r\n{\r\nstruct vmci_subscription *s;\r\nmutex_lock(&subscriber_mutex);\r\ns = event_find(sub_id);\r\nif (s)\r\nlist_del_rcu(&s->node);\r\nmutex_unlock(&subscriber_mutex);\r\nif (!s)\r\nreturn VMCI_ERROR_NOT_FOUND;\r\nsynchronize_rcu();\r\nkfree(s);\r\nreturn VMCI_SUCCESS;\r\n}
