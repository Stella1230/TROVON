static bool is_admin_up(struct net_device *dev)\r\n{\r\nreturn dev && (dev->flags & IFF_UP);\r\n}\r\nstatic bool is_slave_up(struct net_device *dev)\r\n{\r\nreturn dev && is_admin_up(dev) && netif_oper_up(dev);\r\n}\r\nstatic void __hsr_set_operstate(struct net_device *dev, int transition)\r\n{\r\nwrite_lock_bh(&dev_base_lock);\r\nif (dev->operstate != transition) {\r\ndev->operstate = transition;\r\nwrite_unlock_bh(&dev_base_lock);\r\nnetdev_state_change(dev);\r\n} else {\r\nwrite_unlock_bh(&dev_base_lock);\r\n}\r\n}\r\nvoid hsr_set_operstate(struct net_device *hsr_dev, struct net_device *slave1,\r\nstruct net_device *slave2)\r\n{\r\nif (!is_admin_up(hsr_dev)) {\r\n__hsr_set_operstate(hsr_dev, IF_OPER_DOWN);\r\nreturn;\r\n}\r\nif (is_slave_up(slave1) || is_slave_up(slave2))\r\n__hsr_set_operstate(hsr_dev, IF_OPER_UP);\r\nelse\r\n__hsr_set_operstate(hsr_dev, IF_OPER_LOWERLAYERDOWN);\r\n}\r\nvoid hsr_set_carrier(struct net_device *hsr_dev, struct net_device *slave1,\r\nstruct net_device *slave2)\r\n{\r\nif (is_slave_up(slave1) || is_slave_up(slave2))\r\nnetif_carrier_on(hsr_dev);\r\nelse\r\nnetif_carrier_off(hsr_dev);\r\n}\r\nvoid hsr_check_announce(struct net_device *hsr_dev, int old_operstate)\r\n{\r\nstruct hsr_priv *hsr_priv;\r\nhsr_priv = netdev_priv(hsr_dev);\r\nif ((hsr_dev->operstate == IF_OPER_UP) && (old_operstate != IF_OPER_UP)) {\r\nhsr_priv->announce_count = 0;\r\nhsr_priv->announce_timer.expires = jiffies +\r\nmsecs_to_jiffies(HSR_ANNOUNCE_INTERVAL);\r\nadd_timer(&hsr_priv->announce_timer);\r\n}\r\nif ((hsr_dev->operstate != IF_OPER_UP) && (old_operstate == IF_OPER_UP))\r\ndel_timer(&hsr_priv->announce_timer);\r\n}\r\nint hsr_get_max_mtu(struct hsr_priv *hsr_priv)\r\n{\r\nint mtu_max;\r\nif (hsr_priv->slave[0] && hsr_priv->slave[1])\r\nmtu_max = min(hsr_priv->slave[0]->mtu, hsr_priv->slave[1]->mtu);\r\nelse if (hsr_priv->slave[0])\r\nmtu_max = hsr_priv->slave[0]->mtu;\r\nelse if (hsr_priv->slave[1])\r\nmtu_max = hsr_priv->slave[1]->mtu;\r\nelse\r\nmtu_max = HSR_TAGLEN;\r\nreturn mtu_max - HSR_TAGLEN;\r\n}\r\nstatic int hsr_dev_change_mtu(struct net_device *dev, int new_mtu)\r\n{\r\nstruct hsr_priv *hsr_priv;\r\nhsr_priv = netdev_priv(dev);\r\nif (new_mtu > hsr_get_max_mtu(hsr_priv)) {\r\nnetdev_info(hsr_priv->dev, "A HSR master's MTU cannot be greater than the smallest MTU of its slaves minus the HSR Tag length (%d octets).\n",\r\nHSR_TAGLEN);\r\nreturn -EINVAL;\r\n}\r\ndev->mtu = new_mtu;\r\nreturn 0;\r\n}\r\nstatic int hsr_dev_open(struct net_device *dev)\r\n{\r\nstruct hsr_priv *hsr_priv;\r\nint i;\r\nchar *slave_name;\r\nhsr_priv = netdev_priv(dev);\r\nfor (i = 0; i < HSR_MAX_SLAVE; i++) {\r\nif (hsr_priv->slave[i])\r\nslave_name = hsr_priv->slave[i]->name;\r\nelse\r\nslave_name = "null";\r\nif (!is_slave_up(hsr_priv->slave[i]))\r\nnetdev_warn(dev, "Slave %c (%s) is not up; please bring it up to get a working HSR network\n",\r\n'A' + i, slave_name);\r\n}\r\nreturn 0;\r\n}\r\nstatic int hsr_dev_close(struct net_device *dev)\r\n{\r\nreturn 0;\r\n}\r\nstatic void hsr_fill_tag(struct hsr_ethhdr *hsr_ethhdr, struct hsr_priv *hsr_priv)\r\n{\r\nunsigned long irqflags;\r\nset_hsr_tag_path(&hsr_ethhdr->hsr_tag, 0x1);\r\nset_hsr_tag_LSDU_size(&hsr_ethhdr->hsr_tag, 0);\r\nspin_lock_irqsave(&hsr_priv->seqnr_lock, irqflags);\r\nhsr_ethhdr->hsr_tag.sequence_nr = htons(hsr_priv->sequence_nr);\r\nhsr_priv->sequence_nr++;\r\nspin_unlock_irqrestore(&hsr_priv->seqnr_lock, irqflags);\r\nhsr_ethhdr->hsr_tag.encap_proto = hsr_ethhdr->ethhdr.h_proto;\r\nhsr_ethhdr->ethhdr.h_proto = htons(ETH_P_PRP);\r\n}\r\nstatic int slave_xmit(struct sk_buff *skb, struct hsr_priv *hsr_priv,\r\nenum hsr_dev_idx dev_idx)\r\n{\r\nstruct hsr_ethhdr *hsr_ethhdr;\r\nhsr_ethhdr = (struct hsr_ethhdr *) skb->data;\r\nskb->dev = hsr_priv->slave[dev_idx];\r\nhsr_addr_subst_dest(hsr_priv, &hsr_ethhdr->ethhdr, dev_idx);\r\nether_addr_copy(hsr_ethhdr->ethhdr.h_source, skb->dev->dev_addr);\r\nreturn dev_queue_xmit(skb);\r\n}\r\nstatic int hsr_dev_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct hsr_priv *hsr_priv;\r\nstruct hsr_ethhdr *hsr_ethhdr;\r\nstruct sk_buff *skb2;\r\nint res1, res2;\r\nhsr_priv = netdev_priv(dev);\r\nhsr_ethhdr = (struct hsr_ethhdr *) skb->data;\r\nif ((skb->protocol != htons(ETH_P_PRP)) ||\r\n(hsr_ethhdr->ethhdr.h_proto != htons(ETH_P_PRP))) {\r\nhsr_fill_tag(hsr_ethhdr, hsr_priv);\r\nskb->protocol = htons(ETH_P_PRP);\r\n}\r\nskb2 = pskb_copy(skb, GFP_ATOMIC);\r\nres1 = NET_XMIT_DROP;\r\nif (likely(hsr_priv->slave[HSR_DEV_SLAVE_A]))\r\nres1 = slave_xmit(skb, hsr_priv, HSR_DEV_SLAVE_A);\r\nres2 = NET_XMIT_DROP;\r\nif (likely(skb2 && hsr_priv->slave[HSR_DEV_SLAVE_B]))\r\nres2 = slave_xmit(skb2, hsr_priv, HSR_DEV_SLAVE_B);\r\nif (likely(res1 == NET_XMIT_SUCCESS || res1 == NET_XMIT_CN ||\r\nres2 == NET_XMIT_SUCCESS || res2 == NET_XMIT_CN)) {\r\nhsr_priv->dev->stats.tx_packets++;\r\nhsr_priv->dev->stats.tx_bytes += skb->len;\r\n} else {\r\nhsr_priv->dev->stats.tx_dropped++;\r\n}\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic int hsr_header_create(struct sk_buff *skb, struct net_device *dev,\r\nunsigned short type, const void *daddr,\r\nconst void *saddr, unsigned int len)\r\n{\r\nint res;\r\nif (skb_headroom(skb) < HSR_TAGLEN + ETH_HLEN)\r\nreturn -ENOBUFS;\r\nskb_push(skb, HSR_TAGLEN);\r\nres = eth_header(skb, dev, type, daddr, saddr, len + HSR_TAGLEN);\r\nif (res <= 0)\r\nreturn res;\r\nskb_reset_mac_header(skb);\r\nreturn res + HSR_TAGLEN;\r\n}\r\nstatic int hsr_pad(int size)\r\n{\r\nconst int min_size = ETH_ZLEN - HSR_TAGLEN - ETH_HLEN;\r\nif (size >= min_size)\r\nreturn size;\r\nreturn min_size;\r\n}\r\nstatic void send_hsr_supervision_frame(struct net_device *hsr_dev, u8 type)\r\n{\r\nstruct hsr_priv *hsr_priv;\r\nstruct sk_buff *skb;\r\nint hlen, tlen;\r\nstruct hsr_sup_tag *hsr_stag;\r\nstruct hsr_sup_payload *hsr_sp;\r\nunsigned long irqflags;\r\nhlen = LL_RESERVED_SPACE(hsr_dev);\r\ntlen = hsr_dev->needed_tailroom;\r\nskb = alloc_skb(hsr_pad(sizeof(struct hsr_sup_payload)) + hlen + tlen,\r\nGFP_ATOMIC);\r\nif (skb == NULL)\r\nreturn;\r\nhsr_priv = netdev_priv(hsr_dev);\r\nskb_reserve(skb, hlen);\r\nskb->dev = hsr_dev;\r\nskb->protocol = htons(ETH_P_PRP);\r\nskb->priority = TC_PRIO_CONTROL;\r\nif (dev_hard_header(skb, skb->dev, ETH_P_PRP,\r\nhsr_priv->sup_multicast_addr,\r\nskb->dev->dev_addr, skb->len) < 0)\r\ngoto out;\r\nskb_pull(skb, sizeof(struct ethhdr));\r\nhsr_stag = (typeof(hsr_stag)) skb->data;\r\nset_hsr_stag_path(hsr_stag, 0xf);\r\nset_hsr_stag_HSR_Ver(hsr_stag, 0);\r\nspin_lock_irqsave(&hsr_priv->seqnr_lock, irqflags);\r\nhsr_stag->sequence_nr = htons(hsr_priv->sequence_nr);\r\nhsr_priv->sequence_nr++;\r\nspin_unlock_irqrestore(&hsr_priv->seqnr_lock, irqflags);\r\nhsr_stag->HSR_TLV_Type = type;\r\nhsr_stag->HSR_TLV_Length = 12;\r\nskb_push(skb, sizeof(struct ethhdr));\r\nhsr_sp = (typeof(hsr_sp)) skb_put(skb, sizeof(*hsr_sp));\r\nether_addr_copy(hsr_sp->MacAddressA, hsr_dev->dev_addr);\r\ndev_queue_xmit(skb);\r\nreturn;\r\nout:\r\nkfree_skb(skb);\r\n}\r\nstatic void hsr_announce(unsigned long data)\r\n{\r\nstruct hsr_priv *hsr_priv;\r\nhsr_priv = (struct hsr_priv *) data;\r\nif (hsr_priv->announce_count < 3) {\r\nsend_hsr_supervision_frame(hsr_priv->dev, HSR_TLV_ANNOUNCE);\r\nhsr_priv->announce_count++;\r\n} else {\r\nsend_hsr_supervision_frame(hsr_priv->dev, HSR_TLV_LIFE_CHECK);\r\n}\r\nif (hsr_priv->announce_count < 3)\r\nhsr_priv->announce_timer.expires = jiffies +\r\nmsecs_to_jiffies(HSR_ANNOUNCE_INTERVAL);\r\nelse\r\nhsr_priv->announce_timer.expires = jiffies +\r\nmsecs_to_jiffies(HSR_LIFE_CHECK_INTERVAL);\r\nif (is_admin_up(hsr_priv->dev))\r\nadd_timer(&hsr_priv->announce_timer);\r\n}\r\nstatic void restore_slaves(struct net_device *hsr_dev)\r\n{\r\nstruct hsr_priv *hsr_priv;\r\nint i;\r\nint res;\r\nhsr_priv = netdev_priv(hsr_dev);\r\nrtnl_lock();\r\nfor (i = 0; i < HSR_MAX_SLAVE; i++) {\r\nif (!hsr_priv->slave[i])\r\ncontinue;\r\nres = dev_set_promiscuity(hsr_priv->slave[i], -1);\r\nif (res)\r\nnetdev_info(hsr_dev,\r\n"Cannot restore slave promiscuity (%s, %d)\n",\r\nhsr_priv->slave[i]->name, res);\r\n}\r\nrtnl_unlock();\r\n}\r\nstatic void reclaim_hsr_dev(struct rcu_head *rh)\r\n{\r\nstruct hsr_priv *hsr_priv;\r\nhsr_priv = container_of(rh, struct hsr_priv, rcu_head);\r\nfree_netdev(hsr_priv->dev);\r\n}\r\nstatic void hsr_dev_destroy(struct net_device *hsr_dev)\r\n{\r\nstruct hsr_priv *hsr_priv;\r\nhsr_priv = netdev_priv(hsr_dev);\r\ndel_timer(&hsr_priv->announce_timer);\r\nunregister_hsr_master(hsr_priv);\r\nrestore_slaves(hsr_dev);\r\ncall_rcu(&hsr_priv->rcu_head, reclaim_hsr_dev);\r\n}\r\nvoid hsr_dev_setup(struct net_device *dev)\r\n{\r\nrandom_ether_addr(dev->dev_addr);\r\nether_setup(dev);\r\ndev->header_ops = &hsr_header_ops;\r\ndev->netdev_ops = &hsr_device_ops;\r\ndev->tx_queue_len = 0;\r\ndev->destructor = hsr_dev_destroy;\r\n}\r\nbool is_hsr_master(struct net_device *dev)\r\n{\r\nreturn (dev->netdev_ops->ndo_start_xmit == hsr_dev_xmit);\r\n}\r\nstatic int check_slave_ok(struct net_device *dev)\r\n{\r\nif ((dev->flags & IFF_LOOPBACK) || (dev->type != ARPHRD_ETHER) ||\r\n(dev->addr_len != ETH_ALEN)) {\r\nnetdev_info(dev, "Cannot use loopback or non-ethernet device as HSR slave.\n");\r\nreturn -EINVAL;\r\n}\r\nif (is_hsr_master(dev)) {\r\nnetdev_info(dev, "Cannot create trees of HSR devices.\n");\r\nreturn -EINVAL;\r\n}\r\nif (is_hsr_slave(dev)) {\r\nnetdev_info(dev, "This device is already a HSR slave.\n");\r\nreturn -EINVAL;\r\n}\r\nif (dev->priv_flags & IFF_802_1Q_VLAN) {\r\nnetdev_info(dev, "HSR on top of VLAN is not yet supported in this driver.\n");\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nint hsr_dev_finalize(struct net_device *hsr_dev, struct net_device *slave[2],\r\nunsigned char multicast_spec)\r\n{\r\nstruct hsr_priv *hsr_priv;\r\nint i;\r\nint res;\r\nhsr_priv = netdev_priv(hsr_dev);\r\nhsr_priv->dev = hsr_dev;\r\nINIT_LIST_HEAD(&hsr_priv->node_db);\r\nINIT_LIST_HEAD(&hsr_priv->self_node_db);\r\nfor (i = 0; i < HSR_MAX_SLAVE; i++)\r\nhsr_priv->slave[i] = slave[i];\r\nspin_lock_init(&hsr_priv->seqnr_lock);\r\nhsr_priv->sequence_nr = USHRT_MAX - 1024;\r\ninit_timer(&hsr_priv->announce_timer);\r\nhsr_priv->announce_timer.function = hsr_announce;\r\nhsr_priv->announce_timer.data = (unsigned long) hsr_priv;\r\nether_addr_copy(hsr_priv->sup_multicast_addr, def_multicast_addr);\r\nhsr_priv->sup_multicast_addr[ETH_ALEN - 1] = multicast_spec;\r\nfor (i = 0; i < HSR_MAX_SLAVE; i++) {\r\nres = check_slave_ok(slave[i]);\r\nif (res)\r\nreturn res;\r\n}\r\nhsr_dev->features = slave[0]->features & slave[1]->features;\r\nhsr_dev->features |= NETIF_F_LLTX;\r\nhsr_dev->features |= NETIF_F_VLAN_CHALLENGED;\r\nether_addr_copy(hsr_dev->dev_addr, hsr_priv->slave[0]->dev_addr);\r\nfor (i = 0; i < HSR_MAX_SLAVE; i++) {\r\nif (slave[i]->hard_header_len + HSR_TAGLEN >\r\nhsr_dev->hard_header_len)\r\nhsr_dev->hard_header_len =\r\nslave[i]->hard_header_len + HSR_TAGLEN;\r\n}\r\nfor (i = 0; i < HSR_MAX_SLAVE; i++)\r\nif (slave[i]->mtu - HSR_TAGLEN < hsr_dev->mtu)\r\nhsr_dev->mtu = slave[i]->mtu - HSR_TAGLEN;\r\nnetif_carrier_off(hsr_dev);\r\nfor (i = 0; i < HSR_MAX_SLAVE; i++) {\r\nres = dev_set_promiscuity(slave[i], 1);\r\nif (res) {\r\nnetdev_info(hsr_dev, "Cannot set slave promiscuity (%s, %d)\n",\r\nslave[i]->name, res);\r\ngoto fail;\r\n}\r\n}\r\nres = hsr_create_self_node(&hsr_priv->self_node_db,\r\nhsr_dev->dev_addr,\r\nhsr_priv->slave[1]->dev_addr);\r\nif (res < 0)\r\ngoto fail;\r\nres = register_netdevice(hsr_dev);\r\nif (res)\r\ngoto fail;\r\nregister_hsr_master(hsr_priv);\r\nreturn 0;\r\nfail:\r\nrestore_slaves(hsr_dev);\r\nreturn res;\r\n}
