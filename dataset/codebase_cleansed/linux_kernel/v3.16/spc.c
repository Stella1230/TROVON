static inline bool cluster_is_a15(u32 cluster)\r\n{\r\nreturn cluster == info->a15_clusid;\r\n}\r\nvoid ve_spc_global_wakeup_irq(bool set)\r\n{\r\nu32 reg;\r\nreg = readl_relaxed(info->baseaddr + WAKE_INT_MASK);\r\nif (set)\r\nreg |= GBL_WAKEUP_INT_MSK;\r\nelse\r\nreg &= ~GBL_WAKEUP_INT_MSK;\r\nwritel_relaxed(reg, info->baseaddr + WAKE_INT_MASK);\r\n}\r\nvoid ve_spc_cpu_wakeup_irq(u32 cluster, u32 cpu, bool set)\r\n{\r\nu32 mask, reg;\r\nif (cluster >= MAX_CLUSTERS)\r\nreturn;\r\nmask = 1 << cpu;\r\nif (!cluster_is_a15(cluster))\r\nmask <<= 4;\r\nreg = readl_relaxed(info->baseaddr + WAKE_INT_MASK);\r\nif (set)\r\nreg |= mask;\r\nelse\r\nreg &= ~mask;\r\nwritel_relaxed(reg, info->baseaddr + WAKE_INT_MASK);\r\n}\r\nvoid ve_spc_set_resume_addr(u32 cluster, u32 cpu, u32 addr)\r\n{\r\nvoid __iomem *baseaddr;\r\nif (cluster >= MAX_CLUSTERS)\r\nreturn;\r\nif (cluster_is_a15(cluster))\r\nbaseaddr = info->baseaddr + A15_BX_ADDR0 + (cpu << 2);\r\nelse\r\nbaseaddr = info->baseaddr + A7_BX_ADDR0 + (cpu << 2);\r\nwritel_relaxed(addr, baseaddr);\r\n}\r\nvoid ve_spc_powerdown(u32 cluster, bool enable)\r\n{\r\nu32 pwdrn_reg;\r\nif (cluster >= MAX_CLUSTERS)\r\nreturn;\r\npwdrn_reg = cluster_is_a15(cluster) ? A15_PWRDN_EN : A7_PWRDN_EN;\r\nwritel_relaxed(enable, info->baseaddr + pwdrn_reg);\r\n}\r\nstatic u32 standbywfi_cpu_mask(u32 cpu, u32 cluster)\r\n{\r\nreturn cluster_is_a15(cluster) ?\r\nSTANDBYWFI_STAT_A15_CPU_MASK(cpu)\r\n: STANDBYWFI_STAT_A7_CPU_MASK(cpu);\r\n}\r\nint ve_spc_cpu_in_wfi(u32 cpu, u32 cluster)\r\n{\r\nint ret;\r\nu32 mask = standbywfi_cpu_mask(cpu, cluster);\r\nif (cluster >= MAX_CLUSTERS)\r\nreturn 1;\r\nret = readl_relaxed(info->baseaddr + STANDBYWFI_STAT);\r\npr_debug("%s: PCFGREG[0x%X] = 0x%08X, mask = 0x%X\n",\r\n__func__, STANDBYWFI_STAT, ret, mask);\r\nreturn ret & mask;\r\n}\r\nstatic int ve_spc_get_performance(int cluster, u32 *freq)\r\n{\r\nstruct ve_spc_opp *opps = info->opps[cluster];\r\nu32 perf_cfg_reg = 0;\r\nu32 perf;\r\nperf_cfg_reg = cluster_is_a15(cluster) ? PERF_LVL_A15 : PERF_LVL_A7;\r\nperf = readl_relaxed(info->baseaddr + perf_cfg_reg);\r\nif (perf >= info->num_opps[cluster])\r\nreturn -EINVAL;\r\nopps += perf;\r\n*freq = opps->freq;\r\nreturn 0;\r\n}\r\nstatic int ve_spc_round_performance(int cluster, u32 freq)\r\n{\r\nint idx, max_opp = info->num_opps[cluster];\r\nstruct ve_spc_opp *opps = info->opps[cluster];\r\nu32 fmin = 0, fmax = ~0, ftmp;\r\nfreq /= 1000;\r\nfor (idx = 0; idx < max_opp; idx++, opps++) {\r\nftmp = opps->freq;\r\nif (ftmp >= freq) {\r\nif (ftmp <= fmax)\r\nfmax = ftmp;\r\n} else {\r\nif (ftmp >= fmin)\r\nfmin = ftmp;\r\n}\r\n}\r\nif (fmax != ~0)\r\nreturn fmax * 1000;\r\nelse\r\nreturn fmin * 1000;\r\n}\r\nstatic int ve_spc_find_performance_index(int cluster, u32 freq)\r\n{\r\nint idx, max_opp = info->num_opps[cluster];\r\nstruct ve_spc_opp *opps = info->opps[cluster];\r\nfor (idx = 0; idx < max_opp; idx++, opps++)\r\nif (opps->freq == freq)\r\nbreak;\r\nreturn (idx == max_opp) ? -EINVAL : idx;\r\n}\r\nstatic int ve_spc_waitforcompletion(int req_type)\r\n{\r\nint ret = wait_for_completion_interruptible_timeout(\r\n&info->done, usecs_to_jiffies(TIMEOUT_US));\r\nif (ret == 0)\r\nret = -ETIMEDOUT;\r\nelse if (ret > 0)\r\nret = info->cur_rsp_stat & STAT_COMPLETE(req_type) ? 0 : -EIO;\r\nreturn ret;\r\n}\r\nstatic int ve_spc_set_performance(int cluster, u32 freq)\r\n{\r\nu32 perf_cfg_reg, perf_stat_reg;\r\nint ret, perf, req_type;\r\nif (cluster_is_a15(cluster)) {\r\nreq_type = CA15_DVFS;\r\nperf_cfg_reg = PERF_LVL_A15;\r\nperf_stat_reg = PERF_REQ_A15;\r\n} else {\r\nreq_type = CA7_DVFS;\r\nperf_cfg_reg = PERF_LVL_A7;\r\nperf_stat_reg = PERF_REQ_A7;\r\n}\r\nperf = ve_spc_find_performance_index(cluster, freq);\r\nif (perf < 0)\r\nreturn perf;\r\nif (down_timeout(&info->sem, usecs_to_jiffies(TIMEOUT_US)))\r\nreturn -ETIME;\r\ninit_completion(&info->done);\r\ninfo->cur_rsp_mask = RESPONSE_MASK(req_type);\r\nwritel(perf, info->baseaddr + perf_cfg_reg);\r\nret = ve_spc_waitforcompletion(req_type);\r\ninfo->cur_rsp_mask = 0;\r\nup(&info->sem);\r\nreturn ret;\r\n}\r\nstatic int ve_spc_read_sys_cfg(int func, int offset, uint32_t *data)\r\n{\r\nint ret;\r\nif (down_timeout(&info->sem, usecs_to_jiffies(TIMEOUT_US)))\r\nreturn -ETIME;\r\ninit_completion(&info->done);\r\ninfo->cur_rsp_mask = RESPONSE_MASK(SPC_SYS_CFG);\r\nwritel(SYSCFG_START | func | offset >> 2, info->baseaddr + COMMS);\r\nret = ve_spc_waitforcompletion(SPC_SYS_CFG);\r\nif (ret == 0)\r\n*data = readl(info->baseaddr + SYSCFG_RDATA);\r\ninfo->cur_rsp_mask = 0;\r\nup(&info->sem);\r\nreturn ret;\r\n}\r\nstatic irqreturn_t ve_spc_irq_handler(int irq, void *data)\r\n{\r\nstruct ve_spc_drvdata *drv_data = data;\r\nuint32_t status = readl_relaxed(drv_data->baseaddr + PWC_STATUS);\r\nif (info->cur_rsp_mask & status) {\r\ninfo->cur_rsp_stat = status;\r\ncomplete(&drv_data->done);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int ve_spc_populate_opps(uint32_t cluster)\r\n{\r\nuint32_t data = 0, off, ret, idx;\r\nstruct ve_spc_opp *opps;\r\nopps = kzalloc(sizeof(*opps) * MAX_OPPS, GFP_KERNEL);\r\nif (!opps)\r\nreturn -ENOMEM;\r\ninfo->opps[cluster] = opps;\r\noff = cluster_is_a15(cluster) ? A15_PERFVAL_BASE : A7_PERFVAL_BASE;\r\nfor (idx = 0; idx < MAX_OPPS; idx++, off += 4, opps++) {\r\nret = ve_spc_read_sys_cfg(SYSCFG_SCC, off, &data);\r\nif (!ret) {\r\nopps->freq = (data & FREQ_MASK) * MULT_FACTOR;\r\nopps->u_volt = (data >> VOLT_SHIFT) * 1000;\r\n} else {\r\nbreak;\r\n}\r\n}\r\ninfo->num_opps[cluster] = idx;\r\nreturn ret;\r\n}\r\nstatic int ve_init_opp_table(struct device *cpu_dev)\r\n{\r\nint cluster = topology_physical_package_id(cpu_dev->id);\r\nint idx, ret = 0, max_opp = info->num_opps[cluster];\r\nstruct ve_spc_opp *opps = info->opps[cluster];\r\nfor (idx = 0; idx < max_opp; idx++, opps++) {\r\nret = dev_pm_opp_add(cpu_dev, opps->freq * 1000, opps->u_volt);\r\nif (ret) {\r\ndev_warn(cpu_dev, "failed to add opp %lu %lu\n",\r\nopps->freq, opps->u_volt);\r\nreturn ret;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nint __init ve_spc_init(void __iomem *baseaddr, u32 a15_clusid, int irq)\r\n{\r\nint ret;\r\ninfo = kzalloc(sizeof(*info), GFP_KERNEL);\r\nif (!info) {\r\npr_err(SPCLOG "unable to allocate mem\n");\r\nreturn -ENOMEM;\r\n}\r\ninfo->baseaddr = baseaddr;\r\ninfo->a15_clusid = a15_clusid;\r\nif (irq <= 0) {\r\npr_err(SPCLOG "Invalid IRQ %d\n", irq);\r\nkfree(info);\r\nreturn -EINVAL;\r\n}\r\ninit_completion(&info->done);\r\nreadl_relaxed(info->baseaddr + PWC_STATUS);\r\nret = request_irq(irq, ve_spc_irq_handler, IRQF_TRIGGER_HIGH\r\n| IRQF_ONESHOT, "vexpress-spc", info);\r\nif (ret) {\r\npr_err(SPCLOG "IRQ %d request failed\n", irq);\r\nkfree(info);\r\nreturn -ENODEV;\r\n}\r\nsema_init(&info->sem, 1);\r\nsync_cache_w(info);\r\nsync_cache_w(&info);\r\nreturn 0;\r\n}\r\nstatic unsigned long spc_recalc_rate(struct clk_hw *hw,\r\nunsigned long parent_rate)\r\n{\r\nstruct clk_spc *spc = to_clk_spc(hw);\r\nu32 freq;\r\nif (ve_spc_get_performance(spc->cluster, &freq))\r\nreturn -EIO;\r\nreturn freq * 1000;\r\n}\r\nstatic long spc_round_rate(struct clk_hw *hw, unsigned long drate,\r\nunsigned long *parent_rate)\r\n{\r\nstruct clk_spc *spc = to_clk_spc(hw);\r\nreturn ve_spc_round_performance(spc->cluster, drate);\r\n}\r\nstatic int spc_set_rate(struct clk_hw *hw, unsigned long rate,\r\nunsigned long parent_rate)\r\n{\r\nstruct clk_spc *spc = to_clk_spc(hw);\r\nreturn ve_spc_set_performance(spc->cluster, rate / 1000);\r\n}\r\nstatic struct clk *ve_spc_clk_register(struct device *cpu_dev)\r\n{\r\nstruct clk_init_data init;\r\nstruct clk_spc *spc;\r\nspc = kzalloc(sizeof(*spc), GFP_KERNEL);\r\nif (!spc) {\r\npr_err("could not allocate spc clk\n");\r\nreturn ERR_PTR(-ENOMEM);\r\n}\r\nspc->hw.init = &init;\r\nspc->cluster = topology_physical_package_id(cpu_dev->id);\r\ninit.name = dev_name(cpu_dev);\r\ninit.ops = &clk_spc_ops;\r\ninit.flags = CLK_IS_ROOT | CLK_GET_RATE_NOCACHE;\r\ninit.num_parents = 0;\r\nreturn devm_clk_register(cpu_dev, &spc->hw);\r\n}\r\nstatic int __init ve_spc_clk_init(void)\r\n{\r\nint cpu;\r\nstruct clk *clk;\r\nif (!info)\r\nreturn 0;\r\nif (ve_spc_populate_opps(0) || ve_spc_populate_opps(1)) {\r\npr_err("failed to build OPP table\n");\r\nreturn -ENODEV;\r\n}\r\nfor_each_possible_cpu(cpu) {\r\nstruct device *cpu_dev = get_cpu_device(cpu);\r\nif (!cpu_dev) {\r\npr_warn("failed to get cpu%d device\n", cpu);\r\ncontinue;\r\n}\r\nclk = ve_spc_clk_register(cpu_dev);\r\nif (IS_ERR(clk)) {\r\npr_warn("failed to register cpu%d clock\n", cpu);\r\ncontinue;\r\n}\r\nif (clk_register_clkdev(clk, NULL, dev_name(cpu_dev))) {\r\npr_warn("failed to register cpu%d clock lookup\n", cpu);\r\ncontinue;\r\n}\r\nif (ve_init_opp_table(cpu_dev))\r\npr_warn("failed to initialise cpu%d opp table\n", cpu);\r\n}\r\nplatform_device_register_simple("vexpress-spc-cpufreq", -1, NULL, 0);\r\nreturn 0;\r\n}
