static void *loongson_dma_alloc_coherent(struct device *dev, size_t size,\r\ndma_addr_t *dma_handle, gfp_t gfp, struct dma_attrs *attrs)\r\n{\r\nvoid *ret;\r\nif (dma_alloc_from_coherent(dev, size, dma_handle, &ret))\r\nreturn ret;\r\ngfp &= ~(__GFP_DMA | __GFP_DMA32 | __GFP_HIGHMEM);\r\n#ifdef CONFIG_ISA\r\nif (dev == NULL)\r\ngfp |= __GFP_DMA;\r\nelse\r\n#endif\r\n#ifdef CONFIG_ZONE_DMA\r\nif (dev->coherent_dma_mask < DMA_BIT_MASK(32))\r\ngfp |= __GFP_DMA;\r\nelse\r\n#endif\r\n#ifdef CONFIG_ZONE_DMA32\r\nif (dev->coherent_dma_mask < DMA_BIT_MASK(40))\r\ngfp |= __GFP_DMA32;\r\nelse\r\n#endif\r\n;\r\ngfp |= __GFP_NORETRY;\r\nret = swiotlb_alloc_coherent(dev, size, dma_handle, gfp);\r\nmb();\r\nreturn ret;\r\n}\r\nstatic void loongson_dma_free_coherent(struct device *dev, size_t size,\r\nvoid *vaddr, dma_addr_t dma_handle, struct dma_attrs *attrs)\r\n{\r\nint order = get_order(size);\r\nif (dma_release_from_coherent(dev, order, vaddr))\r\nreturn;\r\nswiotlb_free_coherent(dev, size, vaddr, dma_handle);\r\n}\r\nstatic dma_addr_t loongson_dma_map_page(struct device *dev, struct page *page,\r\nunsigned long offset, size_t size,\r\nenum dma_data_direction dir,\r\nstruct dma_attrs *attrs)\r\n{\r\ndma_addr_t daddr = swiotlb_map_page(dev, page, offset, size,\r\ndir, attrs);\r\nmb();\r\nreturn daddr;\r\n}\r\nstatic int loongson_dma_map_sg(struct device *dev, struct scatterlist *sg,\r\nint nents, enum dma_data_direction dir,\r\nstruct dma_attrs *attrs)\r\n{\r\nint r = swiotlb_map_sg_attrs(dev, sg, nents, dir, NULL);\r\nmb();\r\nreturn r;\r\n}\r\nstatic void loongson_dma_sync_single_for_device(struct device *dev,\r\ndma_addr_t dma_handle, size_t size,\r\nenum dma_data_direction dir)\r\n{\r\nswiotlb_sync_single_for_device(dev, dma_handle, size, dir);\r\nmb();\r\n}\r\nstatic void loongson_dma_sync_sg_for_device(struct device *dev,\r\nstruct scatterlist *sg, int nents,\r\nenum dma_data_direction dir)\r\n{\r\nswiotlb_sync_sg_for_device(dev, sg, nents, dir);\r\nmb();\r\n}\r\nstatic int loongson_dma_set_mask(struct device *dev, u64 mask)\r\n{\r\nif (mask > DMA_BIT_MASK(loongson_sysconf.dma_mask_bits)) {\r\n*dev->dma_mask = DMA_BIT_MASK(loongson_sysconf.dma_mask_bits);\r\nreturn -EIO;\r\n}\r\n*dev->dma_mask = mask;\r\nreturn 0;\r\n}\r\ndma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)\r\n{\r\nreturn paddr;\r\n}\r\nphys_addr_t dma_to_phys(struct device *dev, dma_addr_t daddr)\r\n{\r\nreturn daddr;\r\n}\r\nvoid __init plat_swiotlb_setup(void)\r\n{\r\nswiotlb_init(1);\r\nmips_dma_map_ops = &loongson_dma_map_ops;\r\n}
