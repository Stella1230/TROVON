static int osc_page_protected(const struct lu_env *env,\r\nconst struct osc_page *opg,\r\nenum cl_lock_mode mode, int unref)\r\n{\r\nreturn 1;\r\n}\r\nstatic void osc_page_fini(const struct lu_env *env,\r\nstruct cl_page_slice *slice)\r\n{\r\nstruct osc_page *opg = cl2osc_page(slice);\r\nCDEBUG(D_TRACE, "%p\n", opg);\r\nLASSERT(opg->ops_lock == NULL);\r\n}\r\nstatic void osc_page_transfer_get(struct osc_page *opg, const char *label)\r\n{\r\nstruct cl_page *page = cl_page_top(opg->ops_cl.cpl_page);\r\nLASSERT(!opg->ops_transfer_pinned);\r\ncl_page_get(page);\r\nlu_ref_add_atomic(&page->cp_reference, label, page);\r\nopg->ops_transfer_pinned = 1;\r\n}\r\nstatic void osc_page_transfer_put(const struct lu_env *env,\r\nstruct osc_page *opg)\r\n{\r\nstruct cl_page *page = cl_page_top(opg->ops_cl.cpl_page);\r\nif (opg->ops_transfer_pinned) {\r\nlu_ref_del(&page->cp_reference, "transfer", page);\r\nopg->ops_transfer_pinned = 0;\r\ncl_page_put(env, page);\r\n}\r\n}\r\nstatic void osc_page_transfer_add(const struct lu_env *env,\r\nstruct osc_page *opg, enum cl_req_type crt)\r\n{\r\nstruct osc_object *obj = cl2osc(opg->ops_cl.cpl_obj);\r\nosc_lru_del(osc_cli(obj), opg, false);\r\nspin_lock(&obj->oo_seatbelt);\r\nlist_add(&opg->ops_inflight, &obj->oo_inflight[crt]);\r\nopg->ops_submitter = current;\r\nspin_unlock(&obj->oo_seatbelt);\r\n}\r\nstatic int osc_page_cache_add(const struct lu_env *env,\r\nconst struct cl_page_slice *slice,\r\nstruct cl_io *io)\r\n{\r\nstruct osc_io *oio = osc_env_io(env);\r\nstruct osc_page *opg = cl2osc_page(slice);\r\nint result;\r\nLINVRNT(osc_page_protected(env, opg, CLM_WRITE, 0));\r\nosc_page_transfer_get(opg, "transfer\0cache");\r\nresult = osc_queue_async_io(env, io, opg);\r\nif (result != 0)\r\nosc_page_transfer_put(env, opg);\r\nelse\r\nosc_page_transfer_add(env, opg, CRT_WRITE);\r\nif (cl_io_is_sync_write(io) || cl_io_is_mkwrite(io)) {\r\nif (oio->oi_active != NULL) {\r\nosc_extent_release(env, oio->oi_active);\r\noio->oi_active = NULL;\r\n}\r\n}\r\nreturn result;\r\n}\r\nvoid osc_index2policy(ldlm_policy_data_t *policy, const struct cl_object *obj,\r\npgoff_t start, pgoff_t end)\r\n{\r\nmemset(policy, 0, sizeof(*policy));\r\npolicy->l_extent.start = cl_offset(obj, start);\r\npolicy->l_extent.end = cl_offset(obj, end + 1) - 1;\r\n}\r\nstatic int osc_page_addref_lock(const struct lu_env *env,\r\nstruct osc_page *opg,\r\nstruct cl_lock *lock)\r\n{\r\nstruct osc_lock *olock;\r\nint rc;\r\nLASSERT(opg->ops_lock == NULL);\r\nolock = osc_lock_at(lock);\r\nif (atomic_inc_return(&olock->ols_pageref) <= 0) {\r\natomic_dec(&olock->ols_pageref);\r\nrc = -ENODATA;\r\n} else {\r\ncl_lock_get(lock);\r\nopg->ops_lock = lock;\r\nrc = 0;\r\n}\r\nreturn rc;\r\n}\r\nstatic void osc_page_putref_lock(const struct lu_env *env,\r\nstruct osc_page *opg)\r\n{\r\nstruct cl_lock *lock = opg->ops_lock;\r\nstruct osc_lock *olock;\r\nLASSERT(lock != NULL);\r\nolock = osc_lock_at(lock);\r\natomic_dec(&olock->ols_pageref);\r\nopg->ops_lock = NULL;\r\ncl_lock_put(env, lock);\r\n}\r\nstatic int osc_page_is_under_lock(const struct lu_env *env,\r\nconst struct cl_page_slice *slice,\r\nstruct cl_io *unused)\r\n{\r\nstruct cl_lock *lock;\r\nint result = -ENODATA;\r\nlock = cl_lock_at_page(env, slice->cpl_obj, slice->cpl_page,\r\nNULL, 1, 0);\r\nif (lock != NULL) {\r\nif (osc_page_addref_lock(env, cl2osc_page(slice), lock) == 0)\r\nresult = -EBUSY;\r\ncl_lock_put(env, lock);\r\n}\r\nreturn result;\r\n}\r\nstatic void osc_page_disown(const struct lu_env *env,\r\nconst struct cl_page_slice *slice,\r\nstruct cl_io *io)\r\n{\r\nstruct osc_page *opg = cl2osc_page(slice);\r\nif (unlikely(opg->ops_lock))\r\nosc_page_putref_lock(env, opg);\r\n}\r\nstatic void osc_page_completion_read(const struct lu_env *env,\r\nconst struct cl_page_slice *slice,\r\nint ioret)\r\n{\r\nstruct osc_page *opg = cl2osc_page(slice);\r\nstruct osc_object *obj = cl2osc(opg->ops_cl.cpl_obj);\r\nif (likely(opg->ops_lock))\r\nosc_page_putref_lock(env, opg);\r\nosc_lru_add(osc_cli(obj), opg);\r\n}\r\nstatic void osc_page_completion_write(const struct lu_env *env,\r\nconst struct cl_page_slice *slice,\r\nint ioret)\r\n{\r\nstruct osc_page *opg = cl2osc_page(slice);\r\nstruct osc_object *obj = cl2osc(slice->cpl_obj);\r\nosc_lru_add(osc_cli(obj), opg);\r\n}\r\nstatic int osc_page_fail(const struct lu_env *env,\r\nconst struct cl_page_slice *slice,\r\nstruct cl_io *unused)\r\n{\r\nLBUG();\r\nreturn 0;\r\n}\r\nstatic const char *osc_list(struct list_head *head)\r\n{\r\nreturn list_empty(head) ? "-" : "+";\r\n}\r\nstatic inline cfs_time_t osc_submit_duration(struct osc_page *opg)\r\n{\r\nif (opg->ops_submit_time == 0)\r\nreturn 0;\r\nreturn (cfs_time_current() - opg->ops_submit_time);\r\n}\r\nstatic int osc_page_print(const struct lu_env *env,\r\nconst struct cl_page_slice *slice,\r\nvoid *cookie, lu_printer_t printer)\r\n{\r\nstruct osc_page *opg = cl2osc_page(slice);\r\nstruct osc_async_page *oap = &opg->ops_oap;\r\nstruct osc_object *obj = cl2osc(slice->cpl_obj);\r\nstruct client_obd *cli = &osc_export(obj)->exp_obd->u.cli;\r\nreturn (*printer)(env, cookie, LUSTRE_OSC_NAME"-page@%p: "\r\n"1< %#x %d %u %s %s > "\r\n"2< "LPU64" %u %u %#x %#x | %p %p %p > "\r\n"3< %s %p %d %lu %d > "\r\n"4< %d %d %d %lu %s | %s %s %s %s > "\r\n"5< %s %s %s %s | %d %s | %d %s %s>\n",\r\nopg,\r\noap->oap_magic, oap->oap_cmd,\r\noap->oap_interrupted,\r\nosc_list(&oap->oap_pending_item),\r\nosc_list(&oap->oap_rpc_item),\r\noap->oap_obj_off, oap->oap_page_off, oap->oap_count,\r\noap->oap_async_flags, oap->oap_brw_flags,\r\noap->oap_request, oap->oap_cli, obj,\r\nosc_list(&opg->ops_inflight),\r\nopg->ops_submitter, opg->ops_transfer_pinned,\r\nosc_submit_duration(opg), opg->ops_srvlock,\r\ncli->cl_r_in_flight, cli->cl_w_in_flight,\r\ncli->cl_max_rpcs_in_flight,\r\ncli->cl_avail_grant,\r\nosc_list(&cli->cl_cache_waiters),\r\nosc_list(&cli->cl_loi_ready_list),\r\nosc_list(&cli->cl_loi_hp_ready_list),\r\nosc_list(&cli->cl_loi_write_list),\r\nosc_list(&cli->cl_loi_read_list),\r\nosc_list(&obj->oo_ready_item),\r\nosc_list(&obj->oo_hp_ready_item),\r\nosc_list(&obj->oo_write_item),\r\nosc_list(&obj->oo_read_item),\r\natomic_read(&obj->oo_nr_reads),\r\nosc_list(&obj->oo_reading_exts),\r\natomic_read(&obj->oo_nr_writes),\r\nosc_list(&obj->oo_hp_exts),\r\nosc_list(&obj->oo_urgent_exts));\r\n}\r\nstatic void osc_page_delete(const struct lu_env *env,\r\nconst struct cl_page_slice *slice)\r\n{\r\nstruct osc_page *opg = cl2osc_page(slice);\r\nstruct osc_object *obj = cl2osc(opg->ops_cl.cpl_obj);\r\nint rc;\r\nLINVRNT(opg->ops_temp || osc_page_protected(env, opg, CLM_READ, 1));\r\nCDEBUG(D_TRACE, "%p\n", opg);\r\nosc_page_transfer_put(env, opg);\r\nrc = osc_teardown_async_page(env, obj, opg);\r\nif (rc) {\r\nCL_PAGE_DEBUG(D_ERROR, env, cl_page_top(slice->cpl_page),\r\n"Trying to teardown failed: %d\n", rc);\r\nLASSERT(0);\r\n}\r\nspin_lock(&obj->oo_seatbelt);\r\nif (opg->ops_submitter != NULL) {\r\nLASSERT(!list_empty(&opg->ops_inflight));\r\nlist_del_init(&opg->ops_inflight);\r\nopg->ops_submitter = NULL;\r\n}\r\nspin_unlock(&obj->oo_seatbelt);\r\nosc_lru_del(osc_cli(obj), opg, true);\r\n}\r\nvoid osc_page_clip(const struct lu_env *env, const struct cl_page_slice *slice,\r\nint from, int to)\r\n{\r\nstruct osc_page *opg = cl2osc_page(slice);\r\nstruct osc_async_page *oap = &opg->ops_oap;\r\nLINVRNT(osc_page_protected(env, opg, CLM_READ, 0));\r\nopg->ops_from = from;\r\nopg->ops_to = to;\r\nspin_lock(&oap->oap_lock);\r\noap->oap_async_flags |= ASYNC_COUNT_STABLE;\r\nspin_unlock(&oap->oap_lock);\r\n}\r\nstatic int osc_page_cancel(const struct lu_env *env,\r\nconst struct cl_page_slice *slice)\r\n{\r\nstruct osc_page *opg = cl2osc_page(slice);\r\nint rc = 0;\r\nLINVRNT(osc_page_protected(env, opg, CLM_READ, 0));\r\nif (opg->ops_transfer_pinned)\r\nrc = osc_cancel_async_page(env, opg);\r\nLASSERT(ergo(rc == 0, opg->ops_transfer_pinned == 0));\r\nreturn rc;\r\n}\r\nstatic int osc_page_flush(const struct lu_env *env,\r\nconst struct cl_page_slice *slice,\r\nstruct cl_io *io)\r\n{\r\nstruct osc_page *opg = cl2osc_page(slice);\r\nint rc = 0;\r\nrc = osc_flush_async_page(env, io, opg);\r\nreturn rc;\r\n}\r\nint osc_page_init(const struct lu_env *env, struct cl_object *obj,\r\nstruct cl_page *page, struct page *vmpage)\r\n{\r\nstruct osc_object *osc = cl2osc(obj);\r\nstruct osc_page *opg = cl_object_page_slice(obj, page);\r\nint result;\r\nopg->ops_from = 0;\r\nopg->ops_to = PAGE_CACHE_SIZE;\r\nresult = osc_prep_async_page(osc, opg, vmpage,\r\ncl_offset(obj, page->cp_index));\r\nif (result == 0) {\r\nstruct osc_io *oio = osc_env_io(env);\r\nopg->ops_srvlock = osc_io_srvlock(oio);\r\ncl_page_slice_add(page, &opg->ops_cl, obj,\r\n&osc_page_ops);\r\n}\r\nINIT_LIST_HEAD(&opg->ops_inflight);\r\nINIT_LIST_HEAD(&opg->ops_lru);\r\nif (page->cp_type == CPT_CACHEABLE && result == 0)\r\nresult = osc_lru_reserve(env, osc, opg);\r\nreturn result;\r\n}\r\nvoid osc_page_submit(const struct lu_env *env, struct osc_page *opg,\r\nenum cl_req_type crt, int brw_flags)\r\n{\r\nstruct osc_async_page *oap = &opg->ops_oap;\r\nstruct osc_object *obj = oap->oap_obj;\r\nLINVRNT(osc_page_protected(env, opg,\r\ncrt == CRT_WRITE ? CLM_WRITE : CLM_READ, 1));\r\nLASSERTF(oap->oap_magic == OAP_MAGIC, "Bad oap magic: oap %p, "\r\n"magic 0x%x\n", oap, oap->oap_magic);\r\nLASSERT(oap->oap_async_flags & ASYNC_READY);\r\nLASSERT(oap->oap_async_flags & ASYNC_COUNT_STABLE);\r\noap->oap_cmd = crt == CRT_WRITE ? OBD_BRW_WRITE : OBD_BRW_READ;\r\noap->oap_page_off = opg->ops_from;\r\noap->oap_count = opg->ops_to - opg->ops_from;\r\noap->oap_brw_flags = OBD_BRW_SYNC | brw_flags;\r\nif (!client_is_remote(osc_export(obj)) &&\r\ncapable(CFS_CAP_SYS_RESOURCE)) {\r\noap->oap_brw_flags |= OBD_BRW_NOQUOTA;\r\noap->oap_cmd |= OBD_BRW_NOQUOTA;\r\n}\r\nopg->ops_submit_time = cfs_time_current();\r\nosc_page_transfer_get(opg, "transfer\0imm");\r\nosc_page_transfer_add(env, opg, crt);\r\n}\r\nstatic int osc_cache_too_much(struct client_obd *cli)\r\n{\r\nstruct cl_client_cache *cache = cli->cl_cache;\r\nint pages = atomic_read(&cli->cl_lru_in_list) >> 1;\r\nif (atomic_read(&osc_lru_waiters) > 0 &&\r\natomic_read(cli->cl_lru_left) < lru_shrink_max)\r\nreturn min(pages, lru_shrink_max);\r\nif (atomic_read(cli->cl_lru_left) < cache->ccc_lru_max >> 4) {\r\nunsigned long tmp;\r\ntmp = cache->ccc_lru_max / atomic_read(&cache->ccc_users);\r\nif (pages > tmp)\r\nreturn min(pages, lru_shrink_max);\r\nreturn pages > lru_shrink_min ? lru_shrink_min : 0;\r\n}\r\nreturn 0;\r\n}\r\nstatic int discard_pagevec(const struct lu_env *env, struct cl_io *io,\r\nstruct cl_page **pvec, int max_index)\r\n{\r\nint count;\r\nint i;\r\nfor (count = 0, i = 0; i < max_index; i++) {\r\nstruct cl_page *page = pvec[i];\r\nif (cl_page_own_try(env, io, page) == 0) {\r\nif (!cl_page_in_use(page)) {\r\ncl_page_unmap(env, io, page);\r\ncl_page_discard(env, io, page);\r\n++count;\r\n}\r\ncl_page_disown(env, io, page);\r\n}\r\ncl_page_put(env, page);\r\npvec[i] = NULL;\r\n}\r\nreturn max_index - count;\r\n}\r\nint osc_lru_shrink(struct client_obd *cli, int target)\r\n{\r\nstruct cl_env_nest nest;\r\nstruct lu_env *env;\r\nstruct cl_io *io;\r\nstruct cl_object *clobj = NULL;\r\nstruct cl_page **pvec;\r\nstruct osc_page *opg;\r\nint maxscan = 0;\r\nint count = 0;\r\nint index = 0;\r\nint rc = 0;\r\nLASSERT(atomic_read(&cli->cl_lru_in_list) >= 0);\r\nif (atomic_read(&cli->cl_lru_in_list) == 0 || target <= 0)\r\nreturn 0;\r\nenv = cl_env_nested_get(&nest);\r\nif (IS_ERR(env))\r\nreturn PTR_ERR(env);\r\npvec = osc_env_info(env)->oti_pvec;\r\nio = &osc_env_info(env)->oti_io;\r\nclient_obd_list_lock(&cli->cl_lru_list_lock);\r\natomic_inc(&cli->cl_lru_shrinkers);\r\nmaxscan = min(target << 1, atomic_read(&cli->cl_lru_in_list));\r\nwhile (!list_empty(&cli->cl_lru_list)) {\r\nstruct cl_page *page;\r\nif (--maxscan < 0)\r\nbreak;\r\nopg = list_entry(cli->cl_lru_list.next, struct osc_page,\r\nops_lru);\r\npage = cl_page_top(opg->ops_cl.cpl_page);\r\nif (cl_page_in_use_noref(page)) {\r\nlist_move_tail(&opg->ops_lru, &cli->cl_lru_list);\r\ncontinue;\r\n}\r\nLASSERT(page->cp_obj != NULL);\r\nif (clobj != page->cp_obj) {\r\nstruct cl_object *tmp = page->cp_obj;\r\ncl_object_get(tmp);\r\nclient_obd_list_unlock(&cli->cl_lru_list_lock);\r\nif (clobj != NULL) {\r\ncount -= discard_pagevec(env, io, pvec, index);\r\nindex = 0;\r\ncl_io_fini(env, io);\r\ncl_object_put(env, clobj);\r\nclobj = NULL;\r\n}\r\nclobj = tmp;\r\nio->ci_obj = clobj;\r\nio->ci_ignore_layout = 1;\r\nrc = cl_io_init(env, io, CIT_MISC, clobj);\r\nclient_obd_list_lock(&cli->cl_lru_list_lock);\r\nif (rc != 0)\r\nbreak;\r\n++maxscan;\r\ncontinue;\r\n}\r\nlist_move_tail(&opg->ops_lru, &cli->cl_lru_list);\r\ncl_page_get(page);\r\npvec[index++] = page;\r\nif (++count >= target)\r\nbreak;\r\nif (unlikely(index == OTI_PVEC_SIZE)) {\r\nclient_obd_list_unlock(&cli->cl_lru_list_lock);\r\ncount -= discard_pagevec(env, io, pvec, index);\r\nindex = 0;\r\nclient_obd_list_lock(&cli->cl_lru_list_lock);\r\n}\r\n}\r\nclient_obd_list_unlock(&cli->cl_lru_list_lock);\r\nif (clobj != NULL) {\r\ncount -= discard_pagevec(env, io, pvec, index);\r\ncl_io_fini(env, io);\r\ncl_object_put(env, clobj);\r\n}\r\ncl_env_nested_put(&nest, env);\r\natomic_dec(&cli->cl_lru_shrinkers);\r\nreturn count > 0 ? count : rc;\r\n}\r\nstatic void osc_lru_add(struct client_obd *cli, struct osc_page *opg)\r\n{\r\nbool wakeup = false;\r\nif (!opg->ops_in_lru)\r\nreturn;\r\natomic_dec(&cli->cl_lru_busy);\r\nclient_obd_list_lock(&cli->cl_lru_list_lock);\r\nif (list_empty(&opg->ops_lru)) {\r\nlist_move_tail(&opg->ops_lru, &cli->cl_lru_list);\r\natomic_inc_return(&cli->cl_lru_in_list);\r\nwakeup = atomic_read(&osc_lru_waiters) > 0;\r\n}\r\nclient_obd_list_unlock(&cli->cl_lru_list_lock);\r\nif (wakeup) {\r\nosc_lru_shrink(cli, osc_cache_too_much(cli));\r\nwake_up_all(&osc_lru_waitq);\r\n}\r\n}\r\nstatic void osc_lru_del(struct client_obd *cli, struct osc_page *opg, bool del)\r\n{\r\nif (opg->ops_in_lru) {\r\nclient_obd_list_lock(&cli->cl_lru_list_lock);\r\nif (!list_empty(&opg->ops_lru)) {\r\nLASSERT(atomic_read(&cli->cl_lru_in_list) > 0);\r\nlist_del_init(&opg->ops_lru);\r\natomic_dec(&cli->cl_lru_in_list);\r\nif (!del)\r\natomic_inc(&cli->cl_lru_busy);\r\n} else if (del) {\r\nLASSERT(atomic_read(&cli->cl_lru_busy) > 0);\r\natomic_dec(&cli->cl_lru_busy);\r\n}\r\nclient_obd_list_unlock(&cli->cl_lru_list_lock);\r\nif (del) {\r\natomic_inc(cli->cl_lru_left);\r\nif (atomic_read(&cli->cl_lru_shrinkers) == 0 &&\r\n!memory_pressure_get())\r\nosc_lru_shrink(cli, osc_cache_too_much(cli));\r\nwake_up(&osc_lru_waitq);\r\n}\r\n} else {\r\nLASSERT(list_empty(&opg->ops_lru));\r\n}\r\n}\r\nstatic inline int max_to_shrink(struct client_obd *cli)\r\n{\r\nreturn min(atomic_read(&cli->cl_lru_in_list) >> 1, lru_shrink_max);\r\n}\r\nstatic int osc_lru_reclaim(struct client_obd *cli)\r\n{\r\nstruct cl_client_cache *cache = cli->cl_cache;\r\nint max_scans;\r\nint rc;\r\nLASSERT(cache != NULL);\r\nLASSERT(!list_empty(&cache->ccc_lru));\r\nrc = osc_lru_shrink(cli, lru_shrink_min);\r\nif (rc != 0) {\r\nCDEBUG(D_CACHE, "%s: Free %d pages from own LRU: %p.\n",\r\ncli->cl_import->imp_obd->obd_name, rc, cli);\r\nreturn rc;\r\n}\r\nCDEBUG(D_CACHE, "%s: cli %p no free slots, pages: %d, busy: %d.\n",\r\ncli->cl_import->imp_obd->obd_name, cli,\r\natomic_read(&cli->cl_lru_in_list),\r\natomic_read(&cli->cl_lru_busy));\r\nspin_lock(&cache->ccc_lru_lock);\r\ncache->ccc_lru_shrinkers++;\r\nlist_move_tail(&cli->cl_lru_osc, &cache->ccc_lru);\r\nmax_scans = atomic_read(&cache->ccc_users);\r\nwhile (--max_scans > 0 && !list_empty(&cache->ccc_lru)) {\r\ncli = list_entry(cache->ccc_lru.next, struct client_obd,\r\ncl_lru_osc);\r\nCDEBUG(D_CACHE, "%s: cli %p LRU pages: %d, busy: %d.\n",\r\ncli->cl_import->imp_obd->obd_name, cli,\r\natomic_read(&cli->cl_lru_in_list),\r\natomic_read(&cli->cl_lru_busy));\r\nlist_move_tail(&cli->cl_lru_osc, &cache->ccc_lru);\r\nif (atomic_read(&cli->cl_lru_in_list) > 0) {\r\nspin_unlock(&cache->ccc_lru_lock);\r\nrc = osc_lru_shrink(cli, max_to_shrink(cli));\r\nspin_lock(&cache->ccc_lru_lock);\r\nif (rc != 0)\r\nbreak;\r\n}\r\n}\r\nspin_unlock(&cache->ccc_lru_lock);\r\nCDEBUG(D_CACHE, "%s: cli %p freed %d pages.\n",\r\ncli->cl_import->imp_obd->obd_name, cli, rc);\r\nreturn rc;\r\n}\r\nstatic int osc_lru_reserve(const struct lu_env *env, struct osc_object *obj,\r\nstruct osc_page *opg)\r\n{\r\nstruct l_wait_info lwi = LWI_INTR(LWI_ON_SIGNAL_NOOP, NULL);\r\nstruct client_obd *cli = osc_cli(obj);\r\nint rc = 0;\r\nif (cli->cl_cache == NULL)\r\nreturn 0;\r\nLASSERT(atomic_read(cli->cl_lru_left) >= 0);\r\nwhile (!atomic_add_unless(cli->cl_lru_left, -1, 0)) {\r\nint gen;\r\nrc = osc_lru_reclaim(cli);\r\nif (rc < 0)\r\nbreak;\r\nif (rc > 0)\r\ncontinue;\r\ncond_resched();\r\natomic_inc(&osc_lru_waiters);\r\ngen = atomic_read(&cli->cl_lru_in_list);\r\nrc = l_wait_event(osc_lru_waitq,\r\natomic_read(cli->cl_lru_left) > 0 ||\r\n(atomic_read(&cli->cl_lru_in_list) > 0 &&\r\ngen != atomic_read(&cli->cl_lru_in_list)),\r\n&lwi);\r\natomic_dec(&osc_lru_waiters);\r\nif (rc < 0)\r\nbreak;\r\n}\r\nif (rc >= 0) {\r\natomic_inc(&cli->cl_lru_busy);\r\nopg->ops_in_lru = 1;\r\nrc = 0;\r\n}\r\nreturn rc;\r\n}
