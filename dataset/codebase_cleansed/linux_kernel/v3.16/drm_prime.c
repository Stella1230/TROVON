static int drm_prime_add_buf_handle(struct drm_prime_file_private *prime_fpriv,\r\nstruct dma_buf *dma_buf, uint32_t handle)\r\n{\r\nstruct drm_prime_member *member;\r\nmember = kmalloc(sizeof(*member), GFP_KERNEL);\r\nif (!member)\r\nreturn -ENOMEM;\r\nget_dma_buf(dma_buf);\r\nmember->dma_buf = dma_buf;\r\nmember->handle = handle;\r\nlist_add(&member->entry, &prime_fpriv->head);\r\nreturn 0;\r\n}\r\nstatic struct dma_buf *drm_prime_lookup_buf_by_handle(struct drm_prime_file_private *prime_fpriv,\r\nuint32_t handle)\r\n{\r\nstruct drm_prime_member *member;\r\nlist_for_each_entry(member, &prime_fpriv->head, entry) {\r\nif (member->handle == handle)\r\nreturn member->dma_buf;\r\n}\r\nreturn NULL;\r\n}\r\nstatic int drm_prime_lookup_buf_handle(struct drm_prime_file_private *prime_fpriv,\r\nstruct dma_buf *dma_buf,\r\nuint32_t *handle)\r\n{\r\nstruct drm_prime_member *member;\r\nlist_for_each_entry(member, &prime_fpriv->head, entry) {\r\nif (member->dma_buf == dma_buf) {\r\n*handle = member->handle;\r\nreturn 0;\r\n}\r\n}\r\nreturn -ENOENT;\r\n}\r\nstatic int drm_gem_map_attach(struct dma_buf *dma_buf,\r\nstruct device *target_dev,\r\nstruct dma_buf_attachment *attach)\r\n{\r\nstruct drm_prime_attachment *prime_attach;\r\nstruct drm_gem_object *obj = dma_buf->priv;\r\nstruct drm_device *dev = obj->dev;\r\nprime_attach = kzalloc(sizeof(*prime_attach), GFP_KERNEL);\r\nif (!prime_attach)\r\nreturn -ENOMEM;\r\nprime_attach->dir = DMA_NONE;\r\nattach->priv = prime_attach;\r\nif (!dev->driver->gem_prime_pin)\r\nreturn 0;\r\nreturn dev->driver->gem_prime_pin(obj);\r\n}\r\nstatic void drm_gem_map_detach(struct dma_buf *dma_buf,\r\nstruct dma_buf_attachment *attach)\r\n{\r\nstruct drm_prime_attachment *prime_attach = attach->priv;\r\nstruct drm_gem_object *obj = dma_buf->priv;\r\nstruct drm_device *dev = obj->dev;\r\nstruct sg_table *sgt;\r\nif (dev->driver->gem_prime_unpin)\r\ndev->driver->gem_prime_unpin(obj);\r\nif (!prime_attach)\r\nreturn;\r\nsgt = prime_attach->sgt;\r\nif (sgt) {\r\nif (prime_attach->dir != DMA_NONE)\r\ndma_unmap_sg(attach->dev, sgt->sgl, sgt->nents,\r\nprime_attach->dir);\r\nsg_free_table(sgt);\r\n}\r\nkfree(sgt);\r\nkfree(prime_attach);\r\nattach->priv = NULL;\r\n}\r\nvoid drm_prime_remove_buf_handle_locked(struct drm_prime_file_private *prime_fpriv,\r\nstruct dma_buf *dma_buf)\r\n{\r\nstruct drm_prime_member *member, *safe;\r\nlist_for_each_entry_safe(member, safe, &prime_fpriv->head, entry) {\r\nif (member->dma_buf == dma_buf) {\r\ndma_buf_put(dma_buf);\r\nlist_del(&member->entry);\r\nkfree(member);\r\n}\r\n}\r\n}\r\nstatic struct sg_table *drm_gem_map_dma_buf(struct dma_buf_attachment *attach,\r\nenum dma_data_direction dir)\r\n{\r\nstruct drm_prime_attachment *prime_attach = attach->priv;\r\nstruct drm_gem_object *obj = attach->dmabuf->priv;\r\nstruct sg_table *sgt;\r\nif (WARN_ON(dir == DMA_NONE || !prime_attach))\r\nreturn ERR_PTR(-EINVAL);\r\nif (prime_attach->dir == dir)\r\nreturn prime_attach->sgt;\r\nif (WARN_ON(prime_attach->dir != DMA_NONE))\r\nreturn ERR_PTR(-EBUSY);\r\nsgt = obj->dev->driver->gem_prime_get_sg_table(obj);\r\nif (!IS_ERR(sgt)) {\r\nif (!dma_map_sg(attach->dev, sgt->sgl, sgt->nents, dir)) {\r\nsg_free_table(sgt);\r\nkfree(sgt);\r\nsgt = ERR_PTR(-ENOMEM);\r\n} else {\r\nprime_attach->sgt = sgt;\r\nprime_attach->dir = dir;\r\n}\r\n}\r\nreturn sgt;\r\n}\r\nstatic void drm_gem_unmap_dma_buf(struct dma_buf_attachment *attach,\r\nstruct sg_table *sgt,\r\nenum dma_data_direction dir)\r\n{\r\n}\r\nvoid drm_gem_dmabuf_release(struct dma_buf *dma_buf)\r\n{\r\nstruct drm_gem_object *obj = dma_buf->priv;\r\ndrm_gem_object_unreference_unlocked(obj);\r\n}\r\nstatic void *drm_gem_dmabuf_vmap(struct dma_buf *dma_buf)\r\n{\r\nstruct drm_gem_object *obj = dma_buf->priv;\r\nstruct drm_device *dev = obj->dev;\r\nreturn dev->driver->gem_prime_vmap(obj);\r\n}\r\nstatic void drm_gem_dmabuf_vunmap(struct dma_buf *dma_buf, void *vaddr)\r\n{\r\nstruct drm_gem_object *obj = dma_buf->priv;\r\nstruct drm_device *dev = obj->dev;\r\ndev->driver->gem_prime_vunmap(obj, vaddr);\r\n}\r\nstatic void *drm_gem_dmabuf_kmap_atomic(struct dma_buf *dma_buf,\r\nunsigned long page_num)\r\n{\r\nreturn NULL;\r\n}\r\nstatic void drm_gem_dmabuf_kunmap_atomic(struct dma_buf *dma_buf,\r\nunsigned long page_num, void *addr)\r\n{\r\n}\r\nstatic void *drm_gem_dmabuf_kmap(struct dma_buf *dma_buf,\r\nunsigned long page_num)\r\n{\r\nreturn NULL;\r\n}\r\nstatic void drm_gem_dmabuf_kunmap(struct dma_buf *dma_buf,\r\nunsigned long page_num, void *addr)\r\n{\r\n}\r\nstatic int drm_gem_dmabuf_mmap(struct dma_buf *dma_buf,\r\nstruct vm_area_struct *vma)\r\n{\r\nstruct drm_gem_object *obj = dma_buf->priv;\r\nstruct drm_device *dev = obj->dev;\r\nif (!dev->driver->gem_prime_mmap)\r\nreturn -ENOSYS;\r\nreturn dev->driver->gem_prime_mmap(obj, vma);\r\n}\r\nstruct dma_buf *drm_gem_prime_export(struct drm_device *dev,\r\nstruct drm_gem_object *obj, int flags)\r\n{\r\nreturn dma_buf_export(obj, &drm_gem_prime_dmabuf_ops, obj->size, flags);\r\n}\r\nstatic struct dma_buf *export_and_register_object(struct drm_device *dev,\r\nstruct drm_gem_object *obj,\r\nuint32_t flags)\r\n{\r\nstruct dma_buf *dmabuf;\r\nif (obj->handle_count == 0) {\r\ndmabuf = ERR_PTR(-ENOENT);\r\nreturn dmabuf;\r\n}\r\ndmabuf = dev->driver->gem_prime_export(dev, obj, flags);\r\nif (IS_ERR(dmabuf)) {\r\nreturn dmabuf;\r\n}\r\nobj->dma_buf = dmabuf;\r\nget_dma_buf(obj->dma_buf);\r\ndrm_gem_object_reference(obj);\r\nreturn dmabuf;\r\n}\r\nint drm_gem_prime_handle_to_fd(struct drm_device *dev,\r\nstruct drm_file *file_priv, uint32_t handle,\r\nuint32_t flags,\r\nint *prime_fd)\r\n{\r\nstruct drm_gem_object *obj;\r\nint ret = 0;\r\nstruct dma_buf *dmabuf;\r\nmutex_lock(&file_priv->prime.lock);\r\nobj = drm_gem_object_lookup(dev, file_priv, handle);\r\nif (!obj) {\r\nret = -ENOENT;\r\ngoto out_unlock;\r\n}\r\ndmabuf = drm_prime_lookup_buf_by_handle(&file_priv->prime, handle);\r\nif (dmabuf) {\r\nget_dma_buf(dmabuf);\r\ngoto out_have_handle;\r\n}\r\nmutex_lock(&dev->object_name_lock);\r\nif (obj->import_attach) {\r\ndmabuf = obj->import_attach->dmabuf;\r\nget_dma_buf(dmabuf);\r\ngoto out_have_obj;\r\n}\r\nif (obj->dma_buf) {\r\nget_dma_buf(obj->dma_buf);\r\ndmabuf = obj->dma_buf;\r\ngoto out_have_obj;\r\n}\r\ndmabuf = export_and_register_object(dev, obj, flags);\r\nif (IS_ERR(dmabuf)) {\r\nret = PTR_ERR(dmabuf);\r\nmutex_unlock(&dev->object_name_lock);\r\ngoto out;\r\n}\r\nout_have_obj:\r\nret = drm_prime_add_buf_handle(&file_priv->prime,\r\ndmabuf, handle);\r\nmutex_unlock(&dev->object_name_lock);\r\nif (ret)\r\ngoto fail_put_dmabuf;\r\nout_have_handle:\r\nret = dma_buf_fd(dmabuf, flags);\r\nif (ret < 0) {\r\ngoto fail_put_dmabuf;\r\n} else {\r\n*prime_fd = ret;\r\nret = 0;\r\n}\r\ngoto out;\r\nfail_put_dmabuf:\r\ndma_buf_put(dmabuf);\r\nout:\r\ndrm_gem_object_unreference_unlocked(obj);\r\nout_unlock:\r\nmutex_unlock(&file_priv->prime.lock);\r\nreturn ret;\r\n}\r\nstruct drm_gem_object *drm_gem_prime_import(struct drm_device *dev,\r\nstruct dma_buf *dma_buf)\r\n{\r\nstruct dma_buf_attachment *attach;\r\nstruct sg_table *sgt;\r\nstruct drm_gem_object *obj;\r\nint ret;\r\nif (!dev->driver->gem_prime_import_sg_table)\r\nreturn ERR_PTR(-EINVAL);\r\nif (dma_buf->ops == &drm_gem_prime_dmabuf_ops) {\r\nobj = dma_buf->priv;\r\nif (obj->dev == dev) {\r\ndrm_gem_object_reference(obj);\r\nreturn obj;\r\n}\r\n}\r\nattach = dma_buf_attach(dma_buf, dev->dev);\r\nif (IS_ERR(attach))\r\nreturn ERR_CAST(attach);\r\nget_dma_buf(dma_buf);\r\nsgt = dma_buf_map_attachment(attach, DMA_BIDIRECTIONAL);\r\nif (IS_ERR(sgt)) {\r\nret = PTR_ERR(sgt);\r\ngoto fail_detach;\r\n}\r\nobj = dev->driver->gem_prime_import_sg_table(dev, dma_buf->size, sgt);\r\nif (IS_ERR(obj)) {\r\nret = PTR_ERR(obj);\r\ngoto fail_unmap;\r\n}\r\nobj->import_attach = attach;\r\nreturn obj;\r\nfail_unmap:\r\ndma_buf_unmap_attachment(attach, sgt, DMA_BIDIRECTIONAL);\r\nfail_detach:\r\ndma_buf_detach(dma_buf, attach);\r\ndma_buf_put(dma_buf);\r\nreturn ERR_PTR(ret);\r\n}\r\nint drm_gem_prime_fd_to_handle(struct drm_device *dev,\r\nstruct drm_file *file_priv, int prime_fd,\r\nuint32_t *handle)\r\n{\r\nstruct dma_buf *dma_buf;\r\nstruct drm_gem_object *obj;\r\nint ret;\r\ndma_buf = dma_buf_get(prime_fd);\r\nif (IS_ERR(dma_buf))\r\nreturn PTR_ERR(dma_buf);\r\nmutex_lock(&file_priv->prime.lock);\r\nret = drm_prime_lookup_buf_handle(&file_priv->prime,\r\ndma_buf, handle);\r\nif (ret == 0)\r\ngoto out_put;\r\nmutex_lock(&dev->object_name_lock);\r\nobj = dev->driver->gem_prime_import(dev, dma_buf);\r\nif (IS_ERR(obj)) {\r\nret = PTR_ERR(obj);\r\ngoto out_unlock;\r\n}\r\nif (obj->dma_buf) {\r\nWARN_ON(obj->dma_buf != dma_buf);\r\n} else {\r\nobj->dma_buf = dma_buf;\r\nget_dma_buf(dma_buf);\r\n}\r\nret = drm_gem_handle_create_tail(file_priv, obj, handle);\r\ndrm_gem_object_unreference_unlocked(obj);\r\nif (ret)\r\ngoto out_put;\r\nret = drm_prime_add_buf_handle(&file_priv->prime,\r\ndma_buf, *handle);\r\nif (ret)\r\ngoto fail;\r\nmutex_unlock(&file_priv->prime.lock);\r\ndma_buf_put(dma_buf);\r\nreturn 0;\r\nfail:\r\ndrm_gem_handle_delete(file_priv, *handle);\r\nout_unlock:\r\nmutex_unlock(&dev->object_name_lock);\r\nout_put:\r\ndma_buf_put(dma_buf);\r\nmutex_unlock(&file_priv->prime.lock);\r\nreturn ret;\r\n}\r\nint drm_prime_handle_to_fd_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct drm_prime_handle *args = data;\r\nuint32_t flags;\r\nif (!drm_core_check_feature(dev, DRIVER_PRIME))\r\nreturn -EINVAL;\r\nif (!dev->driver->prime_handle_to_fd)\r\nreturn -ENOSYS;\r\nif (args->flags & ~DRM_CLOEXEC)\r\nreturn -EINVAL;\r\nflags = args->flags & DRM_CLOEXEC;\r\nreturn dev->driver->prime_handle_to_fd(dev, file_priv,\r\nargs->handle, flags, &args->fd);\r\n}\r\nint drm_prime_fd_to_handle_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct drm_prime_handle *args = data;\r\nif (!drm_core_check_feature(dev, DRIVER_PRIME))\r\nreturn -EINVAL;\r\nif (!dev->driver->prime_fd_to_handle)\r\nreturn -ENOSYS;\r\nreturn dev->driver->prime_fd_to_handle(dev, file_priv,\r\nargs->fd, &args->handle);\r\n}\r\nstruct sg_table *drm_prime_pages_to_sg(struct page **pages, int nr_pages)\r\n{\r\nstruct sg_table *sg = NULL;\r\nint ret;\r\nsg = kmalloc(sizeof(struct sg_table), GFP_KERNEL);\r\nif (!sg) {\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\nret = sg_alloc_table_from_pages(sg, pages, nr_pages, 0,\r\nnr_pages << PAGE_SHIFT, GFP_KERNEL);\r\nif (ret)\r\ngoto out;\r\nreturn sg;\r\nout:\r\nkfree(sg);\r\nreturn ERR_PTR(ret);\r\n}\r\nint drm_prime_sg_to_page_addr_arrays(struct sg_table *sgt, struct page **pages,\r\ndma_addr_t *addrs, int max_pages)\r\n{\r\nunsigned count;\r\nstruct scatterlist *sg;\r\nstruct page *page;\r\nu32 len;\r\nint pg_index;\r\ndma_addr_t addr;\r\npg_index = 0;\r\nfor_each_sg(sgt->sgl, sg, sgt->nents, count) {\r\nlen = sg->length;\r\npage = sg_page(sg);\r\naddr = sg_dma_address(sg);\r\nwhile (len > 0) {\r\nif (WARN_ON(pg_index >= max_pages))\r\nreturn -1;\r\npages[pg_index] = page;\r\nif (addrs)\r\naddrs[pg_index] = addr;\r\npage++;\r\naddr += PAGE_SIZE;\r\nlen -= PAGE_SIZE;\r\npg_index++;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nvoid drm_prime_gem_destroy(struct drm_gem_object *obj, struct sg_table *sg)\r\n{\r\nstruct dma_buf_attachment *attach;\r\nstruct dma_buf *dma_buf;\r\nattach = obj->import_attach;\r\nif (sg)\r\ndma_buf_unmap_attachment(attach, sg, DMA_BIDIRECTIONAL);\r\ndma_buf = attach->dmabuf;\r\ndma_buf_detach(attach->dmabuf, attach);\r\ndma_buf_put(dma_buf);\r\n}\r\nvoid drm_prime_init_file_private(struct drm_prime_file_private *prime_fpriv)\r\n{\r\nINIT_LIST_HEAD(&prime_fpriv->head);\r\nmutex_init(&prime_fpriv->lock);\r\n}\r\nvoid drm_prime_destroy_file_private(struct drm_prime_file_private *prime_fpriv)\r\n{\r\nWARN_ON(!list_empty(&prime_fpriv->head));\r\n}
