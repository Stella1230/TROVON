static inline struct ttm_object_file *\r\nttm_object_file_ref(struct ttm_object_file *tfile)\r\n{\r\nkref_get(&tfile->refcount);\r\nreturn tfile;\r\n}\r\nstatic void ttm_object_file_destroy(struct kref *kref)\r\n{\r\nstruct ttm_object_file *tfile =\r\ncontainer_of(kref, struct ttm_object_file, refcount);\r\nkfree(tfile);\r\n}\r\nstatic inline void ttm_object_file_unref(struct ttm_object_file **p_tfile)\r\n{\r\nstruct ttm_object_file *tfile = *p_tfile;\r\n*p_tfile = NULL;\r\nkref_put(&tfile->refcount, ttm_object_file_destroy);\r\n}\r\nint ttm_base_object_init(struct ttm_object_file *tfile,\r\nstruct ttm_base_object *base,\r\nbool shareable,\r\nenum ttm_object_type object_type,\r\nvoid (*refcount_release) (struct ttm_base_object **),\r\nvoid (*ref_obj_release) (struct ttm_base_object *,\r\nenum ttm_ref_type ref_type))\r\n{\r\nstruct ttm_object_device *tdev = tfile->tdev;\r\nint ret;\r\nbase->shareable = shareable;\r\nbase->tfile = ttm_object_file_ref(tfile);\r\nbase->refcount_release = refcount_release;\r\nbase->ref_obj_release = ref_obj_release;\r\nbase->object_type = object_type;\r\nkref_init(&base->refcount);\r\nspin_lock(&tdev->object_lock);\r\nret = drm_ht_just_insert_please_rcu(&tdev->object_hash,\r\n&base->hash,\r\n(unsigned long)base, 31, 0, 0);\r\nspin_unlock(&tdev->object_lock);\r\nif (unlikely(ret != 0))\r\ngoto out_err0;\r\nret = ttm_ref_object_add(tfile, base, TTM_REF_USAGE, NULL);\r\nif (unlikely(ret != 0))\r\ngoto out_err1;\r\nttm_base_object_unref(&base);\r\nreturn 0;\r\nout_err1:\r\nspin_lock(&tdev->object_lock);\r\n(void)drm_ht_remove_item_rcu(&tdev->object_hash, &base->hash);\r\nspin_unlock(&tdev->object_lock);\r\nout_err0:\r\nreturn ret;\r\n}\r\nstatic void ttm_release_base(struct kref *kref)\r\n{\r\nstruct ttm_base_object *base =\r\ncontainer_of(kref, struct ttm_base_object, refcount);\r\nstruct ttm_object_device *tdev = base->tfile->tdev;\r\nspin_lock(&tdev->object_lock);\r\n(void)drm_ht_remove_item_rcu(&tdev->object_hash, &base->hash);\r\nspin_unlock(&tdev->object_lock);\r\nttm_object_file_unref(&base->tfile);\r\nif (base->refcount_release)\r\nbase->refcount_release(&base);\r\n}\r\nvoid ttm_base_object_unref(struct ttm_base_object **p_base)\r\n{\r\nstruct ttm_base_object *base = *p_base;\r\n*p_base = NULL;\r\nkref_put(&base->refcount, ttm_release_base);\r\n}\r\nstruct ttm_base_object *ttm_base_object_lookup(struct ttm_object_file *tfile,\r\nuint32_t key)\r\n{\r\nstruct ttm_base_object *base = NULL;\r\nstruct drm_hash_item *hash;\r\nstruct drm_open_hash *ht = &tfile->ref_hash[TTM_REF_USAGE];\r\nint ret;\r\nrcu_read_lock();\r\nret = drm_ht_find_item_rcu(ht, key, &hash);\r\nif (likely(ret == 0)) {\r\nbase = drm_hash_entry(hash, struct ttm_ref_object, hash)->obj;\r\nif (!kref_get_unless_zero(&base->refcount))\r\nbase = NULL;\r\n}\r\nrcu_read_unlock();\r\nreturn base;\r\n}\r\nstruct ttm_base_object *\r\nttm_base_object_lookup_for_ref(struct ttm_object_device *tdev, uint32_t key)\r\n{\r\nstruct ttm_base_object *base = NULL;\r\nstruct drm_hash_item *hash;\r\nstruct drm_open_hash *ht = &tdev->object_hash;\r\nint ret;\r\nrcu_read_lock();\r\nret = drm_ht_find_item_rcu(ht, key, &hash);\r\nif (likely(ret == 0)) {\r\nbase = drm_hash_entry(hash, struct ttm_base_object, hash);\r\nif (!kref_get_unless_zero(&base->refcount))\r\nbase = NULL;\r\n}\r\nrcu_read_unlock();\r\nreturn base;\r\n}\r\nbool ttm_ref_object_exists(struct ttm_object_file *tfile,\r\nstruct ttm_base_object *base)\r\n{\r\nstruct drm_open_hash *ht = &tfile->ref_hash[TTM_REF_USAGE];\r\nstruct drm_hash_item *hash;\r\nstruct ttm_ref_object *ref;\r\nrcu_read_lock();\r\nif (unlikely(drm_ht_find_item_rcu(ht, base->hash.key, &hash) != 0))\r\ngoto out_false;\r\nref = drm_hash_entry(hash, struct ttm_ref_object, hash);\r\nif (unlikely(base != ref->obj))\r\ngoto out_false;\r\nrmb();\r\nif (unlikely(atomic_read(&ref->kref.refcount) == 0))\r\ngoto out_false;\r\nrcu_read_unlock();\r\nreturn true;\r\nout_false:\r\nrcu_read_unlock();\r\nreturn false;\r\n}\r\nint ttm_ref_object_add(struct ttm_object_file *tfile,\r\nstruct ttm_base_object *base,\r\nenum ttm_ref_type ref_type, bool *existed)\r\n{\r\nstruct drm_open_hash *ht = &tfile->ref_hash[ref_type];\r\nstruct ttm_ref_object *ref;\r\nstruct drm_hash_item *hash;\r\nstruct ttm_mem_global *mem_glob = tfile->tdev->mem_glob;\r\nint ret = -EINVAL;\r\nif (base->tfile != tfile && !base->shareable)\r\nreturn -EPERM;\r\nif (existed != NULL)\r\n*existed = true;\r\nwhile (ret == -EINVAL) {\r\nrcu_read_lock();\r\nret = drm_ht_find_item_rcu(ht, base->hash.key, &hash);\r\nif (ret == 0) {\r\nref = drm_hash_entry(hash, struct ttm_ref_object, hash);\r\nif (kref_get_unless_zero(&ref->kref)) {\r\nrcu_read_unlock();\r\nbreak;\r\n}\r\n}\r\nrcu_read_unlock();\r\nret = ttm_mem_global_alloc(mem_glob, sizeof(*ref),\r\nfalse, false);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nref = kmalloc(sizeof(*ref), GFP_KERNEL);\r\nif (unlikely(ref == NULL)) {\r\nttm_mem_global_free(mem_glob, sizeof(*ref));\r\nreturn -ENOMEM;\r\n}\r\nref->hash.key = base->hash.key;\r\nref->obj = base;\r\nref->tfile = tfile;\r\nref->ref_type = ref_type;\r\nkref_init(&ref->kref);\r\nspin_lock(&tfile->lock);\r\nret = drm_ht_insert_item_rcu(ht, &ref->hash);\r\nif (likely(ret == 0)) {\r\nlist_add_tail(&ref->head, &tfile->ref_list);\r\nkref_get(&base->refcount);\r\nspin_unlock(&tfile->lock);\r\nif (existed != NULL)\r\n*existed = false;\r\nbreak;\r\n}\r\nspin_unlock(&tfile->lock);\r\nBUG_ON(ret != -EINVAL);\r\nttm_mem_global_free(mem_glob, sizeof(*ref));\r\nkfree(ref);\r\n}\r\nreturn ret;\r\n}\r\nstatic void ttm_ref_object_release(struct kref *kref)\r\n{\r\nstruct ttm_ref_object *ref =\r\ncontainer_of(kref, struct ttm_ref_object, kref);\r\nstruct ttm_base_object *base = ref->obj;\r\nstruct ttm_object_file *tfile = ref->tfile;\r\nstruct drm_open_hash *ht;\r\nstruct ttm_mem_global *mem_glob = tfile->tdev->mem_glob;\r\nht = &tfile->ref_hash[ref->ref_type];\r\n(void)drm_ht_remove_item_rcu(ht, &ref->hash);\r\nlist_del(&ref->head);\r\nspin_unlock(&tfile->lock);\r\nif (ref->ref_type != TTM_REF_USAGE && base->ref_obj_release)\r\nbase->ref_obj_release(base, ref->ref_type);\r\nttm_base_object_unref(&ref->obj);\r\nttm_mem_global_free(mem_glob, sizeof(*ref));\r\nkfree_rcu(ref, rcu_head);\r\nspin_lock(&tfile->lock);\r\n}\r\nint ttm_ref_object_base_unref(struct ttm_object_file *tfile,\r\nunsigned long key, enum ttm_ref_type ref_type)\r\n{\r\nstruct drm_open_hash *ht = &tfile->ref_hash[ref_type];\r\nstruct ttm_ref_object *ref;\r\nstruct drm_hash_item *hash;\r\nint ret;\r\nspin_lock(&tfile->lock);\r\nret = drm_ht_find_item(ht, key, &hash);\r\nif (unlikely(ret != 0)) {\r\nspin_unlock(&tfile->lock);\r\nreturn -EINVAL;\r\n}\r\nref = drm_hash_entry(hash, struct ttm_ref_object, hash);\r\nkref_put(&ref->kref, ttm_ref_object_release);\r\nspin_unlock(&tfile->lock);\r\nreturn 0;\r\n}\r\nvoid ttm_object_file_release(struct ttm_object_file **p_tfile)\r\n{\r\nstruct ttm_ref_object *ref;\r\nstruct list_head *list;\r\nunsigned int i;\r\nstruct ttm_object_file *tfile = *p_tfile;\r\n*p_tfile = NULL;\r\nspin_lock(&tfile->lock);\r\nwhile (!list_empty(&tfile->ref_list)) {\r\nlist = tfile->ref_list.next;\r\nref = list_entry(list, struct ttm_ref_object, head);\r\nttm_ref_object_release(&ref->kref);\r\n}\r\nfor (i = 0; i < TTM_REF_NUM; ++i)\r\ndrm_ht_remove(&tfile->ref_hash[i]);\r\nspin_unlock(&tfile->lock);\r\nttm_object_file_unref(&tfile);\r\n}\r\nstruct ttm_object_file *ttm_object_file_init(struct ttm_object_device *tdev,\r\nunsigned int hash_order)\r\n{\r\nstruct ttm_object_file *tfile = kmalloc(sizeof(*tfile), GFP_KERNEL);\r\nunsigned int i;\r\nunsigned int j = 0;\r\nint ret;\r\nif (unlikely(tfile == NULL))\r\nreturn NULL;\r\nspin_lock_init(&tfile->lock);\r\ntfile->tdev = tdev;\r\nkref_init(&tfile->refcount);\r\nINIT_LIST_HEAD(&tfile->ref_list);\r\nfor (i = 0; i < TTM_REF_NUM; ++i) {\r\nret = drm_ht_create(&tfile->ref_hash[i], hash_order);\r\nif (ret) {\r\nj = i;\r\ngoto out_err;\r\n}\r\n}\r\nreturn tfile;\r\nout_err:\r\nfor (i = 0; i < j; ++i)\r\ndrm_ht_remove(&tfile->ref_hash[i]);\r\nkfree(tfile);\r\nreturn NULL;\r\n}\r\nstruct ttm_object_device *\r\nttm_object_device_init(struct ttm_mem_global *mem_glob,\r\nunsigned int hash_order,\r\nconst struct dma_buf_ops *ops)\r\n{\r\nstruct ttm_object_device *tdev = kmalloc(sizeof(*tdev), GFP_KERNEL);\r\nint ret;\r\nif (unlikely(tdev == NULL))\r\nreturn NULL;\r\ntdev->mem_glob = mem_glob;\r\nspin_lock_init(&tdev->object_lock);\r\natomic_set(&tdev->object_count, 0);\r\nret = drm_ht_create(&tdev->object_hash, hash_order);\r\nif (ret != 0)\r\ngoto out_no_object_hash;\r\ntdev->ops = *ops;\r\ntdev->dmabuf_release = tdev->ops.release;\r\ntdev->ops.release = ttm_prime_dmabuf_release;\r\ntdev->dma_buf_size = ttm_round_pot(sizeof(struct dma_buf)) +\r\nttm_round_pot(sizeof(struct file));\r\nreturn tdev;\r\nout_no_object_hash:\r\nkfree(tdev);\r\nreturn NULL;\r\n}\r\nvoid ttm_object_device_release(struct ttm_object_device **p_tdev)\r\n{\r\nstruct ttm_object_device *tdev = *p_tdev;\r\n*p_tdev = NULL;\r\nspin_lock(&tdev->object_lock);\r\ndrm_ht_remove(&tdev->object_hash);\r\nspin_unlock(&tdev->object_lock);\r\nkfree(tdev);\r\n}\r\nstatic bool __must_check get_dma_buf_unless_doomed(struct dma_buf *dmabuf)\r\n{\r\nreturn atomic_long_inc_not_zero(&dmabuf->file->f_count) != 0L;\r\n}\r\nstatic void ttm_prime_refcount_release(struct ttm_base_object **p_base)\r\n{\r\nstruct ttm_base_object *base = *p_base;\r\nstruct ttm_prime_object *prime;\r\n*p_base = NULL;\r\nprime = container_of(base, struct ttm_prime_object, base);\r\nBUG_ON(prime->dma_buf != NULL);\r\nmutex_destroy(&prime->mutex);\r\nif (prime->refcount_release)\r\nprime->refcount_release(&base);\r\n}\r\nstatic void ttm_prime_dmabuf_release(struct dma_buf *dma_buf)\r\n{\r\nstruct ttm_prime_object *prime =\r\n(struct ttm_prime_object *) dma_buf->priv;\r\nstruct ttm_base_object *base = &prime->base;\r\nstruct ttm_object_device *tdev = base->tfile->tdev;\r\nif (tdev->dmabuf_release)\r\ntdev->dmabuf_release(dma_buf);\r\nmutex_lock(&prime->mutex);\r\nif (prime->dma_buf == dma_buf)\r\nprime->dma_buf = NULL;\r\nmutex_unlock(&prime->mutex);\r\nttm_mem_global_free(tdev->mem_glob, tdev->dma_buf_size);\r\nttm_base_object_unref(&base);\r\n}\r\nint ttm_prime_fd_to_handle(struct ttm_object_file *tfile,\r\nint fd, u32 *handle)\r\n{\r\nstruct ttm_object_device *tdev = tfile->tdev;\r\nstruct dma_buf *dma_buf;\r\nstruct ttm_prime_object *prime;\r\nstruct ttm_base_object *base;\r\nint ret;\r\ndma_buf = dma_buf_get(fd);\r\nif (IS_ERR(dma_buf))\r\nreturn PTR_ERR(dma_buf);\r\nif (dma_buf->ops != &tdev->ops)\r\nreturn -ENOSYS;\r\nprime = (struct ttm_prime_object *) dma_buf->priv;\r\nbase = &prime->base;\r\n*handle = base->hash.key;\r\nret = ttm_ref_object_add(tfile, base, TTM_REF_USAGE, NULL);\r\ndma_buf_put(dma_buf);\r\nreturn ret;\r\n}\r\nint ttm_prime_handle_to_fd(struct ttm_object_file *tfile,\r\nuint32_t handle, uint32_t flags,\r\nint *prime_fd)\r\n{\r\nstruct ttm_object_device *tdev = tfile->tdev;\r\nstruct ttm_base_object *base;\r\nstruct dma_buf *dma_buf;\r\nstruct ttm_prime_object *prime;\r\nint ret;\r\nbase = ttm_base_object_lookup(tfile, handle);\r\nif (unlikely(base == NULL ||\r\nbase->object_type != ttm_prime_type)) {\r\nret = -ENOENT;\r\ngoto out_unref;\r\n}\r\nprime = container_of(base, struct ttm_prime_object, base);\r\nif (unlikely(!base->shareable)) {\r\nret = -EPERM;\r\ngoto out_unref;\r\n}\r\nret = mutex_lock_interruptible(&prime->mutex);\r\nif (unlikely(ret != 0)) {\r\nret = -ERESTARTSYS;\r\ngoto out_unref;\r\n}\r\ndma_buf = prime->dma_buf;\r\nif (!dma_buf || !get_dma_buf_unless_doomed(dma_buf)) {\r\nret = ttm_mem_global_alloc(tdev->mem_glob, tdev->dma_buf_size,\r\nfalse, true);\r\nif (unlikely(ret != 0)) {\r\nmutex_unlock(&prime->mutex);\r\ngoto out_unref;\r\n}\r\ndma_buf = dma_buf_export(prime, &tdev->ops,\r\nprime->size, flags);\r\nif (IS_ERR(dma_buf)) {\r\nret = PTR_ERR(dma_buf);\r\nttm_mem_global_free(tdev->mem_glob,\r\ntdev->dma_buf_size);\r\nmutex_unlock(&prime->mutex);\r\ngoto out_unref;\r\n}\r\nbase = NULL;\r\nprime->dma_buf = dma_buf;\r\n}\r\nmutex_unlock(&prime->mutex);\r\nret = dma_buf_fd(dma_buf, flags);\r\nif (ret >= 0) {\r\n*prime_fd = ret;\r\nret = 0;\r\n} else\r\ndma_buf_put(dma_buf);\r\nout_unref:\r\nif (base)\r\nttm_base_object_unref(&base);\r\nreturn ret;\r\n}\r\nint ttm_prime_object_init(struct ttm_object_file *tfile, size_t size,\r\nstruct ttm_prime_object *prime, bool shareable,\r\nenum ttm_object_type type,\r\nvoid (*refcount_release) (struct ttm_base_object **),\r\nvoid (*ref_obj_release) (struct ttm_base_object *,\r\nenum ttm_ref_type ref_type))\r\n{\r\nmutex_init(&prime->mutex);\r\nprime->size = PAGE_ALIGN(size);\r\nprime->real_type = type;\r\nprime->dma_buf = NULL;\r\nprime->refcount_release = refcount_release;\r\nreturn ttm_base_object_init(tfile, &prime->base, shareable,\r\nttm_prime_type,\r\nttm_prime_refcount_release,\r\nref_obj_release);\r\n}
