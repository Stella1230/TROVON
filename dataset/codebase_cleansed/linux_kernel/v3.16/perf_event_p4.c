static u64 p4_get_alias_event(u64 config)\r\n{\r\nu64 config_match;\r\nint i;\r\nif (!(config & P4_CONFIG_ALIASABLE))\r\nreturn 0;\r\nconfig_match = config & P4_CONFIG_EVENT_ALIAS_MASK;\r\nfor (i = 0; i < ARRAY_SIZE(p4_event_aliases); i++) {\r\nif (config_match == p4_event_aliases[i].original) {\r\nconfig_match = p4_event_aliases[i].alternative;\r\nbreak;\r\n} else if (config_match == p4_event_aliases[i].alternative) {\r\nconfig_match = p4_event_aliases[i].original;\r\nbreak;\r\n}\r\n}\r\nif (i >= ARRAY_SIZE(p4_event_aliases))\r\nreturn 0;\r\nreturn config_match | (config & P4_CONFIG_EVENT_ALIAS_IMMUTABLE_BITS);\r\n}\r\nstatic struct p4_event_bind *p4_config_get_bind(u64 config)\r\n{\r\nunsigned int evnt = p4_config_unpack_event(config);\r\nstruct p4_event_bind *bind = NULL;\r\nif (evnt < ARRAY_SIZE(p4_event_bind_map))\r\nbind = &p4_event_bind_map[evnt];\r\nreturn bind;\r\n}\r\nstatic u64 p4_pmu_event_map(int hw_event)\r\n{\r\nstruct p4_event_bind *bind;\r\nunsigned int esel;\r\nu64 config;\r\nconfig = p4_general_events[hw_event];\r\nbind = p4_config_get_bind(config);\r\nesel = P4_OPCODE_ESEL(bind->opcode);\r\nconfig |= p4_config_pack_cccr(P4_CCCR_ESEL(esel));\r\nreturn config;\r\n}\r\nstatic bool p4_event_match_cpu_model(unsigned int event_idx)\r\n{\r\nif (event_idx == P4_EVENT_INSTR_COMPLETED) {\r\nif (boot_cpu_data.x86_model != 3 &&\r\nboot_cpu_data.x86_model != 4 &&\r\nboot_cpu_data.x86_model != 6)\r\nreturn false;\r\n}\r\nreturn true;\r\n}\r\nstatic int p4_validate_raw_event(struct perf_event *event)\r\n{\r\nunsigned int v, emask;\r\nv = p4_config_unpack_event(event->attr.config);\r\nif (v >= ARRAY_SIZE(p4_event_bind_map))\r\nreturn -EINVAL;\r\nif (!p4_event_match_cpu_model(v))\r\nreturn -EINVAL;\r\nif (p4_ht_active() && p4_event_bind_map[v].shared) {\r\nif (perf_paranoid_cpu() && !capable(CAP_SYS_ADMIN))\r\nreturn -EACCES;\r\n}\r\nemask = p4_config_unpack_escr(event->attr.config) & P4_ESCR_EVENTMASK_MASK;\r\nif (emask & ~p4_event_bind_map[v].escr_emask)\r\nreturn -EINVAL;\r\nif (p4_config_pebs_has(event->attr.config, P4_PEBS_CONFIG_ENABLE))\r\nreturn -EINVAL;\r\nv = p4_config_unpack_metric(event->attr.config);\r\nif (v >= ARRAY_SIZE(p4_pebs_bind_map))\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic int p4_hw_config(struct perf_event *event)\r\n{\r\nint cpu = get_cpu();\r\nint rc = 0;\r\nu32 escr, cccr;\r\ncccr = p4_default_cccr_conf(cpu);\r\nescr = p4_default_escr_conf(cpu, event->attr.exclude_kernel,\r\nevent->attr.exclude_user);\r\nevent->hw.config = p4_config_pack_escr(escr) |\r\np4_config_pack_cccr(cccr);\r\nif (p4_ht_active() && p4_ht_thread(cpu))\r\nevent->hw.config = p4_set_ht_bit(event->hw.config);\r\nif (event->attr.type == PERF_TYPE_RAW) {\r\nstruct p4_event_bind *bind;\r\nunsigned int esel;\r\nevent->attr.config &= P4_CONFIG_MASK;\r\nrc = p4_validate_raw_event(event);\r\nif (rc)\r\ngoto out;\r\nevent->hw.config |= event->attr.config;\r\nbind = p4_config_get_bind(event->attr.config);\r\nif (!bind) {\r\nrc = -EINVAL;\r\ngoto out;\r\n}\r\nesel = P4_OPCODE_ESEL(bind->opcode);\r\nevent->hw.config |= p4_config_pack_cccr(P4_CCCR_ESEL(esel));\r\n}\r\nrc = x86_setup_perfctr(event);\r\nout:\r\nput_cpu();\r\nreturn rc;\r\n}\r\nstatic inline int p4_pmu_clear_cccr_ovf(struct hw_perf_event *hwc)\r\n{\r\nu64 v;\r\nrdmsrl(hwc->config_base, v);\r\nif (v & P4_CCCR_OVF) {\r\nwrmsrl(hwc->config_base, v & ~P4_CCCR_OVF);\r\nreturn 1;\r\n}\r\nrdmsrl(hwc->event_base, v);\r\nif (!(v & ARCH_P4_UNFLAGGED_BIT))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic void p4_pmu_disable_pebs(void)\r\n{\r\n}\r\nstatic inline void p4_pmu_disable_event(struct perf_event *event)\r\n{\r\nstruct hw_perf_event *hwc = &event->hw;\r\n(void)wrmsrl_safe(hwc->config_base,\r\np4_config_unpack_cccr(hwc->config) & ~P4_CCCR_ENABLE & ~P4_CCCR_OVF & ~P4_CCCR_RESERVED);\r\n}\r\nstatic void p4_pmu_disable_all(void)\r\n{\r\nstruct cpu_hw_events *cpuc = &__get_cpu_var(cpu_hw_events);\r\nint idx;\r\nfor (idx = 0; idx < x86_pmu.num_counters; idx++) {\r\nstruct perf_event *event = cpuc->events[idx];\r\nif (!test_bit(idx, cpuc->active_mask))\r\ncontinue;\r\np4_pmu_disable_event(event);\r\n}\r\np4_pmu_disable_pebs();\r\n}\r\nstatic void p4_pmu_enable_pebs(u64 config)\r\n{\r\nstruct p4_pebs_bind *bind;\r\nunsigned int idx;\r\nBUILD_BUG_ON(P4_PEBS_METRIC__max > P4_PEBS_CONFIG_METRIC_MASK);\r\nidx = p4_config_unpack_metric(config);\r\nif (idx == P4_PEBS_METRIC__none)\r\nreturn;\r\nbind = &p4_pebs_bind_map[idx];\r\n(void)wrmsrl_safe(MSR_IA32_PEBS_ENABLE, (u64)bind->metric_pebs);\r\n(void)wrmsrl_safe(MSR_P4_PEBS_MATRIX_VERT, (u64)bind->metric_vert);\r\n}\r\nstatic void p4_pmu_enable_event(struct perf_event *event)\r\n{\r\nstruct hw_perf_event *hwc = &event->hw;\r\nint thread = p4_ht_config_thread(hwc->config);\r\nu64 escr_conf = p4_config_unpack_escr(p4_clear_ht_bit(hwc->config));\r\nunsigned int idx = p4_config_unpack_event(hwc->config);\r\nstruct p4_event_bind *bind;\r\nu64 escr_addr, cccr;\r\nbind = &p4_event_bind_map[idx];\r\nescr_addr = bind->escr_msr[thread];\r\nWARN_ON_ONCE(p4_is_event_cascaded(hwc->config));\r\nWARN_ON_ONCE(hwc->idx == 1);\r\nescr_conf &= ~P4_ESCR_EVENT_MASK;\r\nescr_conf |= P4_ESCR_EVENT(P4_OPCODE_EVNT(bind->opcode));\r\ncccr = p4_config_unpack_cccr(hwc->config);\r\np4_pmu_enable_pebs(hwc->config);\r\n(void)wrmsrl_safe(escr_addr, escr_conf);\r\n(void)wrmsrl_safe(hwc->config_base,\r\n(cccr & ~P4_CCCR_RESERVED) | P4_CCCR_ENABLE);\r\n}\r\nstatic void p4_pmu_enable_all(int added)\r\n{\r\nstruct cpu_hw_events *cpuc = &__get_cpu_var(cpu_hw_events);\r\nint idx;\r\nfor (idx = 0; idx < x86_pmu.num_counters; idx++) {\r\nstruct perf_event *event = cpuc->events[idx];\r\nif (!test_bit(idx, cpuc->active_mask))\r\ncontinue;\r\np4_pmu_enable_event(event);\r\n}\r\n}\r\nstatic int p4_pmu_handle_irq(struct pt_regs *regs)\r\n{\r\nstruct perf_sample_data data;\r\nstruct cpu_hw_events *cpuc;\r\nstruct perf_event *event;\r\nstruct hw_perf_event *hwc;\r\nint idx, handled = 0;\r\nu64 val;\r\ncpuc = &__get_cpu_var(cpu_hw_events);\r\nfor (idx = 0; idx < x86_pmu.num_counters; idx++) {\r\nint overflow;\r\nif (!test_bit(idx, cpuc->active_mask)) {\r\nif (__test_and_clear_bit(idx, cpuc->running))\r\nhandled++;\r\ncontinue;\r\n}\r\nevent = cpuc->events[idx];\r\nhwc = &event->hw;\r\nWARN_ON_ONCE(hwc->idx != idx);\r\noverflow = p4_pmu_clear_cccr_ovf(hwc);\r\nval = x86_perf_event_update(event);\r\nif (!overflow && (val & (1ULL << (x86_pmu.cntval_bits - 1))))\r\ncontinue;\r\nhandled += overflow;\r\nperf_sample_data_init(&data, 0, hwc->last_period);\r\nif (!x86_perf_event_set_period(event))\r\ncontinue;\r\nif (perf_event_overflow(event, &data, regs))\r\nx86_pmu_stop(event, 0);\r\n}\r\nif (handled)\r\ninc_irq_stat(apic_perf_irqs);\r\napic_write(APIC_LVTPC, APIC_DM_NMI);\r\nreturn handled;\r\n}\r\nstatic void p4_pmu_swap_config_ts(struct hw_perf_event *hwc, int cpu)\r\n{\r\nu32 escr, cccr;\r\nif (!p4_should_swap_ts(hwc->config, cpu))\r\nreturn;\r\nescr = p4_config_unpack_escr(hwc->config);\r\ncccr = p4_config_unpack_cccr(hwc->config);\r\nif (p4_ht_thread(cpu)) {\r\ncccr &= ~P4_CCCR_OVF_PMI_T0;\r\ncccr |= P4_CCCR_OVF_PMI_T1;\r\nif (escr & P4_ESCR_T0_OS) {\r\nescr &= ~P4_ESCR_T0_OS;\r\nescr |= P4_ESCR_T1_OS;\r\n}\r\nif (escr & P4_ESCR_T0_USR) {\r\nescr &= ~P4_ESCR_T0_USR;\r\nescr |= P4_ESCR_T1_USR;\r\n}\r\nhwc->config = p4_config_pack_escr(escr);\r\nhwc->config |= p4_config_pack_cccr(cccr);\r\nhwc->config |= P4_CONFIG_HT;\r\n} else {\r\ncccr &= ~P4_CCCR_OVF_PMI_T1;\r\ncccr |= P4_CCCR_OVF_PMI_T0;\r\nif (escr & P4_ESCR_T1_OS) {\r\nescr &= ~P4_ESCR_T1_OS;\r\nescr |= P4_ESCR_T0_OS;\r\n}\r\nif (escr & P4_ESCR_T1_USR) {\r\nescr &= ~P4_ESCR_T1_USR;\r\nescr |= P4_ESCR_T0_USR;\r\n}\r\nhwc->config = p4_config_pack_escr(escr);\r\nhwc->config |= p4_config_pack_cccr(cccr);\r\nhwc->config &= ~P4_CONFIG_HT;\r\n}\r\n}\r\nstatic int p4_get_escr_idx(unsigned int addr)\r\n{\r\nunsigned int idx = P4_ESCR_MSR_IDX(addr);\r\nif (unlikely(idx >= P4_ESCR_MSR_TABLE_SIZE ||\r\n!p4_escr_table[idx] ||\r\np4_escr_table[idx] != addr)) {\r\nWARN_ONCE(1, "P4 PMU: Wrong address passed: %x\n", addr);\r\nreturn -1;\r\n}\r\nreturn idx;\r\n}\r\nstatic int p4_next_cntr(int thread, unsigned long *used_mask,\r\nstruct p4_event_bind *bind)\r\n{\r\nint i, j;\r\nfor (i = 0; i < P4_CNTR_LIMIT; i++) {\r\nj = bind->cntr[thread][i];\r\nif (j != -1 && !test_bit(j, used_mask))\r\nreturn j;\r\n}\r\nreturn -1;\r\n}\r\nstatic int p4_pmu_schedule_events(struct cpu_hw_events *cpuc, int n, int *assign)\r\n{\r\nunsigned long used_mask[BITS_TO_LONGS(X86_PMC_IDX_MAX)];\r\nunsigned long escr_mask[BITS_TO_LONGS(P4_ESCR_MSR_TABLE_SIZE)];\r\nint cpu = smp_processor_id();\r\nstruct hw_perf_event *hwc;\r\nstruct p4_event_bind *bind;\r\nunsigned int i, thread, num;\r\nint cntr_idx, escr_idx;\r\nu64 config_alias;\r\nint pass;\r\nbitmap_zero(used_mask, X86_PMC_IDX_MAX);\r\nbitmap_zero(escr_mask, P4_ESCR_MSR_TABLE_SIZE);\r\nfor (i = 0, num = n; i < n; i++, num--) {\r\nhwc = &cpuc->event_list[i]->hw;\r\nthread = p4_ht_thread(cpu);\r\npass = 0;\r\nagain:\r\nif (pass > 2)\r\ngoto done;\r\nbind = p4_config_get_bind(hwc->config);\r\nescr_idx = p4_get_escr_idx(bind->escr_msr[thread]);\r\nif (unlikely(escr_idx == -1))\r\ngoto done;\r\nif (hwc->idx != -1 && !p4_should_swap_ts(hwc->config, cpu)) {\r\ncntr_idx = hwc->idx;\r\nif (assign)\r\nassign[i] = hwc->idx;\r\ngoto reserve;\r\n}\r\ncntr_idx = p4_next_cntr(thread, used_mask, bind);\r\nif (cntr_idx == -1 || test_bit(escr_idx, escr_mask)) {\r\nconfig_alias = p4_get_alias_event(hwc->config);\r\nif (!config_alias)\r\ngoto done;\r\nhwc->config = config_alias;\r\npass++;\r\ngoto again;\r\n}\r\nif (p4_should_swap_ts(hwc->config, cpu))\r\nhwc->idx = -1;\r\np4_pmu_swap_config_ts(hwc, cpu);\r\nif (assign)\r\nassign[i] = cntr_idx;\r\nreserve:\r\nset_bit(cntr_idx, used_mask);\r\nset_bit(escr_idx, escr_mask);\r\n}\r\ndone:\r\nreturn num ? -EINVAL : 0;\r\n}\r\n__init int p4_pmu_init(void)\r\n{\r\nunsigned int low, high;\r\nint i, reg;\r\nBUILD_BUG_ON(ARCH_P4_MAX_CCCR > INTEL_PMC_MAX_GENERIC);\r\nrdmsr(MSR_IA32_MISC_ENABLE, low, high);\r\nif (!(low & (1 << 7))) {\r\npr_cont("unsupported Netburst CPU model %d ",\r\nboot_cpu_data.x86_model);\r\nreturn -ENODEV;\r\n}\r\nmemcpy(hw_cache_event_ids, p4_hw_cache_event_ids,\r\nsizeof(hw_cache_event_ids));\r\npr_cont("Netburst events, ");\r\nx86_pmu = p4_pmu;\r\nfor (i = 0; i < x86_pmu.num_counters; i++) {\r\nreg = x86_pmu_config_addr(i);\r\nwrmsrl_safe(reg, 0ULL);\r\n}\r\nreturn 0;\r\n}
