static u64 replace_wr_id(u64 wr_id, u16 idx)\r\n{\r\nu64 ret;\r\nret = wr_id & ~QMAP_IDX_MASK;\r\nret |= idx & QMAP_IDX_MASK;\r\nreturn ret;\r\n}\r\nstatic u16 get_app_wr_id(u64 wr_id)\r\n{\r\nreturn wr_id & QMAP_IDX_MASK;\r\n}\r\nstatic inline int ehca_write_rwqe(struct ipz_queue *ipz_rqueue,\r\nstruct ehca_wqe *wqe_p,\r\nstruct ib_recv_wr *recv_wr,\r\nu32 rq_map_idx)\r\n{\r\nu8 cnt_ds;\r\nif (unlikely((recv_wr->num_sge < 0) ||\r\n(recv_wr->num_sge > ipz_rqueue->act_nr_of_sg))) {\r\nehca_gen_err("Invalid number of WQE SGE. "\r\n"num_sqe=%x max_nr_of_sg=%x",\r\nrecv_wr->num_sge, ipz_rqueue->act_nr_of_sg);\r\nreturn -EINVAL;\r\n}\r\nmemset(wqe_p, 0, offsetof(struct ehca_wqe, u.ud_av.sg_list));\r\nwqe_p->work_request_id = replace_wr_id(recv_wr->wr_id, rq_map_idx);\r\nwqe_p->nr_of_data_seg = recv_wr->num_sge;\r\nfor (cnt_ds = 0; cnt_ds < recv_wr->num_sge; cnt_ds++) {\r\nwqe_p->u.all_rcv.sg_list[cnt_ds].vaddr =\r\nrecv_wr->sg_list[cnt_ds].addr;\r\nwqe_p->u.all_rcv.sg_list[cnt_ds].lkey =\r\nrecv_wr->sg_list[cnt_ds].lkey;\r\nwqe_p->u.all_rcv.sg_list[cnt_ds].length =\r\nrecv_wr->sg_list[cnt_ds].length;\r\n}\r\nif (ehca_debug_level >= 3) {\r\nehca_gen_dbg("RECEIVE WQE written into ipz_rqueue=%p",\r\nipz_rqueue);\r\nehca_dmp(wqe_p, 16*(6 + wqe_p->nr_of_data_seg), "recv wqe");\r\n}\r\nreturn 0;\r\n}\r\nstatic void trace_send_wr_ud(const struct ib_send_wr *send_wr)\r\n{\r\nint idx;\r\nint j;\r\nwhile (send_wr) {\r\nstruct ib_mad_hdr *mad_hdr = send_wr->wr.ud.mad_hdr;\r\nstruct ib_sge *sge = send_wr->sg_list;\r\nehca_gen_dbg("send_wr#%x wr_id=%lx num_sge=%x "\r\n"send_flags=%x opcode=%x", idx, send_wr->wr_id,\r\nsend_wr->num_sge, send_wr->send_flags,\r\nsend_wr->opcode);\r\nif (mad_hdr) {\r\nehca_gen_dbg("send_wr#%x mad_hdr base_version=%x "\r\n"mgmt_class=%x class_version=%x method=%x "\r\n"status=%x class_specific=%x tid=%lx "\r\n"attr_id=%x resv=%x attr_mod=%x",\r\nidx, mad_hdr->base_version,\r\nmad_hdr->mgmt_class,\r\nmad_hdr->class_version, mad_hdr->method,\r\nmad_hdr->status, mad_hdr->class_specific,\r\nmad_hdr->tid, mad_hdr->attr_id,\r\nmad_hdr->resv,\r\nmad_hdr->attr_mod);\r\n}\r\nfor (j = 0; j < send_wr->num_sge; j++) {\r\nu8 *data = __va(sge->addr);\r\nehca_gen_dbg("send_wr#%x sge#%x addr=%p length=%x "\r\n"lkey=%x",\r\nidx, j, data, sge->length, sge->lkey);\r\nehca_dmp(data, sge->length, "send_wr#%x sge#%x",\r\nidx, j);\r\nsge++;\r\n}\r\nidx++;\r\nsend_wr = send_wr->next;\r\n}\r\n}\r\nstatic inline int ehca_write_swqe(struct ehca_qp *qp,\r\nstruct ehca_wqe *wqe_p,\r\nconst struct ib_send_wr *send_wr,\r\nu32 sq_map_idx,\r\nint hidden)\r\n{\r\nu32 idx;\r\nu64 dma_length;\r\nstruct ehca_av *my_av;\r\nu32 remote_qkey = send_wr->wr.ud.remote_qkey;\r\nstruct ehca_qmap_entry *qmap_entry = &qp->sq_map.map[sq_map_idx];\r\nif (unlikely((send_wr->num_sge < 0) ||\r\n(send_wr->num_sge > qp->ipz_squeue.act_nr_of_sg))) {\r\nehca_gen_err("Invalid number of WQE SGE. "\r\n"num_sqe=%x max_nr_of_sg=%x",\r\nsend_wr->num_sge, qp->ipz_squeue.act_nr_of_sg);\r\nreturn -EINVAL;\r\n}\r\nmemset(wqe_p, 0, offsetof(struct ehca_wqe, u.ud_av.sg_list));\r\nwqe_p->work_request_id = replace_wr_id(send_wr->wr_id, sq_map_idx);\r\nqmap_entry->app_wr_id = get_app_wr_id(send_wr->wr_id);\r\nqmap_entry->reported = 0;\r\nqmap_entry->cqe_req = 0;\r\nswitch (send_wr->opcode) {\r\ncase IB_WR_SEND:\r\ncase IB_WR_SEND_WITH_IMM:\r\nwqe_p->optype = WQE_OPTYPE_SEND;\r\nbreak;\r\ncase IB_WR_RDMA_WRITE:\r\ncase IB_WR_RDMA_WRITE_WITH_IMM:\r\nwqe_p->optype = WQE_OPTYPE_RDMAWRITE;\r\nbreak;\r\ncase IB_WR_RDMA_READ:\r\nwqe_p->optype = WQE_OPTYPE_RDMAREAD;\r\nbreak;\r\ndefault:\r\nehca_gen_err("Invalid opcode=%x", send_wr->opcode);\r\nreturn -EINVAL;\r\n}\r\nwqe_p->wqef = (send_wr->opcode) & WQEF_HIGH_NIBBLE;\r\nwqe_p->wr_flag = 0;\r\nif ((send_wr->send_flags & IB_SEND_SIGNALED ||\r\nqp->init_attr.sq_sig_type == IB_SIGNAL_ALL_WR)\r\n&& !hidden) {\r\nwqe_p->wr_flag |= WQE_WRFLAG_REQ_SIGNAL_COM;\r\nqmap_entry->cqe_req = 1;\r\n}\r\nif (send_wr->opcode == IB_WR_SEND_WITH_IMM ||\r\nsend_wr->opcode == IB_WR_RDMA_WRITE_WITH_IMM) {\r\nwqe_p->immediate_data = be32_to_cpu(send_wr->ex.imm_data);\r\nwqe_p->wr_flag |= WQE_WRFLAG_IMM_DATA_PRESENT;\r\n}\r\nwqe_p->nr_of_data_seg = send_wr->num_sge;\r\nswitch (qp->qp_type) {\r\ncase IB_QPT_SMI:\r\ncase IB_QPT_GSI:\r\ncase IB_QPT_UD:\r\nif (send_wr->wr.ud.remote_qkey & 0x80000000)\r\nremote_qkey = qp->qkey;\r\nwqe_p->destination_qp_number = send_wr->wr.ud.remote_qpn << 8;\r\nwqe_p->local_ee_context_qkey = remote_qkey;\r\nif (unlikely(!send_wr->wr.ud.ah)) {\r\nehca_gen_err("wr.ud.ah is NULL. qp=%p", qp);\r\nreturn -EINVAL;\r\n}\r\nif (unlikely(send_wr->wr.ud.remote_qpn == 0)) {\r\nehca_gen_err("dest QP# is 0. qp=%x", qp->real_qp_num);\r\nreturn -EINVAL;\r\n}\r\nmy_av = container_of(send_wr->wr.ud.ah, struct ehca_av, ib_ah);\r\nwqe_p->u.ud_av.ud_av = my_av->av;\r\nfor (idx = 0; idx < send_wr->num_sge; idx++) {\r\nwqe_p->u.ud_av.sg_list[idx].vaddr =\r\nsend_wr->sg_list[idx].addr;\r\nwqe_p->u.ud_av.sg_list[idx].lkey =\r\nsend_wr->sg_list[idx].lkey;\r\nwqe_p->u.ud_av.sg_list[idx].length =\r\nsend_wr->sg_list[idx].length;\r\n}\r\nif (qp->qp_type == IB_QPT_SMI ||\r\nqp->qp_type == IB_QPT_GSI)\r\nwqe_p->u.ud_av.ud_av.pmtu = 1;\r\nif (qp->qp_type == IB_QPT_GSI) {\r\nwqe_p->pkeyi = send_wr->wr.ud.pkey_index;\r\n#ifdef DEBUG_GSI_SEND_WR\r\ntrace_send_wr_ud(send_wr);\r\n#endif\r\n}\r\nbreak;\r\ncase IB_QPT_UC:\r\nif (send_wr->send_flags & IB_SEND_FENCE)\r\nwqe_p->wr_flag |= WQE_WRFLAG_FENCE;\r\ncase IB_QPT_RC:\r\nwqe_p->u.nud.remote_virtual_address =\r\nsend_wr->wr.rdma.remote_addr;\r\nwqe_p->u.nud.rkey = send_wr->wr.rdma.rkey;\r\ndma_length = 0;\r\nfor (idx = 0; idx < send_wr->num_sge; idx++) {\r\nwqe_p->u.nud.sg_list[idx].vaddr =\r\nsend_wr->sg_list[idx].addr;\r\nwqe_p->u.nud.sg_list[idx].lkey =\r\nsend_wr->sg_list[idx].lkey;\r\nwqe_p->u.nud.sg_list[idx].length =\r\nsend_wr->sg_list[idx].length;\r\ndma_length += send_wr->sg_list[idx].length;\r\n}\r\nwqe_p->u.nud.atomic_1st_op_dma_len = dma_length;\r\nif (send_wr->opcode == IB_WR_RDMA_READ) {\r\nqp->message_count = qp->packet_count = 0;\r\nqp->unsol_ack_circ = 1;\r\n} else\r\nqp->packet_count += (dma_length >> qp->mtu_shift) + 1;\r\nbreak;\r\ndefault:\r\nehca_gen_err("Invalid qptype=%x", qp->qp_type);\r\nreturn -EINVAL;\r\n}\r\nif (ehca_debug_level >= 3) {\r\nehca_gen_dbg("SEND WQE written into queue qp=%p ", qp);\r\nehca_dmp( wqe_p, 16*(6 + wqe_p->nr_of_data_seg), "send wqe");\r\n}\r\nreturn 0;\r\n}\r\nstatic inline void map_ib_wc_status(u32 cqe_status,\r\nenum ib_wc_status *wc_status)\r\n{\r\nif (unlikely(cqe_status & WC_STATUS_ERROR_BIT)) {\r\nswitch (cqe_status & 0x3F) {\r\ncase 0x01:\r\ncase 0x21:\r\n*wc_status = IB_WC_LOC_LEN_ERR;\r\nbreak;\r\ncase 0x02:\r\ncase 0x22:\r\n*wc_status = IB_WC_LOC_QP_OP_ERR;\r\nbreak;\r\ncase 0x03:\r\ncase 0x23:\r\n*wc_status = IB_WC_LOC_EEC_OP_ERR;\r\nbreak;\r\ncase 0x04:\r\ncase 0x24:\r\n*wc_status = IB_WC_LOC_PROT_ERR;\r\nbreak;\r\ncase 0x05:\r\ncase 0x25:\r\n*wc_status = IB_WC_WR_FLUSH_ERR;\r\nbreak;\r\ncase 0x06:\r\n*wc_status = IB_WC_MW_BIND_ERR;\r\nbreak;\r\ncase 0x07:\r\nswitch ((cqe_status\r\n& WC_STATUS_REMOTE_ERROR_FLAGS) >> 11) {\r\ncase 0x0:\r\n*wc_status = IB_WC_GENERAL_ERR;\r\nbreak;\r\ncase 0x1:\r\n*wc_status = IB_WC_REM_INV_REQ_ERR;\r\nbreak;\r\ncase 0x2:\r\n*wc_status = IB_WC_REM_ACCESS_ERR;\r\nbreak;\r\ncase 0x3:\r\n*wc_status = IB_WC_REM_OP_ERR;\r\nbreak;\r\ncase 0x4:\r\n*wc_status = IB_WC_REM_INV_RD_REQ_ERR;\r\nbreak;\r\n}\r\nbreak;\r\ncase 0x08:\r\n*wc_status = IB_WC_RETRY_EXC_ERR;\r\nbreak;\r\ncase 0x09:\r\n*wc_status = IB_WC_RNR_RETRY_EXC_ERR;\r\nbreak;\r\ncase 0x0A:\r\ncase 0x2D:\r\n*wc_status = IB_WC_REM_ABORT_ERR;\r\nbreak;\r\ncase 0x0B:\r\ncase 0x2E:\r\n*wc_status = IB_WC_INV_EECN_ERR;\r\nbreak;\r\ncase 0x0C:\r\ncase 0x2F:\r\n*wc_status = IB_WC_INV_EEC_STATE_ERR;\r\nbreak;\r\ncase 0x0D:\r\n*wc_status = IB_WC_BAD_RESP_ERR;\r\nbreak;\r\ncase 0x10:\r\n*wc_status = IB_WC_WR_FLUSH_ERR;\r\nbreak;\r\ndefault:\r\n*wc_status = IB_WC_FATAL_ERR;\r\n}\r\n} else\r\n*wc_status = IB_WC_SUCCESS;\r\n}\r\nstatic inline int post_one_send(struct ehca_qp *my_qp,\r\nstruct ib_send_wr *cur_send_wr,\r\nint hidden)\r\n{\r\nstruct ehca_wqe *wqe_p;\r\nint ret;\r\nu32 sq_map_idx;\r\nu64 start_offset = my_qp->ipz_squeue.current_q_offset;\r\nwqe_p = ipz_qeit_get_inc(&my_qp->ipz_squeue);\r\nif (unlikely(!wqe_p)) {\r\nehca_err(my_qp->ib_qp.device, "Too many posted WQEs "\r\n"qp_num=%x", my_qp->ib_qp.qp_num);\r\nreturn -ENOMEM;\r\n}\r\nsq_map_idx = start_offset / my_qp->ipz_squeue.qe_size;\r\nret = ehca_write_swqe(my_qp, wqe_p, cur_send_wr, sq_map_idx, hidden);\r\nif (unlikely(ret)) {\r\nmy_qp->ipz_squeue.current_q_offset = start_offset;\r\nehca_err(my_qp->ib_qp.device, "Could not write WQE "\r\n"qp_num=%x", my_qp->ib_qp.qp_num);\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nint ehca_post_send(struct ib_qp *qp,\r\nstruct ib_send_wr *send_wr,\r\nstruct ib_send_wr **bad_send_wr)\r\n{\r\nstruct ehca_qp *my_qp = container_of(qp, struct ehca_qp, ib_qp);\r\nint wqe_cnt = 0;\r\nint ret = 0;\r\nunsigned long flags;\r\nif (unlikely(my_qp->state < IB_QPS_RTS)) {\r\nehca_err(qp->device, "Invalid QP state qp_state=%d qpn=%x",\r\nmy_qp->state, qp->qp_num);\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nspin_lock_irqsave(&my_qp->spinlock_s, flags);\r\nif (unlikely(my_qp->unsol_ack_circ &&\r\nmy_qp->packet_count > ACK_CIRC_THRESHOLD &&\r\nmy_qp->message_count > my_qp->init_attr.cap.max_send_wr)) {\r\nstruct ib_send_wr circ_wr;\r\nmemset(&circ_wr, 0, sizeof(circ_wr));\r\ncirc_wr.opcode = IB_WR_RDMA_READ;\r\npost_one_send(my_qp, &circ_wr, 1);\r\nwqe_cnt++;\r\nehca_dbg(qp->device, "posted circ wr qp_num=%x", qp->qp_num);\r\nmy_qp->message_count = my_qp->packet_count = 0;\r\n}\r\nwhile (send_wr) {\r\nret = post_one_send(my_qp, send_wr, 0);\r\nif (unlikely(ret)) {\r\ngoto post_send_exit0;\r\n}\r\nwqe_cnt++;\r\nsend_wr = send_wr->next;\r\n}\r\npost_send_exit0:\r\niosync();\r\nhipz_update_sqa(my_qp, wqe_cnt);\r\nif (unlikely(ret || ehca_debug_level >= 2))\r\nehca_dbg(qp->device, "ehca_qp=%p qp_num=%x wqe_cnt=%d ret=%i",\r\nmy_qp, qp->qp_num, wqe_cnt, ret);\r\nmy_qp->message_count += wqe_cnt;\r\nspin_unlock_irqrestore(&my_qp->spinlock_s, flags);\r\nout:\r\nif (ret)\r\n*bad_send_wr = send_wr;\r\nreturn ret;\r\n}\r\nstatic int internal_post_recv(struct ehca_qp *my_qp,\r\nstruct ib_device *dev,\r\nstruct ib_recv_wr *recv_wr,\r\nstruct ib_recv_wr **bad_recv_wr)\r\n{\r\nstruct ehca_wqe *wqe_p;\r\nint wqe_cnt = 0;\r\nint ret = 0;\r\nu32 rq_map_idx;\r\nunsigned long flags;\r\nstruct ehca_qmap_entry *qmap_entry;\r\nif (unlikely(!HAS_RQ(my_qp))) {\r\nehca_err(dev, "QP has no RQ ehca_qp=%p qp_num=%x ext_type=%d",\r\nmy_qp, my_qp->real_qp_num, my_qp->ext_type);\r\nret = -ENODEV;\r\ngoto out;\r\n}\r\nspin_lock_irqsave(&my_qp->spinlock_r, flags);\r\nwhile (recv_wr) {\r\nu64 start_offset = my_qp->ipz_rqueue.current_q_offset;\r\nwqe_p = ipz_qeit_get_inc(&my_qp->ipz_rqueue);\r\nif (unlikely(!wqe_p)) {\r\nret = -ENOMEM;\r\nehca_err(dev, "Too many posted WQEs "\r\n"qp_num=%x", my_qp->real_qp_num);\r\ngoto post_recv_exit0;\r\n}\r\nrq_map_idx = start_offset / my_qp->ipz_rqueue.qe_size;\r\nret = ehca_write_rwqe(&my_qp->ipz_rqueue, wqe_p, recv_wr,\r\nrq_map_idx);\r\nif (unlikely(ret)) {\r\nmy_qp->ipz_rqueue.current_q_offset = start_offset;\r\nret = -EINVAL;\r\nehca_err(dev, "Could not write WQE "\r\n"qp_num=%x", my_qp->real_qp_num);\r\ngoto post_recv_exit0;\r\n}\r\nqmap_entry = &my_qp->rq_map.map[rq_map_idx];\r\nqmap_entry->app_wr_id = get_app_wr_id(recv_wr->wr_id);\r\nqmap_entry->reported = 0;\r\nqmap_entry->cqe_req = 1;\r\nwqe_cnt++;\r\nrecv_wr = recv_wr->next;\r\n}\r\npost_recv_exit0:\r\niosync();\r\nhipz_update_rqa(my_qp, wqe_cnt);\r\nif (unlikely(ret || ehca_debug_level >= 2))\r\nehca_dbg(dev, "ehca_qp=%p qp_num=%x wqe_cnt=%d ret=%i",\r\nmy_qp, my_qp->real_qp_num, wqe_cnt, ret);\r\nspin_unlock_irqrestore(&my_qp->spinlock_r, flags);\r\nout:\r\nif (ret)\r\n*bad_recv_wr = recv_wr;\r\nreturn ret;\r\n}\r\nint ehca_post_recv(struct ib_qp *qp,\r\nstruct ib_recv_wr *recv_wr,\r\nstruct ib_recv_wr **bad_recv_wr)\r\n{\r\nstruct ehca_qp *my_qp = container_of(qp, struct ehca_qp, ib_qp);\r\nif (unlikely(my_qp->state == IB_QPS_RESET)) {\r\nehca_err(qp->device, "Invalid QP state qp_state=%d qpn=%x",\r\nmy_qp->state, qp->qp_num);\r\n*bad_recv_wr = recv_wr;\r\nreturn -EINVAL;\r\n}\r\nreturn internal_post_recv(my_qp, qp->device, recv_wr, bad_recv_wr);\r\n}\r\nint ehca_post_srq_recv(struct ib_srq *srq,\r\nstruct ib_recv_wr *recv_wr,\r\nstruct ib_recv_wr **bad_recv_wr)\r\n{\r\nreturn internal_post_recv(container_of(srq, struct ehca_qp, ib_srq),\r\nsrq->device, recv_wr, bad_recv_wr);\r\n}\r\nstatic inline int ehca_poll_cq_one(struct ib_cq *cq, struct ib_wc *wc)\r\n{\r\nint ret = 0, qmap_tail_idx;\r\nstruct ehca_cq *my_cq = container_of(cq, struct ehca_cq, ib_cq);\r\nstruct ehca_cqe *cqe;\r\nstruct ehca_qp *my_qp;\r\nstruct ehca_qmap_entry *qmap_entry;\r\nstruct ehca_queue_map *qmap;\r\nint cqe_count = 0, is_error;\r\nrepoll:\r\ncqe = (struct ehca_cqe *)\r\nipz_qeit_get_inc_valid(&my_cq->ipz_queue);\r\nif (!cqe) {\r\nret = -EAGAIN;\r\nif (ehca_debug_level >= 3)\r\nehca_dbg(cq->device, "Completion queue is empty "\r\n"my_cq=%p cq_num=%x", my_cq, my_cq->cq_number);\r\ngoto poll_cq_one_exit0;\r\n}\r\nrmb();\r\ncqe_count++;\r\nif (unlikely(cqe->status & WC_STATUS_PURGE_BIT)) {\r\nstruct ehca_qp *qp;\r\nint purgeflag;\r\nunsigned long flags;\r\nqp = ehca_cq_get_qp(my_cq, cqe->local_qp_number);\r\nif (!qp) {\r\nehca_err(cq->device, "cq_num=%x qp_num=%x "\r\n"could not find qp -> ignore cqe",\r\nmy_cq->cq_number, cqe->local_qp_number);\r\nehca_dmp(cqe, 64, "cq_num=%x qp_num=%x",\r\nmy_cq->cq_number, cqe->local_qp_number);\r\ngoto repoll;\r\n}\r\nspin_lock_irqsave(&qp->spinlock_s, flags);\r\npurgeflag = qp->sqerr_purgeflag;\r\nspin_unlock_irqrestore(&qp->spinlock_s, flags);\r\nif (purgeflag) {\r\nehca_dbg(cq->device,\r\n"Got CQE with purged bit qp_num=%x src_qp=%x",\r\ncqe->local_qp_number, cqe->remote_qp_number);\r\nif (ehca_debug_level >= 2)\r\nehca_dmp(cqe, 64, "qp_num=%x src_qp=%x",\r\ncqe->local_qp_number,\r\ncqe->remote_qp_number);\r\nqp->sqerr_purgeflag = 0;\r\ngoto repoll;\r\n}\r\n}\r\nis_error = cqe->status & WC_STATUS_ERROR_BIT;\r\nif (unlikely(ehca_debug_level >= 3 || (ehca_debug_level && is_error))) {\r\nehca_dbg(cq->device,\r\n"Received %sCOMPLETION ehca_cq=%p cq_num=%x -----",\r\nis_error ? "ERROR " : "", my_cq, my_cq->cq_number);\r\nehca_dmp(cqe, 64, "ehca_cq=%p cq_num=%x",\r\nmy_cq, my_cq->cq_number);\r\nehca_dbg(cq->device,\r\n"ehca_cq=%p cq_num=%x -------------------------",\r\nmy_cq, my_cq->cq_number);\r\n}\r\nread_lock(&ehca_qp_idr_lock);\r\nmy_qp = idr_find(&ehca_qp_idr, cqe->qp_token);\r\nread_unlock(&ehca_qp_idr_lock);\r\nif (!my_qp)\r\ngoto repoll;\r\nwc->qp = &my_qp->ib_qp;\r\nqmap_tail_idx = get_app_wr_id(cqe->work_request_id);\r\nif (!(cqe->w_completion_flags & WC_SEND_RECEIVE_BIT))\r\nqmap = &my_qp->sq_map;\r\nelse\r\nqmap = &my_qp->rq_map;\r\nqmap->tail = qmap_tail_idx;\r\nif (is_error) {\r\nmy_qp->sq_map.next_wqe_idx = next_index(my_qp->sq_map.tail,\r\nmy_qp->sq_map.entries);\r\nmy_qp->sq_map.left_to_poll = 0;\r\nehca_add_to_err_list(my_qp, 1);\r\nmy_qp->rq_map.next_wqe_idx = next_index(my_qp->rq_map.tail,\r\nmy_qp->rq_map.entries);\r\nmy_qp->rq_map.left_to_poll = 0;\r\nif (HAS_RQ(my_qp))\r\nehca_add_to_err_list(my_qp, 0);\r\n}\r\nqmap_entry = &qmap->map[qmap_tail_idx];\r\nif (qmap_entry->reported) {\r\nehca_warn(cq->device, "Double cqe on qp_num=%#x",\r\nmy_qp->real_qp_num);\r\ngoto repoll;\r\n}\r\nwc->wr_id = replace_wr_id(cqe->work_request_id, qmap_entry->app_wr_id);\r\nqmap_entry->reported = 1;\r\nif (qmap->left_to_poll > 0) {\r\nqmap->left_to_poll--;\r\nif ((my_qp->sq_map.left_to_poll == 0) &&\r\n(my_qp->rq_map.left_to_poll == 0)) {\r\nehca_add_to_err_list(my_qp, 1);\r\nif (HAS_RQ(my_qp))\r\nehca_add_to_err_list(my_qp, 0);\r\n}\r\n}\r\nwc->opcode = ib_wc_opcode[cqe->optype]-1;\r\nif (unlikely(wc->opcode == -1)) {\r\nehca_err(cq->device, "Invalid cqe->OPType=%x cqe->status=%x "\r\n"ehca_cq=%p cq_num=%x",\r\ncqe->optype, cqe->status, my_cq, my_cq->cq_number);\r\nehca_dmp(cqe, 64, "ehca_cq=%p cq_num=%x",\r\nmy_cq, my_cq->cq_number);\r\ngoto repoll;\r\n}\r\nif (unlikely(is_error)) {\r\nmap_ib_wc_status(cqe->status, &wc->status);\r\nwc->vendor_err = wc->status;\r\n} else\r\nwc->status = IB_WC_SUCCESS;\r\nwc->byte_len = cqe->nr_bytes_transferred;\r\nwc->pkey_index = cqe->pkey_index;\r\nwc->slid = cqe->rlid;\r\nwc->dlid_path_bits = cqe->dlid;\r\nwc->src_qp = cqe->remote_qp_number;\r\nwc->wc_flags = (cqe->w_completion_flags >> 5) & 3;\r\nwc->ex.imm_data = cpu_to_be32(cqe->immediate_data);\r\nwc->sl = cqe->service_level;\r\npoll_cq_one_exit0:\r\nif (cqe_count > 0)\r\nhipz_update_feca(my_cq, cqe_count);\r\nreturn ret;\r\n}\r\nstatic int generate_flush_cqes(struct ehca_qp *my_qp, struct ib_cq *cq,\r\nstruct ib_wc *wc, int num_entries,\r\nstruct ipz_queue *ipz_queue, int on_sq)\r\n{\r\nint nr = 0;\r\nstruct ehca_wqe *wqe;\r\nu64 offset;\r\nstruct ehca_queue_map *qmap;\r\nstruct ehca_qmap_entry *qmap_entry;\r\nif (on_sq)\r\nqmap = &my_qp->sq_map;\r\nelse\r\nqmap = &my_qp->rq_map;\r\nqmap_entry = &qmap->map[qmap->next_wqe_idx];\r\nwhile ((nr < num_entries) && (qmap_entry->reported == 0)) {\r\nmemset(wc, 0, sizeof(*wc));\r\noffset = qmap->next_wqe_idx * ipz_queue->qe_size;\r\nwqe = (struct ehca_wqe *)ipz_qeit_calc(ipz_queue, offset);\r\nif (!wqe) {\r\nehca_err(cq->device, "Invalid wqe offset=%#llx on "\r\n"qp_num=%#x", offset, my_qp->real_qp_num);\r\nreturn nr;\r\n}\r\nwc->wr_id = replace_wr_id(wqe->work_request_id,\r\nqmap_entry->app_wr_id);\r\nif (on_sq) {\r\nswitch (wqe->optype) {\r\ncase WQE_OPTYPE_SEND:\r\nwc->opcode = IB_WC_SEND;\r\nbreak;\r\ncase WQE_OPTYPE_RDMAWRITE:\r\nwc->opcode = IB_WC_RDMA_WRITE;\r\nbreak;\r\ncase WQE_OPTYPE_RDMAREAD:\r\nwc->opcode = IB_WC_RDMA_READ;\r\nbreak;\r\ndefault:\r\nehca_err(cq->device, "Invalid optype=%x",\r\nwqe->optype);\r\nreturn nr;\r\n}\r\n} else\r\nwc->opcode = IB_WC_RECV;\r\nif (wqe->wr_flag & WQE_WRFLAG_IMM_DATA_PRESENT) {\r\nwc->ex.imm_data = wqe->immediate_data;\r\nwc->wc_flags |= IB_WC_WITH_IMM;\r\n}\r\nwc->status = IB_WC_WR_FLUSH_ERR;\r\nwc->qp = &my_qp->ib_qp;\r\nqmap_entry->reported = 1;\r\nqmap->next_wqe_idx = next_index(qmap->next_wqe_idx,\r\nqmap->entries);\r\nqmap_entry = &qmap->map[qmap->next_wqe_idx];\r\nwc++; nr++;\r\n}\r\nreturn nr;\r\n}\r\nint ehca_poll_cq(struct ib_cq *cq, int num_entries, struct ib_wc *wc)\r\n{\r\nstruct ehca_cq *my_cq = container_of(cq, struct ehca_cq, ib_cq);\r\nint nr;\r\nstruct ehca_qp *err_qp;\r\nstruct ib_wc *current_wc = wc;\r\nint ret = 0;\r\nunsigned long flags;\r\nint entries_left = num_entries;\r\nif (num_entries < 1) {\r\nehca_err(cq->device, "Invalid num_entries=%d ehca_cq=%p "\r\n"cq_num=%x", num_entries, my_cq, my_cq->cq_number);\r\nret = -EINVAL;\r\ngoto poll_cq_exit0;\r\n}\r\nspin_lock_irqsave(&my_cq->spinlock, flags);\r\nlist_for_each_entry(err_qp, &my_cq->sqp_err_list, sq_err_node) {\r\nnr = generate_flush_cqes(err_qp, cq, current_wc, entries_left,\r\n&err_qp->ipz_squeue, 1);\r\nentries_left -= nr;\r\ncurrent_wc += nr;\r\nif (entries_left == 0)\r\nbreak;\r\n}\r\nlist_for_each_entry(err_qp, &my_cq->rqp_err_list, rq_err_node) {\r\nnr = generate_flush_cqes(err_qp, cq, current_wc, entries_left,\r\n&err_qp->ipz_rqueue, 0);\r\nentries_left -= nr;\r\ncurrent_wc += nr;\r\nif (entries_left == 0)\r\nbreak;\r\n}\r\nfor (nr = 0; nr < entries_left; nr++) {\r\nret = ehca_poll_cq_one(cq, current_wc);\r\nif (ret)\r\nbreak;\r\ncurrent_wc++;\r\n}\r\nentries_left -= nr;\r\nspin_unlock_irqrestore(&my_cq->spinlock, flags);\r\nif (ret == -EAGAIN || !ret)\r\nret = num_entries - entries_left;\r\npoll_cq_exit0:\r\nreturn ret;\r\n}\r\nint ehca_req_notify_cq(struct ib_cq *cq, enum ib_cq_notify_flags notify_flags)\r\n{\r\nstruct ehca_cq *my_cq = container_of(cq, struct ehca_cq, ib_cq);\r\nint ret = 0;\r\nswitch (notify_flags & IB_CQ_SOLICITED_MASK) {\r\ncase IB_CQ_SOLICITED:\r\nhipz_set_cqx_n0(my_cq, 1);\r\nbreak;\r\ncase IB_CQ_NEXT_COMP:\r\nhipz_set_cqx_n1(my_cq, 1);\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nif (notify_flags & IB_CQ_REPORT_MISSED_EVENTS) {\r\nunsigned long spl_flags;\r\nspin_lock_irqsave(&my_cq->spinlock, spl_flags);\r\nret = ipz_qeit_is_valid(&my_cq->ipz_queue);\r\nspin_unlock_irqrestore(&my_cq->spinlock, spl_flags);\r\n}\r\nreturn ret;\r\n}
