int reqsk_queue_alloc(struct request_sock_queue *queue,\r\nunsigned int nr_table_entries)\r\n{\r\nsize_t lopt_size = sizeof(struct listen_sock);\r\nstruct listen_sock *lopt;\r\nnr_table_entries = min_t(u32, nr_table_entries, sysctl_max_syn_backlog);\r\nnr_table_entries = max_t(u32, nr_table_entries, 8);\r\nnr_table_entries = roundup_pow_of_two(nr_table_entries + 1);\r\nlopt_size += nr_table_entries * sizeof(struct request_sock *);\r\nif (lopt_size > PAGE_SIZE)\r\nlopt = vzalloc(lopt_size);\r\nelse\r\nlopt = kzalloc(lopt_size, GFP_KERNEL);\r\nif (lopt == NULL)\r\nreturn -ENOMEM;\r\nfor (lopt->max_qlen_log = 3;\r\n(1 << lopt->max_qlen_log) < nr_table_entries;\r\nlopt->max_qlen_log++);\r\nget_random_bytes(&lopt->hash_rnd, sizeof(lopt->hash_rnd));\r\nrwlock_init(&queue->syn_wait_lock);\r\nqueue->rskq_accept_head = NULL;\r\nlopt->nr_table_entries = nr_table_entries;\r\nwrite_lock_bh(&queue->syn_wait_lock);\r\nqueue->listen_opt = lopt;\r\nwrite_unlock_bh(&queue->syn_wait_lock);\r\nreturn 0;\r\n}\r\nvoid __reqsk_queue_destroy(struct request_sock_queue *queue)\r\n{\r\nstruct listen_sock *lopt;\r\nsize_t lopt_size;\r\nlopt = queue->listen_opt;\r\nlopt_size = sizeof(struct listen_sock) +\r\nlopt->nr_table_entries * sizeof(struct request_sock *);\r\nif (lopt_size > PAGE_SIZE)\r\nvfree(lopt);\r\nelse\r\nkfree(lopt);\r\n}\r\nstatic inline struct listen_sock *reqsk_queue_yank_listen_sk(\r\nstruct request_sock_queue *queue)\r\n{\r\nstruct listen_sock *lopt;\r\nwrite_lock_bh(&queue->syn_wait_lock);\r\nlopt = queue->listen_opt;\r\nqueue->listen_opt = NULL;\r\nwrite_unlock_bh(&queue->syn_wait_lock);\r\nreturn lopt;\r\n}\r\nvoid reqsk_queue_destroy(struct request_sock_queue *queue)\r\n{\r\nstruct listen_sock *lopt = reqsk_queue_yank_listen_sk(queue);\r\nsize_t lopt_size = sizeof(struct listen_sock) +\r\nlopt->nr_table_entries * sizeof(struct request_sock *);\r\nif (lopt->qlen != 0) {\r\nunsigned int i;\r\nfor (i = 0; i < lopt->nr_table_entries; i++) {\r\nstruct request_sock *req;\r\nwhile ((req = lopt->syn_table[i]) != NULL) {\r\nlopt->syn_table[i] = req->dl_next;\r\nlopt->qlen--;\r\nreqsk_free(req);\r\n}\r\n}\r\n}\r\nWARN_ON(lopt->qlen != 0);\r\nif (lopt_size > PAGE_SIZE)\r\nvfree(lopt);\r\nelse\r\nkfree(lopt);\r\n}\r\nvoid reqsk_fastopen_remove(struct sock *sk, struct request_sock *req,\r\nbool reset)\r\n{\r\nstruct sock *lsk = tcp_rsk(req)->listener;\r\nstruct fastopen_queue *fastopenq =\r\ninet_csk(lsk)->icsk_accept_queue.fastopenq;\r\ntcp_sk(sk)->fastopen_rsk = NULL;\r\nspin_lock_bh(&fastopenq->lock);\r\nfastopenq->qlen--;\r\ntcp_rsk(req)->listener = NULL;\r\nif (req->sk)\r\ngoto out;\r\nif (!reset || lsk->sk_state != TCP_LISTEN) {\r\nspin_unlock_bh(&fastopenq->lock);\r\nsock_put(lsk);\r\nreqsk_free(req);\r\nreturn;\r\n}\r\nreq->expires = jiffies + 60*HZ;\r\nif (fastopenq->rskq_rst_head == NULL)\r\nfastopenq->rskq_rst_head = req;\r\nelse\r\nfastopenq->rskq_rst_tail->dl_next = req;\r\nreq->dl_next = NULL;\r\nfastopenq->rskq_rst_tail = req;\r\nfastopenq->qlen++;\r\nout:\r\nspin_unlock_bh(&fastopenq->lock);\r\nsock_put(lsk);\r\n}
