static int xen_pcifront_enable_irq(struct pci_dev *dev)\r\n{\r\nint rc;\r\nint share = 1;\r\nint pirq;\r\nu8 gsi;\r\nrc = pci_read_config_byte(dev, PCI_INTERRUPT_LINE, &gsi);\r\nif (rc < 0) {\r\ndev_warn(&dev->dev, "Xen PCI: failed to read interrupt line: %d\n",\r\nrc);\r\nreturn rc;\r\n}\r\npirq = gsi;\r\nif (gsi < NR_IRQS_LEGACY)\r\nshare = 0;\r\nrc = xen_bind_pirq_gsi_to_irq(gsi, pirq, share, "pcifront");\r\nif (rc < 0) {\r\ndev_warn(&dev->dev, "Xen PCI: failed to bind GSI%d (PIRQ%d) to IRQ: %d\n",\r\ngsi, pirq, rc);\r\nreturn rc;\r\n}\r\ndev->irq = rc;\r\ndev_info(&dev->dev, "Xen PCI mapped GSI%d to IRQ%d\n", gsi, dev->irq);\r\nreturn 0;\r\n}\r\nstatic int xen_register_pirq(u32 gsi, int gsi_override, int triggering,\r\nbool set_pirq)\r\n{\r\nint rc, pirq = -1, irq = -1;\r\nstruct physdev_map_pirq map_irq;\r\nint shareable = 0;\r\nchar *name;\r\nirq = xen_irq_from_gsi(gsi);\r\nif (irq > 0)\r\nreturn irq;\r\nif (set_pirq)\r\npirq = gsi;\r\nmap_irq.domid = DOMID_SELF;\r\nmap_irq.type = MAP_PIRQ_TYPE_GSI;\r\nmap_irq.index = gsi;\r\nmap_irq.pirq = pirq;\r\nrc = HYPERVISOR_physdev_op(PHYSDEVOP_map_pirq, &map_irq);\r\nif (rc) {\r\nprintk(KERN_WARNING "xen map irq failed %d\n", rc);\r\nreturn -1;\r\n}\r\nif (triggering == ACPI_EDGE_SENSITIVE) {\r\nshareable = 0;\r\nname = "ioapic-edge";\r\n} else {\r\nshareable = 1;\r\nname = "ioapic-level";\r\n}\r\nif (gsi_override >= 0)\r\ngsi = gsi_override;\r\nirq = xen_bind_pirq_gsi_to_irq(gsi, map_irq.pirq, shareable, name);\r\nif (irq < 0)\r\ngoto out;\r\nprintk(KERN_DEBUG "xen: --> pirq=%d -> irq=%d (gsi=%d)\n", map_irq.pirq, irq, gsi);\r\nout:\r\nreturn irq;\r\n}\r\nstatic int acpi_register_gsi_xen_hvm(struct device *dev, u32 gsi,\r\nint trigger, int polarity)\r\n{\r\nif (!xen_hvm_domain())\r\nreturn -1;\r\nreturn xen_register_pirq(gsi, -1 , trigger,\r\nfalse );\r\n}\r\nstatic int xen_register_gsi(u32 gsi, int gsi_override, int triggering, int polarity)\r\n{\r\nint rc, irq;\r\nstruct physdev_setup_gsi setup_gsi;\r\nif (!xen_pv_domain())\r\nreturn -1;\r\nprintk(KERN_DEBUG "xen: registering gsi %u triggering %d polarity %d\n",\r\ngsi, triggering, polarity);\r\nirq = xen_register_pirq(gsi, gsi_override, triggering, true);\r\nsetup_gsi.gsi = gsi;\r\nsetup_gsi.triggering = (triggering == ACPI_EDGE_SENSITIVE ? 0 : 1);\r\nsetup_gsi.polarity = (polarity == ACPI_ACTIVE_HIGH ? 0 : 1);\r\nrc = HYPERVISOR_physdev_op(PHYSDEVOP_setup_gsi, &setup_gsi);\r\nif (rc == -EEXIST)\r\nprintk(KERN_INFO "Already setup the GSI :%d\n", gsi);\r\nelse if (rc) {\r\nprintk(KERN_ERR "Failed to setup GSI :%d, err_code:%d\n",\r\ngsi, rc);\r\n}\r\nreturn irq;\r\n}\r\nstatic int acpi_register_gsi_xen(struct device *dev, u32 gsi,\r\nint trigger, int polarity)\r\n{\r\nreturn xen_register_gsi(gsi, -1 , trigger, polarity);\r\n}\r\nstatic int xen_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)\r\n{\r\nint irq, ret, i;\r\nstruct msi_desc *msidesc;\r\nint *v;\r\nif (type == PCI_CAP_ID_MSI && nvec > 1)\r\nreturn 1;\r\nv = kzalloc(sizeof(int) * max(1, nvec), GFP_KERNEL);\r\nif (!v)\r\nreturn -ENOMEM;\r\nif (type == PCI_CAP_ID_MSIX)\r\nret = xen_pci_frontend_enable_msix(dev, v, nvec);\r\nelse\r\nret = xen_pci_frontend_enable_msi(dev, v);\r\nif (ret)\r\ngoto error;\r\ni = 0;\r\nlist_for_each_entry(msidesc, &dev->msi_list, list) {\r\nirq = xen_bind_pirq_msi_to_irq(dev, msidesc, v[i],\r\n(type == PCI_CAP_ID_MSI) ? nvec : 1,\r\n(type == PCI_CAP_ID_MSIX) ?\r\n"pcifront-msi-x" :\r\n"pcifront-msi",\r\nDOMID_SELF);\r\nif (irq < 0) {\r\nret = irq;\r\ngoto free;\r\n}\r\ni++;\r\n}\r\nkfree(v);\r\nreturn 0;\r\nerror:\r\ndev_err(&dev->dev, "Xen PCI frontend has not registered MSI/MSI-X support!\n");\r\nfree:\r\nkfree(v);\r\nreturn ret;\r\n}\r\nstatic void xen_msi_compose_msg(struct pci_dev *pdev, unsigned int pirq,\r\nstruct msi_msg *msg)\r\n{\r\nmsg->address_hi = MSI_ADDR_BASE_HI | MSI_ADDR_EXT_DEST_ID(pirq);\r\nmsg->address_lo =\r\nMSI_ADDR_BASE_LO |\r\nMSI_ADDR_DEST_MODE_PHYSICAL |\r\nMSI_ADDR_REDIRECTION_CPU |\r\nMSI_ADDR_DEST_ID(pirq);\r\nmsg->data = XEN_PIRQ_MSI_DATA;\r\n}\r\nstatic int xen_hvm_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)\r\n{\r\nint irq, pirq;\r\nstruct msi_desc *msidesc;\r\nstruct msi_msg msg;\r\nif (type == PCI_CAP_ID_MSI && nvec > 1)\r\nreturn 1;\r\nlist_for_each_entry(msidesc, &dev->msi_list, list) {\r\n__read_msi_msg(msidesc, &msg);\r\npirq = MSI_ADDR_EXT_DEST_ID(msg.address_hi) |\r\n((msg.address_lo >> MSI_ADDR_DEST_ID_SHIFT) & 0xff);\r\nif (msg.data != XEN_PIRQ_MSI_DATA ||\r\nxen_irq_from_pirq(pirq) < 0) {\r\npirq = xen_allocate_pirq_msi(dev, msidesc);\r\nif (pirq < 0) {\r\nirq = -ENODEV;\r\ngoto error;\r\n}\r\nxen_msi_compose_msg(dev, pirq, &msg);\r\n__write_msi_msg(msidesc, &msg);\r\ndev_dbg(&dev->dev, "xen: msi bound to pirq=%d\n", pirq);\r\n} else {\r\ndev_dbg(&dev->dev,\r\n"xen: msi already bound to pirq=%d\n", pirq);\r\n}\r\nirq = xen_bind_pirq_msi_to_irq(dev, msidesc, pirq,\r\n(type == PCI_CAP_ID_MSI) ? nvec : 1,\r\n(type == PCI_CAP_ID_MSIX) ?\r\n"msi-x" : "msi",\r\nDOMID_SELF);\r\nif (irq < 0)\r\ngoto error;\r\ndev_dbg(&dev->dev,\r\n"xen: msi --> pirq=%d --> irq=%d\n", pirq, irq);\r\n}\r\nreturn 0;\r\nerror:\r\ndev_err(&dev->dev,\r\n"Xen PCI frontend has not registered MSI/MSI-X support!\n");\r\nreturn irq;\r\n}\r\nstatic int xen_initdom_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)\r\n{\r\nint ret = 0;\r\nstruct msi_desc *msidesc;\r\nlist_for_each_entry(msidesc, &dev->msi_list, list) {\r\nstruct physdev_map_pirq map_irq;\r\ndomid_t domid;\r\ndomid = ret = xen_find_device_domain_owner(dev);\r\nif (ret < 0)\r\ndomid = DOMID_SELF;\r\nmemset(&map_irq, 0, sizeof(map_irq));\r\nmap_irq.domid = domid;\r\nmap_irq.type = MAP_PIRQ_TYPE_MSI_SEG;\r\nmap_irq.index = -1;\r\nmap_irq.pirq = -1;\r\nmap_irq.bus = dev->bus->number |\r\n(pci_domain_nr(dev->bus) << 16);\r\nmap_irq.devfn = dev->devfn;\r\nif (type == PCI_CAP_ID_MSI && nvec > 1) {\r\nmap_irq.type = MAP_PIRQ_TYPE_MULTI_MSI;\r\nmap_irq.entry_nr = nvec;\r\n} else if (type == PCI_CAP_ID_MSIX) {\r\nint pos;\r\nu32 table_offset, bir;\r\npos = dev->msix_cap;\r\npci_read_config_dword(dev, pos + PCI_MSIX_TABLE,\r\n&table_offset);\r\nbir = (u8)(table_offset & PCI_MSIX_TABLE_BIR);\r\nmap_irq.table_base = pci_resource_start(dev, bir);\r\nmap_irq.entry_nr = msidesc->msi_attrib.entry_nr;\r\n}\r\nret = -EINVAL;\r\nif (pci_seg_supported)\r\nret = HYPERVISOR_physdev_op(PHYSDEVOP_map_pirq,\r\n&map_irq);\r\nif (type == PCI_CAP_ID_MSI && nvec > 1 && ret) {\r\nret = 1;\r\ngoto out;\r\n}\r\nif (ret == -EINVAL && !pci_domain_nr(dev->bus)) {\r\nmap_irq.type = MAP_PIRQ_TYPE_MSI;\r\nmap_irq.index = -1;\r\nmap_irq.pirq = -1;\r\nmap_irq.bus = dev->bus->number;\r\nret = HYPERVISOR_physdev_op(PHYSDEVOP_map_pirq,\r\n&map_irq);\r\nif (ret != -EINVAL)\r\npci_seg_supported = false;\r\n}\r\nif (ret) {\r\ndev_warn(&dev->dev, "xen map irq failed %d for %d domain\n",\r\nret, domid);\r\ngoto out;\r\n}\r\nret = xen_bind_pirq_msi_to_irq(dev, msidesc, map_irq.pirq,\r\n(type == PCI_CAP_ID_MSI) ? nvec : 1,\r\n(type == PCI_CAP_ID_MSIX) ? "msi-x" : "msi",\r\ndomid);\r\nif (ret < 0)\r\ngoto out;\r\n}\r\nret = 0;\r\nout:\r\nreturn ret;\r\n}\r\nstatic void xen_initdom_restore_msi_irqs(struct pci_dev *dev)\r\n{\r\nint ret = 0;\r\nif (pci_seg_supported) {\r\nstruct physdev_pci_device restore_ext;\r\nrestore_ext.seg = pci_domain_nr(dev->bus);\r\nrestore_ext.bus = dev->bus->number;\r\nrestore_ext.devfn = dev->devfn;\r\nret = HYPERVISOR_physdev_op(PHYSDEVOP_restore_msi_ext,\r\n&restore_ext);\r\nif (ret == -ENOSYS)\r\npci_seg_supported = false;\r\nWARN(ret && ret != -ENOSYS, "restore_msi_ext -> %d\n", ret);\r\n}\r\nif (!pci_seg_supported) {\r\nstruct physdev_restore_msi restore;\r\nrestore.bus = dev->bus->number;\r\nrestore.devfn = dev->devfn;\r\nret = HYPERVISOR_physdev_op(PHYSDEVOP_restore_msi, &restore);\r\nWARN(ret && ret != -ENOSYS, "restore_msi -> %d\n", ret);\r\n}\r\n}\r\nstatic void xen_teardown_msi_irqs(struct pci_dev *dev)\r\n{\r\nstruct msi_desc *msidesc;\r\nmsidesc = list_entry(dev->msi_list.next, struct msi_desc, list);\r\nif (msidesc->msi_attrib.is_msix)\r\nxen_pci_frontend_disable_msix(dev);\r\nelse\r\nxen_pci_frontend_disable_msi(dev);\r\ndefault_teardown_msi_irqs(dev);\r\n}\r\nstatic void xen_teardown_msi_irq(unsigned int irq)\r\n{\r\nxen_destroy_irq(irq);\r\n}\r\nstatic u32 xen_nop_msi_mask_irq(struct msi_desc *desc, u32 mask, u32 flag)\r\n{\r\nreturn 0;\r\n}\r\nstatic u32 xen_nop_msix_mask_irq(struct msi_desc *desc, u32 flag)\r\n{\r\nreturn 0;\r\n}\r\nint __init pci_xen_init(void)\r\n{\r\nif (!xen_pv_domain() || xen_initial_domain())\r\nreturn -ENODEV;\r\nprintk(KERN_INFO "PCI: setting up Xen PCI frontend stub\n");\r\npcibios_set_cache_line_size();\r\npcibios_enable_irq = xen_pcifront_enable_irq;\r\npcibios_disable_irq = NULL;\r\n#ifdef CONFIG_ACPI\r\nacpi_noirq = 1;\r\n#endif\r\n#ifdef CONFIG_PCI_MSI\r\nx86_msi.setup_msi_irqs = xen_setup_msi_irqs;\r\nx86_msi.teardown_msi_irq = xen_teardown_msi_irq;\r\nx86_msi.teardown_msi_irqs = xen_teardown_msi_irqs;\r\nx86_msi.msi_mask_irq = xen_nop_msi_mask_irq;\r\nx86_msi.msix_mask_irq = xen_nop_msix_mask_irq;\r\n#endif\r\nreturn 0;\r\n}\r\nint __init pci_xen_hvm_init(void)\r\n{\r\nif (!xen_have_vector_callback || !xen_feature(XENFEAT_hvm_pirqs))\r\nreturn 0;\r\n#ifdef CONFIG_ACPI\r\n__acpi_register_gsi = acpi_register_gsi_xen_hvm;\r\n#endif\r\n#ifdef CONFIG_PCI_MSI\r\nx86_msi.setup_msi_irqs = xen_hvm_setup_msi_irqs;\r\nx86_msi.teardown_msi_irq = xen_teardown_msi_irq;\r\n#endif\r\nreturn 0;\r\n}\r\nstatic __init void xen_setup_acpi_sci(void)\r\n{\r\nint rc;\r\nint trigger, polarity;\r\nint gsi = acpi_sci_override_gsi;\r\nint irq = -1;\r\nint gsi_override = -1;\r\nif (!gsi)\r\nreturn;\r\nrc = acpi_get_override_irq(gsi, &trigger, &polarity);\r\nif (rc) {\r\nprintk(KERN_WARNING "xen: acpi_get_override_irq failed for acpi"\r\n" sci, rc=%d\n", rc);\r\nreturn;\r\n}\r\ntrigger = trigger ? ACPI_LEVEL_SENSITIVE : ACPI_EDGE_SENSITIVE;\r\npolarity = polarity ? ACPI_ACTIVE_LOW : ACPI_ACTIVE_HIGH;\r\nprintk(KERN_INFO "xen: sci override: global_irq=%d trigger=%d "\r\n"polarity=%d\n", gsi, trigger, polarity);\r\nif (acpi_gsi_to_irq(gsi, &irq) == 0) {\r\nif (irq >= 0)\r\ngsi_override = irq;\r\n}\r\ngsi = xen_register_gsi(gsi, gsi_override, trigger, polarity);\r\nprintk(KERN_INFO "xen: acpi sci %d\n", gsi);\r\nreturn;\r\n}\r\nint __init pci_xen_initial_domain(void)\r\n{\r\nint irq;\r\n#ifdef CONFIG_PCI_MSI\r\nx86_msi.setup_msi_irqs = xen_initdom_setup_msi_irqs;\r\nx86_msi.teardown_msi_irq = xen_teardown_msi_irq;\r\nx86_msi.restore_msi_irqs = xen_initdom_restore_msi_irqs;\r\nx86_msi.msi_mask_irq = xen_nop_msi_mask_irq;\r\nx86_msi.msix_mask_irq = xen_nop_msix_mask_irq;\r\n#endif\r\nxen_setup_acpi_sci();\r\n__acpi_register_gsi = acpi_register_gsi_xen;\r\nfor (irq = 0; irq < NR_IRQS_LEGACY; irq++) {\r\nint trigger, polarity;\r\nif (acpi_get_override_irq(irq, &trigger, &polarity) == -1)\r\ncontinue;\r\nxen_register_pirq(irq, -1 ,\r\ntrigger ? ACPI_LEVEL_SENSITIVE : ACPI_EDGE_SENSITIVE,\r\ntrue );\r\n}\r\nif (0 == nr_ioapics) {\r\nfor (irq = 0; irq < NR_IRQS_LEGACY; irq++)\r\nxen_bind_pirq_gsi_to_irq(irq, irq, 0, "xt-pic");\r\n}\r\nreturn 0;\r\n}\r\nstatic struct xen_device_domain_owner *find_device(struct pci_dev *dev)\r\n{\r\nstruct xen_device_domain_owner *owner;\r\nlist_for_each_entry(owner, &dev_domain_list, list) {\r\nif (owner->dev == dev)\r\nreturn owner;\r\n}\r\nreturn NULL;\r\n}\r\nint xen_find_device_domain_owner(struct pci_dev *dev)\r\n{\r\nstruct xen_device_domain_owner *owner;\r\nint domain = -ENODEV;\r\nspin_lock(&dev_domain_list_spinlock);\r\nowner = find_device(dev);\r\nif (owner)\r\ndomain = owner->domain;\r\nspin_unlock(&dev_domain_list_spinlock);\r\nreturn domain;\r\n}\r\nint xen_register_device_domain_owner(struct pci_dev *dev, uint16_t domain)\r\n{\r\nstruct xen_device_domain_owner *owner;\r\nowner = kzalloc(sizeof(struct xen_device_domain_owner), GFP_KERNEL);\r\nif (!owner)\r\nreturn -ENODEV;\r\nspin_lock(&dev_domain_list_spinlock);\r\nif (find_device(dev)) {\r\nspin_unlock(&dev_domain_list_spinlock);\r\nkfree(owner);\r\nreturn -EEXIST;\r\n}\r\nowner->domain = domain;\r\nowner->dev = dev;\r\nlist_add_tail(&owner->list, &dev_domain_list);\r\nspin_unlock(&dev_domain_list_spinlock);\r\nreturn 0;\r\n}\r\nint xen_unregister_device_domain_owner(struct pci_dev *dev)\r\n{\r\nstruct xen_device_domain_owner *owner;\r\nspin_lock(&dev_domain_list_spinlock);\r\nowner = find_device(dev);\r\nif (!owner) {\r\nspin_unlock(&dev_domain_list_spinlock);\r\nreturn -ENODEV;\r\n}\r\nlist_del(&owner->list);\r\nspin_unlock(&dev_domain_list_spinlock);\r\nkfree(owner);\r\nreturn 0;\r\n}
