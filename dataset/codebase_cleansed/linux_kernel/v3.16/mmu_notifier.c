void __mmu_notifier_release(struct mm_struct *mm)\r\n{\r\nstruct mmu_notifier *mn;\r\nint id;\r\nid = srcu_read_lock(&srcu);\r\nhlist_for_each_entry_rcu(mn, &mm->mmu_notifier_mm->list, hlist)\r\nif (mn->ops->release)\r\nmn->ops->release(mn, mm);\r\nsrcu_read_unlock(&srcu, id);\r\nspin_lock(&mm->mmu_notifier_mm->lock);\r\nwhile (unlikely(!hlist_empty(&mm->mmu_notifier_mm->list))) {\r\nmn = hlist_entry(mm->mmu_notifier_mm->list.first,\r\nstruct mmu_notifier,\r\nhlist);\r\nhlist_del_init_rcu(&mn->hlist);\r\n}\r\nspin_unlock(&mm->mmu_notifier_mm->lock);\r\nsynchronize_srcu(&srcu);\r\n}\r\nint __mmu_notifier_clear_flush_young(struct mm_struct *mm,\r\nunsigned long address)\r\n{\r\nstruct mmu_notifier *mn;\r\nint young = 0, id;\r\nid = srcu_read_lock(&srcu);\r\nhlist_for_each_entry_rcu(mn, &mm->mmu_notifier_mm->list, hlist) {\r\nif (mn->ops->clear_flush_young)\r\nyoung |= mn->ops->clear_flush_young(mn, mm, address);\r\n}\r\nsrcu_read_unlock(&srcu, id);\r\nreturn young;\r\n}\r\nint __mmu_notifier_test_young(struct mm_struct *mm,\r\nunsigned long address)\r\n{\r\nstruct mmu_notifier *mn;\r\nint young = 0, id;\r\nid = srcu_read_lock(&srcu);\r\nhlist_for_each_entry_rcu(mn, &mm->mmu_notifier_mm->list, hlist) {\r\nif (mn->ops->test_young) {\r\nyoung = mn->ops->test_young(mn, mm, address);\r\nif (young)\r\nbreak;\r\n}\r\n}\r\nsrcu_read_unlock(&srcu, id);\r\nreturn young;\r\n}\r\nvoid __mmu_notifier_change_pte(struct mm_struct *mm, unsigned long address,\r\npte_t pte)\r\n{\r\nstruct mmu_notifier *mn;\r\nint id;\r\nid = srcu_read_lock(&srcu);\r\nhlist_for_each_entry_rcu(mn, &mm->mmu_notifier_mm->list, hlist) {\r\nif (mn->ops->change_pte)\r\nmn->ops->change_pte(mn, mm, address, pte);\r\n}\r\nsrcu_read_unlock(&srcu, id);\r\n}\r\nvoid __mmu_notifier_invalidate_page(struct mm_struct *mm,\r\nunsigned long address)\r\n{\r\nstruct mmu_notifier *mn;\r\nint id;\r\nid = srcu_read_lock(&srcu);\r\nhlist_for_each_entry_rcu(mn, &mm->mmu_notifier_mm->list, hlist) {\r\nif (mn->ops->invalidate_page)\r\nmn->ops->invalidate_page(mn, mm, address);\r\n}\r\nsrcu_read_unlock(&srcu, id);\r\n}\r\nvoid __mmu_notifier_invalidate_range_start(struct mm_struct *mm,\r\nunsigned long start, unsigned long end)\r\n{\r\nstruct mmu_notifier *mn;\r\nint id;\r\nid = srcu_read_lock(&srcu);\r\nhlist_for_each_entry_rcu(mn, &mm->mmu_notifier_mm->list, hlist) {\r\nif (mn->ops->invalidate_range_start)\r\nmn->ops->invalidate_range_start(mn, mm, start, end);\r\n}\r\nsrcu_read_unlock(&srcu, id);\r\n}\r\nvoid __mmu_notifier_invalidate_range_end(struct mm_struct *mm,\r\nunsigned long start, unsigned long end)\r\n{\r\nstruct mmu_notifier *mn;\r\nint id;\r\nid = srcu_read_lock(&srcu);\r\nhlist_for_each_entry_rcu(mn, &mm->mmu_notifier_mm->list, hlist) {\r\nif (mn->ops->invalidate_range_end)\r\nmn->ops->invalidate_range_end(mn, mm, start, end);\r\n}\r\nsrcu_read_unlock(&srcu, id);\r\n}\r\nstatic int do_mmu_notifier_register(struct mmu_notifier *mn,\r\nstruct mm_struct *mm,\r\nint take_mmap_sem)\r\n{\r\nstruct mmu_notifier_mm *mmu_notifier_mm;\r\nint ret;\r\nBUG_ON(atomic_read(&mm->mm_users) <= 0);\r\nBUG_ON(!srcu.per_cpu_ref);\r\nret = -ENOMEM;\r\nmmu_notifier_mm = kmalloc(sizeof(struct mmu_notifier_mm), GFP_KERNEL);\r\nif (unlikely(!mmu_notifier_mm))\r\ngoto out;\r\nif (take_mmap_sem)\r\ndown_write(&mm->mmap_sem);\r\nret = mm_take_all_locks(mm);\r\nif (unlikely(ret))\r\ngoto out_clean;\r\nif (!mm_has_notifiers(mm)) {\r\nINIT_HLIST_HEAD(&mmu_notifier_mm->list);\r\nspin_lock_init(&mmu_notifier_mm->lock);\r\nmm->mmu_notifier_mm = mmu_notifier_mm;\r\nmmu_notifier_mm = NULL;\r\n}\r\natomic_inc(&mm->mm_count);\r\nspin_lock(&mm->mmu_notifier_mm->lock);\r\nhlist_add_head(&mn->hlist, &mm->mmu_notifier_mm->list);\r\nspin_unlock(&mm->mmu_notifier_mm->lock);\r\nmm_drop_all_locks(mm);\r\nout_clean:\r\nif (take_mmap_sem)\r\nup_write(&mm->mmap_sem);\r\nkfree(mmu_notifier_mm);\r\nout:\r\nBUG_ON(atomic_read(&mm->mm_users) <= 0);\r\nreturn ret;\r\n}\r\nint mmu_notifier_register(struct mmu_notifier *mn, struct mm_struct *mm)\r\n{\r\nreturn do_mmu_notifier_register(mn, mm, 1);\r\n}\r\nint __mmu_notifier_register(struct mmu_notifier *mn, struct mm_struct *mm)\r\n{\r\nreturn do_mmu_notifier_register(mn, mm, 0);\r\n}\r\nvoid __mmu_notifier_mm_destroy(struct mm_struct *mm)\r\n{\r\nBUG_ON(!hlist_empty(&mm->mmu_notifier_mm->list));\r\nkfree(mm->mmu_notifier_mm);\r\nmm->mmu_notifier_mm = LIST_POISON1;\r\n}\r\nvoid mmu_notifier_unregister(struct mmu_notifier *mn, struct mm_struct *mm)\r\n{\r\nBUG_ON(atomic_read(&mm->mm_count) <= 0);\r\nif (!hlist_unhashed(&mn->hlist)) {\r\nint id;\r\nid = srcu_read_lock(&srcu);\r\nif (mn->ops->release)\r\nmn->ops->release(mn, mm);\r\nsrcu_read_unlock(&srcu, id);\r\nspin_lock(&mm->mmu_notifier_mm->lock);\r\nhlist_del_init_rcu(&mn->hlist);\r\nspin_unlock(&mm->mmu_notifier_mm->lock);\r\n}\r\nsynchronize_srcu(&srcu);\r\nBUG_ON(atomic_read(&mm->mm_count) <= 0);\r\nmmdrop(mm);\r\n}\r\nstatic int __init mmu_notifier_init(void)\r\n{\r\nreturn init_srcu_struct(&srcu);\r\n}
