int maple_driver_register(struct maple_driver *drv)\r\n{\r\nif (!drv)\r\nreturn -EINVAL;\r\ndrv->drv.bus = &maple_bus_type;\r\nreturn driver_register(&drv->drv);\r\n}\r\nvoid maple_driver_unregister(struct maple_driver *drv)\r\n{\r\ndriver_unregister(&drv->drv);\r\n}\r\nstatic void maple_dma_reset(void)\r\n{\r\n__raw_writel(MAPLE_MAGIC, MAPLE_RESET);\r\n__raw_writel(1, MAPLE_TRIGTYPE);\r\n__raw_writel(MAPLE_2MBPS | MAPLE_TIMEOUT(0xFFFF), MAPLE_SPEED);\r\n__raw_writel(virt_to_phys(maple_sendbuf), MAPLE_DMAADDR);\r\n__raw_writel(1, MAPLE_ENABLE);\r\n}\r\nvoid maple_getcond_callback(struct maple_device *dev,\r\nvoid (*callback) (struct mapleq *mq),\r\nunsigned long interval, unsigned long function)\r\n{\r\ndev->callback = callback;\r\ndev->interval = interval;\r\ndev->function = cpu_to_be32(function);\r\ndev->when = jiffies;\r\n}\r\nstatic int maple_dma_done(void)\r\n{\r\nreturn (__raw_readl(MAPLE_STATE) & 1) == 0;\r\n}\r\nstatic void maple_release_device(struct device *dev)\r\n{\r\nstruct maple_device *mdev;\r\nstruct mapleq *mq;\r\nmdev = to_maple_dev(dev);\r\nmq = mdev->mq;\r\nkmem_cache_free(maple_queue_cache, mq->recvbuf);\r\nkfree(mq);\r\nkfree(mdev);\r\n}\r\nint maple_add_packet(struct maple_device *mdev, u32 function, u32 command,\r\nsize_t length, void *data)\r\n{\r\nint ret = 0;\r\nvoid *sendbuf = NULL;\r\nif (length) {\r\nsendbuf = kzalloc(length * 4, GFP_KERNEL);\r\nif (!sendbuf) {\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\n((__be32 *)sendbuf)[0] = cpu_to_be32(function);\r\n}\r\nmdev->mq->command = command;\r\nmdev->mq->length = length;\r\nif (length > 1)\r\nmemcpy(sendbuf + 4, data, (length - 1) * 4);\r\nmdev->mq->sendbuf = sendbuf;\r\nmutex_lock(&maple_wlist_lock);\r\nlist_add_tail(&mdev->mq->list, &maple_waitq);\r\nmutex_unlock(&maple_wlist_lock);\r\nout:\r\nreturn ret;\r\n}\r\nstatic struct mapleq *maple_allocq(struct maple_device *mdev)\r\n{\r\nstruct mapleq *mq;\r\nmq = kzalloc(sizeof(*mq), GFP_KERNEL);\r\nif (!mq)\r\ngoto failed_nomem;\r\nINIT_LIST_HEAD(&mq->list);\r\nmq->dev = mdev;\r\nmq->recvbuf = kmem_cache_zalloc(maple_queue_cache, GFP_KERNEL);\r\nif (!mq->recvbuf)\r\ngoto failed_p2;\r\nmq->recvbuf->buf = &((mq->recvbuf->bufx)[0]);\r\nreturn mq;\r\nfailed_p2:\r\nkfree(mq);\r\nfailed_nomem:\r\ndev_err(&mdev->dev, "could not allocate memory for device (%d, %d)\n",\r\nmdev->port, mdev->unit);\r\nreturn NULL;\r\n}\r\nstatic struct maple_device *maple_alloc_dev(int port, int unit)\r\n{\r\nstruct maple_device *mdev;\r\nmdev = kzalloc(sizeof(*mdev), GFP_KERNEL);\r\nif (!mdev)\r\nreturn NULL;\r\nmdev->port = port;\r\nmdev->unit = unit;\r\nmdev->mq = maple_allocq(mdev);\r\nif (!mdev->mq) {\r\nkfree(mdev);\r\nreturn NULL;\r\n}\r\nmdev->dev.bus = &maple_bus_type;\r\nmdev->dev.parent = &maple_bus;\r\ninit_waitqueue_head(&mdev->maple_wait);\r\nreturn mdev;\r\n}\r\nstatic void maple_free_dev(struct maple_device *mdev)\r\n{\r\nkmem_cache_free(maple_queue_cache, mdev->mq->recvbuf);\r\nkfree(mdev->mq);\r\nkfree(mdev);\r\n}\r\nstatic void maple_build_block(struct mapleq *mq)\r\n{\r\nint port, unit, from, to, len;\r\nunsigned long *lsendbuf = mq->sendbuf;\r\nport = mq->dev->port & 3;\r\nunit = mq->dev->unit;\r\nlen = mq->length;\r\nfrom = port << 6;\r\nto = (port << 6) | (unit > 0 ? (1 << (unit - 1)) & 0x1f : 0x20);\r\n*maple_lastptr &= 0x7fffffff;\r\nmaple_lastptr = maple_sendptr;\r\n*maple_sendptr++ = (port << 16) | len | 0x80000000;\r\n*maple_sendptr++ = virt_to_phys(mq->recvbuf->buf);\r\n*maple_sendptr++ =\r\nmq->command | (to << 8) | (from << 16) | (len << 24);\r\nwhile (len-- > 0)\r\n*maple_sendptr++ = *lsendbuf++;\r\n}\r\nstatic void maple_send(void)\r\n{\r\nint i, maple_packets = 0;\r\nstruct mapleq *mq, *nmq;\r\nif (!maple_dma_done())\r\nreturn;\r\n__raw_writel(0, MAPLE_ENABLE);\r\nif (!list_empty(&maple_sentq))\r\ngoto finish;\r\nmutex_lock(&maple_wlist_lock);\r\nif (list_empty(&maple_waitq)) {\r\nmutex_unlock(&maple_wlist_lock);\r\ngoto finish;\r\n}\r\nmaple_lastptr = maple_sendbuf;\r\nmaple_sendptr = maple_sendbuf;\r\nlist_for_each_entry_safe(mq, nmq, &maple_waitq, list) {\r\nmaple_build_block(mq);\r\nlist_del_init(&mq->list);\r\nlist_add_tail(&mq->list, &maple_sentq);\r\nif (maple_packets++ > MAPLE_MAXPACKETS)\r\nbreak;\r\n}\r\nmutex_unlock(&maple_wlist_lock);\r\nif (maple_packets > 0) {\r\nfor (i = 0; i < (1 << MAPLE_DMA_PAGES); i++)\r\ndma_cache_sync(0, maple_sendbuf + i * PAGE_SIZE,\r\nPAGE_SIZE, DMA_BIDIRECTIONAL);\r\n}\r\nfinish:\r\nmaple_dma_reset();\r\n}\r\nstatic int maple_check_matching_driver(struct device_driver *driver,\r\nvoid *devptr)\r\n{\r\nstruct maple_driver *maple_drv;\r\nstruct maple_device *mdev;\r\nmdev = devptr;\r\nmaple_drv = to_maple_driver(driver);\r\nif (mdev->devinfo.function & cpu_to_be32(maple_drv->function))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic void maple_detach_driver(struct maple_device *mdev)\r\n{\r\ndevice_unregister(&mdev->dev);\r\n}\r\nstatic void maple_attach_driver(struct maple_device *mdev)\r\n{\r\nchar *p, *recvbuf;\r\nunsigned long function;\r\nint matched, error;\r\nrecvbuf = mdev->mq->recvbuf->buf;\r\nmemcpy(&mdev->devinfo.function, recvbuf + 4, 4);\r\nmemcpy(&mdev->devinfo.function_data[0], recvbuf + 8, 12);\r\nmemcpy(&mdev->devinfo.area_code, recvbuf + 20, 1);\r\nmemcpy(&mdev->devinfo.connector_direction, recvbuf + 21, 1);\r\nmemcpy(&mdev->devinfo.product_name[0], recvbuf + 22, 30);\r\nmemcpy(&mdev->devinfo.standby_power, recvbuf + 112, 2);\r\nmemcpy(&mdev->devinfo.max_power, recvbuf + 114, 2);\r\nmemcpy(mdev->product_name, mdev->devinfo.product_name, 30);\r\nmdev->product_name[30] = '\0';\r\nmemcpy(mdev->product_licence, mdev->devinfo.product_licence, 60);\r\nmdev->product_licence[60] = '\0';\r\nfor (p = mdev->product_name + 29; mdev->product_name <= p; p--)\r\nif (*p == ' ')\r\n*p = '\0';\r\nelse\r\nbreak;\r\nfor (p = mdev->product_licence + 59; mdev->product_licence <= p; p--)\r\nif (*p == ' ')\r\n*p = '\0';\r\nelse\r\nbreak;\r\nfunction = be32_to_cpu(mdev->devinfo.function);\r\ndev_info(&mdev->dev, "detected %s: function 0x%lX: at (%d, %d)\n",\r\nmdev->product_name, function, mdev->port, mdev->unit);\r\nif (function > 0x200) {\r\nfunction = 0;\r\nmdev->driver = &maple_unsupported_device;\r\ndev_set_name(&mdev->dev, "%d:0.port", mdev->port);\r\n} else {\r\nmatched =\r\nbus_for_each_drv(&maple_bus_type, NULL, mdev,\r\nmaple_check_matching_driver);\r\nif (matched == 0) {\r\ndev_info(&mdev->dev, "no driver found\n");\r\nmdev->driver = &maple_unsupported_device;\r\n}\r\ndev_set_name(&mdev->dev, "%d:0%d.%lX", mdev->port,\r\nmdev->unit, function);\r\n}\r\nmdev->function = function;\r\nmdev->dev.release = &maple_release_device;\r\natomic_set(&mdev->busy, 0);\r\nerror = device_register(&mdev->dev);\r\nif (error) {\r\ndev_warn(&mdev->dev, "could not register device at"\r\n" (%d, %d), with error 0x%X\n", mdev->unit,\r\nmdev->port, error);\r\nmaple_free_dev(mdev);\r\nmdev = NULL;\r\nreturn;\r\n}\r\n}\r\nstatic int check_maple_device(struct device *device, void *portptr)\r\n{\r\nstruct maple_device_specify *ds;\r\nstruct maple_device *mdev;\r\nds = portptr;\r\nmdev = to_maple_dev(device);\r\nif (mdev->port == ds->port && mdev->unit == ds->unit)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int setup_maple_commands(struct device *device, void *ignored)\r\n{\r\nint add;\r\nstruct maple_device *mdev = to_maple_dev(device);\r\nif (mdev->interval > 0 && atomic_read(&mdev->busy) == 0 &&\r\ntime_after(jiffies, mdev->when)) {\r\nadd = maple_add_packet(mdev,\r\nbe32_to_cpu(mdev->devinfo.function),\r\nMAPLE_COMMAND_GETCOND, 1, NULL);\r\nif (!add)\r\nmdev->when = jiffies + mdev->interval;\r\n} else {\r\nif (time_after(jiffies, maple_pnp_time))\r\nif (atomic_read(&mdev->busy) == 0) {\r\natomic_set(&mdev->busy, 1);\r\nmaple_add_packet(mdev, 0,\r\nMAPLE_COMMAND_DEVINFO, 0, NULL);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void maple_vblank_handler(struct work_struct *work)\r\n{\r\nint x, locking;\r\nstruct maple_device *mdev;\r\nif (!maple_dma_done())\r\nreturn;\r\n__raw_writel(0, MAPLE_ENABLE);\r\nif (!list_empty(&maple_sentq))\r\ngoto finish;\r\nbus_for_each_dev(&maple_bus_type, NULL, NULL,\r\nsetup_maple_commands);\r\nif (time_after(jiffies, maple_pnp_time)) {\r\nfor (x = 0; x < MAPLE_PORTS; x++) {\r\nif (checked[x] && empty[x]) {\r\nmdev = baseunits[x];\r\nif (!mdev)\r\nbreak;\r\natomic_set(&mdev->busy, 1);\r\nlocking = maple_add_packet(mdev, 0,\r\nMAPLE_COMMAND_DEVINFO, 0, NULL);\r\nif (!locking)\r\nbreak;\r\n}\r\n}\r\nmaple_pnp_time = jiffies + MAPLE_PNP_INTERVAL;\r\n}\r\nfinish:\r\nmaple_send();\r\n}\r\nstatic void maple_map_subunits(struct maple_device *mdev, int submask)\r\n{\r\nint retval, k, devcheck;\r\nstruct maple_device *mdev_add;\r\nstruct maple_device_specify ds;\r\nds.port = mdev->port;\r\nfor (k = 0; k < 5; k++) {\r\nds.unit = k + 1;\r\nretval =\r\nbus_for_each_dev(&maple_bus_type, NULL, &ds,\r\ncheck_maple_device);\r\nif (retval) {\r\nsubmask = submask >> 1;\r\ncontinue;\r\n}\r\ndevcheck = submask & 0x01;\r\nif (devcheck) {\r\nmdev_add = maple_alloc_dev(mdev->port, k + 1);\r\nif (!mdev_add)\r\nreturn;\r\natomic_set(&mdev_add->busy, 1);\r\nmaple_add_packet(mdev_add, 0, MAPLE_COMMAND_DEVINFO,\r\n0, NULL);\r\nscanning = 1;\r\n}\r\nsubmask = submask >> 1;\r\n}\r\n}\r\nstatic void maple_clean_submap(struct maple_device *mdev)\r\n{\r\nint killbit;\r\nkillbit = (mdev->unit > 0 ? (1 << (mdev->unit - 1)) & 0x1f : 0x20);\r\nkillbit = ~killbit;\r\nkillbit &= 0xFF;\r\nsubdevice_map[mdev->port] = subdevice_map[mdev->port] & killbit;\r\n}\r\nstatic void maple_response_none(struct maple_device *mdev)\r\n{\r\nmaple_clean_submap(mdev);\r\nif (likely(mdev->unit != 0)) {\r\nif (mdev->can_unload) {\r\nif (!mdev->can_unload(mdev)) {\r\natomic_set(&mdev->busy, 2);\r\nwake_up(&mdev->maple_wait);\r\nreturn;\r\n}\r\n}\r\ndev_info(&mdev->dev, "detaching device at (%d, %d)\n",\r\nmdev->port, mdev->unit);\r\nmaple_detach_driver(mdev);\r\nreturn;\r\n} else {\r\nif (!started || !fullscan) {\r\nif (checked[mdev->port] == false) {\r\nchecked[mdev->port] = true;\r\nempty[mdev->port] = true;\r\ndev_info(&mdev->dev, "no devices"\r\n" to port %d\n", mdev->port);\r\n}\r\nreturn;\r\n}\r\n}\r\natomic_set(&mdev->busy, 0);\r\n}\r\nstatic void maple_response_devinfo(struct maple_device *mdev,\r\nchar *recvbuf)\r\n{\r\nchar submask;\r\nif (!started || (scanning == 2) || !fullscan) {\r\nif ((mdev->unit == 0) && (checked[mdev->port] == false)) {\r\nchecked[mdev->port] = true;\r\nmaple_attach_driver(mdev);\r\n} else {\r\nif (mdev->unit != 0)\r\nmaple_attach_driver(mdev);\r\nif (mdev->unit == 0) {\r\nempty[mdev->port] = false;\r\nmaple_attach_driver(mdev);\r\n}\r\n}\r\n}\r\nif (mdev->unit == 0) {\r\nsubmask = recvbuf[2] & 0x1F;\r\nif (submask ^ subdevice_map[mdev->port]) {\r\nmaple_map_subunits(mdev, submask);\r\nsubdevice_map[mdev->port] = submask;\r\n}\r\n}\r\n}\r\nstatic void maple_response_fileerr(struct maple_device *mdev, void *recvbuf)\r\n{\r\nif (mdev->fileerr_handler) {\r\nmdev->fileerr_handler(mdev, recvbuf);\r\nreturn;\r\n} else\r\ndev_warn(&mdev->dev, "device at (%d, %d) reports"\r\n"file error 0x%X\n", mdev->port, mdev->unit,\r\n((int *)recvbuf)[1]);\r\n}\r\nstatic void maple_port_rescan(void)\r\n{\r\nint i;\r\nstruct maple_device *mdev;\r\nfullscan = 1;\r\nfor (i = 0; i < MAPLE_PORTS; i++) {\r\nif (checked[i] == false) {\r\nfullscan = 0;\r\nmdev = baseunits[i];\r\nmaple_add_packet(mdev, 0, MAPLE_COMMAND_DEVINFO,\r\n0, NULL);\r\n}\r\n}\r\n}\r\nstatic void maple_dma_handler(struct work_struct *work)\r\n{\r\nstruct mapleq *mq, *nmq;\r\nstruct maple_device *mdev;\r\nchar *recvbuf;\r\nenum maple_code code;\r\nif (!maple_dma_done())\r\nreturn;\r\n__raw_writel(0, MAPLE_ENABLE);\r\nif (!list_empty(&maple_sentq)) {\r\nlist_for_each_entry_safe(mq, nmq, &maple_sentq, list) {\r\nmdev = mq->dev;\r\nrecvbuf = mq->recvbuf->buf;\r\ndma_cache_sync(&mdev->dev, recvbuf, 0x400,\r\nDMA_FROM_DEVICE);\r\ncode = recvbuf[0];\r\nkfree(mq->sendbuf);\r\nlist_del_init(&mq->list);\r\nswitch (code) {\r\ncase MAPLE_RESPONSE_NONE:\r\nmaple_response_none(mdev);\r\nbreak;\r\ncase MAPLE_RESPONSE_DEVINFO:\r\nmaple_response_devinfo(mdev, recvbuf);\r\natomic_set(&mdev->busy, 0);\r\nbreak;\r\ncase MAPLE_RESPONSE_DATATRF:\r\nif (mdev->callback)\r\nmdev->callback(mq);\r\natomic_set(&mdev->busy, 0);\r\nwake_up(&mdev->maple_wait);\r\nbreak;\r\ncase MAPLE_RESPONSE_FILEERR:\r\nmaple_response_fileerr(mdev, recvbuf);\r\natomic_set(&mdev->busy, 0);\r\nwake_up(&mdev->maple_wait);\r\nbreak;\r\ncase MAPLE_RESPONSE_AGAIN:\r\ncase MAPLE_RESPONSE_BADCMD:\r\ncase MAPLE_RESPONSE_BADFUNC:\r\ndev_warn(&mdev->dev, "non-fatal error"\r\n" 0x%X at (%d, %d)\n", code,\r\nmdev->port, mdev->unit);\r\natomic_set(&mdev->busy, 0);\r\nbreak;\r\ncase MAPLE_RESPONSE_ALLINFO:\r\ndev_notice(&mdev->dev, "extended"\r\n" device information request for (%d, %d)"\r\n" but call is not supported\n", mdev->port,\r\nmdev->unit);\r\natomic_set(&mdev->busy, 0);\r\nbreak;\r\ncase MAPLE_RESPONSE_OK:\r\natomic_set(&mdev->busy, 0);\r\nwake_up(&mdev->maple_wait);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nif (scanning == 1) {\r\nmaple_send();\r\nscanning = 2;\r\n} else\r\nscanning = 0;\r\nif (!fullscan)\r\nmaple_port_rescan();\r\nstarted = 1;\r\n}\r\nmaple_send();\r\n}\r\nstatic irqreturn_t maple_dma_interrupt(int irq, void *dev_id)\r\n{\r\nschedule_work(&maple_dma_process);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t maple_vblank_interrupt(int irq, void *dev_id)\r\n{\r\nschedule_work(&maple_vblank_process);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int maple_set_dma_interrupt_handler(void)\r\n{\r\nreturn request_irq(HW_EVENT_MAPLE_DMA, maple_dma_interrupt,\r\nIRQF_SHARED, "maple bus DMA", &maple_unsupported_device);\r\n}\r\nstatic int maple_set_vblank_interrupt_handler(void)\r\n{\r\nreturn request_irq(HW_EVENT_VSYNC, maple_vblank_interrupt,\r\nIRQF_SHARED, "maple bus VBLANK", &maple_unsupported_device);\r\n}\r\nstatic int maple_get_dma_buffer(void)\r\n{\r\nmaple_sendbuf =\r\n(void *) __get_free_pages(GFP_KERNEL | __GFP_ZERO,\r\nMAPLE_DMA_PAGES);\r\nif (!maple_sendbuf)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nstatic int maple_match_bus_driver(struct device *devptr,\r\nstruct device_driver *drvptr)\r\n{\r\nstruct maple_driver *maple_drv = to_maple_driver(drvptr);\r\nstruct maple_device *maple_dev = to_maple_dev(devptr);\r\nif (maple_dev->devinfo.function == 0xFFFFFFFF)\r\nreturn 0;\r\nelse if (maple_dev->devinfo.function &\r\ncpu_to_be32(maple_drv->function))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int maple_bus_uevent(struct device *dev,\r\nstruct kobj_uevent_env *env)\r\n{\r\nreturn 0;\r\n}\r\nstatic void maple_bus_release(struct device *dev)\r\n{\r\n}\r\nstatic int __init maple_bus_init(void)\r\n{\r\nint retval, i;\r\nstruct maple_device *mdev[MAPLE_PORTS];\r\n__raw_writel(0, MAPLE_ENABLE);\r\nretval = device_register(&maple_bus);\r\nif (retval)\r\ngoto cleanup;\r\nretval = bus_register(&maple_bus_type);\r\nif (retval)\r\ngoto cleanup_device;\r\nretval = driver_register(&maple_unsupported_device.drv);\r\nif (retval)\r\ngoto cleanup_bus;\r\nretval = maple_get_dma_buffer();\r\nif (retval) {\r\ndev_err(&maple_bus, "failed to allocate DMA buffers\n");\r\ngoto cleanup_basic;\r\n}\r\nretval = maple_set_dma_interrupt_handler();\r\nif (retval) {\r\ndev_err(&maple_bus, "bus failed to grab maple "\r\n"DMA IRQ\n");\r\ngoto cleanup_dma;\r\n}\r\nretval = maple_set_vblank_interrupt_handler();\r\nif (retval) {\r\ndev_err(&maple_bus, "bus failed to grab VBLANK IRQ\n");\r\ngoto cleanup_irq;\r\n}\r\nmaple_queue_cache = KMEM_CACHE(maple_buffer, SLAB_HWCACHE_ALIGN);\r\nif (!maple_queue_cache)\r\ngoto cleanup_bothirqs;\r\nINIT_LIST_HEAD(&maple_waitq);\r\nINIT_LIST_HEAD(&maple_sentq);\r\nfor (i = 0; i < MAPLE_PORTS; i++) {\r\nchecked[i] = false;\r\nempty[i] = false;\r\nmdev[i] = maple_alloc_dev(i, 0);\r\nif (!mdev[i]) {\r\nwhile (i-- > 0)\r\nmaple_free_dev(mdev[i]);\r\ngoto cleanup_cache;\r\n}\r\nbaseunits[i] = mdev[i];\r\natomic_set(&mdev[i]->busy, 1);\r\nmaple_add_packet(mdev[i], 0, MAPLE_COMMAND_DEVINFO, 0, NULL);\r\nsubdevice_map[i] = 0;\r\n}\r\nmaple_pnp_time = jiffies + HZ;\r\nmaple_send();\r\ndev_info(&maple_bus, "bus core now registered\n");\r\nreturn 0;\r\ncleanup_cache:\r\nkmem_cache_destroy(maple_queue_cache);\r\ncleanup_bothirqs:\r\nfree_irq(HW_EVENT_VSYNC, 0);\r\ncleanup_irq:\r\nfree_irq(HW_EVENT_MAPLE_DMA, 0);\r\ncleanup_dma:\r\nfree_pages((unsigned long) maple_sendbuf, MAPLE_DMA_PAGES);\r\ncleanup_basic:\r\ndriver_unregister(&maple_unsupported_device.drv);\r\ncleanup_bus:\r\nbus_unregister(&maple_bus_type);\r\ncleanup_device:\r\ndevice_unregister(&maple_bus);\r\ncleanup:\r\nprintk(KERN_ERR "Maple bus registration failed\n");\r\nreturn retval;\r\n}
