static void *\r\ngm200_secboot_load_firmware(struct nvkm_subdev *subdev, const char *name,\r\nsize_t min_size)\r\n{\r\nconst struct firmware *fw;\r\nvoid *blob;\r\nint ret;\r\nret = nvkm_firmware_get(subdev->device, name, &fw);\r\nif (ret)\r\nreturn ERR_PTR(ret);\r\nif (fw->size < min_size) {\r\nnvkm_error(subdev, "%s is smaller than expected size %zu\n",\r\nname, min_size);\r\nnvkm_firmware_put(fw);\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\nblob = kmemdup(fw->data, fw->size, GFP_KERNEL);\r\nnvkm_firmware_put(fw);\r\nif (!blob)\r\nreturn ERR_PTR(-ENOMEM);\r\nreturn blob;\r\n}\r\nstatic void *\r\nls_ucode_img_build(const struct firmware *bl, const struct firmware *code,\r\nconst struct firmware *data, struct ls_ucode_img_desc *desc)\r\n{\r\nstruct fw_bin_header *bin_hdr = (void *)bl->data;\r\nstruct fw_bl_desc *bl_desc = (void *)bl->data + bin_hdr->header_offset;\r\nvoid *bl_data = (void *)bl->data + bin_hdr->data_offset;\r\nu32 pos = 0;\r\nvoid *image;\r\ndesc->bootloader_start_offset = pos;\r\ndesc->bootloader_size = ALIGN(bl_desc->code_size, sizeof(u32));\r\ndesc->bootloader_imem_offset = bl_desc->start_tag * 256;\r\ndesc->bootloader_entry_point = bl_desc->start_tag * 256;\r\npos = ALIGN(pos + desc->bootloader_size, BL_DESC_BLK_SIZE);\r\ndesc->app_start_offset = pos;\r\ndesc->app_size = ALIGN(code->size, BL_DESC_BLK_SIZE) +\r\nALIGN(data->size, BL_DESC_BLK_SIZE);\r\ndesc->app_imem_offset = 0;\r\ndesc->app_imem_entry = 0;\r\ndesc->app_dmem_offset = 0;\r\ndesc->app_resident_code_offset = 0;\r\ndesc->app_resident_code_size = ALIGN(code->size, BL_DESC_BLK_SIZE);\r\npos = ALIGN(pos + desc->app_resident_code_size, BL_DESC_BLK_SIZE);\r\ndesc->app_resident_data_offset = pos - desc->app_start_offset;\r\ndesc->app_resident_data_size = ALIGN(data->size, BL_DESC_BLK_SIZE);\r\ndesc->image_size = ALIGN(bl_desc->code_size, BL_DESC_BLK_SIZE) +\r\ndesc->app_size;\r\nimage = kzalloc(desc->image_size, GFP_KERNEL);\r\nif (!image)\r\nreturn ERR_PTR(-ENOMEM);\r\nmemcpy(image + desc->bootloader_start_offset, bl_data,\r\nbl_desc->code_size);\r\nmemcpy(image + desc->app_start_offset, code->data, code->size);\r\nmemcpy(image + desc->app_start_offset + desc->app_resident_data_offset,\r\ndata->data, data->size);\r\nreturn image;\r\n}\r\nstatic int\r\nls_ucode_img_load_generic(struct nvkm_subdev *subdev,\r\nstruct ls_ucode_img *img, const char *falcon_name,\r\nconst u32 falcon_id)\r\n{\r\nconst struct firmware *bl, *code, *data;\r\nstruct lsf_ucode_desc *lsf_desc;\r\nchar f[64];\r\nint ret;\r\nimg->ucode_header = NULL;\r\nsnprintf(f, sizeof(f), "gr/%s_bl", falcon_name);\r\nret = nvkm_firmware_get(subdev->device, f, &bl);\r\nif (ret)\r\ngoto error;\r\nsnprintf(f, sizeof(f), "gr/%s_inst", falcon_name);\r\nret = nvkm_firmware_get(subdev->device, f, &code);\r\nif (ret)\r\ngoto free_bl;\r\nsnprintf(f, sizeof(f), "gr/%s_data", falcon_name);\r\nret = nvkm_firmware_get(subdev->device, f, &data);\r\nif (ret)\r\ngoto free_inst;\r\nimg->ucode_data = ls_ucode_img_build(bl, code, data,\r\n&img->ucode_desc);\r\nif (IS_ERR(img->ucode_data)) {\r\nret = PTR_ERR(img->ucode_data);\r\ngoto free_data;\r\n}\r\nimg->ucode_size = img->ucode_desc.image_size;\r\nsnprintf(f, sizeof(f), "gr/%s_sig", falcon_name);\r\nlsf_desc = gm200_secboot_load_firmware(subdev, f, sizeof(*lsf_desc));\r\nif (IS_ERR(lsf_desc)) {\r\nret = PTR_ERR(lsf_desc);\r\ngoto free_image;\r\n}\r\nlsf_desc->falcon_id = falcon_id;\r\nmemcpy(&img->lsb_header.signature, lsf_desc, sizeof(*lsf_desc));\r\nimg->falcon_id = lsf_desc->falcon_id;\r\nkfree(lsf_desc);\r\ngoto free_data;\r\nfree_image:\r\nkfree(img->ucode_data);\r\nfree_data:\r\nnvkm_firmware_put(data);\r\nfree_inst:\r\nnvkm_firmware_put(code);\r\nfree_bl:\r\nnvkm_firmware_put(bl);\r\nerror:\r\nreturn ret;\r\n}\r\nstatic int\r\nls_ucode_img_load_fecs(struct nvkm_subdev *subdev, struct ls_ucode_img *img)\r\n{\r\nreturn ls_ucode_img_load_generic(subdev, img, "fecs",\r\nNVKM_SECBOOT_FALCON_FECS);\r\n}\r\nstatic int\r\nls_ucode_img_load_gpccs(struct nvkm_subdev *subdev, struct ls_ucode_img *img)\r\n{\r\nreturn ls_ucode_img_load_generic(subdev, img, "gpccs",\r\nNVKM_SECBOOT_FALCON_GPCCS);\r\n}\r\nstatic struct ls_ucode_img *\r\nls_ucode_img_load(struct nvkm_subdev *subdev, lsf_load_func load_func)\r\n{\r\nstruct ls_ucode_img *img;\r\nint ret;\r\nimg = kzalloc(sizeof(*img), GFP_KERNEL);\r\nif (!img)\r\nreturn ERR_PTR(-ENOMEM);\r\nret = load_func(subdev, img);\r\nif (ret) {\r\nkfree(img);\r\nreturn ERR_PTR(ret);\r\n}\r\nreturn img;\r\n}\r\nstatic void\r\nls_ucode_img_populate_bl_desc(struct ls_ucode_img *img, u64 wpr_addr,\r\nstruct gm200_flcn_bl_desc *desc)\r\n{\r\nstruct ls_ucode_img_desc *pdesc = &img->ucode_desc;\r\nu64 addr_base;\r\naddr_base = wpr_addr + img->lsb_header.ucode_off +\r\npdesc->app_start_offset;\r\nmemset(desc, 0, sizeof(*desc));\r\ndesc->ctx_dma = FALCON_DMAIDX_UCODE;\r\ndesc->code_dma_base.lo = lower_32_bits(\r\n(addr_base + pdesc->app_resident_code_offset));\r\ndesc->code_dma_base.hi = upper_32_bits(\r\n(addr_base + pdesc->app_resident_code_offset));\r\ndesc->non_sec_code_size = pdesc->app_resident_code_size;\r\ndesc->data_dma_base.lo = lower_32_bits(\r\n(addr_base + pdesc->app_resident_data_offset));\r\ndesc->data_dma_base.hi = upper_32_bits(\r\n(addr_base + pdesc->app_resident_data_offset));\r\ndesc->data_size = pdesc->app_resident_data_size;\r\ndesc->code_entry_point = pdesc->app_imem_entry;\r\n}\r\nstatic u32\r\nls_ucode_img_fill_headers(struct gm200_secboot *gsb, struct ls_ucode_img *img,\r\nu32 offset)\r\n{\r\nstruct lsf_wpr_header *whdr = &img->wpr_header;\r\nstruct lsf_lsb_header *lhdr = &img->lsb_header;\r\nstruct ls_ucode_img_desc *desc = &img->ucode_desc;\r\nif (img->ucode_header) {\r\nnvkm_fatal(&gsb->base.subdev,\r\n"images withough loader are not supported yet!\n");\r\nreturn offset;\r\n}\r\nwhdr->falcon_id = img->falcon_id;\r\nwhdr->bootstrap_owner = gsb->base.func->boot_falcon;\r\nwhdr->status = LSF_IMAGE_STATUS_COPY;\r\noffset = ALIGN(offset, LSF_LSB_HEADER_ALIGN);\r\nwhdr->lsb_offset = offset;\r\noffset += sizeof(struct lsf_lsb_header);\r\noffset = ALIGN(offset, LSF_UCODE_DATA_ALIGN);\r\nlhdr->ucode_off = offset;\r\noffset += img->ucode_size;\r\nlhdr->bl_code_size = ALIGN(desc->bootloader_size,\r\nLSF_BL_CODE_SIZE_ALIGN);\r\nlhdr->ucode_size = ALIGN(desc->app_resident_data_offset,\r\nLSF_BL_CODE_SIZE_ALIGN) + lhdr->bl_code_size;\r\nlhdr->data_size = ALIGN(desc->app_size, LSF_BL_CODE_SIZE_ALIGN) +\r\nlhdr->bl_code_size - lhdr->ucode_size;\r\nlhdr->bl_imem_off = desc->bootloader_imem_offset;\r\nlhdr->app_code_off = desc->app_start_offset +\r\ndesc->app_resident_code_offset;\r\nlhdr->app_code_size = desc->app_resident_code_size;\r\nlhdr->app_data_off = desc->app_start_offset +\r\ndesc->app_resident_data_offset;\r\nlhdr->app_data_size = desc->app_resident_data_size;\r\nlhdr->flags = 0;\r\nif (img->falcon_id == gsb->base.func->boot_falcon)\r\nlhdr->flags = LSF_FLAG_DMACTL_REQ_CTX;\r\nif (img->falcon_id == NVKM_SECBOOT_FALCON_GPCCS)\r\nlhdr->flags |= LSF_FLAG_FORCE_PRIV_LOAD;\r\nlhdr->bl_data_size = ALIGN(sizeof(struct gm200_flcn_bl_desc),\r\nLSF_BL_DATA_SIZE_ALIGN);\r\noffset = ALIGN(offset, LSF_BL_DATA_ALIGN);\r\nlhdr->bl_data_off = offset;\r\noffset += lhdr->bl_data_size;\r\nreturn offset;\r\n}\r\nstatic void\r\nls_ucode_mgr_init(struct ls_ucode_mgr *mgr)\r\n{\r\nmemset(mgr, 0, sizeof(*mgr));\r\nINIT_LIST_HEAD(&mgr->img_list);\r\n}\r\nstatic void\r\nls_ucode_mgr_cleanup(struct ls_ucode_mgr *mgr)\r\n{\r\nstruct ls_ucode_img *img, *t;\r\nlist_for_each_entry_safe(img, t, &mgr->img_list, node) {\r\nkfree(img->ucode_data);\r\nkfree(img->ucode_header);\r\nkfree(img);\r\n}\r\n}\r\nstatic void\r\nls_ucode_mgr_add_img(struct ls_ucode_mgr *mgr, struct ls_ucode_img *img)\r\n{\r\nmgr->count++;\r\nlist_add_tail(&img->node, &mgr->img_list);\r\n}\r\nstatic void\r\nls_ucode_mgr_fill_headers(struct gm200_secboot *gsb, struct ls_ucode_mgr *mgr)\r\n{\r\nstruct ls_ucode_img *img;\r\nu32 offset;\r\noffset = sizeof(struct lsf_wpr_header) * (mgr->count + 1);\r\nlist_for_each_entry(img, &mgr->img_list, node) {\r\noffset = ls_ucode_img_fill_headers(gsb, img, offset);\r\n}\r\nmgr->wpr_size = offset;\r\n}\r\nstatic int\r\nls_ucode_mgr_write_wpr(struct gm200_secboot *gsb, struct ls_ucode_mgr *mgr,\r\nstruct nvkm_gpuobj *wpr_blob)\r\n{\r\nstruct ls_ucode_img *img;\r\nu32 pos = 0;\r\nnvkm_kmap(wpr_blob);\r\nlist_for_each_entry(img, &mgr->img_list, node) {\r\nnvkm_gpuobj_memcpy_to(wpr_blob, pos, &img->wpr_header,\r\nsizeof(img->wpr_header));\r\nnvkm_gpuobj_memcpy_to(wpr_blob, img->wpr_header.lsb_offset,\r\n&img->lsb_header, sizeof(img->lsb_header));\r\nif (!img->ucode_header) {\r\nu8 desc[gsb->func->bl_desc_size];\r\nstruct gm200_flcn_bl_desc gdesc;\r\nls_ucode_img_populate_bl_desc(img, gsb->wpr_addr,\r\n&gdesc);\r\ngsb->func->fixup_bl_desc(&gdesc, &desc);\r\nnvkm_gpuobj_memcpy_to(wpr_blob,\r\nimg->lsb_header.bl_data_off,\r\n&desc, gsb->func->bl_desc_size);\r\n}\r\nnvkm_gpuobj_memcpy_to(wpr_blob, img->lsb_header.ucode_off,\r\nimg->ucode_data, img->ucode_size);\r\npos += sizeof(img->wpr_header);\r\n}\r\nnvkm_wo32(wpr_blob, pos, NVKM_SECBOOT_FALCON_INVALID);\r\nnvkm_done(wpr_blob);\r\nreturn 0;\r\n}\r\nstatic int\r\ngm200_secboot_prepare_ls_blob(struct gm200_secboot *gsb)\r\n{\r\nstruct nvkm_secboot *sb = &gsb->base;\r\nstruct nvkm_device *device = sb->subdev.device;\r\nstruct ls_ucode_mgr mgr;\r\nint falcon_id;\r\nint ret;\r\nls_ucode_mgr_init(&mgr);\r\nfor_each_set_bit(falcon_id, &gsb->base.func->managed_falcons,\r\nNVKM_SECBOOT_FALCON_END) {\r\nstruct ls_ucode_img *img;\r\nimg = ls_ucode_img_load(&sb->subdev, lsf_load_funcs[falcon_id]);\r\nif (IS_ERR(img)) {\r\nret = PTR_ERR(img);\r\ngoto cleanup;\r\n}\r\nls_ucode_mgr_add_img(&mgr, img);\r\n}\r\nls_ucode_mgr_fill_headers(gsb, &mgr);\r\nmgr.wpr_size = ALIGN(mgr.wpr_size, WPR_ALIGNMENT);\r\nret = nvkm_gpuobj_new(device, mgr.wpr_size, WPR_ALIGNMENT, false, NULL,\r\n&gsb->ls_blob);\r\nif (ret)\r\ngoto cleanup;\r\nnvkm_debug(&sb->subdev, "%d managed LS falcons, WPR size is %d bytes\n",\r\nmgr.count, mgr.wpr_size);\r\nif (!gsb->wpr_size) {\r\ngsb->wpr_addr = gsb->ls_blob->addr;\r\ngsb->wpr_size = gsb->ls_blob->size;\r\n}\r\nret = ls_ucode_mgr_write_wpr(gsb, &mgr, gsb->ls_blob);\r\nif (ret)\r\nnvkm_gpuobj_del(&gsb->ls_blob);\r\ncleanup:\r\nls_ucode_mgr_cleanup(&mgr);\r\nreturn ret;\r\n}\r\nstatic void\r\ngm200_secboot_hsf_patch_signature(struct gm200_secboot *gsb, void *acr_image)\r\n{\r\nstruct nvkm_secboot *sb = &gsb->base;\r\nstruct fw_bin_header *hsbin_hdr = acr_image;\r\nstruct hsf_fw_header *fw_hdr = acr_image + hsbin_hdr->header_offset;\r\nvoid *hs_data = acr_image + hsbin_hdr->data_offset;\r\nvoid *sig;\r\nu32 sig_size;\r\nif ((nvkm_rd32(sb->subdev.device, sb->base + 0xc08) >> 20) & 0x1) {\r\nsig = acr_image + fw_hdr->sig_dbg_offset;\r\nsig_size = fw_hdr->sig_dbg_size;\r\n} else {\r\nsig = acr_image + fw_hdr->sig_prod_offset;\r\nsig_size = fw_hdr->sig_prod_size;\r\n}\r\nmemcpy(hs_data + fw_hdr->patch_loc, sig + fw_hdr->patch_sig, sig_size);\r\n}\r\nstatic void\r\ngm200_secboot_populate_hsf_bl_desc(void *acr_image,\r\nstruct gm200_flcn_bl_desc *bl_desc)\r\n{\r\nstruct fw_bin_header *hsbin_hdr = acr_image;\r\nstruct hsf_fw_header *fw_hdr = acr_image + hsbin_hdr->header_offset;\r\nstruct hsf_load_header *load_hdr = acr_image + fw_hdr->hdr_offset;\r\nfw_hdr = acr_image + hsbin_hdr->header_offset;\r\nload_hdr = acr_image + fw_hdr->hdr_offset;\r\nmemset(bl_desc, 0, sizeof(*bl_desc));\r\nbl_desc->ctx_dma = FALCON_DMAIDX_VIRT;\r\nbl_desc->non_sec_code_off = load_hdr->non_sec_code_off;\r\nbl_desc->non_sec_code_size = load_hdr->non_sec_code_size;\r\nbl_desc->sec_code_off = load_hdr->app[0].sec_code_off;\r\nbl_desc->sec_code_size = load_hdr->app[0].sec_code_size;\r\nbl_desc->code_entry_point = 0;\r\nbl_desc->code_dma_base.lo = 0;\r\nbl_desc->data_dma_base.lo = load_hdr->data_dma_base;\r\nbl_desc->data_size = load_hdr->data_size;\r\n}\r\nstatic int\r\ngm200_secboot_prepare_hs_blob(struct gm200_secboot *gsb, const char *fw,\r\nstruct nvkm_gpuobj **blob,\r\nstruct gm200_flcn_bl_desc *bl_desc, bool patch)\r\n{\r\nstruct nvkm_subdev *subdev = &gsb->base.subdev;\r\nvoid *acr_image;\r\nstruct fw_bin_header *hsbin_hdr;\r\nstruct hsf_fw_header *fw_hdr;\r\nvoid *acr_data;\r\nstruct hsf_load_header *load_hdr;\r\nstruct hsflcn_acr_desc *desc;\r\nint ret;\r\nacr_image = gm200_secboot_load_firmware(subdev, fw, 0);\r\nif (IS_ERR(acr_image))\r\nreturn PTR_ERR(acr_image);\r\nhsbin_hdr = acr_image;\r\ngm200_secboot_hsf_patch_signature(gsb, acr_image);\r\nacr_data = acr_image + hsbin_hdr->data_offset;\r\nif (patch) {\r\nfw_hdr = acr_image + hsbin_hdr->header_offset;\r\nload_hdr = acr_image + fw_hdr->hdr_offset;\r\ndesc = acr_data + load_hdr->data_dma_base;\r\ngsb->func->fixup_hs_desc(gsb, desc);\r\n}\r\ngm200_secboot_populate_hsf_bl_desc(acr_image, bl_desc);\r\nret = nvkm_gpuobj_new(subdev->device, ALIGN(hsbin_hdr->data_size, 256),\r\n0x1000, false, NULL, blob);\r\nif (ret)\r\ngoto cleanup;\r\nnvkm_kmap(*blob);\r\nnvkm_gpuobj_memcpy_to(*blob, 0, acr_data, hsbin_hdr->data_size);\r\nnvkm_done(*blob);\r\ncleanup:\r\nkfree(acr_image);\r\nreturn ret;\r\n}\r\nstatic int\r\ngm200_secboot_prepare_hsbl_blob(struct gm200_secboot *gsb)\r\n{\r\nstruct nvkm_subdev *subdev = &gsb->base.subdev;\r\ngsb->hsbl_blob = gm200_secboot_load_firmware(subdev, "acr/bl", 0);\r\nif (IS_ERR(gsb->hsbl_blob)) {\r\nint ret = PTR_ERR(gsb->hsbl_blob);\r\ngsb->hsbl_blob = NULL;\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nint\r\ngm20x_secboot_prepare_blobs(struct gm200_secboot *gsb)\r\n{\r\nint ret;\r\nif (!gsb->ls_blob) {\r\nret = gm200_secboot_prepare_ls_blob(gsb);\r\nif (ret)\r\nreturn ret;\r\n}\r\nif (!gsb->acr_load_blob) {\r\nret = gm200_secboot_prepare_hs_blob(gsb, "acr/ucode_load",\r\n&gsb->acr_load_blob,\r\n&gsb->acr_load_bl_desc, true);\r\nif (ret)\r\nreturn ret;\r\n}\r\nif (!gsb->hsbl_blob) {\r\nret = gm200_secboot_prepare_hsbl_blob(gsb);\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\ngm200_secboot_prepare_blobs(struct gm200_secboot *gsb)\r\n{\r\nint ret;\r\nret = gm20x_secboot_prepare_blobs(gsb);\r\nif (ret)\r\nreturn ret;\r\nif (!gsb->acr_unload_blob) {\r\nret = gm200_secboot_prepare_hs_blob(gsb, "acr/ucode_unload",\r\n&gsb->acr_unload_blob,\r\n&gsb->acr_unload_bl_desc, false);\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\ngm200_secboot_blobs_ready(struct gm200_secboot *gsb)\r\n{\r\nstruct nvkm_subdev *subdev = &gsb->base.subdev;\r\nint ret;\r\nif (gsb->firmware_ok)\r\nreturn 0;\r\nret = gsb->func->prepare_blobs(gsb);\r\nif (ret) {\r\nnvkm_error(subdev, "failed to load secure firmware\n");\r\nreturn ret;\r\n}\r\ngsb->firmware_ok = true;\r\nreturn 0;\r\n}\r\nstatic void\r\ngm200_secboot_load_hs_bl(struct gm200_secboot *gsb, void *data, u32 data_size)\r\n{\r\nstruct nvkm_device *device = gsb->base.subdev.device;\r\nstruct fw_bin_header *hdr = gsb->hsbl_blob;\r\nstruct fw_bl_desc *hsbl_desc = gsb->hsbl_blob + hdr->header_offset;\r\nvoid *blob_data = gsb->hsbl_blob + hdr->data_offset;\r\nvoid *hsbl_code = blob_data + hsbl_desc->code_off;\r\nvoid *hsbl_data = blob_data + hsbl_desc->data_off;\r\nu32 code_size = ALIGN(hsbl_desc->code_size, 256);\r\nconst u32 base = gsb->base.base;\r\nu32 blk;\r\nu32 tag;\r\nint i;\r\nnvkm_wr32(device, base + 0x1c0, (0x00000000 | (0x1 << 24)));\r\nfor (i = 0; i < hsbl_desc->data_size / 4; i++)\r\nnvkm_wr32(device, base + 0x1c4, ((u32 *)hsbl_data)[i]);\r\nnvkm_wr32(device, base + 0x1c0,\r\n(hsbl_desc->dmem_load_off | (0x1 << 24)));\r\nfor (i = 0; i < data_size / 4; i++)\r\nnvkm_wr32(device, base + 0x1c4, ((u32 *)data)[i]);\r\nblk = (nvkm_rd32(device, base + 0x108) & 0x1ff) - (code_size >> 8);\r\ntag = hsbl_desc->start_tag;\r\nnvkm_wr32(device, base + 0x180, ((blk & 0xff) << 8) | (0x1 << 24));\r\nfor (i = 0; i < code_size / 4; i++) {\r\nif ((i & 0x3f) == 0) {\r\nnvkm_wr32(device, base + 0x188, tag & 0xffff);\r\ntag++;\r\n}\r\nnvkm_wr32(device, base + 0x184, ((u32 *)hsbl_code)[i]);\r\n}\r\nnvkm_wr32(device, base + 0x188, 0);\r\n}\r\nstatic int\r\ngm200_secboot_setup_falcon(struct gm200_secboot *gsb)\r\n{\r\nstruct nvkm_device *device = gsb->base.subdev.device;\r\nstruct fw_bin_header *hdr = gsb->hsbl_blob;\r\nstruct fw_bl_desc *hsbl_desc = gsb->hsbl_blob + hdr->header_offset;\r\nu32 virt_addr = hsbl_desc->start_tag << 8;\r\nconst u32 base = gsb->base.base;\r\nconst u32 reg_base = base + 0xe00;\r\nu32 inst_loc;\r\nint ret;\r\nret = nvkm_secboot_falcon_reset(&gsb->base);\r\nif (ret)\r\nreturn ret;\r\nnvkm_wr32(device, reg_base + 4 * (FALCON_DMAIDX_UCODE), 0x4);\r\nnvkm_wr32(device, reg_base + 4 * (FALCON_DMAIDX_VIRT), 0x0);\r\nnvkm_wr32(device, reg_base + 4 * (FALCON_DMAIDX_PHYS_VID), 0x4);\r\nnvkm_wr32(device, reg_base + 4 * (FALCON_DMAIDX_PHYS_SYS_COH),\r\n0x4 | 0x1);\r\nnvkm_wr32(device, reg_base + 4 * (FALCON_DMAIDX_PHYS_SYS_NCOH),\r\n0x4 | 0x2);\r\nif (nvkm_memory_target(gsb->inst->memory) == NVKM_MEM_TARGET_VRAM)\r\ninst_loc = 0x0;\r\nelse\r\ninst_loc = 0x3;\r\nnvkm_mask(device, base + 0x048, 0x1, 0x1);\r\nnvkm_wr32(device, base + 0x480,\r\n((gsb->inst->addr >> 12) & 0xfffffff) |\r\n(inst_loc << 28) | (1 << 30));\r\nnvkm_wr32(device, base + 0x104, virt_addr);\r\nreturn 0;\r\n}\r\nstatic int\r\ngm200_secboot_run_hs_blob(struct gm200_secboot *gsb, struct nvkm_gpuobj *blob,\r\nstruct gm200_flcn_bl_desc *desc)\r\n{\r\nstruct nvkm_vma vma;\r\nu64 vma_addr;\r\nconst u32 bl_desc_size = gsb->func->bl_desc_size;\r\nu8 bl_desc[bl_desc_size];\r\nint ret;\r\nret = nvkm_gpuobj_map(blob, gsb->vm, NV_MEM_ACCESS_RW, &vma);\r\nif (ret)\r\nreturn ret;\r\nvma_addr = flcn64_to_u64(desc->code_dma_base) + vma.offset;\r\ndesc->code_dma_base.lo = lower_32_bits(vma_addr);\r\ndesc->code_dma_base.hi = upper_32_bits(vma_addr);\r\nvma_addr = flcn64_to_u64(desc->data_dma_base) + vma.offset;\r\ndesc->data_dma_base.lo = lower_32_bits(vma_addr);\r\ndesc->data_dma_base.hi = upper_32_bits(vma_addr);\r\ngsb->func->fixup_bl_desc(desc, &bl_desc);\r\nret = gm200_secboot_setup_falcon(gsb);\r\nif (ret)\r\ngoto done;\r\ngm200_secboot_load_hs_bl(gsb, &bl_desc, bl_desc_size);\r\nret = nvkm_secboot_falcon_run(&gsb->base);\r\nif (ret)\r\ngoto done;\r\ndone:\r\nvma_addr = flcn64_to_u64(desc->code_dma_base) - vma.offset;\r\ndesc->code_dma_base.lo = lower_32_bits(vma_addr);\r\ndesc->code_dma_base.hi = upper_32_bits(vma_addr);\r\nvma_addr = flcn64_to_u64(desc->data_dma_base) - vma.offset;\r\ndesc->data_dma_base.lo = lower_32_bits(vma_addr);\r\ndesc->data_dma_base.hi = upper_32_bits(vma_addr);\r\nnvkm_gpuobj_unmap(&vma);\r\nreturn ret;\r\n}\r\nint\r\ngm200_secboot_reset(struct nvkm_secboot *sb, enum nvkm_secboot_falcon falcon)\r\n{\r\nstruct gm200_secboot *gsb = gm200_secboot(sb);\r\nint ret;\r\nret = gm200_secboot_blobs_ready(gsb);\r\nif (ret)\r\nreturn ret;\r\nif (falcon != NVKM_SECBOOT_FALCON_FECS)\r\ngoto end;\r\nif (gsb->acr_unload_blob &&\r\ngsb->falcon_state[NVKM_SECBOOT_FALCON_FECS] != NON_SECURE) {\r\nret = gm200_secboot_run_hs_blob(gsb, gsb->acr_unload_blob,\r\n&gsb->acr_unload_bl_desc);\r\nif (ret)\r\nreturn ret;\r\n}\r\nret = gm200_secboot_run_hs_blob(gsb, gsb->acr_load_blob,\r\n&gsb->acr_load_bl_desc);\r\nif (ret)\r\nreturn ret;\r\nend:\r\ngsb->falcon_state[falcon] = RESET;\r\nreturn 0;\r\n}\r\nint\r\ngm200_secboot_start(struct nvkm_secboot *sb, enum nvkm_secboot_falcon falcon)\r\n{\r\nstruct gm200_secboot *gsb = gm200_secboot(sb);\r\nint base;\r\nswitch (falcon) {\r\ncase NVKM_SECBOOT_FALCON_FECS:\r\nbase = 0x409000;\r\nbreak;\r\ncase NVKM_SECBOOT_FALCON_GPCCS:\r\nbase = 0x41a000;\r\nbreak;\r\ndefault:\r\nnvkm_error(&sb->subdev, "cannot start unhandled falcon!\n");\r\nreturn -EINVAL;\r\n}\r\nnvkm_wr32(sb->subdev.device, base + 0x130, 0x00000002);\r\ngsb->falcon_state[falcon] = RUNNING;\r\nreturn 0;\r\n}\r\nint\r\ngm200_secboot_init(struct nvkm_secboot *sb)\r\n{\r\nstruct gm200_secboot *gsb = gm200_secboot(sb);\r\nstruct nvkm_device *device = sb->subdev.device;\r\nstruct nvkm_vm *vm;\r\nconst u64 vm_area_len = 600 * 1024;\r\nint ret;\r\nret = nvkm_gpuobj_new(device, 0x1000, 0, true, NULL, &gsb->inst);\r\nif (ret)\r\nreturn ret;\r\nret = nvkm_gpuobj_new(device, 0x8000, 0, true, NULL, &gsb->pgd);\r\nif (ret)\r\nreturn ret;\r\nret = nvkm_vm_new(device, 0, vm_area_len, 0, NULL, &vm);\r\nif (ret)\r\nreturn ret;\r\natomic_inc(&vm->engref[NVKM_SUBDEV_PMU]);\r\nret = nvkm_vm_ref(vm, &gsb->vm, gsb->pgd);\r\nnvkm_vm_ref(NULL, &vm, NULL);\r\nif (ret)\r\nreturn ret;\r\nnvkm_kmap(gsb->inst);\r\nnvkm_wo32(gsb->inst, 0x200, lower_32_bits(gsb->pgd->addr));\r\nnvkm_wo32(gsb->inst, 0x204, upper_32_bits(gsb->pgd->addr));\r\nnvkm_wo32(gsb->inst, 0x208, lower_32_bits(vm_area_len - 1));\r\nnvkm_wo32(gsb->inst, 0x20c, upper_32_bits(vm_area_len - 1));\r\nnvkm_done(gsb->inst);\r\nreturn 0;\r\n}\r\nint\r\ngm200_secboot_fini(struct nvkm_secboot *sb, bool suspend)\r\n{\r\nstruct gm200_secboot *gsb = gm200_secboot(sb);\r\nint ret = 0;\r\nint i;\r\nif (gsb->acr_unload_blob &&\r\ngsb->falcon_state[NVKM_SECBOOT_FALCON_FECS] != NON_SECURE)\r\nret = gm200_secboot_run_hs_blob(gsb, gsb->acr_unload_blob,\r\n&gsb->acr_unload_bl_desc);\r\nfor (i = 0; i < NVKM_SECBOOT_FALCON_END; i++)\r\ngsb->falcon_state[i] = NON_SECURE;\r\nreturn ret;\r\n}\r\nvoid *\r\ngm200_secboot_dtor(struct nvkm_secboot *sb)\r\n{\r\nstruct gm200_secboot *gsb = gm200_secboot(sb);\r\nnvkm_gpuobj_del(&gsb->acr_unload_blob);\r\nkfree(gsb->hsbl_blob);\r\nnvkm_gpuobj_del(&gsb->acr_load_blob);\r\nnvkm_gpuobj_del(&gsb->ls_blob);\r\nnvkm_vm_ref(NULL, &gsb->vm, gsb->pgd);\r\nnvkm_gpuobj_del(&gsb->pgd);\r\nnvkm_gpuobj_del(&gsb->inst);\r\nreturn gsb;\r\n}\r\nstatic void\r\ngm200_secboot_fixup_bl_desc(const struct gm200_flcn_bl_desc *desc, void *ret)\r\n{\r\nmemcpy(ret, desc, sizeof(*desc));\r\n}\r\nstatic void\r\ngm200_secboot_fixup_hs_desc(struct gm200_secboot *gsb,\r\nstruct hsflcn_acr_desc *desc)\r\n{\r\ndesc->ucode_blob_base = gsb->ls_blob->addr;\r\ndesc->ucode_blob_size = gsb->ls_blob->size;\r\ndesc->wpr_offset = 0;\r\ndesc->wpr_region_id = 1;\r\ndesc->regions.no_regions = 1;\r\ndesc->regions.region_props[0].region_id = 1;\r\ndesc->regions.region_props[0].start_addr = gsb->wpr_addr >> 8;\r\ndesc->regions.region_props[0].end_addr =\r\n(gsb->wpr_addr + gsb->wpr_size) >> 8;\r\n}\r\nint\r\ngm200_secboot_new(struct nvkm_device *device, int index,\r\nstruct nvkm_secboot **psb)\r\n{\r\nint ret;\r\nstruct gm200_secboot *gsb;\r\ngsb = kzalloc(sizeof(*gsb), GFP_KERNEL);\r\nif (!gsb) {\r\npsb = NULL;\r\nreturn -ENOMEM;\r\n}\r\n*psb = &gsb->base;\r\nret = nvkm_secboot_ctor(&gm200_secboot, device, index, &gsb->base);\r\nif (ret)\r\nreturn ret;\r\ngsb->func = &gm200_secboot_func;\r\nreturn 0;\r\n}
