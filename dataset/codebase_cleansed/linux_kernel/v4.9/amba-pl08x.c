static inline struct pl08x_dma_chan *to_pl08x_chan(struct dma_chan *chan)\r\n{\r\nreturn container_of(chan, struct pl08x_dma_chan, vc.chan);\r\n}\r\nstatic inline struct pl08x_txd *to_pl08x_txd(struct dma_async_tx_descriptor *tx)\r\n{\r\nreturn container_of(tx, struct pl08x_txd, vd.tx);\r\n}\r\nstatic int pl08x_request_mux(struct pl08x_dma_chan *plchan)\r\n{\r\nconst struct pl08x_platform_data *pd = plchan->host->pd;\r\nint ret;\r\nif (plchan->mux_use++ == 0 && pd->get_xfer_signal) {\r\nret = pd->get_xfer_signal(plchan->cd);\r\nif (ret < 0) {\r\nplchan->mux_use = 0;\r\nreturn ret;\r\n}\r\nplchan->signal = ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic void pl08x_release_mux(struct pl08x_dma_chan *plchan)\r\n{\r\nconst struct pl08x_platform_data *pd = plchan->host->pd;\r\nif (plchan->signal >= 0) {\r\nWARN_ON(plchan->mux_use == 0);\r\nif (--plchan->mux_use == 0 && pd->put_xfer_signal) {\r\npd->put_xfer_signal(plchan->cd, plchan->signal);\r\nplchan->signal = -1;\r\n}\r\n}\r\n}\r\nstatic int pl08x_phy_channel_busy(struct pl08x_phy_chan *ch)\r\n{\r\nunsigned int val;\r\nval = readl(ch->reg_config);\r\nreturn val & PL080_CONFIG_ACTIVE;\r\n}\r\nstatic void pl08x_write_lli(struct pl08x_driver_data *pl08x,\r\nstruct pl08x_phy_chan *phychan, const u32 *lli, u32 ccfg)\r\n{\r\nif (pl08x->vd->pl080s)\r\ndev_vdbg(&pl08x->adev->dev,\r\n"WRITE channel %d: csrc=0x%08x, cdst=0x%08x, "\r\n"clli=0x%08x, cctl=0x%08x, cctl2=0x%08x, ccfg=0x%08x\n",\r\nphychan->id, lli[PL080_LLI_SRC], lli[PL080_LLI_DST],\r\nlli[PL080_LLI_LLI], lli[PL080_LLI_CCTL],\r\nlli[PL080S_LLI_CCTL2], ccfg);\r\nelse\r\ndev_vdbg(&pl08x->adev->dev,\r\n"WRITE channel %d: csrc=0x%08x, cdst=0x%08x, "\r\n"clli=0x%08x, cctl=0x%08x, ccfg=0x%08x\n",\r\nphychan->id, lli[PL080_LLI_SRC], lli[PL080_LLI_DST],\r\nlli[PL080_LLI_LLI], lli[PL080_LLI_CCTL], ccfg);\r\nwritel_relaxed(lli[PL080_LLI_SRC], phychan->base + PL080_CH_SRC_ADDR);\r\nwritel_relaxed(lli[PL080_LLI_DST], phychan->base + PL080_CH_DST_ADDR);\r\nwritel_relaxed(lli[PL080_LLI_LLI], phychan->base + PL080_CH_LLI);\r\nwritel_relaxed(lli[PL080_LLI_CCTL], phychan->base + PL080_CH_CONTROL);\r\nif (pl08x->vd->pl080s)\r\nwritel_relaxed(lli[PL080S_LLI_CCTL2],\r\nphychan->base + PL080S_CH_CONTROL2);\r\nwritel(ccfg, phychan->reg_config);\r\n}\r\nstatic void pl08x_start_next_txd(struct pl08x_dma_chan *plchan)\r\n{\r\nstruct pl08x_driver_data *pl08x = plchan->host;\r\nstruct pl08x_phy_chan *phychan = plchan->phychan;\r\nstruct virt_dma_desc *vd = vchan_next_desc(&plchan->vc);\r\nstruct pl08x_txd *txd = to_pl08x_txd(&vd->tx);\r\nu32 val;\r\nlist_del(&txd->vd.node);\r\nplchan->at = txd;\r\nwhile (pl08x_phy_channel_busy(phychan))\r\ncpu_relax();\r\npl08x_write_lli(pl08x, phychan, &txd->llis_va[0], txd->ccfg);\r\nwhile (readl(pl08x->base + PL080_EN_CHAN) & (1 << phychan->id))\r\ncpu_relax();\r\nval = readl(phychan->reg_config);\r\nwhile ((val & PL080_CONFIG_ACTIVE) || (val & PL080_CONFIG_ENABLE))\r\nval = readl(phychan->reg_config);\r\nwritel(val | PL080_CONFIG_ENABLE, phychan->reg_config);\r\n}\r\nstatic void pl08x_pause_phy_chan(struct pl08x_phy_chan *ch)\r\n{\r\nu32 val;\r\nint timeout;\r\nval = readl(ch->reg_config);\r\nval |= PL080_CONFIG_HALT;\r\nwritel(val, ch->reg_config);\r\nfor (timeout = 1000; timeout; timeout--) {\r\nif (!pl08x_phy_channel_busy(ch))\r\nbreak;\r\nudelay(1);\r\n}\r\nif (pl08x_phy_channel_busy(ch))\r\npr_err("pl08x: channel%u timeout waiting for pause\n", ch->id);\r\n}\r\nstatic void pl08x_resume_phy_chan(struct pl08x_phy_chan *ch)\r\n{\r\nu32 val;\r\nval = readl(ch->reg_config);\r\nval &= ~PL080_CONFIG_HALT;\r\nwritel(val, ch->reg_config);\r\n}\r\nstatic void pl08x_terminate_phy_chan(struct pl08x_driver_data *pl08x,\r\nstruct pl08x_phy_chan *ch)\r\n{\r\nu32 val = readl(ch->reg_config);\r\nval &= ~(PL080_CONFIG_ENABLE | PL080_CONFIG_ERR_IRQ_MASK |\r\nPL080_CONFIG_TC_IRQ_MASK);\r\nwritel(val, ch->reg_config);\r\nwritel(1 << ch->id, pl08x->base + PL080_ERR_CLEAR);\r\nwritel(1 << ch->id, pl08x->base + PL080_TC_CLEAR);\r\n}\r\nstatic inline u32 get_bytes_in_cctl(u32 cctl)\r\n{\r\nu32 bytes = cctl & PL080_CONTROL_TRANSFER_SIZE_MASK;\r\ncctl &= PL080_CONTROL_SWIDTH_MASK;\r\nswitch (cctl >> PL080_CONTROL_SWIDTH_SHIFT) {\r\ncase PL080_WIDTH_8BIT:\r\nbreak;\r\ncase PL080_WIDTH_16BIT:\r\nbytes *= 2;\r\nbreak;\r\ncase PL080_WIDTH_32BIT:\r\nbytes *= 4;\r\nbreak;\r\n}\r\nreturn bytes;\r\n}\r\nstatic inline u32 get_bytes_in_cctl_pl080s(u32 cctl, u32 cctl1)\r\n{\r\nu32 bytes = cctl1 & PL080S_CONTROL_TRANSFER_SIZE_MASK;\r\ncctl &= PL080_CONTROL_SWIDTH_MASK;\r\nswitch (cctl >> PL080_CONTROL_SWIDTH_SHIFT) {\r\ncase PL080_WIDTH_8BIT:\r\nbreak;\r\ncase PL080_WIDTH_16BIT:\r\nbytes *= 2;\r\nbreak;\r\ncase PL080_WIDTH_32BIT:\r\nbytes *= 4;\r\nbreak;\r\n}\r\nreturn bytes;\r\n}\r\nstatic u32 pl08x_getbytes_chan(struct pl08x_dma_chan *plchan)\r\n{\r\nstruct pl08x_driver_data *pl08x = plchan->host;\r\nconst u32 *llis_va, *llis_va_limit;\r\nstruct pl08x_phy_chan *ch;\r\ndma_addr_t llis_bus;\r\nstruct pl08x_txd *txd;\r\nu32 llis_max_words;\r\nsize_t bytes;\r\nu32 clli;\r\nch = plchan->phychan;\r\ntxd = plchan->at;\r\nif (!ch || !txd)\r\nreturn 0;\r\nclli = readl(ch->base + PL080_CH_LLI) & ~PL080_LLI_LM_AHB2;\r\nif (pl08x->vd->pl080s)\r\nbytes = get_bytes_in_cctl_pl080s(\r\nreadl(ch->base + PL080_CH_CONTROL),\r\nreadl(ch->base + PL080S_CH_CONTROL2));\r\nelse\r\nbytes = get_bytes_in_cctl(readl(ch->base + PL080_CH_CONTROL));\r\nif (!clli)\r\nreturn bytes;\r\nllis_va = txd->llis_va;\r\nllis_bus = txd->llis_bus;\r\nllis_max_words = pl08x->lli_words * MAX_NUM_TSFR_LLIS;\r\nBUG_ON(clli < llis_bus || clli >= llis_bus +\r\nsizeof(u32) * llis_max_words);\r\nllis_va += (clli - llis_bus) / sizeof(u32);\r\nllis_va_limit = llis_va + llis_max_words;\r\nfor (; llis_va < llis_va_limit; llis_va += pl08x->lli_words) {\r\nif (pl08x->vd->pl080s)\r\nbytes += get_bytes_in_cctl_pl080s(\r\nllis_va[PL080_LLI_CCTL],\r\nllis_va[PL080S_LLI_CCTL2]);\r\nelse\r\nbytes += get_bytes_in_cctl(llis_va[PL080_LLI_CCTL]);\r\nif (llis_va[PL080_LLI_LLI] <= clli)\r\nbreak;\r\n}\r\nreturn bytes;\r\n}\r\nstatic struct pl08x_phy_chan *\r\npl08x_get_phy_channel(struct pl08x_driver_data *pl08x,\r\nstruct pl08x_dma_chan *virt_chan)\r\n{\r\nstruct pl08x_phy_chan *ch = NULL;\r\nunsigned long flags;\r\nint i;\r\nfor (i = 0; i < pl08x->vd->channels; i++) {\r\nch = &pl08x->phy_chans[i];\r\nspin_lock_irqsave(&ch->lock, flags);\r\nif (!ch->locked && !ch->serving) {\r\nch->serving = virt_chan;\r\nspin_unlock_irqrestore(&ch->lock, flags);\r\nbreak;\r\n}\r\nspin_unlock_irqrestore(&ch->lock, flags);\r\n}\r\nif (i == pl08x->vd->channels) {\r\nreturn NULL;\r\n}\r\nreturn ch;\r\n}\r\nstatic inline void pl08x_put_phy_channel(struct pl08x_driver_data *pl08x,\r\nstruct pl08x_phy_chan *ch)\r\n{\r\nch->serving = NULL;\r\n}\r\nstatic void pl08x_phy_alloc_and_start(struct pl08x_dma_chan *plchan)\r\n{\r\nstruct pl08x_driver_data *pl08x = plchan->host;\r\nstruct pl08x_phy_chan *ch;\r\nch = pl08x_get_phy_channel(pl08x, plchan);\r\nif (!ch) {\r\ndev_dbg(&pl08x->adev->dev, "no physical channel available for xfer on %s\n", plchan->name);\r\nplchan->state = PL08X_CHAN_WAITING;\r\nreturn;\r\n}\r\ndev_dbg(&pl08x->adev->dev, "allocated physical channel %d for xfer on %s\n",\r\nch->id, plchan->name);\r\nplchan->phychan = ch;\r\nplchan->state = PL08X_CHAN_RUNNING;\r\npl08x_start_next_txd(plchan);\r\n}\r\nstatic void pl08x_phy_reassign_start(struct pl08x_phy_chan *ch,\r\nstruct pl08x_dma_chan *plchan)\r\n{\r\nstruct pl08x_driver_data *pl08x = plchan->host;\r\ndev_dbg(&pl08x->adev->dev, "reassigned physical channel %d for xfer on %s\n",\r\nch->id, plchan->name);\r\nch->serving = plchan;\r\nplchan->phychan = ch;\r\nplchan->state = PL08X_CHAN_RUNNING;\r\npl08x_start_next_txd(plchan);\r\n}\r\nstatic void pl08x_phy_free(struct pl08x_dma_chan *plchan)\r\n{\r\nstruct pl08x_driver_data *pl08x = plchan->host;\r\nstruct pl08x_dma_chan *p, *next;\r\nretry:\r\nnext = NULL;\r\nlist_for_each_entry(p, &pl08x->memcpy.channels, vc.chan.device_node)\r\nif (p->state == PL08X_CHAN_WAITING) {\r\nnext = p;\r\nbreak;\r\n}\r\nif (!next) {\r\nlist_for_each_entry(p, &pl08x->slave.channels, vc.chan.device_node)\r\nif (p->state == PL08X_CHAN_WAITING) {\r\nnext = p;\r\nbreak;\r\n}\r\n}\r\npl08x_terminate_phy_chan(pl08x, plchan->phychan);\r\nif (next) {\r\nbool success;\r\nspin_lock(&next->vc.lock);\r\nsuccess = next->state == PL08X_CHAN_WAITING;\r\nif (success)\r\npl08x_phy_reassign_start(plchan->phychan, next);\r\nspin_unlock(&next->vc.lock);\r\nif (!success)\r\ngoto retry;\r\n} else {\r\npl08x_put_phy_channel(pl08x, plchan->phychan);\r\n}\r\nplchan->phychan = NULL;\r\nplchan->state = PL08X_CHAN_IDLE;\r\n}\r\nstatic inline unsigned int pl08x_get_bytes_for_cctl(unsigned int coded)\r\n{\r\nswitch (coded) {\r\ncase PL080_WIDTH_8BIT:\r\nreturn 1;\r\ncase PL080_WIDTH_16BIT:\r\nreturn 2;\r\ncase PL080_WIDTH_32BIT:\r\nreturn 4;\r\ndefault:\r\nbreak;\r\n}\r\nBUG();\r\nreturn 0;\r\n}\r\nstatic inline u32 pl08x_cctl_bits(u32 cctl, u8 srcwidth, u8 dstwidth,\r\nsize_t tsize)\r\n{\r\nu32 retbits = cctl;\r\nretbits &= ~PL080_CONTROL_DWIDTH_MASK;\r\nretbits &= ~PL080_CONTROL_SWIDTH_MASK;\r\nretbits &= ~PL080_CONTROL_TRANSFER_SIZE_MASK;\r\nswitch (srcwidth) {\r\ncase 1:\r\nretbits |= PL080_WIDTH_8BIT << PL080_CONTROL_SWIDTH_SHIFT;\r\nbreak;\r\ncase 2:\r\nretbits |= PL080_WIDTH_16BIT << PL080_CONTROL_SWIDTH_SHIFT;\r\nbreak;\r\ncase 4:\r\nretbits |= PL080_WIDTH_32BIT << PL080_CONTROL_SWIDTH_SHIFT;\r\nbreak;\r\ndefault:\r\nBUG();\r\nbreak;\r\n}\r\nswitch (dstwidth) {\r\ncase 1:\r\nretbits |= PL080_WIDTH_8BIT << PL080_CONTROL_DWIDTH_SHIFT;\r\nbreak;\r\ncase 2:\r\nretbits |= PL080_WIDTH_16BIT << PL080_CONTROL_DWIDTH_SHIFT;\r\nbreak;\r\ncase 4:\r\nretbits |= PL080_WIDTH_32BIT << PL080_CONTROL_DWIDTH_SHIFT;\r\nbreak;\r\ndefault:\r\nBUG();\r\nbreak;\r\n}\r\ntsize &= PL080_CONTROL_TRANSFER_SIZE_MASK;\r\nretbits |= tsize << PL080_CONTROL_TRANSFER_SIZE_SHIFT;\r\nreturn retbits;\r\n}\r\nstatic void pl08x_choose_master_bus(struct pl08x_lli_build_data *bd,\r\nstruct pl08x_bus_data **mbus, struct pl08x_bus_data **sbus, u32 cctl)\r\n{\r\nif (!(cctl & PL080_CONTROL_DST_INCR)) {\r\n*mbus = &bd->dstbus;\r\n*sbus = &bd->srcbus;\r\n} else if (!(cctl & PL080_CONTROL_SRC_INCR)) {\r\n*mbus = &bd->srcbus;\r\n*sbus = &bd->dstbus;\r\n} else {\r\nif (bd->dstbus.buswidth >= bd->srcbus.buswidth) {\r\n*mbus = &bd->dstbus;\r\n*sbus = &bd->srcbus;\r\n} else {\r\n*mbus = &bd->srcbus;\r\n*sbus = &bd->dstbus;\r\n}\r\n}\r\n}\r\nstatic void pl08x_fill_lli_for_desc(struct pl08x_driver_data *pl08x,\r\nstruct pl08x_lli_build_data *bd,\r\nint num_llis, int len, u32 cctl, u32 cctl2)\r\n{\r\nu32 offset = num_llis * pl08x->lli_words;\r\nu32 *llis_va = bd->txd->llis_va + offset;\r\ndma_addr_t llis_bus = bd->txd->llis_bus;\r\nBUG_ON(num_llis >= MAX_NUM_TSFR_LLIS);\r\noffset += pl08x->lli_words;\r\nllis_va[PL080_LLI_SRC] = bd->srcbus.addr;\r\nllis_va[PL080_LLI_DST] = bd->dstbus.addr;\r\nllis_va[PL080_LLI_LLI] = (llis_bus + sizeof(u32) * offset);\r\nllis_va[PL080_LLI_LLI] |= bd->lli_bus;\r\nllis_va[PL080_LLI_CCTL] = cctl;\r\nif (pl08x->vd->pl080s)\r\nllis_va[PL080S_LLI_CCTL2] = cctl2;\r\nif (cctl & PL080_CONTROL_SRC_INCR)\r\nbd->srcbus.addr += len;\r\nif (cctl & PL080_CONTROL_DST_INCR)\r\nbd->dstbus.addr += len;\r\nBUG_ON(bd->remainder < len);\r\nbd->remainder -= len;\r\n}\r\nstatic inline void prep_byte_width_lli(struct pl08x_driver_data *pl08x,\r\nstruct pl08x_lli_build_data *bd, u32 *cctl, u32 len,\r\nint num_llis, size_t *total_bytes)\r\n{\r\n*cctl = pl08x_cctl_bits(*cctl, 1, 1, len);\r\npl08x_fill_lli_for_desc(pl08x, bd, num_llis, len, *cctl, len);\r\n(*total_bytes) += len;\r\n}\r\nstatic void pl08x_dump_lli(struct pl08x_driver_data *pl08x,\r\nconst u32 *llis_va, int num_llis)\r\n{\r\nint i;\r\nif (pl08x->vd->pl080s) {\r\ndev_vdbg(&pl08x->adev->dev,\r\n"%-3s %-9s %-10s %-10s %-10s %-10s %s\n",\r\n"lli", "", "csrc", "cdst", "clli", "cctl", "cctl2");\r\nfor (i = 0; i < num_llis; i++) {\r\ndev_vdbg(&pl08x->adev->dev,\r\n"%3d @%p: 0x%08x 0x%08x 0x%08x 0x%08x 0x%08x\n",\r\ni, llis_va, llis_va[PL080_LLI_SRC],\r\nllis_va[PL080_LLI_DST], llis_va[PL080_LLI_LLI],\r\nllis_va[PL080_LLI_CCTL],\r\nllis_va[PL080S_LLI_CCTL2]);\r\nllis_va += pl08x->lli_words;\r\n}\r\n} else {\r\ndev_vdbg(&pl08x->adev->dev,\r\n"%-3s %-9s %-10s %-10s %-10s %s\n",\r\n"lli", "", "csrc", "cdst", "clli", "cctl");\r\nfor (i = 0; i < num_llis; i++) {\r\ndev_vdbg(&pl08x->adev->dev,\r\n"%3d @%p: 0x%08x 0x%08x 0x%08x 0x%08x\n",\r\ni, llis_va, llis_va[PL080_LLI_SRC],\r\nllis_va[PL080_LLI_DST], llis_va[PL080_LLI_LLI],\r\nllis_va[PL080_LLI_CCTL]);\r\nllis_va += pl08x->lli_words;\r\n}\r\n}\r\n}\r\nstatic inline void pl08x_dump_lli(struct pl08x_driver_data *pl08x,\r\nconst u32 *llis_va, int num_llis) {}\r\nstatic int pl08x_fill_llis_for_desc(struct pl08x_driver_data *pl08x,\r\nstruct pl08x_txd *txd)\r\n{\r\nstruct pl08x_bus_data *mbus, *sbus;\r\nstruct pl08x_lli_build_data bd;\r\nint num_llis = 0;\r\nu32 cctl, early_bytes = 0;\r\nsize_t max_bytes_per_lli, total_bytes;\r\nu32 *llis_va, *last_lli;\r\nstruct pl08x_sg *dsg;\r\ntxd->llis_va = dma_pool_alloc(pl08x->pool, GFP_NOWAIT, &txd->llis_bus);\r\nif (!txd->llis_va) {\r\ndev_err(&pl08x->adev->dev, "%s no memory for llis\n", __func__);\r\nreturn 0;\r\n}\r\nbd.txd = txd;\r\nbd.lli_bus = (pl08x->lli_buses & PL08X_AHB2) ? PL080_LLI_LM_AHB2 : 0;\r\ncctl = txd->cctl;\r\nbd.srcbus.maxwidth =\r\npl08x_get_bytes_for_cctl((cctl & PL080_CONTROL_SWIDTH_MASK) >>\r\nPL080_CONTROL_SWIDTH_SHIFT);\r\nbd.dstbus.maxwidth =\r\npl08x_get_bytes_for_cctl((cctl & PL080_CONTROL_DWIDTH_MASK) >>\r\nPL080_CONTROL_DWIDTH_SHIFT);\r\nlist_for_each_entry(dsg, &txd->dsg_list, node) {\r\ntotal_bytes = 0;\r\ncctl = txd->cctl;\r\nbd.srcbus.addr = dsg->src_addr;\r\nbd.dstbus.addr = dsg->dst_addr;\r\nbd.remainder = dsg->len;\r\nbd.srcbus.buswidth = bd.srcbus.maxwidth;\r\nbd.dstbus.buswidth = bd.dstbus.maxwidth;\r\npl08x_choose_master_bus(&bd, &mbus, &sbus, cctl);\r\ndev_vdbg(&pl08x->adev->dev,\r\n"src=0x%08llx%s/%u dst=0x%08llx%s/%u len=%zu\n",\r\n(u64)bd.srcbus.addr,\r\ncctl & PL080_CONTROL_SRC_INCR ? "+" : "",\r\nbd.srcbus.buswidth,\r\n(u64)bd.dstbus.addr,\r\ncctl & PL080_CONTROL_DST_INCR ? "+" : "",\r\nbd.dstbus.buswidth,\r\nbd.remainder);\r\ndev_vdbg(&pl08x->adev->dev, "mbus=%s sbus=%s\n",\r\nmbus == &bd.srcbus ? "src" : "dst",\r\nsbus == &bd.srcbus ? "src" : "dst");\r\nif (!bd.remainder) {\r\nu32 fc = (txd->ccfg & PL080_CONFIG_FLOW_CONTROL_MASK) >>\r\nPL080_CONFIG_FLOW_CONTROL_SHIFT;\r\nif (!((fc >= PL080_FLOW_SRC2DST_DST) &&\r\n(fc <= PL080_FLOW_SRC2DST_SRC))) {\r\ndev_err(&pl08x->adev->dev, "%s sg len can't be zero",\r\n__func__);\r\nreturn 0;\r\n}\r\nif (!IS_BUS_ALIGNED(&bd.srcbus) ||\r\n!IS_BUS_ALIGNED(&bd.dstbus)) {\r\ndev_err(&pl08x->adev->dev,\r\n"%s src & dst address must be aligned to src"\r\n" & dst width if peripheral is flow controller",\r\n__func__);\r\nreturn 0;\r\n}\r\ncctl = pl08x_cctl_bits(cctl, bd.srcbus.buswidth,\r\nbd.dstbus.buswidth, 0);\r\npl08x_fill_lli_for_desc(pl08x, &bd, num_llis++,\r\n0, cctl, 0);\r\nbreak;\r\n}\r\nif (bd.remainder < mbus->buswidth)\r\nearly_bytes = bd.remainder;\r\nelse if (!IS_BUS_ALIGNED(mbus)) {\r\nearly_bytes = mbus->buswidth -\r\n(mbus->addr & (mbus->buswidth - 1));\r\nif ((bd.remainder - early_bytes) < mbus->buswidth)\r\nearly_bytes = bd.remainder;\r\n}\r\nif (early_bytes) {\r\ndev_vdbg(&pl08x->adev->dev,\r\n"%s byte width LLIs (remain 0x%08zx)\n",\r\n__func__, bd.remainder);\r\nprep_byte_width_lli(pl08x, &bd, &cctl, early_bytes,\r\nnum_llis++, &total_bytes);\r\n}\r\nif (bd.remainder) {\r\nif (!IS_BUS_ALIGNED(sbus)) {\r\ndev_dbg(&pl08x->adev->dev,\r\n"%s set down bus width to one byte\n",\r\n__func__);\r\nsbus->buswidth = 1;\r\n}\r\nmax_bytes_per_lli = bd.srcbus.buswidth *\r\npl08x->vd->max_transfer_size;\r\ndev_vdbg(&pl08x->adev->dev,\r\n"%s max bytes per lli = %zu\n",\r\n__func__, max_bytes_per_lli);\r\nwhile (bd.remainder > (mbus->buswidth - 1)) {\r\nsize_t lli_len, tsize, width;\r\nlli_len = min(bd.remainder, max_bytes_per_lli);\r\nwidth = max(mbus->buswidth, sbus->buswidth);\r\nlli_len = (lli_len / width) * width;\r\ntsize = lli_len / bd.srcbus.buswidth;\r\ndev_vdbg(&pl08x->adev->dev,\r\n"%s fill lli with single lli chunk of "\r\n"size 0x%08zx (remainder 0x%08zx)\n",\r\n__func__, lli_len, bd.remainder);\r\ncctl = pl08x_cctl_bits(cctl, bd.srcbus.buswidth,\r\nbd.dstbus.buswidth, tsize);\r\npl08x_fill_lli_for_desc(pl08x, &bd, num_llis++,\r\nlli_len, cctl, tsize);\r\ntotal_bytes += lli_len;\r\n}\r\nif (bd.remainder) {\r\ndev_vdbg(&pl08x->adev->dev,\r\n"%s align with boundary, send odd bytes (remain %zu)\n",\r\n__func__, bd.remainder);\r\nprep_byte_width_lli(pl08x, &bd, &cctl,\r\nbd.remainder, num_llis++, &total_bytes);\r\n}\r\n}\r\nif (total_bytes != dsg->len) {\r\ndev_err(&pl08x->adev->dev,\r\n"%s size of encoded lli:s don't match total txd, transferred 0x%08zx from size 0x%08zx\n",\r\n__func__, total_bytes, dsg->len);\r\nreturn 0;\r\n}\r\nif (num_llis >= MAX_NUM_TSFR_LLIS) {\r\ndev_err(&pl08x->adev->dev,\r\n"%s need to increase MAX_NUM_TSFR_LLIS from 0x%08x\n",\r\n__func__, MAX_NUM_TSFR_LLIS);\r\nreturn 0;\r\n}\r\n}\r\nllis_va = txd->llis_va;\r\nlast_lli = llis_va + (num_llis - 1) * pl08x->lli_words;\r\nif (txd->cyclic) {\r\nlast_lli[PL080_LLI_LLI] = txd->llis_bus | bd.lli_bus;\r\n} else {\r\nlast_lli[PL080_LLI_LLI] = 0;\r\nlast_lli[PL080_LLI_CCTL] |= PL080_CONTROL_TC_IRQ_EN;\r\n}\r\npl08x_dump_lli(pl08x, llis_va, num_llis);\r\nreturn num_llis;\r\n}\r\nstatic void pl08x_free_txd(struct pl08x_driver_data *pl08x,\r\nstruct pl08x_txd *txd)\r\n{\r\nstruct pl08x_sg *dsg, *_dsg;\r\nif (txd->llis_va)\r\ndma_pool_free(pl08x->pool, txd->llis_va, txd->llis_bus);\r\nlist_for_each_entry_safe(dsg, _dsg, &txd->dsg_list, node) {\r\nlist_del(&dsg->node);\r\nkfree(dsg);\r\n}\r\nkfree(txd);\r\n}\r\nstatic void pl08x_desc_free(struct virt_dma_desc *vd)\r\n{\r\nstruct pl08x_txd *txd = to_pl08x_txd(&vd->tx);\r\nstruct pl08x_dma_chan *plchan = to_pl08x_chan(vd->tx.chan);\r\ndma_descriptor_unmap(&vd->tx);\r\nif (!txd->done)\r\npl08x_release_mux(plchan);\r\npl08x_free_txd(plchan->host, txd);\r\n}\r\nstatic void pl08x_free_txd_list(struct pl08x_driver_data *pl08x,\r\nstruct pl08x_dma_chan *plchan)\r\n{\r\nLIST_HEAD(head);\r\nvchan_get_all_descriptors(&plchan->vc, &head);\r\nvchan_dma_desc_free_list(&plchan->vc, &head);\r\n}\r\nstatic void pl08x_free_chan_resources(struct dma_chan *chan)\r\n{\r\nvchan_free_chan_resources(to_virt_chan(chan));\r\n}\r\nstatic struct dma_async_tx_descriptor *pl08x_prep_dma_interrupt(\r\nstruct dma_chan *chan, unsigned long flags)\r\n{\r\nstruct dma_async_tx_descriptor *retval = NULL;\r\nreturn retval;\r\n}\r\nstatic enum dma_status pl08x_dma_tx_status(struct dma_chan *chan,\r\ndma_cookie_t cookie, struct dma_tx_state *txstate)\r\n{\r\nstruct pl08x_dma_chan *plchan = to_pl08x_chan(chan);\r\nstruct virt_dma_desc *vd;\r\nunsigned long flags;\r\nenum dma_status ret;\r\nsize_t bytes = 0;\r\nret = dma_cookie_status(chan, cookie, txstate);\r\nif (ret == DMA_COMPLETE)\r\nreturn ret;\r\nif (!txstate) {\r\nif (plchan->state == PL08X_CHAN_PAUSED)\r\nret = DMA_PAUSED;\r\nreturn ret;\r\n}\r\nspin_lock_irqsave(&plchan->vc.lock, flags);\r\nret = dma_cookie_status(chan, cookie, txstate);\r\nif (ret != DMA_COMPLETE) {\r\nvd = vchan_find_desc(&plchan->vc, cookie);\r\nif (vd) {\r\nstruct pl08x_txd *txd = to_pl08x_txd(&vd->tx);\r\nstruct pl08x_sg *dsg;\r\nlist_for_each_entry(dsg, &txd->dsg_list, node)\r\nbytes += dsg->len;\r\n} else {\r\nbytes = pl08x_getbytes_chan(plchan);\r\n}\r\n}\r\nspin_unlock_irqrestore(&plchan->vc.lock, flags);\r\ndma_set_residue(txstate, bytes);\r\nif (plchan->state == PL08X_CHAN_PAUSED && ret == DMA_IN_PROGRESS)\r\nret = DMA_PAUSED;\r\nreturn ret;\r\n}\r\nstatic u32 pl08x_select_bus(u8 src, u8 dst)\r\n{\r\nu32 cctl = 0;\r\nif (!(dst & PL08X_AHB1) || ((dst & PL08X_AHB2) && (src & PL08X_AHB1)))\r\ncctl |= PL080_CONTROL_DST_AHB2;\r\nif (!(src & PL08X_AHB1) || ((src & PL08X_AHB2) && !(dst & PL08X_AHB2)))\r\ncctl |= PL080_CONTROL_SRC_AHB2;\r\nreturn cctl;\r\n}\r\nstatic u32 pl08x_cctl(u32 cctl)\r\n{\r\ncctl &= ~(PL080_CONTROL_SRC_AHB2 | PL080_CONTROL_DST_AHB2 |\r\nPL080_CONTROL_SRC_INCR | PL080_CONTROL_DST_INCR |\r\nPL080_CONTROL_PROT_MASK);\r\nreturn cctl | PL080_CONTROL_PROT_SYS;\r\n}\r\nstatic u32 pl08x_width(enum dma_slave_buswidth width)\r\n{\r\nswitch (width) {\r\ncase DMA_SLAVE_BUSWIDTH_1_BYTE:\r\nreturn PL080_WIDTH_8BIT;\r\ncase DMA_SLAVE_BUSWIDTH_2_BYTES:\r\nreturn PL080_WIDTH_16BIT;\r\ncase DMA_SLAVE_BUSWIDTH_4_BYTES:\r\nreturn PL080_WIDTH_32BIT;\r\ndefault:\r\nreturn ~0;\r\n}\r\n}\r\nstatic u32 pl08x_burst(u32 maxburst)\r\n{\r\nint i;\r\nfor (i = 0; i < ARRAY_SIZE(burst_sizes); i++)\r\nif (burst_sizes[i].burstwords <= maxburst)\r\nbreak;\r\nreturn burst_sizes[i].reg;\r\n}\r\nstatic u32 pl08x_get_cctl(struct pl08x_dma_chan *plchan,\r\nenum dma_slave_buswidth addr_width, u32 maxburst)\r\n{\r\nu32 width, burst, cctl = 0;\r\nwidth = pl08x_width(addr_width);\r\nif (width == ~0)\r\nreturn ~0;\r\ncctl |= width << PL080_CONTROL_SWIDTH_SHIFT;\r\ncctl |= width << PL080_CONTROL_DWIDTH_SHIFT;\r\nif (plchan->cd->single)\r\nmaxburst = 1;\r\nburst = pl08x_burst(maxburst);\r\ncctl |= burst << PL080_CONTROL_SB_SIZE_SHIFT;\r\ncctl |= burst << PL080_CONTROL_DB_SIZE_SHIFT;\r\nreturn pl08x_cctl(cctl);\r\n}\r\nstatic void pl08x_issue_pending(struct dma_chan *chan)\r\n{\r\nstruct pl08x_dma_chan *plchan = to_pl08x_chan(chan);\r\nunsigned long flags;\r\nspin_lock_irqsave(&plchan->vc.lock, flags);\r\nif (vchan_issue_pending(&plchan->vc)) {\r\nif (!plchan->phychan && plchan->state != PL08X_CHAN_WAITING)\r\npl08x_phy_alloc_and_start(plchan);\r\n}\r\nspin_unlock_irqrestore(&plchan->vc.lock, flags);\r\n}\r\nstatic struct pl08x_txd *pl08x_get_txd(struct pl08x_dma_chan *plchan)\r\n{\r\nstruct pl08x_txd *txd = kzalloc(sizeof(*txd), GFP_NOWAIT);\r\nif (txd) {\r\nINIT_LIST_HEAD(&txd->dsg_list);\r\ntxd->ccfg = PL080_CONFIG_ERR_IRQ_MASK |\r\nPL080_CONFIG_TC_IRQ_MASK;\r\n}\r\nreturn txd;\r\n}\r\nstatic struct dma_async_tx_descriptor *pl08x_prep_dma_memcpy(\r\nstruct dma_chan *chan, dma_addr_t dest, dma_addr_t src,\r\nsize_t len, unsigned long flags)\r\n{\r\nstruct pl08x_dma_chan *plchan = to_pl08x_chan(chan);\r\nstruct pl08x_driver_data *pl08x = plchan->host;\r\nstruct pl08x_txd *txd;\r\nstruct pl08x_sg *dsg;\r\nint ret;\r\ntxd = pl08x_get_txd(plchan);\r\nif (!txd) {\r\ndev_err(&pl08x->adev->dev,\r\n"%s no memory for descriptor\n", __func__);\r\nreturn NULL;\r\n}\r\ndsg = kzalloc(sizeof(struct pl08x_sg), GFP_NOWAIT);\r\nif (!dsg) {\r\npl08x_free_txd(pl08x, txd);\r\nreturn NULL;\r\n}\r\nlist_add_tail(&dsg->node, &txd->dsg_list);\r\ndsg->src_addr = src;\r\ndsg->dst_addr = dest;\r\ndsg->len = len;\r\ntxd->ccfg |= PL080_FLOW_MEM2MEM << PL080_CONFIG_FLOW_CONTROL_SHIFT;\r\ntxd->cctl = pl08x->pd->memcpy_channel.cctl_memcpy &\r\n~(PL080_CONTROL_DST_AHB2 | PL080_CONTROL_SRC_AHB2);\r\ntxd->cctl |= PL080_CONTROL_SRC_INCR | PL080_CONTROL_DST_INCR;\r\nif (pl08x->vd->dualmaster)\r\ntxd->cctl |= pl08x_select_bus(pl08x->mem_buses,\r\npl08x->mem_buses);\r\nret = pl08x_fill_llis_for_desc(plchan->host, txd);\r\nif (!ret) {\r\npl08x_free_txd(pl08x, txd);\r\nreturn NULL;\r\n}\r\nreturn vchan_tx_prep(&plchan->vc, &txd->vd, flags);\r\n}\r\nstatic struct pl08x_txd *pl08x_init_txd(\r\nstruct dma_chan *chan,\r\nenum dma_transfer_direction direction,\r\ndma_addr_t *slave_addr)\r\n{\r\nstruct pl08x_dma_chan *plchan = to_pl08x_chan(chan);\r\nstruct pl08x_driver_data *pl08x = plchan->host;\r\nstruct pl08x_txd *txd;\r\nenum dma_slave_buswidth addr_width;\r\nint ret, tmp;\r\nu8 src_buses, dst_buses;\r\nu32 maxburst, cctl;\r\ntxd = pl08x_get_txd(plchan);\r\nif (!txd) {\r\ndev_err(&pl08x->adev->dev, "%s no txd\n", __func__);\r\nreturn NULL;\r\n}\r\nif (direction == DMA_MEM_TO_DEV) {\r\ncctl = PL080_CONTROL_SRC_INCR;\r\n*slave_addr = plchan->cfg.dst_addr;\r\naddr_width = plchan->cfg.dst_addr_width;\r\nmaxburst = plchan->cfg.dst_maxburst;\r\nsrc_buses = pl08x->mem_buses;\r\ndst_buses = plchan->cd->periph_buses;\r\n} else if (direction == DMA_DEV_TO_MEM) {\r\ncctl = PL080_CONTROL_DST_INCR;\r\n*slave_addr = plchan->cfg.src_addr;\r\naddr_width = plchan->cfg.src_addr_width;\r\nmaxburst = plchan->cfg.src_maxburst;\r\nsrc_buses = plchan->cd->periph_buses;\r\ndst_buses = pl08x->mem_buses;\r\n} else {\r\npl08x_free_txd(pl08x, txd);\r\ndev_err(&pl08x->adev->dev,\r\n"%s direction unsupported\n", __func__);\r\nreturn NULL;\r\n}\r\ncctl |= pl08x_get_cctl(plchan, addr_width, maxburst);\r\nif (cctl == ~0) {\r\npl08x_free_txd(pl08x, txd);\r\ndev_err(&pl08x->adev->dev,\r\n"DMA slave configuration botched?\n");\r\nreturn NULL;\r\n}\r\ntxd->cctl = cctl | pl08x_select_bus(src_buses, dst_buses);\r\nif (plchan->cfg.device_fc)\r\ntmp = (direction == DMA_MEM_TO_DEV) ? PL080_FLOW_MEM2PER_PER :\r\nPL080_FLOW_PER2MEM_PER;\r\nelse\r\ntmp = (direction == DMA_MEM_TO_DEV) ? PL080_FLOW_MEM2PER :\r\nPL080_FLOW_PER2MEM;\r\ntxd->ccfg |= tmp << PL080_CONFIG_FLOW_CONTROL_SHIFT;\r\nret = pl08x_request_mux(plchan);\r\nif (ret < 0) {\r\npl08x_free_txd(pl08x, txd);\r\ndev_dbg(&pl08x->adev->dev,\r\n"unable to mux for transfer on %s due to platform restrictions\n",\r\nplchan->name);\r\nreturn NULL;\r\n}\r\ndev_dbg(&pl08x->adev->dev, "allocated DMA request signal %d for xfer on %s\n",\r\nplchan->signal, plchan->name);\r\nif (direction == DMA_MEM_TO_DEV)\r\ntxd->ccfg |= plchan->signal << PL080_CONFIG_DST_SEL_SHIFT;\r\nelse\r\ntxd->ccfg |= plchan->signal << PL080_CONFIG_SRC_SEL_SHIFT;\r\nreturn txd;\r\n}\r\nstatic int pl08x_tx_add_sg(struct pl08x_txd *txd,\r\nenum dma_transfer_direction direction,\r\ndma_addr_t slave_addr,\r\ndma_addr_t buf_addr,\r\nunsigned int len)\r\n{\r\nstruct pl08x_sg *dsg;\r\ndsg = kzalloc(sizeof(struct pl08x_sg), GFP_NOWAIT);\r\nif (!dsg)\r\nreturn -ENOMEM;\r\nlist_add_tail(&dsg->node, &txd->dsg_list);\r\ndsg->len = len;\r\nif (direction == DMA_MEM_TO_DEV) {\r\ndsg->src_addr = buf_addr;\r\ndsg->dst_addr = slave_addr;\r\n} else {\r\ndsg->src_addr = slave_addr;\r\ndsg->dst_addr = buf_addr;\r\n}\r\nreturn 0;\r\n}\r\nstatic struct dma_async_tx_descriptor *pl08x_prep_slave_sg(\r\nstruct dma_chan *chan, struct scatterlist *sgl,\r\nunsigned int sg_len, enum dma_transfer_direction direction,\r\nunsigned long flags, void *context)\r\n{\r\nstruct pl08x_dma_chan *plchan = to_pl08x_chan(chan);\r\nstruct pl08x_driver_data *pl08x = plchan->host;\r\nstruct pl08x_txd *txd;\r\nstruct scatterlist *sg;\r\nint ret, tmp;\r\ndma_addr_t slave_addr;\r\ndev_dbg(&pl08x->adev->dev, "%s prepare transaction of %d bytes from %s\n",\r\n__func__, sg_dma_len(sgl), plchan->name);\r\ntxd = pl08x_init_txd(chan, direction, &slave_addr);\r\nif (!txd)\r\nreturn NULL;\r\nfor_each_sg(sgl, sg, sg_len, tmp) {\r\nret = pl08x_tx_add_sg(txd, direction, slave_addr,\r\nsg_dma_address(sg),\r\nsg_dma_len(sg));\r\nif (ret) {\r\npl08x_release_mux(plchan);\r\npl08x_free_txd(pl08x, txd);\r\ndev_err(&pl08x->adev->dev, "%s no mem for pl080 sg\n",\r\n__func__);\r\nreturn NULL;\r\n}\r\n}\r\nret = pl08x_fill_llis_for_desc(plchan->host, txd);\r\nif (!ret) {\r\npl08x_release_mux(plchan);\r\npl08x_free_txd(pl08x, txd);\r\nreturn NULL;\r\n}\r\nreturn vchan_tx_prep(&plchan->vc, &txd->vd, flags);\r\n}\r\nstatic struct dma_async_tx_descriptor *pl08x_prep_dma_cyclic(\r\nstruct dma_chan *chan, dma_addr_t buf_addr, size_t buf_len,\r\nsize_t period_len, enum dma_transfer_direction direction,\r\nunsigned long flags)\r\n{\r\nstruct pl08x_dma_chan *plchan = to_pl08x_chan(chan);\r\nstruct pl08x_driver_data *pl08x = plchan->host;\r\nstruct pl08x_txd *txd;\r\nint ret, tmp;\r\ndma_addr_t slave_addr;\r\ndev_dbg(&pl08x->adev->dev,\r\n"%s prepare cyclic transaction of %zd/%zd bytes %s %s\n",\r\n__func__, period_len, buf_len,\r\ndirection == DMA_MEM_TO_DEV ? "to" : "from",\r\nplchan->name);\r\ntxd = pl08x_init_txd(chan, direction, &slave_addr);\r\nif (!txd)\r\nreturn NULL;\r\ntxd->cyclic = true;\r\ntxd->cctl |= PL080_CONTROL_TC_IRQ_EN;\r\nfor (tmp = 0; tmp < buf_len; tmp += period_len) {\r\nret = pl08x_tx_add_sg(txd, direction, slave_addr,\r\nbuf_addr + tmp, period_len);\r\nif (ret) {\r\npl08x_release_mux(plchan);\r\npl08x_free_txd(pl08x, txd);\r\nreturn NULL;\r\n}\r\n}\r\nret = pl08x_fill_llis_for_desc(plchan->host, txd);\r\nif (!ret) {\r\npl08x_release_mux(plchan);\r\npl08x_free_txd(pl08x, txd);\r\nreturn NULL;\r\n}\r\nreturn vchan_tx_prep(&plchan->vc, &txd->vd, flags);\r\n}\r\nstatic int pl08x_config(struct dma_chan *chan,\r\nstruct dma_slave_config *config)\r\n{\r\nstruct pl08x_dma_chan *plchan = to_pl08x_chan(chan);\r\nstruct pl08x_driver_data *pl08x = plchan->host;\r\nif (!plchan->slave)\r\nreturn -EINVAL;\r\nif (config->src_addr_width == DMA_SLAVE_BUSWIDTH_8_BYTES ||\r\nconfig->dst_addr_width == DMA_SLAVE_BUSWIDTH_8_BYTES)\r\nreturn -EINVAL;\r\nif (config->device_fc && pl08x->vd->pl080s) {\r\ndev_err(&pl08x->adev->dev,\r\n"%s: PL080S does not support peripheral flow control\n",\r\n__func__);\r\nreturn -EINVAL;\r\n}\r\nplchan->cfg = *config;\r\nreturn 0;\r\n}\r\nstatic int pl08x_terminate_all(struct dma_chan *chan)\r\n{\r\nstruct pl08x_dma_chan *plchan = to_pl08x_chan(chan);\r\nstruct pl08x_driver_data *pl08x = plchan->host;\r\nunsigned long flags;\r\nspin_lock_irqsave(&plchan->vc.lock, flags);\r\nif (!plchan->phychan && !plchan->at) {\r\nspin_unlock_irqrestore(&plchan->vc.lock, flags);\r\nreturn 0;\r\n}\r\nplchan->state = PL08X_CHAN_IDLE;\r\nif (plchan->phychan) {\r\npl08x_phy_free(plchan);\r\n}\r\nif (plchan->at) {\r\npl08x_desc_free(&plchan->at->vd);\r\nplchan->at = NULL;\r\n}\r\npl08x_free_txd_list(pl08x, plchan);\r\nspin_unlock_irqrestore(&plchan->vc.lock, flags);\r\nreturn 0;\r\n}\r\nstatic int pl08x_pause(struct dma_chan *chan)\r\n{\r\nstruct pl08x_dma_chan *plchan = to_pl08x_chan(chan);\r\nunsigned long flags;\r\nspin_lock_irqsave(&plchan->vc.lock, flags);\r\nif (!plchan->phychan && !plchan->at) {\r\nspin_unlock_irqrestore(&plchan->vc.lock, flags);\r\nreturn 0;\r\n}\r\npl08x_pause_phy_chan(plchan->phychan);\r\nplchan->state = PL08X_CHAN_PAUSED;\r\nspin_unlock_irqrestore(&plchan->vc.lock, flags);\r\nreturn 0;\r\n}\r\nstatic int pl08x_resume(struct dma_chan *chan)\r\n{\r\nstruct pl08x_dma_chan *plchan = to_pl08x_chan(chan);\r\nunsigned long flags;\r\nspin_lock_irqsave(&plchan->vc.lock, flags);\r\nif (!plchan->phychan && !plchan->at) {\r\nspin_unlock_irqrestore(&plchan->vc.lock, flags);\r\nreturn 0;\r\n}\r\npl08x_resume_phy_chan(plchan->phychan);\r\nplchan->state = PL08X_CHAN_RUNNING;\r\nspin_unlock_irqrestore(&plchan->vc.lock, flags);\r\nreturn 0;\r\n}\r\nbool pl08x_filter_id(struct dma_chan *chan, void *chan_id)\r\n{\r\nstruct pl08x_dma_chan *plchan;\r\nchar *name = chan_id;\r\nif (chan->device->dev->driver != &pl08x_amba_driver.drv)\r\nreturn false;\r\nplchan = to_pl08x_chan(chan);\r\nif (!strcmp(plchan->name, name))\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic void pl08x_ensure_on(struct pl08x_driver_data *pl08x)\r\n{\r\nif (pl08x->vd->nomadik)\r\nreturn;\r\nwritel(PL080_CONFIG_ENABLE, pl08x->base + PL080_CONFIG);\r\n}\r\nstatic irqreturn_t pl08x_irq(int irq, void *dev)\r\n{\r\nstruct pl08x_driver_data *pl08x = dev;\r\nu32 mask = 0, err, tc, i;\r\nerr = readl(pl08x->base + PL080_ERR_STATUS);\r\nif (err) {\r\ndev_err(&pl08x->adev->dev, "%s error interrupt, register value 0x%08x\n",\r\n__func__, err);\r\nwritel(err, pl08x->base + PL080_ERR_CLEAR);\r\n}\r\ntc = readl(pl08x->base + PL080_TC_STATUS);\r\nif (tc)\r\nwritel(tc, pl08x->base + PL080_TC_CLEAR);\r\nif (!err && !tc)\r\nreturn IRQ_NONE;\r\nfor (i = 0; i < pl08x->vd->channels; i++) {\r\nif (((1 << i) & err) || ((1 << i) & tc)) {\r\nstruct pl08x_phy_chan *phychan = &pl08x->phy_chans[i];\r\nstruct pl08x_dma_chan *plchan = phychan->serving;\r\nstruct pl08x_txd *tx;\r\nif (!plchan) {\r\ndev_err(&pl08x->adev->dev,\r\n"%s Error TC interrupt on unused channel: 0x%08x\n",\r\n__func__, i);\r\ncontinue;\r\n}\r\nspin_lock(&plchan->vc.lock);\r\ntx = plchan->at;\r\nif (tx && tx->cyclic) {\r\nvchan_cyclic_callback(&tx->vd);\r\n} else if (tx) {\r\nplchan->at = NULL;\r\npl08x_release_mux(plchan);\r\ntx->done = true;\r\nvchan_cookie_complete(&tx->vd);\r\nif (vchan_next_desc(&plchan->vc))\r\npl08x_start_next_txd(plchan);\r\nelse\r\npl08x_phy_free(plchan);\r\n}\r\nspin_unlock(&plchan->vc.lock);\r\nmask |= (1 << i);\r\n}\r\n}\r\nreturn mask ? IRQ_HANDLED : IRQ_NONE;\r\n}\r\nstatic void pl08x_dma_slave_init(struct pl08x_dma_chan *chan)\r\n{\r\nchan->slave = true;\r\nchan->name = chan->cd->bus_id;\r\nchan->cfg.src_addr = chan->cd->addr;\r\nchan->cfg.dst_addr = chan->cd->addr;\r\n}\r\nstatic int pl08x_dma_init_virtual_channels(struct pl08x_driver_data *pl08x,\r\nstruct dma_device *dmadev, unsigned int channels, bool slave)\r\n{\r\nstruct pl08x_dma_chan *chan;\r\nint i;\r\nINIT_LIST_HEAD(&dmadev->channels);\r\nfor (i = 0; i < channels; i++) {\r\nchan = kzalloc(sizeof(*chan), GFP_KERNEL);\r\nif (!chan)\r\nreturn -ENOMEM;\r\nchan->host = pl08x;\r\nchan->state = PL08X_CHAN_IDLE;\r\nchan->signal = -1;\r\nif (slave) {\r\nchan->cd = &pl08x->pd->slave_channels[i];\r\nchan->signal = i;\r\npl08x_dma_slave_init(chan);\r\n} else {\r\nchan->cd = &pl08x->pd->memcpy_channel;\r\nchan->name = kasprintf(GFP_KERNEL, "memcpy%d", i);\r\nif (!chan->name) {\r\nkfree(chan);\r\nreturn -ENOMEM;\r\n}\r\n}\r\ndev_dbg(&pl08x->adev->dev,\r\n"initialize virtual channel \"%s\"\n",\r\nchan->name);\r\nchan->vc.desc_free = pl08x_desc_free;\r\nvchan_init(&chan->vc, dmadev);\r\n}\r\ndev_info(&pl08x->adev->dev, "initialized %d virtual %s channels\n",\r\ni, slave ? "slave" : "memcpy");\r\nreturn i;\r\n}\r\nstatic void pl08x_free_virtual_channels(struct dma_device *dmadev)\r\n{\r\nstruct pl08x_dma_chan *chan = NULL;\r\nstruct pl08x_dma_chan *next;\r\nlist_for_each_entry_safe(chan,\r\nnext, &dmadev->channels, vc.chan.device_node) {\r\nlist_del(&chan->vc.chan.device_node);\r\nkfree(chan);\r\n}\r\n}\r\nstatic const char *pl08x_state_str(enum pl08x_dma_chan_state state)\r\n{\r\nswitch (state) {\r\ncase PL08X_CHAN_IDLE:\r\nreturn "idle";\r\ncase PL08X_CHAN_RUNNING:\r\nreturn "running";\r\ncase PL08X_CHAN_PAUSED:\r\nreturn "paused";\r\ncase PL08X_CHAN_WAITING:\r\nreturn "waiting";\r\ndefault:\r\nbreak;\r\n}\r\nreturn "UNKNOWN STATE";\r\n}\r\nstatic int pl08x_debugfs_show(struct seq_file *s, void *data)\r\n{\r\nstruct pl08x_driver_data *pl08x = s->private;\r\nstruct pl08x_dma_chan *chan;\r\nstruct pl08x_phy_chan *ch;\r\nunsigned long flags;\r\nint i;\r\nseq_printf(s, "PL08x physical channels:\n");\r\nseq_printf(s, "CHANNEL:\tUSER:\n");\r\nseq_printf(s, "--------\t-----\n");\r\nfor (i = 0; i < pl08x->vd->channels; i++) {\r\nstruct pl08x_dma_chan *virt_chan;\r\nch = &pl08x->phy_chans[i];\r\nspin_lock_irqsave(&ch->lock, flags);\r\nvirt_chan = ch->serving;\r\nseq_printf(s, "%d\t\t%s%s\n",\r\nch->id,\r\nvirt_chan ? virt_chan->name : "(none)",\r\nch->locked ? " LOCKED" : "");\r\nspin_unlock_irqrestore(&ch->lock, flags);\r\n}\r\nseq_printf(s, "\nPL08x virtual memcpy channels:\n");\r\nseq_printf(s, "CHANNEL:\tSTATE:\n");\r\nseq_printf(s, "--------\t------\n");\r\nlist_for_each_entry(chan, &pl08x->memcpy.channels, vc.chan.device_node) {\r\nseq_printf(s, "%s\t\t%s\n", chan->name,\r\npl08x_state_str(chan->state));\r\n}\r\nseq_printf(s, "\nPL08x virtual slave channels:\n");\r\nseq_printf(s, "CHANNEL:\tSTATE:\n");\r\nseq_printf(s, "--------\t------\n");\r\nlist_for_each_entry(chan, &pl08x->slave.channels, vc.chan.device_node) {\r\nseq_printf(s, "%s\t\t%s\n", chan->name,\r\npl08x_state_str(chan->state));\r\n}\r\nreturn 0;\r\n}\r\nstatic int pl08x_debugfs_open(struct inode *inode, struct file *file)\r\n{\r\nreturn single_open(file, pl08x_debugfs_show, inode->i_private);\r\n}\r\nstatic void init_pl08x_debugfs(struct pl08x_driver_data *pl08x)\r\n{\r\n(void) debugfs_create_file(dev_name(&pl08x->adev->dev),\r\nS_IFREG | S_IRUGO, NULL, pl08x,\r\n&pl08x_debugfs_operations);\r\n}\r\nstatic inline void init_pl08x_debugfs(struct pl08x_driver_data *pl08x)\r\n{\r\n}\r\nstatic struct dma_chan *pl08x_find_chan_id(struct pl08x_driver_data *pl08x,\r\nu32 id)\r\n{\r\nstruct pl08x_dma_chan *chan;\r\nlist_for_each_entry(chan, &pl08x->slave.channels, vc.chan.device_node) {\r\nif (chan->signal == id)\r\nreturn &chan->vc.chan;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct dma_chan *pl08x_of_xlate(struct of_phandle_args *dma_spec,\r\nstruct of_dma *ofdma)\r\n{\r\nstruct pl08x_driver_data *pl08x = ofdma->of_dma_data;\r\nstruct dma_chan *dma_chan;\r\nstruct pl08x_dma_chan *plchan;\r\nif (!pl08x)\r\nreturn NULL;\r\nif (dma_spec->args_count != 2) {\r\ndev_err(&pl08x->adev->dev,\r\n"DMA channel translation requires two cells\n");\r\nreturn NULL;\r\n}\r\ndma_chan = pl08x_find_chan_id(pl08x, dma_spec->args[0]);\r\nif (!dma_chan) {\r\ndev_err(&pl08x->adev->dev,\r\n"DMA slave channel not found\n");\r\nreturn NULL;\r\n}\r\nplchan = to_pl08x_chan(dma_chan);\r\ndev_dbg(&pl08x->adev->dev,\r\n"translated channel for signal %d\n",\r\ndma_spec->args[0]);\r\nplchan->cd->periph_buses = dma_spec->args[1];\r\nreturn dma_get_slave_channel(dma_chan);\r\n}\r\nstatic int pl08x_of_probe(struct amba_device *adev,\r\nstruct pl08x_driver_data *pl08x,\r\nstruct device_node *np)\r\n{\r\nstruct pl08x_platform_data *pd;\r\nstruct pl08x_channel_data *chanp = NULL;\r\nu32 cctl_memcpy = 0;\r\nu32 val;\r\nint ret;\r\nint i;\r\npd = devm_kzalloc(&adev->dev, sizeof(*pd), GFP_KERNEL);\r\nif (!pd)\r\nreturn -ENOMEM;\r\nif (of_property_read_bool(np, "lli-bus-interface-ahb1"))\r\npd->lli_buses |= PL08X_AHB1;\r\nif (of_property_read_bool(np, "lli-bus-interface-ahb2"))\r\npd->lli_buses |= PL08X_AHB2;\r\nif (!pd->lli_buses) {\r\ndev_info(&adev->dev, "no bus masters for LLIs stated, assume all\n");\r\npd->lli_buses |= PL08X_AHB1 | PL08X_AHB2;\r\n}\r\nif (of_property_read_bool(np, "mem-bus-interface-ahb1"))\r\npd->mem_buses |= PL08X_AHB1;\r\nif (of_property_read_bool(np, "mem-bus-interface-ahb2"))\r\npd->mem_buses |= PL08X_AHB2;\r\nif (!pd->mem_buses) {\r\ndev_info(&adev->dev, "no bus masters for memory stated, assume all\n");\r\npd->mem_buses |= PL08X_AHB1 | PL08X_AHB2;\r\n}\r\nret = of_property_read_u32(np, "memcpy-burst-size", &val);\r\nif (ret) {\r\ndev_info(&adev->dev, "no memcpy burst size specified, using 1 byte\n");\r\nval = 1;\r\n}\r\nswitch (val) {\r\ndefault:\r\ndev_err(&adev->dev, "illegal burst size for memcpy, set to 1\n");\r\ncase 1:\r\ncctl_memcpy |= PL080_BSIZE_1 << PL080_CONTROL_SB_SIZE_SHIFT |\r\nPL080_BSIZE_1 << PL080_CONTROL_DB_SIZE_SHIFT;\r\nbreak;\r\ncase 4:\r\ncctl_memcpy |= PL080_BSIZE_4 << PL080_CONTROL_SB_SIZE_SHIFT |\r\nPL080_BSIZE_4 << PL080_CONTROL_DB_SIZE_SHIFT;\r\nbreak;\r\ncase 8:\r\ncctl_memcpy |= PL080_BSIZE_8 << PL080_CONTROL_SB_SIZE_SHIFT |\r\nPL080_BSIZE_8 << PL080_CONTROL_DB_SIZE_SHIFT;\r\nbreak;\r\ncase 16:\r\ncctl_memcpy |= PL080_BSIZE_16 << PL080_CONTROL_SB_SIZE_SHIFT |\r\nPL080_BSIZE_16 << PL080_CONTROL_DB_SIZE_SHIFT;\r\nbreak;\r\ncase 32:\r\ncctl_memcpy |= PL080_BSIZE_32 << PL080_CONTROL_SB_SIZE_SHIFT |\r\nPL080_BSIZE_32 << PL080_CONTROL_DB_SIZE_SHIFT;\r\nbreak;\r\ncase 64:\r\ncctl_memcpy |= PL080_BSIZE_64 << PL080_CONTROL_SB_SIZE_SHIFT |\r\nPL080_BSIZE_64 << PL080_CONTROL_DB_SIZE_SHIFT;\r\nbreak;\r\ncase 128:\r\ncctl_memcpy |= PL080_BSIZE_128 << PL080_CONTROL_SB_SIZE_SHIFT |\r\nPL080_BSIZE_128 << PL080_CONTROL_DB_SIZE_SHIFT;\r\nbreak;\r\ncase 256:\r\ncctl_memcpy |= PL080_BSIZE_256 << PL080_CONTROL_SB_SIZE_SHIFT |\r\nPL080_BSIZE_256 << PL080_CONTROL_DB_SIZE_SHIFT;\r\nbreak;\r\n}\r\nret = of_property_read_u32(np, "memcpy-bus-width", &val);\r\nif (ret) {\r\ndev_info(&adev->dev, "no memcpy bus width specified, using 8 bits\n");\r\nval = 8;\r\n}\r\nswitch (val) {\r\ndefault:\r\ndev_err(&adev->dev, "illegal bus width for memcpy, set to 8 bits\n");\r\ncase 8:\r\ncctl_memcpy |= PL080_WIDTH_8BIT << PL080_CONTROL_SWIDTH_SHIFT |\r\nPL080_WIDTH_8BIT << PL080_CONTROL_DWIDTH_SHIFT;\r\nbreak;\r\ncase 16:\r\ncctl_memcpy |= PL080_WIDTH_16BIT << PL080_CONTROL_SWIDTH_SHIFT |\r\nPL080_WIDTH_16BIT << PL080_CONTROL_DWIDTH_SHIFT;\r\nbreak;\r\ncase 32:\r\ncctl_memcpy |= PL080_WIDTH_32BIT << PL080_CONTROL_SWIDTH_SHIFT |\r\nPL080_WIDTH_32BIT << PL080_CONTROL_DWIDTH_SHIFT;\r\nbreak;\r\n}\r\ncctl_memcpy |= PL080_CONTROL_PROT_SYS;\r\npd->memcpy_channel.bus_id = "memcpy";\r\npd->memcpy_channel.cctl_memcpy = cctl_memcpy;\r\npd->memcpy_channel.periph_buses = pd->mem_buses;\r\nchanp = devm_kcalloc(&adev->dev,\r\npl08x->vd->signals,\r\nsizeof(struct pl08x_channel_data),\r\nGFP_KERNEL);\r\nif (!chanp)\r\nreturn -ENOMEM;\r\npd->slave_channels = chanp;\r\nfor (i = 0; i < pl08x->vd->signals; i++) {\r\nchanp->bus_id = kasprintf(GFP_KERNEL, "slave%d", i);\r\nchanp++;\r\n}\r\npd->num_slave_channels = pl08x->vd->signals;\r\npl08x->pd = pd;\r\nreturn of_dma_controller_register(adev->dev.of_node, pl08x_of_xlate,\r\npl08x);\r\n}\r\nstatic inline int pl08x_of_probe(struct amba_device *adev,\r\nstruct pl08x_driver_data *pl08x,\r\nstruct device_node *np)\r\n{\r\nreturn -EINVAL;\r\n}\r\nstatic int pl08x_probe(struct amba_device *adev, const struct amba_id *id)\r\n{\r\nstruct pl08x_driver_data *pl08x;\r\nconst struct vendor_data *vd = id->data;\r\nstruct device_node *np = adev->dev.of_node;\r\nu32 tsfr_size;\r\nint ret = 0;\r\nint i;\r\nret = amba_request_regions(adev, NULL);\r\nif (ret)\r\nreturn ret;\r\nret = dma_set_mask_and_coherent(&adev->dev, DMA_BIT_MASK(32));\r\nif (ret)\r\ngoto out_no_pl08x;\r\npl08x = kzalloc(sizeof(*pl08x), GFP_KERNEL);\r\nif (!pl08x) {\r\nret = -ENOMEM;\r\ngoto out_no_pl08x;\r\n}\r\npl08x->adev = adev;\r\npl08x->vd = vd;\r\ndma_cap_set(DMA_MEMCPY, pl08x->memcpy.cap_mask);\r\npl08x->memcpy.dev = &adev->dev;\r\npl08x->memcpy.device_free_chan_resources = pl08x_free_chan_resources;\r\npl08x->memcpy.device_prep_dma_memcpy = pl08x_prep_dma_memcpy;\r\npl08x->memcpy.device_prep_dma_interrupt = pl08x_prep_dma_interrupt;\r\npl08x->memcpy.device_tx_status = pl08x_dma_tx_status;\r\npl08x->memcpy.device_issue_pending = pl08x_issue_pending;\r\npl08x->memcpy.device_config = pl08x_config;\r\npl08x->memcpy.device_pause = pl08x_pause;\r\npl08x->memcpy.device_resume = pl08x_resume;\r\npl08x->memcpy.device_terminate_all = pl08x_terminate_all;\r\npl08x->memcpy.src_addr_widths = PL80X_DMA_BUSWIDTHS;\r\npl08x->memcpy.dst_addr_widths = PL80X_DMA_BUSWIDTHS;\r\npl08x->memcpy.directions = BIT(DMA_MEM_TO_MEM);\r\npl08x->memcpy.residue_granularity = DMA_RESIDUE_GRANULARITY_SEGMENT;\r\ndma_cap_set(DMA_SLAVE, pl08x->slave.cap_mask);\r\ndma_cap_set(DMA_CYCLIC, pl08x->slave.cap_mask);\r\npl08x->slave.dev = &adev->dev;\r\npl08x->slave.device_free_chan_resources = pl08x_free_chan_resources;\r\npl08x->slave.device_prep_dma_interrupt = pl08x_prep_dma_interrupt;\r\npl08x->slave.device_tx_status = pl08x_dma_tx_status;\r\npl08x->slave.device_issue_pending = pl08x_issue_pending;\r\npl08x->slave.device_prep_slave_sg = pl08x_prep_slave_sg;\r\npl08x->slave.device_prep_dma_cyclic = pl08x_prep_dma_cyclic;\r\npl08x->slave.device_config = pl08x_config;\r\npl08x->slave.device_pause = pl08x_pause;\r\npl08x->slave.device_resume = pl08x_resume;\r\npl08x->slave.device_terminate_all = pl08x_terminate_all;\r\npl08x->slave.src_addr_widths = PL80X_DMA_BUSWIDTHS;\r\npl08x->slave.dst_addr_widths = PL80X_DMA_BUSWIDTHS;\r\npl08x->slave.directions = BIT(DMA_DEV_TO_MEM) | BIT(DMA_MEM_TO_DEV);\r\npl08x->slave.residue_granularity = DMA_RESIDUE_GRANULARITY_SEGMENT;\r\npl08x->pd = dev_get_platdata(&adev->dev);\r\nif (!pl08x->pd) {\r\nif (np) {\r\nret = pl08x_of_probe(adev, pl08x, np);\r\nif (ret)\r\ngoto out_no_platdata;\r\n} else {\r\ndev_err(&adev->dev, "no platform data supplied\n");\r\nret = -EINVAL;\r\ngoto out_no_platdata;\r\n}\r\n}\r\npl08x->lli_buses = PL08X_AHB1;\r\npl08x->mem_buses = PL08X_AHB1;\r\nif (pl08x->vd->dualmaster) {\r\npl08x->lli_buses = pl08x->pd->lli_buses;\r\npl08x->mem_buses = pl08x->pd->mem_buses;\r\n}\r\nif (vd->pl080s)\r\npl08x->lli_words = PL080S_LLI_WORDS;\r\nelse\r\npl08x->lli_words = PL080_LLI_WORDS;\r\ntsfr_size = MAX_NUM_TSFR_LLIS * pl08x->lli_words * sizeof(u32);\r\npl08x->pool = dma_pool_create(DRIVER_NAME, &pl08x->adev->dev,\r\ntsfr_size, PL08X_ALIGN, 0);\r\nif (!pl08x->pool) {\r\nret = -ENOMEM;\r\ngoto out_no_lli_pool;\r\n}\r\npl08x->base = ioremap(adev->res.start, resource_size(&adev->res));\r\nif (!pl08x->base) {\r\nret = -ENOMEM;\r\ngoto out_no_ioremap;\r\n}\r\npl08x_ensure_on(pl08x);\r\nwritel(0x000000FF, pl08x->base + PL080_ERR_CLEAR);\r\nwritel(0x000000FF, pl08x->base + PL080_TC_CLEAR);\r\nret = request_irq(adev->irq[0], pl08x_irq, 0, DRIVER_NAME, pl08x);\r\nif (ret) {\r\ndev_err(&adev->dev, "%s failed to request interrupt %d\n",\r\n__func__, adev->irq[0]);\r\ngoto out_no_irq;\r\n}\r\npl08x->phy_chans = kzalloc((vd->channels * sizeof(*pl08x->phy_chans)),\r\nGFP_KERNEL);\r\nif (!pl08x->phy_chans) {\r\nret = -ENOMEM;\r\ngoto out_no_phychans;\r\n}\r\nfor (i = 0; i < vd->channels; i++) {\r\nstruct pl08x_phy_chan *ch = &pl08x->phy_chans[i];\r\nch->id = i;\r\nch->base = pl08x->base + PL080_Cx_BASE(i);\r\nch->reg_config = ch->base + vd->config_offset;\r\nspin_lock_init(&ch->lock);\r\nif (vd->nomadik) {\r\nu32 val;\r\nval = readl(ch->reg_config);\r\nif (val & (PL080N_CONFIG_ITPROT | PL080N_CONFIG_SECPROT)) {\r\ndev_info(&adev->dev, "physical channel %d reserved for secure access only\n", i);\r\nch->locked = true;\r\n}\r\n}\r\ndev_dbg(&adev->dev, "physical channel %d is %s\n",\r\ni, pl08x_phy_channel_busy(ch) ? "BUSY" : "FREE");\r\n}\r\nret = pl08x_dma_init_virtual_channels(pl08x, &pl08x->memcpy,\r\npl08x->vd->channels, false);\r\nif (ret <= 0) {\r\ndev_warn(&pl08x->adev->dev,\r\n"%s failed to enumerate memcpy channels - %d\n",\r\n__func__, ret);\r\ngoto out_no_memcpy;\r\n}\r\nret = pl08x_dma_init_virtual_channels(pl08x, &pl08x->slave,\r\npl08x->pd->num_slave_channels, true);\r\nif (ret < 0) {\r\ndev_warn(&pl08x->adev->dev,\r\n"%s failed to enumerate slave channels - %d\n",\r\n__func__, ret);\r\ngoto out_no_slave;\r\n}\r\nret = dma_async_device_register(&pl08x->memcpy);\r\nif (ret) {\r\ndev_warn(&pl08x->adev->dev,\r\n"%s failed to register memcpy as an async device - %d\n",\r\n__func__, ret);\r\ngoto out_no_memcpy_reg;\r\n}\r\nret = dma_async_device_register(&pl08x->slave);\r\nif (ret) {\r\ndev_warn(&pl08x->adev->dev,\r\n"%s failed to register slave as an async device - %d\n",\r\n__func__, ret);\r\ngoto out_no_slave_reg;\r\n}\r\namba_set_drvdata(adev, pl08x);\r\ninit_pl08x_debugfs(pl08x);\r\ndev_info(&pl08x->adev->dev, "DMA: PL%03x%s rev%u at 0x%08llx irq %d\n",\r\namba_part(adev), pl08x->vd->pl080s ? "s" : "", amba_rev(adev),\r\n(unsigned long long)adev->res.start, adev->irq[0]);\r\nreturn 0;\r\nout_no_slave_reg:\r\ndma_async_device_unregister(&pl08x->memcpy);\r\nout_no_memcpy_reg:\r\npl08x_free_virtual_channels(&pl08x->slave);\r\nout_no_slave:\r\npl08x_free_virtual_channels(&pl08x->memcpy);\r\nout_no_memcpy:\r\nkfree(pl08x->phy_chans);\r\nout_no_phychans:\r\nfree_irq(adev->irq[0], pl08x);\r\nout_no_irq:\r\niounmap(pl08x->base);\r\nout_no_ioremap:\r\ndma_pool_destroy(pl08x->pool);\r\nout_no_lli_pool:\r\nout_no_platdata:\r\nkfree(pl08x);\r\nout_no_pl08x:\r\namba_release_regions(adev);\r\nreturn ret;\r\n}\r\nstatic int __init pl08x_init(void)\r\n{\r\nint retval;\r\nretval = amba_driver_register(&pl08x_amba_driver);\r\nif (retval)\r\nprintk(KERN_WARNING DRIVER_NAME\r\n"failed to register as an AMBA device (%d)\n",\r\nretval);\r\nreturn retval;\r\n}
