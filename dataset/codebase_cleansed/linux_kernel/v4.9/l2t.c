static inline unsigned int vlan_prio(const struct l2t_entry *e)\r\n{\r\nreturn e->vlan >> VLAN_PRIO_SHIFT;\r\n}\r\nstatic inline void l2t_hold(struct l2t_data *d, struct l2t_entry *e)\r\n{\r\nif (atomic_add_return(1, &e->refcnt) == 1)\r\natomic_dec(&d->nfree);\r\n}\r\nstatic inline unsigned int arp_hash(struct l2t_data *d, const u32 *key,\r\nint ifindex)\r\n{\r\nunsigned int l2t_size_half = d->l2t_size / 2;\r\nreturn jhash_2words(*key, ifindex, 0) % l2t_size_half;\r\n}\r\nstatic inline unsigned int ipv6_hash(struct l2t_data *d, const u32 *key,\r\nint ifindex)\r\n{\r\nunsigned int l2t_size_half = d->l2t_size / 2;\r\nu32 xor = key[0] ^ key[1] ^ key[2] ^ key[3];\r\nreturn (l2t_size_half +\r\n(jhash_2words(xor, ifindex, 0) % l2t_size_half));\r\n}\r\nstatic unsigned int addr_hash(struct l2t_data *d, const u32 *addr,\r\nint addr_len, int ifindex)\r\n{\r\nreturn addr_len == 4 ? arp_hash(d, addr, ifindex) :\r\nipv6_hash(d, addr, ifindex);\r\n}\r\nstatic int addreq(const struct l2t_entry *e, const u32 *addr)\r\n{\r\nif (e->v6)\r\nreturn (e->addr[0] ^ addr[0]) | (e->addr[1] ^ addr[1]) |\r\n(e->addr[2] ^ addr[2]) | (e->addr[3] ^ addr[3]);\r\nreturn e->addr[0] ^ addr[0];\r\n}\r\nstatic void neigh_replace(struct l2t_entry *e, struct neighbour *n)\r\n{\r\nneigh_hold(n);\r\nif (e->neigh)\r\nneigh_release(e->neigh);\r\ne->neigh = n;\r\n}\r\nstatic int write_l2e(struct adapter *adap, struct l2t_entry *e, int sync)\r\n{\r\nstruct l2t_data *d = adap->l2t;\r\nunsigned int l2t_idx = e->idx + d->l2t_start;\r\nstruct sk_buff *skb;\r\nstruct cpl_l2t_write_req *req;\r\nskb = alloc_skb(sizeof(*req), GFP_ATOMIC);\r\nif (!skb)\r\nreturn -ENOMEM;\r\nreq = (struct cpl_l2t_write_req *)__skb_put(skb, sizeof(*req));\r\nINIT_TP_WR(req, 0);\r\nOPCODE_TID(req) = htonl(MK_OPCODE_TID(CPL_L2T_WRITE_REQ,\r\nl2t_idx | (sync ? SYNC_WR_F : 0) |\r\nTID_QID_V(adap->sge.fw_evtq.abs_id)));\r\nreq->params = htons(L2T_W_PORT_V(e->lport) | L2T_W_NOREPLY_V(!sync));\r\nreq->l2t_idx = htons(l2t_idx);\r\nreq->vlan = htons(e->vlan);\r\nif (e->neigh && !(e->neigh->dev->flags & IFF_LOOPBACK))\r\nmemcpy(e->dmac, e->neigh->ha, sizeof(e->dmac));\r\nmemcpy(req->dst_mac, e->dmac, sizeof(req->dst_mac));\r\nt4_mgmt_tx(adap, skb);\r\nif (sync && e->state != L2T_STATE_SWITCHING)\r\ne->state = L2T_STATE_SYNC_WRITE;\r\nreturn 0;\r\n}\r\nstatic void send_pending(struct adapter *adap, struct l2t_entry *e)\r\n{\r\nstruct sk_buff *skb;\r\nwhile ((skb = __skb_dequeue(&e->arpq)) != NULL)\r\nt4_ofld_send(adap, skb);\r\n}\r\nvoid do_l2t_write_rpl(struct adapter *adap, const struct cpl_l2t_write_rpl *rpl)\r\n{\r\nstruct l2t_data *d = adap->l2t;\r\nunsigned int tid = GET_TID(rpl);\r\nunsigned int l2t_idx = tid % L2T_SIZE;\r\nif (unlikely(rpl->status != CPL_ERR_NONE)) {\r\ndev_err(adap->pdev_dev,\r\n"Unexpected L2T_WRITE_RPL status %u for entry %u\n",\r\nrpl->status, l2t_idx);\r\nreturn;\r\n}\r\nif (tid & SYNC_WR_F) {\r\nstruct l2t_entry *e = &d->l2tab[l2t_idx - d->l2t_start];\r\nspin_lock(&e->lock);\r\nif (e->state != L2T_STATE_SWITCHING) {\r\nsend_pending(adap, e);\r\ne->state = (e->neigh->nud_state & NUD_STALE) ?\r\nL2T_STATE_STALE : L2T_STATE_VALID;\r\n}\r\nspin_unlock(&e->lock);\r\n}\r\n}\r\nstatic inline void arpq_enqueue(struct l2t_entry *e, struct sk_buff *skb)\r\n{\r\n__skb_queue_tail(&e->arpq, skb);\r\n}\r\nint cxgb4_l2t_send(struct net_device *dev, struct sk_buff *skb,\r\nstruct l2t_entry *e)\r\n{\r\nstruct adapter *adap = netdev2adap(dev);\r\nagain:\r\nswitch (e->state) {\r\ncase L2T_STATE_STALE:\r\nneigh_event_send(e->neigh, NULL);\r\nspin_lock_bh(&e->lock);\r\nif (e->state == L2T_STATE_STALE)\r\ne->state = L2T_STATE_VALID;\r\nspin_unlock_bh(&e->lock);\r\ncase L2T_STATE_VALID:\r\nreturn t4_ofld_send(adap, skb);\r\ncase L2T_STATE_RESOLVING:\r\ncase L2T_STATE_SYNC_WRITE:\r\nspin_lock_bh(&e->lock);\r\nif (e->state != L2T_STATE_SYNC_WRITE &&\r\ne->state != L2T_STATE_RESOLVING) {\r\nspin_unlock_bh(&e->lock);\r\ngoto again;\r\n}\r\narpq_enqueue(e, skb);\r\nspin_unlock_bh(&e->lock);\r\nif (e->state == L2T_STATE_RESOLVING &&\r\n!neigh_event_send(e->neigh, NULL)) {\r\nspin_lock_bh(&e->lock);\r\nif (e->state == L2T_STATE_RESOLVING &&\r\n!skb_queue_empty(&e->arpq))\r\nwrite_l2e(adap, e, 1);\r\nspin_unlock_bh(&e->lock);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic struct l2t_entry *alloc_l2e(struct l2t_data *d)\r\n{\r\nstruct l2t_entry *end, *e, **p;\r\nif (!atomic_read(&d->nfree))\r\nreturn NULL;\r\nfor (e = d->rover, end = &d->l2tab[d->l2t_size]; e != end; ++e)\r\nif (atomic_read(&e->refcnt) == 0)\r\ngoto found;\r\nfor (e = d->l2tab; atomic_read(&e->refcnt); ++e)\r\n;\r\nfound:\r\nd->rover = e + 1;\r\natomic_dec(&d->nfree);\r\nif (e->state < L2T_STATE_SWITCHING)\r\nfor (p = &d->l2tab[e->hash].first; *p; p = &(*p)->next)\r\nif (*p == e) {\r\n*p = e->next;\r\ne->next = NULL;\r\nbreak;\r\n}\r\ne->state = L2T_STATE_UNUSED;\r\nreturn e;\r\n}\r\nstatic struct l2t_entry *find_or_alloc_l2e(struct l2t_data *d, u16 vlan,\r\nu8 port, u8 *dmac)\r\n{\r\nstruct l2t_entry *end, *e, **p;\r\nstruct l2t_entry *first_free = NULL;\r\nfor (e = &d->l2tab[0], end = &d->l2tab[d->l2t_size]; e != end; ++e) {\r\nif (atomic_read(&e->refcnt) == 0) {\r\nif (!first_free)\r\nfirst_free = e;\r\n} else {\r\nif (e->state == L2T_STATE_SWITCHING) {\r\nif (ether_addr_equal(e->dmac, dmac) &&\r\n(e->vlan == vlan) && (e->lport == port))\r\ngoto exists;\r\n}\r\n}\r\n}\r\nif (first_free) {\r\ne = first_free;\r\ngoto found;\r\n}\r\nreturn NULL;\r\nfound:\r\nif (e->state < L2T_STATE_SWITCHING)\r\nfor (p = &d->l2tab[e->hash].first; *p; p = &(*p)->next)\r\nif (*p == e) {\r\n*p = e->next;\r\ne->next = NULL;\r\nbreak;\r\n}\r\ne->state = L2T_STATE_UNUSED;\r\nexists:\r\nreturn e;\r\n}\r\nstatic void _t4_l2e_free(struct l2t_entry *e)\r\n{\r\nstruct l2t_data *d;\r\nstruct sk_buff *skb;\r\nif (atomic_read(&e->refcnt) == 0) {\r\nif (e->neigh) {\r\nneigh_release(e->neigh);\r\ne->neigh = NULL;\r\n}\r\nwhile ((skb = __skb_dequeue(&e->arpq)) != NULL)\r\nkfree_skb(skb);\r\n}\r\nd = container_of(e, struct l2t_data, l2tab[e->idx]);\r\natomic_inc(&d->nfree);\r\n}\r\nstatic void t4_l2e_free(struct l2t_entry *e)\r\n{\r\nstruct l2t_data *d;\r\nstruct sk_buff *skb;\r\nspin_lock_bh(&e->lock);\r\nif (atomic_read(&e->refcnt) == 0) {\r\nif (e->neigh) {\r\nneigh_release(e->neigh);\r\ne->neigh = NULL;\r\n}\r\nwhile ((skb = __skb_dequeue(&e->arpq)) != NULL)\r\nkfree_skb(skb);\r\n}\r\nspin_unlock_bh(&e->lock);\r\nd = container_of(e, struct l2t_data, l2tab[e->idx]);\r\natomic_inc(&d->nfree);\r\n}\r\nvoid cxgb4_l2t_release(struct l2t_entry *e)\r\n{\r\nif (atomic_dec_and_test(&e->refcnt))\r\nt4_l2e_free(e);\r\n}\r\nstatic void reuse_entry(struct l2t_entry *e, struct neighbour *neigh)\r\n{\r\nunsigned int nud_state;\r\nspin_lock(&e->lock);\r\nif (neigh != e->neigh)\r\nneigh_replace(e, neigh);\r\nnud_state = neigh->nud_state;\r\nif (memcmp(e->dmac, neigh->ha, sizeof(e->dmac)) ||\r\n!(nud_state & NUD_VALID))\r\ne->state = L2T_STATE_RESOLVING;\r\nelse if (nud_state & NUD_CONNECTED)\r\ne->state = L2T_STATE_VALID;\r\nelse\r\ne->state = L2T_STATE_STALE;\r\nspin_unlock(&e->lock);\r\n}\r\nstruct l2t_entry *cxgb4_l2t_get(struct l2t_data *d, struct neighbour *neigh,\r\nconst struct net_device *physdev,\r\nunsigned int priority)\r\n{\r\nu8 lport;\r\nu16 vlan;\r\nstruct l2t_entry *e;\r\nint addr_len = neigh->tbl->key_len;\r\nu32 *addr = (u32 *)neigh->primary_key;\r\nint ifidx = neigh->dev->ifindex;\r\nint hash = addr_hash(d, addr, addr_len, ifidx);\r\nif (neigh->dev->flags & IFF_LOOPBACK)\r\nlport = netdev2pinfo(physdev)->tx_chan + 4;\r\nelse\r\nlport = netdev2pinfo(physdev)->lport;\r\nif (neigh->dev->priv_flags & IFF_802_1Q_VLAN)\r\nvlan = vlan_dev_vlan_id(neigh->dev);\r\nelse\r\nvlan = VLAN_NONE;\r\nwrite_lock_bh(&d->lock);\r\nfor (e = d->l2tab[hash].first; e; e = e->next)\r\nif (!addreq(e, addr) && e->ifindex == ifidx &&\r\ne->vlan == vlan && e->lport == lport) {\r\nl2t_hold(d, e);\r\nif (atomic_read(&e->refcnt) == 1)\r\nreuse_entry(e, neigh);\r\ngoto done;\r\n}\r\ne = alloc_l2e(d);\r\nif (e) {\r\nspin_lock(&e->lock);\r\ne->state = L2T_STATE_RESOLVING;\r\nif (neigh->dev->flags & IFF_LOOPBACK)\r\nmemcpy(e->dmac, physdev->dev_addr, sizeof(e->dmac));\r\nmemcpy(e->addr, addr, addr_len);\r\ne->ifindex = ifidx;\r\ne->hash = hash;\r\ne->lport = lport;\r\ne->v6 = addr_len == 16;\r\natomic_set(&e->refcnt, 1);\r\nneigh_replace(e, neigh);\r\ne->vlan = vlan;\r\ne->next = d->l2tab[hash].first;\r\nd->l2tab[hash].first = e;\r\nspin_unlock(&e->lock);\r\n}\r\ndone:\r\nwrite_unlock_bh(&d->lock);\r\nreturn e;\r\n}\r\nu64 cxgb4_select_ntuple(struct net_device *dev,\r\nconst struct l2t_entry *l2t)\r\n{\r\nstruct adapter *adap = netdev2adap(dev);\r\nstruct tp_params *tp = &adap->params.tp;\r\nu64 ntuple = 0;\r\nif (tp->vlan_shift >= 0 && l2t->vlan != VLAN_NONE)\r\nntuple |= (u64)(FT_VLAN_VLD_F | l2t->vlan) << tp->vlan_shift;\r\nif (tp->port_shift >= 0)\r\nntuple |= (u64)l2t->lport << tp->port_shift;\r\nif (tp->protocol_shift >= 0)\r\nntuple |= (u64)IPPROTO_TCP << tp->protocol_shift;\r\nif (tp->vnic_shift >= 0) {\r\nu32 viid = cxgb4_port_viid(dev);\r\nu32 vf = FW_VIID_VIN_G(viid);\r\nu32 pf = FW_VIID_PFN_G(viid);\r\nu32 vld = FW_VIID_VIVLD_G(viid);\r\nntuple |= (u64)(FT_VNID_ID_VF_V(vf) |\r\nFT_VNID_ID_PF_V(pf) |\r\nFT_VNID_ID_VLD_V(vld)) << tp->vnic_shift;\r\n}\r\nreturn ntuple;\r\n}\r\nstatic void handle_failed_resolution(struct adapter *adap, struct l2t_entry *e)\r\n{\r\nstruct sk_buff *skb;\r\nwhile ((skb = __skb_dequeue(&e->arpq)) != NULL) {\r\nconst struct l2t_skb_cb *cb = L2T_SKB_CB(skb);\r\nspin_unlock(&e->lock);\r\nif (cb->arp_err_handler)\r\ncb->arp_err_handler(cb->handle, skb);\r\nelse\r\nt4_ofld_send(adap, skb);\r\nspin_lock(&e->lock);\r\n}\r\n}\r\nvoid t4_l2t_update(struct adapter *adap, struct neighbour *neigh)\r\n{\r\nstruct l2t_entry *e;\r\nstruct sk_buff_head *arpq = NULL;\r\nstruct l2t_data *d = adap->l2t;\r\nint addr_len = neigh->tbl->key_len;\r\nu32 *addr = (u32 *) neigh->primary_key;\r\nint ifidx = neigh->dev->ifindex;\r\nint hash = addr_hash(d, addr, addr_len, ifidx);\r\nread_lock_bh(&d->lock);\r\nfor (e = d->l2tab[hash].first; e; e = e->next)\r\nif (!addreq(e, addr) && e->ifindex == ifidx) {\r\nspin_lock(&e->lock);\r\nif (atomic_read(&e->refcnt))\r\ngoto found;\r\nspin_unlock(&e->lock);\r\nbreak;\r\n}\r\nread_unlock_bh(&d->lock);\r\nreturn;\r\nfound:\r\nread_unlock(&d->lock);\r\nif (neigh != e->neigh)\r\nneigh_replace(e, neigh);\r\nif (e->state == L2T_STATE_RESOLVING) {\r\nif (neigh->nud_state & NUD_FAILED) {\r\narpq = &e->arpq;\r\n} else if ((neigh->nud_state & (NUD_CONNECTED | NUD_STALE)) &&\r\n!skb_queue_empty(&e->arpq)) {\r\nwrite_l2e(adap, e, 1);\r\n}\r\n} else {\r\ne->state = neigh->nud_state & NUD_CONNECTED ?\r\nL2T_STATE_VALID : L2T_STATE_STALE;\r\nif (memcmp(e->dmac, neigh->ha, sizeof(e->dmac)))\r\nwrite_l2e(adap, e, 0);\r\n}\r\nif (arpq)\r\nhandle_failed_resolution(adap, e);\r\nspin_unlock_bh(&e->lock);\r\n}\r\nstruct l2t_entry *t4_l2t_alloc_switching(struct adapter *adap, u16 vlan,\r\nu8 port, u8 *eth_addr)\r\n{\r\nstruct l2t_data *d = adap->l2t;\r\nstruct l2t_entry *e;\r\nint ret;\r\nwrite_lock_bh(&d->lock);\r\ne = find_or_alloc_l2e(d, vlan, port, eth_addr);\r\nif (e) {\r\nspin_lock(&e->lock);\r\nif (!atomic_read(&e->refcnt)) {\r\ne->state = L2T_STATE_SWITCHING;\r\ne->vlan = vlan;\r\ne->lport = port;\r\nether_addr_copy(e->dmac, eth_addr);\r\natomic_set(&e->refcnt, 1);\r\nret = write_l2e(adap, e, 0);\r\nif (ret < 0) {\r\n_t4_l2e_free(e);\r\nspin_unlock(&e->lock);\r\nwrite_unlock_bh(&d->lock);\r\nreturn NULL;\r\n}\r\n} else {\r\natomic_inc(&e->refcnt);\r\n}\r\nspin_unlock(&e->lock);\r\n}\r\nwrite_unlock_bh(&d->lock);\r\nreturn e;\r\n}\r\nstruct l2t_entry *cxgb4_l2t_alloc_switching(struct net_device *dev, u16 vlan,\r\nu8 port, u8 *dmac)\r\n{\r\nstruct adapter *adap = netdev2adap(dev);\r\nreturn t4_l2t_alloc_switching(adap, vlan, port, dmac);\r\n}\r\nstruct l2t_data *t4_init_l2t(unsigned int l2t_start, unsigned int l2t_end)\r\n{\r\nunsigned int l2t_size;\r\nint i;\r\nstruct l2t_data *d;\r\nif (l2t_start >= l2t_end || l2t_end >= L2T_SIZE)\r\nreturn NULL;\r\nl2t_size = l2t_end - l2t_start + 1;\r\nif (l2t_size < L2T_MIN_HASH_BUCKETS)\r\nreturn NULL;\r\nd = t4_alloc_mem(sizeof(*d) + l2t_size * sizeof(struct l2t_entry));\r\nif (!d)\r\nreturn NULL;\r\nd->l2t_start = l2t_start;\r\nd->l2t_size = l2t_size;\r\nd->rover = d->l2tab;\r\natomic_set(&d->nfree, l2t_size);\r\nrwlock_init(&d->lock);\r\nfor (i = 0; i < d->l2t_size; ++i) {\r\nd->l2tab[i].idx = i;\r\nd->l2tab[i].state = L2T_STATE_UNUSED;\r\nspin_lock_init(&d->l2tab[i].lock);\r\natomic_set(&d->l2tab[i].refcnt, 0);\r\nskb_queue_head_init(&d->l2tab[i].arpq);\r\n}\r\nreturn d;\r\n}\r\nstatic inline void *l2t_get_idx(struct seq_file *seq, loff_t pos)\r\n{\r\nstruct l2t_data *d = seq->private;\r\nreturn pos >= d->l2t_size ? NULL : &d->l2tab[pos];\r\n}\r\nstatic void *l2t_seq_start(struct seq_file *seq, loff_t *pos)\r\n{\r\nreturn *pos ? l2t_get_idx(seq, *pos - 1) : SEQ_START_TOKEN;\r\n}\r\nstatic void *l2t_seq_next(struct seq_file *seq, void *v, loff_t *pos)\r\n{\r\nv = l2t_get_idx(seq, *pos);\r\nif (v)\r\n++*pos;\r\nreturn v;\r\n}\r\nstatic void l2t_seq_stop(struct seq_file *seq, void *v)\r\n{\r\n}\r\nstatic char l2e_state(const struct l2t_entry *e)\r\n{\r\nswitch (e->state) {\r\ncase L2T_STATE_VALID: return 'V';\r\ncase L2T_STATE_STALE: return 'S';\r\ncase L2T_STATE_SYNC_WRITE: return 'W';\r\ncase L2T_STATE_RESOLVING:\r\nreturn skb_queue_empty(&e->arpq) ? 'R' : 'A';\r\ncase L2T_STATE_SWITCHING: return 'X';\r\ndefault:\r\nreturn 'U';\r\n}\r\n}\r\nstatic int l2t_seq_show(struct seq_file *seq, void *v)\r\n{\r\nif (v == SEQ_START_TOKEN)\r\nseq_puts(seq, " Idx IP address "\r\n"Ethernet address VLAN/P LP State Users Port\n");\r\nelse {\r\nchar ip[60];\r\nstruct l2t_data *d = seq->private;\r\nstruct l2t_entry *e = v;\r\nspin_lock_bh(&e->lock);\r\nif (e->state == L2T_STATE_SWITCHING)\r\nip[0] = '\0';\r\nelse\r\nsprintf(ip, e->v6 ? "%pI6c" : "%pI4", e->addr);\r\nseq_printf(seq, "%4u %-25s %17pM %4d %u %2u %c %5u %s\n",\r\ne->idx + d->l2t_start, ip, e->dmac,\r\ne->vlan & VLAN_VID_MASK, vlan_prio(e), e->lport,\r\nl2e_state(e), atomic_read(&e->refcnt),\r\ne->neigh ? e->neigh->dev->name : "");\r\nspin_unlock_bh(&e->lock);\r\n}\r\nreturn 0;\r\n}\r\nstatic int l2t_seq_open(struct inode *inode, struct file *file)\r\n{\r\nint rc = seq_open(file, &l2t_seq_ops);\r\nif (!rc) {\r\nstruct adapter *adap = inode->i_private;\r\nstruct seq_file *seq = file->private_data;\r\nseq->private = adap->l2t;\r\n}\r\nreturn rc;\r\n}
