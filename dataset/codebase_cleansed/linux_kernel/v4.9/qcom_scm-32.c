static inline struct qcom_scm_response *qcom_scm_command_to_response(\r\nconst struct qcom_scm_command *cmd)\r\n{\r\nreturn (void *)cmd + le32_to_cpu(cmd->resp_hdr_offset);\r\n}\r\nstatic inline void *qcom_scm_get_command_buffer(const struct qcom_scm_command *cmd)\r\n{\r\nreturn (void *)cmd->buf;\r\n}\r\nstatic inline void *qcom_scm_get_response_buffer(const struct qcom_scm_response *rsp)\r\n{\r\nreturn (void *)rsp + le32_to_cpu(rsp->buf_offset);\r\n}\r\nstatic u32 smc(u32 cmd_addr)\r\n{\r\nint context_id;\r\nregister u32 r0 asm("r0") = 1;\r\nregister u32 r1 asm("r1") = (u32)&context_id;\r\nregister u32 r2 asm("r2") = cmd_addr;\r\ndo {\r\nasm volatile(\r\n__asmeq("%0", "r0")\r\n__asmeq("%1", "r0")\r\n__asmeq("%2", "r1")\r\n__asmeq("%3", "r2")\r\n#ifdef REQUIRES_SEC\r\n".arch_extension sec\n"\r\n#endif\r\n"smc #0 @ switch to secure world\n"\r\n: "=r" (r0)\r\n: "r" (r0), "r" (r1), "r" (r2)\r\n: "r3");\r\n} while (r0 == QCOM_SCM_INTERRUPTED);\r\nreturn r0;\r\n}\r\nstatic int qcom_scm_call(struct device *dev, u32 svc_id, u32 cmd_id,\r\nconst void *cmd_buf, size_t cmd_len, void *resp_buf,\r\nsize_t resp_len)\r\n{\r\nint ret;\r\nstruct qcom_scm_command *cmd;\r\nstruct qcom_scm_response *rsp;\r\nsize_t alloc_len = sizeof(*cmd) + cmd_len + sizeof(*rsp) + resp_len;\r\ndma_addr_t cmd_phys;\r\ncmd = kzalloc(PAGE_ALIGN(alloc_len), GFP_KERNEL);\r\nif (!cmd)\r\nreturn -ENOMEM;\r\ncmd->len = cpu_to_le32(alloc_len);\r\ncmd->buf_offset = cpu_to_le32(sizeof(*cmd));\r\ncmd->resp_hdr_offset = cpu_to_le32(sizeof(*cmd) + cmd_len);\r\ncmd->id = cpu_to_le32((svc_id << 10) | cmd_id);\r\nif (cmd_buf)\r\nmemcpy(qcom_scm_get_command_buffer(cmd), cmd_buf, cmd_len);\r\nrsp = qcom_scm_command_to_response(cmd);\r\ncmd_phys = dma_map_single(dev, cmd, alloc_len, DMA_TO_DEVICE);\r\nif (dma_mapping_error(dev, cmd_phys)) {\r\nkfree(cmd);\r\nreturn -ENOMEM;\r\n}\r\nmutex_lock(&qcom_scm_lock);\r\nret = smc(cmd_phys);\r\nif (ret < 0)\r\nret = qcom_scm_remap_error(ret);\r\nmutex_unlock(&qcom_scm_lock);\r\nif (ret)\r\ngoto out;\r\ndo {\r\ndma_sync_single_for_cpu(dev, cmd_phys + sizeof(*cmd) + cmd_len,\r\nsizeof(*rsp), DMA_FROM_DEVICE);\r\n} while (!rsp->is_complete);\r\nif (resp_buf) {\r\ndma_sync_single_for_cpu(dev, cmd_phys + sizeof(*cmd) + cmd_len +\r\nle32_to_cpu(rsp->buf_offset),\r\nresp_len, DMA_FROM_DEVICE);\r\nmemcpy(resp_buf, qcom_scm_get_response_buffer(rsp),\r\nresp_len);\r\n}\r\nout:\r\ndma_unmap_single(dev, cmd_phys, alloc_len, DMA_TO_DEVICE);\r\nkfree(cmd);\r\nreturn ret;\r\n}\r\nstatic s32 qcom_scm_call_atomic1(u32 svc, u32 cmd, u32 arg1)\r\n{\r\nint context_id;\r\nregister u32 r0 asm("r0") = SCM_ATOMIC(svc, cmd, 1);\r\nregister u32 r1 asm("r1") = (u32)&context_id;\r\nregister u32 r2 asm("r2") = arg1;\r\nasm volatile(\r\n__asmeq("%0", "r0")\r\n__asmeq("%1", "r0")\r\n__asmeq("%2", "r1")\r\n__asmeq("%3", "r2")\r\n#ifdef REQUIRES_SEC\r\n".arch_extension sec\n"\r\n#endif\r\n"smc #0 @ switch to secure world\n"\r\n: "=r" (r0)\r\n: "r" (r0), "r" (r1), "r" (r2)\r\n: "r3");\r\nreturn r0;\r\n}\r\nstatic s32 qcom_scm_call_atomic2(u32 svc, u32 cmd, u32 arg1, u32 arg2)\r\n{\r\nint context_id;\r\nregister u32 r0 asm("r0") = SCM_ATOMIC(svc, cmd, 2);\r\nregister u32 r1 asm("r1") = (u32)&context_id;\r\nregister u32 r2 asm("r2") = arg1;\r\nregister u32 r3 asm("r3") = arg2;\r\nasm volatile(\r\n__asmeq("%0", "r0")\r\n__asmeq("%1", "r0")\r\n__asmeq("%2", "r1")\r\n__asmeq("%3", "r2")\r\n__asmeq("%4", "r3")\r\n#ifdef REQUIRES_SEC\r\n".arch_extension sec\n"\r\n#endif\r\n"smc #0 @ switch to secure world\n"\r\n: "=r" (r0)\r\n: "r" (r0), "r" (r1), "r" (r2), "r" (r3)\r\n);\r\nreturn r0;\r\n}\r\nu32 qcom_scm_get_version(void)\r\n{\r\nint context_id;\r\nstatic u32 version = -1;\r\nregister u32 r0 asm("r0");\r\nregister u32 r1 asm("r1");\r\nif (version != -1)\r\nreturn version;\r\nmutex_lock(&qcom_scm_lock);\r\nr0 = 0x1 << 8;\r\nr1 = (u32)&context_id;\r\ndo {\r\nasm volatile(\r\n__asmeq("%0", "r0")\r\n__asmeq("%1", "r1")\r\n__asmeq("%2", "r0")\r\n__asmeq("%3", "r1")\r\n#ifdef REQUIRES_SEC\r\n".arch_extension sec\n"\r\n#endif\r\n"smc #0 @ switch to secure world\n"\r\n: "=r" (r0), "=r" (r1)\r\n: "r" (r0), "r" (r1)\r\n: "r2", "r3");\r\n} while (r0 == QCOM_SCM_INTERRUPTED);\r\nversion = r1;\r\nmutex_unlock(&qcom_scm_lock);\r\nreturn version;\r\n}\r\nint __qcom_scm_set_cold_boot_addr(void *entry, const cpumask_t *cpus)\r\n{\r\nint flags = 0;\r\nint cpu;\r\nint scm_cb_flags[] = {\r\nQCOM_SCM_FLAG_COLDBOOT_CPU0,\r\nQCOM_SCM_FLAG_COLDBOOT_CPU1,\r\nQCOM_SCM_FLAG_COLDBOOT_CPU2,\r\nQCOM_SCM_FLAG_COLDBOOT_CPU3,\r\n};\r\nif (!cpus || (cpus && cpumask_empty(cpus)))\r\nreturn -EINVAL;\r\nfor_each_cpu(cpu, cpus) {\r\nif (cpu < ARRAY_SIZE(scm_cb_flags))\r\nflags |= scm_cb_flags[cpu];\r\nelse\r\nset_cpu_present(cpu, false);\r\n}\r\nreturn qcom_scm_call_atomic2(QCOM_SCM_SVC_BOOT, QCOM_SCM_BOOT_ADDR,\r\nflags, virt_to_phys(entry));\r\n}\r\nint __qcom_scm_set_warm_boot_addr(struct device *dev, void *entry,\r\nconst cpumask_t *cpus)\r\n{\r\nint ret;\r\nint flags = 0;\r\nint cpu;\r\nstruct {\r\n__le32 flags;\r\n__le32 addr;\r\n} cmd;\r\nfor_each_cpu(cpu, cpus) {\r\nif (entry == qcom_scm_wb[cpu].entry)\r\ncontinue;\r\nflags |= qcom_scm_wb[cpu].flag;\r\n}\r\nif (!flags)\r\nreturn 0;\r\ncmd.addr = cpu_to_le32(virt_to_phys(entry));\r\ncmd.flags = cpu_to_le32(flags);\r\nret = qcom_scm_call(dev, QCOM_SCM_SVC_BOOT, QCOM_SCM_BOOT_ADDR,\r\n&cmd, sizeof(cmd), NULL, 0);\r\nif (!ret) {\r\nfor_each_cpu(cpu, cpus)\r\nqcom_scm_wb[cpu].entry = entry;\r\n}\r\nreturn ret;\r\n}\r\nvoid __qcom_scm_cpu_power_down(u32 flags)\r\n{\r\nqcom_scm_call_atomic1(QCOM_SCM_SVC_BOOT, QCOM_SCM_CMD_TERMINATE_PC,\r\nflags & QCOM_SCM_FLUSH_FLAG_MASK);\r\n}\r\nint __qcom_scm_is_call_available(struct device *dev, u32 svc_id, u32 cmd_id)\r\n{\r\nint ret;\r\n__le32 svc_cmd = cpu_to_le32((svc_id << 10) | cmd_id);\r\n__le32 ret_val = 0;\r\nret = qcom_scm_call(dev, QCOM_SCM_SVC_INFO, QCOM_IS_CALL_AVAIL_CMD,\r\n&svc_cmd, sizeof(svc_cmd), &ret_val,\r\nsizeof(ret_val));\r\nif (ret)\r\nreturn ret;\r\nreturn le32_to_cpu(ret_val);\r\n}\r\nint __qcom_scm_hdcp_req(struct device *dev, struct qcom_scm_hdcp_req *req,\r\nu32 req_cnt, u32 *resp)\r\n{\r\nif (req_cnt > QCOM_SCM_HDCP_MAX_REQ_CNT)\r\nreturn -ERANGE;\r\nreturn qcom_scm_call(dev, QCOM_SCM_SVC_HDCP, QCOM_SCM_CMD_HDCP,\r\nreq, req_cnt * sizeof(*req), resp, sizeof(*resp));\r\n}\r\nvoid __qcom_scm_init(void)\r\n{\r\n}\r\nbool __qcom_scm_pas_supported(struct device *dev, u32 peripheral)\r\n{\r\n__le32 out;\r\n__le32 in;\r\nint ret;\r\nin = cpu_to_le32(peripheral);\r\nret = qcom_scm_call(dev, QCOM_SCM_SVC_PIL,\r\nQCOM_SCM_PAS_IS_SUPPORTED_CMD,\r\n&in, sizeof(in),\r\n&out, sizeof(out));\r\nreturn ret ? false : !!out;\r\n}\r\nint __qcom_scm_pas_init_image(struct device *dev, u32 peripheral,\r\ndma_addr_t metadata_phys)\r\n{\r\n__le32 scm_ret;\r\nint ret;\r\nstruct {\r\n__le32 proc;\r\n__le32 image_addr;\r\n} request;\r\nrequest.proc = cpu_to_le32(peripheral);\r\nrequest.image_addr = cpu_to_le32(metadata_phys);\r\nret = qcom_scm_call(dev, QCOM_SCM_SVC_PIL,\r\nQCOM_SCM_PAS_INIT_IMAGE_CMD,\r\n&request, sizeof(request),\r\n&scm_ret, sizeof(scm_ret));\r\nreturn ret ? : le32_to_cpu(scm_ret);\r\n}\r\nint __qcom_scm_pas_mem_setup(struct device *dev, u32 peripheral,\r\nphys_addr_t addr, phys_addr_t size)\r\n{\r\n__le32 scm_ret;\r\nint ret;\r\nstruct {\r\n__le32 proc;\r\n__le32 addr;\r\n__le32 len;\r\n} request;\r\nrequest.proc = cpu_to_le32(peripheral);\r\nrequest.addr = cpu_to_le32(addr);\r\nrequest.len = cpu_to_le32(size);\r\nret = qcom_scm_call(dev, QCOM_SCM_SVC_PIL,\r\nQCOM_SCM_PAS_MEM_SETUP_CMD,\r\n&request, sizeof(request),\r\n&scm_ret, sizeof(scm_ret));\r\nreturn ret ? : le32_to_cpu(scm_ret);\r\n}\r\nint __qcom_scm_pas_auth_and_reset(struct device *dev, u32 peripheral)\r\n{\r\n__le32 out;\r\n__le32 in;\r\nint ret;\r\nin = cpu_to_le32(peripheral);\r\nret = qcom_scm_call(dev, QCOM_SCM_SVC_PIL,\r\nQCOM_SCM_PAS_AUTH_AND_RESET_CMD,\r\n&in, sizeof(in),\r\n&out, sizeof(out));\r\nreturn ret ? : le32_to_cpu(out);\r\n}\r\nint __qcom_scm_pas_shutdown(struct device *dev, u32 peripheral)\r\n{\r\n__le32 out;\r\n__le32 in;\r\nint ret;\r\nin = cpu_to_le32(peripheral);\r\nret = qcom_scm_call(dev, QCOM_SCM_SVC_PIL,\r\nQCOM_SCM_PAS_SHUTDOWN_CMD,\r\n&in, sizeof(in),\r\n&out, sizeof(out));\r\nreturn ret ? : le32_to_cpu(out);\r\n}\r\nint __qcom_scm_pas_mss_reset(struct device *dev, bool reset)\r\n{\r\n__le32 out;\r\n__le32 in = cpu_to_le32(reset);\r\nint ret;\r\nret = qcom_scm_call(dev, QCOM_SCM_SVC_PIL, QCOM_SCM_PAS_MSS_RESET,\r\n&in, sizeof(in),\r\n&out, sizeof(out));\r\nreturn ret ? : le32_to_cpu(out);\r\n}
