static inline u8 qlcnic_mac_hash(u64 mac, u16 vlan)\r\n{\r\nreturn (u8)((mac & 0xff) ^ ((mac >> 40) & 0xff) ^ (vlan & 0xff));\r\n}\r\nstatic inline u32 qlcnic_get_ref_handle(struct qlcnic_adapter *adapter,\r\nu16 handle, u8 ring_id)\r\n{\r\nif (qlcnic_83xx_check(adapter))\r\nreturn handle | (ring_id << 15);\r\nelse\r\nreturn handle;\r\n}\r\nstatic inline int qlcnic_82xx_is_lb_pkt(u64 sts_data)\r\n{\r\nreturn (qlcnic_get_sts_status(sts_data) == STATUS_CKSUM_LOOP) ? 1 : 0;\r\n}\r\nstatic void qlcnic_delete_rx_list_mac(struct qlcnic_adapter *adapter,\r\nstruct qlcnic_filter *fil,\r\nvoid *addr, u16 vlan_id)\r\n{\r\nint ret;\r\nu8 op;\r\nop = vlan_id ? QLCNIC_MAC_VLAN_ADD : QLCNIC_MAC_ADD;\r\nret = qlcnic_sre_macaddr_change(adapter, addr, vlan_id, op);\r\nif (ret)\r\nreturn;\r\nop = vlan_id ? QLCNIC_MAC_VLAN_DEL : QLCNIC_MAC_DEL;\r\nret = qlcnic_sre_macaddr_change(adapter, addr, vlan_id, op);\r\nif (!ret) {\r\nhlist_del(&fil->fnode);\r\nadapter->rx_fhash.fnum--;\r\n}\r\n}\r\nstatic struct qlcnic_filter *qlcnic_find_mac_filter(struct hlist_head *head,\r\nvoid *addr, u16 vlan_id)\r\n{\r\nstruct qlcnic_filter *tmp_fil = NULL;\r\nstruct hlist_node *n;\r\nhlist_for_each_entry_safe(tmp_fil, n, head, fnode) {\r\nif (ether_addr_equal(tmp_fil->faddr, addr) &&\r\ntmp_fil->vlan_id == vlan_id)\r\nreturn tmp_fil;\r\n}\r\nreturn NULL;\r\n}\r\nstatic void qlcnic_add_lb_filter(struct qlcnic_adapter *adapter,\r\nstruct sk_buff *skb, int loopback_pkt, u16 vlan_id)\r\n{\r\nstruct ethhdr *phdr = (struct ethhdr *)(skb->data);\r\nstruct qlcnic_filter *fil, *tmp_fil;\r\nstruct hlist_head *head;\r\nunsigned long time;\r\nu64 src_addr = 0;\r\nu8 hindex, op;\r\nint ret;\r\nif (!qlcnic_sriov_pf_check(adapter) || (vlan_id == 0xffff))\r\nvlan_id = 0;\r\nmemcpy(&src_addr, phdr->h_source, ETH_ALEN);\r\nhindex = qlcnic_mac_hash(src_addr, vlan_id) &\r\n(adapter->fhash.fbucket_size - 1);\r\nif (loopback_pkt) {\r\nif (adapter->rx_fhash.fnum >= adapter->rx_fhash.fmax)\r\nreturn;\r\nhead = &(adapter->rx_fhash.fhead[hindex]);\r\ntmp_fil = qlcnic_find_mac_filter(head, &src_addr, vlan_id);\r\nif (tmp_fil) {\r\ntime = tmp_fil->ftime;\r\nif (time_after(jiffies, QLCNIC_READD_AGE * HZ + time))\r\ntmp_fil->ftime = jiffies;\r\nreturn;\r\n}\r\nfil = kzalloc(sizeof(struct qlcnic_filter), GFP_ATOMIC);\r\nif (!fil)\r\nreturn;\r\nfil->ftime = jiffies;\r\nmemcpy(fil->faddr, &src_addr, ETH_ALEN);\r\nfil->vlan_id = vlan_id;\r\nspin_lock(&adapter->rx_mac_learn_lock);\r\nhlist_add_head(&(fil->fnode), head);\r\nadapter->rx_fhash.fnum++;\r\nspin_unlock(&adapter->rx_mac_learn_lock);\r\n} else {\r\nhead = &adapter->fhash.fhead[hindex];\r\nspin_lock(&adapter->mac_learn_lock);\r\ntmp_fil = qlcnic_find_mac_filter(head, &src_addr, vlan_id);\r\nif (tmp_fil) {\r\nop = vlan_id ? QLCNIC_MAC_VLAN_DEL : QLCNIC_MAC_DEL;\r\nret = qlcnic_sre_macaddr_change(adapter,\r\n(u8 *)&src_addr,\r\nvlan_id, op);\r\nif (!ret) {\r\nhlist_del(&tmp_fil->fnode);\r\nadapter->fhash.fnum--;\r\n}\r\nspin_unlock(&adapter->mac_learn_lock);\r\nreturn;\r\n}\r\nspin_unlock(&adapter->mac_learn_lock);\r\nhead = &adapter->rx_fhash.fhead[hindex];\r\nspin_lock(&adapter->rx_mac_learn_lock);\r\ntmp_fil = qlcnic_find_mac_filter(head, &src_addr, vlan_id);\r\nif (tmp_fil)\r\nqlcnic_delete_rx_list_mac(adapter, tmp_fil, &src_addr,\r\nvlan_id);\r\nspin_unlock(&adapter->rx_mac_learn_lock);\r\n}\r\n}\r\nvoid qlcnic_82xx_change_filter(struct qlcnic_adapter *adapter, u64 *uaddr,\r\nu16 vlan_id)\r\n{\r\nstruct cmd_desc_type0 *hwdesc;\r\nstruct qlcnic_nic_req *req;\r\nstruct qlcnic_mac_req *mac_req;\r\nstruct qlcnic_vlan_req *vlan_req;\r\nstruct qlcnic_host_tx_ring *tx_ring = adapter->tx_ring;\r\nu32 producer;\r\nu64 word;\r\nproducer = tx_ring->producer;\r\nhwdesc = &tx_ring->desc_head[tx_ring->producer];\r\nreq = (struct qlcnic_nic_req *)hwdesc;\r\nmemset(req, 0, sizeof(struct qlcnic_nic_req));\r\nreq->qhdr = cpu_to_le64(QLCNIC_REQUEST << 23);\r\nword = QLCNIC_MAC_EVENT | ((u64)(adapter->portnum) << 16);\r\nreq->req_hdr = cpu_to_le64(word);\r\nmac_req = (struct qlcnic_mac_req *)&(req->words[0]);\r\nmac_req->op = vlan_id ? QLCNIC_MAC_VLAN_ADD : QLCNIC_MAC_ADD;\r\nmemcpy(mac_req->mac_addr, uaddr, ETH_ALEN);\r\nvlan_req = (struct qlcnic_vlan_req *)&req->words[1];\r\nvlan_req->vlan_id = cpu_to_le16(vlan_id);\r\ntx_ring->producer = get_next_index(producer, tx_ring->num_desc);\r\nsmp_mb();\r\n}\r\nstatic void qlcnic_send_filter(struct qlcnic_adapter *adapter,\r\nstruct cmd_desc_type0 *first_desc,\r\nstruct sk_buff *skb)\r\n{\r\nstruct vlan_ethhdr *vh = (struct vlan_ethhdr *)(skb->data);\r\nstruct ethhdr *phdr = (struct ethhdr *)(skb->data);\r\nu16 protocol = ntohs(skb->protocol);\r\nstruct qlcnic_filter *fil, *tmp_fil;\r\nstruct hlist_head *head;\r\nstruct hlist_node *n;\r\nu64 src_addr = 0;\r\nu16 vlan_id = 0;\r\nu8 hindex, hval;\r\nif (ether_addr_equal(phdr->h_source, adapter->mac_addr))\r\nreturn;\r\nif (adapter->flags & QLCNIC_VLAN_FILTERING) {\r\nif (protocol == ETH_P_8021Q) {\r\nvh = (struct vlan_ethhdr *)skb->data;\r\nvlan_id = ntohs(vh->h_vlan_TCI);\r\n} else if (skb_vlan_tag_present(skb)) {\r\nvlan_id = skb_vlan_tag_get(skb);\r\n}\r\n}\r\nmemcpy(&src_addr, phdr->h_source, ETH_ALEN);\r\nhval = qlcnic_mac_hash(src_addr, vlan_id);\r\nhindex = hval & (adapter->fhash.fbucket_size - 1);\r\nhead = &(adapter->fhash.fhead[hindex]);\r\nhlist_for_each_entry_safe(tmp_fil, n, head, fnode) {\r\nif (ether_addr_equal(tmp_fil->faddr, (u8 *)&src_addr) &&\r\ntmp_fil->vlan_id == vlan_id) {\r\nif (jiffies > (QLCNIC_READD_AGE * HZ + tmp_fil->ftime))\r\nqlcnic_change_filter(adapter, &src_addr,\r\nvlan_id);\r\ntmp_fil->ftime = jiffies;\r\nreturn;\r\n}\r\n}\r\nif (unlikely(adapter->fhash.fnum >= adapter->fhash.fmax)) {\r\nadapter->stats.mac_filter_limit_overrun++;\r\nreturn;\r\n}\r\nfil = kzalloc(sizeof(struct qlcnic_filter), GFP_ATOMIC);\r\nif (!fil)\r\nreturn;\r\nqlcnic_change_filter(adapter, &src_addr, vlan_id);\r\nfil->ftime = jiffies;\r\nfil->vlan_id = vlan_id;\r\nmemcpy(fil->faddr, &src_addr, ETH_ALEN);\r\nspin_lock(&adapter->mac_learn_lock);\r\nhlist_add_head(&(fil->fnode), head);\r\nadapter->fhash.fnum++;\r\nspin_unlock(&adapter->mac_learn_lock);\r\n}\r\nstatic int qlcnic_tx_encap_pkt(struct qlcnic_adapter *adapter,\r\nstruct cmd_desc_type0 *first_desc,\r\nstruct sk_buff *skb,\r\nstruct qlcnic_host_tx_ring *tx_ring)\r\n{\r\nu8 opcode = 0, inner_hdr_len = 0, outer_hdr_len = 0, total_hdr_len = 0;\r\nint copied, copy_len, descr_size;\r\nu32 producer = tx_ring->producer;\r\nstruct cmd_desc_type0 *hwdesc;\r\nu16 flags = 0, encap_descr = 0;\r\nopcode = QLCNIC_TX_ETHER_PKT;\r\nencap_descr = QLCNIC_ENCAP_VXLAN_PKT;\r\nif (skb_is_gso(skb)) {\r\ninner_hdr_len = skb_inner_transport_header(skb) +\r\ninner_tcp_hdrlen(skb) -\r\nskb_inner_mac_header(skb);\r\nouter_hdr_len = skb_transport_offset(skb) + 8 +\r\nsizeof(struct udphdr);\r\nfirst_desc->outer_hdr_length = outer_hdr_len;\r\ntotal_hdr_len = inner_hdr_len + outer_hdr_len;\r\nencap_descr |= QLCNIC_ENCAP_DO_L3_CSUM |\r\nQLCNIC_ENCAP_DO_L4_CSUM;\r\nfirst_desc->mss = cpu_to_le16(skb_shinfo(skb)->gso_size);\r\nfirst_desc->hdr_length = inner_hdr_len;\r\ncopied = 0;\r\ndescr_size = (int)sizeof(struct cmd_desc_type0);\r\nwhile (copied < total_hdr_len) {\r\ncopy_len = min(descr_size, (total_hdr_len - copied));\r\nhwdesc = &tx_ring->desc_head[producer];\r\ntx_ring->cmd_buf_arr[producer].skb = NULL;\r\nskb_copy_from_linear_data_offset(skb, copied,\r\n(char *)hwdesc,\r\ncopy_len);\r\ncopied += copy_len;\r\nproducer = get_next_index(producer, tx_ring->num_desc);\r\n}\r\ntx_ring->producer = producer;\r\nsmp_mb();\r\nadapter->stats.encap_lso_frames++;\r\nopcode = QLCNIC_TX_ENCAP_LSO;\r\n} else if (skb->ip_summed == CHECKSUM_PARTIAL) {\r\nif (inner_ip_hdr(skb)->version == 6) {\r\nif (inner_ipv6_hdr(skb)->nexthdr == IPPROTO_UDP)\r\nencap_descr |= QLCNIC_ENCAP_INNER_L4_UDP;\r\n} else {\r\nif (inner_ip_hdr(skb)->protocol == IPPROTO_UDP)\r\nencap_descr |= QLCNIC_ENCAP_INNER_L4_UDP;\r\n}\r\nadapter->stats.encap_tx_csummed++;\r\nopcode = QLCNIC_TX_ENCAP_PKT;\r\n}\r\nif (ip_hdr(skb)->version == 6)\r\nencap_descr |= QLCNIC_ENCAP_OUTER_L3_IP6;\r\nencap_descr |= (skb_network_header_len(skb) >> 2) << 6;\r\nencap_descr |= skb_network_offset(skb) << 10;\r\nfirst_desc->encap_descr = cpu_to_le16(encap_descr);\r\nfirst_desc->tcp_hdr_offset = skb_inner_transport_header(skb) -\r\nskb->data;\r\nfirst_desc->ip_hdr_offset = skb_inner_network_offset(skb);\r\nqlcnic_set_tx_flags_opcode(first_desc, flags, opcode);\r\nreturn 0;\r\n}\r\nstatic int qlcnic_tx_pkt(struct qlcnic_adapter *adapter,\r\nstruct cmd_desc_type0 *first_desc, struct sk_buff *skb,\r\nstruct qlcnic_host_tx_ring *tx_ring)\r\n{\r\nu8 l4proto, opcode = 0, hdr_len = 0;\r\nu16 flags = 0, vlan_tci = 0;\r\nint copied, offset, copy_len, size;\r\nstruct cmd_desc_type0 *hwdesc;\r\nstruct vlan_ethhdr *vh;\r\nu16 protocol = ntohs(skb->protocol);\r\nu32 producer = tx_ring->producer;\r\nif (protocol == ETH_P_8021Q) {\r\nvh = (struct vlan_ethhdr *)skb->data;\r\nflags = QLCNIC_FLAGS_VLAN_TAGGED;\r\nvlan_tci = ntohs(vh->h_vlan_TCI);\r\nprotocol = ntohs(vh->h_vlan_encapsulated_proto);\r\n} else if (skb_vlan_tag_present(skb)) {\r\nflags = QLCNIC_FLAGS_VLAN_OOB;\r\nvlan_tci = skb_vlan_tag_get(skb);\r\n}\r\nif (unlikely(adapter->tx_pvid)) {\r\nif (vlan_tci && !(adapter->flags & QLCNIC_TAGGING_ENABLED))\r\nreturn -EIO;\r\nif (vlan_tci && (adapter->flags & QLCNIC_TAGGING_ENABLED))\r\ngoto set_flags;\r\nflags = QLCNIC_FLAGS_VLAN_OOB;\r\nvlan_tci = adapter->tx_pvid;\r\n}\r\nset_flags:\r\nqlcnic_set_tx_vlan_tci(first_desc, vlan_tci);\r\nqlcnic_set_tx_flags_opcode(first_desc, flags, opcode);\r\nif (*(skb->data) & BIT_0) {\r\nflags |= BIT_0;\r\nmemcpy(&first_desc->eth_addr, skb->data, ETH_ALEN);\r\n}\r\nopcode = QLCNIC_TX_ETHER_PKT;\r\nif (skb_is_gso(skb)) {\r\nhdr_len = skb_transport_offset(skb) + tcp_hdrlen(skb);\r\nfirst_desc->mss = cpu_to_le16(skb_shinfo(skb)->gso_size);\r\nfirst_desc->hdr_length = hdr_len;\r\nopcode = (protocol == ETH_P_IPV6) ? QLCNIC_TX_TCP_LSO6 :\r\nQLCNIC_TX_TCP_LSO;\r\ncopied = 0;\r\noffset = 2;\r\nif (flags & QLCNIC_FLAGS_VLAN_OOB) {\r\nfirst_desc->hdr_length += VLAN_HLEN;\r\nfirst_desc->tcp_hdr_offset = VLAN_HLEN;\r\nfirst_desc->ip_hdr_offset = VLAN_HLEN;\r\nflags |= QLCNIC_FLAGS_VLAN_TAGGED;\r\nhwdesc = &tx_ring->desc_head[producer];\r\ntx_ring->cmd_buf_arr[producer].skb = NULL;\r\ncopy_len = min((int)sizeof(struct cmd_desc_type0) -\r\noffset, hdr_len + VLAN_HLEN);\r\nvh = (struct vlan_ethhdr *)((char *) hwdesc + 2);\r\nskb_copy_from_linear_data(skb, vh, 12);\r\nvh->h_vlan_proto = htons(ETH_P_8021Q);\r\nvh->h_vlan_TCI = htons(vlan_tci);\r\nskb_copy_from_linear_data_offset(skb, 12,\r\n(char *)vh + 16,\r\ncopy_len - 16);\r\ncopied = copy_len - VLAN_HLEN;\r\noffset = 0;\r\nproducer = get_next_index(producer, tx_ring->num_desc);\r\n}\r\nwhile (copied < hdr_len) {\r\nsize = (int)sizeof(struct cmd_desc_type0) - offset;\r\ncopy_len = min(size, (hdr_len - copied));\r\nhwdesc = &tx_ring->desc_head[producer];\r\ntx_ring->cmd_buf_arr[producer].skb = NULL;\r\nskb_copy_from_linear_data_offset(skb, copied,\r\n(char *)hwdesc +\r\noffset, copy_len);\r\ncopied += copy_len;\r\noffset = 0;\r\nproducer = get_next_index(producer, tx_ring->num_desc);\r\n}\r\ntx_ring->producer = producer;\r\nsmp_mb();\r\nadapter->stats.lso_frames++;\r\n} else if (skb->ip_summed == CHECKSUM_PARTIAL) {\r\nif (protocol == ETH_P_IP) {\r\nl4proto = ip_hdr(skb)->protocol;\r\nif (l4proto == IPPROTO_TCP)\r\nopcode = QLCNIC_TX_TCP_PKT;\r\nelse if (l4proto == IPPROTO_UDP)\r\nopcode = QLCNIC_TX_UDP_PKT;\r\n} else if (protocol == ETH_P_IPV6) {\r\nl4proto = ipv6_hdr(skb)->nexthdr;\r\nif (l4proto == IPPROTO_TCP)\r\nopcode = QLCNIC_TX_TCPV6_PKT;\r\nelse if (l4proto == IPPROTO_UDP)\r\nopcode = QLCNIC_TX_UDPV6_PKT;\r\n}\r\n}\r\nfirst_desc->tcp_hdr_offset += skb_transport_offset(skb);\r\nfirst_desc->ip_hdr_offset += skb_network_offset(skb);\r\nqlcnic_set_tx_flags_opcode(first_desc, flags, opcode);\r\nreturn 0;\r\n}\r\nstatic int qlcnic_map_tx_skb(struct pci_dev *pdev, struct sk_buff *skb,\r\nstruct qlcnic_cmd_buffer *pbuf)\r\n{\r\nstruct qlcnic_skb_frag *nf;\r\nstruct skb_frag_struct *frag;\r\nint i, nr_frags;\r\ndma_addr_t map;\r\nnr_frags = skb_shinfo(skb)->nr_frags;\r\nnf = &pbuf->frag_array[0];\r\nmap = pci_map_single(pdev, skb->data, skb_headlen(skb),\r\nPCI_DMA_TODEVICE);\r\nif (pci_dma_mapping_error(pdev, map))\r\ngoto out_err;\r\nnf->dma = map;\r\nnf->length = skb_headlen(skb);\r\nfor (i = 0; i < nr_frags; i++) {\r\nfrag = &skb_shinfo(skb)->frags[i];\r\nnf = &pbuf->frag_array[i+1];\r\nmap = skb_frag_dma_map(&pdev->dev, frag, 0, skb_frag_size(frag),\r\nDMA_TO_DEVICE);\r\nif (dma_mapping_error(&pdev->dev, map))\r\ngoto unwind;\r\nnf->dma = map;\r\nnf->length = skb_frag_size(frag);\r\n}\r\nreturn 0;\r\nunwind:\r\nwhile (--i >= 0) {\r\nnf = &pbuf->frag_array[i+1];\r\npci_unmap_page(pdev, nf->dma, nf->length, PCI_DMA_TODEVICE);\r\n}\r\nnf = &pbuf->frag_array[0];\r\npci_unmap_single(pdev, nf->dma, skb_headlen(skb), PCI_DMA_TODEVICE);\r\nout_err:\r\nreturn -ENOMEM;\r\n}\r\nstatic void qlcnic_unmap_buffers(struct pci_dev *pdev, struct sk_buff *skb,\r\nstruct qlcnic_cmd_buffer *pbuf)\r\n{\r\nstruct qlcnic_skb_frag *nf = &pbuf->frag_array[0];\r\nint i, nr_frags = skb_shinfo(skb)->nr_frags;\r\nfor (i = 0; i < nr_frags; i++) {\r\nnf = &pbuf->frag_array[i+1];\r\npci_unmap_page(pdev, nf->dma, nf->length, PCI_DMA_TODEVICE);\r\n}\r\nnf = &pbuf->frag_array[0];\r\npci_unmap_single(pdev, nf->dma, skb_headlen(skb), PCI_DMA_TODEVICE);\r\npbuf->skb = NULL;\r\n}\r\nstatic inline void qlcnic_clear_cmddesc(u64 *desc)\r\n{\r\ndesc[0] = 0ULL;\r\ndesc[2] = 0ULL;\r\ndesc[7] = 0ULL;\r\n}\r\nnetdev_tx_t qlcnic_xmit_frame(struct sk_buff *skb, struct net_device *netdev)\r\n{\r\nstruct qlcnic_adapter *adapter = netdev_priv(netdev);\r\nstruct qlcnic_host_tx_ring *tx_ring;\r\nstruct qlcnic_cmd_buffer *pbuf;\r\nstruct qlcnic_skb_frag *buffrag;\r\nstruct cmd_desc_type0 *hwdesc, *first_desc;\r\nstruct pci_dev *pdev;\r\nstruct ethhdr *phdr;\r\nint i, k, frag_count, delta = 0;\r\nu32 producer, num_txd;\r\nu16 protocol;\r\nbool l4_is_udp = false;\r\nif (!test_bit(__QLCNIC_DEV_UP, &adapter->state)) {\r\nnetif_tx_stop_all_queues(netdev);\r\nreturn NETDEV_TX_BUSY;\r\n}\r\nif (adapter->flags & QLCNIC_MACSPOOF) {\r\nphdr = (struct ethhdr *)skb->data;\r\nif (!ether_addr_equal(phdr->h_source, adapter->mac_addr))\r\ngoto drop_packet;\r\n}\r\ntx_ring = &adapter->tx_ring[skb_get_queue_mapping(skb)];\r\nnum_txd = tx_ring->num_desc;\r\nfrag_count = skb_shinfo(skb)->nr_frags + 1;\r\nif (!skb_is_gso(skb) && frag_count > QLCNIC_MAX_FRAGS_PER_TX) {\r\nfor (i = 0; i < (frag_count - QLCNIC_MAX_FRAGS_PER_TX); i++)\r\ndelta += skb_frag_size(&skb_shinfo(skb)->frags[i]);\r\nif (!__pskb_pull_tail(skb, delta))\r\ngoto drop_packet;\r\nfrag_count = 1 + skb_shinfo(skb)->nr_frags;\r\n}\r\nif (unlikely(qlcnic_tx_avail(tx_ring) <= TX_STOP_THRESH)) {\r\nnetif_tx_stop_queue(tx_ring->txq);\r\nif (qlcnic_tx_avail(tx_ring) > TX_STOP_THRESH) {\r\nnetif_tx_start_queue(tx_ring->txq);\r\n} else {\r\ntx_ring->tx_stats.xmit_off++;\r\nreturn NETDEV_TX_BUSY;\r\n}\r\n}\r\nproducer = tx_ring->producer;\r\npbuf = &tx_ring->cmd_buf_arr[producer];\r\npdev = adapter->pdev;\r\nfirst_desc = &tx_ring->desc_head[producer];\r\nhwdesc = &tx_ring->desc_head[producer];\r\nqlcnic_clear_cmddesc((u64 *)hwdesc);\r\nif (qlcnic_map_tx_skb(pdev, skb, pbuf)) {\r\nadapter->stats.tx_dma_map_error++;\r\ngoto drop_packet;\r\n}\r\npbuf->skb = skb;\r\npbuf->frag_count = frag_count;\r\nqlcnic_set_tx_frags_len(first_desc, frag_count, skb->len);\r\nqlcnic_set_tx_port(first_desc, adapter->portnum);\r\nfor (i = 0; i < frag_count; i++) {\r\nk = i % 4;\r\nif ((k == 0) && (i > 0)) {\r\nproducer = get_next_index(producer, num_txd);\r\nhwdesc = &tx_ring->desc_head[producer];\r\nqlcnic_clear_cmddesc((u64 *)hwdesc);\r\ntx_ring->cmd_buf_arr[producer].skb = NULL;\r\n}\r\nbuffrag = &pbuf->frag_array[i];\r\nhwdesc->buffer_length[k] = cpu_to_le16(buffrag->length);\r\nswitch (k) {\r\ncase 0:\r\nhwdesc->addr_buffer1 = cpu_to_le64(buffrag->dma);\r\nbreak;\r\ncase 1:\r\nhwdesc->addr_buffer2 = cpu_to_le64(buffrag->dma);\r\nbreak;\r\ncase 2:\r\nhwdesc->addr_buffer3 = cpu_to_le64(buffrag->dma);\r\nbreak;\r\ncase 3:\r\nhwdesc->addr_buffer4 = cpu_to_le64(buffrag->dma);\r\nbreak;\r\n}\r\n}\r\ntx_ring->producer = get_next_index(producer, num_txd);\r\nsmp_mb();\r\nprotocol = ntohs(skb->protocol);\r\nif (protocol == ETH_P_IP)\r\nl4_is_udp = ip_hdr(skb)->protocol == IPPROTO_UDP;\r\nelse if (protocol == ETH_P_IPV6)\r\nl4_is_udp = ipv6_hdr(skb)->nexthdr == IPPROTO_UDP;\r\nif (!skb->encapsulation || !l4_is_udp ||\r\n!qlcnic_encap_tx_offload(adapter)) {\r\nif (unlikely(qlcnic_tx_pkt(adapter, first_desc, skb,\r\ntx_ring)))\r\ngoto unwind_buff;\r\n} else {\r\nif (unlikely(qlcnic_tx_encap_pkt(adapter, first_desc,\r\nskb, tx_ring)))\r\ngoto unwind_buff;\r\n}\r\nif (adapter->drv_mac_learn)\r\nqlcnic_send_filter(adapter, first_desc, skb);\r\ntx_ring->tx_stats.tx_bytes += skb->len;\r\ntx_ring->tx_stats.xmit_called++;\r\nwmb();\r\nqlcnic_update_cmd_producer(tx_ring);\r\nreturn NETDEV_TX_OK;\r\nunwind_buff:\r\nqlcnic_unmap_buffers(pdev, skb, pbuf);\r\ndrop_packet:\r\nadapter->stats.txdropped++;\r\ndev_kfree_skb_any(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nvoid qlcnic_advert_link_change(struct qlcnic_adapter *adapter, int linkup)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nif (adapter->ahw->linkup && !linkup) {\r\nnetdev_info(netdev, "NIC Link is down\n");\r\nadapter->ahw->linkup = 0;\r\nnetif_carrier_off(netdev);\r\n} else if (!adapter->ahw->linkup && linkup) {\r\nadapter->ahw->linkup = 1;\r\nif (qlcnic_83xx_check(adapter) && adapter->ahw->lb_mode) {\r\nnetdev_info(netdev, "NIC Link is up for loopback test\n");\r\nreturn;\r\n}\r\nnetdev_info(netdev, "NIC Link is up\n");\r\nnetif_carrier_on(netdev);\r\n}\r\n}\r\nstatic int qlcnic_alloc_rx_skb(struct qlcnic_adapter *adapter,\r\nstruct qlcnic_host_rds_ring *rds_ring,\r\nstruct qlcnic_rx_buffer *buffer)\r\n{\r\nstruct sk_buff *skb;\r\ndma_addr_t dma;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nskb = netdev_alloc_skb(adapter->netdev, rds_ring->skb_size);\r\nif (!skb) {\r\nadapter->stats.skb_alloc_failure++;\r\nreturn -ENOMEM;\r\n}\r\nskb_reserve(skb, NET_IP_ALIGN);\r\ndma = pci_map_single(pdev, skb->data,\r\nrds_ring->dma_size, PCI_DMA_FROMDEVICE);\r\nif (pci_dma_mapping_error(pdev, dma)) {\r\nadapter->stats.rx_dma_map_error++;\r\ndev_kfree_skb_any(skb);\r\nreturn -ENOMEM;\r\n}\r\nbuffer->skb = skb;\r\nbuffer->dma = dma;\r\nreturn 0;\r\n}\r\nstatic void qlcnic_post_rx_buffers_nodb(struct qlcnic_adapter *adapter,\r\nstruct qlcnic_host_rds_ring *rds_ring,\r\nu8 ring_id)\r\n{\r\nstruct rcv_desc *pdesc;\r\nstruct qlcnic_rx_buffer *buffer;\r\nint count = 0;\r\nuint32_t producer, handle;\r\nstruct list_head *head;\r\nif (!spin_trylock(&rds_ring->lock))\r\nreturn;\r\nproducer = rds_ring->producer;\r\nhead = &rds_ring->free_list;\r\nwhile (!list_empty(head)) {\r\nbuffer = list_entry(head->next, struct qlcnic_rx_buffer, list);\r\nif (!buffer->skb) {\r\nif (qlcnic_alloc_rx_skb(adapter, rds_ring, buffer))\r\nbreak;\r\n}\r\ncount++;\r\nlist_del(&buffer->list);\r\npdesc = &rds_ring->desc_head[producer];\r\nhandle = qlcnic_get_ref_handle(adapter,\r\nbuffer->ref_handle, ring_id);\r\npdesc->reference_handle = cpu_to_le16(handle);\r\npdesc->buffer_length = cpu_to_le32(rds_ring->dma_size);\r\npdesc->addr_buffer = cpu_to_le64(buffer->dma);\r\nproducer = get_next_index(producer, rds_ring->num_desc);\r\n}\r\nif (count) {\r\nrds_ring->producer = producer;\r\nwritel((producer - 1) & (rds_ring->num_desc - 1),\r\nrds_ring->crb_rcv_producer);\r\n}\r\nspin_unlock(&rds_ring->lock);\r\n}\r\nstatic int qlcnic_process_cmd_ring(struct qlcnic_adapter *adapter,\r\nstruct qlcnic_host_tx_ring *tx_ring,\r\nint budget)\r\n{\r\nu32 sw_consumer, hw_consumer;\r\nint i, done, count = 0;\r\nstruct qlcnic_cmd_buffer *buffer;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct qlcnic_skb_frag *frag;\r\nif (!spin_trylock(&tx_ring->tx_clean_lock))\r\nreturn 1;\r\nsw_consumer = tx_ring->sw_consumer;\r\nhw_consumer = le32_to_cpu(*(tx_ring->hw_consumer));\r\nwhile (sw_consumer != hw_consumer) {\r\nbuffer = &tx_ring->cmd_buf_arr[sw_consumer];\r\nif (buffer->skb) {\r\nfrag = &buffer->frag_array[0];\r\npci_unmap_single(pdev, frag->dma, frag->length,\r\nPCI_DMA_TODEVICE);\r\nfrag->dma = 0ULL;\r\nfor (i = 1; i < buffer->frag_count; i++) {\r\nfrag++;\r\npci_unmap_page(pdev, frag->dma, frag->length,\r\nPCI_DMA_TODEVICE);\r\nfrag->dma = 0ULL;\r\n}\r\ntx_ring->tx_stats.xmit_finished++;\r\ndev_kfree_skb_any(buffer->skb);\r\nbuffer->skb = NULL;\r\n}\r\nsw_consumer = get_next_index(sw_consumer, tx_ring->num_desc);\r\nif (++count >= budget)\r\nbreak;\r\n}\r\ntx_ring->sw_consumer = sw_consumer;\r\nif (count && netif_running(netdev)) {\r\nsmp_mb();\r\nif (netif_tx_queue_stopped(tx_ring->txq) &&\r\nnetif_carrier_ok(netdev)) {\r\nif (qlcnic_tx_avail(tx_ring) > TX_STOP_THRESH) {\r\nnetif_tx_wake_queue(tx_ring->txq);\r\ntx_ring->tx_stats.xmit_on++;\r\n}\r\n}\r\nadapter->tx_timeo_cnt = 0;\r\n}\r\nhw_consumer = le32_to_cpu(*(tx_ring->hw_consumer));\r\ndone = (sw_consumer == hw_consumer);\r\nspin_unlock(&tx_ring->tx_clean_lock);\r\nreturn done;\r\n}\r\nstatic int qlcnic_poll(struct napi_struct *napi, int budget)\r\n{\r\nint tx_complete, work_done;\r\nstruct qlcnic_host_sds_ring *sds_ring;\r\nstruct qlcnic_adapter *adapter;\r\nstruct qlcnic_host_tx_ring *tx_ring;\r\nsds_ring = container_of(napi, struct qlcnic_host_sds_ring, napi);\r\nadapter = sds_ring->adapter;\r\ntx_ring = sds_ring->tx_ring;\r\ntx_complete = qlcnic_process_cmd_ring(adapter, tx_ring,\r\nbudget);\r\nwork_done = qlcnic_process_rcv_ring(sds_ring, budget);\r\nif (!tx_complete)\r\nwork_done = budget;\r\nif (work_done < budget) {\r\nnapi_complete(&sds_ring->napi);\r\nif (test_bit(__QLCNIC_DEV_UP, &adapter->state)) {\r\nqlcnic_enable_sds_intr(adapter, sds_ring);\r\nqlcnic_enable_tx_intr(adapter, tx_ring);\r\n}\r\n}\r\nreturn work_done;\r\n}\r\nstatic int qlcnic_tx_poll(struct napi_struct *napi, int budget)\r\n{\r\nstruct qlcnic_host_tx_ring *tx_ring;\r\nstruct qlcnic_adapter *adapter;\r\nint work_done;\r\ntx_ring = container_of(napi, struct qlcnic_host_tx_ring, napi);\r\nadapter = tx_ring->adapter;\r\nwork_done = qlcnic_process_cmd_ring(adapter, tx_ring, budget);\r\nif (work_done) {\r\nnapi_complete(&tx_ring->napi);\r\nif (test_bit(__QLCNIC_DEV_UP, &adapter->state))\r\nqlcnic_enable_tx_intr(adapter, tx_ring);\r\n} else {\r\nwork_done = budget;\r\n}\r\nreturn work_done;\r\n}\r\nstatic int qlcnic_rx_poll(struct napi_struct *napi, int budget)\r\n{\r\nstruct qlcnic_host_sds_ring *sds_ring;\r\nstruct qlcnic_adapter *adapter;\r\nint work_done;\r\nsds_ring = container_of(napi, struct qlcnic_host_sds_ring, napi);\r\nadapter = sds_ring->adapter;\r\nwork_done = qlcnic_process_rcv_ring(sds_ring, budget);\r\nif (work_done < budget) {\r\nnapi_complete(&sds_ring->napi);\r\nif (test_bit(__QLCNIC_DEV_UP, &adapter->state))\r\nqlcnic_enable_sds_intr(adapter, sds_ring);\r\n}\r\nreturn work_done;\r\n}\r\nstatic void qlcnic_handle_linkevent(struct qlcnic_adapter *adapter,\r\nstruct qlcnic_fw_msg *msg)\r\n{\r\nu32 cable_OUI;\r\nu16 cable_len, link_speed;\r\nu8 link_status, module, duplex, autoneg, lb_status = 0;\r\nstruct net_device *netdev = adapter->netdev;\r\nadapter->ahw->has_link_events = 1;\r\ncable_OUI = msg->body[1] & 0xffffffff;\r\ncable_len = (msg->body[1] >> 32) & 0xffff;\r\nlink_speed = (msg->body[1] >> 48) & 0xffff;\r\nlink_status = msg->body[2] & 0xff;\r\nduplex = (msg->body[2] >> 16) & 0xff;\r\nautoneg = (msg->body[2] >> 24) & 0xff;\r\nlb_status = (msg->body[2] >> 32) & 0x3;\r\nmodule = (msg->body[2] >> 8) & 0xff;\r\nif (module == LINKEVENT_MODULE_TWINAX_UNSUPPORTED_CABLE)\r\ndev_info(&netdev->dev,\r\n"unsupported cable: OUI 0x%x, length %d\n",\r\ncable_OUI, cable_len);\r\nelse if (module == LINKEVENT_MODULE_TWINAX_UNSUPPORTED_CABLELEN)\r\ndev_info(&netdev->dev, "unsupported cable length %d\n",\r\ncable_len);\r\nif (!link_status && (lb_status == QLCNIC_ILB_MODE ||\r\nlb_status == QLCNIC_ELB_MODE))\r\nadapter->ahw->loopback_state |= QLCNIC_LINKEVENT;\r\nqlcnic_advert_link_change(adapter, link_status);\r\nif (duplex == LINKEVENT_FULL_DUPLEX)\r\nadapter->ahw->link_duplex = DUPLEX_FULL;\r\nelse\r\nadapter->ahw->link_duplex = DUPLEX_HALF;\r\nadapter->ahw->module_type = module;\r\nadapter->ahw->link_autoneg = autoneg;\r\nif (link_status) {\r\nadapter->ahw->link_speed = link_speed;\r\n} else {\r\nadapter->ahw->link_speed = SPEED_UNKNOWN;\r\nadapter->ahw->link_duplex = DUPLEX_UNKNOWN;\r\n}\r\n}\r\nstatic void qlcnic_handle_fw_message(int desc_cnt, int index,\r\nstruct qlcnic_host_sds_ring *sds_ring)\r\n{\r\nstruct qlcnic_fw_msg msg;\r\nstruct status_desc *desc;\r\nstruct qlcnic_adapter *adapter;\r\nstruct device *dev;\r\nint i = 0, opcode, ret;\r\nwhile (desc_cnt > 0 && i < 8) {\r\ndesc = &sds_ring->desc_head[index];\r\nmsg.words[i++] = le64_to_cpu(desc->status_desc_data[0]);\r\nmsg.words[i++] = le64_to_cpu(desc->status_desc_data[1]);\r\nindex = get_next_index(index, sds_ring->num_desc);\r\ndesc_cnt--;\r\n}\r\nadapter = sds_ring->adapter;\r\ndev = &adapter->pdev->dev;\r\nopcode = qlcnic_get_nic_msg_opcode(msg.body[0]);\r\nswitch (opcode) {\r\ncase QLCNIC_C2H_OPCODE_GET_LINKEVENT_RESPONSE:\r\nqlcnic_handle_linkevent(adapter, &msg);\r\nbreak;\r\ncase QLCNIC_C2H_OPCODE_CONFIG_LOOPBACK:\r\nret = (u32)(msg.body[1]);\r\nswitch (ret) {\r\ncase 0:\r\nadapter->ahw->loopback_state |= QLCNIC_LB_RESPONSE;\r\nbreak;\r\ncase 1:\r\ndev_info(dev, "loopback already in progress\n");\r\nadapter->ahw->diag_cnt = -EINPROGRESS;\r\nbreak;\r\ncase 2:\r\ndev_info(dev, "loopback cable is not connected\n");\r\nadapter->ahw->diag_cnt = -ENODEV;\r\nbreak;\r\ndefault:\r\ndev_info(dev,\r\n"loopback configure request failed, err %x\n",\r\nret);\r\nadapter->ahw->diag_cnt = -EIO;\r\nbreak;\r\n}\r\nbreak;\r\ncase QLCNIC_C2H_OPCODE_GET_DCB_AEN:\r\nqlcnic_dcb_aen_handler(adapter->dcb, (void *)&msg);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nstatic struct sk_buff *qlcnic_process_rxbuf(struct qlcnic_adapter *adapter,\r\nstruct qlcnic_host_rds_ring *ring,\r\nu16 index, u16 cksum)\r\n{\r\nstruct qlcnic_rx_buffer *buffer;\r\nstruct sk_buff *skb;\r\nbuffer = &ring->rx_buf_arr[index];\r\nif (unlikely(buffer->skb == NULL)) {\r\nWARN_ON(1);\r\nreturn NULL;\r\n}\r\npci_unmap_single(adapter->pdev, buffer->dma, ring->dma_size,\r\nPCI_DMA_FROMDEVICE);\r\nskb = buffer->skb;\r\nif (likely((adapter->netdev->features & NETIF_F_RXCSUM) &&\r\n(cksum == STATUS_CKSUM_OK || cksum == STATUS_CKSUM_LOOP))) {\r\nadapter->stats.csummed++;\r\nskb->ip_summed = CHECKSUM_UNNECESSARY;\r\n} else {\r\nskb_checksum_none_assert(skb);\r\n}\r\nbuffer->skb = NULL;\r\nreturn skb;\r\n}\r\nstatic inline int qlcnic_check_rx_tagging(struct qlcnic_adapter *adapter,\r\nstruct sk_buff *skb, u16 *vlan_tag)\r\n{\r\nstruct ethhdr *eth_hdr;\r\nif (!__vlan_get_tag(skb, vlan_tag)) {\r\neth_hdr = (struct ethhdr *)skb->data;\r\nmemmove(skb->data + VLAN_HLEN, eth_hdr, ETH_ALEN * 2);\r\nskb_pull(skb, VLAN_HLEN);\r\n}\r\nif (!adapter->rx_pvid)\r\nreturn 0;\r\nif (*vlan_tag == adapter->rx_pvid) {\r\n*vlan_tag = 0xffff;\r\nreturn 0;\r\n}\r\nif (adapter->flags & QLCNIC_TAGGING_ENABLED)\r\nreturn 0;\r\nreturn -EINVAL;\r\n}\r\nstatic struct qlcnic_rx_buffer *\r\nqlcnic_process_rcv(struct qlcnic_adapter *adapter,\r\nstruct qlcnic_host_sds_ring *sds_ring, int ring,\r\nu64 sts_data0)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\r\nstruct qlcnic_rx_buffer *buffer;\r\nstruct sk_buff *skb;\r\nstruct qlcnic_host_rds_ring *rds_ring;\r\nint index, length, cksum, pkt_offset, is_lb_pkt;\r\nu16 vid = 0xffff, t_vid;\r\nif (unlikely(ring >= adapter->max_rds_rings))\r\nreturn NULL;\r\nrds_ring = &recv_ctx->rds_rings[ring];\r\nindex = qlcnic_get_sts_refhandle(sts_data0);\r\nif (unlikely(index >= rds_ring->num_desc))\r\nreturn NULL;\r\nbuffer = &rds_ring->rx_buf_arr[index];\r\nlength = qlcnic_get_sts_totallength(sts_data0);\r\ncksum = qlcnic_get_sts_status(sts_data0);\r\npkt_offset = qlcnic_get_sts_pkt_offset(sts_data0);\r\nskb = qlcnic_process_rxbuf(adapter, rds_ring, index, cksum);\r\nif (!skb)\r\nreturn buffer;\r\nif (adapter->rx_mac_learn) {\r\nt_vid = 0;\r\nis_lb_pkt = qlcnic_82xx_is_lb_pkt(sts_data0);\r\nqlcnic_add_lb_filter(adapter, skb, is_lb_pkt, t_vid);\r\n}\r\nif (length > rds_ring->skb_size)\r\nskb_put(skb, rds_ring->skb_size);\r\nelse\r\nskb_put(skb, length);\r\nif (pkt_offset)\r\nskb_pull(skb, pkt_offset);\r\nif (unlikely(qlcnic_check_rx_tagging(adapter, skb, &vid))) {\r\nadapter->stats.rxdropped++;\r\ndev_kfree_skb(skb);\r\nreturn buffer;\r\n}\r\nskb->protocol = eth_type_trans(skb, netdev);\r\nif (vid != 0xffff)\r\n__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vid);\r\nnapi_gro_receive(&sds_ring->napi, skb);\r\nadapter->stats.rx_pkts++;\r\nadapter->stats.rxbytes += length;\r\nreturn buffer;\r\n}\r\nstatic struct qlcnic_rx_buffer *\r\nqlcnic_process_lro(struct qlcnic_adapter *adapter,\r\nint ring, u64 sts_data0, u64 sts_data1)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\r\nstruct qlcnic_rx_buffer *buffer;\r\nstruct sk_buff *skb;\r\nstruct qlcnic_host_rds_ring *rds_ring;\r\nstruct iphdr *iph;\r\nstruct ipv6hdr *ipv6h;\r\nstruct tcphdr *th;\r\nbool push, timestamp;\r\nint index, l2_hdr_offset, l4_hdr_offset, is_lb_pkt;\r\nu16 lro_length, length, data_offset, t_vid, vid = 0xffff;\r\nu32 seq_number;\r\nif (unlikely(ring >= adapter->max_rds_rings))\r\nreturn NULL;\r\nrds_ring = &recv_ctx->rds_rings[ring];\r\nindex = qlcnic_get_lro_sts_refhandle(sts_data0);\r\nif (unlikely(index >= rds_ring->num_desc))\r\nreturn NULL;\r\nbuffer = &rds_ring->rx_buf_arr[index];\r\ntimestamp = qlcnic_get_lro_sts_timestamp(sts_data0);\r\nlro_length = qlcnic_get_lro_sts_length(sts_data0);\r\nl2_hdr_offset = qlcnic_get_lro_sts_l2_hdr_offset(sts_data0);\r\nl4_hdr_offset = qlcnic_get_lro_sts_l4_hdr_offset(sts_data0);\r\npush = qlcnic_get_lro_sts_push_flag(sts_data0);\r\nseq_number = qlcnic_get_lro_sts_seq_number(sts_data1);\r\nskb = qlcnic_process_rxbuf(adapter, rds_ring, index, STATUS_CKSUM_OK);\r\nif (!skb)\r\nreturn buffer;\r\nif (adapter->rx_mac_learn) {\r\nt_vid = 0;\r\nis_lb_pkt = qlcnic_82xx_is_lb_pkt(sts_data0);\r\nqlcnic_add_lb_filter(adapter, skb, is_lb_pkt, t_vid);\r\n}\r\nif (timestamp)\r\ndata_offset = l4_hdr_offset + QLC_TCP_TS_HDR_SIZE;\r\nelse\r\ndata_offset = l4_hdr_offset + QLC_TCP_HDR_SIZE;\r\nskb_put(skb, lro_length + data_offset);\r\nskb_pull(skb, l2_hdr_offset);\r\nif (unlikely(qlcnic_check_rx_tagging(adapter, skb, &vid))) {\r\nadapter->stats.rxdropped++;\r\ndev_kfree_skb(skb);\r\nreturn buffer;\r\n}\r\nskb->protocol = eth_type_trans(skb, netdev);\r\nif (ntohs(skb->protocol) == ETH_P_IPV6) {\r\nipv6h = (struct ipv6hdr *)skb->data;\r\nth = (struct tcphdr *)(skb->data + sizeof(struct ipv6hdr));\r\nlength = (th->doff << 2) + lro_length;\r\nipv6h->payload_len = htons(length);\r\n} else {\r\niph = (struct iphdr *)skb->data;\r\nth = (struct tcphdr *)(skb->data + (iph->ihl << 2));\r\nlength = (iph->ihl << 2) + (th->doff << 2) + lro_length;\r\ncsum_replace2(&iph->check, iph->tot_len, htons(length));\r\niph->tot_len = htons(length);\r\n}\r\nth->psh = push;\r\nth->seq = htonl(seq_number);\r\nlength = skb->len;\r\nif (adapter->flags & QLCNIC_FW_LRO_MSS_CAP) {\r\nskb_shinfo(skb)->gso_size = qlcnic_get_lro_sts_mss(sts_data1);\r\nif (skb->protocol == htons(ETH_P_IPV6))\r\nskb_shinfo(skb)->gso_type = SKB_GSO_TCPV6;\r\nelse\r\nskb_shinfo(skb)->gso_type = SKB_GSO_TCPV4;\r\n}\r\nif (vid != 0xffff)\r\n__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vid);\r\nnetif_receive_skb(skb);\r\nadapter->stats.lro_pkts++;\r\nadapter->stats.lrobytes += length;\r\nreturn buffer;\r\n}\r\nstatic int qlcnic_process_rcv_ring(struct qlcnic_host_sds_ring *sds_ring, int max)\r\n{\r\nstruct qlcnic_host_rds_ring *rds_ring;\r\nstruct qlcnic_adapter *adapter = sds_ring->adapter;\r\nstruct list_head *cur;\r\nstruct status_desc *desc;\r\nstruct qlcnic_rx_buffer *rxbuf;\r\nint opcode, desc_cnt, count = 0;\r\nu64 sts_data0, sts_data1;\r\nu8 ring;\r\nu32 consumer = sds_ring->consumer;\r\nwhile (count < max) {\r\ndesc = &sds_ring->desc_head[consumer];\r\nsts_data0 = le64_to_cpu(desc->status_desc_data[0]);\r\nif (!(sts_data0 & STATUS_OWNER_HOST))\r\nbreak;\r\ndesc_cnt = qlcnic_get_sts_desc_cnt(sts_data0);\r\nopcode = qlcnic_get_sts_opcode(sts_data0);\r\nswitch (opcode) {\r\ncase QLCNIC_RXPKT_DESC:\r\ncase QLCNIC_OLD_RXPKT_DESC:\r\ncase QLCNIC_SYN_OFFLOAD:\r\nring = qlcnic_get_sts_type(sts_data0);\r\nrxbuf = qlcnic_process_rcv(adapter, sds_ring, ring,\r\nsts_data0);\r\nbreak;\r\ncase QLCNIC_LRO_DESC:\r\nring = qlcnic_get_lro_sts_type(sts_data0);\r\nsts_data1 = le64_to_cpu(desc->status_desc_data[1]);\r\nrxbuf = qlcnic_process_lro(adapter, ring, sts_data0,\r\nsts_data1);\r\nbreak;\r\ncase QLCNIC_RESPONSE_DESC:\r\nqlcnic_handle_fw_message(desc_cnt, consumer, sds_ring);\r\ndefault:\r\ngoto skip;\r\n}\r\nWARN_ON(desc_cnt > 1);\r\nif (likely(rxbuf))\r\nlist_add_tail(&rxbuf->list, &sds_ring->free_list[ring]);\r\nelse\r\nadapter->stats.null_rxbuf++;\r\nskip:\r\nfor (; desc_cnt > 0; desc_cnt--) {\r\ndesc = &sds_ring->desc_head[consumer];\r\ndesc->status_desc_data[0] = QLCNIC_DESC_OWNER_FW;\r\nconsumer = get_next_index(consumer, sds_ring->num_desc);\r\n}\r\ncount++;\r\n}\r\nfor (ring = 0; ring < adapter->max_rds_rings; ring++) {\r\nrds_ring = &adapter->recv_ctx->rds_rings[ring];\r\nif (!list_empty(&sds_ring->free_list[ring])) {\r\nlist_for_each(cur, &sds_ring->free_list[ring]) {\r\nrxbuf = list_entry(cur, struct qlcnic_rx_buffer,\r\nlist);\r\nqlcnic_alloc_rx_skb(adapter, rds_ring, rxbuf);\r\n}\r\nspin_lock(&rds_ring->lock);\r\nlist_splice_tail_init(&sds_ring->free_list[ring],\r\n&rds_ring->free_list);\r\nspin_unlock(&rds_ring->lock);\r\n}\r\nqlcnic_post_rx_buffers_nodb(adapter, rds_ring, ring);\r\n}\r\nif (count) {\r\nsds_ring->consumer = consumer;\r\nwritel(consumer, sds_ring->crb_sts_consumer);\r\n}\r\nreturn count;\r\n}\r\nvoid qlcnic_post_rx_buffers(struct qlcnic_adapter *adapter,\r\nstruct qlcnic_host_rds_ring *rds_ring, u8 ring_id)\r\n{\r\nstruct rcv_desc *pdesc;\r\nstruct qlcnic_rx_buffer *buffer;\r\nint count = 0;\r\nu32 producer, handle;\r\nstruct list_head *head;\r\nproducer = rds_ring->producer;\r\nhead = &rds_ring->free_list;\r\nwhile (!list_empty(head)) {\r\nbuffer = list_entry(head->next, struct qlcnic_rx_buffer, list);\r\nif (!buffer->skb) {\r\nif (qlcnic_alloc_rx_skb(adapter, rds_ring, buffer))\r\nbreak;\r\n}\r\ncount++;\r\nlist_del(&buffer->list);\r\npdesc = &rds_ring->desc_head[producer];\r\npdesc->addr_buffer = cpu_to_le64(buffer->dma);\r\nhandle = qlcnic_get_ref_handle(adapter, buffer->ref_handle,\r\nring_id);\r\npdesc->reference_handle = cpu_to_le16(handle);\r\npdesc->buffer_length = cpu_to_le32(rds_ring->dma_size);\r\nproducer = get_next_index(producer, rds_ring->num_desc);\r\n}\r\nif (count) {\r\nrds_ring->producer = producer;\r\nwritel((producer-1) & (rds_ring->num_desc-1),\r\nrds_ring->crb_rcv_producer);\r\n}\r\n}\r\nstatic void dump_skb(struct sk_buff *skb, struct qlcnic_adapter *adapter)\r\n{\r\nif (adapter->ahw->msg_enable & NETIF_MSG_DRV) {\r\nchar prefix[30];\r\nscnprintf(prefix, sizeof(prefix), "%s: %s: ",\r\ndev_name(&adapter->pdev->dev), __func__);\r\nprint_hex_dump_debug(prefix, DUMP_PREFIX_NONE, 16, 1,\r\nskb->data, skb->len, true);\r\n}\r\n}\r\nstatic void qlcnic_process_rcv_diag(struct qlcnic_adapter *adapter, int ring,\r\nu64 sts_data0)\r\n{\r\nstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\r\nstruct sk_buff *skb;\r\nstruct qlcnic_host_rds_ring *rds_ring;\r\nint index, length, cksum, pkt_offset;\r\nif (unlikely(ring >= adapter->max_rds_rings))\r\nreturn;\r\nrds_ring = &recv_ctx->rds_rings[ring];\r\nindex = qlcnic_get_sts_refhandle(sts_data0);\r\nlength = qlcnic_get_sts_totallength(sts_data0);\r\nif (unlikely(index >= rds_ring->num_desc))\r\nreturn;\r\ncksum = qlcnic_get_sts_status(sts_data0);\r\npkt_offset = qlcnic_get_sts_pkt_offset(sts_data0);\r\nskb = qlcnic_process_rxbuf(adapter, rds_ring, index, cksum);\r\nif (!skb)\r\nreturn;\r\nif (length > rds_ring->skb_size)\r\nskb_put(skb, rds_ring->skb_size);\r\nelse\r\nskb_put(skb, length);\r\nif (pkt_offset)\r\nskb_pull(skb, pkt_offset);\r\nif (!qlcnic_check_loopback_buff(skb->data, adapter->mac_addr))\r\nadapter->ahw->diag_cnt++;\r\nelse\r\ndump_skb(skb, adapter);\r\ndev_kfree_skb_any(skb);\r\nadapter->stats.rx_pkts++;\r\nadapter->stats.rxbytes += length;\r\nreturn;\r\n}\r\nvoid qlcnic_82xx_process_rcv_ring_diag(struct qlcnic_host_sds_ring *sds_ring)\r\n{\r\nstruct qlcnic_adapter *adapter = sds_ring->adapter;\r\nstruct status_desc *desc;\r\nu64 sts_data0;\r\nint ring, opcode, desc_cnt;\r\nu32 consumer = sds_ring->consumer;\r\ndesc = &sds_ring->desc_head[consumer];\r\nsts_data0 = le64_to_cpu(desc->status_desc_data[0]);\r\nif (!(sts_data0 & STATUS_OWNER_HOST))\r\nreturn;\r\ndesc_cnt = qlcnic_get_sts_desc_cnt(sts_data0);\r\nopcode = qlcnic_get_sts_opcode(sts_data0);\r\nswitch (opcode) {\r\ncase QLCNIC_RESPONSE_DESC:\r\nqlcnic_handle_fw_message(desc_cnt, consumer, sds_ring);\r\nbreak;\r\ndefault:\r\nring = qlcnic_get_sts_type(sts_data0);\r\nqlcnic_process_rcv_diag(adapter, ring, sts_data0);\r\nbreak;\r\n}\r\nfor (; desc_cnt > 0; desc_cnt--) {\r\ndesc = &sds_ring->desc_head[consumer];\r\ndesc->status_desc_data[0] = cpu_to_le64(STATUS_OWNER_PHANTOM);\r\nconsumer = get_next_index(consumer, sds_ring->num_desc);\r\n}\r\nsds_ring->consumer = consumer;\r\nwritel(consumer, sds_ring->crb_sts_consumer);\r\n}\r\nint qlcnic_82xx_napi_add(struct qlcnic_adapter *adapter,\r\nstruct net_device *netdev)\r\n{\r\nint ring;\r\nstruct qlcnic_host_sds_ring *sds_ring;\r\nstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\r\nstruct qlcnic_host_tx_ring *tx_ring;\r\nif (qlcnic_alloc_sds_rings(recv_ctx, adapter->drv_sds_rings))\r\nreturn -ENOMEM;\r\nfor (ring = 0; ring < adapter->drv_sds_rings; ring++) {\r\nsds_ring = &recv_ctx->sds_rings[ring];\r\nif (qlcnic_check_multi_tx(adapter) &&\r\n!adapter->ahw->diag_test) {\r\nnetif_napi_add(netdev, &sds_ring->napi, qlcnic_rx_poll,\r\nNAPI_POLL_WEIGHT);\r\n} else {\r\nif (ring == (adapter->drv_sds_rings - 1))\r\nnetif_napi_add(netdev, &sds_ring->napi,\r\nqlcnic_poll,\r\nNAPI_POLL_WEIGHT);\r\nelse\r\nnetif_napi_add(netdev, &sds_ring->napi,\r\nqlcnic_rx_poll,\r\nNAPI_POLL_WEIGHT);\r\n}\r\n}\r\nif (qlcnic_alloc_tx_rings(adapter, netdev)) {\r\nqlcnic_free_sds_rings(recv_ctx);\r\nreturn -ENOMEM;\r\n}\r\nif (qlcnic_check_multi_tx(adapter) && !adapter->ahw->diag_test) {\r\nfor (ring = 0; ring < adapter->drv_tx_rings; ring++) {\r\ntx_ring = &adapter->tx_ring[ring];\r\nnetif_tx_napi_add(netdev, &tx_ring->napi, qlcnic_tx_poll,\r\nNAPI_POLL_WEIGHT);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nvoid qlcnic_82xx_napi_del(struct qlcnic_adapter *adapter)\r\n{\r\nint ring;\r\nstruct qlcnic_host_sds_ring *sds_ring;\r\nstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\r\nstruct qlcnic_host_tx_ring *tx_ring;\r\nfor (ring = 0; ring < adapter->drv_sds_rings; ring++) {\r\nsds_ring = &recv_ctx->sds_rings[ring];\r\nnetif_napi_del(&sds_ring->napi);\r\n}\r\nqlcnic_free_sds_rings(adapter->recv_ctx);\r\nif (qlcnic_check_multi_tx(adapter) && !adapter->ahw->diag_test) {\r\nfor (ring = 0; ring < adapter->drv_tx_rings; ring++) {\r\ntx_ring = &adapter->tx_ring[ring];\r\nnetif_napi_del(&tx_ring->napi);\r\n}\r\n}\r\nqlcnic_free_tx_rings(adapter);\r\n}\r\nvoid qlcnic_82xx_napi_enable(struct qlcnic_adapter *adapter)\r\n{\r\nint ring;\r\nstruct qlcnic_host_sds_ring *sds_ring;\r\nstruct qlcnic_host_tx_ring *tx_ring;\r\nstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\r\nif (adapter->is_up != QLCNIC_ADAPTER_UP_MAGIC)\r\nreturn;\r\nfor (ring = 0; ring < adapter->drv_sds_rings; ring++) {\r\nsds_ring = &recv_ctx->sds_rings[ring];\r\nnapi_enable(&sds_ring->napi);\r\nqlcnic_enable_sds_intr(adapter, sds_ring);\r\n}\r\nif (qlcnic_check_multi_tx(adapter) &&\r\n(adapter->flags & QLCNIC_MSIX_ENABLED) &&\r\n!adapter->ahw->diag_test) {\r\nfor (ring = 0; ring < adapter->drv_tx_rings; ring++) {\r\ntx_ring = &adapter->tx_ring[ring];\r\nnapi_enable(&tx_ring->napi);\r\nqlcnic_enable_tx_intr(adapter, tx_ring);\r\n}\r\n}\r\n}\r\nvoid qlcnic_82xx_napi_disable(struct qlcnic_adapter *adapter)\r\n{\r\nint ring;\r\nstruct qlcnic_host_sds_ring *sds_ring;\r\nstruct qlcnic_host_tx_ring *tx_ring;\r\nstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\r\nif (adapter->is_up != QLCNIC_ADAPTER_UP_MAGIC)\r\nreturn;\r\nfor (ring = 0; ring < adapter->drv_sds_rings; ring++) {\r\nsds_ring = &recv_ctx->sds_rings[ring];\r\nqlcnic_disable_sds_intr(adapter, sds_ring);\r\nnapi_synchronize(&sds_ring->napi);\r\nnapi_disable(&sds_ring->napi);\r\n}\r\nif ((adapter->flags & QLCNIC_MSIX_ENABLED) &&\r\n!adapter->ahw->diag_test &&\r\nqlcnic_check_multi_tx(adapter)) {\r\nfor (ring = 0; ring < adapter->drv_tx_rings; ring++) {\r\ntx_ring = &adapter->tx_ring[ring];\r\nqlcnic_disable_tx_intr(adapter, tx_ring);\r\nnapi_synchronize(&tx_ring->napi);\r\nnapi_disable(&tx_ring->napi);\r\n}\r\n}\r\n}\r\nstatic inline int qlcnic_83xx_is_lb_pkt(u64 sts_data, int lro_pkt)\r\n{\r\nif (lro_pkt)\r\nreturn (sts_data & QLC_83XX_LRO_LB_PKT) ? 1 : 0;\r\nelse\r\nreturn (sts_data & QLC_83XX_NORMAL_LB_PKT) ? 1 : 0;\r\n}\r\nstatic inline u8 qlcnic_encap_length(u64 sts_data)\r\n{\r\nreturn sts_data & QLCNIC_ENCAP_LENGTH_MASK;\r\n}\r\nstatic struct qlcnic_rx_buffer *\r\nqlcnic_83xx_process_rcv(struct qlcnic_adapter *adapter,\r\nstruct qlcnic_host_sds_ring *sds_ring,\r\nu8 ring, u64 sts_data[])\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\r\nstruct qlcnic_rx_buffer *buffer;\r\nstruct sk_buff *skb;\r\nstruct qlcnic_host_rds_ring *rds_ring;\r\nint index, length, cksum, is_lb_pkt;\r\nu16 vid = 0xffff;\r\nint err;\r\nif (unlikely(ring >= adapter->max_rds_rings))\r\nreturn NULL;\r\nrds_ring = &recv_ctx->rds_rings[ring];\r\nindex = qlcnic_83xx_hndl(sts_data[0]);\r\nif (unlikely(index >= rds_ring->num_desc))\r\nreturn NULL;\r\nbuffer = &rds_ring->rx_buf_arr[index];\r\nlength = qlcnic_83xx_pktln(sts_data[0]);\r\ncksum = qlcnic_83xx_csum_status(sts_data[1]);\r\nskb = qlcnic_process_rxbuf(adapter, rds_ring, index, cksum);\r\nif (!skb)\r\nreturn buffer;\r\nif (length > rds_ring->skb_size)\r\nskb_put(skb, rds_ring->skb_size);\r\nelse\r\nskb_put(skb, length);\r\nerr = qlcnic_check_rx_tagging(adapter, skb, &vid);\r\nif (adapter->rx_mac_learn) {\r\nis_lb_pkt = qlcnic_83xx_is_lb_pkt(sts_data[1], 0);\r\nqlcnic_add_lb_filter(adapter, skb, is_lb_pkt, vid);\r\n}\r\nif (unlikely(err)) {\r\nadapter->stats.rxdropped++;\r\ndev_kfree_skb(skb);\r\nreturn buffer;\r\n}\r\nskb->protocol = eth_type_trans(skb, netdev);\r\nif (qlcnic_encap_length(sts_data[1]) &&\r\nskb->ip_summed == CHECKSUM_UNNECESSARY) {\r\nskb->csum_level = 1;\r\nadapter->stats.encap_rx_csummed++;\r\n}\r\nif (vid != 0xffff)\r\n__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vid);\r\nnapi_gro_receive(&sds_ring->napi, skb);\r\nadapter->stats.rx_pkts++;\r\nadapter->stats.rxbytes += length;\r\nreturn buffer;\r\n}\r\nstatic struct qlcnic_rx_buffer *\r\nqlcnic_83xx_process_lro(struct qlcnic_adapter *adapter,\r\nu8 ring, u64 sts_data[])\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\r\nstruct qlcnic_rx_buffer *buffer;\r\nstruct sk_buff *skb;\r\nstruct qlcnic_host_rds_ring *rds_ring;\r\nstruct iphdr *iph;\r\nstruct ipv6hdr *ipv6h;\r\nstruct tcphdr *th;\r\nbool push;\r\nint l2_hdr_offset, l4_hdr_offset;\r\nint index, is_lb_pkt;\r\nu16 lro_length, length, data_offset, gso_size;\r\nu16 vid = 0xffff;\r\nint err;\r\nif (unlikely(ring >= adapter->max_rds_rings))\r\nreturn NULL;\r\nrds_ring = &recv_ctx->rds_rings[ring];\r\nindex = qlcnic_83xx_hndl(sts_data[0]);\r\nif (unlikely(index >= rds_ring->num_desc))\r\nreturn NULL;\r\nbuffer = &rds_ring->rx_buf_arr[index];\r\nlro_length = qlcnic_83xx_lro_pktln(sts_data[0]);\r\nl2_hdr_offset = qlcnic_83xx_l2_hdr_off(sts_data[1]);\r\nl4_hdr_offset = qlcnic_83xx_l4_hdr_off(sts_data[1]);\r\npush = qlcnic_83xx_is_psh_bit(sts_data[1]);\r\nskb = qlcnic_process_rxbuf(adapter, rds_ring, index, STATUS_CKSUM_OK);\r\nif (!skb)\r\nreturn buffer;\r\nif (qlcnic_83xx_is_tstamp(sts_data[1]))\r\ndata_offset = l4_hdr_offset + QLCNIC_TCP_TS_HDR_SIZE;\r\nelse\r\ndata_offset = l4_hdr_offset + QLCNIC_TCP_HDR_SIZE;\r\nskb_put(skb, lro_length + data_offset);\r\nskb_pull(skb, l2_hdr_offset);\r\nerr = qlcnic_check_rx_tagging(adapter, skb, &vid);\r\nif (adapter->rx_mac_learn) {\r\nis_lb_pkt = qlcnic_83xx_is_lb_pkt(sts_data[1], 1);\r\nqlcnic_add_lb_filter(adapter, skb, is_lb_pkt, vid);\r\n}\r\nif (unlikely(err)) {\r\nadapter->stats.rxdropped++;\r\ndev_kfree_skb(skb);\r\nreturn buffer;\r\n}\r\nskb->protocol = eth_type_trans(skb, netdev);\r\nif (ntohs(skb->protocol) == ETH_P_IPV6) {\r\nipv6h = (struct ipv6hdr *)skb->data;\r\nth = (struct tcphdr *)(skb->data + sizeof(struct ipv6hdr));\r\nlength = (th->doff << 2) + lro_length;\r\nipv6h->payload_len = htons(length);\r\n} else {\r\niph = (struct iphdr *)skb->data;\r\nth = (struct tcphdr *)(skb->data + (iph->ihl << 2));\r\nlength = (iph->ihl << 2) + (th->doff << 2) + lro_length;\r\ncsum_replace2(&iph->check, iph->tot_len, htons(length));\r\niph->tot_len = htons(length);\r\n}\r\nth->psh = push;\r\nlength = skb->len;\r\nif (adapter->flags & QLCNIC_FW_LRO_MSS_CAP) {\r\ngso_size = qlcnic_83xx_get_lro_sts_mss(sts_data[0]);\r\nskb_shinfo(skb)->gso_size = gso_size;\r\nif (skb->protocol == htons(ETH_P_IPV6))\r\nskb_shinfo(skb)->gso_type = SKB_GSO_TCPV6;\r\nelse\r\nskb_shinfo(skb)->gso_type = SKB_GSO_TCPV4;\r\n}\r\nif (vid != 0xffff)\r\n__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vid);\r\nnetif_receive_skb(skb);\r\nadapter->stats.lro_pkts++;\r\nadapter->stats.lrobytes += length;\r\nreturn buffer;\r\n}\r\nstatic int qlcnic_83xx_process_rcv_ring(struct qlcnic_host_sds_ring *sds_ring,\r\nint max)\r\n{\r\nstruct qlcnic_host_rds_ring *rds_ring;\r\nstruct qlcnic_adapter *adapter = sds_ring->adapter;\r\nstruct list_head *cur;\r\nstruct status_desc *desc;\r\nstruct qlcnic_rx_buffer *rxbuf = NULL;\r\nu8 ring;\r\nu64 sts_data[2];\r\nint count = 0, opcode;\r\nu32 consumer = sds_ring->consumer;\r\nwhile (count < max) {\r\ndesc = &sds_ring->desc_head[consumer];\r\nsts_data[1] = le64_to_cpu(desc->status_desc_data[1]);\r\nopcode = qlcnic_83xx_opcode(sts_data[1]);\r\nif (!opcode)\r\nbreak;\r\nsts_data[0] = le64_to_cpu(desc->status_desc_data[0]);\r\nring = QLCNIC_FETCH_RING_ID(sts_data[0]);\r\nswitch (opcode) {\r\ncase QLC_83XX_REG_DESC:\r\nrxbuf = qlcnic_83xx_process_rcv(adapter, sds_ring,\r\nring, sts_data);\r\nbreak;\r\ncase QLC_83XX_LRO_DESC:\r\nrxbuf = qlcnic_83xx_process_lro(adapter, ring,\r\nsts_data);\r\nbreak;\r\ndefault:\r\ndev_info(&adapter->pdev->dev,\r\n"Unknown opcode: 0x%x\n", opcode);\r\ngoto skip;\r\n}\r\nif (likely(rxbuf))\r\nlist_add_tail(&rxbuf->list, &sds_ring->free_list[ring]);\r\nelse\r\nadapter->stats.null_rxbuf++;\r\nskip:\r\ndesc = &sds_ring->desc_head[consumer];\r\ndesc->status_desc_data[1] = 0;\r\nconsumer = get_next_index(consumer, sds_ring->num_desc);\r\ncount++;\r\n}\r\nfor (ring = 0; ring < adapter->max_rds_rings; ring++) {\r\nrds_ring = &adapter->recv_ctx->rds_rings[ring];\r\nif (!list_empty(&sds_ring->free_list[ring])) {\r\nlist_for_each(cur, &sds_ring->free_list[ring]) {\r\nrxbuf = list_entry(cur, struct qlcnic_rx_buffer,\r\nlist);\r\nqlcnic_alloc_rx_skb(adapter, rds_ring, rxbuf);\r\n}\r\nspin_lock(&rds_ring->lock);\r\nlist_splice_tail_init(&sds_ring->free_list[ring],\r\n&rds_ring->free_list);\r\nspin_unlock(&rds_ring->lock);\r\n}\r\nqlcnic_post_rx_buffers_nodb(adapter, rds_ring, ring);\r\n}\r\nif (count) {\r\nsds_ring->consumer = consumer;\r\nwritel(consumer, sds_ring->crb_sts_consumer);\r\n}\r\nreturn count;\r\n}\r\nstatic int qlcnic_83xx_msix_sriov_vf_poll(struct napi_struct *napi, int budget)\r\n{\r\nint tx_complete;\r\nint work_done;\r\nstruct qlcnic_host_sds_ring *sds_ring;\r\nstruct qlcnic_adapter *adapter;\r\nstruct qlcnic_host_tx_ring *tx_ring;\r\nsds_ring = container_of(napi, struct qlcnic_host_sds_ring, napi);\r\nadapter = sds_ring->adapter;\r\ntx_ring = adapter->tx_ring;\r\ntx_complete = qlcnic_process_cmd_ring(adapter, tx_ring, budget);\r\nwork_done = qlcnic_83xx_process_rcv_ring(sds_ring, budget);\r\nif (!tx_complete)\r\nwork_done = budget;\r\nif (work_done < budget) {\r\nnapi_complete(&sds_ring->napi);\r\nqlcnic_enable_sds_intr(adapter, sds_ring);\r\n}\r\nreturn work_done;\r\n}\r\nstatic int qlcnic_83xx_poll(struct napi_struct *napi, int budget)\r\n{\r\nint tx_complete;\r\nint work_done;\r\nstruct qlcnic_host_sds_ring *sds_ring;\r\nstruct qlcnic_adapter *adapter;\r\nstruct qlcnic_host_tx_ring *tx_ring;\r\nsds_ring = container_of(napi, struct qlcnic_host_sds_ring, napi);\r\nadapter = sds_ring->adapter;\r\ntx_ring = adapter->tx_ring;\r\ntx_complete = qlcnic_process_cmd_ring(adapter, tx_ring, budget);\r\nwork_done = qlcnic_83xx_process_rcv_ring(sds_ring, budget);\r\nif (!tx_complete)\r\nwork_done = budget;\r\nif (work_done < budget) {\r\nnapi_complete(&sds_ring->napi);\r\nqlcnic_enable_sds_intr(adapter, sds_ring);\r\n}\r\nreturn work_done;\r\n}\r\nstatic int qlcnic_83xx_msix_tx_poll(struct napi_struct *napi, int budget)\r\n{\r\nint work_done;\r\nstruct qlcnic_host_tx_ring *tx_ring;\r\nstruct qlcnic_adapter *adapter;\r\ntx_ring = container_of(napi, struct qlcnic_host_tx_ring, napi);\r\nadapter = tx_ring->adapter;\r\nwork_done = qlcnic_process_cmd_ring(adapter, tx_ring, budget);\r\nif (work_done) {\r\nnapi_complete(&tx_ring->napi);\r\nif (test_bit(__QLCNIC_DEV_UP , &adapter->state))\r\nqlcnic_enable_tx_intr(adapter, tx_ring);\r\n} else {\r\nwork_done = budget;\r\n}\r\nreturn work_done;\r\n}\r\nstatic int qlcnic_83xx_rx_poll(struct napi_struct *napi, int budget)\r\n{\r\nint work_done;\r\nstruct qlcnic_host_sds_ring *sds_ring;\r\nstruct qlcnic_adapter *adapter;\r\nsds_ring = container_of(napi, struct qlcnic_host_sds_ring, napi);\r\nadapter = sds_ring->adapter;\r\nwork_done = qlcnic_83xx_process_rcv_ring(sds_ring, budget);\r\nif (work_done < budget) {\r\nnapi_complete(&sds_ring->napi);\r\nif (test_bit(__QLCNIC_DEV_UP, &adapter->state))\r\nqlcnic_enable_sds_intr(adapter, sds_ring);\r\n}\r\nreturn work_done;\r\n}\r\nvoid qlcnic_83xx_napi_enable(struct qlcnic_adapter *adapter)\r\n{\r\nint ring;\r\nstruct qlcnic_host_sds_ring *sds_ring;\r\nstruct qlcnic_host_tx_ring *tx_ring;\r\nstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\r\nif (adapter->is_up != QLCNIC_ADAPTER_UP_MAGIC)\r\nreturn;\r\nfor (ring = 0; ring < adapter->drv_sds_rings; ring++) {\r\nsds_ring = &recv_ctx->sds_rings[ring];\r\nnapi_enable(&sds_ring->napi);\r\nif (adapter->flags & QLCNIC_MSIX_ENABLED)\r\nqlcnic_enable_sds_intr(adapter, sds_ring);\r\n}\r\nif ((adapter->flags & QLCNIC_MSIX_ENABLED) &&\r\n!(adapter->flags & QLCNIC_TX_INTR_SHARED)) {\r\nfor (ring = 0; ring < adapter->drv_tx_rings; ring++) {\r\ntx_ring = &adapter->tx_ring[ring];\r\nnapi_enable(&tx_ring->napi);\r\nqlcnic_enable_tx_intr(adapter, tx_ring);\r\n}\r\n}\r\n}\r\nvoid qlcnic_83xx_napi_disable(struct qlcnic_adapter *adapter)\r\n{\r\nint ring;\r\nstruct qlcnic_host_sds_ring *sds_ring;\r\nstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\r\nstruct qlcnic_host_tx_ring *tx_ring;\r\nif (adapter->is_up != QLCNIC_ADAPTER_UP_MAGIC)\r\nreturn;\r\nfor (ring = 0; ring < adapter->drv_sds_rings; ring++) {\r\nsds_ring = &recv_ctx->sds_rings[ring];\r\nif (adapter->flags & QLCNIC_MSIX_ENABLED)\r\nqlcnic_disable_sds_intr(adapter, sds_ring);\r\nnapi_synchronize(&sds_ring->napi);\r\nnapi_disable(&sds_ring->napi);\r\n}\r\nif ((adapter->flags & QLCNIC_MSIX_ENABLED) &&\r\n!(adapter->flags & QLCNIC_TX_INTR_SHARED)) {\r\nfor (ring = 0; ring < adapter->drv_tx_rings; ring++) {\r\ntx_ring = &adapter->tx_ring[ring];\r\nqlcnic_disable_tx_intr(adapter, tx_ring);\r\nnapi_synchronize(&tx_ring->napi);\r\nnapi_disable(&tx_ring->napi);\r\n}\r\n}\r\n}\r\nint qlcnic_83xx_napi_add(struct qlcnic_adapter *adapter,\r\nstruct net_device *netdev)\r\n{\r\nint ring;\r\nstruct qlcnic_host_sds_ring *sds_ring;\r\nstruct qlcnic_host_tx_ring *tx_ring;\r\nstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\r\nif (qlcnic_alloc_sds_rings(recv_ctx, adapter->drv_sds_rings))\r\nreturn -ENOMEM;\r\nfor (ring = 0; ring < adapter->drv_sds_rings; ring++) {\r\nsds_ring = &recv_ctx->sds_rings[ring];\r\nif (adapter->flags & QLCNIC_MSIX_ENABLED) {\r\nif (!(adapter->flags & QLCNIC_TX_INTR_SHARED))\r\nnetif_napi_add(netdev, &sds_ring->napi,\r\nqlcnic_83xx_rx_poll,\r\nNAPI_POLL_WEIGHT);\r\nelse\r\nnetif_napi_add(netdev, &sds_ring->napi,\r\nqlcnic_83xx_msix_sriov_vf_poll,\r\nNAPI_POLL_WEIGHT);\r\n} else {\r\nnetif_napi_add(netdev, &sds_ring->napi,\r\nqlcnic_83xx_poll,\r\nNAPI_POLL_WEIGHT);\r\n}\r\n}\r\nif (qlcnic_alloc_tx_rings(adapter, netdev)) {\r\nqlcnic_free_sds_rings(recv_ctx);\r\nreturn -ENOMEM;\r\n}\r\nif ((adapter->flags & QLCNIC_MSIX_ENABLED) &&\r\n!(adapter->flags & QLCNIC_TX_INTR_SHARED)) {\r\nfor (ring = 0; ring < adapter->drv_tx_rings; ring++) {\r\ntx_ring = &adapter->tx_ring[ring];\r\nnetif_tx_napi_add(netdev, &tx_ring->napi,\r\nqlcnic_83xx_msix_tx_poll,\r\nNAPI_POLL_WEIGHT);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nvoid qlcnic_83xx_napi_del(struct qlcnic_adapter *adapter)\r\n{\r\nint ring;\r\nstruct qlcnic_host_sds_ring *sds_ring;\r\nstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\r\nstruct qlcnic_host_tx_ring *tx_ring;\r\nfor (ring = 0; ring < adapter->drv_sds_rings; ring++) {\r\nsds_ring = &recv_ctx->sds_rings[ring];\r\nnetif_napi_del(&sds_ring->napi);\r\n}\r\nqlcnic_free_sds_rings(adapter->recv_ctx);\r\nif ((adapter->flags & QLCNIC_MSIX_ENABLED) &&\r\n!(adapter->flags & QLCNIC_TX_INTR_SHARED)) {\r\nfor (ring = 0; ring < adapter->drv_tx_rings; ring++) {\r\ntx_ring = &adapter->tx_ring[ring];\r\nnetif_napi_del(&tx_ring->napi);\r\n}\r\n}\r\nqlcnic_free_tx_rings(adapter);\r\n}\r\nstatic void qlcnic_83xx_process_rcv_diag(struct qlcnic_adapter *adapter,\r\nint ring, u64 sts_data[])\r\n{\r\nstruct qlcnic_recv_context *recv_ctx = adapter->recv_ctx;\r\nstruct sk_buff *skb;\r\nstruct qlcnic_host_rds_ring *rds_ring;\r\nint index, length;\r\nif (unlikely(ring >= adapter->max_rds_rings))\r\nreturn;\r\nrds_ring = &recv_ctx->rds_rings[ring];\r\nindex = qlcnic_83xx_hndl(sts_data[0]);\r\nif (unlikely(index >= rds_ring->num_desc))\r\nreturn;\r\nlength = qlcnic_83xx_pktln(sts_data[0]);\r\nskb = qlcnic_process_rxbuf(adapter, rds_ring, index, STATUS_CKSUM_OK);\r\nif (!skb)\r\nreturn;\r\nif (length > rds_ring->skb_size)\r\nskb_put(skb, rds_ring->skb_size);\r\nelse\r\nskb_put(skb, length);\r\nif (!qlcnic_check_loopback_buff(skb->data, adapter->mac_addr))\r\nadapter->ahw->diag_cnt++;\r\nelse\r\ndump_skb(skb, adapter);\r\ndev_kfree_skb_any(skb);\r\nreturn;\r\n}\r\nvoid qlcnic_83xx_process_rcv_ring_diag(struct qlcnic_host_sds_ring *sds_ring)\r\n{\r\nstruct qlcnic_adapter *adapter = sds_ring->adapter;\r\nstruct status_desc *desc;\r\nu64 sts_data[2];\r\nint ring, opcode;\r\nu32 consumer = sds_ring->consumer;\r\ndesc = &sds_ring->desc_head[consumer];\r\nsts_data[0] = le64_to_cpu(desc->status_desc_data[0]);\r\nsts_data[1] = le64_to_cpu(desc->status_desc_data[1]);\r\nopcode = qlcnic_83xx_opcode(sts_data[1]);\r\nif (!opcode)\r\nreturn;\r\nring = QLCNIC_FETCH_RING_ID(sts_data[0]);\r\nqlcnic_83xx_process_rcv_diag(adapter, ring, sts_data);\r\ndesc = &sds_ring->desc_head[consumer];\r\ndesc->status_desc_data[0] = cpu_to_le64(STATUS_OWNER_PHANTOM);\r\nconsumer = get_next_index(consumer, sds_ring->num_desc);\r\nsds_ring->consumer = consumer;\r\nwritel(consumer, sds_ring->crb_sts_consumer);\r\n}
