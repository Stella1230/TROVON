void copy_page(void *to, void *from)\r\n{\r\nmemcpy(to, from, PAGE_SIZE);\r\n}\r\n__kernel_size_t __copy_user(void *to, const void *from, __kernel_size_t n)\r\n{\r\nmemcpy(to, from, n);\r\nreturn 0;\r\n}\r\n__kernel_size_t __clear_user(void *to, __kernel_size_t n)\r\n{\r\nmemset(to, 0, n);\r\nreturn 0;\r\n}\r\nvoid local_flush_tlb_all(void)\r\n{\r\nBUG();\r\n}\r\nvoid local_flush_tlb_mm(struct mm_struct *mm)\r\n{\r\nBUG();\r\n}\r\nvoid local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,\r\nunsigned long end)\r\n{\r\nBUG();\r\n}\r\nvoid local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)\r\n{\r\nBUG();\r\n}\r\nvoid local_flush_tlb_one(unsigned long asid, unsigned long page)\r\n{\r\nBUG();\r\n}\r\nvoid local_flush_tlb_kernel_range(unsigned long start, unsigned long end)\r\n{\r\nBUG();\r\n}\r\nvoid __flush_tlb_global(void)\r\n{\r\n}\r\nvoid __update_tlb(struct vm_area_struct *vma, unsigned long address, pte_t pte)\r\n{\r\n}\r\nvoid __init kmap_coherent_init(void)\r\n{\r\n}\r\nvoid *kmap_coherent(struct page *page, unsigned long addr)\r\n{\r\nBUG();\r\nreturn NULL;\r\n}\r\nvoid kunmap_coherent(void *kvaddr)\r\n{\r\nBUG();\r\n}\r\nvoid __init page_table_range_init(unsigned long start, unsigned long end,\r\npgd_t *pgd_base)\r\n{\r\n}\r\nvoid __set_fixmap(enum fixed_addresses idx, unsigned long phys, pgprot_t prot)\r\n{\r\n}\r\nvoid pgtable_cache_init(void)\r\n{\r\n}
