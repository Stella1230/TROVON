static void __flush_dcache(unsigned long start, unsigned long end)\r\n{\r\nunsigned long addr;\r\nstart &= ~(cpuinfo.dcache_line_size - 1);\r\nend += (cpuinfo.dcache_line_size - 1);\r\nend &= ~(cpuinfo.dcache_line_size - 1);\r\nif (end > start + cpuinfo.dcache_size)\r\nend = start + cpuinfo.dcache_size;\r\nfor (addr = start; addr < end; addr += cpuinfo.dcache_line_size) {\r\n__asm__ __volatile__ (" flushd 0(%0)\n"\r\n:\r\n: "r"(addr)\r\n);\r\n}\r\n}\r\nstatic void __invalidate_dcache(unsigned long start, unsigned long end)\r\n{\r\nunsigned long addr;\r\nstart &= ~(cpuinfo.dcache_line_size - 1);\r\nend += (cpuinfo.dcache_line_size - 1);\r\nend &= ~(cpuinfo.dcache_line_size - 1);\r\nfor (addr = start; addr < end; addr += cpuinfo.dcache_line_size) {\r\n__asm__ __volatile__ (" initda 0(%0)\n"\r\n:\r\n: "r"(addr)\r\n);\r\n}\r\n}\r\nstatic void __flush_icache(unsigned long start, unsigned long end)\r\n{\r\nunsigned long addr;\r\nstart &= ~(cpuinfo.icache_line_size - 1);\r\nend += (cpuinfo.icache_line_size - 1);\r\nend &= ~(cpuinfo.icache_line_size - 1);\r\nif (end > start + cpuinfo.icache_size)\r\nend = start + cpuinfo.icache_size;\r\nfor (addr = start; addr < end; addr += cpuinfo.icache_line_size) {\r\n__asm__ __volatile__ (" flushi %0\n"\r\n:\r\n: "r"(addr)\r\n);\r\n}\r\n__asm__ __volatile(" flushp\n");\r\n}\r\nstatic void flush_aliases(struct address_space *mapping, struct page *page)\r\n{\r\nstruct mm_struct *mm = current->active_mm;\r\nstruct vm_area_struct *mpnt;\r\npgoff_t pgoff;\r\npgoff = page->index;\r\nflush_dcache_mmap_lock(mapping);\r\nvma_interval_tree_foreach(mpnt, &mapping->i_mmap, pgoff, pgoff) {\r\nunsigned long offset;\r\nif (mpnt->vm_mm != mm)\r\ncontinue;\r\nif (!(mpnt->vm_flags & VM_MAYSHARE))\r\ncontinue;\r\noffset = (pgoff - mpnt->vm_pgoff) << PAGE_SHIFT;\r\nflush_cache_page(mpnt, mpnt->vm_start + offset,\r\npage_to_pfn(page));\r\n}\r\nflush_dcache_mmap_unlock(mapping);\r\n}\r\nvoid flush_cache_all(void)\r\n{\r\n__flush_dcache(0, cpuinfo.dcache_size);\r\n__flush_icache(0, cpuinfo.icache_size);\r\n}\r\nvoid flush_cache_mm(struct mm_struct *mm)\r\n{\r\nflush_cache_all();\r\n}\r\nvoid flush_cache_dup_mm(struct mm_struct *mm)\r\n{\r\nflush_cache_all();\r\n}\r\nvoid flush_icache_range(unsigned long start, unsigned long end)\r\n{\r\n__flush_dcache(start, end);\r\n__flush_icache(start, end);\r\n}\r\nvoid flush_dcache_range(unsigned long start, unsigned long end)\r\n{\r\n__flush_dcache(start, end);\r\n__flush_icache(start, end);\r\n}\r\nvoid invalidate_dcache_range(unsigned long start, unsigned long end)\r\n{\r\n__invalidate_dcache(start, end);\r\n}\r\nvoid flush_cache_range(struct vm_area_struct *vma, unsigned long start,\r\nunsigned long end)\r\n{\r\n__flush_dcache(start, end);\r\nif (vma == NULL || (vma->vm_flags & VM_EXEC))\r\n__flush_icache(start, end);\r\n}\r\nvoid flush_icache_page(struct vm_area_struct *vma, struct page *page)\r\n{\r\nunsigned long start = (unsigned long) page_address(page);\r\nunsigned long end = start + PAGE_SIZE;\r\n__flush_dcache(start, end);\r\n__flush_icache(start, end);\r\n}\r\nvoid flush_cache_page(struct vm_area_struct *vma, unsigned long vmaddr,\r\nunsigned long pfn)\r\n{\r\nunsigned long start = vmaddr;\r\nunsigned long end = start + PAGE_SIZE;\r\n__flush_dcache(start, end);\r\nif (vma->vm_flags & VM_EXEC)\r\n__flush_icache(start, end);\r\n}\r\nvoid __flush_dcache_page(struct address_space *mapping, struct page *page)\r\n{\r\nunsigned long start = (unsigned long)page_address(page);\r\n__flush_dcache(start, start + PAGE_SIZE);\r\n}\r\nvoid flush_dcache_page(struct page *page)\r\n{\r\nstruct address_space *mapping;\r\nif (page == ZERO_PAGE(0))\r\nreturn;\r\nmapping = page_mapping(page);\r\nif (mapping && !mapping_mapped(mapping)) {\r\nclear_bit(PG_dcache_clean, &page->flags);\r\n} else {\r\n__flush_dcache_page(mapping, page);\r\nif (mapping) {\r\nunsigned long start = (unsigned long)page_address(page);\r\nflush_aliases(mapping, page);\r\nflush_icache_range(start, start + PAGE_SIZE);\r\n}\r\nset_bit(PG_dcache_clean, &page->flags);\r\n}\r\n}\r\nvoid update_mmu_cache(struct vm_area_struct *vma,\r\nunsigned long address, pte_t *pte)\r\n{\r\nunsigned long pfn = pte_pfn(*pte);\r\nstruct page *page;\r\nstruct address_space *mapping;\r\nif (!pfn_valid(pfn))\r\nreturn;\r\npage = pfn_to_page(pfn);\r\nif (page == ZERO_PAGE(0))\r\nreturn;\r\nmapping = page_mapping(page);\r\nif (!test_and_set_bit(PG_dcache_clean, &page->flags))\r\n__flush_dcache_page(mapping, page);\r\nif(mapping)\r\n{\r\nflush_aliases(mapping, page);\r\nif (vma->vm_flags & VM_EXEC)\r\nflush_icache_page(vma, page);\r\n}\r\n}\r\nvoid copy_user_page(void *vto, void *vfrom, unsigned long vaddr,\r\nstruct page *to)\r\n{\r\n__flush_dcache(vaddr, vaddr + PAGE_SIZE);\r\n__flush_icache(vaddr, vaddr + PAGE_SIZE);\r\ncopy_page(vto, vfrom);\r\n__flush_dcache((unsigned long)vto, (unsigned long)vto + PAGE_SIZE);\r\n__flush_icache((unsigned long)vto, (unsigned long)vto + PAGE_SIZE);\r\n}\r\nvoid clear_user_page(void *addr, unsigned long vaddr, struct page *page)\r\n{\r\n__flush_dcache(vaddr, vaddr + PAGE_SIZE);\r\n__flush_icache(vaddr, vaddr + PAGE_SIZE);\r\nclear_page(addr);\r\n__flush_dcache((unsigned long)addr, (unsigned long)addr + PAGE_SIZE);\r\n__flush_icache((unsigned long)addr, (unsigned long)addr + PAGE_SIZE);\r\n}\r\nvoid copy_from_user_page(struct vm_area_struct *vma, struct page *page,\r\nunsigned long user_vaddr,\r\nvoid *dst, void *src, int len)\r\n{\r\nflush_cache_page(vma, user_vaddr, page_to_pfn(page));\r\nmemcpy(dst, src, len);\r\n__flush_dcache((unsigned long)src, (unsigned long)src + len);\r\nif (vma->vm_flags & VM_EXEC)\r\n__flush_icache((unsigned long)src, (unsigned long)src + len);\r\n}\r\nvoid copy_to_user_page(struct vm_area_struct *vma, struct page *page,\r\nunsigned long user_vaddr,\r\nvoid *dst, void *src, int len)\r\n{\r\nflush_cache_page(vma, user_vaddr, page_to_pfn(page));\r\nmemcpy(dst, src, len);\r\n__flush_dcache((unsigned long)dst, (unsigned long)dst + len);\r\nif (vma->vm_flags & VM_EXEC)\r\n__flush_icache((unsigned long)dst, (unsigned long)dst + len);\r\n}
