static void rds_tcp_inc_purge(struct rds_incoming *inc)\r\n{\r\nstruct rds_tcp_incoming *tinc;\r\ntinc = container_of(inc, struct rds_tcp_incoming, ti_inc);\r\nrdsdebug("purging tinc %p inc %p\n", tinc, inc);\r\nskb_queue_purge(&tinc->ti_skb_list);\r\n}\r\nvoid rds_tcp_inc_free(struct rds_incoming *inc)\r\n{\r\nstruct rds_tcp_incoming *tinc;\r\ntinc = container_of(inc, struct rds_tcp_incoming, ti_inc);\r\nrds_tcp_inc_purge(inc);\r\nrdsdebug("freeing tinc %p inc %p\n", tinc, inc);\r\nkmem_cache_free(rds_tcp_incoming_slab, tinc);\r\n}\r\nint rds_tcp_inc_copy_to_user(struct rds_incoming *inc, struct iov_iter *to)\r\n{\r\nstruct rds_tcp_incoming *tinc;\r\nstruct sk_buff *skb;\r\nint ret = 0;\r\nif (!iov_iter_count(to))\r\ngoto out;\r\ntinc = container_of(inc, struct rds_tcp_incoming, ti_inc);\r\nskb_queue_walk(&tinc->ti_skb_list, skb) {\r\nunsigned long to_copy, skb_off;\r\nfor (skb_off = 0; skb_off < skb->len; skb_off += to_copy) {\r\nto_copy = iov_iter_count(to);\r\nto_copy = min(to_copy, skb->len - skb_off);\r\nif (skb_copy_datagram_iter(skb, skb_off, to, to_copy))\r\nreturn -EFAULT;\r\nrds_stats_add(s_copy_to_user, to_copy);\r\nret += to_copy;\r\nif (!iov_iter_count(to))\r\ngoto out;\r\n}\r\n}\r\nout:\r\nreturn ret;\r\n}\r\nstatic void rds_tcp_cong_recv(struct rds_connection *conn,\r\nstruct rds_tcp_incoming *tinc)\r\n{\r\nstruct sk_buff *skb;\r\nunsigned int to_copy, skb_off;\r\nunsigned int map_off;\r\nunsigned int map_page;\r\nstruct rds_cong_map *map;\r\nint ret;\r\nif (be32_to_cpu(tinc->ti_inc.i_hdr.h_len) != RDS_CONG_MAP_BYTES)\r\nreturn;\r\nmap_page = 0;\r\nmap_off = 0;\r\nmap = conn->c_fcong;\r\nskb_queue_walk(&tinc->ti_skb_list, skb) {\r\nskb_off = 0;\r\nwhile (skb_off < skb->len) {\r\nto_copy = min_t(unsigned int, PAGE_SIZE - map_off,\r\nskb->len - skb_off);\r\nBUG_ON(map_page >= RDS_CONG_MAP_PAGES);\r\nret = skb_copy_bits(skb, skb_off,\r\n(void *)map->m_page_addrs[map_page] + map_off,\r\nto_copy);\r\nBUG_ON(ret != 0);\r\nskb_off += to_copy;\r\nmap_off += to_copy;\r\nif (map_off == PAGE_SIZE) {\r\nmap_off = 0;\r\nmap_page++;\r\n}\r\n}\r\n}\r\nrds_cong_map_updated(map, ~(u64) 0);\r\n}\r\nstatic int rds_tcp_data_recv(read_descriptor_t *desc, struct sk_buff *skb,\r\nunsigned int offset, size_t len)\r\n{\r\nstruct rds_tcp_desc_arg *arg = desc->arg.data;\r\nstruct rds_conn_path *cp = arg->conn_path;\r\nstruct rds_tcp_connection *tc = cp->cp_transport_data;\r\nstruct rds_tcp_incoming *tinc = tc->t_tinc;\r\nstruct sk_buff *clone;\r\nsize_t left = len, to_copy;\r\nrdsdebug("tcp data tc %p skb %p offset %u len %zu\n", tc, skb, offset,\r\nlen);\r\nwhile (left) {\r\nif (!tinc) {\r\ntinc = kmem_cache_alloc(rds_tcp_incoming_slab,\r\narg->gfp);\r\nif (!tinc) {\r\ndesc->error = -ENOMEM;\r\ngoto out;\r\n}\r\ntc->t_tinc = tinc;\r\nrdsdebug("alloced tinc %p\n", tinc);\r\nrds_inc_path_init(&tinc->ti_inc, cp,\r\ncp->cp_conn->c_faddr);\r\nskb_queue_head_init(&tinc->ti_skb_list);\r\n}\r\nif (left && tc->t_tinc_hdr_rem) {\r\nto_copy = min(tc->t_tinc_hdr_rem, left);\r\nrdsdebug("copying %zu header from skb %p\n", to_copy,\r\nskb);\r\nskb_copy_bits(skb, offset,\r\n(char *)&tinc->ti_inc.i_hdr +\r\nsizeof(struct rds_header) -\r\ntc->t_tinc_hdr_rem,\r\nto_copy);\r\ntc->t_tinc_hdr_rem -= to_copy;\r\nleft -= to_copy;\r\noffset += to_copy;\r\nif (tc->t_tinc_hdr_rem == 0) {\r\ntc->t_tinc_data_rem =\r\nbe32_to_cpu(tinc->ti_inc.i_hdr.h_len);\r\n}\r\n}\r\nif (left && tc->t_tinc_data_rem) {\r\nto_copy = min(tc->t_tinc_data_rem, left);\r\nclone = pskb_extract(skb, offset, to_copy, arg->gfp);\r\nif (!clone) {\r\ndesc->error = -ENOMEM;\r\ngoto out;\r\n}\r\nskb_queue_tail(&tinc->ti_skb_list, clone);\r\nrdsdebug("skb %p data %p len %d off %u to_copy %zu -> "\r\n"clone %p data %p len %d\n",\r\nskb, skb->data, skb->len, offset, to_copy,\r\nclone, clone->data, clone->len);\r\ntc->t_tinc_data_rem -= to_copy;\r\nleft -= to_copy;\r\noffset += to_copy;\r\n}\r\nif (tc->t_tinc_hdr_rem == 0 && tc->t_tinc_data_rem == 0) {\r\nstruct rds_connection *conn = cp->cp_conn;\r\nif (tinc->ti_inc.i_hdr.h_flags == RDS_FLAG_CONG_BITMAP)\r\nrds_tcp_cong_recv(conn, tinc);\r\nelse\r\nrds_recv_incoming(conn, conn->c_faddr,\r\nconn->c_laddr, &tinc->ti_inc,\r\narg->gfp);\r\ntc->t_tinc_hdr_rem = sizeof(struct rds_header);\r\ntc->t_tinc_data_rem = 0;\r\ntc->t_tinc = NULL;\r\nrds_inc_put(&tinc->ti_inc);\r\ntinc = NULL;\r\n}\r\n}\r\nout:\r\nrdsdebug("returning len %zu left %zu skb len %d rx queue depth %d\n",\r\nlen, left, skb->len,\r\nskb_queue_len(&tc->t_sock->sk->sk_receive_queue));\r\nreturn len - left;\r\n}\r\nstatic int rds_tcp_read_sock(struct rds_conn_path *cp, gfp_t gfp)\r\n{\r\nstruct rds_tcp_connection *tc = cp->cp_transport_data;\r\nstruct socket *sock = tc->t_sock;\r\nread_descriptor_t desc;\r\nstruct rds_tcp_desc_arg arg;\r\narg.conn_path = cp;\r\narg.gfp = gfp;\r\ndesc.arg.data = &arg;\r\ndesc.error = 0;\r\ndesc.count = 1;\r\ntcp_read_sock(sock->sk, &desc, rds_tcp_data_recv);\r\nrdsdebug("tcp_read_sock for tc %p gfp 0x%x returned %d\n", tc, gfp,\r\ndesc.error);\r\nreturn desc.error;\r\n}\r\nint rds_tcp_recv_path(struct rds_conn_path *cp)\r\n{\r\nstruct rds_tcp_connection *tc = cp->cp_transport_data;\r\nstruct socket *sock = tc->t_sock;\r\nint ret = 0;\r\nrdsdebug("recv worker path [%d] tc %p sock %p\n",\r\ncp->cp_index, tc, sock);\r\nlock_sock(sock->sk);\r\nret = rds_tcp_read_sock(cp, GFP_KERNEL);\r\nrelease_sock(sock->sk);\r\nreturn ret;\r\n}\r\nvoid rds_tcp_data_ready(struct sock *sk)\r\n{\r\nvoid (*ready)(struct sock *sk);\r\nstruct rds_conn_path *cp;\r\nstruct rds_tcp_connection *tc;\r\nrdsdebug("data ready sk %p\n", sk);\r\nread_lock_bh(&sk->sk_callback_lock);\r\ncp = sk->sk_user_data;\r\nif (!cp) {\r\nready = sk->sk_data_ready;\r\ngoto out;\r\n}\r\ntc = cp->cp_transport_data;\r\nready = tc->t_orig_data_ready;\r\nrds_tcp_stats_inc(s_tcp_data_ready_calls);\r\nif (rds_tcp_read_sock(cp, GFP_ATOMIC) == -ENOMEM)\r\nqueue_delayed_work(rds_wq, &cp->cp_recv_w, 0);\r\nout:\r\nread_unlock_bh(&sk->sk_callback_lock);\r\nready(sk);\r\n}\r\nint rds_tcp_recv_init(void)\r\n{\r\nrds_tcp_incoming_slab = kmem_cache_create("rds_tcp_incoming",\r\nsizeof(struct rds_tcp_incoming),\r\n0, 0, NULL);\r\nif (!rds_tcp_incoming_slab)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nvoid rds_tcp_recv_exit(void)\r\n{\r\nkmem_cache_destroy(rds_tcp_incoming_slab);\r\n}
