static inline int\r\nxfs_ialloc_cluster_alignment(\r\nstruct xfs_mount *mp)\r\n{\r\nif (xfs_sb_version_hasalign(&mp->m_sb) &&\r\nmp->m_sb.sb_inoalignmt >=\r\nXFS_B_TO_FSBT(mp, mp->m_inode_cluster_size))\r\nreturn mp->m_sb.sb_inoalignmt;\r\nreturn 1;\r\n}\r\nint\r\nxfs_inobt_lookup(\r\nstruct xfs_btree_cur *cur,\r\nxfs_agino_t ino,\r\nxfs_lookup_t dir,\r\nint *stat)\r\n{\r\ncur->bc_rec.i.ir_startino = ino;\r\ncur->bc_rec.i.ir_holemask = 0;\r\ncur->bc_rec.i.ir_count = 0;\r\ncur->bc_rec.i.ir_freecount = 0;\r\ncur->bc_rec.i.ir_free = 0;\r\nreturn xfs_btree_lookup(cur, dir, stat);\r\n}\r\nSTATIC int\r\nxfs_inobt_update(\r\nstruct xfs_btree_cur *cur,\r\nxfs_inobt_rec_incore_t *irec)\r\n{\r\nunion xfs_btree_rec rec;\r\nrec.inobt.ir_startino = cpu_to_be32(irec->ir_startino);\r\nif (xfs_sb_version_hassparseinodes(&cur->bc_mp->m_sb)) {\r\nrec.inobt.ir_u.sp.ir_holemask = cpu_to_be16(irec->ir_holemask);\r\nrec.inobt.ir_u.sp.ir_count = irec->ir_count;\r\nrec.inobt.ir_u.sp.ir_freecount = irec->ir_freecount;\r\n} else {\r\nrec.inobt.ir_u.f.ir_freecount = cpu_to_be32(irec->ir_freecount);\r\n}\r\nrec.inobt.ir_free = cpu_to_be64(irec->ir_free);\r\nreturn xfs_btree_update(cur, &rec);\r\n}\r\nint\r\nxfs_inobt_get_rec(\r\nstruct xfs_btree_cur *cur,\r\nxfs_inobt_rec_incore_t *irec,\r\nint *stat)\r\n{\r\nunion xfs_btree_rec *rec;\r\nint error;\r\nerror = xfs_btree_get_rec(cur, &rec, stat);\r\nif (error || *stat == 0)\r\nreturn error;\r\nirec->ir_startino = be32_to_cpu(rec->inobt.ir_startino);\r\nif (xfs_sb_version_hassparseinodes(&cur->bc_mp->m_sb)) {\r\nirec->ir_holemask = be16_to_cpu(rec->inobt.ir_u.sp.ir_holemask);\r\nirec->ir_count = rec->inobt.ir_u.sp.ir_count;\r\nirec->ir_freecount = rec->inobt.ir_u.sp.ir_freecount;\r\n} else {\r\nirec->ir_holemask = XFS_INOBT_HOLEMASK_FULL;\r\nirec->ir_count = XFS_INODES_PER_CHUNK;\r\nirec->ir_freecount =\r\nbe32_to_cpu(rec->inobt.ir_u.f.ir_freecount);\r\n}\r\nirec->ir_free = be64_to_cpu(rec->inobt.ir_free);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_inobt_insert_rec(\r\nstruct xfs_btree_cur *cur,\r\n__uint16_t holemask,\r\n__uint8_t count,\r\n__int32_t freecount,\r\nxfs_inofree_t free,\r\nint *stat)\r\n{\r\ncur->bc_rec.i.ir_holemask = holemask;\r\ncur->bc_rec.i.ir_count = count;\r\ncur->bc_rec.i.ir_freecount = freecount;\r\ncur->bc_rec.i.ir_free = free;\r\nreturn xfs_btree_insert(cur, stat);\r\n}\r\nSTATIC int\r\nxfs_inobt_insert(\r\nstruct xfs_mount *mp,\r\nstruct xfs_trans *tp,\r\nstruct xfs_buf *agbp,\r\nxfs_agino_t newino,\r\nxfs_agino_t newlen,\r\nxfs_btnum_t btnum)\r\n{\r\nstruct xfs_btree_cur *cur;\r\nstruct xfs_agi *agi = XFS_BUF_TO_AGI(agbp);\r\nxfs_agnumber_t agno = be32_to_cpu(agi->agi_seqno);\r\nxfs_agino_t thisino;\r\nint i;\r\nint error;\r\ncur = xfs_inobt_init_cursor(mp, tp, agbp, agno, btnum);\r\nfor (thisino = newino;\r\nthisino < newino + newlen;\r\nthisino += XFS_INODES_PER_CHUNK) {\r\nerror = xfs_inobt_lookup(cur, thisino, XFS_LOOKUP_EQ, &i);\r\nif (error) {\r\nxfs_btree_del_cursor(cur, XFS_BTREE_ERROR);\r\nreturn error;\r\n}\r\nASSERT(i == 0);\r\nerror = xfs_inobt_insert_rec(cur, XFS_INOBT_HOLEMASK_FULL,\r\nXFS_INODES_PER_CHUNK,\r\nXFS_INODES_PER_CHUNK,\r\nXFS_INOBT_ALL_FREE, &i);\r\nif (error) {\r\nxfs_btree_del_cursor(cur, XFS_BTREE_ERROR);\r\nreturn error;\r\n}\r\nASSERT(i == 1);\r\n}\r\nxfs_btree_del_cursor(cur, XFS_BTREE_NOERROR);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_check_agi_freecount(\r\nstruct xfs_btree_cur *cur,\r\nstruct xfs_agi *agi)\r\n{\r\nif (cur->bc_nlevels == 1) {\r\nxfs_inobt_rec_incore_t rec;\r\nint freecount = 0;\r\nint error;\r\nint i;\r\nerror = xfs_inobt_lookup(cur, 0, XFS_LOOKUP_GE, &i);\r\nif (error)\r\nreturn error;\r\ndo {\r\nerror = xfs_inobt_get_rec(cur, &rec, &i);\r\nif (error)\r\nreturn error;\r\nif (i) {\r\nfreecount += rec.ir_freecount;\r\nerror = xfs_btree_increment(cur, 0, &i);\r\nif (error)\r\nreturn error;\r\n}\r\n} while (i == 1);\r\nif (!XFS_FORCED_SHUTDOWN(cur->bc_mp))\r\nASSERT(freecount == be32_to_cpu(agi->agi_freecount));\r\n}\r\nreturn 0;\r\n}\r\nint\r\nxfs_ialloc_inode_init(\r\nstruct xfs_mount *mp,\r\nstruct xfs_trans *tp,\r\nstruct list_head *buffer_list,\r\nint icount,\r\nxfs_agnumber_t agno,\r\nxfs_agblock_t agbno,\r\nxfs_agblock_t length,\r\nunsigned int gen)\r\n{\r\nstruct xfs_buf *fbuf;\r\nstruct xfs_dinode *free;\r\nint nbufs, blks_per_cluster, inodes_per_cluster;\r\nint version;\r\nint i, j;\r\nxfs_daddr_t d;\r\nxfs_ino_t ino = 0;\r\nblks_per_cluster = xfs_icluster_size_fsb(mp);\r\ninodes_per_cluster = blks_per_cluster << mp->m_sb.sb_inopblog;\r\nnbufs = length / blks_per_cluster;\r\nif (xfs_sb_version_hascrc(&mp->m_sb)) {\r\nversion = 3;\r\nino = XFS_AGINO_TO_INO(mp, agno,\r\nXFS_OFFBNO_TO_AGINO(mp, agbno, 0));\r\nif (tp)\r\nxfs_icreate_log(tp, agno, agbno, icount,\r\nmp->m_sb.sb_inodesize, length, gen);\r\n} else\r\nversion = 2;\r\nfor (j = 0; j < nbufs; j++) {\r\nd = XFS_AGB_TO_DADDR(mp, agno, agbno + (j * blks_per_cluster));\r\nfbuf = xfs_trans_get_buf(tp, mp->m_ddev_targp, d,\r\nmp->m_bsize * blks_per_cluster,\r\nXBF_UNMAPPED);\r\nif (!fbuf)\r\nreturn -ENOMEM;\r\nfbuf->b_ops = &xfs_inode_buf_ops;\r\nxfs_buf_zero(fbuf, 0, BBTOB(fbuf->b_length));\r\nfor (i = 0; i < inodes_per_cluster; i++) {\r\nint ioffset = i << mp->m_sb.sb_inodelog;\r\nuint isize = xfs_dinode_size(version);\r\nfree = xfs_make_iptr(mp, fbuf, i);\r\nfree->di_magic = cpu_to_be16(XFS_DINODE_MAGIC);\r\nfree->di_version = version;\r\nfree->di_gen = cpu_to_be32(gen);\r\nfree->di_next_unlinked = cpu_to_be32(NULLAGINO);\r\nif (version == 3) {\r\nfree->di_ino = cpu_to_be64(ino);\r\nino++;\r\nuuid_copy(&free->di_uuid,\r\n&mp->m_sb.sb_meta_uuid);\r\nxfs_dinode_calc_crc(mp, free);\r\n} else if (tp) {\r\nxfs_trans_log_buf(tp, fbuf, ioffset,\r\nioffset + isize - 1);\r\n}\r\n}\r\nif (tp) {\r\nxfs_trans_inode_alloc_buf(tp, fbuf);\r\nif (version == 3) {\r\nxfs_trans_ordered_buf(tp, fbuf);\r\nxfs_trans_log_buf(tp, fbuf, 0,\r\nBBTOB(fbuf->b_length) - 1);\r\n}\r\n} else {\r\nfbuf->b_flags |= XBF_DONE;\r\nxfs_buf_delwri_queue(fbuf, buffer_list);\r\nxfs_buf_relse(fbuf);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nSTATIC void\r\nxfs_align_sparse_ino(\r\nstruct xfs_mount *mp,\r\nxfs_agino_t *startino,\r\nuint16_t *allocmask)\r\n{\r\nxfs_agblock_t agbno;\r\nxfs_agblock_t mod;\r\nint offset;\r\nagbno = XFS_AGINO_TO_AGBNO(mp, *startino);\r\nmod = agbno % mp->m_sb.sb_inoalignmt;\r\nif (!mod)\r\nreturn;\r\noffset = mod << mp->m_sb.sb_inopblog;\r\n*startino -= offset;\r\n*allocmask <<= offset / XFS_INODES_PER_HOLEMASK_BIT;\r\n}\r\nSTATIC bool\r\n__xfs_inobt_can_merge(\r\nstruct xfs_inobt_rec_incore *trec,\r\nstruct xfs_inobt_rec_incore *srec)\r\n{\r\nuint64_t talloc;\r\nuint64_t salloc;\r\nif (trec->ir_startino != srec->ir_startino)\r\nreturn false;\r\nif (!xfs_inobt_issparse(trec->ir_holemask) ||\r\n!xfs_inobt_issparse(srec->ir_holemask))\r\nreturn false;\r\nif (!trec->ir_count || !srec->ir_count)\r\nreturn false;\r\nif (trec->ir_count + srec->ir_count > XFS_INODES_PER_CHUNK)\r\nreturn false;\r\ntalloc = xfs_inobt_irec_to_allocmask(trec);\r\nsalloc = xfs_inobt_irec_to_allocmask(srec);\r\nif (talloc & salloc)\r\nreturn false;\r\nreturn true;\r\n}\r\nSTATIC void\r\n__xfs_inobt_rec_merge(\r\nstruct xfs_inobt_rec_incore *trec,\r\nstruct xfs_inobt_rec_incore *srec)\r\n{\r\nASSERT(trec->ir_startino == srec->ir_startino);\r\ntrec->ir_count += srec->ir_count;\r\ntrec->ir_freecount += srec->ir_freecount;\r\ntrec->ir_holemask &= srec->ir_holemask;\r\ntrec->ir_free &= srec->ir_free;\r\n}\r\nSTATIC int\r\nxfs_inobt_insert_sprec(\r\nstruct xfs_mount *mp,\r\nstruct xfs_trans *tp,\r\nstruct xfs_buf *agbp,\r\nint btnum,\r\nstruct xfs_inobt_rec_incore *nrec,\r\nbool merge)\r\n{\r\nstruct xfs_btree_cur *cur;\r\nstruct xfs_agi *agi = XFS_BUF_TO_AGI(agbp);\r\nxfs_agnumber_t agno = be32_to_cpu(agi->agi_seqno);\r\nint error;\r\nint i;\r\nstruct xfs_inobt_rec_incore rec;\r\ncur = xfs_inobt_init_cursor(mp, tp, agbp, agno, btnum);\r\nerror = xfs_inobt_lookup(cur, nrec->ir_startino, XFS_LOOKUP_EQ, &i);\r\nif (error)\r\ngoto error;\r\nif (i == 0) {\r\nerror = xfs_inobt_insert_rec(cur, nrec->ir_holemask,\r\nnrec->ir_count, nrec->ir_freecount,\r\nnrec->ir_free, &i);\r\nif (error)\r\ngoto error;\r\nXFS_WANT_CORRUPTED_GOTO(mp, i == 1, error);\r\ngoto out;\r\n}\r\nif (merge) {\r\nerror = xfs_inobt_get_rec(cur, &rec, &i);\r\nif (error)\r\ngoto error;\r\nXFS_WANT_CORRUPTED_GOTO(mp, i == 1, error);\r\nXFS_WANT_CORRUPTED_GOTO(mp,\r\nrec.ir_startino == nrec->ir_startino,\r\nerror);\r\nXFS_WANT_CORRUPTED_GOTO(mp, __xfs_inobt_can_merge(nrec, &rec),\r\nerror);\r\ntrace_xfs_irec_merge_pre(mp, agno, rec.ir_startino,\r\nrec.ir_holemask, nrec->ir_startino,\r\nnrec->ir_holemask);\r\n__xfs_inobt_rec_merge(nrec, &rec);\r\ntrace_xfs_irec_merge_post(mp, agno, nrec->ir_startino,\r\nnrec->ir_holemask);\r\nerror = xfs_inobt_rec_check_count(mp, nrec);\r\nif (error)\r\ngoto error;\r\n}\r\nerror = xfs_inobt_update(cur, nrec);\r\nif (error)\r\ngoto error;\r\nout:\r\nxfs_btree_del_cursor(cur, XFS_BTREE_NOERROR);\r\nreturn 0;\r\nerror:\r\nxfs_btree_del_cursor(cur, XFS_BTREE_ERROR);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_ialloc_ag_alloc(\r\nxfs_trans_t *tp,\r\nxfs_buf_t *agbp,\r\nint *alloc)\r\n{\r\nxfs_agi_t *agi;\r\nxfs_alloc_arg_t args;\r\nxfs_agnumber_t agno;\r\nint error;\r\nxfs_agino_t newino;\r\nxfs_agino_t newlen;\r\nint isaligned = 0;\r\nuint16_t allocmask = (uint16_t) -1;\r\nstruct xfs_inobt_rec_incore rec;\r\nstruct xfs_perag *pag;\r\nint do_sparse = 0;\r\nmemset(&args, 0, sizeof(args));\r\nargs.tp = tp;\r\nargs.mp = tp->t_mountp;\r\nargs.fsbno = NULLFSBLOCK;\r\nxfs_rmap_ag_owner(&args.oinfo, XFS_RMAP_OWN_INODES);\r\n#ifdef DEBUG\r\nif (xfs_sb_version_hassparseinodes(&tp->t_mountp->m_sb) &&\r\nargs.mp->m_ialloc_min_blks < args.mp->m_ialloc_blks)\r\ndo_sparse = prandom_u32() & 1;\r\n#endif\r\nnewlen = args.mp->m_ialloc_inos;\r\nif (args.mp->m_maxicount &&\r\npercpu_counter_read_positive(&args.mp->m_icount) + newlen >\r\nargs.mp->m_maxicount)\r\nreturn -ENOSPC;\r\nargs.minlen = args.maxlen = args.mp->m_ialloc_blks;\r\nagi = XFS_BUF_TO_AGI(agbp);\r\nnewino = be32_to_cpu(agi->agi_newino);\r\nagno = be32_to_cpu(agi->agi_seqno);\r\nargs.agbno = XFS_AGINO_TO_AGBNO(args.mp, newino) +\r\nargs.mp->m_ialloc_blks;\r\nif (do_sparse)\r\ngoto sparse_alloc;\r\nif (likely(newino != NULLAGINO &&\r\n(args.agbno < be32_to_cpu(agi->agi_length)))) {\r\nargs.fsbno = XFS_AGB_TO_FSB(args.mp, agno, args.agbno);\r\nargs.type = XFS_ALLOCTYPE_THIS_BNO;\r\nargs.prod = 1;\r\nargs.alignment = 1;\r\nargs.minalignslop = xfs_ialloc_cluster_alignment(args.mp) - 1;\r\nargs.minleft = args.mp->m_in_maxlevels - 1;\r\nif ((error = xfs_alloc_vextent(&args)))\r\nreturn error;\r\nargs.minalignslop = 0;\r\n}\r\nif (unlikely(args.fsbno == NULLFSBLOCK)) {\r\nisaligned = 0;\r\nif (args.mp->m_sinoalign) {\r\nASSERT(!(args.mp->m_flags & XFS_MOUNT_NOALIGN));\r\nargs.alignment = args.mp->m_dalign;\r\nisaligned = 1;\r\n} else\r\nargs.alignment = xfs_ialloc_cluster_alignment(args.mp);\r\nargs.agbno = be32_to_cpu(agi->agi_root);\r\nargs.fsbno = XFS_AGB_TO_FSB(args.mp, agno, args.agbno);\r\nargs.type = XFS_ALLOCTYPE_NEAR_BNO;\r\nargs.prod = 1;\r\nargs.minleft = args.mp->m_in_maxlevels - 1;\r\nif ((error = xfs_alloc_vextent(&args)))\r\nreturn error;\r\n}\r\nif (isaligned && args.fsbno == NULLFSBLOCK) {\r\nargs.type = XFS_ALLOCTYPE_NEAR_BNO;\r\nargs.agbno = be32_to_cpu(agi->agi_root);\r\nargs.fsbno = XFS_AGB_TO_FSB(args.mp, agno, args.agbno);\r\nargs.alignment = xfs_ialloc_cluster_alignment(args.mp);\r\nif ((error = xfs_alloc_vextent(&args)))\r\nreturn error;\r\n}\r\nif (xfs_sb_version_hassparseinodes(&args.mp->m_sb) &&\r\nargs.mp->m_ialloc_min_blks < args.mp->m_ialloc_blks &&\r\nargs.fsbno == NULLFSBLOCK) {\r\nsparse_alloc:\r\nargs.type = XFS_ALLOCTYPE_NEAR_BNO;\r\nargs.agbno = be32_to_cpu(agi->agi_root);\r\nargs.fsbno = XFS_AGB_TO_FSB(args.mp, agno, args.agbno);\r\nargs.alignment = args.mp->m_sb.sb_spino_align;\r\nargs.prod = 1;\r\nargs.minlen = args.mp->m_ialloc_min_blks;\r\nargs.maxlen = args.minlen;\r\nargs.min_agbno = args.mp->m_sb.sb_inoalignmt;\r\nargs.max_agbno = round_down(args.mp->m_sb.sb_agblocks,\r\nargs.mp->m_sb.sb_inoalignmt) -\r\nargs.mp->m_ialloc_blks;\r\nerror = xfs_alloc_vextent(&args);\r\nif (error)\r\nreturn error;\r\nnewlen = args.len << args.mp->m_sb.sb_inopblog;\r\nASSERT(newlen <= XFS_INODES_PER_CHUNK);\r\nallocmask = (1 << (newlen / XFS_INODES_PER_HOLEMASK_BIT)) - 1;\r\n}\r\nif (args.fsbno == NULLFSBLOCK) {\r\n*alloc = 0;\r\nreturn 0;\r\n}\r\nASSERT(args.len == args.minlen);\r\nerror = xfs_ialloc_inode_init(args.mp, tp, NULL, newlen, agno,\r\nargs.agbno, args.len, prandom_u32());\r\nif (error)\r\nreturn error;\r\nnewino = XFS_OFFBNO_TO_AGINO(args.mp, args.agbno, 0);\r\nif (xfs_inobt_issparse(~allocmask)) {\r\nxfs_align_sparse_ino(args.mp, &newino, &allocmask);\r\nrec.ir_startino = newino;\r\nrec.ir_holemask = ~allocmask;\r\nrec.ir_count = newlen;\r\nrec.ir_freecount = newlen;\r\nrec.ir_free = XFS_INOBT_ALL_FREE;\r\nerror = xfs_inobt_insert_sprec(args.mp, tp, agbp, XFS_BTNUM_INO,\r\n&rec, true);\r\nif (error == -EFSCORRUPTED) {\r\nxfs_alert(args.mp,\r\n"invalid sparse inode record: ino 0x%llx holemask 0x%x count %u",\r\nXFS_AGINO_TO_INO(args.mp, agno,\r\nrec.ir_startino),\r\nrec.ir_holemask, rec.ir_count);\r\nxfs_force_shutdown(args.mp, SHUTDOWN_CORRUPT_INCORE);\r\n}\r\nif (error)\r\nreturn error;\r\nif (xfs_sb_version_hasfinobt(&args.mp->m_sb)) {\r\nerror = xfs_inobt_insert_sprec(args.mp, tp, agbp,\r\nXFS_BTNUM_FINO, &rec,\r\nfalse);\r\nif (error)\r\nreturn error;\r\n}\r\n} else {\r\nerror = xfs_inobt_insert(args.mp, tp, agbp, newino, newlen,\r\nXFS_BTNUM_INO);\r\nif (error)\r\nreturn error;\r\nif (xfs_sb_version_hasfinobt(&args.mp->m_sb)) {\r\nerror = xfs_inobt_insert(args.mp, tp, agbp, newino,\r\nnewlen, XFS_BTNUM_FINO);\r\nif (error)\r\nreturn error;\r\n}\r\n}\r\nbe32_add_cpu(&agi->agi_count, newlen);\r\nbe32_add_cpu(&agi->agi_freecount, newlen);\r\npag = xfs_perag_get(args.mp, agno);\r\npag->pagi_freecount += newlen;\r\nxfs_perag_put(pag);\r\nagi->agi_newino = cpu_to_be32(newino);\r\nxfs_ialloc_log_agi(tp, agbp,\r\nXFS_AGI_COUNT | XFS_AGI_FREECOUNT | XFS_AGI_NEWINO);\r\nxfs_trans_mod_sb(tp, XFS_TRANS_SB_ICOUNT, (long)newlen);\r\nxfs_trans_mod_sb(tp, XFS_TRANS_SB_IFREE, (long)newlen);\r\n*alloc = 1;\r\nreturn 0;\r\n}\r\nSTATIC xfs_agnumber_t\r\nxfs_ialloc_next_ag(\r\nxfs_mount_t *mp)\r\n{\r\nxfs_agnumber_t agno;\r\nspin_lock(&mp->m_agirotor_lock);\r\nagno = mp->m_agirotor;\r\nif (++mp->m_agirotor >= mp->m_maxagi)\r\nmp->m_agirotor = 0;\r\nspin_unlock(&mp->m_agirotor_lock);\r\nreturn agno;\r\n}\r\nSTATIC xfs_agnumber_t\r\nxfs_ialloc_ag_select(\r\nxfs_trans_t *tp,\r\nxfs_ino_t parent,\r\numode_t mode,\r\nint okalloc)\r\n{\r\nxfs_agnumber_t agcount;\r\nxfs_agnumber_t agno;\r\nint flags;\r\nxfs_extlen_t ineed;\r\nxfs_extlen_t longest = 0;\r\nxfs_mount_t *mp;\r\nint needspace;\r\nxfs_perag_t *pag;\r\nxfs_agnumber_t pagno;\r\nint error;\r\nneedspace = S_ISDIR(mode) || S_ISREG(mode) || S_ISLNK(mode);\r\nmp = tp->t_mountp;\r\nagcount = mp->m_maxagi;\r\nif (S_ISDIR(mode))\r\npagno = xfs_ialloc_next_ag(mp);\r\nelse {\r\npagno = XFS_INO_TO_AGNO(mp, parent);\r\nif (pagno >= agcount)\r\npagno = 0;\r\n}\r\nASSERT(pagno < agcount);\r\nagno = pagno;\r\nflags = XFS_ALLOC_FLAG_TRYLOCK;\r\nfor (;;) {\r\npag = xfs_perag_get(mp, agno);\r\nif (!pag->pagi_inodeok) {\r\nxfs_ialloc_next_ag(mp);\r\ngoto nextag;\r\n}\r\nif (!pag->pagi_init) {\r\nerror = xfs_ialloc_pagi_init(mp, tp, agno);\r\nif (error)\r\ngoto nextag;\r\n}\r\nif (pag->pagi_freecount) {\r\nxfs_perag_put(pag);\r\nreturn agno;\r\n}\r\nif (!okalloc)\r\ngoto nextag;\r\nif (!pag->pagf_init) {\r\nerror = xfs_alloc_pagf_init(mp, tp, agno, flags);\r\nif (error)\r\ngoto nextag;\r\n}\r\nineed = mp->m_ialloc_min_blks;\r\nif (flags && ineed > 1)\r\nineed += xfs_ialloc_cluster_alignment(mp);\r\nlongest = pag->pagf_longest;\r\nif (!longest)\r\nlongest = pag->pagf_flcount > 0;\r\nif (pag->pagf_freeblks >= needspace + ineed &&\r\nlongest >= ineed) {\r\nxfs_perag_put(pag);\r\nreturn agno;\r\n}\r\nnextag:\r\nxfs_perag_put(pag);\r\nif (XFS_FORCED_SHUTDOWN(mp))\r\nreturn NULLAGNUMBER;\r\nagno++;\r\nif (agno >= agcount)\r\nagno = 0;\r\nif (agno == pagno) {\r\nif (flags == 0)\r\nreturn NULLAGNUMBER;\r\nflags = 0;\r\n}\r\n}\r\n}\r\nSTATIC int\r\nxfs_ialloc_next_rec(\r\nstruct xfs_btree_cur *cur,\r\nxfs_inobt_rec_incore_t *rec,\r\nint *done,\r\nint left)\r\n{\r\nint error;\r\nint i;\r\nif (left)\r\nerror = xfs_btree_decrement(cur, 0, &i);\r\nelse\r\nerror = xfs_btree_increment(cur, 0, &i);\r\nif (error)\r\nreturn error;\r\n*done = !i;\r\nif (i) {\r\nerror = xfs_inobt_get_rec(cur, rec, &i);\r\nif (error)\r\nreturn error;\r\nXFS_WANT_CORRUPTED_RETURN(cur->bc_mp, i == 1);\r\n}\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_ialloc_get_rec(\r\nstruct xfs_btree_cur *cur,\r\nxfs_agino_t agino,\r\nxfs_inobt_rec_incore_t *rec,\r\nint *done)\r\n{\r\nint error;\r\nint i;\r\nerror = xfs_inobt_lookup(cur, agino, XFS_LOOKUP_EQ, &i);\r\nif (error)\r\nreturn error;\r\n*done = !i;\r\nif (i) {\r\nerror = xfs_inobt_get_rec(cur, rec, &i);\r\nif (error)\r\nreturn error;\r\nXFS_WANT_CORRUPTED_RETURN(cur->bc_mp, i == 1);\r\n}\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_inobt_first_free_inode(\r\nstruct xfs_inobt_rec_incore *rec)\r\n{\r\nxfs_inofree_t realfree;\r\nif (!xfs_inobt_issparse(rec->ir_holemask))\r\nreturn xfs_lowbit64(rec->ir_free);\r\nrealfree = xfs_inobt_irec_to_allocmask(rec);\r\nrealfree &= rec->ir_free;\r\nreturn xfs_lowbit64(realfree);\r\n}\r\nSTATIC int\r\nxfs_dialloc_ag_inobt(\r\nstruct xfs_trans *tp,\r\nstruct xfs_buf *agbp,\r\nxfs_ino_t parent,\r\nxfs_ino_t *inop)\r\n{\r\nstruct xfs_mount *mp = tp->t_mountp;\r\nstruct xfs_agi *agi = XFS_BUF_TO_AGI(agbp);\r\nxfs_agnumber_t agno = be32_to_cpu(agi->agi_seqno);\r\nxfs_agnumber_t pagno = XFS_INO_TO_AGNO(mp, parent);\r\nxfs_agino_t pagino = XFS_INO_TO_AGINO(mp, parent);\r\nstruct xfs_perag *pag;\r\nstruct xfs_btree_cur *cur, *tcur;\r\nstruct xfs_inobt_rec_incore rec, trec;\r\nxfs_ino_t ino;\r\nint error;\r\nint offset;\r\nint i, j;\r\npag = xfs_perag_get(mp, agno);\r\nASSERT(pag->pagi_init);\r\nASSERT(pag->pagi_inodeok);\r\nASSERT(pag->pagi_freecount > 0);\r\nrestart_pagno:\r\ncur = xfs_inobt_init_cursor(mp, tp, agbp, agno, XFS_BTNUM_INO);\r\nif (!pagino)\r\npagino = be32_to_cpu(agi->agi_newino);\r\nerror = xfs_check_agi_freecount(cur, agi);\r\nif (error)\r\ngoto error0;\r\nif (pagno == agno) {\r\nint doneleft;\r\nint doneright;\r\nint searchdistance = 10;\r\nerror = xfs_inobt_lookup(cur, pagino, XFS_LOOKUP_LE, &i);\r\nif (error)\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(mp, i == 1, error0);\r\nerror = xfs_inobt_get_rec(cur, &rec, &j);\r\nif (error)\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(mp, j == 1, error0);\r\nif (rec.ir_freecount > 0) {\r\ngoto alloc_inode;\r\n}\r\nerror = xfs_btree_dup_cursor(cur, &tcur);\r\nif (error)\r\ngoto error0;\r\nif (pagino != NULLAGINO &&\r\npag->pagl_pagino == pagino &&\r\npag->pagl_leftrec != NULLAGINO &&\r\npag->pagl_rightrec != NULLAGINO) {\r\nerror = xfs_ialloc_get_rec(tcur, pag->pagl_leftrec,\r\n&trec, &doneleft);\r\nif (error)\r\ngoto error1;\r\nerror = xfs_ialloc_get_rec(cur, pag->pagl_rightrec,\r\n&rec, &doneright);\r\nif (error)\r\ngoto error1;\r\n} else {\r\nerror = xfs_ialloc_next_rec(tcur, &trec, &doneleft, 1);\r\nif (error)\r\ngoto error1;\r\nerror = xfs_ialloc_next_rec(cur, &rec, &doneright, 0);\r\nif (error)\r\ngoto error1;\r\n}\r\nwhile (!doneleft || !doneright) {\r\nint useleft;\r\nif (!--searchdistance) {\r\nxfs_btree_del_cursor(tcur, XFS_BTREE_NOERROR);\r\npag->pagl_leftrec = trec.ir_startino;\r\npag->pagl_rightrec = rec.ir_startino;\r\npag->pagl_pagino = pagino;\r\ngoto newino;\r\n}\r\nif (!doneleft && !doneright) {\r\nuseleft = pagino -\r\n(trec.ir_startino + XFS_INODES_PER_CHUNK - 1) <\r\nrec.ir_startino - pagino;\r\n} else {\r\nuseleft = !doneleft;\r\n}\r\nif (useleft && trec.ir_freecount) {\r\nrec = trec;\r\nxfs_btree_del_cursor(cur, XFS_BTREE_NOERROR);\r\ncur = tcur;\r\npag->pagl_leftrec = trec.ir_startino;\r\npag->pagl_rightrec = rec.ir_startino;\r\npag->pagl_pagino = pagino;\r\ngoto alloc_inode;\r\n}\r\nif (!useleft && rec.ir_freecount) {\r\nxfs_btree_del_cursor(tcur, XFS_BTREE_NOERROR);\r\npag->pagl_leftrec = trec.ir_startino;\r\npag->pagl_rightrec = rec.ir_startino;\r\npag->pagl_pagino = pagino;\r\ngoto alloc_inode;\r\n}\r\nif (useleft) {\r\nerror = xfs_ialloc_next_rec(tcur, &trec,\r\n&doneleft, 1);\r\n} else {\r\nerror = xfs_ialloc_next_rec(cur, &rec,\r\n&doneright, 0);\r\n}\r\nif (error)\r\ngoto error1;\r\n}\r\npag->pagl_pagino = NULLAGINO;\r\npag->pagl_leftrec = NULLAGINO;\r\npag->pagl_rightrec = NULLAGINO;\r\nxfs_btree_del_cursor(tcur, XFS_BTREE_NOERROR);\r\nxfs_btree_del_cursor(cur, XFS_BTREE_NOERROR);\r\ngoto restart_pagno;\r\n}\r\nnewino:\r\nif (agi->agi_newino != cpu_to_be32(NULLAGINO)) {\r\nerror = xfs_inobt_lookup(cur, be32_to_cpu(agi->agi_newino),\r\nXFS_LOOKUP_EQ, &i);\r\nif (error)\r\ngoto error0;\r\nif (i == 1) {\r\nerror = xfs_inobt_get_rec(cur, &rec, &j);\r\nif (error)\r\ngoto error0;\r\nif (j == 1 && rec.ir_freecount > 0) {\r\ngoto alloc_inode;\r\n}\r\n}\r\n}\r\nerror = xfs_inobt_lookup(cur, 0, XFS_LOOKUP_GE, &i);\r\nif (error)\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(mp, i == 1, error0);\r\nfor (;;) {\r\nerror = xfs_inobt_get_rec(cur, &rec, &i);\r\nif (error)\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(mp, i == 1, error0);\r\nif (rec.ir_freecount > 0)\r\nbreak;\r\nerror = xfs_btree_increment(cur, 0, &i);\r\nif (error)\r\ngoto error0;\r\nXFS_WANT_CORRUPTED_GOTO(mp, i == 1, error0);\r\n}\r\nalloc_inode:\r\noffset = xfs_inobt_first_free_inode(&rec);\r\nASSERT(offset >= 0);\r\nASSERT(offset < XFS_INODES_PER_CHUNK);\r\nASSERT((XFS_AGINO_TO_OFFSET(mp, rec.ir_startino) %\r\nXFS_INODES_PER_CHUNK) == 0);\r\nino = XFS_AGINO_TO_INO(mp, agno, rec.ir_startino + offset);\r\nrec.ir_free &= ~XFS_INOBT_MASK(offset);\r\nrec.ir_freecount--;\r\nerror = xfs_inobt_update(cur, &rec);\r\nif (error)\r\ngoto error0;\r\nbe32_add_cpu(&agi->agi_freecount, -1);\r\nxfs_ialloc_log_agi(tp, agbp, XFS_AGI_FREECOUNT);\r\npag->pagi_freecount--;\r\nerror = xfs_check_agi_freecount(cur, agi);\r\nif (error)\r\ngoto error0;\r\nxfs_btree_del_cursor(cur, XFS_BTREE_NOERROR);\r\nxfs_trans_mod_sb(tp, XFS_TRANS_SB_IFREE, -1);\r\nxfs_perag_put(pag);\r\n*inop = ino;\r\nreturn 0;\r\nerror1:\r\nxfs_btree_del_cursor(tcur, XFS_BTREE_ERROR);\r\nerror0:\r\nxfs_btree_del_cursor(cur, XFS_BTREE_ERROR);\r\nxfs_perag_put(pag);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_dialloc_ag_finobt_near(\r\nxfs_agino_t pagino,\r\nstruct xfs_btree_cur **ocur,\r\nstruct xfs_inobt_rec_incore *rec)\r\n{\r\nstruct xfs_btree_cur *lcur = *ocur;\r\nstruct xfs_btree_cur *rcur;\r\nstruct xfs_inobt_rec_incore rrec;\r\nint error;\r\nint i, j;\r\nerror = xfs_inobt_lookup(lcur, pagino, XFS_LOOKUP_LE, &i);\r\nif (error)\r\nreturn error;\r\nif (i == 1) {\r\nerror = xfs_inobt_get_rec(lcur, rec, &i);\r\nif (error)\r\nreturn error;\r\nXFS_WANT_CORRUPTED_RETURN(lcur->bc_mp, i == 1);\r\nif (pagino >= rec->ir_startino &&\r\npagino < (rec->ir_startino + XFS_INODES_PER_CHUNK))\r\nreturn 0;\r\n}\r\nerror = xfs_btree_dup_cursor(lcur, &rcur);\r\nif (error)\r\nreturn error;\r\nerror = xfs_inobt_lookup(rcur, pagino, XFS_LOOKUP_GE, &j);\r\nif (error)\r\ngoto error_rcur;\r\nif (j == 1) {\r\nerror = xfs_inobt_get_rec(rcur, &rrec, &j);\r\nif (error)\r\ngoto error_rcur;\r\nXFS_WANT_CORRUPTED_GOTO(lcur->bc_mp, j == 1, error_rcur);\r\n}\r\nXFS_WANT_CORRUPTED_GOTO(lcur->bc_mp, i == 1 || j == 1, error_rcur);\r\nif (i == 1 && j == 1) {\r\nif ((pagino - rec->ir_startino + XFS_INODES_PER_CHUNK - 1) >\r\n(rrec.ir_startino - pagino)) {\r\n*rec = rrec;\r\nxfs_btree_del_cursor(lcur, XFS_BTREE_NOERROR);\r\n*ocur = rcur;\r\n} else {\r\nxfs_btree_del_cursor(rcur, XFS_BTREE_NOERROR);\r\n}\r\n} else if (j == 1) {\r\n*rec = rrec;\r\nxfs_btree_del_cursor(lcur, XFS_BTREE_NOERROR);\r\n*ocur = rcur;\r\n} else if (i == 1) {\r\nxfs_btree_del_cursor(rcur, XFS_BTREE_NOERROR);\r\n}\r\nreturn 0;\r\nerror_rcur:\r\nxfs_btree_del_cursor(rcur, XFS_BTREE_ERROR);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_dialloc_ag_finobt_newino(\r\nstruct xfs_agi *agi,\r\nstruct xfs_btree_cur *cur,\r\nstruct xfs_inobt_rec_incore *rec)\r\n{\r\nint error;\r\nint i;\r\nif (agi->agi_newino != cpu_to_be32(NULLAGINO)) {\r\nerror = xfs_inobt_lookup(cur, be32_to_cpu(agi->agi_newino),\r\nXFS_LOOKUP_EQ, &i);\r\nif (error)\r\nreturn error;\r\nif (i == 1) {\r\nerror = xfs_inobt_get_rec(cur, rec, &i);\r\nif (error)\r\nreturn error;\r\nXFS_WANT_CORRUPTED_RETURN(cur->bc_mp, i == 1);\r\nreturn 0;\r\n}\r\n}\r\nerror = xfs_inobt_lookup(cur, 0, XFS_LOOKUP_GE, &i);\r\nif (error)\r\nreturn error;\r\nXFS_WANT_CORRUPTED_RETURN(cur->bc_mp, i == 1);\r\nerror = xfs_inobt_get_rec(cur, rec, &i);\r\nif (error)\r\nreturn error;\r\nXFS_WANT_CORRUPTED_RETURN(cur->bc_mp, i == 1);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_dialloc_ag_update_inobt(\r\nstruct xfs_btree_cur *cur,\r\nstruct xfs_inobt_rec_incore *frec,\r\nint offset)\r\n{\r\nstruct xfs_inobt_rec_incore rec;\r\nint error;\r\nint i;\r\nerror = xfs_inobt_lookup(cur, frec->ir_startino, XFS_LOOKUP_EQ, &i);\r\nif (error)\r\nreturn error;\r\nXFS_WANT_CORRUPTED_RETURN(cur->bc_mp, i == 1);\r\nerror = xfs_inobt_get_rec(cur, &rec, &i);\r\nif (error)\r\nreturn error;\r\nXFS_WANT_CORRUPTED_RETURN(cur->bc_mp, i == 1);\r\nASSERT((XFS_AGINO_TO_OFFSET(cur->bc_mp, rec.ir_startino) %\r\nXFS_INODES_PER_CHUNK) == 0);\r\nrec.ir_free &= ~XFS_INOBT_MASK(offset);\r\nrec.ir_freecount--;\r\nXFS_WANT_CORRUPTED_RETURN(cur->bc_mp, (rec.ir_free == frec->ir_free) &&\r\n(rec.ir_freecount == frec->ir_freecount));\r\nreturn xfs_inobt_update(cur, &rec);\r\n}\r\nSTATIC int\r\nxfs_dialloc_ag(\r\nstruct xfs_trans *tp,\r\nstruct xfs_buf *agbp,\r\nxfs_ino_t parent,\r\nxfs_ino_t *inop)\r\n{\r\nstruct xfs_mount *mp = tp->t_mountp;\r\nstruct xfs_agi *agi = XFS_BUF_TO_AGI(agbp);\r\nxfs_agnumber_t agno = be32_to_cpu(agi->agi_seqno);\r\nxfs_agnumber_t pagno = XFS_INO_TO_AGNO(mp, parent);\r\nxfs_agino_t pagino = XFS_INO_TO_AGINO(mp, parent);\r\nstruct xfs_perag *pag;\r\nstruct xfs_btree_cur *cur;\r\nstruct xfs_btree_cur *icur;\r\nstruct xfs_inobt_rec_incore rec;\r\nxfs_ino_t ino;\r\nint error;\r\nint offset;\r\nint i;\r\nif (!xfs_sb_version_hasfinobt(&mp->m_sb))\r\nreturn xfs_dialloc_ag_inobt(tp, agbp, parent, inop);\r\npag = xfs_perag_get(mp, agno);\r\nif (!pagino)\r\npagino = be32_to_cpu(agi->agi_newino);\r\ncur = xfs_inobt_init_cursor(mp, tp, agbp, agno, XFS_BTNUM_FINO);\r\nerror = xfs_check_agi_freecount(cur, agi);\r\nif (error)\r\ngoto error_cur;\r\nif (agno == pagno)\r\nerror = xfs_dialloc_ag_finobt_near(pagino, &cur, &rec);\r\nelse\r\nerror = xfs_dialloc_ag_finobt_newino(agi, cur, &rec);\r\nif (error)\r\ngoto error_cur;\r\noffset = xfs_inobt_first_free_inode(&rec);\r\nASSERT(offset >= 0);\r\nASSERT(offset < XFS_INODES_PER_CHUNK);\r\nASSERT((XFS_AGINO_TO_OFFSET(mp, rec.ir_startino) %\r\nXFS_INODES_PER_CHUNK) == 0);\r\nino = XFS_AGINO_TO_INO(mp, agno, rec.ir_startino + offset);\r\nrec.ir_free &= ~XFS_INOBT_MASK(offset);\r\nrec.ir_freecount--;\r\nif (rec.ir_freecount)\r\nerror = xfs_inobt_update(cur, &rec);\r\nelse\r\nerror = xfs_btree_delete(cur, &i);\r\nif (error)\r\ngoto error_cur;\r\nicur = xfs_inobt_init_cursor(mp, tp, agbp, agno, XFS_BTNUM_INO);\r\nerror = xfs_check_agi_freecount(icur, agi);\r\nif (error)\r\ngoto error_icur;\r\nerror = xfs_dialloc_ag_update_inobt(icur, &rec, offset);\r\nif (error)\r\ngoto error_icur;\r\nbe32_add_cpu(&agi->agi_freecount, -1);\r\nxfs_ialloc_log_agi(tp, agbp, XFS_AGI_FREECOUNT);\r\npag->pagi_freecount--;\r\nxfs_trans_mod_sb(tp, XFS_TRANS_SB_IFREE, -1);\r\nerror = xfs_check_agi_freecount(icur, agi);\r\nif (error)\r\ngoto error_icur;\r\nerror = xfs_check_agi_freecount(cur, agi);\r\nif (error)\r\ngoto error_icur;\r\nxfs_btree_del_cursor(icur, XFS_BTREE_NOERROR);\r\nxfs_btree_del_cursor(cur, XFS_BTREE_NOERROR);\r\nxfs_perag_put(pag);\r\n*inop = ino;\r\nreturn 0;\r\nerror_icur:\r\nxfs_btree_del_cursor(icur, XFS_BTREE_ERROR);\r\nerror_cur:\r\nxfs_btree_del_cursor(cur, XFS_BTREE_ERROR);\r\nxfs_perag_put(pag);\r\nreturn error;\r\n}\r\nint\r\nxfs_dialloc(\r\nstruct xfs_trans *tp,\r\nxfs_ino_t parent,\r\numode_t mode,\r\nint okalloc,\r\nstruct xfs_buf **IO_agbp,\r\nxfs_ino_t *inop)\r\n{\r\nstruct xfs_mount *mp = tp->t_mountp;\r\nstruct xfs_buf *agbp;\r\nxfs_agnumber_t agno;\r\nint error;\r\nint ialloced;\r\nint noroom = 0;\r\nxfs_agnumber_t start_agno;\r\nstruct xfs_perag *pag;\r\nif (*IO_agbp) {\r\nagbp = *IO_agbp;\r\ngoto out_alloc;\r\n}\r\nstart_agno = xfs_ialloc_ag_select(tp, parent, mode, okalloc);\r\nif (start_agno == NULLAGNUMBER) {\r\n*inop = NULLFSINO;\r\nreturn 0;\r\n}\r\nif (mp->m_maxicount &&\r\npercpu_counter_read_positive(&mp->m_icount) + mp->m_ialloc_inos\r\n> mp->m_maxicount) {\r\nnoroom = 1;\r\nokalloc = 0;\r\n}\r\nagno = start_agno;\r\nfor (;;) {\r\npag = xfs_perag_get(mp, agno);\r\nif (!pag->pagi_inodeok) {\r\nxfs_ialloc_next_ag(mp);\r\ngoto nextag;\r\n}\r\nif (!pag->pagi_init) {\r\nerror = xfs_ialloc_pagi_init(mp, tp, agno);\r\nif (error)\r\ngoto out_error;\r\n}\r\nif (!pag->pagi_freecount && !okalloc)\r\ngoto nextag;\r\nerror = xfs_ialloc_read_agi(mp, tp, agno, &agbp);\r\nif (error)\r\ngoto out_error;\r\nif (pag->pagi_freecount) {\r\nxfs_perag_put(pag);\r\ngoto out_alloc;\r\n}\r\nif (!okalloc)\r\ngoto nextag_relse_buffer;\r\nerror = xfs_ialloc_ag_alloc(tp, agbp, &ialloced);\r\nif (error) {\r\nxfs_trans_brelse(tp, agbp);\r\nif (error != -ENOSPC)\r\ngoto out_error;\r\nxfs_perag_put(pag);\r\n*inop = NULLFSINO;\r\nreturn 0;\r\n}\r\nif (ialloced) {\r\nASSERT(pag->pagi_freecount > 0);\r\nxfs_perag_put(pag);\r\n*IO_agbp = agbp;\r\n*inop = NULLFSINO;\r\nreturn 0;\r\n}\r\nnextag_relse_buffer:\r\nxfs_trans_brelse(tp, agbp);\r\nnextag:\r\nxfs_perag_put(pag);\r\nif (++agno == mp->m_sb.sb_agcount)\r\nagno = 0;\r\nif (agno == start_agno) {\r\n*inop = NULLFSINO;\r\nreturn noroom ? -ENOSPC : 0;\r\n}\r\n}\r\nout_alloc:\r\n*IO_agbp = NULL;\r\nreturn xfs_dialloc_ag(tp, agbp, parent, inop);\r\nout_error:\r\nxfs_perag_put(pag);\r\nreturn error;\r\n}\r\nSTATIC void\r\nxfs_difree_inode_chunk(\r\nstruct xfs_mount *mp,\r\nxfs_agnumber_t agno,\r\nstruct xfs_inobt_rec_incore *rec,\r\nstruct xfs_defer_ops *dfops)\r\n{\r\nxfs_agblock_t sagbno = XFS_AGINO_TO_AGBNO(mp, rec->ir_startino);\r\nint startidx, endidx;\r\nint nextbit;\r\nxfs_agblock_t agbno;\r\nint contigblk;\r\nstruct xfs_owner_info oinfo;\r\nDECLARE_BITMAP(holemask, XFS_INOBT_HOLEMASK_BITS);\r\nxfs_rmap_ag_owner(&oinfo, XFS_RMAP_OWN_INODES);\r\nif (!xfs_inobt_issparse(rec->ir_holemask)) {\r\nxfs_bmap_add_free(mp, dfops, XFS_AGB_TO_FSB(mp, agno, sagbno),\r\nmp->m_ialloc_blks, &oinfo);\r\nreturn;\r\n}\r\nASSERT(sizeof(rec->ir_holemask) <= sizeof(holemask[0]));\r\nholemask[0] = rec->ir_holemask;\r\nstartidx = endidx = find_first_zero_bit(holemask,\r\nXFS_INOBT_HOLEMASK_BITS);\r\nnextbit = startidx + 1;\r\nwhile (startidx < XFS_INOBT_HOLEMASK_BITS) {\r\nnextbit = find_next_zero_bit(holemask, XFS_INOBT_HOLEMASK_BITS,\r\nnextbit);\r\nif (nextbit != XFS_INOBT_HOLEMASK_BITS &&\r\nnextbit == endidx + 1) {\r\nendidx = nextbit;\r\ngoto next;\r\n}\r\nagbno = sagbno + (startidx * XFS_INODES_PER_HOLEMASK_BIT) /\r\nmp->m_sb.sb_inopblock;\r\ncontigblk = ((endidx - startidx + 1) *\r\nXFS_INODES_PER_HOLEMASK_BIT) /\r\nmp->m_sb.sb_inopblock;\r\nASSERT(agbno % mp->m_sb.sb_spino_align == 0);\r\nASSERT(contigblk % mp->m_sb.sb_spino_align == 0);\r\nxfs_bmap_add_free(mp, dfops, XFS_AGB_TO_FSB(mp, agno, agbno),\r\ncontigblk, &oinfo);\r\nstartidx = endidx = nextbit;\r\nnext:\r\nnextbit++;\r\n}\r\n}\r\nSTATIC int\r\nxfs_difree_inobt(\r\nstruct xfs_mount *mp,\r\nstruct xfs_trans *tp,\r\nstruct xfs_buf *agbp,\r\nxfs_agino_t agino,\r\nstruct xfs_defer_ops *dfops,\r\nstruct xfs_icluster *xic,\r\nstruct xfs_inobt_rec_incore *orec)\r\n{\r\nstruct xfs_agi *agi = XFS_BUF_TO_AGI(agbp);\r\nxfs_agnumber_t agno = be32_to_cpu(agi->agi_seqno);\r\nstruct xfs_perag *pag;\r\nstruct xfs_btree_cur *cur;\r\nstruct xfs_inobt_rec_incore rec;\r\nint ilen;\r\nint error;\r\nint i;\r\nint off;\r\nASSERT(agi->agi_magicnum == cpu_to_be32(XFS_AGI_MAGIC));\r\nASSERT(XFS_AGINO_TO_AGBNO(mp, agino) < be32_to_cpu(agi->agi_length));\r\ncur = xfs_inobt_init_cursor(mp, tp, agbp, agno, XFS_BTNUM_INO);\r\nerror = xfs_check_agi_freecount(cur, agi);\r\nif (error)\r\ngoto error0;\r\nif ((error = xfs_inobt_lookup(cur, agino, XFS_LOOKUP_LE, &i))) {\r\nxfs_warn(mp, "%s: xfs_inobt_lookup() returned error %d.",\r\n__func__, error);\r\ngoto error0;\r\n}\r\nXFS_WANT_CORRUPTED_GOTO(mp, i == 1, error0);\r\nerror = xfs_inobt_get_rec(cur, &rec, &i);\r\nif (error) {\r\nxfs_warn(mp, "%s: xfs_inobt_get_rec() returned error %d.",\r\n__func__, error);\r\ngoto error0;\r\n}\r\nXFS_WANT_CORRUPTED_GOTO(mp, i == 1, error0);\r\noff = agino - rec.ir_startino;\r\nASSERT(off >= 0 && off < XFS_INODES_PER_CHUNK);\r\nASSERT(!(rec.ir_free & XFS_INOBT_MASK(off)));\r\nrec.ir_free |= XFS_INOBT_MASK(off);\r\nrec.ir_freecount++;\r\nif (!(mp->m_flags & XFS_MOUNT_IKEEP) &&\r\nrec.ir_free == XFS_INOBT_ALL_FREE &&\r\nmp->m_sb.sb_inopblock <= XFS_INODES_PER_CHUNK) {\r\nxic->deleted = 1;\r\nxic->first_ino = XFS_AGINO_TO_INO(mp, agno, rec.ir_startino);\r\nxic->alloc = xfs_inobt_irec_to_allocmask(&rec);\r\nilen = rec.ir_freecount;\r\nbe32_add_cpu(&agi->agi_count, -ilen);\r\nbe32_add_cpu(&agi->agi_freecount, -(ilen - 1));\r\nxfs_ialloc_log_agi(tp, agbp, XFS_AGI_COUNT | XFS_AGI_FREECOUNT);\r\npag = xfs_perag_get(mp, agno);\r\npag->pagi_freecount -= ilen - 1;\r\nxfs_perag_put(pag);\r\nxfs_trans_mod_sb(tp, XFS_TRANS_SB_ICOUNT, -ilen);\r\nxfs_trans_mod_sb(tp, XFS_TRANS_SB_IFREE, -(ilen - 1));\r\nif ((error = xfs_btree_delete(cur, &i))) {\r\nxfs_warn(mp, "%s: xfs_btree_delete returned error %d.",\r\n__func__, error);\r\ngoto error0;\r\n}\r\nxfs_difree_inode_chunk(mp, agno, &rec, dfops);\r\n} else {\r\nxic->deleted = 0;\r\nerror = xfs_inobt_update(cur, &rec);\r\nif (error) {\r\nxfs_warn(mp, "%s: xfs_inobt_update returned error %d.",\r\n__func__, error);\r\ngoto error0;\r\n}\r\nbe32_add_cpu(&agi->agi_freecount, 1);\r\nxfs_ialloc_log_agi(tp, agbp, XFS_AGI_FREECOUNT);\r\npag = xfs_perag_get(mp, agno);\r\npag->pagi_freecount++;\r\nxfs_perag_put(pag);\r\nxfs_trans_mod_sb(tp, XFS_TRANS_SB_IFREE, 1);\r\n}\r\nerror = xfs_check_agi_freecount(cur, agi);\r\nif (error)\r\ngoto error0;\r\n*orec = rec;\r\nxfs_btree_del_cursor(cur, XFS_BTREE_NOERROR);\r\nreturn 0;\r\nerror0:\r\nxfs_btree_del_cursor(cur, XFS_BTREE_ERROR);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_difree_finobt(\r\nstruct xfs_mount *mp,\r\nstruct xfs_trans *tp,\r\nstruct xfs_buf *agbp,\r\nxfs_agino_t agino,\r\nstruct xfs_inobt_rec_incore *ibtrec)\r\n{\r\nstruct xfs_agi *agi = XFS_BUF_TO_AGI(agbp);\r\nxfs_agnumber_t agno = be32_to_cpu(agi->agi_seqno);\r\nstruct xfs_btree_cur *cur;\r\nstruct xfs_inobt_rec_incore rec;\r\nint offset = agino - ibtrec->ir_startino;\r\nint error;\r\nint i;\r\ncur = xfs_inobt_init_cursor(mp, tp, agbp, agno, XFS_BTNUM_FINO);\r\nerror = xfs_inobt_lookup(cur, ibtrec->ir_startino, XFS_LOOKUP_EQ, &i);\r\nif (error)\r\ngoto error;\r\nif (i == 0) {\r\nXFS_WANT_CORRUPTED_GOTO(mp, ibtrec->ir_freecount == 1, error);\r\nerror = xfs_inobt_insert_rec(cur, ibtrec->ir_holemask,\r\nibtrec->ir_count,\r\nibtrec->ir_freecount,\r\nibtrec->ir_free, &i);\r\nif (error)\r\ngoto error;\r\nASSERT(i == 1);\r\ngoto out;\r\n}\r\nerror = xfs_inobt_get_rec(cur, &rec, &i);\r\nif (error)\r\ngoto error;\r\nXFS_WANT_CORRUPTED_GOTO(mp, i == 1, error);\r\nrec.ir_free |= XFS_INOBT_MASK(offset);\r\nrec.ir_freecount++;\r\nXFS_WANT_CORRUPTED_GOTO(mp, (rec.ir_free == ibtrec->ir_free) &&\r\n(rec.ir_freecount == ibtrec->ir_freecount),\r\nerror);\r\nif (rec.ir_free == XFS_INOBT_ALL_FREE &&\r\nmp->m_sb.sb_inopblock <= XFS_INODES_PER_CHUNK &&\r\n!(mp->m_flags & XFS_MOUNT_IKEEP)) {\r\nerror = xfs_btree_delete(cur, &i);\r\nif (error)\r\ngoto error;\r\nASSERT(i == 1);\r\n} else {\r\nerror = xfs_inobt_update(cur, &rec);\r\nif (error)\r\ngoto error;\r\n}\r\nout:\r\nerror = xfs_check_agi_freecount(cur, agi);\r\nif (error)\r\ngoto error;\r\nxfs_btree_del_cursor(cur, XFS_BTREE_NOERROR);\r\nreturn 0;\r\nerror:\r\nxfs_btree_del_cursor(cur, XFS_BTREE_ERROR);\r\nreturn error;\r\n}\r\nint\r\nxfs_difree(\r\nstruct xfs_trans *tp,\r\nxfs_ino_t inode,\r\nstruct xfs_defer_ops *dfops,\r\nstruct xfs_icluster *xic)\r\n{\r\nxfs_agblock_t agbno;\r\nstruct xfs_buf *agbp;\r\nxfs_agino_t agino;\r\nxfs_agnumber_t agno;\r\nint error;\r\nstruct xfs_mount *mp;\r\nstruct xfs_inobt_rec_incore rec;\r\nmp = tp->t_mountp;\r\nagno = XFS_INO_TO_AGNO(mp, inode);\r\nif (agno >= mp->m_sb.sb_agcount) {\r\nxfs_warn(mp, "%s: agno >= mp->m_sb.sb_agcount (%d >= %d).",\r\n__func__, agno, mp->m_sb.sb_agcount);\r\nASSERT(0);\r\nreturn -EINVAL;\r\n}\r\nagino = XFS_INO_TO_AGINO(mp, inode);\r\nif (inode != XFS_AGINO_TO_INO(mp, agno, agino)) {\r\nxfs_warn(mp, "%s: inode != XFS_AGINO_TO_INO() (%llu != %llu).",\r\n__func__, (unsigned long long)inode,\r\n(unsigned long long)XFS_AGINO_TO_INO(mp, agno, agino));\r\nASSERT(0);\r\nreturn -EINVAL;\r\n}\r\nagbno = XFS_AGINO_TO_AGBNO(mp, agino);\r\nif (agbno >= mp->m_sb.sb_agblocks) {\r\nxfs_warn(mp, "%s: agbno >= mp->m_sb.sb_agblocks (%d >= %d).",\r\n__func__, agbno, mp->m_sb.sb_agblocks);\r\nASSERT(0);\r\nreturn -EINVAL;\r\n}\r\nerror = xfs_ialloc_read_agi(mp, tp, agno, &agbp);\r\nif (error) {\r\nxfs_warn(mp, "%s: xfs_ialloc_read_agi() returned error %d.",\r\n__func__, error);\r\nreturn error;\r\n}\r\nerror = xfs_difree_inobt(mp, tp, agbp, agino, dfops, xic, &rec);\r\nif (error)\r\ngoto error0;\r\nif (xfs_sb_version_hasfinobt(&mp->m_sb)) {\r\nerror = xfs_difree_finobt(mp, tp, agbp, agino, &rec);\r\nif (error)\r\ngoto error0;\r\n}\r\nreturn 0;\r\nerror0:\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_imap_lookup(\r\nstruct xfs_mount *mp,\r\nstruct xfs_trans *tp,\r\nxfs_agnumber_t agno,\r\nxfs_agino_t agino,\r\nxfs_agblock_t agbno,\r\nxfs_agblock_t *chunk_agbno,\r\nxfs_agblock_t *offset_agbno,\r\nint flags)\r\n{\r\nstruct xfs_inobt_rec_incore rec;\r\nstruct xfs_btree_cur *cur;\r\nstruct xfs_buf *agbp;\r\nint error;\r\nint i;\r\nerror = xfs_ialloc_read_agi(mp, tp, agno, &agbp);\r\nif (error) {\r\nxfs_alert(mp,\r\n"%s: xfs_ialloc_read_agi() returned error %d, agno %d",\r\n__func__, error, agno);\r\nreturn error;\r\n}\r\ncur = xfs_inobt_init_cursor(mp, tp, agbp, agno, XFS_BTNUM_INO);\r\nerror = xfs_inobt_lookup(cur, agino, XFS_LOOKUP_LE, &i);\r\nif (!error) {\r\nif (i)\r\nerror = xfs_inobt_get_rec(cur, &rec, &i);\r\nif (!error && i == 0)\r\nerror = -EINVAL;\r\n}\r\nxfs_trans_brelse(tp, agbp);\r\nxfs_btree_del_cursor(cur, error ? XFS_BTREE_ERROR : XFS_BTREE_NOERROR);\r\nif (error)\r\nreturn error;\r\nif (rec.ir_startino > agino ||\r\nrec.ir_startino + mp->m_ialloc_inos <= agino)\r\nreturn -EINVAL;\r\nif ((flags & XFS_IGET_UNTRUSTED) &&\r\n(rec.ir_free & XFS_INOBT_MASK(agino - rec.ir_startino)))\r\nreturn -EINVAL;\r\n*chunk_agbno = XFS_AGINO_TO_AGBNO(mp, rec.ir_startino);\r\n*offset_agbno = agbno - *chunk_agbno;\r\nreturn 0;\r\n}\r\nint\r\nxfs_imap(\r\nxfs_mount_t *mp,\r\nxfs_trans_t *tp,\r\nxfs_ino_t ino,\r\nstruct xfs_imap *imap,\r\nuint flags)\r\n{\r\nxfs_agblock_t agbno;\r\nxfs_agino_t agino;\r\nxfs_agnumber_t agno;\r\nint blks_per_cluster;\r\nxfs_agblock_t chunk_agbno;\r\nxfs_agblock_t cluster_agbno;\r\nint error;\r\nint offset;\r\nxfs_agblock_t offset_agbno;\r\nASSERT(ino != NULLFSINO);\r\nagno = XFS_INO_TO_AGNO(mp, ino);\r\nagino = XFS_INO_TO_AGINO(mp, ino);\r\nagbno = XFS_AGINO_TO_AGBNO(mp, agino);\r\nif (agno >= mp->m_sb.sb_agcount || agbno >= mp->m_sb.sb_agblocks ||\r\nino != XFS_AGINO_TO_INO(mp, agno, agino)) {\r\n#ifdef DEBUG\r\nif (flags & XFS_IGET_UNTRUSTED)\r\nreturn -EINVAL;\r\nif (agno >= mp->m_sb.sb_agcount) {\r\nxfs_alert(mp,\r\n"%s: agno (%d) >= mp->m_sb.sb_agcount (%d)",\r\n__func__, agno, mp->m_sb.sb_agcount);\r\n}\r\nif (agbno >= mp->m_sb.sb_agblocks) {\r\nxfs_alert(mp,\r\n"%s: agbno (0x%llx) >= mp->m_sb.sb_agblocks (0x%lx)",\r\n__func__, (unsigned long long)agbno,\r\n(unsigned long)mp->m_sb.sb_agblocks);\r\n}\r\nif (ino != XFS_AGINO_TO_INO(mp, agno, agino)) {\r\nxfs_alert(mp,\r\n"%s: ino (0x%llx) != XFS_AGINO_TO_INO() (0x%llx)",\r\n__func__, ino,\r\nXFS_AGINO_TO_INO(mp, agno, agino));\r\n}\r\nxfs_stack_trace();\r\n#endif\r\nreturn -EINVAL;\r\n}\r\nblks_per_cluster = xfs_icluster_size_fsb(mp);\r\nif (flags & XFS_IGET_UNTRUSTED) {\r\nerror = xfs_imap_lookup(mp, tp, agno, agino, agbno,\r\n&chunk_agbno, &offset_agbno, flags);\r\nif (error)\r\nreturn error;\r\ngoto out_map;\r\n}\r\nif (blks_per_cluster == 1) {\r\noffset = XFS_INO_TO_OFFSET(mp, ino);\r\nASSERT(offset < mp->m_sb.sb_inopblock);\r\nimap->im_blkno = XFS_AGB_TO_DADDR(mp, agno, agbno);\r\nimap->im_len = XFS_FSB_TO_BB(mp, 1);\r\nimap->im_boffset = (ushort)(offset << mp->m_sb.sb_inodelog);\r\nreturn 0;\r\n}\r\nif (mp->m_inoalign_mask) {\r\noffset_agbno = agbno & mp->m_inoalign_mask;\r\nchunk_agbno = agbno - offset_agbno;\r\n} else {\r\nerror = xfs_imap_lookup(mp, tp, agno, agino, agbno,\r\n&chunk_agbno, &offset_agbno, flags);\r\nif (error)\r\nreturn error;\r\n}\r\nout_map:\r\nASSERT(agbno >= chunk_agbno);\r\ncluster_agbno = chunk_agbno +\r\n((offset_agbno / blks_per_cluster) * blks_per_cluster);\r\noffset = ((agbno - cluster_agbno) * mp->m_sb.sb_inopblock) +\r\nXFS_INO_TO_OFFSET(mp, ino);\r\nimap->im_blkno = XFS_AGB_TO_DADDR(mp, agno, cluster_agbno);\r\nimap->im_len = XFS_FSB_TO_BB(mp, blks_per_cluster);\r\nimap->im_boffset = (ushort)(offset << mp->m_sb.sb_inodelog);\r\nif ((imap->im_blkno + imap->im_len) >\r\nXFS_FSB_TO_BB(mp, mp->m_sb.sb_dblocks)) {\r\nxfs_alert(mp,\r\n"%s: (im_blkno (0x%llx) + im_len (0x%llx)) > sb_dblocks (0x%llx)",\r\n__func__, (unsigned long long) imap->im_blkno,\r\n(unsigned long long) imap->im_len,\r\nXFS_FSB_TO_BB(mp, mp->m_sb.sb_dblocks));\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nvoid\r\nxfs_ialloc_compute_maxlevels(\r\nxfs_mount_t *mp)\r\n{\r\nuint inodes;\r\ninodes = (1LL << XFS_INO_AGINO_BITS(mp)) >> XFS_INODES_PER_CHUNK_LOG;\r\nmp->m_in_maxlevels = xfs_btree_compute_maxlevels(mp, mp->m_inobt_mnr,\r\ninodes);\r\n}\r\nvoid\r\nxfs_ialloc_log_agi(\r\nxfs_trans_t *tp,\r\nxfs_buf_t *bp,\r\nint fields)\r\n{\r\nint first;\r\nint last;\r\nstatic const short offsets[] = {\r\noffsetof(xfs_agi_t, agi_magicnum),\r\noffsetof(xfs_agi_t, agi_versionnum),\r\noffsetof(xfs_agi_t, agi_seqno),\r\noffsetof(xfs_agi_t, agi_length),\r\noffsetof(xfs_agi_t, agi_count),\r\noffsetof(xfs_agi_t, agi_root),\r\noffsetof(xfs_agi_t, agi_level),\r\noffsetof(xfs_agi_t, agi_freecount),\r\noffsetof(xfs_agi_t, agi_newino),\r\noffsetof(xfs_agi_t, agi_dirino),\r\noffsetof(xfs_agi_t, agi_unlinked),\r\noffsetof(xfs_agi_t, agi_free_root),\r\noffsetof(xfs_agi_t, agi_free_level),\r\nsizeof(xfs_agi_t)\r\n};\r\n#ifdef DEBUG\r\nxfs_agi_t *agi;\r\nagi = XFS_BUF_TO_AGI(bp);\r\nASSERT(agi->agi_magicnum == cpu_to_be32(XFS_AGI_MAGIC));\r\n#endif\r\nxfs_trans_buf_set_type(tp, bp, XFS_BLFT_AGI_BUF);\r\nif (fields & XFS_AGI_ALL_BITS_R1) {\r\nxfs_btree_offsets(fields, offsets, XFS_AGI_NUM_BITS_R1,\r\n&first, &last);\r\nxfs_trans_log_buf(tp, bp, first, last);\r\n}\r\nfields &= ~XFS_AGI_ALL_BITS_R1;\r\nif (fields) {\r\nxfs_btree_offsets(fields, offsets, XFS_AGI_NUM_BITS_R2,\r\n&first, &last);\r\nxfs_trans_log_buf(tp, bp, first, last);\r\n}\r\n}\r\nSTATIC void\r\nxfs_check_agi_unlinked(\r\nstruct xfs_agi *agi)\r\n{\r\nint i;\r\nfor (i = 0; i < XFS_AGI_UNLINKED_BUCKETS; i++)\r\nASSERT(agi->agi_unlinked[i]);\r\n}\r\nstatic bool\r\nxfs_agi_verify(\r\nstruct xfs_buf *bp)\r\n{\r\nstruct xfs_mount *mp = bp->b_target->bt_mount;\r\nstruct xfs_agi *agi = XFS_BUF_TO_AGI(bp);\r\nif (xfs_sb_version_hascrc(&mp->m_sb)) {\r\nif (!uuid_equal(&agi->agi_uuid, &mp->m_sb.sb_meta_uuid))\r\nreturn false;\r\nif (!xfs_log_check_lsn(mp,\r\nbe64_to_cpu(XFS_BUF_TO_AGI(bp)->agi_lsn)))\r\nreturn false;\r\n}\r\nif (agi->agi_magicnum != cpu_to_be32(XFS_AGI_MAGIC))\r\nreturn false;\r\nif (!XFS_AGI_GOOD_VERSION(be32_to_cpu(agi->agi_versionnum)))\r\nreturn false;\r\nif (be32_to_cpu(agi->agi_level) > XFS_BTREE_MAXLEVELS)\r\nreturn false;\r\nif (bp->b_pag && be32_to_cpu(agi->agi_seqno) != bp->b_pag->pag_agno)\r\nreturn false;\r\nxfs_check_agi_unlinked(agi);\r\nreturn true;\r\n}\r\nstatic void\r\nxfs_agi_read_verify(\r\nstruct xfs_buf *bp)\r\n{\r\nstruct xfs_mount *mp = bp->b_target->bt_mount;\r\nif (xfs_sb_version_hascrc(&mp->m_sb) &&\r\n!xfs_buf_verify_cksum(bp, XFS_AGI_CRC_OFF))\r\nxfs_buf_ioerror(bp, -EFSBADCRC);\r\nelse if (XFS_TEST_ERROR(!xfs_agi_verify(bp), mp,\r\nXFS_ERRTAG_IALLOC_READ_AGI,\r\nXFS_RANDOM_IALLOC_READ_AGI))\r\nxfs_buf_ioerror(bp, -EFSCORRUPTED);\r\nif (bp->b_error)\r\nxfs_verifier_error(bp);\r\n}\r\nstatic void\r\nxfs_agi_write_verify(\r\nstruct xfs_buf *bp)\r\n{\r\nstruct xfs_mount *mp = bp->b_target->bt_mount;\r\nstruct xfs_buf_log_item *bip = bp->b_fspriv;\r\nif (!xfs_agi_verify(bp)) {\r\nxfs_buf_ioerror(bp, -EFSCORRUPTED);\r\nxfs_verifier_error(bp);\r\nreturn;\r\n}\r\nif (!xfs_sb_version_hascrc(&mp->m_sb))\r\nreturn;\r\nif (bip)\r\nXFS_BUF_TO_AGI(bp)->agi_lsn = cpu_to_be64(bip->bli_item.li_lsn);\r\nxfs_buf_update_cksum(bp, XFS_AGI_CRC_OFF);\r\n}\r\nint\r\nxfs_read_agi(\r\nstruct xfs_mount *mp,\r\nstruct xfs_trans *tp,\r\nxfs_agnumber_t agno,\r\nstruct xfs_buf **bpp)\r\n{\r\nint error;\r\ntrace_xfs_read_agi(mp, agno);\r\nASSERT(agno != NULLAGNUMBER);\r\nerror = xfs_trans_read_buf(mp, tp, mp->m_ddev_targp,\r\nXFS_AG_DADDR(mp, agno, XFS_AGI_DADDR(mp)),\r\nXFS_FSS_TO_BB(mp, 1), 0, bpp, &xfs_agi_buf_ops);\r\nif (error)\r\nreturn error;\r\nxfs_buf_set_ref(*bpp, XFS_AGI_REF);\r\nreturn 0;\r\n}\r\nint\r\nxfs_ialloc_read_agi(\r\nstruct xfs_mount *mp,\r\nstruct xfs_trans *tp,\r\nxfs_agnumber_t agno,\r\nstruct xfs_buf **bpp)\r\n{\r\nstruct xfs_agi *agi;\r\nstruct xfs_perag *pag;\r\nint error;\r\ntrace_xfs_ialloc_read_agi(mp, agno);\r\nerror = xfs_read_agi(mp, tp, agno, bpp);\r\nif (error)\r\nreturn error;\r\nagi = XFS_BUF_TO_AGI(*bpp);\r\npag = xfs_perag_get(mp, agno);\r\nif (!pag->pagi_init) {\r\npag->pagi_freecount = be32_to_cpu(agi->agi_freecount);\r\npag->pagi_count = be32_to_cpu(agi->agi_count);\r\npag->pagi_init = 1;\r\n}\r\nASSERT(pag->pagi_freecount == be32_to_cpu(agi->agi_freecount) ||\r\nXFS_FORCED_SHUTDOWN(mp));\r\nxfs_perag_put(pag);\r\nreturn 0;\r\n}\r\nint\r\nxfs_ialloc_pagi_init(\r\nxfs_mount_t *mp,\r\nxfs_trans_t *tp,\r\nxfs_agnumber_t agno)\r\n{\r\nxfs_buf_t *bp = NULL;\r\nint error;\r\nerror = xfs_ialloc_read_agi(mp, tp, agno, &bp);\r\nif (error)\r\nreturn error;\r\nif (bp)\r\nxfs_trans_brelse(tp, bp);\r\nreturn 0;\r\n}
