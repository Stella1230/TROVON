int pcpu_freelist_init(struct pcpu_freelist *s)\r\n{\r\nint cpu;\r\ns->freelist = alloc_percpu(struct pcpu_freelist_head);\r\nif (!s->freelist)\r\nreturn -ENOMEM;\r\nfor_each_possible_cpu(cpu) {\r\nstruct pcpu_freelist_head *head = per_cpu_ptr(s->freelist, cpu);\r\nraw_spin_lock_init(&head->lock);\r\nhead->first = NULL;\r\n}\r\nreturn 0;\r\n}\r\nvoid pcpu_freelist_destroy(struct pcpu_freelist *s)\r\n{\r\nfree_percpu(s->freelist);\r\n}\r\nstatic inline void __pcpu_freelist_push(struct pcpu_freelist_head *head,\r\nstruct pcpu_freelist_node *node)\r\n{\r\nraw_spin_lock(&head->lock);\r\nnode->next = head->first;\r\nhead->first = node;\r\nraw_spin_unlock(&head->lock);\r\n}\r\nvoid pcpu_freelist_push(struct pcpu_freelist *s,\r\nstruct pcpu_freelist_node *node)\r\n{\r\nstruct pcpu_freelist_head *head = this_cpu_ptr(s->freelist);\r\n__pcpu_freelist_push(head, node);\r\n}\r\nvoid pcpu_freelist_populate(struct pcpu_freelist *s, void *buf, u32 elem_size,\r\nu32 nr_elems)\r\n{\r\nstruct pcpu_freelist_head *head;\r\nunsigned long flags;\r\nint i, cpu, pcpu_entries;\r\npcpu_entries = nr_elems / num_possible_cpus() + 1;\r\ni = 0;\r\nlocal_irq_save(flags);\r\nfor_each_possible_cpu(cpu) {\r\nagain:\r\nhead = per_cpu_ptr(s->freelist, cpu);\r\n__pcpu_freelist_push(head, buf);\r\ni++;\r\nbuf += elem_size;\r\nif (i == nr_elems)\r\nbreak;\r\nif (i % pcpu_entries)\r\ngoto again;\r\n}\r\nlocal_irq_restore(flags);\r\n}\r\nstruct pcpu_freelist_node *pcpu_freelist_pop(struct pcpu_freelist *s)\r\n{\r\nstruct pcpu_freelist_head *head;\r\nstruct pcpu_freelist_node *node;\r\nint orig_cpu, cpu;\r\norig_cpu = cpu = raw_smp_processor_id();\r\nwhile (1) {\r\nhead = per_cpu_ptr(s->freelist, cpu);\r\nraw_spin_lock(&head->lock);\r\nnode = head->first;\r\nif (node) {\r\nhead->first = node->next;\r\nraw_spin_unlock(&head->lock);\r\nreturn node;\r\n}\r\nraw_spin_unlock(&head->lock);\r\ncpu = cpumask_next(cpu, cpu_possible_mask);\r\nif (cpu >= nr_cpu_ids)\r\ncpu = 0;\r\nif (cpu == orig_cpu)\r\nreturn NULL;\r\n}\r\n}
