int __init extent_map_init(void)\r\n{\r\nextent_map_cache = kmem_cache_create("btrfs_extent_map",\r\nsizeof(struct extent_map), 0,\r\nSLAB_MEM_SPREAD, NULL);\r\nif (!extent_map_cache)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nvoid extent_map_exit(void)\r\n{\r\nkmem_cache_destroy(extent_map_cache);\r\n}\r\nvoid extent_map_tree_init(struct extent_map_tree *tree)\r\n{\r\ntree->map = RB_ROOT;\r\nINIT_LIST_HEAD(&tree->modified_extents);\r\nrwlock_init(&tree->lock);\r\n}\r\nstruct extent_map *alloc_extent_map(void)\r\n{\r\nstruct extent_map *em;\r\nem = kmem_cache_zalloc(extent_map_cache, GFP_NOFS);\r\nif (!em)\r\nreturn NULL;\r\nRB_CLEAR_NODE(&em->rb_node);\r\nem->flags = 0;\r\nem->compress_type = BTRFS_COMPRESS_NONE;\r\nem->generation = 0;\r\natomic_set(&em->refs, 1);\r\nINIT_LIST_HEAD(&em->list);\r\nreturn em;\r\n}\r\nvoid free_extent_map(struct extent_map *em)\r\n{\r\nif (!em)\r\nreturn;\r\nWARN_ON(atomic_read(&em->refs) == 0);\r\nif (atomic_dec_and_test(&em->refs)) {\r\nWARN_ON(extent_map_in_tree(em));\r\nWARN_ON(!list_empty(&em->list));\r\nif (test_bit(EXTENT_FLAG_FS_MAPPING, &em->flags))\r\nkfree(em->map_lookup);\r\nkmem_cache_free(extent_map_cache, em);\r\n}\r\n}\r\nstatic u64 range_end(u64 start, u64 len)\r\n{\r\nif (start + len < start)\r\nreturn (u64)-1;\r\nreturn start + len;\r\n}\r\nstatic int tree_insert(struct rb_root *root, struct extent_map *em)\r\n{\r\nstruct rb_node **p = &root->rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct extent_map *entry = NULL;\r\nstruct rb_node *orig_parent = NULL;\r\nu64 end = range_end(em->start, em->len);\r\nwhile (*p) {\r\nparent = *p;\r\nentry = rb_entry(parent, struct extent_map, rb_node);\r\nif (em->start < entry->start)\r\np = &(*p)->rb_left;\r\nelse if (em->start >= extent_map_end(entry))\r\np = &(*p)->rb_right;\r\nelse\r\nreturn -EEXIST;\r\n}\r\norig_parent = parent;\r\nwhile (parent && em->start >= extent_map_end(entry)) {\r\nparent = rb_next(parent);\r\nentry = rb_entry(parent, struct extent_map, rb_node);\r\n}\r\nif (parent)\r\nif (end > entry->start && em->start < extent_map_end(entry))\r\nreturn -EEXIST;\r\nparent = orig_parent;\r\nentry = rb_entry(parent, struct extent_map, rb_node);\r\nwhile (parent && em->start < entry->start) {\r\nparent = rb_prev(parent);\r\nentry = rb_entry(parent, struct extent_map, rb_node);\r\n}\r\nif (parent)\r\nif (end > entry->start && em->start < extent_map_end(entry))\r\nreturn -EEXIST;\r\nrb_link_node(&em->rb_node, orig_parent, p);\r\nrb_insert_color(&em->rb_node, root);\r\nreturn 0;\r\n}\r\nstatic struct rb_node *__tree_search(struct rb_root *root, u64 offset,\r\nstruct rb_node **prev_ret,\r\nstruct rb_node **next_ret)\r\n{\r\nstruct rb_node *n = root->rb_node;\r\nstruct rb_node *prev = NULL;\r\nstruct rb_node *orig_prev = NULL;\r\nstruct extent_map *entry;\r\nstruct extent_map *prev_entry = NULL;\r\nwhile (n) {\r\nentry = rb_entry(n, struct extent_map, rb_node);\r\nprev = n;\r\nprev_entry = entry;\r\nif (offset < entry->start)\r\nn = n->rb_left;\r\nelse if (offset >= extent_map_end(entry))\r\nn = n->rb_right;\r\nelse\r\nreturn n;\r\n}\r\nif (prev_ret) {\r\norig_prev = prev;\r\nwhile (prev && offset >= extent_map_end(prev_entry)) {\r\nprev = rb_next(prev);\r\nprev_entry = rb_entry(prev, struct extent_map, rb_node);\r\n}\r\n*prev_ret = prev;\r\nprev = orig_prev;\r\n}\r\nif (next_ret) {\r\nprev_entry = rb_entry(prev, struct extent_map, rb_node);\r\nwhile (prev && offset < prev_entry->start) {\r\nprev = rb_prev(prev);\r\nprev_entry = rb_entry(prev, struct extent_map, rb_node);\r\n}\r\n*next_ret = prev;\r\n}\r\nreturn NULL;\r\n}\r\nstatic int mergable_maps(struct extent_map *prev, struct extent_map *next)\r\n{\r\nif (test_bit(EXTENT_FLAG_PINNED, &prev->flags))\r\nreturn 0;\r\nif (test_bit(EXTENT_FLAG_COMPRESSED, &prev->flags))\r\nreturn 0;\r\nif (test_bit(EXTENT_FLAG_LOGGING, &prev->flags) ||\r\ntest_bit(EXTENT_FLAG_LOGGING, &next->flags))\r\nreturn 0;\r\nif (!list_empty(&prev->list) || !list_empty(&next->list))\r\nreturn 0;\r\nif (extent_map_end(prev) == next->start &&\r\nprev->flags == next->flags &&\r\nprev->bdev == next->bdev &&\r\n((next->block_start == EXTENT_MAP_HOLE &&\r\nprev->block_start == EXTENT_MAP_HOLE) ||\r\n(next->block_start == EXTENT_MAP_INLINE &&\r\nprev->block_start == EXTENT_MAP_INLINE) ||\r\n(next->block_start == EXTENT_MAP_DELALLOC &&\r\nprev->block_start == EXTENT_MAP_DELALLOC) ||\r\n(next->block_start < EXTENT_MAP_LAST_BYTE - 1 &&\r\nnext->block_start == extent_map_block_end(prev)))) {\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic void try_merge_map(struct extent_map_tree *tree, struct extent_map *em)\r\n{\r\nstruct extent_map *merge = NULL;\r\nstruct rb_node *rb;\r\nif (em->start != 0) {\r\nrb = rb_prev(&em->rb_node);\r\nif (rb)\r\nmerge = rb_entry(rb, struct extent_map, rb_node);\r\nif (rb && mergable_maps(merge, em)) {\r\nem->start = merge->start;\r\nem->orig_start = merge->orig_start;\r\nem->len += merge->len;\r\nem->block_len += merge->block_len;\r\nem->block_start = merge->block_start;\r\nem->mod_len = (em->mod_len + em->mod_start) - merge->mod_start;\r\nem->mod_start = merge->mod_start;\r\nem->generation = max(em->generation, merge->generation);\r\nrb_erase(&merge->rb_node, &tree->map);\r\nRB_CLEAR_NODE(&merge->rb_node);\r\nfree_extent_map(merge);\r\n}\r\n}\r\nrb = rb_next(&em->rb_node);\r\nif (rb)\r\nmerge = rb_entry(rb, struct extent_map, rb_node);\r\nif (rb && mergable_maps(em, merge)) {\r\nem->len += merge->len;\r\nem->block_len += merge->block_len;\r\nrb_erase(&merge->rb_node, &tree->map);\r\nRB_CLEAR_NODE(&merge->rb_node);\r\nem->mod_len = (merge->mod_start + merge->mod_len) - em->mod_start;\r\nem->generation = max(em->generation, merge->generation);\r\nfree_extent_map(merge);\r\n}\r\n}\r\nint unpin_extent_cache(struct extent_map_tree *tree, u64 start, u64 len,\r\nu64 gen)\r\n{\r\nint ret = 0;\r\nstruct extent_map *em;\r\nbool prealloc = false;\r\nwrite_lock(&tree->lock);\r\nem = lookup_extent_mapping(tree, start, len);\r\nWARN_ON(!em || em->start != start);\r\nif (!em)\r\ngoto out;\r\nem->generation = gen;\r\nclear_bit(EXTENT_FLAG_PINNED, &em->flags);\r\nem->mod_start = em->start;\r\nem->mod_len = em->len;\r\nif (test_bit(EXTENT_FLAG_FILLING, &em->flags)) {\r\nprealloc = true;\r\nclear_bit(EXTENT_FLAG_FILLING, &em->flags);\r\n}\r\ntry_merge_map(tree, em);\r\nif (prealloc) {\r\nem->mod_start = em->start;\r\nem->mod_len = em->len;\r\n}\r\nfree_extent_map(em);\r\nout:\r\nwrite_unlock(&tree->lock);\r\nreturn ret;\r\n}\r\nvoid clear_em_logging(struct extent_map_tree *tree, struct extent_map *em)\r\n{\r\nclear_bit(EXTENT_FLAG_LOGGING, &em->flags);\r\nif (extent_map_in_tree(em))\r\ntry_merge_map(tree, em);\r\n}\r\nstatic inline void setup_extent_mapping(struct extent_map_tree *tree,\r\nstruct extent_map *em,\r\nint modified)\r\n{\r\natomic_inc(&em->refs);\r\nem->mod_start = em->start;\r\nem->mod_len = em->len;\r\nif (modified)\r\nlist_move(&em->list, &tree->modified_extents);\r\nelse\r\ntry_merge_map(tree, em);\r\n}\r\nint add_extent_mapping(struct extent_map_tree *tree,\r\nstruct extent_map *em, int modified)\r\n{\r\nint ret = 0;\r\nret = tree_insert(&tree->map, em);\r\nif (ret)\r\ngoto out;\r\nsetup_extent_mapping(tree, em, modified);\r\nout:\r\nreturn ret;\r\n}\r\nstatic struct extent_map *\r\n__lookup_extent_mapping(struct extent_map_tree *tree,\r\nu64 start, u64 len, int strict)\r\n{\r\nstruct extent_map *em;\r\nstruct rb_node *rb_node;\r\nstruct rb_node *prev = NULL;\r\nstruct rb_node *next = NULL;\r\nu64 end = range_end(start, len);\r\nrb_node = __tree_search(&tree->map, start, &prev, &next);\r\nif (!rb_node) {\r\nif (prev)\r\nrb_node = prev;\r\nelse if (next)\r\nrb_node = next;\r\nelse\r\nreturn NULL;\r\n}\r\nem = rb_entry(rb_node, struct extent_map, rb_node);\r\nif (strict && !(end > em->start && start < extent_map_end(em)))\r\nreturn NULL;\r\natomic_inc(&em->refs);\r\nreturn em;\r\n}\r\nstruct extent_map *lookup_extent_mapping(struct extent_map_tree *tree,\r\nu64 start, u64 len)\r\n{\r\nreturn __lookup_extent_mapping(tree, start, len, 1);\r\n}\r\nstruct extent_map *search_extent_mapping(struct extent_map_tree *tree,\r\nu64 start, u64 len)\r\n{\r\nreturn __lookup_extent_mapping(tree, start, len, 0);\r\n}\r\nint remove_extent_mapping(struct extent_map_tree *tree, struct extent_map *em)\r\n{\r\nint ret = 0;\r\nWARN_ON(test_bit(EXTENT_FLAG_PINNED, &em->flags));\r\nrb_erase(&em->rb_node, &tree->map);\r\nif (!test_bit(EXTENT_FLAG_LOGGING, &em->flags))\r\nlist_del_init(&em->list);\r\nRB_CLEAR_NODE(&em->rb_node);\r\nreturn ret;\r\n}\r\nvoid replace_extent_mapping(struct extent_map_tree *tree,\r\nstruct extent_map *cur,\r\nstruct extent_map *new,\r\nint modified)\r\n{\r\nWARN_ON(test_bit(EXTENT_FLAG_PINNED, &cur->flags));\r\nASSERT(extent_map_in_tree(cur));\r\nif (!test_bit(EXTENT_FLAG_LOGGING, &cur->flags))\r\nlist_del_init(&cur->list);\r\nrb_replace_node(&cur->rb_node, &new->rb_node, &tree->map);\r\nRB_CLEAR_NODE(&cur->rb_node);\r\nsetup_extent_mapping(tree, new, modified);\r\n}
