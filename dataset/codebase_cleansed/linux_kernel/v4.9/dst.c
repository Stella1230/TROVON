static void dst_gc_task(struct work_struct *work)\r\n{\r\nint delayed = 0;\r\nint work_performed = 0;\r\nunsigned long expires = ~0L;\r\nstruct dst_entry *dst, *next, head;\r\nstruct dst_entry *last = &head;\r\nmutex_lock(&dst_gc_mutex);\r\nnext = dst_busy_list;\r\nloop:\r\nwhile ((dst = next) != NULL) {\r\nnext = dst->next;\r\nprefetch(&next->next);\r\ncond_resched();\r\nif (likely(atomic_read(&dst->__refcnt))) {\r\nlast->next = dst;\r\nlast = dst;\r\ndelayed++;\r\ncontinue;\r\n}\r\nwork_performed++;\r\ndst = dst_destroy(dst);\r\nif (dst) {\r\nif (dst->obsolete > 0)\r\ncontinue;\r\n___dst_free(dst);\r\ndst->next = next;\r\nnext = dst;\r\n}\r\n}\r\nspin_lock_bh(&dst_garbage.lock);\r\nnext = dst_garbage.list;\r\nif (next) {\r\ndst_garbage.list = NULL;\r\nspin_unlock_bh(&dst_garbage.lock);\r\ngoto loop;\r\n}\r\nlast->next = NULL;\r\ndst_busy_list = head.next;\r\nif (!dst_busy_list)\r\ndst_garbage.timer_inc = DST_GC_MAX;\r\nelse {\r\nif (work_performed <= delayed/10) {\r\ndst_garbage.timer_expires += dst_garbage.timer_inc;\r\nif (dst_garbage.timer_expires > DST_GC_MAX)\r\ndst_garbage.timer_expires = DST_GC_MAX;\r\ndst_garbage.timer_inc += DST_GC_INC;\r\n} else {\r\ndst_garbage.timer_inc = DST_GC_INC;\r\ndst_garbage.timer_expires = DST_GC_MIN;\r\n}\r\nexpires = dst_garbage.timer_expires;\r\nif (expires > 4*HZ)\r\nexpires = round_jiffies_relative(expires);\r\nschedule_delayed_work(&dst_gc_work, expires);\r\n}\r\nspin_unlock_bh(&dst_garbage.lock);\r\nmutex_unlock(&dst_gc_mutex);\r\n}\r\nint dst_discard_out(struct net *net, struct sock *sk, struct sk_buff *skb)\r\n{\r\nkfree_skb(skb);\r\nreturn 0;\r\n}\r\nvoid dst_init(struct dst_entry *dst, struct dst_ops *ops,\r\nstruct net_device *dev, int initial_ref, int initial_obsolete,\r\nunsigned short flags)\r\n{\r\ndst->child = NULL;\r\ndst->dev = dev;\r\nif (dev)\r\ndev_hold(dev);\r\ndst->ops = ops;\r\ndst_init_metrics(dst, dst_default_metrics, true);\r\ndst->expires = 0UL;\r\ndst->path = dst;\r\ndst->from = NULL;\r\n#ifdef CONFIG_XFRM\r\ndst->xfrm = NULL;\r\n#endif\r\ndst->input = dst_discard;\r\ndst->output = dst_discard_out;\r\ndst->error = 0;\r\ndst->obsolete = initial_obsolete;\r\ndst->header_len = 0;\r\ndst->trailer_len = 0;\r\n#ifdef CONFIG_IP_ROUTE_CLASSID\r\ndst->tclassid = 0;\r\n#endif\r\ndst->lwtstate = NULL;\r\natomic_set(&dst->__refcnt, initial_ref);\r\ndst->__use = 0;\r\ndst->lastuse = jiffies;\r\ndst->flags = flags;\r\ndst->pending_confirm = 0;\r\ndst->next = NULL;\r\nif (!(flags & DST_NOCOUNT))\r\ndst_entries_add(ops, 1);\r\n}\r\nvoid *dst_alloc(struct dst_ops *ops, struct net_device *dev,\r\nint initial_ref, int initial_obsolete, unsigned short flags)\r\n{\r\nstruct dst_entry *dst;\r\nif (ops->gc && dst_entries_get_fast(ops) > ops->gc_thresh) {\r\nif (ops->gc(ops))\r\nreturn NULL;\r\n}\r\ndst = kmem_cache_alloc(ops->kmem_cachep, GFP_ATOMIC);\r\nif (!dst)\r\nreturn NULL;\r\ndst_init(dst, ops, dev, initial_ref, initial_obsolete, flags);\r\nreturn dst;\r\n}\r\nstatic void ___dst_free(struct dst_entry *dst)\r\n{\r\nif (dst->dev == NULL || !(dst->dev->flags&IFF_UP)) {\r\ndst->input = dst_discard;\r\ndst->output = dst_discard_out;\r\n}\r\ndst->obsolete = DST_OBSOLETE_DEAD;\r\n}\r\nvoid __dst_free(struct dst_entry *dst)\r\n{\r\nspin_lock_bh(&dst_garbage.lock);\r\n___dst_free(dst);\r\ndst->next = dst_garbage.list;\r\ndst_garbage.list = dst;\r\nif (dst_garbage.timer_inc > DST_GC_INC) {\r\ndst_garbage.timer_inc = DST_GC_INC;\r\ndst_garbage.timer_expires = DST_GC_MIN;\r\nmod_delayed_work(system_wq, &dst_gc_work,\r\ndst_garbage.timer_expires);\r\n}\r\nspin_unlock_bh(&dst_garbage.lock);\r\n}\r\nstruct dst_entry *dst_destroy(struct dst_entry * dst)\r\n{\r\nstruct dst_entry *child;\r\nsmp_rmb();\r\nagain:\r\nchild = dst->child;\r\nif (!(dst->flags & DST_NOCOUNT))\r\ndst_entries_add(dst->ops, -1);\r\nif (dst->ops->destroy)\r\ndst->ops->destroy(dst);\r\nif (dst->dev)\r\ndev_put(dst->dev);\r\nlwtstate_put(dst->lwtstate);\r\nif (dst->flags & DST_METADATA)\r\nmetadata_dst_free((struct metadata_dst *)dst);\r\nelse\r\nkmem_cache_free(dst->ops->kmem_cachep, dst);\r\ndst = child;\r\nif (dst) {\r\nint nohash = dst->flags & DST_NOHASH;\r\nif (atomic_dec_and_test(&dst->__refcnt)) {\r\nif (nohash)\r\ngoto again;\r\n} else {\r\nif (nohash)\r\nreturn dst;\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nstatic void dst_destroy_rcu(struct rcu_head *head)\r\n{\r\nstruct dst_entry *dst = container_of(head, struct dst_entry, rcu_head);\r\ndst = dst_destroy(dst);\r\nif (dst)\r\n__dst_free(dst);\r\n}\r\nvoid dst_release(struct dst_entry *dst)\r\n{\r\nif (dst) {\r\nint newrefcnt;\r\nunsigned short nocache = dst->flags & DST_NOCACHE;\r\nnewrefcnt = atomic_dec_return(&dst->__refcnt);\r\nif (unlikely(newrefcnt < 0))\r\nnet_warn_ratelimited("%s: dst:%p refcnt:%d\n",\r\n__func__, dst, newrefcnt);\r\nif (!newrefcnt && unlikely(nocache))\r\ncall_rcu(&dst->rcu_head, dst_destroy_rcu);\r\n}\r\n}\r\nu32 *dst_cow_metrics_generic(struct dst_entry *dst, unsigned long old)\r\n{\r\nu32 *p = kmalloc(sizeof(u32) * RTAX_MAX, GFP_ATOMIC);\r\nif (p) {\r\nu32 *old_p = __DST_METRICS_PTR(old);\r\nunsigned long prev, new;\r\nmemcpy(p, old_p, sizeof(u32) * RTAX_MAX);\r\nnew = (unsigned long) p;\r\nprev = cmpxchg(&dst->_metrics, old, new);\r\nif (prev != old) {\r\nkfree(p);\r\np = __DST_METRICS_PTR(prev);\r\nif (prev & DST_METRICS_READ_ONLY)\r\np = NULL;\r\n}\r\n}\r\nreturn p;\r\n}\r\nvoid __dst_destroy_metrics_generic(struct dst_entry *dst, unsigned long old)\r\n{\r\nunsigned long prev, new;\r\nnew = ((unsigned long) dst_default_metrics) | DST_METRICS_READ_ONLY;\r\nprev = cmpxchg(&dst->_metrics, old, new);\r\nif (prev == old)\r\nkfree(__DST_METRICS_PTR(old));\r\n}\r\nstatic int dst_md_discard_out(struct net *net, struct sock *sk, struct sk_buff *skb)\r\n{\r\nWARN_ONCE(1, "Attempting to call output on metadata dst\n");\r\nkfree_skb(skb);\r\nreturn 0;\r\n}\r\nstatic int dst_md_discard(struct sk_buff *skb)\r\n{\r\nWARN_ONCE(1, "Attempting to call input on metadata dst\n");\r\nkfree_skb(skb);\r\nreturn 0;\r\n}\r\nstatic void __metadata_dst_init(struct metadata_dst *md_dst, u8 optslen)\r\n{\r\nstruct dst_entry *dst;\r\ndst = &md_dst->dst;\r\ndst_init(dst, &md_dst_ops, NULL, 1, DST_OBSOLETE_NONE,\r\nDST_METADATA | DST_NOCACHE | DST_NOCOUNT);\r\ndst->input = dst_md_discard;\r\ndst->output = dst_md_discard_out;\r\nmemset(dst + 1, 0, sizeof(*md_dst) + optslen - sizeof(*dst));\r\n}\r\nstruct metadata_dst *metadata_dst_alloc(u8 optslen, gfp_t flags)\r\n{\r\nstruct metadata_dst *md_dst;\r\nmd_dst = kmalloc(sizeof(*md_dst) + optslen, flags);\r\nif (!md_dst)\r\nreturn NULL;\r\n__metadata_dst_init(md_dst, optslen);\r\nreturn md_dst;\r\n}\r\nvoid metadata_dst_free(struct metadata_dst *md_dst)\r\n{\r\n#ifdef CONFIG_DST_CACHE\r\ndst_cache_destroy(&md_dst->u.tun_info.dst_cache);\r\n#endif\r\nkfree(md_dst);\r\n}\r\nstruct metadata_dst __percpu *metadata_dst_alloc_percpu(u8 optslen, gfp_t flags)\r\n{\r\nint cpu;\r\nstruct metadata_dst __percpu *md_dst;\r\nmd_dst = __alloc_percpu_gfp(sizeof(struct metadata_dst) + optslen,\r\n__alignof__(struct metadata_dst), flags);\r\nif (!md_dst)\r\nreturn NULL;\r\nfor_each_possible_cpu(cpu)\r\n__metadata_dst_init(per_cpu_ptr(md_dst, cpu), optslen);\r\nreturn md_dst;\r\n}\r\nstatic void dst_ifdown(struct dst_entry *dst, struct net_device *dev,\r\nint unregister)\r\n{\r\nif (dst->ops->ifdown)\r\ndst->ops->ifdown(dst, dev, unregister);\r\nif (dev != dst->dev)\r\nreturn;\r\nif (!unregister) {\r\ndst->input = dst_discard;\r\ndst->output = dst_discard_out;\r\n} else {\r\ndst->dev = dev_net(dst->dev)->loopback_dev;\r\ndev_hold(dst->dev);\r\ndev_put(dev);\r\n}\r\n}\r\nstatic int dst_dev_event(struct notifier_block *this, unsigned long event,\r\nvoid *ptr)\r\n{\r\nstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\r\nstruct dst_entry *dst, *last = NULL;\r\nswitch (event) {\r\ncase NETDEV_UNREGISTER_FINAL:\r\ncase NETDEV_DOWN:\r\nmutex_lock(&dst_gc_mutex);\r\nfor (dst = dst_busy_list; dst; dst = dst->next) {\r\nlast = dst;\r\ndst_ifdown(dst, dev, event != NETDEV_DOWN);\r\n}\r\nspin_lock_bh(&dst_garbage.lock);\r\ndst = dst_garbage.list;\r\ndst_garbage.list = NULL;\r\nspin_unlock_bh(&dst_garbage.lock);\r\nif (last)\r\nlast->next = dst;\r\nelse\r\ndst_busy_list = dst;\r\nfor (; dst; dst = dst->next)\r\ndst_ifdown(dst, dev, event != NETDEV_DOWN);\r\nmutex_unlock(&dst_gc_mutex);\r\nbreak;\r\n}\r\nreturn NOTIFY_DONE;\r\n}\r\nvoid __init dst_subsys_init(void)\r\n{\r\nregister_netdevice_notifier(&dst_dev_notifier);\r\n}
