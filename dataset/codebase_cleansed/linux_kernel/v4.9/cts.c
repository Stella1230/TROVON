static inline u8 *crypto_cts_reqctx_space(struct skcipher_request *req)\r\n{\r\nstruct crypto_cts_reqctx *rctx = skcipher_request_ctx(req);\r\nstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\r\nstruct crypto_cts_ctx *ctx = crypto_skcipher_ctx(tfm);\r\nstruct crypto_skcipher *child = ctx->child;\r\nreturn PTR_ALIGN((u8 *)(rctx + 1) + crypto_skcipher_reqsize(child),\r\ncrypto_skcipher_alignmask(tfm) + 1);\r\n}\r\nstatic int crypto_cts_setkey(struct crypto_skcipher *parent, const u8 *key,\r\nunsigned int keylen)\r\n{\r\nstruct crypto_cts_ctx *ctx = crypto_skcipher_ctx(parent);\r\nstruct crypto_skcipher *child = ctx->child;\r\nint err;\r\ncrypto_skcipher_clear_flags(child, CRYPTO_TFM_REQ_MASK);\r\ncrypto_skcipher_set_flags(child, crypto_skcipher_get_flags(parent) &\r\nCRYPTO_TFM_REQ_MASK);\r\nerr = crypto_skcipher_setkey(child, key, keylen);\r\ncrypto_skcipher_set_flags(parent, crypto_skcipher_get_flags(child) &\r\nCRYPTO_TFM_RES_MASK);\r\nreturn err;\r\n}\r\nstatic void cts_cbc_crypt_done(struct crypto_async_request *areq, int err)\r\n{\r\nstruct skcipher_request *req = areq->data;\r\nif (err == -EINPROGRESS)\r\nreturn;\r\nskcipher_request_complete(req, err);\r\n}\r\nstatic int cts_cbc_encrypt(struct skcipher_request *req)\r\n{\r\nstruct crypto_cts_reqctx *rctx = skcipher_request_ctx(req);\r\nstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\r\nstruct skcipher_request *subreq = &rctx->subreq;\r\nint bsize = crypto_skcipher_blocksize(tfm);\r\nu8 d[bsize * 2] __attribute__ ((aligned(__alignof__(u32))));\r\nstruct scatterlist *sg;\r\nunsigned int offset;\r\nint lastn;\r\noffset = rctx->offset;\r\nlastn = req->cryptlen - offset;\r\nsg = scatterwalk_ffwd(rctx->sg, req->dst, offset - bsize);\r\nscatterwalk_map_and_copy(d + bsize, sg, 0, bsize, 0);\r\nmemset(d, 0, bsize);\r\nscatterwalk_map_and_copy(d, req->src, offset, lastn, 0);\r\nscatterwalk_map_and_copy(d, sg, 0, bsize + lastn, 1);\r\nmemzero_explicit(d, sizeof(d));\r\nskcipher_request_set_callback(subreq, req->base.flags &\r\nCRYPTO_TFM_REQ_MAY_BACKLOG,\r\ncts_cbc_crypt_done, req);\r\nskcipher_request_set_crypt(subreq, sg, sg, bsize, req->iv);\r\nreturn crypto_skcipher_encrypt(subreq);\r\n}\r\nstatic void crypto_cts_encrypt_done(struct crypto_async_request *areq, int err)\r\n{\r\nstruct skcipher_request *req = areq->data;\r\nif (err)\r\ngoto out;\r\nerr = cts_cbc_encrypt(req);\r\nif (err == -EINPROGRESS ||\r\n(err == -EBUSY && req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG))\r\nreturn;\r\nout:\r\nskcipher_request_complete(req, err);\r\n}\r\nstatic int crypto_cts_encrypt(struct skcipher_request *req)\r\n{\r\nstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\r\nstruct crypto_cts_reqctx *rctx = skcipher_request_ctx(req);\r\nstruct crypto_cts_ctx *ctx = crypto_skcipher_ctx(tfm);\r\nstruct skcipher_request *subreq = &rctx->subreq;\r\nint bsize = crypto_skcipher_blocksize(tfm);\r\nunsigned int nbytes = req->cryptlen;\r\nint cbc_blocks = (nbytes + bsize - 1) / bsize - 1;\r\nunsigned int offset;\r\nskcipher_request_set_tfm(subreq, ctx->child);\r\nif (cbc_blocks <= 0) {\r\nskcipher_request_set_callback(subreq, req->base.flags,\r\nreq->base.complete,\r\nreq->base.data);\r\nskcipher_request_set_crypt(subreq, req->src, req->dst, nbytes,\r\nreq->iv);\r\nreturn crypto_skcipher_encrypt(subreq);\r\n}\r\noffset = cbc_blocks * bsize;\r\nrctx->offset = offset;\r\nskcipher_request_set_callback(subreq, req->base.flags,\r\ncrypto_cts_encrypt_done, req);\r\nskcipher_request_set_crypt(subreq, req->src, req->dst,\r\noffset, req->iv);\r\nreturn crypto_skcipher_encrypt(subreq) ?:\r\ncts_cbc_encrypt(req);\r\n}\r\nstatic int cts_cbc_decrypt(struct skcipher_request *req)\r\n{\r\nstruct crypto_cts_reqctx *rctx = skcipher_request_ctx(req);\r\nstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\r\nstruct skcipher_request *subreq = &rctx->subreq;\r\nint bsize = crypto_skcipher_blocksize(tfm);\r\nu8 d[bsize * 2] __attribute__ ((aligned(__alignof__(u32))));\r\nstruct scatterlist *sg;\r\nunsigned int offset;\r\nu8 *space;\r\nint lastn;\r\noffset = rctx->offset;\r\nlastn = req->cryptlen - offset;\r\nsg = scatterwalk_ffwd(rctx->sg, req->dst, offset - bsize);\r\nscatterwalk_map_and_copy(d + bsize, sg, 0, bsize, 0);\r\nspace = crypto_cts_reqctx_space(req);\r\ncrypto_xor(d + bsize, space, bsize);\r\nmemset(d, 0, bsize);\r\nscatterwalk_map_and_copy(d, req->src, offset, lastn, 0);\r\ncrypto_xor(d + bsize, d, lastn);\r\nmemcpy(d + lastn, d + bsize + lastn, bsize - lastn);\r\nscatterwalk_map_and_copy(d, sg, 0, bsize + lastn, 1);\r\nmemzero_explicit(d, sizeof(d));\r\nskcipher_request_set_callback(subreq, req->base.flags &\r\nCRYPTO_TFM_REQ_MAY_BACKLOG,\r\ncts_cbc_crypt_done, req);\r\nskcipher_request_set_crypt(subreq, sg, sg, bsize, space);\r\nreturn crypto_skcipher_decrypt(subreq);\r\n}\r\nstatic void crypto_cts_decrypt_done(struct crypto_async_request *areq, int err)\r\n{\r\nstruct skcipher_request *req = areq->data;\r\nif (err)\r\ngoto out;\r\nerr = cts_cbc_decrypt(req);\r\nif (err == -EINPROGRESS ||\r\n(err == -EBUSY && req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG))\r\nreturn;\r\nout:\r\nskcipher_request_complete(req, err);\r\n}\r\nstatic int crypto_cts_decrypt(struct skcipher_request *req)\r\n{\r\nstruct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);\r\nstruct crypto_cts_reqctx *rctx = skcipher_request_ctx(req);\r\nstruct crypto_cts_ctx *ctx = crypto_skcipher_ctx(tfm);\r\nstruct skcipher_request *subreq = &rctx->subreq;\r\nint bsize = crypto_skcipher_blocksize(tfm);\r\nunsigned int nbytes = req->cryptlen;\r\nint cbc_blocks = (nbytes + bsize - 1) / bsize - 1;\r\nunsigned int offset;\r\nu8 *space;\r\nskcipher_request_set_tfm(subreq, ctx->child);\r\nif (cbc_blocks <= 0) {\r\nskcipher_request_set_callback(subreq, req->base.flags,\r\nreq->base.complete,\r\nreq->base.data);\r\nskcipher_request_set_crypt(subreq, req->src, req->dst, nbytes,\r\nreq->iv);\r\nreturn crypto_skcipher_decrypt(subreq);\r\n}\r\nskcipher_request_set_callback(subreq, req->base.flags,\r\ncrypto_cts_decrypt_done, req);\r\nspace = crypto_cts_reqctx_space(req);\r\noffset = cbc_blocks * bsize;\r\nrctx->offset = offset;\r\nif (cbc_blocks <= 1)\r\nmemcpy(space, req->iv, bsize);\r\nelse\r\nscatterwalk_map_and_copy(space, req->src, offset - 2 * bsize,\r\nbsize, 0);\r\nskcipher_request_set_crypt(subreq, req->src, req->dst,\r\noffset, req->iv);\r\nreturn crypto_skcipher_decrypt(subreq) ?:\r\ncts_cbc_decrypt(req);\r\n}\r\nstatic int crypto_cts_init_tfm(struct crypto_skcipher *tfm)\r\n{\r\nstruct skcipher_instance *inst = skcipher_alg_instance(tfm);\r\nstruct crypto_skcipher_spawn *spawn = skcipher_instance_ctx(inst);\r\nstruct crypto_cts_ctx *ctx = crypto_skcipher_ctx(tfm);\r\nstruct crypto_skcipher *cipher;\r\nunsigned reqsize;\r\nunsigned bsize;\r\nunsigned align;\r\ncipher = crypto_spawn_skcipher2(spawn);\r\nif (IS_ERR(cipher))\r\nreturn PTR_ERR(cipher);\r\nctx->child = cipher;\r\nalign = crypto_skcipher_alignmask(tfm);\r\nbsize = crypto_skcipher_blocksize(cipher);\r\nreqsize = ALIGN(sizeof(struct crypto_cts_reqctx) +\r\ncrypto_skcipher_reqsize(cipher),\r\ncrypto_tfm_ctx_alignment()) +\r\n(align & ~(crypto_tfm_ctx_alignment() - 1)) + bsize;\r\ncrypto_skcipher_set_reqsize(tfm, reqsize);\r\nreturn 0;\r\n}\r\nstatic void crypto_cts_exit_tfm(struct crypto_skcipher *tfm)\r\n{\r\nstruct crypto_cts_ctx *ctx = crypto_skcipher_ctx(tfm);\r\ncrypto_free_skcipher(ctx->child);\r\n}\r\nstatic void crypto_cts_free(struct skcipher_instance *inst)\r\n{\r\ncrypto_drop_skcipher(skcipher_instance_ctx(inst));\r\nkfree(inst);\r\n}\r\nstatic int crypto_cts_create(struct crypto_template *tmpl, struct rtattr **tb)\r\n{\r\nstruct crypto_skcipher_spawn *spawn;\r\nstruct skcipher_instance *inst;\r\nstruct crypto_attr_type *algt;\r\nstruct skcipher_alg *alg;\r\nconst char *cipher_name;\r\nint err;\r\nalgt = crypto_get_attr_type(tb);\r\nif (IS_ERR(algt))\r\nreturn PTR_ERR(algt);\r\nif ((algt->type ^ CRYPTO_ALG_TYPE_SKCIPHER) & algt->mask)\r\nreturn -EINVAL;\r\ncipher_name = crypto_attr_alg_name(tb[1]);\r\nif (IS_ERR(cipher_name))\r\nreturn PTR_ERR(cipher_name);\r\ninst = kzalloc(sizeof(*inst) + sizeof(*spawn), GFP_KERNEL);\r\nif (!inst)\r\nreturn -ENOMEM;\r\nspawn = skcipher_instance_ctx(inst);\r\ncrypto_set_skcipher_spawn(spawn, skcipher_crypto_instance(inst));\r\nerr = crypto_grab_skcipher2(spawn, cipher_name, 0,\r\ncrypto_requires_sync(algt->type,\r\nalgt->mask));\r\nif (err)\r\ngoto err_free_inst;\r\nalg = crypto_spawn_skcipher_alg(spawn);\r\nerr = -EINVAL;\r\nif (crypto_skcipher_alg_ivsize(alg) != alg->base.cra_blocksize)\r\ngoto err_drop_spawn;\r\nif (strncmp(alg->base.cra_name, "cbc(", 4))\r\ngoto err_drop_spawn;\r\nerr = crypto_inst_setname(skcipher_crypto_instance(inst), "cts",\r\n&alg->base);\r\nif (err)\r\ngoto err_drop_spawn;\r\ninst->alg.base.cra_flags = alg->base.cra_flags & CRYPTO_ALG_ASYNC;\r\ninst->alg.base.cra_priority = alg->base.cra_priority;\r\ninst->alg.base.cra_blocksize = alg->base.cra_blocksize;\r\ninst->alg.base.cra_alignmask = alg->base.cra_alignmask;\r\ninst->alg.base.cra_alignmask |= __alignof__(u32) - 1;\r\ninst->alg.ivsize = alg->base.cra_blocksize;\r\ninst->alg.chunksize = crypto_skcipher_alg_chunksize(alg);\r\ninst->alg.min_keysize = crypto_skcipher_alg_min_keysize(alg);\r\ninst->alg.max_keysize = crypto_skcipher_alg_max_keysize(alg);\r\ninst->alg.base.cra_ctxsize = sizeof(struct crypto_cts_ctx);\r\ninst->alg.init = crypto_cts_init_tfm;\r\ninst->alg.exit = crypto_cts_exit_tfm;\r\ninst->alg.setkey = crypto_cts_setkey;\r\ninst->alg.encrypt = crypto_cts_encrypt;\r\ninst->alg.decrypt = crypto_cts_decrypt;\r\ninst->free = crypto_cts_free;\r\nerr = skcipher_register_instance(tmpl, inst);\r\nif (err)\r\ngoto err_drop_spawn;\r\nout:\r\nreturn err;\r\nerr_drop_spawn:\r\ncrypto_drop_skcipher(spawn);\r\nerr_free_inst:\r\nkfree(inst);\r\ngoto out;\r\n}\r\nstatic int __init crypto_cts_module_init(void)\r\n{\r\nreturn crypto_register_template(&crypto_cts_tmpl);\r\n}\r\nstatic void __exit crypto_cts_module_exit(void)\r\n{\r\ncrypto_unregister_template(&crypto_cts_tmpl);\r\n}
