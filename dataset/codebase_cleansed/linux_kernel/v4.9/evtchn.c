static evtchn_port_t *evtchn_alloc_ring(unsigned int size)\r\n{\r\nevtchn_port_t *ring;\r\nsize_t s = size * sizeof(*ring);\r\nring = kmalloc(s, GFP_KERNEL);\r\nif (!ring)\r\nring = vmalloc(s);\r\nreturn ring;\r\n}\r\nstatic void evtchn_free_ring(evtchn_port_t *ring)\r\n{\r\nkvfree(ring);\r\n}\r\nstatic unsigned int evtchn_ring_offset(struct per_user_data *u,\r\nunsigned int idx)\r\n{\r\nreturn idx & (u->ring_size - 1);\r\n}\r\nstatic evtchn_port_t *evtchn_ring_entry(struct per_user_data *u,\r\nunsigned int idx)\r\n{\r\nreturn u->ring + evtchn_ring_offset(u, idx);\r\n}\r\nstatic int add_evtchn(struct per_user_data *u, struct user_evtchn *evtchn)\r\n{\r\nstruct rb_node **new = &(u->evtchns.rb_node), *parent = NULL;\r\nu->nr_evtchns++;\r\nwhile (*new) {\r\nstruct user_evtchn *this;\r\nthis = container_of(*new, struct user_evtchn, node);\r\nparent = *new;\r\nif (this->port < evtchn->port)\r\nnew = &((*new)->rb_left);\r\nelse if (this->port > evtchn->port)\r\nnew = &((*new)->rb_right);\r\nelse\r\nreturn -EEXIST;\r\n}\r\nrb_link_node(&evtchn->node, parent, new);\r\nrb_insert_color(&evtchn->node, &u->evtchns);\r\nreturn 0;\r\n}\r\nstatic void del_evtchn(struct per_user_data *u, struct user_evtchn *evtchn)\r\n{\r\nu->nr_evtchns--;\r\nrb_erase(&evtchn->node, &u->evtchns);\r\nkfree(evtchn);\r\n}\r\nstatic struct user_evtchn *find_evtchn(struct per_user_data *u, unsigned port)\r\n{\r\nstruct rb_node *node = u->evtchns.rb_node;\r\nwhile (node) {\r\nstruct user_evtchn *evtchn;\r\nevtchn = container_of(node, struct user_evtchn, node);\r\nif (evtchn->port < port)\r\nnode = node->rb_left;\r\nelse if (evtchn->port > port)\r\nnode = node->rb_right;\r\nelse\r\nreturn evtchn;\r\n}\r\nreturn NULL;\r\n}\r\nstatic irqreturn_t evtchn_interrupt(int irq, void *data)\r\n{\r\nstruct user_evtchn *evtchn = data;\r\nstruct per_user_data *u = evtchn->user;\r\nWARN(!evtchn->enabled,\r\n"Interrupt for port %d, but apparently not enabled; per-user %p\n",\r\nevtchn->port, u);\r\ndisable_irq_nosync(irq);\r\nevtchn->enabled = false;\r\nspin_lock(&u->ring_prod_lock);\r\nif ((u->ring_prod - u->ring_cons) < u->ring_size) {\r\n*evtchn_ring_entry(u, u->ring_prod) = evtchn->port;\r\nwmb();\r\nif (u->ring_cons == u->ring_prod++) {\r\nwake_up_interruptible(&u->evtchn_wait);\r\nkill_fasync(&u->evtchn_async_queue,\r\nSIGIO, POLL_IN);\r\n}\r\n} else\r\nu->ring_overflow = 1;\r\nspin_unlock(&u->ring_prod_lock);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic ssize_t evtchn_read(struct file *file, char __user *buf,\r\nsize_t count, loff_t *ppos)\r\n{\r\nint rc;\r\nunsigned int c, p, bytes1 = 0, bytes2 = 0;\r\nstruct per_user_data *u = file->private_data;\r\ncount &= ~(sizeof(evtchn_port_t)-1);\r\nif (count == 0)\r\nreturn 0;\r\nif (count > PAGE_SIZE)\r\ncount = PAGE_SIZE;\r\nfor (;;) {\r\nmutex_lock(&u->ring_cons_mutex);\r\nrc = -EFBIG;\r\nif (u->ring_overflow)\r\ngoto unlock_out;\r\nc = u->ring_cons;\r\np = u->ring_prod;\r\nif (c != p)\r\nbreak;\r\nmutex_unlock(&u->ring_cons_mutex);\r\nif (file->f_flags & O_NONBLOCK)\r\nreturn -EAGAIN;\r\nrc = wait_event_interruptible(u->evtchn_wait,\r\nu->ring_cons != u->ring_prod);\r\nif (rc)\r\nreturn rc;\r\n}\r\nif (((c ^ p) & u->ring_size) != 0) {\r\nbytes1 = (u->ring_size - evtchn_ring_offset(u, c)) *\r\nsizeof(evtchn_port_t);\r\nbytes2 = evtchn_ring_offset(u, p) * sizeof(evtchn_port_t);\r\n} else {\r\nbytes1 = (p - c) * sizeof(evtchn_port_t);\r\nbytes2 = 0;\r\n}\r\nif (bytes1 > count) {\r\nbytes1 = count;\r\nbytes2 = 0;\r\n} else if ((bytes1 + bytes2) > count) {\r\nbytes2 = count - bytes1;\r\n}\r\nrc = -EFAULT;\r\nrmb();\r\nif (copy_to_user(buf, evtchn_ring_entry(u, c), bytes1) ||\r\n((bytes2 != 0) &&\r\ncopy_to_user(&buf[bytes1], &u->ring[0], bytes2)))\r\ngoto unlock_out;\r\nu->ring_cons += (bytes1 + bytes2) / sizeof(evtchn_port_t);\r\nrc = bytes1 + bytes2;\r\nunlock_out:\r\nmutex_unlock(&u->ring_cons_mutex);\r\nreturn rc;\r\n}\r\nstatic ssize_t evtchn_write(struct file *file, const char __user *buf,\r\nsize_t count, loff_t *ppos)\r\n{\r\nint rc, i;\r\nevtchn_port_t *kbuf = (evtchn_port_t *)__get_free_page(GFP_KERNEL);\r\nstruct per_user_data *u = file->private_data;\r\nif (kbuf == NULL)\r\nreturn -ENOMEM;\r\ncount &= ~(sizeof(evtchn_port_t)-1);\r\nrc = 0;\r\nif (count == 0)\r\ngoto out;\r\nif (count > PAGE_SIZE)\r\ncount = PAGE_SIZE;\r\nrc = -EFAULT;\r\nif (copy_from_user(kbuf, buf, count) != 0)\r\ngoto out;\r\nmutex_lock(&u->bind_mutex);\r\nfor (i = 0; i < (count/sizeof(evtchn_port_t)); i++) {\r\nunsigned port = kbuf[i];\r\nstruct user_evtchn *evtchn;\r\nevtchn = find_evtchn(u, port);\r\nif (evtchn && !evtchn->enabled) {\r\nevtchn->enabled = true;\r\nenable_irq(irq_from_evtchn(port));\r\n}\r\n}\r\nmutex_unlock(&u->bind_mutex);\r\nrc = count;\r\nout:\r\nfree_page((unsigned long)kbuf);\r\nreturn rc;\r\n}\r\nstatic int evtchn_resize_ring(struct per_user_data *u)\r\n{\r\nunsigned int new_size;\r\nevtchn_port_t *new_ring, *old_ring;\r\nif (u->nr_evtchns <= u->ring_size)\r\nreturn 0;\r\nif (u->ring_size == 0)\r\nnew_size = 64;\r\nelse\r\nnew_size = 2 * u->ring_size;\r\nnew_ring = evtchn_alloc_ring(new_size);\r\nif (!new_ring)\r\nreturn -ENOMEM;\r\nold_ring = u->ring;\r\nmutex_lock(&u->ring_cons_mutex);\r\nspin_lock_irq(&u->ring_prod_lock);\r\nmemcpy(new_ring, old_ring, u->ring_size * sizeof(*u->ring));\r\nmemcpy(new_ring + u->ring_size, old_ring,\r\nu->ring_size * sizeof(*u->ring));\r\nu->ring = new_ring;\r\nu->ring_size = new_size;\r\nspin_unlock_irq(&u->ring_prod_lock);\r\nmutex_unlock(&u->ring_cons_mutex);\r\nevtchn_free_ring(old_ring);\r\nreturn 0;\r\n}\r\nstatic int evtchn_bind_to_user(struct per_user_data *u, int port)\r\n{\r\nstruct user_evtchn *evtchn;\r\nstruct evtchn_close close;\r\nint rc = 0;\r\nevtchn = kzalloc(sizeof(*evtchn), GFP_KERNEL);\r\nif (!evtchn)\r\nreturn -ENOMEM;\r\nevtchn->user = u;\r\nevtchn->port = port;\r\nevtchn->enabled = true;\r\nrc = add_evtchn(u, evtchn);\r\nif (rc < 0)\r\ngoto err;\r\nrc = evtchn_resize_ring(u);\r\nif (rc < 0)\r\ngoto err;\r\nrc = bind_evtchn_to_irqhandler(port, evtchn_interrupt, 0,\r\nu->name, evtchn);\r\nif (rc < 0)\r\ngoto err;\r\nrc = evtchn_make_refcounted(port);\r\nreturn rc;\r\nerr:\r\nclose.port = port;\r\nif (HYPERVISOR_event_channel_op(EVTCHNOP_close, &close) != 0)\r\nBUG();\r\ndel_evtchn(u, evtchn);\r\nreturn rc;\r\n}\r\nstatic void evtchn_unbind_from_user(struct per_user_data *u,\r\nstruct user_evtchn *evtchn)\r\n{\r\nint irq = irq_from_evtchn(evtchn->port);\r\nBUG_ON(irq < 0);\r\nunbind_from_irqhandler(irq, evtchn);\r\ndel_evtchn(u, evtchn);\r\n}\r\nstatic long evtchn_ioctl(struct file *file,\r\nunsigned int cmd, unsigned long arg)\r\n{\r\nint rc;\r\nstruct per_user_data *u = file->private_data;\r\nvoid __user *uarg = (void __user *) arg;\r\nmutex_lock(&u->bind_mutex);\r\nswitch (cmd) {\r\ncase IOCTL_EVTCHN_BIND_VIRQ: {\r\nstruct ioctl_evtchn_bind_virq bind;\r\nstruct evtchn_bind_virq bind_virq;\r\nrc = -EACCES;\r\nif (u->restrict_domid != UNRESTRICTED_DOMID)\r\nbreak;\r\nrc = -EFAULT;\r\nif (copy_from_user(&bind, uarg, sizeof(bind)))\r\nbreak;\r\nbind_virq.virq = bind.virq;\r\nbind_virq.vcpu = xen_vcpu_nr(0);\r\nrc = HYPERVISOR_event_channel_op(EVTCHNOP_bind_virq,\r\n&bind_virq);\r\nif (rc != 0)\r\nbreak;\r\nrc = evtchn_bind_to_user(u, bind_virq.port);\r\nif (rc == 0)\r\nrc = bind_virq.port;\r\nbreak;\r\n}\r\ncase IOCTL_EVTCHN_BIND_INTERDOMAIN: {\r\nstruct ioctl_evtchn_bind_interdomain bind;\r\nstruct evtchn_bind_interdomain bind_interdomain;\r\nrc = -EFAULT;\r\nif (copy_from_user(&bind, uarg, sizeof(bind)))\r\nbreak;\r\nrc = -EACCES;\r\nif (u->restrict_domid != UNRESTRICTED_DOMID &&\r\nu->restrict_domid != bind.remote_domain)\r\nbreak;\r\nbind_interdomain.remote_dom = bind.remote_domain;\r\nbind_interdomain.remote_port = bind.remote_port;\r\nrc = HYPERVISOR_event_channel_op(EVTCHNOP_bind_interdomain,\r\n&bind_interdomain);\r\nif (rc != 0)\r\nbreak;\r\nrc = evtchn_bind_to_user(u, bind_interdomain.local_port);\r\nif (rc == 0)\r\nrc = bind_interdomain.local_port;\r\nbreak;\r\n}\r\ncase IOCTL_EVTCHN_BIND_UNBOUND_PORT: {\r\nstruct ioctl_evtchn_bind_unbound_port bind;\r\nstruct evtchn_alloc_unbound alloc_unbound;\r\nrc = -EACCES;\r\nif (u->restrict_domid != UNRESTRICTED_DOMID)\r\nbreak;\r\nrc = -EFAULT;\r\nif (copy_from_user(&bind, uarg, sizeof(bind)))\r\nbreak;\r\nalloc_unbound.dom = DOMID_SELF;\r\nalloc_unbound.remote_dom = bind.remote_domain;\r\nrc = HYPERVISOR_event_channel_op(EVTCHNOP_alloc_unbound,\r\n&alloc_unbound);\r\nif (rc != 0)\r\nbreak;\r\nrc = evtchn_bind_to_user(u, alloc_unbound.port);\r\nif (rc == 0)\r\nrc = alloc_unbound.port;\r\nbreak;\r\n}\r\ncase IOCTL_EVTCHN_UNBIND: {\r\nstruct ioctl_evtchn_unbind unbind;\r\nstruct user_evtchn *evtchn;\r\nrc = -EFAULT;\r\nif (copy_from_user(&unbind, uarg, sizeof(unbind)))\r\nbreak;\r\nrc = -EINVAL;\r\nif (unbind.port >= xen_evtchn_nr_channels())\r\nbreak;\r\nrc = -ENOTCONN;\r\nevtchn = find_evtchn(u, unbind.port);\r\nif (!evtchn)\r\nbreak;\r\ndisable_irq(irq_from_evtchn(unbind.port));\r\nevtchn_unbind_from_user(u, evtchn);\r\nrc = 0;\r\nbreak;\r\n}\r\ncase IOCTL_EVTCHN_NOTIFY: {\r\nstruct ioctl_evtchn_notify notify;\r\nstruct user_evtchn *evtchn;\r\nrc = -EFAULT;\r\nif (copy_from_user(&notify, uarg, sizeof(notify)))\r\nbreak;\r\nrc = -ENOTCONN;\r\nevtchn = find_evtchn(u, notify.port);\r\nif (evtchn) {\r\nnotify_remote_via_evtchn(notify.port);\r\nrc = 0;\r\n}\r\nbreak;\r\n}\r\ncase IOCTL_EVTCHN_RESET: {\r\nmutex_lock(&u->ring_cons_mutex);\r\nspin_lock_irq(&u->ring_prod_lock);\r\nu->ring_cons = u->ring_prod = u->ring_overflow = 0;\r\nspin_unlock_irq(&u->ring_prod_lock);\r\nmutex_unlock(&u->ring_cons_mutex);\r\nrc = 0;\r\nbreak;\r\n}\r\ncase IOCTL_EVTCHN_RESTRICT_DOMID: {\r\nstruct ioctl_evtchn_restrict_domid ierd;\r\nrc = -EACCES;\r\nif (u->restrict_domid != UNRESTRICTED_DOMID)\r\nbreak;\r\nrc = -EFAULT;\r\nif (copy_from_user(&ierd, uarg, sizeof(ierd)))\r\nbreak;\r\nrc = -EINVAL;\r\nif (ierd.domid == 0 || ierd.domid >= DOMID_FIRST_RESERVED)\r\nbreak;\r\nu->restrict_domid = ierd.domid;\r\nrc = 0;\r\nbreak;\r\n}\r\ndefault:\r\nrc = -ENOSYS;\r\nbreak;\r\n}\r\nmutex_unlock(&u->bind_mutex);\r\nreturn rc;\r\n}\r\nstatic unsigned int evtchn_poll(struct file *file, poll_table *wait)\r\n{\r\nunsigned int mask = POLLOUT | POLLWRNORM;\r\nstruct per_user_data *u = file->private_data;\r\npoll_wait(file, &u->evtchn_wait, wait);\r\nif (u->ring_cons != u->ring_prod)\r\nmask |= POLLIN | POLLRDNORM;\r\nif (u->ring_overflow)\r\nmask = POLLERR;\r\nreturn mask;\r\n}\r\nstatic int evtchn_fasync(int fd, struct file *filp, int on)\r\n{\r\nstruct per_user_data *u = filp->private_data;\r\nreturn fasync_helper(fd, filp, on, &u->evtchn_async_queue);\r\n}\r\nstatic int evtchn_open(struct inode *inode, struct file *filp)\r\n{\r\nstruct per_user_data *u;\r\nu = kzalloc(sizeof(*u), GFP_KERNEL);\r\nif (u == NULL)\r\nreturn -ENOMEM;\r\nu->name = kasprintf(GFP_KERNEL, "evtchn:%s", current->comm);\r\nif (u->name == NULL) {\r\nkfree(u);\r\nreturn -ENOMEM;\r\n}\r\ninit_waitqueue_head(&u->evtchn_wait);\r\nmutex_init(&u->bind_mutex);\r\nmutex_init(&u->ring_cons_mutex);\r\nspin_lock_init(&u->ring_prod_lock);\r\nu->restrict_domid = UNRESTRICTED_DOMID;\r\nfilp->private_data = u;\r\nreturn nonseekable_open(inode, filp);\r\n}\r\nstatic int evtchn_release(struct inode *inode, struct file *filp)\r\n{\r\nstruct per_user_data *u = filp->private_data;\r\nstruct rb_node *node;\r\nwhile ((node = u->evtchns.rb_node)) {\r\nstruct user_evtchn *evtchn;\r\nevtchn = rb_entry(node, struct user_evtchn, node);\r\ndisable_irq(irq_from_evtchn(evtchn->port));\r\nevtchn_unbind_from_user(u, evtchn);\r\n}\r\nevtchn_free_ring(u->ring);\r\nkfree(u->name);\r\nkfree(u);\r\nreturn 0;\r\n}\r\nstatic int __init evtchn_init(void)\r\n{\r\nint err;\r\nif (!xen_domain())\r\nreturn -ENODEV;\r\nerr = misc_register(&evtchn_miscdev);\r\nif (err != 0) {\r\npr_err("Could not register /dev/xen/evtchn\n");\r\nreturn err;\r\n}\r\npr_info("Event-channel device installed\n");\r\nreturn 0;\r\n}\r\nstatic void __exit evtchn_cleanup(void)\r\n{\r\nmisc_deregister(&evtchn_miscdev);\r\n}
