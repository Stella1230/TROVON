static inline bool event_is_fab_match(u64 event)\r\n{\r\nevent &= 0xff0fe;\r\nreturn (event == 0x30056 || event == 0x4f052);\r\n}\r\nint isa207_get_constraint(u64 event, unsigned long *maskp, unsigned long *valp)\r\n{\r\nunsigned int unit, pmc, cache, ebb;\r\nunsigned long mask, value;\r\nmask = value = 0;\r\nif (event & ~EVENT_VALID_MASK)\r\nreturn -1;\r\npmc = (event >> EVENT_PMC_SHIFT) & EVENT_PMC_MASK;\r\nunit = (event >> EVENT_UNIT_SHIFT) & EVENT_UNIT_MASK;\r\ncache = (event >> EVENT_CACHE_SEL_SHIFT) & EVENT_CACHE_SEL_MASK;\r\nebb = (event >> EVENT_EBB_SHIFT) & EVENT_EBB_MASK;\r\nif (pmc) {\r\nu64 base_event;\r\nif (pmc > 6)\r\nreturn -1;\r\nbase_event = event & ~EVENT_LINUX_MASK;\r\nif (pmc >= 5 && base_event != 0x500fa &&\r\nbase_event != 0x600f4)\r\nreturn -1;\r\nmask |= CNST_PMC_MASK(pmc);\r\nvalue |= CNST_PMC_VAL(pmc);\r\n}\r\nif (pmc <= 4) {\r\nmask |= CNST_NC_MASK;\r\nvalue |= CNST_NC_VAL;\r\n}\r\nif (unit >= 6 && unit <= 9) {\r\nif (cache & 0x7)\r\nreturn -1;\r\n} else if (event & EVENT_IS_L1) {\r\nmask |= CNST_L1_QUAL_MASK;\r\nvalue |= CNST_L1_QUAL_VAL(cache);\r\n}\r\nif (event & EVENT_IS_MARKED) {\r\nmask |= CNST_SAMPLE_MASK;\r\nvalue |= CNST_SAMPLE_VAL(event >> EVENT_SAMPLE_SHIFT);\r\n}\r\nif (event_is_fab_match(event)) {\r\nmask |= CNST_FAB_MATCH_MASK;\r\nvalue |= CNST_FAB_MATCH_VAL(event >> EVENT_THR_CTL_SHIFT);\r\n} else {\r\nunsigned int cmp, exp;\r\ncmp = (event >> EVENT_THR_CMP_SHIFT) & EVENT_THR_CMP_MASK;\r\nexp = cmp >> 7;\r\nif (exp && (cmp & 0x60) == 0)\r\nreturn -1;\r\nmask |= CNST_THRESH_MASK;\r\nvalue |= CNST_THRESH_VAL(event >> EVENT_THRESH_SHIFT);\r\n}\r\nif (!pmc && ebb)\r\nreturn -1;\r\nif (event & EVENT_WANTS_BHRB) {\r\nif (!ebb)\r\nreturn -1;\r\nmask |= CNST_IFM_MASK;\r\nvalue |= CNST_IFM_VAL(event >> EVENT_IFM_SHIFT);\r\n}\r\nmask |= CNST_EBB_VAL(ebb);\r\nvalue |= CNST_EBB_MASK;\r\n*maskp = mask;\r\n*valp = value;\r\nreturn 0;\r\n}\r\nint isa207_compute_mmcr(u64 event[], int n_ev,\r\nunsigned int hwc[], unsigned long mmcr[],\r\nstruct perf_event *pevents[])\r\n{\r\nunsigned long mmcra, mmcr1, mmcr2, unit, combine, psel, cache, val;\r\nunsigned int pmc, pmc_inuse;\r\nint i;\r\npmc_inuse = 0;\r\nfor (i = 0; i < n_ev; ++i) {\r\npmc = (event[i] >> EVENT_PMC_SHIFT) & EVENT_PMC_MASK;\r\nif (pmc)\r\npmc_inuse |= 1 << pmc;\r\n}\r\nmmcra = MMCRA_SDAR_MODE_TLB;\r\nmmcr1 = mmcr2 = 0;\r\nfor (i = 0; i < n_ev; ++i) {\r\npmc = (event[i] >> EVENT_PMC_SHIFT) & EVENT_PMC_MASK;\r\nunit = (event[i] >> EVENT_UNIT_SHIFT) & EVENT_UNIT_MASK;\r\ncombine = (event[i] >> EVENT_COMBINE_SHIFT) & EVENT_COMBINE_MASK;\r\npsel = event[i] & EVENT_PSEL_MASK;\r\nif (!pmc) {\r\nfor (pmc = 1; pmc <= 4; ++pmc) {\r\nif (!(pmc_inuse & (1 << pmc)))\r\nbreak;\r\n}\r\npmc_inuse |= 1 << pmc;\r\n}\r\nif (pmc <= 4) {\r\nmmcr1 |= unit << MMCR1_UNIT_SHIFT(pmc);\r\nmmcr1 |= combine << MMCR1_COMBINE_SHIFT(pmc);\r\nmmcr1 |= psel << MMCR1_PMCSEL_SHIFT(pmc);\r\n}\r\nif (event[i] & EVENT_IS_L1) {\r\ncache = event[i] >> EVENT_CACHE_SEL_SHIFT;\r\nmmcr1 |= (cache & 1) << MMCR1_IC_QUAL_SHIFT;\r\ncache >>= 1;\r\nmmcr1 |= (cache & 1) << MMCR1_DC_QUAL_SHIFT;\r\n}\r\nif (event[i] & EVENT_IS_MARKED) {\r\nmmcra |= MMCRA_SAMPLE_ENABLE;\r\nval = (event[i] >> EVENT_SAMPLE_SHIFT) & EVENT_SAMPLE_MASK;\r\nif (val) {\r\nmmcra |= (val & 3) << MMCRA_SAMP_MODE_SHIFT;\r\nmmcra |= (val >> 2) << MMCRA_SAMP_ELIG_SHIFT;\r\n}\r\n}\r\nif (event_is_fab_match(event[i])) {\r\nmmcr1 |= ((event[i] >> EVENT_THR_CTL_SHIFT) &\r\nEVENT_THR_CTL_MASK) << MMCR1_FAB_SHIFT;\r\n} else {\r\nval = (event[i] >> EVENT_THR_CTL_SHIFT) & EVENT_THR_CTL_MASK;\r\nmmcra |= val << MMCRA_THR_CTL_SHIFT;\r\nval = (event[i] >> EVENT_THR_SEL_SHIFT) & EVENT_THR_SEL_MASK;\r\nmmcra |= val << MMCRA_THR_SEL_SHIFT;\r\nval = (event[i] >> EVENT_THR_CMP_SHIFT) & EVENT_THR_CMP_MASK;\r\nmmcra |= val << MMCRA_THR_CMP_SHIFT;\r\n}\r\nif (event[i] & EVENT_WANTS_BHRB) {\r\nval = (event[i] >> EVENT_IFM_SHIFT) & EVENT_IFM_MASK;\r\nmmcra |= val << MMCRA_IFM_SHIFT;\r\n}\r\nif (pevents[i]->attr.exclude_user)\r\nmmcr2 |= MMCR2_FCP(pmc);\r\nif (pevents[i]->attr.exclude_hv)\r\nmmcr2 |= MMCR2_FCH(pmc);\r\nif (pevents[i]->attr.exclude_kernel) {\r\nif (cpu_has_feature(CPU_FTR_HVMODE))\r\nmmcr2 |= MMCR2_FCH(pmc);\r\nelse\r\nmmcr2 |= MMCR2_FCS(pmc);\r\n}\r\nhwc[i] = pmc - 1;\r\n}\r\nmmcr[0] = 0;\r\nif (pmc_inuse & 2)\r\nmmcr[0] = MMCR0_PMC1CE;\r\nif (pmc_inuse & 0x7c)\r\nmmcr[0] |= MMCR0_PMCjCE;\r\nif (!(pmc_inuse & 0x60))\r\nmmcr[0] |= MMCR0_FC56;\r\nmmcr[1] = mmcr1;\r\nmmcr[2] = mmcra;\r\nmmcr[3] = mmcr2;\r\nreturn 0;\r\n}\r\nvoid isa207_disable_pmc(unsigned int pmc, unsigned long mmcr[])\r\n{\r\nif (pmc <= 3)\r\nmmcr[1] &= ~(0xffUL << MMCR1_PMCSEL_SHIFT(pmc + 1));\r\n}
