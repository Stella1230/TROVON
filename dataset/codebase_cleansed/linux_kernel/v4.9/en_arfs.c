static enum mlx5e_traffic_types arfs_get_tt(enum arfs_type type)\r\n{\r\nswitch (type) {\r\ncase ARFS_IPV4_TCP:\r\nreturn MLX5E_TT_IPV4_TCP;\r\ncase ARFS_IPV4_UDP:\r\nreturn MLX5E_TT_IPV4_UDP;\r\ncase ARFS_IPV6_TCP:\r\nreturn MLX5E_TT_IPV6_TCP;\r\ncase ARFS_IPV6_UDP:\r\nreturn MLX5E_TT_IPV6_UDP;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n}\r\nstatic int arfs_disable(struct mlx5e_priv *priv)\r\n{\r\nstruct mlx5_flow_destination dest;\r\nstruct mlx5e_tir *tir = priv->indir_tir;\r\nint err = 0;\r\nint tt;\r\nint i;\r\ndest.type = MLX5_FLOW_DESTINATION_TYPE_TIR;\r\nfor (i = 0; i < ARFS_NUM_TYPES; i++) {\r\ndest.tir_num = tir[i].tirn;\r\ntt = arfs_get_tt(i);\r\nerr = mlx5_modify_rule_destination(priv->fs.ttc.rules[tt],\r\n&dest);\r\nif (err) {\r\nnetdev_err(priv->netdev,\r\n"%s: modify ttc destination failed\n",\r\n__func__);\r\nreturn err;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint mlx5e_arfs_disable(struct mlx5e_priv *priv)\r\n{\r\narfs_del_rules(priv);\r\nreturn arfs_disable(priv);\r\n}\r\nint mlx5e_arfs_enable(struct mlx5e_priv *priv)\r\n{\r\nstruct mlx5_flow_destination dest;\r\nint err = 0;\r\nint tt;\r\nint i;\r\ndest.type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;\r\nfor (i = 0; i < ARFS_NUM_TYPES; i++) {\r\ndest.ft = priv->fs.arfs.arfs_tables[i].ft.t;\r\ntt = arfs_get_tt(i);\r\nerr = mlx5_modify_rule_destination(priv->fs.ttc.rules[tt],\r\n&dest);\r\nif (err) {\r\nnetdev_err(priv->netdev,\r\n"%s: modify ttc destination failed err=%d\n",\r\n__func__, err);\r\narfs_disable(priv);\r\nreturn err;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void arfs_destroy_table(struct arfs_table *arfs_t)\r\n{\r\nmlx5_del_flow_rule(arfs_t->default_rule);\r\nmlx5e_destroy_flow_table(&arfs_t->ft);\r\n}\r\nvoid mlx5e_arfs_destroy_tables(struct mlx5e_priv *priv)\r\n{\r\nint i;\r\nif (!(priv->netdev->hw_features & NETIF_F_NTUPLE))\r\nreturn;\r\narfs_del_rules(priv);\r\ndestroy_workqueue(priv->fs.arfs.wq);\r\nfor (i = 0; i < ARFS_NUM_TYPES; i++) {\r\nif (!IS_ERR_OR_NULL(priv->fs.arfs.arfs_tables[i].ft.t))\r\narfs_destroy_table(&priv->fs.arfs.arfs_tables[i]);\r\n}\r\n}\r\nstatic int arfs_add_default_rule(struct mlx5e_priv *priv,\r\nenum arfs_type type)\r\n{\r\nstruct arfs_table *arfs_t = &priv->fs.arfs.arfs_tables[type];\r\nstruct mlx5_flow_destination dest;\r\nstruct mlx5e_tir *tir = priv->indir_tir;\r\nstruct mlx5_flow_spec *spec;\r\nint err = 0;\r\nspec = mlx5_vzalloc(sizeof(*spec));\r\nif (!spec) {\r\nnetdev_err(priv->netdev, "%s: alloc failed\n", __func__);\r\nerr = -ENOMEM;\r\ngoto out;\r\n}\r\ndest.type = MLX5_FLOW_DESTINATION_TYPE_TIR;\r\nswitch (type) {\r\ncase ARFS_IPV4_TCP:\r\ndest.tir_num = tir[MLX5E_TT_IPV4_TCP].tirn;\r\nbreak;\r\ncase ARFS_IPV4_UDP:\r\ndest.tir_num = tir[MLX5E_TT_IPV4_UDP].tirn;\r\nbreak;\r\ncase ARFS_IPV6_TCP:\r\ndest.tir_num = tir[MLX5E_TT_IPV6_TCP].tirn;\r\nbreak;\r\ncase ARFS_IPV6_UDP:\r\ndest.tir_num = tir[MLX5E_TT_IPV6_UDP].tirn;\r\nbreak;\r\ndefault:\r\nerr = -EINVAL;\r\ngoto out;\r\n}\r\narfs_t->default_rule = mlx5_add_flow_rule(arfs_t->ft.t, spec,\r\nMLX5_FLOW_CONTEXT_ACTION_FWD_DEST,\r\nMLX5_FS_DEFAULT_FLOW_TAG,\r\n&dest);\r\nif (IS_ERR(arfs_t->default_rule)) {\r\nerr = PTR_ERR(arfs_t->default_rule);\r\narfs_t->default_rule = NULL;\r\nnetdev_err(priv->netdev, "%s: add rule failed, arfs type=%d\n",\r\n__func__, type);\r\n}\r\nout:\r\nkvfree(spec);\r\nreturn err;\r\n}\r\nstatic int arfs_create_groups(struct mlx5e_flow_table *ft,\r\nenum arfs_type type)\r\n{\r\nint inlen = MLX5_ST_SZ_BYTES(create_flow_group_in);\r\nvoid *outer_headers_c;\r\nint ix = 0;\r\nu32 *in;\r\nint err;\r\nu8 *mc;\r\nft->g = kcalloc(MLX5E_ARFS_NUM_GROUPS,\r\nsizeof(*ft->g), GFP_KERNEL);\r\nin = mlx5_vzalloc(inlen);\r\nif (!in || !ft->g) {\r\nkvfree(ft->g);\r\nkvfree(in);\r\nreturn -ENOMEM;\r\n}\r\nmc = MLX5_ADDR_OF(create_flow_group_in, in, match_criteria);\r\nouter_headers_c = MLX5_ADDR_OF(fte_match_param, mc,\r\nouter_headers);\r\nMLX5_SET_TO_ONES(fte_match_set_lyr_2_4, outer_headers_c, ethertype);\r\nswitch (type) {\r\ncase ARFS_IPV4_TCP:\r\ncase ARFS_IPV6_TCP:\r\nMLX5_SET_TO_ONES(fte_match_set_lyr_2_4, outer_headers_c, tcp_dport);\r\nMLX5_SET_TO_ONES(fte_match_set_lyr_2_4, outer_headers_c, tcp_sport);\r\nbreak;\r\ncase ARFS_IPV4_UDP:\r\ncase ARFS_IPV6_UDP:\r\nMLX5_SET_TO_ONES(fte_match_set_lyr_2_4, outer_headers_c, udp_dport);\r\nMLX5_SET_TO_ONES(fte_match_set_lyr_2_4, outer_headers_c, udp_sport);\r\nbreak;\r\ndefault:\r\nerr = -EINVAL;\r\ngoto out;\r\n}\r\nswitch (type) {\r\ncase ARFS_IPV4_TCP:\r\ncase ARFS_IPV4_UDP:\r\nMLX5_SET_TO_ONES(fte_match_set_lyr_2_4, outer_headers_c,\r\nsrc_ipv4_src_ipv6.ipv4_layout.ipv4);\r\nMLX5_SET_TO_ONES(fte_match_set_lyr_2_4, outer_headers_c,\r\ndst_ipv4_dst_ipv6.ipv4_layout.ipv4);\r\nbreak;\r\ncase ARFS_IPV6_TCP:\r\ncase ARFS_IPV6_UDP:\r\nmemset(MLX5_ADDR_OF(fte_match_set_lyr_2_4, outer_headers_c,\r\nsrc_ipv4_src_ipv6.ipv6_layout.ipv6),\r\n0xff, 16);\r\nmemset(MLX5_ADDR_OF(fte_match_set_lyr_2_4, outer_headers_c,\r\ndst_ipv4_dst_ipv6.ipv6_layout.ipv6),\r\n0xff, 16);\r\nbreak;\r\ndefault:\r\nerr = -EINVAL;\r\ngoto out;\r\n}\r\nMLX5_SET_CFG(in, match_criteria_enable, MLX5_MATCH_OUTER_HEADERS);\r\nMLX5_SET_CFG(in, start_flow_index, ix);\r\nix += MLX5E_ARFS_GROUP1_SIZE;\r\nMLX5_SET_CFG(in, end_flow_index, ix - 1);\r\nft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);\r\nif (IS_ERR(ft->g[ft->num_groups]))\r\ngoto err;\r\nft->num_groups++;\r\nmemset(in, 0, inlen);\r\nMLX5_SET_CFG(in, start_flow_index, ix);\r\nix += MLX5E_ARFS_GROUP2_SIZE;\r\nMLX5_SET_CFG(in, end_flow_index, ix - 1);\r\nft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);\r\nif (IS_ERR(ft->g[ft->num_groups]))\r\ngoto err;\r\nft->num_groups++;\r\nkvfree(in);\r\nreturn 0;\r\nerr:\r\nerr = PTR_ERR(ft->g[ft->num_groups]);\r\nft->g[ft->num_groups] = NULL;\r\nout:\r\nkvfree(in);\r\nreturn err;\r\n}\r\nstatic int arfs_create_table(struct mlx5e_priv *priv,\r\nenum arfs_type type)\r\n{\r\nstruct mlx5e_arfs_tables *arfs = &priv->fs.arfs;\r\nstruct mlx5e_flow_table *ft = &arfs->arfs_tables[type].ft;\r\nint err;\r\nft->t = mlx5_create_flow_table(priv->fs.ns, MLX5E_NIC_PRIO,\r\nMLX5E_ARFS_TABLE_SIZE, MLX5E_ARFS_FT_LEVEL);\r\nif (IS_ERR(ft->t)) {\r\nerr = PTR_ERR(ft->t);\r\nft->t = NULL;\r\nreturn err;\r\n}\r\nerr = arfs_create_groups(ft, type);\r\nif (err)\r\ngoto err;\r\nerr = arfs_add_default_rule(priv, type);\r\nif (err)\r\ngoto err;\r\nreturn 0;\r\nerr:\r\nmlx5e_destroy_flow_table(ft);\r\nreturn err;\r\n}\r\nint mlx5e_arfs_create_tables(struct mlx5e_priv *priv)\r\n{\r\nint err = 0;\r\nint i;\r\nif (!(priv->netdev->hw_features & NETIF_F_NTUPLE))\r\nreturn 0;\r\nspin_lock_init(&priv->fs.arfs.arfs_lock);\r\nINIT_LIST_HEAD(&priv->fs.arfs.rules);\r\npriv->fs.arfs.wq = create_singlethread_workqueue("mlx5e_arfs");\r\nif (!priv->fs.arfs.wq)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < ARFS_NUM_TYPES; i++) {\r\nerr = arfs_create_table(priv, i);\r\nif (err)\r\ngoto err;\r\n}\r\nreturn 0;\r\nerr:\r\nmlx5e_arfs_destroy_tables(priv);\r\nreturn err;\r\n}\r\nstatic void arfs_may_expire_flow(struct mlx5e_priv *priv)\r\n{\r\nstruct arfs_rule *arfs_rule;\r\nstruct hlist_node *htmp;\r\nint quota = 0;\r\nint i;\r\nint j;\r\nHLIST_HEAD(del_list);\r\nspin_lock_bh(&priv->fs.arfs.arfs_lock);\r\nmlx5e_for_each_arfs_rule(arfs_rule, htmp, priv->fs.arfs.arfs_tables, i, j) {\r\nif (quota++ > MLX5E_ARFS_EXPIRY_QUOTA)\r\nbreak;\r\nif (!work_pending(&arfs_rule->arfs_work) &&\r\nrps_may_expire_flow(priv->netdev,\r\narfs_rule->rxq, arfs_rule->flow_id,\r\narfs_rule->filter_id)) {\r\nhlist_del_init(&arfs_rule->hlist);\r\nhlist_add_head(&arfs_rule->hlist, &del_list);\r\n}\r\n}\r\nspin_unlock_bh(&priv->fs.arfs.arfs_lock);\r\nhlist_for_each_entry_safe(arfs_rule, htmp, &del_list, hlist) {\r\nif (arfs_rule->rule)\r\nmlx5_del_flow_rule(arfs_rule->rule);\r\nhlist_del(&arfs_rule->hlist);\r\nkfree(arfs_rule);\r\n}\r\n}\r\nstatic void arfs_del_rules(struct mlx5e_priv *priv)\r\n{\r\nstruct hlist_node *htmp;\r\nstruct arfs_rule *rule;\r\nint i;\r\nint j;\r\nHLIST_HEAD(del_list);\r\nspin_lock_bh(&priv->fs.arfs.arfs_lock);\r\nmlx5e_for_each_arfs_rule(rule, htmp, priv->fs.arfs.arfs_tables, i, j) {\r\nhlist_del_init(&rule->hlist);\r\nhlist_add_head(&rule->hlist, &del_list);\r\n}\r\nspin_unlock_bh(&priv->fs.arfs.arfs_lock);\r\nhlist_for_each_entry_safe(rule, htmp, &del_list, hlist) {\r\ncancel_work_sync(&rule->arfs_work);\r\nif (rule->rule)\r\nmlx5_del_flow_rule(rule->rule);\r\nhlist_del(&rule->hlist);\r\nkfree(rule);\r\n}\r\n}\r\nstatic struct hlist_head *\r\narfs_hash_bucket(struct arfs_table *arfs_t, __be16 src_port,\r\n__be16 dst_port)\r\n{\r\nunsigned long l;\r\nint bucket_idx;\r\nl = (__force unsigned long)src_port |\r\n((__force unsigned long)dst_port << 2);\r\nbucket_idx = hash_long(l, ARFS_HASH_SHIFT);\r\nreturn &arfs_t->rules_hash[bucket_idx];\r\n}\r\nstatic u8 arfs_get_ip_proto(const struct sk_buff *skb)\r\n{\r\nreturn (skb->protocol == htons(ETH_P_IP)) ?\r\nip_hdr(skb)->protocol : ipv6_hdr(skb)->nexthdr;\r\n}\r\nstatic struct arfs_table *arfs_get_table(struct mlx5e_arfs_tables *arfs,\r\nu8 ip_proto, __be16 etype)\r\n{\r\nif (etype == htons(ETH_P_IP) && ip_proto == IPPROTO_TCP)\r\nreturn &arfs->arfs_tables[ARFS_IPV4_TCP];\r\nif (etype == htons(ETH_P_IP) && ip_proto == IPPROTO_UDP)\r\nreturn &arfs->arfs_tables[ARFS_IPV4_UDP];\r\nif (etype == htons(ETH_P_IPV6) && ip_proto == IPPROTO_TCP)\r\nreturn &arfs->arfs_tables[ARFS_IPV6_TCP];\r\nif (etype == htons(ETH_P_IPV6) && ip_proto == IPPROTO_UDP)\r\nreturn &arfs->arfs_tables[ARFS_IPV6_UDP];\r\nreturn NULL;\r\n}\r\nstatic struct mlx5_flow_rule *arfs_add_rule(struct mlx5e_priv *priv,\r\nstruct arfs_rule *arfs_rule)\r\n{\r\nstruct mlx5e_arfs_tables *arfs = &priv->fs.arfs;\r\nstruct arfs_tuple *tuple = &arfs_rule->tuple;\r\nstruct mlx5_flow_rule *rule = NULL;\r\nstruct mlx5_flow_destination dest;\r\nstruct arfs_table *arfs_table;\r\nstruct mlx5_flow_spec *spec;\r\nstruct mlx5_flow_table *ft;\r\nint err = 0;\r\nspec = mlx5_vzalloc(sizeof(*spec));\r\nif (!spec) {\r\nnetdev_err(priv->netdev, "%s: alloc failed\n", __func__);\r\nerr = -ENOMEM;\r\ngoto out;\r\n}\r\nspec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;\r\nMLX5_SET_TO_ONES(fte_match_param, spec->match_criteria,\r\nouter_headers.ethertype);\r\nMLX5_SET(fte_match_param, spec->match_value, outer_headers.ethertype,\r\nntohs(tuple->etype));\r\narfs_table = arfs_get_table(arfs, tuple->ip_proto, tuple->etype);\r\nif (!arfs_table) {\r\nerr = -EINVAL;\r\ngoto out;\r\n}\r\nft = arfs_table->ft.t;\r\nif (tuple->ip_proto == IPPROTO_TCP) {\r\nMLX5_SET_TO_ONES(fte_match_param, spec->match_criteria,\r\nouter_headers.tcp_dport);\r\nMLX5_SET_TO_ONES(fte_match_param, spec->match_criteria,\r\nouter_headers.tcp_sport);\r\nMLX5_SET(fte_match_param, spec->match_value, outer_headers.tcp_dport,\r\nntohs(tuple->dst_port));\r\nMLX5_SET(fte_match_param, spec->match_value, outer_headers.tcp_sport,\r\nntohs(tuple->src_port));\r\n} else {\r\nMLX5_SET_TO_ONES(fte_match_param, spec->match_criteria,\r\nouter_headers.udp_dport);\r\nMLX5_SET_TO_ONES(fte_match_param, spec->match_criteria,\r\nouter_headers.udp_sport);\r\nMLX5_SET(fte_match_param, spec->match_value, outer_headers.udp_dport,\r\nntohs(tuple->dst_port));\r\nMLX5_SET(fte_match_param, spec->match_value, outer_headers.udp_sport,\r\nntohs(tuple->src_port));\r\n}\r\nif (tuple->etype == htons(ETH_P_IP)) {\r\nmemcpy(MLX5_ADDR_OF(fte_match_param, spec->match_value,\r\nouter_headers.src_ipv4_src_ipv6.ipv4_layout.ipv4),\r\n&tuple->src_ipv4,\r\n4);\r\nmemcpy(MLX5_ADDR_OF(fte_match_param, spec->match_value,\r\nouter_headers.dst_ipv4_dst_ipv6.ipv4_layout.ipv4),\r\n&tuple->dst_ipv4,\r\n4);\r\nMLX5_SET_TO_ONES(fte_match_param, spec->match_criteria,\r\nouter_headers.src_ipv4_src_ipv6.ipv4_layout.ipv4);\r\nMLX5_SET_TO_ONES(fte_match_param, spec->match_criteria,\r\nouter_headers.dst_ipv4_dst_ipv6.ipv4_layout.ipv4);\r\n} else {\r\nmemcpy(MLX5_ADDR_OF(fte_match_param, spec->match_value,\r\nouter_headers.src_ipv4_src_ipv6.ipv6_layout.ipv6),\r\n&tuple->src_ipv6,\r\n16);\r\nmemcpy(MLX5_ADDR_OF(fte_match_param, spec->match_value,\r\nouter_headers.dst_ipv4_dst_ipv6.ipv6_layout.ipv6),\r\n&tuple->dst_ipv6,\r\n16);\r\nmemset(MLX5_ADDR_OF(fte_match_param, spec->match_criteria,\r\nouter_headers.src_ipv4_src_ipv6.ipv6_layout.ipv6),\r\n0xff,\r\n16);\r\nmemset(MLX5_ADDR_OF(fte_match_param, spec->match_criteria,\r\nouter_headers.dst_ipv4_dst_ipv6.ipv6_layout.ipv6),\r\n0xff,\r\n16);\r\n}\r\ndest.type = MLX5_FLOW_DESTINATION_TYPE_TIR;\r\ndest.tir_num = priv->direct_tir[arfs_rule->rxq].tirn;\r\nrule = mlx5_add_flow_rule(ft, spec, MLX5_FLOW_CONTEXT_ACTION_FWD_DEST,\r\nMLX5_FS_DEFAULT_FLOW_TAG,\r\n&dest);\r\nif (IS_ERR(rule)) {\r\nerr = PTR_ERR(rule);\r\nnetdev_err(priv->netdev, "%s: add rule(filter id=%d, rq idx=%d) failed, err=%d\n",\r\n__func__, arfs_rule->filter_id, arfs_rule->rxq, err);\r\n}\r\nout:\r\nkvfree(spec);\r\nreturn err ? ERR_PTR(err) : rule;\r\n}\r\nstatic void arfs_modify_rule_rq(struct mlx5e_priv *priv,\r\nstruct mlx5_flow_rule *rule, u16 rxq)\r\n{\r\nstruct mlx5_flow_destination dst;\r\nint err = 0;\r\ndst.type = MLX5_FLOW_DESTINATION_TYPE_TIR;\r\ndst.tir_num = priv->direct_tir[rxq].tirn;\r\nerr = mlx5_modify_rule_destination(rule, &dst);\r\nif (err)\r\nnetdev_warn(priv->netdev,\r\n"Failed to modfiy aRFS rule destination to rq=%d\n", rxq);\r\n}\r\nstatic void arfs_handle_work(struct work_struct *work)\r\n{\r\nstruct arfs_rule *arfs_rule = container_of(work,\r\nstruct arfs_rule,\r\narfs_work);\r\nstruct mlx5e_priv *priv = arfs_rule->priv;\r\nstruct mlx5_flow_rule *rule;\r\nmutex_lock(&priv->state_lock);\r\nif (!test_bit(MLX5E_STATE_OPENED, &priv->state)) {\r\nspin_lock_bh(&priv->fs.arfs.arfs_lock);\r\nhlist_del(&arfs_rule->hlist);\r\nspin_unlock_bh(&priv->fs.arfs.arfs_lock);\r\nmutex_unlock(&priv->state_lock);\r\nkfree(arfs_rule);\r\ngoto out;\r\n}\r\nmutex_unlock(&priv->state_lock);\r\nif (!arfs_rule->rule) {\r\nrule = arfs_add_rule(priv, arfs_rule);\r\nif (IS_ERR(rule))\r\ngoto out;\r\narfs_rule->rule = rule;\r\n} else {\r\narfs_modify_rule_rq(priv, arfs_rule->rule,\r\narfs_rule->rxq);\r\n}\r\nout:\r\narfs_may_expire_flow(priv);\r\n}\r\nstatic __be16 arfs_get_dst_port(const struct sk_buff *skb)\r\n{\r\nchar *transport_header;\r\ntransport_header = skb_transport_header(skb);\r\nif (arfs_get_ip_proto(skb) == IPPROTO_TCP)\r\nreturn ((struct tcphdr *)transport_header)->dest;\r\nreturn ((struct udphdr *)transport_header)->dest;\r\n}\r\nstatic __be16 arfs_get_src_port(const struct sk_buff *skb)\r\n{\r\nchar *transport_header;\r\ntransport_header = skb_transport_header(skb);\r\nif (arfs_get_ip_proto(skb) == IPPROTO_TCP)\r\nreturn ((struct tcphdr *)transport_header)->source;\r\nreturn ((struct udphdr *)transport_header)->source;\r\n}\r\nstatic struct arfs_rule *arfs_alloc_rule(struct mlx5e_priv *priv,\r\nstruct arfs_table *arfs_t,\r\nconst struct sk_buff *skb,\r\nu16 rxq, u32 flow_id)\r\n{\r\nstruct arfs_rule *rule;\r\nstruct arfs_tuple *tuple;\r\nrule = kzalloc(sizeof(*rule), GFP_ATOMIC);\r\nif (!rule)\r\nreturn NULL;\r\nrule->priv = priv;\r\nrule->rxq = rxq;\r\nINIT_WORK(&rule->arfs_work, arfs_handle_work);\r\ntuple = &rule->tuple;\r\ntuple->etype = skb->protocol;\r\nif (tuple->etype == htons(ETH_P_IP)) {\r\ntuple->src_ipv4 = ip_hdr(skb)->saddr;\r\ntuple->dst_ipv4 = ip_hdr(skb)->daddr;\r\n} else {\r\nmemcpy(&tuple->src_ipv6, &ipv6_hdr(skb)->saddr,\r\nsizeof(struct in6_addr));\r\nmemcpy(&tuple->dst_ipv6, &ipv6_hdr(skb)->daddr,\r\nsizeof(struct in6_addr));\r\n}\r\ntuple->ip_proto = arfs_get_ip_proto(skb);\r\ntuple->src_port = arfs_get_src_port(skb);\r\ntuple->dst_port = arfs_get_dst_port(skb);\r\nrule->flow_id = flow_id;\r\nrule->filter_id = priv->fs.arfs.last_filter_id++ % RPS_NO_FILTER;\r\nhlist_add_head(&rule->hlist,\r\narfs_hash_bucket(arfs_t, tuple->src_port,\r\ntuple->dst_port));\r\nreturn rule;\r\n}\r\nstatic bool arfs_cmp_ips(struct arfs_tuple *tuple,\r\nconst struct sk_buff *skb)\r\n{\r\nif (tuple->etype == htons(ETH_P_IP) &&\r\ntuple->src_ipv4 == ip_hdr(skb)->saddr &&\r\ntuple->dst_ipv4 == ip_hdr(skb)->daddr)\r\nreturn true;\r\nif (tuple->etype == htons(ETH_P_IPV6) &&\r\n(!memcmp(&tuple->src_ipv6, &ipv6_hdr(skb)->saddr,\r\nsizeof(struct in6_addr))) &&\r\n(!memcmp(&tuple->dst_ipv6, &ipv6_hdr(skb)->daddr,\r\nsizeof(struct in6_addr))))\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic struct arfs_rule *arfs_find_rule(struct arfs_table *arfs_t,\r\nconst struct sk_buff *skb)\r\n{\r\nstruct arfs_rule *arfs_rule;\r\nstruct hlist_head *head;\r\n__be16 src_port = arfs_get_src_port(skb);\r\n__be16 dst_port = arfs_get_dst_port(skb);\r\nhead = arfs_hash_bucket(arfs_t, src_port, dst_port);\r\nhlist_for_each_entry(arfs_rule, head, hlist) {\r\nif (arfs_rule->tuple.src_port == src_port &&\r\narfs_rule->tuple.dst_port == dst_port &&\r\narfs_cmp_ips(&arfs_rule->tuple, skb)) {\r\nreturn arfs_rule;\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nint mlx5e_rx_flow_steer(struct net_device *dev, const struct sk_buff *skb,\r\nu16 rxq_index, u32 flow_id)\r\n{\r\nstruct mlx5e_priv *priv = netdev_priv(dev);\r\nstruct mlx5e_arfs_tables *arfs = &priv->fs.arfs;\r\nstruct arfs_table *arfs_t;\r\nstruct arfs_rule *arfs_rule;\r\nif (skb->protocol != htons(ETH_P_IP) &&\r\nskb->protocol != htons(ETH_P_IPV6))\r\nreturn -EPROTONOSUPPORT;\r\narfs_t = arfs_get_table(arfs, arfs_get_ip_proto(skb), skb->protocol);\r\nif (!arfs_t)\r\nreturn -EPROTONOSUPPORT;\r\nspin_lock_bh(&arfs->arfs_lock);\r\narfs_rule = arfs_find_rule(arfs_t, skb);\r\nif (arfs_rule) {\r\nif (arfs_rule->rxq == rxq_index) {\r\nspin_unlock_bh(&arfs->arfs_lock);\r\nreturn arfs_rule->filter_id;\r\n}\r\narfs_rule->rxq = rxq_index;\r\n} else {\r\narfs_rule = arfs_alloc_rule(priv, arfs_t, skb,\r\nrxq_index, flow_id);\r\nif (!arfs_rule) {\r\nspin_unlock_bh(&arfs->arfs_lock);\r\nreturn -ENOMEM;\r\n}\r\n}\r\nqueue_work(priv->fs.arfs.wq, &arfs_rule->arfs_work);\r\nspin_unlock_bh(&arfs->arfs_lock);\r\nreturn arfs_rule->filter_id;\r\n}
