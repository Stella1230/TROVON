static int echainiv_encrypt(struct aead_request *req)\r\n{\r\nstruct crypto_aead *geniv = crypto_aead_reqtfm(req);\r\nstruct aead_geniv_ctx *ctx = crypto_aead_ctx(geniv);\r\nstruct aead_request *subreq = aead_request_ctx(req);\r\n__be64 nseqno;\r\nu64 seqno;\r\nu8 *info;\r\nunsigned int ivsize = crypto_aead_ivsize(geniv);\r\nint err;\r\nif (req->cryptlen < ivsize)\r\nreturn -EINVAL;\r\naead_request_set_tfm(subreq, ctx->child);\r\ninfo = req->iv;\r\nif (req->src != req->dst) {\r\nSKCIPHER_REQUEST_ON_STACK(nreq, ctx->sknull);\r\nskcipher_request_set_tfm(nreq, ctx->sknull);\r\nskcipher_request_set_callback(nreq, req->base.flags,\r\nNULL, NULL);\r\nskcipher_request_set_crypt(nreq, req->src, req->dst,\r\nreq->assoclen + req->cryptlen,\r\nNULL);\r\nerr = crypto_skcipher_encrypt(nreq);\r\nif (err)\r\nreturn err;\r\n}\r\naead_request_set_callback(subreq, req->base.flags,\r\nreq->base.complete, req->base.data);\r\naead_request_set_crypt(subreq, req->dst, req->dst,\r\nreq->cryptlen, info);\r\naead_request_set_ad(subreq, req->assoclen);\r\nmemcpy(&nseqno, info + ivsize - 8, 8);\r\nseqno = be64_to_cpu(nseqno);\r\nmemset(info, 0, ivsize);\r\nscatterwalk_map_and_copy(info, req->dst, req->assoclen, ivsize, 1);\r\ndo {\r\nu64 a;\r\nmemcpy(&a, ctx->salt + ivsize - 8, 8);\r\na |= 1;\r\na *= seqno;\r\nmemcpy(info + ivsize - 8, &a, 8);\r\n} while ((ivsize -= 8));\r\nreturn crypto_aead_encrypt(subreq);\r\n}\r\nstatic int echainiv_decrypt(struct aead_request *req)\r\n{\r\nstruct crypto_aead *geniv = crypto_aead_reqtfm(req);\r\nstruct aead_geniv_ctx *ctx = crypto_aead_ctx(geniv);\r\nstruct aead_request *subreq = aead_request_ctx(req);\r\ncrypto_completion_t compl;\r\nvoid *data;\r\nunsigned int ivsize = crypto_aead_ivsize(geniv);\r\nif (req->cryptlen < ivsize)\r\nreturn -EINVAL;\r\naead_request_set_tfm(subreq, ctx->child);\r\ncompl = req->base.complete;\r\ndata = req->base.data;\r\naead_request_set_callback(subreq, req->base.flags, compl, data);\r\naead_request_set_crypt(subreq, req->src, req->dst,\r\nreq->cryptlen - ivsize, req->iv);\r\naead_request_set_ad(subreq, req->assoclen + ivsize);\r\nscatterwalk_map_and_copy(req->iv, req->src, req->assoclen, ivsize, 0);\r\nreturn crypto_aead_decrypt(subreq);\r\n}\r\nstatic int echainiv_aead_create(struct crypto_template *tmpl,\r\nstruct rtattr **tb)\r\n{\r\nstruct aead_instance *inst;\r\nstruct crypto_aead_spawn *spawn;\r\nstruct aead_alg *alg;\r\nint err;\r\ninst = aead_geniv_alloc(tmpl, tb, 0, 0);\r\nif (IS_ERR(inst))\r\nreturn PTR_ERR(inst);\r\nspawn = aead_instance_ctx(inst);\r\nalg = crypto_spawn_aead_alg(spawn);\r\nerr = -EINVAL;\r\nif (inst->alg.ivsize & (sizeof(u64) - 1) || !inst->alg.ivsize)\r\ngoto free_inst;\r\ninst->alg.encrypt = echainiv_encrypt;\r\ninst->alg.decrypt = echainiv_decrypt;\r\ninst->alg.init = aead_init_geniv;\r\ninst->alg.exit = aead_exit_geniv;\r\ninst->alg.base.cra_ctxsize = sizeof(struct aead_geniv_ctx);\r\ninst->alg.base.cra_ctxsize += inst->alg.ivsize;\r\ninst->free = aead_geniv_free;\r\nerr = aead_register_instance(tmpl, inst);\r\nif (err)\r\ngoto free_inst;\r\nout:\r\nreturn err;\r\nfree_inst:\r\naead_geniv_free(inst);\r\ngoto out;\r\n}\r\nstatic void echainiv_free(struct crypto_instance *inst)\r\n{\r\naead_geniv_free(aead_instance(inst));\r\n}\r\nstatic int __init echainiv_module_init(void)\r\n{\r\nreturn crypto_register_template(&echainiv_tmpl);\r\n}\r\nstatic void __exit echainiv_module_exit(void)\r\n{\r\ncrypto_unregister_template(&echainiv_tmpl);\r\n}
