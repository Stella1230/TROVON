static u8 ip4_frag_ecn(u8 tos)\r\n{\r\nreturn 1 << (tos & INET_ECN_MASK);\r\n}\r\nint ip_frag_mem(struct net *net)\r\n{\r\nreturn sum_frag_mem_limit(&net->ipv4.frags);\r\n}\r\nstatic unsigned int ipqhashfn(__be16 id, __be32 saddr, __be32 daddr, u8 prot)\r\n{\r\nnet_get_random_once(&ip4_frags.rnd, sizeof(ip4_frags.rnd));\r\nreturn jhash_3words((__force u32)id << 16 | prot,\r\n(__force u32)saddr, (__force u32)daddr,\r\nip4_frags.rnd);\r\n}\r\nstatic unsigned int ip4_hashfn(const struct inet_frag_queue *q)\r\n{\r\nconst struct ipq *ipq;\r\nipq = container_of(q, struct ipq, q);\r\nreturn ipqhashfn(ipq->id, ipq->saddr, ipq->daddr, ipq->protocol);\r\n}\r\nstatic bool ip4_frag_match(const struct inet_frag_queue *q, const void *a)\r\n{\r\nconst struct ipq *qp;\r\nconst struct ip4_create_arg *arg = a;\r\nqp = container_of(q, struct ipq, q);\r\nreturn qp->id == arg->iph->id &&\r\nqp->saddr == arg->iph->saddr &&\r\nqp->daddr == arg->iph->daddr &&\r\nqp->protocol == arg->iph->protocol &&\r\nqp->user == arg->user &&\r\nqp->vif == arg->vif;\r\n}\r\nstatic void ip4_frag_init(struct inet_frag_queue *q, const void *a)\r\n{\r\nstruct ipq *qp = container_of(q, struct ipq, q);\r\nstruct netns_ipv4 *ipv4 = container_of(q->net, struct netns_ipv4,\r\nfrags);\r\nstruct net *net = container_of(ipv4, struct net, ipv4);\r\nconst struct ip4_create_arg *arg = a;\r\nqp->protocol = arg->iph->protocol;\r\nqp->id = arg->iph->id;\r\nqp->ecn = ip4_frag_ecn(arg->iph->tos);\r\nqp->saddr = arg->iph->saddr;\r\nqp->daddr = arg->iph->daddr;\r\nqp->vif = arg->vif;\r\nqp->user = arg->user;\r\nqp->peer = q->net->max_dist ?\r\ninet_getpeer_v4(net->ipv4.peers, arg->iph->saddr, arg->vif, 1) :\r\nNULL;\r\n}\r\nstatic void ip4_frag_free(struct inet_frag_queue *q)\r\n{\r\nstruct ipq *qp;\r\nqp = container_of(q, struct ipq, q);\r\nif (qp->peer)\r\ninet_putpeer(qp->peer);\r\n}\r\nstatic void ipq_put(struct ipq *ipq)\r\n{\r\ninet_frag_put(&ipq->q, &ip4_frags);\r\n}\r\nstatic void ipq_kill(struct ipq *ipq)\r\n{\r\ninet_frag_kill(&ipq->q, &ip4_frags);\r\n}\r\nstatic bool frag_expire_skip_icmp(u32 user)\r\n{\r\nreturn user == IP_DEFRAG_AF_PACKET ||\r\nip_defrag_user_in_between(user, IP_DEFRAG_CONNTRACK_IN,\r\n__IP_DEFRAG_CONNTRACK_IN_END) ||\r\nip_defrag_user_in_between(user, IP_DEFRAG_CONNTRACK_BRIDGE_IN,\r\n__IP_DEFRAG_CONNTRACK_BRIDGE_IN);\r\n}\r\nstatic void ip_expire(unsigned long arg)\r\n{\r\nstruct ipq *qp;\r\nstruct net *net;\r\nqp = container_of((struct inet_frag_queue *) arg, struct ipq, q);\r\nnet = container_of(qp->q.net, struct net, ipv4.frags);\r\nspin_lock(&qp->q.lock);\r\nif (qp->q.flags & INET_FRAG_COMPLETE)\r\ngoto out;\r\nipq_kill(qp);\r\n__IP_INC_STATS(net, IPSTATS_MIB_REASMFAILS);\r\nif (!inet_frag_evicting(&qp->q)) {\r\nstruct sk_buff *head = qp->q.fragments;\r\nconst struct iphdr *iph;\r\nint err;\r\n__IP_INC_STATS(net, IPSTATS_MIB_REASMTIMEOUT);\r\nif (!(qp->q.flags & INET_FRAG_FIRST_IN) || !qp->q.fragments)\r\ngoto out;\r\nrcu_read_lock();\r\nhead->dev = dev_get_by_index_rcu(net, qp->iif);\r\nif (!head->dev)\r\ngoto out_rcu_unlock;\r\niph = ip_hdr(head);\r\nerr = ip_route_input_noref(head, iph->daddr, iph->saddr,\r\niph->tos, head->dev);\r\nif (err)\r\ngoto out_rcu_unlock;\r\nif (frag_expire_skip_icmp(qp->user) &&\r\n(skb_rtable(head)->rt_type != RTN_LOCAL))\r\ngoto out_rcu_unlock;\r\nicmp_send(head, ICMP_TIME_EXCEEDED, ICMP_EXC_FRAGTIME, 0);\r\nout_rcu_unlock:\r\nrcu_read_unlock();\r\n}\r\nout:\r\nspin_unlock(&qp->q.lock);\r\nipq_put(qp);\r\n}\r\nstatic struct ipq *ip_find(struct net *net, struct iphdr *iph,\r\nu32 user, int vif)\r\n{\r\nstruct inet_frag_queue *q;\r\nstruct ip4_create_arg arg;\r\nunsigned int hash;\r\narg.iph = iph;\r\narg.user = user;\r\narg.vif = vif;\r\nhash = ipqhashfn(iph->id, iph->saddr, iph->daddr, iph->protocol);\r\nq = inet_frag_find(&net->ipv4.frags, &ip4_frags, &arg, hash);\r\nif (IS_ERR_OR_NULL(q)) {\r\ninet_frag_maybe_warn_overflow(q, pr_fmt());\r\nreturn NULL;\r\n}\r\nreturn container_of(q, struct ipq, q);\r\n}\r\nstatic int ip_frag_too_far(struct ipq *qp)\r\n{\r\nstruct inet_peer *peer = qp->peer;\r\nunsigned int max = qp->q.net->max_dist;\r\nunsigned int start, end;\r\nint rc;\r\nif (!peer || !max)\r\nreturn 0;\r\nstart = qp->rid;\r\nend = atomic_inc_return(&peer->rid);\r\nqp->rid = end;\r\nrc = qp->q.fragments && (end - start) > max;\r\nif (rc) {\r\nstruct net *net;\r\nnet = container_of(qp->q.net, struct net, ipv4.frags);\r\n__IP_INC_STATS(net, IPSTATS_MIB_REASMFAILS);\r\n}\r\nreturn rc;\r\n}\r\nstatic int ip_frag_reinit(struct ipq *qp)\r\n{\r\nstruct sk_buff *fp;\r\nunsigned int sum_truesize = 0;\r\nif (!mod_timer(&qp->q.timer, jiffies + qp->q.net->timeout)) {\r\natomic_inc(&qp->q.refcnt);\r\nreturn -ETIMEDOUT;\r\n}\r\nfp = qp->q.fragments;\r\ndo {\r\nstruct sk_buff *xp = fp->next;\r\nsum_truesize += fp->truesize;\r\nkfree_skb(fp);\r\nfp = xp;\r\n} while (fp);\r\nsub_frag_mem_limit(qp->q.net, sum_truesize);\r\nqp->q.flags = 0;\r\nqp->q.len = 0;\r\nqp->q.meat = 0;\r\nqp->q.fragments = NULL;\r\nqp->q.fragments_tail = NULL;\r\nqp->iif = 0;\r\nqp->ecn = 0;\r\nreturn 0;\r\n}\r\nstatic int ip_frag_queue(struct ipq *qp, struct sk_buff *skb)\r\n{\r\nstruct sk_buff *prev, *next;\r\nstruct net_device *dev;\r\nunsigned int fragsize;\r\nint flags, offset;\r\nint ihl, end;\r\nint err = -ENOENT;\r\nu8 ecn;\r\nif (qp->q.flags & INET_FRAG_COMPLETE)\r\ngoto err;\r\nif (!(IPCB(skb)->flags & IPSKB_FRAG_COMPLETE) &&\r\nunlikely(ip_frag_too_far(qp)) &&\r\nunlikely(err = ip_frag_reinit(qp))) {\r\nipq_kill(qp);\r\ngoto err;\r\n}\r\necn = ip4_frag_ecn(ip_hdr(skb)->tos);\r\noffset = ntohs(ip_hdr(skb)->frag_off);\r\nflags = offset & ~IP_OFFSET;\r\noffset &= IP_OFFSET;\r\noffset <<= 3;\r\nihl = ip_hdrlen(skb);\r\nend = offset + skb->len - skb_network_offset(skb) - ihl;\r\nerr = -EINVAL;\r\nif ((flags & IP_MF) == 0) {\r\nif (end < qp->q.len ||\r\n((qp->q.flags & INET_FRAG_LAST_IN) && end != qp->q.len))\r\ngoto err;\r\nqp->q.flags |= INET_FRAG_LAST_IN;\r\nqp->q.len = end;\r\n} else {\r\nif (end&7) {\r\nend &= ~7;\r\nif (skb->ip_summed != CHECKSUM_UNNECESSARY)\r\nskb->ip_summed = CHECKSUM_NONE;\r\n}\r\nif (end > qp->q.len) {\r\nif (qp->q.flags & INET_FRAG_LAST_IN)\r\ngoto err;\r\nqp->q.len = end;\r\n}\r\n}\r\nif (end == offset)\r\ngoto err;\r\nerr = -ENOMEM;\r\nif (!pskb_pull(skb, skb_network_offset(skb) + ihl))\r\ngoto err;\r\nerr = pskb_trim_rcsum(skb, end - offset);\r\nif (err)\r\ngoto err;\r\nprev = qp->q.fragments_tail;\r\nif (!prev || FRAG_CB(prev)->offset < offset) {\r\nnext = NULL;\r\ngoto found;\r\n}\r\nprev = NULL;\r\nfor (next = qp->q.fragments; next != NULL; next = next->next) {\r\nif (FRAG_CB(next)->offset >= offset)\r\nbreak;\r\nprev = next;\r\n}\r\nfound:\r\nif (prev) {\r\nint i = (FRAG_CB(prev)->offset + prev->len) - offset;\r\nif (i > 0) {\r\noffset += i;\r\nerr = -EINVAL;\r\nif (end <= offset)\r\ngoto err;\r\nerr = -ENOMEM;\r\nif (!pskb_pull(skb, i))\r\ngoto err;\r\nif (skb->ip_summed != CHECKSUM_UNNECESSARY)\r\nskb->ip_summed = CHECKSUM_NONE;\r\n}\r\n}\r\nerr = -ENOMEM;\r\nwhile (next && FRAG_CB(next)->offset < end) {\r\nint i = end - FRAG_CB(next)->offset;\r\nif (i < next->len) {\r\nif (!pskb_pull(next, i))\r\ngoto err;\r\nFRAG_CB(next)->offset += i;\r\nqp->q.meat -= i;\r\nif (next->ip_summed != CHECKSUM_UNNECESSARY)\r\nnext->ip_summed = CHECKSUM_NONE;\r\nbreak;\r\n} else {\r\nstruct sk_buff *free_it = next;\r\nnext = next->next;\r\nif (prev)\r\nprev->next = next;\r\nelse\r\nqp->q.fragments = next;\r\nqp->q.meat -= free_it->len;\r\nsub_frag_mem_limit(qp->q.net, free_it->truesize);\r\nkfree_skb(free_it);\r\n}\r\n}\r\nFRAG_CB(skb)->offset = offset;\r\nskb->next = next;\r\nif (!next)\r\nqp->q.fragments_tail = skb;\r\nif (prev)\r\nprev->next = skb;\r\nelse\r\nqp->q.fragments = skb;\r\ndev = skb->dev;\r\nif (dev) {\r\nqp->iif = dev->ifindex;\r\nskb->dev = NULL;\r\n}\r\nqp->q.stamp = skb->tstamp;\r\nqp->q.meat += skb->len;\r\nqp->ecn |= ecn;\r\nadd_frag_mem_limit(qp->q.net, skb->truesize);\r\nif (offset == 0)\r\nqp->q.flags |= INET_FRAG_FIRST_IN;\r\nfragsize = skb->len + ihl;\r\nif (fragsize > qp->q.max_size)\r\nqp->q.max_size = fragsize;\r\nif (ip_hdr(skb)->frag_off & htons(IP_DF) &&\r\nfragsize > qp->max_df_size)\r\nqp->max_df_size = fragsize;\r\nif (qp->q.flags == (INET_FRAG_FIRST_IN | INET_FRAG_LAST_IN) &&\r\nqp->q.meat == qp->q.len) {\r\nunsigned long orefdst = skb->_skb_refdst;\r\nskb->_skb_refdst = 0UL;\r\nerr = ip_frag_reasm(qp, prev, dev);\r\nskb->_skb_refdst = orefdst;\r\nreturn err;\r\n}\r\nskb_dst_drop(skb);\r\nreturn -EINPROGRESS;\r\nerr:\r\nkfree_skb(skb);\r\nreturn err;\r\n}\r\nstatic int ip_frag_reasm(struct ipq *qp, struct sk_buff *prev,\r\nstruct net_device *dev)\r\n{\r\nstruct net *net = container_of(qp->q.net, struct net, ipv4.frags);\r\nstruct iphdr *iph;\r\nstruct sk_buff *fp, *head = qp->q.fragments;\r\nint len;\r\nint ihlen;\r\nint err;\r\nu8 ecn;\r\nipq_kill(qp);\r\necn = ip_frag_ecn_table[qp->ecn];\r\nif (unlikely(ecn == 0xff)) {\r\nerr = -EINVAL;\r\ngoto out_fail;\r\n}\r\nif (prev) {\r\nhead = prev->next;\r\nfp = skb_clone(head, GFP_ATOMIC);\r\nif (!fp)\r\ngoto out_nomem;\r\nfp->next = head->next;\r\nif (!fp->next)\r\nqp->q.fragments_tail = fp;\r\nprev->next = fp;\r\nskb_morph(head, qp->q.fragments);\r\nhead->next = qp->q.fragments->next;\r\nconsume_skb(qp->q.fragments);\r\nqp->q.fragments = head;\r\n}\r\nWARN_ON(!head);\r\nWARN_ON(FRAG_CB(head)->offset != 0);\r\nihlen = ip_hdrlen(head);\r\nlen = ihlen + qp->q.len;\r\nerr = -E2BIG;\r\nif (len > 65535)\r\ngoto out_oversize;\r\nif (skb_unclone(head, GFP_ATOMIC))\r\ngoto out_nomem;\r\nif (skb_has_frag_list(head)) {\r\nstruct sk_buff *clone;\r\nint i, plen = 0;\r\nclone = alloc_skb(0, GFP_ATOMIC);\r\nif (!clone)\r\ngoto out_nomem;\r\nclone->next = head->next;\r\nhead->next = clone;\r\nskb_shinfo(clone)->frag_list = skb_shinfo(head)->frag_list;\r\nskb_frag_list_init(head);\r\nfor (i = 0; i < skb_shinfo(head)->nr_frags; i++)\r\nplen += skb_frag_size(&skb_shinfo(head)->frags[i]);\r\nclone->len = clone->data_len = head->data_len - plen;\r\nhead->data_len -= clone->len;\r\nhead->len -= clone->len;\r\nclone->csum = 0;\r\nclone->ip_summed = head->ip_summed;\r\nadd_frag_mem_limit(qp->q.net, clone->truesize);\r\n}\r\nskb_shinfo(head)->frag_list = head->next;\r\nskb_push(head, head->data - skb_network_header(head));\r\nfor (fp=head->next; fp; fp = fp->next) {\r\nhead->data_len += fp->len;\r\nhead->len += fp->len;\r\nif (head->ip_summed != fp->ip_summed)\r\nhead->ip_summed = CHECKSUM_NONE;\r\nelse if (head->ip_summed == CHECKSUM_COMPLETE)\r\nhead->csum = csum_add(head->csum, fp->csum);\r\nhead->truesize += fp->truesize;\r\n}\r\nsub_frag_mem_limit(qp->q.net, head->truesize);\r\nhead->next = NULL;\r\nhead->dev = dev;\r\nhead->tstamp = qp->q.stamp;\r\nIPCB(head)->frag_max_size = max(qp->max_df_size, qp->q.max_size);\r\niph = ip_hdr(head);\r\niph->tot_len = htons(len);\r\niph->tos |= ecn;\r\nif (qp->max_df_size == qp->q.max_size) {\r\nIPCB(head)->flags |= IPSKB_FRAG_PMTU;\r\niph->frag_off = htons(IP_DF);\r\n} else {\r\niph->frag_off = 0;\r\n}\r\nip_send_check(iph);\r\n__IP_INC_STATS(net, IPSTATS_MIB_REASMOKS);\r\nqp->q.fragments = NULL;\r\nqp->q.fragments_tail = NULL;\r\nreturn 0;\r\nout_nomem:\r\nnet_dbg_ratelimited("queue_glue: no memory for gluing queue %p\n", qp);\r\nerr = -ENOMEM;\r\ngoto out_fail;\r\nout_oversize:\r\nnet_info_ratelimited("Oversized IP packet from %pI4\n", &qp->saddr);\r\nout_fail:\r\n__IP_INC_STATS(net, IPSTATS_MIB_REASMFAILS);\r\nreturn err;\r\n}\r\nint ip_defrag(struct net *net, struct sk_buff *skb, u32 user)\r\n{\r\nstruct net_device *dev = skb->dev ? : skb_dst(skb)->dev;\r\nint vif = l3mdev_master_ifindex_rcu(dev);\r\nstruct ipq *qp;\r\n__IP_INC_STATS(net, IPSTATS_MIB_REASMREQDS);\r\nskb_orphan(skb);\r\nqp = ip_find(net, ip_hdr(skb), user, vif);\r\nif (qp) {\r\nint ret;\r\nspin_lock(&qp->q.lock);\r\nret = ip_frag_queue(qp, skb);\r\nspin_unlock(&qp->q.lock);\r\nipq_put(qp);\r\nreturn ret;\r\n}\r\n__IP_INC_STATS(net, IPSTATS_MIB_REASMFAILS);\r\nkfree_skb(skb);\r\nreturn -ENOMEM;\r\n}\r\nstruct sk_buff *ip_check_defrag(struct net *net, struct sk_buff *skb, u32 user)\r\n{\r\nstruct iphdr iph;\r\nint netoff;\r\nu32 len;\r\nif (skb->protocol != htons(ETH_P_IP))\r\nreturn skb;\r\nnetoff = skb_network_offset(skb);\r\nif (skb_copy_bits(skb, netoff, &iph, sizeof(iph)) < 0)\r\nreturn skb;\r\nif (iph.ihl < 5 || iph.version != 4)\r\nreturn skb;\r\nlen = ntohs(iph.tot_len);\r\nif (skb->len < netoff + len || len < (iph.ihl * 4))\r\nreturn skb;\r\nif (ip_is_fragment(&iph)) {\r\nskb = skb_share_check(skb, GFP_ATOMIC);\r\nif (skb) {\r\nif (!pskb_may_pull(skb, netoff + iph.ihl * 4))\r\nreturn skb;\r\nif (pskb_trim_rcsum(skb, netoff + len))\r\nreturn skb;\r\nmemset(IPCB(skb), 0, sizeof(struct inet_skb_parm));\r\nif (ip_defrag(net, skb, user))\r\nreturn NULL;\r\nskb_clear_hash(skb);\r\n}\r\n}\r\nreturn skb;\r\n}\r\nstatic int __net_init ip4_frags_ns_ctl_register(struct net *net)\r\n{\r\nstruct ctl_table *table;\r\nstruct ctl_table_header *hdr;\r\ntable = ip4_frags_ns_ctl_table;\r\nif (!net_eq(net, &init_net)) {\r\ntable = kmemdup(table, sizeof(ip4_frags_ns_ctl_table), GFP_KERNEL);\r\nif (!table)\r\ngoto err_alloc;\r\ntable[0].data = &net->ipv4.frags.high_thresh;\r\ntable[0].extra1 = &net->ipv4.frags.low_thresh;\r\ntable[0].extra2 = &init_net.ipv4.frags.high_thresh;\r\ntable[1].data = &net->ipv4.frags.low_thresh;\r\ntable[1].extra2 = &net->ipv4.frags.high_thresh;\r\ntable[2].data = &net->ipv4.frags.timeout;\r\ntable[3].data = &net->ipv4.frags.max_dist;\r\n}\r\nhdr = register_net_sysctl(net, "net/ipv4", table);\r\nif (!hdr)\r\ngoto err_reg;\r\nnet->ipv4.frags_hdr = hdr;\r\nreturn 0;\r\nerr_reg:\r\nif (!net_eq(net, &init_net))\r\nkfree(table);\r\nerr_alloc:\r\nreturn -ENOMEM;\r\n}\r\nstatic void __net_exit ip4_frags_ns_ctl_unregister(struct net *net)\r\n{\r\nstruct ctl_table *table;\r\ntable = net->ipv4.frags_hdr->ctl_table_arg;\r\nunregister_net_sysctl_table(net->ipv4.frags_hdr);\r\nkfree(table);\r\n}\r\nstatic void __init ip4_frags_ctl_register(void)\r\n{\r\nregister_net_sysctl(&init_net, "net/ipv4", ip4_frags_ctl_table);\r\n}\r\nstatic int ip4_frags_ns_ctl_register(struct net *net)\r\n{\r\nreturn 0;\r\n}\r\nstatic void ip4_frags_ns_ctl_unregister(struct net *net)\r\n{\r\n}\r\nstatic void __init ip4_frags_ctl_register(void)\r\n{\r\n}\r\nstatic int __net_init ipv4_frags_init_net(struct net *net)\r\n{\r\nint res;\r\nnet->ipv4.frags.high_thresh = 4 * 1024 * 1024;\r\nnet->ipv4.frags.low_thresh = 3 * 1024 * 1024;\r\nnet->ipv4.frags.timeout = IP_FRAG_TIME;\r\nnet->ipv4.frags.max_dist = 64;\r\nres = inet_frags_init_net(&net->ipv4.frags);\r\nif (res)\r\nreturn res;\r\nres = ip4_frags_ns_ctl_register(net);\r\nif (res)\r\ninet_frags_uninit_net(&net->ipv4.frags);\r\nreturn res;\r\n}\r\nstatic void __net_exit ipv4_frags_exit_net(struct net *net)\r\n{\r\nip4_frags_ns_ctl_unregister(net);\r\ninet_frags_exit_net(&net->ipv4.frags, &ip4_frags);\r\n}\r\nvoid __init ipfrag_init(void)\r\n{\r\nip4_frags_ctl_register();\r\nregister_pernet_subsys(&ip4_frags_ops);\r\nip4_frags.hashfn = ip4_hashfn;\r\nip4_frags.constructor = ip4_frag_init;\r\nip4_frags.destructor = ip4_frag_free;\r\nip4_frags.qsize = sizeof(struct ipq);\r\nip4_frags.match = ip4_frag_match;\r\nip4_frags.frag_expire = ip_expire;\r\nip4_frags.frags_cache_name = ip_frag_cache_name;\r\nif (inet_frags_init(&ip4_frags))\r\npanic("IP: failed to allocate ip4_frags cache\n");\r\n}
