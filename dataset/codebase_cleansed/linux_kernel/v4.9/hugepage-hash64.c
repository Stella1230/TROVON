int __hash_page_thp(unsigned long ea, unsigned long access, unsigned long vsid,\r\npmd_t *pmdp, unsigned long trap, unsigned long flags,\r\nint ssize, unsigned int psize)\r\n{\r\nunsigned int index, valid;\r\nunsigned char *hpte_slot_array;\r\nunsigned long rflags, pa, hidx;\r\nunsigned long old_pmd, new_pmd;\r\nint ret, lpsize = MMU_PAGE_16M;\r\nunsigned long vpn, hash, shift, slot;\r\ndo {\r\npmd_t pmd = READ_ONCE(*pmdp);\r\nold_pmd = pmd_val(pmd);\r\nif (unlikely(old_pmd & H_PAGE_BUSY))\r\nreturn 0;\r\nif (unlikely(!check_pte_access(access, old_pmd)))\r\nreturn 1;\r\nnew_pmd = old_pmd | H_PAGE_BUSY | _PAGE_ACCESSED;\r\nif (access & _PAGE_WRITE)\r\nnew_pmd |= _PAGE_DIRTY;\r\n} while (!pmd_xchg(pmdp, __pmd(old_pmd), __pmd(new_pmd)));\r\nrflags = htab_convert_pte_flags(new_pmd);\r\n#if 0\r\nif (!cpu_has_feature(CPU_FTR_COHERENT_ICACHE)) {\r\nrflags = hash_page_do_lazy_icache(rflags, __pte(old_pte), trap);\r\n}\r\n#endif\r\nshift = mmu_psize_defs[psize].shift;\r\nindex = (ea & ~HPAGE_PMD_MASK) >> shift;\r\nBUG_ON(index >= PTE_FRAG_SIZE);\r\nvpn = hpt_vpn(ea, vsid, ssize);\r\nhpte_slot_array = get_hpte_slot_array(pmdp);\r\nif (psize == MMU_PAGE_4K) {\r\nif ((old_pmd & H_PAGE_HASHPTE) && !(old_pmd & H_PAGE_COMBO)) {\r\nflush_hash_hugepage(vsid, ea, pmdp, MMU_PAGE_64K,\r\nssize, flags);\r\nmemset(hpte_slot_array, 0, PTE_FRAG_SIZE);\r\n}\r\n}\r\nvalid = hpte_valid(hpte_slot_array, index);\r\nif (valid) {\r\nhash = hpt_hash(vpn, shift, ssize);\r\nhidx = hpte_hash_index(hpte_slot_array, index);\r\nif (hidx & _PTEIDX_SECONDARY)\r\nhash = ~hash;\r\nslot = (hash & htab_hash_mask) * HPTES_PER_GROUP;\r\nslot += hidx & _PTEIDX_GROUP_IX;\r\nret = mmu_hash_ops.hpte_updatepp(slot, rflags, vpn,\r\npsize, lpsize, ssize, flags);\r\nif (ret == -1) {\r\nvalid = 0;\r\nhpte_slot_array[index] = 0;\r\n}\r\n}\r\nif (!valid) {\r\nunsigned long hpte_group;\r\nhash = hpt_hash(vpn, shift, ssize);\r\npa = pmd_pfn(__pmd(old_pmd)) << PAGE_SHIFT;\r\nnew_pmd |= H_PAGE_HASHPTE;\r\nrepeat:\r\nhpte_group = ((hash & htab_hash_mask) * HPTES_PER_GROUP) & ~0x7UL;\r\nslot = mmu_hash_ops.hpte_insert(hpte_group, vpn, pa, rflags, 0,\r\npsize, lpsize, ssize);\r\nif (unlikely(slot == -1)) {\r\nhpte_group = ((~hash & htab_hash_mask) *\r\nHPTES_PER_GROUP) & ~0x7UL;\r\nslot = mmu_hash_ops.hpte_insert(hpte_group, vpn, pa,\r\nrflags,\r\nHPTE_V_SECONDARY,\r\npsize, lpsize, ssize);\r\nif (slot == -1) {\r\nif (mftb() & 0x1)\r\nhpte_group = ((hash & htab_hash_mask) *\r\nHPTES_PER_GROUP) & ~0x7UL;\r\nmmu_hash_ops.hpte_remove(hpte_group);\r\ngoto repeat;\r\n}\r\n}\r\nif (unlikely(slot == -2)) {\r\n*pmdp = __pmd(old_pmd);\r\nhash_failure_debug(ea, access, vsid, trap, ssize,\r\npsize, lpsize, old_pmd);\r\nreturn -1;\r\n}\r\nmark_hpte_slot_valid(hpte_slot_array, index, slot);\r\n}\r\nif (psize == MMU_PAGE_4K)\r\nnew_pmd |= H_PAGE_COMBO;\r\nsmp_wmb();\r\n*pmdp = __pmd(new_pmd & ~H_PAGE_BUSY);\r\nreturn 0;\r\n}
