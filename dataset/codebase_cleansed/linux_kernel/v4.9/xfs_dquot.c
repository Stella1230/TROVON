void\r\nxfs_qm_dqdestroy(\r\nxfs_dquot_t *dqp)\r\n{\r\nASSERT(list_empty(&dqp->q_lru));\r\nkmem_free(dqp->q_logitem.qli_item.li_lv_shadow);\r\nmutex_destroy(&dqp->q_qlock);\r\nXFS_STATS_DEC(dqp->q_mount, xs_qm_dquot);\r\nkmem_zone_free(xfs_qm_dqzone, dqp);\r\n}\r\nvoid\r\nxfs_qm_adjust_dqlimits(\r\nstruct xfs_mount *mp,\r\nstruct xfs_dquot *dq)\r\n{\r\nstruct xfs_quotainfo *q = mp->m_quotainfo;\r\nstruct xfs_disk_dquot *d = &dq->q_core;\r\nstruct xfs_def_quota *defq;\r\nint prealloc = 0;\r\nASSERT(d->d_id);\r\ndefq = xfs_get_defquota(dq, q);\r\nif (defq->bsoftlimit && !d->d_blk_softlimit) {\r\nd->d_blk_softlimit = cpu_to_be64(defq->bsoftlimit);\r\nprealloc = 1;\r\n}\r\nif (defq->bhardlimit && !d->d_blk_hardlimit) {\r\nd->d_blk_hardlimit = cpu_to_be64(defq->bhardlimit);\r\nprealloc = 1;\r\n}\r\nif (defq->isoftlimit && !d->d_ino_softlimit)\r\nd->d_ino_softlimit = cpu_to_be64(defq->isoftlimit);\r\nif (defq->ihardlimit && !d->d_ino_hardlimit)\r\nd->d_ino_hardlimit = cpu_to_be64(defq->ihardlimit);\r\nif (defq->rtbsoftlimit && !d->d_rtb_softlimit)\r\nd->d_rtb_softlimit = cpu_to_be64(defq->rtbsoftlimit);\r\nif (defq->rtbhardlimit && !d->d_rtb_hardlimit)\r\nd->d_rtb_hardlimit = cpu_to_be64(defq->rtbhardlimit);\r\nif (prealloc)\r\nxfs_dquot_set_prealloc_limits(dq);\r\n}\r\nvoid\r\nxfs_qm_adjust_dqtimers(\r\nxfs_mount_t *mp,\r\nxfs_disk_dquot_t *d)\r\n{\r\nASSERT(d->d_id);\r\n#ifdef DEBUG\r\nif (d->d_blk_hardlimit)\r\nASSERT(be64_to_cpu(d->d_blk_softlimit) <=\r\nbe64_to_cpu(d->d_blk_hardlimit));\r\nif (d->d_ino_hardlimit)\r\nASSERT(be64_to_cpu(d->d_ino_softlimit) <=\r\nbe64_to_cpu(d->d_ino_hardlimit));\r\nif (d->d_rtb_hardlimit)\r\nASSERT(be64_to_cpu(d->d_rtb_softlimit) <=\r\nbe64_to_cpu(d->d_rtb_hardlimit));\r\n#endif\r\nif (!d->d_btimer) {\r\nif ((d->d_blk_softlimit &&\r\n(be64_to_cpu(d->d_bcount) >\r\nbe64_to_cpu(d->d_blk_softlimit))) ||\r\n(d->d_blk_hardlimit &&\r\n(be64_to_cpu(d->d_bcount) >\r\nbe64_to_cpu(d->d_blk_hardlimit)))) {\r\nd->d_btimer = cpu_to_be32(get_seconds() +\r\nmp->m_quotainfo->qi_btimelimit);\r\n} else {\r\nd->d_bwarns = 0;\r\n}\r\n} else {\r\nif ((!d->d_blk_softlimit ||\r\n(be64_to_cpu(d->d_bcount) <=\r\nbe64_to_cpu(d->d_blk_softlimit))) &&\r\n(!d->d_blk_hardlimit ||\r\n(be64_to_cpu(d->d_bcount) <=\r\nbe64_to_cpu(d->d_blk_hardlimit)))) {\r\nd->d_btimer = 0;\r\n}\r\n}\r\nif (!d->d_itimer) {\r\nif ((d->d_ino_softlimit &&\r\n(be64_to_cpu(d->d_icount) >\r\nbe64_to_cpu(d->d_ino_softlimit))) ||\r\n(d->d_ino_hardlimit &&\r\n(be64_to_cpu(d->d_icount) >\r\nbe64_to_cpu(d->d_ino_hardlimit)))) {\r\nd->d_itimer = cpu_to_be32(get_seconds() +\r\nmp->m_quotainfo->qi_itimelimit);\r\n} else {\r\nd->d_iwarns = 0;\r\n}\r\n} else {\r\nif ((!d->d_ino_softlimit ||\r\n(be64_to_cpu(d->d_icount) <=\r\nbe64_to_cpu(d->d_ino_softlimit))) &&\r\n(!d->d_ino_hardlimit ||\r\n(be64_to_cpu(d->d_icount) <=\r\nbe64_to_cpu(d->d_ino_hardlimit)))) {\r\nd->d_itimer = 0;\r\n}\r\n}\r\nif (!d->d_rtbtimer) {\r\nif ((d->d_rtb_softlimit &&\r\n(be64_to_cpu(d->d_rtbcount) >\r\nbe64_to_cpu(d->d_rtb_softlimit))) ||\r\n(d->d_rtb_hardlimit &&\r\n(be64_to_cpu(d->d_rtbcount) >\r\nbe64_to_cpu(d->d_rtb_hardlimit)))) {\r\nd->d_rtbtimer = cpu_to_be32(get_seconds() +\r\nmp->m_quotainfo->qi_rtbtimelimit);\r\n} else {\r\nd->d_rtbwarns = 0;\r\n}\r\n} else {\r\nif ((!d->d_rtb_softlimit ||\r\n(be64_to_cpu(d->d_rtbcount) <=\r\nbe64_to_cpu(d->d_rtb_softlimit))) &&\r\n(!d->d_rtb_hardlimit ||\r\n(be64_to_cpu(d->d_rtbcount) <=\r\nbe64_to_cpu(d->d_rtb_hardlimit)))) {\r\nd->d_rtbtimer = 0;\r\n}\r\n}\r\n}\r\nSTATIC void\r\nxfs_qm_init_dquot_blk(\r\nxfs_trans_t *tp,\r\nxfs_mount_t *mp,\r\nxfs_dqid_t id,\r\nuint type,\r\nxfs_buf_t *bp)\r\n{\r\nstruct xfs_quotainfo *q = mp->m_quotainfo;\r\nxfs_dqblk_t *d;\r\nxfs_dqid_t curid;\r\nint i;\r\nASSERT(tp);\r\nASSERT(xfs_buf_islocked(bp));\r\nd = bp->b_addr;\r\ncurid = id - (id % q->qi_dqperchunk);\r\nmemset(d, 0, BBTOB(q->qi_dqchunklen));\r\nfor (i = 0; i < q->qi_dqperchunk; i++, d++, curid++) {\r\nd->dd_diskdq.d_magic = cpu_to_be16(XFS_DQUOT_MAGIC);\r\nd->dd_diskdq.d_version = XFS_DQUOT_VERSION;\r\nd->dd_diskdq.d_id = cpu_to_be32(curid);\r\nd->dd_diskdq.d_flags = type;\r\nif (xfs_sb_version_hascrc(&mp->m_sb)) {\r\nuuid_copy(&d->dd_uuid, &mp->m_sb.sb_meta_uuid);\r\nxfs_update_cksum((char *)d, sizeof(struct xfs_dqblk),\r\nXFS_DQUOT_CRC_OFF);\r\n}\r\n}\r\nxfs_trans_dquot_buf(tp, bp,\r\n(type & XFS_DQ_USER ? XFS_BLF_UDQUOT_BUF :\r\n((type & XFS_DQ_PROJ) ? XFS_BLF_PDQUOT_BUF :\r\nXFS_BLF_GDQUOT_BUF)));\r\nxfs_trans_log_buf(tp, bp, 0, BBTOB(q->qi_dqchunklen) - 1);\r\n}\r\nvoid\r\nxfs_dquot_set_prealloc_limits(struct xfs_dquot *dqp)\r\n{\r\n__uint64_t space;\r\ndqp->q_prealloc_hi_wmark = be64_to_cpu(dqp->q_core.d_blk_hardlimit);\r\ndqp->q_prealloc_lo_wmark = be64_to_cpu(dqp->q_core.d_blk_softlimit);\r\nif (!dqp->q_prealloc_lo_wmark) {\r\ndqp->q_prealloc_lo_wmark = dqp->q_prealloc_hi_wmark;\r\ndo_div(dqp->q_prealloc_lo_wmark, 100);\r\ndqp->q_prealloc_lo_wmark *= 95;\r\n}\r\nspace = dqp->q_prealloc_hi_wmark;\r\ndo_div(space, 100);\r\ndqp->q_low_space[XFS_QLOWSP_1_PCNT] = space;\r\ndqp->q_low_space[XFS_QLOWSP_3_PCNT] = space * 3;\r\ndqp->q_low_space[XFS_QLOWSP_5_PCNT] = space * 5;\r\n}\r\nSTATIC int\r\nxfs_qm_dqalloc(\r\nxfs_trans_t **tpp,\r\nxfs_mount_t *mp,\r\nxfs_dquot_t *dqp,\r\nxfs_inode_t *quotip,\r\nxfs_fileoff_t offset_fsb,\r\nxfs_buf_t **O_bpp)\r\n{\r\nxfs_fsblock_t firstblock;\r\nstruct xfs_defer_ops dfops;\r\nxfs_bmbt_irec_t map;\r\nint nmaps, error;\r\nxfs_buf_t *bp;\r\nxfs_trans_t *tp = *tpp;\r\nASSERT(tp != NULL);\r\ntrace_xfs_dqalloc(dqp);\r\nxfs_defer_init(&dfops, &firstblock);\r\nxfs_ilock(quotip, XFS_ILOCK_EXCL);\r\nif (!xfs_this_quota_on(dqp->q_mount, dqp->dq_flags)) {\r\nxfs_iunlock(quotip, XFS_ILOCK_EXCL);\r\nreturn -ESRCH;\r\n}\r\nxfs_trans_ijoin(tp, quotip, XFS_ILOCK_EXCL);\r\nnmaps = 1;\r\nerror = xfs_bmapi_write(tp, quotip, offset_fsb,\r\nXFS_DQUOT_CLUSTER_SIZE_FSB, XFS_BMAPI_METADATA,\r\n&firstblock, XFS_QM_DQALLOC_SPACE_RES(mp),\r\n&map, &nmaps, &dfops);\r\nif (error)\r\ngoto error0;\r\nASSERT(map.br_blockcount == XFS_DQUOT_CLUSTER_SIZE_FSB);\r\nASSERT(nmaps == 1);\r\nASSERT((map.br_startblock != DELAYSTARTBLOCK) &&\r\n(map.br_startblock != HOLESTARTBLOCK));\r\ndqp->q_blkno = XFS_FSB_TO_DADDR(mp, map.br_startblock);\r\nbp = xfs_trans_get_buf(tp, mp->m_ddev_targp,\r\ndqp->q_blkno,\r\nmp->m_quotainfo->qi_dqchunklen,\r\n0);\r\nif (!bp) {\r\nerror = -ENOMEM;\r\ngoto error1;\r\n}\r\nbp->b_ops = &xfs_dquot_buf_ops;\r\nxfs_qm_init_dquot_blk(tp, mp, be32_to_cpu(dqp->q_core.d_id),\r\ndqp->dq_flags & XFS_DQ_ALLTYPES, bp);\r\nxfs_trans_bhold(tp, bp);\r\nerror = xfs_defer_finish(tpp, &dfops, NULL);\r\nif (error)\r\ngoto error1;\r\nif (*tpp != tp) {\r\ntp = *tpp;\r\nxfs_trans_bjoin(tp, bp);\r\n} else {\r\nxfs_trans_bhold_release(tp, bp);\r\n}\r\n*O_bpp = bp;\r\nreturn 0;\r\nerror1:\r\nxfs_defer_cancel(&dfops);\r\nerror0:\r\nxfs_iunlock(quotip, XFS_ILOCK_EXCL);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_qm_dqrepair(\r\nstruct xfs_mount *mp,\r\nstruct xfs_trans *tp,\r\nstruct xfs_dquot *dqp,\r\nxfs_dqid_t firstid,\r\nstruct xfs_buf **bpp)\r\n{\r\nint error;\r\nstruct xfs_disk_dquot *ddq;\r\nstruct xfs_dqblk *d;\r\nint i;\r\nerror = xfs_trans_read_buf(mp, tp, mp->m_ddev_targp, dqp->q_blkno,\r\nmp->m_quotainfo->qi_dqchunklen,\r\n0, bpp, NULL);\r\nif (error) {\r\nASSERT(*bpp == NULL);\r\nreturn error;\r\n}\r\n(*bpp)->b_ops = &xfs_dquot_buf_ops;\r\nASSERT(xfs_buf_islocked(*bpp));\r\nd = (struct xfs_dqblk *)(*bpp)->b_addr;\r\nfor (i = 0; i < mp->m_quotainfo->qi_dqperchunk; i++) {\r\nddq = &d[i].dd_diskdq;\r\nerror = xfs_dqcheck(mp, ddq, firstid + i,\r\ndqp->dq_flags & XFS_DQ_ALLTYPES,\r\nXFS_QMOPT_DQREPAIR, "xfs_qm_dqrepair");\r\nif (error) {\r\nxfs_trans_brelse(tp, *bpp);\r\nreturn -EIO;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_qm_dqtobp(\r\nxfs_trans_t **tpp,\r\nxfs_dquot_t *dqp,\r\nxfs_disk_dquot_t **O_ddpp,\r\nxfs_buf_t **O_bpp,\r\nuint flags)\r\n{\r\nstruct xfs_bmbt_irec map;\r\nint nmaps = 1, error;\r\nstruct xfs_buf *bp;\r\nstruct xfs_inode *quotip;\r\nstruct xfs_mount *mp = dqp->q_mount;\r\nxfs_dqid_t id = be32_to_cpu(dqp->q_core.d_id);\r\nstruct xfs_trans *tp = (tpp ? *tpp : NULL);\r\nuint lock_mode;\r\nquotip = xfs_quota_inode(dqp->q_mount, dqp->dq_flags);\r\ndqp->q_fileoffset = (xfs_fileoff_t)id / mp->m_quotainfo->qi_dqperchunk;\r\nlock_mode = xfs_ilock_data_map_shared(quotip);\r\nif (!xfs_this_quota_on(dqp->q_mount, dqp->dq_flags)) {\r\nxfs_iunlock(quotip, lock_mode);\r\nreturn -ESRCH;\r\n}\r\nerror = xfs_bmapi_read(quotip, dqp->q_fileoffset,\r\nXFS_DQUOT_CLUSTER_SIZE_FSB, &map, &nmaps, 0);\r\nxfs_iunlock(quotip, lock_mode);\r\nif (error)\r\nreturn error;\r\nASSERT(nmaps == 1);\r\nASSERT(map.br_blockcount == 1);\r\ndqp->q_bufoffset = (id % mp->m_quotainfo->qi_dqperchunk) *\r\nsizeof(xfs_dqblk_t);\r\nASSERT(map.br_startblock != DELAYSTARTBLOCK);\r\nif (map.br_startblock == HOLESTARTBLOCK) {\r\nif (!(flags & XFS_QMOPT_DQALLOC))\r\nreturn -ENOENT;\r\nASSERT(tp);\r\nerror = xfs_qm_dqalloc(tpp, mp, dqp, quotip,\r\ndqp->q_fileoffset, &bp);\r\nif (error)\r\nreturn error;\r\ntp = *tpp;\r\n} else {\r\ntrace_xfs_dqtobp_read(dqp);\r\ndqp->q_blkno = XFS_FSB_TO_DADDR(mp, map.br_startblock);\r\nerror = xfs_trans_read_buf(mp, tp, mp->m_ddev_targp,\r\ndqp->q_blkno,\r\nmp->m_quotainfo->qi_dqchunklen,\r\n0, &bp, &xfs_dquot_buf_ops);\r\nif (error == -EFSCORRUPTED && (flags & XFS_QMOPT_DQREPAIR)) {\r\nxfs_dqid_t firstid = (xfs_dqid_t)map.br_startoff *\r\nmp->m_quotainfo->qi_dqperchunk;\r\nASSERT(bp == NULL);\r\nerror = xfs_qm_dqrepair(mp, tp, dqp, firstid, &bp);\r\n}\r\nif (error) {\r\nASSERT(bp == NULL);\r\nreturn error;\r\n}\r\n}\r\nASSERT(xfs_buf_islocked(bp));\r\n*O_bpp = bp;\r\n*O_ddpp = bp->b_addr + dqp->q_bufoffset;\r\nreturn 0;\r\n}\r\nint\r\nxfs_qm_dqread(\r\nstruct xfs_mount *mp,\r\nxfs_dqid_t id,\r\nuint type,\r\nuint flags,\r\nstruct xfs_dquot **O_dqpp)\r\n{\r\nstruct xfs_dquot *dqp;\r\nstruct xfs_disk_dquot *ddqp;\r\nstruct xfs_buf *bp;\r\nstruct xfs_trans *tp = NULL;\r\nint error;\r\ndqp = kmem_zone_zalloc(xfs_qm_dqzone, KM_SLEEP);\r\ndqp->dq_flags = type;\r\ndqp->q_core.d_id = cpu_to_be32(id);\r\ndqp->q_mount = mp;\r\nINIT_LIST_HEAD(&dqp->q_lru);\r\nmutex_init(&dqp->q_qlock);\r\ninit_waitqueue_head(&dqp->q_pinwait);\r\ninit_completion(&dqp->q_flush);\r\ncomplete(&dqp->q_flush);\r\nswitch (type) {\r\ncase XFS_DQ_USER:\r\nbreak;\r\ncase XFS_DQ_GROUP:\r\nlockdep_set_class(&dqp->q_qlock, &xfs_dquot_group_class);\r\nbreak;\r\ncase XFS_DQ_PROJ:\r\nlockdep_set_class(&dqp->q_qlock, &xfs_dquot_project_class);\r\nbreak;\r\ndefault:\r\nASSERT(0);\r\nbreak;\r\n}\r\nXFS_STATS_INC(mp, xs_qm_dquot);\r\ntrace_xfs_dqread(dqp);\r\nif (flags & XFS_QMOPT_DQALLOC) {\r\nerror = xfs_trans_alloc(mp, &M_RES(mp)->tr_qm_dqalloc,\r\nXFS_QM_DQALLOC_SPACE_RES(mp), 0, 0, &tp);\r\nif (error)\r\ngoto error0;\r\n}\r\nerror = xfs_qm_dqtobp(&tp, dqp, &ddqp, &bp, flags);\r\nif (error) {\r\ntrace_xfs_dqread_fail(dqp);\r\ngoto error1;\r\n}\r\nmemcpy(&dqp->q_core, ddqp, sizeof(xfs_disk_dquot_t));\r\nxfs_qm_dquot_logitem_init(dqp);\r\ndqp->q_res_bcount = be64_to_cpu(ddqp->d_bcount);\r\ndqp->q_res_icount = be64_to_cpu(ddqp->d_icount);\r\ndqp->q_res_rtbcount = be64_to_cpu(ddqp->d_rtbcount);\r\nxfs_dquot_set_prealloc_limits(dqp);\r\nxfs_buf_set_ref(bp, XFS_DQUOT_REF);\r\nASSERT(xfs_buf_islocked(bp));\r\nxfs_trans_brelse(tp, bp);\r\nif (tp) {\r\nerror = xfs_trans_commit(tp);\r\nif (error)\r\ngoto error0;\r\n}\r\n*O_dqpp = dqp;\r\nreturn error;\r\nerror1:\r\nif (tp)\r\nxfs_trans_cancel(tp);\r\nerror0:\r\nxfs_qm_dqdestroy(dqp);\r\n*O_dqpp = NULL;\r\nreturn error;\r\n}\r\nstatic int\r\nxfs_dq_get_next_id(\r\nxfs_mount_t *mp,\r\nuint type,\r\nxfs_dqid_t *id,\r\nloff_t eof)\r\n{\r\nstruct xfs_inode *quotip;\r\nxfs_fsblock_t start;\r\nloff_t offset;\r\nuint lock;\r\nxfs_dqid_t next_id;\r\nint error = 0;\r\nnext_id = *id + 1;\r\nif (next_id % mp->m_quotainfo->qi_dqperchunk) {\r\n*id = next_id;\r\nreturn 0;\r\n}\r\nstart = (xfs_fsblock_t)next_id / mp->m_quotainfo->qi_dqperchunk;\r\nquotip = xfs_quota_inode(mp, type);\r\nlock = xfs_ilock_data_map_shared(quotip);\r\noffset = __xfs_seek_hole_data(VFS_I(quotip), XFS_FSB_TO_B(mp, start),\r\neof, SEEK_DATA);\r\nif (offset < 0)\r\nerror = offset;\r\nxfs_iunlock(quotip, lock);\r\nif (error)\r\nreturn (error == -ENXIO ? -ENOENT: error);\r\n*id = XFS_B_TO_FSB(mp, offset) * mp->m_quotainfo->qi_dqperchunk;\r\nreturn 0;\r\n}\r\nint\r\nxfs_qm_dqget(\r\nxfs_mount_t *mp,\r\nxfs_inode_t *ip,\r\nxfs_dqid_t id,\r\nuint type,\r\nuint flags,\r\nxfs_dquot_t **O_dqpp)\r\n{\r\nstruct xfs_quotainfo *qi = mp->m_quotainfo;\r\nstruct radix_tree_root *tree = xfs_dquot_tree(qi, type);\r\nstruct xfs_dquot *dqp;\r\nloff_t eof = 0;\r\nint error;\r\nASSERT(XFS_IS_QUOTA_RUNNING(mp));\r\nif ((! XFS_IS_UQUOTA_ON(mp) && type == XFS_DQ_USER) ||\r\n(! XFS_IS_PQUOTA_ON(mp) && type == XFS_DQ_PROJ) ||\r\n(! XFS_IS_GQUOTA_ON(mp) && type == XFS_DQ_GROUP)) {\r\nreturn -ESRCH;\r\n}\r\n#ifdef DEBUG\r\nif (xfs_do_dqerror) {\r\nif ((xfs_dqerror_target == mp->m_ddev_targp) &&\r\n(xfs_dqreq_num++ % xfs_dqerror_mod) == 0) {\r\nxfs_debug(mp, "Returning error in dqget");\r\nreturn -EIO;\r\n}\r\n}\r\nASSERT(type == XFS_DQ_USER ||\r\ntype == XFS_DQ_PROJ ||\r\ntype == XFS_DQ_GROUP);\r\nif (ip) {\r\nASSERT(xfs_isilocked(ip, XFS_ILOCK_EXCL));\r\nASSERT(xfs_inode_dquot(ip, type) == NULL);\r\n}\r\n#endif\r\nif (flags & XFS_QMOPT_DQNEXT) {\r\nstruct xfs_inode *quotip;\r\nxfs_fileoff_t last;\r\nuint lock_mode;\r\nquotip = xfs_quota_inode(mp, type);\r\nlock_mode = xfs_ilock_data_map_shared(quotip);\r\nerror = xfs_bmap_last_offset(quotip, &last, XFS_DATA_FORK);\r\nxfs_iunlock(quotip, lock_mode);\r\nif (error)\r\nreturn error;\r\neof = XFS_FSB_TO_B(mp, last);\r\n}\r\nrestart:\r\nmutex_lock(&qi->qi_tree_lock);\r\ndqp = radix_tree_lookup(tree, id);\r\nif (dqp) {\r\nxfs_dqlock(dqp);\r\nif (dqp->dq_flags & XFS_DQ_FREEING) {\r\nxfs_dqunlock(dqp);\r\nmutex_unlock(&qi->qi_tree_lock);\r\ntrace_xfs_dqget_freeing(dqp);\r\ndelay(1);\r\ngoto restart;\r\n}\r\nif (flags & XFS_QMOPT_DQNEXT) {\r\nif (XFS_IS_DQUOT_UNINITIALIZED(dqp)) {\r\nxfs_dqunlock(dqp);\r\nmutex_unlock(&qi->qi_tree_lock);\r\nerror = xfs_dq_get_next_id(mp, type, &id, eof);\r\nif (error)\r\nreturn error;\r\ngoto restart;\r\n}\r\n}\r\ndqp->q_nrefs++;\r\nmutex_unlock(&qi->qi_tree_lock);\r\ntrace_xfs_dqget_hit(dqp);\r\nXFS_STATS_INC(mp, xs_qm_dqcachehits);\r\n*O_dqpp = dqp;\r\nreturn 0;\r\n}\r\nmutex_unlock(&qi->qi_tree_lock);\r\nXFS_STATS_INC(mp, xs_qm_dqcachemisses);\r\nif (ip)\r\nxfs_iunlock(ip, XFS_ILOCK_EXCL);\r\nerror = xfs_qm_dqread(mp, id, type, flags, &dqp);\r\nif (ip)\r\nxfs_ilock(ip, XFS_ILOCK_EXCL);\r\nif (error == -ENOENT && (flags & XFS_QMOPT_DQNEXT)) {\r\nerror = xfs_dq_get_next_id(mp, type, &id, eof);\r\nif (!error)\r\ngoto restart;\r\n}\r\nif (error)\r\nreturn error;\r\nif (ip) {\r\nif (xfs_this_quota_on(mp, type)) {\r\nstruct xfs_dquot *dqp1;\r\ndqp1 = xfs_inode_dquot(ip, type);\r\nif (dqp1) {\r\nxfs_qm_dqdestroy(dqp);\r\ndqp = dqp1;\r\nxfs_dqlock(dqp);\r\ngoto dqret;\r\n}\r\n} else {\r\nxfs_qm_dqdestroy(dqp);\r\nreturn -ESRCH;\r\n}\r\n}\r\nmutex_lock(&qi->qi_tree_lock);\r\nerror = radix_tree_insert(tree, id, dqp);\r\nif (unlikely(error)) {\r\nWARN_ON(error != -EEXIST);\r\nmutex_unlock(&qi->qi_tree_lock);\r\ntrace_xfs_dqget_dup(dqp);\r\nxfs_qm_dqdestroy(dqp);\r\nXFS_STATS_INC(mp, xs_qm_dquot_dups);\r\ngoto restart;\r\n}\r\nxfs_dqlock(dqp);\r\ndqp->q_nrefs = 1;\r\nqi->qi_dquots++;\r\nmutex_unlock(&qi->qi_tree_lock);\r\nif (flags & XFS_QMOPT_DQNEXT) {\r\nif (XFS_IS_DQUOT_UNINITIALIZED(dqp)) {\r\nxfs_qm_dqput(dqp);\r\nerror = xfs_dq_get_next_id(mp, type, &id, eof);\r\nif (error)\r\nreturn error;\r\ngoto restart;\r\n}\r\n}\r\ndqret:\r\nASSERT((ip == NULL) || xfs_isilocked(ip, XFS_ILOCK_EXCL));\r\ntrace_xfs_dqget_miss(dqp);\r\n*O_dqpp = dqp;\r\nreturn 0;\r\n}\r\nvoid\r\nxfs_qm_dqput(\r\nstruct xfs_dquot *dqp)\r\n{\r\nASSERT(dqp->q_nrefs > 0);\r\nASSERT(XFS_DQ_IS_LOCKED(dqp));\r\ntrace_xfs_dqput(dqp);\r\nif (--dqp->q_nrefs == 0) {\r\nstruct xfs_quotainfo *qi = dqp->q_mount->m_quotainfo;\r\ntrace_xfs_dqput_free(dqp);\r\nif (list_lru_add(&qi->qi_lru, &dqp->q_lru))\r\nXFS_STATS_INC(dqp->q_mount, xs_qm_dquot_unused);\r\n}\r\nxfs_dqunlock(dqp);\r\n}\r\nvoid\r\nxfs_qm_dqrele(\r\nxfs_dquot_t *dqp)\r\n{\r\nif (!dqp)\r\nreturn;\r\ntrace_xfs_dqrele(dqp);\r\nxfs_dqlock(dqp);\r\nxfs_qm_dqput(dqp);\r\n}\r\nSTATIC void\r\nxfs_qm_dqflush_done(\r\nstruct xfs_buf *bp,\r\nstruct xfs_log_item *lip)\r\n{\r\nxfs_dq_logitem_t *qip = (struct xfs_dq_logitem *)lip;\r\nxfs_dquot_t *dqp = qip->qli_dquot;\r\nstruct xfs_ail *ailp = lip->li_ailp;\r\nif ((lip->li_flags & XFS_LI_IN_AIL) &&\r\nlip->li_lsn == qip->qli_flush_lsn) {\r\nspin_lock(&ailp->xa_lock);\r\nif (lip->li_lsn == qip->qli_flush_lsn)\r\nxfs_trans_ail_delete(ailp, lip, SHUTDOWN_CORRUPT_INCORE);\r\nelse\r\nspin_unlock(&ailp->xa_lock);\r\n}\r\nxfs_dqfunlock(dqp);\r\n}\r\nint\r\nxfs_qm_dqflush(\r\nstruct xfs_dquot *dqp,\r\nstruct xfs_buf **bpp)\r\n{\r\nstruct xfs_mount *mp = dqp->q_mount;\r\nstruct xfs_buf *bp;\r\nstruct xfs_disk_dquot *ddqp;\r\nint error;\r\nASSERT(XFS_DQ_IS_LOCKED(dqp));\r\nASSERT(!completion_done(&dqp->q_flush));\r\ntrace_xfs_dqflush(dqp);\r\n*bpp = NULL;\r\nxfs_qm_dqunpin_wait(dqp);\r\nif (XFS_FORCED_SHUTDOWN(mp)) {\r\nstruct xfs_log_item *lip = &dqp->q_logitem.qli_item;\r\ndqp->dq_flags &= ~XFS_DQ_DIRTY;\r\nxfs_trans_ail_remove(lip, SHUTDOWN_CORRUPT_INCORE);\r\nerror = -EIO;\r\ngoto out_unlock;\r\n}\r\nerror = xfs_trans_read_buf(mp, NULL, mp->m_ddev_targp, dqp->q_blkno,\r\nmp->m_quotainfo->qi_dqchunklen, 0, &bp,\r\n&xfs_dquot_buf_ops);\r\nif (error)\r\ngoto out_unlock;\r\nddqp = bp->b_addr + dqp->q_bufoffset;\r\nerror = xfs_dqcheck(mp, &dqp->q_core, be32_to_cpu(ddqp->d_id), 0,\r\nXFS_QMOPT_DOWARN, "dqflush (incore copy)");\r\nif (error) {\r\nxfs_buf_relse(bp);\r\nxfs_dqfunlock(dqp);\r\nxfs_force_shutdown(mp, SHUTDOWN_CORRUPT_INCORE);\r\nreturn -EIO;\r\n}\r\nmemcpy(ddqp, &dqp->q_core, sizeof(xfs_disk_dquot_t));\r\ndqp->dq_flags &= ~XFS_DQ_DIRTY;\r\nxfs_trans_ail_copy_lsn(mp->m_ail, &dqp->q_logitem.qli_flush_lsn,\r\n&dqp->q_logitem.qli_item.li_lsn);\r\nif (xfs_sb_version_hascrc(&mp->m_sb)) {\r\nstruct xfs_dqblk *dqb = (struct xfs_dqblk *)ddqp;\r\ndqb->dd_lsn = cpu_to_be64(dqp->q_logitem.qli_item.li_lsn);\r\nxfs_update_cksum((char *)dqb, sizeof(struct xfs_dqblk),\r\nXFS_DQUOT_CRC_OFF);\r\n}\r\nxfs_buf_attach_iodone(bp, xfs_qm_dqflush_done,\r\n&dqp->q_logitem.qli_item);\r\nif (xfs_buf_ispinned(bp)) {\r\ntrace_xfs_dqflush_force(dqp);\r\nxfs_log_force(mp, 0);\r\n}\r\ntrace_xfs_dqflush_done(dqp);\r\n*bpp = bp;\r\nreturn 0;\r\nout_unlock:\r\nxfs_dqfunlock(dqp);\r\nreturn -EIO;\r\n}\r\nvoid\r\nxfs_dqlock2(\r\nxfs_dquot_t *d1,\r\nxfs_dquot_t *d2)\r\n{\r\nif (d1 && d2) {\r\nASSERT(d1 != d2);\r\nif (be32_to_cpu(d1->q_core.d_id) >\r\nbe32_to_cpu(d2->q_core.d_id)) {\r\nmutex_lock(&d2->q_qlock);\r\nmutex_lock_nested(&d1->q_qlock, XFS_QLOCK_NESTED);\r\n} else {\r\nmutex_lock(&d1->q_qlock);\r\nmutex_lock_nested(&d2->q_qlock, XFS_QLOCK_NESTED);\r\n}\r\n} else if (d1) {\r\nmutex_lock(&d1->q_qlock);\r\n} else if (d2) {\r\nmutex_lock(&d2->q_qlock);\r\n}\r\n}\r\nint __init\r\nxfs_qm_init(void)\r\n{\r\nxfs_qm_dqzone =\r\nkmem_zone_init(sizeof(struct xfs_dquot), "xfs_dquot");\r\nif (!xfs_qm_dqzone)\r\ngoto out;\r\nxfs_qm_dqtrxzone =\r\nkmem_zone_init(sizeof(struct xfs_dquot_acct), "xfs_dqtrx");\r\nif (!xfs_qm_dqtrxzone)\r\ngoto out_free_dqzone;\r\nreturn 0;\r\nout_free_dqzone:\r\nkmem_zone_destroy(xfs_qm_dqzone);\r\nout:\r\nreturn -ENOMEM;\r\n}\r\nvoid\r\nxfs_qm_exit(void)\r\n{\r\nkmem_zone_destroy(xfs_qm_dqtrxzone);\r\nkmem_zone_destroy(xfs_qm_dqzone);\r\n}
