static void put_flow_table(struct mlx5e_ethtool_table *eth_ft)\r\n{\r\nif (!--eth_ft->num_rules) {\r\nmlx5_destroy_flow_table(eth_ft->ft);\r\neth_ft->ft = NULL;\r\n}\r\n}\r\nstatic struct mlx5e_ethtool_table *get_flow_table(struct mlx5e_priv *priv,\r\nstruct ethtool_rx_flow_spec *fs,\r\nint num_tuples)\r\n{\r\nstruct mlx5e_ethtool_table *eth_ft;\r\nstruct mlx5_flow_namespace *ns;\r\nstruct mlx5_flow_table *ft;\r\nint max_tuples;\r\nint table_size;\r\nint prio;\r\nswitch (fs->flow_type & ~(FLOW_EXT | FLOW_MAC_EXT)) {\r\ncase TCP_V4_FLOW:\r\ncase UDP_V4_FLOW:\r\nmax_tuples = ETHTOOL_NUM_L3_L4_FTS;\r\nprio = MLX5E_ETHTOOL_L3_L4_PRIO + (max_tuples - num_tuples);\r\neth_ft = &priv->fs.ethtool.l3_l4_ft[prio];\r\nbreak;\r\ncase IP_USER_FLOW:\r\nmax_tuples = ETHTOOL_NUM_L3_L4_FTS;\r\nprio = MLX5E_ETHTOOL_L3_L4_PRIO + (max_tuples - num_tuples);\r\neth_ft = &priv->fs.ethtool.l3_l4_ft[prio];\r\nbreak;\r\ncase ETHER_FLOW:\r\nmax_tuples = ETHTOOL_NUM_L2_FTS;\r\nprio = max_tuples - num_tuples;\r\neth_ft = &priv->fs.ethtool.l2_ft[prio];\r\nprio += MLX5E_ETHTOOL_L2_PRIO;\r\nbreak;\r\ndefault:\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\neth_ft->num_rules++;\r\nif (eth_ft->ft)\r\nreturn eth_ft;\r\nns = mlx5_get_flow_namespace(priv->mdev,\r\nMLX5_FLOW_NAMESPACE_ETHTOOL);\r\nif (!ns)\r\nreturn ERR_PTR(-ENOTSUPP);\r\ntable_size = min_t(u32, BIT(MLX5_CAP_FLOWTABLE(priv->mdev,\r\nflow_table_properties_nic_receive.log_max_ft_size)),\r\nMLX5E_ETHTOOL_NUM_ENTRIES);\r\nft = mlx5_create_auto_grouped_flow_table(ns, prio,\r\ntable_size,\r\nMLX5E_ETHTOOL_NUM_GROUPS, 0);\r\nif (IS_ERR(ft))\r\nreturn (void *)ft;\r\neth_ft->ft = ft;\r\nreturn eth_ft;\r\n}\r\nstatic void mask_spec(u8 *mask, u8 *val, size_t size)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < size; i++, mask++, val++)\r\n*((u8 *)val) = *((u8 *)mask) & *((u8 *)val);\r\n}\r\nstatic void set_ips(void *outer_headers_v, void *outer_headers_c, __be32 ip4src_m,\r\n__be32 ip4src_v, __be32 ip4dst_m, __be32 ip4dst_v)\r\n{\r\nif (ip4src_m) {\r\nmemcpy(MLX5_ADDR_OF(fte_match_set_lyr_2_4, outer_headers_v,\r\nsrc_ipv4_src_ipv6.ipv4_layout.ipv4),\r\n&ip4src_v, sizeof(ip4src_v));\r\nmemset(MLX5_ADDR_OF(fte_match_set_lyr_2_4, outer_headers_c,\r\nsrc_ipv4_src_ipv6.ipv4_layout.ipv4),\r\n0xff, sizeof(ip4src_m));\r\n}\r\nif (ip4dst_m) {\r\nmemcpy(MLX5_ADDR_OF(fte_match_set_lyr_2_4, outer_headers_v,\r\ndst_ipv4_dst_ipv6.ipv4_layout.ipv4),\r\n&ip4dst_v, sizeof(ip4dst_v));\r\nmemset(MLX5_ADDR_OF(fte_match_set_lyr_2_4, outer_headers_c,\r\ndst_ipv4_dst_ipv6.ipv4_layout.ipv4),\r\n0xff, sizeof(ip4dst_m));\r\n}\r\nMLX5_SET(fte_match_set_lyr_2_4, outer_headers_v,\r\nethertype, ETH_P_IP);\r\nMLX5_SET(fte_match_set_lyr_2_4, outer_headers_c,\r\nethertype, 0xffff);\r\n}\r\nstatic int set_flow_attrs(u32 *match_c, u32 *match_v,\r\nstruct ethtool_rx_flow_spec *fs)\r\n{\r\nvoid *outer_headers_c = MLX5_ADDR_OF(fte_match_param, match_c,\r\nouter_headers);\r\nvoid *outer_headers_v = MLX5_ADDR_OF(fte_match_param, match_v,\r\nouter_headers);\r\nu32 flow_type = fs->flow_type & ~(FLOW_EXT | FLOW_MAC_EXT);\r\nstruct ethtool_tcpip4_spec *l4_mask;\r\nstruct ethtool_tcpip4_spec *l4_val;\r\nstruct ethtool_usrip4_spec *l3_mask;\r\nstruct ethtool_usrip4_spec *l3_val;\r\nstruct ethhdr *eth_val;\r\nstruct ethhdr *eth_mask;\r\nswitch (flow_type) {\r\ncase TCP_V4_FLOW:\r\nl4_mask = &fs->m_u.tcp_ip4_spec;\r\nl4_val = &fs->h_u.tcp_ip4_spec;\r\nset_ips(outer_headers_v, outer_headers_c, l4_mask->ip4src,\r\nl4_val->ip4src, l4_mask->ip4dst, l4_val->ip4dst);\r\nif (l4_mask->psrc) {\r\nMLX5_SET(fte_match_set_lyr_2_4, outer_headers_c, tcp_sport,\r\n0xffff);\r\nMLX5_SET(fte_match_set_lyr_2_4, outer_headers_v, tcp_sport,\r\nntohs(l4_val->psrc));\r\n}\r\nif (l4_mask->pdst) {\r\nMLX5_SET(fte_match_set_lyr_2_4, outer_headers_c, tcp_dport,\r\n0xffff);\r\nMLX5_SET(fte_match_set_lyr_2_4, outer_headers_v, tcp_dport,\r\nntohs(l4_val->pdst));\r\n}\r\nMLX5_SET(fte_match_set_lyr_2_4, outer_headers_c, ip_protocol,\r\n0xffff);\r\nMLX5_SET(fte_match_set_lyr_2_4, outer_headers_v, ip_protocol,\r\nIPPROTO_TCP);\r\nbreak;\r\ncase UDP_V4_FLOW:\r\nl4_mask = &fs->m_u.tcp_ip4_spec;\r\nl4_val = &fs->h_u.tcp_ip4_spec;\r\nset_ips(outer_headers_v, outer_headers_c, l4_mask->ip4src,\r\nl4_val->ip4src, l4_mask->ip4dst, l4_val->ip4dst);\r\nif (l4_mask->psrc) {\r\nMLX5_SET(fte_match_set_lyr_2_4, outer_headers_c, udp_sport,\r\n0xffff);\r\nMLX5_SET(fte_match_set_lyr_2_4, outer_headers_v, udp_sport,\r\nntohs(l4_val->psrc));\r\n}\r\nif (l4_mask->pdst) {\r\nMLX5_SET(fte_match_set_lyr_2_4, outer_headers_c, udp_dport,\r\n0xffff);\r\nMLX5_SET(fte_match_set_lyr_2_4, outer_headers_v, udp_dport,\r\nntohs(l4_val->pdst));\r\n}\r\nMLX5_SET(fte_match_set_lyr_2_4, outer_headers_c, ip_protocol,\r\n0xffff);\r\nMLX5_SET(fte_match_set_lyr_2_4, outer_headers_v, ip_protocol,\r\nIPPROTO_UDP);\r\nbreak;\r\ncase IP_USER_FLOW:\r\nl3_mask = &fs->m_u.usr_ip4_spec;\r\nl3_val = &fs->h_u.usr_ip4_spec;\r\nset_ips(outer_headers_v, outer_headers_c, l3_mask->ip4src,\r\nl3_val->ip4src, l3_mask->ip4dst, l3_val->ip4dst);\r\nbreak;\r\ncase ETHER_FLOW:\r\neth_mask = &fs->m_u.ether_spec;\r\neth_val = &fs->h_u.ether_spec;\r\nmask_spec((u8 *)eth_mask, (u8 *)eth_val, sizeof(*eth_mask));\r\nether_addr_copy(MLX5_ADDR_OF(fte_match_set_lyr_2_4,\r\nouter_headers_c, smac_47_16),\r\neth_mask->h_source);\r\nether_addr_copy(MLX5_ADDR_OF(fte_match_set_lyr_2_4,\r\nouter_headers_v, smac_47_16),\r\neth_val->h_source);\r\nether_addr_copy(MLX5_ADDR_OF(fte_match_set_lyr_2_4,\r\nouter_headers_c, dmac_47_16),\r\neth_mask->h_dest);\r\nether_addr_copy(MLX5_ADDR_OF(fte_match_set_lyr_2_4,\r\nouter_headers_v, dmac_47_16),\r\neth_val->h_dest);\r\nMLX5_SET(fte_match_set_lyr_2_4, outer_headers_c, ethertype,\r\nntohs(eth_mask->h_proto));\r\nMLX5_SET(fte_match_set_lyr_2_4, outer_headers_v, ethertype,\r\nntohs(eth_val->h_proto));\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nif ((fs->flow_type & FLOW_EXT) &&\r\n(fs->m_ext.vlan_tci & cpu_to_be16(VLAN_VID_MASK))) {\r\nMLX5_SET(fte_match_set_lyr_2_4, outer_headers_c,\r\nvlan_tag, 1);\r\nMLX5_SET(fte_match_set_lyr_2_4, outer_headers_v,\r\nvlan_tag, 1);\r\nMLX5_SET(fte_match_set_lyr_2_4, outer_headers_c,\r\nfirst_vid, 0xfff);\r\nMLX5_SET(fte_match_set_lyr_2_4, outer_headers_v,\r\nfirst_vid, ntohs(fs->h_ext.vlan_tci));\r\n}\r\nif (fs->flow_type & FLOW_MAC_EXT &&\r\n!is_zero_ether_addr(fs->m_ext.h_dest)) {\r\nether_addr_copy(MLX5_ADDR_OF(fte_match_set_lyr_2_4,\r\nouter_headers_c, dmac_47_16),\r\nfs->m_ext.h_dest);\r\nether_addr_copy(MLX5_ADDR_OF(fte_match_set_lyr_2_4,\r\nouter_headers_v, dmac_47_16),\r\nfs->h_ext.h_dest);\r\n}\r\nreturn 0;\r\n}\r\nstatic void add_rule_to_list(struct mlx5e_priv *priv,\r\nstruct mlx5e_ethtool_rule *rule)\r\n{\r\nstruct mlx5e_ethtool_rule *iter;\r\nstruct list_head *head = &priv->fs.ethtool.rules;\r\nlist_for_each_entry(iter, &priv->fs.ethtool.rules, list) {\r\nif (iter->flow_spec.location > rule->flow_spec.location)\r\nbreak;\r\nhead = &iter->list;\r\n}\r\npriv->fs.ethtool.tot_num_rules++;\r\nlist_add(&rule->list, head);\r\n}\r\nstatic bool outer_header_zero(u32 *match_criteria)\r\n{\r\nint size = MLX5_ST_SZ_BYTES(fte_match_param);\r\nchar *outer_headers_c = MLX5_ADDR_OF(fte_match_param, match_criteria,\r\nouter_headers);\r\nreturn outer_headers_c[0] == 0 && !memcmp(outer_headers_c,\r\nouter_headers_c + 1,\r\nsize - 1);\r\n}\r\nstatic struct mlx5_flow_rule *add_ethtool_flow_rule(struct mlx5e_priv *priv,\r\nstruct mlx5_flow_table *ft,\r\nstruct ethtool_rx_flow_spec *fs)\r\n{\r\nstruct mlx5_flow_destination *dst = NULL;\r\nstruct mlx5_flow_spec *spec;\r\nstruct mlx5_flow_rule *rule;\r\nint err = 0;\r\nu32 action;\r\nspec = mlx5_vzalloc(sizeof(*spec));\r\nif (!spec)\r\nreturn ERR_PTR(-ENOMEM);\r\nerr = set_flow_attrs(spec->match_criteria, spec->match_value,\r\nfs);\r\nif (err)\r\ngoto free;\r\nif (fs->ring_cookie == RX_CLS_FLOW_DISC) {\r\naction = MLX5_FLOW_CONTEXT_ACTION_DROP;\r\n} else {\r\ndst = kzalloc(sizeof(*dst), GFP_KERNEL);\r\nif (!dst) {\r\nerr = -ENOMEM;\r\ngoto free;\r\n}\r\ndst->type = MLX5_FLOW_DESTINATION_TYPE_TIR;\r\ndst->tir_num = priv->direct_tir[fs->ring_cookie].tirn;\r\naction = MLX5_FLOW_CONTEXT_ACTION_FWD_DEST;\r\n}\r\nspec->match_criteria_enable = (!outer_header_zero(spec->match_criteria));\r\nrule = mlx5_add_flow_rule(ft, spec, action,\r\nMLX5_FS_DEFAULT_FLOW_TAG, dst);\r\nif (IS_ERR(rule)) {\r\nerr = PTR_ERR(rule);\r\nnetdev_err(priv->netdev, "%s: failed to add ethtool steering rule: %d\n",\r\n__func__, err);\r\ngoto free;\r\n}\r\nfree:\r\nkvfree(spec);\r\nkfree(dst);\r\nreturn err ? ERR_PTR(err) : rule;\r\n}\r\nstatic void del_ethtool_rule(struct mlx5e_priv *priv,\r\nstruct mlx5e_ethtool_rule *eth_rule)\r\n{\r\nif (eth_rule->rule)\r\nmlx5_del_flow_rule(eth_rule->rule);\r\nlist_del(&eth_rule->list);\r\npriv->fs.ethtool.tot_num_rules--;\r\nput_flow_table(eth_rule->eth_ft);\r\nkfree(eth_rule);\r\n}\r\nstatic struct mlx5e_ethtool_rule *find_ethtool_rule(struct mlx5e_priv *priv,\r\nint location)\r\n{\r\nstruct mlx5e_ethtool_rule *iter;\r\nlist_for_each_entry(iter, &priv->fs.ethtool.rules, list) {\r\nif (iter->flow_spec.location == location)\r\nreturn iter;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct mlx5e_ethtool_rule *get_ethtool_rule(struct mlx5e_priv *priv,\r\nint location)\r\n{\r\nstruct mlx5e_ethtool_rule *eth_rule;\r\neth_rule = find_ethtool_rule(priv, location);\r\nif (eth_rule)\r\ndel_ethtool_rule(priv, eth_rule);\r\neth_rule = kzalloc(sizeof(*eth_rule), GFP_KERNEL);\r\nif (!eth_rule)\r\nreturn ERR_PTR(-ENOMEM);\r\nadd_rule_to_list(priv, eth_rule);\r\nreturn eth_rule;\r\n}\r\nstatic int validate_flow(struct mlx5e_priv *priv,\r\nstruct ethtool_rx_flow_spec *fs)\r\n{\r\nstruct ethtool_tcpip4_spec *l4_mask;\r\nstruct ethtool_usrip4_spec *l3_mask;\r\nstruct ethhdr *eth_mask;\r\nint num_tuples = 0;\r\nif (fs->location >= MAX_NUM_OF_ETHTOOL_RULES)\r\nreturn -EINVAL;\r\nif (fs->ring_cookie >= priv->params.num_channels &&\r\nfs->ring_cookie != RX_CLS_FLOW_DISC)\r\nreturn -EINVAL;\r\nswitch (fs->flow_type & ~(FLOW_EXT | FLOW_MAC_EXT)) {\r\ncase ETHER_FLOW:\r\neth_mask = &fs->m_u.ether_spec;\r\nif (!is_zero_ether_addr(eth_mask->h_dest))\r\nnum_tuples++;\r\nif (!is_zero_ether_addr(eth_mask->h_source))\r\nnum_tuples++;\r\nif (eth_mask->h_proto)\r\nnum_tuples++;\r\nbreak;\r\ncase TCP_V4_FLOW:\r\ncase UDP_V4_FLOW:\r\nif (fs->m_u.tcp_ip4_spec.tos)\r\nreturn -EINVAL;\r\nl4_mask = &fs->m_u.tcp_ip4_spec;\r\nif (l4_mask->ip4src) {\r\nif (!all_ones(l4_mask->ip4src))\r\nreturn -EINVAL;\r\nnum_tuples++;\r\n}\r\nif (l4_mask->ip4dst) {\r\nif (!all_ones(l4_mask->ip4dst))\r\nreturn -EINVAL;\r\nnum_tuples++;\r\n}\r\nif (l4_mask->psrc) {\r\nif (!all_ones(l4_mask->psrc))\r\nreturn -EINVAL;\r\nnum_tuples++;\r\n}\r\nif (l4_mask->pdst) {\r\nif (!all_ones(l4_mask->pdst))\r\nreturn -EINVAL;\r\nnum_tuples++;\r\n}\r\nnum_tuples++;\r\nbreak;\r\ncase IP_USER_FLOW:\r\nl3_mask = &fs->m_u.usr_ip4_spec;\r\nif (l3_mask->l4_4_bytes || l3_mask->tos || l3_mask->proto ||\r\nfs->h_u.usr_ip4_spec.ip_ver != ETH_RX_NFC_IP4)\r\nreturn -EINVAL;\r\nif (l3_mask->ip4src) {\r\nif (!all_ones(l3_mask->ip4src))\r\nreturn -EINVAL;\r\nnum_tuples++;\r\n}\r\nif (l3_mask->ip4dst) {\r\nif (!all_ones(l3_mask->ip4dst))\r\nreturn -EINVAL;\r\nnum_tuples++;\r\n}\r\nnum_tuples++;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nif ((fs->flow_type & FLOW_EXT)) {\r\nif (fs->m_ext.vlan_etype ||\r\n(fs->m_ext.vlan_tci != cpu_to_be16(VLAN_VID_MASK)))\r\nreturn -EINVAL;\r\nif (fs->m_ext.vlan_tci) {\r\nif (be16_to_cpu(fs->h_ext.vlan_tci) >= VLAN_N_VID)\r\nreturn -EINVAL;\r\n}\r\nnum_tuples++;\r\n}\r\nif (fs->flow_type & FLOW_MAC_EXT &&\r\n!is_zero_ether_addr(fs->m_ext.h_dest))\r\nnum_tuples++;\r\nreturn num_tuples;\r\n}\r\nint mlx5e_ethtool_flow_replace(struct mlx5e_priv *priv,\r\nstruct ethtool_rx_flow_spec *fs)\r\n{\r\nstruct mlx5e_ethtool_table *eth_ft;\r\nstruct mlx5e_ethtool_rule *eth_rule;\r\nstruct mlx5_flow_rule *rule;\r\nint num_tuples;\r\nint err;\r\nnum_tuples = validate_flow(priv, fs);\r\nif (num_tuples <= 0) {\r\nnetdev_warn(priv->netdev, "%s: flow is not valid\n", __func__);\r\nreturn -EINVAL;\r\n}\r\neth_ft = get_flow_table(priv, fs, num_tuples);\r\nif (IS_ERR(eth_ft))\r\nreturn PTR_ERR(eth_ft);\r\neth_rule = get_ethtool_rule(priv, fs->location);\r\nif (IS_ERR(eth_rule)) {\r\nput_flow_table(eth_ft);\r\nreturn PTR_ERR(eth_rule);\r\n}\r\neth_rule->flow_spec = *fs;\r\neth_rule->eth_ft = eth_ft;\r\nif (!eth_ft->ft) {\r\nerr = -EINVAL;\r\ngoto del_ethtool_rule;\r\n}\r\nrule = add_ethtool_flow_rule(priv, eth_ft->ft, fs);\r\nif (IS_ERR(rule)) {\r\nerr = PTR_ERR(rule);\r\ngoto del_ethtool_rule;\r\n}\r\neth_rule->rule = rule;\r\nreturn 0;\r\ndel_ethtool_rule:\r\ndel_ethtool_rule(priv, eth_rule);\r\nreturn err;\r\n}\r\nint mlx5e_ethtool_flow_remove(struct mlx5e_priv *priv,\r\nint location)\r\n{\r\nstruct mlx5e_ethtool_rule *eth_rule;\r\nint err = 0;\r\nif (location >= MAX_NUM_OF_ETHTOOL_RULES)\r\nreturn -ENOSPC;\r\neth_rule = find_ethtool_rule(priv, location);\r\nif (!eth_rule) {\r\nerr = -ENOENT;\r\ngoto out;\r\n}\r\ndel_ethtool_rule(priv, eth_rule);\r\nout:\r\nreturn err;\r\n}\r\nint mlx5e_ethtool_get_flow(struct mlx5e_priv *priv, struct ethtool_rxnfc *info,\r\nint location)\r\n{\r\nstruct mlx5e_ethtool_rule *eth_rule;\r\nif (location < 0 || location >= MAX_NUM_OF_ETHTOOL_RULES)\r\nreturn -EINVAL;\r\nlist_for_each_entry(eth_rule, &priv->fs.ethtool.rules, list) {\r\nif (eth_rule->flow_spec.location == location) {\r\ninfo->fs = eth_rule->flow_spec;\r\nreturn 0;\r\n}\r\n}\r\nreturn -ENOENT;\r\n}\r\nint mlx5e_ethtool_get_all_flows(struct mlx5e_priv *priv, struct ethtool_rxnfc *info,\r\nu32 *rule_locs)\r\n{\r\nint location = 0;\r\nint idx = 0;\r\nint err = 0;\r\nwhile ((!err || err == -ENOENT) && idx < info->rule_cnt) {\r\nerr = mlx5e_ethtool_get_flow(priv, info, location);\r\nif (!err)\r\nrule_locs[idx++] = location;\r\nlocation++;\r\n}\r\nreturn err;\r\n}\r\nvoid mlx5e_ethtool_cleanup_steering(struct mlx5e_priv *priv)\r\n{\r\nstruct mlx5e_ethtool_rule *iter;\r\nstruct mlx5e_ethtool_rule *temp;\r\nlist_for_each_entry_safe(iter, temp, &priv->fs.ethtool.rules, list)\r\ndel_ethtool_rule(priv, iter);\r\n}\r\nvoid mlx5e_ethtool_init_steering(struct mlx5e_priv *priv)\r\n{\r\nINIT_LIST_HEAD(&priv->fs.ethtool.rules);\r\n}
