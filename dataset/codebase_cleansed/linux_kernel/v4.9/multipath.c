static int multipath_map (struct mpconf *conf)\r\n{\r\nint i, disks = conf->raid_disks;\r\nrcu_read_lock();\r\nfor (i = 0; i < disks; i++) {\r\nstruct md_rdev *rdev = rcu_dereference(conf->multipaths[i].rdev);\r\nif (rdev && test_bit(In_sync, &rdev->flags) &&\r\n!test_bit(Faulty, &rdev->flags)) {\r\natomic_inc(&rdev->nr_pending);\r\nrcu_read_unlock();\r\nreturn i;\r\n}\r\n}\r\nrcu_read_unlock();\r\nprintk(KERN_ERR "multipath_map(): no more operational IO paths?\n");\r\nreturn (-1);\r\n}\r\nstatic void multipath_reschedule_retry (struct multipath_bh *mp_bh)\r\n{\r\nunsigned long flags;\r\nstruct mddev *mddev = mp_bh->mddev;\r\nstruct mpconf *conf = mddev->private;\r\nspin_lock_irqsave(&conf->device_lock, flags);\r\nlist_add(&mp_bh->retry_list, &conf->retry_list);\r\nspin_unlock_irqrestore(&conf->device_lock, flags);\r\nmd_wakeup_thread(mddev->thread);\r\n}\r\nstatic void multipath_end_bh_io (struct multipath_bh *mp_bh, int err)\r\n{\r\nstruct bio *bio = mp_bh->master_bio;\r\nstruct mpconf *conf = mp_bh->mddev->private;\r\nbio->bi_error = err;\r\nbio_endio(bio);\r\nmempool_free(mp_bh, conf->pool);\r\n}\r\nstatic void multipath_end_request(struct bio *bio)\r\n{\r\nstruct multipath_bh *mp_bh = bio->bi_private;\r\nstruct mpconf *conf = mp_bh->mddev->private;\r\nstruct md_rdev *rdev = conf->multipaths[mp_bh->path].rdev;\r\nif (!bio->bi_error)\r\nmultipath_end_bh_io(mp_bh, 0);\r\nelse if (!(bio->bi_opf & REQ_RAHEAD)) {\r\nchar b[BDEVNAME_SIZE];\r\nmd_error (mp_bh->mddev, rdev);\r\nprintk(KERN_ERR "multipath: %s: rescheduling sector %llu\n",\r\nbdevname(rdev->bdev,b),\r\n(unsigned long long)bio->bi_iter.bi_sector);\r\nmultipath_reschedule_retry(mp_bh);\r\n} else\r\nmultipath_end_bh_io(mp_bh, bio->bi_error);\r\nrdev_dec_pending(rdev, conf->mddev);\r\n}\r\nstatic void multipath_make_request(struct mddev *mddev, struct bio * bio)\r\n{\r\nstruct mpconf *conf = mddev->private;\r\nstruct multipath_bh * mp_bh;\r\nstruct multipath_info *multipath;\r\nif (unlikely(bio->bi_opf & REQ_PREFLUSH)) {\r\nmd_flush_request(mddev, bio);\r\nreturn;\r\n}\r\nmp_bh = mempool_alloc(conf->pool, GFP_NOIO);\r\nmp_bh->master_bio = bio;\r\nmp_bh->mddev = mddev;\r\nmp_bh->path = multipath_map(conf);\r\nif (mp_bh->path < 0) {\r\nbio_io_error(bio);\r\nmempool_free(mp_bh, conf->pool);\r\nreturn;\r\n}\r\nmultipath = conf->multipaths + mp_bh->path;\r\nbio_init(&mp_bh->bio);\r\n__bio_clone_fast(&mp_bh->bio, bio);\r\nmp_bh->bio.bi_iter.bi_sector += multipath->rdev->data_offset;\r\nmp_bh->bio.bi_bdev = multipath->rdev->bdev;\r\nmp_bh->bio.bi_opf |= REQ_FAILFAST_TRANSPORT;\r\nmp_bh->bio.bi_end_io = multipath_end_request;\r\nmp_bh->bio.bi_private = mp_bh;\r\ngeneric_make_request(&mp_bh->bio);\r\nreturn;\r\n}\r\nstatic void multipath_status(struct seq_file *seq, struct mddev *mddev)\r\n{\r\nstruct mpconf *conf = mddev->private;\r\nint i;\r\nseq_printf (seq, " [%d/%d] [", conf->raid_disks,\r\nconf->raid_disks - mddev->degraded);\r\nrcu_read_lock();\r\nfor (i = 0; i < conf->raid_disks; i++) {\r\nstruct md_rdev *rdev = rcu_dereference(conf->multipaths[i].rdev);\r\nseq_printf (seq, "%s", rdev && test_bit(In_sync, &rdev->flags) ? "U" : "_");\r\n}\r\nrcu_read_unlock();\r\nseq_printf (seq, "]");\r\n}\r\nstatic int multipath_congested(struct mddev *mddev, int bits)\r\n{\r\nstruct mpconf *conf = mddev->private;\r\nint i, ret = 0;\r\nrcu_read_lock();\r\nfor (i = 0; i < mddev->raid_disks ; i++) {\r\nstruct md_rdev *rdev = rcu_dereference(conf->multipaths[i].rdev);\r\nif (rdev && !test_bit(Faulty, &rdev->flags)) {\r\nstruct request_queue *q = bdev_get_queue(rdev->bdev);\r\nret |= bdi_congested(&q->backing_dev_info, bits);\r\nbreak;\r\n}\r\n}\r\nrcu_read_unlock();\r\nreturn ret;\r\n}\r\nstatic void multipath_error (struct mddev *mddev, struct md_rdev *rdev)\r\n{\r\nstruct mpconf *conf = mddev->private;\r\nchar b[BDEVNAME_SIZE];\r\nif (conf->raid_disks - mddev->degraded <= 1) {\r\nprintk(KERN_ALERT\r\n"multipath: only one IO path left and IO error.\n");\r\nreturn;\r\n}\r\nif (test_and_clear_bit(In_sync, &rdev->flags)) {\r\nunsigned long flags;\r\nspin_lock_irqsave(&conf->device_lock, flags);\r\nmddev->degraded++;\r\nspin_unlock_irqrestore(&conf->device_lock, flags);\r\n}\r\nset_bit(Faulty, &rdev->flags);\r\nset_bit(MD_CHANGE_DEVS, &mddev->flags);\r\nprintk(KERN_ALERT "multipath: IO failure on %s,"\r\n" disabling IO path.\n"\r\n"multipath: Operation continuing"\r\n" on %d IO paths.\n",\r\nbdevname(rdev->bdev, b),\r\nconf->raid_disks - mddev->degraded);\r\n}\r\nstatic void print_multipath_conf (struct mpconf *conf)\r\n{\r\nint i;\r\nstruct multipath_info *tmp;\r\nprintk("MULTIPATH conf printout:\n");\r\nif (!conf) {\r\nprintk("(conf==NULL)\n");\r\nreturn;\r\n}\r\nprintk(" --- wd:%d rd:%d\n", conf->raid_disks - conf->mddev->degraded,\r\nconf->raid_disks);\r\nfor (i = 0; i < conf->raid_disks; i++) {\r\nchar b[BDEVNAME_SIZE];\r\ntmp = conf->multipaths + i;\r\nif (tmp->rdev)\r\nprintk(" disk%d, o:%d, dev:%s\n",\r\ni,!test_bit(Faulty, &tmp->rdev->flags),\r\nbdevname(tmp->rdev->bdev,b));\r\n}\r\n}\r\nstatic int multipath_add_disk(struct mddev *mddev, struct md_rdev *rdev)\r\n{\r\nstruct mpconf *conf = mddev->private;\r\nstruct request_queue *q;\r\nint err = -EEXIST;\r\nint path;\r\nstruct multipath_info *p;\r\nint first = 0;\r\nint last = mddev->raid_disks - 1;\r\nif (rdev->raid_disk >= 0)\r\nfirst = last = rdev->raid_disk;\r\nprint_multipath_conf(conf);\r\nfor (path = first; path <= last; path++)\r\nif ((p=conf->multipaths+path)->rdev == NULL) {\r\nq = rdev->bdev->bd_disk->queue;\r\ndisk_stack_limits(mddev->gendisk, rdev->bdev,\r\nrdev->data_offset << 9);\r\nerr = md_integrity_add_rdev(rdev, mddev);\r\nif (err)\r\nbreak;\r\nspin_lock_irq(&conf->device_lock);\r\nmddev->degraded--;\r\nrdev->raid_disk = path;\r\nset_bit(In_sync, &rdev->flags);\r\nspin_unlock_irq(&conf->device_lock);\r\nrcu_assign_pointer(p->rdev, rdev);\r\nerr = 0;\r\nbreak;\r\n}\r\nprint_multipath_conf(conf);\r\nreturn err;\r\n}\r\nstatic int multipath_remove_disk(struct mddev *mddev, struct md_rdev *rdev)\r\n{\r\nstruct mpconf *conf = mddev->private;\r\nint err = 0;\r\nint number = rdev->raid_disk;\r\nstruct multipath_info *p = conf->multipaths + number;\r\nprint_multipath_conf(conf);\r\nif (rdev == p->rdev) {\r\nif (test_bit(In_sync, &rdev->flags) ||\r\natomic_read(&rdev->nr_pending)) {\r\nprintk(KERN_ERR "hot-remove-disk, slot %d is identified"\r\n" but is still operational!\n", number);\r\nerr = -EBUSY;\r\ngoto abort;\r\n}\r\np->rdev = NULL;\r\nif (!test_bit(RemoveSynchronized, &rdev->flags)) {\r\nsynchronize_rcu();\r\nif (atomic_read(&rdev->nr_pending)) {\r\nerr = -EBUSY;\r\np->rdev = rdev;\r\ngoto abort;\r\n}\r\n}\r\nerr = md_integrity_register(mddev);\r\n}\r\nabort:\r\nprint_multipath_conf(conf);\r\nreturn err;\r\n}\r\nstatic void multipathd(struct md_thread *thread)\r\n{\r\nstruct mddev *mddev = thread->mddev;\r\nstruct multipath_bh *mp_bh;\r\nstruct bio *bio;\r\nunsigned long flags;\r\nstruct mpconf *conf = mddev->private;\r\nstruct list_head *head = &conf->retry_list;\r\nmd_check_recovery(mddev);\r\nfor (;;) {\r\nchar b[BDEVNAME_SIZE];\r\nspin_lock_irqsave(&conf->device_lock, flags);\r\nif (list_empty(head))\r\nbreak;\r\nmp_bh = list_entry(head->prev, struct multipath_bh, retry_list);\r\nlist_del(head->prev);\r\nspin_unlock_irqrestore(&conf->device_lock, flags);\r\nbio = &mp_bh->bio;\r\nbio->bi_iter.bi_sector = mp_bh->master_bio->bi_iter.bi_sector;\r\nif ((mp_bh->path = multipath_map (conf))<0) {\r\nprintk(KERN_ALERT "multipath: %s: unrecoverable IO read"\r\n" error for block %llu\n",\r\nbdevname(bio->bi_bdev,b),\r\n(unsigned long long)bio->bi_iter.bi_sector);\r\nmultipath_end_bh_io(mp_bh, -EIO);\r\n} else {\r\nprintk(KERN_ERR "multipath: %s: redirecting sector %llu"\r\n" to another IO path\n",\r\nbdevname(bio->bi_bdev,b),\r\n(unsigned long long)bio->bi_iter.bi_sector);\r\n*bio = *(mp_bh->master_bio);\r\nbio->bi_iter.bi_sector +=\r\nconf->multipaths[mp_bh->path].rdev->data_offset;\r\nbio->bi_bdev = conf->multipaths[mp_bh->path].rdev->bdev;\r\nbio->bi_opf |= REQ_FAILFAST_TRANSPORT;\r\nbio->bi_end_io = multipath_end_request;\r\nbio->bi_private = mp_bh;\r\ngeneric_make_request(bio);\r\n}\r\n}\r\nspin_unlock_irqrestore(&conf->device_lock, flags);\r\n}\r\nstatic sector_t multipath_size(struct mddev *mddev, sector_t sectors, int raid_disks)\r\n{\r\nWARN_ONCE(sectors || raid_disks,\r\n"%s does not support generic reshape\n", __func__);\r\nreturn mddev->dev_sectors;\r\n}\r\nstatic int multipath_run (struct mddev *mddev)\r\n{\r\nstruct mpconf *conf;\r\nint disk_idx;\r\nstruct multipath_info *disk;\r\nstruct md_rdev *rdev;\r\nint working_disks;\r\nif (md_check_no_bitmap(mddev))\r\nreturn -EINVAL;\r\nif (mddev->level != LEVEL_MULTIPATH) {\r\nprintk("multipath: %s: raid level not set to multipath IO (%d)\n",\r\nmdname(mddev), mddev->level);\r\ngoto out;\r\n}\r\nconf = kzalloc(sizeof(struct mpconf), GFP_KERNEL);\r\nmddev->private = conf;\r\nif (!conf) {\r\nprintk(KERN_ERR\r\n"multipath: couldn't allocate memory for %s\n",\r\nmdname(mddev));\r\ngoto out;\r\n}\r\nconf->multipaths = kzalloc(sizeof(struct multipath_info)*mddev->raid_disks,\r\nGFP_KERNEL);\r\nif (!conf->multipaths) {\r\nprintk(KERN_ERR\r\n"multipath: couldn't allocate memory for %s\n",\r\nmdname(mddev));\r\ngoto out_free_conf;\r\n}\r\nworking_disks = 0;\r\nrdev_for_each(rdev, mddev) {\r\ndisk_idx = rdev->raid_disk;\r\nif (disk_idx < 0 ||\r\ndisk_idx >= mddev->raid_disks)\r\ncontinue;\r\ndisk = conf->multipaths + disk_idx;\r\ndisk->rdev = rdev;\r\ndisk_stack_limits(mddev->gendisk, rdev->bdev,\r\nrdev->data_offset << 9);\r\nif (!test_bit(Faulty, &rdev->flags))\r\nworking_disks++;\r\n}\r\nconf->raid_disks = mddev->raid_disks;\r\nconf->mddev = mddev;\r\nspin_lock_init(&conf->device_lock);\r\nINIT_LIST_HEAD(&conf->retry_list);\r\nif (!working_disks) {\r\nprintk(KERN_ERR "multipath: no operational IO paths for %s\n",\r\nmdname(mddev));\r\ngoto out_free_conf;\r\n}\r\nmddev->degraded = conf->raid_disks - working_disks;\r\nconf->pool = mempool_create_kmalloc_pool(NR_RESERVED_BUFS,\r\nsizeof(struct multipath_bh));\r\nif (conf->pool == NULL) {\r\nprintk(KERN_ERR\r\n"multipath: couldn't allocate memory for %s\n",\r\nmdname(mddev));\r\ngoto out_free_conf;\r\n}\r\n{\r\nmddev->thread = md_register_thread(multipathd, mddev,\r\n"multipath");\r\nif (!mddev->thread) {\r\nprintk(KERN_ERR "multipath: couldn't allocate thread"\r\n" for %s\n", mdname(mddev));\r\ngoto out_free_conf;\r\n}\r\n}\r\nprintk(KERN_INFO\r\n"multipath: array %s active with %d out of %d IO paths\n",\r\nmdname(mddev), conf->raid_disks - mddev->degraded,\r\nmddev->raid_disks);\r\nmd_set_array_sectors(mddev, multipath_size(mddev, 0, 0));\r\nif (md_integrity_register(mddev))\r\ngoto out_free_conf;\r\nreturn 0;\r\nout_free_conf:\r\nmempool_destroy(conf->pool);\r\nkfree(conf->multipaths);\r\nkfree(conf);\r\nmddev->private = NULL;\r\nout:\r\nreturn -EIO;\r\n}\r\nstatic void multipath_free(struct mddev *mddev, void *priv)\r\n{\r\nstruct mpconf *conf = priv;\r\nmempool_destroy(conf->pool);\r\nkfree(conf->multipaths);\r\nkfree(conf);\r\n}\r\nstatic int __init multipath_init (void)\r\n{\r\nreturn register_md_personality (&multipath_personality);\r\n}\r\nstatic void __exit multipath_exit (void)\r\n{\r\nunregister_md_personality (&multipath_personality);\r\n}
