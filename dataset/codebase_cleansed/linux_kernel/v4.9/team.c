static struct team_port *team_port_get_rcu(const struct net_device *dev)\r\n{\r\nreturn rcu_dereference(dev->rx_handler_data);\r\n}\r\nstatic struct team_port *team_port_get_rtnl(const struct net_device *dev)\r\n{\r\nstruct team_port *port = rtnl_dereference(dev->rx_handler_data);\r\nreturn team_port_exists(dev) ? port : NULL;\r\n}\r\nstatic int __set_port_dev_addr(struct net_device *port_dev,\r\nconst unsigned char *dev_addr)\r\n{\r\nstruct sockaddr addr;\r\nmemcpy(addr.sa_data, dev_addr, port_dev->addr_len);\r\naddr.sa_family = port_dev->type;\r\nreturn dev_set_mac_address(port_dev, &addr);\r\n}\r\nstatic int team_port_set_orig_dev_addr(struct team_port *port)\r\n{\r\nreturn __set_port_dev_addr(port->dev, port->orig.dev_addr);\r\n}\r\nstatic int team_port_set_team_dev_addr(struct team *team,\r\nstruct team_port *port)\r\n{\r\nreturn __set_port_dev_addr(port->dev, team->dev->dev_addr);\r\n}\r\nint team_modeop_port_enter(struct team *team, struct team_port *port)\r\n{\r\nreturn team_port_set_team_dev_addr(team, port);\r\n}\r\nvoid team_modeop_port_change_dev_addr(struct team *team,\r\nstruct team_port *port)\r\n{\r\nteam_port_set_team_dev_addr(team, port);\r\n}\r\nstatic void team_lower_state_changed(struct team_port *port)\r\n{\r\nstruct netdev_lag_lower_state_info info;\r\ninfo.link_up = port->linkup;\r\ninfo.tx_enabled = team_port_enabled(port);\r\nnetdev_lower_state_changed(port->dev, &info);\r\n}\r\nstatic void team_refresh_port_linkup(struct team_port *port)\r\n{\r\nbool new_linkup = port->user.linkup_enabled ? port->user.linkup :\r\nport->state.linkup;\r\nif (port->linkup != new_linkup) {\r\nport->linkup = new_linkup;\r\nteam_lower_state_changed(port);\r\n}\r\n}\r\nstatic struct team_option *__team_find_option(struct team *team,\r\nconst char *opt_name)\r\n{\r\nstruct team_option *option;\r\nlist_for_each_entry(option, &team->option_list, list) {\r\nif (strcmp(option->name, opt_name) == 0)\r\nreturn option;\r\n}\r\nreturn NULL;\r\n}\r\nstatic void __team_option_inst_del(struct team_option_inst *opt_inst)\r\n{\r\nlist_del(&opt_inst->list);\r\nkfree(opt_inst);\r\n}\r\nstatic void __team_option_inst_del_option(struct team *team,\r\nstruct team_option *option)\r\n{\r\nstruct team_option_inst *opt_inst, *tmp;\r\nlist_for_each_entry_safe(opt_inst, tmp, &team->option_inst_list, list) {\r\nif (opt_inst->option == option)\r\n__team_option_inst_del(opt_inst);\r\n}\r\n}\r\nstatic int __team_option_inst_add(struct team *team, struct team_option *option,\r\nstruct team_port *port)\r\n{\r\nstruct team_option_inst *opt_inst;\r\nunsigned int array_size;\r\nunsigned int i;\r\nint err;\r\narray_size = option->array_size;\r\nif (!array_size)\r\narray_size = 1;\r\nfor (i = 0; i < array_size; i++) {\r\nopt_inst = kmalloc(sizeof(*opt_inst), GFP_KERNEL);\r\nif (!opt_inst)\r\nreturn -ENOMEM;\r\nopt_inst->option = option;\r\nopt_inst->info.port = port;\r\nopt_inst->info.array_index = i;\r\nopt_inst->changed = true;\r\nopt_inst->removed = false;\r\nlist_add_tail(&opt_inst->list, &team->option_inst_list);\r\nif (option->init) {\r\nerr = option->init(team, &opt_inst->info);\r\nif (err)\r\nreturn err;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int __team_option_inst_add_option(struct team *team,\r\nstruct team_option *option)\r\n{\r\nint err;\r\nif (!option->per_port) {\r\nerr = __team_option_inst_add(team, option, NULL);\r\nif (err)\r\ngoto inst_del_option;\r\n}\r\nreturn 0;\r\ninst_del_option:\r\n__team_option_inst_del_option(team, option);\r\nreturn err;\r\n}\r\nstatic void __team_option_inst_mark_removed_option(struct team *team,\r\nstruct team_option *option)\r\n{\r\nstruct team_option_inst *opt_inst;\r\nlist_for_each_entry(opt_inst, &team->option_inst_list, list) {\r\nif (opt_inst->option == option) {\r\nopt_inst->changed = true;\r\nopt_inst->removed = true;\r\n}\r\n}\r\n}\r\nstatic void __team_option_inst_del_port(struct team *team,\r\nstruct team_port *port)\r\n{\r\nstruct team_option_inst *opt_inst, *tmp;\r\nlist_for_each_entry_safe(opt_inst, tmp, &team->option_inst_list, list) {\r\nif (opt_inst->option->per_port &&\r\nopt_inst->info.port == port)\r\n__team_option_inst_del(opt_inst);\r\n}\r\n}\r\nstatic int __team_option_inst_add_port(struct team *team,\r\nstruct team_port *port)\r\n{\r\nstruct team_option *option;\r\nint err;\r\nlist_for_each_entry(option, &team->option_list, list) {\r\nif (!option->per_port)\r\ncontinue;\r\nerr = __team_option_inst_add(team, option, port);\r\nif (err)\r\ngoto inst_del_port;\r\n}\r\nreturn 0;\r\ninst_del_port:\r\n__team_option_inst_del_port(team, port);\r\nreturn err;\r\n}\r\nstatic void __team_option_inst_mark_removed_port(struct team *team,\r\nstruct team_port *port)\r\n{\r\nstruct team_option_inst *opt_inst;\r\nlist_for_each_entry(opt_inst, &team->option_inst_list, list) {\r\nif (opt_inst->info.port == port) {\r\nopt_inst->changed = true;\r\nopt_inst->removed = true;\r\n}\r\n}\r\n}\r\nstatic int __team_options_register(struct team *team,\r\nconst struct team_option *option,\r\nsize_t option_count)\r\n{\r\nint i;\r\nstruct team_option **dst_opts;\r\nint err;\r\ndst_opts = kzalloc(sizeof(struct team_option *) * option_count,\r\nGFP_KERNEL);\r\nif (!dst_opts)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < option_count; i++, option++) {\r\nif (__team_find_option(team, option->name)) {\r\nerr = -EEXIST;\r\ngoto alloc_rollback;\r\n}\r\ndst_opts[i] = kmemdup(option, sizeof(*option), GFP_KERNEL);\r\nif (!dst_opts[i]) {\r\nerr = -ENOMEM;\r\ngoto alloc_rollback;\r\n}\r\n}\r\nfor (i = 0; i < option_count; i++) {\r\nerr = __team_option_inst_add_option(team, dst_opts[i]);\r\nif (err)\r\ngoto inst_rollback;\r\nlist_add_tail(&dst_opts[i]->list, &team->option_list);\r\n}\r\nkfree(dst_opts);\r\nreturn 0;\r\ninst_rollback:\r\nfor (i--; i >= 0; i--)\r\n__team_option_inst_del_option(team, dst_opts[i]);\r\ni = option_count - 1;\r\nalloc_rollback:\r\nfor (i--; i >= 0; i--)\r\nkfree(dst_opts[i]);\r\nkfree(dst_opts);\r\nreturn err;\r\n}\r\nstatic void __team_options_mark_removed(struct team *team,\r\nconst struct team_option *option,\r\nsize_t option_count)\r\n{\r\nint i;\r\nfor (i = 0; i < option_count; i++, option++) {\r\nstruct team_option *del_opt;\r\ndel_opt = __team_find_option(team, option->name);\r\nif (del_opt)\r\n__team_option_inst_mark_removed_option(team, del_opt);\r\n}\r\n}\r\nstatic void __team_options_unregister(struct team *team,\r\nconst struct team_option *option,\r\nsize_t option_count)\r\n{\r\nint i;\r\nfor (i = 0; i < option_count; i++, option++) {\r\nstruct team_option *del_opt;\r\ndel_opt = __team_find_option(team, option->name);\r\nif (del_opt) {\r\n__team_option_inst_del_option(team, del_opt);\r\nlist_del(&del_opt->list);\r\nkfree(del_opt);\r\n}\r\n}\r\n}\r\nint team_options_register(struct team *team,\r\nconst struct team_option *option,\r\nsize_t option_count)\r\n{\r\nint err;\r\nerr = __team_options_register(team, option, option_count);\r\nif (err)\r\nreturn err;\r\n__team_options_change_check(team);\r\nreturn 0;\r\n}\r\nvoid team_options_unregister(struct team *team,\r\nconst struct team_option *option,\r\nsize_t option_count)\r\n{\r\n__team_options_mark_removed(team, option, option_count);\r\n__team_options_change_check(team);\r\n__team_options_unregister(team, option, option_count);\r\n}\r\nstatic int team_option_get(struct team *team,\r\nstruct team_option_inst *opt_inst,\r\nstruct team_gsetter_ctx *ctx)\r\n{\r\nif (!opt_inst->option->getter)\r\nreturn -EOPNOTSUPP;\r\nreturn opt_inst->option->getter(team, ctx);\r\n}\r\nstatic int team_option_set(struct team *team,\r\nstruct team_option_inst *opt_inst,\r\nstruct team_gsetter_ctx *ctx)\r\n{\r\nif (!opt_inst->option->setter)\r\nreturn -EOPNOTSUPP;\r\nreturn opt_inst->option->setter(team, ctx);\r\n}\r\nvoid team_option_inst_set_change(struct team_option_inst_info *opt_inst_info)\r\n{\r\nstruct team_option_inst *opt_inst;\r\nopt_inst = container_of(opt_inst_info, struct team_option_inst, info);\r\nopt_inst->changed = true;\r\n}\r\nvoid team_options_change_check(struct team *team)\r\n{\r\n__team_options_change_check(team);\r\n}\r\nstatic struct team_mode_item *__find_mode(const char *kind)\r\n{\r\nstruct team_mode_item *mitem;\r\nlist_for_each_entry(mitem, &mode_list, list) {\r\nif (strcmp(mitem->mode->kind, kind) == 0)\r\nreturn mitem;\r\n}\r\nreturn NULL;\r\n}\r\nstatic bool is_good_mode_name(const char *name)\r\n{\r\nwhile (*name != '\0') {\r\nif (!isalpha(*name) && !isdigit(*name) && *name != '_')\r\nreturn false;\r\nname++;\r\n}\r\nreturn true;\r\n}\r\nint team_mode_register(const struct team_mode *mode)\r\n{\r\nint err = 0;\r\nstruct team_mode_item *mitem;\r\nif (!is_good_mode_name(mode->kind) ||\r\nmode->priv_size > TEAM_MODE_PRIV_SIZE)\r\nreturn -EINVAL;\r\nmitem = kmalloc(sizeof(*mitem), GFP_KERNEL);\r\nif (!mitem)\r\nreturn -ENOMEM;\r\nspin_lock(&mode_list_lock);\r\nif (__find_mode(mode->kind)) {\r\nerr = -EEXIST;\r\nkfree(mitem);\r\ngoto unlock;\r\n}\r\nmitem->mode = mode;\r\nlist_add_tail(&mitem->list, &mode_list);\r\nunlock:\r\nspin_unlock(&mode_list_lock);\r\nreturn err;\r\n}\r\nvoid team_mode_unregister(const struct team_mode *mode)\r\n{\r\nstruct team_mode_item *mitem;\r\nspin_lock(&mode_list_lock);\r\nmitem = __find_mode(mode->kind);\r\nif (mitem) {\r\nlist_del_init(&mitem->list);\r\nkfree(mitem);\r\n}\r\nspin_unlock(&mode_list_lock);\r\n}\r\nstatic const struct team_mode *team_mode_get(const char *kind)\r\n{\r\nstruct team_mode_item *mitem;\r\nconst struct team_mode *mode = NULL;\r\nspin_lock(&mode_list_lock);\r\nmitem = __find_mode(kind);\r\nif (!mitem) {\r\nspin_unlock(&mode_list_lock);\r\nrequest_module("team-mode-%s", kind);\r\nspin_lock(&mode_list_lock);\r\nmitem = __find_mode(kind);\r\n}\r\nif (mitem) {\r\nmode = mitem->mode;\r\nif (!try_module_get(mode->owner))\r\nmode = NULL;\r\n}\r\nspin_unlock(&mode_list_lock);\r\nreturn mode;\r\n}\r\nstatic void team_mode_put(const struct team_mode *mode)\r\n{\r\nmodule_put(mode->owner);\r\n}\r\nstatic bool team_dummy_transmit(struct team *team, struct sk_buff *skb)\r\n{\r\ndev_kfree_skb_any(skb);\r\nreturn false;\r\n}\r\nstatic rx_handler_result_t team_dummy_receive(struct team *team,\r\nstruct team_port *port,\r\nstruct sk_buff *skb)\r\n{\r\nreturn RX_HANDLER_ANOTHER;\r\n}\r\nstatic bool team_is_mode_set(struct team *team)\r\n{\r\nreturn team->mode != &__team_no_mode;\r\n}\r\nstatic void team_set_no_mode(struct team *team)\r\n{\r\nteam->user_carrier_enabled = false;\r\nteam->mode = &__team_no_mode;\r\n}\r\nstatic void team_adjust_ops(struct team *team)\r\n{\r\nif (!team->en_port_count || !team_is_mode_set(team) ||\r\n!team->mode->ops->transmit)\r\nteam->ops.transmit = team_dummy_transmit;\r\nelse\r\nteam->ops.transmit = team->mode->ops->transmit;\r\nif (!team->en_port_count || !team_is_mode_set(team) ||\r\n!team->mode->ops->receive)\r\nteam->ops.receive = team_dummy_receive;\r\nelse\r\nteam->ops.receive = team->mode->ops->receive;\r\n}\r\nstatic int __team_change_mode(struct team *team,\r\nconst struct team_mode *new_mode)\r\n{\r\nif (team_is_mode_set(team)) {\r\nvoid (*exit_op)(struct team *team) = team->ops.exit;\r\nmemset(&team->ops, 0, sizeof(struct team_mode_ops));\r\nteam_adjust_ops(team);\r\nif (exit_op)\r\nexit_op(team);\r\nteam_mode_put(team->mode);\r\nteam_set_no_mode(team);\r\nmemset(&team->mode_priv, 0,\r\nsizeof(struct team) - offsetof(struct team, mode_priv));\r\n}\r\nif (!new_mode)\r\nreturn 0;\r\nif (new_mode->ops->init) {\r\nint err;\r\nerr = new_mode->ops->init(team);\r\nif (err)\r\nreturn err;\r\n}\r\nteam->mode = new_mode;\r\nmemcpy(&team->ops, new_mode->ops, sizeof(struct team_mode_ops));\r\nteam_adjust_ops(team);\r\nreturn 0;\r\n}\r\nstatic int team_change_mode(struct team *team, const char *kind)\r\n{\r\nconst struct team_mode *new_mode;\r\nstruct net_device *dev = team->dev;\r\nint err;\r\nif (!list_empty(&team->port_list)) {\r\nnetdev_err(dev, "No ports can be present during mode change\n");\r\nreturn -EBUSY;\r\n}\r\nif (team_is_mode_set(team) && strcmp(team->mode->kind, kind) == 0) {\r\nnetdev_err(dev, "Unable to change to the same mode the team is in\n");\r\nreturn -EINVAL;\r\n}\r\nnew_mode = team_mode_get(kind);\r\nif (!new_mode) {\r\nnetdev_err(dev, "Mode \"%s\" not found\n", kind);\r\nreturn -EINVAL;\r\n}\r\nerr = __team_change_mode(team, new_mode);\r\nif (err) {\r\nnetdev_err(dev, "Failed to change to mode \"%s\"\n", kind);\r\nteam_mode_put(new_mode);\r\nreturn err;\r\n}\r\nnetdev_info(dev, "Mode changed to \"%s\"\n", kind);\r\nreturn 0;\r\n}\r\nstatic void team_notify_peers_work(struct work_struct *work)\r\n{\r\nstruct team *team;\r\nint val;\r\nteam = container_of(work, struct team, notify_peers.dw.work);\r\nif (!rtnl_trylock()) {\r\nschedule_delayed_work(&team->notify_peers.dw, 0);\r\nreturn;\r\n}\r\nval = atomic_dec_if_positive(&team->notify_peers.count_pending);\r\nif (val < 0) {\r\nrtnl_unlock();\r\nreturn;\r\n}\r\ncall_netdevice_notifiers(NETDEV_NOTIFY_PEERS, team->dev);\r\nrtnl_unlock();\r\nif (val)\r\nschedule_delayed_work(&team->notify_peers.dw,\r\nmsecs_to_jiffies(team->notify_peers.interval));\r\n}\r\nstatic void team_notify_peers(struct team *team)\r\n{\r\nif (!team->notify_peers.count || !netif_running(team->dev))\r\nreturn;\r\natomic_add(team->notify_peers.count, &team->notify_peers.count_pending);\r\nschedule_delayed_work(&team->notify_peers.dw, 0);\r\n}\r\nstatic void team_notify_peers_init(struct team *team)\r\n{\r\nINIT_DELAYED_WORK(&team->notify_peers.dw, team_notify_peers_work);\r\n}\r\nstatic void team_notify_peers_fini(struct team *team)\r\n{\r\ncancel_delayed_work_sync(&team->notify_peers.dw);\r\n}\r\nstatic void team_mcast_rejoin_work(struct work_struct *work)\r\n{\r\nstruct team *team;\r\nint val;\r\nteam = container_of(work, struct team, mcast_rejoin.dw.work);\r\nif (!rtnl_trylock()) {\r\nschedule_delayed_work(&team->mcast_rejoin.dw, 0);\r\nreturn;\r\n}\r\nval = atomic_dec_if_positive(&team->mcast_rejoin.count_pending);\r\nif (val < 0) {\r\nrtnl_unlock();\r\nreturn;\r\n}\r\ncall_netdevice_notifiers(NETDEV_RESEND_IGMP, team->dev);\r\nrtnl_unlock();\r\nif (val)\r\nschedule_delayed_work(&team->mcast_rejoin.dw,\r\nmsecs_to_jiffies(team->mcast_rejoin.interval));\r\n}\r\nstatic void team_mcast_rejoin(struct team *team)\r\n{\r\nif (!team->mcast_rejoin.count || !netif_running(team->dev))\r\nreturn;\r\natomic_add(team->mcast_rejoin.count, &team->mcast_rejoin.count_pending);\r\nschedule_delayed_work(&team->mcast_rejoin.dw, 0);\r\n}\r\nstatic void team_mcast_rejoin_init(struct team *team)\r\n{\r\nINIT_DELAYED_WORK(&team->mcast_rejoin.dw, team_mcast_rejoin_work);\r\n}\r\nstatic void team_mcast_rejoin_fini(struct team *team)\r\n{\r\ncancel_delayed_work_sync(&team->mcast_rejoin.dw);\r\n}\r\nstatic rx_handler_result_t team_handle_frame(struct sk_buff **pskb)\r\n{\r\nstruct sk_buff *skb = *pskb;\r\nstruct team_port *port;\r\nstruct team *team;\r\nrx_handler_result_t res;\r\nskb = skb_share_check(skb, GFP_ATOMIC);\r\nif (!skb)\r\nreturn RX_HANDLER_CONSUMED;\r\n*pskb = skb;\r\nport = team_port_get_rcu(skb->dev);\r\nteam = port->team;\r\nif (!team_port_enabled(port)) {\r\nres = RX_HANDLER_EXACT;\r\n} else {\r\nres = team->ops.receive(team, port, skb);\r\n}\r\nif (res == RX_HANDLER_ANOTHER) {\r\nstruct team_pcpu_stats *pcpu_stats;\r\npcpu_stats = this_cpu_ptr(team->pcpu_stats);\r\nu64_stats_update_begin(&pcpu_stats->syncp);\r\npcpu_stats->rx_packets++;\r\npcpu_stats->rx_bytes += skb->len;\r\nif (skb->pkt_type == PACKET_MULTICAST)\r\npcpu_stats->rx_multicast++;\r\nu64_stats_update_end(&pcpu_stats->syncp);\r\nskb->dev = team->dev;\r\n} else if (res == RX_HANDLER_EXACT) {\r\nthis_cpu_inc(team->pcpu_stats->rx_nohandler);\r\n} else {\r\nthis_cpu_inc(team->pcpu_stats->rx_dropped);\r\n}\r\nreturn res;\r\n}\r\nstatic int team_queue_override_init(struct team *team)\r\n{\r\nstruct list_head *listarr;\r\nunsigned int queue_cnt = team->dev->num_tx_queues - 1;\r\nunsigned int i;\r\nif (!queue_cnt)\r\nreturn 0;\r\nlistarr = kmalloc(sizeof(struct list_head) * queue_cnt, GFP_KERNEL);\r\nif (!listarr)\r\nreturn -ENOMEM;\r\nteam->qom_lists = listarr;\r\nfor (i = 0; i < queue_cnt; i++)\r\nINIT_LIST_HEAD(listarr++);\r\nreturn 0;\r\n}\r\nstatic void team_queue_override_fini(struct team *team)\r\n{\r\nkfree(team->qom_lists);\r\n}\r\nstatic struct list_head *__team_get_qom_list(struct team *team, u16 queue_id)\r\n{\r\nreturn &team->qom_lists[queue_id - 1];\r\n}\r\nstatic bool team_queue_override_transmit(struct team *team, struct sk_buff *skb)\r\n{\r\nstruct list_head *qom_list;\r\nstruct team_port *port;\r\nif (!team->queue_override_enabled || !skb->queue_mapping)\r\nreturn false;\r\nqom_list = __team_get_qom_list(team, skb->queue_mapping);\r\nlist_for_each_entry_rcu(port, qom_list, qom_list) {\r\nif (!team_dev_queue_xmit(team, port, skb))\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic void __team_queue_override_port_del(struct team *team,\r\nstruct team_port *port)\r\n{\r\nif (!port->queue_id)\r\nreturn;\r\nlist_del_rcu(&port->qom_list);\r\n}\r\nstatic bool team_queue_override_port_has_gt_prio_than(struct team_port *port,\r\nstruct team_port *cur)\r\n{\r\nif (port->priority < cur->priority)\r\nreturn true;\r\nif (port->priority > cur->priority)\r\nreturn false;\r\nif (port->index < cur->index)\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic void __team_queue_override_port_add(struct team *team,\r\nstruct team_port *port)\r\n{\r\nstruct team_port *cur;\r\nstruct list_head *qom_list;\r\nstruct list_head *node;\r\nif (!port->queue_id)\r\nreturn;\r\nqom_list = __team_get_qom_list(team, port->queue_id);\r\nnode = qom_list;\r\nlist_for_each_entry(cur, qom_list, qom_list) {\r\nif (team_queue_override_port_has_gt_prio_than(port, cur))\r\nbreak;\r\nnode = &cur->qom_list;\r\n}\r\nlist_add_tail_rcu(&port->qom_list, node);\r\n}\r\nstatic void __team_queue_override_enabled_check(struct team *team)\r\n{\r\nstruct team_port *port;\r\nbool enabled = false;\r\nlist_for_each_entry(port, &team->port_list, list) {\r\nif (port->queue_id) {\r\nenabled = true;\r\nbreak;\r\n}\r\n}\r\nif (enabled == team->queue_override_enabled)\r\nreturn;\r\nnetdev_dbg(team->dev, "%s queue override\n",\r\nenabled ? "Enabling" : "Disabling");\r\nteam->queue_override_enabled = enabled;\r\n}\r\nstatic void team_queue_override_port_prio_changed(struct team *team,\r\nstruct team_port *port)\r\n{\r\nif (!port->queue_id || team_port_enabled(port))\r\nreturn;\r\n__team_queue_override_port_del(team, port);\r\n__team_queue_override_port_add(team, port);\r\n__team_queue_override_enabled_check(team);\r\n}\r\nstatic void team_queue_override_port_change_queue_id(struct team *team,\r\nstruct team_port *port,\r\nu16 new_queue_id)\r\n{\r\nif (team_port_enabled(port)) {\r\n__team_queue_override_port_del(team, port);\r\nport->queue_id = new_queue_id;\r\n__team_queue_override_port_add(team, port);\r\n__team_queue_override_enabled_check(team);\r\n} else {\r\nport->queue_id = new_queue_id;\r\n}\r\n}\r\nstatic void team_queue_override_port_add(struct team *team,\r\nstruct team_port *port)\r\n{\r\n__team_queue_override_port_add(team, port);\r\n__team_queue_override_enabled_check(team);\r\n}\r\nstatic void team_queue_override_port_del(struct team *team,\r\nstruct team_port *port)\r\n{\r\n__team_queue_override_port_del(team, port);\r\n__team_queue_override_enabled_check(team);\r\n}\r\nstatic bool team_port_find(const struct team *team,\r\nconst struct team_port *port)\r\n{\r\nstruct team_port *cur;\r\nlist_for_each_entry(cur, &team->port_list, list)\r\nif (cur == port)\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic void team_port_enable(struct team *team,\r\nstruct team_port *port)\r\n{\r\nif (team_port_enabled(port))\r\nreturn;\r\nport->index = team->en_port_count++;\r\nhlist_add_head_rcu(&port->hlist,\r\nteam_port_index_hash(team, port->index));\r\nteam_adjust_ops(team);\r\nteam_queue_override_port_add(team, port);\r\nif (team->ops.port_enabled)\r\nteam->ops.port_enabled(team, port);\r\nteam_notify_peers(team);\r\nteam_mcast_rejoin(team);\r\nteam_lower_state_changed(port);\r\n}\r\nstatic void __reconstruct_port_hlist(struct team *team, int rm_index)\r\n{\r\nint i;\r\nstruct team_port *port;\r\nfor (i = rm_index + 1; i < team->en_port_count; i++) {\r\nport = team_get_port_by_index(team, i);\r\nhlist_del_rcu(&port->hlist);\r\nport->index--;\r\nhlist_add_head_rcu(&port->hlist,\r\nteam_port_index_hash(team, port->index));\r\n}\r\n}\r\nstatic void team_port_disable(struct team *team,\r\nstruct team_port *port)\r\n{\r\nif (!team_port_enabled(port))\r\nreturn;\r\nif (team->ops.port_disabled)\r\nteam->ops.port_disabled(team, port);\r\nhlist_del_rcu(&port->hlist);\r\n__reconstruct_port_hlist(team, port->index);\r\nport->index = -1;\r\nteam->en_port_count--;\r\nteam_queue_override_port_del(team, port);\r\nteam_adjust_ops(team);\r\nteam_notify_peers(team);\r\nteam_mcast_rejoin(team);\r\nteam_lower_state_changed(port);\r\n}\r\nstatic void ___team_compute_features(struct team *team)\r\n{\r\nstruct team_port *port;\r\nu32 vlan_features = TEAM_VLAN_FEATURES & NETIF_F_ALL_FOR_ALL;\r\nnetdev_features_t enc_features = TEAM_ENC_FEATURES;\r\nunsigned short max_hard_header_len = ETH_HLEN;\r\nunsigned int dst_release_flag = IFF_XMIT_DST_RELEASE |\r\nIFF_XMIT_DST_RELEASE_PERM;\r\nlist_for_each_entry(port, &team->port_list, list) {\r\nvlan_features = netdev_increment_features(vlan_features,\r\nport->dev->vlan_features,\r\nTEAM_VLAN_FEATURES);\r\nenc_features =\r\nnetdev_increment_features(enc_features,\r\nport->dev->hw_enc_features,\r\nTEAM_ENC_FEATURES);\r\ndst_release_flag &= port->dev->priv_flags;\r\nif (port->dev->hard_header_len > max_hard_header_len)\r\nmax_hard_header_len = port->dev->hard_header_len;\r\n}\r\nteam->dev->vlan_features = vlan_features;\r\nteam->dev->hw_enc_features = enc_features | NETIF_F_GSO_ENCAP_ALL;\r\nteam->dev->hard_header_len = max_hard_header_len;\r\nteam->dev->priv_flags &= ~IFF_XMIT_DST_RELEASE;\r\nif (dst_release_flag == (IFF_XMIT_DST_RELEASE | IFF_XMIT_DST_RELEASE_PERM))\r\nteam->dev->priv_flags |= IFF_XMIT_DST_RELEASE;\r\n}\r\nstatic void __team_compute_features(struct team *team)\r\n{\r\n___team_compute_features(team);\r\nnetdev_change_features(team->dev);\r\n}\r\nstatic void team_compute_features(struct team *team)\r\n{\r\nmutex_lock(&team->lock);\r\n___team_compute_features(team);\r\nmutex_unlock(&team->lock);\r\nnetdev_change_features(team->dev);\r\n}\r\nstatic int team_port_enter(struct team *team, struct team_port *port)\r\n{\r\nint err = 0;\r\ndev_hold(team->dev);\r\nif (team->ops.port_enter) {\r\nerr = team->ops.port_enter(team, port);\r\nif (err) {\r\nnetdev_err(team->dev, "Device %s failed to enter team mode\n",\r\nport->dev->name);\r\ngoto err_port_enter;\r\n}\r\n}\r\nreturn 0;\r\nerr_port_enter:\r\ndev_put(team->dev);\r\nreturn err;\r\n}\r\nstatic void team_port_leave(struct team *team, struct team_port *port)\r\n{\r\nif (team->ops.port_leave)\r\nteam->ops.port_leave(team, port);\r\ndev_put(team->dev);\r\n}\r\nstatic int team_port_enable_netpoll(struct team *team, struct team_port *port)\r\n{\r\nstruct netpoll *np;\r\nint err;\r\nif (!team->dev->npinfo)\r\nreturn 0;\r\nnp = kzalloc(sizeof(*np), GFP_KERNEL);\r\nif (!np)\r\nreturn -ENOMEM;\r\nerr = __netpoll_setup(np, port->dev);\r\nif (err) {\r\nkfree(np);\r\nreturn err;\r\n}\r\nport->np = np;\r\nreturn err;\r\n}\r\nstatic void team_port_disable_netpoll(struct team_port *port)\r\n{\r\nstruct netpoll *np = port->np;\r\nif (!np)\r\nreturn;\r\nport->np = NULL;\r\nsynchronize_rcu_bh();\r\n__netpoll_cleanup(np);\r\nkfree(np);\r\n}\r\nstatic int team_port_enable_netpoll(struct team *team, struct team_port *port)\r\n{\r\nreturn 0;\r\n}\r\nstatic void team_port_disable_netpoll(struct team_port *port)\r\n{\r\n}\r\nstatic int team_upper_dev_link(struct team *team, struct team_port *port)\r\n{\r\nstruct netdev_lag_upper_info lag_upper_info;\r\nint err;\r\nlag_upper_info.tx_type = team->mode->lag_tx_type;\r\nerr = netdev_master_upper_dev_link(port->dev, team->dev, NULL,\r\n&lag_upper_info);\r\nif (err)\r\nreturn err;\r\nport->dev->priv_flags |= IFF_TEAM_PORT;\r\nreturn 0;\r\n}\r\nstatic void team_upper_dev_unlink(struct team *team, struct team_port *port)\r\n{\r\nnetdev_upper_dev_unlink(port->dev, team->dev);\r\nport->dev->priv_flags &= ~IFF_TEAM_PORT;\r\n}\r\nstatic int team_port_add(struct team *team, struct net_device *port_dev)\r\n{\r\nstruct net_device *dev = team->dev;\r\nstruct team_port *port;\r\nchar *portname = port_dev->name;\r\nint err;\r\nif (port_dev->flags & IFF_LOOPBACK) {\r\nnetdev_err(dev, "Device %s is loopback device. Loopback devices can't be added as a team port\n",\r\nportname);\r\nreturn -EINVAL;\r\n}\r\nif (team_port_exists(port_dev)) {\r\nnetdev_err(dev, "Device %s is already a port "\r\n"of a team device\n", portname);\r\nreturn -EBUSY;\r\n}\r\nif (port_dev->features & NETIF_F_VLAN_CHALLENGED &&\r\nvlan_uses_dev(dev)) {\r\nnetdev_err(dev, "Device %s is VLAN challenged and team device has VLAN set up\n",\r\nportname);\r\nreturn -EPERM;\r\n}\r\nerr = team_dev_type_check_change(dev, port_dev);\r\nif (err)\r\nreturn err;\r\nif (port_dev->flags & IFF_UP) {\r\nnetdev_err(dev, "Device %s is up. Set it down before adding it as a team port\n",\r\nportname);\r\nreturn -EBUSY;\r\n}\r\nport = kzalloc(sizeof(struct team_port) + team->mode->port_priv_size,\r\nGFP_KERNEL);\r\nif (!port)\r\nreturn -ENOMEM;\r\nport->dev = port_dev;\r\nport->team = team;\r\nINIT_LIST_HEAD(&port->qom_list);\r\nport->orig.mtu = port_dev->mtu;\r\nerr = dev_set_mtu(port_dev, dev->mtu);\r\nif (err) {\r\nnetdev_dbg(dev, "Error %d calling dev_set_mtu\n", err);\r\ngoto err_set_mtu;\r\n}\r\nmemcpy(port->orig.dev_addr, port_dev->dev_addr, port_dev->addr_len);\r\nerr = team_port_enter(team, port);\r\nif (err) {\r\nnetdev_err(dev, "Device %s failed to enter team mode\n",\r\nportname);\r\ngoto err_port_enter;\r\n}\r\nerr = dev_open(port_dev);\r\nif (err) {\r\nnetdev_dbg(dev, "Device %s opening failed\n",\r\nportname);\r\ngoto err_dev_open;\r\n}\r\nnetif_addr_lock_bh(dev);\r\ndev_uc_sync_multiple(port_dev, dev);\r\ndev_mc_sync_multiple(port_dev, dev);\r\nnetif_addr_unlock_bh(dev);\r\nerr = vlan_vids_add_by_dev(port_dev, dev);\r\nif (err) {\r\nnetdev_err(dev, "Failed to add vlan ids to device %s\n",\r\nportname);\r\ngoto err_vids_add;\r\n}\r\nerr = team_port_enable_netpoll(team, port);\r\nif (err) {\r\nnetdev_err(dev, "Failed to enable netpoll on device %s\n",\r\nportname);\r\ngoto err_enable_netpoll;\r\n}\r\nif (!(dev->features & NETIF_F_LRO))\r\ndev_disable_lro(port_dev);\r\nerr = netdev_rx_handler_register(port_dev, team_handle_frame,\r\nport);\r\nif (err) {\r\nnetdev_err(dev, "Device %s failed to register rx_handler\n",\r\nportname);\r\ngoto err_handler_register;\r\n}\r\nerr = team_upper_dev_link(team, port);\r\nif (err) {\r\nnetdev_err(dev, "Device %s failed to set upper link\n",\r\nportname);\r\ngoto err_set_upper_link;\r\n}\r\nerr = __team_option_inst_add_port(team, port);\r\nif (err) {\r\nnetdev_err(dev, "Device %s failed to add per-port options\n",\r\nportname);\r\ngoto err_option_port_add;\r\n}\r\nport->index = -1;\r\nlist_add_tail_rcu(&port->list, &team->port_list);\r\nteam_port_enable(team, port);\r\n__team_compute_features(team);\r\n__team_port_change_port_added(port, !!netif_carrier_ok(port_dev));\r\n__team_options_change_check(team);\r\nnetdev_info(dev, "Port device %s added\n", portname);\r\nreturn 0;\r\nerr_option_port_add:\r\nteam_upper_dev_unlink(team, port);\r\nerr_set_upper_link:\r\nnetdev_rx_handler_unregister(port_dev);\r\nerr_handler_register:\r\nteam_port_disable_netpoll(port);\r\nerr_enable_netpoll:\r\nvlan_vids_del_by_dev(port_dev, dev);\r\nerr_vids_add:\r\ndev_uc_unsync(port_dev, dev);\r\ndev_mc_unsync(port_dev, dev);\r\ndev_close(port_dev);\r\nerr_dev_open:\r\nteam_port_leave(team, port);\r\nteam_port_set_orig_dev_addr(port);\r\nerr_port_enter:\r\ndev_set_mtu(port_dev, port->orig.mtu);\r\nerr_set_mtu:\r\nkfree(port);\r\nreturn err;\r\n}\r\nstatic int team_port_del(struct team *team, struct net_device *port_dev)\r\n{\r\nstruct net_device *dev = team->dev;\r\nstruct team_port *port;\r\nchar *portname = port_dev->name;\r\nport = team_port_get_rtnl(port_dev);\r\nif (!port || !team_port_find(team, port)) {\r\nnetdev_err(dev, "Device %s does not act as a port of this team\n",\r\nportname);\r\nreturn -ENOENT;\r\n}\r\nteam_port_disable(team, port);\r\nlist_del_rcu(&port->list);\r\nteam_upper_dev_unlink(team, port);\r\nnetdev_rx_handler_unregister(port_dev);\r\nteam_port_disable_netpoll(port);\r\nvlan_vids_del_by_dev(port_dev, dev);\r\ndev_uc_unsync(port_dev, dev);\r\ndev_mc_unsync(port_dev, dev);\r\ndev_close(port_dev);\r\nteam_port_leave(team, port);\r\n__team_option_inst_mark_removed_port(team, port);\r\n__team_options_change_check(team);\r\n__team_option_inst_del_port(team, port);\r\n__team_port_change_port_removed(port);\r\nteam_port_set_orig_dev_addr(port);\r\ndev_set_mtu(port_dev, port->orig.mtu);\r\nkfree_rcu(port, rcu);\r\nnetdev_info(dev, "Port device %s removed\n", portname);\r\n__team_compute_features(team);\r\nreturn 0;\r\n}\r\nstatic int team_mode_option_get(struct team *team, struct team_gsetter_ctx *ctx)\r\n{\r\nctx->data.str_val = team->mode->kind;\r\nreturn 0;\r\n}\r\nstatic int team_mode_option_set(struct team *team, struct team_gsetter_ctx *ctx)\r\n{\r\nreturn team_change_mode(team, ctx->data.str_val);\r\n}\r\nstatic int team_notify_peers_count_get(struct team *team,\r\nstruct team_gsetter_ctx *ctx)\r\n{\r\nctx->data.u32_val = team->notify_peers.count;\r\nreturn 0;\r\n}\r\nstatic int team_notify_peers_count_set(struct team *team,\r\nstruct team_gsetter_ctx *ctx)\r\n{\r\nteam->notify_peers.count = ctx->data.u32_val;\r\nreturn 0;\r\n}\r\nstatic int team_notify_peers_interval_get(struct team *team,\r\nstruct team_gsetter_ctx *ctx)\r\n{\r\nctx->data.u32_val = team->notify_peers.interval;\r\nreturn 0;\r\n}\r\nstatic int team_notify_peers_interval_set(struct team *team,\r\nstruct team_gsetter_ctx *ctx)\r\n{\r\nteam->notify_peers.interval = ctx->data.u32_val;\r\nreturn 0;\r\n}\r\nstatic int team_mcast_rejoin_count_get(struct team *team,\r\nstruct team_gsetter_ctx *ctx)\r\n{\r\nctx->data.u32_val = team->mcast_rejoin.count;\r\nreturn 0;\r\n}\r\nstatic int team_mcast_rejoin_count_set(struct team *team,\r\nstruct team_gsetter_ctx *ctx)\r\n{\r\nteam->mcast_rejoin.count = ctx->data.u32_val;\r\nreturn 0;\r\n}\r\nstatic int team_mcast_rejoin_interval_get(struct team *team,\r\nstruct team_gsetter_ctx *ctx)\r\n{\r\nctx->data.u32_val = team->mcast_rejoin.interval;\r\nreturn 0;\r\n}\r\nstatic int team_mcast_rejoin_interval_set(struct team *team,\r\nstruct team_gsetter_ctx *ctx)\r\n{\r\nteam->mcast_rejoin.interval = ctx->data.u32_val;\r\nreturn 0;\r\n}\r\nstatic int team_port_en_option_get(struct team *team,\r\nstruct team_gsetter_ctx *ctx)\r\n{\r\nstruct team_port *port = ctx->info->port;\r\nctx->data.bool_val = team_port_enabled(port);\r\nreturn 0;\r\n}\r\nstatic int team_port_en_option_set(struct team *team,\r\nstruct team_gsetter_ctx *ctx)\r\n{\r\nstruct team_port *port = ctx->info->port;\r\nif (ctx->data.bool_val)\r\nteam_port_enable(team, port);\r\nelse\r\nteam_port_disable(team, port);\r\nreturn 0;\r\n}\r\nstatic int team_user_linkup_option_get(struct team *team,\r\nstruct team_gsetter_ctx *ctx)\r\n{\r\nstruct team_port *port = ctx->info->port;\r\nctx->data.bool_val = port->user.linkup;\r\nreturn 0;\r\n}\r\nstatic int team_user_linkup_option_set(struct team *team,\r\nstruct team_gsetter_ctx *ctx)\r\n{\r\nstruct team_port *port = ctx->info->port;\r\nport->user.linkup = ctx->data.bool_val;\r\nteam_refresh_port_linkup(port);\r\n__team_carrier_check(port->team);\r\nreturn 0;\r\n}\r\nstatic int team_user_linkup_en_option_get(struct team *team,\r\nstruct team_gsetter_ctx *ctx)\r\n{\r\nstruct team_port *port = ctx->info->port;\r\nctx->data.bool_val = port->user.linkup_enabled;\r\nreturn 0;\r\n}\r\nstatic int team_user_linkup_en_option_set(struct team *team,\r\nstruct team_gsetter_ctx *ctx)\r\n{\r\nstruct team_port *port = ctx->info->port;\r\nport->user.linkup_enabled = ctx->data.bool_val;\r\nteam_refresh_port_linkup(port);\r\n__team_carrier_check(port->team);\r\nreturn 0;\r\n}\r\nstatic int team_priority_option_get(struct team *team,\r\nstruct team_gsetter_ctx *ctx)\r\n{\r\nstruct team_port *port = ctx->info->port;\r\nctx->data.s32_val = port->priority;\r\nreturn 0;\r\n}\r\nstatic int team_priority_option_set(struct team *team,\r\nstruct team_gsetter_ctx *ctx)\r\n{\r\nstruct team_port *port = ctx->info->port;\r\ns32 priority = ctx->data.s32_val;\r\nif (port->priority == priority)\r\nreturn 0;\r\nport->priority = priority;\r\nteam_queue_override_port_prio_changed(team, port);\r\nreturn 0;\r\n}\r\nstatic int team_queue_id_option_get(struct team *team,\r\nstruct team_gsetter_ctx *ctx)\r\n{\r\nstruct team_port *port = ctx->info->port;\r\nctx->data.u32_val = port->queue_id;\r\nreturn 0;\r\n}\r\nstatic int team_queue_id_option_set(struct team *team,\r\nstruct team_gsetter_ctx *ctx)\r\n{\r\nstruct team_port *port = ctx->info->port;\r\nu16 new_queue_id = ctx->data.u32_val;\r\nif (port->queue_id == new_queue_id)\r\nreturn 0;\r\nif (new_queue_id >= team->dev->real_num_tx_queues)\r\nreturn -EINVAL;\r\nteam_queue_override_port_change_queue_id(team, port, new_queue_id);\r\nreturn 0;\r\n}\r\nstatic int team_init(struct net_device *dev)\r\n{\r\nstruct team *team = netdev_priv(dev);\r\nint i;\r\nint err;\r\nteam->dev = dev;\r\nmutex_init(&team->lock);\r\nteam_set_no_mode(team);\r\nteam->pcpu_stats = netdev_alloc_pcpu_stats(struct team_pcpu_stats);\r\nif (!team->pcpu_stats)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < TEAM_PORT_HASHENTRIES; i++)\r\nINIT_HLIST_HEAD(&team->en_port_hlist[i]);\r\nINIT_LIST_HEAD(&team->port_list);\r\nerr = team_queue_override_init(team);\r\nif (err)\r\ngoto err_team_queue_override_init;\r\nteam_adjust_ops(team);\r\nINIT_LIST_HEAD(&team->option_list);\r\nINIT_LIST_HEAD(&team->option_inst_list);\r\nteam_notify_peers_init(team);\r\nteam_mcast_rejoin_init(team);\r\nerr = team_options_register(team, team_options, ARRAY_SIZE(team_options));\r\nif (err)\r\ngoto err_options_register;\r\nnetif_carrier_off(dev);\r\nnetdev_lockdep_set_classes(dev);\r\nreturn 0;\r\nerr_options_register:\r\nteam_mcast_rejoin_fini(team);\r\nteam_notify_peers_fini(team);\r\nteam_queue_override_fini(team);\r\nerr_team_queue_override_init:\r\nfree_percpu(team->pcpu_stats);\r\nreturn err;\r\n}\r\nstatic void team_uninit(struct net_device *dev)\r\n{\r\nstruct team *team = netdev_priv(dev);\r\nstruct team_port *port;\r\nstruct team_port *tmp;\r\nmutex_lock(&team->lock);\r\nlist_for_each_entry_safe(port, tmp, &team->port_list, list)\r\nteam_port_del(team, port->dev);\r\n__team_change_mode(team, NULL);\r\n__team_options_unregister(team, team_options, ARRAY_SIZE(team_options));\r\nteam_mcast_rejoin_fini(team);\r\nteam_notify_peers_fini(team);\r\nteam_queue_override_fini(team);\r\nmutex_unlock(&team->lock);\r\n}\r\nstatic void team_destructor(struct net_device *dev)\r\n{\r\nstruct team *team = netdev_priv(dev);\r\nfree_percpu(team->pcpu_stats);\r\nfree_netdev(dev);\r\n}\r\nstatic int team_open(struct net_device *dev)\r\n{\r\nreturn 0;\r\n}\r\nstatic int team_close(struct net_device *dev)\r\n{\r\nreturn 0;\r\n}\r\nstatic netdev_tx_t team_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct team *team = netdev_priv(dev);\r\nbool tx_success;\r\nunsigned int len = skb->len;\r\ntx_success = team_queue_override_transmit(team, skb);\r\nif (!tx_success)\r\ntx_success = team->ops.transmit(team, skb);\r\nif (tx_success) {\r\nstruct team_pcpu_stats *pcpu_stats;\r\npcpu_stats = this_cpu_ptr(team->pcpu_stats);\r\nu64_stats_update_begin(&pcpu_stats->syncp);\r\npcpu_stats->tx_packets++;\r\npcpu_stats->tx_bytes += len;\r\nu64_stats_update_end(&pcpu_stats->syncp);\r\n} else {\r\nthis_cpu_inc(team->pcpu_stats->tx_dropped);\r\n}\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic u16 team_select_queue(struct net_device *dev, struct sk_buff *skb,\r\nvoid *accel_priv, select_queue_fallback_t fallback)\r\n{\r\nu16 txq = skb_rx_queue_recorded(skb) ? skb_get_rx_queue(skb) : 0;\r\nqdisc_skb_cb(skb)->slave_dev_queue_mapping = skb->queue_mapping;\r\nif (unlikely(txq >= dev->real_num_tx_queues)) {\r\ndo {\r\ntxq -= dev->real_num_tx_queues;\r\n} while (txq >= dev->real_num_tx_queues);\r\n}\r\nreturn txq;\r\n}\r\nstatic void team_change_rx_flags(struct net_device *dev, int change)\r\n{\r\nstruct team *team = netdev_priv(dev);\r\nstruct team_port *port;\r\nint inc;\r\nrcu_read_lock();\r\nlist_for_each_entry_rcu(port, &team->port_list, list) {\r\nif (change & IFF_PROMISC) {\r\ninc = dev->flags & IFF_PROMISC ? 1 : -1;\r\ndev_set_promiscuity(port->dev, inc);\r\n}\r\nif (change & IFF_ALLMULTI) {\r\ninc = dev->flags & IFF_ALLMULTI ? 1 : -1;\r\ndev_set_allmulti(port->dev, inc);\r\n}\r\n}\r\nrcu_read_unlock();\r\n}\r\nstatic void team_set_rx_mode(struct net_device *dev)\r\n{\r\nstruct team *team = netdev_priv(dev);\r\nstruct team_port *port;\r\nrcu_read_lock();\r\nlist_for_each_entry_rcu(port, &team->port_list, list) {\r\ndev_uc_sync_multiple(port->dev, dev);\r\ndev_mc_sync_multiple(port->dev, dev);\r\n}\r\nrcu_read_unlock();\r\n}\r\nstatic int team_set_mac_address(struct net_device *dev, void *p)\r\n{\r\nstruct sockaddr *addr = p;\r\nstruct team *team = netdev_priv(dev);\r\nstruct team_port *port;\r\nif (dev->type == ARPHRD_ETHER && !is_valid_ether_addr(addr->sa_data))\r\nreturn -EADDRNOTAVAIL;\r\nmemcpy(dev->dev_addr, addr->sa_data, dev->addr_len);\r\nmutex_lock(&team->lock);\r\nlist_for_each_entry(port, &team->port_list, list)\r\nif (team->ops.port_change_dev_addr)\r\nteam->ops.port_change_dev_addr(team, port);\r\nmutex_unlock(&team->lock);\r\nreturn 0;\r\n}\r\nstatic int team_change_mtu(struct net_device *dev, int new_mtu)\r\n{\r\nstruct team *team = netdev_priv(dev);\r\nstruct team_port *port;\r\nint err;\r\nmutex_lock(&team->lock);\r\nteam->port_mtu_change_allowed = true;\r\nlist_for_each_entry(port, &team->port_list, list) {\r\nerr = dev_set_mtu(port->dev, new_mtu);\r\nif (err) {\r\nnetdev_err(dev, "Device %s failed to change mtu",\r\nport->dev->name);\r\ngoto unwind;\r\n}\r\n}\r\nteam->port_mtu_change_allowed = false;\r\nmutex_unlock(&team->lock);\r\ndev->mtu = new_mtu;\r\nreturn 0;\r\nunwind:\r\nlist_for_each_entry_continue_reverse(port, &team->port_list, list)\r\ndev_set_mtu(port->dev, dev->mtu);\r\nteam->port_mtu_change_allowed = false;\r\nmutex_unlock(&team->lock);\r\nreturn err;\r\n}\r\nstatic struct rtnl_link_stats64 *\r\nteam_get_stats64(struct net_device *dev, struct rtnl_link_stats64 *stats)\r\n{\r\nstruct team *team = netdev_priv(dev);\r\nstruct team_pcpu_stats *p;\r\nu64 rx_packets, rx_bytes, rx_multicast, tx_packets, tx_bytes;\r\nu32 rx_dropped = 0, tx_dropped = 0, rx_nohandler = 0;\r\nunsigned int start;\r\nint i;\r\nfor_each_possible_cpu(i) {\r\np = per_cpu_ptr(team->pcpu_stats, i);\r\ndo {\r\nstart = u64_stats_fetch_begin_irq(&p->syncp);\r\nrx_packets = p->rx_packets;\r\nrx_bytes = p->rx_bytes;\r\nrx_multicast = p->rx_multicast;\r\ntx_packets = p->tx_packets;\r\ntx_bytes = p->tx_bytes;\r\n} while (u64_stats_fetch_retry_irq(&p->syncp, start));\r\nstats->rx_packets += rx_packets;\r\nstats->rx_bytes += rx_bytes;\r\nstats->multicast += rx_multicast;\r\nstats->tx_packets += tx_packets;\r\nstats->tx_bytes += tx_bytes;\r\nrx_dropped += p->rx_dropped;\r\ntx_dropped += p->tx_dropped;\r\nrx_nohandler += p->rx_nohandler;\r\n}\r\nstats->rx_dropped = rx_dropped;\r\nstats->tx_dropped = tx_dropped;\r\nstats->rx_nohandler = rx_nohandler;\r\nreturn stats;\r\n}\r\nstatic int team_vlan_rx_add_vid(struct net_device *dev, __be16 proto, u16 vid)\r\n{\r\nstruct team *team = netdev_priv(dev);\r\nstruct team_port *port;\r\nint err;\r\nmutex_lock(&team->lock);\r\nlist_for_each_entry(port, &team->port_list, list) {\r\nerr = vlan_vid_add(port->dev, proto, vid);\r\nif (err)\r\ngoto unwind;\r\n}\r\nmutex_unlock(&team->lock);\r\nreturn 0;\r\nunwind:\r\nlist_for_each_entry_continue_reverse(port, &team->port_list, list)\r\nvlan_vid_del(port->dev, proto, vid);\r\nmutex_unlock(&team->lock);\r\nreturn err;\r\n}\r\nstatic int team_vlan_rx_kill_vid(struct net_device *dev, __be16 proto, u16 vid)\r\n{\r\nstruct team *team = netdev_priv(dev);\r\nstruct team_port *port;\r\nmutex_lock(&team->lock);\r\nlist_for_each_entry(port, &team->port_list, list)\r\nvlan_vid_del(port->dev, proto, vid);\r\nmutex_unlock(&team->lock);\r\nreturn 0;\r\n}\r\nstatic void team_poll_controller(struct net_device *dev)\r\n{\r\n}\r\nstatic void __team_netpoll_cleanup(struct team *team)\r\n{\r\nstruct team_port *port;\r\nlist_for_each_entry(port, &team->port_list, list)\r\nteam_port_disable_netpoll(port);\r\n}\r\nstatic void team_netpoll_cleanup(struct net_device *dev)\r\n{\r\nstruct team *team = netdev_priv(dev);\r\nmutex_lock(&team->lock);\r\n__team_netpoll_cleanup(team);\r\nmutex_unlock(&team->lock);\r\n}\r\nstatic int team_netpoll_setup(struct net_device *dev,\r\nstruct netpoll_info *npifo)\r\n{\r\nstruct team *team = netdev_priv(dev);\r\nstruct team_port *port;\r\nint err = 0;\r\nmutex_lock(&team->lock);\r\nlist_for_each_entry(port, &team->port_list, list) {\r\nerr = team_port_enable_netpoll(team, port);\r\nif (err) {\r\n__team_netpoll_cleanup(team);\r\nbreak;\r\n}\r\n}\r\nmutex_unlock(&team->lock);\r\nreturn err;\r\n}\r\nstatic int team_add_slave(struct net_device *dev, struct net_device *port_dev)\r\n{\r\nstruct team *team = netdev_priv(dev);\r\nint err;\r\nmutex_lock(&team->lock);\r\nerr = team_port_add(team, port_dev);\r\nmutex_unlock(&team->lock);\r\nreturn err;\r\n}\r\nstatic int team_del_slave(struct net_device *dev, struct net_device *port_dev)\r\n{\r\nstruct team *team = netdev_priv(dev);\r\nint err;\r\nmutex_lock(&team->lock);\r\nerr = team_port_del(team, port_dev);\r\nmutex_unlock(&team->lock);\r\nreturn err;\r\n}\r\nstatic netdev_features_t team_fix_features(struct net_device *dev,\r\nnetdev_features_t features)\r\n{\r\nstruct team_port *port;\r\nstruct team *team = netdev_priv(dev);\r\nnetdev_features_t mask;\r\nmask = features;\r\nfeatures &= ~NETIF_F_ONE_FOR_ALL;\r\nfeatures |= NETIF_F_ALL_FOR_ALL;\r\nrcu_read_lock();\r\nlist_for_each_entry_rcu(port, &team->port_list, list) {\r\nfeatures = netdev_increment_features(features,\r\nport->dev->features,\r\nmask);\r\n}\r\nrcu_read_unlock();\r\nfeatures = netdev_add_tso_features(features, mask);\r\nreturn features;\r\n}\r\nstatic int team_change_carrier(struct net_device *dev, bool new_carrier)\r\n{\r\nstruct team *team = netdev_priv(dev);\r\nteam->user_carrier_enabled = true;\r\nif (new_carrier)\r\nnetif_carrier_on(dev);\r\nelse\r\nnetif_carrier_off(dev);\r\nreturn 0;\r\n}\r\nstatic void team_ethtool_get_drvinfo(struct net_device *dev,\r\nstruct ethtool_drvinfo *drvinfo)\r\n{\r\nstrlcpy(drvinfo->driver, DRV_NAME, sizeof(drvinfo->driver));\r\nstrlcpy(drvinfo->version, UTS_RELEASE, sizeof(drvinfo->version));\r\n}\r\nstatic void team_setup_by_port(struct net_device *dev,\r\nstruct net_device *port_dev)\r\n{\r\ndev->header_ops = port_dev->header_ops;\r\ndev->type = port_dev->type;\r\ndev->hard_header_len = port_dev->hard_header_len;\r\ndev->addr_len = port_dev->addr_len;\r\ndev->mtu = port_dev->mtu;\r\nmemcpy(dev->broadcast, port_dev->broadcast, port_dev->addr_len);\r\neth_hw_addr_inherit(dev, port_dev);\r\n}\r\nstatic int team_dev_type_check_change(struct net_device *dev,\r\nstruct net_device *port_dev)\r\n{\r\nstruct team *team = netdev_priv(dev);\r\nchar *portname = port_dev->name;\r\nint err;\r\nif (dev->type == port_dev->type)\r\nreturn 0;\r\nif (!list_empty(&team->port_list)) {\r\nnetdev_err(dev, "Device %s is of different type\n", portname);\r\nreturn -EBUSY;\r\n}\r\nerr = call_netdevice_notifiers(NETDEV_PRE_TYPE_CHANGE, dev);\r\nerr = notifier_to_errno(err);\r\nif (err) {\r\nnetdev_err(dev, "Refused to change device type\n");\r\nreturn err;\r\n}\r\ndev_uc_flush(dev);\r\ndev_mc_flush(dev);\r\nteam_setup_by_port(dev, port_dev);\r\ncall_netdevice_notifiers(NETDEV_POST_TYPE_CHANGE, dev);\r\nreturn 0;\r\n}\r\nstatic void team_setup(struct net_device *dev)\r\n{\r\nether_setup(dev);\r\ndev->netdev_ops = &team_netdev_ops;\r\ndev->ethtool_ops = &team_ethtool_ops;\r\ndev->destructor = team_destructor;\r\ndev->priv_flags &= ~(IFF_XMIT_DST_RELEASE | IFF_TX_SKB_SHARING);\r\ndev->priv_flags |= IFF_NO_QUEUE;\r\ndev->priv_flags |= IFF_TEAM;\r\ndev->priv_flags |= IFF_UNICAST_FLT | IFF_LIVE_ADDR_CHANGE;\r\ndev->features |= NETIF_F_LLTX;\r\ndev->features |= NETIF_F_GRO;\r\ndev->features |= NETIF_F_NETNS_LOCAL;\r\ndev->hw_features = TEAM_VLAN_FEATURES |\r\nNETIF_F_HW_VLAN_CTAG_TX |\r\nNETIF_F_HW_VLAN_CTAG_RX |\r\nNETIF_F_HW_VLAN_CTAG_FILTER;\r\ndev->hw_features |= NETIF_F_GSO_ENCAP_ALL;\r\ndev->features |= dev->hw_features;\r\n}\r\nstatic int team_newlink(struct net *src_net, struct net_device *dev,\r\nstruct nlattr *tb[], struct nlattr *data[])\r\n{\r\nif (tb[IFLA_ADDRESS] == NULL)\r\neth_hw_addr_random(dev);\r\nreturn register_netdevice(dev);\r\n}\r\nstatic int team_validate(struct nlattr *tb[], struct nlattr *data[])\r\n{\r\nif (tb[IFLA_ADDRESS]) {\r\nif (nla_len(tb[IFLA_ADDRESS]) != ETH_ALEN)\r\nreturn -EINVAL;\r\nif (!is_valid_ether_addr(nla_data(tb[IFLA_ADDRESS])))\r\nreturn -EADDRNOTAVAIL;\r\n}\r\nreturn 0;\r\n}\r\nstatic unsigned int team_get_num_tx_queues(void)\r\n{\r\nreturn TEAM_DEFAULT_NUM_TX_QUEUES;\r\n}\r\nstatic unsigned int team_get_num_rx_queues(void)\r\n{\r\nreturn TEAM_DEFAULT_NUM_RX_QUEUES;\r\n}\r\nstatic int team_nl_cmd_noop(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nstruct sk_buff *msg;\r\nvoid *hdr;\r\nint err;\r\nmsg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);\r\nif (!msg)\r\nreturn -ENOMEM;\r\nhdr = genlmsg_put(msg, info->snd_portid, info->snd_seq,\r\n&team_nl_family, 0, TEAM_CMD_NOOP);\r\nif (!hdr) {\r\nerr = -EMSGSIZE;\r\ngoto err_msg_put;\r\n}\r\ngenlmsg_end(msg, hdr);\r\nreturn genlmsg_unicast(genl_info_net(info), msg, info->snd_portid);\r\nerr_msg_put:\r\nnlmsg_free(msg);\r\nreturn err;\r\n}\r\nstatic struct team *team_nl_team_get(struct genl_info *info)\r\n{\r\nstruct net *net = genl_info_net(info);\r\nint ifindex;\r\nstruct net_device *dev;\r\nstruct team *team;\r\nif (!info->attrs[TEAM_ATTR_TEAM_IFINDEX])\r\nreturn NULL;\r\nifindex = nla_get_u32(info->attrs[TEAM_ATTR_TEAM_IFINDEX]);\r\ndev = dev_get_by_index(net, ifindex);\r\nif (!dev || dev->netdev_ops != &team_netdev_ops) {\r\nif (dev)\r\ndev_put(dev);\r\nreturn NULL;\r\n}\r\nteam = netdev_priv(dev);\r\nmutex_lock(&team->lock);\r\nreturn team;\r\n}\r\nstatic void team_nl_team_put(struct team *team)\r\n{\r\nmutex_unlock(&team->lock);\r\ndev_put(team->dev);\r\n}\r\nstatic int team_nl_send_unicast(struct sk_buff *skb, struct team *team, u32 portid)\r\n{\r\nreturn genlmsg_unicast(dev_net(team->dev), skb, portid);\r\n}\r\nstatic int team_nl_fill_one_option_get(struct sk_buff *skb, struct team *team,\r\nstruct team_option_inst *opt_inst)\r\n{\r\nstruct nlattr *option_item;\r\nstruct team_option *option = opt_inst->option;\r\nstruct team_option_inst_info *opt_inst_info = &opt_inst->info;\r\nstruct team_gsetter_ctx ctx;\r\nint err;\r\nctx.info = opt_inst_info;\r\nerr = team_option_get(team, opt_inst, &ctx);\r\nif (err)\r\nreturn err;\r\noption_item = nla_nest_start(skb, TEAM_ATTR_ITEM_OPTION);\r\nif (!option_item)\r\nreturn -EMSGSIZE;\r\nif (nla_put_string(skb, TEAM_ATTR_OPTION_NAME, option->name))\r\ngoto nest_cancel;\r\nif (opt_inst_info->port &&\r\nnla_put_u32(skb, TEAM_ATTR_OPTION_PORT_IFINDEX,\r\nopt_inst_info->port->dev->ifindex))\r\ngoto nest_cancel;\r\nif (opt_inst->option->array_size &&\r\nnla_put_u32(skb, TEAM_ATTR_OPTION_ARRAY_INDEX,\r\nopt_inst_info->array_index))\r\ngoto nest_cancel;\r\nswitch (option->type) {\r\ncase TEAM_OPTION_TYPE_U32:\r\nif (nla_put_u8(skb, TEAM_ATTR_OPTION_TYPE, NLA_U32))\r\ngoto nest_cancel;\r\nif (nla_put_u32(skb, TEAM_ATTR_OPTION_DATA, ctx.data.u32_val))\r\ngoto nest_cancel;\r\nbreak;\r\ncase TEAM_OPTION_TYPE_STRING:\r\nif (nla_put_u8(skb, TEAM_ATTR_OPTION_TYPE, NLA_STRING))\r\ngoto nest_cancel;\r\nif (nla_put_string(skb, TEAM_ATTR_OPTION_DATA,\r\nctx.data.str_val))\r\ngoto nest_cancel;\r\nbreak;\r\ncase TEAM_OPTION_TYPE_BINARY:\r\nif (nla_put_u8(skb, TEAM_ATTR_OPTION_TYPE, NLA_BINARY))\r\ngoto nest_cancel;\r\nif (nla_put(skb, TEAM_ATTR_OPTION_DATA, ctx.data.bin_val.len,\r\nctx.data.bin_val.ptr))\r\ngoto nest_cancel;\r\nbreak;\r\ncase TEAM_OPTION_TYPE_BOOL:\r\nif (nla_put_u8(skb, TEAM_ATTR_OPTION_TYPE, NLA_FLAG))\r\ngoto nest_cancel;\r\nif (ctx.data.bool_val &&\r\nnla_put_flag(skb, TEAM_ATTR_OPTION_DATA))\r\ngoto nest_cancel;\r\nbreak;\r\ncase TEAM_OPTION_TYPE_S32:\r\nif (nla_put_u8(skb, TEAM_ATTR_OPTION_TYPE, NLA_S32))\r\ngoto nest_cancel;\r\nif (nla_put_s32(skb, TEAM_ATTR_OPTION_DATA, ctx.data.s32_val))\r\ngoto nest_cancel;\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\nif (opt_inst->removed && nla_put_flag(skb, TEAM_ATTR_OPTION_REMOVED))\r\ngoto nest_cancel;\r\nif (opt_inst->changed) {\r\nif (nla_put_flag(skb, TEAM_ATTR_OPTION_CHANGED))\r\ngoto nest_cancel;\r\nopt_inst->changed = false;\r\n}\r\nnla_nest_end(skb, option_item);\r\nreturn 0;\r\nnest_cancel:\r\nnla_nest_cancel(skb, option_item);\r\nreturn -EMSGSIZE;\r\n}\r\nstatic int __send_and_alloc_skb(struct sk_buff **pskb,\r\nstruct team *team, u32 portid,\r\nteam_nl_send_func_t *send_func)\r\n{\r\nint err;\r\nif (*pskb) {\r\nerr = send_func(*pskb, team, portid);\r\nif (err)\r\nreturn err;\r\n}\r\n*pskb = genlmsg_new(GENLMSG_DEFAULT_SIZE, GFP_KERNEL);\r\nif (!*pskb)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nstatic int team_nl_send_options_get(struct team *team, u32 portid, u32 seq,\r\nint flags, team_nl_send_func_t *send_func,\r\nstruct list_head *sel_opt_inst_list)\r\n{\r\nstruct nlattr *option_list;\r\nstruct nlmsghdr *nlh;\r\nvoid *hdr;\r\nstruct team_option_inst *opt_inst;\r\nint err;\r\nstruct sk_buff *skb = NULL;\r\nbool incomplete;\r\nint i;\r\nopt_inst = list_first_entry(sel_opt_inst_list,\r\nstruct team_option_inst, tmp_list);\r\nstart_again:\r\nerr = __send_and_alloc_skb(&skb, team, portid, send_func);\r\nif (err)\r\nreturn err;\r\nhdr = genlmsg_put(skb, portid, seq, &team_nl_family, flags | NLM_F_MULTI,\r\nTEAM_CMD_OPTIONS_GET);\r\nif (!hdr)\r\nreturn -EMSGSIZE;\r\nif (nla_put_u32(skb, TEAM_ATTR_TEAM_IFINDEX, team->dev->ifindex))\r\ngoto nla_put_failure;\r\noption_list = nla_nest_start(skb, TEAM_ATTR_LIST_OPTION);\r\nif (!option_list)\r\ngoto nla_put_failure;\r\ni = 0;\r\nincomplete = false;\r\nlist_for_each_entry_from(opt_inst, sel_opt_inst_list, tmp_list) {\r\nerr = team_nl_fill_one_option_get(skb, team, opt_inst);\r\nif (err) {\r\nif (err == -EMSGSIZE) {\r\nif (!i)\r\ngoto errout;\r\nincomplete = true;\r\nbreak;\r\n}\r\ngoto errout;\r\n}\r\ni++;\r\n}\r\nnla_nest_end(skb, option_list);\r\ngenlmsg_end(skb, hdr);\r\nif (incomplete)\r\ngoto start_again;\r\nsend_done:\r\nnlh = nlmsg_put(skb, portid, seq, NLMSG_DONE, 0, flags | NLM_F_MULTI);\r\nif (!nlh) {\r\nerr = __send_and_alloc_skb(&skb, team, portid, send_func);\r\nif (err)\r\ngoto errout;\r\ngoto send_done;\r\n}\r\nreturn send_func(skb, team, portid);\r\nnla_put_failure:\r\nerr = -EMSGSIZE;\r\nerrout:\r\ngenlmsg_cancel(skb, hdr);\r\nnlmsg_free(skb);\r\nreturn err;\r\n}\r\nstatic int team_nl_cmd_options_get(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nstruct team *team;\r\nstruct team_option_inst *opt_inst;\r\nint err;\r\nLIST_HEAD(sel_opt_inst_list);\r\nteam = team_nl_team_get(info);\r\nif (!team)\r\nreturn -EINVAL;\r\nlist_for_each_entry(opt_inst, &team->option_inst_list, list)\r\nlist_add_tail(&opt_inst->tmp_list, &sel_opt_inst_list);\r\nerr = team_nl_send_options_get(team, info->snd_portid, info->snd_seq,\r\nNLM_F_ACK, team_nl_send_unicast,\r\n&sel_opt_inst_list);\r\nteam_nl_team_put(team);\r\nreturn err;\r\n}\r\nstatic int team_nl_cmd_options_set(struct sk_buff *skb, struct genl_info *info)\r\n{\r\nstruct team *team;\r\nint err = 0;\r\nint i;\r\nstruct nlattr *nl_option;\r\nLIST_HEAD(opt_inst_list);\r\nrtnl_lock();\r\nteam = team_nl_team_get(info);\r\nif (!team) {\r\nerr = -EINVAL;\r\ngoto rtnl_unlock;\r\n}\r\nerr = -EINVAL;\r\nif (!info->attrs[TEAM_ATTR_LIST_OPTION]) {\r\nerr = -EINVAL;\r\ngoto team_put;\r\n}\r\nnla_for_each_nested(nl_option, info->attrs[TEAM_ATTR_LIST_OPTION], i) {\r\nstruct nlattr *opt_attrs[TEAM_ATTR_OPTION_MAX + 1];\r\nstruct nlattr *attr;\r\nstruct nlattr *attr_data;\r\nenum team_option_type opt_type;\r\nint opt_port_ifindex = 0;\r\nu32 opt_array_index = 0;\r\nbool opt_is_array = false;\r\nstruct team_option_inst *opt_inst;\r\nchar *opt_name;\r\nbool opt_found = false;\r\nif (nla_type(nl_option) != TEAM_ATTR_ITEM_OPTION) {\r\nerr = -EINVAL;\r\ngoto team_put;\r\n}\r\nerr = nla_parse_nested(opt_attrs, TEAM_ATTR_OPTION_MAX,\r\nnl_option, team_nl_option_policy);\r\nif (err)\r\ngoto team_put;\r\nif (!opt_attrs[TEAM_ATTR_OPTION_NAME] ||\r\n!opt_attrs[TEAM_ATTR_OPTION_TYPE]) {\r\nerr = -EINVAL;\r\ngoto team_put;\r\n}\r\nswitch (nla_get_u8(opt_attrs[TEAM_ATTR_OPTION_TYPE])) {\r\ncase NLA_U32:\r\nopt_type = TEAM_OPTION_TYPE_U32;\r\nbreak;\r\ncase NLA_STRING:\r\nopt_type = TEAM_OPTION_TYPE_STRING;\r\nbreak;\r\ncase NLA_BINARY:\r\nopt_type = TEAM_OPTION_TYPE_BINARY;\r\nbreak;\r\ncase NLA_FLAG:\r\nopt_type = TEAM_OPTION_TYPE_BOOL;\r\nbreak;\r\ncase NLA_S32:\r\nopt_type = TEAM_OPTION_TYPE_S32;\r\nbreak;\r\ndefault:\r\ngoto team_put;\r\n}\r\nattr_data = opt_attrs[TEAM_ATTR_OPTION_DATA];\r\nif (opt_type != TEAM_OPTION_TYPE_BOOL && !attr_data) {\r\nerr = -EINVAL;\r\ngoto team_put;\r\n}\r\nopt_name = nla_data(opt_attrs[TEAM_ATTR_OPTION_NAME]);\r\nattr = opt_attrs[TEAM_ATTR_OPTION_PORT_IFINDEX];\r\nif (attr)\r\nopt_port_ifindex = nla_get_u32(attr);\r\nattr = opt_attrs[TEAM_ATTR_OPTION_ARRAY_INDEX];\r\nif (attr) {\r\nopt_is_array = true;\r\nopt_array_index = nla_get_u32(attr);\r\n}\r\nlist_for_each_entry(opt_inst, &team->option_inst_list, list) {\r\nstruct team_option *option = opt_inst->option;\r\nstruct team_gsetter_ctx ctx;\r\nstruct team_option_inst_info *opt_inst_info;\r\nint tmp_ifindex;\r\nopt_inst_info = &opt_inst->info;\r\ntmp_ifindex = opt_inst_info->port ?\r\nopt_inst_info->port->dev->ifindex : 0;\r\nif (option->type != opt_type ||\r\nstrcmp(option->name, opt_name) ||\r\ntmp_ifindex != opt_port_ifindex ||\r\n(option->array_size && !opt_is_array) ||\r\nopt_inst_info->array_index != opt_array_index)\r\ncontinue;\r\nopt_found = true;\r\nctx.info = opt_inst_info;\r\nswitch (opt_type) {\r\ncase TEAM_OPTION_TYPE_U32:\r\nctx.data.u32_val = nla_get_u32(attr_data);\r\nbreak;\r\ncase TEAM_OPTION_TYPE_STRING:\r\nif (nla_len(attr_data) > TEAM_STRING_MAX_LEN) {\r\nerr = -EINVAL;\r\ngoto team_put;\r\n}\r\nctx.data.str_val = nla_data(attr_data);\r\nbreak;\r\ncase TEAM_OPTION_TYPE_BINARY:\r\nctx.data.bin_val.len = nla_len(attr_data);\r\nctx.data.bin_val.ptr = nla_data(attr_data);\r\nbreak;\r\ncase TEAM_OPTION_TYPE_BOOL:\r\nctx.data.bool_val = attr_data ? true : false;\r\nbreak;\r\ncase TEAM_OPTION_TYPE_S32:\r\nctx.data.s32_val = nla_get_s32(attr_data);\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\nerr = team_option_set(team, opt_inst, &ctx);\r\nif (err)\r\ngoto team_put;\r\nopt_inst->changed = true;\r\nlist_add(&opt_inst->tmp_list, &opt_inst_list);\r\n}\r\nif (!opt_found) {\r\nerr = -ENOENT;\r\ngoto team_put;\r\n}\r\n}\r\nerr = team_nl_send_event_options_get(team, &opt_inst_list);\r\nteam_put:\r\nteam_nl_team_put(team);\r\nrtnl_unlock:\r\nrtnl_unlock();\r\nreturn err;\r\n}\r\nstatic int team_nl_fill_one_port_get(struct sk_buff *skb,\r\nstruct team_port *port)\r\n{\r\nstruct nlattr *port_item;\r\nport_item = nla_nest_start(skb, TEAM_ATTR_ITEM_PORT);\r\nif (!port_item)\r\ngoto nest_cancel;\r\nif (nla_put_u32(skb, TEAM_ATTR_PORT_IFINDEX, port->dev->ifindex))\r\ngoto nest_cancel;\r\nif (port->changed) {\r\nif (nla_put_flag(skb, TEAM_ATTR_PORT_CHANGED))\r\ngoto nest_cancel;\r\nport->changed = false;\r\n}\r\nif ((port->removed &&\r\nnla_put_flag(skb, TEAM_ATTR_PORT_REMOVED)) ||\r\n(port->state.linkup &&\r\nnla_put_flag(skb, TEAM_ATTR_PORT_LINKUP)) ||\r\nnla_put_u32(skb, TEAM_ATTR_PORT_SPEED, port->state.speed) ||\r\nnla_put_u8(skb, TEAM_ATTR_PORT_DUPLEX, port->state.duplex))\r\ngoto nest_cancel;\r\nnla_nest_end(skb, port_item);\r\nreturn 0;\r\nnest_cancel:\r\nnla_nest_cancel(skb, port_item);\r\nreturn -EMSGSIZE;\r\n}\r\nstatic int team_nl_send_port_list_get(struct team *team, u32 portid, u32 seq,\r\nint flags, team_nl_send_func_t *send_func,\r\nstruct team_port *one_port)\r\n{\r\nstruct nlattr *port_list;\r\nstruct nlmsghdr *nlh;\r\nvoid *hdr;\r\nstruct team_port *port;\r\nint err;\r\nstruct sk_buff *skb = NULL;\r\nbool incomplete;\r\nint i;\r\nport = list_first_entry_or_null(&team->port_list,\r\nstruct team_port, list);\r\nstart_again:\r\nerr = __send_and_alloc_skb(&skb, team, portid, send_func);\r\nif (err)\r\nreturn err;\r\nhdr = genlmsg_put(skb, portid, seq, &team_nl_family, flags | NLM_F_MULTI,\r\nTEAM_CMD_PORT_LIST_GET);\r\nif (!hdr)\r\nreturn -EMSGSIZE;\r\nif (nla_put_u32(skb, TEAM_ATTR_TEAM_IFINDEX, team->dev->ifindex))\r\ngoto nla_put_failure;\r\nport_list = nla_nest_start(skb, TEAM_ATTR_LIST_PORT);\r\nif (!port_list)\r\ngoto nla_put_failure;\r\ni = 0;\r\nincomplete = false;\r\nif (one_port) {\r\nerr = team_nl_fill_one_port_get(skb, one_port);\r\nif (err)\r\ngoto errout;\r\n} else if (port) {\r\nlist_for_each_entry_from(port, &team->port_list, list) {\r\nerr = team_nl_fill_one_port_get(skb, port);\r\nif (err) {\r\nif (err == -EMSGSIZE) {\r\nif (!i)\r\ngoto errout;\r\nincomplete = true;\r\nbreak;\r\n}\r\ngoto errout;\r\n}\r\ni++;\r\n}\r\n}\r\nnla_nest_end(skb, port_list);\r\ngenlmsg_end(skb, hdr);\r\nif (incomplete)\r\ngoto start_again;\r\nsend_done:\r\nnlh = nlmsg_put(skb, portid, seq, NLMSG_DONE, 0, flags | NLM_F_MULTI);\r\nif (!nlh) {\r\nerr = __send_and_alloc_skb(&skb, team, portid, send_func);\r\nif (err)\r\ngoto errout;\r\ngoto send_done;\r\n}\r\nreturn send_func(skb, team, portid);\r\nnla_put_failure:\r\nerr = -EMSGSIZE;\r\nerrout:\r\ngenlmsg_cancel(skb, hdr);\r\nnlmsg_free(skb);\r\nreturn err;\r\n}\r\nstatic int team_nl_cmd_port_list_get(struct sk_buff *skb,\r\nstruct genl_info *info)\r\n{\r\nstruct team *team;\r\nint err;\r\nteam = team_nl_team_get(info);\r\nif (!team)\r\nreturn -EINVAL;\r\nerr = team_nl_send_port_list_get(team, info->snd_portid, info->snd_seq,\r\nNLM_F_ACK, team_nl_send_unicast, NULL);\r\nteam_nl_team_put(team);\r\nreturn err;\r\n}\r\nstatic int team_nl_send_multicast(struct sk_buff *skb,\r\nstruct team *team, u32 portid)\r\n{\r\nreturn genlmsg_multicast_netns(&team_nl_family, dev_net(team->dev),\r\nskb, 0, 0, GFP_KERNEL);\r\n}\r\nstatic int team_nl_send_event_options_get(struct team *team,\r\nstruct list_head *sel_opt_inst_list)\r\n{\r\nreturn team_nl_send_options_get(team, 0, 0, 0, team_nl_send_multicast,\r\nsel_opt_inst_list);\r\n}\r\nstatic int team_nl_send_event_port_get(struct team *team,\r\nstruct team_port *port)\r\n{\r\nreturn team_nl_send_port_list_get(team, 0, 0, 0, team_nl_send_multicast,\r\nport);\r\n}\r\nstatic int team_nl_init(void)\r\n{\r\nreturn genl_register_family_with_ops_groups(&team_nl_family, team_nl_ops,\r\nteam_nl_mcgrps);\r\n}\r\nstatic void team_nl_fini(void)\r\n{\r\ngenl_unregister_family(&team_nl_family);\r\n}\r\nstatic void __team_options_change_check(struct team *team)\r\n{\r\nint err;\r\nstruct team_option_inst *opt_inst;\r\nLIST_HEAD(sel_opt_inst_list);\r\nlist_for_each_entry(opt_inst, &team->option_inst_list, list) {\r\nif (opt_inst->changed)\r\nlist_add_tail(&opt_inst->tmp_list, &sel_opt_inst_list);\r\n}\r\nerr = team_nl_send_event_options_get(team, &sel_opt_inst_list);\r\nif (err && err != -ESRCH)\r\nnetdev_warn(team->dev, "Failed to send options change via netlink (err %d)\n",\r\nerr);\r\n}\r\nstatic void __team_port_change_send(struct team_port *port, bool linkup)\r\n{\r\nint err;\r\nport->changed = true;\r\nport->state.linkup = linkup;\r\nteam_refresh_port_linkup(port);\r\nif (linkup) {\r\nstruct ethtool_link_ksettings ecmd;\r\nerr = __ethtool_get_link_ksettings(port->dev, &ecmd);\r\nif (!err) {\r\nport->state.speed = ecmd.base.speed;\r\nport->state.duplex = ecmd.base.duplex;\r\ngoto send_event;\r\n}\r\n}\r\nport->state.speed = 0;\r\nport->state.duplex = 0;\r\nsend_event:\r\nerr = team_nl_send_event_port_get(port->team, port);\r\nif (err && err != -ESRCH)\r\nnetdev_warn(port->team->dev, "Failed to send port change of device %s via netlink (err %d)\n",\r\nport->dev->name, err);\r\n}\r\nstatic void __team_carrier_check(struct team *team)\r\n{\r\nstruct team_port *port;\r\nbool team_linkup;\r\nif (team->user_carrier_enabled)\r\nreturn;\r\nteam_linkup = false;\r\nlist_for_each_entry(port, &team->port_list, list) {\r\nif (port->linkup) {\r\nteam_linkup = true;\r\nbreak;\r\n}\r\n}\r\nif (team_linkup)\r\nnetif_carrier_on(team->dev);\r\nelse\r\nnetif_carrier_off(team->dev);\r\n}\r\nstatic void __team_port_change_check(struct team_port *port, bool linkup)\r\n{\r\nif (port->state.linkup != linkup)\r\n__team_port_change_send(port, linkup);\r\n__team_carrier_check(port->team);\r\n}\r\nstatic void __team_port_change_port_added(struct team_port *port, bool linkup)\r\n{\r\n__team_port_change_send(port, linkup);\r\n__team_carrier_check(port->team);\r\n}\r\nstatic void __team_port_change_port_removed(struct team_port *port)\r\n{\r\nport->removed = true;\r\n__team_port_change_send(port, false);\r\n__team_carrier_check(port->team);\r\n}\r\nstatic void team_port_change_check(struct team_port *port, bool linkup)\r\n{\r\nstruct team *team = port->team;\r\nmutex_lock(&team->lock);\r\n__team_port_change_check(port, linkup);\r\nmutex_unlock(&team->lock);\r\n}\r\nstatic int team_device_event(struct notifier_block *unused,\r\nunsigned long event, void *ptr)\r\n{\r\nstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\r\nstruct team_port *port;\r\nport = team_port_get_rtnl(dev);\r\nif (!port)\r\nreturn NOTIFY_DONE;\r\nswitch (event) {\r\ncase NETDEV_UP:\r\nif (netif_carrier_ok(dev))\r\nteam_port_change_check(port, true);\r\nbreak;\r\ncase NETDEV_DOWN:\r\nteam_port_change_check(port, false);\r\nbreak;\r\ncase NETDEV_CHANGE:\r\nif (netif_running(port->dev))\r\nteam_port_change_check(port,\r\n!!netif_carrier_ok(port->dev));\r\nbreak;\r\ncase NETDEV_UNREGISTER:\r\nteam_del_slave(port->team->dev, dev);\r\nbreak;\r\ncase NETDEV_FEAT_CHANGE:\r\nteam_compute_features(port->team);\r\nbreak;\r\ncase NETDEV_PRECHANGEMTU:\r\nif (!port->team->port_mtu_change_allowed)\r\nreturn NOTIFY_BAD;\r\nbreak;\r\ncase NETDEV_PRE_TYPE_CHANGE:\r\nreturn NOTIFY_BAD;\r\ncase NETDEV_RESEND_IGMP:\r\ncall_netdevice_notifiers(event, port->team->dev);\r\nbreak;\r\n}\r\nreturn NOTIFY_DONE;\r\n}\r\nstatic int __init team_module_init(void)\r\n{\r\nint err;\r\nregister_netdevice_notifier(&team_notifier_block);\r\nerr = rtnl_link_register(&team_link_ops);\r\nif (err)\r\ngoto err_rtnl_reg;\r\nerr = team_nl_init();\r\nif (err)\r\ngoto err_nl_init;\r\nreturn 0;\r\nerr_nl_init:\r\nrtnl_link_unregister(&team_link_ops);\r\nerr_rtnl_reg:\r\nunregister_netdevice_notifier(&team_notifier_block);\r\nreturn err;\r\n}\r\nstatic void __exit team_module_exit(void)\r\n{\r\nteam_nl_fini();\r\nrtnl_link_unregister(&team_link_ops);\r\nunregister_netdevice_notifier(&team_notifier_block);\r\n}
