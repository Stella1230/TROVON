static inline struct user_lock_res *user_lksb_to_lock_res(struct ocfs2_dlm_lksb *lksb)\r\n{\r\nreturn container_of(lksb, struct user_lock_res, l_lksb);\r\n}\r\nstatic inline int user_check_wait_flag(struct user_lock_res *lockres,\r\nint flag)\r\n{\r\nint ret;\r\nspin_lock(&lockres->l_lock);\r\nret = lockres->l_flags & flag;\r\nspin_unlock(&lockres->l_lock);\r\nreturn ret;\r\n}\r\nstatic inline void user_wait_on_busy_lock(struct user_lock_res *lockres)\r\n{\r\nwait_event(lockres->l_event,\r\n!user_check_wait_flag(lockres, USER_LOCK_BUSY));\r\n}\r\nstatic inline void user_wait_on_blocked_lock(struct user_lock_res *lockres)\r\n{\r\nwait_event(lockres->l_event,\r\n!user_check_wait_flag(lockres, USER_LOCK_BLOCKED));\r\n}\r\nstatic inline struct ocfs2_cluster_connection *\r\ncluster_connection_from_user_lockres(struct user_lock_res *lockres)\r\n{\r\nstruct dlmfs_inode_private *ip;\r\nip = container_of(lockres,\r\nstruct dlmfs_inode_private,\r\nip_lockres);\r\nreturn ip->ip_conn;\r\n}\r\nstatic struct inode *\r\nuser_dlm_inode_from_user_lockres(struct user_lock_res *lockres)\r\n{\r\nstruct dlmfs_inode_private *ip;\r\nip = container_of(lockres,\r\nstruct dlmfs_inode_private,\r\nip_lockres);\r\nreturn &ip->ip_vfs_inode;\r\n}\r\nstatic inline void user_recover_from_dlm_error(struct user_lock_res *lockres)\r\n{\r\nspin_lock(&lockres->l_lock);\r\nlockres->l_flags &= ~USER_LOCK_BUSY;\r\nspin_unlock(&lockres->l_lock);\r\n}\r\nstatic inline int user_highest_compat_lock_level(int level)\r\n{\r\nint new_level = DLM_LOCK_EX;\r\nif (level == DLM_LOCK_EX)\r\nnew_level = DLM_LOCK_NL;\r\nelse if (level == DLM_LOCK_PR)\r\nnew_level = DLM_LOCK_PR;\r\nreturn new_level;\r\n}\r\nstatic void user_ast(struct ocfs2_dlm_lksb *lksb)\r\n{\r\nstruct user_lock_res *lockres = user_lksb_to_lock_res(lksb);\r\nint status;\r\nmlog(ML_BASTS, "AST fired for lockres %.*s, level %d => %d\n",\r\nlockres->l_namelen, lockres->l_name, lockres->l_level,\r\nlockres->l_requested);\r\nspin_lock(&lockres->l_lock);\r\nstatus = ocfs2_dlm_lock_status(&lockres->l_lksb);\r\nif (status) {\r\nmlog(ML_ERROR, "lksb status value of %u on lockres %.*s\n",\r\nstatus, lockres->l_namelen, lockres->l_name);\r\nspin_unlock(&lockres->l_lock);\r\nreturn;\r\n}\r\nmlog_bug_on_msg(lockres->l_requested == DLM_LOCK_IV,\r\n"Lockres %.*s, requested ivmode. flags 0x%x\n",\r\nlockres->l_namelen, lockres->l_name, lockres->l_flags);\r\nif (lockres->l_requested < lockres->l_level) {\r\nif (lockres->l_requested <=\r\nuser_highest_compat_lock_level(lockres->l_blocking)) {\r\nlockres->l_blocking = DLM_LOCK_NL;\r\nlockres->l_flags &= ~USER_LOCK_BLOCKED;\r\n}\r\n}\r\nlockres->l_level = lockres->l_requested;\r\nlockres->l_requested = DLM_LOCK_IV;\r\nlockres->l_flags |= USER_LOCK_ATTACHED;\r\nlockres->l_flags &= ~USER_LOCK_BUSY;\r\nspin_unlock(&lockres->l_lock);\r\nwake_up(&lockres->l_event);\r\n}\r\nstatic inline void user_dlm_grab_inode_ref(struct user_lock_res *lockres)\r\n{\r\nstruct inode *inode;\r\ninode = user_dlm_inode_from_user_lockres(lockres);\r\nif (!igrab(inode))\r\nBUG();\r\n}\r\nstatic void __user_dlm_queue_lockres(struct user_lock_res *lockres)\r\n{\r\nif (!(lockres->l_flags & USER_LOCK_QUEUED)) {\r\nuser_dlm_grab_inode_ref(lockres);\r\nINIT_WORK(&lockres->l_work, user_dlm_unblock_lock);\r\nqueue_work(user_dlm_worker, &lockres->l_work);\r\nlockres->l_flags |= USER_LOCK_QUEUED;\r\n}\r\n}\r\nstatic void __user_dlm_cond_queue_lockres(struct user_lock_res *lockres)\r\n{\r\nint queue = 0;\r\nif (!(lockres->l_flags & USER_LOCK_BLOCKED))\r\nreturn;\r\nswitch (lockres->l_blocking) {\r\ncase DLM_LOCK_EX:\r\nif (!lockres->l_ex_holders && !lockres->l_ro_holders)\r\nqueue = 1;\r\nbreak;\r\ncase DLM_LOCK_PR:\r\nif (!lockres->l_ex_holders)\r\nqueue = 1;\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\nif (queue)\r\n__user_dlm_queue_lockres(lockres);\r\n}\r\nstatic void user_bast(struct ocfs2_dlm_lksb *lksb, int level)\r\n{\r\nstruct user_lock_res *lockres = user_lksb_to_lock_res(lksb);\r\nmlog(ML_BASTS, "BAST fired for lockres %.*s, blocking %d, level %d\n",\r\nlockres->l_namelen, lockres->l_name, level, lockres->l_level);\r\nspin_lock(&lockres->l_lock);\r\nlockres->l_flags |= USER_LOCK_BLOCKED;\r\nif (level > lockres->l_blocking)\r\nlockres->l_blocking = level;\r\n__user_dlm_queue_lockres(lockres);\r\nspin_unlock(&lockres->l_lock);\r\nwake_up(&lockres->l_event);\r\n}\r\nstatic void user_unlock_ast(struct ocfs2_dlm_lksb *lksb, int status)\r\n{\r\nstruct user_lock_res *lockres = user_lksb_to_lock_res(lksb);\r\nmlog(ML_BASTS, "UNLOCK AST fired for lockres %.*s, flags 0x%x\n",\r\nlockres->l_namelen, lockres->l_name, lockres->l_flags);\r\nif (status)\r\nmlog(ML_ERROR, "dlm returns status %d\n", status);\r\nspin_lock(&lockres->l_lock);\r\nif (lockres->l_flags & USER_LOCK_IN_TEARDOWN\r\n&& !(lockres->l_flags & USER_LOCK_IN_CANCEL)) {\r\nlockres->l_level = DLM_LOCK_IV;\r\n} else if (status == DLM_CANCELGRANT) {\r\nBUG_ON(!(lockres->l_flags & USER_LOCK_IN_CANCEL));\r\nlockres->l_flags &= ~USER_LOCK_IN_CANCEL;\r\ngoto out_noclear;\r\n} else {\r\nBUG_ON(!(lockres->l_flags & USER_LOCK_IN_CANCEL));\r\nlockres->l_requested = DLM_LOCK_IV;\r\nlockres->l_flags &= ~USER_LOCK_IN_CANCEL;\r\nif (lockres->l_flags & USER_LOCK_BLOCKED)\r\n__user_dlm_queue_lockres(lockres);\r\n}\r\nlockres->l_flags &= ~USER_LOCK_BUSY;\r\nout_noclear:\r\nspin_unlock(&lockres->l_lock);\r\nwake_up(&lockres->l_event);\r\n}\r\nstatic inline void user_dlm_drop_inode_ref(struct user_lock_res *lockres)\r\n{\r\nstruct inode *inode;\r\ninode = user_dlm_inode_from_user_lockres(lockres);\r\niput(inode);\r\n}\r\nstatic void user_dlm_unblock_lock(struct work_struct *work)\r\n{\r\nint new_level, status;\r\nstruct user_lock_res *lockres =\r\ncontainer_of(work, struct user_lock_res, l_work);\r\nstruct ocfs2_cluster_connection *conn =\r\ncluster_connection_from_user_lockres(lockres);\r\nmlog(0, "lockres %.*s\n", lockres->l_namelen, lockres->l_name);\r\nspin_lock(&lockres->l_lock);\r\nmlog_bug_on_msg(!(lockres->l_flags & USER_LOCK_QUEUED),\r\n"Lockres %.*s, flags 0x%x\n",\r\nlockres->l_namelen, lockres->l_name, lockres->l_flags);\r\nlockres->l_flags &= ~USER_LOCK_QUEUED;\r\nif (!(lockres->l_flags & USER_LOCK_BLOCKED)) {\r\nmlog(ML_BASTS, "lockres %.*s USER_LOCK_BLOCKED\n",\r\nlockres->l_namelen, lockres->l_name);\r\nspin_unlock(&lockres->l_lock);\r\ngoto drop_ref;\r\n}\r\nif (lockres->l_flags & USER_LOCK_IN_TEARDOWN) {\r\nmlog(ML_BASTS, "lockres %.*s USER_LOCK_IN_TEARDOWN\n",\r\nlockres->l_namelen, lockres->l_name);\r\nspin_unlock(&lockres->l_lock);\r\ngoto drop_ref;\r\n}\r\nif (lockres->l_flags & USER_LOCK_BUSY) {\r\nif (lockres->l_flags & USER_LOCK_IN_CANCEL) {\r\nmlog(ML_BASTS, "lockres %.*s USER_LOCK_IN_CANCEL\n",\r\nlockres->l_namelen, lockres->l_name);\r\nspin_unlock(&lockres->l_lock);\r\ngoto drop_ref;\r\n}\r\nlockres->l_flags |= USER_LOCK_IN_CANCEL;\r\nspin_unlock(&lockres->l_lock);\r\nstatus = ocfs2_dlm_unlock(conn, &lockres->l_lksb,\r\nDLM_LKF_CANCEL);\r\nif (status)\r\nuser_log_dlm_error("ocfs2_dlm_unlock", status, lockres);\r\ngoto drop_ref;\r\n}\r\nif ((lockres->l_blocking == DLM_LOCK_EX)\r\n&& (lockres->l_ex_holders || lockres->l_ro_holders)) {\r\nspin_unlock(&lockres->l_lock);\r\nmlog(ML_BASTS, "lockres %.*s, EX/PR Holders %u,%u\n",\r\nlockres->l_namelen, lockres->l_name,\r\nlockres->l_ex_holders, lockres->l_ro_holders);\r\ngoto drop_ref;\r\n}\r\nif ((lockres->l_blocking == DLM_LOCK_PR)\r\n&& lockres->l_ex_holders) {\r\nspin_unlock(&lockres->l_lock);\r\nmlog(ML_BASTS, "lockres %.*s, EX Holders %u\n",\r\nlockres->l_namelen, lockres->l_name,\r\nlockres->l_ex_holders);\r\ngoto drop_ref;\r\n}\r\nnew_level = user_highest_compat_lock_level(lockres->l_blocking);\r\nlockres->l_requested = new_level;\r\nlockres->l_flags |= USER_LOCK_BUSY;\r\nmlog(ML_BASTS, "lockres %.*s, downconvert %d => %d\n",\r\nlockres->l_namelen, lockres->l_name, lockres->l_level, new_level);\r\nspin_unlock(&lockres->l_lock);\r\nstatus = ocfs2_dlm_lock(conn, new_level, &lockres->l_lksb,\r\nDLM_LKF_CONVERT|DLM_LKF_VALBLK,\r\nlockres->l_name,\r\nlockres->l_namelen);\r\nif (status) {\r\nuser_log_dlm_error("ocfs2_dlm_lock", status, lockres);\r\nuser_recover_from_dlm_error(lockres);\r\n}\r\ndrop_ref:\r\nuser_dlm_drop_inode_ref(lockres);\r\n}\r\nstatic inline void user_dlm_inc_holders(struct user_lock_res *lockres,\r\nint level)\r\n{\r\nswitch(level) {\r\ncase DLM_LOCK_EX:\r\nlockres->l_ex_holders++;\r\nbreak;\r\ncase DLM_LOCK_PR:\r\nlockres->l_ro_holders++;\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\n}\r\nstatic inline int\r\nuser_may_continue_on_blocked_lock(struct user_lock_res *lockres,\r\nint wanted)\r\n{\r\nBUG_ON(!(lockres->l_flags & USER_LOCK_BLOCKED));\r\nreturn wanted <= user_highest_compat_lock_level(lockres->l_blocking);\r\n}\r\nint user_dlm_cluster_lock(struct user_lock_res *lockres,\r\nint level,\r\nint lkm_flags)\r\n{\r\nint status, local_flags;\r\nstruct ocfs2_cluster_connection *conn =\r\ncluster_connection_from_user_lockres(lockres);\r\nif (level != DLM_LOCK_EX &&\r\nlevel != DLM_LOCK_PR) {\r\nmlog(ML_ERROR, "lockres %.*s: invalid request!\n",\r\nlockres->l_namelen, lockres->l_name);\r\nstatus = -EINVAL;\r\ngoto bail;\r\n}\r\nmlog(ML_BASTS, "lockres %.*s, level %d, flags = 0x%x\n",\r\nlockres->l_namelen, lockres->l_name, level, lkm_flags);\r\nagain:\r\nif (signal_pending(current)) {\r\nstatus = -ERESTARTSYS;\r\ngoto bail;\r\n}\r\nspin_lock(&lockres->l_lock);\r\nif ((lockres->l_flags & USER_LOCK_BUSY) &&\r\n(level > lockres->l_level)) {\r\nspin_unlock(&lockres->l_lock);\r\nuser_wait_on_busy_lock(lockres);\r\ngoto again;\r\n}\r\nif ((lockres->l_flags & USER_LOCK_BLOCKED) &&\r\n(!user_may_continue_on_blocked_lock(lockres, level))) {\r\nspin_unlock(&lockres->l_lock);\r\nuser_wait_on_blocked_lock(lockres);\r\ngoto again;\r\n}\r\nif (level > lockres->l_level) {\r\nlocal_flags = lkm_flags | DLM_LKF_VALBLK;\r\nif (lockres->l_level != DLM_LOCK_IV)\r\nlocal_flags |= DLM_LKF_CONVERT;\r\nlockres->l_requested = level;\r\nlockres->l_flags |= USER_LOCK_BUSY;\r\nspin_unlock(&lockres->l_lock);\r\nBUG_ON(level == DLM_LOCK_IV);\r\nBUG_ON(level == DLM_LOCK_NL);\r\nstatus = ocfs2_dlm_lock(conn, level, &lockres->l_lksb,\r\nlocal_flags, lockres->l_name,\r\nlockres->l_namelen);\r\nif (status) {\r\nif ((lkm_flags & DLM_LKF_NOQUEUE) &&\r\n(status != -EAGAIN))\r\nuser_log_dlm_error("ocfs2_dlm_lock",\r\nstatus, lockres);\r\nuser_recover_from_dlm_error(lockres);\r\ngoto bail;\r\n}\r\nuser_wait_on_busy_lock(lockres);\r\ngoto again;\r\n}\r\nuser_dlm_inc_holders(lockres, level);\r\nspin_unlock(&lockres->l_lock);\r\nstatus = 0;\r\nbail:\r\nreturn status;\r\n}\r\nstatic inline void user_dlm_dec_holders(struct user_lock_res *lockres,\r\nint level)\r\n{\r\nswitch(level) {\r\ncase DLM_LOCK_EX:\r\nBUG_ON(!lockres->l_ex_holders);\r\nlockres->l_ex_holders--;\r\nbreak;\r\ncase DLM_LOCK_PR:\r\nBUG_ON(!lockres->l_ro_holders);\r\nlockres->l_ro_holders--;\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\n}\r\nvoid user_dlm_cluster_unlock(struct user_lock_res *lockres,\r\nint level)\r\n{\r\nif (level != DLM_LOCK_EX &&\r\nlevel != DLM_LOCK_PR) {\r\nmlog(ML_ERROR, "lockres %.*s: invalid request!\n",\r\nlockres->l_namelen, lockres->l_name);\r\nreturn;\r\n}\r\nspin_lock(&lockres->l_lock);\r\nuser_dlm_dec_holders(lockres, level);\r\n__user_dlm_cond_queue_lockres(lockres);\r\nspin_unlock(&lockres->l_lock);\r\n}\r\nvoid user_dlm_write_lvb(struct inode *inode,\r\nconst char *val,\r\nunsigned int len)\r\n{\r\nstruct user_lock_res *lockres = &DLMFS_I(inode)->ip_lockres;\r\nchar *lvb;\r\nBUG_ON(len > DLM_LVB_LEN);\r\nspin_lock(&lockres->l_lock);\r\nBUG_ON(lockres->l_level < DLM_LOCK_EX);\r\nlvb = ocfs2_dlm_lvb(&lockres->l_lksb);\r\nmemcpy(lvb, val, len);\r\nspin_unlock(&lockres->l_lock);\r\n}\r\nssize_t user_dlm_read_lvb(struct inode *inode,\r\nchar *val,\r\nunsigned int len)\r\n{\r\nstruct user_lock_res *lockres = &DLMFS_I(inode)->ip_lockres;\r\nchar *lvb;\r\nssize_t ret = len;\r\nBUG_ON(len > DLM_LVB_LEN);\r\nspin_lock(&lockres->l_lock);\r\nBUG_ON(lockres->l_level < DLM_LOCK_PR);\r\nif (ocfs2_dlm_lvb_valid(&lockres->l_lksb)) {\r\nlvb = ocfs2_dlm_lvb(&lockres->l_lksb);\r\nmemcpy(val, lvb, len);\r\n} else\r\nret = 0;\r\nspin_unlock(&lockres->l_lock);\r\nreturn ret;\r\n}\r\nvoid user_dlm_lock_res_init(struct user_lock_res *lockres,\r\nstruct dentry *dentry)\r\n{\r\nmemset(lockres, 0, sizeof(*lockres));\r\nspin_lock_init(&lockres->l_lock);\r\ninit_waitqueue_head(&lockres->l_event);\r\nlockres->l_level = DLM_LOCK_IV;\r\nlockres->l_requested = DLM_LOCK_IV;\r\nlockres->l_blocking = DLM_LOCK_IV;\r\nBUG_ON(dentry->d_name.len >= USER_DLM_LOCK_ID_MAX_LEN);\r\nmemcpy(lockres->l_name,\r\ndentry->d_name.name,\r\ndentry->d_name.len);\r\nlockres->l_namelen = dentry->d_name.len;\r\n}\r\nint user_dlm_destroy_lock(struct user_lock_res *lockres)\r\n{\r\nint status = -EBUSY;\r\nstruct ocfs2_cluster_connection *conn =\r\ncluster_connection_from_user_lockres(lockres);\r\nmlog(ML_BASTS, "lockres %.*s\n", lockres->l_namelen, lockres->l_name);\r\nspin_lock(&lockres->l_lock);\r\nif (lockres->l_flags & USER_LOCK_IN_TEARDOWN) {\r\nspin_unlock(&lockres->l_lock);\r\nreturn 0;\r\n}\r\nlockres->l_flags |= USER_LOCK_IN_TEARDOWN;\r\nwhile (lockres->l_flags & USER_LOCK_BUSY) {\r\nspin_unlock(&lockres->l_lock);\r\nuser_wait_on_busy_lock(lockres);\r\nspin_lock(&lockres->l_lock);\r\n}\r\nif (lockres->l_ro_holders || lockres->l_ex_holders) {\r\nspin_unlock(&lockres->l_lock);\r\ngoto bail;\r\n}\r\nstatus = 0;\r\nif (!(lockres->l_flags & USER_LOCK_ATTACHED)) {\r\nspin_unlock(&lockres->l_lock);\r\ngoto bail;\r\n}\r\nlockres->l_flags &= ~USER_LOCK_ATTACHED;\r\nlockres->l_flags |= USER_LOCK_BUSY;\r\nspin_unlock(&lockres->l_lock);\r\nstatus = ocfs2_dlm_unlock(conn, &lockres->l_lksb, DLM_LKF_VALBLK);\r\nif (status) {\r\nuser_log_dlm_error("ocfs2_dlm_unlock", status, lockres);\r\ngoto bail;\r\n}\r\nuser_wait_on_busy_lock(lockres);\r\nstatus = 0;\r\nbail:\r\nreturn status;\r\n}\r\nstatic void user_dlm_recovery_handler_noop(int node_num,\r\nvoid *recovery_data)\r\n{\r\nreturn;\r\n}\r\nvoid user_dlm_set_locking_protocol(void)\r\n{\r\nocfs2_stack_glue_set_max_proto_version(&user_dlm_lproto.lp_max_version);\r\n}\r\nstruct ocfs2_cluster_connection *user_dlm_register(const struct qstr *name)\r\n{\r\nint rc;\r\nstruct ocfs2_cluster_connection *conn;\r\nrc = ocfs2_cluster_connect_agnostic(name->name, name->len,\r\n&user_dlm_lproto,\r\nuser_dlm_recovery_handler_noop,\r\nNULL, &conn);\r\nif (rc)\r\nmlog_errno(rc);\r\nreturn rc ? ERR_PTR(rc) : conn;\r\n}\r\nvoid user_dlm_unregister(struct ocfs2_cluster_connection *conn)\r\n{\r\nocfs2_cluster_disconnect(conn, 0);\r\n}
