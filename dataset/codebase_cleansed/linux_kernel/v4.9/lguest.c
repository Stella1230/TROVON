static bool iov_empty(const struct iovec iov[], unsigned int num_iov)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < num_iov; i++)\r\nif (iov[i].iov_len)\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic void iov_consume(struct device *d,\r\nstruct iovec iov[], unsigned num_iov,\r\nvoid *dest, unsigned len)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < num_iov; i++) {\r\nunsigned int used;\r\nused = iov[i].iov_len < len ? iov[i].iov_len : len;\r\nif (dest) {\r\nmemcpy(dest, iov[i].iov_base, used);\r\ndest += used;\r\n}\r\niov[i].iov_base += used;\r\niov[i].iov_len -= used;\r\nlen -= used;\r\n}\r\nif (len != 0)\r\nbad_driver(d, "iovec too short!");\r\n}\r\nstatic void *from_guest_phys(unsigned long addr)\r\n{\r\nreturn guest_base + addr;\r\n}\r\nstatic unsigned long to_guest_phys(const void *addr)\r\n{\r\nreturn (addr - guest_base);\r\n}\r\nstatic int open_or_die(const char *name, int flags)\r\n{\r\nint fd = open(name, flags);\r\nif (fd < 0)\r\nerr(1, "Failed to open %s", name);\r\nreturn fd;\r\n}\r\nstatic void *map_zeroed_pages(unsigned int num)\r\n{\r\nint fd = open_or_die("/dev/zero", O_RDONLY);\r\nvoid *addr;\r\naddr = mmap(NULL, getpagesize() * (num+2),\r\nPROT_NONE, MAP_PRIVATE, fd, 0);\r\nif (addr == MAP_FAILED)\r\nerr(1, "Mmapping %u pages of /dev/zero", num);\r\nif (mprotect(addr + getpagesize(), getpagesize() * num,\r\nPROT_READ|PROT_WRITE) == -1)\r\nerr(1, "mprotect rw %u pages failed", num);\r\nclose(fd);\r\nreturn addr + getpagesize();\r\n}\r\nstatic unsigned long get_mmio_region(size_t size)\r\n{\r\nunsigned long addr = guest_mmio;\r\nsize_t i;\r\nif (!size)\r\nreturn addr;\r\nfor (i = 1; i < size; i <<= 1);\r\nguest_mmio += i;\r\nreturn addr;\r\n}\r\nstatic void map_at(int fd, void *addr, unsigned long offset, unsigned long len)\r\n{\r\nssize_t r;\r\nif (mmap(addr, len, PROT_READ|PROT_WRITE,\r\nMAP_FIXED|MAP_PRIVATE, fd, offset) != MAP_FAILED)\r\nreturn;\r\nr = pread(fd, addr, len, offset);\r\nif (r != len)\r\nerr(1, "Reading offset %lu len %lu gave %zi", offset, len, r);\r\n}\r\nstatic unsigned long map_elf(int elf_fd, const Elf32_Ehdr *ehdr)\r\n{\r\nElf32_Phdr phdr[ehdr->e_phnum];\r\nunsigned int i;\r\nif (ehdr->e_type != ET_EXEC\r\n|| ehdr->e_machine != EM_386\r\n|| ehdr->e_phentsize != sizeof(Elf32_Phdr)\r\n|| ehdr->e_phnum < 1 || ehdr->e_phnum > 65536U/sizeof(Elf32_Phdr))\r\nerrx(1, "Malformed elf header");\r\nif (lseek(elf_fd, ehdr->e_phoff, SEEK_SET) < 0)\r\nerr(1, "Seeking to program headers");\r\nif (read(elf_fd, phdr, sizeof(phdr)) != sizeof(phdr))\r\nerr(1, "Reading program headers");\r\nfor (i = 0; i < ehdr->e_phnum; i++) {\r\nif (phdr[i].p_type != PT_LOAD)\r\ncontinue;\r\nverbose("Section %i: size %i addr %p\n",\r\ni, phdr[i].p_memsz, (void *)phdr[i].p_paddr);\r\nmap_at(elf_fd, from_guest_phys(phdr[i].p_paddr),\r\nphdr[i].p_offset, phdr[i].p_filesz);\r\n}\r\nreturn ehdr->e_entry;\r\n}\r\nstatic unsigned long load_bzimage(int fd)\r\n{\r\nstruct boot_params boot;\r\nint r;\r\nvoid *p = from_guest_phys(0x100000);\r\nlseek(fd, 0, SEEK_SET);\r\nread(fd, &boot, sizeof(boot));\r\nif (memcmp(&boot.hdr.header, "HdrS", 4) != 0)\r\nerrx(1, "This doesn't look like a bzImage to me");\r\nlseek(fd, (boot.hdr.setup_sects+1) * 512, SEEK_SET);\r\nwhile ((r = read(fd, p, 65536)) > 0)\r\np += r;\r\nreturn boot.hdr.code32_start;\r\n}\r\nstatic unsigned long load_kernel(int fd)\r\n{\r\nElf32_Ehdr hdr;\r\nif (read(fd, &hdr, sizeof(hdr)) != sizeof(hdr))\r\nerr(1, "Reading kernel");\r\nif (memcmp(hdr.e_ident, ELFMAG, SELFMAG) == 0)\r\nreturn map_elf(fd, &hdr);\r\nreturn load_bzimage(fd);\r\n}\r\nstatic inline unsigned long page_align(unsigned long addr)\r\n{\r\nreturn ((addr + getpagesize()-1) & ~(getpagesize()-1));\r\n}\r\nstatic unsigned long load_initrd(const char *name, unsigned long mem)\r\n{\r\nint ifd;\r\nstruct stat st;\r\nunsigned long len;\r\nifd = open_or_die(name, O_RDONLY);\r\nif (fstat(ifd, &st) < 0)\r\nerr(1, "fstat() on initrd '%s'", name);\r\nlen = page_align(st.st_size);\r\nmap_at(ifd, from_guest_phys(mem - len), 0, st.st_size);\r\nclose(ifd);\r\nverbose("mapped initrd %s size=%lu @ %p\n", name, len, (void*)mem-len);\r\nreturn len;\r\n}\r\nstatic void concat(char *dst, char *args[])\r\n{\r\nunsigned int i, len = 0;\r\nfor (i = 0; args[i]; i++) {\r\nif (i) {\r\nstrcat(dst+len, " ");\r\nlen++;\r\n}\r\nstrcpy(dst+len, args[i]);\r\nlen += strlen(args[i]);\r\n}\r\ndst[len] = '\0';\r\n}\r\nstatic void tell_kernel(unsigned long start)\r\n{\r\nunsigned long args[] = { LHREQ_INITIALIZE,\r\n(unsigned long)guest_base,\r\nguest_limit / getpagesize(), start,\r\n(guest_mmio+getpagesize()-1) / getpagesize() };\r\nverbose("Guest: %p - %p (%#lx, MMIO %#lx)\n",\r\nguest_base, guest_base + guest_limit,\r\nguest_limit, guest_mmio);\r\nlguest_fd = open_or_die("/dev/lguest", O_RDWR);\r\nif (write(lguest_fd, args, sizeof(args)) < 0)\r\nerr(1, "Writing to /dev/lguest");\r\n}\r\nstatic void *_check_pointer(struct device *d,\r\nunsigned long addr, unsigned int size,\r\nunsigned int line)\r\n{\r\nif ((addr + size) > guest_limit || (addr + size) < addr)\r\nbad_driver(d, "%s:%i: Invalid address %#lx",\r\n__FILE__, line, addr);\r\nreturn from_guest_phys(addr);\r\n}\r\nstatic unsigned next_desc(struct device *d, struct vring_desc *desc,\r\nunsigned int i, unsigned int max)\r\n{\r\nunsigned int next;\r\nif (!(desc[i].flags & VRING_DESC_F_NEXT))\r\nreturn max;\r\nnext = desc[i].next;\r\nwmb();\r\nif (next >= max)\r\nbad_driver(d, "Desc next is %u", next);\r\nreturn next;\r\n}\r\nstatic void trigger_irq(struct virtqueue *vq)\r\n{\r\nunsigned long buf[] = { LHREQ_IRQ, vq->dev->config.irq_line };\r\nif (!vq->pending_used)\r\nreturn;\r\nvq->pending_used = 0;\r\nif (vq->vring.avail->flags > 1)\r\nbad_driver_vq(vq, "avail->flags = %u\n", vq->vring.avail->flags);\r\nif (vq->vring.avail->flags & VRING_AVAIL_F_NO_INTERRUPT) {\r\nreturn;\r\n}\r\nvq->dev->mmio->isr = 0x1;\r\nif (write(lguest_fd, buf, sizeof(buf)) != 0)\r\nerr(1, "Triggering irq %i", vq->dev->config.irq_line);\r\n}\r\nstatic unsigned wait_for_vq_desc(struct virtqueue *vq,\r\nstruct iovec iov[],\r\nunsigned int *out_num, unsigned int *in_num)\r\n{\r\nunsigned int i, head, max;\r\nstruct vring_desc *desc;\r\nu16 last_avail = lg_last_avail(vq);\r\nwhile (last_avail == vq->vring.avail->idx) {\r\nu64 event;\r\ntrigger_irq(vq);\r\nvq->vring.used->flags &= ~VRING_USED_F_NO_NOTIFY;\r\nmb();\r\nif (last_avail != vq->vring.avail->idx) {\r\nvq->vring.used->flags |= VRING_USED_F_NO_NOTIFY;\r\nbreak;\r\n}\r\nif (read(vq->eventfd, &event, sizeof(event)) != sizeof(event))\r\nerrx(1, "Event read failed?");\r\nvq->vring.used->flags |= VRING_USED_F_NO_NOTIFY;\r\n}\r\nif ((u16)(vq->vring.avail->idx - last_avail) > vq->vring.num)\r\nbad_driver_vq(vq, "Guest moved used index from %u to %u",\r\nlast_avail, vq->vring.avail->idx);\r\nrmb();\r\nhead = vq->vring.avail->ring[last_avail % vq->vring.num];\r\nlg_last_avail(vq)++;\r\nif (head >= vq->vring.num)\r\nbad_driver_vq(vq, "Guest says index %u is available", head);\r\n*out_num = *in_num = 0;\r\nmax = vq->vring.num;\r\ndesc = vq->vring.desc;\r\ni = head;\r\ndo {\r\nif (desc[i].flags & VRING_DESC_F_INDIRECT) {\r\nif (!(vq->dev->features_accepted &\r\n(1<<VIRTIO_RING_F_INDIRECT_DESC)))\r\nbad_driver_vq(vq, "vq indirect not negotiated");\r\nif (desc != vq->vring.desc)\r\nbad_driver_vq(vq, "Indirect within indirect");\r\nif (desc[i].flags & VRING_DESC_F_NEXT)\r\nbad_driver_vq(vq, "indirect and next together");\r\nif (desc[i].len % sizeof(struct vring_desc))\r\nbad_driver_vq(vq,\r\n"Invalid size for indirect table");\r\nmax = desc[i].len / sizeof(struct vring_desc);\r\ndesc = check_pointer(vq->dev, desc[i].addr, desc[i].len);\r\ni = 0;\r\nif (max > vq->pci_config.queue_size)\r\nbad_driver_vq(vq,\r\n"indirect has too many entries");\r\n}\r\niov[*out_num + *in_num].iov_len = desc[i].len;\r\niov[*out_num + *in_num].iov_base\r\n= check_pointer(vq->dev, desc[i].addr, desc[i].len);\r\nif (desc[i].flags & VRING_DESC_F_WRITE)\r\n(*in_num)++;\r\nelse {\r\nif (*in_num)\r\nbad_driver_vq(vq,\r\n"Descriptor has out after in");\r\n(*out_num)++;\r\n}\r\nif (*out_num + *in_num > max)\r\nbad_driver_vq(vq, "Looped descriptor");\r\n} while ((i = next_desc(vq->dev, desc, i, max)) != max);\r\nreturn head;\r\n}\r\nstatic void add_used(struct virtqueue *vq, unsigned int head, int len)\r\n{\r\nstruct vring_used_elem *used;\r\nused = &vq->vring.used->ring[vq->vring.used->idx % vq->vring.num];\r\nused->id = head;\r\nused->len = len;\r\nwmb();\r\nvq->vring.used->idx++;\r\nvq->pending_used++;\r\n}\r\nstatic void add_used_and_trigger(struct virtqueue *vq, unsigned head, int len)\r\n{\r\nadd_used(vq, head, len);\r\ntrigger_irq(vq);\r\n}\r\nstatic void console_input(struct virtqueue *vq)\r\n{\r\nint len;\r\nunsigned int head, in_num, out_num;\r\nstruct console_abort *abort = vq->dev->priv;\r\nstruct iovec iov[vq->vring.num];\r\nhead = wait_for_vq_desc(vq, iov, &out_num, &in_num);\r\nif (out_num)\r\nbad_driver_vq(vq, "Output buffers in console in queue?");\r\nlen = readv(STDIN_FILENO, iov, in_num);\r\nif (len <= 0) {\r\nwarnx("Failed to get console input, ignoring console.");\r\nfor (;;)\r\npause();\r\n}\r\nadd_used_and_trigger(vq, head, len);\r\nif (len != 1 || ((char *)iov[0].iov_base)[0] != 3) {\r\nabort->count = 0;\r\nreturn;\r\n}\r\nabort->count++;\r\nif (abort->count == 1)\r\ngettimeofday(&abort->start, NULL);\r\nelse if (abort->count == 3) {\r\nstruct timeval now;\r\ngettimeofday(&now, NULL);\r\nif (now.tv_sec <= abort->start.tv_sec+1)\r\nkill(0, SIGINT);\r\nabort->count = 0;\r\n}\r\n}\r\nstatic void console_output(struct virtqueue *vq)\r\n{\r\nunsigned int head, out, in;\r\nstruct iovec iov[vq->vring.num];\r\nhead = wait_for_vq_desc(vq, iov, &out, &in);\r\nif (in)\r\nbad_driver_vq(vq, "Input buffers in console output queue?");\r\nwhile (!iov_empty(iov, out)) {\r\nint len = writev(STDOUT_FILENO, iov, out);\r\nif (len <= 0) {\r\nwarn("Write to stdout gave %i (%d)", len, errno);\r\nbreak;\r\n}\r\niov_consume(vq->dev, iov, out, NULL, len);\r\n}\r\nadd_used(vq, head, 0);\r\n}\r\nstatic void net_output(struct virtqueue *vq)\r\n{\r\nstruct net_info *net_info = vq->dev->priv;\r\nunsigned int head, out, in;\r\nstruct iovec iov[vq->vring.num];\r\nhead = wait_for_vq_desc(vq, iov, &out, &in);\r\nif (in)\r\nbad_driver_vq(vq, "Input buffers in net output queue?");\r\nif (writev(net_info->tunfd, iov, out) < 0)\r\nwarnx("Write to tun failed (%d)?", errno);\r\nadd_used(vq, head, 0);\r\n}\r\nstatic bool will_block(int fd)\r\n{\r\nfd_set fdset;\r\nstruct timeval zero = { 0, 0 };\r\nFD_ZERO(&fdset);\r\nFD_SET(fd, &fdset);\r\nreturn select(fd+1, &fdset, NULL, NULL, &zero) != 1;\r\n}\r\nstatic void net_input(struct virtqueue *vq)\r\n{\r\nint len;\r\nunsigned int head, out, in;\r\nstruct iovec iov[vq->vring.num];\r\nstruct net_info *net_info = vq->dev->priv;\r\nhead = wait_for_vq_desc(vq, iov, &out, &in);\r\nif (out)\r\nbad_driver_vq(vq, "Output buffers in net input queue?");\r\nif (vq->pending_used && will_block(net_info->tunfd))\r\ntrigger_irq(vq);\r\nlen = readv(net_info->tunfd, iov, in);\r\nif (len <= 0)\r\nwarn("Failed to read from tun (%d).", errno);\r\nadd_used(vq, head, len);\r\n}\r\nstatic int do_thread(void *_vq)\r\n{\r\nstruct virtqueue *vq = _vq;\r\nfor (;;)\r\nvq->service(vq);\r\nreturn 0;\r\n}\r\nstatic void kill_launcher(int signal)\r\n{\r\nkill(0, SIGTERM);\r\n}\r\nstatic void reset_vq_pci_config(struct virtqueue *vq)\r\n{\r\nvq->pci_config.queue_size = VIRTQUEUE_NUM;\r\nvq->pci_config.queue_enable = 0;\r\n}\r\nstatic void reset_device(struct device *dev)\r\n{\r\nstruct virtqueue *vq;\r\nverbose("Resetting device %s\n", dev->name);\r\ndev->features_accepted = 0;\r\nsignal(SIGCHLD, SIG_IGN);\r\ndev->mmio->cfg.queue_enable = 0;\r\nfor (vq = dev->vq; vq; vq = vq->next) {\r\nvq->last_avail_idx = 0;\r\nreset_vq_pci_config(vq);\r\nif (vq->thread != (pid_t)-1) {\r\nkill(vq->thread, SIGTERM);\r\nwaitpid(vq->thread, NULL, 0);\r\nvq->thread = (pid_t)-1;\r\n}\r\n}\r\ndev->running = false;\r\ndev->wrote_features_ok = false;\r\nsignal(SIGCHLD, (void *)kill_launcher);\r\n}\r\nstatic void cleanup_devices(void)\r\n{\r\nunsigned int i;\r\nfor (i = 1; i < MAX_PCI_DEVICES; i++) {\r\nstruct device *d = devices.pci[i];\r\nif (!d)\r\ncontinue;\r\nreset_device(d);\r\n}\r\nif (orig_term.c_lflag & (ISIG|ICANON|ECHO))\r\ntcsetattr(STDIN_FILENO, TCSANOW, &orig_term);\r\n}\r\nstatic void init_pci_host_bridge(void)\r\n{\r\npci_host_bridge.name = "PCI Host Bridge";\r\npci_host_bridge.config.class = 0x06;\r\npci_host_bridge.config.subclass = 0;\r\ndevices.pci[0] = &pci_host_bridge;\r\n}\r\nstatic struct device *find_pci_device(unsigned int index)\r\n{\r\nreturn devices.pci[index];\r\n}\r\nstatic void ioread(u16 off, u32 v, u32 mask, u32 *val)\r\n{\r\nassert(off < 4);\r\nassert(mask == 0xFF || mask == 0xFFFF || mask == 0xFFFFFFFF);\r\n*val = (v >> (off * 8)) & mask;\r\n}\r\nstatic void iowrite(u16 off, u32 v, u32 mask, u32 *dst)\r\n{\r\nassert(off < 4);\r\nassert(mask == 0xFF || mask == 0xFFFF || mask == 0xFFFFFFFF);\r\n*dst &= ~(mask << (off * 8));\r\n*dst |= (v & mask) << (off * 8);\r\n}\r\nstatic struct device *dev_and_reg(u32 *reg)\r\n{\r\nif (!pci_config_addr.bits.enabled)\r\nreturn NULL;\r\nif (pci_config_addr.bits.funcnum != 0)\r\nreturn NULL;\r\nif (pci_config_addr.bits.busnum != 0)\r\nreturn NULL;\r\nif (pci_config_addr.bits.offset * 4 >= sizeof(struct pci_config))\r\nreturn NULL;\r\n*reg = pci_config_addr.bits.offset;\r\nreturn find_pci_device(pci_config_addr.bits.devnum);\r\n}\r\nstatic bool valid_bar_access(struct device *d,\r\nstruct virtio_pci_cfg_cap_u32 *cfg_access)\r\n{\r\nif (cfg_access->cap.bar != 0)\r\nreturn false;\r\nif (cfg_access->cap.offset >= d->mmio_size\r\n|| cfg_access->cap.offset + cfg_access->cap.length > d->mmio_size)\r\nreturn false;\r\nif (cfg_access->cap.length != 1\r\n&& cfg_access->cap.length != 2\r\n&& cfg_access->cap.length != 4)\r\nreturn false;\r\nif (cfg_access->cap.offset % cfg_access->cap.length != 0)\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic bool is_pci_addr_port(u16 port)\r\n{\r\nreturn port >= PCI_CONFIG_ADDR && port < PCI_CONFIG_ADDR + 4;\r\n}\r\nstatic bool pci_addr_iowrite(u16 port, u32 mask, u32 val)\r\n{\r\niowrite(port - PCI_CONFIG_ADDR, val, mask,\r\n&pci_config_addr.val);\r\nverbose("PCI%s: %#x/%x: bus %u dev %u func %u reg %u\n",\r\npci_config_addr.bits.enabled ? "" : " DISABLED",\r\nval, mask,\r\npci_config_addr.bits.busnum,\r\npci_config_addr.bits.devnum,\r\npci_config_addr.bits.funcnum,\r\npci_config_addr.bits.offset);\r\nreturn true;\r\n}\r\nstatic void pci_addr_ioread(u16 port, u32 mask, u32 *val)\r\n{\r\nioread(port - PCI_CONFIG_ADDR, pci_config_addr.val, mask, val);\r\n}\r\nstatic bool is_pci_data_port(u16 port)\r\n{\r\nreturn port >= PCI_CONFIG_DATA && port < PCI_CONFIG_DATA + 4;\r\n}\r\nstatic bool pci_data_iowrite(u16 port, u32 mask, u32 val)\r\n{\r\nu32 reg, portoff;\r\nstruct device *d = dev_and_reg(&reg);\r\nif (!d)\r\nreturn false;\r\nportoff = port - PCI_CONFIG_DATA;\r\nif (&d->config_words[reg] == &d->config.bar[0]) {\r\nint i;\r\niowrite(portoff, val, mask, &d->config.bar[0]);\r\nfor (i = 0; (1 << i) < d->mmio_size; i++)\r\nd->config.bar[0] &= ~(1 << i);\r\nreturn true;\r\n} else if ((&d->config_words[reg] > &d->config.bar[0]\r\n&& &d->config_words[reg] <= &d->config.bar[6])\r\n|| &d->config_words[reg] == &d->config.expansion_rom_addr) {\r\niowrite(portoff, val, mask, &d->config_words[reg]);\r\nreturn true;\r\n} else if (&d->config_words[reg] == (void *)&d->config.cacheline_size) {\r\nif (mask == 0xFFFFFFFF)\r\nmask = 0xFFFF;\r\niowrite(portoff, val, mask, &d->config_words[reg]);\r\nreturn true;\r\n} else if (&d->config_words[reg] == (void *)&d->config.command\r\n&& mask == 0xFFFF) {\r\nreturn true;\r\n} else if (&d->config_words[reg]\r\n== (void *)&d->config.cfg_access.cap.bar\r\n|| &d->config_words[reg]\r\n== &d->config.cfg_access.cap.length\r\n|| &d->config_words[reg]\r\n== &d->config.cfg_access.cap.offset) {\r\niowrite(portoff, val, mask, &d->config_words[reg]);\r\nreturn true;\r\n} else if (&d->config_words[reg] == &d->config.cfg_access.pci_cfg_data) {\r\nu32 write_mask;\r\nif (!valid_bar_access(d, &d->config.cfg_access))\r\nreturn false;\r\niowrite(portoff, val, mask, &d->config.cfg_access.pci_cfg_data);\r\nwrite_mask = (1ULL<<(8*d->config.cfg_access.cap.length)) - 1;\r\nverbose("Window writing %#x/%#x to bar %u, offset %u len %u\n",\r\nd->config.cfg_access.pci_cfg_data, write_mask,\r\nd->config.cfg_access.cap.bar,\r\nd->config.cfg_access.cap.offset,\r\nd->config.cfg_access.cap.length);\r\nemulate_mmio_write(d, d->config.cfg_access.cap.offset,\r\nd->config.cfg_access.pci_cfg_data,\r\nwrite_mask);\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic void pci_data_ioread(u16 port, u32 mask, u32 *val)\r\n{\r\nu32 reg;\r\nstruct device *d = dev_and_reg(&reg);\r\nif (!d)\r\nreturn;\r\nif (&d->config_words[reg] == &d->config.cfg_access.pci_cfg_data) {\r\nu32 read_mask;\r\nif (!valid_bar_access(d, &d->config.cfg_access))\r\nbad_driver(d,\r\n"Invalid cfg_access to bar%u, offset %u len %u",\r\nd->config.cfg_access.cap.bar,\r\nd->config.cfg_access.cap.offset,\r\nd->config.cfg_access.cap.length);\r\nread_mask = (1ULL<<(8*d->config.cfg_access.cap.length))-1;\r\nd->config.cfg_access.pci_cfg_data\r\n= emulate_mmio_read(d,\r\nd->config.cfg_access.cap.offset,\r\nread_mask);\r\nverbose("Window read %#x/%#x from bar %u, offset %u len %u\n",\r\nd->config.cfg_access.pci_cfg_data, read_mask,\r\nd->config.cfg_access.cap.bar,\r\nd->config.cfg_access.cap.offset,\r\nd->config.cfg_access.cap.length);\r\n}\r\nioread(port - PCI_CONFIG_DATA, d->config_words[reg], mask, val);\r\n}\r\nstatic u32 getreg_off(size_t offset)\r\n{\r\nu32 r;\r\nunsigned long args[] = { LHREQ_GETREG, offset };\r\nif (pwrite(lguest_fd, args, sizeof(args), cpu_id) < 0)\r\nerr(1, "Getting register %u", offset);\r\nif (pread(lguest_fd, &r, sizeof(r), cpu_id) != sizeof(r))\r\nerr(1, "Reading register %u", offset);\r\nreturn r;\r\n}\r\nstatic void setreg_off(size_t offset, u32 val)\r\n{\r\nunsigned long args[] = { LHREQ_SETREG, offset, val };\r\nif (pwrite(lguest_fd, args, sizeof(args), cpu_id) < 0)\r\nerr(1, "Setting register %u", offset);\r\n}\r\nstatic u32 getreg_num(unsigned regnum, u32 mask)\r\n{\r\nif (mask == 0xFF && (regnum & 0x4))\r\nreturn getreg_num(regnum & 0x3, 0xFFFF) >> 8;\r\nswitch (regnum) {\r\ncase 0: return getreg(eax) & mask;\r\ncase 1: return getreg(ecx) & mask;\r\ncase 2: return getreg(edx) & mask;\r\ncase 3: return getreg(ebx) & mask;\r\ncase 4: return getreg(esp) & mask;\r\ncase 5: return getreg(ebp) & mask;\r\ncase 6: return getreg(esi) & mask;\r\ncase 7: return getreg(edi) & mask;\r\n}\r\nabort();\r\n}\r\nstatic void setreg_num(unsigned regnum, u32 val, u32 mask)\r\n{\r\nassert(~(val & ~mask));\r\nif (mask == 0xFF && (regnum & 0x4)) {\r\nval = (val << 8) | getreg_num(regnum & 0x3, 0xFF);\r\nsetreg_num(regnum & 0x3, val, 0xFFFF);\r\nreturn;\r\n}\r\nswitch (regnum) {\r\ncase 0: setreg(eax, val | (getreg(eax) & ~mask)); return;\r\ncase 1: setreg(ecx, val | (getreg(ecx) & ~mask)); return;\r\ncase 2: setreg(edx, val | (getreg(edx) & ~mask)); return;\r\ncase 3: setreg(ebx, val | (getreg(ebx) & ~mask)); return;\r\ncase 4: setreg(esp, val | (getreg(esp) & ~mask)); return;\r\ncase 5: setreg(ebp, val | (getreg(ebp) & ~mask)); return;\r\ncase 6: setreg(esi, val | (getreg(esi) & ~mask)); return;\r\ncase 7: setreg(edi, val | (getreg(edi) & ~mask)); return;\r\n}\r\nabort();\r\n}\r\nstatic u32 insn_displacement_len(u8 mod_reg_rm)\r\n{\r\nswitch (mod_reg_rm >> 6) {\r\ncase 0:\r\nif ((mod_reg_rm & 0x7) == 0x5)\r\nreturn 2;\r\nreturn 0;\r\ncase 1:\r\nreturn 1;\r\ncase 2:\r\nreturn 4;\r\ncase 3:\r\nreturn 0;\r\n}\r\nabort();\r\n}\r\nstatic void emulate_insn(const u8 insn[])\r\n{\r\nunsigned long args[] = { LHREQ_TRAP, 13 };\r\nunsigned int insnlen = 0, in = 0, small_operand = 0, byte_access;\r\nunsigned int eax, port, mask;\r\nu32 val = 0xFFFFFFFF;\r\nif ((getreg(xcs) & 3) != 0x1)\r\ngoto no_emulate;\r\nif (insn[insnlen] == 0xfa) {\r\ninsnlen = 1;\r\ngoto skip_insn;\r\n}\r\nif (insn[insnlen] == 0x66) {\r\nsmall_operand = 1;\r\ninsnlen = 1;\r\n}\r\nbyte_access = !(insn[insnlen] & 1);\r\nswitch (insn[insnlen] & 0xFE) {\r\ncase 0xE4:\r\nport = insn[insnlen+1];\r\ninsnlen += 2;\r\nin = 1;\r\nbreak;\r\ncase 0xEC:\r\nport = getreg(edx) & 0xFFFF;\r\ninsnlen += 1;\r\nin = 1;\r\nbreak;\r\ncase 0xE6:\r\nport = insn[insnlen+1];\r\ninsnlen += 2;\r\nbreak;\r\ncase 0xEE:\r\nport = getreg(edx) & 0xFFFF;\r\ninsnlen += 1;\r\nbreak;\r\ndefault:\r\ngoto no_emulate;\r\n}\r\nif (byte_access)\r\nmask = 0xFF;\r\nelse if (small_operand)\r\nmask = 0xFFFF;\r\nelse\r\nmask = 0xFFFFFFFF;\r\neax = getreg(eax);\r\nif (in) {\r\nif (port == 0x64)\r\nval = 1;\r\nelse if (is_pci_addr_port(port))\r\npci_addr_ioread(port, mask, &val);\r\nelse if (is_pci_data_port(port))\r\npci_data_ioread(port, mask, &val);\r\neax &= ~mask;\r\neax |= val & mask;\r\nsetreg(eax, eax);\r\n} else {\r\nif (is_pci_addr_port(port)) {\r\nif (!pci_addr_iowrite(port, mask, eax))\r\ngoto bad_io;\r\n} else if (is_pci_data_port(port)) {\r\nif (!pci_data_iowrite(port, mask, eax))\r\ngoto bad_io;\r\n}\r\n}\r\nverbose("IO %s of %x to %u: %#08x\n",\r\nin ? "IN" : "OUT", mask, port, eax);\r\nskip_insn:\r\nsetreg(eip, getreg(eip) + insnlen);\r\nreturn;\r\nbad_io:\r\nwarnx("Attempt to %s port %u (%#x mask)",\r\nin ? "read from" : "write to", port, mask);\r\nno_emulate:\r\nif (write(lguest_fd, args, sizeof(args)) < 0)\r\nerr(1, "Reinjecting trap 13 for fault at %#x", getreg(eip));\r\n}\r\nstatic struct device *find_mmio_region(unsigned long paddr, u32 *off)\r\n{\r\nunsigned int i;\r\nfor (i = 1; i < MAX_PCI_DEVICES; i++) {\r\nstruct device *d = devices.pci[i];\r\nif (!d)\r\ncontinue;\r\nif (paddr < d->mmio_addr)\r\ncontinue;\r\nif (paddr >= d->mmio_addr + d->mmio_size)\r\ncontinue;\r\n*off = paddr - d->mmio_addr;\r\nreturn d;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct virtqueue *vq_by_num(struct device *d, u32 num)\r\n{\r\nstruct virtqueue *vq = d->vq;\r\nwhile (num-- && vq)\r\nvq = vq->next;\r\nreturn vq;\r\n}\r\nstatic void save_vq_config(const struct virtio_pci_common_cfg *cfg,\r\nstruct virtqueue *vq)\r\n{\r\nvq->pci_config = *cfg;\r\n}\r\nstatic void restore_vq_config(struct virtio_pci_common_cfg *cfg,\r\nstruct virtqueue *vq)\r\n{\r\nsize_t off = offsetof(struct virtio_pci_common_cfg, queue_size);\r\nmemcpy((void *)cfg + off, (void *)&vq->pci_config + off,\r\nsizeof(*cfg) - off);\r\n}\r\nstatic void check_virtqueue(struct device *d, struct virtqueue *vq)\r\n{\r\nif (vq->pci_config.queue_desc_hi\r\n|| vq->pci_config.queue_avail_hi\r\n|| vq->pci_config.queue_used_hi)\r\nbad_driver_vq(vq, "invalid 64-bit queue address");\r\nif (vq->pci_config.queue_desc_lo % 16\r\n|| vq->pci_config.queue_avail_lo % 2\r\n|| vq->pci_config.queue_used_lo % 4)\r\nbad_driver_vq(vq, "invalid alignment in queue addresses");\r\nvq->vring.num = vq->pci_config.queue_size;\r\nvq->vring.desc = check_pointer(vq->dev,\r\nvq->pci_config.queue_desc_lo,\r\nsizeof(*vq->vring.desc) * vq->vring.num);\r\nvq->vring.avail = check_pointer(vq->dev,\r\nvq->pci_config.queue_avail_lo,\r\nsizeof(*vq->vring.avail)\r\n+ (sizeof(vq->vring.avail->ring[0])\r\n* vq->vring.num));\r\nvq->vring.used = check_pointer(vq->dev,\r\nvq->pci_config.queue_used_lo,\r\nsizeof(*vq->vring.used)\r\n+ (sizeof(vq->vring.used->ring[0])\r\n* vq->vring.num));\r\nif (vq->vring.used->flags != 0)\r\nbad_driver_vq(vq, "invalid initial used.flags %#x",\r\nvq->vring.used->flags);\r\n}\r\nstatic void start_virtqueue(struct virtqueue *vq)\r\n{\r\nchar *stack = malloc(32768);\r\nvq->eventfd = eventfd(0, 0);\r\nif (vq->eventfd < 0)\r\nerr(1, "Creating eventfd");\r\nvq->thread = clone(do_thread, stack + 32768, CLONE_VM | SIGCHLD, vq);\r\nif (vq->thread == (pid_t)-1)\r\nerr(1, "Creating clone");\r\n}\r\nstatic void start_virtqueues(struct device *d)\r\n{\r\nstruct virtqueue *vq;\r\nfor (vq = d->vq; vq; vq = vq->next) {\r\nif (vq->pci_config.queue_enable)\r\nstart_virtqueue(vq);\r\n}\r\n}\r\nstatic void emulate_mmio_write(struct device *d, u32 off, u32 val, u32 mask)\r\n{\r\nstruct virtqueue *vq;\r\nswitch (off) {\r\ncase offsetof(struct virtio_pci_mmio, cfg.device_feature_select):\r\nif (val == 0)\r\nd->mmio->cfg.device_feature = d->features;\r\nelse if (val == 1)\r\nd->mmio->cfg.device_feature = (d->features >> 32);\r\nelse\r\nd->mmio->cfg.device_feature = 0;\r\ngoto feature_write_through32;\r\ncase offsetof(struct virtio_pci_mmio, cfg.guest_feature_select):\r\nif (val > 1)\r\nbad_driver(d, "Unexpected driver select %u", val);\r\ngoto feature_write_through32;\r\ncase offsetof(struct virtio_pci_mmio, cfg.guest_feature):\r\nif (d->mmio->cfg.guest_feature_select == 0) {\r\nd->features_accepted &= ~((u64)0xFFFFFFFF);\r\nd->features_accepted |= val;\r\n} else {\r\nassert(d->mmio->cfg.guest_feature_select == 1);\r\nd->features_accepted &= 0xFFFFFFFF;\r\nd->features_accepted |= ((u64)val) << 32;\r\n}\r\nif (d->features_accepted & ~d->features)\r\nbad_driver(d, "over-accepted features %#llx of %#llx",\r\nd->features_accepted, d->features);\r\ngoto feature_write_through32;\r\ncase offsetof(struct virtio_pci_mmio, cfg.device_status): {\r\nu8 prev;\r\nverbose("%s: device status -> %#x\n", d->name, val);\r\nif (val == 0) {\r\nreset_device(d);\r\ngoto write_through8;\r\n}\r\nif (d->mmio->cfg.device_status & ~val)\r\nbad_driver(d, "unset of device status bit %#x -> %#x",\r\nd->mmio->cfg.device_status, val);\r\nif (val & VIRTIO_CONFIG_S_DRIVER_OK\r\n&& !(d->mmio->cfg.device_status & VIRTIO_CONFIG_S_DRIVER_OK))\r\nstart_virtqueues(d);\r\nprev = 0;\r\nswitch (val & ~d->mmio->cfg.device_status) {\r\ncase VIRTIO_CONFIG_S_DRIVER_OK:\r\nprev |= VIRTIO_CONFIG_S_FEATURES_OK;\r\ncase VIRTIO_CONFIG_S_FEATURES_OK:\r\nprev |= VIRTIO_CONFIG_S_DRIVER;\r\ncase VIRTIO_CONFIG_S_DRIVER:\r\nprev |= VIRTIO_CONFIG_S_ACKNOWLEDGE;\r\ncase VIRTIO_CONFIG_S_ACKNOWLEDGE:\r\nbreak;\r\ndefault:\r\nbad_driver(d, "unknown device status bit %#x -> %#x",\r\nd->mmio->cfg.device_status, val);\r\n}\r\nif (d->mmio->cfg.device_status != prev)\r\nbad_driver(d, "unexpected status transition %#x -> %#x",\r\nd->mmio->cfg.device_status, val);\r\nswitch (val & ~d->mmio->cfg.device_status) {\r\ncase VIRTIO_CONFIG_S_FEATURES_OK:\r\nd->wrote_features_ok = true;\r\nbreak;\r\ncase VIRTIO_CONFIG_S_DRIVER_OK:\r\nif (d->wrote_features_ok)\r\nbad_driver(d, "did not re-read FEATURES_OK");\r\nbreak;\r\n}\r\ngoto write_through8;\r\n}\r\ncase offsetof(struct virtio_pci_mmio, cfg.queue_select):\r\nvq = vq_by_num(d, val);\r\nif (!vq) {\r\nd->mmio->cfg.queue_size = 0;\r\ngoto write_through16;\r\n}\r\nif (d->mmio->cfg.queue_size)\r\nsave_vq_config(&d->mmio->cfg,\r\nvq_by_num(d, d->mmio->cfg.queue_select));\r\nrestore_vq_config(&d->mmio->cfg, vq);\r\ngoto write_through16;\r\ncase offsetof(struct virtio_pci_mmio, cfg.queue_size):\r\nif (val & (val-1))\r\nbad_driver(d, "invalid queue size %u", val);\r\nif (d->mmio->cfg.queue_enable)\r\nbad_driver(d, "changing queue size on live device");\r\ngoto write_through16;\r\ncase offsetof(struct virtio_pci_mmio, cfg.queue_msix_vector):\r\nbad_driver(d, "attempt to set MSIX vector to %u", val);\r\ncase offsetof(struct virtio_pci_mmio, cfg.queue_enable): {\r\nstruct virtqueue *vq = vq_by_num(d, d->mmio->cfg.queue_select);\r\nif (val != 1)\r\nbad_driver(d, "setting queue_enable to %u", val);\r\nif (d->mmio->cfg.device_status & VIRTIO_CONFIG_S_DRIVER_OK)\r\nbad_driver(d, "enabling vq after DRIVER_OK");\r\nd->mmio->cfg.queue_enable = val;\r\nsave_vq_config(&d->mmio->cfg, vq);\r\ncheck_virtqueue(d, vq);\r\ngoto write_through16;\r\n}\r\ncase offsetof(struct virtio_pci_mmio, cfg.queue_notify_off):\r\nbad_driver(d, "attempt to write to queue_notify_off");\r\ncase offsetof(struct virtio_pci_mmio, cfg.queue_desc_lo):\r\ncase offsetof(struct virtio_pci_mmio, cfg.queue_desc_hi):\r\ncase offsetof(struct virtio_pci_mmio, cfg.queue_avail_lo):\r\ncase offsetof(struct virtio_pci_mmio, cfg.queue_avail_hi):\r\ncase offsetof(struct virtio_pci_mmio, cfg.queue_used_lo):\r\ncase offsetof(struct virtio_pci_mmio, cfg.queue_used_hi):\r\nif (d->mmio->cfg.queue_enable)\r\nbad_driver(d, "changing queue on live device");\r\nif (!(d->mmio->cfg.device_status & VIRTIO_CONFIG_S_FEATURES_OK))\r\nbad_driver(d, "setting up vq before FEATURES_OK");\r\nif (d->wrote_features_ok)\r\nbad_driver(d, "didn't re-read FEATURES_OK before setup");\r\ngoto write_through32;\r\ncase offsetof(struct virtio_pci_mmio, notify):\r\nvq = vq_by_num(d, val);\r\nif (!vq)\r\nbad_driver(d, "Invalid vq notification on %u", val);\r\nwrite(vq->eventfd, "\1\0\0\0\0\0\0\0", 8);\r\ngoto write_through16;\r\ncase offsetof(struct virtio_pci_mmio, isr):\r\nbad_driver(d, "Unexpected write to isr");\r\ncase sizeof(struct virtio_pci_mmio)\r\n+ offsetof(struct virtio_console_config, emerg_wr):\r\nif (strcmp(d->name, "console") == 0) {\r\nchar c = val;\r\nwrite(STDOUT_FILENO, &c, 1);\r\ngoto write_through32;\r\n}\r\ndefault:\r\nbad_driver(d, "Unexpected write to offset %u", off);\r\n}\r\nfeature_write_through32:\r\nif (!(d->mmio->cfg.device_status & VIRTIO_CONFIG_S_DRIVER))\r\nbad_driver(d, "feature write before VIRTIO_CONFIG_S_DRIVER");\r\nif (d->mmio->cfg.device_status & VIRTIO_CONFIG_S_FEATURES_OK)\r\nbad_driver(d, "feature write after VIRTIO_CONFIG_S_FEATURES_OK");\r\nwrite_through32:\r\nif (mask != 0xFFFFFFFF) {\r\nbad_driver(d, "non-32-bit write to offset %u (%#x)",\r\noff, getreg(eip));\r\nreturn;\r\n}\r\nmemcpy((char *)d->mmio + off, &val, 4);\r\nreturn;\r\nwrite_through16:\r\nif (mask != 0xFFFF)\r\nbad_driver(d, "non-16-bit write to offset %u (%#x)",\r\noff, getreg(eip));\r\nmemcpy((char *)d->mmio + off, &val, 2);\r\nreturn;\r\nwrite_through8:\r\nif (mask != 0xFF)\r\nbad_driver(d, "non-8-bit write to offset %u (%#x)",\r\noff, getreg(eip));\r\nmemcpy((char *)d->mmio + off, &val, 1);\r\nreturn;\r\n}\r\nstatic u32 emulate_mmio_read(struct device *d, u32 off, u32 mask)\r\n{\r\nu8 isr;\r\nu32 val = 0;\r\nswitch (off) {\r\ncase offsetof(struct virtio_pci_mmio, cfg.device_feature_select):\r\ncase offsetof(struct virtio_pci_mmio, cfg.device_feature):\r\ncase offsetof(struct virtio_pci_mmio, cfg.guest_feature_select):\r\ncase offsetof(struct virtio_pci_mmio, cfg.guest_feature):\r\nif (!(d->mmio->cfg.device_status & VIRTIO_CONFIG_S_DRIVER))\r\nbad_driver(d,\r\n"feature read before VIRTIO_CONFIG_S_DRIVER");\r\ngoto read_through32;\r\ncase offsetof(struct virtio_pci_mmio, cfg.msix_config):\r\nbad_driver(d, "read of msix_config");\r\ncase offsetof(struct virtio_pci_mmio, cfg.num_queues):\r\ngoto read_through16;\r\ncase offsetof(struct virtio_pci_mmio, cfg.device_status):\r\nd->wrote_features_ok = false;\r\ngoto read_through8;\r\ncase offsetof(struct virtio_pci_mmio, cfg.config_generation):\r\ngoto read_through8;\r\ncase offsetof(struct virtio_pci_mmio, notify):\r\nif (!(d->mmio->cfg.device_status & VIRTIO_CONFIG_S_DRIVER_OK))\r\nbad_driver(d, "notify before VIRTIO_CONFIG_S_DRIVER_OK");\r\ngoto read_through16;\r\ncase offsetof(struct virtio_pci_mmio, isr):\r\nif (mask != 0xFF)\r\nbad_driver(d, "non-8-bit read from offset %u (%#x)",\r\noff, getreg(eip));\r\nisr = d->mmio->isr;\r\nd->mmio->isr = 0;\r\nreturn isr;\r\ncase offsetof(struct virtio_pci_mmio, padding):\r\nbad_driver(d, "read from padding (%#x)", getreg(eip));\r\ndefault:\r\nif (off > d->mmio_size - 4)\r\nbad_driver(d, "read past end (%#x)", getreg(eip));\r\nif (!(d->mmio->cfg.device_status & VIRTIO_CONFIG_S_DRIVER))\r\nbad_driver(d,\r\n"config read before VIRTIO_CONFIG_S_DRIVER");\r\nif (mask == 0xFFFFFFFF)\r\ngoto read_through32;\r\nelse if (mask == 0xFFFF)\r\ngoto read_through16;\r\nelse\r\ngoto read_through8;\r\n}\r\nread_through32:\r\nif (mask != 0xFFFFFFFF)\r\nbad_driver(d, "non-32-bit read to offset %u (%#x)",\r\noff, getreg(eip));\r\nmemcpy(&val, (char *)d->mmio + off, 4);\r\nreturn val;\r\nread_through16:\r\nif (mask != 0xFFFF)\r\nbad_driver(d, "non-16-bit read to offset %u (%#x)",\r\noff, getreg(eip));\r\nmemcpy(&val, (char *)d->mmio + off, 2);\r\nreturn val;\r\nread_through8:\r\nif (mask != 0xFF)\r\nbad_driver(d, "non-8-bit read to offset %u (%#x)",\r\noff, getreg(eip));\r\nmemcpy(&val, (char *)d->mmio + off, 1);\r\nreturn val;\r\n}\r\nstatic void emulate_mmio(unsigned long paddr, const u8 *insn)\r\n{\r\nu32 val, off, mask = 0xFFFFFFFF, insnlen = 0;\r\nstruct device *d = find_mmio_region(paddr, &off);\r\nunsigned long args[] = { LHREQ_TRAP, 14 };\r\nif (!d) {\r\nwarnx("MMIO touching %#08lx (not a device)", paddr);\r\ngoto reinject;\r\n}\r\nif (insn[0] == 0x66) {\r\nmask = 0xFFFF;\r\ninsnlen++;\r\n}\r\nif (insn[insnlen] == 0x89) {\r\nval = getreg_num((insn[insnlen+1] >> 3) & 0x7, mask);\r\nemulate_mmio_write(d, off, val, mask);\r\ninsnlen += 2 + insn_displacement_len(insn[insnlen+1]);\r\n} else if (insn[insnlen] == 0x8b) {\r\nval = emulate_mmio_read(d, off, mask);\r\nsetreg_num((insn[insnlen+1] >> 3) & 0x7, val, mask);\r\ninsnlen += 2 + insn_displacement_len(insn[insnlen+1]);\r\n} else if (insn[0] == 0x88) {\r\nmask = 0xff;\r\nval = getreg_num((insn[1] >> 3) & 0x7, mask);\r\nemulate_mmio_write(d, off, val, mask);\r\ninsnlen = 2 + insn_displacement_len(insn[1]);\r\n} else if (insn[0] == 0x8a) {\r\nmask = 0xff;\r\nval = emulate_mmio_read(d, off, mask);\r\nsetreg_num((insn[1] >> 3) & 0x7, val, mask);\r\ninsnlen = 2 + insn_displacement_len(insn[1]);\r\n} else {\r\nwarnx("Unknown MMIO instruction touching %#08lx:"\r\n" %02x %02x %02x %02x at %u",\r\npaddr, insn[0], insn[1], insn[2], insn[3], getreg(eip));\r\nreinject:\r\nif (write(lguest_fd, args, sizeof(args)) < 0)\r\nerr(1, "Reinjecting trap 14 for fault at %#x",\r\ngetreg(eip));\r\nreturn;\r\n}\r\nsetreg(eip, getreg(eip) + insnlen);\r\n}\r\nstatic void add_pci_virtqueue(struct device *dev,\r\nvoid (*service)(struct virtqueue *),\r\nconst char *name)\r\n{\r\nstruct virtqueue **i, *vq = malloc(sizeof(*vq));\r\nvq->next = NULL;\r\nvq->last_avail_idx = 0;\r\nvq->dev = dev;\r\nvq->name = name;\r\nvq->service = service;\r\nvq->thread = (pid_t)-1;\r\nreset_vq_pci_config(vq);\r\nvq->pci_config.queue_notify_off = 0;\r\nvq->dev->mmio->cfg.num_queues++;\r\nfor (i = &dev->vq; *i; i = &(*i)->next);\r\n*i = vq;\r\n}\r\nstatic void add_pci_feature(struct device *dev, unsigned bit)\r\n{\r\ndev->features |= (1ULL << bit);\r\n}\r\nstatic void no_device_config(struct device *dev)\r\n{\r\ndev->mmio_addr = get_mmio_region(dev->mmio_size);\r\ndev->config.bar[0] = dev->mmio_addr;\r\nassert(~(dev->config.bar[0] & 0xF));\r\n}\r\nstatic void set_device_config(struct device *dev, const void *conf, size_t len)\r\n{\r\ndev->mmio_size += len;\r\ndev->mmio = realloc(dev->mmio, dev->mmio_size);\r\nmemcpy(dev->mmio + 1, conf, len);\r\ndev->config.cfg_access.cap.cap_next\r\n= offsetof(struct pci_config, device);\r\nassert(dev->config.cfg_access.cap.cap_next % 4 == 0);\r\ndev->config.device.length = len;\r\nno_device_config(dev);\r\n}\r\nstatic void init_cap(struct virtio_pci_cap *cap, size_t caplen, int type,\r\nsize_t bar_offset, size_t bar_bytes, u8 next)\r\n{\r\ncap->cap_vndr = PCI_CAP_ID_VNDR;\r\ncap->cap_next = next;\r\ncap->cap_len = caplen;\r\ncap->cfg_type = type;\r\ncap->bar = 0;\r\nmemset(cap->padding, 0, sizeof(cap->padding));\r\ncap->offset = bar_offset;\r\ncap->length = bar_bytes;\r\n}\r\nstatic void init_pci_config(struct pci_config *pci, u16 type,\r\nu8 class, u8 subclass)\r\n{\r\nsize_t bar_offset, bar_len;\r\nmemset(pci, 0, sizeof(*pci));\r\npci->vendor_id = 0x1AF4;\r\npci->device_id = 0x1040 + type;\r\npci->class = class;\r\npci->subclass = subclass;\r\npci->revid = 1;\r\npci->subsystem_device_id = 0x40;\r\npci->irq_line = devices.next_irq++;\r\npci->irq_pin = 0;\r\npci->status = (1 << 4);\r\npci->capabilities = offsetof(struct pci_config, common);\r\nassert(pci->capabilities % 4 == 0);\r\nbar_offset = offsetof(struct virtio_pci_mmio, cfg);\r\nbar_len = sizeof(((struct virtio_pci_mmio *)0)->cfg);\r\ninit_cap(&pci->common, sizeof(pci->common), VIRTIO_PCI_CAP_COMMON_CFG,\r\nbar_offset, bar_len,\r\noffsetof(struct pci_config, notify));\r\nbar_offset += bar_len;\r\nbar_len = sizeof(((struct virtio_pci_mmio *)0)->notify);\r\nassert(pci->common.cap_next % 2 == 0);\r\nassert(bar_len >= 2);\r\ninit_cap(&pci->notify.cap, sizeof(pci->notify),\r\nVIRTIO_PCI_CAP_NOTIFY_CFG,\r\nbar_offset, bar_len,\r\noffsetof(struct pci_config, isr));\r\nbar_offset += bar_len;\r\nbar_len = sizeof(((struct virtio_pci_mmio *)0)->isr);\r\ninit_cap(&pci->isr, sizeof(pci->isr),\r\nVIRTIO_PCI_CAP_ISR_CFG,\r\nbar_offset, bar_len,\r\noffsetof(struct pci_config, cfg_access));\r\ninit_cap(&pci->cfg_access.cap, sizeof(pci->cfg_access),\r\nVIRTIO_PCI_CAP_PCI_CFG,\r\n0, 0, 0);\r\nbar_offset += bar_len + sizeof(((struct virtio_pci_mmio *)0)->padding);\r\nassert(bar_offset == sizeof(struct virtio_pci_mmio));\r\ninit_cap(&pci->device, sizeof(pci->device), VIRTIO_PCI_CAP_DEVICE_CFG,\r\nbar_offset, 0, 0);\r\n}\r\nstatic struct device *new_pci_device(const char *name, u16 type,\r\nu8 class, u8 subclass)\r\n{\r\nstruct device *dev = malloc(sizeof(*dev));\r\ndev->name = name;\r\ndev->vq = NULL;\r\ndev->running = false;\r\ndev->wrote_features_ok = false;\r\ndev->mmio_size = sizeof(struct virtio_pci_mmio);\r\ndev->mmio = calloc(1, dev->mmio_size);\r\ndev->features = (u64)1 << VIRTIO_F_VERSION_1;\r\ndev->features_accepted = 0;\r\nif (devices.device_num + 1 >= MAX_PCI_DEVICES)\r\nerrx(1, "Can only handle 31 PCI devices");\r\ninit_pci_config(&dev->config, type, class, subclass);\r\nassert(!devices.pci[devices.device_num+1]);\r\ndevices.pci[++devices.device_num] = dev;\r\nreturn dev;\r\n}\r\nstatic void setup_console(void)\r\n{\r\nstruct device *dev;\r\nstruct virtio_console_config conf;\r\nif (tcgetattr(STDIN_FILENO, &orig_term) == 0) {\r\nstruct termios term = orig_term;\r\nterm.c_lflag &= ~(ISIG|ICANON|ECHO);\r\ntcsetattr(STDIN_FILENO, TCSANOW, &term);\r\n}\r\ndev = new_pci_device("console", VIRTIO_ID_CONSOLE, 0x07, 0x00);\r\ndev->priv = malloc(sizeof(struct console_abort));\r\n((struct console_abort *)dev->priv)->count = 0;\r\nadd_pci_virtqueue(dev, console_input, "input");\r\nadd_pci_virtqueue(dev, console_output, "output");\r\nadd_pci_feature(dev, VIRTIO_CONSOLE_F_EMERG_WRITE);\r\nset_device_config(dev, &conf, sizeof(conf));\r\nverbose("device %u: console\n", devices.device_num);\r\n}\r\nstatic u32 str2ip(const char *ipaddr)\r\n{\r\nunsigned int b[4];\r\nif (sscanf(ipaddr, "%u.%u.%u.%u", &b[0], &b[1], &b[2], &b[3]) != 4)\r\nerrx(1, "Failed to parse IP address '%s'", ipaddr);\r\nreturn (b[0] << 24) | (b[1] << 16) | (b[2] << 8) | b[3];\r\n}\r\nstatic void str2mac(const char *macaddr, unsigned char mac[6])\r\n{\r\nunsigned int m[6];\r\nif (sscanf(macaddr, "%02x:%02x:%02x:%02x:%02x:%02x",\r\n&m[0], &m[1], &m[2], &m[3], &m[4], &m[5]) != 6)\r\nerrx(1, "Failed to parse mac address '%s'", macaddr);\r\nmac[0] = m[0];\r\nmac[1] = m[1];\r\nmac[2] = m[2];\r\nmac[3] = m[3];\r\nmac[4] = m[4];\r\nmac[5] = m[5];\r\n}\r\nstatic void add_to_bridge(int fd, const char *if_name, const char *br_name)\r\n{\r\nint ifidx;\r\nstruct ifreq ifr;\r\nif (!*br_name)\r\nerrx(1, "must specify bridge name");\r\nifidx = if_nametoindex(if_name);\r\nif (!ifidx)\r\nerrx(1, "interface %s does not exist!", if_name);\r\nstrncpy(ifr.ifr_name, br_name, IFNAMSIZ);\r\nifr.ifr_name[IFNAMSIZ-1] = '\0';\r\nifr.ifr_ifindex = ifidx;\r\nif (ioctl(fd, SIOCBRADDIF, &ifr) < 0)\r\nerr(1, "can't add %s to bridge %s", if_name, br_name);\r\n}\r\nstatic void configure_device(int fd, const char *tapif, u32 ipaddr)\r\n{\r\nstruct ifreq ifr;\r\nstruct sockaddr_in sin;\r\nmemset(&ifr, 0, sizeof(ifr));\r\nstrcpy(ifr.ifr_name, tapif);\r\nsin.sin_family = AF_INET;\r\nsin.sin_addr.s_addr = htonl(ipaddr);\r\nmemcpy(&ifr.ifr_addr, &sin, sizeof(sin));\r\nif (ioctl(fd, SIOCSIFADDR, &ifr) != 0)\r\nerr(1, "Setting %s interface address", tapif);\r\nifr.ifr_flags = IFF_UP;\r\nif (ioctl(fd, SIOCSIFFLAGS, &ifr) != 0)\r\nerr(1, "Bringing interface %s up", tapif);\r\n}\r\nstatic int get_tun_device(char tapif[IFNAMSIZ])\r\n{\r\nstruct ifreq ifr;\r\nint vnet_hdr_sz;\r\nint netfd;\r\nmemset(&ifr, 0, sizeof(ifr));\r\nnetfd = open_or_die("/dev/net/tun", O_RDWR);\r\nifr.ifr_flags = IFF_TAP | IFF_NO_PI | IFF_VNET_HDR;\r\nstrcpy(ifr.ifr_name, "tap%d");\r\nif (ioctl(netfd, TUNSETIFF, &ifr) != 0)\r\nerr(1, "configuring /dev/net/tun");\r\nif (ioctl(netfd, TUNSETOFFLOAD,\r\nTUN_F_CSUM|TUN_F_TSO4|TUN_F_TSO6|TUN_F_TSO_ECN) != 0)\r\nerr(1, "Could not set features for tun device");\r\nioctl(netfd, TUNSETNOCSUM, 1);\r\nvnet_hdr_sz = sizeof(struct virtio_net_hdr_v1);\r\nif (ioctl(netfd, TUNSETVNETHDRSZ, &vnet_hdr_sz) != 0)\r\nerr(1, "Setting tun header size to %u", vnet_hdr_sz);\r\nmemcpy(tapif, ifr.ifr_name, IFNAMSIZ);\r\nreturn netfd;\r\n}\r\nstatic void setup_tun_net(char *arg)\r\n{\r\nstruct device *dev;\r\nstruct net_info *net_info = malloc(sizeof(*net_info));\r\nint ipfd;\r\nu32 ip = INADDR_ANY;\r\nbool bridging = false;\r\nchar tapif[IFNAMSIZ], *p;\r\nstruct virtio_net_config conf;\r\nnet_info->tunfd = get_tun_device(tapif);\r\ndev = new_pci_device("net", VIRTIO_ID_NET, 0x02, 0x00);\r\ndev->priv = net_info;\r\nadd_pci_virtqueue(dev, net_input, "rx");\r\nadd_pci_virtqueue(dev, net_output, "tx");\r\nipfd = socket(PF_INET, SOCK_DGRAM, IPPROTO_IP);\r\nif (ipfd < 0)\r\nerr(1, "opening IP socket");\r\nif (!strncmp(BRIDGE_PFX, arg, strlen(BRIDGE_PFX))) {\r\narg += strlen(BRIDGE_PFX);\r\nbridging = true;\r\n}\r\np = strchr(arg, ':');\r\nif (p) {\r\nstr2mac(p+1, conf.mac);\r\nadd_pci_feature(dev, VIRTIO_NET_F_MAC);\r\n*p = '\0';\r\n}\r\nif (bridging)\r\nadd_to_bridge(ipfd, tapif, arg);\r\nelse\r\nip = str2ip(arg);\r\nconfigure_device(ipfd, tapif, ip);\r\nadd_pci_feature(dev, VIRTIO_NET_F_CSUM);\r\nadd_pci_feature(dev, VIRTIO_NET_F_GUEST_CSUM);\r\nadd_pci_feature(dev, VIRTIO_NET_F_GUEST_TSO4);\r\nadd_pci_feature(dev, VIRTIO_NET_F_GUEST_TSO6);\r\nadd_pci_feature(dev, VIRTIO_NET_F_GUEST_ECN);\r\nadd_pci_feature(dev, VIRTIO_NET_F_HOST_TSO4);\r\nadd_pci_feature(dev, VIRTIO_NET_F_HOST_TSO6);\r\nadd_pci_feature(dev, VIRTIO_NET_F_HOST_ECN);\r\nadd_pci_feature(dev, VIRTIO_RING_F_INDIRECT_DESC);\r\nset_device_config(dev, &conf, sizeof(conf));\r\nclose(ipfd);\r\nif (bridging)\r\nverbose("device %u: tun %s attached to bridge: %s\n",\r\ndevices.device_num, tapif, arg);\r\nelse\r\nverbose("device %u: tun %s: %s\n",\r\ndevices.device_num, tapif, arg);\r\n}\r\nstatic void blk_request(struct virtqueue *vq)\r\n{\r\nstruct vblk_info *vblk = vq->dev->priv;\r\nunsigned int head, out_num, in_num, wlen;\r\nint ret, i;\r\nu8 *in;\r\nstruct virtio_blk_outhdr out;\r\nstruct iovec iov[vq->vring.num];\r\noff64_t off;\r\nhead = wait_for_vq_desc(vq, iov, &out_num, &in_num);\r\niov_consume(vq->dev, iov, out_num, &out, sizeof(out));\r\nin = NULL;\r\nfor (i = out_num + in_num - 1; i >= out_num; i--) {\r\nif (iov[i].iov_len > 0) {\r\nin = iov[i].iov_base + iov[i].iov_len - 1;\r\niov[i].iov_len--;\r\nbreak;\r\n}\r\n}\r\nif (!in)\r\nbad_driver_vq(vq, "Bad virtblk cmd with no room for status");\r\noff = out.sector * 512;\r\nif (out.type & VIRTIO_BLK_T_OUT) {\r\nif (lseek64(vblk->fd, off, SEEK_SET) != off)\r\nerr(1, "Bad seek to sector %llu", out.sector);\r\nret = writev(vblk->fd, iov, out_num);\r\nverbose("WRITE to sector %llu: %i\n", out.sector, ret);\r\nif (ret > 0 && off + ret > vblk->len) {\r\nftruncate64(vblk->fd, vblk->len);\r\nbad_driver_vq(vq, "Write past end %llu+%u", off, ret);\r\n}\r\nwlen = sizeof(*in);\r\n*in = (ret >= 0 ? VIRTIO_BLK_S_OK : VIRTIO_BLK_S_IOERR);\r\n} else if (out.type & VIRTIO_BLK_T_FLUSH) {\r\nret = fdatasync(vblk->fd);\r\nverbose("FLUSH fdatasync: %i\n", ret);\r\nwlen = sizeof(*in);\r\n*in = (ret >= 0 ? VIRTIO_BLK_S_OK : VIRTIO_BLK_S_IOERR);\r\n} else {\r\nif (lseek64(vblk->fd, off, SEEK_SET) != off)\r\nerr(1, "Bad seek to sector %llu", out.sector);\r\nret = readv(vblk->fd, iov + out_num, in_num);\r\nif (ret >= 0) {\r\nwlen = sizeof(*in) + ret;\r\n*in = VIRTIO_BLK_S_OK;\r\n} else {\r\nwlen = sizeof(*in);\r\n*in = VIRTIO_BLK_S_IOERR;\r\n}\r\n}\r\nadd_used(vq, head, wlen);\r\n}\r\nstatic void setup_block_file(const char *filename)\r\n{\r\nstruct device *dev;\r\nstruct vblk_info *vblk;\r\nstruct virtio_blk_config conf;\r\ndev = new_pci_device("block", VIRTIO_ID_BLOCK, 0x01, 0x80);\r\nadd_pci_virtqueue(dev, blk_request, "request");\r\nvblk = dev->priv = malloc(sizeof(*vblk));\r\nvblk->fd = open_or_die(filename, O_RDWR|O_LARGEFILE);\r\nvblk->len = lseek64(vblk->fd, 0, SEEK_END);\r\nconf.capacity = cpu_to_le64(vblk->len / 512);\r\nadd_pci_feature(dev, VIRTIO_BLK_F_SEG_MAX);\r\nconf.seg_max = cpu_to_le32(VIRTQUEUE_NUM - 2);\r\nset_device_config(dev, &conf, sizeof(struct virtio_blk_config));\r\nverbose("device %u: virtblock %llu sectors\n",\r\ndevices.device_num, le64_to_cpu(conf.capacity));\r\n}\r\nstatic void rng_input(struct virtqueue *vq)\r\n{\r\nint len;\r\nunsigned int head, in_num, out_num, totlen = 0;\r\nstruct rng_info *rng_info = vq->dev->priv;\r\nstruct iovec iov[vq->vring.num];\r\nhead = wait_for_vq_desc(vq, iov, &out_num, &in_num);\r\nif (out_num)\r\nbad_driver_vq(vq, "Output buffers in rng?");\r\nwhile (!iov_empty(iov, in_num)) {\r\nlen = readv(rng_info->rfd, iov, in_num);\r\nif (len <= 0)\r\nerr(1, "Read from /dev/urandom gave %i", len);\r\niov_consume(vq->dev, iov, in_num, NULL, len);\r\ntotlen += len;\r\n}\r\nadd_used(vq, head, totlen);\r\n}\r\nstatic void setup_rng(void)\r\n{\r\nstruct device *dev;\r\nstruct rng_info *rng_info = malloc(sizeof(*rng_info));\r\nrng_info->rfd = open_or_die("/dev/urandom", O_RDONLY);\r\ndev = new_pci_device("rng", VIRTIO_ID_RNG, 0xff, 0);\r\ndev->priv = rng_info;\r\nadd_pci_virtqueue(dev, rng_input, "input");\r\nno_device_config(dev);\r\nverbose("device %u: rng\n", devices.device_num);\r\n}\r\nstatic void usage(void)\r\n{\r\nerrx(1, "Usage: lguest [--verbose] "\r\n"[--tunnet=(<ipaddr>:<macaddr>|bridge:<bridgename>:<macaddr>)\n"\r\n"|--block=<filename>|--initrd=<filename>]...\n"\r\n"<mem-in-mb> vmlinux [args...]");\r\n}\r\nint main(int argc, char *argv[])\r\n{\r\nunsigned long mem = 0, start, initrd_size = 0;\r\nint i, c;\r\nstruct boot_params *boot;\r\nconst char *initrd_name = NULL;\r\nstruct passwd *user_details = NULL;\r\nchar *chroot_path = NULL;\r\nmain_args = argv;\r\ndevices.next_irq = 1;\r\ncpu_id = 0;\r\nfor (i = 1; i < argc; i++) {\r\nif (argv[i][0] != '-') {\r\nmem = atoi(argv[i]) * 1024 * 1024;\r\nguest_base = map_zeroed_pages(mem / getpagesize()\r\n+ DEVICE_PAGES);\r\nguest_limit = mem;\r\nguest_max = guest_mmio = mem + DEVICE_PAGES*getpagesize();\r\nbreak;\r\n}\r\n}\r\natexit(cleanup_devices);\r\nsetup_console();\r\nwhile ((c = getopt_long(argc, argv, "v", opts, NULL)) != EOF) {\r\nswitch (c) {\r\ncase 'v':\r\nverbose = true;\r\nbreak;\r\ncase 't':\r\nsetup_tun_net(optarg);\r\nbreak;\r\ncase 'b':\r\nsetup_block_file(optarg);\r\nbreak;\r\ncase 'r':\r\nsetup_rng();\r\nbreak;\r\ncase 'i':\r\ninitrd_name = optarg;\r\nbreak;\r\ncase 'u':\r\nuser_details = getpwnam(optarg);\r\nif (!user_details)\r\nerr(1, "getpwnam failed, incorrect username?");\r\nbreak;\r\ncase 'c':\r\nchroot_path = optarg;\r\nbreak;\r\ndefault:\r\nwarnx("Unknown argument %s", argv[optind]);\r\nusage();\r\n}\r\n}\r\nif (optind + 2 > argc)\r\nusage();\r\nverbose("Guest base is at %p\n", guest_base);\r\ninit_pci_host_bridge();\r\nstart = load_kernel(open_or_die(argv[optind+1], O_RDONLY));\r\nboot = from_guest_phys(0);\r\nif (initrd_name) {\r\ninitrd_size = load_initrd(initrd_name, mem);\r\nboot->hdr.ramdisk_image = mem - initrd_size;\r\nboot->hdr.ramdisk_size = initrd_size;\r\nboot->hdr.type_of_loader = 0xFF;\r\n}\r\nboot->e820_entries = 1;\r\nboot->e820_map[0] = ((struct e820entry) { 0, mem, E820_RAM });\r\nboot->hdr.cmd_line_ptr = to_guest_phys(boot + 1);\r\nconcat((char *)(boot + 1), argv+optind+2);\r\nboot->hdr.kernel_alignment = 0x1000000;\r\nboot->hdr.version = 0x207;\r\nboot->hdr.hardware_subarch = X86_SUBARCH_LGUEST;\r\nboot->hdr.loadflags |= KEEP_SEGMENTS;\r\nboot->tboot_addr = 0;\r\nboot->apm_bios_info.version = 0;\r\ntell_kernel(start);\r\nsignal(SIGCHLD, kill_launcher);\r\nif (chroot_path) {\r\nif (chroot(chroot_path) != 0)\r\nerr(1, "chroot(\"%s\") failed", chroot_path);\r\nif (chdir("/") != 0)\r\nerr(1, "chdir(\"/\") failed");\r\nverbose("chroot done\n");\r\n}\r\nif (user_details) {\r\nuid_t u;\r\ngid_t g;\r\nu = user_details->pw_uid;\r\ng = user_details->pw_gid;\r\nif (initgroups(user_details->pw_name, g) != 0)\r\nerr(1, "initgroups failed");\r\nif (setresgid(g, g, g) != 0)\r\nerr(1, "setresgid failed");\r\nif (setresuid(u, u, u) != 0)\r\nerr(1, "setresuid failed");\r\nverbose("Dropping privileges completed\n");\r\n}\r\nrun_guest();\r\n}
