static inline bool qlcnic_sriov_bc_msg_check(u32 val)\r\n{\r\nreturn (val & (1 << QLC_BC_MSG)) ? true : false;\r\n}\r\nstatic inline bool qlcnic_sriov_channel_free_check(u32 val)\r\n{\r\nreturn (val & (1 << QLC_BC_CFREE)) ? true : false;\r\n}\r\nstatic inline bool qlcnic_sriov_flr_check(u32 val)\r\n{\r\nreturn (val & (1 << QLC_BC_FLR)) ? true : false;\r\n}\r\nstatic inline u8 qlcnic_sriov_target_func_id(u32 val)\r\n{\r\nreturn (val >> 4) & 0xff;\r\n}\r\nstatic int qlcnic_sriov_virtid_fn(struct qlcnic_adapter *adapter, int vf_id)\r\n{\r\nstruct pci_dev *dev = adapter->pdev;\r\nint pos;\r\nu16 stride, offset;\r\nif (qlcnic_sriov_vf_check(adapter))\r\nreturn 0;\r\npos = pci_find_ext_capability(dev, PCI_EXT_CAP_ID_SRIOV);\r\npci_read_config_word(dev, pos + PCI_SRIOV_VF_OFFSET, &offset);\r\npci_read_config_word(dev, pos + PCI_SRIOV_VF_STRIDE, &stride);\r\nreturn (dev->devfn + offset + stride * vf_id) & 0xff;\r\n}\r\nint qlcnic_sriov_init(struct qlcnic_adapter *adapter, int num_vfs)\r\n{\r\nstruct qlcnic_sriov *sriov;\r\nstruct qlcnic_back_channel *bc;\r\nstruct workqueue_struct *wq;\r\nstruct qlcnic_vport *vp;\r\nstruct qlcnic_vf_info *vf;\r\nint err, i;\r\nif (!qlcnic_sriov_enable_check(adapter))\r\nreturn -EIO;\r\nsriov = kzalloc(sizeof(struct qlcnic_sriov), GFP_KERNEL);\r\nif (!sriov)\r\nreturn -ENOMEM;\r\nadapter->ahw->sriov = sriov;\r\nsriov->num_vfs = num_vfs;\r\nbc = &sriov->bc;\r\nsriov->vf_info = kzalloc(sizeof(struct qlcnic_vf_info) *\r\nnum_vfs, GFP_KERNEL);\r\nif (!sriov->vf_info) {\r\nerr = -ENOMEM;\r\ngoto qlcnic_free_sriov;\r\n}\r\nwq = create_singlethread_workqueue("bc-trans");\r\nif (wq == NULL) {\r\nerr = -ENOMEM;\r\ndev_err(&adapter->pdev->dev,\r\n"Cannot create bc-trans workqueue\n");\r\ngoto qlcnic_free_vf_info;\r\n}\r\nbc->bc_trans_wq = wq;\r\nwq = create_singlethread_workqueue("async");\r\nif (wq == NULL) {\r\nerr = -ENOMEM;\r\ndev_err(&adapter->pdev->dev, "Cannot create async workqueue\n");\r\ngoto qlcnic_destroy_trans_wq;\r\n}\r\nbc->bc_async_wq = wq;\r\nINIT_LIST_HEAD(&bc->async_cmd_list);\r\nINIT_WORK(&bc->vf_async_work, qlcnic_sriov_handle_async_issue_cmd);\r\nspin_lock_init(&bc->queue_lock);\r\nbc->adapter = adapter;\r\nfor (i = 0; i < num_vfs; i++) {\r\nvf = &sriov->vf_info[i];\r\nvf->adapter = adapter;\r\nvf->pci_func = qlcnic_sriov_virtid_fn(adapter, i);\r\nmutex_init(&vf->send_cmd_lock);\r\nspin_lock_init(&vf->vlan_list_lock);\r\nINIT_LIST_HEAD(&vf->rcv_act.wait_list);\r\nINIT_LIST_HEAD(&vf->rcv_pend.wait_list);\r\nspin_lock_init(&vf->rcv_act.lock);\r\nspin_lock_init(&vf->rcv_pend.lock);\r\ninit_completion(&vf->ch_free_cmpl);\r\nINIT_WORK(&vf->trans_work, qlcnic_sriov_process_bc_cmd);\r\nif (qlcnic_sriov_pf_check(adapter)) {\r\nvp = kzalloc(sizeof(struct qlcnic_vport), GFP_KERNEL);\r\nif (!vp) {\r\nerr = -ENOMEM;\r\ngoto qlcnic_destroy_async_wq;\r\n}\r\nsriov->vf_info[i].vp = vp;\r\nvp->vlan_mode = QLC_GUEST_VLAN_MODE;\r\nvp->max_tx_bw = MAX_BW;\r\nvp->min_tx_bw = MIN_BW;\r\nvp->spoofchk = false;\r\nrandom_ether_addr(vp->mac);\r\ndev_info(&adapter->pdev->dev,\r\n"MAC Address %pM is configured for VF %d\n",\r\nvp->mac, i);\r\n}\r\n}\r\nreturn 0;\r\nqlcnic_destroy_async_wq:\r\ndestroy_workqueue(bc->bc_async_wq);\r\nqlcnic_destroy_trans_wq:\r\ndestroy_workqueue(bc->bc_trans_wq);\r\nqlcnic_free_vf_info:\r\nkfree(sriov->vf_info);\r\nqlcnic_free_sriov:\r\nkfree(adapter->ahw->sriov);\r\nreturn err;\r\n}\r\nvoid qlcnic_sriov_cleanup_list(struct qlcnic_trans_list *t_list)\r\n{\r\nstruct qlcnic_bc_trans *trans;\r\nstruct qlcnic_cmd_args cmd;\r\nunsigned long flags;\r\nspin_lock_irqsave(&t_list->lock, flags);\r\nwhile (!list_empty(&t_list->wait_list)) {\r\ntrans = list_first_entry(&t_list->wait_list,\r\nstruct qlcnic_bc_trans, list);\r\nlist_del(&trans->list);\r\nt_list->count--;\r\ncmd.req.arg = (u32 *)trans->req_pay;\r\ncmd.rsp.arg = (u32 *)trans->rsp_pay;\r\nqlcnic_free_mbx_args(&cmd);\r\nqlcnic_sriov_cleanup_transaction(trans);\r\n}\r\nspin_unlock_irqrestore(&t_list->lock, flags);\r\n}\r\nvoid __qlcnic_sriov_cleanup(struct qlcnic_adapter *adapter)\r\n{\r\nstruct qlcnic_sriov *sriov = adapter->ahw->sriov;\r\nstruct qlcnic_back_channel *bc = &sriov->bc;\r\nstruct qlcnic_vf_info *vf;\r\nint i;\r\nif (!qlcnic_sriov_enable_check(adapter))\r\nreturn;\r\nqlcnic_sriov_cleanup_async_list(bc);\r\ndestroy_workqueue(bc->bc_async_wq);\r\nfor (i = 0; i < sriov->num_vfs; i++) {\r\nvf = &sriov->vf_info[i];\r\nqlcnic_sriov_cleanup_list(&vf->rcv_pend);\r\ncancel_work_sync(&vf->trans_work);\r\nqlcnic_sriov_cleanup_list(&vf->rcv_act);\r\n}\r\ndestroy_workqueue(bc->bc_trans_wq);\r\nfor (i = 0; i < sriov->num_vfs; i++)\r\nkfree(sriov->vf_info[i].vp);\r\nkfree(sriov->vf_info);\r\nkfree(adapter->ahw->sriov);\r\n}\r\nstatic void qlcnic_sriov_vf_cleanup(struct qlcnic_adapter *adapter)\r\n{\r\nqlcnic_sriov_channel_cfg_cmd(adapter, QLCNIC_BC_CMD_CHANNEL_TERM);\r\nqlcnic_sriov_cfg_bc_intr(adapter, 0);\r\n__qlcnic_sriov_cleanup(adapter);\r\n}\r\nvoid qlcnic_sriov_cleanup(struct qlcnic_adapter *adapter)\r\n{\r\nif (!test_bit(__QLCNIC_SRIOV_ENABLE, &adapter->state))\r\nreturn;\r\nqlcnic_sriov_free_vlans(adapter);\r\nif (qlcnic_sriov_pf_check(adapter))\r\nqlcnic_sriov_pf_cleanup(adapter);\r\nif (qlcnic_sriov_vf_check(adapter))\r\nqlcnic_sriov_vf_cleanup(adapter);\r\n}\r\nstatic int qlcnic_sriov_post_bc_msg(struct qlcnic_adapter *adapter, u32 *hdr,\r\nu32 *pay, u8 pci_func, u8 size)\r\n{\r\nstruct qlcnic_hardware_context *ahw = adapter->ahw;\r\nstruct qlcnic_mailbox *mbx = ahw->mailbox;\r\nstruct qlcnic_cmd_args cmd;\r\nunsigned long timeout;\r\nint err;\r\nmemset(&cmd, 0, sizeof(struct qlcnic_cmd_args));\r\ncmd.hdr = hdr;\r\ncmd.pay = pay;\r\ncmd.pay_size = size;\r\ncmd.func_num = pci_func;\r\ncmd.op_type = QLC_83XX_MBX_POST_BC_OP;\r\ncmd.cmd_op = ((struct qlcnic_bc_hdr *)hdr)->cmd_op;\r\nerr = mbx->ops->enqueue_cmd(adapter, &cmd, &timeout);\r\nif (err) {\r\ndev_err(&adapter->pdev->dev,\r\n"%s: Mailbox not available, cmd_op=0x%x, cmd_type=0x%x, pci_func=0x%x, op_mode=0x%x\n",\r\n__func__, cmd.cmd_op, cmd.type, ahw->pci_func,\r\nahw->op_mode);\r\nreturn err;\r\n}\r\nif (!wait_for_completion_timeout(&cmd.completion, timeout)) {\r\ndev_err(&adapter->pdev->dev,\r\n"%s: Mailbox command timed out, cmd_op=0x%x, cmd_type=0x%x, pci_func=0x%x, op_mode=0x%x\n",\r\n__func__, cmd.cmd_op, cmd.type, ahw->pci_func,\r\nahw->op_mode);\r\nflush_workqueue(mbx->work_q);\r\n}\r\nreturn cmd.rsp_opcode;\r\n}\r\nstatic void qlcnic_sriov_vf_cfg_buff_desc(struct qlcnic_adapter *adapter)\r\n{\r\nadapter->num_rxd = QLC_DEFAULT_RCV_DESCRIPTORS_SRIOV_VF;\r\nadapter->max_rxd = MAX_RCV_DESCRIPTORS_10G;\r\nadapter->num_jumbo_rxd = QLC_DEFAULT_JUMBO_RCV_DESCRIPTORS_SRIOV_VF;\r\nadapter->max_jumbo_rxd = MAX_JUMBO_RCV_DESCRIPTORS_10G;\r\nadapter->num_txd = MAX_CMD_DESCRIPTORS;\r\nadapter->max_rds_rings = MAX_RDS_RINGS;\r\n}\r\nint qlcnic_sriov_get_vf_vport_info(struct qlcnic_adapter *adapter,\r\nstruct qlcnic_info *npar_info, u16 vport_id)\r\n{\r\nstruct device *dev = &adapter->pdev->dev;\r\nstruct qlcnic_cmd_args cmd;\r\nint err;\r\nu32 status;\r\nerr = qlcnic_alloc_mbx_args(&cmd, adapter, QLCNIC_CMD_GET_NIC_INFO);\r\nif (err)\r\nreturn err;\r\ncmd.req.arg[1] = vport_id << 16 | 0x1;\r\nerr = qlcnic_issue_cmd(adapter, &cmd);\r\nif (err) {\r\ndev_err(&adapter->pdev->dev,\r\n"Failed to get vport info, err=%d\n", err);\r\nqlcnic_free_mbx_args(&cmd);\r\nreturn err;\r\n}\r\nstatus = cmd.rsp.arg[2] & 0xffff;\r\nif (status & BIT_0)\r\nnpar_info->min_tx_bw = MSW(cmd.rsp.arg[2]);\r\nif (status & BIT_1)\r\nnpar_info->max_tx_bw = LSW(cmd.rsp.arg[3]);\r\nif (status & BIT_2)\r\nnpar_info->max_tx_ques = MSW(cmd.rsp.arg[3]);\r\nif (status & BIT_3)\r\nnpar_info->max_tx_mac_filters = LSW(cmd.rsp.arg[4]);\r\nif (status & BIT_4)\r\nnpar_info->max_rx_mcast_mac_filters = MSW(cmd.rsp.arg[4]);\r\nif (status & BIT_5)\r\nnpar_info->max_rx_ucast_mac_filters = LSW(cmd.rsp.arg[5]);\r\nif (status & BIT_6)\r\nnpar_info->max_rx_ip_addr = MSW(cmd.rsp.arg[5]);\r\nif (status & BIT_7)\r\nnpar_info->max_rx_lro_flow = LSW(cmd.rsp.arg[6]);\r\nif (status & BIT_8)\r\nnpar_info->max_rx_status_rings = MSW(cmd.rsp.arg[6]);\r\nif (status & BIT_9)\r\nnpar_info->max_rx_buf_rings = LSW(cmd.rsp.arg[7]);\r\nnpar_info->max_rx_ques = MSW(cmd.rsp.arg[7]);\r\nnpar_info->max_tx_vlan_keys = LSW(cmd.rsp.arg[8]);\r\nnpar_info->max_local_ipv6_addrs = MSW(cmd.rsp.arg[8]);\r\nnpar_info->max_remote_ipv6_addrs = LSW(cmd.rsp.arg[9]);\r\ndev_info(dev, "\n\tmin_tx_bw: %d, max_tx_bw: %d max_tx_ques: %d,\n"\r\n"\tmax_tx_mac_filters: %d max_rx_mcast_mac_filters: %d,\n"\r\n"\tmax_rx_ucast_mac_filters: 0x%x, max_rx_ip_addr: %d,\n"\r\n"\tmax_rx_lro_flow: %d max_rx_status_rings: %d,\n"\r\n"\tmax_rx_buf_rings: %d, max_rx_ques: %d, max_tx_vlan_keys %d\n"\r\n"\tlocal_ipv6_addr: %d, remote_ipv6_addr: %d\n",\r\nnpar_info->min_tx_bw, npar_info->max_tx_bw,\r\nnpar_info->max_tx_ques, npar_info->max_tx_mac_filters,\r\nnpar_info->max_rx_mcast_mac_filters,\r\nnpar_info->max_rx_ucast_mac_filters, npar_info->max_rx_ip_addr,\r\nnpar_info->max_rx_lro_flow, npar_info->max_rx_status_rings,\r\nnpar_info->max_rx_buf_rings, npar_info->max_rx_ques,\r\nnpar_info->max_tx_vlan_keys, npar_info->max_local_ipv6_addrs,\r\nnpar_info->max_remote_ipv6_addrs);\r\nqlcnic_free_mbx_args(&cmd);\r\nreturn err;\r\n}\r\nstatic int qlcnic_sriov_set_pvid_mode(struct qlcnic_adapter *adapter,\r\nstruct qlcnic_cmd_args *cmd)\r\n{\r\nadapter->rx_pvid = MSW(cmd->rsp.arg[1]) & 0xffff;\r\nadapter->flags &= ~QLCNIC_TAGGING_ENABLED;\r\nreturn 0;\r\n}\r\nstatic int qlcnic_sriov_set_guest_vlan_mode(struct qlcnic_adapter *adapter,\r\nstruct qlcnic_cmd_args *cmd)\r\n{\r\nstruct qlcnic_sriov *sriov = adapter->ahw->sriov;\r\nint i, num_vlans;\r\nu16 *vlans;\r\nif (sriov->allowed_vlans)\r\nreturn 0;\r\nsriov->any_vlan = cmd->rsp.arg[2] & 0xf;\r\nsriov->num_allowed_vlans = cmd->rsp.arg[2] >> 16;\r\ndev_info(&adapter->pdev->dev, "Number of allowed Guest VLANs = %d\n",\r\nsriov->num_allowed_vlans);\r\nqlcnic_sriov_alloc_vlans(adapter);\r\nif (!sriov->any_vlan)\r\nreturn 0;\r\nnum_vlans = sriov->num_allowed_vlans;\r\nsriov->allowed_vlans = kzalloc(sizeof(u16) * num_vlans, GFP_KERNEL);\r\nif (!sriov->allowed_vlans)\r\nreturn -ENOMEM;\r\nvlans = (u16 *)&cmd->rsp.arg[3];\r\nfor (i = 0; i < num_vlans; i++)\r\nsriov->allowed_vlans[i] = vlans[i];\r\nreturn 0;\r\n}\r\nstatic int qlcnic_sriov_get_vf_acl(struct qlcnic_adapter *adapter)\r\n{\r\nstruct qlcnic_sriov *sriov = adapter->ahw->sriov;\r\nstruct qlcnic_cmd_args cmd;\r\nint ret = 0;\r\nmemset(&cmd, 0, sizeof(cmd));\r\nret = qlcnic_sriov_alloc_bc_mbx_args(&cmd, QLCNIC_BC_CMD_GET_ACL);\r\nif (ret)\r\nreturn ret;\r\nret = qlcnic_issue_cmd(adapter, &cmd);\r\nif (ret) {\r\ndev_err(&adapter->pdev->dev, "Failed to get ACL, err=%d\n",\r\nret);\r\n} else {\r\nsriov->vlan_mode = cmd.rsp.arg[1] & 0x3;\r\nswitch (sriov->vlan_mode) {\r\ncase QLC_GUEST_VLAN_MODE:\r\nret = qlcnic_sriov_set_guest_vlan_mode(adapter, &cmd);\r\nbreak;\r\ncase QLC_PVID_MODE:\r\nret = qlcnic_sriov_set_pvid_mode(adapter, &cmd);\r\nbreak;\r\n}\r\n}\r\nqlcnic_free_mbx_args(&cmd);\r\nreturn ret;\r\n}\r\nstatic int qlcnic_sriov_vf_init_driver(struct qlcnic_adapter *adapter)\r\n{\r\nstruct qlcnic_hardware_context *ahw = adapter->ahw;\r\nstruct qlcnic_info nic_info;\r\nint err;\r\nerr = qlcnic_sriov_get_vf_vport_info(adapter, &nic_info, 0);\r\nif (err)\r\nreturn err;\r\nahw->max_mc_count = nic_info.max_rx_mcast_mac_filters;\r\nerr = qlcnic_get_nic_info(adapter, &nic_info, ahw->pci_func);\r\nif (err)\r\nreturn -EIO;\r\nif (qlcnic_83xx_get_port_info(adapter))\r\nreturn -EIO;\r\nqlcnic_sriov_vf_cfg_buff_desc(adapter);\r\nadapter->flags |= QLCNIC_ADAPTER_INITIALIZED;\r\ndev_info(&adapter->pdev->dev, "HAL Version: %d\n",\r\nadapter->ahw->fw_hal_version);\r\nahw->physical_port = (u8) nic_info.phys_port;\r\nahw->switch_mode = nic_info.switch_mode;\r\nahw->max_mtu = nic_info.max_mtu;\r\nahw->op_mode = nic_info.op_mode;\r\nahw->capabilities = nic_info.capabilities;\r\nreturn 0;\r\n}\r\nstatic int qlcnic_sriov_setup_vf(struct qlcnic_adapter *adapter,\r\nint pci_using_dac)\r\n{\r\nint err;\r\nadapter->flags |= QLCNIC_VLAN_FILTERING;\r\nadapter->ahw->total_nic_func = 1;\r\nINIT_LIST_HEAD(&adapter->vf_mc_list);\r\nif (!qlcnic_use_msi_x && !!qlcnic_use_msi)\r\ndev_warn(&adapter->pdev->dev,\r\n"Device does not support MSI interrupts\n");\r\nqlcnic_set_tx_ring_count(adapter, QLCNIC_SINGLE_RING);\r\nqlcnic_set_sds_ring_count(adapter, QLCNIC_SINGLE_RING);\r\nerr = qlcnic_setup_intr(adapter);\r\nif (err) {\r\ndev_err(&adapter->pdev->dev, "Failed to setup interrupt\n");\r\ngoto err_out_disable_msi;\r\n}\r\nerr = qlcnic_83xx_setup_mbx_intr(adapter);\r\nif (err)\r\ngoto err_out_disable_msi;\r\nerr = qlcnic_sriov_init(adapter, 1);\r\nif (err)\r\ngoto err_out_disable_mbx_intr;\r\nerr = qlcnic_sriov_cfg_bc_intr(adapter, 1);\r\nif (err)\r\ngoto err_out_cleanup_sriov;\r\nerr = qlcnic_sriov_channel_cfg_cmd(adapter, QLCNIC_BC_CMD_CHANNEL_INIT);\r\nif (err)\r\ngoto err_out_disable_bc_intr;\r\nerr = qlcnic_sriov_vf_init_driver(adapter);\r\nif (err)\r\ngoto err_out_send_channel_term;\r\nerr = qlcnic_sriov_get_vf_acl(adapter);\r\nif (err)\r\ngoto err_out_send_channel_term;\r\nerr = qlcnic_setup_netdev(adapter, adapter->netdev, pci_using_dac);\r\nif (err)\r\ngoto err_out_send_channel_term;\r\npci_set_drvdata(adapter->pdev, adapter);\r\ndev_info(&adapter->pdev->dev, "%s: XGbE port initialized\n",\r\nadapter->netdev->name);\r\nqlcnic_schedule_work(adapter, qlcnic_sriov_vf_poll_dev_state,\r\nadapter->ahw->idc.delay);\r\nreturn 0;\r\nerr_out_send_channel_term:\r\nqlcnic_sriov_channel_cfg_cmd(adapter, QLCNIC_BC_CMD_CHANNEL_TERM);\r\nerr_out_disable_bc_intr:\r\nqlcnic_sriov_cfg_bc_intr(adapter, 0);\r\nerr_out_cleanup_sriov:\r\n__qlcnic_sriov_cleanup(adapter);\r\nerr_out_disable_mbx_intr:\r\nqlcnic_83xx_free_mbx_intr(adapter);\r\nerr_out_disable_msi:\r\nqlcnic_teardown_intr(adapter);\r\nreturn err;\r\n}\r\nstatic int qlcnic_sriov_check_dev_ready(struct qlcnic_adapter *adapter)\r\n{\r\nu32 state;\r\ndo {\r\nmsleep(20);\r\nif (++adapter->fw_fail_cnt > QLC_BC_CMD_MAX_RETRY_CNT)\r\nreturn -EIO;\r\nstate = QLCRDX(adapter->ahw, QLC_83XX_IDC_DEV_STATE);\r\n} while (state != QLC_83XX_IDC_DEV_READY);\r\nreturn 0;\r\n}\r\nint qlcnic_sriov_vf_init(struct qlcnic_adapter *adapter, int pci_using_dac)\r\n{\r\nstruct qlcnic_hardware_context *ahw = adapter->ahw;\r\nint err;\r\nset_bit(QLC_83XX_MODULE_LOADED, &ahw->idc.status);\r\nahw->idc.delay = QLC_83XX_IDC_FW_POLL_DELAY;\r\nahw->reset_context = 0;\r\nadapter->fw_fail_cnt = 0;\r\nahw->msix_supported = 1;\r\nadapter->need_fw_reset = 0;\r\nadapter->flags |= QLCNIC_TX_INTR_SHARED;\r\nerr = qlcnic_sriov_check_dev_ready(adapter);\r\nif (err)\r\nreturn err;\r\nerr = qlcnic_sriov_setup_vf(adapter, pci_using_dac);\r\nif (err)\r\nreturn err;\r\nif (qlcnic_read_mac_addr(adapter))\r\ndev_warn(&adapter->pdev->dev, "failed to read mac addr\n");\r\nINIT_DELAYED_WORK(&adapter->idc_aen_work, qlcnic_83xx_idc_aen_work);\r\nclear_bit(__QLCNIC_RESETTING, &adapter->state);\r\nreturn 0;\r\n}\r\nvoid qlcnic_sriov_vf_set_ops(struct qlcnic_adapter *adapter)\r\n{\r\nstruct qlcnic_hardware_context *ahw = adapter->ahw;\r\nahw->op_mode = QLCNIC_SRIOV_VF_FUNC;\r\ndev_info(&adapter->pdev->dev,\r\n"HAL Version: %d Non Privileged SRIOV function\n",\r\nahw->fw_hal_version);\r\nadapter->nic_ops = &qlcnic_sriov_vf_ops;\r\nset_bit(__QLCNIC_SRIOV_ENABLE, &adapter->state);\r\nreturn;\r\n}\r\nvoid qlcnic_sriov_vf_register_map(struct qlcnic_hardware_context *ahw)\r\n{\r\nahw->hw_ops = &qlcnic_sriov_vf_hw_ops;\r\nahw->reg_tbl = (u32 *)qlcnic_83xx_reg_tbl;\r\nahw->ext_reg_tbl = (u32 *)qlcnic_83xx_ext_reg_tbl;\r\n}\r\nstatic u32 qlcnic_sriov_get_bc_paysize(u32 real_pay_size, u8 curr_frag)\r\n{\r\nu32 pay_size;\r\npay_size = real_pay_size / ((curr_frag + 1) * QLC_BC_PAYLOAD_SZ);\r\nif (pay_size)\r\npay_size = QLC_BC_PAYLOAD_SZ;\r\nelse\r\npay_size = real_pay_size % QLC_BC_PAYLOAD_SZ;\r\nreturn pay_size;\r\n}\r\nint qlcnic_sriov_func_to_index(struct qlcnic_adapter *adapter, u8 pci_func)\r\n{\r\nstruct qlcnic_vf_info *vf_info = adapter->ahw->sriov->vf_info;\r\nu8 i;\r\nif (qlcnic_sriov_vf_check(adapter))\r\nreturn 0;\r\nfor (i = 0; i < adapter->ahw->sriov->num_vfs; i++) {\r\nif (vf_info[i].pci_func == pci_func)\r\nreturn i;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic inline int qlcnic_sriov_alloc_bc_trans(struct qlcnic_bc_trans **trans)\r\n{\r\n*trans = kzalloc(sizeof(struct qlcnic_bc_trans), GFP_ATOMIC);\r\nif (!*trans)\r\nreturn -ENOMEM;\r\ninit_completion(&(*trans)->resp_cmpl);\r\nreturn 0;\r\n}\r\nstatic inline int qlcnic_sriov_alloc_bc_msg(struct qlcnic_bc_hdr **hdr,\r\nu32 size)\r\n{\r\n*hdr = kzalloc(sizeof(struct qlcnic_bc_hdr) * size, GFP_ATOMIC);\r\nif (!*hdr)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nstatic int qlcnic_sriov_alloc_bc_mbx_args(struct qlcnic_cmd_args *mbx, u32 type)\r\n{\r\nconst struct qlcnic_mailbox_metadata *mbx_tbl;\r\nint i, size;\r\nmbx_tbl = qlcnic_sriov_bc_mbx_tbl;\r\nsize = ARRAY_SIZE(qlcnic_sriov_bc_mbx_tbl);\r\nfor (i = 0; i < size; i++) {\r\nif (type == mbx_tbl[i].cmd) {\r\nmbx->op_type = QLC_BC_CMD;\r\nmbx->req.num = mbx_tbl[i].in_args;\r\nmbx->rsp.num = mbx_tbl[i].out_args;\r\nmbx->req.arg = kcalloc(mbx->req.num, sizeof(u32),\r\nGFP_ATOMIC);\r\nif (!mbx->req.arg)\r\nreturn -ENOMEM;\r\nmbx->rsp.arg = kcalloc(mbx->rsp.num, sizeof(u32),\r\nGFP_ATOMIC);\r\nif (!mbx->rsp.arg) {\r\nkfree(mbx->req.arg);\r\nmbx->req.arg = NULL;\r\nreturn -ENOMEM;\r\n}\r\nmbx->req.arg[0] = (type | (mbx->req.num << 16) |\r\n(3 << 29));\r\nmbx->rsp.arg[0] = (type & 0xffff) | mbx->rsp.num << 16;\r\nreturn 0;\r\n}\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic int qlcnic_sriov_prepare_bc_hdr(struct qlcnic_bc_trans *trans,\r\nstruct qlcnic_cmd_args *cmd,\r\nu16 seq, u8 msg_type)\r\n{\r\nstruct qlcnic_bc_hdr *hdr;\r\nint i;\r\nu32 num_regs, bc_pay_sz;\r\nu16 remainder;\r\nu8 cmd_op, num_frags, t_num_frags;\r\nbc_pay_sz = QLC_BC_PAYLOAD_SZ;\r\nif (msg_type == QLC_BC_COMMAND) {\r\ntrans->req_pay = (struct qlcnic_bc_payload *)cmd->req.arg;\r\ntrans->rsp_pay = (struct qlcnic_bc_payload *)cmd->rsp.arg;\r\nnum_regs = cmd->req.num;\r\ntrans->req_pay_size = (num_regs * 4);\r\nnum_regs = cmd->rsp.num;\r\ntrans->rsp_pay_size = (num_regs * 4);\r\ncmd_op = cmd->req.arg[0] & 0xff;\r\nremainder = (trans->req_pay_size) % (bc_pay_sz);\r\nnum_frags = (trans->req_pay_size) / (bc_pay_sz);\r\nif (remainder)\r\nnum_frags++;\r\nt_num_frags = num_frags;\r\nif (qlcnic_sriov_alloc_bc_msg(&trans->req_hdr, num_frags))\r\nreturn -ENOMEM;\r\nremainder = (trans->rsp_pay_size) % (bc_pay_sz);\r\nnum_frags = (trans->rsp_pay_size) / (bc_pay_sz);\r\nif (remainder)\r\nnum_frags++;\r\nif (qlcnic_sriov_alloc_bc_msg(&trans->rsp_hdr, num_frags))\r\nreturn -ENOMEM;\r\nnum_frags = t_num_frags;\r\nhdr = trans->req_hdr;\r\n} else {\r\ncmd->req.arg = (u32 *)trans->req_pay;\r\ncmd->rsp.arg = (u32 *)trans->rsp_pay;\r\ncmd_op = cmd->req.arg[0] & 0xff;\r\ncmd->cmd_op = cmd_op;\r\nremainder = (trans->rsp_pay_size) % (bc_pay_sz);\r\nnum_frags = (trans->rsp_pay_size) / (bc_pay_sz);\r\nif (remainder)\r\nnum_frags++;\r\ncmd->req.num = trans->req_pay_size / 4;\r\ncmd->rsp.num = trans->rsp_pay_size / 4;\r\nhdr = trans->rsp_hdr;\r\ncmd->op_type = trans->req_hdr->op_type;\r\n}\r\ntrans->trans_id = seq;\r\ntrans->cmd_id = cmd_op;\r\nfor (i = 0; i < num_frags; i++) {\r\nhdr[i].version = 2;\r\nhdr[i].msg_type = msg_type;\r\nhdr[i].op_type = cmd->op_type;\r\nhdr[i].num_cmds = 1;\r\nhdr[i].num_frags = num_frags;\r\nhdr[i].frag_num = i + 1;\r\nhdr[i].cmd_op = cmd_op;\r\nhdr[i].seq_id = seq;\r\n}\r\nreturn 0;\r\n}\r\nstatic void qlcnic_sriov_cleanup_transaction(struct qlcnic_bc_trans *trans)\r\n{\r\nif (!trans)\r\nreturn;\r\nkfree(trans->req_hdr);\r\nkfree(trans->rsp_hdr);\r\nkfree(trans);\r\n}\r\nstatic int qlcnic_sriov_clear_trans(struct qlcnic_vf_info *vf,\r\nstruct qlcnic_bc_trans *trans, u8 type)\r\n{\r\nstruct qlcnic_trans_list *t_list;\r\nunsigned long flags;\r\nint ret = 0;\r\nif (type == QLC_BC_RESPONSE) {\r\nt_list = &vf->rcv_act;\r\nspin_lock_irqsave(&t_list->lock, flags);\r\nt_list->count--;\r\nlist_del(&trans->list);\r\nif (t_list->count > 0)\r\nret = 1;\r\nspin_unlock_irqrestore(&t_list->lock, flags);\r\n}\r\nif (type == QLC_BC_COMMAND) {\r\nwhile (test_and_set_bit(QLC_BC_VF_SEND, &vf->state))\r\nmsleep(100);\r\nvf->send_cmd = NULL;\r\nclear_bit(QLC_BC_VF_SEND, &vf->state);\r\n}\r\nreturn ret;\r\n}\r\nstatic void qlcnic_sriov_schedule_bc_cmd(struct qlcnic_sriov *sriov,\r\nstruct qlcnic_vf_info *vf,\r\nwork_func_t func)\r\n{\r\nif (test_bit(QLC_BC_VF_FLR, &vf->state) ||\r\nvf->adapter->need_fw_reset)\r\nreturn;\r\nqueue_work(sriov->bc.bc_trans_wq, &vf->trans_work);\r\n}\r\nstatic inline void qlcnic_sriov_wait_for_resp(struct qlcnic_bc_trans *trans)\r\n{\r\nstruct completion *cmpl = &trans->resp_cmpl;\r\nif (wait_for_completion_timeout(cmpl, QLC_MBOX_RESP_TIMEOUT))\r\ntrans->trans_state = QLC_END;\r\nelse\r\ntrans->trans_state = QLC_ABORT;\r\nreturn;\r\n}\r\nstatic void qlcnic_sriov_handle_multi_frags(struct qlcnic_bc_trans *trans,\r\nu8 type)\r\n{\r\nif (type == QLC_BC_RESPONSE) {\r\ntrans->curr_rsp_frag++;\r\nif (trans->curr_rsp_frag < trans->rsp_hdr->num_frags)\r\ntrans->trans_state = QLC_INIT;\r\nelse\r\ntrans->trans_state = QLC_END;\r\n} else {\r\ntrans->curr_req_frag++;\r\nif (trans->curr_req_frag < trans->req_hdr->num_frags)\r\ntrans->trans_state = QLC_INIT;\r\nelse\r\ntrans->trans_state = QLC_WAIT_FOR_RESP;\r\n}\r\n}\r\nstatic void qlcnic_sriov_wait_for_channel_free(struct qlcnic_bc_trans *trans,\r\nu8 type)\r\n{\r\nstruct qlcnic_vf_info *vf = trans->vf;\r\nstruct completion *cmpl = &vf->ch_free_cmpl;\r\nif (!wait_for_completion_timeout(cmpl, QLC_MBOX_CH_FREE_TIMEOUT)) {\r\ntrans->trans_state = QLC_ABORT;\r\nreturn;\r\n}\r\nclear_bit(QLC_BC_VF_CHANNEL, &vf->state);\r\nqlcnic_sriov_handle_multi_frags(trans, type);\r\n}\r\nstatic void qlcnic_sriov_pull_bc_msg(struct qlcnic_adapter *adapter,\r\nu32 *hdr, u32 *pay, u32 size)\r\n{\r\nstruct qlcnic_hardware_context *ahw = adapter->ahw;\r\nu32 fw_mbx;\r\nu8 i, max = 2, hdr_size, j;\r\nhdr_size = (sizeof(struct qlcnic_bc_hdr) / sizeof(u32));\r\nmax = (size / sizeof(u32)) + hdr_size;\r\nfw_mbx = readl(QLCNIC_MBX_FW(ahw, 0));\r\nfor (i = 2, j = 0; j < hdr_size; i++, j++)\r\n*(hdr++) = readl(QLCNIC_MBX_FW(ahw, i));\r\nfor (; j < max; i++, j++)\r\n*(pay++) = readl(QLCNIC_MBX_FW(ahw, i));\r\n}\r\nstatic int __qlcnic_sriov_issue_bc_post(struct qlcnic_vf_info *vf)\r\n{\r\nint ret = -EBUSY;\r\nu32 timeout = 10000;\r\ndo {\r\nif (!test_and_set_bit(QLC_BC_VF_CHANNEL, &vf->state)) {\r\nret = 0;\r\nbreak;\r\n}\r\nmdelay(1);\r\n} while (--timeout);\r\nreturn ret;\r\n}\r\nstatic int qlcnic_sriov_issue_bc_post(struct qlcnic_bc_trans *trans, u8 type)\r\n{\r\nstruct qlcnic_vf_info *vf = trans->vf;\r\nu32 pay_size, hdr_size;\r\nu32 *hdr, *pay;\r\nint ret;\r\nu8 pci_func = trans->func_id;\r\nif (__qlcnic_sriov_issue_bc_post(vf))\r\nreturn -EBUSY;\r\nif (type == QLC_BC_COMMAND) {\r\nhdr = (u32 *)(trans->req_hdr + trans->curr_req_frag);\r\npay = (u32 *)(trans->req_pay + trans->curr_req_frag);\r\nhdr_size = (sizeof(struct qlcnic_bc_hdr) / sizeof(u32));\r\npay_size = qlcnic_sriov_get_bc_paysize(trans->req_pay_size,\r\ntrans->curr_req_frag);\r\npay_size = (pay_size / sizeof(u32));\r\n} else {\r\nhdr = (u32 *)(trans->rsp_hdr + trans->curr_rsp_frag);\r\npay = (u32 *)(trans->rsp_pay + trans->curr_rsp_frag);\r\nhdr_size = (sizeof(struct qlcnic_bc_hdr) / sizeof(u32));\r\npay_size = qlcnic_sriov_get_bc_paysize(trans->rsp_pay_size,\r\ntrans->curr_rsp_frag);\r\npay_size = (pay_size / sizeof(u32));\r\n}\r\nret = qlcnic_sriov_post_bc_msg(vf->adapter, hdr, pay,\r\npci_func, pay_size);\r\nreturn ret;\r\n}\r\nstatic int __qlcnic_sriov_send_bc_msg(struct qlcnic_bc_trans *trans,\r\nstruct qlcnic_vf_info *vf, u8 type)\r\n{\r\nbool flag = true;\r\nint err = -EIO;\r\nwhile (flag) {\r\nif (test_bit(QLC_BC_VF_FLR, &vf->state) ||\r\nvf->adapter->need_fw_reset)\r\ntrans->trans_state = QLC_ABORT;\r\nswitch (trans->trans_state) {\r\ncase QLC_INIT:\r\ntrans->trans_state = QLC_WAIT_FOR_CHANNEL_FREE;\r\nif (qlcnic_sriov_issue_bc_post(trans, type))\r\ntrans->trans_state = QLC_ABORT;\r\nbreak;\r\ncase QLC_WAIT_FOR_CHANNEL_FREE:\r\nqlcnic_sriov_wait_for_channel_free(trans, type);\r\nbreak;\r\ncase QLC_WAIT_FOR_RESP:\r\nqlcnic_sriov_wait_for_resp(trans);\r\nbreak;\r\ncase QLC_END:\r\nerr = 0;\r\nflag = false;\r\nbreak;\r\ncase QLC_ABORT:\r\nerr = -EIO;\r\nflag = false;\r\nclear_bit(QLC_BC_VF_CHANNEL, &vf->state);\r\nbreak;\r\ndefault:\r\nerr = -EIO;\r\nflag = false;\r\n}\r\n}\r\nreturn err;\r\n}\r\nstatic int qlcnic_sriov_send_bc_cmd(struct qlcnic_adapter *adapter,\r\nstruct qlcnic_bc_trans *trans, int pci_func)\r\n{\r\nstruct qlcnic_vf_info *vf;\r\nint err, index = qlcnic_sriov_func_to_index(adapter, pci_func);\r\nif (index < 0)\r\nreturn -EIO;\r\nvf = &adapter->ahw->sriov->vf_info[index];\r\ntrans->vf = vf;\r\ntrans->func_id = pci_func;\r\nif (!test_bit(QLC_BC_VF_STATE, &vf->state)) {\r\nif (qlcnic_sriov_pf_check(adapter))\r\nreturn -EIO;\r\nif (qlcnic_sriov_vf_check(adapter) &&\r\ntrans->cmd_id != QLCNIC_BC_CMD_CHANNEL_INIT)\r\nreturn -EIO;\r\n}\r\nmutex_lock(&vf->send_cmd_lock);\r\nvf->send_cmd = trans;\r\nerr = __qlcnic_sriov_send_bc_msg(trans, vf, QLC_BC_COMMAND);\r\nqlcnic_sriov_clear_trans(vf, trans, QLC_BC_COMMAND);\r\nmutex_unlock(&vf->send_cmd_lock);\r\nreturn err;\r\n}\r\nstatic void __qlcnic_sriov_process_bc_cmd(struct qlcnic_adapter *adapter,\r\nstruct qlcnic_bc_trans *trans,\r\nstruct qlcnic_cmd_args *cmd)\r\n{\r\n#ifdef CONFIG_QLCNIC_SRIOV\r\nif (qlcnic_sriov_pf_check(adapter)) {\r\nqlcnic_sriov_pf_process_bc_cmd(adapter, trans, cmd);\r\nreturn;\r\n}\r\n#endif\r\ncmd->rsp.arg[0] |= (0x9 << 25);\r\nreturn;\r\n}\r\nstatic void qlcnic_sriov_process_bc_cmd(struct work_struct *work)\r\n{\r\nstruct qlcnic_vf_info *vf = container_of(work, struct qlcnic_vf_info,\r\ntrans_work);\r\nstruct qlcnic_bc_trans *trans = NULL;\r\nstruct qlcnic_adapter *adapter = vf->adapter;\r\nstruct qlcnic_cmd_args cmd;\r\nu8 req;\r\nif (adapter->need_fw_reset)\r\nreturn;\r\nif (test_bit(QLC_BC_VF_FLR, &vf->state))\r\nreturn;\r\nmemset(&cmd, 0, sizeof(struct qlcnic_cmd_args));\r\ntrans = list_first_entry(&vf->rcv_act.wait_list,\r\nstruct qlcnic_bc_trans, list);\r\nadapter = vf->adapter;\r\nif (qlcnic_sriov_prepare_bc_hdr(trans, &cmd, trans->req_hdr->seq_id,\r\nQLC_BC_RESPONSE))\r\ngoto cleanup_trans;\r\n__qlcnic_sriov_process_bc_cmd(adapter, trans, &cmd);\r\ntrans->trans_state = QLC_INIT;\r\n__qlcnic_sriov_send_bc_msg(trans, vf, QLC_BC_RESPONSE);\r\ncleanup_trans:\r\nqlcnic_free_mbx_args(&cmd);\r\nreq = qlcnic_sriov_clear_trans(vf, trans, QLC_BC_RESPONSE);\r\nqlcnic_sriov_cleanup_transaction(trans);\r\nif (req)\r\nqlcnic_sriov_schedule_bc_cmd(adapter->ahw->sriov, vf,\r\nqlcnic_sriov_process_bc_cmd);\r\n}\r\nstatic void qlcnic_sriov_handle_bc_resp(struct qlcnic_bc_hdr *hdr,\r\nstruct qlcnic_vf_info *vf)\r\n{\r\nstruct qlcnic_bc_trans *trans;\r\nu32 pay_size;\r\nif (test_and_set_bit(QLC_BC_VF_SEND, &vf->state))\r\nreturn;\r\ntrans = vf->send_cmd;\r\nif (trans == NULL)\r\ngoto clear_send;\r\nif (trans->trans_id != hdr->seq_id)\r\ngoto clear_send;\r\npay_size = qlcnic_sriov_get_bc_paysize(trans->rsp_pay_size,\r\ntrans->curr_rsp_frag);\r\nqlcnic_sriov_pull_bc_msg(vf->adapter,\r\n(u32 *)(trans->rsp_hdr + trans->curr_rsp_frag),\r\n(u32 *)(trans->rsp_pay + trans->curr_rsp_frag),\r\npay_size);\r\nif (++trans->curr_rsp_frag < trans->rsp_hdr->num_frags)\r\ngoto clear_send;\r\ncomplete(&trans->resp_cmpl);\r\nclear_send:\r\nclear_bit(QLC_BC_VF_SEND, &vf->state);\r\n}\r\nint __qlcnic_sriov_add_act_list(struct qlcnic_sriov *sriov,\r\nstruct qlcnic_vf_info *vf,\r\nstruct qlcnic_bc_trans *trans)\r\n{\r\nstruct qlcnic_trans_list *t_list = &vf->rcv_act;\r\nt_list->count++;\r\nlist_add_tail(&trans->list, &t_list->wait_list);\r\nif (t_list->count == 1)\r\nqlcnic_sriov_schedule_bc_cmd(sriov, vf,\r\nqlcnic_sriov_process_bc_cmd);\r\nreturn 0;\r\n}\r\nstatic int qlcnic_sriov_add_act_list(struct qlcnic_sriov *sriov,\r\nstruct qlcnic_vf_info *vf,\r\nstruct qlcnic_bc_trans *trans)\r\n{\r\nstruct qlcnic_trans_list *t_list = &vf->rcv_act;\r\nspin_lock(&t_list->lock);\r\n__qlcnic_sriov_add_act_list(sriov, vf, trans);\r\nspin_unlock(&t_list->lock);\r\nreturn 0;\r\n}\r\nstatic void qlcnic_sriov_handle_pending_trans(struct qlcnic_sriov *sriov,\r\nstruct qlcnic_vf_info *vf,\r\nstruct qlcnic_bc_hdr *hdr)\r\n{\r\nstruct qlcnic_bc_trans *trans = NULL;\r\nstruct list_head *node;\r\nu32 pay_size, curr_frag;\r\nu8 found = 0, active = 0;\r\nspin_lock(&vf->rcv_pend.lock);\r\nif (vf->rcv_pend.count > 0) {\r\nlist_for_each(node, &vf->rcv_pend.wait_list) {\r\ntrans = list_entry(node, struct qlcnic_bc_trans, list);\r\nif (trans->trans_id == hdr->seq_id) {\r\nfound = 1;\r\nbreak;\r\n}\r\n}\r\n}\r\nif (found) {\r\ncurr_frag = trans->curr_req_frag;\r\npay_size = qlcnic_sriov_get_bc_paysize(trans->req_pay_size,\r\ncurr_frag);\r\nqlcnic_sriov_pull_bc_msg(vf->adapter,\r\n(u32 *)(trans->req_hdr + curr_frag),\r\n(u32 *)(trans->req_pay + curr_frag),\r\npay_size);\r\ntrans->curr_req_frag++;\r\nif (trans->curr_req_frag >= hdr->num_frags) {\r\nvf->rcv_pend.count--;\r\nlist_del(&trans->list);\r\nactive = 1;\r\n}\r\n}\r\nspin_unlock(&vf->rcv_pend.lock);\r\nif (active)\r\nif (qlcnic_sriov_add_act_list(sriov, vf, trans))\r\nqlcnic_sriov_cleanup_transaction(trans);\r\nreturn;\r\n}\r\nstatic void qlcnic_sriov_handle_bc_cmd(struct qlcnic_sriov *sriov,\r\nstruct qlcnic_bc_hdr *hdr,\r\nstruct qlcnic_vf_info *vf)\r\n{\r\nstruct qlcnic_bc_trans *trans;\r\nstruct qlcnic_adapter *adapter = vf->adapter;\r\nstruct qlcnic_cmd_args cmd;\r\nu32 pay_size;\r\nint err;\r\nu8 cmd_op;\r\nif (adapter->need_fw_reset)\r\nreturn;\r\nif (!test_bit(QLC_BC_VF_STATE, &vf->state) &&\r\nhdr->op_type != QLC_BC_CMD &&\r\nhdr->cmd_op != QLCNIC_BC_CMD_CHANNEL_INIT)\r\nreturn;\r\nif (hdr->frag_num > 1) {\r\nqlcnic_sriov_handle_pending_trans(sriov, vf, hdr);\r\nreturn;\r\n}\r\nmemset(&cmd, 0, sizeof(struct qlcnic_cmd_args));\r\ncmd_op = hdr->cmd_op;\r\nif (qlcnic_sriov_alloc_bc_trans(&trans))\r\nreturn;\r\nif (hdr->op_type == QLC_BC_CMD)\r\nerr = qlcnic_sriov_alloc_bc_mbx_args(&cmd, cmd_op);\r\nelse\r\nerr = qlcnic_alloc_mbx_args(&cmd, adapter, cmd_op);\r\nif (err) {\r\nqlcnic_sriov_cleanup_transaction(trans);\r\nreturn;\r\n}\r\ncmd.op_type = hdr->op_type;\r\nif (qlcnic_sriov_prepare_bc_hdr(trans, &cmd, hdr->seq_id,\r\nQLC_BC_COMMAND)) {\r\nqlcnic_free_mbx_args(&cmd);\r\nqlcnic_sriov_cleanup_transaction(trans);\r\nreturn;\r\n}\r\npay_size = qlcnic_sriov_get_bc_paysize(trans->req_pay_size,\r\ntrans->curr_req_frag);\r\nqlcnic_sriov_pull_bc_msg(vf->adapter,\r\n(u32 *)(trans->req_hdr + trans->curr_req_frag),\r\n(u32 *)(trans->req_pay + trans->curr_req_frag),\r\npay_size);\r\ntrans->func_id = vf->pci_func;\r\ntrans->vf = vf;\r\ntrans->trans_id = hdr->seq_id;\r\ntrans->curr_req_frag++;\r\nif (qlcnic_sriov_soft_flr_check(adapter, trans, vf))\r\nreturn;\r\nif (trans->curr_req_frag == trans->req_hdr->num_frags) {\r\nif (qlcnic_sriov_add_act_list(sriov, vf, trans)) {\r\nqlcnic_free_mbx_args(&cmd);\r\nqlcnic_sriov_cleanup_transaction(trans);\r\n}\r\n} else {\r\nspin_lock(&vf->rcv_pend.lock);\r\nlist_add_tail(&trans->list, &vf->rcv_pend.wait_list);\r\nvf->rcv_pend.count++;\r\nspin_unlock(&vf->rcv_pend.lock);\r\n}\r\n}\r\nstatic void qlcnic_sriov_handle_msg_event(struct qlcnic_sriov *sriov,\r\nstruct qlcnic_vf_info *vf)\r\n{\r\nstruct qlcnic_bc_hdr hdr;\r\nu32 *ptr = (u32 *)&hdr;\r\nu8 msg_type, i;\r\nfor (i = 2; i < 6; i++)\r\nptr[i - 2] = readl(QLCNIC_MBX_FW(vf->adapter->ahw, i));\r\nmsg_type = hdr.msg_type;\r\nswitch (msg_type) {\r\ncase QLC_BC_COMMAND:\r\nqlcnic_sriov_handle_bc_cmd(sriov, &hdr, vf);\r\nbreak;\r\ncase QLC_BC_RESPONSE:\r\nqlcnic_sriov_handle_bc_resp(&hdr, vf);\r\nbreak;\r\n}\r\n}\r\nstatic void qlcnic_sriov_handle_flr_event(struct qlcnic_sriov *sriov,\r\nstruct qlcnic_vf_info *vf)\r\n{\r\nstruct qlcnic_adapter *adapter = vf->adapter;\r\nif (qlcnic_sriov_pf_check(adapter))\r\nqlcnic_sriov_pf_handle_flr(sriov, vf);\r\nelse\r\ndev_err(&adapter->pdev->dev,\r\n"Invalid event to VF. VF should not get FLR event\n");\r\n}\r\nvoid qlcnic_sriov_handle_bc_event(struct qlcnic_adapter *adapter, u32 event)\r\n{\r\nstruct qlcnic_vf_info *vf;\r\nstruct qlcnic_sriov *sriov;\r\nint index;\r\nu8 pci_func;\r\nsriov = adapter->ahw->sriov;\r\npci_func = qlcnic_sriov_target_func_id(event);\r\nindex = qlcnic_sriov_func_to_index(adapter, pci_func);\r\nif (index < 0)\r\nreturn;\r\nvf = &sriov->vf_info[index];\r\nvf->pci_func = pci_func;\r\nif (qlcnic_sriov_channel_free_check(event))\r\ncomplete(&vf->ch_free_cmpl);\r\nif (qlcnic_sriov_flr_check(event)) {\r\nqlcnic_sriov_handle_flr_event(sriov, vf);\r\nreturn;\r\n}\r\nif (qlcnic_sriov_bc_msg_check(event))\r\nqlcnic_sriov_handle_msg_event(sriov, vf);\r\n}\r\nint qlcnic_sriov_cfg_bc_intr(struct qlcnic_adapter *adapter, u8 enable)\r\n{\r\nstruct qlcnic_cmd_args cmd;\r\nint err;\r\nif (!test_bit(__QLCNIC_SRIOV_ENABLE, &adapter->state))\r\nreturn 0;\r\nif (qlcnic_alloc_mbx_args(&cmd, adapter, QLCNIC_CMD_BC_EVENT_SETUP))\r\nreturn -ENOMEM;\r\nif (enable)\r\ncmd.req.arg[1] = (1 << 4) | (1 << 5) | (1 << 6) | (1 << 7);\r\nerr = qlcnic_83xx_issue_cmd(adapter, &cmd);\r\nif (err != QLCNIC_RCODE_SUCCESS) {\r\ndev_err(&adapter->pdev->dev,\r\n"Failed to %s bc events, err=%d\n",\r\n(enable ? "enable" : "disable"), err);\r\n}\r\nqlcnic_free_mbx_args(&cmd);\r\nreturn err;\r\n}\r\nstatic int qlcnic_sriov_retry_bc_cmd(struct qlcnic_adapter *adapter,\r\nstruct qlcnic_bc_trans *trans)\r\n{\r\nu8 max = QLC_BC_CMD_MAX_RETRY_CNT;\r\nu32 state;\r\nstate = QLCRDX(adapter->ahw, QLC_83XX_IDC_DEV_STATE);\r\nif (state == QLC_83XX_IDC_DEV_READY) {\r\nmsleep(20);\r\nclear_bit(QLC_BC_VF_CHANNEL, &trans->vf->state);\r\ntrans->trans_state = QLC_INIT;\r\nif (++adapter->fw_fail_cnt > max)\r\nreturn -EIO;\r\nelse\r\nreturn 0;\r\n}\r\nreturn -EIO;\r\n}\r\nstatic int __qlcnic_sriov_issue_cmd(struct qlcnic_adapter *adapter,\r\nstruct qlcnic_cmd_args *cmd)\r\n{\r\nstruct qlcnic_hardware_context *ahw = adapter->ahw;\r\nstruct qlcnic_mailbox *mbx = ahw->mailbox;\r\nstruct device *dev = &adapter->pdev->dev;\r\nstruct qlcnic_bc_trans *trans;\r\nint err;\r\nu32 rsp_data, opcode, mbx_err_code, rsp;\r\nu16 seq = ++adapter->ahw->sriov->bc.trans_counter;\r\nu8 func = ahw->pci_func;\r\nrsp = qlcnic_sriov_alloc_bc_trans(&trans);\r\nif (rsp)\r\ngoto free_cmd;\r\nrsp = qlcnic_sriov_prepare_bc_hdr(trans, cmd, seq, QLC_BC_COMMAND);\r\nif (rsp)\r\ngoto cleanup_transaction;\r\nretry:\r\nif (!test_bit(QLC_83XX_MBX_READY, &mbx->status)) {\r\nrsp = -EIO;\r\nQLCDB(adapter, DRV, "MBX not Ready!(cmd 0x%x) for VF 0x%x\n",\r\nQLCNIC_MBX_RSP(cmd->req.arg[0]), func);\r\ngoto err_out;\r\n}\r\nerr = qlcnic_sriov_send_bc_cmd(adapter, trans, func);\r\nif (err) {\r\ndev_err(dev, "MBX command 0x%x timed out for VF %d\n",\r\n(cmd->req.arg[0] & 0xffff), func);\r\nrsp = QLCNIC_RCODE_TIMEOUT;\r\nif ((trans->req_hdr->cmd_op == QLCNIC_BC_CMD_CHANNEL_INIT) &&\r\n!qlcnic_sriov_retry_bc_cmd(adapter, trans))\r\ngoto retry;\r\ngoto err_out;\r\n}\r\nrsp_data = cmd->rsp.arg[0];\r\nmbx_err_code = QLCNIC_MBX_STATUS(rsp_data);\r\nopcode = QLCNIC_MBX_RSP(cmd->req.arg[0]);\r\nif ((mbx_err_code == QLCNIC_MBX_RSP_OK) ||\r\n(mbx_err_code == QLCNIC_MBX_PORT_RSP_OK)) {\r\nrsp = QLCNIC_RCODE_SUCCESS;\r\n} else {\r\nif (cmd->type == QLC_83XX_MBX_CMD_NO_WAIT) {\r\nrsp = QLCNIC_RCODE_SUCCESS;\r\n} else {\r\nrsp = mbx_err_code;\r\nif (!rsp)\r\nrsp = 1;\r\ndev_err(dev,\r\n"MBX command 0x%x failed with err:0x%x for VF %d\n",\r\nopcode, mbx_err_code, func);\r\n}\r\n}\r\nerr_out:\r\nif (rsp == QLCNIC_RCODE_TIMEOUT) {\r\nahw->reset_context = 1;\r\nadapter->need_fw_reset = 1;\r\nclear_bit(QLC_83XX_MBX_READY, &mbx->status);\r\n}\r\ncleanup_transaction:\r\nqlcnic_sriov_cleanup_transaction(trans);\r\nfree_cmd:\r\nif (cmd->type == QLC_83XX_MBX_CMD_NO_WAIT) {\r\nqlcnic_free_mbx_args(cmd);\r\nkfree(cmd);\r\n}\r\nreturn rsp;\r\n}\r\nstatic int qlcnic_sriov_issue_cmd(struct qlcnic_adapter *adapter,\r\nstruct qlcnic_cmd_args *cmd)\r\n{\r\nif (cmd->type == QLC_83XX_MBX_CMD_NO_WAIT)\r\nreturn qlcnic_sriov_async_issue_cmd(adapter, cmd);\r\nelse\r\nreturn __qlcnic_sriov_issue_cmd(adapter, cmd);\r\n}\r\nstatic int qlcnic_sriov_channel_cfg_cmd(struct qlcnic_adapter *adapter, u8 cmd_op)\r\n{\r\nstruct qlcnic_cmd_args cmd;\r\nstruct qlcnic_vf_info *vf = &adapter->ahw->sriov->vf_info[0];\r\nint ret;\r\nmemset(&cmd, 0, sizeof(cmd));\r\nif (qlcnic_sriov_alloc_bc_mbx_args(&cmd, cmd_op))\r\nreturn -ENOMEM;\r\nret = qlcnic_issue_cmd(adapter, &cmd);\r\nif (ret) {\r\ndev_err(&adapter->pdev->dev,\r\n"Failed bc channel %s %d\n", cmd_op ? "term" : "init",\r\nret);\r\ngoto out;\r\n}\r\ncmd_op = (cmd.rsp.arg[0] & 0xff);\r\nif (cmd.rsp.arg[0] >> 25 == 2)\r\nreturn 2;\r\nif (cmd_op == QLCNIC_BC_CMD_CHANNEL_INIT)\r\nset_bit(QLC_BC_VF_STATE, &vf->state);\r\nelse\r\nclear_bit(QLC_BC_VF_STATE, &vf->state);\r\nout:\r\nqlcnic_free_mbx_args(&cmd);\r\nreturn ret;\r\n}\r\nstatic void qlcnic_vf_add_mc_list(struct net_device *netdev, const u8 *mac,\r\nenum qlcnic_mac_type mac_type)\r\n{\r\nstruct qlcnic_adapter *adapter = netdev_priv(netdev);\r\nstruct qlcnic_sriov *sriov = adapter->ahw->sriov;\r\nstruct qlcnic_vf_info *vf;\r\nu16 vlan_id;\r\nint i;\r\nvf = &adapter->ahw->sriov->vf_info[0];\r\nif (!qlcnic_sriov_check_any_vlan(vf)) {\r\nqlcnic_nic_add_mac(adapter, mac, 0, mac_type);\r\n} else {\r\nspin_lock(&vf->vlan_list_lock);\r\nfor (i = 0; i < sriov->num_allowed_vlans; i++) {\r\nvlan_id = vf->sriov_vlans[i];\r\nif (vlan_id)\r\nqlcnic_nic_add_mac(adapter, mac, vlan_id,\r\nmac_type);\r\n}\r\nspin_unlock(&vf->vlan_list_lock);\r\nif (qlcnic_84xx_check(adapter))\r\nqlcnic_nic_add_mac(adapter, mac, 0, mac_type);\r\n}\r\n}\r\nvoid qlcnic_sriov_cleanup_async_list(struct qlcnic_back_channel *bc)\r\n{\r\nstruct list_head *head = &bc->async_cmd_list;\r\nstruct qlcnic_async_cmd *entry;\r\nflush_workqueue(bc->bc_async_wq);\r\ncancel_work_sync(&bc->vf_async_work);\r\nspin_lock(&bc->queue_lock);\r\nwhile (!list_empty(head)) {\r\nentry = list_entry(head->next, struct qlcnic_async_cmd,\r\nlist);\r\nlist_del(&entry->list);\r\nkfree(entry->cmd);\r\nkfree(entry);\r\n}\r\nspin_unlock(&bc->queue_lock);\r\n}\r\nvoid qlcnic_sriov_vf_set_multi(struct net_device *netdev)\r\n{\r\nstruct qlcnic_adapter *adapter = netdev_priv(netdev);\r\nstruct qlcnic_hardware_context *ahw = adapter->ahw;\r\nstatic const u8 bcast_addr[ETH_ALEN] = {\r\n0xff, 0xff, 0xff, 0xff, 0xff, 0xff\r\n};\r\nstruct netdev_hw_addr *ha;\r\nu32 mode = VPORT_MISS_MODE_DROP;\r\nif (!test_bit(__QLCNIC_FW_ATTACHED, &adapter->state))\r\nreturn;\r\nif (netdev->flags & IFF_PROMISC) {\r\nif (!(adapter->flags & QLCNIC_PROMISC_DISABLED))\r\nmode = VPORT_MISS_MODE_ACCEPT_ALL;\r\n} else if ((netdev->flags & IFF_ALLMULTI) ||\r\n(netdev_mc_count(netdev) > ahw->max_mc_count)) {\r\nmode = VPORT_MISS_MODE_ACCEPT_MULTI;\r\n} else {\r\nqlcnic_vf_add_mc_list(netdev, bcast_addr, QLCNIC_BROADCAST_MAC);\r\nif (!netdev_mc_empty(netdev)) {\r\nqlcnic_flush_mcast_mac(adapter);\r\nnetdev_for_each_mc_addr(ha, netdev)\r\nqlcnic_vf_add_mc_list(netdev, ha->addr,\r\nQLCNIC_MULTICAST_MAC);\r\n}\r\n}\r\nif (netdev_uc_count(netdev) > ahw->max_uc_count) {\r\nmode = VPORT_MISS_MODE_ACCEPT_ALL;\r\n} else if (!netdev_uc_empty(netdev)) {\r\nnetdev_for_each_uc_addr(ha, netdev)\r\nqlcnic_vf_add_mc_list(netdev, ha->addr,\r\nQLCNIC_UNICAST_MAC);\r\n}\r\nif (adapter->pdev->is_virtfn) {\r\nif (mode == VPORT_MISS_MODE_ACCEPT_ALL &&\r\n!adapter->fdb_mac_learn) {\r\nqlcnic_alloc_lb_filters_mem(adapter);\r\nadapter->drv_mac_learn = 1;\r\nadapter->rx_mac_learn = true;\r\n} else {\r\nadapter->drv_mac_learn = 0;\r\nadapter->rx_mac_learn = false;\r\n}\r\n}\r\nqlcnic_nic_set_promisc(adapter, mode);\r\n}\r\nstatic void qlcnic_sriov_handle_async_issue_cmd(struct work_struct *work)\r\n{\r\nstruct qlcnic_async_cmd *entry, *tmp;\r\nstruct qlcnic_back_channel *bc;\r\nstruct qlcnic_cmd_args *cmd;\r\nstruct list_head *head;\r\nLIST_HEAD(del_list);\r\nbc = container_of(work, struct qlcnic_back_channel, vf_async_work);\r\nhead = &bc->async_cmd_list;\r\nspin_lock(&bc->queue_lock);\r\nlist_splice_init(head, &del_list);\r\nspin_unlock(&bc->queue_lock);\r\nlist_for_each_entry_safe(entry, tmp, &del_list, list) {\r\nlist_del(&entry->list);\r\ncmd = entry->cmd;\r\n__qlcnic_sriov_issue_cmd(bc->adapter, cmd);\r\nkfree(entry);\r\n}\r\nif (!list_empty(head))\r\nqueue_work(bc->bc_async_wq, &bc->vf_async_work);\r\nreturn;\r\n}\r\nstatic struct qlcnic_async_cmd *\r\nqlcnic_sriov_alloc_async_cmd(struct qlcnic_back_channel *bc,\r\nstruct qlcnic_cmd_args *cmd)\r\n{\r\nstruct qlcnic_async_cmd *entry = NULL;\r\nentry = kzalloc(sizeof(*entry), GFP_ATOMIC);\r\nif (!entry)\r\nreturn NULL;\r\nentry->cmd = cmd;\r\nspin_lock(&bc->queue_lock);\r\nlist_add_tail(&entry->list, &bc->async_cmd_list);\r\nspin_unlock(&bc->queue_lock);\r\nreturn entry;\r\n}\r\nstatic void qlcnic_sriov_schedule_async_cmd(struct qlcnic_back_channel *bc,\r\nstruct qlcnic_cmd_args *cmd)\r\n{\r\nstruct qlcnic_async_cmd *entry = NULL;\r\nentry = qlcnic_sriov_alloc_async_cmd(bc, cmd);\r\nif (!entry) {\r\nqlcnic_free_mbx_args(cmd);\r\nkfree(cmd);\r\nreturn;\r\n}\r\nqueue_work(bc->bc_async_wq, &bc->vf_async_work);\r\n}\r\nstatic int qlcnic_sriov_async_issue_cmd(struct qlcnic_adapter *adapter,\r\nstruct qlcnic_cmd_args *cmd)\r\n{\r\nstruct qlcnic_back_channel *bc = &adapter->ahw->sriov->bc;\r\nif (adapter->need_fw_reset)\r\nreturn -EIO;\r\nqlcnic_sriov_schedule_async_cmd(bc, cmd);\r\nreturn 0;\r\n}\r\nstatic int qlcnic_sriov_vf_reinit_driver(struct qlcnic_adapter *adapter)\r\n{\r\nint err;\r\nadapter->need_fw_reset = 0;\r\nqlcnic_83xx_reinit_mbx_work(adapter->ahw->mailbox);\r\nqlcnic_83xx_enable_mbx_interrupt(adapter);\r\nerr = qlcnic_sriov_cfg_bc_intr(adapter, 1);\r\nif (err)\r\nreturn err;\r\nerr = qlcnic_sriov_channel_cfg_cmd(adapter, QLCNIC_BC_CMD_CHANNEL_INIT);\r\nif (err)\r\ngoto err_out_cleanup_bc_intr;\r\nerr = qlcnic_sriov_vf_init_driver(adapter);\r\nif (err)\r\ngoto err_out_term_channel;\r\nreturn 0;\r\nerr_out_term_channel:\r\nqlcnic_sriov_channel_cfg_cmd(adapter, QLCNIC_BC_CMD_CHANNEL_TERM);\r\nerr_out_cleanup_bc_intr:\r\nqlcnic_sriov_cfg_bc_intr(adapter, 0);\r\nreturn err;\r\n}\r\nstatic void qlcnic_sriov_vf_attach(struct qlcnic_adapter *adapter)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nif (netif_running(netdev)) {\r\nif (!qlcnic_up(adapter, netdev))\r\nqlcnic_restore_indev_addr(netdev, NETDEV_UP);\r\n}\r\nnetif_device_attach(netdev);\r\n}\r\nstatic void qlcnic_sriov_vf_detach(struct qlcnic_adapter *adapter)\r\n{\r\nstruct qlcnic_hardware_context *ahw = adapter->ahw;\r\nstruct qlcnic_intrpt_config *intr_tbl = ahw->intr_tbl;\r\nstruct net_device *netdev = adapter->netdev;\r\nu8 i, max_ints = ahw->num_msix - 1;\r\nnetif_device_detach(netdev);\r\nqlcnic_83xx_detach_mailbox_work(adapter);\r\nqlcnic_83xx_disable_mbx_intr(adapter);\r\nif (netif_running(netdev))\r\nqlcnic_down(adapter, netdev);\r\nfor (i = 0; i < max_ints; i++) {\r\nintr_tbl[i].id = i;\r\nintr_tbl[i].enabled = 0;\r\nintr_tbl[i].src = 0;\r\n}\r\nahw->reset_context = 0;\r\n}\r\nstatic int qlcnic_sriov_vf_handle_dev_ready(struct qlcnic_adapter *adapter)\r\n{\r\nstruct qlcnic_hardware_context *ahw = adapter->ahw;\r\nstruct device *dev = &adapter->pdev->dev;\r\nstruct qlc_83xx_idc *idc = &ahw->idc;\r\nu8 func = ahw->pci_func;\r\nu32 state;\r\nif ((idc->prev_state == QLC_83XX_IDC_DEV_NEED_RESET) ||\r\n(idc->prev_state == QLC_83XX_IDC_DEV_INIT)) {\r\nif (!qlcnic_sriov_vf_reinit_driver(adapter)) {\r\nqlcnic_sriov_vf_attach(adapter);\r\nadapter->fw_fail_cnt = 0;\r\ndev_info(dev,\r\n"%s: Reinitialization of VF 0x%x done after FW reset\n",\r\n__func__, func);\r\n} else {\r\ndev_err(dev,\r\n"%s: Reinitialization of VF 0x%x failed after FW reset\n",\r\n__func__, func);\r\nstate = QLCRDX(ahw, QLC_83XX_IDC_DEV_STATE);\r\ndev_info(dev, "Current state 0x%x after FW reset\n",\r\nstate);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int qlcnic_sriov_vf_handle_context_reset(struct qlcnic_adapter *adapter)\r\n{\r\nstruct qlcnic_hardware_context *ahw = adapter->ahw;\r\nstruct qlcnic_mailbox *mbx = ahw->mailbox;\r\nstruct device *dev = &adapter->pdev->dev;\r\nstruct qlc_83xx_idc *idc = &ahw->idc;\r\nu8 func = ahw->pci_func;\r\nu32 state;\r\nadapter->reset_ctx_cnt++;\r\nif (adapter->reset_ctx_cnt < 3) {\r\nadapter->need_fw_reset = 1;\r\nclear_bit(QLC_83XX_MBX_READY, &mbx->status);\r\ndev_info(dev,\r\n"Resetting context, wait here to check if FW is in failed state\n");\r\nreturn 0;\r\n}\r\nif (adapter->reset_ctx_cnt > QLC_83XX_VF_RESET_FAIL_THRESH) {\r\nclear_bit(QLC_83XX_MODULE_LOADED, &idc->status);\r\nadapter->tx_timeo_cnt = 0;\r\nadapter->fw_fail_cnt = 0;\r\nadapter->reset_ctx_cnt = 0;\r\nqlcnic_sriov_vf_detach(adapter);\r\ndev_err(dev,\r\n"Device context resets have exceeded the threshold, device interface will be shutdown\n");\r\nreturn -EIO;\r\n}\r\ndev_info(dev, "Resetting context of VF 0x%x\n", func);\r\ndev_info(dev, "%s: Context reset count %d for VF 0x%x\n",\r\n__func__, adapter->reset_ctx_cnt, func);\r\nset_bit(__QLCNIC_RESETTING, &adapter->state);\r\nadapter->need_fw_reset = 1;\r\nclear_bit(QLC_83XX_MBX_READY, &mbx->status);\r\nqlcnic_sriov_vf_detach(adapter);\r\nadapter->need_fw_reset = 0;\r\nif (!qlcnic_sriov_vf_reinit_driver(adapter)) {\r\nqlcnic_sriov_vf_attach(adapter);\r\nadapter->tx_timeo_cnt = 0;\r\nadapter->reset_ctx_cnt = 0;\r\nadapter->fw_fail_cnt = 0;\r\ndev_info(dev, "Done resetting context for VF 0x%x\n", func);\r\n} else {\r\ndev_err(dev, "%s: Reinitialization of VF 0x%x failed\n",\r\n__func__, func);\r\nstate = QLCRDX(ahw, QLC_83XX_IDC_DEV_STATE);\r\ndev_info(dev, "%s: Current state 0x%x\n", __func__, state);\r\n}\r\nreturn 0;\r\n}\r\nstatic int qlcnic_sriov_vf_idc_ready_state(struct qlcnic_adapter *adapter)\r\n{\r\nstruct qlcnic_hardware_context *ahw = adapter->ahw;\r\nint ret = 0;\r\nif (ahw->idc.prev_state != QLC_83XX_IDC_DEV_READY)\r\nret = qlcnic_sriov_vf_handle_dev_ready(adapter);\r\nelse if (ahw->reset_context)\r\nret = qlcnic_sriov_vf_handle_context_reset(adapter);\r\nclear_bit(__QLCNIC_RESETTING, &adapter->state);\r\nreturn ret;\r\n}\r\nstatic int qlcnic_sriov_vf_idc_failed_state(struct qlcnic_adapter *adapter)\r\n{\r\nstruct qlc_83xx_idc *idc = &adapter->ahw->idc;\r\ndev_err(&adapter->pdev->dev, "Device is in failed state\n");\r\nif (idc->prev_state == QLC_83XX_IDC_DEV_READY)\r\nqlcnic_sriov_vf_detach(adapter);\r\nclear_bit(QLC_83XX_MODULE_LOADED, &idc->status);\r\nclear_bit(__QLCNIC_RESETTING, &adapter->state);\r\nreturn -EIO;\r\n}\r\nstatic int\r\nqlcnic_sriov_vf_idc_need_quiescent_state(struct qlcnic_adapter *adapter)\r\n{\r\nstruct qlcnic_mailbox *mbx = adapter->ahw->mailbox;\r\nstruct qlc_83xx_idc *idc = &adapter->ahw->idc;\r\ndev_info(&adapter->pdev->dev, "Device is in quiescent state\n");\r\nif (idc->prev_state == QLC_83XX_IDC_DEV_READY) {\r\nset_bit(__QLCNIC_RESETTING, &adapter->state);\r\nadapter->tx_timeo_cnt = 0;\r\nadapter->reset_ctx_cnt = 0;\r\nclear_bit(QLC_83XX_MBX_READY, &mbx->status);\r\nqlcnic_sriov_vf_detach(adapter);\r\n}\r\nreturn 0;\r\n}\r\nstatic int qlcnic_sriov_vf_idc_init_reset_state(struct qlcnic_adapter *adapter)\r\n{\r\nstruct qlcnic_mailbox *mbx = adapter->ahw->mailbox;\r\nstruct qlc_83xx_idc *idc = &adapter->ahw->idc;\r\nu8 func = adapter->ahw->pci_func;\r\nif (idc->prev_state == QLC_83XX_IDC_DEV_READY) {\r\ndev_err(&adapter->pdev->dev,\r\n"Firmware hang detected by VF 0x%x\n", func);\r\nset_bit(__QLCNIC_RESETTING, &adapter->state);\r\nadapter->tx_timeo_cnt = 0;\r\nadapter->reset_ctx_cnt = 0;\r\nclear_bit(QLC_83XX_MBX_READY, &mbx->status);\r\nqlcnic_sriov_vf_detach(adapter);\r\n}\r\nreturn 0;\r\n}\r\nstatic int qlcnic_sriov_vf_idc_unknown_state(struct qlcnic_adapter *adapter)\r\n{\r\ndev_err(&adapter->pdev->dev, "%s: Device in unknown state\n", __func__);\r\nreturn 0;\r\n}\r\nstatic void qlcnic_sriov_vf_periodic_tasks(struct qlcnic_adapter *adapter)\r\n{\r\nif (adapter->fhash.fnum)\r\nqlcnic_prune_lb_filters(adapter);\r\n}\r\nstatic void qlcnic_sriov_vf_poll_dev_state(struct work_struct *work)\r\n{\r\nstruct qlcnic_adapter *adapter;\r\nstruct qlc_83xx_idc *idc;\r\nint ret = 0;\r\nadapter = container_of(work, struct qlcnic_adapter, fw_work.work);\r\nidc = &adapter->ahw->idc;\r\nidc->curr_state = QLCRDX(adapter->ahw, QLC_83XX_IDC_DEV_STATE);\r\nswitch (idc->curr_state) {\r\ncase QLC_83XX_IDC_DEV_READY:\r\nret = qlcnic_sriov_vf_idc_ready_state(adapter);\r\nbreak;\r\ncase QLC_83XX_IDC_DEV_NEED_RESET:\r\ncase QLC_83XX_IDC_DEV_INIT:\r\nret = qlcnic_sriov_vf_idc_init_reset_state(adapter);\r\nbreak;\r\ncase QLC_83XX_IDC_DEV_NEED_QUISCENT:\r\nret = qlcnic_sriov_vf_idc_need_quiescent_state(adapter);\r\nbreak;\r\ncase QLC_83XX_IDC_DEV_FAILED:\r\nret = qlcnic_sriov_vf_idc_failed_state(adapter);\r\nbreak;\r\ncase QLC_83XX_IDC_DEV_QUISCENT:\r\nbreak;\r\ndefault:\r\nret = qlcnic_sriov_vf_idc_unknown_state(adapter);\r\n}\r\nidc->prev_state = idc->curr_state;\r\nqlcnic_sriov_vf_periodic_tasks(adapter);\r\nif (!ret && test_bit(QLC_83XX_MODULE_LOADED, &idc->status))\r\nqlcnic_schedule_work(adapter, qlcnic_sriov_vf_poll_dev_state,\r\nidc->delay);\r\n}\r\nstatic void qlcnic_sriov_vf_cancel_fw_work(struct qlcnic_adapter *adapter)\r\n{\r\nwhile (test_and_set_bit(__QLCNIC_RESETTING, &adapter->state))\r\nmsleep(20);\r\nclear_bit(QLC_83XX_MODULE_LOADED, &adapter->ahw->idc.status);\r\nclear_bit(__QLCNIC_RESETTING, &adapter->state);\r\ncancel_delayed_work_sync(&adapter->fw_work);\r\n}\r\nstatic int qlcnic_sriov_check_vlan_id(struct qlcnic_sriov *sriov,\r\nstruct qlcnic_vf_info *vf, u16 vlan_id)\r\n{\r\nint i, err = -EINVAL;\r\nif (!vf->sriov_vlans)\r\nreturn err;\r\nspin_lock_bh(&vf->vlan_list_lock);\r\nfor (i = 0; i < sriov->num_allowed_vlans; i++) {\r\nif (vf->sriov_vlans[i] == vlan_id) {\r\nerr = 0;\r\nbreak;\r\n}\r\n}\r\nspin_unlock_bh(&vf->vlan_list_lock);\r\nreturn err;\r\n}\r\nstatic int qlcnic_sriov_validate_num_vlans(struct qlcnic_sriov *sriov,\r\nstruct qlcnic_vf_info *vf)\r\n{\r\nint err = 0;\r\nspin_lock_bh(&vf->vlan_list_lock);\r\nif (vf->num_vlan >= sriov->num_allowed_vlans)\r\nerr = -EINVAL;\r\nspin_unlock_bh(&vf->vlan_list_lock);\r\nreturn err;\r\n}\r\nstatic int qlcnic_sriov_validate_vlan_cfg(struct qlcnic_adapter *adapter,\r\nu16 vid, u8 enable)\r\n{\r\nstruct qlcnic_sriov *sriov = adapter->ahw->sriov;\r\nstruct qlcnic_vf_info *vf;\r\nbool vlan_exist;\r\nu8 allowed = 0;\r\nint i;\r\nvf = &adapter->ahw->sriov->vf_info[0];\r\nvlan_exist = qlcnic_sriov_check_any_vlan(vf);\r\nif (sriov->vlan_mode != QLC_GUEST_VLAN_MODE)\r\nreturn -EINVAL;\r\nif (enable) {\r\nif (qlcnic_83xx_vf_check(adapter) && vlan_exist)\r\nreturn -EINVAL;\r\nif (qlcnic_sriov_validate_num_vlans(sriov, vf))\r\nreturn -EINVAL;\r\nif (sriov->any_vlan) {\r\nfor (i = 0; i < sriov->num_allowed_vlans; i++) {\r\nif (sriov->allowed_vlans[i] == vid)\r\nallowed = 1;\r\n}\r\nif (!allowed)\r\nreturn -EINVAL;\r\n}\r\n} else {\r\nif (!vlan_exist || qlcnic_sriov_check_vlan_id(sriov, vf, vid))\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic void qlcnic_sriov_vlan_operation(struct qlcnic_vf_info *vf, u16 vlan_id,\r\nenum qlcnic_vlan_operations opcode)\r\n{\r\nstruct qlcnic_adapter *adapter = vf->adapter;\r\nstruct qlcnic_sriov *sriov;\r\nsriov = adapter->ahw->sriov;\r\nif (!vf->sriov_vlans)\r\nreturn;\r\nspin_lock_bh(&vf->vlan_list_lock);\r\nswitch (opcode) {\r\ncase QLC_VLAN_ADD:\r\nqlcnic_sriov_add_vlan_id(sriov, vf, vlan_id);\r\nbreak;\r\ncase QLC_VLAN_DELETE:\r\nqlcnic_sriov_del_vlan_id(sriov, vf, vlan_id);\r\nbreak;\r\ndefault:\r\nnetdev_err(adapter->netdev, "Invalid VLAN operation\n");\r\n}\r\nspin_unlock_bh(&vf->vlan_list_lock);\r\nreturn;\r\n}\r\nint qlcnic_sriov_cfg_vf_guest_vlan(struct qlcnic_adapter *adapter,\r\nu16 vid, u8 enable)\r\n{\r\nstruct qlcnic_sriov *sriov = adapter->ahw->sriov;\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct qlcnic_vf_info *vf;\r\nstruct qlcnic_cmd_args cmd;\r\nint ret;\r\nmemset(&cmd, 0, sizeof(cmd));\r\nif (vid == 0)\r\nreturn 0;\r\nvf = &adapter->ahw->sriov->vf_info[0];\r\nret = qlcnic_sriov_validate_vlan_cfg(adapter, vid, enable);\r\nif (ret)\r\nreturn ret;\r\nret = qlcnic_sriov_alloc_bc_mbx_args(&cmd,\r\nQLCNIC_BC_CMD_CFG_GUEST_VLAN);\r\nif (ret)\r\nreturn ret;\r\ncmd.req.arg[1] = (enable & 1) | vid << 16;\r\nqlcnic_sriov_cleanup_async_list(&sriov->bc);\r\nret = qlcnic_issue_cmd(adapter, &cmd);\r\nif (ret) {\r\ndev_err(&adapter->pdev->dev,\r\n"Failed to configure guest VLAN, err=%d\n", ret);\r\n} else {\r\nnetif_addr_lock_bh(netdev);\r\nqlcnic_free_mac_list(adapter);\r\nnetif_addr_unlock_bh(netdev);\r\nif (enable)\r\nqlcnic_sriov_vlan_operation(vf, vid, QLC_VLAN_ADD);\r\nelse\r\nqlcnic_sriov_vlan_operation(vf, vid, QLC_VLAN_DELETE);\r\nnetif_addr_lock_bh(netdev);\r\nqlcnic_set_multi(netdev);\r\nnetif_addr_unlock_bh(netdev);\r\n}\r\nqlcnic_free_mbx_args(&cmd);\r\nreturn ret;\r\n}\r\nstatic void qlcnic_sriov_vf_free_mac_list(struct qlcnic_adapter *adapter)\r\n{\r\nstruct list_head *head = &adapter->mac_list;\r\nstruct qlcnic_mac_vlan_list *cur;\r\nwhile (!list_empty(head)) {\r\ncur = list_entry(head->next, struct qlcnic_mac_vlan_list, list);\r\nqlcnic_sre_macaddr_change(adapter, cur->mac_addr, cur->vlan_id,\r\nQLCNIC_MAC_DEL);\r\nlist_del(&cur->list);\r\nkfree(cur);\r\n}\r\n}\r\nstatic int qlcnic_sriov_vf_shutdown(struct pci_dev *pdev)\r\n{\r\nstruct qlcnic_adapter *adapter = pci_get_drvdata(pdev);\r\nstruct net_device *netdev = adapter->netdev;\r\nint retval;\r\nnetif_device_detach(netdev);\r\nqlcnic_cancel_idc_work(adapter);\r\nif (netif_running(netdev))\r\nqlcnic_down(adapter, netdev);\r\nqlcnic_sriov_channel_cfg_cmd(adapter, QLCNIC_BC_CMD_CHANNEL_TERM);\r\nqlcnic_sriov_cfg_bc_intr(adapter, 0);\r\nqlcnic_83xx_disable_mbx_intr(adapter);\r\ncancel_delayed_work_sync(&adapter->idc_aen_work);\r\nretval = pci_save_state(pdev);\r\nif (retval)\r\nreturn retval;\r\nreturn 0;\r\n}\r\nstatic int qlcnic_sriov_vf_resume(struct qlcnic_adapter *adapter)\r\n{\r\nstruct qlc_83xx_idc *idc = &adapter->ahw->idc;\r\nstruct net_device *netdev = adapter->netdev;\r\nint err;\r\nset_bit(QLC_83XX_MODULE_LOADED, &idc->status);\r\nqlcnic_83xx_enable_mbx_interrupt(adapter);\r\nerr = qlcnic_sriov_cfg_bc_intr(adapter, 1);\r\nif (err)\r\nreturn err;\r\nerr = qlcnic_sriov_channel_cfg_cmd(adapter, QLCNIC_BC_CMD_CHANNEL_INIT);\r\nif (!err) {\r\nif (netif_running(netdev)) {\r\nerr = qlcnic_up(adapter, netdev);\r\nif (!err)\r\nqlcnic_restore_indev_addr(netdev, NETDEV_UP);\r\n}\r\n}\r\nnetif_device_attach(netdev);\r\nqlcnic_schedule_work(adapter, qlcnic_sriov_vf_poll_dev_state,\r\nidc->delay);\r\nreturn err;\r\n}\r\nvoid qlcnic_sriov_alloc_vlans(struct qlcnic_adapter *adapter)\r\n{\r\nstruct qlcnic_sriov *sriov = adapter->ahw->sriov;\r\nstruct qlcnic_vf_info *vf;\r\nint i;\r\nfor (i = 0; i < sriov->num_vfs; i++) {\r\nvf = &sriov->vf_info[i];\r\nvf->sriov_vlans = kcalloc(sriov->num_allowed_vlans,\r\nsizeof(*vf->sriov_vlans), GFP_KERNEL);\r\n}\r\n}\r\nvoid qlcnic_sriov_free_vlans(struct qlcnic_adapter *adapter)\r\n{\r\nstruct qlcnic_sriov *sriov = adapter->ahw->sriov;\r\nstruct qlcnic_vf_info *vf;\r\nint i;\r\nfor (i = 0; i < sriov->num_vfs; i++) {\r\nvf = &sriov->vf_info[i];\r\nkfree(vf->sriov_vlans);\r\nvf->sriov_vlans = NULL;\r\n}\r\n}\r\nvoid qlcnic_sriov_add_vlan_id(struct qlcnic_sriov *sriov,\r\nstruct qlcnic_vf_info *vf, u16 vlan_id)\r\n{\r\nint i;\r\nfor (i = 0; i < sriov->num_allowed_vlans; i++) {\r\nif (!vf->sriov_vlans[i]) {\r\nvf->sriov_vlans[i] = vlan_id;\r\nvf->num_vlan++;\r\nreturn;\r\n}\r\n}\r\n}\r\nvoid qlcnic_sriov_del_vlan_id(struct qlcnic_sriov *sriov,\r\nstruct qlcnic_vf_info *vf, u16 vlan_id)\r\n{\r\nint i;\r\nfor (i = 0; i < sriov->num_allowed_vlans; i++) {\r\nif (vf->sriov_vlans[i] == vlan_id) {\r\nvf->sriov_vlans[i] = 0;\r\nvf->num_vlan--;\r\nreturn;\r\n}\r\n}\r\n}\r\nbool qlcnic_sriov_check_any_vlan(struct qlcnic_vf_info *vf)\r\n{\r\nbool err = false;\r\nspin_lock_bh(&vf->vlan_list_lock);\r\nif (vf->num_vlan)\r\nerr = true;\r\nspin_unlock_bh(&vf->vlan_list_lock);\r\nreturn err;\r\n}
