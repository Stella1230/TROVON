unsigned long roce_gid_type_mask_support(struct ib_device *ib_dev, u8 port)\r\n{\r\nint i;\r\nunsigned int ret_flags = 0;\r\nif (!rdma_protocol_roce(ib_dev, port))\r\nreturn 1UL << IB_GID_TYPE_IB;\r\nfor (i = 0; i < CAP_TO_GID_TABLE_SIZE; i++)\r\nif (PORT_CAP_TO_GID_TYPE[i].is_supported(ib_dev, port))\r\nret_flags |= 1UL << PORT_CAP_TO_GID_TYPE[i].gid_type;\r\nreturn ret_flags;\r\n}\r\nstatic void update_gid(enum gid_op_type gid_op, struct ib_device *ib_dev,\r\nu8 port, union ib_gid *gid,\r\nstruct ib_gid_attr *gid_attr)\r\n{\r\nint i;\r\nunsigned long gid_type_mask = roce_gid_type_mask_support(ib_dev, port);\r\nfor (i = 0; i < IB_GID_TYPE_SIZE; i++) {\r\nif ((1UL << i) & gid_type_mask) {\r\ngid_attr->gid_type = i;\r\nswitch (gid_op) {\r\ncase GID_ADD:\r\nib_cache_gid_add(ib_dev, port,\r\ngid, gid_attr);\r\nbreak;\r\ncase GID_DEL:\r\nib_cache_gid_del(ib_dev, port,\r\ngid, gid_attr);\r\nbreak;\r\n}\r\n}\r\n}\r\n}\r\nstatic enum bonding_slave_state is_eth_active_slave_of_bonding_rcu(struct net_device *dev,\r\nstruct net_device *upper)\r\n{\r\nif (upper && netif_is_bond_master(upper)) {\r\nstruct net_device *pdev =\r\nbond_option_active_slave_get_rcu(netdev_priv(upper));\r\nif (pdev)\r\nreturn dev == pdev ? BONDING_SLAVE_STATE_ACTIVE :\r\nBONDING_SLAVE_STATE_INACTIVE;\r\n}\r\nreturn BONDING_SLAVE_STATE_NA;\r\n}\r\nstatic int is_eth_port_of_netdev(struct ib_device *ib_dev, u8 port,\r\nstruct net_device *rdma_ndev, void *cookie)\r\n{\r\nstruct net_device *event_ndev = (struct net_device *)cookie;\r\nstruct net_device *real_dev;\r\nint res;\r\nif (!rdma_ndev)\r\nreturn 0;\r\nrcu_read_lock();\r\nreal_dev = rdma_vlan_dev_real_dev(event_ndev);\r\nif (!real_dev)\r\nreal_dev = event_ndev;\r\nres = ((rdma_is_upper_dev_rcu(rdma_ndev, event_ndev) &&\r\n(is_eth_active_slave_of_bonding_rcu(rdma_ndev, real_dev) &\r\nREQUIRED_BOND_STATES)) ||\r\nreal_dev == rdma_ndev);\r\nrcu_read_unlock();\r\nreturn res;\r\n}\r\nstatic int is_eth_port_inactive_slave(struct ib_device *ib_dev, u8 port,\r\nstruct net_device *rdma_ndev, void *cookie)\r\n{\r\nstruct net_device *master_dev;\r\nint res;\r\nif (!rdma_ndev)\r\nreturn 0;\r\nrcu_read_lock();\r\nmaster_dev = netdev_master_upper_dev_get_rcu(rdma_ndev);\r\nres = is_eth_active_slave_of_bonding_rcu(rdma_ndev, master_dev) ==\r\nBONDING_SLAVE_STATE_INACTIVE;\r\nrcu_read_unlock();\r\nreturn res;\r\n}\r\nstatic int pass_all_filter(struct ib_device *ib_dev, u8 port,\r\nstruct net_device *rdma_ndev, void *cookie)\r\n{\r\nreturn 1;\r\n}\r\nstatic int upper_device_filter(struct ib_device *ib_dev, u8 port,\r\nstruct net_device *rdma_ndev, void *cookie)\r\n{\r\nstruct net_device *event_ndev = (struct net_device *)cookie;\r\nint res;\r\nif (!rdma_ndev)\r\nreturn 0;\r\nif (rdma_ndev == event_ndev)\r\nreturn 1;\r\nrcu_read_lock();\r\nres = rdma_is_upper_dev_rcu(rdma_ndev, event_ndev);\r\nrcu_read_unlock();\r\nreturn res;\r\n}\r\nstatic void update_gid_ip(enum gid_op_type gid_op,\r\nstruct ib_device *ib_dev,\r\nu8 port, struct net_device *ndev,\r\nstruct sockaddr *addr)\r\n{\r\nunion ib_gid gid;\r\nstruct ib_gid_attr gid_attr;\r\nrdma_ip2gid(addr, &gid);\r\nmemset(&gid_attr, 0, sizeof(gid_attr));\r\ngid_attr.ndev = ndev;\r\nupdate_gid(gid_op, ib_dev, port, &gid, &gid_attr);\r\n}\r\nstatic void enum_netdev_default_gids(struct ib_device *ib_dev,\r\nu8 port, struct net_device *event_ndev,\r\nstruct net_device *rdma_ndev)\r\n{\r\nunsigned long gid_type_mask;\r\nrcu_read_lock();\r\nif (!rdma_ndev ||\r\n((rdma_ndev != event_ndev &&\r\n!rdma_is_upper_dev_rcu(rdma_ndev, event_ndev)) ||\r\nis_eth_active_slave_of_bonding_rcu(rdma_ndev,\r\nnetdev_master_upper_dev_get_rcu(rdma_ndev)) ==\r\nBONDING_SLAVE_STATE_INACTIVE)) {\r\nrcu_read_unlock();\r\nreturn;\r\n}\r\nrcu_read_unlock();\r\ngid_type_mask = roce_gid_type_mask_support(ib_dev, port);\r\nib_cache_gid_set_default_gid(ib_dev, port, rdma_ndev, gid_type_mask,\r\nIB_CACHE_GID_DEFAULT_MODE_SET);\r\n}\r\nstatic void bond_delete_netdev_default_gids(struct ib_device *ib_dev,\r\nu8 port,\r\nstruct net_device *event_ndev,\r\nstruct net_device *rdma_ndev)\r\n{\r\nstruct net_device *real_dev = rdma_vlan_dev_real_dev(event_ndev);\r\nif (!rdma_ndev)\r\nreturn;\r\nif (!real_dev)\r\nreal_dev = event_ndev;\r\nrcu_read_lock();\r\nif (rdma_is_upper_dev_rcu(rdma_ndev, event_ndev) &&\r\nis_eth_active_slave_of_bonding_rcu(rdma_ndev, real_dev) ==\r\nBONDING_SLAVE_STATE_INACTIVE) {\r\nunsigned long gid_type_mask;\r\nrcu_read_unlock();\r\ngid_type_mask = roce_gid_type_mask_support(ib_dev, port);\r\nib_cache_gid_set_default_gid(ib_dev, port, rdma_ndev,\r\ngid_type_mask,\r\nIB_CACHE_GID_DEFAULT_MODE_DELETE);\r\n} else {\r\nrcu_read_unlock();\r\n}\r\n}\r\nstatic void enum_netdev_ipv4_ips(struct ib_device *ib_dev,\r\nu8 port, struct net_device *ndev)\r\n{\r\nstruct in_device *in_dev;\r\nstruct sin_list {\r\nstruct list_head list;\r\nstruct sockaddr_in ip;\r\n};\r\nstruct sin_list *sin_iter;\r\nstruct sin_list *sin_temp;\r\nLIST_HEAD(sin_list);\r\nif (ndev->reg_state >= NETREG_UNREGISTERING)\r\nreturn;\r\nrcu_read_lock();\r\nin_dev = __in_dev_get_rcu(ndev);\r\nif (!in_dev) {\r\nrcu_read_unlock();\r\nreturn;\r\n}\r\nfor_ifa(in_dev) {\r\nstruct sin_list *entry = kzalloc(sizeof(*entry), GFP_ATOMIC);\r\nif (!entry) {\r\npr_warn("roce_gid_mgmt: couldn't allocate entry for IPv4 update\n");\r\ncontinue;\r\n}\r\nentry->ip.sin_family = AF_INET;\r\nentry->ip.sin_addr.s_addr = ifa->ifa_address;\r\nlist_add_tail(&entry->list, &sin_list);\r\n}\r\nendfor_ifa(in_dev);\r\nrcu_read_unlock();\r\nlist_for_each_entry_safe(sin_iter, sin_temp, &sin_list, list) {\r\nupdate_gid_ip(GID_ADD, ib_dev, port, ndev,\r\n(struct sockaddr *)&sin_iter->ip);\r\nlist_del(&sin_iter->list);\r\nkfree(sin_iter);\r\n}\r\n}\r\nstatic void enum_netdev_ipv6_ips(struct ib_device *ib_dev,\r\nu8 port, struct net_device *ndev)\r\n{\r\nstruct inet6_ifaddr *ifp;\r\nstruct inet6_dev *in6_dev;\r\nstruct sin6_list {\r\nstruct list_head list;\r\nstruct sockaddr_in6 sin6;\r\n};\r\nstruct sin6_list *sin6_iter;\r\nstruct sin6_list *sin6_temp;\r\nstruct ib_gid_attr gid_attr = {.ndev = ndev};\r\nLIST_HEAD(sin6_list);\r\nif (ndev->reg_state >= NETREG_UNREGISTERING)\r\nreturn;\r\nin6_dev = in6_dev_get(ndev);\r\nif (!in6_dev)\r\nreturn;\r\nread_lock_bh(&in6_dev->lock);\r\nlist_for_each_entry(ifp, &in6_dev->addr_list, if_list) {\r\nstruct sin6_list *entry = kzalloc(sizeof(*entry), GFP_ATOMIC);\r\nif (!entry) {\r\npr_warn("roce_gid_mgmt: couldn't allocate entry for IPv6 update\n");\r\ncontinue;\r\n}\r\nentry->sin6.sin6_family = AF_INET6;\r\nentry->sin6.sin6_addr = ifp->addr;\r\nlist_add_tail(&entry->list, &sin6_list);\r\n}\r\nread_unlock_bh(&in6_dev->lock);\r\nin6_dev_put(in6_dev);\r\nlist_for_each_entry_safe(sin6_iter, sin6_temp, &sin6_list, list) {\r\nunion ib_gid gid;\r\nrdma_ip2gid((struct sockaddr *)&sin6_iter->sin6, &gid);\r\nupdate_gid(GID_ADD, ib_dev, port, &gid, &gid_attr);\r\nlist_del(&sin6_iter->list);\r\nkfree(sin6_iter);\r\n}\r\n}\r\nstatic void _add_netdev_ips(struct ib_device *ib_dev, u8 port,\r\nstruct net_device *ndev)\r\n{\r\nenum_netdev_ipv4_ips(ib_dev, port, ndev);\r\nif (IS_ENABLED(CONFIG_IPV6))\r\nenum_netdev_ipv6_ips(ib_dev, port, ndev);\r\n}\r\nstatic void add_netdev_ips(struct ib_device *ib_dev, u8 port,\r\nstruct net_device *rdma_ndev, void *cookie)\r\n{\r\nstruct net_device *event_ndev = (struct net_device *)cookie;\r\nenum_netdev_default_gids(ib_dev, port, event_ndev, rdma_ndev);\r\n_add_netdev_ips(ib_dev, port, event_ndev);\r\n}\r\nstatic void del_netdev_ips(struct ib_device *ib_dev, u8 port,\r\nstruct net_device *rdma_ndev, void *cookie)\r\n{\r\nstruct net_device *event_ndev = (struct net_device *)cookie;\r\nib_cache_gid_del_all_netdev_gids(ib_dev, port, event_ndev);\r\n}\r\nstatic void enum_all_gids_of_dev_cb(struct ib_device *ib_dev,\r\nu8 port,\r\nstruct net_device *rdma_ndev,\r\nvoid *cookie)\r\n{\r\nstruct net *net;\r\nstruct net_device *ndev;\r\nrtnl_lock();\r\nfor_each_net(net)\r\nfor_each_netdev(net, ndev)\r\nif (is_eth_port_of_netdev(ib_dev, port, rdma_ndev, ndev))\r\nadd_netdev_ips(ib_dev, port, rdma_ndev, ndev);\r\nrtnl_unlock();\r\n}\r\nint roce_rescan_device(struct ib_device *ib_dev)\r\n{\r\nib_enum_roce_netdev(ib_dev, pass_all_filter, NULL,\r\nenum_all_gids_of_dev_cb, NULL);\r\nreturn 0;\r\n}\r\nstatic void callback_for_addr_gid_device_scan(struct ib_device *device,\r\nu8 port,\r\nstruct net_device *rdma_ndev,\r\nvoid *cookie)\r\n{\r\nstruct update_gid_event_work *parsed = cookie;\r\nreturn update_gid(parsed->gid_op, device,\r\nport, &parsed->gid,\r\n&parsed->gid_attr);\r\n}\r\nstatic void handle_netdev_upper(struct ib_device *ib_dev, u8 port,\r\nvoid *cookie,\r\nvoid (*handle_netdev)(struct ib_device *ib_dev,\r\nu8 port,\r\nstruct net_device *ndev))\r\n{\r\nstruct net_device *ndev = (struct net_device *)cookie;\r\nstruct upper_list {\r\nstruct list_head list;\r\nstruct net_device *upper;\r\n};\r\nstruct net_device *upper;\r\nstruct list_head *iter;\r\nstruct upper_list *upper_iter;\r\nstruct upper_list *upper_temp;\r\nLIST_HEAD(upper_list);\r\nrcu_read_lock();\r\nnetdev_for_each_all_upper_dev_rcu(ndev, upper, iter) {\r\nstruct upper_list *entry = kmalloc(sizeof(*entry),\r\nGFP_ATOMIC);\r\nif (!entry) {\r\npr_info("roce_gid_mgmt: couldn't allocate entry to delete ndev\n");\r\ncontinue;\r\n}\r\nlist_add_tail(&entry->list, &upper_list);\r\ndev_hold(upper);\r\nentry->upper = upper;\r\n}\r\nrcu_read_unlock();\r\nhandle_netdev(ib_dev, port, ndev);\r\nlist_for_each_entry_safe(upper_iter, upper_temp, &upper_list,\r\nlist) {\r\nhandle_netdev(ib_dev, port, upper_iter->upper);\r\ndev_put(upper_iter->upper);\r\nlist_del(&upper_iter->list);\r\nkfree(upper_iter);\r\n}\r\n}\r\nstatic void _roce_del_all_netdev_gids(struct ib_device *ib_dev, u8 port,\r\nstruct net_device *event_ndev)\r\n{\r\nib_cache_gid_del_all_netdev_gids(ib_dev, port, event_ndev);\r\n}\r\nstatic void del_netdev_upper_ips(struct ib_device *ib_dev, u8 port,\r\nstruct net_device *rdma_ndev, void *cookie)\r\n{\r\nhandle_netdev_upper(ib_dev, port, cookie, _roce_del_all_netdev_gids);\r\n}\r\nstatic void add_netdev_upper_ips(struct ib_device *ib_dev, u8 port,\r\nstruct net_device *rdma_ndev, void *cookie)\r\n{\r\nhandle_netdev_upper(ib_dev, port, cookie, _add_netdev_ips);\r\n}\r\nstatic void del_netdev_default_ips_join(struct ib_device *ib_dev, u8 port,\r\nstruct net_device *rdma_ndev,\r\nvoid *cookie)\r\n{\r\nstruct net_device *master_ndev;\r\nrcu_read_lock();\r\nmaster_ndev = netdev_master_upper_dev_get_rcu(rdma_ndev);\r\nif (master_ndev)\r\ndev_hold(master_ndev);\r\nrcu_read_unlock();\r\nif (master_ndev) {\r\nbond_delete_netdev_default_gids(ib_dev, port, master_ndev,\r\nrdma_ndev);\r\ndev_put(master_ndev);\r\n}\r\n}\r\nstatic void del_netdev_default_ips(struct ib_device *ib_dev, u8 port,\r\nstruct net_device *rdma_ndev, void *cookie)\r\n{\r\nstruct net_device *event_ndev = (struct net_device *)cookie;\r\nbond_delete_netdev_default_gids(ib_dev, port, event_ndev, rdma_ndev);\r\n}\r\nstatic void netdevice_event_work_handler(struct work_struct *_work)\r\n{\r\nstruct netdev_event_work *work =\r\ncontainer_of(_work, struct netdev_event_work, work);\r\nunsigned int i;\r\nfor (i = 0; i < ARRAY_SIZE(work->cmds) && work->cmds[i].cb; i++) {\r\nib_enum_all_roce_netdevs(work->cmds[i].filter,\r\nwork->cmds[i].filter_ndev,\r\nwork->cmds[i].cb,\r\nwork->cmds[i].ndev);\r\ndev_put(work->cmds[i].ndev);\r\ndev_put(work->cmds[i].filter_ndev);\r\n}\r\nkfree(work);\r\n}\r\nstatic int netdevice_queue_work(struct netdev_event_work_cmd *cmds,\r\nstruct net_device *ndev)\r\n{\r\nunsigned int i;\r\nstruct netdev_event_work *ndev_work =\r\nkmalloc(sizeof(*ndev_work), GFP_KERNEL);\r\nif (!ndev_work) {\r\npr_warn("roce_gid_mgmt: can't allocate work for netdevice_event\n");\r\nreturn NOTIFY_DONE;\r\n}\r\nmemcpy(ndev_work->cmds, cmds, sizeof(ndev_work->cmds));\r\nfor (i = 0; i < ARRAY_SIZE(ndev_work->cmds) && ndev_work->cmds[i].cb; i++) {\r\nif (!ndev_work->cmds[i].ndev)\r\nndev_work->cmds[i].ndev = ndev;\r\nif (!ndev_work->cmds[i].filter_ndev)\r\nndev_work->cmds[i].filter_ndev = ndev;\r\ndev_hold(ndev_work->cmds[i].ndev);\r\ndev_hold(ndev_work->cmds[i].filter_ndev);\r\n}\r\nINIT_WORK(&ndev_work->work, netdevice_event_work_handler);\r\nqueue_work(ib_wq, &ndev_work->work);\r\nreturn NOTIFY_DONE;\r\n}\r\nstatic void netdevice_event_changeupper(struct netdev_notifier_changeupper_info *changeupper_info,\r\nstruct netdev_event_work_cmd *cmds)\r\n{\r\nstatic const struct netdev_event_work_cmd upper_ips_del_cmd = {\r\n.cb = del_netdev_upper_ips, .filter = upper_device_filter};\r\nstatic const struct netdev_event_work_cmd bonding_default_del_cmd = {\r\n.cb = del_netdev_default_ips, .filter = is_eth_port_inactive_slave};\r\nif (changeupper_info->linking == false) {\r\ncmds[0] = upper_ips_del_cmd;\r\ncmds[0].ndev = changeupper_info->upper_dev;\r\ncmds[1] = add_cmd;\r\n} else {\r\ncmds[0] = bonding_default_del_cmd;\r\ncmds[0].ndev = changeupper_info->upper_dev;\r\ncmds[1] = add_cmd_upper_ips;\r\ncmds[1].ndev = changeupper_info->upper_dev;\r\ncmds[1].filter_ndev = changeupper_info->upper_dev;\r\n}\r\n}\r\nstatic int netdevice_event(struct notifier_block *this, unsigned long event,\r\nvoid *ptr)\r\n{\r\nstatic const struct netdev_event_work_cmd del_cmd = {\r\n.cb = del_netdev_ips, .filter = pass_all_filter};\r\nstatic const struct netdev_event_work_cmd bonding_default_del_cmd_join = {\r\n.cb = del_netdev_default_ips_join, .filter = is_eth_port_inactive_slave};\r\nstatic const struct netdev_event_work_cmd default_del_cmd = {\r\n.cb = del_netdev_default_ips, .filter = pass_all_filter};\r\nstatic const struct netdev_event_work_cmd bonding_event_ips_del_cmd = {\r\n.cb = del_netdev_upper_ips, .filter = upper_device_filter};\r\nstruct net_device *ndev = netdev_notifier_info_to_dev(ptr);\r\nstruct netdev_event_work_cmd cmds[ROCE_NETDEV_CALLBACK_SZ] = { {NULL} };\r\nif (ndev->type != ARPHRD_ETHER)\r\nreturn NOTIFY_DONE;\r\nswitch (event) {\r\ncase NETDEV_REGISTER:\r\ncase NETDEV_UP:\r\ncmds[0] = bonding_default_del_cmd_join;\r\ncmds[1] = add_cmd;\r\nbreak;\r\ncase NETDEV_UNREGISTER:\r\nif (ndev->reg_state < NETREG_UNREGISTERED)\r\ncmds[0] = del_cmd;\r\nelse\r\nreturn NOTIFY_DONE;\r\nbreak;\r\ncase NETDEV_CHANGEADDR:\r\ncmds[0] = default_del_cmd;\r\ncmds[1] = add_cmd;\r\nbreak;\r\ncase NETDEV_CHANGEUPPER:\r\nnetdevice_event_changeupper(\r\ncontainer_of(ptr, struct netdev_notifier_changeupper_info, info),\r\ncmds);\r\nbreak;\r\ncase NETDEV_BONDING_FAILOVER:\r\ncmds[0] = bonding_event_ips_del_cmd;\r\ncmds[1] = bonding_default_del_cmd_join;\r\ncmds[2] = add_cmd_upper_ips;\r\nbreak;\r\ndefault:\r\nreturn NOTIFY_DONE;\r\n}\r\nreturn netdevice_queue_work(cmds, ndev);\r\n}\r\nstatic void update_gid_event_work_handler(struct work_struct *_work)\r\n{\r\nstruct update_gid_event_work *work =\r\ncontainer_of(_work, struct update_gid_event_work, work);\r\nib_enum_all_roce_netdevs(is_eth_port_of_netdev, work->gid_attr.ndev,\r\ncallback_for_addr_gid_device_scan, work);\r\ndev_put(work->gid_attr.ndev);\r\nkfree(work);\r\n}\r\nstatic int addr_event(struct notifier_block *this, unsigned long event,\r\nstruct sockaddr *sa, struct net_device *ndev)\r\n{\r\nstruct update_gid_event_work *work;\r\nenum gid_op_type gid_op;\r\nif (ndev->type != ARPHRD_ETHER)\r\nreturn NOTIFY_DONE;\r\nswitch (event) {\r\ncase NETDEV_UP:\r\ngid_op = GID_ADD;\r\nbreak;\r\ncase NETDEV_DOWN:\r\ngid_op = GID_DEL;\r\nbreak;\r\ndefault:\r\nreturn NOTIFY_DONE;\r\n}\r\nwork = kmalloc(sizeof(*work), GFP_ATOMIC);\r\nif (!work) {\r\npr_warn("roce_gid_mgmt: Couldn't allocate work for addr_event\n");\r\nreturn NOTIFY_DONE;\r\n}\r\nINIT_WORK(&work->work, update_gid_event_work_handler);\r\nrdma_ip2gid(sa, &work->gid);\r\nwork->gid_op = gid_op;\r\nmemset(&work->gid_attr, 0, sizeof(work->gid_attr));\r\ndev_hold(ndev);\r\nwork->gid_attr.ndev = ndev;\r\nqueue_work(ib_wq, &work->work);\r\nreturn NOTIFY_DONE;\r\n}\r\nstatic int inetaddr_event(struct notifier_block *this, unsigned long event,\r\nvoid *ptr)\r\n{\r\nstruct sockaddr_in in;\r\nstruct net_device *ndev;\r\nstruct in_ifaddr *ifa = ptr;\r\nin.sin_family = AF_INET;\r\nin.sin_addr.s_addr = ifa->ifa_address;\r\nndev = ifa->ifa_dev->dev;\r\nreturn addr_event(this, event, (struct sockaddr *)&in, ndev);\r\n}\r\nstatic int inet6addr_event(struct notifier_block *this, unsigned long event,\r\nvoid *ptr)\r\n{\r\nstruct sockaddr_in6 in6;\r\nstruct net_device *ndev;\r\nstruct inet6_ifaddr *ifa6 = ptr;\r\nin6.sin6_family = AF_INET6;\r\nin6.sin6_addr = ifa6->addr;\r\nndev = ifa6->idev->dev;\r\nreturn addr_event(this, event, (struct sockaddr *)&in6, ndev);\r\n}\r\nint __init roce_gid_mgmt_init(void)\r\n{\r\nregister_inetaddr_notifier(&nb_inetaddr);\r\nif (IS_ENABLED(CONFIG_IPV6))\r\nregister_inet6addr_notifier(&nb_inet6addr);\r\nregister_netdevice_notifier(&nb_netdevice);\r\nreturn 0;\r\n}\r\nvoid __exit roce_gid_mgmt_cleanup(void)\r\n{\r\nif (IS_ENABLED(CONFIG_IPV6))\r\nunregister_inet6addr_notifier(&nb_inet6addr);\r\nunregister_inetaddr_notifier(&nb_inetaddr);\r\nunregister_netdevice_notifier(&nb_netdevice);\r\n}
