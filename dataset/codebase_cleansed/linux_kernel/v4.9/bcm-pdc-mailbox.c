static ssize_t pdc_debugfs_read(struct file *filp, char __user *ubuf,\r\nsize_t count, loff_t *offp)\r\n{\r\nstruct pdc_state *pdcs;\r\nchar *buf;\r\nssize_t ret, out_offset, out_count;\r\nout_count = 512;\r\nbuf = kmalloc(out_count, GFP_KERNEL);\r\nif (!buf)\r\nreturn -ENOMEM;\r\npdcs = filp->private_data;\r\nout_offset = 0;\r\nout_offset += snprintf(buf + out_offset, out_count - out_offset,\r\n"SPU %u stats:\n", pdcs->pdc_idx);\r\nout_offset += snprintf(buf + out_offset, out_count - out_offset,\r\n"PDC requests............%u\n",\r\npdcs->pdc_requests);\r\nout_offset += snprintf(buf + out_offset, out_count - out_offset,\r\n"PDC responses...........%u\n",\r\npdcs->pdc_replies);\r\nout_offset += snprintf(buf + out_offset, out_count - out_offset,\r\n"Tx err ring full........%u\n",\r\npdcs->txnobuf);\r\nout_offset += snprintf(buf + out_offset, out_count - out_offset,\r\n"Rx err ring full........%u\n",\r\npdcs->rxnobuf);\r\nout_offset += snprintf(buf + out_offset, out_count - out_offset,\r\n"Receive overflow........%u\n",\r\npdcs->rx_oflow);\r\nif (out_offset > out_count)\r\nout_offset = out_count;\r\nret = simple_read_from_buffer(ubuf, count, offp, buf, out_offset);\r\nkfree(buf);\r\nreturn ret;\r\n}\r\nstatic void pdc_setup_debugfs(struct pdc_state *pdcs)\r\n{\r\nchar spu_stats_name[16];\r\nif (!debugfs_initialized())\r\nreturn;\r\nsnprintf(spu_stats_name, 16, "pdc%d_stats", pdcs->pdc_idx);\r\nif (!debugfs_dir)\r\ndebugfs_dir = debugfs_create_dir(KBUILD_MODNAME, NULL);\r\npdcs->debugfs_stats = debugfs_create_file(spu_stats_name, S_IRUSR,\r\ndebugfs_dir, pdcs,\r\n&pdc_debugfs_stats);\r\n}\r\nstatic void pdc_free_debugfs(void)\r\n{\r\nif (debugfs_dir && simple_empty(debugfs_dir)) {\r\ndebugfs_remove_recursive(debugfs_dir);\r\ndebugfs_dir = NULL;\r\n}\r\n}\r\nstatic inline void\r\npdc_build_rxd(struct pdc_state *pdcs, dma_addr_t dma_addr,\r\nu32 buf_len, u32 flags)\r\n{\r\nstruct device *dev = &pdcs->pdev->dev;\r\ndev_dbg(dev,\r\n"Writing rx descriptor for PDC %u at index %u with length %u. flags %#x\n",\r\npdcs->pdc_idx, pdcs->rxout, buf_len, flags);\r\niowrite32(lower_32_bits(dma_addr),\r\n(void *)&pdcs->rxd_64[pdcs->rxout].addrlow);\r\niowrite32(upper_32_bits(dma_addr),\r\n(void *)&pdcs->rxd_64[pdcs->rxout].addrhigh);\r\niowrite32(flags, (void *)&pdcs->rxd_64[pdcs->rxout].ctrl1);\r\niowrite32(buf_len, (void *)&pdcs->rxd_64[pdcs->rxout].ctrl2);\r\npdcs->rxout = NEXTRXD(pdcs->rxout, pdcs->nrxpost);\r\n}\r\nstatic inline void\r\npdc_build_txd(struct pdc_state *pdcs, dma_addr_t dma_addr, u32 buf_len,\r\nu32 flags)\r\n{\r\nstruct device *dev = &pdcs->pdev->dev;\r\ndev_dbg(dev,\r\n"Writing tx descriptor for PDC %u at index %u with length %u, flags %#x\n",\r\npdcs->pdc_idx, pdcs->txout, buf_len, flags);\r\niowrite32(lower_32_bits(dma_addr),\r\n(void *)&pdcs->txd_64[pdcs->txout].addrlow);\r\niowrite32(upper_32_bits(dma_addr),\r\n(void *)&pdcs->txd_64[pdcs->txout].addrhigh);\r\niowrite32(flags, (void *)&pdcs->txd_64[pdcs->txout].ctrl1);\r\niowrite32(buf_len, (void *)&pdcs->txd_64[pdcs->txout].ctrl2);\r\npdcs->txout = NEXTTXD(pdcs->txout, pdcs->ntxpost);\r\n}\r\nstatic int\r\npdc_receive(struct pdc_state *pdcs, struct brcm_message *mssg)\r\n{\r\nstruct device *dev = &pdcs->pdev->dev;\r\nu32 len, rx_status;\r\nu32 num_frags;\r\nint i;\r\nu8 *resp_hdr;\r\nu32 frags_rdy;\r\nu32 rx_idx;\r\ndma_addr_t resp_hdr_daddr;\r\nspin_lock(&pdcs->pdc_lock);\r\nfrags_rdy = NRXDACTIVE(pdcs->rxin, pdcs->last_rx_curr, pdcs->nrxpost);\r\nif ((frags_rdy == 0) || (frags_rdy < pdcs->rxin_numd[pdcs->rxin])) {\r\npdcs->last_rx_curr =\r\n(ioread32((void *)&pdcs->rxregs_64->status0) &\r\nCRYPTO_D64_RS0_CD_MASK) / RING_ENTRY_SIZE;\r\nfrags_rdy = NRXDACTIVE(pdcs->rxin, pdcs->last_rx_curr,\r\npdcs->nrxpost);\r\nif ((frags_rdy == 0) ||\r\n(frags_rdy < pdcs->rxin_numd[pdcs->rxin])) {\r\nspin_unlock(&pdcs->pdc_lock);\r\nreturn -EAGAIN;\r\n}\r\nrmb();\r\n}\r\nnum_frags = pdcs->txin_numd[pdcs->txin];\r\ndma_unmap_sg(dev, pdcs->src_sg[pdcs->txin],\r\nsg_nents(pdcs->src_sg[pdcs->txin]), DMA_TO_DEVICE);\r\nfor (i = 0; i < num_frags; i++)\r\npdcs->txin = NEXTTXD(pdcs->txin, pdcs->ntxpost);\r\ndev_dbg(dev, "PDC %u reclaimed %d tx descriptors",\r\npdcs->pdc_idx, num_frags);\r\nrx_idx = pdcs->rxin;\r\nnum_frags = pdcs->rxin_numd[rx_idx];\r\nmssg->ctx = pdcs->rxp_ctx[rx_idx];\r\npdcs->rxp_ctx[rx_idx] = NULL;\r\nresp_hdr = pdcs->resp_hdr[rx_idx];\r\nresp_hdr_daddr = pdcs->resp_hdr_daddr[rx_idx];\r\ndma_unmap_sg(dev, pdcs->dst_sg[rx_idx],\r\nsg_nents(pdcs->dst_sg[rx_idx]), DMA_FROM_DEVICE);\r\nfor (i = 0; i < num_frags; i++)\r\npdcs->rxin = NEXTRXD(pdcs->rxin, pdcs->nrxpost);\r\nspin_unlock(&pdcs->pdc_lock);\r\ndev_dbg(dev, "PDC %u reclaimed %d rx descriptors",\r\npdcs->pdc_idx, num_frags);\r\ndev_dbg(dev,\r\n"PDC %u txin %u, txout %u, rxin %u, rxout %u, last_rx_curr %u\n",\r\npdcs->pdc_idx, pdcs->txin, pdcs->txout, pdcs->rxin,\r\npdcs->rxout, pdcs->last_rx_curr);\r\nif (pdcs->pdc_resp_hdr_len == PDC_SPUM_RESP_HDR_LEN) {\r\nrx_status = *((u32 *)resp_hdr);\r\nlen = rx_status & RX_STATUS_LEN;\r\ndev_dbg(dev,\r\n"SPU response length %u bytes", len);\r\nif (unlikely(((rx_status & RX_STATUS_OVERFLOW) || (!len)))) {\r\nif (rx_status & RX_STATUS_OVERFLOW) {\r\ndev_err_ratelimited(dev,\r\n"crypto receive overflow");\r\npdcs->rx_oflow++;\r\n} else {\r\ndev_info_ratelimited(dev, "crypto rx len = 0");\r\n}\r\nreturn -EIO;\r\n}\r\n}\r\ndma_pool_free(pdcs->rx_buf_pool, resp_hdr, resp_hdr_daddr);\r\npdcs->pdc_replies++;\r\nif (num_frags > 0)\r\nreturn PDC_SUCCESS;\r\nelse\r\nreturn -EIO;\r\n}\r\nstatic int pdc_tx_list_sg_add(struct pdc_state *pdcs, struct scatterlist *sg)\r\n{\r\nu32 flags = 0;\r\nu32 eot;\r\nu32 tx_avail;\r\nu32 num_desc;\r\nu32 desc_w = 0;\r\nu32 bufcnt;\r\ndma_addr_t databufptr;\r\nnum_desc = (u32)sg_nents(sg);\r\ntx_avail = pdcs->ntxpost - NTXDACTIVE(pdcs->txin, pdcs->txout,\r\npdcs->ntxpost);\r\nif (unlikely(num_desc > tx_avail)) {\r\npdcs->txnobuf++;\r\nreturn -ENOSPC;\r\n}\r\nif (pdcs->tx_msg_start == pdcs->txout) {\r\npdcs->txin_numd[pdcs->tx_msg_start] = 0;\r\npdcs->src_sg[pdcs->txout] = sg;\r\nflags = D64_CTRL1_SOF;\r\n}\r\nwhile (sg) {\r\nif (unlikely(pdcs->txout == (pdcs->ntxd - 1)))\r\neot = D64_CTRL1_EOT;\r\nelse\r\neot = 0;\r\nbufcnt = sg_dma_len(sg);\r\ndatabufptr = sg_dma_address(sg);\r\nwhile (bufcnt > PDC_DMA_BUF_MAX) {\r\npdc_build_txd(pdcs, databufptr, PDC_DMA_BUF_MAX,\r\nflags | eot);\r\ndesc_w++;\r\nbufcnt -= PDC_DMA_BUF_MAX;\r\ndatabufptr += PDC_DMA_BUF_MAX;\r\nif (unlikely(pdcs->txout == (pdcs->ntxd - 1)))\r\neot = D64_CTRL1_EOT;\r\nelse\r\neot = 0;\r\n}\r\nsg = sg_next(sg);\r\nif (!sg)\r\nflags |= (D64_CTRL1_EOF | D64_CTRL1_IOC);\r\npdc_build_txd(pdcs, databufptr, bufcnt, flags | eot);\r\ndesc_w++;\r\nflags &= ~D64_CTRL1_SOF;\r\n}\r\npdcs->txin_numd[pdcs->tx_msg_start] += desc_w;\r\nreturn PDC_SUCCESS;\r\n}\r\nstatic int pdc_tx_list_final(struct pdc_state *pdcs)\r\n{\r\nwmb();\r\niowrite32(pdcs->rxout << 4, (void *)&pdcs->rxregs_64->ptr);\r\niowrite32(pdcs->txout << 4, (void *)&pdcs->txregs_64->ptr);\r\npdcs->pdc_requests++;\r\nreturn PDC_SUCCESS;\r\n}\r\nstatic int pdc_rx_list_init(struct pdc_state *pdcs, struct scatterlist *dst_sg,\r\nvoid *ctx)\r\n{\r\nu32 flags = 0;\r\nu32 rx_avail;\r\nu32 rx_pkt_cnt = 1;\r\ndma_addr_t daddr;\r\nvoid *vaddr;\r\nrx_avail = pdcs->nrxpost - NRXDACTIVE(pdcs->rxin, pdcs->rxout,\r\npdcs->nrxpost);\r\nif (unlikely(rx_pkt_cnt > rx_avail)) {\r\npdcs->rxnobuf++;\r\nreturn -ENOSPC;\r\n}\r\nvaddr = dma_pool_zalloc(pdcs->rx_buf_pool, GFP_ATOMIC, &daddr);\r\nif (!vaddr)\r\nreturn -ENOMEM;\r\npdcs->rx_msg_start = pdcs->rxout;\r\npdcs->tx_msg_start = pdcs->txout;\r\nflags = D64_CTRL1_SOF;\r\npdcs->rxin_numd[pdcs->rx_msg_start] = 1;\r\nif (unlikely(pdcs->rxout == (pdcs->nrxd - 1)))\r\nflags |= D64_CTRL1_EOT;\r\npdcs->rxp_ctx[pdcs->rxout] = ctx;\r\npdcs->dst_sg[pdcs->rxout] = dst_sg;\r\npdcs->resp_hdr[pdcs->rxout] = vaddr;\r\npdcs->resp_hdr_daddr[pdcs->rxout] = daddr;\r\npdc_build_rxd(pdcs, daddr, pdcs->pdc_resp_hdr_len, flags);\r\nreturn PDC_SUCCESS;\r\n}\r\nstatic int pdc_rx_list_sg_add(struct pdc_state *pdcs, struct scatterlist *sg)\r\n{\r\nu32 flags = 0;\r\nu32 rx_avail;\r\nu32 num_desc;\r\nu32 desc_w = 0;\r\nu32 bufcnt;\r\ndma_addr_t databufptr;\r\nnum_desc = (u32)sg_nents(sg);\r\nrx_avail = pdcs->nrxpost - NRXDACTIVE(pdcs->rxin, pdcs->rxout,\r\npdcs->nrxpost);\r\nif (unlikely(num_desc > rx_avail)) {\r\npdcs->rxnobuf++;\r\nreturn -ENOSPC;\r\n}\r\nwhile (sg) {\r\nif (unlikely(pdcs->rxout == (pdcs->nrxd - 1)))\r\nflags = D64_CTRL1_EOT;\r\nelse\r\nflags = 0;\r\nbufcnt = sg_dma_len(sg);\r\ndatabufptr = sg_dma_address(sg);\r\nwhile (bufcnt > PDC_DMA_BUF_MAX) {\r\npdc_build_rxd(pdcs, databufptr, PDC_DMA_BUF_MAX, flags);\r\ndesc_w++;\r\nbufcnt -= PDC_DMA_BUF_MAX;\r\ndatabufptr += PDC_DMA_BUF_MAX;\r\nif (unlikely(pdcs->rxout == (pdcs->nrxd - 1)))\r\nflags = D64_CTRL1_EOT;\r\nelse\r\nflags = 0;\r\n}\r\npdc_build_rxd(pdcs, databufptr, bufcnt, flags);\r\ndesc_w++;\r\nsg = sg_next(sg);\r\n}\r\npdcs->rxin_numd[pdcs->rx_msg_start] += desc_w;\r\nreturn PDC_SUCCESS;\r\n}\r\nstatic irqreturn_t pdc_irq_handler(int irq, void *cookie)\r\n{\r\nstruct pdc_state *pdcs = cookie;\r\nu32 intstatus = ioread32(pdcs->pdc_reg_vbase + PDC_INTSTATUS_OFFSET);\r\nif (intstatus & PDC_XMTINTEN_0)\r\nset_bit(PDC_XMTINT_0, &pdcs->intstatus);\r\nif (intstatus & PDC_RCVINTEN_0)\r\nset_bit(PDC_RCVINT_0, &pdcs->intstatus);\r\niowrite32(intstatus, pdcs->pdc_reg_vbase + PDC_INTSTATUS_OFFSET);\r\nif (pdcs && (irq == pdcs->pdc_irq) && (intstatus & PDC_INTMASK))\r\nreturn IRQ_WAKE_THREAD;\r\nreturn IRQ_NONE;\r\n}\r\nstatic irqreturn_t pdc_irq_thread(int irq, void *cookie)\r\n{\r\nstruct pdc_state *pdcs = cookie;\r\nstruct mbox_controller *mbc;\r\nstruct mbox_chan *chan;\r\nbool tx_int;\r\nbool rx_int;\r\nint rx_status;\r\nstruct brcm_message mssg;\r\ntx_int = test_and_clear_bit(PDC_XMTINT_0, &pdcs->intstatus);\r\nrx_int = test_and_clear_bit(PDC_RCVINT_0, &pdcs->intstatus);\r\nif (pdcs && (tx_int || rx_int)) {\r\ndev_dbg(&pdcs->pdev->dev,\r\n"%s() got irq %d with tx_int %s, rx_int %s",\r\n__func__, irq,\r\ntx_int ? "set" : "clear", rx_int ? "set" : "clear");\r\nmbc = &pdcs->mbc;\r\nchan = &mbc->chans[0];\r\nif (tx_int) {\r\ndev_dbg(&pdcs->pdev->dev, "%s(): tx done", __func__);\r\nmbox_chan_txdone(chan, PDC_SUCCESS);\r\n}\r\nif (rx_int) {\r\nwhile (1) {\r\nmemset(&mssg, 0, sizeof(mssg));\r\nmssg.type = BRCM_MESSAGE_SPU;\r\nrx_status = pdc_receive(pdcs, &mssg);\r\nif (rx_status >= 0) {\r\ndev_dbg(&pdcs->pdev->dev,\r\n"%s(): invoking client rx cb",\r\n__func__);\r\nmbox_chan_received_data(chan, &mssg);\r\n} else {\r\ndev_dbg(&pdcs->pdev->dev,\r\n"%s(): no SPU response available",\r\n__func__);\r\nbreak;\r\n}\r\n}\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nreturn IRQ_NONE;\r\n}\r\nstatic int pdc_ring_init(struct pdc_state *pdcs, int ringset)\r\n{\r\nint i;\r\nint err = PDC_SUCCESS;\r\nstruct dma64 *dma_reg;\r\nstruct device *dev = &pdcs->pdev->dev;\r\nstruct pdc_ring_alloc tx;\r\nstruct pdc_ring_alloc rx;\r\ntx.vbase = dma_pool_zalloc(pdcs->ring_pool, GFP_KERNEL, &tx.dmabase);\r\nif (!tx.vbase) {\r\nerr = -ENOMEM;\r\ngoto done;\r\n}\r\nrx.vbase = dma_pool_zalloc(pdcs->ring_pool, GFP_KERNEL, &rx.dmabase);\r\nif (!rx.vbase) {\r\nerr = -ENOMEM;\r\ngoto fail_dealloc;\r\n}\r\ndev_dbg(dev, " - base DMA addr of tx ring %pad", &tx.dmabase);\r\ndev_dbg(dev, " - base virtual addr of tx ring %p", tx.vbase);\r\ndev_dbg(dev, " - base DMA addr of rx ring %pad", &rx.dmabase);\r\ndev_dbg(dev, " - base virtual addr of rx ring %p", rx.vbase);\r\nspin_lock(&pdcs->pdc_lock);\r\nmemcpy(&pdcs->tx_ring_alloc, &tx, sizeof(tx));\r\nmemcpy(&pdcs->rx_ring_alloc, &rx, sizeof(rx));\r\npdcs->rxin = 0;\r\npdcs->rx_msg_start = 0;\r\npdcs->last_rx_curr = 0;\r\npdcs->rxout = 0;\r\npdcs->txin = 0;\r\npdcs->tx_msg_start = 0;\r\npdcs->txout = 0;\r\npdcs->txd_64 = (struct dma64dd *)pdcs->tx_ring_alloc.vbase;\r\npdcs->rxd_64 = (struct dma64dd *)pdcs->rx_ring_alloc.vbase;\r\ndma_reg = &pdcs->regs->dmaregs[ringset];\r\niowrite32(lower_32_bits(pdcs->tx_ring_alloc.dmabase),\r\n(void *)&dma_reg->dmaxmt.addrlow);\r\niowrite32(upper_32_bits(pdcs->tx_ring_alloc.dmabase),\r\n(void *)&dma_reg->dmaxmt.addrhigh);\r\niowrite32(lower_32_bits(pdcs->rx_ring_alloc.dmabase),\r\n(void *)&dma_reg->dmarcv.addrlow);\r\niowrite32(upper_32_bits(pdcs->rx_ring_alloc.dmabase),\r\n(void *)&dma_reg->dmarcv.addrhigh);\r\nfor (i = 0; i < PDC_RING_ENTRIES; i++) {\r\nif (i != pdcs->ntxpost) {\r\niowrite32(D64_CTRL1_SOF | D64_CTRL1_EOF,\r\n(void *)&pdcs->txd_64[i].ctrl1);\r\n} else {\r\niowrite32(D64_CTRL1_SOF | D64_CTRL1_EOF |\r\nD64_CTRL1_EOT,\r\n(void *)&pdcs->txd_64[i].ctrl1);\r\n}\r\nif (i != pdcs->nrxpost) {\r\niowrite32(D64_CTRL1_SOF,\r\n(void *)&pdcs->rxd_64[i].ctrl1);\r\n} else {\r\niowrite32(D64_CTRL1_SOF | D64_CTRL1_EOT,\r\n(void *)&pdcs->rxd_64[i].ctrl1);\r\n}\r\n}\r\nspin_unlock(&pdcs->pdc_lock);\r\nreturn PDC_SUCCESS;\r\nfail_dealloc:\r\ndma_pool_free(pdcs->ring_pool, tx.vbase, tx.dmabase);\r\ndone:\r\nreturn err;\r\n}\r\nstatic void pdc_ring_free(struct pdc_state *pdcs)\r\n{\r\nif (pdcs->tx_ring_alloc.vbase) {\r\ndma_pool_free(pdcs->ring_pool, pdcs->tx_ring_alloc.vbase,\r\npdcs->tx_ring_alloc.dmabase);\r\npdcs->tx_ring_alloc.vbase = NULL;\r\n}\r\nif (pdcs->rx_ring_alloc.vbase) {\r\ndma_pool_free(pdcs->ring_pool, pdcs->rx_ring_alloc.vbase,\r\npdcs->rx_ring_alloc.dmabase);\r\npdcs->rx_ring_alloc.vbase = NULL;\r\n}\r\n}\r\nstatic int pdc_send_data(struct mbox_chan *chan, void *data)\r\n{\r\nstruct pdc_state *pdcs = chan->con_priv;\r\nstruct device *dev = &pdcs->pdev->dev;\r\nstruct brcm_message *mssg = data;\r\nint err = PDC_SUCCESS;\r\nint src_nent;\r\nint dst_nent;\r\nint nent;\r\nif (mssg->type != BRCM_MESSAGE_SPU)\r\nreturn -ENOTSUPP;\r\nsrc_nent = sg_nents(mssg->spu.src);\r\nif (src_nent) {\r\nnent = dma_map_sg(dev, mssg->spu.src, src_nent, DMA_TO_DEVICE);\r\nif (nent == 0)\r\nreturn -EIO;\r\n}\r\ndst_nent = sg_nents(mssg->spu.dst);\r\nif (dst_nent) {\r\nnent = dma_map_sg(dev, mssg->spu.dst, dst_nent,\r\nDMA_FROM_DEVICE);\r\nif (nent == 0) {\r\ndma_unmap_sg(dev, mssg->spu.src, src_nent,\r\nDMA_TO_DEVICE);\r\nreturn -EIO;\r\n}\r\n}\r\nspin_lock(&pdcs->pdc_lock);\r\nerr = pdc_rx_list_init(pdcs, mssg->spu.dst, mssg->ctx);\r\nerr |= pdc_rx_list_sg_add(pdcs, mssg->spu.dst);\r\nerr |= pdc_tx_list_sg_add(pdcs, mssg->spu.src);\r\nerr |= pdc_tx_list_final(pdcs);\r\nspin_unlock(&pdcs->pdc_lock);\r\nif (err)\r\ndev_err(&pdcs->pdev->dev,\r\n"%s failed with error %d", __func__, err);\r\nreturn err;\r\n}\r\nstatic int pdc_startup(struct mbox_chan *chan)\r\n{\r\nreturn pdc_ring_init(chan->con_priv, PDC_RINGSET);\r\n}\r\nstatic void pdc_shutdown(struct mbox_chan *chan)\r\n{\r\nstruct pdc_state *pdcs = chan->con_priv;\r\nif (!pdcs)\r\nreturn;\r\ndev_dbg(&pdcs->pdev->dev,\r\n"Shutdown mailbox channel for PDC %u", pdcs->pdc_idx);\r\npdc_ring_free(pdcs);\r\n}\r\nstatic\r\nvoid pdc_hw_init(struct pdc_state *pdcs)\r\n{\r\nstruct platform_device *pdev;\r\nstruct device *dev;\r\nstruct dma64 *dma_reg;\r\nint ringset = PDC_RINGSET;\r\npdev = pdcs->pdev;\r\ndev = &pdev->dev;\r\ndev_dbg(dev, "PDC %u initial values:", pdcs->pdc_idx);\r\ndev_dbg(dev, "state structure: %p",\r\npdcs);\r\ndev_dbg(dev, " - base virtual addr of hw regs %p",\r\npdcs->pdc_reg_vbase);\r\npdcs->regs = (struct pdc_regs *)pdcs->pdc_reg_vbase;\r\npdcs->txregs_64 = (struct dma64_regs *)\r\n(void *)(((u8 *)pdcs->pdc_reg_vbase) +\r\nPDC_TXREGS_OFFSET + (sizeof(struct dma64) * ringset));\r\npdcs->rxregs_64 = (struct dma64_regs *)\r\n(void *)(((u8 *)pdcs->pdc_reg_vbase) +\r\nPDC_RXREGS_OFFSET + (sizeof(struct dma64) * ringset));\r\npdcs->ntxd = PDC_RING_ENTRIES;\r\npdcs->nrxd = PDC_RING_ENTRIES;\r\npdcs->ntxpost = PDC_RING_ENTRIES - 1;\r\npdcs->nrxpost = PDC_RING_ENTRIES - 1;\r\npdcs->regs->intmask = 0;\r\ndma_reg = &pdcs->regs->dmaregs[ringset];\r\niowrite32(0, (void *)&dma_reg->dmaxmt.ptr);\r\niowrite32(0, (void *)&dma_reg->dmarcv.ptr);\r\niowrite32(PDC_TX_CTL, (void *)&dma_reg->dmaxmt.control);\r\niowrite32(PDC_RX_CTL + (pdcs->rx_status_len << 1),\r\n(void *)&dma_reg->dmarcv.control);\r\nif (pdcs->pdc_resp_hdr_len == PDC_SPU2_RESP_HDR_LEN)\r\niowrite32(PDC_CKSUM_CTRL,\r\npdcs->pdc_reg_vbase + PDC_CKSUM_CTRL_OFFSET);\r\n}\r\nstatic int pdc_rx_buf_pool_create(struct pdc_state *pdcs)\r\n{\r\nstruct platform_device *pdev;\r\nstruct device *dev;\r\npdev = pdcs->pdev;\r\ndev = &pdev->dev;\r\npdcs->pdc_resp_hdr_len = pdcs->rx_status_len;\r\nif (pdcs->use_bcm_hdr)\r\npdcs->pdc_resp_hdr_len += BCM_HDR_LEN;\r\npdcs->rx_buf_pool = dma_pool_create("pdc rx bufs", dev,\r\npdcs->pdc_resp_hdr_len,\r\nRX_BUF_ALIGN, 0);\r\nif (!pdcs->rx_buf_pool)\r\nreturn -ENOMEM;\r\nreturn PDC_SUCCESS;\r\n}\r\nstatic int pdc_interrupts_init(struct pdc_state *pdcs)\r\n{\r\nstruct platform_device *pdev = pdcs->pdev;\r\nstruct device *dev = &pdev->dev;\r\nstruct device_node *dn = pdev->dev.of_node;\r\nint err;\r\npdcs->intstatus = 0;\r\niowrite32(PDC_INTMASK, pdcs->pdc_reg_vbase + PDC_INTMASK_OFFSET);\r\niowrite32(PDC_LAZY_INT, pdcs->pdc_reg_vbase + PDC_RCVLAZY0_OFFSET);\r\npdcs->pdc_irq = irq_of_parse_and_map(dn, 0);\r\ndev_dbg(dev, "pdc device %s irq %u for pdcs %p",\r\ndev_name(dev), pdcs->pdc_irq, pdcs);\r\nerr = devm_request_threaded_irq(dev, pdcs->pdc_irq,\r\npdc_irq_handler,\r\npdc_irq_thread, 0, dev_name(dev), pdcs);\r\nif (err) {\r\ndev_err(dev, "threaded tx IRQ %u request failed with err %d\n",\r\npdcs->pdc_irq, err);\r\nreturn err;\r\n}\r\nreturn PDC_SUCCESS;\r\n}\r\nstatic int pdc_mb_init(struct pdc_state *pdcs)\r\n{\r\nstruct device *dev = &pdcs->pdev->dev;\r\nstruct mbox_controller *mbc;\r\nint chan_index;\r\nint err;\r\nmbc = &pdcs->mbc;\r\nmbc->dev = dev;\r\nmbc->ops = &pdc_mbox_chan_ops;\r\nmbc->num_chans = 1;\r\nmbc->chans = devm_kcalloc(dev, mbc->num_chans, sizeof(*mbc->chans),\r\nGFP_KERNEL);\r\nif (!mbc->chans)\r\nreturn -ENOMEM;\r\nmbc->txdone_irq = true;\r\nmbc->txdone_poll = false;\r\nfor (chan_index = 0; chan_index < mbc->num_chans; chan_index++)\r\nmbc->chans[chan_index].con_priv = pdcs;\r\nerr = mbox_controller_register(mbc);\r\nif (err) {\r\ndev_crit(dev,\r\n"Failed to register PDC mailbox controller. Error %d.",\r\nerr);\r\nreturn err;\r\n}\r\nreturn 0;\r\n}\r\nstatic int pdc_dt_read(struct platform_device *pdev, struct pdc_state *pdcs)\r\n{\r\nstruct device *dev = &pdev->dev;\r\nstruct device_node *dn = pdev->dev.of_node;\r\nint err;\r\nerr = of_property_read_u32(dn, "brcm,rx-status-len",\r\n&pdcs->rx_status_len);\r\nif (err < 0)\r\ndev_err(dev,\r\n"%s failed to get DMA receive status length from device tree",\r\n__func__);\r\npdcs->use_bcm_hdr = of_property_read_bool(dn, "brcm,use-bcm-hdr");\r\nreturn 0;\r\n}\r\nstatic int pdc_probe(struct platform_device *pdev)\r\n{\r\nint err = 0;\r\nstruct device *dev = &pdev->dev;\r\nstruct resource *pdc_regs;\r\nstruct pdc_state *pdcs;\r\npdcs = devm_kzalloc(dev, sizeof(*pdcs), GFP_KERNEL);\r\nif (!pdcs) {\r\nerr = -ENOMEM;\r\ngoto cleanup;\r\n}\r\nspin_lock_init(&pdcs->pdc_lock);\r\npdcs->pdev = pdev;\r\nplatform_set_drvdata(pdev, pdcs);\r\npdcs->pdc_idx = pdcg.num_spu;\r\npdcg.num_spu++;\r\nerr = dma_set_mask_and_coherent(dev, DMA_BIT_MASK(32));\r\nif (err) {\r\ndev_warn(dev, "PDC device cannot perform DMA. Error %d.", err);\r\ngoto cleanup;\r\n}\r\npdcs->ring_pool = dma_pool_create("pdc rings", dev, PDC_RING_SIZE,\r\nRING_ALIGN, 0);\r\nif (!pdcs->ring_pool) {\r\nerr = -ENOMEM;\r\ngoto cleanup;\r\n}\r\nerr = pdc_dt_read(pdev, pdcs);\r\nif (err)\r\ngoto cleanup_ring_pool;\r\npdc_regs = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nif (!pdc_regs) {\r\nerr = -ENODEV;\r\ngoto cleanup_ring_pool;\r\n}\r\ndev_dbg(dev, "PDC register region res.start = %pa, res.end = %pa",\r\n&pdc_regs->start, &pdc_regs->end);\r\npdcs->pdc_reg_vbase = devm_ioremap_resource(&pdev->dev, pdc_regs);\r\nif (IS_ERR(pdcs->pdc_reg_vbase)) {\r\nerr = PTR_ERR(pdcs->pdc_reg_vbase);\r\ndev_err(&pdev->dev, "Failed to map registers: %d\n", err);\r\ngoto cleanup_ring_pool;\r\n}\r\nerr = pdc_rx_buf_pool_create(pdcs);\r\nif (err)\r\ngoto cleanup_ring_pool;\r\npdc_hw_init(pdcs);\r\nerr = pdc_interrupts_init(pdcs);\r\nif (err)\r\ngoto cleanup_buf_pool;\r\nerr = pdc_mb_init(pdcs);\r\nif (err)\r\ngoto cleanup_buf_pool;\r\npdcs->debugfs_stats = NULL;\r\npdc_setup_debugfs(pdcs);\r\ndev_dbg(dev, "pdc_probe() successful");\r\nreturn PDC_SUCCESS;\r\ncleanup_buf_pool:\r\ndma_pool_destroy(pdcs->rx_buf_pool);\r\ncleanup_ring_pool:\r\ndma_pool_destroy(pdcs->ring_pool);\r\ncleanup:\r\nreturn err;\r\n}\r\nstatic int pdc_remove(struct platform_device *pdev)\r\n{\r\nstruct pdc_state *pdcs = platform_get_drvdata(pdev);\r\npdc_free_debugfs();\r\nmbox_controller_unregister(&pdcs->mbc);\r\ndma_pool_destroy(pdcs->rx_buf_pool);\r\ndma_pool_destroy(pdcs->ring_pool);\r\nreturn 0;\r\n}
