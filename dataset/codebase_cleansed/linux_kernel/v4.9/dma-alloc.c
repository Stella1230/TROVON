static int map_page(unsigned long va, unsigned long pa, pgprot_t prot)\r\n{\r\npgd_t *pge;\r\npud_t *pue;\r\npmd_t *pme;\r\npte_t *pte;\r\nint err = -ENOMEM;\r\npge = pgd_offset_k(va);\r\npue = pud_offset(pge, va);\r\npme = pmd_offset(pue, va);\r\npte = pte_alloc_kernel(pme, va);\r\nif (pte != 0) {\r\nerr = 0;\r\nset_pte(pte, mk_pte_phys(pa & PAGE_MASK, prot));\r\n}\r\nreturn err;\r\n}\r\nvoid *consistent_alloc(gfp_t gfp, size_t size, dma_addr_t *dma_handle)\r\n{\r\nstruct vm_struct *area;\r\nunsigned long page, va, pa;\r\nvoid *ret;\r\nint order, err, i;\r\nif (in_interrupt())\r\nBUG();\r\nsize = PAGE_ALIGN(size);\r\norder = get_order(size);\r\npage = __get_free_pages(gfp, order);\r\nif (!page) {\r\nBUG();\r\nreturn NULL;\r\n}\r\narea = get_vm_area(size, VM_ALLOC);\r\nif (area == 0) {\r\nfree_pages(page, order);\r\nreturn NULL;\r\n}\r\nva = VMALLOC_VMADDR(area->addr);\r\nret = (void *) va;\r\n*dma_handle = pa = virt_to_bus((void *) page);\r\nif (order > 0) {\r\nstruct page *rpage = virt_to_page(page);\r\nsplit_page(rpage, order);\r\n}\r\nerr = 0;\r\nfor (i = 0; i < size && err == 0; i += PAGE_SIZE)\r\nerr = map_page(va + i, pa + i, PAGE_KERNEL_NOCACHE);\r\nif (err) {\r\nvfree((void *) va);\r\nreturn NULL;\r\n}\r\nfrv_cache_invalidate(va, va + size);\r\nreturn ret;\r\n}\r\nvoid consistent_free(void *vaddr)\r\n{\r\nif (in_interrupt())\r\nBUG();\r\nvfree(vaddr);\r\n}\r\nvoid consistent_sync(void *vaddr, size_t size, int direction)\r\n{\r\nunsigned long start = (unsigned long) vaddr;\r\nunsigned long end = start + size;\r\nswitch (direction) {\r\ncase PCI_DMA_NONE:\r\nBUG();\r\ncase PCI_DMA_FROMDEVICE:\r\nfrv_cache_invalidate(start, end);\r\nbreak;\r\ncase PCI_DMA_TODEVICE:\r\nfrv_dcache_writeback(start, end);\r\nbreak;\r\ncase PCI_DMA_BIDIRECTIONAL:\r\nfrv_dcache_writeback(start, end);\r\nbreak;\r\n}\r\n}\r\nvoid consistent_sync_page(struct page *page, unsigned long offset,\r\nsize_t size, int direction)\r\n{\r\nvoid *start;\r\nstart = page_address(page) + offset;\r\nconsistent_sync(start, size, direction);\r\n}
