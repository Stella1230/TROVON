static inline u8 vp_ioread8(u8 __iomem *addr)\r\n{\r\nreturn ioread8(addr);\r\n}\r\nstatic inline u16 vp_ioread16 (u16 __iomem *addr)\r\n{\r\nreturn ioread16(addr);\r\n}\r\nstatic inline u32 vp_ioread32(u32 __iomem *addr)\r\n{\r\nreturn ioread32(addr);\r\n}\r\nstatic inline void vp_iowrite8(u8 value, u8 __iomem *addr)\r\n{\r\niowrite8(value, addr);\r\n}\r\nstatic inline void vp_iowrite16(u16 value, u16 __iomem *addr)\r\n{\r\niowrite16(value, addr);\r\n}\r\nstatic inline void vp_iowrite32(u32 value, u32 __iomem *addr)\r\n{\r\niowrite32(value, addr);\r\n}\r\nstatic void vp_iowrite64_twopart(u64 val,\r\n__le32 __iomem *lo, __le32 __iomem *hi)\r\n{\r\nvp_iowrite32((u32)val, lo);\r\nvp_iowrite32(val >> 32, hi);\r\n}\r\nstatic void __iomem *map_capability(struct pci_dev *dev, int off,\r\nsize_t minlen,\r\nu32 align,\r\nu32 start, u32 size,\r\nsize_t *len)\r\n{\r\nu8 bar;\r\nu32 offset, length;\r\nvoid __iomem *p;\r\npci_read_config_byte(dev, off + offsetof(struct virtio_pci_cap,\r\nbar),\r\n&bar);\r\npci_read_config_dword(dev, off + offsetof(struct virtio_pci_cap, offset),\r\n&offset);\r\npci_read_config_dword(dev, off + offsetof(struct virtio_pci_cap, length),\r\n&length);\r\nif (length <= start) {\r\ndev_err(&dev->dev,\r\n"virtio_pci: bad capability len %u (>%u expected)\n",\r\nlength, start);\r\nreturn NULL;\r\n}\r\nif (length - start < minlen) {\r\ndev_err(&dev->dev,\r\n"virtio_pci: bad capability len %u (>=%zu expected)\n",\r\nlength, minlen);\r\nreturn NULL;\r\n}\r\nlength -= start;\r\nif (start + offset < offset) {\r\ndev_err(&dev->dev,\r\n"virtio_pci: map wrap-around %u+%u\n",\r\nstart, offset);\r\nreturn NULL;\r\n}\r\noffset += start;\r\nif (offset & (align - 1)) {\r\ndev_err(&dev->dev,\r\n"virtio_pci: offset %u not aligned to %u\n",\r\noffset, align);\r\nreturn NULL;\r\n}\r\nif (length > size)\r\nlength = size;\r\nif (len)\r\n*len = length;\r\nif (minlen + offset < minlen ||\r\nminlen + offset > pci_resource_len(dev, bar)) {\r\ndev_err(&dev->dev,\r\n"virtio_pci: map virtio %zu@%u "\r\n"out of range on bar %i length %lu\n",\r\nminlen, offset,\r\nbar, (unsigned long)pci_resource_len(dev, bar));\r\nreturn NULL;\r\n}\r\np = pci_iomap_range(dev, bar, offset, length);\r\nif (!p)\r\ndev_err(&dev->dev,\r\n"virtio_pci: unable to map virtio %u@%u on bar %i\n",\r\nlength, offset, bar);\r\nreturn p;\r\n}\r\nstatic u64 vp_get_features(struct virtio_device *vdev)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nu64 features;\r\nvp_iowrite32(0, &vp_dev->common->device_feature_select);\r\nfeatures = vp_ioread32(&vp_dev->common->device_feature);\r\nvp_iowrite32(1, &vp_dev->common->device_feature_select);\r\nfeatures |= ((u64)vp_ioread32(&vp_dev->common->device_feature) << 32);\r\nreturn features;\r\n}\r\nstatic int vp_finalize_features(struct virtio_device *vdev)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nvring_transport_features(vdev);\r\nif (!__virtio_test_bit(vdev, VIRTIO_F_VERSION_1)) {\r\ndev_err(&vdev->dev, "virtio: device uses modern interface "\r\n"but does not have VIRTIO_F_VERSION_1\n");\r\nreturn -EINVAL;\r\n}\r\nvp_iowrite32(0, &vp_dev->common->guest_feature_select);\r\nvp_iowrite32((u32)vdev->features, &vp_dev->common->guest_feature);\r\nvp_iowrite32(1, &vp_dev->common->guest_feature_select);\r\nvp_iowrite32(vdev->features >> 32, &vp_dev->common->guest_feature);\r\nreturn 0;\r\n}\r\nstatic void vp_get(struct virtio_device *vdev, unsigned offset,\r\nvoid *buf, unsigned len)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nu8 b;\r\n__le16 w;\r\n__le32 l;\r\nBUG_ON(offset + len > vp_dev->device_len);\r\nswitch (len) {\r\ncase 1:\r\nb = ioread8(vp_dev->device + offset);\r\nmemcpy(buf, &b, sizeof b);\r\nbreak;\r\ncase 2:\r\nw = cpu_to_le16(ioread16(vp_dev->device + offset));\r\nmemcpy(buf, &w, sizeof w);\r\nbreak;\r\ncase 4:\r\nl = cpu_to_le32(ioread32(vp_dev->device + offset));\r\nmemcpy(buf, &l, sizeof l);\r\nbreak;\r\ncase 8:\r\nl = cpu_to_le32(ioread32(vp_dev->device + offset));\r\nmemcpy(buf, &l, sizeof l);\r\nl = cpu_to_le32(ioread32(vp_dev->device + offset + sizeof l));\r\nmemcpy(buf + sizeof l, &l, sizeof l);\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\n}\r\nstatic void vp_set(struct virtio_device *vdev, unsigned offset,\r\nconst void *buf, unsigned len)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nu8 b;\r\n__le16 w;\r\n__le32 l;\r\nBUG_ON(offset + len > vp_dev->device_len);\r\nswitch (len) {\r\ncase 1:\r\nmemcpy(&b, buf, sizeof b);\r\niowrite8(b, vp_dev->device + offset);\r\nbreak;\r\ncase 2:\r\nmemcpy(&w, buf, sizeof w);\r\niowrite16(le16_to_cpu(w), vp_dev->device + offset);\r\nbreak;\r\ncase 4:\r\nmemcpy(&l, buf, sizeof l);\r\niowrite32(le32_to_cpu(l), vp_dev->device + offset);\r\nbreak;\r\ncase 8:\r\nmemcpy(&l, buf, sizeof l);\r\niowrite32(le32_to_cpu(l), vp_dev->device + offset);\r\nmemcpy(&l, buf + sizeof l, sizeof l);\r\niowrite32(le32_to_cpu(l), vp_dev->device + offset + sizeof l);\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\n}\r\nstatic u32 vp_generation(struct virtio_device *vdev)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nreturn vp_ioread8(&vp_dev->common->config_generation);\r\n}\r\nstatic u8 vp_get_status(struct virtio_device *vdev)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nreturn vp_ioread8(&vp_dev->common->device_status);\r\n}\r\nstatic void vp_set_status(struct virtio_device *vdev, u8 status)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nBUG_ON(status == 0);\r\nvp_iowrite8(status, &vp_dev->common->device_status);\r\n}\r\nstatic void vp_reset(struct virtio_device *vdev)\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nvp_iowrite8(0, &vp_dev->common->device_status);\r\nwhile (vp_ioread8(&vp_dev->common->device_status))\r\nmsleep(1);\r\nvp_synchronize_vectors(vdev);\r\n}\r\nstatic u16 vp_config_vector(struct virtio_pci_device *vp_dev, u16 vector)\r\n{\r\nvp_iowrite16(vector, &vp_dev->common->msix_config);\r\nreturn vp_ioread16(&vp_dev->common->msix_config);\r\n}\r\nstatic struct virtqueue *setup_vq(struct virtio_pci_device *vp_dev,\r\nstruct virtio_pci_vq_info *info,\r\nunsigned index,\r\nvoid (*callback)(struct virtqueue *vq),\r\nconst char *name,\r\nu16 msix_vec)\r\n{\r\nstruct virtio_pci_common_cfg __iomem *cfg = vp_dev->common;\r\nstruct virtqueue *vq;\r\nu16 num, off;\r\nint err;\r\nif (index >= vp_ioread16(&cfg->num_queues))\r\nreturn ERR_PTR(-ENOENT);\r\nvp_iowrite16(index, &cfg->queue_select);\r\nnum = vp_ioread16(&cfg->queue_size);\r\nif (!num || vp_ioread16(&cfg->queue_enable))\r\nreturn ERR_PTR(-ENOENT);\r\nif (num & (num - 1)) {\r\ndev_warn(&vp_dev->pci_dev->dev, "bad queue size %u", num);\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\noff = vp_ioread16(&cfg->queue_notify_off);\r\ninfo->msix_vector = msix_vec;\r\nvq = vring_create_virtqueue(index, num,\r\nSMP_CACHE_BYTES, &vp_dev->vdev,\r\ntrue, true, vp_notify, callback, name);\r\nif (!vq)\r\nreturn ERR_PTR(-ENOMEM);\r\nvp_iowrite16(virtqueue_get_vring_size(vq), &cfg->queue_size);\r\nvp_iowrite64_twopart(virtqueue_get_desc_addr(vq),\r\n&cfg->queue_desc_lo, &cfg->queue_desc_hi);\r\nvp_iowrite64_twopart(virtqueue_get_avail_addr(vq),\r\n&cfg->queue_avail_lo, &cfg->queue_avail_hi);\r\nvp_iowrite64_twopart(virtqueue_get_used_addr(vq),\r\n&cfg->queue_used_lo, &cfg->queue_used_hi);\r\nif (vp_dev->notify_base) {\r\nif ((u64)off * vp_dev->notify_offset_multiplier + 2\r\n> vp_dev->notify_len) {\r\ndev_warn(&vp_dev->pci_dev->dev,\r\n"bad notification offset %u (x %u) "\r\n"for queue %u > %zd",\r\noff, vp_dev->notify_offset_multiplier,\r\nindex, vp_dev->notify_len);\r\nerr = -EINVAL;\r\ngoto err_map_notify;\r\n}\r\nvq->priv = (void __force *)vp_dev->notify_base +\r\noff * vp_dev->notify_offset_multiplier;\r\n} else {\r\nvq->priv = (void __force *)map_capability(vp_dev->pci_dev,\r\nvp_dev->notify_map_cap, 2, 2,\r\noff * vp_dev->notify_offset_multiplier, 2,\r\nNULL);\r\n}\r\nif (!vq->priv) {\r\nerr = -ENOMEM;\r\ngoto err_map_notify;\r\n}\r\nif (msix_vec != VIRTIO_MSI_NO_VECTOR) {\r\nvp_iowrite16(msix_vec, &cfg->queue_msix_vector);\r\nmsix_vec = vp_ioread16(&cfg->queue_msix_vector);\r\nif (msix_vec == VIRTIO_MSI_NO_VECTOR) {\r\nerr = -EBUSY;\r\ngoto err_assign_vector;\r\n}\r\n}\r\nreturn vq;\r\nerr_assign_vector:\r\nif (!vp_dev->notify_base)\r\npci_iounmap(vp_dev->pci_dev, (void __iomem __force *)vq->priv);\r\nerr_map_notify:\r\nvring_del_virtqueue(vq);\r\nreturn ERR_PTR(err);\r\n}\r\nstatic int vp_modern_find_vqs(struct virtio_device *vdev, unsigned nvqs,\r\nstruct virtqueue *vqs[],\r\nvq_callback_t *callbacks[],\r\nconst char * const names[])\r\n{\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vdev);\r\nstruct virtqueue *vq;\r\nint rc = vp_find_vqs(vdev, nvqs, vqs, callbacks, names);\r\nif (rc)\r\nreturn rc;\r\nlist_for_each_entry(vq, &vdev->vqs, list) {\r\nvp_iowrite16(vq->index, &vp_dev->common->queue_select);\r\nvp_iowrite16(1, &vp_dev->common->queue_enable);\r\n}\r\nreturn 0;\r\n}\r\nstatic void del_vq(struct virtio_pci_vq_info *info)\r\n{\r\nstruct virtqueue *vq = info->vq;\r\nstruct virtio_pci_device *vp_dev = to_vp_device(vq->vdev);\r\nvp_iowrite16(vq->index, &vp_dev->common->queue_select);\r\nif (vp_dev->msix_enabled) {\r\nvp_iowrite16(VIRTIO_MSI_NO_VECTOR,\r\n&vp_dev->common->queue_msix_vector);\r\nvp_ioread16(&vp_dev->common->queue_msix_vector);\r\n}\r\nif (!vp_dev->notify_base)\r\npci_iounmap(vp_dev->pci_dev, (void __force __iomem *)vq->priv);\r\nvring_del_virtqueue(vq);\r\n}\r\nstatic inline int virtio_pci_find_capability(struct pci_dev *dev, u8 cfg_type,\r\nu32 ioresource_types, int *bars)\r\n{\r\nint pos;\r\nfor (pos = pci_find_capability(dev, PCI_CAP_ID_VNDR);\r\npos > 0;\r\npos = pci_find_next_capability(dev, pos, PCI_CAP_ID_VNDR)) {\r\nu8 type, bar;\r\npci_read_config_byte(dev, pos + offsetof(struct virtio_pci_cap,\r\ncfg_type),\r\n&type);\r\npci_read_config_byte(dev, pos + offsetof(struct virtio_pci_cap,\r\nbar),\r\n&bar);\r\nif (bar > 0x5)\r\ncontinue;\r\nif (type == cfg_type) {\r\nif (pci_resource_len(dev, bar) &&\r\npci_resource_flags(dev, bar) & ioresource_types) {\r\n*bars |= (1 << bar);\r\nreturn pos;\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic inline void check_offsets(void)\r\n{\r\nBUILD_BUG_ON(VIRTIO_PCI_CAP_VNDR !=\r\noffsetof(struct virtio_pci_cap, cap_vndr));\r\nBUILD_BUG_ON(VIRTIO_PCI_CAP_NEXT !=\r\noffsetof(struct virtio_pci_cap, cap_next));\r\nBUILD_BUG_ON(VIRTIO_PCI_CAP_LEN !=\r\noffsetof(struct virtio_pci_cap, cap_len));\r\nBUILD_BUG_ON(VIRTIO_PCI_CAP_CFG_TYPE !=\r\noffsetof(struct virtio_pci_cap, cfg_type));\r\nBUILD_BUG_ON(VIRTIO_PCI_CAP_BAR !=\r\noffsetof(struct virtio_pci_cap, bar));\r\nBUILD_BUG_ON(VIRTIO_PCI_CAP_OFFSET !=\r\noffsetof(struct virtio_pci_cap, offset));\r\nBUILD_BUG_ON(VIRTIO_PCI_CAP_LENGTH !=\r\noffsetof(struct virtio_pci_cap, length));\r\nBUILD_BUG_ON(VIRTIO_PCI_NOTIFY_CAP_MULT !=\r\noffsetof(struct virtio_pci_notify_cap,\r\nnotify_off_multiplier));\r\nBUILD_BUG_ON(VIRTIO_PCI_COMMON_DFSELECT !=\r\noffsetof(struct virtio_pci_common_cfg,\r\ndevice_feature_select));\r\nBUILD_BUG_ON(VIRTIO_PCI_COMMON_DF !=\r\noffsetof(struct virtio_pci_common_cfg, device_feature));\r\nBUILD_BUG_ON(VIRTIO_PCI_COMMON_GFSELECT !=\r\noffsetof(struct virtio_pci_common_cfg,\r\nguest_feature_select));\r\nBUILD_BUG_ON(VIRTIO_PCI_COMMON_GF !=\r\noffsetof(struct virtio_pci_common_cfg, guest_feature));\r\nBUILD_BUG_ON(VIRTIO_PCI_COMMON_MSIX !=\r\noffsetof(struct virtio_pci_common_cfg, msix_config));\r\nBUILD_BUG_ON(VIRTIO_PCI_COMMON_NUMQ !=\r\noffsetof(struct virtio_pci_common_cfg, num_queues));\r\nBUILD_BUG_ON(VIRTIO_PCI_COMMON_STATUS !=\r\noffsetof(struct virtio_pci_common_cfg, device_status));\r\nBUILD_BUG_ON(VIRTIO_PCI_COMMON_CFGGENERATION !=\r\noffsetof(struct virtio_pci_common_cfg, config_generation));\r\nBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_SELECT !=\r\noffsetof(struct virtio_pci_common_cfg, queue_select));\r\nBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_SIZE !=\r\noffsetof(struct virtio_pci_common_cfg, queue_size));\r\nBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_MSIX !=\r\noffsetof(struct virtio_pci_common_cfg, queue_msix_vector));\r\nBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_ENABLE !=\r\noffsetof(struct virtio_pci_common_cfg, queue_enable));\r\nBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_NOFF !=\r\noffsetof(struct virtio_pci_common_cfg, queue_notify_off));\r\nBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_DESCLO !=\r\noffsetof(struct virtio_pci_common_cfg, queue_desc_lo));\r\nBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_DESCHI !=\r\noffsetof(struct virtio_pci_common_cfg, queue_desc_hi));\r\nBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_AVAILLO !=\r\noffsetof(struct virtio_pci_common_cfg, queue_avail_lo));\r\nBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_AVAILHI !=\r\noffsetof(struct virtio_pci_common_cfg, queue_avail_hi));\r\nBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_USEDLO !=\r\noffsetof(struct virtio_pci_common_cfg, queue_used_lo));\r\nBUILD_BUG_ON(VIRTIO_PCI_COMMON_Q_USEDHI !=\r\noffsetof(struct virtio_pci_common_cfg, queue_used_hi));\r\n}\r\nint virtio_pci_modern_probe(struct virtio_pci_device *vp_dev)\r\n{\r\nstruct pci_dev *pci_dev = vp_dev->pci_dev;\r\nint err, common, isr, notify, device;\r\nu32 notify_length;\r\nu32 notify_offset;\r\ncheck_offsets();\r\nif (pci_dev->device < 0x1000 || pci_dev->device > 0x107f)\r\nreturn -ENODEV;\r\nif (pci_dev->device < 0x1040) {\r\nvp_dev->vdev.id.device = pci_dev->subsystem_device;\r\n} else {\r\nvp_dev->vdev.id.device = pci_dev->device - 0x1040;\r\n}\r\nvp_dev->vdev.id.vendor = pci_dev->subsystem_vendor;\r\ncommon = virtio_pci_find_capability(pci_dev, VIRTIO_PCI_CAP_COMMON_CFG,\r\nIORESOURCE_IO | IORESOURCE_MEM,\r\n&vp_dev->modern_bars);\r\nif (!common) {\r\ndev_info(&pci_dev->dev,\r\n"virtio_pci: leaving for legacy driver\n");\r\nreturn -ENODEV;\r\n}\r\nisr = virtio_pci_find_capability(pci_dev, VIRTIO_PCI_CAP_ISR_CFG,\r\nIORESOURCE_IO | IORESOURCE_MEM,\r\n&vp_dev->modern_bars);\r\nnotify = virtio_pci_find_capability(pci_dev, VIRTIO_PCI_CAP_NOTIFY_CFG,\r\nIORESOURCE_IO | IORESOURCE_MEM,\r\n&vp_dev->modern_bars);\r\nif (!isr || !notify) {\r\ndev_err(&pci_dev->dev,\r\n"virtio_pci: missing capabilities %i/%i/%i\n",\r\ncommon, isr, notify);\r\nreturn -EINVAL;\r\n}\r\nerr = dma_set_mask_and_coherent(&pci_dev->dev, DMA_BIT_MASK(64));\r\nif (err)\r\nerr = dma_set_mask_and_coherent(&pci_dev->dev,\r\nDMA_BIT_MASK(32));\r\nif (err)\r\ndev_warn(&pci_dev->dev, "Failed to enable 64-bit or 32-bit DMA. Trying to continue, but this might not work.\n");\r\ndevice = virtio_pci_find_capability(pci_dev, VIRTIO_PCI_CAP_DEVICE_CFG,\r\nIORESOURCE_IO | IORESOURCE_MEM,\r\n&vp_dev->modern_bars);\r\nerr = pci_request_selected_regions(pci_dev, vp_dev->modern_bars,\r\n"virtio-pci-modern");\r\nif (err)\r\nreturn err;\r\nerr = -EINVAL;\r\nvp_dev->common = map_capability(pci_dev, common,\r\nsizeof(struct virtio_pci_common_cfg), 4,\r\n0, sizeof(struct virtio_pci_common_cfg),\r\nNULL);\r\nif (!vp_dev->common)\r\ngoto err_map_common;\r\nvp_dev->isr = map_capability(pci_dev, isr, sizeof(u8), 1,\r\n0, 1,\r\nNULL);\r\nif (!vp_dev->isr)\r\ngoto err_map_isr;\r\npci_read_config_dword(pci_dev,\r\nnotify + offsetof(struct virtio_pci_notify_cap,\r\nnotify_off_multiplier),\r\n&vp_dev->notify_offset_multiplier);\r\npci_read_config_dword(pci_dev,\r\nnotify + offsetof(struct virtio_pci_notify_cap,\r\ncap.length),\r\n&notify_length);\r\npci_read_config_dword(pci_dev,\r\nnotify + offsetof(struct virtio_pci_notify_cap,\r\ncap.offset),\r\n&notify_offset);\r\nif ((u64)notify_length + (notify_offset % PAGE_SIZE) <= PAGE_SIZE) {\r\nvp_dev->notify_base = map_capability(pci_dev, notify, 2, 2,\r\n0, notify_length,\r\n&vp_dev->notify_len);\r\nif (!vp_dev->notify_base)\r\ngoto err_map_notify;\r\n} else {\r\nvp_dev->notify_map_cap = notify;\r\n}\r\nif (device) {\r\nvp_dev->device = map_capability(pci_dev, device, 0, 4,\r\n0, PAGE_SIZE,\r\n&vp_dev->device_len);\r\nif (!vp_dev->device)\r\ngoto err_map_device;\r\nvp_dev->vdev.config = &virtio_pci_config_ops;\r\n} else {\r\nvp_dev->vdev.config = &virtio_pci_config_nodev_ops;\r\n}\r\nvp_dev->config_vector = vp_config_vector;\r\nvp_dev->setup_vq = setup_vq;\r\nvp_dev->del_vq = del_vq;\r\nreturn 0;\r\nerr_map_device:\r\nif (vp_dev->notify_base)\r\npci_iounmap(pci_dev, vp_dev->notify_base);\r\nerr_map_notify:\r\npci_iounmap(pci_dev, vp_dev->isr);\r\nerr_map_isr:\r\npci_iounmap(pci_dev, vp_dev->common);\r\nerr_map_common:\r\nreturn err;\r\n}\r\nvoid virtio_pci_modern_remove(struct virtio_pci_device *vp_dev)\r\n{\r\nstruct pci_dev *pci_dev = vp_dev->pci_dev;\r\nif (vp_dev->device)\r\npci_iounmap(pci_dev, vp_dev->device);\r\nif (vp_dev->notify_base)\r\npci_iounmap(pci_dev, vp_dev->notify_base);\r\npci_iounmap(pci_dev, vp_dev->isr);\r\npci_iounmap(pci_dev, vp_dev->common);\r\npci_release_selected_regions(pci_dev, vp_dev->modern_bars);\r\n}
