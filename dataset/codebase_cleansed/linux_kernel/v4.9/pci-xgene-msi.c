static u32 xgene_msi_ir_read(struct xgene_msi *msi,\r\nu32 msi_grp, u32 msir_idx)\r\n{\r\nreturn readl_relaxed(msi->msi_regs + MSI_IR0 +\r\n(msi_grp << 19) + (msir_idx << 16));\r\n}\r\nstatic u32 xgene_msi_int_read(struct xgene_msi *msi, u32 msi_grp)\r\n{\r\nreturn readl_relaxed(msi->msi_regs + MSI_INT0 + (msi_grp << 16));\r\n}\r\nstatic u32 hwirq_to_reg_set(unsigned long hwirq)\r\n{\r\nreturn (hwirq / (NR_HW_IRQS * IRQS_PER_IDX));\r\n}\r\nstatic u32 hwirq_to_group(unsigned long hwirq)\r\n{\r\nreturn (hwirq % NR_HW_IRQS);\r\n}\r\nstatic u32 hwirq_to_msi_data(unsigned long hwirq)\r\n{\r\nreturn ((hwirq / NR_HW_IRQS) % IRQS_PER_IDX);\r\n}\r\nstatic void xgene_compose_msi_msg(struct irq_data *data, struct msi_msg *msg)\r\n{\r\nstruct xgene_msi *msi = irq_data_get_irq_chip_data(data);\r\nu32 reg_set = hwirq_to_reg_set(data->hwirq);\r\nu32 group = hwirq_to_group(data->hwirq);\r\nu64 target_addr = msi->msi_addr + (((8 * group) + reg_set) << 16);\r\nmsg->address_hi = upper_32_bits(target_addr);\r\nmsg->address_lo = lower_32_bits(target_addr);\r\nmsg->data = hwirq_to_msi_data(data->hwirq);\r\n}\r\nstatic int hwirq_to_cpu(unsigned long hwirq)\r\n{\r\nreturn (hwirq % xgene_msi_ctrl.num_cpus);\r\n}\r\nstatic unsigned long hwirq_to_canonical_hwirq(unsigned long hwirq)\r\n{\r\nreturn (hwirq - hwirq_to_cpu(hwirq));\r\n}\r\nstatic int xgene_msi_set_affinity(struct irq_data *irqdata,\r\nconst struct cpumask *mask, bool force)\r\n{\r\nint target_cpu = cpumask_first(mask);\r\nint curr_cpu;\r\ncurr_cpu = hwirq_to_cpu(irqdata->hwirq);\r\nif (curr_cpu == target_cpu)\r\nreturn IRQ_SET_MASK_OK_DONE;\r\nirqdata->hwirq = hwirq_to_canonical_hwirq(irqdata->hwirq) + target_cpu;\r\nreturn IRQ_SET_MASK_OK;\r\n}\r\nstatic int xgene_irq_domain_alloc(struct irq_domain *domain, unsigned int virq,\r\nunsigned int nr_irqs, void *args)\r\n{\r\nstruct xgene_msi *msi = domain->host_data;\r\nint msi_irq;\r\nmutex_lock(&msi->bitmap_lock);\r\nmsi_irq = bitmap_find_next_zero_area(msi->bitmap, NR_MSI_VEC, 0,\r\nmsi->num_cpus, 0);\r\nif (msi_irq < NR_MSI_VEC)\r\nbitmap_set(msi->bitmap, msi_irq, msi->num_cpus);\r\nelse\r\nmsi_irq = -ENOSPC;\r\nmutex_unlock(&msi->bitmap_lock);\r\nif (msi_irq < 0)\r\nreturn msi_irq;\r\nirq_domain_set_info(domain, virq, msi_irq,\r\n&xgene_msi_bottom_irq_chip, domain->host_data,\r\nhandle_simple_irq, NULL, NULL);\r\nreturn 0;\r\n}\r\nstatic void xgene_irq_domain_free(struct irq_domain *domain,\r\nunsigned int virq, unsigned int nr_irqs)\r\n{\r\nstruct irq_data *d = irq_domain_get_irq_data(domain, virq);\r\nstruct xgene_msi *msi = irq_data_get_irq_chip_data(d);\r\nu32 hwirq;\r\nmutex_lock(&msi->bitmap_lock);\r\nhwirq = hwirq_to_canonical_hwirq(d->hwirq);\r\nbitmap_clear(msi->bitmap, hwirq, msi->num_cpus);\r\nmutex_unlock(&msi->bitmap_lock);\r\nirq_domain_free_irqs_parent(domain, virq, nr_irqs);\r\n}\r\nstatic int xgene_allocate_domains(struct xgene_msi *msi)\r\n{\r\nmsi->inner_domain = irq_domain_add_linear(NULL, NR_MSI_VEC,\r\n&msi_domain_ops, msi);\r\nif (!msi->inner_domain)\r\nreturn -ENOMEM;\r\nmsi->msi_domain = pci_msi_create_irq_domain(of_node_to_fwnode(msi->node),\r\n&xgene_msi_domain_info,\r\nmsi->inner_domain);\r\nif (!msi->msi_domain) {\r\nirq_domain_remove(msi->inner_domain);\r\nreturn -ENOMEM;\r\n}\r\nreturn 0;\r\n}\r\nstatic void xgene_free_domains(struct xgene_msi *msi)\r\n{\r\nif (msi->msi_domain)\r\nirq_domain_remove(msi->msi_domain);\r\nif (msi->inner_domain)\r\nirq_domain_remove(msi->inner_domain);\r\n}\r\nstatic int xgene_msi_init_allocator(struct xgene_msi *xgene_msi)\r\n{\r\nint size = BITS_TO_LONGS(NR_MSI_VEC) * sizeof(long);\r\nxgene_msi->bitmap = kzalloc(size, GFP_KERNEL);\r\nif (!xgene_msi->bitmap)\r\nreturn -ENOMEM;\r\nmutex_init(&xgene_msi->bitmap_lock);\r\nxgene_msi->msi_groups = kcalloc(NR_HW_IRQS,\r\nsizeof(struct xgene_msi_group),\r\nGFP_KERNEL);\r\nif (!xgene_msi->msi_groups)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nstatic void xgene_msi_isr(struct irq_desc *desc)\r\n{\r\nstruct irq_chip *chip = irq_desc_get_chip(desc);\r\nstruct xgene_msi_group *msi_groups;\r\nstruct xgene_msi *xgene_msi;\r\nunsigned int virq;\r\nint msir_index, msir_val, hw_irq;\r\nu32 intr_index, grp_select, msi_grp;\r\nchained_irq_enter(chip, desc);\r\nmsi_groups = irq_desc_get_handler_data(desc);\r\nxgene_msi = msi_groups->msi;\r\nmsi_grp = msi_groups->msi_grp;\r\ngrp_select = xgene_msi_int_read(xgene_msi, msi_grp);\r\nwhile (grp_select) {\r\nmsir_index = ffs(grp_select) - 1;\r\nmsir_val = xgene_msi_ir_read(xgene_msi, msi_grp, msir_index);\r\nwhile (msir_val) {\r\nintr_index = ffs(msir_val) - 1;\r\nhw_irq = (((msir_index * IRQS_PER_IDX) + intr_index) *\r\nNR_HW_IRQS) + msi_grp;\r\nhw_irq = hwirq_to_canonical_hwirq(hw_irq);\r\nvirq = irq_find_mapping(xgene_msi->inner_domain, hw_irq);\r\nWARN_ON(!virq);\r\nif (virq != 0)\r\ngeneric_handle_irq(virq);\r\nmsir_val &= ~(1 << intr_index);\r\n}\r\ngrp_select &= ~(1 << msir_index);\r\nif (!grp_select) {\r\ngrp_select = xgene_msi_int_read(xgene_msi, msi_grp);\r\n}\r\n}\r\nchained_irq_exit(chip, desc);\r\n}\r\nstatic int xgene_msi_remove(struct platform_device *pdev)\r\n{\r\nint virq, i;\r\nstruct xgene_msi *msi = platform_get_drvdata(pdev);\r\nfor (i = 0; i < NR_HW_IRQS; i++) {\r\nvirq = msi->msi_groups[i].gic_irq;\r\nif (virq != 0)\r\nirq_set_chained_handler_and_data(virq, NULL, NULL);\r\n}\r\nkfree(msi->msi_groups);\r\nkfree(msi->bitmap);\r\nmsi->bitmap = NULL;\r\nxgene_free_domains(msi);\r\nreturn 0;\r\n}\r\nstatic int xgene_msi_hwirq_alloc(unsigned int cpu)\r\n{\r\nstruct xgene_msi *msi = &xgene_msi_ctrl;\r\nstruct xgene_msi_group *msi_group;\r\ncpumask_var_t mask;\r\nint i;\r\nint err;\r\nfor (i = cpu; i < NR_HW_IRQS; i += msi->num_cpus) {\r\nmsi_group = &msi->msi_groups[i];\r\nif (!msi_group->gic_irq)\r\ncontinue;\r\nirq_set_chained_handler(msi_group->gic_irq,\r\nxgene_msi_isr);\r\nerr = irq_set_handler_data(msi_group->gic_irq, msi_group);\r\nif (err) {\r\npr_err("failed to register GIC IRQ handler\n");\r\nreturn -EINVAL;\r\n}\r\nif (alloc_cpumask_var(&mask, GFP_KERNEL)) {\r\ncpumask_clear(mask);\r\ncpumask_set_cpu(cpu, mask);\r\nerr = irq_set_affinity(msi_group->gic_irq, mask);\r\nif (err)\r\npr_err("failed to set affinity for GIC IRQ");\r\nfree_cpumask_var(mask);\r\n} else {\r\npr_err("failed to alloc CPU mask for affinity\n");\r\nerr = -EINVAL;\r\n}\r\nif (err) {\r\nirq_set_chained_handler_and_data(msi_group->gic_irq,\r\nNULL, NULL);\r\nreturn err;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void xgene_msi_hwirq_free(unsigned int cpu)\r\n{\r\nstruct xgene_msi *msi = &xgene_msi_ctrl;\r\nstruct xgene_msi_group *msi_group;\r\nint i;\r\nfor (i = cpu; i < NR_HW_IRQS; i += msi->num_cpus) {\r\nmsi_group = &msi->msi_groups[i];\r\nif (!msi_group->gic_irq)\r\ncontinue;\r\nirq_set_chained_handler_and_data(msi_group->gic_irq, NULL,\r\nNULL);\r\n}\r\n}\r\nstatic int xgene_msi_cpu_callback(struct notifier_block *nfb,\r\nunsigned long action, void *hcpu)\r\n{\r\nunsigned cpu = (unsigned long)hcpu;\r\nswitch (action) {\r\ncase CPU_ONLINE:\r\ncase CPU_ONLINE_FROZEN:\r\nxgene_msi_hwirq_alloc(cpu);\r\nbreak;\r\ncase CPU_DEAD:\r\ncase CPU_DEAD_FROZEN:\r\nxgene_msi_hwirq_free(cpu);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn NOTIFY_OK;\r\n}\r\nstatic int xgene_msi_probe(struct platform_device *pdev)\r\n{\r\nstruct resource *res;\r\nint rc, irq_index;\r\nstruct xgene_msi *xgene_msi;\r\nunsigned int cpu;\r\nint virt_msir;\r\nu32 msi_val, msi_idx;\r\nxgene_msi = &xgene_msi_ctrl;\r\nplatform_set_drvdata(pdev, xgene_msi);\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nxgene_msi->msi_regs = devm_ioremap_resource(&pdev->dev, res);\r\nif (IS_ERR(xgene_msi->msi_regs)) {\r\ndev_err(&pdev->dev, "no reg space\n");\r\nrc = -EINVAL;\r\ngoto error;\r\n}\r\nxgene_msi->msi_addr = res->start;\r\nxgene_msi->node = pdev->dev.of_node;\r\nxgene_msi->num_cpus = num_possible_cpus();\r\nrc = xgene_msi_init_allocator(xgene_msi);\r\nif (rc) {\r\ndev_err(&pdev->dev, "Error allocating MSI bitmap\n");\r\ngoto error;\r\n}\r\nrc = xgene_allocate_domains(xgene_msi);\r\nif (rc) {\r\ndev_err(&pdev->dev, "Failed to allocate MSI domain\n");\r\ngoto error;\r\n}\r\nfor (irq_index = 0; irq_index < NR_HW_IRQS; irq_index++) {\r\nvirt_msir = platform_get_irq(pdev, irq_index);\r\nif (virt_msir < 0) {\r\ndev_err(&pdev->dev, "Cannot translate IRQ index %d\n",\r\nirq_index);\r\nrc = -EINVAL;\r\ngoto error;\r\n}\r\nxgene_msi->msi_groups[irq_index].gic_irq = virt_msir;\r\nxgene_msi->msi_groups[irq_index].msi_grp = irq_index;\r\nxgene_msi->msi_groups[irq_index].msi = xgene_msi;\r\n}\r\nfor (irq_index = 0; irq_index < NR_HW_IRQS; irq_index++) {\r\nfor (msi_idx = 0; msi_idx < IDX_PER_GROUP; msi_idx++)\r\nmsi_val = xgene_msi_ir_read(xgene_msi, irq_index,\r\nmsi_idx);\r\nmsi_val = xgene_msi_int_read(xgene_msi, irq_index);\r\nif (msi_val) {\r\ndev_err(&pdev->dev, "Failed to clear spurious IRQ\n");\r\nrc = -EINVAL;\r\ngoto error;\r\n}\r\n}\r\ncpu_notifier_register_begin();\r\nfor_each_online_cpu(cpu)\r\nif (xgene_msi_hwirq_alloc(cpu)) {\r\ndev_err(&pdev->dev, "failed to register MSI handlers\n");\r\ncpu_notifier_register_done();\r\ngoto error;\r\n}\r\nrc = __register_hotcpu_notifier(&xgene_msi_cpu_notifier);\r\nif (rc) {\r\ndev_err(&pdev->dev, "failed to add CPU MSI notifier\n");\r\ncpu_notifier_register_done();\r\ngoto error;\r\n}\r\ncpu_notifier_register_done();\r\ndev_info(&pdev->dev, "APM X-Gene PCIe MSI driver loaded\n");\r\nreturn 0;\r\nerror:\r\nxgene_msi_remove(pdev);\r\nreturn rc;\r\n}\r\nstatic int __init xgene_pcie_msi_init(void)\r\n{\r\nreturn platform_driver_register(&xgene_msi_driver);\r\n}
