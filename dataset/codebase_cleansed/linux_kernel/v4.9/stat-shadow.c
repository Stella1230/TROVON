void perf_stat__init_shadow_stats(void)\r\n{\r\nhave_frontend_stalled = pmu_have_event("cpu", "stalled-cycles-frontend");\r\n}\r\nstatic int evsel_context(struct perf_evsel *evsel)\r\n{\r\nint ctx = 0;\r\nif (evsel->attr.exclude_kernel)\r\nctx |= CTX_BIT_KERNEL;\r\nif (evsel->attr.exclude_user)\r\nctx |= CTX_BIT_USER;\r\nif (evsel->attr.exclude_hv)\r\nctx |= CTX_BIT_HV;\r\nif (evsel->attr.exclude_host)\r\nctx |= CTX_BIT_HOST;\r\nif (evsel->attr.exclude_idle)\r\nctx |= CTX_BIT_IDLE;\r\nreturn ctx;\r\n}\r\nvoid perf_stat__reset_shadow_stats(void)\r\n{\r\nmemset(runtime_nsecs_stats, 0, sizeof(runtime_nsecs_stats));\r\nmemset(runtime_cycles_stats, 0, sizeof(runtime_cycles_stats));\r\nmemset(runtime_stalled_cycles_front_stats, 0, sizeof(runtime_stalled_cycles_front_stats));\r\nmemset(runtime_stalled_cycles_back_stats, 0, sizeof(runtime_stalled_cycles_back_stats));\r\nmemset(runtime_branches_stats, 0, sizeof(runtime_branches_stats));\r\nmemset(runtime_cacherefs_stats, 0, sizeof(runtime_cacherefs_stats));\r\nmemset(runtime_l1_dcache_stats, 0, sizeof(runtime_l1_dcache_stats));\r\nmemset(runtime_l1_icache_stats, 0, sizeof(runtime_l1_icache_stats));\r\nmemset(runtime_ll_cache_stats, 0, sizeof(runtime_ll_cache_stats));\r\nmemset(runtime_itlb_cache_stats, 0, sizeof(runtime_itlb_cache_stats));\r\nmemset(runtime_dtlb_cache_stats, 0, sizeof(runtime_dtlb_cache_stats));\r\nmemset(runtime_cycles_in_tx_stats, 0,\r\nsizeof(runtime_cycles_in_tx_stats));\r\nmemset(runtime_transaction_stats, 0,\r\nsizeof(runtime_transaction_stats));\r\nmemset(runtime_elision_stats, 0, sizeof(runtime_elision_stats));\r\nmemset(&walltime_nsecs_stats, 0, sizeof(walltime_nsecs_stats));\r\nmemset(runtime_topdown_total_slots, 0, sizeof(runtime_topdown_total_slots));\r\nmemset(runtime_topdown_slots_retired, 0, sizeof(runtime_topdown_slots_retired));\r\nmemset(runtime_topdown_slots_issued, 0, sizeof(runtime_topdown_slots_issued));\r\nmemset(runtime_topdown_fetch_bubbles, 0, sizeof(runtime_topdown_fetch_bubbles));\r\nmemset(runtime_topdown_recovery_bubbles, 0, sizeof(runtime_topdown_recovery_bubbles));\r\n}\r\nvoid perf_stat__update_shadow_stats(struct perf_evsel *counter, u64 *count,\r\nint cpu)\r\n{\r\nint ctx = evsel_context(counter);\r\nif (perf_evsel__match(counter, SOFTWARE, SW_TASK_CLOCK) ||\r\nperf_evsel__match(counter, SOFTWARE, SW_CPU_CLOCK))\r\nupdate_stats(&runtime_nsecs_stats[cpu], count[0]);\r\nelse if (perf_evsel__match(counter, HARDWARE, HW_CPU_CYCLES))\r\nupdate_stats(&runtime_cycles_stats[ctx][cpu], count[0]);\r\nelse if (perf_stat_evsel__is(counter, CYCLES_IN_TX))\r\nupdate_stats(&runtime_cycles_in_tx_stats[ctx][cpu], count[0]);\r\nelse if (perf_stat_evsel__is(counter, TRANSACTION_START))\r\nupdate_stats(&runtime_transaction_stats[ctx][cpu], count[0]);\r\nelse if (perf_stat_evsel__is(counter, ELISION_START))\r\nupdate_stats(&runtime_elision_stats[ctx][cpu], count[0]);\r\nelse if (perf_stat_evsel__is(counter, TOPDOWN_TOTAL_SLOTS))\r\nupdate_stats(&runtime_topdown_total_slots[ctx][cpu], count[0]);\r\nelse if (perf_stat_evsel__is(counter, TOPDOWN_SLOTS_ISSUED))\r\nupdate_stats(&runtime_topdown_slots_issued[ctx][cpu], count[0]);\r\nelse if (perf_stat_evsel__is(counter, TOPDOWN_SLOTS_RETIRED))\r\nupdate_stats(&runtime_topdown_slots_retired[ctx][cpu], count[0]);\r\nelse if (perf_stat_evsel__is(counter, TOPDOWN_FETCH_BUBBLES))\r\nupdate_stats(&runtime_topdown_fetch_bubbles[ctx][cpu],count[0]);\r\nelse if (perf_stat_evsel__is(counter, TOPDOWN_RECOVERY_BUBBLES))\r\nupdate_stats(&runtime_topdown_recovery_bubbles[ctx][cpu], count[0]);\r\nelse if (perf_evsel__match(counter, HARDWARE, HW_STALLED_CYCLES_FRONTEND))\r\nupdate_stats(&runtime_stalled_cycles_front_stats[ctx][cpu], count[0]);\r\nelse if (perf_evsel__match(counter, HARDWARE, HW_STALLED_CYCLES_BACKEND))\r\nupdate_stats(&runtime_stalled_cycles_back_stats[ctx][cpu], count[0]);\r\nelse if (perf_evsel__match(counter, HARDWARE, HW_BRANCH_INSTRUCTIONS))\r\nupdate_stats(&runtime_branches_stats[ctx][cpu], count[0]);\r\nelse if (perf_evsel__match(counter, HARDWARE, HW_CACHE_REFERENCES))\r\nupdate_stats(&runtime_cacherefs_stats[ctx][cpu], count[0]);\r\nelse if (perf_evsel__match(counter, HW_CACHE, HW_CACHE_L1D))\r\nupdate_stats(&runtime_l1_dcache_stats[ctx][cpu], count[0]);\r\nelse if (perf_evsel__match(counter, HW_CACHE, HW_CACHE_L1I))\r\nupdate_stats(&runtime_ll_cache_stats[ctx][cpu], count[0]);\r\nelse if (perf_evsel__match(counter, HW_CACHE, HW_CACHE_LL))\r\nupdate_stats(&runtime_ll_cache_stats[ctx][cpu], count[0]);\r\nelse if (perf_evsel__match(counter, HW_CACHE, HW_CACHE_DTLB))\r\nupdate_stats(&runtime_dtlb_cache_stats[ctx][cpu], count[0]);\r\nelse if (perf_evsel__match(counter, HW_CACHE, HW_CACHE_ITLB))\r\nupdate_stats(&runtime_itlb_cache_stats[ctx][cpu], count[0]);\r\n}\r\nstatic const char *get_ratio_color(enum grc_type type, double ratio)\r\n{\r\nstatic const double grc_table[GRC_MAX_NR][3] = {\r\n[GRC_STALLED_CYCLES_FE] = { 50.0, 30.0, 10.0 },\r\n[GRC_STALLED_CYCLES_BE] = { 75.0, 50.0, 20.0 },\r\n[GRC_CACHE_MISSES] = { 20.0, 10.0, 5.0 },\r\n};\r\nconst char *color = PERF_COLOR_NORMAL;\r\nif (ratio > grc_table[type][0])\r\ncolor = PERF_COLOR_RED;\r\nelse if (ratio > grc_table[type][1])\r\ncolor = PERF_COLOR_MAGENTA;\r\nelse if (ratio > grc_table[type][2])\r\ncolor = PERF_COLOR_YELLOW;\r\nreturn color;\r\n}\r\nstatic void print_stalled_cycles_frontend(int cpu,\r\nstruct perf_evsel *evsel, double avg,\r\nstruct perf_stat_output_ctx *out)\r\n{\r\ndouble total, ratio = 0.0;\r\nconst char *color;\r\nint ctx = evsel_context(evsel);\r\ntotal = avg_stats(&runtime_cycles_stats[ctx][cpu]);\r\nif (total)\r\nratio = avg / total * 100.0;\r\ncolor = get_ratio_color(GRC_STALLED_CYCLES_FE, ratio);\r\nif (ratio)\r\nout->print_metric(out->ctx, color, "%7.2f%%", "frontend cycles idle",\r\nratio);\r\nelse\r\nout->print_metric(out->ctx, NULL, NULL, "frontend cycles idle", 0);\r\n}\r\nstatic void print_stalled_cycles_backend(int cpu,\r\nstruct perf_evsel *evsel, double avg,\r\nstruct perf_stat_output_ctx *out)\r\n{\r\ndouble total, ratio = 0.0;\r\nconst char *color;\r\nint ctx = evsel_context(evsel);\r\ntotal = avg_stats(&runtime_cycles_stats[ctx][cpu]);\r\nif (total)\r\nratio = avg / total * 100.0;\r\ncolor = get_ratio_color(GRC_STALLED_CYCLES_BE, ratio);\r\nout->print_metric(out->ctx, color, "%7.2f%%", "backend cycles idle", ratio);\r\n}\r\nstatic void print_branch_misses(int cpu,\r\nstruct perf_evsel *evsel,\r\ndouble avg,\r\nstruct perf_stat_output_ctx *out)\r\n{\r\ndouble total, ratio = 0.0;\r\nconst char *color;\r\nint ctx = evsel_context(evsel);\r\ntotal = avg_stats(&runtime_branches_stats[ctx][cpu]);\r\nif (total)\r\nratio = avg / total * 100.0;\r\ncolor = get_ratio_color(GRC_CACHE_MISSES, ratio);\r\nout->print_metric(out->ctx, color, "%7.2f%%", "of all branches", ratio);\r\n}\r\nstatic void print_l1_dcache_misses(int cpu,\r\nstruct perf_evsel *evsel,\r\ndouble avg,\r\nstruct perf_stat_output_ctx *out)\r\n{\r\ndouble total, ratio = 0.0;\r\nconst char *color;\r\nint ctx = evsel_context(evsel);\r\ntotal = avg_stats(&runtime_l1_dcache_stats[ctx][cpu]);\r\nif (total)\r\nratio = avg / total * 100.0;\r\ncolor = get_ratio_color(GRC_CACHE_MISSES, ratio);\r\nout->print_metric(out->ctx, color, "%7.2f%%", "of all L1-dcache hits", ratio);\r\n}\r\nstatic void print_l1_icache_misses(int cpu,\r\nstruct perf_evsel *evsel,\r\ndouble avg,\r\nstruct perf_stat_output_ctx *out)\r\n{\r\ndouble total, ratio = 0.0;\r\nconst char *color;\r\nint ctx = evsel_context(evsel);\r\ntotal = avg_stats(&runtime_l1_icache_stats[ctx][cpu]);\r\nif (total)\r\nratio = avg / total * 100.0;\r\ncolor = get_ratio_color(GRC_CACHE_MISSES, ratio);\r\nout->print_metric(out->ctx, color, "%7.2f%%", "of all L1-icache hits", ratio);\r\n}\r\nstatic void print_dtlb_cache_misses(int cpu,\r\nstruct perf_evsel *evsel,\r\ndouble avg,\r\nstruct perf_stat_output_ctx *out)\r\n{\r\ndouble total, ratio = 0.0;\r\nconst char *color;\r\nint ctx = evsel_context(evsel);\r\ntotal = avg_stats(&runtime_dtlb_cache_stats[ctx][cpu]);\r\nif (total)\r\nratio = avg / total * 100.0;\r\ncolor = get_ratio_color(GRC_CACHE_MISSES, ratio);\r\nout->print_metric(out->ctx, color, "%7.2f%%", "of all dTLB cache hits", ratio);\r\n}\r\nstatic void print_itlb_cache_misses(int cpu,\r\nstruct perf_evsel *evsel,\r\ndouble avg,\r\nstruct perf_stat_output_ctx *out)\r\n{\r\ndouble total, ratio = 0.0;\r\nconst char *color;\r\nint ctx = evsel_context(evsel);\r\ntotal = avg_stats(&runtime_itlb_cache_stats[ctx][cpu]);\r\nif (total)\r\nratio = avg / total * 100.0;\r\ncolor = get_ratio_color(GRC_CACHE_MISSES, ratio);\r\nout->print_metric(out->ctx, color, "%7.2f%%", "of all iTLB cache hits", ratio);\r\n}\r\nstatic void print_ll_cache_misses(int cpu,\r\nstruct perf_evsel *evsel,\r\ndouble avg,\r\nstruct perf_stat_output_ctx *out)\r\n{\r\ndouble total, ratio = 0.0;\r\nconst char *color;\r\nint ctx = evsel_context(evsel);\r\ntotal = avg_stats(&runtime_ll_cache_stats[ctx][cpu]);\r\nif (total)\r\nratio = avg / total * 100.0;\r\ncolor = get_ratio_color(GRC_CACHE_MISSES, ratio);\r\nout->print_metric(out->ctx, color, "%7.2f%%", "of all LL-cache hits", ratio);\r\n}\r\nstatic double sanitize_val(double x)\r\n{\r\nif (x < 0 && x >= -0.02)\r\nreturn 0.0;\r\nreturn x;\r\n}\r\nstatic double td_total_slots(int ctx, int cpu)\r\n{\r\nreturn avg_stats(&runtime_topdown_total_slots[ctx][cpu]);\r\n}\r\nstatic double td_bad_spec(int ctx, int cpu)\r\n{\r\ndouble bad_spec = 0;\r\ndouble total_slots;\r\ndouble total;\r\ntotal = avg_stats(&runtime_topdown_slots_issued[ctx][cpu]) -\r\navg_stats(&runtime_topdown_slots_retired[ctx][cpu]) +\r\navg_stats(&runtime_topdown_recovery_bubbles[ctx][cpu]);\r\ntotal_slots = td_total_slots(ctx, cpu);\r\nif (total_slots)\r\nbad_spec = total / total_slots;\r\nreturn sanitize_val(bad_spec);\r\n}\r\nstatic double td_retiring(int ctx, int cpu)\r\n{\r\ndouble retiring = 0;\r\ndouble total_slots = td_total_slots(ctx, cpu);\r\ndouble ret_slots = avg_stats(&runtime_topdown_slots_retired[ctx][cpu]);\r\nif (total_slots)\r\nretiring = ret_slots / total_slots;\r\nreturn retiring;\r\n}\r\nstatic double td_fe_bound(int ctx, int cpu)\r\n{\r\ndouble fe_bound = 0;\r\ndouble total_slots = td_total_slots(ctx, cpu);\r\ndouble fetch_bub = avg_stats(&runtime_topdown_fetch_bubbles[ctx][cpu]);\r\nif (total_slots)\r\nfe_bound = fetch_bub / total_slots;\r\nreturn fe_bound;\r\n}\r\nstatic double td_be_bound(int ctx, int cpu)\r\n{\r\ndouble sum = (td_fe_bound(ctx, cpu) +\r\ntd_bad_spec(ctx, cpu) +\r\ntd_retiring(ctx, cpu));\r\nif (sum == 0)\r\nreturn 0;\r\nreturn sanitize_val(1.0 - sum);\r\n}\r\nvoid perf_stat__print_shadow_stats(struct perf_evsel *evsel,\r\ndouble avg, int cpu,\r\nstruct perf_stat_output_ctx *out)\r\n{\r\nvoid *ctxp = out->ctx;\r\nprint_metric_t print_metric = out->print_metric;\r\ndouble total, ratio = 0.0, total2;\r\nconst char *color = NULL;\r\nint ctx = evsel_context(evsel);\r\nif (perf_evsel__match(evsel, HARDWARE, HW_INSTRUCTIONS)) {\r\ntotal = avg_stats(&runtime_cycles_stats[ctx][cpu]);\r\nif (total) {\r\nratio = avg / total;\r\nprint_metric(ctxp, NULL, "%7.2f ",\r\n"insn per cycle", ratio);\r\n} else {\r\nprint_metric(ctxp, NULL, NULL, "insn per cycle", 0);\r\n}\r\ntotal = avg_stats(&runtime_stalled_cycles_front_stats[ctx][cpu]);\r\ntotal = max(total, avg_stats(&runtime_stalled_cycles_back_stats[ctx][cpu]));\r\nif (total && avg) {\r\nout->new_line(ctxp);\r\nratio = total / avg;\r\nprint_metric(ctxp, NULL, "%7.2f ",\r\n"stalled cycles per insn",\r\nratio);\r\n} else if (have_frontend_stalled) {\r\nprint_metric(ctxp, NULL, NULL,\r\n"stalled cycles per insn", 0);\r\n}\r\n} else if (perf_evsel__match(evsel, HARDWARE, HW_BRANCH_MISSES)) {\r\nif (runtime_branches_stats[ctx][cpu].n != 0)\r\nprint_branch_misses(cpu, evsel, avg, out);\r\nelse\r\nprint_metric(ctxp, NULL, NULL, "of all branches", 0);\r\n} else if (\r\nevsel->attr.type == PERF_TYPE_HW_CACHE &&\r\nevsel->attr.config == ( PERF_COUNT_HW_CACHE_L1D |\r\n((PERF_COUNT_HW_CACHE_OP_READ) << 8) |\r\n((PERF_COUNT_HW_CACHE_RESULT_MISS) << 16))) {\r\nif (runtime_l1_dcache_stats[ctx][cpu].n != 0)\r\nprint_l1_dcache_misses(cpu, evsel, avg, out);\r\nelse\r\nprint_metric(ctxp, NULL, NULL, "of all L1-dcache hits", 0);\r\n} else if (\r\nevsel->attr.type == PERF_TYPE_HW_CACHE &&\r\nevsel->attr.config == ( PERF_COUNT_HW_CACHE_L1I |\r\n((PERF_COUNT_HW_CACHE_OP_READ) << 8) |\r\n((PERF_COUNT_HW_CACHE_RESULT_MISS) << 16))) {\r\nif (runtime_l1_icache_stats[ctx][cpu].n != 0)\r\nprint_l1_icache_misses(cpu, evsel, avg, out);\r\nelse\r\nprint_metric(ctxp, NULL, NULL, "of all L1-icache hits", 0);\r\n} else if (\r\nevsel->attr.type == PERF_TYPE_HW_CACHE &&\r\nevsel->attr.config == ( PERF_COUNT_HW_CACHE_DTLB |\r\n((PERF_COUNT_HW_CACHE_OP_READ) << 8) |\r\n((PERF_COUNT_HW_CACHE_RESULT_MISS) << 16))) {\r\nif (runtime_dtlb_cache_stats[ctx][cpu].n != 0)\r\nprint_dtlb_cache_misses(cpu, evsel, avg, out);\r\nelse\r\nprint_metric(ctxp, NULL, NULL, "of all dTLB cache hits", 0);\r\n} else if (\r\nevsel->attr.type == PERF_TYPE_HW_CACHE &&\r\nevsel->attr.config == ( PERF_COUNT_HW_CACHE_ITLB |\r\n((PERF_COUNT_HW_CACHE_OP_READ) << 8) |\r\n((PERF_COUNT_HW_CACHE_RESULT_MISS) << 16))) {\r\nif (runtime_itlb_cache_stats[ctx][cpu].n != 0)\r\nprint_itlb_cache_misses(cpu, evsel, avg, out);\r\nelse\r\nprint_metric(ctxp, NULL, NULL, "of all iTLB cache hits", 0);\r\n} else if (\r\nevsel->attr.type == PERF_TYPE_HW_CACHE &&\r\nevsel->attr.config == ( PERF_COUNT_HW_CACHE_LL |\r\n((PERF_COUNT_HW_CACHE_OP_READ) << 8) |\r\n((PERF_COUNT_HW_CACHE_RESULT_MISS) << 16))) {\r\nif (runtime_ll_cache_stats[ctx][cpu].n != 0)\r\nprint_ll_cache_misses(cpu, evsel, avg, out);\r\nelse\r\nprint_metric(ctxp, NULL, NULL, "of all LL-cache hits", 0);\r\n} else if (perf_evsel__match(evsel, HARDWARE, HW_CACHE_MISSES)) {\r\ntotal = avg_stats(&runtime_cacherefs_stats[ctx][cpu]);\r\nif (total)\r\nratio = avg * 100 / total;\r\nif (runtime_cacherefs_stats[ctx][cpu].n != 0)\r\nprint_metric(ctxp, NULL, "%8.3f %%",\r\n"of all cache refs", ratio);\r\nelse\r\nprint_metric(ctxp, NULL, NULL, "of all cache refs", 0);\r\n} else if (perf_evsel__match(evsel, HARDWARE, HW_STALLED_CYCLES_FRONTEND)) {\r\nprint_stalled_cycles_frontend(cpu, evsel, avg, out);\r\n} else if (perf_evsel__match(evsel, HARDWARE, HW_STALLED_CYCLES_BACKEND)) {\r\nprint_stalled_cycles_backend(cpu, evsel, avg, out);\r\n} else if (perf_evsel__match(evsel, HARDWARE, HW_CPU_CYCLES)) {\r\ntotal = avg_stats(&runtime_nsecs_stats[cpu]);\r\nif (total) {\r\nratio = avg / total;\r\nprint_metric(ctxp, NULL, "%8.3f", "GHz", ratio);\r\n} else {\r\nprint_metric(ctxp, NULL, NULL, "Ghz", 0);\r\n}\r\n} else if (perf_stat_evsel__is(evsel, CYCLES_IN_TX)) {\r\ntotal = avg_stats(&runtime_cycles_stats[ctx][cpu]);\r\nif (total)\r\nprint_metric(ctxp, NULL,\r\n"%7.2f%%", "transactional cycles",\r\n100.0 * (avg / total));\r\nelse\r\nprint_metric(ctxp, NULL, NULL, "transactional cycles",\r\n0);\r\n} else if (perf_stat_evsel__is(evsel, CYCLES_IN_TX_CP)) {\r\ntotal = avg_stats(&runtime_cycles_stats[ctx][cpu]);\r\ntotal2 = avg_stats(&runtime_cycles_in_tx_stats[ctx][cpu]);\r\nif (total2 < avg)\r\ntotal2 = avg;\r\nif (total)\r\nprint_metric(ctxp, NULL, "%7.2f%%", "aborted cycles",\r\n100.0 * ((total2-avg) / total));\r\nelse\r\nprint_metric(ctxp, NULL, NULL, "aborted cycles", 0);\r\n} else if (perf_stat_evsel__is(evsel, TRANSACTION_START)) {\r\ntotal = avg_stats(&runtime_cycles_in_tx_stats[ctx][cpu]);\r\nif (avg)\r\nratio = total / avg;\r\nif (runtime_cycles_in_tx_stats[ctx][cpu].n != 0)\r\nprint_metric(ctxp, NULL, "%8.0f",\r\n"cycles / transaction", ratio);\r\nelse\r\nprint_metric(ctxp, NULL, NULL, "cycles / transaction",\r\n0);\r\n} else if (perf_stat_evsel__is(evsel, ELISION_START)) {\r\ntotal = avg_stats(&runtime_cycles_in_tx_stats[ctx][cpu]);\r\nif (avg)\r\nratio = total / avg;\r\nprint_metric(ctxp, NULL, "%8.0f", "cycles / elision", ratio);\r\n} else if (perf_evsel__match(evsel, SOFTWARE, SW_TASK_CLOCK) ||\r\nperf_evsel__match(evsel, SOFTWARE, SW_CPU_CLOCK)) {\r\nif ((ratio = avg_stats(&walltime_nsecs_stats)) != 0)\r\nprint_metric(ctxp, NULL, "%8.3f", "CPUs utilized",\r\navg / ratio);\r\nelse\r\nprint_metric(ctxp, NULL, NULL, "CPUs utilized", 0);\r\n} else if (perf_stat_evsel__is(evsel, TOPDOWN_FETCH_BUBBLES)) {\r\ndouble fe_bound = td_fe_bound(ctx, cpu);\r\nif (fe_bound > 0.2)\r\ncolor = PERF_COLOR_RED;\r\nprint_metric(ctxp, color, "%8.1f%%", "frontend bound",\r\nfe_bound * 100.);\r\n} else if (perf_stat_evsel__is(evsel, TOPDOWN_SLOTS_RETIRED)) {\r\ndouble retiring = td_retiring(ctx, cpu);\r\nif (retiring > 0.7)\r\ncolor = PERF_COLOR_GREEN;\r\nprint_metric(ctxp, color, "%8.1f%%", "retiring",\r\nretiring * 100.);\r\n} else if (perf_stat_evsel__is(evsel, TOPDOWN_RECOVERY_BUBBLES)) {\r\ndouble bad_spec = td_bad_spec(ctx, cpu);\r\nif (bad_spec > 0.1)\r\ncolor = PERF_COLOR_RED;\r\nprint_metric(ctxp, color, "%8.1f%%", "bad speculation",\r\nbad_spec * 100.);\r\n} else if (perf_stat_evsel__is(evsel, TOPDOWN_SLOTS_ISSUED)) {\r\ndouble be_bound = td_be_bound(ctx, cpu);\r\nconst char *name = "backend bound";\r\nstatic int have_recovery_bubbles = -1;\r\nif (have_recovery_bubbles < 0)\r\nhave_recovery_bubbles = pmu_have_event("cpu",\r\n"topdown-recovery-bubbles");\r\nif (!have_recovery_bubbles)\r\nname = "backend bound/bad spec";\r\nif (be_bound > 0.2)\r\ncolor = PERF_COLOR_RED;\r\nif (td_total_slots(ctx, cpu) > 0)\r\nprint_metric(ctxp, color, "%8.1f%%", name,\r\nbe_bound * 100.);\r\nelse\r\nprint_metric(ctxp, NULL, NULL, name, 0);\r\n} else if (runtime_nsecs_stats[cpu].n != 0) {\r\nchar unit = 'M';\r\nchar unit_buf[10];\r\ntotal = avg_stats(&runtime_nsecs_stats[cpu]);\r\nif (total)\r\nratio = 1000.0 * avg / total;\r\nif (ratio < 0.001) {\r\nratio *= 1000;\r\nunit = 'K';\r\n}\r\nsnprintf(unit_buf, sizeof(unit_buf), "%c/sec", unit);\r\nprint_metric(ctxp, NULL, "%8.3f", unit_buf, ratio);\r\n} else {\r\nprint_metric(ctxp, NULL, NULL, NULL, 0);\r\n}\r\n}
