static u32 sh_msiof_read(struct sh_msiof_spi_priv *p, int reg_offs)\r\n{\r\nswitch (reg_offs) {\r\ncase TSCR:\r\ncase RSCR:\r\nreturn ioread16(p->mapbase + reg_offs);\r\ndefault:\r\nreturn ioread32(p->mapbase + reg_offs);\r\n}\r\n}\r\nstatic void sh_msiof_write(struct sh_msiof_spi_priv *p, int reg_offs,\r\nu32 value)\r\n{\r\nswitch (reg_offs) {\r\ncase TSCR:\r\ncase RSCR:\r\niowrite16(value, p->mapbase + reg_offs);\r\nbreak;\r\ndefault:\r\niowrite32(value, p->mapbase + reg_offs);\r\nbreak;\r\n}\r\n}\r\nstatic int sh_msiof_modify_ctr_wait(struct sh_msiof_spi_priv *p,\r\nu32 clr, u32 set)\r\n{\r\nu32 mask = clr | set;\r\nu32 data;\r\nint k;\r\ndata = sh_msiof_read(p, CTR);\r\ndata &= ~clr;\r\ndata |= set;\r\nsh_msiof_write(p, CTR, data);\r\nfor (k = 100; k > 0; k--) {\r\nif ((sh_msiof_read(p, CTR) & mask) == set)\r\nbreak;\r\nudelay(10);\r\n}\r\nreturn k > 0 ? 0 : -ETIMEDOUT;\r\n}\r\nstatic irqreturn_t sh_msiof_spi_irq(int irq, void *data)\r\n{\r\nstruct sh_msiof_spi_priv *p = data;\r\nsh_msiof_write(p, IER, 0);\r\ncomplete(&p->done);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void sh_msiof_spi_set_clk_regs(struct sh_msiof_spi_priv *p,\r\nunsigned long parent_rate, u32 spi_hz)\r\n{\r\nunsigned long div = 1024;\r\nu32 brps, scr;\r\nsize_t k;\r\nif (!WARN_ON(!spi_hz || !parent_rate))\r\ndiv = DIV_ROUND_UP(parent_rate, spi_hz);\r\nfor (k = 0; k < ARRAY_SIZE(sh_msiof_spi_div_table); k++) {\r\nbrps = DIV_ROUND_UP(div, sh_msiof_spi_div_table[k].div);\r\nif (sh_msiof_spi_div_table[k].div == 1 && brps > 2)\r\ncontinue;\r\nif (brps <= 32)\r\nbreak;\r\n}\r\nk = min_t(int, k, ARRAY_SIZE(sh_msiof_spi_div_table) - 1);\r\nscr = sh_msiof_spi_div_table[k].brdv | SCR_BRPS(brps);\r\nsh_msiof_write(p, TSCR, scr);\r\nif (!(p->master->flags & SPI_MASTER_MUST_TX))\r\nsh_msiof_write(p, RSCR, scr);\r\n}\r\nstatic u32 sh_msiof_get_delay_bit(u32 dtdl_or_syncdl)\r\n{\r\nif (dtdl_or_syncdl % 100)\r\nreturn dtdl_or_syncdl / 100 + 5;\r\nelse\r\nreturn dtdl_or_syncdl / 100;\r\n}\r\nstatic u32 sh_msiof_spi_get_dtdl_and_syncdl(struct sh_msiof_spi_priv *p)\r\n{\r\nu32 val;\r\nif (!p->info)\r\nreturn 0;\r\nif (p->info->dtdl > 200 || p->info->syncdl > 300) {\r\ndev_warn(&p->pdev->dev, "DTDL or SYNCDL is too large\n");\r\nreturn 0;\r\n}\r\nif ((p->info->dtdl + p->info->syncdl) % 100) {\r\ndev_warn(&p->pdev->dev, "the sum of DTDL/SYNCDL is not good\n");\r\nreturn 0;\r\n}\r\nval = sh_msiof_get_delay_bit(p->info->dtdl) << MDR1_DTDL_SHIFT;\r\nval |= sh_msiof_get_delay_bit(p->info->syncdl) << MDR1_SYNCDL_SHIFT;\r\nreturn val;\r\n}\r\nstatic void sh_msiof_spi_set_pin_regs(struct sh_msiof_spi_priv *p,\r\nu32 cpol, u32 cpha,\r\nu32 tx_hi_z, u32 lsb_first, u32 cs_high)\r\n{\r\nu32 tmp;\r\nint edge;\r\ntmp = MDR1_SYNCMD_SPI | 1 << MDR1_FLD_SHIFT | MDR1_XXSTP;\r\ntmp |= !cs_high << MDR1_SYNCAC_SHIFT;\r\ntmp |= lsb_first << MDR1_BITLSB_SHIFT;\r\ntmp |= sh_msiof_spi_get_dtdl_and_syncdl(p);\r\nsh_msiof_write(p, TMDR1, tmp | MDR1_TRMD | TMDR1_PCON);\r\nif (p->master->flags & SPI_MASTER_MUST_TX) {\r\ntmp &= ~0x0000ffff;\r\n}\r\nsh_msiof_write(p, RMDR1, tmp);\r\ntmp = 0;\r\ntmp |= CTR_TSCKIZ_SCK | cpol << CTR_TSCKIZ_POL_SHIFT;\r\ntmp |= CTR_RSCKIZ_SCK | cpol << CTR_RSCKIZ_POL_SHIFT;\r\nedge = cpol ^ !cpha;\r\ntmp |= edge << CTR_TEDG_SHIFT;\r\ntmp |= edge << CTR_REDG_SHIFT;\r\ntmp |= tx_hi_z ? CTR_TXDIZ_HIZ : CTR_TXDIZ_LOW;\r\nsh_msiof_write(p, CTR, tmp);\r\n}\r\nstatic void sh_msiof_spi_set_mode_regs(struct sh_msiof_spi_priv *p,\r\nconst void *tx_buf, void *rx_buf,\r\nu32 bits, u32 words)\r\n{\r\nu32 dr2 = MDR2_BITLEN1(bits) | MDR2_WDLEN1(words);\r\nif (tx_buf || (p->master->flags & SPI_MASTER_MUST_TX))\r\nsh_msiof_write(p, TMDR2, dr2);\r\nelse\r\nsh_msiof_write(p, TMDR2, dr2 | MDR2_GRPMASK1);\r\nif (rx_buf)\r\nsh_msiof_write(p, RMDR2, dr2);\r\n}\r\nstatic void sh_msiof_reset_str(struct sh_msiof_spi_priv *p)\r\n{\r\nsh_msiof_write(p, STR, sh_msiof_read(p, STR));\r\n}\r\nstatic void sh_msiof_spi_write_fifo_8(struct sh_msiof_spi_priv *p,\r\nconst void *tx_buf, int words, int fs)\r\n{\r\nconst u8 *buf_8 = tx_buf;\r\nint k;\r\nfor (k = 0; k < words; k++)\r\nsh_msiof_write(p, TFDR, buf_8[k] << fs);\r\n}\r\nstatic void sh_msiof_spi_write_fifo_16(struct sh_msiof_spi_priv *p,\r\nconst void *tx_buf, int words, int fs)\r\n{\r\nconst u16 *buf_16 = tx_buf;\r\nint k;\r\nfor (k = 0; k < words; k++)\r\nsh_msiof_write(p, TFDR, buf_16[k] << fs);\r\n}\r\nstatic void sh_msiof_spi_write_fifo_16u(struct sh_msiof_spi_priv *p,\r\nconst void *tx_buf, int words, int fs)\r\n{\r\nconst u16 *buf_16 = tx_buf;\r\nint k;\r\nfor (k = 0; k < words; k++)\r\nsh_msiof_write(p, TFDR, get_unaligned(&buf_16[k]) << fs);\r\n}\r\nstatic void sh_msiof_spi_write_fifo_32(struct sh_msiof_spi_priv *p,\r\nconst void *tx_buf, int words, int fs)\r\n{\r\nconst u32 *buf_32 = tx_buf;\r\nint k;\r\nfor (k = 0; k < words; k++)\r\nsh_msiof_write(p, TFDR, buf_32[k] << fs);\r\n}\r\nstatic void sh_msiof_spi_write_fifo_32u(struct sh_msiof_spi_priv *p,\r\nconst void *tx_buf, int words, int fs)\r\n{\r\nconst u32 *buf_32 = tx_buf;\r\nint k;\r\nfor (k = 0; k < words; k++)\r\nsh_msiof_write(p, TFDR, get_unaligned(&buf_32[k]) << fs);\r\n}\r\nstatic void sh_msiof_spi_write_fifo_s32(struct sh_msiof_spi_priv *p,\r\nconst void *tx_buf, int words, int fs)\r\n{\r\nconst u32 *buf_32 = tx_buf;\r\nint k;\r\nfor (k = 0; k < words; k++)\r\nsh_msiof_write(p, TFDR, swab32(buf_32[k] << fs));\r\n}\r\nstatic void sh_msiof_spi_write_fifo_s32u(struct sh_msiof_spi_priv *p,\r\nconst void *tx_buf, int words, int fs)\r\n{\r\nconst u32 *buf_32 = tx_buf;\r\nint k;\r\nfor (k = 0; k < words; k++)\r\nsh_msiof_write(p, TFDR, swab32(get_unaligned(&buf_32[k]) << fs));\r\n}\r\nstatic void sh_msiof_spi_read_fifo_8(struct sh_msiof_spi_priv *p,\r\nvoid *rx_buf, int words, int fs)\r\n{\r\nu8 *buf_8 = rx_buf;\r\nint k;\r\nfor (k = 0; k < words; k++)\r\nbuf_8[k] = sh_msiof_read(p, RFDR) >> fs;\r\n}\r\nstatic void sh_msiof_spi_read_fifo_16(struct sh_msiof_spi_priv *p,\r\nvoid *rx_buf, int words, int fs)\r\n{\r\nu16 *buf_16 = rx_buf;\r\nint k;\r\nfor (k = 0; k < words; k++)\r\nbuf_16[k] = sh_msiof_read(p, RFDR) >> fs;\r\n}\r\nstatic void sh_msiof_spi_read_fifo_16u(struct sh_msiof_spi_priv *p,\r\nvoid *rx_buf, int words, int fs)\r\n{\r\nu16 *buf_16 = rx_buf;\r\nint k;\r\nfor (k = 0; k < words; k++)\r\nput_unaligned(sh_msiof_read(p, RFDR) >> fs, &buf_16[k]);\r\n}\r\nstatic void sh_msiof_spi_read_fifo_32(struct sh_msiof_spi_priv *p,\r\nvoid *rx_buf, int words, int fs)\r\n{\r\nu32 *buf_32 = rx_buf;\r\nint k;\r\nfor (k = 0; k < words; k++)\r\nbuf_32[k] = sh_msiof_read(p, RFDR) >> fs;\r\n}\r\nstatic void sh_msiof_spi_read_fifo_32u(struct sh_msiof_spi_priv *p,\r\nvoid *rx_buf, int words, int fs)\r\n{\r\nu32 *buf_32 = rx_buf;\r\nint k;\r\nfor (k = 0; k < words; k++)\r\nput_unaligned(sh_msiof_read(p, RFDR) >> fs, &buf_32[k]);\r\n}\r\nstatic void sh_msiof_spi_read_fifo_s32(struct sh_msiof_spi_priv *p,\r\nvoid *rx_buf, int words, int fs)\r\n{\r\nu32 *buf_32 = rx_buf;\r\nint k;\r\nfor (k = 0; k < words; k++)\r\nbuf_32[k] = swab32(sh_msiof_read(p, RFDR) >> fs);\r\n}\r\nstatic void sh_msiof_spi_read_fifo_s32u(struct sh_msiof_spi_priv *p,\r\nvoid *rx_buf, int words, int fs)\r\n{\r\nu32 *buf_32 = rx_buf;\r\nint k;\r\nfor (k = 0; k < words; k++)\r\nput_unaligned(swab32(sh_msiof_read(p, RFDR) >> fs), &buf_32[k]);\r\n}\r\nstatic int sh_msiof_spi_setup(struct spi_device *spi)\r\n{\r\nstruct device_node *np = spi->master->dev.of_node;\r\nstruct sh_msiof_spi_priv *p = spi_master_get_devdata(spi->master);\r\npm_runtime_get_sync(&p->pdev->dev);\r\nif (!np) {\r\nspi->cs_gpio = (uintptr_t)spi->controller_data;\r\n}\r\nsh_msiof_spi_set_pin_regs(p, !!(spi->mode & SPI_CPOL),\r\n!!(spi->mode & SPI_CPHA),\r\n!!(spi->mode & SPI_3WIRE),\r\n!!(spi->mode & SPI_LSB_FIRST),\r\n!!(spi->mode & SPI_CS_HIGH));\r\nif (spi->cs_gpio >= 0)\r\ngpio_set_value(spi->cs_gpio, !(spi->mode & SPI_CS_HIGH));\r\npm_runtime_put(&p->pdev->dev);\r\nreturn 0;\r\n}\r\nstatic int sh_msiof_prepare_message(struct spi_master *master,\r\nstruct spi_message *msg)\r\n{\r\nstruct sh_msiof_spi_priv *p = spi_master_get_devdata(master);\r\nconst struct spi_device *spi = msg->spi;\r\nsh_msiof_spi_set_pin_regs(p, !!(spi->mode & SPI_CPOL),\r\n!!(spi->mode & SPI_CPHA),\r\n!!(spi->mode & SPI_3WIRE),\r\n!!(spi->mode & SPI_LSB_FIRST),\r\n!!(spi->mode & SPI_CS_HIGH));\r\nreturn 0;\r\n}\r\nstatic int sh_msiof_spi_start(struct sh_msiof_spi_priv *p, void *rx_buf)\r\n{\r\nint ret;\r\nret = sh_msiof_modify_ctr_wait(p, 0, CTR_TSCKE);\r\nif (rx_buf && !ret)\r\nret = sh_msiof_modify_ctr_wait(p, 0, CTR_RXE);\r\nif (!ret)\r\nret = sh_msiof_modify_ctr_wait(p, 0, CTR_TXE);\r\nif (!ret)\r\nret = sh_msiof_modify_ctr_wait(p, 0, CTR_TFSE);\r\nreturn ret;\r\n}\r\nstatic int sh_msiof_spi_stop(struct sh_msiof_spi_priv *p, void *rx_buf)\r\n{\r\nint ret;\r\nret = sh_msiof_modify_ctr_wait(p, CTR_TFSE, 0);\r\nif (!ret)\r\nret = sh_msiof_modify_ctr_wait(p, CTR_TXE, 0);\r\nif (rx_buf && !ret)\r\nret = sh_msiof_modify_ctr_wait(p, CTR_RXE, 0);\r\nif (!ret)\r\nret = sh_msiof_modify_ctr_wait(p, CTR_TSCKE, 0);\r\nreturn ret;\r\n}\r\nstatic int sh_msiof_spi_txrx_once(struct sh_msiof_spi_priv *p,\r\nvoid (*tx_fifo)(struct sh_msiof_spi_priv *,\r\nconst void *, int, int),\r\nvoid (*rx_fifo)(struct sh_msiof_spi_priv *,\r\nvoid *, int, int),\r\nconst void *tx_buf, void *rx_buf,\r\nint words, int bits)\r\n{\r\nint fifo_shift;\r\nint ret;\r\nif (tx_buf)\r\nwords = min_t(int, words, p->tx_fifo_size);\r\nif (rx_buf)\r\nwords = min_t(int, words, p->rx_fifo_size);\r\nfifo_shift = 32 - bits;\r\nsh_msiof_write(p, FCTR, 0);\r\nsh_msiof_spi_set_mode_regs(p, tx_buf, rx_buf, bits, words);\r\nsh_msiof_write(p, IER, IER_TEOFE | IER_REOFE);\r\nif (tx_buf)\r\ntx_fifo(p, tx_buf, words, fifo_shift);\r\nreinit_completion(&p->done);\r\nret = sh_msiof_spi_start(p, rx_buf);\r\nif (ret) {\r\ndev_err(&p->pdev->dev, "failed to start hardware\n");\r\ngoto stop_ier;\r\n}\r\nif (!wait_for_completion_timeout(&p->done, HZ)) {\r\ndev_err(&p->pdev->dev, "PIO timeout\n");\r\nret = -ETIMEDOUT;\r\ngoto stop_reset;\r\n}\r\nif (rx_buf)\r\nrx_fifo(p, rx_buf, words, fifo_shift);\r\nsh_msiof_reset_str(p);\r\nret = sh_msiof_spi_stop(p, rx_buf);\r\nif (ret) {\r\ndev_err(&p->pdev->dev, "failed to shut down hardware\n");\r\nreturn ret;\r\n}\r\nreturn words;\r\nstop_reset:\r\nsh_msiof_reset_str(p);\r\nsh_msiof_spi_stop(p, rx_buf);\r\nstop_ier:\r\nsh_msiof_write(p, IER, 0);\r\nreturn ret;\r\n}\r\nstatic void sh_msiof_dma_complete(void *arg)\r\n{\r\nstruct sh_msiof_spi_priv *p = arg;\r\nsh_msiof_write(p, IER, 0);\r\ncomplete(&p->done);\r\n}\r\nstatic int sh_msiof_dma_once(struct sh_msiof_spi_priv *p, const void *tx,\r\nvoid *rx, unsigned int len)\r\n{\r\nu32 ier_bits = 0;\r\nstruct dma_async_tx_descriptor *desc_tx = NULL, *desc_rx = NULL;\r\ndma_cookie_t cookie;\r\nint ret;\r\nif (rx) {\r\nier_bits |= IER_RDREQE | IER_RDMAE;\r\ndesc_rx = dmaengine_prep_slave_single(p->master->dma_rx,\r\np->rx_dma_addr, len, DMA_FROM_DEVICE,\r\nDMA_PREP_INTERRUPT | DMA_CTRL_ACK);\r\nif (!desc_rx)\r\nreturn -EAGAIN;\r\ndesc_rx->callback = sh_msiof_dma_complete;\r\ndesc_rx->callback_param = p;\r\ncookie = dmaengine_submit(desc_rx);\r\nif (dma_submit_error(cookie))\r\nreturn cookie;\r\n}\r\nif (tx) {\r\nier_bits |= IER_TDREQE | IER_TDMAE;\r\ndma_sync_single_for_device(p->master->dma_tx->device->dev,\r\np->tx_dma_addr, len, DMA_TO_DEVICE);\r\ndesc_tx = dmaengine_prep_slave_single(p->master->dma_tx,\r\np->tx_dma_addr, len, DMA_TO_DEVICE,\r\nDMA_PREP_INTERRUPT | DMA_CTRL_ACK);\r\nif (!desc_tx) {\r\nret = -EAGAIN;\r\ngoto no_dma_tx;\r\n}\r\nif (rx) {\r\ndesc_tx->callback = NULL;\r\n} else {\r\ndesc_tx->callback = sh_msiof_dma_complete;\r\ndesc_tx->callback_param = p;\r\n}\r\ncookie = dmaengine_submit(desc_tx);\r\nif (dma_submit_error(cookie)) {\r\nret = cookie;\r\ngoto no_dma_tx;\r\n}\r\n}\r\nsh_msiof_write(p, FCTR, FCTR_TFWM_1 | FCTR_RFWM_1);\r\nsh_msiof_spi_set_mode_regs(p, tx, rx, 32, len / 4);\r\nsh_msiof_write(p, IER, ier_bits);\r\nreinit_completion(&p->done);\r\nif (rx)\r\ndma_async_issue_pending(p->master->dma_rx);\r\nif (tx)\r\ndma_async_issue_pending(p->master->dma_tx);\r\nret = sh_msiof_spi_start(p, rx);\r\nif (ret) {\r\ndev_err(&p->pdev->dev, "failed to start hardware\n");\r\ngoto stop_dma;\r\n}\r\nif (!wait_for_completion_timeout(&p->done, HZ)) {\r\ndev_err(&p->pdev->dev, "DMA timeout\n");\r\nret = -ETIMEDOUT;\r\ngoto stop_reset;\r\n}\r\nsh_msiof_reset_str(p);\r\nret = sh_msiof_spi_stop(p, rx);\r\nif (ret) {\r\ndev_err(&p->pdev->dev, "failed to shut down hardware\n");\r\nreturn ret;\r\n}\r\nif (rx)\r\ndma_sync_single_for_cpu(p->master->dma_rx->device->dev,\r\np->rx_dma_addr, len,\r\nDMA_FROM_DEVICE);\r\nreturn 0;\r\nstop_reset:\r\nsh_msiof_reset_str(p);\r\nsh_msiof_spi_stop(p, rx);\r\nstop_dma:\r\nif (tx)\r\ndmaengine_terminate_all(p->master->dma_tx);\r\nno_dma_tx:\r\nif (rx)\r\ndmaengine_terminate_all(p->master->dma_rx);\r\nsh_msiof_write(p, IER, 0);\r\nreturn ret;\r\n}\r\nstatic void copy_bswap32(u32 *dst, const u32 *src, unsigned int words)\r\n{\r\nif ((unsigned long)src & 3) {\r\nwhile (words--) {\r\n*dst++ = swab32(get_unaligned(src));\r\nsrc++;\r\n}\r\n} else if ((unsigned long)dst & 3) {\r\nwhile (words--) {\r\nput_unaligned(swab32(*src++), dst);\r\ndst++;\r\n}\r\n} else {\r\nwhile (words--)\r\n*dst++ = swab32(*src++);\r\n}\r\n}\r\nstatic void copy_wswap32(u32 *dst, const u32 *src, unsigned int words)\r\n{\r\nif ((unsigned long)src & 3) {\r\nwhile (words--) {\r\n*dst++ = swahw32(get_unaligned(src));\r\nsrc++;\r\n}\r\n} else if ((unsigned long)dst & 3) {\r\nwhile (words--) {\r\nput_unaligned(swahw32(*src++), dst);\r\ndst++;\r\n}\r\n} else {\r\nwhile (words--)\r\n*dst++ = swahw32(*src++);\r\n}\r\n}\r\nstatic void copy_plain32(u32 *dst, const u32 *src, unsigned int words)\r\n{\r\nmemcpy(dst, src, words * 4);\r\n}\r\nstatic int sh_msiof_transfer_one(struct spi_master *master,\r\nstruct spi_device *spi,\r\nstruct spi_transfer *t)\r\n{\r\nstruct sh_msiof_spi_priv *p = spi_master_get_devdata(master);\r\nvoid (*copy32)(u32 *, const u32 *, unsigned int);\r\nvoid (*tx_fifo)(struct sh_msiof_spi_priv *, const void *, int, int);\r\nvoid (*rx_fifo)(struct sh_msiof_spi_priv *, void *, int, int);\r\nconst void *tx_buf = t->tx_buf;\r\nvoid *rx_buf = t->rx_buf;\r\nunsigned int len = t->len;\r\nunsigned int bits = t->bits_per_word;\r\nunsigned int bytes_per_word;\r\nunsigned int words;\r\nint n;\r\nbool swab;\r\nint ret;\r\nsh_msiof_spi_set_clk_regs(p, clk_get_rate(p->clk), t->speed_hz);\r\nwhile (master->dma_tx && len > 15) {\r\nunsigned int l = 0;\r\nif (tx_buf)\r\nl = min(len, p->tx_fifo_size * 4);\r\nif (rx_buf)\r\nl = min(len, p->rx_fifo_size * 4);\r\nif (bits <= 8) {\r\nif (l & 3)\r\nbreak;\r\ncopy32 = copy_bswap32;\r\n} else if (bits <= 16) {\r\nif (l & 1)\r\nbreak;\r\ncopy32 = copy_wswap32;\r\n} else {\r\ncopy32 = copy_plain32;\r\n}\r\nif (tx_buf)\r\ncopy32(p->tx_dma_page, tx_buf, l / 4);\r\nret = sh_msiof_dma_once(p, tx_buf, rx_buf, l);\r\nif (ret == -EAGAIN) {\r\npr_warn_once("%s %s: DMA not available, falling back to PIO\n",\r\ndev_driver_string(&p->pdev->dev),\r\ndev_name(&p->pdev->dev));\r\nbreak;\r\n}\r\nif (ret)\r\nreturn ret;\r\nif (rx_buf) {\r\ncopy32(rx_buf, p->rx_dma_page, l / 4);\r\nrx_buf += l;\r\n}\r\nif (tx_buf)\r\ntx_buf += l;\r\nlen -= l;\r\nif (!len)\r\nreturn 0;\r\n}\r\nif (bits <= 8 && len > 15 && !(len & 3)) {\r\nbits = 32;\r\nswab = true;\r\n} else {\r\nswab = false;\r\n}\r\nif (bits <= 8) {\r\nbytes_per_word = 1;\r\ntx_fifo = sh_msiof_spi_write_fifo_8;\r\nrx_fifo = sh_msiof_spi_read_fifo_8;\r\n} else if (bits <= 16) {\r\nbytes_per_word = 2;\r\nif ((unsigned long)tx_buf & 0x01)\r\ntx_fifo = sh_msiof_spi_write_fifo_16u;\r\nelse\r\ntx_fifo = sh_msiof_spi_write_fifo_16;\r\nif ((unsigned long)rx_buf & 0x01)\r\nrx_fifo = sh_msiof_spi_read_fifo_16u;\r\nelse\r\nrx_fifo = sh_msiof_spi_read_fifo_16;\r\n} else if (swab) {\r\nbytes_per_word = 4;\r\nif ((unsigned long)tx_buf & 0x03)\r\ntx_fifo = sh_msiof_spi_write_fifo_s32u;\r\nelse\r\ntx_fifo = sh_msiof_spi_write_fifo_s32;\r\nif ((unsigned long)rx_buf & 0x03)\r\nrx_fifo = sh_msiof_spi_read_fifo_s32u;\r\nelse\r\nrx_fifo = sh_msiof_spi_read_fifo_s32;\r\n} else {\r\nbytes_per_word = 4;\r\nif ((unsigned long)tx_buf & 0x03)\r\ntx_fifo = sh_msiof_spi_write_fifo_32u;\r\nelse\r\ntx_fifo = sh_msiof_spi_write_fifo_32;\r\nif ((unsigned long)rx_buf & 0x03)\r\nrx_fifo = sh_msiof_spi_read_fifo_32u;\r\nelse\r\nrx_fifo = sh_msiof_spi_read_fifo_32;\r\n}\r\nwords = len / bytes_per_word;\r\nwhile (words > 0) {\r\nn = sh_msiof_spi_txrx_once(p, tx_fifo, rx_fifo, tx_buf, rx_buf,\r\nwords, bits);\r\nif (n < 0)\r\nreturn n;\r\nif (tx_buf)\r\ntx_buf += n * bytes_per_word;\r\nif (rx_buf)\r\nrx_buf += n * bytes_per_word;\r\nwords -= n;\r\n}\r\nreturn 0;\r\n}\r\nstatic struct sh_msiof_spi_info *sh_msiof_spi_parse_dt(struct device *dev)\r\n{\r\nstruct sh_msiof_spi_info *info;\r\nstruct device_node *np = dev->of_node;\r\nu32 num_cs = 1;\r\ninfo = devm_kzalloc(dev, sizeof(struct sh_msiof_spi_info), GFP_KERNEL);\r\nif (!info)\r\nreturn NULL;\r\nof_property_read_u32(np, "num-cs", &num_cs);\r\nof_property_read_u32(np, "renesas,tx-fifo-size",\r\n&info->tx_fifo_override);\r\nof_property_read_u32(np, "renesas,rx-fifo-size",\r\n&info->rx_fifo_override);\r\nof_property_read_u32(np, "renesas,dtdl", &info->dtdl);\r\nof_property_read_u32(np, "renesas,syncdl", &info->syncdl);\r\ninfo->num_chipselect = num_cs;\r\nreturn info;\r\n}\r\nstatic struct sh_msiof_spi_info *sh_msiof_spi_parse_dt(struct device *dev)\r\n{\r\nreturn NULL;\r\n}\r\nstatic struct dma_chan *sh_msiof_request_dma_chan(struct device *dev,\r\nenum dma_transfer_direction dir, unsigned int id, dma_addr_t port_addr)\r\n{\r\ndma_cap_mask_t mask;\r\nstruct dma_chan *chan;\r\nstruct dma_slave_config cfg;\r\nint ret;\r\ndma_cap_zero(mask);\r\ndma_cap_set(DMA_SLAVE, mask);\r\nchan = dma_request_slave_channel_compat(mask, shdma_chan_filter,\r\n(void *)(unsigned long)id, dev,\r\ndir == DMA_MEM_TO_DEV ? "tx" : "rx");\r\nif (!chan) {\r\ndev_warn(dev, "dma_request_slave_channel_compat failed\n");\r\nreturn NULL;\r\n}\r\nmemset(&cfg, 0, sizeof(cfg));\r\ncfg.direction = dir;\r\nif (dir == DMA_MEM_TO_DEV) {\r\ncfg.dst_addr = port_addr;\r\ncfg.dst_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;\r\n} else {\r\ncfg.src_addr = port_addr;\r\ncfg.src_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES;\r\n}\r\nret = dmaengine_slave_config(chan, &cfg);\r\nif (ret) {\r\ndev_warn(dev, "dmaengine_slave_config failed %d\n", ret);\r\ndma_release_channel(chan);\r\nreturn NULL;\r\n}\r\nreturn chan;\r\n}\r\nstatic int sh_msiof_request_dma(struct sh_msiof_spi_priv *p)\r\n{\r\nstruct platform_device *pdev = p->pdev;\r\nstruct device *dev = &pdev->dev;\r\nconst struct sh_msiof_spi_info *info = dev_get_platdata(dev);\r\nunsigned int dma_tx_id, dma_rx_id;\r\nconst struct resource *res;\r\nstruct spi_master *master;\r\nstruct device *tx_dev, *rx_dev;\r\nif (dev->of_node) {\r\ndma_tx_id = 0;\r\ndma_rx_id = 0;\r\n} else if (info && info->dma_tx_id && info->dma_rx_id) {\r\ndma_tx_id = info->dma_tx_id;\r\ndma_rx_id = info->dma_rx_id;\r\n} else {\r\nreturn 0;\r\n}\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 1);\r\nif (!res)\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nmaster = p->master;\r\nmaster->dma_tx = sh_msiof_request_dma_chan(dev, DMA_MEM_TO_DEV,\r\ndma_tx_id,\r\nres->start + TFDR);\r\nif (!master->dma_tx)\r\nreturn -ENODEV;\r\nmaster->dma_rx = sh_msiof_request_dma_chan(dev, DMA_DEV_TO_MEM,\r\ndma_rx_id,\r\nres->start + RFDR);\r\nif (!master->dma_rx)\r\ngoto free_tx_chan;\r\np->tx_dma_page = (void *)__get_free_page(GFP_KERNEL | GFP_DMA);\r\nif (!p->tx_dma_page)\r\ngoto free_rx_chan;\r\np->rx_dma_page = (void *)__get_free_page(GFP_KERNEL | GFP_DMA);\r\nif (!p->rx_dma_page)\r\ngoto free_tx_page;\r\ntx_dev = master->dma_tx->device->dev;\r\np->tx_dma_addr = dma_map_single(tx_dev, p->tx_dma_page, PAGE_SIZE,\r\nDMA_TO_DEVICE);\r\nif (dma_mapping_error(tx_dev, p->tx_dma_addr))\r\ngoto free_rx_page;\r\nrx_dev = master->dma_rx->device->dev;\r\np->rx_dma_addr = dma_map_single(rx_dev, p->rx_dma_page, PAGE_SIZE,\r\nDMA_FROM_DEVICE);\r\nif (dma_mapping_error(rx_dev, p->rx_dma_addr))\r\ngoto unmap_tx_page;\r\ndev_info(dev, "DMA available");\r\nreturn 0;\r\nunmap_tx_page:\r\ndma_unmap_single(tx_dev, p->tx_dma_addr, PAGE_SIZE, DMA_TO_DEVICE);\r\nfree_rx_page:\r\nfree_page((unsigned long)p->rx_dma_page);\r\nfree_tx_page:\r\nfree_page((unsigned long)p->tx_dma_page);\r\nfree_rx_chan:\r\ndma_release_channel(master->dma_rx);\r\nfree_tx_chan:\r\ndma_release_channel(master->dma_tx);\r\nmaster->dma_tx = NULL;\r\nreturn -ENODEV;\r\n}\r\nstatic void sh_msiof_release_dma(struct sh_msiof_spi_priv *p)\r\n{\r\nstruct spi_master *master = p->master;\r\nstruct device *dev;\r\nif (!master->dma_tx)\r\nreturn;\r\ndev = &p->pdev->dev;\r\ndma_unmap_single(master->dma_rx->device->dev, p->rx_dma_addr,\r\nPAGE_SIZE, DMA_FROM_DEVICE);\r\ndma_unmap_single(master->dma_tx->device->dev, p->tx_dma_addr,\r\nPAGE_SIZE, DMA_TO_DEVICE);\r\nfree_page((unsigned long)p->rx_dma_page);\r\nfree_page((unsigned long)p->tx_dma_page);\r\ndma_release_channel(master->dma_rx);\r\ndma_release_channel(master->dma_tx);\r\n}\r\nstatic int sh_msiof_spi_probe(struct platform_device *pdev)\r\n{\r\nstruct resource *r;\r\nstruct spi_master *master;\r\nconst struct sh_msiof_chipdata *chipdata;\r\nconst struct of_device_id *of_id;\r\nstruct sh_msiof_spi_priv *p;\r\nint i;\r\nint ret;\r\nmaster = spi_alloc_master(&pdev->dev, sizeof(struct sh_msiof_spi_priv));\r\nif (master == NULL) {\r\ndev_err(&pdev->dev, "failed to allocate spi master\n");\r\nreturn -ENOMEM;\r\n}\r\np = spi_master_get_devdata(master);\r\nplatform_set_drvdata(pdev, p);\r\np->master = master;\r\nof_id = of_match_device(sh_msiof_match, &pdev->dev);\r\nif (of_id) {\r\nchipdata = of_id->data;\r\np->info = sh_msiof_spi_parse_dt(&pdev->dev);\r\n} else {\r\nchipdata = (const void *)pdev->id_entry->driver_data;\r\np->info = dev_get_platdata(&pdev->dev);\r\n}\r\nif (!p->info) {\r\ndev_err(&pdev->dev, "failed to obtain device info\n");\r\nret = -ENXIO;\r\ngoto err1;\r\n}\r\ninit_completion(&p->done);\r\np->clk = devm_clk_get(&pdev->dev, NULL);\r\nif (IS_ERR(p->clk)) {\r\ndev_err(&pdev->dev, "cannot get clock\n");\r\nret = PTR_ERR(p->clk);\r\ngoto err1;\r\n}\r\ni = platform_get_irq(pdev, 0);\r\nif (i < 0) {\r\ndev_err(&pdev->dev, "cannot get platform IRQ\n");\r\nret = -ENOENT;\r\ngoto err1;\r\n}\r\nr = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\np->mapbase = devm_ioremap_resource(&pdev->dev, r);\r\nif (IS_ERR(p->mapbase)) {\r\nret = PTR_ERR(p->mapbase);\r\ngoto err1;\r\n}\r\nret = devm_request_irq(&pdev->dev, i, sh_msiof_spi_irq, 0,\r\ndev_name(&pdev->dev), p);\r\nif (ret) {\r\ndev_err(&pdev->dev, "unable to request irq\n");\r\ngoto err1;\r\n}\r\np->pdev = pdev;\r\npm_runtime_enable(&pdev->dev);\r\np->tx_fifo_size = chipdata->tx_fifo_size;\r\np->rx_fifo_size = chipdata->rx_fifo_size;\r\nif (p->info->tx_fifo_override)\r\np->tx_fifo_size = p->info->tx_fifo_override;\r\nif (p->info->rx_fifo_override)\r\np->rx_fifo_size = p->info->rx_fifo_override;\r\nmaster->mode_bits = SPI_CPOL | SPI_CPHA | SPI_CS_HIGH;\r\nmaster->mode_bits |= SPI_LSB_FIRST | SPI_3WIRE;\r\nmaster->flags = chipdata->master_flags;\r\nmaster->bus_num = pdev->id;\r\nmaster->dev.of_node = pdev->dev.of_node;\r\nmaster->num_chipselect = p->info->num_chipselect;\r\nmaster->setup = sh_msiof_spi_setup;\r\nmaster->prepare_message = sh_msiof_prepare_message;\r\nmaster->bits_per_word_mask = SPI_BPW_RANGE_MASK(8, 32);\r\nmaster->auto_runtime_pm = true;\r\nmaster->transfer_one = sh_msiof_transfer_one;\r\nret = sh_msiof_request_dma(p);\r\nif (ret < 0)\r\ndev_warn(&pdev->dev, "DMA not available, using PIO\n");\r\nret = devm_spi_register_master(&pdev->dev, master);\r\nif (ret < 0) {\r\ndev_err(&pdev->dev, "spi_register_master error.\n");\r\ngoto err2;\r\n}\r\nreturn 0;\r\nerr2:\r\nsh_msiof_release_dma(p);\r\npm_runtime_disable(&pdev->dev);\r\nerr1:\r\nspi_master_put(master);\r\nreturn ret;\r\n}\r\nstatic int sh_msiof_spi_remove(struct platform_device *pdev)\r\n{\r\nstruct sh_msiof_spi_priv *p = platform_get_drvdata(pdev);\r\nsh_msiof_release_dma(p);\r\npm_runtime_disable(&pdev->dev);\r\nreturn 0;\r\n}
