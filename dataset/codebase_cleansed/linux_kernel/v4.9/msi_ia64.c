static int ia64_set_msi_irq_affinity(struct irq_data *idata,\r\nconst cpumask_t *cpu_mask, bool force)\r\n{\r\nstruct msi_msg msg;\r\nu32 addr, data;\r\nint cpu = cpumask_first_and(cpu_mask, cpu_online_mask);\r\nunsigned int irq = idata->irq;\r\nif (irq_prepare_move(irq, cpu))\r\nreturn -1;\r\n__get_cached_msi_msg(irq_data_get_msi_desc(idata), &msg);\r\naddr = msg.address_lo;\r\naddr &= MSI_ADDR_DEST_ID_MASK;\r\naddr |= MSI_ADDR_DEST_ID_CPU(cpu_physical_id(cpu));\r\nmsg.address_lo = addr;\r\ndata = msg.data;\r\ndata &= MSI_DATA_VECTOR_MASK;\r\ndata |= MSI_DATA_VECTOR(irq_to_vector(irq));\r\nmsg.data = data;\r\npci_write_msi_msg(irq, &msg);\r\ncpumask_copy(irq_data_get_affinity_mask(idata), cpumask_of(cpu));\r\nreturn 0;\r\n}\r\nint ia64_setup_msi_irq(struct pci_dev *pdev, struct msi_desc *desc)\r\n{\r\nstruct msi_msg msg;\r\nunsigned long dest_phys_id;\r\nint irq, vector;\r\nirq = create_irq();\r\nif (irq < 0)\r\nreturn irq;\r\nirq_set_msi_desc(irq, desc);\r\ndest_phys_id = cpu_physical_id(cpumask_any_and(&(irq_to_domain(irq)),\r\ncpu_online_mask));\r\nvector = irq_to_vector(irq);\r\nmsg.address_hi = 0;\r\nmsg.address_lo =\r\nMSI_ADDR_HEADER |\r\nMSI_ADDR_DEST_MODE_PHYS |\r\nMSI_ADDR_REDIRECTION_CPU |\r\nMSI_ADDR_DEST_ID_CPU(dest_phys_id);\r\nmsg.data =\r\nMSI_DATA_TRIGGER_EDGE |\r\nMSI_DATA_LEVEL_ASSERT |\r\nMSI_DATA_DELIVERY_FIXED |\r\nMSI_DATA_VECTOR(vector);\r\npci_write_msi_msg(irq, &msg);\r\nirq_set_chip_and_handler(irq, &ia64_msi_chip, handle_edge_irq);\r\nreturn 0;\r\n}\r\nvoid ia64_teardown_msi_irq(unsigned int irq)\r\n{\r\ndestroy_irq(irq);\r\n}\r\nstatic void ia64_ack_msi_irq(struct irq_data *data)\r\n{\r\nirq_complete_move(data->irq);\r\nirq_move_irq(data);\r\nia64_eoi();\r\n}\r\nstatic int ia64_msi_retrigger_irq(struct irq_data *data)\r\n{\r\nunsigned int vector = irq_to_vector(data->irq);\r\nia64_resend_irq(vector);\r\nreturn 1;\r\n}\r\nint arch_setup_msi_irq(struct pci_dev *pdev, struct msi_desc *desc)\r\n{\r\nif (platform_setup_msi_irq)\r\nreturn platform_setup_msi_irq(pdev, desc);\r\nreturn ia64_setup_msi_irq(pdev, desc);\r\n}\r\nvoid arch_teardown_msi_irq(unsigned int irq)\r\n{\r\nif (platform_teardown_msi_irq)\r\nreturn platform_teardown_msi_irq(irq);\r\nreturn ia64_teardown_msi_irq(irq);\r\n}\r\nstatic int dmar_msi_set_affinity(struct irq_data *data,\r\nconst struct cpumask *mask, bool force)\r\n{\r\nunsigned int irq = data->irq;\r\nstruct irq_cfg *cfg = irq_cfg + irq;\r\nstruct msi_msg msg;\r\nint cpu = cpumask_first_and(mask, cpu_online_mask);\r\nif (irq_prepare_move(irq, cpu))\r\nreturn -1;\r\ndmar_msi_read(irq, &msg);\r\nmsg.data &= ~MSI_DATA_VECTOR_MASK;\r\nmsg.data |= MSI_DATA_VECTOR(cfg->vector);\r\nmsg.address_lo &= ~MSI_ADDR_DEST_ID_MASK;\r\nmsg.address_lo |= MSI_ADDR_DEST_ID_CPU(cpu_physical_id(cpu));\r\ndmar_msi_write(irq, &msg);\r\ncpumask_copy(irq_data_get_affinity_mask(data), mask);\r\nreturn 0;\r\n}\r\nstatic void\r\nmsi_compose_msg(struct pci_dev *pdev, unsigned int irq, struct msi_msg *msg)\r\n{\r\nstruct irq_cfg *cfg = irq_cfg + irq;\r\nunsigned dest;\r\ndest = cpu_physical_id(cpumask_first_and(&(irq_to_domain(irq)),\r\ncpu_online_mask));\r\nmsg->address_hi = 0;\r\nmsg->address_lo =\r\nMSI_ADDR_HEADER |\r\nMSI_ADDR_DEST_MODE_PHYS |\r\nMSI_ADDR_REDIRECTION_CPU |\r\nMSI_ADDR_DEST_ID_CPU(dest);\r\nmsg->data =\r\nMSI_DATA_TRIGGER_EDGE |\r\nMSI_DATA_LEVEL_ASSERT |\r\nMSI_DATA_DELIVERY_FIXED |\r\nMSI_DATA_VECTOR(cfg->vector);\r\n}\r\nint dmar_alloc_hwirq(int id, int node, void *arg)\r\n{\r\nint irq;\r\nstruct msi_msg msg;\r\nirq = create_irq();\r\nif (irq > 0) {\r\nirq_set_handler_data(irq, arg);\r\nirq_set_chip_and_handler_name(irq, &dmar_msi_type,\r\nhandle_edge_irq, "edge");\r\nmsi_compose_msg(NULL, irq, &msg);\r\ndmar_msi_write(irq, &msg);\r\n}\r\nreturn irq;\r\n}\r\nvoid dmar_free_hwirq(int irq)\r\n{\r\nirq_set_handler_data(irq, NULL);\r\ndestroy_irq(irq);\r\n}
