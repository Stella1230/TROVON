static int set_up_temporary_text_mapping(pgd_t *pgd)\r\n{\r\npmd_t *pmd;\r\npud_t *pud;\r\npud = (pud_t *)get_safe_page(GFP_ATOMIC);\r\nif (!pud)\r\nreturn -ENOMEM;\r\npmd = (pmd_t *)get_safe_page(GFP_ATOMIC);\r\nif (!pmd)\r\nreturn -ENOMEM;\r\nset_pmd(pmd + pmd_index(restore_jump_address),\r\n__pmd((jump_address_phys & PMD_MASK) | __PAGE_KERNEL_LARGE_EXEC));\r\nset_pud(pud + pud_index(restore_jump_address),\r\n__pud(__pa(pmd) | _KERNPG_TABLE));\r\nset_pgd(pgd + pgd_index(restore_jump_address),\r\n__pgd(__pa(pud) | _KERNPG_TABLE));\r\nreturn 0;\r\n}\r\nstatic void *alloc_pgt_page(void *context)\r\n{\r\nreturn (void *)get_safe_page(GFP_ATOMIC);\r\n}\r\nstatic int set_up_temporary_mappings(void)\r\n{\r\nstruct x86_mapping_info info = {\r\n.alloc_pgt_page = alloc_pgt_page,\r\n.pmd_flag = __PAGE_KERNEL_LARGE_EXEC,\r\n.offset = __PAGE_OFFSET,\r\n};\r\nunsigned long mstart, mend;\r\npgd_t *pgd;\r\nint result;\r\nint i;\r\npgd = (pgd_t *)get_safe_page(GFP_ATOMIC);\r\nif (!pgd)\r\nreturn -ENOMEM;\r\nresult = set_up_temporary_text_mapping(pgd);\r\nif (result)\r\nreturn result;\r\nfor (i = 0; i < nr_pfn_mapped; i++) {\r\nmstart = pfn_mapped[i].start << PAGE_SHIFT;\r\nmend = pfn_mapped[i].end << PAGE_SHIFT;\r\nresult = kernel_ident_mapping_init(&info, pgd, mstart, mend);\r\nif (result)\r\nreturn result;\r\n}\r\ntemp_level4_pgt = __pa(pgd);\r\nreturn 0;\r\n}\r\nstatic int relocate_restore_code(void)\r\n{\r\npgd_t *pgd;\r\npud_t *pud;\r\nrelocated_restore_code = get_safe_page(GFP_ATOMIC);\r\nif (!relocated_restore_code)\r\nreturn -ENOMEM;\r\nmemcpy((void *)relocated_restore_code, &core_restore_code, PAGE_SIZE);\r\npgd = (pgd_t *)__va(read_cr3()) + pgd_index(relocated_restore_code);\r\npud = pud_offset(pgd, relocated_restore_code);\r\nif (pud_large(*pud)) {\r\nset_pud(pud, __pud(pud_val(*pud) & ~_PAGE_NX));\r\n} else {\r\npmd_t *pmd = pmd_offset(pud, relocated_restore_code);\r\nif (pmd_large(*pmd)) {\r\nset_pmd(pmd, __pmd(pmd_val(*pmd) & ~_PAGE_NX));\r\n} else {\r\npte_t *pte = pte_offset_kernel(pmd, relocated_restore_code);\r\nset_pte(pte, __pte(pte_val(*pte) & ~_PAGE_NX));\r\n}\r\n}\r\n__flush_tlb_all();\r\nreturn 0;\r\n}\r\nint swsusp_arch_resume(void)\r\n{\r\nint error;\r\nerror = set_up_temporary_mappings();\r\nif (error)\r\nreturn error;\r\nerror = relocate_restore_code();\r\nif (error)\r\nreturn error;\r\nrestore_image();\r\nreturn 0;\r\n}\r\nint pfn_is_nosave(unsigned long pfn)\r\n{\r\nunsigned long nosave_begin_pfn = __pa_symbol(&__nosave_begin) >> PAGE_SHIFT;\r\nunsigned long nosave_end_pfn = PAGE_ALIGN(__pa_symbol(&__nosave_end)) >> PAGE_SHIFT;\r\nreturn (pfn >= nosave_begin_pfn) && (pfn < nosave_end_pfn);\r\n}\r\nint arch_hibernation_header_save(void *addr, unsigned int max_size)\r\n{\r\nstruct restore_data_record *rdr = addr;\r\nif (max_size < sizeof(struct restore_data_record))\r\nreturn -EOVERFLOW;\r\nrdr->jump_address = (unsigned long)&restore_registers;\r\nrdr->jump_address_phys = __pa_symbol(&restore_registers);\r\nrdr->cr3 = restore_cr3;\r\nrdr->magic = RESTORE_MAGIC;\r\nreturn 0;\r\n}\r\nint arch_hibernation_header_restore(void *addr)\r\n{\r\nstruct restore_data_record *rdr = addr;\r\nrestore_jump_address = rdr->jump_address;\r\njump_address_phys = rdr->jump_address_phys;\r\nrestore_cr3 = rdr->cr3;\r\nreturn (rdr->magic == RESTORE_MAGIC) ? 0 : -EINVAL;\r\n}
