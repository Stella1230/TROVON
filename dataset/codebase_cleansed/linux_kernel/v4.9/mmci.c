static int mmci_card_busy(struct mmc_host *mmc)\r\n{\r\nstruct mmci_host *host = mmc_priv(mmc);\r\nunsigned long flags;\r\nint busy = 0;\r\nspin_lock_irqsave(&host->lock, flags);\r\nif (readl(host->base + MMCISTATUS) & MCI_ST_CARDBUSY)\r\nbusy = 1;\r\nspin_unlock_irqrestore(&host->lock, flags);\r\nreturn busy;\r\n}\r\nstatic int mmci_validate_data(struct mmci_host *host,\r\nstruct mmc_data *data)\r\n{\r\nif (!data)\r\nreturn 0;\r\nif (!is_power_of_2(data->blksz)) {\r\ndev_err(mmc_dev(host->mmc),\r\n"unsupported block size (%d bytes)\n", data->blksz);\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic void mmci_reg_delay(struct mmci_host *host)\r\n{\r\nif (host->cclk < 25000000)\r\nudelay(30);\r\nelse\r\nndelay(120);\r\n}\r\nstatic void mmci_write_clkreg(struct mmci_host *host, u32 clk)\r\n{\r\nif (host->clk_reg != clk) {\r\nhost->clk_reg = clk;\r\nwritel(clk, host->base + MMCICLOCK);\r\n}\r\n}\r\nstatic void mmci_write_pwrreg(struct mmci_host *host, u32 pwr)\r\n{\r\nif (host->pwr_reg != pwr) {\r\nhost->pwr_reg = pwr;\r\nwritel(pwr, host->base + MMCIPOWER);\r\n}\r\n}\r\nstatic void mmci_write_datactrlreg(struct mmci_host *host, u32 datactrl)\r\n{\r\ndatactrl |= host->datactrl_reg & MCI_ST_DPSM_BUSYMODE;\r\nif (host->datactrl_reg != datactrl) {\r\nhost->datactrl_reg = datactrl;\r\nwritel(datactrl, host->base + MMCIDATACTRL);\r\n}\r\n}\r\nstatic void mmci_set_clkreg(struct mmci_host *host, unsigned int desired)\r\n{\r\nstruct variant_data *variant = host->variant;\r\nu32 clk = variant->clkreg;\r\nhost->cclk = 0;\r\nif (desired) {\r\nif (variant->explicit_mclk_control) {\r\nhost->cclk = host->mclk;\r\n} else if (desired >= host->mclk) {\r\nclk = MCI_CLK_BYPASS;\r\nif (variant->st_clkdiv)\r\nclk |= MCI_ST_UX500_NEG_EDGE;\r\nhost->cclk = host->mclk;\r\n} else if (variant->st_clkdiv) {\r\nclk = DIV_ROUND_UP(host->mclk, desired) - 2;\r\nif (clk >= 256)\r\nclk = 255;\r\nhost->cclk = host->mclk / (clk + 2);\r\n} else {\r\nclk = host->mclk / (2 * desired) - 1;\r\nif (clk >= 256)\r\nclk = 255;\r\nhost->cclk = host->mclk / (2 * (clk + 1));\r\n}\r\nclk |= variant->clkreg_enable;\r\nclk |= MCI_CLK_ENABLE;\r\n}\r\nhost->mmc->actual_clock = host->cclk;\r\nif (host->mmc->ios.bus_width == MMC_BUS_WIDTH_4)\r\nclk |= MCI_4BIT_BUS;\r\nif (host->mmc->ios.bus_width == MMC_BUS_WIDTH_8)\r\nclk |= variant->clkreg_8bit_bus_enable;\r\nif (host->mmc->ios.timing == MMC_TIMING_UHS_DDR50 ||\r\nhost->mmc->ios.timing == MMC_TIMING_MMC_DDR52)\r\nclk |= variant->clkreg_neg_edge_enable;\r\nmmci_write_clkreg(host, clk);\r\n}\r\nstatic void\r\nmmci_request_end(struct mmci_host *host, struct mmc_request *mrq)\r\n{\r\nwritel(0, host->base + MMCICOMMAND);\r\nBUG_ON(host->data);\r\nhost->mrq = NULL;\r\nhost->cmd = NULL;\r\nmmc_request_done(host->mmc, mrq);\r\n}\r\nstatic void mmci_set_mask1(struct mmci_host *host, unsigned int mask)\r\n{\r\nvoid __iomem *base = host->base;\r\nif (host->singleirq) {\r\nunsigned int mask0 = readl(base + MMCIMASK0);\r\nmask0 &= ~MCI_IRQ1MASK;\r\nmask0 |= mask;\r\nwritel(mask0, base + MMCIMASK0);\r\n}\r\nwritel(mask, base + MMCIMASK1);\r\n}\r\nstatic void mmci_stop_data(struct mmci_host *host)\r\n{\r\nmmci_write_datactrlreg(host, 0);\r\nmmci_set_mask1(host, 0);\r\nhost->data = NULL;\r\n}\r\nstatic void mmci_init_sg(struct mmci_host *host, struct mmc_data *data)\r\n{\r\nunsigned int flags = SG_MITER_ATOMIC;\r\nif (data->flags & MMC_DATA_READ)\r\nflags |= SG_MITER_TO_SG;\r\nelse\r\nflags |= SG_MITER_FROM_SG;\r\nsg_miter_start(&host->sg_miter, data->sg, data->sg_len, flags);\r\n}\r\nstatic void mmci_dma_setup(struct mmci_host *host)\r\n{\r\nconst char *rxname, *txname;\r\nstruct variant_data *variant = host->variant;\r\nhost->dma_rx_channel = dma_request_slave_channel(mmc_dev(host->mmc), "rx");\r\nhost->dma_tx_channel = dma_request_slave_channel(mmc_dev(host->mmc), "tx");\r\nhost->next_data.cookie = 1;\r\nif (host->dma_rx_channel && !host->dma_tx_channel)\r\nhost->dma_tx_channel = host->dma_rx_channel;\r\nif (host->dma_rx_channel)\r\nrxname = dma_chan_name(host->dma_rx_channel);\r\nelse\r\nrxname = "none";\r\nif (host->dma_tx_channel)\r\ntxname = dma_chan_name(host->dma_tx_channel);\r\nelse\r\ntxname = "none";\r\ndev_info(mmc_dev(host->mmc), "DMA channels RX %s, TX %s\n",\r\nrxname, txname);\r\nif (host->dma_tx_channel) {\r\nstruct device *dev = host->dma_tx_channel->device->dev;\r\nunsigned int max_seg_size = dma_get_max_seg_size(dev);\r\nif (max_seg_size < host->mmc->max_seg_size)\r\nhost->mmc->max_seg_size = max_seg_size;\r\n}\r\nif (host->dma_rx_channel) {\r\nstruct device *dev = host->dma_rx_channel->device->dev;\r\nunsigned int max_seg_size = dma_get_max_seg_size(dev);\r\nif (max_seg_size < host->mmc->max_seg_size)\r\nhost->mmc->max_seg_size = max_seg_size;\r\n}\r\nif (variant->qcom_dml && host->dma_rx_channel && host->dma_tx_channel)\r\nif (dml_hw_init(host, host->mmc->parent->of_node))\r\nvariant->qcom_dml = false;\r\n}\r\nstatic inline void mmci_dma_release(struct mmci_host *host)\r\n{\r\nif (host->dma_rx_channel)\r\ndma_release_channel(host->dma_rx_channel);\r\nif (host->dma_tx_channel)\r\ndma_release_channel(host->dma_tx_channel);\r\nhost->dma_rx_channel = host->dma_tx_channel = NULL;\r\n}\r\nstatic void mmci_dma_data_error(struct mmci_host *host)\r\n{\r\ndev_err(mmc_dev(host->mmc), "error during DMA transfer!\n");\r\ndmaengine_terminate_all(host->dma_current);\r\nhost->dma_current = NULL;\r\nhost->dma_desc_current = NULL;\r\nhost->data->host_cookie = 0;\r\n}\r\nstatic void mmci_dma_unmap(struct mmci_host *host, struct mmc_data *data)\r\n{\r\nstruct dma_chan *chan;\r\nenum dma_data_direction dir;\r\nif (data->flags & MMC_DATA_READ) {\r\ndir = DMA_FROM_DEVICE;\r\nchan = host->dma_rx_channel;\r\n} else {\r\ndir = DMA_TO_DEVICE;\r\nchan = host->dma_tx_channel;\r\n}\r\ndma_unmap_sg(chan->device->dev, data->sg, data->sg_len, dir);\r\n}\r\nstatic void mmci_dma_finalize(struct mmci_host *host, struct mmc_data *data)\r\n{\r\nu32 status;\r\nint i;\r\nfor (i = 0; ; i++) {\r\nstatus = readl(host->base + MMCISTATUS);\r\nif (!(status & MCI_RXDATAAVLBLMASK) || i >= 100)\r\nbreak;\r\nudelay(10);\r\n}\r\nif (status & MCI_RXDATAAVLBLMASK) {\r\nmmci_dma_data_error(host);\r\nif (!data->error)\r\ndata->error = -EIO;\r\n}\r\nif (!data->host_cookie)\r\nmmci_dma_unmap(host, data);\r\nif (status & MCI_RXDATAAVLBLMASK) {\r\ndev_err(mmc_dev(host->mmc), "buggy DMA detected. Taking evasive action.\n");\r\nmmci_dma_release(host);\r\n}\r\nhost->dma_current = NULL;\r\nhost->dma_desc_current = NULL;\r\n}\r\nstatic int __mmci_dma_prep_data(struct mmci_host *host, struct mmc_data *data,\r\nstruct dma_chan **dma_chan,\r\nstruct dma_async_tx_descriptor **dma_desc)\r\n{\r\nstruct variant_data *variant = host->variant;\r\nstruct dma_slave_config conf = {\r\n.src_addr = host->phybase + MMCIFIFO,\r\n.dst_addr = host->phybase + MMCIFIFO,\r\n.src_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES,\r\n.dst_addr_width = DMA_SLAVE_BUSWIDTH_4_BYTES,\r\n.src_maxburst = variant->fifohalfsize >> 2,\r\n.dst_maxburst = variant->fifohalfsize >> 2,\r\n.device_fc = false,\r\n};\r\nstruct dma_chan *chan;\r\nstruct dma_device *device;\r\nstruct dma_async_tx_descriptor *desc;\r\nenum dma_data_direction buffer_dirn;\r\nint nr_sg;\r\nunsigned long flags = DMA_CTRL_ACK;\r\nif (data->flags & MMC_DATA_READ) {\r\nconf.direction = DMA_DEV_TO_MEM;\r\nbuffer_dirn = DMA_FROM_DEVICE;\r\nchan = host->dma_rx_channel;\r\n} else {\r\nconf.direction = DMA_MEM_TO_DEV;\r\nbuffer_dirn = DMA_TO_DEVICE;\r\nchan = host->dma_tx_channel;\r\n}\r\nif (!chan)\r\nreturn -EINVAL;\r\nif (data->blksz * data->blocks <= variant->fifosize)\r\nreturn -EINVAL;\r\ndevice = chan->device;\r\nnr_sg = dma_map_sg(device->dev, data->sg, data->sg_len, buffer_dirn);\r\nif (nr_sg == 0)\r\nreturn -EINVAL;\r\nif (host->variant->qcom_dml)\r\nflags |= DMA_PREP_INTERRUPT;\r\ndmaengine_slave_config(chan, &conf);\r\ndesc = dmaengine_prep_slave_sg(chan, data->sg, nr_sg,\r\nconf.direction, flags);\r\nif (!desc)\r\ngoto unmap_exit;\r\n*dma_chan = chan;\r\n*dma_desc = desc;\r\nreturn 0;\r\nunmap_exit:\r\ndma_unmap_sg(device->dev, data->sg, data->sg_len, buffer_dirn);\r\nreturn -ENOMEM;\r\n}\r\nstatic inline int mmci_dma_prep_data(struct mmci_host *host,\r\nstruct mmc_data *data)\r\n{\r\nif (host->dma_current && host->dma_desc_current)\r\nreturn 0;\r\nreturn __mmci_dma_prep_data(host, data, &host->dma_current,\r\n&host->dma_desc_current);\r\n}\r\nstatic inline int mmci_dma_prep_next(struct mmci_host *host,\r\nstruct mmc_data *data)\r\n{\r\nstruct mmci_host_next *nd = &host->next_data;\r\nreturn __mmci_dma_prep_data(host, data, &nd->dma_chan, &nd->dma_desc);\r\n}\r\nstatic int mmci_dma_start_data(struct mmci_host *host, unsigned int datactrl)\r\n{\r\nint ret;\r\nstruct mmc_data *data = host->data;\r\nret = mmci_dma_prep_data(host, host->data);\r\nif (ret)\r\nreturn ret;\r\ndev_vdbg(mmc_dev(host->mmc),\r\n"Submit MMCI DMA job, sglen %d blksz %04x blks %04x flags %08x\n",\r\ndata->sg_len, data->blksz, data->blocks, data->flags);\r\ndmaengine_submit(host->dma_desc_current);\r\ndma_async_issue_pending(host->dma_current);\r\nif (host->variant->qcom_dml)\r\ndml_start_xfer(host, data);\r\ndatactrl |= MCI_DPSM_DMAENABLE;\r\nmmci_write_datactrlreg(host, datactrl);\r\nwritel(readl(host->base + MMCIMASK0) | MCI_DATAENDMASK,\r\nhost->base + MMCIMASK0);\r\nreturn 0;\r\n}\r\nstatic void mmci_get_next_data(struct mmci_host *host, struct mmc_data *data)\r\n{\r\nstruct mmci_host_next *next = &host->next_data;\r\nWARN_ON(data->host_cookie && data->host_cookie != next->cookie);\r\nWARN_ON(!data->host_cookie && (next->dma_desc || next->dma_chan));\r\nhost->dma_desc_current = next->dma_desc;\r\nhost->dma_current = next->dma_chan;\r\nnext->dma_desc = NULL;\r\nnext->dma_chan = NULL;\r\n}\r\nstatic void mmci_pre_request(struct mmc_host *mmc, struct mmc_request *mrq,\r\nbool is_first_req)\r\n{\r\nstruct mmci_host *host = mmc_priv(mmc);\r\nstruct mmc_data *data = mrq->data;\r\nstruct mmci_host_next *nd = &host->next_data;\r\nif (!data)\r\nreturn;\r\nBUG_ON(data->host_cookie);\r\nif (mmci_validate_data(host, data))\r\nreturn;\r\nif (!mmci_dma_prep_next(host, data))\r\ndata->host_cookie = ++nd->cookie < 0 ? 1 : nd->cookie;\r\n}\r\nstatic void mmci_post_request(struct mmc_host *mmc, struct mmc_request *mrq,\r\nint err)\r\n{\r\nstruct mmci_host *host = mmc_priv(mmc);\r\nstruct mmc_data *data = mrq->data;\r\nif (!data || !data->host_cookie)\r\nreturn;\r\nmmci_dma_unmap(host, data);\r\nif (err) {\r\nstruct mmci_host_next *next = &host->next_data;\r\nstruct dma_chan *chan;\r\nif (data->flags & MMC_DATA_READ)\r\nchan = host->dma_rx_channel;\r\nelse\r\nchan = host->dma_tx_channel;\r\ndmaengine_terminate_all(chan);\r\nif (host->dma_desc_current == next->dma_desc)\r\nhost->dma_desc_current = NULL;\r\nif (host->dma_current == next->dma_chan)\r\nhost->dma_current = NULL;\r\nnext->dma_desc = NULL;\r\nnext->dma_chan = NULL;\r\ndata->host_cookie = 0;\r\n}\r\n}\r\nstatic void mmci_get_next_data(struct mmci_host *host, struct mmc_data *data)\r\n{\r\n}\r\nstatic inline void mmci_dma_setup(struct mmci_host *host)\r\n{\r\n}\r\nstatic inline void mmci_dma_release(struct mmci_host *host)\r\n{\r\n}\r\nstatic inline void mmci_dma_unmap(struct mmci_host *host, struct mmc_data *data)\r\n{\r\n}\r\nstatic inline void mmci_dma_finalize(struct mmci_host *host,\r\nstruct mmc_data *data)\r\n{\r\n}\r\nstatic inline void mmci_dma_data_error(struct mmci_host *host)\r\n{\r\n}\r\nstatic inline int mmci_dma_start_data(struct mmci_host *host, unsigned int datactrl)\r\n{\r\nreturn -ENOSYS;\r\n}\r\nstatic void mmci_start_data(struct mmci_host *host, struct mmc_data *data)\r\n{\r\nstruct variant_data *variant = host->variant;\r\nunsigned int datactrl, timeout, irqmask;\r\nunsigned long long clks;\r\nvoid __iomem *base;\r\nint blksz_bits;\r\ndev_dbg(mmc_dev(host->mmc), "blksz %04x blks %04x flags %08x\n",\r\ndata->blksz, data->blocks, data->flags);\r\nhost->data = data;\r\nhost->size = data->blksz * data->blocks;\r\ndata->bytes_xfered = 0;\r\nclks = (unsigned long long)data->timeout_ns * host->cclk;\r\ndo_div(clks, NSEC_PER_SEC);\r\ntimeout = data->timeout_clks + (unsigned int)clks;\r\nbase = host->base;\r\nwritel(timeout, base + MMCIDATATIMER);\r\nwritel(host->size, base + MMCIDATALENGTH);\r\nblksz_bits = ffs(data->blksz) - 1;\r\nBUG_ON(1 << blksz_bits != data->blksz);\r\nif (variant->blksz_datactrl16)\r\ndatactrl = MCI_DPSM_ENABLE | (data->blksz << 16);\r\nelse if (variant->blksz_datactrl4)\r\ndatactrl = MCI_DPSM_ENABLE | (data->blksz << 4);\r\nelse\r\ndatactrl = MCI_DPSM_ENABLE | blksz_bits << 4;\r\nif (data->flags & MMC_DATA_READ)\r\ndatactrl |= MCI_DPSM_DIRECTION;\r\nif (host->mmc->card && mmc_card_sdio(host->mmc->card)) {\r\nu32 clk;\r\ndatactrl |= variant->datactrl_mask_sdio;\r\nif (variant->st_sdio && data->flags & MMC_DATA_WRITE &&\r\n(host->size < 8 ||\r\n(host->size <= 8 && host->mclk > 50000000)))\r\nclk = host->clk_reg & ~variant->clkreg_enable;\r\nelse\r\nclk = host->clk_reg | variant->clkreg_enable;\r\nmmci_write_clkreg(host, clk);\r\n}\r\nif (host->mmc->ios.timing == MMC_TIMING_UHS_DDR50 ||\r\nhost->mmc->ios.timing == MMC_TIMING_MMC_DDR52)\r\ndatactrl |= variant->datactrl_mask_ddrmode;\r\nif (!mmci_dma_start_data(host, datactrl))\r\nreturn;\r\nmmci_init_sg(host, data);\r\nif (data->flags & MMC_DATA_READ) {\r\nirqmask = MCI_RXFIFOHALFFULLMASK;\r\nif (host->size < variant->fifohalfsize)\r\nirqmask |= MCI_RXDATAAVLBLMASK;\r\n} else {\r\nirqmask = MCI_TXFIFOHALFEMPTYMASK;\r\n}\r\nmmci_write_datactrlreg(host, datactrl);\r\nwritel(readl(base + MMCIMASK0) & ~MCI_DATAENDMASK, base + MMCIMASK0);\r\nmmci_set_mask1(host, irqmask);\r\n}\r\nstatic void\r\nmmci_start_command(struct mmci_host *host, struct mmc_command *cmd, u32 c)\r\n{\r\nvoid __iomem *base = host->base;\r\ndev_dbg(mmc_dev(host->mmc), "op %02x arg %08x flags %08x\n",\r\ncmd->opcode, cmd->arg, cmd->flags);\r\nif (readl(base + MMCICOMMAND) & MCI_CPSM_ENABLE) {\r\nwritel(0, base + MMCICOMMAND);\r\nmmci_reg_delay(host);\r\n}\r\nc |= cmd->opcode | MCI_CPSM_ENABLE;\r\nif (cmd->flags & MMC_RSP_PRESENT) {\r\nif (cmd->flags & MMC_RSP_136)\r\nc |= MCI_CPSM_LONGRSP;\r\nc |= MCI_CPSM_RESPONSE;\r\n}\r\nif (0)\r\nc |= MCI_CPSM_INTERRUPT;\r\nif (mmc_cmd_type(cmd) == MMC_CMD_ADTC)\r\nc |= host->variant->data_cmd_enable;\r\nhost->cmd = cmd;\r\nwritel(cmd->arg, base + MMCIARGUMENT);\r\nwritel(c, base + MMCICOMMAND);\r\n}\r\nstatic void\r\nmmci_data_irq(struct mmci_host *host, struct mmc_data *data,\r\nunsigned int status)\r\n{\r\nif (!data)\r\nreturn;\r\nif (status & (MCI_DATACRCFAIL|MCI_DATATIMEOUT|MCI_STARTBITERR|\r\nMCI_TXUNDERRUN|MCI_RXOVERRUN)) {\r\nu32 remain, success;\r\nif (dma_inprogress(host)) {\r\nmmci_dma_data_error(host);\r\nmmci_dma_unmap(host, data);\r\n}\r\nremain = readl(host->base + MMCIDATACNT);\r\nsuccess = data->blksz * data->blocks - remain;\r\ndev_dbg(mmc_dev(host->mmc), "MCI ERROR IRQ, status 0x%08x at 0x%08x\n",\r\nstatus, success);\r\nif (status & MCI_DATACRCFAIL) {\r\nsuccess -= 1;\r\ndata->error = -EILSEQ;\r\n} else if (status & MCI_DATATIMEOUT) {\r\ndata->error = -ETIMEDOUT;\r\n} else if (status & MCI_STARTBITERR) {\r\ndata->error = -ECOMM;\r\n} else if (status & MCI_TXUNDERRUN) {\r\ndata->error = -EIO;\r\n} else if (status & MCI_RXOVERRUN) {\r\nif (success > host->variant->fifosize)\r\nsuccess -= host->variant->fifosize;\r\nelse\r\nsuccess = 0;\r\ndata->error = -EIO;\r\n}\r\ndata->bytes_xfered = round_down(success, data->blksz);\r\n}\r\nif (status & MCI_DATABLOCKEND)\r\ndev_err(mmc_dev(host->mmc), "stray MCI_DATABLOCKEND interrupt\n");\r\nif (status & MCI_DATAEND || data->error) {\r\nif (dma_inprogress(host))\r\nmmci_dma_finalize(host, data);\r\nmmci_stop_data(host);\r\nif (!data->error)\r\ndata->bytes_xfered = data->blksz * data->blocks;\r\nif (!data->stop || host->mrq->sbc) {\r\nmmci_request_end(host, data->mrq);\r\n} else {\r\nmmci_start_command(host, data->stop, 0);\r\n}\r\n}\r\n}\r\nstatic void\r\nmmci_cmd_irq(struct mmci_host *host, struct mmc_command *cmd,\r\nunsigned int status)\r\n{\r\nvoid __iomem *base = host->base;\r\nbool sbc, busy_resp;\r\nif (!cmd)\r\nreturn;\r\nsbc = (cmd == host->mrq->sbc);\r\nbusy_resp = host->variant->busy_detect && (cmd->flags & MMC_RSP_BUSY);\r\nif (!((status|host->busy_status) & (MCI_CMDCRCFAIL|MCI_CMDTIMEOUT|\r\nMCI_CMDSENT|MCI_CMDRESPEND)))\r\nreturn;\r\nif (host->busy_status && (status & MCI_ST_CARDBUSY))\r\nreturn;\r\nif (!host->busy_status && busy_resp &&\r\n!(status & (MCI_CMDCRCFAIL|MCI_CMDTIMEOUT)) &&\r\n(readl(base + MMCISTATUS) & MCI_ST_CARDBUSY)) {\r\nwritel(readl(base + MMCIMASK0) | MCI_ST_BUSYEND,\r\nbase + MMCIMASK0);\r\nhost->busy_status = status & (MCI_CMDSENT|MCI_CMDRESPEND);\r\nreturn;\r\n}\r\nif (host->busy_status) {\r\nwritel(readl(base + MMCIMASK0) & ~MCI_ST_BUSYEND,\r\nbase + MMCIMASK0);\r\nhost->busy_status = 0;\r\n}\r\nhost->cmd = NULL;\r\nif (status & MCI_CMDTIMEOUT) {\r\ncmd->error = -ETIMEDOUT;\r\n} else if (status & MCI_CMDCRCFAIL && cmd->flags & MMC_RSP_CRC) {\r\ncmd->error = -EILSEQ;\r\n} else {\r\ncmd->resp[0] = readl(base + MMCIRESPONSE0);\r\ncmd->resp[1] = readl(base + MMCIRESPONSE1);\r\ncmd->resp[2] = readl(base + MMCIRESPONSE2);\r\ncmd->resp[3] = readl(base + MMCIRESPONSE3);\r\n}\r\nif ((!sbc && !cmd->data) || cmd->error) {\r\nif (host->data) {\r\nif (dma_inprogress(host)) {\r\nmmci_dma_data_error(host);\r\nmmci_dma_unmap(host, host->data);\r\n}\r\nmmci_stop_data(host);\r\n}\r\nmmci_request_end(host, host->mrq);\r\n} else if (sbc) {\r\nmmci_start_command(host, host->mrq->cmd, 0);\r\n} else if (!(cmd->data->flags & MMC_DATA_READ)) {\r\nmmci_start_data(host, cmd->data);\r\n}\r\n}\r\nstatic int mmci_get_rx_fifocnt(struct mmci_host *host, u32 status, int remain)\r\n{\r\nreturn remain - (readl(host->base + MMCIFIFOCNT) << 2);\r\n}\r\nstatic int mmci_qcom_get_rx_fifocnt(struct mmci_host *host, u32 status, int r)\r\n{\r\nif (status & MCI_RXFIFOHALFFULL)\r\nreturn host->variant->fifohalfsize;\r\nelse if (status & MCI_RXDATAAVLBL)\r\nreturn 4;\r\nreturn 0;\r\n}\r\nstatic int mmci_pio_read(struct mmci_host *host, char *buffer, unsigned int remain)\r\n{\r\nvoid __iomem *base = host->base;\r\nchar *ptr = buffer;\r\nu32 status = readl(host->base + MMCISTATUS);\r\nint host_remain = host->size;\r\ndo {\r\nint count = host->get_rx_fifocnt(host, status, host_remain);\r\nif (count > remain)\r\ncount = remain;\r\nif (count <= 0)\r\nbreak;\r\nif (unlikely(count & 0x3)) {\r\nif (count < 4) {\r\nunsigned char buf[4];\r\nioread32_rep(base + MMCIFIFO, buf, 1);\r\nmemcpy(ptr, buf, count);\r\n} else {\r\nioread32_rep(base + MMCIFIFO, ptr, count >> 2);\r\ncount &= ~0x3;\r\n}\r\n} else {\r\nioread32_rep(base + MMCIFIFO, ptr, count >> 2);\r\n}\r\nptr += count;\r\nremain -= count;\r\nhost_remain -= count;\r\nif (remain == 0)\r\nbreak;\r\nstatus = readl(base + MMCISTATUS);\r\n} while (status & MCI_RXDATAAVLBL);\r\nreturn ptr - buffer;\r\n}\r\nstatic int mmci_pio_write(struct mmci_host *host, char *buffer, unsigned int remain, u32 status)\r\n{\r\nstruct variant_data *variant = host->variant;\r\nvoid __iomem *base = host->base;\r\nchar *ptr = buffer;\r\ndo {\r\nunsigned int count, maxcnt;\r\nmaxcnt = status & MCI_TXFIFOEMPTY ?\r\nvariant->fifosize : variant->fifohalfsize;\r\ncount = min(remain, maxcnt);\r\niowrite32_rep(base + MMCIFIFO, ptr, (count + 3) >> 2);\r\nptr += count;\r\nremain -= count;\r\nif (remain == 0)\r\nbreak;\r\nstatus = readl(base + MMCISTATUS);\r\n} while (status & MCI_TXFIFOHALFEMPTY);\r\nreturn ptr - buffer;\r\n}\r\nstatic irqreturn_t mmci_pio_irq(int irq, void *dev_id)\r\n{\r\nstruct mmci_host *host = dev_id;\r\nstruct sg_mapping_iter *sg_miter = &host->sg_miter;\r\nstruct variant_data *variant = host->variant;\r\nvoid __iomem *base = host->base;\r\nunsigned long flags;\r\nu32 status;\r\nstatus = readl(base + MMCISTATUS);\r\ndev_dbg(mmc_dev(host->mmc), "irq1 (pio) %08x\n", status);\r\nlocal_irq_save(flags);\r\ndo {\r\nunsigned int remain, len;\r\nchar *buffer;\r\nif (!(status & (MCI_TXFIFOHALFEMPTY|MCI_RXDATAAVLBL)))\r\nbreak;\r\nif (!sg_miter_next(sg_miter))\r\nbreak;\r\nbuffer = sg_miter->addr;\r\nremain = sg_miter->length;\r\nlen = 0;\r\nif (status & MCI_RXACTIVE)\r\nlen = mmci_pio_read(host, buffer, remain);\r\nif (status & MCI_TXACTIVE)\r\nlen = mmci_pio_write(host, buffer, remain, status);\r\nsg_miter->consumed = len;\r\nhost->size -= len;\r\nremain -= len;\r\nif (remain)\r\nbreak;\r\nstatus = readl(base + MMCISTATUS);\r\n} while (1);\r\nsg_miter_stop(sg_miter);\r\nlocal_irq_restore(flags);\r\nif (status & MCI_RXACTIVE && host->size < variant->fifohalfsize)\r\nmmci_set_mask1(host, MCI_RXDATAAVLBLMASK);\r\nif (host->size == 0) {\r\nmmci_set_mask1(host, 0);\r\nwritel(readl(base + MMCIMASK0) | MCI_DATAENDMASK, base + MMCIMASK0);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t mmci_irq(int irq, void *dev_id)\r\n{\r\nstruct mmci_host *host = dev_id;\r\nu32 status;\r\nint ret = 0;\r\nspin_lock(&host->lock);\r\ndo {\r\nstatus = readl(host->base + MMCISTATUS);\r\nif (host->singleirq) {\r\nif (status & readl(host->base + MMCIMASK1))\r\nmmci_pio_irq(irq, dev_id);\r\nstatus &= ~MCI_IRQ1MASK;\r\n}\r\nstatus &= readl(host->base + MMCIMASK0);\r\nwritel(status, host->base + MMCICLEAR);\r\ndev_dbg(mmc_dev(host->mmc), "irq0 (data+cmd) %08x\n", status);\r\nif (host->variant->reversed_irq_handling) {\r\nmmci_data_irq(host, host->data, status);\r\nmmci_cmd_irq(host, host->cmd, status);\r\n} else {\r\nmmci_cmd_irq(host, host->cmd, status);\r\nmmci_data_irq(host, host->data, status);\r\n}\r\nif (host->busy_status)\r\nstatus &= ~MCI_ST_CARDBUSY;\r\nret = 1;\r\n} while (status);\r\nspin_unlock(&host->lock);\r\nreturn IRQ_RETVAL(ret);\r\n}\r\nstatic void mmci_request(struct mmc_host *mmc, struct mmc_request *mrq)\r\n{\r\nstruct mmci_host *host = mmc_priv(mmc);\r\nunsigned long flags;\r\nWARN_ON(host->mrq != NULL);\r\nmrq->cmd->error = mmci_validate_data(host, mrq->data);\r\nif (mrq->cmd->error) {\r\nmmc_request_done(mmc, mrq);\r\nreturn;\r\n}\r\nspin_lock_irqsave(&host->lock, flags);\r\nhost->mrq = mrq;\r\nif (mrq->data)\r\nmmci_get_next_data(host, mrq->data);\r\nif (mrq->data && mrq->data->flags & MMC_DATA_READ)\r\nmmci_start_data(host, mrq->data);\r\nif (mrq->sbc)\r\nmmci_start_command(host, mrq->sbc, 0);\r\nelse\r\nmmci_start_command(host, mrq->cmd, 0);\r\nspin_unlock_irqrestore(&host->lock, flags);\r\n}\r\nstatic void mmci_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)\r\n{\r\nstruct mmci_host *host = mmc_priv(mmc);\r\nstruct variant_data *variant = host->variant;\r\nu32 pwr = 0;\r\nunsigned long flags;\r\nint ret;\r\nif (host->plat->ios_handler &&\r\nhost->plat->ios_handler(mmc_dev(mmc), ios))\r\ndev_err(mmc_dev(mmc), "platform ios_handler failed\n");\r\nswitch (ios->power_mode) {\r\ncase MMC_POWER_OFF:\r\nif (!IS_ERR(mmc->supply.vmmc))\r\nmmc_regulator_set_ocr(mmc, mmc->supply.vmmc, 0);\r\nif (!IS_ERR(mmc->supply.vqmmc) && host->vqmmc_enabled) {\r\nregulator_disable(mmc->supply.vqmmc);\r\nhost->vqmmc_enabled = false;\r\n}\r\nbreak;\r\ncase MMC_POWER_UP:\r\nif (!IS_ERR(mmc->supply.vmmc))\r\nmmc_regulator_set_ocr(mmc, mmc->supply.vmmc, ios->vdd);\r\npwr |= variant->pwrreg_powerup;\r\nbreak;\r\ncase MMC_POWER_ON:\r\nif (!IS_ERR(mmc->supply.vqmmc) && !host->vqmmc_enabled) {\r\nret = regulator_enable(mmc->supply.vqmmc);\r\nif (ret < 0)\r\ndev_err(mmc_dev(mmc),\r\n"failed to enable vqmmc regulator\n");\r\nelse\r\nhost->vqmmc_enabled = true;\r\n}\r\npwr |= MCI_PWR_ON;\r\nbreak;\r\n}\r\nif (variant->signal_direction && ios->power_mode != MMC_POWER_OFF) {\r\npwr |= host->pwr_reg_add;\r\nif (ios->bus_width == MMC_BUS_WIDTH_4)\r\npwr &= ~MCI_ST_DATA74DIREN;\r\nelse if (ios->bus_width == MMC_BUS_WIDTH_1)\r\npwr &= (~MCI_ST_DATA74DIREN &\r\n~MCI_ST_DATA31DIREN &\r\n~MCI_ST_DATA2DIREN);\r\n}\r\nif (ios->bus_mode == MMC_BUSMODE_OPENDRAIN) {\r\nif (host->hw_designer != AMBA_VENDOR_ST)\r\npwr |= MCI_ROD;\r\nelse {\r\npwr |= MCI_OD;\r\n}\r\n}\r\nif (!ios->clock && variant->pwrreg_clkgate)\r\npwr &= ~MCI_PWR_ON;\r\nif (host->variant->explicit_mclk_control &&\r\nios->clock != host->clock_cache) {\r\nret = clk_set_rate(host->clk, ios->clock);\r\nif (ret < 0)\r\ndev_err(mmc_dev(host->mmc),\r\n"Error setting clock rate (%d)\n", ret);\r\nelse\r\nhost->mclk = clk_get_rate(host->clk);\r\n}\r\nhost->clock_cache = ios->clock;\r\nspin_lock_irqsave(&host->lock, flags);\r\nmmci_set_clkreg(host, ios->clock);\r\nmmci_write_pwrreg(host, pwr);\r\nmmci_reg_delay(host);\r\nspin_unlock_irqrestore(&host->lock, flags);\r\n}\r\nstatic int mmci_get_cd(struct mmc_host *mmc)\r\n{\r\nstruct mmci_host *host = mmc_priv(mmc);\r\nstruct mmci_platform_data *plat = host->plat;\r\nunsigned int status = mmc_gpio_get_cd(mmc);\r\nif (status == -ENOSYS) {\r\nif (!plat->status)\r\nreturn 1;\r\nstatus = plat->status(mmc_dev(host->mmc));\r\n}\r\nreturn status;\r\n}\r\nstatic int mmci_sig_volt_switch(struct mmc_host *mmc, struct mmc_ios *ios)\r\n{\r\nint ret = 0;\r\nif (!IS_ERR(mmc->supply.vqmmc)) {\r\nswitch (ios->signal_voltage) {\r\ncase MMC_SIGNAL_VOLTAGE_330:\r\nret = regulator_set_voltage(mmc->supply.vqmmc,\r\n2700000, 3600000);\r\nbreak;\r\ncase MMC_SIGNAL_VOLTAGE_180:\r\nret = regulator_set_voltage(mmc->supply.vqmmc,\r\n1700000, 1950000);\r\nbreak;\r\ncase MMC_SIGNAL_VOLTAGE_120:\r\nret = regulator_set_voltage(mmc->supply.vqmmc,\r\n1100000, 1300000);\r\nbreak;\r\n}\r\nif (ret)\r\ndev_warn(mmc_dev(mmc), "Voltage switch failed\n");\r\n}\r\nreturn ret;\r\n}\r\nstatic int mmci_of_parse(struct device_node *np, struct mmc_host *mmc)\r\n{\r\nstruct mmci_host *host = mmc_priv(mmc);\r\nint ret = mmc_of_parse(mmc);\r\nif (ret)\r\nreturn ret;\r\nif (of_get_property(np, "st,sig-dir-dat0", NULL))\r\nhost->pwr_reg_add |= MCI_ST_DATA0DIREN;\r\nif (of_get_property(np, "st,sig-dir-dat2", NULL))\r\nhost->pwr_reg_add |= MCI_ST_DATA2DIREN;\r\nif (of_get_property(np, "st,sig-dir-dat31", NULL))\r\nhost->pwr_reg_add |= MCI_ST_DATA31DIREN;\r\nif (of_get_property(np, "st,sig-dir-dat74", NULL))\r\nhost->pwr_reg_add |= MCI_ST_DATA74DIREN;\r\nif (of_get_property(np, "st,sig-dir-cmd", NULL))\r\nhost->pwr_reg_add |= MCI_ST_CMDDIREN;\r\nif (of_get_property(np, "st,sig-pin-fbclk", NULL))\r\nhost->pwr_reg_add |= MCI_ST_FBCLKEN;\r\nif (of_get_property(np, "mmc-cap-mmc-highspeed", NULL))\r\nmmc->caps |= MMC_CAP_MMC_HIGHSPEED;\r\nif (of_get_property(np, "mmc-cap-sd-highspeed", NULL))\r\nmmc->caps |= MMC_CAP_SD_HIGHSPEED;\r\nreturn 0;\r\n}\r\nstatic int mmci_probe(struct amba_device *dev,\r\nconst struct amba_id *id)\r\n{\r\nstruct mmci_platform_data *plat = dev->dev.platform_data;\r\nstruct device_node *np = dev->dev.of_node;\r\nstruct variant_data *variant = id->data;\r\nstruct mmci_host *host;\r\nstruct mmc_host *mmc;\r\nint ret;\r\nif (!plat && !np) {\r\ndev_err(&dev->dev, "No plat data or DT found\n");\r\nreturn -EINVAL;\r\n}\r\nif (!plat) {\r\nplat = devm_kzalloc(&dev->dev, sizeof(*plat), GFP_KERNEL);\r\nif (!plat)\r\nreturn -ENOMEM;\r\n}\r\nmmc = mmc_alloc_host(sizeof(struct mmci_host), &dev->dev);\r\nif (!mmc)\r\nreturn -ENOMEM;\r\nret = mmci_of_parse(np, mmc);\r\nif (ret)\r\ngoto host_free;\r\nhost = mmc_priv(mmc);\r\nhost->mmc = mmc;\r\nhost->hw_designer = amba_manf(dev);\r\nhost->hw_revision = amba_rev(dev);\r\ndev_dbg(mmc_dev(mmc), "designer ID = 0x%02x\n", host->hw_designer);\r\ndev_dbg(mmc_dev(mmc), "revision = 0x%01x\n", host->hw_revision);\r\nhost->clk = devm_clk_get(&dev->dev, NULL);\r\nif (IS_ERR(host->clk)) {\r\nret = PTR_ERR(host->clk);\r\ngoto host_free;\r\n}\r\nret = clk_prepare_enable(host->clk);\r\nif (ret)\r\ngoto host_free;\r\nif (variant->qcom_fifo)\r\nhost->get_rx_fifocnt = mmci_qcom_get_rx_fifocnt;\r\nelse\r\nhost->get_rx_fifocnt = mmci_get_rx_fifocnt;\r\nhost->plat = plat;\r\nhost->variant = variant;\r\nhost->mclk = clk_get_rate(host->clk);\r\nif (host->mclk > variant->f_max) {\r\nret = clk_set_rate(host->clk, variant->f_max);\r\nif (ret < 0)\r\ngoto clk_disable;\r\nhost->mclk = clk_get_rate(host->clk);\r\ndev_dbg(mmc_dev(mmc), "eventual mclk rate: %u Hz\n",\r\nhost->mclk);\r\n}\r\nhost->phybase = dev->res.start;\r\nhost->base = devm_ioremap_resource(&dev->dev, &dev->res);\r\nif (IS_ERR(host->base)) {\r\nret = PTR_ERR(host->base);\r\ngoto clk_disable;\r\n}\r\nif (variant->st_clkdiv)\r\nmmc->f_min = DIV_ROUND_UP(host->mclk, 257);\r\nelse if (variant->explicit_mclk_control)\r\nmmc->f_min = clk_round_rate(host->clk, 100000);\r\nelse\r\nmmc->f_min = DIV_ROUND_UP(host->mclk, 512);\r\nif (mmc->f_max)\r\nmmc->f_max = variant->explicit_mclk_control ?\r\nmin(variant->f_max, mmc->f_max) :\r\nmin(host->mclk, mmc->f_max);\r\nelse\r\nmmc->f_max = variant->explicit_mclk_control ?\r\nfmax : min(host->mclk, fmax);\r\ndev_dbg(mmc_dev(mmc), "clocking block at %u Hz\n", mmc->f_max);\r\nret = mmc_regulator_get_supply(mmc);\r\nif (ret == -EPROBE_DEFER)\r\ngoto clk_disable;\r\nif (!mmc->ocr_avail)\r\nmmc->ocr_avail = plat->ocr_mask;\r\nelse if (plat->ocr_mask)\r\ndev_warn(mmc_dev(mmc), "Platform OCR mask is ignored\n");\r\nif (!np) {\r\nif (!plat->cd_invert)\r\nmmc->caps2 |= MMC_CAP2_CD_ACTIVE_HIGH;\r\nmmc->caps2 |= MMC_CAP2_RO_ACTIVE_HIGH;\r\n}\r\nmmc->caps |= MMC_CAP_CMD23;\r\nif (variant->busy_detect) {\r\nmmci_ops.card_busy = mmci_card_busy;\r\nmmci_write_datactrlreg(host, MCI_ST_DPSM_BUSYMODE);\r\nmmc->caps |= MMC_CAP_WAIT_WHILE_BUSY;\r\nmmc->max_busy_timeout = 0;\r\n}\r\nmmc->ops = &mmci_ops;\r\nmmc->pm_caps |= MMC_PM_KEEP_POWER;\r\nmmc->max_segs = NR_SG;\r\nmmc->max_req_size = (1 << variant->datalength_bits) - 1;\r\nmmc->max_seg_size = mmc->max_req_size;\r\nmmc->max_blk_size = 1 << 11;\r\nmmc->max_blk_count = mmc->max_req_size >> 11;\r\nspin_lock_init(&host->lock);\r\nwritel(0, host->base + MMCIMASK0);\r\nwritel(0, host->base + MMCIMASK1);\r\nwritel(0xfff, host->base + MMCICLEAR);\r\nif (!np) {\r\nret = mmc_gpiod_request_cd(mmc, "cd", 0, false, 0, NULL);\r\nif (ret < 0) {\r\nif (ret == -EPROBE_DEFER)\r\ngoto clk_disable;\r\nelse if (gpio_is_valid(plat->gpio_cd)) {\r\nret = mmc_gpio_request_cd(mmc, plat->gpio_cd, 0);\r\nif (ret)\r\ngoto clk_disable;\r\n}\r\n}\r\nret = mmc_gpiod_request_ro(mmc, "wp", 0, false, 0, NULL);\r\nif (ret < 0) {\r\nif (ret == -EPROBE_DEFER)\r\ngoto clk_disable;\r\nelse if (gpio_is_valid(plat->gpio_wp)) {\r\nret = mmc_gpio_request_ro(mmc, plat->gpio_wp);\r\nif (ret)\r\ngoto clk_disable;\r\n}\r\n}\r\n}\r\nret = devm_request_irq(&dev->dev, dev->irq[0], mmci_irq, IRQF_SHARED,\r\nDRIVER_NAME " (cmd)", host);\r\nif (ret)\r\ngoto clk_disable;\r\nif (!dev->irq[1])\r\nhost->singleirq = true;\r\nelse {\r\nret = devm_request_irq(&dev->dev, dev->irq[1], mmci_pio_irq,\r\nIRQF_SHARED, DRIVER_NAME " (pio)", host);\r\nif (ret)\r\ngoto clk_disable;\r\n}\r\nwritel(MCI_IRQENABLE, host->base + MMCIMASK0);\r\namba_set_drvdata(dev, mmc);\r\ndev_info(&dev->dev, "%s: PL%03x manf %x rev%u at 0x%08llx irq %d,%d (pio)\n",\r\nmmc_hostname(mmc), amba_part(dev), amba_manf(dev),\r\namba_rev(dev), (unsigned long long)dev->res.start,\r\ndev->irq[0], dev->irq[1]);\r\nmmci_dma_setup(host);\r\npm_runtime_set_autosuspend_delay(&dev->dev, 50);\r\npm_runtime_use_autosuspend(&dev->dev);\r\nmmc_add_host(mmc);\r\npm_runtime_put(&dev->dev);\r\nreturn 0;\r\nclk_disable:\r\nclk_disable_unprepare(host->clk);\r\nhost_free:\r\nmmc_free_host(mmc);\r\nreturn ret;\r\n}\r\nstatic int mmci_remove(struct amba_device *dev)\r\n{\r\nstruct mmc_host *mmc = amba_get_drvdata(dev);\r\nif (mmc) {\r\nstruct mmci_host *host = mmc_priv(mmc);\r\npm_runtime_get_sync(&dev->dev);\r\nmmc_remove_host(mmc);\r\nwritel(0, host->base + MMCIMASK0);\r\nwritel(0, host->base + MMCIMASK1);\r\nwritel(0, host->base + MMCICOMMAND);\r\nwritel(0, host->base + MMCIDATACTRL);\r\nmmci_dma_release(host);\r\nclk_disable_unprepare(host->clk);\r\nmmc_free_host(mmc);\r\n}\r\nreturn 0;\r\n}\r\nstatic void mmci_save(struct mmci_host *host)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&host->lock, flags);\r\nwritel(0, host->base + MMCIMASK0);\r\nif (host->variant->pwrreg_nopower) {\r\nwritel(0, host->base + MMCIDATACTRL);\r\nwritel(0, host->base + MMCIPOWER);\r\nwritel(0, host->base + MMCICLOCK);\r\n}\r\nmmci_reg_delay(host);\r\nspin_unlock_irqrestore(&host->lock, flags);\r\n}\r\nstatic void mmci_restore(struct mmci_host *host)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&host->lock, flags);\r\nif (host->variant->pwrreg_nopower) {\r\nwritel(host->clk_reg, host->base + MMCICLOCK);\r\nwritel(host->datactrl_reg, host->base + MMCIDATACTRL);\r\nwritel(host->pwr_reg, host->base + MMCIPOWER);\r\n}\r\nwritel(MCI_IRQENABLE, host->base + MMCIMASK0);\r\nmmci_reg_delay(host);\r\nspin_unlock_irqrestore(&host->lock, flags);\r\n}\r\nstatic int mmci_runtime_suspend(struct device *dev)\r\n{\r\nstruct amba_device *adev = to_amba_device(dev);\r\nstruct mmc_host *mmc = amba_get_drvdata(adev);\r\nif (mmc) {\r\nstruct mmci_host *host = mmc_priv(mmc);\r\npinctrl_pm_select_sleep_state(dev);\r\nmmci_save(host);\r\nclk_disable_unprepare(host->clk);\r\n}\r\nreturn 0;\r\n}\r\nstatic int mmci_runtime_resume(struct device *dev)\r\n{\r\nstruct amba_device *adev = to_amba_device(dev);\r\nstruct mmc_host *mmc = amba_get_drvdata(adev);\r\nif (mmc) {\r\nstruct mmci_host *host = mmc_priv(mmc);\r\nclk_prepare_enable(host->clk);\r\nmmci_restore(host);\r\npinctrl_pm_select_default_state(dev);\r\n}\r\nreturn 0;\r\n}
