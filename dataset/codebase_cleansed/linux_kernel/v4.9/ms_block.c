static size_t msb_sg_copy(struct scatterlist *sg_from,\r\nstruct scatterlist *sg_to, int to_nents, size_t offset, size_t len)\r\n{\r\nsize_t copied = 0;\r\nwhile (offset > 0) {\r\nif (offset >= sg_from->length) {\r\nif (sg_is_last(sg_from))\r\nreturn 0;\r\noffset -= sg_from->length;\r\nsg_from = sg_next(sg_from);\r\ncontinue;\r\n}\r\ncopied = min(len, sg_from->length - offset);\r\nsg_set_page(sg_to, sg_page(sg_from),\r\ncopied, sg_from->offset + offset);\r\nlen -= copied;\r\noffset = 0;\r\nif (sg_is_last(sg_from) || !len)\r\ngoto out;\r\nsg_to = sg_next(sg_to);\r\nto_nents--;\r\nsg_from = sg_next(sg_from);\r\n}\r\nwhile (len > sg_from->length && to_nents--) {\r\nlen -= sg_from->length;\r\ncopied += sg_from->length;\r\nsg_set_page(sg_to, sg_page(sg_from),\r\nsg_from->length, sg_from->offset);\r\nif (sg_is_last(sg_from) || !len)\r\ngoto out;\r\nsg_from = sg_next(sg_from);\r\nsg_to = sg_next(sg_to);\r\n}\r\nif (len && to_nents) {\r\nsg_set_page(sg_to, sg_page(sg_from), len, sg_from->offset);\r\ncopied += len;\r\n}\r\nout:\r\nsg_mark_end(sg_to);\r\nreturn copied;\r\n}\r\nstatic int msb_sg_compare_to_buffer(struct scatterlist *sg,\r\nsize_t offset, u8 *buffer, size_t len)\r\n{\r\nint retval = 0, cmplen;\r\nstruct sg_mapping_iter miter;\r\nsg_miter_start(&miter, sg, sg_nents(sg),\r\nSG_MITER_ATOMIC | SG_MITER_FROM_SG);\r\nwhile (sg_miter_next(&miter) && len > 0) {\r\nif (offset >= miter.length) {\r\noffset -= miter.length;\r\ncontinue;\r\n}\r\ncmplen = min(miter.length - offset, len);\r\nretval = memcmp(miter.addr + offset, buffer, cmplen) ? -1 : 0;\r\nif (retval)\r\nbreak;\r\nbuffer += cmplen;\r\nlen -= cmplen;\r\noffset = 0;\r\n}\r\nif (!retval && len)\r\nretval = -1;\r\nsg_miter_stop(&miter);\r\nreturn retval;\r\n}\r\nstatic int msb_get_zone_from_lba(int lba)\r\n{\r\nif (lba < 494)\r\nreturn 0;\r\nreturn ((lba - 494) / 496) + 1;\r\n}\r\nstatic int msb_get_zone_from_pba(int pba)\r\n{\r\nreturn pba / MS_BLOCKS_IN_ZONE;\r\n}\r\nstatic int msb_validate_used_block_bitmap(struct msb_data *msb)\r\n{\r\nint total_free_blocks = 0;\r\nint i;\r\nif (!debug)\r\nreturn 0;\r\nfor (i = 0; i < msb->zone_count; i++)\r\ntotal_free_blocks += msb->free_block_count[i];\r\nif (msb->block_count - bitmap_weight(msb->used_blocks_bitmap,\r\nmsb->block_count) == total_free_blocks)\r\nreturn 0;\r\npr_err("BUG: free block counts don't match the bitmap");\r\nmsb->read_only = true;\r\nreturn -EINVAL;\r\n}\r\nstatic void msb_mark_block_used(struct msb_data *msb, int pba)\r\n{\r\nint zone = msb_get_zone_from_pba(pba);\r\nif (test_bit(pba, msb->used_blocks_bitmap)) {\r\npr_err(\r\n"BUG: attempt to mark already used pba %d as used", pba);\r\nmsb->read_only = true;\r\nreturn;\r\n}\r\nif (msb_validate_used_block_bitmap(msb))\r\nreturn;\r\n__set_bit(pba, msb->used_blocks_bitmap);\r\nmsb->free_block_count[zone]--;\r\n}\r\nstatic void msb_mark_block_unused(struct msb_data *msb, int pba)\r\n{\r\nint zone = msb_get_zone_from_pba(pba);\r\nif (!test_bit(pba, msb->used_blocks_bitmap)) {\r\npr_err("BUG: attempt to mark already unused pba %d as unused" , pba);\r\nmsb->read_only = true;\r\nreturn;\r\n}\r\nif (msb_validate_used_block_bitmap(msb))\r\nreturn;\r\n__clear_bit(pba, msb->used_blocks_bitmap);\r\nmsb->free_block_count[zone]++;\r\n}\r\nstatic void msb_invalidate_reg_window(struct msb_data *msb)\r\n{\r\nmsb->reg_addr.w_offset = offsetof(struct ms_register, id);\r\nmsb->reg_addr.w_length = sizeof(struct ms_id_register);\r\nmsb->reg_addr.r_offset = offsetof(struct ms_register, id);\r\nmsb->reg_addr.r_length = sizeof(struct ms_id_register);\r\nmsb->addr_valid = false;\r\n}\r\nstatic int msb_run_state_machine(struct msb_data *msb, int (*state_func)\r\n(struct memstick_dev *card, struct memstick_request **req))\r\n{\r\nstruct memstick_dev *card = msb->card;\r\nWARN_ON(msb->state != -1);\r\nmsb->int_polling = false;\r\nmsb->state = 0;\r\nmsb->exit_error = 0;\r\nmemset(&card->current_mrq, 0, sizeof(card->current_mrq));\r\ncard->next_request = state_func;\r\nmemstick_new_req(card->host);\r\nwait_for_completion(&card->mrq_complete);\r\nWARN_ON(msb->state != -1);\r\nreturn msb->exit_error;\r\n}\r\nstatic int msb_exit_state_machine(struct msb_data *msb, int error)\r\n{\r\nWARN_ON(msb->state == -1);\r\nmsb->state = -1;\r\nmsb->exit_error = error;\r\nmsb->card->next_request = h_msb_default_bad;\r\nif (error)\r\nmsb_invalidate_reg_window(msb);\r\ncomplete(&msb->card->mrq_complete);\r\nreturn -ENXIO;\r\n}\r\nstatic int msb_read_int_reg(struct msb_data *msb, long timeout)\r\n{\r\nstruct memstick_request *mrq = &msb->card->current_mrq;\r\nWARN_ON(msb->state == -1);\r\nif (!msb->int_polling) {\r\nmsb->int_timeout = jiffies +\r\nmsecs_to_jiffies(timeout == -1 ? 500 : timeout);\r\nmsb->int_polling = true;\r\n} else if (time_after(jiffies, msb->int_timeout)) {\r\nmrq->data[0] = MEMSTICK_INT_CMDNAK;\r\nreturn 0;\r\n}\r\nif ((msb->caps & MEMSTICK_CAP_AUTO_GET_INT) &&\r\nmrq->need_card_int && !mrq->error) {\r\nmrq->data[0] = mrq->int_reg;\r\nmrq->need_card_int = false;\r\nreturn 0;\r\n} else {\r\nmemstick_init_req(mrq, MS_TPC_GET_INT, NULL, 1);\r\nreturn 1;\r\n}\r\n}\r\nstatic int msb_read_regs(struct msb_data *msb, int offset, int len)\r\n{\r\nstruct memstick_request *req = &msb->card->current_mrq;\r\nif (msb->reg_addr.r_offset != offset ||\r\nmsb->reg_addr.r_length != len || !msb->addr_valid) {\r\nmsb->reg_addr.r_offset = offset;\r\nmsb->reg_addr.r_length = len;\r\nmsb->addr_valid = true;\r\nmemstick_init_req(req, MS_TPC_SET_RW_REG_ADRS,\r\n&msb->reg_addr, sizeof(msb->reg_addr));\r\nreturn 0;\r\n}\r\nmemstick_init_req(req, MS_TPC_READ_REG, NULL, len);\r\nreturn 1;\r\n}\r\nstatic int msb_write_regs(struct msb_data *msb, int offset, int len, void *buf)\r\n{\r\nstruct memstick_request *req = &msb->card->current_mrq;\r\nif (msb->reg_addr.w_offset != offset ||\r\nmsb->reg_addr.w_length != len || !msb->addr_valid) {\r\nmsb->reg_addr.w_offset = offset;\r\nmsb->reg_addr.w_length = len;\r\nmsb->addr_valid = true;\r\nmemstick_init_req(req, MS_TPC_SET_RW_REG_ADRS,\r\n&msb->reg_addr, sizeof(msb->reg_addr));\r\nreturn 0;\r\n}\r\nmemstick_init_req(req, MS_TPC_WRITE_REG, buf, len);\r\nreturn 1;\r\n}\r\nstatic int h_msb_default_bad(struct memstick_dev *card,\r\nstruct memstick_request **mrq)\r\n{\r\nreturn -ENXIO;\r\n}\r\nstatic int h_msb_read_page(struct memstick_dev *card,\r\nstruct memstick_request **out_mrq)\r\n{\r\nstruct msb_data *msb = memstick_get_drvdata(card);\r\nstruct memstick_request *mrq = *out_mrq = &card->current_mrq;\r\nstruct scatterlist sg[2];\r\nu8 command, intreg;\r\nif (mrq->error) {\r\ndbg("read_page, unknown error");\r\nreturn msb_exit_state_machine(msb, mrq->error);\r\n}\r\nagain:\r\nswitch (msb->state) {\r\ncase MSB_RP_SEND_BLOCK_ADDRESS:\r\nif (!msb_write_regs(msb,\r\noffsetof(struct ms_register, param),\r\nsizeof(struct ms_param_register),\r\n(unsigned char *)&msb->regs.param))\r\nreturn 0;\r\nmsb->state = MSB_RP_SEND_READ_COMMAND;\r\nreturn 0;\r\ncase MSB_RP_SEND_READ_COMMAND:\r\ncommand = MS_CMD_BLOCK_READ;\r\nmemstick_init_req(mrq, MS_TPC_SET_CMD, &command, 1);\r\nmsb->state = MSB_RP_SEND_INT_REQ;\r\nreturn 0;\r\ncase MSB_RP_SEND_INT_REQ:\r\nmsb->state = MSB_RP_RECEIVE_INT_REQ_RESULT;\r\nif (msb_read_int_reg(msb, -1))\r\nreturn 0;\r\ncase MSB_RP_RECEIVE_INT_REQ_RESULT:\r\nintreg = mrq->data[0];\r\nmsb->regs.status.interrupt = intreg;\r\nif (intreg & MEMSTICK_INT_CMDNAK)\r\nreturn msb_exit_state_machine(msb, -EIO);\r\nif (!(intreg & MEMSTICK_INT_CED)) {\r\nmsb->state = MSB_RP_SEND_INT_REQ;\r\ngoto again;\r\n}\r\nmsb->int_polling = false;\r\nmsb->state = (intreg & MEMSTICK_INT_ERR) ?\r\nMSB_RP_SEND_READ_STATUS_REG : MSB_RP_SEND_OOB_READ;\r\ngoto again;\r\ncase MSB_RP_SEND_READ_STATUS_REG:\r\nif (!msb_read_regs(msb,\r\noffsetof(struct ms_register, status),\r\nsizeof(struct ms_status_register)))\r\nreturn 0;\r\nmsb->state = MSB_RP_RECEIVE_STATUS_REG;\r\nreturn 0;\r\ncase MSB_RP_RECEIVE_STATUS_REG:\r\nmsb->regs.status = *(struct ms_status_register *)mrq->data;\r\nmsb->state = MSB_RP_SEND_OOB_READ;\r\ncase MSB_RP_SEND_OOB_READ:\r\nif (!msb_read_regs(msb,\r\noffsetof(struct ms_register, extra_data),\r\nsizeof(struct ms_extra_data_register)))\r\nreturn 0;\r\nmsb->state = MSB_RP_RECEIVE_OOB_READ;\r\nreturn 0;\r\ncase MSB_RP_RECEIVE_OOB_READ:\r\nmsb->regs.extra_data =\r\n*(struct ms_extra_data_register *) mrq->data;\r\nmsb->state = MSB_RP_SEND_READ_DATA;\r\ncase MSB_RP_SEND_READ_DATA:\r\nif (msb->regs.param.cp == MEMSTICK_CP_EXTRA) {\r\nmsb->state = MSB_RP_RECEIVE_READ_DATA;\r\ngoto again;\r\n}\r\nsg_init_table(sg, ARRAY_SIZE(sg));\r\nmsb_sg_copy(msb->current_sg, sg, ARRAY_SIZE(sg),\r\nmsb->current_sg_offset,\r\nmsb->page_size);\r\nmemstick_init_req_sg(mrq, MS_TPC_READ_LONG_DATA, sg);\r\nmsb->state = MSB_RP_RECEIVE_READ_DATA;\r\nreturn 0;\r\ncase MSB_RP_RECEIVE_READ_DATA:\r\nif (!(msb->regs.status.interrupt & MEMSTICK_INT_ERR)) {\r\nmsb->current_sg_offset += msb->page_size;\r\nreturn msb_exit_state_machine(msb, 0);\r\n}\r\nif (msb->regs.status.status1 & MEMSTICK_UNCORR_ERROR) {\r\ndbg("read_page: uncorrectable error");\r\nreturn msb_exit_state_machine(msb, -EBADMSG);\r\n}\r\nif (msb->regs.status.status1 & MEMSTICK_CORR_ERROR) {\r\ndbg("read_page: correctable error");\r\nmsb->current_sg_offset += msb->page_size;\r\nreturn msb_exit_state_machine(msb, -EUCLEAN);\r\n} else {\r\ndbg("read_page: INT error, but no status error bits");\r\nreturn msb_exit_state_machine(msb, -EIO);\r\n}\r\n}\r\nBUG();\r\n}\r\nstatic int h_msb_write_block(struct memstick_dev *card,\r\nstruct memstick_request **out_mrq)\r\n{\r\nstruct msb_data *msb = memstick_get_drvdata(card);\r\nstruct memstick_request *mrq = *out_mrq = &card->current_mrq;\r\nstruct scatterlist sg[2];\r\nu8 intreg, command;\r\nif (mrq->error)\r\nreturn msb_exit_state_machine(msb, mrq->error);\r\nagain:\r\nswitch (msb->state) {\r\ncase MSB_WB_SEND_WRITE_PARAMS:\r\nif (!msb_write_regs(msb,\r\noffsetof(struct ms_register, param),\r\nsizeof(struct ms_param_register),\r\n&msb->regs.param))\r\nreturn 0;\r\nmsb->state = MSB_WB_SEND_WRITE_OOB;\r\nreturn 0;\r\ncase MSB_WB_SEND_WRITE_OOB:\r\nif (!msb_write_regs(msb,\r\noffsetof(struct ms_register, extra_data),\r\nsizeof(struct ms_extra_data_register),\r\n&msb->regs.extra_data))\r\nreturn 0;\r\nmsb->state = MSB_WB_SEND_WRITE_COMMAND;\r\nreturn 0;\r\ncase MSB_WB_SEND_WRITE_COMMAND:\r\ncommand = MS_CMD_BLOCK_WRITE;\r\nmemstick_init_req(mrq, MS_TPC_SET_CMD, &command, 1);\r\nmsb->state = MSB_WB_SEND_INT_REQ;\r\nreturn 0;\r\ncase MSB_WB_SEND_INT_REQ:\r\nmsb->state = MSB_WB_RECEIVE_INT_REQ;\r\nif (msb_read_int_reg(msb, -1))\r\nreturn 0;\r\ncase MSB_WB_RECEIVE_INT_REQ:\r\nintreg = mrq->data[0];\r\nmsb->regs.status.interrupt = intreg;\r\nif (intreg & (MEMSTICK_INT_CMDNAK))\r\nreturn msb_exit_state_machine(msb, -EIO);\r\nif (intreg & MEMSTICK_INT_ERR)\r\nreturn msb_exit_state_machine(msb, -EBADMSG);\r\nif (msb->current_page == msb->pages_in_block) {\r\nif (intreg & MEMSTICK_INT_CED)\r\nreturn msb_exit_state_machine(msb, 0);\r\nmsb->state = MSB_WB_SEND_INT_REQ;\r\ngoto again;\r\n}\r\nif (!(intreg & MEMSTICK_INT_BREQ)) {\r\nmsb->state = MSB_WB_SEND_INT_REQ;\r\ngoto again;\r\n}\r\nmsb->int_polling = false;\r\nmsb->state = MSB_WB_SEND_WRITE_DATA;\r\ncase MSB_WB_SEND_WRITE_DATA:\r\nsg_init_table(sg, ARRAY_SIZE(sg));\r\nif (msb_sg_copy(msb->current_sg, sg, ARRAY_SIZE(sg),\r\nmsb->current_sg_offset,\r\nmsb->page_size) < msb->page_size)\r\nreturn msb_exit_state_machine(msb, -EIO);\r\nmemstick_init_req_sg(mrq, MS_TPC_WRITE_LONG_DATA, sg);\r\nmrq->need_card_int = 1;\r\nmsb->state = MSB_WB_RECEIVE_WRITE_CONFIRMATION;\r\nreturn 0;\r\ncase MSB_WB_RECEIVE_WRITE_CONFIRMATION:\r\nmsb->current_page++;\r\nmsb->current_sg_offset += msb->page_size;\r\nmsb->state = MSB_WB_SEND_INT_REQ;\r\ngoto again;\r\ndefault:\r\nBUG();\r\n}\r\nreturn 0;\r\n}\r\nstatic int h_msb_send_command(struct memstick_dev *card,\r\nstruct memstick_request **out_mrq)\r\n{\r\nstruct msb_data *msb = memstick_get_drvdata(card);\r\nstruct memstick_request *mrq = *out_mrq = &card->current_mrq;\r\nu8 intreg;\r\nif (mrq->error) {\r\ndbg("send_command: unknown error");\r\nreturn msb_exit_state_machine(msb, mrq->error);\r\n}\r\nagain:\r\nswitch (msb->state) {\r\ncase MSB_SC_SEND_WRITE_PARAMS:\r\nif (!msb_write_regs(msb,\r\noffsetof(struct ms_register, param),\r\nsizeof(struct ms_param_register),\r\n&msb->regs.param))\r\nreturn 0;\r\nmsb->state = MSB_SC_SEND_WRITE_OOB;\r\nreturn 0;\r\ncase MSB_SC_SEND_WRITE_OOB:\r\nif (!msb->command_need_oob) {\r\nmsb->state = MSB_SC_SEND_COMMAND;\r\ngoto again;\r\n}\r\nif (!msb_write_regs(msb,\r\noffsetof(struct ms_register, extra_data),\r\nsizeof(struct ms_extra_data_register),\r\n&msb->regs.extra_data))\r\nreturn 0;\r\nmsb->state = MSB_SC_SEND_COMMAND;\r\nreturn 0;\r\ncase MSB_SC_SEND_COMMAND:\r\nmemstick_init_req(mrq, MS_TPC_SET_CMD, &msb->command_value, 1);\r\nmsb->state = MSB_SC_SEND_INT_REQ;\r\nreturn 0;\r\ncase MSB_SC_SEND_INT_REQ:\r\nmsb->state = MSB_SC_RECEIVE_INT_REQ;\r\nif (msb_read_int_reg(msb, -1))\r\nreturn 0;\r\ncase MSB_SC_RECEIVE_INT_REQ:\r\nintreg = mrq->data[0];\r\nif (intreg & MEMSTICK_INT_CMDNAK)\r\nreturn msb_exit_state_machine(msb, -EIO);\r\nif (intreg & MEMSTICK_INT_ERR)\r\nreturn msb_exit_state_machine(msb, -EBADMSG);\r\nif (!(intreg & MEMSTICK_INT_CED)) {\r\nmsb->state = MSB_SC_SEND_INT_REQ;\r\ngoto again;\r\n}\r\nreturn msb_exit_state_machine(msb, 0);\r\n}\r\nBUG();\r\n}\r\nstatic int h_msb_reset(struct memstick_dev *card,\r\nstruct memstick_request **out_mrq)\r\n{\r\nu8 command = MS_CMD_RESET;\r\nstruct msb_data *msb = memstick_get_drvdata(card);\r\nstruct memstick_request *mrq = *out_mrq = &card->current_mrq;\r\nif (mrq->error)\r\nreturn msb_exit_state_machine(msb, mrq->error);\r\nswitch (msb->state) {\r\ncase MSB_RS_SEND:\r\nmemstick_init_req(mrq, MS_TPC_SET_CMD, &command, 1);\r\nmrq->need_card_int = 0;\r\nmsb->state = MSB_RS_CONFIRM;\r\nreturn 0;\r\ncase MSB_RS_CONFIRM:\r\nreturn msb_exit_state_machine(msb, 0);\r\n}\r\nBUG();\r\n}\r\nstatic int h_msb_parallel_switch(struct memstick_dev *card,\r\nstruct memstick_request **out_mrq)\r\n{\r\nstruct msb_data *msb = memstick_get_drvdata(card);\r\nstruct memstick_request *mrq = *out_mrq = &card->current_mrq;\r\nstruct memstick_host *host = card->host;\r\nif (mrq->error) {\r\ndbg("parallel_switch: error");\r\nmsb->regs.param.system &= ~MEMSTICK_SYS_PAM;\r\nreturn msb_exit_state_machine(msb, mrq->error);\r\n}\r\nswitch (msb->state) {\r\ncase MSB_PS_SEND_SWITCH_COMMAND:\r\nmsb->regs.param.system |= MEMSTICK_SYS_PAM;\r\nif (!msb_write_regs(msb,\r\noffsetof(struct ms_register, param),\r\n1,\r\n(unsigned char *)&msb->regs.param))\r\nreturn 0;\r\nmsb->state = MSB_PS_SWICH_HOST;\r\nreturn 0;\r\ncase MSB_PS_SWICH_HOST:\r\nhost->set_param(host, MEMSTICK_INTERFACE, MEMSTICK_PAR4);\r\nmemstick_init_req(mrq, MS_TPC_GET_INT, NULL, 1);\r\nmsb->state = MSB_PS_CONFIRM;\r\nreturn 0;\r\ncase MSB_PS_CONFIRM:\r\nreturn msb_exit_state_machine(msb, 0);\r\n}\r\nBUG();\r\n}\r\nstatic int msb_reset(struct msb_data *msb, bool full)\r\n{\r\nbool was_parallel = msb->regs.param.system & MEMSTICK_SYS_PAM;\r\nstruct memstick_dev *card = msb->card;\r\nstruct memstick_host *host = card->host;\r\nint error;\r\nmsb->regs.param.system = MEMSTICK_SYS_BAMD;\r\nif (full) {\r\nerror = host->set_param(host,\r\nMEMSTICK_POWER, MEMSTICK_POWER_OFF);\r\nif (error)\r\ngoto out_error;\r\nmsb_invalidate_reg_window(msb);\r\nerror = host->set_param(host,\r\nMEMSTICK_POWER, MEMSTICK_POWER_ON);\r\nif (error)\r\ngoto out_error;\r\nerror = host->set_param(host,\r\nMEMSTICK_INTERFACE, MEMSTICK_SERIAL);\r\nif (error) {\r\nout_error:\r\ndbg("Failed to reset the host controller");\r\nmsb->read_only = true;\r\nreturn -EFAULT;\r\n}\r\n}\r\nerror = msb_run_state_machine(msb, h_msb_reset);\r\nif (error) {\r\ndbg("Failed to reset the card");\r\nmsb->read_only = true;\r\nreturn -ENODEV;\r\n}\r\nif (was_parallel)\r\nmsb_switch_to_parallel(msb);\r\nreturn 0;\r\n}\r\nstatic int msb_switch_to_parallel(struct msb_data *msb)\r\n{\r\nint error;\r\nerror = msb_run_state_machine(msb, h_msb_parallel_switch);\r\nif (error) {\r\npr_err("Switch to parallel failed");\r\nmsb->regs.param.system &= ~MEMSTICK_SYS_PAM;\r\nmsb_reset(msb, true);\r\nreturn -EFAULT;\r\n}\r\nmsb->caps |= MEMSTICK_CAP_AUTO_GET_INT;\r\nreturn 0;\r\n}\r\nstatic int msb_set_overwrite_flag(struct msb_data *msb,\r\nu16 pba, u8 page, u8 flag)\r\n{\r\nif (msb->read_only)\r\nreturn -EROFS;\r\nmsb->regs.param.block_address = cpu_to_be16(pba);\r\nmsb->regs.param.page_address = page;\r\nmsb->regs.param.cp = MEMSTICK_CP_OVERWRITE;\r\nmsb->regs.extra_data.overwrite_flag = flag;\r\nmsb->command_value = MS_CMD_BLOCK_WRITE;\r\nmsb->command_need_oob = true;\r\ndbg_verbose("changing overwrite flag to %02x for sector %d, page %d",\r\nflag, pba, page);\r\nreturn msb_run_state_machine(msb, h_msb_send_command);\r\n}\r\nstatic int msb_mark_bad(struct msb_data *msb, int pba)\r\n{\r\npr_notice("marking pba %d as bad", pba);\r\nmsb_reset(msb, true);\r\nreturn msb_set_overwrite_flag(\r\nmsb, pba, 0, 0xFF & ~MEMSTICK_OVERWRITE_BKST);\r\n}\r\nstatic int msb_mark_page_bad(struct msb_data *msb, int pba, int page)\r\n{\r\ndbg("marking page %d of pba %d as bad", page, pba);\r\nmsb_reset(msb, true);\r\nreturn msb_set_overwrite_flag(msb,\r\npba, page, ~MEMSTICK_OVERWRITE_PGST0);\r\n}\r\nstatic int msb_erase_block(struct msb_data *msb, u16 pba)\r\n{\r\nint error, try;\r\nif (msb->read_only)\r\nreturn -EROFS;\r\ndbg_verbose("erasing pba %d", pba);\r\nfor (try = 1; try < 3; try++) {\r\nmsb->regs.param.block_address = cpu_to_be16(pba);\r\nmsb->regs.param.page_address = 0;\r\nmsb->regs.param.cp = MEMSTICK_CP_BLOCK;\r\nmsb->command_value = MS_CMD_BLOCK_ERASE;\r\nmsb->command_need_oob = false;\r\nerror = msb_run_state_machine(msb, h_msb_send_command);\r\nif (!error || msb_reset(msb, true))\r\nbreak;\r\n}\r\nif (error) {\r\npr_err("erase failed, marking pba %d as bad", pba);\r\nmsb_mark_bad(msb, pba);\r\n}\r\ndbg_verbose("erase success, marking pba %d as unused", pba);\r\nmsb_mark_block_unused(msb, pba);\r\n__set_bit(pba, msb->erased_blocks_bitmap);\r\nreturn error;\r\n}\r\nstatic int msb_read_page(struct msb_data *msb,\r\nu16 pba, u8 page, struct ms_extra_data_register *extra,\r\nstruct scatterlist *sg, int offset)\r\n{\r\nint try, error;\r\nif (pba == MS_BLOCK_INVALID) {\r\nunsigned long flags;\r\nstruct sg_mapping_iter miter;\r\nsize_t len = msb->page_size;\r\ndbg_verbose("read unmapped sector. returning 0xFF");\r\nlocal_irq_save(flags);\r\nsg_miter_start(&miter, sg, sg_nents(sg),\r\nSG_MITER_ATOMIC | SG_MITER_TO_SG);\r\nwhile (sg_miter_next(&miter) && len > 0) {\r\nint chunklen;\r\nif (offset && offset >= miter.length) {\r\noffset -= miter.length;\r\ncontinue;\r\n}\r\nchunklen = min(miter.length - offset, len);\r\nmemset(miter.addr + offset, 0xFF, chunklen);\r\nlen -= chunklen;\r\noffset = 0;\r\n}\r\nsg_miter_stop(&miter);\r\nlocal_irq_restore(flags);\r\nif (offset)\r\nreturn -EFAULT;\r\nif (extra)\r\nmemset(extra, 0xFF, sizeof(*extra));\r\nreturn 0;\r\n}\r\nif (pba >= msb->block_count) {\r\npr_err("BUG: attempt to read beyond the end of the card at pba %d", pba);\r\nreturn -EINVAL;\r\n}\r\nfor (try = 1; try < 3; try++) {\r\nmsb->regs.param.block_address = cpu_to_be16(pba);\r\nmsb->regs.param.page_address = page;\r\nmsb->regs.param.cp = MEMSTICK_CP_PAGE;\r\nmsb->current_sg = sg;\r\nmsb->current_sg_offset = offset;\r\nerror = msb_run_state_machine(msb, h_msb_read_page);\r\nif (error == -EUCLEAN) {\r\npr_notice("correctable error on pba %d, page %d",\r\npba, page);\r\nerror = 0;\r\n}\r\nif (!error && extra)\r\n*extra = msb->regs.extra_data;\r\nif (!error || msb_reset(msb, true))\r\nbreak;\r\n}\r\nif (error == -EBADMSG) {\r\npr_err("uncorrectable error on read of pba %d, page %d",\r\npba, page);\r\nif (msb->regs.extra_data.overwrite_flag &\r\nMEMSTICK_OVERWRITE_PGST0)\r\nmsb_mark_page_bad(msb, pba, page);\r\nreturn -EBADMSG;\r\n}\r\nif (error)\r\npr_err("read of pba %d, page %d failed with error %d",\r\npba, page, error);\r\nreturn error;\r\n}\r\nstatic int msb_read_oob(struct msb_data *msb, u16 pba, u16 page,\r\nstruct ms_extra_data_register *extra)\r\n{\r\nint error;\r\nBUG_ON(!extra);\r\nmsb->regs.param.block_address = cpu_to_be16(pba);\r\nmsb->regs.param.page_address = page;\r\nmsb->regs.param.cp = MEMSTICK_CP_EXTRA;\r\nif (pba > msb->block_count) {\r\npr_err("BUG: attempt to read beyond the end of card at pba %d", pba);\r\nreturn -EINVAL;\r\n}\r\nerror = msb_run_state_machine(msb, h_msb_read_page);\r\n*extra = msb->regs.extra_data;\r\nif (error == -EUCLEAN) {\r\npr_notice("correctable error on pba %d, page %d",\r\npba, page);\r\nreturn 0;\r\n}\r\nreturn error;\r\n}\r\nstatic int msb_verify_block(struct msb_data *msb, u16 pba,\r\nstruct scatterlist *orig_sg, int offset)\r\n{\r\nstruct scatterlist sg;\r\nint page = 0, error;\r\nsg_init_one(&sg, msb->block_buffer, msb->block_size);\r\nwhile (page < msb->pages_in_block) {\r\nerror = msb_read_page(msb, pba, page,\r\nNULL, &sg, page * msb->page_size);\r\nif (error)\r\nreturn error;\r\npage++;\r\n}\r\nif (msb_sg_compare_to_buffer(orig_sg, offset,\r\nmsb->block_buffer, msb->block_size))\r\nreturn -EIO;\r\nreturn 0;\r\n}\r\nstatic int msb_write_block(struct msb_data *msb,\r\nu16 pba, u32 lba, struct scatterlist *sg, int offset)\r\n{\r\nint error, current_try = 1;\r\nBUG_ON(sg->length < msb->page_size);\r\nif (msb->read_only)\r\nreturn -EROFS;\r\nif (pba == MS_BLOCK_INVALID) {\r\npr_err(\r\n"BUG: write: attempt to write MS_BLOCK_INVALID block");\r\nreturn -EINVAL;\r\n}\r\nif (pba >= msb->block_count || lba >= msb->logical_block_count) {\r\npr_err(\r\n"BUG: write: attempt to write beyond the end of device");\r\nreturn -EINVAL;\r\n}\r\nif (msb_get_zone_from_lba(lba) != msb_get_zone_from_pba(pba)) {\r\npr_err("BUG: write: lba zone mismatch");\r\nreturn -EINVAL;\r\n}\r\nif (pba == msb->boot_block_locations[0] ||\r\npba == msb->boot_block_locations[1]) {\r\npr_err("BUG: write: attempt to write to boot blocks!");\r\nreturn -EINVAL;\r\n}\r\nwhile (1) {\r\nif (msb->read_only)\r\nreturn -EROFS;\r\nmsb->regs.param.cp = MEMSTICK_CP_BLOCK;\r\nmsb->regs.param.page_address = 0;\r\nmsb->regs.param.block_address = cpu_to_be16(pba);\r\nmsb->regs.extra_data.management_flag = 0xFF;\r\nmsb->regs.extra_data.overwrite_flag = 0xF8;\r\nmsb->regs.extra_data.logical_address = cpu_to_be16(lba);\r\nmsb->current_sg = sg;\r\nmsb->current_sg_offset = offset;\r\nmsb->current_page = 0;\r\nerror = msb_run_state_machine(msb, h_msb_write_block);\r\nif (!error && (verify_writes ||\r\n!test_bit(pba, msb->erased_blocks_bitmap)))\r\nerror = msb_verify_block(msb, pba, sg, offset);\r\nif (!error)\r\nbreak;\r\nif (current_try > 1 || msb_reset(msb, true))\r\nbreak;\r\npr_err("write failed, trying to erase the pba %d", pba);\r\nerror = msb_erase_block(msb, pba);\r\nif (error)\r\nbreak;\r\ncurrent_try++;\r\n}\r\nreturn error;\r\n}\r\nstatic u16 msb_get_free_block(struct msb_data *msb, int zone)\r\n{\r\nu16 pos;\r\nint pba = zone * MS_BLOCKS_IN_ZONE;\r\nint i;\r\nget_random_bytes(&pos, sizeof(pos));\r\nif (!msb->free_block_count[zone]) {\r\npr_err("NO free blocks in the zone %d, to use for a write, (media is WORN out) switching to RO mode", zone);\r\nmsb->read_only = true;\r\nreturn MS_BLOCK_INVALID;\r\n}\r\npos %= msb->free_block_count[zone];\r\ndbg_verbose("have %d choices for a free block, selected randomally: %d",\r\nmsb->free_block_count[zone], pos);\r\npba = find_next_zero_bit(msb->used_blocks_bitmap,\r\nmsb->block_count, pba);\r\nfor (i = 0; i < pos; ++i)\r\npba = find_next_zero_bit(msb->used_blocks_bitmap,\r\nmsb->block_count, pba + 1);\r\ndbg_verbose("result of the free blocks scan: pba %d", pba);\r\nif (pba == msb->block_count || (msb_get_zone_from_pba(pba)) != zone) {\r\npr_err("BUG: cant get a free block");\r\nmsb->read_only = true;\r\nreturn MS_BLOCK_INVALID;\r\n}\r\nmsb_mark_block_used(msb, pba);\r\nreturn pba;\r\n}\r\nstatic int msb_update_block(struct msb_data *msb, u16 lba,\r\nstruct scatterlist *sg, int offset)\r\n{\r\nu16 pba, new_pba;\r\nint error, try;\r\npba = msb->lba_to_pba_table[lba];\r\ndbg_verbose("start of a block update at lba %d, pba %d", lba, pba);\r\nif (pba != MS_BLOCK_INVALID) {\r\ndbg_verbose("setting the update flag on the block");\r\nmsb_set_overwrite_flag(msb, pba, 0,\r\n0xFF & ~MEMSTICK_OVERWRITE_UDST);\r\n}\r\nfor (try = 0; try < 3; try++) {\r\nnew_pba = msb_get_free_block(msb,\r\nmsb_get_zone_from_lba(lba));\r\nif (new_pba == MS_BLOCK_INVALID) {\r\nerror = -EIO;\r\ngoto out;\r\n}\r\ndbg_verbose("block update: writing updated block to the pba %d",\r\nnew_pba);\r\nerror = msb_write_block(msb, new_pba, lba, sg, offset);\r\nif (error == -EBADMSG) {\r\nmsb_mark_bad(msb, new_pba);\r\ncontinue;\r\n}\r\nif (error)\r\ngoto out;\r\ndbg_verbose("block update: erasing the old block");\r\nmsb_erase_block(msb, pba);\r\nmsb->lba_to_pba_table[lba] = new_pba;\r\nreturn 0;\r\n}\r\nout:\r\nif (error) {\r\npr_err("block update error after %d tries, switching to r/o mode", try);\r\nmsb->read_only = true;\r\n}\r\nreturn error;\r\n}\r\nstatic void msb_fix_boot_page_endianness(struct ms_boot_page *p)\r\n{\r\np->header.block_id = be16_to_cpu(p->header.block_id);\r\np->header.format_reserved = be16_to_cpu(p->header.format_reserved);\r\np->entry.disabled_block.start_addr\r\n= be32_to_cpu(p->entry.disabled_block.start_addr);\r\np->entry.disabled_block.data_size\r\n= be32_to_cpu(p->entry.disabled_block.data_size);\r\np->entry.cis_idi.start_addr\r\n= be32_to_cpu(p->entry.cis_idi.start_addr);\r\np->entry.cis_idi.data_size\r\n= be32_to_cpu(p->entry.cis_idi.data_size);\r\np->attr.block_size = be16_to_cpu(p->attr.block_size);\r\np->attr.number_of_blocks = be16_to_cpu(p->attr.number_of_blocks);\r\np->attr.number_of_effective_blocks\r\n= be16_to_cpu(p->attr.number_of_effective_blocks);\r\np->attr.page_size = be16_to_cpu(p->attr.page_size);\r\np->attr.memory_manufacturer_code\r\n= be16_to_cpu(p->attr.memory_manufacturer_code);\r\np->attr.memory_device_code = be16_to_cpu(p->attr.memory_device_code);\r\np->attr.implemented_capacity\r\n= be16_to_cpu(p->attr.implemented_capacity);\r\np->attr.controller_number = be16_to_cpu(p->attr.controller_number);\r\np->attr.controller_function = be16_to_cpu(p->attr.controller_function);\r\n}\r\nstatic int msb_read_boot_blocks(struct msb_data *msb)\r\n{\r\nint pba = 0;\r\nstruct scatterlist sg;\r\nstruct ms_extra_data_register extra;\r\nstruct ms_boot_page *page;\r\nmsb->boot_block_locations[0] = MS_BLOCK_INVALID;\r\nmsb->boot_block_locations[1] = MS_BLOCK_INVALID;\r\nmsb->boot_block_count = 0;\r\ndbg_verbose("Start of a scan for the boot blocks");\r\nif (!msb->boot_page) {\r\npage = kmalloc(sizeof(struct ms_boot_page)*2, GFP_KERNEL);\r\nif (!page)\r\nreturn -ENOMEM;\r\nmsb->boot_page = page;\r\n} else\r\npage = msb->boot_page;\r\nmsb->block_count = MS_BLOCK_MAX_BOOT_ADDR;\r\nfor (pba = 0; pba < MS_BLOCK_MAX_BOOT_ADDR; pba++) {\r\nsg_init_one(&sg, page, sizeof(*page));\r\nif (msb_read_page(msb, pba, 0, &extra, &sg, 0)) {\r\ndbg("boot scan: can't read pba %d", pba);\r\ncontinue;\r\n}\r\nif (extra.management_flag & MEMSTICK_MANAGEMENT_SYSFLG) {\r\ndbg("management flag doesn't indicate boot block %d",\r\npba);\r\ncontinue;\r\n}\r\nif (be16_to_cpu(page->header.block_id) != MS_BLOCK_BOOT_ID) {\r\ndbg("the pba at %d doesn' contain boot block ID", pba);\r\ncontinue;\r\n}\r\nmsb_fix_boot_page_endianness(page);\r\nmsb->boot_block_locations[msb->boot_block_count] = pba;\r\npage++;\r\nmsb->boot_block_count++;\r\nif (msb->boot_block_count == 2)\r\nbreak;\r\n}\r\nif (!msb->boot_block_count) {\r\npr_err("media doesn't contain master page, aborting");\r\nreturn -EIO;\r\n}\r\ndbg_verbose("End of scan for boot blocks");\r\nreturn 0;\r\n}\r\nstatic int msb_read_bad_block_table(struct msb_data *msb, int block_nr)\r\n{\r\nstruct ms_boot_page *boot_block;\r\nstruct scatterlist sg;\r\nu16 *buffer = NULL;\r\nint offset = 0;\r\nint i, error = 0;\r\nint data_size, data_offset, page, page_offset, size_to_read;\r\nu16 pba;\r\nBUG_ON(block_nr > 1);\r\nboot_block = &msb->boot_page[block_nr];\r\npba = msb->boot_block_locations[block_nr];\r\nif (msb->boot_block_locations[block_nr] == MS_BLOCK_INVALID)\r\nreturn -EINVAL;\r\ndata_size = boot_block->entry.disabled_block.data_size;\r\ndata_offset = sizeof(struct ms_boot_page) +\r\nboot_block->entry.disabled_block.start_addr;\r\nif (!data_size)\r\nreturn 0;\r\npage = data_offset / msb->page_size;\r\npage_offset = data_offset % msb->page_size;\r\nsize_to_read =\r\nDIV_ROUND_UP(data_size + page_offset, msb->page_size) *\r\nmsb->page_size;\r\ndbg("reading bad block of boot block at pba %d, offset %d len %d",\r\npba, data_offset, data_size);\r\nbuffer = kzalloc(size_to_read, GFP_KERNEL);\r\nif (!buffer)\r\nreturn -ENOMEM;\r\nsg_init_one(&sg, buffer, size_to_read);\r\nwhile (offset < size_to_read) {\r\nerror = msb_read_page(msb, pba, page, NULL, &sg, offset);\r\nif (error)\r\ngoto out;\r\npage++;\r\noffset += msb->page_size;\r\nif (page == msb->pages_in_block) {\r\npr_err(\r\n"bad block table extends beyond the boot block");\r\nbreak;\r\n}\r\n}\r\nfor (i = page_offset; i < data_size / sizeof(u16); i++) {\r\nu16 bad_block = be16_to_cpu(buffer[i]);\r\nif (bad_block >= msb->block_count) {\r\ndbg("bad block table contains invalid block %d",\r\nbad_block);\r\ncontinue;\r\n}\r\nif (test_bit(bad_block, msb->used_blocks_bitmap)) {\r\ndbg("duplicate bad block %d in the table",\r\nbad_block);\r\ncontinue;\r\n}\r\ndbg("block %d is marked as factory bad", bad_block);\r\nmsb_mark_block_used(msb, bad_block);\r\n}\r\nout:\r\nkfree(buffer);\r\nreturn error;\r\n}\r\nstatic int msb_ftl_initialize(struct msb_data *msb)\r\n{\r\nint i;\r\nif (msb->ftl_initialized)\r\nreturn 0;\r\nmsb->zone_count = msb->block_count / MS_BLOCKS_IN_ZONE;\r\nmsb->logical_block_count = msb->zone_count * 496 - 2;\r\nmsb->used_blocks_bitmap = kzalloc(msb->block_count / 8, GFP_KERNEL);\r\nmsb->erased_blocks_bitmap = kzalloc(msb->block_count / 8, GFP_KERNEL);\r\nmsb->lba_to_pba_table =\r\nkmalloc(msb->logical_block_count * sizeof(u16), GFP_KERNEL);\r\nif (!msb->used_blocks_bitmap || !msb->lba_to_pba_table ||\r\n!msb->erased_blocks_bitmap) {\r\nkfree(msb->used_blocks_bitmap);\r\nkfree(msb->lba_to_pba_table);\r\nkfree(msb->erased_blocks_bitmap);\r\nreturn -ENOMEM;\r\n}\r\nfor (i = 0; i < msb->zone_count; i++)\r\nmsb->free_block_count[i] = MS_BLOCKS_IN_ZONE;\r\nmemset(msb->lba_to_pba_table, MS_BLOCK_INVALID,\r\nmsb->logical_block_count * sizeof(u16));\r\ndbg("initial FTL tables created. Zone count = %d, Logical block count = %d",\r\nmsb->zone_count, msb->logical_block_count);\r\nmsb->ftl_initialized = true;\r\nreturn 0;\r\n}\r\nstatic int msb_ftl_scan(struct msb_data *msb)\r\n{\r\nu16 pba, lba, other_block;\r\nu8 overwrite_flag, management_flag, other_overwrite_flag;\r\nint error;\r\nstruct ms_extra_data_register extra;\r\nu8 *overwrite_flags = kzalloc(msb->block_count, GFP_KERNEL);\r\nif (!overwrite_flags)\r\nreturn -ENOMEM;\r\ndbg("Start of media scanning");\r\nfor (pba = 0; pba < msb->block_count; pba++) {\r\nif (pba == msb->boot_block_locations[0] ||\r\npba == msb->boot_block_locations[1]) {\r\ndbg_verbose("pba %05d -> [boot block]", pba);\r\nmsb_mark_block_used(msb, pba);\r\ncontinue;\r\n}\r\nif (test_bit(pba, msb->used_blocks_bitmap)) {\r\ndbg_verbose("pba %05d -> [factory bad]", pba);\r\ncontinue;\r\n}\r\nmemset(&extra, 0, sizeof(extra));\r\nerror = msb_read_oob(msb, pba, 0, &extra);\r\nif (error == -EBADMSG) {\r\npr_notice(\r\n"oob of pba %d damaged, will try to erase it", pba);\r\nmsb_mark_block_used(msb, pba);\r\nmsb_erase_block(msb, pba);\r\ncontinue;\r\n} else if (error) {\r\npr_err("unknown error %d on read of oob of pba %d - aborting",\r\nerror, pba);\r\nkfree(overwrite_flags);\r\nreturn error;\r\n}\r\nlba = be16_to_cpu(extra.logical_address);\r\nmanagement_flag = extra.management_flag;\r\noverwrite_flag = extra.overwrite_flag;\r\noverwrite_flags[pba] = overwrite_flag;\r\nif (!(overwrite_flag & MEMSTICK_OVERWRITE_BKST)) {\r\ndbg("pba %05d -> [BAD]", pba);\r\nmsb_mark_block_used(msb, pba);\r\ncontinue;\r\n}\r\nif ((management_flag & MEMSTICK_MANAGEMENT_FLAG_NORMAL) !=\r\nMEMSTICK_MANAGEMENT_FLAG_NORMAL) {\r\ndbg("pba %05d -> [reserved management flag %02x]",\r\npba, management_flag);\r\nmsb_mark_block_used(msb, pba);\r\ncontinue;\r\n}\r\nif (!(management_flag & MEMSTICK_MANAGEMENT_ATFLG)) {\r\ndbg("pba %05d -> [temp table] - will erase", pba);\r\nmsb_mark_block_used(msb, pba);\r\nmsb_erase_block(msb, pba);\r\ncontinue;\r\n}\r\nif (lba == MS_BLOCK_INVALID) {\r\ndbg_verbose("pba %05d -> [free]", pba);\r\ncontinue;\r\n}\r\nmsb_mark_block_used(msb, pba);\r\nif (msb_get_zone_from_lba(lba) != msb_get_zone_from_pba(pba)) {\r\npr_notice("pba %05d -> [bad lba %05d] - will erase",\r\npba, lba);\r\nmsb_erase_block(msb, pba);\r\ncontinue;\r\n}\r\nif (msb->lba_to_pba_table[lba] == MS_BLOCK_INVALID) {\r\ndbg_verbose("pba %05d -> [lba %05d]", pba, lba);\r\nmsb->lba_to_pba_table[lba] = pba;\r\ncontinue;\r\n}\r\nother_block = msb->lba_to_pba_table[lba];\r\nother_overwrite_flag = overwrite_flags[other_block];\r\npr_notice("Collision between pba %d and pba %d",\r\npba, other_block);\r\nif (!(overwrite_flag & MEMSTICK_OVERWRITE_UDST)) {\r\npr_notice("pba %d is marked as stable, use it", pba);\r\nmsb_erase_block(msb, other_block);\r\nmsb->lba_to_pba_table[lba] = pba;\r\ncontinue;\r\n}\r\nif (!(other_overwrite_flag & MEMSTICK_OVERWRITE_UDST)) {\r\npr_notice("pba %d is marked as stable, use it",\r\nother_block);\r\nmsb_erase_block(msb, pba);\r\ncontinue;\r\n}\r\npr_notice("collision between blocks %d and %d, without stable flag set on both, erasing pba %d",\r\npba, other_block, other_block);\r\nmsb_erase_block(msb, other_block);\r\nmsb->lba_to_pba_table[lba] = pba;\r\n}\r\ndbg("End of media scanning");\r\nkfree(overwrite_flags);\r\nreturn 0;\r\n}\r\nstatic void msb_cache_flush_timer(unsigned long data)\r\n{\r\nstruct msb_data *msb = (struct msb_data *)data;\r\nmsb->need_flush_cache = true;\r\nqueue_work(msb->io_queue, &msb->io_work);\r\n}\r\nstatic void msb_cache_discard(struct msb_data *msb)\r\n{\r\nif (msb->cache_block_lba == MS_BLOCK_INVALID)\r\nreturn;\r\ndel_timer_sync(&msb->cache_flush_timer);\r\ndbg_verbose("Discarding the write cache");\r\nmsb->cache_block_lba = MS_BLOCK_INVALID;\r\nbitmap_zero(&msb->valid_cache_bitmap, msb->pages_in_block);\r\n}\r\nstatic int msb_cache_init(struct msb_data *msb)\r\n{\r\nsetup_timer(&msb->cache_flush_timer, msb_cache_flush_timer,\r\n(unsigned long)msb);\r\nif (!msb->cache)\r\nmsb->cache = kzalloc(msb->block_size, GFP_KERNEL);\r\nif (!msb->cache)\r\nreturn -ENOMEM;\r\nmsb_cache_discard(msb);\r\nreturn 0;\r\n}\r\nstatic int msb_cache_flush(struct msb_data *msb)\r\n{\r\nstruct scatterlist sg;\r\nstruct ms_extra_data_register extra;\r\nint page, offset, error;\r\nu16 pba, lba;\r\nif (msb->read_only)\r\nreturn -EROFS;\r\nif (msb->cache_block_lba == MS_BLOCK_INVALID)\r\nreturn 0;\r\nlba = msb->cache_block_lba;\r\npba = msb->lba_to_pba_table[lba];\r\ndbg_verbose("Flushing the write cache of pba %d (LBA %d)",\r\npba, msb->cache_block_lba);\r\nsg_init_one(&sg, msb->cache , msb->block_size);\r\nfor (page = 0; page < msb->pages_in_block; page++) {\r\nif (test_bit(page, &msb->valid_cache_bitmap))\r\ncontinue;\r\noffset = page * msb->page_size;\r\ndbg_verbose("reading non-present sector %d of cache block %d",\r\npage, lba);\r\nerror = msb_read_page(msb, pba, page, &extra, &sg, offset);\r\nif (error == -EBADMSG) {\r\npr_err("read error on sector %d, contents probably damaged", page);\r\ncontinue;\r\n}\r\nif (error)\r\nreturn error;\r\nif ((extra.overwrite_flag & MEMSTICK_OV_PG_NORMAL) !=\r\nMEMSTICK_OV_PG_NORMAL) {\r\ndbg("page %d is marked as bad", page);\r\ncontinue;\r\n}\r\nset_bit(page, &msb->valid_cache_bitmap);\r\n}\r\nerror = msb_update_block(msb, msb->cache_block_lba, &sg, 0);\r\npba = msb->lba_to_pba_table[msb->cache_block_lba];\r\nif (!error) {\r\nfor (page = 0; page < msb->pages_in_block; page++) {\r\nif (test_bit(page, &msb->valid_cache_bitmap))\r\ncontinue;\r\ndbg("marking page %d as containing damaged data",\r\npage);\r\nmsb_set_overwrite_flag(msb,\r\npba , page, 0xFF & ~MEMSTICK_OV_PG_NORMAL);\r\n}\r\n}\r\nmsb_cache_discard(msb);\r\nreturn error;\r\n}\r\nstatic int msb_cache_write(struct msb_data *msb, int lba,\r\nint page, bool add_to_cache_only, struct scatterlist *sg, int offset)\r\n{\r\nint error;\r\nstruct scatterlist sg_tmp[10];\r\nif (msb->read_only)\r\nreturn -EROFS;\r\nif (msb->cache_block_lba == MS_BLOCK_INVALID ||\r\nlba != msb->cache_block_lba)\r\nif (add_to_cache_only)\r\nreturn 0;\r\nif (msb->cache_block_lba != MS_BLOCK_INVALID &&\r\nlba != msb->cache_block_lba) {\r\ndbg_verbose("first flush the cache");\r\nerror = msb_cache_flush(msb);\r\nif (error)\r\nreturn error;\r\n}\r\nif (msb->cache_block_lba == MS_BLOCK_INVALID) {\r\nmsb->cache_block_lba = lba;\r\nmod_timer(&msb->cache_flush_timer,\r\njiffies + msecs_to_jiffies(cache_flush_timeout));\r\n}\r\ndbg_verbose("Write of LBA %d page %d to cache ", lba, page);\r\nsg_init_table(sg_tmp, ARRAY_SIZE(sg_tmp));\r\nmsb_sg_copy(sg, sg_tmp, ARRAY_SIZE(sg_tmp), offset, msb->page_size);\r\nsg_copy_to_buffer(sg_tmp, sg_nents(sg_tmp),\r\nmsb->cache + page * msb->page_size, msb->page_size);\r\nset_bit(page, &msb->valid_cache_bitmap);\r\nreturn 0;\r\n}\r\nstatic int msb_cache_read(struct msb_data *msb, int lba,\r\nint page, struct scatterlist *sg, int offset)\r\n{\r\nint pba = msb->lba_to_pba_table[lba];\r\nstruct scatterlist sg_tmp[10];\r\nint error = 0;\r\nif (lba == msb->cache_block_lba &&\r\ntest_bit(page, &msb->valid_cache_bitmap)) {\r\ndbg_verbose("Read of LBA %d (pba %d) sector %d from cache",\r\nlba, pba, page);\r\nsg_init_table(sg_tmp, ARRAY_SIZE(sg_tmp));\r\nmsb_sg_copy(sg, sg_tmp, ARRAY_SIZE(sg_tmp),\r\noffset, msb->page_size);\r\nsg_copy_from_buffer(sg_tmp, sg_nents(sg_tmp),\r\nmsb->cache + msb->page_size * page,\r\nmsb->page_size);\r\n} else {\r\ndbg_verbose("Read of LBA %d (pba %d) sector %d from device",\r\nlba, pba, page);\r\nerror = msb_read_page(msb, pba, page, NULL, sg, offset);\r\nif (error)\r\nreturn error;\r\nmsb_cache_write(msb, lba, page, true, sg, offset);\r\n}\r\nreturn error;\r\n}\r\nstatic int msb_init_card(struct memstick_dev *card)\r\n{\r\nstruct msb_data *msb = memstick_get_drvdata(card);\r\nstruct memstick_host *host = card->host;\r\nstruct ms_boot_page *boot_block;\r\nint error = 0, i, raw_size_in_megs;\r\nmsb->caps = 0;\r\nif (card->id.class >= MEMSTICK_CLASS_ROM &&\r\ncard->id.class <= MEMSTICK_CLASS_ROM)\r\nmsb->read_only = true;\r\nmsb->state = -1;\r\nerror = msb_reset(msb, false);\r\nif (error)\r\nreturn error;\r\nif (host->caps & MEMSTICK_CAP_PAR4)\r\nmsb_switch_to_parallel(msb);\r\nmsb->page_size = sizeof(struct ms_boot_page);\r\nerror = msb_read_boot_blocks(msb);\r\nif (error)\r\nreturn -EIO;\r\nboot_block = &msb->boot_page[0];\r\nmsb->block_count = boot_block->attr.number_of_blocks;\r\nmsb->page_size = boot_block->attr.page_size;\r\nmsb->pages_in_block = boot_block->attr.block_size * 2;\r\nmsb->block_size = msb->page_size * msb->pages_in_block;\r\nif (msb->page_size > PAGE_SIZE) {\r\ndbg("device page %d size isn't supported", msb->page_size);\r\nreturn -EINVAL;\r\n}\r\nmsb->block_buffer = kzalloc(msb->block_size, GFP_KERNEL);\r\nif (!msb->block_buffer)\r\nreturn -ENOMEM;\r\nraw_size_in_megs = (msb->block_size * msb->block_count) >> 20;\r\nfor (i = 0; chs_table[i].size; i++) {\r\nif (chs_table[i].size != raw_size_in_megs)\r\ncontinue;\r\nmsb->geometry.cylinders = chs_table[i].cyl;\r\nmsb->geometry.heads = chs_table[i].head;\r\nmsb->geometry.sectors = chs_table[i].sec;\r\nbreak;\r\n}\r\nif (boot_block->attr.transfer_supporting == 1)\r\nmsb->caps |= MEMSTICK_CAP_PAR4;\r\nif (boot_block->attr.device_type & 0x03)\r\nmsb->read_only = true;\r\ndbg("Total block count = %d", msb->block_count);\r\ndbg("Each block consists of %d pages", msb->pages_in_block);\r\ndbg("Page size = %d bytes", msb->page_size);\r\ndbg("Parallel mode supported: %d", !!(msb->caps & MEMSTICK_CAP_PAR4));\r\ndbg("Read only: %d", msb->read_only);\r\n#if 0\r\nif (host->caps & msb->caps & MEMSTICK_CAP_PAR4)\r\nmsb_switch_to_parallel(msb);\r\n#endif\r\nerror = msb_cache_init(msb);\r\nif (error)\r\nreturn error;\r\nerror = msb_ftl_initialize(msb);\r\nif (error)\r\nreturn error;\r\nerror = msb_read_bad_block_table(msb, 0);\r\nif (error && error != -ENOMEM) {\r\ndbg("failed to read bad block table from primary boot block, trying from backup");\r\nerror = msb_read_bad_block_table(msb, 1);\r\n}\r\nif (error)\r\nreturn error;\r\nerror = msb_ftl_scan(msb);\r\nif (error) {\r\npr_err("Scan of media failed");\r\nreturn error;\r\n}\r\nreturn 0;\r\n}\r\nstatic int msb_do_write_request(struct msb_data *msb, int lba,\r\nint page, struct scatterlist *sg, size_t len, int *sucessfuly_written)\r\n{\r\nint error = 0;\r\noff_t offset = 0;\r\n*sucessfuly_written = 0;\r\nwhile (offset < len) {\r\nif (page == 0 && len - offset >= msb->block_size) {\r\nif (msb->cache_block_lba == lba)\r\nmsb_cache_discard(msb);\r\ndbg_verbose("Writing whole lba %d", lba);\r\nerror = msb_update_block(msb, lba, sg, offset);\r\nif (error)\r\nreturn error;\r\noffset += msb->block_size;\r\n*sucessfuly_written += msb->block_size;\r\nlba++;\r\ncontinue;\r\n}\r\nerror = msb_cache_write(msb, lba, page, false, sg, offset);\r\nif (error)\r\nreturn error;\r\noffset += msb->page_size;\r\n*sucessfuly_written += msb->page_size;\r\npage++;\r\nif (page == msb->pages_in_block) {\r\npage = 0;\r\nlba++;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int msb_do_read_request(struct msb_data *msb, int lba,\r\nint page, struct scatterlist *sg, int len, int *sucessfuly_read)\r\n{\r\nint error = 0;\r\nint offset = 0;\r\n*sucessfuly_read = 0;\r\nwhile (offset < len) {\r\nerror = msb_cache_read(msb, lba, page, sg, offset);\r\nif (error)\r\nreturn error;\r\noffset += msb->page_size;\r\n*sucessfuly_read += msb->page_size;\r\npage++;\r\nif (page == msb->pages_in_block) {\r\npage = 0;\r\nlba++;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void msb_io_work(struct work_struct *work)\r\n{\r\nstruct msb_data *msb = container_of(work, struct msb_data, io_work);\r\nint page, error, len;\r\nsector_t lba;\r\nunsigned long flags;\r\nstruct scatterlist *sg = msb->prealloc_sg;\r\ndbg_verbose("IO: work started");\r\nwhile (1) {\r\nspin_lock_irqsave(&msb->q_lock, flags);\r\nif (msb->need_flush_cache) {\r\nmsb->need_flush_cache = false;\r\nspin_unlock_irqrestore(&msb->q_lock, flags);\r\nmsb_cache_flush(msb);\r\ncontinue;\r\n}\r\nif (!msb->req) {\r\nmsb->req = blk_fetch_request(msb->queue);\r\nif (!msb->req) {\r\ndbg_verbose("IO: no more requests exiting");\r\nspin_unlock_irqrestore(&msb->q_lock, flags);\r\nreturn;\r\n}\r\n}\r\nspin_unlock_irqrestore(&msb->q_lock, flags);\r\nif (!msb->req)\r\nreturn;\r\ndbg_verbose("IO: processing new request");\r\nblk_rq_map_sg(msb->queue, msb->req, sg);\r\nlba = blk_rq_pos(msb->req);\r\nsector_div(lba, msb->page_size / 512);\r\npage = sector_div(lba, msb->pages_in_block);\r\nif (rq_data_dir(msb->req) == READ)\r\nerror = msb_do_read_request(msb, lba, page, sg,\r\nblk_rq_bytes(msb->req), &len);\r\nelse\r\nerror = msb_do_write_request(msb, lba, page, sg,\r\nblk_rq_bytes(msb->req), &len);\r\nspin_lock_irqsave(&msb->q_lock, flags);\r\nif (len)\r\nif (!__blk_end_request(msb->req, 0, len))\r\nmsb->req = NULL;\r\nif (error && msb->req) {\r\ndbg_verbose("IO: ending one sector of the request with error");\r\nif (!__blk_end_request(msb->req, error, msb->page_size))\r\nmsb->req = NULL;\r\n}\r\nif (msb->req)\r\ndbg_verbose("IO: request still pending");\r\nspin_unlock_irqrestore(&msb->q_lock, flags);\r\n}\r\n}\r\nstatic int msb_bd_open(struct block_device *bdev, fmode_t mode)\r\n{\r\nstruct gendisk *disk = bdev->bd_disk;\r\nstruct msb_data *msb = disk->private_data;\r\ndbg_verbose("block device open");\r\nmutex_lock(&msb_disk_lock);\r\nif (msb && msb->card)\r\nmsb->usage_count++;\r\nmutex_unlock(&msb_disk_lock);\r\nreturn 0;\r\n}\r\nstatic void msb_data_clear(struct msb_data *msb)\r\n{\r\nkfree(msb->boot_page);\r\nkfree(msb->used_blocks_bitmap);\r\nkfree(msb->lba_to_pba_table);\r\nkfree(msb->cache);\r\nmsb->card = NULL;\r\n}\r\nstatic int msb_disk_release(struct gendisk *disk)\r\n{\r\nstruct msb_data *msb = disk->private_data;\r\ndbg_verbose("block device release");\r\nmutex_lock(&msb_disk_lock);\r\nif (msb) {\r\nif (msb->usage_count)\r\nmsb->usage_count--;\r\nif (!msb->usage_count) {\r\ndisk->private_data = NULL;\r\nidr_remove(&msb_disk_idr, msb->disk_id);\r\nput_disk(disk);\r\nkfree(msb);\r\n}\r\n}\r\nmutex_unlock(&msb_disk_lock);\r\nreturn 0;\r\n}\r\nstatic void msb_bd_release(struct gendisk *disk, fmode_t mode)\r\n{\r\nmsb_disk_release(disk);\r\n}\r\nstatic int msb_bd_getgeo(struct block_device *bdev,\r\nstruct hd_geometry *geo)\r\n{\r\nstruct msb_data *msb = bdev->bd_disk->private_data;\r\n*geo = msb->geometry;\r\nreturn 0;\r\n}\r\nstatic int msb_prepare_req(struct request_queue *q, struct request *req)\r\n{\r\nif (req->cmd_type != REQ_TYPE_FS) {\r\nblk_dump_rq_flags(req, "MS unsupported request");\r\nreturn BLKPREP_KILL;\r\n}\r\nreq->cmd_flags |= REQ_DONTPREP;\r\nreturn BLKPREP_OK;\r\n}\r\nstatic void msb_submit_req(struct request_queue *q)\r\n{\r\nstruct memstick_dev *card = q->queuedata;\r\nstruct msb_data *msb = memstick_get_drvdata(card);\r\nstruct request *req = NULL;\r\ndbg_verbose("Submit request");\r\nif (msb->card_dead) {\r\ndbg("Refusing requests on removed card");\r\nWARN_ON(!msb->io_queue_stopped);\r\nwhile ((req = blk_fetch_request(q)) != NULL)\r\n__blk_end_request_all(req, -ENODEV);\r\nreturn;\r\n}\r\nif (msb->req)\r\nreturn;\r\nif (!msb->io_queue_stopped)\r\nqueue_work(msb->io_queue, &msb->io_work);\r\n}\r\nstatic int msb_check_card(struct memstick_dev *card)\r\n{\r\nstruct msb_data *msb = memstick_get_drvdata(card);\r\nreturn (msb->card_dead == 0);\r\n}\r\nstatic void msb_stop(struct memstick_dev *card)\r\n{\r\nstruct msb_data *msb = memstick_get_drvdata(card);\r\nunsigned long flags;\r\ndbg("Stopping all msblock IO");\r\nspin_lock_irqsave(&msb->q_lock, flags);\r\nblk_stop_queue(msb->queue);\r\nmsb->io_queue_stopped = true;\r\nspin_unlock_irqrestore(&msb->q_lock, flags);\r\ndel_timer_sync(&msb->cache_flush_timer);\r\nflush_workqueue(msb->io_queue);\r\nif (msb->req) {\r\nspin_lock_irqsave(&msb->q_lock, flags);\r\nblk_requeue_request(msb->queue, msb->req);\r\nmsb->req = NULL;\r\nspin_unlock_irqrestore(&msb->q_lock, flags);\r\n}\r\n}\r\nstatic void msb_start(struct memstick_dev *card)\r\n{\r\nstruct msb_data *msb = memstick_get_drvdata(card);\r\nunsigned long flags;\r\ndbg("Resuming IO from msblock");\r\nmsb_invalidate_reg_window(msb);\r\nspin_lock_irqsave(&msb->q_lock, flags);\r\nif (!msb->io_queue_stopped || msb->card_dead) {\r\nspin_unlock_irqrestore(&msb->q_lock, flags);\r\nreturn;\r\n}\r\nspin_unlock_irqrestore(&msb->q_lock, flags);\r\nmsb->need_flush_cache = true;\r\nmsb->io_queue_stopped = false;\r\nspin_lock_irqsave(&msb->q_lock, flags);\r\nblk_start_queue(msb->queue);\r\nspin_unlock_irqrestore(&msb->q_lock, flags);\r\nqueue_work(msb->io_queue, &msb->io_work);\r\n}\r\nstatic int msb_init_disk(struct memstick_dev *card)\r\n{\r\nstruct msb_data *msb = memstick_get_drvdata(card);\r\nstruct memstick_host *host = card->host;\r\nint rc;\r\nu64 limit = BLK_BOUNCE_HIGH;\r\nunsigned long capacity;\r\nif (host->dev.dma_mask && *(host->dev.dma_mask))\r\nlimit = *(host->dev.dma_mask);\r\nmutex_lock(&msb_disk_lock);\r\nmsb->disk_id = idr_alloc(&msb_disk_idr, card, 0, 256, GFP_KERNEL);\r\nmutex_unlock(&msb_disk_lock);\r\nif (msb->disk_id < 0)\r\nreturn msb->disk_id;\r\nmsb->disk = alloc_disk(0);\r\nif (!msb->disk) {\r\nrc = -ENOMEM;\r\ngoto out_release_id;\r\n}\r\nmsb->queue = blk_init_queue(msb_submit_req, &msb->q_lock);\r\nif (!msb->queue) {\r\nrc = -ENOMEM;\r\ngoto out_put_disk;\r\n}\r\nmsb->queue->queuedata = card;\r\nblk_queue_prep_rq(msb->queue, msb_prepare_req);\r\nblk_queue_bounce_limit(msb->queue, limit);\r\nblk_queue_max_hw_sectors(msb->queue, MS_BLOCK_MAX_PAGES);\r\nblk_queue_max_segments(msb->queue, MS_BLOCK_MAX_SEGS);\r\nblk_queue_max_segment_size(msb->queue,\r\nMS_BLOCK_MAX_PAGES * msb->page_size);\r\nblk_queue_logical_block_size(msb->queue, msb->page_size);\r\nsprintf(msb->disk->disk_name, "msblk%d", msb->disk_id);\r\nmsb->disk->fops = &msb_bdops;\r\nmsb->disk->private_data = msb;\r\nmsb->disk->queue = msb->queue;\r\nmsb->disk->flags |= GENHD_FL_EXT_DEVT;\r\ncapacity = msb->pages_in_block * msb->logical_block_count;\r\ncapacity *= (msb->page_size / 512);\r\nset_capacity(msb->disk, capacity);\r\ndbg("Set total disk size to %lu sectors", capacity);\r\nmsb->usage_count = 1;\r\nmsb->io_queue = alloc_ordered_workqueue("ms_block", WQ_MEM_RECLAIM);\r\nINIT_WORK(&msb->io_work, msb_io_work);\r\nsg_init_table(msb->prealloc_sg, MS_BLOCK_MAX_SEGS+1);\r\nif (msb->read_only)\r\nset_disk_ro(msb->disk, 1);\r\nmsb_start(card);\r\ndevice_add_disk(&card->dev, msb->disk);\r\ndbg("Disk added");\r\nreturn 0;\r\nout_put_disk:\r\nput_disk(msb->disk);\r\nout_release_id:\r\nmutex_lock(&msb_disk_lock);\r\nidr_remove(&msb_disk_idr, msb->disk_id);\r\nmutex_unlock(&msb_disk_lock);\r\nreturn rc;\r\n}\r\nstatic int msb_probe(struct memstick_dev *card)\r\n{\r\nstruct msb_data *msb;\r\nint rc = 0;\r\nmsb = kzalloc(sizeof(struct msb_data), GFP_KERNEL);\r\nif (!msb)\r\nreturn -ENOMEM;\r\nmemstick_set_drvdata(card, msb);\r\nmsb->card = card;\r\nspin_lock_init(&msb->q_lock);\r\nrc = msb_init_card(card);\r\nif (rc)\r\ngoto out_free;\r\nrc = msb_init_disk(card);\r\nif (!rc) {\r\ncard->check = msb_check_card;\r\ncard->stop = msb_stop;\r\ncard->start = msb_start;\r\nreturn 0;\r\n}\r\nout_free:\r\nmemstick_set_drvdata(card, NULL);\r\nmsb_data_clear(msb);\r\nkfree(msb);\r\nreturn rc;\r\n}\r\nstatic void msb_remove(struct memstick_dev *card)\r\n{\r\nstruct msb_data *msb = memstick_get_drvdata(card);\r\nunsigned long flags;\r\nif (!msb->io_queue_stopped)\r\nmsb_stop(card);\r\ndbg("Removing the disk device");\r\nspin_lock_irqsave(&msb->q_lock, flags);\r\nmsb->card_dead = true;\r\nblk_start_queue(msb->queue);\r\nspin_unlock_irqrestore(&msb->q_lock, flags);\r\ndel_gendisk(msb->disk);\r\nblk_cleanup_queue(msb->queue);\r\nmsb->queue = NULL;\r\nmutex_lock(&msb_disk_lock);\r\nmsb_data_clear(msb);\r\nmutex_unlock(&msb_disk_lock);\r\nmsb_disk_release(msb->disk);\r\nmemstick_set_drvdata(card, NULL);\r\n}\r\nstatic int msb_suspend(struct memstick_dev *card, pm_message_t state)\r\n{\r\nmsb_stop(card);\r\nreturn 0;\r\n}\r\nstatic int msb_resume(struct memstick_dev *card)\r\n{\r\nstruct msb_data *msb = memstick_get_drvdata(card);\r\nstruct msb_data *new_msb = NULL;\r\nbool card_dead = true;\r\n#ifndef CONFIG_MEMSTICK_UNSAFE_RESUME\r\nmsb->card_dead = true;\r\nreturn 0;\r\n#endif\r\nmutex_lock(&card->host->lock);\r\nnew_msb = kzalloc(sizeof(struct msb_data), GFP_KERNEL);\r\nif (!new_msb)\r\ngoto out;\r\nnew_msb->card = card;\r\nmemstick_set_drvdata(card, new_msb);\r\nspin_lock_init(&new_msb->q_lock);\r\nsg_init_table(msb->prealloc_sg, MS_BLOCK_MAX_SEGS+1);\r\nif (msb_init_card(card))\r\ngoto out;\r\nif (msb->block_size != new_msb->block_size)\r\ngoto out;\r\nif (memcmp(msb->boot_page, new_msb->boot_page,\r\nsizeof(struct ms_boot_page)))\r\ngoto out;\r\nif (msb->logical_block_count != new_msb->logical_block_count ||\r\nmemcmp(msb->lba_to_pba_table, new_msb->lba_to_pba_table,\r\nmsb->logical_block_count))\r\ngoto out;\r\nif (msb->block_count != new_msb->block_count ||\r\nmemcmp(msb->used_blocks_bitmap, new_msb->used_blocks_bitmap,\r\nmsb->block_count / 8))\r\ngoto out;\r\ncard_dead = false;\r\nout:\r\nif (card_dead)\r\ndbg("Card was removed/replaced during suspend");\r\nmsb->card_dead = card_dead;\r\nmemstick_set_drvdata(card, msb);\r\nif (new_msb) {\r\nmsb_data_clear(new_msb);\r\nkfree(new_msb);\r\n}\r\nmsb_start(card);\r\nmutex_unlock(&card->host->lock);\r\nreturn 0;\r\n}\r\nstatic int __init msb_init(void)\r\n{\r\nint rc = memstick_register_driver(&msb_driver);\r\nif (rc)\r\npr_err("failed to register memstick driver (error %d)\n", rc);\r\nreturn rc;\r\n}\r\nstatic void __exit msb_exit(void)\r\n{\r\nmemstick_unregister_driver(&msb_driver);\r\nidr_destroy(&msb_disk_idr);\r\n}
