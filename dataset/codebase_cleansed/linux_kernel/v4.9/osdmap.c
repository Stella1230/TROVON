char *ceph_osdmap_state_str(char *str, int len, int state)\r\n{\r\nif (!len)\r\nreturn str;\r\nif ((state & CEPH_OSD_EXISTS) && (state & CEPH_OSD_UP))\r\nsnprintf(str, len, "exists, up");\r\nelse if (state & CEPH_OSD_EXISTS)\r\nsnprintf(str, len, "exists");\r\nelse if (state & CEPH_OSD_UP)\r\nsnprintf(str, len, "up");\r\nelse\r\nsnprintf(str, len, "doesn't exist");\r\nreturn str;\r\n}\r\nstatic int calc_bits_of(unsigned int t)\r\n{\r\nint b = 0;\r\nwhile (t) {\r\nt = t >> 1;\r\nb++;\r\n}\r\nreturn b;\r\n}\r\nstatic void calc_pg_masks(struct ceph_pg_pool_info *pi)\r\n{\r\npi->pg_num_mask = (1 << calc_bits_of(pi->pg_num-1)) - 1;\r\npi->pgp_num_mask = (1 << calc_bits_of(pi->pgp_num-1)) - 1;\r\n}\r\nstatic int crush_decode_uniform_bucket(void **p, void *end,\r\nstruct crush_bucket_uniform *b)\r\n{\r\ndout("crush_decode_uniform_bucket %p to %p\n", *p, end);\r\nceph_decode_need(p, end, (1+b->h.size) * sizeof(u32), bad);\r\nb->item_weight = ceph_decode_32(p);\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nstatic int crush_decode_list_bucket(void **p, void *end,\r\nstruct crush_bucket_list *b)\r\n{\r\nint j;\r\ndout("crush_decode_list_bucket %p to %p\n", *p, end);\r\nb->item_weights = kcalloc(b->h.size, sizeof(u32), GFP_NOFS);\r\nif (b->item_weights == NULL)\r\nreturn -ENOMEM;\r\nb->sum_weights = kcalloc(b->h.size, sizeof(u32), GFP_NOFS);\r\nif (b->sum_weights == NULL)\r\nreturn -ENOMEM;\r\nceph_decode_need(p, end, 2 * b->h.size * sizeof(u32), bad);\r\nfor (j = 0; j < b->h.size; j++) {\r\nb->item_weights[j] = ceph_decode_32(p);\r\nb->sum_weights[j] = ceph_decode_32(p);\r\n}\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nstatic int crush_decode_tree_bucket(void **p, void *end,\r\nstruct crush_bucket_tree *b)\r\n{\r\nint j;\r\ndout("crush_decode_tree_bucket %p to %p\n", *p, end);\r\nceph_decode_8_safe(p, end, b->num_nodes, bad);\r\nb->node_weights = kcalloc(b->num_nodes, sizeof(u32), GFP_NOFS);\r\nif (b->node_weights == NULL)\r\nreturn -ENOMEM;\r\nceph_decode_need(p, end, b->num_nodes * sizeof(u32), bad);\r\nfor (j = 0; j < b->num_nodes; j++)\r\nb->node_weights[j] = ceph_decode_32(p);\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nstatic int crush_decode_straw_bucket(void **p, void *end,\r\nstruct crush_bucket_straw *b)\r\n{\r\nint j;\r\ndout("crush_decode_straw_bucket %p to %p\n", *p, end);\r\nb->item_weights = kcalloc(b->h.size, sizeof(u32), GFP_NOFS);\r\nif (b->item_weights == NULL)\r\nreturn -ENOMEM;\r\nb->straws = kcalloc(b->h.size, sizeof(u32), GFP_NOFS);\r\nif (b->straws == NULL)\r\nreturn -ENOMEM;\r\nceph_decode_need(p, end, 2 * b->h.size * sizeof(u32), bad);\r\nfor (j = 0; j < b->h.size; j++) {\r\nb->item_weights[j] = ceph_decode_32(p);\r\nb->straws[j] = ceph_decode_32(p);\r\n}\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nstatic int crush_decode_straw2_bucket(void **p, void *end,\r\nstruct crush_bucket_straw2 *b)\r\n{\r\nint j;\r\ndout("crush_decode_straw2_bucket %p to %p\n", *p, end);\r\nb->item_weights = kcalloc(b->h.size, sizeof(u32), GFP_NOFS);\r\nif (b->item_weights == NULL)\r\nreturn -ENOMEM;\r\nceph_decode_need(p, end, b->h.size * sizeof(u32), bad);\r\nfor (j = 0; j < b->h.size; j++)\r\nb->item_weights[j] = ceph_decode_32(p);\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nstatic int skip_name_map(void **p, void *end)\r\n{\r\nint len;\r\nceph_decode_32_safe(p, end, len ,bad);\r\nwhile (len--) {\r\nint strlen;\r\n*p += sizeof(u32);\r\nceph_decode_32_safe(p, end, strlen, bad);\r\n*p += strlen;\r\n}\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nstatic struct crush_map *crush_decode(void *pbyval, void *end)\r\n{\r\nstruct crush_map *c;\r\nint err = -EINVAL;\r\nint i, j;\r\nvoid **p = &pbyval;\r\nvoid *start = pbyval;\r\nu32 magic;\r\nu32 num_name_maps;\r\ndout("crush_decode %p to %p len %d\n", *p, end, (int)(end - *p));\r\nc = kzalloc(sizeof(*c), GFP_NOFS);\r\nif (c == NULL)\r\nreturn ERR_PTR(-ENOMEM);\r\nc->choose_local_tries = 2;\r\nc->choose_local_fallback_tries = 5;\r\nc->choose_total_tries = 19;\r\nc->chooseleaf_descend_once = 0;\r\nceph_decode_need(p, end, 4*sizeof(u32), bad);\r\nmagic = ceph_decode_32(p);\r\nif (magic != CRUSH_MAGIC) {\r\npr_err("crush_decode magic %x != current %x\n",\r\n(unsigned int)magic, (unsigned int)CRUSH_MAGIC);\r\ngoto bad;\r\n}\r\nc->max_buckets = ceph_decode_32(p);\r\nc->max_rules = ceph_decode_32(p);\r\nc->max_devices = ceph_decode_32(p);\r\nc->buckets = kcalloc(c->max_buckets, sizeof(*c->buckets), GFP_NOFS);\r\nif (c->buckets == NULL)\r\ngoto badmem;\r\nc->rules = kcalloc(c->max_rules, sizeof(*c->rules), GFP_NOFS);\r\nif (c->rules == NULL)\r\ngoto badmem;\r\nfor (i = 0; i < c->max_buckets; i++) {\r\nint size = 0;\r\nu32 alg;\r\nstruct crush_bucket *b;\r\nceph_decode_32_safe(p, end, alg, bad);\r\nif (alg == 0) {\r\nc->buckets[i] = NULL;\r\ncontinue;\r\n}\r\ndout("crush_decode bucket %d off %x %p to %p\n",\r\ni, (int)(*p-start), *p, end);\r\nswitch (alg) {\r\ncase CRUSH_BUCKET_UNIFORM:\r\nsize = sizeof(struct crush_bucket_uniform);\r\nbreak;\r\ncase CRUSH_BUCKET_LIST:\r\nsize = sizeof(struct crush_bucket_list);\r\nbreak;\r\ncase CRUSH_BUCKET_TREE:\r\nsize = sizeof(struct crush_bucket_tree);\r\nbreak;\r\ncase CRUSH_BUCKET_STRAW:\r\nsize = sizeof(struct crush_bucket_straw);\r\nbreak;\r\ncase CRUSH_BUCKET_STRAW2:\r\nsize = sizeof(struct crush_bucket_straw2);\r\nbreak;\r\ndefault:\r\nerr = -EINVAL;\r\ngoto bad;\r\n}\r\nBUG_ON(size == 0);\r\nb = c->buckets[i] = kzalloc(size, GFP_NOFS);\r\nif (b == NULL)\r\ngoto badmem;\r\nceph_decode_need(p, end, 4*sizeof(u32), bad);\r\nb->id = ceph_decode_32(p);\r\nb->type = ceph_decode_16(p);\r\nb->alg = ceph_decode_8(p);\r\nb->hash = ceph_decode_8(p);\r\nb->weight = ceph_decode_32(p);\r\nb->size = ceph_decode_32(p);\r\ndout("crush_decode bucket size %d off %x %p to %p\n",\r\nb->size, (int)(*p-start), *p, end);\r\nb->items = kcalloc(b->size, sizeof(__s32), GFP_NOFS);\r\nif (b->items == NULL)\r\ngoto badmem;\r\nb->perm = kcalloc(b->size, sizeof(u32), GFP_NOFS);\r\nif (b->perm == NULL)\r\ngoto badmem;\r\nb->perm_n = 0;\r\nceph_decode_need(p, end, b->size*sizeof(u32), bad);\r\nfor (j = 0; j < b->size; j++)\r\nb->items[j] = ceph_decode_32(p);\r\nswitch (b->alg) {\r\ncase CRUSH_BUCKET_UNIFORM:\r\nerr = crush_decode_uniform_bucket(p, end,\r\n(struct crush_bucket_uniform *)b);\r\nif (err < 0)\r\ngoto bad;\r\nbreak;\r\ncase CRUSH_BUCKET_LIST:\r\nerr = crush_decode_list_bucket(p, end,\r\n(struct crush_bucket_list *)b);\r\nif (err < 0)\r\ngoto bad;\r\nbreak;\r\ncase CRUSH_BUCKET_TREE:\r\nerr = crush_decode_tree_bucket(p, end,\r\n(struct crush_bucket_tree *)b);\r\nif (err < 0)\r\ngoto bad;\r\nbreak;\r\ncase CRUSH_BUCKET_STRAW:\r\nerr = crush_decode_straw_bucket(p, end,\r\n(struct crush_bucket_straw *)b);\r\nif (err < 0)\r\ngoto bad;\r\nbreak;\r\ncase CRUSH_BUCKET_STRAW2:\r\nerr = crush_decode_straw2_bucket(p, end,\r\n(struct crush_bucket_straw2 *)b);\r\nif (err < 0)\r\ngoto bad;\r\nbreak;\r\n}\r\n}\r\ndout("rule vec is %p\n", c->rules);\r\nfor (i = 0; i < c->max_rules; i++) {\r\nu32 yes;\r\nstruct crush_rule *r;\r\nceph_decode_32_safe(p, end, yes, bad);\r\nif (!yes) {\r\ndout("crush_decode NO rule %d off %x %p to %p\n",\r\ni, (int)(*p-start), *p, end);\r\nc->rules[i] = NULL;\r\ncontinue;\r\n}\r\ndout("crush_decode rule %d off %x %p to %p\n",\r\ni, (int)(*p-start), *p, end);\r\nceph_decode_32_safe(p, end, yes, bad);\r\n#if BITS_PER_LONG == 32\r\nerr = -EINVAL;\r\nif (yes > (ULONG_MAX - sizeof(*r))\r\n/ sizeof(struct crush_rule_step))\r\ngoto bad;\r\n#endif\r\nr = c->rules[i] = kmalloc(sizeof(*r) +\r\nyes*sizeof(struct crush_rule_step),\r\nGFP_NOFS);\r\nif (r == NULL)\r\ngoto badmem;\r\ndout(" rule %d is at %p\n", i, r);\r\nr->len = yes;\r\nceph_decode_copy_safe(p, end, &r->mask, 4, bad);\r\nceph_decode_need(p, end, r->len*3*sizeof(u32), bad);\r\nfor (j = 0; j < r->len; j++) {\r\nr->steps[j].op = ceph_decode_32(p);\r\nr->steps[j].arg1 = ceph_decode_32(p);\r\nr->steps[j].arg2 = ceph_decode_32(p);\r\n}\r\n}\r\nfor (num_name_maps = 0; num_name_maps < 3; num_name_maps++) {\r\nerr = skip_name_map(p, end);\r\nif (err < 0)\r\ngoto done;\r\n}\r\nceph_decode_need(p, end, 3*sizeof(u32), done);\r\nc->choose_local_tries = ceph_decode_32(p);\r\nc->choose_local_fallback_tries = ceph_decode_32(p);\r\nc->choose_total_tries = ceph_decode_32(p);\r\ndout("crush decode tunable choose_local_tries = %d\n",\r\nc->choose_local_tries);\r\ndout("crush decode tunable choose_local_fallback_tries = %d\n",\r\nc->choose_local_fallback_tries);\r\ndout("crush decode tunable choose_total_tries = %d\n",\r\nc->choose_total_tries);\r\nceph_decode_need(p, end, sizeof(u32), done);\r\nc->chooseleaf_descend_once = ceph_decode_32(p);\r\ndout("crush decode tunable chooseleaf_descend_once = %d\n",\r\nc->chooseleaf_descend_once);\r\nceph_decode_need(p, end, sizeof(u8), done);\r\nc->chooseleaf_vary_r = ceph_decode_8(p);\r\ndout("crush decode tunable chooseleaf_vary_r = %d\n",\r\nc->chooseleaf_vary_r);\r\nceph_decode_need(p, end, sizeof(u8) + sizeof(u32), done);\r\n*p += sizeof(u8) + sizeof(u32);\r\nceph_decode_need(p, end, sizeof(u8), done);\r\nc->chooseleaf_stable = ceph_decode_8(p);\r\ndout("crush decode tunable chooseleaf_stable = %d\n",\r\nc->chooseleaf_stable);\r\ndone:\r\ndout("crush_decode success\n");\r\nreturn c;\r\nbadmem:\r\nerr = -ENOMEM;\r\nbad:\r\ndout("crush_decode fail %d\n", err);\r\ncrush_destroy(c);\r\nreturn ERR_PTR(err);\r\n}\r\nint ceph_pg_compare(const struct ceph_pg *lhs, const struct ceph_pg *rhs)\r\n{\r\nif (lhs->pool < rhs->pool)\r\nreturn -1;\r\nif (lhs->pool > rhs->pool)\r\nreturn 1;\r\nif (lhs->seed < rhs->seed)\r\nreturn -1;\r\nif (lhs->seed > rhs->seed)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int __insert_pg_mapping(struct ceph_pg_mapping *new,\r\nstruct rb_root *root)\r\n{\r\nstruct rb_node **p = &root->rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct ceph_pg_mapping *pg = NULL;\r\nint c;\r\ndout("__insert_pg_mapping %llx %p\n", *(u64 *)&new->pgid, new);\r\nwhile (*p) {\r\nparent = *p;\r\npg = rb_entry(parent, struct ceph_pg_mapping, node);\r\nc = ceph_pg_compare(&new->pgid, &pg->pgid);\r\nif (c < 0)\r\np = &(*p)->rb_left;\r\nelse if (c > 0)\r\np = &(*p)->rb_right;\r\nelse\r\nreturn -EEXIST;\r\n}\r\nrb_link_node(&new->node, parent, p);\r\nrb_insert_color(&new->node, root);\r\nreturn 0;\r\n}\r\nstatic struct ceph_pg_mapping *__lookup_pg_mapping(struct rb_root *root,\r\nstruct ceph_pg pgid)\r\n{\r\nstruct rb_node *n = root->rb_node;\r\nstruct ceph_pg_mapping *pg;\r\nint c;\r\nwhile (n) {\r\npg = rb_entry(n, struct ceph_pg_mapping, node);\r\nc = ceph_pg_compare(&pgid, &pg->pgid);\r\nif (c < 0) {\r\nn = n->rb_left;\r\n} else if (c > 0) {\r\nn = n->rb_right;\r\n} else {\r\ndout("__lookup_pg_mapping %lld.%x got %p\n",\r\npgid.pool, pgid.seed, pg);\r\nreturn pg;\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nstatic int __remove_pg_mapping(struct rb_root *root, struct ceph_pg pgid)\r\n{\r\nstruct ceph_pg_mapping *pg = __lookup_pg_mapping(root, pgid);\r\nif (pg) {\r\ndout("__remove_pg_mapping %lld.%x %p\n", pgid.pool, pgid.seed,\r\npg);\r\nrb_erase(&pg->node, root);\r\nkfree(pg);\r\nreturn 0;\r\n}\r\ndout("__remove_pg_mapping %lld.%x dne\n", pgid.pool, pgid.seed);\r\nreturn -ENOENT;\r\n}\r\nstatic int __insert_pg_pool(struct rb_root *root, struct ceph_pg_pool_info *new)\r\n{\r\nstruct rb_node **p = &root->rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct ceph_pg_pool_info *pi = NULL;\r\nwhile (*p) {\r\nparent = *p;\r\npi = rb_entry(parent, struct ceph_pg_pool_info, node);\r\nif (new->id < pi->id)\r\np = &(*p)->rb_left;\r\nelse if (new->id > pi->id)\r\np = &(*p)->rb_right;\r\nelse\r\nreturn -EEXIST;\r\n}\r\nrb_link_node(&new->node, parent, p);\r\nrb_insert_color(&new->node, root);\r\nreturn 0;\r\n}\r\nstatic struct ceph_pg_pool_info *__lookup_pg_pool(struct rb_root *root, u64 id)\r\n{\r\nstruct ceph_pg_pool_info *pi;\r\nstruct rb_node *n = root->rb_node;\r\nwhile (n) {\r\npi = rb_entry(n, struct ceph_pg_pool_info, node);\r\nif (id < pi->id)\r\nn = n->rb_left;\r\nelse if (id > pi->id)\r\nn = n->rb_right;\r\nelse\r\nreturn pi;\r\n}\r\nreturn NULL;\r\n}\r\nstruct ceph_pg_pool_info *ceph_pg_pool_by_id(struct ceph_osdmap *map, u64 id)\r\n{\r\nreturn __lookup_pg_pool(&map->pg_pools, id);\r\n}\r\nconst char *ceph_pg_pool_name_by_id(struct ceph_osdmap *map, u64 id)\r\n{\r\nstruct ceph_pg_pool_info *pi;\r\nif (id == CEPH_NOPOOL)\r\nreturn NULL;\r\nif (WARN_ON_ONCE(id > (u64) INT_MAX))\r\nreturn NULL;\r\npi = __lookup_pg_pool(&map->pg_pools, (int) id);\r\nreturn pi ? pi->name : NULL;\r\n}\r\nint ceph_pg_poolid_by_name(struct ceph_osdmap *map, const char *name)\r\n{\r\nstruct rb_node *rbp;\r\nfor (rbp = rb_first(&map->pg_pools); rbp; rbp = rb_next(rbp)) {\r\nstruct ceph_pg_pool_info *pi =\r\nrb_entry(rbp, struct ceph_pg_pool_info, node);\r\nif (pi->name && strcmp(pi->name, name) == 0)\r\nreturn pi->id;\r\n}\r\nreturn -ENOENT;\r\n}\r\nstatic void __remove_pg_pool(struct rb_root *root, struct ceph_pg_pool_info *pi)\r\n{\r\nrb_erase(&pi->node, root);\r\nkfree(pi->name);\r\nkfree(pi);\r\n}\r\nstatic int decode_pool(void **p, void *end, struct ceph_pg_pool_info *pi)\r\n{\r\nu8 ev, cv;\r\nunsigned len, num;\r\nvoid *pool_end;\r\nceph_decode_need(p, end, 2 + 4, bad);\r\nev = ceph_decode_8(p);\r\ncv = ceph_decode_8(p);\r\nif (ev < 5) {\r\npr_warn("got v %d < 5 cv %d of ceph_pg_pool\n", ev, cv);\r\nreturn -EINVAL;\r\n}\r\nif (cv > 9) {\r\npr_warn("got v %d cv %d > 9 of ceph_pg_pool\n", ev, cv);\r\nreturn -EINVAL;\r\n}\r\nlen = ceph_decode_32(p);\r\nceph_decode_need(p, end, len, bad);\r\npool_end = *p + len;\r\npi->type = ceph_decode_8(p);\r\npi->size = ceph_decode_8(p);\r\npi->crush_ruleset = ceph_decode_8(p);\r\npi->object_hash = ceph_decode_8(p);\r\npi->pg_num = ceph_decode_32(p);\r\npi->pgp_num = ceph_decode_32(p);\r\n*p += 4 + 4;\r\n*p += 4;\r\n*p += 8 + 4;\r\nnum = ceph_decode_32(p);\r\nwhile (num--) {\r\n*p += 8;\r\n*p += 1 + 1;\r\nlen = ceph_decode_32(p);\r\n*p += len;\r\n}\r\nnum = ceph_decode_32(p);\r\n*p += num * (8 + 8);\r\n*p += 8;\r\npi->flags = ceph_decode_64(p);\r\n*p += 4;\r\nif (ev >= 7)\r\npi->min_size = ceph_decode_8(p);\r\nelse\r\npi->min_size = pi->size - pi->size / 2;\r\nif (ev >= 8)\r\n*p += 8 + 8;\r\nif (ev >= 9) {\r\nnum = ceph_decode_32(p);\r\n*p += num * 8;\r\n*p += 8;\r\n*p += 1;\r\npi->read_tier = ceph_decode_64(p);\r\npi->write_tier = ceph_decode_64(p);\r\n} else {\r\npi->read_tier = -1;\r\npi->write_tier = -1;\r\n}\r\nif (ev >= 10) {\r\nnum = ceph_decode_32(p);\r\nwhile (num--) {\r\nlen = ceph_decode_32(p);\r\n*p += len;\r\nlen = ceph_decode_32(p);\r\n*p += len;\r\n}\r\n}\r\nif (ev >= 11) {\r\n*p += 1 + 1;\r\nlen = ceph_decode_32(p);\r\n*p += len;\r\n*p += 4;\r\n*p += 4;\r\n}\r\nif (ev >= 12)\r\n*p += 4;\r\nif (ev >= 13) {\r\n*p += 8;\r\n*p += 8;\r\n*p += 4;\r\n*p += 4;\r\n*p += 4;\r\n*p += 4;\r\n}\r\nif (ev >= 14) {\r\nlen = ceph_decode_32(p);\r\n*p += len;\r\n}\r\nif (ev >= 15)\r\npi->last_force_request_resend = ceph_decode_32(p);\r\nelse\r\npi->last_force_request_resend = 0;\r\n*p = pool_end;\r\ncalc_pg_masks(pi);\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nstatic int decode_pool_names(void **p, void *end, struct ceph_osdmap *map)\r\n{\r\nstruct ceph_pg_pool_info *pi;\r\nu32 num, len;\r\nu64 pool;\r\nceph_decode_32_safe(p, end, num, bad);\r\ndout(" %d pool names\n", num);\r\nwhile (num--) {\r\nceph_decode_64_safe(p, end, pool, bad);\r\nceph_decode_32_safe(p, end, len, bad);\r\ndout(" pool %llu len %d\n", pool, len);\r\nceph_decode_need(p, end, len, bad);\r\npi = __lookup_pg_pool(&map->pg_pools, pool);\r\nif (pi) {\r\nchar *name = kstrndup(*p, len, GFP_NOFS);\r\nif (!name)\r\nreturn -ENOMEM;\r\nkfree(pi->name);\r\npi->name = name;\r\ndout(" name is %s\n", pi->name);\r\n}\r\n*p += len;\r\n}\r\nreturn 0;\r\nbad:\r\nreturn -EINVAL;\r\n}\r\nstruct ceph_osdmap *ceph_osdmap_alloc(void)\r\n{\r\nstruct ceph_osdmap *map;\r\nmap = kzalloc(sizeof(*map), GFP_NOIO);\r\nif (!map)\r\nreturn NULL;\r\nmap->pg_pools = RB_ROOT;\r\nmap->pool_max = -1;\r\nmap->pg_temp = RB_ROOT;\r\nmap->primary_temp = RB_ROOT;\r\nmutex_init(&map->crush_scratch_mutex);\r\nreturn map;\r\n}\r\nvoid ceph_osdmap_destroy(struct ceph_osdmap *map)\r\n{\r\ndout("osdmap_destroy %p\n", map);\r\nif (map->crush)\r\ncrush_destroy(map->crush);\r\nwhile (!RB_EMPTY_ROOT(&map->pg_temp)) {\r\nstruct ceph_pg_mapping *pg =\r\nrb_entry(rb_first(&map->pg_temp),\r\nstruct ceph_pg_mapping, node);\r\nrb_erase(&pg->node, &map->pg_temp);\r\nkfree(pg);\r\n}\r\nwhile (!RB_EMPTY_ROOT(&map->primary_temp)) {\r\nstruct ceph_pg_mapping *pg =\r\nrb_entry(rb_first(&map->primary_temp),\r\nstruct ceph_pg_mapping, node);\r\nrb_erase(&pg->node, &map->primary_temp);\r\nkfree(pg);\r\n}\r\nwhile (!RB_EMPTY_ROOT(&map->pg_pools)) {\r\nstruct ceph_pg_pool_info *pi =\r\nrb_entry(rb_first(&map->pg_pools),\r\nstruct ceph_pg_pool_info, node);\r\n__remove_pg_pool(&map->pg_pools, pi);\r\n}\r\nkfree(map->osd_state);\r\nkfree(map->osd_weight);\r\nkfree(map->osd_addr);\r\nkfree(map->osd_primary_affinity);\r\nkfree(map);\r\n}\r\nstatic int osdmap_set_max_osd(struct ceph_osdmap *map, int max)\r\n{\r\nu8 *state;\r\nu32 *weight;\r\nstruct ceph_entity_addr *addr;\r\nint i;\r\nstate = krealloc(map->osd_state, max*sizeof(*state), GFP_NOFS);\r\nif (!state)\r\nreturn -ENOMEM;\r\nmap->osd_state = state;\r\nweight = krealloc(map->osd_weight, max*sizeof(*weight), GFP_NOFS);\r\nif (!weight)\r\nreturn -ENOMEM;\r\nmap->osd_weight = weight;\r\naddr = krealloc(map->osd_addr, max*sizeof(*addr), GFP_NOFS);\r\nif (!addr)\r\nreturn -ENOMEM;\r\nmap->osd_addr = addr;\r\nfor (i = map->max_osd; i < max; i++) {\r\nmap->osd_state[i] = 0;\r\nmap->osd_weight[i] = CEPH_OSD_OUT;\r\nmemset(map->osd_addr + i, 0, sizeof(*map->osd_addr));\r\n}\r\nif (map->osd_primary_affinity) {\r\nu32 *affinity;\r\naffinity = krealloc(map->osd_primary_affinity,\r\nmax*sizeof(*affinity), GFP_NOFS);\r\nif (!affinity)\r\nreturn -ENOMEM;\r\nmap->osd_primary_affinity = affinity;\r\nfor (i = map->max_osd; i < max; i++)\r\nmap->osd_primary_affinity[i] =\r\nCEPH_OSD_DEFAULT_PRIMARY_AFFINITY;\r\n}\r\nmap->max_osd = max;\r\nreturn 0;\r\n}\r\nstatic int get_osdmap_client_data_v(void **p, void *end,\r\nconst char *prefix, u8 *v)\r\n{\r\nu8 struct_v;\r\nceph_decode_8_safe(p, end, struct_v, e_inval);\r\nif (struct_v >= 7) {\r\nu8 struct_compat;\r\nceph_decode_8_safe(p, end, struct_compat, e_inval);\r\nif (struct_compat > OSDMAP_WRAPPER_COMPAT_VER) {\r\npr_warn("got v %d cv %d > %d of %s ceph_osdmap\n",\r\nstruct_v, struct_compat,\r\nOSDMAP_WRAPPER_COMPAT_VER, prefix);\r\nreturn -EINVAL;\r\n}\r\n*p += 4;\r\nceph_decode_8_safe(p, end, struct_v, e_inval);\r\nceph_decode_8_safe(p, end, struct_compat, e_inval);\r\nif (struct_compat > OSDMAP_CLIENT_DATA_COMPAT_VER) {\r\npr_warn("got v %d cv %d > %d of %s ceph_osdmap client data\n",\r\nstruct_v, struct_compat,\r\nOSDMAP_CLIENT_DATA_COMPAT_VER, prefix);\r\nreturn -EINVAL;\r\n}\r\n*p += 4;\r\n} else {\r\nu16 version;\r\n*p -= 1;\r\nceph_decode_16_safe(p, end, version, e_inval);\r\nif (version < 6) {\r\npr_warn("got v %d < 6 of %s ceph_osdmap\n",\r\nversion, prefix);\r\nreturn -EINVAL;\r\n}\r\nstruct_v = 0;\r\n}\r\n*v = struct_v;\r\nreturn 0;\r\ne_inval:\r\nreturn -EINVAL;\r\n}\r\nstatic int __decode_pools(void **p, void *end, struct ceph_osdmap *map,\r\nbool incremental)\r\n{\r\nu32 n;\r\nceph_decode_32_safe(p, end, n, e_inval);\r\nwhile (n--) {\r\nstruct ceph_pg_pool_info *pi;\r\nu64 pool;\r\nint ret;\r\nceph_decode_64_safe(p, end, pool, e_inval);\r\npi = __lookup_pg_pool(&map->pg_pools, pool);\r\nif (!incremental || !pi) {\r\npi = kzalloc(sizeof(*pi), GFP_NOFS);\r\nif (!pi)\r\nreturn -ENOMEM;\r\npi->id = pool;\r\nret = __insert_pg_pool(&map->pg_pools, pi);\r\nif (ret) {\r\nkfree(pi);\r\nreturn ret;\r\n}\r\n}\r\nret = decode_pool(p, end, pi);\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn 0;\r\ne_inval:\r\nreturn -EINVAL;\r\n}\r\nstatic int decode_pools(void **p, void *end, struct ceph_osdmap *map)\r\n{\r\nreturn __decode_pools(p, end, map, false);\r\n}\r\nstatic int decode_new_pools(void **p, void *end, struct ceph_osdmap *map)\r\n{\r\nreturn __decode_pools(p, end, map, true);\r\n}\r\nstatic int __decode_pg_temp(void **p, void *end, struct ceph_osdmap *map,\r\nbool incremental)\r\n{\r\nu32 n;\r\nceph_decode_32_safe(p, end, n, e_inval);\r\nwhile (n--) {\r\nstruct ceph_pg pgid;\r\nu32 len, i;\r\nint ret;\r\nret = ceph_decode_pgid(p, end, &pgid);\r\nif (ret)\r\nreturn ret;\r\nceph_decode_32_safe(p, end, len, e_inval);\r\nret = __remove_pg_mapping(&map->pg_temp, pgid);\r\nBUG_ON(!incremental && ret != -ENOENT);\r\nif (!incremental || len > 0) {\r\nstruct ceph_pg_mapping *pg;\r\nceph_decode_need(p, end, len*sizeof(u32), e_inval);\r\nif (len > (UINT_MAX - sizeof(*pg)) / sizeof(u32))\r\nreturn -EINVAL;\r\npg = kzalloc(sizeof(*pg) + len*sizeof(u32), GFP_NOFS);\r\nif (!pg)\r\nreturn -ENOMEM;\r\npg->pgid = pgid;\r\npg->pg_temp.len = len;\r\nfor (i = 0; i < len; i++)\r\npg->pg_temp.osds[i] = ceph_decode_32(p);\r\nret = __insert_pg_mapping(pg, &map->pg_temp);\r\nif (ret) {\r\nkfree(pg);\r\nreturn ret;\r\n}\r\n}\r\n}\r\nreturn 0;\r\ne_inval:\r\nreturn -EINVAL;\r\n}\r\nstatic int decode_pg_temp(void **p, void *end, struct ceph_osdmap *map)\r\n{\r\nreturn __decode_pg_temp(p, end, map, false);\r\n}\r\nstatic int decode_new_pg_temp(void **p, void *end, struct ceph_osdmap *map)\r\n{\r\nreturn __decode_pg_temp(p, end, map, true);\r\n}\r\nstatic int __decode_primary_temp(void **p, void *end, struct ceph_osdmap *map,\r\nbool incremental)\r\n{\r\nu32 n;\r\nceph_decode_32_safe(p, end, n, e_inval);\r\nwhile (n--) {\r\nstruct ceph_pg pgid;\r\nu32 osd;\r\nint ret;\r\nret = ceph_decode_pgid(p, end, &pgid);\r\nif (ret)\r\nreturn ret;\r\nceph_decode_32_safe(p, end, osd, e_inval);\r\nret = __remove_pg_mapping(&map->primary_temp, pgid);\r\nBUG_ON(!incremental && ret != -ENOENT);\r\nif (!incremental || osd != (u32)-1) {\r\nstruct ceph_pg_mapping *pg;\r\npg = kzalloc(sizeof(*pg), GFP_NOFS);\r\nif (!pg)\r\nreturn -ENOMEM;\r\npg->pgid = pgid;\r\npg->primary_temp.osd = osd;\r\nret = __insert_pg_mapping(pg, &map->primary_temp);\r\nif (ret) {\r\nkfree(pg);\r\nreturn ret;\r\n}\r\n}\r\n}\r\nreturn 0;\r\ne_inval:\r\nreturn -EINVAL;\r\n}\r\nstatic int decode_primary_temp(void **p, void *end, struct ceph_osdmap *map)\r\n{\r\nreturn __decode_primary_temp(p, end, map, false);\r\n}\r\nstatic int decode_new_primary_temp(void **p, void *end,\r\nstruct ceph_osdmap *map)\r\n{\r\nreturn __decode_primary_temp(p, end, map, true);\r\n}\r\nu32 ceph_get_primary_affinity(struct ceph_osdmap *map, int osd)\r\n{\r\nBUG_ON(osd >= map->max_osd);\r\nif (!map->osd_primary_affinity)\r\nreturn CEPH_OSD_DEFAULT_PRIMARY_AFFINITY;\r\nreturn map->osd_primary_affinity[osd];\r\n}\r\nstatic int set_primary_affinity(struct ceph_osdmap *map, int osd, u32 aff)\r\n{\r\nBUG_ON(osd >= map->max_osd);\r\nif (!map->osd_primary_affinity) {\r\nint i;\r\nmap->osd_primary_affinity = kmalloc(map->max_osd*sizeof(u32),\r\nGFP_NOFS);\r\nif (!map->osd_primary_affinity)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < map->max_osd; i++)\r\nmap->osd_primary_affinity[i] =\r\nCEPH_OSD_DEFAULT_PRIMARY_AFFINITY;\r\n}\r\nmap->osd_primary_affinity[osd] = aff;\r\nreturn 0;\r\n}\r\nstatic int decode_primary_affinity(void **p, void *end,\r\nstruct ceph_osdmap *map)\r\n{\r\nu32 len, i;\r\nceph_decode_32_safe(p, end, len, e_inval);\r\nif (len == 0) {\r\nkfree(map->osd_primary_affinity);\r\nmap->osd_primary_affinity = NULL;\r\nreturn 0;\r\n}\r\nif (len != map->max_osd)\r\ngoto e_inval;\r\nceph_decode_need(p, end, map->max_osd*sizeof(u32), e_inval);\r\nfor (i = 0; i < map->max_osd; i++) {\r\nint ret;\r\nret = set_primary_affinity(map, i, ceph_decode_32(p));\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn 0;\r\ne_inval:\r\nreturn -EINVAL;\r\n}\r\nstatic int decode_new_primary_affinity(void **p, void *end,\r\nstruct ceph_osdmap *map)\r\n{\r\nu32 n;\r\nceph_decode_32_safe(p, end, n, e_inval);\r\nwhile (n--) {\r\nu32 osd, aff;\r\nint ret;\r\nceph_decode_32_safe(p, end, osd, e_inval);\r\nceph_decode_32_safe(p, end, aff, e_inval);\r\nret = set_primary_affinity(map, osd, aff);\r\nif (ret)\r\nreturn ret;\r\npr_info("osd%d primary-affinity 0x%x\n", osd, aff);\r\n}\r\nreturn 0;\r\ne_inval:\r\nreturn -EINVAL;\r\n}\r\nstatic int osdmap_decode(void **p, void *end, struct ceph_osdmap *map)\r\n{\r\nu8 struct_v;\r\nu32 epoch = 0;\r\nvoid *start = *p;\r\nu32 max;\r\nu32 len, i;\r\nint err;\r\ndout("%s %p to %p len %d\n", __func__, *p, end, (int)(end - *p));\r\nerr = get_osdmap_client_data_v(p, end, "full", &struct_v);\r\nif (err)\r\ngoto bad;\r\nceph_decode_need(p, end, sizeof(map->fsid) + sizeof(u32) +\r\nsizeof(map->created) + sizeof(map->modified), e_inval);\r\nceph_decode_copy(p, &map->fsid, sizeof(map->fsid));\r\nepoch = map->epoch = ceph_decode_32(p);\r\nceph_decode_copy(p, &map->created, sizeof(map->created));\r\nceph_decode_copy(p, &map->modified, sizeof(map->modified));\r\nerr = decode_pools(p, end, map);\r\nif (err)\r\ngoto bad;\r\nerr = decode_pool_names(p, end, map);\r\nif (err)\r\ngoto bad;\r\nceph_decode_32_safe(p, end, map->pool_max, e_inval);\r\nceph_decode_32_safe(p, end, map->flags, e_inval);\r\nceph_decode_32_safe(p, end, max, e_inval);\r\nerr = osdmap_set_max_osd(map, max);\r\nif (err)\r\ngoto bad;\r\nceph_decode_need(p, end, 3*sizeof(u32) +\r\nmap->max_osd*(1 + sizeof(*map->osd_weight) +\r\nsizeof(*map->osd_addr)), e_inval);\r\nif (ceph_decode_32(p) != map->max_osd)\r\ngoto e_inval;\r\nceph_decode_copy(p, map->osd_state, map->max_osd);\r\nif (ceph_decode_32(p) != map->max_osd)\r\ngoto e_inval;\r\nfor (i = 0; i < map->max_osd; i++)\r\nmap->osd_weight[i] = ceph_decode_32(p);\r\nif (ceph_decode_32(p) != map->max_osd)\r\ngoto e_inval;\r\nceph_decode_copy(p, map->osd_addr, map->max_osd*sizeof(*map->osd_addr));\r\nfor (i = 0; i < map->max_osd; i++)\r\nceph_decode_addr(&map->osd_addr[i]);\r\nerr = decode_pg_temp(p, end, map);\r\nif (err)\r\ngoto bad;\r\nif (struct_v >= 1) {\r\nerr = decode_primary_temp(p, end, map);\r\nif (err)\r\ngoto bad;\r\n}\r\nif (struct_v >= 2) {\r\nerr = decode_primary_affinity(p, end, map);\r\nif (err)\r\ngoto bad;\r\n} else {\r\nkfree(map->osd_primary_affinity);\r\nmap->osd_primary_affinity = NULL;\r\n}\r\nceph_decode_32_safe(p, end, len, e_inval);\r\nmap->crush = crush_decode(*p, min(*p + len, end));\r\nif (IS_ERR(map->crush)) {\r\nerr = PTR_ERR(map->crush);\r\nmap->crush = NULL;\r\ngoto bad;\r\n}\r\n*p += len;\r\n*p = end;\r\ndout("full osdmap epoch %d max_osd %d\n", map->epoch, map->max_osd);\r\nreturn 0;\r\ne_inval:\r\nerr = -EINVAL;\r\nbad:\r\npr_err("corrupt full osdmap (%d) epoch %d off %d (%p of %p-%p)\n",\r\nerr, epoch, (int)(*p - start), *p, start, end);\r\nprint_hex_dump(KERN_DEBUG, "osdmap: ",\r\nDUMP_PREFIX_OFFSET, 16, 1,\r\nstart, end - start, true);\r\nreturn err;\r\n}\r\nstruct ceph_osdmap *ceph_osdmap_decode(void **p, void *end)\r\n{\r\nstruct ceph_osdmap *map;\r\nint ret;\r\nmap = ceph_osdmap_alloc();\r\nif (!map)\r\nreturn ERR_PTR(-ENOMEM);\r\nret = osdmap_decode(p, end, map);\r\nif (ret) {\r\nceph_osdmap_destroy(map);\r\nreturn ERR_PTR(ret);\r\n}\r\nreturn map;\r\n}\r\nstatic int decode_new_up_state_weight(void **p, void *end,\r\nstruct ceph_osdmap *map)\r\n{\r\nvoid *new_up_client;\r\nvoid *new_state;\r\nvoid *new_weight_end;\r\nu32 len;\r\nnew_up_client = *p;\r\nceph_decode_32_safe(p, end, len, e_inval);\r\nlen *= sizeof(u32) + sizeof(struct ceph_entity_addr);\r\nceph_decode_need(p, end, len, e_inval);\r\n*p += len;\r\nnew_state = *p;\r\nceph_decode_32_safe(p, end, len, e_inval);\r\nlen *= sizeof(u32) + sizeof(u8);\r\nceph_decode_need(p, end, len, e_inval);\r\n*p += len;\r\nceph_decode_32_safe(p, end, len, e_inval);\r\nwhile (len--) {\r\ns32 osd;\r\nu32 w;\r\nceph_decode_need(p, end, 2*sizeof(u32), e_inval);\r\nosd = ceph_decode_32(p);\r\nw = ceph_decode_32(p);\r\nBUG_ON(osd >= map->max_osd);\r\npr_info("osd%d weight 0x%x %s\n", osd, w,\r\nw == CEPH_OSD_IN ? "(in)" :\r\n(w == CEPH_OSD_OUT ? "(out)" : ""));\r\nmap->osd_weight[osd] = w;\r\nif (w) {\r\nmap->osd_state[osd] |= CEPH_OSD_EXISTS;\r\nmap->osd_state[osd] &= ~(CEPH_OSD_AUTOOUT |\r\nCEPH_OSD_NEW);\r\n}\r\n}\r\nnew_weight_end = *p;\r\n*p = new_state;\r\nlen = ceph_decode_32(p);\r\nwhile (len--) {\r\ns32 osd;\r\nu8 xorstate;\r\nint ret;\r\nosd = ceph_decode_32(p);\r\nxorstate = ceph_decode_8(p);\r\nif (xorstate == 0)\r\nxorstate = CEPH_OSD_UP;\r\nBUG_ON(osd >= map->max_osd);\r\nif ((map->osd_state[osd] & CEPH_OSD_UP) &&\r\n(xorstate & CEPH_OSD_UP))\r\npr_info("osd%d down\n", osd);\r\nif ((map->osd_state[osd] & CEPH_OSD_EXISTS) &&\r\n(xorstate & CEPH_OSD_EXISTS)) {\r\npr_info("osd%d does not exist\n", osd);\r\nmap->osd_weight[osd] = CEPH_OSD_IN;\r\nret = set_primary_affinity(map, osd,\r\nCEPH_OSD_DEFAULT_PRIMARY_AFFINITY);\r\nif (ret)\r\nreturn ret;\r\nmemset(map->osd_addr + osd, 0, sizeof(*map->osd_addr));\r\nmap->osd_state[osd] = 0;\r\n} else {\r\nmap->osd_state[osd] ^= xorstate;\r\n}\r\n}\r\n*p = new_up_client;\r\nlen = ceph_decode_32(p);\r\nwhile (len--) {\r\ns32 osd;\r\nstruct ceph_entity_addr addr;\r\nosd = ceph_decode_32(p);\r\nceph_decode_copy(p, &addr, sizeof(addr));\r\nceph_decode_addr(&addr);\r\nBUG_ON(osd >= map->max_osd);\r\npr_info("osd%d up\n", osd);\r\nmap->osd_state[osd] |= CEPH_OSD_EXISTS | CEPH_OSD_UP;\r\nmap->osd_addr[osd] = addr;\r\n}\r\n*p = new_weight_end;\r\nreturn 0;\r\ne_inval:\r\nreturn -EINVAL;\r\n}\r\nstruct ceph_osdmap *osdmap_apply_incremental(void **p, void *end,\r\nstruct ceph_osdmap *map)\r\n{\r\nstruct crush_map *newcrush = NULL;\r\nstruct ceph_fsid fsid;\r\nu32 epoch = 0;\r\nstruct ceph_timespec modified;\r\ns32 len;\r\nu64 pool;\r\n__s64 new_pool_max;\r\n__s32 new_flags, max;\r\nvoid *start = *p;\r\nint err;\r\nu8 struct_v;\r\ndout("%s %p to %p len %d\n", __func__, *p, end, (int)(end - *p));\r\nerr = get_osdmap_client_data_v(p, end, "inc", &struct_v);\r\nif (err)\r\ngoto bad;\r\nceph_decode_need(p, end, sizeof(fsid) + sizeof(u32) + sizeof(modified) +\r\nsizeof(u64) + sizeof(u32), e_inval);\r\nceph_decode_copy(p, &fsid, sizeof(fsid));\r\nepoch = ceph_decode_32(p);\r\nBUG_ON(epoch != map->epoch+1);\r\nceph_decode_copy(p, &modified, sizeof(modified));\r\nnew_pool_max = ceph_decode_64(p);\r\nnew_flags = ceph_decode_32(p);\r\nceph_decode_32_safe(p, end, len, e_inval);\r\nif (len > 0) {\r\ndout("apply_incremental full map len %d, %p to %p\n",\r\nlen, *p, end);\r\nreturn ceph_osdmap_decode(p, min(*p+len, end));\r\n}\r\nceph_decode_32_safe(p, end, len, e_inval);\r\nif (len > 0) {\r\nnewcrush = crush_decode(*p, min(*p+len, end));\r\nif (IS_ERR(newcrush)) {\r\nerr = PTR_ERR(newcrush);\r\nnewcrush = NULL;\r\ngoto bad;\r\n}\r\n*p += len;\r\n}\r\nif (new_flags >= 0)\r\nmap->flags = new_flags;\r\nif (new_pool_max >= 0)\r\nmap->pool_max = new_pool_max;\r\nceph_decode_32_safe(p, end, max, e_inval);\r\nif (max >= 0) {\r\nerr = osdmap_set_max_osd(map, max);\r\nif (err)\r\ngoto bad;\r\n}\r\nmap->epoch++;\r\nmap->modified = modified;\r\nif (newcrush) {\r\nif (map->crush)\r\ncrush_destroy(map->crush);\r\nmap->crush = newcrush;\r\nnewcrush = NULL;\r\n}\r\nerr = decode_new_pools(p, end, map);\r\nif (err)\r\ngoto bad;\r\nerr = decode_pool_names(p, end, map);\r\nif (err)\r\ngoto bad;\r\nceph_decode_32_safe(p, end, len, e_inval);\r\nwhile (len--) {\r\nstruct ceph_pg_pool_info *pi;\r\nceph_decode_64_safe(p, end, pool, e_inval);\r\npi = __lookup_pg_pool(&map->pg_pools, pool);\r\nif (pi)\r\n__remove_pg_pool(&map->pg_pools, pi);\r\n}\r\nerr = decode_new_up_state_weight(p, end, map);\r\nif (err)\r\ngoto bad;\r\nerr = decode_new_pg_temp(p, end, map);\r\nif (err)\r\ngoto bad;\r\nif (struct_v >= 1) {\r\nerr = decode_new_primary_temp(p, end, map);\r\nif (err)\r\ngoto bad;\r\n}\r\nif (struct_v >= 2) {\r\nerr = decode_new_primary_affinity(p, end, map);\r\nif (err)\r\ngoto bad;\r\n}\r\n*p = end;\r\ndout("inc osdmap epoch %d max_osd %d\n", map->epoch, map->max_osd);\r\nreturn map;\r\ne_inval:\r\nerr = -EINVAL;\r\nbad:\r\npr_err("corrupt inc osdmap (%d) epoch %d off %d (%p of %p-%p)\n",\r\nerr, epoch, (int)(*p - start), *p, start, end);\r\nprint_hex_dump(KERN_DEBUG, "osdmap: ",\r\nDUMP_PREFIX_OFFSET, 16, 1,\r\nstart, end - start, true);\r\nif (newcrush)\r\ncrush_destroy(newcrush);\r\nreturn ERR_PTR(err);\r\n}\r\nvoid ceph_oloc_copy(struct ceph_object_locator *dest,\r\nconst struct ceph_object_locator *src)\r\n{\r\nWARN_ON(!ceph_oloc_empty(dest));\r\nWARN_ON(dest->pool_ns);\r\ndest->pool = src->pool;\r\nif (src->pool_ns)\r\ndest->pool_ns = ceph_get_string(src->pool_ns);\r\n}\r\nvoid ceph_oloc_destroy(struct ceph_object_locator *oloc)\r\n{\r\nceph_put_string(oloc->pool_ns);\r\n}\r\nvoid ceph_oid_copy(struct ceph_object_id *dest,\r\nconst struct ceph_object_id *src)\r\n{\r\nWARN_ON(!ceph_oid_empty(dest));\r\nif (src->name != src->inline_name) {\r\ndest->name = kmalloc(src->name_len + 1,\r\nGFP_NOIO | __GFP_NOFAIL);\r\n}\r\nmemcpy(dest->name, src->name, src->name_len + 1);\r\ndest->name_len = src->name_len;\r\n}\r\nvoid ceph_oid_destroy(struct ceph_object_id *oid)\r\n{\r\nif (oid->name != oid->inline_name)\r\nkfree(oid->name);\r\n}\r\nstatic bool __osds_equal(const struct ceph_osds *lhs,\r\nconst struct ceph_osds *rhs)\r\n{\r\nif (lhs->size == rhs->size &&\r\n!memcmp(lhs->osds, rhs->osds, rhs->size * sizeof(rhs->osds[0])))\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic bool osds_equal(const struct ceph_osds *lhs,\r\nconst struct ceph_osds *rhs)\r\n{\r\nif (__osds_equal(lhs, rhs) &&\r\nlhs->primary == rhs->primary)\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic bool osds_valid(const struct ceph_osds *set)\r\n{\r\nif (set->size > 0 && set->primary >= 0)\r\nreturn true;\r\nif (!set->size && set->primary == -1)\r\nreturn true;\r\nif (set->size > 0 && set->primary == -1) {\r\nint i;\r\nfor (i = 0; i < set->size; i++) {\r\nif (set->osds[i] != CRUSH_ITEM_NONE)\r\nbreak;\r\n}\r\nif (i == set->size)\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nvoid ceph_osds_copy(struct ceph_osds *dest, const struct ceph_osds *src)\r\n{\r\nmemcpy(dest->osds, src->osds, src->size * sizeof(src->osds[0]));\r\ndest->size = src->size;\r\ndest->primary = src->primary;\r\n}\r\nstatic bool is_split(const struct ceph_pg *pgid,\r\nu32 old_pg_num,\r\nu32 new_pg_num)\r\n{\r\nint old_bits = calc_bits_of(old_pg_num);\r\nint old_mask = (1 << old_bits) - 1;\r\nint n;\r\nWARN_ON(pgid->seed >= old_pg_num);\r\nif (new_pg_num <= old_pg_num)\r\nreturn false;\r\nfor (n = 1; ; n++) {\r\nint next_bit = n << (old_bits - 1);\r\nu32 s = next_bit | pgid->seed;\r\nif (s < old_pg_num || s == pgid->seed)\r\ncontinue;\r\nif (s >= new_pg_num)\r\nbreak;\r\ns = ceph_stable_mod(s, old_pg_num, old_mask);\r\nif (s == pgid->seed)\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nbool ceph_is_new_interval(const struct ceph_osds *old_acting,\r\nconst struct ceph_osds *new_acting,\r\nconst struct ceph_osds *old_up,\r\nconst struct ceph_osds *new_up,\r\nint old_size,\r\nint new_size,\r\nint old_min_size,\r\nint new_min_size,\r\nu32 old_pg_num,\r\nu32 new_pg_num,\r\nbool old_sort_bitwise,\r\nbool new_sort_bitwise,\r\nconst struct ceph_pg *pgid)\r\n{\r\nreturn !osds_equal(old_acting, new_acting) ||\r\n!osds_equal(old_up, new_up) ||\r\nold_size != new_size ||\r\nold_min_size != new_min_size ||\r\nis_split(pgid, old_pg_num, new_pg_num) ||\r\nold_sort_bitwise != new_sort_bitwise;\r\n}\r\nstatic int calc_pg_rank(int osd, const struct ceph_osds *acting)\r\n{\r\nint i;\r\nfor (i = 0; i < acting->size; i++) {\r\nif (acting->osds[i] == osd)\r\nreturn i;\r\n}\r\nreturn -1;\r\n}\r\nstatic bool primary_changed(const struct ceph_osds *old_acting,\r\nconst struct ceph_osds *new_acting)\r\n{\r\nif (!old_acting->size && !new_acting->size)\r\nreturn false;\r\nif (!old_acting->size ^ !new_acting->size)\r\nreturn true;\r\nif (old_acting->primary != new_acting->primary)\r\nreturn true;\r\nif (calc_pg_rank(old_acting->primary, old_acting) !=\r\ncalc_pg_rank(new_acting->primary, new_acting))\r\nreturn true;\r\nreturn false;\r\n}\r\nbool ceph_osds_changed(const struct ceph_osds *old_acting,\r\nconst struct ceph_osds *new_acting,\r\nbool any_change)\r\n{\r\nif (primary_changed(old_acting, new_acting))\r\nreturn true;\r\nif (any_change && !__osds_equal(old_acting, new_acting))\r\nreturn true;\r\nreturn false;\r\n}\r\nint ceph_calc_file_object_mapping(struct ceph_file_layout *layout,\r\nu64 off, u64 len,\r\nu64 *ono,\r\nu64 *oxoff, u64 *oxlen)\r\n{\r\nu32 osize = layout->object_size;\r\nu32 su = layout->stripe_unit;\r\nu32 sc = layout->stripe_count;\r\nu32 bl, stripeno, stripepos, objsetno;\r\nu32 su_per_object;\r\nu64 t, su_offset;\r\ndout("mapping %llu~%llu osize %u fl_su %u\n", off, len,\r\nosize, su);\r\nif (su == 0 || sc == 0)\r\ngoto invalid;\r\nsu_per_object = osize / su;\r\nif (su_per_object == 0)\r\ngoto invalid;\r\ndout("osize %u / su %u = su_per_object %u\n", osize, su,\r\nsu_per_object);\r\nif ((su & ~PAGE_MASK) != 0)\r\ngoto invalid;\r\nt = off;\r\ndo_div(t, su);\r\nbl = t;\r\ndout("off %llu / su %u = bl %u\n", off, su, bl);\r\nstripeno = bl / sc;\r\nstripepos = bl % sc;\r\nobjsetno = stripeno / su_per_object;\r\n*ono = objsetno * sc + stripepos;\r\ndout("objset %u * sc %u = ono %u\n", objsetno, sc, (unsigned int)*ono);\r\nt = off;\r\nsu_offset = do_div(t, su);\r\n*oxoff = su_offset + (stripeno % su_per_object) * su;\r\n*oxlen = min_t(u64, len, su - su_offset);\r\ndout(" obj extent %llu~%llu\n", *oxoff, *oxlen);\r\nreturn 0;\r\ninvalid:\r\ndout(" invalid layout\n");\r\n*ono = 0;\r\n*oxoff = 0;\r\n*oxlen = 0;\r\nreturn -EINVAL;\r\n}\r\nint ceph_object_locator_to_pg(struct ceph_osdmap *osdmap,\r\nstruct ceph_object_id *oid,\r\nstruct ceph_object_locator *oloc,\r\nstruct ceph_pg *raw_pgid)\r\n{\r\nstruct ceph_pg_pool_info *pi;\r\npi = ceph_pg_pool_by_id(osdmap, oloc->pool);\r\nif (!pi)\r\nreturn -ENOENT;\r\nif (!oloc->pool_ns) {\r\nraw_pgid->pool = oloc->pool;\r\nraw_pgid->seed = ceph_str_hash(pi->object_hash, oid->name,\r\noid->name_len);\r\ndout("%s %s -> raw_pgid %llu.%x\n", __func__, oid->name,\r\nraw_pgid->pool, raw_pgid->seed);\r\n} else {\r\nchar stack_buf[256];\r\nchar *buf = stack_buf;\r\nint nsl = oloc->pool_ns->len;\r\nsize_t total = nsl + 1 + oid->name_len;\r\nif (total > sizeof(stack_buf)) {\r\nbuf = kmalloc(total, GFP_NOIO);\r\nif (!buf)\r\nreturn -ENOMEM;\r\n}\r\nmemcpy(buf, oloc->pool_ns->str, nsl);\r\nbuf[nsl] = '\037';\r\nmemcpy(buf + nsl + 1, oid->name, oid->name_len);\r\nraw_pgid->pool = oloc->pool;\r\nraw_pgid->seed = ceph_str_hash(pi->object_hash, buf, total);\r\nif (buf != stack_buf)\r\nkfree(buf);\r\ndout("%s %s ns %.*s -> raw_pgid %llu.%x\n", __func__,\r\noid->name, nsl, oloc->pool_ns->str,\r\nraw_pgid->pool, raw_pgid->seed);\r\n}\r\nreturn 0;\r\n}\r\nstatic void raw_pg_to_pg(struct ceph_pg_pool_info *pi,\r\nconst struct ceph_pg *raw_pgid,\r\nstruct ceph_pg *pgid)\r\n{\r\npgid->pool = raw_pgid->pool;\r\npgid->seed = ceph_stable_mod(raw_pgid->seed, pi->pg_num,\r\npi->pg_num_mask);\r\n}\r\nstatic u32 raw_pg_to_pps(struct ceph_pg_pool_info *pi,\r\nconst struct ceph_pg *raw_pgid)\r\n{\r\nif (pi->flags & CEPH_POOL_FLAG_HASHPSPOOL) {\r\nreturn crush_hash32_2(CRUSH_HASH_RJENKINS1,\r\nceph_stable_mod(raw_pgid->seed,\r\npi->pgp_num,\r\npi->pgp_num_mask),\r\nraw_pgid->pool);\r\n} else {\r\nreturn ceph_stable_mod(raw_pgid->seed, pi->pgp_num,\r\npi->pgp_num_mask) +\r\n(unsigned)raw_pgid->pool;\r\n}\r\n}\r\nstatic int do_crush(struct ceph_osdmap *map, int ruleno, int x,\r\nint *result, int result_max,\r\nconst __u32 *weight, int weight_max)\r\n{\r\nint r;\r\nBUG_ON(result_max > CEPH_PG_MAX_SIZE);\r\nmutex_lock(&map->crush_scratch_mutex);\r\nr = crush_do_rule(map->crush, ruleno, x, result, result_max,\r\nweight, weight_max, map->crush_scratch_ary);\r\nmutex_unlock(&map->crush_scratch_mutex);\r\nreturn r;\r\n}\r\nstatic void pg_to_raw_osds(struct ceph_osdmap *osdmap,\r\nstruct ceph_pg_pool_info *pi,\r\nconst struct ceph_pg *raw_pgid,\r\nstruct ceph_osds *raw,\r\nu32 *ppps)\r\n{\r\nu32 pps = raw_pg_to_pps(pi, raw_pgid);\r\nint ruleno;\r\nint len;\r\nceph_osds_init(raw);\r\nif (ppps)\r\n*ppps = pps;\r\nruleno = crush_find_rule(osdmap->crush, pi->crush_ruleset, pi->type,\r\npi->size);\r\nif (ruleno < 0) {\r\npr_err("no crush rule: pool %lld ruleset %d type %d size %d\n",\r\npi->id, pi->crush_ruleset, pi->type, pi->size);\r\nreturn;\r\n}\r\nlen = do_crush(osdmap, ruleno, pps, raw->osds,\r\nmin_t(int, pi->size, ARRAY_SIZE(raw->osds)),\r\nosdmap->osd_weight, osdmap->max_osd);\r\nif (len < 0) {\r\npr_err("error %d from crush rule %d: pool %lld ruleset %d type %d size %d\n",\r\nlen, ruleno, pi->id, pi->crush_ruleset, pi->type,\r\npi->size);\r\nreturn;\r\n}\r\nraw->size = len;\r\n}\r\nstatic void raw_to_up_osds(struct ceph_osdmap *osdmap,\r\nstruct ceph_pg_pool_info *pi,\r\nstruct ceph_osds *set)\r\n{\r\nint i;\r\nBUG_ON(set->primary != -1);\r\nif (ceph_can_shift_osds(pi)) {\r\nint removed = 0;\r\nfor (i = 0; i < set->size; i++) {\r\nif (ceph_osd_is_down(osdmap, set->osds[i])) {\r\nremoved++;\r\ncontinue;\r\n}\r\nif (removed)\r\nset->osds[i - removed] = set->osds[i];\r\n}\r\nset->size -= removed;\r\nif (set->size > 0)\r\nset->primary = set->osds[0];\r\n} else {\r\nfor (i = set->size - 1; i >= 0; i--) {\r\nif (ceph_osd_is_down(osdmap, set->osds[i]))\r\nset->osds[i] = CRUSH_ITEM_NONE;\r\nelse\r\nset->primary = set->osds[i];\r\n}\r\n}\r\n}\r\nstatic void apply_primary_affinity(struct ceph_osdmap *osdmap,\r\nstruct ceph_pg_pool_info *pi,\r\nu32 pps,\r\nstruct ceph_osds *up)\r\n{\r\nint i;\r\nint pos = -1;\r\nif (!osdmap->osd_primary_affinity)\r\nreturn;\r\nfor (i = 0; i < up->size; i++) {\r\nint osd = up->osds[i];\r\nif (osd != CRUSH_ITEM_NONE &&\r\nosdmap->osd_primary_affinity[osd] !=\r\nCEPH_OSD_DEFAULT_PRIMARY_AFFINITY) {\r\nbreak;\r\n}\r\n}\r\nif (i == up->size)\r\nreturn;\r\nfor (i = 0; i < up->size; i++) {\r\nint osd = up->osds[i];\r\nu32 aff;\r\nif (osd == CRUSH_ITEM_NONE)\r\ncontinue;\r\naff = osdmap->osd_primary_affinity[osd];\r\nif (aff < CEPH_OSD_MAX_PRIMARY_AFFINITY &&\r\n(crush_hash32_2(CRUSH_HASH_RJENKINS1,\r\npps, osd) >> 16) >= aff) {\r\nif (pos < 0)\r\npos = i;\r\n} else {\r\npos = i;\r\nbreak;\r\n}\r\n}\r\nif (pos < 0)\r\nreturn;\r\nup->primary = up->osds[pos];\r\nif (ceph_can_shift_osds(pi) && pos > 0) {\r\nfor (i = pos; i > 0; i--)\r\nup->osds[i] = up->osds[i - 1];\r\nup->osds[0] = up->primary;\r\n}\r\n}\r\nstatic void get_temp_osds(struct ceph_osdmap *osdmap,\r\nstruct ceph_pg_pool_info *pi,\r\nconst struct ceph_pg *raw_pgid,\r\nstruct ceph_osds *temp)\r\n{\r\nstruct ceph_pg pgid;\r\nstruct ceph_pg_mapping *pg;\r\nint i;\r\nraw_pg_to_pg(pi, raw_pgid, &pgid);\r\nceph_osds_init(temp);\r\npg = __lookup_pg_mapping(&osdmap->pg_temp, pgid);\r\nif (pg) {\r\nfor (i = 0; i < pg->pg_temp.len; i++) {\r\nif (ceph_osd_is_down(osdmap, pg->pg_temp.osds[i])) {\r\nif (ceph_can_shift_osds(pi))\r\ncontinue;\r\ntemp->osds[temp->size++] = CRUSH_ITEM_NONE;\r\n} else {\r\ntemp->osds[temp->size++] = pg->pg_temp.osds[i];\r\n}\r\n}\r\nfor (i = 0; i < temp->size; i++) {\r\nif (temp->osds[i] != CRUSH_ITEM_NONE) {\r\ntemp->primary = temp->osds[i];\r\nbreak;\r\n}\r\n}\r\n}\r\npg = __lookup_pg_mapping(&osdmap->primary_temp, pgid);\r\nif (pg)\r\ntemp->primary = pg->primary_temp.osd;\r\n}\r\nvoid ceph_pg_to_up_acting_osds(struct ceph_osdmap *osdmap,\r\nconst struct ceph_pg *raw_pgid,\r\nstruct ceph_osds *up,\r\nstruct ceph_osds *acting)\r\n{\r\nstruct ceph_pg_pool_info *pi;\r\nu32 pps;\r\npi = ceph_pg_pool_by_id(osdmap, raw_pgid->pool);\r\nif (!pi) {\r\nceph_osds_init(up);\r\nceph_osds_init(acting);\r\ngoto out;\r\n}\r\npg_to_raw_osds(osdmap, pi, raw_pgid, up, &pps);\r\nraw_to_up_osds(osdmap, pi, up);\r\napply_primary_affinity(osdmap, pi, pps, up);\r\nget_temp_osds(osdmap, pi, raw_pgid, acting);\r\nif (!acting->size) {\r\nmemcpy(acting->osds, up->osds, up->size * sizeof(up->osds[0]));\r\nacting->size = up->size;\r\nif (acting->primary == -1)\r\nacting->primary = up->primary;\r\n}\r\nout:\r\nWARN_ON(!osds_valid(up) || !osds_valid(acting));\r\n}\r\nint ceph_pg_to_acting_primary(struct ceph_osdmap *osdmap,\r\nconst struct ceph_pg *raw_pgid)\r\n{\r\nstruct ceph_osds up, acting;\r\nceph_pg_to_up_acting_osds(osdmap, raw_pgid, &up, &acting);\r\nreturn acting.primary;\r\n}
