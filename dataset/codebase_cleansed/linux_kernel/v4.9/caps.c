static char *gcap_string(char *s, int c)\r\n{\r\nif (c & CEPH_CAP_GSHARED)\r\n*s++ = 's';\r\nif (c & CEPH_CAP_GEXCL)\r\n*s++ = 'x';\r\nif (c & CEPH_CAP_GCACHE)\r\n*s++ = 'c';\r\nif (c & CEPH_CAP_GRD)\r\n*s++ = 'r';\r\nif (c & CEPH_CAP_GWR)\r\n*s++ = 'w';\r\nif (c & CEPH_CAP_GBUFFER)\r\n*s++ = 'b';\r\nif (c & CEPH_CAP_GLAZYIO)\r\n*s++ = 'l';\r\nreturn s;\r\n}\r\nconst char *ceph_cap_string(int caps)\r\n{\r\nint i;\r\nchar *s;\r\nint c;\r\nspin_lock(&cap_str_lock);\r\ni = last_cap_str++;\r\nif (last_cap_str == MAX_CAP_STR)\r\nlast_cap_str = 0;\r\nspin_unlock(&cap_str_lock);\r\ns = cap_str[i];\r\nif (caps & CEPH_CAP_PIN)\r\n*s++ = 'p';\r\nc = (caps >> CEPH_CAP_SAUTH) & 3;\r\nif (c) {\r\n*s++ = 'A';\r\ns = gcap_string(s, c);\r\n}\r\nc = (caps >> CEPH_CAP_SLINK) & 3;\r\nif (c) {\r\n*s++ = 'L';\r\ns = gcap_string(s, c);\r\n}\r\nc = (caps >> CEPH_CAP_SXATTR) & 3;\r\nif (c) {\r\n*s++ = 'X';\r\ns = gcap_string(s, c);\r\n}\r\nc = caps >> CEPH_CAP_SFILE;\r\nif (c) {\r\n*s++ = 'F';\r\ns = gcap_string(s, c);\r\n}\r\nif (s == cap_str[i])\r\n*s++ = '-';\r\n*s = 0;\r\nreturn cap_str[i];\r\n}\r\nvoid ceph_caps_init(struct ceph_mds_client *mdsc)\r\n{\r\nINIT_LIST_HEAD(&mdsc->caps_list);\r\nspin_lock_init(&mdsc->caps_list_lock);\r\n}\r\nvoid ceph_caps_finalize(struct ceph_mds_client *mdsc)\r\n{\r\nstruct ceph_cap *cap;\r\nspin_lock(&mdsc->caps_list_lock);\r\nwhile (!list_empty(&mdsc->caps_list)) {\r\ncap = list_first_entry(&mdsc->caps_list,\r\nstruct ceph_cap, caps_item);\r\nlist_del(&cap->caps_item);\r\nkmem_cache_free(ceph_cap_cachep, cap);\r\n}\r\nmdsc->caps_total_count = 0;\r\nmdsc->caps_avail_count = 0;\r\nmdsc->caps_use_count = 0;\r\nmdsc->caps_reserve_count = 0;\r\nmdsc->caps_min_count = 0;\r\nspin_unlock(&mdsc->caps_list_lock);\r\n}\r\nvoid ceph_adjust_min_caps(struct ceph_mds_client *mdsc, int delta)\r\n{\r\nspin_lock(&mdsc->caps_list_lock);\r\nmdsc->caps_min_count += delta;\r\nBUG_ON(mdsc->caps_min_count < 0);\r\nspin_unlock(&mdsc->caps_list_lock);\r\n}\r\nvoid ceph_reserve_caps(struct ceph_mds_client *mdsc,\r\nstruct ceph_cap_reservation *ctx, int need)\r\n{\r\nint i;\r\nstruct ceph_cap *cap;\r\nint have;\r\nint alloc = 0;\r\nLIST_HEAD(newcaps);\r\ndout("reserve caps ctx=%p need=%d\n", ctx, need);\r\nspin_lock(&mdsc->caps_list_lock);\r\nif (mdsc->caps_avail_count >= need)\r\nhave = need;\r\nelse\r\nhave = mdsc->caps_avail_count;\r\nmdsc->caps_avail_count -= have;\r\nmdsc->caps_reserve_count += have;\r\nBUG_ON(mdsc->caps_total_count != mdsc->caps_use_count +\r\nmdsc->caps_reserve_count +\r\nmdsc->caps_avail_count);\r\nspin_unlock(&mdsc->caps_list_lock);\r\nfor (i = have; i < need; i++) {\r\ncap = kmem_cache_alloc(ceph_cap_cachep, GFP_NOFS);\r\nif (!cap)\r\nbreak;\r\nlist_add(&cap->caps_item, &newcaps);\r\nalloc++;\r\n}\r\nif (have + alloc != need)\r\npr_warn("reserve caps ctx=%p ENOMEM need=%d got=%d\n",\r\nctx, need, have + alloc);\r\nspin_lock(&mdsc->caps_list_lock);\r\nmdsc->caps_total_count += alloc;\r\nmdsc->caps_reserve_count += alloc;\r\nlist_splice(&newcaps, &mdsc->caps_list);\r\nBUG_ON(mdsc->caps_total_count != mdsc->caps_use_count +\r\nmdsc->caps_reserve_count +\r\nmdsc->caps_avail_count);\r\nspin_unlock(&mdsc->caps_list_lock);\r\nctx->count = need;\r\ndout("reserve caps ctx=%p %d = %d used + %d resv + %d avail\n",\r\nctx, mdsc->caps_total_count, mdsc->caps_use_count,\r\nmdsc->caps_reserve_count, mdsc->caps_avail_count);\r\n}\r\nint ceph_unreserve_caps(struct ceph_mds_client *mdsc,\r\nstruct ceph_cap_reservation *ctx)\r\n{\r\ndout("unreserve caps ctx=%p count=%d\n", ctx, ctx->count);\r\nif (ctx->count) {\r\nspin_lock(&mdsc->caps_list_lock);\r\nBUG_ON(mdsc->caps_reserve_count < ctx->count);\r\nmdsc->caps_reserve_count -= ctx->count;\r\nmdsc->caps_avail_count += ctx->count;\r\nctx->count = 0;\r\ndout("unreserve caps %d = %d used + %d resv + %d avail\n",\r\nmdsc->caps_total_count, mdsc->caps_use_count,\r\nmdsc->caps_reserve_count, mdsc->caps_avail_count);\r\nBUG_ON(mdsc->caps_total_count != mdsc->caps_use_count +\r\nmdsc->caps_reserve_count +\r\nmdsc->caps_avail_count);\r\nspin_unlock(&mdsc->caps_list_lock);\r\n}\r\nreturn 0;\r\n}\r\nstruct ceph_cap *ceph_get_cap(struct ceph_mds_client *mdsc,\r\nstruct ceph_cap_reservation *ctx)\r\n{\r\nstruct ceph_cap *cap = NULL;\r\nif (!ctx) {\r\ncap = kmem_cache_alloc(ceph_cap_cachep, GFP_NOFS);\r\nif (cap) {\r\nspin_lock(&mdsc->caps_list_lock);\r\nmdsc->caps_use_count++;\r\nmdsc->caps_total_count++;\r\nspin_unlock(&mdsc->caps_list_lock);\r\n}\r\nreturn cap;\r\n}\r\nspin_lock(&mdsc->caps_list_lock);\r\ndout("get_cap ctx=%p (%d) %d = %d used + %d resv + %d avail\n",\r\nctx, ctx->count, mdsc->caps_total_count, mdsc->caps_use_count,\r\nmdsc->caps_reserve_count, mdsc->caps_avail_count);\r\nBUG_ON(!ctx->count);\r\nBUG_ON(ctx->count > mdsc->caps_reserve_count);\r\nBUG_ON(list_empty(&mdsc->caps_list));\r\nctx->count--;\r\nmdsc->caps_reserve_count--;\r\nmdsc->caps_use_count++;\r\ncap = list_first_entry(&mdsc->caps_list, struct ceph_cap, caps_item);\r\nlist_del(&cap->caps_item);\r\nBUG_ON(mdsc->caps_total_count != mdsc->caps_use_count +\r\nmdsc->caps_reserve_count + mdsc->caps_avail_count);\r\nspin_unlock(&mdsc->caps_list_lock);\r\nreturn cap;\r\n}\r\nvoid ceph_put_cap(struct ceph_mds_client *mdsc, struct ceph_cap *cap)\r\n{\r\nspin_lock(&mdsc->caps_list_lock);\r\ndout("put_cap %p %d = %d used + %d resv + %d avail\n",\r\ncap, mdsc->caps_total_count, mdsc->caps_use_count,\r\nmdsc->caps_reserve_count, mdsc->caps_avail_count);\r\nmdsc->caps_use_count--;\r\nif (mdsc->caps_avail_count >= mdsc->caps_reserve_count +\r\nmdsc->caps_min_count) {\r\nmdsc->caps_total_count--;\r\nkmem_cache_free(ceph_cap_cachep, cap);\r\n} else {\r\nmdsc->caps_avail_count++;\r\nlist_add(&cap->caps_item, &mdsc->caps_list);\r\n}\r\nBUG_ON(mdsc->caps_total_count != mdsc->caps_use_count +\r\nmdsc->caps_reserve_count + mdsc->caps_avail_count);\r\nspin_unlock(&mdsc->caps_list_lock);\r\n}\r\nvoid ceph_reservation_status(struct ceph_fs_client *fsc,\r\nint *total, int *avail, int *used, int *reserved,\r\nint *min)\r\n{\r\nstruct ceph_mds_client *mdsc = fsc->mdsc;\r\nif (total)\r\n*total = mdsc->caps_total_count;\r\nif (avail)\r\n*avail = mdsc->caps_avail_count;\r\nif (used)\r\n*used = mdsc->caps_use_count;\r\nif (reserved)\r\n*reserved = mdsc->caps_reserve_count;\r\nif (min)\r\n*min = mdsc->caps_min_count;\r\n}\r\nstatic struct ceph_cap *__get_cap_for_mds(struct ceph_inode_info *ci, int mds)\r\n{\r\nstruct ceph_cap *cap;\r\nstruct rb_node *n = ci->i_caps.rb_node;\r\nwhile (n) {\r\ncap = rb_entry(n, struct ceph_cap, ci_node);\r\nif (mds < cap->mds)\r\nn = n->rb_left;\r\nelse if (mds > cap->mds)\r\nn = n->rb_right;\r\nelse\r\nreturn cap;\r\n}\r\nreturn NULL;\r\n}\r\nstruct ceph_cap *ceph_get_cap_for_mds(struct ceph_inode_info *ci, int mds)\r\n{\r\nstruct ceph_cap *cap;\r\nspin_lock(&ci->i_ceph_lock);\r\ncap = __get_cap_for_mds(ci, mds);\r\nspin_unlock(&ci->i_ceph_lock);\r\nreturn cap;\r\n}\r\nstatic int __ceph_get_cap_mds(struct ceph_inode_info *ci)\r\n{\r\nstruct ceph_cap *cap;\r\nint mds = -1;\r\nstruct rb_node *p;\r\nfor (p = rb_first(&ci->i_caps); p; p = rb_next(p)) {\r\ncap = rb_entry(p, struct ceph_cap, ci_node);\r\nmds = cap->mds;\r\nif (cap->issued & (CEPH_CAP_FILE_WR |\r\nCEPH_CAP_FILE_BUFFER |\r\nCEPH_CAP_FILE_EXCL))\r\nbreak;\r\n}\r\nreturn mds;\r\n}\r\nint ceph_get_cap_mds(struct inode *inode)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nint mds;\r\nspin_lock(&ci->i_ceph_lock);\r\nmds = __ceph_get_cap_mds(ceph_inode(inode));\r\nspin_unlock(&ci->i_ceph_lock);\r\nreturn mds;\r\n}\r\nstatic void __insert_cap_node(struct ceph_inode_info *ci,\r\nstruct ceph_cap *new)\r\n{\r\nstruct rb_node **p = &ci->i_caps.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct ceph_cap *cap = NULL;\r\nwhile (*p) {\r\nparent = *p;\r\ncap = rb_entry(parent, struct ceph_cap, ci_node);\r\nif (new->mds < cap->mds)\r\np = &(*p)->rb_left;\r\nelse if (new->mds > cap->mds)\r\np = &(*p)->rb_right;\r\nelse\r\nBUG();\r\n}\r\nrb_link_node(&new->ci_node, parent, p);\r\nrb_insert_color(&new->ci_node, &ci->i_caps);\r\n}\r\nstatic void __cap_set_timeouts(struct ceph_mds_client *mdsc,\r\nstruct ceph_inode_info *ci)\r\n{\r\nstruct ceph_mount_options *ma = mdsc->fsc->mount_options;\r\nci->i_hold_caps_min = round_jiffies(jiffies +\r\nma->caps_wanted_delay_min * HZ);\r\nci->i_hold_caps_max = round_jiffies(jiffies +\r\nma->caps_wanted_delay_max * HZ);\r\ndout("__cap_set_timeouts %p min %lu max %lu\n", &ci->vfs_inode,\r\nci->i_hold_caps_min - jiffies, ci->i_hold_caps_max - jiffies);\r\n}\r\nstatic void __cap_delay_requeue(struct ceph_mds_client *mdsc,\r\nstruct ceph_inode_info *ci)\r\n{\r\n__cap_set_timeouts(mdsc, ci);\r\ndout("__cap_delay_requeue %p flags %d at %lu\n", &ci->vfs_inode,\r\nci->i_ceph_flags, ci->i_hold_caps_max);\r\nif (!mdsc->stopping) {\r\nspin_lock(&mdsc->cap_delay_lock);\r\nif (!list_empty(&ci->i_cap_delay_list)) {\r\nif (ci->i_ceph_flags & CEPH_I_FLUSH)\r\ngoto no_change;\r\nlist_del_init(&ci->i_cap_delay_list);\r\n}\r\nlist_add_tail(&ci->i_cap_delay_list, &mdsc->cap_delay_list);\r\nno_change:\r\nspin_unlock(&mdsc->cap_delay_lock);\r\n}\r\n}\r\nstatic void __cap_delay_requeue_front(struct ceph_mds_client *mdsc,\r\nstruct ceph_inode_info *ci)\r\n{\r\ndout("__cap_delay_requeue_front %p\n", &ci->vfs_inode);\r\nspin_lock(&mdsc->cap_delay_lock);\r\nci->i_ceph_flags |= CEPH_I_FLUSH;\r\nif (!list_empty(&ci->i_cap_delay_list))\r\nlist_del_init(&ci->i_cap_delay_list);\r\nlist_add(&ci->i_cap_delay_list, &mdsc->cap_delay_list);\r\nspin_unlock(&mdsc->cap_delay_lock);\r\n}\r\nstatic void __cap_delay_cancel(struct ceph_mds_client *mdsc,\r\nstruct ceph_inode_info *ci)\r\n{\r\ndout("__cap_delay_cancel %p\n", &ci->vfs_inode);\r\nif (list_empty(&ci->i_cap_delay_list))\r\nreturn;\r\nspin_lock(&mdsc->cap_delay_lock);\r\nlist_del_init(&ci->i_cap_delay_list);\r\nspin_unlock(&mdsc->cap_delay_lock);\r\n}\r\nstatic void __check_cap_issue(struct ceph_inode_info *ci, struct ceph_cap *cap,\r\nunsigned issued)\r\n{\r\nunsigned had = __ceph_caps_issued(ci, NULL);\r\nif ((issued & (CEPH_CAP_FILE_CACHE|CEPH_CAP_FILE_LAZYIO)) &&\r\n(had & (CEPH_CAP_FILE_CACHE|CEPH_CAP_FILE_LAZYIO)) == 0) {\r\nci->i_rdcache_gen++;\r\n}\r\nif ((issued & CEPH_CAP_FILE_SHARED) &&\r\n(had & CEPH_CAP_FILE_SHARED) == 0) {\r\nci->i_shared_gen++;\r\nif (S_ISDIR(ci->vfs_inode.i_mode)) {\r\ndout(" marking %p NOT complete\n", &ci->vfs_inode);\r\n__ceph_dir_clear_complete(ci);\r\n}\r\n}\r\n}\r\nvoid ceph_add_cap(struct inode *inode,\r\nstruct ceph_mds_session *session, u64 cap_id,\r\nint fmode, unsigned issued, unsigned wanted,\r\nunsigned seq, unsigned mseq, u64 realmino, int flags,\r\nstruct ceph_cap **new_cap)\r\n{\r\nstruct ceph_mds_client *mdsc = ceph_inode_to_client(inode)->mdsc;\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_cap *cap;\r\nint mds = session->s_mds;\r\nint actual_wanted;\r\ndout("add_cap %p mds%d cap %llx %s seq %d\n", inode,\r\nsession->s_mds, cap_id, ceph_cap_string(issued), seq);\r\nif (fmode >= 0)\r\nwanted |= ceph_caps_for_mode(fmode);\r\ncap = __get_cap_for_mds(ci, mds);\r\nif (!cap) {\r\ncap = *new_cap;\r\n*new_cap = NULL;\r\ncap->issued = 0;\r\ncap->implemented = 0;\r\ncap->mds = mds;\r\ncap->mds_wanted = 0;\r\ncap->mseq = 0;\r\ncap->ci = ci;\r\n__insert_cap_node(ci, cap);\r\ncap->session = session;\r\nspin_lock(&session->s_cap_lock);\r\nlist_add_tail(&cap->session_caps, &session->s_caps);\r\nsession->s_nr_caps++;\r\nspin_unlock(&session->s_cap_lock);\r\n} else {\r\nif (ceph_seq_cmp(seq, cap->seq) <= 0) {\r\nWARN_ON(cap != ci->i_auth_cap);\r\nWARN_ON(cap->cap_id != cap_id);\r\nseq = cap->seq;\r\nmseq = cap->mseq;\r\nissued |= cap->issued;\r\nflags |= CEPH_CAP_FLAG_AUTH;\r\n}\r\n}\r\nif (!ci->i_snap_realm) {\r\nstruct ceph_snap_realm *realm = ceph_lookup_snap_realm(mdsc,\r\nrealmino);\r\nif (realm) {\r\nspin_lock(&realm->inodes_with_caps_lock);\r\nci->i_snap_realm = realm;\r\nlist_add(&ci->i_snap_realm_item,\r\n&realm->inodes_with_caps);\r\nspin_unlock(&realm->inodes_with_caps_lock);\r\n} else {\r\npr_err("ceph_add_cap: couldn't find snap realm %llx\n",\r\nrealmino);\r\nWARN_ON(!realm);\r\n}\r\n}\r\n__check_cap_issue(ci, cap, issued);\r\nactual_wanted = __ceph_caps_wanted(ci);\r\nif ((wanted & ~actual_wanted) ||\r\n(issued & ~actual_wanted & CEPH_CAP_ANY_WR)) {\r\ndout(" issued %s, mds wanted %s, actual %s, queueing\n",\r\nceph_cap_string(issued), ceph_cap_string(wanted),\r\nceph_cap_string(actual_wanted));\r\n__cap_delay_requeue(mdsc, ci);\r\n}\r\nif (flags & CEPH_CAP_FLAG_AUTH) {\r\nif (ci->i_auth_cap == NULL ||\r\nceph_seq_cmp(ci->i_auth_cap->mseq, mseq) < 0) {\r\nci->i_auth_cap = cap;\r\ncap->mds_wanted = wanted;\r\n}\r\n} else {\r\nWARN_ON(ci->i_auth_cap == cap);\r\n}\r\ndout("add_cap inode %p (%llx.%llx) cap %p %s now %s seq %d mds%d\n",\r\ninode, ceph_vinop(inode), cap, ceph_cap_string(issued),\r\nceph_cap_string(issued|cap->issued), seq, mds);\r\ncap->cap_id = cap_id;\r\ncap->issued = issued;\r\ncap->implemented |= issued;\r\nif (ceph_seq_cmp(mseq, cap->mseq) > 0)\r\ncap->mds_wanted = wanted;\r\nelse\r\ncap->mds_wanted |= wanted;\r\ncap->seq = seq;\r\ncap->issue_seq = seq;\r\ncap->mseq = mseq;\r\ncap->cap_gen = session->s_cap_gen;\r\nif (fmode >= 0)\r\n__ceph_get_fmode(ci, fmode);\r\n}\r\nstatic int __cap_is_valid(struct ceph_cap *cap)\r\n{\r\nunsigned long ttl;\r\nu32 gen;\r\nspin_lock(&cap->session->s_gen_ttl_lock);\r\ngen = cap->session->s_cap_gen;\r\nttl = cap->session->s_cap_ttl;\r\nspin_unlock(&cap->session->s_gen_ttl_lock);\r\nif (cap->cap_gen < gen || time_after_eq(jiffies, ttl)) {\r\ndout("__cap_is_valid %p cap %p issued %s "\r\n"but STALE (gen %u vs %u)\n", &cap->ci->vfs_inode,\r\ncap, ceph_cap_string(cap->issued), cap->cap_gen, gen);\r\nreturn 0;\r\n}\r\nreturn 1;\r\n}\r\nint __ceph_caps_issued(struct ceph_inode_info *ci, int *implemented)\r\n{\r\nint have = ci->i_snap_caps;\r\nstruct ceph_cap *cap;\r\nstruct rb_node *p;\r\nif (implemented)\r\n*implemented = 0;\r\nfor (p = rb_first(&ci->i_caps); p; p = rb_next(p)) {\r\ncap = rb_entry(p, struct ceph_cap, ci_node);\r\nif (!__cap_is_valid(cap))\r\ncontinue;\r\ndout("__ceph_caps_issued %p cap %p issued %s\n",\r\n&ci->vfs_inode, cap, ceph_cap_string(cap->issued));\r\nhave |= cap->issued;\r\nif (implemented)\r\n*implemented |= cap->implemented;\r\n}\r\nif (ci->i_auth_cap) {\r\ncap = ci->i_auth_cap;\r\nhave &= ~cap->implemented | cap->issued;\r\n}\r\nreturn have;\r\n}\r\nint __ceph_caps_issued_other(struct ceph_inode_info *ci, struct ceph_cap *ocap)\r\n{\r\nint have = ci->i_snap_caps;\r\nstruct ceph_cap *cap;\r\nstruct rb_node *p;\r\nfor (p = rb_first(&ci->i_caps); p; p = rb_next(p)) {\r\ncap = rb_entry(p, struct ceph_cap, ci_node);\r\nif (cap == ocap)\r\ncontinue;\r\nif (!__cap_is_valid(cap))\r\ncontinue;\r\nhave |= cap->issued;\r\n}\r\nreturn have;\r\n}\r\nstatic void __touch_cap(struct ceph_cap *cap)\r\n{\r\nstruct ceph_mds_session *s = cap->session;\r\nspin_lock(&s->s_cap_lock);\r\nif (s->s_cap_iterator == NULL) {\r\ndout("__touch_cap %p cap %p mds%d\n", &cap->ci->vfs_inode, cap,\r\ns->s_mds);\r\nlist_move_tail(&cap->session_caps, &s->s_caps);\r\n} else {\r\ndout("__touch_cap %p cap %p mds%d NOP, iterating over caps\n",\r\n&cap->ci->vfs_inode, cap, s->s_mds);\r\n}\r\nspin_unlock(&s->s_cap_lock);\r\n}\r\nint __ceph_caps_issued_mask(struct ceph_inode_info *ci, int mask, int touch)\r\n{\r\nstruct ceph_cap *cap;\r\nstruct rb_node *p;\r\nint have = ci->i_snap_caps;\r\nif ((have & mask) == mask) {\r\ndout("__ceph_caps_issued_mask %p snap issued %s"\r\n" (mask %s)\n", &ci->vfs_inode,\r\nceph_cap_string(have),\r\nceph_cap_string(mask));\r\nreturn 1;\r\n}\r\nfor (p = rb_first(&ci->i_caps); p; p = rb_next(p)) {\r\ncap = rb_entry(p, struct ceph_cap, ci_node);\r\nif (!__cap_is_valid(cap))\r\ncontinue;\r\nif ((cap->issued & mask) == mask) {\r\ndout("__ceph_caps_issued_mask %p cap %p issued %s"\r\n" (mask %s)\n", &ci->vfs_inode, cap,\r\nceph_cap_string(cap->issued),\r\nceph_cap_string(mask));\r\nif (touch)\r\n__touch_cap(cap);\r\nreturn 1;\r\n}\r\nhave |= cap->issued;\r\nif ((have & mask) == mask) {\r\ndout("__ceph_caps_issued_mask %p combo issued %s"\r\n" (mask %s)\n", &ci->vfs_inode,\r\nceph_cap_string(cap->issued),\r\nceph_cap_string(mask));\r\nif (touch) {\r\nstruct rb_node *q;\r\n__touch_cap(cap);\r\nfor (q = rb_first(&ci->i_caps); q != p;\r\nq = rb_next(q)) {\r\ncap = rb_entry(q, struct ceph_cap,\r\nci_node);\r\nif (!__cap_is_valid(cap))\r\ncontinue;\r\n__touch_cap(cap);\r\n}\r\n}\r\nreturn 1;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint __ceph_caps_revoking_other(struct ceph_inode_info *ci,\r\nstruct ceph_cap *ocap, int mask)\r\n{\r\nstruct ceph_cap *cap;\r\nstruct rb_node *p;\r\nfor (p = rb_first(&ci->i_caps); p; p = rb_next(p)) {\r\ncap = rb_entry(p, struct ceph_cap, ci_node);\r\nif (cap != ocap &&\r\n(cap->implemented & ~cap->issued & mask))\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nint ceph_caps_revoking(struct ceph_inode_info *ci, int mask)\r\n{\r\nstruct inode *inode = &ci->vfs_inode;\r\nint ret;\r\nspin_lock(&ci->i_ceph_lock);\r\nret = __ceph_caps_revoking_other(ci, NULL, mask);\r\nspin_unlock(&ci->i_ceph_lock);\r\ndout("ceph_caps_revoking %p %s = %d\n", inode,\r\nceph_cap_string(mask), ret);\r\nreturn ret;\r\n}\r\nint __ceph_caps_used(struct ceph_inode_info *ci)\r\n{\r\nint used = 0;\r\nif (ci->i_pin_ref)\r\nused |= CEPH_CAP_PIN;\r\nif (ci->i_rd_ref)\r\nused |= CEPH_CAP_FILE_RD;\r\nif (ci->i_rdcache_ref ||\r\n(!S_ISDIR(ci->vfs_inode.i_mode) &&\r\nci->vfs_inode.i_data.nrpages))\r\nused |= CEPH_CAP_FILE_CACHE;\r\nif (ci->i_wr_ref)\r\nused |= CEPH_CAP_FILE_WR;\r\nif (ci->i_wb_ref || ci->i_wrbuffer_ref)\r\nused |= CEPH_CAP_FILE_BUFFER;\r\nreturn used;\r\n}\r\nint __ceph_caps_file_wanted(struct ceph_inode_info *ci)\r\n{\r\nint i, bits = 0;\r\nfor (i = 0; i < CEPH_FILE_MODE_BITS; i++) {\r\nif (ci->i_nr_by_mode[i])\r\nbits |= 1 << i;\r\n}\r\nif (bits == 0)\r\nreturn 0;\r\nreturn ceph_caps_for_mode(bits >> 1);\r\n}\r\nint __ceph_caps_mds_wanted(struct ceph_inode_info *ci)\r\n{\r\nstruct ceph_cap *cap;\r\nstruct rb_node *p;\r\nint mds_wanted = 0;\r\nfor (p = rb_first(&ci->i_caps); p; p = rb_next(p)) {\r\ncap = rb_entry(p, struct ceph_cap, ci_node);\r\nif (!__cap_is_valid(cap))\r\ncontinue;\r\nif (cap == ci->i_auth_cap)\r\nmds_wanted |= cap->mds_wanted;\r\nelse\r\nmds_wanted |= (cap->mds_wanted & ~CEPH_CAP_ANY_FILE_WR);\r\n}\r\nreturn mds_wanted;\r\n}\r\nstatic int __ceph_is_any_caps(struct ceph_inode_info *ci)\r\n{\r\nreturn !RB_EMPTY_ROOT(&ci->i_caps);\r\n}\r\nint ceph_is_any_caps(struct inode *inode)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nint ret;\r\nspin_lock(&ci->i_ceph_lock);\r\nret = __ceph_is_any_caps(ci);\r\nspin_unlock(&ci->i_ceph_lock);\r\nreturn ret;\r\n}\r\nstatic void drop_inode_snap_realm(struct ceph_inode_info *ci)\r\n{\r\nstruct ceph_snap_realm *realm = ci->i_snap_realm;\r\nspin_lock(&realm->inodes_with_caps_lock);\r\nlist_del_init(&ci->i_snap_realm_item);\r\nci->i_snap_realm_counter++;\r\nci->i_snap_realm = NULL;\r\nspin_unlock(&realm->inodes_with_caps_lock);\r\nceph_put_snap_realm(ceph_sb_to_client(ci->vfs_inode.i_sb)->mdsc,\r\nrealm);\r\n}\r\nvoid __ceph_remove_cap(struct ceph_cap *cap, bool queue_release)\r\n{\r\nstruct ceph_mds_session *session = cap->session;\r\nstruct ceph_inode_info *ci = cap->ci;\r\nstruct ceph_mds_client *mdsc =\r\nceph_sb_to_client(ci->vfs_inode.i_sb)->mdsc;\r\nint removed = 0;\r\ndout("__ceph_remove_cap %p from %p\n", cap, &ci->vfs_inode);\r\nspin_lock(&session->s_cap_lock);\r\nif (session->s_cap_iterator == cap) {\r\ndout("__ceph_remove_cap delaying %p removal from session %p\n",\r\ncap, cap->session);\r\n} else {\r\nlist_del_init(&cap->session_caps);\r\nsession->s_nr_caps--;\r\ncap->session = NULL;\r\nremoved = 1;\r\n}\r\ncap->ci = NULL;\r\nif (queue_release &&\r\n(!session->s_cap_reconnect || cap->cap_gen == session->s_cap_gen)) {\r\ncap->queue_release = 1;\r\nif (removed) {\r\nlist_add_tail(&cap->session_caps,\r\n&session->s_cap_releases);\r\nsession->s_num_cap_releases++;\r\nremoved = 0;\r\n}\r\n} else {\r\ncap->queue_release = 0;\r\n}\r\ncap->cap_ino = ci->i_vino.ino;\r\nspin_unlock(&session->s_cap_lock);\r\nrb_erase(&cap->ci_node, &ci->i_caps);\r\nif (ci->i_auth_cap == cap)\r\nci->i_auth_cap = NULL;\r\nif (removed)\r\nceph_put_cap(mdsc, cap);\r\nif (!__ceph_is_any_caps(ci) && ci->i_wr_ref == 0 && ci->i_snap_realm)\r\ndrop_inode_snap_realm(ci);\r\nif (!__ceph_is_any_real_caps(ci))\r\n__cap_delay_cancel(mdsc, ci);\r\n}\r\nstatic int send_cap_msg(struct ceph_mds_session *session,\r\nu64 ino, u64 cid, int op,\r\nint caps, int wanted, int dirty,\r\nu32 seq, u64 flush_tid, u64 oldest_flush_tid,\r\nu32 issue_seq, u32 mseq, u64 size, u64 max_size,\r\nstruct timespec *mtime, struct timespec *atime,\r\nstruct timespec *ctime, u32 time_warp_seq,\r\nkuid_t uid, kgid_t gid, umode_t mode,\r\nu64 xattr_version,\r\nstruct ceph_buffer *xattrs_buf,\r\nu64 follows, bool inline_data)\r\n{\r\nstruct ceph_mds_caps *fc;\r\nstruct ceph_msg *msg;\r\nvoid *p;\r\nsize_t extra_len;\r\ndout("send_cap_msg %s %llx %llx caps %s wanted %s dirty %s"\r\n" seq %u/%u tid %llu/%llu mseq %u follows %lld size %llu/%llu"\r\n" xattr_ver %llu xattr_len %d\n", ceph_cap_op_name(op),\r\ncid, ino, ceph_cap_string(caps), ceph_cap_string(wanted),\r\nceph_cap_string(dirty),\r\nseq, issue_seq, flush_tid, oldest_flush_tid,\r\nmseq, follows, size, max_size,\r\nxattr_version, xattrs_buf ? (int)xattrs_buf->vec.iov_len : 0);\r\nextra_len = 4 + 8 + 4 + 4 + 8;\r\nmsg = ceph_msg_new(CEPH_MSG_CLIENT_CAPS, sizeof(*fc) + extra_len,\r\nGFP_NOFS, false);\r\nif (!msg)\r\nreturn -ENOMEM;\r\nmsg->hdr.version = cpu_to_le16(6);\r\nmsg->hdr.tid = cpu_to_le64(flush_tid);\r\nfc = msg->front.iov_base;\r\nmemset(fc, 0, sizeof(*fc));\r\nfc->cap_id = cpu_to_le64(cid);\r\nfc->op = cpu_to_le32(op);\r\nfc->seq = cpu_to_le32(seq);\r\nfc->issue_seq = cpu_to_le32(issue_seq);\r\nfc->migrate_seq = cpu_to_le32(mseq);\r\nfc->caps = cpu_to_le32(caps);\r\nfc->wanted = cpu_to_le32(wanted);\r\nfc->dirty = cpu_to_le32(dirty);\r\nfc->ino = cpu_to_le64(ino);\r\nfc->snap_follows = cpu_to_le64(follows);\r\nfc->size = cpu_to_le64(size);\r\nfc->max_size = cpu_to_le64(max_size);\r\nif (mtime)\r\nceph_encode_timespec(&fc->mtime, mtime);\r\nif (atime)\r\nceph_encode_timespec(&fc->atime, atime);\r\nif (ctime)\r\nceph_encode_timespec(&fc->ctime, ctime);\r\nfc->time_warp_seq = cpu_to_le32(time_warp_seq);\r\nfc->uid = cpu_to_le32(from_kuid(&init_user_ns, uid));\r\nfc->gid = cpu_to_le32(from_kgid(&init_user_ns, gid));\r\nfc->mode = cpu_to_le32(mode);\r\np = fc + 1;\r\nceph_encode_32(&p, 0);\r\nceph_encode_64(&p, inline_data ? 0 : CEPH_INLINE_NONE);\r\nceph_encode_32(&p, 0);\r\nceph_encode_32(&p, 0);\r\nceph_encode_64(&p, oldest_flush_tid);\r\nfc->xattr_version = cpu_to_le64(xattr_version);\r\nif (xattrs_buf) {\r\nmsg->middle = ceph_buffer_get(xattrs_buf);\r\nfc->xattr_len = cpu_to_le32(xattrs_buf->vec.iov_len);\r\nmsg->hdr.middle_len = cpu_to_le32(xattrs_buf->vec.iov_len);\r\n}\r\nceph_con_send(&session->s_con, msg);\r\nreturn 0;\r\n}\r\nvoid ceph_queue_caps_release(struct inode *inode)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct rb_node *p;\r\np = rb_first(&ci->i_caps);\r\nwhile (p) {\r\nstruct ceph_cap *cap = rb_entry(p, struct ceph_cap, ci_node);\r\np = rb_next(p);\r\n__ceph_remove_cap(cap, true);\r\n}\r\n}\r\nstatic int __send_cap(struct ceph_mds_client *mdsc, struct ceph_cap *cap,\r\nint op, int used, int want, int retain, int flushing,\r\nu64 flush_tid, u64 oldest_flush_tid)\r\n__releases(cap->ci->i_ceph_lock)\r\n{\r\nstruct ceph_inode_info *ci = cap->ci;\r\nstruct inode *inode = &ci->vfs_inode;\r\nu64 cap_id = cap->cap_id;\r\nint held, revoking, dropping, keep;\r\nu64 follows, size, max_size;\r\nu32 seq, issue_seq, mseq, time_warp_seq;\r\nstruct timespec mtime, atime, ctime;\r\nint wake = 0;\r\numode_t mode;\r\nkuid_t uid;\r\nkgid_t gid;\r\nstruct ceph_mds_session *session;\r\nu64 xattr_version = 0;\r\nstruct ceph_buffer *xattr_blob = NULL;\r\nint delayed = 0;\r\nint ret;\r\nbool inline_data;\r\nheld = cap->issued | cap->implemented;\r\nrevoking = cap->implemented & ~cap->issued;\r\nretain &= ~revoking;\r\ndropping = cap->issued & ~retain;\r\ndout("__send_cap %p cap %p session %p %s -> %s (revoking %s)\n",\r\ninode, cap, cap->session,\r\nceph_cap_string(held), ceph_cap_string(held & retain),\r\nceph_cap_string(revoking));\r\nBUG_ON((retain & CEPH_CAP_PIN) == 0);\r\nsession = cap->session;\r\nif ((ci->i_ceph_flags & CEPH_I_NODELAY) == 0 &&\r\ntime_before(jiffies, ci->i_hold_caps_min)) {\r\ndout(" delaying issued %s -> %s, wanted %s -> %s on send\n",\r\nceph_cap_string(cap->issued),\r\nceph_cap_string(cap->issued & retain),\r\nceph_cap_string(cap->mds_wanted),\r\nceph_cap_string(want));\r\nwant |= cap->mds_wanted;\r\nretain |= cap->issued;\r\ndelayed = 1;\r\n}\r\nci->i_ceph_flags &= ~(CEPH_I_NODELAY | CEPH_I_FLUSH);\r\ncap->issued &= retain;\r\nif (cap->implemented & ~cap->issued) {\r\nwake = 1;\r\n}\r\ncap->implemented &= cap->issued | used;\r\ncap->mds_wanted = want;\r\nfollows = flushing ? ci->i_head_snapc->seq : 0;\r\nkeep = cap->implemented;\r\nseq = cap->seq;\r\nissue_seq = cap->issue_seq;\r\nmseq = cap->mseq;\r\nsize = inode->i_size;\r\nci->i_reported_size = size;\r\nmax_size = ci->i_wanted_max_size;\r\nci->i_requested_max_size = max_size;\r\nmtime = inode->i_mtime;\r\natime = inode->i_atime;\r\nctime = inode->i_ctime;\r\ntime_warp_seq = ci->i_time_warp_seq;\r\nuid = inode->i_uid;\r\ngid = inode->i_gid;\r\nmode = inode->i_mode;\r\nif (flushing & CEPH_CAP_XATTR_EXCL) {\r\n__ceph_build_xattrs_blob(ci);\r\nxattr_blob = ci->i_xattrs.blob;\r\nxattr_version = ci->i_xattrs.version;\r\n}\r\ninline_data = ci->i_inline_version != CEPH_INLINE_NONE;\r\nspin_unlock(&ci->i_ceph_lock);\r\nret = send_cap_msg(session, ceph_vino(inode).ino, cap_id,\r\nop, keep, want, flushing, seq,\r\nflush_tid, oldest_flush_tid, issue_seq, mseq,\r\nsize, max_size, &mtime, &atime, &ctime, time_warp_seq,\r\nuid, gid, mode, xattr_version, xattr_blob,\r\nfollows, inline_data);\r\nif (ret < 0) {\r\ndout("error sending cap msg, must requeue %p\n", inode);\r\ndelayed = 1;\r\n}\r\nif (wake)\r\nwake_up_all(&ci->i_cap_wq);\r\nreturn delayed;\r\n}\r\nstatic inline int __send_flush_snap(struct inode *inode,\r\nstruct ceph_mds_session *session,\r\nstruct ceph_cap_snap *capsnap,\r\nu32 mseq, u64 oldest_flush_tid)\r\n{\r\nreturn send_cap_msg(session, ceph_vino(inode).ino, 0,\r\nCEPH_CAP_OP_FLUSHSNAP, capsnap->issued, 0,\r\ncapsnap->dirty, 0, capsnap->cap_flush.tid,\r\noldest_flush_tid, 0, mseq, capsnap->size, 0,\r\n&capsnap->mtime, &capsnap->atime,\r\n&capsnap->ctime, capsnap->time_warp_seq,\r\ncapsnap->uid, capsnap->gid, capsnap->mode,\r\ncapsnap->xattr_version, capsnap->xattr_blob,\r\ncapsnap->follows, capsnap->inline_data);\r\n}\r\nstatic void __ceph_flush_snaps(struct ceph_inode_info *ci,\r\nstruct ceph_mds_session *session)\r\n__releases(ci->i_ceph_lock)\r\n__acquires(ci->i_ceph_lock)\r\n{\r\nstruct inode *inode = &ci->vfs_inode;\r\nstruct ceph_mds_client *mdsc = session->s_mdsc;\r\nstruct ceph_cap_snap *capsnap;\r\nu64 oldest_flush_tid = 0;\r\nu64 first_tid = 1, last_tid = 0;\r\ndout("__flush_snaps %p session %p\n", inode, session);\r\nlist_for_each_entry(capsnap, &ci->i_cap_snaps, ci_item) {\r\nif (capsnap->dirty_pages || capsnap->writing)\r\nbreak;\r\nBUG_ON(!capsnap->need_flush);\r\nif (capsnap->cap_flush.tid > 0) {\r\ndout(" already flushed %p, skipping\n", capsnap);\r\ncontinue;\r\n}\r\nspin_lock(&mdsc->cap_dirty_lock);\r\ncapsnap->cap_flush.tid = ++mdsc->last_cap_flush_tid;\r\nlist_add_tail(&capsnap->cap_flush.g_list,\r\n&mdsc->cap_flush_list);\r\nif (oldest_flush_tid == 0)\r\noldest_flush_tid = __get_oldest_flush_tid(mdsc);\r\nif (list_empty(&ci->i_flushing_item)) {\r\nlist_add_tail(&ci->i_flushing_item,\r\n&session->s_cap_flushing);\r\n}\r\nspin_unlock(&mdsc->cap_dirty_lock);\r\nlist_add_tail(&capsnap->cap_flush.i_list,\r\n&ci->i_cap_flush_list);\r\nif (first_tid == 1)\r\nfirst_tid = capsnap->cap_flush.tid;\r\nlast_tid = capsnap->cap_flush.tid;\r\n}\r\nci->i_ceph_flags &= ~CEPH_I_FLUSH_SNAPS;\r\nwhile (first_tid <= last_tid) {\r\nstruct ceph_cap *cap = ci->i_auth_cap;\r\nstruct ceph_cap_flush *cf;\r\nint ret;\r\nif (!(cap && cap->session == session)) {\r\ndout("__flush_snaps %p auth cap %p not mds%d, "\r\n"stop\n", inode, cap, session->s_mds);\r\nbreak;\r\n}\r\nret = -ENOENT;\r\nlist_for_each_entry(cf, &ci->i_cap_flush_list, i_list) {\r\nif (cf->tid >= first_tid) {\r\nret = 0;\r\nbreak;\r\n}\r\n}\r\nif (ret < 0)\r\nbreak;\r\nfirst_tid = cf->tid + 1;\r\ncapsnap = container_of(cf, struct ceph_cap_snap, cap_flush);\r\natomic_inc(&capsnap->nref);\r\nspin_unlock(&ci->i_ceph_lock);\r\ndout("__flush_snaps %p capsnap %p tid %llu %s\n",\r\ninode, capsnap, cf->tid, ceph_cap_string(capsnap->dirty));\r\nret = __send_flush_snap(inode, session, capsnap, cap->mseq,\r\noldest_flush_tid);\r\nif (ret < 0) {\r\npr_err("__flush_snaps: error sending cap flushsnap, "\r\n"ino (%llx.%llx) tid %llu follows %llu\n",\r\nceph_vinop(inode), cf->tid, capsnap->follows);\r\n}\r\nceph_put_cap_snap(capsnap);\r\nspin_lock(&ci->i_ceph_lock);\r\n}\r\n}\r\nvoid ceph_flush_snaps(struct ceph_inode_info *ci,\r\nstruct ceph_mds_session **psession)\r\n{\r\nstruct inode *inode = &ci->vfs_inode;\r\nstruct ceph_mds_client *mdsc = ceph_inode_to_client(inode)->mdsc;\r\nstruct ceph_mds_session *session = NULL;\r\nint mds;\r\ndout("ceph_flush_snaps %p\n", inode);\r\nif (psession)\r\nsession = *psession;\r\nretry:\r\nspin_lock(&ci->i_ceph_lock);\r\nif (!(ci->i_ceph_flags & CEPH_I_FLUSH_SNAPS)) {\r\ndout(" no capsnap needs flush, doing nothing\n");\r\ngoto out;\r\n}\r\nif (!ci->i_auth_cap) {\r\ndout(" no auth cap (migrating?), doing nothing\n");\r\ngoto out;\r\n}\r\nmds = ci->i_auth_cap->session->s_mds;\r\nif (session && session->s_mds != mds) {\r\ndout(" oops, wrong session %p mutex\n", session);\r\nmutex_unlock(&session->s_mutex);\r\nceph_put_mds_session(session);\r\nsession = NULL;\r\n}\r\nif (!session) {\r\nspin_unlock(&ci->i_ceph_lock);\r\nmutex_lock(&mdsc->mutex);\r\nsession = __ceph_lookup_mds_session(mdsc, mds);\r\nmutex_unlock(&mdsc->mutex);\r\nif (session) {\r\ndout(" inverting session/ino locks on %p\n", session);\r\nmutex_lock(&session->s_mutex);\r\n}\r\ngoto retry;\r\n}\r\n__ceph_flush_snaps(ci, session);\r\nout:\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (psession) {\r\n*psession = session;\r\n} else {\r\nmutex_unlock(&session->s_mutex);\r\nceph_put_mds_session(session);\r\n}\r\nspin_lock(&mdsc->snap_flush_lock);\r\nlist_del_init(&ci->i_snap_flush_item);\r\nspin_unlock(&mdsc->snap_flush_lock);\r\n}\r\nint __ceph_mark_dirty_caps(struct ceph_inode_info *ci, int mask,\r\nstruct ceph_cap_flush **pcf)\r\n{\r\nstruct ceph_mds_client *mdsc =\r\nceph_sb_to_client(ci->vfs_inode.i_sb)->mdsc;\r\nstruct inode *inode = &ci->vfs_inode;\r\nint was = ci->i_dirty_caps;\r\nint dirty = 0;\r\nif (!ci->i_auth_cap) {\r\npr_warn("__mark_dirty_caps %p %llx mask %s, "\r\n"but no auth cap (session was closed?)\n",\r\ninode, ceph_ino(inode), ceph_cap_string(mask));\r\nreturn 0;\r\n}\r\ndout("__mark_dirty_caps %p %s dirty %s -> %s\n", &ci->vfs_inode,\r\nceph_cap_string(mask), ceph_cap_string(was),\r\nceph_cap_string(was | mask));\r\nci->i_dirty_caps |= mask;\r\nif (was == 0) {\r\nWARN_ON_ONCE(ci->i_prealloc_cap_flush);\r\nswap(ci->i_prealloc_cap_flush, *pcf);\r\nif (!ci->i_head_snapc) {\r\nWARN_ON_ONCE(!rwsem_is_locked(&mdsc->snap_rwsem));\r\nci->i_head_snapc = ceph_get_snap_context(\r\nci->i_snap_realm->cached_context);\r\n}\r\ndout(" inode %p now dirty snapc %p auth cap %p\n",\r\n&ci->vfs_inode, ci->i_head_snapc, ci->i_auth_cap);\r\nBUG_ON(!list_empty(&ci->i_dirty_item));\r\nspin_lock(&mdsc->cap_dirty_lock);\r\nlist_add(&ci->i_dirty_item, &mdsc->cap_dirty);\r\nspin_unlock(&mdsc->cap_dirty_lock);\r\nif (ci->i_flushing_caps == 0) {\r\nihold(inode);\r\ndirty |= I_DIRTY_SYNC;\r\n}\r\n} else {\r\nWARN_ON_ONCE(!ci->i_prealloc_cap_flush);\r\n}\r\nBUG_ON(list_empty(&ci->i_dirty_item));\r\nif (((was | ci->i_flushing_caps) & CEPH_CAP_FILE_BUFFER) &&\r\n(mask & CEPH_CAP_FILE_BUFFER))\r\ndirty |= I_DIRTY_DATASYNC;\r\n__cap_delay_requeue(mdsc, ci);\r\nreturn dirty;\r\n}\r\nstruct ceph_cap_flush *ceph_alloc_cap_flush(void)\r\n{\r\nreturn kmem_cache_alloc(ceph_cap_flush_cachep, GFP_KERNEL);\r\n}\r\nvoid ceph_free_cap_flush(struct ceph_cap_flush *cf)\r\n{\r\nif (cf)\r\nkmem_cache_free(ceph_cap_flush_cachep, cf);\r\n}\r\nstatic u64 __get_oldest_flush_tid(struct ceph_mds_client *mdsc)\r\n{\r\nif (!list_empty(&mdsc->cap_flush_list)) {\r\nstruct ceph_cap_flush *cf =\r\nlist_first_entry(&mdsc->cap_flush_list,\r\nstruct ceph_cap_flush, g_list);\r\nreturn cf->tid;\r\n}\r\nreturn 0;\r\n}\r\nstatic bool __finish_cap_flush(struct ceph_mds_client *mdsc,\r\nstruct ceph_inode_info *ci,\r\nstruct ceph_cap_flush *cf)\r\n{\r\nstruct ceph_cap_flush *prev;\r\nbool wake = cf->wake;\r\nif (mdsc) {\r\nif (wake && cf->g_list.prev != &mdsc->cap_flush_list) {\r\nprev = list_prev_entry(cf, g_list);\r\nprev->wake = true;\r\nwake = false;\r\n}\r\nlist_del(&cf->g_list);\r\n} else if (ci) {\r\nif (wake && cf->i_list.prev != &ci->i_cap_flush_list) {\r\nprev = list_prev_entry(cf, i_list);\r\nprev->wake = true;\r\nwake = false;\r\n}\r\nlist_del(&cf->i_list);\r\n} else {\r\nBUG_ON(1);\r\n}\r\nreturn wake;\r\n}\r\nstatic int __mark_caps_flushing(struct inode *inode,\r\nstruct ceph_mds_session *session, bool wake,\r\nu64 *flush_tid, u64 *oldest_flush_tid)\r\n{\r\nstruct ceph_mds_client *mdsc = ceph_sb_to_client(inode->i_sb)->mdsc;\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_cap_flush *cf = NULL;\r\nint flushing;\r\nBUG_ON(ci->i_dirty_caps == 0);\r\nBUG_ON(list_empty(&ci->i_dirty_item));\r\nBUG_ON(!ci->i_prealloc_cap_flush);\r\nflushing = ci->i_dirty_caps;\r\ndout("__mark_caps_flushing flushing %s, flushing_caps %s -> %s\n",\r\nceph_cap_string(flushing),\r\nceph_cap_string(ci->i_flushing_caps),\r\nceph_cap_string(ci->i_flushing_caps | flushing));\r\nci->i_flushing_caps |= flushing;\r\nci->i_dirty_caps = 0;\r\ndout(" inode %p now !dirty\n", inode);\r\nswap(cf, ci->i_prealloc_cap_flush);\r\ncf->caps = flushing;\r\ncf->wake = wake;\r\nspin_lock(&mdsc->cap_dirty_lock);\r\nlist_del_init(&ci->i_dirty_item);\r\ncf->tid = ++mdsc->last_cap_flush_tid;\r\nlist_add_tail(&cf->g_list, &mdsc->cap_flush_list);\r\n*oldest_flush_tid = __get_oldest_flush_tid(mdsc);\r\nif (list_empty(&ci->i_flushing_item)) {\r\nlist_add_tail(&ci->i_flushing_item, &session->s_cap_flushing);\r\nmdsc->num_cap_flushing++;\r\n}\r\nspin_unlock(&mdsc->cap_dirty_lock);\r\nlist_add_tail(&cf->i_list, &ci->i_cap_flush_list);\r\n*flush_tid = cf->tid;\r\nreturn flushing;\r\n}\r\nstatic int try_nonblocking_invalidate(struct inode *inode)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nu32 invalidating_gen = ci->i_rdcache_gen;\r\nspin_unlock(&ci->i_ceph_lock);\r\ninvalidate_mapping_pages(&inode->i_data, 0, -1);\r\nspin_lock(&ci->i_ceph_lock);\r\nif (inode->i_data.nrpages == 0 &&\r\ninvalidating_gen == ci->i_rdcache_gen) {\r\ndout("try_nonblocking_invalidate %p success\n", inode);\r\nci->i_rdcache_revoking = ci->i_rdcache_gen - 1;\r\nreturn 0;\r\n}\r\ndout("try_nonblocking_invalidate %p failed\n", inode);\r\nreturn -1;\r\n}\r\nvoid ceph_check_caps(struct ceph_inode_info *ci, int flags,\r\nstruct ceph_mds_session *session)\r\n{\r\nstruct ceph_fs_client *fsc = ceph_inode_to_client(&ci->vfs_inode);\r\nstruct ceph_mds_client *mdsc = fsc->mdsc;\r\nstruct inode *inode = &ci->vfs_inode;\r\nstruct ceph_cap *cap;\r\nu64 flush_tid, oldest_flush_tid;\r\nint file_wanted, used, cap_used;\r\nint took_snap_rwsem = 0;\r\nint issued, implemented, want, retain, revoking, flushing = 0;\r\nint mds = -1;\r\nstruct rb_node *p;\r\nint delayed = 0, sent = 0, num;\r\nbool is_delayed = flags & CHECK_CAPS_NODELAY;\r\nbool queue_invalidate = false;\r\nbool force_requeue = false;\r\nbool tried_invalidate = false;\r\nif (mdsc->stopping)\r\nis_delayed = 1;\r\nspin_lock(&ci->i_ceph_lock);\r\nif (ci->i_ceph_flags & CEPH_I_FLUSH)\r\nflags |= CHECK_CAPS_FLUSH;\r\ngoto retry_locked;\r\nretry:\r\nspin_lock(&ci->i_ceph_lock);\r\nretry_locked:\r\nfile_wanted = __ceph_caps_file_wanted(ci);\r\nused = __ceph_caps_used(ci);\r\nissued = __ceph_caps_issued(ci, &implemented);\r\nrevoking = implemented & ~issued;\r\nwant = file_wanted;\r\nretain = file_wanted | used | CEPH_CAP_PIN;\r\nif (!mdsc->stopping && inode->i_nlink > 0) {\r\nif (file_wanted) {\r\nretain |= CEPH_CAP_ANY;\r\n} else if (S_ISDIR(inode->i_mode) &&\r\n(issued & CEPH_CAP_FILE_SHARED) &&\r\n__ceph_dir_is_complete(ci)) {\r\nwant = CEPH_CAP_ANY_SHARED | CEPH_CAP_FILE_EXCL;\r\nretain |= want;\r\n} else {\r\nretain |= CEPH_CAP_ANY_SHARED;\r\nif (ci->i_max_size == 0)\r\nretain |= CEPH_CAP_ANY_RD;\r\n}\r\n}\r\ndout("check_caps %p file_want %s used %s dirty %s flushing %s"\r\n" issued %s revoking %s retain %s %s%s%s\n", inode,\r\nceph_cap_string(file_wanted),\r\nceph_cap_string(used), ceph_cap_string(ci->i_dirty_caps),\r\nceph_cap_string(ci->i_flushing_caps),\r\nceph_cap_string(issued), ceph_cap_string(revoking),\r\nceph_cap_string(retain),\r\n(flags & CHECK_CAPS_AUTHONLY) ? " AUTHONLY" : "",\r\n(flags & CHECK_CAPS_NODELAY) ? " NODELAY" : "",\r\n(flags & CHECK_CAPS_FLUSH) ? " FLUSH" : "");\r\nif ((!is_delayed || mdsc->stopping) &&\r\n!S_ISDIR(inode->i_mode) &&\r\n!(ci->i_wb_ref || ci->i_wrbuffer_ref) &&\r\ninode->i_data.nrpages &&\r\n(revoking & (CEPH_CAP_FILE_CACHE|\r\nCEPH_CAP_FILE_LAZYIO)) &&\r\n!tried_invalidate) {\r\ndout("check_caps trying to invalidate on %p\n", inode);\r\nif (try_nonblocking_invalidate(inode) < 0) {\r\nif (revoking & (CEPH_CAP_FILE_CACHE|\r\nCEPH_CAP_FILE_LAZYIO)) {\r\ndout("check_caps queuing invalidate\n");\r\nqueue_invalidate = true;\r\nci->i_rdcache_revoking = ci->i_rdcache_gen;\r\n} else {\r\ndout("check_caps failed to invalidate pages\n");\r\nforce_requeue = true;\r\n__cap_set_timeouts(mdsc, ci);\r\n}\r\n}\r\ntried_invalidate = true;\r\ngoto retry_locked;\r\n}\r\nnum = 0;\r\nfor (p = rb_first(&ci->i_caps); p; p = rb_next(p)) {\r\ncap = rb_entry(p, struct ceph_cap, ci_node);\r\nnum++;\r\nif (mds >= cap->mds ||\r\n((flags & CHECK_CAPS_AUTHONLY) && cap != ci->i_auth_cap))\r\ncontinue;\r\ncap_used = used;\r\nif (ci->i_auth_cap && cap != ci->i_auth_cap)\r\ncap_used &= ~ci->i_auth_cap->issued;\r\nrevoking = cap->implemented & ~cap->issued;\r\ndout(" mds%d cap %p used %s issued %s implemented %s revoking %s\n",\r\ncap->mds, cap, ceph_cap_string(cap_used),\r\nceph_cap_string(cap->issued),\r\nceph_cap_string(cap->implemented),\r\nceph_cap_string(revoking));\r\nif (cap == ci->i_auth_cap &&\r\n(cap->issued & CEPH_CAP_FILE_WR)) {\r\nif (ci->i_wanted_max_size > ci->i_max_size &&\r\nci->i_wanted_max_size > ci->i_requested_max_size) {\r\ndout("requesting new max_size\n");\r\ngoto ack;\r\n}\r\nif ((inode->i_size << 1) >= ci->i_max_size &&\r\n(ci->i_reported_size << 1) < ci->i_max_size) {\r\ndout("i_size approaching max_size\n");\r\ngoto ack;\r\n}\r\n}\r\nif (cap == ci->i_auth_cap) {\r\nif ((flags & CHECK_CAPS_FLUSH) && ci->i_dirty_caps) {\r\ndout("flushing dirty caps\n");\r\ngoto ack;\r\n}\r\nif (ci->i_ceph_flags & CEPH_I_FLUSH_SNAPS) {\r\ndout("flushing snap caps\n");\r\ngoto ack;\r\n}\r\n}\r\nif (revoking && (revoking & cap_used) == 0) {\r\ndout("completed revocation of %s\n",\r\nceph_cap_string(cap->implemented & ~cap->issued));\r\ngoto ack;\r\n}\r\nif (want & ~(cap->mds_wanted | cap->issued))\r\ngoto ack;\r\nif ((cap->issued & ~retain) == 0 &&\r\ncap->mds_wanted == want)\r\ncontinue;\r\nif (is_delayed)\r\ngoto ack;\r\nif ((ci->i_ceph_flags & CEPH_I_NODELAY) == 0 &&\r\ntime_before(jiffies, ci->i_hold_caps_max)) {\r\ndout(" delaying issued %s -> %s, wanted %s -> %s\n",\r\nceph_cap_string(cap->issued),\r\nceph_cap_string(cap->issued & retain),\r\nceph_cap_string(cap->mds_wanted),\r\nceph_cap_string(want));\r\ndelayed++;\r\ncontinue;\r\n}\r\nack:\r\nif (ci->i_ceph_flags & CEPH_I_NOFLUSH) {\r\ndout(" skipping %p I_NOFLUSH set\n", inode);\r\ncontinue;\r\n}\r\nif (session && session != cap->session) {\r\ndout("oops, wrong session %p mutex\n", session);\r\nmutex_unlock(&session->s_mutex);\r\nsession = NULL;\r\n}\r\nif (!session) {\r\nsession = cap->session;\r\nif (mutex_trylock(&session->s_mutex) == 0) {\r\ndout("inverting session/ino locks on %p\n",\r\nsession);\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (took_snap_rwsem) {\r\nup_read(&mdsc->snap_rwsem);\r\ntook_snap_rwsem = 0;\r\n}\r\nmutex_lock(&session->s_mutex);\r\ngoto retry;\r\n}\r\n}\r\nif (cap == ci->i_auth_cap &&\r\n(ci->i_ceph_flags &\r\n(CEPH_I_KICK_FLUSH | CEPH_I_FLUSH_SNAPS))) {\r\nif (ci->i_ceph_flags & CEPH_I_KICK_FLUSH) {\r\nspin_lock(&mdsc->cap_dirty_lock);\r\noldest_flush_tid = __get_oldest_flush_tid(mdsc);\r\nspin_unlock(&mdsc->cap_dirty_lock);\r\n__kick_flushing_caps(mdsc, session, ci,\r\noldest_flush_tid);\r\nci->i_ceph_flags &= ~CEPH_I_KICK_FLUSH;\r\n}\r\nif (ci->i_ceph_flags & CEPH_I_FLUSH_SNAPS)\r\n__ceph_flush_snaps(ci, session);\r\ngoto retry_locked;\r\n}\r\nif (!took_snap_rwsem) {\r\nif (down_read_trylock(&mdsc->snap_rwsem) == 0) {\r\ndout("inverting snap/in locks on %p\n",\r\ninode);\r\nspin_unlock(&ci->i_ceph_lock);\r\ndown_read(&mdsc->snap_rwsem);\r\ntook_snap_rwsem = 1;\r\ngoto retry;\r\n}\r\ntook_snap_rwsem = 1;\r\n}\r\nif (cap == ci->i_auth_cap && ci->i_dirty_caps) {\r\nflushing = __mark_caps_flushing(inode, session, false,\r\n&flush_tid,\r\n&oldest_flush_tid);\r\n} else {\r\nflushing = 0;\r\nflush_tid = 0;\r\nspin_lock(&mdsc->cap_dirty_lock);\r\noldest_flush_tid = __get_oldest_flush_tid(mdsc);\r\nspin_unlock(&mdsc->cap_dirty_lock);\r\n}\r\nmds = cap->mds;\r\nsent++;\r\ndelayed += __send_cap(mdsc, cap, CEPH_CAP_OP_UPDATE, cap_used,\r\nwant, retain, flushing,\r\nflush_tid, oldest_flush_tid);\r\ngoto retry;\r\n}\r\nif (delayed && is_delayed)\r\nforce_requeue = true;\r\nif (!delayed && !is_delayed)\r\n__cap_delay_cancel(mdsc, ci);\r\nelse if (!is_delayed || force_requeue)\r\n__cap_delay_requeue(mdsc, ci);\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (queue_invalidate)\r\nceph_queue_invalidate(inode);\r\nif (session)\r\nmutex_unlock(&session->s_mutex);\r\nif (took_snap_rwsem)\r\nup_read(&mdsc->snap_rwsem);\r\n}\r\nstatic int try_flush_caps(struct inode *inode, u64 *ptid)\r\n{\r\nstruct ceph_mds_client *mdsc = ceph_sb_to_client(inode->i_sb)->mdsc;\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_mds_session *session = NULL;\r\nint flushing = 0;\r\nu64 flush_tid = 0, oldest_flush_tid = 0;\r\nretry:\r\nspin_lock(&ci->i_ceph_lock);\r\nif (ci->i_ceph_flags & CEPH_I_NOFLUSH) {\r\ndout("try_flush_caps skipping %p I_NOFLUSH set\n", inode);\r\ngoto out;\r\n}\r\nif (ci->i_dirty_caps && ci->i_auth_cap) {\r\nstruct ceph_cap *cap = ci->i_auth_cap;\r\nint used = __ceph_caps_used(ci);\r\nint want = __ceph_caps_wanted(ci);\r\nint delayed;\r\nif (!session || session != cap->session) {\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (session)\r\nmutex_unlock(&session->s_mutex);\r\nsession = cap->session;\r\nmutex_lock(&session->s_mutex);\r\ngoto retry;\r\n}\r\nif (cap->session->s_state < CEPH_MDS_SESSION_OPEN)\r\ngoto out;\r\nflushing = __mark_caps_flushing(inode, session, true,\r\n&flush_tid, &oldest_flush_tid);\r\ndelayed = __send_cap(mdsc, cap, CEPH_CAP_OP_FLUSH, used, want,\r\n(cap->issued | cap->implemented),\r\nflushing, flush_tid, oldest_flush_tid);\r\nif (delayed) {\r\nspin_lock(&ci->i_ceph_lock);\r\n__cap_delay_requeue(mdsc, ci);\r\nspin_unlock(&ci->i_ceph_lock);\r\n}\r\n} else {\r\nif (!list_empty(&ci->i_cap_flush_list)) {\r\nstruct ceph_cap_flush *cf =\r\nlist_last_entry(&ci->i_cap_flush_list,\r\nstruct ceph_cap_flush, i_list);\r\ncf->wake = true;\r\nflush_tid = cf->tid;\r\n}\r\nflushing = ci->i_flushing_caps;\r\nspin_unlock(&ci->i_ceph_lock);\r\n}\r\nout:\r\nif (session)\r\nmutex_unlock(&session->s_mutex);\r\n*ptid = flush_tid;\r\nreturn flushing;\r\n}\r\nstatic int caps_are_flushed(struct inode *inode, u64 flush_tid)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nint ret = 1;\r\nspin_lock(&ci->i_ceph_lock);\r\nif (!list_empty(&ci->i_cap_flush_list)) {\r\nstruct ceph_cap_flush * cf =\r\nlist_first_entry(&ci->i_cap_flush_list,\r\nstruct ceph_cap_flush, i_list);\r\nif (cf->tid <= flush_tid)\r\nret = 0;\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\nreturn ret;\r\n}\r\nstatic int unsafe_request_wait(struct inode *inode)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_mds_request *req1 = NULL, *req2 = NULL;\r\nint ret, err = 0;\r\nspin_lock(&ci->i_unsafe_lock);\r\nif (S_ISDIR(inode->i_mode) && !list_empty(&ci->i_unsafe_dirops)) {\r\nreq1 = list_last_entry(&ci->i_unsafe_dirops,\r\nstruct ceph_mds_request,\r\nr_unsafe_dir_item);\r\nceph_mdsc_get_request(req1);\r\n}\r\nif (!list_empty(&ci->i_unsafe_iops)) {\r\nreq2 = list_last_entry(&ci->i_unsafe_iops,\r\nstruct ceph_mds_request,\r\nr_unsafe_target_item);\r\nceph_mdsc_get_request(req2);\r\n}\r\nspin_unlock(&ci->i_unsafe_lock);\r\ndout("unsafe_requeset_wait %p wait on tid %llu %llu\n",\r\ninode, req1 ? req1->r_tid : 0ULL, req2 ? req2->r_tid : 0ULL);\r\nif (req1) {\r\nret = !wait_for_completion_timeout(&req1->r_safe_completion,\r\nceph_timeout_jiffies(req1->r_timeout));\r\nif (ret)\r\nerr = -EIO;\r\nceph_mdsc_put_request(req1);\r\n}\r\nif (req2) {\r\nret = !wait_for_completion_timeout(&req2->r_safe_completion,\r\nceph_timeout_jiffies(req2->r_timeout));\r\nif (ret)\r\nerr = -EIO;\r\nceph_mdsc_put_request(req2);\r\n}\r\nreturn err;\r\n}\r\nint ceph_fsync(struct file *file, loff_t start, loff_t end, int datasync)\r\n{\r\nstruct inode *inode = file->f_mapping->host;\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nu64 flush_tid;\r\nint ret;\r\nint dirty;\r\ndout("fsync %p%s\n", inode, datasync ? " datasync" : "");\r\nceph_sync_write_wait(inode);\r\nret = filemap_write_and_wait_range(inode->i_mapping, start, end);\r\nif (ret < 0)\r\ngoto out;\r\nif (datasync)\r\ngoto out;\r\ninode_lock(inode);\r\ndirty = try_flush_caps(inode, &flush_tid);\r\ndout("fsync dirty caps are %s\n", ceph_cap_string(dirty));\r\nret = unsafe_request_wait(inode);\r\nif (!ret && (dirty & ~CEPH_CAP_ANY_FILE_WR)) {\r\nret = wait_event_interruptible(ci->i_cap_wq,\r\ncaps_are_flushed(inode, flush_tid));\r\n}\r\ninode_unlock(inode);\r\nout:\r\ndout("fsync %p%s result=%d\n", inode, datasync ? " datasync" : "", ret);\r\nreturn ret;\r\n}\r\nint ceph_write_inode(struct inode *inode, struct writeback_control *wbc)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nu64 flush_tid;\r\nint err = 0;\r\nint dirty;\r\nint wait = wbc->sync_mode == WB_SYNC_ALL;\r\ndout("write_inode %p wait=%d\n", inode, wait);\r\nif (wait) {\r\ndirty = try_flush_caps(inode, &flush_tid);\r\nif (dirty)\r\nerr = wait_event_interruptible(ci->i_cap_wq,\r\ncaps_are_flushed(inode, flush_tid));\r\n} else {\r\nstruct ceph_mds_client *mdsc =\r\nceph_sb_to_client(inode->i_sb)->mdsc;\r\nspin_lock(&ci->i_ceph_lock);\r\nif (__ceph_caps_dirty(ci))\r\n__cap_delay_requeue_front(mdsc, ci);\r\nspin_unlock(&ci->i_ceph_lock);\r\n}\r\nreturn err;\r\n}\r\nstatic void __kick_flushing_caps(struct ceph_mds_client *mdsc,\r\nstruct ceph_mds_session *session,\r\nstruct ceph_inode_info *ci,\r\nu64 oldest_flush_tid)\r\n__releases(ci->i_ceph_lock)\r\n__acquires(ci->i_ceph_lock)\r\n{\r\nstruct inode *inode = &ci->vfs_inode;\r\nstruct ceph_cap *cap;\r\nstruct ceph_cap_flush *cf;\r\nint ret;\r\nu64 first_tid = 0;\r\nlist_for_each_entry(cf, &ci->i_cap_flush_list, i_list) {\r\nif (cf->tid < first_tid)\r\ncontinue;\r\ncap = ci->i_auth_cap;\r\nif (!(cap && cap->session == session)) {\r\npr_err("%p auth cap %p not mds%d ???\n",\r\ninode, cap, session->s_mds);\r\nbreak;\r\n}\r\nfirst_tid = cf->tid + 1;\r\nif (cf->caps) {\r\ndout("kick_flushing_caps %p cap %p tid %llu %s\n",\r\ninode, cap, cf->tid, ceph_cap_string(cf->caps));\r\nci->i_ceph_flags |= CEPH_I_NODELAY;\r\nret = __send_cap(mdsc, cap, CEPH_CAP_OP_FLUSH,\r\n__ceph_caps_used(ci),\r\n__ceph_caps_wanted(ci),\r\ncap->issued | cap->implemented,\r\ncf->caps, cf->tid, oldest_flush_tid);\r\nif (ret) {\r\npr_err("kick_flushing_caps: error sending "\r\n"cap flush, ino (%llx.%llx) "\r\n"tid %llu flushing %s\n",\r\nceph_vinop(inode), cf->tid,\r\nceph_cap_string(cf->caps));\r\n}\r\n} else {\r\nstruct ceph_cap_snap *capsnap =\r\ncontainer_of(cf, struct ceph_cap_snap,\r\ncap_flush);\r\ndout("kick_flushing_caps %p capsnap %p tid %llu %s\n",\r\ninode, capsnap, cf->tid,\r\nceph_cap_string(capsnap->dirty));\r\natomic_inc(&capsnap->nref);\r\nspin_unlock(&ci->i_ceph_lock);\r\nret = __send_flush_snap(inode, session, capsnap, cap->mseq,\r\noldest_flush_tid);\r\nif (ret < 0) {\r\npr_err("kick_flushing_caps: error sending "\r\n"cap flushsnap, ino (%llx.%llx) "\r\n"tid %llu follows %llu\n",\r\nceph_vinop(inode), cf->tid,\r\ncapsnap->follows);\r\n}\r\nceph_put_cap_snap(capsnap);\r\n}\r\nspin_lock(&ci->i_ceph_lock);\r\n}\r\n}\r\nvoid ceph_early_kick_flushing_caps(struct ceph_mds_client *mdsc,\r\nstruct ceph_mds_session *session)\r\n{\r\nstruct ceph_inode_info *ci;\r\nstruct ceph_cap *cap;\r\nu64 oldest_flush_tid;\r\ndout("early_kick_flushing_caps mds%d\n", session->s_mds);\r\nspin_lock(&mdsc->cap_dirty_lock);\r\noldest_flush_tid = __get_oldest_flush_tid(mdsc);\r\nspin_unlock(&mdsc->cap_dirty_lock);\r\nlist_for_each_entry(ci, &session->s_cap_flushing, i_flushing_item) {\r\nspin_lock(&ci->i_ceph_lock);\r\ncap = ci->i_auth_cap;\r\nif (!(cap && cap->session == session)) {\r\npr_err("%p auth cap %p not mds%d ???\n",\r\n&ci->vfs_inode, cap, session->s_mds);\r\nspin_unlock(&ci->i_ceph_lock);\r\ncontinue;\r\n}\r\nif ((cap->issued & ci->i_flushing_caps) !=\r\nci->i_flushing_caps) {\r\nci->i_ceph_flags &= ~CEPH_I_KICK_FLUSH;\r\n__kick_flushing_caps(mdsc, session, ci,\r\noldest_flush_tid);\r\n} else {\r\nci->i_ceph_flags |= CEPH_I_KICK_FLUSH;\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\n}\r\n}\r\nvoid ceph_kick_flushing_caps(struct ceph_mds_client *mdsc,\r\nstruct ceph_mds_session *session)\r\n{\r\nstruct ceph_inode_info *ci;\r\nstruct ceph_cap *cap;\r\nu64 oldest_flush_tid;\r\ndout("kick_flushing_caps mds%d\n", session->s_mds);\r\nspin_lock(&mdsc->cap_dirty_lock);\r\noldest_flush_tid = __get_oldest_flush_tid(mdsc);\r\nspin_unlock(&mdsc->cap_dirty_lock);\r\nlist_for_each_entry(ci, &session->s_cap_flushing, i_flushing_item) {\r\nspin_lock(&ci->i_ceph_lock);\r\ncap = ci->i_auth_cap;\r\nif (!(cap && cap->session == session)) {\r\npr_err("%p auth cap %p not mds%d ???\n",\r\n&ci->vfs_inode, cap, session->s_mds);\r\nspin_unlock(&ci->i_ceph_lock);\r\ncontinue;\r\n}\r\nif (ci->i_ceph_flags & CEPH_I_KICK_FLUSH) {\r\nci->i_ceph_flags &= ~CEPH_I_KICK_FLUSH;\r\n__kick_flushing_caps(mdsc, session, ci,\r\noldest_flush_tid);\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\n}\r\n}\r\nstatic void kick_flushing_inode_caps(struct ceph_mds_client *mdsc,\r\nstruct ceph_mds_session *session,\r\nstruct inode *inode)\r\n__releases(ci->i_ceph_lock)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_cap *cap;\r\ncap = ci->i_auth_cap;\r\ndout("kick_flushing_inode_caps %p flushing %s\n", inode,\r\nceph_cap_string(ci->i_flushing_caps));\r\nif (!list_empty(&ci->i_cap_flush_list)) {\r\nu64 oldest_flush_tid;\r\nspin_lock(&mdsc->cap_dirty_lock);\r\nlist_move_tail(&ci->i_flushing_item,\r\n&cap->session->s_cap_flushing);\r\noldest_flush_tid = __get_oldest_flush_tid(mdsc);\r\nspin_unlock(&mdsc->cap_dirty_lock);\r\nci->i_ceph_flags &= ~CEPH_I_KICK_FLUSH;\r\n__kick_flushing_caps(mdsc, session, ci, oldest_flush_tid);\r\nspin_unlock(&ci->i_ceph_lock);\r\n} else {\r\nspin_unlock(&ci->i_ceph_lock);\r\n}\r\n}\r\nstatic void __take_cap_refs(struct ceph_inode_info *ci, int got,\r\nbool snap_rwsem_locked)\r\n{\r\nif (got & CEPH_CAP_PIN)\r\nci->i_pin_ref++;\r\nif (got & CEPH_CAP_FILE_RD)\r\nci->i_rd_ref++;\r\nif (got & CEPH_CAP_FILE_CACHE)\r\nci->i_rdcache_ref++;\r\nif (got & CEPH_CAP_FILE_WR) {\r\nif (ci->i_wr_ref == 0 && !ci->i_head_snapc) {\r\nBUG_ON(!snap_rwsem_locked);\r\nci->i_head_snapc = ceph_get_snap_context(\r\nci->i_snap_realm->cached_context);\r\n}\r\nci->i_wr_ref++;\r\n}\r\nif (got & CEPH_CAP_FILE_BUFFER) {\r\nif (ci->i_wb_ref == 0)\r\nihold(&ci->vfs_inode);\r\nci->i_wb_ref++;\r\ndout("__take_cap_refs %p wb %d -> %d (?)\n",\r\n&ci->vfs_inode, ci->i_wb_ref-1, ci->i_wb_ref);\r\n}\r\n}\r\nstatic int try_get_cap_refs(struct ceph_inode_info *ci, int need, int want,\r\nloff_t endoff, bool nonblock, int *got, int *err)\r\n{\r\nstruct inode *inode = &ci->vfs_inode;\r\nstruct ceph_mds_client *mdsc = ceph_inode_to_client(inode)->mdsc;\r\nint ret = 0;\r\nint have, implemented;\r\nint file_wanted;\r\nbool snap_rwsem_locked = false;\r\ndout("get_cap_refs %p need %s want %s\n", inode,\r\nceph_cap_string(need), ceph_cap_string(want));\r\nagain:\r\nspin_lock(&ci->i_ceph_lock);\r\nfile_wanted = __ceph_caps_file_wanted(ci);\r\nif ((file_wanted & need) != need) {\r\ndout("try_get_cap_refs need %s file_wanted %s, EBADF\n",\r\nceph_cap_string(need), ceph_cap_string(file_wanted));\r\n*err = -EBADF;\r\nret = 1;\r\ngoto out_unlock;\r\n}\r\nwhile (ci->i_truncate_pending) {\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (snap_rwsem_locked) {\r\nup_read(&mdsc->snap_rwsem);\r\nsnap_rwsem_locked = false;\r\n}\r\n__ceph_do_pending_vmtruncate(inode);\r\nspin_lock(&ci->i_ceph_lock);\r\n}\r\nhave = __ceph_caps_issued(ci, &implemented);\r\nif (have & need & CEPH_CAP_FILE_WR) {\r\nif (endoff >= 0 && endoff > (loff_t)ci->i_max_size) {\r\ndout("get_cap_refs %p endoff %llu > maxsize %llu\n",\r\ninode, endoff, ci->i_max_size);\r\nif (endoff > ci->i_requested_max_size) {\r\n*err = -EAGAIN;\r\nret = 1;\r\n}\r\ngoto out_unlock;\r\n}\r\nif (__ceph_have_pending_cap_snap(ci)) {\r\ndout("get_cap_refs %p cap_snap_pending\n", inode);\r\ngoto out_unlock;\r\n}\r\n}\r\nif ((have & need) == need) {\r\nint not = want & ~(have & need);\r\nint revoking = implemented & ~have;\r\ndout("get_cap_refs %p have %s but not %s (revoking %s)\n",\r\ninode, ceph_cap_string(have), ceph_cap_string(not),\r\nceph_cap_string(revoking));\r\nif ((revoking & not) == 0) {\r\nif (!snap_rwsem_locked &&\r\n!ci->i_head_snapc &&\r\n(need & CEPH_CAP_FILE_WR)) {\r\nif (!down_read_trylock(&mdsc->snap_rwsem)) {\r\nif (nonblock) {\r\n*err = -EAGAIN;\r\nret = 1;\r\ngoto out_unlock;\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\ndown_read(&mdsc->snap_rwsem);\r\nsnap_rwsem_locked = true;\r\ngoto again;\r\n}\r\nsnap_rwsem_locked = true;\r\n}\r\n*got = need | (have & want);\r\nif ((need & CEPH_CAP_FILE_RD) &&\r\n!(*got & CEPH_CAP_FILE_CACHE))\r\nceph_disable_fscache_readpage(ci);\r\n__take_cap_refs(ci, *got, true);\r\nret = 1;\r\n}\r\n} else {\r\nint session_readonly = false;\r\nif ((need & CEPH_CAP_FILE_WR) && ci->i_auth_cap) {\r\nstruct ceph_mds_session *s = ci->i_auth_cap->session;\r\nspin_lock(&s->s_cap_lock);\r\nsession_readonly = s->s_readonly;\r\nspin_unlock(&s->s_cap_lock);\r\n}\r\nif (session_readonly) {\r\ndout("get_cap_refs %p needed %s but mds%d readonly\n",\r\ninode, ceph_cap_string(need), ci->i_auth_cap->mds);\r\n*err = -EROFS;\r\nret = 1;\r\ngoto out_unlock;\r\n}\r\nif (ci->i_ceph_flags & CEPH_I_CAP_DROPPED) {\r\nint mds_wanted;\r\nif (ACCESS_ONCE(mdsc->fsc->mount_state) ==\r\nCEPH_MOUNT_SHUTDOWN) {\r\ndout("get_cap_refs %p forced umount\n", inode);\r\n*err = -EIO;\r\nret = 1;\r\ngoto out_unlock;\r\n}\r\nmds_wanted = __ceph_caps_mds_wanted(ci);\r\nif ((mds_wanted & need) != need) {\r\ndout("get_cap_refs %p caps were dropped"\r\n" (session killed?)\n", inode);\r\n*err = -ESTALE;\r\nret = 1;\r\ngoto out_unlock;\r\n}\r\nif ((mds_wanted & file_wanted) ==\r\n(file_wanted & (CEPH_CAP_FILE_RD|CEPH_CAP_FILE_WR)))\r\nci->i_ceph_flags &= ~CEPH_I_CAP_DROPPED;\r\n}\r\ndout("get_cap_refs %p have %s needed %s\n", inode,\r\nceph_cap_string(have), ceph_cap_string(need));\r\n}\r\nout_unlock:\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (snap_rwsem_locked)\r\nup_read(&mdsc->snap_rwsem);\r\ndout("get_cap_refs %p ret %d got %s\n", inode,\r\nret, ceph_cap_string(*got));\r\nreturn ret;\r\n}\r\nstatic void check_max_size(struct inode *inode, loff_t endoff)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nint check = 0;\r\nspin_lock(&ci->i_ceph_lock);\r\nif (endoff >= ci->i_max_size && endoff > ci->i_wanted_max_size) {\r\ndout("write %p at large endoff %llu, req max_size\n",\r\ninode, endoff);\r\nci->i_wanted_max_size = endoff;\r\n}\r\nif (ci->i_auth_cap &&\r\n(ci->i_auth_cap->issued & CEPH_CAP_FILE_WR) &&\r\nci->i_wanted_max_size > ci->i_max_size &&\r\nci->i_wanted_max_size > ci->i_requested_max_size)\r\ncheck = 1;\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (check)\r\nceph_check_caps(ci, CHECK_CAPS_AUTHONLY, NULL);\r\n}\r\nint ceph_get_caps(struct ceph_inode_info *ci, int need, int want,\r\nloff_t endoff, int *got, struct page **pinned_page)\r\n{\r\nint _got, ret, err = 0;\r\nret = ceph_pool_perm_check(ci, need);\r\nif (ret < 0)\r\nreturn ret;\r\nwhile (true) {\r\nif (endoff > 0)\r\ncheck_max_size(&ci->vfs_inode, endoff);\r\nerr = 0;\r\n_got = 0;\r\nret = try_get_cap_refs(ci, need, want, endoff,\r\nfalse, &_got, &err);\r\nif (ret) {\r\nif (err == -EAGAIN)\r\ncontinue;\r\nif (err < 0)\r\nret = err;\r\n} else {\r\nret = wait_event_interruptible(ci->i_cap_wq,\r\ntry_get_cap_refs(ci, need, want, endoff,\r\ntrue, &_got, &err));\r\nif (err == -EAGAIN)\r\ncontinue;\r\nif (err < 0)\r\nret = err;\r\n}\r\nif (ret < 0) {\r\nif (err == -ESTALE) {\r\nret = ceph_renew_caps(&ci->vfs_inode);\r\nif (ret == 0)\r\ncontinue;\r\n}\r\nreturn ret;\r\n}\r\nif (ci->i_inline_version != CEPH_INLINE_NONE &&\r\n(_got & (CEPH_CAP_FILE_CACHE|CEPH_CAP_FILE_LAZYIO)) &&\r\ni_size_read(&ci->vfs_inode) > 0) {\r\nstruct page *page =\r\nfind_get_page(ci->vfs_inode.i_mapping, 0);\r\nif (page) {\r\nif (PageUptodate(page)) {\r\n*pinned_page = page;\r\nbreak;\r\n}\r\nput_page(page);\r\n}\r\nceph_put_cap_refs(ci, _got);\r\n_got = 0;\r\nret = __ceph_do_getattr(&ci->vfs_inode, NULL,\r\nCEPH_STAT_CAP_INLINE_DATA,\r\ntrue);\r\nif (ret < 0)\r\nreturn ret;\r\ncontinue;\r\n}\r\nbreak;\r\n}\r\nif ((_got & CEPH_CAP_FILE_RD) && (_got & CEPH_CAP_FILE_CACHE))\r\nceph_fscache_revalidate_cookie(ci);\r\n*got = _got;\r\nreturn 0;\r\n}\r\nvoid ceph_get_cap_refs(struct ceph_inode_info *ci, int caps)\r\n{\r\nspin_lock(&ci->i_ceph_lock);\r\n__take_cap_refs(ci, caps, false);\r\nspin_unlock(&ci->i_ceph_lock);\r\n}\r\nstatic int ceph_try_drop_cap_snap(struct ceph_inode_info *ci,\r\nstruct ceph_cap_snap *capsnap)\r\n{\r\nif (!capsnap->need_flush &&\r\n!capsnap->writing && !capsnap->dirty_pages) {\r\ndout("dropping cap_snap %p follows %llu\n",\r\ncapsnap, capsnap->follows);\r\nBUG_ON(capsnap->cap_flush.tid > 0);\r\nceph_put_snap_context(capsnap->context);\r\nif (!list_is_last(&capsnap->ci_item, &ci->i_cap_snaps))\r\nci->i_ceph_flags |= CEPH_I_FLUSH_SNAPS;\r\nlist_del(&capsnap->ci_item);\r\nceph_put_cap_snap(capsnap);\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nvoid ceph_put_cap_refs(struct ceph_inode_info *ci, int had)\r\n{\r\nstruct inode *inode = &ci->vfs_inode;\r\nint last = 0, put = 0, flushsnaps = 0, wake = 0;\r\nspin_lock(&ci->i_ceph_lock);\r\nif (had & CEPH_CAP_PIN)\r\n--ci->i_pin_ref;\r\nif (had & CEPH_CAP_FILE_RD)\r\nif (--ci->i_rd_ref == 0)\r\nlast++;\r\nif (had & CEPH_CAP_FILE_CACHE)\r\nif (--ci->i_rdcache_ref == 0)\r\nlast++;\r\nif (had & CEPH_CAP_FILE_BUFFER) {\r\nif (--ci->i_wb_ref == 0) {\r\nlast++;\r\nput++;\r\n}\r\ndout("put_cap_refs %p wb %d -> %d (?)\n",\r\ninode, ci->i_wb_ref+1, ci->i_wb_ref);\r\n}\r\nif (had & CEPH_CAP_FILE_WR)\r\nif (--ci->i_wr_ref == 0) {\r\nlast++;\r\nif (__ceph_have_pending_cap_snap(ci)) {\r\nstruct ceph_cap_snap *capsnap =\r\nlist_last_entry(&ci->i_cap_snaps,\r\nstruct ceph_cap_snap,\r\nci_item);\r\ncapsnap->writing = 0;\r\nif (ceph_try_drop_cap_snap(ci, capsnap))\r\nput++;\r\nelse if (__ceph_finish_cap_snap(ci, capsnap))\r\nflushsnaps = 1;\r\nwake = 1;\r\n}\r\nif (ci->i_wrbuffer_ref_head == 0 &&\r\nci->i_dirty_caps == 0 &&\r\nci->i_flushing_caps == 0) {\r\nBUG_ON(!ci->i_head_snapc);\r\nceph_put_snap_context(ci->i_head_snapc);\r\nci->i_head_snapc = NULL;\r\n}\r\nif (!__ceph_is_any_caps(ci) && ci->i_snap_realm)\r\ndrop_inode_snap_realm(ci);\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\ndout("put_cap_refs %p had %s%s%s\n", inode, ceph_cap_string(had),\r\nlast ? " last" : "", put ? " put" : "");\r\nif (last && !flushsnaps)\r\nceph_check_caps(ci, 0, NULL);\r\nelse if (flushsnaps)\r\nceph_flush_snaps(ci, NULL);\r\nif (wake)\r\nwake_up_all(&ci->i_cap_wq);\r\nwhile (put-- > 0)\r\niput(inode);\r\n}\r\nvoid ceph_put_wrbuffer_cap_refs(struct ceph_inode_info *ci, int nr,\r\nstruct ceph_snap_context *snapc)\r\n{\r\nstruct inode *inode = &ci->vfs_inode;\r\nstruct ceph_cap_snap *capsnap = NULL;\r\nint put = 0;\r\nbool last = false;\r\nbool found = false;\r\nbool flush_snaps = false;\r\nbool complete_capsnap = false;\r\nspin_lock(&ci->i_ceph_lock);\r\nci->i_wrbuffer_ref -= nr;\r\nif (ci->i_wrbuffer_ref == 0) {\r\nlast = true;\r\nput++;\r\n}\r\nif (ci->i_head_snapc == snapc) {\r\nci->i_wrbuffer_ref_head -= nr;\r\nif (ci->i_wrbuffer_ref_head == 0 &&\r\nci->i_wr_ref == 0 &&\r\nci->i_dirty_caps == 0 &&\r\nci->i_flushing_caps == 0) {\r\nBUG_ON(!ci->i_head_snapc);\r\nceph_put_snap_context(ci->i_head_snapc);\r\nci->i_head_snapc = NULL;\r\n}\r\ndout("put_wrbuffer_cap_refs on %p head %d/%d -> %d/%d %s\n",\r\ninode,\r\nci->i_wrbuffer_ref+nr, ci->i_wrbuffer_ref_head+nr,\r\nci->i_wrbuffer_ref, ci->i_wrbuffer_ref_head,\r\nlast ? " LAST" : "");\r\n} else {\r\nlist_for_each_entry(capsnap, &ci->i_cap_snaps, ci_item) {\r\nif (capsnap->context == snapc) {\r\nfound = true;\r\nbreak;\r\n}\r\n}\r\nBUG_ON(!found);\r\ncapsnap->dirty_pages -= nr;\r\nif (capsnap->dirty_pages == 0) {\r\ncomplete_capsnap = true;\r\nif (!capsnap->writing) {\r\nif (ceph_try_drop_cap_snap(ci, capsnap)) {\r\nput++;\r\n} else {\r\nci->i_ceph_flags |= CEPH_I_FLUSH_SNAPS;\r\nflush_snaps = true;\r\n}\r\n}\r\n}\r\ndout("put_wrbuffer_cap_refs on %p cap_snap %p "\r\n" snap %lld %d/%d -> %d/%d %s%s\n",\r\ninode, capsnap, capsnap->context->seq,\r\nci->i_wrbuffer_ref+nr, capsnap->dirty_pages + nr,\r\nci->i_wrbuffer_ref, capsnap->dirty_pages,\r\nlast ? " (wrbuffer last)" : "",\r\ncomplete_capsnap ? " (complete capsnap)" : "");\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (last) {\r\nceph_check_caps(ci, CHECK_CAPS_AUTHONLY, NULL);\r\n} else if (flush_snaps) {\r\nceph_flush_snaps(ci, NULL);\r\n}\r\nif (complete_capsnap)\r\nwake_up_all(&ci->i_cap_wq);\r\nwhile (put-- > 0)\r\niput(inode);\r\n}\r\nstatic void invalidate_aliases(struct inode *inode)\r\n{\r\nstruct dentry *dn, *prev = NULL;\r\ndout("invalidate_aliases inode %p\n", inode);\r\nd_prune_aliases(inode);\r\nwhile ((dn = d_find_alias(inode))) {\r\nif (dn == prev) {\r\ndput(dn);\r\nbreak;\r\n}\r\nd_invalidate(dn);\r\nif (prev)\r\ndput(prev);\r\nprev = dn;\r\n}\r\nif (prev)\r\ndput(prev);\r\n}\r\nstatic void handle_cap_grant(struct ceph_mds_client *mdsc,\r\nstruct inode *inode, struct ceph_mds_caps *grant,\r\nstruct ceph_string **pns, u64 inline_version,\r\nvoid *inline_data, u32 inline_len,\r\nstruct ceph_buffer *xattr_buf,\r\nstruct ceph_mds_session *session,\r\nstruct ceph_cap *cap, int issued)\r\n__releases(ci->i_ceph_lock)\r\n__releases(mdsc->snap_rwsem)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nint mds = session->s_mds;\r\nint seq = le32_to_cpu(grant->seq);\r\nint newcaps = le32_to_cpu(grant->caps);\r\nint used, wanted, dirty;\r\nu64 size = le64_to_cpu(grant->size);\r\nu64 max_size = le64_to_cpu(grant->max_size);\r\nstruct timespec mtime, atime, ctime;\r\nint check_caps = 0;\r\nbool wake = false;\r\nbool writeback = false;\r\nbool queue_trunc = false;\r\nbool queue_invalidate = false;\r\nbool deleted_inode = false;\r\nbool fill_inline = false;\r\ndout("handle_cap_grant inode %p cap %p mds%d seq %d %s\n",\r\ninode, cap, mds, seq, ceph_cap_string(newcaps));\r\ndout(" size %llu max_size %llu, i_size %llu\n", size, max_size,\r\ninode->i_size);\r\nif (ceph_seq_cmp(seq, cap->seq) <= 0) {\r\nWARN_ON(cap != ci->i_auth_cap);\r\nWARN_ON(cap->cap_id != le64_to_cpu(grant->cap_id));\r\nseq = cap->seq;\r\nnewcaps |= cap->issued;\r\n}\r\nif (!S_ISDIR(inode->i_mode) &&\r\n((cap->issued & ~newcaps) & CEPH_CAP_FILE_CACHE) &&\r\n(newcaps & CEPH_CAP_FILE_LAZYIO) == 0 &&\r\n!(ci->i_wrbuffer_ref || ci->i_wb_ref)) {\r\nif (try_nonblocking_invalidate(inode)) {\r\nif (ci->i_rdcache_revoking != ci->i_rdcache_gen) {\r\nqueue_invalidate = true;\r\nci->i_rdcache_revoking = ci->i_rdcache_gen;\r\n}\r\n}\r\n}\r\ncap->cap_gen = session->s_cap_gen;\r\ncap->seq = seq;\r\n__check_cap_issue(ci, cap, newcaps);\r\nif ((newcaps & CEPH_CAP_AUTH_SHARED) &&\r\n(issued & CEPH_CAP_AUTH_EXCL) == 0) {\r\ninode->i_mode = le32_to_cpu(grant->mode);\r\ninode->i_uid = make_kuid(&init_user_ns, le32_to_cpu(grant->uid));\r\ninode->i_gid = make_kgid(&init_user_ns, le32_to_cpu(grant->gid));\r\ndout("%p mode 0%o uid.gid %d.%d\n", inode, inode->i_mode,\r\nfrom_kuid(&init_user_ns, inode->i_uid),\r\nfrom_kgid(&init_user_ns, inode->i_gid));\r\n}\r\nif ((newcaps & CEPH_CAP_AUTH_SHARED) &&\r\n(issued & CEPH_CAP_LINK_EXCL) == 0) {\r\nset_nlink(inode, le32_to_cpu(grant->nlink));\r\nif (inode->i_nlink == 0 &&\r\n(newcaps & (CEPH_CAP_LINK_SHARED | CEPH_CAP_LINK_EXCL)))\r\ndeleted_inode = true;\r\n}\r\nif ((issued & CEPH_CAP_XATTR_EXCL) == 0 && grant->xattr_len) {\r\nint len = le32_to_cpu(grant->xattr_len);\r\nu64 version = le64_to_cpu(grant->xattr_version);\r\nif (version > ci->i_xattrs.version) {\r\ndout(" got new xattrs v%llu on %p len %d\n",\r\nversion, inode, len);\r\nif (ci->i_xattrs.blob)\r\nceph_buffer_put(ci->i_xattrs.blob);\r\nci->i_xattrs.blob = ceph_buffer_get(xattr_buf);\r\nci->i_xattrs.version = version;\r\nceph_forget_all_cached_acls(inode);\r\n}\r\n}\r\nif (newcaps & CEPH_CAP_ANY_RD) {\r\nceph_decode_timespec(&mtime, &grant->mtime);\r\nceph_decode_timespec(&atime, &grant->atime);\r\nceph_decode_timespec(&ctime, &grant->ctime);\r\nceph_fill_file_time(inode, issued,\r\nle32_to_cpu(grant->time_warp_seq),\r\n&ctime, &mtime, &atime);\r\n}\r\nif (newcaps & (CEPH_CAP_ANY_FILE_RD | CEPH_CAP_ANY_FILE_WR)) {\r\ns64 old_pool = ci->i_layout.pool_id;\r\nstruct ceph_string *old_ns;\r\nceph_file_layout_from_legacy(&ci->i_layout, &grant->layout);\r\nold_ns = rcu_dereference_protected(ci->i_layout.pool_ns,\r\nlockdep_is_held(&ci->i_ceph_lock));\r\nrcu_assign_pointer(ci->i_layout.pool_ns, *pns);\r\nif (ci->i_layout.pool_id != old_pool || *pns != old_ns)\r\nci->i_ceph_flags &= ~CEPH_I_POOL_PERM;\r\n*pns = old_ns;\r\nqueue_trunc = ceph_fill_file_size(inode, issued,\r\nle32_to_cpu(grant->truncate_seq),\r\nle64_to_cpu(grant->truncate_size),\r\nsize);\r\nif (ci->i_auth_cap == cap && max_size != ci->i_max_size) {\r\ndout("max_size %lld -> %llu\n",\r\nci->i_max_size, max_size);\r\nci->i_max_size = max_size;\r\nif (max_size >= ci->i_wanted_max_size) {\r\nci->i_wanted_max_size = 0;\r\nci->i_requested_max_size = 0;\r\n}\r\nwake = true;\r\n}\r\n}\r\nwanted = __ceph_caps_wanted(ci);\r\nused = __ceph_caps_used(ci);\r\ndirty = __ceph_caps_dirty(ci);\r\ndout(" my wanted = %s, used = %s, dirty %s\n",\r\nceph_cap_string(wanted),\r\nceph_cap_string(used),\r\nceph_cap_string(dirty));\r\nif (wanted != le32_to_cpu(grant->wanted)) {\r\ndout("mds wanted %s -> %s\n",\r\nceph_cap_string(le32_to_cpu(grant->wanted)),\r\nceph_cap_string(wanted));\r\nif (le32_to_cpu(grant->op) == CEPH_CAP_OP_IMPORT)\r\ncheck_caps = 1;\r\n}\r\nif (cap->issued & ~newcaps) {\r\nint revoking = cap->issued & ~newcaps;\r\ndout("revocation: %s -> %s (revoking %s)\n",\r\nceph_cap_string(cap->issued),\r\nceph_cap_string(newcaps),\r\nceph_cap_string(revoking));\r\nif (revoking & used & CEPH_CAP_FILE_BUFFER)\r\nwriteback = true;\r\nelse if (revoking == CEPH_CAP_FILE_CACHE &&\r\n(newcaps & CEPH_CAP_FILE_LAZYIO) == 0 &&\r\nqueue_invalidate)\r\n;\r\nelse if (cap == ci->i_auth_cap)\r\ncheck_caps = 1;\r\nelse\r\ncheck_caps = 2;\r\ncap->issued = newcaps;\r\ncap->implemented |= newcaps;\r\n} else if (cap->issued == newcaps) {\r\ndout("caps unchanged: %s -> %s\n",\r\nceph_cap_string(cap->issued), ceph_cap_string(newcaps));\r\n} else {\r\ndout("grant: %s -> %s\n", ceph_cap_string(cap->issued),\r\nceph_cap_string(newcaps));\r\nif (cap == ci->i_auth_cap &&\r\n__ceph_caps_revoking_other(ci, cap, newcaps))\r\ncheck_caps = 2;\r\ncap->issued = newcaps;\r\ncap->implemented |= newcaps;\r\nwake = true;\r\n}\r\nBUG_ON(cap->issued & ~cap->implemented);\r\nif (inline_version > 0 && inline_version >= ci->i_inline_version) {\r\nci->i_inline_version = inline_version;\r\nif (ci->i_inline_version != CEPH_INLINE_NONE &&\r\n(newcaps & (CEPH_CAP_FILE_CACHE|CEPH_CAP_FILE_LAZYIO)))\r\nfill_inline = true;\r\n}\r\nif (le32_to_cpu(grant->op) == CEPH_CAP_OP_IMPORT) {\r\nif (newcaps & ~issued)\r\nwake = true;\r\nkick_flushing_inode_caps(mdsc, session, inode);\r\nup_read(&mdsc->snap_rwsem);\r\n} else {\r\nspin_unlock(&ci->i_ceph_lock);\r\n}\r\nif (fill_inline)\r\nceph_fill_inline_data(inode, NULL, inline_data, inline_len);\r\nif (queue_trunc)\r\nceph_queue_vmtruncate(inode);\r\nif (writeback)\r\nceph_queue_writeback(inode);\r\nif (queue_invalidate)\r\nceph_queue_invalidate(inode);\r\nif (deleted_inode)\r\ninvalidate_aliases(inode);\r\nif (wake)\r\nwake_up_all(&ci->i_cap_wq);\r\nif (check_caps == 1)\r\nceph_check_caps(ci, CHECK_CAPS_NODELAY|CHECK_CAPS_AUTHONLY,\r\nsession);\r\nelse if (check_caps == 2)\r\nceph_check_caps(ci, CHECK_CAPS_NODELAY, session);\r\nelse\r\nmutex_unlock(&session->s_mutex);\r\n}\r\nstatic void handle_cap_flush_ack(struct inode *inode, u64 flush_tid,\r\nstruct ceph_mds_caps *m,\r\nstruct ceph_mds_session *session,\r\nstruct ceph_cap *cap)\r\n__releases(ci->i_ceph_lock)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_mds_client *mdsc = ceph_sb_to_client(inode->i_sb)->mdsc;\r\nstruct ceph_cap_flush *cf, *tmp_cf;\r\nLIST_HEAD(to_remove);\r\nunsigned seq = le32_to_cpu(m->seq);\r\nint dirty = le32_to_cpu(m->dirty);\r\nint cleaned = 0;\r\nbool drop = false;\r\nbool wake_ci = 0;\r\nbool wake_mdsc = 0;\r\nlist_for_each_entry_safe(cf, tmp_cf, &ci->i_cap_flush_list, i_list) {\r\nif (cf->tid == flush_tid)\r\ncleaned = cf->caps;\r\nif (cf->caps == 0)\r\ncontinue;\r\nif (cf->tid <= flush_tid) {\r\nif (__finish_cap_flush(NULL, ci, cf))\r\nwake_ci = true;\r\nlist_add_tail(&cf->i_list, &to_remove);\r\n} else {\r\ncleaned &= ~cf->caps;\r\nif (!cleaned)\r\nbreak;\r\n}\r\n}\r\ndout("handle_cap_flush_ack inode %p mds%d seq %d on %s cleaned %s,"\r\n" flushing %s -> %s\n",\r\ninode, session->s_mds, seq, ceph_cap_string(dirty),\r\nceph_cap_string(cleaned), ceph_cap_string(ci->i_flushing_caps),\r\nceph_cap_string(ci->i_flushing_caps & ~cleaned));\r\nif (list_empty(&to_remove) && !cleaned)\r\ngoto out;\r\nci->i_flushing_caps &= ~cleaned;\r\nspin_lock(&mdsc->cap_dirty_lock);\r\nlist_for_each_entry(cf, &to_remove, i_list) {\r\nif (__finish_cap_flush(mdsc, NULL, cf))\r\nwake_mdsc = true;\r\n}\r\nif (ci->i_flushing_caps == 0) {\r\nif (list_empty(&ci->i_cap_flush_list)) {\r\nlist_del_init(&ci->i_flushing_item);\r\nif (!list_empty(&session->s_cap_flushing)) {\r\ndout(" mds%d still flushing cap on %p\n",\r\nsession->s_mds,\r\n&list_first_entry(&session->s_cap_flushing,\r\nstruct ceph_inode_info,\r\ni_flushing_item)->vfs_inode);\r\n}\r\n}\r\nmdsc->num_cap_flushing--;\r\ndout(" inode %p now !flushing\n", inode);\r\nif (ci->i_dirty_caps == 0) {\r\ndout(" inode %p now clean\n", inode);\r\nBUG_ON(!list_empty(&ci->i_dirty_item));\r\ndrop = true;\r\nif (ci->i_wr_ref == 0 &&\r\nci->i_wrbuffer_ref_head == 0) {\r\nBUG_ON(!ci->i_head_snapc);\r\nceph_put_snap_context(ci->i_head_snapc);\r\nci->i_head_snapc = NULL;\r\n}\r\n} else {\r\nBUG_ON(list_empty(&ci->i_dirty_item));\r\n}\r\n}\r\nspin_unlock(&mdsc->cap_dirty_lock);\r\nout:\r\nspin_unlock(&ci->i_ceph_lock);\r\nwhile (!list_empty(&to_remove)) {\r\ncf = list_first_entry(&to_remove,\r\nstruct ceph_cap_flush, i_list);\r\nlist_del(&cf->i_list);\r\nceph_free_cap_flush(cf);\r\n}\r\nif (wake_ci)\r\nwake_up_all(&ci->i_cap_wq);\r\nif (wake_mdsc)\r\nwake_up_all(&mdsc->cap_flushing_wq);\r\nif (drop)\r\niput(inode);\r\n}\r\nstatic void handle_cap_flushsnap_ack(struct inode *inode, u64 flush_tid,\r\nstruct ceph_mds_caps *m,\r\nstruct ceph_mds_session *session)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_mds_client *mdsc = ceph_sb_to_client(inode->i_sb)->mdsc;\r\nu64 follows = le64_to_cpu(m->snap_follows);\r\nstruct ceph_cap_snap *capsnap;\r\nbool flushed = false;\r\nbool wake_ci = false;\r\nbool wake_mdsc = false;\r\ndout("handle_cap_flushsnap_ack inode %p ci %p mds%d follows %lld\n",\r\ninode, ci, session->s_mds, follows);\r\nspin_lock(&ci->i_ceph_lock);\r\nlist_for_each_entry(capsnap, &ci->i_cap_snaps, ci_item) {\r\nif (capsnap->follows == follows) {\r\nif (capsnap->cap_flush.tid != flush_tid) {\r\ndout(" cap_snap %p follows %lld tid %lld !="\r\n" %lld\n", capsnap, follows,\r\nflush_tid, capsnap->cap_flush.tid);\r\nbreak;\r\n}\r\nflushed = true;\r\nbreak;\r\n} else {\r\ndout(" skipping cap_snap %p follows %lld\n",\r\ncapsnap, capsnap->follows);\r\n}\r\n}\r\nif (flushed) {\r\nWARN_ON(capsnap->dirty_pages || capsnap->writing);\r\ndout(" removing %p cap_snap %p follows %lld\n",\r\ninode, capsnap, follows);\r\nlist_del(&capsnap->ci_item);\r\nif (__finish_cap_flush(NULL, ci, &capsnap->cap_flush))\r\nwake_ci = true;\r\nspin_lock(&mdsc->cap_dirty_lock);\r\nif (list_empty(&ci->i_cap_flush_list))\r\nlist_del_init(&ci->i_flushing_item);\r\nif (__finish_cap_flush(mdsc, NULL, &capsnap->cap_flush))\r\nwake_mdsc = true;\r\nspin_unlock(&mdsc->cap_dirty_lock);\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (flushed) {\r\nceph_put_snap_context(capsnap->context);\r\nceph_put_cap_snap(capsnap);\r\nif (wake_ci)\r\nwake_up_all(&ci->i_cap_wq);\r\nif (wake_mdsc)\r\nwake_up_all(&mdsc->cap_flushing_wq);\r\niput(inode);\r\n}\r\n}\r\nstatic void handle_cap_trunc(struct inode *inode,\r\nstruct ceph_mds_caps *trunc,\r\nstruct ceph_mds_session *session)\r\n__releases(ci->i_ceph_lock)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nint mds = session->s_mds;\r\nint seq = le32_to_cpu(trunc->seq);\r\nu32 truncate_seq = le32_to_cpu(trunc->truncate_seq);\r\nu64 truncate_size = le64_to_cpu(trunc->truncate_size);\r\nu64 size = le64_to_cpu(trunc->size);\r\nint implemented = 0;\r\nint dirty = __ceph_caps_dirty(ci);\r\nint issued = __ceph_caps_issued(ceph_inode(inode), &implemented);\r\nint queue_trunc = 0;\r\nissued |= implemented | dirty;\r\ndout("handle_cap_trunc inode %p mds%d seq %d to %lld seq %d\n",\r\ninode, mds, seq, truncate_size, truncate_seq);\r\nqueue_trunc = ceph_fill_file_size(inode, issued,\r\ntruncate_seq, truncate_size, size);\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (queue_trunc)\r\nceph_queue_vmtruncate(inode);\r\n}\r\nstatic void handle_cap_export(struct inode *inode, struct ceph_mds_caps *ex,\r\nstruct ceph_mds_cap_peer *ph,\r\nstruct ceph_mds_session *session)\r\n{\r\nstruct ceph_mds_client *mdsc = ceph_inode_to_client(inode)->mdsc;\r\nstruct ceph_mds_session *tsession = NULL;\r\nstruct ceph_cap *cap, *tcap, *new_cap = NULL;\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nu64 t_cap_id;\r\nunsigned mseq = le32_to_cpu(ex->migrate_seq);\r\nunsigned t_seq, t_mseq;\r\nint target, issued;\r\nint mds = session->s_mds;\r\nif (ph) {\r\nt_cap_id = le64_to_cpu(ph->cap_id);\r\nt_seq = le32_to_cpu(ph->seq);\r\nt_mseq = le32_to_cpu(ph->mseq);\r\ntarget = le32_to_cpu(ph->mds);\r\n} else {\r\nt_cap_id = t_seq = t_mseq = 0;\r\ntarget = -1;\r\n}\r\ndout("handle_cap_export inode %p ci %p mds%d mseq %d target %d\n",\r\ninode, ci, mds, mseq, target);\r\nretry:\r\nspin_lock(&ci->i_ceph_lock);\r\ncap = __get_cap_for_mds(ci, mds);\r\nif (!cap || cap->cap_id != le64_to_cpu(ex->cap_id))\r\ngoto out_unlock;\r\nif (target < 0) {\r\n__ceph_remove_cap(cap, false);\r\nif (!ci->i_auth_cap)\r\nci->i_ceph_flags |= CEPH_I_CAP_DROPPED;\r\ngoto out_unlock;\r\n}\r\nissued = cap->issued;\r\nWARN_ON(issued != cap->implemented);\r\ntcap = __get_cap_for_mds(ci, target);\r\nif (tcap) {\r\nif (tcap->cap_id != t_cap_id ||\r\nceph_seq_cmp(tcap->seq, t_seq) < 0) {\r\ndout(" updating import cap %p mds%d\n", tcap, target);\r\ntcap->cap_id = t_cap_id;\r\ntcap->seq = t_seq - 1;\r\ntcap->issue_seq = t_seq - 1;\r\ntcap->mseq = t_mseq;\r\ntcap->issued |= issued;\r\ntcap->implemented |= issued;\r\nif (cap == ci->i_auth_cap)\r\nci->i_auth_cap = tcap;\r\nif (!list_empty(&ci->i_cap_flush_list) &&\r\nci->i_auth_cap == tcap) {\r\nspin_lock(&mdsc->cap_dirty_lock);\r\nlist_move_tail(&ci->i_flushing_item,\r\n&tcap->session->s_cap_flushing);\r\nspin_unlock(&mdsc->cap_dirty_lock);\r\n}\r\n}\r\n__ceph_remove_cap(cap, false);\r\ngoto out_unlock;\r\n} else if (tsession) {\r\nint flag = (cap == ci->i_auth_cap) ? CEPH_CAP_FLAG_AUTH : 0;\r\nceph_add_cap(inode, tsession, t_cap_id, -1, issued, 0,\r\nt_seq - 1, t_mseq, (u64)-1, flag, &new_cap);\r\n__ceph_remove_cap(cap, false);\r\ngoto out_unlock;\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\nmutex_unlock(&session->s_mutex);\r\ntsession = ceph_mdsc_open_export_target_session(mdsc, target);\r\nif (!IS_ERR(tsession)) {\r\nif (mds > target) {\r\nmutex_lock(&session->s_mutex);\r\nmutex_lock_nested(&tsession->s_mutex,\r\nSINGLE_DEPTH_NESTING);\r\n} else {\r\nmutex_lock(&tsession->s_mutex);\r\nmutex_lock_nested(&session->s_mutex,\r\nSINGLE_DEPTH_NESTING);\r\n}\r\nnew_cap = ceph_get_cap(mdsc, NULL);\r\n} else {\r\nWARN_ON(1);\r\ntsession = NULL;\r\ntarget = -1;\r\n}\r\ngoto retry;\r\nout_unlock:\r\nspin_unlock(&ci->i_ceph_lock);\r\nmutex_unlock(&session->s_mutex);\r\nif (tsession) {\r\nmutex_unlock(&tsession->s_mutex);\r\nceph_put_mds_session(tsession);\r\n}\r\nif (new_cap)\r\nceph_put_cap(mdsc, new_cap);\r\n}\r\nstatic void handle_cap_import(struct ceph_mds_client *mdsc,\r\nstruct inode *inode, struct ceph_mds_caps *im,\r\nstruct ceph_mds_cap_peer *ph,\r\nstruct ceph_mds_session *session,\r\nstruct ceph_cap **target_cap, int *old_issued)\r\n__acquires(ci->i_ceph_lock)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_cap *cap, *ocap, *new_cap = NULL;\r\nint mds = session->s_mds;\r\nint issued;\r\nunsigned caps = le32_to_cpu(im->caps);\r\nunsigned wanted = le32_to_cpu(im->wanted);\r\nunsigned seq = le32_to_cpu(im->seq);\r\nunsigned mseq = le32_to_cpu(im->migrate_seq);\r\nu64 realmino = le64_to_cpu(im->realm);\r\nu64 cap_id = le64_to_cpu(im->cap_id);\r\nu64 p_cap_id;\r\nint peer;\r\nif (ph) {\r\np_cap_id = le64_to_cpu(ph->cap_id);\r\npeer = le32_to_cpu(ph->mds);\r\n} else {\r\np_cap_id = 0;\r\npeer = -1;\r\n}\r\ndout("handle_cap_import inode %p ci %p mds%d mseq %d peer %d\n",\r\ninode, ci, mds, mseq, peer);\r\nretry:\r\nspin_lock(&ci->i_ceph_lock);\r\ncap = __get_cap_for_mds(ci, mds);\r\nif (!cap) {\r\nif (!new_cap) {\r\nspin_unlock(&ci->i_ceph_lock);\r\nnew_cap = ceph_get_cap(mdsc, NULL);\r\ngoto retry;\r\n}\r\ncap = new_cap;\r\n} else {\r\nif (new_cap) {\r\nceph_put_cap(mdsc, new_cap);\r\nnew_cap = NULL;\r\n}\r\n}\r\n__ceph_caps_issued(ci, &issued);\r\nissued |= __ceph_caps_dirty(ci);\r\nceph_add_cap(inode, session, cap_id, -1, caps, wanted, seq, mseq,\r\nrealmino, CEPH_CAP_FLAG_AUTH, &new_cap);\r\nocap = peer >= 0 ? __get_cap_for_mds(ci, peer) : NULL;\r\nif (ocap && ocap->cap_id == p_cap_id) {\r\ndout(" remove export cap %p mds%d flags %d\n",\r\nocap, peer, ph->flags);\r\nif ((ph->flags & CEPH_CAP_FLAG_AUTH) &&\r\n(ocap->seq != le32_to_cpu(ph->seq) ||\r\nocap->mseq != le32_to_cpu(ph->mseq))) {\r\npr_err("handle_cap_import: mismatched seq/mseq: "\r\n"ino (%llx.%llx) mds%d seq %d mseq %d "\r\n"importer mds%d has peer seq %d mseq %d\n",\r\nceph_vinop(inode), peer, ocap->seq,\r\nocap->mseq, mds, le32_to_cpu(ph->seq),\r\nle32_to_cpu(ph->mseq));\r\n}\r\n__ceph_remove_cap(ocap, (ph->flags & CEPH_CAP_FLAG_RELEASE));\r\n}\r\nci->i_wanted_max_size = 0;\r\nci->i_requested_max_size = 0;\r\n*old_issued = issued;\r\n*target_cap = cap;\r\n}\r\nvoid ceph_handle_caps(struct ceph_mds_session *session,\r\nstruct ceph_msg *msg)\r\n{\r\nstruct ceph_mds_client *mdsc = session->s_mdsc;\r\nstruct super_block *sb = mdsc->fsc->sb;\r\nstruct inode *inode;\r\nstruct ceph_inode_info *ci;\r\nstruct ceph_cap *cap;\r\nstruct ceph_mds_caps *h;\r\nstruct ceph_mds_cap_peer *peer = NULL;\r\nstruct ceph_snap_realm *realm = NULL;\r\nstruct ceph_string *pool_ns = NULL;\r\nint mds = session->s_mds;\r\nint op, issued;\r\nu32 seq, mseq;\r\nstruct ceph_vino vino;\r\nu64 tid;\r\nu64 inline_version = 0;\r\nvoid *inline_data = NULL;\r\nu32 inline_len = 0;\r\nvoid *snaptrace;\r\nsize_t snaptrace_len;\r\nvoid *p, *end;\r\ndout("handle_caps from mds%d\n", mds);\r\nend = msg->front.iov_base + msg->front.iov_len;\r\ntid = le64_to_cpu(msg->hdr.tid);\r\nif (msg->front.iov_len < sizeof(*h))\r\ngoto bad;\r\nh = msg->front.iov_base;\r\nop = le32_to_cpu(h->op);\r\nvino.ino = le64_to_cpu(h->ino);\r\nvino.snap = CEPH_NOSNAP;\r\nseq = le32_to_cpu(h->seq);\r\nmseq = le32_to_cpu(h->migrate_seq);\r\nsnaptrace = h + 1;\r\nsnaptrace_len = le32_to_cpu(h->snap_trace_len);\r\np = snaptrace + snaptrace_len;\r\nif (le16_to_cpu(msg->hdr.version) >= 2) {\r\nu32 flock_len;\r\nceph_decode_32_safe(&p, end, flock_len, bad);\r\nif (p + flock_len > end)\r\ngoto bad;\r\np += flock_len;\r\n}\r\nif (le16_to_cpu(msg->hdr.version) >= 3) {\r\nif (op == CEPH_CAP_OP_IMPORT) {\r\nif (p + sizeof(*peer) > end)\r\ngoto bad;\r\npeer = p;\r\np += sizeof(*peer);\r\n} else if (op == CEPH_CAP_OP_EXPORT) {\r\npeer = (void *)&h->size;\r\n}\r\n}\r\nif (le16_to_cpu(msg->hdr.version) >= 4) {\r\nceph_decode_64_safe(&p, end, inline_version, bad);\r\nceph_decode_32_safe(&p, end, inline_len, bad);\r\nif (p + inline_len > end)\r\ngoto bad;\r\ninline_data = p;\r\np += inline_len;\r\n}\r\nif (le16_to_cpu(msg->hdr.version) >= 8) {\r\nu64 flush_tid;\r\nu32 caller_uid, caller_gid;\r\nu32 osd_epoch_barrier;\r\nu32 pool_ns_len;\r\nceph_decode_32_safe(&p, end, osd_epoch_barrier, bad);\r\nceph_decode_64_safe(&p, end, flush_tid, bad);\r\nceph_decode_32_safe(&p, end, caller_uid, bad);\r\nceph_decode_32_safe(&p, end, caller_gid, bad);\r\nceph_decode_32_safe(&p, end, pool_ns_len, bad);\r\nif (pool_ns_len > 0) {\r\nceph_decode_need(&p, end, pool_ns_len, bad);\r\npool_ns = ceph_find_or_create_string(p, pool_ns_len);\r\np += pool_ns_len;\r\n}\r\n}\r\ninode = ceph_find_inode(sb, vino);\r\nci = ceph_inode(inode);\r\ndout(" op %s ino %llx.%llx inode %p\n", ceph_cap_op_name(op), vino.ino,\r\nvino.snap, inode);\r\nmutex_lock(&session->s_mutex);\r\nsession->s_seq++;\r\ndout(" mds%d seq %lld cap seq %u\n", session->s_mds, session->s_seq,\r\n(unsigned)seq);\r\nif (!inode) {\r\ndout(" i don't have ino %llx\n", vino.ino);\r\nif (op == CEPH_CAP_OP_IMPORT) {\r\ncap = ceph_get_cap(mdsc, NULL);\r\ncap->cap_ino = vino.ino;\r\ncap->queue_release = 1;\r\ncap->cap_id = le64_to_cpu(h->cap_id);\r\ncap->mseq = mseq;\r\ncap->seq = seq;\r\nspin_lock(&session->s_cap_lock);\r\nlist_add_tail(&cap->session_caps,\r\n&session->s_cap_releases);\r\nsession->s_num_cap_releases++;\r\nspin_unlock(&session->s_cap_lock);\r\n}\r\ngoto flush_cap_releases;\r\n}\r\nswitch (op) {\r\ncase CEPH_CAP_OP_FLUSHSNAP_ACK:\r\nhandle_cap_flushsnap_ack(inode, tid, h, session);\r\ngoto done;\r\ncase CEPH_CAP_OP_EXPORT:\r\nhandle_cap_export(inode, h, peer, session);\r\ngoto done_unlocked;\r\ncase CEPH_CAP_OP_IMPORT:\r\nrealm = NULL;\r\nif (snaptrace_len) {\r\ndown_write(&mdsc->snap_rwsem);\r\nceph_update_snap_trace(mdsc, snaptrace,\r\nsnaptrace + snaptrace_len,\r\nfalse, &realm);\r\ndowngrade_write(&mdsc->snap_rwsem);\r\n} else {\r\ndown_read(&mdsc->snap_rwsem);\r\n}\r\nhandle_cap_import(mdsc, inode, h, peer, session,\r\n&cap, &issued);\r\nhandle_cap_grant(mdsc, inode, h, &pool_ns,\r\ninline_version, inline_data, inline_len,\r\nmsg->middle, session, cap, issued);\r\nif (realm)\r\nceph_put_snap_realm(mdsc, realm);\r\ngoto done_unlocked;\r\n}\r\nspin_lock(&ci->i_ceph_lock);\r\ncap = __get_cap_for_mds(ceph_inode(inode), mds);\r\nif (!cap) {\r\ndout(" no cap on %p ino %llx.%llx from mds%d\n",\r\ninode, ceph_ino(inode), ceph_snap(inode), mds);\r\nspin_unlock(&ci->i_ceph_lock);\r\ngoto flush_cap_releases;\r\n}\r\nswitch (op) {\r\ncase CEPH_CAP_OP_REVOKE:\r\ncase CEPH_CAP_OP_GRANT:\r\n__ceph_caps_issued(ci, &issued);\r\nissued |= __ceph_caps_dirty(ci);\r\nhandle_cap_grant(mdsc, inode, h, &pool_ns,\r\ninline_version, inline_data, inline_len,\r\nmsg->middle, session, cap, issued);\r\ngoto done_unlocked;\r\ncase CEPH_CAP_OP_FLUSH_ACK:\r\nhandle_cap_flush_ack(inode, tid, h, session, cap);\r\nbreak;\r\ncase CEPH_CAP_OP_TRUNC:\r\nhandle_cap_trunc(inode, h, session);\r\nbreak;\r\ndefault:\r\nspin_unlock(&ci->i_ceph_lock);\r\npr_err("ceph_handle_caps: unknown cap op %d %s\n", op,\r\nceph_cap_op_name(op));\r\n}\r\ngoto done;\r\nflush_cap_releases:\r\nceph_send_cap_releases(mdsc, session);\r\ndone:\r\nmutex_unlock(&session->s_mutex);\r\ndone_unlocked:\r\niput(inode);\r\nceph_put_string(pool_ns);\r\nreturn;\r\nbad:\r\npr_err("ceph_handle_caps: corrupt message\n");\r\nceph_msg_dump(msg);\r\nreturn;\r\n}\r\nvoid ceph_check_delayed_caps(struct ceph_mds_client *mdsc)\r\n{\r\nstruct ceph_inode_info *ci;\r\nint flags = CHECK_CAPS_NODELAY;\r\ndout("check_delayed_caps\n");\r\nwhile (1) {\r\nspin_lock(&mdsc->cap_delay_lock);\r\nif (list_empty(&mdsc->cap_delay_list))\r\nbreak;\r\nci = list_first_entry(&mdsc->cap_delay_list,\r\nstruct ceph_inode_info,\r\ni_cap_delay_list);\r\nif ((ci->i_ceph_flags & CEPH_I_FLUSH) == 0 &&\r\ntime_before(jiffies, ci->i_hold_caps_max))\r\nbreak;\r\nlist_del_init(&ci->i_cap_delay_list);\r\nspin_unlock(&mdsc->cap_delay_lock);\r\ndout("check_delayed_caps on %p\n", &ci->vfs_inode);\r\nceph_check_caps(ci, flags, NULL);\r\n}\r\nspin_unlock(&mdsc->cap_delay_lock);\r\n}\r\nvoid ceph_flush_dirty_caps(struct ceph_mds_client *mdsc)\r\n{\r\nstruct ceph_inode_info *ci;\r\nstruct inode *inode;\r\ndout("flush_dirty_caps\n");\r\nspin_lock(&mdsc->cap_dirty_lock);\r\nwhile (!list_empty(&mdsc->cap_dirty)) {\r\nci = list_first_entry(&mdsc->cap_dirty, struct ceph_inode_info,\r\ni_dirty_item);\r\ninode = &ci->vfs_inode;\r\nihold(inode);\r\ndout("flush_dirty_caps %p\n", inode);\r\nspin_unlock(&mdsc->cap_dirty_lock);\r\nceph_check_caps(ci, CHECK_CAPS_NODELAY|CHECK_CAPS_FLUSH, NULL);\r\niput(inode);\r\nspin_lock(&mdsc->cap_dirty_lock);\r\n}\r\nspin_unlock(&mdsc->cap_dirty_lock);\r\ndout("flush_dirty_caps done\n");\r\n}\r\nvoid __ceph_get_fmode(struct ceph_inode_info *ci, int fmode)\r\n{\r\nint i;\r\nint bits = (fmode << 1) | 1;\r\nfor (i = 0; i < CEPH_FILE_MODE_BITS; i++) {\r\nif (bits & (1 << i))\r\nci->i_nr_by_mode[i]++;\r\n}\r\n}\r\nvoid ceph_put_fmode(struct ceph_inode_info *ci, int fmode)\r\n{\r\nint i, last = 0;\r\nint bits = (fmode << 1) | 1;\r\nspin_lock(&ci->i_ceph_lock);\r\nfor (i = 0; i < CEPH_FILE_MODE_BITS; i++) {\r\nif (bits & (1 << i)) {\r\nBUG_ON(ci->i_nr_by_mode[i] == 0);\r\nif (--ci->i_nr_by_mode[i] == 0)\r\nlast++;\r\n}\r\n}\r\ndout("put_fmode %p fmode %d {%d,%d,%d,%d}\n",\r\n&ci->vfs_inode, fmode,\r\nci->i_nr_by_mode[0], ci->i_nr_by_mode[1],\r\nci->i_nr_by_mode[2], ci->i_nr_by_mode[3]);\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (last && ci->i_vino.snap == CEPH_NOSNAP)\r\nceph_check_caps(ci, 0, NULL);\r\n}\r\nint ceph_encode_inode_release(void **p, struct inode *inode,\r\nint mds, int drop, int unless, int force)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_cap *cap;\r\nstruct ceph_mds_request_release *rel = *p;\r\nint used, dirty;\r\nint ret = 0;\r\nspin_lock(&ci->i_ceph_lock);\r\nused = __ceph_caps_used(ci);\r\ndirty = __ceph_caps_dirty(ci);\r\ndout("encode_inode_release %p mds%d used|dirty %s drop %s unless %s\n",\r\ninode, mds, ceph_cap_string(used|dirty), ceph_cap_string(drop),\r\nceph_cap_string(unless));\r\ndrop &= ~(used | dirty);\r\ncap = __get_cap_for_mds(ci, mds);\r\nif (cap && __cap_is_valid(cap)) {\r\nif (force ||\r\n((cap->issued & drop) &&\r\n(cap->issued & unless) == 0)) {\r\nif ((cap->issued & drop) &&\r\n(cap->issued & unless) == 0) {\r\nint wanted = __ceph_caps_wanted(ci);\r\nif ((ci->i_ceph_flags & CEPH_I_NODELAY) == 0)\r\nwanted |= cap->mds_wanted;\r\ndout("encode_inode_release %p cap %p "\r\n"%s -> %s, wanted %s -> %s\n", inode, cap,\r\nceph_cap_string(cap->issued),\r\nceph_cap_string(cap->issued & ~drop),\r\nceph_cap_string(cap->mds_wanted),\r\nceph_cap_string(wanted));\r\ncap->issued &= ~drop;\r\ncap->implemented &= ~drop;\r\ncap->mds_wanted = wanted;\r\n} else {\r\ndout("encode_inode_release %p cap %p %s"\r\n" (force)\n", inode, cap,\r\nceph_cap_string(cap->issued));\r\n}\r\nrel->ino = cpu_to_le64(ceph_ino(inode));\r\nrel->cap_id = cpu_to_le64(cap->cap_id);\r\nrel->seq = cpu_to_le32(cap->seq);\r\nrel->issue_seq = cpu_to_le32(cap->issue_seq);\r\nrel->mseq = cpu_to_le32(cap->mseq);\r\nrel->caps = cpu_to_le32(cap->implemented);\r\nrel->wanted = cpu_to_le32(cap->mds_wanted);\r\nrel->dname_len = 0;\r\nrel->dname_seq = 0;\r\n*p += sizeof(*rel);\r\nret = 1;\r\n} else {\r\ndout("encode_inode_release %p cap %p %s\n",\r\ninode, cap, ceph_cap_string(cap->issued));\r\n}\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\nreturn ret;\r\n}\r\nint ceph_encode_dentry_release(void **p, struct dentry *dentry,\r\nint mds, int drop, int unless)\r\n{\r\nstruct inode *dir = d_inode(dentry->d_parent);\r\nstruct ceph_mds_request_release *rel = *p;\r\nstruct ceph_dentry_info *di = ceph_dentry(dentry);\r\nint force = 0;\r\nint ret;\r\nspin_lock(&dentry->d_lock);\r\nif (di->lease_session && di->lease_session->s_mds == mds)\r\nforce = 1;\r\nspin_unlock(&dentry->d_lock);\r\nret = ceph_encode_inode_release(p, dir, mds, drop, unless, force);\r\nspin_lock(&dentry->d_lock);\r\nif (ret && di->lease_session && di->lease_session->s_mds == mds) {\r\ndout("encode_dentry_release %p mds%d seq %d\n",\r\ndentry, mds, (int)di->lease_seq);\r\nrel->dname_len = cpu_to_le32(dentry->d_name.len);\r\nmemcpy(*p, dentry->d_name.name, dentry->d_name.len);\r\n*p += dentry->d_name.len;\r\nrel->dname_seq = cpu_to_le32(di->lease_seq);\r\n__ceph_mdsc_drop_dentry_lease(dentry);\r\n}\r\nspin_unlock(&dentry->d_lock);\r\nreturn ret;\r\n}
