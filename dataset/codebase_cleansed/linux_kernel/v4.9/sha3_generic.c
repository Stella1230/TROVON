static void keccakf(u64 st[25])\r\n{\r\nint i, j, round;\r\nu64 t, bc[5];\r\nfor (round = 0; round < KECCAK_ROUNDS; round++) {\r\nfor (i = 0; i < 5; i++)\r\nbc[i] = st[i] ^ st[i + 5] ^ st[i + 10] ^ st[i + 15]\r\n^ st[i + 20];\r\nfor (i = 0; i < 5; i++) {\r\nt = bc[(i + 4) % 5] ^ ROTL64(bc[(i + 1) % 5], 1);\r\nfor (j = 0; j < 25; j += 5)\r\nst[j + i] ^= t;\r\n}\r\nt = st[1];\r\nfor (i = 0; i < 24; i++) {\r\nj = keccakf_piln[i];\r\nbc[0] = st[j];\r\nst[j] = ROTL64(t, keccakf_rotc[i]);\r\nt = bc[0];\r\n}\r\nfor (j = 0; j < 25; j += 5) {\r\nfor (i = 0; i < 5; i++)\r\nbc[i] = st[j + i];\r\nfor (i = 0; i < 5; i++)\r\nst[j + i] ^= (~bc[(i + 1) % 5]) &\r\nbc[(i + 2) % 5];\r\n}\r\nst[0] ^= keccakf_rndc[round];\r\n}\r\n}\r\nstatic void sha3_init(struct sha3_state *sctx, unsigned int digest_sz)\r\n{\r\nmemset(sctx, 0, sizeof(*sctx));\r\nsctx->md_len = digest_sz;\r\nsctx->rsiz = 200 - 2 * digest_sz;\r\nsctx->rsizw = sctx->rsiz / 8;\r\n}\r\nstatic int sha3_224_init(struct shash_desc *desc)\r\n{\r\nstruct sha3_state *sctx = shash_desc_ctx(desc);\r\nsha3_init(sctx, SHA3_224_DIGEST_SIZE);\r\nreturn 0;\r\n}\r\nstatic int sha3_256_init(struct shash_desc *desc)\r\n{\r\nstruct sha3_state *sctx = shash_desc_ctx(desc);\r\nsha3_init(sctx, SHA3_256_DIGEST_SIZE);\r\nreturn 0;\r\n}\r\nstatic int sha3_384_init(struct shash_desc *desc)\r\n{\r\nstruct sha3_state *sctx = shash_desc_ctx(desc);\r\nsha3_init(sctx, SHA3_384_DIGEST_SIZE);\r\nreturn 0;\r\n}\r\nstatic int sha3_512_init(struct shash_desc *desc)\r\n{\r\nstruct sha3_state *sctx = shash_desc_ctx(desc);\r\nsha3_init(sctx, SHA3_512_DIGEST_SIZE);\r\nreturn 0;\r\n}\r\nstatic int sha3_update(struct shash_desc *desc, const u8 *data,\r\nunsigned int len)\r\n{\r\nstruct sha3_state *sctx = shash_desc_ctx(desc);\r\nunsigned int done;\r\nconst u8 *src;\r\ndone = 0;\r\nsrc = data;\r\nif ((sctx->partial + len) > (sctx->rsiz - 1)) {\r\nif (sctx->partial) {\r\ndone = -sctx->partial;\r\nmemcpy(sctx->buf + sctx->partial, data,\r\ndone + sctx->rsiz);\r\nsrc = sctx->buf;\r\n}\r\ndo {\r\nunsigned int i;\r\nfor (i = 0; i < sctx->rsizw; i++)\r\nsctx->st[i] ^= ((u64 *) src)[i];\r\nkeccakf(sctx->st);\r\ndone += sctx->rsiz;\r\nsrc = data + done;\r\n} while (done + (sctx->rsiz - 1) < len);\r\nsctx->partial = 0;\r\n}\r\nmemcpy(sctx->buf + sctx->partial, src, len - done);\r\nsctx->partial += (len - done);\r\nreturn 0;\r\n}\r\nstatic int sha3_final(struct shash_desc *desc, u8 *out)\r\n{\r\nstruct sha3_state *sctx = shash_desc_ctx(desc);\r\nunsigned int i, inlen = sctx->partial;\r\nsctx->buf[inlen++] = 0x06;\r\nmemset(sctx->buf + inlen, 0, sctx->rsiz - inlen);\r\nsctx->buf[sctx->rsiz - 1] |= 0x80;\r\nfor (i = 0; i < sctx->rsizw; i++)\r\nsctx->st[i] ^= ((u64 *) sctx->buf)[i];\r\nkeccakf(sctx->st);\r\nfor (i = 0; i < sctx->rsizw; i++)\r\nsctx->st[i] = cpu_to_le64(sctx->st[i]);\r\nmemcpy(out, sctx->st, sctx->md_len);\r\nmemset(sctx, 0, sizeof(*sctx));\r\nreturn 0;\r\n}\r\nstatic int __init sha3_generic_mod_init(void)\r\n{\r\nint ret;\r\nret = crypto_register_shash(&sha3_224);\r\nif (ret < 0)\r\ngoto err_out;\r\nret = crypto_register_shash(&sha3_256);\r\nif (ret < 0)\r\ngoto err_out_224;\r\nret = crypto_register_shash(&sha3_384);\r\nif (ret < 0)\r\ngoto err_out_256;\r\nret = crypto_register_shash(&sha3_512);\r\nif (ret < 0)\r\ngoto err_out_384;\r\nreturn 0;\r\nerr_out_384:\r\ncrypto_unregister_shash(&sha3_384);\r\nerr_out_256:\r\ncrypto_unregister_shash(&sha3_256);\r\nerr_out_224:\r\ncrypto_unregister_shash(&sha3_224);\r\nerr_out:\r\nreturn ret;\r\n}\r\nstatic void __exit sha3_generic_mod_fini(void)\r\n{\r\ncrypto_unregister_shash(&sha3_224);\r\ncrypto_unregister_shash(&sha3_256);\r\ncrypto_unregister_shash(&sha3_384);\r\ncrypto_unregister_shash(&sha3_512);\r\n}
