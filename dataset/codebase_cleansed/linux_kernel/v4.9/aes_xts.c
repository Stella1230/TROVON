static int p8_aes_xts_init(struct crypto_tfm *tfm)\r\n{\r\nconst char *alg;\r\nstruct crypto_blkcipher *fallback;\r\nstruct p8_aes_xts_ctx *ctx = crypto_tfm_ctx(tfm);\r\nif (!(alg = crypto_tfm_alg_name(tfm))) {\r\nprintk(KERN_ERR "Failed to get algorithm name.\n");\r\nreturn -ENOENT;\r\n}\r\nfallback =\r\ncrypto_alloc_blkcipher(alg, 0, CRYPTO_ALG_NEED_FALLBACK);\r\nif (IS_ERR(fallback)) {\r\nprintk(KERN_ERR\r\n"Failed to allocate transformation for '%s': %ld\n",\r\nalg, PTR_ERR(fallback));\r\nreturn PTR_ERR(fallback);\r\n}\r\nprintk(KERN_INFO "Using '%s' as fallback implementation.\n",\r\ncrypto_tfm_alg_driver_name((struct crypto_tfm *) fallback));\r\ncrypto_blkcipher_set_flags(\r\nfallback,\r\ncrypto_blkcipher_get_flags((struct crypto_blkcipher *)tfm));\r\nctx->fallback = fallback;\r\nreturn 0;\r\n}\r\nstatic void p8_aes_xts_exit(struct crypto_tfm *tfm)\r\n{\r\nstruct p8_aes_xts_ctx *ctx = crypto_tfm_ctx(tfm);\r\nif (ctx->fallback) {\r\ncrypto_free_blkcipher(ctx->fallback);\r\nctx->fallback = NULL;\r\n}\r\n}\r\nstatic int p8_aes_xts_setkey(struct crypto_tfm *tfm, const u8 *key,\r\nunsigned int keylen)\r\n{\r\nint ret;\r\nstruct p8_aes_xts_ctx *ctx = crypto_tfm_ctx(tfm);\r\nret = xts_check_key(tfm, key, keylen);\r\nif (ret)\r\nreturn ret;\r\npreempt_disable();\r\npagefault_disable();\r\nenable_kernel_vsx();\r\nret = aes_p8_set_encrypt_key(key + keylen/2, (keylen/2) * 8, &ctx->tweak_key);\r\nret += aes_p8_set_encrypt_key(key, (keylen/2) * 8, &ctx->enc_key);\r\nret += aes_p8_set_decrypt_key(key, (keylen/2) * 8, &ctx->dec_key);\r\ndisable_kernel_vsx();\r\npagefault_enable();\r\npreempt_enable();\r\nret += crypto_blkcipher_setkey(ctx->fallback, key, keylen);\r\nreturn ret;\r\n}\r\nstatic int p8_aes_xts_crypt(struct blkcipher_desc *desc,\r\nstruct scatterlist *dst,\r\nstruct scatterlist *src,\r\nunsigned int nbytes, int enc)\r\n{\r\nint ret;\r\nu8 tweak[AES_BLOCK_SIZE];\r\nu8 *iv;\r\nstruct blkcipher_walk walk;\r\nstruct p8_aes_xts_ctx *ctx =\r\ncrypto_tfm_ctx(crypto_blkcipher_tfm(desc->tfm));\r\nstruct blkcipher_desc fallback_desc = {\r\n.tfm = ctx->fallback,\r\n.info = desc->info,\r\n.flags = desc->flags\r\n};\r\nif (in_interrupt()) {\r\nret = enc ? crypto_blkcipher_encrypt(&fallback_desc, dst, src, nbytes) :\r\ncrypto_blkcipher_decrypt(&fallback_desc, dst, src, nbytes);\r\n} else {\r\npreempt_disable();\r\npagefault_disable();\r\nenable_kernel_vsx();\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nret = blkcipher_walk_virt(desc, &walk);\r\niv = walk.iv;\r\nmemset(tweak, 0, AES_BLOCK_SIZE);\r\naes_p8_encrypt(iv, tweak, &ctx->tweak_key);\r\nwhile ((nbytes = walk.nbytes)) {\r\nif (enc)\r\naes_p8_xts_encrypt(walk.src.virt.addr, walk.dst.virt.addr,\r\nnbytes & AES_BLOCK_MASK, &ctx->enc_key, NULL, tweak);\r\nelse\r\naes_p8_xts_decrypt(walk.src.virt.addr, walk.dst.virt.addr,\r\nnbytes & AES_BLOCK_MASK, &ctx->dec_key, NULL, tweak);\r\nnbytes &= AES_BLOCK_SIZE - 1;\r\nret = blkcipher_walk_done(desc, &walk, nbytes);\r\n}\r\ndisable_kernel_vsx();\r\npagefault_enable();\r\npreempt_enable();\r\n}\r\nreturn ret;\r\n}\r\nstatic int p8_aes_xts_encrypt(struct blkcipher_desc *desc,\r\nstruct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nreturn p8_aes_xts_crypt(desc, dst, src, nbytes, 1);\r\n}\r\nstatic int p8_aes_xts_decrypt(struct blkcipher_desc *desc,\r\nstruct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nreturn p8_aes_xts_crypt(desc, dst, src, nbytes, 0);\r\n}
