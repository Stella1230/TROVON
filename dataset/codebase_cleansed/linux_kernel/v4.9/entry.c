int kvm_mips_entry_setup(void)\r\n{\r\nunsigned int kscratch_mask = cpu_data[0].kscratch_mask & 0xfc;\r\nif (kscratch_mask) {\r\nscratch_vcpu[0] = 31;\r\nscratch_vcpu[1] = ffs(kscratch_mask) - 1;\r\nkscratch_mask &= ~BIT(scratch_vcpu[1]);\r\n}\r\nif (kscratch_mask) {\r\nscratch_tmp[0] = 31;\r\nscratch_tmp[1] = ffs(kscratch_mask) - 1;\r\nkscratch_mask &= ~BIT(scratch_tmp[1]);\r\n}\r\nreturn 0;\r\n}\r\nstatic void kvm_mips_build_save_scratch(u32 **p, unsigned int tmp,\r\nunsigned int frame)\r\n{\r\nUASM_i_MFC0(p, tmp, scratch_vcpu[0], scratch_vcpu[1]);\r\nUASM_i_SW(p, tmp, offsetof(struct pt_regs, cp0_epc), frame);\r\nif (scratch_tmp[0] == 31) {\r\nUASM_i_MFC0(p, tmp, scratch_tmp[0], scratch_tmp[1]);\r\nUASM_i_SW(p, tmp, offsetof(struct pt_regs, cp0_cause), frame);\r\n}\r\n}\r\nstatic void kvm_mips_build_restore_scratch(u32 **p, unsigned int tmp,\r\nunsigned int frame)\r\n{\r\nUASM_i_LW(p, tmp, offsetof(struct pt_regs, cp0_epc), frame);\r\nUASM_i_MTC0(p, tmp, scratch_vcpu[0], scratch_vcpu[1]);\r\nif (scratch_tmp[0] == 31) {\r\nUASM_i_LW(p, tmp, offsetof(struct pt_regs, cp0_cause), frame);\r\nUASM_i_MTC0(p, tmp, scratch_tmp[0], scratch_tmp[1]);\r\n}\r\n}\r\nstatic inline void build_set_exc_base(u32 **p, unsigned int reg)\r\n{\r\nif (cpu_has_ebase_wg) {\r\nuasm_i_ori(p, reg, reg, MIPS_EBASE_WG);\r\nUASM_i_MTC0(p, reg, C0_EBASE);\r\n} else {\r\nuasm_i_mtc0(p, reg, C0_EBASE);\r\n}\r\n}\r\nvoid *kvm_mips_build_vcpu_run(void *addr)\r\n{\r\nu32 *p = addr;\r\nunsigned int i;\r\nUASM_i_ADDIU(&p, K1, SP, -(int)sizeof(struct pt_regs));\r\nfor (i = 16; i < 32; ++i) {\r\nif (i == 24)\r\ni = 28;\r\nUASM_i_SW(&p, i, offsetof(struct pt_regs, regs[i]), K1);\r\n}\r\nuasm_i_mfc0(&p, V0, C0_STATUS);\r\nUASM_i_SW(&p, V0, offsetof(struct pt_regs, cp0_status), K1);\r\nkvm_mips_build_save_scratch(&p, V1, K1);\r\nUASM_i_MTC0(&p, A1, scratch_vcpu[0], scratch_vcpu[1]);\r\nUASM_i_ADDIU(&p, K1, A1, offsetof(struct kvm_vcpu, arch));\r\nUASM_i_SW(&p, SP, offsetof(struct kvm_vcpu_arch, host_stack), K1);\r\nUASM_i_SW(&p, GP, offsetof(struct kvm_vcpu_arch, host_gp), K1);\r\nUASM_i_LA(&p, K0, ST0_EXL | KSU_USER | ST0_BEV | ST0_KX_IF_64);\r\nuasm_i_mtc0(&p, K0, C0_STATUS);\r\nuasm_i_ehb(&p);\r\nUASM_i_LW(&p, K0, offsetof(struct kvm_vcpu_arch, guest_ebase), K1);\r\nbuild_set_exc_base(&p, K0);\r\nuasm_i_addiu(&p, K0, ZERO, ST0_EXL | KSU_USER | ST0_IE | ST0_KX_IF_64);\r\nuasm_i_andi(&p, V0, V0, ST0_IM);\r\nuasm_i_or(&p, K0, K0, V0);\r\nuasm_i_mtc0(&p, K0, C0_STATUS);\r\nuasm_i_ehb(&p);\r\np = kvm_mips_build_enter_guest(p);\r\nreturn p;\r\n}\r\nstatic void *kvm_mips_build_enter_guest(void *addr)\r\n{\r\nu32 *p = addr;\r\nunsigned int i;\r\nstruct uasm_label labels[2];\r\nstruct uasm_reloc relocs[2];\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\nUASM_i_LW(&p, T0, offsetof(struct kvm_vcpu_arch, pc), K1);\r\nUASM_i_MTC0(&p, T0, C0_EPC);\r\nUASM_i_LW(&p, T0, offsetof(struct kvm_vcpu_arch, cop0), K1);\r\nUASM_i_LW(&p, T0, offsetof(struct mips_coproc, reg[MIPS_CP0_STATUS][0]),\r\nT0);\r\nuasm_i_andi(&p, T0, T0, KSU_USER | ST0_ERL | ST0_EXL);\r\nuasm_i_xori(&p, T0, T0, KSU_USER);\r\nuasm_il_bnez(&p, &r, T0, label_kernel_asid);\r\nUASM_i_ADDIU(&p, T1, K1,\r\noffsetof(struct kvm_vcpu_arch, guest_kernel_asid));\r\nUASM_i_ADDIU(&p, T1, K1,\r\noffsetof(struct kvm_vcpu_arch, guest_user_asid));\r\nuasm_l_kernel_asid(&l, p);\r\nuasm_i_lw(&p, T2, offsetof(struct thread_info, cpu), GP);\r\nuasm_i_sll(&p, T2, T2, 2);\r\nUASM_i_ADDU(&p, T3, T1, T2);\r\nuasm_i_lw(&p, K0, 0, T3);\r\n#ifdef CONFIG_MIPS_ASID_BITS_VARIABLE\r\nuasm_i_addiu(&p, T3, ZERO, sizeof(struct cpuinfo_mips)/4);\r\nuasm_i_mul(&p, T2, T2, T3);\r\nUASM_i_LA_mostly(&p, AT, (long)&cpu_data[0].asid_mask);\r\nUASM_i_ADDU(&p, AT, AT, T2);\r\nUASM_i_LW(&p, T2, uasm_rel_lo((long)&cpu_data[0].asid_mask), AT);\r\nuasm_i_and(&p, K0, K0, T2);\r\n#else\r\nuasm_i_andi(&p, K0, K0, MIPS_ENTRYHI_ASID);\r\n#endif\r\nuasm_i_mtc0(&p, K0, C0_ENTRYHI);\r\nuasm_i_ehb(&p);\r\nuasm_i_mtc0(&p, ZERO, C0_HWRENA);\r\nfor (i = 1; i < 32; ++i) {\r\nif (i == K0 || i == K1)\r\ncontinue;\r\nUASM_i_LW(&p, i, offsetof(struct kvm_vcpu_arch, gprs[i]), K1);\r\n}\r\n#ifndef CONFIG_CPU_MIPSR6\r\nUASM_i_LW(&p, K0, offsetof(struct kvm_vcpu_arch, hi), K1);\r\nuasm_i_mthi(&p, K0);\r\nUASM_i_LW(&p, K0, offsetof(struct kvm_vcpu_arch, lo), K1);\r\nuasm_i_mtlo(&p, K0);\r\n#endif\r\nUASM_i_LW(&p, K0, offsetof(struct kvm_vcpu_arch, gprs[K0]), K1);\r\nUASM_i_LW(&p, K1, offsetof(struct kvm_vcpu_arch, gprs[K1]), K1);\r\nuasm_i_eret(&p);\r\nuasm_resolve_relocs(relocs, labels);\r\nreturn p;\r\n}\r\nvoid *kvm_mips_build_exception(void *addr, void *handler)\r\n{\r\nu32 *p = addr;\r\nstruct uasm_label labels[2];\r\nstruct uasm_reloc relocs[2];\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\nUASM_i_MTC0(&p, K1, scratch_tmp[0], scratch_tmp[1]);\r\nUASM_i_MFC0(&p, K1, scratch_vcpu[0], scratch_vcpu[1]);\r\nUASM_i_ADDIU(&p, K1, K1, offsetof(struct kvm_vcpu, arch));\r\nUASM_i_SW(&p, K0, offsetof(struct kvm_vcpu_arch, gprs[K0]), K1);\r\nuasm_il_b(&p, &r, label_exit_common);\r\nuasm_i_nop(&p);\r\nuasm_l_exit_common(&l, handler);\r\nuasm_resolve_relocs(relocs, labels);\r\nreturn p;\r\n}\r\nvoid *kvm_mips_build_exit(void *addr)\r\n{\r\nu32 *p = addr;\r\nunsigned int i;\r\nstruct uasm_label labels[3];\r\nstruct uasm_reloc relocs[3];\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\nfor (i = 0; i < 32; ++i) {\r\nif (i == K0 || i == K1)\r\ncontinue;\r\nUASM_i_SW(&p, i, offsetof(struct kvm_vcpu_arch, gprs[i]), K1);\r\n}\r\n#ifndef CONFIG_CPU_MIPSR6\r\nuasm_i_mfhi(&p, T0);\r\nUASM_i_SW(&p, T0, offsetof(struct kvm_vcpu_arch, hi), K1);\r\nuasm_i_mflo(&p, T0);\r\nUASM_i_SW(&p, T0, offsetof(struct kvm_vcpu_arch, lo), K1);\r\n#endif\r\nuasm_i_ehb(&p);\r\nUASM_i_MFC0(&p, T0, scratch_tmp[0], scratch_tmp[1]);\r\nUASM_i_SW(&p, T0, offsetof(struct kvm_vcpu_arch, gprs[K1]), K1);\r\nUASM_i_MFC0(&p, A1, scratch_vcpu[0], scratch_vcpu[1]);\r\nuasm_i_move(&p, S1, A1);\r\nUASM_i_LW(&p, A0, offsetof(struct kvm_vcpu, run), A1);\r\nuasm_i_move(&p, S0, A0);\r\nUASM_i_MFC0(&p, K0, C0_EPC);\r\nUASM_i_SW(&p, K0, offsetof(struct kvm_vcpu_arch, pc), K1);\r\nUASM_i_MFC0(&p, K0, C0_BADVADDR);\r\nUASM_i_SW(&p, K0, offsetof(struct kvm_vcpu_arch, host_cp0_badvaddr),\r\nK1);\r\nuasm_i_mfc0(&p, K0, C0_CAUSE);\r\nuasm_i_sw(&p, K0, offsetof(struct kvm_vcpu_arch, host_cp0_cause), K1);\r\nuasm_i_mfc0(&p, V0, C0_STATUS);\r\nuasm_i_lui(&p, AT, ST0_BEV >> 16);\r\nuasm_i_or(&p, K0, V0, AT);\r\nuasm_i_mtc0(&p, K0, C0_STATUS);\r\nuasm_i_ehb(&p);\r\nUASM_i_LA_mostly(&p, K0, (long)&ebase);\r\nUASM_i_LW(&p, K0, uasm_rel_lo((long)&ebase), K0);\r\nbuild_set_exc_base(&p, K0);\r\nif (raw_cpu_has_fpu) {\r\nuasm_i_lui(&p, AT, ST0_CU1 >> 16);\r\nuasm_i_and(&p, V1, V0, AT);\r\nuasm_il_beqz(&p, &r, V1, label_fpu_1);\r\nuasm_i_nop(&p);\r\nuasm_i_cfc1(&p, T0, 31);\r\nuasm_i_sw(&p, T0, offsetof(struct kvm_vcpu_arch, fpu.fcr31),\r\nK1);\r\nuasm_i_ctc1(&p, ZERO, 31);\r\nuasm_l_fpu_1(&l, p);\r\n}\r\nif (cpu_has_msa) {\r\nuasm_i_mfc0(&p, T0, C0_CONFIG5);\r\nuasm_i_ext(&p, T0, T0, 27, 1);\r\nuasm_il_beqz(&p, &r, T0, label_msa_1);\r\nuasm_i_nop(&p);\r\nuasm_i_cfcmsa(&p, T0, MSA_CSR);\r\nuasm_i_sw(&p, T0, offsetof(struct kvm_vcpu_arch, fpu.msacsr),\r\nK1);\r\nuasm_i_ctcmsa(&p, MSA_CSR, ZERO);\r\nuasm_l_msa_1(&l, p);\r\n}\r\nuasm_i_addiu(&p, AT, ZERO, ~(ST0_EXL | KSU_USER | ST0_IE));\r\nuasm_i_and(&p, V0, V0, AT);\r\nuasm_i_lui(&p, AT, ST0_CU0 >> 16);\r\nuasm_i_or(&p, V0, V0, AT);\r\nuasm_i_mtc0(&p, V0, C0_STATUS);\r\nuasm_i_ehb(&p);\r\nUASM_i_LW(&p, GP, offsetof(struct kvm_vcpu_arch, host_gp), K1);\r\nUASM_i_LW(&p, SP, offsetof(struct kvm_vcpu_arch, host_stack), K1);\r\nUASM_i_ADDIU(&p, SP, SP, -(int)sizeof(struct pt_regs));\r\nkvm_mips_build_restore_scratch(&p, K0, SP);\r\nUASM_i_LA_mostly(&p, K0, (long)&hwrena);\r\nuasm_i_lw(&p, K0, uasm_rel_lo((long)&hwrena), K0);\r\nuasm_i_mtc0(&p, K0, C0_HWRENA);\r\nUASM_i_LA(&p, T9, (unsigned long)kvm_mips_handle_exit);\r\nuasm_i_jalr(&p, RA, T9);\r\nUASM_i_ADDIU(&p, SP, SP, -CALLFRAME_SIZ);\r\nuasm_resolve_relocs(relocs, labels);\r\np = kvm_mips_build_ret_from_exit(p);\r\nreturn p;\r\n}\r\nstatic void *kvm_mips_build_ret_from_exit(void *addr)\r\n{\r\nu32 *p = addr;\r\nstruct uasm_label labels[2];\r\nstruct uasm_reloc relocs[2];\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\nuasm_i_di(&p, ZERO);\r\nuasm_i_ehb(&p);\r\nuasm_i_move(&p, K1, S1);\r\nUASM_i_ADDIU(&p, K1, K1, offsetof(struct kvm_vcpu, arch));\r\nuasm_i_andi(&p, T0, V0, RESUME_HOST);\r\nuasm_il_bnez(&p, &r, T0, label_return_to_host);\r\nuasm_i_nop(&p);\r\np = kvm_mips_build_ret_to_guest(p);\r\nuasm_l_return_to_host(&l, p);\r\np = kvm_mips_build_ret_to_host(p);\r\nuasm_resolve_relocs(relocs, labels);\r\nreturn p;\r\n}\r\nstatic void *kvm_mips_build_ret_to_guest(void *addr)\r\n{\r\nu32 *p = addr;\r\nUASM_i_MTC0(&p, S1, scratch_vcpu[0], scratch_vcpu[1]);\r\nUASM_i_LW(&p, T0, offsetof(struct kvm_vcpu_arch, guest_ebase), K1);\r\nuasm_i_mfc0(&p, V1, C0_STATUS);\r\nuasm_i_lui(&p, AT, ST0_BEV >> 16);\r\nuasm_i_or(&p, K0, V1, AT);\r\nuasm_i_mtc0(&p, K0, C0_STATUS);\r\nuasm_i_ehb(&p);\r\nbuild_set_exc_base(&p, T0);\r\nuasm_i_ori(&p, V1, V1, ST0_EXL | KSU_USER | ST0_IE);\r\nUASM_i_LA(&p, AT, ~(ST0_CU0 | ST0_MX));\r\nuasm_i_and(&p, V1, V1, AT);\r\nuasm_i_mtc0(&p, V1, C0_STATUS);\r\nuasm_i_ehb(&p);\r\np = kvm_mips_build_enter_guest(p);\r\nreturn p;\r\n}\r\nstatic void *kvm_mips_build_ret_to_host(void *addr)\r\n{\r\nu32 *p = addr;\r\nunsigned int i;\r\nUASM_i_LW(&p, K1, offsetof(struct kvm_vcpu_arch, host_stack), K1);\r\nUASM_i_ADDIU(&p, K1, K1, -(int)sizeof(struct pt_regs));\r\nuasm_i_sra(&p, K0, V0, 2);\r\nuasm_i_move(&p, V0, K0);\r\nfor (i = 16; i < 31; ++i) {\r\nif (i == 24)\r\ni = 28;\r\nUASM_i_LW(&p, i, offsetof(struct pt_regs, regs[i]), K1);\r\n}\r\nUASM_i_LA_mostly(&p, K0, (long)&hwrena);\r\nuasm_i_lw(&p, K0, uasm_rel_lo((long)&hwrena), K0);\r\nuasm_i_mtc0(&p, K0, C0_HWRENA);\r\nUASM_i_LW(&p, RA, offsetof(struct pt_regs, regs[RA]), K1);\r\nuasm_i_jr(&p, RA);\r\nuasm_i_nop(&p);\r\nreturn p;\r\n}
