static struct virtio_vsock *virtio_vsock_get(void)\r\n{\r\nreturn the_virtio_vsock;\r\n}\r\nstatic u32 virtio_transport_get_local_cid(void)\r\n{\r\nstruct virtio_vsock *vsock = virtio_vsock_get();\r\nreturn vsock->guest_cid;\r\n}\r\nstatic void\r\nvirtio_transport_send_pkt_work(struct work_struct *work)\r\n{\r\nstruct virtio_vsock *vsock =\r\ncontainer_of(work, struct virtio_vsock, send_pkt_work);\r\nstruct virtqueue *vq;\r\nbool added = false;\r\nbool restart_rx = false;\r\nmutex_lock(&vsock->tx_lock);\r\nvq = vsock->vqs[VSOCK_VQ_TX];\r\nfor (;;) {\r\nstruct virtio_vsock_pkt *pkt;\r\nstruct scatterlist hdr, buf, *sgs[2];\r\nint ret, in_sg = 0, out_sg = 0;\r\nbool reply;\r\nspin_lock_bh(&vsock->send_pkt_list_lock);\r\nif (list_empty(&vsock->send_pkt_list)) {\r\nspin_unlock_bh(&vsock->send_pkt_list_lock);\r\nbreak;\r\n}\r\npkt = list_first_entry(&vsock->send_pkt_list,\r\nstruct virtio_vsock_pkt, list);\r\nlist_del_init(&pkt->list);\r\nspin_unlock_bh(&vsock->send_pkt_list_lock);\r\nreply = pkt->reply;\r\nsg_init_one(&hdr, &pkt->hdr, sizeof(pkt->hdr));\r\nsgs[out_sg++] = &hdr;\r\nif (pkt->buf) {\r\nsg_init_one(&buf, pkt->buf, pkt->len);\r\nsgs[out_sg++] = &buf;\r\n}\r\nret = virtqueue_add_sgs(vq, sgs, out_sg, in_sg, pkt, GFP_KERNEL);\r\nif (ret < 0) {\r\nspin_lock_bh(&vsock->send_pkt_list_lock);\r\nlist_add(&pkt->list, &vsock->send_pkt_list);\r\nspin_unlock_bh(&vsock->send_pkt_list_lock);\r\nbreak;\r\n}\r\nif (reply) {\r\nstruct virtqueue *rx_vq = vsock->vqs[VSOCK_VQ_RX];\r\nint val;\r\nval = atomic_dec_return(&vsock->queued_replies);\r\nif (val + 1 == virtqueue_get_vring_size(rx_vq))\r\nrestart_rx = true;\r\n}\r\nadded = true;\r\n}\r\nif (added)\r\nvirtqueue_kick(vq);\r\nmutex_unlock(&vsock->tx_lock);\r\nif (restart_rx)\r\nqueue_work(virtio_vsock_workqueue, &vsock->rx_work);\r\n}\r\nstatic int\r\nvirtio_transport_send_pkt(struct virtio_vsock_pkt *pkt)\r\n{\r\nstruct virtio_vsock *vsock;\r\nint len = pkt->len;\r\nvsock = virtio_vsock_get();\r\nif (!vsock) {\r\nvirtio_transport_free_pkt(pkt);\r\nreturn -ENODEV;\r\n}\r\nif (pkt->reply)\r\natomic_inc(&vsock->queued_replies);\r\nspin_lock_bh(&vsock->send_pkt_list_lock);\r\nlist_add_tail(&pkt->list, &vsock->send_pkt_list);\r\nspin_unlock_bh(&vsock->send_pkt_list_lock);\r\nqueue_work(virtio_vsock_workqueue, &vsock->send_pkt_work);\r\nreturn len;\r\n}\r\nstatic void virtio_vsock_rx_fill(struct virtio_vsock *vsock)\r\n{\r\nint buf_len = VIRTIO_VSOCK_DEFAULT_RX_BUF_SIZE;\r\nstruct virtio_vsock_pkt *pkt;\r\nstruct scatterlist hdr, buf, *sgs[2];\r\nstruct virtqueue *vq;\r\nint ret;\r\nvq = vsock->vqs[VSOCK_VQ_RX];\r\ndo {\r\npkt = kzalloc(sizeof(*pkt), GFP_KERNEL);\r\nif (!pkt)\r\nbreak;\r\npkt->buf = kmalloc(buf_len, GFP_KERNEL);\r\nif (!pkt->buf) {\r\nvirtio_transport_free_pkt(pkt);\r\nbreak;\r\n}\r\npkt->len = buf_len;\r\nsg_init_one(&hdr, &pkt->hdr, sizeof(pkt->hdr));\r\nsgs[0] = &hdr;\r\nsg_init_one(&buf, pkt->buf, buf_len);\r\nsgs[1] = &buf;\r\nret = virtqueue_add_sgs(vq, sgs, 0, 2, pkt, GFP_KERNEL);\r\nif (ret) {\r\nvirtio_transport_free_pkt(pkt);\r\nbreak;\r\n}\r\nvsock->rx_buf_nr++;\r\n} while (vq->num_free);\r\nif (vsock->rx_buf_nr > vsock->rx_buf_max_nr)\r\nvsock->rx_buf_max_nr = vsock->rx_buf_nr;\r\nvirtqueue_kick(vq);\r\n}\r\nstatic void virtio_transport_tx_work(struct work_struct *work)\r\n{\r\nstruct virtio_vsock *vsock =\r\ncontainer_of(work, struct virtio_vsock, tx_work);\r\nstruct virtqueue *vq;\r\nbool added = false;\r\nvq = vsock->vqs[VSOCK_VQ_TX];\r\nmutex_lock(&vsock->tx_lock);\r\ndo {\r\nstruct virtio_vsock_pkt *pkt;\r\nunsigned int len;\r\nvirtqueue_disable_cb(vq);\r\nwhile ((pkt = virtqueue_get_buf(vq, &len)) != NULL) {\r\nvirtio_transport_free_pkt(pkt);\r\nadded = true;\r\n}\r\n} while (!virtqueue_enable_cb(vq));\r\nmutex_unlock(&vsock->tx_lock);\r\nif (added)\r\nqueue_work(virtio_vsock_workqueue, &vsock->send_pkt_work);\r\n}\r\nstatic bool virtio_transport_more_replies(struct virtio_vsock *vsock)\r\n{\r\nstruct virtqueue *vq = vsock->vqs[VSOCK_VQ_RX];\r\nint val;\r\nsmp_rmb();\r\nval = atomic_read(&vsock->queued_replies);\r\nreturn val < virtqueue_get_vring_size(vq);\r\n}\r\nstatic void virtio_transport_rx_work(struct work_struct *work)\r\n{\r\nstruct virtio_vsock *vsock =\r\ncontainer_of(work, struct virtio_vsock, rx_work);\r\nstruct virtqueue *vq;\r\nvq = vsock->vqs[VSOCK_VQ_RX];\r\nmutex_lock(&vsock->rx_lock);\r\ndo {\r\nvirtqueue_disable_cb(vq);\r\nfor (;;) {\r\nstruct virtio_vsock_pkt *pkt;\r\nunsigned int len;\r\nif (!virtio_transport_more_replies(vsock)) {\r\ngoto out;\r\n}\r\npkt = virtqueue_get_buf(vq, &len);\r\nif (!pkt) {\r\nbreak;\r\n}\r\nvsock->rx_buf_nr--;\r\nif (unlikely(len < sizeof(pkt->hdr) ||\r\nlen > sizeof(pkt->hdr) + pkt->len)) {\r\nvirtio_transport_free_pkt(pkt);\r\ncontinue;\r\n}\r\npkt->len = len - sizeof(pkt->hdr);\r\nvirtio_transport_recv_pkt(pkt);\r\n}\r\n} while (!virtqueue_enable_cb(vq));\r\nout:\r\nif (vsock->rx_buf_nr < vsock->rx_buf_max_nr / 2)\r\nvirtio_vsock_rx_fill(vsock);\r\nmutex_unlock(&vsock->rx_lock);\r\n}\r\nstatic int virtio_vsock_event_fill_one(struct virtio_vsock *vsock,\r\nstruct virtio_vsock_event *event)\r\n{\r\nstruct scatterlist sg;\r\nstruct virtqueue *vq;\r\nvq = vsock->vqs[VSOCK_VQ_EVENT];\r\nsg_init_one(&sg, event, sizeof(*event));\r\nreturn virtqueue_add_inbuf(vq, &sg, 1, event, GFP_KERNEL);\r\n}\r\nstatic void virtio_vsock_event_fill(struct virtio_vsock *vsock)\r\n{\r\nsize_t i;\r\nfor (i = 0; i < ARRAY_SIZE(vsock->event_list); i++) {\r\nstruct virtio_vsock_event *event = &vsock->event_list[i];\r\nvirtio_vsock_event_fill_one(vsock, event);\r\n}\r\nvirtqueue_kick(vsock->vqs[VSOCK_VQ_EVENT]);\r\n}\r\nstatic void virtio_vsock_reset_sock(struct sock *sk)\r\n{\r\nlock_sock(sk);\r\nsk->sk_state = SS_UNCONNECTED;\r\nsk->sk_err = ECONNRESET;\r\nsk->sk_error_report(sk);\r\nrelease_sock(sk);\r\n}\r\nstatic void virtio_vsock_update_guest_cid(struct virtio_vsock *vsock)\r\n{\r\nstruct virtio_device *vdev = vsock->vdev;\r\nu64 guest_cid;\r\nvdev->config->get(vdev, offsetof(struct virtio_vsock_config, guest_cid),\r\n&guest_cid, sizeof(guest_cid));\r\nvsock->guest_cid = le64_to_cpu(guest_cid);\r\n}\r\nstatic void virtio_vsock_event_handle(struct virtio_vsock *vsock,\r\nstruct virtio_vsock_event *event)\r\n{\r\nswitch (le32_to_cpu(event->id)) {\r\ncase VIRTIO_VSOCK_EVENT_TRANSPORT_RESET:\r\nvirtio_vsock_update_guest_cid(vsock);\r\nvsock_for_each_connected_socket(virtio_vsock_reset_sock);\r\nbreak;\r\n}\r\n}\r\nstatic void virtio_transport_event_work(struct work_struct *work)\r\n{\r\nstruct virtio_vsock *vsock =\r\ncontainer_of(work, struct virtio_vsock, event_work);\r\nstruct virtqueue *vq;\r\nvq = vsock->vqs[VSOCK_VQ_EVENT];\r\nmutex_lock(&vsock->event_lock);\r\ndo {\r\nstruct virtio_vsock_event *event;\r\nunsigned int len;\r\nvirtqueue_disable_cb(vq);\r\nwhile ((event = virtqueue_get_buf(vq, &len)) != NULL) {\r\nif (len == sizeof(*event))\r\nvirtio_vsock_event_handle(vsock, event);\r\nvirtio_vsock_event_fill_one(vsock, event);\r\n}\r\n} while (!virtqueue_enable_cb(vq));\r\nvirtqueue_kick(vsock->vqs[VSOCK_VQ_EVENT]);\r\nmutex_unlock(&vsock->event_lock);\r\n}\r\nstatic void virtio_vsock_event_done(struct virtqueue *vq)\r\n{\r\nstruct virtio_vsock *vsock = vq->vdev->priv;\r\nif (!vsock)\r\nreturn;\r\nqueue_work(virtio_vsock_workqueue, &vsock->event_work);\r\n}\r\nstatic void virtio_vsock_tx_done(struct virtqueue *vq)\r\n{\r\nstruct virtio_vsock *vsock = vq->vdev->priv;\r\nif (!vsock)\r\nreturn;\r\nqueue_work(virtio_vsock_workqueue, &vsock->tx_work);\r\n}\r\nstatic void virtio_vsock_rx_done(struct virtqueue *vq)\r\n{\r\nstruct virtio_vsock *vsock = vq->vdev->priv;\r\nif (!vsock)\r\nreturn;\r\nqueue_work(virtio_vsock_workqueue, &vsock->rx_work);\r\n}\r\nstatic int virtio_vsock_probe(struct virtio_device *vdev)\r\n{\r\nvq_callback_t *callbacks[] = {\r\nvirtio_vsock_rx_done,\r\nvirtio_vsock_tx_done,\r\nvirtio_vsock_event_done,\r\n};\r\nstatic const char * const names[] = {\r\n"rx",\r\n"tx",\r\n"event",\r\n};\r\nstruct virtio_vsock *vsock = NULL;\r\nint ret;\r\nret = mutex_lock_interruptible(&the_virtio_vsock_mutex);\r\nif (ret)\r\nreturn ret;\r\nif (the_virtio_vsock) {\r\nret = -EBUSY;\r\ngoto out;\r\n}\r\nvsock = kzalloc(sizeof(*vsock), GFP_KERNEL);\r\nif (!vsock) {\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\nvsock->vdev = vdev;\r\nret = vsock->vdev->config->find_vqs(vsock->vdev, VSOCK_VQ_MAX,\r\nvsock->vqs, callbacks, names);\r\nif (ret < 0)\r\ngoto out;\r\nvirtio_vsock_update_guest_cid(vsock);\r\nret = vsock_core_init(&virtio_transport.transport);\r\nif (ret < 0)\r\ngoto out_vqs;\r\nvsock->rx_buf_nr = 0;\r\nvsock->rx_buf_max_nr = 0;\r\natomic_set(&vsock->queued_replies, 0);\r\nvdev->priv = vsock;\r\nthe_virtio_vsock = vsock;\r\nmutex_init(&vsock->tx_lock);\r\nmutex_init(&vsock->rx_lock);\r\nmutex_init(&vsock->event_lock);\r\nspin_lock_init(&vsock->send_pkt_list_lock);\r\nINIT_LIST_HEAD(&vsock->send_pkt_list);\r\nINIT_WORK(&vsock->rx_work, virtio_transport_rx_work);\r\nINIT_WORK(&vsock->tx_work, virtio_transport_tx_work);\r\nINIT_WORK(&vsock->event_work, virtio_transport_event_work);\r\nINIT_WORK(&vsock->send_pkt_work, virtio_transport_send_pkt_work);\r\nmutex_lock(&vsock->rx_lock);\r\nvirtio_vsock_rx_fill(vsock);\r\nmutex_unlock(&vsock->rx_lock);\r\nmutex_lock(&vsock->event_lock);\r\nvirtio_vsock_event_fill(vsock);\r\nmutex_unlock(&vsock->event_lock);\r\nmutex_unlock(&the_virtio_vsock_mutex);\r\nreturn 0;\r\nout_vqs:\r\nvsock->vdev->config->del_vqs(vsock->vdev);\r\nout:\r\nkfree(vsock);\r\nmutex_unlock(&the_virtio_vsock_mutex);\r\nreturn ret;\r\n}\r\nstatic void virtio_vsock_remove(struct virtio_device *vdev)\r\n{\r\nstruct virtio_vsock *vsock = vdev->priv;\r\nstruct virtio_vsock_pkt *pkt;\r\nflush_work(&vsock->rx_work);\r\nflush_work(&vsock->tx_work);\r\nflush_work(&vsock->event_work);\r\nflush_work(&vsock->send_pkt_work);\r\nvdev->config->reset(vdev);\r\nmutex_lock(&vsock->rx_lock);\r\nwhile ((pkt = virtqueue_detach_unused_buf(vsock->vqs[VSOCK_VQ_RX])))\r\nvirtio_transport_free_pkt(pkt);\r\nmutex_unlock(&vsock->rx_lock);\r\nmutex_lock(&vsock->tx_lock);\r\nwhile ((pkt = virtqueue_detach_unused_buf(vsock->vqs[VSOCK_VQ_TX])))\r\nvirtio_transport_free_pkt(pkt);\r\nmutex_unlock(&vsock->tx_lock);\r\nspin_lock_bh(&vsock->send_pkt_list_lock);\r\nwhile (!list_empty(&vsock->send_pkt_list)) {\r\npkt = list_first_entry(&vsock->send_pkt_list,\r\nstruct virtio_vsock_pkt, list);\r\nlist_del(&pkt->list);\r\nvirtio_transport_free_pkt(pkt);\r\n}\r\nspin_unlock_bh(&vsock->send_pkt_list_lock);\r\nmutex_lock(&the_virtio_vsock_mutex);\r\nthe_virtio_vsock = NULL;\r\nvsock_core_exit();\r\nmutex_unlock(&the_virtio_vsock_mutex);\r\nvdev->config->del_vqs(vdev);\r\nkfree(vsock);\r\n}\r\nstatic int __init virtio_vsock_init(void)\r\n{\r\nint ret;\r\nvirtio_vsock_workqueue = alloc_workqueue("virtio_vsock", 0, 0);\r\nif (!virtio_vsock_workqueue)\r\nreturn -ENOMEM;\r\nret = register_virtio_driver(&virtio_vsock_driver);\r\nif (ret)\r\ndestroy_workqueue(virtio_vsock_workqueue);\r\nreturn ret;\r\n}\r\nstatic void __exit virtio_vsock_exit(void)\r\n{\r\nunregister_virtio_driver(&virtio_vsock_driver);\r\ndestroy_workqueue(virtio_vsock_workqueue);\r\n}
