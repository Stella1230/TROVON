static inline bool msc_block_is_empty(struct msc_block_desc *bdesc)\r\n{\r\nif (!bdesc->valid_dw)\r\nreturn true;\r\nif (!msc_data_sz(bdesc))\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic struct msc_window *msc_oldest_window(struct msc *msc)\r\n{\r\nstruct msc_window *win;\r\nu32 reg = ioread32(msc->reg_base + REG_MSU_MSC0NWSA);\r\nunsigned long win_addr = (unsigned long)reg << PAGE_SHIFT;\r\nunsigned int found = 0;\r\nif (list_empty(&msc->win_list))\r\nreturn NULL;\r\nlist_for_each_entry(win, &msc->win_list, entry) {\r\nif (win->block[0].addr == win_addr)\r\nfound++;\r\nif (msc_block_is_empty(win->block[0].bdesc))\r\ncontinue;\r\nif (found)\r\nreturn win;\r\n}\r\nreturn list_entry(msc->win_list.next, struct msc_window, entry);\r\n}\r\nstatic unsigned int msc_win_oldest_block(struct msc_window *win)\r\n{\r\nunsigned int blk;\r\nstruct msc_block_desc *bdesc = win->block[0].bdesc;\r\nif (!msc_block_wrapped(bdesc))\r\nreturn 0;\r\nfor (blk = 0; blk < win->nr_blocks; blk++) {\r\nbdesc = win->block[blk].bdesc;\r\nif (msc_block_last_written(bdesc))\r\nreturn blk;\r\n}\r\nreturn 0;\r\n}\r\nstatic inline bool msc_is_last_win(struct msc_window *win)\r\n{\r\nreturn win->entry.next == &win->msc->win_list;\r\n}\r\nstatic struct msc_window *msc_next_window(struct msc_window *win)\r\n{\r\nif (msc_is_last_win(win))\r\nreturn list_entry(win->msc->win_list.next, struct msc_window,\r\nentry);\r\nreturn list_entry(win->entry.next, struct msc_window, entry);\r\n}\r\nstatic struct msc_block_desc *msc_iter_bdesc(struct msc_iter *iter)\r\n{\r\nreturn iter->win->block[iter->block].bdesc;\r\n}\r\nstatic void msc_iter_init(struct msc_iter *iter)\r\n{\r\nmemset(iter, 0, sizeof(*iter));\r\niter->start_block = -1;\r\niter->block = -1;\r\n}\r\nstatic struct msc_iter *msc_iter_install(struct msc *msc)\r\n{\r\nstruct msc_iter *iter;\r\niter = kzalloc(sizeof(*iter), GFP_KERNEL);\r\nif (!iter)\r\nreturn ERR_PTR(-ENOMEM);\r\nmutex_lock(&msc->buf_mutex);\r\nif (msc->enabled) {\r\nkfree(iter);\r\niter = ERR_PTR(-EBUSY);\r\ngoto unlock;\r\n}\r\nmsc_iter_init(iter);\r\niter->msc = msc;\r\nlist_add_tail(&iter->entry, &msc->iter_list);\r\nunlock:\r\nmutex_unlock(&msc->buf_mutex);\r\nreturn iter;\r\n}\r\nstatic void msc_iter_remove(struct msc_iter *iter, struct msc *msc)\r\n{\r\nmutex_lock(&msc->buf_mutex);\r\nlist_del(&iter->entry);\r\nmutex_unlock(&msc->buf_mutex);\r\nkfree(iter);\r\n}\r\nstatic void msc_iter_block_start(struct msc_iter *iter)\r\n{\r\nif (iter->start_block != -1)\r\nreturn;\r\niter->start_block = msc_win_oldest_block(iter->win);\r\niter->block = iter->start_block;\r\niter->wrap_count = 0;\r\nif (msc_block_wrapped(msc_iter_bdesc(iter)))\r\niter->wrap_count = 2;\r\n}\r\nstatic int msc_iter_win_start(struct msc_iter *iter, struct msc *msc)\r\n{\r\nif (iter->start_win)\r\nreturn 0;\r\niter->start_win = msc_oldest_window(msc);\r\nif (!iter->start_win)\r\nreturn -EINVAL;\r\niter->win = iter->start_win;\r\niter->start_block = -1;\r\nmsc_iter_block_start(iter);\r\nreturn 0;\r\n}\r\nstatic int msc_iter_win_advance(struct msc_iter *iter)\r\n{\r\niter->win = msc_next_window(iter->win);\r\niter->start_block = -1;\r\nif (iter->win == iter->start_win) {\r\niter->eof++;\r\nreturn 1;\r\n}\r\nmsc_iter_block_start(iter);\r\nreturn 0;\r\n}\r\nstatic int msc_iter_block_advance(struct msc_iter *iter)\r\n{\r\niter->block_off = 0;\r\nif (iter->wrap_count && iter->block == iter->start_block) {\r\niter->wrap_count--;\r\nif (!iter->wrap_count)\r\nreturn msc_iter_win_advance(iter);\r\n}\r\nif (!iter->wrap_count && msc_block_last_written(msc_iter_bdesc(iter)))\r\nreturn msc_iter_win_advance(iter);\r\nif (++iter->block == iter->win->nr_blocks)\r\niter->block = 0;\r\nif (!iter->wrap_count && iter->block == iter->start_block)\r\nreturn msc_iter_win_advance(iter);\r\nreturn 0;\r\n}\r\nstatic void msc_buffer_clear_hw_header(struct msc *msc)\r\n{\r\nstruct msc_window *win;\r\nlist_for_each_entry(win, &msc->win_list, entry) {\r\nunsigned int blk;\r\nsize_t hw_sz = sizeof(struct msc_block_desc) -\r\noffsetof(struct msc_block_desc, hw_tag);\r\nfor (blk = 0; blk < win->nr_blocks; blk++) {\r\nstruct msc_block_desc *bdesc = win->block[blk].bdesc;\r\nmemset(&bdesc->hw_tag, 0, hw_sz);\r\n}\r\n}\r\n}\r\nstatic int msc_configure(struct msc *msc)\r\n{\r\nu32 reg;\r\nlockdep_assert_held(&msc->buf_mutex);\r\nif (msc->mode > MSC_MODE_MULTI)\r\nreturn -ENOTSUPP;\r\nif (msc->mode == MSC_MODE_MULTI)\r\nmsc_buffer_clear_hw_header(msc);\r\nreg = msc->base_addr >> PAGE_SHIFT;\r\niowrite32(reg, msc->reg_base + REG_MSU_MSC0BAR);\r\nif (msc->mode == MSC_MODE_SINGLE) {\r\nreg = msc->nr_pages;\r\niowrite32(reg, msc->reg_base + REG_MSU_MSC0SIZE);\r\n}\r\nreg = ioread32(msc->reg_base + REG_MSU_MSC0CTL);\r\nreg &= ~(MSC_MODE | MSC_WRAPEN | MSC_EN | MSC_RD_HDR_OVRD);\r\nreg |= MSC_EN;\r\nreg |= msc->mode << __ffs(MSC_MODE);\r\nreg |= msc->burst_len << __ffs(MSC_LEN);\r\nif (msc->wrap)\r\nreg |= MSC_WRAPEN;\r\niowrite32(reg, msc->reg_base + REG_MSU_MSC0CTL);\r\nmsc->thdev->output.multiblock = msc->mode == MSC_MODE_MULTI;\r\nintel_th_trace_enable(msc->thdev);\r\nmsc->enabled = 1;\r\nreturn 0;\r\n}\r\nstatic void msc_disable(struct msc *msc)\r\n{\r\nunsigned long count;\r\nu32 reg;\r\nlockdep_assert_held(&msc->buf_mutex);\r\nintel_th_trace_disable(msc->thdev);\r\nfor (reg = 0, count = MSC_PLE_WAITLOOP_DEPTH;\r\ncount && !(reg & MSCSTS_PLE); count--) {\r\nreg = ioread32(msc->reg_base + REG_MSU_MSC0STS);\r\ncpu_relax();\r\n}\r\nif (!count)\r\ndev_dbg(msc_dev(msc), "timeout waiting for MSC0 PLE\n");\r\nif (msc->mode == MSC_MODE_SINGLE) {\r\nmsc->single_wrap = !!(reg & MSCSTS_WRAPSTAT);\r\nreg = ioread32(msc->reg_base + REG_MSU_MSC0MWP);\r\nmsc->single_sz = reg & ((msc->nr_pages << PAGE_SHIFT) - 1);\r\ndev_dbg(msc_dev(msc), "MSCnMWP: %08x/%08lx, wrap: %d\n",\r\nreg, msc->single_sz, msc->single_wrap);\r\n}\r\nreg = ioread32(msc->reg_base + REG_MSU_MSC0CTL);\r\nreg &= ~MSC_EN;\r\niowrite32(reg, msc->reg_base + REG_MSU_MSC0CTL);\r\nmsc->enabled = 0;\r\niowrite32(0, msc->reg_base + REG_MSU_MSC0BAR);\r\niowrite32(0, msc->reg_base + REG_MSU_MSC0SIZE);\r\ndev_dbg(msc_dev(msc), "MSCnNWSA: %08x\n",\r\nioread32(msc->reg_base + REG_MSU_MSC0NWSA));\r\nreg = ioread32(msc->reg_base + REG_MSU_MSC0STS);\r\ndev_dbg(msc_dev(msc), "MSCnSTS: %08x\n", reg);\r\n}\r\nstatic int intel_th_msc_activate(struct intel_th_device *thdev)\r\n{\r\nstruct msc *msc = dev_get_drvdata(&thdev->dev);\r\nint ret = -EBUSY;\r\nif (!atomic_inc_unless_negative(&msc->user_count))\r\nreturn -ENODEV;\r\nmutex_lock(&msc->buf_mutex);\r\nif (list_empty(&msc->iter_list))\r\nret = msc_configure(msc);\r\nmutex_unlock(&msc->buf_mutex);\r\nif (ret)\r\natomic_dec(&msc->user_count);\r\nreturn ret;\r\n}\r\nstatic void intel_th_msc_deactivate(struct intel_th_device *thdev)\r\n{\r\nstruct msc *msc = dev_get_drvdata(&thdev->dev);\r\nmutex_lock(&msc->buf_mutex);\r\nif (msc->enabled) {\r\nmsc_disable(msc);\r\natomic_dec(&msc->user_count);\r\n}\r\nmutex_unlock(&msc->buf_mutex);\r\n}\r\nstatic int msc_buffer_contig_alloc(struct msc *msc, unsigned long size)\r\n{\r\nunsigned int order = get_order(size);\r\nstruct page *page;\r\nif (!size)\r\nreturn 0;\r\npage = alloc_pages(GFP_KERNEL | __GFP_ZERO, order);\r\nif (!page)\r\nreturn -ENOMEM;\r\nsplit_page(page, order);\r\nmsc->nr_pages = size >> PAGE_SHIFT;\r\nmsc->base = page_address(page);\r\nmsc->base_addr = page_to_phys(page);\r\nreturn 0;\r\n}\r\nstatic void msc_buffer_contig_free(struct msc *msc)\r\n{\r\nunsigned long off;\r\nfor (off = 0; off < msc->nr_pages << PAGE_SHIFT; off += PAGE_SIZE) {\r\nstruct page *page = virt_to_page(msc->base + off);\r\npage->mapping = NULL;\r\n__free_page(page);\r\n}\r\nmsc->nr_pages = 0;\r\n}\r\nstatic struct page *msc_buffer_contig_get_page(struct msc *msc,\r\nunsigned long pgoff)\r\n{\r\nif (pgoff >= msc->nr_pages)\r\nreturn NULL;\r\nreturn virt_to_page(msc->base + (pgoff << PAGE_SHIFT));\r\n}\r\nstatic int msc_buffer_win_alloc(struct msc *msc, unsigned int nr_blocks)\r\n{\r\nstruct msc_window *win;\r\nunsigned long size = PAGE_SIZE;\r\nint i, ret = -ENOMEM;\r\nif (!nr_blocks)\r\nreturn 0;\r\nwin = kzalloc(offsetof(struct msc_window, block[nr_blocks]),\r\nGFP_KERNEL);\r\nif (!win)\r\nreturn -ENOMEM;\r\nif (!list_empty(&msc->win_list)) {\r\nstruct msc_window *prev = list_entry(msc->win_list.prev,\r\nstruct msc_window, entry);\r\nwin->pgoff = prev->pgoff + prev->nr_blocks;\r\n}\r\nfor (i = 0; i < nr_blocks; i++) {\r\nwin->block[i].bdesc = dma_alloc_coherent(msc_dev(msc), size,\r\n&win->block[i].addr,\r\nGFP_KERNEL);\r\n#ifdef CONFIG_X86\r\nset_memory_uc((unsigned long)win->block[i].bdesc, 1);\r\n#endif\r\nif (!win->block[i].bdesc)\r\ngoto err_nomem;\r\n}\r\nwin->msc = msc;\r\nwin->nr_blocks = nr_blocks;\r\nif (list_empty(&msc->win_list)) {\r\nmsc->base = win->block[0].bdesc;\r\nmsc->base_addr = win->block[0].addr;\r\n}\r\nlist_add_tail(&win->entry, &msc->win_list);\r\nmsc->nr_pages += nr_blocks;\r\nreturn 0;\r\nerr_nomem:\r\nfor (i--; i >= 0; i--) {\r\n#ifdef CONFIG_X86\r\nset_memory_wb((unsigned long)win->block[i].bdesc, 1);\r\n#endif\r\ndma_free_coherent(msc_dev(msc), size, win->block[i].bdesc,\r\nwin->block[i].addr);\r\n}\r\nkfree(win);\r\nreturn ret;\r\n}\r\nstatic void msc_buffer_win_free(struct msc *msc, struct msc_window *win)\r\n{\r\nint i;\r\nmsc->nr_pages -= win->nr_blocks;\r\nlist_del(&win->entry);\r\nif (list_empty(&msc->win_list)) {\r\nmsc->base = NULL;\r\nmsc->base_addr = 0;\r\n}\r\nfor (i = 0; i < win->nr_blocks; i++) {\r\nstruct page *page = virt_to_page(win->block[i].bdesc);\r\npage->mapping = NULL;\r\n#ifdef CONFIG_X86\r\nset_memory_wb((unsigned long)win->block[i].bdesc, 1);\r\n#endif\r\ndma_free_coherent(msc_dev(win->msc), PAGE_SIZE,\r\nwin->block[i].bdesc, win->block[i].addr);\r\n}\r\nkfree(win);\r\n}\r\nstatic void msc_buffer_relink(struct msc *msc)\r\n{\r\nstruct msc_window *win, *next_win;\r\nlist_for_each_entry(win, &msc->win_list, entry) {\r\nunsigned int blk;\r\nu32 sw_tag = 0;\r\nif (msc_is_last_win(win)) {\r\nsw_tag |= MSC_SW_TAG_LASTWIN;\r\nnext_win = list_entry(msc->win_list.next,\r\nstruct msc_window, entry);\r\n} else {\r\nnext_win = list_entry(win->entry.next,\r\nstruct msc_window, entry);\r\n}\r\nfor (blk = 0; blk < win->nr_blocks; blk++) {\r\nstruct msc_block_desc *bdesc = win->block[blk].bdesc;\r\nmemset(bdesc, 0, sizeof(*bdesc));\r\nbdesc->next_win = next_win->block[0].addr >> PAGE_SHIFT;\r\nif (blk == win->nr_blocks - 1) {\r\nsw_tag |= MSC_SW_TAG_LASTBLK;\r\nbdesc->next_blk =\r\nwin->block[0].addr >> PAGE_SHIFT;\r\n} else {\r\nbdesc->next_blk =\r\nwin->block[blk + 1].addr >> PAGE_SHIFT;\r\n}\r\nbdesc->sw_tag = sw_tag;\r\nbdesc->block_sz = PAGE_SIZE / 64;\r\n}\r\n}\r\nwmb();\r\n}\r\nstatic void msc_buffer_multi_free(struct msc *msc)\r\n{\r\nstruct msc_window *win, *iter;\r\nlist_for_each_entry_safe(win, iter, &msc->win_list, entry)\r\nmsc_buffer_win_free(msc, win);\r\n}\r\nstatic int msc_buffer_multi_alloc(struct msc *msc, unsigned long *nr_pages,\r\nunsigned int nr_wins)\r\n{\r\nint ret, i;\r\nfor (i = 0; i < nr_wins; i++) {\r\nret = msc_buffer_win_alloc(msc, nr_pages[i]);\r\nif (ret) {\r\nmsc_buffer_multi_free(msc);\r\nreturn ret;\r\n}\r\n}\r\nmsc_buffer_relink(msc);\r\nreturn 0;\r\n}\r\nstatic void msc_buffer_free(struct msc *msc)\r\n{\r\nif (msc->mode == MSC_MODE_SINGLE)\r\nmsc_buffer_contig_free(msc);\r\nelse if (msc->mode == MSC_MODE_MULTI)\r\nmsc_buffer_multi_free(msc);\r\n}\r\nstatic int msc_buffer_alloc(struct msc *msc, unsigned long *nr_pages,\r\nunsigned int nr_wins)\r\n{\r\nint ret;\r\nif (atomic_read(&msc->user_count) != -1)\r\nreturn -EBUSY;\r\nif (msc->mode == MSC_MODE_SINGLE) {\r\nif (nr_wins != 1)\r\nreturn -EINVAL;\r\nret = msc_buffer_contig_alloc(msc, nr_pages[0] << PAGE_SHIFT);\r\n} else if (msc->mode == MSC_MODE_MULTI) {\r\nret = msc_buffer_multi_alloc(msc, nr_pages, nr_wins);\r\n} else {\r\nret = -ENOTSUPP;\r\n}\r\nif (!ret) {\r\nsmp_mb__before_atomic();\r\nif (WARN_ON_ONCE(atomic_cmpxchg(&msc->user_count, -1, 0) != -1))\r\nreturn -EINVAL;\r\n}\r\nreturn ret;\r\n}\r\nstatic int msc_buffer_unlocked_free_unless_used(struct msc *msc)\r\n{\r\nint count, ret = 0;\r\ncount = atomic_cmpxchg(&msc->user_count, 0, -1);\r\nif (count > 0)\r\nret = -EBUSY;\r\nelse if (!count)\r\nmsc_buffer_free(msc);\r\nreturn ret;\r\n}\r\nstatic int msc_buffer_free_unless_used(struct msc *msc)\r\n{\r\nint ret;\r\nmutex_lock(&msc->buf_mutex);\r\nret = msc_buffer_unlocked_free_unless_used(msc);\r\nmutex_unlock(&msc->buf_mutex);\r\nreturn ret;\r\n}\r\nstatic struct page *msc_buffer_get_page(struct msc *msc, unsigned long pgoff)\r\n{\r\nstruct msc_window *win;\r\nif (msc->mode == MSC_MODE_SINGLE)\r\nreturn msc_buffer_contig_get_page(msc, pgoff);\r\nlist_for_each_entry(win, &msc->win_list, entry)\r\nif (pgoff >= win->pgoff && pgoff < win->pgoff + win->nr_blocks)\r\ngoto found;\r\nreturn NULL;\r\nfound:\r\npgoff -= win->pgoff;\r\nreturn virt_to_page(win->block[pgoff].bdesc);\r\n}\r\nstatic unsigned long msc_win_to_user(void *data, void *src, size_t len)\r\n{\r\nstruct msc_win_to_user_struct *u = data;\r\nunsigned long ret;\r\nret = copy_to_user(u->buf + u->offset, src, len);\r\nu->offset += len - ret;\r\nreturn ret;\r\n}\r\nstatic int intel_th_msc_open(struct inode *inode, struct file *file)\r\n{\r\nstruct intel_th_device *thdev = file->private_data;\r\nstruct msc *msc = dev_get_drvdata(&thdev->dev);\r\nstruct msc_iter *iter;\r\nif (!capable(CAP_SYS_RAWIO))\r\nreturn -EPERM;\r\niter = msc_iter_install(msc);\r\nif (IS_ERR(iter))\r\nreturn PTR_ERR(iter);\r\nfile->private_data = iter;\r\nreturn nonseekable_open(inode, file);\r\n}\r\nstatic int intel_th_msc_release(struct inode *inode, struct file *file)\r\n{\r\nstruct msc_iter *iter = file->private_data;\r\nstruct msc *msc = iter->msc;\r\nmsc_iter_remove(iter, msc);\r\nreturn 0;\r\n}\r\nstatic ssize_t\r\nmsc_single_to_user(struct msc *msc, char __user *buf, loff_t off, size_t len)\r\n{\r\nunsigned long size = msc->nr_pages << PAGE_SHIFT, rem = len;\r\nunsigned long start = off, tocopy = 0;\r\nif (msc->single_wrap) {\r\nstart += msc->single_sz;\r\nif (start < size) {\r\ntocopy = min(rem, size - start);\r\nif (copy_to_user(buf, msc->base + start, tocopy))\r\nreturn -EFAULT;\r\nbuf += tocopy;\r\nrem -= tocopy;\r\nstart += tocopy;\r\n}\r\nstart &= size - 1;\r\nif (rem) {\r\ntocopy = min(rem, msc->single_sz - start);\r\nif (copy_to_user(buf, msc->base + start, tocopy))\r\nreturn -EFAULT;\r\nrem -= tocopy;\r\n}\r\nreturn len - rem;\r\n}\r\nif (copy_to_user(buf, msc->base + start, rem))\r\nreturn -EFAULT;\r\nreturn len;\r\n}\r\nstatic ssize_t intel_th_msc_read(struct file *file, char __user *buf,\r\nsize_t len, loff_t *ppos)\r\n{\r\nstruct msc_iter *iter = file->private_data;\r\nstruct msc *msc = iter->msc;\r\nsize_t size;\r\nloff_t off = *ppos;\r\nssize_t ret = 0;\r\nif (!atomic_inc_unless_negative(&msc->user_count))\r\nreturn 0;\r\nif (msc->mode == MSC_MODE_SINGLE && !msc->single_wrap)\r\nsize = msc->single_sz;\r\nelse\r\nsize = msc->nr_pages << PAGE_SHIFT;\r\nif (!size)\r\ngoto put_count;\r\nif (off >= size)\r\ngoto put_count;\r\nif (off + len >= size)\r\nlen = size - off;\r\nif (msc->mode == MSC_MODE_SINGLE) {\r\nret = msc_single_to_user(msc, buf, off, len);\r\nif (ret >= 0)\r\n*ppos += ret;\r\n} else if (msc->mode == MSC_MODE_MULTI) {\r\nstruct msc_win_to_user_struct u = {\r\n.buf = buf,\r\n.offset = 0,\r\n};\r\nret = msc_buffer_iterate(iter, len, &u, msc_win_to_user);\r\nif (ret >= 0)\r\n*ppos = iter->offset;\r\n} else {\r\nret = -ENOTSUPP;\r\n}\r\nput_count:\r\natomic_dec(&msc->user_count);\r\nreturn ret;\r\n}\r\nstatic void msc_mmap_open(struct vm_area_struct *vma)\r\n{\r\nstruct msc_iter *iter = vma->vm_file->private_data;\r\nstruct msc *msc = iter->msc;\r\natomic_inc(&msc->mmap_count);\r\n}\r\nstatic void msc_mmap_close(struct vm_area_struct *vma)\r\n{\r\nstruct msc_iter *iter = vma->vm_file->private_data;\r\nstruct msc *msc = iter->msc;\r\nunsigned long pg;\r\nif (!atomic_dec_and_mutex_lock(&msc->mmap_count, &msc->buf_mutex))\r\nreturn;\r\nfor (pg = 0; pg < msc->nr_pages; pg++) {\r\nstruct page *page = msc_buffer_get_page(msc, pg);\r\nif (WARN_ON_ONCE(!page))\r\ncontinue;\r\nif (page->mapping)\r\npage->mapping = NULL;\r\n}\r\natomic_dec(&msc->user_count);\r\nmutex_unlock(&msc->buf_mutex);\r\n}\r\nstatic int msc_mmap_fault(struct vm_area_struct *vma, struct vm_fault *vmf)\r\n{\r\nstruct msc_iter *iter = vma->vm_file->private_data;\r\nstruct msc *msc = iter->msc;\r\nvmf->page = msc_buffer_get_page(msc, vmf->pgoff);\r\nif (!vmf->page)\r\nreturn VM_FAULT_SIGBUS;\r\nget_page(vmf->page);\r\nvmf->page->mapping = vma->vm_file->f_mapping;\r\nvmf->page->index = vmf->pgoff;\r\nreturn 0;\r\n}\r\nstatic int intel_th_msc_mmap(struct file *file, struct vm_area_struct *vma)\r\n{\r\nunsigned long size = vma->vm_end - vma->vm_start;\r\nstruct msc_iter *iter = vma->vm_file->private_data;\r\nstruct msc *msc = iter->msc;\r\nint ret = -EINVAL;\r\nif (!size || offset_in_page(size))\r\nreturn -EINVAL;\r\nif (vma->vm_pgoff)\r\nreturn -EINVAL;\r\nif (!atomic_inc_unless_negative(&msc->user_count))\r\nreturn -EINVAL;\r\nif (msc->mode != MSC_MODE_SINGLE &&\r\nmsc->mode != MSC_MODE_MULTI)\r\ngoto out;\r\nif (size >> PAGE_SHIFT != msc->nr_pages)\r\ngoto out;\r\natomic_set(&msc->mmap_count, 1);\r\nret = 0;\r\nout:\r\nif (ret)\r\natomic_dec(&msc->user_count);\r\nvma->vm_page_prot = pgprot_noncached(vma->vm_page_prot);\r\nvma->vm_flags |= VM_DONTEXPAND | VM_DONTCOPY;\r\nvma->vm_ops = &msc_mmap_ops;\r\nreturn ret;\r\n}\r\nstatic int intel_th_msc_init(struct msc *msc)\r\n{\r\natomic_set(&msc->user_count, -1);\r\nmsc->mode = MSC_MODE_MULTI;\r\nmutex_init(&msc->buf_mutex);\r\nINIT_LIST_HEAD(&msc->win_list);\r\nINIT_LIST_HEAD(&msc->iter_list);\r\nmsc->burst_len =\r\n(ioread32(msc->reg_base + REG_MSU_MSC0CTL) & MSC_LEN) >>\r\n__ffs(MSC_LEN);\r\nreturn 0;\r\n}\r\nstatic ssize_t\r\nwrap_show(struct device *dev, struct device_attribute *attr, char *buf)\r\n{\r\nstruct msc *msc = dev_get_drvdata(dev);\r\nreturn scnprintf(buf, PAGE_SIZE, "%d\n", msc->wrap);\r\n}\r\nstatic ssize_t\r\nwrap_store(struct device *dev, struct device_attribute *attr, const char *buf,\r\nsize_t size)\r\n{\r\nstruct msc *msc = dev_get_drvdata(dev);\r\nunsigned long val;\r\nint ret;\r\nret = kstrtoul(buf, 10, &val);\r\nif (ret)\r\nreturn ret;\r\nmsc->wrap = !!val;\r\nreturn size;\r\n}\r\nstatic ssize_t\r\nmode_show(struct device *dev, struct device_attribute *attr, char *buf)\r\n{\r\nstruct msc *msc = dev_get_drvdata(dev);\r\nreturn scnprintf(buf, PAGE_SIZE, "%s\n", msc_mode[msc->mode]);\r\n}\r\nstatic ssize_t\r\nmode_store(struct device *dev, struct device_attribute *attr, const char *buf,\r\nsize_t size)\r\n{\r\nstruct msc *msc = dev_get_drvdata(dev);\r\nsize_t len = size;\r\nchar *cp;\r\nint i, ret;\r\nif (!capable(CAP_SYS_RAWIO))\r\nreturn -EPERM;\r\ncp = memchr(buf, '\n', len);\r\nif (cp)\r\nlen = cp - buf;\r\nfor (i = 0; i < ARRAY_SIZE(msc_mode); i++)\r\nif (!strncmp(msc_mode[i], buf, len))\r\ngoto found;\r\nreturn -EINVAL;\r\nfound:\r\nmutex_lock(&msc->buf_mutex);\r\nret = msc_buffer_unlocked_free_unless_used(msc);\r\nif (!ret)\r\nmsc->mode = i;\r\nmutex_unlock(&msc->buf_mutex);\r\nreturn ret ? ret : size;\r\n}\r\nstatic ssize_t\r\nnr_pages_show(struct device *dev, struct device_attribute *attr, char *buf)\r\n{\r\nstruct msc *msc = dev_get_drvdata(dev);\r\nstruct msc_window *win;\r\nsize_t count = 0;\r\nmutex_lock(&msc->buf_mutex);\r\nif (msc->mode == MSC_MODE_SINGLE)\r\ncount = scnprintf(buf, PAGE_SIZE, "%ld\n", msc->nr_pages);\r\nelse if (msc->mode == MSC_MODE_MULTI) {\r\nlist_for_each_entry(win, &msc->win_list, entry) {\r\ncount += scnprintf(buf + count, PAGE_SIZE - count,\r\n"%d%c", win->nr_blocks,\r\nmsc_is_last_win(win) ? '\n' : ',');\r\n}\r\n} else {\r\ncount = scnprintf(buf, PAGE_SIZE, "unsupported\n");\r\n}\r\nmutex_unlock(&msc->buf_mutex);\r\nreturn count;\r\n}\r\nstatic ssize_t\r\nnr_pages_store(struct device *dev, struct device_attribute *attr,\r\nconst char *buf, size_t size)\r\n{\r\nstruct msc *msc = dev_get_drvdata(dev);\r\nunsigned long val, *win = NULL, *rewin;\r\nsize_t len = size;\r\nconst char *p = buf;\r\nchar *end, *s;\r\nint ret, nr_wins = 0;\r\nif (!capable(CAP_SYS_RAWIO))\r\nreturn -EPERM;\r\nret = msc_buffer_free_unless_used(msc);\r\nif (ret)\r\nreturn ret;\r\nend = memchr(buf, '\n', len);\r\nif (end)\r\nlen = end - buf;\r\ndo {\r\nend = memchr(p, ',', len);\r\ns = kstrndup(p, end ? end - p : len, GFP_KERNEL);\r\nif (!s) {\r\nret = -ENOMEM;\r\ngoto free_win;\r\n}\r\nret = kstrtoul(s, 10, &val);\r\nkfree(s);\r\nif (ret || !val)\r\ngoto free_win;\r\nif (nr_wins && msc->mode == MSC_MODE_SINGLE) {\r\nret = -EINVAL;\r\ngoto free_win;\r\n}\r\nnr_wins++;\r\nrewin = krealloc(win, sizeof(*win) * nr_wins, GFP_KERNEL);\r\nif (!rewin) {\r\nkfree(win);\r\nreturn -ENOMEM;\r\n}\r\nwin = rewin;\r\nwin[nr_wins - 1] = val;\r\nif (!end)\r\nbreak;\r\nlen -= end - p;\r\np = end + 1;\r\n} while (len);\r\nmutex_lock(&msc->buf_mutex);\r\nret = msc_buffer_alloc(msc, win, nr_wins);\r\nmutex_unlock(&msc->buf_mutex);\r\nfree_win:\r\nkfree(win);\r\nreturn ret ? ret : size;\r\n}\r\nstatic int intel_th_msc_probe(struct intel_th_device *thdev)\r\n{\r\nstruct device *dev = &thdev->dev;\r\nstruct resource *res;\r\nstruct msc *msc;\r\nvoid __iomem *base;\r\nint err;\r\nres = intel_th_device_get_resource(thdev, IORESOURCE_MEM, 0);\r\nif (!res)\r\nreturn -ENODEV;\r\nbase = devm_ioremap(dev, res->start, resource_size(res));\r\nif (!base)\r\nreturn -ENOMEM;\r\nmsc = devm_kzalloc(dev, sizeof(*msc), GFP_KERNEL);\r\nif (!msc)\r\nreturn -ENOMEM;\r\nmsc->index = thdev->id;\r\nmsc->thdev = thdev;\r\nmsc->reg_base = base + msc->index * 0x100;\r\nerr = intel_th_msc_init(msc);\r\nif (err)\r\nreturn err;\r\ndev_set_drvdata(dev, msc);\r\nreturn 0;\r\n}\r\nstatic void intel_th_msc_remove(struct intel_th_device *thdev)\r\n{\r\nstruct msc *msc = dev_get_drvdata(&thdev->dev);\r\nint ret;\r\nintel_th_msc_deactivate(thdev);\r\nret = msc_buffer_free_unless_used(msc);\r\nWARN_ON_ONCE(ret);\r\n}
