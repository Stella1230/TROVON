static int __init xpa_disable(char *s)\r\n{\r\nmips_xpa_disabled = 1;\r\nreturn 1;\r\n}\r\nstatic inline int r45k_bvahwbug(void)\r\n{\r\nreturn 0;\r\n}\r\nstatic inline int r4k_250MHZhwbug(void)\r\n{\r\nreturn 0;\r\n}\r\nstatic inline int __maybe_unused bcm1250_m3_war(void)\r\n{\r\nreturn BCM1250_M3_WAR;\r\n}\r\nstatic inline int __maybe_unused r10000_llsc_war(void)\r\n{\r\nreturn R10000_LLSC_WAR;\r\n}\r\nstatic int use_bbit_insns(void)\r\n{\r\nswitch (current_cpu_type()) {\r\ncase CPU_CAVIUM_OCTEON:\r\ncase CPU_CAVIUM_OCTEON_PLUS:\r\ncase CPU_CAVIUM_OCTEON2:\r\ncase CPU_CAVIUM_OCTEON3:\r\nreturn 1;\r\ndefault:\r\nreturn 0;\r\n}\r\n}\r\nstatic int use_lwx_insns(void)\r\n{\r\nswitch (current_cpu_type()) {\r\ncase CPU_CAVIUM_OCTEON2:\r\ncase CPU_CAVIUM_OCTEON3:\r\nreturn 1;\r\ndefault:\r\nreturn 0;\r\n}\r\n}\r\nstatic bool scratchpad_available(void)\r\n{\r\nreturn true;\r\n}\r\nstatic int scratchpad_offset(int i)\r\n{\r\ni += 1;\r\nreturn CONFIG_CAVIUM_OCTEON_CVMSEG_SIZE * 128 - (8 * i) - 32768;\r\n}\r\nstatic bool scratchpad_available(void)\r\n{\r\nreturn false;\r\n}\r\nstatic int scratchpad_offset(int i)\r\n{\r\nBUG();\r\nreturn 0;\r\n}\r\nstatic int m4kc_tlbp_war(void)\r\n{\r\nreturn (current_cpu_data.processor_id & 0xffff00) ==\r\n(PRID_COMP_MIPS | PRID_IMP_4KC);\r\n}\r\nstatic void uasm_bgezl_hazard(u32 **p, struct uasm_reloc **r, int instance)\r\n{\r\nswitch (instance) {\r\ncase 0 ... 7:\r\nuasm_il_bgezl(p, r, 0, label_tlbw_hazard_0 + instance);\r\nreturn;\r\ndefault:\r\nBUG();\r\n}\r\n}\r\nstatic void uasm_bgezl_label(struct uasm_label **l, u32 **p, int instance)\r\n{\r\nswitch (instance) {\r\ncase 0 ... 7:\r\nuasm_build_label(l, *p, label_tlbw_hazard_0 + instance);\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\n}\r\nstatic void output_pgtable_bits_defines(void)\r\n{\r\n#define pr_define(fmt, ...) \\r\npr_debug("#define " fmt, ##__VA_ARGS__)\r\npr_debug("#include <asm/asm.h>\n");\r\npr_debug("#include <asm/regdef.h>\n");\r\npr_debug("\n");\r\npr_define("_PAGE_PRESENT_SHIFT %d\n", _PAGE_PRESENT_SHIFT);\r\npr_define("_PAGE_NO_READ_SHIFT %d\n", _PAGE_NO_READ_SHIFT);\r\npr_define("_PAGE_WRITE_SHIFT %d\n", _PAGE_WRITE_SHIFT);\r\npr_define("_PAGE_ACCESSED_SHIFT %d\n", _PAGE_ACCESSED_SHIFT);\r\npr_define("_PAGE_MODIFIED_SHIFT %d\n", _PAGE_MODIFIED_SHIFT);\r\n#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT\r\npr_define("_PAGE_HUGE_SHIFT %d\n", _PAGE_HUGE_SHIFT);\r\n#endif\r\n#ifdef _PAGE_NO_EXEC_SHIFT\r\nif (cpu_has_rixi)\r\npr_define("_PAGE_NO_EXEC_SHIFT %d\n", _PAGE_NO_EXEC_SHIFT);\r\n#endif\r\npr_define("_PAGE_GLOBAL_SHIFT %d\n", _PAGE_GLOBAL_SHIFT);\r\npr_define("_PAGE_VALID_SHIFT %d\n", _PAGE_VALID_SHIFT);\r\npr_define("_PAGE_DIRTY_SHIFT %d\n", _PAGE_DIRTY_SHIFT);\r\npr_define("_PFN_SHIFT %d\n", _PFN_SHIFT);\r\npr_debug("\n");\r\n}\r\nstatic inline void dump_handler(const char *symbol, const u32 *handler, int count)\r\n{\r\nint i;\r\npr_debug("LEAF(%s)\n", symbol);\r\npr_debug("\t.set push\n");\r\npr_debug("\t.set noreorder\n");\r\nfor (i = 0; i < count; i++)\r\npr_debug("\t.word\t0x%08x\t\t# %p\n", handler[i], &handler[i]);\r\npr_debug("\t.set\tpop\n");\r\npr_debug("\tEND(%s)\n", symbol);\r\n}\r\nstatic inline int __maybe_unused c0_kscratch(void)\r\n{\r\nswitch (current_cpu_type()) {\r\ncase CPU_XLP:\r\ncase CPU_XLR:\r\nreturn 22;\r\ndefault:\r\nreturn 31;\r\n}\r\n}\r\nstatic int allocate_kscratch(void)\r\n{\r\nint r;\r\nunsigned int a = cpu_data[0].kscratch_mask & ~kscratch_used_mask;\r\nr = ffs(a);\r\nif (r == 0)\r\nreturn -1;\r\nr--;\r\nkscratch_used_mask |= (1 << r);\r\nreturn r;\r\n}\r\nstatic struct work_registers build_get_work_registers(u32 **p)\r\n{\r\nstruct work_registers r;\r\nif (scratch_reg >= 0) {\r\nUASM_i_MTC0(p, 1, c0_kscratch(), scratch_reg);\r\nr.r1 = K0;\r\nr.r2 = K1;\r\nr.r3 = 1;\r\nreturn r;\r\n}\r\nif (num_possible_cpus() > 1) {\r\nUASM_i_CPUID_MFC0(p, K0, SMP_CPUID_REG);\r\nUASM_i_SRL_SAFE(p, K0, K0, SMP_CPUID_REGSHIFT);\r\nUASM_i_SLL(p, K0, K0, ilog2(sizeof(struct tlb_reg_save)));\r\nUASM_i_LA(p, K1, (long)&handler_reg_save);\r\nUASM_i_ADDU(p, K0, K0, K1);\r\n} else {\r\nUASM_i_LA(p, K0, (long)&handler_reg_save);\r\n}\r\nUASM_i_SW(p, 1, offsetof(struct tlb_reg_save, a), K0);\r\nUASM_i_SW(p, 2, offsetof(struct tlb_reg_save, b), K0);\r\nr.r1 = K1;\r\nr.r2 = 1;\r\nr.r3 = 2;\r\nreturn r;\r\n}\r\nstatic void build_restore_work_registers(u32 **p)\r\n{\r\nif (scratch_reg >= 0) {\r\nUASM_i_MFC0(p, 1, c0_kscratch(), scratch_reg);\r\nreturn;\r\n}\r\nUASM_i_LW(p, 1, offsetof(struct tlb_reg_save, a), K0);\r\nUASM_i_LW(p, 2, offsetof(struct tlb_reg_save, b), K0);\r\n}\r\nstatic void build_r3000_tlb_refill_handler(void)\r\n{\r\nlong pgdc = (long)pgd_current;\r\nu32 *p;\r\nmemset(tlb_handler, 0, sizeof(tlb_handler));\r\np = tlb_handler;\r\nuasm_i_mfc0(&p, K0, C0_BADVADDR);\r\nuasm_i_lui(&p, K1, uasm_rel_hi(pgdc));\r\nuasm_i_lw(&p, K1, uasm_rel_lo(pgdc), K1);\r\nuasm_i_srl(&p, K0, K0, 22);\r\nuasm_i_sll(&p, K0, K0, 2);\r\nuasm_i_addu(&p, K1, K1, K0);\r\nuasm_i_mfc0(&p, K0, C0_CONTEXT);\r\nuasm_i_lw(&p, K1, 0, K1);\r\nuasm_i_andi(&p, K0, K0, 0xffc);\r\nuasm_i_addu(&p, K1, K1, K0);\r\nuasm_i_lw(&p, K0, 0, K1);\r\nuasm_i_nop(&p);\r\nuasm_i_mtc0(&p, K0, C0_ENTRYLO0);\r\nuasm_i_mfc0(&p, K1, C0_EPC);\r\nuasm_i_tlbwr(&p);\r\nuasm_i_jr(&p, K1);\r\nuasm_i_rfe(&p);\r\nif (p > tlb_handler + 32)\r\npanic("TLB refill handler space exceeded");\r\npr_debug("Wrote TLB refill handler (%u instructions).\n",\r\n(unsigned int)(p - tlb_handler));\r\nmemcpy((void *)ebase, tlb_handler, 0x80);\r\nlocal_flush_icache_range(ebase, ebase + 0x80);\r\ndump_handler("r3000_tlb_refill", (u32 *)ebase, 32);\r\n}\r\nstatic void __maybe_unused build_tlb_probe_entry(u32 **p)\r\n{\r\nswitch (current_cpu_type()) {\r\ncase CPU_R4600:\r\ncase CPU_R4700:\r\ncase CPU_R5000:\r\ncase CPU_NEVADA:\r\nuasm_i_nop(p);\r\nuasm_i_tlbp(p);\r\nbreak;\r\ndefault:\r\nuasm_i_tlbp(p);\r\nbreak;\r\n}\r\n}\r\nstatic void build_tlb_write_entry(u32 **p, struct uasm_label **l,\r\nstruct uasm_reloc **r,\r\nenum tlb_write_entry wmode)\r\n{\r\nvoid(*tlbw)(u32 **) = NULL;\r\nswitch (wmode) {\r\ncase tlb_random: tlbw = uasm_i_tlbwr; break;\r\ncase tlb_indexed: tlbw = uasm_i_tlbwi; break;\r\n}\r\nif (cpu_has_mips_r2_r6) {\r\nif (cpu_has_mips_r2_exec_hazard)\r\nuasm_i_ehb(p);\r\ntlbw(p);\r\nreturn;\r\n}\r\nswitch (current_cpu_type()) {\r\ncase CPU_R4000PC:\r\ncase CPU_R4000SC:\r\ncase CPU_R4000MC:\r\ncase CPU_R4400PC:\r\ncase CPU_R4400SC:\r\ncase CPU_R4400MC:\r\nuasm_bgezl_hazard(p, r, hazard_instance);\r\ntlbw(p);\r\nuasm_bgezl_label(l, p, hazard_instance);\r\nhazard_instance++;\r\nuasm_i_nop(p);\r\nbreak;\r\ncase CPU_R4600:\r\ncase CPU_R4700:\r\nuasm_i_nop(p);\r\ntlbw(p);\r\nuasm_i_nop(p);\r\nbreak;\r\ncase CPU_R5000:\r\ncase CPU_NEVADA:\r\nuasm_i_nop(p);\r\nuasm_i_nop(p);\r\ntlbw(p);\r\nbreak;\r\ncase CPU_R4300:\r\ncase CPU_5KC:\r\ncase CPU_TX49XX:\r\ncase CPU_PR4450:\r\ncase CPU_XLR:\r\nuasm_i_nop(p);\r\ntlbw(p);\r\nbreak;\r\ncase CPU_R10000:\r\ncase CPU_R12000:\r\ncase CPU_R14000:\r\ncase CPU_R16000:\r\ncase CPU_4KC:\r\ncase CPU_4KEC:\r\ncase CPU_M14KC:\r\ncase CPU_M14KEC:\r\ncase CPU_SB1:\r\ncase CPU_SB1A:\r\ncase CPU_4KSC:\r\ncase CPU_20KC:\r\ncase CPU_25KF:\r\ncase CPU_BMIPS32:\r\ncase CPU_BMIPS3300:\r\ncase CPU_BMIPS4350:\r\ncase CPU_BMIPS4380:\r\ncase CPU_BMIPS5000:\r\ncase CPU_LOONGSON2:\r\ncase CPU_LOONGSON3:\r\ncase CPU_R5500:\r\nif (m4kc_tlbp_war())\r\nuasm_i_nop(p);\r\ncase CPU_ALCHEMY:\r\ntlbw(p);\r\nbreak;\r\ncase CPU_RM7000:\r\nuasm_i_nop(p);\r\nuasm_i_nop(p);\r\nuasm_i_nop(p);\r\nuasm_i_nop(p);\r\ntlbw(p);\r\nbreak;\r\ncase CPU_VR4111:\r\ncase CPU_VR4121:\r\ncase CPU_VR4122:\r\ncase CPU_VR4181:\r\ncase CPU_VR4181A:\r\nuasm_i_nop(p);\r\nuasm_i_nop(p);\r\ntlbw(p);\r\nuasm_i_nop(p);\r\nuasm_i_nop(p);\r\nbreak;\r\ncase CPU_VR4131:\r\ncase CPU_VR4133:\r\ncase CPU_R5432:\r\nuasm_i_nop(p);\r\nuasm_i_nop(p);\r\ntlbw(p);\r\nbreak;\r\ncase CPU_JZRISC:\r\ntlbw(p);\r\nuasm_i_nop(p);\r\nbreak;\r\ndefault:\r\npanic("No TLB refill handler yet (CPU type: %d)",\r\ncurrent_cpu_type());\r\nbreak;\r\n}\r\n}\r\nstatic __maybe_unused void build_convert_pte_to_entrylo(u32 **p,\r\nunsigned int reg)\r\n{\r\nif (_PAGE_GLOBAL_SHIFT == 0) {\r\nreturn;\r\n}\r\nif (cpu_has_rixi && _PAGE_NO_EXEC) {\r\nif (fill_includes_sw_bits) {\r\nUASM_i_ROTR(p, reg, reg, ilog2(_PAGE_GLOBAL));\r\n} else {\r\nUASM_i_SRL(p, reg, reg, ilog2(_PAGE_NO_EXEC));\r\nUASM_i_ROTR(p, reg, reg,\r\nilog2(_PAGE_GLOBAL) - ilog2(_PAGE_NO_EXEC));\r\n}\r\n} else {\r\n#ifdef CONFIG_PHYS_ADDR_T_64BIT\r\nuasm_i_dsrl_safe(p, reg, reg, ilog2(_PAGE_GLOBAL));\r\n#else\r\nUASM_i_SRL(p, reg, reg, ilog2(_PAGE_GLOBAL));\r\n#endif\r\n}\r\n}\r\nstatic void build_restore_pagemask(u32 **p, struct uasm_reloc **r,\r\nunsigned int tmp, enum label_id lid,\r\nint restore_scratch)\r\n{\r\nif (restore_scratch) {\r\nif (PM_DEFAULT_MASK >> 16) {\r\nuasm_i_lui(p, tmp, PM_DEFAULT_MASK >> 16);\r\nuasm_i_ori(p, tmp, tmp, PM_DEFAULT_MASK & 0xffff);\r\nuasm_i_mtc0(p, tmp, C0_PAGEMASK);\r\nuasm_il_b(p, r, lid);\r\n} else if (PM_DEFAULT_MASK) {\r\nuasm_i_ori(p, tmp, 0, PM_DEFAULT_MASK);\r\nuasm_i_mtc0(p, tmp, C0_PAGEMASK);\r\nuasm_il_b(p, r, lid);\r\n} else {\r\nuasm_i_mtc0(p, 0, C0_PAGEMASK);\r\nuasm_il_b(p, r, lid);\r\n}\r\nif (scratch_reg >= 0)\r\nUASM_i_MFC0(p, 1, c0_kscratch(), scratch_reg);\r\nelse\r\nUASM_i_LW(p, 1, scratchpad_offset(0), 0);\r\n} else {\r\nif (PM_DEFAULT_MASK >> 16) {\r\nuasm_i_lui(p, tmp, PM_DEFAULT_MASK >> 16);\r\nuasm_i_ori(p, tmp, tmp, PM_DEFAULT_MASK & 0xffff);\r\nuasm_il_b(p, r, lid);\r\nuasm_i_mtc0(p, tmp, C0_PAGEMASK);\r\n} else if (PM_DEFAULT_MASK) {\r\nuasm_i_ori(p, tmp, 0, PM_DEFAULT_MASK);\r\nuasm_il_b(p, r, lid);\r\nuasm_i_mtc0(p, tmp, C0_PAGEMASK);\r\n} else {\r\nuasm_il_b(p, r, lid);\r\nuasm_i_mtc0(p, 0, C0_PAGEMASK);\r\n}\r\n}\r\n}\r\nstatic void build_huge_tlb_write_entry(u32 **p, struct uasm_label **l,\r\nstruct uasm_reloc **r,\r\nunsigned int tmp,\r\nenum tlb_write_entry wmode,\r\nint restore_scratch)\r\n{\r\nuasm_i_lui(p, tmp, PM_HUGE_MASK >> 16);\r\nuasm_i_ori(p, tmp, tmp, PM_HUGE_MASK & 0xffff);\r\nuasm_i_mtc0(p, tmp, C0_PAGEMASK);\r\nbuild_tlb_write_entry(p, l, r, wmode);\r\nbuild_restore_pagemask(p, r, tmp, label_leave, restore_scratch);\r\n}\r\nstatic void\r\nbuild_is_huge_pte(u32 **p, struct uasm_reloc **r, unsigned int tmp,\r\nunsigned int pmd, int lid)\r\n{\r\nUASM_i_LW(p, tmp, 0, pmd);\r\nif (use_bbit_insns()) {\r\nuasm_il_bbit1(p, r, tmp, ilog2(_PAGE_HUGE), lid);\r\n} else {\r\nuasm_i_andi(p, tmp, tmp, _PAGE_HUGE);\r\nuasm_il_bnez(p, r, tmp, lid);\r\n}\r\n}\r\nstatic void build_huge_update_entries(u32 **p, unsigned int pte,\r\nunsigned int tmp)\r\n{\r\nint small_sequence;\r\nsmall_sequence = (HPAGE_SIZE >> 7) < 0x10000;\r\nif (!small_sequence)\r\nuasm_i_lui(p, tmp, HPAGE_SIZE >> (7 + 16));\r\nbuild_convert_pte_to_entrylo(p, pte);\r\nUASM_i_MTC0(p, pte, C0_ENTRYLO0);\r\nif (small_sequence)\r\nUASM_i_ADDIU(p, pte, pte, HPAGE_SIZE >> 7);\r\nelse\r\nUASM_i_ADDU(p, pte, pte, tmp);\r\nUASM_i_MTC0(p, pte, C0_ENTRYLO1);\r\n}\r\nstatic void build_huge_handler_tail(u32 **p, struct uasm_reloc **r,\r\nstruct uasm_label **l,\r\nunsigned int pte,\r\nunsigned int ptr)\r\n{\r\n#ifdef CONFIG_SMP\r\nUASM_i_SC(p, pte, 0, ptr);\r\nuasm_il_beqz(p, r, pte, label_tlb_huge_update);\r\nUASM_i_LW(p, pte, 0, ptr);\r\n#else\r\nUASM_i_SW(p, pte, 0, ptr);\r\n#endif\r\nbuild_huge_update_entries(p, pte, ptr);\r\nbuild_huge_tlb_write_entry(p, l, r, pte, tlb_indexed, 0);\r\n}\r\nstatic void\r\nbuild_get_pmde64(u32 **p, struct uasm_label **l, struct uasm_reloc **r,\r\nunsigned int tmp, unsigned int ptr)\r\n{\r\n#ifndef CONFIG_MIPS_PGD_C0_CONTEXT\r\nlong pgdc = (long)pgd_current;\r\n#endif\r\nuasm_i_dmfc0(p, tmp, C0_BADVADDR);\r\nif (check_for_high_segbits) {\r\nuasm_i_dsrl_safe(p, ptr, tmp, PGDIR_SHIFT + PGD_ORDER + PAGE_SHIFT - 3);\r\nuasm_il_bnez(p, r, ptr, label_vmalloc);\r\n} else {\r\nuasm_il_bltz(p, r, tmp, label_vmalloc);\r\n}\r\nif (pgd_reg != -1) {\r\nif (cpu_has_ldpte)\r\nUASM_i_MFC0(p, ptr, C0_PWBASE);\r\nelse\r\nUASM_i_MFC0(p, ptr, c0_kscratch(), pgd_reg);\r\n} else {\r\n#if defined(CONFIG_MIPS_PGD_C0_CONTEXT)\r\nUASM_i_MFC0(p, ptr, C0_CONTEXT);\r\nuasm_i_dins(p, ptr, 0, 0, 23);\r\nuasm_i_ori(p, ptr, ptr, 0x540);\r\nuasm_i_drotr(p, ptr, ptr, 11);\r\n#elif defined(CONFIG_SMP)\r\nUASM_i_CPUID_MFC0(p, ptr, SMP_CPUID_REG);\r\nuasm_i_dsrl_safe(p, ptr, ptr, SMP_CPUID_PTRSHIFT);\r\nUASM_i_LA_mostly(p, tmp, pgdc);\r\nuasm_i_daddu(p, ptr, ptr, tmp);\r\nuasm_i_dmfc0(p, tmp, C0_BADVADDR);\r\nuasm_i_ld(p, ptr, uasm_rel_lo(pgdc), ptr);\r\n#else\r\nUASM_i_LA_mostly(p, ptr, pgdc);\r\nuasm_i_ld(p, ptr, uasm_rel_lo(pgdc), ptr);\r\n#endif\r\n}\r\nuasm_l_vmalloc_done(l, *p);\r\nuasm_i_dsrl_safe(p, tmp, tmp, PGDIR_SHIFT - 3);\r\nuasm_i_andi(p, tmp, tmp, (PTRS_PER_PGD - 1)<<3);\r\nuasm_i_daddu(p, ptr, ptr, tmp);\r\n#ifndef __PAGETABLE_PMD_FOLDED\r\nuasm_i_dmfc0(p, tmp, C0_BADVADDR);\r\nuasm_i_ld(p, ptr, 0, ptr);\r\nuasm_i_dsrl_safe(p, tmp, tmp, PMD_SHIFT-3);\r\nuasm_i_andi(p, tmp, tmp, (PTRS_PER_PMD - 1)<<3);\r\nuasm_i_daddu(p, ptr, ptr, tmp);\r\n#endif\r\n}\r\nstatic void\r\nbuild_get_pgd_vmalloc64(u32 **p, struct uasm_label **l, struct uasm_reloc **r,\r\nunsigned int bvaddr, unsigned int ptr,\r\nenum vmalloc64_mode mode)\r\n{\r\nlong swpd = (long)swapper_pg_dir;\r\nint single_insn_swpd;\r\nint did_vmalloc_branch = 0;\r\nsingle_insn_swpd = uasm_in_compat_space_p(swpd) && !uasm_rel_lo(swpd);\r\nuasm_l_vmalloc(l, *p);\r\nif (mode != not_refill && check_for_high_segbits) {\r\nif (single_insn_swpd) {\r\nuasm_il_bltz(p, r, bvaddr, label_vmalloc_done);\r\nuasm_i_lui(p, ptr, uasm_rel_hi(swpd));\r\ndid_vmalloc_branch = 1;\r\n} else {\r\nuasm_il_bgez(p, r, bvaddr, label_large_segbits_fault);\r\n}\r\n}\r\nif (!did_vmalloc_branch) {\r\nif (single_insn_swpd) {\r\nuasm_il_b(p, r, label_vmalloc_done);\r\nuasm_i_lui(p, ptr, uasm_rel_hi(swpd));\r\n} else {\r\nUASM_i_LA_mostly(p, ptr, swpd);\r\nuasm_il_b(p, r, label_vmalloc_done);\r\nif (uasm_in_compat_space_p(swpd))\r\nuasm_i_addiu(p, ptr, ptr, uasm_rel_lo(swpd));\r\nelse\r\nuasm_i_daddiu(p, ptr, ptr, uasm_rel_lo(swpd));\r\n}\r\n}\r\nif (mode != not_refill && check_for_high_segbits) {\r\nuasm_l_large_segbits_fault(l, *p);\r\nUASM_i_LA(p, ptr, (unsigned long)tlb_do_page_fault_0);\r\nuasm_i_jr(p, ptr);\r\nif (mode == refill_scratch) {\r\nif (scratch_reg >= 0)\r\nUASM_i_MFC0(p, 1, c0_kscratch(), scratch_reg);\r\nelse\r\nUASM_i_LW(p, 1, scratchpad_offset(0), 0);\r\n} else {\r\nuasm_i_nop(p);\r\n}\r\n}\r\n}\r\nstatic void __maybe_unused\r\nbuild_get_pgde32(u32 **p, unsigned int tmp, unsigned int ptr)\r\n{\r\nif (pgd_reg != -1) {\r\nuasm_i_mfc0(p, ptr, c0_kscratch(), pgd_reg);\r\nuasm_i_mfc0(p, tmp, C0_BADVADDR);\r\n} else {\r\nlong pgdc = (long)pgd_current;\r\n#ifdef CONFIG_SMP\r\nuasm_i_mfc0(p, ptr, SMP_CPUID_REG);\r\nUASM_i_LA_mostly(p, tmp, pgdc);\r\nuasm_i_srl(p, ptr, ptr, SMP_CPUID_PTRSHIFT);\r\nuasm_i_addu(p, ptr, tmp, ptr);\r\n#else\r\nUASM_i_LA_mostly(p, ptr, pgdc);\r\n#endif\r\nuasm_i_mfc0(p, tmp, C0_BADVADDR);\r\nuasm_i_lw(p, ptr, uasm_rel_lo(pgdc), ptr);\r\n}\r\nuasm_i_srl(p, tmp, tmp, PGDIR_SHIFT);\r\nuasm_i_sll(p, tmp, tmp, PGD_T_LOG2);\r\nuasm_i_addu(p, ptr, ptr, tmp);\r\n}\r\nstatic void build_adjust_context(u32 **p, unsigned int ctx)\r\n{\r\nunsigned int shift = 4 - (PTE_T_LOG2 + 1) + PAGE_SHIFT - 12;\r\nunsigned int mask = (PTRS_PER_PTE / 2 - 1) << (PTE_T_LOG2 + 1);\r\nswitch (current_cpu_type()) {\r\ncase CPU_VR41XX:\r\ncase CPU_VR4111:\r\ncase CPU_VR4121:\r\ncase CPU_VR4122:\r\ncase CPU_VR4131:\r\ncase CPU_VR4181:\r\ncase CPU_VR4181A:\r\ncase CPU_VR4133:\r\nshift += 2;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nif (shift)\r\nUASM_i_SRL(p, ctx, ctx, shift);\r\nuasm_i_andi(p, ctx, ctx, mask);\r\n}\r\nstatic void build_get_ptep(u32 **p, unsigned int tmp, unsigned int ptr)\r\n{\r\nswitch (current_cpu_type()) {\r\ncase CPU_NEVADA:\r\nUASM_i_LW(p, ptr, 0, ptr);\r\nGET_CONTEXT(p, tmp);\r\nbreak;\r\ndefault:\r\nGET_CONTEXT(p, tmp);\r\nUASM_i_LW(p, ptr, 0, ptr);\r\nbreak;\r\n}\r\nbuild_adjust_context(p, tmp);\r\nUASM_i_ADDU(p, ptr, ptr, tmp);\r\n}\r\nstatic void build_update_entries(u32 **p, unsigned int tmp, unsigned int ptep)\r\n{\r\nint pte_off_even = 0;\r\nint pte_off_odd = sizeof(pte_t);\r\n#if defined(CONFIG_CPU_MIPS32) && defined(CONFIG_PHYS_ADDR_T_64BIT)\r\npte_off_even += offsetof(pte_t, pte_high);\r\npte_off_odd += offsetof(pte_t, pte_high);\r\n#endif\r\nif (IS_ENABLED(CONFIG_XPA)) {\r\nuasm_i_lw(p, tmp, pte_off_even, ptep);\r\nUASM_i_ROTR(p, tmp, tmp, ilog2(_PAGE_GLOBAL));\r\nUASM_i_MTC0(p, tmp, C0_ENTRYLO0);\r\nif (cpu_has_xpa && !mips_xpa_disabled) {\r\nuasm_i_lw(p, tmp, 0, ptep);\r\nuasm_i_ext(p, tmp, tmp, 0, 24);\r\nuasm_i_mthc0(p, tmp, C0_ENTRYLO0);\r\n}\r\nuasm_i_lw(p, tmp, pte_off_odd, ptep);\r\nUASM_i_ROTR(p, tmp, tmp, ilog2(_PAGE_GLOBAL));\r\nUASM_i_MTC0(p, tmp, C0_ENTRYLO1);\r\nif (cpu_has_xpa && !mips_xpa_disabled) {\r\nuasm_i_lw(p, tmp, sizeof(pte_t), ptep);\r\nuasm_i_ext(p, tmp, tmp, 0, 24);\r\nuasm_i_mthc0(p, tmp, C0_ENTRYLO1);\r\n}\r\nreturn;\r\n}\r\nUASM_i_LW(p, tmp, pte_off_even, ptep);\r\nUASM_i_LW(p, ptep, pte_off_odd, ptep);\r\nif (r45k_bvahwbug())\r\nbuild_tlb_probe_entry(p);\r\nbuild_convert_pte_to_entrylo(p, tmp);\r\nif (r4k_250MHZhwbug())\r\nUASM_i_MTC0(p, 0, C0_ENTRYLO0);\r\nUASM_i_MTC0(p, tmp, C0_ENTRYLO0);\r\nbuild_convert_pte_to_entrylo(p, ptep);\r\nif (r45k_bvahwbug())\r\nuasm_i_mfc0(p, tmp, C0_INDEX);\r\nif (r4k_250MHZhwbug())\r\nUASM_i_MTC0(p, 0, C0_ENTRYLO1);\r\nUASM_i_MTC0(p, ptep, C0_ENTRYLO1);\r\n}\r\nstatic struct mips_huge_tlb_info\r\nbuild_fast_tlb_refill_handler (u32 **p, struct uasm_label **l,\r\nstruct uasm_reloc **r, unsigned int tmp,\r\nunsigned int ptr, int c0_scratch_reg)\r\n{\r\nstruct mips_huge_tlb_info rv;\r\nunsigned int even, odd;\r\nint vmalloc_branch_delay_filled = 0;\r\nconst int scratch = 1;\r\nrv.huge_pte = scratch;\r\nrv.restore_scratch = 0;\r\nrv.need_reload_pte = false;\r\nif (check_for_high_segbits) {\r\nUASM_i_MFC0(p, tmp, C0_BADVADDR);\r\nif (pgd_reg != -1)\r\nUASM_i_MFC0(p, ptr, c0_kscratch(), pgd_reg);\r\nelse\r\nUASM_i_MFC0(p, ptr, C0_CONTEXT);\r\nif (c0_scratch_reg >= 0)\r\nUASM_i_MTC0(p, scratch, c0_kscratch(), c0_scratch_reg);\r\nelse\r\nUASM_i_SW(p, scratch, scratchpad_offset(0), 0);\r\nuasm_i_dsrl_safe(p, scratch, tmp,\r\nPGDIR_SHIFT + PGD_ORDER + PAGE_SHIFT - 3);\r\nuasm_il_bnez(p, r, scratch, label_vmalloc);\r\nif (pgd_reg == -1) {\r\nvmalloc_branch_delay_filled = 1;\r\nuasm_i_dins(p, ptr, 0, 0, 23);\r\n}\r\n} else {\r\nif (pgd_reg != -1)\r\nUASM_i_MFC0(p, ptr, c0_kscratch(), pgd_reg);\r\nelse\r\nUASM_i_MFC0(p, ptr, C0_CONTEXT);\r\nUASM_i_MFC0(p, tmp, C0_BADVADDR);\r\nif (c0_scratch_reg >= 0)\r\nUASM_i_MTC0(p, scratch, c0_kscratch(), c0_scratch_reg);\r\nelse\r\nUASM_i_SW(p, scratch, scratchpad_offset(0), 0);\r\nif (pgd_reg == -1)\r\nuasm_i_dins(p, ptr, 0, 0, 23);\r\nuasm_il_bltz(p, r, tmp, label_vmalloc);\r\n}\r\nif (pgd_reg == -1) {\r\nvmalloc_branch_delay_filled = 1;\r\nuasm_i_ori(p, ptr, ptr, 0x540);\r\nuasm_i_drotr(p, ptr, ptr, 11);\r\n}\r\n#ifdef __PAGETABLE_PMD_FOLDED\r\n#define LOC_PTEP scratch\r\n#else\r\n#define LOC_PTEP ptr\r\n#endif\r\nif (!vmalloc_branch_delay_filled)\r\nuasm_i_dsrl_safe(p, scratch, tmp, PGDIR_SHIFT - 3);\r\nuasm_l_vmalloc_done(l, *p);\r\nif (vmalloc_branch_delay_filled)\r\nuasm_i_dsrl_safe(p, scratch, tmp, PGDIR_SHIFT - 3);\r\n#ifdef __PAGETABLE_PMD_FOLDED\r\nGET_CONTEXT(p, tmp);\r\n#endif\r\nuasm_i_andi(p, scratch, scratch, (PTRS_PER_PGD - 1) << 3);\r\nif (use_lwx_insns()) {\r\nUASM_i_LWX(p, LOC_PTEP, scratch, ptr);\r\n} else {\r\nuasm_i_daddu(p, ptr, ptr, scratch);\r\nuasm_i_ld(p, LOC_PTEP, 0, ptr);\r\n}\r\n#ifndef __PAGETABLE_PMD_FOLDED\r\nuasm_i_dsrl_safe(p, scratch, tmp, PMD_SHIFT - 3);\r\nuasm_i_andi(p, scratch, scratch, (PTRS_PER_PMD - 1) << 3);\r\nGET_CONTEXT(p, tmp);\r\nif (use_lwx_insns()) {\r\nUASM_i_LWX(p, scratch, scratch, ptr);\r\n} else {\r\nuasm_i_daddu(p, ptr, ptr, scratch);\r\nUASM_i_LW(p, scratch, 0, ptr);\r\n}\r\n#endif\r\nbuild_adjust_context(p, tmp);\r\n#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT\r\nuasm_il_bbit1(p, r, scratch, ilog2(_PAGE_HUGE), label_tlb_huge_update);\r\nif (use_lwx_insns())\r\nuasm_i_nop(p);\r\n#endif\r\nif (use_lwx_insns()) {\r\neven = ptr;\r\nodd = tmp;\r\nUASM_i_LWX(p, even, scratch, tmp);\r\nUASM_i_ADDIU(p, tmp, tmp, sizeof(pte_t));\r\nUASM_i_LWX(p, odd, scratch, tmp);\r\n} else {\r\nUASM_i_ADDU(p, ptr, scratch, tmp);\r\neven = tmp;\r\nodd = ptr;\r\nUASM_i_LW(p, even, 0, ptr);\r\nUASM_i_LW(p, odd, sizeof(pte_t), ptr);\r\n}\r\nif (cpu_has_rixi) {\r\nuasm_i_drotr(p, even, even, ilog2(_PAGE_GLOBAL));\r\nUASM_i_MTC0(p, even, C0_ENTRYLO0);\r\nuasm_i_drotr(p, odd, odd, ilog2(_PAGE_GLOBAL));\r\n} else {\r\nuasm_i_dsrl_safe(p, even, even, ilog2(_PAGE_GLOBAL));\r\nUASM_i_MTC0(p, even, C0_ENTRYLO0);\r\nuasm_i_dsrl_safe(p, odd, odd, ilog2(_PAGE_GLOBAL));\r\n}\r\nUASM_i_MTC0(p, odd, C0_ENTRYLO1);\r\nif (c0_scratch_reg >= 0) {\r\nUASM_i_MFC0(p, scratch, c0_kscratch(), c0_scratch_reg);\r\nbuild_tlb_write_entry(p, l, r, tlb_random);\r\nuasm_l_leave(l, *p);\r\nrv.restore_scratch = 1;\r\n} else if (PAGE_SHIFT == 14 || PAGE_SHIFT == 13) {\r\nbuild_tlb_write_entry(p, l, r, tlb_random);\r\nuasm_l_leave(l, *p);\r\nUASM_i_LW(p, scratch, scratchpad_offset(0), 0);\r\n} else {\r\nUASM_i_LW(p, scratch, scratchpad_offset(0), 0);\r\nbuild_tlb_write_entry(p, l, r, tlb_random);\r\nuasm_l_leave(l, *p);\r\nrv.restore_scratch = 1;\r\n}\r\nuasm_i_eret(p);\r\nreturn rv;\r\n}\r\nstatic void build_r4000_tlb_refill_handler(void)\r\n{\r\nu32 *p = tlb_handler;\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nu32 *f;\r\nunsigned int final_len;\r\nstruct mips_huge_tlb_info htlb_info __maybe_unused;\r\nenum vmalloc64_mode vmalloc_mode __maybe_unused;\r\nmemset(tlb_handler, 0, sizeof(tlb_handler));\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\nmemset(final_handler, 0, sizeof(final_handler));\r\nif (IS_ENABLED(CONFIG_64BIT) && (scratch_reg >= 0 || scratchpad_available()) && use_bbit_insns()) {\r\nhtlb_info = build_fast_tlb_refill_handler(&p, &l, &r, K0, K1,\r\nscratch_reg);\r\nvmalloc_mode = refill_scratch;\r\n} else {\r\nhtlb_info.huge_pte = K0;\r\nhtlb_info.restore_scratch = 0;\r\nhtlb_info.need_reload_pte = true;\r\nvmalloc_mode = refill_noscratch;\r\nif (bcm1250_m3_war()) {\r\nunsigned int segbits = 44;\r\nuasm_i_dmfc0(&p, K0, C0_BADVADDR);\r\nuasm_i_dmfc0(&p, K1, C0_ENTRYHI);\r\nuasm_i_xor(&p, K0, K0, K1);\r\nuasm_i_dsrl_safe(&p, K1, K0, 62);\r\nuasm_i_dsrl_safe(&p, K0, K0, 12 + 1);\r\nuasm_i_dsll_safe(&p, K0, K0, 64 + 12 + 1 - segbits);\r\nuasm_i_or(&p, K0, K0, K1);\r\nuasm_il_bnez(&p, &r, K0, label_leave);\r\n}\r\n#ifdef CONFIG_64BIT\r\nbuild_get_pmde64(&p, &l, &r, K0, K1);\r\n#else\r\nbuild_get_pgde32(&p, K0, K1);\r\n#endif\r\n#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT\r\nbuild_is_huge_pte(&p, &r, K0, K1, label_tlb_huge_update);\r\n#endif\r\nbuild_get_ptep(&p, K0, K1);\r\nbuild_update_entries(&p, K0, K1);\r\nbuild_tlb_write_entry(&p, &l, &r, tlb_random);\r\nuasm_l_leave(&l, p);\r\nuasm_i_eret(&p);\r\n}\r\n#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT\r\nuasm_l_tlb_huge_update(&l, p);\r\nif (htlb_info.need_reload_pte)\r\nUASM_i_LW(&p, htlb_info.huge_pte, 0, K1);\r\nbuild_huge_update_entries(&p, htlb_info.huge_pte, K1);\r\nbuild_huge_tlb_write_entry(&p, &l, &r, K0, tlb_random,\r\nhtlb_info.restore_scratch);\r\n#endif\r\n#ifdef CONFIG_64BIT\r\nbuild_get_pgd_vmalloc64(&p, &l, &r, K0, K1, vmalloc_mode);\r\n#endif\r\nswitch (boot_cpu_type()) {\r\ndefault:\r\nif (sizeof(long) == 4) {\r\ncase CPU_LOONGSON2:\r\nif ((p - tlb_handler) > 64)\r\npanic("TLB refill handler space exceeded");\r\nf = final_handler;\r\nuasm_copy_handler(relocs, labels, tlb_handler, p, f);\r\nfinal_len = p - tlb_handler;\r\nbreak;\r\n} else {\r\nif (((p - tlb_handler) > (MIPS64_REFILL_INSNS * 2) - 1)\r\n|| (((p - tlb_handler) > (MIPS64_REFILL_INSNS * 2) - 3)\r\n&& uasm_insn_has_bdelay(relocs,\r\ntlb_handler + MIPS64_REFILL_INSNS - 3)))\r\npanic("TLB refill handler space exceeded");\r\nf = final_handler + MIPS64_REFILL_INSNS;\r\nif ((p - tlb_handler) <= MIPS64_REFILL_INSNS) {\r\nuasm_copy_handler(relocs, labels, tlb_handler, p, f);\r\nfinal_len = p - tlb_handler;\r\n} else {\r\n#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT\r\nconst enum label_id ls = label_tlb_huge_update;\r\n#else\r\nconst enum label_id ls = label_vmalloc;\r\n#endif\r\nu32 *split;\r\nint ov = 0;\r\nint i;\r\nfor (i = 0; i < ARRAY_SIZE(labels) && labels[i].lab != ls; i++)\r\n;\r\nBUG_ON(i == ARRAY_SIZE(labels));\r\nsplit = labels[i].addr;\r\nif (split > tlb_handler + MIPS64_REFILL_INSNS ||\r\nsplit < p - MIPS64_REFILL_INSNS)\r\nov = 1;\r\nif (ov) {\r\nsplit = tlb_handler + MIPS64_REFILL_INSNS - 2;\r\nif (uasm_insn_has_bdelay(relocs, split - 1))\r\nsplit--;\r\n}\r\nuasm_copy_handler(relocs, labels, tlb_handler, split, f);\r\nf += split - tlb_handler;\r\nif (ov) {\r\nuasm_l_split(&l, final_handler);\r\nuasm_il_b(&f, &r, label_split);\r\nif (uasm_insn_has_bdelay(relocs, split))\r\nuasm_i_nop(&f);\r\nelse {\r\nuasm_copy_handler(relocs, labels,\r\nsplit, split + 1, f);\r\nuasm_move_labels(labels, f, f + 1, -1);\r\nf++;\r\nsplit++;\r\n}\r\n}\r\nuasm_copy_handler(relocs, labels, split, p, final_handler);\r\nfinal_len = (f - (final_handler + MIPS64_REFILL_INSNS)) +\r\n(p - split);\r\n}\r\n}\r\nbreak;\r\n}\r\nuasm_resolve_relocs(relocs, labels);\r\npr_debug("Wrote TLB refill handler (%u instructions).\n",\r\nfinal_len);\r\nmemcpy((void *)ebase, final_handler, 0x100);\r\nlocal_flush_icache_range(ebase, ebase + 0x100);\r\ndump_handler("r4000_tlb_refill", (u32 *)ebase, 64);\r\n}\r\nstatic void setup_pw(void)\r\n{\r\nunsigned long pgd_i, pgd_w;\r\n#ifndef __PAGETABLE_PMD_FOLDED\r\nunsigned long pmd_i, pmd_w;\r\n#endif\r\nunsigned long pt_i, pt_w;\r\nunsigned long pte_i, pte_w;\r\n#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT\r\nunsigned long psn;\r\npsn = ilog2(_PAGE_HUGE);\r\n#endif\r\npgd_i = PGDIR_SHIFT;\r\n#ifndef __PAGETABLE_PMD_FOLDED\r\npgd_w = PGDIR_SHIFT - PMD_SHIFT + PGD_ORDER;\r\npmd_i = PMD_SHIFT;\r\npmd_w = PMD_SHIFT - PAGE_SHIFT;\r\n#else\r\npgd_w = PGDIR_SHIFT - PAGE_SHIFT + PGD_ORDER;\r\n#endif\r\npt_i = PAGE_SHIFT;\r\npt_w = PAGE_SHIFT - 3;\r\npte_i = ilog2(_PAGE_GLOBAL);\r\npte_w = 0;\r\n#ifndef __PAGETABLE_PMD_FOLDED\r\nwrite_c0_pwfield(pgd_i << 24 | pmd_i << 12 | pt_i << 6 | pte_i);\r\nwrite_c0_pwsize(1 << 30 | pgd_w << 24 | pmd_w << 12 | pt_w << 6 | pte_w);\r\n#else\r\nwrite_c0_pwfield(pgd_i << 24 | pt_i << 6 | pte_i);\r\nwrite_c0_pwsize(1 << 30 | pgd_w << 24 | pt_w << 6 | pte_w);\r\n#endif\r\n#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT\r\nwrite_c0_pwctl(1 << 6 | psn);\r\n#endif\r\nwrite_c0_kpgd(swapper_pg_dir);\r\nkscratch_used_mask |= (1 << 7);\r\n}\r\nstatic void build_loongson3_tlb_refill_handler(void)\r\n{\r\nu32 *p = tlb_handler;\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\nmemset(tlb_handler, 0, sizeof(tlb_handler));\r\nif (check_for_high_segbits) {\r\nuasm_i_dmfc0(&p, K0, C0_BADVADDR);\r\nuasm_i_dsrl_safe(&p, K1, K0, PGDIR_SHIFT + PGD_ORDER + PAGE_SHIFT - 3);\r\nuasm_il_beqz(&p, &r, K1, label_vmalloc);\r\nuasm_i_nop(&p);\r\nuasm_il_bgez(&p, &r, K0, label_large_segbits_fault);\r\nuasm_i_nop(&p);\r\nuasm_l_vmalloc(&l, p);\r\n}\r\nuasm_i_dmfc0(&p, K1, C0_PGD);\r\nuasm_i_lddir(&p, K0, K1, 3);\r\n#ifndef __PAGETABLE_PMD_FOLDED\r\nuasm_i_lddir(&p, K1, K0, 1);\r\n#endif\r\nuasm_i_ldpte(&p, K1, 0);\r\nuasm_i_ldpte(&p, K1, 1);\r\nuasm_i_tlbwr(&p);\r\nif (PM_DEFAULT_MASK >> 16) {\r\nuasm_i_lui(&p, K0, PM_DEFAULT_MASK >> 16);\r\nuasm_i_ori(&p, K0, K0, PM_DEFAULT_MASK & 0xffff);\r\nuasm_i_mtc0(&p, K0, C0_PAGEMASK);\r\n} else if (PM_DEFAULT_MASK) {\r\nuasm_i_ori(&p, K0, 0, PM_DEFAULT_MASK);\r\nuasm_i_mtc0(&p, K0, C0_PAGEMASK);\r\n} else {\r\nuasm_i_mtc0(&p, 0, C0_PAGEMASK);\r\n}\r\nuasm_i_eret(&p);\r\nif (check_for_high_segbits) {\r\nuasm_l_large_segbits_fault(&l, p);\r\nUASM_i_LA(&p, K1, (unsigned long)tlb_do_page_fault_0);\r\nuasm_i_jr(&p, K1);\r\nuasm_i_nop(&p);\r\n}\r\nuasm_resolve_relocs(relocs, labels);\r\nmemcpy((void *)(ebase + 0x80), tlb_handler, 0x80);\r\nlocal_flush_icache_range(ebase + 0x80, ebase + 0x100);\r\ndump_handler("loongson3_tlb_refill", (u32 *)(ebase + 0x80), 32);\r\n}\r\nstatic void build_setup_pgd(void)\r\n{\r\nconst int a0 = 4;\r\nconst int __maybe_unused a1 = 5;\r\nconst int __maybe_unused a2 = 6;\r\nu32 *p = tlbmiss_handler_setup_pgd_start;\r\nconst int tlbmiss_handler_setup_pgd_size =\r\ntlbmiss_handler_setup_pgd_end - tlbmiss_handler_setup_pgd_start;\r\n#ifndef CONFIG_MIPS_PGD_C0_CONTEXT\r\nlong pgdc = (long)pgd_current;\r\n#endif\r\nmemset(tlbmiss_handler_setup_pgd, 0, tlbmiss_handler_setup_pgd_size *\r\nsizeof(tlbmiss_handler_setup_pgd[0]));\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\npgd_reg = allocate_kscratch();\r\n#ifdef CONFIG_MIPS_PGD_C0_CONTEXT\r\nif (pgd_reg == -1) {\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nUASM_i_SRA(&p, a1, a0, 29);\r\nUASM_i_ADDIU(&p, a1, a1, 4);\r\nuasm_il_bnez(&p, &r, a1, label_tlbl_goaround1);\r\nuasm_i_nop(&p);\r\nuasm_i_dinsm(&p, a0, 0, 29, 64 - 29);\r\nuasm_l_tlbl_goaround1(&l, p);\r\nUASM_i_SLL(&p, a0, a0, 11);\r\nuasm_i_jr(&p, 31);\r\nUASM_i_MTC0(&p, a0, C0_CONTEXT);\r\n} else {\r\nuasm_i_jr(&p, 31);\r\nif (cpu_has_ldpte)\r\nUASM_i_MTC0(&p, a0, C0_PWBASE);\r\nelse\r\nUASM_i_MTC0(&p, a0, c0_kscratch(), pgd_reg);\r\n}\r\n#else\r\n#ifdef CONFIG_SMP\r\nUASM_i_CPUID_MFC0(&p, a1, SMP_CPUID_REG);\r\nUASM_i_SRL_SAFE(&p, a1, a1, SMP_CPUID_PTRSHIFT);\r\nUASM_i_LA_mostly(&p, a2, pgdc);\r\nUASM_i_ADDU(&p, a2, a2, a1);\r\nUASM_i_SW(&p, a0, uasm_rel_lo(pgdc), a2);\r\n#else\r\nUASM_i_LA_mostly(&p, a2, pgdc);\r\nUASM_i_SW(&p, a0, uasm_rel_lo(pgdc), a2);\r\n#endif\r\nuasm_i_jr(&p, 31);\r\nif (pgd_reg != -1)\r\nUASM_i_MTC0(&p, a0, c0_kscratch(), pgd_reg);\r\nelse\r\nuasm_i_nop(&p);\r\n#endif\r\nif (p >= tlbmiss_handler_setup_pgd_end)\r\npanic("tlbmiss_handler_setup_pgd space exceeded");\r\nuasm_resolve_relocs(relocs, labels);\r\npr_debug("Wrote tlbmiss_handler_setup_pgd (%u instructions).\n",\r\n(unsigned int)(p - tlbmiss_handler_setup_pgd));\r\ndump_handler("tlbmiss_handler", tlbmiss_handler_setup_pgd,\r\ntlbmiss_handler_setup_pgd_size);\r\n}\r\nstatic void\r\niPTE_LW(u32 **p, unsigned int pte, unsigned int ptr)\r\n{\r\n#ifdef CONFIG_SMP\r\n# ifdef CONFIG_PHYS_ADDR_T_64BIT\r\nif (cpu_has_64bits)\r\nuasm_i_lld(p, pte, 0, ptr);\r\nelse\r\n# endif\r\nUASM_i_LL(p, pte, 0, ptr);\r\n#else\r\n# ifdef CONFIG_PHYS_ADDR_T_64BIT\r\nif (cpu_has_64bits)\r\nuasm_i_ld(p, pte, 0, ptr);\r\nelse\r\n# endif\r\nUASM_i_LW(p, pte, 0, ptr);\r\n#endif\r\n}\r\nstatic void\r\niPTE_SW(u32 **p, struct uasm_reloc **r, unsigned int pte, unsigned int ptr,\r\nunsigned int mode, unsigned int scratch)\r\n{\r\nunsigned int hwmode = mode & (_PAGE_VALID | _PAGE_DIRTY);\r\nunsigned int swmode = mode & ~hwmode;\r\nif (IS_ENABLED(CONFIG_XPA) && !cpu_has_64bits) {\r\nuasm_i_lui(p, scratch, swmode >> 16);\r\nuasm_i_or(p, pte, pte, scratch);\r\nBUG_ON(swmode & 0xffff);\r\n} else {\r\nuasm_i_ori(p, pte, pte, mode);\r\n}\r\n#ifdef CONFIG_SMP\r\n# ifdef CONFIG_PHYS_ADDR_T_64BIT\r\nif (cpu_has_64bits)\r\nuasm_i_scd(p, pte, 0, ptr);\r\nelse\r\n# endif\r\nUASM_i_SC(p, pte, 0, ptr);\r\nif (r10000_llsc_war())\r\nuasm_il_beqzl(p, r, pte, label_smp_pgtable_change);\r\nelse\r\nuasm_il_beqz(p, r, pte, label_smp_pgtable_change);\r\n# ifdef CONFIG_PHYS_ADDR_T_64BIT\r\nif (!cpu_has_64bits) {\r\nuasm_i_ll(p, pte, sizeof(pte_t) / 2, ptr);\r\nuasm_i_ori(p, pte, pte, hwmode);\r\nBUG_ON(hwmode & ~0xffff);\r\nuasm_i_sc(p, pte, sizeof(pte_t) / 2, ptr);\r\nuasm_il_beqz(p, r, pte, label_smp_pgtable_change);\r\nuasm_i_lw(p, pte, 0, ptr);\r\n} else\r\nuasm_i_nop(p);\r\n# else\r\nuasm_i_nop(p);\r\n# endif\r\n#else\r\n# ifdef CONFIG_PHYS_ADDR_T_64BIT\r\nif (cpu_has_64bits)\r\nuasm_i_sd(p, pte, 0, ptr);\r\nelse\r\n# endif\r\nUASM_i_SW(p, pte, 0, ptr);\r\n# ifdef CONFIG_PHYS_ADDR_T_64BIT\r\nif (!cpu_has_64bits) {\r\nuasm_i_lw(p, pte, sizeof(pte_t) / 2, ptr);\r\nuasm_i_ori(p, pte, pte, hwmode);\r\nBUG_ON(hwmode & ~0xffff);\r\nuasm_i_sw(p, pte, sizeof(pte_t) / 2, ptr);\r\nuasm_i_lw(p, pte, 0, ptr);\r\n}\r\n# endif\r\n#endif\r\n}\r\nstatic void\r\nbuild_pte_present(u32 **p, struct uasm_reloc **r,\r\nint pte, int ptr, int scratch, enum label_id lid)\r\n{\r\nint t = scratch >= 0 ? scratch : pte;\r\nint cur = pte;\r\nif (cpu_has_rixi) {\r\nif (use_bbit_insns()) {\r\nuasm_il_bbit0(p, r, pte, ilog2(_PAGE_PRESENT), lid);\r\nuasm_i_nop(p);\r\n} else {\r\nif (_PAGE_PRESENT_SHIFT) {\r\nuasm_i_srl(p, t, cur, _PAGE_PRESENT_SHIFT);\r\ncur = t;\r\n}\r\nuasm_i_andi(p, t, cur, 1);\r\nuasm_il_beqz(p, r, t, lid);\r\nif (pte == t)\r\niPTE_LW(p, pte, ptr);\r\n}\r\n} else {\r\nif (_PAGE_PRESENT_SHIFT) {\r\nuasm_i_srl(p, t, cur, _PAGE_PRESENT_SHIFT);\r\ncur = t;\r\n}\r\nuasm_i_andi(p, t, cur,\r\n(_PAGE_PRESENT | _PAGE_NO_READ) >> _PAGE_PRESENT_SHIFT);\r\nuasm_i_xori(p, t, t, _PAGE_PRESENT >> _PAGE_PRESENT_SHIFT);\r\nuasm_il_bnez(p, r, t, lid);\r\nif (pte == t)\r\niPTE_LW(p, pte, ptr);\r\n}\r\n}\r\nstatic void\r\nbuild_make_valid(u32 **p, struct uasm_reloc **r, unsigned int pte,\r\nunsigned int ptr, unsigned int scratch)\r\n{\r\nunsigned int mode = _PAGE_VALID | _PAGE_ACCESSED;\r\niPTE_SW(p, r, pte, ptr, mode, scratch);\r\n}\r\nstatic void\r\nbuild_pte_writable(u32 **p, struct uasm_reloc **r,\r\nunsigned int pte, unsigned int ptr, int scratch,\r\nenum label_id lid)\r\n{\r\nint t = scratch >= 0 ? scratch : pte;\r\nint cur = pte;\r\nif (_PAGE_PRESENT_SHIFT) {\r\nuasm_i_srl(p, t, cur, _PAGE_PRESENT_SHIFT);\r\ncur = t;\r\n}\r\nuasm_i_andi(p, t, cur,\r\n(_PAGE_PRESENT | _PAGE_WRITE) >> _PAGE_PRESENT_SHIFT);\r\nuasm_i_xori(p, t, t,\r\n(_PAGE_PRESENT | _PAGE_WRITE) >> _PAGE_PRESENT_SHIFT);\r\nuasm_il_bnez(p, r, t, lid);\r\nif (pte == t)\r\niPTE_LW(p, pte, ptr);\r\nelse\r\nuasm_i_nop(p);\r\n}\r\nstatic void\r\nbuild_make_write(u32 **p, struct uasm_reloc **r, unsigned int pte,\r\nunsigned int ptr, unsigned int scratch)\r\n{\r\nunsigned int mode = (_PAGE_ACCESSED | _PAGE_MODIFIED | _PAGE_VALID\r\n| _PAGE_DIRTY);\r\niPTE_SW(p, r, pte, ptr, mode, scratch);\r\n}\r\nstatic void\r\nbuild_pte_modifiable(u32 **p, struct uasm_reloc **r,\r\nunsigned int pte, unsigned int ptr, int scratch,\r\nenum label_id lid)\r\n{\r\nif (use_bbit_insns()) {\r\nuasm_il_bbit0(p, r, pte, ilog2(_PAGE_WRITE), lid);\r\nuasm_i_nop(p);\r\n} else {\r\nint t = scratch >= 0 ? scratch : pte;\r\nuasm_i_srl(p, t, pte, _PAGE_WRITE_SHIFT);\r\nuasm_i_andi(p, t, t, 1);\r\nuasm_il_beqz(p, r, t, lid);\r\nif (pte == t)\r\niPTE_LW(p, pte, ptr);\r\n}\r\n}\r\nstatic void\r\nbuild_r3000_pte_reload_tlbwi(u32 **p, unsigned int pte, unsigned int tmp)\r\n{\r\nuasm_i_mtc0(p, pte, C0_ENTRYLO0);\r\nuasm_i_mfc0(p, tmp, C0_EPC);\r\nuasm_i_tlbwi(p);\r\nuasm_i_jr(p, tmp);\r\nuasm_i_rfe(p);\r\n}\r\nstatic void\r\nbuild_r3000_tlb_reload_write(u32 **p, struct uasm_label **l,\r\nstruct uasm_reloc **r, unsigned int pte,\r\nunsigned int tmp)\r\n{\r\nuasm_i_mfc0(p, tmp, C0_INDEX);\r\nuasm_i_mtc0(p, pte, C0_ENTRYLO0);\r\nuasm_il_bltz(p, r, tmp, label_r3000_write_probe_fail);\r\nuasm_i_mfc0(p, tmp, C0_EPC);\r\nuasm_i_tlbwi(p);\r\nuasm_i_jr(p, tmp);\r\nuasm_i_rfe(p);\r\nuasm_l_r3000_write_probe_fail(l, *p);\r\nuasm_i_tlbwr(p);\r\nuasm_i_jr(p, tmp);\r\nuasm_i_rfe(p);\r\n}\r\nstatic void\r\nbuild_r3000_tlbchange_handler_head(u32 **p, unsigned int pte,\r\nunsigned int ptr)\r\n{\r\nlong pgdc = (long)pgd_current;\r\nuasm_i_mfc0(p, pte, C0_BADVADDR);\r\nuasm_i_lui(p, ptr, uasm_rel_hi(pgdc));\r\nuasm_i_lw(p, ptr, uasm_rel_lo(pgdc), ptr);\r\nuasm_i_srl(p, pte, pte, 22);\r\nuasm_i_sll(p, pte, pte, 2);\r\nuasm_i_addu(p, ptr, ptr, pte);\r\nuasm_i_mfc0(p, pte, C0_CONTEXT);\r\nuasm_i_lw(p, ptr, 0, ptr);\r\nuasm_i_andi(p, pte, pte, 0xffc);\r\nuasm_i_addu(p, ptr, ptr, pte);\r\nuasm_i_lw(p, pte, 0, ptr);\r\nuasm_i_tlbp(p);\r\n}\r\nstatic void build_r3000_tlb_load_handler(void)\r\n{\r\nu32 *p = handle_tlbl;\r\nconst int handle_tlbl_size = handle_tlbl_end - handle_tlbl;\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nmemset(handle_tlbl, 0, handle_tlbl_size * sizeof(handle_tlbl[0]));\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\nbuild_r3000_tlbchange_handler_head(&p, K0, K1);\r\nbuild_pte_present(&p, &r, K0, K1, -1, label_nopage_tlbl);\r\nuasm_i_nop(&p);\r\nbuild_make_valid(&p, &r, K0, K1, -1);\r\nbuild_r3000_tlb_reload_write(&p, &l, &r, K0, K1);\r\nuasm_l_nopage_tlbl(&l, p);\r\nuasm_i_j(&p, (unsigned long)tlb_do_page_fault_0 & 0x0fffffff);\r\nuasm_i_nop(&p);\r\nif (p >= handle_tlbl_end)\r\npanic("TLB load handler fastpath space exceeded");\r\nuasm_resolve_relocs(relocs, labels);\r\npr_debug("Wrote TLB load handler fastpath (%u instructions).\n",\r\n(unsigned int)(p - handle_tlbl));\r\ndump_handler("r3000_tlb_load", handle_tlbl, handle_tlbl_size);\r\n}\r\nstatic void build_r3000_tlb_store_handler(void)\r\n{\r\nu32 *p = handle_tlbs;\r\nconst int handle_tlbs_size = handle_tlbs_end - handle_tlbs;\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nmemset(handle_tlbs, 0, handle_tlbs_size * sizeof(handle_tlbs[0]));\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\nbuild_r3000_tlbchange_handler_head(&p, K0, K1);\r\nbuild_pte_writable(&p, &r, K0, K1, -1, label_nopage_tlbs);\r\nuasm_i_nop(&p);\r\nbuild_make_write(&p, &r, K0, K1, -1);\r\nbuild_r3000_tlb_reload_write(&p, &l, &r, K0, K1);\r\nuasm_l_nopage_tlbs(&l, p);\r\nuasm_i_j(&p, (unsigned long)tlb_do_page_fault_1 & 0x0fffffff);\r\nuasm_i_nop(&p);\r\nif (p >= handle_tlbs_end)\r\npanic("TLB store handler fastpath space exceeded");\r\nuasm_resolve_relocs(relocs, labels);\r\npr_debug("Wrote TLB store handler fastpath (%u instructions).\n",\r\n(unsigned int)(p - handle_tlbs));\r\ndump_handler("r3000_tlb_store", handle_tlbs, handle_tlbs_size);\r\n}\r\nstatic void build_r3000_tlb_modify_handler(void)\r\n{\r\nu32 *p = handle_tlbm;\r\nconst int handle_tlbm_size = handle_tlbm_end - handle_tlbm;\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nmemset(handle_tlbm, 0, handle_tlbm_size * sizeof(handle_tlbm[0]));\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\nbuild_r3000_tlbchange_handler_head(&p, K0, K1);\r\nbuild_pte_modifiable(&p, &r, K0, K1, -1, label_nopage_tlbm);\r\nuasm_i_nop(&p);\r\nbuild_make_write(&p, &r, K0, K1, -1);\r\nbuild_r3000_pte_reload_tlbwi(&p, K0, K1);\r\nuasm_l_nopage_tlbm(&l, p);\r\nuasm_i_j(&p, (unsigned long)tlb_do_page_fault_1 & 0x0fffffff);\r\nuasm_i_nop(&p);\r\nif (p >= handle_tlbm_end)\r\npanic("TLB modify handler fastpath space exceeded");\r\nuasm_resolve_relocs(relocs, labels);\r\npr_debug("Wrote TLB modify handler fastpath (%u instructions).\n",\r\n(unsigned int)(p - handle_tlbm));\r\ndump_handler("r3000_tlb_modify", handle_tlbm, handle_tlbm_size);\r\n}\r\nstatic struct work_registers\r\nbuild_r4000_tlbchange_handler_head(u32 **p, struct uasm_label **l,\r\nstruct uasm_reloc **r)\r\n{\r\nstruct work_registers wr = build_get_work_registers(p);\r\n#ifdef CONFIG_64BIT\r\nbuild_get_pmde64(p, l, r, wr.r1, wr.r2);\r\n#else\r\nbuild_get_pgde32(p, wr.r1, wr.r2);\r\n#endif\r\n#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT\r\nbuild_is_huge_pte(p, r, wr.r1, wr.r2, label_tlb_huge_update);\r\n#endif\r\nUASM_i_MFC0(p, wr.r1, C0_BADVADDR);\r\nUASM_i_LW(p, wr.r2, 0, wr.r2);\r\nUASM_i_SRL(p, wr.r1, wr.r1, PAGE_SHIFT + PTE_ORDER - PTE_T_LOG2);\r\nuasm_i_andi(p, wr.r1, wr.r1, (PTRS_PER_PTE - 1) << PTE_T_LOG2);\r\nUASM_i_ADDU(p, wr.r2, wr.r2, wr.r1);\r\n#ifdef CONFIG_SMP\r\nuasm_l_smp_pgtable_change(l, *p);\r\n#endif\r\niPTE_LW(p, wr.r1, wr.r2);\r\nif (!m4kc_tlbp_war()) {\r\nbuild_tlb_probe_entry(p);\r\nif (cpu_has_htw) {\r\nuasm_i_ehb(p);\r\nuasm_i_mfc0(p, wr.r3, C0_INDEX);\r\nuasm_il_bltz(p, r, wr.r3, label_leave);\r\nuasm_i_nop(p);\r\n}\r\n}\r\nreturn wr;\r\n}\r\nstatic void\r\nbuild_r4000_tlbchange_handler_tail(u32 **p, struct uasm_label **l,\r\nstruct uasm_reloc **r, unsigned int tmp,\r\nunsigned int ptr)\r\n{\r\nuasm_i_ori(p, ptr, ptr, sizeof(pte_t));\r\nuasm_i_xori(p, ptr, ptr, sizeof(pte_t));\r\nbuild_update_entries(p, tmp, ptr);\r\nbuild_tlb_write_entry(p, l, r, tlb_indexed);\r\nuasm_l_leave(l, *p);\r\nbuild_restore_work_registers(p);\r\nuasm_i_eret(p);\r\n#ifdef CONFIG_64BIT\r\nbuild_get_pgd_vmalloc64(p, l, r, tmp, ptr, not_refill);\r\n#endif\r\n}\r\nstatic void build_r4000_tlb_load_handler(void)\r\n{\r\nu32 *p = handle_tlbl;\r\nconst int handle_tlbl_size = handle_tlbl_end - handle_tlbl;\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nstruct work_registers wr;\r\nmemset(handle_tlbl, 0, handle_tlbl_size * sizeof(handle_tlbl[0]));\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\nif (bcm1250_m3_war()) {\r\nunsigned int segbits = 44;\r\nuasm_i_dmfc0(&p, K0, C0_BADVADDR);\r\nuasm_i_dmfc0(&p, K1, C0_ENTRYHI);\r\nuasm_i_xor(&p, K0, K0, K1);\r\nuasm_i_dsrl_safe(&p, K1, K0, 62);\r\nuasm_i_dsrl_safe(&p, K0, K0, 12 + 1);\r\nuasm_i_dsll_safe(&p, K0, K0, 64 + 12 + 1 - segbits);\r\nuasm_i_or(&p, K0, K0, K1);\r\nuasm_il_bnez(&p, &r, K0, label_leave);\r\n}\r\nwr = build_r4000_tlbchange_handler_head(&p, &l, &r);\r\nbuild_pte_present(&p, &r, wr.r1, wr.r2, wr.r3, label_nopage_tlbl);\r\nif (m4kc_tlbp_war())\r\nbuild_tlb_probe_entry(&p);\r\nif (cpu_has_rixi && !cpu_has_rixiex) {\r\nif (use_bbit_insns()) {\r\nuasm_il_bbit0(&p, &r, wr.r1, ilog2(_PAGE_VALID),\r\nlabel_tlbl_goaround1);\r\n} else {\r\nuasm_i_andi(&p, wr.r3, wr.r1, _PAGE_VALID);\r\nuasm_il_beqz(&p, &r, wr.r3, label_tlbl_goaround1);\r\n}\r\nuasm_i_nop(&p);\r\nuasm_i_tlbr(&p);\r\nswitch (current_cpu_type()) {\r\ndefault:\r\nif (cpu_has_mips_r2_exec_hazard) {\r\nuasm_i_ehb(&p);\r\ncase CPU_CAVIUM_OCTEON:\r\ncase CPU_CAVIUM_OCTEON_PLUS:\r\ncase CPU_CAVIUM_OCTEON2:\r\nbreak;\r\n}\r\n}\r\nif (use_bbit_insns()) {\r\nuasm_i_bbit0(&p, wr.r2, ilog2(sizeof(pte_t)), 8);\r\n} else {\r\nuasm_i_andi(&p, wr.r3, wr.r2, sizeof(pte_t));\r\nuasm_i_beqz(&p, wr.r3, 8);\r\n}\r\nUASM_i_MFC0(&p, wr.r3, C0_ENTRYLO0);\r\nUASM_i_MFC0(&p, wr.r3, C0_ENTRYLO1);\r\nif (use_bbit_insns()) {\r\nuasm_il_bbit1(&p, &r, wr.r3, 1, label_nopage_tlbl);\r\nuasm_i_nop(&p);\r\nuasm_l_tlbl_goaround1(&l, p);\r\n} else {\r\nuasm_i_andi(&p, wr.r3, wr.r3, 2);\r\nuasm_il_bnez(&p, &r, wr.r3, label_nopage_tlbl);\r\nuasm_i_nop(&p);\r\n}\r\nuasm_l_tlbl_goaround1(&l, p);\r\n}\r\nbuild_make_valid(&p, &r, wr.r1, wr.r2, wr.r3);\r\nbuild_r4000_tlbchange_handler_tail(&p, &l, &r, wr.r1, wr.r2);\r\n#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT\r\nuasm_l_tlb_huge_update(&l, p);\r\niPTE_LW(&p, wr.r1, wr.r2);\r\nbuild_pte_present(&p, &r, wr.r1, wr.r2, wr.r3, label_nopage_tlbl);\r\nbuild_tlb_probe_entry(&p);\r\nif (cpu_has_rixi && !cpu_has_rixiex) {\r\nif (use_bbit_insns()) {\r\nuasm_il_bbit0(&p, &r, wr.r1, ilog2(_PAGE_VALID),\r\nlabel_tlbl_goaround2);\r\n} else {\r\nuasm_i_andi(&p, wr.r3, wr.r1, _PAGE_VALID);\r\nuasm_il_beqz(&p, &r, wr.r3, label_tlbl_goaround2);\r\n}\r\nuasm_i_nop(&p);\r\nuasm_i_tlbr(&p);\r\nswitch (current_cpu_type()) {\r\ndefault:\r\nif (cpu_has_mips_r2_exec_hazard) {\r\nuasm_i_ehb(&p);\r\ncase CPU_CAVIUM_OCTEON:\r\ncase CPU_CAVIUM_OCTEON_PLUS:\r\ncase CPU_CAVIUM_OCTEON2:\r\nbreak;\r\n}\r\n}\r\nif (use_bbit_insns()) {\r\nuasm_i_bbit0(&p, wr.r2, ilog2(sizeof(pte_t)), 8);\r\n} else {\r\nuasm_i_andi(&p, wr.r3, wr.r2, sizeof(pte_t));\r\nuasm_i_beqz(&p, wr.r3, 8);\r\n}\r\nUASM_i_MFC0(&p, wr.r3, C0_ENTRYLO0);\r\nUASM_i_MFC0(&p, wr.r3, C0_ENTRYLO1);\r\nif (use_bbit_insns()) {\r\nuasm_il_bbit0(&p, &r, wr.r3, 1, label_tlbl_goaround2);\r\n} else {\r\nuasm_i_andi(&p, wr.r3, wr.r3, 2);\r\nuasm_il_beqz(&p, &r, wr.r3, label_tlbl_goaround2);\r\n}\r\nif (PM_DEFAULT_MASK == 0)\r\nuasm_i_nop(&p);\r\nbuild_restore_pagemask(&p, &r, wr.r3, label_nopage_tlbl, 0);\r\nuasm_l_tlbl_goaround2(&l, p);\r\n}\r\nuasm_i_ori(&p, wr.r1, wr.r1, (_PAGE_ACCESSED | _PAGE_VALID));\r\nbuild_huge_handler_tail(&p, &r, &l, wr.r1, wr.r2);\r\n#endif\r\nuasm_l_nopage_tlbl(&l, p);\r\nbuild_restore_work_registers(&p);\r\n#ifdef CONFIG_CPU_MICROMIPS\r\nif ((unsigned long)tlb_do_page_fault_0 & 1) {\r\nuasm_i_lui(&p, K0, uasm_rel_hi((long)tlb_do_page_fault_0));\r\nuasm_i_addiu(&p, K0, K0, uasm_rel_lo((long)tlb_do_page_fault_0));\r\nuasm_i_jr(&p, K0);\r\n} else\r\n#endif\r\nuasm_i_j(&p, (unsigned long)tlb_do_page_fault_0 & 0x0fffffff);\r\nuasm_i_nop(&p);\r\nif (p >= handle_tlbl_end)\r\npanic("TLB load handler fastpath space exceeded");\r\nuasm_resolve_relocs(relocs, labels);\r\npr_debug("Wrote TLB load handler fastpath (%u instructions).\n",\r\n(unsigned int)(p - handle_tlbl));\r\ndump_handler("r4000_tlb_load", handle_tlbl, handle_tlbl_size);\r\n}\r\nstatic void build_r4000_tlb_store_handler(void)\r\n{\r\nu32 *p = handle_tlbs;\r\nconst int handle_tlbs_size = handle_tlbs_end - handle_tlbs;\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nstruct work_registers wr;\r\nmemset(handle_tlbs, 0, handle_tlbs_size * sizeof(handle_tlbs[0]));\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\nwr = build_r4000_tlbchange_handler_head(&p, &l, &r);\r\nbuild_pte_writable(&p, &r, wr.r1, wr.r2, wr.r3, label_nopage_tlbs);\r\nif (m4kc_tlbp_war())\r\nbuild_tlb_probe_entry(&p);\r\nbuild_make_write(&p, &r, wr.r1, wr.r2, wr.r3);\r\nbuild_r4000_tlbchange_handler_tail(&p, &l, &r, wr.r1, wr.r2);\r\n#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT\r\nuasm_l_tlb_huge_update(&l, p);\r\niPTE_LW(&p, wr.r1, wr.r2);\r\nbuild_pte_writable(&p, &r, wr.r1, wr.r2, wr.r3, label_nopage_tlbs);\r\nbuild_tlb_probe_entry(&p);\r\nuasm_i_ori(&p, wr.r1, wr.r1,\r\n_PAGE_ACCESSED | _PAGE_MODIFIED | _PAGE_VALID | _PAGE_DIRTY);\r\nbuild_huge_handler_tail(&p, &r, &l, wr.r1, wr.r2);\r\n#endif\r\nuasm_l_nopage_tlbs(&l, p);\r\nbuild_restore_work_registers(&p);\r\n#ifdef CONFIG_CPU_MICROMIPS\r\nif ((unsigned long)tlb_do_page_fault_1 & 1) {\r\nuasm_i_lui(&p, K0, uasm_rel_hi((long)tlb_do_page_fault_1));\r\nuasm_i_addiu(&p, K0, K0, uasm_rel_lo((long)tlb_do_page_fault_1));\r\nuasm_i_jr(&p, K0);\r\n} else\r\n#endif\r\nuasm_i_j(&p, (unsigned long)tlb_do_page_fault_1 & 0x0fffffff);\r\nuasm_i_nop(&p);\r\nif (p >= handle_tlbs_end)\r\npanic("TLB store handler fastpath space exceeded");\r\nuasm_resolve_relocs(relocs, labels);\r\npr_debug("Wrote TLB store handler fastpath (%u instructions).\n",\r\n(unsigned int)(p - handle_tlbs));\r\ndump_handler("r4000_tlb_store", handle_tlbs, handle_tlbs_size);\r\n}\r\nstatic void build_r4000_tlb_modify_handler(void)\r\n{\r\nu32 *p = handle_tlbm;\r\nconst int handle_tlbm_size = handle_tlbm_end - handle_tlbm;\r\nstruct uasm_label *l = labels;\r\nstruct uasm_reloc *r = relocs;\r\nstruct work_registers wr;\r\nmemset(handle_tlbm, 0, handle_tlbm_size * sizeof(handle_tlbm[0]));\r\nmemset(labels, 0, sizeof(labels));\r\nmemset(relocs, 0, sizeof(relocs));\r\nwr = build_r4000_tlbchange_handler_head(&p, &l, &r);\r\nbuild_pte_modifiable(&p, &r, wr.r1, wr.r2, wr.r3, label_nopage_tlbm);\r\nif (m4kc_tlbp_war())\r\nbuild_tlb_probe_entry(&p);\r\nbuild_make_write(&p, &r, wr.r1, wr.r2, wr.r3);\r\nbuild_r4000_tlbchange_handler_tail(&p, &l, &r, wr.r1, wr.r2);\r\n#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT\r\nuasm_l_tlb_huge_update(&l, p);\r\niPTE_LW(&p, wr.r1, wr.r2);\r\nbuild_pte_modifiable(&p, &r, wr.r1, wr.r2, wr.r3, label_nopage_tlbm);\r\nbuild_tlb_probe_entry(&p);\r\nuasm_i_ori(&p, wr.r1, wr.r1,\r\n_PAGE_ACCESSED | _PAGE_MODIFIED | _PAGE_VALID | _PAGE_DIRTY);\r\nbuild_huge_handler_tail(&p, &r, &l, wr.r1, wr.r2);\r\n#endif\r\nuasm_l_nopage_tlbm(&l, p);\r\nbuild_restore_work_registers(&p);\r\n#ifdef CONFIG_CPU_MICROMIPS\r\nif ((unsigned long)tlb_do_page_fault_1 & 1) {\r\nuasm_i_lui(&p, K0, uasm_rel_hi((long)tlb_do_page_fault_1));\r\nuasm_i_addiu(&p, K0, K0, uasm_rel_lo((long)tlb_do_page_fault_1));\r\nuasm_i_jr(&p, K0);\r\n} else\r\n#endif\r\nuasm_i_j(&p, (unsigned long)tlb_do_page_fault_1 & 0x0fffffff);\r\nuasm_i_nop(&p);\r\nif (p >= handle_tlbm_end)\r\npanic("TLB modify handler fastpath space exceeded");\r\nuasm_resolve_relocs(relocs, labels);\r\npr_debug("Wrote TLB modify handler fastpath (%u instructions).\n",\r\n(unsigned int)(p - handle_tlbm));\r\ndump_handler("r4000_tlb_modify", handle_tlbm, handle_tlbm_size);\r\n}\r\nstatic void flush_tlb_handlers(void)\r\n{\r\nlocal_flush_icache_range((unsigned long)handle_tlbl,\r\n(unsigned long)handle_tlbl_end);\r\nlocal_flush_icache_range((unsigned long)handle_tlbs,\r\n(unsigned long)handle_tlbs_end);\r\nlocal_flush_icache_range((unsigned long)handle_tlbm,\r\n(unsigned long)handle_tlbm_end);\r\nlocal_flush_icache_range((unsigned long)tlbmiss_handler_setup_pgd,\r\n(unsigned long)tlbmiss_handler_setup_pgd_end);\r\n}\r\nstatic void print_htw_config(void)\r\n{\r\nunsigned long config;\r\nunsigned int pwctl;\r\nconst int field = 2 * sizeof(unsigned long);\r\nconfig = read_c0_pwfield();\r\npr_debug("PWField (0x%0*lx): GDI: 0x%02lx UDI: 0x%02lx MDI: 0x%02lx PTI: 0x%02lx PTEI: 0x%02lx\n",\r\nfield, config,\r\n(config & MIPS_PWFIELD_GDI_MASK) >> MIPS_PWFIELD_GDI_SHIFT,\r\n(config & MIPS_PWFIELD_UDI_MASK) >> MIPS_PWFIELD_UDI_SHIFT,\r\n(config & MIPS_PWFIELD_MDI_MASK) >> MIPS_PWFIELD_MDI_SHIFT,\r\n(config & MIPS_PWFIELD_PTI_MASK) >> MIPS_PWFIELD_PTI_SHIFT,\r\n(config & MIPS_PWFIELD_PTEI_MASK) >> MIPS_PWFIELD_PTEI_SHIFT);\r\nconfig = read_c0_pwsize();\r\npr_debug("PWSize (0x%0*lx): PS: 0x%lx GDW: 0x%02lx UDW: 0x%02lx MDW: 0x%02lx PTW: 0x%02lx PTEW: 0x%02lx\n",\r\nfield, config,\r\n(config & MIPS_PWSIZE_PS_MASK) >> MIPS_PWSIZE_PS_SHIFT,\r\n(config & MIPS_PWSIZE_GDW_MASK) >> MIPS_PWSIZE_GDW_SHIFT,\r\n(config & MIPS_PWSIZE_UDW_MASK) >> MIPS_PWSIZE_UDW_SHIFT,\r\n(config & MIPS_PWSIZE_MDW_MASK) >> MIPS_PWSIZE_MDW_SHIFT,\r\n(config & MIPS_PWSIZE_PTW_MASK) >> MIPS_PWSIZE_PTW_SHIFT,\r\n(config & MIPS_PWSIZE_PTEW_MASK) >> MIPS_PWSIZE_PTEW_SHIFT);\r\npwctl = read_c0_pwctl();\r\npr_debug("PWCtl (0x%x): PWEn: 0x%x XK: 0x%x XS: 0x%x XU: 0x%x DPH: 0x%x HugePg: 0x%x Psn: 0x%x\n",\r\npwctl,\r\n(pwctl & MIPS_PWCTL_PWEN_MASK) >> MIPS_PWCTL_PWEN_SHIFT,\r\n(pwctl & MIPS_PWCTL_XK_MASK) >> MIPS_PWCTL_XK_SHIFT,\r\n(pwctl & MIPS_PWCTL_XS_MASK) >> MIPS_PWCTL_XS_SHIFT,\r\n(pwctl & MIPS_PWCTL_XU_MASK) >> MIPS_PWCTL_XU_SHIFT,\r\n(pwctl & MIPS_PWCTL_DPH_MASK) >> MIPS_PWCTL_DPH_SHIFT,\r\n(pwctl & MIPS_PWCTL_HUGEPG_MASK) >> MIPS_PWCTL_HUGEPG_SHIFT,\r\n(pwctl & MIPS_PWCTL_PSN_MASK) >> MIPS_PWCTL_PSN_SHIFT);\r\n}\r\nstatic void config_htw_params(void)\r\n{\r\nunsigned long pwfield, pwsize, ptei;\r\nunsigned int config;\r\npwfield = read_c0_pwfield();\r\npwfield &= ~MIPS_PWFIELD_GDI_MASK;\r\npwfield |= PGDIR_SHIFT << MIPS_PWFIELD_GDI_SHIFT;\r\npwfield &= ~MIPS_PWFIELD_PTI_MASK;\r\npwfield |= PAGE_SHIFT << MIPS_PWFIELD_PTI_SHIFT;\r\nif (CONFIG_PGTABLE_LEVELS >= 3) {\r\npwfield &= ~MIPS_PWFIELD_MDI_MASK;\r\npwfield |= PMD_SHIFT << MIPS_PWFIELD_MDI_SHIFT;\r\n}\r\nptei = _PAGE_GLOBAL_SHIFT << MIPS_PWFIELD_PTEI_SHIFT;\r\npwfield |= ptei;\r\nwrite_c0_pwfield(pwfield);\r\nback_to_back_c0_hazard();\r\npwfield = read_c0_pwfield();\r\nif (((pwfield & MIPS_PWFIELD_PTEI_MASK) << MIPS_PWFIELD_PTEI_SHIFT)\r\n!= ptei) {\r\npr_warn("Unsupported PTEI field value: 0x%lx. HTW will not be enabled",\r\nptei);\r\ncurrent_cpu_data.options &= ~MIPS_CPU_HTW;\r\nreturn;\r\n}\r\npwsize = ilog2(PTRS_PER_PGD) << MIPS_PWSIZE_GDW_SHIFT;\r\npwsize |= ilog2(PTRS_PER_PTE) << MIPS_PWSIZE_PTW_SHIFT;\r\nif (CONFIG_PGTABLE_LEVELS >= 3)\r\npwsize |= ilog2(PTRS_PER_PMD) << MIPS_PWSIZE_MDW_SHIFT;\r\nif (IS_ENABLED(CONFIG_64BIT))\r\npwsize |= MIPS_PWSIZE_PS_MASK;\r\npwsize |= ((PTE_T_LOG2 - PGD_T_LOG2) << MIPS_PWSIZE_PTEW_SHIFT)\r\n& MIPS_PWSIZE_PTEW_MASK;\r\nwrite_c0_pwsize(pwsize);\r\nback_to_back_c0_hazard();\r\nconfig = 1 << MIPS_PWCTL_PWEN_SHIFT;\r\nif (IS_ENABLED(CONFIG_64BIT))\r\nconfig |= MIPS_PWCTL_XU_MASK;\r\nwrite_c0_pwctl(config);\r\npr_info("Hardware Page Table Walker enabled\n");\r\nprint_htw_config();\r\n}\r\nstatic void config_xpa_params(void)\r\n{\r\n#ifdef CONFIG_XPA\r\nunsigned int pagegrain;\r\nif (mips_xpa_disabled) {\r\npr_info("Extended Physical Addressing (XPA) disabled\n");\r\nreturn;\r\n}\r\npagegrain = read_c0_pagegrain();\r\nwrite_c0_pagegrain(pagegrain | PG_ELPA);\r\nback_to_back_c0_hazard();\r\npagegrain = read_c0_pagegrain();\r\nif (pagegrain & PG_ELPA)\r\npr_info("Extended Physical Addressing (XPA) enabled\n");\r\nelse\r\npanic("Extended Physical Addressing (XPA) disabled");\r\n#endif\r\n}\r\nstatic void check_pabits(void)\r\n{\r\nunsigned long entry;\r\nunsigned pabits, fillbits;\r\nif (!cpu_has_rixi || !_PAGE_NO_EXEC) {\r\nreturn;\r\n}\r\nwrite_c0_entrylo0(~0ul);\r\nback_to_back_c0_hazard();\r\nentry = read_c0_entrylo0();\r\nentry &= ~((1 << MIPS_ENTRYLO_PFN_SHIFT) - 1);\r\nentry &= ~(MIPS_ENTRYLO_RI | MIPS_ENTRYLO_XI);\r\npabits = fls_long(entry) + 6;\r\nfillbits = max_t(int, (int)BITS_PER_LONG - pabits, 0);\r\nfillbits -= min_t(unsigned, fillbits, 2);\r\nif (fillbits >= ilog2(_PAGE_NO_EXEC))\r\nfill_includes_sw_bits = true;\r\npr_debug("Entry* registers contain %u fill bits\n", fillbits);\r\n}\r\nvoid build_tlb_refill_handler(void)\r\n{\r\nstatic int run_once = 0;\r\nif (IS_ENABLED(CONFIG_XPA) && !cpu_has_rixi)\r\npanic("Kernels supporting XPA currently require CPUs with RIXI");\r\noutput_pgtable_bits_defines();\r\ncheck_pabits();\r\n#ifdef CONFIG_64BIT\r\ncheck_for_high_segbits = current_cpu_data.vmbits > (PGDIR_SHIFT + PGD_ORDER + PAGE_SHIFT - 3);\r\n#endif\r\nswitch (current_cpu_type()) {\r\ncase CPU_R2000:\r\ncase CPU_R3000:\r\ncase CPU_R3000A:\r\ncase CPU_R3081E:\r\ncase CPU_TX3912:\r\ncase CPU_TX3922:\r\ncase CPU_TX3927:\r\n#ifndef CONFIG_MIPS_PGD_C0_CONTEXT\r\nif (cpu_has_local_ebase)\r\nbuild_r3000_tlb_refill_handler();\r\nif (!run_once) {\r\nif (!cpu_has_local_ebase)\r\nbuild_r3000_tlb_refill_handler();\r\nbuild_setup_pgd();\r\nbuild_r3000_tlb_load_handler();\r\nbuild_r3000_tlb_store_handler();\r\nbuild_r3000_tlb_modify_handler();\r\nflush_tlb_handlers();\r\nrun_once++;\r\n}\r\n#else\r\npanic("No R3000 TLB refill handler");\r\n#endif\r\nbreak;\r\ncase CPU_R6000:\r\ncase CPU_R6000A:\r\npanic("No R6000 TLB refill handler yet");\r\nbreak;\r\ncase CPU_R8000:\r\npanic("No R8000 TLB refill handler yet");\r\nbreak;\r\ndefault:\r\nif (cpu_has_ldpte)\r\nsetup_pw();\r\nif (!run_once) {\r\nscratch_reg = allocate_kscratch();\r\nbuild_setup_pgd();\r\nbuild_r4000_tlb_load_handler();\r\nbuild_r4000_tlb_store_handler();\r\nbuild_r4000_tlb_modify_handler();\r\nif (cpu_has_ldpte)\r\nbuild_loongson3_tlb_refill_handler();\r\nelse if (!cpu_has_local_ebase)\r\nbuild_r4000_tlb_refill_handler();\r\nflush_tlb_handlers();\r\nrun_once++;\r\n}\r\nif (cpu_has_local_ebase)\r\nbuild_r4000_tlb_refill_handler();\r\nif (cpu_has_xpa)\r\nconfig_xpa_params();\r\nif (cpu_has_htw)\r\nconfig_htw_params();\r\n}\r\n}
