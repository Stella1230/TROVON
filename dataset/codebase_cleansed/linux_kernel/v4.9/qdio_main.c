static inline int do_siga_sync(unsigned long schid,\r\nunsigned int out_mask, unsigned int in_mask,\r\nunsigned int fc)\r\n{\r\nregister unsigned long __fc asm ("0") = fc;\r\nregister unsigned long __schid asm ("1") = schid;\r\nregister unsigned long out asm ("2") = out_mask;\r\nregister unsigned long in asm ("3") = in_mask;\r\nint cc;\r\nasm volatile(\r\n" siga 0\n"\r\n" ipm %0\n"\r\n" srl %0,28\n"\r\n: "=d" (cc)\r\n: "d" (__fc), "d" (__schid), "d" (out), "d" (in) : "cc");\r\nreturn cc;\r\n}\r\nstatic inline int do_siga_input(unsigned long schid, unsigned int mask,\r\nunsigned int fc)\r\n{\r\nregister unsigned long __fc asm ("0") = fc;\r\nregister unsigned long __schid asm ("1") = schid;\r\nregister unsigned long __mask asm ("2") = mask;\r\nint cc;\r\nasm volatile(\r\n" siga 0\n"\r\n" ipm %0\n"\r\n" srl %0,28\n"\r\n: "=d" (cc)\r\n: "d" (__fc), "d" (__schid), "d" (__mask) : "cc");\r\nreturn cc;\r\n}\r\nstatic inline int do_siga_output(unsigned long schid, unsigned long mask,\r\nunsigned int *bb, unsigned int fc,\r\nunsigned long aob)\r\n{\r\nregister unsigned long __fc asm("0") = fc;\r\nregister unsigned long __schid asm("1") = schid;\r\nregister unsigned long __mask asm("2") = mask;\r\nregister unsigned long __aob asm("3") = aob;\r\nint cc;\r\nasm volatile(\r\n" siga 0\n"\r\n" ipm %0\n"\r\n" srl %0,28\n"\r\n: "=d" (cc), "+d" (__fc), "+d" (__aob)\r\n: "d" (__schid), "d" (__mask)\r\n: "cc");\r\n*bb = __fc >> 31;\r\nreturn cc;\r\n}\r\nstatic inline int qdio_check_ccq(struct qdio_q *q, unsigned int ccq)\r\n{\r\nif (ccq == 0 || ccq == 32)\r\nreturn 0;\r\nif (ccq == 97)\r\nreturn 1;\r\nif (ccq == 96)\r\nreturn 2;\r\nDBF_ERROR("%4x ccq:%3d", SCH_NO(q), ccq);\r\nreturn -EIO;\r\n}\r\nstatic int qdio_do_eqbs(struct qdio_q *q, unsigned char *state,\r\nint start, int count, int auto_ack)\r\n{\r\nint rc, tmp_count = count, tmp_start = start, nr = q->nr, retried = 0;\r\nunsigned int ccq = 0;\r\nqperf_inc(q, eqbs);\r\nif (!q->is_input_q)\r\nnr += q->irq_ptr->nr_input_qs;\r\nagain:\r\nccq = do_eqbs(q->irq_ptr->sch_token, state, nr, &tmp_start, &tmp_count,\r\nauto_ack);\r\nrc = qdio_check_ccq(q, ccq);\r\nif (!rc)\r\nreturn count - tmp_count;\r\nif (rc == 1) {\r\nDBF_DEV_EVENT(DBF_WARN, q->irq_ptr, "EQBS again:%2d", ccq);\r\ngoto again;\r\n}\r\nif (rc == 2) {\r\nqperf_inc(q, eqbs_partial);\r\nDBF_DEV_EVENT(DBF_WARN, q->irq_ptr, "EQBS part:%02x",\r\ntmp_count);\r\nif (!retried++)\r\ngoto again;\r\nelse\r\nreturn count - tmp_count;\r\n}\r\nDBF_ERROR("%4x EQBS ERROR", SCH_NO(q));\r\nDBF_ERROR("%3d%3d%2d", count, tmp_count, nr);\r\nq->handler(q->irq_ptr->cdev, QDIO_ERROR_GET_BUF_STATE,\r\nq->nr, q->first_to_kick, count, q->irq_ptr->int_parm);\r\nreturn 0;\r\n}\r\nstatic int qdio_do_sqbs(struct qdio_q *q, unsigned char state, int start,\r\nint count)\r\n{\r\nunsigned int ccq = 0;\r\nint tmp_count = count, tmp_start = start;\r\nint nr = q->nr;\r\nint rc;\r\nif (!count)\r\nreturn 0;\r\nqperf_inc(q, sqbs);\r\nif (!q->is_input_q)\r\nnr += q->irq_ptr->nr_input_qs;\r\nagain:\r\nccq = do_sqbs(q->irq_ptr->sch_token, state, nr, &tmp_start, &tmp_count);\r\nrc = qdio_check_ccq(q, ccq);\r\nif (!rc) {\r\nWARN_ON_ONCE(tmp_count);\r\nreturn count - tmp_count;\r\n}\r\nif (rc == 1 || rc == 2) {\r\nDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "SQBS again:%2d", ccq);\r\nqperf_inc(q, sqbs_partial);\r\ngoto again;\r\n}\r\nDBF_ERROR("%4x SQBS ERROR", SCH_NO(q));\r\nDBF_ERROR("%3d%3d%2d", count, tmp_count, nr);\r\nq->handler(q->irq_ptr->cdev, QDIO_ERROR_SET_BUF_STATE,\r\nq->nr, q->first_to_kick, count, q->irq_ptr->int_parm);\r\nreturn 0;\r\n}\r\nstatic inline int get_buf_states(struct qdio_q *q, unsigned int bufnr,\r\nunsigned char *state, unsigned int count,\r\nint auto_ack, int merge_pending)\r\n{\r\nunsigned char __state = 0;\r\nint i;\r\nif (is_qebsm(q))\r\nreturn qdio_do_eqbs(q, state, bufnr, count, auto_ack);\r\nfor (i = 0; i < count; i++) {\r\nif (!__state) {\r\n__state = q->slsb.val[bufnr];\r\nif (merge_pending && __state == SLSB_P_OUTPUT_PENDING)\r\n__state = SLSB_P_OUTPUT_EMPTY;\r\n} else if (merge_pending) {\r\nif ((q->slsb.val[bufnr] & __state) != __state)\r\nbreak;\r\n} else if (q->slsb.val[bufnr] != __state)\r\nbreak;\r\nbufnr = next_buf(bufnr);\r\n}\r\n*state = __state;\r\nreturn i;\r\n}\r\nstatic inline int get_buf_state(struct qdio_q *q, unsigned int bufnr,\r\nunsigned char *state, int auto_ack)\r\n{\r\nreturn get_buf_states(q, bufnr, state, 1, auto_ack, 0);\r\n}\r\nstatic inline int set_buf_states(struct qdio_q *q, int bufnr,\r\nunsigned char state, int count)\r\n{\r\nint i;\r\nif (is_qebsm(q))\r\nreturn qdio_do_sqbs(q, state, bufnr, count);\r\nfor (i = 0; i < count; i++) {\r\nxchg(&q->slsb.val[bufnr], state);\r\nbufnr = next_buf(bufnr);\r\n}\r\nreturn count;\r\n}\r\nstatic inline int set_buf_state(struct qdio_q *q, int bufnr,\r\nunsigned char state)\r\n{\r\nreturn set_buf_states(q, bufnr, state, 1);\r\n}\r\nstatic void qdio_init_buf_states(struct qdio_irq *irq_ptr)\r\n{\r\nstruct qdio_q *q;\r\nint i;\r\nfor_each_input_queue(irq_ptr, q, i)\r\nset_buf_states(q, 0, SLSB_P_INPUT_NOT_INIT,\r\nQDIO_MAX_BUFFERS_PER_Q);\r\nfor_each_output_queue(irq_ptr, q, i)\r\nset_buf_states(q, 0, SLSB_P_OUTPUT_NOT_INIT,\r\nQDIO_MAX_BUFFERS_PER_Q);\r\n}\r\nstatic inline int qdio_siga_sync(struct qdio_q *q, unsigned int output,\r\nunsigned int input)\r\n{\r\nunsigned long schid = *((u32 *) &q->irq_ptr->schid);\r\nunsigned int fc = QDIO_SIGA_SYNC;\r\nint cc;\r\nDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-s:%1d", q->nr);\r\nqperf_inc(q, siga_sync);\r\nif (is_qebsm(q)) {\r\nschid = q->irq_ptr->sch_token;\r\nfc |= QDIO_SIGA_QEBSM_FLAG;\r\n}\r\ncc = do_siga_sync(schid, output, input, fc);\r\nif (unlikely(cc))\r\nDBF_ERROR("%4x SIGA-S:%2d", SCH_NO(q), cc);\r\nreturn (cc) ? -EIO : 0;\r\n}\r\nstatic inline int qdio_siga_sync_q(struct qdio_q *q)\r\n{\r\nif (q->is_input_q)\r\nreturn qdio_siga_sync(q, 0, q->mask);\r\nelse\r\nreturn qdio_siga_sync(q, q->mask, 0);\r\n}\r\nstatic int qdio_siga_output(struct qdio_q *q, unsigned int *busy_bit,\r\nunsigned long aob)\r\n{\r\nunsigned long schid = *((u32 *) &q->irq_ptr->schid);\r\nunsigned int fc = QDIO_SIGA_WRITE;\r\nu64 start_time = 0;\r\nint retries = 0, cc;\r\nunsigned long laob = 0;\r\nWARN_ON_ONCE(aob && ((queue_type(q) != QDIO_IQDIO_QFMT) ||\r\n!q->u.out.use_cq));\r\nif (q->u.out.use_cq && aob != 0) {\r\nfc = QDIO_SIGA_WRITEQ;\r\nlaob = aob;\r\n}\r\nif (is_qebsm(q)) {\r\nschid = q->irq_ptr->sch_token;\r\nfc |= QDIO_SIGA_QEBSM_FLAG;\r\n}\r\nagain:\r\ncc = do_siga_output(schid, q->mask, busy_bit, fc, laob);\r\nif (unlikely(*busy_bit)) {\r\nretries++;\r\nif (!start_time) {\r\nstart_time = get_tod_clock_fast();\r\ngoto again;\r\n}\r\nif (get_tod_clock_fast() - start_time < QDIO_BUSY_BIT_PATIENCE)\r\ngoto again;\r\n}\r\nif (retries) {\r\nDBF_DEV_EVENT(DBF_WARN, q->irq_ptr,\r\n"%4x cc2 BB1:%1d", SCH_NO(q), q->nr);\r\nDBF_DEV_EVENT(DBF_WARN, q->irq_ptr, "count:%u", retries);\r\n}\r\nreturn cc;\r\n}\r\nstatic inline int qdio_siga_input(struct qdio_q *q)\r\n{\r\nunsigned long schid = *((u32 *) &q->irq_ptr->schid);\r\nunsigned int fc = QDIO_SIGA_READ;\r\nint cc;\r\nDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-r:%1d", q->nr);\r\nqperf_inc(q, siga_read);\r\nif (is_qebsm(q)) {\r\nschid = q->irq_ptr->sch_token;\r\nfc |= QDIO_SIGA_QEBSM_FLAG;\r\n}\r\ncc = do_siga_input(schid, q->mask, fc);\r\nif (unlikely(cc))\r\nDBF_ERROR("%4x SIGA-R:%2d", SCH_NO(q), cc);\r\nreturn (cc) ? -EIO : 0;\r\n}\r\nstatic inline void qdio_sync_queues(struct qdio_q *q)\r\n{\r\nif (pci_out_supported(q))\r\nqdio_siga_sync_all(q);\r\nelse\r\nqdio_siga_sync_q(q);\r\n}\r\nint debug_get_buf_state(struct qdio_q *q, unsigned int bufnr,\r\nunsigned char *state)\r\n{\r\nif (need_siga_sync(q))\r\nqdio_siga_sync_q(q);\r\nreturn get_buf_states(q, bufnr, state, 1, 0, 0);\r\n}\r\nstatic inline void qdio_stop_polling(struct qdio_q *q)\r\n{\r\nif (!q->u.in.polling)\r\nreturn;\r\nq->u.in.polling = 0;\r\nqperf_inc(q, stop_polling);\r\nif (is_qebsm(q)) {\r\nset_buf_states(q, q->u.in.ack_start, SLSB_P_INPUT_NOT_INIT,\r\nq->u.in.ack_count);\r\nq->u.in.ack_count = 0;\r\n} else\r\nset_buf_state(q, q->u.in.ack_start, SLSB_P_INPUT_NOT_INIT);\r\n}\r\nstatic inline void account_sbals(struct qdio_q *q, unsigned int count)\r\n{\r\nint pos;\r\nq->q_stats.nr_sbal_total += count;\r\nif (count == QDIO_MAX_BUFFERS_MASK) {\r\nq->q_stats.nr_sbals[7]++;\r\nreturn;\r\n}\r\npos = ilog2(count);\r\nq->q_stats.nr_sbals[pos]++;\r\n}\r\nstatic void process_buffer_error(struct qdio_q *q, int count)\r\n{\r\nunsigned char state = (q->is_input_q) ? SLSB_P_INPUT_NOT_INIT :\r\nSLSB_P_OUTPUT_NOT_INIT;\r\nq->qdio_error = QDIO_ERROR_SLSB_STATE;\r\nif ((!q->is_input_q &&\r\n(q->sbal[q->first_to_check]->element[15].sflags) == 0x10)) {\r\nqperf_inc(q, target_full);\r\nDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "OUTFULL FTC:%02x",\r\nq->first_to_check);\r\ngoto set;\r\n}\r\nDBF_ERROR("%4x BUF ERROR", SCH_NO(q));\r\nDBF_ERROR((q->is_input_q) ? "IN:%2d" : "OUT:%2d", q->nr);\r\nDBF_ERROR("FTC:%3d C:%3d", q->first_to_check, count);\r\nDBF_ERROR("F14:%2x F15:%2x",\r\nq->sbal[q->first_to_check]->element[14].sflags,\r\nq->sbal[q->first_to_check]->element[15].sflags);\r\nset:\r\nset_buf_states(q, q->first_to_check, state, count);\r\n}\r\nstatic inline void inbound_primed(struct qdio_q *q, int count)\r\n{\r\nint new;\r\nDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in prim: %02x", count);\r\nif (is_qebsm(q)) {\r\nif (!q->u.in.polling) {\r\nq->u.in.polling = 1;\r\nq->u.in.ack_count = count;\r\nq->u.in.ack_start = q->first_to_check;\r\nreturn;\r\n}\r\nset_buf_states(q, q->u.in.ack_start, SLSB_P_INPUT_NOT_INIT,\r\nq->u.in.ack_count);\r\nq->u.in.ack_count = count;\r\nq->u.in.ack_start = q->first_to_check;\r\nreturn;\r\n}\r\nnew = add_buf(q->first_to_check, count - 1);\r\nif (q->u.in.polling) {\r\nset_buf_state(q, new, SLSB_P_INPUT_ACK);\r\nset_buf_state(q, q->u.in.ack_start, SLSB_P_INPUT_NOT_INIT);\r\n} else {\r\nq->u.in.polling = 1;\r\nset_buf_state(q, new, SLSB_P_INPUT_ACK);\r\n}\r\nq->u.in.ack_start = new;\r\ncount--;\r\nif (!count)\r\nreturn;\r\nset_buf_states(q, q->first_to_check, SLSB_P_INPUT_NOT_INIT, count);\r\n}\r\nstatic int get_inbound_buffer_frontier(struct qdio_q *q)\r\n{\r\nint count, stop;\r\nunsigned char state = 0;\r\nq->timestamp = get_tod_clock_fast();\r\ncount = min(atomic_read(&q->nr_buf_used), QDIO_MAX_BUFFERS_MASK);\r\nstop = add_buf(q->first_to_check, count);\r\nif (q->first_to_check == stop)\r\ngoto out;\r\ncount = get_buf_states(q, q->first_to_check, &state, count, 1, 0);\r\nif (!count)\r\ngoto out;\r\nswitch (state) {\r\ncase SLSB_P_INPUT_PRIMED:\r\ninbound_primed(q, count);\r\nq->first_to_check = add_buf(q->first_to_check, count);\r\nif (atomic_sub_return(count, &q->nr_buf_used) == 0)\r\nqperf_inc(q, inbound_queue_full);\r\nif (q->irq_ptr->perf_stat_enabled)\r\naccount_sbals(q, count);\r\nbreak;\r\ncase SLSB_P_INPUT_ERROR:\r\nprocess_buffer_error(q, count);\r\nq->first_to_check = add_buf(q->first_to_check, count);\r\natomic_sub(count, &q->nr_buf_used);\r\nif (q->irq_ptr->perf_stat_enabled)\r\naccount_sbals_error(q, count);\r\nbreak;\r\ncase SLSB_CU_INPUT_EMPTY:\r\ncase SLSB_P_INPUT_NOT_INIT:\r\ncase SLSB_P_INPUT_ACK:\r\nif (q->irq_ptr->perf_stat_enabled)\r\nq->q_stats.nr_sbal_nop++;\r\nDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in nop");\r\nbreak;\r\ndefault:\r\nWARN_ON_ONCE(1);\r\n}\r\nout:\r\nreturn q->first_to_check;\r\n}\r\nstatic int qdio_inbound_q_moved(struct qdio_q *q)\r\n{\r\nint bufnr;\r\nbufnr = get_inbound_buffer_frontier(q);\r\nif (bufnr != q->last_move) {\r\nq->last_move = bufnr;\r\nif (!is_thinint_irq(q->irq_ptr) && MACHINE_IS_LPAR)\r\nq->u.in.timestamp = get_tod_clock();\r\nreturn 1;\r\n} else\r\nreturn 0;\r\n}\r\nstatic inline int qdio_inbound_q_done(struct qdio_q *q)\r\n{\r\nunsigned char state = 0;\r\nif (!atomic_read(&q->nr_buf_used))\r\nreturn 1;\r\nif (need_siga_sync(q))\r\nqdio_siga_sync_q(q);\r\nget_buf_state(q, q->first_to_check, &state, 0);\r\nif (state == SLSB_P_INPUT_PRIMED || state == SLSB_P_INPUT_ERROR)\r\nreturn 0;\r\nif (is_thinint_irq(q->irq_ptr))\r\nreturn 1;\r\nif (MACHINE_IS_VM)\r\nreturn 1;\r\nif (get_tod_clock_fast() > q->u.in.timestamp + QDIO_INPUT_THRESHOLD) {\r\nDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "in done:%02x",\r\nq->first_to_check);\r\nreturn 1;\r\n} else\r\nreturn 0;\r\n}\r\nstatic inline int contains_aobs(struct qdio_q *q)\r\n{\r\nreturn !q->is_input_q && q->u.out.use_cq;\r\n}\r\nstatic inline void qdio_handle_aobs(struct qdio_q *q, int start, int count)\r\n{\r\nunsigned char state = 0;\r\nint j, b = start;\r\nif (!contains_aobs(q))\r\nreturn;\r\nfor (j = 0; j < count; ++j) {\r\nget_buf_state(q, b, &state, 0);\r\nif (state == SLSB_P_OUTPUT_PENDING) {\r\nstruct qaob *aob = q->u.out.aobs[b];\r\nif (aob == NULL)\r\ncontinue;\r\nq->u.out.sbal_state[b].flags |=\r\nQDIO_OUTBUF_STATE_FLAG_PENDING;\r\nq->u.out.aobs[b] = NULL;\r\n} else if (state == SLSB_P_OUTPUT_EMPTY) {\r\nq->u.out.sbal_state[b].aob = NULL;\r\n}\r\nb = next_buf(b);\r\n}\r\n}\r\nstatic inline unsigned long qdio_aob_for_buffer(struct qdio_output_q *q,\r\nint bufnr)\r\n{\r\nunsigned long phys_aob = 0;\r\nif (!q->use_cq)\r\ngoto out;\r\nif (!q->aobs[bufnr]) {\r\nstruct qaob *aob = qdio_allocate_aob();\r\nq->aobs[bufnr] = aob;\r\n}\r\nif (q->aobs[bufnr]) {\r\nq->sbal_state[bufnr].flags = QDIO_OUTBUF_STATE_FLAG_NONE;\r\nq->sbal_state[bufnr].aob = q->aobs[bufnr];\r\nq->aobs[bufnr]->user1 = (u64) q->sbal_state[bufnr].user;\r\nphys_aob = virt_to_phys(q->aobs[bufnr]);\r\nWARN_ON_ONCE(phys_aob & 0xFF);\r\n}\r\nout:\r\nreturn phys_aob;\r\n}\r\nstatic void qdio_kick_handler(struct qdio_q *q)\r\n{\r\nint start = q->first_to_kick;\r\nint end = q->first_to_check;\r\nint count;\r\nif (unlikely(q->irq_ptr->state != QDIO_IRQ_STATE_ACTIVE))\r\nreturn;\r\ncount = sub_buf(end, start);\r\nif (q->is_input_q) {\r\nqperf_inc(q, inbound_handler);\r\nDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "kih s:%02x c:%02x", start, count);\r\n} else {\r\nqperf_inc(q, outbound_handler);\r\nDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "koh: s:%02x c:%02x",\r\nstart, count);\r\n}\r\nqdio_handle_aobs(q, start, count);\r\nq->handler(q->irq_ptr->cdev, q->qdio_error, q->nr, start, count,\r\nq->irq_ptr->int_parm);\r\nq->first_to_kick = end;\r\nq->qdio_error = 0;\r\n}\r\nstatic inline int qdio_tasklet_schedule(struct qdio_q *q)\r\n{\r\nif (likely(q->irq_ptr->state == QDIO_IRQ_STATE_ACTIVE)) {\r\ntasklet_schedule(&q->tasklet);\r\nreturn 0;\r\n}\r\nreturn -EPERM;\r\n}\r\nstatic void __qdio_inbound_processing(struct qdio_q *q)\r\n{\r\nqperf_inc(q, tasklet_inbound);\r\nif (!qdio_inbound_q_moved(q))\r\nreturn;\r\nqdio_kick_handler(q);\r\nif (!qdio_inbound_q_done(q)) {\r\nqperf_inc(q, tasklet_inbound_resched);\r\nif (!qdio_tasklet_schedule(q))\r\nreturn;\r\n}\r\nqdio_stop_polling(q);\r\nif (!qdio_inbound_q_done(q)) {\r\nqperf_inc(q, tasklet_inbound_resched2);\r\nqdio_tasklet_schedule(q);\r\n}\r\n}\r\nvoid qdio_inbound_processing(unsigned long data)\r\n{\r\nstruct qdio_q *q = (struct qdio_q *)data;\r\n__qdio_inbound_processing(q);\r\n}\r\nstatic int get_outbound_buffer_frontier(struct qdio_q *q)\r\n{\r\nint count, stop;\r\nunsigned char state = 0;\r\nq->timestamp = get_tod_clock_fast();\r\nif (need_siga_sync(q))\r\nif (((queue_type(q) != QDIO_IQDIO_QFMT) &&\r\n!pci_out_supported(q)) ||\r\n(queue_type(q) == QDIO_IQDIO_QFMT &&\r\nmulticast_outbound(q)))\r\nqdio_siga_sync_q(q);\r\ncount = min(atomic_read(&q->nr_buf_used), QDIO_MAX_BUFFERS_MASK);\r\nstop = add_buf(q->first_to_check, count);\r\nif (q->first_to_check == stop)\r\ngoto out;\r\ncount = get_buf_states(q, q->first_to_check, &state, count, 0, 1);\r\nif (!count)\r\ngoto out;\r\nswitch (state) {\r\ncase SLSB_P_OUTPUT_EMPTY:\r\nDBF_DEV_EVENT(DBF_INFO, q->irq_ptr,\r\n"out empty:%1d %02x", q->nr, count);\r\natomic_sub(count, &q->nr_buf_used);\r\nq->first_to_check = add_buf(q->first_to_check, count);\r\nif (q->irq_ptr->perf_stat_enabled)\r\naccount_sbals(q, count);\r\nbreak;\r\ncase SLSB_P_OUTPUT_ERROR:\r\nprocess_buffer_error(q, count);\r\nq->first_to_check = add_buf(q->first_to_check, count);\r\natomic_sub(count, &q->nr_buf_used);\r\nif (q->irq_ptr->perf_stat_enabled)\r\naccount_sbals_error(q, count);\r\nbreak;\r\ncase SLSB_CU_OUTPUT_PRIMED:\r\nif (q->irq_ptr->perf_stat_enabled)\r\nq->q_stats.nr_sbal_nop++;\r\nDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "out primed:%1d",\r\nq->nr);\r\nbreak;\r\ncase SLSB_P_OUTPUT_NOT_INIT:\r\ncase SLSB_P_OUTPUT_HALTED:\r\nbreak;\r\ndefault:\r\nWARN_ON_ONCE(1);\r\n}\r\nout:\r\nreturn q->first_to_check;\r\n}\r\nstatic inline int qdio_outbound_q_done(struct qdio_q *q)\r\n{\r\nreturn atomic_read(&q->nr_buf_used) == 0;\r\n}\r\nstatic inline int qdio_outbound_q_moved(struct qdio_q *q)\r\n{\r\nint bufnr;\r\nbufnr = get_outbound_buffer_frontier(q);\r\nif (bufnr != q->last_move) {\r\nq->last_move = bufnr;\r\nDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "out moved:%1d", q->nr);\r\nreturn 1;\r\n} else\r\nreturn 0;\r\n}\r\nstatic int qdio_kick_outbound_q(struct qdio_q *q, unsigned long aob)\r\n{\r\nint retries = 0, cc;\r\nunsigned int busy_bit;\r\nif (!need_siga_out(q))\r\nreturn 0;\r\nDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-w:%1d", q->nr);\r\nretry:\r\nqperf_inc(q, siga_write);\r\ncc = qdio_siga_output(q, &busy_bit, aob);\r\nswitch (cc) {\r\ncase 0:\r\nbreak;\r\ncase 2:\r\nif (busy_bit) {\r\nwhile (++retries < QDIO_BUSY_BIT_RETRIES) {\r\nmdelay(QDIO_BUSY_BIT_RETRY_DELAY);\r\ngoto retry;\r\n}\r\nDBF_ERROR("%4x cc2 BBC:%1d", SCH_NO(q), q->nr);\r\ncc = -EBUSY;\r\n} else {\r\nDBF_DEV_EVENT(DBF_INFO, q->irq_ptr, "siga-w cc2:%1d", q->nr);\r\ncc = -ENOBUFS;\r\n}\r\nbreak;\r\ncase 1:\r\ncase 3:\r\nDBF_ERROR("%4x SIGA-W:%1d", SCH_NO(q), cc);\r\ncc = -EIO;\r\nbreak;\r\n}\r\nif (retries) {\r\nDBF_ERROR("%4x cc2 BB2:%1d", SCH_NO(q), q->nr);\r\nDBF_ERROR("count:%u", retries);\r\n}\r\nreturn cc;\r\n}\r\nstatic void __qdio_outbound_processing(struct qdio_q *q)\r\n{\r\nqperf_inc(q, tasklet_outbound);\r\nWARN_ON_ONCE(atomic_read(&q->nr_buf_used) < 0);\r\nif (qdio_outbound_q_moved(q))\r\nqdio_kick_handler(q);\r\nif (queue_type(q) == QDIO_ZFCP_QFMT)\r\nif (!pci_out_supported(q) && !qdio_outbound_q_done(q))\r\ngoto sched;\r\nif (q->u.out.pci_out_enabled)\r\nreturn;\r\nif (qdio_outbound_q_done(q))\r\ndel_timer_sync(&q->u.out.timer);\r\nelse\r\nif (!timer_pending(&q->u.out.timer) &&\r\nlikely(q->irq_ptr->state == QDIO_IRQ_STATE_ACTIVE))\r\nmod_timer(&q->u.out.timer, jiffies + 10 * HZ);\r\nreturn;\r\nsched:\r\nqdio_tasklet_schedule(q);\r\n}\r\nvoid qdio_outbound_processing(unsigned long data)\r\n{\r\nstruct qdio_q *q = (struct qdio_q *)data;\r\n__qdio_outbound_processing(q);\r\n}\r\nvoid qdio_outbound_timer(unsigned long data)\r\n{\r\nstruct qdio_q *q = (struct qdio_q *)data;\r\nqdio_tasklet_schedule(q);\r\n}\r\nstatic inline void qdio_check_outbound_after_thinint(struct qdio_q *q)\r\n{\r\nstruct qdio_q *out;\r\nint i;\r\nif (!pci_out_supported(q))\r\nreturn;\r\nfor_each_output_queue(q->irq_ptr, out, i)\r\nif (!qdio_outbound_q_done(out))\r\nqdio_tasklet_schedule(out);\r\n}\r\nstatic void __tiqdio_inbound_processing(struct qdio_q *q)\r\n{\r\nqperf_inc(q, tasklet_inbound);\r\nif (need_siga_sync(q) && need_siga_sync_after_ai(q))\r\nqdio_sync_queues(q);\r\nqdio_check_outbound_after_thinint(q);\r\nif (!qdio_inbound_q_moved(q))\r\nreturn;\r\nqdio_kick_handler(q);\r\nif (!qdio_inbound_q_done(q)) {\r\nqperf_inc(q, tasklet_inbound_resched);\r\nif (!qdio_tasklet_schedule(q))\r\nreturn;\r\n}\r\nqdio_stop_polling(q);\r\nif (!qdio_inbound_q_done(q)) {\r\nqperf_inc(q, tasklet_inbound_resched2);\r\nqdio_tasklet_schedule(q);\r\n}\r\n}\r\nvoid tiqdio_inbound_processing(unsigned long data)\r\n{\r\nstruct qdio_q *q = (struct qdio_q *)data;\r\n__tiqdio_inbound_processing(q);\r\n}\r\nstatic inline void qdio_set_state(struct qdio_irq *irq_ptr,\r\nenum qdio_irq_states state)\r\n{\r\nDBF_DEV_EVENT(DBF_INFO, irq_ptr, "newstate: %1d", state);\r\nirq_ptr->state = state;\r\nmb();\r\n}\r\nstatic void qdio_irq_check_sense(struct qdio_irq *irq_ptr, struct irb *irb)\r\n{\r\nif (irb->esw.esw0.erw.cons) {\r\nDBF_ERROR("%4x sense:", irq_ptr->schid.sch_no);\r\nDBF_ERROR_HEX(irb, 64);\r\nDBF_ERROR_HEX(irb->ecw, 64);\r\n}\r\n}\r\nstatic void qdio_int_handler_pci(struct qdio_irq *irq_ptr)\r\n{\r\nint i;\r\nstruct qdio_q *q;\r\nif (unlikely(irq_ptr->state != QDIO_IRQ_STATE_ACTIVE))\r\nreturn;\r\nfor_each_input_queue(irq_ptr, q, i) {\r\nif (q->u.in.queue_start_poll) {\r\nif (test_and_set_bit(QDIO_QUEUE_IRQS_DISABLED,\r\n&q->u.in.queue_irq_state)) {\r\nqperf_inc(q, int_discarded);\r\ncontinue;\r\n}\r\nq->u.in.queue_start_poll(q->irq_ptr->cdev, q->nr,\r\nq->irq_ptr->int_parm);\r\n} else {\r\ntasklet_schedule(&q->tasklet);\r\n}\r\n}\r\nif (!(irq_ptr->qib.ac & QIB_AC_OUTBOUND_PCI_SUPPORTED))\r\nreturn;\r\nfor_each_output_queue(irq_ptr, q, i) {\r\nif (qdio_outbound_q_done(q))\r\ncontinue;\r\nif (need_siga_sync(q) && need_siga_sync_out_after_pci(q))\r\nqdio_siga_sync_q(q);\r\nqdio_tasklet_schedule(q);\r\n}\r\n}\r\nstatic void qdio_handle_activate_check(struct ccw_device *cdev,\r\nunsigned long intparm, int cstat, int dstat)\r\n{\r\nstruct qdio_irq *irq_ptr = cdev->private->qdio_data;\r\nstruct qdio_q *q;\r\nint count;\r\nDBF_ERROR("%4x ACT CHECK", irq_ptr->schid.sch_no);\r\nDBF_ERROR("intp :%lx", intparm);\r\nDBF_ERROR("ds: %2x cs:%2x", dstat, cstat);\r\nif (irq_ptr->nr_input_qs) {\r\nq = irq_ptr->input_qs[0];\r\n} else if (irq_ptr->nr_output_qs) {\r\nq = irq_ptr->output_qs[0];\r\n} else {\r\ndump_stack();\r\ngoto no_handler;\r\n}\r\ncount = sub_buf(q->first_to_check, q->first_to_kick);\r\nq->handler(q->irq_ptr->cdev, QDIO_ERROR_ACTIVATE,\r\nq->nr, q->first_to_kick, count, irq_ptr->int_parm);\r\nno_handler:\r\nqdio_set_state(irq_ptr, QDIO_IRQ_STATE_STOPPED);\r\nlgr_info_log();\r\n}\r\nstatic void qdio_establish_handle_irq(struct ccw_device *cdev, int cstat,\r\nint dstat)\r\n{\r\nstruct qdio_irq *irq_ptr = cdev->private->qdio_data;\r\nDBF_DEV_EVENT(DBF_INFO, irq_ptr, "qest irq");\r\nif (cstat)\r\ngoto error;\r\nif (dstat & ~(DEV_STAT_DEV_END | DEV_STAT_CHN_END))\r\ngoto error;\r\nif (!(dstat & DEV_STAT_DEV_END))\r\ngoto error;\r\nqdio_set_state(irq_ptr, QDIO_IRQ_STATE_ESTABLISHED);\r\nreturn;\r\nerror:\r\nDBF_ERROR("%4x EQ:error", irq_ptr->schid.sch_no);\r\nDBF_ERROR("ds: %2x cs:%2x", dstat, cstat);\r\nqdio_set_state(irq_ptr, QDIO_IRQ_STATE_ERR);\r\n}\r\nvoid qdio_int_handler(struct ccw_device *cdev, unsigned long intparm,\r\nstruct irb *irb)\r\n{\r\nstruct qdio_irq *irq_ptr = cdev->private->qdio_data;\r\nstruct subchannel_id schid;\r\nint cstat, dstat;\r\nif (!intparm || !irq_ptr) {\r\nccw_device_get_schid(cdev, &schid);\r\nDBF_ERROR("qint:%4x", schid.sch_no);\r\nreturn;\r\n}\r\nif (irq_ptr->perf_stat_enabled)\r\nirq_ptr->perf_stat.qdio_int++;\r\nif (IS_ERR(irb)) {\r\nDBF_ERROR("%4x IO error", irq_ptr->schid.sch_no);\r\nqdio_set_state(irq_ptr, QDIO_IRQ_STATE_ERR);\r\nwake_up(&cdev->private->wait_q);\r\nreturn;\r\n}\r\nqdio_irq_check_sense(irq_ptr, irb);\r\ncstat = irb->scsw.cmd.cstat;\r\ndstat = irb->scsw.cmd.dstat;\r\nswitch (irq_ptr->state) {\r\ncase QDIO_IRQ_STATE_INACTIVE:\r\nqdio_establish_handle_irq(cdev, cstat, dstat);\r\nbreak;\r\ncase QDIO_IRQ_STATE_CLEANUP:\r\nqdio_set_state(irq_ptr, QDIO_IRQ_STATE_INACTIVE);\r\nbreak;\r\ncase QDIO_IRQ_STATE_ESTABLISHED:\r\ncase QDIO_IRQ_STATE_ACTIVE:\r\nif (cstat & SCHN_STAT_PCI) {\r\nqdio_int_handler_pci(irq_ptr);\r\nreturn;\r\n}\r\nif (cstat || dstat)\r\nqdio_handle_activate_check(cdev, intparm, cstat,\r\ndstat);\r\nbreak;\r\ncase QDIO_IRQ_STATE_STOPPED:\r\nbreak;\r\ndefault:\r\nWARN_ON_ONCE(1);\r\n}\r\nwake_up(&cdev->private->wait_q);\r\n}\r\nint qdio_get_ssqd_desc(struct ccw_device *cdev,\r\nstruct qdio_ssqd_desc *data)\r\n{\r\nstruct subchannel_id schid;\r\nif (!cdev || !cdev->private)\r\nreturn -EINVAL;\r\nccw_device_get_schid(cdev, &schid);\r\nDBF_EVENT("get ssqd:%4x", schid.sch_no);\r\nreturn qdio_setup_get_ssqd(NULL, &schid, data);\r\n}\r\nstatic void qdio_shutdown_queues(struct ccw_device *cdev)\r\n{\r\nstruct qdio_irq *irq_ptr = cdev->private->qdio_data;\r\nstruct qdio_q *q;\r\nint i;\r\nfor_each_input_queue(irq_ptr, q, i)\r\ntasklet_kill(&q->tasklet);\r\nfor_each_output_queue(irq_ptr, q, i) {\r\ndel_timer_sync(&q->u.out.timer);\r\ntasklet_kill(&q->tasklet);\r\n}\r\n}\r\nint qdio_shutdown(struct ccw_device *cdev, int how)\r\n{\r\nstruct qdio_irq *irq_ptr = cdev->private->qdio_data;\r\nstruct subchannel_id schid;\r\nint rc;\r\nif (!irq_ptr)\r\nreturn -ENODEV;\r\nWARN_ON_ONCE(irqs_disabled());\r\nccw_device_get_schid(cdev, &schid);\r\nDBF_EVENT("qshutdown:%4x", schid.sch_no);\r\nmutex_lock(&irq_ptr->setup_mutex);\r\nif (irq_ptr->state == QDIO_IRQ_STATE_INACTIVE) {\r\nmutex_unlock(&irq_ptr->setup_mutex);\r\nreturn 0;\r\n}\r\nqdio_set_state(irq_ptr, QDIO_IRQ_STATE_STOPPED);\r\ntiqdio_remove_input_queues(irq_ptr);\r\nqdio_shutdown_queues(cdev);\r\nqdio_shutdown_debug_entries(irq_ptr);\r\nspin_lock_irq(get_ccwdev_lock(cdev));\r\nif (how & QDIO_FLAG_CLEANUP_USING_CLEAR)\r\nrc = ccw_device_clear(cdev, QDIO_DOING_CLEANUP);\r\nelse\r\nrc = ccw_device_halt(cdev, QDIO_DOING_CLEANUP);\r\nif (rc) {\r\nDBF_ERROR("%4x SHUTD ERR", irq_ptr->schid.sch_no);\r\nDBF_ERROR("rc:%4d", rc);\r\ngoto no_cleanup;\r\n}\r\nqdio_set_state(irq_ptr, QDIO_IRQ_STATE_CLEANUP);\r\nspin_unlock_irq(get_ccwdev_lock(cdev));\r\nwait_event_interruptible_timeout(cdev->private->wait_q,\r\nirq_ptr->state == QDIO_IRQ_STATE_INACTIVE ||\r\nirq_ptr->state == QDIO_IRQ_STATE_ERR,\r\n10 * HZ);\r\nspin_lock_irq(get_ccwdev_lock(cdev));\r\nno_cleanup:\r\nqdio_shutdown_thinint(irq_ptr);\r\nif ((void *)cdev->handler == (void *)qdio_int_handler)\r\ncdev->handler = irq_ptr->orig_handler;\r\nspin_unlock_irq(get_ccwdev_lock(cdev));\r\nqdio_set_state(irq_ptr, QDIO_IRQ_STATE_INACTIVE);\r\nmutex_unlock(&irq_ptr->setup_mutex);\r\nif (rc)\r\nreturn rc;\r\nreturn 0;\r\n}\r\nint qdio_free(struct ccw_device *cdev)\r\n{\r\nstruct qdio_irq *irq_ptr = cdev->private->qdio_data;\r\nstruct subchannel_id schid;\r\nif (!irq_ptr)\r\nreturn -ENODEV;\r\nccw_device_get_schid(cdev, &schid);\r\nDBF_EVENT("qfree:%4x", schid.sch_no);\r\nDBF_DEV_EVENT(DBF_ERR, irq_ptr, "dbf abandoned");\r\nmutex_lock(&irq_ptr->setup_mutex);\r\nirq_ptr->debug_area = NULL;\r\ncdev->private->qdio_data = NULL;\r\nmutex_unlock(&irq_ptr->setup_mutex);\r\nqdio_release_memory(irq_ptr);\r\nreturn 0;\r\n}\r\nint qdio_allocate(struct qdio_initialize *init_data)\r\n{\r\nstruct subchannel_id schid;\r\nstruct qdio_irq *irq_ptr;\r\nccw_device_get_schid(init_data->cdev, &schid);\r\nDBF_EVENT("qallocate:%4x", schid.sch_no);\r\nif ((init_data->no_input_qs && !init_data->input_handler) ||\r\n(init_data->no_output_qs && !init_data->output_handler))\r\nreturn -EINVAL;\r\nif ((init_data->no_input_qs > QDIO_MAX_QUEUES_PER_IRQ) ||\r\n(init_data->no_output_qs > QDIO_MAX_QUEUES_PER_IRQ))\r\nreturn -EINVAL;\r\nif ((!init_data->input_sbal_addr_array) ||\r\n(!init_data->output_sbal_addr_array))\r\nreturn -EINVAL;\r\nirq_ptr = (void *) get_zeroed_page(GFP_KERNEL | GFP_DMA);\r\nif (!irq_ptr)\r\ngoto out_err;\r\nmutex_init(&irq_ptr->setup_mutex);\r\nif (qdio_allocate_dbf(init_data, irq_ptr))\r\ngoto out_rel;\r\nirq_ptr->chsc_page = get_zeroed_page(GFP_KERNEL);\r\nif (!irq_ptr->chsc_page)\r\ngoto out_rel;\r\nirq_ptr->qdr = (struct qdr *) get_zeroed_page(GFP_KERNEL | GFP_DMA);\r\nif (!irq_ptr->qdr)\r\ngoto out_rel;\r\nif (qdio_allocate_qs(irq_ptr, init_data->no_input_qs,\r\ninit_data->no_output_qs))\r\ngoto out_rel;\r\ninit_data->cdev->private->qdio_data = irq_ptr;\r\nqdio_set_state(irq_ptr, QDIO_IRQ_STATE_INACTIVE);\r\nreturn 0;\r\nout_rel:\r\nqdio_release_memory(irq_ptr);\r\nout_err:\r\nreturn -ENOMEM;\r\n}\r\nstatic void qdio_detect_hsicq(struct qdio_irq *irq_ptr)\r\n{\r\nstruct qdio_q *q = irq_ptr->input_qs[0];\r\nint i, use_cq = 0;\r\nif (irq_ptr->nr_input_qs > 1 && queue_type(q) == QDIO_IQDIO_QFMT)\r\nuse_cq = 1;\r\nfor_each_output_queue(irq_ptr, q, i) {\r\nif (use_cq) {\r\nif (qdio_enable_async_operation(&q->u.out) < 0) {\r\nuse_cq = 0;\r\ncontinue;\r\n}\r\n} else\r\nqdio_disable_async_operation(&q->u.out);\r\n}\r\nDBF_EVENT("use_cq:%d", use_cq);\r\n}\r\nint qdio_establish(struct qdio_initialize *init_data)\r\n{\r\nstruct ccw_device *cdev = init_data->cdev;\r\nstruct subchannel_id schid;\r\nstruct qdio_irq *irq_ptr;\r\nint rc;\r\nccw_device_get_schid(cdev, &schid);\r\nDBF_EVENT("qestablish:%4x", schid.sch_no);\r\nirq_ptr = cdev->private->qdio_data;\r\nif (!irq_ptr)\r\nreturn -ENODEV;\r\nmutex_lock(&irq_ptr->setup_mutex);\r\nqdio_setup_irq(init_data);\r\nrc = qdio_establish_thinint(irq_ptr);\r\nif (rc) {\r\nmutex_unlock(&irq_ptr->setup_mutex);\r\nqdio_shutdown(cdev, QDIO_FLAG_CLEANUP_USING_CLEAR);\r\nreturn rc;\r\n}\r\nirq_ptr->ccw.cmd_code = irq_ptr->equeue.cmd;\r\nirq_ptr->ccw.flags = CCW_FLAG_SLI;\r\nirq_ptr->ccw.count = irq_ptr->equeue.count;\r\nirq_ptr->ccw.cda = (u32)((addr_t)irq_ptr->qdr);\r\nspin_lock_irq(get_ccwdev_lock(cdev));\r\nccw_device_set_options_mask(cdev, 0);\r\nrc = ccw_device_start(cdev, &irq_ptr->ccw, QDIO_DOING_ESTABLISH, 0, 0);\r\nspin_unlock_irq(get_ccwdev_lock(cdev));\r\nif (rc) {\r\nDBF_ERROR("%4x est IO ERR", irq_ptr->schid.sch_no);\r\nDBF_ERROR("rc:%4x", rc);\r\nmutex_unlock(&irq_ptr->setup_mutex);\r\nqdio_shutdown(cdev, QDIO_FLAG_CLEANUP_USING_CLEAR);\r\nreturn rc;\r\n}\r\nwait_event_interruptible_timeout(cdev->private->wait_q,\r\nirq_ptr->state == QDIO_IRQ_STATE_ESTABLISHED ||\r\nirq_ptr->state == QDIO_IRQ_STATE_ERR, HZ);\r\nif (irq_ptr->state != QDIO_IRQ_STATE_ESTABLISHED) {\r\nmutex_unlock(&irq_ptr->setup_mutex);\r\nqdio_shutdown(cdev, QDIO_FLAG_CLEANUP_USING_CLEAR);\r\nreturn -EIO;\r\n}\r\nqdio_setup_ssqd_info(irq_ptr);\r\nqdio_detect_hsicq(irq_ptr);\r\nqdio_init_buf_states(irq_ptr);\r\nmutex_unlock(&irq_ptr->setup_mutex);\r\nqdio_print_subchannel_info(irq_ptr, cdev);\r\nqdio_setup_debug_entries(irq_ptr, cdev);\r\nreturn 0;\r\n}\r\nint qdio_activate(struct ccw_device *cdev)\r\n{\r\nstruct subchannel_id schid;\r\nstruct qdio_irq *irq_ptr;\r\nint rc;\r\nccw_device_get_schid(cdev, &schid);\r\nDBF_EVENT("qactivate:%4x", schid.sch_no);\r\nirq_ptr = cdev->private->qdio_data;\r\nif (!irq_ptr)\r\nreturn -ENODEV;\r\nmutex_lock(&irq_ptr->setup_mutex);\r\nif (irq_ptr->state == QDIO_IRQ_STATE_INACTIVE) {\r\nrc = -EBUSY;\r\ngoto out;\r\n}\r\nirq_ptr->ccw.cmd_code = irq_ptr->aqueue.cmd;\r\nirq_ptr->ccw.flags = CCW_FLAG_SLI;\r\nirq_ptr->ccw.count = irq_ptr->aqueue.count;\r\nirq_ptr->ccw.cda = 0;\r\nspin_lock_irq(get_ccwdev_lock(cdev));\r\nccw_device_set_options(cdev, CCWDEV_REPORT_ALL);\r\nrc = ccw_device_start(cdev, &irq_ptr->ccw, QDIO_DOING_ACTIVATE,\r\n0, DOIO_DENY_PREFETCH);\r\nspin_unlock_irq(get_ccwdev_lock(cdev));\r\nif (rc) {\r\nDBF_ERROR("%4x act IO ERR", irq_ptr->schid.sch_no);\r\nDBF_ERROR("rc:%4x", rc);\r\ngoto out;\r\n}\r\nif (is_thinint_irq(irq_ptr))\r\ntiqdio_add_input_queues(irq_ptr);\r\nmsleep(5);\r\nswitch (irq_ptr->state) {\r\ncase QDIO_IRQ_STATE_STOPPED:\r\ncase QDIO_IRQ_STATE_ERR:\r\nrc = -EIO;\r\nbreak;\r\ndefault:\r\nqdio_set_state(irq_ptr, QDIO_IRQ_STATE_ACTIVE);\r\nrc = 0;\r\n}\r\nout:\r\nmutex_unlock(&irq_ptr->setup_mutex);\r\nreturn rc;\r\n}\r\nstatic inline int buf_in_between(int bufnr, int start, int count)\r\n{\r\nint end = add_buf(start, count);\r\nif (end > start) {\r\nif (bufnr >= start && bufnr < end)\r\nreturn 1;\r\nelse\r\nreturn 0;\r\n}\r\nif ((bufnr >= start && bufnr <= QDIO_MAX_BUFFERS_PER_Q) ||\r\n(bufnr < end))\r\nreturn 1;\r\nelse\r\nreturn 0;\r\n}\r\nstatic int handle_inbound(struct qdio_q *q, unsigned int callflags,\r\nint bufnr, int count)\r\n{\r\nint diff;\r\nqperf_inc(q, inbound_call);\r\nif (!q->u.in.polling)\r\ngoto set;\r\nif (count == QDIO_MAX_BUFFERS_PER_Q) {\r\nq->u.in.polling = 0;\r\nq->u.in.ack_count = 0;\r\ngoto set;\r\n} else if (buf_in_between(q->u.in.ack_start, bufnr, count)) {\r\nif (is_qebsm(q)) {\r\ndiff = add_buf(bufnr, count);\r\ndiff = sub_buf(diff, q->u.in.ack_start);\r\nq->u.in.ack_count -= diff;\r\nif (q->u.in.ack_count <= 0) {\r\nq->u.in.polling = 0;\r\nq->u.in.ack_count = 0;\r\ngoto set;\r\n}\r\nq->u.in.ack_start = add_buf(q->u.in.ack_start, diff);\r\n}\r\nelse\r\nq->u.in.polling = 0;\r\n}\r\nset:\r\ncount = set_buf_states(q, bufnr, SLSB_CU_INPUT_EMPTY, count);\r\natomic_add(count, &q->nr_buf_used);\r\nif (need_siga_in(q))\r\nreturn qdio_siga_input(q);\r\nreturn 0;\r\n}\r\nstatic int handle_outbound(struct qdio_q *q, unsigned int callflags,\r\nint bufnr, int count)\r\n{\r\nunsigned char state = 0;\r\nint used, rc = 0;\r\nqperf_inc(q, outbound_call);\r\ncount = set_buf_states(q, bufnr, SLSB_CU_OUTPUT_PRIMED, count);\r\nused = atomic_add_return(count, &q->nr_buf_used);\r\nif (used == QDIO_MAX_BUFFERS_PER_Q)\r\nqperf_inc(q, outbound_queue_full);\r\nif (callflags & QDIO_FLAG_PCI_OUT) {\r\nq->u.out.pci_out_enabled = 1;\r\nqperf_inc(q, pci_request_int);\r\n} else\r\nq->u.out.pci_out_enabled = 0;\r\nif (queue_type(q) == QDIO_IQDIO_QFMT) {\r\nunsigned long phys_aob = 0;\r\nWARN_ON_ONCE(count > 1 && !multicast_outbound(q));\r\nphys_aob = qdio_aob_for_buffer(&q->u.out, bufnr);\r\nrc = qdio_kick_outbound_q(q, phys_aob);\r\n} else if (need_siga_sync(q)) {\r\nrc = qdio_siga_sync_q(q);\r\n} else {\r\nget_buf_state(q, prev_buf(bufnr), &state, 0);\r\nif (state != SLSB_CU_OUTPUT_PRIMED)\r\nrc = qdio_kick_outbound_q(q, 0);\r\nelse\r\nqperf_inc(q, fast_requeue);\r\n}\r\nif (used >= q->u.out.scan_threshold || rc)\r\nqdio_tasklet_schedule(q);\r\nelse\r\nif (!timer_pending(&q->u.out.timer) &&\r\nlikely(q->irq_ptr->state == QDIO_IRQ_STATE_ACTIVE))\r\nmod_timer(&q->u.out.timer, jiffies + HZ);\r\nreturn rc;\r\n}\r\nint do_QDIO(struct ccw_device *cdev, unsigned int callflags,\r\nint q_nr, unsigned int bufnr, unsigned int count)\r\n{\r\nstruct qdio_irq *irq_ptr;\r\nif (bufnr >= QDIO_MAX_BUFFERS_PER_Q || count > QDIO_MAX_BUFFERS_PER_Q)\r\nreturn -EINVAL;\r\nirq_ptr = cdev->private->qdio_data;\r\nif (!irq_ptr)\r\nreturn -ENODEV;\r\nDBF_DEV_EVENT(DBF_INFO, irq_ptr,\r\n"do%02x b:%02x c:%02x", callflags, bufnr, count);\r\nif (irq_ptr->state != QDIO_IRQ_STATE_ACTIVE)\r\nreturn -EIO;\r\nif (!count)\r\nreturn 0;\r\nif (callflags & QDIO_FLAG_SYNC_INPUT)\r\nreturn handle_inbound(irq_ptr->input_qs[q_nr],\r\ncallflags, bufnr, count);\r\nelse if (callflags & QDIO_FLAG_SYNC_OUTPUT)\r\nreturn handle_outbound(irq_ptr->output_qs[q_nr],\r\ncallflags, bufnr, count);\r\nreturn -EINVAL;\r\n}\r\nint qdio_start_irq(struct ccw_device *cdev, int nr)\r\n{\r\nstruct qdio_q *q;\r\nstruct qdio_irq *irq_ptr = cdev->private->qdio_data;\r\nif (!irq_ptr)\r\nreturn -ENODEV;\r\nq = irq_ptr->input_qs[nr];\r\nclear_nonshared_ind(irq_ptr);\r\nqdio_stop_polling(q);\r\nclear_bit(QDIO_QUEUE_IRQS_DISABLED, &q->u.in.queue_irq_state);\r\nif (test_nonshared_ind(irq_ptr))\r\ngoto rescan;\r\nif (!qdio_inbound_q_done(q))\r\ngoto rescan;\r\nreturn 0;\r\nrescan:\r\nif (test_and_set_bit(QDIO_QUEUE_IRQS_DISABLED,\r\n&q->u.in.queue_irq_state))\r\nreturn 0;\r\nelse\r\nreturn 1;\r\n}\r\nint qdio_get_next_buffers(struct ccw_device *cdev, int nr, int *bufnr,\r\nint *error)\r\n{\r\nstruct qdio_q *q;\r\nint start, end;\r\nstruct qdio_irq *irq_ptr = cdev->private->qdio_data;\r\nif (!irq_ptr)\r\nreturn -ENODEV;\r\nq = irq_ptr->input_qs[nr];\r\nif (need_siga_sync(q))\r\nqdio_sync_queues(q);\r\nqdio_check_outbound_after_thinint(q);\r\nif (!qdio_inbound_q_moved(q))\r\nreturn 0;\r\nif (unlikely(q->irq_ptr->state != QDIO_IRQ_STATE_ACTIVE))\r\nreturn -EIO;\r\nstart = q->first_to_kick;\r\nend = q->first_to_check;\r\n*bufnr = start;\r\n*error = q->qdio_error;\r\nq->first_to_kick = end;\r\nq->qdio_error = 0;\r\nreturn sub_buf(end, start);\r\n}\r\nint qdio_stop_irq(struct ccw_device *cdev, int nr)\r\n{\r\nstruct qdio_q *q;\r\nstruct qdio_irq *irq_ptr = cdev->private->qdio_data;\r\nif (!irq_ptr)\r\nreturn -ENODEV;\r\nq = irq_ptr->input_qs[nr];\r\nif (test_and_set_bit(QDIO_QUEUE_IRQS_DISABLED,\r\n&q->u.in.queue_irq_state))\r\nreturn 0;\r\nelse\r\nreturn 1;\r\n}\r\nint qdio_pnso_brinfo(struct subchannel_id schid,\r\nint cnc, u16 *response,\r\nvoid (*cb)(void *priv, enum qdio_brinfo_entry_type type,\r\nvoid *entry),\r\nvoid *priv)\r\n{\r\nstruct chsc_pnso_area *rr;\r\nint rc;\r\nu32 prev_instance = 0;\r\nint isfirstblock = 1;\r\nint i, size, elems;\r\nrr = (struct chsc_pnso_area *)get_zeroed_page(GFP_KERNEL);\r\nif (rr == NULL)\r\nreturn -ENOMEM;\r\ndo {\r\nrc = chsc_pnso_brinfo(schid, rr, rr->naihdr.resume_token, cnc);\r\nif (rc != 0 && rc != -EBUSY)\r\ngoto out;\r\nif (rr->response.code != 1) {\r\nrc = -EIO;\r\ncontinue;\r\n} else\r\nrc = 0;\r\nif (cb == NULL)\r\ncontinue;\r\nsize = rr->naihdr.naids;\r\nelems = (rr->response.length -\r\nsizeof(struct chsc_header) -\r\nsizeof(struct chsc_brinfo_naihdr)) /\r\nsize;\r\nif (!isfirstblock && (rr->naihdr.instance != prev_instance)) {\r\nrc = -EAGAIN;\r\nbreak;\r\n}\r\nisfirstblock = 0;\r\nprev_instance = rr->naihdr.instance;\r\nfor (i = 0; i < elems; i++)\r\nswitch (size) {\r\ncase sizeof(struct qdio_brinfo_entry_l3_ipv6):\r\n(*cb)(priv, l3_ipv6_addr,\r\n&rr->entries.l3_ipv6[i]);\r\nbreak;\r\ncase sizeof(struct qdio_brinfo_entry_l3_ipv4):\r\n(*cb)(priv, l3_ipv4_addr,\r\n&rr->entries.l3_ipv4[i]);\r\nbreak;\r\ncase sizeof(struct qdio_brinfo_entry_l2):\r\n(*cb)(priv, l2_addr_lnid,\r\n&rr->entries.l2[i]);\r\nbreak;\r\ndefault:\r\nWARN_ON_ONCE(1);\r\nrc = -EIO;\r\ngoto out;\r\n}\r\n} while (rr->response.code == 0x0107 ||\r\n(rr->response.code == 1 &&\r\n(rr->naihdr.resume_token.t1 || rr->naihdr.resume_token.t2)));\r\n(*response) = rr->response.code;\r\nout:\r\nfree_page((unsigned long)rr);\r\nreturn rc;\r\n}\r\nstatic int __init init_QDIO(void)\r\n{\r\nint rc;\r\nrc = qdio_debug_init();\r\nif (rc)\r\nreturn rc;\r\nrc = qdio_setup_init();\r\nif (rc)\r\ngoto out_debug;\r\nrc = tiqdio_allocate_memory();\r\nif (rc)\r\ngoto out_cache;\r\nrc = tiqdio_register_thinints();\r\nif (rc)\r\ngoto out_ti;\r\nreturn 0;\r\nout_ti:\r\ntiqdio_free_memory();\r\nout_cache:\r\nqdio_setup_exit();\r\nout_debug:\r\nqdio_debug_exit();\r\nreturn rc;\r\n}\r\nstatic void __exit exit_QDIO(void)\r\n{\r\ntiqdio_unregister_thinints();\r\ntiqdio_free_memory();\r\nqdio_setup_exit();\r\nqdio_debug_exit();\r\n}
