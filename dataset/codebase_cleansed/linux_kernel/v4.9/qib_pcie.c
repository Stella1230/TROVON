int qib_pcie_init(struct pci_dev *pdev, const struct pci_device_id *ent)\r\n{\r\nint ret;\r\nret = pci_enable_device(pdev);\r\nif (ret) {\r\nqib_early_err(&pdev->dev, "pci enable failed: error %d\n",\r\n-ret);\r\ngoto done;\r\n}\r\nret = pci_request_regions(pdev, QIB_DRV_NAME);\r\nif (ret) {\r\nqib_devinfo(pdev, "pci_request_regions fails: err %d\n", -ret);\r\ngoto bail;\r\n}\r\nret = pci_set_dma_mask(pdev, DMA_BIT_MASK(64));\r\nif (ret) {\r\nret = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (ret) {\r\nqib_devinfo(pdev, "Unable to set DMA mask: %d\n", ret);\r\ngoto bail;\r\n}\r\nret = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));\r\n} else\r\nret = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));\r\nif (ret) {\r\nqib_early_err(&pdev->dev,\r\n"Unable to set DMA consistent mask: %d\n", ret);\r\ngoto bail;\r\n}\r\npci_set_master(pdev);\r\nret = pci_enable_pcie_error_reporting(pdev);\r\nif (ret) {\r\nqib_early_err(&pdev->dev,\r\n"Unable to enable pcie error reporting: %d\n",\r\nret);\r\nret = 0;\r\n}\r\ngoto done;\r\nbail:\r\npci_disable_device(pdev);\r\npci_release_regions(pdev);\r\ndone:\r\nreturn ret;\r\n}\r\nint qib_pcie_ddinit(struct qib_devdata *dd, struct pci_dev *pdev,\r\nconst struct pci_device_id *ent)\r\n{\r\nunsigned long len;\r\nresource_size_t addr;\r\ndd->pcidev = pdev;\r\npci_set_drvdata(pdev, dd);\r\naddr = pci_resource_start(pdev, 0);\r\nlen = pci_resource_len(pdev, 0);\r\ndd->kregbase = ioremap_nocache(addr, len);\r\nif (!dd->kregbase)\r\nreturn -ENOMEM;\r\ndd->kregend = (u64 __iomem *)((void __iomem *) dd->kregbase + len);\r\ndd->physaddr = addr;\r\ndd->pcibar0 = addr;\r\ndd->pcibar1 = addr >> 32;\r\ndd->deviceid = ent->device;\r\ndd->vendorid = ent->vendor;\r\nreturn 0;\r\n}\r\nvoid qib_pcie_ddcleanup(struct qib_devdata *dd)\r\n{\r\nu64 __iomem *base = (void __iomem *) dd->kregbase;\r\ndd->kregbase = NULL;\r\niounmap(base);\r\nif (dd->piobase)\r\niounmap(dd->piobase);\r\nif (dd->userbase)\r\niounmap(dd->userbase);\r\nif (dd->piovl15base)\r\niounmap(dd->piovl15base);\r\npci_disable_device(dd->pcidev);\r\npci_release_regions(dd->pcidev);\r\npci_set_drvdata(dd->pcidev, NULL);\r\n}\r\nstatic void qib_msix_setup(struct qib_devdata *dd, int pos, u32 *msixcnt,\r\nstruct qib_msix_entry *qib_msix_entry)\r\n{\r\nint ret;\r\nint nvec = *msixcnt;\r\nstruct msix_entry *msix_entry;\r\nint i;\r\nret = pci_msix_vec_count(dd->pcidev);\r\nif (ret < 0)\r\ngoto do_intx;\r\nnvec = min(nvec, ret);\r\nmsix_entry = kcalloc(nvec, sizeof(*msix_entry), GFP_KERNEL);\r\nif (!msix_entry)\r\ngoto do_intx;\r\nfor (i = 0; i < nvec; i++)\r\nmsix_entry[i] = qib_msix_entry[i].msix;\r\nret = pci_enable_msix_range(dd->pcidev, msix_entry, 1, nvec);\r\nif (ret < 0)\r\ngoto free_msix_entry;\r\nelse\r\nnvec = ret;\r\nfor (i = 0; i < nvec; i++)\r\nqib_msix_entry[i].msix = msix_entry[i];\r\nkfree(msix_entry);\r\n*msixcnt = nvec;\r\nreturn;\r\nfree_msix_entry:\r\nkfree(msix_entry);\r\ndo_intx:\r\nqib_dev_err(\r\ndd,\r\n"pci_enable_msix_range %d vectors failed: %d, falling back to INTx\n",\r\nnvec, ret);\r\n*msixcnt = 0;\r\nqib_enable_intx(dd->pcidev);\r\n}\r\nstatic int qib_msi_setup(struct qib_devdata *dd, int pos)\r\n{\r\nstruct pci_dev *pdev = dd->pcidev;\r\nu16 control;\r\nint ret;\r\nret = pci_enable_msi(pdev);\r\nif (ret)\r\nqib_dev_err(dd,\r\n"pci_enable_msi failed: %d, interrupts may not work\n",\r\nret);\r\npci_read_config_dword(pdev, pos + PCI_MSI_ADDRESS_LO,\r\n&dd->msi_lo);\r\npci_read_config_dword(pdev, pos + PCI_MSI_ADDRESS_HI,\r\n&dd->msi_hi);\r\npci_read_config_word(pdev, pos + PCI_MSI_FLAGS, &control);\r\npci_read_config_word(pdev, pos + ((control & PCI_MSI_FLAGS_64BIT)\r\n? 12 : 8),\r\n&dd->msi_data);\r\nreturn ret;\r\n}\r\nint qib_pcie_params(struct qib_devdata *dd, u32 minw, u32 *nent,\r\nstruct qib_msix_entry *entry)\r\n{\r\nu16 linkstat, speed;\r\nint pos = 0, ret = 1;\r\nif (!pci_is_pcie(dd->pcidev)) {\r\nqib_dev_err(dd, "Can't find PCI Express capability!\n");\r\ndd->lbus_width = 1;\r\ndd->lbus_speed = 2500;\r\ngoto bail;\r\n}\r\npos = dd->pcidev->msix_cap;\r\nif (nent && *nent && pos) {\r\nqib_msix_setup(dd, pos, nent, entry);\r\nret = 0;\r\n} else {\r\npos = dd->pcidev->msi_cap;\r\nif (pos)\r\nret = qib_msi_setup(dd, pos);\r\nelse\r\nqib_dev_err(dd, "No PCI MSI or MSIx capability!\n");\r\n}\r\nif (!pos)\r\nqib_enable_intx(dd->pcidev);\r\npcie_capability_read_word(dd->pcidev, PCI_EXP_LNKSTA, &linkstat);\r\nspeed = linkstat & 0xf;\r\nlinkstat >>= 4;\r\nlinkstat &= 0x1f;\r\ndd->lbus_width = linkstat;\r\nswitch (speed) {\r\ncase 1:\r\ndd->lbus_speed = 2500;\r\nbreak;\r\ncase 2:\r\ndd->lbus_speed = 5000;\r\nbreak;\r\ndefault:\r\ndd->lbus_speed = 2500;\r\nbreak;\r\n}\r\nif (minw && linkstat < minw)\r\nqib_dev_err(dd,\r\n"PCIe width %u (x%u HCA), performance reduced\n",\r\nlinkstat, minw);\r\nqib_tune_pcie_caps(dd);\r\nqib_tune_pcie_coalesce(dd);\r\nbail:\r\nsnprintf(dd->lbus_info, sizeof(dd->lbus_info),\r\n"PCIe,%uMHz,x%u\n", dd->lbus_speed, dd->lbus_width);\r\nreturn ret;\r\n}\r\nint qib_reinit_intr(struct qib_devdata *dd)\r\n{\r\nint pos;\r\nu16 control;\r\nint ret = 0;\r\nif (!dd->msi_lo)\r\ngoto bail;\r\npos = dd->pcidev->msi_cap;\r\nif (!pos) {\r\nqib_dev_err(dd,\r\n"Can't find MSI capability, can't restore MSI settings\n");\r\nret = 0;\r\ngoto bail;\r\n}\r\npci_write_config_dword(dd->pcidev, pos + PCI_MSI_ADDRESS_LO,\r\ndd->msi_lo);\r\npci_write_config_dword(dd->pcidev, pos + PCI_MSI_ADDRESS_HI,\r\ndd->msi_hi);\r\npci_read_config_word(dd->pcidev, pos + PCI_MSI_FLAGS, &control);\r\nif (!(control & PCI_MSI_FLAGS_ENABLE)) {\r\ncontrol |= PCI_MSI_FLAGS_ENABLE;\r\npci_write_config_word(dd->pcidev, pos + PCI_MSI_FLAGS,\r\ncontrol);\r\n}\r\npci_write_config_word(dd->pcidev, pos +\r\n((control & PCI_MSI_FLAGS_64BIT) ? 12 : 8),\r\ndd->msi_data);\r\nret = 1;\r\nbail:\r\nif (!ret && (dd->flags & QIB_HAS_INTX)) {\r\nqib_enable_intx(dd->pcidev);\r\nret = 1;\r\n}\r\npci_set_master(dd->pcidev);\r\nreturn ret;\r\n}\r\nvoid qib_nomsi(struct qib_devdata *dd)\r\n{\r\ndd->msi_lo = 0;\r\npci_disable_msi(dd->pcidev);\r\n}\r\nvoid qib_nomsix(struct qib_devdata *dd)\r\n{\r\npci_disable_msix(dd->pcidev);\r\n}\r\nvoid qib_enable_intx(struct pci_dev *pdev)\r\n{\r\nu16 cw, new;\r\nint pos;\r\npci_read_config_word(pdev, PCI_COMMAND, &cw);\r\nnew = cw & ~PCI_COMMAND_INTX_DISABLE;\r\nif (new != cw)\r\npci_write_config_word(pdev, PCI_COMMAND, new);\r\npos = pdev->msi_cap;\r\nif (pos) {\r\npci_read_config_word(pdev, pos + PCI_MSI_FLAGS, &cw);\r\nnew = cw & ~PCI_MSI_FLAGS_ENABLE;\r\nif (new != cw)\r\npci_write_config_word(pdev, pos + PCI_MSI_FLAGS, new);\r\n}\r\npos = pdev->msix_cap;\r\nif (pos) {\r\npci_read_config_word(pdev, pos + PCI_MSIX_FLAGS, &cw);\r\nnew = cw & ~PCI_MSIX_FLAGS_ENABLE;\r\nif (new != cw)\r\npci_write_config_word(pdev, pos + PCI_MSIX_FLAGS, new);\r\n}\r\n}\r\nvoid qib_pcie_getcmd(struct qib_devdata *dd, u16 *cmd, u8 *iline, u8 *cline)\r\n{\r\npci_read_config_word(dd->pcidev, PCI_COMMAND, cmd);\r\npci_read_config_byte(dd->pcidev, PCI_INTERRUPT_LINE, iline);\r\npci_read_config_byte(dd->pcidev, PCI_CACHE_LINE_SIZE, cline);\r\n}\r\nvoid qib_pcie_reenable(struct qib_devdata *dd, u16 cmd, u8 iline, u8 cline)\r\n{\r\nint r;\r\nr = pci_write_config_dword(dd->pcidev, PCI_BASE_ADDRESS_0,\r\ndd->pcibar0);\r\nif (r)\r\nqib_dev_err(dd, "rewrite of BAR0 failed: %d\n", r);\r\nr = pci_write_config_dword(dd->pcidev, PCI_BASE_ADDRESS_1,\r\ndd->pcibar1);\r\nif (r)\r\nqib_dev_err(dd, "rewrite of BAR1 failed: %d\n", r);\r\npci_write_config_word(dd->pcidev, PCI_COMMAND, cmd);\r\npci_write_config_byte(dd->pcidev, PCI_INTERRUPT_LINE, iline);\r\npci_write_config_byte(dd->pcidev, PCI_CACHE_LINE_SIZE, cline);\r\nr = pci_enable_device(dd->pcidev);\r\nif (r)\r\nqib_dev_err(dd,\r\n"pci_enable_device failed after reset: %d\n", r);\r\n}\r\nstatic void qib_tune_pcie_coalesce(struct qib_devdata *dd)\r\n{\r\nint r;\r\nstruct pci_dev *parent;\r\nu16 devid;\r\nu32 mask, bits, val;\r\nif (!qib_pcie_coalesce)\r\nreturn;\r\nparent = dd->pcidev->bus->self;\r\nif (parent->bus->parent) {\r\nqib_devinfo(dd->pcidev, "Parent not root\n");\r\nreturn;\r\n}\r\nif (!pci_is_pcie(parent))\r\nreturn;\r\nif (parent->vendor != 0x8086)\r\nreturn;\r\ndevid = parent->device;\r\nif (devid >= 0x25e2 && devid <= 0x25fa) {\r\nif (parent->revision <= 0xb2)\r\nbits = 1U << 10;\r\nelse\r\nbits = 7U << 10;\r\nmask = (3U << 24) | (7U << 10);\r\n} else if (devid >= 0x65e2 && devid <= 0x65fa) {\r\nbits = 1U << 10;\r\nmask = (3U << 24) | (7U << 10);\r\n} else if (devid >= 0x4021 && devid <= 0x402e) {\r\nbits = 7U << 10;\r\nmask = 7U << 10;\r\n} else if (devid >= 0x3604 && devid <= 0x360a) {\r\nbits = 7U << 10;\r\nmask = (3U << 24) | (7U << 10);\r\n} else {\r\nreturn;\r\n}\r\npci_read_config_dword(parent, 0x48, &val);\r\nval &= ~mask;\r\nval |= bits;\r\nr = pci_write_config_dword(parent, 0x48, val);\r\n}\r\nstatic void qib_tune_pcie_caps(struct qib_devdata *dd)\r\n{\r\nstruct pci_dev *parent;\r\nu16 rc_mpss, rc_mps, ep_mpss, ep_mps;\r\nu16 rc_mrrs, ep_mrrs, max_mrrs;\r\nparent = dd->pcidev->bus->self;\r\nif (!pci_is_root_bus(parent->bus)) {\r\nqib_devinfo(dd->pcidev, "Parent not root\n");\r\nreturn;\r\n}\r\nif (!pci_is_pcie(parent) || !pci_is_pcie(dd->pcidev))\r\nreturn;\r\nrc_mpss = parent->pcie_mpss;\r\nrc_mps = ffs(pcie_get_mps(parent)) - 8;\r\nep_mpss = dd->pcidev->pcie_mpss;\r\nep_mps = ffs(pcie_get_mps(dd->pcidev)) - 8;\r\nif (rc_mpss > ep_mpss)\r\nrc_mpss = ep_mpss;\r\nif (rc_mpss > (qib_pcie_caps & 7))\r\nrc_mpss = qib_pcie_caps & 7;\r\nif (rc_mpss > rc_mps) {\r\nrc_mps = rc_mpss;\r\npcie_set_mps(parent, 128 << rc_mps);\r\n}\r\nif (rc_mpss > ep_mps) {\r\nep_mps = rc_mpss;\r\npcie_set_mps(dd->pcidev, 128 << ep_mps);\r\n}\r\nmax_mrrs = 5;\r\nif (max_mrrs > ((qib_pcie_caps >> 4) & 7))\r\nmax_mrrs = (qib_pcie_caps >> 4) & 7;\r\nmax_mrrs = 128 << max_mrrs;\r\nrc_mrrs = pcie_get_readrq(parent);\r\nep_mrrs = pcie_get_readrq(dd->pcidev);\r\nif (max_mrrs > rc_mrrs) {\r\nrc_mrrs = max_mrrs;\r\npcie_set_readrq(parent, rc_mrrs);\r\n}\r\nif (max_mrrs > ep_mrrs) {\r\nep_mrrs = max_mrrs;\r\npcie_set_readrq(dd->pcidev, ep_mrrs);\r\n}\r\n}\r\nstatic pci_ers_result_t\r\nqib_pci_error_detected(struct pci_dev *pdev, pci_channel_state_t state)\r\n{\r\nstruct qib_devdata *dd = pci_get_drvdata(pdev);\r\npci_ers_result_t ret = PCI_ERS_RESULT_RECOVERED;\r\nswitch (state) {\r\ncase pci_channel_io_normal:\r\nqib_devinfo(pdev, "State Normal, ignoring\n");\r\nbreak;\r\ncase pci_channel_io_frozen:\r\nqib_devinfo(pdev, "State Frozen, requesting reset\n");\r\npci_disable_device(pdev);\r\nret = PCI_ERS_RESULT_NEED_RESET;\r\nbreak;\r\ncase pci_channel_io_perm_failure:\r\nqib_devinfo(pdev, "State Permanent Failure, disabling\n");\r\nif (dd) {\r\ndd->flags &= ~QIB_PRESENT;\r\nqib_disable_after_error(dd);\r\n}\r\nret = PCI_ERS_RESULT_DISCONNECT;\r\nbreak;\r\ndefault:\r\nqib_devinfo(pdev, "QIB PCI errors detected (state %d)\n",\r\nstate);\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nstatic pci_ers_result_t\r\nqib_pci_mmio_enabled(struct pci_dev *pdev)\r\n{\r\nu64 words = 0U;\r\nstruct qib_devdata *dd = pci_get_drvdata(pdev);\r\npci_ers_result_t ret = PCI_ERS_RESULT_RECOVERED;\r\nif (dd && dd->pport) {\r\nwords = dd->f_portcntr(dd->pport, QIBPORTCNTR_WORDRCV);\r\nif (words == ~0ULL)\r\nret = PCI_ERS_RESULT_NEED_RESET;\r\n}\r\nqib_devinfo(pdev,\r\n"QIB mmio_enabled function called, read wordscntr %Lx, returning %d\n",\r\nwords, ret);\r\nreturn ret;\r\n}\r\nstatic pci_ers_result_t\r\nqib_pci_slot_reset(struct pci_dev *pdev)\r\n{\r\nqib_devinfo(pdev, "QIB slot_reset function called, ignored\n");\r\nreturn PCI_ERS_RESULT_CAN_RECOVER;\r\n}\r\nstatic pci_ers_result_t\r\nqib_pci_link_reset(struct pci_dev *pdev)\r\n{\r\nqib_devinfo(pdev, "QIB link_reset function called, ignored\n");\r\nreturn PCI_ERS_RESULT_CAN_RECOVER;\r\n}\r\nstatic void\r\nqib_pci_resume(struct pci_dev *pdev)\r\n{\r\nstruct qib_devdata *dd = pci_get_drvdata(pdev);\r\nqib_devinfo(pdev, "QIB resume function called\n");\r\npci_cleanup_aer_uncorrect_error_status(pdev);\r\nqib_init(dd, 1);\r\n}
