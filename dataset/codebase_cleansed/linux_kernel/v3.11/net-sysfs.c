static inline int dev_isalive(const struct net_device *dev)\r\n{\r\nreturn dev->reg_state <= NETREG_REGISTERED;\r\n}\r\nstatic ssize_t netdev_show(const struct device *dev,\r\nstruct device_attribute *attr, char *buf,\r\nssize_t (*format)(const struct net_device *, char *))\r\n{\r\nstruct net_device *net = to_net_dev(dev);\r\nssize_t ret = -EINVAL;\r\nread_lock(&dev_base_lock);\r\nif (dev_isalive(net))\r\nret = (*format)(net, buf);\r\nread_unlock(&dev_base_lock);\r\nreturn ret;\r\n}\r\nstatic ssize_t netdev_store(struct device *dev, struct device_attribute *attr,\r\nconst char *buf, size_t len,\r\nint (*set)(struct net_device *, unsigned long))\r\n{\r\nstruct net_device *netdev = to_net_dev(dev);\r\nstruct net *net = dev_net(netdev);\r\nunsigned long new;\r\nint ret = -EINVAL;\r\nif (!ns_capable(net->user_ns, CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nret = kstrtoul(buf, 0, &new);\r\nif (ret)\r\ngoto err;\r\nif (!rtnl_trylock())\r\nreturn restart_syscall();\r\nif (dev_isalive(netdev)) {\r\nif ((ret = (*set)(netdev, new)) == 0)\r\nret = len;\r\n}\r\nrtnl_unlock();\r\nerr:\r\nreturn ret;\r\n}\r\nstatic ssize_t show_address(struct device *dev, struct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct net_device *net = to_net_dev(dev);\r\nssize_t ret = -EINVAL;\r\nread_lock(&dev_base_lock);\r\nif (dev_isalive(net))\r\nret = sysfs_format_mac(buf, net->dev_addr, net->addr_len);\r\nread_unlock(&dev_base_lock);\r\nreturn ret;\r\n}\r\nstatic ssize_t show_broadcast(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct net_device *net = to_net_dev(dev);\r\nif (dev_isalive(net))\r\nreturn sysfs_format_mac(buf, net->broadcast, net->addr_len);\r\nreturn -EINVAL;\r\n}\r\nstatic int change_carrier(struct net_device *net, unsigned long new_carrier)\r\n{\r\nif (!netif_running(net))\r\nreturn -EINVAL;\r\nreturn dev_change_carrier(net, (bool) new_carrier);\r\n}\r\nstatic ssize_t store_carrier(struct device *dev, struct device_attribute *attr,\r\nconst char *buf, size_t len)\r\n{\r\nreturn netdev_store(dev, attr, buf, len, change_carrier);\r\n}\r\nstatic ssize_t show_carrier(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct net_device *netdev = to_net_dev(dev);\r\nif (netif_running(netdev)) {\r\nreturn sprintf(buf, fmt_dec, !!netif_carrier_ok(netdev));\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic ssize_t show_speed(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct net_device *netdev = to_net_dev(dev);\r\nint ret = -EINVAL;\r\nif (!rtnl_trylock())\r\nreturn restart_syscall();\r\nif (netif_running(netdev)) {\r\nstruct ethtool_cmd cmd;\r\nif (!__ethtool_get_settings(netdev, &cmd))\r\nret = sprintf(buf, fmt_udec, ethtool_cmd_speed(&cmd));\r\n}\r\nrtnl_unlock();\r\nreturn ret;\r\n}\r\nstatic ssize_t show_duplex(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct net_device *netdev = to_net_dev(dev);\r\nint ret = -EINVAL;\r\nif (!rtnl_trylock())\r\nreturn restart_syscall();\r\nif (netif_running(netdev)) {\r\nstruct ethtool_cmd cmd;\r\nif (!__ethtool_get_settings(netdev, &cmd)) {\r\nconst char *duplex;\r\nswitch (cmd.duplex) {\r\ncase DUPLEX_HALF:\r\nduplex = "half";\r\nbreak;\r\ncase DUPLEX_FULL:\r\nduplex = "full";\r\nbreak;\r\ndefault:\r\nduplex = "unknown";\r\nbreak;\r\n}\r\nret = sprintf(buf, "%s\n", duplex);\r\n}\r\n}\r\nrtnl_unlock();\r\nreturn ret;\r\n}\r\nstatic ssize_t show_dormant(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct net_device *netdev = to_net_dev(dev);\r\nif (netif_running(netdev))\r\nreturn sprintf(buf, fmt_dec, !!netif_dormant(netdev));\r\nreturn -EINVAL;\r\n}\r\nstatic ssize_t show_operstate(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nconst struct net_device *netdev = to_net_dev(dev);\r\nunsigned char operstate;\r\nread_lock(&dev_base_lock);\r\noperstate = netdev->operstate;\r\nif (!netif_running(netdev))\r\noperstate = IF_OPER_DOWN;\r\nread_unlock(&dev_base_lock);\r\nif (operstate >= ARRAY_SIZE(operstates))\r\nreturn -EINVAL;\r\nreturn sprintf(buf, "%s\n", operstates[operstate]);\r\n}\r\nstatic int change_mtu(struct net_device *net, unsigned long new_mtu)\r\n{\r\nreturn dev_set_mtu(net, (int) new_mtu);\r\n}\r\nstatic ssize_t store_mtu(struct device *dev, struct device_attribute *attr,\r\nconst char *buf, size_t len)\r\n{\r\nreturn netdev_store(dev, attr, buf, len, change_mtu);\r\n}\r\nstatic int change_flags(struct net_device *net, unsigned long new_flags)\r\n{\r\nreturn dev_change_flags(net, (unsigned int) new_flags);\r\n}\r\nstatic ssize_t store_flags(struct device *dev, struct device_attribute *attr,\r\nconst char *buf, size_t len)\r\n{\r\nreturn netdev_store(dev, attr, buf, len, change_flags);\r\n}\r\nstatic int change_tx_queue_len(struct net_device *net, unsigned long new_len)\r\n{\r\nnet->tx_queue_len = new_len;\r\nreturn 0;\r\n}\r\nstatic ssize_t store_tx_queue_len(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf, size_t len)\r\n{\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nreturn netdev_store(dev, attr, buf, len, change_tx_queue_len);\r\n}\r\nstatic ssize_t store_ifalias(struct device *dev, struct device_attribute *attr,\r\nconst char *buf, size_t len)\r\n{\r\nstruct net_device *netdev = to_net_dev(dev);\r\nstruct net *net = dev_net(netdev);\r\nsize_t count = len;\r\nssize_t ret;\r\nif (!ns_capable(net->user_ns, CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nif (len > 0 && buf[len - 1] == '\n')\r\n--count;\r\nif (!rtnl_trylock())\r\nreturn restart_syscall();\r\nret = dev_set_alias(netdev, buf, count);\r\nrtnl_unlock();\r\nreturn ret < 0 ? ret : len;\r\n}\r\nstatic ssize_t show_ifalias(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nconst struct net_device *netdev = to_net_dev(dev);\r\nssize_t ret = 0;\r\nif (!rtnl_trylock())\r\nreturn restart_syscall();\r\nif (netdev->ifalias)\r\nret = sprintf(buf, "%s\n", netdev->ifalias);\r\nrtnl_unlock();\r\nreturn ret;\r\n}\r\nstatic int change_group(struct net_device *net, unsigned long new_group)\r\n{\r\ndev_set_group(net, (int) new_group);\r\nreturn 0;\r\n}\r\nstatic ssize_t store_group(struct device *dev, struct device_attribute *attr,\r\nconst char *buf, size_t len)\r\n{\r\nreturn netdev_store(dev, attr, buf, len, change_group);\r\n}\r\nstatic ssize_t netstat_show(const struct device *d,\r\nstruct device_attribute *attr, char *buf,\r\nunsigned long offset)\r\n{\r\nstruct net_device *dev = to_net_dev(d);\r\nssize_t ret = -EINVAL;\r\nWARN_ON(offset > sizeof(struct rtnl_link_stats64) ||\r\noffset % sizeof(u64) != 0);\r\nread_lock(&dev_base_lock);\r\nif (dev_isalive(dev)) {\r\nstruct rtnl_link_stats64 temp;\r\nconst struct rtnl_link_stats64 *stats = dev_get_stats(dev, &temp);\r\nret = sprintf(buf, fmt_u64, *(u64 *)(((u8 *) stats) + offset));\r\n}\r\nread_unlock(&dev_base_lock);\r\nreturn ret;\r\n}\r\nstatic ssize_t rx_queue_attr_show(struct kobject *kobj, struct attribute *attr,\r\nchar *buf)\r\n{\r\nstruct rx_queue_attribute *attribute = to_rx_queue_attr(attr);\r\nstruct netdev_rx_queue *queue = to_rx_queue(kobj);\r\nif (!attribute->show)\r\nreturn -EIO;\r\nreturn attribute->show(queue, attribute, buf);\r\n}\r\nstatic ssize_t rx_queue_attr_store(struct kobject *kobj, struct attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nstruct rx_queue_attribute *attribute = to_rx_queue_attr(attr);\r\nstruct netdev_rx_queue *queue = to_rx_queue(kobj);\r\nif (!attribute->store)\r\nreturn -EIO;\r\nreturn attribute->store(queue, attribute, buf, count);\r\n}\r\nstatic ssize_t show_rps_map(struct netdev_rx_queue *queue,\r\nstruct rx_queue_attribute *attribute, char *buf)\r\n{\r\nstruct rps_map *map;\r\ncpumask_var_t mask;\r\nsize_t len = 0;\r\nint i;\r\nif (!zalloc_cpumask_var(&mask, GFP_KERNEL))\r\nreturn -ENOMEM;\r\nrcu_read_lock();\r\nmap = rcu_dereference(queue->rps_map);\r\nif (map)\r\nfor (i = 0; i < map->len; i++)\r\ncpumask_set_cpu(map->cpus[i], mask);\r\nlen += cpumask_scnprintf(buf + len, PAGE_SIZE, mask);\r\nif (PAGE_SIZE - len < 3) {\r\nrcu_read_unlock();\r\nfree_cpumask_var(mask);\r\nreturn -EINVAL;\r\n}\r\nrcu_read_unlock();\r\nfree_cpumask_var(mask);\r\nlen += sprintf(buf + len, "\n");\r\nreturn len;\r\n}\r\nstatic ssize_t store_rps_map(struct netdev_rx_queue *queue,\r\nstruct rx_queue_attribute *attribute,\r\nconst char *buf, size_t len)\r\n{\r\nstruct rps_map *old_map, *map;\r\ncpumask_var_t mask;\r\nint err, cpu, i;\r\nstatic DEFINE_SPINLOCK(rps_map_lock);\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nif (!alloc_cpumask_var(&mask, GFP_KERNEL))\r\nreturn -ENOMEM;\r\nerr = bitmap_parse(buf, len, cpumask_bits(mask), nr_cpumask_bits);\r\nif (err) {\r\nfree_cpumask_var(mask);\r\nreturn err;\r\n}\r\nmap = kzalloc(max_t(unsigned int,\r\nRPS_MAP_SIZE(cpumask_weight(mask)), L1_CACHE_BYTES),\r\nGFP_KERNEL);\r\nif (!map) {\r\nfree_cpumask_var(mask);\r\nreturn -ENOMEM;\r\n}\r\ni = 0;\r\nfor_each_cpu_and(cpu, mask, cpu_online_mask)\r\nmap->cpus[i++] = cpu;\r\nif (i)\r\nmap->len = i;\r\nelse {\r\nkfree(map);\r\nmap = NULL;\r\n}\r\nspin_lock(&rps_map_lock);\r\nold_map = rcu_dereference_protected(queue->rps_map,\r\nlockdep_is_held(&rps_map_lock));\r\nrcu_assign_pointer(queue->rps_map, map);\r\nspin_unlock(&rps_map_lock);\r\nif (map)\r\nstatic_key_slow_inc(&rps_needed);\r\nif (old_map) {\r\nkfree_rcu(old_map, rcu);\r\nstatic_key_slow_dec(&rps_needed);\r\n}\r\nfree_cpumask_var(mask);\r\nreturn len;\r\n}\r\nstatic ssize_t show_rps_dev_flow_table_cnt(struct netdev_rx_queue *queue,\r\nstruct rx_queue_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct rps_dev_flow_table *flow_table;\r\nunsigned long val = 0;\r\nrcu_read_lock();\r\nflow_table = rcu_dereference(queue->rps_flow_table);\r\nif (flow_table)\r\nval = (unsigned long)flow_table->mask + 1;\r\nrcu_read_unlock();\r\nreturn sprintf(buf, "%lu\n", val);\r\n}\r\nstatic void rps_dev_flow_table_release(struct rcu_head *rcu)\r\n{\r\nstruct rps_dev_flow_table *table = container_of(rcu,\r\nstruct rps_dev_flow_table, rcu);\r\nvfree(table);\r\n}\r\nstatic ssize_t store_rps_dev_flow_table_cnt(struct netdev_rx_queue *queue,\r\nstruct rx_queue_attribute *attr,\r\nconst char *buf, size_t len)\r\n{\r\nunsigned long mask, count;\r\nstruct rps_dev_flow_table *table, *old_table;\r\nstatic DEFINE_SPINLOCK(rps_dev_flow_lock);\r\nint rc;\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nrc = kstrtoul(buf, 0, &count);\r\nif (rc < 0)\r\nreturn rc;\r\nif (count) {\r\nmask = count - 1;\r\nwhile ((mask | (mask >> 1)) != mask)\r\nmask |= (mask >> 1);\r\n#if BITS_PER_LONG > 32\r\nif (mask > (unsigned long)(u32)mask)\r\nreturn -EINVAL;\r\n#else\r\nif (mask > (ULONG_MAX - RPS_DEV_FLOW_TABLE_SIZE(1))\r\n/ sizeof(struct rps_dev_flow)) {\r\nreturn -EINVAL;\r\n}\r\n#endif\r\ntable = vmalloc(RPS_DEV_FLOW_TABLE_SIZE(mask + 1));\r\nif (!table)\r\nreturn -ENOMEM;\r\ntable->mask = mask;\r\nfor (count = 0; count <= mask; count++)\r\ntable->flows[count].cpu = RPS_NO_CPU;\r\n} else\r\ntable = NULL;\r\nspin_lock(&rps_dev_flow_lock);\r\nold_table = rcu_dereference_protected(queue->rps_flow_table,\r\nlockdep_is_held(&rps_dev_flow_lock));\r\nrcu_assign_pointer(queue->rps_flow_table, table);\r\nspin_unlock(&rps_dev_flow_lock);\r\nif (old_table)\r\ncall_rcu(&old_table->rcu, rps_dev_flow_table_release);\r\nreturn len;\r\n}\r\nstatic void rx_queue_release(struct kobject *kobj)\r\n{\r\nstruct netdev_rx_queue *queue = to_rx_queue(kobj);\r\nstruct rps_map *map;\r\nstruct rps_dev_flow_table *flow_table;\r\nmap = rcu_dereference_protected(queue->rps_map, 1);\r\nif (map) {\r\nRCU_INIT_POINTER(queue->rps_map, NULL);\r\nkfree_rcu(map, rcu);\r\n}\r\nflow_table = rcu_dereference_protected(queue->rps_flow_table, 1);\r\nif (flow_table) {\r\nRCU_INIT_POINTER(queue->rps_flow_table, NULL);\r\ncall_rcu(&flow_table->rcu, rps_dev_flow_table_release);\r\n}\r\nmemset(kobj, 0, sizeof(*kobj));\r\ndev_put(queue->dev);\r\n}\r\nstatic int rx_queue_add_kobject(struct net_device *net, int index)\r\n{\r\nstruct netdev_rx_queue *queue = net->_rx + index;\r\nstruct kobject *kobj = &queue->kobj;\r\nint error = 0;\r\nkobj->kset = net->queues_kset;\r\nerror = kobject_init_and_add(kobj, &rx_queue_ktype, NULL,\r\n"rx-%u", index);\r\nif (error) {\r\nkobject_put(kobj);\r\nreturn error;\r\n}\r\nkobject_uevent(kobj, KOBJ_ADD);\r\ndev_hold(queue->dev);\r\nreturn error;\r\n}\r\nint\r\nnet_rx_queue_update_kobjects(struct net_device *net, int old_num, int new_num)\r\n{\r\n#ifdef CONFIG_RPS\r\nint i;\r\nint error = 0;\r\nfor (i = old_num; i < new_num; i++) {\r\nerror = rx_queue_add_kobject(net, i);\r\nif (error) {\r\nnew_num = old_num;\r\nbreak;\r\n}\r\n}\r\nwhile (--i >= new_num)\r\nkobject_put(&net->_rx[i].kobj);\r\nreturn error;\r\n#else\r\nreturn 0;\r\n#endif\r\n}\r\nstatic ssize_t netdev_queue_attr_show(struct kobject *kobj,\r\nstruct attribute *attr, char *buf)\r\n{\r\nstruct netdev_queue_attribute *attribute = to_netdev_queue_attr(attr);\r\nstruct netdev_queue *queue = to_netdev_queue(kobj);\r\nif (!attribute->show)\r\nreturn -EIO;\r\nreturn attribute->show(queue, attribute, buf);\r\n}\r\nstatic ssize_t netdev_queue_attr_store(struct kobject *kobj,\r\nstruct attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nstruct netdev_queue_attribute *attribute = to_netdev_queue_attr(attr);\r\nstruct netdev_queue *queue = to_netdev_queue(kobj);\r\nif (!attribute->store)\r\nreturn -EIO;\r\nreturn attribute->store(queue, attribute, buf, count);\r\n}\r\nstatic ssize_t show_trans_timeout(struct netdev_queue *queue,\r\nstruct netdev_queue_attribute *attribute,\r\nchar *buf)\r\n{\r\nunsigned long trans_timeout;\r\nspin_lock_irq(&queue->_xmit_lock);\r\ntrans_timeout = queue->trans_timeout;\r\nspin_unlock_irq(&queue->_xmit_lock);\r\nreturn sprintf(buf, "%lu", trans_timeout);\r\n}\r\nstatic ssize_t bql_show(char *buf, unsigned int value)\r\n{\r\nreturn sprintf(buf, "%u\n", value);\r\n}\r\nstatic ssize_t bql_set(const char *buf, const size_t count,\r\nunsigned int *pvalue)\r\n{\r\nunsigned int value;\r\nint err;\r\nif (!strcmp(buf, "max") || !strcmp(buf, "max\n"))\r\nvalue = DQL_MAX_LIMIT;\r\nelse {\r\nerr = kstrtouint(buf, 10, &value);\r\nif (err < 0)\r\nreturn err;\r\nif (value > DQL_MAX_LIMIT)\r\nreturn -EINVAL;\r\n}\r\n*pvalue = value;\r\nreturn count;\r\n}\r\nstatic ssize_t bql_show_hold_time(struct netdev_queue *queue,\r\nstruct netdev_queue_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct dql *dql = &queue->dql;\r\nreturn sprintf(buf, "%u\n", jiffies_to_msecs(dql->slack_hold_time));\r\n}\r\nstatic ssize_t bql_set_hold_time(struct netdev_queue *queue,\r\nstruct netdev_queue_attribute *attribute,\r\nconst char *buf, size_t len)\r\n{\r\nstruct dql *dql = &queue->dql;\r\nunsigned int value;\r\nint err;\r\nerr = kstrtouint(buf, 10, &value);\r\nif (err < 0)\r\nreturn err;\r\ndql->slack_hold_time = msecs_to_jiffies(value);\r\nreturn len;\r\n}\r\nstatic ssize_t bql_show_inflight(struct netdev_queue *queue,\r\nstruct netdev_queue_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct dql *dql = &queue->dql;\r\nreturn sprintf(buf, "%u\n", dql->num_queued - dql->num_completed);\r\n}\r\nstatic inline unsigned int get_netdev_queue_index(struct netdev_queue *queue)\r\n{\r\nstruct net_device *dev = queue->dev;\r\nint i;\r\nfor (i = 0; i < dev->num_tx_queues; i++)\r\nif (queue == &dev->_tx[i])\r\nbreak;\r\nBUG_ON(i >= dev->num_tx_queues);\r\nreturn i;\r\n}\r\nstatic ssize_t show_xps_map(struct netdev_queue *queue,\r\nstruct netdev_queue_attribute *attribute, char *buf)\r\n{\r\nstruct net_device *dev = queue->dev;\r\nstruct xps_dev_maps *dev_maps;\r\ncpumask_var_t mask;\r\nunsigned long index;\r\nsize_t len = 0;\r\nint i;\r\nif (!zalloc_cpumask_var(&mask, GFP_KERNEL))\r\nreturn -ENOMEM;\r\nindex = get_netdev_queue_index(queue);\r\nrcu_read_lock();\r\ndev_maps = rcu_dereference(dev->xps_maps);\r\nif (dev_maps) {\r\nfor_each_possible_cpu(i) {\r\nstruct xps_map *map =\r\nrcu_dereference(dev_maps->cpu_map[i]);\r\nif (map) {\r\nint j;\r\nfor (j = 0; j < map->len; j++) {\r\nif (map->queues[j] == index) {\r\ncpumask_set_cpu(i, mask);\r\nbreak;\r\n}\r\n}\r\n}\r\n}\r\n}\r\nrcu_read_unlock();\r\nlen += cpumask_scnprintf(buf + len, PAGE_SIZE, mask);\r\nif (PAGE_SIZE - len < 3) {\r\nfree_cpumask_var(mask);\r\nreturn -EINVAL;\r\n}\r\nfree_cpumask_var(mask);\r\nlen += sprintf(buf + len, "\n");\r\nreturn len;\r\n}\r\nstatic ssize_t store_xps_map(struct netdev_queue *queue,\r\nstruct netdev_queue_attribute *attribute,\r\nconst char *buf, size_t len)\r\n{\r\nstruct net_device *dev = queue->dev;\r\nunsigned long index;\r\ncpumask_var_t mask;\r\nint err;\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nif (!alloc_cpumask_var(&mask, GFP_KERNEL))\r\nreturn -ENOMEM;\r\nindex = get_netdev_queue_index(queue);\r\nerr = bitmap_parse(buf, len, cpumask_bits(mask), nr_cpumask_bits);\r\nif (err) {\r\nfree_cpumask_var(mask);\r\nreturn err;\r\n}\r\nerr = netif_set_xps_queue(dev, mask, index);\r\nfree_cpumask_var(mask);\r\nreturn err ? : len;\r\n}\r\nstatic void netdev_queue_release(struct kobject *kobj)\r\n{\r\nstruct netdev_queue *queue = to_netdev_queue(kobj);\r\nmemset(kobj, 0, sizeof(*kobj));\r\ndev_put(queue->dev);\r\n}\r\nstatic int netdev_queue_add_kobject(struct net_device *net, int index)\r\n{\r\nstruct netdev_queue *queue = net->_tx + index;\r\nstruct kobject *kobj = &queue->kobj;\r\nint error = 0;\r\nkobj->kset = net->queues_kset;\r\nerror = kobject_init_and_add(kobj, &netdev_queue_ktype, NULL,\r\n"tx-%u", index);\r\nif (error)\r\ngoto exit;\r\n#ifdef CONFIG_BQL\r\nerror = sysfs_create_group(kobj, &dql_group);\r\nif (error)\r\ngoto exit;\r\n#endif\r\nkobject_uevent(kobj, KOBJ_ADD);\r\ndev_hold(queue->dev);\r\nreturn 0;\r\nexit:\r\nkobject_put(kobj);\r\nreturn error;\r\n}\r\nint\r\nnetdev_queue_update_kobjects(struct net_device *net, int old_num, int new_num)\r\n{\r\n#ifdef CONFIG_SYSFS\r\nint i;\r\nint error = 0;\r\nfor (i = old_num; i < new_num; i++) {\r\nerror = netdev_queue_add_kobject(net, i);\r\nif (error) {\r\nnew_num = old_num;\r\nbreak;\r\n}\r\n}\r\nwhile (--i >= new_num) {\r\nstruct netdev_queue *queue = net->_tx + i;\r\n#ifdef CONFIG_BQL\r\nsysfs_remove_group(&queue->kobj, &dql_group);\r\n#endif\r\nkobject_put(&queue->kobj);\r\n}\r\nreturn error;\r\n#else\r\nreturn 0;\r\n#endif\r\n}\r\nstatic int register_queue_kobjects(struct net_device *net)\r\n{\r\nint error = 0, txq = 0, rxq = 0, real_rx = 0, real_tx = 0;\r\n#ifdef CONFIG_SYSFS\r\nnet->queues_kset = kset_create_and_add("queues",\r\nNULL, &net->dev.kobj);\r\nif (!net->queues_kset)\r\nreturn -ENOMEM;\r\n#endif\r\n#ifdef CONFIG_RPS\r\nreal_rx = net->real_num_rx_queues;\r\n#endif\r\nreal_tx = net->real_num_tx_queues;\r\nerror = net_rx_queue_update_kobjects(net, 0, real_rx);\r\nif (error)\r\ngoto error;\r\nrxq = real_rx;\r\nerror = netdev_queue_update_kobjects(net, 0, real_tx);\r\nif (error)\r\ngoto error;\r\ntxq = real_tx;\r\nreturn 0;\r\nerror:\r\nnetdev_queue_update_kobjects(net, txq, 0);\r\nnet_rx_queue_update_kobjects(net, rxq, 0);\r\nreturn error;\r\n}\r\nstatic void remove_queue_kobjects(struct net_device *net)\r\n{\r\nint real_rx = 0, real_tx = 0;\r\n#ifdef CONFIG_RPS\r\nreal_rx = net->real_num_rx_queues;\r\n#endif\r\nreal_tx = net->real_num_tx_queues;\r\nnet_rx_queue_update_kobjects(net, real_rx, 0);\r\nnetdev_queue_update_kobjects(net, real_tx, 0);\r\n#ifdef CONFIG_SYSFS\r\nkset_unregister(net->queues_kset);\r\n#endif\r\n}\r\nstatic void *net_grab_current_ns(void)\r\n{\r\nstruct net *ns = current->nsproxy->net_ns;\r\n#ifdef CONFIG_NET_NS\r\nif (ns)\r\natomic_inc(&ns->passive);\r\n#endif\r\nreturn ns;\r\n}\r\nstatic const void *net_initial_ns(void)\r\n{\r\nreturn &init_net;\r\n}\r\nstatic const void *net_netlink_ns(struct sock *sk)\r\n{\r\nreturn sock_net(sk);\r\n}\r\nstatic int netdev_uevent(struct device *d, struct kobj_uevent_env *env)\r\n{\r\nstruct net_device *dev = to_net_dev(d);\r\nint retval;\r\nretval = add_uevent_var(env, "INTERFACE=%s", dev->name);\r\nif (retval)\r\ngoto exit;\r\nretval = add_uevent_var(env, "IFINDEX=%d", dev->ifindex);\r\nexit:\r\nreturn retval;\r\n}\r\nstatic void netdev_release(struct device *d)\r\n{\r\nstruct net_device *dev = to_net_dev(d);\r\nBUG_ON(dev->reg_state != NETREG_RELEASED);\r\nkfree(dev->ifalias);\r\nkfree((char *)dev - dev->padded);\r\n}\r\nstatic const void *net_namespace(struct device *d)\r\n{\r\nstruct net_device *dev;\r\ndev = container_of(d, struct net_device, dev);\r\nreturn dev_net(dev);\r\n}\r\nvoid netdev_unregister_kobject(struct net_device * net)\r\n{\r\nstruct device *dev = &(net->dev);\r\nkobject_get(&dev->kobj);\r\nremove_queue_kobjects(net);\r\npm_runtime_set_memalloc_noio(dev, false);\r\ndevice_del(dev);\r\n}\r\nint netdev_register_kobject(struct net_device *net)\r\n{\r\nstruct device *dev = &(net->dev);\r\nconst struct attribute_group **groups = net->sysfs_groups;\r\nint error = 0;\r\ndevice_initialize(dev);\r\ndev->class = &net_class;\r\ndev->platform_data = net;\r\ndev->groups = groups;\r\ndev_set_name(dev, "%s", net->name);\r\n#ifdef CONFIG_SYSFS\r\nif (*groups)\r\ngroups++;\r\n*groups++ = &netstat_group;\r\n#if IS_ENABLED(CONFIG_WIRELESS_EXT) || IS_ENABLED(CONFIG_CFG80211)\r\nif (net->ieee80211_ptr)\r\n*groups++ = &wireless_group;\r\n#if IS_ENABLED(CONFIG_WIRELESS_EXT)\r\nelse if (net->wireless_handlers)\r\n*groups++ = &wireless_group;\r\n#endif\r\n#endif\r\n#endif\r\nerror = device_add(dev);\r\nif (error)\r\nreturn error;\r\nerror = register_queue_kobjects(net);\r\nif (error) {\r\ndevice_del(dev);\r\nreturn error;\r\n}\r\npm_runtime_set_memalloc_noio(dev, true);\r\nreturn error;\r\n}\r\nint netdev_class_create_file(struct class_attribute *class_attr)\r\n{\r\nreturn class_create_file(&net_class, class_attr);\r\n}\r\nvoid netdev_class_remove_file(struct class_attribute *class_attr)\r\n{\r\nclass_remove_file(&net_class, class_attr);\r\n}\r\nint netdev_kobject_init(void)\r\n{\r\nkobj_ns_type_register(&net_ns_type_operations);\r\nreturn class_register(&net_class);\r\n}
