int bnx2fc_send_stat_req(struct bnx2fc_hba *hba)\r\n{\r\nstruct fcoe_kwqe_stat stat_req;\r\nstruct kwqe *kwqe_arr[2];\r\nint num_kwqes = 1;\r\nint rc = 0;\r\nmemset(&stat_req, 0x00, sizeof(struct fcoe_kwqe_stat));\r\nstat_req.hdr.op_code = FCOE_KWQE_OPCODE_STAT;\r\nstat_req.hdr.flags =\r\n(FCOE_KWQE_LAYER_CODE << FCOE_KWQE_HEADER_LAYER_CODE_SHIFT);\r\nstat_req.stat_params_addr_lo = (u32) hba->stats_buf_dma;\r\nstat_req.stat_params_addr_hi = (u32) ((u64)hba->stats_buf_dma >> 32);\r\nkwqe_arr[0] = (struct kwqe *) &stat_req;\r\nif (hba->cnic && hba->cnic->submit_kwqes)\r\nrc = hba->cnic->submit_kwqes(hba->cnic, kwqe_arr, num_kwqes);\r\nreturn rc;\r\n}\r\nint bnx2fc_send_fw_fcoe_init_msg(struct bnx2fc_hba *hba)\r\n{\r\nstruct fcoe_kwqe_init1 fcoe_init1;\r\nstruct fcoe_kwqe_init2 fcoe_init2;\r\nstruct fcoe_kwqe_init3 fcoe_init3;\r\nstruct kwqe *kwqe_arr[3];\r\nint num_kwqes = 3;\r\nint rc = 0;\r\nif (!hba->cnic) {\r\nprintk(KERN_ERR PFX "hba->cnic NULL during fcoe fw init\n");\r\nreturn -ENODEV;\r\n}\r\nmemset(&fcoe_init1, 0x00, sizeof(struct fcoe_kwqe_init1));\r\nfcoe_init1.hdr.op_code = FCOE_KWQE_OPCODE_INIT1;\r\nfcoe_init1.hdr.flags = (FCOE_KWQE_LAYER_CODE <<\r\nFCOE_KWQE_HEADER_LAYER_CODE_SHIFT);\r\nfcoe_init1.num_tasks = hba->max_tasks;\r\nfcoe_init1.sq_num_wqes = BNX2FC_SQ_WQES_MAX;\r\nfcoe_init1.rq_num_wqes = BNX2FC_RQ_WQES_MAX;\r\nfcoe_init1.rq_buffer_log_size = BNX2FC_RQ_BUF_LOG_SZ;\r\nfcoe_init1.cq_num_wqes = BNX2FC_CQ_WQES_MAX;\r\nfcoe_init1.dummy_buffer_addr_lo = (u32) hba->dummy_buf_dma;\r\nfcoe_init1.dummy_buffer_addr_hi = (u32) ((u64)hba->dummy_buf_dma >> 32);\r\nfcoe_init1.task_list_pbl_addr_lo = (u32) hba->task_ctx_bd_dma;\r\nfcoe_init1.task_list_pbl_addr_hi =\r\n(u32) ((u64) hba->task_ctx_bd_dma >> 32);\r\nfcoe_init1.mtu = BNX2FC_MINI_JUMBO_MTU;\r\nfcoe_init1.flags = (PAGE_SHIFT <<\r\nFCOE_KWQE_INIT1_LOG_PAGE_SIZE_SHIFT);\r\nfcoe_init1.num_sessions_log = BNX2FC_NUM_MAX_SESS_LOG;\r\nmemset(&fcoe_init2, 0x00, sizeof(struct fcoe_kwqe_init2));\r\nfcoe_init2.hdr.op_code = FCOE_KWQE_OPCODE_INIT2;\r\nfcoe_init2.hdr.flags = (FCOE_KWQE_LAYER_CODE <<\r\nFCOE_KWQE_HEADER_LAYER_CODE_SHIFT);\r\nfcoe_init2.hsi_major_version = FCOE_HSI_MAJOR_VERSION;\r\nfcoe_init2.hsi_minor_version = FCOE_HSI_MINOR_VERSION;\r\nfcoe_init2.hash_tbl_pbl_addr_lo = (u32) hba->hash_tbl_pbl_dma;\r\nfcoe_init2.hash_tbl_pbl_addr_hi = (u32)\r\n((u64) hba->hash_tbl_pbl_dma >> 32);\r\nfcoe_init2.t2_hash_tbl_addr_lo = (u32) hba->t2_hash_tbl_dma;\r\nfcoe_init2.t2_hash_tbl_addr_hi = (u32)\r\n((u64) hba->t2_hash_tbl_dma >> 32);\r\nfcoe_init2.t2_ptr_hash_tbl_addr_lo = (u32) hba->t2_hash_tbl_ptr_dma;\r\nfcoe_init2.t2_ptr_hash_tbl_addr_hi = (u32)\r\n((u64) hba->t2_hash_tbl_ptr_dma >> 32);\r\nfcoe_init2.free_list_count = BNX2FC_NUM_MAX_SESS;\r\nmemset(&fcoe_init3, 0x00, sizeof(struct fcoe_kwqe_init3));\r\nfcoe_init3.hdr.op_code = FCOE_KWQE_OPCODE_INIT3;\r\nfcoe_init3.hdr.flags = (FCOE_KWQE_LAYER_CODE <<\r\nFCOE_KWQE_HEADER_LAYER_CODE_SHIFT);\r\nfcoe_init3.error_bit_map_lo = 0xffffffff;\r\nfcoe_init3.error_bit_map_hi = 0xffffffff;\r\nfcoe_init3.perf_config = 3;\r\nkwqe_arr[0] = (struct kwqe *) &fcoe_init1;\r\nkwqe_arr[1] = (struct kwqe *) &fcoe_init2;\r\nkwqe_arr[2] = (struct kwqe *) &fcoe_init3;\r\nif (hba->cnic && hba->cnic->submit_kwqes)\r\nrc = hba->cnic->submit_kwqes(hba->cnic, kwqe_arr, num_kwqes);\r\nreturn rc;\r\n}\r\nint bnx2fc_send_fw_fcoe_destroy_msg(struct bnx2fc_hba *hba)\r\n{\r\nstruct fcoe_kwqe_destroy fcoe_destroy;\r\nstruct kwqe *kwqe_arr[2];\r\nint num_kwqes = 1;\r\nint rc = -1;\r\nmemset(&fcoe_destroy, 0x00, sizeof(struct fcoe_kwqe_destroy));\r\nfcoe_destroy.hdr.op_code = FCOE_KWQE_OPCODE_DESTROY;\r\nfcoe_destroy.hdr.flags = (FCOE_KWQE_LAYER_CODE <<\r\nFCOE_KWQE_HEADER_LAYER_CODE_SHIFT);\r\nkwqe_arr[0] = (struct kwqe *) &fcoe_destroy;\r\nif (hba->cnic && hba->cnic->submit_kwqes)\r\nrc = hba->cnic->submit_kwqes(hba->cnic, kwqe_arr, num_kwqes);\r\nreturn rc;\r\n}\r\nint bnx2fc_send_session_ofld_req(struct fcoe_port *port,\r\nstruct bnx2fc_rport *tgt)\r\n{\r\nstruct fc_lport *lport = port->lport;\r\nstruct bnx2fc_interface *interface = port->priv;\r\nstruct fcoe_ctlr *ctlr = bnx2fc_to_ctlr(interface);\r\nstruct bnx2fc_hba *hba = interface->hba;\r\nstruct kwqe *kwqe_arr[4];\r\nstruct fcoe_kwqe_conn_offload1 ofld_req1;\r\nstruct fcoe_kwqe_conn_offload2 ofld_req2;\r\nstruct fcoe_kwqe_conn_offload3 ofld_req3;\r\nstruct fcoe_kwqe_conn_offload4 ofld_req4;\r\nstruct fc_rport_priv *rdata = tgt->rdata;\r\nstruct fc_rport *rport = tgt->rport;\r\nint num_kwqes = 4;\r\nu32 port_id;\r\nint rc = 0;\r\nu16 conn_id;\r\nmemset(&ofld_req1, 0x00, sizeof(struct fcoe_kwqe_conn_offload1));\r\nofld_req1.hdr.op_code = FCOE_KWQE_OPCODE_OFFLOAD_CONN1;\r\nofld_req1.hdr.flags =\r\n(FCOE_KWQE_LAYER_CODE << FCOE_KWQE_HEADER_LAYER_CODE_SHIFT);\r\nconn_id = (u16)tgt->fcoe_conn_id;\r\nofld_req1.fcoe_conn_id = conn_id;\r\nofld_req1.sq_addr_lo = (u32) tgt->sq_dma;\r\nofld_req1.sq_addr_hi = (u32)((u64) tgt->sq_dma >> 32);\r\nofld_req1.rq_pbl_addr_lo = (u32) tgt->rq_pbl_dma;\r\nofld_req1.rq_pbl_addr_hi = (u32)((u64) tgt->rq_pbl_dma >> 32);\r\nofld_req1.rq_first_pbe_addr_lo = (u32) tgt->rq_dma;\r\nofld_req1.rq_first_pbe_addr_hi =\r\n(u32)((u64) tgt->rq_dma >> 32);\r\nofld_req1.rq_prod = 0x8000;\r\nmemset(&ofld_req2, 0x00, sizeof(struct fcoe_kwqe_conn_offload2));\r\nofld_req2.hdr.op_code = FCOE_KWQE_OPCODE_OFFLOAD_CONN2;\r\nofld_req2.hdr.flags =\r\n(FCOE_KWQE_LAYER_CODE << FCOE_KWQE_HEADER_LAYER_CODE_SHIFT);\r\nofld_req2.tx_max_fc_pay_len = rdata->maxframe_size;\r\nofld_req2.cq_addr_lo = (u32) tgt->cq_dma;\r\nofld_req2.cq_addr_hi = (u32)((u64)tgt->cq_dma >> 32);\r\nofld_req2.xferq_addr_lo = (u32) tgt->xferq_dma;\r\nofld_req2.xferq_addr_hi = (u32)((u64)tgt->xferq_dma >> 32);\r\nofld_req2.conn_db_addr_lo = (u32)tgt->conn_db_dma;\r\nofld_req2.conn_db_addr_hi = (u32)((u64)tgt->conn_db_dma >> 32);\r\nmemset(&ofld_req3, 0x00, sizeof(struct fcoe_kwqe_conn_offload3));\r\nofld_req3.hdr.op_code = FCOE_KWQE_OPCODE_OFFLOAD_CONN3;\r\nofld_req3.hdr.flags =\r\n(FCOE_KWQE_LAYER_CODE << FCOE_KWQE_HEADER_LAYER_CODE_SHIFT);\r\nofld_req3.vlan_tag = interface->vlan_id <<\r\nFCOE_KWQE_CONN_OFFLOAD3_VLAN_ID_SHIFT;\r\nofld_req3.vlan_tag |= 3 << FCOE_KWQE_CONN_OFFLOAD3_PRIORITY_SHIFT;\r\nport_id = fc_host_port_id(lport->host);\r\nif (port_id == 0) {\r\nBNX2FC_HBA_DBG(lport, "ofld_req: port_id = 0, link down?\n");\r\nreturn -EINVAL;\r\n}\r\ntgt->sid = port_id;\r\nofld_req3.s_id[0] = (port_id & 0x000000FF);\r\nofld_req3.s_id[1] = (port_id & 0x0000FF00) >> 8;\r\nofld_req3.s_id[2] = (port_id & 0x00FF0000) >> 16;\r\nport_id = rport->port_id;\r\nofld_req3.d_id[0] = (port_id & 0x000000FF);\r\nofld_req3.d_id[1] = (port_id & 0x0000FF00) >> 8;\r\nofld_req3.d_id[2] = (port_id & 0x00FF0000) >> 16;\r\nofld_req3.tx_total_conc_seqs = rdata->max_seq;\r\nofld_req3.tx_max_conc_seqs_c3 = rdata->max_seq;\r\nofld_req3.rx_max_fc_pay_len = lport->mfs;\r\nofld_req3.rx_total_conc_seqs = BNX2FC_MAX_SEQS;\r\nofld_req3.rx_max_conc_seqs_c3 = BNX2FC_MAX_SEQS;\r\nofld_req3.rx_open_seqs_exch_c3 = 1;\r\nofld_req3.confq_first_pbe_addr_lo = tgt->confq_dma;\r\nofld_req3.confq_first_pbe_addr_hi = (u32)((u64) tgt->confq_dma >> 32);\r\nofld_req3.flags = 0;\r\nofld_req3.flags |= (((rdata->sp_features & FC_SP_FT_EDTR) ? 1 : 0) <<\r\nFCOE_KWQE_CONN_OFFLOAD3_B_E_D_TOV_RES_SHIFT);\r\nofld_req3.flags |= (((rdata->sp_features & FC_SP_FT_SEQC) ? 1 : 0) <<\r\nFCOE_KWQE_CONN_OFFLOAD3_B_CONT_INCR_SEQ_CNT_SHIFT);\r\nif (tgt->dev_type == TYPE_TAPE) {\r\nofld_req3.flags |= 1 <<\r\nFCOE_KWQE_CONN_OFFLOAD3_B_CONF_REQ_SHIFT;\r\nofld_req3.flags |= (((rdata->flags & FC_RP_FLAGS_REC_SUPPORTED)\r\n? 1 : 0) <<\r\nFCOE_KWQE_CONN_OFFLOAD3_B_REC_VALID_SHIFT);\r\n}\r\nofld_req3.flags |= (interface->vlan_enabled <<\r\nFCOE_KWQE_CONN_OFFLOAD3_B_VLAN_FLAG_SHIFT);\r\nmemset(&ofld_req4, 0x00, sizeof(struct fcoe_kwqe_conn_offload4));\r\nofld_req4.hdr.op_code = FCOE_KWQE_OPCODE_OFFLOAD_CONN4;\r\nofld_req4.hdr.flags =\r\n(FCOE_KWQE_LAYER_CODE << FCOE_KWQE_HEADER_LAYER_CODE_SHIFT);\r\nofld_req4.e_d_tov_timer_val = lport->e_d_tov / 20;\r\nofld_req4.src_mac_addr_lo[0] = port->data_src_addr[5];\r\nofld_req4.src_mac_addr_lo[1] = port->data_src_addr[4];\r\nofld_req4.src_mac_addr_mid[0] = port->data_src_addr[3];\r\nofld_req4.src_mac_addr_mid[1] = port->data_src_addr[2];\r\nofld_req4.src_mac_addr_hi[0] = port->data_src_addr[1];\r\nofld_req4.src_mac_addr_hi[1] = port->data_src_addr[0];\r\nofld_req4.dst_mac_addr_lo[0] = ctlr->dest_addr[5];\r\nofld_req4.dst_mac_addr_lo[1] = ctlr->dest_addr[4];\r\nofld_req4.dst_mac_addr_mid[0] = ctlr->dest_addr[3];\r\nofld_req4.dst_mac_addr_mid[1] = ctlr->dest_addr[2];\r\nofld_req4.dst_mac_addr_hi[0] = ctlr->dest_addr[1];\r\nofld_req4.dst_mac_addr_hi[1] = ctlr->dest_addr[0];\r\nofld_req4.lcq_addr_lo = (u32) tgt->lcq_dma;\r\nofld_req4.lcq_addr_hi = (u32)((u64) tgt->lcq_dma >> 32);\r\nofld_req4.confq_pbl_base_addr_lo = (u32) tgt->confq_pbl_dma;\r\nofld_req4.confq_pbl_base_addr_hi =\r\n(u32)((u64) tgt->confq_pbl_dma >> 32);\r\nkwqe_arr[0] = (struct kwqe *) &ofld_req1;\r\nkwqe_arr[1] = (struct kwqe *) &ofld_req2;\r\nkwqe_arr[2] = (struct kwqe *) &ofld_req3;\r\nkwqe_arr[3] = (struct kwqe *) &ofld_req4;\r\nif (hba->cnic && hba->cnic->submit_kwqes)\r\nrc = hba->cnic->submit_kwqes(hba->cnic, kwqe_arr, num_kwqes);\r\nreturn rc;\r\n}\r\nint bnx2fc_send_session_enable_req(struct fcoe_port *port,\r\nstruct bnx2fc_rport *tgt)\r\n{\r\nstruct kwqe *kwqe_arr[2];\r\nstruct bnx2fc_interface *interface = port->priv;\r\nstruct fcoe_ctlr *ctlr = bnx2fc_to_ctlr(interface);\r\nstruct bnx2fc_hba *hba = interface->hba;\r\nstruct fcoe_kwqe_conn_enable_disable enbl_req;\r\nstruct fc_lport *lport = port->lport;\r\nstruct fc_rport *rport = tgt->rport;\r\nint num_kwqes = 1;\r\nint rc = 0;\r\nu32 port_id;\r\nmemset(&enbl_req, 0x00,\r\nsizeof(struct fcoe_kwqe_conn_enable_disable));\r\nenbl_req.hdr.op_code = FCOE_KWQE_OPCODE_ENABLE_CONN;\r\nenbl_req.hdr.flags =\r\n(FCOE_KWQE_LAYER_CODE << FCOE_KWQE_HEADER_LAYER_CODE_SHIFT);\r\nenbl_req.src_mac_addr_lo[0] = port->data_src_addr[5];\r\nenbl_req.src_mac_addr_lo[1] = port->data_src_addr[4];\r\nenbl_req.src_mac_addr_mid[0] = port->data_src_addr[3];\r\nenbl_req.src_mac_addr_mid[1] = port->data_src_addr[2];\r\nenbl_req.src_mac_addr_hi[0] = port->data_src_addr[1];\r\nenbl_req.src_mac_addr_hi[1] = port->data_src_addr[0];\r\nmemcpy(tgt->src_addr, port->data_src_addr, ETH_ALEN);\r\nenbl_req.dst_mac_addr_lo[0] = ctlr->dest_addr[5];\r\nenbl_req.dst_mac_addr_lo[1] = ctlr->dest_addr[4];\r\nenbl_req.dst_mac_addr_mid[0] = ctlr->dest_addr[3];\r\nenbl_req.dst_mac_addr_mid[1] = ctlr->dest_addr[2];\r\nenbl_req.dst_mac_addr_hi[0] = ctlr->dest_addr[1];\r\nenbl_req.dst_mac_addr_hi[1] = ctlr->dest_addr[0];\r\nport_id = fc_host_port_id(lport->host);\r\nif (port_id != tgt->sid) {\r\nprintk(KERN_ERR PFX "WARN: enable_req port_id = 0x%x,"\r\n"sid = 0x%x\n", port_id, tgt->sid);\r\nport_id = tgt->sid;\r\n}\r\nenbl_req.s_id[0] = (port_id & 0x000000FF);\r\nenbl_req.s_id[1] = (port_id & 0x0000FF00) >> 8;\r\nenbl_req.s_id[2] = (port_id & 0x00FF0000) >> 16;\r\nport_id = rport->port_id;\r\nenbl_req.d_id[0] = (port_id & 0x000000FF);\r\nenbl_req.d_id[1] = (port_id & 0x0000FF00) >> 8;\r\nenbl_req.d_id[2] = (port_id & 0x00FF0000) >> 16;\r\nenbl_req.vlan_tag = interface->vlan_id <<\r\nFCOE_KWQE_CONN_ENABLE_DISABLE_VLAN_ID_SHIFT;\r\nenbl_req.vlan_tag |= 3 << FCOE_KWQE_CONN_ENABLE_DISABLE_PRIORITY_SHIFT;\r\nenbl_req.vlan_flag = interface->vlan_enabled;\r\nenbl_req.context_id = tgt->context_id;\r\nenbl_req.conn_id = tgt->fcoe_conn_id;\r\nkwqe_arr[0] = (struct kwqe *) &enbl_req;\r\nif (hba->cnic && hba->cnic->submit_kwqes)\r\nrc = hba->cnic->submit_kwqes(hba->cnic, kwqe_arr, num_kwqes);\r\nreturn rc;\r\n}\r\nint bnx2fc_send_session_disable_req(struct fcoe_port *port,\r\nstruct bnx2fc_rport *tgt)\r\n{\r\nstruct bnx2fc_interface *interface = port->priv;\r\nstruct fcoe_ctlr *ctlr = bnx2fc_to_ctlr(interface);\r\nstruct bnx2fc_hba *hba = interface->hba;\r\nstruct fcoe_kwqe_conn_enable_disable disable_req;\r\nstruct kwqe *kwqe_arr[2];\r\nstruct fc_rport *rport = tgt->rport;\r\nint num_kwqes = 1;\r\nint rc = 0;\r\nu32 port_id;\r\nmemset(&disable_req, 0x00,\r\nsizeof(struct fcoe_kwqe_conn_enable_disable));\r\ndisable_req.hdr.op_code = FCOE_KWQE_OPCODE_DISABLE_CONN;\r\ndisable_req.hdr.flags =\r\n(FCOE_KWQE_LAYER_CODE << FCOE_KWQE_HEADER_LAYER_CODE_SHIFT);\r\ndisable_req.src_mac_addr_lo[0] = tgt->src_addr[5];\r\ndisable_req.src_mac_addr_lo[1] = tgt->src_addr[4];\r\ndisable_req.src_mac_addr_mid[0] = tgt->src_addr[3];\r\ndisable_req.src_mac_addr_mid[1] = tgt->src_addr[2];\r\ndisable_req.src_mac_addr_hi[0] = tgt->src_addr[1];\r\ndisable_req.src_mac_addr_hi[1] = tgt->src_addr[0];\r\ndisable_req.dst_mac_addr_lo[0] = ctlr->dest_addr[5];\r\ndisable_req.dst_mac_addr_lo[1] = ctlr->dest_addr[4];\r\ndisable_req.dst_mac_addr_mid[0] = ctlr->dest_addr[3];\r\ndisable_req.dst_mac_addr_mid[1] = ctlr->dest_addr[2];\r\ndisable_req.dst_mac_addr_hi[0] = ctlr->dest_addr[1];\r\ndisable_req.dst_mac_addr_hi[1] = ctlr->dest_addr[0];\r\nport_id = tgt->sid;\r\ndisable_req.s_id[0] = (port_id & 0x000000FF);\r\ndisable_req.s_id[1] = (port_id & 0x0000FF00) >> 8;\r\ndisable_req.s_id[2] = (port_id & 0x00FF0000) >> 16;\r\nport_id = rport->port_id;\r\ndisable_req.d_id[0] = (port_id & 0x000000FF);\r\ndisable_req.d_id[1] = (port_id & 0x0000FF00) >> 8;\r\ndisable_req.d_id[2] = (port_id & 0x00FF0000) >> 16;\r\ndisable_req.context_id = tgt->context_id;\r\ndisable_req.conn_id = tgt->fcoe_conn_id;\r\ndisable_req.vlan_tag = interface->vlan_id <<\r\nFCOE_KWQE_CONN_ENABLE_DISABLE_VLAN_ID_SHIFT;\r\ndisable_req.vlan_tag |=\r\n3 << FCOE_KWQE_CONN_ENABLE_DISABLE_PRIORITY_SHIFT;\r\ndisable_req.vlan_flag = interface->vlan_enabled;\r\nkwqe_arr[0] = (struct kwqe *) &disable_req;\r\nif (hba->cnic && hba->cnic->submit_kwqes)\r\nrc = hba->cnic->submit_kwqes(hba->cnic, kwqe_arr, num_kwqes);\r\nreturn rc;\r\n}\r\nint bnx2fc_send_session_destroy_req(struct bnx2fc_hba *hba,\r\nstruct bnx2fc_rport *tgt)\r\n{\r\nstruct fcoe_kwqe_conn_destroy destroy_req;\r\nstruct kwqe *kwqe_arr[2];\r\nint num_kwqes = 1;\r\nint rc = 0;\r\nmemset(&destroy_req, 0x00, sizeof(struct fcoe_kwqe_conn_destroy));\r\ndestroy_req.hdr.op_code = FCOE_KWQE_OPCODE_DESTROY_CONN;\r\ndestroy_req.hdr.flags =\r\n(FCOE_KWQE_LAYER_CODE << FCOE_KWQE_HEADER_LAYER_CODE_SHIFT);\r\ndestroy_req.context_id = tgt->context_id;\r\ndestroy_req.conn_id = tgt->fcoe_conn_id;\r\nkwqe_arr[0] = (struct kwqe *) &destroy_req;\r\nif (hba->cnic && hba->cnic->submit_kwqes)\r\nrc = hba->cnic->submit_kwqes(hba->cnic, kwqe_arr, num_kwqes);\r\nreturn rc;\r\n}\r\nstatic bool is_valid_lport(struct bnx2fc_hba *hba, struct fc_lport *lport)\r\n{\r\nstruct bnx2fc_lport *blport;\r\nspin_lock_bh(&hba->hba_lock);\r\nlist_for_each_entry(blport, &hba->vports, list) {\r\nif (blport->lport == lport) {\r\nspin_unlock_bh(&hba->hba_lock);\r\nreturn true;\r\n}\r\n}\r\nspin_unlock_bh(&hba->hba_lock);\r\nreturn false;\r\n}\r\nstatic void bnx2fc_unsol_els_work(struct work_struct *work)\r\n{\r\nstruct bnx2fc_unsol_els *unsol_els;\r\nstruct fc_lport *lport;\r\nstruct bnx2fc_hba *hba;\r\nstruct fc_frame *fp;\r\nunsol_els = container_of(work, struct bnx2fc_unsol_els, unsol_els_work);\r\nlport = unsol_els->lport;\r\nfp = unsol_els->fp;\r\nhba = unsol_els->hba;\r\nif (is_valid_lport(hba, lport))\r\nfc_exch_recv(lport, fp);\r\nkfree(unsol_els);\r\n}\r\nvoid bnx2fc_process_l2_frame_compl(struct bnx2fc_rport *tgt,\r\nunsigned char *buf,\r\nu32 frame_len, u16 l2_oxid)\r\n{\r\nstruct fcoe_port *port = tgt->port;\r\nstruct fc_lport *lport = port->lport;\r\nstruct bnx2fc_interface *interface = port->priv;\r\nstruct bnx2fc_unsol_els *unsol_els;\r\nstruct fc_frame_header *fh;\r\nstruct fc_frame *fp;\r\nstruct sk_buff *skb;\r\nu32 payload_len;\r\nu32 crc;\r\nu8 op;\r\nunsol_els = kzalloc(sizeof(*unsol_els), GFP_ATOMIC);\r\nif (!unsol_els) {\r\nBNX2FC_TGT_DBG(tgt, "Unable to allocate unsol_work\n");\r\nreturn;\r\n}\r\nBNX2FC_TGT_DBG(tgt, "l2_frame_compl l2_oxid = 0x%x, frame_len = %d\n",\r\nl2_oxid, frame_len);\r\npayload_len = frame_len - sizeof(struct fc_frame_header);\r\nfp = fc_frame_alloc(lport, payload_len);\r\nif (!fp) {\r\nprintk(KERN_ERR PFX "fc_frame_alloc failure\n");\r\nkfree(unsol_els);\r\nreturn;\r\n}\r\nfh = (struct fc_frame_header *) fc_frame_header_get(fp);\r\nmemcpy(fh, buf, frame_len);\r\nif (l2_oxid != FC_XID_UNKNOWN)\r\nfh->fh_ox_id = htons(l2_oxid);\r\nskb = fp_skb(fp);\r\nif ((fh->fh_r_ctl == FC_RCTL_ELS_REQ) ||\r\n(fh->fh_r_ctl == FC_RCTL_ELS_REP)) {\r\nif (fh->fh_type == FC_TYPE_ELS) {\r\nop = fc_frame_payload_op(fp);\r\nif ((op == ELS_TEST) || (op == ELS_ESTC) ||\r\n(op == ELS_FAN) || (op == ELS_CSU)) {\r\nprintk(KERN_ERR PFX "dropping ELS 0x%x\n", op);\r\nkfree_skb(skb);\r\nkfree(unsol_els);\r\nreturn;\r\n}\r\n}\r\ncrc = fcoe_fc_crc(fp);\r\nfc_frame_init(fp);\r\nfr_dev(fp) = lport;\r\nfr_sof(fp) = FC_SOF_I3;\r\nfr_eof(fp) = FC_EOF_T;\r\nfr_crc(fp) = cpu_to_le32(~crc);\r\nunsol_els->lport = lport;\r\nunsol_els->hba = interface->hba;\r\nunsol_els->fp = fp;\r\nINIT_WORK(&unsol_els->unsol_els_work, bnx2fc_unsol_els_work);\r\nqueue_work(bnx2fc_wq, &unsol_els->unsol_els_work);\r\n} else {\r\nBNX2FC_HBA_DBG(lport, "fh_r_ctl = 0x%x\n", fh->fh_r_ctl);\r\nkfree_skb(skb);\r\nkfree(unsol_els);\r\n}\r\n}\r\nstatic void bnx2fc_process_unsol_compl(struct bnx2fc_rport *tgt, u16 wqe)\r\n{\r\nu8 num_rq;\r\nstruct fcoe_err_report_entry *err_entry;\r\nunsigned char *rq_data;\r\nunsigned char *buf = NULL, *buf1;\r\nint i;\r\nu16 xid;\r\nu32 frame_len, len;\r\nstruct bnx2fc_cmd *io_req = NULL;\r\nstruct fcoe_task_ctx_entry *task, *task_page;\r\nstruct bnx2fc_interface *interface = tgt->port->priv;\r\nstruct bnx2fc_hba *hba = interface->hba;\r\nint task_idx, index;\r\nint rc = 0;\r\nu64 err_warn_bit_map;\r\nu8 err_warn = 0xff;\r\nBNX2FC_TGT_DBG(tgt, "Entered UNSOL COMPLETION wqe = 0x%x\n", wqe);\r\nswitch (wqe & FCOE_UNSOLICITED_CQE_SUBTYPE) {\r\ncase FCOE_UNSOLICITED_FRAME_CQE_TYPE:\r\nframe_len = (wqe & FCOE_UNSOLICITED_CQE_PKT_LEN) >>\r\nFCOE_UNSOLICITED_CQE_PKT_LEN_SHIFT;\r\nnum_rq = (frame_len + BNX2FC_RQ_BUF_SZ - 1) / BNX2FC_RQ_BUF_SZ;\r\nspin_lock_bh(&tgt->tgt_lock);\r\nrq_data = (unsigned char *)bnx2fc_get_next_rqe(tgt, num_rq);\r\nspin_unlock_bh(&tgt->tgt_lock);\r\nif (rq_data) {\r\nbuf = rq_data;\r\n} else {\r\nbuf1 = buf = kmalloc((num_rq * BNX2FC_RQ_BUF_SZ),\r\nGFP_ATOMIC);\r\nif (!buf1) {\r\nBNX2FC_TGT_DBG(tgt, "Memory alloc failure\n");\r\nbreak;\r\n}\r\nfor (i = 0; i < num_rq; i++) {\r\nspin_lock_bh(&tgt->tgt_lock);\r\nrq_data = (unsigned char *)\r\nbnx2fc_get_next_rqe(tgt, 1);\r\nspin_unlock_bh(&tgt->tgt_lock);\r\nlen = BNX2FC_RQ_BUF_SZ;\r\nmemcpy(buf1, rq_data, len);\r\nbuf1 += len;\r\n}\r\n}\r\nbnx2fc_process_l2_frame_compl(tgt, buf, frame_len,\r\nFC_XID_UNKNOWN);\r\nif (buf != rq_data)\r\nkfree(buf);\r\nspin_lock_bh(&tgt->tgt_lock);\r\nbnx2fc_return_rqe(tgt, num_rq);\r\nspin_unlock_bh(&tgt->tgt_lock);\r\nbreak;\r\ncase FCOE_ERROR_DETECTION_CQE_TYPE:\r\nspin_lock_bh(&tgt->tgt_lock);\r\nnum_rq = 1;\r\nerr_entry = (struct fcoe_err_report_entry *)\r\nbnx2fc_get_next_rqe(tgt, 1);\r\nxid = err_entry->fc_hdr.ox_id;\r\nBNX2FC_TGT_DBG(tgt, "Unsol Error Frame OX_ID = 0x%x\n", xid);\r\nBNX2FC_TGT_DBG(tgt, "err_warn_bitmap = %08x:%08x\n",\r\nerr_entry->data.err_warn_bitmap_hi,\r\nerr_entry->data.err_warn_bitmap_lo);\r\nBNX2FC_TGT_DBG(tgt, "buf_offsets - tx = 0x%x, rx = 0x%x\n",\r\nerr_entry->data.tx_buf_off, err_entry->data.rx_buf_off);\r\nif (xid > hba->max_xid) {\r\nBNX2FC_TGT_DBG(tgt, "xid(0x%x) out of FW range\n",\r\nxid);\r\ngoto ret_err_rqe;\r\n}\r\ntask_idx = xid / BNX2FC_TASKS_PER_PAGE;\r\nindex = xid % BNX2FC_TASKS_PER_PAGE;\r\ntask_page = (struct fcoe_task_ctx_entry *)\r\nhba->task_ctx[task_idx];\r\ntask = &(task_page[index]);\r\nio_req = (struct bnx2fc_cmd *)hba->cmd_mgr->cmds[xid];\r\nif (!io_req)\r\ngoto ret_err_rqe;\r\nif (io_req->cmd_type != BNX2FC_SCSI_CMD) {\r\nprintk(KERN_ERR PFX "err_warn: Not a SCSI cmd\n");\r\ngoto ret_err_rqe;\r\n}\r\nif (test_and_clear_bit(BNX2FC_FLAG_IO_CLEANUP,\r\n&io_req->req_flags)) {\r\nBNX2FC_IO_DBG(io_req, "unsol_err: cleanup in "\r\n"progress.. ignore unsol err\n");\r\ngoto ret_err_rqe;\r\n}\r\nerr_warn_bit_map = (u64)\r\n((u64)err_entry->data.err_warn_bitmap_hi << 32) |\r\n(u64)err_entry->data.err_warn_bitmap_lo;\r\nfor (i = 0; i < BNX2FC_NUM_ERR_BITS; i++) {\r\nif (err_warn_bit_map & (u64)((u64)1 << i)) {\r\nerr_warn = i;\r\nbreak;\r\n}\r\n}\r\nif (test_bit(BNX2FC_FLAG_ISSUE_ABTS, &io_req->req_flags)) {\r\nprintk(KERN_ERR PFX "err_warn: io_req (0x%x) already "\r\n"in ABTS processing\n", xid);\r\ngoto ret_err_rqe;\r\n}\r\nBNX2FC_TGT_DBG(tgt, "err = 0x%x\n", err_warn);\r\nif (tgt->dev_type != TYPE_TAPE)\r\ngoto skip_rec;\r\nswitch (err_warn) {\r\ncase FCOE_ERROR_CODE_REC_TOV_TIMER_EXPIRATION:\r\ncase FCOE_ERROR_CODE_DATA_OOO_RO:\r\ncase FCOE_ERROR_CODE_COMMON_INCORRECT_SEQ_CNT:\r\ncase FCOE_ERROR_CODE_DATA_SOFI3_SEQ_ACTIVE_SET:\r\ncase FCOE_ERROR_CODE_FCP_RSP_OPENED_SEQ:\r\ncase FCOE_ERROR_CODE_DATA_SOFN_SEQ_ACTIVE_RESET:\r\nBNX2FC_TGT_DBG(tgt, "REC TOV popped for xid - 0x%x\n",\r\nxid);\r\nmemcpy(&io_req->err_entry, err_entry,\r\nsizeof(struct fcoe_err_report_entry));\r\nif (!test_bit(BNX2FC_FLAG_SRR_SENT,\r\n&io_req->req_flags)) {\r\nspin_unlock_bh(&tgt->tgt_lock);\r\nrc = bnx2fc_send_rec(io_req);\r\nspin_lock_bh(&tgt->tgt_lock);\r\nif (rc)\r\ngoto skip_rec;\r\n} else\r\nprintk(KERN_ERR PFX "SRR in progress\n");\r\ngoto ret_err_rqe;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nskip_rec:\r\nset_bit(BNX2FC_FLAG_ISSUE_ABTS, &io_req->req_flags);\r\nif (cancel_delayed_work(&io_req->timeout_work))\r\nkref_put(&io_req->refcount, bnx2fc_cmd_release);\r\nrc = bnx2fc_initiate_abts(io_req);\r\nif (rc != SUCCESS) {\r\nprintk(KERN_ERR PFX "err_warn: initiate_abts "\r\n"failed xid = 0x%x. issue cleanup\n",\r\nio_req->xid);\r\nbnx2fc_initiate_cleanup(io_req);\r\n}\r\nret_err_rqe:\r\nbnx2fc_return_rqe(tgt, 1);\r\nspin_unlock_bh(&tgt->tgt_lock);\r\nbreak;\r\ncase FCOE_WARNING_DETECTION_CQE_TYPE:\r\nspin_lock_bh(&tgt->tgt_lock);\r\nnum_rq = 1;\r\nerr_entry = (struct fcoe_err_report_entry *)\r\nbnx2fc_get_next_rqe(tgt, 1);\r\nxid = cpu_to_be16(err_entry->fc_hdr.ox_id);\r\nBNX2FC_TGT_DBG(tgt, "Unsol Warning Frame OX_ID = 0x%x\n", xid);\r\nBNX2FC_TGT_DBG(tgt, "err_warn_bitmap = %08x:%08x",\r\nerr_entry->data.err_warn_bitmap_hi,\r\nerr_entry->data.err_warn_bitmap_lo);\r\nBNX2FC_TGT_DBG(tgt, "buf_offsets - tx = 0x%x, rx = 0x%x",\r\nerr_entry->data.tx_buf_off, err_entry->data.rx_buf_off);\r\nif (xid > hba->max_xid) {\r\nBNX2FC_TGT_DBG(tgt, "xid(0x%x) out of FW range\n", xid);\r\ngoto ret_warn_rqe;\r\n}\r\nerr_warn_bit_map = (u64)\r\n((u64)err_entry->data.err_warn_bitmap_hi << 32) |\r\n(u64)err_entry->data.err_warn_bitmap_lo;\r\nfor (i = 0; i < BNX2FC_NUM_ERR_BITS; i++) {\r\nif (err_warn_bit_map & (u64) (1 << i)) {\r\nerr_warn = i;\r\nbreak;\r\n}\r\n}\r\nBNX2FC_TGT_DBG(tgt, "warn = 0x%x\n", err_warn);\r\ntask_idx = xid / BNX2FC_TASKS_PER_PAGE;\r\nindex = xid % BNX2FC_TASKS_PER_PAGE;\r\ntask_page = (struct fcoe_task_ctx_entry *)\r\ninterface->hba->task_ctx[task_idx];\r\ntask = &(task_page[index]);\r\nio_req = (struct bnx2fc_cmd *)hba->cmd_mgr->cmds[xid];\r\nif (!io_req)\r\ngoto ret_warn_rqe;\r\nif (io_req->cmd_type != BNX2FC_SCSI_CMD) {\r\nprintk(KERN_ERR PFX "err_warn: Not a SCSI cmd\n");\r\ngoto ret_warn_rqe;\r\n}\r\nmemcpy(&io_req->err_entry, err_entry,\r\nsizeof(struct fcoe_err_report_entry));\r\nif (err_warn == FCOE_ERROR_CODE_REC_TOV_TIMER_EXPIRATION)\r\nBUG_ON(1);\r\nelse\r\nBNX2FC_TGT_DBG(tgt, "Unsolicited warning\n");\r\nret_warn_rqe:\r\nbnx2fc_return_rqe(tgt, 1);\r\nspin_unlock_bh(&tgt->tgt_lock);\r\nbreak;\r\ndefault:\r\nprintk(KERN_ERR PFX "Unsol Compl: Invalid CQE Subtype\n");\r\nbreak;\r\n}\r\n}\r\nvoid bnx2fc_process_cq_compl(struct bnx2fc_rport *tgt, u16 wqe)\r\n{\r\nstruct fcoe_task_ctx_entry *task;\r\nstruct fcoe_task_ctx_entry *task_page;\r\nstruct fcoe_port *port = tgt->port;\r\nstruct bnx2fc_interface *interface = port->priv;\r\nstruct bnx2fc_hba *hba = interface->hba;\r\nstruct bnx2fc_cmd *io_req;\r\nint task_idx, index;\r\nu16 xid;\r\nu8 cmd_type;\r\nu8 rx_state = 0;\r\nu8 num_rq;\r\nspin_lock_bh(&tgt->tgt_lock);\r\nxid = wqe & FCOE_PEND_WQ_CQE_TASK_ID;\r\nif (xid >= hba->max_tasks) {\r\nprintk(KERN_ERR PFX "ERROR:xid out of range\n");\r\nspin_unlock_bh(&tgt->tgt_lock);\r\nreturn;\r\n}\r\ntask_idx = xid / BNX2FC_TASKS_PER_PAGE;\r\nindex = xid % BNX2FC_TASKS_PER_PAGE;\r\ntask_page = (struct fcoe_task_ctx_entry *)hba->task_ctx[task_idx];\r\ntask = &(task_page[index]);\r\nnum_rq = ((task->rxwr_txrd.var_ctx.rx_flags &\r\nFCOE_TCE_RX_WR_TX_RD_VAR_NUM_RQ_WQE) >>\r\nFCOE_TCE_RX_WR_TX_RD_VAR_NUM_RQ_WQE_SHIFT);\r\nio_req = (struct bnx2fc_cmd *)hba->cmd_mgr->cmds[xid];\r\nif (io_req == NULL) {\r\nprintk(KERN_ERR PFX "ERROR? cq_compl - io_req is NULL\n");\r\nspin_unlock_bh(&tgt->tgt_lock);\r\nreturn;\r\n}\r\ncmd_type = io_req->cmd_type;\r\nrx_state = ((task->rxwr_txrd.var_ctx.rx_flags &\r\nFCOE_TCE_RX_WR_TX_RD_VAR_RX_STATE) >>\r\nFCOE_TCE_RX_WR_TX_RD_VAR_RX_STATE_SHIFT);\r\nswitch (cmd_type) {\r\ncase BNX2FC_SCSI_CMD:\r\nif (rx_state == FCOE_TASK_RX_STATE_COMPLETED) {\r\nbnx2fc_process_scsi_cmd_compl(io_req, task, num_rq);\r\nspin_unlock_bh(&tgt->tgt_lock);\r\nreturn;\r\n}\r\nif (rx_state == FCOE_TASK_RX_STATE_ABTS_COMPLETED)\r\nbnx2fc_process_abts_compl(io_req, task, num_rq);\r\nelse if (rx_state ==\r\nFCOE_TASK_RX_STATE_EXCHANGE_CLEANUP_COMPLETED)\r\nbnx2fc_process_cleanup_compl(io_req, task, num_rq);\r\nelse\r\nprintk(KERN_ERR PFX "Invalid rx state - %d\n",\r\nrx_state);\r\nbreak;\r\ncase BNX2FC_TASK_MGMT_CMD:\r\nBNX2FC_IO_DBG(io_req, "Processing TM complete\n");\r\nbnx2fc_process_tm_compl(io_req, task, num_rq);\r\nbreak;\r\ncase BNX2FC_ABTS:\r\nBNX2FC_IO_DBG(io_req, "cq_compl- ABTS sent out by fw\n");\r\nkref_put(&io_req->refcount, bnx2fc_cmd_release);\r\nbreak;\r\ncase BNX2FC_ELS:\r\nif (rx_state == FCOE_TASK_RX_STATE_COMPLETED)\r\nbnx2fc_process_els_compl(io_req, task, num_rq);\r\nelse if (rx_state == FCOE_TASK_RX_STATE_ABTS_COMPLETED)\r\nbnx2fc_process_abts_compl(io_req, task, num_rq);\r\nelse if (rx_state ==\r\nFCOE_TASK_RX_STATE_EXCHANGE_CLEANUP_COMPLETED)\r\nbnx2fc_process_cleanup_compl(io_req, task, num_rq);\r\nelse\r\nprintk(KERN_ERR PFX "Invalid rx state = %d\n",\r\nrx_state);\r\nbreak;\r\ncase BNX2FC_CLEANUP:\r\nBNX2FC_IO_DBG(io_req, "cq_compl- cleanup resp rcvd\n");\r\nkref_put(&io_req->refcount, bnx2fc_cmd_release);\r\nbreak;\r\ncase BNX2FC_SEQ_CLEANUP:\r\nBNX2FC_IO_DBG(io_req, "cq_compl(0x%x) - seq cleanup resp\n",\r\nio_req->xid);\r\nbnx2fc_process_seq_cleanup_compl(io_req, task, rx_state);\r\nkref_put(&io_req->refcount, bnx2fc_cmd_release);\r\nbreak;\r\ndefault:\r\nprintk(KERN_ERR PFX "Invalid cmd_type %d\n", cmd_type);\r\nbreak;\r\n}\r\nspin_unlock_bh(&tgt->tgt_lock);\r\n}\r\nvoid bnx2fc_arm_cq(struct bnx2fc_rport *tgt)\r\n{\r\nstruct b577xx_fcoe_rx_doorbell *rx_db = &tgt->rx_db;\r\nu32 msg;\r\nwmb();\r\nrx_db->doorbell_cq_cons = tgt->cq_cons_idx | (tgt->cq_curr_toggle_bit <<\r\nFCOE_CQE_TOGGLE_BIT_SHIFT);\r\nmsg = *((u32 *)rx_db);\r\nwritel(cpu_to_le32(msg), tgt->ctx_base);\r\nmmiowb();\r\n}\r\nstruct bnx2fc_work *bnx2fc_alloc_work(struct bnx2fc_rport *tgt, u16 wqe)\r\n{\r\nstruct bnx2fc_work *work;\r\nwork = kzalloc(sizeof(struct bnx2fc_work), GFP_ATOMIC);\r\nif (!work)\r\nreturn NULL;\r\nINIT_LIST_HEAD(&work->list);\r\nwork->tgt = tgt;\r\nwork->wqe = wqe;\r\nreturn work;\r\n}\r\nint bnx2fc_process_new_cqes(struct bnx2fc_rport *tgt)\r\n{\r\nstruct fcoe_cqe *cq;\r\nu32 cq_cons;\r\nstruct fcoe_cqe *cqe;\r\nu32 num_free_sqes = 0;\r\nu32 num_cqes = 0;\r\nu16 wqe;\r\nspin_lock_bh(&tgt->cq_lock);\r\nif (!tgt->cq) {\r\nprintk(KERN_ERR PFX "process_new_cqes: cq is NULL\n");\r\nspin_unlock_bh(&tgt->cq_lock);\r\nreturn 0;\r\n}\r\ncq = tgt->cq;\r\ncq_cons = tgt->cq_cons_idx;\r\ncqe = &cq[cq_cons];\r\nwhile (((wqe = cqe->wqe) & FCOE_CQE_TOGGLE_BIT) ==\r\n(tgt->cq_curr_toggle_bit <<\r\nFCOE_CQE_TOGGLE_BIT_SHIFT)) {\r\nif (wqe & FCOE_CQE_CQE_TYPE) {\r\nbnx2fc_process_unsol_compl(tgt, wqe);\r\n} else {\r\nstruct bnx2fc_work *work = NULL;\r\nstruct bnx2fc_percpu_s *fps = NULL;\r\nunsigned int cpu = wqe % num_possible_cpus();\r\nfps = &per_cpu(bnx2fc_percpu, cpu);\r\nspin_lock_bh(&fps->fp_work_lock);\r\nif (unlikely(!fps->iothread))\r\ngoto unlock;\r\nwork = bnx2fc_alloc_work(tgt, wqe);\r\nif (work)\r\nlist_add_tail(&work->list,\r\n&fps->work_list);\r\nunlock:\r\nspin_unlock_bh(&fps->fp_work_lock);\r\nif (fps->iothread && work)\r\nwake_up_process(fps->iothread);\r\nelse\r\nbnx2fc_process_cq_compl(tgt, wqe);\r\nnum_free_sqes++;\r\n}\r\ncqe++;\r\ntgt->cq_cons_idx++;\r\nnum_cqes++;\r\nif (tgt->cq_cons_idx == BNX2FC_CQ_WQES_MAX) {\r\ntgt->cq_cons_idx = 0;\r\ncqe = cq;\r\ntgt->cq_curr_toggle_bit =\r\n1 - tgt->cq_curr_toggle_bit;\r\n}\r\n}\r\nif (num_cqes) {\r\nif (tgt->ctx_base)\r\nbnx2fc_arm_cq(tgt);\r\natomic_add(num_free_sqes, &tgt->free_sqes);\r\n}\r\nspin_unlock_bh(&tgt->cq_lock);\r\nreturn 0;\r\n}\r\nstatic void bnx2fc_fastpath_notification(struct bnx2fc_hba *hba,\r\nstruct fcoe_kcqe *new_cqe_kcqe)\r\n{\r\nu32 conn_id = new_cqe_kcqe->fcoe_conn_id;\r\nstruct bnx2fc_rport *tgt = hba->tgt_ofld_list[conn_id];\r\nif (!tgt) {\r\nprintk(KERN_ERR PFX "conn_id 0x%x not valid\n", conn_id);\r\nreturn;\r\n}\r\nbnx2fc_process_new_cqes(tgt);\r\n}\r\nstatic void bnx2fc_process_ofld_cmpl(struct bnx2fc_hba *hba,\r\nstruct fcoe_kcqe *ofld_kcqe)\r\n{\r\nstruct bnx2fc_rport *tgt;\r\nstruct fcoe_port *port;\r\nstruct bnx2fc_interface *interface;\r\nu32 conn_id;\r\nu32 context_id;\r\nconn_id = ofld_kcqe->fcoe_conn_id;\r\ncontext_id = ofld_kcqe->fcoe_conn_context_id;\r\ntgt = hba->tgt_ofld_list[conn_id];\r\nif (!tgt) {\r\nprintk(KERN_ALERT PFX "ERROR:ofld_cmpl: No pending ofld req\n");\r\nreturn;\r\n}\r\nBNX2FC_TGT_DBG(tgt, "Entered ofld compl - context_id = 0x%x\n",\r\nofld_kcqe->fcoe_conn_context_id);\r\nport = tgt->port;\r\ninterface = tgt->port->priv;\r\nif (hba != interface->hba) {\r\nprintk(KERN_ERR PFX "ERROR:ofld_cmpl: HBA mis-match\n");\r\ngoto ofld_cmpl_err;\r\n}\r\ntgt->context_id = context_id;\r\nif (ofld_kcqe->completion_status) {\r\nif (ofld_kcqe->completion_status ==\r\nFCOE_KCQE_COMPLETION_STATUS_CTX_ALLOC_FAILURE) {\r\nprintk(KERN_ERR PFX "unable to allocate FCoE context "\r\n"resources\n");\r\nset_bit(BNX2FC_FLAG_CTX_ALLOC_FAILURE, &tgt->flags);\r\n}\r\n} else {\r\nset_bit(BNX2FC_FLAG_OFFLOADED, &tgt->flags);\r\n}\r\nofld_cmpl_err:\r\nset_bit(BNX2FC_FLAG_OFLD_REQ_CMPL, &tgt->flags);\r\nwake_up_interruptible(&tgt->ofld_wait);\r\n}\r\nstatic void bnx2fc_process_enable_conn_cmpl(struct bnx2fc_hba *hba,\r\nstruct fcoe_kcqe *ofld_kcqe)\r\n{\r\nstruct bnx2fc_rport *tgt;\r\nstruct bnx2fc_interface *interface;\r\nu32 conn_id;\r\nu32 context_id;\r\ncontext_id = ofld_kcqe->fcoe_conn_context_id;\r\nconn_id = ofld_kcqe->fcoe_conn_id;\r\ntgt = hba->tgt_ofld_list[conn_id];\r\nif (!tgt) {\r\nprintk(KERN_ERR PFX "ERROR:enbl_cmpl: No pending ofld req\n");\r\nreturn;\r\n}\r\nBNX2FC_TGT_DBG(tgt, "Enable compl - context_id = 0x%x\n",\r\nofld_kcqe->fcoe_conn_context_id);\r\nif (tgt->context_id != context_id) {\r\nprintk(KERN_ERR PFX "context id mis-match\n");\r\nreturn;\r\n}\r\ninterface = tgt->port->priv;\r\nif (hba != interface->hba) {\r\nprintk(KERN_ERR PFX "bnx2fc-enbl_cmpl: HBA mis-match\n");\r\ngoto enbl_cmpl_err;\r\n}\r\nif (!ofld_kcqe->completion_status)\r\nset_bit(BNX2FC_FLAG_ENABLED, &tgt->flags);\r\nenbl_cmpl_err:\r\nset_bit(BNX2FC_FLAG_OFLD_REQ_CMPL, &tgt->flags);\r\nwake_up_interruptible(&tgt->ofld_wait);\r\n}\r\nstatic void bnx2fc_process_conn_disable_cmpl(struct bnx2fc_hba *hba,\r\nstruct fcoe_kcqe *disable_kcqe)\r\n{\r\nstruct bnx2fc_rport *tgt;\r\nu32 conn_id;\r\nconn_id = disable_kcqe->fcoe_conn_id;\r\ntgt = hba->tgt_ofld_list[conn_id];\r\nif (!tgt) {\r\nprintk(KERN_ERR PFX "ERROR: disable_cmpl: No disable req\n");\r\nreturn;\r\n}\r\nBNX2FC_TGT_DBG(tgt, PFX "disable_cmpl: conn_id %d\n", conn_id);\r\nif (disable_kcqe->completion_status) {\r\nprintk(KERN_ERR PFX "Disable failed with cmpl status %d\n",\r\ndisable_kcqe->completion_status);\r\nset_bit(BNX2FC_FLAG_DISABLE_FAILED, &tgt->flags);\r\nset_bit(BNX2FC_FLAG_UPLD_REQ_COMPL, &tgt->flags);\r\nwake_up_interruptible(&tgt->upld_wait);\r\n} else {\r\nBNX2FC_TGT_DBG(tgt, "disable successful\n");\r\nclear_bit(BNX2FC_FLAG_OFFLOADED, &tgt->flags);\r\nclear_bit(BNX2FC_FLAG_ENABLED, &tgt->flags);\r\nset_bit(BNX2FC_FLAG_DISABLED, &tgt->flags);\r\nset_bit(BNX2FC_FLAG_UPLD_REQ_COMPL, &tgt->flags);\r\nwake_up_interruptible(&tgt->upld_wait);\r\n}\r\n}\r\nstatic void bnx2fc_process_conn_destroy_cmpl(struct bnx2fc_hba *hba,\r\nstruct fcoe_kcqe *destroy_kcqe)\r\n{\r\nstruct bnx2fc_rport *tgt;\r\nu32 conn_id;\r\nconn_id = destroy_kcqe->fcoe_conn_id;\r\ntgt = hba->tgt_ofld_list[conn_id];\r\nif (!tgt) {\r\nprintk(KERN_ERR PFX "destroy_cmpl: No destroy req\n");\r\nreturn;\r\n}\r\nBNX2FC_TGT_DBG(tgt, "destroy_cmpl: conn_id %d\n", conn_id);\r\nif (destroy_kcqe->completion_status) {\r\nprintk(KERN_ERR PFX "Destroy conn failed, cmpl status %d\n",\r\ndestroy_kcqe->completion_status);\r\nreturn;\r\n} else {\r\nBNX2FC_TGT_DBG(tgt, "upload successful\n");\r\nclear_bit(BNX2FC_FLAG_DISABLED, &tgt->flags);\r\nset_bit(BNX2FC_FLAG_DESTROYED, &tgt->flags);\r\nset_bit(BNX2FC_FLAG_UPLD_REQ_COMPL, &tgt->flags);\r\nwake_up_interruptible(&tgt->upld_wait);\r\n}\r\n}\r\nstatic void bnx2fc_init_failure(struct bnx2fc_hba *hba, u32 err_code)\r\n{\r\nswitch (err_code) {\r\ncase FCOE_KCQE_COMPLETION_STATUS_INVALID_OPCODE:\r\nprintk(KERN_ERR PFX "init_failure due to invalid opcode\n");\r\nbreak;\r\ncase FCOE_KCQE_COMPLETION_STATUS_CTX_ALLOC_FAILURE:\r\nprintk(KERN_ERR PFX "init failed due to ctx alloc failure\n");\r\nbreak;\r\ncase FCOE_KCQE_COMPLETION_STATUS_NIC_ERROR:\r\nprintk(KERN_ERR PFX "init_failure due to NIC error\n");\r\nbreak;\r\ncase FCOE_KCQE_COMPLETION_STATUS_ERROR:\r\nprintk(KERN_ERR PFX "init failure due to compl status err\n");\r\nbreak;\r\ncase FCOE_KCQE_COMPLETION_STATUS_WRONG_HSI_VERSION:\r\nprintk(KERN_ERR PFX "init failure due to HSI mismatch\n");\r\nbreak;\r\ndefault:\r\nprintk(KERN_ERR PFX "Unknown Error code %d\n", err_code);\r\n}\r\n}\r\nvoid bnx2fc_indicate_kcqe(void *context, struct kcqe *kcq[],\r\nu32 num_cqe)\r\n{\r\nstruct bnx2fc_hba *hba = (struct bnx2fc_hba *)context;\r\nint i = 0;\r\nstruct fcoe_kcqe *kcqe = NULL;\r\nwhile (i < num_cqe) {\r\nkcqe = (struct fcoe_kcqe *) kcq[i++];\r\nswitch (kcqe->op_code) {\r\ncase FCOE_KCQE_OPCODE_CQ_EVENT_NOTIFICATION:\r\nbnx2fc_fastpath_notification(hba, kcqe);\r\nbreak;\r\ncase FCOE_KCQE_OPCODE_OFFLOAD_CONN:\r\nbnx2fc_process_ofld_cmpl(hba, kcqe);\r\nbreak;\r\ncase FCOE_KCQE_OPCODE_ENABLE_CONN:\r\nbnx2fc_process_enable_conn_cmpl(hba, kcqe);\r\nbreak;\r\ncase FCOE_KCQE_OPCODE_INIT_FUNC:\r\nif (kcqe->completion_status !=\r\nFCOE_KCQE_COMPLETION_STATUS_SUCCESS) {\r\nbnx2fc_init_failure(hba,\r\nkcqe->completion_status);\r\n} else {\r\nset_bit(ADAPTER_STATE_UP, &hba->adapter_state);\r\nbnx2fc_get_link_state(hba);\r\nprintk(KERN_INFO PFX "[%.2x]: FCOE_INIT passed\n",\r\n(u8)hba->pcidev->bus->number);\r\n}\r\nbreak;\r\ncase FCOE_KCQE_OPCODE_DESTROY_FUNC:\r\nif (kcqe->completion_status !=\r\nFCOE_KCQE_COMPLETION_STATUS_SUCCESS) {\r\nprintk(KERN_ERR PFX "DESTROY failed\n");\r\n} else {\r\nprintk(KERN_ERR PFX "DESTROY success\n");\r\n}\r\nset_bit(BNX2FC_FLAG_DESTROY_CMPL, &hba->flags);\r\nwake_up_interruptible(&hba->destroy_wait);\r\nbreak;\r\ncase FCOE_KCQE_OPCODE_DISABLE_CONN:\r\nbnx2fc_process_conn_disable_cmpl(hba, kcqe);\r\nbreak;\r\ncase FCOE_KCQE_OPCODE_DESTROY_CONN:\r\nbnx2fc_process_conn_destroy_cmpl(hba, kcqe);\r\nbreak;\r\ncase FCOE_KCQE_OPCODE_STAT_FUNC:\r\nif (kcqe->completion_status !=\r\nFCOE_KCQE_COMPLETION_STATUS_SUCCESS)\r\nprintk(KERN_ERR PFX "STAT failed\n");\r\ncomplete(&hba->stat_req_done);\r\nbreak;\r\ncase FCOE_KCQE_OPCODE_FCOE_ERROR:\r\ndefault:\r\nprintk(KERN_ERR PFX "unknown opcode 0x%x\n",\r\nkcqe->op_code);\r\n}\r\n}\r\n}\r\nvoid bnx2fc_add_2_sq(struct bnx2fc_rport *tgt, u16 xid)\r\n{\r\nstruct fcoe_sqe *sqe;\r\nsqe = &tgt->sq[tgt->sq_prod_idx];\r\nsqe->wqe = xid << FCOE_SQE_TASK_ID_SHIFT;\r\nsqe->wqe |= tgt->sq_curr_toggle_bit << FCOE_SQE_TOGGLE_BIT_SHIFT;\r\nif (++tgt->sq_prod_idx == BNX2FC_SQ_WQES_MAX) {\r\ntgt->sq_prod_idx = 0;\r\ntgt->sq_curr_toggle_bit = 1 - tgt->sq_curr_toggle_bit;\r\n}\r\n}\r\nvoid bnx2fc_ring_doorbell(struct bnx2fc_rport *tgt)\r\n{\r\nstruct b577xx_doorbell_set_prod *sq_db = &tgt->sq_db;\r\nu32 msg;\r\nwmb();\r\nsq_db->prod = tgt->sq_prod_idx |\r\n(tgt->sq_curr_toggle_bit << 15);\r\nmsg = *((u32 *)sq_db);\r\nwritel(cpu_to_le32(msg), tgt->ctx_base);\r\nmmiowb();\r\n}\r\nint bnx2fc_map_doorbell(struct bnx2fc_rport *tgt)\r\n{\r\nu32 context_id = tgt->context_id;\r\nstruct fcoe_port *port = tgt->port;\r\nu32 reg_off;\r\nresource_size_t reg_base;\r\nstruct bnx2fc_interface *interface = port->priv;\r\nstruct bnx2fc_hba *hba = interface->hba;\r\nreg_base = pci_resource_start(hba->pcidev,\r\nBNX2X_DOORBELL_PCI_BAR);\r\nreg_off = BNX2FC_5771X_DB_PAGE_SIZE *\r\n(context_id & 0x1FFFF) + DPM_TRIGER_TYPE;\r\ntgt->ctx_base = ioremap_nocache(reg_base + reg_off, 4);\r\nif (!tgt->ctx_base)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nchar *bnx2fc_get_next_rqe(struct bnx2fc_rport *tgt, u8 num_items)\r\n{\r\nchar *buf = (char *)tgt->rq + (tgt->rq_cons_idx * BNX2FC_RQ_BUF_SZ);\r\nif (tgt->rq_cons_idx + num_items > BNX2FC_RQ_WQES_MAX)\r\nreturn NULL;\r\ntgt->rq_cons_idx += num_items;\r\nif (tgt->rq_cons_idx >= BNX2FC_RQ_WQES_MAX)\r\ntgt->rq_cons_idx -= BNX2FC_RQ_WQES_MAX;\r\nreturn buf;\r\n}\r\nvoid bnx2fc_return_rqe(struct bnx2fc_rport *tgt, u8 num_items)\r\n{\r\nu32 next_prod_idx = tgt->rq_prod_idx + num_items;\r\nif ((next_prod_idx & 0x7fff) == BNX2FC_RQ_WQES_MAX) {\r\nnext_prod_idx += 0x8000 - BNX2FC_RQ_WQES_MAX;\r\n}\r\ntgt->rq_prod_idx = next_prod_idx;\r\ntgt->conn_db->rq_prod = tgt->rq_prod_idx;\r\n}\r\nvoid bnx2fc_init_seq_cleanup_task(struct bnx2fc_cmd *seq_clnp_req,\r\nstruct fcoe_task_ctx_entry *task,\r\nstruct bnx2fc_cmd *orig_io_req,\r\nu32 offset)\r\n{\r\nstruct scsi_cmnd *sc_cmd = orig_io_req->sc_cmd;\r\nstruct bnx2fc_rport *tgt = seq_clnp_req->tgt;\r\nstruct bnx2fc_interface *interface = tgt->port->priv;\r\nstruct fcoe_bd_ctx *bd = orig_io_req->bd_tbl->bd_tbl;\r\nstruct fcoe_task_ctx_entry *orig_task;\r\nstruct fcoe_task_ctx_entry *task_page;\r\nstruct fcoe_ext_mul_sges_ctx *sgl;\r\nu8 task_type = FCOE_TASK_TYPE_SEQUENCE_CLEANUP;\r\nu8 orig_task_type;\r\nu16 orig_xid = orig_io_req->xid;\r\nu32 context_id = tgt->context_id;\r\nu64 phys_addr = (u64)orig_io_req->bd_tbl->bd_tbl_dma;\r\nu32 orig_offset = offset;\r\nint bd_count;\r\nint orig_task_idx, index;\r\nint i;\r\nmemset(task, 0, sizeof(struct fcoe_task_ctx_entry));\r\nif (sc_cmd->sc_data_direction == DMA_TO_DEVICE)\r\norig_task_type = FCOE_TASK_TYPE_WRITE;\r\nelse\r\norig_task_type = FCOE_TASK_TYPE_READ;\r\ntask->txwr_rxrd.const_ctx.tx_flags =\r\nFCOE_TASK_TX_STATE_SEQUENCE_CLEANUP <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_TX_STATE_SHIFT;\r\ntask->txwr_rxrd.const_ctx.init_flags = task_type <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_TASK_TYPE_SHIFT;\r\ntask->txwr_rxrd.const_ctx.init_flags |= FCOE_TASK_CLASS_TYPE_3 <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_CLASS_TYPE_SHIFT;\r\ntask->rxwr_txrd.const_ctx.init_flags = context_id <<\r\nFCOE_TCE_RX_WR_TX_RD_CONST_CID_SHIFT;\r\ntask->rxwr_txrd.const_ctx.init_flags = context_id <<\r\nFCOE_TCE_RX_WR_TX_RD_CONST_CID_SHIFT;\r\ntask->txwr_rxrd.union_ctx.cleanup.ctx.cleaned_task_id = orig_xid;\r\ntask->txwr_rxrd.union_ctx.cleanup.ctx.rolled_tx_seq_cnt = 0;\r\ntask->txwr_rxrd.union_ctx.cleanup.ctx.rolled_tx_data_offset = offset;\r\nbd_count = orig_io_req->bd_tbl->bd_valid;\r\nfor (i = 0; i < bd_count; i++) {\r\nif (offset < bd[i].buf_len)\r\nbreak;\r\noffset -= bd[i].buf_len;\r\n}\r\nphys_addr += (i * sizeof(struct fcoe_bd_ctx));\r\nif (orig_task_type == FCOE_TASK_TYPE_WRITE) {\r\ntask->txwr_only.sgl_ctx.sgl.mul_sgl.cur_sge_addr.lo =\r\n(u32)phys_addr;\r\ntask->txwr_only.sgl_ctx.sgl.mul_sgl.cur_sge_addr.hi =\r\n(u32)((u64)phys_addr >> 32);\r\ntask->txwr_only.sgl_ctx.sgl.mul_sgl.sgl_size =\r\nbd_count;\r\ntask->txwr_only.sgl_ctx.sgl.mul_sgl.cur_sge_off =\r\noffset;\r\ntask->txwr_only.sgl_ctx.sgl.mul_sgl.cur_sge_idx = i;\r\n} else {\r\norig_task_idx = orig_xid / BNX2FC_TASKS_PER_PAGE;\r\nindex = orig_xid % BNX2FC_TASKS_PER_PAGE;\r\ntask_page = (struct fcoe_task_ctx_entry *)\r\ninterface->hba->task_ctx[orig_task_idx];\r\norig_task = &(task_page[index]);\r\nsgl = &task->rxwr_only.union_ctx.read_info.sgl_ctx.sgl;\r\nsgl->mul_sgl.cur_sge_addr.lo = (u32)phys_addr;\r\nsgl->mul_sgl.cur_sge_addr.hi = (u32)((u64)phys_addr >> 32);\r\nsgl->mul_sgl.sgl_size = bd_count;\r\nsgl->mul_sgl.cur_sge_off = offset;\r\nsgl->mul_sgl.cur_sge_idx = i;\r\nmemset(&task->rxwr_only.rx_seq_ctx, 0,\r\nsizeof(struct fcoe_rx_seq_ctx));\r\ntask->rxwr_only.rx_seq_ctx.low_exp_ro = orig_offset;\r\ntask->rxwr_only.rx_seq_ctx.high_exp_ro = orig_offset;\r\n}\r\n}\r\nvoid bnx2fc_init_cleanup_task(struct bnx2fc_cmd *io_req,\r\nstruct fcoe_task_ctx_entry *task,\r\nu16 orig_xid)\r\n{\r\nu8 task_type = FCOE_TASK_TYPE_EXCHANGE_CLEANUP;\r\nstruct bnx2fc_rport *tgt = io_req->tgt;\r\nu32 context_id = tgt->context_id;\r\nmemset(task, 0, sizeof(struct fcoe_task_ctx_entry));\r\ntask->txwr_rxrd.const_ctx.init_flags = task_type <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_TASK_TYPE_SHIFT;\r\ntask->txwr_rxrd.const_ctx.init_flags |= FCOE_TASK_CLASS_TYPE_3 <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_CLASS_TYPE_SHIFT;\r\nif (tgt->dev_type == TYPE_TAPE)\r\ntask->txwr_rxrd.const_ctx.init_flags |=\r\nFCOE_TASK_DEV_TYPE_TAPE <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_DEV_TYPE_SHIFT;\r\nelse\r\ntask->txwr_rxrd.const_ctx.init_flags |=\r\nFCOE_TASK_DEV_TYPE_DISK <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_DEV_TYPE_SHIFT;\r\ntask->txwr_rxrd.union_ctx.cleanup.ctx.cleaned_task_id = orig_xid;\r\ntask->txwr_rxrd.const_ctx.tx_flags =\r\nFCOE_TASK_TX_STATE_EXCHANGE_CLEANUP <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_TX_STATE_SHIFT;\r\ntask->rxwr_txrd.const_ctx.init_flags = context_id <<\r\nFCOE_TCE_RX_WR_TX_RD_CONST_CID_SHIFT;\r\ntask->rxwr_txrd.var_ctx.rx_flags |= 1 <<\r\nFCOE_TCE_RX_WR_TX_RD_VAR_EXP_FIRST_FRAME_SHIFT;\r\n}\r\nvoid bnx2fc_init_mp_task(struct bnx2fc_cmd *io_req,\r\nstruct fcoe_task_ctx_entry *task)\r\n{\r\nstruct bnx2fc_mp_req *mp_req = &(io_req->mp_req);\r\nstruct bnx2fc_rport *tgt = io_req->tgt;\r\nstruct fc_frame_header *fc_hdr;\r\nstruct fcoe_ext_mul_sges_ctx *sgl;\r\nu8 task_type = 0;\r\nu64 *hdr;\r\nu64 temp_hdr[3];\r\nu32 context_id;\r\nif ((io_req->cmd_type == BNX2FC_TASK_MGMT_CMD) ||\r\n(io_req->cmd_type == BNX2FC_ELS)) {\r\ntask_type = FCOE_TASK_TYPE_MIDPATH;\r\n} else if (io_req->cmd_type == BNX2FC_ABTS) {\r\ntask_type = FCOE_TASK_TYPE_ABTS;\r\n}\r\nmemset(task, 0, sizeof(struct fcoe_task_ctx_entry));\r\nio_req->task = task;\r\nBNX2FC_IO_DBG(io_req, "Init MP task for cmd_type = %d task_type = %d\n",\r\nio_req->cmd_type, task_type);\r\nif ((task_type == FCOE_TASK_TYPE_MIDPATH) ||\r\n(task_type == FCOE_TASK_TYPE_UNSOLICITED)) {\r\ntask->txwr_only.sgl_ctx.sgl.mul_sgl.cur_sge_addr.lo =\r\n(u32)mp_req->mp_req_bd_dma;\r\ntask->txwr_only.sgl_ctx.sgl.mul_sgl.cur_sge_addr.hi =\r\n(u32)((u64)mp_req->mp_req_bd_dma >> 32);\r\ntask->txwr_only.sgl_ctx.sgl.mul_sgl.sgl_size = 1;\r\n}\r\ntask->txwr_rxrd.const_ctx.init_flags = task_type <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_TASK_TYPE_SHIFT;\r\nif (tgt->dev_type == TYPE_TAPE)\r\ntask->txwr_rxrd.const_ctx.init_flags |=\r\nFCOE_TASK_DEV_TYPE_TAPE <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_DEV_TYPE_SHIFT;\r\nelse\r\ntask->txwr_rxrd.const_ctx.init_flags |=\r\nFCOE_TASK_DEV_TYPE_DISK <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_DEV_TYPE_SHIFT;\r\ntask->txwr_rxrd.const_ctx.init_flags |= FCOE_TASK_CLASS_TYPE_3 <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_CLASS_TYPE_SHIFT;\r\ntask->txwr_rxrd.const_ctx.tx_flags = FCOE_TASK_TX_STATE_INIT <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_TX_STATE_SHIFT;\r\ntask->rxwr_txrd.const_ctx.data_2_trns = io_req->data_xfer_len;\r\ntask->rxwr_txrd.var_ctx.rx_flags |= 1 <<\r\nFCOE_TCE_RX_WR_TX_RD_VAR_EXP_FIRST_FRAME_SHIFT;\r\ncontext_id = tgt->context_id;\r\ntask->rxwr_txrd.const_ctx.init_flags = context_id <<\r\nFCOE_TCE_RX_WR_TX_RD_CONST_CID_SHIFT;\r\nfc_hdr = &(mp_req->req_fc_hdr);\r\nif (task_type == FCOE_TASK_TYPE_MIDPATH) {\r\nfc_hdr->fh_ox_id = cpu_to_be16(io_req->xid);\r\nfc_hdr->fh_rx_id = htons(0xffff);\r\ntask->rxwr_txrd.var_ctx.rx_id = 0xffff;\r\n} else if (task_type == FCOE_TASK_TYPE_UNSOLICITED) {\r\nfc_hdr->fh_rx_id = cpu_to_be16(io_req->xid);\r\n}\r\nhdr = (u64 *) &task->txwr_rxrd.union_ctx.tx_frame.fc_hdr;\r\nmemcpy(temp_hdr, fc_hdr, sizeof(temp_hdr));\r\nhdr[0] = cpu_to_be64(temp_hdr[0]);\r\nhdr[1] = cpu_to_be64(temp_hdr[1]);\r\nhdr[2] = cpu_to_be64(temp_hdr[2]);\r\nif (task_type == FCOE_TASK_TYPE_MIDPATH) {\r\nsgl = &task->rxwr_only.union_ctx.read_info.sgl_ctx.sgl;\r\nsgl->mul_sgl.cur_sge_addr.lo = (u32)mp_req->mp_resp_bd_dma;\r\nsgl->mul_sgl.cur_sge_addr.hi =\r\n(u32)((u64)mp_req->mp_resp_bd_dma >> 32);\r\nsgl->mul_sgl.sgl_size = 1;\r\n}\r\n}\r\nvoid bnx2fc_init_task(struct bnx2fc_cmd *io_req,\r\nstruct fcoe_task_ctx_entry *task)\r\n{\r\nu8 task_type;\r\nstruct scsi_cmnd *sc_cmd = io_req->sc_cmd;\r\nstruct io_bdt *bd_tbl = io_req->bd_tbl;\r\nstruct bnx2fc_rport *tgt = io_req->tgt;\r\nstruct fcoe_cached_sge_ctx *cached_sge;\r\nstruct fcoe_ext_mul_sges_ctx *sgl;\r\nint dev_type = tgt->dev_type;\r\nu64 *fcp_cmnd;\r\nu64 tmp_fcp_cmnd[4];\r\nu32 context_id;\r\nint cnt, i;\r\nint bd_count;\r\nmemset(task, 0, sizeof(struct fcoe_task_ctx_entry));\r\nio_req->task = task;\r\nif (sc_cmd->sc_data_direction == DMA_TO_DEVICE)\r\ntask_type = FCOE_TASK_TYPE_WRITE;\r\nelse\r\ntask_type = FCOE_TASK_TYPE_READ;\r\nbd_count = bd_tbl->bd_valid;\r\ncached_sge = &task->rxwr_only.union_ctx.read_info.sgl_ctx.cached_sge;\r\nif (task_type == FCOE_TASK_TYPE_WRITE) {\r\nif ((dev_type == TYPE_DISK) && (bd_count == 1)) {\r\nstruct fcoe_bd_ctx *fcoe_bd_tbl = bd_tbl->bd_tbl;\r\ntask->txwr_only.sgl_ctx.cached_sge.cur_buf_addr.lo =\r\ncached_sge->cur_buf_addr.lo =\r\nfcoe_bd_tbl->buf_addr_lo;\r\ntask->txwr_only.sgl_ctx.cached_sge.cur_buf_addr.hi =\r\ncached_sge->cur_buf_addr.hi =\r\nfcoe_bd_tbl->buf_addr_hi;\r\ntask->txwr_only.sgl_ctx.cached_sge.cur_buf_rem =\r\ncached_sge->cur_buf_rem =\r\nfcoe_bd_tbl->buf_len;\r\ntask->txwr_rxrd.const_ctx.init_flags |= 1 <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_CACHED_SGE_SHIFT;\r\n} else {\r\ntask->txwr_only.sgl_ctx.sgl.mul_sgl.cur_sge_addr.lo =\r\n(u32)bd_tbl->bd_tbl_dma;\r\ntask->txwr_only.sgl_ctx.sgl.mul_sgl.cur_sge_addr.hi =\r\n(u32)((u64)bd_tbl->bd_tbl_dma >> 32);\r\ntask->txwr_only.sgl_ctx.sgl.mul_sgl.sgl_size =\r\nbd_tbl->bd_valid;\r\n}\r\n}\r\ntask->txwr_rxrd.const_ctx.init_flags |= task_type <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_TASK_TYPE_SHIFT;\r\nif (dev_type == TYPE_TAPE) {\r\ntask->txwr_rxrd.const_ctx.init_flags |=\r\nFCOE_TASK_DEV_TYPE_TAPE <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_DEV_TYPE_SHIFT;\r\nio_req->rec_retry = 0;\r\nio_req->rec_retry = 0;\r\n} else\r\ntask->txwr_rxrd.const_ctx.init_flags |=\r\nFCOE_TASK_DEV_TYPE_DISK <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_DEV_TYPE_SHIFT;\r\ntask->txwr_rxrd.const_ctx.init_flags |= FCOE_TASK_CLASS_TYPE_3 <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_CLASS_TYPE_SHIFT;\r\ntask->txwr_rxrd.const_ctx.tx_flags = FCOE_TASK_TX_STATE_NORMAL <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_TX_STATE_SHIFT;\r\ntask->txwr_rxrd.union_ctx.tx_seq.ctx.seq_cnt = 1;\r\nfcp_cmnd = (u64 *)\r\ntask->txwr_rxrd.union_ctx.fcp_cmd.opaque;\r\nbnx2fc_build_fcp_cmnd(io_req, (struct fcp_cmnd *)&tmp_fcp_cmnd);\r\ncnt = sizeof(struct fcp_cmnd) / sizeof(u64);\r\nfor (i = 0; i < cnt; i++) {\r\n*fcp_cmnd = cpu_to_be64(tmp_fcp_cmnd[i]);\r\nfcp_cmnd++;\r\n}\r\ntask->rxwr_txrd.const_ctx.data_2_trns = io_req->data_xfer_len;\r\ncontext_id = tgt->context_id;\r\ntask->rxwr_txrd.const_ctx.init_flags = context_id <<\r\nFCOE_TCE_RX_WR_TX_RD_CONST_CID_SHIFT;\r\ntask->rxwr_txrd.var_ctx.rx_flags |= 1 <<\r\nFCOE_TCE_RX_WR_TX_RD_VAR_EXP_FIRST_FRAME_SHIFT;\r\ntask->rxwr_txrd.var_ctx.rx_id = 0xffff;\r\nif (task_type != FCOE_TASK_TYPE_READ)\r\nreturn;\r\nsgl = &task->rxwr_only.union_ctx.read_info.sgl_ctx.sgl;\r\nbd_count = bd_tbl->bd_valid;\r\nif (dev_type == TYPE_DISK) {\r\nif (bd_count == 1) {\r\nstruct fcoe_bd_ctx *fcoe_bd_tbl = bd_tbl->bd_tbl;\r\ncached_sge->cur_buf_addr.lo = fcoe_bd_tbl->buf_addr_lo;\r\ncached_sge->cur_buf_addr.hi = fcoe_bd_tbl->buf_addr_hi;\r\ncached_sge->cur_buf_rem = fcoe_bd_tbl->buf_len;\r\ntask->txwr_rxrd.const_ctx.init_flags |= 1 <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_CACHED_SGE_SHIFT;\r\n} else if (bd_count == 2) {\r\nstruct fcoe_bd_ctx *fcoe_bd_tbl = bd_tbl->bd_tbl;\r\ncached_sge->cur_buf_addr.lo = fcoe_bd_tbl->buf_addr_lo;\r\ncached_sge->cur_buf_addr.hi = fcoe_bd_tbl->buf_addr_hi;\r\ncached_sge->cur_buf_rem = fcoe_bd_tbl->buf_len;\r\nfcoe_bd_tbl++;\r\ncached_sge->second_buf_addr.lo =\r\nfcoe_bd_tbl->buf_addr_lo;\r\ncached_sge->second_buf_addr.hi =\r\nfcoe_bd_tbl->buf_addr_hi;\r\ncached_sge->second_buf_rem = fcoe_bd_tbl->buf_len;\r\ntask->txwr_rxrd.const_ctx.init_flags |= 1 <<\r\nFCOE_TCE_TX_WR_RX_RD_CONST_CACHED_SGE_SHIFT;\r\n} else {\r\nsgl->mul_sgl.cur_sge_addr.lo = (u32)bd_tbl->bd_tbl_dma;\r\nsgl->mul_sgl.cur_sge_addr.hi =\r\n(u32)((u64)bd_tbl->bd_tbl_dma >> 32);\r\nsgl->mul_sgl.sgl_size = bd_count;\r\n}\r\n} else {\r\nsgl->mul_sgl.cur_sge_addr.lo = (u32)bd_tbl->bd_tbl_dma;\r\nsgl->mul_sgl.cur_sge_addr.hi =\r\n(u32)((u64)bd_tbl->bd_tbl_dma >> 32);\r\nsgl->mul_sgl.sgl_size = bd_count;\r\n}\r\n}\r\nint bnx2fc_setup_task_ctx(struct bnx2fc_hba *hba)\r\n{\r\nint rc = 0;\r\nstruct regpair *task_ctx_bdt;\r\ndma_addr_t addr;\r\nint task_ctx_arr_sz;\r\nint i;\r\nhba->task_ctx_bd_tbl = dma_alloc_coherent(&hba->pcidev->dev,\r\nPAGE_SIZE,\r\n&hba->task_ctx_bd_dma,\r\nGFP_KERNEL);\r\nif (!hba->task_ctx_bd_tbl) {\r\nprintk(KERN_ERR PFX "unable to allocate task context BDT\n");\r\nrc = -1;\r\ngoto out;\r\n}\r\nmemset(hba->task_ctx_bd_tbl, 0, PAGE_SIZE);\r\ntask_ctx_arr_sz = (hba->max_tasks / BNX2FC_TASKS_PER_PAGE);\r\nhba->task_ctx = kzalloc((task_ctx_arr_sz * sizeof(void *)),\r\nGFP_KERNEL);\r\nif (!hba->task_ctx) {\r\nprintk(KERN_ERR PFX "unable to allocate task context array\n");\r\nrc = -1;\r\ngoto out1;\r\n}\r\nhba->task_ctx_dma = kmalloc((task_ctx_arr_sz *\r\nsizeof(dma_addr_t)), GFP_KERNEL);\r\nif (!hba->task_ctx_dma) {\r\nprintk(KERN_ERR PFX "unable to alloc context mapping array\n");\r\nrc = -1;\r\ngoto out2;\r\n}\r\ntask_ctx_bdt = (struct regpair *)hba->task_ctx_bd_tbl;\r\nfor (i = 0; i < task_ctx_arr_sz; i++) {\r\nhba->task_ctx[i] = dma_alloc_coherent(&hba->pcidev->dev,\r\nPAGE_SIZE,\r\n&hba->task_ctx_dma[i],\r\nGFP_KERNEL);\r\nif (!hba->task_ctx[i]) {\r\nprintk(KERN_ERR PFX "unable to alloc task context\n");\r\nrc = -1;\r\ngoto out3;\r\n}\r\nmemset(hba->task_ctx[i], 0, PAGE_SIZE);\r\naddr = (u64)hba->task_ctx_dma[i];\r\ntask_ctx_bdt->hi = cpu_to_le32((u64)addr >> 32);\r\ntask_ctx_bdt->lo = cpu_to_le32((u32)addr);\r\ntask_ctx_bdt++;\r\n}\r\nreturn 0;\r\nout3:\r\nfor (i = 0; i < task_ctx_arr_sz; i++) {\r\nif (hba->task_ctx[i]) {\r\ndma_free_coherent(&hba->pcidev->dev, PAGE_SIZE,\r\nhba->task_ctx[i], hba->task_ctx_dma[i]);\r\nhba->task_ctx[i] = NULL;\r\n}\r\n}\r\nkfree(hba->task_ctx_dma);\r\nhba->task_ctx_dma = NULL;\r\nout2:\r\nkfree(hba->task_ctx);\r\nhba->task_ctx = NULL;\r\nout1:\r\ndma_free_coherent(&hba->pcidev->dev, PAGE_SIZE,\r\nhba->task_ctx_bd_tbl, hba->task_ctx_bd_dma);\r\nhba->task_ctx_bd_tbl = NULL;\r\nout:\r\nreturn rc;\r\n}\r\nvoid bnx2fc_free_task_ctx(struct bnx2fc_hba *hba)\r\n{\r\nint task_ctx_arr_sz;\r\nint i;\r\nif (hba->task_ctx_bd_tbl) {\r\ndma_free_coherent(&hba->pcidev->dev, PAGE_SIZE,\r\nhba->task_ctx_bd_tbl,\r\nhba->task_ctx_bd_dma);\r\nhba->task_ctx_bd_tbl = NULL;\r\n}\r\ntask_ctx_arr_sz = (hba->max_tasks / BNX2FC_TASKS_PER_PAGE);\r\nif (hba->task_ctx) {\r\nfor (i = 0; i < task_ctx_arr_sz; i++) {\r\nif (hba->task_ctx[i]) {\r\ndma_free_coherent(&hba->pcidev->dev, PAGE_SIZE,\r\nhba->task_ctx[i],\r\nhba->task_ctx_dma[i]);\r\nhba->task_ctx[i] = NULL;\r\n}\r\n}\r\nkfree(hba->task_ctx);\r\nhba->task_ctx = NULL;\r\n}\r\nkfree(hba->task_ctx_dma);\r\nhba->task_ctx_dma = NULL;\r\n}\r\nstatic void bnx2fc_free_hash_table(struct bnx2fc_hba *hba)\r\n{\r\nint i;\r\nint segment_count;\r\nint hash_table_size;\r\nu32 *pbl;\r\nsegment_count = hba->hash_tbl_segment_count;\r\nhash_table_size = BNX2FC_NUM_MAX_SESS * BNX2FC_MAX_ROWS_IN_HASH_TBL *\r\nsizeof(struct fcoe_hash_table_entry);\r\npbl = hba->hash_tbl_pbl;\r\nfor (i = 0; i < segment_count; ++i) {\r\ndma_addr_t dma_address;\r\ndma_address = le32_to_cpu(*pbl);\r\n++pbl;\r\ndma_address += ((u64)le32_to_cpu(*pbl)) << 32;\r\n++pbl;\r\ndma_free_coherent(&hba->pcidev->dev,\r\nBNX2FC_HASH_TBL_CHUNK_SIZE,\r\nhba->hash_tbl_segments[i],\r\ndma_address);\r\n}\r\nif (hba->hash_tbl_pbl) {\r\ndma_free_coherent(&hba->pcidev->dev, PAGE_SIZE,\r\nhba->hash_tbl_pbl,\r\nhba->hash_tbl_pbl_dma);\r\nhba->hash_tbl_pbl = NULL;\r\n}\r\n}\r\nstatic int bnx2fc_allocate_hash_table(struct bnx2fc_hba *hba)\r\n{\r\nint i;\r\nint hash_table_size;\r\nint segment_count;\r\nint segment_array_size;\r\nint dma_segment_array_size;\r\ndma_addr_t *dma_segment_array;\r\nu32 *pbl;\r\nhash_table_size = BNX2FC_NUM_MAX_SESS * BNX2FC_MAX_ROWS_IN_HASH_TBL *\r\nsizeof(struct fcoe_hash_table_entry);\r\nsegment_count = hash_table_size + BNX2FC_HASH_TBL_CHUNK_SIZE - 1;\r\nsegment_count /= BNX2FC_HASH_TBL_CHUNK_SIZE;\r\nhba->hash_tbl_segment_count = segment_count;\r\nsegment_array_size = segment_count * sizeof(*hba->hash_tbl_segments);\r\nhba->hash_tbl_segments = kzalloc(segment_array_size, GFP_KERNEL);\r\nif (!hba->hash_tbl_segments) {\r\nprintk(KERN_ERR PFX "hash table pointers alloc failed\n");\r\nreturn -ENOMEM;\r\n}\r\ndma_segment_array_size = segment_count * sizeof(*dma_segment_array);\r\ndma_segment_array = kzalloc(dma_segment_array_size, GFP_KERNEL);\r\nif (!dma_segment_array) {\r\nprintk(KERN_ERR PFX "hash table pointers (dma) alloc failed\n");\r\nreturn -ENOMEM;\r\n}\r\nfor (i = 0; i < segment_count; ++i) {\r\nhba->hash_tbl_segments[i] =\r\ndma_alloc_coherent(&hba->pcidev->dev,\r\nBNX2FC_HASH_TBL_CHUNK_SIZE,\r\n&dma_segment_array[i],\r\nGFP_KERNEL);\r\nif (!hba->hash_tbl_segments[i]) {\r\nprintk(KERN_ERR PFX "hash segment alloc failed\n");\r\nwhile (--i >= 0) {\r\ndma_free_coherent(&hba->pcidev->dev,\r\nBNX2FC_HASH_TBL_CHUNK_SIZE,\r\nhba->hash_tbl_segments[i],\r\ndma_segment_array[i]);\r\nhba->hash_tbl_segments[i] = NULL;\r\n}\r\nkfree(dma_segment_array);\r\nreturn -ENOMEM;\r\n}\r\nmemset(hba->hash_tbl_segments[i], 0,\r\nBNX2FC_HASH_TBL_CHUNK_SIZE);\r\n}\r\nhba->hash_tbl_pbl = dma_alloc_coherent(&hba->pcidev->dev,\r\nPAGE_SIZE,\r\n&hba->hash_tbl_pbl_dma,\r\nGFP_KERNEL);\r\nif (!hba->hash_tbl_pbl) {\r\nprintk(KERN_ERR PFX "hash table pbl alloc failed\n");\r\nkfree(dma_segment_array);\r\nreturn -ENOMEM;\r\n}\r\nmemset(hba->hash_tbl_pbl, 0, PAGE_SIZE);\r\npbl = hba->hash_tbl_pbl;\r\nfor (i = 0; i < segment_count; ++i) {\r\nu64 paddr = dma_segment_array[i];\r\n*pbl = cpu_to_le32((u32) paddr);\r\n++pbl;\r\n*pbl = cpu_to_le32((u32) (paddr >> 32));\r\n++pbl;\r\n}\r\npbl = hba->hash_tbl_pbl;\r\ni = 0;\r\nwhile (*pbl && *(pbl + 1)) {\r\nu32 lo;\r\nu32 hi;\r\nlo = *pbl;\r\n++pbl;\r\nhi = *pbl;\r\n++pbl;\r\n++i;\r\n}\r\nkfree(dma_segment_array);\r\nreturn 0;\r\n}\r\nint bnx2fc_setup_fw_resc(struct bnx2fc_hba *hba)\r\n{\r\nu64 addr;\r\nu32 mem_size;\r\nint i;\r\nif (bnx2fc_allocate_hash_table(hba))\r\nreturn -ENOMEM;\r\nmem_size = BNX2FC_NUM_MAX_SESS * sizeof(struct regpair);\r\nhba->t2_hash_tbl_ptr = dma_alloc_coherent(&hba->pcidev->dev, mem_size,\r\n&hba->t2_hash_tbl_ptr_dma,\r\nGFP_KERNEL);\r\nif (!hba->t2_hash_tbl_ptr) {\r\nprintk(KERN_ERR PFX "unable to allocate t2 hash table ptr\n");\r\nbnx2fc_free_fw_resc(hba);\r\nreturn -ENOMEM;\r\n}\r\nmemset(hba->t2_hash_tbl_ptr, 0x00, mem_size);\r\nmem_size = BNX2FC_NUM_MAX_SESS *\r\nsizeof(struct fcoe_t2_hash_table_entry);\r\nhba->t2_hash_tbl = dma_alloc_coherent(&hba->pcidev->dev, mem_size,\r\n&hba->t2_hash_tbl_dma,\r\nGFP_KERNEL);\r\nif (!hba->t2_hash_tbl) {\r\nprintk(KERN_ERR PFX "unable to allocate t2 hash table\n");\r\nbnx2fc_free_fw_resc(hba);\r\nreturn -ENOMEM;\r\n}\r\nmemset(hba->t2_hash_tbl, 0x00, mem_size);\r\nfor (i = 0; i < BNX2FC_NUM_MAX_SESS; i++) {\r\naddr = (unsigned long) hba->t2_hash_tbl_dma +\r\n((i+1) * sizeof(struct fcoe_t2_hash_table_entry));\r\nhba->t2_hash_tbl[i].next.lo = addr & 0xffffffff;\r\nhba->t2_hash_tbl[i].next.hi = addr >> 32;\r\n}\r\nhba->dummy_buffer = dma_alloc_coherent(&hba->pcidev->dev,\r\nPAGE_SIZE, &hba->dummy_buf_dma,\r\nGFP_KERNEL);\r\nif (!hba->dummy_buffer) {\r\nprintk(KERN_ERR PFX "unable to alloc MP Dummy Buffer\n");\r\nbnx2fc_free_fw_resc(hba);\r\nreturn -ENOMEM;\r\n}\r\nhba->stats_buffer = dma_alloc_coherent(&hba->pcidev->dev,\r\nPAGE_SIZE,\r\n&hba->stats_buf_dma,\r\nGFP_KERNEL);\r\nif (!hba->stats_buffer) {\r\nprintk(KERN_ERR PFX "unable to alloc Stats Buffer\n");\r\nbnx2fc_free_fw_resc(hba);\r\nreturn -ENOMEM;\r\n}\r\nmemset(hba->stats_buffer, 0x00, PAGE_SIZE);\r\nreturn 0;\r\n}\r\nvoid bnx2fc_free_fw_resc(struct bnx2fc_hba *hba)\r\n{\r\nu32 mem_size;\r\nif (hba->stats_buffer) {\r\ndma_free_coherent(&hba->pcidev->dev, PAGE_SIZE,\r\nhba->stats_buffer, hba->stats_buf_dma);\r\nhba->stats_buffer = NULL;\r\n}\r\nif (hba->dummy_buffer) {\r\ndma_free_coherent(&hba->pcidev->dev, PAGE_SIZE,\r\nhba->dummy_buffer, hba->dummy_buf_dma);\r\nhba->dummy_buffer = NULL;\r\n}\r\nif (hba->t2_hash_tbl_ptr) {\r\nmem_size = BNX2FC_NUM_MAX_SESS * sizeof(struct regpair);\r\ndma_free_coherent(&hba->pcidev->dev, mem_size,\r\nhba->t2_hash_tbl_ptr,\r\nhba->t2_hash_tbl_ptr_dma);\r\nhba->t2_hash_tbl_ptr = NULL;\r\n}\r\nif (hba->t2_hash_tbl) {\r\nmem_size = BNX2FC_NUM_MAX_SESS *\r\nsizeof(struct fcoe_t2_hash_table_entry);\r\ndma_free_coherent(&hba->pcidev->dev, mem_size,\r\nhba->t2_hash_tbl, hba->t2_hash_tbl_dma);\r\nhba->t2_hash_tbl = NULL;\r\n}\r\nbnx2fc_free_hash_table(hba);\r\n}
