static inline void gfs2_update_stats(struct gfs2_lkstats *s, unsigned index,\r\ns64 sample)\r\n{\r\ns64 delta = sample - s->stats[index];\r\ns->stats[index] += (delta >> 3);\r\nindex++;\r\ns->stats[index] += ((abs64(delta) - s->stats[index]) >> 2);\r\n}\r\nstatic inline void gfs2_update_reply_times(struct gfs2_glock *gl)\r\n{\r\nstruct gfs2_pcpu_lkstats *lks;\r\nconst unsigned gltype = gl->gl_name.ln_type;\r\nunsigned index = test_bit(GLF_BLOCKING, &gl->gl_flags) ?\r\nGFS2_LKS_SRTTB : GFS2_LKS_SRTT;\r\ns64 rtt;\r\npreempt_disable();\r\nrtt = ktime_to_ns(ktime_sub(ktime_get_real(), gl->gl_dstamp));\r\nlks = this_cpu_ptr(gl->gl_sbd->sd_lkstats);\r\ngfs2_update_stats(&gl->gl_stats, index, rtt);\r\ngfs2_update_stats(&lks->lkstats[gltype], index, rtt);\r\npreempt_enable();\r\ntrace_gfs2_glock_lock_time(gl, rtt);\r\n}\r\nstatic inline void gfs2_update_request_times(struct gfs2_glock *gl)\r\n{\r\nstruct gfs2_pcpu_lkstats *lks;\r\nconst unsigned gltype = gl->gl_name.ln_type;\r\nktime_t dstamp;\r\ns64 irt;\r\npreempt_disable();\r\ndstamp = gl->gl_dstamp;\r\ngl->gl_dstamp = ktime_get_real();\r\nirt = ktime_to_ns(ktime_sub(gl->gl_dstamp, dstamp));\r\nlks = this_cpu_ptr(gl->gl_sbd->sd_lkstats);\r\ngfs2_update_stats(&gl->gl_stats, GFS2_LKS_SIRT, irt);\r\ngfs2_update_stats(&lks->lkstats[gltype], GFS2_LKS_SIRT, irt);\r\npreempt_enable();\r\n}\r\nstatic void gdlm_ast(void *arg)\r\n{\r\nstruct gfs2_glock *gl = arg;\r\nunsigned ret = gl->gl_state;\r\ngfs2_update_reply_times(gl);\r\nBUG_ON(gl->gl_lksb.sb_flags & DLM_SBF_DEMOTED);\r\nif ((gl->gl_lksb.sb_flags & DLM_SBF_VALNOTVALID) && gl->gl_lksb.sb_lvbptr)\r\nmemset(gl->gl_lksb.sb_lvbptr, 0, GDLM_LVB_SIZE);\r\nswitch (gl->gl_lksb.sb_status) {\r\ncase -DLM_EUNLOCK:\r\ngfs2_glock_free(gl);\r\nreturn;\r\ncase -DLM_ECANCEL:\r\nret |= LM_OUT_CANCELED;\r\ngoto out;\r\ncase -EAGAIN:\r\ncase -EDEADLK:\r\ngoto out;\r\ncase -ETIMEDOUT:\r\nret |= LM_OUT_ERROR;\r\ngoto out;\r\ncase 0:\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\nret = gl->gl_req;\r\nif (gl->gl_lksb.sb_flags & DLM_SBF_ALTMODE) {\r\nif (gl->gl_req == LM_ST_SHARED)\r\nret = LM_ST_DEFERRED;\r\nelse if (gl->gl_req == LM_ST_DEFERRED)\r\nret = LM_ST_SHARED;\r\nelse\r\nBUG();\r\n}\r\nset_bit(GLF_INITIAL, &gl->gl_flags);\r\ngfs2_glock_complete(gl, ret);\r\nreturn;\r\nout:\r\nif (!test_bit(GLF_INITIAL, &gl->gl_flags))\r\ngl->gl_lksb.sb_lkid = 0;\r\ngfs2_glock_complete(gl, ret);\r\n}\r\nstatic void gdlm_bast(void *arg, int mode)\r\n{\r\nstruct gfs2_glock *gl = arg;\r\nswitch (mode) {\r\ncase DLM_LOCK_EX:\r\ngfs2_glock_cb(gl, LM_ST_UNLOCKED);\r\nbreak;\r\ncase DLM_LOCK_CW:\r\ngfs2_glock_cb(gl, LM_ST_DEFERRED);\r\nbreak;\r\ncase DLM_LOCK_PR:\r\ngfs2_glock_cb(gl, LM_ST_SHARED);\r\nbreak;\r\ndefault:\r\nprintk(KERN_ERR "unknown bast mode %d", mode);\r\nBUG();\r\n}\r\n}\r\nstatic int make_mode(const unsigned int lmstate)\r\n{\r\nswitch (lmstate) {\r\ncase LM_ST_UNLOCKED:\r\nreturn DLM_LOCK_NL;\r\ncase LM_ST_EXCLUSIVE:\r\nreturn DLM_LOCK_EX;\r\ncase LM_ST_DEFERRED:\r\nreturn DLM_LOCK_CW;\r\ncase LM_ST_SHARED:\r\nreturn DLM_LOCK_PR;\r\n}\r\nprintk(KERN_ERR "unknown LM state %d", lmstate);\r\nBUG();\r\nreturn -1;\r\n}\r\nstatic u32 make_flags(struct gfs2_glock *gl, const unsigned int gfs_flags,\r\nconst int req)\r\n{\r\nu32 lkf = 0;\r\nif (gl->gl_lksb.sb_lvbptr)\r\nlkf |= DLM_LKF_VALBLK;\r\nif (gfs_flags & LM_FLAG_TRY)\r\nlkf |= DLM_LKF_NOQUEUE;\r\nif (gfs_flags & LM_FLAG_TRY_1CB) {\r\nlkf |= DLM_LKF_NOQUEUE;\r\nlkf |= DLM_LKF_NOQUEUEBAST;\r\n}\r\nif (gfs_flags & LM_FLAG_PRIORITY) {\r\nlkf |= DLM_LKF_NOORDER;\r\nlkf |= DLM_LKF_HEADQUE;\r\n}\r\nif (gfs_flags & LM_FLAG_ANY) {\r\nif (req == DLM_LOCK_PR)\r\nlkf |= DLM_LKF_ALTCW;\r\nelse if (req == DLM_LOCK_CW)\r\nlkf |= DLM_LKF_ALTPR;\r\nelse\r\nBUG();\r\n}\r\nif (gl->gl_lksb.sb_lkid != 0) {\r\nlkf |= DLM_LKF_CONVERT;\r\nif (test_bit(GLF_BLOCKING, &gl->gl_flags))\r\nlkf |= DLM_LKF_QUECVT;\r\n}\r\nreturn lkf;\r\n}\r\nstatic void gfs2_reverse_hex(char *c, u64 value)\r\n{\r\n*c = '0';\r\nwhile (value) {\r\n*c-- = hex_asc[value & 0x0f];\r\nvalue >>= 4;\r\n}\r\n}\r\nstatic int gdlm_lock(struct gfs2_glock *gl, unsigned int req_state,\r\nunsigned int flags)\r\n{\r\nstruct lm_lockstruct *ls = &gl->gl_sbd->sd_lockstruct;\r\nint req;\r\nu32 lkf;\r\nchar strname[GDLM_STRNAME_BYTES] = "";\r\nreq = make_mode(req_state);\r\nlkf = make_flags(gl, flags, req);\r\ngfs2_glstats_inc(gl, GFS2_LKS_DCOUNT);\r\ngfs2_sbstats_inc(gl, GFS2_LKS_DCOUNT);\r\nif (gl->gl_lksb.sb_lkid) {\r\ngfs2_update_request_times(gl);\r\n} else {\r\nmemset(strname, ' ', GDLM_STRNAME_BYTES - 1);\r\nstrname[GDLM_STRNAME_BYTES - 1] = '\0';\r\ngfs2_reverse_hex(strname + 7, gl->gl_name.ln_type);\r\ngfs2_reverse_hex(strname + 23, gl->gl_name.ln_number);\r\ngl->gl_dstamp = ktime_get_real();\r\n}\r\nreturn dlm_lock(ls->ls_dlm, req, &gl->gl_lksb, lkf, strname,\r\nGDLM_STRNAME_BYTES - 1, 0, gdlm_ast, gl, gdlm_bast);\r\n}\r\nstatic void gdlm_put_lock(struct gfs2_glock *gl)\r\n{\r\nstruct gfs2_sbd *sdp = gl->gl_sbd;\r\nstruct lm_lockstruct *ls = &sdp->sd_lockstruct;\r\nint lvb_needs_unlock = 0;\r\nint error;\r\nif (gl->gl_lksb.sb_lkid == 0) {\r\ngfs2_glock_free(gl);\r\nreturn;\r\n}\r\nclear_bit(GLF_BLOCKING, &gl->gl_flags);\r\ngfs2_glstats_inc(gl, GFS2_LKS_DCOUNT);\r\ngfs2_sbstats_inc(gl, GFS2_LKS_DCOUNT);\r\ngfs2_update_request_times(gl);\r\nif (gl->gl_lksb.sb_lvbptr && (gl->gl_state == LM_ST_EXCLUSIVE))\r\nlvb_needs_unlock = 1;\r\nif (test_bit(SDF_SKIP_DLM_UNLOCK, &sdp->sd_flags) &&\r\n!lvb_needs_unlock) {\r\ngfs2_glock_free(gl);\r\nreturn;\r\n}\r\nerror = dlm_unlock(ls->ls_dlm, gl->gl_lksb.sb_lkid, DLM_LKF_VALBLK,\r\nNULL, gl);\r\nif (error) {\r\nprintk(KERN_ERR "gdlm_unlock %x,%llx err=%d\n",\r\ngl->gl_name.ln_type,\r\n(unsigned long long)gl->gl_name.ln_number, error);\r\nreturn;\r\n}\r\n}\r\nstatic void gdlm_cancel(struct gfs2_glock *gl)\r\n{\r\nstruct lm_lockstruct *ls = &gl->gl_sbd->sd_lockstruct;\r\ndlm_unlock(ls->ls_dlm, gl->gl_lksb.sb_lkid, DLM_LKF_CANCEL, NULL, gl);\r\n}\r\nstatic void control_lvb_read(struct lm_lockstruct *ls, uint32_t *lvb_gen,\r\nchar *lvb_bits)\r\n{\r\nuint32_t gen;\r\nmemcpy(lvb_bits, ls->ls_control_lvb, GDLM_LVB_SIZE);\r\nmemcpy(&gen, lvb_bits, sizeof(uint32_t));\r\n*lvb_gen = le32_to_cpu(gen);\r\n}\r\nstatic void control_lvb_write(struct lm_lockstruct *ls, uint32_t lvb_gen,\r\nchar *lvb_bits)\r\n{\r\nuint32_t gen;\r\nmemcpy(ls->ls_control_lvb, lvb_bits, GDLM_LVB_SIZE);\r\ngen = cpu_to_le32(lvb_gen);\r\nmemcpy(ls->ls_control_lvb, &gen, sizeof(uint32_t));\r\n}\r\nstatic int all_jid_bits_clear(char *lvb)\r\n{\r\nreturn !memchr_inv(lvb + JID_BITMAP_OFFSET, 0,\r\nGDLM_LVB_SIZE - JID_BITMAP_OFFSET);\r\n}\r\nstatic void sync_wait_cb(void *arg)\r\n{\r\nstruct lm_lockstruct *ls = arg;\r\ncomplete(&ls->ls_sync_wait);\r\n}\r\nstatic int sync_unlock(struct gfs2_sbd *sdp, struct dlm_lksb *lksb, char *name)\r\n{\r\nstruct lm_lockstruct *ls = &sdp->sd_lockstruct;\r\nint error;\r\nerror = dlm_unlock(ls->ls_dlm, lksb->sb_lkid, 0, lksb, ls);\r\nif (error) {\r\nfs_err(sdp, "%s lkid %x error %d\n",\r\nname, lksb->sb_lkid, error);\r\nreturn error;\r\n}\r\nwait_for_completion(&ls->ls_sync_wait);\r\nif (lksb->sb_status != -DLM_EUNLOCK) {\r\nfs_err(sdp, "%s lkid %x status %d\n",\r\nname, lksb->sb_lkid, lksb->sb_status);\r\nreturn -1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int sync_lock(struct gfs2_sbd *sdp, int mode, uint32_t flags,\r\nunsigned int num, struct dlm_lksb *lksb, char *name)\r\n{\r\nstruct lm_lockstruct *ls = &sdp->sd_lockstruct;\r\nchar strname[GDLM_STRNAME_BYTES];\r\nint error, status;\r\nmemset(strname, 0, GDLM_STRNAME_BYTES);\r\nsnprintf(strname, GDLM_STRNAME_BYTES, "%8x%16x", LM_TYPE_NONDISK, num);\r\nerror = dlm_lock(ls->ls_dlm, mode, lksb, flags,\r\nstrname, GDLM_STRNAME_BYTES - 1,\r\n0, sync_wait_cb, ls, NULL);\r\nif (error) {\r\nfs_err(sdp, "%s lkid %x flags %x mode %d error %d\n",\r\nname, lksb->sb_lkid, flags, mode, error);\r\nreturn error;\r\n}\r\nwait_for_completion(&ls->ls_sync_wait);\r\nstatus = lksb->sb_status;\r\nif (status && status != -EAGAIN) {\r\nfs_err(sdp, "%s lkid %x flags %x mode %d status %d\n",\r\nname, lksb->sb_lkid, flags, mode, status);\r\n}\r\nreturn status;\r\n}\r\nstatic int mounted_unlock(struct gfs2_sbd *sdp)\r\n{\r\nstruct lm_lockstruct *ls = &sdp->sd_lockstruct;\r\nreturn sync_unlock(sdp, &ls->ls_mounted_lksb, "mounted_lock");\r\n}\r\nstatic int mounted_lock(struct gfs2_sbd *sdp, int mode, uint32_t flags)\r\n{\r\nstruct lm_lockstruct *ls = &sdp->sd_lockstruct;\r\nreturn sync_lock(sdp, mode, flags, GFS2_MOUNTED_LOCK,\r\n&ls->ls_mounted_lksb, "mounted_lock");\r\n}\r\nstatic int control_unlock(struct gfs2_sbd *sdp)\r\n{\r\nstruct lm_lockstruct *ls = &sdp->sd_lockstruct;\r\nreturn sync_unlock(sdp, &ls->ls_control_lksb, "control_lock");\r\n}\r\nstatic int control_lock(struct gfs2_sbd *sdp, int mode, uint32_t flags)\r\n{\r\nstruct lm_lockstruct *ls = &sdp->sd_lockstruct;\r\nreturn sync_lock(sdp, mode, flags, GFS2_CONTROL_LOCK,\r\n&ls->ls_control_lksb, "control_lock");\r\n}\r\nstatic void gfs2_control_func(struct work_struct *work)\r\n{\r\nstruct gfs2_sbd *sdp = container_of(work, struct gfs2_sbd, sd_control_work.work);\r\nstruct lm_lockstruct *ls = &sdp->sd_lockstruct;\r\nuint32_t block_gen, start_gen, lvb_gen, flags;\r\nint recover_set = 0;\r\nint write_lvb = 0;\r\nint recover_size;\r\nint i, error;\r\nspin_lock(&ls->ls_recover_spin);\r\nif (!test_bit(DFL_MOUNT_DONE, &ls->ls_recover_flags) ||\r\ntest_bit(DFL_FIRST_MOUNT, &ls->ls_recover_flags)) {\r\nspin_unlock(&ls->ls_recover_spin);\r\nreturn;\r\n}\r\nblock_gen = ls->ls_recover_block;\r\nstart_gen = ls->ls_recover_start;\r\nspin_unlock(&ls->ls_recover_spin);\r\nif (block_gen == start_gen)\r\nreturn;\r\nerror = control_lock(sdp, DLM_LOCK_EX, DLM_LKF_CONVERT|DLM_LKF_VALBLK);\r\nif (error) {\r\nfs_err(sdp, "control lock EX error %d\n", error);\r\nreturn;\r\n}\r\ncontrol_lvb_read(ls, &lvb_gen, ls->ls_lvb_bits);\r\nspin_lock(&ls->ls_recover_spin);\r\nif (block_gen != ls->ls_recover_block ||\r\nstart_gen != ls->ls_recover_start) {\r\nfs_info(sdp, "recover generation %u block1 %u %u\n",\r\nstart_gen, block_gen, ls->ls_recover_block);\r\nspin_unlock(&ls->ls_recover_spin);\r\ncontrol_lock(sdp, DLM_LOCK_NL, DLM_LKF_CONVERT);\r\nreturn;\r\n}\r\nrecover_size = ls->ls_recover_size;\r\nif (lvb_gen <= start_gen) {\r\nfor (i = 0; i < recover_size; i++) {\r\nif (ls->ls_recover_result[i] != LM_RD_SUCCESS)\r\ncontinue;\r\nls->ls_recover_result[i] = 0;\r\nif (!test_bit_le(i, ls->ls_lvb_bits + JID_BITMAP_OFFSET))\r\ncontinue;\r\n__clear_bit_le(i, ls->ls_lvb_bits + JID_BITMAP_OFFSET);\r\nwrite_lvb = 1;\r\n}\r\n}\r\nif (lvb_gen == start_gen) {\r\nfor (i = 0; i < recover_size; i++) {\r\nif (!ls->ls_recover_submit[i])\r\ncontinue;\r\nif (ls->ls_recover_submit[i] < lvb_gen)\r\nls->ls_recover_submit[i] = 0;\r\n}\r\n} else if (lvb_gen < start_gen) {\r\nfor (i = 0; i < recover_size; i++) {\r\nif (!ls->ls_recover_submit[i])\r\ncontinue;\r\nif (ls->ls_recover_submit[i] < start_gen) {\r\nls->ls_recover_submit[i] = 0;\r\n__set_bit_le(i, ls->ls_lvb_bits + JID_BITMAP_OFFSET);\r\n}\r\n}\r\nwrite_lvb = 1;\r\n} else {\r\n}\r\nspin_unlock(&ls->ls_recover_spin);\r\nif (write_lvb) {\r\ncontrol_lvb_write(ls, start_gen, ls->ls_lvb_bits);\r\nflags = DLM_LKF_CONVERT | DLM_LKF_VALBLK;\r\n} else {\r\nflags = DLM_LKF_CONVERT;\r\n}\r\nerror = control_lock(sdp, DLM_LOCK_NL, flags);\r\nif (error) {\r\nfs_err(sdp, "control lock NL error %d\n", error);\r\nreturn;\r\n}\r\nfor (i = 0; i < recover_size; i++) {\r\nif (test_bit_le(i, ls->ls_lvb_bits + JID_BITMAP_OFFSET)) {\r\nfs_info(sdp, "recover generation %u jid %d\n",\r\nstart_gen, i);\r\ngfs2_recover_set(sdp, i);\r\nrecover_set++;\r\n}\r\n}\r\nif (recover_set)\r\nreturn;\r\nspin_lock(&ls->ls_recover_spin);\r\nif (ls->ls_recover_block == block_gen &&\r\nls->ls_recover_start == start_gen) {\r\nclear_bit(DFL_BLOCK_LOCKS, &ls->ls_recover_flags);\r\nspin_unlock(&ls->ls_recover_spin);\r\nfs_info(sdp, "recover generation %u done\n", start_gen);\r\ngfs2_glock_thaw(sdp);\r\n} else {\r\nfs_info(sdp, "recover generation %u block2 %u %u\n",\r\nstart_gen, block_gen, ls->ls_recover_block);\r\nspin_unlock(&ls->ls_recover_spin);\r\n}\r\n}\r\nstatic int control_mount(struct gfs2_sbd *sdp)\r\n{\r\nstruct lm_lockstruct *ls = &sdp->sd_lockstruct;\r\nuint32_t start_gen, block_gen, mount_gen, lvb_gen;\r\nint mounted_mode;\r\nint retries = 0;\r\nint error;\r\nmemset(&ls->ls_mounted_lksb, 0, sizeof(struct dlm_lksb));\r\nmemset(&ls->ls_control_lksb, 0, sizeof(struct dlm_lksb));\r\nmemset(&ls->ls_control_lvb, 0, GDLM_LVB_SIZE);\r\nls->ls_control_lksb.sb_lvbptr = ls->ls_control_lvb;\r\ninit_completion(&ls->ls_sync_wait);\r\nset_bit(DFL_BLOCK_LOCKS, &ls->ls_recover_flags);\r\nerror = control_lock(sdp, DLM_LOCK_NL, DLM_LKF_VALBLK);\r\nif (error) {\r\nfs_err(sdp, "control_mount control_lock NL error %d\n", error);\r\nreturn error;\r\n}\r\nerror = mounted_lock(sdp, DLM_LOCK_NL, 0);\r\nif (error) {\r\nfs_err(sdp, "control_mount mounted_lock NL error %d\n", error);\r\ncontrol_unlock(sdp);\r\nreturn error;\r\n}\r\nmounted_mode = DLM_LOCK_NL;\r\nrestart:\r\nif (retries++ && signal_pending(current)) {\r\nerror = -EINTR;\r\ngoto fail;\r\n}\r\nif (mounted_mode != DLM_LOCK_NL) {\r\nerror = mounted_lock(sdp, DLM_LOCK_NL, DLM_LKF_CONVERT);\r\nif (error)\r\ngoto fail;\r\nmounted_mode = DLM_LOCK_NL;\r\n}\r\nmsleep_interruptible(500);\r\nerror = control_lock(sdp, DLM_LOCK_EX, DLM_LKF_CONVERT|DLM_LKF_NOQUEUE|DLM_LKF_VALBLK);\r\nif (error == -EAGAIN) {\r\ngoto restart;\r\n} else if (error) {\r\nfs_err(sdp, "control_mount control_lock EX error %d\n", error);\r\ngoto fail;\r\n}\r\nerror = mounted_lock(sdp, DLM_LOCK_EX, DLM_LKF_CONVERT|DLM_LKF_NOQUEUE);\r\nif (!error) {\r\nmounted_mode = DLM_LOCK_EX;\r\ngoto locks_done;\r\n} else if (error != -EAGAIN) {\r\nfs_err(sdp, "control_mount mounted_lock EX error %d\n", error);\r\ngoto fail;\r\n}\r\nerror = mounted_lock(sdp, DLM_LOCK_PR, DLM_LKF_CONVERT|DLM_LKF_NOQUEUE);\r\nif (!error) {\r\nmounted_mode = DLM_LOCK_PR;\r\ngoto locks_done;\r\n} else {\r\nfs_err(sdp, "control_mount mounted_lock PR error %d\n", error);\r\ngoto fail;\r\n}\r\nlocks_done:\r\ncontrol_lvb_read(ls, &lvb_gen, ls->ls_lvb_bits);\r\nif (lvb_gen == 0xFFFFFFFF) {\r\nfs_err(sdp, "control_mount control_lock disabled\n");\r\nerror = -EINVAL;\r\ngoto fail;\r\n}\r\nif (mounted_mode == DLM_LOCK_EX) {\r\nspin_lock(&ls->ls_recover_spin);\r\nclear_bit(DFL_BLOCK_LOCKS, &ls->ls_recover_flags);\r\nset_bit(DFL_MOUNT_DONE, &ls->ls_recover_flags);\r\nset_bit(DFL_FIRST_MOUNT, &ls->ls_recover_flags);\r\nspin_unlock(&ls->ls_recover_spin);\r\nfs_info(sdp, "first mounter control generation %u\n", lvb_gen);\r\nreturn 0;\r\n}\r\nerror = control_lock(sdp, DLM_LOCK_NL, DLM_LKF_CONVERT);\r\nif (error)\r\ngoto fail;\r\nif (!all_jid_bits_clear(ls->ls_lvb_bits)) {\r\nfs_info(sdp, "control_mount wait for journal recovery\n");\r\ngoto restart;\r\n}\r\nspin_lock(&ls->ls_recover_spin);\r\nblock_gen = ls->ls_recover_block;\r\nstart_gen = ls->ls_recover_start;\r\nmount_gen = ls->ls_recover_mount;\r\nif (lvb_gen < mount_gen) {\r\nfs_info(sdp, "control_mount wait1 block %u start %u mount %u "\r\n"lvb %u flags %lx\n", block_gen, start_gen, mount_gen,\r\nlvb_gen, ls->ls_recover_flags);\r\nspin_unlock(&ls->ls_recover_spin);\r\ngoto restart;\r\n}\r\nif (lvb_gen != start_gen) {\r\nfs_info(sdp, "control_mount wait2 block %u start %u mount %u "\r\n"lvb %u flags %lx\n", block_gen, start_gen, mount_gen,\r\nlvb_gen, ls->ls_recover_flags);\r\nspin_unlock(&ls->ls_recover_spin);\r\ngoto restart;\r\n}\r\nif (block_gen == start_gen) {\r\nfs_info(sdp, "control_mount wait3 block %u start %u mount %u "\r\n"lvb %u flags %lx\n", block_gen, start_gen, mount_gen,\r\nlvb_gen, ls->ls_recover_flags);\r\nspin_unlock(&ls->ls_recover_spin);\r\ngoto restart;\r\n}\r\nclear_bit(DFL_BLOCK_LOCKS, &ls->ls_recover_flags);\r\nset_bit(DFL_MOUNT_DONE, &ls->ls_recover_flags);\r\nmemset(ls->ls_recover_submit, 0, ls->ls_recover_size*sizeof(uint32_t));\r\nmemset(ls->ls_recover_result, 0, ls->ls_recover_size*sizeof(uint32_t));\r\nspin_unlock(&ls->ls_recover_spin);\r\nreturn 0;\r\nfail:\r\nmounted_unlock(sdp);\r\ncontrol_unlock(sdp);\r\nreturn error;\r\n}\r\nstatic int dlm_recovery_wait(void *word)\r\n{\r\nschedule();\r\nreturn 0;\r\n}\r\nstatic int control_first_done(struct gfs2_sbd *sdp)\r\n{\r\nstruct lm_lockstruct *ls = &sdp->sd_lockstruct;\r\nuint32_t start_gen, block_gen;\r\nint error;\r\nrestart:\r\nspin_lock(&ls->ls_recover_spin);\r\nstart_gen = ls->ls_recover_start;\r\nblock_gen = ls->ls_recover_block;\r\nif (test_bit(DFL_BLOCK_LOCKS, &ls->ls_recover_flags) ||\r\n!test_bit(DFL_MOUNT_DONE, &ls->ls_recover_flags) ||\r\n!test_bit(DFL_FIRST_MOUNT, &ls->ls_recover_flags)) {\r\nfs_err(sdp, "control_first_done start %u block %u flags %lx\n",\r\nstart_gen, block_gen, ls->ls_recover_flags);\r\nspin_unlock(&ls->ls_recover_spin);\r\ncontrol_unlock(sdp);\r\nreturn -1;\r\n}\r\nif (start_gen == block_gen) {\r\nspin_unlock(&ls->ls_recover_spin);\r\nfs_info(sdp, "control_first_done wait gen %u\n", start_gen);\r\nwait_on_bit(&ls->ls_recover_flags, DFL_DLM_RECOVERY,\r\ndlm_recovery_wait, TASK_UNINTERRUPTIBLE);\r\ngoto restart;\r\n}\r\nclear_bit(DFL_FIRST_MOUNT, &ls->ls_recover_flags);\r\nset_bit(DFL_FIRST_MOUNT_DONE, &ls->ls_recover_flags);\r\nmemset(ls->ls_recover_submit, 0, ls->ls_recover_size*sizeof(uint32_t));\r\nmemset(ls->ls_recover_result, 0, ls->ls_recover_size*sizeof(uint32_t));\r\nspin_unlock(&ls->ls_recover_spin);\r\nmemset(ls->ls_lvb_bits, 0, GDLM_LVB_SIZE);\r\ncontrol_lvb_write(ls, start_gen, ls->ls_lvb_bits);\r\nerror = mounted_lock(sdp, DLM_LOCK_PR, DLM_LKF_CONVERT);\r\nif (error)\r\nfs_err(sdp, "control_first_done mounted PR error %d\n", error);\r\nerror = control_lock(sdp, DLM_LOCK_NL, DLM_LKF_CONVERT|DLM_LKF_VALBLK);\r\nif (error)\r\nfs_err(sdp, "control_first_done control NL error %d\n", error);\r\nreturn error;\r\n}\r\nstatic int set_recover_size(struct gfs2_sbd *sdp, struct dlm_slot *slots,\r\nint num_slots)\r\n{\r\nstruct lm_lockstruct *ls = &sdp->sd_lockstruct;\r\nuint32_t *submit = NULL;\r\nuint32_t *result = NULL;\r\nuint32_t old_size, new_size;\r\nint i, max_jid;\r\nif (!ls->ls_lvb_bits) {\r\nls->ls_lvb_bits = kzalloc(GDLM_LVB_SIZE, GFP_NOFS);\r\nif (!ls->ls_lvb_bits)\r\nreturn -ENOMEM;\r\n}\r\nmax_jid = 0;\r\nfor (i = 0; i < num_slots; i++) {\r\nif (max_jid < slots[i].slot - 1)\r\nmax_jid = slots[i].slot - 1;\r\n}\r\nold_size = ls->ls_recover_size;\r\nif (old_size >= max_jid + 1)\r\nreturn 0;\r\nnew_size = old_size + RECOVER_SIZE_INC;\r\nsubmit = kzalloc(new_size * sizeof(uint32_t), GFP_NOFS);\r\nresult = kzalloc(new_size * sizeof(uint32_t), GFP_NOFS);\r\nif (!submit || !result) {\r\nkfree(submit);\r\nkfree(result);\r\nreturn -ENOMEM;\r\n}\r\nspin_lock(&ls->ls_recover_spin);\r\nmemcpy(submit, ls->ls_recover_submit, old_size * sizeof(uint32_t));\r\nmemcpy(result, ls->ls_recover_result, old_size * sizeof(uint32_t));\r\nkfree(ls->ls_recover_submit);\r\nkfree(ls->ls_recover_result);\r\nls->ls_recover_submit = submit;\r\nls->ls_recover_result = result;\r\nls->ls_recover_size = new_size;\r\nspin_unlock(&ls->ls_recover_spin);\r\nreturn 0;\r\n}\r\nstatic void free_recover_size(struct lm_lockstruct *ls)\r\n{\r\nkfree(ls->ls_lvb_bits);\r\nkfree(ls->ls_recover_submit);\r\nkfree(ls->ls_recover_result);\r\nls->ls_recover_submit = NULL;\r\nls->ls_recover_result = NULL;\r\nls->ls_recover_size = 0;\r\n}\r\nstatic void gdlm_recover_prep(void *arg)\r\n{\r\nstruct gfs2_sbd *sdp = arg;\r\nstruct lm_lockstruct *ls = &sdp->sd_lockstruct;\r\nspin_lock(&ls->ls_recover_spin);\r\nls->ls_recover_block = ls->ls_recover_start;\r\nset_bit(DFL_DLM_RECOVERY, &ls->ls_recover_flags);\r\nif (!test_bit(DFL_MOUNT_DONE, &ls->ls_recover_flags) ||\r\ntest_bit(DFL_FIRST_MOUNT, &ls->ls_recover_flags)) {\r\nspin_unlock(&ls->ls_recover_spin);\r\nreturn;\r\n}\r\nset_bit(DFL_BLOCK_LOCKS, &ls->ls_recover_flags);\r\nspin_unlock(&ls->ls_recover_spin);\r\n}\r\nstatic void gdlm_recover_slot(void *arg, struct dlm_slot *slot)\r\n{\r\nstruct gfs2_sbd *sdp = arg;\r\nstruct lm_lockstruct *ls = &sdp->sd_lockstruct;\r\nint jid = slot->slot - 1;\r\nspin_lock(&ls->ls_recover_spin);\r\nif (ls->ls_recover_size < jid + 1) {\r\nfs_err(sdp, "recover_slot jid %d gen %u short size %d",\r\njid, ls->ls_recover_block, ls->ls_recover_size);\r\nspin_unlock(&ls->ls_recover_spin);\r\nreturn;\r\n}\r\nif (ls->ls_recover_submit[jid]) {\r\nfs_info(sdp, "recover_slot jid %d gen %u prev %u",\r\njid, ls->ls_recover_block, ls->ls_recover_submit[jid]);\r\n}\r\nls->ls_recover_submit[jid] = ls->ls_recover_block;\r\nspin_unlock(&ls->ls_recover_spin);\r\n}\r\nstatic void gdlm_recover_done(void *arg, struct dlm_slot *slots, int num_slots,\r\nint our_slot, uint32_t generation)\r\n{\r\nstruct gfs2_sbd *sdp = arg;\r\nstruct lm_lockstruct *ls = &sdp->sd_lockstruct;\r\nset_recover_size(sdp, slots, num_slots);\r\nspin_lock(&ls->ls_recover_spin);\r\nls->ls_recover_start = generation;\r\nif (!ls->ls_recover_mount) {\r\nls->ls_recover_mount = generation;\r\nls->ls_jid = our_slot - 1;\r\n}\r\nif (!test_bit(DFL_UNMOUNT, &ls->ls_recover_flags))\r\nqueue_delayed_work(gfs2_control_wq, &sdp->sd_control_work, 0);\r\nclear_bit(DFL_DLM_RECOVERY, &ls->ls_recover_flags);\r\nsmp_mb__after_clear_bit();\r\nwake_up_bit(&ls->ls_recover_flags, DFL_DLM_RECOVERY);\r\nspin_unlock(&ls->ls_recover_spin);\r\n}\r\nstatic void gdlm_recovery_result(struct gfs2_sbd *sdp, unsigned int jid,\r\nunsigned int result)\r\n{\r\nstruct lm_lockstruct *ls = &sdp->sd_lockstruct;\r\nif (test_bit(DFL_NO_DLM_OPS, &ls->ls_recover_flags))\r\nreturn;\r\nif (jid == ls->ls_jid)\r\nreturn;\r\nspin_lock(&ls->ls_recover_spin);\r\nif (test_bit(DFL_FIRST_MOUNT, &ls->ls_recover_flags)) {\r\nspin_unlock(&ls->ls_recover_spin);\r\nreturn;\r\n}\r\nif (ls->ls_recover_size < jid + 1) {\r\nfs_err(sdp, "recovery_result jid %d short size %d",\r\njid, ls->ls_recover_size);\r\nspin_unlock(&ls->ls_recover_spin);\r\nreturn;\r\n}\r\nfs_info(sdp, "recover jid %d result %s\n", jid,\r\nresult == LM_RD_GAVEUP ? "busy" : "success");\r\nls->ls_recover_result[jid] = result;\r\nif (!test_bit(DFL_UNMOUNT, &ls->ls_recover_flags))\r\nqueue_delayed_work(gfs2_control_wq, &sdp->sd_control_work,\r\nresult == LM_RD_GAVEUP ? HZ : 0);\r\nspin_unlock(&ls->ls_recover_spin);\r\n}\r\nstatic int gdlm_mount(struct gfs2_sbd *sdp, const char *table)\r\n{\r\nstruct lm_lockstruct *ls = &sdp->sd_lockstruct;\r\nchar cluster[GFS2_LOCKNAME_LEN];\r\nconst char *fsname;\r\nuint32_t flags;\r\nint error, ops_result;\r\nINIT_DELAYED_WORK(&sdp->sd_control_work, gfs2_control_func);\r\nspin_lock_init(&ls->ls_recover_spin);\r\nls->ls_recover_flags = 0;\r\nls->ls_recover_mount = 0;\r\nls->ls_recover_start = 0;\r\nls->ls_recover_block = 0;\r\nls->ls_recover_size = 0;\r\nls->ls_recover_submit = NULL;\r\nls->ls_recover_result = NULL;\r\nls->ls_lvb_bits = NULL;\r\nerror = set_recover_size(sdp, NULL, 0);\r\nif (error)\r\ngoto fail;\r\nfsname = strchr(table, ':');\r\nif (!fsname) {\r\nfs_info(sdp, "no fsname found\n");\r\nerror = -EINVAL;\r\ngoto fail_free;\r\n}\r\nmemset(cluster, 0, sizeof(cluster));\r\nmemcpy(cluster, table, strlen(table) - strlen(fsname));\r\nfsname++;\r\nflags = DLM_LSFL_FS | DLM_LSFL_NEWEXCL;\r\nerror = dlm_new_lockspace(fsname, cluster, flags, GDLM_LVB_SIZE,\r\n&gdlm_lockspace_ops, sdp, &ops_result,\r\n&ls->ls_dlm);\r\nif (error) {\r\nfs_err(sdp, "dlm_new_lockspace error %d\n", error);\r\ngoto fail_free;\r\n}\r\nif (ops_result < 0) {\r\nfs_info(sdp, "dlm lockspace ops not used\n");\r\nfree_recover_size(ls);\r\nset_bit(DFL_NO_DLM_OPS, &ls->ls_recover_flags);\r\nreturn 0;\r\n}\r\nif (!test_bit(SDF_NOJOURNALID, &sdp->sd_flags)) {\r\nfs_err(sdp, "dlm lockspace ops disallow jid preset\n");\r\nerror = -EINVAL;\r\ngoto fail_release;\r\n}\r\nerror = control_mount(sdp);\r\nif (error) {\r\nfs_err(sdp, "mount control error %d\n", error);\r\ngoto fail_release;\r\n}\r\nls->ls_first = !!test_bit(DFL_FIRST_MOUNT, &ls->ls_recover_flags);\r\nclear_bit(SDF_NOJOURNALID, &sdp->sd_flags);\r\nsmp_mb__after_clear_bit();\r\nwake_up_bit(&sdp->sd_flags, SDF_NOJOURNALID);\r\nreturn 0;\r\nfail_release:\r\ndlm_release_lockspace(ls->ls_dlm, 2);\r\nfail_free:\r\nfree_recover_size(ls);\r\nfail:\r\nreturn error;\r\n}\r\nstatic void gdlm_first_done(struct gfs2_sbd *sdp)\r\n{\r\nstruct lm_lockstruct *ls = &sdp->sd_lockstruct;\r\nint error;\r\nif (test_bit(DFL_NO_DLM_OPS, &ls->ls_recover_flags))\r\nreturn;\r\nerror = control_first_done(sdp);\r\nif (error)\r\nfs_err(sdp, "mount first_done error %d\n", error);\r\n}\r\nstatic void gdlm_unmount(struct gfs2_sbd *sdp)\r\n{\r\nstruct lm_lockstruct *ls = &sdp->sd_lockstruct;\r\nif (test_bit(DFL_NO_DLM_OPS, &ls->ls_recover_flags))\r\ngoto release;\r\nspin_lock(&ls->ls_recover_spin);\r\nset_bit(DFL_UNMOUNT, &ls->ls_recover_flags);\r\nspin_unlock(&ls->ls_recover_spin);\r\nflush_delayed_work(&sdp->sd_control_work);\r\nrelease:\r\nif (ls->ls_dlm) {\r\ndlm_release_lockspace(ls->ls_dlm, 2);\r\nls->ls_dlm = NULL;\r\n}\r\nfree_recover_size(ls);\r\n}
