xfs_da_state_t *\r\nxfs_da_state_alloc(void)\r\n{\r\nreturn kmem_zone_zalloc(xfs_da_state_zone, KM_NOFS);\r\n}\r\nSTATIC void\r\nxfs_da_state_kill_altpath(xfs_da_state_t *state)\r\n{\r\nint i;\r\nfor (i = 0; i < state->altpath.active; i++)\r\nstate->altpath.blk[i].bp = NULL;\r\nstate->altpath.active = 0;\r\n}\r\nvoid\r\nxfs_da_state_free(xfs_da_state_t *state)\r\n{\r\nxfs_da_state_kill_altpath(state);\r\n#ifdef DEBUG\r\nmemset((char *)state, 0, sizeof(*state));\r\n#endif\r\nkmem_zone_free(xfs_da_state_zone, state);\r\n}\r\nvoid\r\nxfs_da3_node_hdr_from_disk(\r\nstruct xfs_da3_icnode_hdr *to,\r\nstruct xfs_da_intnode *from)\r\n{\r\nASSERT(from->hdr.info.magic == cpu_to_be16(XFS_DA_NODE_MAGIC) ||\r\nfrom->hdr.info.magic == cpu_to_be16(XFS_DA3_NODE_MAGIC));\r\nif (from->hdr.info.magic == cpu_to_be16(XFS_DA3_NODE_MAGIC)) {\r\nstruct xfs_da3_node_hdr *hdr3 = (struct xfs_da3_node_hdr *)from;\r\nto->forw = be32_to_cpu(hdr3->info.hdr.forw);\r\nto->back = be32_to_cpu(hdr3->info.hdr.back);\r\nto->magic = be16_to_cpu(hdr3->info.hdr.magic);\r\nto->count = be16_to_cpu(hdr3->__count);\r\nto->level = be16_to_cpu(hdr3->__level);\r\nreturn;\r\n}\r\nto->forw = be32_to_cpu(from->hdr.info.forw);\r\nto->back = be32_to_cpu(from->hdr.info.back);\r\nto->magic = be16_to_cpu(from->hdr.info.magic);\r\nto->count = be16_to_cpu(from->hdr.__count);\r\nto->level = be16_to_cpu(from->hdr.__level);\r\n}\r\nvoid\r\nxfs_da3_node_hdr_to_disk(\r\nstruct xfs_da_intnode *to,\r\nstruct xfs_da3_icnode_hdr *from)\r\n{\r\nASSERT(from->magic == XFS_DA_NODE_MAGIC ||\r\nfrom->magic == XFS_DA3_NODE_MAGIC);\r\nif (from->magic == XFS_DA3_NODE_MAGIC) {\r\nstruct xfs_da3_node_hdr *hdr3 = (struct xfs_da3_node_hdr *)to;\r\nhdr3->info.hdr.forw = cpu_to_be32(from->forw);\r\nhdr3->info.hdr.back = cpu_to_be32(from->back);\r\nhdr3->info.hdr.magic = cpu_to_be16(from->magic);\r\nhdr3->__count = cpu_to_be16(from->count);\r\nhdr3->__level = cpu_to_be16(from->level);\r\nreturn;\r\n}\r\nto->hdr.info.forw = cpu_to_be32(from->forw);\r\nto->hdr.info.back = cpu_to_be32(from->back);\r\nto->hdr.info.magic = cpu_to_be16(from->magic);\r\nto->hdr.__count = cpu_to_be16(from->count);\r\nto->hdr.__level = cpu_to_be16(from->level);\r\n}\r\nstatic bool\r\nxfs_da3_node_verify(\r\nstruct xfs_buf *bp)\r\n{\r\nstruct xfs_mount *mp = bp->b_target->bt_mount;\r\nstruct xfs_da_intnode *hdr = bp->b_addr;\r\nstruct xfs_da3_icnode_hdr ichdr;\r\nxfs_da3_node_hdr_from_disk(&ichdr, hdr);\r\nif (xfs_sb_version_hascrc(&mp->m_sb)) {\r\nstruct xfs_da3_node_hdr *hdr3 = bp->b_addr;\r\nif (ichdr.magic != XFS_DA3_NODE_MAGIC)\r\nreturn false;\r\nif (!uuid_equal(&hdr3->info.uuid, &mp->m_sb.sb_uuid))\r\nreturn false;\r\nif (be64_to_cpu(hdr3->info.blkno) != bp->b_bn)\r\nreturn false;\r\n} else {\r\nif (ichdr.magic != XFS_DA_NODE_MAGIC)\r\nreturn false;\r\n}\r\nif (ichdr.level == 0)\r\nreturn false;\r\nif (ichdr.level > XFS_DA_NODE_MAXDEPTH)\r\nreturn false;\r\nif (ichdr.count == 0)\r\nreturn false;\r\nif (ichdr.count > mp->m_dir_node_ents &&\r\nichdr.count > mp->m_attr_node_ents)\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic void\r\nxfs_da3_node_write_verify(\r\nstruct xfs_buf *bp)\r\n{\r\nstruct xfs_mount *mp = bp->b_target->bt_mount;\r\nstruct xfs_buf_log_item *bip = bp->b_fspriv;\r\nstruct xfs_da3_node_hdr *hdr3 = bp->b_addr;\r\nif (!xfs_da3_node_verify(bp)) {\r\nXFS_CORRUPTION_ERROR(__func__, XFS_ERRLEVEL_LOW, mp, bp->b_addr);\r\nxfs_buf_ioerror(bp, EFSCORRUPTED);\r\nreturn;\r\n}\r\nif (!xfs_sb_version_hascrc(&mp->m_sb))\r\nreturn;\r\nif (bip)\r\nhdr3->info.lsn = cpu_to_be64(bip->bli_item.li_lsn);\r\nxfs_update_cksum(bp->b_addr, BBTOB(bp->b_length), XFS_DA3_NODE_CRC_OFF);\r\n}\r\nstatic void\r\nxfs_da3_node_read_verify(\r\nstruct xfs_buf *bp)\r\n{\r\nstruct xfs_mount *mp = bp->b_target->bt_mount;\r\nstruct xfs_da_blkinfo *info = bp->b_addr;\r\nswitch (be16_to_cpu(info->magic)) {\r\ncase XFS_DA3_NODE_MAGIC:\r\nif (!xfs_verify_cksum(bp->b_addr, BBTOB(bp->b_length),\r\nXFS_DA3_NODE_CRC_OFF))\r\nbreak;\r\ncase XFS_DA_NODE_MAGIC:\r\nif (!xfs_da3_node_verify(bp))\r\nbreak;\r\nreturn;\r\ncase XFS_ATTR_LEAF_MAGIC:\r\ncase XFS_ATTR3_LEAF_MAGIC:\r\nbp->b_ops = &xfs_attr3_leaf_buf_ops;\r\nbp->b_ops->verify_read(bp);\r\nreturn;\r\ncase XFS_DIR2_LEAFN_MAGIC:\r\ncase XFS_DIR3_LEAFN_MAGIC:\r\nbp->b_ops = &xfs_dir3_leafn_buf_ops;\r\nbp->b_ops->verify_read(bp);\r\nreturn;\r\ndefault:\r\nbreak;\r\n}\r\nXFS_CORRUPTION_ERROR(__func__, XFS_ERRLEVEL_LOW, mp, bp->b_addr);\r\nxfs_buf_ioerror(bp, EFSCORRUPTED);\r\n}\r\nint\r\nxfs_da3_node_read(\r\nstruct xfs_trans *tp,\r\nstruct xfs_inode *dp,\r\nxfs_dablk_t bno,\r\nxfs_daddr_t mappedbno,\r\nstruct xfs_buf **bpp,\r\nint which_fork)\r\n{\r\nint err;\r\nerr = xfs_da_read_buf(tp, dp, bno, mappedbno, bpp,\r\nwhich_fork, &xfs_da3_node_buf_ops);\r\nif (!err && tp) {\r\nstruct xfs_da_blkinfo *info = (*bpp)->b_addr;\r\nint type;\r\nswitch (be16_to_cpu(info->magic)) {\r\ncase XFS_DA_NODE_MAGIC:\r\ncase XFS_DA3_NODE_MAGIC:\r\ntype = XFS_BLFT_DA_NODE_BUF;\r\nbreak;\r\ncase XFS_ATTR_LEAF_MAGIC:\r\ncase XFS_ATTR3_LEAF_MAGIC:\r\ntype = XFS_BLFT_ATTR_LEAF_BUF;\r\nbreak;\r\ncase XFS_DIR2_LEAFN_MAGIC:\r\ncase XFS_DIR3_LEAFN_MAGIC:\r\ntype = XFS_BLFT_DIR_LEAFN_BUF;\r\nbreak;\r\ndefault:\r\ntype = 0;\r\nASSERT(0);\r\nbreak;\r\n}\r\nxfs_trans_buf_set_type(tp, *bpp, type);\r\n}\r\nreturn err;\r\n}\r\nint\r\nxfs_da3_node_create(\r\nstruct xfs_da_args *args,\r\nxfs_dablk_t blkno,\r\nint level,\r\nstruct xfs_buf **bpp,\r\nint whichfork)\r\n{\r\nstruct xfs_da_intnode *node;\r\nstruct xfs_trans *tp = args->trans;\r\nstruct xfs_mount *mp = tp->t_mountp;\r\nstruct xfs_da3_icnode_hdr ichdr = {0};\r\nstruct xfs_buf *bp;\r\nint error;\r\ntrace_xfs_da_node_create(args);\r\nASSERT(level <= XFS_DA_NODE_MAXDEPTH);\r\nerror = xfs_da_get_buf(tp, args->dp, blkno, -1, &bp, whichfork);\r\nif (error)\r\nreturn(error);\r\nbp->b_ops = &xfs_da3_node_buf_ops;\r\nxfs_trans_buf_set_type(tp, bp, XFS_BLFT_DA_NODE_BUF);\r\nnode = bp->b_addr;\r\nif (xfs_sb_version_hascrc(&mp->m_sb)) {\r\nstruct xfs_da3_node_hdr *hdr3 = bp->b_addr;\r\nichdr.magic = XFS_DA3_NODE_MAGIC;\r\nhdr3->info.blkno = cpu_to_be64(bp->b_bn);\r\nhdr3->info.owner = cpu_to_be64(args->dp->i_ino);\r\nuuid_copy(&hdr3->info.uuid, &mp->m_sb.sb_uuid);\r\n} else {\r\nichdr.magic = XFS_DA_NODE_MAGIC;\r\n}\r\nichdr.level = level;\r\nxfs_da3_node_hdr_to_disk(node, &ichdr);\r\nxfs_trans_log_buf(tp, bp,\r\nXFS_DA_LOGRANGE(node, &node->hdr, xfs_da3_node_hdr_size(node)));\r\n*bpp = bp;\r\nreturn(0);\r\n}\r\nint\r\nxfs_da3_split(\r\nstruct xfs_da_state *state)\r\n{\r\nstruct xfs_da_state_blk *oldblk;\r\nstruct xfs_da_state_blk *newblk;\r\nstruct xfs_da_state_blk *addblk;\r\nstruct xfs_da_intnode *node;\r\nstruct xfs_buf *bp;\r\nint max;\r\nint action;\r\nint error;\r\nint i;\r\ntrace_xfs_da_split(state->args);\r\nmax = state->path.active - 1;\r\nASSERT((max >= 0) && (max < XFS_DA_NODE_MAXDEPTH));\r\nASSERT(state->path.blk[max].magic == XFS_ATTR_LEAF_MAGIC ||\r\nstate->path.blk[max].magic == XFS_DIR2_LEAFN_MAGIC);\r\naddblk = &state->path.blk[max];\r\nfor (i = max; (i >= 0) && addblk; state->path.active--, i--) {\r\noldblk = &state->path.blk[i];\r\nnewblk = &state->altpath.blk[i];\r\nswitch (oldblk->magic) {\r\ncase XFS_ATTR_LEAF_MAGIC:\r\nerror = xfs_attr3_leaf_split(state, oldblk, newblk);\r\nif ((error != 0) && (error != ENOSPC)) {\r\nreturn(error);\r\n}\r\nif (!error) {\r\naddblk = newblk;\r\nbreak;\r\n}\r\nstate->extravalid = 1;\r\nif (state->inleaf) {\r\nstate->extraafter = 0;\r\ntrace_xfs_attr_leaf_split_before(state->args);\r\nerror = xfs_attr3_leaf_split(state, oldblk,\r\n&state->extrablk);\r\n} else {\r\nstate->extraafter = 1;\r\ntrace_xfs_attr_leaf_split_after(state->args);\r\nerror = xfs_attr3_leaf_split(state, newblk,\r\n&state->extrablk);\r\n}\r\nif (error)\r\nreturn(error);\r\naddblk = newblk;\r\nbreak;\r\ncase XFS_DIR2_LEAFN_MAGIC:\r\nerror = xfs_dir2_leafn_split(state, oldblk, newblk);\r\nif (error)\r\nreturn error;\r\naddblk = newblk;\r\nbreak;\r\ncase XFS_DA_NODE_MAGIC:\r\nerror = xfs_da3_node_split(state, oldblk, newblk, addblk,\r\nmax - i, &action);\r\naddblk->bp = NULL;\r\nif (error)\r\nreturn(error);\r\nif (action)\r\naddblk = newblk;\r\nelse\r\naddblk = NULL;\r\nbreak;\r\n}\r\nxfs_da3_fixhashpath(state, &state->path);\r\n}\r\nif (!addblk)\r\nreturn(0);\r\nASSERT(state->path.active == 0);\r\noldblk = &state->path.blk[0];\r\nerror = xfs_da3_root_split(state, oldblk, addblk);\r\nif (error) {\r\naddblk->bp = NULL;\r\nreturn(error);\r\n}\r\nnode = oldblk->bp->b_addr;\r\nif (node->hdr.info.forw) {\r\nif (be32_to_cpu(node->hdr.info.forw) == addblk->blkno) {\r\nbp = addblk->bp;\r\n} else {\r\nASSERT(state->extravalid);\r\nbp = state->extrablk.bp;\r\n}\r\nnode = bp->b_addr;\r\nnode->hdr.info.back = cpu_to_be32(oldblk->blkno);\r\nxfs_trans_log_buf(state->args->trans, bp,\r\nXFS_DA_LOGRANGE(node, &node->hdr.info,\r\nsizeof(node->hdr.info)));\r\n}\r\nnode = oldblk->bp->b_addr;\r\nif (node->hdr.info.back) {\r\nif (be32_to_cpu(node->hdr.info.back) == addblk->blkno) {\r\nbp = addblk->bp;\r\n} else {\r\nASSERT(state->extravalid);\r\nbp = state->extrablk.bp;\r\n}\r\nnode = bp->b_addr;\r\nnode->hdr.info.forw = cpu_to_be32(oldblk->blkno);\r\nxfs_trans_log_buf(state->args->trans, bp,\r\nXFS_DA_LOGRANGE(node, &node->hdr.info,\r\nsizeof(node->hdr.info)));\r\n}\r\naddblk->bp = NULL;\r\nreturn(0);\r\n}\r\nSTATIC int\r\nxfs_da3_root_split(\r\nstruct xfs_da_state *state,\r\nstruct xfs_da_state_blk *blk1,\r\nstruct xfs_da_state_blk *blk2)\r\n{\r\nstruct xfs_da_intnode *node;\r\nstruct xfs_da_intnode *oldroot;\r\nstruct xfs_da_node_entry *btree;\r\nstruct xfs_da3_icnode_hdr nodehdr;\r\nstruct xfs_da_args *args;\r\nstruct xfs_buf *bp;\r\nstruct xfs_inode *dp;\r\nstruct xfs_trans *tp;\r\nstruct xfs_mount *mp;\r\nstruct xfs_dir2_leaf *leaf;\r\nxfs_dablk_t blkno;\r\nint level;\r\nint error;\r\nint size;\r\ntrace_xfs_da_root_split(state->args);\r\nargs = state->args;\r\nerror = xfs_da_grow_inode(args, &blkno);\r\nif (error)\r\nreturn error;\r\ndp = args->dp;\r\ntp = args->trans;\r\nmp = state->mp;\r\nerror = xfs_da_get_buf(tp, dp, blkno, -1, &bp, args->whichfork);\r\nif (error)\r\nreturn error;\r\nnode = bp->b_addr;\r\noldroot = blk1->bp->b_addr;\r\nif (oldroot->hdr.info.magic == cpu_to_be16(XFS_DA_NODE_MAGIC) ||\r\noldroot->hdr.info.magic == cpu_to_be16(XFS_DA3_NODE_MAGIC)) {\r\nstruct xfs_da3_icnode_hdr nodehdr;\r\nxfs_da3_node_hdr_from_disk(&nodehdr, oldroot);\r\nbtree = xfs_da3_node_tree_p(oldroot);\r\nsize = (int)((char *)&btree[nodehdr.count] - (char *)oldroot);\r\nlevel = nodehdr.level;\r\nxfs_trans_buf_set_type(tp, bp, XFS_BLFT_DA_NODE_BUF);\r\n} else {\r\nstruct xfs_dir3_icleaf_hdr leafhdr;\r\nstruct xfs_dir2_leaf_entry *ents;\r\nleaf = (xfs_dir2_leaf_t *)oldroot;\r\nxfs_dir3_leaf_hdr_from_disk(&leafhdr, leaf);\r\nents = xfs_dir3_leaf_ents_p(leaf);\r\nASSERT(leafhdr.magic == XFS_DIR2_LEAFN_MAGIC ||\r\nleafhdr.magic == XFS_DIR3_LEAFN_MAGIC);\r\nsize = (int)((char *)&ents[leafhdr.count] - (char *)leaf);\r\nlevel = 0;\r\nxfs_trans_buf_set_type(tp, bp, XFS_BLFT_DIR_LEAFN_BUF);\r\n}\r\nmemcpy(node, oldroot, size);\r\nif (oldroot->hdr.info.magic == cpu_to_be16(XFS_DA3_NODE_MAGIC) ||\r\noldroot->hdr.info.magic == cpu_to_be16(XFS_DIR3_LEAFN_MAGIC)) {\r\nstruct xfs_da3_intnode *node3 = (struct xfs_da3_intnode *)node;\r\nnode3->hdr.info.blkno = cpu_to_be64(bp->b_bn);\r\n}\r\nxfs_trans_log_buf(tp, bp, 0, size - 1);\r\nbp->b_ops = blk1->bp->b_ops;\r\nblk1->bp = bp;\r\nblk1->blkno = blkno;\r\nerror = xfs_da3_node_create(args,\r\n(args->whichfork == XFS_DATA_FORK) ? mp->m_dirleafblk : 0,\r\nlevel + 1, &bp, args->whichfork);\r\nif (error)\r\nreturn error;\r\nnode = bp->b_addr;\r\nxfs_da3_node_hdr_from_disk(&nodehdr, node);\r\nbtree = xfs_da3_node_tree_p(node);\r\nbtree[0].hashval = cpu_to_be32(blk1->hashval);\r\nbtree[0].before = cpu_to_be32(blk1->blkno);\r\nbtree[1].hashval = cpu_to_be32(blk2->hashval);\r\nbtree[1].before = cpu_to_be32(blk2->blkno);\r\nnodehdr.count = 2;\r\nxfs_da3_node_hdr_to_disk(node, &nodehdr);\r\n#ifdef DEBUG\r\nif (oldroot->hdr.info.magic == cpu_to_be16(XFS_DIR2_LEAFN_MAGIC) ||\r\noldroot->hdr.info.magic == cpu_to_be16(XFS_DIR3_LEAFN_MAGIC)) {\r\nASSERT(blk1->blkno >= mp->m_dirleafblk &&\r\nblk1->blkno < mp->m_dirfreeblk);\r\nASSERT(blk2->blkno >= mp->m_dirleafblk &&\r\nblk2->blkno < mp->m_dirfreeblk);\r\n}\r\n#endif\r\nxfs_trans_log_buf(tp, bp,\r\nXFS_DA_LOGRANGE(node, btree, sizeof(xfs_da_node_entry_t) * 2));\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_da3_node_split(\r\nstruct xfs_da_state *state,\r\nstruct xfs_da_state_blk *oldblk,\r\nstruct xfs_da_state_blk *newblk,\r\nstruct xfs_da_state_blk *addblk,\r\nint treelevel,\r\nint *result)\r\n{\r\nstruct xfs_da_intnode *node;\r\nstruct xfs_da3_icnode_hdr nodehdr;\r\nxfs_dablk_t blkno;\r\nint newcount;\r\nint error;\r\nint useextra;\r\ntrace_xfs_da_node_split(state->args);\r\nnode = oldblk->bp->b_addr;\r\nxfs_da3_node_hdr_from_disk(&nodehdr, node);\r\nuseextra = state->extravalid && state->args->whichfork == XFS_ATTR_FORK;\r\nnewcount = 1 + useextra;\r\nif (nodehdr.count + newcount > state->node_ents) {\r\nerror = xfs_da_grow_inode(state->args, &blkno);\r\nif (error)\r\nreturn(error);\r\nerror = xfs_da3_node_create(state->args, blkno, treelevel,\r\n&newblk->bp, state->args->whichfork);\r\nif (error)\r\nreturn(error);\r\nnewblk->blkno = blkno;\r\nnewblk->magic = XFS_DA_NODE_MAGIC;\r\nxfs_da3_node_rebalance(state, oldblk, newblk);\r\nerror = xfs_da3_blk_link(state, oldblk, newblk);\r\nif (error)\r\nreturn(error);\r\n*result = 1;\r\n} else {\r\n*result = 0;\r\n}\r\nnode = oldblk->bp->b_addr;\r\nxfs_da3_node_hdr_from_disk(&nodehdr, node);\r\nif (oldblk->index <= nodehdr.count) {\r\noldblk->index++;\r\nxfs_da3_node_add(state, oldblk, addblk);\r\nif (useextra) {\r\nif (state->extraafter)\r\noldblk->index++;\r\nxfs_da3_node_add(state, oldblk, &state->extrablk);\r\nstate->extravalid = 0;\r\n}\r\n} else {\r\nnewblk->index++;\r\nxfs_da3_node_add(state, newblk, addblk);\r\nif (useextra) {\r\nif (state->extraafter)\r\nnewblk->index++;\r\nxfs_da3_node_add(state, newblk, &state->extrablk);\r\nstate->extravalid = 0;\r\n}\r\n}\r\nreturn(0);\r\n}\r\nSTATIC void\r\nxfs_da3_node_rebalance(\r\nstruct xfs_da_state *state,\r\nstruct xfs_da_state_blk *blk1,\r\nstruct xfs_da_state_blk *blk2)\r\n{\r\nstruct xfs_da_intnode *node1;\r\nstruct xfs_da_intnode *node2;\r\nstruct xfs_da_intnode *tmpnode;\r\nstruct xfs_da_node_entry *btree1;\r\nstruct xfs_da_node_entry *btree2;\r\nstruct xfs_da_node_entry *btree_s;\r\nstruct xfs_da_node_entry *btree_d;\r\nstruct xfs_da3_icnode_hdr nodehdr1;\r\nstruct xfs_da3_icnode_hdr nodehdr2;\r\nstruct xfs_trans *tp;\r\nint count;\r\nint tmp;\r\nint swap = 0;\r\ntrace_xfs_da_node_rebalance(state->args);\r\nnode1 = blk1->bp->b_addr;\r\nnode2 = blk2->bp->b_addr;\r\nxfs_da3_node_hdr_from_disk(&nodehdr1, node1);\r\nxfs_da3_node_hdr_from_disk(&nodehdr2, node2);\r\nbtree1 = xfs_da3_node_tree_p(node1);\r\nbtree2 = xfs_da3_node_tree_p(node2);\r\nif (nodehdr1.count > 0 && nodehdr2.count > 0 &&\r\n((be32_to_cpu(btree2[0].hashval) < be32_to_cpu(btree1[0].hashval)) ||\r\n(be32_to_cpu(btree2[nodehdr2.count - 1].hashval) <\r\nbe32_to_cpu(btree1[nodehdr1.count - 1].hashval)))) {\r\ntmpnode = node1;\r\nnode1 = node2;\r\nnode2 = tmpnode;\r\nxfs_da3_node_hdr_from_disk(&nodehdr1, node1);\r\nxfs_da3_node_hdr_from_disk(&nodehdr2, node2);\r\nbtree1 = xfs_da3_node_tree_p(node1);\r\nbtree2 = xfs_da3_node_tree_p(node2);\r\nswap = 1;\r\n}\r\ncount = (nodehdr1.count - nodehdr2.count) / 2;\r\nif (count == 0)\r\nreturn;\r\ntp = state->args->trans;\r\nif (count > 0) {\r\ntmp = nodehdr2.count;\r\nif (tmp > 0) {\r\ntmp *= (uint)sizeof(xfs_da_node_entry_t);\r\nbtree_s = &btree2[0];\r\nbtree_d = &btree2[count];\r\nmemmove(btree_d, btree_s, tmp);\r\n}\r\nnodehdr2.count += count;\r\ntmp = count * (uint)sizeof(xfs_da_node_entry_t);\r\nbtree_s = &btree1[nodehdr1.count - count];\r\nbtree_d = &btree2[0];\r\nmemcpy(btree_d, btree_s, tmp);\r\nnodehdr1.count -= count;\r\n} else {\r\ncount = -count;\r\ntmp = count * (uint)sizeof(xfs_da_node_entry_t);\r\nbtree_s = &btree2[0];\r\nbtree_d = &btree1[nodehdr1.count];\r\nmemcpy(btree_d, btree_s, tmp);\r\nnodehdr1.count += count;\r\nxfs_trans_log_buf(tp, blk1->bp,\r\nXFS_DA_LOGRANGE(node1, btree_d, tmp));\r\ntmp = nodehdr2.count - count;\r\ntmp *= (uint)sizeof(xfs_da_node_entry_t);\r\nbtree_s = &btree2[count];\r\nbtree_d = &btree2[0];\r\nmemmove(btree_d, btree_s, tmp);\r\nnodehdr2.count -= count;\r\n}\r\nxfs_da3_node_hdr_to_disk(node1, &nodehdr1);\r\nxfs_trans_log_buf(tp, blk1->bp,\r\nXFS_DA_LOGRANGE(node1, &node1->hdr,\r\nxfs_da3_node_hdr_size(node1)));\r\nxfs_da3_node_hdr_to_disk(node2, &nodehdr2);\r\nxfs_trans_log_buf(tp, blk2->bp,\r\nXFS_DA_LOGRANGE(node2, &node2->hdr,\r\nxfs_da3_node_hdr_size(node2) +\r\n(sizeof(btree2[0]) * nodehdr2.count)));\r\nif (swap) {\r\nnode1 = blk1->bp->b_addr;\r\nnode2 = blk2->bp->b_addr;\r\nxfs_da3_node_hdr_from_disk(&nodehdr1, node1);\r\nxfs_da3_node_hdr_from_disk(&nodehdr2, node2);\r\nbtree1 = xfs_da3_node_tree_p(node1);\r\nbtree2 = xfs_da3_node_tree_p(node2);\r\n}\r\nblk1->hashval = be32_to_cpu(btree1[nodehdr1.count - 1].hashval);\r\nblk2->hashval = be32_to_cpu(btree2[nodehdr2.count - 1].hashval);\r\nif (blk1->index >= nodehdr1.count) {\r\nblk2->index = blk1->index - nodehdr1.count;\r\nblk1->index = nodehdr1.count + 1;\r\n}\r\n}\r\nSTATIC void\r\nxfs_da3_node_add(\r\nstruct xfs_da_state *state,\r\nstruct xfs_da_state_blk *oldblk,\r\nstruct xfs_da_state_blk *newblk)\r\n{\r\nstruct xfs_da_intnode *node;\r\nstruct xfs_da3_icnode_hdr nodehdr;\r\nstruct xfs_da_node_entry *btree;\r\nint tmp;\r\ntrace_xfs_da_node_add(state->args);\r\nnode = oldblk->bp->b_addr;\r\nxfs_da3_node_hdr_from_disk(&nodehdr, node);\r\nbtree = xfs_da3_node_tree_p(node);\r\nASSERT(oldblk->index >= 0 && oldblk->index <= nodehdr.count);\r\nASSERT(newblk->blkno != 0);\r\nif (state->args->whichfork == XFS_DATA_FORK)\r\nASSERT(newblk->blkno >= state->mp->m_dirleafblk &&\r\nnewblk->blkno < state->mp->m_dirfreeblk);\r\ntmp = 0;\r\nif (oldblk->index < nodehdr.count) {\r\ntmp = (nodehdr.count - oldblk->index) * (uint)sizeof(*btree);\r\nmemmove(&btree[oldblk->index + 1], &btree[oldblk->index], tmp);\r\n}\r\nbtree[oldblk->index].hashval = cpu_to_be32(newblk->hashval);\r\nbtree[oldblk->index].before = cpu_to_be32(newblk->blkno);\r\nxfs_trans_log_buf(state->args->trans, oldblk->bp,\r\nXFS_DA_LOGRANGE(node, &btree[oldblk->index],\r\ntmp + sizeof(*btree)));\r\nnodehdr.count += 1;\r\nxfs_da3_node_hdr_to_disk(node, &nodehdr);\r\nxfs_trans_log_buf(state->args->trans, oldblk->bp,\r\nXFS_DA_LOGRANGE(node, &node->hdr, xfs_da3_node_hdr_size(node)));\r\noldblk->hashval = be32_to_cpu(btree[nodehdr.count - 1].hashval);\r\n}\r\nint\r\nxfs_da3_join(\r\nstruct xfs_da_state *state)\r\n{\r\nstruct xfs_da_state_blk *drop_blk;\r\nstruct xfs_da_state_blk *save_blk;\r\nint action = 0;\r\nint error;\r\ntrace_xfs_da_join(state->args);\r\ndrop_blk = &state->path.blk[ state->path.active-1 ];\r\nsave_blk = &state->altpath.blk[ state->path.active-1 ];\r\nASSERT(state->path.blk[0].magic == XFS_DA_NODE_MAGIC);\r\nASSERT(drop_blk->magic == XFS_ATTR_LEAF_MAGIC ||\r\ndrop_blk->magic == XFS_DIR2_LEAFN_MAGIC);\r\nfor ( ; state->path.active >= 2; drop_blk--, save_blk--,\r\nstate->path.active--) {\r\nswitch (drop_blk->magic) {\r\ncase XFS_ATTR_LEAF_MAGIC:\r\nerror = xfs_attr3_leaf_toosmall(state, &action);\r\nif (error)\r\nreturn(error);\r\nif (action == 0)\r\nreturn(0);\r\nxfs_attr3_leaf_unbalance(state, drop_blk, save_blk);\r\nbreak;\r\ncase XFS_DIR2_LEAFN_MAGIC:\r\nerror = xfs_dir2_leafn_toosmall(state, &action);\r\nif (error)\r\nreturn error;\r\nif (action == 0)\r\nreturn 0;\r\nxfs_dir2_leafn_unbalance(state, drop_blk, save_blk);\r\nbreak;\r\ncase XFS_DA_NODE_MAGIC:\r\nxfs_da3_node_remove(state, drop_blk);\r\nxfs_da3_fixhashpath(state, &state->path);\r\nerror = xfs_da3_node_toosmall(state, &action);\r\nif (error)\r\nreturn(error);\r\nif (action == 0)\r\nreturn 0;\r\nxfs_da3_node_unbalance(state, drop_blk, save_blk);\r\nbreak;\r\n}\r\nxfs_da3_fixhashpath(state, &state->altpath);\r\nerror = xfs_da3_blk_unlink(state, drop_blk, save_blk);\r\nxfs_da_state_kill_altpath(state);\r\nif (error)\r\nreturn(error);\r\nerror = xfs_da_shrink_inode(state->args, drop_blk->blkno,\r\ndrop_blk->bp);\r\ndrop_blk->bp = NULL;\r\nif (error)\r\nreturn(error);\r\n}\r\nxfs_da3_node_remove(state, drop_blk);\r\nxfs_da3_fixhashpath(state, &state->path);\r\nerror = xfs_da3_root_join(state, &state->path.blk[0]);\r\nreturn(error);\r\n}\r\nstatic void\r\nxfs_da_blkinfo_onlychild_validate(struct xfs_da_blkinfo *blkinfo, __u16 level)\r\n{\r\n__be16 magic = blkinfo->magic;\r\nif (level == 1) {\r\nASSERT(magic == cpu_to_be16(XFS_DIR2_LEAFN_MAGIC) ||\r\nmagic == cpu_to_be16(XFS_DIR3_LEAFN_MAGIC) ||\r\nmagic == cpu_to_be16(XFS_ATTR_LEAF_MAGIC) ||\r\nmagic == cpu_to_be16(XFS_ATTR3_LEAF_MAGIC));\r\n} else {\r\nASSERT(magic == cpu_to_be16(XFS_DA_NODE_MAGIC) ||\r\nmagic == cpu_to_be16(XFS_DA3_NODE_MAGIC));\r\n}\r\nASSERT(!blkinfo->forw);\r\nASSERT(!blkinfo->back);\r\n}\r\nSTATIC int\r\nxfs_da3_root_join(\r\nstruct xfs_da_state *state,\r\nstruct xfs_da_state_blk *root_blk)\r\n{\r\nstruct xfs_da_intnode *oldroot;\r\nstruct xfs_da_args *args;\r\nxfs_dablk_t child;\r\nstruct xfs_buf *bp;\r\nstruct xfs_da3_icnode_hdr oldroothdr;\r\nstruct xfs_da_node_entry *btree;\r\nint error;\r\ntrace_xfs_da_root_join(state->args);\r\nASSERT(root_blk->magic == XFS_DA_NODE_MAGIC);\r\nargs = state->args;\r\noldroot = root_blk->bp->b_addr;\r\nxfs_da3_node_hdr_from_disk(&oldroothdr, oldroot);\r\nASSERT(oldroothdr.forw == 0);\r\nASSERT(oldroothdr.back == 0);\r\nif (oldroothdr.count > 1)\r\nreturn 0;\r\nbtree = xfs_da3_node_tree_p(oldroot);\r\nchild = be32_to_cpu(btree[0].before);\r\nASSERT(child != 0);\r\nerror = xfs_da3_node_read(args->trans, args->dp, child, -1, &bp,\r\nargs->whichfork);\r\nif (error)\r\nreturn error;\r\nxfs_da_blkinfo_onlychild_validate(bp->b_addr, oldroothdr.level);\r\nmemcpy(root_blk->bp->b_addr, bp->b_addr, state->blocksize);\r\nroot_blk->bp->b_ops = bp->b_ops;\r\nxfs_trans_buf_copy_type(root_blk->bp, bp);\r\nif (oldroothdr.magic == XFS_DA3_NODE_MAGIC) {\r\nstruct xfs_da3_blkinfo *da3 = root_blk->bp->b_addr;\r\nda3->blkno = cpu_to_be64(root_blk->bp->b_bn);\r\n}\r\nxfs_trans_log_buf(args->trans, root_blk->bp, 0, state->blocksize - 1);\r\nerror = xfs_da_shrink_inode(args, child, bp);\r\nreturn(error);\r\n}\r\nSTATIC int\r\nxfs_da3_node_toosmall(\r\nstruct xfs_da_state *state,\r\nint *action)\r\n{\r\nstruct xfs_da_intnode *node;\r\nstruct xfs_da_state_blk *blk;\r\nstruct xfs_da_blkinfo *info;\r\nxfs_dablk_t blkno;\r\nstruct xfs_buf *bp;\r\nstruct xfs_da3_icnode_hdr nodehdr;\r\nint count;\r\nint forward;\r\nint error;\r\nint retval;\r\nint i;\r\ntrace_xfs_da_node_toosmall(state->args);\r\nblk = &state->path.blk[ state->path.active-1 ];\r\ninfo = blk->bp->b_addr;\r\nnode = (xfs_da_intnode_t *)info;\r\nxfs_da3_node_hdr_from_disk(&nodehdr, node);\r\nif (nodehdr.count > (state->node_ents >> 1)) {\r\n*action = 0;\r\nreturn(0);\r\n}\r\nif (nodehdr.count == 0) {\r\nforward = (info->forw != 0);\r\nmemcpy(&state->altpath, &state->path, sizeof(state->path));\r\nerror = xfs_da3_path_shift(state, &state->altpath, forward,\r\n0, &retval);\r\nif (error)\r\nreturn(error);\r\nif (retval) {\r\n*action = 0;\r\n} else {\r\n*action = 2;\r\n}\r\nreturn(0);\r\n}\r\ncount = state->node_ents;\r\ncount -= state->node_ents >> 2;\r\ncount -= nodehdr.count;\r\nforward = nodehdr.forw < nodehdr.back;\r\nfor (i = 0; i < 2; forward = !forward, i++) {\r\nif (forward)\r\nblkno = nodehdr.forw;\r\nelse\r\nblkno = nodehdr.back;\r\nif (blkno == 0)\r\ncontinue;\r\nerror = xfs_da3_node_read(state->args->trans, state->args->dp,\r\nblkno, -1, &bp, state->args->whichfork);\r\nif (error)\r\nreturn(error);\r\nnode = bp->b_addr;\r\nxfs_da3_node_hdr_from_disk(&nodehdr, node);\r\nxfs_trans_brelse(state->args->trans, bp);\r\nif (count - nodehdr.count >= 0)\r\nbreak;\r\n}\r\nif (i >= 2) {\r\n*action = 0;\r\nreturn 0;\r\n}\r\nmemcpy(&state->altpath, &state->path, sizeof(state->path));\r\nif (blkno < blk->blkno) {\r\nerror = xfs_da3_path_shift(state, &state->altpath, forward,\r\n0, &retval);\r\n} else {\r\nerror = xfs_da3_path_shift(state, &state->path, forward,\r\n0, &retval);\r\n}\r\nif (error)\r\nreturn error;\r\nif (retval) {\r\n*action = 0;\r\nreturn 0;\r\n}\r\n*action = 1;\r\nreturn 0;\r\n}\r\nSTATIC uint\r\nxfs_da3_node_lasthash(\r\nstruct xfs_buf *bp,\r\nint *count)\r\n{\r\nstruct xfs_da_intnode *node;\r\nstruct xfs_da_node_entry *btree;\r\nstruct xfs_da3_icnode_hdr nodehdr;\r\nnode = bp->b_addr;\r\nxfs_da3_node_hdr_from_disk(&nodehdr, node);\r\nif (count)\r\n*count = nodehdr.count;\r\nif (!nodehdr.count)\r\nreturn 0;\r\nbtree = xfs_da3_node_tree_p(node);\r\nreturn be32_to_cpu(btree[nodehdr.count - 1].hashval);\r\n}\r\nvoid\r\nxfs_da3_fixhashpath(\r\nstruct xfs_da_state *state,\r\nstruct xfs_da_state_path *path)\r\n{\r\nstruct xfs_da_state_blk *blk;\r\nstruct xfs_da_intnode *node;\r\nstruct xfs_da_node_entry *btree;\r\nxfs_dahash_t lasthash=0;\r\nint level;\r\nint count;\r\ntrace_xfs_da_fixhashpath(state->args);\r\nlevel = path->active-1;\r\nblk = &path->blk[ level ];\r\nswitch (blk->magic) {\r\ncase XFS_ATTR_LEAF_MAGIC:\r\nlasthash = xfs_attr_leaf_lasthash(blk->bp, &count);\r\nif (count == 0)\r\nreturn;\r\nbreak;\r\ncase XFS_DIR2_LEAFN_MAGIC:\r\nlasthash = xfs_dir2_leafn_lasthash(blk->bp, &count);\r\nif (count == 0)\r\nreturn;\r\nbreak;\r\ncase XFS_DA_NODE_MAGIC:\r\nlasthash = xfs_da3_node_lasthash(blk->bp, &count);\r\nif (count == 0)\r\nreturn;\r\nbreak;\r\n}\r\nfor (blk--, level--; level >= 0; blk--, level--) {\r\nstruct xfs_da3_icnode_hdr nodehdr;\r\nnode = blk->bp->b_addr;\r\nxfs_da3_node_hdr_from_disk(&nodehdr, node);\r\nbtree = xfs_da3_node_tree_p(node);\r\nif (be32_to_cpu(btree->hashval) == lasthash)\r\nbreak;\r\nblk->hashval = lasthash;\r\nbtree[blk->index].hashval = cpu_to_be32(lasthash);\r\nxfs_trans_log_buf(state->args->trans, blk->bp,\r\nXFS_DA_LOGRANGE(node, &btree[blk->index],\r\nsizeof(*btree)));\r\nlasthash = be32_to_cpu(btree[nodehdr.count - 1].hashval);\r\n}\r\n}\r\nSTATIC void\r\nxfs_da3_node_remove(\r\nstruct xfs_da_state *state,\r\nstruct xfs_da_state_blk *drop_blk)\r\n{\r\nstruct xfs_da_intnode *node;\r\nstruct xfs_da3_icnode_hdr nodehdr;\r\nstruct xfs_da_node_entry *btree;\r\nint index;\r\nint tmp;\r\ntrace_xfs_da_node_remove(state->args);\r\nnode = drop_blk->bp->b_addr;\r\nxfs_da3_node_hdr_from_disk(&nodehdr, node);\r\nASSERT(drop_blk->index < nodehdr.count);\r\nASSERT(drop_blk->index >= 0);\r\nindex = drop_blk->index;\r\nbtree = xfs_da3_node_tree_p(node);\r\nif (index < nodehdr.count - 1) {\r\ntmp = nodehdr.count - index - 1;\r\ntmp *= (uint)sizeof(xfs_da_node_entry_t);\r\nmemmove(&btree[index], &btree[index + 1], tmp);\r\nxfs_trans_log_buf(state->args->trans, drop_blk->bp,\r\nXFS_DA_LOGRANGE(node, &btree[index], tmp));\r\nindex = nodehdr.count - 1;\r\n}\r\nmemset(&btree[index], 0, sizeof(xfs_da_node_entry_t));\r\nxfs_trans_log_buf(state->args->trans, drop_blk->bp,\r\nXFS_DA_LOGRANGE(node, &btree[index], sizeof(btree[index])));\r\nnodehdr.count -= 1;\r\nxfs_da3_node_hdr_to_disk(node, &nodehdr);\r\nxfs_trans_log_buf(state->args->trans, drop_blk->bp,\r\nXFS_DA_LOGRANGE(node, &node->hdr, xfs_da3_node_hdr_size(node)));\r\ndrop_blk->hashval = be32_to_cpu(btree[index - 1].hashval);\r\n}\r\nSTATIC void\r\nxfs_da3_node_unbalance(\r\nstruct xfs_da_state *state,\r\nstruct xfs_da_state_blk *drop_blk,\r\nstruct xfs_da_state_blk *save_blk)\r\n{\r\nstruct xfs_da_intnode *drop_node;\r\nstruct xfs_da_intnode *save_node;\r\nstruct xfs_da_node_entry *drop_btree;\r\nstruct xfs_da_node_entry *save_btree;\r\nstruct xfs_da3_icnode_hdr drop_hdr;\r\nstruct xfs_da3_icnode_hdr save_hdr;\r\nstruct xfs_trans *tp;\r\nint sindex;\r\nint tmp;\r\ntrace_xfs_da_node_unbalance(state->args);\r\ndrop_node = drop_blk->bp->b_addr;\r\nsave_node = save_blk->bp->b_addr;\r\nxfs_da3_node_hdr_from_disk(&drop_hdr, drop_node);\r\nxfs_da3_node_hdr_from_disk(&save_hdr, save_node);\r\ndrop_btree = xfs_da3_node_tree_p(drop_node);\r\nsave_btree = xfs_da3_node_tree_p(save_node);\r\ntp = state->args->trans;\r\nif ((be32_to_cpu(drop_btree[0].hashval) <\r\nbe32_to_cpu(save_btree[0].hashval)) ||\r\n(be32_to_cpu(drop_btree[drop_hdr.count - 1].hashval) <\r\nbe32_to_cpu(save_btree[save_hdr.count - 1].hashval))) {\r\ntmp = save_hdr.count * sizeof(xfs_da_node_entry_t);\r\nmemmove(&save_btree[drop_hdr.count], &save_btree[0], tmp);\r\nsindex = 0;\r\nxfs_trans_log_buf(tp, save_blk->bp,\r\nXFS_DA_LOGRANGE(save_node, &save_btree[0],\r\n(save_hdr.count + drop_hdr.count) *\r\nsizeof(xfs_da_node_entry_t)));\r\n} else {\r\nsindex = save_hdr.count;\r\nxfs_trans_log_buf(tp, save_blk->bp,\r\nXFS_DA_LOGRANGE(save_node, &save_btree[sindex],\r\ndrop_hdr.count * sizeof(xfs_da_node_entry_t)));\r\n}\r\ntmp = drop_hdr.count * (uint)sizeof(xfs_da_node_entry_t);\r\nmemcpy(&save_btree[sindex], &drop_btree[0], tmp);\r\nsave_hdr.count += drop_hdr.count;\r\nxfs_da3_node_hdr_to_disk(save_node, &save_hdr);\r\nxfs_trans_log_buf(tp, save_blk->bp,\r\nXFS_DA_LOGRANGE(save_node, &save_node->hdr,\r\nxfs_da3_node_hdr_size(save_node)));\r\nsave_blk->hashval = be32_to_cpu(save_btree[save_hdr.count - 1].hashval);\r\n}\r\nint\r\nxfs_da3_node_lookup_int(\r\nstruct xfs_da_state *state,\r\nint *result)\r\n{\r\nstruct xfs_da_state_blk *blk;\r\nstruct xfs_da_blkinfo *curr;\r\nstruct xfs_da_intnode *node;\r\nstruct xfs_da_node_entry *btree;\r\nstruct xfs_da3_icnode_hdr nodehdr;\r\nstruct xfs_da_args *args;\r\nxfs_dablk_t blkno;\r\nxfs_dahash_t hashval;\r\nxfs_dahash_t btreehashval;\r\nint probe;\r\nint span;\r\nint max;\r\nint error;\r\nint retval;\r\nargs = state->args;\r\nblkno = (args->whichfork == XFS_DATA_FORK)? state->mp->m_dirleafblk : 0;\r\nfor (blk = &state->path.blk[0], state->path.active = 1;\r\nstate->path.active <= XFS_DA_NODE_MAXDEPTH;\r\nblk++, state->path.active++) {\r\nblk->blkno = blkno;\r\nerror = xfs_da3_node_read(args->trans, args->dp, blkno,\r\n-1, &blk->bp, args->whichfork);\r\nif (error) {\r\nblk->blkno = 0;\r\nstate->path.active--;\r\nreturn(error);\r\n}\r\ncurr = blk->bp->b_addr;\r\nblk->magic = be16_to_cpu(curr->magic);\r\nif (blk->magic == XFS_ATTR_LEAF_MAGIC ||\r\nblk->magic == XFS_ATTR3_LEAF_MAGIC) {\r\nblk->magic = XFS_ATTR_LEAF_MAGIC;\r\nblk->hashval = xfs_attr_leaf_lasthash(blk->bp, NULL);\r\nbreak;\r\n}\r\nif (blk->magic == XFS_DIR2_LEAFN_MAGIC ||\r\nblk->magic == XFS_DIR3_LEAFN_MAGIC) {\r\nblk->magic = XFS_DIR2_LEAFN_MAGIC;\r\nblk->hashval = xfs_dir2_leafn_lasthash(blk->bp, NULL);\r\nbreak;\r\n}\r\nblk->magic = XFS_DA_NODE_MAGIC;\r\nnode = blk->bp->b_addr;\r\nxfs_da3_node_hdr_from_disk(&nodehdr, node);\r\nbtree = xfs_da3_node_tree_p(node);\r\nmax = nodehdr.count;\r\nblk->hashval = be32_to_cpu(btree[max - 1].hashval);\r\nprobe = span = max / 2;\r\nhashval = args->hashval;\r\nwhile (span > 4) {\r\nspan /= 2;\r\nbtreehashval = be32_to_cpu(btree[probe].hashval);\r\nif (btreehashval < hashval)\r\nprobe += span;\r\nelse if (btreehashval > hashval)\r\nprobe -= span;\r\nelse\r\nbreak;\r\n}\r\nASSERT((probe >= 0) && (probe < max));\r\nASSERT((span <= 4) ||\r\n(be32_to_cpu(btree[probe].hashval) == hashval));\r\nwhile (probe > 0 &&\r\nbe32_to_cpu(btree[probe].hashval) >= hashval) {\r\nprobe--;\r\n}\r\nwhile (probe < max &&\r\nbe32_to_cpu(btree[probe].hashval) < hashval) {\r\nprobe++;\r\n}\r\nif (probe == max) {\r\nblk->index = max - 1;\r\nblkno = be32_to_cpu(btree[max - 1].before);\r\n} else {\r\nblk->index = probe;\r\nblkno = be32_to_cpu(btree[probe].before);\r\n}\r\n}\r\nfor (;;) {\r\nif (blk->magic == XFS_DIR2_LEAFN_MAGIC) {\r\nretval = xfs_dir2_leafn_lookup_int(blk->bp, args,\r\n&blk->index, state);\r\n} else if (blk->magic == XFS_ATTR_LEAF_MAGIC) {\r\nretval = xfs_attr3_leaf_lookup_int(blk->bp, args);\r\nblk->index = args->index;\r\nargs->blkno = blk->blkno;\r\n} else {\r\nASSERT(0);\r\nreturn XFS_ERROR(EFSCORRUPTED);\r\n}\r\nif (((retval == ENOENT) || (retval == ENOATTR)) &&\r\n(blk->hashval == args->hashval)) {\r\nerror = xfs_da3_path_shift(state, &state->path, 1, 1,\r\n&retval);\r\nif (error)\r\nreturn(error);\r\nif (retval == 0) {\r\ncontinue;\r\n} else if (blk->magic == XFS_ATTR_LEAF_MAGIC) {\r\nretval = XFS_ERROR(ENOATTR);\r\n}\r\n}\r\nbreak;\r\n}\r\n*result = retval;\r\nreturn(0);\r\n}\r\nSTATIC int\r\nxfs_da3_node_order(\r\nstruct xfs_buf *node1_bp,\r\nstruct xfs_buf *node2_bp)\r\n{\r\nstruct xfs_da_intnode *node1;\r\nstruct xfs_da_intnode *node2;\r\nstruct xfs_da_node_entry *btree1;\r\nstruct xfs_da_node_entry *btree2;\r\nstruct xfs_da3_icnode_hdr node1hdr;\r\nstruct xfs_da3_icnode_hdr node2hdr;\r\nnode1 = node1_bp->b_addr;\r\nnode2 = node2_bp->b_addr;\r\nxfs_da3_node_hdr_from_disk(&node1hdr, node1);\r\nxfs_da3_node_hdr_from_disk(&node2hdr, node2);\r\nbtree1 = xfs_da3_node_tree_p(node1);\r\nbtree2 = xfs_da3_node_tree_p(node2);\r\nif (node1hdr.count > 0 && node2hdr.count > 0 &&\r\n((be32_to_cpu(btree2[0].hashval) < be32_to_cpu(btree1[0].hashval)) ||\r\n(be32_to_cpu(btree2[node2hdr.count - 1].hashval) <\r\nbe32_to_cpu(btree1[node1hdr.count - 1].hashval)))) {\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nint\r\nxfs_da3_blk_link(\r\nstruct xfs_da_state *state,\r\nstruct xfs_da_state_blk *old_blk,\r\nstruct xfs_da_state_blk *new_blk)\r\n{\r\nstruct xfs_da_blkinfo *old_info;\r\nstruct xfs_da_blkinfo *new_info;\r\nstruct xfs_da_blkinfo *tmp_info;\r\nstruct xfs_da_args *args;\r\nstruct xfs_buf *bp;\r\nint before = 0;\r\nint error;\r\nargs = state->args;\r\nASSERT(args != NULL);\r\nold_info = old_blk->bp->b_addr;\r\nnew_info = new_blk->bp->b_addr;\r\nASSERT(old_blk->magic == XFS_DA_NODE_MAGIC ||\r\nold_blk->magic == XFS_DIR2_LEAFN_MAGIC ||\r\nold_blk->magic == XFS_ATTR_LEAF_MAGIC);\r\nswitch (old_blk->magic) {\r\ncase XFS_ATTR_LEAF_MAGIC:\r\nbefore = xfs_attr_leaf_order(old_blk->bp, new_blk->bp);\r\nbreak;\r\ncase XFS_DIR2_LEAFN_MAGIC:\r\nbefore = xfs_dir2_leafn_order(old_blk->bp, new_blk->bp);\r\nbreak;\r\ncase XFS_DA_NODE_MAGIC:\r\nbefore = xfs_da3_node_order(old_blk->bp, new_blk->bp);\r\nbreak;\r\n}\r\nif (before) {\r\ntrace_xfs_da_link_before(args);\r\nnew_info->forw = cpu_to_be32(old_blk->blkno);\r\nnew_info->back = old_info->back;\r\nif (old_info->back) {\r\nerror = xfs_da3_node_read(args->trans, args->dp,\r\nbe32_to_cpu(old_info->back),\r\n-1, &bp, args->whichfork);\r\nif (error)\r\nreturn(error);\r\nASSERT(bp != NULL);\r\ntmp_info = bp->b_addr;\r\nASSERT(tmp_info->magic == old_info->magic);\r\nASSERT(be32_to_cpu(tmp_info->forw) == old_blk->blkno);\r\ntmp_info->forw = cpu_to_be32(new_blk->blkno);\r\nxfs_trans_log_buf(args->trans, bp, 0, sizeof(*tmp_info)-1);\r\n}\r\nold_info->back = cpu_to_be32(new_blk->blkno);\r\n} else {\r\ntrace_xfs_da_link_after(args);\r\nnew_info->forw = old_info->forw;\r\nnew_info->back = cpu_to_be32(old_blk->blkno);\r\nif (old_info->forw) {\r\nerror = xfs_da3_node_read(args->trans, args->dp,\r\nbe32_to_cpu(old_info->forw),\r\n-1, &bp, args->whichfork);\r\nif (error)\r\nreturn(error);\r\nASSERT(bp != NULL);\r\ntmp_info = bp->b_addr;\r\nASSERT(tmp_info->magic == old_info->magic);\r\nASSERT(be32_to_cpu(tmp_info->back) == old_blk->blkno);\r\ntmp_info->back = cpu_to_be32(new_blk->blkno);\r\nxfs_trans_log_buf(args->trans, bp, 0, sizeof(*tmp_info)-1);\r\n}\r\nold_info->forw = cpu_to_be32(new_blk->blkno);\r\n}\r\nxfs_trans_log_buf(args->trans, old_blk->bp, 0, sizeof(*tmp_info) - 1);\r\nxfs_trans_log_buf(args->trans, new_blk->bp, 0, sizeof(*tmp_info) - 1);\r\nreturn(0);\r\n}\r\nSTATIC int\r\nxfs_da3_blk_unlink(\r\nstruct xfs_da_state *state,\r\nstruct xfs_da_state_blk *drop_blk,\r\nstruct xfs_da_state_blk *save_blk)\r\n{\r\nstruct xfs_da_blkinfo *drop_info;\r\nstruct xfs_da_blkinfo *save_info;\r\nstruct xfs_da_blkinfo *tmp_info;\r\nstruct xfs_da_args *args;\r\nstruct xfs_buf *bp;\r\nint error;\r\nargs = state->args;\r\nASSERT(args != NULL);\r\nsave_info = save_blk->bp->b_addr;\r\ndrop_info = drop_blk->bp->b_addr;\r\nASSERT(save_blk->magic == XFS_DA_NODE_MAGIC ||\r\nsave_blk->magic == XFS_DIR2_LEAFN_MAGIC ||\r\nsave_blk->magic == XFS_ATTR_LEAF_MAGIC);\r\nASSERT(save_blk->magic == drop_blk->magic);\r\nASSERT((be32_to_cpu(save_info->forw) == drop_blk->blkno) ||\r\n(be32_to_cpu(save_info->back) == drop_blk->blkno));\r\nASSERT((be32_to_cpu(drop_info->forw) == save_blk->blkno) ||\r\n(be32_to_cpu(drop_info->back) == save_blk->blkno));\r\nif (be32_to_cpu(save_info->back) == drop_blk->blkno) {\r\ntrace_xfs_da_unlink_back(args);\r\nsave_info->back = drop_info->back;\r\nif (drop_info->back) {\r\nerror = xfs_da3_node_read(args->trans, args->dp,\r\nbe32_to_cpu(drop_info->back),\r\n-1, &bp, args->whichfork);\r\nif (error)\r\nreturn(error);\r\nASSERT(bp != NULL);\r\ntmp_info = bp->b_addr;\r\nASSERT(tmp_info->magic == save_info->magic);\r\nASSERT(be32_to_cpu(tmp_info->forw) == drop_blk->blkno);\r\ntmp_info->forw = cpu_to_be32(save_blk->blkno);\r\nxfs_trans_log_buf(args->trans, bp, 0,\r\nsizeof(*tmp_info) - 1);\r\n}\r\n} else {\r\ntrace_xfs_da_unlink_forward(args);\r\nsave_info->forw = drop_info->forw;\r\nif (drop_info->forw) {\r\nerror = xfs_da3_node_read(args->trans, args->dp,\r\nbe32_to_cpu(drop_info->forw),\r\n-1, &bp, args->whichfork);\r\nif (error)\r\nreturn(error);\r\nASSERT(bp != NULL);\r\ntmp_info = bp->b_addr;\r\nASSERT(tmp_info->magic == save_info->magic);\r\nASSERT(be32_to_cpu(tmp_info->back) == drop_blk->blkno);\r\ntmp_info->back = cpu_to_be32(save_blk->blkno);\r\nxfs_trans_log_buf(args->trans, bp, 0,\r\nsizeof(*tmp_info) - 1);\r\n}\r\n}\r\nxfs_trans_log_buf(args->trans, save_blk->bp, 0, sizeof(*save_info) - 1);\r\nreturn(0);\r\n}\r\nint\r\nxfs_da3_path_shift(\r\nstruct xfs_da_state *state,\r\nstruct xfs_da_state_path *path,\r\nint forward,\r\nint release,\r\nint *result)\r\n{\r\nstruct xfs_da_state_blk *blk;\r\nstruct xfs_da_blkinfo *info;\r\nstruct xfs_da_intnode *node;\r\nstruct xfs_da_args *args;\r\nstruct xfs_da_node_entry *btree;\r\nstruct xfs_da3_icnode_hdr nodehdr;\r\nxfs_dablk_t blkno = 0;\r\nint level;\r\nint error;\r\ntrace_xfs_da_path_shift(state->args);\r\nargs = state->args;\r\nASSERT(args != NULL);\r\nASSERT(path != NULL);\r\nASSERT((path->active > 0) && (path->active < XFS_DA_NODE_MAXDEPTH));\r\nlevel = (path->active-1) - 1;\r\nfor (blk = &path->blk[level]; level >= 0; blk--, level--) {\r\nnode = blk->bp->b_addr;\r\nxfs_da3_node_hdr_from_disk(&nodehdr, node);\r\nbtree = xfs_da3_node_tree_p(node);\r\nif (forward && (blk->index < nodehdr.count - 1)) {\r\nblk->index++;\r\nblkno = be32_to_cpu(btree[blk->index].before);\r\nbreak;\r\n} else if (!forward && (blk->index > 0)) {\r\nblk->index--;\r\nblkno = be32_to_cpu(btree[blk->index].before);\r\nbreak;\r\n}\r\n}\r\nif (level < 0) {\r\n*result = XFS_ERROR(ENOENT);\r\nASSERT(args->op_flags & XFS_DA_OP_OKNOENT);\r\nreturn(0);\r\n}\r\nfor (blk++, level++; level < path->active; blk++, level++) {\r\nif (release)\r\nxfs_trans_brelse(args->trans, blk->bp);\r\nblk->blkno = blkno;\r\nerror = xfs_da3_node_read(args->trans, args->dp, blkno, -1,\r\n&blk->bp, args->whichfork);\r\nif (error)\r\nreturn(error);\r\ninfo = blk->bp->b_addr;\r\nASSERT(info->magic == cpu_to_be16(XFS_DA_NODE_MAGIC) ||\r\ninfo->magic == cpu_to_be16(XFS_DA3_NODE_MAGIC) ||\r\ninfo->magic == cpu_to_be16(XFS_DIR2_LEAFN_MAGIC) ||\r\ninfo->magic == cpu_to_be16(XFS_DIR3_LEAFN_MAGIC) ||\r\ninfo->magic == cpu_to_be16(XFS_ATTR_LEAF_MAGIC) ||\r\ninfo->magic == cpu_to_be16(XFS_ATTR3_LEAF_MAGIC));\r\nswitch (be16_to_cpu(info->magic)) {\r\ncase XFS_DA_NODE_MAGIC:\r\ncase XFS_DA3_NODE_MAGIC:\r\nblk->magic = XFS_DA_NODE_MAGIC;\r\nnode = (xfs_da_intnode_t *)info;\r\nxfs_da3_node_hdr_from_disk(&nodehdr, node);\r\nbtree = xfs_da3_node_tree_p(node);\r\nblk->hashval = be32_to_cpu(btree[nodehdr.count - 1].hashval);\r\nif (forward)\r\nblk->index = 0;\r\nelse\r\nblk->index = nodehdr.count - 1;\r\nblkno = be32_to_cpu(btree[blk->index].before);\r\nbreak;\r\ncase XFS_ATTR_LEAF_MAGIC:\r\ncase XFS_ATTR3_LEAF_MAGIC:\r\nblk->magic = XFS_ATTR_LEAF_MAGIC;\r\nASSERT(level == path->active-1);\r\nblk->index = 0;\r\nblk->hashval = xfs_attr_leaf_lasthash(blk->bp,\r\nNULL);\r\nbreak;\r\ncase XFS_DIR2_LEAFN_MAGIC:\r\ncase XFS_DIR3_LEAFN_MAGIC:\r\nblk->magic = XFS_DIR2_LEAFN_MAGIC;\r\nASSERT(level == path->active-1);\r\nblk->index = 0;\r\nblk->hashval = xfs_dir2_leafn_lasthash(blk->bp,\r\nNULL);\r\nbreak;\r\ndefault:\r\nASSERT(0);\r\nbreak;\r\n}\r\n}\r\n*result = 0;\r\nreturn 0;\r\n}\r\nxfs_dahash_t\r\nxfs_da_hashname(const __uint8_t *name, int namelen)\r\n{\r\nxfs_dahash_t hash;\r\nfor (hash = 0; namelen >= 4; namelen -= 4, name += 4)\r\nhash = (name[0] << 21) ^ (name[1] << 14) ^ (name[2] << 7) ^\r\n(name[3] << 0) ^ rol32(hash, 7 * 4);\r\nswitch (namelen) {\r\ncase 3:\r\nreturn (name[0] << 14) ^ (name[1] << 7) ^ (name[2] << 0) ^\r\nrol32(hash, 7 * 3);\r\ncase 2:\r\nreturn (name[0] << 7) ^ (name[1] << 0) ^ rol32(hash, 7 * 2);\r\ncase 1:\r\nreturn (name[0] << 0) ^ rol32(hash, 7 * 1);\r\ndefault:\r\nreturn hash;\r\n}\r\n}\r\nenum xfs_dacmp\r\nxfs_da_compname(\r\nstruct xfs_da_args *args,\r\nconst unsigned char *name,\r\nint len)\r\n{\r\nreturn (args->namelen == len && memcmp(args->name, name, len) == 0) ?\r\nXFS_CMP_EXACT : XFS_CMP_DIFFERENT;\r\n}\r\nstatic xfs_dahash_t\r\nxfs_default_hashname(\r\nstruct xfs_name *name)\r\n{\r\nreturn xfs_da_hashname(name->name, name->len);\r\n}\r\nint\r\nxfs_da_grow_inode_int(\r\nstruct xfs_da_args *args,\r\nxfs_fileoff_t *bno,\r\nint count)\r\n{\r\nstruct xfs_trans *tp = args->trans;\r\nstruct xfs_inode *dp = args->dp;\r\nint w = args->whichfork;\r\nxfs_drfsbno_t nblks = dp->i_d.di_nblocks;\r\nstruct xfs_bmbt_irec map, *mapp;\r\nint nmap, error, got, i, mapi;\r\nerror = xfs_bmap_first_unused(tp, dp, count, bno, w);\r\nif (error)\r\nreturn error;\r\nnmap = 1;\r\nASSERT(args->firstblock != NULL);\r\nerror = xfs_bmapi_write(tp, dp, *bno, count,\r\nxfs_bmapi_aflag(w)|XFS_BMAPI_METADATA|XFS_BMAPI_CONTIG,\r\nargs->firstblock, args->total, &map, &nmap,\r\nargs->flist);\r\nif (error)\r\nreturn error;\r\nASSERT(nmap <= 1);\r\nif (nmap == 1) {\r\nmapp = &map;\r\nmapi = 1;\r\n} else if (nmap == 0 && count > 1) {\r\nxfs_fileoff_t b;\r\nint c;\r\nmapp = kmem_alloc(sizeof(*mapp) * count, KM_SLEEP);\r\nfor (b = *bno, mapi = 0; b < *bno + count; ) {\r\nnmap = MIN(XFS_BMAP_MAX_NMAP, count);\r\nc = (int)(*bno + count - b);\r\nerror = xfs_bmapi_write(tp, dp, b, c,\r\nxfs_bmapi_aflag(w)|XFS_BMAPI_METADATA,\r\nargs->firstblock, args->total,\r\n&mapp[mapi], &nmap, args->flist);\r\nif (error)\r\ngoto out_free_map;\r\nif (nmap < 1)\r\nbreak;\r\nmapi += nmap;\r\nb = mapp[mapi - 1].br_startoff +\r\nmapp[mapi - 1].br_blockcount;\r\n}\r\n} else {\r\nmapi = 0;\r\nmapp = NULL;\r\n}\r\nfor (i = 0, got = 0; i < mapi; i++)\r\ngot += mapp[i].br_blockcount;\r\nif (got != count || mapp[0].br_startoff != *bno ||\r\nmapp[mapi - 1].br_startoff + mapp[mapi - 1].br_blockcount !=\r\n*bno + count) {\r\nerror = XFS_ERROR(ENOSPC);\r\ngoto out_free_map;\r\n}\r\nargs->total -= dp->i_d.di_nblocks - nblks;\r\nout_free_map:\r\nif (mapp != &map)\r\nkmem_free(mapp);\r\nreturn error;\r\n}\r\nint\r\nxfs_da_grow_inode(\r\nstruct xfs_da_args *args,\r\nxfs_dablk_t *new_blkno)\r\n{\r\nxfs_fileoff_t bno;\r\nint count;\r\nint error;\r\ntrace_xfs_da_grow_inode(args);\r\nif (args->whichfork == XFS_DATA_FORK) {\r\nbno = args->dp->i_mount->m_dirleafblk;\r\ncount = args->dp->i_mount->m_dirblkfsbs;\r\n} else {\r\nbno = 0;\r\ncount = 1;\r\n}\r\nerror = xfs_da_grow_inode_int(args, &bno, count);\r\nif (!error)\r\n*new_blkno = (xfs_dablk_t)bno;\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_da3_swap_lastblock(\r\nstruct xfs_da_args *args,\r\nxfs_dablk_t *dead_blknop,\r\nstruct xfs_buf **dead_bufp)\r\n{\r\nstruct xfs_da_blkinfo *dead_info;\r\nstruct xfs_da_blkinfo *sib_info;\r\nstruct xfs_da_intnode *par_node;\r\nstruct xfs_da_intnode *dead_node;\r\nstruct xfs_dir2_leaf *dead_leaf2;\r\nstruct xfs_da_node_entry *btree;\r\nstruct xfs_da3_icnode_hdr par_hdr;\r\nstruct xfs_inode *ip;\r\nstruct xfs_trans *tp;\r\nstruct xfs_mount *mp;\r\nstruct xfs_buf *dead_buf;\r\nstruct xfs_buf *last_buf;\r\nstruct xfs_buf *sib_buf;\r\nstruct xfs_buf *par_buf;\r\nxfs_dahash_t dead_hash;\r\nxfs_fileoff_t lastoff;\r\nxfs_dablk_t dead_blkno;\r\nxfs_dablk_t last_blkno;\r\nxfs_dablk_t sib_blkno;\r\nxfs_dablk_t par_blkno;\r\nint error;\r\nint w;\r\nint entno;\r\nint level;\r\nint dead_level;\r\ntrace_xfs_da_swap_lastblock(args);\r\ndead_buf = *dead_bufp;\r\ndead_blkno = *dead_blknop;\r\ntp = args->trans;\r\nip = args->dp;\r\nw = args->whichfork;\r\nASSERT(w == XFS_DATA_FORK);\r\nmp = ip->i_mount;\r\nlastoff = mp->m_dirfreeblk;\r\nerror = xfs_bmap_last_before(tp, ip, &lastoff, w);\r\nif (error)\r\nreturn error;\r\nif (unlikely(lastoff == 0)) {\r\nXFS_ERROR_REPORT("xfs_da_swap_lastblock(1)", XFS_ERRLEVEL_LOW,\r\nmp);\r\nreturn XFS_ERROR(EFSCORRUPTED);\r\n}\r\nlast_blkno = (xfs_dablk_t)lastoff - mp->m_dirblkfsbs;\r\nerror = xfs_da3_node_read(tp, ip, last_blkno, -1, &last_buf, w);\r\nif (error)\r\nreturn error;\r\nmemcpy(dead_buf->b_addr, last_buf->b_addr, mp->m_dirblksize);\r\nxfs_trans_log_buf(tp, dead_buf, 0, mp->m_dirblksize - 1);\r\ndead_info = dead_buf->b_addr;\r\nif (dead_info->magic == cpu_to_be16(XFS_DIR2_LEAFN_MAGIC) ||\r\ndead_info->magic == cpu_to_be16(XFS_DIR3_LEAFN_MAGIC)) {\r\nstruct xfs_dir3_icleaf_hdr leafhdr;\r\nstruct xfs_dir2_leaf_entry *ents;\r\ndead_leaf2 = (xfs_dir2_leaf_t *)dead_info;\r\nxfs_dir3_leaf_hdr_from_disk(&leafhdr, dead_leaf2);\r\nents = xfs_dir3_leaf_ents_p(dead_leaf2);\r\ndead_level = 0;\r\ndead_hash = be32_to_cpu(ents[leafhdr.count - 1].hashval);\r\n} else {\r\nstruct xfs_da3_icnode_hdr deadhdr;\r\ndead_node = (xfs_da_intnode_t *)dead_info;\r\nxfs_da3_node_hdr_from_disk(&deadhdr, dead_node);\r\nbtree = xfs_da3_node_tree_p(dead_node);\r\ndead_level = deadhdr.level;\r\ndead_hash = be32_to_cpu(btree[deadhdr.count - 1].hashval);\r\n}\r\nsib_buf = par_buf = NULL;\r\nif ((sib_blkno = be32_to_cpu(dead_info->back))) {\r\nerror = xfs_da3_node_read(tp, ip, sib_blkno, -1, &sib_buf, w);\r\nif (error)\r\ngoto done;\r\nsib_info = sib_buf->b_addr;\r\nif (unlikely(\r\nbe32_to_cpu(sib_info->forw) != last_blkno ||\r\nsib_info->magic != dead_info->magic)) {\r\nXFS_ERROR_REPORT("xfs_da_swap_lastblock(2)",\r\nXFS_ERRLEVEL_LOW, mp);\r\nerror = XFS_ERROR(EFSCORRUPTED);\r\ngoto done;\r\n}\r\nsib_info->forw = cpu_to_be32(dead_blkno);\r\nxfs_trans_log_buf(tp, sib_buf,\r\nXFS_DA_LOGRANGE(sib_info, &sib_info->forw,\r\nsizeof(sib_info->forw)));\r\nsib_buf = NULL;\r\n}\r\nif ((sib_blkno = be32_to_cpu(dead_info->forw))) {\r\nerror = xfs_da3_node_read(tp, ip, sib_blkno, -1, &sib_buf, w);\r\nif (error)\r\ngoto done;\r\nsib_info = sib_buf->b_addr;\r\nif (unlikely(\r\nbe32_to_cpu(sib_info->back) != last_blkno ||\r\nsib_info->magic != dead_info->magic)) {\r\nXFS_ERROR_REPORT("xfs_da_swap_lastblock(3)",\r\nXFS_ERRLEVEL_LOW, mp);\r\nerror = XFS_ERROR(EFSCORRUPTED);\r\ngoto done;\r\n}\r\nsib_info->back = cpu_to_be32(dead_blkno);\r\nxfs_trans_log_buf(tp, sib_buf,\r\nXFS_DA_LOGRANGE(sib_info, &sib_info->back,\r\nsizeof(sib_info->back)));\r\nsib_buf = NULL;\r\n}\r\npar_blkno = mp->m_dirleafblk;\r\nlevel = -1;\r\nfor (;;) {\r\nerror = xfs_da3_node_read(tp, ip, par_blkno, -1, &par_buf, w);\r\nif (error)\r\ngoto done;\r\npar_node = par_buf->b_addr;\r\nxfs_da3_node_hdr_from_disk(&par_hdr, par_node);\r\nif (level >= 0 && level != par_hdr.level + 1) {\r\nXFS_ERROR_REPORT("xfs_da_swap_lastblock(4)",\r\nXFS_ERRLEVEL_LOW, mp);\r\nerror = XFS_ERROR(EFSCORRUPTED);\r\ngoto done;\r\n}\r\nlevel = par_hdr.level;\r\nbtree = xfs_da3_node_tree_p(par_node);\r\nfor (entno = 0;\r\nentno < par_hdr.count &&\r\nbe32_to_cpu(btree[entno].hashval) < dead_hash;\r\nentno++)\r\ncontinue;\r\nif (entno == par_hdr.count) {\r\nXFS_ERROR_REPORT("xfs_da_swap_lastblock(5)",\r\nXFS_ERRLEVEL_LOW, mp);\r\nerror = XFS_ERROR(EFSCORRUPTED);\r\ngoto done;\r\n}\r\npar_blkno = be32_to_cpu(btree[entno].before);\r\nif (level == dead_level + 1)\r\nbreak;\r\nxfs_trans_brelse(tp, par_buf);\r\npar_buf = NULL;\r\n}\r\nfor (;;) {\r\nfor (;\r\nentno < par_hdr.count &&\r\nbe32_to_cpu(btree[entno].before) != last_blkno;\r\nentno++)\r\ncontinue;\r\nif (entno < par_hdr.count)\r\nbreak;\r\npar_blkno = par_hdr.forw;\r\nxfs_trans_brelse(tp, par_buf);\r\npar_buf = NULL;\r\nif (unlikely(par_blkno == 0)) {\r\nXFS_ERROR_REPORT("xfs_da_swap_lastblock(6)",\r\nXFS_ERRLEVEL_LOW, mp);\r\nerror = XFS_ERROR(EFSCORRUPTED);\r\ngoto done;\r\n}\r\nerror = xfs_da3_node_read(tp, ip, par_blkno, -1, &par_buf, w);\r\nif (error)\r\ngoto done;\r\npar_node = par_buf->b_addr;\r\nxfs_da3_node_hdr_from_disk(&par_hdr, par_node);\r\nif (par_hdr.level != level) {\r\nXFS_ERROR_REPORT("xfs_da_swap_lastblock(7)",\r\nXFS_ERRLEVEL_LOW, mp);\r\nerror = XFS_ERROR(EFSCORRUPTED);\r\ngoto done;\r\n}\r\nbtree = xfs_da3_node_tree_p(par_node);\r\nentno = 0;\r\n}\r\nbtree[entno].before = cpu_to_be32(dead_blkno);\r\nxfs_trans_log_buf(tp, par_buf,\r\nXFS_DA_LOGRANGE(par_node, &btree[entno].before,\r\nsizeof(btree[entno].before)));\r\n*dead_blknop = last_blkno;\r\n*dead_bufp = last_buf;\r\nreturn 0;\r\ndone:\r\nif (par_buf)\r\nxfs_trans_brelse(tp, par_buf);\r\nif (sib_buf)\r\nxfs_trans_brelse(tp, sib_buf);\r\nxfs_trans_brelse(tp, last_buf);\r\nreturn error;\r\n}\r\nint\r\nxfs_da_shrink_inode(\r\nxfs_da_args_t *args,\r\nxfs_dablk_t dead_blkno,\r\nstruct xfs_buf *dead_buf)\r\n{\r\nxfs_inode_t *dp;\r\nint done, error, w, count;\r\nxfs_trans_t *tp;\r\nxfs_mount_t *mp;\r\ntrace_xfs_da_shrink_inode(args);\r\ndp = args->dp;\r\nw = args->whichfork;\r\ntp = args->trans;\r\nmp = dp->i_mount;\r\nif (w == XFS_DATA_FORK)\r\ncount = mp->m_dirblkfsbs;\r\nelse\r\ncount = 1;\r\nfor (;;) {\r\nerror = xfs_bunmapi(tp, dp, dead_blkno, count,\r\nxfs_bmapi_aflag(w)|XFS_BMAPI_METADATA,\r\n0, args->firstblock, args->flist, &done);\r\nif (error == ENOSPC) {\r\nif (w != XFS_DATA_FORK)\r\nbreak;\r\nerror = xfs_da3_swap_lastblock(args, &dead_blkno,\r\n&dead_buf);\r\nif (error)\r\nbreak;\r\n} else {\r\nbreak;\r\n}\r\n}\r\nxfs_trans_binval(tp, dead_buf);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_da_map_covers_blocks(\r\nint nmap,\r\nxfs_bmbt_irec_t *mapp,\r\nxfs_dablk_t bno,\r\nint count)\r\n{\r\nint i;\r\nxfs_fileoff_t off;\r\nfor (i = 0, off = bno; i < nmap; i++) {\r\nif (mapp[i].br_startblock == HOLESTARTBLOCK ||\r\nmapp[i].br_startblock == DELAYSTARTBLOCK) {\r\nreturn 0;\r\n}\r\nif (off != mapp[i].br_startoff) {\r\nreturn 0;\r\n}\r\noff += mapp[i].br_blockcount;\r\n}\r\nreturn off == bno + count;\r\n}\r\nstatic int\r\nxfs_buf_map_from_irec(\r\nstruct xfs_mount *mp,\r\nstruct xfs_buf_map **mapp,\r\nunsigned int *nmaps,\r\nstruct xfs_bmbt_irec *irecs,\r\nunsigned int nirecs)\r\n{\r\nstruct xfs_buf_map *map;\r\nint i;\r\nASSERT(*nmaps == 1);\r\nASSERT(nirecs >= 1);\r\nif (nirecs > 1) {\r\nmap = kmem_zalloc(nirecs * sizeof(struct xfs_buf_map),\r\nKM_SLEEP | KM_NOFS);\r\nif (!map)\r\nreturn ENOMEM;\r\n*mapp = map;\r\n}\r\n*nmaps = nirecs;\r\nmap = *mapp;\r\nfor (i = 0; i < *nmaps; i++) {\r\nASSERT(irecs[i].br_startblock != DELAYSTARTBLOCK &&\r\nirecs[i].br_startblock != HOLESTARTBLOCK);\r\nmap[i].bm_bn = XFS_FSB_TO_DADDR(mp, irecs[i].br_startblock);\r\nmap[i].bm_len = XFS_FSB_TO_BB(mp, irecs[i].br_blockcount);\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\nxfs_dabuf_map(\r\nstruct xfs_trans *trans,\r\nstruct xfs_inode *dp,\r\nxfs_dablk_t bno,\r\nxfs_daddr_t mappedbno,\r\nint whichfork,\r\nstruct xfs_buf_map **map,\r\nint *nmaps)\r\n{\r\nstruct xfs_mount *mp = dp->i_mount;\r\nint nfsb;\r\nint error = 0;\r\nstruct xfs_bmbt_irec irec;\r\nstruct xfs_bmbt_irec *irecs = &irec;\r\nint nirecs;\r\nASSERT(map && *map);\r\nASSERT(*nmaps == 1);\r\nnfsb = (whichfork == XFS_DATA_FORK) ? mp->m_dirblkfsbs : 1;\r\nif (mappedbno == -1 || mappedbno == -2) {\r\nif (nfsb != 1)\r\nirecs = kmem_zalloc(sizeof(irec) * nfsb,\r\nKM_SLEEP | KM_NOFS);\r\nnirecs = nfsb;\r\nerror = xfs_bmapi_read(dp, (xfs_fileoff_t)bno, nfsb, irecs,\r\n&nirecs, xfs_bmapi_aflag(whichfork));\r\nif (error)\r\ngoto out;\r\n} else {\r\nirecs->br_startblock = XFS_DADDR_TO_FSB(mp, mappedbno);\r\nirecs->br_startoff = (xfs_fileoff_t)bno;\r\nirecs->br_blockcount = nfsb;\r\nirecs->br_state = 0;\r\nnirecs = 1;\r\n}\r\nif (!xfs_da_map_covers_blocks(nirecs, irecs, bno, nfsb)) {\r\nerror = mappedbno == -2 ? -1 : XFS_ERROR(EFSCORRUPTED);\r\nif (unlikely(error == EFSCORRUPTED)) {\r\nif (xfs_error_level >= XFS_ERRLEVEL_LOW) {\r\nint i;\r\nxfs_alert(mp, "%s: bno %lld dir: inode %lld",\r\n__func__, (long long)bno,\r\n(long long)dp->i_ino);\r\nfor (i = 0; i < *nmaps; i++) {\r\nxfs_alert(mp,\r\n"[%02d] br_startoff %lld br_startblock %lld br_blockcount %lld br_state %d",\r\ni,\r\n(long long)irecs[i].br_startoff,\r\n(long long)irecs[i].br_startblock,\r\n(long long)irecs[i].br_blockcount,\r\nirecs[i].br_state);\r\n}\r\n}\r\nXFS_ERROR_REPORT("xfs_da_do_buf(1)",\r\nXFS_ERRLEVEL_LOW, mp);\r\n}\r\ngoto out;\r\n}\r\nerror = xfs_buf_map_from_irec(mp, map, nmaps, irecs, nirecs);\r\nout:\r\nif (irecs != &irec)\r\nkmem_free(irecs);\r\nreturn error;\r\n}\r\nint\r\nxfs_da_get_buf(\r\nstruct xfs_trans *trans,\r\nstruct xfs_inode *dp,\r\nxfs_dablk_t bno,\r\nxfs_daddr_t mappedbno,\r\nstruct xfs_buf **bpp,\r\nint whichfork)\r\n{\r\nstruct xfs_buf *bp;\r\nstruct xfs_buf_map map;\r\nstruct xfs_buf_map *mapp;\r\nint nmap;\r\nint error;\r\n*bpp = NULL;\r\nmapp = &map;\r\nnmap = 1;\r\nerror = xfs_dabuf_map(trans, dp, bno, mappedbno, whichfork,\r\n&mapp, &nmap);\r\nif (error) {\r\nif (error == -1)\r\nerror = 0;\r\ngoto out_free;\r\n}\r\nbp = xfs_trans_get_buf_map(trans, dp->i_mount->m_ddev_targp,\r\nmapp, nmap, 0);\r\nerror = bp ? bp->b_error : XFS_ERROR(EIO);\r\nif (error) {\r\nxfs_trans_brelse(trans, bp);\r\ngoto out_free;\r\n}\r\n*bpp = bp;\r\nout_free:\r\nif (mapp != &map)\r\nkmem_free(mapp);\r\nreturn error;\r\n}\r\nint\r\nxfs_da_read_buf(\r\nstruct xfs_trans *trans,\r\nstruct xfs_inode *dp,\r\nxfs_dablk_t bno,\r\nxfs_daddr_t mappedbno,\r\nstruct xfs_buf **bpp,\r\nint whichfork,\r\nconst struct xfs_buf_ops *ops)\r\n{\r\nstruct xfs_buf *bp;\r\nstruct xfs_buf_map map;\r\nstruct xfs_buf_map *mapp;\r\nint nmap;\r\nint error;\r\n*bpp = NULL;\r\nmapp = &map;\r\nnmap = 1;\r\nerror = xfs_dabuf_map(trans, dp, bno, mappedbno, whichfork,\r\n&mapp, &nmap);\r\nif (error) {\r\nif (error == -1)\r\nerror = 0;\r\ngoto out_free;\r\n}\r\nerror = xfs_trans_read_buf_map(dp->i_mount, trans,\r\ndp->i_mount->m_ddev_targp,\r\nmapp, nmap, 0, &bp, ops);\r\nif (error)\r\ngoto out_free;\r\nif (whichfork == XFS_ATTR_FORK)\r\nxfs_buf_set_ref(bp, XFS_ATTR_BTREE_REF);\r\nelse\r\nxfs_buf_set_ref(bp, XFS_DIR_BTREE_REF);\r\n{\r\nxfs_dir2_data_hdr_t *hdr = bp->b_addr;\r\nxfs_dir2_free_t *free = bp->b_addr;\r\nxfs_da_blkinfo_t *info = bp->b_addr;\r\nuint magic, magic1;\r\nstruct xfs_mount *mp = dp->i_mount;\r\nmagic = be16_to_cpu(info->magic);\r\nmagic1 = be32_to_cpu(hdr->magic);\r\nif (unlikely(\r\nXFS_TEST_ERROR((magic != XFS_DA_NODE_MAGIC) &&\r\n(magic != XFS_DA3_NODE_MAGIC) &&\r\n(magic != XFS_ATTR_LEAF_MAGIC) &&\r\n(magic != XFS_ATTR3_LEAF_MAGIC) &&\r\n(magic != XFS_DIR2_LEAF1_MAGIC) &&\r\n(magic != XFS_DIR3_LEAF1_MAGIC) &&\r\n(magic != XFS_DIR2_LEAFN_MAGIC) &&\r\n(magic != XFS_DIR3_LEAFN_MAGIC) &&\r\n(magic1 != XFS_DIR2_BLOCK_MAGIC) &&\r\n(magic1 != XFS_DIR3_BLOCK_MAGIC) &&\r\n(magic1 != XFS_DIR2_DATA_MAGIC) &&\r\n(magic1 != XFS_DIR3_DATA_MAGIC) &&\r\n(free->hdr.magic !=\r\ncpu_to_be32(XFS_DIR2_FREE_MAGIC)) &&\r\n(free->hdr.magic !=\r\ncpu_to_be32(XFS_DIR3_FREE_MAGIC)),\r\nmp, XFS_ERRTAG_DA_READ_BUF,\r\nXFS_RANDOM_DA_READ_BUF))) {\r\ntrace_xfs_da_btree_corrupt(bp, _RET_IP_);\r\nXFS_CORRUPTION_ERROR("xfs_da_do_buf(2)",\r\nXFS_ERRLEVEL_LOW, mp, info);\r\nerror = XFS_ERROR(EFSCORRUPTED);\r\nxfs_trans_brelse(trans, bp);\r\ngoto out_free;\r\n}\r\n}\r\n*bpp = bp;\r\nout_free:\r\nif (mapp != &map)\r\nkmem_free(mapp);\r\nreturn error;\r\n}\r\nxfs_daddr_t\r\nxfs_da_reada_buf(\r\nstruct xfs_trans *trans,\r\nstruct xfs_inode *dp,\r\nxfs_dablk_t bno,\r\nxfs_daddr_t mappedbno,\r\nint whichfork,\r\nconst struct xfs_buf_ops *ops)\r\n{\r\nstruct xfs_buf_map map;\r\nstruct xfs_buf_map *mapp;\r\nint nmap;\r\nint error;\r\nmapp = &map;\r\nnmap = 1;\r\nerror = xfs_dabuf_map(trans, dp, bno, mappedbno, whichfork,\r\n&mapp, &nmap);\r\nif (error) {\r\nif (error == -1)\r\nerror = 0;\r\ngoto out_free;\r\n}\r\nmappedbno = mapp[0].bm_bn;\r\nxfs_buf_readahead_map(dp->i_mount->m_ddev_targp, mapp, nmap, ops);\r\nout_free:\r\nif (mapp != &map)\r\nkmem_free(mapp);\r\nif (error)\r\nreturn -1;\r\nreturn mappedbno;\r\n}
