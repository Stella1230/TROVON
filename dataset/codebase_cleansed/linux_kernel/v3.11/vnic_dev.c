void *vnic_dev_priv(struct vnic_dev *vdev)\r\n{\r\nreturn vdev->priv;\r\n}\r\nstatic int vnic_dev_discover_res(struct vnic_dev *vdev,\r\nstruct vnic_dev_bar *bar, unsigned int num_bars)\r\n{\r\nstruct vnic_resource_header __iomem *rh;\r\nstruct mgmt_barmap_hdr __iomem *mrh;\r\nstruct vnic_resource __iomem *r;\r\nu8 type;\r\nif (num_bars == 0)\r\nreturn -EINVAL;\r\nif (bar->len < VNIC_MAX_RES_HDR_SIZE) {\r\npr_err("vNIC BAR0 res hdr length error\n");\r\nreturn -EINVAL;\r\n}\r\nrh = bar->vaddr;\r\nmrh = bar->vaddr;\r\nif (!rh) {\r\npr_err("vNIC BAR0 res hdr not mem-mapped\n");\r\nreturn -EINVAL;\r\n}\r\nif ((ioread32(&rh->magic) != VNIC_RES_MAGIC) ||\r\n(ioread32(&rh->version) != VNIC_RES_VERSION)) {\r\nif ((ioread32(&mrh->magic) != MGMTVNIC_MAGIC) ||\r\n(ioread32(&mrh->version) != MGMTVNIC_VERSION)) {\r\npr_err("vNIC BAR0 res magic/version error "\r\n"exp (%lx/%lx) or (%lx/%lx), curr (%x/%x)\n",\r\nVNIC_RES_MAGIC, VNIC_RES_VERSION,\r\nMGMTVNIC_MAGIC, MGMTVNIC_VERSION,\r\nioread32(&rh->magic), ioread32(&rh->version));\r\nreturn -EINVAL;\r\n}\r\n}\r\nif (ioread32(&mrh->magic) == MGMTVNIC_MAGIC)\r\nr = (struct vnic_resource __iomem *)(mrh + 1);\r\nelse\r\nr = (struct vnic_resource __iomem *)(rh + 1);\r\nwhile ((type = ioread8(&r->type)) != RES_TYPE_EOL) {\r\nu8 bar_num = ioread8(&r->bar);\r\nu32 bar_offset = ioread32(&r->bar_offset);\r\nu32 count = ioread32(&r->count);\r\nu32 len;\r\nr++;\r\nif (bar_num >= num_bars)\r\ncontinue;\r\nif (!bar[bar_num].len || !bar[bar_num].vaddr)\r\ncontinue;\r\nswitch (type) {\r\ncase RES_TYPE_WQ:\r\ncase RES_TYPE_RQ:\r\ncase RES_TYPE_CQ:\r\ncase RES_TYPE_INTR_CTRL:\r\nlen = count * VNIC_RES_STRIDE;\r\nif (len + bar_offset > bar[bar_num].len) {\r\npr_err("vNIC BAR0 resource %d "\r\n"out-of-bounds, offset 0x%x + "\r\n"size 0x%x > bar len 0x%lx\n",\r\ntype, bar_offset,\r\nlen,\r\nbar[bar_num].len);\r\nreturn -EINVAL;\r\n}\r\nbreak;\r\ncase RES_TYPE_INTR_PBA_LEGACY:\r\ncase RES_TYPE_DEVCMD:\r\nlen = count;\r\nbreak;\r\ndefault:\r\ncontinue;\r\n}\r\nvdev->res[type].count = count;\r\nvdev->res[type].vaddr = (char __iomem *)bar[bar_num].vaddr +\r\nbar_offset;\r\nvdev->res[type].bus_addr = bar[bar_num].bus_addr + bar_offset;\r\n}\r\nreturn 0;\r\n}\r\nunsigned int vnic_dev_get_res_count(struct vnic_dev *vdev,\r\nenum vnic_res_type type)\r\n{\r\nreturn vdev->res[type].count;\r\n}\r\nvoid __iomem *vnic_dev_get_res(struct vnic_dev *vdev, enum vnic_res_type type,\r\nunsigned int index)\r\n{\r\nif (!vdev->res[type].vaddr)\r\nreturn NULL;\r\nswitch (type) {\r\ncase RES_TYPE_WQ:\r\ncase RES_TYPE_RQ:\r\ncase RES_TYPE_CQ:\r\ncase RES_TYPE_INTR_CTRL:\r\nreturn (char __iomem *)vdev->res[type].vaddr +\r\nindex * VNIC_RES_STRIDE;\r\ndefault:\r\nreturn (char __iomem *)vdev->res[type].vaddr;\r\n}\r\n}\r\nstatic unsigned int vnic_dev_desc_ring_size(struct vnic_dev_ring *ring,\r\nunsigned int desc_count, unsigned int desc_size)\r\n{\r\nunsigned int count_align = 32;\r\nunsigned int desc_align = 16;\r\nring->base_align = 512;\r\nif (desc_count == 0)\r\ndesc_count = 4096;\r\nring->desc_count = ALIGN(desc_count, count_align);\r\nring->desc_size = ALIGN(desc_size, desc_align);\r\nring->size = ring->desc_count * ring->desc_size;\r\nring->size_unaligned = ring->size + ring->base_align;\r\nreturn ring->size_unaligned;\r\n}\r\nvoid vnic_dev_clear_desc_ring(struct vnic_dev_ring *ring)\r\n{\r\nmemset(ring->descs, 0, ring->size);\r\n}\r\nint vnic_dev_alloc_desc_ring(struct vnic_dev *vdev, struct vnic_dev_ring *ring,\r\nunsigned int desc_count, unsigned int desc_size)\r\n{\r\nvnic_dev_desc_ring_size(ring, desc_count, desc_size);\r\nring->descs_unaligned = pci_alloc_consistent(vdev->pdev,\r\nring->size_unaligned,\r\n&ring->base_addr_unaligned);\r\nif (!ring->descs_unaligned) {\r\npr_err("Failed to allocate ring (size=%d), aborting\n",\r\n(int)ring->size);\r\nreturn -ENOMEM;\r\n}\r\nring->base_addr = ALIGN(ring->base_addr_unaligned,\r\nring->base_align);\r\nring->descs = (u8 *)ring->descs_unaligned +\r\n(ring->base_addr - ring->base_addr_unaligned);\r\nvnic_dev_clear_desc_ring(ring);\r\nring->desc_avail = ring->desc_count - 1;\r\nreturn 0;\r\n}\r\nvoid vnic_dev_free_desc_ring(struct vnic_dev *vdev, struct vnic_dev_ring *ring)\r\n{\r\nif (ring->descs) {\r\npci_free_consistent(vdev->pdev,\r\nring->size_unaligned,\r\nring->descs_unaligned,\r\nring->base_addr_unaligned);\r\nring->descs = NULL;\r\n}\r\n}\r\nstatic int _vnic_dev_cmd(struct vnic_dev *vdev, enum vnic_devcmd_cmd cmd,\r\nint wait)\r\n{\r\nstruct vnic_devcmd __iomem *devcmd = vdev->devcmd;\r\nunsigned int i;\r\nint delay;\r\nu32 status;\r\nint err;\r\nstatus = ioread32(&devcmd->status);\r\nif (status == 0xFFFFFFFF) {\r\nreturn -ENODEV;\r\n}\r\nif (status & STAT_BUSY) {\r\npr_err("Busy devcmd %d\n", _CMD_N(cmd));\r\nreturn -EBUSY;\r\n}\r\nif (_CMD_DIR(cmd) & _CMD_DIR_WRITE) {\r\nfor (i = 0; i < VNIC_DEVCMD_NARGS; i++)\r\nwriteq(vdev->args[i], &devcmd->args[i]);\r\nwmb();\r\n}\r\niowrite32(cmd, &devcmd->cmd);\r\nif ((_CMD_FLAGS(cmd) & _CMD_FLAGS_NOWAIT))\r\nreturn 0;\r\nfor (delay = 0; delay < wait; delay++) {\r\nudelay(100);\r\nstatus = ioread32(&devcmd->status);\r\nif (status == 0xFFFFFFFF) {\r\nreturn -ENODEV;\r\n}\r\nif (!(status & STAT_BUSY)) {\r\nif (status & STAT_ERROR) {\r\nerr = (int)readq(&devcmd->args[0]);\r\nif (err == ERR_EINVAL &&\r\ncmd == CMD_CAPABILITY)\r\nreturn err;\r\nif (err != ERR_ECMDUNKNOWN ||\r\ncmd != CMD_CAPABILITY)\r\npr_err("Error %d devcmd %d\n",\r\nerr, _CMD_N(cmd));\r\nreturn err;\r\n}\r\nif (_CMD_DIR(cmd) & _CMD_DIR_READ) {\r\nrmb();\r\nfor (i = 0; i < VNIC_DEVCMD_NARGS; i++)\r\nvdev->args[i] = readq(&devcmd->args[i]);\r\n}\r\nreturn 0;\r\n}\r\n}\r\npr_err("Timedout devcmd %d\n", _CMD_N(cmd));\r\nreturn -ETIMEDOUT;\r\n}\r\nstatic int vnic_dev_cmd_proxy(struct vnic_dev *vdev,\r\nenum vnic_devcmd_cmd proxy_cmd, enum vnic_devcmd_cmd cmd,\r\nu64 *a0, u64 *a1, int wait)\r\n{\r\nu32 status;\r\nint err;\r\nmemset(vdev->args, 0, sizeof(vdev->args));\r\nvdev->args[0] = vdev->proxy_index;\r\nvdev->args[1] = cmd;\r\nvdev->args[2] = *a0;\r\nvdev->args[3] = *a1;\r\nerr = _vnic_dev_cmd(vdev, proxy_cmd, wait);\r\nif (err)\r\nreturn err;\r\nstatus = (u32)vdev->args[0];\r\nif (status & STAT_ERROR) {\r\nerr = (int)vdev->args[1];\r\nif (err != ERR_ECMDUNKNOWN ||\r\ncmd != CMD_CAPABILITY)\r\npr_err("Error %d proxy devcmd %d\n", err, _CMD_N(cmd));\r\nreturn err;\r\n}\r\n*a0 = vdev->args[1];\r\n*a1 = vdev->args[2];\r\nreturn 0;\r\n}\r\nstatic int vnic_dev_cmd_no_proxy(struct vnic_dev *vdev,\r\nenum vnic_devcmd_cmd cmd, u64 *a0, u64 *a1, int wait)\r\n{\r\nint err;\r\nvdev->args[0] = *a0;\r\nvdev->args[1] = *a1;\r\nerr = _vnic_dev_cmd(vdev, cmd, wait);\r\n*a0 = vdev->args[0];\r\n*a1 = vdev->args[1];\r\nreturn err;\r\n}\r\nvoid vnic_dev_cmd_proxy_by_index_start(struct vnic_dev *vdev, u16 index)\r\n{\r\nvdev->proxy = PROXY_BY_INDEX;\r\nvdev->proxy_index = index;\r\n}\r\nvoid vnic_dev_cmd_proxy_end(struct vnic_dev *vdev)\r\n{\r\nvdev->proxy = PROXY_NONE;\r\nvdev->proxy_index = 0;\r\n}\r\nint vnic_dev_cmd(struct vnic_dev *vdev, enum vnic_devcmd_cmd cmd,\r\nu64 *a0, u64 *a1, int wait)\r\n{\r\nmemset(vdev->args, 0, sizeof(vdev->args));\r\nswitch (vdev->proxy) {\r\ncase PROXY_BY_INDEX:\r\nreturn vnic_dev_cmd_proxy(vdev, CMD_PROXY_BY_INDEX, cmd,\r\na0, a1, wait);\r\ncase PROXY_BY_BDF:\r\nreturn vnic_dev_cmd_proxy(vdev, CMD_PROXY_BY_BDF, cmd,\r\na0, a1, wait);\r\ncase PROXY_NONE:\r\ndefault:\r\nreturn vnic_dev_cmd_no_proxy(vdev, cmd, a0, a1, wait);\r\n}\r\n}\r\nstatic int vnic_dev_capable(struct vnic_dev *vdev, enum vnic_devcmd_cmd cmd)\r\n{\r\nu64 a0 = (u32)cmd, a1 = 0;\r\nint wait = 1000;\r\nint err;\r\nerr = vnic_dev_cmd(vdev, CMD_CAPABILITY, &a0, &a1, wait);\r\nreturn !(err || a0);\r\n}\r\nint vnic_dev_fw_info(struct vnic_dev *vdev,\r\nstruct vnic_devcmd_fw_info **fw_info)\r\n{\r\nu64 a0, a1 = 0;\r\nint wait = 1000;\r\nint err = 0;\r\nif (!vdev->fw_info) {\r\nvdev->fw_info = pci_alloc_consistent(vdev->pdev,\r\nsizeof(struct vnic_devcmd_fw_info),\r\n&vdev->fw_info_pa);\r\nif (!vdev->fw_info)\r\nreturn -ENOMEM;\r\nmemset(vdev->fw_info, 0, sizeof(struct vnic_devcmd_fw_info));\r\na0 = vdev->fw_info_pa;\r\na1 = sizeof(struct vnic_devcmd_fw_info);\r\nif (vnic_dev_capable(vdev, CMD_MCPU_FW_INFO))\r\nerr = vnic_dev_cmd(vdev, CMD_MCPU_FW_INFO,\r\n&a0, &a1, wait);\r\nelse\r\nerr = vnic_dev_cmd(vdev, CMD_MCPU_FW_INFO_OLD,\r\n&a0, &a1, wait);\r\n}\r\n*fw_info = vdev->fw_info;\r\nreturn err;\r\n}\r\nint vnic_dev_spec(struct vnic_dev *vdev, unsigned int offset, unsigned int size,\r\nvoid *value)\r\n{\r\nu64 a0, a1;\r\nint wait = 1000;\r\nint err;\r\na0 = offset;\r\na1 = size;\r\nerr = vnic_dev_cmd(vdev, CMD_DEV_SPEC, &a0, &a1, wait);\r\nswitch (size) {\r\ncase 1: *(u8 *)value = (u8)a0; break;\r\ncase 2: *(u16 *)value = (u16)a0; break;\r\ncase 4: *(u32 *)value = (u32)a0; break;\r\ncase 8: *(u64 *)value = a0; break;\r\ndefault: BUG(); break;\r\n}\r\nreturn err;\r\n}\r\nint vnic_dev_stats_dump(struct vnic_dev *vdev, struct vnic_stats **stats)\r\n{\r\nu64 a0, a1;\r\nint wait = 1000;\r\nif (!vdev->stats) {\r\nvdev->stats = pci_alloc_consistent(vdev->pdev,\r\nsizeof(struct vnic_stats), &vdev->stats_pa);\r\nif (!vdev->stats)\r\nreturn -ENOMEM;\r\n}\r\n*stats = vdev->stats;\r\na0 = vdev->stats_pa;\r\na1 = sizeof(struct vnic_stats);\r\nreturn vnic_dev_cmd(vdev, CMD_STATS_DUMP, &a0, &a1, wait);\r\n}\r\nint vnic_dev_close(struct vnic_dev *vdev)\r\n{\r\nu64 a0 = 0, a1 = 0;\r\nint wait = 1000;\r\nreturn vnic_dev_cmd(vdev, CMD_CLOSE, &a0, &a1, wait);\r\n}\r\nint vnic_dev_enable_wait(struct vnic_dev *vdev)\r\n{\r\nu64 a0 = 0, a1 = 0;\r\nint wait = 1000;\r\nif (vnic_dev_capable(vdev, CMD_ENABLE_WAIT))\r\nreturn vnic_dev_cmd(vdev, CMD_ENABLE_WAIT, &a0, &a1, wait);\r\nelse\r\nreturn vnic_dev_cmd(vdev, CMD_ENABLE, &a0, &a1, wait);\r\n}\r\nint vnic_dev_disable(struct vnic_dev *vdev)\r\n{\r\nu64 a0 = 0, a1 = 0;\r\nint wait = 1000;\r\nreturn vnic_dev_cmd(vdev, CMD_DISABLE, &a0, &a1, wait);\r\n}\r\nint vnic_dev_open(struct vnic_dev *vdev, int arg)\r\n{\r\nu64 a0 = (u32)arg, a1 = 0;\r\nint wait = 1000;\r\nreturn vnic_dev_cmd(vdev, CMD_OPEN, &a0, &a1, wait);\r\n}\r\nint vnic_dev_open_done(struct vnic_dev *vdev, int *done)\r\n{\r\nu64 a0 = 0, a1 = 0;\r\nint wait = 1000;\r\nint err;\r\n*done = 0;\r\nerr = vnic_dev_cmd(vdev, CMD_OPEN_STATUS, &a0, &a1, wait);\r\nif (err)\r\nreturn err;\r\n*done = (a0 == 0);\r\nreturn 0;\r\n}\r\nstatic int vnic_dev_soft_reset(struct vnic_dev *vdev, int arg)\r\n{\r\nu64 a0 = (u32)arg, a1 = 0;\r\nint wait = 1000;\r\nreturn vnic_dev_cmd(vdev, CMD_SOFT_RESET, &a0, &a1, wait);\r\n}\r\nstatic int vnic_dev_soft_reset_done(struct vnic_dev *vdev, int *done)\r\n{\r\nu64 a0 = 0, a1 = 0;\r\nint wait = 1000;\r\nint err;\r\n*done = 0;\r\nerr = vnic_dev_cmd(vdev, CMD_SOFT_RESET_STATUS, &a0, &a1, wait);\r\nif (err)\r\nreturn err;\r\n*done = (a0 == 0);\r\nreturn 0;\r\n}\r\nint vnic_dev_hang_reset(struct vnic_dev *vdev, int arg)\r\n{\r\nu64 a0 = (u32)arg, a1 = 0;\r\nint wait = 1000;\r\nint err;\r\nif (vnic_dev_capable(vdev, CMD_HANG_RESET)) {\r\nreturn vnic_dev_cmd(vdev, CMD_HANG_RESET,\r\n&a0, &a1, wait);\r\n} else {\r\nerr = vnic_dev_soft_reset(vdev, arg);\r\nif (err)\r\nreturn err;\r\nreturn vnic_dev_init(vdev, 0);\r\n}\r\n}\r\nint vnic_dev_hang_reset_done(struct vnic_dev *vdev, int *done)\r\n{\r\nu64 a0 = 0, a1 = 0;\r\nint wait = 1000;\r\nint err;\r\n*done = 0;\r\nif (vnic_dev_capable(vdev, CMD_HANG_RESET_STATUS)) {\r\nerr = vnic_dev_cmd(vdev, CMD_HANG_RESET_STATUS,\r\n&a0, &a1, wait);\r\nif (err)\r\nreturn err;\r\n} else {\r\nreturn vnic_dev_soft_reset_done(vdev, done);\r\n}\r\n*done = (a0 == 0);\r\nreturn 0;\r\n}\r\nint vnic_dev_hang_notify(struct vnic_dev *vdev)\r\n{\r\nu64 a0, a1;\r\nint wait = 1000;\r\nreturn vnic_dev_cmd(vdev, CMD_HANG_NOTIFY, &a0, &a1, wait);\r\n}\r\nint vnic_dev_get_mac_addr(struct vnic_dev *vdev, u8 *mac_addr)\r\n{\r\nu64 a0, a1;\r\nint wait = 1000;\r\nint err, i;\r\nfor (i = 0; i < ETH_ALEN; i++)\r\nmac_addr[i] = 0;\r\nerr = vnic_dev_cmd(vdev, CMD_GET_MAC_ADDR, &a0, &a1, wait);\r\nif (err)\r\nreturn err;\r\nfor (i = 0; i < ETH_ALEN; i++)\r\nmac_addr[i] = ((u8 *)&a0)[i];\r\nreturn 0;\r\n}\r\nint vnic_dev_packet_filter(struct vnic_dev *vdev, int directed, int multicast,\r\nint broadcast, int promisc, int allmulti)\r\n{\r\nu64 a0, a1 = 0;\r\nint wait = 1000;\r\nint err;\r\na0 = (directed ? CMD_PFILTER_DIRECTED : 0) |\r\n(multicast ? CMD_PFILTER_MULTICAST : 0) |\r\n(broadcast ? CMD_PFILTER_BROADCAST : 0) |\r\n(promisc ? CMD_PFILTER_PROMISCUOUS : 0) |\r\n(allmulti ? CMD_PFILTER_ALL_MULTICAST : 0);\r\nerr = vnic_dev_cmd(vdev, CMD_PACKET_FILTER, &a0, &a1, wait);\r\nif (err)\r\npr_err("Can't set packet filter\n");\r\nreturn err;\r\n}\r\nint vnic_dev_add_addr(struct vnic_dev *vdev, u8 *addr)\r\n{\r\nu64 a0 = 0, a1 = 0;\r\nint wait = 1000;\r\nint err;\r\nint i;\r\nfor (i = 0; i < ETH_ALEN; i++)\r\n((u8 *)&a0)[i] = addr[i];\r\nerr = vnic_dev_cmd(vdev, CMD_ADDR_ADD, &a0, &a1, wait);\r\nif (err)\r\npr_err("Can't add addr [%pM], %d\n", addr, err);\r\nreturn err;\r\n}\r\nint vnic_dev_del_addr(struct vnic_dev *vdev, u8 *addr)\r\n{\r\nu64 a0 = 0, a1 = 0;\r\nint wait = 1000;\r\nint err;\r\nint i;\r\nfor (i = 0; i < ETH_ALEN; i++)\r\n((u8 *)&a0)[i] = addr[i];\r\nerr = vnic_dev_cmd(vdev, CMD_ADDR_DEL, &a0, &a1, wait);\r\nif (err)\r\npr_err("Can't del addr [%pM], %d\n", addr, err);\r\nreturn err;\r\n}\r\nint vnic_dev_set_ig_vlan_rewrite_mode(struct vnic_dev *vdev,\r\nu8 ig_vlan_rewrite_mode)\r\n{\r\nu64 a0 = ig_vlan_rewrite_mode, a1 = 0;\r\nint wait = 1000;\r\nif (vnic_dev_capable(vdev, CMD_IG_VLAN_REWRITE_MODE))\r\nreturn vnic_dev_cmd(vdev, CMD_IG_VLAN_REWRITE_MODE,\r\n&a0, &a1, wait);\r\nelse\r\nreturn 0;\r\n}\r\nstatic int vnic_dev_notify_setcmd(struct vnic_dev *vdev,\r\nvoid *notify_addr, dma_addr_t notify_pa, u16 intr)\r\n{\r\nu64 a0, a1;\r\nint wait = 1000;\r\nint r;\r\nmemset(notify_addr, 0, sizeof(struct vnic_devcmd_notify));\r\nvdev->notify = notify_addr;\r\nvdev->notify_pa = notify_pa;\r\na0 = (u64)notify_pa;\r\na1 = ((u64)intr << 32) & 0x0000ffff00000000ULL;\r\na1 += sizeof(struct vnic_devcmd_notify);\r\nr = vnic_dev_cmd(vdev, CMD_NOTIFY, &a0, &a1, wait);\r\nvdev->notify_sz = (r == 0) ? (u32)a1 : 0;\r\nreturn r;\r\n}\r\nint vnic_dev_notify_set(struct vnic_dev *vdev, u16 intr)\r\n{\r\nvoid *notify_addr;\r\ndma_addr_t notify_pa;\r\nif (vdev->notify || vdev->notify_pa) {\r\npr_err("notify block %p still allocated", vdev->notify);\r\nreturn -EINVAL;\r\n}\r\nnotify_addr = pci_alloc_consistent(vdev->pdev,\r\nsizeof(struct vnic_devcmd_notify),\r\n&notify_pa);\r\nif (!notify_addr)\r\nreturn -ENOMEM;\r\nreturn vnic_dev_notify_setcmd(vdev, notify_addr, notify_pa, intr);\r\n}\r\nstatic int vnic_dev_notify_unsetcmd(struct vnic_dev *vdev)\r\n{\r\nu64 a0, a1;\r\nint wait = 1000;\r\nint err;\r\na0 = 0;\r\na1 = 0x0000ffff00000000ULL;\r\na1 += sizeof(struct vnic_devcmd_notify);\r\nerr = vnic_dev_cmd(vdev, CMD_NOTIFY, &a0, &a1, wait);\r\nvdev->notify = NULL;\r\nvdev->notify_pa = 0;\r\nvdev->notify_sz = 0;\r\nreturn err;\r\n}\r\nint vnic_dev_notify_unset(struct vnic_dev *vdev)\r\n{\r\nif (vdev->notify) {\r\npci_free_consistent(vdev->pdev,\r\nsizeof(struct vnic_devcmd_notify),\r\nvdev->notify,\r\nvdev->notify_pa);\r\n}\r\nreturn vnic_dev_notify_unsetcmd(vdev);\r\n}\r\nstatic int vnic_dev_notify_ready(struct vnic_dev *vdev)\r\n{\r\nu32 *words;\r\nunsigned int nwords = vdev->notify_sz / 4;\r\nunsigned int i;\r\nu32 csum;\r\nif (!vdev->notify || !vdev->notify_sz)\r\nreturn 0;\r\ndo {\r\ncsum = 0;\r\nmemcpy(&vdev->notify_copy, vdev->notify, vdev->notify_sz);\r\nwords = (u32 *)&vdev->notify_copy;\r\nfor (i = 1; i < nwords; i++)\r\ncsum += words[i];\r\n} while (csum != words[0]);\r\nreturn 1;\r\n}\r\nint vnic_dev_init(struct vnic_dev *vdev, int arg)\r\n{\r\nu64 a0 = (u32)arg, a1 = 0;\r\nint wait = 1000;\r\nint r = 0;\r\nif (vnic_dev_capable(vdev, CMD_INIT))\r\nr = vnic_dev_cmd(vdev, CMD_INIT, &a0, &a1, wait);\r\nelse {\r\nvnic_dev_cmd(vdev, CMD_INIT_v1, &a0, &a1, wait);\r\nif (a0 & CMD_INITF_DEFAULT_MAC) {\r\nvnic_dev_cmd(vdev, CMD_GET_MAC_ADDR, &a0, &a1, wait);\r\nvnic_dev_cmd(vdev, CMD_ADDR_ADD, &a0, &a1, wait);\r\n}\r\n}\r\nreturn r;\r\n}\r\nint vnic_dev_deinit(struct vnic_dev *vdev)\r\n{\r\nu64 a0 = 0, a1 = 0;\r\nint wait = 1000;\r\nreturn vnic_dev_cmd(vdev, CMD_DEINIT, &a0, &a1, wait);\r\n}\r\nvoid vnic_dev_intr_coal_timer_info_default(struct vnic_dev *vdev)\r\n{\r\nvdev->intr_coal_timer_info.mul = 2;\r\nvdev->intr_coal_timer_info.div = 3;\r\nvdev->intr_coal_timer_info.max_usec =\r\nvnic_dev_intr_coal_timer_hw_to_usec(vdev, 0xffff);\r\n}\r\nint vnic_dev_intr_coal_timer_info(struct vnic_dev *vdev)\r\n{\r\nint wait = 1000;\r\nint err;\r\nmemset(vdev->args, 0, sizeof(vdev->args));\r\nif (vnic_dev_capable(vdev, CMD_INTR_COAL_CONVERT))\r\nerr = _vnic_dev_cmd(vdev, CMD_INTR_COAL_CONVERT, wait);\r\nelse\r\nerr = ERR_ECMDUNKNOWN;\r\nif ((err == ERR_ECMDUNKNOWN) ||\r\n(!err && !(vdev->args[0] && vdev->args[1] && vdev->args[2]))) {\r\npr_warning("Using default conversion factor for "\r\n"interrupt coalesce timer\n");\r\nvnic_dev_intr_coal_timer_info_default(vdev);\r\nreturn 0;\r\n}\r\nif (!err) {\r\nvdev->intr_coal_timer_info.mul = (u32) vdev->args[0];\r\nvdev->intr_coal_timer_info.div = (u32) vdev->args[1];\r\nvdev->intr_coal_timer_info.max_usec = (u32) vdev->args[2];\r\n}\r\nreturn err;\r\n}\r\nint vnic_dev_link_status(struct vnic_dev *vdev)\r\n{\r\nif (!vnic_dev_notify_ready(vdev))\r\nreturn 0;\r\nreturn vdev->notify_copy.link_state;\r\n}\r\nu32 vnic_dev_port_speed(struct vnic_dev *vdev)\r\n{\r\nif (!vnic_dev_notify_ready(vdev))\r\nreturn 0;\r\nreturn vdev->notify_copy.port_speed;\r\n}\r\nu32 vnic_dev_msg_lvl(struct vnic_dev *vdev)\r\n{\r\nif (!vnic_dev_notify_ready(vdev))\r\nreturn 0;\r\nreturn vdev->notify_copy.msglvl;\r\n}\r\nu32 vnic_dev_mtu(struct vnic_dev *vdev)\r\n{\r\nif (!vnic_dev_notify_ready(vdev))\r\nreturn 0;\r\nreturn vdev->notify_copy.mtu;\r\n}\r\nvoid vnic_dev_set_intr_mode(struct vnic_dev *vdev,\r\nenum vnic_dev_intr_mode intr_mode)\r\n{\r\nvdev->intr_mode = intr_mode;\r\n}\r\nenum vnic_dev_intr_mode vnic_dev_get_intr_mode(\r\nstruct vnic_dev *vdev)\r\n{\r\nreturn vdev->intr_mode;\r\n}\r\nu32 vnic_dev_intr_coal_timer_usec_to_hw(struct vnic_dev *vdev, u32 usec)\r\n{\r\nreturn (usec * vdev->intr_coal_timer_info.mul) /\r\nvdev->intr_coal_timer_info.div;\r\n}\r\nu32 vnic_dev_intr_coal_timer_hw_to_usec(struct vnic_dev *vdev, u32 hw_cycles)\r\n{\r\nreturn (hw_cycles * vdev->intr_coal_timer_info.div) /\r\nvdev->intr_coal_timer_info.mul;\r\n}\r\nu32 vnic_dev_get_intr_coal_timer_max(struct vnic_dev *vdev)\r\n{\r\nreturn vdev->intr_coal_timer_info.max_usec;\r\n}\r\nvoid vnic_dev_unregister(struct vnic_dev *vdev)\r\n{\r\nif (vdev) {\r\nif (vdev->notify)\r\npci_free_consistent(vdev->pdev,\r\nsizeof(struct vnic_devcmd_notify),\r\nvdev->notify,\r\nvdev->notify_pa);\r\nif (vdev->stats)\r\npci_free_consistent(vdev->pdev,\r\nsizeof(struct vnic_stats),\r\nvdev->stats, vdev->stats_pa);\r\nif (vdev->fw_info)\r\npci_free_consistent(vdev->pdev,\r\nsizeof(struct vnic_devcmd_fw_info),\r\nvdev->fw_info, vdev->fw_info_pa);\r\nkfree(vdev);\r\n}\r\n}\r\nstruct vnic_dev *vnic_dev_register(struct vnic_dev *vdev,\r\nvoid *priv, struct pci_dev *pdev, struct vnic_dev_bar *bar,\r\nunsigned int num_bars)\r\n{\r\nif (!vdev) {\r\nvdev = kzalloc(sizeof(struct vnic_dev), GFP_ATOMIC);\r\nif (!vdev)\r\nreturn NULL;\r\n}\r\nvdev->priv = priv;\r\nvdev->pdev = pdev;\r\nif (vnic_dev_discover_res(vdev, bar, num_bars))\r\ngoto err_out;\r\nvdev->devcmd = vnic_dev_get_res(vdev, RES_TYPE_DEVCMD, 0);\r\nif (!vdev->devcmd)\r\ngoto err_out;\r\nreturn vdev;\r\nerr_out:\r\nvnic_dev_unregister(vdev);\r\nreturn NULL;\r\n}\r\nint vnic_dev_init_prov2(struct vnic_dev *vdev, u8 *buf, u32 len)\r\n{\r\nu64 a0, a1 = len;\r\nint wait = 1000;\r\ndma_addr_t prov_pa;\r\nvoid *prov_buf;\r\nint ret;\r\nprov_buf = pci_alloc_consistent(vdev->pdev, len, &prov_pa);\r\nif (!prov_buf)\r\nreturn -ENOMEM;\r\nmemcpy(prov_buf, buf, len);\r\na0 = prov_pa;\r\nret = vnic_dev_cmd(vdev, CMD_INIT_PROV_INFO2, &a0, &a1, wait);\r\npci_free_consistent(vdev->pdev, len, prov_buf, prov_pa);\r\nreturn ret;\r\n}\r\nint vnic_dev_enable2(struct vnic_dev *vdev, int active)\r\n{\r\nu64 a0, a1 = 0;\r\nint wait = 1000;\r\na0 = (active ? CMD_ENABLE2_ACTIVE : 0);\r\nreturn vnic_dev_cmd(vdev, CMD_ENABLE2, &a0, &a1, wait);\r\n}\r\nstatic int vnic_dev_cmd_status(struct vnic_dev *vdev, enum vnic_devcmd_cmd cmd,\r\nint *status)\r\n{\r\nu64 a0 = cmd, a1 = 0;\r\nint wait = 1000;\r\nint ret;\r\nret = vnic_dev_cmd(vdev, CMD_STATUS, &a0, &a1, wait);\r\nif (!ret)\r\n*status = (int)a0;\r\nreturn ret;\r\n}\r\nint vnic_dev_enable2_done(struct vnic_dev *vdev, int *status)\r\n{\r\nreturn vnic_dev_cmd_status(vdev, CMD_ENABLE2, status);\r\n}\r\nint vnic_dev_deinit_done(struct vnic_dev *vdev, int *status)\r\n{\r\nreturn vnic_dev_cmd_status(vdev, CMD_DEINIT, status);\r\n}\r\nint vnic_dev_set_mac_addr(struct vnic_dev *vdev, u8 *mac_addr)\r\n{\r\nu64 a0, a1;\r\nint wait = 1000;\r\nint i;\r\nfor (i = 0; i < ETH_ALEN; i++)\r\n((u8 *)&a0)[i] = mac_addr[i];\r\nreturn vnic_dev_cmd(vdev, CMD_SET_MAC_ADDR, &a0, &a1, wait);\r\n}
