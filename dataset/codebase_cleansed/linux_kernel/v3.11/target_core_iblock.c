static inline struct iblock_dev *IBLOCK_DEV(struct se_device *dev)\r\n{\r\nreturn container_of(dev, struct iblock_dev, dev);\r\n}\r\nstatic int iblock_attach_hba(struct se_hba *hba, u32 host_id)\r\n{\r\npr_debug("CORE_HBA[%d] - TCM iBlock HBA Driver %s on"\r\n" Generic Target Core Stack %s\n", hba->hba_id,\r\nIBLOCK_VERSION, TARGET_CORE_MOD_VERSION);\r\nreturn 0;\r\n}\r\nstatic void iblock_detach_hba(struct se_hba *hba)\r\n{\r\n}\r\nstatic struct se_device *iblock_alloc_device(struct se_hba *hba, const char *name)\r\n{\r\nstruct iblock_dev *ib_dev = NULL;\r\nib_dev = kzalloc(sizeof(struct iblock_dev), GFP_KERNEL);\r\nif (!ib_dev) {\r\npr_err("Unable to allocate struct iblock_dev\n");\r\nreturn NULL;\r\n}\r\npr_debug( "IBLOCK: Allocated ib_dev for %s\n", name);\r\nreturn &ib_dev->dev;\r\n}\r\nstatic int iblock_configure_device(struct se_device *dev)\r\n{\r\nstruct iblock_dev *ib_dev = IBLOCK_DEV(dev);\r\nstruct request_queue *q;\r\nstruct block_device *bd = NULL;\r\nfmode_t mode;\r\nint ret = -ENOMEM;\r\nif (!(ib_dev->ibd_flags & IBDF_HAS_UDEV_PATH)) {\r\npr_err("Missing udev_path= parameters for IBLOCK\n");\r\nreturn -EINVAL;\r\n}\r\nib_dev->ibd_bio_set = bioset_create(IBLOCK_BIO_POOL_SIZE, 0);\r\nif (!ib_dev->ibd_bio_set) {\r\npr_err("IBLOCK: Unable to create bioset\n");\r\ngoto out;\r\n}\r\npr_debug( "IBLOCK: Claiming struct block_device: %s\n",\r\nib_dev->ibd_udev_path);\r\nmode = FMODE_READ|FMODE_EXCL;\r\nif (!ib_dev->ibd_readonly)\r\nmode |= FMODE_WRITE;\r\nbd = blkdev_get_by_path(ib_dev->ibd_udev_path, mode, ib_dev);\r\nif (IS_ERR(bd)) {\r\nret = PTR_ERR(bd);\r\ngoto out_free_bioset;\r\n}\r\nib_dev->ibd_bd = bd;\r\nq = bdev_get_queue(bd);\r\ndev->dev_attrib.hw_block_size = bdev_logical_block_size(bd);\r\ndev->dev_attrib.hw_max_sectors = UINT_MAX;\r\ndev->dev_attrib.hw_queue_depth = q->nr_requests;\r\nif (blk_queue_discard(q)) {\r\ndev->dev_attrib.max_unmap_lba_count =\r\nq->limits.max_discard_sectors;\r\ndev->dev_attrib.max_unmap_block_desc_count = 1;\r\ndev->dev_attrib.unmap_granularity =\r\nq->limits.discard_granularity >> 9;\r\ndev->dev_attrib.unmap_granularity_alignment =\r\nq->limits.discard_alignment;\r\npr_debug("IBLOCK: BLOCK Discard support available,"\r\n" disabled by default\n");\r\n}\r\ndev->dev_attrib.max_write_same_len = 0xFFFF;\r\nif (blk_queue_nonrot(q))\r\ndev->dev_attrib.is_nonrot = 1;\r\nreturn 0;\r\nout_free_bioset:\r\nbioset_free(ib_dev->ibd_bio_set);\r\nib_dev->ibd_bio_set = NULL;\r\nout:\r\nreturn ret;\r\n}\r\nstatic void iblock_free_device(struct se_device *dev)\r\n{\r\nstruct iblock_dev *ib_dev = IBLOCK_DEV(dev);\r\nif (ib_dev->ibd_bd != NULL)\r\nblkdev_put(ib_dev->ibd_bd, FMODE_WRITE|FMODE_READ|FMODE_EXCL);\r\nif (ib_dev->ibd_bio_set != NULL)\r\nbioset_free(ib_dev->ibd_bio_set);\r\nkfree(ib_dev);\r\n}\r\nstatic unsigned long long iblock_emulate_read_cap_with_block_size(\r\nstruct se_device *dev,\r\nstruct block_device *bd,\r\nstruct request_queue *q)\r\n{\r\nunsigned long long blocks_long = (div_u64(i_size_read(bd->bd_inode),\r\nbdev_logical_block_size(bd)) - 1);\r\nu32 block_size = bdev_logical_block_size(bd);\r\nif (block_size == dev->dev_attrib.block_size)\r\nreturn blocks_long;\r\nswitch (block_size) {\r\ncase 4096:\r\nswitch (dev->dev_attrib.block_size) {\r\ncase 2048:\r\nblocks_long <<= 1;\r\nbreak;\r\ncase 1024:\r\nblocks_long <<= 2;\r\nbreak;\r\ncase 512:\r\nblocks_long <<= 3;\r\ndefault:\r\nbreak;\r\n}\r\nbreak;\r\ncase 2048:\r\nswitch (dev->dev_attrib.block_size) {\r\ncase 4096:\r\nblocks_long >>= 1;\r\nbreak;\r\ncase 1024:\r\nblocks_long <<= 1;\r\nbreak;\r\ncase 512:\r\nblocks_long <<= 2;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nbreak;\r\ncase 1024:\r\nswitch (dev->dev_attrib.block_size) {\r\ncase 4096:\r\nblocks_long >>= 2;\r\nbreak;\r\ncase 2048:\r\nblocks_long >>= 1;\r\nbreak;\r\ncase 512:\r\nblocks_long <<= 1;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nbreak;\r\ncase 512:\r\nswitch (dev->dev_attrib.block_size) {\r\ncase 4096:\r\nblocks_long >>= 3;\r\nbreak;\r\ncase 2048:\r\nblocks_long >>= 2;\r\nbreak;\r\ncase 1024:\r\nblocks_long >>= 1;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn blocks_long;\r\n}\r\nstatic void iblock_complete_cmd(struct se_cmd *cmd)\r\n{\r\nstruct iblock_req *ibr = cmd->priv;\r\nu8 status;\r\nif (!atomic_dec_and_test(&ibr->pending))\r\nreturn;\r\nif (atomic_read(&ibr->ib_bio_err_cnt))\r\nstatus = SAM_STAT_CHECK_CONDITION;\r\nelse\r\nstatus = SAM_STAT_GOOD;\r\ntarget_complete_cmd(cmd, status);\r\nkfree(ibr);\r\n}\r\nstatic void iblock_bio_done(struct bio *bio, int err)\r\n{\r\nstruct se_cmd *cmd = bio->bi_private;\r\nstruct iblock_req *ibr = cmd->priv;\r\nif (!test_bit(BIO_UPTODATE, &bio->bi_flags) && !err)\r\nerr = -EIO;\r\nif (err != 0) {\r\npr_err("test_bit(BIO_UPTODATE) failed for bio: %p,"\r\n" err: %d\n", bio, err);\r\natomic_inc(&ibr->ib_bio_err_cnt);\r\nsmp_mb__after_atomic_inc();\r\n}\r\nbio_put(bio);\r\niblock_complete_cmd(cmd);\r\n}\r\nstatic struct bio *\r\niblock_get_bio(struct se_cmd *cmd, sector_t lba, u32 sg_num)\r\n{\r\nstruct iblock_dev *ib_dev = IBLOCK_DEV(cmd->se_dev);\r\nstruct bio *bio;\r\nif (sg_num > BIO_MAX_PAGES)\r\nsg_num = BIO_MAX_PAGES;\r\nbio = bio_alloc_bioset(GFP_NOIO, sg_num, ib_dev->ibd_bio_set);\r\nif (!bio) {\r\npr_err("Unable to allocate memory for bio\n");\r\nreturn NULL;\r\n}\r\nbio->bi_bdev = ib_dev->ibd_bd;\r\nbio->bi_private = cmd;\r\nbio->bi_end_io = &iblock_bio_done;\r\nbio->bi_sector = lba;\r\nreturn bio;\r\n}\r\nstatic void iblock_submit_bios(struct bio_list *list, int rw)\r\n{\r\nstruct blk_plug plug;\r\nstruct bio *bio;\r\nblk_start_plug(&plug);\r\nwhile ((bio = bio_list_pop(list)))\r\nsubmit_bio(rw, bio);\r\nblk_finish_plug(&plug);\r\n}\r\nstatic void iblock_end_io_flush(struct bio *bio, int err)\r\n{\r\nstruct se_cmd *cmd = bio->bi_private;\r\nif (err)\r\npr_err("IBLOCK: cache flush failed: %d\n", err);\r\nif (cmd) {\r\nif (err)\r\ntarget_complete_cmd(cmd, SAM_STAT_CHECK_CONDITION);\r\nelse\r\ntarget_complete_cmd(cmd, SAM_STAT_GOOD);\r\n}\r\nbio_put(bio);\r\n}\r\nstatic sense_reason_t\r\niblock_execute_sync_cache(struct se_cmd *cmd)\r\n{\r\nstruct iblock_dev *ib_dev = IBLOCK_DEV(cmd->se_dev);\r\nint immed = (cmd->t_task_cdb[1] & 0x2);\r\nstruct bio *bio;\r\nif (immed)\r\ntarget_complete_cmd(cmd, SAM_STAT_GOOD);\r\nbio = bio_alloc(GFP_KERNEL, 0);\r\nbio->bi_end_io = iblock_end_io_flush;\r\nbio->bi_bdev = ib_dev->ibd_bd;\r\nif (!immed)\r\nbio->bi_private = cmd;\r\nsubmit_bio(WRITE_FLUSH, bio);\r\nreturn 0;\r\n}\r\nstatic sense_reason_t\r\niblock_do_unmap(struct se_cmd *cmd, void *priv,\r\nsector_t lba, sector_t nolb)\r\n{\r\nstruct block_device *bdev = priv;\r\nint ret;\r\nret = blkdev_issue_discard(bdev, lba, nolb, GFP_KERNEL, 0);\r\nif (ret < 0) {\r\npr_err("blkdev_issue_discard() failed: %d\n", ret);\r\nreturn TCM_LOGICAL_UNIT_COMMUNICATION_FAILURE;\r\n}\r\nreturn 0;\r\n}\r\nstatic sense_reason_t\r\niblock_execute_unmap(struct se_cmd *cmd)\r\n{\r\nstruct block_device *bdev = IBLOCK_DEV(cmd->se_dev)->ibd_bd;\r\nreturn sbc_execute_unmap(cmd, iblock_do_unmap, bdev);\r\n}\r\nstatic sense_reason_t\r\niblock_execute_write_same_unmap(struct se_cmd *cmd)\r\n{\r\nstruct block_device *bdev = IBLOCK_DEV(cmd->se_dev)->ibd_bd;\r\nsector_t lba = cmd->t_task_lba;\r\nsector_t nolb = sbc_get_write_same_sectors(cmd);\r\nint ret;\r\nret = iblock_do_unmap(cmd, bdev, lba, nolb);\r\nif (ret)\r\nreturn ret;\r\ntarget_complete_cmd(cmd, GOOD);\r\nreturn 0;\r\n}\r\nstatic sense_reason_t\r\niblock_execute_write_same(struct se_cmd *cmd)\r\n{\r\nstruct iblock_req *ibr;\r\nstruct scatterlist *sg;\r\nstruct bio *bio;\r\nstruct bio_list list;\r\nsector_t block_lba = cmd->t_task_lba;\r\nsector_t sectors = sbc_get_write_same_sectors(cmd);\r\nsg = &cmd->t_data_sg[0];\r\nif (cmd->t_data_nents > 1 ||\r\nsg->length != cmd->se_dev->dev_attrib.block_size) {\r\npr_err("WRITE_SAME: Illegal SGL t_data_nents: %u length: %u"\r\n" block_size: %u\n", cmd->t_data_nents, sg->length,\r\ncmd->se_dev->dev_attrib.block_size);\r\nreturn TCM_INVALID_CDB_FIELD;\r\n}\r\nibr = kzalloc(sizeof(struct iblock_req), GFP_KERNEL);\r\nif (!ibr)\r\ngoto fail;\r\ncmd->priv = ibr;\r\nbio = iblock_get_bio(cmd, block_lba, 1);\r\nif (!bio)\r\ngoto fail_free_ibr;\r\nbio_list_init(&list);\r\nbio_list_add(&list, bio);\r\natomic_set(&ibr->pending, 1);\r\nwhile (sectors) {\r\nwhile (bio_add_page(bio, sg_page(sg), sg->length, sg->offset)\r\n!= sg->length) {\r\nbio = iblock_get_bio(cmd, block_lba, 1);\r\nif (!bio)\r\ngoto fail_put_bios;\r\natomic_inc(&ibr->pending);\r\nbio_list_add(&list, bio);\r\n}\r\nblock_lba += sg->length >> IBLOCK_LBA_SHIFT;\r\nsectors -= 1;\r\n}\r\niblock_submit_bios(&list, WRITE);\r\nreturn 0;\r\nfail_put_bios:\r\nwhile ((bio = bio_list_pop(&list)))\r\nbio_put(bio);\r\nfail_free_ibr:\r\nkfree(ibr);\r\nfail:\r\nreturn TCM_LOGICAL_UNIT_COMMUNICATION_FAILURE;\r\n}\r\nstatic ssize_t iblock_set_configfs_dev_params(struct se_device *dev,\r\nconst char *page, ssize_t count)\r\n{\r\nstruct iblock_dev *ib_dev = IBLOCK_DEV(dev);\r\nchar *orig, *ptr, *arg_p, *opts;\r\nsubstring_t args[MAX_OPT_ARGS];\r\nint ret = 0, token;\r\nunsigned long tmp_readonly;\r\nopts = kstrdup(page, GFP_KERNEL);\r\nif (!opts)\r\nreturn -ENOMEM;\r\norig = opts;\r\nwhile ((ptr = strsep(&opts, ",\n")) != NULL) {\r\nif (!*ptr)\r\ncontinue;\r\ntoken = match_token(ptr, tokens, args);\r\nswitch (token) {\r\ncase Opt_udev_path:\r\nif (ib_dev->ibd_bd) {\r\npr_err("Unable to set udev_path= while"\r\n" ib_dev->ibd_bd exists\n");\r\nret = -EEXIST;\r\ngoto out;\r\n}\r\nif (match_strlcpy(ib_dev->ibd_udev_path, &args[0],\r\nSE_UDEV_PATH_LEN) == 0) {\r\nret = -EINVAL;\r\nbreak;\r\n}\r\npr_debug("IBLOCK: Referencing UDEV path: %s\n",\r\nib_dev->ibd_udev_path);\r\nib_dev->ibd_flags |= IBDF_HAS_UDEV_PATH;\r\nbreak;\r\ncase Opt_readonly:\r\narg_p = match_strdup(&args[0]);\r\nif (!arg_p) {\r\nret = -ENOMEM;\r\nbreak;\r\n}\r\nret = strict_strtoul(arg_p, 0, &tmp_readonly);\r\nkfree(arg_p);\r\nif (ret < 0) {\r\npr_err("strict_strtoul() failed for"\r\n" readonly=\n");\r\ngoto out;\r\n}\r\nib_dev->ibd_readonly = tmp_readonly;\r\npr_debug("IBLOCK: readonly: %d\n", ib_dev->ibd_readonly);\r\nbreak;\r\ncase Opt_force:\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nout:\r\nkfree(orig);\r\nreturn (!ret) ? count : ret;\r\n}\r\nstatic ssize_t iblock_show_configfs_dev_params(struct se_device *dev, char *b)\r\n{\r\nstruct iblock_dev *ib_dev = IBLOCK_DEV(dev);\r\nstruct block_device *bd = ib_dev->ibd_bd;\r\nchar buf[BDEVNAME_SIZE];\r\nssize_t bl = 0;\r\nif (bd)\r\nbl += sprintf(b + bl, "iBlock device: %s",\r\nbdevname(bd, buf));\r\nif (ib_dev->ibd_flags & IBDF_HAS_UDEV_PATH)\r\nbl += sprintf(b + bl, " UDEV PATH: %s",\r\nib_dev->ibd_udev_path);\r\nbl += sprintf(b + bl, " readonly: %d\n", ib_dev->ibd_readonly);\r\nbl += sprintf(b + bl, " ");\r\nif (bd) {\r\nbl += sprintf(b + bl, "Major: %d Minor: %d %s\n",\r\nMAJOR(bd->bd_dev), MINOR(bd->bd_dev), (!bd->bd_contains) ?\r\n"" : (bd->bd_holder == ib_dev) ?\r\n"CLAIMED: IBLOCK" : "CLAIMED: OS");\r\n} else {\r\nbl += sprintf(b + bl, "Major: 0 Minor: 0\n");\r\n}\r\nreturn bl;\r\n}\r\nstatic sense_reason_t\r\niblock_execute_rw(struct se_cmd *cmd)\r\n{\r\nstruct scatterlist *sgl = cmd->t_data_sg;\r\nu32 sgl_nents = cmd->t_data_nents;\r\nenum dma_data_direction data_direction = cmd->data_direction;\r\nstruct se_device *dev = cmd->se_dev;\r\nstruct iblock_req *ibr;\r\nstruct bio *bio;\r\nstruct bio_list list;\r\nstruct scatterlist *sg;\r\nu32 sg_num = sgl_nents;\r\nsector_t block_lba;\r\nunsigned bio_cnt;\r\nint rw = 0;\r\nint i;\r\nif (data_direction == DMA_TO_DEVICE) {\r\nstruct iblock_dev *ib_dev = IBLOCK_DEV(dev);\r\nstruct request_queue *q = bdev_get_queue(ib_dev->ibd_bd);\r\nif (q->flush_flags & REQ_FUA) {\r\nif (cmd->se_cmd_flags & SCF_FUA)\r\nrw = WRITE_FUA;\r\nelse if (!(q->flush_flags & REQ_FLUSH))\r\nrw = WRITE_FUA;\r\nelse\r\nrw = WRITE;\r\n} else {\r\nrw = WRITE;\r\n}\r\n} else {\r\nrw = READ;\r\n}\r\nif (dev->dev_attrib.block_size == 4096)\r\nblock_lba = (cmd->t_task_lba << 3);\r\nelse if (dev->dev_attrib.block_size == 2048)\r\nblock_lba = (cmd->t_task_lba << 2);\r\nelse if (dev->dev_attrib.block_size == 1024)\r\nblock_lba = (cmd->t_task_lba << 1);\r\nelse if (dev->dev_attrib.block_size == 512)\r\nblock_lba = cmd->t_task_lba;\r\nelse {\r\npr_err("Unsupported SCSI -> BLOCK LBA conversion:"\r\n" %u\n", dev->dev_attrib.block_size);\r\nreturn TCM_LOGICAL_UNIT_COMMUNICATION_FAILURE;\r\n}\r\nibr = kzalloc(sizeof(struct iblock_req), GFP_KERNEL);\r\nif (!ibr)\r\ngoto fail;\r\ncmd->priv = ibr;\r\nif (!sgl_nents) {\r\natomic_set(&ibr->pending, 1);\r\niblock_complete_cmd(cmd);\r\nreturn 0;\r\n}\r\nbio = iblock_get_bio(cmd, block_lba, sgl_nents);\r\nif (!bio)\r\ngoto fail_free_ibr;\r\nbio_list_init(&list);\r\nbio_list_add(&list, bio);\r\natomic_set(&ibr->pending, 2);\r\nbio_cnt = 1;\r\nfor_each_sg(sgl, sg, sgl_nents, i) {\r\nwhile (bio_add_page(bio, sg_page(sg), sg->length, sg->offset)\r\n!= sg->length) {\r\nif (bio_cnt >= IBLOCK_MAX_BIO_PER_TASK) {\r\niblock_submit_bios(&list, rw);\r\nbio_cnt = 0;\r\n}\r\nbio = iblock_get_bio(cmd, block_lba, sg_num);\r\nif (!bio)\r\ngoto fail_put_bios;\r\natomic_inc(&ibr->pending);\r\nbio_list_add(&list, bio);\r\nbio_cnt++;\r\n}\r\nblock_lba += sg->length >> IBLOCK_LBA_SHIFT;\r\nsg_num--;\r\n}\r\niblock_submit_bios(&list, rw);\r\niblock_complete_cmd(cmd);\r\nreturn 0;\r\nfail_put_bios:\r\nwhile ((bio = bio_list_pop(&list)))\r\nbio_put(bio);\r\nfail_free_ibr:\r\nkfree(ibr);\r\nfail:\r\nreturn TCM_LOGICAL_UNIT_COMMUNICATION_FAILURE;\r\n}\r\nstatic sector_t iblock_get_blocks(struct se_device *dev)\r\n{\r\nstruct iblock_dev *ib_dev = IBLOCK_DEV(dev);\r\nstruct block_device *bd = ib_dev->ibd_bd;\r\nstruct request_queue *q = bdev_get_queue(bd);\r\nreturn iblock_emulate_read_cap_with_block_size(dev, bd, q);\r\n}\r\nstatic sense_reason_t\r\niblock_parse_cdb(struct se_cmd *cmd)\r\n{\r\nreturn sbc_parse_cdb(cmd, &iblock_sbc_ops);\r\n}\r\nbool iblock_get_write_cache(struct se_device *dev)\r\n{\r\nstruct iblock_dev *ib_dev = IBLOCK_DEV(dev);\r\nstruct block_device *bd = ib_dev->ibd_bd;\r\nstruct request_queue *q = bdev_get_queue(bd);\r\nreturn q->flush_flags & REQ_FLUSH;\r\n}\r\nstatic int __init iblock_module_init(void)\r\n{\r\nreturn transport_subsystem_register(&iblock_template);\r\n}\r\nstatic void __exit iblock_module_exit(void)\r\n{\r\ntransport_subsystem_release(&iblock_template);\r\n}
