static unsigned int\r\nnfsd_cache_size_limit(void)\r\n{\r\nunsigned int limit;\r\nunsigned long low_pages = totalram_pages - totalhigh_pages;\r\nlimit = (16 * int_sqrt(low_pages)) << (PAGE_SHIFT-10);\r\nreturn min_t(unsigned int, limit, 256*1024);\r\n}\r\nstatic unsigned int\r\nnfsd_hashsize(unsigned int limit)\r\n{\r\nreturn roundup_pow_of_two(limit / TARGET_BUCKET_SIZE);\r\n}\r\nstatic struct svc_cacherep *\r\nnfsd_reply_cache_alloc(void)\r\n{\r\nstruct svc_cacherep *rp;\r\nrp = kmem_cache_alloc(drc_slab, GFP_KERNEL);\r\nif (rp) {\r\nrp->c_state = RC_UNUSED;\r\nrp->c_type = RC_NOCACHE;\r\nINIT_LIST_HEAD(&rp->c_lru);\r\nINIT_HLIST_NODE(&rp->c_hash);\r\n}\r\nreturn rp;\r\n}\r\nstatic void\r\nnfsd_reply_cache_free_locked(struct svc_cacherep *rp)\r\n{\r\nif (rp->c_type == RC_REPLBUFF && rp->c_replvec.iov_base) {\r\ndrc_mem_usage -= rp->c_replvec.iov_len;\r\nkfree(rp->c_replvec.iov_base);\r\n}\r\nif (!hlist_unhashed(&rp->c_hash))\r\nhlist_del(&rp->c_hash);\r\nlist_del(&rp->c_lru);\r\n--num_drc_entries;\r\ndrc_mem_usage -= sizeof(*rp);\r\nkmem_cache_free(drc_slab, rp);\r\n}\r\nstatic void\r\nnfsd_reply_cache_free(struct svc_cacherep *rp)\r\n{\r\nspin_lock(&cache_lock);\r\nnfsd_reply_cache_free_locked(rp);\r\nspin_unlock(&cache_lock);\r\n}\r\nint nfsd_reply_cache_init(void)\r\n{\r\nunsigned int hashsize;\r\nINIT_LIST_HEAD(&lru_head);\r\nmax_drc_entries = nfsd_cache_size_limit();\r\nnum_drc_entries = 0;\r\nhashsize = nfsd_hashsize(max_drc_entries);\r\nmaskbits = ilog2(hashsize);\r\nregister_shrinker(&nfsd_reply_cache_shrinker);\r\ndrc_slab = kmem_cache_create("nfsd_drc", sizeof(struct svc_cacherep),\r\n0, 0, NULL);\r\nif (!drc_slab)\r\ngoto out_nomem;\r\ncache_hash = kcalloc(hashsize, sizeof(struct hlist_head), GFP_KERNEL);\r\nif (!cache_hash)\r\ngoto out_nomem;\r\nreturn 0;\r\nout_nomem:\r\nprintk(KERN_ERR "nfsd: failed to allocate reply cache\n");\r\nnfsd_reply_cache_shutdown();\r\nreturn -ENOMEM;\r\n}\r\nvoid nfsd_reply_cache_shutdown(void)\r\n{\r\nstruct svc_cacherep *rp;\r\nunregister_shrinker(&nfsd_reply_cache_shrinker);\r\ncancel_delayed_work_sync(&cache_cleaner);\r\nwhile (!list_empty(&lru_head)) {\r\nrp = list_entry(lru_head.next, struct svc_cacherep, c_lru);\r\nnfsd_reply_cache_free_locked(rp);\r\n}\r\nkfree (cache_hash);\r\ncache_hash = NULL;\r\nif (drc_slab) {\r\nkmem_cache_destroy(drc_slab);\r\ndrc_slab = NULL;\r\n}\r\n}\r\nstatic void\r\nlru_put_end(struct svc_cacherep *rp)\r\n{\r\nrp->c_timestamp = jiffies;\r\nlist_move_tail(&rp->c_lru, &lru_head);\r\nschedule_delayed_work(&cache_cleaner, RC_EXPIRE);\r\n}\r\nstatic void\r\nhash_refile(struct svc_cacherep *rp)\r\n{\r\nhlist_del_init(&rp->c_hash);\r\nhlist_add_head(&rp->c_hash, cache_hash + hash_32(rp->c_xid, maskbits));\r\n}\r\nstatic inline bool\r\nnfsd_cache_entry_expired(struct svc_cacherep *rp)\r\n{\r\nreturn rp->c_state != RC_INPROG &&\r\ntime_after(jiffies, rp->c_timestamp + RC_EXPIRE);\r\n}\r\nstatic void\r\nprune_cache_entries(void)\r\n{\r\nstruct svc_cacherep *rp, *tmp;\r\nlist_for_each_entry_safe(rp, tmp, &lru_head, c_lru) {\r\nif (!nfsd_cache_entry_expired(rp) &&\r\nnum_drc_entries <= max_drc_entries)\r\nbreak;\r\nnfsd_reply_cache_free_locked(rp);\r\n}\r\nif (list_empty(&lru_head))\r\ncancel_delayed_work(&cache_cleaner);\r\nelse\r\nmod_delayed_work(system_wq, &cache_cleaner, RC_EXPIRE);\r\n}\r\nstatic void\r\ncache_cleaner_func(struct work_struct *unused)\r\n{\r\nspin_lock(&cache_lock);\r\nprune_cache_entries();\r\nspin_unlock(&cache_lock);\r\n}\r\nstatic int\r\nnfsd_reply_cache_shrink(struct shrinker *shrink, struct shrink_control *sc)\r\n{\r\nunsigned int num;\r\nspin_lock(&cache_lock);\r\nif (sc->nr_to_scan)\r\nprune_cache_entries();\r\nnum = num_drc_entries;\r\nspin_unlock(&cache_lock);\r\nreturn num;\r\n}\r\nstatic __wsum\r\nnfsd_cache_csum(struct svc_rqst *rqstp)\r\n{\r\nint idx;\r\nunsigned int base;\r\n__wsum csum;\r\nstruct xdr_buf *buf = &rqstp->rq_arg;\r\nconst unsigned char *p = buf->head[0].iov_base;\r\nsize_t csum_len = min_t(size_t, buf->head[0].iov_len + buf->page_len,\r\nRC_CSUMLEN);\r\nsize_t len = min(buf->head[0].iov_len, csum_len);\r\ncsum = csum_partial(p, len, 0);\r\ncsum_len -= len;\r\nidx = buf->page_base / PAGE_SIZE;\r\nbase = buf->page_base & ~PAGE_MASK;\r\nwhile (csum_len) {\r\np = page_address(buf->pages[idx]) + base;\r\nlen = min_t(size_t, PAGE_SIZE - base, csum_len);\r\ncsum = csum_partial(p, len, csum);\r\ncsum_len -= len;\r\nbase = 0;\r\n++idx;\r\n}\r\nreturn csum;\r\n}\r\nstatic bool\r\nnfsd_cache_match(struct svc_rqst *rqstp, __wsum csum, struct svc_cacherep *rp)\r\n{\r\nif (rqstp->rq_xid != rp->c_xid || rqstp->rq_proc != rp->c_proc ||\r\nrqstp->rq_prot != rp->c_prot || rqstp->rq_vers != rp->c_vers ||\r\nrqstp->rq_arg.len != rp->c_len ||\r\n!rpc_cmp_addr(svc_addr(rqstp), (struct sockaddr *)&rp->c_addr) ||\r\nrpc_get_port(svc_addr(rqstp)) != rpc_get_port((struct sockaddr *)&rp->c_addr))\r\nreturn false;\r\nif (csum != rp->c_csum) {\r\n++payload_misses;\r\nreturn false;\r\n}\r\nreturn true;\r\n}\r\nstatic struct svc_cacherep *\r\nnfsd_cache_search(struct svc_rqst *rqstp, __wsum csum)\r\n{\r\nstruct svc_cacherep *rp, *ret = NULL;\r\nstruct hlist_head *rh;\r\nunsigned int entries = 0;\r\nrh = &cache_hash[hash_32(rqstp->rq_xid, maskbits)];\r\nhlist_for_each_entry(rp, rh, c_hash) {\r\n++entries;\r\nif (nfsd_cache_match(rqstp, csum, rp)) {\r\nret = rp;\r\nbreak;\r\n}\r\n}\r\nif (entries > longest_chain) {\r\nlongest_chain = entries;\r\nlongest_chain_cachesize = num_drc_entries;\r\n} else if (entries == longest_chain) {\r\nlongest_chain_cachesize = min(longest_chain_cachesize,\r\nnum_drc_entries);\r\n}\r\nreturn ret;\r\n}\r\nint\r\nnfsd_cache_lookup(struct svc_rqst *rqstp)\r\n{\r\nstruct svc_cacherep *rp, *found;\r\n__be32 xid = rqstp->rq_xid;\r\nu32 proto = rqstp->rq_prot,\r\nvers = rqstp->rq_vers,\r\nproc = rqstp->rq_proc;\r\n__wsum csum;\r\nunsigned long age;\r\nint type = rqstp->rq_cachetype;\r\nint rtn = RC_DOIT;\r\nrqstp->rq_cacherep = NULL;\r\nif (type == RC_NOCACHE) {\r\nnfsdstats.rcnocache++;\r\nreturn rtn;\r\n}\r\ncsum = nfsd_cache_csum(rqstp);\r\nspin_lock(&cache_lock);\r\nif (!list_empty(&lru_head)) {\r\nrp = list_first_entry(&lru_head, struct svc_cacherep, c_lru);\r\nif (nfsd_cache_entry_expired(rp) ||\r\nnum_drc_entries >= max_drc_entries) {\r\nlru_put_end(rp);\r\nprune_cache_entries();\r\ngoto search_cache;\r\n}\r\n}\r\nspin_unlock(&cache_lock);\r\nrp = nfsd_reply_cache_alloc();\r\nspin_lock(&cache_lock);\r\nif (likely(rp)) {\r\n++num_drc_entries;\r\ndrc_mem_usage += sizeof(*rp);\r\n}\r\nsearch_cache:\r\nfound = nfsd_cache_search(rqstp, csum);\r\nif (found) {\r\nif (likely(rp))\r\nnfsd_reply_cache_free_locked(rp);\r\nrp = found;\r\ngoto found_entry;\r\n}\r\nif (!rp) {\r\ndprintk("nfsd: unable to allocate DRC entry!\n");\r\ngoto out;\r\n}\r\nif (num_drc_entries >= max_drc_entries)\r\nnfsd_reply_cache_free_locked(list_first_entry(&lru_head,\r\nstruct svc_cacherep, c_lru));\r\nnfsdstats.rcmisses++;\r\nrqstp->rq_cacherep = rp;\r\nrp->c_state = RC_INPROG;\r\nrp->c_xid = xid;\r\nrp->c_proc = proc;\r\nrpc_copy_addr((struct sockaddr *)&rp->c_addr, svc_addr(rqstp));\r\nrpc_set_port((struct sockaddr *)&rp->c_addr, rpc_get_port(svc_addr(rqstp)));\r\nrp->c_prot = proto;\r\nrp->c_vers = vers;\r\nrp->c_len = rqstp->rq_arg.len;\r\nrp->c_csum = csum;\r\nhash_refile(rp);\r\nlru_put_end(rp);\r\nif (rp->c_type == RC_REPLBUFF) {\r\ndrc_mem_usage -= rp->c_replvec.iov_len;\r\nkfree(rp->c_replvec.iov_base);\r\nrp->c_replvec.iov_base = NULL;\r\n}\r\nrp->c_type = RC_NOCACHE;\r\nout:\r\nspin_unlock(&cache_lock);\r\nreturn rtn;\r\nfound_entry:\r\nnfsdstats.rchits++;\r\nage = jiffies - rp->c_timestamp;\r\nlru_put_end(rp);\r\nrtn = RC_DROPIT;\r\nif (rp->c_state == RC_INPROG || age < RC_DELAY)\r\ngoto out;\r\nrtn = RC_DOIT;\r\nif (!rqstp->rq_secure && rp->c_secure)\r\ngoto out;\r\nswitch (rp->c_type) {\r\ncase RC_NOCACHE:\r\nbreak;\r\ncase RC_REPLSTAT:\r\nsvc_putu32(&rqstp->rq_res.head[0], rp->c_replstat);\r\nrtn = RC_REPLY;\r\nbreak;\r\ncase RC_REPLBUFF:\r\nif (!nfsd_cache_append(rqstp, &rp->c_replvec))\r\ngoto out;\r\nrtn = RC_REPLY;\r\nbreak;\r\ndefault:\r\nprintk(KERN_WARNING "nfsd: bad repcache type %d\n", rp->c_type);\r\nnfsd_reply_cache_free_locked(rp);\r\n}\r\ngoto out;\r\n}\r\nvoid\r\nnfsd_cache_update(struct svc_rqst *rqstp, int cachetype, __be32 *statp)\r\n{\r\nstruct svc_cacherep *rp = rqstp->rq_cacherep;\r\nstruct kvec *resv = &rqstp->rq_res.head[0], *cachv;\r\nint len;\r\nsize_t bufsize = 0;\r\nif (!rp)\r\nreturn;\r\nlen = resv->iov_len - ((char*)statp - (char*)resv->iov_base);\r\nlen >>= 2;\r\nif (!statp || len > (256 >> 2)) {\r\nnfsd_reply_cache_free(rp);\r\nreturn;\r\n}\r\nswitch (cachetype) {\r\ncase RC_REPLSTAT:\r\nif (len != 1)\r\nprintk("nfsd: RC_REPLSTAT/reply len %d!\n",len);\r\nrp->c_replstat = *statp;\r\nbreak;\r\ncase RC_REPLBUFF:\r\ncachv = &rp->c_replvec;\r\nbufsize = len << 2;\r\ncachv->iov_base = kmalloc(bufsize, GFP_KERNEL);\r\nif (!cachv->iov_base) {\r\nnfsd_reply_cache_free(rp);\r\nreturn;\r\n}\r\ncachv->iov_len = bufsize;\r\nmemcpy(cachv->iov_base, statp, bufsize);\r\nbreak;\r\ncase RC_NOCACHE:\r\nnfsd_reply_cache_free(rp);\r\nreturn;\r\n}\r\nspin_lock(&cache_lock);\r\ndrc_mem_usage += bufsize;\r\nlru_put_end(rp);\r\nrp->c_secure = rqstp->rq_secure;\r\nrp->c_type = cachetype;\r\nrp->c_state = RC_DONE;\r\nspin_unlock(&cache_lock);\r\nreturn;\r\n}\r\nstatic int\r\nnfsd_cache_append(struct svc_rqst *rqstp, struct kvec *data)\r\n{\r\nstruct kvec *vec = &rqstp->rq_res.head[0];\r\nif (vec->iov_len + data->iov_len > PAGE_SIZE) {\r\nprintk(KERN_WARNING "nfsd: cached reply too large (%Zd).\n",\r\ndata->iov_len);\r\nreturn 0;\r\n}\r\nmemcpy((char*)vec->iov_base + vec->iov_len, data->iov_base, data->iov_len);\r\nvec->iov_len += data->iov_len;\r\nreturn 1;\r\n}\r\nstatic int nfsd_reply_cache_stats_show(struct seq_file *m, void *v)\r\n{\r\nspin_lock(&cache_lock);\r\nseq_printf(m, "max entries: %u\n", max_drc_entries);\r\nseq_printf(m, "num entries: %u\n", num_drc_entries);\r\nseq_printf(m, "hash buckets: %u\n", 1 << maskbits);\r\nseq_printf(m, "mem usage: %u\n", drc_mem_usage);\r\nseq_printf(m, "cache hits: %u\n", nfsdstats.rchits);\r\nseq_printf(m, "cache misses: %u\n", nfsdstats.rcmisses);\r\nseq_printf(m, "not cached: %u\n", nfsdstats.rcnocache);\r\nseq_printf(m, "payload misses: %u\n", payload_misses);\r\nseq_printf(m, "longest chain len: %u\n", longest_chain);\r\nseq_printf(m, "cachesize at longest: %u\n", longest_chain_cachesize);\r\nspin_unlock(&cache_lock);\r\nreturn 0;\r\n}\r\nint nfsd_reply_cache_stats_open(struct inode *inode, struct file *file)\r\n{\r\nreturn single_open(file, nfsd_reply_cache_stats_show, NULL);\r\n}
