static int w840_probe1(struct pci_dev *pdev, const struct pci_device_id *ent)\r\n{\r\nstruct net_device *dev;\r\nstruct netdev_private *np;\r\nstatic int find_cnt;\r\nint chip_idx = ent->driver_data;\r\nint irq;\r\nint i, option = find_cnt < MAX_UNITS ? options[find_cnt] : 0;\r\nvoid __iomem *ioaddr;\r\ni = pci_enable_device(pdev);\r\nif (i) return i;\r\npci_set_master(pdev);\r\nirq = pdev->irq;\r\nif (pci_set_dma_mask(pdev, DMA_BIT_MASK(32))) {\r\npr_warn("Device %s disabled due to DMA limitations\n",\r\npci_name(pdev));\r\nreturn -EIO;\r\n}\r\ndev = alloc_etherdev(sizeof(*np));\r\nif (!dev)\r\nreturn -ENOMEM;\r\nSET_NETDEV_DEV(dev, &pdev->dev);\r\nif (pci_request_regions(pdev, DRV_NAME))\r\ngoto err_out_netdev;\r\nioaddr = pci_iomap(pdev, TULIP_BAR, netdev_res_size);\r\nif (!ioaddr)\r\ngoto err_out_free_res;\r\nfor (i = 0; i < 3; i++)\r\n((__le16 *)dev->dev_addr)[i] = cpu_to_le16(eeprom_read(ioaddr, i));\r\niowrite32(0x00000001, ioaddr + PCIBusCfg);\r\nnp = netdev_priv(dev);\r\nnp->pci_dev = pdev;\r\nnp->chip_id = chip_idx;\r\nnp->drv_flags = pci_id_tbl[chip_idx].drv_flags;\r\nspin_lock_init(&np->lock);\r\nnp->mii_if.dev = dev;\r\nnp->mii_if.mdio_read = mdio_read;\r\nnp->mii_if.mdio_write = mdio_write;\r\nnp->base_addr = ioaddr;\r\npci_set_drvdata(pdev, dev);\r\nif (dev->mem_start)\r\noption = dev->mem_start;\r\nif (option > 0) {\r\nif (option & 0x200)\r\nnp->mii_if.full_duplex = 1;\r\nif (option & 15)\r\ndev_info(&dev->dev,\r\n"ignoring user supplied media type %d",\r\noption & 15);\r\n}\r\nif (find_cnt < MAX_UNITS && full_duplex[find_cnt] > 0)\r\nnp->mii_if.full_duplex = 1;\r\nif (np->mii_if.full_duplex)\r\nnp->mii_if.force_media = 1;\r\ndev->netdev_ops = &netdev_ops;\r\ndev->ethtool_ops = &netdev_ethtool_ops;\r\ndev->watchdog_timeo = TX_TIMEOUT;\r\ni = register_netdev(dev);\r\nif (i)\r\ngoto err_out_cleardev;\r\ndev_info(&dev->dev, "%s at %p, %pM, IRQ %d\n",\r\npci_id_tbl[chip_idx].name, ioaddr, dev->dev_addr, irq);\r\nif (np->drv_flags & CanHaveMII) {\r\nint phy, phy_idx = 0;\r\nfor (phy = 1; phy < 32 && phy_idx < MII_CNT; phy++) {\r\nint mii_status = mdio_read(dev, phy, MII_BMSR);\r\nif (mii_status != 0xffff && mii_status != 0x0000) {\r\nnp->phys[phy_idx++] = phy;\r\nnp->mii_if.advertising = mdio_read(dev, phy, MII_ADVERTISE);\r\nnp->mii = (mdio_read(dev, phy, MII_PHYSID1) << 16)+\r\nmdio_read(dev, phy, MII_PHYSID2);\r\ndev_info(&dev->dev,\r\n"MII PHY %08xh found at address %d, status 0x%04x advertising %04x\n",\r\nnp->mii, phy, mii_status,\r\nnp->mii_if.advertising);\r\n}\r\n}\r\nnp->mii_cnt = phy_idx;\r\nnp->mii_if.phy_id = np->phys[0];\r\nif (phy_idx == 0) {\r\ndev_warn(&dev->dev,\r\n"MII PHY not found -- this device may not operate correctly\n");\r\n}\r\n}\r\nfind_cnt++;\r\nreturn 0;\r\nerr_out_cleardev:\r\npci_set_drvdata(pdev, NULL);\r\npci_iounmap(pdev, ioaddr);\r\nerr_out_free_res:\r\npci_release_regions(pdev);\r\nerr_out_netdev:\r\nfree_netdev (dev);\r\nreturn -ENODEV;\r\n}\r\nstatic int eeprom_read(void __iomem *addr, int location)\r\n{\r\nint i;\r\nint retval = 0;\r\nvoid __iomem *ee_addr = addr + EECtrl;\r\nint read_cmd = location | EE_ReadCmd;\r\niowrite32(EE_ChipSelect, ee_addr);\r\nfor (i = 10; i >= 0; i--) {\r\nshort dataval = (read_cmd & (1 << i)) ? EE_Write1 : EE_Write0;\r\niowrite32(dataval, ee_addr);\r\neeprom_delay(ee_addr);\r\niowrite32(dataval | EE_ShiftClk, ee_addr);\r\neeprom_delay(ee_addr);\r\n}\r\niowrite32(EE_ChipSelect, ee_addr);\r\neeprom_delay(ee_addr);\r\nfor (i = 16; i > 0; i--) {\r\niowrite32(EE_ChipSelect | EE_ShiftClk, ee_addr);\r\neeprom_delay(ee_addr);\r\nretval = (retval << 1) | ((ioread32(ee_addr) & EE_DataIn) ? 1 : 0);\r\niowrite32(EE_ChipSelect, ee_addr);\r\neeprom_delay(ee_addr);\r\n}\r\niowrite32(0, ee_addr);\r\nreturn retval;\r\n}\r\nstatic void mdio_sync(void __iomem *mdio_addr)\r\n{\r\nint bits = 32;\r\nwhile (--bits >= 0) {\r\niowrite32(MDIO_WRITE1, mdio_addr);\r\nmdio_delay(mdio_addr);\r\niowrite32(MDIO_WRITE1 | MDIO_ShiftClk, mdio_addr);\r\nmdio_delay(mdio_addr);\r\n}\r\n}\r\nstatic int mdio_read(struct net_device *dev, int phy_id, int location)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *mdio_addr = np->base_addr + MIICtrl;\r\nint mii_cmd = (0xf6 << 10) | (phy_id << 5) | location;\r\nint i, retval = 0;\r\nif (mii_preamble_required)\r\nmdio_sync(mdio_addr);\r\nfor (i = 15; i >= 0; i--) {\r\nint dataval = (mii_cmd & (1 << i)) ? MDIO_WRITE1 : MDIO_WRITE0;\r\niowrite32(dataval, mdio_addr);\r\nmdio_delay(mdio_addr);\r\niowrite32(dataval | MDIO_ShiftClk, mdio_addr);\r\nmdio_delay(mdio_addr);\r\n}\r\nfor (i = 20; i > 0; i--) {\r\niowrite32(MDIO_EnbIn, mdio_addr);\r\nmdio_delay(mdio_addr);\r\nretval = (retval << 1) | ((ioread32(mdio_addr) & MDIO_DataIn) ? 1 : 0);\r\niowrite32(MDIO_EnbIn | MDIO_ShiftClk, mdio_addr);\r\nmdio_delay(mdio_addr);\r\n}\r\nreturn (retval>>1) & 0xffff;\r\n}\r\nstatic void mdio_write(struct net_device *dev, int phy_id, int location, int value)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *mdio_addr = np->base_addr + MIICtrl;\r\nint mii_cmd = (0x5002 << 16) | (phy_id << 23) | (location<<18) | value;\r\nint i;\r\nif (location == 4 && phy_id == np->phys[0])\r\nnp->mii_if.advertising = value;\r\nif (mii_preamble_required)\r\nmdio_sync(mdio_addr);\r\nfor (i = 31; i >= 0; i--) {\r\nint dataval = (mii_cmd & (1 << i)) ? MDIO_WRITE1 : MDIO_WRITE0;\r\niowrite32(dataval, mdio_addr);\r\nmdio_delay(mdio_addr);\r\niowrite32(dataval | MDIO_ShiftClk, mdio_addr);\r\nmdio_delay(mdio_addr);\r\n}\r\nfor (i = 2; i > 0; i--) {\r\niowrite32(MDIO_EnbIn, mdio_addr);\r\nmdio_delay(mdio_addr);\r\niowrite32(MDIO_EnbIn | MDIO_ShiftClk, mdio_addr);\r\nmdio_delay(mdio_addr);\r\n}\r\n}\r\nstatic int netdev_open(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *ioaddr = np->base_addr;\r\nconst int irq = np->pci_dev->irq;\r\nint i;\r\niowrite32(0x00000001, ioaddr + PCIBusCfg);\r\nnetif_device_detach(dev);\r\ni = request_irq(irq, intr_handler, IRQF_SHARED, dev->name, dev);\r\nif (i)\r\ngoto out_err;\r\nif (debug > 1)\r\nnetdev_dbg(dev, "w89c840_open() irq %d\n", irq);\r\nif((i=alloc_ringdesc(dev)))\r\ngoto out_err;\r\nspin_lock_irq(&np->lock);\r\nnetif_device_attach(dev);\r\ninit_registers(dev);\r\nspin_unlock_irq(&np->lock);\r\nnetif_start_queue(dev);\r\nif (debug > 2)\r\nnetdev_dbg(dev, "Done netdev_open()\n");\r\ninit_timer(&np->timer);\r\nnp->timer.expires = jiffies + 1*HZ;\r\nnp->timer.data = (unsigned long)dev;\r\nnp->timer.function = netdev_timer;\r\nadd_timer(&np->timer);\r\nreturn 0;\r\nout_err:\r\nnetif_device_attach(dev);\r\nreturn i;\r\n}\r\nstatic int update_link(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nint duplex, fasteth, result, mii_reg;\r\nmii_reg = mdio_read(dev, np->phys[0], MII_BMSR);\r\nif (mii_reg == 0xffff)\r\nreturn np->csr6;\r\nmii_reg = mdio_read(dev, np->phys[0], MII_BMSR);\r\nif (!(mii_reg & 0x4)) {\r\nif (netif_carrier_ok(dev)) {\r\nif (debug)\r\ndev_info(&dev->dev,\r\n"MII #%d reports no link. Disabling watchdog\n",\r\nnp->phys[0]);\r\nnetif_carrier_off(dev);\r\n}\r\nreturn np->csr6;\r\n}\r\nif (!netif_carrier_ok(dev)) {\r\nif (debug)\r\ndev_info(&dev->dev,\r\n"MII #%d link is back. Enabling watchdog\n",\r\nnp->phys[0]);\r\nnetif_carrier_on(dev);\r\n}\r\nif ((np->mii & ~0xf) == MII_DAVICOM_DM9101) {\r\nmii_reg = mdio_read(dev, np->phys[0], MII_BMCR);\r\nduplex = mii_reg & BMCR_FULLDPLX;\r\nfasteth = mii_reg & BMCR_SPEED100;\r\n} else {\r\nint negotiated;\r\nmii_reg = mdio_read(dev, np->phys[0], MII_LPA);\r\nnegotiated = mii_reg & np->mii_if.advertising;\r\nduplex = (negotiated & LPA_100FULL) || ((negotiated & 0x02C0) == LPA_10FULL);\r\nfasteth = negotiated & 0x380;\r\n}\r\nduplex |= np->mii_if.force_media;\r\nresult = np->csr6 & ~0x20000200;\r\nif (duplex)\r\nresult |= 0x200;\r\nif (fasteth)\r\nresult |= 0x20000000;\r\nif (result != np->csr6 && debug)\r\ndev_info(&dev->dev,\r\n"Setting %dMBit-%s-duplex based on MII#%d\n",\r\nfasteth ? 100 : 10, duplex ? "full" : "half",\r\nnp->phys[0]);\r\nreturn result;\r\n}\r\nstatic inline void update_csr6(struct net_device *dev, int new)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *ioaddr = np->base_addr;\r\nint limit = RXTX_TIMEOUT;\r\nif (!netif_device_present(dev))\r\nnew = 0;\r\nif (new==np->csr6)\r\nreturn;\r\niowrite32(np->csr6 & ~0x2002, ioaddr + NetworkConfig);\r\nfor (;;) {\r\nint csr5 = ioread32(ioaddr + IntrStatus);\r\nint t;\r\nt = (csr5 >> 17) & 0x07;\r\nif (t==0||t==1) {\r\nt = (csr5 >> 20) & 0x07;\r\nif (t==0||t==1)\r\nbreak;\r\n}\r\nlimit--;\r\nif(!limit) {\r\ndev_info(&dev->dev,\r\n"couldn't stop rxtx, IntrStatus %xh\n", csr5);\r\nbreak;\r\n}\r\nudelay(1);\r\n}\r\nnp->csr6 = new;\r\niowrite32(np->csr6, ioaddr + NetworkConfig);\r\nif (new & 0x200)\r\nnp->mii_if.full_duplex = 1;\r\n}\r\nstatic void netdev_timer(unsigned long data)\r\n{\r\nstruct net_device *dev = (struct net_device *)data;\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *ioaddr = np->base_addr;\r\nif (debug > 2)\r\nnetdev_dbg(dev, "Media selection timer tick, status %08x config %08x\n",\r\nioread32(ioaddr + IntrStatus),\r\nioread32(ioaddr + NetworkConfig));\r\nspin_lock_irq(&np->lock);\r\nupdate_csr6(dev, update_link(dev));\r\nspin_unlock_irq(&np->lock);\r\nnp->timer.expires = jiffies + 10*HZ;\r\nadd_timer(&np->timer);\r\n}\r\nstatic void init_rxtx_rings(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nint i;\r\nnp->rx_head_desc = &np->rx_ring[0];\r\nnp->tx_ring = (struct w840_tx_desc*)&np->rx_ring[RX_RING_SIZE];\r\nfor (i = 0; i < RX_RING_SIZE; i++) {\r\nnp->rx_ring[i].length = np->rx_buf_sz;\r\nnp->rx_ring[i].status = 0;\r\nnp->rx_skbuff[i] = NULL;\r\n}\r\nnp->rx_ring[i-1].length |= DescEndRing;\r\nfor (i = 0; i < RX_RING_SIZE; i++) {\r\nstruct sk_buff *skb = netdev_alloc_skb(dev, np->rx_buf_sz);\r\nnp->rx_skbuff[i] = skb;\r\nif (skb == NULL)\r\nbreak;\r\nnp->rx_addr[i] = pci_map_single(np->pci_dev,skb->data,\r\nnp->rx_buf_sz,PCI_DMA_FROMDEVICE);\r\nnp->rx_ring[i].buffer1 = np->rx_addr[i];\r\nnp->rx_ring[i].status = DescOwned;\r\n}\r\nnp->cur_rx = 0;\r\nnp->dirty_rx = (unsigned int)(i - RX_RING_SIZE);\r\nfor (i = 0; i < TX_RING_SIZE; i++) {\r\nnp->tx_skbuff[i] = NULL;\r\nnp->tx_ring[i].status = 0;\r\n}\r\nnp->tx_full = 0;\r\nnp->tx_q_bytes = np->dirty_tx = np->cur_tx = 0;\r\niowrite32(np->ring_dma_addr, np->base_addr + RxRingPtr);\r\niowrite32(np->ring_dma_addr+sizeof(struct w840_rx_desc)*RX_RING_SIZE,\r\nnp->base_addr + TxRingPtr);\r\n}\r\nstatic void free_rxtx_rings(struct netdev_private* np)\r\n{\r\nint i;\r\nfor (i = 0; i < RX_RING_SIZE; i++) {\r\nnp->rx_ring[i].status = 0;\r\nif (np->rx_skbuff[i]) {\r\npci_unmap_single(np->pci_dev,\r\nnp->rx_addr[i],\r\nnp->rx_skbuff[i]->len,\r\nPCI_DMA_FROMDEVICE);\r\ndev_kfree_skb(np->rx_skbuff[i]);\r\n}\r\nnp->rx_skbuff[i] = NULL;\r\n}\r\nfor (i = 0; i < TX_RING_SIZE; i++) {\r\nif (np->tx_skbuff[i]) {\r\npci_unmap_single(np->pci_dev,\r\nnp->tx_addr[i],\r\nnp->tx_skbuff[i]->len,\r\nPCI_DMA_TODEVICE);\r\ndev_kfree_skb(np->tx_skbuff[i]);\r\n}\r\nnp->tx_skbuff[i] = NULL;\r\n}\r\n}\r\nstatic void init_registers(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *ioaddr = np->base_addr;\r\nint i;\r\nfor (i = 0; i < 6; i++)\r\niowrite8(dev->dev_addr[i], ioaddr + StationAddr + i);\r\n#ifdef __BIG_ENDIAN\r\ni = (1<<20);\r\n#else\r\ni = 0;\r\n#endif\r\ni |= (0x04<<2);\r\ni |= 0x02;\r\n#if defined (__i386__) && !defined(MODULE)\r\nif (boot_cpu_data.x86 <= 4) {\r\ni |= 0x4800;\r\ndev_info(&dev->dev,\r\n"This is a 386/486 PCI system, setting cache alignment to 8 longwords\n");\r\n} else {\r\ni |= 0xE000;\r\n}\r\n#elif defined(__powerpc__) || defined(__i386__) || defined(__alpha__) || defined(__ia64__) || defined(__x86_64__)\r\ni |= 0xE000;\r\n#elif defined(CONFIG_SPARC) || defined (CONFIG_PARISC)\r\ni |= 0x4800;\r\n#else\r\n#warning Processor architecture undefined\r\ni |= 0x4800;\r\n#endif\r\niowrite32(i, ioaddr + PCIBusCfg);\r\nnp->csr6 = 0;\r\nupdate_csr6(dev, 0x00022002 | update_link(dev) | __set_rx_mode(dev));\r\niowrite32(0x1A0F5, ioaddr + IntrStatus);\r\niowrite32(0x1A0F5, ioaddr + IntrEnable);\r\niowrite32(0, ioaddr + RxStartDemand);\r\n}\r\nstatic void tx_timeout(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *ioaddr = np->base_addr;\r\nconst int irq = np->pci_dev->irq;\r\ndev_warn(&dev->dev, "Transmit timed out, status %08x, resetting...\n",\r\nioread32(ioaddr + IntrStatus));\r\n{\r\nint i;\r\nprintk(KERN_DEBUG " Rx ring %p: ", np->rx_ring);\r\nfor (i = 0; i < RX_RING_SIZE; i++)\r\nprintk(KERN_CONT " %08x", (unsigned int)np->rx_ring[i].status);\r\nprintk(KERN_CONT "\n");\r\nprintk(KERN_DEBUG " Tx ring %p: ", np->tx_ring);\r\nfor (i = 0; i < TX_RING_SIZE; i++)\r\nprintk(KERN_CONT " %08x", np->tx_ring[i].status);\r\nprintk(KERN_CONT "\n");\r\n}\r\nprintk(KERN_DEBUG "Tx cur %d Tx dirty %d Tx Full %d, q bytes %d\n",\r\nnp->cur_tx, np->dirty_tx, np->tx_full, np->tx_q_bytes);\r\nprintk(KERN_DEBUG "Tx Descriptor addr %xh\n", ioread32(ioaddr+0x4C));\r\ndisable_irq(irq);\r\nspin_lock_irq(&np->lock);\r\niowrite32(1, np->base_addr+PCIBusCfg);\r\nudelay(1);\r\nfree_rxtx_rings(np);\r\ninit_rxtx_rings(dev);\r\ninit_registers(dev);\r\nspin_unlock_irq(&np->lock);\r\nenable_irq(irq);\r\nnetif_wake_queue(dev);\r\ndev->trans_start = jiffies;\r\nnp->stats.tx_errors++;\r\n}\r\nstatic int alloc_ringdesc(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nnp->rx_buf_sz = (dev->mtu <= 1500 ? PKT_BUF_SZ : dev->mtu + 32);\r\nnp->rx_ring = pci_alloc_consistent(np->pci_dev,\r\nsizeof(struct w840_rx_desc)*RX_RING_SIZE +\r\nsizeof(struct w840_tx_desc)*TX_RING_SIZE,\r\n&np->ring_dma_addr);\r\nif(!np->rx_ring)\r\nreturn -ENOMEM;\r\ninit_rxtx_rings(dev);\r\nreturn 0;\r\n}\r\nstatic void free_ringdesc(struct netdev_private *np)\r\n{\r\npci_free_consistent(np->pci_dev,\r\nsizeof(struct w840_rx_desc)*RX_RING_SIZE +\r\nsizeof(struct w840_tx_desc)*TX_RING_SIZE,\r\nnp->rx_ring, np->ring_dma_addr);\r\n}\r\nstatic netdev_tx_t start_tx(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nunsigned entry;\r\nentry = np->cur_tx % TX_RING_SIZE;\r\nnp->tx_addr[entry] = pci_map_single(np->pci_dev,\r\nskb->data,skb->len, PCI_DMA_TODEVICE);\r\nnp->tx_skbuff[entry] = skb;\r\nnp->tx_ring[entry].buffer1 = np->tx_addr[entry];\r\nif (skb->len < TX_BUFLIMIT) {\r\nnp->tx_ring[entry].length = DescWholePkt | skb->len;\r\n} else {\r\nint len = skb->len - TX_BUFLIMIT;\r\nnp->tx_ring[entry].buffer2 = np->tx_addr[entry]+TX_BUFLIMIT;\r\nnp->tx_ring[entry].length = DescWholePkt | (len << 11) | TX_BUFLIMIT;\r\n}\r\nif(entry == TX_RING_SIZE-1)\r\nnp->tx_ring[entry].length |= DescEndRing;\r\nspin_lock_irq(&np->lock);\r\nnp->cur_tx++;\r\nwmb();\r\nnp->tx_ring[entry].status = DescOwned;\r\nwmb();\r\niowrite32(0, np->base_addr + TxStartDemand);\r\nnp->tx_q_bytes += skb->len;\r\nif (np->cur_tx - np->dirty_tx > TX_QUEUE_LEN ||\r\n((np->drv_flags & HasBrokenTx) && np->tx_q_bytes > TX_BUG_FIFO_LIMIT)) {\r\nnetif_stop_queue(dev);\r\nwmb();\r\nnp->tx_full = 1;\r\n}\r\nspin_unlock_irq(&np->lock);\r\nif (debug > 4) {\r\nnetdev_dbg(dev, "Transmit frame #%d queued in slot %d\n",\r\nnp->cur_tx, entry);\r\n}\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void netdev_tx_done(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nfor (; np->cur_tx - np->dirty_tx > 0; np->dirty_tx++) {\r\nint entry = np->dirty_tx % TX_RING_SIZE;\r\nint tx_status = np->tx_ring[entry].status;\r\nif (tx_status < 0)\r\nbreak;\r\nif (tx_status & 0x8000) {\r\n#ifndef final_version\r\nif (debug > 1)\r\nnetdev_dbg(dev, "Transmit error, Tx status %08x\n",\r\ntx_status);\r\n#endif\r\nnp->stats.tx_errors++;\r\nif (tx_status & 0x0104) np->stats.tx_aborted_errors++;\r\nif (tx_status & 0x0C80) np->stats.tx_carrier_errors++;\r\nif (tx_status & 0x0200) np->stats.tx_window_errors++;\r\nif (tx_status & 0x0002) np->stats.tx_fifo_errors++;\r\nif ((tx_status & 0x0080) && np->mii_if.full_duplex == 0)\r\nnp->stats.tx_heartbeat_errors++;\r\n} else {\r\n#ifndef final_version\r\nif (debug > 3)\r\nnetdev_dbg(dev, "Transmit slot %d ok, Tx status %08x\n",\r\nentry, tx_status);\r\n#endif\r\nnp->stats.tx_bytes += np->tx_skbuff[entry]->len;\r\nnp->stats.collisions += (tx_status >> 3) & 15;\r\nnp->stats.tx_packets++;\r\n}\r\npci_unmap_single(np->pci_dev,np->tx_addr[entry],\r\nnp->tx_skbuff[entry]->len,\r\nPCI_DMA_TODEVICE);\r\nnp->tx_q_bytes -= np->tx_skbuff[entry]->len;\r\ndev_kfree_skb_irq(np->tx_skbuff[entry]);\r\nnp->tx_skbuff[entry] = NULL;\r\n}\r\nif (np->tx_full &&\r\nnp->cur_tx - np->dirty_tx < TX_QUEUE_LEN_RESTART &&\r\nnp->tx_q_bytes < TX_BUG_FIFO_LIMIT) {\r\nnp->tx_full = 0;\r\nwmb();\r\nnetif_wake_queue(dev);\r\n}\r\n}\r\nstatic irqreturn_t intr_handler(int irq, void *dev_instance)\r\n{\r\nstruct net_device *dev = (struct net_device *)dev_instance;\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *ioaddr = np->base_addr;\r\nint work_limit = max_interrupt_work;\r\nint handled = 0;\r\nif (!netif_device_present(dev))\r\nreturn IRQ_NONE;\r\ndo {\r\nu32 intr_status = ioread32(ioaddr + IntrStatus);\r\niowrite32(intr_status & 0x001ffff, ioaddr + IntrStatus);\r\nif (debug > 4)\r\nnetdev_dbg(dev, "Interrupt, status %04x\n", intr_status);\r\nif ((intr_status & (NormalIntr|AbnormalIntr)) == 0)\r\nbreak;\r\nhandled = 1;\r\nif (intr_status & (RxIntr | RxNoBuf))\r\nnetdev_rx(dev);\r\nif (intr_status & RxNoBuf)\r\niowrite32(0, ioaddr + RxStartDemand);\r\nif (intr_status & (TxNoBuf | TxIntr) &&\r\nnp->cur_tx != np->dirty_tx) {\r\nspin_lock(&np->lock);\r\nnetdev_tx_done(dev);\r\nspin_unlock(&np->lock);\r\n}\r\nif (intr_status & (AbnormalIntr | TxFIFOUnderflow | SystemError |\r\nTimerInt | TxDied))\r\nnetdev_error(dev, intr_status);\r\nif (--work_limit < 0) {\r\ndev_warn(&dev->dev,\r\n"Too much work at interrupt, status=0x%04x\n",\r\nintr_status);\r\nspin_lock(&np->lock);\r\nif (netif_device_present(dev)) {\r\niowrite32(AbnormalIntr | TimerInt, ioaddr + IntrEnable);\r\niowrite32(10, ioaddr + GPTimer);\r\n}\r\nspin_unlock(&np->lock);\r\nbreak;\r\n}\r\n} while (1);\r\nif (debug > 3)\r\nnetdev_dbg(dev, "exiting interrupt, status=%#4.4x\n",\r\nioread32(ioaddr + IntrStatus));\r\nreturn IRQ_RETVAL(handled);\r\n}\r\nstatic int netdev_rx(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nint entry = np->cur_rx % RX_RING_SIZE;\r\nint work_limit = np->dirty_rx + RX_RING_SIZE - np->cur_rx;\r\nif (debug > 4) {\r\nnetdev_dbg(dev, " In netdev_rx(), entry %d status %04x\n",\r\nentry, np->rx_ring[entry].status);\r\n}\r\nwhile (--work_limit >= 0) {\r\nstruct w840_rx_desc *desc = np->rx_head_desc;\r\ns32 status = desc->status;\r\nif (debug > 4)\r\nnetdev_dbg(dev, " netdev_rx() status was %08x\n",\r\nstatus);\r\nif (status < 0)\r\nbreak;\r\nif ((status & 0x38008300) != 0x0300) {\r\nif ((status & 0x38000300) != 0x0300) {\r\nif ((status & 0xffff) != 0x7fff) {\r\ndev_warn(&dev->dev,\r\n"Oversized Ethernet frame spanned multiple buffers, entry %#x status %04x!\n",\r\nnp->cur_rx, status);\r\nnp->stats.rx_length_errors++;\r\n}\r\n} else if (status & 0x8000) {\r\nif (debug > 2)\r\nnetdev_dbg(dev, "Receive error, Rx status %08x\n",\r\nstatus);\r\nnp->stats.rx_errors++;\r\nif (status & 0x0890) np->stats.rx_length_errors++;\r\nif (status & 0x004C) np->stats.rx_frame_errors++;\r\nif (status & 0x0002) np->stats.rx_crc_errors++;\r\n}\r\n} else {\r\nstruct sk_buff *skb;\r\nint pkt_len = ((status >> 16) & 0x7ff) - 4;\r\n#ifndef final_version\r\nif (debug > 4)\r\nnetdev_dbg(dev, " netdev_rx() normal Rx pkt length %d status %x\n",\r\npkt_len, status);\r\n#endif\r\nif (pkt_len < rx_copybreak &&\r\n(skb = netdev_alloc_skb(dev, pkt_len + 2)) != NULL) {\r\nskb_reserve(skb, 2);\r\npci_dma_sync_single_for_cpu(np->pci_dev,np->rx_addr[entry],\r\nnp->rx_skbuff[entry]->len,\r\nPCI_DMA_FROMDEVICE);\r\nskb_copy_to_linear_data(skb, np->rx_skbuff[entry]->data, pkt_len);\r\nskb_put(skb, pkt_len);\r\npci_dma_sync_single_for_device(np->pci_dev,np->rx_addr[entry],\r\nnp->rx_skbuff[entry]->len,\r\nPCI_DMA_FROMDEVICE);\r\n} else {\r\npci_unmap_single(np->pci_dev,np->rx_addr[entry],\r\nnp->rx_skbuff[entry]->len,\r\nPCI_DMA_FROMDEVICE);\r\nskb_put(skb = np->rx_skbuff[entry], pkt_len);\r\nnp->rx_skbuff[entry] = NULL;\r\n}\r\n#ifndef final_version\r\nif (debug > 5)\r\nnetdev_dbg(dev, " Rx data %pM %pM %02x%02x %pI4\n",\r\n&skb->data[0], &skb->data[6],\r\nskb->data[12], skb->data[13],\r\n&skb->data[14]);\r\n#endif\r\nskb->protocol = eth_type_trans(skb, dev);\r\nnetif_rx(skb);\r\nnp->stats.rx_packets++;\r\nnp->stats.rx_bytes += pkt_len;\r\n}\r\nentry = (++np->cur_rx) % RX_RING_SIZE;\r\nnp->rx_head_desc = &np->rx_ring[entry];\r\n}\r\nfor (; np->cur_rx - np->dirty_rx > 0; np->dirty_rx++) {\r\nstruct sk_buff *skb;\r\nentry = np->dirty_rx % RX_RING_SIZE;\r\nif (np->rx_skbuff[entry] == NULL) {\r\nskb = netdev_alloc_skb(dev, np->rx_buf_sz);\r\nnp->rx_skbuff[entry] = skb;\r\nif (skb == NULL)\r\nbreak;\r\nnp->rx_addr[entry] = pci_map_single(np->pci_dev,\r\nskb->data,\r\nnp->rx_buf_sz, PCI_DMA_FROMDEVICE);\r\nnp->rx_ring[entry].buffer1 = np->rx_addr[entry];\r\n}\r\nwmb();\r\nnp->rx_ring[entry].status = DescOwned;\r\n}\r\nreturn 0;\r\n}\r\nstatic void netdev_error(struct net_device *dev, int intr_status)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *ioaddr = np->base_addr;\r\nif (debug > 2)\r\nnetdev_dbg(dev, "Abnormal event, %08x\n", intr_status);\r\nif (intr_status == 0xffffffff)\r\nreturn;\r\nspin_lock(&np->lock);\r\nif (intr_status & TxFIFOUnderflow) {\r\nint new;\r\n#if 0\r\nnew = np->csr6 + 0x4000;\r\n#else\r\nnew = (np->csr6 >> 14)&0x7f;\r\nif (new < 64)\r\nnew *= 2;\r\nelse\r\nnew = 127;\r\nnew = (np->csr6 & ~(0x7F << 14)) | (new<<14);\r\n#endif\r\nnetdev_dbg(dev, "Tx underflow, new csr6 %08x\n", new);\r\nupdate_csr6(dev, new);\r\n}\r\nif (intr_status & RxDied) {\r\nnp->stats.rx_errors++;\r\n}\r\nif (intr_status & TimerInt) {\r\nif (netif_device_present(dev))\r\niowrite32(0x1A0F5, ioaddr + IntrEnable);\r\n}\r\nnp->stats.rx_missed_errors += ioread32(ioaddr + RxMissed) & 0xffff;\r\niowrite32(0, ioaddr + RxStartDemand);\r\nspin_unlock(&np->lock);\r\n}\r\nstatic struct net_device_stats *get_stats(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *ioaddr = np->base_addr;\r\nspin_lock_irq(&np->lock);\r\nif (netif_running(dev) && netif_device_present(dev))\r\nnp->stats.rx_missed_errors += ioread32(ioaddr + RxMissed) & 0xffff;\r\nspin_unlock_irq(&np->lock);\r\nreturn &np->stats;\r\n}\r\nstatic u32 __set_rx_mode(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *ioaddr = np->base_addr;\r\nu32 mc_filter[2];\r\nu32 rx_mode;\r\nif (dev->flags & IFF_PROMISC) {\r\nmemset(mc_filter, 0xff, sizeof(mc_filter));\r\nrx_mode = RxAcceptBroadcast | AcceptMulticast | RxAcceptAllPhys\r\n| AcceptMyPhys;\r\n} else if ((netdev_mc_count(dev) > multicast_filter_limit) ||\r\n(dev->flags & IFF_ALLMULTI)) {\r\nmemset(mc_filter, 0xff, sizeof(mc_filter));\r\nrx_mode = RxAcceptBroadcast | AcceptMulticast | AcceptMyPhys;\r\n} else {\r\nstruct netdev_hw_addr *ha;\r\nmemset(mc_filter, 0, sizeof(mc_filter));\r\nnetdev_for_each_mc_addr(ha, dev) {\r\nint filbit;\r\nfilbit = (ether_crc(ETH_ALEN, ha->addr) >> 26) ^ 0x3F;\r\nfilbit &= 0x3f;\r\nmc_filter[filbit >> 5] |= 1 << (filbit & 31);\r\n}\r\nrx_mode = RxAcceptBroadcast | AcceptMulticast | AcceptMyPhys;\r\n}\r\niowrite32(mc_filter[0], ioaddr + MulticastFilter0);\r\niowrite32(mc_filter[1], ioaddr + MulticastFilter1);\r\nreturn rx_mode;\r\n}\r\nstatic void set_rx_mode(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nu32 rx_mode = __set_rx_mode(dev);\r\nspin_lock_irq(&np->lock);\r\nupdate_csr6(dev, (np->csr6 & ~0x00F8) | rx_mode);\r\nspin_unlock_irq(&np->lock);\r\n}\r\nstatic void netdev_get_drvinfo (struct net_device *dev, struct ethtool_drvinfo *info)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nstrlcpy(info->driver, DRV_NAME, sizeof(info->driver));\r\nstrlcpy(info->version, DRV_VERSION, sizeof(info->version));\r\nstrlcpy(info->bus_info, pci_name(np->pci_dev), sizeof(info->bus_info));\r\n}\r\nstatic int netdev_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nint rc;\r\nspin_lock_irq(&np->lock);\r\nrc = mii_ethtool_gset(&np->mii_if, cmd);\r\nspin_unlock_irq(&np->lock);\r\nreturn rc;\r\n}\r\nstatic int netdev_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nint rc;\r\nspin_lock_irq(&np->lock);\r\nrc = mii_ethtool_sset(&np->mii_if, cmd);\r\nspin_unlock_irq(&np->lock);\r\nreturn rc;\r\n}\r\nstatic int netdev_nway_reset(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nreturn mii_nway_restart(&np->mii_if);\r\n}\r\nstatic u32 netdev_get_link(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nreturn mii_link_ok(&np->mii_if);\r\n}\r\nstatic u32 netdev_get_msglevel(struct net_device *dev)\r\n{\r\nreturn debug;\r\n}\r\nstatic void netdev_set_msglevel(struct net_device *dev, u32 value)\r\n{\r\ndebug = value;\r\n}\r\nstatic int netdev_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)\r\n{\r\nstruct mii_ioctl_data *data = if_mii(rq);\r\nstruct netdev_private *np = netdev_priv(dev);\r\nswitch(cmd) {\r\ncase SIOCGMIIPHY:\r\ndata->phy_id = ((struct netdev_private *)netdev_priv(dev))->phys[0] & 0x1f;\r\ncase SIOCGMIIREG:\r\nspin_lock_irq(&np->lock);\r\ndata->val_out = mdio_read(dev, data->phy_id & 0x1f, data->reg_num & 0x1f);\r\nspin_unlock_irq(&np->lock);\r\nreturn 0;\r\ncase SIOCSMIIREG:\r\nspin_lock_irq(&np->lock);\r\nmdio_write(dev, data->phy_id & 0x1f, data->reg_num & 0x1f, data->val_in);\r\nspin_unlock_irq(&np->lock);\r\nreturn 0;\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nstatic int netdev_close(struct net_device *dev)\r\n{\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *ioaddr = np->base_addr;\r\nnetif_stop_queue(dev);\r\nif (debug > 1) {\r\nnetdev_dbg(dev, "Shutting down ethercard, status was %08x Config %08x\n",\r\nioread32(ioaddr + IntrStatus),\r\nioread32(ioaddr + NetworkConfig));\r\nnetdev_dbg(dev, "Queue pointers were Tx %d / %d, Rx %d / %d\n",\r\nnp->cur_tx, np->dirty_tx,\r\nnp->cur_rx, np->dirty_rx);\r\n}\r\nspin_lock_irq(&np->lock);\r\nnetif_device_detach(dev);\r\nupdate_csr6(dev, 0);\r\niowrite32(0x0000, ioaddr + IntrEnable);\r\nspin_unlock_irq(&np->lock);\r\nfree_irq(np->pci_dev->irq, dev);\r\nwmb();\r\nnetif_device_attach(dev);\r\nif (ioread32(ioaddr + NetworkConfig) != 0xffffffff)\r\nnp->stats.rx_missed_errors += ioread32(ioaddr + RxMissed) & 0xffff;\r\n#ifdef __i386__\r\nif (debug > 2) {\r\nint i;\r\nprintk(KERN_DEBUG" Tx ring at %p:\n", np->tx_ring);\r\nfor (i = 0; i < TX_RING_SIZE; i++)\r\nprintk(KERN_DEBUG " #%d desc. %04x %04x %08x\n",\r\ni, np->tx_ring[i].length,\r\nnp->tx_ring[i].status, np->tx_ring[i].buffer1);\r\nprintk(KERN_DEBUG " Rx ring %p:\n", np->rx_ring);\r\nfor (i = 0; i < RX_RING_SIZE; i++) {\r\nprintk(KERN_DEBUG " #%d desc. %04x %04x %08x\n",\r\ni, np->rx_ring[i].length,\r\nnp->rx_ring[i].status, np->rx_ring[i].buffer1);\r\n}\r\n}\r\n#endif\r\ndel_timer_sync(&np->timer);\r\nfree_rxtx_rings(np);\r\nfree_ringdesc(np);\r\nreturn 0;\r\n}\r\nstatic void w840_remove1(struct pci_dev *pdev)\r\n{\r\nstruct net_device *dev = pci_get_drvdata(pdev);\r\nif (dev) {\r\nstruct netdev_private *np = netdev_priv(dev);\r\nunregister_netdev(dev);\r\npci_release_regions(pdev);\r\npci_iounmap(pdev, np->base_addr);\r\nfree_netdev(dev);\r\n}\r\npci_set_drvdata(pdev, NULL);\r\n}\r\nstatic int w840_suspend (struct pci_dev *pdev, pm_message_t state)\r\n{\r\nstruct net_device *dev = pci_get_drvdata (pdev);\r\nstruct netdev_private *np = netdev_priv(dev);\r\nvoid __iomem *ioaddr = np->base_addr;\r\nrtnl_lock();\r\nif (netif_running (dev)) {\r\ndel_timer_sync(&np->timer);\r\nspin_lock_irq(&np->lock);\r\nnetif_device_detach(dev);\r\nupdate_csr6(dev, 0);\r\niowrite32(0, ioaddr + IntrEnable);\r\nspin_unlock_irq(&np->lock);\r\nsynchronize_irq(np->pci_dev->irq);\r\nnetif_tx_disable(dev);\r\nnp->stats.rx_missed_errors += ioread32(ioaddr + RxMissed) & 0xffff;\r\nBUG_ON(np->csr6 || ioread32(ioaddr + IntrEnable));\r\nfree_rxtx_rings(np);\r\n} else {\r\nnetif_device_detach(dev);\r\n}\r\nrtnl_unlock();\r\nreturn 0;\r\n}\r\nstatic int w840_resume (struct pci_dev *pdev)\r\n{\r\nstruct net_device *dev = pci_get_drvdata (pdev);\r\nstruct netdev_private *np = netdev_priv(dev);\r\nint retval = 0;\r\nrtnl_lock();\r\nif (netif_device_present(dev))\r\ngoto out;\r\nif (netif_running(dev)) {\r\nif ((retval = pci_enable_device(pdev))) {\r\ndev_err(&dev->dev,\r\n"pci_enable_device failed in resume\n");\r\ngoto out;\r\n}\r\nspin_lock_irq(&np->lock);\r\niowrite32(1, np->base_addr+PCIBusCfg);\r\nioread32(np->base_addr+PCIBusCfg);\r\nudelay(1);\r\nnetif_device_attach(dev);\r\ninit_rxtx_rings(dev);\r\ninit_registers(dev);\r\nspin_unlock_irq(&np->lock);\r\nnetif_wake_queue(dev);\r\nmod_timer(&np->timer, jiffies + 1*HZ);\r\n} else {\r\nnetif_device_attach(dev);\r\n}\r\nout:\r\nrtnl_unlock();\r\nreturn retval;\r\n}\r\nstatic int __init w840_init(void)\r\n{\r\nprintk(version);\r\nreturn pci_register_driver(&w840_driver);\r\n}\r\nstatic void __exit w840_exit(void)\r\n{\r\npci_unregister_driver(&w840_driver);\r\n}
