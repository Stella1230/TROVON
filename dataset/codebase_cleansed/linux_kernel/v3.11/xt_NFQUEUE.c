static unsigned int\r\nnfqueue_tg(struct sk_buff *skb, const struct xt_action_param *par)\r\n{\r\nconst struct xt_NFQ_info *tinfo = par->targinfo;\r\nreturn NF_QUEUE_NR(tinfo->queuenum);\r\n}\r\nstatic u32 hash_v4(const struct sk_buff *skb)\r\n{\r\nconst struct iphdr *iph = ip_hdr(skb);\r\nif ((__force u32)iph->saddr < (__force u32)iph->daddr)\r\nreturn jhash_3words((__force u32)iph->saddr,\r\n(__force u32)iph->daddr, iph->protocol, jhash_initval);\r\nreturn jhash_3words((__force u32)iph->daddr,\r\n(__force u32)iph->saddr, iph->protocol, jhash_initval);\r\n}\r\nstatic u32 hash_v6(const struct sk_buff *skb)\r\n{\r\nconst struct ipv6hdr *ip6h = ipv6_hdr(skb);\r\nu32 a, b, c;\r\nif ((__force u32)ip6h->saddr.s6_addr32[3] <\r\n(__force u32)ip6h->daddr.s6_addr32[3]) {\r\na = (__force u32) ip6h->saddr.s6_addr32[3];\r\nb = (__force u32) ip6h->daddr.s6_addr32[3];\r\n} else {\r\nb = (__force u32) ip6h->saddr.s6_addr32[3];\r\na = (__force u32) ip6h->daddr.s6_addr32[3];\r\n}\r\nif ((__force u32)ip6h->saddr.s6_addr32[1] <\r\n(__force u32)ip6h->daddr.s6_addr32[1])\r\nc = (__force u32) ip6h->saddr.s6_addr32[1];\r\nelse\r\nc = (__force u32) ip6h->daddr.s6_addr32[1];\r\nreturn jhash_3words(a, b, c, jhash_initval);\r\n}\r\nstatic u32\r\nnfqueue_hash(const struct sk_buff *skb, const struct xt_action_param *par)\r\n{\r\nconst struct xt_NFQ_info_v1 *info = par->targinfo;\r\nu32 queue = info->queuenum;\r\nif (par->family == NFPROTO_IPV4)\r\nqueue += ((u64) hash_v4(skb) * info->queues_total) >> 32;\r\n#if IS_ENABLED(CONFIG_IP6_NF_IPTABLES)\r\nelse if (par->family == NFPROTO_IPV6)\r\nqueue += ((u64) hash_v6(skb) * info->queues_total) >> 32;\r\n#endif\r\nreturn queue;\r\n}\r\nstatic unsigned int\r\nnfqueue_tg_v1(struct sk_buff *skb, const struct xt_action_param *par)\r\n{\r\nconst struct xt_NFQ_info_v1 *info = par->targinfo;\r\nu32 queue = info->queuenum;\r\nif (info->queues_total > 1)\r\nqueue = nfqueue_hash(skb, par);\r\nreturn NF_QUEUE_NR(queue);\r\n}\r\nstatic unsigned int\r\nnfqueue_tg_v2(struct sk_buff *skb, const struct xt_action_param *par)\r\n{\r\nconst struct xt_NFQ_info_v2 *info = par->targinfo;\r\nunsigned int ret = nfqueue_tg_v1(skb, par);\r\nif (info->bypass)\r\nret |= NF_VERDICT_FLAG_QUEUE_BYPASS;\r\nreturn ret;\r\n}\r\nstatic int nfqueue_tg_check(const struct xt_tgchk_param *par)\r\n{\r\nconst struct xt_NFQ_info_v3 *info = par->targinfo;\r\nu32 maxid;\r\nif (unlikely(!rnd_inited)) {\r\nget_random_bytes(&jhash_initval, sizeof(jhash_initval));\r\nrnd_inited = true;\r\n}\r\nif (info->queues_total == 0) {\r\npr_err("NFQUEUE: number of total queues is 0\n");\r\nreturn -EINVAL;\r\n}\r\nmaxid = info->queues_total - 1 + info->queuenum;\r\nif (maxid > 0xffff) {\r\npr_err("NFQUEUE: number of queues (%u) out of range (got %u)\n",\r\ninfo->queues_total, maxid);\r\nreturn -ERANGE;\r\n}\r\nif (par->target->revision == 2 && info->flags > 1)\r\nreturn -EINVAL;\r\nif (par->target->revision == 3 && info->flags & ~NFQ_FLAG_MASK)\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic unsigned int\r\nnfqueue_tg_v3(struct sk_buff *skb, const struct xt_action_param *par)\r\n{\r\nconst struct xt_NFQ_info_v3 *info = par->targinfo;\r\nu32 queue = info->queuenum;\r\nif (info->queues_total > 1) {\r\nif (info->flags & NFQ_FLAG_CPU_FANOUT) {\r\nint cpu = smp_processor_id();\r\nqueue = info->queuenum + cpu % info->queues_total;\r\n} else\r\nqueue = nfqueue_hash(skb, par);\r\n}\r\nreturn NF_QUEUE_NR(queue);\r\n}\r\nstatic int __init nfqueue_tg_init(void)\r\n{\r\nreturn xt_register_targets(nfqueue_tg_reg, ARRAY_SIZE(nfqueue_tg_reg));\r\n}\r\nstatic void __exit nfqueue_tg_exit(void)\r\n{\r\nxt_unregister_targets(nfqueue_tg_reg, ARRAY_SIZE(nfqueue_tg_reg));\r\n}
