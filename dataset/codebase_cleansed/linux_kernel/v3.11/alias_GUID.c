void mlx4_ib_update_cache_on_guid_change(struct mlx4_ib_dev *dev, int block_num,\r\nu8 port_num, u8 *p_data)\r\n{\r\nint i;\r\nu64 guid_indexes;\r\nint slave_id;\r\nint port_index = port_num - 1;\r\nif (!mlx4_is_master(dev->dev))\r\nreturn;\r\nguid_indexes = be64_to_cpu((__force __be64) dev->sriov.alias_guid.\r\nports_guid[port_num - 1].\r\nall_rec_per_port[block_num].guid_indexes);\r\npr_debug("port: %d, guid_indexes: 0x%llx\n", port_num, guid_indexes);\r\nfor (i = 0; i < NUM_ALIAS_GUID_IN_REC; i++) {\r\nif (test_bit(i + 4, (unsigned long *)&guid_indexes)) {\r\nslave_id = (block_num * NUM_ALIAS_GUID_IN_REC) + i ;\r\nif (slave_id >= dev->dev->num_slaves) {\r\npr_debug("The last slave: %d\n", slave_id);\r\nreturn;\r\n}\r\nmemcpy(&dev->sriov.demux[port_index].guid_cache[slave_id],\r\n&p_data[i * GUID_REC_SIZE],\r\nGUID_REC_SIZE);\r\n} else\r\npr_debug("Guid number: %d in block: %d"\r\n" was not updated\n", i, block_num);\r\n}\r\n}\r\nstatic __be64 get_cached_alias_guid(struct mlx4_ib_dev *dev, int port, int index)\r\n{\r\nif (index >= NUM_ALIAS_GUID_PER_PORT) {\r\npr_err("%s: ERROR: asked for index:%d\n", __func__, index);\r\nreturn (__force __be64) -1;\r\n}\r\nreturn *(__be64 *)&dev->sriov.demux[port - 1].guid_cache[index];\r\n}\r\nib_sa_comp_mask mlx4_ib_get_aguid_comp_mask_from_ix(int index)\r\n{\r\nreturn IB_SA_COMP_MASK(4 + index);\r\n}\r\nvoid mlx4_ib_notify_slaves_on_guid_change(struct mlx4_ib_dev *dev,\r\nint block_num, u8 port_num,\r\nu8 *p_data)\r\n{\r\nint i;\r\nu64 guid_indexes;\r\nint slave_id;\r\nenum slave_port_state new_state;\r\nenum slave_port_state prev_state;\r\n__be64 tmp_cur_ag, form_cache_ag;\r\nenum slave_port_gen_event gen_event;\r\nif (!mlx4_is_master(dev->dev))\r\nreturn;\r\nguid_indexes = be64_to_cpu((__force __be64) dev->sriov.alias_guid.\r\nports_guid[port_num - 1].\r\nall_rec_per_port[block_num].guid_indexes);\r\npr_debug("port: %d, guid_indexes: 0x%llx\n", port_num, guid_indexes);\r\nfor (i = 0; i < NUM_ALIAS_GUID_IN_REC; i++) {\r\nif (!(test_bit(i + 4, (unsigned long *)&guid_indexes)))\r\ncontinue;\r\nslave_id = (block_num * NUM_ALIAS_GUID_IN_REC) + i ;\r\nif (slave_id >= dev->dev->num_slaves)\r\nreturn;\r\ntmp_cur_ag = *(__be64 *)&p_data[i * GUID_REC_SIZE];\r\nform_cache_ag = get_cached_alias_guid(dev, port_num,\r\n(NUM_ALIAS_GUID_IN_REC * block_num) + i);\r\nif (tmp_cur_ag != form_cache_ag)\r\ncontinue;\r\nmlx4_gen_guid_change_eqe(dev->dev, slave_id, port_num);\r\nif (tmp_cur_ag != MLX4_NOT_SET_GUID) {\r\nprev_state = mlx4_get_slave_port_state(dev->dev, slave_id, port_num);\r\nnew_state = set_and_calc_slave_port_state(dev->dev, slave_id, port_num,\r\nMLX4_PORT_STATE_IB_PORT_STATE_EVENT_GID_VALID,\r\n&gen_event);\r\npr_debug("slave: %d, port: %d prev_port_state: %d,"\r\n" new_port_state: %d, gen_event: %d\n",\r\nslave_id, port_num, prev_state, new_state, gen_event);\r\nif (gen_event == SLAVE_PORT_GEN_EVENT_UP) {\r\npr_debug("sending PORT_UP event to slave: %d, port: %d\n",\r\nslave_id, port_num);\r\nmlx4_gen_port_state_change_eqe(dev->dev, slave_id,\r\nport_num, MLX4_PORT_CHANGE_SUBTYPE_ACTIVE);\r\n}\r\n} else {\r\nset_and_calc_slave_port_state(dev->dev, slave_id, port_num,\r\nMLX4_PORT_STATE_IB_EVENT_GID_INVALID,\r\n&gen_event);\r\npr_debug("sending PORT DOWN event to slave: %d, port: %d\n",\r\nslave_id, port_num);\r\nmlx4_gen_port_state_change_eqe(dev->dev, slave_id, port_num,\r\nMLX4_PORT_CHANGE_SUBTYPE_DOWN);\r\n}\r\n}\r\n}\r\nstatic void aliasguid_query_handler(int status,\r\nstruct ib_sa_guidinfo_rec *guid_rec,\r\nvoid *context)\r\n{\r\nstruct mlx4_ib_dev *dev;\r\nstruct mlx4_alias_guid_work_context *cb_ctx = context;\r\nu8 port_index ;\r\nint i;\r\nstruct mlx4_sriov_alias_guid_info_rec_det *rec;\r\nunsigned long flags, flags1;\r\nif (!context)\r\nreturn;\r\ndev = cb_ctx->dev;\r\nport_index = cb_ctx->port - 1;\r\nrec = &dev->sriov.alias_guid.ports_guid[port_index].\r\nall_rec_per_port[cb_ctx->block_num];\r\nif (status) {\r\nrec->status = MLX4_GUID_INFO_STATUS_IDLE;\r\npr_debug("(port: %d) failed: status = %d\n",\r\ncb_ctx->port, status);\r\ngoto out;\r\n}\r\nif (guid_rec->block_num != cb_ctx->block_num) {\r\npr_err("block num mismatch: %d != %d\n",\r\ncb_ctx->block_num, guid_rec->block_num);\r\ngoto out;\r\n}\r\npr_debug("lid/port: %d/%d, block_num: %d\n",\r\nbe16_to_cpu(guid_rec->lid), cb_ctx->port,\r\nguid_rec->block_num);\r\nrec = &dev->sriov.alias_guid.ports_guid[port_index].\r\nall_rec_per_port[guid_rec->block_num];\r\nrec->status = MLX4_GUID_INFO_STATUS_SET;\r\nrec->method = MLX4_GUID_INFO_RECORD_SET;\r\nfor (i = 0 ; i < NUM_ALIAS_GUID_IN_REC; i++) {\r\n__be64 tmp_cur_ag;\r\ntmp_cur_ag = *(__be64 *)&guid_rec->guid_info_list[i * GUID_REC_SIZE];\r\nif (tmp_cur_ag == MLX4_NOT_SET_GUID) {\r\nmlx4_ib_warn(&dev->ib_dev, "%s:Record num %d in "\r\n"block_num: %d was declined by SM, "\r\n"ownership by %d (0 = driver, 1=sysAdmin,"\r\n" 2=None)\n", __func__, i,\r\nguid_rec->block_num, rec->ownership);\r\nif (rec->ownership == MLX4_GUID_DRIVER_ASSIGN) {\r\n*(__be64 *)&rec->all_recs[i * GUID_REC_SIZE] =\r\nMLX4_NOT_SET_GUID;\r\nrec->status = MLX4_GUID_INFO_STATUS_IDLE;\r\nrec->guid_indexes |= mlx4_ib_get_aguid_comp_mask_from_ix(i);\r\n}\r\n} else {\r\nif (rec->ownership == MLX4_GUID_SYSADMIN_ASSIGN &&\r\ntmp_cur_ag != *(__be64 *)&rec->all_recs[i * GUID_REC_SIZE]) {\r\nmlx4_ib_warn(&dev->ib_dev, "%s: Failed to set"\r\n" admin guid after SysAdmin "\r\n"configuration. "\r\n"Record num %d in block_num:%d "\r\n"was declined by SM, "\r\n"new val(0x%llx) was kept\n",\r\n__func__, i,\r\nguid_rec->block_num,\r\nbe64_to_cpu(*(__be64 *) &\r\nrec->all_recs[i * GUID_REC_SIZE]));\r\n} else {\r\nmemcpy(&rec->all_recs[i * GUID_REC_SIZE],\r\n&guid_rec->guid_info_list[i * GUID_REC_SIZE],\r\nGUID_REC_SIZE);\r\n}\r\n}\r\n}\r\nmlx4_ib_notify_slaves_on_guid_change(dev, guid_rec->block_num,\r\ncb_ctx->port,\r\nguid_rec->guid_info_list);\r\nout:\r\nspin_lock_irqsave(&dev->sriov.going_down_lock, flags);\r\nspin_lock_irqsave(&dev->sriov.alias_guid.ag_work_lock, flags1);\r\nif (!dev->sriov.is_going_down)\r\nqueue_delayed_work(dev->sriov.alias_guid.ports_guid[port_index].wq,\r\n&dev->sriov.alias_guid.ports_guid[port_index].\r\nalias_guid_work, 0);\r\nif (cb_ctx->sa_query) {\r\nlist_del(&cb_ctx->list);\r\nkfree(cb_ctx);\r\n} else\r\ncomplete(&cb_ctx->done);\r\nspin_unlock_irqrestore(&dev->sriov.alias_guid.ag_work_lock, flags1);\r\nspin_unlock_irqrestore(&dev->sriov.going_down_lock, flags);\r\n}\r\nstatic void invalidate_guid_record(struct mlx4_ib_dev *dev, u8 port, int index)\r\n{\r\nint i;\r\nu64 cur_admin_val;\r\nib_sa_comp_mask comp_mask = 0;\r\ndev->sriov.alias_guid.ports_guid[port - 1].all_rec_per_port[index].status\r\n= MLX4_GUID_INFO_STATUS_IDLE;\r\ndev->sriov.alias_guid.ports_guid[port - 1].all_rec_per_port[index].method\r\n= MLX4_GUID_INFO_RECORD_SET;\r\nfor (i = 0; i < NUM_ALIAS_GUID_IN_REC; i++) {\r\ncur_admin_val =\r\n*(u64 *)&dev->sriov.alias_guid.ports_guid[port - 1].\r\nall_rec_per_port[index].all_recs[GUID_REC_SIZE * i];\r\nif (MLX4_GUID_FOR_DELETE_VAL == cur_admin_val ||\r\n(!index && !i) ||\r\nMLX4_GUID_NONE_ASSIGN == dev->sriov.alias_guid.\r\nports_guid[port - 1].all_rec_per_port[index].ownership)\r\ncontinue;\r\ncomp_mask |= mlx4_ib_get_aguid_comp_mask_from_ix(i);\r\n}\r\ndev->sriov.alias_guid.ports_guid[port - 1].\r\nall_rec_per_port[index].guid_indexes = comp_mask;\r\n}\r\nstatic int set_guid_rec(struct ib_device *ibdev,\r\nu8 port, int index,\r\nstruct mlx4_sriov_alias_guid_info_rec_det *rec_det)\r\n{\r\nint err;\r\nstruct mlx4_ib_dev *dev = to_mdev(ibdev);\r\nstruct ib_sa_guidinfo_rec guid_info_rec;\r\nib_sa_comp_mask comp_mask;\r\nstruct ib_port_attr attr;\r\nstruct mlx4_alias_guid_work_context *callback_context;\r\nunsigned long resched_delay, flags, flags1;\r\nstruct list_head *head =\r\n&dev->sriov.alias_guid.ports_guid[port - 1].cb_list;\r\nerr = __mlx4_ib_query_port(ibdev, port, &attr, 1);\r\nif (err) {\r\npr_debug("mlx4_ib_query_port failed (err: %d), port: %d\n",\r\nerr, port);\r\nreturn err;\r\n}\r\nif (attr.state != IB_PORT_ACTIVE) {\r\npr_debug("port %d not active...rescheduling\n", port);\r\nresched_delay = 5 * HZ;\r\nerr = -EAGAIN;\r\ngoto new_schedule;\r\n}\r\ncallback_context = kmalloc(sizeof *callback_context, GFP_KERNEL);\r\nif (!callback_context) {\r\nerr = -ENOMEM;\r\nresched_delay = HZ * 5;\r\ngoto new_schedule;\r\n}\r\ncallback_context->port = port;\r\ncallback_context->dev = dev;\r\ncallback_context->block_num = index;\r\nmemset(&guid_info_rec, 0, sizeof (struct ib_sa_guidinfo_rec));\r\nguid_info_rec.lid = cpu_to_be16(attr.lid);\r\nguid_info_rec.block_num = index;\r\nmemcpy(guid_info_rec.guid_info_list, rec_det->all_recs,\r\nGUID_REC_SIZE * NUM_ALIAS_GUID_IN_REC);\r\ncomp_mask = IB_SA_GUIDINFO_REC_LID | IB_SA_GUIDINFO_REC_BLOCK_NUM |\r\nrec_det->guid_indexes;\r\ninit_completion(&callback_context->done);\r\nspin_lock_irqsave(&dev->sriov.alias_guid.ag_work_lock, flags1);\r\nlist_add_tail(&callback_context->list, head);\r\nspin_unlock_irqrestore(&dev->sriov.alias_guid.ag_work_lock, flags1);\r\ncallback_context->query_id =\r\nib_sa_guid_info_rec_query(dev->sriov.alias_guid.sa_client,\r\nibdev, port, &guid_info_rec,\r\ncomp_mask, rec_det->method, 1000,\r\nGFP_KERNEL, aliasguid_query_handler,\r\ncallback_context,\r\n&callback_context->sa_query);\r\nif (callback_context->query_id < 0) {\r\npr_debug("ib_sa_guid_info_rec_query failed, query_id: "\r\n"%d. will reschedule to the next 1 sec.\n",\r\ncallback_context->query_id);\r\nspin_lock_irqsave(&dev->sriov.alias_guid.ag_work_lock, flags1);\r\nlist_del(&callback_context->list);\r\nkfree(callback_context);\r\nspin_unlock_irqrestore(&dev->sriov.alias_guid.ag_work_lock, flags1);\r\nresched_delay = 1 * HZ;\r\nerr = -EAGAIN;\r\ngoto new_schedule;\r\n}\r\nerr = 0;\r\ngoto out;\r\nnew_schedule:\r\nspin_lock_irqsave(&dev->sriov.going_down_lock, flags);\r\nspin_lock_irqsave(&dev->sriov.alias_guid.ag_work_lock, flags1);\r\ninvalidate_guid_record(dev, port, index);\r\nif (!dev->sriov.is_going_down) {\r\nqueue_delayed_work(dev->sriov.alias_guid.ports_guid[port - 1].wq,\r\n&dev->sriov.alias_guid.ports_guid[port - 1].alias_guid_work,\r\nresched_delay);\r\n}\r\nspin_unlock_irqrestore(&dev->sriov.alias_guid.ag_work_lock, flags1);\r\nspin_unlock_irqrestore(&dev->sriov.going_down_lock, flags);\r\nout:\r\nreturn err;\r\n}\r\nvoid mlx4_ib_invalidate_all_guid_record(struct mlx4_ib_dev *dev, int port)\r\n{\r\nint i;\r\nunsigned long flags, flags1;\r\npr_debug("port %d\n", port);\r\nspin_lock_irqsave(&dev->sriov.going_down_lock, flags);\r\nspin_lock_irqsave(&dev->sriov.alias_guid.ag_work_lock, flags1);\r\nfor (i = 0; i < NUM_ALIAS_GUID_REC_IN_PORT; i++)\r\ninvalidate_guid_record(dev, port, i);\r\nif (mlx4_is_master(dev->dev) && !dev->sriov.is_going_down) {\r\ncancel_delayed_work(&dev->sriov.alias_guid.\r\nports_guid[port - 1].alias_guid_work);\r\nqueue_delayed_work(dev->sriov.alias_guid.ports_guid[port - 1].wq,\r\n&dev->sriov.alias_guid.ports_guid[port - 1].alias_guid_work,\r\n0);\r\n}\r\nspin_unlock_irqrestore(&dev->sriov.alias_guid.ag_work_lock, flags1);\r\nspin_unlock_irqrestore(&dev->sriov.going_down_lock, flags);\r\n}\r\nstatic int get_next_record_to_update(struct mlx4_ib_dev *dev, u8 port,\r\nstruct mlx4_next_alias_guid_work *rec)\r\n{\r\nint j;\r\nunsigned long flags;\r\nfor (j = 0; j < NUM_ALIAS_GUID_REC_IN_PORT; j++) {\r\nspin_lock_irqsave(&dev->sriov.alias_guid.ag_work_lock, flags);\r\nif (dev->sriov.alias_guid.ports_guid[port].all_rec_per_port[j].status ==\r\nMLX4_GUID_INFO_STATUS_IDLE) {\r\nmemcpy(&rec->rec_det,\r\n&dev->sriov.alias_guid.ports_guid[port].all_rec_per_port[j],\r\nsizeof (struct mlx4_sriov_alias_guid_info_rec_det));\r\nrec->port = port;\r\nrec->block_num = j;\r\ndev->sriov.alias_guid.ports_guid[port].all_rec_per_port[j].status =\r\nMLX4_GUID_INFO_STATUS_PENDING;\r\nspin_unlock_irqrestore(&dev->sriov.alias_guid.ag_work_lock, flags);\r\nreturn 0;\r\n}\r\nspin_unlock_irqrestore(&dev->sriov.alias_guid.ag_work_lock, flags);\r\n}\r\nreturn -ENOENT;\r\n}\r\nstatic void set_administratively_guid_record(struct mlx4_ib_dev *dev, int port,\r\nint rec_index,\r\nstruct mlx4_sriov_alias_guid_info_rec_det *rec_det)\r\n{\r\ndev->sriov.alias_guid.ports_guid[port].all_rec_per_port[rec_index].guid_indexes =\r\nrec_det->guid_indexes;\r\nmemcpy(dev->sriov.alias_guid.ports_guid[port].all_rec_per_port[rec_index].all_recs,\r\nrec_det->all_recs, NUM_ALIAS_GUID_IN_REC * GUID_REC_SIZE);\r\ndev->sriov.alias_guid.ports_guid[port].all_rec_per_port[rec_index].status =\r\nrec_det->status;\r\n}\r\nstatic void set_all_slaves_guids(struct mlx4_ib_dev *dev, int port)\r\n{\r\nint j;\r\nstruct mlx4_sriov_alias_guid_info_rec_det rec_det ;\r\nfor (j = 0 ; j < NUM_ALIAS_GUID_REC_IN_PORT ; j++) {\r\nmemset(rec_det.all_recs, 0, NUM_ALIAS_GUID_IN_REC * GUID_REC_SIZE);\r\nrec_det.guid_indexes = (!j ? 0 : IB_SA_GUIDINFO_REC_GID0) |\r\nIB_SA_GUIDINFO_REC_GID1 | IB_SA_GUIDINFO_REC_GID2 |\r\nIB_SA_GUIDINFO_REC_GID3 | IB_SA_GUIDINFO_REC_GID4 |\r\nIB_SA_GUIDINFO_REC_GID5 | IB_SA_GUIDINFO_REC_GID6 |\r\nIB_SA_GUIDINFO_REC_GID7;\r\nrec_det.status = MLX4_GUID_INFO_STATUS_IDLE;\r\nset_administratively_guid_record(dev, port, j, &rec_det);\r\n}\r\n}\r\nstatic void alias_guid_work(struct work_struct *work)\r\n{\r\nstruct delayed_work *delay = to_delayed_work(work);\r\nint ret = 0;\r\nstruct mlx4_next_alias_guid_work *rec;\r\nstruct mlx4_sriov_alias_guid_port_rec_det *sriov_alias_port =\r\ncontainer_of(delay, struct mlx4_sriov_alias_guid_port_rec_det,\r\nalias_guid_work);\r\nstruct mlx4_sriov_alias_guid *sriov_alias_guid = sriov_alias_port->parent;\r\nstruct mlx4_ib_sriov *ib_sriov = container_of(sriov_alias_guid,\r\nstruct mlx4_ib_sriov,\r\nalias_guid);\r\nstruct mlx4_ib_dev *dev = container_of(ib_sriov, struct mlx4_ib_dev, sriov);\r\nrec = kzalloc(sizeof *rec, GFP_KERNEL);\r\nif (!rec) {\r\npr_err("alias_guid_work: No Memory\n");\r\nreturn;\r\n}\r\npr_debug("starting [port: %d]...\n", sriov_alias_port->port + 1);\r\nret = get_next_record_to_update(dev, sriov_alias_port->port, rec);\r\nif (ret) {\r\npr_debug("No more records to update.\n");\r\ngoto out;\r\n}\r\nset_guid_rec(&dev->ib_dev, rec->port + 1, rec->block_num,\r\n&rec->rec_det);\r\nout:\r\nkfree(rec);\r\n}\r\nvoid mlx4_ib_init_alias_guid_work(struct mlx4_ib_dev *dev, int port)\r\n{\r\nunsigned long flags, flags1;\r\nif (!mlx4_is_master(dev->dev))\r\nreturn;\r\nspin_lock_irqsave(&dev->sriov.going_down_lock, flags);\r\nspin_lock_irqsave(&dev->sriov.alias_guid.ag_work_lock, flags1);\r\nif (!dev->sriov.is_going_down) {\r\nqueue_delayed_work(dev->sriov.alias_guid.ports_guid[port].wq,\r\n&dev->sriov.alias_guid.ports_guid[port].alias_guid_work, 0);\r\n}\r\nspin_unlock_irqrestore(&dev->sriov.alias_guid.ag_work_lock, flags1);\r\nspin_unlock_irqrestore(&dev->sriov.going_down_lock, flags);\r\n}\r\nvoid mlx4_ib_destroy_alias_guid_service(struct mlx4_ib_dev *dev)\r\n{\r\nint i;\r\nstruct mlx4_ib_sriov *sriov = &dev->sriov;\r\nstruct mlx4_alias_guid_work_context *cb_ctx;\r\nstruct mlx4_sriov_alias_guid_port_rec_det *det;\r\nstruct ib_sa_query *sa_query;\r\nunsigned long flags;\r\nfor (i = 0 ; i < dev->num_ports; i++) {\r\ncancel_delayed_work(&dev->sriov.alias_guid.ports_guid[i].alias_guid_work);\r\ndet = &sriov->alias_guid.ports_guid[i];\r\nspin_lock_irqsave(&sriov->alias_guid.ag_work_lock, flags);\r\nwhile (!list_empty(&det->cb_list)) {\r\ncb_ctx = list_entry(det->cb_list.next,\r\nstruct mlx4_alias_guid_work_context,\r\nlist);\r\nsa_query = cb_ctx->sa_query;\r\ncb_ctx->sa_query = NULL;\r\nlist_del(&cb_ctx->list);\r\nspin_unlock_irqrestore(&sriov->alias_guid.ag_work_lock, flags);\r\nib_sa_cancel_query(cb_ctx->query_id, sa_query);\r\nwait_for_completion(&cb_ctx->done);\r\nkfree(cb_ctx);\r\nspin_lock_irqsave(&sriov->alias_guid.ag_work_lock, flags);\r\n}\r\nspin_unlock_irqrestore(&sriov->alias_guid.ag_work_lock, flags);\r\n}\r\nfor (i = 0 ; i < dev->num_ports; i++) {\r\nflush_workqueue(dev->sriov.alias_guid.ports_guid[i].wq);\r\ndestroy_workqueue(dev->sriov.alias_guid.ports_guid[i].wq);\r\n}\r\nib_sa_unregister_client(dev->sriov.alias_guid.sa_client);\r\nkfree(dev->sriov.alias_guid.sa_client);\r\n}\r\nint mlx4_ib_init_alias_guid_service(struct mlx4_ib_dev *dev)\r\n{\r\nchar alias_wq_name[15];\r\nint ret = 0;\r\nint i, j, k;\r\nunion ib_gid gid;\r\nif (!mlx4_is_master(dev->dev))\r\nreturn 0;\r\ndev->sriov.alias_guid.sa_client =\r\nkzalloc(sizeof *dev->sriov.alias_guid.sa_client, GFP_KERNEL);\r\nif (!dev->sriov.alias_guid.sa_client)\r\nreturn -ENOMEM;\r\nib_sa_register_client(dev->sriov.alias_guid.sa_client);\r\nspin_lock_init(&dev->sriov.alias_guid.ag_work_lock);\r\nfor (i = 1; i <= dev->num_ports; ++i) {\r\nif (dev->ib_dev.query_gid(&dev->ib_dev , i, 0, &gid)) {\r\nret = -EFAULT;\r\ngoto err_unregister;\r\n}\r\n}\r\nfor (i = 0 ; i < dev->num_ports; i++) {\r\nmemset(&dev->sriov.alias_guid.ports_guid[i], 0,\r\nsizeof (struct mlx4_sriov_alias_guid_port_rec_det));\r\nfor (j = 0; j < NUM_ALIAS_GUID_REC_IN_PORT; j++) {\r\nif (mlx4_ib_sm_guid_assign) {\r\ndev->sriov.alias_guid.ports_guid[i].\r\nall_rec_per_port[j].\r\nownership = MLX4_GUID_DRIVER_ASSIGN;\r\ncontinue;\r\n}\r\ndev->sriov.alias_guid.ports_guid[i].all_rec_per_port[j].\r\nownership = MLX4_GUID_NONE_ASSIGN;\r\nfor (k = 0; k < NUM_ALIAS_GUID_IN_REC; k++) {\r\n*(__be64 *)&dev->sriov.alias_guid.ports_guid[i].\r\nall_rec_per_port[j].all_recs[GUID_REC_SIZE * k] =\r\ncpu_to_be64(MLX4_GUID_FOR_DELETE_VAL);\r\n}\r\n}\r\nINIT_LIST_HEAD(&dev->sriov.alias_guid.ports_guid[i].cb_list);\r\nfor (j = 0 ; j < NUM_ALIAS_GUID_REC_IN_PORT; j++)\r\ninvalidate_guid_record(dev, i + 1, j);\r\ndev->sriov.alias_guid.ports_guid[i].parent = &dev->sriov.alias_guid;\r\ndev->sriov.alias_guid.ports_guid[i].port = i;\r\nif (mlx4_ib_sm_guid_assign)\r\nset_all_slaves_guids(dev, i);\r\nsnprintf(alias_wq_name, sizeof alias_wq_name, "alias_guid%d", i);\r\ndev->sriov.alias_guid.ports_guid[i].wq =\r\ncreate_singlethread_workqueue(alias_wq_name);\r\nif (!dev->sriov.alias_guid.ports_guid[i].wq) {\r\nret = -ENOMEM;\r\ngoto err_thread;\r\n}\r\nINIT_DELAYED_WORK(&dev->sriov.alias_guid.ports_guid[i].alias_guid_work,\r\nalias_guid_work);\r\n}\r\nreturn 0;\r\nerr_thread:\r\nfor (--i; i >= 0; i--) {\r\ndestroy_workqueue(dev->sriov.alias_guid.ports_guid[i].wq);\r\ndev->sriov.alias_guid.ports_guid[i].wq = NULL;\r\n}\r\nerr_unregister:\r\nib_sa_unregister_client(dev->sriov.alias_guid.sa_client);\r\nkfree(dev->sriov.alias_guid.sa_client);\r\ndev->sriov.alias_guid.sa_client = NULL;\r\npr_err("init_alias_guid_service: Failed. (ret:%d)\n", ret);\r\nreturn ret;\r\n}
