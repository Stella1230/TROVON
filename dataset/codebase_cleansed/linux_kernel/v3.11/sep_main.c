void sep_queue_status_remove(struct sep_device *sep,\r\nstruct sep_queue_info **queue_elem)\r\n{\r\nunsigned long lck_flags;\r\ndev_dbg(&sep->pdev->dev, "[PID%d] sep_queue_status_remove\n",\r\ncurrent->pid);\r\nif (!queue_elem || !(*queue_elem)) {\r\ndev_dbg(&sep->pdev->dev, "PID%d %s null\n",\r\ncurrent->pid, __func__);\r\nreturn;\r\n}\r\nspin_lock_irqsave(&sep->sep_queue_lock, lck_flags);\r\nlist_del(&(*queue_elem)->list);\r\nsep->sep_queue_num--;\r\nspin_unlock_irqrestore(&sep->sep_queue_lock, lck_flags);\r\nkfree(*queue_elem);\r\n*queue_elem = NULL;\r\ndev_dbg(&sep->pdev->dev, "[PID%d] sep_queue_status_remove return\n",\r\ncurrent->pid);\r\nreturn;\r\n}\r\nstruct sep_queue_info *sep_queue_status_add(\r\nstruct sep_device *sep,\r\nu32 opcode,\r\nu32 size,\r\nu32 pid,\r\nu8 *name, size_t name_len)\r\n{\r\nunsigned long lck_flags;\r\nstruct sep_queue_info *my_elem = NULL;\r\nmy_elem = kzalloc(sizeof(struct sep_queue_info), GFP_KERNEL);\r\nif (!my_elem)\r\nreturn NULL;\r\ndev_dbg(&sep->pdev->dev, "[PID%d] kzalloc ok\n", current->pid);\r\nmy_elem->data.opcode = opcode;\r\nmy_elem->data.size = size;\r\nmy_elem->data.pid = pid;\r\nif (name_len > TASK_COMM_LEN)\r\nname_len = TASK_COMM_LEN;\r\nmemcpy(&my_elem->data.name, name, name_len);\r\nspin_lock_irqsave(&sep->sep_queue_lock, lck_flags);\r\nlist_add_tail(&my_elem->list, &sep->sep_queue_status);\r\nsep->sep_queue_num++;\r\nspin_unlock_irqrestore(&sep->sep_queue_lock, lck_flags);\r\nreturn my_elem;\r\n}\r\nstatic int sep_allocate_dmatables_region(struct sep_device *sep,\r\nvoid **dmatables_region,\r\nstruct sep_dma_context *dma_ctx,\r\nconst u32 table_count)\r\n{\r\nconst size_t new_len =\r\nSYNCHRONIC_DMA_TABLES_AREA_SIZE_BYTES - 1;\r\nvoid *tmp_region = NULL;\r\ndev_dbg(&sep->pdev->dev, "[PID%d] dma_ctx = 0x%p\n",\r\ncurrent->pid, dma_ctx);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] dmatables_region = 0x%p\n",\r\ncurrent->pid, dmatables_region);\r\nif (!dma_ctx || !dmatables_region) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] dma context/region uninitialized\n",\r\ncurrent->pid);\r\nreturn -EINVAL;\r\n}\r\ndev_dbg(&sep->pdev->dev, "[PID%d] newlen = 0x%08zX\n",\r\ncurrent->pid, new_len);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] oldlen = 0x%08X\n", current->pid,\r\ndma_ctx->dmatables_len);\r\ntmp_region = kzalloc(new_len + dma_ctx->dmatables_len, GFP_KERNEL);\r\nif (!tmp_region)\r\nreturn -ENOMEM;\r\nif (*dmatables_region) {\r\nmemcpy(tmp_region, *dmatables_region, dma_ctx->dmatables_len);\r\nkfree(*dmatables_region);\r\n*dmatables_region = NULL;\r\n}\r\n*dmatables_region = tmp_region;\r\ndma_ctx->dmatables_len += new_len;\r\nreturn 0;\r\n}\r\nint sep_wait_transaction(struct sep_device *sep)\r\n{\r\nint error = 0;\r\nDEFINE_WAIT(wait);\r\nif (0 == test_and_set_bit(SEP_TRANSACTION_STARTED_LOCK_BIT,\r\n&sep->in_use_flags)) {\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] no transactions, returning\n",\r\ncurrent->pid);\r\ngoto end_function_setpid;\r\n}\r\nfor (;;) {\r\nprepare_to_wait_exclusive(&sep->event_transactions,\r\n&wait,\r\nTASK_INTERRUPTIBLE);\r\nif (0 == test_and_set_bit(SEP_TRANSACTION_STARTED_LOCK_BIT,\r\n&sep->in_use_flags)) {\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] no transactions, breaking\n",\r\ncurrent->pid);\r\nbreak;\r\n}\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] transactions ongoing, sleeping\n",\r\ncurrent->pid);\r\nschedule();\r\ndev_dbg(&sep->pdev->dev, "[PID%d] woken up\n", current->pid);\r\nif (signal_pending(current)) {\r\ndev_dbg(&sep->pdev->dev, "[PID%d] received signal\n",\r\ncurrent->pid);\r\nerror = -EINTR;\r\ngoto end_function;\r\n}\r\n}\r\nend_function_setpid:\r\nsep->pid_doing_transaction = current->pid;\r\nend_function:\r\nfinish_wait(&sep->event_transactions, &wait);\r\nreturn error;\r\n}\r\nstatic inline int sep_check_transaction_owner(struct sep_device *sep)\r\n{\r\ndev_dbg(&sep->pdev->dev, "[PID%d] transaction pid = %d\n",\r\ncurrent->pid,\r\nsep->pid_doing_transaction);\r\nif ((sep->pid_doing_transaction == 0) ||\r\n(current->pid != sep->pid_doing_transaction)) {\r\nreturn -EACCES;\r\n}\r\nreturn 0;\r\n}\r\nstatic void _sep_dump_message(struct sep_device *sep)\r\n{\r\nint count;\r\nu32 *p = sep->shared_addr;\r\nfor (count = 0; count < 10 * 4; count += 4)\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] Word %d of the message is %x\n",\r\ncurrent->pid, count/4, *p++);\r\n}\r\nstatic int sep_map_and_alloc_shared_area(struct sep_device *sep)\r\n{\r\nsep->shared_addr = dma_alloc_coherent(&sep->pdev->dev,\r\nsep->shared_size,\r\n&sep->shared_bus, GFP_KERNEL);\r\nif (!sep->shared_addr) {\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] shared memory dma_alloc_coherent failed\n",\r\ncurrent->pid);\r\nreturn -ENOMEM;\r\n}\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] shared_addr %zx bytes @%p (bus %llx)\n",\r\ncurrent->pid,\r\nsep->shared_size, sep->shared_addr,\r\n(unsigned long long)sep->shared_bus);\r\nreturn 0;\r\n}\r\nstatic void sep_unmap_and_free_shared_area(struct sep_device *sep)\r\n{\r\ndma_free_coherent(&sep->pdev->dev, sep->shared_size,\r\nsep->shared_addr, sep->shared_bus);\r\n}\r\nstatic void *sep_shared_bus_to_virt(struct sep_device *sep,\r\ndma_addr_t bus_address)\r\n{\r\nreturn sep->shared_addr + (bus_address - sep->shared_bus);\r\n}\r\nstatic int sep_open(struct inode *inode, struct file *filp)\r\n{\r\nstruct sep_device *sep;\r\nstruct sep_private_data *priv;\r\ndev_dbg(&sep_dev->pdev->dev, "[PID%d] open\n", current->pid);\r\nif (filp->f_flags & O_NONBLOCK)\r\nreturn -ENOTSUPP;\r\npriv = kzalloc(sizeof(*priv), GFP_KERNEL);\r\nif (!priv)\r\nreturn -ENOMEM;\r\nsep = sep_dev;\r\npriv->device = sep;\r\nfilp->private_data = priv;\r\ndev_dbg(&sep_dev->pdev->dev, "[PID%d] priv is 0x%p\n",\r\ncurrent->pid, priv);\r\nreturn 0;\r\n}\r\nint sep_free_dma_table_data_handler(struct sep_device *sep,\r\nstruct sep_dma_context **dma_ctx)\r\n{\r\nint count;\r\nint dcb_counter;\r\nstruct sep_dma_resource *dma;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] sep_free_dma_table_data_handler\n",\r\ncurrent->pid);\r\nif (!dma_ctx || !(*dma_ctx)) {\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] no DMA context or context already freed\n",\r\ncurrent->pid);\r\nreturn 0;\r\n}\r\ndev_dbg(&sep->pdev->dev, "[PID%d] (*dma_ctx)->nr_dcb_creat 0x%x\n",\r\ncurrent->pid,\r\n(*dma_ctx)->nr_dcb_creat);\r\nfor (dcb_counter = 0;\r\ndcb_counter < (*dma_ctx)->nr_dcb_creat; dcb_counter++) {\r\ndma = &(*dma_ctx)->dma_res_arr[dcb_counter];\r\nif (dma->in_map_array) {\r\nfor (count = 0; count < dma->in_num_pages; count++) {\r\ndma_unmap_page(&sep->pdev->dev,\r\ndma->in_map_array[count].dma_addr,\r\ndma->in_map_array[count].size,\r\nDMA_TO_DEVICE);\r\n}\r\nkfree(dma->in_map_array);\r\n}\r\nif (((*dma_ctx)->secure_dma == false) &&\r\n(dma->out_map_array)) {\r\nfor (count = 0; count < dma->out_num_pages; count++) {\r\ndma_unmap_page(&sep->pdev->dev,\r\ndma->out_map_array[count].dma_addr,\r\ndma->out_map_array[count].size,\r\nDMA_FROM_DEVICE);\r\n}\r\nkfree(dma->out_map_array);\r\n}\r\nif (dma->in_page_array) {\r\nfor (count = 0; count < dma->in_num_pages; count++) {\r\nflush_dcache_page(dma->in_page_array[count]);\r\npage_cache_release(dma->in_page_array[count]);\r\n}\r\nkfree(dma->in_page_array);\r\n}\r\nif (((*dma_ctx)->secure_dma == false) &&\r\n(dma->out_page_array)) {\r\nfor (count = 0; count < dma->out_num_pages; count++) {\r\nif (!PageReserved(dma->out_page_array[count]))\r\nSetPageDirty(dma->\r\nout_page_array[count]);\r\nflush_dcache_page(dma->out_page_array[count]);\r\npage_cache_release(dma->out_page_array[count]);\r\n}\r\nkfree(dma->out_page_array);\r\n}\r\nif (dma->src_sg) {\r\ndma_unmap_sg(&sep->pdev->dev, dma->src_sg,\r\ndma->in_map_num_entries, DMA_TO_DEVICE);\r\ndma->src_sg = NULL;\r\n}\r\nif (dma->dst_sg) {\r\ndma_unmap_sg(&sep->pdev->dev, dma->dst_sg,\r\ndma->in_map_num_entries, DMA_FROM_DEVICE);\r\ndma->dst_sg = NULL;\r\n}\r\ndma->in_page_array = NULL;\r\ndma->out_page_array = NULL;\r\ndma->in_num_pages = 0;\r\ndma->out_num_pages = 0;\r\ndma->in_map_array = NULL;\r\ndma->out_map_array = NULL;\r\ndma->in_map_num_entries = 0;\r\ndma->out_map_num_entries = 0;\r\n}\r\n(*dma_ctx)->nr_dcb_creat = 0;\r\n(*dma_ctx)->num_lli_tables_created = 0;\r\nkfree(*dma_ctx);\r\n*dma_ctx = NULL;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] sep_free_dma_table_data_handler end\n",\r\ncurrent->pid);\r\nreturn 0;\r\n}\r\nstatic int sep_end_transaction_handler(struct sep_device *sep,\r\nstruct sep_dma_context **dma_ctx,\r\nstruct sep_call_status *call_status,\r\nstruct sep_queue_info **my_queue_elem)\r\n{\r\ndev_dbg(&sep->pdev->dev, "[PID%d] ending transaction\n", current->pid);\r\nif (sep_check_transaction_owner(sep)) {\r\ndev_dbg(&sep->pdev->dev, "[PID%d] not transaction owner\n",\r\ncurrent->pid);\r\nreturn 0;\r\n}\r\nsep_queue_status_remove(sep, my_queue_elem);\r\nif (dma_ctx)\r\nsep_free_dma_table_data_handler(sep, dma_ctx);\r\nif (call_status)\r\ncall_status->status = 0;\r\nmemset(sep->shared_addr, 0,\r\nSEP_DRIVER_MESSAGE_SHARED_AREA_SIZE_IN_BYTES);\r\n#ifdef SEP_ENABLE_RUNTIME_PM\r\nif (sep->in_use) {\r\nsep->in_use = 0;\r\npm_runtime_mark_last_busy(&sep->pdev->dev);\r\npm_runtime_put_autosuspend(&sep->pdev->dev);\r\n}\r\n#endif\r\nclear_bit(SEP_WORKING_LOCK_BIT, &sep->in_use_flags);\r\nsep->pid_doing_transaction = 0;\r\ndev_dbg(&sep->pdev->dev, "[PID%d] waking up next transaction\n",\r\ncurrent->pid);\r\nclear_bit(SEP_TRANSACTION_STARTED_LOCK_BIT, &sep->in_use_flags);\r\nwake_up(&sep->event_transactions);\r\nreturn 0;\r\n}\r\nstatic int sep_release(struct inode *inode, struct file *filp)\r\n{\r\nstruct sep_private_data * const private_data = filp->private_data;\r\nstruct sep_call_status *call_status = &private_data->call_status;\r\nstruct sep_device *sep = private_data->device;\r\nstruct sep_dma_context **dma_ctx = &private_data->dma_ctx;\r\nstruct sep_queue_info **my_queue_elem = &private_data->my_queue_elem;\r\ndev_dbg(&sep->pdev->dev, "[PID%d] release\n", current->pid);\r\nsep_end_transaction_handler(sep, dma_ctx, call_status,\r\nmy_queue_elem);\r\nkfree(filp->private_data);\r\nreturn 0;\r\n}\r\nstatic int sep_mmap(struct file *filp, struct vm_area_struct *vma)\r\n{\r\nstruct sep_private_data * const private_data = filp->private_data;\r\nstruct sep_call_status *call_status = &private_data->call_status;\r\nstruct sep_device *sep = private_data->device;\r\nstruct sep_queue_info **my_queue_elem = &private_data->my_queue_elem;\r\ndma_addr_t bus_addr;\r\nunsigned long error = 0;\r\ndev_dbg(&sep->pdev->dev, "[PID%d] sep_mmap\n", current->pid);\r\nerror = sep_wait_transaction(sep);\r\nif (error)\r\ngoto end_function;\r\nmemset(sep->shared_addr, 0,\r\nSEP_DRIVER_MESSAGE_SHARED_AREA_SIZE_IN_BYTES);\r\nif ((vma->vm_end - vma->vm_start) > SEP_DRIVER_MMMAP_AREA_SIZE) {\r\nerror = -EINVAL;\r\ngoto end_function_with_error;\r\n}\r\ndev_dbg(&sep->pdev->dev, "[PID%d] shared_addr is %p\n",\r\ncurrent->pid, sep->shared_addr);\r\nbus_addr = sep->shared_bus;\r\nif (remap_pfn_range(vma, vma->vm_start, bus_addr >> PAGE_SHIFT,\r\nvma->vm_end - vma->vm_start, vma->vm_page_prot)) {\r\ndev_dbg(&sep->pdev->dev, "[PID%d] remap_pfn_range failed\n",\r\ncurrent->pid);\r\nerror = -EAGAIN;\r\ngoto end_function_with_error;\r\n}\r\nset_bit(SEP_LEGACY_MMAP_DONE_OFFSET, &call_status->status);\r\ngoto end_function;\r\nend_function_with_error:\r\nsep_end_transaction_handler(sep, NULL, call_status,\r\nmy_queue_elem);\r\nend_function:\r\nreturn error;\r\n}\r\nstatic unsigned int sep_poll(struct file *filp, poll_table *wait)\r\n{\r\nstruct sep_private_data * const private_data = filp->private_data;\r\nstruct sep_call_status *call_status = &private_data->call_status;\r\nstruct sep_device *sep = private_data->device;\r\nu32 mask = 0;\r\nu32 retval = 0;\r\nu32 retval2 = 0;\r\nunsigned long lock_irq_flag;\r\nif (sep_check_transaction_owner(sep)) {\r\ndev_dbg(&sep->pdev->dev, "[PID%d] poll pid not owner\n",\r\ncurrent->pid);\r\nmask = POLLERR;\r\ngoto end_function;\r\n}\r\nif (0 == test_bit(SEP_LEGACY_SENDMSG_DONE_OFFSET,\r\n&call_status->status)) {\r\ndev_warn(&sep->pdev->dev, "[PID%d] sendmsg not called\n",\r\ncurrent->pid);\r\nmask = POLLERR;\r\ngoto end_function;\r\n}\r\ndev_dbg(&sep->pdev->dev, "[PID%d] poll: calling wait sep_event\n",\r\ncurrent->pid);\r\npoll_wait(filp, &sep->event_interrupt, wait);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] poll: send_ct is %lx reply ct is %lx\n",\r\ncurrent->pid, sep->send_ct, sep->reply_ct);\r\nretval2 = sep_read_reg(sep, HW_HOST_SEP_HOST_GPR3_REG_ADDR);\r\nif ((retval2 != 0x0) && (retval2 != 0x8)) {\r\ndev_dbg(&sep->pdev->dev, "[PID%d] poll; poll error %x\n",\r\ncurrent->pid, retval2);\r\nmask |= POLLERR;\r\ngoto end_function;\r\n}\r\nspin_lock_irqsave(&sep->snd_rply_lck, lock_irq_flag);\r\nif (sep->send_ct == sep->reply_ct) {\r\nspin_unlock_irqrestore(&sep->snd_rply_lck, lock_irq_flag);\r\nretval = sep_read_reg(sep, HW_HOST_SEP_HOST_GPR2_REG_ADDR);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] poll: data ready check (GPR2) %x\n",\r\ncurrent->pid, retval);\r\nif ((retval >> 30) & 0x1) {\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] poll: SEP printf request\n",\r\ncurrent->pid);\r\ngoto end_function;\r\n}\r\nif (retval >> 31) {\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] poll: SEP request\n",\r\ncurrent->pid);\r\n} else {\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] poll: normal return\n",\r\ncurrent->pid);\r\nsep_dump_message(sep);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] poll; SEP reply POLLIN|POLLRDNORM\n",\r\ncurrent->pid);\r\nmask |= POLLIN | POLLRDNORM;\r\n}\r\nset_bit(SEP_LEGACY_POLL_DONE_OFFSET, &call_status->status);\r\n} else {\r\nspin_unlock_irqrestore(&sep->snd_rply_lck, lock_irq_flag);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] poll; no reply; returning mask of 0\n",\r\ncurrent->pid);\r\nmask = 0;\r\n}\r\nend_function:\r\nreturn mask;\r\n}\r\nstatic u32 *sep_time_address(struct sep_device *sep)\r\n{\r\nreturn sep->shared_addr +\r\nSEP_DRIVER_SYSTEM_TIME_MEMORY_OFFSET_IN_BYTES;\r\n}\r\nstatic unsigned long sep_set_time(struct sep_device *sep)\r\n{\r\nstruct timeval time;\r\nu32 *time_addr;\r\ndo_gettimeofday(&time);\r\ntime_addr = sep_time_address(sep);\r\ntime_addr[0] = SEP_TIME_VAL_TOKEN;\r\ntime_addr[1] = time.tv_sec;\r\ndev_dbg(&sep->pdev->dev, "[PID%d] time.tv_sec is %lu\n",\r\ncurrent->pid, time.tv_sec);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] time_addr is %p\n",\r\ncurrent->pid, time_addr);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] sep->shared_addr is %p\n",\r\ncurrent->pid, sep->shared_addr);\r\nreturn time.tv_sec;\r\n}\r\nint sep_send_command_handler(struct sep_device *sep)\r\n{\r\nunsigned long lock_irq_flag;\r\nu32 *msg_pool;\r\nint error = 0;\r\nmsg_pool = (u32 *)sep->shared_addr;\r\nmsg_pool += 2;\r\nif (*msg_pool != SEP_START_MSG_TOKEN) {\r\ndev_warn(&sep->pdev->dev, "start message token not present\n");\r\nerror = -EPROTO;\r\ngoto end_function;\r\n}\r\nmsg_pool += 1;\r\nif ((*msg_pool < 2) ||\r\n(*msg_pool > SEP_DRIVER_MAX_MESSAGE_SIZE_IN_BYTES)) {\r\ndev_warn(&sep->pdev->dev, "invalid message size\n");\r\nerror = -EPROTO;\r\ngoto end_function;\r\n}\r\nmsg_pool += 1;\r\nif (*msg_pool < 2) {\r\ndev_warn(&sep->pdev->dev, "invalid message opcode\n");\r\nerror = -EPROTO;\r\ngoto end_function;\r\n}\r\n#if defined(CONFIG_PM_RUNTIME) && defined(SEP_ENABLE_RUNTIME_PM)\r\ndev_dbg(&sep->pdev->dev, "[PID%d] before pm sync status 0x%X\n",\r\ncurrent->pid,\r\nsep->pdev->dev.power.runtime_status);\r\nsep->in_use = 1;\r\npm_runtime_get_sync(&sep->pdev->dev);\r\n#endif\r\nif (test_and_set_bit(SEP_WORKING_LOCK_BIT, &sep->in_use_flags)) {\r\nerror = -EPROTO;\r\ngoto end_function;\r\n}\r\nsep->in_use = 1;\r\nsep_set_time(sep);\r\nsep_dump_message(sep);\r\nspin_lock_irqsave(&sep->snd_rply_lck, lock_irq_flag);\r\nsep->send_ct++;\r\nspin_unlock_irqrestore(&sep->snd_rply_lck, lock_irq_flag);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] sep_send_command_handler send_ct %lx reply_ct %lx\n",\r\ncurrent->pid, sep->send_ct, sep->reply_ct);\r\nsep_write_reg(sep, HW_HOST_HOST_SEP_GPR0_REG_ADDR, 0x2);\r\nend_function:\r\nreturn error;\r\n}\r\nstatic int sep_crypto_dma(\r\nstruct sep_device *sep,\r\nstruct scatterlist *sg,\r\nstruct sep_dma_map **dma_maps,\r\nenum dma_data_direction direction)\r\n{\r\nstruct scatterlist *temp_sg;\r\nu32 count_segment;\r\nu32 count_mapped;\r\nstruct sep_dma_map *sep_dma;\r\nint ct1;\r\nif (sg->length == 0)\r\nreturn 0;\r\ntemp_sg = sg;\r\ncount_segment = 0;\r\nwhile (temp_sg) {\r\ncount_segment += 1;\r\ntemp_sg = scatterwalk_sg_next(temp_sg);\r\n}\r\ndev_dbg(&sep->pdev->dev,\r\n"There are (hex) %x segments in sg\n", count_segment);\r\ncount_mapped = dma_map_sg(&sep->pdev->dev, sg,\r\ncount_segment, direction);\r\ndev_dbg(&sep->pdev->dev,\r\n"There are (hex) %x maps in sg\n", count_mapped);\r\nif (count_mapped == 0) {\r\ndev_dbg(&sep->pdev->dev, "Cannot dma_map_sg\n");\r\nreturn -ENOMEM;\r\n}\r\nsep_dma = kmalloc(sizeof(struct sep_dma_map) *\r\ncount_mapped, GFP_ATOMIC);\r\nif (sep_dma == NULL) {\r\ndev_dbg(&sep->pdev->dev, "Cannot allocate dma_maps\n");\r\nreturn -ENOMEM;\r\n}\r\nfor_each_sg(sg, temp_sg, count_mapped, ct1) {\r\nsep_dma[ct1].dma_addr = sg_dma_address(temp_sg);\r\nsep_dma[ct1].size = sg_dma_len(temp_sg);\r\ndev_dbg(&sep->pdev->dev, "(all hex) map %x dma %lx len %lx\n",\r\nct1, (unsigned long)sep_dma[ct1].dma_addr,\r\n(unsigned long)sep_dma[ct1].size);\r\n}\r\n*dma_maps = sep_dma;\r\nreturn count_mapped;\r\n}\r\nstatic int sep_crypto_lli(\r\nstruct sep_device *sep,\r\nstruct scatterlist *sg,\r\nstruct sep_dma_map **maps,\r\nstruct sep_lli_entry **llis,\r\nu32 data_size,\r\nenum dma_data_direction direction)\r\n{\r\nint ct1;\r\nstruct sep_lli_entry *sep_lli;\r\nstruct sep_dma_map *sep_map;\r\nint nbr_ents;\r\nnbr_ents = sep_crypto_dma(sep, sg, maps, direction);\r\nif (nbr_ents <= 0) {\r\ndev_dbg(&sep->pdev->dev, "crypto_dma failed %x\n",\r\nnbr_ents);\r\nreturn nbr_ents;\r\n}\r\nsep_map = *maps;\r\nsep_lli = kmalloc(sizeof(struct sep_lli_entry) * nbr_ents, GFP_ATOMIC);\r\nif (sep_lli == NULL) {\r\ndev_dbg(&sep->pdev->dev, "Cannot allocate lli_maps\n");\r\nkfree(*maps);\r\n*maps = NULL;\r\nreturn -ENOMEM;\r\n}\r\nfor (ct1 = 0; ct1 < nbr_ents; ct1 += 1) {\r\nsep_lli[ct1].bus_address = (u32)sep_map[ct1].dma_addr;\r\nif (sep_map[ct1].size > data_size)\r\nsep_map[ct1].size = data_size;\r\nsep_lli[ct1].block_size = (u32)sep_map[ct1].size;\r\n}\r\n*llis = sep_lli;\r\nreturn nbr_ents;\r\n}\r\nstatic int sep_lock_kernel_pages(struct sep_device *sep,\r\nunsigned long kernel_virt_addr,\r\nu32 data_size,\r\nstruct sep_lli_entry **lli_array_ptr,\r\nint in_out_flag,\r\nstruct sep_dma_context *dma_ctx)\r\n{\r\nu32 num_pages;\r\nstruct scatterlist *sg;\r\nstruct sep_lli_entry *lli_array;\r\nstruct sep_dma_map *map_array;\r\nenum dma_data_direction direction;\r\nlli_array = NULL;\r\nmap_array = NULL;\r\nif (in_out_flag == SEP_DRIVER_IN_FLAG) {\r\ndirection = DMA_TO_DEVICE;\r\nsg = dma_ctx->src_sg;\r\n} else {\r\ndirection = DMA_FROM_DEVICE;\r\nsg = dma_ctx->dst_sg;\r\n}\r\nnum_pages = sep_crypto_lli(sep, sg, &map_array, &lli_array,\r\ndata_size, direction);\r\nif (num_pages <= 0) {\r\ndev_dbg(&sep->pdev->dev, "sep_crypto_lli returned error %x\n",\r\nnum_pages);\r\nreturn -ENOMEM;\r\n}\r\nif (in_out_flag == SEP_DRIVER_IN_FLAG) {\r\n*lli_array_ptr = lli_array;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_num_pages =\r\nnum_pages;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_page_array =\r\nNULL;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_map_array =\r\nmap_array;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_map_num_entries =\r\nnum_pages;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].src_sg =\r\ndma_ctx->src_sg;\r\n} else {\r\n*lli_array_ptr = lli_array;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].out_num_pages =\r\nnum_pages;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].out_page_array =\r\nNULL;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].out_map_array =\r\nmap_array;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].\r\nout_map_num_entries = num_pages;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].dst_sg =\r\ndma_ctx->dst_sg;\r\n}\r\nreturn 0;\r\n}\r\nstatic int sep_lock_user_pages(struct sep_device *sep,\r\nu32 app_virt_addr,\r\nu32 data_size,\r\nstruct sep_lli_entry **lli_array_ptr,\r\nint in_out_flag,\r\nstruct sep_dma_context *dma_ctx)\r\n{\r\nint error = 0;\r\nu32 count;\r\nint result;\r\nu32 end_page;\r\nu32 start_page;\r\nu32 num_pages;\r\nstruct page **page_array;\r\nstruct sep_lli_entry *lli_array;\r\nstruct sep_dma_map *map_array;\r\nend_page = (app_virt_addr + data_size - 1) >> PAGE_SHIFT;\r\nstart_page = app_virt_addr >> PAGE_SHIFT;\r\nnum_pages = end_page - start_page + 1;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] lock user pages app_virt_addr is %x\n",\r\ncurrent->pid, app_virt_addr);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] data_size is (hex) %x\n",\r\ncurrent->pid, data_size);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] start_page is (hex) %x\n",\r\ncurrent->pid, start_page);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] end_page is (hex) %x\n",\r\ncurrent->pid, end_page);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] num_pages is (hex) %x\n",\r\ncurrent->pid, num_pages);\r\npage_array = kmalloc_array(num_pages, sizeof(struct page *),\r\nGFP_ATOMIC);\r\nif (!page_array) {\r\nerror = -ENOMEM;\r\ngoto end_function;\r\n}\r\nmap_array = kmalloc_array(num_pages, sizeof(struct sep_dma_map),\r\nGFP_ATOMIC);\r\nif (!map_array) {\r\nerror = -ENOMEM;\r\ngoto end_function_with_error1;\r\n}\r\nlli_array = kmalloc_array(num_pages, sizeof(struct sep_lli_entry),\r\nGFP_ATOMIC);\r\nif (!lli_array) {\r\nerror = -ENOMEM;\r\ngoto end_function_with_error2;\r\n}\r\ndown_read(&current->mm->mmap_sem);\r\nresult = get_user_pages(current, current->mm, app_virt_addr,\r\nnum_pages,\r\n((in_out_flag == SEP_DRIVER_IN_FLAG) ? 0 : 1),\r\n0, page_array, NULL);\r\nup_read(&current->mm->mmap_sem);\r\nif (result != num_pages) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] not all pages locked by get_user_pages, "\r\n"result 0x%X, num_pages 0x%X\n",\r\ncurrent->pid, result, num_pages);\r\nerror = -ENOMEM;\r\ngoto end_function_with_error3;\r\n}\r\ndev_dbg(&sep->pdev->dev, "[PID%d] get_user_pages succeeded\n",\r\ncurrent->pid);\r\nfor (count = 0; count < num_pages; count++) {\r\nmap_array[count].dma_addr =\r\ndma_map_page(&sep->pdev->dev, page_array[count],\r\n0, PAGE_SIZE, DMA_BIDIRECTIONAL);\r\nmap_array[count].size = PAGE_SIZE;\r\nlli_array[count].bus_address = (u32)map_array[count].dma_addr;\r\nlli_array[count].block_size = PAGE_SIZE;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] lli_array[%x].bus_address is %08lx, "\r\n"lli_array[%x].block_size is (hex) %x\n", current->pid,\r\ncount, (unsigned long)lli_array[count].bus_address,\r\ncount, lli_array[count].block_size);\r\n}\r\nlli_array[0].bus_address =\r\nlli_array[0].bus_address + (app_virt_addr & (~PAGE_MASK));\r\nif ((PAGE_SIZE - (app_virt_addr & (~PAGE_MASK))) >= data_size)\r\nlli_array[0].block_size = data_size;\r\nelse\r\nlli_array[0].block_size =\r\nPAGE_SIZE - (app_virt_addr & (~PAGE_MASK));\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] After check if page 0 has all data\n",\r\ncurrent->pid);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] lli_array[0].bus_address is (hex) %08lx, "\r\n"lli_array[0].block_size is (hex) %x\n",\r\ncurrent->pid,\r\n(unsigned long)lli_array[0].bus_address,\r\nlli_array[0].block_size);\r\nif (num_pages > 1) {\r\nlli_array[num_pages - 1].block_size =\r\n(app_virt_addr + data_size) & (~PAGE_MASK);\r\nif (lli_array[num_pages - 1].block_size == 0)\r\nlli_array[num_pages - 1].block_size = PAGE_SIZE;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] After last page size adjustment\n",\r\ncurrent->pid);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] lli_array[%x].bus_address is (hex) %08lx, "\r\n"lli_array[%x].block_size is (hex) %x\n",\r\ncurrent->pid,\r\nnum_pages - 1,\r\n(unsigned long)lli_array[num_pages - 1].bus_address,\r\nnum_pages - 1,\r\nlli_array[num_pages - 1].block_size);\r\n}\r\nif (in_out_flag == SEP_DRIVER_IN_FLAG) {\r\n*lli_array_ptr = lli_array;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_num_pages =\r\nnum_pages;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_page_array =\r\npage_array;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_map_array =\r\nmap_array;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_map_num_entries =\r\nnum_pages;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].src_sg = NULL;\r\n} else {\r\n*lli_array_ptr = lli_array;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].out_num_pages =\r\nnum_pages;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].out_page_array =\r\npage_array;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].out_map_array =\r\nmap_array;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].\r\nout_map_num_entries = num_pages;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].dst_sg = NULL;\r\n}\r\ngoto end_function;\r\nend_function_with_error3:\r\nkfree(lli_array);\r\nend_function_with_error2:\r\nkfree(map_array);\r\nend_function_with_error1:\r\nkfree(page_array);\r\nend_function:\r\nreturn error;\r\n}\r\nstatic int sep_lli_table_secure_dma(struct sep_device *sep,\r\nu32 app_virt_addr,\r\nu32 data_size,\r\nstruct sep_lli_entry **lli_array_ptr,\r\nint in_out_flag,\r\nstruct sep_dma_context *dma_ctx)\r\n{\r\nint error = 0;\r\nu32 count;\r\nu32 end_page;\r\nu32 start_page;\r\nu32 num_pages;\r\nstruct sep_lli_entry *lli_array;\r\nend_page = (app_virt_addr + data_size - 1) >> PAGE_SHIFT;\r\nstart_page = app_virt_addr >> PAGE_SHIFT;\r\nnum_pages = end_page - start_page + 1;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] lock user pages app_virt_addr is %x\n",\r\ncurrent->pid, app_virt_addr);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] data_size is (hex) %x\n",\r\ncurrent->pid, data_size);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] start_page is (hex) %x\n",\r\ncurrent->pid, start_page);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] end_page is (hex) %x\n",\r\ncurrent->pid, end_page);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] num_pages is (hex) %x\n",\r\ncurrent->pid, num_pages);\r\nlli_array = kmalloc_array(num_pages, sizeof(struct sep_lli_entry),\r\nGFP_ATOMIC);\r\nif (!lli_array)\r\nreturn -ENOMEM;\r\nstart_page = start_page << PAGE_SHIFT;\r\nfor (count = 0; count < num_pages; count++) {\r\nlli_array[count].bus_address = start_page;\r\nlli_array[count].block_size = PAGE_SIZE;\r\nstart_page += PAGE_SIZE;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] lli_array[%x].bus_address is %08lx, "\r\n"lli_array[%x].block_size is (hex) %x\n",\r\ncurrent->pid,\r\ncount, (unsigned long)lli_array[count].bus_address,\r\ncount, lli_array[count].block_size);\r\n}\r\nlli_array[0].bus_address =\r\nlli_array[0].bus_address + (app_virt_addr & (~PAGE_MASK));\r\nif ((PAGE_SIZE - (app_virt_addr & (~PAGE_MASK))) >= data_size)\r\nlli_array[0].block_size = data_size;\r\nelse\r\nlli_array[0].block_size =\r\nPAGE_SIZE - (app_virt_addr & (~PAGE_MASK));\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] After check if page 0 has all data\n"\r\n"lli_array[0].bus_address is (hex) %08lx, "\r\n"lli_array[0].block_size is (hex) %x\n",\r\ncurrent->pid,\r\n(unsigned long)lli_array[0].bus_address,\r\nlli_array[0].block_size);\r\nif (num_pages > 1) {\r\nlli_array[num_pages - 1].block_size =\r\n(app_virt_addr + data_size) & (~PAGE_MASK);\r\nif (lli_array[num_pages - 1].block_size == 0)\r\nlli_array[num_pages - 1].block_size = PAGE_SIZE;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] After last page size adjustment\n"\r\n"lli_array[%x].bus_address is (hex) %08lx, "\r\n"lli_array[%x].block_size is (hex) %x\n",\r\ncurrent->pid, num_pages - 1,\r\n(unsigned long)lli_array[num_pages - 1].bus_address,\r\nnum_pages - 1,\r\nlli_array[num_pages - 1].block_size);\r\n}\r\n*lli_array_ptr = lli_array;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].out_num_pages = num_pages;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].out_page_array = NULL;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].out_map_array = NULL;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].out_map_num_entries = 0;\r\nreturn error;\r\n}\r\nstatic u32 sep_calculate_lli_table_max_size(struct sep_device *sep,\r\nstruct sep_lli_entry *lli_in_array_ptr,\r\nu32 num_array_entries,\r\nu32 *last_table_flag)\r\n{\r\nu32 counter;\r\nu32 table_data_size = 0;\r\nu32 next_table_data_size;\r\n*last_table_flag = 0;\r\nfor (counter = 0;\r\n(counter < (SEP_DRIVER_ENTRIES_PER_TABLE_IN_SEP - 1)) &&\r\n(counter < num_array_entries); counter++)\r\ntable_data_size += lli_in_array_ptr[counter].block_size;\r\nif (counter == num_array_entries) {\r\n*last_table_flag = 1;\r\ngoto end_function;\r\n}\r\nnext_table_data_size = 0;\r\nfor (; counter < num_array_entries; counter++) {\r\nnext_table_data_size += lli_in_array_ptr[counter].block_size;\r\nif (next_table_data_size >= SEP_DRIVER_MIN_DATA_SIZE_PER_TABLE)\r\nbreak;\r\n}\r\nif (next_table_data_size &&\r\nnext_table_data_size < SEP_DRIVER_MIN_DATA_SIZE_PER_TABLE)\r\ntable_data_size -= (SEP_DRIVER_MIN_DATA_SIZE_PER_TABLE -\r\nnext_table_data_size);\r\nend_function:\r\nreturn table_data_size;\r\n}\r\nstatic void sep_build_lli_table(struct sep_device *sep,\r\nstruct sep_lli_entry *lli_array_ptr,\r\nstruct sep_lli_entry *lli_table_ptr,\r\nu32 *num_processed_entries_ptr,\r\nu32 *num_table_entries_ptr,\r\nu32 table_data_size)\r\n{\r\nu32 curr_table_data_size;\r\nu32 array_counter;\r\ncurr_table_data_size = 0;\r\narray_counter = 0;\r\n*num_table_entries_ptr = 1;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] build lli table table_data_size: (hex) %x\n",\r\ncurrent->pid, table_data_size);\r\nwhile (curr_table_data_size < table_data_size) {\r\n(*num_table_entries_ptr)++;\r\nlli_table_ptr->bus_address =\r\ncpu_to_le32(lli_array_ptr[array_counter].bus_address);\r\nlli_table_ptr->block_size =\r\ncpu_to_le32(lli_array_ptr[array_counter].block_size);\r\ncurr_table_data_size += lli_array_ptr[array_counter].block_size;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] lli_table_ptr is %p\n",\r\ncurrent->pid, lli_table_ptr);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] lli_table_ptr->bus_address: %08lx\n",\r\ncurrent->pid,\r\n(unsigned long)lli_table_ptr->bus_address);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] lli_table_ptr->block_size is (hex) %x\n",\r\ncurrent->pid, lli_table_ptr->block_size);\r\nif (curr_table_data_size > table_data_size) {\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] curr_table_data_size too large\n",\r\ncurrent->pid);\r\nlli_table_ptr->block_size =\r\ncpu_to_le32(lli_table_ptr->block_size) -\r\n(curr_table_data_size - table_data_size);\r\nlli_array_ptr[array_counter].bus_address +=\r\ncpu_to_le32(lli_table_ptr->block_size);\r\nlli_array_ptr[array_counter].block_size =\r\n(curr_table_data_size - table_data_size);\r\n} else\r\narray_counter++;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] lli_table_ptr->bus_address is %08lx\n",\r\ncurrent->pid,\r\n(unsigned long)lli_table_ptr->bus_address);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] lli_table_ptr->block_size is (hex) %x\n",\r\ncurrent->pid,\r\nlli_table_ptr->block_size);\r\nlli_table_ptr++;\r\n}\r\nlli_table_ptr->bus_address = 0xffffffff;\r\nlli_table_ptr->block_size = 0;\r\n*num_processed_entries_ptr += array_counter;\r\n}\r\nstatic dma_addr_t sep_shared_area_virt_to_bus(struct sep_device *sep,\r\nvoid *virt_address)\r\n{\r\ndev_dbg(&sep->pdev->dev, "[PID%d] sh virt to phys v %p\n",\r\ncurrent->pid, virt_address);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] sh virt to phys p %08lx\n",\r\ncurrent->pid,\r\n(unsigned long)\r\nsep->shared_bus + (virt_address - sep->shared_addr));\r\nreturn sep->shared_bus + (size_t)(virt_address - sep->shared_addr);\r\n}\r\nstatic void *sep_shared_area_bus_to_virt(struct sep_device *sep,\r\ndma_addr_t bus_address)\r\n{\r\ndev_dbg(&sep->pdev->dev, "[PID%d] shared bus to virt b=%lx v=%lx\n",\r\ncurrent->pid,\r\n(unsigned long)bus_address, (unsigned long)(sep->shared_addr +\r\n(size_t)(bus_address - sep->shared_bus)));\r\nreturn sep->shared_addr + (size_t)(bus_address - sep->shared_bus);\r\n}\r\nstatic void sep_debug_print_lli_tables(struct sep_device *sep,\r\nstruct sep_lli_entry *lli_table_ptr,\r\nunsigned long num_table_entries,\r\nunsigned long table_data_size)\r\n{\r\n#ifdef DEBUG\r\nunsigned long table_count = 1;\r\nunsigned long entries_count = 0;\r\ndev_dbg(&sep->pdev->dev, "[PID%d] sep_debug_print_lli_tables start\n",\r\ncurrent->pid);\r\nif (num_table_entries == 0) {\r\ndev_dbg(&sep->pdev->dev, "[PID%d] no table to print\n",\r\ncurrent->pid);\r\nreturn;\r\n}\r\nwhile ((unsigned long) lli_table_ptr->bus_address != 0xffffffff) {\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] lli table %08lx, "\r\n"table_data_size is (hex) %lx\n",\r\ncurrent->pid, table_count, table_data_size);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] num_table_entries is (hex) %lx\n",\r\ncurrent->pid, num_table_entries);\r\nfor (entries_count = 0; entries_count < num_table_entries;\r\nentries_count++, lli_table_ptr++) {\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] lli_table_ptr address is %08lx\n",\r\ncurrent->pid,\r\n(unsigned long) lli_table_ptr);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] phys address is %08lx "\r\n"block size is (hex) %x\n", current->pid,\r\n(unsigned long)lli_table_ptr->bus_address,\r\nlli_table_ptr->block_size);\r\n}\r\nlli_table_ptr--;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] phys lli_table_ptr->block_size "\r\n"is (hex) %x\n",\r\ncurrent->pid,\r\nlli_table_ptr->block_size);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] phys lli_table_ptr->physical_address "\r\n"is %08lx\n",\r\ncurrent->pid,\r\n(unsigned long)lli_table_ptr->bus_address);\r\ntable_data_size = lli_table_ptr->block_size & 0xffffff;\r\nnum_table_entries = (lli_table_ptr->block_size >> 24) & 0xff;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] phys table_data_size is "\r\n"(hex) %lx num_table_entries is"\r\n" %lx bus_address is%lx\n",\r\ncurrent->pid,\r\ntable_data_size,\r\nnum_table_entries,\r\n(unsigned long)lli_table_ptr->bus_address);\r\nif ((unsigned long)lli_table_ptr->bus_address != 0xffffffff)\r\nlli_table_ptr = (struct sep_lli_entry *)\r\nsep_shared_bus_to_virt(sep,\r\n(unsigned long)lli_table_ptr->bus_address);\r\ntable_count++;\r\n}\r\ndev_dbg(&sep->pdev->dev, "[PID%d] sep_debug_print_lli_tables end\n",\r\ncurrent->pid);\r\n#endif\r\n}\r\nstatic void sep_prepare_empty_lli_table(struct sep_device *sep,\r\ndma_addr_t *lli_table_addr_ptr,\r\nu32 *num_entries_ptr,\r\nu32 *table_data_size_ptr,\r\nvoid **dmatables_region,\r\nstruct sep_dma_context *dma_ctx)\r\n{\r\nstruct sep_lli_entry *lli_table_ptr;\r\nlli_table_ptr =\r\n(struct sep_lli_entry *)(sep->shared_addr +\r\nSYNCHRONIC_DMA_TABLES_AREA_OFFSET_BYTES +\r\ndma_ctx->num_lli_tables_created * sizeof(struct sep_lli_entry) *\r\nSEP_DRIVER_ENTRIES_PER_TABLE_IN_SEP);\r\nif (dmatables_region && *dmatables_region)\r\nlli_table_ptr = *dmatables_region;\r\nlli_table_ptr->bus_address = 0;\r\nlli_table_ptr->block_size = 0;\r\nlli_table_ptr++;\r\nlli_table_ptr->bus_address = 0xFFFFFFFF;\r\nlli_table_ptr->block_size = 0;\r\n*lli_table_addr_ptr = sep->shared_bus +\r\nSYNCHRONIC_DMA_TABLES_AREA_OFFSET_BYTES +\r\ndma_ctx->num_lli_tables_created *\r\nsizeof(struct sep_lli_entry) *\r\nSEP_DRIVER_ENTRIES_PER_TABLE_IN_SEP;\r\n*num_entries_ptr = 2;\r\n*table_data_size_ptr = 0;\r\ndma_ctx->num_lli_tables_created++;\r\n}\r\nstatic int sep_prepare_input_dma_table(struct sep_device *sep,\r\nunsigned long app_virt_addr,\r\nu32 data_size,\r\nu32 block_size,\r\ndma_addr_t *lli_table_ptr,\r\nu32 *num_entries_ptr,\r\nu32 *table_data_size_ptr,\r\nbool is_kva,\r\nvoid **dmatables_region,\r\nstruct sep_dma_context *dma_ctx\r\n)\r\n{\r\nint error = 0;\r\nstruct sep_lli_entry *info_entry_ptr;\r\nstruct sep_lli_entry *lli_array_ptr;\r\nu32 current_entry = 0;\r\nu32 sep_lli_entries = 0;\r\nstruct sep_lli_entry *in_lli_table_ptr;\r\nu32 table_data_size = 0;\r\nu32 last_table_flag = 0;\r\nu32 num_entries_in_table = 0;\r\nvoid *lli_table_alloc_addr = NULL;\r\nvoid *dma_lli_table_alloc_addr = NULL;\r\nvoid *dma_in_lli_table_ptr = NULL;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] prepare intput dma tbl data size: (hex) %x\n",\r\ncurrent->pid, data_size);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] block_size is (hex) %x\n",\r\ncurrent->pid, block_size);\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_page_array = NULL;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_num_pages = 0;\r\nlli_table_alloc_addr = (void *)(sep->shared_addr +\r\nSYNCHRONIC_DMA_TABLES_AREA_OFFSET_BYTES +\r\ndma_ctx->num_lli_tables_created * sizeof(struct sep_lli_entry) *\r\nSEP_DRIVER_ENTRIES_PER_TABLE_IN_SEP);\r\nif (data_size == 0) {\r\nif (dmatables_region) {\r\nerror = sep_allocate_dmatables_region(sep,\r\ndmatables_region,\r\ndma_ctx,\r\n1);\r\nif (error)\r\nreturn error;\r\n}\r\nsep_prepare_empty_lli_table(sep, lli_table_ptr,\r\nnum_entries_ptr, table_data_size_ptr,\r\ndmatables_region, dma_ctx);\r\ngoto update_dcb_counter;\r\n}\r\nif (is_kva == true)\r\nerror = sep_lock_kernel_pages(sep, app_virt_addr,\r\ndata_size, &lli_array_ptr, SEP_DRIVER_IN_FLAG,\r\ndma_ctx);\r\nelse\r\nerror = sep_lock_user_pages(sep, app_virt_addr,\r\ndata_size, &lli_array_ptr, SEP_DRIVER_IN_FLAG,\r\ndma_ctx);\r\nif (error)\r\ngoto end_function;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] output sep_in_num_pages is (hex) %x\n",\r\ncurrent->pid,\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_num_pages);\r\ncurrent_entry = 0;\r\ninfo_entry_ptr = NULL;\r\nsep_lli_entries =\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_num_pages;\r\ndma_lli_table_alloc_addr = lli_table_alloc_addr;\r\nif (dmatables_region) {\r\nerror = sep_allocate_dmatables_region(sep,\r\ndmatables_region,\r\ndma_ctx,\r\nsep_lli_entries);\r\nif (error)\r\ngoto end_function_error;\r\nlli_table_alloc_addr = *dmatables_region;\r\n}\r\nwhile (current_entry < sep_lli_entries) {\r\nin_lli_table_ptr =\r\n(struct sep_lli_entry *)lli_table_alloc_addr;\r\ndma_in_lli_table_ptr =\r\n(struct sep_lli_entry *)dma_lli_table_alloc_addr;\r\nlli_table_alloc_addr += sizeof(struct sep_lli_entry) *\r\nSEP_DRIVER_ENTRIES_PER_TABLE_IN_SEP;\r\ndma_lli_table_alloc_addr += sizeof(struct sep_lli_entry) *\r\nSEP_DRIVER_ENTRIES_PER_TABLE_IN_SEP;\r\nif (dma_lli_table_alloc_addr >\r\n((void *)sep->shared_addr +\r\nSYNCHRONIC_DMA_TABLES_AREA_OFFSET_BYTES +\r\nSYNCHRONIC_DMA_TABLES_AREA_SIZE_BYTES)) {\r\nerror = -ENOMEM;\r\ngoto end_function_error;\r\n}\r\ndma_ctx->num_lli_tables_created++;\r\ntable_data_size = sep_calculate_lli_table_max_size(sep,\r\n&lli_array_ptr[current_entry],\r\n(sep_lli_entries - current_entry),\r\n&last_table_flag);\r\nif (!last_table_flag)\r\ntable_data_size =\r\n(table_data_size / block_size) * block_size;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] output table_data_size is (hex) %x\n",\r\ncurrent->pid,\r\ntable_data_size);\r\nsep_build_lli_table(sep, &lli_array_ptr[current_entry],\r\nin_lli_table_ptr,\r\n&current_entry, &num_entries_in_table, table_data_size);\r\nif (info_entry_ptr == NULL) {\r\n*lli_table_ptr = sep_shared_area_virt_to_bus(sep,\r\ndma_in_lli_table_ptr);\r\n*num_entries_ptr = num_entries_in_table;\r\n*table_data_size_ptr = table_data_size;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] output lli_table_in_ptr is %08lx\n",\r\ncurrent->pid,\r\n(unsigned long)*lli_table_ptr);\r\n} else {\r\ninfo_entry_ptr->bus_address =\r\nsep_shared_area_virt_to_bus(sep,\r\ndma_in_lli_table_ptr);\r\ninfo_entry_ptr->block_size =\r\n((num_entries_in_table) << 24) |\r\n(table_data_size);\r\n}\r\ninfo_entry_ptr = in_lli_table_ptr + num_entries_in_table - 1;\r\n}\r\nif (!dmatables_region) {\r\nsep_debug_print_lli_tables(sep, (struct sep_lli_entry *)\r\nsep_shared_area_bus_to_virt(sep, *lli_table_ptr),\r\n*num_entries_ptr, *table_data_size_ptr);\r\n}\r\nkfree(lli_array_ptr);\r\nupdate_dcb_counter:\r\ndma_ctx->nr_dcb_creat++;\r\ngoto end_function;\r\nend_function_error:\r\nkfree(dma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_map_array);\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_map_array = NULL;\r\nkfree(lli_array_ptr);\r\nkfree(dma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_page_array);\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_page_array = NULL;\r\nend_function:\r\nreturn error;\r\n}\r\nstatic int sep_construct_dma_tables_from_lli(\r\nstruct sep_device *sep,\r\nstruct sep_lli_entry *lli_in_array,\r\nu32 sep_in_lli_entries,\r\nstruct sep_lli_entry *lli_out_array,\r\nu32 sep_out_lli_entries,\r\nu32 block_size,\r\ndma_addr_t *lli_table_in_ptr,\r\ndma_addr_t *lli_table_out_ptr,\r\nu32 *in_num_entries_ptr,\r\nu32 *out_num_entries_ptr,\r\nu32 *table_data_size_ptr,\r\nvoid **dmatables_region,\r\nstruct sep_dma_context *dma_ctx)\r\n{\r\nvoid *lli_table_alloc_addr = NULL;\r\nvoid *dma_lli_table_alloc_addr = NULL;\r\nstruct sep_lli_entry *in_lli_table_ptr = NULL;\r\nstruct sep_lli_entry *dma_in_lli_table_ptr = NULL;\r\nstruct sep_lli_entry *out_lli_table_ptr = NULL;\r\nstruct sep_lli_entry *dma_out_lli_table_ptr = NULL;\r\nstruct sep_lli_entry *info_in_entry_ptr = NULL;\r\nstruct sep_lli_entry *info_out_entry_ptr = NULL;\r\nu32 current_in_entry = 0;\r\nu32 current_out_entry = 0;\r\nu32 in_table_data_size = 0;\r\nu32 out_table_data_size = 0;\r\nu32 last_table_flag = 0;\r\nu32 table_data_size = 0;\r\nu32 num_entries_in_table = 0;\r\nu32 num_entries_out_table = 0;\r\nif (!dma_ctx) {\r\ndev_warn(&sep->pdev->dev, "DMA context uninitialized\n");\r\nreturn -EINVAL;\r\n}\r\nlli_table_alloc_addr = (void *)(sep->shared_addr +\r\nSYNCHRONIC_DMA_TABLES_AREA_OFFSET_BYTES +\r\n(dma_ctx->num_lli_tables_created *\r\n(sizeof(struct sep_lli_entry) *\r\nSEP_DRIVER_ENTRIES_PER_TABLE_IN_SEP)));\r\ndma_lli_table_alloc_addr = lli_table_alloc_addr;\r\nif (dmatables_region) {\r\nif (sep_allocate_dmatables_region(sep,\r\ndmatables_region,\r\ndma_ctx,\r\n2*sep_in_lli_entries))\r\nreturn -ENOMEM;\r\nlli_table_alloc_addr = *dmatables_region;\r\n}\r\nwhile (current_in_entry < sep_in_lli_entries) {\r\nin_lli_table_ptr =\r\n(struct sep_lli_entry *)lli_table_alloc_addr;\r\ndma_in_lli_table_ptr =\r\n(struct sep_lli_entry *)dma_lli_table_alloc_addr;\r\nlli_table_alloc_addr += sizeof(struct sep_lli_entry) *\r\nSEP_DRIVER_ENTRIES_PER_TABLE_IN_SEP;\r\ndma_lli_table_alloc_addr += sizeof(struct sep_lli_entry) *\r\nSEP_DRIVER_ENTRIES_PER_TABLE_IN_SEP;\r\nout_lli_table_ptr =\r\n(struct sep_lli_entry *)lli_table_alloc_addr;\r\ndma_out_lli_table_ptr =\r\n(struct sep_lli_entry *)dma_lli_table_alloc_addr;\r\nif ((dma_lli_table_alloc_addr + sizeof(struct sep_lli_entry) *\r\nSEP_DRIVER_ENTRIES_PER_TABLE_IN_SEP) >\r\n((void *)sep->shared_addr +\r\nSYNCHRONIC_DMA_TABLES_AREA_OFFSET_BYTES +\r\nSYNCHRONIC_DMA_TABLES_AREA_SIZE_BYTES)) {\r\ndev_warn(&sep->pdev->dev, "dma table limit overrun\n");\r\nreturn -ENOMEM;\r\n}\r\ndma_ctx->num_lli_tables_created += 2;\r\nlli_table_alloc_addr += sizeof(struct sep_lli_entry) *\r\nSEP_DRIVER_ENTRIES_PER_TABLE_IN_SEP;\r\ndma_lli_table_alloc_addr += sizeof(struct sep_lli_entry) *\r\nSEP_DRIVER_ENTRIES_PER_TABLE_IN_SEP;\r\nin_table_data_size =\r\nsep_calculate_lli_table_max_size(sep,\r\n&lli_in_array[current_in_entry],\r\n(sep_in_lli_entries - current_in_entry),\r\n&last_table_flag);\r\nout_table_data_size =\r\nsep_calculate_lli_table_max_size(sep,\r\n&lli_out_array[current_out_entry],\r\n(sep_out_lli_entries - current_out_entry),\r\n&last_table_flag);\r\nif (!last_table_flag) {\r\nin_table_data_size = (in_table_data_size /\r\nblock_size) * block_size;\r\nout_table_data_size = (out_table_data_size /\r\nblock_size) * block_size;\r\n}\r\ntable_data_size = in_table_data_size;\r\nif (table_data_size > out_table_data_size)\r\ntable_data_size = out_table_data_size;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] construct tables from lli"\r\n" in_table_data_size is (hex) %x\n", current->pid,\r\nin_table_data_size);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] construct tables from lli"\r\n"out_table_data_size is (hex) %x\n", current->pid,\r\nout_table_data_size);\r\nsep_build_lli_table(sep, &lli_in_array[current_in_entry],\r\nin_lli_table_ptr,\r\n&current_in_entry,\r\n&num_entries_in_table,\r\ntable_data_size);\r\nsep_build_lli_table(sep, &lli_out_array[current_out_entry],\r\nout_lli_table_ptr,\r\n&current_out_entry,\r\n&num_entries_out_table,\r\ntable_data_size);\r\nif (info_in_entry_ptr == NULL || info_out_entry_ptr == NULL) {\r\n*lli_table_in_ptr =\r\nsep_shared_area_virt_to_bus(sep, dma_in_lli_table_ptr);\r\n*in_num_entries_ptr = num_entries_in_table;\r\n*lli_table_out_ptr =\r\nsep_shared_area_virt_to_bus(sep,\r\ndma_out_lli_table_ptr);\r\n*out_num_entries_ptr = num_entries_out_table;\r\n*table_data_size_ptr = table_data_size;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] output lli_table_in_ptr is %08lx\n",\r\ncurrent->pid,\r\n(unsigned long)*lli_table_in_ptr);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] output lli_table_out_ptr is %08lx\n",\r\ncurrent->pid,\r\n(unsigned long)*lli_table_out_ptr);\r\n} else {\r\ninfo_in_entry_ptr->bus_address =\r\nsep_shared_area_virt_to_bus(sep,\r\ndma_in_lli_table_ptr);\r\ninfo_in_entry_ptr->block_size =\r\n((num_entries_in_table) << 24) |\r\n(table_data_size);\r\ninfo_out_entry_ptr->bus_address =\r\nsep_shared_area_virt_to_bus(sep,\r\ndma_out_lli_table_ptr);\r\ninfo_out_entry_ptr->block_size =\r\n((num_entries_out_table) << 24) |\r\n(table_data_size);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] output lli_table_in_ptr:%08lx %08x\n",\r\ncurrent->pid,\r\n(unsigned long)info_in_entry_ptr->bus_address,\r\ninfo_in_entry_ptr->block_size);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] output lli_table_out_ptr:"\r\n"%08lx %08x\n",\r\ncurrent->pid,\r\n(unsigned long)info_out_entry_ptr->bus_address,\r\ninfo_out_entry_ptr->block_size);\r\n}\r\ninfo_in_entry_ptr = in_lli_table_ptr +\r\nnum_entries_in_table - 1;\r\ninfo_out_entry_ptr = out_lli_table_ptr +\r\nnum_entries_out_table - 1;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] output num_entries_out_table is %x\n",\r\ncurrent->pid,\r\n(u32)num_entries_out_table);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] output info_in_entry_ptr is %lx\n",\r\ncurrent->pid,\r\n(unsigned long)info_in_entry_ptr);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] output info_out_entry_ptr is %lx\n",\r\ncurrent->pid,\r\n(unsigned long)info_out_entry_ptr);\r\n}\r\nif (!dmatables_region) {\r\nsep_debug_print_lli_tables(\r\nsep,\r\n(struct sep_lli_entry *)\r\nsep_shared_area_bus_to_virt(sep, *lli_table_in_ptr),\r\n*in_num_entries_ptr,\r\n*table_data_size_ptr);\r\n}\r\nif (!dmatables_region) {\r\nsep_debug_print_lli_tables(\r\nsep,\r\n(struct sep_lli_entry *)\r\nsep_shared_area_bus_to_virt(sep, *lli_table_out_ptr),\r\n*out_num_entries_ptr,\r\n*table_data_size_ptr);\r\n}\r\nreturn 0;\r\n}\r\nstatic int sep_prepare_input_output_dma_table(struct sep_device *sep,\r\nunsigned long app_virt_in_addr,\r\nunsigned long app_virt_out_addr,\r\nu32 data_size,\r\nu32 block_size,\r\ndma_addr_t *lli_table_in_ptr,\r\ndma_addr_t *lli_table_out_ptr,\r\nu32 *in_num_entries_ptr,\r\nu32 *out_num_entries_ptr,\r\nu32 *table_data_size_ptr,\r\nbool is_kva,\r\nvoid **dmatables_region,\r\nstruct sep_dma_context *dma_ctx)\r\n{\r\nint error = 0;\r\nstruct sep_lli_entry *lli_in_array;\r\nstruct sep_lli_entry *lli_out_array;\r\nif (!dma_ctx) {\r\nerror = -EINVAL;\r\ngoto end_function;\r\n}\r\nif (data_size == 0) {\r\nif (dmatables_region) {\r\nerror = sep_allocate_dmatables_region(\r\nsep,\r\ndmatables_region,\r\ndma_ctx,\r\n2);\r\nif (error)\r\ngoto end_function;\r\n}\r\nsep_prepare_empty_lli_table(sep, lli_table_in_ptr,\r\nin_num_entries_ptr, table_data_size_ptr,\r\ndmatables_region, dma_ctx);\r\nsep_prepare_empty_lli_table(sep, lli_table_out_ptr,\r\nout_num_entries_ptr, table_data_size_ptr,\r\ndmatables_region, dma_ctx);\r\ngoto update_dcb_counter;\r\n}\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_page_array = NULL;\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].out_page_array = NULL;\r\nif (is_kva == true) {\r\ndev_dbg(&sep->pdev->dev, "[PID%d] Locking kernel input pages\n",\r\ncurrent->pid);\r\nerror = sep_lock_kernel_pages(sep, app_virt_in_addr,\r\ndata_size, &lli_in_array, SEP_DRIVER_IN_FLAG,\r\ndma_ctx);\r\nif (error) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] sep_lock_kernel_pages for input "\r\n"virtual buffer failed\n", current->pid);\r\ngoto end_function;\r\n}\r\ndev_dbg(&sep->pdev->dev, "[PID%d] Locking kernel output pages\n",\r\ncurrent->pid);\r\nerror = sep_lock_kernel_pages(sep, app_virt_out_addr,\r\ndata_size, &lli_out_array, SEP_DRIVER_OUT_FLAG,\r\ndma_ctx);\r\nif (error) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] sep_lock_kernel_pages for output "\r\n"virtual buffer failed\n", current->pid);\r\ngoto end_function_free_lli_in;\r\n}\r\n}\r\nelse {\r\ndev_dbg(&sep->pdev->dev, "[PID%d] Locking user input pages\n",\r\ncurrent->pid);\r\nerror = sep_lock_user_pages(sep, app_virt_in_addr,\r\ndata_size, &lli_in_array, SEP_DRIVER_IN_FLAG,\r\ndma_ctx);\r\nif (error) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] sep_lock_user_pages for input "\r\n"virtual buffer failed\n", current->pid);\r\ngoto end_function;\r\n}\r\nif (dma_ctx->secure_dma == true) {\r\ndev_dbg(&sep->pdev->dev, "[PID%d] in secure_dma\n",\r\ncurrent->pid);\r\nerror = sep_lli_table_secure_dma(sep,\r\napp_virt_out_addr, data_size, &lli_out_array,\r\nSEP_DRIVER_OUT_FLAG, dma_ctx);\r\nif (error) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] secure dma table setup "\r\n" for output virtual buffer failed\n",\r\ncurrent->pid);\r\ngoto end_function_free_lli_in;\r\n}\r\n} else {\r\ndev_dbg(&sep->pdev->dev, "[PID%d] not in secure_dma\n",\r\ncurrent->pid);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] Locking user output pages\n",\r\ncurrent->pid);\r\nerror = sep_lock_user_pages(sep, app_virt_out_addr,\r\ndata_size, &lli_out_array, SEP_DRIVER_OUT_FLAG,\r\ndma_ctx);\r\nif (error) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] sep_lock_user_pages"\r\n" for output virtual buffer failed\n",\r\ncurrent->pid);\r\ngoto end_function_free_lli_in;\r\n}\r\n}\r\n}\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] After lock; prep input output dma table sep_in_num_pages is (hex) %x\n",\r\ncurrent->pid,\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_num_pages);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] sep_out_num_pages is (hex) %x\n",\r\ncurrent->pid,\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].out_num_pages);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] SEP_DRIVER_ENTRIES_PER_TABLE_IN_SEP is (hex) %x\n",\r\ncurrent->pid, SEP_DRIVER_ENTRIES_PER_TABLE_IN_SEP);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] calling create table from lli\n",\r\ncurrent->pid);\r\nerror = sep_construct_dma_tables_from_lli(\r\nsep, lli_in_array,\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].\r\nin_num_pages,\r\nlli_out_array,\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].\r\nout_num_pages,\r\nblock_size, lli_table_in_ptr, lli_table_out_ptr,\r\nin_num_entries_ptr, out_num_entries_ptr,\r\ntable_data_size_ptr, dmatables_region, dma_ctx);\r\nif (error) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] sep_construct_dma_tables_from_lli failed\n",\r\ncurrent->pid);\r\ngoto end_function_with_error;\r\n}\r\nkfree(lli_out_array);\r\nkfree(lli_in_array);\r\nupdate_dcb_counter:\r\ndma_ctx->nr_dcb_creat++;\r\ngoto end_function;\r\nend_function_with_error:\r\nkfree(dma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].out_map_array);\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].out_map_array = NULL;\r\nkfree(dma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].out_page_array);\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].out_page_array = NULL;\r\nkfree(lli_out_array);\r\nend_function_free_lli_in:\r\nkfree(dma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_map_array);\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_map_array = NULL;\r\nkfree(dma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_page_array);\r\ndma_ctx->dma_res_arr[dma_ctx->nr_dcb_creat].in_page_array = NULL;\r\nkfree(lli_in_array);\r\nend_function:\r\nreturn error;\r\n}\r\nint sep_prepare_input_output_dma_table_in_dcb(struct sep_device *sep,\r\nunsigned long app_in_address,\r\nunsigned long app_out_address,\r\nu32 data_in_size,\r\nu32 block_size,\r\nu32 tail_block_size,\r\nbool isapplet,\r\nbool is_kva,\r\nbool secure_dma,\r\nstruct sep_dcblock *dcb_region,\r\nvoid **dmatables_region,\r\nstruct sep_dma_context **dma_ctx,\r\nstruct scatterlist *src_sg,\r\nstruct scatterlist *dst_sg)\r\n{\r\nint error = 0;\r\nu32 tail_size = 0;\r\nstruct sep_dcblock *dcb_table_ptr = NULL;\r\ndma_addr_t in_first_mlli_address = 0;\r\nu32 in_first_num_entries = 0;\r\ndma_addr_t out_first_mlli_address = 0;\r\nu32 out_first_num_entries = 0;\r\nu32 first_data_size = 0;\r\ndev_dbg(&sep->pdev->dev, "[PID%d] app_in_address %lx\n",\r\ncurrent->pid, app_in_address);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] app_out_address %lx\n",\r\ncurrent->pid, app_out_address);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] data_in_size %x\n",\r\ncurrent->pid, data_in_size);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] block_size %x\n",\r\ncurrent->pid, block_size);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] tail_block_size %x\n",\r\ncurrent->pid, tail_block_size);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] isapplet %x\n",\r\ncurrent->pid, isapplet);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] is_kva %x\n",\r\ncurrent->pid, is_kva);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] src_sg %p\n",\r\ncurrent->pid, src_sg);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] dst_sg %p\n",\r\ncurrent->pid, dst_sg);\r\nif (!dma_ctx) {\r\ndev_warn(&sep->pdev->dev, "[PID%d] no DMA context pointer\n",\r\ncurrent->pid);\r\nerror = -EINVAL;\r\ngoto end_function;\r\n}\r\nif (*dma_ctx) {\r\ndev_dbg(&sep->pdev->dev, "[PID%d] DMA context already set\n",\r\ncurrent->pid);\r\n} else {\r\n*dma_ctx = kzalloc(sizeof(**dma_ctx), GFP_KERNEL);\r\nif (!(*dma_ctx)) {\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] Not enough memory for DMA context\n",\r\ncurrent->pid);\r\nerror = -ENOMEM;\r\ngoto end_function;\r\n}\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] Created DMA context addr at 0x%p\n",\r\ncurrent->pid, *dma_ctx);\r\n}\r\n(*dma_ctx)->secure_dma = secure_dma;\r\n(*dma_ctx)->src_sg = src_sg;\r\n(*dma_ctx)->dst_sg = dst_sg;\r\nif ((*dma_ctx)->nr_dcb_creat == SEP_MAX_NUM_SYNC_DMA_OPS) {\r\ndev_dbg(&sep->pdev->dev, "[PID%d] no more DCBs available\n",\r\ncurrent->pid);\r\nerror = -ENOSPC;\r\ngoto end_function_error;\r\n}\r\nif (dcb_region) {\r\ndcb_table_ptr = dcb_region;\r\n} else {\r\ndcb_table_ptr = (struct sep_dcblock *)(sep->shared_addr +\r\nSEP_DRIVER_SYSTEM_DCB_MEMORY_OFFSET_IN_BYTES +\r\n((*dma_ctx)->nr_dcb_creat *\r\nsizeof(struct sep_dcblock)));\r\n}\r\ndcb_table_ptr->input_mlli_address = 0;\r\ndcb_table_ptr->input_mlli_num_entries = 0;\r\ndcb_table_ptr->input_mlli_data_size = 0;\r\ndcb_table_ptr->output_mlli_address = 0;\r\ndcb_table_ptr->output_mlli_num_entries = 0;\r\ndcb_table_ptr->output_mlli_data_size = 0;\r\ndcb_table_ptr->tail_data_size = 0;\r\ndcb_table_ptr->out_vr_tail_pt = 0;\r\nif (isapplet == true) {\r\nif (data_in_size < SEP_DRIVER_MIN_DATA_SIZE_PER_TABLE) {\r\nif (is_kva == true) {\r\nerror = -ENODEV;\r\ngoto end_function_error;\r\n} else {\r\nif (copy_from_user(dcb_table_ptr->tail_data,\r\n(void __user *)app_in_address,\r\ndata_in_size)) {\r\nerror = -EFAULT;\r\ngoto end_function_error;\r\n}\r\n}\r\ndcb_table_ptr->tail_data_size = data_in_size;\r\nif (app_out_address)\r\ndcb_table_ptr->out_vr_tail_pt =\r\n(aligned_u64)app_out_address;\r\ntail_size = 0x0;\r\ndata_in_size = 0x0;\r\n} else {\r\nif (!app_out_address) {\r\ntail_size = data_in_size % block_size;\r\nif (!tail_size) {\r\nif (tail_block_size == block_size)\r\ntail_size = block_size;\r\n}\r\n} else {\r\ntail_size = 0;\r\n}\r\n}\r\nif (tail_size) {\r\nif (tail_size > sizeof(dcb_table_ptr->tail_data))\r\nreturn -EINVAL;\r\nif (is_kva == true) {\r\nerror = -ENODEV;\r\ngoto end_function_error;\r\n} else {\r\nif (copy_from_user(dcb_table_ptr->tail_data,\r\n(void __user *)(app_in_address +\r\ndata_in_size - tail_size), tail_size)) {\r\nerror = -EFAULT;\r\ngoto end_function_error;\r\n}\r\n}\r\nif (app_out_address)\r\ndcb_table_ptr->out_vr_tail_pt =\r\n(aligned_u64)app_out_address +\r\ndata_in_size - tail_size;\r\ndcb_table_ptr->tail_data_size = tail_size;\r\ndata_in_size = (data_in_size - tail_size);\r\n}\r\n}\r\nif (app_out_address) {\r\nerror = sep_prepare_input_output_dma_table(sep,\r\napp_in_address,\r\napp_out_address,\r\ndata_in_size,\r\nblock_size,\r\n&in_first_mlli_address,\r\n&out_first_mlli_address,\r\n&in_first_num_entries,\r\n&out_first_num_entries,\r\n&first_data_size,\r\nis_kva,\r\ndmatables_region,\r\n*dma_ctx);\r\n} else {\r\nerror = sep_prepare_input_dma_table(sep,\r\napp_in_address,\r\ndata_in_size,\r\nblock_size,\r\n&in_first_mlli_address,\r\n&in_first_num_entries,\r\n&first_data_size,\r\nis_kva,\r\ndmatables_region,\r\n*dma_ctx);\r\n}\r\nif (error) {\r\ndev_warn(&sep->pdev->dev,\r\n"prepare DMA table call failed "\r\n"from prepare DCB call\n");\r\ngoto end_function_error;\r\n}\r\ndcb_table_ptr->input_mlli_address = in_first_mlli_address;\r\ndcb_table_ptr->input_mlli_num_entries = in_first_num_entries;\r\ndcb_table_ptr->input_mlli_data_size = first_data_size;\r\ndcb_table_ptr->output_mlli_address = out_first_mlli_address;\r\ndcb_table_ptr->output_mlli_num_entries = out_first_num_entries;\r\ndcb_table_ptr->output_mlli_data_size = first_data_size;\r\ngoto end_function;\r\nend_function_error:\r\nkfree(*dma_ctx);\r\n*dma_ctx = NULL;\r\nend_function:\r\nreturn error;\r\n}\r\nstatic int sep_free_dma_tables_and_dcb(struct sep_device *sep, bool isapplet,\r\nbool is_kva, struct sep_dma_context **dma_ctx)\r\n{\r\nstruct sep_dcblock *dcb_table_ptr;\r\nunsigned long pt_hold;\r\nvoid *tail_pt;\r\nint i = 0;\r\nint error = 0;\r\nint error_temp = 0;\r\ndev_dbg(&sep->pdev->dev, "[PID%d] sep_free_dma_tables_and_dcb\n",\r\ncurrent->pid);\r\nif (!dma_ctx || !*dma_ctx)\r\nreturn 0;\r\nif (((*dma_ctx)->secure_dma == false) && (isapplet == true)) {\r\ndev_dbg(&sep->pdev->dev, "[PID%d] handling applet\n",\r\ncurrent->pid);\r\ndcb_table_ptr = (struct sep_dcblock *)\r\n(sep->shared_addr +\r\nSEP_DRIVER_SYSTEM_DCB_MEMORY_OFFSET_IN_BYTES);\r\nfor (i = 0; i < (*dma_ctx)->nr_dcb_creat; i++, dcb_table_ptr++) {\r\nif (dcb_table_ptr->out_vr_tail_pt) {\r\npt_hold = (unsigned long)dcb_table_ptr->\r\nout_vr_tail_pt;\r\ntail_pt = (void *)pt_hold;\r\nif (is_kva == true) {\r\nerror = -ENODEV;\r\nbreak;\r\n} else {\r\nerror_temp = copy_to_user(\r\n(void __user *)tail_pt,\r\ndcb_table_ptr->tail_data,\r\ndcb_table_ptr->tail_data_size);\r\n}\r\nif (error_temp) {\r\nerror = -EFAULT;\r\nbreak;\r\n}\r\n}\r\n}\r\n}\r\nsep_free_dma_table_data_handler(sep, dma_ctx);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] sep_free_dma_tables_and_dcb end\n",\r\ncurrent->pid);\r\nreturn error;\r\n}\r\nstatic int sep_prepare_dcb_handler(struct sep_device *sep, unsigned long arg,\r\nbool secure_dma,\r\nstruct sep_dma_context **dma_ctx)\r\n{\r\nint error;\r\nstatic struct build_dcb_struct command_args;\r\nif (copy_from_user(&command_args, (void __user *)arg,\r\nsizeof(struct build_dcb_struct))) {\r\nerror = -EFAULT;\r\ngoto end_function;\r\n}\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] prep dcb handler app_in_address is %08llx\n",\r\ncurrent->pid, command_args.app_in_address);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] app_out_address is %08llx\n",\r\ncurrent->pid, command_args.app_out_address);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] data_size is %x\n",\r\ncurrent->pid, command_args.data_in_size);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] block_size is %x\n",\r\ncurrent->pid, command_args.block_size);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] tail block_size is %x\n",\r\ncurrent->pid, command_args.tail_block_size);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] is_applet is %x\n",\r\ncurrent->pid, command_args.is_applet);\r\nif (!command_args.app_in_address) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] null app_in_address\n", current->pid);\r\nerror = -EINVAL;\r\ngoto end_function;\r\n}\r\nerror = sep_prepare_input_output_dma_table_in_dcb(sep,\r\n(unsigned long)command_args.app_in_address,\r\n(unsigned long)command_args.app_out_address,\r\ncommand_args.data_in_size, command_args.block_size,\r\ncommand_args.tail_block_size,\r\ncommand_args.is_applet, false,\r\nsecure_dma, NULL, NULL, dma_ctx, NULL, NULL);\r\nend_function:\r\nreturn error;\r\n}\r\nstatic int sep_free_dcb_handler(struct sep_device *sep,\r\nstruct sep_dma_context **dma_ctx)\r\n{\r\nif (!dma_ctx || !(*dma_ctx)) {\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] no dma context defined, nothing to free\n",\r\ncurrent->pid);\r\nreturn -EINVAL;\r\n}\r\ndev_dbg(&sep->pdev->dev, "[PID%d] free dcbs num of DCBs %x\n",\r\ncurrent->pid,\r\n(*dma_ctx)->nr_dcb_creat);\r\nreturn sep_free_dma_tables_and_dcb(sep, false, false, dma_ctx);\r\n}\r\nstatic long sep_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)\r\n{\r\nstruct sep_private_data * const private_data = filp->private_data;\r\nstruct sep_call_status *call_status = &private_data->call_status;\r\nstruct sep_device *sep = private_data->device;\r\nstruct sep_dma_context **dma_ctx = &private_data->dma_ctx;\r\nstruct sep_queue_info **my_queue_elem = &private_data->my_queue_elem;\r\nint error = 0;\r\ndev_dbg(&sep->pdev->dev, "[PID%d] ioctl cmd 0x%x\n",\r\ncurrent->pid, cmd);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] dma context addr 0x%p\n",\r\ncurrent->pid, *dma_ctx);\r\nerror = sep_check_transaction_owner(sep);\r\nif (error) {\r\ndev_dbg(&sep->pdev->dev, "[PID%d] ioctl pid is not owner\n",\r\ncurrent->pid);\r\ngoto end_function;\r\n}\r\nif (0 == test_bit(SEP_LEGACY_MMAP_DONE_OFFSET,\r\n&call_status->status)) {\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] mmap not called\n", current->pid);\r\nerror = -EPROTO;\r\ngoto end_function;\r\n}\r\nif (_IOC_TYPE(cmd) != SEP_IOC_MAGIC_NUMBER) {\r\nerror = -ENOTTY;\r\ngoto end_function;\r\n}\r\nswitch (cmd) {\r\ncase SEP_IOCSENDSEPCOMMAND:\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] SEP_IOCSENDSEPCOMMAND start\n",\r\ncurrent->pid);\r\nif (1 == test_bit(SEP_LEGACY_SENDMSG_DONE_OFFSET,\r\n&call_status->status)) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] send msg already done\n",\r\ncurrent->pid);\r\nerror = -EPROTO;\r\ngoto end_function;\r\n}\r\nerror = sep_send_command_handler(sep);\r\nif (!error)\r\nset_bit(SEP_LEGACY_SENDMSG_DONE_OFFSET,\r\n&call_status->status);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] SEP_IOCSENDSEPCOMMAND end\n",\r\ncurrent->pid);\r\nbreak;\r\ncase SEP_IOCENDTRANSACTION:\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] SEP_IOCENDTRANSACTION start\n",\r\ncurrent->pid);\r\nerror = sep_end_transaction_handler(sep, dma_ctx, call_status,\r\nmy_queue_elem);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] SEP_IOCENDTRANSACTION end\n",\r\ncurrent->pid);\r\nbreak;\r\ncase SEP_IOCPREPAREDCB:\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] SEP_IOCPREPAREDCB start\n",\r\ncurrent->pid);\r\ncase SEP_IOCPREPAREDCB_SECURE_DMA:\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] SEP_IOCPREPAREDCB_SECURE_DMA start\n",\r\ncurrent->pid);\r\nif (1 == test_bit(SEP_LEGACY_SENDMSG_DONE_OFFSET,\r\n&call_status->status)) {\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] dcb prep needed before send msg\n",\r\ncurrent->pid);\r\nerror = -EPROTO;\r\ngoto end_function;\r\n}\r\nif (!arg) {\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] dcb null arg\n", current->pid);\r\nerror = -EINVAL;\r\ngoto end_function;\r\n}\r\nif (cmd == SEP_IOCPREPAREDCB) {\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] SEP_IOCPREPAREDCB (no secure_dma)\n",\r\ncurrent->pid);\r\nerror = sep_prepare_dcb_handler(sep, arg, false,\r\ndma_ctx);\r\n} else {\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] SEP_IOC_POC (with secure_dma)\n",\r\ncurrent->pid);\r\nerror = sep_prepare_dcb_handler(sep, arg, true,\r\ndma_ctx);\r\n}\r\ndev_dbg(&sep->pdev->dev, "[PID%d] dcb's end\n",\r\ncurrent->pid);\r\nbreak;\r\ncase SEP_IOCFREEDCB:\r\ndev_dbg(&sep->pdev->dev, "[PID%d] SEP_IOCFREEDCB start\n",\r\ncurrent->pid);\r\ncase SEP_IOCFREEDCB_SECURE_DMA:\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] SEP_IOCFREEDCB_SECURE_DMA start\n",\r\ncurrent->pid);\r\nerror = sep_free_dcb_handler(sep, dma_ctx);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] SEP_IOCFREEDCB end\n",\r\ncurrent->pid);\r\nbreak;\r\ndefault:\r\nerror = -ENOTTY;\r\ndev_dbg(&sep->pdev->dev, "[PID%d] default end\n",\r\ncurrent->pid);\r\nbreak;\r\n}\r\nend_function:\r\ndev_dbg(&sep->pdev->dev, "[PID%d] ioctl end\n", current->pid);\r\nreturn error;\r\n}\r\nstatic irqreturn_t sep_inthandler(int irq, void *dev_id)\r\n{\r\nunsigned long lock_irq_flag;\r\nu32 reg_val, reg_val2 = 0;\r\nstruct sep_device *sep = dev_id;\r\nirqreturn_t int_error = IRQ_HANDLED;\r\n#if defined(CONFIG_PM_RUNTIME) && defined(SEP_ENABLE_RUNTIME_PM)\r\nif (sep->pdev->dev.power.runtime_status != RPM_ACTIVE) {\r\ndev_dbg(&sep->pdev->dev, "interrupt during pwr save\n");\r\nreturn IRQ_NONE;\r\n}\r\n#endif\r\nif (test_bit(SEP_WORKING_LOCK_BIT, &sep->in_use_flags) == 0) {\r\ndev_dbg(&sep->pdev->dev, "interrupt while nobody using sep\n");\r\nreturn IRQ_NONE;\r\n}\r\nreg_val = sep_read_reg(sep, HW_HOST_IRR_REG_ADDR);\r\ndev_dbg(&sep->pdev->dev, "sep int: IRR REG val: %x\n", reg_val);\r\nif (reg_val & (0x1 << 13)) {\r\nspin_lock_irqsave(&sep->snd_rply_lck, lock_irq_flag);\r\nsep->reply_ct++;\r\nspin_unlock_irqrestore(&sep->snd_rply_lck, lock_irq_flag);\r\ndev_dbg(&sep->pdev->dev, "sep int: send_ct %lx reply_ct %lx\n",\r\nsep->send_ct, sep->reply_ct);\r\nif (sep->in_kernel) {\r\ntasklet_schedule(&sep->finish_tasklet);\r\ngoto finished_interrupt;\r\n}\r\nreg_val2 = sep_read_reg(sep, HW_HOST_SEP_HOST_GPR2_REG_ADDR);\r\ndev_dbg(&sep->pdev->dev,\r\n"SEP Interrupt - GPR2 is %08x\n", reg_val2);\r\nclear_bit(SEP_WORKING_LOCK_BIT, &sep->in_use_flags);\r\nif ((reg_val2 >> 30) & 0x1) {\r\ndev_dbg(&sep->pdev->dev, "int: printf request\n");\r\n} else if (reg_val2 >> 31) {\r\ndev_dbg(&sep->pdev->dev, "int: daemon request\n");\r\n} else {\r\ndev_dbg(&sep->pdev->dev, "int: SEP reply\n");\r\nwake_up(&sep->event_interrupt);\r\n}\r\n} else {\r\ndev_dbg(&sep->pdev->dev, "int: not SEP interrupt\n");\r\nint_error = IRQ_NONE;\r\n}\r\nfinished_interrupt:\r\nif (int_error == IRQ_HANDLED)\r\nsep_write_reg(sep, HW_HOST_ICR_REG_ADDR, reg_val);\r\nreturn int_error;\r\n}\r\nstatic int sep_reconfig_shared_area(struct sep_device *sep)\r\n{\r\nint ret_val;\r\nunsigned long end_time;\r\ndev_dbg(&sep->pdev->dev, "reconfig shared; sending %08llx to sep\n",\r\n(unsigned long long)sep->shared_bus);\r\nsep_write_reg(sep, HW_HOST_HOST_SEP_GPR1_REG_ADDR, sep->shared_bus);\r\nret_val = sep_read_reg(sep, HW_HOST_SEP_HOST_GPR1_REG_ADDR);\r\nend_time = jiffies + (WAIT_TIME * HZ);\r\nwhile ((time_before(jiffies, end_time)) && (ret_val != 0xffffffff) &&\r\n(ret_val != sep->shared_bus))\r\nret_val = sep_read_reg(sep, HW_HOST_SEP_HOST_GPR1_REG_ADDR);\r\nif (ret_val != sep->shared_bus) {\r\ndev_warn(&sep->pdev->dev, "could not reconfig shared area\n");\r\ndev_warn(&sep->pdev->dev, "result was %x\n", ret_val);\r\nret_val = -ENOMEM;\r\n} else\r\nret_val = 0;\r\ndev_dbg(&sep->pdev->dev, "reconfig shared area end\n");\r\nreturn ret_val;\r\n}\r\nssize_t sep_activate_dcb_dmatables_context(struct sep_device *sep,\r\nstruct sep_dcblock **dcb_region,\r\nvoid **dmatables_region,\r\nstruct sep_dma_context *dma_ctx)\r\n{\r\nvoid *dmaregion_free_start = NULL;\r\nvoid *dmaregion_free_end = NULL;\r\nvoid *dcbregion_free_start = NULL;\r\nvoid *dcbregion_free_end = NULL;\r\nssize_t error = 0;\r\ndev_dbg(&sep->pdev->dev, "[PID%d] activating dcb/dma region\n",\r\ncurrent->pid);\r\nif (1 > dma_ctx->nr_dcb_creat) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] invalid number of dcbs to activate 0x%08X\n",\r\ncurrent->pid, dma_ctx->nr_dcb_creat);\r\nerror = -EINVAL;\r\ngoto end_function;\r\n}\r\ndmaregion_free_start = sep->shared_addr\r\n+ SYNCHRONIC_DMA_TABLES_AREA_OFFSET_BYTES;\r\ndmaregion_free_end = dmaregion_free_start\r\n+ SYNCHRONIC_DMA_TABLES_AREA_SIZE_BYTES - 1;\r\nif (dmaregion_free_start\r\n+ dma_ctx->dmatables_len > dmaregion_free_end) {\r\nerror = -ENOMEM;\r\ngoto end_function;\r\n}\r\nmemcpy(dmaregion_free_start,\r\n*dmatables_region,\r\ndma_ctx->dmatables_len);\r\nkfree(*dmatables_region);\r\n*dmatables_region = NULL;\r\ndcbregion_free_start = sep->shared_addr +\r\nSEP_DRIVER_SYSTEM_DCB_MEMORY_OFFSET_IN_BYTES;\r\ndcbregion_free_end = dcbregion_free_start +\r\n(SEP_MAX_NUM_SYNC_DMA_OPS *\r\nsizeof(struct sep_dcblock)) - 1;\r\nif (dcbregion_free_start\r\n+ (dma_ctx->nr_dcb_creat * sizeof(struct sep_dcblock))\r\n> dcbregion_free_end) {\r\nerror = -ENOMEM;\r\ngoto end_function;\r\n}\r\nmemcpy(dcbregion_free_start,\r\n*dcb_region,\r\ndma_ctx->nr_dcb_creat * sizeof(struct sep_dcblock));\r\ndev_dbg(&sep->pdev->dev, "activate: input table\n");\r\nsep_debug_print_lli_tables(sep,\r\n(struct sep_lli_entry *)sep_shared_area_bus_to_virt(sep,\r\n(*dcb_region)->input_mlli_address),\r\n(*dcb_region)->input_mlli_num_entries,\r\n(*dcb_region)->input_mlli_data_size);\r\ndev_dbg(&sep->pdev->dev, "activate: output table\n");\r\nsep_debug_print_lli_tables(sep,\r\n(struct sep_lli_entry *)sep_shared_area_bus_to_virt(sep,\r\n(*dcb_region)->output_mlli_address),\r\n(*dcb_region)->output_mlli_num_entries,\r\n(*dcb_region)->output_mlli_data_size);\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] printing activated tables\n", current->pid);\r\nend_function:\r\nkfree(*dmatables_region);\r\n*dmatables_region = NULL;\r\nkfree(*dcb_region);\r\n*dcb_region = NULL;\r\nreturn error;\r\n}\r\nstatic ssize_t sep_create_dcb_dmatables_context(struct sep_device *sep,\r\nstruct sep_dcblock **dcb_region,\r\nvoid **dmatables_region,\r\nstruct sep_dma_context **dma_ctx,\r\nconst struct build_dcb_struct __user *user_dcb_args,\r\nconst u32 num_dcbs, bool secure_dma)\r\n{\r\nint error = 0;\r\nint i = 0;\r\nstruct build_dcb_struct *dcb_args = NULL;\r\ndev_dbg(&sep->pdev->dev, "[PID%d] creating dcb/dma region\n",\r\ncurrent->pid);\r\nif (!dcb_region || !dma_ctx || !dmatables_region || !user_dcb_args) {\r\nerror = -EINVAL;\r\ngoto end_function;\r\n}\r\nif (SEP_MAX_NUM_SYNC_DMA_OPS < num_dcbs) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] invalid number of dcbs 0x%08X\n",\r\ncurrent->pid, num_dcbs);\r\nerror = -EINVAL;\r\ngoto end_function;\r\n}\r\ndcb_args = kcalloc(num_dcbs, sizeof(struct build_dcb_struct),\r\nGFP_KERNEL);\r\nif (!dcb_args) {\r\nerror = -ENOMEM;\r\ngoto end_function;\r\n}\r\nif (copy_from_user(dcb_args,\r\nuser_dcb_args,\r\nnum_dcbs * sizeof(struct build_dcb_struct))) {\r\nerror = -EFAULT;\r\ngoto end_function;\r\n}\r\n*dcb_region = kzalloc(num_dcbs * sizeof(struct sep_dcblock),\r\nGFP_KERNEL);\r\nif (!(*dcb_region)) {\r\nerror = -ENOMEM;\r\ngoto end_function;\r\n}\r\nfor (i = 0; i < num_dcbs; i++) {\r\nerror = sep_prepare_input_output_dma_table_in_dcb(sep,\r\n(unsigned long)dcb_args[i].app_in_address,\r\n(unsigned long)dcb_args[i].app_out_address,\r\ndcb_args[i].data_in_size,\r\ndcb_args[i].block_size,\r\ndcb_args[i].tail_block_size,\r\ndcb_args[i].is_applet,\r\nfalse, secure_dma,\r\n*dcb_region, dmatables_region,\r\ndma_ctx,\r\nNULL,\r\nNULL);\r\nif (error) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] dma table creation failed\n",\r\ncurrent->pid);\r\ngoto end_function;\r\n}\r\nif (dcb_args[i].app_in_address != 0)\r\n(*dma_ctx)->input_data_len += dcb_args[i].data_in_size;\r\n}\r\nend_function:\r\nkfree(dcb_args);\r\nreturn error;\r\n}\r\nint sep_create_dcb_dmatables_context_kernel(struct sep_device *sep,\r\nstruct sep_dcblock **dcb_region,\r\nvoid **dmatables_region,\r\nstruct sep_dma_context **dma_ctx,\r\nconst struct build_dcb_struct_kernel *dcb_data,\r\nconst u32 num_dcbs)\r\n{\r\nint error = 0;\r\nint i = 0;\r\ndev_dbg(&sep->pdev->dev, "[PID%d] creating dcb/dma region\n",\r\ncurrent->pid);\r\nif (!dcb_region || !dma_ctx || !dmatables_region || !dcb_data) {\r\nerror = -EINVAL;\r\ngoto end_function;\r\n}\r\nif (SEP_MAX_NUM_SYNC_DMA_OPS < num_dcbs) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] invalid number of dcbs 0x%08X\n",\r\ncurrent->pid, num_dcbs);\r\nerror = -EINVAL;\r\ngoto end_function;\r\n}\r\ndev_dbg(&sep->pdev->dev, "[PID%d] num_dcbs is %d\n",\r\ncurrent->pid, num_dcbs);\r\n*dcb_region = kzalloc(num_dcbs * sizeof(struct sep_dcblock),\r\nGFP_KERNEL);\r\nif (!(*dcb_region)) {\r\nerror = -ENOMEM;\r\ngoto end_function;\r\n}\r\nfor (i = 0; i < num_dcbs; i++) {\r\nerror = sep_prepare_input_output_dma_table_in_dcb(sep,\r\n(unsigned long)dcb_data->app_in_address,\r\n(unsigned long)dcb_data->app_out_address,\r\ndcb_data->data_in_size,\r\ndcb_data->block_size,\r\ndcb_data->tail_block_size,\r\ndcb_data->is_applet,\r\ntrue,\r\nfalse,\r\n*dcb_region, dmatables_region,\r\ndma_ctx,\r\ndcb_data->src_sg,\r\ndcb_data->dst_sg);\r\nif (error) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] dma table creation failed\n",\r\ncurrent->pid);\r\ngoto end_function;\r\n}\r\n}\r\nend_function:\r\nreturn error;\r\n}\r\nstatic ssize_t sep_activate_msgarea_context(struct sep_device *sep,\r\nvoid **msg_region,\r\nconst size_t msg_len)\r\n{\r\ndev_dbg(&sep->pdev->dev, "[PID%d] activating msg region\n",\r\ncurrent->pid);\r\nif (!msg_region || !(*msg_region) ||\r\nSEP_DRIVER_MESSAGE_SHARED_AREA_SIZE_IN_BYTES < msg_len) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] invalid act msgarea len 0x%08zX\n",\r\ncurrent->pid, msg_len);\r\nreturn -EINVAL;\r\n}\r\nmemcpy(sep->shared_addr, *msg_region, msg_len);\r\nreturn 0;\r\n}\r\nstatic ssize_t sep_create_msgarea_context(struct sep_device *sep,\r\nvoid **msg_region,\r\nconst void __user *msg_user,\r\nconst size_t msg_len)\r\n{\r\nint error = 0;\r\ndev_dbg(&sep->pdev->dev, "[PID%d] creating msg region\n",\r\ncurrent->pid);\r\nif (!msg_region ||\r\n!msg_user ||\r\nSEP_DRIVER_MAX_MESSAGE_SIZE_IN_BYTES < msg_len ||\r\nSEP_DRIVER_MIN_MESSAGE_SIZE_IN_BYTES > msg_len) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] invalid creat msgarea len 0x%08zX\n",\r\ncurrent->pid, msg_len);\r\nerror = -EINVAL;\r\ngoto end_function;\r\n}\r\n*msg_region = kzalloc(msg_len, GFP_KERNEL);\r\nif (!(*msg_region)) {\r\nerror = -ENOMEM;\r\ngoto end_function;\r\n}\r\nif (copy_from_user(*msg_region, msg_user, msg_len)) {\r\nerror = -EFAULT;\r\ngoto end_function;\r\n}\r\nend_function:\r\nif (error && msg_region) {\r\nkfree(*msg_region);\r\n*msg_region = NULL;\r\n}\r\nreturn error;\r\n}\r\nstatic ssize_t sep_read(struct file *filp,\r\nchar __user *buf_user, size_t count_user,\r\nloff_t *offset)\r\n{\r\nstruct sep_private_data * const private_data = filp->private_data;\r\nstruct sep_call_status *call_status = &private_data->call_status;\r\nstruct sep_device *sep = private_data->device;\r\nstruct sep_dma_context **dma_ctx = &private_data->dma_ctx;\r\nstruct sep_queue_info **my_queue_elem = &private_data->my_queue_elem;\r\nssize_t error = 0, error_tmp = 0;\r\nerror = sep_check_transaction_owner(sep);\r\nif (error) {\r\ndev_dbg(&sep->pdev->dev, "[PID%d] read pid is not owner\n",\r\ncurrent->pid);\r\ngoto end_function;\r\n}\r\nif (0 == test_bit(SEP_FASTCALL_WRITE_DONE_OFFSET,\r\n&call_status->status)) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] fastcall write not called\n",\r\ncurrent->pid);\r\nerror = -EPROTO;\r\ngoto end_function_error;\r\n}\r\nif (!buf_user) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] null user buffer\n",\r\ncurrent->pid);\r\nerror = -EINVAL;\r\ngoto end_function_error;\r\n}\r\nwait_event(sep->event_interrupt,\r\ntest_bit(SEP_WORKING_LOCK_BIT,\r\n&sep->in_use_flags) == 0);\r\nsep_dump_message(sep);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] count_user = 0x%08zX\n",\r\ncurrent->pid, count_user);\r\nif (count_user > SEP_DRIVER_MESSAGE_SHARED_AREA_SIZE_IN_BYTES)\r\ncount_user = SEP_DRIVER_MESSAGE_SHARED_AREA_SIZE_IN_BYTES;\r\nif (copy_to_user(buf_user, sep->shared_addr, count_user)) {\r\nerror = -EFAULT;\r\ngoto end_function_error;\r\n}\r\ndev_dbg(&sep->pdev->dev, "[PID%d] read succeeded\n", current->pid);\r\nerror = count_user;\r\nend_function_error:\r\nerror_tmp = sep_free_dcb_handler(sep, dma_ctx);\r\nif (error_tmp)\r\ndev_warn(&sep->pdev->dev, "[PID%d] dcb free failed\n",\r\ncurrent->pid);\r\nerror_tmp = sep_end_transaction_handler(sep, dma_ctx, call_status,\r\nmy_queue_elem);\r\nif (error_tmp)\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] ending transaction failed\n",\r\ncurrent->pid);\r\nend_function:\r\nreturn error;\r\n}\r\nstatic inline ssize_t sep_fastcall_args_get(struct sep_device *sep,\r\nstruct sep_fastcall_hdr *args,\r\nconst char __user *buf_user,\r\nconst size_t count_user)\r\n{\r\nssize_t error = 0;\r\nsize_t actual_count = 0;\r\nif (!buf_user) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] null user buffer\n",\r\ncurrent->pid);\r\nerror = -EINVAL;\r\ngoto end_function;\r\n}\r\nif (count_user < sizeof(struct sep_fastcall_hdr)) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] too small message size 0x%08zX\n",\r\ncurrent->pid, count_user);\r\nerror = -EINVAL;\r\ngoto end_function;\r\n}\r\nif (copy_from_user(args, buf_user, sizeof(struct sep_fastcall_hdr))) {\r\nerror = -EFAULT;\r\ngoto end_function;\r\n}\r\nif (SEP_FC_MAGIC != args->magic) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] invalid fastcall magic 0x%08X\n",\r\ncurrent->pid, args->magic);\r\nerror = -EINVAL;\r\ngoto end_function;\r\n}\r\ndev_dbg(&sep->pdev->dev, "[PID%d] fastcall hdr num of DCBs 0x%08X\n",\r\ncurrent->pid, args->num_dcbs);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] fastcall hdr msg len 0x%08X\n",\r\ncurrent->pid, args->msg_len);\r\nif (SEP_DRIVER_MAX_MESSAGE_SIZE_IN_BYTES < args->msg_len ||\r\nSEP_DRIVER_MIN_MESSAGE_SIZE_IN_BYTES > args->msg_len) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] invalid message length\n",\r\ncurrent->pid);\r\nerror = -EINVAL;\r\ngoto end_function;\r\n}\r\nactual_count = sizeof(struct sep_fastcall_hdr)\r\n+ args->msg_len\r\n+ (args->num_dcbs * sizeof(struct build_dcb_struct));\r\nif (actual_count != count_user) {\r\ndev_warn(&sep->pdev->dev,\r\n"[PID%d] inconsistent message "\r\n"sizes 0x%08zX vs 0x%08zX\n",\r\ncurrent->pid, actual_count, count_user);\r\nerror = -EMSGSIZE;\r\ngoto end_function;\r\n}\r\nend_function:\r\nreturn error;\r\n}\r\nstatic ssize_t sep_write(struct file *filp,\r\nconst char __user *buf_user, size_t count_user,\r\nloff_t *offset)\r\n{\r\nstruct sep_private_data * const private_data = filp->private_data;\r\nstruct sep_call_status *call_status = &private_data->call_status;\r\nstruct sep_device *sep = private_data->device;\r\nstruct sep_dma_context *dma_ctx = NULL;\r\nstruct sep_fastcall_hdr call_hdr = {0};\r\nvoid *msg_region = NULL;\r\nvoid *dmatables_region = NULL;\r\nstruct sep_dcblock *dcb_region = NULL;\r\nssize_t error = 0;\r\nstruct sep_queue_info *my_queue_elem = NULL;\r\nbool my_secure_dma;\r\ndev_dbg(&sep->pdev->dev, "[PID%d] sep dev is 0x%p\n",\r\ncurrent->pid, sep);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] private_data is 0x%p\n",\r\ncurrent->pid, private_data);\r\nerror = sep_fastcall_args_get(sep, &call_hdr, buf_user, count_user);\r\nif (error)\r\ngoto end_function;\r\nbuf_user += sizeof(struct sep_fastcall_hdr);\r\nif (call_hdr.secure_dma == 0)\r\nmy_secure_dma = false;\r\nelse\r\nmy_secure_dma = true;\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] waiting for double buffering region access\n",\r\ncurrent->pid);\r\nerror = down_interruptible(&sep->sep_doublebuf);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] double buffering region start\n",\r\ncurrent->pid);\r\nif (error) {\r\ngoto end_function_error;\r\n}\r\nif (0 < call_hdr.num_dcbs) {\r\nerror = sep_create_dcb_dmatables_context(sep,\r\n&dcb_region,\r\n&dmatables_region,\r\n&dma_ctx,\r\n(const struct build_dcb_struct __user *)\r\nbuf_user,\r\ncall_hdr.num_dcbs, my_secure_dma);\r\nif (error)\r\ngoto end_function_error_doublebuf;\r\nbuf_user += call_hdr.num_dcbs * sizeof(struct build_dcb_struct);\r\n}\r\nerror = sep_create_msgarea_context(sep,\r\n&msg_region,\r\nbuf_user,\r\ncall_hdr.msg_len);\r\nif (error)\r\ngoto end_function_error_doublebuf;\r\ndev_dbg(&sep->pdev->dev, "[PID%d] updating queue status\n",\r\ncurrent->pid);\r\nmy_queue_elem = sep_queue_status_add(sep,\r\n((struct sep_msgarea_hdr *)msg_region)->opcode,\r\n(dma_ctx) ? dma_ctx->input_data_len : 0,\r\ncurrent->pid,\r\ncurrent->comm, sizeof(current->comm));\r\nif (!my_queue_elem) {\r\ndev_dbg(&sep->pdev->dev,\r\n"[PID%d] updating queue status error\n", current->pid);\r\nerror = -ENOMEM;\r\ngoto end_function_error_doublebuf;\r\n}\r\nerror = sep_wait_transaction(sep);\r\nif (error) {\r\ndev_dbg(&sep->pdev->dev, "[PID%d] interrupted by signal\n",\r\ncurrent->pid);\r\nsep_queue_status_remove(sep, &my_queue_elem);\r\ngoto end_function_error_doublebuf;\r\n}\r\ndev_dbg(&sep->pdev->dev, "[PID%d] saving queue element\n",\r\ncurrent->pid);\r\nprivate_data->my_queue_elem = my_queue_elem;\r\nerror = sep_activate_msgarea_context(sep, &msg_region,\r\ncall_hdr.msg_len);\r\nif (error)\r\ngoto end_function_error_clear_transact;\r\nsep_dump_message(sep);\r\nif (0 < call_hdr.num_dcbs) {\r\nerror = sep_activate_dcb_dmatables_context(sep,\r\n&dcb_region,\r\n&dmatables_region,\r\ndma_ctx);\r\nif (error)\r\ngoto end_function_error_clear_transact;\r\n}\r\nerror = sep_send_command_handler(sep);\r\nif (error)\r\ngoto end_function_error_clear_transact;\r\nprivate_data->dma_ctx = dma_ctx;\r\nset_bit(SEP_FASTCALL_WRITE_DONE_OFFSET, &call_status->status);\r\nerror = count_user;\r\nup(&sep->sep_doublebuf);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] double buffering region end\n",\r\ncurrent->pid);\r\ngoto end_function;\r\nend_function_error_clear_transact:\r\nsep_end_transaction_handler(sep, &dma_ctx, call_status,\r\n&private_data->my_queue_elem);\r\nend_function_error_doublebuf:\r\nup(&sep->sep_doublebuf);\r\ndev_dbg(&sep->pdev->dev, "[PID%d] double buffering region end\n",\r\ncurrent->pid);\r\nend_function_error:\r\nif (dma_ctx)\r\nsep_free_dma_table_data_handler(sep, &dma_ctx);\r\nend_function:\r\nkfree(dcb_region);\r\nkfree(dmatables_region);\r\nkfree(msg_region);\r\nreturn error;\r\n}\r\nstatic loff_t sep_seek(struct file *filp, loff_t offset, int origin)\r\n{\r\nreturn -ENOSYS;\r\n}\r\nstatic ssize_t\r\nsep_sysfs_read(struct file *filp, struct kobject *kobj,\r\nstruct bin_attribute *attr,\r\nchar *buf, loff_t pos, size_t count)\r\n{\r\nunsigned long lck_flags;\r\nsize_t nleft = count;\r\nstruct sep_device *sep = sep_dev;\r\nstruct sep_queue_info *queue_elem = NULL;\r\nu32 queue_num = 0;\r\nu32 i = 1;\r\nspin_lock_irqsave(&sep->sep_queue_lock, lck_flags);\r\nqueue_num = sep->sep_queue_num;\r\nif (queue_num > SEP_DOUBLEBUF_USERS_LIMIT)\r\nqueue_num = SEP_DOUBLEBUF_USERS_LIMIT;\r\nif (count < sizeof(queue_num)\r\n+ (queue_num * sizeof(struct sep_queue_data))) {\r\nspin_unlock_irqrestore(&sep->sep_queue_lock, lck_flags);\r\nreturn -EINVAL;\r\n}\r\nmemcpy(buf, &queue_num, sizeof(queue_num));\r\nbuf += sizeof(queue_num);\r\nnleft -= sizeof(queue_num);\r\nlist_for_each_entry(queue_elem, &sep->sep_queue_status, list) {\r\nif (i++ > queue_num)\r\nbreak;\r\nmemcpy(buf, &queue_elem->data, sizeof(queue_elem->data));\r\nnleft -= sizeof(queue_elem->data);\r\nbuf += sizeof(queue_elem->data);\r\n}\r\nspin_unlock_irqrestore(&sep->sep_queue_lock, lck_flags);\r\nreturn count - nleft;\r\n}\r\nstatic int sep_register_driver_with_fs(struct sep_device *sep)\r\n{\r\nint ret_val;\r\nsep->miscdev_sep.minor = MISC_DYNAMIC_MINOR;\r\nsep->miscdev_sep.name = SEP_DEV_NAME;\r\nsep->miscdev_sep.fops = &sep_file_operations;\r\nret_val = misc_register(&sep->miscdev_sep);\r\nif (ret_val) {\r\ndev_warn(&sep->pdev->dev, "misc reg fails for SEP %x\n",\r\nret_val);\r\nreturn ret_val;\r\n}\r\nret_val = device_create_bin_file(sep->miscdev_sep.this_device,\r\n&queue_status);\r\nif (ret_val) {\r\ndev_warn(&sep->pdev->dev, "sysfs attribute1 fails for SEP %x\n",\r\nret_val);\r\nreturn ret_val;\r\n}\r\nreturn ret_val;\r\n}\r\nstatic int sep_probe(struct pci_dev *pdev,\r\nconst struct pci_device_id *ent)\r\n{\r\nint error = 0;\r\nstruct sep_device *sep = NULL;\r\nif (sep_dev != NULL) {\r\ndev_dbg(&pdev->dev, "only one SEP supported.\n");\r\nreturn -EBUSY;\r\n}\r\nerror = pci_enable_device(pdev);\r\nif (error) {\r\ndev_warn(&pdev->dev, "error enabling pci device\n");\r\ngoto end_function;\r\n}\r\nsep_dev = kzalloc(sizeof(struct sep_device), GFP_ATOMIC);\r\nif (sep_dev == NULL) {\r\nerror = -ENOMEM;\r\ngoto end_function_disable_device;\r\n}\r\nsep = sep_dev;\r\nsep->pdev = pci_dev_get(pdev);\r\ninit_waitqueue_head(&sep->event_transactions);\r\ninit_waitqueue_head(&sep->event_interrupt);\r\nspin_lock_init(&sep->snd_rply_lck);\r\nspin_lock_init(&sep->sep_queue_lock);\r\nsema_init(&sep->sep_doublebuf, SEP_DOUBLEBUF_USERS_LIMIT);\r\nINIT_LIST_HEAD(&sep->sep_queue_status);\r\ndev_dbg(&sep->pdev->dev,\r\n"sep probe: PCI obtained, device being prepared\n");\r\nsep->reg_physical_addr = pci_resource_start(sep->pdev, 0);\r\nif (!sep->reg_physical_addr) {\r\ndev_warn(&sep->pdev->dev, "Error getting register start\n");\r\nerror = -ENODEV;\r\ngoto end_function_free_sep_dev;\r\n}\r\nsep->reg_physical_end = pci_resource_end(sep->pdev, 0);\r\nif (!sep->reg_physical_end) {\r\ndev_warn(&sep->pdev->dev, "Error getting register end\n");\r\nerror = -ENODEV;\r\ngoto end_function_free_sep_dev;\r\n}\r\nsep->reg_addr = ioremap_nocache(sep->reg_physical_addr,\r\n(size_t)(sep->reg_physical_end - sep->reg_physical_addr + 1));\r\nif (!sep->reg_addr) {\r\ndev_warn(&sep->pdev->dev, "Error getting register virtual\n");\r\nerror = -ENODEV;\r\ngoto end_function_free_sep_dev;\r\n}\r\ndev_dbg(&sep->pdev->dev,\r\n"Register area start %llx end %llx virtual %p\n",\r\n(unsigned long long)sep->reg_physical_addr,\r\n(unsigned long long)sep->reg_physical_end,\r\nsep->reg_addr);\r\nsep->shared_size = SEP_DRIVER_MESSAGE_SHARED_AREA_SIZE_IN_BYTES +\r\nSYNCHRONIC_DMA_TABLES_AREA_SIZE_BYTES +\r\nSEP_DRIVER_DATA_POOL_SHARED_AREA_SIZE_IN_BYTES +\r\nSEP_DRIVER_STATIC_AREA_SIZE_IN_BYTES +\r\nSEP_DRIVER_SYSTEM_DATA_MEMORY_SIZE_IN_BYTES;\r\nif (sep_map_and_alloc_shared_area(sep)) {\r\nerror = -ENOMEM;\r\ngoto end_function_error;\r\n}\r\nsep_write_reg(sep, HW_HOST_ICR_REG_ADDR, 0xFFFFFFFF);\r\nsep_write_reg(sep, HW_HOST_IMR_REG_ADDR, (~(0x1 << 13)));\r\nsep->reply_ct = sep_read_reg(sep, HW_HOST_SEP_HOST_GPR2_REG_ADDR);\r\nsep->reply_ct &= 0x3FFFFFFF;\r\nsep->send_ct = sep->reply_ct;\r\nerror = request_irq(pdev->irq, sep_inthandler, IRQF_SHARED,\r\n"sep_driver", sep);\r\nif (error)\r\ngoto end_function_deallocate_sep_shared_area;\r\nerror = sep_reconfig_shared_area(sep);\r\nif (error)\r\ngoto end_function_free_irq;\r\nsep->in_use = 1;\r\nerror = sep_register_driver_with_fs(sep);\r\nif (error) {\r\ndev_err(&sep->pdev->dev, "error registering dev file\n");\r\ngoto end_function_free_irq;\r\n}\r\nsep->in_use = 0;\r\n#ifdef SEP_ENABLE_RUNTIME_PM\r\npm_runtime_put_noidle(&sep->pdev->dev);\r\npm_runtime_allow(&sep->pdev->dev);\r\npm_runtime_set_autosuspend_delay(&sep->pdev->dev,\r\nSUSPEND_DELAY);\r\npm_runtime_use_autosuspend(&sep->pdev->dev);\r\npm_runtime_mark_last_busy(&sep->pdev->dev);\r\nsep->power_save_setup = 1;\r\n#endif\r\n#if defined(CONFIG_CRYPTO) || defined(CONFIG_CRYPTO_MODULE)\r\nerror = sep_crypto_setup();\r\nif (error) {\r\ndev_err(&sep->pdev->dev, "crypto setup failed\n");\r\ngoto end_function_free_irq;\r\n}\r\n#endif\r\ngoto end_function;\r\nend_function_free_irq:\r\nfree_irq(pdev->irq, sep);\r\nend_function_deallocate_sep_shared_area:\r\nsep_unmap_and_free_shared_area(sep);\r\nend_function_error:\r\niounmap(sep->reg_addr);\r\nend_function_free_sep_dev:\r\npci_dev_put(sep_dev->pdev);\r\nkfree(sep_dev);\r\nsep_dev = NULL;\r\nend_function_disable_device:\r\npci_disable_device(pdev);\r\nend_function:\r\nreturn error;\r\n}\r\nstatic void sep_remove(struct pci_dev *pdev)\r\n{\r\nstruct sep_device *sep = sep_dev;\r\nmisc_deregister(&sep->miscdev_sep);\r\n#if defined(CONFIG_CRYPTO) || defined(CONFIG_CRYPTO_MODULE)\r\nsep_crypto_takedown();\r\n#endif\r\nfree_irq(sep->pdev->irq, sep);\r\nsep_unmap_and_free_shared_area(sep_dev);\r\niounmap(sep_dev->reg_addr);\r\n#ifdef SEP_ENABLE_RUNTIME_PM\r\nif (sep->in_use) {\r\nsep->in_use = 0;\r\npm_runtime_forbid(&sep->pdev->dev);\r\npm_runtime_get_noresume(&sep->pdev->dev);\r\n}\r\n#endif\r\npci_dev_put(sep_dev->pdev);\r\nkfree(sep_dev);\r\nsep_dev = NULL;\r\n}\r\nstatic int sep_pci_resume(struct device *dev)\r\n{\r\nstruct sep_device *sep = sep_dev;\r\ndev_dbg(&sep->pdev->dev, "pci resume called\n");\r\nif (sep->power_state == SEP_DRIVER_POWERON)\r\nreturn 0;\r\nsep_write_reg(sep, HW_HOST_ICR_REG_ADDR, 0xFFFFFFFF);\r\nsep_write_reg(sep, HW_HOST_IMR_REG_ADDR, (~(0x1 << 13)));\r\nsep->reply_ct = sep_read_reg(sep, HW_HOST_SEP_HOST_GPR2_REG_ADDR);\r\nsep->reply_ct &= 0x3FFFFFFF;\r\nsep->send_ct = sep->reply_ct;\r\nsep->power_state = SEP_DRIVER_POWERON;\r\nreturn 0;\r\n}\r\nstatic int sep_pci_suspend(struct device *dev)\r\n{\r\nstruct sep_device *sep = sep_dev;\r\ndev_dbg(&sep->pdev->dev, "pci suspend called\n");\r\nif (sep->in_use == 1)\r\nreturn -EAGAIN;\r\nsep->power_state = SEP_DRIVER_POWEROFF;\r\nsep_write_reg(sep, HW_HOST_ICR_REG_ADDR, 0xFFFFFFFF);\r\nsep_write_reg(sep, HW_HOST_IMR_REG_ADDR, 0xFFFFFFFF);\r\nreturn 0;\r\n}\r\nstatic int sep_pm_runtime_resume(struct device *dev)\r\n{\r\nu32 retval2;\r\nu32 delay_count;\r\nstruct sep_device *sep = sep_dev;\r\ndev_dbg(&sep->pdev->dev, "pm runtime resume called\n");\r\nretval2 = 0;\r\ndelay_count = 0;\r\nwhile ((!retval2) && (delay_count < SCU_DELAY_MAX)) {\r\nretval2 = sep_read_reg(sep, HW_HOST_SEP_HOST_GPR3_REG_ADDR);\r\nretval2 &= 0x00000008;\r\nif (!retval2) {\r\nudelay(SCU_DELAY_ITERATION);\r\ndelay_count += 1;\r\n}\r\n}\r\nif (!retval2) {\r\ndev_warn(&sep->pdev->dev, "scu boot bit not set at resume\n");\r\nreturn -EINVAL;\r\n}\r\nsep_write_reg(sep, HW_HOST_ICR_REG_ADDR, 0xFFFFFFFF);\r\nsep_write_reg(sep, HW_HOST_IMR_REG_ADDR, (~(0x1 << 13)));\r\nsep->reply_ct = sep_read_reg(sep, HW_HOST_SEP_HOST_GPR2_REG_ADDR);\r\nsep->reply_ct &= 0x3FFFFFFF;\r\nsep->send_ct = sep->reply_ct;\r\nreturn 0;\r\n}\r\nstatic int sep_pm_runtime_suspend(struct device *dev)\r\n{\r\nstruct sep_device *sep = sep_dev;\r\ndev_dbg(&sep->pdev->dev, "pm runtime suspend called\n");\r\nsep_write_reg(sep, HW_HOST_ICR_REG_ADDR, 0xFFFFFFFF);\r\nreturn 0;\r\n}
