static inline unsigned dio_pages_present(struct dio_submit *sdio)\r\n{\r\nreturn sdio->tail - sdio->head;\r\n}\r\nstatic inline int dio_refill_pages(struct dio *dio, struct dio_submit *sdio)\r\n{\r\nint ret;\r\nint nr_pages;\r\nnr_pages = min(sdio->total_pages - sdio->curr_page, DIO_PAGES);\r\nret = get_user_pages_fast(\r\nsdio->curr_user_address,\r\nnr_pages,\r\ndio->rw == READ,\r\n&dio->pages[0]);\r\nif (ret < 0 && sdio->blocks_available && (dio->rw & WRITE)) {\r\nstruct page *page = ZERO_PAGE(0);\r\nif (dio->page_errors == 0)\r\ndio->page_errors = ret;\r\npage_cache_get(page);\r\ndio->pages[0] = page;\r\nsdio->head = 0;\r\nsdio->tail = 1;\r\nret = 0;\r\ngoto out;\r\n}\r\nif (ret >= 0) {\r\nsdio->curr_user_address += ret * PAGE_SIZE;\r\nsdio->curr_page += ret;\r\nsdio->head = 0;\r\nsdio->tail = ret;\r\nret = 0;\r\n}\r\nout:\r\nreturn ret;\r\n}\r\nstatic inline struct page *dio_get_page(struct dio *dio,\r\nstruct dio_submit *sdio)\r\n{\r\nif (dio_pages_present(sdio) == 0) {\r\nint ret;\r\nret = dio_refill_pages(dio, sdio);\r\nif (ret)\r\nreturn ERR_PTR(ret);\r\nBUG_ON(dio_pages_present(sdio) == 0);\r\n}\r\nreturn dio->pages[sdio->head++];\r\n}\r\nstatic ssize_t dio_complete(struct dio *dio, loff_t offset, ssize_t ret, bool is_async)\r\n{\r\nssize_t transferred = 0;\r\nif (ret == -EIOCBQUEUED)\r\nret = 0;\r\nif (dio->result) {\r\ntransferred = dio->result;\r\nif ((dio->rw == READ) && ((offset + transferred) > dio->i_size))\r\ntransferred = dio->i_size - offset;\r\n}\r\nif (ret == 0)\r\nret = dio->page_errors;\r\nif (ret == 0)\r\nret = dio->io_error;\r\nif (ret == 0)\r\nret = transferred;\r\nif (dio->end_io && dio->result) {\r\ndio->end_io(dio->iocb, offset, transferred,\r\ndio->private, ret, is_async);\r\n} else {\r\ninode_dio_done(dio->inode);\r\nif (is_async)\r\naio_complete(dio->iocb, ret, 0);\r\n}\r\nreturn ret;\r\n}\r\nstatic void dio_bio_end_aio(struct bio *bio, int error)\r\n{\r\nstruct dio *dio = bio->bi_private;\r\nunsigned long remaining;\r\nunsigned long flags;\r\ndio_bio_complete(dio, bio);\r\nspin_lock_irqsave(&dio->bio_lock, flags);\r\nremaining = --dio->refcount;\r\nif (remaining == 1 && dio->waiter)\r\nwake_up_process(dio->waiter);\r\nspin_unlock_irqrestore(&dio->bio_lock, flags);\r\nif (remaining == 0) {\r\ndio_complete(dio, dio->iocb->ki_pos, 0, true);\r\nkmem_cache_free(dio_cache, dio);\r\n}\r\n}\r\nstatic void dio_bio_end_io(struct bio *bio, int error)\r\n{\r\nstruct dio *dio = bio->bi_private;\r\nunsigned long flags;\r\nspin_lock_irqsave(&dio->bio_lock, flags);\r\nbio->bi_private = dio->bio_list;\r\ndio->bio_list = bio;\r\nif (--dio->refcount == 1 && dio->waiter)\r\nwake_up_process(dio->waiter);\r\nspin_unlock_irqrestore(&dio->bio_lock, flags);\r\n}\r\nvoid dio_end_io(struct bio *bio, int error)\r\n{\r\nstruct dio *dio = bio->bi_private;\r\nif (dio->is_async)\r\ndio_bio_end_aio(bio, error);\r\nelse\r\ndio_bio_end_io(bio, error);\r\n}\r\nstatic inline void\r\ndio_bio_alloc(struct dio *dio, struct dio_submit *sdio,\r\nstruct block_device *bdev,\r\nsector_t first_sector, int nr_vecs)\r\n{\r\nstruct bio *bio;\r\nbio = bio_alloc(GFP_KERNEL, nr_vecs);\r\nbio->bi_bdev = bdev;\r\nbio->bi_sector = first_sector;\r\nif (dio->is_async)\r\nbio->bi_end_io = dio_bio_end_aio;\r\nelse\r\nbio->bi_end_io = dio_bio_end_io;\r\nsdio->bio = bio;\r\nsdio->logical_offset_in_bio = sdio->cur_page_fs_offset;\r\n}\r\nstatic inline void dio_bio_submit(struct dio *dio, struct dio_submit *sdio)\r\n{\r\nstruct bio *bio = sdio->bio;\r\nunsigned long flags;\r\nbio->bi_private = dio;\r\nspin_lock_irqsave(&dio->bio_lock, flags);\r\ndio->refcount++;\r\nspin_unlock_irqrestore(&dio->bio_lock, flags);\r\nif (dio->is_async && dio->rw == READ)\r\nbio_set_pages_dirty(bio);\r\nif (sdio->submit_io)\r\nsdio->submit_io(dio->rw, bio, dio->inode,\r\nsdio->logical_offset_in_bio);\r\nelse\r\nsubmit_bio(dio->rw, bio);\r\nsdio->bio = NULL;\r\nsdio->boundary = 0;\r\nsdio->logical_offset_in_bio = 0;\r\n}\r\nstatic inline void dio_cleanup(struct dio *dio, struct dio_submit *sdio)\r\n{\r\nwhile (dio_pages_present(sdio))\r\npage_cache_release(dio_get_page(dio, sdio));\r\n}\r\nstatic struct bio *dio_await_one(struct dio *dio)\r\n{\r\nunsigned long flags;\r\nstruct bio *bio = NULL;\r\nspin_lock_irqsave(&dio->bio_lock, flags);\r\nwhile (dio->refcount > 1 && dio->bio_list == NULL) {\r\n__set_current_state(TASK_UNINTERRUPTIBLE);\r\ndio->waiter = current;\r\nspin_unlock_irqrestore(&dio->bio_lock, flags);\r\nio_schedule();\r\nspin_lock_irqsave(&dio->bio_lock, flags);\r\ndio->waiter = NULL;\r\n}\r\nif (dio->bio_list) {\r\nbio = dio->bio_list;\r\ndio->bio_list = bio->bi_private;\r\n}\r\nspin_unlock_irqrestore(&dio->bio_lock, flags);\r\nreturn bio;\r\n}\r\nstatic int dio_bio_complete(struct dio *dio, struct bio *bio)\r\n{\r\nconst int uptodate = test_bit(BIO_UPTODATE, &bio->bi_flags);\r\nstruct bio_vec *bvec;\r\nunsigned i;\r\nif (!uptodate)\r\ndio->io_error = -EIO;\r\nif (dio->is_async && dio->rw == READ) {\r\nbio_check_pages_dirty(bio);\r\n} else {\r\nbio_for_each_segment_all(bvec, bio, i) {\r\nstruct page *page = bvec->bv_page;\r\nif (dio->rw == READ && !PageCompound(page))\r\nset_page_dirty_lock(page);\r\npage_cache_release(page);\r\n}\r\nbio_put(bio);\r\n}\r\nreturn uptodate ? 0 : -EIO;\r\n}\r\nstatic void dio_await_completion(struct dio *dio)\r\n{\r\nstruct bio *bio;\r\ndo {\r\nbio = dio_await_one(dio);\r\nif (bio)\r\ndio_bio_complete(dio, bio);\r\n} while (bio);\r\n}\r\nstatic inline int dio_bio_reap(struct dio *dio, struct dio_submit *sdio)\r\n{\r\nint ret = 0;\r\nif (sdio->reap_counter++ >= 64) {\r\nwhile (dio->bio_list) {\r\nunsigned long flags;\r\nstruct bio *bio;\r\nint ret2;\r\nspin_lock_irqsave(&dio->bio_lock, flags);\r\nbio = dio->bio_list;\r\ndio->bio_list = bio->bi_private;\r\nspin_unlock_irqrestore(&dio->bio_lock, flags);\r\nret2 = dio_bio_complete(dio, bio);\r\nif (ret == 0)\r\nret = ret2;\r\n}\r\nsdio->reap_counter = 0;\r\n}\r\nreturn ret;\r\n}\r\nstatic int get_more_blocks(struct dio *dio, struct dio_submit *sdio,\r\nstruct buffer_head *map_bh)\r\n{\r\nint ret;\r\nsector_t fs_startblk;\r\nsector_t fs_endblk;\r\nunsigned long fs_count;\r\nint create;\r\nunsigned int i_blkbits = sdio->blkbits + sdio->blkfactor;\r\nret = dio->page_errors;\r\nif (ret == 0) {\r\nBUG_ON(sdio->block_in_file >= sdio->final_block_in_request);\r\nfs_startblk = sdio->block_in_file >> sdio->blkfactor;\r\nfs_endblk = (sdio->final_block_in_request - 1) >>\r\nsdio->blkfactor;\r\nfs_count = fs_endblk - fs_startblk + 1;\r\nmap_bh->b_state = 0;\r\nmap_bh->b_size = fs_count << i_blkbits;\r\ncreate = dio->rw & WRITE;\r\nif (dio->flags & DIO_SKIP_HOLES) {\r\nif (sdio->block_in_file < (i_size_read(dio->inode) >>\r\nsdio->blkbits))\r\ncreate = 0;\r\n}\r\nret = (*sdio->get_block)(dio->inode, fs_startblk,\r\nmap_bh, create);\r\ndio->private = map_bh->b_private;\r\n}\r\nreturn ret;\r\n}\r\nstatic inline int dio_new_bio(struct dio *dio, struct dio_submit *sdio,\r\nsector_t start_sector, struct buffer_head *map_bh)\r\n{\r\nsector_t sector;\r\nint ret, nr_pages;\r\nret = dio_bio_reap(dio, sdio);\r\nif (ret)\r\ngoto out;\r\nsector = start_sector << (sdio->blkbits - 9);\r\nnr_pages = min(sdio->pages_in_io, bio_get_nr_vecs(map_bh->b_bdev));\r\nnr_pages = min(nr_pages, BIO_MAX_PAGES);\r\nBUG_ON(nr_pages <= 0);\r\ndio_bio_alloc(dio, sdio, map_bh->b_bdev, sector, nr_pages);\r\nsdio->boundary = 0;\r\nout:\r\nreturn ret;\r\n}\r\nstatic inline int dio_bio_add_page(struct dio_submit *sdio)\r\n{\r\nint ret;\r\nret = bio_add_page(sdio->bio, sdio->cur_page,\r\nsdio->cur_page_len, sdio->cur_page_offset);\r\nif (ret == sdio->cur_page_len) {\r\nif ((sdio->cur_page_len + sdio->cur_page_offset) == PAGE_SIZE)\r\nsdio->pages_in_io--;\r\npage_cache_get(sdio->cur_page);\r\nsdio->final_block_in_bio = sdio->cur_page_block +\r\n(sdio->cur_page_len >> sdio->blkbits);\r\nret = 0;\r\n} else {\r\nret = 1;\r\n}\r\nreturn ret;\r\n}\r\nstatic inline int dio_send_cur_page(struct dio *dio, struct dio_submit *sdio,\r\nstruct buffer_head *map_bh)\r\n{\r\nint ret = 0;\r\nif (sdio->bio) {\r\nloff_t cur_offset = sdio->cur_page_fs_offset;\r\nloff_t bio_next_offset = sdio->logical_offset_in_bio +\r\nsdio->bio->bi_size;\r\nif (sdio->final_block_in_bio != sdio->cur_page_block ||\r\ncur_offset != bio_next_offset)\r\ndio_bio_submit(dio, sdio);\r\n}\r\nif (sdio->bio == NULL) {\r\nret = dio_new_bio(dio, sdio, sdio->cur_page_block, map_bh);\r\nif (ret)\r\ngoto out;\r\n}\r\nif (dio_bio_add_page(sdio) != 0) {\r\ndio_bio_submit(dio, sdio);\r\nret = dio_new_bio(dio, sdio, sdio->cur_page_block, map_bh);\r\nif (ret == 0) {\r\nret = dio_bio_add_page(sdio);\r\nBUG_ON(ret != 0);\r\n}\r\n}\r\nout:\r\nreturn ret;\r\n}\r\nstatic inline int\r\nsubmit_page_section(struct dio *dio, struct dio_submit *sdio, struct page *page,\r\nunsigned offset, unsigned len, sector_t blocknr,\r\nstruct buffer_head *map_bh)\r\n{\r\nint ret = 0;\r\nif (dio->rw & WRITE) {\r\ntask_io_account_write(len);\r\n}\r\nif (sdio->cur_page == page &&\r\nsdio->cur_page_offset + sdio->cur_page_len == offset &&\r\nsdio->cur_page_block +\r\n(sdio->cur_page_len >> sdio->blkbits) == blocknr) {\r\nsdio->cur_page_len += len;\r\ngoto out;\r\n}\r\nif (sdio->cur_page) {\r\nret = dio_send_cur_page(dio, sdio, map_bh);\r\npage_cache_release(sdio->cur_page);\r\nsdio->cur_page = NULL;\r\nif (ret)\r\nreturn ret;\r\n}\r\npage_cache_get(page);\r\nsdio->cur_page = page;\r\nsdio->cur_page_offset = offset;\r\nsdio->cur_page_len = len;\r\nsdio->cur_page_block = blocknr;\r\nsdio->cur_page_fs_offset = sdio->block_in_file << sdio->blkbits;\r\nout:\r\nif (sdio->boundary) {\r\nret = dio_send_cur_page(dio, sdio, map_bh);\r\ndio_bio_submit(dio, sdio);\r\npage_cache_release(sdio->cur_page);\r\nsdio->cur_page = NULL;\r\n}\r\nreturn ret;\r\n}\r\nstatic void clean_blockdev_aliases(struct dio *dio, struct buffer_head *map_bh)\r\n{\r\nunsigned i;\r\nunsigned nblocks;\r\nnblocks = map_bh->b_size >> dio->inode->i_blkbits;\r\nfor (i = 0; i < nblocks; i++) {\r\nunmap_underlying_metadata(map_bh->b_bdev,\r\nmap_bh->b_blocknr + i);\r\n}\r\n}\r\nstatic inline void dio_zero_block(struct dio *dio, struct dio_submit *sdio,\r\nint end, struct buffer_head *map_bh)\r\n{\r\nunsigned dio_blocks_per_fs_block;\r\nunsigned this_chunk_blocks;\r\nunsigned this_chunk_bytes;\r\nstruct page *page;\r\nsdio->start_zero_done = 1;\r\nif (!sdio->blkfactor || !buffer_new(map_bh))\r\nreturn;\r\ndio_blocks_per_fs_block = 1 << sdio->blkfactor;\r\nthis_chunk_blocks = sdio->block_in_file & (dio_blocks_per_fs_block - 1);\r\nif (!this_chunk_blocks)\r\nreturn;\r\nif (end)\r\nthis_chunk_blocks = dio_blocks_per_fs_block - this_chunk_blocks;\r\nthis_chunk_bytes = this_chunk_blocks << sdio->blkbits;\r\npage = ZERO_PAGE(0);\r\nif (submit_page_section(dio, sdio, page, 0, this_chunk_bytes,\r\nsdio->next_block_for_io, map_bh))\r\nreturn;\r\nsdio->next_block_for_io += this_chunk_blocks;\r\n}\r\nstatic int do_direct_IO(struct dio *dio, struct dio_submit *sdio,\r\nstruct buffer_head *map_bh)\r\n{\r\nconst unsigned blkbits = sdio->blkbits;\r\nconst unsigned blocks_per_page = PAGE_SIZE >> blkbits;\r\nstruct page *page;\r\nunsigned block_in_page;\r\nint ret = 0;\r\nblock_in_page = sdio->first_block_in_page;\r\nwhile (sdio->block_in_file < sdio->final_block_in_request) {\r\npage = dio_get_page(dio, sdio);\r\nif (IS_ERR(page)) {\r\nret = PTR_ERR(page);\r\ngoto out;\r\n}\r\nwhile (block_in_page < blocks_per_page) {\r\nunsigned offset_in_page = block_in_page << blkbits;\r\nunsigned this_chunk_bytes;\r\nunsigned this_chunk_blocks;\r\nunsigned u;\r\nif (sdio->blocks_available == 0) {\r\nunsigned long blkmask;\r\nunsigned long dio_remainder;\r\nret = get_more_blocks(dio, sdio, map_bh);\r\nif (ret) {\r\npage_cache_release(page);\r\ngoto out;\r\n}\r\nif (!buffer_mapped(map_bh))\r\ngoto do_holes;\r\nsdio->blocks_available =\r\nmap_bh->b_size >> sdio->blkbits;\r\nsdio->next_block_for_io =\r\nmap_bh->b_blocknr << sdio->blkfactor;\r\nif (buffer_new(map_bh))\r\nclean_blockdev_aliases(dio, map_bh);\r\nif (!sdio->blkfactor)\r\ngoto do_holes;\r\nblkmask = (1 << sdio->blkfactor) - 1;\r\ndio_remainder = (sdio->block_in_file & blkmask);\r\nif (!buffer_new(map_bh))\r\nsdio->next_block_for_io += dio_remainder;\r\nsdio->blocks_available -= dio_remainder;\r\n}\r\ndo_holes:\r\nif (!buffer_mapped(map_bh)) {\r\nloff_t i_size_aligned;\r\nif (dio->rw & WRITE) {\r\npage_cache_release(page);\r\nreturn -ENOTBLK;\r\n}\r\ni_size_aligned = ALIGN(i_size_read(dio->inode),\r\n1 << blkbits);\r\nif (sdio->block_in_file >=\r\ni_size_aligned >> blkbits) {\r\npage_cache_release(page);\r\ngoto out;\r\n}\r\nzero_user(page, block_in_page << blkbits,\r\n1 << blkbits);\r\nsdio->block_in_file++;\r\nblock_in_page++;\r\ngoto next_block;\r\n}\r\nif (unlikely(sdio->blkfactor && !sdio->start_zero_done))\r\ndio_zero_block(dio, sdio, 0, map_bh);\r\nthis_chunk_blocks = sdio->blocks_available;\r\nu = (PAGE_SIZE - offset_in_page) >> blkbits;\r\nif (this_chunk_blocks > u)\r\nthis_chunk_blocks = u;\r\nu = sdio->final_block_in_request - sdio->block_in_file;\r\nif (this_chunk_blocks > u)\r\nthis_chunk_blocks = u;\r\nthis_chunk_bytes = this_chunk_blocks << blkbits;\r\nBUG_ON(this_chunk_bytes == 0);\r\nif (this_chunk_blocks == sdio->blocks_available)\r\nsdio->boundary = buffer_boundary(map_bh);\r\nret = submit_page_section(dio, sdio, page,\r\noffset_in_page,\r\nthis_chunk_bytes,\r\nsdio->next_block_for_io,\r\nmap_bh);\r\nif (ret) {\r\npage_cache_release(page);\r\ngoto out;\r\n}\r\nsdio->next_block_for_io += this_chunk_blocks;\r\nsdio->block_in_file += this_chunk_blocks;\r\nblock_in_page += this_chunk_blocks;\r\nsdio->blocks_available -= this_chunk_blocks;\r\nnext_block:\r\nBUG_ON(sdio->block_in_file > sdio->final_block_in_request);\r\nif (sdio->block_in_file == sdio->final_block_in_request)\r\nbreak;\r\n}\r\npage_cache_release(page);\r\nblock_in_page = 0;\r\n}\r\nout:\r\nreturn ret;\r\n}\r\nstatic inline int drop_refcount(struct dio *dio)\r\n{\r\nint ret2;\r\nunsigned long flags;\r\nspin_lock_irqsave(&dio->bio_lock, flags);\r\nret2 = --dio->refcount;\r\nspin_unlock_irqrestore(&dio->bio_lock, flags);\r\nreturn ret2;\r\n}\r\nstatic inline ssize_t\r\ndo_blockdev_direct_IO(int rw, struct kiocb *iocb, struct inode *inode,\r\nstruct block_device *bdev, const struct iovec *iov, loff_t offset,\r\nunsigned long nr_segs, get_block_t get_block, dio_iodone_t end_io,\r\ndio_submit_t submit_io, int flags)\r\n{\r\nint seg;\r\nsize_t size;\r\nunsigned long addr;\r\nunsigned i_blkbits = ACCESS_ONCE(inode->i_blkbits);\r\nunsigned blkbits = i_blkbits;\r\nunsigned blocksize_mask = (1 << blkbits) - 1;\r\nssize_t retval = -EINVAL;\r\nloff_t end = offset;\r\nstruct dio *dio;\r\nstruct dio_submit sdio = { 0, };\r\nunsigned long user_addr;\r\nsize_t bytes;\r\nstruct buffer_head map_bh = { 0, };\r\nstruct blk_plug plug;\r\nif (rw & WRITE)\r\nrw = WRITE_ODIRECT;\r\nif (offset & blocksize_mask) {\r\nif (bdev)\r\nblkbits = blksize_bits(bdev_logical_block_size(bdev));\r\nblocksize_mask = (1 << blkbits) - 1;\r\nif (offset & blocksize_mask)\r\ngoto out;\r\n}\r\nfor (seg = 0; seg < nr_segs; seg++) {\r\naddr = (unsigned long)iov[seg].iov_base;\r\nsize = iov[seg].iov_len;\r\nend += size;\r\nif (unlikely((addr & blocksize_mask) ||\r\n(size & blocksize_mask))) {\r\nif (bdev)\r\nblkbits = blksize_bits(\r\nbdev_logical_block_size(bdev));\r\nblocksize_mask = (1 << blkbits) - 1;\r\nif ((addr & blocksize_mask) || (size & blocksize_mask))\r\ngoto out;\r\n}\r\n}\r\nif (rw == READ && end == offset)\r\nreturn 0;\r\ndio = kmem_cache_alloc(dio_cache, GFP_KERNEL);\r\nretval = -ENOMEM;\r\nif (!dio)\r\ngoto out;\r\nmemset(dio, 0, offsetof(struct dio, pages));\r\ndio->flags = flags;\r\nif (dio->flags & DIO_LOCKING) {\r\nif (rw == READ) {\r\nstruct address_space *mapping =\r\niocb->ki_filp->f_mapping;\r\nmutex_lock(&inode->i_mutex);\r\nretval = filemap_write_and_wait_range(mapping, offset,\r\nend - 1);\r\nif (retval) {\r\nmutex_unlock(&inode->i_mutex);\r\nkmem_cache_free(dio_cache, dio);\r\ngoto out;\r\n}\r\n}\r\n}\r\natomic_inc(&inode->i_dio_count);\r\ndio->is_async = !is_sync_kiocb(iocb) && !((rw & WRITE) &&\r\n(end > i_size_read(inode)));\r\nretval = 0;\r\ndio->inode = inode;\r\ndio->rw = rw;\r\nsdio.blkbits = blkbits;\r\nsdio.blkfactor = i_blkbits - blkbits;\r\nsdio.block_in_file = offset >> blkbits;\r\nsdio.get_block = get_block;\r\ndio->end_io = end_io;\r\nsdio.submit_io = submit_io;\r\nsdio.final_block_in_bio = -1;\r\nsdio.next_block_for_io = -1;\r\ndio->iocb = iocb;\r\ndio->i_size = i_size_read(inode);\r\nspin_lock_init(&dio->bio_lock);\r\ndio->refcount = 1;\r\nif (unlikely(sdio.blkfactor))\r\nsdio.pages_in_io = 2;\r\nfor (seg = 0; seg < nr_segs; seg++) {\r\nuser_addr = (unsigned long)iov[seg].iov_base;\r\nsdio.pages_in_io +=\r\n((user_addr + iov[seg].iov_len + PAGE_SIZE-1) /\r\nPAGE_SIZE - user_addr / PAGE_SIZE);\r\n}\r\nblk_start_plug(&plug);\r\nfor (seg = 0; seg < nr_segs; seg++) {\r\nuser_addr = (unsigned long)iov[seg].iov_base;\r\nsdio.size += bytes = iov[seg].iov_len;\r\nsdio.first_block_in_page = (user_addr & ~PAGE_MASK) >> blkbits;\r\nsdio.final_block_in_request = sdio.block_in_file +\r\n(bytes >> blkbits);\r\nsdio.head = 0;\r\nsdio.tail = 0;\r\nsdio.curr_page = 0;\r\nsdio.total_pages = 0;\r\nif (user_addr & (PAGE_SIZE-1)) {\r\nsdio.total_pages++;\r\nbytes -= PAGE_SIZE - (user_addr & (PAGE_SIZE - 1));\r\n}\r\nsdio.total_pages += (bytes + PAGE_SIZE - 1) / PAGE_SIZE;\r\nsdio.curr_user_address = user_addr;\r\nretval = do_direct_IO(dio, &sdio, &map_bh);\r\ndio->result += iov[seg].iov_len -\r\n((sdio.final_block_in_request - sdio.block_in_file) <<\r\nblkbits);\r\nif (retval) {\r\ndio_cleanup(dio, &sdio);\r\nbreak;\r\n}\r\n}\r\nif (retval == -ENOTBLK) {\r\nretval = 0;\r\n}\r\ndio_zero_block(dio, &sdio, 1, &map_bh);\r\nif (sdio.cur_page) {\r\nssize_t ret2;\r\nret2 = dio_send_cur_page(dio, &sdio, &map_bh);\r\nif (retval == 0)\r\nretval = ret2;\r\npage_cache_release(sdio.cur_page);\r\nsdio.cur_page = NULL;\r\n}\r\nif (sdio.bio)\r\ndio_bio_submit(dio, &sdio);\r\nblk_finish_plug(&plug);\r\ndio_cleanup(dio, &sdio);\r\nif (rw == READ && (dio->flags & DIO_LOCKING))\r\nmutex_unlock(&dio->inode->i_mutex);\r\nBUG_ON(retval == -EIOCBQUEUED);\r\nif (dio->is_async && retval == 0 && dio->result &&\r\n((rw == READ) || (dio->result == sdio.size)))\r\nretval = -EIOCBQUEUED;\r\nif (retval != -EIOCBQUEUED)\r\ndio_await_completion(dio);\r\nif (drop_refcount(dio) == 0) {\r\nretval = dio_complete(dio, offset, retval, false);\r\nkmem_cache_free(dio_cache, dio);\r\n} else\r\nBUG_ON(retval != -EIOCBQUEUED);\r\nout:\r\nreturn retval;\r\n}\r\nssize_t\r\n__blockdev_direct_IO(int rw, struct kiocb *iocb, struct inode *inode,\r\nstruct block_device *bdev, const struct iovec *iov, loff_t offset,\r\nunsigned long nr_segs, get_block_t get_block, dio_iodone_t end_io,\r\ndio_submit_t submit_io, int flags)\r\n{\r\nprefetch(&bdev->bd_disk->part_tbl);\r\nprefetch(bdev->bd_queue);\r\nprefetch((char *)bdev->bd_queue + SMP_CACHE_BYTES);\r\nreturn do_blockdev_direct_IO(rw, iocb, inode, bdev, iov, offset,\r\nnr_segs, get_block, end_io,\r\nsubmit_io, flags);\r\n}\r\nstatic __init int dio_init(void)\r\n{\r\ndio_cache = KMEM_CACHE(dio, SLAB_PANIC);\r\nreturn 0;\r\n}
