void rxrpc_UDP_error_report(struct sock *sk)\r\n{\r\nstruct sock_exterr_skb *serr;\r\nstruct rxrpc_transport *trans;\r\nstruct rxrpc_local *local = sk->sk_user_data;\r\nstruct rxrpc_peer *peer;\r\nstruct sk_buff *skb;\r\n__be32 addr;\r\n__be16 port;\r\n_enter("%p{%d}", sk, local->debug_id);\r\nskb = skb_dequeue(&sk->sk_error_queue);\r\nif (!skb) {\r\n_leave("UDP socket errqueue empty");\r\nreturn;\r\n}\r\nrxrpc_new_skb(skb);\r\nserr = SKB_EXT_ERR(skb);\r\naddr = *(__be32 *)(skb_network_header(skb) + serr->addr_offset);\r\nport = serr->port;\r\n_net("Rx UDP Error from %pI4:%hu", &addr, ntohs(port));\r\n_debug("Msg l:%d d:%d", skb->len, skb->data_len);\r\npeer = rxrpc_find_peer(local, addr, port);\r\nif (IS_ERR(peer)) {\r\nrxrpc_free_skb(skb);\r\n_leave(" [no peer]");\r\nreturn;\r\n}\r\ntrans = rxrpc_find_transport(local, peer);\r\nif (!trans) {\r\nrxrpc_put_peer(peer);\r\nrxrpc_free_skb(skb);\r\n_leave(" [no trans]");\r\nreturn;\r\n}\r\nif (serr->ee.ee_origin == SO_EE_ORIGIN_ICMP &&\r\nserr->ee.ee_type == ICMP_DEST_UNREACH &&\r\nserr->ee.ee_code == ICMP_FRAG_NEEDED\r\n) {\r\nu32 mtu = serr->ee.ee_info;\r\n_net("Rx Received ICMP Fragmentation Needed (%d)", mtu);\r\nif (mtu > 0 && peer->if_mtu == 65535 && mtu < peer->if_mtu) {\r\npeer->if_mtu = mtu;\r\n_net("I/F MTU %u", mtu);\r\n}\r\nif (mtu == 0) {\r\nif (mtu > 1500) {\r\nmtu >>= 1;\r\nif (mtu < 1500)\r\nmtu = 1500;\r\n} else {\r\nmtu -= 100;\r\nif (mtu < peer->hdrsize)\r\nmtu = peer->hdrsize + 4;\r\n}\r\n}\r\nif (mtu < peer->mtu) {\r\nspin_lock_bh(&peer->lock);\r\npeer->mtu = mtu;\r\npeer->maxdata = peer->mtu - peer->hdrsize;\r\nspin_unlock_bh(&peer->lock);\r\n_net("Net MTU %u (maxdata %u)",\r\npeer->mtu, peer->maxdata);\r\n}\r\n}\r\nrxrpc_put_peer(peer);\r\nskb_queue_tail(&trans->error_queue, skb);\r\nrxrpc_queue_work(&trans->error_handler);\r\nspin_lock_bh(&sk->sk_error_queue.lock);\r\nsk->sk_err = 0;\r\nskb = skb_peek(&sk->sk_error_queue);\r\nif (skb) {\r\nsk->sk_err = SKB_EXT_ERR(skb)->ee.ee_errno;\r\nspin_unlock_bh(&sk->sk_error_queue.lock);\r\nsk->sk_error_report(sk);\r\n} else {\r\nspin_unlock_bh(&sk->sk_error_queue.lock);\r\n}\r\n_leave("");\r\n}\r\nvoid rxrpc_UDP_error_handler(struct work_struct *work)\r\n{\r\nstruct sock_extended_err *ee;\r\nstruct sock_exterr_skb *serr;\r\nstruct rxrpc_transport *trans =\r\ncontainer_of(work, struct rxrpc_transport, error_handler);\r\nstruct sk_buff *skb;\r\nint err;\r\n_enter("");\r\nskb = skb_dequeue(&trans->error_queue);\r\nif (!skb)\r\nreturn;\r\nserr = SKB_EXT_ERR(skb);\r\nee = &serr->ee;\r\n_net("Rx Error o=%d t=%d c=%d e=%d",\r\nee->ee_origin, ee->ee_type, ee->ee_code, ee->ee_errno);\r\nerr = ee->ee_errno;\r\nswitch (ee->ee_origin) {\r\ncase SO_EE_ORIGIN_ICMP:\r\nswitch (ee->ee_type) {\r\ncase ICMP_DEST_UNREACH:\r\nswitch (ee->ee_code) {\r\ncase ICMP_NET_UNREACH:\r\n_net("Rx Received ICMP Network Unreachable");\r\nerr = ENETUNREACH;\r\nbreak;\r\ncase ICMP_HOST_UNREACH:\r\n_net("Rx Received ICMP Host Unreachable");\r\nerr = EHOSTUNREACH;\r\nbreak;\r\ncase ICMP_PORT_UNREACH:\r\n_net("Rx Received ICMP Port Unreachable");\r\nerr = ECONNREFUSED;\r\nbreak;\r\ncase ICMP_FRAG_NEEDED:\r\n_net("Rx Received ICMP Fragmentation Needed (%d)",\r\nee->ee_info);\r\nerr = 0;\r\nbreak;\r\ncase ICMP_NET_UNKNOWN:\r\n_net("Rx Received ICMP Unknown Network");\r\nerr = ENETUNREACH;\r\nbreak;\r\ncase ICMP_HOST_UNKNOWN:\r\n_net("Rx Received ICMP Unknown Host");\r\nerr = EHOSTUNREACH;\r\nbreak;\r\ndefault:\r\n_net("Rx Received ICMP DestUnreach code=%u",\r\nee->ee_code);\r\nbreak;\r\n}\r\nbreak;\r\ncase ICMP_TIME_EXCEEDED:\r\n_net("Rx Received ICMP TTL Exceeded");\r\nbreak;\r\ndefault:\r\n_proto("Rx Received ICMP error { type=%u code=%u }",\r\nee->ee_type, ee->ee_code);\r\nbreak;\r\n}\r\nbreak;\r\ncase SO_EE_ORIGIN_LOCAL:\r\n_proto("Rx Received local error { error=%d }",\r\nee->ee_errno);\r\nbreak;\r\ncase SO_EE_ORIGIN_NONE:\r\ncase SO_EE_ORIGIN_ICMP6:\r\ndefault:\r\n_proto("Rx Received error report { orig=%u }",\r\nee->ee_origin);\r\nbreak;\r\n}\r\nif (err) {\r\nstruct rxrpc_call *call, *_n;\r\n_debug("ISSUE ERROR %d", err);\r\nspin_lock_bh(&trans->peer->lock);\r\ntrans->peer->net_error = err;\r\nlist_for_each_entry_safe(call, _n, &trans->peer->error_targets,\r\nerror_link) {\r\nwrite_lock(&call->state_lock);\r\nif (call->state != RXRPC_CALL_COMPLETE &&\r\ncall->state < RXRPC_CALL_NETWORK_ERROR) {\r\ncall->state = RXRPC_CALL_NETWORK_ERROR;\r\nset_bit(RXRPC_CALL_RCVD_ERROR, &call->events);\r\nrxrpc_queue_call(call);\r\n}\r\nwrite_unlock(&call->state_lock);\r\nlist_del_init(&call->error_link);\r\n}\r\nspin_unlock_bh(&trans->peer->lock);\r\n}\r\nif (!skb_queue_empty(&trans->error_queue))\r\nrxrpc_queue_work(&trans->error_handler);\r\nrxrpc_free_skb(skb);\r\nrxrpc_put_transport(trans);\r\n_leave("");\r\n}
