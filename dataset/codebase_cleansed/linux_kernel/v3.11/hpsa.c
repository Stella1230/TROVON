static inline struct ctlr_info *sdev_to_hba(struct scsi_device *sdev)\r\n{\r\nunsigned long *priv = shost_priv(sdev->host);\r\nreturn (struct ctlr_info *) *priv;\r\n}\r\nstatic inline struct ctlr_info *shost_to_hba(struct Scsi_Host *sh)\r\n{\r\nunsigned long *priv = shost_priv(sh);\r\nreturn (struct ctlr_info *) *priv;\r\n}\r\nstatic int check_for_unit_attention(struct ctlr_info *h,\r\nstruct CommandList *c)\r\n{\r\nif (c->err_info->SenseInfo[2] != UNIT_ATTENTION)\r\nreturn 0;\r\nswitch (c->err_info->SenseInfo[12]) {\r\ncase STATE_CHANGED:\r\ndev_warn(&h->pdev->dev, HPSA "%d: a state change "\r\n"detected, command retried\n", h->ctlr);\r\nbreak;\r\ncase LUN_FAILED:\r\ndev_warn(&h->pdev->dev, HPSA "%d: LUN failure "\r\n"detected, action required\n", h->ctlr);\r\nbreak;\r\ncase REPORT_LUNS_CHANGED:\r\ndev_warn(&h->pdev->dev, HPSA "%d: report LUN data "\r\n"changed, action required\n", h->ctlr);\r\nbreak;\r\ncase POWER_OR_RESET:\r\ndev_warn(&h->pdev->dev, HPSA "%d: a power on "\r\n"or device reset detected\n", h->ctlr);\r\nbreak;\r\ncase UNIT_ATTENTION_CLEARED:\r\ndev_warn(&h->pdev->dev, HPSA "%d: unit attention "\r\n"cleared by another initiator\n", h->ctlr);\r\nbreak;\r\ndefault:\r\ndev_warn(&h->pdev->dev, HPSA "%d: unknown "\r\n"unit attention detected\n", h->ctlr);\r\nbreak;\r\n}\r\nreturn 1;\r\n}\r\nstatic int check_for_busy(struct ctlr_info *h, struct CommandList *c)\r\n{\r\nif (c->err_info->CommandStatus != CMD_TARGET_STATUS ||\r\n(c->err_info->ScsiStatus != SAM_STAT_BUSY &&\r\nc->err_info->ScsiStatus != SAM_STAT_TASK_SET_FULL))\r\nreturn 0;\r\ndev_warn(&h->pdev->dev, HPSA "device busy");\r\nreturn 1;\r\n}\r\nstatic ssize_t host_store_rescan(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nstruct ctlr_info *h;\r\nstruct Scsi_Host *shost = class_to_shost(dev);\r\nh = shost_to_hba(shost);\r\nhpsa_scan_start(h->scsi_host);\r\nreturn count;\r\n}\r\nstatic ssize_t host_show_firmware_revision(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct ctlr_info *h;\r\nstruct Scsi_Host *shost = class_to_shost(dev);\r\nunsigned char *fwrev;\r\nh = shost_to_hba(shost);\r\nif (!h->hba_inquiry_data)\r\nreturn 0;\r\nfwrev = &h->hba_inquiry_data[32];\r\nreturn snprintf(buf, 20, "%c%c%c%c\n",\r\nfwrev[0], fwrev[1], fwrev[2], fwrev[3]);\r\n}\r\nstatic ssize_t host_show_commands_outstanding(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct Scsi_Host *shost = class_to_shost(dev);\r\nstruct ctlr_info *h = shost_to_hba(shost);\r\nreturn snprintf(buf, 20, "%d\n", h->commands_outstanding);\r\n}\r\nstatic ssize_t host_show_transport_mode(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct ctlr_info *h;\r\nstruct Scsi_Host *shost = class_to_shost(dev);\r\nh = shost_to_hba(shost);\r\nreturn snprintf(buf, 20, "%s\n",\r\nh->transMethod & CFGTBL_Trans_Performant ?\r\n"performant" : "simple");\r\n}\r\nstatic int ctlr_is_hard_resettable(u32 board_id)\r\n{\r\nint i;\r\nfor (i = 0; i < ARRAY_SIZE(unresettable_controller); i++)\r\nif (unresettable_controller[i] == board_id)\r\nreturn 0;\r\nreturn 1;\r\n}\r\nstatic int ctlr_is_soft_resettable(u32 board_id)\r\n{\r\nint i;\r\nfor (i = 0; i < ARRAY_SIZE(soft_unresettable_controller); i++)\r\nif (soft_unresettable_controller[i] == board_id)\r\nreturn 0;\r\nreturn 1;\r\n}\r\nstatic int ctlr_is_resettable(u32 board_id)\r\n{\r\nreturn ctlr_is_hard_resettable(board_id) ||\r\nctlr_is_soft_resettable(board_id);\r\n}\r\nstatic ssize_t host_show_resettable(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct ctlr_info *h;\r\nstruct Scsi_Host *shost = class_to_shost(dev);\r\nh = shost_to_hba(shost);\r\nreturn snprintf(buf, 20, "%d\n", ctlr_is_resettable(h->board_id));\r\n}\r\nstatic inline int is_logical_dev_addr_mode(unsigned char scsi3addr[])\r\n{\r\nreturn (scsi3addr[3] & 0xC0) == 0x40;\r\n}\r\nstatic ssize_t raid_level_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nssize_t l = 0;\r\nunsigned char rlevel;\r\nstruct ctlr_info *h;\r\nstruct scsi_device *sdev;\r\nstruct hpsa_scsi_dev_t *hdev;\r\nunsigned long flags;\r\nsdev = to_scsi_device(dev);\r\nh = sdev_to_hba(sdev);\r\nspin_lock_irqsave(&h->lock, flags);\r\nhdev = sdev->hostdata;\r\nif (!hdev) {\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nreturn -ENODEV;\r\n}\r\nif (!is_logical_dev_addr_mode(hdev->scsi3addr)) {\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nl = snprintf(buf, PAGE_SIZE, "N/A\n");\r\nreturn l;\r\n}\r\nrlevel = hdev->raid_level;\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nif (rlevel > RAID_UNKNOWN)\r\nrlevel = RAID_UNKNOWN;\r\nl = snprintf(buf, PAGE_SIZE, "RAID %s\n", raid_label[rlevel]);\r\nreturn l;\r\n}\r\nstatic ssize_t lunid_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct ctlr_info *h;\r\nstruct scsi_device *sdev;\r\nstruct hpsa_scsi_dev_t *hdev;\r\nunsigned long flags;\r\nunsigned char lunid[8];\r\nsdev = to_scsi_device(dev);\r\nh = sdev_to_hba(sdev);\r\nspin_lock_irqsave(&h->lock, flags);\r\nhdev = sdev->hostdata;\r\nif (!hdev) {\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nreturn -ENODEV;\r\n}\r\nmemcpy(lunid, hdev->scsi3addr, sizeof(lunid));\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nreturn snprintf(buf, 20, "0x%02x%02x%02x%02x%02x%02x%02x%02x\n",\r\nlunid[0], lunid[1], lunid[2], lunid[3],\r\nlunid[4], lunid[5], lunid[6], lunid[7]);\r\n}\r\nstatic ssize_t unique_id_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct ctlr_info *h;\r\nstruct scsi_device *sdev;\r\nstruct hpsa_scsi_dev_t *hdev;\r\nunsigned long flags;\r\nunsigned char sn[16];\r\nsdev = to_scsi_device(dev);\r\nh = sdev_to_hba(sdev);\r\nspin_lock_irqsave(&h->lock, flags);\r\nhdev = sdev->hostdata;\r\nif (!hdev) {\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nreturn -ENODEV;\r\n}\r\nmemcpy(sn, hdev->device_id, sizeof(sn));\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nreturn snprintf(buf, 16 * 2 + 2,\r\n"%02X%02X%02X%02X%02X%02X%02X%02X"\r\n"%02X%02X%02X%02X%02X%02X%02X%02X\n",\r\nsn[0], sn[1], sn[2], sn[3],\r\nsn[4], sn[5], sn[6], sn[7],\r\nsn[8], sn[9], sn[10], sn[11],\r\nsn[12], sn[13], sn[14], sn[15]);\r\n}\r\nstatic inline void addQ(struct list_head *list, struct CommandList *c)\r\n{\r\nlist_add_tail(&c->list, list);\r\n}\r\nstatic inline u32 next_command(struct ctlr_info *h, u8 q)\r\n{\r\nu32 a;\r\nstruct reply_pool *rq = &h->reply_queue[q];\r\nunsigned long flags;\r\nif (unlikely(!(h->transMethod & CFGTBL_Trans_Performant)))\r\nreturn h->access.command_completed(h, q);\r\nif ((rq->head[rq->current_entry] & 1) == rq->wraparound) {\r\na = rq->head[rq->current_entry];\r\nrq->current_entry++;\r\nspin_lock_irqsave(&h->lock, flags);\r\nh->commands_outstanding--;\r\nspin_unlock_irqrestore(&h->lock, flags);\r\n} else {\r\na = FIFO_EMPTY;\r\n}\r\nif (rq->current_entry == h->max_commands) {\r\nrq->current_entry = 0;\r\nrq->wraparound ^= 1;\r\n}\r\nreturn a;\r\n}\r\nstatic void set_performant_mode(struct ctlr_info *h, struct CommandList *c)\r\n{\r\nif (likely(h->transMethod & CFGTBL_Trans_Performant)) {\r\nc->busaddr |= 1 | (h->blockFetchTable[c->Header.SGList] << 1);\r\nif (likely(h->msix_vector))\r\nc->Header.ReplyQueue =\r\nsmp_processor_id() % h->nreply_queues;\r\n}\r\n}\r\nstatic int is_firmware_flash_cmd(u8 *cdb)\r\n{\r\nreturn cdb[0] == BMIC_WRITE && cdb[6] == BMIC_FLASH_FIRMWARE;\r\n}\r\nstatic void dial_down_lockup_detection_during_fw_flash(struct ctlr_info *h,\r\nstruct CommandList *c)\r\n{\r\nif (!is_firmware_flash_cmd(c->Request.CDB))\r\nreturn;\r\natomic_inc(&h->firmware_flash_in_progress);\r\nh->heartbeat_sample_interval = HEARTBEAT_SAMPLE_INTERVAL_DURING_FLASH;\r\n}\r\nstatic void dial_up_lockup_detection_on_fw_flash_complete(struct ctlr_info *h,\r\nstruct CommandList *c)\r\n{\r\nif (is_firmware_flash_cmd(c->Request.CDB) &&\r\natomic_dec_and_test(&h->firmware_flash_in_progress))\r\nh->heartbeat_sample_interval = HEARTBEAT_SAMPLE_INTERVAL;\r\n}\r\nstatic void enqueue_cmd_and_start_io(struct ctlr_info *h,\r\nstruct CommandList *c)\r\n{\r\nunsigned long flags;\r\nset_performant_mode(h, c);\r\ndial_down_lockup_detection_during_fw_flash(h, c);\r\nspin_lock_irqsave(&h->lock, flags);\r\naddQ(&h->reqQ, c);\r\nh->Qdepth++;\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nstart_io(h);\r\n}\r\nstatic inline void removeQ(struct CommandList *c)\r\n{\r\nif (WARN_ON(list_empty(&c->list)))\r\nreturn;\r\nlist_del_init(&c->list);\r\n}\r\nstatic inline int is_hba_lunid(unsigned char scsi3addr[])\r\n{\r\nreturn memcmp(scsi3addr, RAID_CTLR_LUNID, 8) == 0;\r\n}\r\nstatic inline int is_scsi_rev_5(struct ctlr_info *h)\r\n{\r\nif (!h->hba_inquiry_data)\r\nreturn 0;\r\nif ((h->hba_inquiry_data[2] & 0x07) == 5)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int hpsa_find_target_lun(struct ctlr_info *h,\r\nunsigned char scsi3addr[], int bus, int *target, int *lun)\r\n{\r\nint i, found = 0;\r\nDECLARE_BITMAP(lun_taken, HPSA_MAX_DEVICES);\r\nbitmap_zero(lun_taken, HPSA_MAX_DEVICES);\r\nfor (i = 0; i < h->ndevices; i++) {\r\nif (h->dev[i]->bus == bus && h->dev[i]->target != -1)\r\n__set_bit(h->dev[i]->target, lun_taken);\r\n}\r\ni = find_first_zero_bit(lun_taken, HPSA_MAX_DEVICES);\r\nif (i < HPSA_MAX_DEVICES) {\r\n*target = i;\r\n*lun = 0;\r\nfound = 1;\r\n}\r\nreturn !found;\r\n}\r\nstatic int hpsa_scsi_add_entry(struct ctlr_info *h, int hostno,\r\nstruct hpsa_scsi_dev_t *device,\r\nstruct hpsa_scsi_dev_t *added[], int *nadded)\r\n{\r\nint n = h->ndevices;\r\nint i;\r\nunsigned char addr1[8], addr2[8];\r\nstruct hpsa_scsi_dev_t *sd;\r\nif (n >= HPSA_MAX_DEVICES) {\r\ndev_err(&h->pdev->dev, "too many devices, some will be "\r\n"inaccessible.\n");\r\nreturn -1;\r\n}\r\nif (device->lun != -1)\r\ngoto lun_assigned;\r\nif (device->scsi3addr[4] == 0) {\r\nif (hpsa_find_target_lun(h, device->scsi3addr,\r\ndevice->bus, &device->target, &device->lun) != 0)\r\nreturn -1;\r\ngoto lun_assigned;\r\n}\r\nmemcpy(addr1, device->scsi3addr, 8);\r\naddr1[4] = 0;\r\nfor (i = 0; i < n; i++) {\r\nsd = h->dev[i];\r\nmemcpy(addr2, sd->scsi3addr, 8);\r\naddr2[4] = 0;\r\nif (memcmp(addr1, addr2, 8) == 0) {\r\ndevice->bus = sd->bus;\r\ndevice->target = sd->target;\r\ndevice->lun = device->scsi3addr[4];\r\nbreak;\r\n}\r\n}\r\nif (device->lun == -1) {\r\ndev_warn(&h->pdev->dev, "physical device with no LUN=0,"\r\n" suspect firmware bug or unsupported hardware "\r\n"configuration.\n");\r\nreturn -1;\r\n}\r\nlun_assigned:\r\nh->dev[n] = device;\r\nh->ndevices++;\r\nadded[*nadded] = device;\r\n(*nadded)++;\r\ndev_info(&h->pdev->dev, "%s device c%db%dt%dl%d added.\n",\r\nscsi_device_type(device->devtype), hostno,\r\ndevice->bus, device->target, device->lun);\r\nreturn 0;\r\n}\r\nstatic void hpsa_scsi_update_entry(struct ctlr_info *h, int hostno,\r\nint entry, struct hpsa_scsi_dev_t *new_entry)\r\n{\r\nBUG_ON(entry < 0 || entry >= HPSA_MAX_DEVICES);\r\nh->dev[entry]->raid_level = new_entry->raid_level;\r\ndev_info(&h->pdev->dev, "%s device c%db%dt%dl%d updated.\n",\r\nscsi_device_type(new_entry->devtype), hostno, new_entry->bus,\r\nnew_entry->target, new_entry->lun);\r\n}\r\nstatic void hpsa_scsi_replace_entry(struct ctlr_info *h, int hostno,\r\nint entry, struct hpsa_scsi_dev_t *new_entry,\r\nstruct hpsa_scsi_dev_t *added[], int *nadded,\r\nstruct hpsa_scsi_dev_t *removed[], int *nremoved)\r\n{\r\nBUG_ON(entry < 0 || entry >= HPSA_MAX_DEVICES);\r\nremoved[*nremoved] = h->dev[entry];\r\n(*nremoved)++;\r\nif (new_entry->target == -1) {\r\nnew_entry->target = h->dev[entry]->target;\r\nnew_entry->lun = h->dev[entry]->lun;\r\n}\r\nh->dev[entry] = new_entry;\r\nadded[*nadded] = new_entry;\r\n(*nadded)++;\r\ndev_info(&h->pdev->dev, "%s device c%db%dt%dl%d changed.\n",\r\nscsi_device_type(new_entry->devtype), hostno, new_entry->bus,\r\nnew_entry->target, new_entry->lun);\r\n}\r\nstatic void hpsa_scsi_remove_entry(struct ctlr_info *h, int hostno, int entry,\r\nstruct hpsa_scsi_dev_t *removed[], int *nremoved)\r\n{\r\nint i;\r\nstruct hpsa_scsi_dev_t *sd;\r\nBUG_ON(entry < 0 || entry >= HPSA_MAX_DEVICES);\r\nsd = h->dev[entry];\r\nremoved[*nremoved] = h->dev[entry];\r\n(*nremoved)++;\r\nfor (i = entry; i < h->ndevices-1; i++)\r\nh->dev[i] = h->dev[i+1];\r\nh->ndevices--;\r\ndev_info(&h->pdev->dev, "%s device c%db%dt%dl%d removed.\n",\r\nscsi_device_type(sd->devtype), hostno, sd->bus, sd->target,\r\nsd->lun);\r\n}\r\nstatic void fixup_botched_add(struct ctlr_info *h,\r\nstruct hpsa_scsi_dev_t *added)\r\n{\r\nunsigned long flags;\r\nint i, j;\r\nspin_lock_irqsave(&h->lock, flags);\r\nfor (i = 0; i < h->ndevices; i++) {\r\nif (h->dev[i] == added) {\r\nfor (j = i; j < h->ndevices-1; j++)\r\nh->dev[j] = h->dev[j+1];\r\nh->ndevices--;\r\nbreak;\r\n}\r\n}\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nkfree(added);\r\n}\r\nstatic inline int device_is_the_same(struct hpsa_scsi_dev_t *dev1,\r\nstruct hpsa_scsi_dev_t *dev2)\r\n{\r\nif (memcmp(dev1->scsi3addr, dev2->scsi3addr,\r\nsizeof(dev1->scsi3addr)) != 0)\r\nreturn 0;\r\nif (memcmp(dev1->device_id, dev2->device_id,\r\nsizeof(dev1->device_id)) != 0)\r\nreturn 0;\r\nif (memcmp(dev1->model, dev2->model, sizeof(dev1->model)) != 0)\r\nreturn 0;\r\nif (memcmp(dev1->vendor, dev2->vendor, sizeof(dev1->vendor)) != 0)\r\nreturn 0;\r\nif (dev1->devtype != dev2->devtype)\r\nreturn 0;\r\nif (dev1->bus != dev2->bus)\r\nreturn 0;\r\nreturn 1;\r\n}\r\nstatic inline int device_updated(struct hpsa_scsi_dev_t *dev1,\r\nstruct hpsa_scsi_dev_t *dev2)\r\n{\r\nif (dev1->raid_level != dev2->raid_level)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int hpsa_scsi_find_entry(struct hpsa_scsi_dev_t *needle,\r\nstruct hpsa_scsi_dev_t *haystack[], int haystack_size,\r\nint *index)\r\n{\r\nint i;\r\n#define DEVICE_NOT_FOUND 0\r\n#define DEVICE_CHANGED 1\r\n#define DEVICE_SAME 2\r\n#define DEVICE_UPDATED 3\r\nfor (i = 0; i < haystack_size; i++) {\r\nif (haystack[i] == NULL)\r\ncontinue;\r\nif (SCSI3ADDR_EQ(needle->scsi3addr, haystack[i]->scsi3addr)) {\r\n*index = i;\r\nif (device_is_the_same(needle, haystack[i])) {\r\nif (device_updated(needle, haystack[i]))\r\nreturn DEVICE_UPDATED;\r\nreturn DEVICE_SAME;\r\n} else {\r\nreturn DEVICE_CHANGED;\r\n}\r\n}\r\n}\r\n*index = -1;\r\nreturn DEVICE_NOT_FOUND;\r\n}\r\nstatic void adjust_hpsa_scsi_table(struct ctlr_info *h, int hostno,\r\nstruct hpsa_scsi_dev_t *sd[], int nsds)\r\n{\r\nint i, entry, device_change, changes = 0;\r\nstruct hpsa_scsi_dev_t *csd;\r\nunsigned long flags;\r\nstruct hpsa_scsi_dev_t **added, **removed;\r\nint nadded, nremoved;\r\nstruct Scsi_Host *sh = NULL;\r\nadded = kzalloc(sizeof(*added) * HPSA_MAX_DEVICES, GFP_KERNEL);\r\nremoved = kzalloc(sizeof(*removed) * HPSA_MAX_DEVICES, GFP_KERNEL);\r\nif (!added || !removed) {\r\ndev_warn(&h->pdev->dev, "out of memory in "\r\n"adjust_hpsa_scsi_table\n");\r\ngoto free_and_out;\r\n}\r\nspin_lock_irqsave(&h->devlock, flags);\r\ni = 0;\r\nnremoved = 0;\r\nnadded = 0;\r\nwhile (i < h->ndevices) {\r\ncsd = h->dev[i];\r\ndevice_change = hpsa_scsi_find_entry(csd, sd, nsds, &entry);\r\nif (device_change == DEVICE_NOT_FOUND) {\r\nchanges++;\r\nhpsa_scsi_remove_entry(h, hostno, i,\r\nremoved, &nremoved);\r\ncontinue;\r\n} else if (device_change == DEVICE_CHANGED) {\r\nchanges++;\r\nhpsa_scsi_replace_entry(h, hostno, i, sd[entry],\r\nadded, &nadded, removed, &nremoved);\r\nsd[entry] = NULL;\r\n} else if (device_change == DEVICE_UPDATED) {\r\nhpsa_scsi_update_entry(h, hostno, i, sd[entry]);\r\n}\r\ni++;\r\n}\r\nfor (i = 0; i < nsds; i++) {\r\nif (!sd[i])\r\ncontinue;\r\ndevice_change = hpsa_scsi_find_entry(sd[i], h->dev,\r\nh->ndevices, &entry);\r\nif (device_change == DEVICE_NOT_FOUND) {\r\nchanges++;\r\nif (hpsa_scsi_add_entry(h, hostno, sd[i],\r\nadded, &nadded) != 0)\r\nbreak;\r\nsd[i] = NULL;\r\n} else if (device_change == DEVICE_CHANGED) {\r\nchanges++;\r\ndev_warn(&h->pdev->dev,\r\n"device unexpectedly changed.\n");\r\n}\r\n}\r\nspin_unlock_irqrestore(&h->devlock, flags);\r\nif (hostno == -1 || !changes)\r\ngoto free_and_out;\r\nsh = h->scsi_host;\r\nfor (i = 0; i < nremoved; i++) {\r\nstruct scsi_device *sdev =\r\nscsi_device_lookup(sh, removed[i]->bus,\r\nremoved[i]->target, removed[i]->lun);\r\nif (sdev != NULL) {\r\nscsi_remove_device(sdev);\r\nscsi_device_put(sdev);\r\n} else {\r\ndev_warn(&h->pdev->dev, "didn't find c%db%dt%dl%d "\r\n" for removal.", hostno, removed[i]->bus,\r\nremoved[i]->target, removed[i]->lun);\r\n}\r\nkfree(removed[i]);\r\nremoved[i] = NULL;\r\n}\r\nfor (i = 0; i < nadded; i++) {\r\nif (scsi_add_device(sh, added[i]->bus,\r\nadded[i]->target, added[i]->lun) == 0)\r\ncontinue;\r\ndev_warn(&h->pdev->dev, "scsi_add_device c%db%dt%dl%d failed, "\r\n"device not added.\n", hostno, added[i]->bus,\r\nadded[i]->target, added[i]->lun);\r\nfixup_botched_add(h, added[i]);\r\n}\r\nfree_and_out:\r\nkfree(added);\r\nkfree(removed);\r\n}\r\nstatic struct hpsa_scsi_dev_t *lookup_hpsa_scsi_dev(struct ctlr_info *h,\r\nint bus, int target, int lun)\r\n{\r\nint i;\r\nstruct hpsa_scsi_dev_t *sd;\r\nfor (i = 0; i < h->ndevices; i++) {\r\nsd = h->dev[i];\r\nif (sd->bus == bus && sd->target == target && sd->lun == lun)\r\nreturn sd;\r\n}\r\nreturn NULL;\r\n}\r\nstatic int hpsa_slave_alloc(struct scsi_device *sdev)\r\n{\r\nstruct hpsa_scsi_dev_t *sd;\r\nunsigned long flags;\r\nstruct ctlr_info *h;\r\nh = sdev_to_hba(sdev);\r\nspin_lock_irqsave(&h->devlock, flags);\r\nsd = lookup_hpsa_scsi_dev(h, sdev_channel(sdev),\r\nsdev_id(sdev), sdev->lun);\r\nif (sd != NULL)\r\nsdev->hostdata = sd;\r\nspin_unlock_irqrestore(&h->devlock, flags);\r\nreturn 0;\r\n}\r\nstatic void hpsa_slave_destroy(struct scsi_device *sdev)\r\n{\r\n}\r\nstatic void hpsa_free_sg_chain_blocks(struct ctlr_info *h)\r\n{\r\nint i;\r\nif (!h->cmd_sg_list)\r\nreturn;\r\nfor (i = 0; i < h->nr_cmds; i++) {\r\nkfree(h->cmd_sg_list[i]);\r\nh->cmd_sg_list[i] = NULL;\r\n}\r\nkfree(h->cmd_sg_list);\r\nh->cmd_sg_list = NULL;\r\n}\r\nstatic int hpsa_allocate_sg_chain_blocks(struct ctlr_info *h)\r\n{\r\nint i;\r\nif (h->chainsize <= 0)\r\nreturn 0;\r\nh->cmd_sg_list = kzalloc(sizeof(*h->cmd_sg_list) * h->nr_cmds,\r\nGFP_KERNEL);\r\nif (!h->cmd_sg_list)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < h->nr_cmds; i++) {\r\nh->cmd_sg_list[i] = kmalloc(sizeof(*h->cmd_sg_list[i]) *\r\nh->chainsize, GFP_KERNEL);\r\nif (!h->cmd_sg_list[i])\r\ngoto clean;\r\n}\r\nreturn 0;\r\nclean:\r\nhpsa_free_sg_chain_blocks(h);\r\nreturn -ENOMEM;\r\n}\r\nstatic int hpsa_map_sg_chain_block(struct ctlr_info *h,\r\nstruct CommandList *c)\r\n{\r\nstruct SGDescriptor *chain_sg, *chain_block;\r\nu64 temp64;\r\nchain_sg = &c->SG[h->max_cmd_sg_entries - 1];\r\nchain_block = h->cmd_sg_list[c->cmdindex];\r\nchain_sg->Ext = HPSA_SG_CHAIN;\r\nchain_sg->Len = sizeof(*chain_sg) *\r\n(c->Header.SGTotal - h->max_cmd_sg_entries);\r\ntemp64 = pci_map_single(h->pdev, chain_block, chain_sg->Len,\r\nPCI_DMA_TODEVICE);\r\nif (dma_mapping_error(&h->pdev->dev, temp64)) {\r\nchain_sg->Addr.lower = 0;\r\nchain_sg->Addr.upper = 0;\r\nreturn -1;\r\n}\r\nchain_sg->Addr.lower = (u32) (temp64 & 0x0FFFFFFFFULL);\r\nchain_sg->Addr.upper = (u32) ((temp64 >> 32) & 0x0FFFFFFFFULL);\r\nreturn 0;\r\n}\r\nstatic void hpsa_unmap_sg_chain_block(struct ctlr_info *h,\r\nstruct CommandList *c)\r\n{\r\nstruct SGDescriptor *chain_sg;\r\nunion u64bit temp64;\r\nif (c->Header.SGTotal <= h->max_cmd_sg_entries)\r\nreturn;\r\nchain_sg = &c->SG[h->max_cmd_sg_entries - 1];\r\ntemp64.val32.lower = chain_sg->Addr.lower;\r\ntemp64.val32.upper = chain_sg->Addr.upper;\r\npci_unmap_single(h->pdev, temp64.val, chain_sg->Len, PCI_DMA_TODEVICE);\r\n}\r\nstatic void complete_scsi_command(struct CommandList *cp)\r\n{\r\nstruct scsi_cmnd *cmd;\r\nstruct ctlr_info *h;\r\nstruct ErrorInfo *ei;\r\nunsigned char sense_key;\r\nunsigned char asc;\r\nunsigned char ascq;\r\nunsigned long sense_data_size;\r\nei = cp->err_info;\r\ncmd = (struct scsi_cmnd *) cp->scsi_cmd;\r\nh = cp->h;\r\nscsi_dma_unmap(cmd);\r\nif (cp->Header.SGTotal > h->max_cmd_sg_entries)\r\nhpsa_unmap_sg_chain_block(h, cp);\r\ncmd->result = (DID_OK << 16);\r\ncmd->result |= (COMMAND_COMPLETE << 8);\r\ncmd->result |= ei->ScsiStatus;\r\nif (SCSI_SENSE_BUFFERSIZE < sizeof(ei->SenseInfo))\r\nsense_data_size = SCSI_SENSE_BUFFERSIZE;\r\nelse\r\nsense_data_size = sizeof(ei->SenseInfo);\r\nif (ei->SenseLen < sense_data_size)\r\nsense_data_size = ei->SenseLen;\r\nmemcpy(cmd->sense_buffer, ei->SenseInfo, sense_data_size);\r\nscsi_set_resid(cmd, ei->ResidualCnt);\r\nif (ei->CommandStatus == 0) {\r\ncmd->scsi_done(cmd);\r\ncmd_free(h, cp);\r\nreturn;\r\n}\r\nswitch (ei->CommandStatus) {\r\ncase CMD_TARGET_STATUS:\r\nif (ei->ScsiStatus) {\r\nsense_key = 0xf & ei->SenseInfo[2];\r\nasc = ei->SenseInfo[12];\r\nascq = ei->SenseInfo[13];\r\n}\r\nif (ei->ScsiStatus == SAM_STAT_CHECK_CONDITION) {\r\nif (check_for_unit_attention(h, cp)) {\r\ncmd->result = DID_SOFT_ERROR << 16;\r\nbreak;\r\n}\r\nif (sense_key == ILLEGAL_REQUEST) {\r\nif (cp->Request.CDB[0] == REPORT_LUNS)\r\nbreak;\r\nif ((asc == 0x25) && (ascq == 0x0)) {\r\ndev_warn(&h->pdev->dev, "cp %p "\r\n"has check condition\n", cp);\r\nbreak;\r\n}\r\n}\r\nif (sense_key == NOT_READY) {\r\nif ((asc == 0x04) && (ascq == 0x03)) {\r\ndev_warn(&h->pdev->dev, "cp %p "\r\n"has check condition: unit "\r\n"not ready, manual "\r\n"intervention required\n", cp);\r\nbreak;\r\n}\r\n}\r\nif (sense_key == ABORTED_COMMAND) {\r\ndev_warn(&h->pdev->dev, "cp %p "\r\n"has check condition: aborted command: "\r\n"ASC: 0x%x, ASCQ: 0x%x\n",\r\ncp, asc, ascq);\r\ncmd->result = DID_SOFT_ERROR << 16;\r\nbreak;\r\n}\r\ndev_dbg(&h->pdev->dev, "cp %p has check condition: "\r\n"unknown type: "\r\n"Sense: 0x%x, ASC: 0x%x, ASCQ: 0x%x, "\r\n"Returning result: 0x%x, "\r\n"cmd=[%02x %02x %02x %02x %02x "\r\n"%02x %02x %02x %02x %02x %02x "\r\n"%02x %02x %02x %02x %02x]\n",\r\ncp, sense_key, asc, ascq,\r\ncmd->result,\r\ncmd->cmnd[0], cmd->cmnd[1],\r\ncmd->cmnd[2], cmd->cmnd[3],\r\ncmd->cmnd[4], cmd->cmnd[5],\r\ncmd->cmnd[6], cmd->cmnd[7],\r\ncmd->cmnd[8], cmd->cmnd[9],\r\ncmd->cmnd[10], cmd->cmnd[11],\r\ncmd->cmnd[12], cmd->cmnd[13],\r\ncmd->cmnd[14], cmd->cmnd[15]);\r\nbreak;\r\n}\r\nif (ei->ScsiStatus) {\r\ndev_warn(&h->pdev->dev, "cp %p has status 0x%x "\r\n"Sense: 0x%x, ASC: 0x%x, ASCQ: 0x%x, "\r\n"Returning result: 0x%x\n",\r\ncp, ei->ScsiStatus,\r\nsense_key, asc, ascq,\r\ncmd->result);\r\n} else {\r\ndev_warn(&h->pdev->dev, "cp %p SCSI status was 0. "\r\n"Returning no connection.\n", cp),\r\ncmd->result = DID_NO_CONNECT << 16;\r\n}\r\nbreak;\r\ncase CMD_DATA_UNDERRUN:\r\nbreak;\r\ncase CMD_DATA_OVERRUN:\r\ndev_warn(&h->pdev->dev, "cp %p has"\r\n" completed with data overrun "\r\n"reported\n", cp);\r\nbreak;\r\ncase CMD_INVALID: {\r\ncmd->result = DID_NO_CONNECT << 16;\r\n}\r\nbreak;\r\ncase CMD_PROTOCOL_ERR:\r\ncmd->result = DID_ERROR << 16;\r\ndev_warn(&h->pdev->dev, "cp %p has "\r\n"protocol error\n", cp);\r\nbreak;\r\ncase CMD_HARDWARE_ERR:\r\ncmd->result = DID_ERROR << 16;\r\ndev_warn(&h->pdev->dev, "cp %p had hardware error\n", cp);\r\nbreak;\r\ncase CMD_CONNECTION_LOST:\r\ncmd->result = DID_ERROR << 16;\r\ndev_warn(&h->pdev->dev, "cp %p had connection lost\n", cp);\r\nbreak;\r\ncase CMD_ABORTED:\r\ncmd->result = DID_ABORT << 16;\r\ndev_warn(&h->pdev->dev, "cp %p was aborted with status 0x%x\n",\r\ncp, ei->ScsiStatus);\r\nbreak;\r\ncase CMD_ABORT_FAILED:\r\ncmd->result = DID_ERROR << 16;\r\ndev_warn(&h->pdev->dev, "cp %p reports abort failed\n", cp);\r\nbreak;\r\ncase CMD_UNSOLICITED_ABORT:\r\ncmd->result = DID_SOFT_ERROR << 16;\r\ndev_warn(&h->pdev->dev, "cp %p aborted due to an unsolicited "\r\n"abort\n", cp);\r\nbreak;\r\ncase CMD_TIMEOUT:\r\ncmd->result = DID_TIME_OUT << 16;\r\ndev_warn(&h->pdev->dev, "cp %p timedout\n", cp);\r\nbreak;\r\ncase CMD_UNABORTABLE:\r\ncmd->result = DID_ERROR << 16;\r\ndev_warn(&h->pdev->dev, "Command unabortable\n");\r\nbreak;\r\ndefault:\r\ncmd->result = DID_ERROR << 16;\r\ndev_warn(&h->pdev->dev, "cp %p returned unknown status %x\n",\r\ncp, ei->CommandStatus);\r\n}\r\ncmd->scsi_done(cmd);\r\ncmd_free(h, cp);\r\n}\r\nstatic void hpsa_pci_unmap(struct pci_dev *pdev,\r\nstruct CommandList *c, int sg_used, int data_direction)\r\n{\r\nint i;\r\nunion u64bit addr64;\r\nfor (i = 0; i < sg_used; i++) {\r\naddr64.val32.lower = c->SG[i].Addr.lower;\r\naddr64.val32.upper = c->SG[i].Addr.upper;\r\npci_unmap_single(pdev, (dma_addr_t) addr64.val, c->SG[i].Len,\r\ndata_direction);\r\n}\r\n}\r\nstatic int hpsa_map_one(struct pci_dev *pdev,\r\nstruct CommandList *cp,\r\nunsigned char *buf,\r\nsize_t buflen,\r\nint data_direction)\r\n{\r\nu64 addr64;\r\nif (buflen == 0 || data_direction == PCI_DMA_NONE) {\r\ncp->Header.SGList = 0;\r\ncp->Header.SGTotal = 0;\r\nreturn 0;\r\n}\r\naddr64 = (u64) pci_map_single(pdev, buf, buflen, data_direction);\r\nif (dma_mapping_error(&pdev->dev, addr64)) {\r\ncp->Header.SGList = 0;\r\ncp->Header.SGTotal = 0;\r\nreturn -1;\r\n}\r\ncp->SG[0].Addr.lower =\r\n(u32) (addr64 & (u64) 0x00000000FFFFFFFF);\r\ncp->SG[0].Addr.upper =\r\n(u32) ((addr64 >> 32) & (u64) 0x00000000FFFFFFFF);\r\ncp->SG[0].Len = buflen;\r\ncp->Header.SGList = (u8) 1;\r\ncp->Header.SGTotal = (u16) 1;\r\nreturn 0;\r\n}\r\nstatic inline void hpsa_scsi_do_simple_cmd_core(struct ctlr_info *h,\r\nstruct CommandList *c)\r\n{\r\nDECLARE_COMPLETION_ONSTACK(wait);\r\nc->waiting = &wait;\r\nenqueue_cmd_and_start_io(h, c);\r\nwait_for_completion(&wait);\r\n}\r\nstatic void hpsa_scsi_do_simple_cmd_core_if_no_lockup(struct ctlr_info *h,\r\nstruct CommandList *c)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&h->lock, flags);\r\nif (unlikely(h->lockup_detected)) {\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nc->err_info->CommandStatus = CMD_HARDWARE_ERR;\r\n} else {\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nhpsa_scsi_do_simple_cmd_core(h, c);\r\n}\r\n}\r\nstatic void hpsa_scsi_do_simple_cmd_with_retry(struct ctlr_info *h,\r\nstruct CommandList *c, int data_direction)\r\n{\r\nint backoff_time = 10, retry_count = 0;\r\ndo {\r\nmemset(c->err_info, 0, sizeof(*c->err_info));\r\nhpsa_scsi_do_simple_cmd_core(h, c);\r\nretry_count++;\r\nif (retry_count > 3) {\r\nmsleep(backoff_time);\r\nif (backoff_time < 1000)\r\nbackoff_time *= 2;\r\n}\r\n} while ((check_for_unit_attention(h, c) ||\r\ncheck_for_busy(h, c)) &&\r\nretry_count <= MAX_DRIVER_CMD_RETRIES);\r\nhpsa_pci_unmap(h->pdev, c, 1, data_direction);\r\n}\r\nstatic void hpsa_scsi_interpret_error(struct CommandList *cp)\r\n{\r\nstruct ErrorInfo *ei;\r\nstruct device *d = &cp->h->pdev->dev;\r\nei = cp->err_info;\r\nswitch (ei->CommandStatus) {\r\ncase CMD_TARGET_STATUS:\r\ndev_warn(d, "cmd %p has completed with errors\n", cp);\r\ndev_warn(d, "cmd %p has SCSI Status = %x\n", cp,\r\nei->ScsiStatus);\r\nif (ei->ScsiStatus == 0)\r\ndev_warn(d, "SCSI status is abnormally zero. "\r\n"(probably indicates selection timeout "\r\n"reported incorrectly due to a known "\r\n"firmware bug, circa July, 2001.)\n");\r\nbreak;\r\ncase CMD_DATA_UNDERRUN:\r\ndev_info(d, "UNDERRUN\n");\r\nbreak;\r\ncase CMD_DATA_OVERRUN:\r\ndev_warn(d, "cp %p has completed with data overrun\n", cp);\r\nbreak;\r\ncase CMD_INVALID: {\r\ndev_warn(d, "cp %p is reported invalid (probably means "\r\n"target device no longer present)\n", cp);\r\n}\r\nbreak;\r\ncase CMD_PROTOCOL_ERR:\r\ndev_warn(d, "cp %p has protocol error \n", cp);\r\nbreak;\r\ncase CMD_HARDWARE_ERR:\r\ndev_warn(d, "cp %p had hardware error\n", cp);\r\nbreak;\r\ncase CMD_CONNECTION_LOST:\r\ndev_warn(d, "cp %p had connection lost\n", cp);\r\nbreak;\r\ncase CMD_ABORTED:\r\ndev_warn(d, "cp %p was aborted\n", cp);\r\nbreak;\r\ncase CMD_ABORT_FAILED:\r\ndev_warn(d, "cp %p reports abort failed\n", cp);\r\nbreak;\r\ncase CMD_UNSOLICITED_ABORT:\r\ndev_warn(d, "cp %p aborted due to an unsolicited abort\n", cp);\r\nbreak;\r\ncase CMD_TIMEOUT:\r\ndev_warn(d, "cp %p timed out\n", cp);\r\nbreak;\r\ncase CMD_UNABORTABLE:\r\ndev_warn(d, "Command unabortable\n");\r\nbreak;\r\ndefault:\r\ndev_warn(d, "cp %p returned unknown status %x\n", cp,\r\nei->CommandStatus);\r\n}\r\n}\r\nstatic int hpsa_scsi_do_inquiry(struct ctlr_info *h, unsigned char *scsi3addr,\r\nunsigned char page, unsigned char *buf,\r\nunsigned char bufsize)\r\n{\r\nint rc = IO_OK;\r\nstruct CommandList *c;\r\nstruct ErrorInfo *ei;\r\nc = cmd_special_alloc(h);\r\nif (c == NULL) {\r\ndev_warn(&h->pdev->dev, "cmd_special_alloc returned NULL!\n");\r\nreturn -ENOMEM;\r\n}\r\nif (fill_cmd(c, HPSA_INQUIRY, h, buf, bufsize,\r\npage, scsi3addr, TYPE_CMD)) {\r\nrc = -1;\r\ngoto out;\r\n}\r\nhpsa_scsi_do_simple_cmd_with_retry(h, c, PCI_DMA_FROMDEVICE);\r\nei = c->err_info;\r\nif (ei->CommandStatus != 0 && ei->CommandStatus != CMD_DATA_UNDERRUN) {\r\nhpsa_scsi_interpret_error(c);\r\nrc = -1;\r\n}\r\nout:\r\ncmd_special_free(h, c);\r\nreturn rc;\r\n}\r\nstatic int hpsa_send_reset(struct ctlr_info *h, unsigned char *scsi3addr)\r\n{\r\nint rc = IO_OK;\r\nstruct CommandList *c;\r\nstruct ErrorInfo *ei;\r\nc = cmd_special_alloc(h);\r\nif (c == NULL) {\r\ndev_warn(&h->pdev->dev, "cmd_special_alloc returned NULL!\n");\r\nreturn -ENOMEM;\r\n}\r\n(void) fill_cmd(c, HPSA_DEVICE_RESET_MSG, h,\r\nNULL, 0, 0, scsi3addr, TYPE_MSG);\r\nhpsa_scsi_do_simple_cmd_core(h, c);\r\nei = c->err_info;\r\nif (ei->CommandStatus != 0) {\r\nhpsa_scsi_interpret_error(c);\r\nrc = -1;\r\n}\r\ncmd_special_free(h, c);\r\nreturn rc;\r\n}\r\nstatic void hpsa_get_raid_level(struct ctlr_info *h,\r\nunsigned char *scsi3addr, unsigned char *raid_level)\r\n{\r\nint rc;\r\nunsigned char *buf;\r\n*raid_level = RAID_UNKNOWN;\r\nbuf = kzalloc(64, GFP_KERNEL);\r\nif (!buf)\r\nreturn;\r\nrc = hpsa_scsi_do_inquiry(h, scsi3addr, 0xC1, buf, 64);\r\nif (rc == 0)\r\n*raid_level = buf[8];\r\nif (*raid_level > RAID_UNKNOWN)\r\n*raid_level = RAID_UNKNOWN;\r\nkfree(buf);\r\nreturn;\r\n}\r\nstatic int hpsa_get_device_id(struct ctlr_info *h, unsigned char *scsi3addr,\r\nunsigned char *device_id, int buflen)\r\n{\r\nint rc;\r\nunsigned char *buf;\r\nif (buflen > 16)\r\nbuflen = 16;\r\nbuf = kzalloc(64, GFP_KERNEL);\r\nif (!buf)\r\nreturn -1;\r\nrc = hpsa_scsi_do_inquiry(h, scsi3addr, 0x83, buf, 64);\r\nif (rc == 0)\r\nmemcpy(device_id, &buf[8], buflen);\r\nkfree(buf);\r\nreturn rc != 0;\r\n}\r\nstatic int hpsa_scsi_do_report_luns(struct ctlr_info *h, int logical,\r\nstruct ReportLUNdata *buf, int bufsize,\r\nint extended_response)\r\n{\r\nint rc = IO_OK;\r\nstruct CommandList *c;\r\nunsigned char scsi3addr[8];\r\nstruct ErrorInfo *ei;\r\nc = cmd_special_alloc(h);\r\nif (c == NULL) {\r\ndev_err(&h->pdev->dev, "cmd_special_alloc returned NULL!\n");\r\nreturn -1;\r\n}\r\nmemset(scsi3addr, 0, sizeof(scsi3addr));\r\nif (fill_cmd(c, logical ? HPSA_REPORT_LOG : HPSA_REPORT_PHYS, h,\r\nbuf, bufsize, 0, scsi3addr, TYPE_CMD)) {\r\nrc = -1;\r\ngoto out;\r\n}\r\nif (extended_response)\r\nc->Request.CDB[1] = extended_response;\r\nhpsa_scsi_do_simple_cmd_with_retry(h, c, PCI_DMA_FROMDEVICE);\r\nei = c->err_info;\r\nif (ei->CommandStatus != 0 &&\r\nei->CommandStatus != CMD_DATA_UNDERRUN) {\r\nhpsa_scsi_interpret_error(c);\r\nrc = -1;\r\n}\r\nout:\r\ncmd_special_free(h, c);\r\nreturn rc;\r\n}\r\nstatic inline int hpsa_scsi_do_report_phys_luns(struct ctlr_info *h,\r\nstruct ReportLUNdata *buf,\r\nint bufsize, int extended_response)\r\n{\r\nreturn hpsa_scsi_do_report_luns(h, 0, buf, bufsize, extended_response);\r\n}\r\nstatic inline int hpsa_scsi_do_report_log_luns(struct ctlr_info *h,\r\nstruct ReportLUNdata *buf, int bufsize)\r\n{\r\nreturn hpsa_scsi_do_report_luns(h, 1, buf, bufsize, 0);\r\n}\r\nstatic inline void hpsa_set_bus_target_lun(struct hpsa_scsi_dev_t *device,\r\nint bus, int target, int lun)\r\n{\r\ndevice->bus = bus;\r\ndevice->target = target;\r\ndevice->lun = lun;\r\n}\r\nstatic int hpsa_update_device_info(struct ctlr_info *h,\r\nunsigned char scsi3addr[], struct hpsa_scsi_dev_t *this_device,\r\nunsigned char *is_OBDR_device)\r\n{\r\n#define OBDR_SIG_OFFSET 43\r\n#define OBDR_TAPE_SIG "$DR-10"\r\n#define OBDR_SIG_LEN (sizeof(OBDR_TAPE_SIG) - 1)\r\n#define OBDR_TAPE_INQ_SIZE (OBDR_SIG_OFFSET + OBDR_SIG_LEN)\r\nunsigned char *inq_buff;\r\nunsigned char *obdr_sig;\r\ninq_buff = kzalloc(OBDR_TAPE_INQ_SIZE, GFP_KERNEL);\r\nif (!inq_buff)\r\ngoto bail_out;\r\nif (hpsa_scsi_do_inquiry(h, scsi3addr, 0, inq_buff,\r\n(unsigned char) OBDR_TAPE_INQ_SIZE) != 0) {\r\ndev_err(&h->pdev->dev,\r\n"hpsa_update_device_info: inquiry failed\n");\r\ngoto bail_out;\r\n}\r\nthis_device->devtype = (inq_buff[0] & 0x1f);\r\nmemcpy(this_device->scsi3addr, scsi3addr, 8);\r\nmemcpy(this_device->vendor, &inq_buff[8],\r\nsizeof(this_device->vendor));\r\nmemcpy(this_device->model, &inq_buff[16],\r\nsizeof(this_device->model));\r\nmemset(this_device->device_id, 0,\r\nsizeof(this_device->device_id));\r\nhpsa_get_device_id(h, scsi3addr, this_device->device_id,\r\nsizeof(this_device->device_id));\r\nif (this_device->devtype == TYPE_DISK &&\r\nis_logical_dev_addr_mode(scsi3addr))\r\nhpsa_get_raid_level(h, scsi3addr, &this_device->raid_level);\r\nelse\r\nthis_device->raid_level = RAID_UNKNOWN;\r\nif (is_OBDR_device) {\r\nobdr_sig = &inq_buff[OBDR_SIG_OFFSET];\r\n*is_OBDR_device = (this_device->devtype == TYPE_ROM &&\r\nstrncmp(obdr_sig, OBDR_TAPE_SIG,\r\nOBDR_SIG_LEN) == 0);\r\n}\r\nkfree(inq_buff);\r\nreturn 0;\r\nbail_out:\r\nkfree(inq_buff);\r\nreturn 1;\r\n}\r\nstatic int is_ext_target(struct ctlr_info *h, struct hpsa_scsi_dev_t *device)\r\n{\r\nint i;\r\nfor (i = 0; ext_target_model[i]; i++)\r\nif (strncmp(device->model, ext_target_model[i],\r\nstrlen(ext_target_model[i])) == 0)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic void figure_bus_target_lun(struct ctlr_info *h,\r\nu8 *lunaddrbytes, struct hpsa_scsi_dev_t *device)\r\n{\r\nu32 lunid = le32_to_cpu(*((__le32 *) lunaddrbytes));\r\nif (!is_logical_dev_addr_mode(lunaddrbytes)) {\r\nif (is_hba_lunid(lunaddrbytes))\r\nhpsa_set_bus_target_lun(device, 3, 0, lunid & 0x3fff);\r\nelse\r\nhpsa_set_bus_target_lun(device, 2, -1, -1);\r\nreturn;\r\n}\r\nif (is_ext_target(h, device)) {\r\nhpsa_set_bus_target_lun(device,\r\n1, (lunid >> 16) & 0x3fff, lunid & 0x00ff);\r\nreturn;\r\n}\r\nhpsa_set_bus_target_lun(device, 0, 0, lunid & 0x3fff);\r\n}\r\nstatic int add_ext_target_dev(struct ctlr_info *h,\r\nstruct hpsa_scsi_dev_t *tmpdevice,\r\nstruct hpsa_scsi_dev_t *this_device, u8 *lunaddrbytes,\r\nunsigned long lunzerobits[], int *n_ext_target_devs)\r\n{\r\nunsigned char scsi3addr[8];\r\nif (test_bit(tmpdevice->target, lunzerobits))\r\nreturn 0;\r\nif (!is_logical_dev_addr_mode(lunaddrbytes))\r\nreturn 0;\r\nif (!is_ext_target(h, tmpdevice))\r\nreturn 0;\r\nif (tmpdevice->lun == 0)\r\nreturn 0;\r\nmemset(scsi3addr, 0, 8);\r\nscsi3addr[3] = tmpdevice->target;\r\nif (is_hba_lunid(scsi3addr))\r\nreturn 0;\r\nif (is_scsi_rev_5(h))\r\nreturn 0;\r\nif (*n_ext_target_devs >= MAX_EXT_TARGETS) {\r\ndev_warn(&h->pdev->dev, "Maximum number of external "\r\n"target devices exceeded. Check your hardware "\r\n"configuration.");\r\nreturn 0;\r\n}\r\nif (hpsa_update_device_info(h, scsi3addr, this_device, NULL))\r\nreturn 0;\r\n(*n_ext_target_devs)++;\r\nhpsa_set_bus_target_lun(this_device,\r\ntmpdevice->bus, tmpdevice->target, 0);\r\nset_bit(tmpdevice->target, lunzerobits);\r\nreturn 1;\r\n}\r\nstatic int hpsa_gather_lun_info(struct ctlr_info *h,\r\nint reportlunsize,\r\nstruct ReportLUNdata *physdev, u32 *nphysicals,\r\nstruct ReportLUNdata *logdev, u32 *nlogicals)\r\n{\r\nif (hpsa_scsi_do_report_phys_luns(h, physdev, reportlunsize, 0)) {\r\ndev_err(&h->pdev->dev, "report physical LUNs failed.\n");\r\nreturn -1;\r\n}\r\n*nphysicals = be32_to_cpu(*((__be32 *)physdev->LUNListLength)) / 8;\r\nif (*nphysicals > HPSA_MAX_PHYS_LUN) {\r\ndev_warn(&h->pdev->dev, "maximum physical LUNs (%d) exceeded."\r\n" %d LUNs ignored.\n", HPSA_MAX_PHYS_LUN,\r\n*nphysicals - HPSA_MAX_PHYS_LUN);\r\n*nphysicals = HPSA_MAX_PHYS_LUN;\r\n}\r\nif (hpsa_scsi_do_report_log_luns(h, logdev, reportlunsize)) {\r\ndev_err(&h->pdev->dev, "report logical LUNs failed.\n");\r\nreturn -1;\r\n}\r\n*nlogicals = be32_to_cpu(*((__be32 *) logdev->LUNListLength)) / 8;\r\nif (*nlogicals > HPSA_MAX_LUN) {\r\ndev_warn(&h->pdev->dev,\r\n"maximum logical LUNs (%d) exceeded. "\r\n"%d LUNs ignored.\n", HPSA_MAX_LUN,\r\n*nlogicals - HPSA_MAX_LUN);\r\n*nlogicals = HPSA_MAX_LUN;\r\n}\r\nif (*nlogicals + *nphysicals > HPSA_MAX_PHYS_LUN) {\r\ndev_warn(&h->pdev->dev,\r\n"maximum logical + physical LUNs (%d) exceeded. "\r\n"%d LUNs ignored.\n", HPSA_MAX_PHYS_LUN,\r\n*nphysicals + *nlogicals - HPSA_MAX_PHYS_LUN);\r\n*nlogicals = HPSA_MAX_PHYS_LUN - *nphysicals;\r\n}\r\nreturn 0;\r\n}\r\nu8 *figure_lunaddrbytes(struct ctlr_info *h, int raid_ctlr_position, int i,\r\nint nphysicals, int nlogicals, struct ReportLUNdata *physdev_list,\r\nstruct ReportLUNdata *logdev_list)\r\n{\r\nint logicals_start = nphysicals + (raid_ctlr_position == 0);\r\nint last_device = nphysicals + nlogicals + (raid_ctlr_position == 0);\r\nif (i == raid_ctlr_position)\r\nreturn RAID_CTLR_LUNID;\r\nif (i < logicals_start)\r\nreturn &physdev_list->LUN[i - (raid_ctlr_position == 0)][0];\r\nif (i < last_device)\r\nreturn &logdev_list->LUN[i - nphysicals -\r\n(raid_ctlr_position == 0)][0];\r\nBUG();\r\nreturn NULL;\r\n}\r\nstatic void hpsa_update_scsi_devices(struct ctlr_info *h, int hostno)\r\n{\r\nstruct ReportLUNdata *physdev_list = NULL;\r\nstruct ReportLUNdata *logdev_list = NULL;\r\nu32 nphysicals = 0;\r\nu32 nlogicals = 0;\r\nu32 ndev_allocated = 0;\r\nstruct hpsa_scsi_dev_t **currentsd, *this_device, *tmpdevice;\r\nint ncurrent = 0;\r\nint reportlunsize = sizeof(*physdev_list) + HPSA_MAX_PHYS_LUN * 8;\r\nint i, n_ext_target_devs, ndevs_to_allocate;\r\nint raid_ctlr_position;\r\nDECLARE_BITMAP(lunzerobits, MAX_EXT_TARGETS);\r\ncurrentsd = kzalloc(sizeof(*currentsd) * HPSA_MAX_DEVICES, GFP_KERNEL);\r\nphysdev_list = kzalloc(reportlunsize, GFP_KERNEL);\r\nlogdev_list = kzalloc(reportlunsize, GFP_KERNEL);\r\ntmpdevice = kzalloc(sizeof(*tmpdevice), GFP_KERNEL);\r\nif (!currentsd || !physdev_list || !logdev_list || !tmpdevice) {\r\ndev_err(&h->pdev->dev, "out of memory\n");\r\ngoto out;\r\n}\r\nmemset(lunzerobits, 0, sizeof(lunzerobits));\r\nif (hpsa_gather_lun_info(h, reportlunsize, physdev_list, &nphysicals,\r\nlogdev_list, &nlogicals))\r\ngoto out;\r\nndevs_to_allocate = nphysicals + nlogicals + MAX_EXT_TARGETS + 1;\r\nfor (i = 0; i < ndevs_to_allocate; i++) {\r\nif (i >= HPSA_MAX_DEVICES) {\r\ndev_warn(&h->pdev->dev, "maximum devices (%d) exceeded."\r\n" %d devices ignored.\n", HPSA_MAX_DEVICES,\r\nndevs_to_allocate - HPSA_MAX_DEVICES);\r\nbreak;\r\n}\r\ncurrentsd[i] = kzalloc(sizeof(*currentsd[i]), GFP_KERNEL);\r\nif (!currentsd[i]) {\r\ndev_warn(&h->pdev->dev, "out of memory at %s:%d\n",\r\n__FILE__, __LINE__);\r\ngoto out;\r\n}\r\nndev_allocated++;\r\n}\r\nif (unlikely(is_scsi_rev_5(h)))\r\nraid_ctlr_position = 0;\r\nelse\r\nraid_ctlr_position = nphysicals + nlogicals;\r\nn_ext_target_devs = 0;\r\nfor (i = 0; i < nphysicals + nlogicals + 1; i++) {\r\nu8 *lunaddrbytes, is_OBDR = 0;\r\nlunaddrbytes = figure_lunaddrbytes(h, raid_ctlr_position,\r\ni, nphysicals, nlogicals, physdev_list, logdev_list);\r\nif (lunaddrbytes[3] & 0xC0 &&\r\ni < nphysicals + (raid_ctlr_position == 0))\r\ncontinue;\r\nif (hpsa_update_device_info(h, lunaddrbytes, tmpdevice,\r\n&is_OBDR))\r\ncontinue;\r\nfigure_bus_target_lun(h, lunaddrbytes, tmpdevice);\r\nthis_device = currentsd[ncurrent];\r\nif (add_ext_target_dev(h, tmpdevice, this_device,\r\nlunaddrbytes, lunzerobits,\r\n&n_ext_target_devs)) {\r\nncurrent++;\r\nthis_device = currentsd[ncurrent];\r\n}\r\n*this_device = *tmpdevice;\r\nswitch (this_device->devtype) {\r\ncase TYPE_ROM:\r\nif (is_OBDR)\r\nncurrent++;\r\nbreak;\r\ncase TYPE_DISK:\r\nif (i < nphysicals)\r\nbreak;\r\nncurrent++;\r\nbreak;\r\ncase TYPE_TAPE:\r\ncase TYPE_MEDIUM_CHANGER:\r\nncurrent++;\r\nbreak;\r\ncase TYPE_RAID:\r\nif (!is_hba_lunid(lunaddrbytes))\r\nbreak;\r\nncurrent++;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nif (ncurrent >= HPSA_MAX_DEVICES)\r\nbreak;\r\n}\r\nadjust_hpsa_scsi_table(h, hostno, currentsd, ncurrent);\r\nout:\r\nkfree(tmpdevice);\r\nfor (i = 0; i < ndev_allocated; i++)\r\nkfree(currentsd[i]);\r\nkfree(currentsd);\r\nkfree(physdev_list);\r\nkfree(logdev_list);\r\n}\r\nstatic int hpsa_scatter_gather(struct ctlr_info *h,\r\nstruct CommandList *cp,\r\nstruct scsi_cmnd *cmd)\r\n{\r\nunsigned int len;\r\nstruct scatterlist *sg;\r\nu64 addr64;\r\nint use_sg, i, sg_index, chained;\r\nstruct SGDescriptor *curr_sg;\r\nBUG_ON(scsi_sg_count(cmd) > h->maxsgentries);\r\nuse_sg = scsi_dma_map(cmd);\r\nif (use_sg < 0)\r\nreturn use_sg;\r\nif (!use_sg)\r\ngoto sglist_finished;\r\ncurr_sg = cp->SG;\r\nchained = 0;\r\nsg_index = 0;\r\nscsi_for_each_sg(cmd, sg, use_sg, i) {\r\nif (i == h->max_cmd_sg_entries - 1 &&\r\nuse_sg > h->max_cmd_sg_entries) {\r\nchained = 1;\r\ncurr_sg = h->cmd_sg_list[cp->cmdindex];\r\nsg_index = 0;\r\n}\r\naddr64 = (u64) sg_dma_address(sg);\r\nlen = sg_dma_len(sg);\r\ncurr_sg->Addr.lower = (u32) (addr64 & 0x0FFFFFFFFULL);\r\ncurr_sg->Addr.upper = (u32) ((addr64 >> 32) & 0x0FFFFFFFFULL);\r\ncurr_sg->Len = len;\r\ncurr_sg->Ext = 0;\r\ncurr_sg++;\r\n}\r\nif (use_sg + chained > h->maxSG)\r\nh->maxSG = use_sg + chained;\r\nif (chained) {\r\ncp->Header.SGList = h->max_cmd_sg_entries;\r\ncp->Header.SGTotal = (u16) (use_sg + 1);\r\nif (hpsa_map_sg_chain_block(h, cp)) {\r\nscsi_dma_unmap(cmd);\r\nreturn -1;\r\n}\r\nreturn 0;\r\n}\r\nsglist_finished:\r\ncp->Header.SGList = (u8) use_sg;\r\ncp->Header.SGTotal = (u16) use_sg;\r\nreturn 0;\r\n}\r\nstatic int hpsa_scsi_queue_command_lck(struct scsi_cmnd *cmd,\r\nvoid (*done)(struct scsi_cmnd *))\r\n{\r\nstruct ctlr_info *h;\r\nstruct hpsa_scsi_dev_t *dev;\r\nunsigned char scsi3addr[8];\r\nstruct CommandList *c;\r\nunsigned long flags;\r\nh = sdev_to_hba(cmd->device);\r\ndev = cmd->device->hostdata;\r\nif (!dev) {\r\ncmd->result = DID_NO_CONNECT << 16;\r\ndone(cmd);\r\nreturn 0;\r\n}\r\nmemcpy(scsi3addr, dev->scsi3addr, sizeof(scsi3addr));\r\nspin_lock_irqsave(&h->lock, flags);\r\nif (unlikely(h->lockup_detected)) {\r\nspin_unlock_irqrestore(&h->lock, flags);\r\ncmd->result = DID_ERROR << 16;\r\ndone(cmd);\r\nreturn 0;\r\n}\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nc = cmd_alloc(h);\r\nif (c == NULL) {\r\ndev_err(&h->pdev->dev, "cmd_alloc returned NULL!\n");\r\nreturn SCSI_MLQUEUE_HOST_BUSY;\r\n}\r\ncmd->scsi_done = done;\r\ncmd->host_scribble = (unsigned char *) c;\r\nc->cmd_type = CMD_SCSI;\r\nc->scsi_cmd = cmd;\r\nc->Header.ReplyQueue = 0;\r\nmemcpy(&c->Header.LUN.LunAddrBytes[0], &scsi3addr[0], 8);\r\nc->Header.Tag.lower = (c->cmdindex << DIRECT_LOOKUP_SHIFT);\r\nc->Header.Tag.lower |= DIRECT_LOOKUP_BIT;\r\nc->Request.Timeout = 0;\r\nmemset(c->Request.CDB, 0, sizeof(c->Request.CDB));\r\nBUG_ON(cmd->cmd_len > sizeof(c->Request.CDB));\r\nc->Request.CDBLen = cmd->cmd_len;\r\nmemcpy(c->Request.CDB, cmd->cmnd, cmd->cmd_len);\r\nc->Request.Type.Type = TYPE_CMD;\r\nc->Request.Type.Attribute = ATTR_SIMPLE;\r\nswitch (cmd->sc_data_direction) {\r\ncase DMA_TO_DEVICE:\r\nc->Request.Type.Direction = XFER_WRITE;\r\nbreak;\r\ncase DMA_FROM_DEVICE:\r\nc->Request.Type.Direction = XFER_READ;\r\nbreak;\r\ncase DMA_NONE:\r\nc->Request.Type.Direction = XFER_NONE;\r\nbreak;\r\ncase DMA_BIDIRECTIONAL:\r\nc->Request.Type.Direction = XFER_RSVD;\r\nbreak;\r\ndefault:\r\ndev_err(&h->pdev->dev, "unknown data direction: %d\n",\r\ncmd->sc_data_direction);\r\nBUG();\r\nbreak;\r\n}\r\nif (hpsa_scatter_gather(h, c, cmd) < 0) {\r\ncmd_free(h, c);\r\nreturn SCSI_MLQUEUE_HOST_BUSY;\r\n}\r\nenqueue_cmd_and_start_io(h, c);\r\nreturn 0;\r\n}\r\nint hpsa_scan_finished(struct Scsi_Host *sh,\r\nunsigned long elapsed_time)\r\n{\r\nstruct ctlr_info *h = shost_to_hba(sh);\r\nunsigned long flags;\r\nint finished;\r\nspin_lock_irqsave(&h->scan_lock, flags);\r\nfinished = h->scan_finished;\r\nspin_unlock_irqrestore(&h->scan_lock, flags);\r\nreturn finished;\r\n}\r\nstatic int hpsa_change_queue_depth(struct scsi_device *sdev,\r\nint qdepth, int reason)\r\n{\r\nstruct ctlr_info *h = sdev_to_hba(sdev);\r\nif (reason != SCSI_QDEPTH_DEFAULT)\r\nreturn -ENOTSUPP;\r\nif (qdepth < 1)\r\nqdepth = 1;\r\nelse\r\nif (qdepth > h->nr_cmds)\r\nqdepth = h->nr_cmds;\r\nscsi_adjust_queue_depth(sdev, scsi_get_tag_type(sdev), qdepth);\r\nreturn sdev->queue_depth;\r\n}\r\nstatic void hpsa_unregister_scsi(struct ctlr_info *h)\r\n{\r\nscsi_remove_host(h->scsi_host);\r\nscsi_host_put(h->scsi_host);\r\nh->scsi_host = NULL;\r\n}\r\nstatic int hpsa_register_scsi(struct ctlr_info *h)\r\n{\r\nstruct Scsi_Host *sh;\r\nint error;\r\nsh = scsi_host_alloc(&hpsa_driver_template, sizeof(h));\r\nif (sh == NULL)\r\ngoto fail;\r\nsh->io_port = 0;\r\nsh->n_io_port = 0;\r\nsh->this_id = -1;\r\nsh->max_channel = 3;\r\nsh->max_cmd_len = MAX_COMMAND_SIZE;\r\nsh->max_lun = HPSA_MAX_LUN;\r\nsh->max_id = HPSA_MAX_LUN;\r\nsh->can_queue = h->nr_cmds;\r\nsh->cmd_per_lun = h->nr_cmds;\r\nsh->sg_tablesize = h->maxsgentries;\r\nh->scsi_host = sh;\r\nsh->hostdata[0] = (unsigned long) h;\r\nsh->irq = h->intr[h->intr_mode];\r\nsh->unique_id = sh->irq;\r\nerror = scsi_add_host(sh, &h->pdev->dev);\r\nif (error)\r\ngoto fail_host_put;\r\nscsi_scan_host(sh);\r\nreturn 0;\r\nfail_host_put:\r\ndev_err(&h->pdev->dev, "%s: scsi_add_host"\r\n" failed for controller %d\n", __func__, h->ctlr);\r\nscsi_host_put(sh);\r\nreturn error;\r\nfail:\r\ndev_err(&h->pdev->dev, "%s: scsi_host_alloc"\r\n" failed for controller %d\n", __func__, h->ctlr);\r\nreturn -ENOMEM;\r\n}\r\nstatic int wait_for_device_to_become_ready(struct ctlr_info *h,\r\nunsigned char lunaddr[])\r\n{\r\nint rc = 0;\r\nint count = 0;\r\nint waittime = 1;\r\nstruct CommandList *c;\r\nc = cmd_special_alloc(h);\r\nif (!c) {\r\ndev_warn(&h->pdev->dev, "out of memory in "\r\n"wait_for_device_to_become_ready.\n");\r\nreturn IO_ERROR;\r\n}\r\nwhile (count < HPSA_TUR_RETRY_LIMIT) {\r\nmsleep(1000 * waittime);\r\ncount++;\r\nif (waittime < HPSA_MAX_WAIT_INTERVAL_SECS)\r\nwaittime = waittime * 2;\r\n(void) fill_cmd(c, TEST_UNIT_READY, h,\r\nNULL, 0, 0, lunaddr, TYPE_CMD);\r\nhpsa_scsi_do_simple_cmd_core(h, c);\r\nif (c->err_info->CommandStatus == CMD_SUCCESS)\r\nbreak;\r\nif (c->err_info->CommandStatus == CMD_TARGET_STATUS &&\r\nc->err_info->ScsiStatus == SAM_STAT_CHECK_CONDITION &&\r\n(c->err_info->SenseInfo[2] == NO_SENSE ||\r\nc->err_info->SenseInfo[2] == UNIT_ATTENTION))\r\nbreak;\r\ndev_warn(&h->pdev->dev, "waiting %d secs "\r\n"for device to become ready.\n", waittime);\r\nrc = 1;\r\n}\r\nif (rc)\r\ndev_warn(&h->pdev->dev, "giving up on device.\n");\r\nelse\r\ndev_warn(&h->pdev->dev, "device is ready.\n");\r\ncmd_special_free(h, c);\r\nreturn rc;\r\n}\r\nstatic int hpsa_eh_device_reset_handler(struct scsi_cmnd *scsicmd)\r\n{\r\nint rc;\r\nstruct ctlr_info *h;\r\nstruct hpsa_scsi_dev_t *dev;\r\nh = sdev_to_hba(scsicmd->device);\r\nif (h == NULL)\r\nreturn FAILED;\r\ndev = scsicmd->device->hostdata;\r\nif (!dev) {\r\ndev_err(&h->pdev->dev, "hpsa_eh_device_reset_handler: "\r\n"device lookup failed.\n");\r\nreturn FAILED;\r\n}\r\ndev_warn(&h->pdev->dev, "resetting device %d:%d:%d:%d\n",\r\nh->scsi_host->host_no, dev->bus, dev->target, dev->lun);\r\nrc = hpsa_send_reset(h, dev->scsi3addr);\r\nif (rc == 0 && wait_for_device_to_become_ready(h, dev->scsi3addr) == 0)\r\nreturn SUCCESS;\r\ndev_warn(&h->pdev->dev, "resetting device failed.\n");\r\nreturn FAILED;\r\n}\r\nstatic void swizzle_abort_tag(u8 *tag)\r\n{\r\nu8 original_tag[8];\r\nmemcpy(original_tag, tag, 8);\r\ntag[0] = original_tag[3];\r\ntag[1] = original_tag[2];\r\ntag[2] = original_tag[1];\r\ntag[3] = original_tag[0];\r\ntag[4] = original_tag[7];\r\ntag[5] = original_tag[6];\r\ntag[6] = original_tag[5];\r\ntag[7] = original_tag[4];\r\n}\r\nstatic int hpsa_send_abort(struct ctlr_info *h, unsigned char *scsi3addr,\r\nstruct CommandList *abort, int swizzle)\r\n{\r\nint rc = IO_OK;\r\nstruct CommandList *c;\r\nstruct ErrorInfo *ei;\r\nc = cmd_special_alloc(h);\r\nif (c == NULL) {\r\ndev_warn(&h->pdev->dev, "cmd_special_alloc returned NULL!\n");\r\nreturn -ENOMEM;\r\n}\r\n(void) fill_cmd(c, HPSA_ABORT_MSG, h, abort,\r\n0, 0, scsi3addr, TYPE_MSG);\r\nif (swizzle)\r\nswizzle_abort_tag(&c->Request.CDB[4]);\r\nhpsa_scsi_do_simple_cmd_core(h, c);\r\ndev_dbg(&h->pdev->dev, "%s: Tag:0x%08x:%08x: do_simple_cmd_core completed.\n",\r\n__func__, abort->Header.Tag.upper, abort->Header.Tag.lower);\r\nei = c->err_info;\r\nswitch (ei->CommandStatus) {\r\ncase CMD_SUCCESS:\r\nbreak;\r\ncase CMD_UNABORTABLE:\r\nrc = -1;\r\nbreak;\r\ndefault:\r\ndev_dbg(&h->pdev->dev, "%s: Tag:0x%08x:%08x: interpreting error.\n",\r\n__func__, abort->Header.Tag.upper,\r\nabort->Header.Tag.lower);\r\nhpsa_scsi_interpret_error(c);\r\nrc = -1;\r\nbreak;\r\n}\r\ncmd_special_free(h, c);\r\ndev_dbg(&h->pdev->dev, "%s: Tag:0x%08x:%08x: Finished.\n", __func__,\r\nabort->Header.Tag.upper, abort->Header.Tag.lower);\r\nreturn rc;\r\n}\r\nstatic struct CommandList *hpsa_find_cmd_in_queue(struct ctlr_info *h,\r\nstruct scsi_cmnd *find, struct list_head *queue_head)\r\n{\r\nunsigned long flags;\r\nstruct CommandList *c = NULL;\r\nif (!find)\r\nreturn 0;\r\nspin_lock_irqsave(&h->lock, flags);\r\nlist_for_each_entry(c, queue_head, list) {\r\nif (c->scsi_cmd == NULL)\r\ncontinue;\r\nif (c->scsi_cmd == find) {\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nreturn c;\r\n}\r\n}\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nreturn NULL;\r\n}\r\nstatic struct CommandList *hpsa_find_cmd_in_queue_by_tag(struct ctlr_info *h,\r\nu8 *tag, struct list_head *queue_head)\r\n{\r\nunsigned long flags;\r\nstruct CommandList *c;\r\nspin_lock_irqsave(&h->lock, flags);\r\nlist_for_each_entry(c, queue_head, list) {\r\nif (memcmp(&c->Header.Tag, tag, 8) != 0)\r\ncontinue;\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nreturn c;\r\n}\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nreturn NULL;\r\n}\r\nstatic int hpsa_send_abort_both_ways(struct ctlr_info *h,\r\nunsigned char *scsi3addr, struct CommandList *abort)\r\n{\r\nu8 swizzled_tag[8];\r\nstruct CommandList *c;\r\nint rc = 0, rc2 = 0;\r\nmemcpy(swizzled_tag, &abort->Request.CDB[4], 8);\r\nswizzle_abort_tag(swizzled_tag);\r\nc = hpsa_find_cmd_in_queue_by_tag(h, swizzled_tag, &h->cmpQ);\r\nif (c != NULL) {\r\ndev_warn(&h->pdev->dev, "Unexpectedly found byte-swapped tag in completion queue.\n");\r\nreturn hpsa_send_abort(h, scsi3addr, abort, 0);\r\n}\r\nrc = hpsa_send_abort(h, scsi3addr, abort, 0);\r\nc = hpsa_find_cmd_in_queue(h, abort->scsi_cmd, &h->cmpQ);\r\nif (c)\r\nrc2 = hpsa_send_abort(h, scsi3addr, abort, 1);\r\nreturn rc && rc2;\r\n}\r\nstatic int hpsa_eh_abort_handler(struct scsi_cmnd *sc)\r\n{\r\nint i, rc;\r\nstruct ctlr_info *h;\r\nstruct hpsa_scsi_dev_t *dev;\r\nstruct CommandList *abort;\r\nstruct CommandList *found;\r\nstruct scsi_cmnd *as;\r\nchar msg[256];\r\nint ml = 0;\r\nh = sdev_to_hba(sc->device);\r\nif (WARN(h == NULL,\r\n"ABORT REQUEST FAILED, Controller lookup failed.\n"))\r\nreturn FAILED;\r\nif (!(HPSATMF_PHYS_TASK_ABORT & h->TMFSupportFlags) &&\r\n!(HPSATMF_LOG_TASK_ABORT & h->TMFSupportFlags))\r\nreturn FAILED;\r\nmemset(msg, 0, sizeof(msg));\r\nml += sprintf(msg+ml, "ABORT REQUEST on C%d:B%d:T%d:L%d ",\r\nh->scsi_host->host_no, sc->device->channel,\r\nsc->device->id, sc->device->lun);\r\ndev = sc->device->hostdata;\r\nif (!dev) {\r\ndev_err(&h->pdev->dev, "%s FAILED, Device lookup failed.\n",\r\nmsg);\r\nreturn FAILED;\r\n}\r\nabort = (struct CommandList *) sc->host_scribble;\r\nif (abort == NULL) {\r\ndev_err(&h->pdev->dev, "%s FAILED, Command to abort is NULL.\n",\r\nmsg);\r\nreturn FAILED;\r\n}\r\nml += sprintf(msg+ml, "Tag:0x%08x:%08x ",\r\nabort->Header.Tag.upper, abort->Header.Tag.lower);\r\nas = (struct scsi_cmnd *) abort->scsi_cmd;\r\nif (as != NULL)\r\nml += sprintf(msg+ml, "Command:0x%x SN:0x%lx ",\r\nas->cmnd[0], as->serial_number);\r\ndev_dbg(&h->pdev->dev, "%s\n", msg);\r\ndev_warn(&h->pdev->dev, "Abort request on C%d:B%d:T%d:L%d\n",\r\nh->scsi_host->host_no, dev->bus, dev->target, dev->lun);\r\nfound = hpsa_find_cmd_in_queue(h, sc, &h->reqQ);\r\nif (found) {\r\nfound->err_info->CommandStatus = CMD_ABORTED;\r\nfinish_cmd(found);\r\ndev_info(&h->pdev->dev, "%s Request SUCCEEDED (driver queue).\n",\r\nmsg);\r\nreturn SUCCESS;\r\n}\r\nfound = hpsa_find_cmd_in_queue(h, sc, &h->cmpQ);\r\nif (!found) {\r\ndev_dbg(&h->pdev->dev, "%s Request SUCCEEDED (not known to driver).\n",\r\nmsg);\r\nreturn SUCCESS;\r\n}\r\nrc = hpsa_send_abort_both_ways(h, dev->scsi3addr, abort);\r\nif (rc != 0) {\r\ndev_dbg(&h->pdev->dev, "%s Request FAILED.\n", msg);\r\ndev_warn(&h->pdev->dev, "FAILED abort on device C%d:B%d:T%d:L%d\n",\r\nh->scsi_host->host_no,\r\ndev->bus, dev->target, dev->lun);\r\nreturn FAILED;\r\n}\r\ndev_info(&h->pdev->dev, "%s REQUEST SUCCEEDED.\n", msg);\r\n#define ABORT_COMPLETE_WAIT_SECS 30\r\nfor (i = 0; i < ABORT_COMPLETE_WAIT_SECS * 10; i++) {\r\nfound = hpsa_find_cmd_in_queue(h, sc, &h->cmpQ);\r\nif (!found)\r\nreturn SUCCESS;\r\nmsleep(100);\r\n}\r\ndev_warn(&h->pdev->dev, "%s FAILED. Aborted command has not completed after %d seconds.\n",\r\nmsg, ABORT_COMPLETE_WAIT_SECS);\r\nreturn FAILED;\r\n}\r\nstatic struct CommandList *cmd_alloc(struct ctlr_info *h)\r\n{\r\nstruct CommandList *c;\r\nint i;\r\nunion u64bit temp64;\r\ndma_addr_t cmd_dma_handle, err_dma_handle;\r\nunsigned long flags;\r\nspin_lock_irqsave(&h->lock, flags);\r\ndo {\r\ni = find_first_zero_bit(h->cmd_pool_bits, h->nr_cmds);\r\nif (i == h->nr_cmds) {\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nreturn NULL;\r\n}\r\n} while (test_and_set_bit\r\n(i & (BITS_PER_LONG - 1),\r\nh->cmd_pool_bits + (i / BITS_PER_LONG)) != 0);\r\nh->nr_allocs++;\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nc = h->cmd_pool + i;\r\nmemset(c, 0, sizeof(*c));\r\ncmd_dma_handle = h->cmd_pool_dhandle\r\n+ i * sizeof(*c);\r\nc->err_info = h->errinfo_pool + i;\r\nmemset(c->err_info, 0, sizeof(*c->err_info));\r\nerr_dma_handle = h->errinfo_pool_dhandle\r\n+ i * sizeof(*c->err_info);\r\nc->cmdindex = i;\r\nINIT_LIST_HEAD(&c->list);\r\nc->busaddr = (u32) cmd_dma_handle;\r\ntemp64.val = (u64) err_dma_handle;\r\nc->ErrDesc.Addr.lower = temp64.val32.lower;\r\nc->ErrDesc.Addr.upper = temp64.val32.upper;\r\nc->ErrDesc.Len = sizeof(*c->err_info);\r\nc->h = h;\r\nreturn c;\r\n}\r\nstatic struct CommandList *cmd_special_alloc(struct ctlr_info *h)\r\n{\r\nstruct CommandList *c;\r\nunion u64bit temp64;\r\ndma_addr_t cmd_dma_handle, err_dma_handle;\r\nc = pci_alloc_consistent(h->pdev, sizeof(*c), &cmd_dma_handle);\r\nif (c == NULL)\r\nreturn NULL;\r\nmemset(c, 0, sizeof(*c));\r\nc->cmdindex = -1;\r\nc->err_info = pci_alloc_consistent(h->pdev, sizeof(*c->err_info),\r\n&err_dma_handle);\r\nif (c->err_info == NULL) {\r\npci_free_consistent(h->pdev,\r\nsizeof(*c), c, cmd_dma_handle);\r\nreturn NULL;\r\n}\r\nmemset(c->err_info, 0, sizeof(*c->err_info));\r\nINIT_LIST_HEAD(&c->list);\r\nc->busaddr = (u32) cmd_dma_handle;\r\ntemp64.val = (u64) err_dma_handle;\r\nc->ErrDesc.Addr.lower = temp64.val32.lower;\r\nc->ErrDesc.Addr.upper = temp64.val32.upper;\r\nc->ErrDesc.Len = sizeof(*c->err_info);\r\nc->h = h;\r\nreturn c;\r\n}\r\nstatic void cmd_free(struct ctlr_info *h, struct CommandList *c)\r\n{\r\nint i;\r\nunsigned long flags;\r\ni = c - h->cmd_pool;\r\nspin_lock_irqsave(&h->lock, flags);\r\nclear_bit(i & (BITS_PER_LONG - 1),\r\nh->cmd_pool_bits + (i / BITS_PER_LONG));\r\nh->nr_frees++;\r\nspin_unlock_irqrestore(&h->lock, flags);\r\n}\r\nstatic void cmd_special_free(struct ctlr_info *h, struct CommandList *c)\r\n{\r\nunion u64bit temp64;\r\ntemp64.val32.lower = c->ErrDesc.Addr.lower;\r\ntemp64.val32.upper = c->ErrDesc.Addr.upper;\r\npci_free_consistent(h->pdev, sizeof(*c->err_info),\r\nc->err_info, (dma_addr_t) temp64.val);\r\npci_free_consistent(h->pdev, sizeof(*c),\r\nc, (dma_addr_t) (c->busaddr & DIRECT_LOOKUP_MASK));\r\n}\r\nstatic int hpsa_ioctl32_passthru(struct scsi_device *dev, int cmd, void *arg)\r\n{\r\nIOCTL32_Command_struct __user *arg32 =\r\n(IOCTL32_Command_struct __user *) arg;\r\nIOCTL_Command_struct arg64;\r\nIOCTL_Command_struct __user *p = compat_alloc_user_space(sizeof(arg64));\r\nint err;\r\nu32 cp;\r\nmemset(&arg64, 0, sizeof(arg64));\r\nerr = 0;\r\nerr |= copy_from_user(&arg64.LUN_info, &arg32->LUN_info,\r\nsizeof(arg64.LUN_info));\r\nerr |= copy_from_user(&arg64.Request, &arg32->Request,\r\nsizeof(arg64.Request));\r\nerr |= copy_from_user(&arg64.error_info, &arg32->error_info,\r\nsizeof(arg64.error_info));\r\nerr |= get_user(arg64.buf_size, &arg32->buf_size);\r\nerr |= get_user(cp, &arg32->buf);\r\narg64.buf = compat_ptr(cp);\r\nerr |= copy_to_user(p, &arg64, sizeof(arg64));\r\nif (err)\r\nreturn -EFAULT;\r\nerr = hpsa_ioctl(dev, CCISS_PASSTHRU, (void *)p);\r\nif (err)\r\nreturn err;\r\nerr |= copy_in_user(&arg32->error_info, &p->error_info,\r\nsizeof(arg32->error_info));\r\nif (err)\r\nreturn -EFAULT;\r\nreturn err;\r\n}\r\nstatic int hpsa_ioctl32_big_passthru(struct scsi_device *dev,\r\nint cmd, void *arg)\r\n{\r\nBIG_IOCTL32_Command_struct __user *arg32 =\r\n(BIG_IOCTL32_Command_struct __user *) arg;\r\nBIG_IOCTL_Command_struct arg64;\r\nBIG_IOCTL_Command_struct __user *p =\r\ncompat_alloc_user_space(sizeof(arg64));\r\nint err;\r\nu32 cp;\r\nmemset(&arg64, 0, sizeof(arg64));\r\nerr = 0;\r\nerr |= copy_from_user(&arg64.LUN_info, &arg32->LUN_info,\r\nsizeof(arg64.LUN_info));\r\nerr |= copy_from_user(&arg64.Request, &arg32->Request,\r\nsizeof(arg64.Request));\r\nerr |= copy_from_user(&arg64.error_info, &arg32->error_info,\r\nsizeof(arg64.error_info));\r\nerr |= get_user(arg64.buf_size, &arg32->buf_size);\r\nerr |= get_user(arg64.malloc_size, &arg32->malloc_size);\r\nerr |= get_user(cp, &arg32->buf);\r\narg64.buf = compat_ptr(cp);\r\nerr |= copy_to_user(p, &arg64, sizeof(arg64));\r\nif (err)\r\nreturn -EFAULT;\r\nerr = hpsa_ioctl(dev, CCISS_BIG_PASSTHRU, (void *)p);\r\nif (err)\r\nreturn err;\r\nerr |= copy_in_user(&arg32->error_info, &p->error_info,\r\nsizeof(arg32->error_info));\r\nif (err)\r\nreturn -EFAULT;\r\nreturn err;\r\n}\r\nstatic int hpsa_compat_ioctl(struct scsi_device *dev, int cmd, void *arg)\r\n{\r\nswitch (cmd) {\r\ncase CCISS_GETPCIINFO:\r\ncase CCISS_GETINTINFO:\r\ncase CCISS_SETINTINFO:\r\ncase CCISS_GETNODENAME:\r\ncase CCISS_SETNODENAME:\r\ncase CCISS_GETHEARTBEAT:\r\ncase CCISS_GETBUSTYPES:\r\ncase CCISS_GETFIRMVER:\r\ncase CCISS_GETDRIVVER:\r\ncase CCISS_REVALIDVOLS:\r\ncase CCISS_DEREGDISK:\r\ncase CCISS_REGNEWDISK:\r\ncase CCISS_REGNEWD:\r\ncase CCISS_RESCANDISK:\r\ncase CCISS_GETLUNINFO:\r\nreturn hpsa_ioctl(dev, cmd, arg);\r\ncase CCISS_PASSTHRU32:\r\nreturn hpsa_ioctl32_passthru(dev, cmd, arg);\r\ncase CCISS_BIG_PASSTHRU32:\r\nreturn hpsa_ioctl32_big_passthru(dev, cmd, arg);\r\ndefault:\r\nreturn -ENOIOCTLCMD;\r\n}\r\n}\r\nstatic int hpsa_getpciinfo_ioctl(struct ctlr_info *h, void __user *argp)\r\n{\r\nstruct hpsa_pci_info pciinfo;\r\nif (!argp)\r\nreturn -EINVAL;\r\npciinfo.domain = pci_domain_nr(h->pdev->bus);\r\npciinfo.bus = h->pdev->bus->number;\r\npciinfo.dev_fn = h->pdev->devfn;\r\npciinfo.board_id = h->board_id;\r\nif (copy_to_user(argp, &pciinfo, sizeof(pciinfo)))\r\nreturn -EFAULT;\r\nreturn 0;\r\n}\r\nstatic int hpsa_getdrivver_ioctl(struct ctlr_info *h, void __user *argp)\r\n{\r\nDriverVer_type DriverVer;\r\nunsigned char vmaj, vmin, vsubmin;\r\nint rc;\r\nrc = sscanf(HPSA_DRIVER_VERSION, "%hhu.%hhu.%hhu",\r\n&vmaj, &vmin, &vsubmin);\r\nif (rc != 3) {\r\ndev_info(&h->pdev->dev, "driver version string '%s' "\r\n"unrecognized.", HPSA_DRIVER_VERSION);\r\nvmaj = 0;\r\nvmin = 0;\r\nvsubmin = 0;\r\n}\r\nDriverVer = (vmaj << 16) | (vmin << 8) | vsubmin;\r\nif (!argp)\r\nreturn -EINVAL;\r\nif (copy_to_user(argp, &DriverVer, sizeof(DriverVer_type)))\r\nreturn -EFAULT;\r\nreturn 0;\r\n}\r\nstatic int hpsa_passthru_ioctl(struct ctlr_info *h, void __user *argp)\r\n{\r\nIOCTL_Command_struct iocommand;\r\nstruct CommandList *c;\r\nchar *buff = NULL;\r\nunion u64bit temp64;\r\nint rc = 0;\r\nif (!argp)\r\nreturn -EINVAL;\r\nif (!capable(CAP_SYS_RAWIO))\r\nreturn -EPERM;\r\nif (copy_from_user(&iocommand, argp, sizeof(iocommand)))\r\nreturn -EFAULT;\r\nif ((iocommand.buf_size < 1) &&\r\n(iocommand.Request.Type.Direction != XFER_NONE)) {\r\nreturn -EINVAL;\r\n}\r\nif (iocommand.buf_size > 0) {\r\nbuff = kmalloc(iocommand.buf_size, GFP_KERNEL);\r\nif (buff == NULL)\r\nreturn -EFAULT;\r\nif (iocommand.Request.Type.Direction == XFER_WRITE) {\r\nif (copy_from_user(buff, iocommand.buf,\r\niocommand.buf_size)) {\r\nrc = -EFAULT;\r\ngoto out_kfree;\r\n}\r\n} else {\r\nmemset(buff, 0, iocommand.buf_size);\r\n}\r\n}\r\nc = cmd_special_alloc(h);\r\nif (c == NULL) {\r\nrc = -ENOMEM;\r\ngoto out_kfree;\r\n}\r\nc->cmd_type = CMD_IOCTL_PEND;\r\nc->Header.ReplyQueue = 0;\r\nif (iocommand.buf_size > 0) {\r\nc->Header.SGList = 1;\r\nc->Header.SGTotal = 1;\r\n} else {\r\nc->Header.SGList = 0;\r\nc->Header.SGTotal = 0;\r\n}\r\nmemcpy(&c->Header.LUN, &iocommand.LUN_info, sizeof(c->Header.LUN));\r\nc->Header.Tag.lower = c->busaddr;\r\nmemcpy(&c->Request, &iocommand.Request,\r\nsizeof(c->Request));\r\nif (iocommand.buf_size > 0) {\r\ntemp64.val = pci_map_single(h->pdev, buff,\r\niocommand.buf_size, PCI_DMA_BIDIRECTIONAL);\r\nif (dma_mapping_error(&h->pdev->dev, temp64.val)) {\r\nc->SG[0].Addr.lower = 0;\r\nc->SG[0].Addr.upper = 0;\r\nc->SG[0].Len = 0;\r\nrc = -ENOMEM;\r\ngoto out;\r\n}\r\nc->SG[0].Addr.lower = temp64.val32.lower;\r\nc->SG[0].Addr.upper = temp64.val32.upper;\r\nc->SG[0].Len = iocommand.buf_size;\r\nc->SG[0].Ext = 0;\r\n}\r\nhpsa_scsi_do_simple_cmd_core_if_no_lockup(h, c);\r\nif (iocommand.buf_size > 0)\r\nhpsa_pci_unmap(h->pdev, c, 1, PCI_DMA_BIDIRECTIONAL);\r\ncheck_ioctl_unit_attention(h, c);\r\nmemcpy(&iocommand.error_info, c->err_info,\r\nsizeof(iocommand.error_info));\r\nif (copy_to_user(argp, &iocommand, sizeof(iocommand))) {\r\nrc = -EFAULT;\r\ngoto out;\r\n}\r\nif (iocommand.Request.Type.Direction == XFER_READ &&\r\niocommand.buf_size > 0) {\r\nif (copy_to_user(iocommand.buf, buff, iocommand.buf_size)) {\r\nrc = -EFAULT;\r\ngoto out;\r\n}\r\n}\r\nout:\r\ncmd_special_free(h, c);\r\nout_kfree:\r\nkfree(buff);\r\nreturn rc;\r\n}\r\nstatic int hpsa_big_passthru_ioctl(struct ctlr_info *h, void __user *argp)\r\n{\r\nBIG_IOCTL_Command_struct *ioc;\r\nstruct CommandList *c;\r\nunsigned char **buff = NULL;\r\nint *buff_size = NULL;\r\nunion u64bit temp64;\r\nBYTE sg_used = 0;\r\nint status = 0;\r\nint i;\r\nu32 left;\r\nu32 sz;\r\nBYTE __user *data_ptr;\r\nif (!argp)\r\nreturn -EINVAL;\r\nif (!capable(CAP_SYS_RAWIO))\r\nreturn -EPERM;\r\nioc = (BIG_IOCTL_Command_struct *)\r\nkmalloc(sizeof(*ioc), GFP_KERNEL);\r\nif (!ioc) {\r\nstatus = -ENOMEM;\r\ngoto cleanup1;\r\n}\r\nif (copy_from_user(ioc, argp, sizeof(*ioc))) {\r\nstatus = -EFAULT;\r\ngoto cleanup1;\r\n}\r\nif ((ioc->buf_size < 1) &&\r\n(ioc->Request.Type.Direction != XFER_NONE)) {\r\nstatus = -EINVAL;\r\ngoto cleanup1;\r\n}\r\nif (ioc->malloc_size > MAX_KMALLOC_SIZE) {\r\nstatus = -EINVAL;\r\ngoto cleanup1;\r\n}\r\nif (ioc->buf_size > ioc->malloc_size * SG_ENTRIES_IN_CMD) {\r\nstatus = -EINVAL;\r\ngoto cleanup1;\r\n}\r\nbuff = kzalloc(SG_ENTRIES_IN_CMD * sizeof(char *), GFP_KERNEL);\r\nif (!buff) {\r\nstatus = -ENOMEM;\r\ngoto cleanup1;\r\n}\r\nbuff_size = kmalloc(SG_ENTRIES_IN_CMD * sizeof(int), GFP_KERNEL);\r\nif (!buff_size) {\r\nstatus = -ENOMEM;\r\ngoto cleanup1;\r\n}\r\nleft = ioc->buf_size;\r\ndata_ptr = ioc->buf;\r\nwhile (left) {\r\nsz = (left > ioc->malloc_size) ? ioc->malloc_size : left;\r\nbuff_size[sg_used] = sz;\r\nbuff[sg_used] = kmalloc(sz, GFP_KERNEL);\r\nif (buff[sg_used] == NULL) {\r\nstatus = -ENOMEM;\r\ngoto cleanup1;\r\n}\r\nif (ioc->Request.Type.Direction == XFER_WRITE) {\r\nif (copy_from_user(buff[sg_used], data_ptr, sz)) {\r\nstatus = -ENOMEM;\r\ngoto cleanup1;\r\n}\r\n} else\r\nmemset(buff[sg_used], 0, sz);\r\nleft -= sz;\r\ndata_ptr += sz;\r\nsg_used++;\r\n}\r\nc = cmd_special_alloc(h);\r\nif (c == NULL) {\r\nstatus = -ENOMEM;\r\ngoto cleanup1;\r\n}\r\nc->cmd_type = CMD_IOCTL_PEND;\r\nc->Header.ReplyQueue = 0;\r\nc->Header.SGList = c->Header.SGTotal = sg_used;\r\nmemcpy(&c->Header.LUN, &ioc->LUN_info, sizeof(c->Header.LUN));\r\nc->Header.Tag.lower = c->busaddr;\r\nmemcpy(&c->Request, &ioc->Request, sizeof(c->Request));\r\nif (ioc->buf_size > 0) {\r\nint i;\r\nfor (i = 0; i < sg_used; i++) {\r\ntemp64.val = pci_map_single(h->pdev, buff[i],\r\nbuff_size[i], PCI_DMA_BIDIRECTIONAL);\r\nif (dma_mapping_error(&h->pdev->dev, temp64.val)) {\r\nc->SG[i].Addr.lower = 0;\r\nc->SG[i].Addr.upper = 0;\r\nc->SG[i].Len = 0;\r\nhpsa_pci_unmap(h->pdev, c, i,\r\nPCI_DMA_BIDIRECTIONAL);\r\nstatus = -ENOMEM;\r\ngoto cleanup1;\r\n}\r\nc->SG[i].Addr.lower = temp64.val32.lower;\r\nc->SG[i].Addr.upper = temp64.val32.upper;\r\nc->SG[i].Len = buff_size[i];\r\nc->SG[i].Ext = 0;\r\n}\r\n}\r\nhpsa_scsi_do_simple_cmd_core_if_no_lockup(h, c);\r\nif (sg_used)\r\nhpsa_pci_unmap(h->pdev, c, sg_used, PCI_DMA_BIDIRECTIONAL);\r\ncheck_ioctl_unit_attention(h, c);\r\nmemcpy(&ioc->error_info, c->err_info, sizeof(ioc->error_info));\r\nif (copy_to_user(argp, ioc, sizeof(*ioc))) {\r\ncmd_special_free(h, c);\r\nstatus = -EFAULT;\r\ngoto cleanup1;\r\n}\r\nif (ioc->Request.Type.Direction == XFER_READ && ioc->buf_size > 0) {\r\nBYTE __user *ptr = ioc->buf;\r\nfor (i = 0; i < sg_used; i++) {\r\nif (copy_to_user(ptr, buff[i], buff_size[i])) {\r\ncmd_special_free(h, c);\r\nstatus = -EFAULT;\r\ngoto cleanup1;\r\n}\r\nptr += buff_size[i];\r\n}\r\n}\r\ncmd_special_free(h, c);\r\nstatus = 0;\r\ncleanup1:\r\nif (buff) {\r\nfor (i = 0; i < sg_used; i++)\r\nkfree(buff[i]);\r\nkfree(buff);\r\n}\r\nkfree(buff_size);\r\nkfree(ioc);\r\nreturn status;\r\n}\r\nstatic void check_ioctl_unit_attention(struct ctlr_info *h,\r\nstruct CommandList *c)\r\n{\r\nif (c->err_info->CommandStatus == CMD_TARGET_STATUS &&\r\nc->err_info->ScsiStatus != SAM_STAT_CHECK_CONDITION)\r\n(void) check_for_unit_attention(h, c);\r\n}\r\nstatic int hpsa_ioctl(struct scsi_device *dev, int cmd, void *arg)\r\n{\r\nstruct ctlr_info *h;\r\nvoid __user *argp = (void __user *)arg;\r\nh = sdev_to_hba(dev);\r\nswitch (cmd) {\r\ncase CCISS_DEREGDISK:\r\ncase CCISS_REGNEWDISK:\r\ncase CCISS_REGNEWD:\r\nhpsa_scan_start(h->scsi_host);\r\nreturn 0;\r\ncase CCISS_GETPCIINFO:\r\nreturn hpsa_getpciinfo_ioctl(h, argp);\r\ncase CCISS_GETDRIVVER:\r\nreturn hpsa_getdrivver_ioctl(h, argp);\r\ncase CCISS_PASSTHRU:\r\nreturn hpsa_passthru_ioctl(h, argp);\r\ncase CCISS_BIG_PASSTHRU:\r\nreturn hpsa_big_passthru_ioctl(h, argp);\r\ndefault:\r\nreturn -ENOTTY;\r\n}\r\n}\r\nstatic int hpsa_send_host_reset(struct ctlr_info *h, unsigned char *scsi3addr,\r\nu8 reset_type)\r\n{\r\nstruct CommandList *c;\r\nc = cmd_alloc(h);\r\nif (!c)\r\nreturn -ENOMEM;\r\n(void) fill_cmd(c, HPSA_DEVICE_RESET_MSG, h, NULL, 0, 0,\r\nRAID_CTLR_LUNID, TYPE_MSG);\r\nc->Request.CDB[1] = reset_type;\r\nc->waiting = NULL;\r\nenqueue_cmd_and_start_io(h, c);\r\nreturn 0;\r\n}\r\nstatic int fill_cmd(struct CommandList *c, u8 cmd, struct ctlr_info *h,\r\nvoid *buff, size_t size, u8 page_code, unsigned char *scsi3addr,\r\nint cmd_type)\r\n{\r\nint pci_dir = XFER_NONE;\r\nstruct CommandList *a;\r\nc->cmd_type = CMD_IOCTL_PEND;\r\nc->Header.ReplyQueue = 0;\r\nif (buff != NULL && size > 0) {\r\nc->Header.SGList = 1;\r\nc->Header.SGTotal = 1;\r\n} else {\r\nc->Header.SGList = 0;\r\nc->Header.SGTotal = 0;\r\n}\r\nc->Header.Tag.lower = c->busaddr;\r\nmemcpy(c->Header.LUN.LunAddrBytes, scsi3addr, 8);\r\nc->Request.Type.Type = cmd_type;\r\nif (cmd_type == TYPE_CMD) {\r\nswitch (cmd) {\r\ncase HPSA_INQUIRY:\r\nif (page_code != 0) {\r\nc->Request.CDB[1] = 0x01;\r\nc->Request.CDB[2] = page_code;\r\n}\r\nc->Request.CDBLen = 6;\r\nc->Request.Type.Attribute = ATTR_SIMPLE;\r\nc->Request.Type.Direction = XFER_READ;\r\nc->Request.Timeout = 0;\r\nc->Request.CDB[0] = HPSA_INQUIRY;\r\nc->Request.CDB[4] = size & 0xFF;\r\nbreak;\r\ncase HPSA_REPORT_LOG:\r\ncase HPSA_REPORT_PHYS:\r\nc->Request.CDBLen = 12;\r\nc->Request.Type.Attribute = ATTR_SIMPLE;\r\nc->Request.Type.Direction = XFER_READ;\r\nc->Request.Timeout = 0;\r\nc->Request.CDB[0] = cmd;\r\nc->Request.CDB[6] = (size >> 24) & 0xFF;\r\nc->Request.CDB[7] = (size >> 16) & 0xFF;\r\nc->Request.CDB[8] = (size >> 8) & 0xFF;\r\nc->Request.CDB[9] = size & 0xFF;\r\nbreak;\r\ncase HPSA_CACHE_FLUSH:\r\nc->Request.CDBLen = 12;\r\nc->Request.Type.Attribute = ATTR_SIMPLE;\r\nc->Request.Type.Direction = XFER_WRITE;\r\nc->Request.Timeout = 0;\r\nc->Request.CDB[0] = BMIC_WRITE;\r\nc->Request.CDB[6] = BMIC_CACHE_FLUSH;\r\nc->Request.CDB[7] = (size >> 8) & 0xFF;\r\nc->Request.CDB[8] = size & 0xFF;\r\nbreak;\r\ncase TEST_UNIT_READY:\r\nc->Request.CDBLen = 6;\r\nc->Request.Type.Attribute = ATTR_SIMPLE;\r\nc->Request.Type.Direction = XFER_NONE;\r\nc->Request.Timeout = 0;\r\nbreak;\r\ndefault:\r\ndev_warn(&h->pdev->dev, "unknown command 0x%c\n", cmd);\r\nBUG();\r\nreturn -1;\r\n}\r\n} else if (cmd_type == TYPE_MSG) {\r\nswitch (cmd) {\r\ncase HPSA_DEVICE_RESET_MSG:\r\nc->Request.CDBLen = 16;\r\nc->Request.Type.Type = 1;\r\nc->Request.Type.Attribute = ATTR_SIMPLE;\r\nc->Request.Type.Direction = XFER_NONE;\r\nc->Request.Timeout = 0;\r\nmemset(&c->Request.CDB[0], 0, sizeof(c->Request.CDB));\r\nc->Request.CDB[0] = cmd;\r\nc->Request.CDB[1] = HPSA_RESET_TYPE_LUN;\r\nc->Request.CDB[4] = 0x00;\r\nc->Request.CDB[5] = 0x00;\r\nc->Request.CDB[6] = 0x00;\r\nc->Request.CDB[7] = 0x00;\r\nbreak;\r\ncase HPSA_ABORT_MSG:\r\na = buff;\r\ndev_dbg(&h->pdev->dev, "Abort Tag:0x%08x:%08x using request Tag:0x%08x:%08x\n",\r\na->Header.Tag.upper, a->Header.Tag.lower,\r\nc->Header.Tag.upper, c->Header.Tag.lower);\r\nc->Request.CDBLen = 16;\r\nc->Request.Type.Type = TYPE_MSG;\r\nc->Request.Type.Attribute = ATTR_SIMPLE;\r\nc->Request.Type.Direction = XFER_WRITE;\r\nc->Request.Timeout = 0;\r\nc->Request.CDB[0] = HPSA_TASK_MANAGEMENT;\r\nc->Request.CDB[1] = HPSA_TMF_ABORT_TASK;\r\nc->Request.CDB[2] = 0x00;\r\nc->Request.CDB[3] = 0x00;\r\nc->Request.CDB[4] = a->Header.Tag.lower & 0xFF;\r\nc->Request.CDB[5] = (a->Header.Tag.lower >> 8) & 0xFF;\r\nc->Request.CDB[6] = (a->Header.Tag.lower >> 16) & 0xFF;\r\nc->Request.CDB[7] = (a->Header.Tag.lower >> 24) & 0xFF;\r\nc->Request.CDB[8] = a->Header.Tag.upper & 0xFF;\r\nc->Request.CDB[9] = (a->Header.Tag.upper >> 8) & 0xFF;\r\nc->Request.CDB[10] = (a->Header.Tag.upper >> 16) & 0xFF;\r\nc->Request.CDB[11] = (a->Header.Tag.upper >> 24) & 0xFF;\r\nc->Request.CDB[12] = 0x00;\r\nc->Request.CDB[13] = 0x00;\r\nc->Request.CDB[14] = 0x00;\r\nc->Request.CDB[15] = 0x00;\r\nbreak;\r\ndefault:\r\ndev_warn(&h->pdev->dev, "unknown message type %d\n",\r\ncmd);\r\nBUG();\r\n}\r\n} else {\r\ndev_warn(&h->pdev->dev, "unknown command type %d\n", cmd_type);\r\nBUG();\r\n}\r\nswitch (c->Request.Type.Direction) {\r\ncase XFER_READ:\r\npci_dir = PCI_DMA_FROMDEVICE;\r\nbreak;\r\ncase XFER_WRITE:\r\npci_dir = PCI_DMA_TODEVICE;\r\nbreak;\r\ncase XFER_NONE:\r\npci_dir = PCI_DMA_NONE;\r\nbreak;\r\ndefault:\r\npci_dir = PCI_DMA_BIDIRECTIONAL;\r\n}\r\nif (hpsa_map_one(h->pdev, c, buff, size, pci_dir))\r\nreturn -1;\r\nreturn 0;\r\n}\r\nstatic void __iomem *remap_pci_mem(ulong base, ulong size)\r\n{\r\nulong page_base = ((ulong) base) & PAGE_MASK;\r\nulong page_offs = ((ulong) base) - page_base;\r\nvoid __iomem *page_remapped = ioremap_nocache(page_base,\r\npage_offs + size);\r\nreturn page_remapped ? (page_remapped + page_offs) : NULL;\r\n}\r\nstatic void start_io(struct ctlr_info *h)\r\n{\r\nstruct CommandList *c;\r\nunsigned long flags;\r\nspin_lock_irqsave(&h->lock, flags);\r\nwhile (!list_empty(&h->reqQ)) {\r\nc = list_entry(h->reqQ.next, struct CommandList, list);\r\nif ((h->access.fifo_full(h))) {\r\ndev_warn(&h->pdev->dev, "fifo full\n");\r\nbreak;\r\n}\r\nremoveQ(c);\r\nh->Qdepth--;\r\naddQ(&h->cmpQ, c);\r\nh->commands_outstanding++;\r\nif (h->commands_outstanding > h->max_outstanding)\r\nh->max_outstanding = h->commands_outstanding;\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nh->access.submit_command(h, c);\r\nspin_lock_irqsave(&h->lock, flags);\r\n}\r\nspin_unlock_irqrestore(&h->lock, flags);\r\n}\r\nstatic inline unsigned long get_next_completion(struct ctlr_info *h, u8 q)\r\n{\r\nreturn h->access.command_completed(h, q);\r\n}\r\nstatic inline bool interrupt_pending(struct ctlr_info *h)\r\n{\r\nreturn h->access.intr_pending(h);\r\n}\r\nstatic inline long interrupt_not_for_us(struct ctlr_info *h)\r\n{\r\nreturn (h->access.intr_pending(h) == 0) ||\r\n(h->interrupts_enabled == 0);\r\n}\r\nstatic inline int bad_tag(struct ctlr_info *h, u32 tag_index,\r\nu32 raw_tag)\r\n{\r\nif (unlikely(tag_index >= h->nr_cmds)) {\r\ndev_warn(&h->pdev->dev, "bad tag 0x%08x ignored.\n", raw_tag);\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic inline void finish_cmd(struct CommandList *c)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&c->h->lock, flags);\r\nremoveQ(c);\r\nspin_unlock_irqrestore(&c->h->lock, flags);\r\ndial_up_lockup_detection_on_fw_flash_complete(c->h, c);\r\nif (likely(c->cmd_type == CMD_SCSI))\r\ncomplete_scsi_command(c);\r\nelse if (c->cmd_type == CMD_IOCTL_PEND)\r\ncomplete(c->waiting);\r\n}\r\nstatic inline u32 hpsa_tag_contains_index(u32 tag)\r\n{\r\nreturn tag & DIRECT_LOOKUP_BIT;\r\n}\r\nstatic inline u32 hpsa_tag_to_index(u32 tag)\r\n{\r\nreturn tag >> DIRECT_LOOKUP_SHIFT;\r\n}\r\nstatic inline u32 hpsa_tag_discard_error_bits(struct ctlr_info *h, u32 tag)\r\n{\r\n#define HPSA_PERF_ERROR_BITS ((1 << DIRECT_LOOKUP_SHIFT) - 1)\r\n#define HPSA_SIMPLE_ERROR_BITS 0x03\r\nif (unlikely(!(h->transMethod & CFGTBL_Trans_Performant)))\r\nreturn tag & ~HPSA_SIMPLE_ERROR_BITS;\r\nreturn tag & ~HPSA_PERF_ERROR_BITS;\r\n}\r\nstatic inline void process_indexed_cmd(struct ctlr_info *h,\r\nu32 raw_tag)\r\n{\r\nu32 tag_index;\r\nstruct CommandList *c;\r\ntag_index = hpsa_tag_to_index(raw_tag);\r\nif (!bad_tag(h, tag_index, raw_tag)) {\r\nc = h->cmd_pool + tag_index;\r\nfinish_cmd(c);\r\n}\r\n}\r\nstatic inline void process_nonindexed_cmd(struct ctlr_info *h,\r\nu32 raw_tag)\r\n{\r\nu32 tag;\r\nstruct CommandList *c = NULL;\r\nunsigned long flags;\r\ntag = hpsa_tag_discard_error_bits(h, raw_tag);\r\nspin_lock_irqsave(&h->lock, flags);\r\nlist_for_each_entry(c, &h->cmpQ, list) {\r\nif ((c->busaddr & 0xFFFFFFE0) == (tag & 0xFFFFFFE0)) {\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nfinish_cmd(c);\r\nreturn;\r\n}\r\n}\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nbad_tag(h, h->nr_cmds + 1, raw_tag);\r\n}\r\nstatic int ignore_bogus_interrupt(struct ctlr_info *h)\r\n{\r\nif (likely(!reset_devices))\r\nreturn 0;\r\nif (likely(h->interrupts_enabled))\r\nreturn 0;\r\ndev_info(&h->pdev->dev, "Received interrupt while interrupts disabled "\r\n"(known firmware bug.) Ignoring.\n");\r\nreturn 1;\r\n}\r\nstatic struct ctlr_info *queue_to_hba(u8 *queue)\r\n{\r\nreturn container_of((queue - *queue), struct ctlr_info, q[0]);\r\n}\r\nstatic irqreturn_t hpsa_intx_discard_completions(int irq, void *queue)\r\n{\r\nstruct ctlr_info *h = queue_to_hba(queue);\r\nu8 q = *(u8 *) queue;\r\nu32 raw_tag;\r\nif (ignore_bogus_interrupt(h))\r\nreturn IRQ_NONE;\r\nif (interrupt_not_for_us(h))\r\nreturn IRQ_NONE;\r\nh->last_intr_timestamp = get_jiffies_64();\r\nwhile (interrupt_pending(h)) {\r\nraw_tag = get_next_completion(h, q);\r\nwhile (raw_tag != FIFO_EMPTY)\r\nraw_tag = next_command(h, q);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t hpsa_msix_discard_completions(int irq, void *queue)\r\n{\r\nstruct ctlr_info *h = queue_to_hba(queue);\r\nu32 raw_tag;\r\nu8 q = *(u8 *) queue;\r\nif (ignore_bogus_interrupt(h))\r\nreturn IRQ_NONE;\r\nh->last_intr_timestamp = get_jiffies_64();\r\nraw_tag = get_next_completion(h, q);\r\nwhile (raw_tag != FIFO_EMPTY)\r\nraw_tag = next_command(h, q);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t do_hpsa_intr_intx(int irq, void *queue)\r\n{\r\nstruct ctlr_info *h = queue_to_hba((u8 *) queue);\r\nu32 raw_tag;\r\nu8 q = *(u8 *) queue;\r\nif (interrupt_not_for_us(h))\r\nreturn IRQ_NONE;\r\nh->last_intr_timestamp = get_jiffies_64();\r\nwhile (interrupt_pending(h)) {\r\nraw_tag = get_next_completion(h, q);\r\nwhile (raw_tag != FIFO_EMPTY) {\r\nif (likely(hpsa_tag_contains_index(raw_tag)))\r\nprocess_indexed_cmd(h, raw_tag);\r\nelse\r\nprocess_nonindexed_cmd(h, raw_tag);\r\nraw_tag = next_command(h, q);\r\n}\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t do_hpsa_intr_msi(int irq, void *queue)\r\n{\r\nstruct ctlr_info *h = queue_to_hba(queue);\r\nu32 raw_tag;\r\nu8 q = *(u8 *) queue;\r\nh->last_intr_timestamp = get_jiffies_64();\r\nraw_tag = get_next_completion(h, q);\r\nwhile (raw_tag != FIFO_EMPTY) {\r\nif (likely(hpsa_tag_contains_index(raw_tag)))\r\nprocess_indexed_cmd(h, raw_tag);\r\nelse\r\nprocess_nonindexed_cmd(h, raw_tag);\r\nraw_tag = next_command(h, q);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int hpsa_message(struct pci_dev *pdev, unsigned char opcode,\r\nunsigned char type)\r\n{\r\nstruct Command {\r\nstruct CommandListHeader CommandHeader;\r\nstruct RequestBlock Request;\r\nstruct ErrDescriptor ErrorDescriptor;\r\n};\r\nstruct Command *cmd;\r\nstatic const size_t cmd_sz = sizeof(*cmd) +\r\nsizeof(cmd->ErrorDescriptor);\r\ndma_addr_t paddr64;\r\nuint32_t paddr32, tag;\r\nvoid __iomem *vaddr;\r\nint i, err;\r\nvaddr = pci_ioremap_bar(pdev, 0);\r\nif (vaddr == NULL)\r\nreturn -ENOMEM;\r\nerr = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (err) {\r\niounmap(vaddr);\r\nreturn -ENOMEM;\r\n}\r\ncmd = pci_alloc_consistent(pdev, cmd_sz, &paddr64);\r\nif (cmd == NULL) {\r\niounmap(vaddr);\r\nreturn -ENOMEM;\r\n}\r\npaddr32 = paddr64;\r\ncmd->CommandHeader.ReplyQueue = 0;\r\ncmd->CommandHeader.SGList = 0;\r\ncmd->CommandHeader.SGTotal = 0;\r\ncmd->CommandHeader.Tag.lower = paddr32;\r\ncmd->CommandHeader.Tag.upper = 0;\r\nmemset(&cmd->CommandHeader.LUN.LunAddrBytes, 0, 8);\r\ncmd->Request.CDBLen = 16;\r\ncmd->Request.Type.Type = TYPE_MSG;\r\ncmd->Request.Type.Attribute = ATTR_HEADOFQUEUE;\r\ncmd->Request.Type.Direction = XFER_NONE;\r\ncmd->Request.Timeout = 0;\r\ncmd->Request.CDB[0] = opcode;\r\ncmd->Request.CDB[1] = type;\r\nmemset(&cmd->Request.CDB[2], 0, 14);\r\ncmd->ErrorDescriptor.Addr.lower = paddr32 + sizeof(*cmd);\r\ncmd->ErrorDescriptor.Addr.upper = 0;\r\ncmd->ErrorDescriptor.Len = sizeof(struct ErrorInfo);\r\nwritel(paddr32, vaddr + SA5_REQUEST_PORT_OFFSET);\r\nfor (i = 0; i < HPSA_MSG_SEND_RETRY_LIMIT; i++) {\r\ntag = readl(vaddr + SA5_REPLY_PORT_OFFSET);\r\nif ((tag & ~HPSA_SIMPLE_ERROR_BITS) == paddr32)\r\nbreak;\r\nmsleep(HPSA_MSG_SEND_RETRY_INTERVAL_MSECS);\r\n}\r\niounmap(vaddr);\r\nif (i == HPSA_MSG_SEND_RETRY_LIMIT) {\r\ndev_err(&pdev->dev, "controller message %02x:%02x timed out\n",\r\nopcode, type);\r\nreturn -ETIMEDOUT;\r\n}\r\npci_free_consistent(pdev, cmd_sz, cmd, paddr64);\r\nif (tag & HPSA_ERROR_BIT) {\r\ndev_err(&pdev->dev, "controller message %02x:%02x failed\n",\r\nopcode, type);\r\nreturn -EIO;\r\n}\r\ndev_info(&pdev->dev, "controller message %02x:%02x succeeded\n",\r\nopcode, type);\r\nreturn 0;\r\n}\r\nstatic int hpsa_controller_hard_reset(struct pci_dev *pdev,\r\nvoid * __iomem vaddr, u32 use_doorbell)\r\n{\r\nu16 pmcsr;\r\nint pos;\r\nif (use_doorbell) {\r\ndev_info(&pdev->dev, "using doorbell to reset controller\n");\r\nwritel(use_doorbell, vaddr + SA5_DOORBELL);\r\n} else {\r\npos = pci_find_capability(pdev, PCI_CAP_ID_PM);\r\nif (pos == 0) {\r\ndev_err(&pdev->dev,\r\n"hpsa_reset_controller: "\r\n"PCI PM not supported\n");\r\nreturn -ENODEV;\r\n}\r\ndev_info(&pdev->dev, "using PCI PM to reset controller\n");\r\npci_read_config_word(pdev, pos + PCI_PM_CTRL, &pmcsr);\r\npmcsr &= ~PCI_PM_CTRL_STATE_MASK;\r\npmcsr |= PCI_D3hot;\r\npci_write_config_word(pdev, pos + PCI_PM_CTRL, pmcsr);\r\nmsleep(500);\r\npmcsr &= ~PCI_PM_CTRL_STATE_MASK;\r\npmcsr |= PCI_D0;\r\npci_write_config_word(pdev, pos + PCI_PM_CTRL, pmcsr);\r\nmsleep(500);\r\n}\r\nreturn 0;\r\n}\r\nstatic void init_driver_version(char *driver_version, int len)\r\n{\r\nmemset(driver_version, 0, len);\r\nstrncpy(driver_version, HPSA " " HPSA_DRIVER_VERSION, len - 1);\r\n}\r\nstatic int write_driver_ver_to_cfgtable(struct CfgTable __iomem *cfgtable)\r\n{\r\nchar *driver_version;\r\nint i, size = sizeof(cfgtable->driver_version);\r\ndriver_version = kmalloc(size, GFP_KERNEL);\r\nif (!driver_version)\r\nreturn -ENOMEM;\r\ninit_driver_version(driver_version, size);\r\nfor (i = 0; i < size; i++)\r\nwriteb(driver_version[i], &cfgtable->driver_version[i]);\r\nkfree(driver_version);\r\nreturn 0;\r\n}\r\nstatic void read_driver_ver_from_cfgtable(struct CfgTable __iomem *cfgtable,\r\nunsigned char *driver_ver)\r\n{\r\nint i;\r\nfor (i = 0; i < sizeof(cfgtable->driver_version); i++)\r\ndriver_ver[i] = readb(&cfgtable->driver_version[i]);\r\n}\r\nstatic int controller_reset_failed(struct CfgTable __iomem *cfgtable)\r\n{\r\nchar *driver_ver, *old_driver_ver;\r\nint rc, size = sizeof(cfgtable->driver_version);\r\nold_driver_ver = kmalloc(2 * size, GFP_KERNEL);\r\nif (!old_driver_ver)\r\nreturn -ENOMEM;\r\ndriver_ver = old_driver_ver + size;\r\ninit_driver_version(old_driver_ver, size);\r\nread_driver_ver_from_cfgtable(cfgtable, driver_ver);\r\nrc = !memcmp(driver_ver, old_driver_ver, size);\r\nkfree(old_driver_ver);\r\nreturn rc;\r\n}\r\nstatic int hpsa_kdump_hard_reset_controller(struct pci_dev *pdev)\r\n{\r\nu64 cfg_offset;\r\nu32 cfg_base_addr;\r\nu64 cfg_base_addr_index;\r\nvoid __iomem *vaddr;\r\nunsigned long paddr;\r\nu32 misc_fw_support;\r\nint rc;\r\nstruct CfgTable __iomem *cfgtable;\r\nu32 use_doorbell;\r\nu32 board_id;\r\nu16 command_register;\r\nrc = hpsa_lookup_board_id(pdev, &board_id);\r\nif (rc < 0 || !ctlr_is_resettable(board_id)) {\r\ndev_warn(&pdev->dev, "Not resetting device.\n");\r\nreturn -ENODEV;\r\n}\r\nif (!ctlr_is_hard_resettable(board_id))\r\nreturn -ENOTSUPP;\r\npci_read_config_word(pdev, 4, &command_register);\r\npci_disable_device(pdev);\r\npci_save_state(pdev);\r\nrc = hpsa_pci_find_memory_BAR(pdev, &paddr);\r\nif (rc)\r\nreturn rc;\r\nvaddr = remap_pci_mem(paddr, 0x250);\r\nif (!vaddr)\r\nreturn -ENOMEM;\r\nrc = hpsa_find_cfg_addrs(pdev, vaddr, &cfg_base_addr,\r\n&cfg_base_addr_index, &cfg_offset);\r\nif (rc)\r\ngoto unmap_vaddr;\r\ncfgtable = remap_pci_mem(pci_resource_start(pdev,\r\ncfg_base_addr_index) + cfg_offset, sizeof(*cfgtable));\r\nif (!cfgtable) {\r\nrc = -ENOMEM;\r\ngoto unmap_vaddr;\r\n}\r\nrc = write_driver_ver_to_cfgtable(cfgtable);\r\nif (rc)\r\ngoto unmap_vaddr;\r\nmisc_fw_support = readl(&cfgtable->misc_fw_support);\r\nuse_doorbell = misc_fw_support & MISC_FW_DOORBELL_RESET2;\r\nif (use_doorbell) {\r\nuse_doorbell = DOORBELL_CTLR_RESET2;\r\n} else {\r\nuse_doorbell = misc_fw_support & MISC_FW_DOORBELL_RESET;\r\nif (use_doorbell) {\r\ndev_warn(&pdev->dev, "Soft reset not supported. "\r\n"Firmware update is required.\n");\r\nrc = -ENOTSUPP;\r\ngoto unmap_cfgtable;\r\n}\r\n}\r\nrc = hpsa_controller_hard_reset(pdev, vaddr, use_doorbell);\r\nif (rc)\r\ngoto unmap_cfgtable;\r\npci_restore_state(pdev);\r\nrc = pci_enable_device(pdev);\r\nif (rc) {\r\ndev_warn(&pdev->dev, "failed to enable device.\n");\r\ngoto unmap_cfgtable;\r\n}\r\npci_write_config_word(pdev, 4, command_register);\r\nmsleep(HPSA_POST_RESET_PAUSE_MSECS);\r\ndev_info(&pdev->dev, "Waiting for board to reset.\n");\r\nrc = hpsa_wait_for_board_state(pdev, vaddr, BOARD_NOT_READY);\r\nif (rc) {\r\ndev_warn(&pdev->dev,\r\n"failed waiting for board to reset."\r\n" Will try soft reset.\n");\r\nrc = -ENOTSUPP;\r\ngoto unmap_cfgtable;\r\n}\r\nrc = hpsa_wait_for_board_state(pdev, vaddr, BOARD_READY);\r\nif (rc) {\r\ndev_warn(&pdev->dev,\r\n"failed waiting for board to become ready "\r\n"after hard reset\n");\r\ngoto unmap_cfgtable;\r\n}\r\nrc = controller_reset_failed(vaddr);\r\nif (rc < 0)\r\ngoto unmap_cfgtable;\r\nif (rc) {\r\ndev_warn(&pdev->dev, "Unable to successfully reset "\r\n"controller. Will try soft reset.\n");\r\nrc = -ENOTSUPP;\r\n} else {\r\ndev_info(&pdev->dev, "board ready after hard reset.\n");\r\n}\r\nunmap_cfgtable:\r\niounmap(cfgtable);\r\nunmap_vaddr:\r\niounmap(vaddr);\r\nreturn rc;\r\n}\r\nstatic void print_cfg_table(struct device *dev, struct CfgTable *tb)\r\n{\r\n#ifdef HPSA_DEBUG\r\nint i;\r\nchar temp_name[17];\r\ndev_info(dev, "Controller Configuration information\n");\r\ndev_info(dev, "------------------------------------\n");\r\nfor (i = 0; i < 4; i++)\r\ntemp_name[i] = readb(&(tb->Signature[i]));\r\ntemp_name[4] = '\0';\r\ndev_info(dev, " Signature = %s\n", temp_name);\r\ndev_info(dev, " Spec Number = %d\n", readl(&(tb->SpecValence)));\r\ndev_info(dev, " Transport methods supported = 0x%x\n",\r\nreadl(&(tb->TransportSupport)));\r\ndev_info(dev, " Transport methods active = 0x%x\n",\r\nreadl(&(tb->TransportActive)));\r\ndev_info(dev, " Requested transport Method = 0x%x\n",\r\nreadl(&(tb->HostWrite.TransportRequest)));\r\ndev_info(dev, " Coalesce Interrupt Delay = 0x%x\n",\r\nreadl(&(tb->HostWrite.CoalIntDelay)));\r\ndev_info(dev, " Coalesce Interrupt Count = 0x%x\n",\r\nreadl(&(tb->HostWrite.CoalIntCount)));\r\ndev_info(dev, " Max outstanding commands = 0x%d\n",\r\nreadl(&(tb->CmdsOutMax)));\r\ndev_info(dev, " Bus Types = 0x%x\n", readl(&(tb->BusTypes)));\r\nfor (i = 0; i < 16; i++)\r\ntemp_name[i] = readb(&(tb->ServerName[i]));\r\ntemp_name[16] = '\0';\r\ndev_info(dev, " Server Name = %s\n", temp_name);\r\ndev_info(dev, " Heartbeat Counter = 0x%x\n\n\n",\r\nreadl(&(tb->HeartBeat)));\r\n#endif\r\n}\r\nstatic int find_PCI_BAR_index(struct pci_dev *pdev, unsigned long pci_bar_addr)\r\n{\r\nint i, offset, mem_type, bar_type;\r\nif (pci_bar_addr == PCI_BASE_ADDRESS_0)\r\nreturn 0;\r\noffset = 0;\r\nfor (i = 0; i < DEVICE_COUNT_RESOURCE; i++) {\r\nbar_type = pci_resource_flags(pdev, i) & PCI_BASE_ADDRESS_SPACE;\r\nif (bar_type == PCI_BASE_ADDRESS_SPACE_IO)\r\noffset += 4;\r\nelse {\r\nmem_type = pci_resource_flags(pdev, i) &\r\nPCI_BASE_ADDRESS_MEM_TYPE_MASK;\r\nswitch (mem_type) {\r\ncase PCI_BASE_ADDRESS_MEM_TYPE_32:\r\ncase PCI_BASE_ADDRESS_MEM_TYPE_1M:\r\noffset += 4;\r\nbreak;\r\ncase PCI_BASE_ADDRESS_MEM_TYPE_64:\r\noffset += 8;\r\nbreak;\r\ndefault:\r\ndev_warn(&pdev->dev,\r\n"base address is invalid\n");\r\nreturn -1;\r\nbreak;\r\n}\r\n}\r\nif (offset == pci_bar_addr - PCI_BASE_ADDRESS_0)\r\nreturn i + 1;\r\n}\r\nreturn -1;\r\n}\r\nstatic void hpsa_interrupt_mode(struct ctlr_info *h)\r\n{\r\n#ifdef CONFIG_PCI_MSI\r\nint err, i;\r\nstruct msix_entry hpsa_msix_entries[MAX_REPLY_QUEUES];\r\nfor (i = 0; i < MAX_REPLY_QUEUES; i++) {\r\nhpsa_msix_entries[i].vector = 0;\r\nhpsa_msix_entries[i].entry = i;\r\n}\r\nif ((h->board_id == 0x40700E11) || (h->board_id == 0x40800E11) ||\r\n(h->board_id == 0x40820E11) || (h->board_id == 0x40830E11))\r\ngoto default_int_mode;\r\nif (pci_find_capability(h->pdev, PCI_CAP_ID_MSIX)) {\r\ndev_info(&h->pdev->dev, "MSIX\n");\r\nerr = pci_enable_msix(h->pdev, hpsa_msix_entries,\r\nMAX_REPLY_QUEUES);\r\nif (!err) {\r\nfor (i = 0; i < MAX_REPLY_QUEUES; i++)\r\nh->intr[i] = hpsa_msix_entries[i].vector;\r\nh->msix_vector = 1;\r\nreturn;\r\n}\r\nif (err > 0) {\r\ndev_warn(&h->pdev->dev, "only %d MSI-X vectors "\r\n"available\n", err);\r\ngoto default_int_mode;\r\n} else {\r\ndev_warn(&h->pdev->dev, "MSI-X init failed %d\n",\r\nerr);\r\ngoto default_int_mode;\r\n}\r\n}\r\nif (pci_find_capability(h->pdev, PCI_CAP_ID_MSI)) {\r\ndev_info(&h->pdev->dev, "MSI\n");\r\nif (!pci_enable_msi(h->pdev))\r\nh->msi_vector = 1;\r\nelse\r\ndev_warn(&h->pdev->dev, "MSI init failed\n");\r\n}\r\ndefault_int_mode:\r\n#endif\r\nh->intr[h->intr_mode] = h->pdev->irq;\r\n}\r\nstatic int hpsa_lookup_board_id(struct pci_dev *pdev, u32 *board_id)\r\n{\r\nint i;\r\nu32 subsystem_vendor_id, subsystem_device_id;\r\nsubsystem_vendor_id = pdev->subsystem_vendor;\r\nsubsystem_device_id = pdev->subsystem_device;\r\n*board_id = ((subsystem_device_id << 16) & 0xffff0000) |\r\nsubsystem_vendor_id;\r\nfor (i = 0; i < ARRAY_SIZE(products); i++)\r\nif (*board_id == products[i].board_id)\r\nreturn i;\r\nif ((subsystem_vendor_id != PCI_VENDOR_ID_HP &&\r\nsubsystem_vendor_id != PCI_VENDOR_ID_COMPAQ) ||\r\n!hpsa_allow_any) {\r\ndev_warn(&pdev->dev, "unrecognized board ID: "\r\n"0x%08x, ignoring.\n", *board_id);\r\nreturn -ENODEV;\r\n}\r\nreturn ARRAY_SIZE(products) - 1;\r\n}\r\nstatic int hpsa_pci_find_memory_BAR(struct pci_dev *pdev,\r\nunsigned long *memory_bar)\r\n{\r\nint i;\r\nfor (i = 0; i < DEVICE_COUNT_RESOURCE; i++)\r\nif (pci_resource_flags(pdev, i) & IORESOURCE_MEM) {\r\n*memory_bar = pci_resource_start(pdev, i);\r\ndev_dbg(&pdev->dev, "memory BAR = %lx\n",\r\n*memory_bar);\r\nreturn 0;\r\n}\r\ndev_warn(&pdev->dev, "no memory BAR found\n");\r\nreturn -ENODEV;\r\n}\r\nstatic int hpsa_wait_for_board_state(struct pci_dev *pdev, void __iomem *vaddr,\r\nint wait_for_ready)\r\n{\r\nint i, iterations;\r\nu32 scratchpad;\r\nif (wait_for_ready)\r\niterations = HPSA_BOARD_READY_ITERATIONS;\r\nelse\r\niterations = HPSA_BOARD_NOT_READY_ITERATIONS;\r\nfor (i = 0; i < iterations; i++) {\r\nscratchpad = readl(vaddr + SA5_SCRATCHPAD_OFFSET);\r\nif (wait_for_ready) {\r\nif (scratchpad == HPSA_FIRMWARE_READY)\r\nreturn 0;\r\n} else {\r\nif (scratchpad != HPSA_FIRMWARE_READY)\r\nreturn 0;\r\n}\r\nmsleep(HPSA_BOARD_READY_POLL_INTERVAL_MSECS);\r\n}\r\ndev_warn(&pdev->dev, "board not ready, timed out.\n");\r\nreturn -ENODEV;\r\n}\r\nstatic int hpsa_find_cfg_addrs(struct pci_dev *pdev, void __iomem *vaddr,\r\nu32 *cfg_base_addr, u64 *cfg_base_addr_index,\r\nu64 *cfg_offset)\r\n{\r\n*cfg_base_addr = readl(vaddr + SA5_CTCFG_OFFSET);\r\n*cfg_offset = readl(vaddr + SA5_CTMEM_OFFSET);\r\n*cfg_base_addr &= (u32) 0x0000ffff;\r\n*cfg_base_addr_index = find_PCI_BAR_index(pdev, *cfg_base_addr);\r\nif (*cfg_base_addr_index == -1) {\r\ndev_warn(&pdev->dev, "cannot find cfg_base_addr_index\n");\r\nreturn -ENODEV;\r\n}\r\nreturn 0;\r\n}\r\nstatic int hpsa_find_cfgtables(struct ctlr_info *h)\r\n{\r\nu64 cfg_offset;\r\nu32 cfg_base_addr;\r\nu64 cfg_base_addr_index;\r\nu32 trans_offset;\r\nint rc;\r\nrc = hpsa_find_cfg_addrs(h->pdev, h->vaddr, &cfg_base_addr,\r\n&cfg_base_addr_index, &cfg_offset);\r\nif (rc)\r\nreturn rc;\r\nh->cfgtable = remap_pci_mem(pci_resource_start(h->pdev,\r\ncfg_base_addr_index) + cfg_offset, sizeof(*h->cfgtable));\r\nif (!h->cfgtable)\r\nreturn -ENOMEM;\r\nrc = write_driver_ver_to_cfgtable(h->cfgtable);\r\nif (rc)\r\nreturn rc;\r\ntrans_offset = readl(&h->cfgtable->TransMethodOffset);\r\nh->transtable = remap_pci_mem(pci_resource_start(h->pdev,\r\ncfg_base_addr_index)+cfg_offset+trans_offset,\r\nsizeof(*h->transtable));\r\nif (!h->transtable)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nstatic void hpsa_get_max_perf_mode_cmds(struct ctlr_info *h)\r\n{\r\nh->max_commands = readl(&(h->cfgtable->MaxPerformantModeCommands));\r\nif (reset_devices && h->max_commands > 32)\r\nh->max_commands = 32;\r\nif (h->max_commands < 16) {\r\ndev_warn(&h->pdev->dev, "Controller reports "\r\n"max supported commands of %d, an obvious lie. "\r\n"Using 16. Ensure that firmware is up to date.\n",\r\nh->max_commands);\r\nh->max_commands = 16;\r\n}\r\n}\r\nstatic void hpsa_find_board_params(struct ctlr_info *h)\r\n{\r\nhpsa_get_max_perf_mode_cmds(h);\r\nh->nr_cmds = h->max_commands - 4;\r\nh->maxsgentries = readl(&(h->cfgtable->MaxScatterGatherElements));\r\nh->max_cmd_sg_entries = 31;\r\nif (h->maxsgentries > 512) {\r\nh->max_cmd_sg_entries = 32;\r\nh->chainsize = h->maxsgentries - h->max_cmd_sg_entries + 1;\r\nh->maxsgentries--;\r\n} else {\r\nh->maxsgentries = 31;\r\nh->chainsize = 0;\r\n}\r\nh->TMFSupportFlags = readl(&(h->cfgtable->TMFSupportFlags));\r\n}\r\nstatic inline bool hpsa_CISS_signature_present(struct ctlr_info *h)\r\n{\r\nif (!check_signature(h->cfgtable->Signature, "CISS", 4)) {\r\ndev_warn(&h->pdev->dev, "not a valid CISS config table\n");\r\nreturn false;\r\n}\r\nreturn true;\r\n}\r\nstatic inline void hpsa_enable_scsi_prefetch(struct ctlr_info *h)\r\n{\r\n#ifdef CONFIG_X86\r\nu32 prefetch;\r\nprefetch = readl(&(h->cfgtable->SCSI_Prefetch));\r\nprefetch |= 0x100;\r\nwritel(prefetch, &(h->cfgtable->SCSI_Prefetch));\r\n#endif\r\n}\r\nstatic inline void hpsa_p600_dma_prefetch_quirk(struct ctlr_info *h)\r\n{\r\nu32 dma_prefetch;\r\nif (h->board_id != 0x3225103C)\r\nreturn;\r\ndma_prefetch = readl(h->vaddr + I2O_DMA1_CFG);\r\ndma_prefetch |= 0x8000;\r\nwritel(dma_prefetch, h->vaddr + I2O_DMA1_CFG);\r\n}\r\nstatic void hpsa_wait_for_mode_change_ack(struct ctlr_info *h)\r\n{\r\nint i;\r\nu32 doorbell_value;\r\nunsigned long flags;\r\nfor (i = 0; i < MAX_CONFIG_WAIT; i++) {\r\nspin_lock_irqsave(&h->lock, flags);\r\ndoorbell_value = readl(h->vaddr + SA5_DOORBELL);\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nif (!(doorbell_value & CFGTBL_ChangeReq))\r\nbreak;\r\nusleep_range(10000, 20000);\r\n}\r\n}\r\nstatic int hpsa_enter_simple_mode(struct ctlr_info *h)\r\n{\r\nu32 trans_support;\r\ntrans_support = readl(&(h->cfgtable->TransportSupport));\r\nif (!(trans_support & SIMPLE_MODE))\r\nreturn -ENOTSUPP;\r\nh->max_commands = readl(&(h->cfgtable->CmdsOutMax));\r\nwritel(CFGTBL_Trans_Simple, &(h->cfgtable->HostWrite.TransportRequest));\r\nwritel(CFGTBL_ChangeReq, h->vaddr + SA5_DOORBELL);\r\nhpsa_wait_for_mode_change_ack(h);\r\nprint_cfg_table(&h->pdev->dev, h->cfgtable);\r\nif (!(readl(&(h->cfgtable->TransportActive)) & CFGTBL_Trans_Simple)) {\r\ndev_warn(&h->pdev->dev,\r\n"unable to get board into simple mode\n");\r\nreturn -ENODEV;\r\n}\r\nh->transMethod = CFGTBL_Trans_Simple;\r\nreturn 0;\r\n}\r\nstatic int hpsa_pci_init(struct ctlr_info *h)\r\n{\r\nint prod_index, err;\r\nprod_index = hpsa_lookup_board_id(h->pdev, &h->board_id);\r\nif (prod_index < 0)\r\nreturn -ENODEV;\r\nh->product_name = products[prod_index].product_name;\r\nh->access = *(products[prod_index].access);\r\npci_disable_link_state(h->pdev, PCIE_LINK_STATE_L0S |\r\nPCIE_LINK_STATE_L1 | PCIE_LINK_STATE_CLKPM);\r\nerr = pci_enable_device(h->pdev);\r\nif (err) {\r\ndev_warn(&h->pdev->dev, "unable to enable PCI device\n");\r\nreturn err;\r\n}\r\npci_set_master(h->pdev);\r\nerr = pci_request_regions(h->pdev, HPSA);\r\nif (err) {\r\ndev_err(&h->pdev->dev,\r\n"cannot obtain PCI resources, aborting\n");\r\nreturn err;\r\n}\r\nhpsa_interrupt_mode(h);\r\nerr = hpsa_pci_find_memory_BAR(h->pdev, &h->paddr);\r\nif (err)\r\ngoto err_out_free_res;\r\nh->vaddr = remap_pci_mem(h->paddr, 0x250);\r\nif (!h->vaddr) {\r\nerr = -ENOMEM;\r\ngoto err_out_free_res;\r\n}\r\nerr = hpsa_wait_for_board_state(h->pdev, h->vaddr, BOARD_READY);\r\nif (err)\r\ngoto err_out_free_res;\r\nerr = hpsa_find_cfgtables(h);\r\nif (err)\r\ngoto err_out_free_res;\r\nhpsa_find_board_params(h);\r\nif (!hpsa_CISS_signature_present(h)) {\r\nerr = -ENODEV;\r\ngoto err_out_free_res;\r\n}\r\nhpsa_enable_scsi_prefetch(h);\r\nhpsa_p600_dma_prefetch_quirk(h);\r\nerr = hpsa_enter_simple_mode(h);\r\nif (err)\r\ngoto err_out_free_res;\r\nreturn 0;\r\nerr_out_free_res:\r\nif (h->transtable)\r\niounmap(h->transtable);\r\nif (h->cfgtable)\r\niounmap(h->cfgtable);\r\nif (h->vaddr)\r\niounmap(h->vaddr);\r\npci_disable_device(h->pdev);\r\npci_release_regions(h->pdev);\r\nreturn err;\r\n}\r\nstatic void hpsa_hba_inquiry(struct ctlr_info *h)\r\n{\r\nint rc;\r\n#define HBA_INQUIRY_BYTE_COUNT 64\r\nh->hba_inquiry_data = kmalloc(HBA_INQUIRY_BYTE_COUNT, GFP_KERNEL);\r\nif (!h->hba_inquiry_data)\r\nreturn;\r\nrc = hpsa_scsi_do_inquiry(h, RAID_CTLR_LUNID, 0,\r\nh->hba_inquiry_data, HBA_INQUIRY_BYTE_COUNT);\r\nif (rc != 0) {\r\nkfree(h->hba_inquiry_data);\r\nh->hba_inquiry_data = NULL;\r\n}\r\n}\r\nstatic int hpsa_init_reset_devices(struct pci_dev *pdev)\r\n{\r\nint rc, i;\r\nif (!reset_devices)\r\nreturn 0;\r\nrc = hpsa_kdump_hard_reset_controller(pdev);\r\nif (rc == -ENOTSUPP)\r\nreturn rc;\r\nif (rc)\r\nreturn -ENODEV;\r\ndev_warn(&pdev->dev, "Waiting for controller to respond to no-op\n");\r\nfor (i = 0; i < HPSA_POST_RESET_NOOP_RETRIES; i++) {\r\nif (hpsa_noop(pdev) == 0)\r\nbreak;\r\nelse\r\ndev_warn(&pdev->dev, "no-op failed%s\n",\r\n(i < 11 ? "; re-trying" : ""));\r\n}\r\nreturn 0;\r\n}\r\nstatic int hpsa_allocate_cmd_pool(struct ctlr_info *h)\r\n{\r\nh->cmd_pool_bits = kzalloc(\r\nDIV_ROUND_UP(h->nr_cmds, BITS_PER_LONG) *\r\nsizeof(unsigned long), GFP_KERNEL);\r\nh->cmd_pool = pci_alloc_consistent(h->pdev,\r\nh->nr_cmds * sizeof(*h->cmd_pool),\r\n&(h->cmd_pool_dhandle));\r\nh->errinfo_pool = pci_alloc_consistent(h->pdev,\r\nh->nr_cmds * sizeof(*h->errinfo_pool),\r\n&(h->errinfo_pool_dhandle));\r\nif ((h->cmd_pool_bits == NULL)\r\n|| (h->cmd_pool == NULL)\r\n|| (h->errinfo_pool == NULL)) {\r\ndev_err(&h->pdev->dev, "out of memory in %s", __func__);\r\nreturn -ENOMEM;\r\n}\r\nreturn 0;\r\n}\r\nstatic void hpsa_free_cmd_pool(struct ctlr_info *h)\r\n{\r\nkfree(h->cmd_pool_bits);\r\nif (h->cmd_pool)\r\npci_free_consistent(h->pdev,\r\nh->nr_cmds * sizeof(struct CommandList),\r\nh->cmd_pool, h->cmd_pool_dhandle);\r\nif (h->errinfo_pool)\r\npci_free_consistent(h->pdev,\r\nh->nr_cmds * sizeof(struct ErrorInfo),\r\nh->errinfo_pool,\r\nh->errinfo_pool_dhandle);\r\n}\r\nstatic int hpsa_request_irq(struct ctlr_info *h,\r\nirqreturn_t (*msixhandler)(int, void *),\r\nirqreturn_t (*intxhandler)(int, void *))\r\n{\r\nint rc, i;\r\nfor (i = 0; i < MAX_REPLY_QUEUES; i++)\r\nh->q[i] = (u8) i;\r\nif (h->intr_mode == PERF_MODE_INT && h->msix_vector) {\r\nfor (i = 0; i < MAX_REPLY_QUEUES; i++)\r\nrc = request_irq(h->intr[i], msixhandler,\r\n0, h->devname,\r\n&h->q[i]);\r\n} else {\r\nif (h->msix_vector || h->msi_vector) {\r\nrc = request_irq(h->intr[h->intr_mode],\r\nmsixhandler, 0, h->devname,\r\n&h->q[h->intr_mode]);\r\n} else {\r\nrc = request_irq(h->intr[h->intr_mode],\r\nintxhandler, IRQF_SHARED, h->devname,\r\n&h->q[h->intr_mode]);\r\n}\r\n}\r\nif (rc) {\r\ndev_err(&h->pdev->dev, "unable to get irq %d for %s\n",\r\nh->intr[h->intr_mode], h->devname);\r\nreturn -ENODEV;\r\n}\r\nreturn 0;\r\n}\r\nstatic int hpsa_kdump_soft_reset(struct ctlr_info *h)\r\n{\r\nif (hpsa_send_host_reset(h, RAID_CTLR_LUNID,\r\nHPSA_RESET_TYPE_CONTROLLER)) {\r\ndev_warn(&h->pdev->dev, "Resetting array controller failed.\n");\r\nreturn -EIO;\r\n}\r\ndev_info(&h->pdev->dev, "Waiting for board to soft reset.\n");\r\nif (hpsa_wait_for_board_state(h->pdev, h->vaddr, BOARD_NOT_READY)) {\r\ndev_warn(&h->pdev->dev, "Soft reset had no effect.\n");\r\nreturn -1;\r\n}\r\ndev_info(&h->pdev->dev, "Board reset, awaiting READY status.\n");\r\nif (hpsa_wait_for_board_state(h->pdev, h->vaddr, BOARD_READY)) {\r\ndev_warn(&h->pdev->dev, "Board failed to become ready "\r\n"after soft reset.\n");\r\nreturn -1;\r\n}\r\nreturn 0;\r\n}\r\nstatic void free_irqs(struct ctlr_info *h)\r\n{\r\nint i;\r\nif (!h->msix_vector || h->intr_mode != PERF_MODE_INT) {\r\ni = h->intr_mode;\r\nfree_irq(h->intr[i], &h->q[i]);\r\nreturn;\r\n}\r\nfor (i = 0; i < MAX_REPLY_QUEUES; i++)\r\nfree_irq(h->intr[i], &h->q[i]);\r\n}\r\nstatic void hpsa_free_irqs_and_disable_msix(struct ctlr_info *h)\r\n{\r\nfree_irqs(h);\r\n#ifdef CONFIG_PCI_MSI\r\nif (h->msix_vector) {\r\nif (h->pdev->msix_enabled)\r\npci_disable_msix(h->pdev);\r\n} else if (h->msi_vector) {\r\nif (h->pdev->msi_enabled)\r\npci_disable_msi(h->pdev);\r\n}\r\n#endif\r\n}\r\nstatic void hpsa_undo_allocations_after_kdump_soft_reset(struct ctlr_info *h)\r\n{\r\nhpsa_free_irqs_and_disable_msix(h);\r\nhpsa_free_sg_chain_blocks(h);\r\nhpsa_free_cmd_pool(h);\r\nkfree(h->blockFetchTable);\r\npci_free_consistent(h->pdev, h->reply_pool_size,\r\nh->reply_pool, h->reply_pool_dhandle);\r\nif (h->vaddr)\r\niounmap(h->vaddr);\r\nif (h->transtable)\r\niounmap(h->transtable);\r\nif (h->cfgtable)\r\niounmap(h->cfgtable);\r\npci_release_regions(h->pdev);\r\nkfree(h);\r\n}\r\nstatic void remove_ctlr_from_lockup_detector_list(struct ctlr_info *h)\r\n{\r\nassert_spin_locked(&lockup_detector_lock);\r\nif (!hpsa_lockup_detector)\r\nreturn;\r\nif (h->lockup_detected)\r\nreturn;\r\nlist_del(&h->lockup_list);\r\n}\r\nstatic void fail_all_cmds_on_list(struct ctlr_info *h, struct list_head *list)\r\n{\r\nstruct CommandList *c = NULL;\r\nassert_spin_locked(&h->lock);\r\nwhile (!list_empty(list)) {\r\nc = list_entry(list->next, struct CommandList, list);\r\nc->err_info->CommandStatus = CMD_HARDWARE_ERR;\r\nfinish_cmd(c);\r\n}\r\n}\r\nstatic void controller_lockup_detected(struct ctlr_info *h)\r\n{\r\nunsigned long flags;\r\nassert_spin_locked(&lockup_detector_lock);\r\nremove_ctlr_from_lockup_detector_list(h);\r\nh->access.set_intr_mask(h, HPSA_INTR_OFF);\r\nspin_lock_irqsave(&h->lock, flags);\r\nh->lockup_detected = readl(h->vaddr + SA5_SCRATCHPAD_OFFSET);\r\nspin_unlock_irqrestore(&h->lock, flags);\r\ndev_warn(&h->pdev->dev, "Controller lockup detected: 0x%08x\n",\r\nh->lockup_detected);\r\npci_disable_device(h->pdev);\r\nspin_lock_irqsave(&h->lock, flags);\r\nfail_all_cmds_on_list(h, &h->cmpQ);\r\nfail_all_cmds_on_list(h, &h->reqQ);\r\nspin_unlock_irqrestore(&h->lock, flags);\r\n}\r\nstatic void detect_controller_lockup(struct ctlr_info *h)\r\n{\r\nu64 now;\r\nu32 heartbeat;\r\nunsigned long flags;\r\nassert_spin_locked(&lockup_detector_lock);\r\nnow = get_jiffies_64();\r\nif (time_after64(h->last_intr_timestamp +\r\n(h->heartbeat_sample_interval), now))\r\nreturn;\r\nif (time_after64(h->last_heartbeat_timestamp +\r\n(h->heartbeat_sample_interval), now))\r\nreturn;\r\nspin_lock_irqsave(&h->lock, flags);\r\nheartbeat = readl(&h->cfgtable->HeartBeat);\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nif (h->last_heartbeat == heartbeat) {\r\ncontroller_lockup_detected(h);\r\nreturn;\r\n}\r\nh->last_heartbeat = heartbeat;\r\nh->last_heartbeat_timestamp = now;\r\n}\r\nstatic int detect_controller_lockup_thread(void *notused)\r\n{\r\nstruct ctlr_info *h;\r\nunsigned long flags;\r\nwhile (1) {\r\nstruct list_head *this, *tmp;\r\nschedule_timeout_interruptible(HEARTBEAT_SAMPLE_INTERVAL);\r\nif (kthread_should_stop())\r\nbreak;\r\nspin_lock_irqsave(&lockup_detector_lock, flags);\r\nlist_for_each_safe(this, tmp, &hpsa_ctlr_list) {\r\nh = list_entry(this, struct ctlr_info, lockup_list);\r\ndetect_controller_lockup(h);\r\n}\r\nspin_unlock_irqrestore(&lockup_detector_lock, flags);\r\n}\r\nreturn 0;\r\n}\r\nstatic void add_ctlr_to_lockup_detector_list(struct ctlr_info *h)\r\n{\r\nunsigned long flags;\r\nh->heartbeat_sample_interval = HEARTBEAT_SAMPLE_INTERVAL;\r\nspin_lock_irqsave(&lockup_detector_lock, flags);\r\nlist_add_tail(&h->lockup_list, &hpsa_ctlr_list);\r\nspin_unlock_irqrestore(&lockup_detector_lock, flags);\r\n}\r\nstatic void start_controller_lockup_detector(struct ctlr_info *h)\r\n{\r\nif (!hpsa_lockup_detector) {\r\nspin_lock_init(&lockup_detector_lock);\r\nhpsa_lockup_detector =\r\nkthread_run(detect_controller_lockup_thread,\r\nNULL, HPSA);\r\n}\r\nif (!hpsa_lockup_detector) {\r\ndev_warn(&h->pdev->dev,\r\n"Could not start lockup detector thread\n");\r\nreturn;\r\n}\r\nadd_ctlr_to_lockup_detector_list(h);\r\n}\r\nstatic void stop_controller_lockup_detector(struct ctlr_info *h)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&lockup_detector_lock, flags);\r\nremove_ctlr_from_lockup_detector_list(h);\r\nif (list_empty(&hpsa_ctlr_list)) {\r\nspin_unlock_irqrestore(&lockup_detector_lock, flags);\r\nkthread_stop(hpsa_lockup_detector);\r\nspin_lock_irqsave(&lockup_detector_lock, flags);\r\nhpsa_lockup_detector = NULL;\r\n}\r\nspin_unlock_irqrestore(&lockup_detector_lock, flags);\r\n}\r\nstatic int hpsa_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)\r\n{\r\nint dac, rc;\r\nstruct ctlr_info *h;\r\nint try_soft_reset = 0;\r\nunsigned long flags;\r\nif (number_of_controllers == 0)\r\nprintk(KERN_INFO DRIVER_NAME "\n");\r\nrc = hpsa_init_reset_devices(pdev);\r\nif (rc) {\r\nif (rc != -ENOTSUPP)\r\nreturn rc;\r\ntry_soft_reset = 1;\r\nrc = 0;\r\n}\r\nreinit_after_soft_reset:\r\n#define COMMANDLIST_ALIGNMENT 32\r\nBUILD_BUG_ON(sizeof(struct CommandList) % COMMANDLIST_ALIGNMENT);\r\nh = kzalloc(sizeof(*h), GFP_KERNEL);\r\nif (!h)\r\nreturn -ENOMEM;\r\nh->pdev = pdev;\r\nh->intr_mode = hpsa_simple_mode ? SIMPLE_MODE_INT : PERF_MODE_INT;\r\nINIT_LIST_HEAD(&h->cmpQ);\r\nINIT_LIST_HEAD(&h->reqQ);\r\nspin_lock_init(&h->lock);\r\nspin_lock_init(&h->scan_lock);\r\nrc = hpsa_pci_init(h);\r\nif (rc != 0)\r\ngoto clean1;\r\nsprintf(h->devname, HPSA "%d", number_of_controllers);\r\nh->ctlr = number_of_controllers;\r\nnumber_of_controllers++;\r\nrc = pci_set_dma_mask(pdev, DMA_BIT_MASK(64));\r\nif (rc == 0) {\r\ndac = 1;\r\n} else {\r\nrc = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (rc == 0) {\r\ndac = 0;\r\n} else {\r\ndev_err(&pdev->dev, "no suitable DMA available\n");\r\ngoto clean1;\r\n}\r\n}\r\nh->access.set_intr_mask(h, HPSA_INTR_OFF);\r\nif (hpsa_request_irq(h, do_hpsa_intr_msi, do_hpsa_intr_intx))\r\ngoto clean2;\r\ndev_info(&pdev->dev, "%s: <0x%x> at IRQ %d%s using DAC\n",\r\nh->devname, pdev->device,\r\nh->intr[h->intr_mode], dac ? "" : " not");\r\nif (hpsa_allocate_cmd_pool(h))\r\ngoto clean4;\r\nif (hpsa_allocate_sg_chain_blocks(h))\r\ngoto clean4;\r\ninit_waitqueue_head(&h->scan_wait_queue);\r\nh->scan_finished = 1;\r\npci_set_drvdata(pdev, h);\r\nh->ndevices = 0;\r\nh->scsi_host = NULL;\r\nspin_lock_init(&h->devlock);\r\nhpsa_put_ctlr_into_performant_mode(h);\r\nif (try_soft_reset) {\r\nspin_lock_irqsave(&h->lock, flags);\r\nh->access.set_intr_mask(h, HPSA_INTR_OFF);\r\nspin_unlock_irqrestore(&h->lock, flags);\r\nfree_irqs(h);\r\nrc = hpsa_request_irq(h, hpsa_msix_discard_completions,\r\nhpsa_intx_discard_completions);\r\nif (rc) {\r\ndev_warn(&h->pdev->dev, "Failed to request_irq after "\r\n"soft reset.\n");\r\ngoto clean4;\r\n}\r\nrc = hpsa_kdump_soft_reset(h);\r\nif (rc)\r\ngoto clean4;\r\ndev_info(&h->pdev->dev, "Board READY.\n");\r\ndev_info(&h->pdev->dev,\r\n"Waiting for stale completions to drain.\n");\r\nh->access.set_intr_mask(h, HPSA_INTR_ON);\r\nmsleep(10000);\r\nh->access.set_intr_mask(h, HPSA_INTR_OFF);\r\nrc = controller_reset_failed(h->cfgtable);\r\nif (rc)\r\ndev_info(&h->pdev->dev,\r\n"Soft reset appears to have failed.\n");\r\nhpsa_undo_allocations_after_kdump_soft_reset(h);\r\ntry_soft_reset = 0;\r\nif (rc)\r\nreturn -ENODEV;\r\ngoto reinit_after_soft_reset;\r\n}\r\nh->access.set_intr_mask(h, HPSA_INTR_ON);\r\nhpsa_hba_inquiry(h);\r\nhpsa_register_scsi(h);\r\nstart_controller_lockup_detector(h);\r\nreturn 1;\r\nclean4:\r\nhpsa_free_sg_chain_blocks(h);\r\nhpsa_free_cmd_pool(h);\r\nfree_irqs(h);\r\nclean2:\r\nclean1:\r\nkfree(h);\r\nreturn rc;\r\n}\r\nstatic void hpsa_flush_cache(struct ctlr_info *h)\r\n{\r\nchar *flush_buf;\r\nstruct CommandList *c;\r\nflush_buf = kzalloc(4, GFP_KERNEL);\r\nif (!flush_buf)\r\nreturn;\r\nc = cmd_special_alloc(h);\r\nif (!c) {\r\ndev_warn(&h->pdev->dev, "cmd_special_alloc returned NULL!\n");\r\ngoto out_of_memory;\r\n}\r\nif (fill_cmd(c, HPSA_CACHE_FLUSH, h, flush_buf, 4, 0,\r\nRAID_CTLR_LUNID, TYPE_CMD)) {\r\ngoto out;\r\n}\r\nhpsa_scsi_do_simple_cmd_with_retry(h, c, PCI_DMA_TODEVICE);\r\nif (c->err_info->CommandStatus != 0)\r\nout:\r\ndev_warn(&h->pdev->dev,\r\n"error flushing cache on controller\n");\r\ncmd_special_free(h, c);\r\nout_of_memory:\r\nkfree(flush_buf);\r\n}\r\nstatic void hpsa_shutdown(struct pci_dev *pdev)\r\n{\r\nstruct ctlr_info *h;\r\nh = pci_get_drvdata(pdev);\r\nhpsa_flush_cache(h);\r\nh->access.set_intr_mask(h, HPSA_INTR_OFF);\r\nhpsa_free_irqs_and_disable_msix(h);\r\n}\r\nstatic void hpsa_free_device_info(struct ctlr_info *h)\r\n{\r\nint i;\r\nfor (i = 0; i < h->ndevices; i++)\r\nkfree(h->dev[i]);\r\n}\r\nstatic void hpsa_remove_one(struct pci_dev *pdev)\r\n{\r\nstruct ctlr_info *h;\r\nif (pci_get_drvdata(pdev) == NULL) {\r\ndev_err(&pdev->dev, "unable to remove device\n");\r\nreturn;\r\n}\r\nh = pci_get_drvdata(pdev);\r\nstop_controller_lockup_detector(h);\r\nhpsa_unregister_scsi(h);\r\nhpsa_shutdown(pdev);\r\niounmap(h->vaddr);\r\niounmap(h->transtable);\r\niounmap(h->cfgtable);\r\nhpsa_free_device_info(h);\r\nhpsa_free_sg_chain_blocks(h);\r\npci_free_consistent(h->pdev,\r\nh->nr_cmds * sizeof(struct CommandList),\r\nh->cmd_pool, h->cmd_pool_dhandle);\r\npci_free_consistent(h->pdev,\r\nh->nr_cmds * sizeof(struct ErrorInfo),\r\nh->errinfo_pool, h->errinfo_pool_dhandle);\r\npci_free_consistent(h->pdev, h->reply_pool_size,\r\nh->reply_pool, h->reply_pool_dhandle);\r\nkfree(h->cmd_pool_bits);\r\nkfree(h->blockFetchTable);\r\nkfree(h->hba_inquiry_data);\r\npci_disable_device(pdev);\r\npci_release_regions(pdev);\r\npci_set_drvdata(pdev, NULL);\r\nkfree(h);\r\n}\r\nstatic void calc_bucket_map(int bucket[], int num_buckets,\r\nint nsgs, int *bucket_map)\r\n{\r\nint i, j, b, size;\r\n#define MINIMUM_TRANSFER_BLOCKS 4\r\n#define NUM_BUCKETS 8\r\nfor (i = 0; i <= nsgs; i++) {\r\nsize = i + MINIMUM_TRANSFER_BLOCKS;\r\nb = num_buckets;\r\nfor (j = 0; j < 8; j++) {\r\nif (bucket[j] >= size) {\r\nb = j;\r\nbreak;\r\n}\r\n}\r\nbucket_map[i] = b;\r\n}\r\n}\r\nstatic void hpsa_enter_performant_mode(struct ctlr_info *h, u32 use_short_tags)\r\n{\r\nint i;\r\nunsigned long register_value;\r\nint bft[8] = {5, 6, 8, 10, 12, 20, 28, SG_ENTRIES_IN_CMD + 4};\r\nBUILD_BUG_ON(28 > SG_ENTRIES_IN_CMD + 4);\r\nmemset(h->reply_pool, 0, h->reply_pool_size);\r\nbft[7] = SG_ENTRIES_IN_CMD + 4;\r\ncalc_bucket_map(bft, ARRAY_SIZE(bft),\r\nSG_ENTRIES_IN_CMD, h->blockFetchTable);\r\nfor (i = 0; i < 8; i++)\r\nwritel(bft[i], &h->transtable->BlockFetch[i]);\r\nwritel(h->max_commands, &h->transtable->RepQSize);\r\nwritel(h->nreply_queues, &h->transtable->RepQCount);\r\nwritel(0, &h->transtable->RepQCtrAddrLow32);\r\nwritel(0, &h->transtable->RepQCtrAddrHigh32);\r\nfor (i = 0; i < h->nreply_queues; i++) {\r\nwritel(0, &h->transtable->RepQAddr[i].upper);\r\nwritel(h->reply_pool_dhandle +\r\n(h->max_commands * sizeof(u64) * i),\r\n&h->transtable->RepQAddr[i].lower);\r\n}\r\nwritel(CFGTBL_Trans_Performant | use_short_tags |\r\nCFGTBL_Trans_enable_directed_msix,\r\n&(h->cfgtable->HostWrite.TransportRequest));\r\nwritel(CFGTBL_ChangeReq, h->vaddr + SA5_DOORBELL);\r\nhpsa_wait_for_mode_change_ack(h);\r\nregister_value = readl(&(h->cfgtable->TransportActive));\r\nif (!(register_value & CFGTBL_Trans_Performant)) {\r\ndev_warn(&h->pdev->dev, "unable to get board into"\r\n" performant mode\n");\r\nreturn;\r\n}\r\nh->access = SA5_performant_access;\r\nh->transMethod = CFGTBL_Trans_Performant;\r\n}\r\nstatic void hpsa_put_ctlr_into_performant_mode(struct ctlr_info *h)\r\n{\r\nu32 trans_support;\r\nint i;\r\nif (hpsa_simple_mode)\r\nreturn;\r\ntrans_support = readl(&(h->cfgtable->TransportSupport));\r\nif (!(trans_support & PERFORMANT_MODE))\r\nreturn;\r\nh->nreply_queues = h->msix_vector ? MAX_REPLY_QUEUES : 1;\r\nhpsa_get_max_perf_mode_cmds(h);\r\nh->reply_pool_size = h->max_commands * sizeof(u64) * h->nreply_queues;\r\nh->reply_pool = pci_alloc_consistent(h->pdev, h->reply_pool_size,\r\n&(h->reply_pool_dhandle));\r\nfor (i = 0; i < h->nreply_queues; i++) {\r\nh->reply_queue[i].head = &h->reply_pool[h->max_commands * i];\r\nh->reply_queue[i].size = h->max_commands;\r\nh->reply_queue[i].wraparound = 1;\r\nh->reply_queue[i].current_entry = 0;\r\n}\r\nh->blockFetchTable = kmalloc(((SG_ENTRIES_IN_CMD + 1) *\r\nsizeof(u32)), GFP_KERNEL);\r\nif ((h->reply_pool == NULL)\r\n|| (h->blockFetchTable == NULL))\r\ngoto clean_up;\r\nhpsa_enter_performant_mode(h,\r\ntrans_support & CFGTBL_Trans_use_short_tags);\r\nreturn;\r\nclean_up:\r\nif (h->reply_pool)\r\npci_free_consistent(h->pdev, h->reply_pool_size,\r\nh->reply_pool, h->reply_pool_dhandle);\r\nkfree(h->blockFetchTable);\r\n}\r\nstatic int __init hpsa_init(void)\r\n{\r\nreturn pci_register_driver(&hpsa_pci_driver);\r\n}\r\nstatic void __exit hpsa_cleanup(void)\r\n{\r\npci_unregister_driver(&hpsa_pci_driver);\r\n}
