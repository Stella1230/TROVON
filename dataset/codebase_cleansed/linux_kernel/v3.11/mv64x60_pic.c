static void mv64x60_mask_low(struct irq_data *d)\r\n{\r\nint level2 = irqd_to_hwirq(d) & MV64x60_LEVEL2_MASK;\r\nunsigned long flags;\r\nspin_lock_irqsave(&mv64x60_lock, flags);\r\nmv64x60_cached_low_mask &= ~(1 << level2);\r\nout_le32(mv64x60_irq_reg_base + MV64X60_IC_CPU0_INTR_MASK_LO,\r\nmv64x60_cached_low_mask);\r\nspin_unlock_irqrestore(&mv64x60_lock, flags);\r\n(void)in_le32(mv64x60_irq_reg_base + MV64X60_IC_CPU0_INTR_MASK_LO);\r\n}\r\nstatic void mv64x60_unmask_low(struct irq_data *d)\r\n{\r\nint level2 = irqd_to_hwirq(d) & MV64x60_LEVEL2_MASK;\r\nunsigned long flags;\r\nspin_lock_irqsave(&mv64x60_lock, flags);\r\nmv64x60_cached_low_mask |= 1 << level2;\r\nout_le32(mv64x60_irq_reg_base + MV64X60_IC_CPU0_INTR_MASK_LO,\r\nmv64x60_cached_low_mask);\r\nspin_unlock_irqrestore(&mv64x60_lock, flags);\r\n(void)in_le32(mv64x60_irq_reg_base + MV64X60_IC_CPU0_INTR_MASK_LO);\r\n}\r\nstatic void mv64x60_mask_high(struct irq_data *d)\r\n{\r\nint level2 = irqd_to_hwirq(d) & MV64x60_LEVEL2_MASK;\r\nunsigned long flags;\r\nspin_lock_irqsave(&mv64x60_lock, flags);\r\nmv64x60_cached_high_mask &= ~(1 << level2);\r\nout_le32(mv64x60_irq_reg_base + MV64X60_IC_CPU0_INTR_MASK_HI,\r\nmv64x60_cached_high_mask);\r\nspin_unlock_irqrestore(&mv64x60_lock, flags);\r\n(void)in_le32(mv64x60_irq_reg_base + MV64X60_IC_CPU0_INTR_MASK_HI);\r\n}\r\nstatic void mv64x60_unmask_high(struct irq_data *d)\r\n{\r\nint level2 = irqd_to_hwirq(d) & MV64x60_LEVEL2_MASK;\r\nunsigned long flags;\r\nspin_lock_irqsave(&mv64x60_lock, flags);\r\nmv64x60_cached_high_mask |= 1 << level2;\r\nout_le32(mv64x60_irq_reg_base + MV64X60_IC_CPU0_INTR_MASK_HI,\r\nmv64x60_cached_high_mask);\r\nspin_unlock_irqrestore(&mv64x60_lock, flags);\r\n(void)in_le32(mv64x60_irq_reg_base + MV64X60_IC_CPU0_INTR_MASK_HI);\r\n}\r\nstatic void mv64x60_mask_gpp(struct irq_data *d)\r\n{\r\nint level2 = irqd_to_hwirq(d) & MV64x60_LEVEL2_MASK;\r\nunsigned long flags;\r\nspin_lock_irqsave(&mv64x60_lock, flags);\r\nmv64x60_cached_gpp_mask &= ~(1 << level2);\r\nout_le32(mv64x60_gpp_reg_base + MV64x60_GPP_INTR_MASK,\r\nmv64x60_cached_gpp_mask);\r\nspin_unlock_irqrestore(&mv64x60_lock, flags);\r\n(void)in_le32(mv64x60_gpp_reg_base + MV64x60_GPP_INTR_MASK);\r\n}\r\nstatic void mv64x60_mask_ack_gpp(struct irq_data *d)\r\n{\r\nint level2 = irqd_to_hwirq(d) & MV64x60_LEVEL2_MASK;\r\nunsigned long flags;\r\nspin_lock_irqsave(&mv64x60_lock, flags);\r\nmv64x60_cached_gpp_mask &= ~(1 << level2);\r\nout_le32(mv64x60_gpp_reg_base + MV64x60_GPP_INTR_MASK,\r\nmv64x60_cached_gpp_mask);\r\nout_le32(mv64x60_gpp_reg_base + MV64x60_GPP_INTR_CAUSE,\r\n~(1 << level2));\r\nspin_unlock_irqrestore(&mv64x60_lock, flags);\r\n(void)in_le32(mv64x60_gpp_reg_base + MV64x60_GPP_INTR_CAUSE);\r\n}\r\nstatic void mv64x60_unmask_gpp(struct irq_data *d)\r\n{\r\nint level2 = irqd_to_hwirq(d) & MV64x60_LEVEL2_MASK;\r\nunsigned long flags;\r\nspin_lock_irqsave(&mv64x60_lock, flags);\r\nmv64x60_cached_gpp_mask |= 1 << level2;\r\nout_le32(mv64x60_gpp_reg_base + MV64x60_GPP_INTR_MASK,\r\nmv64x60_cached_gpp_mask);\r\nspin_unlock_irqrestore(&mv64x60_lock, flags);\r\n(void)in_le32(mv64x60_gpp_reg_base + MV64x60_GPP_INTR_MASK);\r\n}\r\nstatic int mv64x60_host_map(struct irq_domain *h, unsigned int virq,\r\nirq_hw_number_t hwirq)\r\n{\r\nint level1;\r\nirq_set_status_flags(virq, IRQ_LEVEL);\r\nlevel1 = (hwirq & MV64x60_LEVEL1_MASK) >> MV64x60_LEVEL1_OFFSET;\r\nBUG_ON(level1 > MV64x60_LEVEL1_GPP);\r\nirq_set_chip_and_handler(virq, mv64x60_chips[level1],\r\nhandle_level_irq);\r\nreturn 0;\r\n}\r\nvoid __init mv64x60_init_irq(void)\r\n{\r\nstruct device_node *np;\r\nphys_addr_t paddr;\r\nunsigned int size;\r\nconst unsigned int *reg;\r\nunsigned long flags;\r\nnp = of_find_compatible_node(NULL, NULL, "marvell,mv64360-gpp");\r\nreg = of_get_property(np, "reg", &size);\r\npaddr = of_translate_address(np, reg);\r\nmv64x60_gpp_reg_base = ioremap(paddr, reg[1]);\r\nof_node_put(np);\r\nnp = of_find_compatible_node(NULL, NULL, "marvell,mv64360-pic");\r\nreg = of_get_property(np, "reg", &size);\r\npaddr = of_translate_address(np, reg);\r\nmv64x60_irq_reg_base = ioremap(paddr, reg[1]);\r\nmv64x60_irq_host = irq_domain_add_linear(np, MV64x60_NUM_IRQS,\r\n&mv64x60_host_ops, NULL);\r\nspin_lock_irqsave(&mv64x60_lock, flags);\r\nout_le32(mv64x60_gpp_reg_base + MV64x60_GPP_INTR_MASK,\r\nmv64x60_cached_gpp_mask);\r\nout_le32(mv64x60_irq_reg_base + MV64X60_IC_CPU0_INTR_MASK_LO,\r\nmv64x60_cached_low_mask);\r\nout_le32(mv64x60_irq_reg_base + MV64X60_IC_CPU0_INTR_MASK_HI,\r\nmv64x60_cached_high_mask);\r\nout_le32(mv64x60_gpp_reg_base + MV64x60_GPP_INTR_CAUSE, 0);\r\nout_le32(mv64x60_irq_reg_base + MV64X60_IC_MAIN_CAUSE_LO, 0);\r\nout_le32(mv64x60_irq_reg_base + MV64X60_IC_MAIN_CAUSE_HI, 0);\r\nspin_unlock_irqrestore(&mv64x60_lock, flags);\r\n}\r\nunsigned int mv64x60_get_irq(void)\r\n{\r\nu32 cause;\r\nint level1;\r\nirq_hw_number_t hwirq;\r\nint virq = NO_IRQ;\r\ncause = in_le32(mv64x60_irq_reg_base + MV64X60_IC_CPU0_SELECT_CAUSE);\r\nif (cause & MV64X60_SELECT_CAUSE_HIGH) {\r\ncause &= mv64x60_cached_high_mask;\r\nlevel1 = MV64x60_LEVEL1_HIGH;\r\nif (cause & MV64X60_HIGH_GPP_GROUPS) {\r\ncause = in_le32(mv64x60_gpp_reg_base +\r\nMV64x60_GPP_INTR_CAUSE);\r\ncause &= mv64x60_cached_gpp_mask;\r\nlevel1 = MV64x60_LEVEL1_GPP;\r\n}\r\n} else {\r\ncause &= mv64x60_cached_low_mask;\r\nlevel1 = MV64x60_LEVEL1_LOW;\r\n}\r\nif (cause) {\r\nhwirq = (level1 << MV64x60_LEVEL1_OFFSET) | __ilog2(cause);\r\nvirq = irq_linear_revmap(mv64x60_irq_host, hwirq);\r\n}\r\nreturn virq;\r\n}
