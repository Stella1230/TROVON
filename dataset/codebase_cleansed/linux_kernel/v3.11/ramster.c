static struct flushlist_node *ramster_flnode_alloc(struct tmem_pool *pool)\r\n{\r\nstruct flushlist_node *flnode = NULL;\r\nstruct ramster_preload *kp;\r\nkp = &__get_cpu_var(ramster_preloads);\r\nflnode = kp->flnode;\r\nBUG_ON(flnode == NULL);\r\nkp->flnode = NULL;\r\ninc_ramster_flnodes();\r\nreturn flnode;\r\n}\r\nstatic void ramster_flnode_free(struct flushlist_node *flnode,\r\nstruct tmem_pool *pool)\r\n{\r\ndec_ramster_flnodes();\r\nBUG_ON(ramster_flnodes < 0);\r\nkmem_cache_free(ramster_flnode_cache, flnode);\r\n}\r\nint ramster_do_preload_flnode(struct tmem_pool *pool)\r\n{\r\nstruct ramster_preload *kp;\r\nstruct flushlist_node *flnode;\r\nint ret = -ENOMEM;\r\nBUG_ON(!irqs_disabled());\r\nif (unlikely(ramster_flnode_cache == NULL))\r\nBUG();\r\nkp = &__get_cpu_var(ramster_preloads);\r\nflnode = kmem_cache_alloc(ramster_flnode_cache, GFP_ATOMIC);\r\nif (unlikely(flnode == NULL) && kp->flnode == NULL)\r\nBUG();\r\nelse if (kp->flnode == NULL)\r\nkp->flnode = flnode;\r\nelse\r\nkmem_cache_free(ramster_flnode_cache, flnode);\r\nreturn ret;\r\n}\r\nint ramster_localify(int pool_id, struct tmem_oid *oidp, uint32_t index,\r\nchar *data, unsigned int size, void *extra)\r\n{\r\nint ret = -ENOENT;\r\nunsigned long flags;\r\nstruct tmem_pool *pool;\r\nbool eph, delete = false;\r\nvoid *pampd, *saved_hb;\r\nstruct tmem_obj *obj;\r\npool = zcache_get_pool_by_id(LOCAL_CLIENT, pool_id);\r\nif (unlikely(pool == NULL))\r\ngoto out;\r\neph = is_ephemeral(pool);\r\nlocal_irq_save(flags);\r\npampd = tmem_localify_get_pampd(pool, oidp, index, &obj, &saved_hb);\r\nif (pampd == NULL) {\r\n#ifdef RAMSTER_TESTING\r\npr_err("UNTESTED pampd==NULL in ramster_localify\n");\r\n#endif\r\nif (eph)\r\ninc_ramster_remote_eph_pages_unsucc_get();\r\nelse\r\ninc_ramster_remote_pers_pages_unsucc_get();\r\nobj = NULL;\r\ngoto finish;\r\n} else if (unlikely(!pampd_is_remote(pampd))) {\r\n#ifdef RAMSTER_TESTING\r\npr_err("UNTESTED dup while waiting in ramster_localify\n");\r\n#endif\r\nif (eph)\r\ninc_ramster_remote_eph_pages_unsucc_get();\r\nelse\r\ninc_ramster_remote_pers_pages_unsucc_get();\r\nobj = NULL;\r\npampd = NULL;\r\nret = -EEXIST;\r\ngoto finish;\r\n} else if (size == 0) {\r\npampd = NULL;\r\nif (eph)\r\ninc_ramster_remote_eph_pages_unsucc_get();\r\nelse\r\nBUG();\r\ndelete = true;\r\ngoto finish;\r\n}\r\nif (pampd_is_intransit(pampd)) {\r\nBUG_ON(eph);\r\npampd = pampd_mask_intransit_and_remote(pampd);\r\nzbud_copy_to_zbud(pampd, data, size);\r\n} else {\r\npampd = NULL;\r\nobj = NULL;\r\n}\r\nBUG_ON(extra == NULL);\r\nzcache_decompress_to_page(data, size, (struct page *)extra);\r\nif (eph)\r\ninc_ramster_remote_eph_pages_succ_get();\r\nelse\r\ninc_ramster_remote_pers_pages_succ_get();\r\nret = 0;\r\nfinish:\r\ntmem_localify_finish(obj, index, pampd, saved_hb, delete);\r\nzcache_put_pool(pool);\r\nlocal_irq_restore(flags);\r\nout:\r\nreturn ret;\r\n}\r\nvoid ramster_pampd_new_obj(struct tmem_obj *obj)\r\n{\r\nobj->extra = NULL;\r\n}\r\nvoid ramster_pampd_free_obj(struct tmem_pool *pool, struct tmem_obj *obj,\r\nbool pool_destroy)\r\n{\r\nstruct flushlist_node *flnode;\r\nBUG_ON(preemptible());\r\nif (obj->extra == NULL)\r\nreturn;\r\nif (pool_destroy && is_ephemeral(pool))\r\nreturn;\r\nBUG_ON(!pampd_is_remote(obj->extra));\r\nflnode = ramster_flnode_alloc(pool);\r\nflnode->xh.client_id = pampd_remote_node(obj->extra);\r\nflnode->xh.pool_id = pool->pool_id;\r\nflnode->xh.oid = obj->oid;\r\nflnode->xh.index = FLUSH_ENTIRE_OBJECT;\r\nflnode->rem_op.op = RAMSTER_REMOTIFY_FLUSH_OBJ;\r\nspin_lock(&ramster_rem_op_list_lock);\r\nlist_add(&flnode->rem_op.list, &ramster_rem_op_list);\r\nspin_unlock(&ramster_rem_op_list_lock);\r\n}\r\nvoid *ramster_pampd_repatriate_preload(void *pampd, struct tmem_pool *pool,\r\nstruct tmem_oid *oidp, uint32_t index,\r\nbool *intransit)\r\n{\r\nint clen = pampd_remote_size(pampd), c;\r\nvoid *ret_pampd = NULL;\r\nunsigned long flags;\r\nstruct tmem_handle th;\r\nBUG_ON(!pampd_is_remote(pampd));\r\nBUG_ON(is_ephemeral(pool));\r\nif (use_frontswap_exclusive_gets)\r\ngoto out;\r\nif (pampd_is_intransit(pampd)) {\r\n*intransit = true;\r\ngoto out;\r\n}\r\n*intransit = false;\r\nlocal_irq_save(flags);\r\nth.client_id = pampd_remote_node(pampd);\r\nth.pool_id = pool->pool_id;\r\nth.oid = *oidp;\r\nth.index = index;\r\nret_pampd = zcache_pampd_create(NULL, clen, true, false, &th);\r\nif (ret_pampd != NULL) {\r\nret_pampd = pampd_mark_intransit(ret_pampd);\r\nc = atomic_dec_return(&ramster_remote_pers_pages);\r\nWARN_ON_ONCE(c < 0);\r\n} else {\r\ninc_ramster_pers_pages_remote_nomem();\r\n}\r\nlocal_irq_restore(flags);\r\nout:\r\nreturn ret_pampd;\r\n}\r\nint ramster_pampd_repatriate(void *fake_pampd, void *real_pampd,\r\nstruct tmem_pool *pool,\r\nstruct tmem_oid *oid, uint32_t index,\r\nbool free, void *extra)\r\n{\r\nstruct tmem_xhandle xh;\r\nint ret;\r\nif (pampd_is_intransit(real_pampd))\r\nfree = true;\r\nxh = tmem_xhandle_fill(LOCAL_CLIENT, pool, oid, index);\r\nret = r2net_remote_async_get(&xh, free,\r\npampd_remote_node(fake_pampd),\r\npampd_remote_size(fake_pampd),\r\npampd_remote_cksum(fake_pampd),\r\nextra);\r\nreturn ret;\r\n}\r\nbool ramster_pampd_is_remote(void *pampd)\r\n{\r\nreturn pampd_is_remote(pampd);\r\n}\r\nint ramster_pampd_replace_in_obj(void *new_pampd, struct tmem_obj *obj)\r\n{\r\nint ret = -1;\r\nif (new_pampd != NULL) {\r\nif (obj->extra == NULL)\r\nobj->extra = new_pampd;\r\nelse if (pampd_remote_node(new_pampd) !=\r\npampd_remote_node((void *)(obj->extra)))\r\nBUG();\r\nret = 0;\r\n}\r\nreturn ret;\r\n}\r\nvoid *ramster_pampd_free(void *pampd, struct tmem_pool *pool,\r\nstruct tmem_oid *oid, uint32_t index, bool acct)\r\n{\r\nbool eph = is_ephemeral(pool);\r\nvoid *local_pampd = NULL;\r\nint c;\r\nBUG_ON(preemptible());\r\nBUG_ON(!pampd_is_remote(pampd));\r\nWARN_ON(acct == false);\r\nif (oid == NULL) {\r\n} else if (eph) {\r\n} else if (pampd_is_intransit(pampd)) {\r\nlocal_pampd = pampd_mask_intransit_and_remote(pampd);\r\n} else {\r\nstruct flushlist_node *flnode =\r\nramster_flnode_alloc(pool);\r\nflnode->xh.client_id = pampd_remote_node(pampd);\r\nflnode->xh.pool_id = pool->pool_id;\r\nflnode->xh.oid = *oid;\r\nflnode->xh.index = index;\r\nflnode->rem_op.op = RAMSTER_REMOTIFY_FLUSH_PAGE;\r\nspin_lock(&ramster_rem_op_list_lock);\r\nlist_add(&flnode->rem_op.list, &ramster_rem_op_list);\r\nspin_unlock(&ramster_rem_op_list_lock);\r\nc = atomic_dec_return(&ramster_remote_pers_pages);\r\nWARN_ON_ONCE(c < 0);\r\n}\r\nreturn local_pampd;\r\n}\r\nvoid ramster_count_foreign_pages(bool eph, int count)\r\n{\r\nBUG_ON(count != 1 && count != -1);\r\nif (eph) {\r\nif (count > 0) {\r\ninc_ramster_foreign_eph_pages();\r\n} else {\r\ndec_ramster_foreign_eph_pages();\r\n#ifdef CONFIG_RAMSTER_DEBUG\r\nWARN_ON_ONCE(ramster_foreign_eph_pages < 0);\r\n#endif\r\n}\r\n} else {\r\nif (count > 0) {\r\ninc_ramster_foreign_pers_pages();\r\n} else {\r\ndec_ramster_foreign_pers_pages();\r\n#ifdef CONFIG_RAMSTER_DEBUG\r\nWARN_ON_ONCE(ramster_foreign_pers_pages < 0);\r\n#endif\r\n}\r\n}\r\n}\r\nstatic void ramster_remotify_queue_delayed_work(unsigned long delay)\r\n{\r\nif (!queue_delayed_work(ramster_remotify_workqueue,\r\n&ramster_remotify_worker, delay))\r\npr_err("ramster_remotify: bad workqueue\n");\r\n}\r\nstatic void ramster_remote_flush_page(struct flushlist_node *flnode)\r\n{\r\nstruct tmem_xhandle *xh;\r\nint remotenode, ret;\r\npreempt_disable();\r\nxh = &flnode->xh;\r\nremotenode = flnode->xh.client_id;\r\nret = r2net_remote_flush(xh, remotenode);\r\nif (ret >= 0)\r\ninc_ramster_remote_pages_flushed();\r\nelse\r\ninc_ramster_remote_page_flushes_failed();\r\npreempt_enable_no_resched();\r\nramster_flnode_free(flnode, NULL);\r\n}\r\nstatic void ramster_remote_flush_object(struct flushlist_node *flnode)\r\n{\r\nstruct tmem_xhandle *xh;\r\nint remotenode, ret;\r\npreempt_disable();\r\nxh = &flnode->xh;\r\nremotenode = flnode->xh.client_id;\r\nret = r2net_remote_flush_object(xh, remotenode);\r\nif (ret >= 0)\r\ninc_ramster_remote_objects_flushed();\r\nelse\r\ninc_ramster_remote_object_flushes_failed();\r\npreempt_enable_no_resched();\r\nramster_flnode_free(flnode, NULL);\r\n}\r\nint ramster_remotify_pageframe(bool eph)\r\n{\r\nstruct tmem_xhandle xh;\r\nunsigned int size;\r\nint remotenode, ret, zbuds;\r\nstruct tmem_pool *pool;\r\nunsigned long flags;\r\nunsigned char cksum;\r\nchar *p;\r\nint i, j;\r\nunsigned char *tmpmem[2];\r\nstruct tmem_handle th[2];\r\nunsigned int zsize[2];\r\ntmpmem[0] = __get_cpu_var(ramster_remoteputmem1);\r\ntmpmem[1] = __get_cpu_var(ramster_remoteputmem2);\r\nlocal_bh_disable();\r\nzbuds = zbud_make_zombie_lru(&th[0], &tmpmem[0], &zsize[0], eph);\r\nlocal_bh_enable();\r\nif (zbuds == 0)\r\ngoto out;\r\nBUG_ON(zbuds > 2);\r\nfor (i = 0; i < zbuds; i++) {\r\nxh.client_id = th[i].client_id;\r\nxh.pool_id = th[i].pool_id;\r\nxh.oid = th[i].oid;\r\nxh.index = th[i].index;\r\nsize = zsize[i];\r\nBUG_ON(size == 0 || size > zbud_max_buddy_size());\r\nfor (p = tmpmem[i], cksum = 0, j = 0; j < size; j++)\r\ncksum += *p++;\r\nret = r2net_remote_put(&xh, tmpmem[i], size, eph, &remotenode);\r\nif (ret != 0) {\r\nif (eph)\r\ninc_ramster_eph_pages_remote_failed();\r\nelse\r\ninc_ramster_pers_pages_remote_failed();\r\nbreak;\r\n} else {\r\nif (!eph)\r\natomic_inc(&ramster_remote_pers_pages);\r\n}\r\nif (eph)\r\ninc_ramster_eph_pages_remoted();\r\nelse\r\ninc_ramster_pers_pages_remoted();\r\nlocal_bh_disable();\r\npool = zcache_get_pool_by_id(LOCAL_CLIENT, xh.pool_id);\r\nlocal_irq_save(flags);\r\n(void)tmem_replace(pool, &xh.oid, xh.index,\r\npampd_make_remote(remotenode, size, cksum));\r\nlocal_irq_restore(flags);\r\nzcache_put_pool(pool);\r\nlocal_bh_enable();\r\n}\r\nout:\r\nreturn zbuds;\r\n}\r\nstatic void zcache_do_remotify_flushes(void)\r\n{\r\nstruct ramster_remotify_hdr *rem_op;\r\nunion remotify_list_node *u;\r\nwhile (1) {\r\nspin_lock(&ramster_rem_op_list_lock);\r\nif (list_empty(&ramster_rem_op_list)) {\r\nspin_unlock(&ramster_rem_op_list_lock);\r\ngoto out;\r\n}\r\nrem_op = list_first_entry(&ramster_rem_op_list,\r\nstruct ramster_remotify_hdr, list);\r\nlist_del_init(&rem_op->list);\r\nspin_unlock(&ramster_rem_op_list_lock);\r\nu = (union remotify_list_node *)rem_op;\r\nswitch (rem_op->op) {\r\ncase RAMSTER_REMOTIFY_FLUSH_PAGE:\r\nramster_remote_flush_page((struct flushlist_node *)u);\r\nbreak;\r\ncase RAMSTER_REMOTIFY_FLUSH_OBJ:\r\nramster_remote_flush_object((struct flushlist_node *)u);\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\n}\r\nout:\r\nreturn;\r\n}\r\nstatic void ramster_remotify_process(struct work_struct *work)\r\n{\r\nstatic bool remotify_in_progress;\r\nint i;\r\nBUG_ON(irqs_disabled());\r\nif (remotify_in_progress)\r\ngoto requeue;\r\nif (ramster_remote_target_nodenum == -1)\r\ngoto requeue;\r\nremotify_in_progress = true;\r\nif (use_cleancache && ramster_eph_remotify_enable) {\r\nfor (i = 0; i < 100; i++) {\r\nzcache_do_remotify_flushes();\r\n(void)ramster_remotify_pageframe(true);\r\n}\r\n}\r\nif (use_frontswap && ramster_pers_remotify_enable) {\r\nfor (i = 0; i < 100; i++) {\r\nzcache_do_remotify_flushes();\r\n(void)ramster_remotify_pageframe(false);\r\n}\r\n}\r\nremotify_in_progress = false;\r\nrequeue:\r\nramster_remotify_queue_delayed_work(HZ);\r\n}\r\nvoid ramster_remotify_init(void)\r\n{\r\nunsigned long n = 60UL;\r\nramster_remotify_workqueue =\r\ncreate_singlethread_workqueue("ramster_remotify");\r\nramster_remotify_queue_delayed_work(n * HZ);\r\n}\r\nstatic ssize_t ramster_manual_node_up_show(struct kobject *kobj,\r\nstruct kobj_attribute *attr, char *buf)\r\n{\r\nint i;\r\nchar *p = buf;\r\nfor (i = 0; i < MANUAL_NODES; i++)\r\nif (ramster_nodes_manual_up[i])\r\np += sprintf(p, "%d ", i);\r\np += sprintf(p, "\n");\r\nreturn p - buf;\r\n}\r\nstatic ssize_t ramster_manual_node_up_store(struct kobject *kobj,\r\nstruct kobj_attribute *attr, const char *buf, size_t count)\r\n{\r\nint err;\r\nunsigned long node_num;\r\nerr = kstrtoul(buf, 10, &node_num);\r\nif (err) {\r\npr_err("ramster: bad strtoul?\n");\r\nreturn -EINVAL;\r\n}\r\nif (node_num >= MANUAL_NODES) {\r\npr_err("ramster: bad node_num=%lu?\n", node_num);\r\nreturn -EINVAL;\r\n}\r\nif (ramster_nodes_manual_up[node_num]) {\r\npr_err("ramster: node %d already up, ignoring\n",\r\n(int)node_num);\r\n} else {\r\nramster_nodes_manual_up[node_num] = true;\r\nr2net_hb_node_up_manual((int)node_num);\r\n}\r\nreturn count;\r\n}\r\nstatic ssize_t ramster_remote_target_nodenum_show(struct kobject *kobj,\r\nstruct kobj_attribute *attr, char *buf)\r\n{\r\nif (ramster_remote_target_nodenum == -1UL)\r\nreturn sprintf(buf, "unset\n");\r\nelse\r\nreturn sprintf(buf, "%d\n", ramster_remote_target_nodenum);\r\n}\r\nstatic ssize_t ramster_remote_target_nodenum_store(struct kobject *kobj,\r\nstruct kobj_attribute *attr, const char *buf, size_t count)\r\n{\r\nint err;\r\nunsigned long node_num;\r\nerr = kstrtoul(buf, 10, &node_num);\r\nif (err) {\r\npr_err("ramster: bad strtoul?\n");\r\nreturn -EINVAL;\r\n} else if (node_num == -1UL) {\r\npr_err("ramster: disabling all remotification, "\r\n"data may still reside on remote nodes however\n");\r\nreturn -EINVAL;\r\n} else if (node_num >= MANUAL_NODES) {\r\npr_err("ramster: bad node_num=%lu?\n", node_num);\r\nreturn -EINVAL;\r\n} else if (!ramster_nodes_manual_up[node_num]) {\r\npr_err("ramster: node %d not up, ignoring setting "\r\n"of remotification target\n", (int)node_num);\r\n} else if (r2net_remote_target_node_set((int)node_num) >= 0) {\r\npr_info("ramster: node %d set as remotification target\n",\r\n(int)node_num);\r\nramster_remote_target_nodenum = (int)node_num;\r\n} else {\r\npr_err("ramster: bad num to node node_num=%d?\n",\r\n(int)node_num);\r\nreturn -EINVAL;\r\n}\r\nreturn count;\r\n}\r\nstatic void frontswap_selfshrink(void)\r\n{\r\nstatic unsigned long cur_frontswap_pages;\r\nstatic unsigned long last_frontswap_pages;\r\nstatic unsigned long tgt_frontswap_pages;\r\nlast_frontswap_pages = cur_frontswap_pages;\r\ncur_frontswap_pages = frontswap_curr_pages();\r\nif (!cur_frontswap_pages ||\r\n(cur_frontswap_pages > last_frontswap_pages)) {\r\nfrontswap_inertia_counter = frontswap_inertia;\r\nreturn;\r\n}\r\nif (frontswap_inertia_counter && --frontswap_inertia_counter)\r\nreturn;\r\nif (cur_frontswap_pages <= frontswap_hysteresis)\r\ntgt_frontswap_pages = 0;\r\nelse\r\ntgt_frontswap_pages = cur_frontswap_pages -\r\n(cur_frontswap_pages / frontswap_hysteresis);\r\nfrontswap_shrink(tgt_frontswap_pages);\r\n}\r\nstatic int __init ramster_nofrontswap_selfshrink_setup(char *s)\r\n{\r\nuse_frontswap_selfshrink = false;\r\nreturn 1;\r\n}\r\nstatic void selfshrink_process(struct work_struct *work)\r\n{\r\nif (frontswap_selfshrinking && frontswap_enabled) {\r\nfrontswap_selfshrink();\r\nschedule_delayed_work(&selfshrink_worker,\r\nselfshrink_interval * HZ);\r\n}\r\n}\r\nvoid ramster_cpu_up(int cpu)\r\n{\r\nunsigned char *p1 = kzalloc(PAGE_SIZE, GFP_KERNEL | __GFP_REPEAT);\r\nunsigned char *p2 = kzalloc(PAGE_SIZE, GFP_KERNEL | __GFP_REPEAT);\r\nBUG_ON(!p1 || !p2);\r\nper_cpu(ramster_remoteputmem1, cpu) = p1;\r\nper_cpu(ramster_remoteputmem2, cpu) = p2;\r\n}\r\nvoid ramster_cpu_down(int cpu)\r\n{\r\nstruct ramster_preload *kp;\r\nkfree(per_cpu(ramster_remoteputmem1, cpu));\r\nper_cpu(ramster_remoteputmem1, cpu) = NULL;\r\nkfree(per_cpu(ramster_remoteputmem2, cpu));\r\nper_cpu(ramster_remoteputmem2, cpu) = NULL;\r\nkp = &per_cpu(ramster_preloads, cpu);\r\nif (kp->flnode) {\r\nkmem_cache_free(ramster_flnode_cache, kp->flnode);\r\nkp->flnode = NULL;\r\n}\r\n}\r\nvoid ramster_register_pamops(struct tmem_pamops *pamops)\r\n{\r\npamops->free_obj = ramster_pampd_free_obj;\r\npamops->new_obj = ramster_pampd_new_obj;\r\npamops->replace_in_obj = ramster_pampd_replace_in_obj;\r\npamops->is_remote = ramster_pampd_is_remote;\r\npamops->repatriate = ramster_pampd_repatriate;\r\npamops->repatriate_preload = ramster_pampd_repatriate_preload;\r\n}\r\nvoid ramster_init(bool cleancache, bool frontswap,\r\nbool frontswap_exclusive_gets,\r\nbool frontswap_selfshrink)\r\n{\r\nint ret = 0;\r\nif (cleancache)\r\nuse_cleancache = true;\r\nif (frontswap)\r\nuse_frontswap = true;\r\nif (frontswap_exclusive_gets)\r\nuse_frontswap_exclusive_gets = true;\r\nramster_debugfs_init();\r\nret = sysfs_create_group(mm_kobj, &ramster_attr_group);\r\nif (ret)\r\npr_err("ramster: can't create sysfs for ramster\n");\r\n(void)r2net_register_handlers();\r\n#ifdef CONFIG_RAMSTER_MODULE\r\nret = r2nm_init();\r\nif (ret)\r\npr_err("ramster: can't init r2net\n");\r\nfrontswap_selfshrinking = frontswap_selfshrink;\r\n#else\r\nfrontswap_selfshrinking = use_frontswap_selfshrink;\r\n#endif\r\nINIT_LIST_HEAD(&ramster_rem_op_list);\r\nramster_flnode_cache = kmem_cache_create("ramster_flnode",\r\nsizeof(struct flushlist_node), 0, 0, NULL);\r\nif (frontswap_selfshrinking) {\r\npr_info("ramster: Initializing frontswap selfshrink driver.\n");\r\nschedule_delayed_work(&selfshrink_worker,\r\nselfshrink_interval * HZ);\r\n}\r\nramster_remotify_init();\r\n}
