static inline void dirty_indirect(struct buffer_head *bh, struct inode *inode)\r\n{\r\nmark_buffer_dirty_inode(bh, inode);\r\nif (IS_SYNC(inode))\r\nsync_dirty_buffer(bh);\r\n}\r\nstatic int block_to_path(struct inode *inode, long block, int offsets[DEPTH])\r\n{\r\nstruct super_block *sb = inode->i_sb;\r\nstruct sysv_sb_info *sbi = SYSV_SB(sb);\r\nint ptrs_bits = sbi->s_ind_per_block_bits;\r\nunsigned long indirect_blocks = sbi->s_ind_per_block,\r\ndouble_blocks = sbi->s_ind_per_block_2;\r\nint n = 0;\r\nif (block < 0) {\r\nprintk("sysv_block_map: block < 0\n");\r\n} else if (block < DIRECT) {\r\noffsets[n++] = block;\r\n} else if ( (block -= DIRECT) < indirect_blocks) {\r\noffsets[n++] = DIRECT;\r\noffsets[n++] = block;\r\n} else if ((block -= indirect_blocks) < double_blocks) {\r\noffsets[n++] = DIRECT+1;\r\noffsets[n++] = block >> ptrs_bits;\r\noffsets[n++] = block & (indirect_blocks - 1);\r\n} else if (((block -= double_blocks) >> (ptrs_bits * 2)) < indirect_blocks) {\r\noffsets[n++] = DIRECT+2;\r\noffsets[n++] = block >> (ptrs_bits * 2);\r\noffsets[n++] = (block >> ptrs_bits) & (indirect_blocks - 1);\r\noffsets[n++] = block & (indirect_blocks - 1);\r\n} else {\r\n;\r\n}\r\nreturn n;\r\n}\r\nstatic inline int block_to_cpu(struct sysv_sb_info *sbi, sysv_zone_t nr)\r\n{\r\nreturn sbi->s_block_base + fs32_to_cpu(sbi, nr);\r\n}\r\nstatic inline void add_chain(Indirect *p, struct buffer_head *bh, sysv_zone_t *v)\r\n{\r\np->key = *(p->p = v);\r\np->bh = bh;\r\n}\r\nstatic inline int verify_chain(Indirect *from, Indirect *to)\r\n{\r\nwhile (from <= to && from->key == *from->p)\r\nfrom++;\r\nreturn (from > to);\r\n}\r\nstatic inline sysv_zone_t *block_end(struct buffer_head *bh)\r\n{\r\nreturn (sysv_zone_t*)((char*)bh->b_data + bh->b_size);\r\n}\r\nstatic Indirect *get_branch(struct inode *inode,\r\nint depth,\r\nint offsets[],\r\nIndirect chain[],\r\nint *err)\r\n{\r\nstruct super_block *sb = inode->i_sb;\r\nIndirect *p = chain;\r\nstruct buffer_head *bh;\r\n*err = 0;\r\nadd_chain(chain, NULL, SYSV_I(inode)->i_data + *offsets);\r\nif (!p->key)\r\ngoto no_block;\r\nwhile (--depth) {\r\nint block = block_to_cpu(SYSV_SB(sb), p->key);\r\nbh = sb_bread(sb, block);\r\nif (!bh)\r\ngoto failure;\r\nif (!verify_chain(chain, p))\r\ngoto changed;\r\nadd_chain(++p, bh, (sysv_zone_t*)bh->b_data + *++offsets);\r\nif (!p->key)\r\ngoto no_block;\r\n}\r\nreturn NULL;\r\nchanged:\r\nbrelse(bh);\r\n*err = -EAGAIN;\r\ngoto no_block;\r\nfailure:\r\n*err = -EIO;\r\nno_block:\r\nreturn p;\r\n}\r\nstatic int alloc_branch(struct inode *inode,\r\nint num,\r\nint *offsets,\r\nIndirect *branch)\r\n{\r\nint blocksize = inode->i_sb->s_blocksize;\r\nint n = 0;\r\nint i;\r\nbranch[0].key = sysv_new_block(inode->i_sb);\r\nif (branch[0].key) for (n = 1; n < num; n++) {\r\nstruct buffer_head *bh;\r\nint parent;\r\nbranch[n].key = sysv_new_block(inode->i_sb);\r\nif (!branch[n].key)\r\nbreak;\r\nparent = block_to_cpu(SYSV_SB(inode->i_sb), branch[n-1].key);\r\nbh = sb_getblk(inode->i_sb, parent);\r\nlock_buffer(bh);\r\nmemset(bh->b_data, 0, blocksize);\r\nbranch[n].bh = bh;\r\nbranch[n].p = (sysv_zone_t*) bh->b_data + offsets[n];\r\n*branch[n].p = branch[n].key;\r\nset_buffer_uptodate(bh);\r\nunlock_buffer(bh);\r\ndirty_indirect(bh, inode);\r\n}\r\nif (n == num)\r\nreturn 0;\r\nfor (i = 1; i < n; i++)\r\nbforget(branch[i].bh);\r\nfor (i = 0; i < n; i++)\r\nsysv_free_block(inode->i_sb, branch[i].key);\r\nreturn -ENOSPC;\r\n}\r\nstatic inline int splice_branch(struct inode *inode,\r\nIndirect chain[],\r\nIndirect *where,\r\nint num)\r\n{\r\nint i;\r\nwrite_lock(&pointers_lock);\r\nif (!verify_chain(chain, where-1) || *where->p)\r\ngoto changed;\r\n*where->p = where->key;\r\nwrite_unlock(&pointers_lock);\r\ninode->i_ctime = CURRENT_TIME_SEC;\r\nif (where->bh)\r\ndirty_indirect(where->bh, inode);\r\nif (IS_SYNC(inode))\r\nsysv_sync_inode(inode);\r\nelse\r\nmark_inode_dirty(inode);\r\nreturn 0;\r\nchanged:\r\nwrite_unlock(&pointers_lock);\r\nfor (i = 1; i < num; i++)\r\nbforget(where[i].bh);\r\nfor (i = 0; i < num; i++)\r\nsysv_free_block(inode->i_sb, where[i].key);\r\nreturn -EAGAIN;\r\n}\r\nstatic int get_block(struct inode *inode, sector_t iblock, struct buffer_head *bh_result, int create)\r\n{\r\nint err = -EIO;\r\nint offsets[DEPTH];\r\nIndirect chain[DEPTH];\r\nstruct super_block *sb = inode->i_sb;\r\nIndirect *partial;\r\nint left;\r\nint depth = block_to_path(inode, iblock, offsets);\r\nif (depth == 0)\r\ngoto out;\r\nreread:\r\nread_lock(&pointers_lock);\r\npartial = get_branch(inode, depth, offsets, chain, &err);\r\nread_unlock(&pointers_lock);\r\nif (!partial) {\r\ngot_it:\r\nmap_bh(bh_result, sb, block_to_cpu(SYSV_SB(sb),\r\nchain[depth-1].key));\r\npartial = chain+depth-1;\r\ngoto cleanup;\r\n}\r\nif (!create || err == -EIO) {\r\ncleanup:\r\nwhile (partial > chain) {\r\nbrelse(partial->bh);\r\npartial--;\r\n}\r\nout:\r\nreturn err;\r\n}\r\nif (err == -EAGAIN)\r\ngoto changed;\r\nleft = (chain + depth) - partial;\r\nerr = alloc_branch(inode, left, offsets+(partial-chain), partial);\r\nif (err)\r\ngoto cleanup;\r\nif (splice_branch(inode, chain, partial, left) < 0)\r\ngoto changed;\r\nset_buffer_new(bh_result);\r\ngoto got_it;\r\nchanged:\r\nwhile (partial > chain) {\r\nbrelse(partial->bh);\r\npartial--;\r\n}\r\ngoto reread;\r\n}\r\nstatic inline int all_zeroes(sysv_zone_t *p, sysv_zone_t *q)\r\n{\r\nwhile (p < q)\r\nif (*p++)\r\nreturn 0;\r\nreturn 1;\r\n}\r\nstatic Indirect *find_shared(struct inode *inode,\r\nint depth,\r\nint offsets[],\r\nIndirect chain[],\r\nsysv_zone_t *top)\r\n{\r\nIndirect *partial, *p;\r\nint k, err;\r\n*top = 0;\r\nfor (k = depth; k > 1 && !offsets[k-1]; k--)\r\n;\r\nwrite_lock(&pointers_lock);\r\npartial = get_branch(inode, k, offsets, chain, &err);\r\nif (!partial)\r\npartial = chain + k-1;\r\nif (!partial->key && *partial->p) {\r\nwrite_unlock(&pointers_lock);\r\ngoto no_top;\r\n}\r\nfor (p=partial; p>chain && all_zeroes((sysv_zone_t*)p->bh->b_data,p->p); p--)\r\n;\r\nif (p == chain + k - 1 && p > chain) {\r\np->p--;\r\n} else {\r\n*top = *p->p;\r\n*p->p = 0;\r\n}\r\nwrite_unlock(&pointers_lock);\r\nwhile (partial > p) {\r\nbrelse(partial->bh);\r\npartial--;\r\n}\r\nno_top:\r\nreturn partial;\r\n}\r\nstatic inline void free_data(struct inode *inode, sysv_zone_t *p, sysv_zone_t *q)\r\n{\r\nfor ( ; p < q ; p++) {\r\nsysv_zone_t nr = *p;\r\nif (nr) {\r\n*p = 0;\r\nsysv_free_block(inode->i_sb, nr);\r\nmark_inode_dirty(inode);\r\n}\r\n}\r\n}\r\nstatic void free_branches(struct inode *inode, sysv_zone_t *p, sysv_zone_t *q, int depth)\r\n{\r\nstruct buffer_head * bh;\r\nstruct super_block *sb = inode->i_sb;\r\nif (depth--) {\r\nfor ( ; p < q ; p++) {\r\nint block;\r\nsysv_zone_t nr = *p;\r\nif (!nr)\r\ncontinue;\r\n*p = 0;\r\nblock = block_to_cpu(SYSV_SB(sb), nr);\r\nbh = sb_bread(sb, block);\r\nif (!bh)\r\ncontinue;\r\nfree_branches(inode, (sysv_zone_t*)bh->b_data,\r\nblock_end(bh), depth);\r\nbforget(bh);\r\nsysv_free_block(sb, nr);\r\nmark_inode_dirty(inode);\r\n}\r\n} else\r\nfree_data(inode, p, q);\r\n}\r\nvoid sysv_truncate (struct inode * inode)\r\n{\r\nsysv_zone_t *i_data = SYSV_I(inode)->i_data;\r\nint offsets[DEPTH];\r\nIndirect chain[DEPTH];\r\nIndirect *partial;\r\nsysv_zone_t nr = 0;\r\nint n;\r\nlong iblock;\r\nunsigned blocksize;\r\nif (!(S_ISREG(inode->i_mode) || S_ISDIR(inode->i_mode) ||\r\nS_ISLNK(inode->i_mode)))\r\nreturn;\r\nblocksize = inode->i_sb->s_blocksize;\r\niblock = (inode->i_size + blocksize-1)\r\n>> inode->i_sb->s_blocksize_bits;\r\nblock_truncate_page(inode->i_mapping, inode->i_size, get_block);\r\nn = block_to_path(inode, iblock, offsets);\r\nif (n == 0)\r\nreturn;\r\nif (n == 1) {\r\nfree_data(inode, i_data+offsets[0], i_data + DIRECT);\r\ngoto do_indirects;\r\n}\r\npartial = find_shared(inode, n, offsets, chain, &nr);\r\nif (nr) {\r\nif (partial == chain)\r\nmark_inode_dirty(inode);\r\nelse\r\ndirty_indirect(partial->bh, inode);\r\nfree_branches(inode, &nr, &nr+1, (chain+n-1) - partial);\r\n}\r\nwhile (partial > chain) {\r\nfree_branches(inode, partial->p + 1, block_end(partial->bh),\r\n(chain+n-1) - partial);\r\ndirty_indirect(partial->bh, inode);\r\nbrelse (partial->bh);\r\npartial--;\r\n}\r\ndo_indirects:\r\nwhile (n < DEPTH) {\r\nnr = i_data[DIRECT + n - 1];\r\nif (nr) {\r\ni_data[DIRECT + n - 1] = 0;\r\nmark_inode_dirty(inode);\r\nfree_branches(inode, &nr, &nr+1, n);\r\n}\r\nn++;\r\n}\r\ninode->i_mtime = inode->i_ctime = CURRENT_TIME_SEC;\r\nif (IS_SYNC(inode))\r\nsysv_sync_inode (inode);\r\nelse\r\nmark_inode_dirty(inode);\r\n}\r\nstatic unsigned sysv_nblocks(struct super_block *s, loff_t size)\r\n{\r\nstruct sysv_sb_info *sbi = SYSV_SB(s);\r\nint ptrs_bits = sbi->s_ind_per_block_bits;\r\nunsigned blocks, res, direct = DIRECT, i = DEPTH;\r\nblocks = (size + s->s_blocksize - 1) >> s->s_blocksize_bits;\r\nres = blocks;\r\nwhile (--i && blocks > direct) {\r\nblocks = ((blocks - direct - 1) >> ptrs_bits) + 1;\r\nres += blocks;\r\ndirect = 1;\r\n}\r\nreturn blocks;\r\n}\r\nint sysv_getattr(struct vfsmount *mnt, struct dentry *dentry, struct kstat *stat)\r\n{\r\nstruct super_block *s = dentry->d_sb;\r\ngeneric_fillattr(dentry->d_inode, stat);\r\nstat->blocks = (s->s_blocksize / 512) * sysv_nblocks(s, stat->size);\r\nstat->blksize = s->s_blocksize;\r\nreturn 0;\r\n}\r\nstatic int sysv_writepage(struct page *page, struct writeback_control *wbc)\r\n{\r\nreturn block_write_full_page(page,get_block,wbc);\r\n}\r\nstatic int sysv_readpage(struct file *file, struct page *page)\r\n{\r\nreturn block_read_full_page(page,get_block);\r\n}\r\nint sysv_prepare_chunk(struct page *page, loff_t pos, unsigned len)\r\n{\r\nreturn __block_write_begin(page, pos, len, get_block);\r\n}\r\nstatic void sysv_write_failed(struct address_space *mapping, loff_t to)\r\n{\r\nstruct inode *inode = mapping->host;\r\nif (to > inode->i_size) {\r\ntruncate_pagecache(inode, to, inode->i_size);\r\nsysv_truncate(inode);\r\n}\r\n}\r\nstatic int sysv_write_begin(struct file *file, struct address_space *mapping,\r\nloff_t pos, unsigned len, unsigned flags,\r\nstruct page **pagep, void **fsdata)\r\n{\r\nint ret;\r\nret = block_write_begin(mapping, pos, len, flags, pagep, get_block);\r\nif (unlikely(ret))\r\nsysv_write_failed(mapping, pos + len);\r\nreturn ret;\r\n}\r\nstatic sector_t sysv_bmap(struct address_space *mapping, sector_t block)\r\n{\r\nreturn generic_block_bmap(mapping,block,get_block);\r\n}
