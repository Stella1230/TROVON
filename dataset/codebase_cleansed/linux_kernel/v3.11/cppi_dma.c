static inline void cpu_drain_writebuffer(void)\r\n{\r\nwmb();\r\n#ifdef CONFIG_CPU_ARM926T\r\nasm("mcr p15, 0, r0, c7, c10, 4 @ drain write buffer\n");\r\n#endif\r\n}\r\nstatic inline struct cppi_descriptor *cppi_bd_alloc(struct cppi_channel *c)\r\n{\r\nstruct cppi_descriptor *bd = c->freelist;\r\nif (bd)\r\nc->freelist = bd->next;\r\nreturn bd;\r\n}\r\nstatic inline void\r\ncppi_bd_free(struct cppi_channel *c, struct cppi_descriptor *bd)\r\n{\r\nif (!bd)\r\nreturn;\r\nbd->next = c->freelist;\r\nc->freelist = bd;\r\n}\r\nstatic void cppi_reset_rx(struct cppi_rx_stateram __iomem *rx)\r\n{\r\nmusb_writel(&rx->rx_skipbytes, 0, 0);\r\nmusb_writel(&rx->rx_head, 0, 0);\r\nmusb_writel(&rx->rx_sop, 0, 0);\r\nmusb_writel(&rx->rx_current, 0, 0);\r\nmusb_writel(&rx->rx_buf_current, 0, 0);\r\nmusb_writel(&rx->rx_len_len, 0, 0);\r\nmusb_writel(&rx->rx_cnt_cnt, 0, 0);\r\n}\r\nstatic void cppi_reset_tx(struct cppi_tx_stateram __iomem *tx, u32 ptr)\r\n{\r\nmusb_writel(&tx->tx_head, 0, 0);\r\nmusb_writel(&tx->tx_buf, 0, 0);\r\nmusb_writel(&tx->tx_current, 0, 0);\r\nmusb_writel(&tx->tx_buf_current, 0, 0);\r\nmusb_writel(&tx->tx_info, 0, 0);\r\nmusb_writel(&tx->tx_rem_len, 0, 0);\r\nmusb_writel(&tx->tx_complete, 0, ptr);\r\n}\r\nstatic void cppi_pool_init(struct cppi *cppi, struct cppi_channel *c)\r\n{\r\nint j;\r\nc->head = NULL;\r\nc->tail = NULL;\r\nc->last_processed = NULL;\r\nc->channel.status = MUSB_DMA_STATUS_UNKNOWN;\r\nc->controller = cppi;\r\nc->is_rndis = 0;\r\nc->freelist = NULL;\r\nfor (j = 0; j < NUM_TXCHAN_BD + 1; j++) {\r\nstruct cppi_descriptor *bd;\r\ndma_addr_t dma;\r\nbd = dma_pool_alloc(cppi->pool, GFP_KERNEL, &dma);\r\nbd->dma = dma;\r\ncppi_bd_free(c, bd);\r\n}\r\n}\r\nstatic void cppi_pool_free(struct cppi_channel *c)\r\n{\r\nstruct cppi *cppi = c->controller;\r\nstruct cppi_descriptor *bd;\r\n(void) cppi_channel_abort(&c->channel);\r\nc->channel.status = MUSB_DMA_STATUS_UNKNOWN;\r\nc->controller = NULL;\r\nbd = c->last_processed;\r\ndo {\r\nif (bd)\r\ndma_pool_free(cppi->pool, bd, bd->dma);\r\nbd = cppi_bd_alloc(c);\r\n} while (bd);\r\nc->last_processed = NULL;\r\n}\r\nstatic int cppi_controller_start(struct dma_controller *c)\r\n{\r\nstruct cppi *controller;\r\nvoid __iomem *tibase;\r\nint i;\r\ncontroller = container_of(c, struct cppi, controller);\r\nfor (i = 0; i < ARRAY_SIZE(controller->tx); i++) {\r\ncontroller->tx[i].transmit = true;\r\ncontroller->tx[i].index = i;\r\n}\r\nfor (i = 0; i < ARRAY_SIZE(controller->rx); i++) {\r\ncontroller->rx[i].transmit = false;\r\ncontroller->rx[i].index = i;\r\n}\r\nfor (i = 0; i < ARRAY_SIZE(controller->tx); i++)\r\ncppi_pool_init(controller, controller->tx + i);\r\nfor (i = 0; i < ARRAY_SIZE(controller->rx); i++)\r\ncppi_pool_init(controller, controller->rx + i);\r\ntibase = controller->tibase;\r\nINIT_LIST_HEAD(&controller->tx_complete);\r\nfor (i = 0; i < ARRAY_SIZE(controller->tx); i++) {\r\nstruct cppi_channel *tx_ch = controller->tx + i;\r\nstruct cppi_tx_stateram __iomem *tx;\r\nINIT_LIST_HEAD(&tx_ch->tx_complete);\r\ntx = tibase + DAVINCI_TXCPPI_STATERAM_OFFSET(i);\r\ntx_ch->state_ram = tx;\r\ncppi_reset_tx(tx, 0);\r\n}\r\nfor (i = 0; i < ARRAY_SIZE(controller->rx); i++) {\r\nstruct cppi_channel *rx_ch = controller->rx + i;\r\nstruct cppi_rx_stateram __iomem *rx;\r\nINIT_LIST_HEAD(&rx_ch->tx_complete);\r\nrx = tibase + DAVINCI_RXCPPI_STATERAM_OFFSET(i);\r\nrx_ch->state_ram = rx;\r\ncppi_reset_rx(rx);\r\n}\r\nmusb_writel(tibase, DAVINCI_TXCPPI_INTENAB_REG,\r\nDAVINCI_DMA_ALL_CHANNELS_ENABLE);\r\nmusb_writel(tibase, DAVINCI_RXCPPI_INTENAB_REG,\r\nDAVINCI_DMA_ALL_CHANNELS_ENABLE);\r\nmusb_writel(tibase, DAVINCI_TXCPPI_CTRL_REG, DAVINCI_DMA_CTRL_ENABLE);\r\nmusb_writel(tibase, DAVINCI_RXCPPI_CTRL_REG, DAVINCI_DMA_CTRL_ENABLE);\r\nmusb_writel(tibase, DAVINCI_RNDIS_REG, 0);\r\nmusb_writel(tibase, DAVINCI_AUTOREQ_REG, 0);\r\nreturn 0;\r\n}\r\nstatic int cppi_controller_stop(struct dma_controller *c)\r\n{\r\nstruct cppi *controller;\r\nvoid __iomem *tibase;\r\nint i;\r\nstruct musb *musb;\r\ncontroller = container_of(c, struct cppi, controller);\r\nmusb = controller->musb;\r\ntibase = controller->tibase;\r\nmusb_writel(tibase, DAVINCI_TXCPPI_INTCLR_REG,\r\nDAVINCI_DMA_ALL_CHANNELS_ENABLE);\r\nmusb_writel(tibase, DAVINCI_RXCPPI_INTCLR_REG,\r\nDAVINCI_DMA_ALL_CHANNELS_ENABLE);\r\ndev_dbg(musb->controller, "Tearing down RX and TX Channels\n");\r\nfor (i = 0; i < ARRAY_SIZE(controller->tx); i++) {\r\ncontroller->tx[i].last_processed = NULL;\r\ncppi_pool_free(controller->tx + i);\r\n}\r\nfor (i = 0; i < ARRAY_SIZE(controller->rx); i++)\r\ncppi_pool_free(controller->rx + i);\r\nmusb_writel(tibase, DAVINCI_TXCPPI_CTRL_REG, DAVINCI_DMA_CTRL_DISABLE);\r\nmusb_writel(tibase, DAVINCI_RXCPPI_CTRL_REG, DAVINCI_DMA_CTRL_DISABLE);\r\nreturn 0;\r\n}\r\nstatic inline void core_rxirq_disable(void __iomem *tibase, unsigned epnum)\r\n{\r\nmusb_writel(tibase, DAVINCI_USB_INT_MASK_CLR_REG, 1 << (epnum + 8));\r\n}\r\nstatic inline void core_rxirq_enable(void __iomem *tibase, unsigned epnum)\r\n{\r\nmusb_writel(tibase, DAVINCI_USB_INT_MASK_SET_REG, 1 << (epnum + 8));\r\n}\r\nstatic struct dma_channel *\r\ncppi_channel_allocate(struct dma_controller *c,\r\nstruct musb_hw_ep *ep, u8 transmit)\r\n{\r\nstruct cppi *controller;\r\nu8 index;\r\nstruct cppi_channel *cppi_ch;\r\nvoid __iomem *tibase;\r\nstruct musb *musb;\r\ncontroller = container_of(c, struct cppi, controller);\r\ntibase = controller->tibase;\r\nmusb = controller->musb;\r\nindex = ep->epnum - 1;\r\nif (transmit) {\r\nif (index >= ARRAY_SIZE(controller->tx)) {\r\ndev_dbg(musb->controller, "no %cX%d CPPI channel\n", 'T', index);\r\nreturn NULL;\r\n}\r\ncppi_ch = controller->tx + index;\r\n} else {\r\nif (index >= ARRAY_SIZE(controller->rx)) {\r\ndev_dbg(musb->controller, "no %cX%d CPPI channel\n", 'R', index);\r\nreturn NULL;\r\n}\r\ncppi_ch = controller->rx + index;\r\ncore_rxirq_disable(tibase, ep->epnum);\r\n}\r\nif (cppi_ch->hw_ep)\r\ndev_dbg(musb->controller, "re-allocating DMA%d %cX channel %p\n",\r\nindex, transmit ? 'T' : 'R', cppi_ch);\r\ncppi_ch->hw_ep = ep;\r\ncppi_ch->channel.status = MUSB_DMA_STATUS_FREE;\r\ncppi_ch->channel.max_len = 0x7fffffff;\r\ndev_dbg(musb->controller, "Allocate CPPI%d %cX\n", index, transmit ? 'T' : 'R');\r\nreturn &cppi_ch->channel;\r\n}\r\nstatic void cppi_channel_release(struct dma_channel *channel)\r\n{\r\nstruct cppi_channel *c;\r\nvoid __iomem *tibase;\r\nc = container_of(channel, struct cppi_channel, channel);\r\ntibase = c->controller->tibase;\r\nif (!c->hw_ep)\r\ndev_dbg(c->controller->musb->controller,\r\n"releasing idle DMA channel %p\n", c);\r\nelse if (!c->transmit)\r\ncore_rxirq_enable(tibase, c->index + 1);\r\nc->hw_ep = NULL;\r\nchannel->status = MUSB_DMA_STATUS_UNKNOWN;\r\n}\r\nstatic void\r\ncppi_dump_rx(int level, struct cppi_channel *c, const char *tag)\r\n{\r\nvoid __iomem *base = c->controller->mregs;\r\nstruct cppi_rx_stateram __iomem *rx = c->state_ram;\r\nmusb_ep_select(base, c->index + 1);\r\ndev_dbg(c->controller->musb->controller,\r\n"RX DMA%d%s: %d left, csr %04x, "\r\n"%08x H%08x S%08x C%08x, "\r\n"B%08x L%08x %08x .. %08x"\r\n"\n",\r\nc->index, tag,\r\nmusb_readl(c->controller->tibase,\r\nDAVINCI_RXCPPI_BUFCNT0_REG + 4 * c->index),\r\nmusb_readw(c->hw_ep->regs, MUSB_RXCSR),\r\nmusb_readl(&rx->rx_skipbytes, 0),\r\nmusb_readl(&rx->rx_head, 0),\r\nmusb_readl(&rx->rx_sop, 0),\r\nmusb_readl(&rx->rx_current, 0),\r\nmusb_readl(&rx->rx_buf_current, 0),\r\nmusb_readl(&rx->rx_len_len, 0),\r\nmusb_readl(&rx->rx_cnt_cnt, 0),\r\nmusb_readl(&rx->rx_complete, 0)\r\n);\r\n}\r\nstatic void\r\ncppi_dump_tx(int level, struct cppi_channel *c, const char *tag)\r\n{\r\nvoid __iomem *base = c->controller->mregs;\r\nstruct cppi_tx_stateram __iomem *tx = c->state_ram;\r\nmusb_ep_select(base, c->index + 1);\r\ndev_dbg(c->controller->musb->controller,\r\n"TX DMA%d%s: csr %04x, "\r\n"H%08x S%08x C%08x %08x, "\r\n"F%08x L%08x .. %08x"\r\n"\n",\r\nc->index, tag,\r\nmusb_readw(c->hw_ep->regs, MUSB_TXCSR),\r\nmusb_readl(&tx->tx_head, 0),\r\nmusb_readl(&tx->tx_buf, 0),\r\nmusb_readl(&tx->tx_current, 0),\r\nmusb_readl(&tx->tx_buf_current, 0),\r\nmusb_readl(&tx->tx_info, 0),\r\nmusb_readl(&tx->tx_rem_len, 0),\r\nmusb_readl(&tx->tx_complete, 0)\r\n);\r\n}\r\nstatic inline void\r\ncppi_rndis_update(struct cppi_channel *c, int is_rx,\r\nvoid __iomem *tibase, int is_rndis)\r\n{\r\nif (c->is_rndis != is_rndis) {\r\nu32 value = musb_readl(tibase, DAVINCI_RNDIS_REG);\r\nu32 temp = 1 << (c->index);\r\nif (is_rx)\r\ntemp <<= 16;\r\nif (is_rndis)\r\nvalue |= temp;\r\nelse\r\nvalue &= ~temp;\r\nmusb_writel(tibase, DAVINCI_RNDIS_REG, value);\r\nc->is_rndis = is_rndis;\r\n}\r\n}\r\nstatic void cppi_dump_rxbd(const char *tag, struct cppi_descriptor *bd)\r\n{\r\npr_debug("RXBD/%s %08x: "\r\n"nxt %08x buf %08x off.blen %08x opt.plen %08x\n",\r\ntag, bd->dma,\r\nbd->hw_next, bd->hw_bufp, bd->hw_off_len,\r\nbd->hw_options);\r\n}\r\nstatic void cppi_dump_rxq(int level, const char *tag, struct cppi_channel *rx)\r\n{\r\nstruct cppi_descriptor *bd;\r\ncppi_dump_rx(level, rx, tag);\r\nif (rx->last_processed)\r\ncppi_dump_rxbd("last", rx->last_processed);\r\nfor (bd = rx->head; bd; bd = bd->next)\r\ncppi_dump_rxbd("active", bd);\r\n}\r\nstatic inline int cppi_autoreq_update(struct cppi_channel *rx,\r\nvoid __iomem *tibase, int onepacket, unsigned n_bds)\r\n{\r\nu32 val;\r\n#ifdef RNDIS_RX_IS_USABLE\r\nu32 tmp;\r\ntmp = musb_readl(tibase, DAVINCI_AUTOREQ_REG);\r\nval = tmp & ~((0x3) << (rx->index * 2));\r\nif (!onepacket) {\r\n#if 0\r\nval |= ((0x3) << (rx->index * 2));\r\nn_bds--;\r\n#else\r\nval |= ((0x1) << (rx->index * 2));\r\n#endif\r\n}\r\nif (val != tmp) {\r\nint n = 100;\r\nmusb_writel(tibase, DAVINCI_AUTOREQ_REG, val);\r\ndo {\r\ntmp = musb_readl(tibase, DAVINCI_AUTOREQ_REG);\r\nif (tmp == val)\r\nbreak;\r\ncpu_relax();\r\n} while (n-- > 0);\r\n}\r\n#endif\r\nif (n_bds && rx->channel.actual_len) {\r\nvoid __iomem *regs = rx->hw_ep->regs;\r\nval = musb_readw(regs, MUSB_RXCSR);\r\nif (!(val & MUSB_RXCSR_H_REQPKT)) {\r\nval |= MUSB_RXCSR_H_REQPKT | MUSB_RXCSR_H_WZC_BITS;\r\nmusb_writew(regs, MUSB_RXCSR, val);\r\nval = musb_readw(regs, MUSB_RXCSR);\r\n}\r\n}\r\nreturn n_bds;\r\n}\r\nstatic void\r\ncppi_next_tx_segment(struct musb *musb, struct cppi_channel *tx)\r\n{\r\nunsigned maxpacket = tx->maxpacket;\r\ndma_addr_t addr = tx->buf_dma + tx->offset;\r\nsize_t length = tx->buf_len - tx->offset;\r\nstruct cppi_descriptor *bd;\r\nunsigned n_bds;\r\nunsigned i;\r\nstruct cppi_tx_stateram __iomem *tx_ram = tx->state_ram;\r\nint rndis;\r\nrndis = (maxpacket & 0x3f) == 0\r\n&& length > maxpacket\r\n&& length < 0xffff\r\n&& (length % maxpacket) != 0;\r\nif (rndis) {\r\nmaxpacket = length;\r\nn_bds = 1;\r\n} else {\r\nn_bds = length / maxpacket;\r\nif (!length || (length % maxpacket))\r\nn_bds++;\r\nn_bds = min(n_bds, (unsigned) NUM_TXCHAN_BD);\r\nlength = min(n_bds * maxpacket, length);\r\n}\r\ndev_dbg(musb->controller, "TX DMA%d, pktSz %d %s bds %d dma 0x%llx len %u\n",\r\ntx->index,\r\nmaxpacket,\r\nrndis ? "rndis" : "transparent",\r\nn_bds,\r\n(unsigned long long)addr, length);\r\ncppi_rndis_update(tx, 0, musb->ctrl_base, rndis);\r\nbd = tx->freelist;\r\ntx->head = bd;\r\ntx->last_processed = NULL;\r\nfor (i = 0; i < n_bds; ) {\r\nif (++i < n_bds && bd->next)\r\nbd->hw_next = bd->next->dma;\r\nelse\r\nbd->hw_next = 0;\r\nbd->hw_bufp = tx->buf_dma + tx->offset;\r\nif ((tx->offset + maxpacket) <= tx->buf_len) {\r\ntx->offset += maxpacket;\r\nbd->hw_off_len = maxpacket;\r\nbd->hw_options = CPPI_SOP_SET | CPPI_EOP_SET\r\n| CPPI_OWN_SET | maxpacket;\r\n} else {\r\nu32 partial_len;\r\npartial_len = tx->buf_len - tx->offset;\r\ntx->offset = tx->buf_len;\r\nbd->hw_off_len = partial_len;\r\nbd->hw_options = CPPI_SOP_SET | CPPI_EOP_SET\r\n| CPPI_OWN_SET | partial_len;\r\nif (partial_len == 0)\r\nbd->hw_options |= CPPI_ZERO_SET;\r\n}\r\ndev_dbg(musb->controller, "TXBD %p: nxt %08x buf %08x len %04x opt %08x\n",\r\nbd, bd->hw_next, bd->hw_bufp,\r\nbd->hw_off_len, bd->hw_options);\r\ntx->tail = bd;\r\nbd = bd->next;\r\n}\r\ncpu_drain_writebuffer();\r\nmusb_writel(&tx_ram->tx_head, 0, (u32)tx->freelist->dma);\r\ncppi_dump_tx(5, tx, "/S");\r\n}\r\nstatic void\r\ncppi_next_rx_segment(struct musb *musb, struct cppi_channel *rx, int onepacket)\r\n{\r\nunsigned maxpacket = rx->maxpacket;\r\ndma_addr_t addr = rx->buf_dma + rx->offset;\r\nsize_t length = rx->buf_len - rx->offset;\r\nstruct cppi_descriptor *bd, *tail;\r\nunsigned n_bds;\r\nunsigned i;\r\nvoid __iomem *tibase = musb->ctrl_base;\r\nint is_rndis = 0;\r\nstruct cppi_rx_stateram __iomem *rx_ram = rx->state_ram;\r\nstruct cppi_descriptor *d;\r\nif (onepacket) {\r\nn_bds = 1;\r\nif (cppi_rx_rndis\r\n&& is_peripheral_active(musb)\r\n&& length > maxpacket\r\n&& (length & ~0xffff) == 0\r\n&& (length & 0x0fff) != 0\r\n&& (length & (maxpacket - 1)) == 0) {\r\nmaxpacket = length;\r\nis_rndis = 1;\r\n}\r\n} else {\r\nif (length > 0xffff) {\r\nn_bds = 0xffff / maxpacket;\r\nlength = n_bds * maxpacket;\r\n} else {\r\nn_bds = length / maxpacket;\r\nif (length % maxpacket)\r\nn_bds++;\r\n}\r\nif (n_bds == 1)\r\nonepacket = 1;\r\nelse\r\nn_bds = min(n_bds, (unsigned) NUM_RXCHAN_BD);\r\n}\r\nif (is_host_active(musb))\r\nn_bds = cppi_autoreq_update(rx, tibase, onepacket, n_bds);\r\ncppi_rndis_update(rx, 1, musb->ctrl_base, is_rndis);\r\nlength = min(n_bds * maxpacket, length);\r\ndev_dbg(musb->controller, "RX DMA%d seg, maxp %d %s bds %d (cnt %d) "\r\n"dma 0x%llx len %u %u/%u\n",\r\nrx->index, maxpacket,\r\nonepacket\r\n? (is_rndis ? "rndis" : "onepacket")\r\n: "multipacket",\r\nn_bds,\r\nmusb_readl(tibase,\r\nDAVINCI_RXCPPI_BUFCNT0_REG + (rx->index * 4))\r\n& 0xffff,\r\n(unsigned long long)addr, length,\r\nrx->channel.actual_len, rx->buf_len);\r\nbd = cppi_bd_alloc(rx);\r\nrx->head = bd;\r\nfor (i = 0, tail = NULL; bd && i < n_bds; i++, tail = bd) {\r\nu32 bd_len;\r\nif (i) {\r\nbd = cppi_bd_alloc(rx);\r\nif (!bd)\r\nbreak;\r\ntail->next = bd;\r\ntail->hw_next = bd->dma;\r\n}\r\nbd->hw_next = 0;\r\nif (maxpacket < length)\r\nbd_len = maxpacket;\r\nelse\r\nbd_len = length;\r\nbd->hw_bufp = addr;\r\naddr += bd_len;\r\nrx->offset += bd_len;\r\nbd->hw_off_len = (0 << 16) + bd_len;\r\nbd->buflen = bd_len;\r\nbd->hw_options = CPPI_OWN_SET | (i == 0 ? length : 0);\r\nlength -= bd_len;\r\n}\r\nif (!tail) {\r\nWARNING("rx dma%d -- no BDs? need %d\n", rx->index, n_bds);\r\nreturn;\r\n} else if (i < n_bds)\r\nWARNING("rx dma%d -- only %d of %d BDs\n", rx->index, i, n_bds);\r\ntail->next = NULL;\r\ntail->hw_next = 0;\r\nbd = rx->head;\r\nrx->tail = tail;\r\nbd->hw_options |= CPPI_SOP_SET;\r\ntail->hw_options |= CPPI_EOP_SET;\r\nfor (d = rx->head; d; d = d->next)\r\ncppi_dump_rxbd("S", d);\r\ntail = rx->last_processed;\r\nif (tail) {\r\ntail->next = bd;\r\ntail->hw_next = bd->dma;\r\n}\r\ncore_rxirq_enable(tibase, rx->index + 1);\r\ncpu_drain_writebuffer();\r\nmusb_writel(&rx_ram->rx_head, 0, bd->dma);\r\ni = musb_readl(tibase,\r\nDAVINCI_RXCPPI_BUFCNT0_REG + (rx->index * 4))\r\n& 0xffff;\r\nif (!i)\r\nmusb_writel(tibase,\r\nDAVINCI_RXCPPI_BUFCNT0_REG + (rx->index * 4),\r\nn_bds + 2);\r\nelse if (n_bds > (i - 3))\r\nmusb_writel(tibase,\r\nDAVINCI_RXCPPI_BUFCNT0_REG + (rx->index * 4),\r\nn_bds - (i - 3));\r\ni = musb_readl(tibase,\r\nDAVINCI_RXCPPI_BUFCNT0_REG + (rx->index * 4))\r\n& 0xffff;\r\nif (i < (2 + n_bds)) {\r\ndev_dbg(musb->controller, "bufcnt%d underrun - %d (for %d)\n",\r\nrx->index, i, n_bds);\r\nmusb_writel(tibase,\r\nDAVINCI_RXCPPI_BUFCNT0_REG + (rx->index * 4),\r\nn_bds + 2);\r\n}\r\ncppi_dump_rx(4, rx, "/S");\r\n}\r\nstatic int cppi_channel_program(struct dma_channel *ch,\r\nu16 maxpacket, u8 mode,\r\ndma_addr_t dma_addr, u32 len)\r\n{\r\nstruct cppi_channel *cppi_ch;\r\nstruct cppi *controller;\r\nstruct musb *musb;\r\ncppi_ch = container_of(ch, struct cppi_channel, channel);\r\ncontroller = cppi_ch->controller;\r\nmusb = controller->musb;\r\nswitch (ch->status) {\r\ncase MUSB_DMA_STATUS_BUS_ABORT:\r\ncase MUSB_DMA_STATUS_CORE_ABORT:\r\nWARNING("%cX DMA%d not cleaned up after abort!\n",\r\ncppi_ch->transmit ? 'T' : 'R',\r\ncppi_ch->index);\r\nbreak;\r\ncase MUSB_DMA_STATUS_BUSY:\r\nWARNING("program active channel? %cX DMA%d\n",\r\ncppi_ch->transmit ? 'T' : 'R',\r\ncppi_ch->index);\r\nbreak;\r\ncase MUSB_DMA_STATUS_UNKNOWN:\r\ndev_dbg(musb->controller, "%cX DMA%d not allocated!\n",\r\ncppi_ch->transmit ? 'T' : 'R',\r\ncppi_ch->index);\r\ncase MUSB_DMA_STATUS_FREE:\r\nbreak;\r\n}\r\nch->status = MUSB_DMA_STATUS_BUSY;\r\ncppi_ch->buf_dma = dma_addr;\r\ncppi_ch->offset = 0;\r\ncppi_ch->maxpacket = maxpacket;\r\ncppi_ch->buf_len = len;\r\ncppi_ch->channel.actual_len = 0;\r\nif (cppi_ch->transmit)\r\ncppi_next_tx_segment(musb, cppi_ch);\r\nelse\r\ncppi_next_rx_segment(musb, cppi_ch, mode);\r\nreturn true;\r\n}\r\nstatic bool cppi_rx_scan(struct cppi *cppi, unsigned ch)\r\n{\r\nstruct cppi_channel *rx = &cppi->rx[ch];\r\nstruct cppi_rx_stateram __iomem *state = rx->state_ram;\r\nstruct cppi_descriptor *bd;\r\nstruct cppi_descriptor *last = rx->last_processed;\r\nbool completed = false;\r\nbool acked = false;\r\nint i;\r\ndma_addr_t safe2ack;\r\nvoid __iomem *regs = rx->hw_ep->regs;\r\nstruct musb *musb = cppi->musb;\r\ncppi_dump_rx(6, rx, "/K");\r\nbd = last ? last->next : rx->head;\r\nif (!bd)\r\nreturn false;\r\nfor (i = 0, safe2ack = musb_readl(&state->rx_complete, 0);\r\n(safe2ack || completed) && bd && i < NUM_RXCHAN_BD;\r\ni++, bd = bd->next) {\r\nu16 len;\r\nrmb();\r\nif (!completed && (bd->hw_options & CPPI_OWN_SET))\r\nbreak;\r\ndev_dbg(musb->controller, "C/RXBD %llx: nxt %08x buf %08x "\r\n"off.len %08x opt.len %08x (%d)\n",\r\n(unsigned long long)bd->dma, bd->hw_next, bd->hw_bufp,\r\nbd->hw_off_len, bd->hw_options,\r\nrx->channel.actual_len);\r\nif ((bd->hw_options & CPPI_SOP_SET) && !completed)\r\nlen = bd->hw_off_len & CPPI_RECV_PKTLEN_MASK;\r\nelse\r\nlen = 0;\r\nif (bd->hw_options & CPPI_EOQ_MASK)\r\ncompleted = true;\r\nif (!completed && len < bd->buflen) {\r\ncompleted = true;\r\ndev_dbg(musb->controller, "rx short %d/%d (%d)\n",\r\nlen, bd->buflen,\r\nrx->channel.actual_len);\r\n}\r\nif (bd->dma == safe2ack) {\r\nmusb_writel(&state->rx_complete, 0, safe2ack);\r\nsafe2ack = musb_readl(&state->rx_complete, 0);\r\nacked = true;\r\nif (bd->dma == safe2ack)\r\nsafe2ack = 0;\r\n}\r\nrx->channel.actual_len += len;\r\ncppi_bd_free(rx, last);\r\nlast = bd;\r\nif (bd->hw_next == 0)\r\ncompleted = true;\r\n}\r\nrx->last_processed = last;\r\nif (!acked && last) {\r\nint csr;\r\nif (safe2ack == 0 || safe2ack == rx->last_processed->dma)\r\nmusb_writel(&state->rx_complete, 0, safe2ack);\r\nif (safe2ack == 0) {\r\ncppi_bd_free(rx, last);\r\nrx->last_processed = NULL;\r\nWARN_ON(rx->head);\r\n}\r\nmusb_ep_select(cppi->mregs, rx->index + 1);\r\ncsr = musb_readw(regs, MUSB_RXCSR);\r\nif (csr & MUSB_RXCSR_DMAENAB) {\r\ndev_dbg(musb->controller, "list%d %p/%p, last %llx%s, csr %04x\n",\r\nrx->index,\r\nrx->head, rx->tail,\r\nrx->last_processed\r\n? (unsigned long long)\r\nrx->last_processed->dma\r\n: 0,\r\ncompleted ? ", completed" : "",\r\ncsr);\r\ncppi_dump_rxq(4, "/what?", rx);\r\n}\r\n}\r\nif (!completed) {\r\nint csr;\r\nrx->head = bd;\r\ncsr = musb_readw(rx->hw_ep->regs, MUSB_RXCSR);\r\nif (is_host_active(cppi->musb)\r\n&& bd\r\n&& !(csr & MUSB_RXCSR_H_REQPKT)) {\r\ncsr |= MUSB_RXCSR_H_REQPKT;\r\nmusb_writew(regs, MUSB_RXCSR,\r\nMUSB_RXCSR_H_WZC_BITS | csr);\r\ncsr = musb_readw(rx->hw_ep->regs, MUSB_RXCSR);\r\n}\r\n} else {\r\nrx->head = NULL;\r\nrx->tail = NULL;\r\n}\r\ncppi_dump_rx(6, rx, completed ? "/completed" : "/cleaned");\r\nreturn completed;\r\n}\r\nirqreturn_t cppi_interrupt(int irq, void *dev_id)\r\n{\r\nstruct musb *musb = dev_id;\r\nstruct cppi *cppi;\r\nvoid __iomem *tibase;\r\nstruct musb_hw_ep *hw_ep = NULL;\r\nu32 rx, tx;\r\nint i, index;\r\nunsigned long uninitialized_var(flags);\r\ncppi = container_of(musb->dma_controller, struct cppi, controller);\r\nif (cppi->irq)\r\nspin_lock_irqsave(&musb->lock, flags);\r\ntibase = musb->ctrl_base;\r\ntx = musb_readl(tibase, DAVINCI_TXCPPI_MASKED_REG);\r\nrx = musb_readl(tibase, DAVINCI_RXCPPI_MASKED_REG);\r\nif (!tx && !rx) {\r\nif (cppi->irq)\r\nspin_unlock_irqrestore(&musb->lock, flags);\r\nreturn IRQ_NONE;\r\n}\r\ndev_dbg(musb->controller, "CPPI IRQ Tx%x Rx%x\n", tx, rx);\r\nfor (index = 0; tx; tx = tx >> 1, index++) {\r\nstruct cppi_channel *tx_ch;\r\nstruct cppi_tx_stateram __iomem *tx_ram;\r\nbool completed = false;\r\nstruct cppi_descriptor *bd;\r\nif (!(tx & 1))\r\ncontinue;\r\ntx_ch = cppi->tx + index;\r\ntx_ram = tx_ch->state_ram;\r\ncppi_dump_tx(5, tx_ch, "/E");\r\nbd = tx_ch->head;\r\nif (NULL == bd) {\r\ndev_dbg(musb->controller, "null BD\n");\r\nmusb_writel(&tx_ram->tx_complete, 0, 0);\r\ncontinue;\r\n}\r\nfor (i = 0; !completed && bd && i < NUM_TXCHAN_BD;\r\ni++, bd = bd->next) {\r\nu16 len;\r\nrmb();\r\nif (bd->hw_options & CPPI_OWN_SET)\r\nbreak;\r\ndev_dbg(musb->controller, "C/TXBD %p n %x b %x off %x opt %x\n",\r\nbd, bd->hw_next, bd->hw_bufp,\r\nbd->hw_off_len, bd->hw_options);\r\nlen = bd->hw_off_len & CPPI_BUFFER_LEN_MASK;\r\ntx_ch->channel.actual_len += len;\r\ntx_ch->last_processed = bd;\r\nmusb_writel(&tx_ram->tx_complete, 0, bd->dma);\r\nif (bd->hw_next == 0)\r\ncompleted = true;\r\n}\r\nif (completed) {\r\nif (tx_ch->offset >= tx_ch->buf_len) {\r\ntx_ch->head = NULL;\r\ntx_ch->tail = NULL;\r\ntx_ch->channel.status = MUSB_DMA_STATUS_FREE;\r\nhw_ep = tx_ch->hw_ep;\r\nmusb_dma_completion(musb, index + 1, 1);\r\n} else {\r\ncppi_next_tx_segment(musb, tx_ch);\r\n}\r\n} else\r\ntx_ch->head = bd;\r\n}\r\nfor (index = 0; rx; rx = rx >> 1, index++) {\r\nif (rx & 1) {\r\nstruct cppi_channel *rx_ch;\r\nrx_ch = cppi->rx + index;\r\nif (!cppi_rx_scan(cppi, index))\r\ncontinue;\r\nif (rx_ch->channel.actual_len != rx_ch->buf_len\r\n&& rx_ch->channel.actual_len\r\n== rx_ch->offset) {\r\ncppi_next_rx_segment(musb, rx_ch, 1);\r\ncontinue;\r\n}\r\nrx_ch->channel.status = MUSB_DMA_STATUS_FREE;\r\nhw_ep = rx_ch->hw_ep;\r\ncore_rxirq_disable(tibase, index + 1);\r\nmusb_dma_completion(musb, index + 1, 0);\r\n}\r\n}\r\nmusb_writel(tibase, DAVINCI_CPPI_EOI_REG, 0);\r\nif (cppi->irq)\r\nspin_unlock_irqrestore(&musb->lock, flags);\r\nreturn IRQ_HANDLED;\r\n}\r\nstruct dma_controller *dma_controller_create(struct musb *musb, void __iomem *mregs)\r\n{\r\nstruct cppi *controller;\r\nstruct device *dev = musb->controller;\r\nstruct platform_device *pdev = to_platform_device(dev);\r\nint irq = platform_get_irq_byname(pdev, "dma");\r\ncontroller = kzalloc(sizeof *controller, GFP_KERNEL);\r\nif (!controller)\r\nreturn NULL;\r\ncontroller->mregs = mregs;\r\ncontroller->tibase = mregs - DAVINCI_BASE_OFFSET;\r\ncontroller->musb = musb;\r\ncontroller->controller.start = cppi_controller_start;\r\ncontroller->controller.stop = cppi_controller_stop;\r\ncontroller->controller.channel_alloc = cppi_channel_allocate;\r\ncontroller->controller.channel_release = cppi_channel_release;\r\ncontroller->controller.channel_program = cppi_channel_program;\r\ncontroller->controller.channel_abort = cppi_channel_abort;\r\ncontroller->pool = dma_pool_create("cppi",\r\ncontroller->musb->controller,\r\nsizeof(struct cppi_descriptor),\r\nCPPI_DESCRIPTOR_ALIGN, 0);\r\nif (!controller->pool) {\r\nkfree(controller);\r\nreturn NULL;\r\n}\r\nif (irq > 0) {\r\nif (request_irq(irq, cppi_interrupt, 0, "cppi-dma", musb)) {\r\ndev_err(dev, "request_irq %d failed!\n", irq);\r\ndma_controller_destroy(&controller->controller);\r\nreturn NULL;\r\n}\r\ncontroller->irq = irq;\r\n}\r\nreturn &controller->controller;\r\n}\r\nvoid dma_controller_destroy(struct dma_controller *c)\r\n{\r\nstruct cppi *cppi;\r\ncppi = container_of(c, struct cppi, controller);\r\nif (cppi->irq)\r\nfree_irq(cppi->irq, cppi->musb);\r\ndma_pool_destroy(cppi->pool);\r\nkfree(cppi);\r\n}\r\nstatic int cppi_channel_abort(struct dma_channel *channel)\r\n{\r\nstruct cppi_channel *cppi_ch;\r\nstruct cppi *controller;\r\nvoid __iomem *mbase;\r\nvoid __iomem *tibase;\r\nvoid __iomem *regs;\r\nu32 value;\r\nstruct cppi_descriptor *queue;\r\ncppi_ch = container_of(channel, struct cppi_channel, channel);\r\ncontroller = cppi_ch->controller;\r\nswitch (channel->status) {\r\ncase MUSB_DMA_STATUS_BUS_ABORT:\r\ncase MUSB_DMA_STATUS_CORE_ABORT:\r\ncase MUSB_DMA_STATUS_BUSY:\r\nregs = cppi_ch->hw_ep->regs;\r\nbreak;\r\ncase MUSB_DMA_STATUS_UNKNOWN:\r\ncase MUSB_DMA_STATUS_FREE:\r\nreturn 0;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nif (!cppi_ch->transmit && cppi_ch->head)\r\ncppi_dump_rxq(3, "/abort", cppi_ch);\r\nmbase = controller->mregs;\r\ntibase = controller->tibase;\r\nqueue = cppi_ch->head;\r\ncppi_ch->head = NULL;\r\ncppi_ch->tail = NULL;\r\nmusb_ep_select(mbase, cppi_ch->index + 1);\r\nif (cppi_ch->transmit) {\r\nstruct cppi_tx_stateram __iomem *tx_ram;\r\ncppi_dump_tx(6, cppi_ch, " (teardown)");\r\ndo {\r\nvalue = musb_readl(tibase, DAVINCI_TXCPPI_TEAR_REG);\r\n} while (!(value & CPPI_TEAR_READY));\r\nmusb_writel(tibase, DAVINCI_TXCPPI_TEAR_REG, cppi_ch->index);\r\ntx_ram = cppi_ch->state_ram;\r\ndo {\r\nvalue = musb_readl(&tx_ram->tx_complete, 0);\r\n} while (0xFFFFFFFC != value);\r\nvalue = musb_readw(regs, MUSB_TXCSR);\r\nvalue &= ~MUSB_TXCSR_DMAENAB;\r\nvalue |= MUSB_TXCSR_FLUSHFIFO;\r\nmusb_writew(regs, MUSB_TXCSR, value);\r\nmusb_writew(regs, MUSB_TXCSR, value);\r\ncppi_reset_tx(tx_ram, 1);\r\ncppi_ch->head = NULL;\r\nmusb_writel(&tx_ram->tx_complete, 0, 1);\r\ncppi_dump_tx(5, cppi_ch, " (done teardown)");\r\n} else {\r\nu16 csr;\r\ncore_rxirq_disable(tibase, cppi_ch->index + 1);\r\nif (is_host_active(cppi_ch->controller->musb)) {\r\nvalue = musb_readl(tibase, DAVINCI_AUTOREQ_REG);\r\nvalue &= ~((0x3) << (cppi_ch->index * 2));\r\nmusb_writel(tibase, DAVINCI_AUTOREQ_REG, value);\r\n}\r\ncsr = musb_readw(regs, MUSB_RXCSR);\r\nif (is_host_active(cppi_ch->controller->musb)) {\r\ncsr |= MUSB_RXCSR_H_WZC_BITS;\r\ncsr &= ~MUSB_RXCSR_H_REQPKT;\r\n} else\r\ncsr |= MUSB_RXCSR_P_WZC_BITS;\r\ncsr &= ~(MUSB_RXCSR_DMAENAB);\r\nmusb_writew(regs, MUSB_RXCSR, csr);\r\ncsr = musb_readw(regs, MUSB_RXCSR);\r\nif (channel->status == MUSB_DMA_STATUS_BUSY)\r\nudelay(50);\r\ncppi_rx_scan(controller, cppi_ch->index);\r\ncppi_reset_rx(cppi_ch->state_ram);\r\ncppi_dump_rx(5, cppi_ch, " (done abort)");\r\ncppi_bd_free(cppi_ch, cppi_ch->last_processed);\r\ncppi_ch->last_processed = NULL;\r\nwhile (queue) {\r\nstruct cppi_descriptor *tmp = queue->next;\r\ncppi_bd_free(cppi_ch, queue);\r\nqueue = tmp;\r\n}\r\n}\r\nchannel->status = MUSB_DMA_STATUS_FREE;\r\ncppi_ch->buf_dma = 0;\r\ncppi_ch->offset = 0;\r\ncppi_ch->buf_len = 0;\r\ncppi_ch->maxpacket = 0;\r\nreturn 0;\r\n}
