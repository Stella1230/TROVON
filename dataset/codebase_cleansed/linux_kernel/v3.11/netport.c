static unsigned int sel_netport_hashfn(u16 pnum)\r\n{\r\nreturn (pnum & (SEL_NETPORT_HASH_SIZE - 1));\r\n}\r\nstatic struct sel_netport *sel_netport_find(u8 protocol, u16 pnum)\r\n{\r\nunsigned int idx;\r\nstruct sel_netport *port;\r\nidx = sel_netport_hashfn(pnum);\r\nlist_for_each_entry_rcu(port, &sel_netport_hash[idx].list, list)\r\nif (port->psec.port == pnum && port->psec.protocol == protocol)\r\nreturn port;\r\nreturn NULL;\r\n}\r\nstatic void sel_netport_insert(struct sel_netport *port)\r\n{\r\nunsigned int idx;\r\nidx = sel_netport_hashfn(port->psec.port);\r\nlist_add_rcu(&port->list, &sel_netport_hash[idx].list);\r\nif (sel_netport_hash[idx].size == SEL_NETPORT_HASH_BKT_LIMIT) {\r\nstruct sel_netport *tail;\r\ntail = list_entry(\r\nrcu_dereference_protected(\r\nsel_netport_hash[idx].list.prev,\r\nlockdep_is_held(&sel_netport_lock)),\r\nstruct sel_netport, list);\r\nlist_del_rcu(&tail->list);\r\nkfree_rcu(tail, rcu);\r\n} else\r\nsel_netport_hash[idx].size++;\r\n}\r\nstatic int sel_netport_sid_slow(u8 protocol, u16 pnum, u32 *sid)\r\n{\r\nint ret = -ENOMEM;\r\nstruct sel_netport *port;\r\nstruct sel_netport *new = NULL;\r\nspin_lock_bh(&sel_netport_lock);\r\nport = sel_netport_find(protocol, pnum);\r\nif (port != NULL) {\r\n*sid = port->psec.sid;\r\nspin_unlock_bh(&sel_netport_lock);\r\nreturn 0;\r\n}\r\nnew = kzalloc(sizeof(*new), GFP_ATOMIC);\r\nif (new == NULL)\r\ngoto out;\r\nret = security_port_sid(protocol, pnum, sid);\r\nif (ret != 0)\r\ngoto out;\r\nnew->psec.port = pnum;\r\nnew->psec.protocol = protocol;\r\nnew->psec.sid = *sid;\r\nsel_netport_insert(new);\r\nout:\r\nspin_unlock_bh(&sel_netport_lock);\r\nif (unlikely(ret)) {\r\nprintk(KERN_WARNING\r\n"SELinux: failure in sel_netport_sid_slow(),"\r\n" unable to determine network port label\n");\r\nkfree(new);\r\n}\r\nreturn ret;\r\n}\r\nint sel_netport_sid(u8 protocol, u16 pnum, u32 *sid)\r\n{\r\nstruct sel_netport *port;\r\nrcu_read_lock();\r\nport = sel_netport_find(protocol, pnum);\r\nif (port != NULL) {\r\n*sid = port->psec.sid;\r\nrcu_read_unlock();\r\nreturn 0;\r\n}\r\nrcu_read_unlock();\r\nreturn sel_netport_sid_slow(protocol, pnum, sid);\r\n}\r\nstatic void sel_netport_flush(void)\r\n{\r\nunsigned int idx;\r\nstruct sel_netport *port, *port_tmp;\r\nspin_lock_bh(&sel_netport_lock);\r\nfor (idx = 0; idx < SEL_NETPORT_HASH_SIZE; idx++) {\r\nlist_for_each_entry_safe(port, port_tmp,\r\n&sel_netport_hash[idx].list, list) {\r\nlist_del_rcu(&port->list);\r\nkfree_rcu(port, rcu);\r\n}\r\nsel_netport_hash[idx].size = 0;\r\n}\r\nspin_unlock_bh(&sel_netport_lock);\r\n}\r\nstatic int sel_netport_avc_callback(u32 event)\r\n{\r\nif (event == AVC_CALLBACK_RESET) {\r\nsel_netport_flush();\r\nsynchronize_net();\r\n}\r\nreturn 0;\r\n}\r\nstatic __init int sel_netport_init(void)\r\n{\r\nint iter;\r\nint ret;\r\nif (!selinux_enabled)\r\nreturn 0;\r\nfor (iter = 0; iter < SEL_NETPORT_HASH_SIZE; iter++) {\r\nINIT_LIST_HEAD(&sel_netport_hash[iter].list);\r\nsel_netport_hash[iter].size = 0;\r\n}\r\nret = avc_add_callback(sel_netport_avc_callback, AVC_CALLBACK_RESET);\r\nif (ret != 0)\r\npanic("avc_add_callback() failed, error %d\n", ret);\r\nreturn ret;\r\n}
