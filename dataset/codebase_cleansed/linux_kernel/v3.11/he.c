static __inline__ void\r\nhe_writel_internal(struct he_dev *he_dev, unsigned val, unsigned addr,\r\nunsigned flags)\r\n{\r\nhe_writel(he_dev, val, CON_DAT);\r\n(void) he_readl(he_dev, CON_DAT);\r\nhe_writel(he_dev, flags | CON_CTL_WRITE | CON_CTL_ADDR(addr), CON_CTL);\r\nwhile (he_readl(he_dev, CON_CTL) & CON_CTL_BUSY);\r\n}\r\nstatic unsigned\r\nhe_readl_internal(struct he_dev *he_dev, unsigned addr, unsigned flags)\r\n{\r\nhe_writel(he_dev, flags | CON_CTL_READ | CON_CTL_ADDR(addr), CON_CTL);\r\nwhile (he_readl(he_dev, CON_CTL) & CON_CTL_BUSY);\r\nreturn he_readl(he_dev, CON_DAT);\r\n}\r\nint he_init_one(struct pci_dev *pci_dev,\r\nconst struct pci_device_id *pci_ent)\r\n{\r\nstruct atm_dev *atm_dev = NULL;\r\nstruct he_dev *he_dev = NULL;\r\nint err = 0;\r\nprintk(KERN_INFO "ATM he driver\n");\r\nif (pci_enable_device(pci_dev))\r\nreturn -EIO;\r\nif (pci_set_dma_mask(pci_dev, DMA_BIT_MASK(32)) != 0) {\r\nprintk(KERN_WARNING "he: no suitable dma available\n");\r\nerr = -EIO;\r\ngoto init_one_failure;\r\n}\r\natm_dev = atm_dev_register(DEV_LABEL, &pci_dev->dev, &he_ops, -1, NULL);\r\nif (!atm_dev) {\r\nerr = -ENODEV;\r\ngoto init_one_failure;\r\n}\r\npci_set_drvdata(pci_dev, atm_dev);\r\nhe_dev = kzalloc(sizeof(struct he_dev),\r\nGFP_KERNEL);\r\nif (!he_dev) {\r\nerr = -ENOMEM;\r\ngoto init_one_failure;\r\n}\r\nhe_dev->pci_dev = pci_dev;\r\nhe_dev->atm_dev = atm_dev;\r\nhe_dev->atm_dev->dev_data = he_dev;\r\natm_dev->dev_data = he_dev;\r\nhe_dev->number = atm_dev->number;\r\ntasklet_init(&he_dev->tasklet, he_tasklet, (unsigned long) he_dev);\r\nspin_lock_init(&he_dev->global_lock);\r\nif (he_start(atm_dev)) {\r\nhe_stop(he_dev);\r\nerr = -ENODEV;\r\ngoto init_one_failure;\r\n}\r\nhe_dev->next = NULL;\r\nif (he_devs)\r\nhe_dev->next = he_devs;\r\nhe_devs = he_dev;\r\nreturn 0;\r\ninit_one_failure:\r\nif (atm_dev)\r\natm_dev_deregister(atm_dev);\r\nkfree(he_dev);\r\npci_disable_device(pci_dev);\r\nreturn err;\r\n}\r\nstatic void he_remove_one(struct pci_dev *pci_dev)\r\n{\r\nstruct atm_dev *atm_dev;\r\nstruct he_dev *he_dev;\r\natm_dev = pci_get_drvdata(pci_dev);\r\nhe_dev = HE_DEV(atm_dev);\r\nhe_stop(he_dev);\r\natm_dev_deregister(atm_dev);\r\nkfree(he_dev);\r\npci_set_drvdata(pci_dev, NULL);\r\npci_disable_device(pci_dev);\r\n}\r\nstatic unsigned\r\nrate_to_atmf(unsigned rate)\r\n{\r\n#define NONZERO (1 << 14)\r\nunsigned exp = 0;\r\nif (rate == 0)\r\nreturn 0;\r\nrate <<= 9;\r\nwhile (rate > 0x3ff) {\r\n++exp;\r\nrate >>= 1;\r\n}\r\nreturn (NONZERO | (exp << 9) | (rate & 0x1ff));\r\n}\r\nstatic void he_init_rx_lbfp0(struct he_dev *he_dev)\r\n{\r\nunsigned i, lbm_offset, lbufd_index, lbuf_addr, lbuf_count;\r\nunsigned lbufs_per_row = he_dev->cells_per_row / he_dev->cells_per_lbuf;\r\nunsigned lbuf_bufsize = he_dev->cells_per_lbuf * ATM_CELL_PAYLOAD;\r\nunsigned row_offset = he_dev->r0_startrow * he_dev->bytes_per_row;\r\nlbufd_index = 0;\r\nlbm_offset = he_readl(he_dev, RCMLBM_BA);\r\nhe_writel(he_dev, lbufd_index, RLBF0_H);\r\nfor (i = 0, lbuf_count = 0; i < he_dev->r0_numbuffs; ++i) {\r\nlbufd_index += 2;\r\nlbuf_addr = (row_offset + (lbuf_count * lbuf_bufsize)) / 32;\r\nhe_writel_rcm(he_dev, lbuf_addr, lbm_offset);\r\nhe_writel_rcm(he_dev, lbufd_index, lbm_offset + 1);\r\nif (++lbuf_count == lbufs_per_row) {\r\nlbuf_count = 0;\r\nrow_offset += he_dev->bytes_per_row;\r\n}\r\nlbm_offset += 4;\r\n}\r\nhe_writel(he_dev, lbufd_index - 2, RLBF0_T);\r\nhe_writel(he_dev, he_dev->r0_numbuffs, RLBF0_C);\r\n}\r\nstatic void he_init_rx_lbfp1(struct he_dev *he_dev)\r\n{\r\nunsigned i, lbm_offset, lbufd_index, lbuf_addr, lbuf_count;\r\nunsigned lbufs_per_row = he_dev->cells_per_row / he_dev->cells_per_lbuf;\r\nunsigned lbuf_bufsize = he_dev->cells_per_lbuf * ATM_CELL_PAYLOAD;\r\nunsigned row_offset = he_dev->r1_startrow * he_dev->bytes_per_row;\r\nlbufd_index = 1;\r\nlbm_offset = he_readl(he_dev, RCMLBM_BA) + (2 * lbufd_index);\r\nhe_writel(he_dev, lbufd_index, RLBF1_H);\r\nfor (i = 0, lbuf_count = 0; i < he_dev->r1_numbuffs; ++i) {\r\nlbufd_index += 2;\r\nlbuf_addr = (row_offset + (lbuf_count * lbuf_bufsize)) / 32;\r\nhe_writel_rcm(he_dev, lbuf_addr, lbm_offset);\r\nhe_writel_rcm(he_dev, lbufd_index, lbm_offset + 1);\r\nif (++lbuf_count == lbufs_per_row) {\r\nlbuf_count = 0;\r\nrow_offset += he_dev->bytes_per_row;\r\n}\r\nlbm_offset += 4;\r\n}\r\nhe_writel(he_dev, lbufd_index - 2, RLBF1_T);\r\nhe_writel(he_dev, he_dev->r1_numbuffs, RLBF1_C);\r\n}\r\nstatic void he_init_tx_lbfp(struct he_dev *he_dev)\r\n{\r\nunsigned i, lbm_offset, lbufd_index, lbuf_addr, lbuf_count;\r\nunsigned lbufs_per_row = he_dev->cells_per_row / he_dev->cells_per_lbuf;\r\nunsigned lbuf_bufsize = he_dev->cells_per_lbuf * ATM_CELL_PAYLOAD;\r\nunsigned row_offset = he_dev->tx_startrow * he_dev->bytes_per_row;\r\nlbufd_index = he_dev->r0_numbuffs + he_dev->r1_numbuffs;\r\nlbm_offset = he_readl(he_dev, RCMLBM_BA) + (2 * lbufd_index);\r\nhe_writel(he_dev, lbufd_index, TLBF_H);\r\nfor (i = 0, lbuf_count = 0; i < he_dev->tx_numbuffs; ++i) {\r\nlbufd_index += 1;\r\nlbuf_addr = (row_offset + (lbuf_count * lbuf_bufsize)) / 32;\r\nhe_writel_rcm(he_dev, lbuf_addr, lbm_offset);\r\nhe_writel_rcm(he_dev, lbufd_index, lbm_offset + 1);\r\nif (++lbuf_count == lbufs_per_row) {\r\nlbuf_count = 0;\r\nrow_offset += he_dev->bytes_per_row;\r\n}\r\nlbm_offset += 2;\r\n}\r\nhe_writel(he_dev, lbufd_index - 1, TLBF_T);\r\n}\r\nstatic int he_init_tpdrq(struct he_dev *he_dev)\r\n{\r\nhe_dev->tpdrq_base = pci_alloc_consistent(he_dev->pci_dev,\r\nCONFIG_TPDRQ_SIZE * sizeof(struct he_tpdrq), &he_dev->tpdrq_phys);\r\nif (he_dev->tpdrq_base == NULL) {\r\nhprintk("failed to alloc tpdrq\n");\r\nreturn -ENOMEM;\r\n}\r\nmemset(he_dev->tpdrq_base, 0,\r\nCONFIG_TPDRQ_SIZE * sizeof(struct he_tpdrq));\r\nhe_dev->tpdrq_tail = he_dev->tpdrq_base;\r\nhe_dev->tpdrq_head = he_dev->tpdrq_base;\r\nhe_writel(he_dev, he_dev->tpdrq_phys, TPDRQ_B_H);\r\nhe_writel(he_dev, 0, TPDRQ_T);\r\nhe_writel(he_dev, CONFIG_TPDRQ_SIZE - 1, TPDRQ_S);\r\nreturn 0;\r\n}\r\nstatic void he_init_cs_block(struct he_dev *he_dev)\r\n{\r\nunsigned clock, rate, delta;\r\nint reg;\r\nfor (reg = 0; reg < 0x20; ++reg)\r\nhe_writel_mbox(he_dev, 0x0, CS_STTIM0 + reg);\r\nclock = he_is622(he_dev) ? 66667000 : 50000000;\r\nrate = he_dev->atm_dev->link_rate;\r\ndelta = rate / 16 / 2;\r\nfor (reg = 0; reg < 0x10; ++reg) {\r\nunsigned period = clock / rate;\r\nhe_writel_mbox(he_dev, period, CS_TGRLD0 + reg);\r\nrate -= delta;\r\n}\r\nif (he_is622(he_dev)) {\r\nhe_writel_mbox(he_dev, 0x000800fa, CS_ERTHR0);\r\nhe_writel_mbox(he_dev, 0x000c33cb, CS_ERTHR1);\r\nhe_writel_mbox(he_dev, 0x0010101b, CS_ERTHR2);\r\nhe_writel_mbox(he_dev, 0x00181dac, CS_ERTHR3);\r\nhe_writel_mbox(he_dev, 0x00280600, CS_ERTHR4);\r\nhe_writel_mbox(he_dev, 0x023de8b3, CS_ERCTL0);\r\nhe_writel_mbox(he_dev, 0x1801, CS_ERCTL1);\r\nhe_writel_mbox(he_dev, 0x68b3, CS_ERCTL2);\r\nhe_writel_mbox(he_dev, 0x1280, CS_ERSTAT0);\r\nhe_writel_mbox(he_dev, 0x68b3, CS_ERSTAT1);\r\nhe_writel_mbox(he_dev, 0x14585, CS_RTFWR);\r\nhe_writel_mbox(he_dev, 0x4680, CS_RTATR);\r\nhe_writel_mbox(he_dev, 0x00159ece, CS_TFBSET);\r\nhe_writel_mbox(he_dev, 0x68b3, CS_WCRMAX);\r\nhe_writel_mbox(he_dev, 0x5eb3, CS_WCRMIN);\r\nhe_writel_mbox(he_dev, 0xe8b3, CS_WCRINC);\r\nhe_writel_mbox(he_dev, 0xdeb3, CS_WCRDEC);\r\nhe_writel_mbox(he_dev, 0x68b3, CS_WCRCEIL);\r\nhe_writel_mbox(he_dev, 0x5, CS_OTPPER);\r\nhe_writel_mbox(he_dev, 0x14, CS_OTWPER);\r\n} else {\r\nhe_writel_mbox(he_dev, 0x000400ea, CS_ERTHR0);\r\nhe_writel_mbox(he_dev, 0x00063388, CS_ERTHR1);\r\nhe_writel_mbox(he_dev, 0x00081018, CS_ERTHR2);\r\nhe_writel_mbox(he_dev, 0x000c1dac, CS_ERTHR3);\r\nhe_writel_mbox(he_dev, 0x0014051a, CS_ERTHR4);\r\nhe_writel_mbox(he_dev, 0x0235e4b1, CS_ERCTL0);\r\nhe_writel_mbox(he_dev, 0x4701, CS_ERCTL1);\r\nhe_writel_mbox(he_dev, 0x64b1, CS_ERCTL2);\r\nhe_writel_mbox(he_dev, 0x1280, CS_ERSTAT0);\r\nhe_writel_mbox(he_dev, 0x64b1, CS_ERSTAT1);\r\nhe_writel_mbox(he_dev, 0xf424, CS_RTFWR);\r\nhe_writel_mbox(he_dev, 0x4680, CS_RTATR);\r\nhe_writel_mbox(he_dev, 0x000563b7, CS_TFBSET);\r\nhe_writel_mbox(he_dev, 0x64b1, CS_WCRMAX);\r\nhe_writel_mbox(he_dev, 0x5ab1, CS_WCRMIN);\r\nhe_writel_mbox(he_dev, 0xe4b1, CS_WCRINC);\r\nhe_writel_mbox(he_dev, 0xdab1, CS_WCRDEC);\r\nhe_writel_mbox(he_dev, 0x64b1, CS_WCRCEIL);\r\nhe_writel_mbox(he_dev, 0x6, CS_OTPPER);\r\nhe_writel_mbox(he_dev, 0x1e, CS_OTWPER);\r\n}\r\nhe_writel_mbox(he_dev, 0x8, CS_OTTLIM);\r\nfor (reg = 0; reg < 0x8; ++reg)\r\nhe_writel_mbox(he_dev, 0x0, CS_HGRRT0 + reg);\r\n}\r\nstatic int he_init_cs_block_rcm(struct he_dev *he_dev)\r\n{\r\nunsigned (*rategrid)[16][16];\r\nunsigned rate, delta;\r\nint i, j, reg;\r\nunsigned rate_atmf, exp, man;\r\nunsigned long long rate_cps;\r\nint mult, buf, buf_limit = 4;\r\nrategrid = kmalloc( sizeof(unsigned) * 16 * 16, GFP_KERNEL);\r\nif (!rategrid)\r\nreturn -ENOMEM;\r\nfor (reg = 0x0; reg < 0xff; ++reg)\r\nhe_writel_rcm(he_dev, 0x0, CONFIG_RCMABR + reg);\r\nfor (reg = 0x100; reg < 0x1ff; ++reg)\r\nhe_writel_rcm(he_dev, 0x0, CONFIG_RCMABR + reg);\r\nrate = he_dev->atm_dev->link_rate;\r\ndelta = rate / 32;\r\nfor (j = 0; j < 16; j++) {\r\n(*rategrid)[0][j] = rate;\r\nrate -= delta;\r\n}\r\nfor (i = 1; i < 16; i++)\r\nfor (j = 0; j < 16; j++)\r\nif (i > 14)\r\n(*rategrid)[i][j] = (*rategrid)[i - 1][j] / 4;\r\nelse\r\n(*rategrid)[i][j] = (*rategrid)[i - 1][j] / 2;\r\nrate_atmf = 0;\r\nwhile (rate_atmf < 0x400) {\r\nman = (rate_atmf & 0x1f) << 4;\r\nexp = rate_atmf >> 5;\r\nrate_cps = (unsigned long long) (1 << exp) * (man + 512) >> 9;\r\nif (rate_cps < 10)\r\nrate_cps = 10;\r\nfor (i = 255; i > 0; i--)\r\nif ((*rategrid)[i/16][i%16] >= rate_cps)\r\nbreak;\r\n#ifdef notdef\r\nbuf = rate_cps * he_dev->tx_numbuffs /\r\n(he_dev->atm_dev->link_rate * 2);\r\n#else\r\nmult = he_dev->atm_dev->link_rate / ATM_OC3_PCR;\r\nif (rate_cps > (272 * mult))\r\nbuf = 4;\r\nelse if (rate_cps > (204 * mult))\r\nbuf = 3;\r\nelse if (rate_cps > (136 * mult))\r\nbuf = 2;\r\nelse if (rate_cps > (68 * mult))\r\nbuf = 1;\r\nelse\r\nbuf = 0;\r\n#endif\r\nif (buf > buf_limit)\r\nbuf = buf_limit;\r\nreg = (reg << 16) | ((i << 8) | buf);\r\n#define RTGTBL_OFFSET 0x400\r\nif (rate_atmf & 0x1)\r\nhe_writel_rcm(he_dev, reg,\r\nCONFIG_RCMABR + RTGTBL_OFFSET + (rate_atmf >> 1));\r\n++rate_atmf;\r\n}\r\nkfree(rategrid);\r\nreturn 0;\r\n}\r\nstatic int he_init_group(struct he_dev *he_dev, int group)\r\n{\r\nstruct he_buff *heb, *next;\r\ndma_addr_t mapping;\r\nint i;\r\nhe_writel(he_dev, 0x0, G0_RBPS_S + (group * 32));\r\nhe_writel(he_dev, 0x0, G0_RBPS_T + (group * 32));\r\nhe_writel(he_dev, 0x0, G0_RBPS_QI + (group * 32));\r\nhe_writel(he_dev, RBP_THRESH(0x1) | RBP_QSIZE(0x0),\r\nG0_RBPS_BS + (group * 32));\r\nhe_dev->rbpl_table = kmalloc(BITS_TO_LONGS(RBPL_TABLE_SIZE)\r\n* sizeof(unsigned long), GFP_KERNEL);\r\nif (!he_dev->rbpl_table) {\r\nhprintk("unable to allocate rbpl bitmap table\n");\r\nreturn -ENOMEM;\r\n}\r\nbitmap_zero(he_dev->rbpl_table, RBPL_TABLE_SIZE);\r\nhe_dev->rbpl_virt = kmalloc(RBPL_TABLE_SIZE\r\n* sizeof(struct he_buff *), GFP_KERNEL);\r\nif (!he_dev->rbpl_virt) {\r\nhprintk("unable to allocate rbpl virt table\n");\r\ngoto out_free_rbpl_table;\r\n}\r\nhe_dev->rbpl_pool = pci_pool_create("rbpl", he_dev->pci_dev,\r\nCONFIG_RBPL_BUFSIZE, 64, 0);\r\nif (he_dev->rbpl_pool == NULL) {\r\nhprintk("unable to create rbpl pool\n");\r\ngoto out_free_rbpl_virt;\r\n}\r\nhe_dev->rbpl_base = pci_alloc_consistent(he_dev->pci_dev,\r\nCONFIG_RBPL_SIZE * sizeof(struct he_rbp), &he_dev->rbpl_phys);\r\nif (he_dev->rbpl_base == NULL) {\r\nhprintk("failed to alloc rbpl_base\n");\r\ngoto out_destroy_rbpl_pool;\r\n}\r\nmemset(he_dev->rbpl_base, 0, CONFIG_RBPL_SIZE * sizeof(struct he_rbp));\r\nINIT_LIST_HEAD(&he_dev->rbpl_outstanding);\r\nfor (i = 0; i < CONFIG_RBPL_SIZE; ++i) {\r\nheb = pci_pool_alloc(he_dev->rbpl_pool, GFP_KERNEL|GFP_DMA, &mapping);\r\nif (!heb)\r\ngoto out_free_rbpl;\r\nheb->mapping = mapping;\r\nlist_add(&heb->entry, &he_dev->rbpl_outstanding);\r\nset_bit(i, he_dev->rbpl_table);\r\nhe_dev->rbpl_virt[i] = heb;\r\nhe_dev->rbpl_hint = i + 1;\r\nhe_dev->rbpl_base[i].idx = i << RBP_IDX_OFFSET;\r\nhe_dev->rbpl_base[i].phys = mapping + offsetof(struct he_buff, data);\r\n}\r\nhe_dev->rbpl_tail = &he_dev->rbpl_base[CONFIG_RBPL_SIZE - 1];\r\nhe_writel(he_dev, he_dev->rbpl_phys, G0_RBPL_S + (group * 32));\r\nhe_writel(he_dev, RBPL_MASK(he_dev->rbpl_tail),\r\nG0_RBPL_T + (group * 32));\r\nhe_writel(he_dev, (CONFIG_RBPL_BUFSIZE - sizeof(struct he_buff))/4,\r\nG0_RBPL_BS + (group * 32));\r\nhe_writel(he_dev,\r\nRBP_THRESH(CONFIG_RBPL_THRESH) |\r\nRBP_QSIZE(CONFIG_RBPL_SIZE - 1) |\r\nRBP_INT_ENB,\r\nG0_RBPL_QI + (group * 32));\r\nhe_dev->rbrq_base = pci_alloc_consistent(he_dev->pci_dev,\r\nCONFIG_RBRQ_SIZE * sizeof(struct he_rbrq), &he_dev->rbrq_phys);\r\nif (he_dev->rbrq_base == NULL) {\r\nhprintk("failed to allocate rbrq\n");\r\ngoto out_free_rbpl;\r\n}\r\nmemset(he_dev->rbrq_base, 0, CONFIG_RBRQ_SIZE * sizeof(struct he_rbrq));\r\nhe_dev->rbrq_head = he_dev->rbrq_base;\r\nhe_writel(he_dev, he_dev->rbrq_phys, G0_RBRQ_ST + (group * 16));\r\nhe_writel(he_dev, 0, G0_RBRQ_H + (group * 16));\r\nhe_writel(he_dev,\r\nRBRQ_THRESH(CONFIG_RBRQ_THRESH) | RBRQ_SIZE(CONFIG_RBRQ_SIZE - 1),\r\nG0_RBRQ_Q + (group * 16));\r\nif (irq_coalesce) {\r\nhprintk("coalescing interrupts\n");\r\nhe_writel(he_dev, RBRQ_TIME(768) | RBRQ_COUNT(7),\r\nG0_RBRQ_I + (group * 16));\r\n} else\r\nhe_writel(he_dev, RBRQ_TIME(0) | RBRQ_COUNT(1),\r\nG0_RBRQ_I + (group * 16));\r\nhe_dev->tbrq_base = pci_alloc_consistent(he_dev->pci_dev,\r\nCONFIG_TBRQ_SIZE * sizeof(struct he_tbrq), &he_dev->tbrq_phys);\r\nif (he_dev->tbrq_base == NULL) {\r\nhprintk("failed to allocate tbrq\n");\r\ngoto out_free_rbpq_base;\r\n}\r\nmemset(he_dev->tbrq_base, 0, CONFIG_TBRQ_SIZE * sizeof(struct he_tbrq));\r\nhe_dev->tbrq_head = he_dev->tbrq_base;\r\nhe_writel(he_dev, he_dev->tbrq_phys, G0_TBRQ_B_T + (group * 16));\r\nhe_writel(he_dev, 0, G0_TBRQ_H + (group * 16));\r\nhe_writel(he_dev, CONFIG_TBRQ_SIZE - 1, G0_TBRQ_S + (group * 16));\r\nhe_writel(he_dev, CONFIG_TBRQ_THRESH, G0_TBRQ_THRESH + (group * 16));\r\nreturn 0;\r\nout_free_rbpq_base:\r\npci_free_consistent(he_dev->pci_dev, CONFIG_RBRQ_SIZE *\r\nsizeof(struct he_rbrq), he_dev->rbrq_base,\r\nhe_dev->rbrq_phys);\r\nout_free_rbpl:\r\nlist_for_each_entry_safe(heb, next, &he_dev->rbpl_outstanding, entry)\r\npci_pool_free(he_dev->rbpl_pool, heb, heb->mapping);\r\npci_free_consistent(he_dev->pci_dev, CONFIG_RBPL_SIZE *\r\nsizeof(struct he_rbp), he_dev->rbpl_base,\r\nhe_dev->rbpl_phys);\r\nout_destroy_rbpl_pool:\r\npci_pool_destroy(he_dev->rbpl_pool);\r\nout_free_rbpl_virt:\r\nkfree(he_dev->rbpl_virt);\r\nout_free_rbpl_table:\r\nkfree(he_dev->rbpl_table);\r\nreturn -ENOMEM;\r\n}\r\nstatic int he_init_irq(struct he_dev *he_dev)\r\n{\r\nint i;\r\nhe_dev->irq_base = pci_alloc_consistent(he_dev->pci_dev,\r\n(CONFIG_IRQ_SIZE+1) * sizeof(struct he_irq), &he_dev->irq_phys);\r\nif (he_dev->irq_base == NULL) {\r\nhprintk("failed to allocate irq\n");\r\nreturn -ENOMEM;\r\n}\r\nhe_dev->irq_tailoffset = (unsigned *)\r\n&he_dev->irq_base[CONFIG_IRQ_SIZE];\r\n*he_dev->irq_tailoffset = 0;\r\nhe_dev->irq_head = he_dev->irq_base;\r\nhe_dev->irq_tail = he_dev->irq_base;\r\nfor (i = 0; i < CONFIG_IRQ_SIZE; ++i)\r\nhe_dev->irq_base[i].isw = ITYPE_INVALID;\r\nhe_writel(he_dev, he_dev->irq_phys, IRQ0_BASE);\r\nhe_writel(he_dev,\r\nIRQ_SIZE(CONFIG_IRQ_SIZE) | IRQ_THRESH(CONFIG_IRQ_THRESH),\r\nIRQ0_HEAD);\r\nhe_writel(he_dev, IRQ_INT_A | IRQ_TYPE_LINE, IRQ0_CNTL);\r\nhe_writel(he_dev, 0x0, IRQ0_DATA);\r\nhe_writel(he_dev, 0x0, IRQ1_BASE);\r\nhe_writel(he_dev, 0x0, IRQ1_HEAD);\r\nhe_writel(he_dev, 0x0, IRQ1_CNTL);\r\nhe_writel(he_dev, 0x0, IRQ1_DATA);\r\nhe_writel(he_dev, 0x0, IRQ2_BASE);\r\nhe_writel(he_dev, 0x0, IRQ2_HEAD);\r\nhe_writel(he_dev, 0x0, IRQ2_CNTL);\r\nhe_writel(he_dev, 0x0, IRQ2_DATA);\r\nhe_writel(he_dev, 0x0, IRQ3_BASE);\r\nhe_writel(he_dev, 0x0, IRQ3_HEAD);\r\nhe_writel(he_dev, 0x0, IRQ3_CNTL);\r\nhe_writel(he_dev, 0x0, IRQ3_DATA);\r\nhe_writel(he_dev, 0x0, GRP_10_MAP);\r\nhe_writel(he_dev, 0x0, GRP_32_MAP);\r\nhe_writel(he_dev, 0x0, GRP_54_MAP);\r\nhe_writel(he_dev, 0x0, GRP_76_MAP);\r\nif (request_irq(he_dev->pci_dev->irq,\r\nhe_irq_handler, IRQF_SHARED, DEV_LABEL, he_dev)) {\r\nhprintk("irq %d already in use\n", he_dev->pci_dev->irq);\r\nreturn -EINVAL;\r\n}\r\nhe_dev->irq = he_dev->pci_dev->irq;\r\nreturn 0;\r\n}\r\nstatic int he_start(struct atm_dev *dev)\r\n{\r\nstruct he_dev *he_dev;\r\nstruct pci_dev *pci_dev;\r\nunsigned long membase;\r\nu16 command;\r\nu32 gen_cntl_0, host_cntl, lb_swap;\r\nu8 cache_size, timer;\r\nunsigned err;\r\nunsigned int status, reg;\r\nint i, group;\r\nhe_dev = HE_DEV(dev);\r\npci_dev = he_dev->pci_dev;\r\nmembase = pci_resource_start(pci_dev, 0);\r\nHPRINTK("membase = 0x%lx irq = %d.\n", membase, pci_dev->irq);\r\nif (pci_read_config_dword(pci_dev, GEN_CNTL_0, &gen_cntl_0) != 0) {\r\nhprintk("can't read GEN_CNTL_0\n");\r\nreturn -EINVAL;\r\n}\r\ngen_cntl_0 |= (MRL_ENB | MRM_ENB | IGNORE_TIMEOUT);\r\nif (pci_write_config_dword(pci_dev, GEN_CNTL_0, gen_cntl_0) != 0) {\r\nhprintk("can't write GEN_CNTL_0.\n");\r\nreturn -EINVAL;\r\n}\r\nif (pci_read_config_word(pci_dev, PCI_COMMAND, &command) != 0) {\r\nhprintk("can't read PCI_COMMAND.\n");\r\nreturn -EINVAL;\r\n}\r\ncommand |= (PCI_COMMAND_MEMORY | PCI_COMMAND_MASTER | PCI_COMMAND_INVALIDATE);\r\nif (pci_write_config_word(pci_dev, PCI_COMMAND, command) != 0) {\r\nhprintk("can't enable memory.\n");\r\nreturn -EINVAL;\r\n}\r\nif (pci_read_config_byte(pci_dev, PCI_CACHE_LINE_SIZE, &cache_size)) {\r\nhprintk("can't read cache line size?\n");\r\nreturn -EINVAL;\r\n}\r\nif (cache_size < 16) {\r\ncache_size = 16;\r\nif (pci_write_config_byte(pci_dev, PCI_CACHE_LINE_SIZE, cache_size))\r\nhprintk("can't set cache line size to %d\n", cache_size);\r\n}\r\nif (pci_read_config_byte(pci_dev, PCI_LATENCY_TIMER, &timer)) {\r\nhprintk("can't read latency timer?\n");\r\nreturn -EINVAL;\r\n}\r\n#define LAT_TIMER 209\r\nif (timer < LAT_TIMER) {\r\nHPRINTK("latency timer was %d, setting to %d\n", timer, LAT_TIMER);\r\ntimer = LAT_TIMER;\r\nif (pci_write_config_byte(pci_dev, PCI_LATENCY_TIMER, timer))\r\nhprintk("can't set latency timer to %d\n", timer);\r\n}\r\nif (!(he_dev->membase = ioremap(membase, HE_REGMAP_SIZE))) {\r\nhprintk("can't set up page mapping\n");\r\nreturn -EINVAL;\r\n}\r\nhe_writel(he_dev, 0x0, RESET_CNTL);\r\nhe_writel(he_dev, 0xff, RESET_CNTL);\r\nmsleep(16);\r\nstatus = he_readl(he_dev, RESET_CNTL);\r\nif ((status & BOARD_RST_STATUS) == 0) {\r\nhprintk("reset failed\n");\r\nreturn -EINVAL;\r\n}\r\nhost_cntl = he_readl(he_dev, HOST_CNTL);\r\nif (host_cntl & PCI_BUS_SIZE64)\r\ngen_cntl_0 |= ENBL_64;\r\nelse\r\ngen_cntl_0 &= ~ENBL_64;\r\nif (disable64 == 1) {\r\nhprintk("disabling 64-bit pci bus transfers\n");\r\ngen_cntl_0 &= ~ENBL_64;\r\n}\r\nif (gen_cntl_0 & ENBL_64)\r\nhprintk("64-bit transfers enabled\n");\r\npci_write_config_dword(pci_dev, GEN_CNTL_0, gen_cntl_0);\r\nfor (i = 0; i < PROD_ID_LEN; ++i)\r\nhe_dev->prod_id[i] = read_prom_byte(he_dev, PROD_ID + i);\r\nhe_dev->media = read_prom_byte(he_dev, MEDIA);\r\nfor (i = 0; i < 6; ++i)\r\ndev->esi[i] = read_prom_byte(he_dev, MAC_ADDR + i);\r\nhprintk("%s%s, %x:%x:%x:%x:%x:%x\n",\r\nhe_dev->prod_id,\r\nhe_dev->media & 0x40 ? "SM" : "MM",\r\ndev->esi[0],\r\ndev->esi[1],\r\ndev->esi[2],\r\ndev->esi[3],\r\ndev->esi[4],\r\ndev->esi[5]);\r\nhe_dev->atm_dev->link_rate = he_is622(he_dev) ?\r\nATM_OC12_PCR : ATM_OC3_PCR;\r\nlb_swap = he_readl(he_dev, LB_SWAP);\r\nif (he_is622(he_dev))\r\nlb_swap &= ~XFER_SIZE;\r\nelse\r\nlb_swap |= XFER_SIZE;\r\n#ifdef __BIG_ENDIAN\r\nlb_swap |= DESC_WR_SWAP | INTR_SWAP | BIG_ENDIAN_HOST;\r\n#else\r\nlb_swap &= ~(DESC_WR_SWAP | INTR_SWAP | BIG_ENDIAN_HOST |\r\nDATA_WR_SWAP | DATA_RD_SWAP | DESC_RD_SWAP);\r\n#endif\r\nhe_writel(he_dev, lb_swap, LB_SWAP);\r\nhe_writel(he_dev, he_is622(he_dev) ? LB_64_ENB : 0x0, SDRAM_CTL);\r\nlb_swap |= SWAP_RNUM_MAX(0xf);\r\nhe_writel(he_dev, lb_swap, LB_SWAP);\r\nif ((err = he_init_irq(he_dev)) != 0)\r\nreturn err;\r\nhost_cntl |= (OUTFF_ENB | CMDFF_ENB |\r\nQUICK_RD_RETRY | QUICK_WR_RETRY | PERR_INT_ENB);\r\nhe_writel(he_dev, host_cntl, HOST_CNTL);\r\ngen_cntl_0 |= INT_PROC_ENBL|INIT_ENB;\r\npci_write_config_dword(pci_dev, GEN_CNTL_0, gen_cntl_0);\r\nhe_dev->vcibits = CONFIG_DEFAULT_VCIBITS;\r\nhe_dev->vpibits = CONFIG_DEFAULT_VPIBITS;\r\nif (nvpibits != -1 && nvcibits != -1 && nvpibits+nvcibits != HE_MAXCIDBITS) {\r\nhprintk("nvpibits + nvcibits != %d\n", HE_MAXCIDBITS);\r\nreturn -ENODEV;\r\n}\r\nif (nvpibits != -1) {\r\nhe_dev->vpibits = nvpibits;\r\nhe_dev->vcibits = HE_MAXCIDBITS - nvpibits;\r\n}\r\nif (nvcibits != -1) {\r\nhe_dev->vcibits = nvcibits;\r\nhe_dev->vpibits = HE_MAXCIDBITS - nvcibits;\r\n}\r\nif (he_is622(he_dev)) {\r\nhe_dev->cells_per_row = 40;\r\nhe_dev->bytes_per_row = 2048;\r\nhe_dev->r0_numrows = 256;\r\nhe_dev->tx_numrows = 512;\r\nhe_dev->r1_numrows = 256;\r\nhe_dev->r0_startrow = 0;\r\nhe_dev->tx_startrow = 256;\r\nhe_dev->r1_startrow = 768;\r\n} else {\r\nhe_dev->cells_per_row = 20;\r\nhe_dev->bytes_per_row = 1024;\r\nhe_dev->r0_numrows = 512;\r\nhe_dev->tx_numrows = 1018;\r\nhe_dev->r1_numrows = 512;\r\nhe_dev->r0_startrow = 6;\r\nhe_dev->tx_startrow = 518;\r\nhe_dev->r1_startrow = 1536;\r\n}\r\nhe_dev->cells_per_lbuf = 4;\r\nhe_dev->buffer_limit = 4;\r\nhe_dev->r0_numbuffs = he_dev->r0_numrows *\r\nhe_dev->cells_per_row / he_dev->cells_per_lbuf;\r\nif (he_dev->r0_numbuffs > 2560)\r\nhe_dev->r0_numbuffs = 2560;\r\nhe_dev->r1_numbuffs = he_dev->r1_numrows *\r\nhe_dev->cells_per_row / he_dev->cells_per_lbuf;\r\nif (he_dev->r1_numbuffs > 2560)\r\nhe_dev->r1_numbuffs = 2560;\r\nhe_dev->tx_numbuffs = he_dev->tx_numrows *\r\nhe_dev->cells_per_row / he_dev->cells_per_lbuf;\r\nif (he_dev->tx_numbuffs > 5120)\r\nhe_dev->tx_numbuffs = 5120;\r\nhe_writel(he_dev,\r\nSLICE_X(0x2) | ARB_RNUM_MAX(0xf) | TH_PRTY(0x3) |\r\nRH_PRTY(0x3) | TL_PRTY(0x2) | RL_PRTY(0x1) |\r\n(he_is622(he_dev) ? BUS_MULTI(0x28) : BUS_MULTI(0x46)) |\r\n(he_is622(he_dev) ? NET_PREF(0x50) : NET_PREF(0x8c)),\r\nLBARB);\r\nhe_writel(he_dev, BANK_ON |\r\n(he_is622(he_dev) ? (REF_RATE(0x384) | WIDE_DATA) : REF_RATE(0x150)),\r\nSDRAMCON);\r\nhe_writel(he_dev,\r\n(he_is622(he_dev) ? RM_BANK_WAIT(1) : RM_BANK_WAIT(0)) |\r\nRM_RW_WAIT(1), RCMCONFIG);\r\nhe_writel(he_dev,\r\n(he_is622(he_dev) ? TM_BANK_WAIT(2) : TM_BANK_WAIT(1)) |\r\nTM_RW_WAIT(1), TCMCONFIG);\r\nhe_writel(he_dev, he_dev->cells_per_lbuf * ATM_CELL_PAYLOAD, LB_CONFIG);\r\nhe_writel(he_dev,\r\n(he_is622(he_dev) ? UT_RD_DELAY(8) : UT_RD_DELAY(0)) |\r\n(he_is622(he_dev) ? RC_UT_MODE(0) : RC_UT_MODE(1)) |\r\nRX_VALVP(he_dev->vpibits) |\r\nRX_VALVC(he_dev->vcibits), RC_CONFIG);\r\nhe_writel(he_dev, DRF_THRESH(0x20) |\r\n(he_is622(he_dev) ? TX_UT_MODE(0) : TX_UT_MODE(1)) |\r\nTX_VCI_MASK(he_dev->vcibits) |\r\nLBFREE_CNT(he_dev->tx_numbuffs), TX_CONFIG);\r\nhe_writel(he_dev, 0x0, TXAAL5_PROTO);\r\nhe_writel(he_dev, PHY_INT_ENB |\r\n(he_is622(he_dev) ? PTMR_PRE(67 - 1) : PTMR_PRE(50 - 1)),\r\nRH_CONFIG);\r\nfor (i = 0; i < TCM_MEM_SIZE; ++i)\r\nhe_writel_tcm(he_dev, 0, i);\r\nfor (i = 0; i < RCM_MEM_SIZE; ++i)\r\nhe_writel_rcm(he_dev, 0, i);\r\nhe_writel(he_dev, CONFIG_TSRB, TSRB_BA);\r\nhe_writel(he_dev, CONFIG_TSRC, TSRC_BA);\r\nhe_writel(he_dev, CONFIG_TSRD, TSRD_BA);\r\nhe_writel(he_dev, CONFIG_TMABR, TMABR_BA);\r\nhe_writel(he_dev, CONFIG_TPDBA, TPD_BA);\r\nhe_writel(he_dev, 0x08000, RCMLBM_BA);\r\nhe_writel(he_dev, 0x0e000, RCMRSRB_BA);\r\nhe_writel(he_dev, 0x0d800, RCMABR_BA);\r\nhe_init_rx_lbfp0(he_dev);\r\nhe_init_rx_lbfp1(he_dev);\r\nhe_writel(he_dev, 0x0, RLBC_H);\r\nhe_writel(he_dev, 0x0, RLBC_T);\r\nhe_writel(he_dev, 0x0, RLBC_H2);\r\nhe_writel(he_dev, 512, RXTHRSH);\r\nhe_writel(he_dev, 256, LITHRSH);\r\nhe_init_tx_lbfp(he_dev);\r\nhe_writel(he_dev, he_is622(he_dev) ? 0x104780 : 0x800, UBUFF_BA);\r\nif (he_is622(he_dev)) {\r\nhe_writel(he_dev, 0x000f, G0_INMQ_S);\r\nhe_writel(he_dev, 0x200f, G0_INMQ_L);\r\nhe_writel(he_dev, 0x001f, G1_INMQ_S);\r\nhe_writel(he_dev, 0x201f, G1_INMQ_L);\r\nhe_writel(he_dev, 0x002f, G2_INMQ_S);\r\nhe_writel(he_dev, 0x202f, G2_INMQ_L);\r\nhe_writel(he_dev, 0x003f, G3_INMQ_S);\r\nhe_writel(he_dev, 0x203f, G3_INMQ_L);\r\nhe_writel(he_dev, 0x004f, G4_INMQ_S);\r\nhe_writel(he_dev, 0x204f, G4_INMQ_L);\r\nhe_writel(he_dev, 0x005f, G5_INMQ_S);\r\nhe_writel(he_dev, 0x205f, G5_INMQ_L);\r\nhe_writel(he_dev, 0x006f, G6_INMQ_S);\r\nhe_writel(he_dev, 0x206f, G6_INMQ_L);\r\nhe_writel(he_dev, 0x007f, G7_INMQ_S);\r\nhe_writel(he_dev, 0x207f, G7_INMQ_L);\r\n} else {\r\nhe_writel(he_dev, 0x0000, G0_INMQ_S);\r\nhe_writel(he_dev, 0x0008, G0_INMQ_L);\r\nhe_writel(he_dev, 0x0001, G1_INMQ_S);\r\nhe_writel(he_dev, 0x0009, G1_INMQ_L);\r\nhe_writel(he_dev, 0x0002, G2_INMQ_S);\r\nhe_writel(he_dev, 0x000a, G2_INMQ_L);\r\nhe_writel(he_dev, 0x0003, G3_INMQ_S);\r\nhe_writel(he_dev, 0x000b, G3_INMQ_L);\r\nhe_writel(he_dev, 0x0004, G4_INMQ_S);\r\nhe_writel(he_dev, 0x000c, G4_INMQ_L);\r\nhe_writel(he_dev, 0x0005, G5_INMQ_S);\r\nhe_writel(he_dev, 0x000d, G5_INMQ_L);\r\nhe_writel(he_dev, 0x0006, G6_INMQ_S);\r\nhe_writel(he_dev, 0x000e, G6_INMQ_L);\r\nhe_writel(he_dev, 0x0007, G7_INMQ_S);\r\nhe_writel(he_dev, 0x000f, G7_INMQ_L);\r\n}\r\nhe_writel(he_dev, 0x0, MCC);\r\nhe_writel(he_dev, 0x0, OEC);\r\nhe_writel(he_dev, 0x0, DCC);\r\nhe_writel(he_dev, 0x0, CEC);\r\nhe_init_cs_block(he_dev);\r\nif (he_init_cs_block_rcm(he_dev) < 0)\r\nreturn -ENOMEM;\r\nhe_init_tpdrq(he_dev);\r\nhe_dev->tpd_pool = pci_pool_create("tpd", he_dev->pci_dev,\r\nsizeof(struct he_tpd), TPD_ALIGNMENT, 0);\r\nif (he_dev->tpd_pool == NULL) {\r\nhprintk("unable to create tpd pci_pool\n");\r\nreturn -ENOMEM;\r\n}\r\nINIT_LIST_HEAD(&he_dev->outstanding_tpds);\r\nif (he_init_group(he_dev, 0) != 0)\r\nreturn -ENOMEM;\r\nfor (group = 1; group < HE_NUM_GROUPS; ++group) {\r\nhe_writel(he_dev, 0x0, G0_RBPS_S + (group * 32));\r\nhe_writel(he_dev, 0x0, G0_RBPS_T + (group * 32));\r\nhe_writel(he_dev, 0x0, G0_RBPS_QI + (group * 32));\r\nhe_writel(he_dev, RBP_THRESH(0x1) | RBP_QSIZE(0x0),\r\nG0_RBPS_BS + (group * 32));\r\nhe_writel(he_dev, 0x0, G0_RBPL_S + (group * 32));\r\nhe_writel(he_dev, 0x0, G0_RBPL_T + (group * 32));\r\nhe_writel(he_dev, RBP_THRESH(0x1) | RBP_QSIZE(0x0),\r\nG0_RBPL_QI + (group * 32));\r\nhe_writel(he_dev, 0x0, G0_RBPL_BS + (group * 32));\r\nhe_writel(he_dev, 0x0, G0_RBRQ_ST + (group * 16));\r\nhe_writel(he_dev, 0x0, G0_RBRQ_H + (group * 16));\r\nhe_writel(he_dev, RBRQ_THRESH(0x1) | RBRQ_SIZE(0x0),\r\nG0_RBRQ_Q + (group * 16));\r\nhe_writel(he_dev, 0x0, G0_RBRQ_I + (group * 16));\r\nhe_writel(he_dev, 0x0, G0_TBRQ_B_T + (group * 16));\r\nhe_writel(he_dev, 0x0, G0_TBRQ_H + (group * 16));\r\nhe_writel(he_dev, TBRQ_THRESH(0x1),\r\nG0_TBRQ_THRESH + (group * 16));\r\nhe_writel(he_dev, 0x0, G0_TBRQ_S + (group * 16));\r\n}\r\nhe_dev->hsp = pci_alloc_consistent(he_dev->pci_dev,\r\nsizeof(struct he_hsp), &he_dev->hsp_phys);\r\nif (he_dev->hsp == NULL) {\r\nhprintk("failed to allocate host status page\n");\r\nreturn -ENOMEM;\r\n}\r\nmemset(he_dev->hsp, 0, sizeof(struct he_hsp));\r\nhe_writel(he_dev, he_dev->hsp_phys, HSP_BA);\r\n#ifdef CONFIG_ATM_HE_USE_SUNI\r\nif (he_isMM(he_dev))\r\nsuni_init(he_dev->atm_dev);\r\nif (he_dev->atm_dev->phy && he_dev->atm_dev->phy->start)\r\nhe_dev->atm_dev->phy->start(he_dev->atm_dev);\r\n#endif\r\nif (sdh) {\r\nint val;\r\nval = he_phy_get(he_dev->atm_dev, SUNI_TPOP_APM);\r\nval = (val & ~SUNI_TPOP_APM_S) | (SUNI_TPOP_S_SDH << SUNI_TPOP_APM_S_SHIFT);\r\nhe_phy_put(he_dev->atm_dev, val, SUNI_TPOP_APM);\r\nhe_phy_put(he_dev->atm_dev, SUNI_TACP_IUCHP_CLP, SUNI_TACP_IUCHP);\r\n}\r\nreg = he_readl_mbox(he_dev, CS_ERCTL0);\r\nreg |= TX_ENABLE|ER_ENABLE;\r\nhe_writel_mbox(he_dev, reg, CS_ERCTL0);\r\nreg = he_readl(he_dev, RC_CONFIG);\r\nreg |= RX_ENABLE;\r\nhe_writel(he_dev, reg, RC_CONFIG);\r\nfor (i = 0; i < HE_NUM_CS_STPER; ++i) {\r\nhe_dev->cs_stper[i].inuse = 0;\r\nhe_dev->cs_stper[i].pcr = -1;\r\n}\r\nhe_dev->total_bw = 0;\r\nhe_dev->atm_dev->ci_range.vpi_bits = he_dev->vpibits;\r\nhe_dev->atm_dev->ci_range.vci_bits = he_dev->vcibits;\r\nhe_dev->irq_peak = 0;\r\nhe_dev->rbrq_peak = 0;\r\nhe_dev->rbpl_peak = 0;\r\nhe_dev->tbrq_peak = 0;\r\nHPRINTK("hell bent for leather!\n");\r\nreturn 0;\r\n}\r\nstatic void\r\nhe_stop(struct he_dev *he_dev)\r\n{\r\nstruct he_buff *heb, *next;\r\nstruct pci_dev *pci_dev;\r\nu32 gen_cntl_0, reg;\r\nu16 command;\r\npci_dev = he_dev->pci_dev;\r\nif (he_dev->membase) {\r\npci_read_config_dword(pci_dev, GEN_CNTL_0, &gen_cntl_0);\r\ngen_cntl_0 &= ~(INT_PROC_ENBL | INIT_ENB);\r\npci_write_config_dword(pci_dev, GEN_CNTL_0, gen_cntl_0);\r\ntasklet_disable(&he_dev->tasklet);\r\nreg = he_readl_mbox(he_dev, CS_ERCTL0);\r\nreg &= ~(TX_ENABLE|ER_ENABLE);\r\nhe_writel_mbox(he_dev, reg, CS_ERCTL0);\r\nreg = he_readl(he_dev, RC_CONFIG);\r\nreg &= ~(RX_ENABLE);\r\nhe_writel(he_dev, reg, RC_CONFIG);\r\n}\r\n#ifdef CONFIG_ATM_HE_USE_SUNI\r\nif (he_dev->atm_dev->phy && he_dev->atm_dev->phy->stop)\r\nhe_dev->atm_dev->phy->stop(he_dev->atm_dev);\r\n#endif\r\nif (he_dev->irq)\r\nfree_irq(he_dev->irq, he_dev);\r\nif (he_dev->irq_base)\r\npci_free_consistent(he_dev->pci_dev, (CONFIG_IRQ_SIZE+1)\r\n* sizeof(struct he_irq), he_dev->irq_base, he_dev->irq_phys);\r\nif (he_dev->hsp)\r\npci_free_consistent(he_dev->pci_dev, sizeof(struct he_hsp),\r\nhe_dev->hsp, he_dev->hsp_phys);\r\nif (he_dev->rbpl_base) {\r\nlist_for_each_entry_safe(heb, next, &he_dev->rbpl_outstanding, entry)\r\npci_pool_free(he_dev->rbpl_pool, heb, heb->mapping);\r\npci_free_consistent(he_dev->pci_dev, CONFIG_RBPL_SIZE\r\n* sizeof(struct he_rbp), he_dev->rbpl_base, he_dev->rbpl_phys);\r\n}\r\nkfree(he_dev->rbpl_virt);\r\nkfree(he_dev->rbpl_table);\r\nif (he_dev->rbpl_pool)\r\npci_pool_destroy(he_dev->rbpl_pool);\r\nif (he_dev->rbrq_base)\r\npci_free_consistent(he_dev->pci_dev, CONFIG_RBRQ_SIZE * sizeof(struct he_rbrq),\r\nhe_dev->rbrq_base, he_dev->rbrq_phys);\r\nif (he_dev->tbrq_base)\r\npci_free_consistent(he_dev->pci_dev, CONFIG_TBRQ_SIZE * sizeof(struct he_tbrq),\r\nhe_dev->tbrq_base, he_dev->tbrq_phys);\r\nif (he_dev->tpdrq_base)\r\npci_free_consistent(he_dev->pci_dev, CONFIG_TBRQ_SIZE * sizeof(struct he_tbrq),\r\nhe_dev->tpdrq_base, he_dev->tpdrq_phys);\r\nif (he_dev->tpd_pool)\r\npci_pool_destroy(he_dev->tpd_pool);\r\nif (he_dev->pci_dev) {\r\npci_read_config_word(he_dev->pci_dev, PCI_COMMAND, &command);\r\ncommand &= ~(PCI_COMMAND_MEMORY | PCI_COMMAND_MASTER);\r\npci_write_config_word(he_dev->pci_dev, PCI_COMMAND, command);\r\n}\r\nif (he_dev->membase)\r\niounmap(he_dev->membase);\r\n}\r\nstatic struct he_tpd *\r\n__alloc_tpd(struct he_dev *he_dev)\r\n{\r\nstruct he_tpd *tpd;\r\ndma_addr_t mapping;\r\ntpd = pci_pool_alloc(he_dev->tpd_pool, GFP_ATOMIC|GFP_DMA, &mapping);\r\nif (tpd == NULL)\r\nreturn NULL;\r\ntpd->status = TPD_ADDR(mapping);\r\ntpd->reserved = 0;\r\ntpd->iovec[0].addr = 0; tpd->iovec[0].len = 0;\r\ntpd->iovec[1].addr = 0; tpd->iovec[1].len = 0;\r\ntpd->iovec[2].addr = 0; tpd->iovec[2].len = 0;\r\nreturn tpd;\r\n}\r\nstatic int\r\nhe_service_rbrq(struct he_dev *he_dev, int group)\r\n{\r\nstruct he_rbrq *rbrq_tail = (struct he_rbrq *)\r\n((unsigned long)he_dev->rbrq_base |\r\nhe_dev->hsp->group[group].rbrq_tail);\r\nunsigned cid, lastcid = -1;\r\nstruct sk_buff *skb;\r\nstruct atm_vcc *vcc = NULL;\r\nstruct he_vcc *he_vcc;\r\nstruct he_buff *heb, *next;\r\nint i;\r\nint pdus_assembled = 0;\r\nint updated = 0;\r\nread_lock(&vcc_sklist_lock);\r\nwhile (he_dev->rbrq_head != rbrq_tail) {\r\n++updated;\r\nHPRINTK("%p rbrq%d 0x%x len=%d cid=0x%x %s%s%s%s%s%s\n",\r\nhe_dev->rbrq_head, group,\r\nRBRQ_ADDR(he_dev->rbrq_head),\r\nRBRQ_BUFLEN(he_dev->rbrq_head),\r\nRBRQ_CID(he_dev->rbrq_head),\r\nRBRQ_CRC_ERR(he_dev->rbrq_head) ? " CRC_ERR" : "",\r\nRBRQ_LEN_ERR(he_dev->rbrq_head) ? " LEN_ERR" : "",\r\nRBRQ_END_PDU(he_dev->rbrq_head) ? " END_PDU" : "",\r\nRBRQ_AAL5_PROT(he_dev->rbrq_head) ? " AAL5_PROT" : "",\r\nRBRQ_CON_CLOSED(he_dev->rbrq_head) ? " CON_CLOSED" : "",\r\nRBRQ_HBUF_ERR(he_dev->rbrq_head) ? " HBUF_ERR" : "");\r\ni = RBRQ_ADDR(he_dev->rbrq_head) >> RBP_IDX_OFFSET;\r\nheb = he_dev->rbpl_virt[i];\r\ncid = RBRQ_CID(he_dev->rbrq_head);\r\nif (cid != lastcid)\r\nvcc = __find_vcc(he_dev, cid);\r\nlastcid = cid;\r\nif (vcc == NULL || (he_vcc = HE_VCC(vcc)) == NULL) {\r\nhprintk("vcc/he_vcc == NULL (cid 0x%x)\n", cid);\r\nif (!RBRQ_HBUF_ERR(he_dev->rbrq_head)) {\r\nclear_bit(i, he_dev->rbpl_table);\r\nlist_del(&heb->entry);\r\npci_pool_free(he_dev->rbpl_pool, heb, heb->mapping);\r\n}\r\ngoto next_rbrq_entry;\r\n}\r\nif (RBRQ_HBUF_ERR(he_dev->rbrq_head)) {\r\nhprintk("HBUF_ERR! (cid 0x%x)\n", cid);\r\natomic_inc(&vcc->stats->rx_drop);\r\ngoto return_host_buffers;\r\n}\r\nheb->len = RBRQ_BUFLEN(he_dev->rbrq_head) * 4;\r\nclear_bit(i, he_dev->rbpl_table);\r\nlist_move_tail(&heb->entry, &he_vcc->buffers);\r\nhe_vcc->pdu_len += heb->len;\r\nif (RBRQ_CON_CLOSED(he_dev->rbrq_head)) {\r\nlastcid = -1;\r\nHPRINTK("wake_up rx_waitq (cid 0x%x)\n", cid);\r\nwake_up(&he_vcc->rx_waitq);\r\ngoto return_host_buffers;\r\n}\r\nif (!RBRQ_END_PDU(he_dev->rbrq_head))\r\ngoto next_rbrq_entry;\r\nif (RBRQ_LEN_ERR(he_dev->rbrq_head)\r\n|| RBRQ_CRC_ERR(he_dev->rbrq_head)) {\r\nHPRINTK("%s%s (%d.%d)\n",\r\nRBRQ_CRC_ERR(he_dev->rbrq_head)\r\n? "CRC_ERR " : "",\r\nRBRQ_LEN_ERR(he_dev->rbrq_head)\r\n? "LEN_ERR" : "",\r\nvcc->vpi, vcc->vci);\r\natomic_inc(&vcc->stats->rx_err);\r\ngoto return_host_buffers;\r\n}\r\nskb = atm_alloc_charge(vcc, he_vcc->pdu_len + rx_skb_reserve,\r\nGFP_ATOMIC);\r\nif (!skb) {\r\nHPRINTK("charge failed (%d.%d)\n", vcc->vpi, vcc->vci);\r\ngoto return_host_buffers;\r\n}\r\nif (rx_skb_reserve > 0)\r\nskb_reserve(skb, rx_skb_reserve);\r\n__net_timestamp(skb);\r\nlist_for_each_entry(heb, &he_vcc->buffers, entry)\r\nmemcpy(skb_put(skb, heb->len), &heb->data, heb->len);\r\nswitch (vcc->qos.aal) {\r\ncase ATM_AAL0:\r\nskb->len = ATM_AAL0_SDU;\r\nskb_set_tail_pointer(skb, skb->len);\r\nbreak;\r\ncase ATM_AAL5:\r\nskb->len = AAL5_LEN(skb->data, he_vcc->pdu_len);\r\nskb_set_tail_pointer(skb, skb->len);\r\n#ifdef USE_CHECKSUM_HW\r\nif (vcc->vpi == 0 && vcc->vci >= ATM_NOT_RSV_VCI) {\r\nskb->ip_summed = CHECKSUM_COMPLETE;\r\nskb->csum = TCP_CKSUM(skb->data,\r\nhe_vcc->pdu_len);\r\n}\r\n#endif\r\nbreak;\r\n}\r\n#ifdef should_never_happen\r\nif (skb->len > vcc->qos.rxtp.max_sdu)\r\nhprintk("pdu_len (%d) > vcc->qos.rxtp.max_sdu (%d)! cid 0x%x\n", skb->len, vcc->qos.rxtp.max_sdu, cid);\r\n#endif\r\n#ifdef notdef\r\nATM_SKB(skb)->vcc = vcc;\r\n#endif\r\nspin_unlock(&he_dev->global_lock);\r\nvcc->push(vcc, skb);\r\nspin_lock(&he_dev->global_lock);\r\natomic_inc(&vcc->stats->rx);\r\nreturn_host_buffers:\r\n++pdus_assembled;\r\nlist_for_each_entry_safe(heb, next, &he_vcc->buffers, entry)\r\npci_pool_free(he_dev->rbpl_pool, heb, heb->mapping);\r\nINIT_LIST_HEAD(&he_vcc->buffers);\r\nhe_vcc->pdu_len = 0;\r\nnext_rbrq_entry:\r\nhe_dev->rbrq_head = (struct he_rbrq *)\r\n((unsigned long) he_dev->rbrq_base |\r\nRBRQ_MASK(he_dev->rbrq_head + 1));\r\n}\r\nread_unlock(&vcc_sklist_lock);\r\nif (updated) {\r\nif (updated > he_dev->rbrq_peak)\r\nhe_dev->rbrq_peak = updated;\r\nhe_writel(he_dev, RBRQ_MASK(he_dev->rbrq_head),\r\nG0_RBRQ_H + (group * 16));\r\n}\r\nreturn pdus_assembled;\r\n}\r\nstatic void\r\nhe_service_tbrq(struct he_dev *he_dev, int group)\r\n{\r\nstruct he_tbrq *tbrq_tail = (struct he_tbrq *)\r\n((unsigned long)he_dev->tbrq_base |\r\nhe_dev->hsp->group[group].tbrq_tail);\r\nstruct he_tpd *tpd;\r\nint slot, updated = 0;\r\nstruct he_tpd *__tpd;\r\nwhile (he_dev->tbrq_head != tbrq_tail) {\r\n++updated;\r\nHPRINTK("tbrq%d 0x%x%s%s\n",\r\ngroup,\r\nTBRQ_TPD(he_dev->tbrq_head),\r\nTBRQ_EOS(he_dev->tbrq_head) ? " EOS" : "",\r\nTBRQ_MULTIPLE(he_dev->tbrq_head) ? " MULTIPLE" : "");\r\ntpd = NULL;\r\nlist_for_each_entry(__tpd, &he_dev->outstanding_tpds, entry) {\r\nif (TPD_ADDR(__tpd->status) == TBRQ_TPD(he_dev->tbrq_head)) {\r\ntpd = __tpd;\r\nlist_del(&__tpd->entry);\r\nbreak;\r\n}\r\n}\r\nif (tpd == NULL) {\r\nhprintk("unable to locate tpd for dma buffer %x\n",\r\nTBRQ_TPD(he_dev->tbrq_head));\r\ngoto next_tbrq_entry;\r\n}\r\nif (TBRQ_EOS(he_dev->tbrq_head)) {\r\nHPRINTK("wake_up(tx_waitq) cid 0x%x\n",\r\nhe_mkcid(he_dev, tpd->vcc->vpi, tpd->vcc->vci));\r\nif (tpd->vcc)\r\nwake_up(&HE_VCC(tpd->vcc)->tx_waitq);\r\ngoto next_tbrq_entry;\r\n}\r\nfor (slot = 0; slot < TPD_MAXIOV; ++slot) {\r\nif (tpd->iovec[slot].addr)\r\npci_unmap_single(he_dev->pci_dev,\r\ntpd->iovec[slot].addr,\r\ntpd->iovec[slot].len & TPD_LEN_MASK,\r\nPCI_DMA_TODEVICE);\r\nif (tpd->iovec[slot].len & TPD_LST)\r\nbreak;\r\n}\r\nif (tpd->skb) {\r\nif (tpd->vcc && tpd->vcc->pop)\r\ntpd->vcc->pop(tpd->vcc, tpd->skb);\r\nelse\r\ndev_kfree_skb_any(tpd->skb);\r\n}\r\nnext_tbrq_entry:\r\nif (tpd)\r\npci_pool_free(he_dev->tpd_pool, tpd, TPD_ADDR(tpd->status));\r\nhe_dev->tbrq_head = (struct he_tbrq *)\r\n((unsigned long) he_dev->tbrq_base |\r\nTBRQ_MASK(he_dev->tbrq_head + 1));\r\n}\r\nif (updated) {\r\nif (updated > he_dev->tbrq_peak)\r\nhe_dev->tbrq_peak = updated;\r\nhe_writel(he_dev, TBRQ_MASK(he_dev->tbrq_head),\r\nG0_TBRQ_H + (group * 16));\r\n}\r\n}\r\nstatic void\r\nhe_service_rbpl(struct he_dev *he_dev, int group)\r\n{\r\nstruct he_rbp *new_tail;\r\nstruct he_rbp *rbpl_head;\r\nstruct he_buff *heb;\r\ndma_addr_t mapping;\r\nint i;\r\nint moved = 0;\r\nrbpl_head = (struct he_rbp *) ((unsigned long)he_dev->rbpl_base |\r\nRBPL_MASK(he_readl(he_dev, G0_RBPL_S)));\r\nfor (;;) {\r\nnew_tail = (struct he_rbp *) ((unsigned long)he_dev->rbpl_base |\r\nRBPL_MASK(he_dev->rbpl_tail+1));\r\nif (new_tail == rbpl_head)\r\nbreak;\r\ni = find_next_zero_bit(he_dev->rbpl_table, RBPL_TABLE_SIZE, he_dev->rbpl_hint);\r\nif (i > (RBPL_TABLE_SIZE - 1)) {\r\ni = find_first_zero_bit(he_dev->rbpl_table, RBPL_TABLE_SIZE);\r\nif (i > (RBPL_TABLE_SIZE - 1))\r\nbreak;\r\n}\r\nhe_dev->rbpl_hint = i + 1;\r\nheb = pci_pool_alloc(he_dev->rbpl_pool, GFP_ATOMIC|GFP_DMA, &mapping);\r\nif (!heb)\r\nbreak;\r\nheb->mapping = mapping;\r\nlist_add(&heb->entry, &he_dev->rbpl_outstanding);\r\nhe_dev->rbpl_virt[i] = heb;\r\nset_bit(i, he_dev->rbpl_table);\r\nnew_tail->idx = i << RBP_IDX_OFFSET;\r\nnew_tail->phys = mapping + offsetof(struct he_buff, data);\r\nhe_dev->rbpl_tail = new_tail;\r\n++moved;\r\n}\r\nif (moved)\r\nhe_writel(he_dev, RBPL_MASK(he_dev->rbpl_tail), G0_RBPL_T);\r\n}\r\nstatic void\r\nhe_tasklet(unsigned long data)\r\n{\r\nunsigned long flags;\r\nstruct he_dev *he_dev = (struct he_dev *) data;\r\nint group, type;\r\nint updated = 0;\r\nHPRINTK("tasklet (0x%lx)\n", data);\r\nspin_lock_irqsave(&he_dev->global_lock, flags);\r\nwhile (he_dev->irq_head != he_dev->irq_tail) {\r\n++updated;\r\ntype = ITYPE_TYPE(he_dev->irq_head->isw);\r\ngroup = ITYPE_GROUP(he_dev->irq_head->isw);\r\nswitch (type) {\r\ncase ITYPE_RBRQ_THRESH:\r\nHPRINTK("rbrq%d threshold\n", group);\r\ncase ITYPE_RBRQ_TIMER:\r\nif (he_service_rbrq(he_dev, group))\r\nhe_service_rbpl(he_dev, group);\r\nbreak;\r\ncase ITYPE_TBRQ_THRESH:\r\nHPRINTK("tbrq%d threshold\n", group);\r\ncase ITYPE_TPD_COMPLETE:\r\nhe_service_tbrq(he_dev, group);\r\nbreak;\r\ncase ITYPE_RBPL_THRESH:\r\nhe_service_rbpl(he_dev, group);\r\nbreak;\r\ncase ITYPE_RBPS_THRESH:\r\nbreak;\r\ncase ITYPE_PHY:\r\nHPRINTK("phy interrupt\n");\r\n#ifdef CONFIG_ATM_HE_USE_SUNI\r\nspin_unlock_irqrestore(&he_dev->global_lock, flags);\r\nif (he_dev->atm_dev->phy && he_dev->atm_dev->phy->interrupt)\r\nhe_dev->atm_dev->phy->interrupt(he_dev->atm_dev);\r\nspin_lock_irqsave(&he_dev->global_lock, flags);\r\n#endif\r\nbreak;\r\ncase ITYPE_OTHER:\r\nswitch (type|group) {\r\ncase ITYPE_PARITY:\r\nhprintk("parity error\n");\r\nbreak;\r\ncase ITYPE_ABORT:\r\nhprintk("abort 0x%x\n", he_readl(he_dev, ABORT_ADDR));\r\nbreak;\r\n}\r\nbreak;\r\ncase ITYPE_TYPE(ITYPE_INVALID):\r\nHPRINTK("isw not updated 0x%x\n", he_dev->irq_head->isw);\r\nhe_service_rbrq(he_dev, 0);\r\nhe_service_rbpl(he_dev, 0);\r\nhe_service_tbrq(he_dev, 0);\r\nbreak;\r\ndefault:\r\nhprintk("bad isw 0x%x?\n", he_dev->irq_head->isw);\r\n}\r\nhe_dev->irq_head->isw = ITYPE_INVALID;\r\nhe_dev->irq_head = (struct he_irq *) NEXT_ENTRY(he_dev->irq_base, he_dev->irq_head, IRQ_MASK);\r\n}\r\nif (updated) {\r\nif (updated > he_dev->irq_peak)\r\nhe_dev->irq_peak = updated;\r\nhe_writel(he_dev,\r\nIRQ_SIZE(CONFIG_IRQ_SIZE) |\r\nIRQ_THRESH(CONFIG_IRQ_THRESH) |\r\nIRQ_TAIL(he_dev->irq_tail), IRQ0_HEAD);\r\n(void) he_readl(he_dev, INT_FIFO);\r\n}\r\nspin_unlock_irqrestore(&he_dev->global_lock, flags);\r\n}\r\nstatic irqreturn_t\r\nhe_irq_handler(int irq, void *dev_id)\r\n{\r\nunsigned long flags;\r\nstruct he_dev *he_dev = (struct he_dev * )dev_id;\r\nint handled = 0;\r\nif (he_dev == NULL)\r\nreturn IRQ_NONE;\r\nspin_lock_irqsave(&he_dev->global_lock, flags);\r\nhe_dev->irq_tail = (struct he_irq *) (((unsigned long)he_dev->irq_base) |\r\n(*he_dev->irq_tailoffset << 2));\r\nif (he_dev->irq_tail == he_dev->irq_head) {\r\nHPRINTK("tailoffset not updated?\n");\r\nhe_dev->irq_tail = (struct he_irq *) ((unsigned long)he_dev->irq_base |\r\n((he_readl(he_dev, IRQ0_BASE) & IRQ_MASK) << 2));\r\n(void) he_readl(he_dev, INT_FIFO);\r\n}\r\n#ifdef DEBUG\r\nif (he_dev->irq_head == he_dev->irq_tail )\r\nhprintk("spurious (or shared) interrupt?\n");\r\n#endif\r\nif (he_dev->irq_head != he_dev->irq_tail) {\r\nhandled = 1;\r\ntasklet_schedule(&he_dev->tasklet);\r\nhe_writel(he_dev, INT_CLEAR_A, INT_FIFO);\r\n(void) he_readl(he_dev, INT_FIFO);\r\n}\r\nspin_unlock_irqrestore(&he_dev->global_lock, flags);\r\nreturn IRQ_RETVAL(handled);\r\n}\r\nstatic __inline__ void\r\n__enqueue_tpd(struct he_dev *he_dev, struct he_tpd *tpd, unsigned cid)\r\n{\r\nstruct he_tpdrq *new_tail;\r\nHPRINTK("tpdrq %p cid 0x%x -> tpdrq_tail %p\n",\r\ntpd, cid, he_dev->tpdrq_tail);\r\nnew_tail = (struct he_tpdrq *) ((unsigned long) he_dev->tpdrq_base |\r\nTPDRQ_MASK(he_dev->tpdrq_tail+1));\r\nif (new_tail == he_dev->tpdrq_head) {\r\nhe_dev->tpdrq_head = (struct he_tpdrq *)\r\n(((unsigned long)he_dev->tpdrq_base) |\r\nTPDRQ_MASK(he_readl(he_dev, TPDRQ_B_H)));\r\nif (new_tail == he_dev->tpdrq_head) {\r\nint slot;\r\nhprintk("tpdrq full (cid 0x%x)\n", cid);\r\nfor (slot = 0; slot < TPD_MAXIOV; ++slot) {\r\nif (tpd->iovec[slot].addr)\r\npci_unmap_single(he_dev->pci_dev,\r\ntpd->iovec[slot].addr,\r\ntpd->iovec[slot].len & TPD_LEN_MASK,\r\nPCI_DMA_TODEVICE);\r\n}\r\nif (tpd->skb) {\r\nif (tpd->vcc->pop)\r\ntpd->vcc->pop(tpd->vcc, tpd->skb);\r\nelse\r\ndev_kfree_skb_any(tpd->skb);\r\natomic_inc(&tpd->vcc->stats->tx_err);\r\n}\r\npci_pool_free(he_dev->tpd_pool, tpd, TPD_ADDR(tpd->status));\r\nreturn;\r\n}\r\n}\r\nlist_add_tail(&tpd->entry, &he_dev->outstanding_tpds);\r\nhe_dev->tpdrq_tail->tpd = TPD_ADDR(tpd->status);\r\nhe_dev->tpdrq_tail->cid = cid;\r\nwmb();\r\nhe_dev->tpdrq_tail = new_tail;\r\nhe_writel(he_dev, TPDRQ_MASK(he_dev->tpdrq_tail), TPDRQ_T);\r\n(void) he_readl(he_dev, TPDRQ_T);\r\n}\r\nstatic int\r\nhe_open(struct atm_vcc *vcc)\r\n{\r\nunsigned long flags;\r\nstruct he_dev *he_dev = HE_DEV(vcc->dev);\r\nstruct he_vcc *he_vcc;\r\nint err = 0;\r\nunsigned cid, rsr0, rsr1, rsr4, tsr0, tsr0_aal, tsr4, period, reg, clock;\r\nshort vpi = vcc->vpi;\r\nint vci = vcc->vci;\r\nif (vci == ATM_VCI_UNSPEC || vpi == ATM_VPI_UNSPEC)\r\nreturn 0;\r\nHPRINTK("open vcc %p %d.%d\n", vcc, vpi, vci);\r\nset_bit(ATM_VF_ADDR, &vcc->flags);\r\ncid = he_mkcid(he_dev, vpi, vci);\r\nhe_vcc = kmalloc(sizeof(struct he_vcc), GFP_ATOMIC);\r\nif (he_vcc == NULL) {\r\nhprintk("unable to allocate he_vcc during open\n");\r\nreturn -ENOMEM;\r\n}\r\nINIT_LIST_HEAD(&he_vcc->buffers);\r\nhe_vcc->pdu_len = 0;\r\nhe_vcc->rc_index = -1;\r\ninit_waitqueue_head(&he_vcc->rx_waitq);\r\ninit_waitqueue_head(&he_vcc->tx_waitq);\r\nvcc->dev_data = he_vcc;\r\nif (vcc->qos.txtp.traffic_class != ATM_NONE) {\r\nint pcr_goal;\r\npcr_goal = atm_pcr_goal(&vcc->qos.txtp);\r\nif (pcr_goal == 0)\r\npcr_goal = he_dev->atm_dev->link_rate;\r\nif (pcr_goal < 0)\r\npcr_goal = -pcr_goal;\r\nHPRINTK("open tx cid 0x%x pcr_goal %d\n", cid, pcr_goal);\r\nswitch (vcc->qos.aal) {\r\ncase ATM_AAL5:\r\ntsr0_aal = TSR0_AAL5;\r\ntsr4 = TSR4_AAL5;\r\nbreak;\r\ncase ATM_AAL0:\r\ntsr0_aal = TSR0_AAL0_SDU;\r\ntsr4 = TSR4_AAL0_SDU;\r\nbreak;\r\ndefault:\r\nerr = -EINVAL;\r\ngoto open_failed;\r\n}\r\nspin_lock_irqsave(&he_dev->global_lock, flags);\r\ntsr0 = he_readl_tsr0(he_dev, cid);\r\nspin_unlock_irqrestore(&he_dev->global_lock, flags);\r\nif (TSR0_CONN_STATE(tsr0) != 0) {\r\nhprintk("cid 0x%x not idle (tsr0 = 0x%x)\n", cid, tsr0);\r\nerr = -EBUSY;\r\ngoto open_failed;\r\n}\r\nswitch (vcc->qos.txtp.traffic_class) {\r\ncase ATM_UBR:\r\ntsr0 = TSR0_UBR | TSR0_GROUP(0) | tsr0_aal |\r\nTSR0_USE_WMIN | TSR0_UPDATE_GER;\r\nbreak;\r\ncase ATM_CBR:\r\nif ((he_dev->total_bw + pcr_goal)\r\n> (he_dev->atm_dev->link_rate * 9 / 10))\r\n{\r\nerr = -EBUSY;\r\ngoto open_failed;\r\n}\r\nspin_lock_irqsave(&he_dev->global_lock, flags);\r\nfor (reg = 0; reg < HE_NUM_CS_STPER; ++reg)\r\nif (he_dev->cs_stper[reg].inuse == 0 ||\r\nhe_dev->cs_stper[reg].pcr == pcr_goal)\r\nbreak;\r\nif (reg == HE_NUM_CS_STPER) {\r\nerr = -EBUSY;\r\nspin_unlock_irqrestore(&he_dev->global_lock, flags);\r\ngoto open_failed;\r\n}\r\nhe_dev->total_bw += pcr_goal;\r\nhe_vcc->rc_index = reg;\r\n++he_dev->cs_stper[reg].inuse;\r\nhe_dev->cs_stper[reg].pcr = pcr_goal;\r\nclock = he_is622(he_dev) ? 66667000 : 50000000;\r\nperiod = clock / pcr_goal;\r\nHPRINTK("rc_index = %d period = %d\n",\r\nreg, period);\r\nhe_writel_mbox(he_dev, rate_to_atmf(period/2),\r\nCS_STPER0 + reg);\r\nspin_unlock_irqrestore(&he_dev->global_lock, flags);\r\ntsr0 = TSR0_CBR | TSR0_GROUP(0) | tsr0_aal |\r\nTSR0_RC_INDEX(reg);\r\nbreak;\r\ndefault:\r\nerr = -EINVAL;\r\ngoto open_failed;\r\n}\r\nspin_lock_irqsave(&he_dev->global_lock, flags);\r\nhe_writel_tsr0(he_dev, tsr0, cid);\r\nhe_writel_tsr4(he_dev, tsr4 | 1, cid);\r\nhe_writel_tsr1(he_dev, TSR1_MCR(rate_to_atmf(0)) |\r\nTSR1_PCR(rate_to_atmf(pcr_goal)), cid);\r\nhe_writel_tsr2(he_dev, TSR2_ACR(rate_to_atmf(pcr_goal)), cid);\r\nhe_writel_tsr9(he_dev, TSR9_OPEN_CONN, cid);\r\nhe_writel_tsr3(he_dev, 0x0, cid);\r\nhe_writel_tsr5(he_dev, 0x0, cid);\r\nhe_writel_tsr6(he_dev, 0x0, cid);\r\nhe_writel_tsr7(he_dev, 0x0, cid);\r\nhe_writel_tsr8(he_dev, 0x0, cid);\r\nhe_writel_tsr10(he_dev, 0x0, cid);\r\nhe_writel_tsr11(he_dev, 0x0, cid);\r\nhe_writel_tsr12(he_dev, 0x0, cid);\r\nhe_writel_tsr13(he_dev, 0x0, cid);\r\nhe_writel_tsr14(he_dev, 0x0, cid);\r\n(void) he_readl_tsr0(he_dev, cid);\r\nspin_unlock_irqrestore(&he_dev->global_lock, flags);\r\n}\r\nif (vcc->qos.rxtp.traffic_class != ATM_NONE) {\r\nunsigned aal;\r\nHPRINTK("open rx cid 0x%x (rx_waitq %p)\n", cid,\r\n&HE_VCC(vcc)->rx_waitq);\r\nswitch (vcc->qos.aal) {\r\ncase ATM_AAL5:\r\naal = RSR0_AAL5;\r\nbreak;\r\ncase ATM_AAL0:\r\naal = RSR0_RAWCELL;\r\nbreak;\r\ndefault:\r\nerr = -EINVAL;\r\ngoto open_failed;\r\n}\r\nspin_lock_irqsave(&he_dev->global_lock, flags);\r\nrsr0 = he_readl_rsr0(he_dev, cid);\r\nif (rsr0 & RSR0_OPEN_CONN) {\r\nspin_unlock_irqrestore(&he_dev->global_lock, flags);\r\nhprintk("cid 0x%x not idle (rsr0 = 0x%x)\n", cid, rsr0);\r\nerr = -EBUSY;\r\ngoto open_failed;\r\n}\r\nrsr1 = RSR1_GROUP(0) | RSR1_RBPL_ONLY;\r\nrsr4 = RSR4_GROUP(0) | RSR4_RBPL_ONLY;\r\nrsr0 = vcc->qos.rxtp.traffic_class == ATM_UBR ?\r\n(RSR0_EPD_ENABLE|RSR0_PPD_ENABLE) : 0;\r\n#ifdef USE_CHECKSUM_HW\r\nif (vpi == 0 && vci >= ATM_NOT_RSV_VCI)\r\nrsr0 |= RSR0_TCP_CKSUM;\r\n#endif\r\nhe_writel_rsr4(he_dev, rsr4, cid);\r\nhe_writel_rsr1(he_dev, rsr1, cid);\r\nhe_writel_rsr0(he_dev,\r\nrsr0 | RSR0_START_PDU | RSR0_OPEN_CONN | aal, cid);\r\n(void) he_readl_rsr0(he_dev, cid);\r\nspin_unlock_irqrestore(&he_dev->global_lock, flags);\r\n}\r\nopen_failed:\r\nif (err) {\r\nkfree(he_vcc);\r\nclear_bit(ATM_VF_ADDR, &vcc->flags);\r\n}\r\nelse\r\nset_bit(ATM_VF_READY, &vcc->flags);\r\nreturn err;\r\n}\r\nstatic void\r\nhe_close(struct atm_vcc *vcc)\r\n{\r\nunsigned long flags;\r\nDECLARE_WAITQUEUE(wait, current);\r\nstruct he_dev *he_dev = HE_DEV(vcc->dev);\r\nstruct he_tpd *tpd;\r\nunsigned cid;\r\nstruct he_vcc *he_vcc = HE_VCC(vcc);\r\n#define MAX_RETRY 30\r\nint retry = 0, sleep = 1, tx_inuse;\r\nHPRINTK("close vcc %p %d.%d\n", vcc, vcc->vpi, vcc->vci);\r\nclear_bit(ATM_VF_READY, &vcc->flags);\r\ncid = he_mkcid(he_dev, vcc->vpi, vcc->vci);\r\nif (vcc->qos.rxtp.traffic_class != ATM_NONE) {\r\nint timeout;\r\nHPRINTK("close rx cid 0x%x\n", cid);\r\nspin_lock_irqsave(&he_dev->global_lock, flags);\r\nwhile (he_readl(he_dev, RCC_STAT) & RCC_BUSY) {\r\nHPRINTK("close cid 0x%x RCC_BUSY\n", cid);\r\nudelay(250);\r\n}\r\nset_current_state(TASK_UNINTERRUPTIBLE);\r\nadd_wait_queue(&he_vcc->rx_waitq, &wait);\r\nhe_writel_rsr0(he_dev, RSR0_CLOSE_CONN, cid);\r\n(void) he_readl_rsr0(he_dev, cid);\r\nhe_writel_mbox(he_dev, cid, RXCON_CLOSE);\r\nspin_unlock_irqrestore(&he_dev->global_lock, flags);\r\ntimeout = schedule_timeout(30*HZ);\r\nremove_wait_queue(&he_vcc->rx_waitq, &wait);\r\nset_current_state(TASK_RUNNING);\r\nif (timeout == 0)\r\nhprintk("close rx timeout cid 0x%x\n", cid);\r\nHPRINTK("close rx cid 0x%x complete\n", cid);\r\n}\r\nif (vcc->qos.txtp.traffic_class != ATM_NONE) {\r\nvolatile unsigned tsr4, tsr0;\r\nint timeout;\r\nHPRINTK("close tx cid 0x%x\n", cid);\r\nwhile (((tx_inuse = atomic_read(&sk_atm(vcc)->sk_wmem_alloc)) > 1) &&\r\n(retry < MAX_RETRY)) {\r\nmsleep(sleep);\r\nif (sleep < 250)\r\nsleep = sleep * 2;\r\n++retry;\r\n}\r\nif (tx_inuse > 1)\r\nhprintk("close tx cid 0x%x tx_inuse = %d\n", cid, tx_inuse);\r\nspin_lock_irqsave(&he_dev->global_lock, flags);\r\nhe_writel_tsr4_upper(he_dev, TSR4_FLUSH_CONN, cid);\r\nswitch (vcc->qos.txtp.traffic_class) {\r\ncase ATM_UBR:\r\nhe_writel_tsr1(he_dev,\r\nTSR1_MCR(rate_to_atmf(200000))\r\n| TSR1_PCR(0), cid);\r\nbreak;\r\ncase ATM_CBR:\r\nhe_writel_tsr14_upper(he_dev, TSR14_DELETE, cid);\r\nbreak;\r\n}\r\n(void) he_readl_tsr4(he_dev, cid);\r\ntpd = __alloc_tpd(he_dev);\r\nif (tpd == NULL) {\r\nhprintk("close tx he_alloc_tpd failed cid 0x%x\n", cid);\r\ngoto close_tx_incomplete;\r\n}\r\ntpd->status |= TPD_EOS | TPD_INT;\r\ntpd->skb = NULL;\r\ntpd->vcc = vcc;\r\nwmb();\r\nset_current_state(TASK_UNINTERRUPTIBLE);\r\nadd_wait_queue(&he_vcc->tx_waitq, &wait);\r\n__enqueue_tpd(he_dev, tpd, cid);\r\nspin_unlock_irqrestore(&he_dev->global_lock, flags);\r\ntimeout = schedule_timeout(30*HZ);\r\nremove_wait_queue(&he_vcc->tx_waitq, &wait);\r\nset_current_state(TASK_RUNNING);\r\nspin_lock_irqsave(&he_dev->global_lock, flags);\r\nif (timeout == 0) {\r\nhprintk("close tx timeout cid 0x%x\n", cid);\r\ngoto close_tx_incomplete;\r\n}\r\nwhile (!((tsr4 = he_readl_tsr4(he_dev, cid)) & TSR4_SESSION_ENDED)) {\r\nHPRINTK("close tx cid 0x%x !TSR4_SESSION_ENDED (tsr4 = 0x%x)\n", cid, tsr4);\r\nudelay(250);\r\n}\r\nwhile (TSR0_CONN_STATE(tsr0 = he_readl_tsr0(he_dev, cid)) != 0) {\r\nHPRINTK("close tx cid 0x%x TSR0_CONN_STATE != 0 (tsr0 = 0x%x)\n", cid, tsr0);\r\nudelay(250);\r\n}\r\nclose_tx_incomplete:\r\nif (vcc->qos.txtp.traffic_class == ATM_CBR) {\r\nint reg = he_vcc->rc_index;\r\nHPRINTK("cs_stper reg = %d\n", reg);\r\nif (he_dev->cs_stper[reg].inuse == 0)\r\nhprintk("cs_stper[%d].inuse = 0!\n", reg);\r\nelse\r\n--he_dev->cs_stper[reg].inuse;\r\nhe_dev->total_bw -= he_dev->cs_stper[reg].pcr;\r\n}\r\nspin_unlock_irqrestore(&he_dev->global_lock, flags);\r\nHPRINTK("close tx cid 0x%x complete\n", cid);\r\n}\r\nkfree(he_vcc);\r\nclear_bit(ATM_VF_ADDR, &vcc->flags);\r\n}\r\nstatic int\r\nhe_send(struct atm_vcc *vcc, struct sk_buff *skb)\r\n{\r\nunsigned long flags;\r\nstruct he_dev *he_dev = HE_DEV(vcc->dev);\r\nunsigned cid = he_mkcid(he_dev, vcc->vpi, vcc->vci);\r\nstruct he_tpd *tpd;\r\n#ifdef USE_SCATTERGATHER\r\nint i, slot = 0;\r\n#endif\r\n#define HE_TPD_BUFSIZE 0xffff\r\nHPRINTK("send %d.%d\n", vcc->vpi, vcc->vci);\r\nif ((skb->len > HE_TPD_BUFSIZE) ||\r\n((vcc->qos.aal == ATM_AAL0) && (skb->len != ATM_AAL0_SDU))) {\r\nhprintk("buffer too large (or small) -- %d bytes\n", skb->len );\r\nif (vcc->pop)\r\nvcc->pop(vcc, skb);\r\nelse\r\ndev_kfree_skb_any(skb);\r\natomic_inc(&vcc->stats->tx_err);\r\nreturn -EINVAL;\r\n}\r\n#ifndef USE_SCATTERGATHER\r\nif (skb_shinfo(skb)->nr_frags) {\r\nhprintk("no scatter/gather support\n");\r\nif (vcc->pop)\r\nvcc->pop(vcc, skb);\r\nelse\r\ndev_kfree_skb_any(skb);\r\natomic_inc(&vcc->stats->tx_err);\r\nreturn -EINVAL;\r\n}\r\n#endif\r\nspin_lock_irqsave(&he_dev->global_lock, flags);\r\ntpd = __alloc_tpd(he_dev);\r\nif (tpd == NULL) {\r\nif (vcc->pop)\r\nvcc->pop(vcc, skb);\r\nelse\r\ndev_kfree_skb_any(skb);\r\natomic_inc(&vcc->stats->tx_err);\r\nspin_unlock_irqrestore(&he_dev->global_lock, flags);\r\nreturn -ENOMEM;\r\n}\r\nif (vcc->qos.aal == ATM_AAL5)\r\ntpd->status |= TPD_CELLTYPE(TPD_USERCELL);\r\nelse {\r\nchar *pti_clp = (void *) (skb->data + 3);\r\nint clp, pti;\r\npti = (*pti_clp & ATM_HDR_PTI_MASK) >> ATM_HDR_PTI_SHIFT;\r\nclp = (*pti_clp & ATM_HDR_CLP);\r\ntpd->status |= TPD_CELLTYPE(pti);\r\nif (clp)\r\ntpd->status |= TPD_CLP;\r\nskb_pull(skb, ATM_AAL0_SDU - ATM_CELL_PAYLOAD);\r\n}\r\n#ifdef USE_SCATTERGATHER\r\ntpd->iovec[slot].addr = pci_map_single(he_dev->pci_dev, skb->data,\r\nskb_headlen(skb), PCI_DMA_TODEVICE);\r\ntpd->iovec[slot].len = skb_headlen(skb);\r\n++slot;\r\nfor (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {\r\nskb_frag_t *frag = &skb_shinfo(skb)->frags[i];\r\nif (slot == TPD_MAXIOV) {\r\ntpd->vcc = vcc;\r\ntpd->skb = NULL;\r\nwmb();\r\n__enqueue_tpd(he_dev, tpd, cid);\r\ntpd = __alloc_tpd(he_dev);\r\nif (tpd == NULL) {\r\nif (vcc->pop)\r\nvcc->pop(vcc, skb);\r\nelse\r\ndev_kfree_skb_any(skb);\r\natomic_inc(&vcc->stats->tx_err);\r\nspin_unlock_irqrestore(&he_dev->global_lock, flags);\r\nreturn -ENOMEM;\r\n}\r\ntpd->status |= TPD_USERCELL;\r\nslot = 0;\r\n}\r\ntpd->iovec[slot].addr = pci_map_single(he_dev->pci_dev,\r\n(void *) page_address(frag->page) + frag->page_offset,\r\nfrag->size, PCI_DMA_TODEVICE);\r\ntpd->iovec[slot].len = frag->size;\r\n++slot;\r\n}\r\ntpd->iovec[slot - 1].len |= TPD_LST;\r\n#else\r\ntpd->address0 = pci_map_single(he_dev->pci_dev, skb->data, skb->len, PCI_DMA_TODEVICE);\r\ntpd->length0 = skb->len | TPD_LST;\r\n#endif\r\ntpd->status |= TPD_INT;\r\ntpd->vcc = vcc;\r\ntpd->skb = skb;\r\nwmb();\r\nATM_SKB(skb)->vcc = vcc;\r\n__enqueue_tpd(he_dev, tpd, cid);\r\nspin_unlock_irqrestore(&he_dev->global_lock, flags);\r\natomic_inc(&vcc->stats->tx);\r\nreturn 0;\r\n}\r\nstatic int\r\nhe_ioctl(struct atm_dev *atm_dev, unsigned int cmd, void __user *arg)\r\n{\r\nunsigned long flags;\r\nstruct he_dev *he_dev = HE_DEV(atm_dev);\r\nstruct he_ioctl_reg reg;\r\nint err = 0;\r\nswitch (cmd) {\r\ncase HE_GET_REG:\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nif (copy_from_user(&reg, arg,\r\nsizeof(struct he_ioctl_reg)))\r\nreturn -EFAULT;\r\nspin_lock_irqsave(&he_dev->global_lock, flags);\r\nswitch (reg.type) {\r\ncase HE_REGTYPE_PCI:\r\nif (reg.addr >= HE_REGMAP_SIZE) {\r\nerr = -EINVAL;\r\nbreak;\r\n}\r\nreg.val = he_readl(he_dev, reg.addr);\r\nbreak;\r\ncase HE_REGTYPE_RCM:\r\nreg.val =\r\nhe_readl_rcm(he_dev, reg.addr);\r\nbreak;\r\ncase HE_REGTYPE_TCM:\r\nreg.val =\r\nhe_readl_tcm(he_dev, reg.addr);\r\nbreak;\r\ncase HE_REGTYPE_MBOX:\r\nreg.val =\r\nhe_readl_mbox(he_dev, reg.addr);\r\nbreak;\r\ndefault:\r\nerr = -EINVAL;\r\nbreak;\r\n}\r\nspin_unlock_irqrestore(&he_dev->global_lock, flags);\r\nif (err == 0)\r\nif (copy_to_user(arg, &reg,\r\nsizeof(struct he_ioctl_reg)))\r\nreturn -EFAULT;\r\nbreak;\r\ndefault:\r\n#ifdef CONFIG_ATM_HE_USE_SUNI\r\nif (atm_dev->phy && atm_dev->phy->ioctl)\r\nerr = atm_dev->phy->ioctl(atm_dev, cmd, arg);\r\n#else\r\nerr = -EINVAL;\r\n#endif\r\nbreak;\r\n}\r\nreturn err;\r\n}\r\nstatic void\r\nhe_phy_put(struct atm_dev *atm_dev, unsigned char val, unsigned long addr)\r\n{\r\nunsigned long flags;\r\nstruct he_dev *he_dev = HE_DEV(atm_dev);\r\nHPRINTK("phy_put(val 0x%x, addr 0x%lx)\n", val, addr);\r\nspin_lock_irqsave(&he_dev->global_lock, flags);\r\nhe_writel(he_dev, val, FRAMER + (addr*4));\r\n(void) he_readl(he_dev, FRAMER + (addr*4));\r\nspin_unlock_irqrestore(&he_dev->global_lock, flags);\r\n}\r\nstatic unsigned char\r\nhe_phy_get(struct atm_dev *atm_dev, unsigned long addr)\r\n{\r\nunsigned long flags;\r\nstruct he_dev *he_dev = HE_DEV(atm_dev);\r\nunsigned reg;\r\nspin_lock_irqsave(&he_dev->global_lock, flags);\r\nreg = he_readl(he_dev, FRAMER + (addr*4));\r\nspin_unlock_irqrestore(&he_dev->global_lock, flags);\r\nHPRINTK("phy_get(addr 0x%lx) =0x%x\n", addr, reg);\r\nreturn reg;\r\n}\r\nstatic int\r\nhe_proc_read(struct atm_dev *dev, loff_t *pos, char *page)\r\n{\r\nunsigned long flags;\r\nstruct he_dev *he_dev = HE_DEV(dev);\r\nint left, i;\r\n#ifdef notdef\r\nstruct he_rbrq *rbrq_tail;\r\nstruct he_tpdrq *tpdrq_head;\r\nint rbpl_head, rbpl_tail;\r\n#endif\r\nstatic long mcc = 0, oec = 0, dcc = 0, cec = 0;\r\nleft = *pos;\r\nif (!left--)\r\nreturn sprintf(page, "ATM he driver\n");\r\nif (!left--)\r\nreturn sprintf(page, "%s%s\n\n",\r\nhe_dev->prod_id, he_dev->media & 0x40 ? "SM" : "MM");\r\nif (!left--)\r\nreturn sprintf(page, "Mismatched Cells VPI/VCI Not Open Dropped Cells RCM Dropped Cells\n");\r\nspin_lock_irqsave(&he_dev->global_lock, flags);\r\nmcc += he_readl(he_dev, MCC);\r\noec += he_readl(he_dev, OEC);\r\ndcc += he_readl(he_dev, DCC);\r\ncec += he_readl(he_dev, CEC);\r\nspin_unlock_irqrestore(&he_dev->global_lock, flags);\r\nif (!left--)\r\nreturn sprintf(page, "%16ld %16ld %13ld %17ld\n\n",\r\nmcc, oec, dcc, cec);\r\nif (!left--)\r\nreturn sprintf(page, "irq_size = %d inuse = ? peak = %d\n",\r\nCONFIG_IRQ_SIZE, he_dev->irq_peak);\r\nif (!left--)\r\nreturn sprintf(page, "tpdrq_size = %d inuse = ?\n",\r\nCONFIG_TPDRQ_SIZE);\r\nif (!left--)\r\nreturn sprintf(page, "rbrq_size = %d inuse = ? peak = %d\n",\r\nCONFIG_RBRQ_SIZE, he_dev->rbrq_peak);\r\nif (!left--)\r\nreturn sprintf(page, "tbrq_size = %d peak = %d\n",\r\nCONFIG_TBRQ_SIZE, he_dev->tbrq_peak);\r\n#ifdef notdef\r\nrbpl_head = RBPL_MASK(he_readl(he_dev, G0_RBPL_S));\r\nrbpl_tail = RBPL_MASK(he_readl(he_dev, G0_RBPL_T));\r\ninuse = rbpl_head - rbpl_tail;\r\nif (inuse < 0)\r\ninuse += CONFIG_RBPL_SIZE * sizeof(struct he_rbp);\r\ninuse /= sizeof(struct he_rbp);\r\nif (!left--)\r\nreturn sprintf(page, "rbpl_size = %d inuse = %d\n\n",\r\nCONFIG_RBPL_SIZE, inuse);\r\n#endif\r\nif (!left--)\r\nreturn sprintf(page, "rate controller periods (cbr)\n pcr #vc\n");\r\nfor (i = 0; i < HE_NUM_CS_STPER; ++i)\r\nif (!left--)\r\nreturn sprintf(page, "cs_stper%-2d %8ld %3d\n", i,\r\nhe_dev->cs_stper[i].pcr,\r\nhe_dev->cs_stper[i].inuse);\r\nif (!left--)\r\nreturn sprintf(page, "total bw (cbr): %d (limit %d)\n",\r\nhe_dev->total_bw, he_dev->atm_dev->link_rate * 10 / 9);\r\nreturn 0;\r\n}\r\nstatic u8 read_prom_byte(struct he_dev *he_dev, int addr)\r\n{\r\nu32 val = 0, tmp_read = 0;\r\nint i, j = 0;\r\nu8 byte_read = 0;\r\nval = readl(he_dev->membase + HOST_CNTL);\r\nval &= 0xFFFFE0FF;\r\nval |= 0x800;\r\nhe_writel(he_dev, val, HOST_CNTL);\r\nfor (i = 0; i < ARRAY_SIZE(readtab); i++) {\r\nhe_writel(he_dev, val | readtab[i], HOST_CNTL);\r\nudelay(EEPROM_DELAY);\r\n}\r\nfor (i = 7; i >= 0; i--) {\r\nhe_writel(he_dev, val | clocktab[j++] | (((addr >> i) & 1) << 9), HOST_CNTL);\r\nudelay(EEPROM_DELAY);\r\nhe_writel(he_dev, val | clocktab[j++] | (((addr >> i) & 1) << 9), HOST_CNTL);\r\nudelay(EEPROM_DELAY);\r\n}\r\nj = 0;\r\nval &= 0xFFFFF7FF;\r\nhe_writel(he_dev, val, HOST_CNTL);\r\nfor (i = 7; i >= 0; i--) {\r\nhe_writel(he_dev, val | clocktab[j++], HOST_CNTL);\r\nudelay(EEPROM_DELAY);\r\ntmp_read = he_readl(he_dev, HOST_CNTL);\r\nbyte_read |= (unsigned char)\r\n((tmp_read & ID_DOUT) >> ID_DOFFSET << i);\r\nhe_writel(he_dev, val | clocktab[j++], HOST_CNTL);\r\nudelay(EEPROM_DELAY);\r\n}\r\nhe_writel(he_dev, val | ID_CS, HOST_CNTL);\r\nudelay(EEPROM_DELAY);\r\nreturn byte_read;\r\n}\r\nstatic int __init he_init(void)\r\n{\r\nreturn pci_register_driver(&he_driver);\r\n}\r\nstatic void __exit he_cleanup(void)\r\n{\r\npci_unregister_driver(&he_driver);\r\n}
