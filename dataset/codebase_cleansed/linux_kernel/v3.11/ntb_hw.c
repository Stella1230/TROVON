int ntb_register_event_callback(struct ntb_device *ndev,\r\nvoid (*func)(void *handle, enum ntb_hw_event event))\r\n{\r\nif (ndev->event_cb)\r\nreturn -EINVAL;\r\nndev->event_cb = func;\r\nreturn 0;\r\n}\r\nvoid ntb_unregister_event_callback(struct ntb_device *ndev)\r\n{\r\nndev->event_cb = NULL;\r\n}\r\nint ntb_register_db_callback(struct ntb_device *ndev, unsigned int idx,\r\nvoid *data, void (*func)(void *data, int db_num))\r\n{\r\nunsigned long mask;\r\nif (idx >= ndev->max_cbs || ndev->db_cb[idx].callback) {\r\ndev_warn(&ndev->pdev->dev, "Invalid Index.\n");\r\nreturn -EINVAL;\r\n}\r\nndev->db_cb[idx].callback = func;\r\nndev->db_cb[idx].data = data;\r\nmask = readw(ndev->reg_ofs.pdb_mask);\r\nclear_bit(idx * ndev->bits_per_vector, &mask);\r\nwritew(mask, ndev->reg_ofs.pdb_mask);\r\nreturn 0;\r\n}\r\nvoid ntb_unregister_db_callback(struct ntb_device *ndev, unsigned int idx)\r\n{\r\nunsigned long mask;\r\nif (idx >= ndev->max_cbs || !ndev->db_cb[idx].callback)\r\nreturn;\r\nmask = readw(ndev->reg_ofs.pdb_mask);\r\nset_bit(idx * ndev->bits_per_vector, &mask);\r\nwritew(mask, ndev->reg_ofs.pdb_mask);\r\nndev->db_cb[idx].callback = NULL;\r\n}\r\nvoid *ntb_find_transport(struct pci_dev *pdev)\r\n{\r\nstruct ntb_device *ndev = pci_get_drvdata(pdev);\r\nreturn ndev->ntb_transport;\r\n}\r\nstruct ntb_device *ntb_register_transport(struct pci_dev *pdev, void *transport)\r\n{\r\nstruct ntb_device *ndev = pci_get_drvdata(pdev);\r\nif (ndev->ntb_transport)\r\nreturn NULL;\r\nndev->ntb_transport = transport;\r\nreturn ndev;\r\n}\r\nvoid ntb_unregister_transport(struct ntb_device *ndev)\r\n{\r\nint i;\r\nif (!ndev->ntb_transport)\r\nreturn;\r\nfor (i = 0; i < ndev->max_cbs; i++)\r\nntb_unregister_db_callback(ndev, i);\r\nntb_unregister_event_callback(ndev);\r\nndev->ntb_transport = NULL;\r\n}\r\nint ntb_write_local_spad(struct ntb_device *ndev, unsigned int idx, u32 val)\r\n{\r\nif (idx >= ndev->limits.max_spads)\r\nreturn -EINVAL;\r\ndev_dbg(&ndev->pdev->dev, "Writing %x to local scratch pad index %d\n",\r\nval, idx);\r\nwritel(val, ndev->reg_ofs.spad_read + idx * 4);\r\nreturn 0;\r\n}\r\nint ntb_read_local_spad(struct ntb_device *ndev, unsigned int idx, u32 *val)\r\n{\r\nif (idx >= ndev->limits.max_spads)\r\nreturn -EINVAL;\r\n*val = readl(ndev->reg_ofs.spad_write + idx * 4);\r\ndev_dbg(&ndev->pdev->dev,\r\n"Reading %x from local scratch pad index %d\n", *val, idx);\r\nreturn 0;\r\n}\r\nint ntb_write_remote_spad(struct ntb_device *ndev, unsigned int idx, u32 val)\r\n{\r\nif (idx >= ndev->limits.max_spads)\r\nreturn -EINVAL;\r\ndev_dbg(&ndev->pdev->dev, "Writing %x to remote scratch pad index %d\n",\r\nval, idx);\r\nwritel(val, ndev->reg_ofs.spad_write + idx * 4);\r\nreturn 0;\r\n}\r\nint ntb_read_remote_spad(struct ntb_device *ndev, unsigned int idx, u32 *val)\r\n{\r\nif (idx >= ndev->limits.max_spads)\r\nreturn -EINVAL;\r\n*val = readl(ndev->reg_ofs.spad_read + idx * 4);\r\ndev_dbg(&ndev->pdev->dev,\r\n"Reading %x from remote scratch pad index %d\n", *val, idx);\r\nreturn 0;\r\n}\r\nvoid __iomem *ntb_get_mw_vbase(struct ntb_device *ndev, unsigned int mw)\r\n{\r\nif (mw >= NTB_NUM_MW)\r\nreturn NULL;\r\nreturn ndev->mw[mw].vbase;\r\n}\r\nresource_size_t ntb_get_mw_size(struct ntb_device *ndev, unsigned int mw)\r\n{\r\nif (mw >= NTB_NUM_MW)\r\nreturn 0;\r\nreturn ndev->mw[mw].bar_sz;\r\n}\r\nvoid ntb_set_mw_addr(struct ntb_device *ndev, unsigned int mw, u64 addr)\r\n{\r\nif (mw >= NTB_NUM_MW)\r\nreturn;\r\ndev_dbg(&ndev->pdev->dev, "Writing addr %Lx to BAR %d\n", addr,\r\nMW_TO_BAR(mw));\r\nndev->mw[mw].phys_addr = addr;\r\nswitch (MW_TO_BAR(mw)) {\r\ncase NTB_BAR_23:\r\nwriteq(addr, ndev->reg_ofs.sbar2_xlat);\r\nbreak;\r\ncase NTB_BAR_45:\r\nwriteq(addr, ndev->reg_ofs.sbar4_xlat);\r\nbreak;\r\n}\r\n}\r\nvoid ntb_ring_sdb(struct ntb_device *ndev, unsigned int db)\r\n{\r\ndev_dbg(&ndev->pdev->dev, "%s: ringing doorbell %d\n", __func__, db);\r\nif (ndev->hw_type == BWD_HW)\r\nwriteq((u64) 1 << db, ndev->reg_ofs.sdb);\r\nelse\r\nwritew(((1 << ndev->bits_per_vector) - 1) <<\r\n(db * ndev->bits_per_vector), ndev->reg_ofs.sdb);\r\n}\r\nstatic void ntb_link_event(struct ntb_device *ndev, int link_state)\r\n{\r\nunsigned int event;\r\nif (ndev->link_status == link_state)\r\nreturn;\r\nif (link_state == NTB_LINK_UP) {\r\nu16 status;\r\ndev_info(&ndev->pdev->dev, "Link Up\n");\r\nndev->link_status = NTB_LINK_UP;\r\nevent = NTB_EVENT_HW_LINK_UP;\r\nif (ndev->hw_type == BWD_HW)\r\nstatus = readw(ndev->reg_ofs.lnk_stat);\r\nelse {\r\nint rc = pci_read_config_word(ndev->pdev,\r\nSNB_LINK_STATUS_OFFSET,\r\n&status);\r\nif (rc)\r\nreturn;\r\n}\r\ndev_info(&ndev->pdev->dev, "Link Width %d, Link Speed %d\n",\r\n(status & NTB_LINK_WIDTH_MASK) >> 4,\r\n(status & NTB_LINK_SPEED_MASK));\r\n} else {\r\ndev_info(&ndev->pdev->dev, "Link Down\n");\r\nndev->link_status = NTB_LINK_DOWN;\r\nevent = NTB_EVENT_HW_LINK_DOWN;\r\n}\r\nif (ndev->event_cb)\r\nndev->event_cb(ndev->ntb_transport, event);\r\n}\r\nstatic int ntb_link_status(struct ntb_device *ndev)\r\n{\r\nint link_state;\r\nif (ndev->hw_type == BWD_HW) {\r\nu32 ntb_cntl;\r\nntb_cntl = readl(ndev->reg_ofs.lnk_cntl);\r\nif (ntb_cntl & BWD_CNTL_LINK_DOWN)\r\nlink_state = NTB_LINK_DOWN;\r\nelse\r\nlink_state = NTB_LINK_UP;\r\n} else {\r\nu16 status;\r\nint rc;\r\nrc = pci_read_config_word(ndev->pdev, SNB_LINK_STATUS_OFFSET,\r\n&status);\r\nif (rc)\r\nreturn rc;\r\nif (status & NTB_LINK_STATUS_ACTIVE)\r\nlink_state = NTB_LINK_UP;\r\nelse\r\nlink_state = NTB_LINK_DOWN;\r\n}\r\nntb_link_event(ndev, link_state);\r\nreturn 0;\r\n}\r\nstatic void bwd_link_poll(struct work_struct *work)\r\n{\r\nstruct ntb_device *ndev = container_of(work, struct ntb_device,\r\nhb_timer.work);\r\nunsigned long ts = jiffies;\r\nif (ts > ndev->last_ts + NTB_HB_TIMEOUT) {\r\nint rc = ntb_link_status(ndev);\r\nif (rc)\r\ndev_err(&ndev->pdev->dev,\r\n"Error determining link status\n");\r\n}\r\nschedule_delayed_work(&ndev->hb_timer, NTB_HB_TIMEOUT);\r\n}\r\nstatic int ntb_xeon_setup(struct ntb_device *ndev)\r\n{\r\nint rc;\r\nu8 val;\r\nndev->hw_type = SNB_HW;\r\nrc = pci_read_config_byte(ndev->pdev, NTB_PPD_OFFSET, &val);\r\nif (rc)\r\nreturn rc;\r\nswitch (val & SNB_PPD_CONN_TYPE) {\r\ncase NTB_CONN_B2B:\r\nndev->conn_type = NTB_CONN_B2B;\r\nbreak;\r\ncase NTB_CONN_CLASSIC:\r\ncase NTB_CONN_RP:\r\ndefault:\r\ndev_err(&ndev->pdev->dev, "Only B2B supported at this time\n");\r\nreturn -EINVAL;\r\n}\r\nif (val & SNB_PPD_DEV_TYPE)\r\nndev->dev_type = NTB_DEV_DSD;\r\nelse\r\nndev->dev_type = NTB_DEV_USD;\r\nndev->reg_ofs.pdb = ndev->reg_base + SNB_PDOORBELL_OFFSET;\r\nndev->reg_ofs.pdb_mask = ndev->reg_base + SNB_PDBMSK_OFFSET;\r\nndev->reg_ofs.sbar2_xlat = ndev->reg_base + SNB_SBAR2XLAT_OFFSET;\r\nndev->reg_ofs.sbar4_xlat = ndev->reg_base + SNB_SBAR4XLAT_OFFSET;\r\nndev->reg_ofs.lnk_cntl = ndev->reg_base + SNB_NTBCNTL_OFFSET;\r\nndev->reg_ofs.lnk_stat = ndev->reg_base + SNB_LINK_STATUS_OFFSET;\r\nndev->reg_ofs.spad_read = ndev->reg_base + SNB_SPAD_OFFSET;\r\nndev->reg_ofs.spci_cmd = ndev->reg_base + SNB_PCICMD_OFFSET;\r\nif (ndev->conn_type == NTB_CONN_B2B) {\r\nndev->reg_ofs.sdb = ndev->reg_base + SNB_B2B_DOORBELL_OFFSET;\r\nndev->reg_ofs.spad_write = ndev->reg_base + SNB_B2B_SPAD_OFFSET;\r\nndev->limits.max_spads = SNB_MAX_SPADS;\r\n} else {\r\nndev->reg_ofs.sdb = ndev->reg_base + SNB_SDOORBELL_OFFSET;\r\nndev->reg_ofs.spad_write = ndev->reg_base + SNB_SPAD_OFFSET;\r\nndev->limits.max_spads = SNB_MAX_COMPAT_SPADS;\r\n}\r\nndev->limits.max_db_bits = SNB_MAX_DB_BITS;\r\nndev->limits.msix_cnt = SNB_MSIX_CNT;\r\nndev->bits_per_vector = SNB_DB_BITS_PER_VEC;\r\nreturn 0;\r\n}\r\nstatic int ntb_bwd_setup(struct ntb_device *ndev)\r\n{\r\nint rc;\r\nu32 val;\r\nndev->hw_type = BWD_HW;\r\nrc = pci_read_config_dword(ndev->pdev, NTB_PPD_OFFSET, &val);\r\nif (rc)\r\nreturn rc;\r\nswitch ((val & BWD_PPD_CONN_TYPE) >> 8) {\r\ncase NTB_CONN_B2B:\r\nndev->conn_type = NTB_CONN_B2B;\r\nbreak;\r\ncase NTB_CONN_RP:\r\ndefault:\r\ndev_err(&ndev->pdev->dev, "Only B2B supported at this time\n");\r\nreturn -EINVAL;\r\n}\r\nif (val & BWD_PPD_DEV_TYPE)\r\nndev->dev_type = NTB_DEV_DSD;\r\nelse\r\nndev->dev_type = NTB_DEV_USD;\r\nrc = pci_write_config_dword(ndev->pdev, NTB_PPD_OFFSET,\r\nval | BWD_PPD_INIT_LINK);\r\nif (rc)\r\nreturn rc;\r\nndev->reg_ofs.pdb = ndev->reg_base + BWD_PDOORBELL_OFFSET;\r\nndev->reg_ofs.pdb_mask = ndev->reg_base + BWD_PDBMSK_OFFSET;\r\nndev->reg_ofs.sbar2_xlat = ndev->reg_base + BWD_SBAR2XLAT_OFFSET;\r\nndev->reg_ofs.sbar4_xlat = ndev->reg_base + BWD_SBAR4XLAT_OFFSET;\r\nndev->reg_ofs.lnk_cntl = ndev->reg_base + BWD_NTBCNTL_OFFSET;\r\nndev->reg_ofs.lnk_stat = ndev->reg_base + BWD_LINK_STATUS_OFFSET;\r\nndev->reg_ofs.spad_read = ndev->reg_base + BWD_SPAD_OFFSET;\r\nndev->reg_ofs.spci_cmd = ndev->reg_base + BWD_PCICMD_OFFSET;\r\nif (ndev->conn_type == NTB_CONN_B2B) {\r\nndev->reg_ofs.sdb = ndev->reg_base + BWD_B2B_DOORBELL_OFFSET;\r\nndev->reg_ofs.spad_write = ndev->reg_base + BWD_B2B_SPAD_OFFSET;\r\nndev->limits.max_spads = BWD_MAX_SPADS;\r\n} else {\r\nndev->reg_ofs.sdb = ndev->reg_base + BWD_PDOORBELL_OFFSET;\r\nndev->reg_ofs.spad_write = ndev->reg_base + BWD_SPAD_OFFSET;\r\nndev->limits.max_spads = BWD_MAX_COMPAT_SPADS;\r\n}\r\nndev->limits.max_db_bits = BWD_MAX_DB_BITS;\r\nndev->limits.msix_cnt = BWD_MSIX_CNT;\r\nndev->bits_per_vector = BWD_DB_BITS_PER_VEC;\r\nINIT_DELAYED_WORK(&ndev->hb_timer, bwd_link_poll);\r\nschedule_delayed_work(&ndev->hb_timer, NTB_HB_TIMEOUT);\r\nreturn 0;\r\n}\r\nstatic int ntb_device_setup(struct ntb_device *ndev)\r\n{\r\nint rc;\r\nswitch (ndev->pdev->device) {\r\ncase PCI_DEVICE_ID_INTEL_NTB_2ND_SNB:\r\ncase PCI_DEVICE_ID_INTEL_NTB_RP_JSF:\r\ncase PCI_DEVICE_ID_INTEL_NTB_RP_SNB:\r\ncase PCI_DEVICE_ID_INTEL_NTB_CLASSIC_JSF:\r\ncase PCI_DEVICE_ID_INTEL_NTB_CLASSIC_SNB:\r\ncase PCI_DEVICE_ID_INTEL_NTB_B2B_JSF:\r\ncase PCI_DEVICE_ID_INTEL_NTB_B2B_SNB:\r\nrc = ntb_xeon_setup(ndev);\r\nbreak;\r\ncase PCI_DEVICE_ID_INTEL_NTB_B2B_BWD:\r\nrc = ntb_bwd_setup(ndev);\r\nbreak;\r\ndefault:\r\nrc = -ENODEV;\r\n}\r\nwritew(PCI_COMMAND_MEMORY | PCI_COMMAND_MASTER, ndev->reg_ofs.spci_cmd);\r\nreturn rc;\r\n}\r\nstatic void ntb_device_free(struct ntb_device *ndev)\r\n{\r\nif (ndev->hw_type == BWD_HW)\r\ncancel_delayed_work_sync(&ndev->hb_timer);\r\n}\r\nstatic irqreturn_t bwd_callback_msix_irq(int irq, void *data)\r\n{\r\nstruct ntb_db_cb *db_cb = data;\r\nstruct ntb_device *ndev = db_cb->ndev;\r\ndev_dbg(&ndev->pdev->dev, "MSI-X irq %d received for DB %d\n", irq,\r\ndb_cb->db_num);\r\nif (db_cb->callback)\r\ndb_cb->callback(db_cb->data, db_cb->db_num);\r\nndev->last_ts = jiffies;\r\nwriteq((u64) 1 << db_cb->db_num, ndev->reg_ofs.pdb);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t xeon_callback_msix_irq(int irq, void *data)\r\n{\r\nstruct ntb_db_cb *db_cb = data;\r\nstruct ntb_device *ndev = db_cb->ndev;\r\ndev_dbg(&ndev->pdev->dev, "MSI-X irq %d received for DB %d\n", irq,\r\ndb_cb->db_num);\r\nif (db_cb->callback)\r\ndb_cb->callback(db_cb->data, db_cb->db_num);\r\nwritew(((1 << ndev->bits_per_vector) - 1) <<\r\n(db_cb->db_num * ndev->bits_per_vector), ndev->reg_ofs.pdb);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t xeon_event_msix_irq(int irq, void *dev)\r\n{\r\nstruct ntb_device *ndev = dev;\r\nint rc;\r\ndev_dbg(&ndev->pdev->dev, "MSI-X irq %d received for Events\n", irq);\r\nrc = ntb_link_status(ndev);\r\nif (rc)\r\ndev_err(&ndev->pdev->dev, "Error determining link status\n");\r\nwritew(1 << ndev->limits.max_db_bits, ndev->reg_ofs.pdb);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t ntb_interrupt(int irq, void *dev)\r\n{\r\nstruct ntb_device *ndev = dev;\r\nunsigned int i = 0;\r\nif (ndev->hw_type == BWD_HW) {\r\nu64 pdb = readq(ndev->reg_ofs.pdb);\r\ndev_dbg(&ndev->pdev->dev, "irq %d - pdb = %Lx\n", irq, pdb);\r\nwhile (pdb) {\r\ni = __ffs(pdb);\r\npdb &= pdb - 1;\r\nbwd_callback_msix_irq(irq, &ndev->db_cb[i]);\r\n}\r\n} else {\r\nu16 pdb = readw(ndev->reg_ofs.pdb);\r\ndev_dbg(&ndev->pdev->dev, "irq %d - pdb = %x sdb %x\n", irq,\r\npdb, readw(ndev->reg_ofs.sdb));\r\nif (pdb & SNB_DB_HW_LINK) {\r\nxeon_event_msix_irq(irq, dev);\r\npdb &= ~SNB_DB_HW_LINK;\r\n}\r\nwhile (pdb) {\r\ni = __ffs(pdb);\r\npdb &= pdb - 1;\r\nxeon_callback_msix_irq(irq, &ndev->db_cb[i]);\r\n}\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int ntb_setup_msix(struct ntb_device *ndev)\r\n{\r\nstruct pci_dev *pdev = ndev->pdev;\r\nstruct msix_entry *msix;\r\nint msix_entries;\r\nint rc, i, pos;\r\nu16 val;\r\npos = pci_find_capability(pdev, PCI_CAP_ID_MSIX);\r\nif (!pos) {\r\nrc = -EIO;\r\ngoto err;\r\n}\r\nrc = pci_read_config_word(pdev, pos + PCI_MSIX_FLAGS, &val);\r\nif (rc)\r\ngoto err;\r\nmsix_entries = msix_table_size(val);\r\nif (msix_entries > ndev->limits.msix_cnt) {\r\nrc = -EINVAL;\r\ngoto err;\r\n}\r\nndev->msix_entries = kmalloc(sizeof(struct msix_entry) * msix_entries,\r\nGFP_KERNEL);\r\nif (!ndev->msix_entries) {\r\nrc = -ENOMEM;\r\ngoto err;\r\n}\r\nfor (i = 0; i < msix_entries; i++)\r\nndev->msix_entries[i].entry = i;\r\nrc = pci_enable_msix(pdev, ndev->msix_entries, msix_entries);\r\nif (rc < 0)\r\ngoto err1;\r\nif (rc > 0) {\r\nif (ndev->hw_type != BWD_HW) {\r\nrc = -EIO;\r\ngoto err1;\r\n}\r\ndev_warn(&pdev->dev,\r\n"Only %d MSI-X vectors. Limiting the number of queues to that number.\n",\r\nrc);\r\nmsix_entries = rc;\r\n}\r\nfor (i = 0; i < msix_entries; i++) {\r\nmsix = &ndev->msix_entries[i];\r\nWARN_ON(!msix->vector);\r\nif (ndev->hw_type == BWD_HW) {\r\nrc = request_irq(msix->vector, bwd_callback_msix_irq, 0,\r\n"ntb-callback-msix", &ndev->db_cb[i]);\r\nif (rc)\r\ngoto err2;\r\n} else {\r\nif (i == msix_entries - 1) {\r\nrc = request_irq(msix->vector,\r\nxeon_event_msix_irq, 0,\r\n"ntb-event-msix", ndev);\r\nif (rc)\r\ngoto err2;\r\n} else {\r\nrc = request_irq(msix->vector,\r\nxeon_callback_msix_irq, 0,\r\n"ntb-callback-msix",\r\n&ndev->db_cb[i]);\r\nif (rc)\r\ngoto err2;\r\n}\r\n}\r\n}\r\nndev->num_msix = msix_entries;\r\nif (ndev->hw_type == BWD_HW)\r\nndev->max_cbs = msix_entries;\r\nelse\r\nndev->max_cbs = msix_entries - 1;\r\nreturn 0;\r\nerr2:\r\nwhile (--i >= 0) {\r\nmsix = &ndev->msix_entries[i];\r\nif (ndev->hw_type != BWD_HW && i == ndev->num_msix - 1)\r\nfree_irq(msix->vector, ndev);\r\nelse\r\nfree_irq(msix->vector, &ndev->db_cb[i]);\r\n}\r\npci_disable_msix(pdev);\r\nerr1:\r\nkfree(ndev->msix_entries);\r\ndev_err(&pdev->dev, "Error allocating MSI-X interrupt\n");\r\nerr:\r\nndev->num_msix = 0;\r\nreturn rc;\r\n}\r\nstatic int ntb_setup_msi(struct ntb_device *ndev)\r\n{\r\nstruct pci_dev *pdev = ndev->pdev;\r\nint rc;\r\nrc = pci_enable_msi(pdev);\r\nif (rc)\r\nreturn rc;\r\nrc = request_irq(pdev->irq, ntb_interrupt, 0, "ntb-msi", ndev);\r\nif (rc) {\r\npci_disable_msi(pdev);\r\ndev_err(&pdev->dev, "Error allocating MSI interrupt\n");\r\nreturn rc;\r\n}\r\nreturn 0;\r\n}\r\nstatic int ntb_setup_intx(struct ntb_device *ndev)\r\n{\r\nstruct pci_dev *pdev = ndev->pdev;\r\nint rc;\r\npci_msi_off(pdev);\r\npci_intx(pdev, 1);\r\nrc = request_irq(pdev->irq, ntb_interrupt, IRQF_SHARED, "ntb-intx",\r\nndev);\r\nif (rc)\r\nreturn rc;\r\nreturn 0;\r\n}\r\nstatic int ntb_setup_interrupts(struct ntb_device *ndev)\r\n{\r\nint rc;\r\nif (ndev->hw_type == BWD_HW)\r\nwriteq(~0, ndev->reg_ofs.pdb_mask);\r\nelse\r\nwritew(~(1 << ndev->limits.max_db_bits),\r\nndev->reg_ofs.pdb_mask);\r\nrc = ntb_setup_msix(ndev);\r\nif (!rc)\r\ngoto done;\r\nndev->bits_per_vector = 1;\r\nndev->max_cbs = ndev->limits.max_db_bits;\r\nrc = ntb_setup_msi(ndev);\r\nif (!rc)\r\ngoto done;\r\nrc = ntb_setup_intx(ndev);\r\nif (rc) {\r\ndev_err(&ndev->pdev->dev, "no usable interrupts\n");\r\nreturn rc;\r\n}\r\ndone:\r\nreturn 0;\r\n}\r\nstatic void ntb_free_interrupts(struct ntb_device *ndev)\r\n{\r\nstruct pci_dev *pdev = ndev->pdev;\r\nif (ndev->hw_type == BWD_HW)\r\nwriteq(~0, ndev->reg_ofs.pdb_mask);\r\nelse\r\nwritew(~0, ndev->reg_ofs.pdb_mask);\r\nif (ndev->num_msix) {\r\nstruct msix_entry *msix;\r\nu32 i;\r\nfor (i = 0; i < ndev->num_msix; i++) {\r\nmsix = &ndev->msix_entries[i];\r\nif (ndev->hw_type != BWD_HW && i == ndev->num_msix - 1)\r\nfree_irq(msix->vector, ndev);\r\nelse\r\nfree_irq(msix->vector, &ndev->db_cb[i]);\r\n}\r\npci_disable_msix(pdev);\r\n} else {\r\nfree_irq(pdev->irq, ndev);\r\nif (pci_dev_msi_enabled(pdev))\r\npci_disable_msi(pdev);\r\n}\r\n}\r\nstatic int ntb_create_callbacks(struct ntb_device *ndev)\r\n{\r\nint i;\r\nndev->db_cb = kcalloc(ndev->limits.max_db_bits,\r\nsizeof(struct ntb_db_cb),\r\nGFP_KERNEL);\r\nif (!ndev->db_cb)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < ndev->limits.max_db_bits; i++) {\r\nndev->db_cb[i].db_num = i;\r\nndev->db_cb[i].ndev = ndev;\r\n}\r\nreturn 0;\r\n}\r\nstatic void ntb_free_callbacks(struct ntb_device *ndev)\r\n{\r\nint i;\r\nfor (i = 0; i < ndev->limits.max_db_bits; i++)\r\nntb_unregister_db_callback(ndev, i);\r\nkfree(ndev->db_cb);\r\n}\r\nstatic int ntb_pci_probe(struct pci_dev *pdev, const struct pci_device_id *id)\r\n{\r\nstruct ntb_device *ndev;\r\nint rc, i;\r\nndev = kzalloc(sizeof(struct ntb_device), GFP_KERNEL);\r\nif (!ndev)\r\nreturn -ENOMEM;\r\nndev->pdev = pdev;\r\nndev->link_status = NTB_LINK_DOWN;\r\npci_set_drvdata(pdev, ndev);\r\nrc = pci_enable_device(pdev);\r\nif (rc)\r\ngoto err;\r\npci_set_master(ndev->pdev);\r\nrc = pci_request_selected_regions(pdev, NTB_BAR_MASK, KBUILD_MODNAME);\r\nif (rc)\r\ngoto err1;\r\nndev->reg_base = pci_ioremap_bar(pdev, NTB_BAR_MMIO);\r\nif (!ndev->reg_base) {\r\ndev_warn(&pdev->dev, "Cannot remap BAR 0\n");\r\nrc = -EIO;\r\ngoto err2;\r\n}\r\nfor (i = 0; i < NTB_NUM_MW; i++) {\r\nndev->mw[i].bar_sz = pci_resource_len(pdev, MW_TO_BAR(i));\r\nndev->mw[i].vbase =\r\nioremap_wc(pci_resource_start(pdev, MW_TO_BAR(i)),\r\nndev->mw[i].bar_sz);\r\ndev_info(&pdev->dev, "MW %d size %llu\n", i,\r\npci_resource_len(pdev, MW_TO_BAR(i)));\r\nif (!ndev->mw[i].vbase) {\r\ndev_warn(&pdev->dev, "Cannot remap BAR %d\n",\r\nMW_TO_BAR(i));\r\nrc = -EIO;\r\ngoto err3;\r\n}\r\n}\r\nrc = pci_set_dma_mask(pdev, DMA_BIT_MASK(64));\r\nif (rc) {\r\nrc = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (rc)\r\ngoto err3;\r\ndev_warn(&pdev->dev, "Cannot DMA highmem\n");\r\n}\r\nrc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));\r\nif (rc) {\r\nrc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (rc)\r\ngoto err3;\r\ndev_warn(&pdev->dev, "Cannot DMA consistent highmem\n");\r\n}\r\nrc = ntb_device_setup(ndev);\r\nif (rc)\r\ngoto err3;\r\nrc = ntb_create_callbacks(ndev);\r\nif (rc)\r\ngoto err4;\r\nrc = ntb_setup_interrupts(ndev);\r\nif (rc)\r\ngoto err5;\r\nfor (i = 0; i < ndev->limits.max_spads; i++) {\r\nntb_write_local_spad(ndev, i, 0);\r\nntb_write_remote_spad(ndev, i, 0);\r\n}\r\nrc = ntb_transport_init(pdev);\r\nif (rc)\r\ngoto err6;\r\nwritel(NTB_CNTL_BAR23_SNOOP | NTB_CNTL_BAR45_SNOOP,\r\nndev->reg_ofs.lnk_cntl);\r\nreturn 0;\r\nerr6:\r\nntb_free_interrupts(ndev);\r\nerr5:\r\nntb_free_callbacks(ndev);\r\nerr4:\r\nntb_device_free(ndev);\r\nerr3:\r\nfor (i--; i >= 0; i--)\r\niounmap(ndev->mw[i].vbase);\r\niounmap(ndev->reg_base);\r\nerr2:\r\npci_release_selected_regions(pdev, NTB_BAR_MASK);\r\nerr1:\r\npci_disable_device(pdev);\r\nerr:\r\nkfree(ndev);\r\ndev_err(&pdev->dev, "Error loading %s module\n", KBUILD_MODNAME);\r\nreturn rc;\r\n}\r\nstatic void ntb_pci_remove(struct pci_dev *pdev)\r\n{\r\nstruct ntb_device *ndev = pci_get_drvdata(pdev);\r\nint i;\r\nu32 ntb_cntl;\r\nntb_cntl = readl(ndev->reg_ofs.lnk_cntl);\r\nntb_cntl |= NTB_LINK_DISABLE;\r\nwritel(ntb_cntl, ndev->reg_ofs.lnk_cntl);\r\nntb_transport_free(ndev->ntb_transport);\r\nntb_free_interrupts(ndev);\r\nntb_free_callbacks(ndev);\r\nntb_device_free(ndev);\r\nfor (i = 0; i < NTB_NUM_MW; i++)\r\niounmap(ndev->mw[i].vbase);\r\niounmap(ndev->reg_base);\r\npci_release_selected_regions(pdev, NTB_BAR_MASK);\r\npci_disable_device(pdev);\r\nkfree(ndev);\r\n}
