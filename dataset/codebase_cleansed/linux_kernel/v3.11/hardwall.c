static int __init noudn(char *str)\r\n{\r\npr_info("User-space UDN access is disabled\n");\r\nhardwall_types[HARDWALL_UDN].disabled = 1;\r\nreturn 0;\r\n}\r\nstatic int __init noidn(char *str)\r\n{\r\npr_info("User-space IDN access is disabled\n");\r\nhardwall_types[HARDWALL_IDN].disabled = 1;\r\nreturn 0;\r\n}\r\nstatic int __init noipi(char *str)\r\n{\r\npr_info("User-space IPI access is disabled\n");\r\nhardwall_types[HARDWALL_IPI].disabled = 1;\r\nreturn 0;\r\n}\r\nstatic int contains(struct hardwall_info *r, int x, int y)\r\n{\r\nreturn (x >= r->ulhc_x && x < r->ulhc_x + r->width) &&\r\n(y >= r->ulhc_y && y < r->ulhc_y + r->height);\r\n}\r\nstatic int check_rectangle(struct hardwall_info *r, struct cpumask *mask)\r\n{\r\nint x, y, cpu, ulhc, lrhc;\r\nulhc = find_first_bit(cpumask_bits(mask), nr_cpumask_bits);\r\nlrhc = find_last_bit(cpumask_bits(mask), nr_cpumask_bits);\r\nr->ulhc_x = cpu_x(ulhc);\r\nr->ulhc_y = cpu_y(ulhc);\r\nr->width = cpu_x(lrhc) - r->ulhc_x + 1;\r\nr->height = cpu_y(lrhc) - r->ulhc_y + 1;\r\nif (r->width <= 0 || r->height <= 0)\r\nreturn -EINVAL;\r\nfor (y = 0, cpu = 0; y < smp_height; ++y)\r\nfor (x = 0; x < smp_width; ++x, ++cpu)\r\nif (cpumask_test_cpu(cpu, mask) != contains(r, x, y))\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic inline int xdn_which_interrupt(struct hardwall_type *hwt)\r\n{\r\n#ifndef __tilepro__\r\nif (hwt->is_idn)\r\nreturn INT_IDN_FIREWALL;\r\n#endif\r\nreturn INT_UDN_FIREWALL;\r\n}\r\nstatic void enable_firewall_interrupts(struct hardwall_type *hwt)\r\n{\r\narch_local_irq_unmask_now(xdn_which_interrupt(hwt));\r\n}\r\nstatic void disable_firewall_interrupts(struct hardwall_type *hwt)\r\n{\r\narch_local_irq_mask_now(xdn_which_interrupt(hwt));\r\n}\r\nstatic void hardwall_setup_func(void *info)\r\n{\r\nstruct hardwall_info *r = info;\r\nstruct hardwall_type *hwt = r->type;\r\nint cpu = smp_processor_id();\r\nint x = cpu % smp_width;\r\nint y = cpu / smp_width;\r\nint bits = 0;\r\nif (x == r->ulhc_x)\r\nbits |= W_PROTECT;\r\nif (x == r->ulhc_x + r->width - 1)\r\nbits |= E_PROTECT;\r\nif (y == r->ulhc_y)\r\nbits |= N_PROTECT;\r\nif (y == r->ulhc_y + r->height - 1)\r\nbits |= S_PROTECT;\r\nBUG_ON(bits == 0);\r\nmtspr_XDN(hwt, DIRECTION_PROTECT, bits);\r\nenable_firewall_interrupts(hwt);\r\n}\r\nstatic void hardwall_protect_rectangle(struct hardwall_info *r)\r\n{\r\nint x, y, cpu, delta;\r\nstruct cpumask rect_cpus;\r\ncpumask_clear(&rect_cpus);\r\ncpu = r->ulhc_y * smp_width + r->ulhc_x;\r\ndelta = (r->height - 1) * smp_width;\r\nfor (x = 0; x < r->width; ++x, ++cpu) {\r\ncpu_online_set(cpu, &rect_cpus);\r\ncpu_online_set(cpu + delta, &rect_cpus);\r\n}\r\ncpu -= r->width;\r\ndelta = r->width - 1;\r\nfor (y = 0; y < r->height; ++y, cpu += smp_width) {\r\ncpu_online_set(cpu, &rect_cpus);\r\ncpu_online_set(cpu + delta, &rect_cpus);\r\n}\r\non_each_cpu_mask(&rect_cpus, hardwall_setup_func, r, 1);\r\n}\r\nvoid __kprobes do_hardwall_trap(struct pt_regs* regs, int fault_num)\r\n{\r\nstruct hardwall_info *rect;\r\nstruct hardwall_type *hwt;\r\nstruct task_struct *p;\r\nstruct siginfo info;\r\nint cpu = smp_processor_id();\r\nint found_processes;\r\nunsigned long flags;\r\nstruct pt_regs *old_regs = set_irq_regs(regs);\r\nirq_enter();\r\nswitch (fault_num) {\r\n#ifndef __tilepro__\r\ncase INT_IDN_FIREWALL:\r\nhwt = &hardwall_types[HARDWALL_IDN];\r\nbreak;\r\n#endif\r\ncase INT_UDN_FIREWALL:\r\nhwt = &hardwall_types[HARDWALL_UDN];\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\nBUG_ON(hwt->disabled);\r\nspin_lock_irqsave(&hwt->lock, flags);\r\nlist_for_each_entry(rect, &hwt->list, list) {\r\nif (cpumask_test_cpu(cpu, &rect->cpumask))\r\nbreak;\r\n}\r\nBUG_ON(&rect->list == &hwt->list);\r\nif (rect->teardown_in_progress) {\r\npr_notice("cpu %d: detected %s hardwall violation %#lx"\r\n" while teardown already in progress\n",\r\ncpu, hwt->name,\r\n(long)mfspr_XDN(hwt, DIRECTION_PROTECT));\r\ngoto done;\r\n}\r\nrect->teardown_in_progress = 1;\r\nwmb();\r\npr_notice("cpu %d: detected %s hardwall violation %#lx...\n",\r\ncpu, hwt->name, (long)mfspr_XDN(hwt, DIRECTION_PROTECT));\r\ninfo.si_signo = SIGILL;\r\ninfo.si_errno = 0;\r\ninfo.si_code = ILL_HARDWALL;\r\nfound_processes = 0;\r\nlist_for_each_entry(p, &rect->task_head,\r\nthread.hardwall[hwt->index].list) {\r\nBUG_ON(p->thread.hardwall[hwt->index].info != rect);\r\nif (!(p->flags & PF_EXITING)) {\r\nfound_processes = 1;\r\npr_notice("hardwall: killing %d\n", p->pid);\r\ndo_send_sig_info(info.si_signo, &info, p, false);\r\n}\r\n}\r\nif (!found_processes)\r\npr_notice("hardwall: no associated processes!\n");\r\ndone:\r\nspin_unlock_irqrestore(&hwt->lock, flags);\r\ndisable_firewall_interrupts(hwt);\r\nirq_exit();\r\nset_irq_regs(old_regs);\r\n}\r\nvoid grant_hardwall_mpls(struct hardwall_type *hwt)\r\n{\r\n#ifndef __tilepro__\r\nif (!hwt->is_xdn) {\r\n__insn_mtspr(SPR_MPL_IPI_0_SET_0, 1);\r\nreturn;\r\n}\r\n#endif\r\nmtspr_MPL_XDN(hwt, ACCESS_SET_0, 1);\r\nmtspr_MPL_XDN(hwt, AVAIL_SET_0, 1);\r\nmtspr_MPL_XDN(hwt, COMPLETE_SET_0, 1);\r\nmtspr_MPL_XDN(hwt, TIMER_SET_0, 1);\r\n#if !CHIP_HAS_REV1_XDN()\r\nmtspr_MPL_XDN(hwt, REFILL_SET_0, 1);\r\nmtspr_MPL_XDN(hwt, CA_SET_0, 1);\r\n#endif\r\n}\r\nvoid restrict_hardwall_mpls(struct hardwall_type *hwt)\r\n{\r\n#ifndef __tilepro__\r\nif (!hwt->is_xdn) {\r\n__insn_mtspr(SPR_MPL_IPI_0_SET_1, 1);\r\nreturn;\r\n}\r\n#endif\r\nmtspr_MPL_XDN(hwt, ACCESS_SET_1, 1);\r\nmtspr_MPL_XDN(hwt, AVAIL_SET_1, 1);\r\nmtspr_MPL_XDN(hwt, COMPLETE_SET_1, 1);\r\nmtspr_MPL_XDN(hwt, TIMER_SET_1, 1);\r\n#if !CHIP_HAS_REV1_XDN()\r\nmtspr_MPL_XDN(hwt, REFILL_SET_1, 1);\r\nmtspr_MPL_XDN(hwt, CA_SET_1, 1);\r\n#endif\r\n}\r\nvoid hardwall_switch_tasks(struct task_struct *prev,\r\nstruct task_struct *next)\r\n{\r\nint i;\r\nfor (i = 0; i < HARDWALL_TYPES; ++i) {\r\nif (prev->thread.hardwall[i].info != NULL) {\r\nif (next->thread.hardwall[i].info == NULL)\r\nrestrict_hardwall_mpls(&hardwall_types[i]);\r\n} else if (next->thread.hardwall[i].info != NULL) {\r\ngrant_hardwall_mpls(&hardwall_types[i]);\r\n}\r\n}\r\n}\r\nint hardwall_ipi_valid(int cpu)\r\n{\r\n#ifdef __tilegx__\r\nstruct hardwall_info *info =\r\ncurrent->thread.hardwall[HARDWALL_IPI].info;\r\nreturn info && cpumask_test_cpu(cpu, &info->cpumask);\r\n#else\r\nreturn 0;\r\n#endif\r\n}\r\nstatic struct hardwall_info *hardwall_create(struct hardwall_type *hwt,\r\nsize_t size,\r\nconst unsigned char __user *bits)\r\n{\r\nstruct hardwall_info *iter, *info;\r\nstruct cpumask mask;\r\nunsigned long flags;\r\nint rc;\r\nif (size > PAGE_SIZE)\r\nreturn ERR_PTR(-EINVAL);\r\nif (copy_from_user(&mask, bits, min(sizeof(struct cpumask), size)))\r\nreturn ERR_PTR(-EFAULT);\r\nif (size < sizeof(struct cpumask)) {\r\nmemset((char *)&mask + size, 0, sizeof(struct cpumask) - size);\r\n} else if (size > sizeof(struct cpumask)) {\r\nsize_t i;\r\nfor (i = sizeof(struct cpumask); i < size; ++i) {\r\nchar c;\r\nif (get_user(c, &bits[i]))\r\nreturn ERR_PTR(-EFAULT);\r\nif (c)\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\n}\r\ninfo = kmalloc(sizeof(struct hardwall_info),\r\nGFP_KERNEL | __GFP_ZERO);\r\nif (info == NULL)\r\nreturn ERR_PTR(-ENOMEM);\r\nINIT_LIST_HEAD(&info->task_head);\r\ninfo->type = hwt;\r\ncpumask_copy(&info->cpumask, &mask);\r\ninfo->id = find_first_bit(cpumask_bits(&mask), nr_cpumask_bits);\r\nif (hwt->is_xdn) {\r\nrc = check_rectangle(info, &mask);\r\nif (rc != 0) {\r\nkfree(info);\r\nreturn ERR_PTR(rc);\r\n}\r\n}\r\nspin_lock_irqsave(&hwt->lock, flags);\r\nlist_for_each_entry(iter, &hwt->list, list) {\r\nif (cpumask_intersects(&iter->cpumask, &info->cpumask)) {\r\nspin_unlock_irqrestore(&hwt->lock, flags);\r\nkfree(info);\r\nreturn ERR_PTR(-EBUSY);\r\n}\r\n}\r\nlist_add_tail(&info->list, &hwt->list);\r\nspin_unlock_irqrestore(&hwt->lock, flags);\r\nif (hwt->is_xdn)\r\nhardwall_protect_rectangle(info);\r\nhardwall_add_proc(info);\r\nreturn info;\r\n}\r\nstatic int hardwall_activate(struct hardwall_info *info)\r\n{\r\nint cpu;\r\nunsigned long flags;\r\nstruct task_struct *p = current;\r\nstruct thread_struct *ts = &p->thread;\r\nstruct hardwall_type *hwt;\r\nif (info == NULL)\r\nreturn -ENODATA;\r\nif (info->teardown_in_progress)\r\nreturn -EINVAL;\r\nif (cpumask_weight(&p->cpus_allowed) != 1)\r\nreturn -EPERM;\r\ncpu = smp_processor_id();\r\nBUG_ON(cpumask_first(&p->cpus_allowed) != cpu);\r\nif (!cpumask_test_cpu(cpu, &info->cpumask))\r\nreturn -EINVAL;\r\nhwt = info->type;\r\nif (ts->hardwall[hwt->index].info) {\r\nBUG_ON(ts->hardwall[hwt->index].info != info);\r\nreturn 0;\r\n}\r\nts->hardwall[hwt->index].info = info;\r\nspin_lock_irqsave(&hwt->lock, flags);\r\nlist_add(&ts->hardwall[hwt->index].list, &info->task_head);\r\nspin_unlock_irqrestore(&hwt->lock, flags);\r\ngrant_hardwall_mpls(hwt);\r\nprintk(KERN_DEBUG "Pid %d (%s) activated for %s hardwall: cpu %d\n",\r\np->pid, p->comm, hwt->name, cpu);\r\nreturn 0;\r\n}\r\nstatic void _hardwall_deactivate(struct hardwall_type *hwt,\r\nstruct task_struct *task)\r\n{\r\nstruct thread_struct *ts = &task->thread;\r\nif (cpumask_weight(&task->cpus_allowed) != 1) {\r\npr_err("pid %d (%s) releasing %s hardwall with"\r\n" an affinity mask containing %d cpus!\n",\r\ntask->pid, task->comm, hwt->name,\r\ncpumask_weight(&task->cpus_allowed));\r\nBUG();\r\n}\r\nBUG_ON(ts->hardwall[hwt->index].info == NULL);\r\nts->hardwall[hwt->index].info = NULL;\r\nlist_del(&ts->hardwall[hwt->index].list);\r\nif (task == current)\r\nrestrict_hardwall_mpls(hwt);\r\n}\r\nstatic int hardwall_deactivate(struct hardwall_type *hwt,\r\nstruct task_struct *task)\r\n{\r\nunsigned long flags;\r\nint activated;\r\nspin_lock_irqsave(&hwt->lock, flags);\r\nactivated = (task->thread.hardwall[hwt->index].info != NULL);\r\nif (activated)\r\n_hardwall_deactivate(hwt, task);\r\nspin_unlock_irqrestore(&hwt->lock, flags);\r\nif (!activated)\r\nreturn -EINVAL;\r\nprintk(KERN_DEBUG "Pid %d (%s) deactivated for %s hardwall: cpu %d\n",\r\ntask->pid, task->comm, hwt->name, smp_processor_id());\r\nreturn 0;\r\n}\r\nvoid hardwall_deactivate_all(struct task_struct *task)\r\n{\r\nint i;\r\nfor (i = 0; i < HARDWALL_TYPES; ++i)\r\nif (task->thread.hardwall[i].info)\r\nhardwall_deactivate(&hardwall_types[i], task);\r\n}\r\nstatic void stop_xdn_switch(void *arg)\r\n{\r\n#if !CHIP_HAS_REV1_XDN()\r\n__insn_mtspr(SPR_UDN_SP_FREEZE,\r\nSPR_UDN_SP_FREEZE__SP_FRZ_MASK |\r\nSPR_UDN_SP_FREEZE__DEMUX_FRZ_MASK |\r\nSPR_UDN_SP_FREEZE__NON_DEST_EXT_MASK);\r\n#else\r\nstruct hardwall_type *hwt = arg;\r\nunsigned long protect = mfspr_XDN(hwt, DIRECTION_PROTECT);\r\nmtspr_XDN(hwt, DIRECTION_PROTECT, (protect | C_PROTECT) << 5);\r\n#endif\r\n}\r\nstatic void empty_xdn_demuxes(struct hardwall_type *hwt)\r\n{\r\n#ifndef __tilepro__\r\nif (hwt->is_idn) {\r\nwhile (__insn_mfspr(SPR_IDN_DATA_AVAIL) & (1 << 0))\r\n(void) __tile_idn0_receive();\r\nwhile (__insn_mfspr(SPR_IDN_DATA_AVAIL) & (1 << 1))\r\n(void) __tile_idn1_receive();\r\nreturn;\r\n}\r\n#endif\r\nwhile (__insn_mfspr(SPR_UDN_DATA_AVAIL) & (1 << 0))\r\n(void) __tile_udn0_receive();\r\nwhile (__insn_mfspr(SPR_UDN_DATA_AVAIL) & (1 << 1))\r\n(void) __tile_udn1_receive();\r\nwhile (__insn_mfspr(SPR_UDN_DATA_AVAIL) & (1 << 2))\r\n(void) __tile_udn2_receive();\r\nwhile (__insn_mfspr(SPR_UDN_DATA_AVAIL) & (1 << 3))\r\n(void) __tile_udn3_receive();\r\n}\r\nstatic void drain_xdn_switch(void *arg)\r\n{\r\nstruct hardwall_info *info = arg;\r\nstruct hardwall_type *hwt = info->type;\r\n#if CHIP_HAS_REV1_XDN()\r\nint pending = mfspr_XDN(hwt, PENDING);\r\nwhile (pending--) {\r\nempty_xdn_demuxes(hwt);\r\nif (hwt->is_idn)\r\n__tile_idn_send(0);\r\nelse\r\n__tile_udn_send(0);\r\n}\r\natomic_dec(&info->xdn_pending_count);\r\nwhile (atomic_read(&info->xdn_pending_count))\r\nempty_xdn_demuxes(hwt);\r\n#else\r\nint i;\r\nint from_tile_words, ca_count;\r\nfor (i = 0; i < 5; i++) {\r\nint words, j;\r\n__insn_mtspr(SPR_UDN_SP_FIFO_SEL, i);\r\nwords = __insn_mfspr(SPR_UDN_SP_STATE) & 0xF;\r\nfor (j = 0; j < words; j++)\r\n(void) __insn_mfspr(SPR_UDN_SP_FIFO_DATA);\r\nBUG_ON((__insn_mfspr(SPR_UDN_SP_STATE) & 0xF) != 0);\r\n}\r\nfrom_tile_words = (__insn_mfspr(SPR_UDN_DEMUX_STATUS) >> 10) & 0x3;\r\nfor (i = 0; i < from_tile_words; i++)\r\n(void) __insn_mfspr(SPR_UDN_DEMUX_WRITE_FIFO);\r\nempty_xdn_demuxes(hwt);\r\nca_count = __insn_mfspr(SPR_UDN_DEMUX_CA_COUNT);\r\nfor (i = 0; i < ca_count; i++)\r\n(void) __insn_mfspr(SPR_UDN_CA_DATA);\r\nBUG_ON(__insn_mfspr(SPR_UDN_DEMUX_CA_COUNT) != 0);\r\n__insn_mtspr(SPR_UDN_DEMUX_CTL, 1);\r\nfor (i = 0; i < 5; i++) {\r\n__insn_mtspr(SPR_UDN_SP_FIFO_SEL, i);\r\n__insn_mtspr(SPR_UDN_SP_STATE, 0xc3000);\r\n}\r\n#endif\r\n}\r\nstatic void reset_xdn_network_state(struct hardwall_type *hwt)\r\n{\r\nif (hwt->disabled)\r\nreturn;\r\nmtspr_XDN(hwt, DIRECTION_PROTECT, 0);\r\nmtspr_XDN(hwt, AVAIL_EN, 0);\r\nmtspr_XDN(hwt, DEADLOCK_TIMEOUT, 0);\r\n#if !CHIP_HAS_REV1_XDN()\r\n{\r\nunsigned int cpu = smp_processor_id();\r\nunsigned int x = cpu % smp_width;\r\nunsigned int y = cpu / smp_width;\r\n__insn_mtspr(SPR_UDN_TILE_COORD, (x << 18) | (y << 7));\r\n}\r\n__insn_mtspr(SPR_UDN_TAG_VALID, 0xf);\r\n__insn_mtspr(SPR_UDN_TAG_0, (1 << 0));\r\n__insn_mtspr(SPR_UDN_TAG_1, (1 << 1));\r\n__insn_mtspr(SPR_UDN_TAG_2, (1 << 2));\r\n__insn_mtspr(SPR_UDN_TAG_3, (1 << 3));\r\n__insn_mtspr(SPR_UDN_REFILL_EN, 0);\r\n__insn_mtspr(SPR_UDN_DEMUX_QUEUE_SEL, 0);\r\n__insn_mtspr(SPR_UDN_SP_FIFO_SEL, 0);\r\n__insn_mtspr(SPR_UDN_SP_FREEZE, 0);\r\n#endif\r\n}\r\nvoid reset_network_state(void)\r\n{\r\nreset_xdn_network_state(&hardwall_types[HARDWALL_UDN]);\r\n#ifndef __tilepro__\r\nreset_xdn_network_state(&hardwall_types[HARDWALL_IDN]);\r\n#endif\r\n}\r\nstatic void restart_xdn_switch(void *arg)\r\n{\r\nstruct hardwall_type *hwt = arg;\r\n#if CHIP_HAS_REV1_XDN()\r\nempty_xdn_demuxes(hwt);\r\n#endif\r\nreset_xdn_network_state(hwt);\r\ndisable_firewall_interrupts(hwt);\r\n}\r\nstatic void hardwall_destroy(struct hardwall_info *info)\r\n{\r\nstruct task_struct *task;\r\nstruct hardwall_type *hwt;\r\nunsigned long flags;\r\nif (info == NULL)\r\nreturn;\r\nhwt = info->type;\r\ninfo->teardown_in_progress = 1;\r\nspin_lock_irqsave(&hwt->lock, flags);\r\nlist_for_each_entry(task, &info->task_head,\r\nthread.hardwall[hwt->index].list)\r\n_hardwall_deactivate(hwt, task);\r\nspin_unlock_irqrestore(&hwt->lock, flags);\r\nif (hwt->is_xdn) {\r\nprintk(KERN_DEBUG\r\n"Clearing %s hardwall rectangle %dx%d %d,%d\n",\r\nhwt->name, info->width, info->height,\r\ninfo->ulhc_x, info->ulhc_y);\r\non_each_cpu_mask(&info->cpumask, stop_xdn_switch, hwt, 1);\r\n#if CHIP_HAS_REV1_XDN()\r\natomic_set(&info->xdn_pending_count,\r\ncpumask_weight(&info->cpumask));\r\non_each_cpu_mask(&info->cpumask, drain_xdn_switch, info, 0);\r\n#else\r\non_each_cpu_mask(&info->cpumask, drain_xdn_switch, info, 1);\r\n#endif\r\non_each_cpu_mask(&info->cpumask, restart_xdn_switch, hwt, 1);\r\n}\r\nhardwall_remove_proc(info);\r\nspin_lock_irqsave(&hwt->lock, flags);\r\nBUG_ON(!list_empty(&info->task_head));\r\nlist_del(&info->list);\r\nspin_unlock_irqrestore(&hwt->lock, flags);\r\nkfree(info);\r\n}\r\nstatic int hardwall_proc_show(struct seq_file *sf, void *v)\r\n{\r\nstruct hardwall_info *info = sf->private;\r\nchar buf[256];\r\nint rc = cpulist_scnprintf(buf, sizeof(buf), &info->cpumask);\r\nbuf[rc++] = '\n';\r\nseq_write(sf, buf, rc);\r\nreturn 0;\r\n}\r\nstatic int hardwall_proc_open(struct inode *inode,\r\nstruct file *file)\r\n{\r\nreturn single_open(file, hardwall_proc_show, PDE_DATA(inode));\r\n}\r\nstatic void hardwall_add_proc(struct hardwall_info *info)\r\n{\r\nchar buf[64];\r\nsnprintf(buf, sizeof(buf), "%d", info->id);\r\nproc_create_data(buf, 0444, info->type->proc_dir,\r\n&hardwall_proc_fops, info);\r\n}\r\nstatic void hardwall_remove_proc(struct hardwall_info *info)\r\n{\r\nchar buf[64];\r\nsnprintf(buf, sizeof(buf), "%d", info->id);\r\nremove_proc_entry(buf, info->type->proc_dir);\r\n}\r\nint proc_pid_hardwall(struct task_struct *task, char *buffer)\r\n{\r\nint i;\r\nint n = 0;\r\nfor (i = 0; i < HARDWALL_TYPES; ++i) {\r\nstruct hardwall_info *info = task->thread.hardwall[i].info;\r\nif (info)\r\nn += sprintf(&buffer[n], "%s: %d\n",\r\ninfo->type->name, info->id);\r\n}\r\nreturn n;\r\n}\r\nvoid proc_tile_hardwall_init(struct proc_dir_entry *root)\r\n{\r\nint i;\r\nfor (i = 0; i < HARDWALL_TYPES; ++i) {\r\nstruct hardwall_type *hwt = &hardwall_types[i];\r\nif (hwt->disabled)\r\ncontinue;\r\nif (hardwall_proc_dir == NULL)\r\nhardwall_proc_dir = proc_mkdir("hardwall", root);\r\nhwt->proc_dir = proc_mkdir(hwt->name, hardwall_proc_dir);\r\n}\r\n}\r\nstatic long hardwall_ioctl(struct file *file, unsigned int a, unsigned long b)\r\n{\r\nstruct hardwall_info *info = file->private_data;\r\nint minor = iminor(file->f_mapping->host);\r\nstruct hardwall_type* hwt;\r\nif (_IOC_TYPE(a) != HARDWALL_IOCTL_BASE)\r\nreturn -EINVAL;\r\nBUILD_BUG_ON(HARDWALL_TYPES != _HARDWALL_TYPES);\r\nBUILD_BUG_ON(HARDWALL_TYPES !=\r\nsizeof(hardwall_types)/sizeof(hardwall_types[0]));\r\nif (minor < 0 || minor >= HARDWALL_TYPES)\r\nreturn -EINVAL;\r\nhwt = &hardwall_types[minor];\r\nWARN_ON(info && hwt != info->type);\r\nswitch (_IOC_NR(a)) {\r\ncase _HARDWALL_CREATE:\r\nif (hwt->disabled)\r\nreturn -ENOSYS;\r\nif (info != NULL)\r\nreturn -EALREADY;\r\ninfo = hardwall_create(hwt, _IOC_SIZE(a),\r\n(const unsigned char __user *)b);\r\nif (IS_ERR(info))\r\nreturn PTR_ERR(info);\r\nfile->private_data = info;\r\nreturn 0;\r\ncase _HARDWALL_ACTIVATE:\r\nreturn hardwall_activate(info);\r\ncase _HARDWALL_DEACTIVATE:\r\nif (current->thread.hardwall[hwt->index].info != info)\r\nreturn -EINVAL;\r\nreturn hardwall_deactivate(hwt, current);\r\ncase _HARDWALL_GET_ID:\r\nreturn info ? info->id : -EINVAL;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n}\r\nstatic long hardwall_compat_ioctl(struct file *file,\r\nunsigned int a, unsigned long b)\r\n{\r\nreturn hardwall_ioctl(file, a, (unsigned long)compat_ptr(b));\r\n}\r\nstatic int hardwall_flush(struct file *file, fl_owner_t owner)\r\n{\r\nstruct hardwall_info *info = file->private_data;\r\nstruct task_struct *task, *tmp;\r\nunsigned long flags;\r\nif (info) {\r\nstruct hardwall_type *hwt = info->type;\r\nspin_lock_irqsave(&hwt->lock, flags);\r\nlist_for_each_entry_safe(task, tmp, &info->task_head,\r\nthread.hardwall[hwt->index].list) {\r\nif (task->files == owner || task->files == NULL)\r\n_hardwall_deactivate(hwt, task);\r\n}\r\nspin_unlock_irqrestore(&hwt->lock, flags);\r\n}\r\nreturn 0;\r\n}\r\nstatic int hardwall_release(struct inode *inode, struct file *file)\r\n{\r\nhardwall_destroy(file->private_data);\r\nreturn 0;\r\n}\r\nstatic int __init dev_hardwall_init(void)\r\n{\r\nint rc;\r\ndev_t dev;\r\nrc = alloc_chrdev_region(&dev, 0, HARDWALL_TYPES, "hardwall");\r\nif (rc < 0)\r\nreturn rc;\r\ncdev_init(&hardwall_dev, &dev_hardwall_fops);\r\nrc = cdev_add(&hardwall_dev, dev, HARDWALL_TYPES);\r\nif (rc < 0)\r\nreturn rc;\r\nreturn 0;\r\n}
