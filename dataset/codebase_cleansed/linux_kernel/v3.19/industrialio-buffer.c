static bool iio_buffer_is_active(struct iio_buffer *buf)\r\n{\r\nreturn !list_empty(&buf->buffer_list);\r\n}\r\nstatic bool iio_buffer_data_available(struct iio_buffer *buf)\r\n{\r\nreturn buf->access->data_available(buf);\r\n}\r\nssize_t iio_buffer_read_first_n_outer(struct file *filp, char __user *buf,\r\nsize_t n, loff_t *f_ps)\r\n{\r\nstruct iio_dev *indio_dev = filp->private_data;\r\nstruct iio_buffer *rb = indio_dev->buffer;\r\nint ret;\r\nif (!indio_dev->info)\r\nreturn -ENODEV;\r\nif (!rb || !rb->access->read_first_n)\r\nreturn -EINVAL;\r\ndo {\r\nif (!iio_buffer_data_available(rb)) {\r\nif (filp->f_flags & O_NONBLOCK)\r\nreturn -EAGAIN;\r\nret = wait_event_interruptible(rb->pollq,\r\niio_buffer_data_available(rb) ||\r\nindio_dev->info == NULL);\r\nif (ret)\r\nreturn ret;\r\nif (indio_dev->info == NULL)\r\nreturn -ENODEV;\r\n}\r\nret = rb->access->read_first_n(rb, n, buf);\r\nif (ret == 0 && (filp->f_flags & O_NONBLOCK))\r\nret = -EAGAIN;\r\n} while (ret == 0);\r\nreturn ret;\r\n}\r\nunsigned int iio_buffer_poll(struct file *filp,\r\nstruct poll_table_struct *wait)\r\n{\r\nstruct iio_dev *indio_dev = filp->private_data;\r\nstruct iio_buffer *rb = indio_dev->buffer;\r\nif (!indio_dev->info)\r\nreturn -ENODEV;\r\npoll_wait(filp, &rb->pollq, wait);\r\nif (iio_buffer_data_available(rb))\r\nreturn POLLIN | POLLRDNORM;\r\nreturn 0;\r\n}\r\nvoid iio_buffer_wakeup_poll(struct iio_dev *indio_dev)\r\n{\r\nif (!indio_dev->buffer)\r\nreturn;\r\nwake_up(&indio_dev->buffer->pollq);\r\n}\r\nvoid iio_buffer_init(struct iio_buffer *buffer)\r\n{\r\nINIT_LIST_HEAD(&buffer->demux_list);\r\nINIT_LIST_HEAD(&buffer->buffer_list);\r\ninit_waitqueue_head(&buffer->pollq);\r\nkref_init(&buffer->ref);\r\n}\r\nstatic ssize_t iio_show_scan_index(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nreturn sprintf(buf, "%u\n", to_iio_dev_attr(attr)->c->scan_index);\r\n}\r\nstatic ssize_t iio_show_fixed_type(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct iio_dev_attr *this_attr = to_iio_dev_attr(attr);\r\nu8 type = this_attr->c->scan_type.endianness;\r\nif (type == IIO_CPU) {\r\n#ifdef __LITTLE_ENDIAN\r\ntype = IIO_LE;\r\n#else\r\ntype = IIO_BE;\r\n#endif\r\n}\r\nif (this_attr->c->scan_type.repeat > 1)\r\nreturn sprintf(buf, "%s:%c%d/%dX%d>>%u\n",\r\niio_endian_prefix[type],\r\nthis_attr->c->scan_type.sign,\r\nthis_attr->c->scan_type.realbits,\r\nthis_attr->c->scan_type.storagebits,\r\nthis_attr->c->scan_type.repeat,\r\nthis_attr->c->scan_type.shift);\r\nelse\r\nreturn sprintf(buf, "%s:%c%d/%d>>%u\n",\r\niio_endian_prefix[type],\r\nthis_attr->c->scan_type.sign,\r\nthis_attr->c->scan_type.realbits,\r\nthis_attr->c->scan_type.storagebits,\r\nthis_attr->c->scan_type.shift);\r\n}\r\nstatic ssize_t iio_scan_el_show(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nint ret;\r\nstruct iio_dev *indio_dev = dev_to_iio_dev(dev);\r\nret = !!test_bit(to_iio_dev_attr(attr)->address,\r\nindio_dev->buffer->scan_mask);\r\nreturn sprintf(buf, "%d\n", ret);\r\n}\r\nstatic int iio_scan_mask_clear(struct iio_buffer *buffer, int bit)\r\n{\r\nclear_bit(bit, buffer->scan_mask);\r\nreturn 0;\r\n}\r\nstatic ssize_t iio_scan_el_store(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf,\r\nsize_t len)\r\n{\r\nint ret;\r\nbool state;\r\nstruct iio_dev *indio_dev = dev_to_iio_dev(dev);\r\nstruct iio_buffer *buffer = indio_dev->buffer;\r\nstruct iio_dev_attr *this_attr = to_iio_dev_attr(attr);\r\nret = strtobool(buf, &state);\r\nif (ret < 0)\r\nreturn ret;\r\nmutex_lock(&indio_dev->mlock);\r\nif (iio_buffer_is_active(indio_dev->buffer)) {\r\nret = -EBUSY;\r\ngoto error_ret;\r\n}\r\nret = iio_scan_mask_query(indio_dev, buffer, this_attr->address);\r\nif (ret < 0)\r\ngoto error_ret;\r\nif (!state && ret) {\r\nret = iio_scan_mask_clear(buffer, this_attr->address);\r\nif (ret)\r\ngoto error_ret;\r\n} else if (state && !ret) {\r\nret = iio_scan_mask_set(indio_dev, buffer, this_attr->address);\r\nif (ret)\r\ngoto error_ret;\r\n}\r\nerror_ret:\r\nmutex_unlock(&indio_dev->mlock);\r\nreturn ret < 0 ? ret : len;\r\n}\r\nstatic ssize_t iio_scan_el_ts_show(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct iio_dev *indio_dev = dev_to_iio_dev(dev);\r\nreturn sprintf(buf, "%d\n", indio_dev->buffer->scan_timestamp);\r\n}\r\nstatic ssize_t iio_scan_el_ts_store(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf,\r\nsize_t len)\r\n{\r\nint ret;\r\nstruct iio_dev *indio_dev = dev_to_iio_dev(dev);\r\nbool state;\r\nret = strtobool(buf, &state);\r\nif (ret < 0)\r\nreturn ret;\r\nmutex_lock(&indio_dev->mlock);\r\nif (iio_buffer_is_active(indio_dev->buffer)) {\r\nret = -EBUSY;\r\ngoto error_ret;\r\n}\r\nindio_dev->buffer->scan_timestamp = state;\r\nerror_ret:\r\nmutex_unlock(&indio_dev->mlock);\r\nreturn ret ? ret : len;\r\n}\r\nstatic int iio_buffer_add_channel_sysfs(struct iio_dev *indio_dev,\r\nconst struct iio_chan_spec *chan)\r\n{\r\nint ret, attrcount = 0;\r\nstruct iio_buffer *buffer = indio_dev->buffer;\r\nret = __iio_add_chan_devattr("index",\r\nchan,\r\n&iio_show_scan_index,\r\nNULL,\r\n0,\r\nIIO_SEPARATE,\r\n&indio_dev->dev,\r\n&buffer->scan_el_dev_attr_list);\r\nif (ret)\r\nreturn ret;\r\nattrcount++;\r\nret = __iio_add_chan_devattr("type",\r\nchan,\r\n&iio_show_fixed_type,\r\nNULL,\r\n0,\r\n0,\r\n&indio_dev->dev,\r\n&buffer->scan_el_dev_attr_list);\r\nif (ret)\r\nreturn ret;\r\nattrcount++;\r\nif (chan->type != IIO_TIMESTAMP)\r\nret = __iio_add_chan_devattr("en",\r\nchan,\r\n&iio_scan_el_show,\r\n&iio_scan_el_store,\r\nchan->scan_index,\r\n0,\r\n&indio_dev->dev,\r\n&buffer->scan_el_dev_attr_list);\r\nelse\r\nret = __iio_add_chan_devattr("en",\r\nchan,\r\n&iio_scan_el_ts_show,\r\n&iio_scan_el_ts_store,\r\nchan->scan_index,\r\n0,\r\n&indio_dev->dev,\r\n&buffer->scan_el_dev_attr_list);\r\nif (ret)\r\nreturn ret;\r\nattrcount++;\r\nret = attrcount;\r\nreturn ret;\r\n}\r\nint iio_buffer_register(struct iio_dev *indio_dev,\r\nconst struct iio_chan_spec *channels,\r\nint num_channels)\r\n{\r\nstruct iio_dev_attr *p;\r\nstruct attribute **attr;\r\nstruct iio_buffer *buffer = indio_dev->buffer;\r\nint ret, i, attrn, attrcount, attrcount_orig = 0;\r\nif (buffer->attrs)\r\nindio_dev->groups[indio_dev->groupcounter++] = buffer->attrs;\r\nif (buffer->scan_el_attrs != NULL) {\r\nattr = buffer->scan_el_attrs->attrs;\r\nwhile (*attr++ != NULL)\r\nattrcount_orig++;\r\n}\r\nattrcount = attrcount_orig;\r\nINIT_LIST_HEAD(&buffer->scan_el_dev_attr_list);\r\nif (channels) {\r\nfor (i = 0; i < num_channels; i++) {\r\nif (channels[i].scan_index < 0)\r\ncontinue;\r\nif (channels[i].scan_index >\r\n(int)indio_dev->masklength - 1)\r\nindio_dev->masklength\r\n= channels[i].scan_index + 1;\r\nret = iio_buffer_add_channel_sysfs(indio_dev,\r\n&channels[i]);\r\nif (ret < 0)\r\ngoto error_cleanup_dynamic;\r\nattrcount += ret;\r\nif (channels[i].type == IIO_TIMESTAMP)\r\nindio_dev->scan_index_timestamp =\r\nchannels[i].scan_index;\r\n}\r\nif (indio_dev->masklength && buffer->scan_mask == NULL) {\r\nbuffer->scan_mask = kcalloc(BITS_TO_LONGS(indio_dev->masklength),\r\nsizeof(*buffer->scan_mask),\r\nGFP_KERNEL);\r\nif (buffer->scan_mask == NULL) {\r\nret = -ENOMEM;\r\ngoto error_cleanup_dynamic;\r\n}\r\n}\r\n}\r\nbuffer->scan_el_group.name = iio_scan_elements_group_name;\r\nbuffer->scan_el_group.attrs = kcalloc(attrcount + 1,\r\nsizeof(buffer->scan_el_group.attrs[0]),\r\nGFP_KERNEL);\r\nif (buffer->scan_el_group.attrs == NULL) {\r\nret = -ENOMEM;\r\ngoto error_free_scan_mask;\r\n}\r\nif (buffer->scan_el_attrs)\r\nmemcpy(buffer->scan_el_group.attrs, buffer->scan_el_attrs,\r\nsizeof(buffer->scan_el_group.attrs[0])*attrcount_orig);\r\nattrn = attrcount_orig;\r\nlist_for_each_entry(p, &buffer->scan_el_dev_attr_list, l)\r\nbuffer->scan_el_group.attrs[attrn++] = &p->dev_attr.attr;\r\nindio_dev->groups[indio_dev->groupcounter++] = &buffer->scan_el_group;\r\nreturn 0;\r\nerror_free_scan_mask:\r\nkfree(buffer->scan_mask);\r\nerror_cleanup_dynamic:\r\niio_free_chan_devattr_list(&buffer->scan_el_dev_attr_list);\r\nreturn ret;\r\n}\r\nvoid iio_buffer_unregister(struct iio_dev *indio_dev)\r\n{\r\nkfree(indio_dev->buffer->scan_mask);\r\nkfree(indio_dev->buffer->scan_el_group.attrs);\r\niio_free_chan_devattr_list(&indio_dev->buffer->scan_el_dev_attr_list);\r\n}\r\nssize_t iio_buffer_read_length(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct iio_dev *indio_dev = dev_to_iio_dev(dev);\r\nstruct iio_buffer *buffer = indio_dev->buffer;\r\nif (buffer->access->get_length)\r\nreturn sprintf(buf, "%d\n",\r\nbuffer->access->get_length(buffer));\r\nreturn 0;\r\n}\r\nssize_t iio_buffer_write_length(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf,\r\nsize_t len)\r\n{\r\nstruct iio_dev *indio_dev = dev_to_iio_dev(dev);\r\nstruct iio_buffer *buffer = indio_dev->buffer;\r\nunsigned int val;\r\nint ret;\r\nret = kstrtouint(buf, 10, &val);\r\nif (ret)\r\nreturn ret;\r\nif (buffer->access->get_length)\r\nif (val == buffer->access->get_length(buffer))\r\nreturn len;\r\nmutex_lock(&indio_dev->mlock);\r\nif (iio_buffer_is_active(indio_dev->buffer)) {\r\nret = -EBUSY;\r\n} else {\r\nif (buffer->access->set_length)\r\nbuffer->access->set_length(buffer, val);\r\nret = 0;\r\n}\r\nmutex_unlock(&indio_dev->mlock);\r\nreturn ret ? ret : len;\r\n}\r\nssize_t iio_buffer_show_enable(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct iio_dev *indio_dev = dev_to_iio_dev(dev);\r\nreturn sprintf(buf, "%d\n", iio_buffer_is_active(indio_dev->buffer));\r\n}\r\nstatic const unsigned long *iio_scan_mask_match(const unsigned long *av_masks,\r\nunsigned int masklength,\r\nconst unsigned long *mask)\r\n{\r\nif (bitmap_empty(mask, masklength))\r\nreturn NULL;\r\nwhile (*av_masks) {\r\nif (bitmap_subset(mask, av_masks, masklength))\r\nreturn av_masks;\r\nav_masks += BITS_TO_LONGS(masklength);\r\n}\r\nreturn NULL;\r\n}\r\nstatic int iio_compute_scan_bytes(struct iio_dev *indio_dev,\r\nconst unsigned long *mask, bool timestamp)\r\n{\r\nconst struct iio_chan_spec *ch;\r\nunsigned bytes = 0;\r\nint length, i;\r\nfor_each_set_bit(i, mask,\r\nindio_dev->masklength) {\r\nch = iio_find_channel_from_si(indio_dev, i);\r\nif (ch->scan_type.repeat > 1)\r\nlength = ch->scan_type.storagebits / 8 *\r\nch->scan_type.repeat;\r\nelse\r\nlength = ch->scan_type.storagebits / 8;\r\nbytes = ALIGN(bytes, length);\r\nbytes += length;\r\n}\r\nif (timestamp) {\r\nch = iio_find_channel_from_si(indio_dev,\r\nindio_dev->scan_index_timestamp);\r\nif (ch->scan_type.repeat > 1)\r\nlength = ch->scan_type.storagebits / 8 *\r\nch->scan_type.repeat;\r\nelse\r\nlength = ch->scan_type.storagebits / 8;\r\nbytes = ALIGN(bytes, length);\r\nbytes += length;\r\n}\r\nreturn bytes;\r\n}\r\nstatic void iio_buffer_activate(struct iio_dev *indio_dev,\r\nstruct iio_buffer *buffer)\r\n{\r\niio_buffer_get(buffer);\r\nlist_add(&buffer->buffer_list, &indio_dev->buffer_list);\r\n}\r\nstatic void iio_buffer_deactivate(struct iio_buffer *buffer)\r\n{\r\nlist_del_init(&buffer->buffer_list);\r\niio_buffer_put(buffer);\r\n}\r\nvoid iio_disable_all_buffers(struct iio_dev *indio_dev)\r\n{\r\nstruct iio_buffer *buffer, *_buffer;\r\nif (list_empty(&indio_dev->buffer_list))\r\nreturn;\r\nif (indio_dev->setup_ops->predisable)\r\nindio_dev->setup_ops->predisable(indio_dev);\r\nlist_for_each_entry_safe(buffer, _buffer,\r\n&indio_dev->buffer_list, buffer_list)\r\niio_buffer_deactivate(buffer);\r\nindio_dev->currentmode = INDIO_DIRECT_MODE;\r\nif (indio_dev->setup_ops->postdisable)\r\nindio_dev->setup_ops->postdisable(indio_dev);\r\nif (indio_dev->available_scan_masks == NULL)\r\nkfree(indio_dev->active_scan_mask);\r\n}\r\nstatic void iio_buffer_update_bytes_per_datum(struct iio_dev *indio_dev,\r\nstruct iio_buffer *buffer)\r\n{\r\nunsigned int bytes;\r\nif (!buffer->access->set_bytes_per_datum)\r\nreturn;\r\nbytes = iio_compute_scan_bytes(indio_dev, buffer->scan_mask,\r\nbuffer->scan_timestamp);\r\nbuffer->access->set_bytes_per_datum(buffer, bytes);\r\n}\r\nstatic int __iio_update_buffers(struct iio_dev *indio_dev,\r\nstruct iio_buffer *insert_buffer,\r\nstruct iio_buffer *remove_buffer)\r\n{\r\nint ret;\r\nint success = 0;\r\nstruct iio_buffer *buffer;\r\nunsigned long *compound_mask;\r\nconst unsigned long *old_mask;\r\nif (!list_empty(&indio_dev->buffer_list)) {\r\nif (indio_dev->setup_ops->predisable) {\r\nret = indio_dev->setup_ops->predisable(indio_dev);\r\nif (ret)\r\nreturn ret;\r\n}\r\nindio_dev->currentmode = INDIO_DIRECT_MODE;\r\nif (indio_dev->setup_ops->postdisable) {\r\nret = indio_dev->setup_ops->postdisable(indio_dev);\r\nif (ret)\r\nreturn ret;\r\n}\r\n}\r\nold_mask = indio_dev->active_scan_mask;\r\nif (!indio_dev->available_scan_masks)\r\nindio_dev->active_scan_mask = NULL;\r\nif (remove_buffer)\r\niio_buffer_deactivate(remove_buffer);\r\nif (insert_buffer)\r\niio_buffer_activate(indio_dev, insert_buffer);\r\nif (list_empty(&indio_dev->buffer_list)) {\r\nindio_dev->currentmode = INDIO_DIRECT_MODE;\r\nif (indio_dev->available_scan_masks == NULL)\r\nkfree(old_mask);\r\nreturn 0;\r\n}\r\ncompound_mask = kcalloc(BITS_TO_LONGS(indio_dev->masklength),\r\nsizeof(long), GFP_KERNEL);\r\nif (compound_mask == NULL) {\r\nif (indio_dev->available_scan_masks == NULL)\r\nkfree(old_mask);\r\nreturn -ENOMEM;\r\n}\r\nindio_dev->scan_timestamp = 0;\r\nlist_for_each_entry(buffer, &indio_dev->buffer_list, buffer_list) {\r\nbitmap_or(compound_mask, compound_mask, buffer->scan_mask,\r\nindio_dev->masklength);\r\nindio_dev->scan_timestamp |= buffer->scan_timestamp;\r\n}\r\nif (indio_dev->available_scan_masks) {\r\nindio_dev->active_scan_mask =\r\niio_scan_mask_match(indio_dev->available_scan_masks,\r\nindio_dev->masklength,\r\ncompound_mask);\r\nif (indio_dev->active_scan_mask == NULL) {\r\niio_buffer_deactivate(insert_buffer);\r\nif (old_mask) {\r\nindio_dev->active_scan_mask = old_mask;\r\nsuccess = -EINVAL;\r\n}\r\nelse {\r\nkfree(compound_mask);\r\nret = -EINVAL;\r\nreturn ret;\r\n}\r\n}\r\n} else {\r\nindio_dev->active_scan_mask = compound_mask;\r\n}\r\niio_update_demux(indio_dev);\r\nif (indio_dev->setup_ops->preenable) {\r\nret = indio_dev->setup_ops->preenable(indio_dev);\r\nif (ret) {\r\nprintk(KERN_ERR\r\n"Buffer not started: buffer preenable failed (%d)\n", ret);\r\ngoto error_remove_inserted;\r\n}\r\n}\r\nindio_dev->scan_bytes =\r\niio_compute_scan_bytes(indio_dev,\r\nindio_dev->active_scan_mask,\r\nindio_dev->scan_timestamp);\r\nlist_for_each_entry(buffer, &indio_dev->buffer_list, buffer_list) {\r\niio_buffer_update_bytes_per_datum(indio_dev, buffer);\r\nif (buffer->access->request_update) {\r\nret = buffer->access->request_update(buffer);\r\nif (ret) {\r\nprintk(KERN_INFO\r\n"Buffer not started: buffer parameter update failed (%d)\n", ret);\r\ngoto error_run_postdisable;\r\n}\r\n}\r\n}\r\nif (indio_dev->info->update_scan_mode) {\r\nret = indio_dev->info\r\n->update_scan_mode(indio_dev,\r\nindio_dev->active_scan_mask);\r\nif (ret < 0) {\r\nprintk(KERN_INFO "Buffer not started: update scan mode failed (%d)\n", ret);\r\ngoto error_run_postdisable;\r\n}\r\n}\r\nif (indio_dev->modes & INDIO_BUFFER_TRIGGERED) {\r\nif (!indio_dev->trig) {\r\nprintk(KERN_INFO "Buffer not started: no trigger\n");\r\nret = -EINVAL;\r\ngoto error_run_postdisable;\r\n}\r\nindio_dev->currentmode = INDIO_BUFFER_TRIGGERED;\r\n} else if (indio_dev->modes & INDIO_BUFFER_HARDWARE) {\r\nindio_dev->currentmode = INDIO_BUFFER_HARDWARE;\r\n} else {\r\nret = -EINVAL;\r\ngoto error_run_postdisable;\r\n}\r\nif (indio_dev->setup_ops->postenable) {\r\nret = indio_dev->setup_ops->postenable(indio_dev);\r\nif (ret) {\r\nprintk(KERN_INFO\r\n"Buffer not started: postenable failed (%d)\n", ret);\r\nindio_dev->currentmode = INDIO_DIRECT_MODE;\r\nif (indio_dev->setup_ops->postdisable)\r\nindio_dev->setup_ops->postdisable(indio_dev);\r\ngoto error_disable_all_buffers;\r\n}\r\n}\r\nif (indio_dev->available_scan_masks)\r\nkfree(compound_mask);\r\nelse\r\nkfree(old_mask);\r\nreturn success;\r\nerror_disable_all_buffers:\r\nindio_dev->currentmode = INDIO_DIRECT_MODE;\r\nerror_run_postdisable:\r\nif (indio_dev->setup_ops->postdisable)\r\nindio_dev->setup_ops->postdisable(indio_dev);\r\nerror_remove_inserted:\r\nif (insert_buffer)\r\niio_buffer_deactivate(insert_buffer);\r\nindio_dev->active_scan_mask = old_mask;\r\nkfree(compound_mask);\r\nreturn ret;\r\n}\r\nint iio_update_buffers(struct iio_dev *indio_dev,\r\nstruct iio_buffer *insert_buffer,\r\nstruct iio_buffer *remove_buffer)\r\n{\r\nint ret;\r\nif (insert_buffer == remove_buffer)\r\nreturn 0;\r\nmutex_lock(&indio_dev->info_exist_lock);\r\nmutex_lock(&indio_dev->mlock);\r\nif (insert_buffer && iio_buffer_is_active(insert_buffer))\r\ninsert_buffer = NULL;\r\nif (remove_buffer && !iio_buffer_is_active(remove_buffer))\r\nremove_buffer = NULL;\r\nif (!insert_buffer && !remove_buffer) {\r\nret = 0;\r\ngoto out_unlock;\r\n}\r\nif (indio_dev->info == NULL) {\r\nret = -ENODEV;\r\ngoto out_unlock;\r\n}\r\nret = __iio_update_buffers(indio_dev, insert_buffer, remove_buffer);\r\nout_unlock:\r\nmutex_unlock(&indio_dev->mlock);\r\nmutex_unlock(&indio_dev->info_exist_lock);\r\nreturn ret;\r\n}\r\nssize_t iio_buffer_store_enable(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf,\r\nsize_t len)\r\n{\r\nint ret;\r\nbool requested_state;\r\nstruct iio_dev *indio_dev = dev_to_iio_dev(dev);\r\nbool inlist;\r\nret = strtobool(buf, &requested_state);\r\nif (ret < 0)\r\nreturn ret;\r\nmutex_lock(&indio_dev->mlock);\r\ninlist = iio_buffer_is_active(indio_dev->buffer);\r\nif (inlist == requested_state)\r\ngoto done;\r\nif (requested_state)\r\nret = __iio_update_buffers(indio_dev,\r\nindio_dev->buffer, NULL);\r\nelse\r\nret = __iio_update_buffers(indio_dev,\r\nNULL, indio_dev->buffer);\r\nif (ret < 0)\r\ngoto done;\r\ndone:\r\nmutex_unlock(&indio_dev->mlock);\r\nreturn (ret < 0) ? ret : len;\r\n}\r\nbool iio_validate_scan_mask_onehot(struct iio_dev *indio_dev,\r\nconst unsigned long *mask)\r\n{\r\nreturn bitmap_weight(mask, indio_dev->masklength) == 1;\r\n}\r\nstatic bool iio_validate_scan_mask(struct iio_dev *indio_dev,\r\nconst unsigned long *mask)\r\n{\r\nif (!indio_dev->setup_ops->validate_scan_mask)\r\nreturn true;\r\nreturn indio_dev->setup_ops->validate_scan_mask(indio_dev, mask);\r\n}\r\nint iio_scan_mask_set(struct iio_dev *indio_dev,\r\nstruct iio_buffer *buffer, int bit)\r\n{\r\nconst unsigned long *mask;\r\nunsigned long *trialmask;\r\ntrialmask = kmalloc(sizeof(*trialmask)*\r\nBITS_TO_LONGS(indio_dev->masklength),\r\nGFP_KERNEL);\r\nif (trialmask == NULL)\r\nreturn -ENOMEM;\r\nif (!indio_dev->masklength) {\r\nWARN_ON("Trying to set scanmask prior to registering buffer\n");\r\ngoto err_invalid_mask;\r\n}\r\nbitmap_copy(trialmask, buffer->scan_mask, indio_dev->masklength);\r\nset_bit(bit, trialmask);\r\nif (!iio_validate_scan_mask(indio_dev, trialmask))\r\ngoto err_invalid_mask;\r\nif (indio_dev->available_scan_masks) {\r\nmask = iio_scan_mask_match(indio_dev->available_scan_masks,\r\nindio_dev->masklength,\r\ntrialmask);\r\nif (!mask)\r\ngoto err_invalid_mask;\r\n}\r\nbitmap_copy(buffer->scan_mask, trialmask, indio_dev->masklength);\r\nkfree(trialmask);\r\nreturn 0;\r\nerr_invalid_mask:\r\nkfree(trialmask);\r\nreturn -EINVAL;\r\n}\r\nint iio_scan_mask_query(struct iio_dev *indio_dev,\r\nstruct iio_buffer *buffer, int bit)\r\n{\r\nif (bit > indio_dev->masklength)\r\nreturn -EINVAL;\r\nif (!buffer->scan_mask)\r\nreturn 0;\r\nreturn !!test_bit(bit, buffer->scan_mask);\r\n}\r\nstatic const void *iio_demux(struct iio_buffer *buffer,\r\nconst void *datain)\r\n{\r\nstruct iio_demux_table *t;\r\nif (list_empty(&buffer->demux_list))\r\nreturn datain;\r\nlist_for_each_entry(t, &buffer->demux_list, l)\r\nmemcpy(buffer->demux_bounce + t->to,\r\ndatain + t->from, t->length);\r\nreturn buffer->demux_bounce;\r\n}\r\nstatic int iio_push_to_buffer(struct iio_buffer *buffer, const void *data)\r\n{\r\nconst void *dataout = iio_demux(buffer, data);\r\nreturn buffer->access->store_to(buffer, dataout);\r\n}\r\nstatic void iio_buffer_demux_free(struct iio_buffer *buffer)\r\n{\r\nstruct iio_demux_table *p, *q;\r\nlist_for_each_entry_safe(p, q, &buffer->demux_list, l) {\r\nlist_del(&p->l);\r\nkfree(p);\r\n}\r\n}\r\nint iio_push_to_buffers(struct iio_dev *indio_dev, const void *data)\r\n{\r\nint ret;\r\nstruct iio_buffer *buf;\r\nlist_for_each_entry(buf, &indio_dev->buffer_list, buffer_list) {\r\nret = iio_push_to_buffer(buf, data);\r\nif (ret < 0)\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic int iio_buffer_add_demux(struct iio_buffer *buffer,\r\nstruct iio_demux_table **p, unsigned int in_loc, unsigned int out_loc,\r\nunsigned int length)\r\n{\r\nif (*p && (*p)->from + (*p)->length == in_loc &&\r\n(*p)->to + (*p)->length == out_loc) {\r\n(*p)->length += length;\r\n} else {\r\n*p = kmalloc(sizeof(**p), GFP_KERNEL);\r\nif (*p == NULL)\r\nreturn -ENOMEM;\r\n(*p)->from = in_loc;\r\n(*p)->to = out_loc;\r\n(*p)->length = length;\r\nlist_add_tail(&(*p)->l, &buffer->demux_list);\r\n}\r\nreturn 0;\r\n}\r\nstatic int iio_buffer_update_demux(struct iio_dev *indio_dev,\r\nstruct iio_buffer *buffer)\r\n{\r\nconst struct iio_chan_spec *ch;\r\nint ret, in_ind = -1, out_ind, length;\r\nunsigned in_loc = 0, out_loc = 0;\r\nstruct iio_demux_table *p = NULL;\r\niio_buffer_demux_free(buffer);\r\nkfree(buffer->demux_bounce);\r\nbuffer->demux_bounce = NULL;\r\nif (bitmap_equal(indio_dev->active_scan_mask,\r\nbuffer->scan_mask,\r\nindio_dev->masklength))\r\nreturn 0;\r\nfor_each_set_bit(out_ind,\r\nbuffer->scan_mask,\r\nindio_dev->masklength) {\r\nin_ind = find_next_bit(indio_dev->active_scan_mask,\r\nindio_dev->masklength,\r\nin_ind + 1);\r\nwhile (in_ind != out_ind) {\r\nin_ind = find_next_bit(indio_dev->active_scan_mask,\r\nindio_dev->masklength,\r\nin_ind + 1);\r\nch = iio_find_channel_from_si(indio_dev, in_ind);\r\nif (ch->scan_type.repeat > 1)\r\nlength = ch->scan_type.storagebits / 8 *\r\nch->scan_type.repeat;\r\nelse\r\nlength = ch->scan_type.storagebits / 8;\r\nin_loc = roundup(in_loc, length) + length;\r\n}\r\nch = iio_find_channel_from_si(indio_dev, in_ind);\r\nif (ch->scan_type.repeat > 1)\r\nlength = ch->scan_type.storagebits / 8 *\r\nch->scan_type.repeat;\r\nelse\r\nlength = ch->scan_type.storagebits / 8;\r\nout_loc = roundup(out_loc, length);\r\nin_loc = roundup(in_loc, length);\r\nret = iio_buffer_add_demux(buffer, &p, in_loc, out_loc, length);\r\nif (ret)\r\ngoto error_clear_mux_table;\r\nout_loc += length;\r\nin_loc += length;\r\n}\r\nif (buffer->scan_timestamp) {\r\nch = iio_find_channel_from_si(indio_dev,\r\nindio_dev->scan_index_timestamp);\r\nif (ch->scan_type.repeat > 1)\r\nlength = ch->scan_type.storagebits / 8 *\r\nch->scan_type.repeat;\r\nelse\r\nlength = ch->scan_type.storagebits / 8;\r\nout_loc = roundup(out_loc, length);\r\nin_loc = roundup(in_loc, length);\r\nret = iio_buffer_add_demux(buffer, &p, in_loc, out_loc, length);\r\nif (ret)\r\ngoto error_clear_mux_table;\r\nout_loc += length;\r\nin_loc += length;\r\n}\r\nbuffer->demux_bounce = kzalloc(out_loc, GFP_KERNEL);\r\nif (buffer->demux_bounce == NULL) {\r\nret = -ENOMEM;\r\ngoto error_clear_mux_table;\r\n}\r\nreturn 0;\r\nerror_clear_mux_table:\r\niio_buffer_demux_free(buffer);\r\nreturn ret;\r\n}\r\nint iio_update_demux(struct iio_dev *indio_dev)\r\n{\r\nstruct iio_buffer *buffer;\r\nint ret;\r\nlist_for_each_entry(buffer, &indio_dev->buffer_list, buffer_list) {\r\nret = iio_buffer_update_demux(indio_dev, buffer);\r\nif (ret < 0)\r\ngoto error_clear_mux_table;\r\n}\r\nreturn 0;\r\nerror_clear_mux_table:\r\nlist_for_each_entry(buffer, &indio_dev->buffer_list, buffer_list)\r\niio_buffer_demux_free(buffer);\r\nreturn ret;\r\n}\r\nstatic void iio_buffer_release(struct kref *ref)\r\n{\r\nstruct iio_buffer *buffer = container_of(ref, struct iio_buffer, ref);\r\nbuffer->access->release(buffer);\r\n}\r\nstruct iio_buffer *iio_buffer_get(struct iio_buffer *buffer)\r\n{\r\nif (buffer)\r\nkref_get(&buffer->ref);\r\nreturn buffer;\r\n}\r\nvoid iio_buffer_put(struct iio_buffer *buffer)\r\n{\r\nif (buffer)\r\nkref_put(&buffer->ref, iio_buffer_release);\r\n}
