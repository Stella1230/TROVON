void *dma_alloc_noncoherent(struct device *dev, size_t size,\r\ndma_addr_t *dma_handle, gfp_t gfp)\r\n{\r\nvoid *paddr;\r\npaddr = alloc_pages_exact(size, gfp);\r\nif (!paddr)\r\nreturn NULL;\r\n*dma_handle = plat_kernel_addr_to_dma(dev, paddr);\r\nreturn paddr;\r\n}\r\nvoid dma_free_noncoherent(struct device *dev, size_t size, void *vaddr,\r\ndma_addr_t dma_handle)\r\n{\r\nfree_pages_exact((void *)plat_dma_addr_to_kernel(dev, dma_handle),\r\nsize);\r\n}\r\nvoid *dma_alloc_coherent(struct device *dev, size_t size,\r\ndma_addr_t *dma_handle, gfp_t gfp)\r\n{\r\nvoid *paddr, *kvaddr;\r\npaddr = alloc_pages_exact(size, gfp);\r\nif (!paddr)\r\nreturn NULL;\r\nkvaddr = ioremap_nocache((unsigned long)paddr, size);\r\nif (kvaddr != NULL)\r\nmemset(kvaddr, 0, size);\r\n*dma_handle = plat_kernel_addr_to_dma(dev, paddr);\r\nreturn kvaddr;\r\n}\r\nvoid dma_free_coherent(struct device *dev, size_t size, void *kvaddr,\r\ndma_addr_t dma_handle)\r\n{\r\niounmap((void __force __iomem *)kvaddr);\r\nfree_pages_exact((void *)plat_dma_addr_to_kernel(dev, dma_handle),\r\nsize);\r\n}\r\nvoid __arc_dma_cache_sync(unsigned long paddr, size_t size,\r\nenum dma_data_direction dir)\r\n{\r\n__inline_dma_cache_sync(paddr, size, dir);\r\n}
