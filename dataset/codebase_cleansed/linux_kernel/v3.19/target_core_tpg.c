static void core_clear_initiator_node_from_tpg(\r\nstruct se_node_acl *nacl,\r\nstruct se_portal_group *tpg)\r\n{\r\nint i;\r\nstruct se_dev_entry *deve;\r\nstruct se_lun *lun;\r\nspin_lock_irq(&nacl->device_list_lock);\r\nfor (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {\r\ndeve = nacl->device_list[i];\r\nif (!(deve->lun_flags & TRANSPORT_LUNFLAGS_INITIATOR_ACCESS))\r\ncontinue;\r\nif (!deve->se_lun) {\r\npr_err("%s device entries device pointer is"\r\n" NULL, but Initiator has access.\n",\r\ntpg->se_tpg_tfo->get_fabric_name());\r\ncontinue;\r\n}\r\nlun = deve->se_lun;\r\nspin_unlock_irq(&nacl->device_list_lock);\r\ncore_disable_device_list_for_node(lun, NULL, deve->mapped_lun,\r\nTRANSPORT_LUNFLAGS_NO_ACCESS, nacl, tpg);\r\nspin_lock_irq(&nacl->device_list_lock);\r\n}\r\nspin_unlock_irq(&nacl->device_list_lock);\r\n}\r\nstruct se_node_acl *__core_tpg_get_initiator_node_acl(\r\nstruct se_portal_group *tpg,\r\nconst char *initiatorname)\r\n{\r\nstruct se_node_acl *acl;\r\nlist_for_each_entry(acl, &tpg->acl_node_list, acl_list) {\r\nif (!strcmp(acl->initiatorname, initiatorname))\r\nreturn acl;\r\n}\r\nreturn NULL;\r\n}\r\nstruct se_node_acl *core_tpg_get_initiator_node_acl(\r\nstruct se_portal_group *tpg,\r\nunsigned char *initiatorname)\r\n{\r\nstruct se_node_acl *acl;\r\nspin_lock_irq(&tpg->acl_node_lock);\r\nacl = __core_tpg_get_initiator_node_acl(tpg, initiatorname);\r\nspin_unlock_irq(&tpg->acl_node_lock);\r\nreturn acl;\r\n}\r\nvoid core_tpg_add_node_to_devs(\r\nstruct se_node_acl *acl,\r\nstruct se_portal_group *tpg)\r\n{\r\nint i = 0;\r\nu32 lun_access = 0;\r\nstruct se_lun *lun;\r\nstruct se_device *dev;\r\nspin_lock(&tpg->tpg_lun_lock);\r\nfor (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {\r\nlun = tpg->tpg_lun_list[i];\r\nif (lun->lun_status != TRANSPORT_LUN_STATUS_ACTIVE)\r\ncontinue;\r\nspin_unlock(&tpg->tpg_lun_lock);\r\ndev = lun->lun_se_dev;\r\nif (!tpg->se_tpg_tfo->tpg_check_demo_mode_write_protect(tpg)) {\r\nlun_access = TRANSPORT_LUNFLAGS_READ_WRITE;\r\n} else {\r\nif (dev->transport->get_device_type(dev) == TYPE_DISK)\r\nlun_access = TRANSPORT_LUNFLAGS_READ_ONLY;\r\nelse\r\nlun_access = TRANSPORT_LUNFLAGS_READ_WRITE;\r\n}\r\npr_debug("TARGET_CORE[%s]->TPG[%u]_LUN[%u] - Adding %s"\r\n" access for LUN in Demo Mode\n",\r\ntpg->se_tpg_tfo->get_fabric_name(),\r\ntpg->se_tpg_tfo->tpg_get_tag(tpg), lun->unpacked_lun,\r\n(lun_access == TRANSPORT_LUNFLAGS_READ_WRITE) ?\r\n"READ-WRITE" : "READ-ONLY");\r\ncore_enable_device_list_for_node(lun, NULL, lun->unpacked_lun,\r\nlun_access, acl, tpg);\r\ncore_scsi3_check_aptpl_registration(dev, tpg, lun, acl,\r\nlun->unpacked_lun);\r\nspin_lock(&tpg->tpg_lun_lock);\r\n}\r\nspin_unlock(&tpg->tpg_lun_lock);\r\n}\r\nstatic int core_set_queue_depth_for_node(\r\nstruct se_portal_group *tpg,\r\nstruct se_node_acl *acl)\r\n{\r\nif (!acl->queue_depth) {\r\npr_err("Queue depth for %s Initiator Node: %s is 0,"\r\n"defaulting to 1.\n", tpg->se_tpg_tfo->get_fabric_name(),\r\nacl->initiatorname);\r\nacl->queue_depth = 1;\r\n}\r\nreturn 0;\r\n}\r\nvoid array_free(void *array, int n)\r\n{\r\nvoid **a = array;\r\nint i;\r\nfor (i = 0; i < n; i++)\r\nkfree(a[i]);\r\nkfree(a);\r\n}\r\nstatic void *array_zalloc(int n, size_t size, gfp_t flags)\r\n{\r\nvoid **a;\r\nint i;\r\na = kzalloc(n * sizeof(void*), flags);\r\nif (!a)\r\nreturn NULL;\r\nfor (i = 0; i < n; i++) {\r\na[i] = kzalloc(size, flags);\r\nif (!a[i]) {\r\narray_free(a, n);\r\nreturn NULL;\r\n}\r\n}\r\nreturn a;\r\n}\r\nstatic int core_create_device_list_for_node(struct se_node_acl *nacl)\r\n{\r\nstruct se_dev_entry *deve;\r\nint i;\r\nnacl->device_list = array_zalloc(TRANSPORT_MAX_LUNS_PER_TPG,\r\nsizeof(struct se_dev_entry), GFP_KERNEL);\r\nif (!nacl->device_list) {\r\npr_err("Unable to allocate memory for"\r\n" struct se_node_acl->device_list\n");\r\nreturn -ENOMEM;\r\n}\r\nfor (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {\r\ndeve = nacl->device_list[i];\r\natomic_set(&deve->ua_count, 0);\r\natomic_set(&deve->pr_ref_count, 0);\r\nspin_lock_init(&deve->ua_lock);\r\nINIT_LIST_HEAD(&deve->alua_port_list);\r\nINIT_LIST_HEAD(&deve->ua_list);\r\n}\r\nreturn 0;\r\n}\r\nstruct se_node_acl *core_tpg_check_initiator_node_acl(\r\nstruct se_portal_group *tpg,\r\nunsigned char *initiatorname)\r\n{\r\nstruct se_node_acl *acl;\r\nacl = core_tpg_get_initiator_node_acl(tpg, initiatorname);\r\nif (acl)\r\nreturn acl;\r\nif (!tpg->se_tpg_tfo->tpg_check_demo_mode(tpg))\r\nreturn NULL;\r\nacl = tpg->se_tpg_tfo->tpg_alloc_fabric_acl(tpg);\r\nif (!acl)\r\nreturn NULL;\r\nINIT_LIST_HEAD(&acl->acl_list);\r\nINIT_LIST_HEAD(&acl->acl_sess_list);\r\nkref_init(&acl->acl_kref);\r\ninit_completion(&acl->acl_free_comp);\r\nspin_lock_init(&acl->device_list_lock);\r\nspin_lock_init(&acl->nacl_sess_lock);\r\natomic_set(&acl->acl_pr_ref_count, 0);\r\nacl->queue_depth = tpg->se_tpg_tfo->tpg_get_default_depth(tpg);\r\nsnprintf(acl->initiatorname, TRANSPORT_IQN_LEN, "%s", initiatorname);\r\nacl->se_tpg = tpg;\r\nacl->acl_index = scsi_get_new_index(SCSI_AUTH_INTR_INDEX);\r\nacl->dynamic_node_acl = 1;\r\ntpg->se_tpg_tfo->set_default_node_attributes(acl);\r\nif (core_create_device_list_for_node(acl) < 0) {\r\ntpg->se_tpg_tfo->tpg_release_fabric_acl(tpg, acl);\r\nreturn NULL;\r\n}\r\nif (core_set_queue_depth_for_node(tpg, acl) < 0) {\r\ncore_free_device_list_for_node(acl, tpg);\r\ntpg->se_tpg_tfo->tpg_release_fabric_acl(tpg, acl);\r\nreturn NULL;\r\n}\r\nif ((tpg->se_tpg_tfo->tpg_check_demo_mode_login_only == NULL) ||\r\n(tpg->se_tpg_tfo->tpg_check_demo_mode_login_only(tpg) != 1))\r\ncore_tpg_add_node_to_devs(acl, tpg);\r\nspin_lock_irq(&tpg->acl_node_lock);\r\nlist_add_tail(&acl->acl_list, &tpg->acl_node_list);\r\ntpg->num_node_acls++;\r\nspin_unlock_irq(&tpg->acl_node_lock);\r\npr_debug("%s_TPG[%u] - Added DYNAMIC ACL with TCQ Depth: %d for %s"\r\n" Initiator Node: %s\n", tpg->se_tpg_tfo->get_fabric_name(),\r\ntpg->se_tpg_tfo->tpg_get_tag(tpg), acl->queue_depth,\r\ntpg->se_tpg_tfo->get_fabric_name(), initiatorname);\r\nreturn acl;\r\n}\r\nvoid core_tpg_wait_for_nacl_pr_ref(struct se_node_acl *nacl)\r\n{\r\nwhile (atomic_read(&nacl->acl_pr_ref_count) != 0)\r\ncpu_relax();\r\n}\r\nvoid core_tpg_clear_object_luns(struct se_portal_group *tpg)\r\n{\r\nint i;\r\nstruct se_lun *lun;\r\nspin_lock(&tpg->tpg_lun_lock);\r\nfor (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {\r\nlun = tpg->tpg_lun_list[i];\r\nif ((lun->lun_status != TRANSPORT_LUN_STATUS_ACTIVE) ||\r\n(lun->lun_se_dev == NULL))\r\ncontinue;\r\nspin_unlock(&tpg->tpg_lun_lock);\r\ncore_dev_del_lun(tpg, lun);\r\nspin_lock(&tpg->tpg_lun_lock);\r\n}\r\nspin_unlock(&tpg->tpg_lun_lock);\r\n}\r\nstruct se_node_acl *core_tpg_add_initiator_node_acl(\r\nstruct se_portal_group *tpg,\r\nstruct se_node_acl *se_nacl,\r\nconst char *initiatorname,\r\nu32 queue_depth)\r\n{\r\nstruct se_node_acl *acl = NULL;\r\nspin_lock_irq(&tpg->acl_node_lock);\r\nacl = __core_tpg_get_initiator_node_acl(tpg, initiatorname);\r\nif (acl) {\r\nif (acl->dynamic_node_acl) {\r\nacl->dynamic_node_acl = 0;\r\npr_debug("%s_TPG[%u] - Replacing dynamic ACL"\r\n" for %s\n", tpg->se_tpg_tfo->get_fabric_name(),\r\ntpg->se_tpg_tfo->tpg_get_tag(tpg), initiatorname);\r\nspin_unlock_irq(&tpg->acl_node_lock);\r\nif (se_nacl)\r\ntpg->se_tpg_tfo->tpg_release_fabric_acl(tpg,\r\nse_nacl);\r\ngoto done;\r\n}\r\npr_err("ACL entry for %s Initiator"\r\n" Node %s already exists for TPG %u, ignoring"\r\n" request.\n", tpg->se_tpg_tfo->get_fabric_name(),\r\ninitiatorname, tpg->se_tpg_tfo->tpg_get_tag(tpg));\r\nspin_unlock_irq(&tpg->acl_node_lock);\r\nreturn ERR_PTR(-EEXIST);\r\n}\r\nspin_unlock_irq(&tpg->acl_node_lock);\r\nif (!se_nacl) {\r\npr_err("struct se_node_acl pointer is NULL\n");\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\nacl = se_nacl;\r\nINIT_LIST_HEAD(&acl->acl_list);\r\nINIT_LIST_HEAD(&acl->acl_sess_list);\r\nkref_init(&acl->acl_kref);\r\ninit_completion(&acl->acl_free_comp);\r\nspin_lock_init(&acl->device_list_lock);\r\nspin_lock_init(&acl->nacl_sess_lock);\r\natomic_set(&acl->acl_pr_ref_count, 0);\r\nacl->queue_depth = queue_depth;\r\nsnprintf(acl->initiatorname, TRANSPORT_IQN_LEN, "%s", initiatorname);\r\nacl->se_tpg = tpg;\r\nacl->acl_index = scsi_get_new_index(SCSI_AUTH_INTR_INDEX);\r\ntpg->se_tpg_tfo->set_default_node_attributes(acl);\r\nif (core_create_device_list_for_node(acl) < 0) {\r\ntpg->se_tpg_tfo->tpg_release_fabric_acl(tpg, acl);\r\nreturn ERR_PTR(-ENOMEM);\r\n}\r\nif (core_set_queue_depth_for_node(tpg, acl) < 0) {\r\ncore_free_device_list_for_node(acl, tpg);\r\ntpg->se_tpg_tfo->tpg_release_fabric_acl(tpg, acl);\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\nspin_lock_irq(&tpg->acl_node_lock);\r\nlist_add_tail(&acl->acl_list, &tpg->acl_node_list);\r\ntpg->num_node_acls++;\r\nspin_unlock_irq(&tpg->acl_node_lock);\r\ndone:\r\npr_debug("%s_TPG[%hu] - Added ACL with TCQ Depth: %d for %s"\r\n" Initiator Node: %s\n", tpg->se_tpg_tfo->get_fabric_name(),\r\ntpg->se_tpg_tfo->tpg_get_tag(tpg), acl->queue_depth,\r\ntpg->se_tpg_tfo->get_fabric_name(), initiatorname);\r\nreturn acl;\r\n}\r\nint core_tpg_del_initiator_node_acl(\r\nstruct se_portal_group *tpg,\r\nstruct se_node_acl *acl,\r\nint force)\r\n{\r\nLIST_HEAD(sess_list);\r\nstruct se_session *sess, *sess_tmp;\r\nunsigned long flags;\r\nint rc;\r\nspin_lock_irq(&tpg->acl_node_lock);\r\nif (acl->dynamic_node_acl) {\r\nacl->dynamic_node_acl = 0;\r\n}\r\nlist_del(&acl->acl_list);\r\ntpg->num_node_acls--;\r\nspin_unlock_irq(&tpg->acl_node_lock);\r\nspin_lock_irqsave(&acl->nacl_sess_lock, flags);\r\nacl->acl_stop = 1;\r\nlist_for_each_entry_safe(sess, sess_tmp, &acl->acl_sess_list,\r\nsess_acl_list) {\r\nif (sess->sess_tearing_down != 0)\r\ncontinue;\r\ntarget_get_session(sess);\r\nlist_move(&sess->sess_acl_list, &sess_list);\r\n}\r\nspin_unlock_irqrestore(&acl->nacl_sess_lock, flags);\r\nlist_for_each_entry_safe(sess, sess_tmp, &sess_list, sess_acl_list) {\r\nlist_del(&sess->sess_acl_list);\r\nrc = tpg->se_tpg_tfo->shutdown_session(sess);\r\ntarget_put_session(sess);\r\nif (!rc)\r\ncontinue;\r\ntarget_put_session(sess);\r\n}\r\ntarget_put_nacl(acl);\r\nwait_for_completion(&acl->acl_free_comp);\r\ncore_tpg_wait_for_nacl_pr_ref(acl);\r\ncore_clear_initiator_node_from_tpg(acl, tpg);\r\ncore_free_device_list_for_node(acl, tpg);\r\npr_debug("%s_TPG[%hu] - Deleted ACL with TCQ Depth: %d for %s"\r\n" Initiator Node: %s\n", tpg->se_tpg_tfo->get_fabric_name(),\r\ntpg->se_tpg_tfo->tpg_get_tag(tpg), acl->queue_depth,\r\ntpg->se_tpg_tfo->get_fabric_name(), acl->initiatorname);\r\nreturn 0;\r\n}\r\nint core_tpg_set_initiator_node_queue_depth(\r\nstruct se_portal_group *tpg,\r\nunsigned char *initiatorname,\r\nu32 queue_depth,\r\nint force)\r\n{\r\nstruct se_session *sess, *init_sess = NULL;\r\nstruct se_node_acl *acl;\r\nunsigned long flags;\r\nint dynamic_acl = 0;\r\nspin_lock_irq(&tpg->acl_node_lock);\r\nacl = __core_tpg_get_initiator_node_acl(tpg, initiatorname);\r\nif (!acl) {\r\npr_err("Access Control List entry for %s Initiator"\r\n" Node %s does not exists for TPG %hu, ignoring"\r\n" request.\n", tpg->se_tpg_tfo->get_fabric_name(),\r\ninitiatorname, tpg->se_tpg_tfo->tpg_get_tag(tpg));\r\nspin_unlock_irq(&tpg->acl_node_lock);\r\nreturn -ENODEV;\r\n}\r\nif (acl->dynamic_node_acl) {\r\nacl->dynamic_node_acl = 0;\r\ndynamic_acl = 1;\r\n}\r\nspin_unlock_irq(&tpg->acl_node_lock);\r\nspin_lock_irqsave(&tpg->session_lock, flags);\r\nlist_for_each_entry(sess, &tpg->tpg_sess_list, sess_list) {\r\nif (sess->se_node_acl != acl)\r\ncontinue;\r\nif (!force) {\r\npr_err("Unable to change queue depth for %s"\r\n" Initiator Node: %s while session is"\r\n" operational. To forcefully change the queue"\r\n" depth and force session reinstatement"\r\n" use the \"force=1\" parameter.\n",\r\ntpg->se_tpg_tfo->get_fabric_name(), initiatorname);\r\nspin_unlock_irqrestore(&tpg->session_lock, flags);\r\nspin_lock_irq(&tpg->acl_node_lock);\r\nif (dynamic_acl)\r\nacl->dynamic_node_acl = 1;\r\nspin_unlock_irq(&tpg->acl_node_lock);\r\nreturn -EEXIST;\r\n}\r\nif (!tpg->se_tpg_tfo->shutdown_session(sess))\r\ncontinue;\r\ninit_sess = sess;\r\nbreak;\r\n}\r\nacl->queue_depth = queue_depth;\r\nif (core_set_queue_depth_for_node(tpg, acl) < 0) {\r\nspin_unlock_irqrestore(&tpg->session_lock, flags);\r\nif (init_sess)\r\ntpg->se_tpg_tfo->close_session(init_sess);\r\nspin_lock_irq(&tpg->acl_node_lock);\r\nif (dynamic_acl)\r\nacl->dynamic_node_acl = 1;\r\nspin_unlock_irq(&tpg->acl_node_lock);\r\nreturn -EINVAL;\r\n}\r\nspin_unlock_irqrestore(&tpg->session_lock, flags);\r\nif (init_sess)\r\ntpg->se_tpg_tfo->close_session(init_sess);\r\npr_debug("Successfully changed queue depth to: %d for Initiator"\r\n" Node: %s on %s Target Portal Group: %u\n", queue_depth,\r\ninitiatorname, tpg->se_tpg_tfo->get_fabric_name(),\r\ntpg->se_tpg_tfo->tpg_get_tag(tpg));\r\nspin_lock_irq(&tpg->acl_node_lock);\r\nif (dynamic_acl)\r\nacl->dynamic_node_acl = 1;\r\nspin_unlock_irq(&tpg->acl_node_lock);\r\nreturn 0;\r\n}\r\nint core_tpg_set_initiator_node_tag(\r\nstruct se_portal_group *tpg,\r\nstruct se_node_acl *acl,\r\nconst char *new_tag)\r\n{\r\nif (strlen(new_tag) >= MAX_ACL_TAG_SIZE)\r\nreturn -EINVAL;\r\nif (!strncmp("NULL", new_tag, 4)) {\r\nacl->acl_tag[0] = '\0';\r\nreturn 0;\r\n}\r\nreturn snprintf(acl->acl_tag, MAX_ACL_TAG_SIZE, "%s", new_tag);\r\n}\r\nstatic void core_tpg_lun_ref_release(struct percpu_ref *ref)\r\n{\r\nstruct se_lun *lun = container_of(ref, struct se_lun, lun_ref);\r\ncomplete(&lun->lun_ref_comp);\r\n}\r\nstatic int core_tpg_setup_virtual_lun0(struct se_portal_group *se_tpg)\r\n{\r\nstruct se_device *dev = g_lun0_dev;\r\nstruct se_lun *lun = &se_tpg->tpg_virt_lun0;\r\nu32 lun_access = TRANSPORT_LUNFLAGS_READ_ONLY;\r\nint ret;\r\nlun->unpacked_lun = 0;\r\nlun->lun_status = TRANSPORT_LUN_STATUS_FREE;\r\natomic_set(&lun->lun_acl_count, 0);\r\ninit_completion(&lun->lun_shutdown_comp);\r\nINIT_LIST_HEAD(&lun->lun_acl_list);\r\nspin_lock_init(&lun->lun_acl_lock);\r\nspin_lock_init(&lun->lun_sep_lock);\r\ninit_completion(&lun->lun_ref_comp);\r\nret = core_tpg_add_lun(se_tpg, lun, lun_access, dev);\r\nif (ret < 0)\r\nreturn ret;\r\nreturn 0;\r\n}\r\nint core_tpg_register(\r\nstruct target_core_fabric_ops *tfo,\r\nstruct se_wwn *se_wwn,\r\nstruct se_portal_group *se_tpg,\r\nvoid *tpg_fabric_ptr,\r\nint se_tpg_type)\r\n{\r\nstruct se_lun *lun;\r\nu32 i;\r\nse_tpg->tpg_lun_list = array_zalloc(TRANSPORT_MAX_LUNS_PER_TPG,\r\nsizeof(struct se_lun), GFP_KERNEL);\r\nif (!se_tpg->tpg_lun_list) {\r\npr_err("Unable to allocate struct se_portal_group->"\r\n"tpg_lun_list\n");\r\nreturn -ENOMEM;\r\n}\r\nfor (i = 0; i < TRANSPORT_MAX_LUNS_PER_TPG; i++) {\r\nlun = se_tpg->tpg_lun_list[i];\r\nlun->unpacked_lun = i;\r\nlun->lun_link_magic = SE_LUN_LINK_MAGIC;\r\nlun->lun_status = TRANSPORT_LUN_STATUS_FREE;\r\natomic_set(&lun->lun_acl_count, 0);\r\ninit_completion(&lun->lun_shutdown_comp);\r\nINIT_LIST_HEAD(&lun->lun_acl_list);\r\nspin_lock_init(&lun->lun_acl_lock);\r\nspin_lock_init(&lun->lun_sep_lock);\r\ninit_completion(&lun->lun_ref_comp);\r\n}\r\nse_tpg->se_tpg_type = se_tpg_type;\r\nse_tpg->se_tpg_fabric_ptr = tpg_fabric_ptr;\r\nse_tpg->se_tpg_tfo = tfo;\r\nse_tpg->se_tpg_wwn = se_wwn;\r\natomic_set(&se_tpg->tpg_pr_ref_count, 0);\r\nINIT_LIST_HEAD(&se_tpg->acl_node_list);\r\nINIT_LIST_HEAD(&se_tpg->se_tpg_node);\r\nINIT_LIST_HEAD(&se_tpg->tpg_sess_list);\r\nspin_lock_init(&se_tpg->acl_node_lock);\r\nspin_lock_init(&se_tpg->session_lock);\r\nspin_lock_init(&se_tpg->tpg_lun_lock);\r\nif (se_tpg->se_tpg_type == TRANSPORT_TPG_TYPE_NORMAL) {\r\nif (core_tpg_setup_virtual_lun0(se_tpg) < 0) {\r\narray_free(se_tpg->tpg_lun_list,\r\nTRANSPORT_MAX_LUNS_PER_TPG);\r\nreturn -ENOMEM;\r\n}\r\n}\r\nspin_lock_bh(&tpg_lock);\r\nlist_add_tail(&se_tpg->se_tpg_node, &tpg_list);\r\nspin_unlock_bh(&tpg_lock);\r\npr_debug("TARGET_CORE[%s]: Allocated %s struct se_portal_group for"\r\n" endpoint: %s, Portal Tag: %u\n", tfo->get_fabric_name(),\r\n(se_tpg->se_tpg_type == TRANSPORT_TPG_TYPE_NORMAL) ?\r\n"Normal" : "Discovery", (tfo->tpg_get_wwn(se_tpg) == NULL) ?\r\n"None" : tfo->tpg_get_wwn(se_tpg), tfo->tpg_get_tag(se_tpg));\r\nreturn 0;\r\n}\r\nint core_tpg_deregister(struct se_portal_group *se_tpg)\r\n{\r\nstruct se_node_acl *nacl, *nacl_tmp;\r\npr_debug("TARGET_CORE[%s]: Deallocating %s struct se_portal_group"\r\n" for endpoint: %s Portal Tag %u\n",\r\n(se_tpg->se_tpg_type == TRANSPORT_TPG_TYPE_NORMAL) ?\r\n"Normal" : "Discovery", se_tpg->se_tpg_tfo->get_fabric_name(),\r\nse_tpg->se_tpg_tfo->tpg_get_wwn(se_tpg),\r\nse_tpg->se_tpg_tfo->tpg_get_tag(se_tpg));\r\nspin_lock_bh(&tpg_lock);\r\nlist_del(&se_tpg->se_tpg_node);\r\nspin_unlock_bh(&tpg_lock);\r\nwhile (atomic_read(&se_tpg->tpg_pr_ref_count) != 0)\r\ncpu_relax();\r\nspin_lock_irq(&se_tpg->acl_node_lock);\r\nlist_for_each_entry_safe(nacl, nacl_tmp, &se_tpg->acl_node_list,\r\nacl_list) {\r\nlist_del(&nacl->acl_list);\r\nse_tpg->num_node_acls--;\r\nspin_unlock_irq(&se_tpg->acl_node_lock);\r\ncore_tpg_wait_for_nacl_pr_ref(nacl);\r\ncore_free_device_list_for_node(nacl, se_tpg);\r\nse_tpg->se_tpg_tfo->tpg_release_fabric_acl(se_tpg, nacl);\r\nspin_lock_irq(&se_tpg->acl_node_lock);\r\n}\r\nspin_unlock_irq(&se_tpg->acl_node_lock);\r\nif (se_tpg->se_tpg_type == TRANSPORT_TPG_TYPE_NORMAL)\r\ncore_tpg_remove_lun(se_tpg, &se_tpg->tpg_virt_lun0);\r\nse_tpg->se_tpg_fabric_ptr = NULL;\r\narray_free(se_tpg->tpg_lun_list, TRANSPORT_MAX_LUNS_PER_TPG);\r\nreturn 0;\r\n}\r\nstruct se_lun *core_tpg_alloc_lun(\r\nstruct se_portal_group *tpg,\r\nu32 unpacked_lun)\r\n{\r\nstruct se_lun *lun;\r\nif (unpacked_lun > (TRANSPORT_MAX_LUNS_PER_TPG-1)) {\r\npr_err("%s LUN: %u exceeds TRANSPORT_MAX_LUNS_PER_TPG"\r\n"-1: %u for Target Portal Group: %u\n",\r\ntpg->se_tpg_tfo->get_fabric_name(),\r\nunpacked_lun, TRANSPORT_MAX_LUNS_PER_TPG-1,\r\ntpg->se_tpg_tfo->tpg_get_tag(tpg));\r\nreturn ERR_PTR(-EOVERFLOW);\r\n}\r\nspin_lock(&tpg->tpg_lun_lock);\r\nlun = tpg->tpg_lun_list[unpacked_lun];\r\nif (lun->lun_status == TRANSPORT_LUN_STATUS_ACTIVE) {\r\npr_err("TPG Logical Unit Number: %u is already active"\r\n" on %s Target Portal Group: %u, ignoring request.\n",\r\nunpacked_lun, tpg->se_tpg_tfo->get_fabric_name(),\r\ntpg->se_tpg_tfo->tpg_get_tag(tpg));\r\nspin_unlock(&tpg->tpg_lun_lock);\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\nspin_unlock(&tpg->tpg_lun_lock);\r\nreturn lun;\r\n}\r\nint core_tpg_add_lun(\r\nstruct se_portal_group *tpg,\r\nstruct se_lun *lun,\r\nu32 lun_access,\r\nstruct se_device *dev)\r\n{\r\nint ret;\r\nret = percpu_ref_init(&lun->lun_ref, core_tpg_lun_ref_release, 0,\r\nGFP_KERNEL);\r\nif (ret < 0)\r\nreturn ret;\r\nret = core_dev_export(dev, tpg, lun);\r\nif (ret < 0) {\r\npercpu_ref_exit(&lun->lun_ref);\r\nreturn ret;\r\n}\r\nspin_lock(&tpg->tpg_lun_lock);\r\nlun->lun_access = lun_access;\r\nlun->lun_status = TRANSPORT_LUN_STATUS_ACTIVE;\r\nspin_unlock(&tpg->tpg_lun_lock);\r\nreturn 0;\r\n}\r\nvoid core_tpg_remove_lun(\r\nstruct se_portal_group *tpg,\r\nstruct se_lun *lun)\r\n{\r\ncore_clear_lun_from_tpg(lun, tpg);\r\ntransport_clear_lun_ref(lun);\r\ncore_dev_unexport(lun->lun_se_dev, tpg, lun);\r\nspin_lock(&tpg->tpg_lun_lock);\r\nlun->lun_status = TRANSPORT_LUN_STATUS_FREE;\r\nspin_unlock(&tpg->tpg_lun_lock);\r\npercpu_ref_exit(&lun->lun_ref);\r\n}
