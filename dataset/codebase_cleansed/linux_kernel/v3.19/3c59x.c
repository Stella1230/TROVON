static void window_set(struct vortex_private *vp, int window)\r\n{\r\nif (window != vp->window) {\r\niowrite16(SelectWindow + window, vp->ioaddr + EL3_CMD);\r\nvp->window = window;\r\n}\r\n}\r\nstatic void poll_vortex(struct net_device *dev)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nunsigned long flags;\r\nlocal_irq_save(flags);\r\n(vp->full_bus_master_rx ? boomerang_interrupt:vortex_interrupt)(dev->irq,dev);\r\nlocal_irq_restore(flags);\r\n}\r\nstatic int vortex_suspend(struct device *dev)\r\n{\r\nstruct pci_dev *pdev = to_pci_dev(dev);\r\nstruct net_device *ndev = pci_get_drvdata(pdev);\r\nif (!ndev || !netif_running(ndev))\r\nreturn 0;\r\nnetif_device_detach(ndev);\r\nvortex_down(ndev, 1);\r\nreturn 0;\r\n}\r\nstatic int vortex_resume(struct device *dev)\r\n{\r\nstruct pci_dev *pdev = to_pci_dev(dev);\r\nstruct net_device *ndev = pci_get_drvdata(pdev);\r\nint err;\r\nif (!ndev || !netif_running(ndev))\r\nreturn 0;\r\nerr = vortex_up(ndev);\r\nif (err)\r\nreturn err;\r\nnetif_device_attach(ndev);\r\nreturn 0;\r\n}\r\nstatic int __init vortex_eisa_probe(struct device *device)\r\n{\r\nvoid __iomem *ioaddr;\r\nstruct eisa_device *edev;\r\nedev = to_eisa_device(device);\r\nif (!request_region(edev->base_addr, VORTEX_TOTAL_SIZE, DRV_NAME))\r\nreturn -EBUSY;\r\nioaddr = ioport_map(edev->base_addr, VORTEX_TOTAL_SIZE);\r\nif (vortex_probe1(device, ioaddr, ioread16(ioaddr + 0xC88) >> 12,\r\nedev->id.driver_data, vortex_cards_found)) {\r\nrelease_region(edev->base_addr, VORTEX_TOTAL_SIZE);\r\nreturn -ENODEV;\r\n}\r\nvortex_cards_found++;\r\nreturn 0;\r\n}\r\nstatic int vortex_eisa_remove(struct device *device)\r\n{\r\nstruct eisa_device *edev;\r\nstruct net_device *dev;\r\nstruct vortex_private *vp;\r\nvoid __iomem *ioaddr;\r\nedev = to_eisa_device(device);\r\ndev = eisa_get_drvdata(edev);\r\nif (!dev) {\r\npr_err("vortex_eisa_remove called for Compaq device!\n");\r\nBUG();\r\n}\r\nvp = netdev_priv(dev);\r\nioaddr = vp->ioaddr;\r\nunregister_netdev(dev);\r\niowrite16(TotalReset|0x14, ioaddr + EL3_CMD);\r\nrelease_region(edev->base_addr, VORTEX_TOTAL_SIZE);\r\nfree_netdev(dev);\r\nreturn 0;\r\n}\r\nstatic int __init vortex_eisa_init(void)\r\n{\r\nint eisa_found = 0;\r\nint orig_cards_found = vortex_cards_found;\r\n#ifdef CONFIG_EISA\r\nint err;\r\nerr = eisa_driver_register (&vortex_eisa_driver);\r\nif (!err) {\r\neisa_found = 1;\r\n}\r\n#endif\r\nif (compaq_ioaddr) {\r\nvortex_probe1(NULL, ioport_map(compaq_ioaddr, VORTEX_TOTAL_SIZE),\r\ncompaq_irq, compaq_device_id, vortex_cards_found++);\r\n}\r\nreturn vortex_cards_found - orig_cards_found + eisa_found;\r\n}\r\nstatic int vortex_init_one(struct pci_dev *pdev,\r\nconst struct pci_device_id *ent)\r\n{\r\nint rc, unit, pci_bar;\r\nstruct vortex_chip_info *vci;\r\nvoid __iomem *ioaddr;\r\nrc = pci_enable_device(pdev);\r\nif (rc < 0)\r\ngoto out;\r\nrc = pci_request_regions(pdev, DRV_NAME);\r\nif (rc < 0)\r\ngoto out_disable;\r\nunit = vortex_cards_found;\r\nif (global_use_mmio < 0 && (unit >= MAX_UNITS || use_mmio[unit] < 0)) {\r\nvci = &vortex_info_tbl[ent->driver_data];\r\npci_bar = vci->drv_flags & (IS_CYCLONE | IS_TORNADO) ? 1 : 0;\r\n} else if (unit < MAX_UNITS && use_mmio[unit] >= 0)\r\npci_bar = use_mmio[unit] ? 1 : 0;\r\nelse\r\npci_bar = global_use_mmio ? 1 : 0;\r\nioaddr = pci_iomap(pdev, pci_bar, 0);\r\nif (!ioaddr)\r\nioaddr = pci_iomap(pdev, 0, 0);\r\nif (!ioaddr) {\r\nrc = -ENOMEM;\r\ngoto out_release;\r\n}\r\nrc = vortex_probe1(&pdev->dev, ioaddr, pdev->irq,\r\nent->driver_data, unit);\r\nif (rc < 0)\r\ngoto out_iounmap;\r\nvortex_cards_found++;\r\ngoto out;\r\nout_iounmap:\r\npci_iounmap(pdev, ioaddr);\r\nout_release:\r\npci_release_regions(pdev);\r\nout_disable:\r\npci_disable_device(pdev);\r\nout:\r\nreturn rc;\r\n}\r\nstatic int vortex_probe1(struct device *gendev, void __iomem *ioaddr, int irq,\r\nint chip_idx, int card_idx)\r\n{\r\nstruct vortex_private *vp;\r\nint option;\r\nunsigned int eeprom[0x40], checksum = 0;\r\nint i, step;\r\nstruct net_device *dev;\r\nstatic int printed_version;\r\nint retval, print_info;\r\nstruct vortex_chip_info * const vci = &vortex_info_tbl[chip_idx];\r\nconst char *print_name = "3c59x";\r\nstruct pci_dev *pdev = NULL;\r\nstruct eisa_device *edev = NULL;\r\nif (!printed_version) {\r\npr_info("%s", version);\r\nprinted_version = 1;\r\n}\r\nif (gendev) {\r\nif ((pdev = DEVICE_PCI(gendev))) {\r\nprint_name = pci_name(pdev);\r\n}\r\nif ((edev = DEVICE_EISA(gendev))) {\r\nprint_name = dev_name(&edev->dev);\r\n}\r\n}\r\ndev = alloc_etherdev(sizeof(*vp));\r\nretval = -ENOMEM;\r\nif (!dev)\r\ngoto out;\r\nSET_NETDEV_DEV(dev, gendev);\r\nvp = netdev_priv(dev);\r\noption = global_options;\r\nif (dev->mem_start) {\r\noption = dev->mem_start;\r\n}\r\nelse if (card_idx < MAX_UNITS) {\r\nif (options[card_idx] >= 0)\r\noption = options[card_idx];\r\n}\r\nif (option > 0) {\r\nif (option & 0x8000)\r\nvortex_debug = 7;\r\nif (option & 0x4000)\r\nvortex_debug = 2;\r\nif (option & 0x0400)\r\nvp->enable_wol = 1;\r\n}\r\nprint_info = (vortex_debug > 1);\r\nif (print_info)\r\npr_info("See Documentation/networking/vortex.txt\n");\r\npr_info("%s: 3Com %s %s at %p.\n",\r\nprint_name,\r\npdev ? "PCI" : "EISA",\r\nvci->name,\r\nioaddr);\r\ndev->base_addr = (unsigned long)ioaddr;\r\ndev->irq = irq;\r\ndev->mtu = mtu;\r\nvp->ioaddr = ioaddr;\r\nvp->large_frames = mtu > 1500;\r\nvp->drv_flags = vci->drv_flags;\r\nvp->has_nway = (vci->drv_flags & HAS_NWAY) ? 1 : 0;\r\nvp->io_size = vci->io_size;\r\nvp->card_idx = card_idx;\r\nvp->window = -1;\r\nif (gendev == NULL) {\r\ncompaq_net_device = dev;\r\n}\r\nif (pdev) {\r\nif (vci->flags & PCI_USES_MASTER)\r\npci_set_master(pdev);\r\nif (vci->drv_flags & IS_VORTEX) {\r\nu8 pci_latency;\r\nu8 new_latency = 248;\r\npci_read_config_byte(pdev, PCI_LATENCY_TIMER, &pci_latency);\r\nif (pci_latency < new_latency) {\r\npr_info("%s: Overriding PCI latency timer (CFLT) setting of %d, new value is %d.\n",\r\nprint_name, pci_latency, new_latency);\r\npci_write_config_byte(pdev, PCI_LATENCY_TIMER, new_latency);\r\n}\r\n}\r\n}\r\nspin_lock_init(&vp->lock);\r\nspin_lock_init(&vp->mii_lock);\r\nspin_lock_init(&vp->window_lock);\r\nvp->gendev = gendev;\r\nvp->mii.dev = dev;\r\nvp->mii.mdio_read = mdio_read;\r\nvp->mii.mdio_write = mdio_write;\r\nvp->mii.phy_id_mask = 0x1f;\r\nvp->mii.reg_num_mask = 0x1f;\r\nvp->rx_ring = pci_alloc_consistent(pdev, sizeof(struct boom_rx_desc) * RX_RING_SIZE\r\n+ sizeof(struct boom_tx_desc) * TX_RING_SIZE,\r\n&vp->rx_ring_dma);\r\nretval = -ENOMEM;\r\nif (!vp->rx_ring)\r\ngoto free_device;\r\nvp->tx_ring = (struct boom_tx_desc *)(vp->rx_ring + RX_RING_SIZE);\r\nvp->tx_ring_dma = vp->rx_ring_dma + sizeof(struct boom_rx_desc) * RX_RING_SIZE;\r\nif (pdev)\r\npci_set_drvdata(pdev, dev);\r\nif (edev)\r\neisa_set_drvdata(edev, dev);\r\nvp->media_override = 7;\r\nif (option >= 0) {\r\nvp->media_override = ((option & 7) == 2) ? 0 : option & 15;\r\nif (vp->media_override != 7)\r\nvp->medialock = 1;\r\nvp->full_duplex = (option & 0x200) ? 1 : 0;\r\nvp->bus_master = (option & 16) ? 1 : 0;\r\n}\r\nif (global_full_duplex > 0)\r\nvp->full_duplex = 1;\r\nif (global_enable_wol > 0)\r\nvp->enable_wol = 1;\r\nif (card_idx < MAX_UNITS) {\r\nif (full_duplex[card_idx] > 0)\r\nvp->full_duplex = 1;\r\nif (flow_ctrl[card_idx] > 0)\r\nvp->flow_ctrl = 1;\r\nif (enable_wol[card_idx] > 0)\r\nvp->enable_wol = 1;\r\n}\r\nvp->mii.force_media = vp->full_duplex;\r\nvp->options = option;\r\n{\r\nint base;\r\nif (vci->drv_flags & EEPROM_8BIT)\r\nbase = 0x230;\r\nelse if (vci->drv_flags & EEPROM_OFFSET)\r\nbase = EEPROM_Read + 0x30;\r\nelse\r\nbase = EEPROM_Read;\r\nfor (i = 0; i < 0x40; i++) {\r\nint timer;\r\nwindow_write16(vp, base + i, 0, Wn0EepromCmd);\r\nfor (timer = 10; timer >= 0; timer--) {\r\nudelay(162);\r\nif ((window_read16(vp, 0, Wn0EepromCmd) &\r\n0x8000) == 0)\r\nbreak;\r\n}\r\neeprom[i] = window_read16(vp, 0, Wn0EepromData);\r\n}\r\n}\r\nfor (i = 0; i < 0x18; i++)\r\nchecksum ^= eeprom[i];\r\nchecksum = (checksum ^ (checksum >> 8)) & 0xff;\r\nif (checksum != 0x00) {\r\nwhile (i < 0x21)\r\nchecksum ^= eeprom[i++];\r\nchecksum = (checksum ^ (checksum >> 8)) & 0xff;\r\n}\r\nif ((checksum != 0x00) && !(vci->drv_flags & IS_TORNADO))\r\npr_cont(" ***INVALID CHECKSUM %4.4x*** ", checksum);\r\nfor (i = 0; i < 3; i++)\r\n((__be16 *)dev->dev_addr)[i] = htons(eeprom[i + 10]);\r\nif (print_info)\r\npr_cont(" %pM", dev->dev_addr);\r\nif (!is_valid_ether_addr(dev->dev_addr)) {\r\nretval = -EINVAL;\r\npr_err("*** EEPROM MAC address is invalid.\n");\r\ngoto free_ring;\r\n}\r\nfor (i = 0; i < 6; i++)\r\nwindow_write8(vp, dev->dev_addr[i], 2, i);\r\nif (print_info)\r\npr_cont(", IRQ %d\n", dev->irq);\r\nif (dev->irq <= 0 || dev->irq >= nr_irqs)\r\npr_warn(" *** Warning: IRQ %d is unlikely to work! ***\n",\r\ndev->irq);\r\nstep = (window_read8(vp, 4, Wn4_NetDiag) & 0x1e) >> 1;\r\nif (print_info) {\r\npr_info(" product code %02x%02x rev %02x.%d date %02d-%02d-%02d\n",\r\neeprom[6]&0xff, eeprom[6]>>8, eeprom[0x14],\r\nstep, (eeprom[4]>>5) & 15, eeprom[4] & 31, eeprom[4]>>9);\r\n}\r\nif (pdev && vci->drv_flags & HAS_CB_FNS) {\r\nunsigned short n;\r\nvp->cb_fn_base = pci_iomap(pdev, 2, 0);\r\nif (!vp->cb_fn_base) {\r\nretval = -ENOMEM;\r\ngoto free_ring;\r\n}\r\nif (print_info) {\r\npr_info("%s: CardBus functions mapped %16.16llx->%p\n",\r\nprint_name,\r\n(unsigned long long)pci_resource_start(pdev, 2),\r\nvp->cb_fn_base);\r\n}\r\nn = window_read16(vp, 2, Wn2_ResetOptions) & ~0x4010;\r\nif (vp->drv_flags & INVERT_LED_PWR)\r\nn |= 0x10;\r\nif (vp->drv_flags & INVERT_MII_PWR)\r\nn |= 0x4000;\r\nwindow_write16(vp, n, 2, Wn2_ResetOptions);\r\nif (vp->drv_flags & WNO_XCVR_PWR) {\r\nwindow_write16(vp, 0x0800, 0, 0);\r\n}\r\n}\r\nvp->info1 = eeprom[13];\r\nvp->info2 = eeprom[15];\r\nvp->capabilities = eeprom[16];\r\nif (vp->info1 & 0x8000) {\r\nvp->full_duplex = 1;\r\nif (print_info)\r\npr_info("Full duplex capable\n");\r\n}\r\n{\r\nstatic const char * const ram_split[] = {"5:3", "3:1", "1:1", "3:5"};\r\nunsigned int config;\r\nvp->available_media = window_read16(vp, 3, Wn3_Options);\r\nif ((vp->available_media & 0xff) == 0)\r\nvp->available_media = 0x40;\r\nconfig = window_read32(vp, 3, Wn3_Config);\r\nif (print_info) {\r\npr_debug(" Internal config register is %4.4x, transceivers %#x.\n",\r\nconfig, window_read16(vp, 3, Wn3_Options));\r\npr_info(" %dK %s-wide RAM %s Rx:Tx split, %s%s interface.\n",\r\n8 << RAM_SIZE(config),\r\nRAM_WIDTH(config) ? "word" : "byte",\r\nram_split[RAM_SPLIT(config)],\r\nAUTOSELECT(config) ? "autoselect/" : "",\r\nXCVR(config) > XCVR_ExtMII ? "<invalid transceiver>" :\r\nmedia_tbl[XCVR(config)].name);\r\n}\r\nvp->default_media = XCVR(config);\r\nif (vp->default_media == XCVR_NWAY)\r\nvp->has_nway = 1;\r\nvp->autoselect = AUTOSELECT(config);\r\n}\r\nif (vp->media_override != 7) {\r\npr_info("%s: Media override to transceiver type %d (%s).\n",\r\nprint_name, vp->media_override,\r\nmedia_tbl[vp->media_override].name);\r\ndev->if_port = vp->media_override;\r\n} else\r\ndev->if_port = vp->default_media;\r\nif ((vp->available_media & 0x40) || (vci->drv_flags & HAS_NWAY) ||\r\ndev->if_port == XCVR_MII || dev->if_port == XCVR_NWAY) {\r\nint phy, phy_idx = 0;\r\nmii_preamble_required++;\r\nif (vp->drv_flags & EXTRA_PREAMBLE)\r\nmii_preamble_required++;\r\nmdio_sync(vp, 32);\r\nmdio_read(dev, 24, MII_BMSR);\r\nfor (phy = 0; phy < 32 && phy_idx < 1; phy++) {\r\nint mii_status, phyx;\r\nif (phy == 0)\r\nphyx = 24;\r\nelse if (phy <= 24)\r\nphyx = phy - 1;\r\nelse\r\nphyx = phy;\r\nmii_status = mdio_read(dev, phyx, MII_BMSR);\r\nif (mii_status && mii_status != 0xffff) {\r\nvp->phys[phy_idx++] = phyx;\r\nif (print_info) {\r\npr_info(" MII transceiver found at address %d, status %4x.\n",\r\nphyx, mii_status);\r\n}\r\nif ((mii_status & 0x0040) == 0)\r\nmii_preamble_required++;\r\n}\r\n}\r\nmii_preamble_required--;\r\nif (phy_idx == 0) {\r\npr_warn(" ***WARNING*** No MII transceivers found!\n");\r\nvp->phys[0] = 24;\r\n} else {\r\nvp->advertising = mdio_read(dev, vp->phys[0], MII_ADVERTISE);\r\nif (vp->full_duplex) {\r\nvp->advertising &= ~0x02A0;\r\nmdio_write(dev, vp->phys[0], 4, vp->advertising);\r\n}\r\n}\r\nvp->mii.phy_id = vp->phys[0];\r\n}\r\nif (vp->capabilities & CapBusMaster) {\r\nvp->full_bus_master_tx = 1;\r\nif (print_info) {\r\npr_info(" Enabling bus-master transmits and %s receives.\n",\r\n(vp->info2 & 1) ? "early" : "whole-frame" );\r\n}\r\nvp->full_bus_master_rx = (vp->info2 & 1) ? 1 : 2;\r\nvp->bus_master = 0;\r\n}\r\nif (vp->full_bus_master_tx) {\r\ndev->netdev_ops = &boomrang_netdev_ops;\r\nif (card_idx < MAX_UNITS &&\r\n((hw_checksums[card_idx] == -1 && (vp->drv_flags & HAS_HWCKSM)) ||\r\nhw_checksums[card_idx] == 1)) {\r\ndev->features |= NETIF_F_IP_CSUM | NETIF_F_SG;\r\n}\r\n} else\r\ndev->netdev_ops = &vortex_netdev_ops;\r\nif (print_info) {\r\npr_info("%s: scatter/gather %sabled. h/w checksums %sabled\n",\r\nprint_name,\r\n(dev->features & NETIF_F_SG) ? "en":"dis",\r\n(dev->features & NETIF_F_IP_CSUM) ? "en":"dis");\r\n}\r\ndev->ethtool_ops = &vortex_ethtool_ops;\r\ndev->watchdog_timeo = (watchdog * HZ) / 1000;\r\nif (pdev) {\r\nvp->pm_state_valid = 1;\r\npci_save_state(pdev);\r\nacpi_set_WOL(dev);\r\n}\r\nretval = register_netdev(dev);\r\nif (retval == 0)\r\nreturn 0;\r\nfree_ring:\r\npci_free_consistent(pdev,\r\nsizeof(struct boom_rx_desc) * RX_RING_SIZE\r\n+ sizeof(struct boom_tx_desc) * TX_RING_SIZE,\r\nvp->rx_ring,\r\nvp->rx_ring_dma);\r\nfree_device:\r\nfree_netdev(dev);\r\npr_err(PFX "vortex_probe1 fails. Returns %d\n", retval);\r\nout:\r\nreturn retval;\r\n}\r\nstatic void\r\nissue_and_wait(struct net_device *dev, int cmd)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = vp->ioaddr;\r\nint i;\r\niowrite16(cmd, ioaddr + EL3_CMD);\r\nfor (i = 0; i < 2000; i++) {\r\nif (!(ioread16(ioaddr + EL3_STATUS) & CmdInProgress))\r\nreturn;\r\n}\r\nfor (i = 0; i < 100000; i++) {\r\nif (!(ioread16(ioaddr + EL3_STATUS) & CmdInProgress)) {\r\nif (vortex_debug > 1)\r\npr_info("%s: command 0x%04x took %d usecs\n",\r\ndev->name, cmd, i * 10);\r\nreturn;\r\n}\r\nudelay(10);\r\n}\r\npr_err("%s: command 0x%04x did not complete! Status=0x%x\n",\r\ndev->name, cmd, ioread16(ioaddr + EL3_STATUS));\r\n}\r\nstatic void\r\nvortex_set_duplex(struct net_device *dev)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\npr_info("%s: setting %s-duplex.\n",\r\ndev->name, (vp->full_duplex) ? "full" : "half");\r\nwindow_write16(vp,\r\n((vp->info1 & 0x8000) || vp->full_duplex ? 0x20 : 0) |\r\n(vp->large_frames ? 0x40 : 0) |\r\n((vp->full_duplex && vp->flow_ctrl && vp->partner_flow_ctrl) ?\r\n0x100 : 0),\r\n3, Wn3_MAC_Ctrl);\r\n}\r\nstatic void vortex_check_media(struct net_device *dev, unsigned int init)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nunsigned int ok_to_print = 0;\r\nif (vortex_debug > 3)\r\nok_to_print = 1;\r\nif (mii_check_media(&vp->mii, ok_to_print, init)) {\r\nvp->full_duplex = vp->mii.full_duplex;\r\nvortex_set_duplex(dev);\r\n} else if (init) {\r\nvortex_set_duplex(dev);\r\n}\r\n}\r\nstatic int\r\nvortex_up(struct net_device *dev)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = vp->ioaddr;\r\nunsigned int config;\r\nint i, mii_reg1, mii_reg5, err = 0;\r\nif (VORTEX_PCI(vp)) {\r\npci_set_power_state(VORTEX_PCI(vp), PCI_D0);\r\nif (vp->pm_state_valid)\r\npci_restore_state(VORTEX_PCI(vp));\r\nerr = pci_enable_device(VORTEX_PCI(vp));\r\nif (err) {\r\npr_warn("%s: Could not enable device\n", dev->name);\r\ngoto err_out;\r\n}\r\n}\r\nconfig = window_read32(vp, 3, Wn3_Config);\r\nif (vp->media_override != 7) {\r\npr_info("%s: Media override to transceiver %d (%s).\n",\r\ndev->name, vp->media_override,\r\nmedia_tbl[vp->media_override].name);\r\ndev->if_port = vp->media_override;\r\n} else if (vp->autoselect) {\r\nif (vp->has_nway) {\r\nif (vortex_debug > 1)\r\npr_info("%s: using NWAY device table, not %d\n",\r\ndev->name, dev->if_port);\r\ndev->if_port = XCVR_NWAY;\r\n} else {\r\ndev->if_port = XCVR_100baseTx;\r\nwhile (! (vp->available_media & media_tbl[dev->if_port].mask))\r\ndev->if_port = media_tbl[dev->if_port].next;\r\nif (vortex_debug > 1)\r\npr_info("%s: first available media type: %s\n",\r\ndev->name, media_tbl[dev->if_port].name);\r\n}\r\n} else {\r\ndev->if_port = vp->default_media;\r\nif (vortex_debug > 1)\r\npr_info("%s: using default media %s\n",\r\ndev->name, media_tbl[dev->if_port].name);\r\n}\r\ninit_timer(&vp->timer);\r\nvp->timer.expires = RUN_AT(media_tbl[dev->if_port].wait);\r\nvp->timer.data = (unsigned long)dev;\r\nvp->timer.function = vortex_timer;\r\nadd_timer(&vp->timer);\r\ninit_timer(&vp->rx_oom_timer);\r\nvp->rx_oom_timer.data = (unsigned long)dev;\r\nvp->rx_oom_timer.function = rx_oom_timer;\r\nif (vortex_debug > 1)\r\npr_debug("%s: Initial media type %s.\n",\r\ndev->name, media_tbl[dev->if_port].name);\r\nvp->full_duplex = vp->mii.force_media;\r\nconfig = BFINS(config, dev->if_port, 20, 4);\r\nif (vortex_debug > 6)\r\npr_debug("vortex_up(): writing 0x%x to InternalConfig\n", config);\r\nwindow_write32(vp, config, 3, Wn3_Config);\r\nif (dev->if_port == XCVR_MII || dev->if_port == XCVR_NWAY) {\r\nmii_reg1 = mdio_read(dev, vp->phys[0], MII_BMSR);\r\nmii_reg5 = mdio_read(dev, vp->phys[0], MII_LPA);\r\nvp->partner_flow_ctrl = ((mii_reg5 & 0x0400) != 0);\r\nvp->mii.full_duplex = vp->full_duplex;\r\nvortex_check_media(dev, 1);\r\n}\r\nelse\r\nvortex_set_duplex(dev);\r\nissue_and_wait(dev, TxReset);\r\nissue_and_wait(dev, RxReset|0x04);\r\niowrite16(SetStatusEnb | 0x00, ioaddr + EL3_CMD);\r\nif (vortex_debug > 1) {\r\npr_debug("%s: vortex_up() irq %d media status %4.4x.\n",\r\ndev->name, dev->irq, window_read16(vp, 4, Wn4_Media));\r\n}\r\nfor (i = 0; i < 6; i++)\r\nwindow_write8(vp, dev->dev_addr[i], 2, i);\r\nfor (; i < 12; i+=2)\r\nwindow_write16(vp, 0, 2, i);\r\nif (vp->cb_fn_base) {\r\nunsigned short n = window_read16(vp, 2, Wn2_ResetOptions) & ~0x4010;\r\nif (vp->drv_flags & INVERT_LED_PWR)\r\nn |= 0x10;\r\nif (vp->drv_flags & INVERT_MII_PWR)\r\nn |= 0x4000;\r\nwindow_write16(vp, n, 2, Wn2_ResetOptions);\r\n}\r\nif (dev->if_port == XCVR_10base2)\r\niowrite16(StartCoax, ioaddr + EL3_CMD);\r\nif (dev->if_port != XCVR_NWAY) {\r\nwindow_write16(vp,\r\n(window_read16(vp, 4, Wn4_Media) &\r\n~(Media_10TP|Media_SQE)) |\r\nmedia_tbl[dev->if_port].media_bits,\r\n4, Wn4_Media);\r\n}\r\niowrite16(StatsDisable, ioaddr + EL3_CMD);\r\nfor (i = 0; i < 10; i++)\r\nwindow_read8(vp, 6, i);\r\nwindow_read16(vp, 6, 10);\r\nwindow_read16(vp, 6, 12);\r\nwindow_read8(vp, 4, 12);\r\nwindow_write16(vp, 0x0040, 4, Wn4_NetDiag);\r\nif (vp->full_bus_master_rx) {\r\nvp->cur_rx = vp->dirty_rx = 0;\r\niowrite16(SetRxThreshold + (1536>>2), ioaddr + EL3_CMD);\r\niowrite32(0x0020, ioaddr + PktStatus);\r\niowrite32(vp->rx_ring_dma, ioaddr + UpListPtr);\r\n}\r\nif (vp->full_bus_master_tx) {\r\nvp->cur_tx = vp->dirty_tx = 0;\r\nif (vp->drv_flags & IS_BOOMERANG)\r\niowrite8(PKT_BUF_SZ>>8, ioaddr + TxFreeThreshold);\r\nfor (i = 0; i < RX_RING_SIZE; i++)\r\nvp->rx_ring[i].status = 0;\r\nfor (i = 0; i < TX_RING_SIZE; i++)\r\nvp->tx_skbuff[i] = NULL;\r\niowrite32(0, ioaddr + DownListPtr);\r\n}\r\nset_rx_mode(dev);\r\nset_8021q_mode(dev, 1);\r\niowrite16(StatsEnable, ioaddr + EL3_CMD);\r\niowrite16(RxEnable, ioaddr + EL3_CMD);\r\niowrite16(TxEnable, ioaddr + EL3_CMD);\r\nvp->status_enable = SetStatusEnb | HostError|IntReq|StatsFull|TxComplete|\r\n(vp->full_bus_master_tx ? DownComplete : TxAvailable) |\r\n(vp->full_bus_master_rx ? UpComplete : RxComplete) |\r\n(vp->bus_master ? DMADone : 0);\r\nvp->intr_enable = SetIntrEnb | IntLatch | TxAvailable |\r\n(vp->full_bus_master_rx ? 0 : RxComplete) |\r\nStatsFull | HostError | TxComplete | IntReq\r\n| (vp->bus_master ? DMADone : 0) | UpComplete | DownComplete;\r\niowrite16(vp->status_enable, ioaddr + EL3_CMD);\r\niowrite16(AckIntr | IntLatch | TxAvailable | RxEarly | IntReq,\r\nioaddr + EL3_CMD);\r\niowrite16(vp->intr_enable, ioaddr + EL3_CMD);\r\nif (vp->cb_fn_base)\r\niowrite32(0x8000, vp->cb_fn_base + 4);\r\nnetif_start_queue (dev);\r\nerr_out:\r\nreturn err;\r\n}\r\nstatic int\r\nvortex_open(struct net_device *dev)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nint i;\r\nint retval;\r\nif ((retval = request_irq(dev->irq, vp->full_bus_master_rx ?\r\nboomerang_interrupt : vortex_interrupt, IRQF_SHARED, dev->name, dev))) {\r\npr_err("%s: Could not reserve IRQ %d\n", dev->name, dev->irq);\r\ngoto err;\r\n}\r\nif (vp->full_bus_master_rx) {\r\nif (vortex_debug > 2)\r\npr_debug("%s: Filling in the Rx ring.\n", dev->name);\r\nfor (i = 0; i < RX_RING_SIZE; i++) {\r\nstruct sk_buff *skb;\r\nvp->rx_ring[i].next = cpu_to_le32(vp->rx_ring_dma + sizeof(struct boom_rx_desc) * (i+1));\r\nvp->rx_ring[i].status = 0;\r\nvp->rx_ring[i].length = cpu_to_le32(PKT_BUF_SZ | LAST_FRAG);\r\nskb = __netdev_alloc_skb(dev, PKT_BUF_SZ + NET_IP_ALIGN,\r\nGFP_KERNEL);\r\nvp->rx_skbuff[i] = skb;\r\nif (skb == NULL)\r\nbreak;\r\nskb_reserve(skb, NET_IP_ALIGN);\r\nvp->rx_ring[i].addr = cpu_to_le32(pci_map_single(VORTEX_PCI(vp), skb->data, PKT_BUF_SZ, PCI_DMA_FROMDEVICE));\r\n}\r\nif (i != RX_RING_SIZE) {\r\nint j;\r\npr_emerg("%s: no memory for rx ring\n", dev->name);\r\nfor (j = 0; j < i; j++) {\r\nif (vp->rx_skbuff[j]) {\r\ndev_kfree_skb(vp->rx_skbuff[j]);\r\nvp->rx_skbuff[j] = NULL;\r\n}\r\n}\r\nretval = -ENOMEM;\r\ngoto err_free_irq;\r\n}\r\nvp->rx_ring[i-1].next = cpu_to_le32(vp->rx_ring_dma);\r\n}\r\nretval = vortex_up(dev);\r\nif (!retval)\r\ngoto out;\r\nerr_free_irq:\r\nfree_irq(dev->irq, dev);\r\nerr:\r\nif (vortex_debug > 1)\r\npr_err("%s: vortex_open() fails: returning %d\n", dev->name, retval);\r\nout:\r\nreturn retval;\r\n}\r\nstatic void\r\nvortex_timer(unsigned long data)\r\n{\r\nstruct net_device *dev = (struct net_device *)data;\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = vp->ioaddr;\r\nint next_tick = 60*HZ;\r\nint ok = 0;\r\nint media_status;\r\nif (vortex_debug > 2) {\r\npr_debug("%s: Media selection timer tick happened, %s.\n",\r\ndev->name, media_tbl[dev->if_port].name);\r\npr_debug("dev->watchdog_timeo=%d\n", dev->watchdog_timeo);\r\n}\r\nmedia_status = window_read16(vp, 4, Wn4_Media);\r\nswitch (dev->if_port) {\r\ncase XCVR_10baseT: case XCVR_100baseTx: case XCVR_100baseFx:\r\nif (media_status & Media_LnkBeat) {\r\nnetif_carrier_on(dev);\r\nok = 1;\r\nif (vortex_debug > 1)\r\npr_debug("%s: Media %s has link beat, %x.\n",\r\ndev->name, media_tbl[dev->if_port].name, media_status);\r\n} else {\r\nnetif_carrier_off(dev);\r\nif (vortex_debug > 1) {\r\npr_debug("%s: Media %s has no link beat, %x.\n",\r\ndev->name, media_tbl[dev->if_port].name, media_status);\r\n}\r\n}\r\nbreak;\r\ncase XCVR_MII: case XCVR_NWAY:\r\n{\r\nok = 1;\r\nvortex_check_media(dev, 0);\r\n}\r\nbreak;\r\ndefault:\r\nif (vortex_debug > 1)\r\npr_debug("%s: Media %s has no indication, %x.\n",\r\ndev->name, media_tbl[dev->if_port].name, media_status);\r\nok = 1;\r\n}\r\nif (dev->flags & IFF_SLAVE || !netif_carrier_ok(dev))\r\nnext_tick = 5*HZ;\r\nif (vp->medialock)\r\ngoto leave_media_alone;\r\nif (!ok) {\r\nunsigned int config;\r\nspin_lock_irq(&vp->lock);\r\ndo {\r\ndev->if_port = media_tbl[dev->if_port].next;\r\n} while ( ! (vp->available_media & media_tbl[dev->if_port].mask));\r\nif (dev->if_port == XCVR_Default) {\r\ndev->if_port = vp->default_media;\r\nif (vortex_debug > 1)\r\npr_debug("%s: Media selection failing, using default %s port.\n",\r\ndev->name, media_tbl[dev->if_port].name);\r\n} else {\r\nif (vortex_debug > 1)\r\npr_debug("%s: Media selection failed, now trying %s port.\n",\r\ndev->name, media_tbl[dev->if_port].name);\r\nnext_tick = media_tbl[dev->if_port].wait;\r\n}\r\nwindow_write16(vp,\r\n(media_status & ~(Media_10TP|Media_SQE)) |\r\nmedia_tbl[dev->if_port].media_bits,\r\n4, Wn4_Media);\r\nconfig = window_read32(vp, 3, Wn3_Config);\r\nconfig = BFINS(config, dev->if_port, 20, 4);\r\nwindow_write32(vp, config, 3, Wn3_Config);\r\niowrite16(dev->if_port == XCVR_10base2 ? StartCoax : StopCoax,\r\nioaddr + EL3_CMD);\r\nif (vortex_debug > 1)\r\npr_debug("wrote 0x%08x to Wn3_Config\n", config);\r\nspin_unlock_irq(&vp->lock);\r\n}\r\nleave_media_alone:\r\nif (vortex_debug > 2)\r\npr_debug("%s: Media selection timer finished, %s.\n",\r\ndev->name, media_tbl[dev->if_port].name);\r\nmod_timer(&vp->timer, RUN_AT(next_tick));\r\nif (vp->deferred)\r\niowrite16(FakeIntr, ioaddr + EL3_CMD);\r\n}\r\nstatic void vortex_tx_timeout(struct net_device *dev)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = vp->ioaddr;\r\npr_err("%s: transmit timed out, tx_status %2.2x status %4.4x.\n",\r\ndev->name, ioread8(ioaddr + TxStatus),\r\nioread16(ioaddr + EL3_STATUS));\r\npr_err(" diagnostics: net %04x media %04x dma %08x fifo %04x\n",\r\nwindow_read16(vp, 4, Wn4_NetDiag),\r\nwindow_read16(vp, 4, Wn4_Media),\r\nioread32(ioaddr + PktStatus),\r\nwindow_read16(vp, 4, Wn4_FIFODiag));\r\nif ((ioread8(ioaddr + TxStatus) & 0x88) == 0x88)\r\npr_err("%s: Transmitter encountered 16 collisions --"\r\n" network cable problem?\n", dev->name);\r\nif (ioread16(ioaddr + EL3_STATUS) & IntLatch) {\r\npr_err("%s: Interrupt posted but not delivered --"\r\n" IRQ blocked by another device?\n", dev->name);\r\n{\r\nunsigned long flags;\r\nlocal_irq_save(flags);\r\nif (vp->full_bus_master_tx)\r\nboomerang_interrupt(dev->irq, dev);\r\nelse\r\nvortex_interrupt(dev->irq, dev);\r\nlocal_irq_restore(flags);\r\n}\r\n}\r\nif (vortex_debug > 0)\r\ndump_tx_ring(dev);\r\nissue_and_wait(dev, TxReset);\r\ndev->stats.tx_errors++;\r\nif (vp->full_bus_master_tx) {\r\npr_debug("%s: Resetting the Tx ring pointer.\n", dev->name);\r\nif (vp->cur_tx - vp->dirty_tx > 0 && ioread32(ioaddr + DownListPtr) == 0)\r\niowrite32(vp->tx_ring_dma + (vp->dirty_tx % TX_RING_SIZE) * sizeof(struct boom_tx_desc),\r\nioaddr + DownListPtr);\r\nif (vp->cur_tx - vp->dirty_tx < TX_RING_SIZE)\r\nnetif_wake_queue (dev);\r\nif (vp->drv_flags & IS_BOOMERANG)\r\niowrite8(PKT_BUF_SZ>>8, ioaddr + TxFreeThreshold);\r\niowrite16(DownUnstall, ioaddr + EL3_CMD);\r\n} else {\r\ndev->stats.tx_dropped++;\r\nnetif_wake_queue(dev);\r\n}\r\niowrite16(TxEnable, ioaddr + EL3_CMD);\r\ndev->trans_start = jiffies;\r\n}\r\nstatic void\r\nvortex_error(struct net_device *dev, int status)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = vp->ioaddr;\r\nint do_tx_reset = 0, reset_mask = 0;\r\nunsigned char tx_status = 0;\r\nif (vortex_debug > 2) {\r\npr_err("%s: vortex_error(), status=0x%x\n", dev->name, status);\r\n}\r\nif (status & TxComplete) {\r\ntx_status = ioread8(ioaddr + TxStatus);\r\nif (vortex_debug > 2 ||\r\n(tx_status != 0x88 && vortex_debug > 0)) {\r\npr_err("%s: Transmit error, Tx status register %2.2x.\n",\r\ndev->name, tx_status);\r\nif (tx_status == 0x82) {\r\npr_err("Probably a duplex mismatch. See "\r\n"Documentation/networking/vortex.txt\n");\r\n}\r\ndump_tx_ring(dev);\r\n}\r\nif (tx_status & 0x14) dev->stats.tx_fifo_errors++;\r\nif (tx_status & 0x38) dev->stats.tx_aborted_errors++;\r\nif (tx_status & 0x08) vp->xstats.tx_max_collisions++;\r\niowrite8(0, ioaddr + TxStatus);\r\nif (tx_status & 0x30) {\r\ndo_tx_reset = 1;\r\n} else if ((tx_status & 0x08) && (vp->drv_flags & MAX_COLLISION_RESET)) {\r\ndo_tx_reset = 1;\r\nreset_mask = 0x0108;\r\n} else {\r\niowrite16(TxEnable, ioaddr + EL3_CMD);\r\n}\r\n}\r\nif (status & RxEarly)\r\niowrite16(AckIntr | RxEarly, ioaddr + EL3_CMD);\r\nif (status & StatsFull) {\r\nstatic int DoneDidThat;\r\nif (vortex_debug > 4)\r\npr_debug("%s: Updating stats.\n", dev->name);\r\nupdate_stats(ioaddr, dev);\r\nif (DoneDidThat == 0 &&\r\nioread16(ioaddr + EL3_STATUS) & StatsFull) {\r\npr_warn("%s: Updating statistics failed, disabling stats as an interrupt source\n",\r\ndev->name);\r\niowrite16(SetIntrEnb |\r\n(window_read16(vp, 5, 10) & ~StatsFull),\r\nioaddr + EL3_CMD);\r\nvp->intr_enable &= ~StatsFull;\r\nDoneDidThat++;\r\n}\r\n}\r\nif (status & IntReq) {\r\niowrite16(vp->status_enable, ioaddr + EL3_CMD);\r\niowrite16(vp->intr_enable, ioaddr + EL3_CMD);\r\n}\r\nif (status & HostError) {\r\nu16 fifo_diag;\r\nfifo_diag = window_read16(vp, 4, Wn4_FIFODiag);\r\npr_err("%s: Host error, FIFO diagnostic register %4.4x.\n",\r\ndev->name, fifo_diag);\r\nif (vp->full_bus_master_tx) {\r\nint bus_status = ioread32(ioaddr + PktStatus);\r\nif (vortex_debug)\r\npr_err("%s: PCI bus error, bus status %8.8x\n", dev->name, bus_status);\r\nvortex_down(dev, 0);\r\nissue_and_wait(dev, TotalReset | 0xff);\r\nvortex_up(dev);\r\n} else if (fifo_diag & 0x0400)\r\ndo_tx_reset = 1;\r\nif (fifo_diag & 0x3000) {\r\nissue_and_wait(dev, RxReset|0x07);\r\nset_rx_mode(dev);\r\nset_8021q_mode(dev, 1);\r\niowrite16(RxEnable, ioaddr + EL3_CMD);\r\niowrite16(AckIntr | HostError, ioaddr + EL3_CMD);\r\n}\r\n}\r\nif (do_tx_reset) {\r\nissue_and_wait(dev, TxReset|reset_mask);\r\niowrite16(TxEnable, ioaddr + EL3_CMD);\r\nif (!vp->full_bus_master_tx)\r\nnetif_wake_queue(dev);\r\n}\r\n}\r\nstatic netdev_tx_t\r\nvortex_start_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = vp->ioaddr;\r\niowrite32(skb->len, ioaddr + TX_FIFO);\r\nif (vp->bus_master) {\r\nint len = (skb->len + 3) & ~3;\r\nvp->tx_skb_dma = pci_map_single(VORTEX_PCI(vp), skb->data, len,\r\nPCI_DMA_TODEVICE);\r\nspin_lock_irq(&vp->window_lock);\r\nwindow_set(vp, 7);\r\niowrite32(vp->tx_skb_dma, ioaddr + Wn7_MasterAddr);\r\niowrite16(len, ioaddr + Wn7_MasterLen);\r\nspin_unlock_irq(&vp->window_lock);\r\nvp->tx_skb = skb;\r\nskb_tx_timestamp(skb);\r\niowrite16(StartDMADown, ioaddr + EL3_CMD);\r\n} else {\r\nskb_tx_timestamp(skb);\r\niowrite32_rep(ioaddr + TX_FIFO, skb->data, (skb->len + 3) >> 2);\r\ndev_consume_skb_any (skb);\r\nif (ioread16(ioaddr + TxFree) > 1536) {\r\nnetif_start_queue (dev);\r\n} else {\r\nnetif_stop_queue(dev);\r\niowrite16(SetTxThreshold + (1536>>2), ioaddr + EL3_CMD);\r\n}\r\n}\r\n{\r\nint tx_status;\r\nint i = 32;\r\nwhile (--i > 0 && (tx_status = ioread8(ioaddr + TxStatus)) > 0) {\r\nif (tx_status & 0x3C) {\r\nif (vortex_debug > 2)\r\npr_debug("%s: Tx error, status %2.2x.\n",\r\ndev->name, tx_status);\r\nif (tx_status & 0x04) dev->stats.tx_fifo_errors++;\r\nif (tx_status & 0x38) dev->stats.tx_aborted_errors++;\r\nif (tx_status & 0x30) {\r\nissue_and_wait(dev, TxReset);\r\n}\r\niowrite16(TxEnable, ioaddr + EL3_CMD);\r\n}\r\niowrite8(0x00, ioaddr + TxStatus);\r\n}\r\n}\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic netdev_tx_t\r\nboomerang_start_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = vp->ioaddr;\r\nint entry = vp->cur_tx % TX_RING_SIZE;\r\nstruct boom_tx_desc *prev_entry = &vp->tx_ring[(vp->cur_tx-1) % TX_RING_SIZE];\r\nunsigned long flags;\r\ndma_addr_t dma_addr;\r\nif (vortex_debug > 6) {\r\npr_debug("boomerang_start_xmit()\n");\r\npr_debug("%s: Trying to send a packet, Tx index %d.\n",\r\ndev->name, vp->cur_tx);\r\n}\r\nif (vp->handling_irq)\r\nreturn NETDEV_TX_BUSY;\r\nif (vp->cur_tx - vp->dirty_tx >= TX_RING_SIZE) {\r\nif (vortex_debug > 0)\r\npr_warn("%s: BUG! Tx Ring full, refusing to send buffer\n",\r\ndev->name);\r\nnetif_stop_queue(dev);\r\nreturn NETDEV_TX_BUSY;\r\n}\r\nvp->tx_skbuff[entry] = skb;\r\nvp->tx_ring[entry].next = 0;\r\n#if DO_ZEROCOPY\r\nif (skb->ip_summed != CHECKSUM_PARTIAL)\r\nvp->tx_ring[entry].status = cpu_to_le32(skb->len | TxIntrUploaded);\r\nelse\r\nvp->tx_ring[entry].status = cpu_to_le32(skb->len | TxIntrUploaded | AddTCPChksum | AddUDPChksum);\r\nif (!skb_shinfo(skb)->nr_frags) {\r\ndma_addr = pci_map_single(VORTEX_PCI(vp), skb->data, skb->len,\r\nPCI_DMA_TODEVICE);\r\nif (dma_mapping_error(&VORTEX_PCI(vp)->dev, dma_addr))\r\ngoto out_dma_err;\r\nvp->tx_ring[entry].frag[0].addr = cpu_to_le32(dma_addr);\r\nvp->tx_ring[entry].frag[0].length = cpu_to_le32(skb->len | LAST_FRAG);\r\n} else {\r\nint i;\r\ndma_addr = pci_map_single(VORTEX_PCI(vp), skb->data,\r\nskb_headlen(skb), PCI_DMA_TODEVICE);\r\nif (dma_mapping_error(&VORTEX_PCI(vp)->dev, dma_addr))\r\ngoto out_dma_err;\r\nvp->tx_ring[entry].frag[0].addr = cpu_to_le32(dma_addr);\r\nvp->tx_ring[entry].frag[0].length = cpu_to_le32(skb_headlen(skb));\r\nfor (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {\r\nskb_frag_t *frag = &skb_shinfo(skb)->frags[i];\r\ndma_addr = skb_frag_dma_map(&VORTEX_PCI(vp)->dev, frag,\r\n0,\r\nfrag->size,\r\nDMA_TO_DEVICE);\r\nif (dma_mapping_error(&VORTEX_PCI(vp)->dev, dma_addr)) {\r\nfor(i = i-1; i >= 0; i--)\r\ndma_unmap_page(&VORTEX_PCI(vp)->dev,\r\nle32_to_cpu(vp->tx_ring[entry].frag[i+1].addr),\r\nle32_to_cpu(vp->tx_ring[entry].frag[i+1].length),\r\nDMA_TO_DEVICE);\r\npci_unmap_single(VORTEX_PCI(vp),\r\nle32_to_cpu(vp->tx_ring[entry].frag[0].addr),\r\nle32_to_cpu(vp->tx_ring[entry].frag[0].length),\r\nPCI_DMA_TODEVICE);\r\ngoto out_dma_err;\r\n}\r\nvp->tx_ring[entry].frag[i+1].addr =\r\ncpu_to_le32(dma_addr);\r\nif (i == skb_shinfo(skb)->nr_frags-1)\r\nvp->tx_ring[entry].frag[i+1].length = cpu_to_le32(skb_frag_size(frag)|LAST_FRAG);\r\nelse\r\nvp->tx_ring[entry].frag[i+1].length = cpu_to_le32(skb_frag_size(frag));\r\n}\r\n}\r\n#else\r\ndma_addr = pci_map_single(VORTEX_PCI(vp), skb->data, skb->len, PCI_DMA_TODEVICE);\r\nif (dma_mapping_error(&VORTEX_PCI(vp)->dev, dma_addr))\r\ngoto out_dma_err;\r\nvp->tx_ring[entry].addr = cpu_to_le32(dma_addr);\r\nvp->tx_ring[entry].length = cpu_to_le32(skb->len | LAST_FRAG);\r\nvp->tx_ring[entry].status = cpu_to_le32(skb->len | TxIntrUploaded);\r\n#endif\r\nspin_lock_irqsave(&vp->lock, flags);\r\nissue_and_wait(dev, DownStall);\r\nprev_entry->next = cpu_to_le32(vp->tx_ring_dma + entry * sizeof(struct boom_tx_desc));\r\nif (ioread32(ioaddr + DownListPtr) == 0) {\r\niowrite32(vp->tx_ring_dma + entry * sizeof(struct boom_tx_desc), ioaddr + DownListPtr);\r\nvp->queued_packet++;\r\n}\r\nvp->cur_tx++;\r\nif (vp->cur_tx - vp->dirty_tx > TX_RING_SIZE - 1) {\r\nnetif_stop_queue (dev);\r\n} else {\r\n#if defined(tx_interrupt_mitigation)\r\nprev_entry->status &= cpu_to_le32(~TxIntrUploaded);\r\n#endif\r\n}\r\nskb_tx_timestamp(skb);\r\niowrite16(DownUnstall, ioaddr + EL3_CMD);\r\nspin_unlock_irqrestore(&vp->lock, flags);\r\nout:\r\nreturn NETDEV_TX_OK;\r\nout_dma_err:\r\ndev_err(&VORTEX_PCI(vp)->dev, "Error mapping dma buffer\n");\r\ngoto out;\r\n}\r\nstatic irqreturn_t\r\nvortex_interrupt(int irq, void *dev_id)\r\n{\r\nstruct net_device *dev = dev_id;\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nvoid __iomem *ioaddr;\r\nint status;\r\nint work_done = max_interrupt_work;\r\nint handled = 0;\r\nioaddr = vp->ioaddr;\r\nspin_lock(&vp->lock);\r\nstatus = ioread16(ioaddr + EL3_STATUS);\r\nif (vortex_debug > 6)\r\npr_debug("vortex_interrupt(). status=0x%4x\n", status);\r\nif ((status & IntLatch) == 0)\r\ngoto handler_exit;\r\nhandled = 1;\r\nif (status & IntReq) {\r\nstatus |= vp->deferred;\r\nvp->deferred = 0;\r\n}\r\nif (status == 0xffff)\r\ngoto handler_exit;\r\nif (vortex_debug > 4)\r\npr_debug("%s: interrupt, status %4.4x, latency %d ticks.\n",\r\ndev->name, status, ioread8(ioaddr + Timer));\r\nspin_lock(&vp->window_lock);\r\nwindow_set(vp, 7);\r\ndo {\r\nif (vortex_debug > 5)\r\npr_debug("%s: In interrupt loop, status %4.4x.\n",\r\ndev->name, status);\r\nif (status & RxComplete)\r\nvortex_rx(dev);\r\nif (status & TxAvailable) {\r\nif (vortex_debug > 5)\r\npr_debug(" TX room bit was handled.\n");\r\niowrite16(AckIntr | TxAvailable, ioaddr + EL3_CMD);\r\nnetif_wake_queue (dev);\r\n}\r\nif (status & DMADone) {\r\nif (ioread16(ioaddr + Wn7_MasterStatus) & 0x1000) {\r\niowrite16(0x1000, ioaddr + Wn7_MasterStatus);\r\npci_unmap_single(VORTEX_PCI(vp), vp->tx_skb_dma, (vp->tx_skb->len + 3) & ~3, PCI_DMA_TODEVICE);\r\ndev_kfree_skb_irq(vp->tx_skb);\r\nif (ioread16(ioaddr + TxFree) > 1536) {\r\nnetif_wake_queue(dev);\r\n} else {\r\niowrite16(SetTxThreshold + (1536>>2), ioaddr + EL3_CMD);\r\nnetif_stop_queue(dev);\r\n}\r\n}\r\n}\r\nif (status & (HostError | RxEarly | StatsFull | TxComplete | IntReq)) {\r\nif (status == 0xffff)\r\nbreak;\r\nif (status & RxEarly)\r\nvortex_rx(dev);\r\nspin_unlock(&vp->window_lock);\r\nvortex_error(dev, status);\r\nspin_lock(&vp->window_lock);\r\nwindow_set(vp, 7);\r\n}\r\nif (--work_done < 0) {\r\npr_warn("%s: Too much work in interrupt, status %4.4x\n",\r\ndev->name, status);\r\ndo {\r\nvp->deferred |= status;\r\niowrite16(SetStatusEnb | (~vp->deferred & vp->status_enable),\r\nioaddr + EL3_CMD);\r\niowrite16(AckIntr | (vp->deferred & 0x7ff), ioaddr + EL3_CMD);\r\n} while ((status = ioread16(ioaddr + EL3_CMD)) & IntLatch);\r\nmod_timer(&vp->timer, jiffies + 1*HZ);\r\nbreak;\r\n}\r\niowrite16(AckIntr | IntReq | IntLatch, ioaddr + EL3_CMD);\r\n} while ((status = ioread16(ioaddr + EL3_STATUS)) & (IntLatch | RxComplete));\r\nspin_unlock(&vp->window_lock);\r\nif (vortex_debug > 4)\r\npr_debug("%s: exiting interrupt, status %4.4x.\n",\r\ndev->name, status);\r\nhandler_exit:\r\nspin_unlock(&vp->lock);\r\nreturn IRQ_RETVAL(handled);\r\n}\r\nstatic irqreturn_t\r\nboomerang_interrupt(int irq, void *dev_id)\r\n{\r\nstruct net_device *dev = dev_id;\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nvoid __iomem *ioaddr;\r\nint status;\r\nint work_done = max_interrupt_work;\r\nioaddr = vp->ioaddr;\r\nspin_lock(&vp->lock);\r\nvp->handling_irq = 1;\r\nstatus = ioread16(ioaddr + EL3_STATUS);\r\nif (vortex_debug > 6)\r\npr_debug("boomerang_interrupt. status=0x%4x\n", status);\r\nif ((status & IntLatch) == 0)\r\ngoto handler_exit;\r\nif (status == 0xffff) {\r\nif (vortex_debug > 1)\r\npr_debug("boomerang_interrupt(1): status = 0xffff\n");\r\ngoto handler_exit;\r\n}\r\nif (status & IntReq) {\r\nstatus |= vp->deferred;\r\nvp->deferred = 0;\r\n}\r\nif (vortex_debug > 4)\r\npr_debug("%s: interrupt, status %4.4x, latency %d ticks.\n",\r\ndev->name, status, ioread8(ioaddr + Timer));\r\ndo {\r\nif (vortex_debug > 5)\r\npr_debug("%s: In interrupt loop, status %4.4x.\n",\r\ndev->name, status);\r\nif (status & UpComplete) {\r\niowrite16(AckIntr | UpComplete, ioaddr + EL3_CMD);\r\nif (vortex_debug > 5)\r\npr_debug("boomerang_interrupt->boomerang_rx\n");\r\nboomerang_rx(dev);\r\n}\r\nif (status & DownComplete) {\r\nunsigned int dirty_tx = vp->dirty_tx;\r\niowrite16(AckIntr | DownComplete, ioaddr + EL3_CMD);\r\nwhile (vp->cur_tx - dirty_tx > 0) {\r\nint entry = dirty_tx % TX_RING_SIZE;\r\n#if 1\r\nif (ioread32(ioaddr + DownListPtr) ==\r\nvp->tx_ring_dma + entry * sizeof(struct boom_tx_desc))\r\nbreak;\r\n#else\r\nif ((vp->tx_ring[entry].status & DN_COMPLETE) == 0)\r\nbreak;\r\n#endif\r\nif (vp->tx_skbuff[entry]) {\r\nstruct sk_buff *skb = vp->tx_skbuff[entry];\r\n#if DO_ZEROCOPY\r\nint i;\r\nfor (i=0; i<=skb_shinfo(skb)->nr_frags; i++)\r\npci_unmap_single(VORTEX_PCI(vp),\r\nle32_to_cpu(vp->tx_ring[entry].frag[i].addr),\r\nle32_to_cpu(vp->tx_ring[entry].frag[i].length)&0xFFF,\r\nPCI_DMA_TODEVICE);\r\n#else\r\npci_unmap_single(VORTEX_PCI(vp),\r\nle32_to_cpu(vp->tx_ring[entry].addr), skb->len, PCI_DMA_TODEVICE);\r\n#endif\r\ndev_kfree_skb_irq(skb);\r\nvp->tx_skbuff[entry] = NULL;\r\n} else {\r\npr_debug("boomerang_interrupt: no skb!\n");\r\n}\r\ndirty_tx++;\r\n}\r\nvp->dirty_tx = dirty_tx;\r\nif (vp->cur_tx - dirty_tx <= TX_RING_SIZE - 1) {\r\nif (vortex_debug > 6)\r\npr_debug("boomerang_interrupt: wake queue\n");\r\nnetif_wake_queue (dev);\r\n}\r\n}\r\nif (status & (HostError | RxEarly | StatsFull | TxComplete | IntReq))\r\nvortex_error(dev, status);\r\nif (--work_done < 0) {\r\npr_warn("%s: Too much work in interrupt, status %4.4x\n",\r\ndev->name, status);\r\ndo {\r\nvp->deferred |= status;\r\niowrite16(SetStatusEnb | (~vp->deferred & vp->status_enable),\r\nioaddr + EL3_CMD);\r\niowrite16(AckIntr | (vp->deferred & 0x7ff), ioaddr + EL3_CMD);\r\n} while ((status = ioread16(ioaddr + EL3_CMD)) & IntLatch);\r\nmod_timer(&vp->timer, jiffies + 1*HZ);\r\nbreak;\r\n}\r\niowrite16(AckIntr | IntReq | IntLatch, ioaddr + EL3_CMD);\r\nif (vp->cb_fn_base)\r\niowrite32(0x8000, vp->cb_fn_base + 4);\r\n} while ((status = ioread16(ioaddr + EL3_STATUS)) & IntLatch);\r\nif (vortex_debug > 4)\r\npr_debug("%s: exiting interrupt, status %4.4x.\n",\r\ndev->name, status);\r\nhandler_exit:\r\nvp->handling_irq = 0;\r\nspin_unlock(&vp->lock);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int vortex_rx(struct net_device *dev)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = vp->ioaddr;\r\nint i;\r\nshort rx_status;\r\nif (vortex_debug > 5)\r\npr_debug("vortex_rx(): status %4.4x, rx_status %4.4x.\n",\r\nioread16(ioaddr+EL3_STATUS), ioread16(ioaddr+RxStatus));\r\nwhile ((rx_status = ioread16(ioaddr + RxStatus)) > 0) {\r\nif (rx_status & 0x4000) {\r\nunsigned char rx_error = ioread8(ioaddr + RxErrors);\r\nif (vortex_debug > 2)\r\npr_debug(" Rx error: status %2.2x.\n", rx_error);\r\ndev->stats.rx_errors++;\r\nif (rx_error & 0x01) dev->stats.rx_over_errors++;\r\nif (rx_error & 0x02) dev->stats.rx_length_errors++;\r\nif (rx_error & 0x04) dev->stats.rx_frame_errors++;\r\nif (rx_error & 0x08) dev->stats.rx_crc_errors++;\r\nif (rx_error & 0x10) dev->stats.rx_length_errors++;\r\n} else {\r\nint pkt_len = rx_status & 0x1fff;\r\nstruct sk_buff *skb;\r\nskb = netdev_alloc_skb(dev, pkt_len + 5);\r\nif (vortex_debug > 4)\r\npr_debug("Receiving packet size %d status %4.4x.\n",\r\npkt_len, rx_status);\r\nif (skb != NULL) {\r\nskb_reserve(skb, 2);\r\nif (vp->bus_master &&\r\n! (ioread16(ioaddr + Wn7_MasterStatus) & 0x8000)) {\r\ndma_addr_t dma = pci_map_single(VORTEX_PCI(vp), skb_put(skb, pkt_len),\r\npkt_len, PCI_DMA_FROMDEVICE);\r\niowrite32(dma, ioaddr + Wn7_MasterAddr);\r\niowrite16((skb->len + 3) & ~3, ioaddr + Wn7_MasterLen);\r\niowrite16(StartDMAUp, ioaddr + EL3_CMD);\r\nwhile (ioread16(ioaddr + Wn7_MasterStatus) & 0x8000)\r\n;\r\npci_unmap_single(VORTEX_PCI(vp), dma, pkt_len, PCI_DMA_FROMDEVICE);\r\n} else {\r\nioread32_rep(ioaddr + RX_FIFO,\r\nskb_put(skb, pkt_len),\r\n(pkt_len + 3) >> 2);\r\n}\r\niowrite16(RxDiscard, ioaddr + EL3_CMD);\r\nskb->protocol = eth_type_trans(skb, dev);\r\nnetif_rx(skb);\r\ndev->stats.rx_packets++;\r\nfor (i = 200; i >= 0; i--)\r\nif ( ! (ioread16(ioaddr + EL3_STATUS) & CmdInProgress))\r\nbreak;\r\ncontinue;\r\n} else if (vortex_debug > 0)\r\npr_notice("%s: No memory to allocate a sk_buff of size %d.\n",\r\ndev->name, pkt_len);\r\ndev->stats.rx_dropped++;\r\n}\r\nissue_and_wait(dev, RxDiscard);\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\nboomerang_rx(struct net_device *dev)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nint entry = vp->cur_rx % RX_RING_SIZE;\r\nvoid __iomem *ioaddr = vp->ioaddr;\r\nint rx_status;\r\nint rx_work_limit = vp->dirty_rx + RX_RING_SIZE - vp->cur_rx;\r\nif (vortex_debug > 5)\r\npr_debug("boomerang_rx(): status %4.4x\n", ioread16(ioaddr+EL3_STATUS));\r\nwhile ((rx_status = le32_to_cpu(vp->rx_ring[entry].status)) & RxDComplete){\r\nif (--rx_work_limit < 0)\r\nbreak;\r\nif (rx_status & RxDError) {\r\nunsigned char rx_error = rx_status >> 16;\r\nif (vortex_debug > 2)\r\npr_debug(" Rx error: status %2.2x.\n", rx_error);\r\ndev->stats.rx_errors++;\r\nif (rx_error & 0x01) dev->stats.rx_over_errors++;\r\nif (rx_error & 0x02) dev->stats.rx_length_errors++;\r\nif (rx_error & 0x04) dev->stats.rx_frame_errors++;\r\nif (rx_error & 0x08) dev->stats.rx_crc_errors++;\r\nif (rx_error & 0x10) dev->stats.rx_length_errors++;\r\n} else {\r\nint pkt_len = rx_status & 0x1fff;\r\nstruct sk_buff *skb;\r\ndma_addr_t dma = le32_to_cpu(vp->rx_ring[entry].addr);\r\nif (vortex_debug > 4)\r\npr_debug("Receiving packet size %d status %4.4x.\n",\r\npkt_len, rx_status);\r\nif (pkt_len < rx_copybreak &&\r\n(skb = netdev_alloc_skb(dev, pkt_len + 2)) != NULL) {\r\nskb_reserve(skb, 2);\r\npci_dma_sync_single_for_cpu(VORTEX_PCI(vp), dma, PKT_BUF_SZ, PCI_DMA_FROMDEVICE);\r\nmemcpy(skb_put(skb, pkt_len),\r\nvp->rx_skbuff[entry]->data,\r\npkt_len);\r\npci_dma_sync_single_for_device(VORTEX_PCI(vp), dma, PKT_BUF_SZ, PCI_DMA_FROMDEVICE);\r\nvp->rx_copy++;\r\n} else {\r\nskb = vp->rx_skbuff[entry];\r\nvp->rx_skbuff[entry] = NULL;\r\nskb_put(skb, pkt_len);\r\npci_unmap_single(VORTEX_PCI(vp), dma, PKT_BUF_SZ, PCI_DMA_FROMDEVICE);\r\nvp->rx_nocopy++;\r\n}\r\nskb->protocol = eth_type_trans(skb, dev);\r\n{\r\nint csum_bits = rx_status & 0xee000000;\r\nif (csum_bits &&\r\n(csum_bits == (IPChksumValid | TCPChksumValid) ||\r\ncsum_bits == (IPChksumValid | UDPChksumValid))) {\r\nskb->ip_summed = CHECKSUM_UNNECESSARY;\r\nvp->rx_csumhits++;\r\n}\r\n}\r\nnetif_rx(skb);\r\ndev->stats.rx_packets++;\r\n}\r\nentry = (++vp->cur_rx) % RX_RING_SIZE;\r\n}\r\nfor (; vp->cur_rx - vp->dirty_rx > 0; vp->dirty_rx++) {\r\nstruct sk_buff *skb;\r\nentry = vp->dirty_rx % RX_RING_SIZE;\r\nif (vp->rx_skbuff[entry] == NULL) {\r\nskb = netdev_alloc_skb_ip_align(dev, PKT_BUF_SZ);\r\nif (skb == NULL) {\r\nstatic unsigned long last_jif;\r\nif (time_after(jiffies, last_jif + 10 * HZ)) {\r\npr_warn("%s: memory shortage\n",\r\ndev->name);\r\nlast_jif = jiffies;\r\n}\r\nif ((vp->cur_rx - vp->dirty_rx) == RX_RING_SIZE)\r\nmod_timer(&vp->rx_oom_timer, RUN_AT(HZ * 1));\r\nbreak;\r\n}\r\nvp->rx_ring[entry].addr = cpu_to_le32(pci_map_single(VORTEX_PCI(vp), skb->data, PKT_BUF_SZ, PCI_DMA_FROMDEVICE));\r\nvp->rx_skbuff[entry] = skb;\r\n}\r\nvp->rx_ring[entry].status = 0;\r\niowrite16(UpUnstall, ioaddr + EL3_CMD);\r\n}\r\nreturn 0;\r\n}\r\nstatic void\r\nrx_oom_timer(unsigned long arg)\r\n{\r\nstruct net_device *dev = (struct net_device *)arg;\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nspin_lock_irq(&vp->lock);\r\nif ((vp->cur_rx - vp->dirty_rx) == RX_RING_SIZE)\r\nboomerang_rx(dev);\r\nif (vortex_debug > 1) {\r\npr_debug("%s: rx_oom_timer %s\n", dev->name,\r\n((vp->cur_rx - vp->dirty_rx) != RX_RING_SIZE) ? "succeeded" : "retrying");\r\n}\r\nspin_unlock_irq(&vp->lock);\r\n}\r\nstatic void\r\nvortex_down(struct net_device *dev, int final_down)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = vp->ioaddr;\r\nnetif_stop_queue (dev);\r\ndel_timer_sync(&vp->rx_oom_timer);\r\ndel_timer_sync(&vp->timer);\r\niowrite16(StatsDisable, ioaddr + EL3_CMD);\r\niowrite16(RxDisable, ioaddr + EL3_CMD);\r\niowrite16(TxDisable, ioaddr + EL3_CMD);\r\nset_8021q_mode(dev, 0);\r\nif (dev->if_port == XCVR_10base2)\r\niowrite16(StopCoax, ioaddr + EL3_CMD);\r\niowrite16(SetIntrEnb | 0x0000, ioaddr + EL3_CMD);\r\nupdate_stats(ioaddr, dev);\r\nif (vp->full_bus_master_rx)\r\niowrite32(0, ioaddr + UpListPtr);\r\nif (vp->full_bus_master_tx)\r\niowrite32(0, ioaddr + DownListPtr);\r\nif (final_down && VORTEX_PCI(vp)) {\r\nvp->pm_state_valid = 1;\r\npci_save_state(VORTEX_PCI(vp));\r\nacpi_set_WOL(dev);\r\n}\r\n}\r\nstatic int\r\nvortex_close(struct net_device *dev)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = vp->ioaddr;\r\nint i;\r\nif (netif_device_present(dev))\r\nvortex_down(dev, 1);\r\nif (vortex_debug > 1) {\r\npr_debug("%s: vortex_close() status %4.4x, Tx status %2.2x.\n",\r\ndev->name, ioread16(ioaddr + EL3_STATUS), ioread8(ioaddr + TxStatus));\r\npr_debug("%s: vortex close stats: rx_nocopy %d rx_copy %d"\r\n" tx_queued %d Rx pre-checksummed %d.\n",\r\ndev->name, vp->rx_nocopy, vp->rx_copy, vp->queued_packet, vp->rx_csumhits);\r\n}\r\n#if DO_ZEROCOPY\r\nif (vp->rx_csumhits &&\r\n(vp->drv_flags & HAS_HWCKSM) == 0 &&\r\n(vp->card_idx >= MAX_UNITS || hw_checksums[vp->card_idx] == -1)) {\r\npr_warn("%s supports hardware checksums, and we're not using them!\n",\r\ndev->name);\r\n}\r\n#endif\r\nfree_irq(dev->irq, dev);\r\nif (vp->full_bus_master_rx) {\r\nfor (i = 0; i < RX_RING_SIZE; i++)\r\nif (vp->rx_skbuff[i]) {\r\npci_unmap_single( VORTEX_PCI(vp), le32_to_cpu(vp->rx_ring[i].addr),\r\nPKT_BUF_SZ, PCI_DMA_FROMDEVICE);\r\ndev_kfree_skb(vp->rx_skbuff[i]);\r\nvp->rx_skbuff[i] = NULL;\r\n}\r\n}\r\nif (vp->full_bus_master_tx) {\r\nfor (i = 0; i < TX_RING_SIZE; i++) {\r\nif (vp->tx_skbuff[i]) {\r\nstruct sk_buff *skb = vp->tx_skbuff[i];\r\n#if DO_ZEROCOPY\r\nint k;\r\nfor (k=0; k<=skb_shinfo(skb)->nr_frags; k++)\r\npci_unmap_single(VORTEX_PCI(vp),\r\nle32_to_cpu(vp->tx_ring[i].frag[k].addr),\r\nle32_to_cpu(vp->tx_ring[i].frag[k].length)&0xFFF,\r\nPCI_DMA_TODEVICE);\r\n#else\r\npci_unmap_single(VORTEX_PCI(vp), le32_to_cpu(vp->tx_ring[i].addr), skb->len, PCI_DMA_TODEVICE);\r\n#endif\r\ndev_kfree_skb(skb);\r\nvp->tx_skbuff[i] = NULL;\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void\r\ndump_tx_ring(struct net_device *dev)\r\n{\r\nif (vortex_debug > 0) {\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = vp->ioaddr;\r\nif (vp->full_bus_master_tx) {\r\nint i;\r\nint stalled = ioread32(ioaddr + PktStatus) & 0x04;\r\npr_err(" Flags; bus-master %d, dirty %d(%d) current %d(%d)\n",\r\nvp->full_bus_master_tx,\r\nvp->dirty_tx, vp->dirty_tx % TX_RING_SIZE,\r\nvp->cur_tx, vp->cur_tx % TX_RING_SIZE);\r\npr_err(" Transmit list %8.8x vs. %p.\n",\r\nioread32(ioaddr + DownListPtr),\r\n&vp->tx_ring[vp->dirty_tx % TX_RING_SIZE]);\r\nissue_and_wait(dev, DownStall);\r\nfor (i = 0; i < TX_RING_SIZE; i++) {\r\nunsigned int length;\r\n#if DO_ZEROCOPY\r\nlength = le32_to_cpu(vp->tx_ring[i].frag[0].length);\r\n#else\r\nlength = le32_to_cpu(vp->tx_ring[i].length);\r\n#endif\r\npr_err(" %d: @%p length %8.8x status %8.8x\n",\r\ni, &vp->tx_ring[i], length,\r\nle32_to_cpu(vp->tx_ring[i].status));\r\n}\r\nif (!stalled)\r\niowrite16(DownUnstall, ioaddr + EL3_CMD);\r\n}\r\n}\r\n}\r\nstatic struct net_device_stats *vortex_get_stats(struct net_device *dev)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = vp->ioaddr;\r\nunsigned long flags;\r\nif (netif_device_present(dev)) {\r\nspin_lock_irqsave (&vp->lock, flags);\r\nupdate_stats(ioaddr, dev);\r\nspin_unlock_irqrestore (&vp->lock, flags);\r\n}\r\nreturn &dev->stats;\r\n}\r\nstatic void update_stats(void __iomem *ioaddr, struct net_device *dev)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\ndev->stats.tx_carrier_errors += window_read8(vp, 6, 0);\r\ndev->stats.tx_heartbeat_errors += window_read8(vp, 6, 1);\r\ndev->stats.tx_window_errors += window_read8(vp, 6, 4);\r\ndev->stats.rx_fifo_errors += window_read8(vp, 6, 5);\r\ndev->stats.tx_packets += window_read8(vp, 6, 6);\r\ndev->stats.tx_packets += (window_read8(vp, 6, 9) &\r\n0x30) << 4;\r\nwindow_read8(vp, 6, 7);\r\ndev->stats.rx_bytes += window_read16(vp, 6, 10);\r\ndev->stats.tx_bytes += window_read16(vp, 6, 12);\r\nvp->xstats.tx_multiple_collisions += window_read8(vp, 6, 2);\r\nvp->xstats.tx_single_collisions += window_read8(vp, 6, 3);\r\nvp->xstats.tx_deferred += window_read8(vp, 6, 8);\r\nvp->xstats.rx_bad_ssd += window_read8(vp, 4, 12);\r\ndev->stats.collisions = vp->xstats.tx_multiple_collisions\r\n+ vp->xstats.tx_single_collisions\r\n+ vp->xstats.tx_max_collisions;\r\n{\r\nu8 up = window_read8(vp, 4, 13);\r\ndev->stats.rx_bytes += (up & 0x0f) << 16;\r\ndev->stats.tx_bytes += (up & 0xf0) << 12;\r\n}\r\n}\r\nstatic int vortex_nway_reset(struct net_device *dev)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nreturn mii_nway_restart(&vp->mii);\r\n}\r\nstatic int vortex_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nreturn mii_ethtool_gset(&vp->mii, cmd);\r\n}\r\nstatic int vortex_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nreturn mii_ethtool_sset(&vp->mii, cmd);\r\n}\r\nstatic u32 vortex_get_msglevel(struct net_device *dev)\r\n{\r\nreturn vortex_debug;\r\n}\r\nstatic void vortex_set_msglevel(struct net_device *dev, u32 dbg)\r\n{\r\nvortex_debug = dbg;\r\n}\r\nstatic int vortex_get_sset_count(struct net_device *dev, int sset)\r\n{\r\nswitch (sset) {\r\ncase ETH_SS_STATS:\r\nreturn VORTEX_NUM_STATS;\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nstatic void vortex_get_ethtool_stats(struct net_device *dev,\r\nstruct ethtool_stats *stats, u64 *data)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = vp->ioaddr;\r\nunsigned long flags;\r\nspin_lock_irqsave(&vp->lock, flags);\r\nupdate_stats(ioaddr, dev);\r\nspin_unlock_irqrestore(&vp->lock, flags);\r\ndata[0] = vp->xstats.tx_deferred;\r\ndata[1] = vp->xstats.tx_max_collisions;\r\ndata[2] = vp->xstats.tx_multiple_collisions;\r\ndata[3] = vp->xstats.tx_single_collisions;\r\ndata[4] = vp->xstats.rx_bad_ssd;\r\n}\r\nstatic void vortex_get_strings(struct net_device *dev, u32 stringset, u8 *data)\r\n{\r\nswitch (stringset) {\r\ncase ETH_SS_STATS:\r\nmemcpy(data, &ethtool_stats_keys, sizeof(ethtool_stats_keys));\r\nbreak;\r\ndefault:\r\nWARN_ON(1);\r\nbreak;\r\n}\r\n}\r\nstatic void vortex_get_drvinfo(struct net_device *dev,\r\nstruct ethtool_drvinfo *info)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nstrlcpy(info->driver, DRV_NAME, sizeof(info->driver));\r\nif (VORTEX_PCI(vp)) {\r\nstrlcpy(info->bus_info, pci_name(VORTEX_PCI(vp)),\r\nsizeof(info->bus_info));\r\n} else {\r\nif (VORTEX_EISA(vp))\r\nstrlcpy(info->bus_info, dev_name(vp->gendev),\r\nsizeof(info->bus_info));\r\nelse\r\nsnprintf(info->bus_info, sizeof(info->bus_info),\r\n"EISA 0x%lx %d", dev->base_addr, dev->irq);\r\n}\r\n}\r\nstatic void vortex_get_wol(struct net_device *dev, struct ethtool_wolinfo *wol)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nif (!VORTEX_PCI(vp))\r\nreturn;\r\nwol->supported = WAKE_MAGIC;\r\nwol->wolopts = 0;\r\nif (vp->enable_wol)\r\nwol->wolopts |= WAKE_MAGIC;\r\n}\r\nstatic int vortex_set_wol(struct net_device *dev, struct ethtool_wolinfo *wol)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nif (!VORTEX_PCI(vp))\r\nreturn -EOPNOTSUPP;\r\nif (wol->wolopts & ~WAKE_MAGIC)\r\nreturn -EINVAL;\r\nif (wol->wolopts & WAKE_MAGIC)\r\nvp->enable_wol = 1;\r\nelse\r\nvp->enable_wol = 0;\r\nacpi_set_WOL(dev);\r\nreturn 0;\r\n}\r\nstatic int vortex_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)\r\n{\r\nint err;\r\nstruct vortex_private *vp = netdev_priv(dev);\r\npci_power_t state = 0;\r\nif(VORTEX_PCI(vp))\r\nstate = VORTEX_PCI(vp)->current_state;\r\nif(state != 0)\r\npci_set_power_state(VORTEX_PCI(vp), PCI_D0);\r\nerr = generic_mii_ioctl(&vp->mii, if_mii(rq), cmd, NULL);\r\nif(state != 0)\r\npci_set_power_state(VORTEX_PCI(vp), state);\r\nreturn err;\r\n}\r\nstatic void set_rx_mode(struct net_device *dev)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = vp->ioaddr;\r\nint new_mode;\r\nif (dev->flags & IFF_PROMISC) {\r\nif (vortex_debug > 3)\r\npr_notice("%s: Setting promiscuous mode.\n", dev->name);\r\nnew_mode = SetRxFilter|RxStation|RxMulticast|RxBroadcast|RxProm;\r\n} else if (!netdev_mc_empty(dev) || dev->flags & IFF_ALLMULTI) {\r\nnew_mode = SetRxFilter|RxStation|RxMulticast|RxBroadcast;\r\n} else\r\nnew_mode = SetRxFilter | RxStation | RxBroadcast;\r\niowrite16(new_mode, ioaddr + EL3_CMD);\r\n}\r\nstatic void set_8021q_mode(struct net_device *dev, int enable)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nint mac_ctrl;\r\nif ((vp->drv_flags&IS_CYCLONE) || (vp->drv_flags&IS_TORNADO)) {\r\nint max_pkt_size = dev->mtu+14;\r\nif (enable)\r\nmax_pkt_size += 4;\r\nwindow_write16(vp, max_pkt_size, 3, Wn3_MaxPktSize);\r\nwindow_write16(vp, VLAN_ETHER_TYPE, 7, Wn7_VlanEtherType);\r\n} else {\r\nvp->large_frames = dev->mtu > 1500 || enable;\r\nmac_ctrl = window_read16(vp, 3, Wn3_MAC_Ctrl);\r\nif (vp->large_frames)\r\nmac_ctrl |= 0x40;\r\nelse\r\nmac_ctrl &= ~0x40;\r\nwindow_write16(vp, mac_ctrl, 3, Wn3_MAC_Ctrl);\r\n}\r\n}\r\nstatic void set_8021q_mode(struct net_device *dev, int enable)\r\n{\r\n}\r\nstatic void mdio_delay(struct vortex_private *vp)\r\n{\r\nwindow_read32(vp, 4, Wn4_PhysicalMgmt);\r\n}\r\nstatic void mdio_sync(struct vortex_private *vp, int bits)\r\n{\r\nwhile (-- bits >= 0) {\r\nwindow_write16(vp, MDIO_DATA_WRITE1, 4, Wn4_PhysicalMgmt);\r\nmdio_delay(vp);\r\nwindow_write16(vp, MDIO_DATA_WRITE1 | MDIO_SHIFT_CLK,\r\n4, Wn4_PhysicalMgmt);\r\nmdio_delay(vp);\r\n}\r\n}\r\nstatic int mdio_read(struct net_device *dev, int phy_id, int location)\r\n{\r\nint i;\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nint read_cmd = (0xf6 << 10) | (phy_id << 5) | location;\r\nunsigned int retval = 0;\r\nspin_lock_bh(&vp->mii_lock);\r\nif (mii_preamble_required)\r\nmdio_sync(vp, 32);\r\nfor (i = 14; i >= 0; i--) {\r\nint dataval = (read_cmd&(1<<i)) ? MDIO_DATA_WRITE1 : MDIO_DATA_WRITE0;\r\nwindow_write16(vp, dataval, 4, Wn4_PhysicalMgmt);\r\nmdio_delay(vp);\r\nwindow_write16(vp, dataval | MDIO_SHIFT_CLK,\r\n4, Wn4_PhysicalMgmt);\r\nmdio_delay(vp);\r\n}\r\nfor (i = 19; i > 0; i--) {\r\nwindow_write16(vp, MDIO_ENB_IN, 4, Wn4_PhysicalMgmt);\r\nmdio_delay(vp);\r\nretval = (retval << 1) |\r\n((window_read16(vp, 4, Wn4_PhysicalMgmt) &\r\nMDIO_DATA_READ) ? 1 : 0);\r\nwindow_write16(vp, MDIO_ENB_IN | MDIO_SHIFT_CLK,\r\n4, Wn4_PhysicalMgmt);\r\nmdio_delay(vp);\r\n}\r\nspin_unlock_bh(&vp->mii_lock);\r\nreturn retval & 0x20000 ? 0xffff : retval>>1 & 0xffff;\r\n}\r\nstatic void mdio_write(struct net_device *dev, int phy_id, int location, int value)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nint write_cmd = 0x50020000 | (phy_id << 23) | (location << 18) | value;\r\nint i;\r\nspin_lock_bh(&vp->mii_lock);\r\nif (mii_preamble_required)\r\nmdio_sync(vp, 32);\r\nfor (i = 31; i >= 0; i--) {\r\nint dataval = (write_cmd&(1<<i)) ? MDIO_DATA_WRITE1 : MDIO_DATA_WRITE0;\r\nwindow_write16(vp, dataval, 4, Wn4_PhysicalMgmt);\r\nmdio_delay(vp);\r\nwindow_write16(vp, dataval | MDIO_SHIFT_CLK,\r\n4, Wn4_PhysicalMgmt);\r\nmdio_delay(vp);\r\n}\r\nfor (i = 1; i >= 0; i--) {\r\nwindow_write16(vp, MDIO_ENB_IN, 4, Wn4_PhysicalMgmt);\r\nmdio_delay(vp);\r\nwindow_write16(vp, MDIO_ENB_IN | MDIO_SHIFT_CLK,\r\n4, Wn4_PhysicalMgmt);\r\nmdio_delay(vp);\r\n}\r\nspin_unlock_bh(&vp->mii_lock);\r\n}\r\nstatic void acpi_set_WOL(struct net_device *dev)\r\n{\r\nstruct vortex_private *vp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = vp->ioaddr;\r\ndevice_set_wakeup_enable(vp->gendev, vp->enable_wol);\r\nif (vp->enable_wol) {\r\nwindow_write16(vp, 2, 7, 0x0c);\r\niowrite16(SetRxFilter|RxStation|RxMulticast|RxBroadcast, ioaddr + EL3_CMD);\r\niowrite16(RxEnable, ioaddr + EL3_CMD);\r\nif (pci_enable_wake(VORTEX_PCI(vp), PCI_D3hot, 1)) {\r\npr_info("%s: WOL not supported.\n", pci_name(VORTEX_PCI(vp)));\r\nvp->enable_wol = 0;\r\nreturn;\r\n}\r\nif (VORTEX_PCI(vp)->current_state < PCI_D3hot)\r\nreturn;\r\npci_set_power_state(VORTEX_PCI(vp), PCI_D3hot);\r\n}\r\n}\r\nstatic void vortex_remove_one(struct pci_dev *pdev)\r\n{\r\nstruct net_device *dev = pci_get_drvdata(pdev);\r\nstruct vortex_private *vp;\r\nif (!dev) {\r\npr_err("vortex_remove_one called for Compaq device!\n");\r\nBUG();\r\n}\r\nvp = netdev_priv(dev);\r\nif (vp->cb_fn_base)\r\npci_iounmap(pdev, vp->cb_fn_base);\r\nunregister_netdev(dev);\r\npci_set_power_state(pdev, PCI_D0);\r\nif (vp->pm_state_valid)\r\npci_restore_state(pdev);\r\npci_disable_device(pdev);\r\niowrite16(TotalReset | ((vp->drv_flags & EEPROM_RESET) ? 0x04 : 0x14),\r\nvp->ioaddr + EL3_CMD);\r\npci_iounmap(pdev, vp->ioaddr);\r\npci_free_consistent(pdev,\r\nsizeof(struct boom_rx_desc) * RX_RING_SIZE\r\n+ sizeof(struct boom_tx_desc) * TX_RING_SIZE,\r\nvp->rx_ring,\r\nvp->rx_ring_dma);\r\npci_release_regions(pdev);\r\nfree_netdev(dev);\r\n}\r\nstatic int __init vortex_init(void)\r\n{\r\nint pci_rc, eisa_rc;\r\npci_rc = pci_register_driver(&vortex_driver);\r\neisa_rc = vortex_eisa_init();\r\nif (pci_rc == 0)\r\nvortex_have_pci = 1;\r\nif (eisa_rc > 0)\r\nvortex_have_eisa = 1;\r\nreturn (vortex_have_pci + vortex_have_eisa) ? 0 : -ENODEV;\r\n}\r\nstatic void __exit vortex_eisa_cleanup(void)\r\n{\r\nvoid __iomem *ioaddr;\r\n#ifdef CONFIG_EISA\r\neisa_driver_unregister(&vortex_eisa_driver);\r\n#endif\r\nif (compaq_net_device) {\r\nioaddr = ioport_map(compaq_net_device->base_addr,\r\nVORTEX_TOTAL_SIZE);\r\nunregister_netdev(compaq_net_device);\r\niowrite16(TotalReset, ioaddr + EL3_CMD);\r\nrelease_region(compaq_net_device->base_addr,\r\nVORTEX_TOTAL_SIZE);\r\nfree_netdev(compaq_net_device);\r\n}\r\n}\r\nstatic void __exit vortex_cleanup(void)\r\n{\r\nif (vortex_have_pci)\r\npci_unregister_driver(&vortex_driver);\r\nif (vortex_have_eisa)\r\nvortex_eisa_cleanup();\r\n}
