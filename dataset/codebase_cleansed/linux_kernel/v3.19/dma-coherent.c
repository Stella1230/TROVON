void dma_cache_sync(struct device *dev, void *vaddr, size_t size, int direction)\r\n{\r\nif (PXSEG(vaddr) == P2SEG)\r\nreturn;\r\nswitch (direction) {\r\ncase DMA_FROM_DEVICE:\r\ninvalidate_dcache_region(vaddr, size);\r\nbreak;\r\ncase DMA_TO_DEVICE:\r\nclean_dcache_region(vaddr, size);\r\nbreak;\r\ncase DMA_BIDIRECTIONAL:\r\nflush_dcache_region(vaddr, size);\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\n}\r\nstatic struct page *__dma_alloc(struct device *dev, size_t size,\r\ndma_addr_t *handle, gfp_t gfp)\r\n{\r\nstruct page *page, *free, *end;\r\nint order;\r\ngfp &= ~(__GFP_COMP);\r\nsize = PAGE_ALIGN(size);\r\norder = get_order(size);\r\npage = alloc_pages(gfp, order);\r\nif (!page)\r\nreturn NULL;\r\nsplit_page(page, order);\r\ninvalidate_dcache_region(phys_to_virt(page_to_phys(page)), size);\r\n*handle = page_to_bus(page);\r\nfree = page + (size >> PAGE_SHIFT);\r\nend = page + (1 << order);\r\nwhile (free < end) {\r\n__free_page(free);\r\nfree++;\r\n}\r\nreturn page;\r\n}\r\nstatic void __dma_free(struct device *dev, size_t size,\r\nstruct page *page, dma_addr_t handle)\r\n{\r\nstruct page *end = page + (PAGE_ALIGN(size) >> PAGE_SHIFT);\r\nwhile (page < end)\r\n__free_page(page++);\r\n}\r\nvoid *dma_alloc_coherent(struct device *dev, size_t size,\r\ndma_addr_t *handle, gfp_t gfp)\r\n{\r\nstruct page *page;\r\nvoid *ret = NULL;\r\npage = __dma_alloc(dev, size, handle, gfp);\r\nif (page)\r\nret = phys_to_uncached(page_to_phys(page));\r\nreturn ret;\r\n}\r\nvoid dma_free_coherent(struct device *dev, size_t size,\r\nvoid *cpu_addr, dma_addr_t handle)\r\n{\r\nvoid *addr = phys_to_cached(uncached_to_phys(cpu_addr));\r\nstruct page *page;\r\npr_debug("dma_free_coherent addr %p (phys %08lx) size %u\n",\r\ncpu_addr, (unsigned long)handle, (unsigned)size);\r\nBUG_ON(!virt_addr_valid(addr));\r\npage = virt_to_page(addr);\r\n__dma_free(dev, size, page, handle);\r\n}\r\nvoid *dma_alloc_writecombine(struct device *dev, size_t size,\r\ndma_addr_t *handle, gfp_t gfp)\r\n{\r\nstruct page *page;\r\ndma_addr_t phys;\r\npage = __dma_alloc(dev, size, handle, gfp);\r\nif (!page)\r\nreturn NULL;\r\nphys = page_to_phys(page);\r\n*handle = phys;\r\nreturn __ioremap(phys, size, _PAGE_BUFFER);\r\n}\r\nvoid dma_free_writecombine(struct device *dev, size_t size,\r\nvoid *cpu_addr, dma_addr_t handle)\r\n{\r\nstruct page *page;\r\niounmap(cpu_addr);\r\npage = phys_to_page(handle);\r\n__dma_free(dev, size, page, handle);\r\n}
