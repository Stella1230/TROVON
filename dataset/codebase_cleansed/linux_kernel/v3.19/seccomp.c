static void populate_seccomp_data(struct seccomp_data *sd)\r\n{\r\nstruct task_struct *task = current;\r\nstruct pt_regs *regs = task_pt_regs(task);\r\nunsigned long args[6];\r\nsd->nr = syscall_get_nr(task, regs);\r\nsd->arch = syscall_get_arch();\r\nsyscall_get_arguments(task, regs, 0, 6, args);\r\nsd->args[0] = args[0];\r\nsd->args[1] = args[1];\r\nsd->args[2] = args[2];\r\nsd->args[3] = args[3];\r\nsd->args[4] = args[4];\r\nsd->args[5] = args[5];\r\nsd->instruction_pointer = KSTK_EIP(task);\r\n}\r\nstatic int seccomp_check_filter(struct sock_filter *filter, unsigned int flen)\r\n{\r\nint pc;\r\nfor (pc = 0; pc < flen; pc++) {\r\nstruct sock_filter *ftest = &filter[pc];\r\nu16 code = ftest->code;\r\nu32 k = ftest->k;\r\nswitch (code) {\r\ncase BPF_LD | BPF_W | BPF_ABS:\r\nftest->code = BPF_LDX | BPF_W | BPF_ABS;\r\nif (k >= sizeof(struct seccomp_data) || k & 3)\r\nreturn -EINVAL;\r\ncontinue;\r\ncase BPF_LD | BPF_W | BPF_LEN:\r\nftest->code = BPF_LD | BPF_IMM;\r\nftest->k = sizeof(struct seccomp_data);\r\ncontinue;\r\ncase BPF_LDX | BPF_W | BPF_LEN:\r\nftest->code = BPF_LDX | BPF_IMM;\r\nftest->k = sizeof(struct seccomp_data);\r\ncontinue;\r\ncase BPF_RET | BPF_K:\r\ncase BPF_RET | BPF_A:\r\ncase BPF_ALU | BPF_ADD | BPF_K:\r\ncase BPF_ALU | BPF_ADD | BPF_X:\r\ncase BPF_ALU | BPF_SUB | BPF_K:\r\ncase BPF_ALU | BPF_SUB | BPF_X:\r\ncase BPF_ALU | BPF_MUL | BPF_K:\r\ncase BPF_ALU | BPF_MUL | BPF_X:\r\ncase BPF_ALU | BPF_DIV | BPF_K:\r\ncase BPF_ALU | BPF_DIV | BPF_X:\r\ncase BPF_ALU | BPF_AND | BPF_K:\r\ncase BPF_ALU | BPF_AND | BPF_X:\r\ncase BPF_ALU | BPF_OR | BPF_K:\r\ncase BPF_ALU | BPF_OR | BPF_X:\r\ncase BPF_ALU | BPF_XOR | BPF_K:\r\ncase BPF_ALU | BPF_XOR | BPF_X:\r\ncase BPF_ALU | BPF_LSH | BPF_K:\r\ncase BPF_ALU | BPF_LSH | BPF_X:\r\ncase BPF_ALU | BPF_RSH | BPF_K:\r\ncase BPF_ALU | BPF_RSH | BPF_X:\r\ncase BPF_ALU | BPF_NEG:\r\ncase BPF_LD | BPF_IMM:\r\ncase BPF_LDX | BPF_IMM:\r\ncase BPF_MISC | BPF_TAX:\r\ncase BPF_MISC | BPF_TXA:\r\ncase BPF_LD | BPF_MEM:\r\ncase BPF_LDX | BPF_MEM:\r\ncase BPF_ST:\r\ncase BPF_STX:\r\ncase BPF_JMP | BPF_JA:\r\ncase BPF_JMP | BPF_JEQ | BPF_K:\r\ncase BPF_JMP | BPF_JEQ | BPF_X:\r\ncase BPF_JMP | BPF_JGE | BPF_K:\r\ncase BPF_JMP | BPF_JGE | BPF_X:\r\ncase BPF_JMP | BPF_JGT | BPF_K:\r\ncase BPF_JMP | BPF_JGT | BPF_X:\r\ncase BPF_JMP | BPF_JSET | BPF_K:\r\ncase BPF_JMP | BPF_JSET | BPF_X:\r\ncontinue;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic u32 seccomp_run_filters(struct seccomp_data *sd)\r\n{\r\nstruct seccomp_filter *f = ACCESS_ONCE(current->seccomp.filter);\r\nstruct seccomp_data sd_local;\r\nu32 ret = SECCOMP_RET_ALLOW;\r\nif (unlikely(WARN_ON(f == NULL)))\r\nreturn SECCOMP_RET_KILL;\r\nsmp_read_barrier_depends();\r\nif (!sd) {\r\npopulate_seccomp_data(&sd_local);\r\nsd = &sd_local;\r\n}\r\nfor (; f; f = f->prev) {\r\nu32 cur_ret = BPF_PROG_RUN(f->prog, (void *)sd);\r\nif ((cur_ret & SECCOMP_RET_ACTION) < (ret & SECCOMP_RET_ACTION))\r\nret = cur_ret;\r\n}\r\nreturn ret;\r\n}\r\nstatic inline bool seccomp_may_assign_mode(unsigned long seccomp_mode)\r\n{\r\nassert_spin_locked(&current->sighand->siglock);\r\nif (current->seccomp.mode && current->seccomp.mode != seccomp_mode)\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic inline void seccomp_assign_mode(struct task_struct *task,\r\nunsigned long seccomp_mode)\r\n{\r\nassert_spin_locked(&task->sighand->siglock);\r\ntask->seccomp.mode = seccomp_mode;\r\nsmp_mb__before_atomic();\r\nset_tsk_thread_flag(task, TIF_SECCOMP);\r\n}\r\nstatic int is_ancestor(struct seccomp_filter *parent,\r\nstruct seccomp_filter *child)\r\n{\r\nif (parent == NULL)\r\nreturn 1;\r\nfor (; child; child = child->prev)\r\nif (child == parent)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic inline pid_t seccomp_can_sync_threads(void)\r\n{\r\nstruct task_struct *thread, *caller;\r\nBUG_ON(!mutex_is_locked(&current->signal->cred_guard_mutex));\r\nassert_spin_locked(&current->sighand->siglock);\r\ncaller = current;\r\nfor_each_thread(caller, thread) {\r\npid_t failed;\r\nif (thread == caller)\r\ncontinue;\r\nif (thread->seccomp.mode == SECCOMP_MODE_DISABLED ||\r\n(thread->seccomp.mode == SECCOMP_MODE_FILTER &&\r\nis_ancestor(thread->seccomp.filter,\r\ncaller->seccomp.filter)))\r\ncontinue;\r\nfailed = task_pid_vnr(thread);\r\nif (unlikely(WARN_ON(failed == 0)))\r\nfailed = -ESRCH;\r\nreturn failed;\r\n}\r\nreturn 0;\r\n}\r\nstatic inline void seccomp_sync_threads(void)\r\n{\r\nstruct task_struct *thread, *caller;\r\nBUG_ON(!mutex_is_locked(&current->signal->cred_guard_mutex));\r\nassert_spin_locked(&current->sighand->siglock);\r\ncaller = current;\r\nfor_each_thread(caller, thread) {\r\nif (thread == caller)\r\ncontinue;\r\nget_seccomp_filter(caller);\r\nput_seccomp_filter(thread);\r\nsmp_store_release(&thread->seccomp.filter,\r\ncaller->seccomp.filter);\r\nif (thread->seccomp.mode == SECCOMP_MODE_DISABLED) {\r\nif (task_no_new_privs(caller))\r\ntask_set_no_new_privs(thread);\r\nseccomp_assign_mode(thread, SECCOMP_MODE_FILTER);\r\n}\r\n}\r\n}\r\nstatic struct seccomp_filter *seccomp_prepare_filter(struct sock_fprog *fprog)\r\n{\r\nstruct seccomp_filter *filter;\r\nunsigned long fp_size;\r\nstruct sock_filter *fp;\r\nint new_len;\r\nlong ret;\r\nif (fprog->len == 0 || fprog->len > BPF_MAXINSNS)\r\nreturn ERR_PTR(-EINVAL);\r\nBUG_ON(INT_MAX / fprog->len < sizeof(struct sock_filter));\r\nfp_size = fprog->len * sizeof(struct sock_filter);\r\nif (!task_no_new_privs(current) &&\r\nsecurity_capable_noaudit(current_cred(), current_user_ns(),\r\nCAP_SYS_ADMIN) != 0)\r\nreturn ERR_PTR(-EACCES);\r\nfp = kzalloc(fp_size, GFP_KERNEL|__GFP_NOWARN);\r\nif (!fp)\r\nreturn ERR_PTR(-ENOMEM);\r\nret = -EFAULT;\r\nif (copy_from_user(fp, fprog->filter, fp_size))\r\ngoto free_prog;\r\nret = bpf_check_classic(fp, fprog->len);\r\nif (ret)\r\ngoto free_prog;\r\nret = seccomp_check_filter(fp, fprog->len);\r\nif (ret)\r\ngoto free_prog;\r\nret = bpf_convert_filter(fp, fprog->len, NULL, &new_len);\r\nif (ret)\r\ngoto free_prog;\r\nret = -ENOMEM;\r\nfilter = kzalloc(sizeof(struct seccomp_filter),\r\nGFP_KERNEL|__GFP_NOWARN);\r\nif (!filter)\r\ngoto free_prog;\r\nfilter->prog = bpf_prog_alloc(bpf_prog_size(new_len), __GFP_NOWARN);\r\nif (!filter->prog)\r\ngoto free_filter;\r\nret = bpf_convert_filter(fp, fprog->len, filter->prog->insnsi, &new_len);\r\nif (ret)\r\ngoto free_filter_prog;\r\nkfree(fp);\r\natomic_set(&filter->usage, 1);\r\nfilter->prog->len = new_len;\r\nbpf_prog_select_runtime(filter->prog);\r\nreturn filter;\r\nfree_filter_prog:\r\n__bpf_prog_free(filter->prog);\r\nfree_filter:\r\nkfree(filter);\r\nfree_prog:\r\nkfree(fp);\r\nreturn ERR_PTR(ret);\r\n}\r\nstatic struct seccomp_filter *\r\nseccomp_prepare_user_filter(const char __user *user_filter)\r\n{\r\nstruct sock_fprog fprog;\r\nstruct seccomp_filter *filter = ERR_PTR(-EFAULT);\r\n#ifdef CONFIG_COMPAT\r\nif (is_compat_task()) {\r\nstruct compat_sock_fprog fprog32;\r\nif (copy_from_user(&fprog32, user_filter, sizeof(fprog32)))\r\ngoto out;\r\nfprog.len = fprog32.len;\r\nfprog.filter = compat_ptr(fprog32.filter);\r\n} else\r\n#endif\r\nif (copy_from_user(&fprog, user_filter, sizeof(fprog)))\r\ngoto out;\r\nfilter = seccomp_prepare_filter(&fprog);\r\nout:\r\nreturn filter;\r\n}\r\nstatic long seccomp_attach_filter(unsigned int flags,\r\nstruct seccomp_filter *filter)\r\n{\r\nunsigned long total_insns;\r\nstruct seccomp_filter *walker;\r\nassert_spin_locked(&current->sighand->siglock);\r\ntotal_insns = filter->prog->len;\r\nfor (walker = current->seccomp.filter; walker; walker = walker->prev)\r\ntotal_insns += walker->prog->len + 4;\r\nif (total_insns > MAX_INSNS_PER_PATH)\r\nreturn -ENOMEM;\r\nif (flags & SECCOMP_FILTER_FLAG_TSYNC) {\r\nint ret;\r\nret = seccomp_can_sync_threads();\r\nif (ret)\r\nreturn ret;\r\n}\r\nfilter->prev = current->seccomp.filter;\r\ncurrent->seccomp.filter = filter;\r\nif (flags & SECCOMP_FILTER_FLAG_TSYNC)\r\nseccomp_sync_threads();\r\nreturn 0;\r\n}\r\nvoid get_seccomp_filter(struct task_struct *tsk)\r\n{\r\nstruct seccomp_filter *orig = tsk->seccomp.filter;\r\nif (!orig)\r\nreturn;\r\natomic_inc(&orig->usage);\r\n}\r\nstatic inline void seccomp_filter_free(struct seccomp_filter *filter)\r\n{\r\nif (filter) {\r\nbpf_prog_free(filter->prog);\r\nkfree(filter);\r\n}\r\n}\r\nvoid put_seccomp_filter(struct task_struct *tsk)\r\n{\r\nstruct seccomp_filter *orig = tsk->seccomp.filter;\r\nwhile (orig && atomic_dec_and_test(&orig->usage)) {\r\nstruct seccomp_filter *freeme = orig;\r\norig = orig->prev;\r\nseccomp_filter_free(freeme);\r\n}\r\n}\r\nstatic void seccomp_send_sigsys(int syscall, int reason)\r\n{\r\nstruct siginfo info;\r\nmemset(&info, 0, sizeof(info));\r\ninfo.si_signo = SIGSYS;\r\ninfo.si_code = SYS_SECCOMP;\r\ninfo.si_call_addr = (void __user *)KSTK_EIP(current);\r\ninfo.si_errno = reason;\r\ninfo.si_arch = syscall_get_arch();\r\ninfo.si_syscall = syscall;\r\nforce_sig_info(SIGSYS, &info, current);\r\n}\r\nstatic void __secure_computing_strict(int this_syscall)\r\n{\r\nint *syscall_whitelist = mode1_syscalls;\r\n#ifdef CONFIG_COMPAT\r\nif (is_compat_task())\r\nsyscall_whitelist = mode1_syscalls_32;\r\n#endif\r\ndo {\r\nif (*syscall_whitelist == this_syscall)\r\nreturn;\r\n} while (*++syscall_whitelist);\r\n#ifdef SECCOMP_DEBUG\r\ndump_stack();\r\n#endif\r\naudit_seccomp(this_syscall, SIGKILL, SECCOMP_RET_KILL);\r\ndo_exit(SIGKILL);\r\n}\r\nvoid secure_computing_strict(int this_syscall)\r\n{\r\nint mode = current->seccomp.mode;\r\nif (mode == 0)\r\nreturn;\r\nelse if (mode == SECCOMP_MODE_STRICT)\r\n__secure_computing_strict(this_syscall);\r\nelse\r\nBUG();\r\n}\r\nint __secure_computing(void)\r\n{\r\nu32 phase1_result = seccomp_phase1(NULL);\r\nif (likely(phase1_result == SECCOMP_PHASE1_OK))\r\nreturn 0;\r\nelse if (likely(phase1_result == SECCOMP_PHASE1_SKIP))\r\nreturn -1;\r\nelse\r\nreturn seccomp_phase2(phase1_result);\r\n}\r\nstatic u32 __seccomp_phase1_filter(int this_syscall, struct seccomp_data *sd)\r\n{\r\nu32 filter_ret, action;\r\nint data;\r\nrmb();\r\nfilter_ret = seccomp_run_filters(sd);\r\ndata = filter_ret & SECCOMP_RET_DATA;\r\naction = filter_ret & SECCOMP_RET_ACTION;\r\nswitch (action) {\r\ncase SECCOMP_RET_ERRNO:\r\nsyscall_set_return_value(current, task_pt_regs(current),\r\n-data, 0);\r\ngoto skip;\r\ncase SECCOMP_RET_TRAP:\r\nsyscall_rollback(current, task_pt_regs(current));\r\nseccomp_send_sigsys(this_syscall, data);\r\ngoto skip;\r\ncase SECCOMP_RET_TRACE:\r\nreturn filter_ret;\r\ncase SECCOMP_RET_ALLOW:\r\nreturn SECCOMP_PHASE1_OK;\r\ncase SECCOMP_RET_KILL:\r\ndefault:\r\naudit_seccomp(this_syscall, SIGSYS, action);\r\ndo_exit(SIGSYS);\r\n}\r\nunreachable();\r\nskip:\r\naudit_seccomp(this_syscall, 0, action);\r\nreturn SECCOMP_PHASE1_SKIP;\r\n}\r\nu32 seccomp_phase1(struct seccomp_data *sd)\r\n{\r\nint mode = current->seccomp.mode;\r\nint this_syscall = sd ? sd->nr :\r\nsyscall_get_nr(current, task_pt_regs(current));\r\nswitch (mode) {\r\ncase SECCOMP_MODE_STRICT:\r\n__secure_computing_strict(this_syscall);\r\nreturn SECCOMP_PHASE1_OK;\r\n#ifdef CONFIG_SECCOMP_FILTER\r\ncase SECCOMP_MODE_FILTER:\r\nreturn __seccomp_phase1_filter(this_syscall, sd);\r\n#endif\r\ndefault:\r\nBUG();\r\n}\r\n}\r\nint seccomp_phase2(u32 phase1_result)\r\n{\r\nstruct pt_regs *regs = task_pt_regs(current);\r\nu32 action = phase1_result & SECCOMP_RET_ACTION;\r\nint data = phase1_result & SECCOMP_RET_DATA;\r\nBUG_ON(action != SECCOMP_RET_TRACE);\r\naudit_seccomp(syscall_get_nr(current, regs), 0, action);\r\nif (!ptrace_event_enabled(current, PTRACE_EVENT_SECCOMP)) {\r\nsyscall_set_return_value(current, regs,\r\n-ENOSYS, 0);\r\nreturn -1;\r\n}\r\nptrace_event(PTRACE_EVENT_SECCOMP, data);\r\nif (fatal_signal_pending(current))\r\ndo_exit(SIGSYS);\r\nif (syscall_get_nr(current, regs) < 0)\r\nreturn -1;\r\nreturn 0;\r\n}\r\nlong prctl_get_seccomp(void)\r\n{\r\nreturn current->seccomp.mode;\r\n}\r\nstatic long seccomp_set_mode_strict(void)\r\n{\r\nconst unsigned long seccomp_mode = SECCOMP_MODE_STRICT;\r\nlong ret = -EINVAL;\r\nspin_lock_irq(&current->sighand->siglock);\r\nif (!seccomp_may_assign_mode(seccomp_mode))\r\ngoto out;\r\n#ifdef TIF_NOTSC\r\ndisable_TSC();\r\n#endif\r\nseccomp_assign_mode(current, seccomp_mode);\r\nret = 0;\r\nout:\r\nspin_unlock_irq(&current->sighand->siglock);\r\nreturn ret;\r\n}\r\nstatic long seccomp_set_mode_filter(unsigned int flags,\r\nconst char __user *filter)\r\n{\r\nconst unsigned long seccomp_mode = SECCOMP_MODE_FILTER;\r\nstruct seccomp_filter *prepared = NULL;\r\nlong ret = -EINVAL;\r\nif (flags & ~SECCOMP_FILTER_FLAG_MASK)\r\nreturn -EINVAL;\r\nprepared = seccomp_prepare_user_filter(filter);\r\nif (IS_ERR(prepared))\r\nreturn PTR_ERR(prepared);\r\nif (flags & SECCOMP_FILTER_FLAG_TSYNC &&\r\nmutex_lock_killable(&current->signal->cred_guard_mutex))\r\ngoto out_free;\r\nspin_lock_irq(&current->sighand->siglock);\r\nif (!seccomp_may_assign_mode(seccomp_mode))\r\ngoto out;\r\nret = seccomp_attach_filter(flags, prepared);\r\nif (ret)\r\ngoto out;\r\nprepared = NULL;\r\nseccomp_assign_mode(current, seccomp_mode);\r\nout:\r\nspin_unlock_irq(&current->sighand->siglock);\r\nif (flags & SECCOMP_FILTER_FLAG_TSYNC)\r\nmutex_unlock(&current->signal->cred_guard_mutex);\r\nout_free:\r\nseccomp_filter_free(prepared);\r\nreturn ret;\r\n}\r\nstatic inline long seccomp_set_mode_filter(unsigned int flags,\r\nconst char __user *filter)\r\n{\r\nreturn -EINVAL;\r\n}\r\nstatic long do_seccomp(unsigned int op, unsigned int flags,\r\nconst char __user *uargs)\r\n{\r\nswitch (op) {\r\ncase SECCOMP_SET_MODE_STRICT:\r\nif (flags != 0 || uargs != NULL)\r\nreturn -EINVAL;\r\nreturn seccomp_set_mode_strict();\r\ncase SECCOMP_SET_MODE_FILTER:\r\nreturn seccomp_set_mode_filter(flags, uargs);\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n}\r\nlong prctl_set_seccomp(unsigned long seccomp_mode, char __user *filter)\r\n{\r\nunsigned int op;\r\nchar __user *uargs;\r\nswitch (seccomp_mode) {\r\ncase SECCOMP_MODE_STRICT:\r\nop = SECCOMP_SET_MODE_STRICT;\r\nuargs = NULL;\r\nbreak;\r\ncase SECCOMP_MODE_FILTER:\r\nop = SECCOMP_SET_MODE_FILTER;\r\nuargs = filter;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn do_seccomp(op, 0, uargs);\r\n}
