static void nhmex_uncore_msr_init_box(struct intel_uncore_box *box)\r\n{\r\nwrmsrl(NHMEX_U_MSR_PMON_GLOBAL_CTL, NHMEX_U_PMON_GLOBAL_EN_ALL);\r\n}\r\nstatic void nhmex_uncore_msr_disable_box(struct intel_uncore_box *box)\r\n{\r\nunsigned msr = uncore_msr_box_ctl(box);\r\nu64 config;\r\nif (msr) {\r\nrdmsrl(msr, config);\r\nconfig &= ~((1ULL << uncore_num_counters(box)) - 1);\r\nif (uncore_msr_fixed_ctl(box))\r\nconfig &= ~NHMEX_W_PMON_GLOBAL_FIXED_EN;\r\nwrmsrl(msr, config);\r\n}\r\n}\r\nstatic void nhmex_uncore_msr_enable_box(struct intel_uncore_box *box)\r\n{\r\nunsigned msr = uncore_msr_box_ctl(box);\r\nu64 config;\r\nif (msr) {\r\nrdmsrl(msr, config);\r\nconfig |= (1ULL << uncore_num_counters(box)) - 1;\r\nif (uncore_msr_fixed_ctl(box))\r\nconfig |= NHMEX_W_PMON_GLOBAL_FIXED_EN;\r\nwrmsrl(msr, config);\r\n}\r\n}\r\nstatic void nhmex_uncore_msr_disable_event(struct intel_uncore_box *box, struct perf_event *event)\r\n{\r\nwrmsrl(event->hw.config_base, 0);\r\n}\r\nstatic void nhmex_uncore_msr_enable_event(struct intel_uncore_box *box, struct perf_event *event)\r\n{\r\nstruct hw_perf_event *hwc = &event->hw;\r\nif (hwc->idx >= UNCORE_PMC_IDX_FIXED)\r\nwrmsrl(hwc->config_base, NHMEX_PMON_CTL_EN_BIT0);\r\nelse if (box->pmu->type->event_mask & NHMEX_PMON_CTL_EN_BIT0)\r\nwrmsrl(hwc->config_base, hwc->config | NHMEX_PMON_CTL_EN_BIT22);\r\nelse\r\nwrmsrl(hwc->config_base, hwc->config | NHMEX_PMON_CTL_EN_BIT0);\r\n}\r\nstatic int nhmex_bbox_hw_config(struct intel_uncore_box *box, struct perf_event *event)\r\n{\r\nstruct hw_perf_event *hwc = &event->hw;\r\nstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\r\nstruct hw_perf_event_extra *reg2 = &hwc->branch_reg;\r\nint ctr, ev_sel;\r\nctr = (hwc->config & NHMEX_B_PMON_CTR_MASK) >>\r\nNHMEX_B_PMON_CTR_SHIFT;\r\nev_sel = (hwc->config & NHMEX_B_PMON_CTL_EV_SEL_MASK) >>\r\nNHMEX_B_PMON_CTL_EV_SEL_SHIFT;\r\nif ((ctr == 0 && ev_sel > 0x3) || (ctr == 1 && ev_sel > 0x6) ||\r\n(ctr == 2 && ev_sel != 0x4) || ctr == 3)\r\nreturn 0;\r\nif (box->pmu->pmu_idx == 0)\r\nreg1->reg = NHMEX_B0_MSR_MATCH;\r\nelse\r\nreg1->reg = NHMEX_B1_MSR_MATCH;\r\nreg1->idx = 0;\r\nreg1->config = event->attr.config1;\r\nreg2->config = event->attr.config2;\r\nreturn 0;\r\n}\r\nstatic void nhmex_bbox_msr_enable_event(struct intel_uncore_box *box, struct perf_event *event)\r\n{\r\nstruct hw_perf_event *hwc = &event->hw;\r\nstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\r\nstruct hw_perf_event_extra *reg2 = &hwc->branch_reg;\r\nif (reg1->idx != EXTRA_REG_NONE) {\r\nwrmsrl(reg1->reg, reg1->config);\r\nwrmsrl(reg1->reg + 1, reg2->config);\r\n}\r\nwrmsrl(hwc->config_base, NHMEX_PMON_CTL_EN_BIT0 |\r\n(hwc->config & NHMEX_B_PMON_CTL_EV_SEL_MASK));\r\n}\r\nstatic int nhmex_sbox_hw_config(struct intel_uncore_box *box, struct perf_event *event)\r\n{\r\nstruct hw_perf_event *hwc = &event->hw;\r\nstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\r\nstruct hw_perf_event_extra *reg2 = &hwc->branch_reg;\r\nif ((hwc->config & NHMEX_PMON_CTL_EV_SEL_MASK) !=\r\nNHMEX_S_EVENT_TO_R_PROG_EV)\r\nreturn 0;\r\nif (box->pmu->pmu_idx == 0)\r\nreg1->reg = NHMEX_S0_MSR_MM_CFG;\r\nelse\r\nreg1->reg = NHMEX_S1_MSR_MM_CFG;\r\nreg1->idx = 0;\r\nreg1->config = event->attr.config1;\r\nreg2->config = event->attr.config2;\r\nreturn 0;\r\n}\r\nstatic void nhmex_sbox_msr_enable_event(struct intel_uncore_box *box, struct perf_event *event)\r\n{\r\nstruct hw_perf_event *hwc = &event->hw;\r\nstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\r\nstruct hw_perf_event_extra *reg2 = &hwc->branch_reg;\r\nif (reg1->idx != EXTRA_REG_NONE) {\r\nwrmsrl(reg1->reg, 0);\r\nwrmsrl(reg1->reg + 1, reg1->config);\r\nwrmsrl(reg1->reg + 2, reg2->config);\r\nwrmsrl(reg1->reg, NHMEX_S_PMON_MM_CFG_EN);\r\n}\r\nwrmsrl(hwc->config_base, hwc->config | NHMEX_PMON_CTL_EN_BIT22);\r\n}\r\nstatic bool nhmex_mbox_get_shared_reg(struct intel_uncore_box *box, int idx, u64 config)\r\n{\r\nstruct intel_uncore_extra_reg *er;\r\nunsigned long flags;\r\nbool ret = false;\r\nu64 mask;\r\nif (idx < EXTRA_REG_NHMEX_M_ZDP_CTL_FVC) {\r\ner = &box->shared_regs[idx];\r\nraw_spin_lock_irqsave(&er->lock, flags);\r\nif (!atomic_read(&er->ref) || er->config == config) {\r\natomic_inc(&er->ref);\r\ner->config = config;\r\nret = true;\r\n}\r\nraw_spin_unlock_irqrestore(&er->lock, flags);\r\nreturn ret;\r\n}\r\nidx -= EXTRA_REG_NHMEX_M_ZDP_CTL_FVC;\r\nif (WARN_ON_ONCE(idx >= 4))\r\nreturn false;\r\nif (uncore_nhmex)\r\nmask = NHMEX_M_PMON_ZDP_CTL_FVC_MASK;\r\nelse\r\nmask = WSMEX_M_PMON_ZDP_CTL_FVC_MASK;\r\ner = &box->shared_regs[EXTRA_REG_NHMEX_M_ZDP_CTL_FVC];\r\nraw_spin_lock_irqsave(&er->lock, flags);\r\nif (__BITS_VALUE(atomic_read(&er->ref), idx, 8)) {\r\nif (uncore_nhmex)\r\nmask |= NHMEX_M_PMON_ZDP_CTL_FVC_EVENT_MASK(idx);\r\nelse\r\nmask |= WSMEX_M_PMON_ZDP_CTL_FVC_EVENT_MASK(idx);\r\n}\r\nif (!atomic_read(&er->ref) || !((er->config ^ config) & mask)) {\r\natomic_add(1 << (idx * 8), &er->ref);\r\nif (uncore_nhmex)\r\nmask = NHMEX_M_PMON_ZDP_CTL_FVC_MASK |\r\nNHMEX_M_PMON_ZDP_CTL_FVC_EVENT_MASK(idx);\r\nelse\r\nmask = WSMEX_M_PMON_ZDP_CTL_FVC_MASK |\r\nWSMEX_M_PMON_ZDP_CTL_FVC_EVENT_MASK(idx);\r\ner->config &= ~mask;\r\ner->config |= (config & mask);\r\nret = true;\r\n}\r\nraw_spin_unlock_irqrestore(&er->lock, flags);\r\nreturn ret;\r\n}\r\nstatic void nhmex_mbox_put_shared_reg(struct intel_uncore_box *box, int idx)\r\n{\r\nstruct intel_uncore_extra_reg *er;\r\nif (idx < EXTRA_REG_NHMEX_M_ZDP_CTL_FVC) {\r\ner = &box->shared_regs[idx];\r\natomic_dec(&er->ref);\r\nreturn;\r\n}\r\nidx -= EXTRA_REG_NHMEX_M_ZDP_CTL_FVC;\r\ner = &box->shared_regs[EXTRA_REG_NHMEX_M_ZDP_CTL_FVC];\r\natomic_sub(1 << (idx * 8), &er->ref);\r\n}\r\nstatic u64 nhmex_mbox_alter_er(struct perf_event *event, int new_idx, bool modify)\r\n{\r\nstruct hw_perf_event *hwc = &event->hw;\r\nstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\r\nu64 idx, orig_idx = __BITS_VALUE(reg1->idx, 0, 8);\r\nu64 config = reg1->config;\r\nidx = orig_idx - EXTRA_REG_NHMEX_M_ZDP_CTL_FVC;\r\nif (uncore_nhmex)\r\nconfig &= NHMEX_M_PMON_ZDP_CTL_FVC_EVENT_MASK(idx);\r\nelse\r\nconfig &= WSMEX_M_PMON_ZDP_CTL_FVC_EVENT_MASK(idx);\r\nif (new_idx > orig_idx) {\r\nidx = new_idx - orig_idx;\r\nconfig <<= 3 * idx;\r\n} else {\r\nidx = orig_idx - new_idx;\r\nconfig >>= 3 * idx;\r\n}\r\nif (uncore_nhmex)\r\nconfig |= NHMEX_M_PMON_ZDP_CTL_FVC_MASK & reg1->config;\r\nelse\r\nconfig |= WSMEX_M_PMON_ZDP_CTL_FVC_MASK & reg1->config;\r\nconfig |= NHMEX_M_PMON_ZDP_CTL_FVC_MASK & reg1->config;\r\nif (modify) {\r\nif (new_idx > orig_idx)\r\nhwc->config += idx << NHMEX_M_PMON_CTL_INC_SEL_SHIFT;\r\nelse\r\nhwc->config -= idx << NHMEX_M_PMON_CTL_INC_SEL_SHIFT;\r\nreg1->config = config;\r\nreg1->idx = ~0xff | new_idx;\r\n}\r\nreturn config;\r\n}\r\nstatic struct event_constraint *\r\nnhmex_mbox_get_constraint(struct intel_uncore_box *box, struct perf_event *event)\r\n{\r\nstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\r\nstruct hw_perf_event_extra *reg2 = &event->hw.branch_reg;\r\nint i, idx[2], alloc = 0;\r\nu64 config1 = reg1->config;\r\nidx[0] = __BITS_VALUE(reg1->idx, 0, 8);\r\nidx[1] = __BITS_VALUE(reg1->idx, 1, 8);\r\nagain:\r\nfor (i = 0; i < 2; i++) {\r\nif (!uncore_box_is_fake(box) && (reg1->alloc & (0x1 << i)))\r\nidx[i] = 0xff;\r\nif (idx[i] == 0xff)\r\ncontinue;\r\nif (!nhmex_mbox_get_shared_reg(box, idx[i],\r\n__BITS_VALUE(config1, i, 32)))\r\ngoto fail;\r\nalloc |= (0x1 << i);\r\n}\r\nif (reg2->idx != EXTRA_REG_NONE &&\r\n(uncore_box_is_fake(box) || !reg2->alloc) &&\r\n!nhmex_mbox_get_shared_reg(box, reg2->idx, reg2->config))\r\ngoto fail;\r\nif (!uncore_box_is_fake(box)) {\r\nif (idx[0] != 0xff && idx[0] != __BITS_VALUE(reg1->idx, 0, 8))\r\nnhmex_mbox_alter_er(event, idx[0], true);\r\nreg1->alloc |= alloc;\r\nif (reg2->idx != EXTRA_REG_NONE)\r\nreg2->alloc = 1;\r\n}\r\nreturn NULL;\r\nfail:\r\nif (idx[0] != 0xff && !(alloc & 0x1) &&\r\nidx[0] >= EXTRA_REG_NHMEX_M_ZDP_CTL_FVC) {\r\nBUG_ON(__BITS_VALUE(reg1->idx, 1, 8) != 0xff);\r\nidx[0] -= EXTRA_REG_NHMEX_M_ZDP_CTL_FVC;\r\nidx[0] = (idx[0] + 1) % 4;\r\nidx[0] += EXTRA_REG_NHMEX_M_ZDP_CTL_FVC;\r\nif (idx[0] != __BITS_VALUE(reg1->idx, 0, 8)) {\r\nconfig1 = nhmex_mbox_alter_er(event, idx[0], false);\r\ngoto again;\r\n}\r\n}\r\nif (alloc & 0x1)\r\nnhmex_mbox_put_shared_reg(box, idx[0]);\r\nif (alloc & 0x2)\r\nnhmex_mbox_put_shared_reg(box, idx[1]);\r\nreturn &uncore_constraint_empty;\r\n}\r\nstatic void nhmex_mbox_put_constraint(struct intel_uncore_box *box, struct perf_event *event)\r\n{\r\nstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\r\nstruct hw_perf_event_extra *reg2 = &event->hw.branch_reg;\r\nif (uncore_box_is_fake(box))\r\nreturn;\r\nif (reg1->alloc & 0x1)\r\nnhmex_mbox_put_shared_reg(box, __BITS_VALUE(reg1->idx, 0, 8));\r\nif (reg1->alloc & 0x2)\r\nnhmex_mbox_put_shared_reg(box, __BITS_VALUE(reg1->idx, 1, 8));\r\nreg1->alloc = 0;\r\nif (reg2->alloc) {\r\nnhmex_mbox_put_shared_reg(box, reg2->idx);\r\nreg2->alloc = 0;\r\n}\r\n}\r\nstatic int nhmex_mbox_extra_reg_idx(struct extra_reg *er)\r\n{\r\nif (er->idx < EXTRA_REG_NHMEX_M_ZDP_CTL_FVC)\r\nreturn er->idx;\r\nreturn er->idx + (er->event >> NHMEX_M_PMON_CTL_INC_SEL_SHIFT) - 0xd;\r\n}\r\nstatic int nhmex_mbox_hw_config(struct intel_uncore_box *box, struct perf_event *event)\r\n{\r\nstruct intel_uncore_type *type = box->pmu->type;\r\nstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\r\nstruct hw_perf_event_extra *reg2 = &event->hw.branch_reg;\r\nstruct extra_reg *er;\r\nunsigned msr;\r\nint reg_idx = 0;\r\nfor (er = nhmex_uncore_mbox_extra_regs; er->msr; er++) {\r\nif (er->event != (event->hw.config & er->config_mask))\r\ncontinue;\r\nif (event->attr.config1 & ~er->valid_mask)\r\nreturn -EINVAL;\r\nmsr = er->msr + type->msr_offset * box->pmu->pmu_idx;\r\nif (WARN_ON_ONCE(msr >= 0xffff || er->idx >= 0xff))\r\nreturn -EINVAL;\r\nif (er->idx == EXTRA_REG_NHMEX_M_PLD)\r\nreg_idx = 1;\r\nelse if (WARN_ON_ONCE(reg_idx > 0))\r\nreturn -EINVAL;\r\nreg1->idx &= ~(0xff << (reg_idx * 8));\r\nreg1->reg &= ~(0xffff << (reg_idx * 16));\r\nreg1->idx |= nhmex_mbox_extra_reg_idx(er) << (reg_idx * 8);\r\nreg1->reg |= msr << (reg_idx * 16);\r\nreg1->config = event->attr.config1;\r\nreg_idx++;\r\n}\r\nif (reg_idx == 2) {\r\nreg2->idx = EXTRA_REG_NHMEX_M_FILTER;\r\nif (event->attr.config2 & NHMEX_M_PMON_MM_CFG_EN)\r\nreg2->config = event->attr.config2;\r\nelse\r\nreg2->config = ~0ULL;\r\nif (box->pmu->pmu_idx == 0)\r\nreg2->reg = NHMEX_M0_MSR_PMU_MM_CFG;\r\nelse\r\nreg2->reg = NHMEX_M1_MSR_PMU_MM_CFG;\r\n}\r\nreturn 0;\r\n}\r\nstatic u64 nhmex_mbox_shared_reg_config(struct intel_uncore_box *box, int idx)\r\n{\r\nstruct intel_uncore_extra_reg *er;\r\nunsigned long flags;\r\nu64 config;\r\nif (idx < EXTRA_REG_NHMEX_M_ZDP_CTL_FVC)\r\nreturn box->shared_regs[idx].config;\r\ner = &box->shared_regs[EXTRA_REG_NHMEX_M_ZDP_CTL_FVC];\r\nraw_spin_lock_irqsave(&er->lock, flags);\r\nconfig = er->config;\r\nraw_spin_unlock_irqrestore(&er->lock, flags);\r\nreturn config;\r\n}\r\nstatic void nhmex_mbox_msr_enable_event(struct intel_uncore_box *box, struct perf_event *event)\r\n{\r\nstruct hw_perf_event *hwc = &event->hw;\r\nstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\r\nstruct hw_perf_event_extra *reg2 = &hwc->branch_reg;\r\nint idx;\r\nidx = __BITS_VALUE(reg1->idx, 0, 8);\r\nif (idx != 0xff)\r\nwrmsrl(__BITS_VALUE(reg1->reg, 0, 16),\r\nnhmex_mbox_shared_reg_config(box, idx));\r\nidx = __BITS_VALUE(reg1->idx, 1, 8);\r\nif (idx != 0xff)\r\nwrmsrl(__BITS_VALUE(reg1->reg, 1, 16),\r\nnhmex_mbox_shared_reg_config(box, idx));\r\nif (reg2->idx != EXTRA_REG_NONE) {\r\nwrmsrl(reg2->reg, 0);\r\nif (reg2->config != ~0ULL) {\r\nwrmsrl(reg2->reg + 1,\r\nreg2->config & NHMEX_M_PMON_ADDR_MATCH_MASK);\r\nwrmsrl(reg2->reg + 2, NHMEX_M_PMON_ADDR_MASK_MASK &\r\n(reg2->config >> NHMEX_M_PMON_ADDR_MASK_SHIFT));\r\nwrmsrl(reg2->reg, NHMEX_M_PMON_MM_CFG_EN);\r\n}\r\n}\r\nwrmsrl(hwc->config_base, hwc->config | NHMEX_PMON_CTL_EN_BIT0);\r\n}\r\nstatic void nhmex_rbox_alter_er(struct intel_uncore_box *box, struct perf_event *event)\r\n{\r\nstruct hw_perf_event *hwc = &event->hw;\r\nstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\r\nif (reg1->idx % 2) {\r\nreg1->idx--;\r\nhwc->config -= 1 << NHMEX_R_PMON_CTL_EV_SEL_SHIFT;\r\n} else {\r\nreg1->idx++;\r\nhwc->config += 1 << NHMEX_R_PMON_CTL_EV_SEL_SHIFT;\r\n}\r\nswitch (reg1->idx % 6) {\r\ncase 2:\r\nreg1->config >>= 8;\r\nbreak;\r\ncase 3:\r\nreg1->config <<= 8;\r\nbreak;\r\n}\r\n}\r\nstatic struct event_constraint *\r\nnhmex_rbox_get_constraint(struct intel_uncore_box *box, struct perf_event *event)\r\n{\r\nstruct hw_perf_event *hwc = &event->hw;\r\nstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\r\nstruct hw_perf_event_extra *reg2 = &hwc->branch_reg;\r\nstruct intel_uncore_extra_reg *er;\r\nunsigned long flags;\r\nint idx, er_idx;\r\nu64 config1;\r\nbool ok = false;\r\nif (!uncore_box_is_fake(box) && reg1->alloc)\r\nreturn NULL;\r\nidx = reg1->idx % 6;\r\nconfig1 = reg1->config;\r\nagain:\r\ner_idx = idx;\r\nif (er_idx > 2)\r\ner_idx--;\r\ner_idx += (reg1->idx / 6) * 5;\r\ner = &box->shared_regs[er_idx];\r\nraw_spin_lock_irqsave(&er->lock, flags);\r\nif (idx < 2) {\r\nif (!atomic_read(&er->ref) || er->config == reg1->config) {\r\natomic_inc(&er->ref);\r\ner->config = reg1->config;\r\nok = true;\r\n}\r\n} else if (idx == 2 || idx == 3) {\r\nu64 mask = 0xff << ((idx - 2) * 8);\r\nif (!__BITS_VALUE(atomic_read(&er->ref), idx - 2, 8) ||\r\n!((er->config ^ config1) & mask)) {\r\natomic_add(1 << ((idx - 2) * 8), &er->ref);\r\ner->config &= ~mask;\r\ner->config |= config1 & mask;\r\nok = true;\r\n}\r\n} else {\r\nif (!atomic_read(&er->ref) ||\r\n(er->config == (hwc->config >> 32) &&\r\ner->config1 == reg1->config &&\r\ner->config2 == reg2->config)) {\r\natomic_inc(&er->ref);\r\ner->config = (hwc->config >> 32);\r\ner->config1 = reg1->config;\r\ner->config2 = reg2->config;\r\nok = true;\r\n}\r\n}\r\nraw_spin_unlock_irqrestore(&er->lock, flags);\r\nif (!ok) {\r\nidx ^= 1;\r\nif (idx != reg1->idx % 6) {\r\nif (idx == 2)\r\nconfig1 >>= 8;\r\nelse if (idx == 3)\r\nconfig1 <<= 8;\r\ngoto again;\r\n}\r\n} else {\r\nif (!uncore_box_is_fake(box)) {\r\nif (idx != reg1->idx % 6)\r\nnhmex_rbox_alter_er(box, event);\r\nreg1->alloc = 1;\r\n}\r\nreturn NULL;\r\n}\r\nreturn &uncore_constraint_empty;\r\n}\r\nstatic void nhmex_rbox_put_constraint(struct intel_uncore_box *box, struct perf_event *event)\r\n{\r\nstruct intel_uncore_extra_reg *er;\r\nstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\r\nint idx, er_idx;\r\nif (uncore_box_is_fake(box) || !reg1->alloc)\r\nreturn;\r\nidx = reg1->idx % 6;\r\ner_idx = idx;\r\nif (er_idx > 2)\r\ner_idx--;\r\ner_idx += (reg1->idx / 6) * 5;\r\ner = &box->shared_regs[er_idx];\r\nif (idx == 2 || idx == 3)\r\natomic_sub(1 << ((idx - 2) * 8), &er->ref);\r\nelse\r\natomic_dec(&er->ref);\r\nreg1->alloc = 0;\r\n}\r\nstatic int nhmex_rbox_hw_config(struct intel_uncore_box *box, struct perf_event *event)\r\n{\r\nstruct hw_perf_event *hwc = &event->hw;\r\nstruct hw_perf_event_extra *reg1 = &event->hw.extra_reg;\r\nstruct hw_perf_event_extra *reg2 = &event->hw.branch_reg;\r\nint idx;\r\nidx = (event->hw.config & NHMEX_R_PMON_CTL_EV_SEL_MASK) >>\r\nNHMEX_R_PMON_CTL_EV_SEL_SHIFT;\r\nif (idx >= 0x18)\r\nreturn -EINVAL;\r\nreg1->idx = idx;\r\nreg1->config = event->attr.config1;\r\nswitch (idx % 6) {\r\ncase 4:\r\ncase 5:\r\nhwc->config |= event->attr.config & (~0ULL << 32);\r\nreg2->config = event->attr.config2;\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nstatic void nhmex_rbox_msr_enable_event(struct intel_uncore_box *box, struct perf_event *event)\r\n{\r\nstruct hw_perf_event *hwc = &event->hw;\r\nstruct hw_perf_event_extra *reg1 = &hwc->extra_reg;\r\nstruct hw_perf_event_extra *reg2 = &hwc->branch_reg;\r\nint idx, port;\r\nidx = reg1->idx;\r\nport = idx / 6 + box->pmu->pmu_idx * 4;\r\nswitch (idx % 6) {\r\ncase 0:\r\nwrmsrl(NHMEX_R_MSR_PORTN_IPERF_CFG0(port), reg1->config);\r\nbreak;\r\ncase 1:\r\nwrmsrl(NHMEX_R_MSR_PORTN_IPERF_CFG1(port), reg1->config);\r\nbreak;\r\ncase 2:\r\ncase 3:\r\nwrmsrl(NHMEX_R_MSR_PORTN_QLX_CFG(port),\r\nuncore_shared_reg_config(box, 2 + (idx / 6) * 5));\r\nbreak;\r\ncase 4:\r\nwrmsrl(NHMEX_R_MSR_PORTN_XBR_SET1_MM_CFG(port),\r\nhwc->config >> 32);\r\nwrmsrl(NHMEX_R_MSR_PORTN_XBR_SET1_MATCH(port), reg1->config);\r\nwrmsrl(NHMEX_R_MSR_PORTN_XBR_SET1_MASK(port), reg2->config);\r\nbreak;\r\ncase 5:\r\nwrmsrl(NHMEX_R_MSR_PORTN_XBR_SET2_MM_CFG(port),\r\nhwc->config >> 32);\r\nwrmsrl(NHMEX_R_MSR_PORTN_XBR_SET2_MATCH(port), reg1->config);\r\nwrmsrl(NHMEX_R_MSR_PORTN_XBR_SET2_MASK(port), reg2->config);\r\nbreak;\r\n}\r\nwrmsrl(hwc->config_base, NHMEX_PMON_CTL_EN_BIT0 |\r\n(hwc->config & NHMEX_R_PMON_CTL_EV_SEL_MASK));\r\n}\r\nvoid nhmex_uncore_cpu_init(void)\r\n{\r\nif (boot_cpu_data.x86_model == 46)\r\nuncore_nhmex = true;\r\nelse\r\nnhmex_uncore_mbox.event_descs = wsmex_uncore_mbox_events;\r\nif (nhmex_uncore_cbox.num_boxes > boot_cpu_data.x86_max_cores)\r\nnhmex_uncore_cbox.num_boxes = boot_cpu_data.x86_max_cores;\r\nuncore_msr_uncores = nhmex_msr_uncores;\r\n}
