void oz_pd_set_state(struct oz_pd *pd, unsigned state)\r\n{\r\npd->state = state;\r\nswitch (state) {\r\ncase OZ_PD_S_IDLE:\r\noz_pd_dbg(pd, ON, "PD State: OZ_PD_S_IDLE\n");\r\nbreak;\r\ncase OZ_PD_S_CONNECTED:\r\noz_pd_dbg(pd, ON, "PD State: OZ_PD_S_CONNECTED\n");\r\nbreak;\r\ncase OZ_PD_S_STOPPED:\r\noz_pd_dbg(pd, ON, "PD State: OZ_PD_S_STOPPED\n");\r\nbreak;\r\ncase OZ_PD_S_SLEEP:\r\noz_pd_dbg(pd, ON, "PD State: OZ_PD_S_SLEEP\n");\r\nbreak;\r\n}\r\n}\r\nvoid oz_pd_get(struct oz_pd *pd)\r\n{\r\natomic_inc(&pd->ref_count);\r\n}\r\nvoid oz_pd_put(struct oz_pd *pd)\r\n{\r\nif (atomic_dec_and_test(&pd->ref_count))\r\noz_pd_destroy(pd);\r\n}\r\nstruct oz_pd *oz_pd_alloc(const u8 *mac_addr)\r\n{\r\nstruct oz_pd *pd = kzalloc(sizeof(struct oz_pd), GFP_ATOMIC);\r\nif (pd) {\r\nint i;\r\natomic_set(&pd->ref_count, 2);\r\nfor (i = 0; i < OZ_NB_APPS; i++)\r\nspin_lock_init(&pd->app_lock[i]);\r\npd->last_rx_pkt_num = 0xffffffff;\r\noz_pd_set_state(pd, OZ_PD_S_IDLE);\r\npd->max_tx_size = OZ_MAX_TX_SIZE;\r\nether_addr_copy(pd->mac_addr, mac_addr);\r\noz_elt_buf_init(&pd->elt_buff);\r\nspin_lock_init(&pd->tx_frame_lock);\r\nINIT_LIST_HEAD(&pd->tx_queue);\r\nINIT_LIST_HEAD(&pd->farewell_list);\r\npd->last_sent_frame = &pd->tx_queue;\r\nspin_lock_init(&pd->stream_lock);\r\nINIT_LIST_HEAD(&pd->stream_list);\r\ntasklet_init(&pd->heartbeat_tasklet, oz_pd_heartbeat_handler,\r\n(unsigned long)pd);\r\ntasklet_init(&pd->timeout_tasklet, oz_pd_timeout_handler,\r\n(unsigned long)pd);\r\nhrtimer_init(&pd->heartbeat, CLOCK_MONOTONIC, HRTIMER_MODE_REL);\r\nhrtimer_init(&pd->timeout, CLOCK_MONOTONIC, HRTIMER_MODE_REL);\r\npd->heartbeat.function = oz_pd_heartbeat_event;\r\npd->timeout.function = oz_pd_timeout_event;\r\n}\r\nreturn pd;\r\n}\r\nstatic void oz_pd_free(struct work_struct *work)\r\n{\r\nstruct list_head *e, *n;\r\nstruct oz_pd *pd;\r\noz_pd_dbg(pd, ON, "Destroying PD\n");\r\npd = container_of(work, struct oz_pd, workitem);\r\ntasklet_kill(&pd->heartbeat_tasklet);\r\ntasklet_kill(&pd->timeout_tasklet);\r\nlist_for_each_safe(e, n, &pd->stream_list)\r\noz_isoc_stream_free(list_entry(e, struct oz_isoc_stream, link));\r\nlist_for_each_safe(e, n, &pd->tx_queue) {\r\nstruct oz_tx_frame *f = list_entry(e, struct oz_tx_frame, link);\r\nif (f->skb != NULL)\r\nkfree_skb(f->skb);\r\noz_retire_frame(pd, f);\r\n}\r\noz_elt_buf_term(&pd->elt_buff);\r\nlist_for_each_safe(e, n, &pd->farewell_list)\r\nkfree(list_entry(e, struct oz_farewell, link));\r\nif (pd->net_dev)\r\ndev_put(pd->net_dev);\r\nkfree(pd);\r\n}\r\nvoid oz_pd_destroy(struct oz_pd *pd)\r\n{\r\nif (hrtimer_active(&pd->timeout))\r\nhrtimer_cancel(&pd->timeout);\r\nif (hrtimer_active(&pd->heartbeat))\r\nhrtimer_cancel(&pd->heartbeat);\r\nINIT_WORK(&pd->workitem, oz_pd_free);\r\nif (!schedule_work(&pd->workitem))\r\noz_pd_dbg(pd, ON, "failed to schedule workitem\n");\r\n}\r\nint oz_services_start(struct oz_pd *pd, u16 apps, int resume)\r\n{\r\nint i, rc = 0;\r\noz_pd_dbg(pd, ON, "%s: (0x%x) resume(%d)\n", __func__, apps, resume);\r\nfor (i = 0; i < OZ_NB_APPS; i++) {\r\nif (g_app_if[i].start && (apps & (1 << i))) {\r\nif (g_app_if[i].start(pd, resume)) {\r\nrc = -1;\r\noz_pd_dbg(pd, ON,\r\n"Unable to start service %d\n", i);\r\nbreak;\r\n}\r\nspin_lock_bh(&g_polling_lock);\r\npd->total_apps |= (1 << i);\r\nif (resume)\r\npd->paused_apps &= ~(1 << i);\r\nspin_unlock_bh(&g_polling_lock);\r\n}\r\n}\r\nreturn rc;\r\n}\r\nvoid oz_services_stop(struct oz_pd *pd, u16 apps, int pause)\r\n{\r\nint i;\r\noz_pd_dbg(pd, ON, "%s: (0x%x) pause(%d)\n", __func__, apps, pause);\r\nfor (i = 0; i < OZ_NB_APPS; i++) {\r\nif (g_app_if[i].stop && (apps & (1 << i))) {\r\nspin_lock_bh(&g_polling_lock);\r\nif (pause) {\r\npd->paused_apps |= (1 << i);\r\n} else {\r\npd->total_apps &= ~(1 << i);\r\npd->paused_apps &= ~(1 << i);\r\n}\r\nspin_unlock_bh(&g_polling_lock);\r\ng_app_if[i].stop(pd, pause);\r\n}\r\n}\r\n}\r\nvoid oz_pd_heartbeat(struct oz_pd *pd, u16 apps)\r\n{\r\nint i, more = 0;\r\nfor (i = 0; i < OZ_NB_APPS; i++) {\r\nif (g_app_if[i].heartbeat && (apps & (1 << i))) {\r\nif (g_app_if[i].heartbeat(pd))\r\nmore = 1;\r\n}\r\n}\r\nif ((!more) && (hrtimer_active(&pd->heartbeat)))\r\nhrtimer_cancel(&pd->heartbeat);\r\nif (pd->mode & OZ_F_ISOC_ANYTIME) {\r\nint count = 8;\r\nwhile (count-- && (oz_send_isoc_frame(pd) >= 0))\r\n;\r\n}\r\n}\r\nvoid oz_pd_stop(struct oz_pd *pd)\r\n{\r\nu16 stop_apps;\r\noz_dbg(ON, "oz_pd_stop() State = 0x%x\n", pd->state);\r\noz_pd_indicate_farewells(pd);\r\nspin_lock_bh(&g_polling_lock);\r\nstop_apps = pd->total_apps;\r\npd->total_apps = 0;\r\npd->paused_apps = 0;\r\nspin_unlock_bh(&g_polling_lock);\r\noz_services_stop(pd, stop_apps, 0);\r\nspin_lock_bh(&g_polling_lock);\r\noz_pd_set_state(pd, OZ_PD_S_STOPPED);\r\nlist_del(&pd->link);\r\nspin_unlock_bh(&g_polling_lock);\r\noz_dbg(ON, "pd ref count = %d\n", atomic_read(&pd->ref_count));\r\noz_pd_put(pd);\r\n}\r\nint oz_pd_sleep(struct oz_pd *pd)\r\n{\r\nint do_stop = 0;\r\nu16 stop_apps;\r\nspin_lock_bh(&g_polling_lock);\r\nif (pd->state & (OZ_PD_S_SLEEP | OZ_PD_S_STOPPED)) {\r\nspin_unlock_bh(&g_polling_lock);\r\nreturn 0;\r\n}\r\nif (pd->keep_alive && pd->session_id)\r\noz_pd_set_state(pd, OZ_PD_S_SLEEP);\r\nelse\r\ndo_stop = 1;\r\nstop_apps = pd->total_apps;\r\nspin_unlock_bh(&g_polling_lock);\r\nif (do_stop) {\r\noz_pd_stop(pd);\r\n} else {\r\noz_services_stop(pd, stop_apps, 1);\r\noz_timer_add(pd, OZ_TIMER_STOP, pd->keep_alive);\r\n}\r\nreturn do_stop;\r\n}\r\nstatic struct oz_tx_frame *oz_tx_frame_alloc(struct oz_pd *pd)\r\n{\r\nstruct oz_tx_frame *f;\r\nf = kmem_cache_alloc(oz_tx_frame_cache, GFP_ATOMIC);\r\nif (f) {\r\nf->total_size = sizeof(struct oz_hdr);\r\nINIT_LIST_HEAD(&f->link);\r\nINIT_LIST_HEAD(&f->elt_list);\r\n}\r\nreturn f;\r\n}\r\nstatic void oz_tx_isoc_free(struct oz_pd *pd, struct oz_tx_frame *f)\r\n{\r\npd->nb_queued_isoc_frames--;\r\nlist_del_init(&f->link);\r\nkmem_cache_free(oz_tx_frame_cache, f);\r\noz_dbg(TX_FRAMES, "Releasing ISOC Frame isoc_nb= %d\n",\r\npd->nb_queued_isoc_frames);\r\n}\r\nstatic void oz_tx_frame_free(struct oz_pd *pd, struct oz_tx_frame *f)\r\n{\r\nkmem_cache_free(oz_tx_frame_cache, f);\r\n}\r\nstatic void oz_set_more_bit(struct sk_buff *skb)\r\n{\r\nstruct oz_hdr *oz_hdr = (struct oz_hdr *)skb_network_header(skb);\r\noz_hdr->control |= OZ_F_MORE_DATA;\r\n}\r\nstatic void oz_set_last_pkt_nb(struct oz_pd *pd, struct sk_buff *skb)\r\n{\r\nstruct oz_hdr *oz_hdr = (struct oz_hdr *)skb_network_header(skb);\r\noz_hdr->last_pkt_num = pd->trigger_pkt_num & OZ_LAST_PN_MASK;\r\n}\r\nint oz_prepare_frame(struct oz_pd *pd, int empty)\r\n{\r\nstruct oz_tx_frame *f;\r\nif ((pd->mode & OZ_MODE_MASK) != OZ_MODE_TRIGGERED)\r\nreturn -1;\r\nif (pd->nb_queued_frames >= OZ_MAX_QUEUED_FRAMES)\r\nreturn -1;\r\nif (!empty && !oz_are_elts_available(&pd->elt_buff))\r\nreturn -1;\r\nf = oz_tx_frame_alloc(pd);\r\nif (f == NULL)\r\nreturn -1;\r\nf->skb = NULL;\r\nf->hdr.control =\r\n(OZ_PROTOCOL_VERSION<<OZ_VERSION_SHIFT) | OZ_F_ACK_REQUESTED;\r\n++pd->last_tx_pkt_num;\r\nput_unaligned(cpu_to_le32(pd->last_tx_pkt_num), &f->hdr.pkt_num);\r\nif (empty == 0) {\r\noz_select_elts_for_tx(&pd->elt_buff, 0, &f->total_size,\r\npd->max_tx_size, &f->elt_list);\r\n}\r\nspin_lock(&pd->tx_frame_lock);\r\nlist_add_tail(&f->link, &pd->tx_queue);\r\npd->nb_queued_frames++;\r\nspin_unlock(&pd->tx_frame_lock);\r\nreturn 0;\r\n}\r\nstatic struct sk_buff *oz_build_frame(struct oz_pd *pd, struct oz_tx_frame *f)\r\n{\r\nstruct sk_buff *skb;\r\nstruct net_device *dev = pd->net_dev;\r\nstruct oz_hdr *oz_hdr;\r\nstruct oz_elt *elt;\r\nstruct oz_elt_info *ei;\r\nskb = alloc_skb(f->total_size + OZ_ALLOCATED_SPACE(dev), GFP_ATOMIC);\r\nif (skb == NULL)\r\nreturn NULL;\r\nskb_reserve(skb, LL_RESERVED_SPACE(dev));\r\nskb_reset_network_header(skb);\r\nskb->dev = dev;\r\nskb->protocol = htons(OZ_ETHERTYPE);\r\nif (dev_hard_header(skb, dev, OZ_ETHERTYPE, pd->mac_addr,\r\ndev->dev_addr, skb->len) < 0)\r\ngoto fail;\r\noz_hdr = (struct oz_hdr *)skb_put(skb, f->total_size);\r\nf->hdr.last_pkt_num = pd->trigger_pkt_num & OZ_LAST_PN_MASK;\r\nmemcpy(oz_hdr, &f->hdr, sizeof(struct oz_hdr));\r\nelt = (struct oz_elt *)(oz_hdr+1);\r\nlist_for_each_entry(ei, &f->elt_list, link) {\r\nmemcpy(elt, ei->data, ei->length);\r\nelt = oz_next_elt(elt);\r\n}\r\nreturn skb;\r\nfail:\r\nkfree_skb(skb);\r\nreturn NULL;\r\n}\r\nstatic void oz_retire_frame(struct oz_pd *pd, struct oz_tx_frame *f)\r\n{\r\nstruct oz_elt_info *ei, *n;\r\nlist_for_each_entry_safe(ei, n, &f->elt_list, link) {\r\nlist_del_init(&ei->link);\r\nif (ei->callback)\r\nei->callback(pd, ei->context);\r\nspin_lock_bh(&pd->elt_buff.lock);\r\noz_elt_info_free(&pd->elt_buff, ei);\r\nspin_unlock_bh(&pd->elt_buff.lock);\r\n}\r\noz_tx_frame_free(pd, f);\r\n}\r\nstatic int oz_send_next_queued_frame(struct oz_pd *pd, int more_data)\r\n{\r\nstruct sk_buff *skb;\r\nstruct oz_tx_frame *f;\r\nstruct list_head *e;\r\nspin_lock(&pd->tx_frame_lock);\r\ne = pd->last_sent_frame->next;\r\nif (e == &pd->tx_queue) {\r\nspin_unlock(&pd->tx_frame_lock);\r\nreturn -1;\r\n}\r\nf = list_entry(e, struct oz_tx_frame, link);\r\nif (f->skb != NULL) {\r\nskb = f->skb;\r\noz_tx_isoc_free(pd, f);\r\nspin_unlock(&pd->tx_frame_lock);\r\nif (more_data)\r\noz_set_more_bit(skb);\r\noz_set_last_pkt_nb(pd, skb);\r\nif ((int)atomic_read(&g_submitted_isoc) <\r\nOZ_MAX_SUBMITTED_ISOC) {\r\nif (dev_queue_xmit(skb) < 0) {\r\noz_dbg(TX_FRAMES, "Dropping ISOC Frame\n");\r\nreturn -1;\r\n}\r\natomic_inc(&g_submitted_isoc);\r\noz_dbg(TX_FRAMES, "Sending ISOC Frame, nb_isoc= %d\n",\r\npd->nb_queued_isoc_frames);\r\nreturn 0;\r\n}\r\nkfree_skb(skb);\r\noz_dbg(TX_FRAMES, "Dropping ISOC Frame>\n");\r\nreturn -1;\r\n}\r\npd->last_sent_frame = e;\r\nskb = oz_build_frame(pd, f);\r\nspin_unlock(&pd->tx_frame_lock);\r\nif (!skb)\r\nreturn -1;\r\nif (more_data)\r\noz_set_more_bit(skb);\r\noz_dbg(TX_FRAMES, "TX frame PN=0x%x\n", f->hdr.pkt_num);\r\nif (dev_queue_xmit(skb) < 0)\r\nreturn -1;\r\nreturn 0;\r\n}\r\nvoid oz_send_queued_frames(struct oz_pd *pd, int backlog)\r\n{\r\nwhile (oz_prepare_frame(pd, 0) >= 0)\r\nbacklog++;\r\nswitch (pd->mode & (OZ_F_ISOC_NO_ELTS | OZ_F_ISOC_ANYTIME)) {\r\ncase OZ_F_ISOC_NO_ELTS: {\r\nbacklog += pd->nb_queued_isoc_frames;\r\nif (backlog <= 0)\r\ngoto out;\r\nif (backlog > OZ_MAX_SUBMITTED_ISOC)\r\nbacklog = OZ_MAX_SUBMITTED_ISOC;\r\nbreak;\r\n}\r\ncase OZ_NO_ELTS_ANYTIME: {\r\nif ((backlog <= 0) && (pd->isoc_sent == 0))\r\ngoto out;\r\nbreak;\r\n}\r\ndefault: {\r\nif (backlog <= 0)\r\ngoto out;\r\nbreak;\r\n}\r\n}\r\nwhile (backlog--) {\r\nif (oz_send_next_queued_frame(pd, backlog) < 0)\r\nbreak;\r\n}\r\nreturn;\r\nout: oz_prepare_frame(pd, 1);\r\noz_send_next_queued_frame(pd, 0);\r\n}\r\nstatic int oz_send_isoc_frame(struct oz_pd *pd)\r\n{\r\nstruct sk_buff *skb;\r\nstruct net_device *dev = pd->net_dev;\r\nstruct oz_hdr *oz_hdr;\r\nstruct oz_elt *elt;\r\nstruct oz_elt_info *ei;\r\nLIST_HEAD(list);\r\nint total_size = sizeof(struct oz_hdr);\r\noz_select_elts_for_tx(&pd->elt_buff, 1, &total_size,\r\npd->max_tx_size, &list);\r\nif (list_empty(&list))\r\nreturn 0;\r\nskb = alloc_skb(total_size + OZ_ALLOCATED_SPACE(dev), GFP_ATOMIC);\r\nif (skb == NULL) {\r\noz_dbg(ON, "Cannot alloc skb\n");\r\noz_elt_info_free_chain(&pd->elt_buff, &list);\r\nreturn -1;\r\n}\r\nskb_reserve(skb, LL_RESERVED_SPACE(dev));\r\nskb_reset_network_header(skb);\r\nskb->dev = dev;\r\nskb->protocol = htons(OZ_ETHERTYPE);\r\nif (dev_hard_header(skb, dev, OZ_ETHERTYPE, pd->mac_addr,\r\ndev->dev_addr, skb->len) < 0) {\r\nkfree_skb(skb);\r\nreturn -1;\r\n}\r\noz_hdr = (struct oz_hdr *)skb_put(skb, total_size);\r\noz_hdr->control = (OZ_PROTOCOL_VERSION<<OZ_VERSION_SHIFT) | OZ_F_ISOC;\r\noz_hdr->last_pkt_num = pd->trigger_pkt_num & OZ_LAST_PN_MASK;\r\nelt = (struct oz_elt *)(oz_hdr+1);\r\nlist_for_each_entry(ei, &list, link) {\r\nmemcpy(elt, ei->data, ei->length);\r\nelt = oz_next_elt(elt);\r\n}\r\ndev_queue_xmit(skb);\r\noz_elt_info_free_chain(&pd->elt_buff, &list);\r\nreturn 0;\r\n}\r\nvoid oz_retire_tx_frames(struct oz_pd *pd, u8 lpn)\r\n{\r\nstruct oz_tx_frame *f, *tmp = NULL;\r\nu8 diff;\r\nu32 pkt_num;\r\nLIST_HEAD(list);\r\nspin_lock(&pd->tx_frame_lock);\r\nlist_for_each_entry(f, &pd->tx_queue, link) {\r\npkt_num = le32_to_cpu(get_unaligned(&f->hdr.pkt_num));\r\ndiff = (lpn - (pkt_num & OZ_LAST_PN_MASK)) & OZ_LAST_PN_MASK;\r\nif ((diff > OZ_LAST_PN_HALF_CYCLE) || (pkt_num == 0))\r\nbreak;\r\noz_dbg(TX_FRAMES, "Releasing pkt_num= %u, nb= %d\n",\r\npkt_num, pd->nb_queued_frames);\r\ntmp = f;\r\npd->nb_queued_frames--;\r\n}\r\nif (tmp)\r\nlist_cut_position(&list, &pd->tx_queue, &tmp->link);\r\npd->last_sent_frame = &pd->tx_queue;\r\nspin_unlock(&pd->tx_frame_lock);\r\nlist_for_each_entry_safe(f, tmp, &list, link)\r\noz_retire_frame(pd, f);\r\n}\r\nstatic struct oz_isoc_stream *pd_stream_find(struct oz_pd *pd, u8 ep_num)\r\n{\r\nstruct oz_isoc_stream *st;\r\nlist_for_each_entry(st, &pd->stream_list, link) {\r\nif (st->ep_num == ep_num)\r\nreturn st;\r\n}\r\nreturn NULL;\r\n}\r\nint oz_isoc_stream_create(struct oz_pd *pd, u8 ep_num)\r\n{\r\nstruct oz_isoc_stream *st =\r\nkzalloc(sizeof(struct oz_isoc_stream), GFP_ATOMIC);\r\nif (!st)\r\nreturn -ENOMEM;\r\nst->ep_num = ep_num;\r\nspin_lock_bh(&pd->stream_lock);\r\nif (!pd_stream_find(pd, ep_num)) {\r\nlist_add(&st->link, &pd->stream_list);\r\nst = NULL;\r\n}\r\nspin_unlock_bh(&pd->stream_lock);\r\nkfree(st);\r\nreturn 0;\r\n}\r\nstatic void oz_isoc_stream_free(struct oz_isoc_stream *st)\r\n{\r\nkfree_skb(st->skb);\r\nkfree(st);\r\n}\r\nint oz_isoc_stream_delete(struct oz_pd *pd, u8 ep_num)\r\n{\r\nstruct oz_isoc_stream *st;\r\nspin_lock_bh(&pd->stream_lock);\r\nst = pd_stream_find(pd, ep_num);\r\nif (st)\r\nlist_del(&st->link);\r\nspin_unlock_bh(&pd->stream_lock);\r\nif (st)\r\noz_isoc_stream_free(st);\r\nreturn 0;\r\n}\r\nstatic void oz_isoc_destructor(struct sk_buff *skb)\r\n{\r\natomic_dec(&g_submitted_isoc);\r\n}\r\nint oz_send_isoc_unit(struct oz_pd *pd, u8 ep_num, const u8 *data, int len)\r\n{\r\nstruct net_device *dev = pd->net_dev;\r\nstruct oz_isoc_stream *st;\r\nu8 nb_units = 0;\r\nstruct sk_buff *skb = NULL;\r\nstruct oz_hdr *oz_hdr = NULL;\r\nint size = 0;\r\nspin_lock_bh(&pd->stream_lock);\r\nst = pd_stream_find(pd, ep_num);\r\nif (st) {\r\nskb = st->skb;\r\nst->skb = NULL;\r\nnb_units = st->nb_units;\r\nst->nb_units = 0;\r\noz_hdr = st->oz_hdr;\r\nsize = st->size;\r\n}\r\nspin_unlock_bh(&pd->stream_lock);\r\nif (!st)\r\nreturn 0;\r\nif (!skb) {\r\nskb = alloc_skb(pd->max_tx_size + OZ_ALLOCATED_SPACE(dev),\r\nGFP_ATOMIC);\r\nif (skb == NULL)\r\nreturn 0;\r\nskb_reserve(skb, LL_RESERVED_SPACE(dev));\r\nskb_reset_network_header(skb);\r\nskb->dev = dev;\r\nskb->protocol = htons(OZ_ETHERTYPE);\r\nskb->priority = 0x7;\r\nsize = sizeof(struct oz_hdr) + sizeof(struct oz_isoc_large);\r\noz_hdr = (struct oz_hdr *)skb_put(skb, size);\r\n}\r\nmemcpy(skb_put(skb, len), data, len);\r\nsize += len;\r\nif (++nb_units < pd->ms_per_isoc) {\r\nspin_lock_bh(&pd->stream_lock);\r\nst->skb = skb;\r\nst->nb_units = nb_units;\r\nst->oz_hdr = oz_hdr;\r\nst->size = size;\r\nspin_unlock_bh(&pd->stream_lock);\r\n} else {\r\nstruct oz_hdr oz;\r\nstruct oz_isoc_large iso;\r\nspin_lock_bh(&pd->stream_lock);\r\niso.frame_number = st->frame_num;\r\nst->frame_num += nb_units;\r\nspin_unlock_bh(&pd->stream_lock);\r\noz.control =\r\n(OZ_PROTOCOL_VERSION<<OZ_VERSION_SHIFT) | OZ_F_ISOC;\r\noz.last_pkt_num = pd->trigger_pkt_num & OZ_LAST_PN_MASK;\r\noz.pkt_num = 0;\r\niso.endpoint = ep_num;\r\niso.format = OZ_DATA_F_ISOC_LARGE;\r\niso.ms_data = nb_units;\r\nmemcpy(oz_hdr, &oz, sizeof(oz));\r\nmemcpy(oz_hdr+1, &iso, sizeof(iso));\r\nif (dev_hard_header(skb, dev, OZ_ETHERTYPE, pd->mac_addr,\r\ndev->dev_addr, skb->len) < 0)\r\ngoto out;\r\nskb->destructor = oz_isoc_destructor;\r\nif (!(pd->mode & OZ_F_ISOC_ANYTIME)) {\r\nstruct oz_tx_frame *isoc_unit = NULL;\r\nint nb = pd->nb_queued_isoc_frames;\r\nif (nb >= pd->isoc_latency) {\r\nstruct oz_tx_frame *f;\r\noz_dbg(TX_FRAMES, "Dropping ISOC Unit nb= %d\n",\r\nnb);\r\nspin_lock(&pd->tx_frame_lock);\r\nlist_for_each_entry(f, &pd->tx_queue, link) {\r\nif (f->skb != NULL) {\r\noz_tx_isoc_free(pd, f);\r\nbreak;\r\n}\r\n}\r\nspin_unlock(&pd->tx_frame_lock);\r\n}\r\nisoc_unit = oz_tx_frame_alloc(pd);\r\nif (isoc_unit == NULL)\r\ngoto out;\r\nisoc_unit->hdr = oz;\r\nisoc_unit->skb = skb;\r\nspin_lock_bh(&pd->tx_frame_lock);\r\nlist_add_tail(&isoc_unit->link, &pd->tx_queue);\r\npd->nb_queued_isoc_frames++;\r\nspin_unlock_bh(&pd->tx_frame_lock);\r\noz_dbg(TX_FRAMES,\r\n"Added ISOC Frame to Tx Queue isoc_nb= %d, nb= %d\n",\r\npd->nb_queued_isoc_frames, pd->nb_queued_frames);\r\nreturn 0;\r\n}\r\nif (atomic_read(&g_submitted_isoc) < OZ_MAX_SUBMITTED_ISOC) {\r\natomic_inc(&g_submitted_isoc);\r\nif (dev_queue_xmit(skb) < 0)\r\nreturn -1;\r\nreturn 0;\r\n}\r\nout: kfree_skb(skb);\r\nreturn -1;\r\n}\r\nreturn 0;\r\n}\r\nvoid oz_apps_init(void)\r\n{\r\nint i;\r\nfor (i = 0; i < OZ_NB_APPS; i++) {\r\nif (g_app_if[i].init)\r\ng_app_if[i].init();\r\n}\r\n}\r\nvoid oz_apps_term(void)\r\n{\r\nint i;\r\nfor (i = 0; i < OZ_NB_APPS; i++) {\r\nif (g_app_if[i].term)\r\ng_app_if[i].term();\r\n}\r\n}\r\nvoid oz_handle_app_elt(struct oz_pd *pd, u8 app_id, struct oz_elt *elt)\r\n{\r\nif (app_id < OZ_NB_APPS && g_app_if[app_id].rx)\r\ng_app_if[app_id].rx(pd, elt);\r\n}\r\nvoid oz_pd_indicate_farewells(struct oz_pd *pd)\r\n{\r\nstruct oz_farewell *f;\r\nconst struct oz_app_if *ai = &g_app_if[OZ_APPID_USB];\r\nwhile (1) {\r\nspin_lock_bh(&g_polling_lock);\r\nif (list_empty(&pd->farewell_list)) {\r\nspin_unlock_bh(&g_polling_lock);\r\nbreak;\r\n}\r\nf = list_first_entry(&pd->farewell_list,\r\nstruct oz_farewell, link);\r\nlist_del(&f->link);\r\nspin_unlock_bh(&g_polling_lock);\r\nif (ai->farewell)\r\nai->farewell(pd, f->ep_num, f->report, f->len);\r\nkfree(f);\r\n}\r\n}
