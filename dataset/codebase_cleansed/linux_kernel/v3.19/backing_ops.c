static void gen_spu_event(struct spu_context *ctx, u32 event)\r\n{\r\nu64 ch0_cnt;\r\nu64 ch0_data;\r\nu64 ch1_data;\r\nch0_cnt = ctx->csa.spu_chnlcnt_RW[0];\r\nch0_data = ctx->csa.spu_chnldata_RW[0];\r\nch1_data = ctx->csa.spu_chnldata_RW[1];\r\nctx->csa.spu_chnldata_RW[0] |= event;\r\nif ((ch0_cnt == 0) && !(ch0_data & event) && (ch1_data & event)) {\r\nctx->csa.spu_chnlcnt_RW[0] = 1;\r\n}\r\n}\r\nstatic int spu_backing_mbox_read(struct spu_context *ctx, u32 * data)\r\n{\r\nu32 mbox_stat;\r\nint ret = 0;\r\nspin_lock(&ctx->csa.register_lock);\r\nmbox_stat = ctx->csa.prob.mb_stat_R;\r\nif (mbox_stat & 0x0000ff) {\r\n*data = ctx->csa.prob.pu_mb_R;\r\nctx->csa.prob.mb_stat_R &= ~(0x0000ff);\r\nctx->csa.spu_chnlcnt_RW[28] = 1;\r\ngen_spu_event(ctx, MFC_PU_MAILBOX_AVAILABLE_EVENT);\r\nret = 4;\r\n}\r\nspin_unlock(&ctx->csa.register_lock);\r\nreturn ret;\r\n}\r\nstatic u32 spu_backing_mbox_stat_read(struct spu_context *ctx)\r\n{\r\nreturn ctx->csa.prob.mb_stat_R;\r\n}\r\nstatic unsigned int spu_backing_mbox_stat_poll(struct spu_context *ctx,\r\nunsigned int events)\r\n{\r\nint ret;\r\nu32 stat;\r\nret = 0;\r\nspin_lock_irq(&ctx->csa.register_lock);\r\nstat = ctx->csa.prob.mb_stat_R;\r\nif (events & (POLLIN | POLLRDNORM)) {\r\nif (stat & 0xff0000)\r\nret |= POLLIN | POLLRDNORM;\r\nelse {\r\nctx->csa.priv1.int_stat_class2_RW &=\r\n~CLASS2_MAILBOX_INTR;\r\nctx->csa.priv1.int_mask_class2_RW |=\r\nCLASS2_ENABLE_MAILBOX_INTR;\r\n}\r\n}\r\nif (events & (POLLOUT | POLLWRNORM)) {\r\nif (stat & 0x00ff00)\r\nret = POLLOUT | POLLWRNORM;\r\nelse {\r\nctx->csa.priv1.int_stat_class2_RW &=\r\n~CLASS2_MAILBOX_THRESHOLD_INTR;\r\nctx->csa.priv1.int_mask_class2_RW |=\r\nCLASS2_ENABLE_MAILBOX_THRESHOLD_INTR;\r\n}\r\n}\r\nspin_unlock_irq(&ctx->csa.register_lock);\r\nreturn ret;\r\n}\r\nstatic int spu_backing_ibox_read(struct spu_context *ctx, u32 * data)\r\n{\r\nint ret;\r\nspin_lock(&ctx->csa.register_lock);\r\nif (ctx->csa.prob.mb_stat_R & 0xff0000) {\r\n*data = ctx->csa.priv2.puint_mb_R;\r\nctx->csa.prob.mb_stat_R &= ~(0xff0000);\r\nctx->csa.spu_chnlcnt_RW[30] = 1;\r\ngen_spu_event(ctx, MFC_PU_INT_MAILBOX_AVAILABLE_EVENT);\r\nret = 4;\r\n} else {\r\nctx->csa.priv1.int_mask_class2_RW |= CLASS2_ENABLE_MAILBOX_INTR;\r\nret = 0;\r\n}\r\nspin_unlock(&ctx->csa.register_lock);\r\nreturn ret;\r\n}\r\nstatic int spu_backing_wbox_write(struct spu_context *ctx, u32 data)\r\n{\r\nint ret;\r\nspin_lock(&ctx->csa.register_lock);\r\nif ((ctx->csa.prob.mb_stat_R) & 0x00ff00) {\r\nint slot = ctx->csa.spu_chnlcnt_RW[29];\r\nint avail = (ctx->csa.prob.mb_stat_R & 0x00ff00) >> 8;\r\nBUG_ON(avail != (4 - slot));\r\nctx->csa.spu_mailbox_data[slot] = data;\r\nctx->csa.spu_chnlcnt_RW[29] = ++slot;\r\nctx->csa.prob.mb_stat_R &= ~(0x00ff00);\r\nctx->csa.prob.mb_stat_R |= (((4 - slot) & 0xff) << 8);\r\ngen_spu_event(ctx, MFC_SPU_MAILBOX_WRITTEN_EVENT);\r\nret = 4;\r\n} else {\r\nctx->csa.priv1.int_mask_class2_RW |=\r\nCLASS2_ENABLE_MAILBOX_THRESHOLD_INTR;\r\nret = 0;\r\n}\r\nspin_unlock(&ctx->csa.register_lock);\r\nreturn ret;\r\n}\r\nstatic u32 spu_backing_signal1_read(struct spu_context *ctx)\r\n{\r\nreturn ctx->csa.spu_chnldata_RW[3];\r\n}\r\nstatic void spu_backing_signal1_write(struct spu_context *ctx, u32 data)\r\n{\r\nspin_lock(&ctx->csa.register_lock);\r\nif (ctx->csa.priv2.spu_cfg_RW & 0x1)\r\nctx->csa.spu_chnldata_RW[3] |= data;\r\nelse\r\nctx->csa.spu_chnldata_RW[3] = data;\r\nctx->csa.spu_chnlcnt_RW[3] = 1;\r\ngen_spu_event(ctx, MFC_SIGNAL_1_EVENT);\r\nspin_unlock(&ctx->csa.register_lock);\r\n}\r\nstatic u32 spu_backing_signal2_read(struct spu_context *ctx)\r\n{\r\nreturn ctx->csa.spu_chnldata_RW[4];\r\n}\r\nstatic void spu_backing_signal2_write(struct spu_context *ctx, u32 data)\r\n{\r\nspin_lock(&ctx->csa.register_lock);\r\nif (ctx->csa.priv2.spu_cfg_RW & 0x2)\r\nctx->csa.spu_chnldata_RW[4] |= data;\r\nelse\r\nctx->csa.spu_chnldata_RW[4] = data;\r\nctx->csa.spu_chnlcnt_RW[4] = 1;\r\ngen_spu_event(ctx, MFC_SIGNAL_2_EVENT);\r\nspin_unlock(&ctx->csa.register_lock);\r\n}\r\nstatic void spu_backing_signal1_type_set(struct spu_context *ctx, u64 val)\r\n{\r\nu64 tmp;\r\nspin_lock(&ctx->csa.register_lock);\r\ntmp = ctx->csa.priv2.spu_cfg_RW;\r\nif (val)\r\ntmp |= 1;\r\nelse\r\ntmp &= ~1;\r\nctx->csa.priv2.spu_cfg_RW = tmp;\r\nspin_unlock(&ctx->csa.register_lock);\r\n}\r\nstatic u64 spu_backing_signal1_type_get(struct spu_context *ctx)\r\n{\r\nreturn ((ctx->csa.priv2.spu_cfg_RW & 1) != 0);\r\n}\r\nstatic void spu_backing_signal2_type_set(struct spu_context *ctx, u64 val)\r\n{\r\nu64 tmp;\r\nspin_lock(&ctx->csa.register_lock);\r\ntmp = ctx->csa.priv2.spu_cfg_RW;\r\nif (val)\r\ntmp |= 2;\r\nelse\r\ntmp &= ~2;\r\nctx->csa.priv2.spu_cfg_RW = tmp;\r\nspin_unlock(&ctx->csa.register_lock);\r\n}\r\nstatic u64 spu_backing_signal2_type_get(struct spu_context *ctx)\r\n{\r\nreturn ((ctx->csa.priv2.spu_cfg_RW & 2) != 0);\r\n}\r\nstatic u32 spu_backing_npc_read(struct spu_context *ctx)\r\n{\r\nreturn ctx->csa.prob.spu_npc_RW;\r\n}\r\nstatic void spu_backing_npc_write(struct spu_context *ctx, u32 val)\r\n{\r\nctx->csa.prob.spu_npc_RW = val;\r\n}\r\nstatic u32 spu_backing_status_read(struct spu_context *ctx)\r\n{\r\nreturn ctx->csa.prob.spu_status_R;\r\n}\r\nstatic char *spu_backing_get_ls(struct spu_context *ctx)\r\n{\r\nreturn ctx->csa.lscsa->ls;\r\n}\r\nstatic void spu_backing_privcntl_write(struct spu_context *ctx, u64 val)\r\n{\r\nctx->csa.priv2.spu_privcntl_RW = val;\r\n}\r\nstatic u32 spu_backing_runcntl_read(struct spu_context *ctx)\r\n{\r\nreturn ctx->csa.prob.spu_runcntl_RW;\r\n}\r\nstatic void spu_backing_runcntl_write(struct spu_context *ctx, u32 val)\r\n{\r\nspin_lock(&ctx->csa.register_lock);\r\nctx->csa.prob.spu_runcntl_RW = val;\r\nif (val & SPU_RUNCNTL_RUNNABLE) {\r\nctx->csa.prob.spu_status_R &=\r\n~SPU_STATUS_STOPPED_BY_STOP &\r\n~SPU_STATUS_STOPPED_BY_HALT &\r\n~SPU_STATUS_SINGLE_STEP &\r\n~SPU_STATUS_INVALID_INSTR &\r\n~SPU_STATUS_INVALID_CH;\r\nctx->csa.prob.spu_status_R |= SPU_STATUS_RUNNING;\r\n} else {\r\nctx->csa.prob.spu_status_R &= ~SPU_STATUS_RUNNING;\r\n}\r\nspin_unlock(&ctx->csa.register_lock);\r\n}\r\nstatic void spu_backing_runcntl_stop(struct spu_context *ctx)\r\n{\r\nspu_backing_runcntl_write(ctx, SPU_RUNCNTL_STOP);\r\n}\r\nstatic void spu_backing_master_start(struct spu_context *ctx)\r\n{\r\nstruct spu_state *csa = &ctx->csa;\r\nu64 sr1;\r\nspin_lock(&csa->register_lock);\r\nsr1 = csa->priv1.mfc_sr1_RW | MFC_STATE1_MASTER_RUN_CONTROL_MASK;\r\ncsa->priv1.mfc_sr1_RW = sr1;\r\nspin_unlock(&csa->register_lock);\r\n}\r\nstatic void spu_backing_master_stop(struct spu_context *ctx)\r\n{\r\nstruct spu_state *csa = &ctx->csa;\r\nu64 sr1;\r\nspin_lock(&csa->register_lock);\r\nsr1 = csa->priv1.mfc_sr1_RW & ~MFC_STATE1_MASTER_RUN_CONTROL_MASK;\r\ncsa->priv1.mfc_sr1_RW = sr1;\r\nspin_unlock(&csa->register_lock);\r\n}\r\nstatic int spu_backing_set_mfc_query(struct spu_context * ctx, u32 mask,\r\nu32 mode)\r\n{\r\nstruct spu_problem_collapsed *prob = &ctx->csa.prob;\r\nint ret;\r\nspin_lock(&ctx->csa.register_lock);\r\nret = -EAGAIN;\r\nif (prob->dma_querytype_RW)\r\ngoto out;\r\nret = 0;\r\nprob->dma_querymask_RW = mask;\r\nprob->dma_querytype_RW = mode;\r\nctx->csa.prob.dma_tagstatus_R &= mask;\r\nout:\r\nspin_unlock(&ctx->csa.register_lock);\r\nreturn ret;\r\n}\r\nstatic u32 spu_backing_read_mfc_tagstatus(struct spu_context * ctx)\r\n{\r\nreturn ctx->csa.prob.dma_tagstatus_R;\r\n}\r\nstatic u32 spu_backing_get_mfc_free_elements(struct spu_context *ctx)\r\n{\r\nreturn ctx->csa.prob.dma_qstatus_R;\r\n}\r\nstatic int spu_backing_send_mfc_command(struct spu_context *ctx,\r\nstruct mfc_dma_command *cmd)\r\n{\r\nint ret;\r\nspin_lock(&ctx->csa.register_lock);\r\nret = -EAGAIN;\r\nspin_unlock(&ctx->csa.register_lock);\r\nreturn ret;\r\n}\r\nstatic void spu_backing_restart_dma(struct spu_context *ctx)\r\n{\r\nctx->csa.priv2.mfc_control_RW |= MFC_CNTL_RESTART_DMA_COMMAND;\r\n}
