static bool tcp_in_window(u32 seq, u32 end_seq, u32 s_win, u32 e_win)\r\n{\r\nif (seq == s_win)\r\nreturn true;\r\nif (after(end_seq, s_win) && before(seq, e_win))\r\nreturn true;\r\nreturn seq == e_win && seq == end_seq;\r\n}\r\nenum tcp_tw_status\r\ntcp_timewait_state_process(struct inet_timewait_sock *tw, struct sk_buff *skb,\r\nconst struct tcphdr *th)\r\n{\r\nstruct tcp_options_received tmp_opt;\r\nstruct tcp_timewait_sock *tcptw = tcp_twsk((struct sock *)tw);\r\nbool paws_reject = false;\r\ntmp_opt.saw_tstamp = 0;\r\nif (th->doff > (sizeof(*th) >> 2) && tcptw->tw_ts_recent_stamp) {\r\ntcp_parse_options(skb, &tmp_opt, 0, NULL);\r\nif (tmp_opt.saw_tstamp) {\r\ntmp_opt.rcv_tsecr -= tcptw->tw_ts_offset;\r\ntmp_opt.ts_recent = tcptw->tw_ts_recent;\r\ntmp_opt.ts_recent_stamp = tcptw->tw_ts_recent_stamp;\r\npaws_reject = tcp_paws_reject(&tmp_opt, th->rst);\r\n}\r\n}\r\nif (tw->tw_substate == TCP_FIN_WAIT2) {\r\nif (paws_reject ||\r\n!tcp_in_window(TCP_SKB_CB(skb)->seq, TCP_SKB_CB(skb)->end_seq,\r\ntcptw->tw_rcv_nxt,\r\ntcptw->tw_rcv_nxt + tcptw->tw_rcv_wnd))\r\nreturn TCP_TW_ACK;\r\nif (th->rst)\r\ngoto kill;\r\nif (th->syn && !before(TCP_SKB_CB(skb)->seq, tcptw->tw_rcv_nxt))\r\ngoto kill_with_rst;\r\nif (!th->ack ||\r\n!after(TCP_SKB_CB(skb)->end_seq, tcptw->tw_rcv_nxt) ||\r\nTCP_SKB_CB(skb)->end_seq == TCP_SKB_CB(skb)->seq) {\r\ninet_twsk_put(tw);\r\nreturn TCP_TW_SUCCESS;\r\n}\r\nif (!th->fin ||\r\nTCP_SKB_CB(skb)->end_seq != tcptw->tw_rcv_nxt + 1) {\r\nkill_with_rst:\r\ninet_twsk_deschedule(tw, &tcp_death_row);\r\ninet_twsk_put(tw);\r\nreturn TCP_TW_RST;\r\n}\r\ntw->tw_substate = TCP_TIME_WAIT;\r\ntcptw->tw_rcv_nxt = TCP_SKB_CB(skb)->end_seq;\r\nif (tmp_opt.saw_tstamp) {\r\ntcptw->tw_ts_recent_stamp = get_seconds();\r\ntcptw->tw_ts_recent = tmp_opt.rcv_tsval;\r\n}\r\nif (tcp_death_row.sysctl_tw_recycle &&\r\ntcptw->tw_ts_recent_stamp &&\r\ntcp_tw_remember_stamp(tw))\r\ninet_twsk_schedule(tw, &tcp_death_row, tw->tw_timeout,\r\nTCP_TIMEWAIT_LEN);\r\nelse\r\ninet_twsk_schedule(tw, &tcp_death_row, TCP_TIMEWAIT_LEN,\r\nTCP_TIMEWAIT_LEN);\r\nreturn TCP_TW_ACK;\r\n}\r\nif (!paws_reject &&\r\n(TCP_SKB_CB(skb)->seq == tcptw->tw_rcv_nxt &&\r\n(TCP_SKB_CB(skb)->seq == TCP_SKB_CB(skb)->end_seq || th->rst))) {\r\nif (th->rst) {\r\nif (sysctl_tcp_rfc1337 == 0) {\r\nkill:\r\ninet_twsk_deschedule(tw, &tcp_death_row);\r\ninet_twsk_put(tw);\r\nreturn TCP_TW_SUCCESS;\r\n}\r\n}\r\ninet_twsk_schedule(tw, &tcp_death_row, TCP_TIMEWAIT_LEN,\r\nTCP_TIMEWAIT_LEN);\r\nif (tmp_opt.saw_tstamp) {\r\ntcptw->tw_ts_recent = tmp_opt.rcv_tsval;\r\ntcptw->tw_ts_recent_stamp = get_seconds();\r\n}\r\ninet_twsk_put(tw);\r\nreturn TCP_TW_SUCCESS;\r\n}\r\nif (th->syn && !th->rst && !th->ack && !paws_reject &&\r\n(after(TCP_SKB_CB(skb)->seq, tcptw->tw_rcv_nxt) ||\r\n(tmp_opt.saw_tstamp &&\r\n(s32)(tcptw->tw_ts_recent - tmp_opt.rcv_tsval) < 0))) {\r\nu32 isn = tcptw->tw_snd_nxt + 65535 + 2;\r\nif (isn == 0)\r\nisn++;\r\nTCP_SKB_CB(skb)->tcp_tw_isn = isn;\r\nreturn TCP_TW_SYN;\r\n}\r\nif (paws_reject)\r\nNET_INC_STATS_BH(twsk_net(tw), LINUX_MIB_PAWSESTABREJECTED);\r\nif (!th->rst) {\r\nif (paws_reject || th->ack)\r\ninet_twsk_schedule(tw, &tcp_death_row, TCP_TIMEWAIT_LEN,\r\nTCP_TIMEWAIT_LEN);\r\nreturn TCP_TW_ACK;\r\n}\r\ninet_twsk_put(tw);\r\nreturn TCP_TW_SUCCESS;\r\n}\r\nvoid tcp_time_wait(struct sock *sk, int state, int timeo)\r\n{\r\nstruct inet_timewait_sock *tw = NULL;\r\nconst struct inet_connection_sock *icsk = inet_csk(sk);\r\nconst struct tcp_sock *tp = tcp_sk(sk);\r\nbool recycle_ok = false;\r\nif (tcp_death_row.sysctl_tw_recycle && tp->rx_opt.ts_recent_stamp)\r\nrecycle_ok = tcp_remember_stamp(sk);\r\nif (tcp_death_row.tw_count < tcp_death_row.sysctl_max_tw_buckets)\r\ntw = inet_twsk_alloc(sk, state);\r\nif (tw != NULL) {\r\nstruct tcp_timewait_sock *tcptw = tcp_twsk((struct sock *)tw);\r\nconst int rto = (icsk->icsk_rto << 2) - (icsk->icsk_rto >> 1);\r\nstruct inet_sock *inet = inet_sk(sk);\r\ntw->tw_transparent = inet->transparent;\r\ntw->tw_rcv_wscale = tp->rx_opt.rcv_wscale;\r\ntcptw->tw_rcv_nxt = tp->rcv_nxt;\r\ntcptw->tw_snd_nxt = tp->snd_nxt;\r\ntcptw->tw_rcv_wnd = tcp_receive_window(tp);\r\ntcptw->tw_ts_recent = tp->rx_opt.ts_recent;\r\ntcptw->tw_ts_recent_stamp = tp->rx_opt.ts_recent_stamp;\r\ntcptw->tw_ts_offset = tp->tsoffset;\r\n#if IS_ENABLED(CONFIG_IPV6)\r\nif (tw->tw_family == PF_INET6) {\r\nstruct ipv6_pinfo *np = inet6_sk(sk);\r\ntw->tw_v6_daddr = sk->sk_v6_daddr;\r\ntw->tw_v6_rcv_saddr = sk->sk_v6_rcv_saddr;\r\ntw->tw_tclass = np->tclass;\r\ntw->tw_flowlabel = np->flow_label >> 12;\r\ntw->tw_ipv6only = sk->sk_ipv6only;\r\n}\r\n#endif\r\n#ifdef CONFIG_TCP_MD5SIG\r\ndo {\r\nstruct tcp_md5sig_key *key;\r\ntcptw->tw_md5_key = NULL;\r\nkey = tp->af_specific->md5_lookup(sk, sk);\r\nif (key != NULL) {\r\ntcptw->tw_md5_key = kmemdup(key, sizeof(*key), GFP_ATOMIC);\r\nif (tcptw->tw_md5_key && !tcp_alloc_md5sig_pool())\r\nBUG();\r\n}\r\n} while (0);\r\n#endif\r\n__inet_twsk_hashdance(tw, sk, &tcp_hashinfo);\r\nif (timeo < rto)\r\ntimeo = rto;\r\nif (recycle_ok) {\r\ntw->tw_timeout = rto;\r\n} else {\r\ntw->tw_timeout = TCP_TIMEWAIT_LEN;\r\nif (state == TCP_TIME_WAIT)\r\ntimeo = TCP_TIMEWAIT_LEN;\r\n}\r\ninet_twsk_schedule(tw, &tcp_death_row, timeo,\r\nTCP_TIMEWAIT_LEN);\r\ninet_twsk_put(tw);\r\n} else {\r\nNET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPTIMEWAITOVERFLOW);\r\n}\r\ntcp_update_metrics(sk);\r\ntcp_done(sk);\r\n}\r\nvoid tcp_twsk_destructor(struct sock *sk)\r\n{\r\n#ifdef CONFIG_TCP_MD5SIG\r\nstruct tcp_timewait_sock *twsk = tcp_twsk(sk);\r\nif (twsk->tw_md5_key)\r\nkfree_rcu(twsk->tw_md5_key, rcu);\r\n#endif\r\n}\r\nvoid tcp_openreq_init_rwin(struct request_sock *req,\r\nstruct sock *sk, struct dst_entry *dst)\r\n{\r\nstruct inet_request_sock *ireq = inet_rsk(req);\r\nstruct tcp_sock *tp = tcp_sk(sk);\r\n__u8 rcv_wscale;\r\nint mss = dst_metric_advmss(dst);\r\nif (tp->rx_opt.user_mss && tp->rx_opt.user_mss < mss)\r\nmss = tp->rx_opt.user_mss;\r\nreq->window_clamp = tp->window_clamp ? : dst_metric(dst, RTAX_WINDOW);\r\nif (sk->sk_userlocks & SOCK_RCVBUF_LOCK &&\r\n(req->window_clamp > tcp_full_space(sk) || req->window_clamp == 0))\r\nreq->window_clamp = tcp_full_space(sk);\r\ntcp_select_initial_window(tcp_full_space(sk),\r\nmss - (ireq->tstamp_ok ? TCPOLEN_TSTAMP_ALIGNED : 0),\r\n&req->rcv_wnd,\r\n&req->window_clamp,\r\nireq->wscale_ok,\r\n&rcv_wscale,\r\ndst_metric(dst, RTAX_INITRWND));\r\nireq->rcv_wscale = rcv_wscale;\r\n}\r\nstatic void tcp_ecn_openreq_child(struct tcp_sock *tp,\r\nconst struct request_sock *req)\r\n{\r\ntp->ecn_flags = inet_rsk(req)->ecn_ok ? TCP_ECN_OK : 0;\r\n}\r\nstruct sock *tcp_create_openreq_child(struct sock *sk, struct request_sock *req, struct sk_buff *skb)\r\n{\r\nstruct sock *newsk = inet_csk_clone_lock(sk, req, GFP_ATOMIC);\r\nif (newsk != NULL) {\r\nconst struct inet_request_sock *ireq = inet_rsk(req);\r\nstruct tcp_request_sock *treq = tcp_rsk(req);\r\nstruct inet_connection_sock *newicsk = inet_csk(newsk);\r\nstruct tcp_sock *newtp = tcp_sk(newsk);\r\nnewtp->pred_flags = 0;\r\nnewtp->rcv_wup = newtp->copied_seq =\r\nnewtp->rcv_nxt = treq->rcv_isn + 1;\r\nnewtp->snd_sml = newtp->snd_una =\r\nnewtp->snd_nxt = newtp->snd_up = treq->snt_isn + 1;\r\ntcp_prequeue_init(newtp);\r\nINIT_LIST_HEAD(&newtp->tsq_node);\r\ntcp_init_wl(newtp, treq->rcv_isn);\r\nnewtp->srtt_us = 0;\r\nnewtp->mdev_us = jiffies_to_usecs(TCP_TIMEOUT_INIT);\r\nnewicsk->icsk_rto = TCP_TIMEOUT_INIT;\r\nnewtp->packets_out = 0;\r\nnewtp->retrans_out = 0;\r\nnewtp->sacked_out = 0;\r\nnewtp->fackets_out = 0;\r\nnewtp->snd_ssthresh = TCP_INFINITE_SSTHRESH;\r\ntcp_enable_early_retrans(newtp);\r\nnewtp->tlp_high_seq = 0;\r\nnewtp->lsndtime = treq->snt_synack;\r\nnewtp->total_retrans = req->num_retrans;\r\nnewtp->snd_cwnd = TCP_INIT_CWND;\r\nnewtp->snd_cwnd_cnt = 0;\r\nif (!try_module_get(newicsk->icsk_ca_ops->owner))\r\ntcp_assign_congestion_control(newsk);\r\ntcp_set_ca_state(newsk, TCP_CA_Open);\r\ntcp_init_xmit_timers(newsk);\r\n__skb_queue_head_init(&newtp->out_of_order_queue);\r\nnewtp->write_seq = newtp->pushed_seq = treq->snt_isn + 1;\r\nnewtp->rx_opt.saw_tstamp = 0;\r\nnewtp->rx_opt.dsack = 0;\r\nnewtp->rx_opt.num_sacks = 0;\r\nnewtp->urg_data = 0;\r\nif (sock_flag(newsk, SOCK_KEEPOPEN))\r\ninet_csk_reset_keepalive_timer(newsk,\r\nkeepalive_time_when(newtp));\r\nnewtp->rx_opt.tstamp_ok = ireq->tstamp_ok;\r\nif ((newtp->rx_opt.sack_ok = ireq->sack_ok) != 0) {\r\nif (sysctl_tcp_fack)\r\ntcp_enable_fack(newtp);\r\n}\r\nnewtp->window_clamp = req->window_clamp;\r\nnewtp->rcv_ssthresh = req->rcv_wnd;\r\nnewtp->rcv_wnd = req->rcv_wnd;\r\nnewtp->rx_opt.wscale_ok = ireq->wscale_ok;\r\nif (newtp->rx_opt.wscale_ok) {\r\nnewtp->rx_opt.snd_wscale = ireq->snd_wscale;\r\nnewtp->rx_opt.rcv_wscale = ireq->rcv_wscale;\r\n} else {\r\nnewtp->rx_opt.snd_wscale = newtp->rx_opt.rcv_wscale = 0;\r\nnewtp->window_clamp = min(newtp->window_clamp, 65535U);\r\n}\r\nnewtp->snd_wnd = (ntohs(tcp_hdr(skb)->window) <<\r\nnewtp->rx_opt.snd_wscale);\r\nnewtp->max_window = newtp->snd_wnd;\r\nif (newtp->rx_opt.tstamp_ok) {\r\nnewtp->rx_opt.ts_recent = req->ts_recent;\r\nnewtp->rx_opt.ts_recent_stamp = get_seconds();\r\nnewtp->tcp_header_len = sizeof(struct tcphdr) + TCPOLEN_TSTAMP_ALIGNED;\r\n} else {\r\nnewtp->rx_opt.ts_recent_stamp = 0;\r\nnewtp->tcp_header_len = sizeof(struct tcphdr);\r\n}\r\nnewtp->tsoffset = 0;\r\n#ifdef CONFIG_TCP_MD5SIG\r\nnewtp->md5sig_info = NULL;\r\nif (newtp->af_specific->md5_lookup(sk, newsk))\r\nnewtp->tcp_header_len += TCPOLEN_MD5SIG_ALIGNED;\r\n#endif\r\nif (skb->len >= TCP_MSS_DEFAULT + newtp->tcp_header_len)\r\nnewicsk->icsk_ack.last_seg_size = skb->len - newtp->tcp_header_len;\r\nnewtp->rx_opt.mss_clamp = req->mss;\r\ntcp_ecn_openreq_child(newtp, req);\r\nnewtp->fastopen_rsk = NULL;\r\nnewtp->syn_data_acked = 0;\r\nTCP_INC_STATS_BH(sock_net(sk), TCP_MIB_PASSIVEOPENS);\r\n}\r\nreturn newsk;\r\n}\r\nstruct sock *tcp_check_req(struct sock *sk, struct sk_buff *skb,\r\nstruct request_sock *req,\r\nstruct request_sock **prev,\r\nbool fastopen)\r\n{\r\nstruct tcp_options_received tmp_opt;\r\nstruct sock *child;\r\nconst struct tcphdr *th = tcp_hdr(skb);\r\n__be32 flg = tcp_flag_word(th) & (TCP_FLAG_RST|TCP_FLAG_SYN|TCP_FLAG_ACK);\r\nbool paws_reject = false;\r\nBUG_ON(fastopen == (sk->sk_state == TCP_LISTEN));\r\ntmp_opt.saw_tstamp = 0;\r\nif (th->doff > (sizeof(struct tcphdr)>>2)) {\r\ntcp_parse_options(skb, &tmp_opt, 0, NULL);\r\nif (tmp_opt.saw_tstamp) {\r\ntmp_opt.ts_recent = req->ts_recent;\r\ntmp_opt.ts_recent_stamp = get_seconds() - ((TCP_TIMEOUT_INIT/HZ)<<req->num_timeout);\r\npaws_reject = tcp_paws_reject(&tmp_opt, th->rst);\r\n}\r\n}\r\nif (TCP_SKB_CB(skb)->seq == tcp_rsk(req)->rcv_isn &&\r\nflg == TCP_FLAG_SYN &&\r\n!paws_reject) {\r\nif (!inet_rtx_syn_ack(sk, req))\r\nreq->expires = min(TCP_TIMEOUT_INIT << req->num_timeout,\r\nTCP_RTO_MAX) + jiffies;\r\nreturn NULL;\r\n}\r\nif ((flg & TCP_FLAG_ACK) && !fastopen &&\r\n(TCP_SKB_CB(skb)->ack_seq !=\r\ntcp_rsk(req)->snt_isn + 1))\r\nreturn sk;\r\nif (paws_reject || !tcp_in_window(TCP_SKB_CB(skb)->seq, TCP_SKB_CB(skb)->end_seq,\r\ntcp_rsk(req)->rcv_nxt, tcp_rsk(req)->rcv_nxt + req->rcv_wnd)) {\r\nif (!(flg & TCP_FLAG_RST))\r\nreq->rsk_ops->send_ack(sk, skb, req);\r\nif (paws_reject)\r\nNET_INC_STATS_BH(sock_net(sk), LINUX_MIB_PAWSESTABREJECTED);\r\nreturn NULL;\r\n}\r\nif (tmp_opt.saw_tstamp && !after(TCP_SKB_CB(skb)->seq, tcp_rsk(req)->rcv_nxt))\r\nreq->ts_recent = tmp_opt.rcv_tsval;\r\nif (TCP_SKB_CB(skb)->seq == tcp_rsk(req)->rcv_isn) {\r\nflg &= ~TCP_FLAG_SYN;\r\n}\r\nif (flg & (TCP_FLAG_RST|TCP_FLAG_SYN)) {\r\nTCP_INC_STATS_BH(sock_net(sk), TCP_MIB_ATTEMPTFAILS);\r\ngoto embryonic_reset;\r\n}\r\nif (!(flg & TCP_FLAG_ACK))\r\nreturn NULL;\r\nif (fastopen)\r\nreturn sk;\r\nif (req->num_timeout < inet_csk(sk)->icsk_accept_queue.rskq_defer_accept &&\r\nTCP_SKB_CB(skb)->end_seq == tcp_rsk(req)->rcv_isn + 1) {\r\ninet_rsk(req)->acked = 1;\r\nNET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPDEFERACCEPTDROP);\r\nreturn NULL;\r\n}\r\nchild = inet_csk(sk)->icsk_af_ops->syn_recv_sock(sk, skb, req, NULL);\r\nif (child == NULL)\r\ngoto listen_overflow;\r\ninet_csk_reqsk_queue_unlink(sk, req, prev);\r\ninet_csk_reqsk_queue_removed(sk, req);\r\ninet_csk_reqsk_queue_add(sk, req, child);\r\nreturn child;\r\nlisten_overflow:\r\nif (!sysctl_tcp_abort_on_overflow) {\r\ninet_rsk(req)->acked = 1;\r\nreturn NULL;\r\n}\r\nembryonic_reset:\r\nif (!(flg & TCP_FLAG_RST)) {\r\nreq->rsk_ops->send_reset(sk, skb);\r\n} else if (fastopen) {\r\nreqsk_fastopen_remove(sk, req, true);\r\ntcp_reset(sk);\r\n}\r\nif (!fastopen) {\r\ninet_csk_reqsk_queue_drop(sk, req, prev);\r\nNET_INC_STATS_BH(sock_net(sk), LINUX_MIB_EMBRYONICRSTS);\r\n}\r\nreturn NULL;\r\n}\r\nint tcp_child_process(struct sock *parent, struct sock *child,\r\nstruct sk_buff *skb)\r\n{\r\nint ret = 0;\r\nint state = child->sk_state;\r\nif (!sock_owned_by_user(child)) {\r\nret = tcp_rcv_state_process(child, skb, tcp_hdr(skb),\r\nskb->len);\r\nif (state == TCP_SYN_RECV && child->sk_state != state)\r\nparent->sk_data_ready(parent);\r\n} else {\r\n__sk_add_backlog(child, skb);\r\n}\r\nbh_unlock_sock(child);\r\nsock_put(child);\r\nreturn ret;\r\n}
