static struct attribute_group *get_sysfs_attr(struct dbs_data *dbs_data)\r\n{\r\nif (have_governor_per_policy())\r\nreturn dbs_data->cdata->attr_group_gov_pol;\r\nelse\r\nreturn dbs_data->cdata->attr_group_gov_sys;\r\n}\r\nvoid dbs_check_cpu(struct dbs_data *dbs_data, int cpu)\r\n{\r\nstruct cpu_dbs_common_info *cdbs = dbs_data->cdata->get_cpu_cdbs(cpu);\r\nstruct od_dbs_tuners *od_tuners = dbs_data->tuners;\r\nstruct cs_dbs_tuners *cs_tuners = dbs_data->tuners;\r\nstruct cpufreq_policy *policy;\r\nunsigned int sampling_rate;\r\nunsigned int max_load = 0;\r\nunsigned int ignore_nice;\r\nunsigned int j;\r\nif (dbs_data->cdata->governor == GOV_ONDEMAND) {\r\nstruct od_cpu_dbs_info_s *od_dbs_info =\r\ndbs_data->cdata->get_cpu_dbs_info_s(cpu);\r\nsampling_rate = od_tuners->sampling_rate;\r\nsampling_rate *= od_dbs_info->rate_mult;\r\nignore_nice = od_tuners->ignore_nice_load;\r\n} else {\r\nsampling_rate = cs_tuners->sampling_rate;\r\nignore_nice = cs_tuners->ignore_nice_load;\r\n}\r\npolicy = cdbs->cur_policy;\r\nfor_each_cpu(j, policy->cpus) {\r\nstruct cpu_dbs_common_info *j_cdbs;\r\nu64 cur_wall_time, cur_idle_time;\r\nunsigned int idle_time, wall_time;\r\nunsigned int load;\r\nint io_busy = 0;\r\nj_cdbs = dbs_data->cdata->get_cpu_cdbs(j);\r\nif (dbs_data->cdata->governor == GOV_ONDEMAND)\r\nio_busy = od_tuners->io_is_busy;\r\ncur_idle_time = get_cpu_idle_time(j, &cur_wall_time, io_busy);\r\nwall_time = (unsigned int)\r\n(cur_wall_time - j_cdbs->prev_cpu_wall);\r\nj_cdbs->prev_cpu_wall = cur_wall_time;\r\nidle_time = (unsigned int)\r\n(cur_idle_time - j_cdbs->prev_cpu_idle);\r\nj_cdbs->prev_cpu_idle = cur_idle_time;\r\nif (ignore_nice) {\r\nu64 cur_nice;\r\nunsigned long cur_nice_jiffies;\r\ncur_nice = kcpustat_cpu(j).cpustat[CPUTIME_NICE] -\r\ncdbs->prev_cpu_nice;\r\ncur_nice_jiffies = (unsigned long)\r\ncputime64_to_jiffies64(cur_nice);\r\ncdbs->prev_cpu_nice =\r\nkcpustat_cpu(j).cpustat[CPUTIME_NICE];\r\nidle_time += jiffies_to_usecs(cur_nice_jiffies);\r\n}\r\nif (unlikely(!wall_time || wall_time < idle_time))\r\ncontinue;\r\nif (unlikely(wall_time > (2 * sampling_rate) &&\r\nj_cdbs->prev_load)) {\r\nload = j_cdbs->prev_load;\r\nj_cdbs->prev_load = 0;\r\n} else {\r\nload = 100 * (wall_time - idle_time) / wall_time;\r\nj_cdbs->prev_load = load;\r\n}\r\nif (load > max_load)\r\nmax_load = load;\r\n}\r\ndbs_data->cdata->gov_check_cpu(cpu, max_load);\r\n}\r\nstatic inline void __gov_queue_work(int cpu, struct dbs_data *dbs_data,\r\nunsigned int delay)\r\n{\r\nstruct cpu_dbs_common_info *cdbs = dbs_data->cdata->get_cpu_cdbs(cpu);\r\nmod_delayed_work_on(cpu, system_wq, &cdbs->work, delay);\r\n}\r\nvoid gov_queue_work(struct dbs_data *dbs_data, struct cpufreq_policy *policy,\r\nunsigned int delay, bool all_cpus)\r\n{\r\nint i;\r\nmutex_lock(&cpufreq_governor_lock);\r\nif (!policy->governor_enabled)\r\ngoto out_unlock;\r\nif (!all_cpus) {\r\n__gov_queue_work(raw_smp_processor_id(), dbs_data, delay);\r\n} else {\r\nfor_each_cpu(i, policy->cpus)\r\n__gov_queue_work(i, dbs_data, delay);\r\n}\r\nout_unlock:\r\nmutex_unlock(&cpufreq_governor_lock);\r\n}\r\nstatic inline void gov_cancel_work(struct dbs_data *dbs_data,\r\nstruct cpufreq_policy *policy)\r\n{\r\nstruct cpu_dbs_common_info *cdbs;\r\nint i;\r\nfor_each_cpu(i, policy->cpus) {\r\ncdbs = dbs_data->cdata->get_cpu_cdbs(i);\r\ncancel_delayed_work_sync(&cdbs->work);\r\n}\r\n}\r\nbool need_load_eval(struct cpu_dbs_common_info *cdbs,\r\nunsigned int sampling_rate)\r\n{\r\nif (policy_is_shared(cdbs->cur_policy)) {\r\nktime_t time_now = ktime_get();\r\ns64 delta_us = ktime_us_delta(time_now, cdbs->time_stamp);\r\nif (delta_us < (s64)(sampling_rate / 2))\r\nreturn false;\r\nelse\r\ncdbs->time_stamp = time_now;\r\n}\r\nreturn true;\r\n}\r\nstatic void set_sampling_rate(struct dbs_data *dbs_data,\r\nunsigned int sampling_rate)\r\n{\r\nif (dbs_data->cdata->governor == GOV_CONSERVATIVE) {\r\nstruct cs_dbs_tuners *cs_tuners = dbs_data->tuners;\r\ncs_tuners->sampling_rate = sampling_rate;\r\n} else {\r\nstruct od_dbs_tuners *od_tuners = dbs_data->tuners;\r\nod_tuners->sampling_rate = sampling_rate;\r\n}\r\n}\r\nint cpufreq_governor_dbs(struct cpufreq_policy *policy,\r\nstruct common_dbs_data *cdata, unsigned int event)\r\n{\r\nstruct dbs_data *dbs_data;\r\nstruct od_cpu_dbs_info_s *od_dbs_info = NULL;\r\nstruct cs_cpu_dbs_info_s *cs_dbs_info = NULL;\r\nstruct od_ops *od_ops = NULL;\r\nstruct od_dbs_tuners *od_tuners = NULL;\r\nstruct cs_dbs_tuners *cs_tuners = NULL;\r\nstruct cpu_dbs_common_info *cpu_cdbs;\r\nunsigned int sampling_rate, latency, ignore_nice, j, cpu = policy->cpu;\r\nint io_busy = 0;\r\nint rc;\r\nif (have_governor_per_policy())\r\ndbs_data = policy->governor_data;\r\nelse\r\ndbs_data = cdata->gdbs_data;\r\nWARN_ON(!dbs_data && (event != CPUFREQ_GOV_POLICY_INIT));\r\nswitch (event) {\r\ncase CPUFREQ_GOV_POLICY_INIT:\r\nif (have_governor_per_policy()) {\r\nWARN_ON(dbs_data);\r\n} else if (dbs_data) {\r\ndbs_data->usage_count++;\r\npolicy->governor_data = dbs_data;\r\nreturn 0;\r\n}\r\ndbs_data = kzalloc(sizeof(*dbs_data), GFP_KERNEL);\r\nif (!dbs_data) {\r\npr_err("%s: POLICY_INIT: kzalloc failed\n", __func__);\r\nreturn -ENOMEM;\r\n}\r\ndbs_data->cdata = cdata;\r\ndbs_data->usage_count = 1;\r\nrc = cdata->init(dbs_data);\r\nif (rc) {\r\npr_err("%s: POLICY_INIT: init() failed\n", __func__);\r\nkfree(dbs_data);\r\nreturn rc;\r\n}\r\nif (!have_governor_per_policy())\r\nWARN_ON(cpufreq_get_global_kobject());\r\nrc = sysfs_create_group(get_governor_parent_kobj(policy),\r\nget_sysfs_attr(dbs_data));\r\nif (rc) {\r\ncdata->exit(dbs_data);\r\nkfree(dbs_data);\r\nreturn rc;\r\n}\r\npolicy->governor_data = dbs_data;\r\nlatency = policy->cpuinfo.transition_latency / 1000;\r\nif (latency == 0)\r\nlatency = 1;\r\ndbs_data->min_sampling_rate = max(dbs_data->min_sampling_rate,\r\nMIN_LATENCY_MULTIPLIER * latency);\r\nset_sampling_rate(dbs_data, max(dbs_data->min_sampling_rate,\r\nlatency * LATENCY_MULTIPLIER));\r\nif ((cdata->governor == GOV_CONSERVATIVE) &&\r\n(!policy->governor->initialized)) {\r\nstruct cs_ops *cs_ops = dbs_data->cdata->gov_ops;\r\ncpufreq_register_notifier(cs_ops->notifier_block,\r\nCPUFREQ_TRANSITION_NOTIFIER);\r\n}\r\nif (!have_governor_per_policy())\r\ncdata->gdbs_data = dbs_data;\r\nreturn 0;\r\ncase CPUFREQ_GOV_POLICY_EXIT:\r\nif (!--dbs_data->usage_count) {\r\nsysfs_remove_group(get_governor_parent_kobj(policy),\r\nget_sysfs_attr(dbs_data));\r\nif (!have_governor_per_policy())\r\ncpufreq_put_global_kobject();\r\nif ((dbs_data->cdata->governor == GOV_CONSERVATIVE) &&\r\n(policy->governor->initialized == 1)) {\r\nstruct cs_ops *cs_ops = dbs_data->cdata->gov_ops;\r\ncpufreq_unregister_notifier(cs_ops->notifier_block,\r\nCPUFREQ_TRANSITION_NOTIFIER);\r\n}\r\ncdata->exit(dbs_data);\r\nkfree(dbs_data);\r\ncdata->gdbs_data = NULL;\r\n}\r\npolicy->governor_data = NULL;\r\nreturn 0;\r\n}\r\ncpu_cdbs = dbs_data->cdata->get_cpu_cdbs(cpu);\r\nif (dbs_data->cdata->governor == GOV_CONSERVATIVE) {\r\ncs_tuners = dbs_data->tuners;\r\ncs_dbs_info = dbs_data->cdata->get_cpu_dbs_info_s(cpu);\r\nsampling_rate = cs_tuners->sampling_rate;\r\nignore_nice = cs_tuners->ignore_nice_load;\r\n} else {\r\nod_tuners = dbs_data->tuners;\r\nod_dbs_info = dbs_data->cdata->get_cpu_dbs_info_s(cpu);\r\nsampling_rate = od_tuners->sampling_rate;\r\nignore_nice = od_tuners->ignore_nice_load;\r\nod_ops = dbs_data->cdata->gov_ops;\r\nio_busy = od_tuners->io_is_busy;\r\n}\r\nswitch (event) {\r\ncase CPUFREQ_GOV_START:\r\nif (!policy->cur)\r\nreturn -EINVAL;\r\nmutex_lock(&dbs_data->mutex);\r\nfor_each_cpu(j, policy->cpus) {\r\nstruct cpu_dbs_common_info *j_cdbs =\r\ndbs_data->cdata->get_cpu_cdbs(j);\r\nunsigned int prev_load;\r\nj_cdbs->cpu = j;\r\nj_cdbs->cur_policy = policy;\r\nj_cdbs->prev_cpu_idle = get_cpu_idle_time(j,\r\n&j_cdbs->prev_cpu_wall, io_busy);\r\nprev_load = (unsigned int)\r\n(j_cdbs->prev_cpu_wall - j_cdbs->prev_cpu_idle);\r\nj_cdbs->prev_load = 100 * prev_load /\r\n(unsigned int) j_cdbs->prev_cpu_wall;\r\nif (ignore_nice)\r\nj_cdbs->prev_cpu_nice =\r\nkcpustat_cpu(j).cpustat[CPUTIME_NICE];\r\nmutex_init(&j_cdbs->timer_mutex);\r\nINIT_DEFERRABLE_WORK(&j_cdbs->work,\r\ndbs_data->cdata->gov_dbs_timer);\r\n}\r\nif (dbs_data->cdata->governor == GOV_CONSERVATIVE) {\r\ncs_dbs_info->down_skip = 0;\r\ncs_dbs_info->enable = 1;\r\ncs_dbs_info->requested_freq = policy->cur;\r\n} else {\r\nod_dbs_info->rate_mult = 1;\r\nod_dbs_info->sample_type = OD_NORMAL_SAMPLE;\r\nod_ops->powersave_bias_init_cpu(cpu);\r\n}\r\nmutex_unlock(&dbs_data->mutex);\r\ncpu_cdbs->time_stamp = ktime_get();\r\ngov_queue_work(dbs_data, policy,\r\ndelay_for_sampling_rate(sampling_rate), true);\r\nbreak;\r\ncase CPUFREQ_GOV_STOP:\r\nif (dbs_data->cdata->governor == GOV_CONSERVATIVE)\r\ncs_dbs_info->enable = 0;\r\ngov_cancel_work(dbs_data, policy);\r\nmutex_lock(&dbs_data->mutex);\r\nmutex_destroy(&cpu_cdbs->timer_mutex);\r\ncpu_cdbs->cur_policy = NULL;\r\nmutex_unlock(&dbs_data->mutex);\r\nbreak;\r\ncase CPUFREQ_GOV_LIMITS:\r\nmutex_lock(&dbs_data->mutex);\r\nif (!cpu_cdbs->cur_policy) {\r\nmutex_unlock(&dbs_data->mutex);\r\nbreak;\r\n}\r\nmutex_lock(&cpu_cdbs->timer_mutex);\r\nif (policy->max < cpu_cdbs->cur_policy->cur)\r\n__cpufreq_driver_target(cpu_cdbs->cur_policy,\r\npolicy->max, CPUFREQ_RELATION_H);\r\nelse if (policy->min > cpu_cdbs->cur_policy->cur)\r\n__cpufreq_driver_target(cpu_cdbs->cur_policy,\r\npolicy->min, CPUFREQ_RELATION_L);\r\ndbs_check_cpu(dbs_data, cpu);\r\nmutex_unlock(&cpu_cdbs->timer_mutex);\r\nmutex_unlock(&dbs_data->mutex);\r\nbreak;\r\n}\r\nreturn 0;\r\n}
