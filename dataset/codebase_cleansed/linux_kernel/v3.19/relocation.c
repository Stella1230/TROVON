static void mapping_tree_init(struct mapping_tree *tree)\r\n{\r\ntree->rb_root = RB_ROOT;\r\nspin_lock_init(&tree->lock);\r\n}\r\nstatic void backref_cache_init(struct backref_cache *cache)\r\n{\r\nint i;\r\ncache->rb_root = RB_ROOT;\r\nfor (i = 0; i < BTRFS_MAX_LEVEL; i++)\r\nINIT_LIST_HEAD(&cache->pending[i]);\r\nINIT_LIST_HEAD(&cache->changed);\r\nINIT_LIST_HEAD(&cache->detached);\r\nINIT_LIST_HEAD(&cache->leaves);\r\n}\r\nstatic void backref_cache_cleanup(struct backref_cache *cache)\r\n{\r\nstruct backref_node *node;\r\nint i;\r\nwhile (!list_empty(&cache->detached)) {\r\nnode = list_entry(cache->detached.next,\r\nstruct backref_node, list);\r\nremove_backref_node(cache, node);\r\n}\r\nwhile (!list_empty(&cache->leaves)) {\r\nnode = list_entry(cache->leaves.next,\r\nstruct backref_node, lower);\r\nremove_backref_node(cache, node);\r\n}\r\ncache->last_trans = 0;\r\nfor (i = 0; i < BTRFS_MAX_LEVEL; i++)\r\nBUG_ON(!list_empty(&cache->pending[i]));\r\nBUG_ON(!list_empty(&cache->changed));\r\nBUG_ON(!list_empty(&cache->detached));\r\nBUG_ON(!RB_EMPTY_ROOT(&cache->rb_root));\r\nBUG_ON(cache->nr_nodes);\r\nBUG_ON(cache->nr_edges);\r\n}\r\nstatic struct backref_node *alloc_backref_node(struct backref_cache *cache)\r\n{\r\nstruct backref_node *node;\r\nnode = kzalloc(sizeof(*node), GFP_NOFS);\r\nif (node) {\r\nINIT_LIST_HEAD(&node->list);\r\nINIT_LIST_HEAD(&node->upper);\r\nINIT_LIST_HEAD(&node->lower);\r\nRB_CLEAR_NODE(&node->rb_node);\r\ncache->nr_nodes++;\r\n}\r\nreturn node;\r\n}\r\nstatic void free_backref_node(struct backref_cache *cache,\r\nstruct backref_node *node)\r\n{\r\nif (node) {\r\ncache->nr_nodes--;\r\nkfree(node);\r\n}\r\n}\r\nstatic struct backref_edge *alloc_backref_edge(struct backref_cache *cache)\r\n{\r\nstruct backref_edge *edge;\r\nedge = kzalloc(sizeof(*edge), GFP_NOFS);\r\nif (edge)\r\ncache->nr_edges++;\r\nreturn edge;\r\n}\r\nstatic void free_backref_edge(struct backref_cache *cache,\r\nstruct backref_edge *edge)\r\n{\r\nif (edge) {\r\ncache->nr_edges--;\r\nkfree(edge);\r\n}\r\n}\r\nstatic struct rb_node *tree_insert(struct rb_root *root, u64 bytenr,\r\nstruct rb_node *node)\r\n{\r\nstruct rb_node **p = &root->rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct tree_entry *entry;\r\nwhile (*p) {\r\nparent = *p;\r\nentry = rb_entry(parent, struct tree_entry, rb_node);\r\nif (bytenr < entry->bytenr)\r\np = &(*p)->rb_left;\r\nelse if (bytenr > entry->bytenr)\r\np = &(*p)->rb_right;\r\nelse\r\nreturn parent;\r\n}\r\nrb_link_node(node, parent, p);\r\nrb_insert_color(node, root);\r\nreturn NULL;\r\n}\r\nstatic struct rb_node *tree_search(struct rb_root *root, u64 bytenr)\r\n{\r\nstruct rb_node *n = root->rb_node;\r\nstruct tree_entry *entry;\r\nwhile (n) {\r\nentry = rb_entry(n, struct tree_entry, rb_node);\r\nif (bytenr < entry->bytenr)\r\nn = n->rb_left;\r\nelse if (bytenr > entry->bytenr)\r\nn = n->rb_right;\r\nelse\r\nreturn n;\r\n}\r\nreturn NULL;\r\n}\r\nstatic void backref_tree_panic(struct rb_node *rb_node, int errno, u64 bytenr)\r\n{\r\nstruct btrfs_fs_info *fs_info = NULL;\r\nstruct backref_node *bnode = rb_entry(rb_node, struct backref_node,\r\nrb_node);\r\nif (bnode->root)\r\nfs_info = bnode->root->fs_info;\r\nbtrfs_panic(fs_info, errno, "Inconsistency in backref cache "\r\n"found at offset %llu", bytenr);\r\n}\r\nstatic struct backref_node *walk_up_backref(struct backref_node *node,\r\nstruct backref_edge *edges[],\r\nint *index)\r\n{\r\nstruct backref_edge *edge;\r\nint idx = *index;\r\nwhile (!list_empty(&node->upper)) {\r\nedge = list_entry(node->upper.next,\r\nstruct backref_edge, list[LOWER]);\r\nedges[idx++] = edge;\r\nnode = edge->node[UPPER];\r\n}\r\nBUG_ON(node->detached);\r\n*index = idx;\r\nreturn node;\r\n}\r\nstatic struct backref_node *walk_down_backref(struct backref_edge *edges[],\r\nint *index)\r\n{\r\nstruct backref_edge *edge;\r\nstruct backref_node *lower;\r\nint idx = *index;\r\nwhile (idx > 0) {\r\nedge = edges[idx - 1];\r\nlower = edge->node[LOWER];\r\nif (list_is_last(&edge->list[LOWER], &lower->upper)) {\r\nidx--;\r\ncontinue;\r\n}\r\nedge = list_entry(edge->list[LOWER].next,\r\nstruct backref_edge, list[LOWER]);\r\nedges[idx - 1] = edge;\r\n*index = idx;\r\nreturn edge->node[UPPER];\r\n}\r\n*index = 0;\r\nreturn NULL;\r\n}\r\nstatic void unlock_node_buffer(struct backref_node *node)\r\n{\r\nif (node->locked) {\r\nbtrfs_tree_unlock(node->eb);\r\nnode->locked = 0;\r\n}\r\n}\r\nstatic void drop_node_buffer(struct backref_node *node)\r\n{\r\nif (node->eb) {\r\nunlock_node_buffer(node);\r\nfree_extent_buffer(node->eb);\r\nnode->eb = NULL;\r\n}\r\n}\r\nstatic void drop_backref_node(struct backref_cache *tree,\r\nstruct backref_node *node)\r\n{\r\nBUG_ON(!list_empty(&node->upper));\r\ndrop_node_buffer(node);\r\nlist_del(&node->list);\r\nlist_del(&node->lower);\r\nif (!RB_EMPTY_NODE(&node->rb_node))\r\nrb_erase(&node->rb_node, &tree->rb_root);\r\nfree_backref_node(tree, node);\r\n}\r\nstatic void remove_backref_node(struct backref_cache *cache,\r\nstruct backref_node *node)\r\n{\r\nstruct backref_node *upper;\r\nstruct backref_edge *edge;\r\nif (!node)\r\nreturn;\r\nBUG_ON(!node->lowest && !node->detached);\r\nwhile (!list_empty(&node->upper)) {\r\nedge = list_entry(node->upper.next, struct backref_edge,\r\nlist[LOWER]);\r\nupper = edge->node[UPPER];\r\nlist_del(&edge->list[LOWER]);\r\nlist_del(&edge->list[UPPER]);\r\nfree_backref_edge(cache, edge);\r\nif (RB_EMPTY_NODE(&upper->rb_node)) {\r\nBUG_ON(!list_empty(&node->upper));\r\ndrop_backref_node(cache, node);\r\nnode = upper;\r\nnode->lowest = 1;\r\ncontinue;\r\n}\r\nif (list_empty(&upper->lower)) {\r\nlist_add_tail(&upper->lower, &cache->leaves);\r\nupper->lowest = 1;\r\n}\r\n}\r\ndrop_backref_node(cache, node);\r\n}\r\nstatic void update_backref_node(struct backref_cache *cache,\r\nstruct backref_node *node, u64 bytenr)\r\n{\r\nstruct rb_node *rb_node;\r\nrb_erase(&node->rb_node, &cache->rb_root);\r\nnode->bytenr = bytenr;\r\nrb_node = tree_insert(&cache->rb_root, node->bytenr, &node->rb_node);\r\nif (rb_node)\r\nbackref_tree_panic(rb_node, -EEXIST, bytenr);\r\n}\r\nstatic int update_backref_cache(struct btrfs_trans_handle *trans,\r\nstruct backref_cache *cache)\r\n{\r\nstruct backref_node *node;\r\nint level = 0;\r\nif (cache->last_trans == 0) {\r\ncache->last_trans = trans->transid;\r\nreturn 0;\r\n}\r\nif (cache->last_trans == trans->transid)\r\nreturn 0;\r\nwhile (!list_empty(&cache->detached)) {\r\nnode = list_entry(cache->detached.next,\r\nstruct backref_node, list);\r\nremove_backref_node(cache, node);\r\n}\r\nwhile (!list_empty(&cache->changed)) {\r\nnode = list_entry(cache->changed.next,\r\nstruct backref_node, list);\r\nlist_del_init(&node->list);\r\nBUG_ON(node->pending);\r\nupdate_backref_node(cache, node, node->new_bytenr);\r\n}\r\nfor (level = 0; level < BTRFS_MAX_LEVEL; level++) {\r\nlist_for_each_entry(node, &cache->pending[level], list) {\r\nBUG_ON(!node->pending);\r\nif (node->bytenr == node->new_bytenr)\r\ncontinue;\r\nupdate_backref_node(cache, node, node->new_bytenr);\r\n}\r\n}\r\ncache->last_trans = 0;\r\nreturn 1;\r\n}\r\nstatic int should_ignore_root(struct btrfs_root *root)\r\n{\r\nstruct btrfs_root *reloc_root;\r\nif (!test_bit(BTRFS_ROOT_REF_COWS, &root->state))\r\nreturn 0;\r\nreloc_root = root->reloc_root;\r\nif (!reloc_root)\r\nreturn 0;\r\nif (btrfs_root_last_snapshot(&reloc_root->root_item) ==\r\nroot->fs_info->running_transaction->transid - 1)\r\nreturn 0;\r\nreturn 1;\r\n}\r\nstatic struct btrfs_root *find_reloc_root(struct reloc_control *rc,\r\nu64 bytenr)\r\n{\r\nstruct rb_node *rb_node;\r\nstruct mapping_node *node;\r\nstruct btrfs_root *root = NULL;\r\nspin_lock(&rc->reloc_root_tree.lock);\r\nrb_node = tree_search(&rc->reloc_root_tree.rb_root, bytenr);\r\nif (rb_node) {\r\nnode = rb_entry(rb_node, struct mapping_node, rb_node);\r\nroot = (struct btrfs_root *)node->data;\r\n}\r\nspin_unlock(&rc->reloc_root_tree.lock);\r\nreturn root;\r\n}\r\nstatic int is_cowonly_root(u64 root_objectid)\r\n{\r\nif (root_objectid == BTRFS_ROOT_TREE_OBJECTID ||\r\nroot_objectid == BTRFS_EXTENT_TREE_OBJECTID ||\r\nroot_objectid == BTRFS_CHUNK_TREE_OBJECTID ||\r\nroot_objectid == BTRFS_DEV_TREE_OBJECTID ||\r\nroot_objectid == BTRFS_TREE_LOG_OBJECTID ||\r\nroot_objectid == BTRFS_CSUM_TREE_OBJECTID ||\r\nroot_objectid == BTRFS_UUID_TREE_OBJECTID ||\r\nroot_objectid == BTRFS_QUOTA_TREE_OBJECTID)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic struct btrfs_root *read_fs_root(struct btrfs_fs_info *fs_info,\r\nu64 root_objectid)\r\n{\r\nstruct btrfs_key key;\r\nkey.objectid = root_objectid;\r\nkey.type = BTRFS_ROOT_ITEM_KEY;\r\nif (is_cowonly_root(root_objectid))\r\nkey.offset = 0;\r\nelse\r\nkey.offset = (u64)-1;\r\nreturn btrfs_get_fs_root(fs_info, &key, false);\r\n}\r\nnoinline_for_stack\r\nint find_inline_backref(struct extent_buffer *leaf, int slot,\r\nunsigned long *ptr, unsigned long *end)\r\n{\r\nstruct btrfs_key key;\r\nstruct btrfs_extent_item *ei;\r\nstruct btrfs_tree_block_info *bi;\r\nu32 item_size;\r\nbtrfs_item_key_to_cpu(leaf, &key, slot);\r\nitem_size = btrfs_item_size_nr(leaf, slot);\r\n#ifdef BTRFS_COMPAT_EXTENT_TREE_V0\r\nif (item_size < sizeof(*ei)) {\r\nWARN_ON(item_size != sizeof(struct btrfs_extent_item_v0));\r\nreturn 1;\r\n}\r\n#endif\r\nei = btrfs_item_ptr(leaf, slot, struct btrfs_extent_item);\r\nWARN_ON(!(btrfs_extent_flags(leaf, ei) &\r\nBTRFS_EXTENT_FLAG_TREE_BLOCK));\r\nif (key.type == BTRFS_EXTENT_ITEM_KEY &&\r\nitem_size <= sizeof(*ei) + sizeof(*bi)) {\r\nWARN_ON(item_size < sizeof(*ei) + sizeof(*bi));\r\nreturn 1;\r\n}\r\nif (key.type == BTRFS_METADATA_ITEM_KEY &&\r\nitem_size <= sizeof(*ei)) {\r\nWARN_ON(item_size < sizeof(*ei));\r\nreturn 1;\r\n}\r\nif (key.type == BTRFS_EXTENT_ITEM_KEY) {\r\nbi = (struct btrfs_tree_block_info *)(ei + 1);\r\n*ptr = (unsigned long)(bi + 1);\r\n} else {\r\n*ptr = (unsigned long)(ei + 1);\r\n}\r\n*end = (unsigned long)ei + item_size;\r\nreturn 0;\r\n}\r\nstatic int clone_backref_node(struct btrfs_trans_handle *trans,\r\nstruct reloc_control *rc,\r\nstruct btrfs_root *src,\r\nstruct btrfs_root *dest)\r\n{\r\nstruct btrfs_root *reloc_root = src->reloc_root;\r\nstruct backref_cache *cache = &rc->backref_cache;\r\nstruct backref_node *node = NULL;\r\nstruct backref_node *new_node;\r\nstruct backref_edge *edge;\r\nstruct backref_edge *new_edge;\r\nstruct rb_node *rb_node;\r\nif (cache->last_trans > 0)\r\nupdate_backref_cache(trans, cache);\r\nrb_node = tree_search(&cache->rb_root, src->commit_root->start);\r\nif (rb_node) {\r\nnode = rb_entry(rb_node, struct backref_node, rb_node);\r\nif (node->detached)\r\nnode = NULL;\r\nelse\r\nBUG_ON(node->new_bytenr != reloc_root->node->start);\r\n}\r\nif (!node) {\r\nrb_node = tree_search(&cache->rb_root,\r\nreloc_root->commit_root->start);\r\nif (rb_node) {\r\nnode = rb_entry(rb_node, struct backref_node,\r\nrb_node);\r\nBUG_ON(node->detached);\r\n}\r\n}\r\nif (!node)\r\nreturn 0;\r\nnew_node = alloc_backref_node(cache);\r\nif (!new_node)\r\nreturn -ENOMEM;\r\nnew_node->bytenr = dest->node->start;\r\nnew_node->level = node->level;\r\nnew_node->lowest = node->lowest;\r\nnew_node->checked = 1;\r\nnew_node->root = dest;\r\nif (!node->lowest) {\r\nlist_for_each_entry(edge, &node->lower, list[UPPER]) {\r\nnew_edge = alloc_backref_edge(cache);\r\nif (!new_edge)\r\ngoto fail;\r\nnew_edge->node[UPPER] = new_node;\r\nnew_edge->node[LOWER] = edge->node[LOWER];\r\nlist_add_tail(&new_edge->list[UPPER],\r\n&new_node->lower);\r\n}\r\n} else {\r\nlist_add_tail(&new_node->lower, &cache->leaves);\r\n}\r\nrb_node = tree_insert(&cache->rb_root, new_node->bytenr,\r\n&new_node->rb_node);\r\nif (rb_node)\r\nbackref_tree_panic(rb_node, -EEXIST, new_node->bytenr);\r\nif (!new_node->lowest) {\r\nlist_for_each_entry(new_edge, &new_node->lower, list[UPPER]) {\r\nlist_add_tail(&new_edge->list[LOWER],\r\n&new_edge->node[LOWER]->upper);\r\n}\r\n}\r\nreturn 0;\r\nfail:\r\nwhile (!list_empty(&new_node->lower)) {\r\nnew_edge = list_entry(new_node->lower.next,\r\nstruct backref_edge, list[UPPER]);\r\nlist_del(&new_edge->list[UPPER]);\r\nfree_backref_edge(cache, new_edge);\r\n}\r\nfree_backref_node(cache, new_node);\r\nreturn -ENOMEM;\r\n}\r\nstatic int __must_check __add_reloc_root(struct btrfs_root *root)\r\n{\r\nstruct rb_node *rb_node;\r\nstruct mapping_node *node;\r\nstruct reloc_control *rc = root->fs_info->reloc_ctl;\r\nnode = kmalloc(sizeof(*node), GFP_NOFS);\r\nif (!node)\r\nreturn -ENOMEM;\r\nnode->bytenr = root->node->start;\r\nnode->data = root;\r\nspin_lock(&rc->reloc_root_tree.lock);\r\nrb_node = tree_insert(&rc->reloc_root_tree.rb_root,\r\nnode->bytenr, &node->rb_node);\r\nspin_unlock(&rc->reloc_root_tree.lock);\r\nif (rb_node) {\r\nbtrfs_panic(root->fs_info, -EEXIST, "Duplicate root found "\r\n"for start=%llu while inserting into relocation "\r\n"tree", node->bytenr);\r\nkfree(node);\r\nreturn -EEXIST;\r\n}\r\nlist_add_tail(&root->root_list, &rc->reloc_roots);\r\nreturn 0;\r\n}\r\nstatic void __del_reloc_root(struct btrfs_root *root)\r\n{\r\nstruct rb_node *rb_node;\r\nstruct mapping_node *node = NULL;\r\nstruct reloc_control *rc = root->fs_info->reloc_ctl;\r\nspin_lock(&rc->reloc_root_tree.lock);\r\nrb_node = tree_search(&rc->reloc_root_tree.rb_root,\r\nroot->node->start);\r\nif (rb_node) {\r\nnode = rb_entry(rb_node, struct mapping_node, rb_node);\r\nrb_erase(&node->rb_node, &rc->reloc_root_tree.rb_root);\r\n}\r\nspin_unlock(&rc->reloc_root_tree.lock);\r\nif (!node)\r\nreturn;\r\nBUG_ON((struct btrfs_root *)node->data != root);\r\nspin_lock(&root->fs_info->trans_lock);\r\nlist_del_init(&root->root_list);\r\nspin_unlock(&root->fs_info->trans_lock);\r\nkfree(node);\r\n}\r\nstatic int __update_reloc_root(struct btrfs_root *root, u64 new_bytenr)\r\n{\r\nstruct rb_node *rb_node;\r\nstruct mapping_node *node = NULL;\r\nstruct reloc_control *rc = root->fs_info->reloc_ctl;\r\nspin_lock(&rc->reloc_root_tree.lock);\r\nrb_node = tree_search(&rc->reloc_root_tree.rb_root,\r\nroot->node->start);\r\nif (rb_node) {\r\nnode = rb_entry(rb_node, struct mapping_node, rb_node);\r\nrb_erase(&node->rb_node, &rc->reloc_root_tree.rb_root);\r\n}\r\nspin_unlock(&rc->reloc_root_tree.lock);\r\nif (!node)\r\nreturn 0;\r\nBUG_ON((struct btrfs_root *)node->data != root);\r\nspin_lock(&rc->reloc_root_tree.lock);\r\nnode->bytenr = new_bytenr;\r\nrb_node = tree_insert(&rc->reloc_root_tree.rb_root,\r\nnode->bytenr, &node->rb_node);\r\nspin_unlock(&rc->reloc_root_tree.lock);\r\nif (rb_node)\r\nbackref_tree_panic(rb_node, -EEXIST, node->bytenr);\r\nreturn 0;\r\n}\r\nstatic struct btrfs_root *create_reloc_root(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root, u64 objectid)\r\n{\r\nstruct btrfs_root *reloc_root;\r\nstruct extent_buffer *eb;\r\nstruct btrfs_root_item *root_item;\r\nstruct btrfs_key root_key;\r\nu64 last_snap = 0;\r\nint ret;\r\nroot_item = kmalloc(sizeof(*root_item), GFP_NOFS);\r\nBUG_ON(!root_item);\r\nroot_key.objectid = BTRFS_TREE_RELOC_OBJECTID;\r\nroot_key.type = BTRFS_ROOT_ITEM_KEY;\r\nroot_key.offset = objectid;\r\nif (root->root_key.objectid == objectid) {\r\nret = btrfs_copy_root(trans, root, root->commit_root, &eb,\r\nBTRFS_TREE_RELOC_OBJECTID);\r\nBUG_ON(ret);\r\nlast_snap = btrfs_root_last_snapshot(&root->root_item);\r\nbtrfs_set_root_last_snapshot(&root->root_item,\r\ntrans->transid - 1);\r\n} else {\r\nret = btrfs_copy_root(trans, root, root->node, &eb,\r\nBTRFS_TREE_RELOC_OBJECTID);\r\nBUG_ON(ret);\r\n}\r\nmemcpy(root_item, &root->root_item, sizeof(*root_item));\r\nbtrfs_set_root_bytenr(root_item, eb->start);\r\nbtrfs_set_root_level(root_item, btrfs_header_level(eb));\r\nbtrfs_set_root_generation(root_item, trans->transid);\r\nif (root->root_key.objectid == objectid) {\r\nbtrfs_set_root_refs(root_item, 0);\r\nmemset(&root_item->drop_progress, 0,\r\nsizeof(struct btrfs_disk_key));\r\nroot_item->drop_level = 0;\r\nbtrfs_set_root_rtransid(root_item, last_snap);\r\nbtrfs_set_root_otransid(root_item, trans->transid);\r\n}\r\nbtrfs_tree_unlock(eb);\r\nfree_extent_buffer(eb);\r\nret = btrfs_insert_root(trans, root->fs_info->tree_root,\r\n&root_key, root_item);\r\nBUG_ON(ret);\r\nkfree(root_item);\r\nreloc_root = btrfs_read_fs_root(root->fs_info->tree_root, &root_key);\r\nBUG_ON(IS_ERR(reloc_root));\r\nreloc_root->last_trans = trans->transid;\r\nreturn reloc_root;\r\n}\r\nint btrfs_init_reloc_root(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root)\r\n{\r\nstruct btrfs_root *reloc_root;\r\nstruct reloc_control *rc = root->fs_info->reloc_ctl;\r\nstruct btrfs_block_rsv *rsv;\r\nint clear_rsv = 0;\r\nint ret;\r\nif (root->reloc_root) {\r\nreloc_root = root->reloc_root;\r\nreloc_root->last_trans = trans->transid;\r\nreturn 0;\r\n}\r\nif (!rc || !rc->create_reloc_tree ||\r\nroot->root_key.objectid == BTRFS_TREE_RELOC_OBJECTID)\r\nreturn 0;\r\nif (!trans->reloc_reserved) {\r\nrsv = trans->block_rsv;\r\ntrans->block_rsv = rc->block_rsv;\r\nclear_rsv = 1;\r\n}\r\nreloc_root = create_reloc_root(trans, root, root->root_key.objectid);\r\nif (clear_rsv)\r\ntrans->block_rsv = rsv;\r\nret = __add_reloc_root(reloc_root);\r\nBUG_ON(ret < 0);\r\nroot->reloc_root = reloc_root;\r\nreturn 0;\r\n}\r\nint btrfs_update_reloc_root(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root)\r\n{\r\nstruct btrfs_root *reloc_root;\r\nstruct btrfs_root_item *root_item;\r\nint ret;\r\nif (!root->reloc_root)\r\ngoto out;\r\nreloc_root = root->reloc_root;\r\nroot_item = &reloc_root->root_item;\r\nif (root->fs_info->reloc_ctl->merge_reloc_tree &&\r\nbtrfs_root_refs(root_item) == 0) {\r\nroot->reloc_root = NULL;\r\n__del_reloc_root(reloc_root);\r\n}\r\nif (reloc_root->commit_root != reloc_root->node) {\r\nbtrfs_set_root_node(root_item, reloc_root->node);\r\nfree_extent_buffer(reloc_root->commit_root);\r\nreloc_root->commit_root = btrfs_root_node(reloc_root);\r\n}\r\nret = btrfs_update_root(trans, root->fs_info->tree_root,\r\n&reloc_root->root_key, root_item);\r\nBUG_ON(ret);\r\nout:\r\nreturn 0;\r\n}\r\nstatic struct inode *find_next_inode(struct btrfs_root *root, u64 objectid)\r\n{\r\nstruct rb_node *node;\r\nstruct rb_node *prev;\r\nstruct btrfs_inode *entry;\r\nstruct inode *inode;\r\nspin_lock(&root->inode_lock);\r\nagain:\r\nnode = root->inode_tree.rb_node;\r\nprev = NULL;\r\nwhile (node) {\r\nprev = node;\r\nentry = rb_entry(node, struct btrfs_inode, rb_node);\r\nif (objectid < btrfs_ino(&entry->vfs_inode))\r\nnode = node->rb_left;\r\nelse if (objectid > btrfs_ino(&entry->vfs_inode))\r\nnode = node->rb_right;\r\nelse\r\nbreak;\r\n}\r\nif (!node) {\r\nwhile (prev) {\r\nentry = rb_entry(prev, struct btrfs_inode, rb_node);\r\nif (objectid <= btrfs_ino(&entry->vfs_inode)) {\r\nnode = prev;\r\nbreak;\r\n}\r\nprev = rb_next(prev);\r\n}\r\n}\r\nwhile (node) {\r\nentry = rb_entry(node, struct btrfs_inode, rb_node);\r\ninode = igrab(&entry->vfs_inode);\r\nif (inode) {\r\nspin_unlock(&root->inode_lock);\r\nreturn inode;\r\n}\r\nobjectid = btrfs_ino(&entry->vfs_inode) + 1;\r\nif (cond_resched_lock(&root->inode_lock))\r\ngoto again;\r\nnode = rb_next(node);\r\n}\r\nspin_unlock(&root->inode_lock);\r\nreturn NULL;\r\n}\r\nstatic int in_block_group(u64 bytenr,\r\nstruct btrfs_block_group_cache *block_group)\r\n{\r\nif (bytenr >= block_group->key.objectid &&\r\nbytenr < block_group->key.objectid + block_group->key.offset)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int get_new_location(struct inode *reloc_inode, u64 *new_bytenr,\r\nu64 bytenr, u64 num_bytes)\r\n{\r\nstruct btrfs_root *root = BTRFS_I(reloc_inode)->root;\r\nstruct btrfs_path *path;\r\nstruct btrfs_file_extent_item *fi;\r\nstruct extent_buffer *leaf;\r\nint ret;\r\npath = btrfs_alloc_path();\r\nif (!path)\r\nreturn -ENOMEM;\r\nbytenr -= BTRFS_I(reloc_inode)->index_cnt;\r\nret = btrfs_lookup_file_extent(NULL, root, path, btrfs_ino(reloc_inode),\r\nbytenr, 0);\r\nif (ret < 0)\r\ngoto out;\r\nif (ret > 0) {\r\nret = -ENOENT;\r\ngoto out;\r\n}\r\nleaf = path->nodes[0];\r\nfi = btrfs_item_ptr(leaf, path->slots[0],\r\nstruct btrfs_file_extent_item);\r\nBUG_ON(btrfs_file_extent_offset(leaf, fi) ||\r\nbtrfs_file_extent_compression(leaf, fi) ||\r\nbtrfs_file_extent_encryption(leaf, fi) ||\r\nbtrfs_file_extent_other_encoding(leaf, fi));\r\nif (num_bytes != btrfs_file_extent_disk_num_bytes(leaf, fi)) {\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\n*new_bytenr = btrfs_file_extent_disk_bytenr(leaf, fi);\r\nret = 0;\r\nout:\r\nbtrfs_free_path(path);\r\nreturn ret;\r\n}\r\nstatic noinline_for_stack\r\nint replace_file_extents(struct btrfs_trans_handle *trans,\r\nstruct reloc_control *rc,\r\nstruct btrfs_root *root,\r\nstruct extent_buffer *leaf)\r\n{\r\nstruct btrfs_key key;\r\nstruct btrfs_file_extent_item *fi;\r\nstruct inode *inode = NULL;\r\nu64 parent;\r\nu64 bytenr;\r\nu64 new_bytenr = 0;\r\nu64 num_bytes;\r\nu64 end;\r\nu32 nritems;\r\nu32 i;\r\nint ret = 0;\r\nint first = 1;\r\nint dirty = 0;\r\nif (rc->stage != UPDATE_DATA_PTRS)\r\nreturn 0;\r\nif (root->root_key.objectid == BTRFS_TREE_RELOC_OBJECTID)\r\nparent = leaf->start;\r\nelse\r\nparent = 0;\r\nnritems = btrfs_header_nritems(leaf);\r\nfor (i = 0; i < nritems; i++) {\r\ncond_resched();\r\nbtrfs_item_key_to_cpu(leaf, &key, i);\r\nif (key.type != BTRFS_EXTENT_DATA_KEY)\r\ncontinue;\r\nfi = btrfs_item_ptr(leaf, i, struct btrfs_file_extent_item);\r\nif (btrfs_file_extent_type(leaf, fi) ==\r\nBTRFS_FILE_EXTENT_INLINE)\r\ncontinue;\r\nbytenr = btrfs_file_extent_disk_bytenr(leaf, fi);\r\nnum_bytes = btrfs_file_extent_disk_num_bytes(leaf, fi);\r\nif (bytenr == 0)\r\ncontinue;\r\nif (!in_block_group(bytenr, rc->block_group))\r\ncontinue;\r\nif (root->root_key.objectid != BTRFS_TREE_RELOC_OBJECTID) {\r\nif (first) {\r\ninode = find_next_inode(root, key.objectid);\r\nfirst = 0;\r\n} else if (inode && btrfs_ino(inode) < key.objectid) {\r\nbtrfs_add_delayed_iput(inode);\r\ninode = find_next_inode(root, key.objectid);\r\n}\r\nif (inode && btrfs_ino(inode) == key.objectid) {\r\nend = key.offset +\r\nbtrfs_file_extent_num_bytes(leaf, fi);\r\nWARN_ON(!IS_ALIGNED(key.offset,\r\nroot->sectorsize));\r\nWARN_ON(!IS_ALIGNED(end, root->sectorsize));\r\nend--;\r\nret = try_lock_extent(&BTRFS_I(inode)->io_tree,\r\nkey.offset, end);\r\nif (!ret)\r\ncontinue;\r\nbtrfs_drop_extent_cache(inode, key.offset, end,\r\n1);\r\nunlock_extent(&BTRFS_I(inode)->io_tree,\r\nkey.offset, end);\r\n}\r\n}\r\nret = get_new_location(rc->data_inode, &new_bytenr,\r\nbytenr, num_bytes);\r\nif (ret) {\r\nbreak;\r\n}\r\nbtrfs_set_file_extent_disk_bytenr(leaf, fi, new_bytenr);\r\ndirty = 1;\r\nkey.offset -= btrfs_file_extent_offset(leaf, fi);\r\nret = btrfs_inc_extent_ref(trans, root, new_bytenr,\r\nnum_bytes, parent,\r\nbtrfs_header_owner(leaf),\r\nkey.objectid, key.offset, 1);\r\nif (ret) {\r\nbtrfs_abort_transaction(trans, root, ret);\r\nbreak;\r\n}\r\nret = btrfs_free_extent(trans, root, bytenr, num_bytes,\r\nparent, btrfs_header_owner(leaf),\r\nkey.objectid, key.offset, 1);\r\nif (ret) {\r\nbtrfs_abort_transaction(trans, root, ret);\r\nbreak;\r\n}\r\n}\r\nif (dirty)\r\nbtrfs_mark_buffer_dirty(leaf);\r\nif (inode)\r\nbtrfs_add_delayed_iput(inode);\r\nreturn ret;\r\n}\r\nstatic noinline_for_stack\r\nint memcmp_node_keys(struct extent_buffer *eb, int slot,\r\nstruct btrfs_path *path, int level)\r\n{\r\nstruct btrfs_disk_key key1;\r\nstruct btrfs_disk_key key2;\r\nbtrfs_node_key(eb, &key1, slot);\r\nbtrfs_node_key(path->nodes[level], &key2, path->slots[level]);\r\nreturn memcmp(&key1, &key2, sizeof(key1));\r\n}\r\nstatic noinline_for_stack\r\nint replace_path(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *dest, struct btrfs_root *src,\r\nstruct btrfs_path *path, struct btrfs_key *next_key,\r\nint lowest_level, int max_level)\r\n{\r\nstruct extent_buffer *eb;\r\nstruct extent_buffer *parent;\r\nstruct btrfs_key key;\r\nu64 old_bytenr;\r\nu64 new_bytenr;\r\nu64 old_ptr_gen;\r\nu64 new_ptr_gen;\r\nu64 last_snapshot;\r\nu32 blocksize;\r\nint cow = 0;\r\nint level;\r\nint ret;\r\nint slot;\r\nBUG_ON(src->root_key.objectid != BTRFS_TREE_RELOC_OBJECTID);\r\nBUG_ON(dest->root_key.objectid == BTRFS_TREE_RELOC_OBJECTID);\r\nlast_snapshot = btrfs_root_last_snapshot(&src->root_item);\r\nagain:\r\nslot = path->slots[lowest_level];\r\nbtrfs_node_key_to_cpu(path->nodes[lowest_level], &key, slot);\r\neb = btrfs_lock_root_node(dest);\r\nbtrfs_set_lock_blocking(eb);\r\nlevel = btrfs_header_level(eb);\r\nif (level < lowest_level) {\r\nbtrfs_tree_unlock(eb);\r\nfree_extent_buffer(eb);\r\nreturn 0;\r\n}\r\nif (cow) {\r\nret = btrfs_cow_block(trans, dest, eb, NULL, 0, &eb);\r\nBUG_ON(ret);\r\n}\r\nbtrfs_set_lock_blocking(eb);\r\nif (next_key) {\r\nnext_key->objectid = (u64)-1;\r\nnext_key->type = (u8)-1;\r\nnext_key->offset = (u64)-1;\r\n}\r\nparent = eb;\r\nwhile (1) {\r\nlevel = btrfs_header_level(parent);\r\nBUG_ON(level < lowest_level);\r\nret = btrfs_bin_search(parent, &key, level, &slot);\r\nif (ret && slot > 0)\r\nslot--;\r\nif (next_key && slot + 1 < btrfs_header_nritems(parent))\r\nbtrfs_node_key_to_cpu(parent, next_key, slot + 1);\r\nold_bytenr = btrfs_node_blockptr(parent, slot);\r\nblocksize = dest->nodesize;\r\nold_ptr_gen = btrfs_node_ptr_generation(parent, slot);\r\nif (level <= max_level) {\r\neb = path->nodes[level];\r\nnew_bytenr = btrfs_node_blockptr(eb,\r\npath->slots[level]);\r\nnew_ptr_gen = btrfs_node_ptr_generation(eb,\r\npath->slots[level]);\r\n} else {\r\nnew_bytenr = 0;\r\nnew_ptr_gen = 0;\r\n}\r\nif (WARN_ON(new_bytenr > 0 && new_bytenr == old_bytenr)) {\r\nret = level;\r\nbreak;\r\n}\r\nif (new_bytenr == 0 || old_ptr_gen > last_snapshot ||\r\nmemcmp_node_keys(parent, slot, path, level)) {\r\nif (level <= lowest_level) {\r\nret = 0;\r\nbreak;\r\n}\r\neb = read_tree_block(dest, old_bytenr, old_ptr_gen);\r\nif (!eb || !extent_buffer_uptodate(eb)) {\r\nret = (!eb) ? -ENOMEM : -EIO;\r\nfree_extent_buffer(eb);\r\nbreak;\r\n}\r\nbtrfs_tree_lock(eb);\r\nif (cow) {\r\nret = btrfs_cow_block(trans, dest, eb, parent,\r\nslot, &eb);\r\nBUG_ON(ret);\r\n}\r\nbtrfs_set_lock_blocking(eb);\r\nbtrfs_tree_unlock(parent);\r\nfree_extent_buffer(parent);\r\nparent = eb;\r\ncontinue;\r\n}\r\nif (!cow) {\r\nbtrfs_tree_unlock(parent);\r\nfree_extent_buffer(parent);\r\ncow = 1;\r\ngoto again;\r\n}\r\nbtrfs_node_key_to_cpu(path->nodes[level], &key,\r\npath->slots[level]);\r\nbtrfs_release_path(path);\r\npath->lowest_level = level;\r\nret = btrfs_search_slot(trans, src, &key, path, 0, 1);\r\npath->lowest_level = 0;\r\nBUG_ON(ret);\r\nbtrfs_set_node_blockptr(parent, slot, new_bytenr);\r\nbtrfs_set_node_ptr_generation(parent, slot, new_ptr_gen);\r\nbtrfs_mark_buffer_dirty(parent);\r\nbtrfs_set_node_blockptr(path->nodes[level],\r\npath->slots[level], old_bytenr);\r\nbtrfs_set_node_ptr_generation(path->nodes[level],\r\npath->slots[level], old_ptr_gen);\r\nbtrfs_mark_buffer_dirty(path->nodes[level]);\r\nret = btrfs_inc_extent_ref(trans, src, old_bytenr, blocksize,\r\npath->nodes[level]->start,\r\nsrc->root_key.objectid, level - 1, 0,\r\n1);\r\nBUG_ON(ret);\r\nret = btrfs_inc_extent_ref(trans, dest, new_bytenr, blocksize,\r\n0, dest->root_key.objectid, level - 1,\r\n0, 1);\r\nBUG_ON(ret);\r\nret = btrfs_free_extent(trans, src, new_bytenr, blocksize,\r\npath->nodes[level]->start,\r\nsrc->root_key.objectid, level - 1, 0,\r\n1);\r\nBUG_ON(ret);\r\nret = btrfs_free_extent(trans, dest, old_bytenr, blocksize,\r\n0, dest->root_key.objectid, level - 1,\r\n0, 1);\r\nBUG_ON(ret);\r\nbtrfs_unlock_up_safe(path, 0);\r\nret = level;\r\nbreak;\r\n}\r\nbtrfs_tree_unlock(parent);\r\nfree_extent_buffer(parent);\r\nreturn ret;\r\n}\r\nstatic noinline_for_stack\r\nint walk_up_reloc_tree(struct btrfs_root *root, struct btrfs_path *path,\r\nint *level)\r\n{\r\nstruct extent_buffer *eb;\r\nint i;\r\nu64 last_snapshot;\r\nu32 nritems;\r\nlast_snapshot = btrfs_root_last_snapshot(&root->root_item);\r\nfor (i = 0; i < *level; i++) {\r\nfree_extent_buffer(path->nodes[i]);\r\npath->nodes[i] = NULL;\r\n}\r\nfor (i = *level; i < BTRFS_MAX_LEVEL && path->nodes[i]; i++) {\r\neb = path->nodes[i];\r\nnritems = btrfs_header_nritems(eb);\r\nwhile (path->slots[i] + 1 < nritems) {\r\npath->slots[i]++;\r\nif (btrfs_node_ptr_generation(eb, path->slots[i]) <=\r\nlast_snapshot)\r\ncontinue;\r\n*level = i;\r\nreturn 0;\r\n}\r\nfree_extent_buffer(path->nodes[i]);\r\npath->nodes[i] = NULL;\r\n}\r\nreturn 1;\r\n}\r\nstatic noinline_for_stack\r\nint walk_down_reloc_tree(struct btrfs_root *root, struct btrfs_path *path,\r\nint *level)\r\n{\r\nstruct extent_buffer *eb = NULL;\r\nint i;\r\nu64 bytenr;\r\nu64 ptr_gen = 0;\r\nu64 last_snapshot;\r\nu32 nritems;\r\nlast_snapshot = btrfs_root_last_snapshot(&root->root_item);\r\nfor (i = *level; i > 0; i--) {\r\neb = path->nodes[i];\r\nnritems = btrfs_header_nritems(eb);\r\nwhile (path->slots[i] < nritems) {\r\nptr_gen = btrfs_node_ptr_generation(eb, path->slots[i]);\r\nif (ptr_gen > last_snapshot)\r\nbreak;\r\npath->slots[i]++;\r\n}\r\nif (path->slots[i] >= nritems) {\r\nif (i == *level)\r\nbreak;\r\n*level = i + 1;\r\nreturn 0;\r\n}\r\nif (i == 1) {\r\n*level = i;\r\nreturn 0;\r\n}\r\nbytenr = btrfs_node_blockptr(eb, path->slots[i]);\r\neb = read_tree_block(root, bytenr, ptr_gen);\r\nif (!eb || !extent_buffer_uptodate(eb)) {\r\nfree_extent_buffer(eb);\r\nreturn -EIO;\r\n}\r\nBUG_ON(btrfs_header_level(eb) != i - 1);\r\npath->nodes[i - 1] = eb;\r\npath->slots[i - 1] = 0;\r\n}\r\nreturn 1;\r\n}\r\nstatic int invalidate_extent_cache(struct btrfs_root *root,\r\nstruct btrfs_key *min_key,\r\nstruct btrfs_key *max_key)\r\n{\r\nstruct inode *inode = NULL;\r\nu64 objectid;\r\nu64 start, end;\r\nu64 ino;\r\nobjectid = min_key->objectid;\r\nwhile (1) {\r\ncond_resched();\r\niput(inode);\r\nif (objectid > max_key->objectid)\r\nbreak;\r\ninode = find_next_inode(root, objectid);\r\nif (!inode)\r\nbreak;\r\nino = btrfs_ino(inode);\r\nif (ino > max_key->objectid) {\r\niput(inode);\r\nbreak;\r\n}\r\nobjectid = ino + 1;\r\nif (!S_ISREG(inode->i_mode))\r\ncontinue;\r\nif (unlikely(min_key->objectid == ino)) {\r\nif (min_key->type > BTRFS_EXTENT_DATA_KEY)\r\ncontinue;\r\nif (min_key->type < BTRFS_EXTENT_DATA_KEY)\r\nstart = 0;\r\nelse {\r\nstart = min_key->offset;\r\nWARN_ON(!IS_ALIGNED(start, root->sectorsize));\r\n}\r\n} else {\r\nstart = 0;\r\n}\r\nif (unlikely(max_key->objectid == ino)) {\r\nif (max_key->type < BTRFS_EXTENT_DATA_KEY)\r\ncontinue;\r\nif (max_key->type > BTRFS_EXTENT_DATA_KEY) {\r\nend = (u64)-1;\r\n} else {\r\nif (max_key->offset == 0)\r\ncontinue;\r\nend = max_key->offset;\r\nWARN_ON(!IS_ALIGNED(end, root->sectorsize));\r\nend--;\r\n}\r\n} else {\r\nend = (u64)-1;\r\n}\r\nlock_extent(&BTRFS_I(inode)->io_tree, start, end);\r\nbtrfs_drop_extent_cache(inode, start, end, 1);\r\nunlock_extent(&BTRFS_I(inode)->io_tree, start, end);\r\n}\r\nreturn 0;\r\n}\r\nstatic int find_next_key(struct btrfs_path *path, int level,\r\nstruct btrfs_key *key)\r\n{\r\nwhile (level < BTRFS_MAX_LEVEL) {\r\nif (!path->nodes[level])\r\nbreak;\r\nif (path->slots[level] + 1 <\r\nbtrfs_header_nritems(path->nodes[level])) {\r\nbtrfs_node_key_to_cpu(path->nodes[level], key,\r\npath->slots[level] + 1);\r\nreturn 0;\r\n}\r\nlevel++;\r\n}\r\nreturn 1;\r\n}\r\nstatic noinline_for_stack int merge_reloc_root(struct reloc_control *rc,\r\nstruct btrfs_root *root)\r\n{\r\nLIST_HEAD(inode_list);\r\nstruct btrfs_key key;\r\nstruct btrfs_key next_key;\r\nstruct btrfs_trans_handle *trans = NULL;\r\nstruct btrfs_root *reloc_root;\r\nstruct btrfs_root_item *root_item;\r\nstruct btrfs_path *path;\r\nstruct extent_buffer *leaf;\r\nint level;\r\nint max_level;\r\nint replaced = 0;\r\nint ret;\r\nint err = 0;\r\nu32 min_reserved;\r\npath = btrfs_alloc_path();\r\nif (!path)\r\nreturn -ENOMEM;\r\npath->reada = 1;\r\nreloc_root = root->reloc_root;\r\nroot_item = &reloc_root->root_item;\r\nif (btrfs_disk_key_objectid(&root_item->drop_progress) == 0) {\r\nlevel = btrfs_root_level(root_item);\r\nextent_buffer_get(reloc_root->node);\r\npath->nodes[level] = reloc_root->node;\r\npath->slots[level] = 0;\r\n} else {\r\nbtrfs_disk_key_to_cpu(&key, &root_item->drop_progress);\r\nlevel = root_item->drop_level;\r\nBUG_ON(level == 0);\r\npath->lowest_level = level;\r\nret = btrfs_search_slot(NULL, reloc_root, &key, path, 0, 0);\r\npath->lowest_level = 0;\r\nif (ret < 0) {\r\nbtrfs_free_path(path);\r\nreturn ret;\r\n}\r\nbtrfs_node_key_to_cpu(path->nodes[level], &next_key,\r\npath->slots[level]);\r\nWARN_ON(memcmp(&key, &next_key, sizeof(key)));\r\nbtrfs_unlock_up_safe(path, 0);\r\n}\r\nmin_reserved = root->nodesize * (BTRFS_MAX_LEVEL - 1) * 2;\r\nmemset(&next_key, 0, sizeof(next_key));\r\nwhile (1) {\r\nret = btrfs_block_rsv_refill(root, rc->block_rsv, min_reserved,\r\nBTRFS_RESERVE_FLUSH_ALL);\r\nif (ret) {\r\nerr = ret;\r\ngoto out;\r\n}\r\ntrans = btrfs_start_transaction(root, 0);\r\nif (IS_ERR(trans)) {\r\nerr = PTR_ERR(trans);\r\ntrans = NULL;\r\ngoto out;\r\n}\r\ntrans->block_rsv = rc->block_rsv;\r\nreplaced = 0;\r\nmax_level = level;\r\nret = walk_down_reloc_tree(reloc_root, path, &level);\r\nif (ret < 0) {\r\nerr = ret;\r\ngoto out;\r\n}\r\nif (ret > 0)\r\nbreak;\r\nif (!find_next_key(path, level, &key) &&\r\nbtrfs_comp_cpu_keys(&next_key, &key) >= 0) {\r\nret = 0;\r\n} else {\r\nret = replace_path(trans, root, reloc_root, path,\r\n&next_key, level, max_level);\r\n}\r\nif (ret < 0) {\r\nerr = ret;\r\ngoto out;\r\n}\r\nif (ret > 0) {\r\nlevel = ret;\r\nbtrfs_node_key_to_cpu(path->nodes[level], &key,\r\npath->slots[level]);\r\nreplaced = 1;\r\n}\r\nret = walk_up_reloc_tree(reloc_root, path, &level);\r\nif (ret > 0)\r\nbreak;\r\nBUG_ON(level == 0);\r\nbtrfs_node_key(path->nodes[level], &root_item->drop_progress,\r\npath->slots[level]);\r\nroot_item->drop_level = level;\r\nbtrfs_end_transaction_throttle(trans, root);\r\ntrans = NULL;\r\nbtrfs_btree_balance_dirty(root);\r\nif (replaced && rc->stage == UPDATE_DATA_PTRS)\r\ninvalidate_extent_cache(root, &key, &next_key);\r\n}\r\nleaf = btrfs_lock_root_node(root);\r\nret = btrfs_cow_block(trans, root, leaf, NULL, 0, &leaf);\r\nbtrfs_tree_unlock(leaf);\r\nfree_extent_buffer(leaf);\r\nif (ret < 0)\r\nerr = ret;\r\nout:\r\nbtrfs_free_path(path);\r\nif (err == 0) {\r\nmemset(&root_item->drop_progress, 0,\r\nsizeof(root_item->drop_progress));\r\nroot_item->drop_level = 0;\r\nbtrfs_set_root_refs(root_item, 0);\r\nbtrfs_update_reloc_root(trans, root);\r\n}\r\nif (trans)\r\nbtrfs_end_transaction_throttle(trans, root);\r\nbtrfs_btree_balance_dirty(root);\r\nif (replaced && rc->stage == UPDATE_DATA_PTRS)\r\ninvalidate_extent_cache(root, &key, &next_key);\r\nreturn err;\r\n}\r\nstatic noinline_for_stack\r\nint prepare_to_merge(struct reloc_control *rc, int err)\r\n{\r\nstruct btrfs_root *root = rc->extent_root;\r\nstruct btrfs_root *reloc_root;\r\nstruct btrfs_trans_handle *trans;\r\nLIST_HEAD(reloc_roots);\r\nu64 num_bytes = 0;\r\nint ret;\r\nmutex_lock(&root->fs_info->reloc_mutex);\r\nrc->merging_rsv_size += root->nodesize * (BTRFS_MAX_LEVEL - 1) * 2;\r\nrc->merging_rsv_size += rc->nodes_relocated * 2;\r\nmutex_unlock(&root->fs_info->reloc_mutex);\r\nagain:\r\nif (!err) {\r\nnum_bytes = rc->merging_rsv_size;\r\nret = btrfs_block_rsv_add(root, rc->block_rsv, num_bytes,\r\nBTRFS_RESERVE_FLUSH_ALL);\r\nif (ret)\r\nerr = ret;\r\n}\r\ntrans = btrfs_join_transaction(rc->extent_root);\r\nif (IS_ERR(trans)) {\r\nif (!err)\r\nbtrfs_block_rsv_release(rc->extent_root,\r\nrc->block_rsv, num_bytes);\r\nreturn PTR_ERR(trans);\r\n}\r\nif (!err) {\r\nif (num_bytes != rc->merging_rsv_size) {\r\nbtrfs_end_transaction(trans, rc->extent_root);\r\nbtrfs_block_rsv_release(rc->extent_root,\r\nrc->block_rsv, num_bytes);\r\ngoto again;\r\n}\r\n}\r\nrc->merge_reloc_tree = 1;\r\nwhile (!list_empty(&rc->reloc_roots)) {\r\nreloc_root = list_entry(rc->reloc_roots.next,\r\nstruct btrfs_root, root_list);\r\nlist_del_init(&reloc_root->root_list);\r\nroot = read_fs_root(reloc_root->fs_info,\r\nreloc_root->root_key.offset);\r\nBUG_ON(IS_ERR(root));\r\nBUG_ON(root->reloc_root != reloc_root);\r\nif (!err)\r\nbtrfs_set_root_refs(&reloc_root->root_item, 1);\r\nbtrfs_update_reloc_root(trans, root);\r\nlist_add(&reloc_root->root_list, &reloc_roots);\r\n}\r\nlist_splice(&reloc_roots, &rc->reloc_roots);\r\nif (!err)\r\nbtrfs_commit_transaction(trans, rc->extent_root);\r\nelse\r\nbtrfs_end_transaction(trans, rc->extent_root);\r\nreturn err;\r\n}\r\nstatic noinline_for_stack\r\nvoid free_reloc_roots(struct list_head *list)\r\n{\r\nstruct btrfs_root *reloc_root;\r\nwhile (!list_empty(list)) {\r\nreloc_root = list_entry(list->next, struct btrfs_root,\r\nroot_list);\r\n__del_reloc_root(reloc_root);\r\n}\r\n}\r\nstatic noinline_for_stack\r\nvoid merge_reloc_roots(struct reloc_control *rc)\r\n{\r\nstruct btrfs_root *root;\r\nstruct btrfs_root *reloc_root;\r\nu64 last_snap;\r\nu64 otransid;\r\nu64 objectid;\r\nLIST_HEAD(reloc_roots);\r\nint found = 0;\r\nint ret = 0;\r\nagain:\r\nroot = rc->extent_root;\r\nmutex_lock(&root->fs_info->reloc_mutex);\r\nlist_splice_init(&rc->reloc_roots, &reloc_roots);\r\nmutex_unlock(&root->fs_info->reloc_mutex);\r\nwhile (!list_empty(&reloc_roots)) {\r\nfound = 1;\r\nreloc_root = list_entry(reloc_roots.next,\r\nstruct btrfs_root, root_list);\r\nif (btrfs_root_refs(&reloc_root->root_item) > 0) {\r\nroot = read_fs_root(reloc_root->fs_info,\r\nreloc_root->root_key.offset);\r\nBUG_ON(IS_ERR(root));\r\nBUG_ON(root->reloc_root != reloc_root);\r\nret = merge_reloc_root(rc, root);\r\nif (ret) {\r\nif (list_empty(&reloc_root->root_list))\r\nlist_add_tail(&reloc_root->root_list,\r\n&reloc_roots);\r\ngoto out;\r\n}\r\n} else {\r\nlist_del_init(&reloc_root->root_list);\r\n}\r\nlast_snap = btrfs_root_rtransid(&reloc_root->root_item);\r\notransid = btrfs_root_otransid(&reloc_root->root_item);\r\nobjectid = reloc_root->root_key.offset;\r\nret = btrfs_drop_snapshot(reloc_root, rc->block_rsv, 0, 1);\r\nif (ret < 0) {\r\nif (list_empty(&reloc_root->root_list))\r\nlist_add_tail(&reloc_root->root_list,\r\n&reloc_roots);\r\ngoto out;\r\n}\r\n}\r\nif (found) {\r\nfound = 0;\r\ngoto again;\r\n}\r\nout:\r\nif (ret) {\r\nbtrfs_std_error(root->fs_info, ret);\r\nif (!list_empty(&reloc_roots))\r\nfree_reloc_roots(&reloc_roots);\r\nmutex_lock(&root->fs_info->reloc_mutex);\r\nlist_splice_init(&rc->reloc_roots, &reloc_roots);\r\nmutex_unlock(&root->fs_info->reloc_mutex);\r\nif (!list_empty(&reloc_roots))\r\nfree_reloc_roots(&reloc_roots);\r\n}\r\nBUG_ON(!RB_EMPTY_ROOT(&rc->reloc_root_tree.rb_root));\r\n}\r\nstatic void free_block_list(struct rb_root *blocks)\r\n{\r\nstruct tree_block *block;\r\nstruct rb_node *rb_node;\r\nwhile ((rb_node = rb_first(blocks))) {\r\nblock = rb_entry(rb_node, struct tree_block, rb_node);\r\nrb_erase(rb_node, blocks);\r\nkfree(block);\r\n}\r\n}\r\nstatic int record_reloc_root_in_trans(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *reloc_root)\r\n{\r\nstruct btrfs_root *root;\r\nif (reloc_root->last_trans == trans->transid)\r\nreturn 0;\r\nroot = read_fs_root(reloc_root->fs_info, reloc_root->root_key.offset);\r\nBUG_ON(IS_ERR(root));\r\nBUG_ON(root->reloc_root != reloc_root);\r\nreturn btrfs_record_root_in_trans(trans, root);\r\n}\r\nnoinline_for_stack\r\nstruct btrfs_root *select_one_root(struct btrfs_trans_handle *trans,\r\nstruct backref_node *node)\r\n{\r\nstruct backref_node *next;\r\nstruct btrfs_root *root;\r\nstruct btrfs_root *fs_root = NULL;\r\nstruct backref_edge *edges[BTRFS_MAX_LEVEL - 1];\r\nint index = 0;\r\nnext = node;\r\nwhile (1) {\r\ncond_resched();\r\nnext = walk_up_backref(next, edges, &index);\r\nroot = next->root;\r\nBUG_ON(!root);\r\nif (!test_bit(BTRFS_ROOT_REF_COWS, &root->state))\r\nreturn root;\r\nif (root->root_key.objectid != BTRFS_TREE_RELOC_OBJECTID)\r\nfs_root = root;\r\nif (next != node)\r\nreturn NULL;\r\nnext = walk_down_backref(edges, &index);\r\nif (!next || next->level <= node->level)\r\nbreak;\r\n}\r\nif (!fs_root)\r\nreturn ERR_PTR(-ENOENT);\r\nreturn fs_root;\r\n}\r\nstatic noinline_for_stack\r\nu64 calcu_metadata_size(struct reloc_control *rc,\r\nstruct backref_node *node, int reserve)\r\n{\r\nstruct backref_node *next = node;\r\nstruct backref_edge *edge;\r\nstruct backref_edge *edges[BTRFS_MAX_LEVEL - 1];\r\nu64 num_bytes = 0;\r\nint index = 0;\r\nBUG_ON(reserve && node->processed);\r\nwhile (next) {\r\ncond_resched();\r\nwhile (1) {\r\nif (next->processed && (reserve || next != node))\r\nbreak;\r\nnum_bytes += rc->extent_root->nodesize;\r\nif (list_empty(&next->upper))\r\nbreak;\r\nedge = list_entry(next->upper.next,\r\nstruct backref_edge, list[LOWER]);\r\nedges[index++] = edge;\r\nnext = edge->node[UPPER];\r\n}\r\nnext = walk_down_backref(edges, &index);\r\n}\r\nreturn num_bytes;\r\n}\r\nstatic int reserve_metadata_space(struct btrfs_trans_handle *trans,\r\nstruct reloc_control *rc,\r\nstruct backref_node *node)\r\n{\r\nstruct btrfs_root *root = rc->extent_root;\r\nu64 num_bytes;\r\nint ret;\r\nu64 tmp;\r\nnum_bytes = calcu_metadata_size(rc, node, 1) * 2;\r\ntrans->block_rsv = rc->block_rsv;\r\nrc->reserved_bytes += num_bytes;\r\nret = btrfs_block_rsv_refill(root, rc->block_rsv, num_bytes,\r\nBTRFS_RESERVE_FLUSH_ALL);\r\nif (ret) {\r\nif (ret == -EAGAIN) {\r\ntmp = rc->extent_root->nodesize *\r\nRELOCATION_RESERVED_NODES;\r\nwhile (tmp <= rc->reserved_bytes)\r\ntmp <<= 1;\r\nrc->block_rsv->size = tmp + rc->extent_root->nodesize *\r\nRELOCATION_RESERVED_NODES;\r\n}\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic int do_relocation(struct btrfs_trans_handle *trans,\r\nstruct reloc_control *rc,\r\nstruct backref_node *node,\r\nstruct btrfs_key *key,\r\nstruct btrfs_path *path, int lowest)\r\n{\r\nstruct backref_node *upper;\r\nstruct backref_edge *edge;\r\nstruct backref_edge *edges[BTRFS_MAX_LEVEL - 1];\r\nstruct btrfs_root *root;\r\nstruct extent_buffer *eb;\r\nu32 blocksize;\r\nu64 bytenr;\r\nu64 generation;\r\nint slot;\r\nint ret;\r\nint err = 0;\r\nBUG_ON(lowest && node->eb);\r\npath->lowest_level = node->level + 1;\r\nrc->backref_cache.path[node->level] = node;\r\nlist_for_each_entry(edge, &node->upper, list[LOWER]) {\r\ncond_resched();\r\nupper = edge->node[UPPER];\r\nroot = select_reloc_root(trans, rc, upper, edges);\r\nBUG_ON(!root);\r\nif (upper->eb && !upper->locked) {\r\nif (!lowest) {\r\nret = btrfs_bin_search(upper->eb, key,\r\nupper->level, &slot);\r\nBUG_ON(ret);\r\nbytenr = btrfs_node_blockptr(upper->eb, slot);\r\nif (node->eb->start == bytenr)\r\ngoto next;\r\n}\r\ndrop_node_buffer(upper);\r\n}\r\nif (!upper->eb) {\r\nret = btrfs_search_slot(trans, root, key, path, 0, 1);\r\nif (ret < 0) {\r\nerr = ret;\r\nbreak;\r\n}\r\nBUG_ON(ret > 0);\r\nif (!upper->eb) {\r\nupper->eb = path->nodes[upper->level];\r\npath->nodes[upper->level] = NULL;\r\n} else {\r\nBUG_ON(upper->eb != path->nodes[upper->level]);\r\n}\r\nupper->locked = 1;\r\npath->locks[upper->level] = 0;\r\nslot = path->slots[upper->level];\r\nbtrfs_release_path(path);\r\n} else {\r\nret = btrfs_bin_search(upper->eb, key, upper->level,\r\n&slot);\r\nBUG_ON(ret);\r\n}\r\nbytenr = btrfs_node_blockptr(upper->eb, slot);\r\nif (lowest) {\r\nBUG_ON(bytenr != node->bytenr);\r\n} else {\r\nif (node->eb->start == bytenr)\r\ngoto next;\r\n}\r\nblocksize = root->nodesize;\r\ngeneration = btrfs_node_ptr_generation(upper->eb, slot);\r\neb = read_tree_block(root, bytenr, generation);\r\nif (!eb || !extent_buffer_uptodate(eb)) {\r\nfree_extent_buffer(eb);\r\nerr = -EIO;\r\ngoto next;\r\n}\r\nbtrfs_tree_lock(eb);\r\nbtrfs_set_lock_blocking(eb);\r\nif (!node->eb) {\r\nret = btrfs_cow_block(trans, root, eb, upper->eb,\r\nslot, &eb);\r\nbtrfs_tree_unlock(eb);\r\nfree_extent_buffer(eb);\r\nif (ret < 0) {\r\nerr = ret;\r\ngoto next;\r\n}\r\nBUG_ON(node->eb != eb);\r\n} else {\r\nbtrfs_set_node_blockptr(upper->eb, slot,\r\nnode->eb->start);\r\nbtrfs_set_node_ptr_generation(upper->eb, slot,\r\ntrans->transid);\r\nbtrfs_mark_buffer_dirty(upper->eb);\r\nret = btrfs_inc_extent_ref(trans, root,\r\nnode->eb->start, blocksize,\r\nupper->eb->start,\r\nbtrfs_header_owner(upper->eb),\r\nnode->level, 0, 1);\r\nBUG_ON(ret);\r\nret = btrfs_drop_subtree(trans, root, eb, upper->eb);\r\nBUG_ON(ret);\r\n}\r\nnext:\r\nif (!upper->pending)\r\ndrop_node_buffer(upper);\r\nelse\r\nunlock_node_buffer(upper);\r\nif (err)\r\nbreak;\r\n}\r\nif (!err && node->pending) {\r\ndrop_node_buffer(node);\r\nlist_move_tail(&node->list, &rc->backref_cache.changed);\r\nnode->pending = 0;\r\n}\r\npath->lowest_level = 0;\r\nBUG_ON(err == -ENOSPC);\r\nreturn err;\r\n}\r\nstatic int link_to_upper(struct btrfs_trans_handle *trans,\r\nstruct reloc_control *rc,\r\nstruct backref_node *node,\r\nstruct btrfs_path *path)\r\n{\r\nstruct btrfs_key key;\r\nbtrfs_node_key_to_cpu(node->eb, &key, 0);\r\nreturn do_relocation(trans, rc, node, &key, path, 0);\r\n}\r\nstatic int finish_pending_nodes(struct btrfs_trans_handle *trans,\r\nstruct reloc_control *rc,\r\nstruct btrfs_path *path, int err)\r\n{\r\nLIST_HEAD(list);\r\nstruct backref_cache *cache = &rc->backref_cache;\r\nstruct backref_node *node;\r\nint level;\r\nint ret;\r\nfor (level = 0; level < BTRFS_MAX_LEVEL; level++) {\r\nwhile (!list_empty(&cache->pending[level])) {\r\nnode = list_entry(cache->pending[level].next,\r\nstruct backref_node, list);\r\nlist_move_tail(&node->list, &list);\r\nBUG_ON(!node->pending);\r\nif (!err) {\r\nret = link_to_upper(trans, rc, node, path);\r\nif (ret < 0)\r\nerr = ret;\r\n}\r\n}\r\nlist_splice_init(&list, &cache->pending[level]);\r\n}\r\nreturn err;\r\n}\r\nstatic void mark_block_processed(struct reloc_control *rc,\r\nu64 bytenr, u32 blocksize)\r\n{\r\nset_extent_bits(&rc->processed_blocks, bytenr, bytenr + blocksize - 1,\r\nEXTENT_DIRTY, GFP_NOFS);\r\n}\r\nstatic void __mark_block_processed(struct reloc_control *rc,\r\nstruct backref_node *node)\r\n{\r\nu32 blocksize;\r\nif (node->level == 0 ||\r\nin_block_group(node->bytenr, rc->block_group)) {\r\nblocksize = rc->extent_root->nodesize;\r\nmark_block_processed(rc, node->bytenr, blocksize);\r\n}\r\nnode->processed = 1;\r\n}\r\nstatic void update_processed_blocks(struct reloc_control *rc,\r\nstruct backref_node *node)\r\n{\r\nstruct backref_node *next = node;\r\nstruct backref_edge *edge;\r\nstruct backref_edge *edges[BTRFS_MAX_LEVEL - 1];\r\nint index = 0;\r\nwhile (next) {\r\ncond_resched();\r\nwhile (1) {\r\nif (next->processed)\r\nbreak;\r\n__mark_block_processed(rc, next);\r\nif (list_empty(&next->upper))\r\nbreak;\r\nedge = list_entry(next->upper.next,\r\nstruct backref_edge, list[LOWER]);\r\nedges[index++] = edge;\r\nnext = edge->node[UPPER];\r\n}\r\nnext = walk_down_backref(edges, &index);\r\n}\r\n}\r\nstatic int tree_block_processed(u64 bytenr, u32 blocksize,\r\nstruct reloc_control *rc)\r\n{\r\nif (test_range_bit(&rc->processed_blocks, bytenr,\r\nbytenr + blocksize - 1, EXTENT_DIRTY, 1, NULL))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int get_tree_block_key(struct reloc_control *rc,\r\nstruct tree_block *block)\r\n{\r\nstruct extent_buffer *eb;\r\nBUG_ON(block->key_ready);\r\neb = read_tree_block(rc->extent_root, block->bytenr,\r\nblock->key.offset);\r\nif (!eb || !extent_buffer_uptodate(eb)) {\r\nfree_extent_buffer(eb);\r\nreturn -EIO;\r\n}\r\nWARN_ON(btrfs_header_level(eb) != block->level);\r\nif (block->level == 0)\r\nbtrfs_item_key_to_cpu(eb, &block->key, 0);\r\nelse\r\nbtrfs_node_key_to_cpu(eb, &block->key, 0);\r\nfree_extent_buffer(eb);\r\nblock->key_ready = 1;\r\nreturn 0;\r\n}\r\nstatic int relocate_tree_block(struct btrfs_trans_handle *trans,\r\nstruct reloc_control *rc,\r\nstruct backref_node *node,\r\nstruct btrfs_key *key,\r\nstruct btrfs_path *path)\r\n{\r\nstruct btrfs_root *root;\r\nint ret = 0;\r\nif (!node)\r\nreturn 0;\r\nBUG_ON(node->processed);\r\nroot = select_one_root(trans, node);\r\nif (root == ERR_PTR(-ENOENT)) {\r\nupdate_processed_blocks(rc, node);\r\ngoto out;\r\n}\r\nif (!root || test_bit(BTRFS_ROOT_REF_COWS, &root->state)) {\r\nret = reserve_metadata_space(trans, rc, node);\r\nif (ret)\r\ngoto out;\r\n}\r\nif (root) {\r\nif (test_bit(BTRFS_ROOT_REF_COWS, &root->state)) {\r\nBUG_ON(node->new_bytenr);\r\nBUG_ON(!list_empty(&node->list));\r\nbtrfs_record_root_in_trans(trans, root);\r\nroot = root->reloc_root;\r\nnode->new_bytenr = root->node->start;\r\nnode->root = root;\r\nlist_add_tail(&node->list, &rc->backref_cache.changed);\r\n} else {\r\npath->lowest_level = node->level;\r\nret = btrfs_search_slot(trans, root, key, path, 0, 1);\r\nbtrfs_release_path(path);\r\nif (ret > 0)\r\nret = 0;\r\n}\r\nif (!ret)\r\nupdate_processed_blocks(rc, node);\r\n} else {\r\nret = do_relocation(trans, rc, node, key, path, 1);\r\n}\r\nout:\r\nif (ret || node->level == 0 || node->cowonly)\r\nremove_backref_node(&rc->backref_cache, node);\r\nreturn ret;\r\n}\r\nstatic noinline_for_stack\r\nint relocate_tree_blocks(struct btrfs_trans_handle *trans,\r\nstruct reloc_control *rc, struct rb_root *blocks)\r\n{\r\nstruct backref_node *node;\r\nstruct btrfs_path *path;\r\nstruct tree_block *block;\r\nstruct rb_node *rb_node;\r\nint ret;\r\nint err = 0;\r\npath = btrfs_alloc_path();\r\nif (!path) {\r\nerr = -ENOMEM;\r\ngoto out_free_blocks;\r\n}\r\nrb_node = rb_first(blocks);\r\nwhile (rb_node) {\r\nblock = rb_entry(rb_node, struct tree_block, rb_node);\r\nif (!block->key_ready)\r\nreadahead_tree_block(rc->extent_root, block->bytenr,\r\nblock->key.objectid);\r\nrb_node = rb_next(rb_node);\r\n}\r\nrb_node = rb_first(blocks);\r\nwhile (rb_node) {\r\nblock = rb_entry(rb_node, struct tree_block, rb_node);\r\nif (!block->key_ready) {\r\nerr = get_tree_block_key(rc, block);\r\nif (err)\r\ngoto out_free_path;\r\n}\r\nrb_node = rb_next(rb_node);\r\n}\r\nrb_node = rb_first(blocks);\r\nwhile (rb_node) {\r\nblock = rb_entry(rb_node, struct tree_block, rb_node);\r\nnode = build_backref_tree(rc, &block->key,\r\nblock->level, block->bytenr);\r\nif (IS_ERR(node)) {\r\nerr = PTR_ERR(node);\r\ngoto out;\r\n}\r\nret = relocate_tree_block(trans, rc, node, &block->key,\r\npath);\r\nif (ret < 0) {\r\nif (ret != -EAGAIN || rb_node == rb_first(blocks))\r\nerr = ret;\r\ngoto out;\r\n}\r\nrb_node = rb_next(rb_node);\r\n}\r\nout:\r\nerr = finish_pending_nodes(trans, rc, path, err);\r\nout_free_path:\r\nbtrfs_free_path(path);\r\nout_free_blocks:\r\nfree_block_list(blocks);\r\nreturn err;\r\n}\r\nstatic noinline_for_stack\r\nint prealloc_file_extent_cluster(struct inode *inode,\r\nstruct file_extent_cluster *cluster)\r\n{\r\nu64 alloc_hint = 0;\r\nu64 start;\r\nu64 end;\r\nu64 offset = BTRFS_I(inode)->index_cnt;\r\nu64 num_bytes;\r\nint nr = 0;\r\nint ret = 0;\r\nBUG_ON(cluster->start != cluster->boundary[0]);\r\nmutex_lock(&inode->i_mutex);\r\nret = btrfs_check_data_free_space(inode, cluster->end +\r\n1 - cluster->start);\r\nif (ret)\r\ngoto out;\r\nwhile (nr < cluster->nr) {\r\nstart = cluster->boundary[nr] - offset;\r\nif (nr + 1 < cluster->nr)\r\nend = cluster->boundary[nr + 1] - 1 - offset;\r\nelse\r\nend = cluster->end - offset;\r\nlock_extent(&BTRFS_I(inode)->io_tree, start, end);\r\nnum_bytes = end + 1 - start;\r\nret = btrfs_prealloc_file_range(inode, 0, start,\r\nnum_bytes, num_bytes,\r\nend + 1, &alloc_hint);\r\nunlock_extent(&BTRFS_I(inode)->io_tree, start, end);\r\nif (ret)\r\nbreak;\r\nnr++;\r\n}\r\nbtrfs_free_reserved_data_space(inode, cluster->end +\r\n1 - cluster->start);\r\nout:\r\nmutex_unlock(&inode->i_mutex);\r\nreturn ret;\r\n}\r\nstatic noinline_for_stack\r\nint setup_extent_mapping(struct inode *inode, u64 start, u64 end,\r\nu64 block_start)\r\n{\r\nstruct btrfs_root *root = BTRFS_I(inode)->root;\r\nstruct extent_map_tree *em_tree = &BTRFS_I(inode)->extent_tree;\r\nstruct extent_map *em;\r\nint ret = 0;\r\nem = alloc_extent_map();\r\nif (!em)\r\nreturn -ENOMEM;\r\nem->start = start;\r\nem->len = end + 1 - start;\r\nem->block_len = em->len;\r\nem->block_start = block_start;\r\nem->bdev = root->fs_info->fs_devices->latest_bdev;\r\nset_bit(EXTENT_FLAG_PINNED, &em->flags);\r\nlock_extent(&BTRFS_I(inode)->io_tree, start, end);\r\nwhile (1) {\r\nwrite_lock(&em_tree->lock);\r\nret = add_extent_mapping(em_tree, em, 0);\r\nwrite_unlock(&em_tree->lock);\r\nif (ret != -EEXIST) {\r\nfree_extent_map(em);\r\nbreak;\r\n}\r\nbtrfs_drop_extent_cache(inode, start, end, 0);\r\n}\r\nunlock_extent(&BTRFS_I(inode)->io_tree, start, end);\r\nreturn ret;\r\n}\r\nstatic int relocate_file_extent_cluster(struct inode *inode,\r\nstruct file_extent_cluster *cluster)\r\n{\r\nu64 page_start;\r\nu64 page_end;\r\nu64 offset = BTRFS_I(inode)->index_cnt;\r\nunsigned long index;\r\nunsigned long last_index;\r\nstruct page *page;\r\nstruct file_ra_state *ra;\r\ngfp_t mask = btrfs_alloc_write_mask(inode->i_mapping);\r\nint nr = 0;\r\nint ret = 0;\r\nif (!cluster->nr)\r\nreturn 0;\r\nra = kzalloc(sizeof(*ra), GFP_NOFS);\r\nif (!ra)\r\nreturn -ENOMEM;\r\nret = prealloc_file_extent_cluster(inode, cluster);\r\nif (ret)\r\ngoto out;\r\nfile_ra_state_init(ra, inode->i_mapping);\r\nret = setup_extent_mapping(inode, cluster->start - offset,\r\ncluster->end - offset, cluster->start);\r\nif (ret)\r\ngoto out;\r\nindex = (cluster->start - offset) >> PAGE_CACHE_SHIFT;\r\nlast_index = (cluster->end - offset) >> PAGE_CACHE_SHIFT;\r\nwhile (index <= last_index) {\r\nret = btrfs_delalloc_reserve_metadata(inode, PAGE_CACHE_SIZE);\r\nif (ret)\r\ngoto out;\r\npage = find_lock_page(inode->i_mapping, index);\r\nif (!page) {\r\npage_cache_sync_readahead(inode->i_mapping,\r\nra, NULL, index,\r\nlast_index + 1 - index);\r\npage = find_or_create_page(inode->i_mapping, index,\r\nmask);\r\nif (!page) {\r\nbtrfs_delalloc_release_metadata(inode,\r\nPAGE_CACHE_SIZE);\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\n}\r\nif (PageReadahead(page)) {\r\npage_cache_async_readahead(inode->i_mapping,\r\nra, NULL, page, index,\r\nlast_index + 1 - index);\r\n}\r\nif (!PageUptodate(page)) {\r\nbtrfs_readpage(NULL, page);\r\nlock_page(page);\r\nif (!PageUptodate(page)) {\r\nunlock_page(page);\r\npage_cache_release(page);\r\nbtrfs_delalloc_release_metadata(inode,\r\nPAGE_CACHE_SIZE);\r\nret = -EIO;\r\ngoto out;\r\n}\r\n}\r\npage_start = page_offset(page);\r\npage_end = page_start + PAGE_CACHE_SIZE - 1;\r\nlock_extent(&BTRFS_I(inode)->io_tree, page_start, page_end);\r\nset_page_extent_mapped(page);\r\nif (nr < cluster->nr &&\r\npage_start + offset == cluster->boundary[nr]) {\r\nset_extent_bits(&BTRFS_I(inode)->io_tree,\r\npage_start, page_end,\r\nEXTENT_BOUNDARY, GFP_NOFS);\r\nnr++;\r\n}\r\nbtrfs_set_extent_delalloc(inode, page_start, page_end, NULL);\r\nset_page_dirty(page);\r\nunlock_extent(&BTRFS_I(inode)->io_tree,\r\npage_start, page_end);\r\nunlock_page(page);\r\npage_cache_release(page);\r\nindex++;\r\nbalance_dirty_pages_ratelimited(inode->i_mapping);\r\nbtrfs_throttle(BTRFS_I(inode)->root);\r\n}\r\nWARN_ON(nr != cluster->nr);\r\nout:\r\nkfree(ra);\r\nreturn ret;\r\n}\r\nstatic noinline_for_stack\r\nint relocate_data_extent(struct inode *inode, struct btrfs_key *extent_key,\r\nstruct file_extent_cluster *cluster)\r\n{\r\nint ret;\r\nif (cluster->nr > 0 && extent_key->objectid != cluster->end + 1) {\r\nret = relocate_file_extent_cluster(inode, cluster);\r\nif (ret)\r\nreturn ret;\r\ncluster->nr = 0;\r\n}\r\nif (!cluster->nr)\r\ncluster->start = extent_key->objectid;\r\nelse\r\nBUG_ON(cluster->nr >= MAX_EXTENTS);\r\ncluster->end = extent_key->objectid + extent_key->offset - 1;\r\ncluster->boundary[cluster->nr] = extent_key->objectid;\r\ncluster->nr++;\r\nif (cluster->nr >= MAX_EXTENTS) {\r\nret = relocate_file_extent_cluster(inode, cluster);\r\nif (ret)\r\nreturn ret;\r\ncluster->nr = 0;\r\n}\r\nreturn 0;\r\n}\r\nstatic int get_ref_objectid_v0(struct reloc_control *rc,\r\nstruct btrfs_path *path,\r\nstruct btrfs_key *extent_key,\r\nu64 *ref_objectid, int *path_change)\r\n{\r\nstruct btrfs_key key;\r\nstruct extent_buffer *leaf;\r\nstruct btrfs_extent_ref_v0 *ref0;\r\nint ret;\r\nint slot;\r\nleaf = path->nodes[0];\r\nslot = path->slots[0];\r\nwhile (1) {\r\nif (slot >= btrfs_header_nritems(leaf)) {\r\nret = btrfs_next_leaf(rc->extent_root, path);\r\nif (ret < 0)\r\nreturn ret;\r\nBUG_ON(ret > 0);\r\nleaf = path->nodes[0];\r\nslot = path->slots[0];\r\nif (path_change)\r\n*path_change = 1;\r\n}\r\nbtrfs_item_key_to_cpu(leaf, &key, slot);\r\nif (key.objectid != extent_key->objectid)\r\nreturn -ENOENT;\r\nif (key.type != BTRFS_EXTENT_REF_V0_KEY) {\r\nslot++;\r\ncontinue;\r\n}\r\nref0 = btrfs_item_ptr(leaf, slot,\r\nstruct btrfs_extent_ref_v0);\r\n*ref_objectid = btrfs_ref_objectid_v0(leaf, ref0);\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nstatic int add_tree_block(struct reloc_control *rc,\r\nstruct btrfs_key *extent_key,\r\nstruct btrfs_path *path,\r\nstruct rb_root *blocks)\r\n{\r\nstruct extent_buffer *eb;\r\nstruct btrfs_extent_item *ei;\r\nstruct btrfs_tree_block_info *bi;\r\nstruct tree_block *block;\r\nstruct rb_node *rb_node;\r\nu32 item_size;\r\nint level = -1;\r\nu64 generation;\r\neb = path->nodes[0];\r\nitem_size = btrfs_item_size_nr(eb, path->slots[0]);\r\nif (extent_key->type == BTRFS_METADATA_ITEM_KEY ||\r\nitem_size >= sizeof(*ei) + sizeof(*bi)) {\r\nei = btrfs_item_ptr(eb, path->slots[0],\r\nstruct btrfs_extent_item);\r\nif (extent_key->type == BTRFS_EXTENT_ITEM_KEY) {\r\nbi = (struct btrfs_tree_block_info *)(ei + 1);\r\nlevel = btrfs_tree_block_level(eb, bi);\r\n} else {\r\nlevel = (int)extent_key->offset;\r\n}\r\ngeneration = btrfs_extent_generation(eb, ei);\r\n} else {\r\n#ifdef BTRFS_COMPAT_EXTENT_TREE_V0\r\nu64 ref_owner;\r\nint ret;\r\nBUG_ON(item_size != sizeof(struct btrfs_extent_item_v0));\r\nret = get_ref_objectid_v0(rc, path, extent_key,\r\n&ref_owner, NULL);\r\nif (ret < 0)\r\nreturn ret;\r\nBUG_ON(ref_owner >= BTRFS_MAX_LEVEL);\r\nlevel = (int)ref_owner;\r\ngeneration = 0;\r\n#else\r\nBUG();\r\n#endif\r\n}\r\nbtrfs_release_path(path);\r\nBUG_ON(level == -1);\r\nblock = kmalloc(sizeof(*block), GFP_NOFS);\r\nif (!block)\r\nreturn -ENOMEM;\r\nblock->bytenr = extent_key->objectid;\r\nblock->key.objectid = rc->extent_root->nodesize;\r\nblock->key.offset = generation;\r\nblock->level = level;\r\nblock->key_ready = 0;\r\nrb_node = tree_insert(blocks, block->bytenr, &block->rb_node);\r\nif (rb_node)\r\nbackref_tree_panic(rb_node, -EEXIST, block->bytenr);\r\nreturn 0;\r\n}\r\nstatic int __add_tree_block(struct reloc_control *rc,\r\nu64 bytenr, u32 blocksize,\r\nstruct rb_root *blocks)\r\n{\r\nstruct btrfs_path *path;\r\nstruct btrfs_key key;\r\nint ret;\r\nbool skinny = btrfs_fs_incompat(rc->extent_root->fs_info,\r\nSKINNY_METADATA);\r\nif (tree_block_processed(bytenr, blocksize, rc))\r\nreturn 0;\r\nif (tree_search(blocks, bytenr))\r\nreturn 0;\r\npath = btrfs_alloc_path();\r\nif (!path)\r\nreturn -ENOMEM;\r\nagain:\r\nkey.objectid = bytenr;\r\nif (skinny) {\r\nkey.type = BTRFS_METADATA_ITEM_KEY;\r\nkey.offset = (u64)-1;\r\n} else {\r\nkey.type = BTRFS_EXTENT_ITEM_KEY;\r\nkey.offset = blocksize;\r\n}\r\npath->search_commit_root = 1;\r\npath->skip_locking = 1;\r\nret = btrfs_search_slot(NULL, rc->extent_root, &key, path, 0, 0);\r\nif (ret < 0)\r\ngoto out;\r\nif (ret > 0 && skinny) {\r\nif (path->slots[0]) {\r\npath->slots[0]--;\r\nbtrfs_item_key_to_cpu(path->nodes[0], &key,\r\npath->slots[0]);\r\nif (key.objectid == bytenr &&\r\n(key.type == BTRFS_METADATA_ITEM_KEY ||\r\n(key.type == BTRFS_EXTENT_ITEM_KEY &&\r\nkey.offset == blocksize)))\r\nret = 0;\r\n}\r\nif (ret) {\r\nskinny = false;\r\nbtrfs_release_path(path);\r\ngoto again;\r\n}\r\n}\r\nBUG_ON(ret);\r\nret = add_tree_block(rc, &key, path, blocks);\r\nout:\r\nbtrfs_free_path(path);\r\nreturn ret;\r\n}\r\nstatic int block_use_full_backref(struct reloc_control *rc,\r\nstruct extent_buffer *eb)\r\n{\r\nu64 flags;\r\nint ret;\r\nif (btrfs_header_flag(eb, BTRFS_HEADER_FLAG_RELOC) ||\r\nbtrfs_header_backref_rev(eb) < BTRFS_MIXED_BACKREF_REV)\r\nreturn 1;\r\nret = btrfs_lookup_extent_info(NULL, rc->extent_root,\r\neb->start, btrfs_header_level(eb), 1,\r\nNULL, &flags);\r\nBUG_ON(ret);\r\nif (flags & BTRFS_BLOCK_FLAG_FULL_BACKREF)\r\nret = 1;\r\nelse\r\nret = 0;\r\nreturn ret;\r\n}\r\nstatic int delete_block_group_cache(struct btrfs_fs_info *fs_info,\r\nstruct inode *inode, u64 ino)\r\n{\r\nstruct btrfs_key key;\r\nstruct btrfs_root *root = fs_info->tree_root;\r\nstruct btrfs_trans_handle *trans;\r\nint ret = 0;\r\nif (inode)\r\ngoto truncate;\r\nkey.objectid = ino;\r\nkey.type = BTRFS_INODE_ITEM_KEY;\r\nkey.offset = 0;\r\ninode = btrfs_iget(fs_info->sb, &key, root, NULL);\r\nif (IS_ERR(inode) || is_bad_inode(inode)) {\r\nif (!IS_ERR(inode))\r\niput(inode);\r\nreturn -ENOENT;\r\n}\r\ntruncate:\r\nret = btrfs_check_trunc_cache_free_space(root,\r\n&fs_info->global_block_rsv);\r\nif (ret)\r\ngoto out;\r\ntrans = btrfs_join_transaction(root);\r\nif (IS_ERR(trans)) {\r\nret = PTR_ERR(trans);\r\ngoto out;\r\n}\r\nret = btrfs_truncate_free_space_cache(root, trans, inode);\r\nbtrfs_end_transaction(trans, root);\r\nbtrfs_btree_balance_dirty(root);\r\nout:\r\niput(inode);\r\nreturn ret;\r\n}\r\nstatic int find_data_references(struct reloc_control *rc,\r\nstruct btrfs_key *extent_key,\r\nstruct extent_buffer *leaf,\r\nstruct btrfs_extent_data_ref *ref,\r\nstruct rb_root *blocks)\r\n{\r\nstruct btrfs_path *path;\r\nstruct tree_block *block;\r\nstruct btrfs_root *root;\r\nstruct btrfs_file_extent_item *fi;\r\nstruct rb_node *rb_node;\r\nstruct btrfs_key key;\r\nu64 ref_root;\r\nu64 ref_objectid;\r\nu64 ref_offset;\r\nu32 ref_count;\r\nu32 nritems;\r\nint err = 0;\r\nint added = 0;\r\nint counted;\r\nint ret;\r\nref_root = btrfs_extent_data_ref_root(leaf, ref);\r\nref_objectid = btrfs_extent_data_ref_objectid(leaf, ref);\r\nref_offset = btrfs_extent_data_ref_offset(leaf, ref);\r\nref_count = btrfs_extent_data_ref_count(leaf, ref);\r\nif (ref_root == BTRFS_ROOT_TREE_OBJECTID) {\r\nret = delete_block_group_cache(rc->extent_root->fs_info,\r\nNULL, ref_objectid);\r\nif (ret != -ENOENT)\r\nreturn ret;\r\nret = 0;\r\n}\r\npath = btrfs_alloc_path();\r\nif (!path)\r\nreturn -ENOMEM;\r\npath->reada = 1;\r\nroot = read_fs_root(rc->extent_root->fs_info, ref_root);\r\nif (IS_ERR(root)) {\r\nerr = PTR_ERR(root);\r\ngoto out;\r\n}\r\nkey.objectid = ref_objectid;\r\nkey.type = BTRFS_EXTENT_DATA_KEY;\r\nif (ref_offset > ((u64)-1 << 32))\r\nkey.offset = 0;\r\nelse\r\nkey.offset = ref_offset;\r\npath->search_commit_root = 1;\r\npath->skip_locking = 1;\r\nret = btrfs_search_slot(NULL, root, &key, path, 0, 0);\r\nif (ret < 0) {\r\nerr = ret;\r\ngoto out;\r\n}\r\nleaf = path->nodes[0];\r\nnritems = btrfs_header_nritems(leaf);\r\nif (block_use_full_backref(rc, leaf))\r\ncounted = 0;\r\nelse\r\ncounted = 1;\r\nrb_node = tree_search(blocks, leaf->start);\r\nif (rb_node) {\r\nif (counted)\r\nadded = 1;\r\nelse\r\npath->slots[0] = nritems;\r\n}\r\nwhile (ref_count > 0) {\r\nwhile (path->slots[0] >= nritems) {\r\nret = btrfs_next_leaf(root, path);\r\nif (ret < 0) {\r\nerr = ret;\r\ngoto out;\r\n}\r\nif (WARN_ON(ret > 0))\r\ngoto out;\r\nleaf = path->nodes[0];\r\nnritems = btrfs_header_nritems(leaf);\r\nadded = 0;\r\nif (block_use_full_backref(rc, leaf))\r\ncounted = 0;\r\nelse\r\ncounted = 1;\r\nrb_node = tree_search(blocks, leaf->start);\r\nif (rb_node) {\r\nif (counted)\r\nadded = 1;\r\nelse\r\npath->slots[0] = nritems;\r\n}\r\n}\r\nbtrfs_item_key_to_cpu(leaf, &key, path->slots[0]);\r\nif (WARN_ON(key.objectid != ref_objectid ||\r\nkey.type != BTRFS_EXTENT_DATA_KEY))\r\nbreak;\r\nfi = btrfs_item_ptr(leaf, path->slots[0],\r\nstruct btrfs_file_extent_item);\r\nif (btrfs_file_extent_type(leaf, fi) ==\r\nBTRFS_FILE_EXTENT_INLINE)\r\ngoto next;\r\nif (btrfs_file_extent_disk_bytenr(leaf, fi) !=\r\nextent_key->objectid)\r\ngoto next;\r\nkey.offset -= btrfs_file_extent_offset(leaf, fi);\r\nif (key.offset != ref_offset)\r\ngoto next;\r\nif (counted)\r\nref_count--;\r\nif (added)\r\ngoto next;\r\nif (!tree_block_processed(leaf->start, leaf->len, rc)) {\r\nblock = kmalloc(sizeof(*block), GFP_NOFS);\r\nif (!block) {\r\nerr = -ENOMEM;\r\nbreak;\r\n}\r\nblock->bytenr = leaf->start;\r\nbtrfs_item_key_to_cpu(leaf, &block->key, 0);\r\nblock->level = 0;\r\nblock->key_ready = 1;\r\nrb_node = tree_insert(blocks, block->bytenr,\r\n&block->rb_node);\r\nif (rb_node)\r\nbackref_tree_panic(rb_node, -EEXIST,\r\nblock->bytenr);\r\n}\r\nif (counted)\r\nadded = 1;\r\nelse\r\npath->slots[0] = nritems;\r\nnext:\r\npath->slots[0]++;\r\n}\r\nout:\r\nbtrfs_free_path(path);\r\nreturn err;\r\n}\r\nstatic noinline_for_stack\r\nint find_next_extent(struct btrfs_trans_handle *trans,\r\nstruct reloc_control *rc, struct btrfs_path *path,\r\nstruct btrfs_key *extent_key)\r\n{\r\nstruct btrfs_key key;\r\nstruct extent_buffer *leaf;\r\nu64 start, end, last;\r\nint ret;\r\nlast = rc->block_group->key.objectid + rc->block_group->key.offset;\r\nwhile (1) {\r\ncond_resched();\r\nif (rc->search_start >= last) {\r\nret = 1;\r\nbreak;\r\n}\r\nkey.objectid = rc->search_start;\r\nkey.type = BTRFS_EXTENT_ITEM_KEY;\r\nkey.offset = 0;\r\npath->search_commit_root = 1;\r\npath->skip_locking = 1;\r\nret = btrfs_search_slot(NULL, rc->extent_root, &key, path,\r\n0, 0);\r\nif (ret < 0)\r\nbreak;\r\nnext:\r\nleaf = path->nodes[0];\r\nif (path->slots[0] >= btrfs_header_nritems(leaf)) {\r\nret = btrfs_next_leaf(rc->extent_root, path);\r\nif (ret != 0)\r\nbreak;\r\nleaf = path->nodes[0];\r\n}\r\nbtrfs_item_key_to_cpu(leaf, &key, path->slots[0]);\r\nif (key.objectid >= last) {\r\nret = 1;\r\nbreak;\r\n}\r\nif (key.type != BTRFS_EXTENT_ITEM_KEY &&\r\nkey.type != BTRFS_METADATA_ITEM_KEY) {\r\npath->slots[0]++;\r\ngoto next;\r\n}\r\nif (key.type == BTRFS_EXTENT_ITEM_KEY &&\r\nkey.objectid + key.offset <= rc->search_start) {\r\npath->slots[0]++;\r\ngoto next;\r\n}\r\nif (key.type == BTRFS_METADATA_ITEM_KEY &&\r\nkey.objectid + rc->extent_root->nodesize <=\r\nrc->search_start) {\r\npath->slots[0]++;\r\ngoto next;\r\n}\r\nret = find_first_extent_bit(&rc->processed_blocks,\r\nkey.objectid, &start, &end,\r\nEXTENT_DIRTY, NULL);\r\nif (ret == 0 && start <= key.objectid) {\r\nbtrfs_release_path(path);\r\nrc->search_start = end + 1;\r\n} else {\r\nif (key.type == BTRFS_EXTENT_ITEM_KEY)\r\nrc->search_start = key.objectid + key.offset;\r\nelse\r\nrc->search_start = key.objectid +\r\nrc->extent_root->nodesize;\r\nmemcpy(extent_key, &key, sizeof(key));\r\nreturn 0;\r\n}\r\n}\r\nbtrfs_release_path(path);\r\nreturn ret;\r\n}\r\nstatic void set_reloc_control(struct reloc_control *rc)\r\n{\r\nstruct btrfs_fs_info *fs_info = rc->extent_root->fs_info;\r\nmutex_lock(&fs_info->reloc_mutex);\r\nfs_info->reloc_ctl = rc;\r\nmutex_unlock(&fs_info->reloc_mutex);\r\n}\r\nstatic void unset_reloc_control(struct reloc_control *rc)\r\n{\r\nstruct btrfs_fs_info *fs_info = rc->extent_root->fs_info;\r\nmutex_lock(&fs_info->reloc_mutex);\r\nfs_info->reloc_ctl = NULL;\r\nmutex_unlock(&fs_info->reloc_mutex);\r\n}\r\nstatic int check_extent_flags(u64 flags)\r\n{\r\nif ((flags & BTRFS_EXTENT_FLAG_DATA) &&\r\n(flags & BTRFS_EXTENT_FLAG_TREE_BLOCK))\r\nreturn 1;\r\nif (!(flags & BTRFS_EXTENT_FLAG_DATA) &&\r\n!(flags & BTRFS_EXTENT_FLAG_TREE_BLOCK))\r\nreturn 1;\r\nif ((flags & BTRFS_EXTENT_FLAG_DATA) &&\r\n(flags & BTRFS_BLOCK_FLAG_FULL_BACKREF))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic noinline_for_stack\r\nint prepare_to_relocate(struct reloc_control *rc)\r\n{\r\nstruct btrfs_trans_handle *trans;\r\nrc->block_rsv = btrfs_alloc_block_rsv(rc->extent_root,\r\nBTRFS_BLOCK_RSV_TEMP);\r\nif (!rc->block_rsv)\r\nreturn -ENOMEM;\r\nmemset(&rc->cluster, 0, sizeof(rc->cluster));\r\nrc->search_start = rc->block_group->key.objectid;\r\nrc->extents_found = 0;\r\nrc->nodes_relocated = 0;\r\nrc->merging_rsv_size = 0;\r\nrc->reserved_bytes = 0;\r\nrc->block_rsv->size = rc->extent_root->nodesize *\r\nRELOCATION_RESERVED_NODES;\r\nrc->create_reloc_tree = 1;\r\nset_reloc_control(rc);\r\ntrans = btrfs_join_transaction(rc->extent_root);\r\nif (IS_ERR(trans)) {\r\nunset_reloc_control(rc);\r\nreturn PTR_ERR(trans);\r\n}\r\nbtrfs_commit_transaction(trans, rc->extent_root);\r\nreturn 0;\r\n}\r\nstatic noinline_for_stack int relocate_block_group(struct reloc_control *rc)\r\n{\r\nstruct rb_root blocks = RB_ROOT;\r\nstruct btrfs_key key;\r\nstruct btrfs_trans_handle *trans = NULL;\r\nstruct btrfs_path *path;\r\nstruct btrfs_extent_item *ei;\r\nu64 flags;\r\nu32 item_size;\r\nint ret;\r\nint err = 0;\r\nint progress = 0;\r\npath = btrfs_alloc_path();\r\nif (!path)\r\nreturn -ENOMEM;\r\npath->reada = 1;\r\nret = prepare_to_relocate(rc);\r\nif (ret) {\r\nerr = ret;\r\ngoto out_free;\r\n}\r\nwhile (1) {\r\nrc->reserved_bytes = 0;\r\nret = btrfs_block_rsv_refill(rc->extent_root,\r\nrc->block_rsv, rc->block_rsv->size,\r\nBTRFS_RESERVE_FLUSH_ALL);\r\nif (ret) {\r\nerr = ret;\r\nbreak;\r\n}\r\nprogress++;\r\ntrans = btrfs_start_transaction(rc->extent_root, 0);\r\nif (IS_ERR(trans)) {\r\nerr = PTR_ERR(trans);\r\ntrans = NULL;\r\nbreak;\r\n}\r\nrestart:\r\nif (update_backref_cache(trans, &rc->backref_cache)) {\r\nbtrfs_end_transaction(trans, rc->extent_root);\r\ncontinue;\r\n}\r\nret = find_next_extent(trans, rc, path, &key);\r\nif (ret < 0)\r\nerr = ret;\r\nif (ret != 0)\r\nbreak;\r\nrc->extents_found++;\r\nei = btrfs_item_ptr(path->nodes[0], path->slots[0],\r\nstruct btrfs_extent_item);\r\nitem_size = btrfs_item_size_nr(path->nodes[0], path->slots[0]);\r\nif (item_size >= sizeof(*ei)) {\r\nflags = btrfs_extent_flags(path->nodes[0], ei);\r\nret = check_extent_flags(flags);\r\nBUG_ON(ret);\r\n} else {\r\n#ifdef BTRFS_COMPAT_EXTENT_TREE_V0\r\nu64 ref_owner;\r\nint path_change = 0;\r\nBUG_ON(item_size !=\r\nsizeof(struct btrfs_extent_item_v0));\r\nret = get_ref_objectid_v0(rc, path, &key, &ref_owner,\r\n&path_change);\r\nif (ref_owner < BTRFS_FIRST_FREE_OBJECTID)\r\nflags = BTRFS_EXTENT_FLAG_TREE_BLOCK;\r\nelse\r\nflags = BTRFS_EXTENT_FLAG_DATA;\r\nif (path_change) {\r\nbtrfs_release_path(path);\r\npath->search_commit_root = 1;\r\npath->skip_locking = 1;\r\nret = btrfs_search_slot(NULL, rc->extent_root,\r\n&key, path, 0, 0);\r\nif (ret < 0) {\r\nerr = ret;\r\nbreak;\r\n}\r\nBUG_ON(ret > 0);\r\n}\r\n#else\r\nBUG();\r\n#endif\r\n}\r\nif (flags & BTRFS_EXTENT_FLAG_TREE_BLOCK) {\r\nret = add_tree_block(rc, &key, path, &blocks);\r\n} else if (rc->stage == UPDATE_DATA_PTRS &&\r\n(flags & BTRFS_EXTENT_FLAG_DATA)) {\r\nret = add_data_references(rc, &key, path, &blocks);\r\n} else {\r\nbtrfs_release_path(path);\r\nret = 0;\r\n}\r\nif (ret < 0) {\r\nerr = ret;\r\nbreak;\r\n}\r\nif (!RB_EMPTY_ROOT(&blocks)) {\r\nret = relocate_tree_blocks(trans, rc, &blocks);\r\nif (ret < 0) {\r\nrc->backref_cache.last_trans = trans->transid - 1;\r\nif (ret != -EAGAIN) {\r\nerr = ret;\r\nbreak;\r\n}\r\nrc->extents_found--;\r\nrc->search_start = key.objectid;\r\n}\r\n}\r\nbtrfs_end_transaction_throttle(trans, rc->extent_root);\r\nbtrfs_btree_balance_dirty(rc->extent_root);\r\ntrans = NULL;\r\nif (rc->stage == MOVE_DATA_EXTENTS &&\r\n(flags & BTRFS_EXTENT_FLAG_DATA)) {\r\nrc->found_file_extent = 1;\r\nret = relocate_data_extent(rc->data_inode,\r\n&key, &rc->cluster);\r\nif (ret < 0) {\r\nerr = ret;\r\nbreak;\r\n}\r\n}\r\n}\r\nif (trans && progress && err == -ENOSPC) {\r\nret = btrfs_force_chunk_alloc(trans, rc->extent_root,\r\nrc->block_group->flags);\r\nif (ret == 0) {\r\nerr = 0;\r\nprogress = 0;\r\ngoto restart;\r\n}\r\n}\r\nbtrfs_release_path(path);\r\nclear_extent_bits(&rc->processed_blocks, 0, (u64)-1, EXTENT_DIRTY,\r\nGFP_NOFS);\r\nif (trans) {\r\nbtrfs_end_transaction_throttle(trans, rc->extent_root);\r\nbtrfs_btree_balance_dirty(rc->extent_root);\r\n}\r\nif (!err) {\r\nret = relocate_file_extent_cluster(rc->data_inode,\r\n&rc->cluster);\r\nif (ret < 0)\r\nerr = ret;\r\n}\r\nrc->create_reloc_tree = 0;\r\nset_reloc_control(rc);\r\nbackref_cache_cleanup(&rc->backref_cache);\r\nbtrfs_block_rsv_release(rc->extent_root, rc->block_rsv, (u64)-1);\r\nerr = prepare_to_merge(rc, err);\r\nmerge_reloc_roots(rc);\r\nrc->merge_reloc_tree = 0;\r\nunset_reloc_control(rc);\r\nbtrfs_block_rsv_release(rc->extent_root, rc->block_rsv, (u64)-1);\r\ntrans = btrfs_join_transaction(rc->extent_root);\r\nif (IS_ERR(trans))\r\nerr = PTR_ERR(trans);\r\nelse\r\nbtrfs_commit_transaction(trans, rc->extent_root);\r\nout_free:\r\nbtrfs_free_block_rsv(rc->extent_root, rc->block_rsv);\r\nbtrfs_free_path(path);\r\nreturn err;\r\n}\r\nstatic int __insert_orphan_inode(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root, u64 objectid)\r\n{\r\nstruct btrfs_path *path;\r\nstruct btrfs_inode_item *item;\r\nstruct extent_buffer *leaf;\r\nint ret;\r\npath = btrfs_alloc_path();\r\nif (!path)\r\nreturn -ENOMEM;\r\nret = btrfs_insert_empty_inode(trans, root, path, objectid);\r\nif (ret)\r\ngoto out;\r\nleaf = path->nodes[0];\r\nitem = btrfs_item_ptr(leaf, path->slots[0], struct btrfs_inode_item);\r\nmemset_extent_buffer(leaf, 0, (unsigned long)item, sizeof(*item));\r\nbtrfs_set_inode_generation(leaf, item, 1);\r\nbtrfs_set_inode_size(leaf, item, 0);\r\nbtrfs_set_inode_mode(leaf, item, S_IFREG | 0600);\r\nbtrfs_set_inode_flags(leaf, item, BTRFS_INODE_NOCOMPRESS |\r\nBTRFS_INODE_PREALLOC);\r\nbtrfs_mark_buffer_dirty(leaf);\r\nout:\r\nbtrfs_free_path(path);\r\nreturn ret;\r\n}\r\nstatic struct reloc_control *alloc_reloc_control(struct btrfs_fs_info *fs_info)\r\n{\r\nstruct reloc_control *rc;\r\nrc = kzalloc(sizeof(*rc), GFP_NOFS);\r\nif (!rc)\r\nreturn NULL;\r\nINIT_LIST_HEAD(&rc->reloc_roots);\r\nbackref_cache_init(&rc->backref_cache);\r\nmapping_tree_init(&rc->reloc_root_tree);\r\nextent_io_tree_init(&rc->processed_blocks,\r\nfs_info->btree_inode->i_mapping);\r\nreturn rc;\r\n}\r\nint btrfs_relocate_block_group(struct btrfs_root *extent_root, u64 group_start)\r\n{\r\nstruct btrfs_fs_info *fs_info = extent_root->fs_info;\r\nstruct reloc_control *rc;\r\nstruct inode *inode;\r\nstruct btrfs_path *path;\r\nint ret;\r\nint rw = 0;\r\nint err = 0;\r\nrc = alloc_reloc_control(fs_info);\r\nif (!rc)\r\nreturn -ENOMEM;\r\nrc->extent_root = extent_root;\r\nrc->block_group = btrfs_lookup_block_group(fs_info, group_start);\r\nBUG_ON(!rc->block_group);\r\nif (!rc->block_group->ro) {\r\nret = btrfs_set_block_group_ro(extent_root, rc->block_group);\r\nif (ret) {\r\nerr = ret;\r\ngoto out;\r\n}\r\nrw = 1;\r\n}\r\npath = btrfs_alloc_path();\r\nif (!path) {\r\nerr = -ENOMEM;\r\ngoto out;\r\n}\r\ninode = lookup_free_space_inode(fs_info->tree_root, rc->block_group,\r\npath);\r\nbtrfs_free_path(path);\r\nif (!IS_ERR(inode))\r\nret = delete_block_group_cache(fs_info, inode, 0);\r\nelse\r\nret = PTR_ERR(inode);\r\nif (ret && ret != -ENOENT) {\r\nerr = ret;\r\ngoto out;\r\n}\r\nrc->data_inode = create_reloc_inode(fs_info, rc->block_group);\r\nif (IS_ERR(rc->data_inode)) {\r\nerr = PTR_ERR(rc->data_inode);\r\nrc->data_inode = NULL;\r\ngoto out;\r\n}\r\nbtrfs_info(extent_root->fs_info, "relocating block group %llu flags %llu",\r\nrc->block_group->key.objectid, rc->block_group->flags);\r\nret = btrfs_start_delalloc_roots(fs_info, 0, -1);\r\nif (ret < 0) {\r\nerr = ret;\r\ngoto out;\r\n}\r\nbtrfs_wait_ordered_roots(fs_info, -1);\r\nwhile (1) {\r\nmutex_lock(&fs_info->cleaner_mutex);\r\nret = relocate_block_group(rc);\r\nmutex_unlock(&fs_info->cleaner_mutex);\r\nif (ret < 0) {\r\nerr = ret;\r\ngoto out;\r\n}\r\nif (rc->extents_found == 0)\r\nbreak;\r\nbtrfs_info(extent_root->fs_info, "found %llu extents",\r\nrc->extents_found);\r\nif (rc->stage == MOVE_DATA_EXTENTS && rc->found_file_extent) {\r\nret = btrfs_wait_ordered_range(rc->data_inode, 0,\r\n(u64)-1);\r\nif (ret) {\r\nerr = ret;\r\ngoto out;\r\n}\r\ninvalidate_mapping_pages(rc->data_inode->i_mapping,\r\n0, -1);\r\nrc->stage = UPDATE_DATA_PTRS;\r\n}\r\n}\r\nWARN_ON(rc->block_group->pinned > 0);\r\nWARN_ON(rc->block_group->reserved > 0);\r\nWARN_ON(btrfs_block_group_used(&rc->block_group->item) > 0);\r\nout:\r\nif (err && rw)\r\nbtrfs_set_block_group_rw(extent_root, rc->block_group);\r\niput(rc->data_inode);\r\nbtrfs_put_block_group(rc->block_group);\r\nkfree(rc);\r\nreturn err;\r\n}\r\nstatic noinline_for_stack int mark_garbage_root(struct btrfs_root *root)\r\n{\r\nstruct btrfs_trans_handle *trans;\r\nint ret, err;\r\ntrans = btrfs_start_transaction(root->fs_info->tree_root, 0);\r\nif (IS_ERR(trans))\r\nreturn PTR_ERR(trans);\r\nmemset(&root->root_item.drop_progress, 0,\r\nsizeof(root->root_item.drop_progress));\r\nroot->root_item.drop_level = 0;\r\nbtrfs_set_root_refs(&root->root_item, 0);\r\nret = btrfs_update_root(trans, root->fs_info->tree_root,\r\n&root->root_key, &root->root_item);\r\nerr = btrfs_end_transaction(trans, root->fs_info->tree_root);\r\nif (err)\r\nreturn err;\r\nreturn ret;\r\n}\r\nint btrfs_recover_relocation(struct btrfs_root *root)\r\n{\r\nLIST_HEAD(reloc_roots);\r\nstruct btrfs_key key;\r\nstruct btrfs_root *fs_root;\r\nstruct btrfs_root *reloc_root;\r\nstruct btrfs_path *path;\r\nstruct extent_buffer *leaf;\r\nstruct reloc_control *rc = NULL;\r\nstruct btrfs_trans_handle *trans;\r\nint ret;\r\nint err = 0;\r\npath = btrfs_alloc_path();\r\nif (!path)\r\nreturn -ENOMEM;\r\npath->reada = -1;\r\nkey.objectid = BTRFS_TREE_RELOC_OBJECTID;\r\nkey.type = BTRFS_ROOT_ITEM_KEY;\r\nkey.offset = (u64)-1;\r\nwhile (1) {\r\nret = btrfs_search_slot(NULL, root->fs_info->tree_root, &key,\r\npath, 0, 0);\r\nif (ret < 0) {\r\nerr = ret;\r\ngoto out;\r\n}\r\nif (ret > 0) {\r\nif (path->slots[0] == 0)\r\nbreak;\r\npath->slots[0]--;\r\n}\r\nleaf = path->nodes[0];\r\nbtrfs_item_key_to_cpu(leaf, &key, path->slots[0]);\r\nbtrfs_release_path(path);\r\nif (key.objectid != BTRFS_TREE_RELOC_OBJECTID ||\r\nkey.type != BTRFS_ROOT_ITEM_KEY)\r\nbreak;\r\nreloc_root = btrfs_read_fs_root(root, &key);\r\nif (IS_ERR(reloc_root)) {\r\nerr = PTR_ERR(reloc_root);\r\ngoto out;\r\n}\r\nlist_add(&reloc_root->root_list, &reloc_roots);\r\nif (btrfs_root_refs(&reloc_root->root_item) > 0) {\r\nfs_root = read_fs_root(root->fs_info,\r\nreloc_root->root_key.offset);\r\nif (IS_ERR(fs_root)) {\r\nret = PTR_ERR(fs_root);\r\nif (ret != -ENOENT) {\r\nerr = ret;\r\ngoto out;\r\n}\r\nret = mark_garbage_root(reloc_root);\r\nif (ret < 0) {\r\nerr = ret;\r\ngoto out;\r\n}\r\n}\r\n}\r\nif (key.offset == 0)\r\nbreak;\r\nkey.offset--;\r\n}\r\nbtrfs_release_path(path);\r\nif (list_empty(&reloc_roots))\r\ngoto out;\r\nrc = alloc_reloc_control(root->fs_info);\r\nif (!rc) {\r\nerr = -ENOMEM;\r\ngoto out;\r\n}\r\nrc->extent_root = root->fs_info->extent_root;\r\nset_reloc_control(rc);\r\ntrans = btrfs_join_transaction(rc->extent_root);\r\nif (IS_ERR(trans)) {\r\nunset_reloc_control(rc);\r\nerr = PTR_ERR(trans);\r\ngoto out_free;\r\n}\r\nrc->merge_reloc_tree = 1;\r\nwhile (!list_empty(&reloc_roots)) {\r\nreloc_root = list_entry(reloc_roots.next,\r\nstruct btrfs_root, root_list);\r\nlist_del(&reloc_root->root_list);\r\nif (btrfs_root_refs(&reloc_root->root_item) == 0) {\r\nlist_add_tail(&reloc_root->root_list,\r\n&rc->reloc_roots);\r\ncontinue;\r\n}\r\nfs_root = read_fs_root(root->fs_info,\r\nreloc_root->root_key.offset);\r\nif (IS_ERR(fs_root)) {\r\nerr = PTR_ERR(fs_root);\r\ngoto out_free;\r\n}\r\nerr = __add_reloc_root(reloc_root);\r\nBUG_ON(err < 0);\r\nfs_root->reloc_root = reloc_root;\r\n}\r\nerr = btrfs_commit_transaction(trans, rc->extent_root);\r\nif (err)\r\ngoto out_free;\r\nmerge_reloc_roots(rc);\r\nunset_reloc_control(rc);\r\ntrans = btrfs_join_transaction(rc->extent_root);\r\nif (IS_ERR(trans))\r\nerr = PTR_ERR(trans);\r\nelse\r\nerr = btrfs_commit_transaction(trans, rc->extent_root);\r\nout_free:\r\nkfree(rc);\r\nout:\r\nif (!list_empty(&reloc_roots))\r\nfree_reloc_roots(&reloc_roots);\r\nbtrfs_free_path(path);\r\nif (err == 0) {\r\nfs_root = read_fs_root(root->fs_info,\r\nBTRFS_DATA_RELOC_TREE_OBJECTID);\r\nif (IS_ERR(fs_root))\r\nerr = PTR_ERR(fs_root);\r\nelse\r\nerr = btrfs_orphan_cleanup(fs_root);\r\n}\r\nreturn err;\r\n}\r\nint btrfs_reloc_clone_csums(struct inode *inode, u64 file_pos, u64 len)\r\n{\r\nstruct btrfs_ordered_sum *sums;\r\nstruct btrfs_ordered_extent *ordered;\r\nstruct btrfs_root *root = BTRFS_I(inode)->root;\r\nint ret;\r\nu64 disk_bytenr;\r\nu64 new_bytenr;\r\nLIST_HEAD(list);\r\nordered = btrfs_lookup_ordered_extent(inode, file_pos);\r\nBUG_ON(ordered->file_offset != file_pos || ordered->len != len);\r\ndisk_bytenr = file_pos + BTRFS_I(inode)->index_cnt;\r\nret = btrfs_lookup_csums_range(root->fs_info->csum_root, disk_bytenr,\r\ndisk_bytenr + len - 1, &list, 0);\r\nif (ret)\r\ngoto out;\r\nwhile (!list_empty(&list)) {\r\nsums = list_entry(list.next, struct btrfs_ordered_sum, list);\r\nlist_del_init(&sums->list);\r\nnew_bytenr = ordered->start + (sums->bytenr - disk_bytenr);\r\nsums->bytenr = new_bytenr;\r\nbtrfs_add_ordered_sum(inode, ordered, sums);\r\n}\r\nout:\r\nbtrfs_put_ordered_extent(ordered);\r\nreturn ret;\r\n}\r\nint btrfs_reloc_cow_block(struct btrfs_trans_handle *trans,\r\nstruct btrfs_root *root, struct extent_buffer *buf,\r\nstruct extent_buffer *cow)\r\n{\r\nstruct reloc_control *rc;\r\nstruct backref_node *node;\r\nint first_cow = 0;\r\nint level;\r\nint ret = 0;\r\nrc = root->fs_info->reloc_ctl;\r\nif (!rc)\r\nreturn 0;\r\nBUG_ON(rc->stage == UPDATE_DATA_PTRS &&\r\nroot->root_key.objectid == BTRFS_DATA_RELOC_TREE_OBJECTID);\r\nif (root->root_key.objectid == BTRFS_TREE_RELOC_OBJECTID) {\r\nif (buf == root->node)\r\n__update_reloc_root(root, cow->start);\r\n}\r\nlevel = btrfs_header_level(buf);\r\nif (btrfs_header_generation(buf) <=\r\nbtrfs_root_last_snapshot(&root->root_item))\r\nfirst_cow = 1;\r\nif (root->root_key.objectid == BTRFS_TREE_RELOC_OBJECTID &&\r\nrc->create_reloc_tree) {\r\nWARN_ON(!first_cow && level == 0);\r\nnode = rc->backref_cache.path[level];\r\nBUG_ON(node->bytenr != buf->start &&\r\nnode->new_bytenr != buf->start);\r\ndrop_node_buffer(node);\r\nextent_buffer_get(cow);\r\nnode->eb = cow;\r\nnode->new_bytenr = cow->start;\r\nif (!node->pending) {\r\nlist_move_tail(&node->list,\r\n&rc->backref_cache.pending[level]);\r\nnode->pending = 1;\r\n}\r\nif (first_cow)\r\n__mark_block_processed(rc, node);\r\nif (first_cow && level > 0)\r\nrc->nodes_relocated += buf->len;\r\n}\r\nif (level == 0 && first_cow && rc->stage == UPDATE_DATA_PTRS)\r\nret = replace_file_extents(trans, rc, root, cow);\r\nreturn ret;\r\n}\r\nvoid btrfs_reloc_pre_snapshot(struct btrfs_trans_handle *trans,\r\nstruct btrfs_pending_snapshot *pending,\r\nu64 *bytes_to_reserve)\r\n{\r\nstruct btrfs_root *root;\r\nstruct reloc_control *rc;\r\nroot = pending->root;\r\nif (!root->reloc_root)\r\nreturn;\r\nrc = root->fs_info->reloc_ctl;\r\nif (!rc->merge_reloc_tree)\r\nreturn;\r\nroot = root->reloc_root;\r\nBUG_ON(btrfs_root_refs(&root->root_item) == 0);\r\n*bytes_to_reserve += rc->nodes_relocated;\r\n}\r\nint btrfs_reloc_post_snapshot(struct btrfs_trans_handle *trans,\r\nstruct btrfs_pending_snapshot *pending)\r\n{\r\nstruct btrfs_root *root = pending->root;\r\nstruct btrfs_root *reloc_root;\r\nstruct btrfs_root *new_root;\r\nstruct reloc_control *rc;\r\nint ret;\r\nif (!root->reloc_root)\r\nreturn 0;\r\nrc = root->fs_info->reloc_ctl;\r\nrc->merging_rsv_size += rc->nodes_relocated;\r\nif (rc->merge_reloc_tree) {\r\nret = btrfs_block_rsv_migrate(&pending->block_rsv,\r\nrc->block_rsv,\r\nrc->nodes_relocated);\r\nif (ret)\r\nreturn ret;\r\n}\r\nnew_root = pending->snap;\r\nreloc_root = create_reloc_root(trans, root->reloc_root,\r\nnew_root->root_key.objectid);\r\nif (IS_ERR(reloc_root))\r\nreturn PTR_ERR(reloc_root);\r\nret = __add_reloc_root(reloc_root);\r\nBUG_ON(ret < 0);\r\nnew_root->reloc_root = reloc_root;\r\nif (rc->create_reloc_tree)\r\nret = clone_backref_node(trans, rc, root, reloc_root);\r\nreturn ret;\r\n}
