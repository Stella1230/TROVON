static void evergreen_init_golden_registers(struct radeon_device *rdev)\r\n{\r\nswitch (rdev->family) {\r\ncase CHIP_CYPRESS:\r\ncase CHIP_HEMLOCK:\r\nradeon_program_register_sequence(rdev,\r\nevergreen_golden_registers,\r\n(const u32)ARRAY_SIZE(evergreen_golden_registers));\r\nradeon_program_register_sequence(rdev,\r\nevergreen_golden_registers2,\r\n(const u32)ARRAY_SIZE(evergreen_golden_registers2));\r\nradeon_program_register_sequence(rdev,\r\ncypress_mgcg_init,\r\n(const u32)ARRAY_SIZE(cypress_mgcg_init));\r\nbreak;\r\ncase CHIP_JUNIPER:\r\nradeon_program_register_sequence(rdev,\r\nevergreen_golden_registers,\r\n(const u32)ARRAY_SIZE(evergreen_golden_registers));\r\nradeon_program_register_sequence(rdev,\r\nevergreen_golden_registers2,\r\n(const u32)ARRAY_SIZE(evergreen_golden_registers2));\r\nradeon_program_register_sequence(rdev,\r\njuniper_mgcg_init,\r\n(const u32)ARRAY_SIZE(juniper_mgcg_init));\r\nbreak;\r\ncase CHIP_REDWOOD:\r\nradeon_program_register_sequence(rdev,\r\nevergreen_golden_registers,\r\n(const u32)ARRAY_SIZE(evergreen_golden_registers));\r\nradeon_program_register_sequence(rdev,\r\nevergreen_golden_registers2,\r\n(const u32)ARRAY_SIZE(evergreen_golden_registers2));\r\nradeon_program_register_sequence(rdev,\r\nredwood_mgcg_init,\r\n(const u32)ARRAY_SIZE(redwood_mgcg_init));\r\nbreak;\r\ncase CHIP_CEDAR:\r\nradeon_program_register_sequence(rdev,\r\ncedar_golden_registers,\r\n(const u32)ARRAY_SIZE(cedar_golden_registers));\r\nradeon_program_register_sequence(rdev,\r\nevergreen_golden_registers2,\r\n(const u32)ARRAY_SIZE(evergreen_golden_registers2));\r\nradeon_program_register_sequence(rdev,\r\ncedar_mgcg_init,\r\n(const u32)ARRAY_SIZE(cedar_mgcg_init));\r\nbreak;\r\ncase CHIP_PALM:\r\nradeon_program_register_sequence(rdev,\r\nwrestler_golden_registers,\r\n(const u32)ARRAY_SIZE(wrestler_golden_registers));\r\nbreak;\r\ncase CHIP_SUMO:\r\nradeon_program_register_sequence(rdev,\r\nsupersumo_golden_registers,\r\n(const u32)ARRAY_SIZE(supersumo_golden_registers));\r\nbreak;\r\ncase CHIP_SUMO2:\r\nradeon_program_register_sequence(rdev,\r\nsupersumo_golden_registers,\r\n(const u32)ARRAY_SIZE(supersumo_golden_registers));\r\nradeon_program_register_sequence(rdev,\r\nsumo_golden_registers,\r\n(const u32)ARRAY_SIZE(sumo_golden_registers));\r\nbreak;\r\ncase CHIP_BARTS:\r\nradeon_program_register_sequence(rdev,\r\nbarts_golden_registers,\r\n(const u32)ARRAY_SIZE(barts_golden_registers));\r\nbreak;\r\ncase CHIP_TURKS:\r\nradeon_program_register_sequence(rdev,\r\nturks_golden_registers,\r\n(const u32)ARRAY_SIZE(turks_golden_registers));\r\nbreak;\r\ncase CHIP_CAICOS:\r\nradeon_program_register_sequence(rdev,\r\ncaicos_golden_registers,\r\n(const u32)ARRAY_SIZE(caicos_golden_registers));\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nvoid evergreen_tiling_fields(unsigned tiling_flags, unsigned *bankw,\r\nunsigned *bankh, unsigned *mtaspect,\r\nunsigned *tile_split)\r\n{\r\n*bankw = (tiling_flags >> RADEON_TILING_EG_BANKW_SHIFT) & RADEON_TILING_EG_BANKW_MASK;\r\n*bankh = (tiling_flags >> RADEON_TILING_EG_BANKH_SHIFT) & RADEON_TILING_EG_BANKH_MASK;\r\n*mtaspect = (tiling_flags >> RADEON_TILING_EG_MACRO_TILE_ASPECT_SHIFT) & RADEON_TILING_EG_MACRO_TILE_ASPECT_MASK;\r\n*tile_split = (tiling_flags >> RADEON_TILING_EG_TILE_SPLIT_SHIFT) & RADEON_TILING_EG_TILE_SPLIT_MASK;\r\nswitch (*bankw) {\r\ndefault:\r\ncase 1: *bankw = EVERGREEN_ADDR_SURF_BANK_WIDTH_1; break;\r\ncase 2: *bankw = EVERGREEN_ADDR_SURF_BANK_WIDTH_2; break;\r\ncase 4: *bankw = EVERGREEN_ADDR_SURF_BANK_WIDTH_4; break;\r\ncase 8: *bankw = EVERGREEN_ADDR_SURF_BANK_WIDTH_8; break;\r\n}\r\nswitch (*bankh) {\r\ndefault:\r\ncase 1: *bankh = EVERGREEN_ADDR_SURF_BANK_HEIGHT_1; break;\r\ncase 2: *bankh = EVERGREEN_ADDR_SURF_BANK_HEIGHT_2; break;\r\ncase 4: *bankh = EVERGREEN_ADDR_SURF_BANK_HEIGHT_4; break;\r\ncase 8: *bankh = EVERGREEN_ADDR_SURF_BANK_HEIGHT_8; break;\r\n}\r\nswitch (*mtaspect) {\r\ndefault:\r\ncase 1: *mtaspect = EVERGREEN_ADDR_SURF_MACRO_TILE_ASPECT_1; break;\r\ncase 2: *mtaspect = EVERGREEN_ADDR_SURF_MACRO_TILE_ASPECT_2; break;\r\ncase 4: *mtaspect = EVERGREEN_ADDR_SURF_MACRO_TILE_ASPECT_4; break;\r\ncase 8: *mtaspect = EVERGREEN_ADDR_SURF_MACRO_TILE_ASPECT_8; break;\r\n}\r\n}\r\nstatic int sumo_set_uvd_clock(struct radeon_device *rdev, u32 clock,\r\nu32 cntl_reg, u32 status_reg)\r\n{\r\nint r, i;\r\nstruct atom_clock_dividers dividers;\r\nr = radeon_atom_get_clock_dividers(rdev, COMPUTE_ENGINE_PLL_PARAM,\r\nclock, false, &dividers);\r\nif (r)\r\nreturn r;\r\nWREG32_P(cntl_reg, dividers.post_div, ~(DCLK_DIR_CNTL_EN|DCLK_DIVIDER_MASK));\r\nfor (i = 0; i < 100; i++) {\r\nif (RREG32(status_reg) & DCLK_STATUS)\r\nbreak;\r\nmdelay(10);\r\n}\r\nif (i == 100)\r\nreturn -ETIMEDOUT;\r\nreturn 0;\r\n}\r\nint sumo_set_uvd_clocks(struct radeon_device *rdev, u32 vclk, u32 dclk)\r\n{\r\nint r = 0;\r\nu32 cg_scratch = RREG32(CG_SCRATCH1);\r\nr = sumo_set_uvd_clock(rdev, vclk, CG_VCLK_CNTL, CG_VCLK_STATUS);\r\nif (r)\r\ngoto done;\r\ncg_scratch &= 0xffff0000;\r\ncg_scratch |= vclk / 100;\r\nr = sumo_set_uvd_clock(rdev, dclk, CG_DCLK_CNTL, CG_DCLK_STATUS);\r\nif (r)\r\ngoto done;\r\ncg_scratch &= 0x0000ffff;\r\ncg_scratch |= (dclk / 100) << 16;\r\ndone:\r\nWREG32(CG_SCRATCH1, cg_scratch);\r\nreturn r;\r\n}\r\nint evergreen_set_uvd_clocks(struct radeon_device *rdev, u32 vclk, u32 dclk)\r\n{\r\nunsigned fb_div = 0, vclk_div = 0, dclk_div = 0;\r\nint r;\r\nWREG32_P(CG_UPLL_FUNC_CNTL_2,\r\nVCLK_SRC_SEL(1) | DCLK_SRC_SEL(1),\r\n~(VCLK_SRC_SEL_MASK | DCLK_SRC_SEL_MASK));\r\nWREG32_P(CG_UPLL_FUNC_CNTL, UPLL_BYPASS_EN_MASK, ~UPLL_BYPASS_EN_MASK);\r\nif (!vclk || !dclk) {\r\nWREG32_P(CG_UPLL_FUNC_CNTL, UPLL_SLEEP_MASK, ~UPLL_SLEEP_MASK);\r\nreturn 0;\r\n}\r\nr = radeon_uvd_calc_upll_dividers(rdev, vclk, dclk, 125000, 250000,\r\n16384, 0x03FFFFFF, 0, 128, 5,\r\n&fb_div, &vclk_div, &dclk_div);\r\nif (r)\r\nreturn r;\r\nWREG32_P(CG_UPLL_FUNC_CNTL, UPLL_VCO_MODE_MASK, ~UPLL_VCO_MODE_MASK);\r\nWREG32_P(CG_UPLL_FUNC_CNTL, UPLL_SLEEP_MASK, ~UPLL_SLEEP_MASK);\r\nWREG32_P(CG_UPLL_FUNC_CNTL, 0, ~UPLL_SLEEP_MASK);\r\nWREG32_P(CG_UPLL_FUNC_CNTL, 0, ~UPLL_RESET_MASK);\r\nmdelay(1);\r\nr = radeon_uvd_send_upll_ctlreq(rdev, CG_UPLL_FUNC_CNTL);\r\nif (r)\r\nreturn r;\r\nWREG32_P(CG_UPLL_FUNC_CNTL, UPLL_RESET_MASK, ~UPLL_RESET_MASK);\r\nWREG32_P(CG_UPLL_SPREAD_SPECTRUM, 0, ~SSEN_MASK);\r\nWREG32_P(CG_UPLL_FUNC_CNTL_3, UPLL_FB_DIV(fb_div), ~UPLL_FB_DIV_MASK);\r\nWREG32_P(CG_UPLL_FUNC_CNTL, 0, ~UPLL_REF_DIV_MASK);\r\nif (fb_div < 307200)\r\nWREG32_P(CG_UPLL_FUNC_CNTL_4, 0, ~UPLL_SPARE_ISPARE9);\r\nelse\r\nWREG32_P(CG_UPLL_FUNC_CNTL_4, UPLL_SPARE_ISPARE9, ~UPLL_SPARE_ISPARE9);\r\nWREG32_P(CG_UPLL_FUNC_CNTL_2,\r\nUPLL_PDIV_A(vclk_div) | UPLL_PDIV_B(dclk_div),\r\n~(UPLL_PDIV_A_MASK | UPLL_PDIV_B_MASK));\r\nmdelay(15);\r\nWREG32_P(CG_UPLL_FUNC_CNTL, 0, ~UPLL_RESET_MASK);\r\nmdelay(15);\r\nWREG32_P(CG_UPLL_FUNC_CNTL, 0, ~UPLL_BYPASS_EN_MASK);\r\nr = radeon_uvd_send_upll_ctlreq(rdev, CG_UPLL_FUNC_CNTL);\r\nif (r)\r\nreturn r;\r\nWREG32_P(CG_UPLL_FUNC_CNTL_2,\r\nVCLK_SRC_SEL(2) | DCLK_SRC_SEL(2),\r\n~(VCLK_SRC_SEL_MASK | DCLK_SRC_SEL_MASK));\r\nmdelay(100);\r\nreturn 0;\r\n}\r\nvoid evergreen_fix_pci_max_read_req_size(struct radeon_device *rdev)\r\n{\r\nint readrq;\r\nu16 v;\r\nreadrq = pcie_get_readrq(rdev->pdev);\r\nv = ffs(readrq) - 8;\r\nif ((v == 0) || (v == 6) || (v == 7))\r\npcie_set_readrq(rdev->pdev, 512);\r\n}\r\nvoid dce4_program_fmt(struct drm_encoder *encoder)\r\n{\r\nstruct drm_device *dev = encoder->dev;\r\nstruct radeon_device *rdev = dev->dev_private;\r\nstruct radeon_encoder *radeon_encoder = to_radeon_encoder(encoder);\r\nstruct radeon_crtc *radeon_crtc = to_radeon_crtc(encoder->crtc);\r\nstruct drm_connector *connector = radeon_get_connector_for_encoder(encoder);\r\nint bpc = 0;\r\nu32 tmp = 0;\r\nenum radeon_connector_dither dither = RADEON_FMT_DITHER_DISABLE;\r\nif (connector) {\r\nstruct radeon_connector *radeon_connector = to_radeon_connector(connector);\r\nbpc = radeon_get_monitor_bpc(connector);\r\ndither = radeon_connector->dither;\r\n}\r\nif (radeon_encoder->devices & ATOM_DEVICE_LCD_SUPPORT)\r\nreturn;\r\nif ((radeon_encoder->encoder_id == ENCODER_OBJECT_ID_INTERNAL_KLDSCP_DAC1) ||\r\n(radeon_encoder->encoder_id == ENCODER_OBJECT_ID_INTERNAL_KLDSCP_DAC2))\r\nreturn;\r\nif (bpc == 0)\r\nreturn;\r\nswitch (bpc) {\r\ncase 6:\r\nif (dither == RADEON_FMT_DITHER_ENABLE)\r\ntmp |= (FMT_FRAME_RANDOM_ENABLE | FMT_HIGHPASS_RANDOM_ENABLE |\r\nFMT_SPATIAL_DITHER_EN);\r\nelse\r\ntmp |= FMT_TRUNCATE_EN;\r\nbreak;\r\ncase 8:\r\nif (dither == RADEON_FMT_DITHER_ENABLE)\r\ntmp |= (FMT_FRAME_RANDOM_ENABLE | FMT_HIGHPASS_RANDOM_ENABLE |\r\nFMT_RGB_RANDOM_ENABLE |\r\nFMT_SPATIAL_DITHER_EN | FMT_SPATIAL_DITHER_DEPTH);\r\nelse\r\ntmp |= (FMT_TRUNCATE_EN | FMT_TRUNCATE_DEPTH);\r\nbreak;\r\ncase 10:\r\ndefault:\r\nbreak;\r\n}\r\nWREG32(FMT_BIT_DEPTH_CONTROL + radeon_crtc->crtc_offset, tmp);\r\n}\r\nstatic bool dce4_is_in_vblank(struct radeon_device *rdev, int crtc)\r\n{\r\nif (RREG32(EVERGREEN_CRTC_STATUS + crtc_offsets[crtc]) & EVERGREEN_CRTC_V_BLANK)\r\nreturn true;\r\nelse\r\nreturn false;\r\n}\r\nstatic bool dce4_is_counter_moving(struct radeon_device *rdev, int crtc)\r\n{\r\nu32 pos1, pos2;\r\npos1 = RREG32(EVERGREEN_CRTC_STATUS_POSITION + crtc_offsets[crtc]);\r\npos2 = RREG32(EVERGREEN_CRTC_STATUS_POSITION + crtc_offsets[crtc]);\r\nif (pos1 != pos2)\r\nreturn true;\r\nelse\r\nreturn false;\r\n}\r\nvoid dce4_wait_for_vblank(struct radeon_device *rdev, int crtc)\r\n{\r\nunsigned i = 0;\r\nif (crtc >= rdev->num_crtc)\r\nreturn;\r\nif (!(RREG32(EVERGREEN_CRTC_CONTROL + crtc_offsets[crtc]) & EVERGREEN_CRTC_MASTER_EN))\r\nreturn;\r\nwhile (dce4_is_in_vblank(rdev, crtc)) {\r\nif (i++ % 100 == 0) {\r\nif (!dce4_is_counter_moving(rdev, crtc))\r\nbreak;\r\n}\r\n}\r\nwhile (!dce4_is_in_vblank(rdev, crtc)) {\r\nif (i++ % 100 == 0) {\r\nif (!dce4_is_counter_moving(rdev, crtc))\r\nbreak;\r\n}\r\n}\r\n}\r\nvoid evergreen_page_flip(struct radeon_device *rdev, int crtc_id, u64 crtc_base)\r\n{\r\nstruct radeon_crtc *radeon_crtc = rdev->mode_info.crtcs[crtc_id];\r\nu32 tmp = RREG32(EVERGREEN_GRPH_UPDATE + radeon_crtc->crtc_offset);\r\nint i;\r\ntmp |= EVERGREEN_GRPH_UPDATE_LOCK;\r\nWREG32(EVERGREEN_GRPH_UPDATE + radeon_crtc->crtc_offset, tmp);\r\nWREG32(EVERGREEN_GRPH_SECONDARY_SURFACE_ADDRESS_HIGH + radeon_crtc->crtc_offset,\r\nupper_32_bits(crtc_base));\r\nWREG32(EVERGREEN_GRPH_SECONDARY_SURFACE_ADDRESS + radeon_crtc->crtc_offset,\r\n(u32)crtc_base);\r\nWREG32(EVERGREEN_GRPH_PRIMARY_SURFACE_ADDRESS_HIGH + radeon_crtc->crtc_offset,\r\nupper_32_bits(crtc_base));\r\nWREG32(EVERGREEN_GRPH_PRIMARY_SURFACE_ADDRESS + radeon_crtc->crtc_offset,\r\n(u32)crtc_base);\r\nfor (i = 0; i < rdev->usec_timeout; i++) {\r\nif (RREG32(EVERGREEN_GRPH_UPDATE + radeon_crtc->crtc_offset) & EVERGREEN_GRPH_SURFACE_UPDATE_PENDING)\r\nbreak;\r\nudelay(1);\r\n}\r\nDRM_DEBUG("Update pending now high. Unlocking vupdate_lock.\n");\r\ntmp &= ~EVERGREEN_GRPH_UPDATE_LOCK;\r\nWREG32(EVERGREEN_GRPH_UPDATE + radeon_crtc->crtc_offset, tmp);\r\n}\r\nbool evergreen_page_flip_pending(struct radeon_device *rdev, int crtc_id)\r\n{\r\nstruct radeon_crtc *radeon_crtc = rdev->mode_info.crtcs[crtc_id];\r\nreturn !!(RREG32(EVERGREEN_GRPH_UPDATE + radeon_crtc->crtc_offset) &\r\nEVERGREEN_GRPH_SURFACE_UPDATE_PENDING);\r\n}\r\nint evergreen_get_temp(struct radeon_device *rdev)\r\n{\r\nu32 temp, toffset;\r\nint actual_temp = 0;\r\nif (rdev->family == CHIP_JUNIPER) {\r\ntoffset = (RREG32(CG_THERMAL_CTRL) & TOFFSET_MASK) >>\r\nTOFFSET_SHIFT;\r\ntemp = (RREG32(CG_TS0_STATUS) & TS0_ADC_DOUT_MASK) >>\r\nTS0_ADC_DOUT_SHIFT;\r\nif (toffset & 0x100)\r\nactual_temp = temp / 2 - (0x200 - toffset);\r\nelse\r\nactual_temp = temp / 2 + toffset;\r\nactual_temp = actual_temp * 1000;\r\n} else {\r\ntemp = (RREG32(CG_MULT_THERMAL_STATUS) & ASIC_T_MASK) >>\r\nASIC_T_SHIFT;\r\nif (temp & 0x400)\r\nactual_temp = -256;\r\nelse if (temp & 0x200)\r\nactual_temp = 255;\r\nelse if (temp & 0x100) {\r\nactual_temp = temp & 0x1ff;\r\nactual_temp |= ~0x1ff;\r\n} else\r\nactual_temp = temp & 0xff;\r\nactual_temp = (actual_temp * 1000) / 2;\r\n}\r\nreturn actual_temp;\r\n}\r\nint sumo_get_temp(struct radeon_device *rdev)\r\n{\r\nu32 temp = RREG32(CG_THERMAL_STATUS) & 0xff;\r\nint actual_temp = temp - 49;\r\nreturn actual_temp * 1000;\r\n}\r\nvoid sumo_pm_init_profile(struct radeon_device *rdev)\r\n{\r\nint idx;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_off_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_on_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_on_cm_idx = 0;\r\nif (rdev->flags & RADEON_IS_MOBILITY)\r\nidx = radeon_pm_get_type_index(rdev, POWER_STATE_TYPE_BATTERY, 0);\r\nelse\r\nidx = radeon_pm_get_type_index(rdev, POWER_STATE_TYPE_PERFORMANCE, 0);\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_off_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_on_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_off_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_on_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_off_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_on_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_off_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_on_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_on_cm_idx = 0;\r\nidx = radeon_pm_get_type_index(rdev, POWER_STATE_TYPE_PERFORMANCE, 0);\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_off_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_on_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_on_cm_idx =\r\nrdev->pm.power_state[idx].num_clock_modes - 1;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_off_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_on_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_on_cm_idx =\r\nrdev->pm.power_state[idx].num_clock_modes - 1;\r\n}\r\nvoid btc_pm_init_profile(struct radeon_device *rdev)\r\n{\r\nint idx;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_off_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_on_ps_idx = rdev->pm.default_power_state_index;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_DEFAULT_IDX].dpms_on_cm_idx = 2;\r\nif (rdev->flags & RADEON_IS_MOBILITY)\r\nidx = radeon_pm_get_type_index(rdev, POWER_STATE_TYPE_BATTERY, 0);\r\nelse\r\nidx = radeon_pm_get_type_index(rdev, POWER_STATE_TYPE_PERFORMANCE, 0);\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_off_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_on_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_SH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_off_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_on_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_SH_IDX].dpms_on_cm_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_off_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_on_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_SH_IDX].dpms_on_cm_idx = 2;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_off_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_on_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_LOW_MH_IDX].dpms_on_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_off_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_on_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_MID_MH_IDX].dpms_on_cm_idx = 1;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_off_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_on_ps_idx = idx;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_off_cm_idx = 0;\r\nrdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_on_cm_idx = 2;\r\n}\r\nvoid evergreen_pm_misc(struct radeon_device *rdev)\r\n{\r\nint req_ps_idx = rdev->pm.requested_power_state_index;\r\nint req_cm_idx = rdev->pm.requested_clock_mode_index;\r\nstruct radeon_power_state *ps = &rdev->pm.power_state[req_ps_idx];\r\nstruct radeon_voltage *voltage = &ps->clock_info[req_cm_idx].voltage;\r\nif (voltage->type == VOLTAGE_SW) {\r\nif ((voltage->voltage & 0xff00) == 0xff00)\r\nreturn;\r\nif (voltage->voltage && (voltage->voltage != rdev->pm.current_vddc)) {\r\nradeon_atom_set_voltage(rdev, voltage->voltage, SET_VOLTAGE_TYPE_ASIC_VDDC);\r\nrdev->pm.current_vddc = voltage->voltage;\r\nDRM_DEBUG("Setting: vddc: %d\n", voltage->voltage);\r\n}\r\nif ((rdev->pm.pm_method == PM_METHOD_PROFILE) &&\r\n(rdev->family >= CHIP_BARTS) &&\r\nrdev->pm.active_crtc_count &&\r\n((rdev->pm.profile_index == PM_PROFILE_MID_MH_IDX) ||\r\n(rdev->pm.profile_index == PM_PROFILE_LOW_MH_IDX)))\r\nvoltage = &rdev->pm.power_state[req_ps_idx].\r\nclock_info[rdev->pm.profiles[PM_PROFILE_HIGH_MH_IDX].dpms_on_cm_idx].voltage;\r\nif ((voltage->vddci & 0xff00) == 0xff00)\r\nreturn;\r\nif (voltage->vddci && (voltage->vddci != rdev->pm.current_vddci)) {\r\nradeon_atom_set_voltage(rdev, voltage->vddci, SET_VOLTAGE_TYPE_ASIC_VDDCI);\r\nrdev->pm.current_vddci = voltage->vddci;\r\nDRM_DEBUG("Setting: vddci: %d\n", voltage->vddci);\r\n}\r\n}\r\n}\r\nvoid evergreen_pm_prepare(struct radeon_device *rdev)\r\n{\r\nstruct drm_device *ddev = rdev->ddev;\r\nstruct drm_crtc *crtc;\r\nstruct radeon_crtc *radeon_crtc;\r\nu32 tmp;\r\nlist_for_each_entry(crtc, &ddev->mode_config.crtc_list, head) {\r\nradeon_crtc = to_radeon_crtc(crtc);\r\nif (radeon_crtc->enabled) {\r\ntmp = RREG32(EVERGREEN_CRTC_CONTROL + radeon_crtc->crtc_offset);\r\ntmp |= EVERGREEN_CRTC_DISP_READ_REQUEST_DISABLE;\r\nWREG32(EVERGREEN_CRTC_CONTROL + radeon_crtc->crtc_offset, tmp);\r\n}\r\n}\r\n}\r\nvoid evergreen_pm_finish(struct radeon_device *rdev)\r\n{\r\nstruct drm_device *ddev = rdev->ddev;\r\nstruct drm_crtc *crtc;\r\nstruct radeon_crtc *radeon_crtc;\r\nu32 tmp;\r\nlist_for_each_entry(crtc, &ddev->mode_config.crtc_list, head) {\r\nradeon_crtc = to_radeon_crtc(crtc);\r\nif (radeon_crtc->enabled) {\r\ntmp = RREG32(EVERGREEN_CRTC_CONTROL + radeon_crtc->crtc_offset);\r\ntmp &= ~EVERGREEN_CRTC_DISP_READ_REQUEST_DISABLE;\r\nWREG32(EVERGREEN_CRTC_CONTROL + radeon_crtc->crtc_offset, tmp);\r\n}\r\n}\r\n}\r\nbool evergreen_hpd_sense(struct radeon_device *rdev, enum radeon_hpd_id hpd)\r\n{\r\nbool connected = false;\r\nswitch (hpd) {\r\ncase RADEON_HPD_1:\r\nif (RREG32(DC_HPD1_INT_STATUS) & DC_HPDx_SENSE)\r\nconnected = true;\r\nbreak;\r\ncase RADEON_HPD_2:\r\nif (RREG32(DC_HPD2_INT_STATUS) & DC_HPDx_SENSE)\r\nconnected = true;\r\nbreak;\r\ncase RADEON_HPD_3:\r\nif (RREG32(DC_HPD3_INT_STATUS) & DC_HPDx_SENSE)\r\nconnected = true;\r\nbreak;\r\ncase RADEON_HPD_4:\r\nif (RREG32(DC_HPD4_INT_STATUS) & DC_HPDx_SENSE)\r\nconnected = true;\r\nbreak;\r\ncase RADEON_HPD_5:\r\nif (RREG32(DC_HPD5_INT_STATUS) & DC_HPDx_SENSE)\r\nconnected = true;\r\nbreak;\r\ncase RADEON_HPD_6:\r\nif (RREG32(DC_HPD6_INT_STATUS) & DC_HPDx_SENSE)\r\nconnected = true;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn connected;\r\n}\r\nvoid evergreen_hpd_set_polarity(struct radeon_device *rdev,\r\nenum radeon_hpd_id hpd)\r\n{\r\nu32 tmp;\r\nbool connected = evergreen_hpd_sense(rdev, hpd);\r\nswitch (hpd) {\r\ncase RADEON_HPD_1:\r\ntmp = RREG32(DC_HPD1_INT_CONTROL);\r\nif (connected)\r\ntmp &= ~DC_HPDx_INT_POLARITY;\r\nelse\r\ntmp |= DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD1_INT_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_2:\r\ntmp = RREG32(DC_HPD2_INT_CONTROL);\r\nif (connected)\r\ntmp &= ~DC_HPDx_INT_POLARITY;\r\nelse\r\ntmp |= DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD2_INT_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_3:\r\ntmp = RREG32(DC_HPD3_INT_CONTROL);\r\nif (connected)\r\ntmp &= ~DC_HPDx_INT_POLARITY;\r\nelse\r\ntmp |= DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD3_INT_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_4:\r\ntmp = RREG32(DC_HPD4_INT_CONTROL);\r\nif (connected)\r\ntmp &= ~DC_HPDx_INT_POLARITY;\r\nelse\r\ntmp |= DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD4_INT_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_5:\r\ntmp = RREG32(DC_HPD5_INT_CONTROL);\r\nif (connected)\r\ntmp &= ~DC_HPDx_INT_POLARITY;\r\nelse\r\ntmp |= DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD5_INT_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_6:\r\ntmp = RREG32(DC_HPD6_INT_CONTROL);\r\nif (connected)\r\ntmp &= ~DC_HPDx_INT_POLARITY;\r\nelse\r\ntmp |= DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD6_INT_CONTROL, tmp);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nvoid evergreen_hpd_init(struct radeon_device *rdev)\r\n{\r\nstruct drm_device *dev = rdev->ddev;\r\nstruct drm_connector *connector;\r\nunsigned enabled = 0;\r\nu32 tmp = DC_HPDx_CONNECTION_TIMER(0x9c4) |\r\nDC_HPDx_RX_INT_TIMER(0xfa) | DC_HPDx_EN;\r\nlist_for_each_entry(connector, &dev->mode_config.connector_list, head) {\r\nstruct radeon_connector *radeon_connector = to_radeon_connector(connector);\r\nif (connector->connector_type == DRM_MODE_CONNECTOR_eDP ||\r\nconnector->connector_type == DRM_MODE_CONNECTOR_LVDS) {\r\ncontinue;\r\n}\r\nswitch (radeon_connector->hpd.hpd) {\r\ncase RADEON_HPD_1:\r\nWREG32(DC_HPD1_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_2:\r\nWREG32(DC_HPD2_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_3:\r\nWREG32(DC_HPD3_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_4:\r\nWREG32(DC_HPD4_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_5:\r\nWREG32(DC_HPD5_CONTROL, tmp);\r\nbreak;\r\ncase RADEON_HPD_6:\r\nWREG32(DC_HPD6_CONTROL, tmp);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nradeon_hpd_set_polarity(rdev, radeon_connector->hpd.hpd);\r\nenabled |= 1 << radeon_connector->hpd.hpd;\r\n}\r\nradeon_irq_kms_enable_hpd(rdev, enabled);\r\n}\r\nvoid evergreen_hpd_fini(struct radeon_device *rdev)\r\n{\r\nstruct drm_device *dev = rdev->ddev;\r\nstruct drm_connector *connector;\r\nunsigned disabled = 0;\r\nlist_for_each_entry(connector, &dev->mode_config.connector_list, head) {\r\nstruct radeon_connector *radeon_connector = to_radeon_connector(connector);\r\nswitch (radeon_connector->hpd.hpd) {\r\ncase RADEON_HPD_1:\r\nWREG32(DC_HPD1_CONTROL, 0);\r\nbreak;\r\ncase RADEON_HPD_2:\r\nWREG32(DC_HPD2_CONTROL, 0);\r\nbreak;\r\ncase RADEON_HPD_3:\r\nWREG32(DC_HPD3_CONTROL, 0);\r\nbreak;\r\ncase RADEON_HPD_4:\r\nWREG32(DC_HPD4_CONTROL, 0);\r\nbreak;\r\ncase RADEON_HPD_5:\r\nWREG32(DC_HPD5_CONTROL, 0);\r\nbreak;\r\ncase RADEON_HPD_6:\r\nWREG32(DC_HPD6_CONTROL, 0);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\ndisabled |= 1 << radeon_connector->hpd.hpd;\r\n}\r\nradeon_irq_kms_disable_hpd(rdev, disabled);\r\n}\r\nstatic u32 evergreen_line_buffer_adjust(struct radeon_device *rdev,\r\nstruct radeon_crtc *radeon_crtc,\r\nstruct drm_display_mode *mode,\r\nstruct drm_display_mode *other_mode)\r\n{\r\nu32 tmp, buffer_alloc, i;\r\nu32 pipe_offset = radeon_crtc->crtc_id * 0x20;\r\nif (radeon_crtc->base.enabled && mode) {\r\nif (other_mode) {\r\ntmp = 0;\r\nbuffer_alloc = 1;\r\n} else {\r\ntmp = 2;\r\nbuffer_alloc = 2;\r\n}\r\n} else {\r\ntmp = 0;\r\nbuffer_alloc = 0;\r\n}\r\nif (radeon_crtc->crtc_id % 2)\r\ntmp += 4;\r\nWREG32(DC_LB_MEMORY_SPLIT + radeon_crtc->crtc_offset, tmp);\r\nif (ASIC_IS_DCE41(rdev) || ASIC_IS_DCE5(rdev)) {\r\nWREG32(PIPE0_DMIF_BUFFER_CONTROL + pipe_offset,\r\nDMIF_BUFFERS_ALLOCATED(buffer_alloc));\r\nfor (i = 0; i < rdev->usec_timeout; i++) {\r\nif (RREG32(PIPE0_DMIF_BUFFER_CONTROL + pipe_offset) &\r\nDMIF_BUFFERS_ALLOCATED_COMPLETED)\r\nbreak;\r\nudelay(1);\r\n}\r\n}\r\nif (radeon_crtc->base.enabled && mode) {\r\nswitch (tmp) {\r\ncase 0:\r\ncase 4:\r\ndefault:\r\nif (ASIC_IS_DCE5(rdev))\r\nreturn 4096 * 2;\r\nelse\r\nreturn 3840 * 2;\r\ncase 1:\r\ncase 5:\r\nif (ASIC_IS_DCE5(rdev))\r\nreturn 6144 * 2;\r\nelse\r\nreturn 5760 * 2;\r\ncase 2:\r\ncase 6:\r\nif (ASIC_IS_DCE5(rdev))\r\nreturn 8192 * 2;\r\nelse\r\nreturn 7680 * 2;\r\ncase 3:\r\ncase 7:\r\nif (ASIC_IS_DCE5(rdev))\r\nreturn 2048 * 2;\r\nelse\r\nreturn 1920 * 2;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nu32 evergreen_get_number_of_dram_channels(struct radeon_device *rdev)\r\n{\r\nu32 tmp = RREG32(MC_SHARED_CHMAP);\r\nswitch ((tmp & NOOFCHAN_MASK) >> NOOFCHAN_SHIFT) {\r\ncase 0:\r\ndefault:\r\nreturn 1;\r\ncase 1:\r\nreturn 2;\r\ncase 2:\r\nreturn 4;\r\ncase 3:\r\nreturn 8;\r\n}\r\n}\r\nstatic u32 evergreen_dram_bandwidth(struct evergreen_wm_params *wm)\r\n{\r\nfixed20_12 dram_efficiency;\r\nfixed20_12 yclk, dram_channels, bandwidth;\r\nfixed20_12 a;\r\na.full = dfixed_const(1000);\r\nyclk.full = dfixed_const(wm->yclk);\r\nyclk.full = dfixed_div(yclk, a);\r\ndram_channels.full = dfixed_const(wm->dram_channels * 4);\r\na.full = dfixed_const(10);\r\ndram_efficiency.full = dfixed_const(7);\r\ndram_efficiency.full = dfixed_div(dram_efficiency, a);\r\nbandwidth.full = dfixed_mul(dram_channels, yclk);\r\nbandwidth.full = dfixed_mul(bandwidth, dram_efficiency);\r\nreturn dfixed_trunc(bandwidth);\r\n}\r\nstatic u32 evergreen_dram_bandwidth_for_display(struct evergreen_wm_params *wm)\r\n{\r\nfixed20_12 disp_dram_allocation;\r\nfixed20_12 yclk, dram_channels, bandwidth;\r\nfixed20_12 a;\r\na.full = dfixed_const(1000);\r\nyclk.full = dfixed_const(wm->yclk);\r\nyclk.full = dfixed_div(yclk, a);\r\ndram_channels.full = dfixed_const(wm->dram_channels * 4);\r\na.full = dfixed_const(10);\r\ndisp_dram_allocation.full = dfixed_const(3);\r\ndisp_dram_allocation.full = dfixed_div(disp_dram_allocation, a);\r\nbandwidth.full = dfixed_mul(dram_channels, yclk);\r\nbandwidth.full = dfixed_mul(bandwidth, disp_dram_allocation);\r\nreturn dfixed_trunc(bandwidth);\r\n}\r\nstatic u32 evergreen_data_return_bandwidth(struct evergreen_wm_params *wm)\r\n{\r\nfixed20_12 return_efficiency;\r\nfixed20_12 sclk, bandwidth;\r\nfixed20_12 a;\r\na.full = dfixed_const(1000);\r\nsclk.full = dfixed_const(wm->sclk);\r\nsclk.full = dfixed_div(sclk, a);\r\na.full = dfixed_const(10);\r\nreturn_efficiency.full = dfixed_const(8);\r\nreturn_efficiency.full = dfixed_div(return_efficiency, a);\r\na.full = dfixed_const(32);\r\nbandwidth.full = dfixed_mul(a, sclk);\r\nbandwidth.full = dfixed_mul(bandwidth, return_efficiency);\r\nreturn dfixed_trunc(bandwidth);\r\n}\r\nstatic u32 evergreen_dmif_request_bandwidth(struct evergreen_wm_params *wm)\r\n{\r\nfixed20_12 disp_clk_request_efficiency;\r\nfixed20_12 disp_clk, bandwidth;\r\nfixed20_12 a;\r\na.full = dfixed_const(1000);\r\ndisp_clk.full = dfixed_const(wm->disp_clk);\r\ndisp_clk.full = dfixed_div(disp_clk, a);\r\na.full = dfixed_const(10);\r\ndisp_clk_request_efficiency.full = dfixed_const(8);\r\ndisp_clk_request_efficiency.full = dfixed_div(disp_clk_request_efficiency, a);\r\na.full = dfixed_const(32);\r\nbandwidth.full = dfixed_mul(a, disp_clk);\r\nbandwidth.full = dfixed_mul(bandwidth, disp_clk_request_efficiency);\r\nreturn dfixed_trunc(bandwidth);\r\n}\r\nstatic u32 evergreen_available_bandwidth(struct evergreen_wm_params *wm)\r\n{\r\nu32 dram_bandwidth = evergreen_dram_bandwidth(wm);\r\nu32 data_return_bandwidth = evergreen_data_return_bandwidth(wm);\r\nu32 dmif_req_bandwidth = evergreen_dmif_request_bandwidth(wm);\r\nreturn min(dram_bandwidth, min(data_return_bandwidth, dmif_req_bandwidth));\r\n}\r\nstatic u32 evergreen_average_bandwidth(struct evergreen_wm_params *wm)\r\n{\r\nfixed20_12 bpp;\r\nfixed20_12 line_time;\r\nfixed20_12 src_width;\r\nfixed20_12 bandwidth;\r\nfixed20_12 a;\r\na.full = dfixed_const(1000);\r\nline_time.full = dfixed_const(wm->active_time + wm->blank_time);\r\nline_time.full = dfixed_div(line_time, a);\r\nbpp.full = dfixed_const(wm->bytes_per_pixel);\r\nsrc_width.full = dfixed_const(wm->src_width);\r\nbandwidth.full = dfixed_mul(src_width, bpp);\r\nbandwidth.full = dfixed_mul(bandwidth, wm->vsc);\r\nbandwidth.full = dfixed_div(bandwidth, line_time);\r\nreturn dfixed_trunc(bandwidth);\r\n}\r\nstatic u32 evergreen_latency_watermark(struct evergreen_wm_params *wm)\r\n{\r\nu32 mc_latency = 2000;\r\nu32 available_bandwidth = evergreen_available_bandwidth(wm);\r\nu32 worst_chunk_return_time = (512 * 8 * 1000) / available_bandwidth;\r\nu32 cursor_line_pair_return_time = (128 * 4 * 1000) / available_bandwidth;\r\nu32 dc_latency = 40000000 / wm->disp_clk;\r\nu32 other_heads_data_return_time = ((wm->num_heads + 1) * worst_chunk_return_time) +\r\n(wm->num_heads * cursor_line_pair_return_time);\r\nu32 latency = mc_latency + other_heads_data_return_time + dc_latency;\r\nu32 max_src_lines_per_dst_line, lb_fill_bw, line_fill_time;\r\nfixed20_12 a, b, c;\r\nif (wm->num_heads == 0)\r\nreturn 0;\r\na.full = dfixed_const(2);\r\nb.full = dfixed_const(1);\r\nif ((wm->vsc.full > a.full) ||\r\n((wm->vsc.full > b.full) && (wm->vtaps >= 3)) ||\r\n(wm->vtaps >= 5) ||\r\n((wm->vsc.full >= a.full) && wm->interlaced))\r\nmax_src_lines_per_dst_line = 4;\r\nelse\r\nmax_src_lines_per_dst_line = 2;\r\na.full = dfixed_const(available_bandwidth);\r\nb.full = dfixed_const(wm->num_heads);\r\na.full = dfixed_div(a, b);\r\nb.full = dfixed_const(1000);\r\nc.full = dfixed_const(wm->disp_clk);\r\nb.full = dfixed_div(c, b);\r\nc.full = dfixed_const(wm->bytes_per_pixel);\r\nb.full = dfixed_mul(b, c);\r\nlb_fill_bw = min(dfixed_trunc(a), dfixed_trunc(b));\r\na.full = dfixed_const(max_src_lines_per_dst_line * wm->src_width * wm->bytes_per_pixel);\r\nb.full = dfixed_const(1000);\r\nc.full = dfixed_const(lb_fill_bw);\r\nb.full = dfixed_div(c, b);\r\na.full = dfixed_div(a, b);\r\nline_fill_time = dfixed_trunc(a);\r\nif (line_fill_time < wm->active_time)\r\nreturn latency;\r\nelse\r\nreturn latency + (line_fill_time - wm->active_time);\r\n}\r\nstatic bool evergreen_average_bandwidth_vs_dram_bandwidth_for_display(struct evergreen_wm_params *wm)\r\n{\r\nif (evergreen_average_bandwidth(wm) <=\r\n(evergreen_dram_bandwidth_for_display(wm) / wm->num_heads))\r\nreturn true;\r\nelse\r\nreturn false;\r\n}\r\nstatic bool evergreen_average_bandwidth_vs_available_bandwidth(struct evergreen_wm_params *wm)\r\n{\r\nif (evergreen_average_bandwidth(wm) <=\r\n(evergreen_available_bandwidth(wm) / wm->num_heads))\r\nreturn true;\r\nelse\r\nreturn false;\r\n}\r\nstatic bool evergreen_check_latency_hiding(struct evergreen_wm_params *wm)\r\n{\r\nu32 lb_partitions = wm->lb_size / wm->src_width;\r\nu32 line_time = wm->active_time + wm->blank_time;\r\nu32 latency_tolerant_lines;\r\nu32 latency_hiding;\r\nfixed20_12 a;\r\na.full = dfixed_const(1);\r\nif (wm->vsc.full > a.full)\r\nlatency_tolerant_lines = 1;\r\nelse {\r\nif (lb_partitions <= (wm->vtaps + 1))\r\nlatency_tolerant_lines = 1;\r\nelse\r\nlatency_tolerant_lines = 2;\r\n}\r\nlatency_hiding = (latency_tolerant_lines * line_time + wm->blank_time);\r\nif (evergreen_latency_watermark(wm) <= latency_hiding)\r\nreturn true;\r\nelse\r\nreturn false;\r\n}\r\nstatic void evergreen_program_watermarks(struct radeon_device *rdev,\r\nstruct radeon_crtc *radeon_crtc,\r\nu32 lb_size, u32 num_heads)\r\n{\r\nstruct drm_display_mode *mode = &radeon_crtc->base.mode;\r\nstruct evergreen_wm_params wm_low, wm_high;\r\nu32 dram_channels;\r\nu32 pixel_period;\r\nu32 line_time = 0;\r\nu32 latency_watermark_a = 0, latency_watermark_b = 0;\r\nu32 priority_a_mark = 0, priority_b_mark = 0;\r\nu32 priority_a_cnt = PRIORITY_OFF;\r\nu32 priority_b_cnt = PRIORITY_OFF;\r\nu32 pipe_offset = radeon_crtc->crtc_id * 16;\r\nu32 tmp, arb_control3;\r\nfixed20_12 a, b, c;\r\nif (radeon_crtc->base.enabled && num_heads && mode) {\r\npixel_period = 1000000 / (u32)mode->clock;\r\nline_time = min((u32)mode->crtc_htotal * pixel_period, (u32)65535);\r\npriority_a_cnt = 0;\r\npriority_b_cnt = 0;\r\ndram_channels = evergreen_get_number_of_dram_channels(rdev);\r\nif ((rdev->pm.pm_method == PM_METHOD_DPM) && rdev->pm.dpm_enabled) {\r\nwm_high.yclk =\r\nradeon_dpm_get_mclk(rdev, false) * 10;\r\nwm_high.sclk =\r\nradeon_dpm_get_sclk(rdev, false) * 10;\r\n} else {\r\nwm_high.yclk = rdev->pm.current_mclk * 10;\r\nwm_high.sclk = rdev->pm.current_sclk * 10;\r\n}\r\nwm_high.disp_clk = mode->clock;\r\nwm_high.src_width = mode->crtc_hdisplay;\r\nwm_high.active_time = mode->crtc_hdisplay * pixel_period;\r\nwm_high.blank_time = line_time - wm_high.active_time;\r\nwm_high.interlaced = false;\r\nif (mode->flags & DRM_MODE_FLAG_INTERLACE)\r\nwm_high.interlaced = true;\r\nwm_high.vsc = radeon_crtc->vsc;\r\nwm_high.vtaps = 1;\r\nif (radeon_crtc->rmx_type != RMX_OFF)\r\nwm_high.vtaps = 2;\r\nwm_high.bytes_per_pixel = 4;\r\nwm_high.lb_size = lb_size;\r\nwm_high.dram_channels = dram_channels;\r\nwm_high.num_heads = num_heads;\r\nif ((rdev->pm.pm_method == PM_METHOD_DPM) && rdev->pm.dpm_enabled) {\r\nwm_low.yclk =\r\nradeon_dpm_get_mclk(rdev, true) * 10;\r\nwm_low.sclk =\r\nradeon_dpm_get_sclk(rdev, true) * 10;\r\n} else {\r\nwm_low.yclk = rdev->pm.current_mclk * 10;\r\nwm_low.sclk = rdev->pm.current_sclk * 10;\r\n}\r\nwm_low.disp_clk = mode->clock;\r\nwm_low.src_width = mode->crtc_hdisplay;\r\nwm_low.active_time = mode->crtc_hdisplay * pixel_period;\r\nwm_low.blank_time = line_time - wm_low.active_time;\r\nwm_low.interlaced = false;\r\nif (mode->flags & DRM_MODE_FLAG_INTERLACE)\r\nwm_low.interlaced = true;\r\nwm_low.vsc = radeon_crtc->vsc;\r\nwm_low.vtaps = 1;\r\nif (radeon_crtc->rmx_type != RMX_OFF)\r\nwm_low.vtaps = 2;\r\nwm_low.bytes_per_pixel = 4;\r\nwm_low.lb_size = lb_size;\r\nwm_low.dram_channels = dram_channels;\r\nwm_low.num_heads = num_heads;\r\nlatency_watermark_a = min(evergreen_latency_watermark(&wm_high), (u32)65535);\r\nlatency_watermark_b = min(evergreen_latency_watermark(&wm_low), (u32)65535);\r\nif (!evergreen_average_bandwidth_vs_dram_bandwidth_for_display(&wm_high) ||\r\n!evergreen_average_bandwidth_vs_available_bandwidth(&wm_high) ||\r\n!evergreen_check_latency_hiding(&wm_high) ||\r\n(rdev->disp_priority == 2)) {\r\nDRM_DEBUG_KMS("force priority a to high\n");\r\npriority_a_cnt |= PRIORITY_ALWAYS_ON;\r\n}\r\nif (!evergreen_average_bandwidth_vs_dram_bandwidth_for_display(&wm_low) ||\r\n!evergreen_average_bandwidth_vs_available_bandwidth(&wm_low) ||\r\n!evergreen_check_latency_hiding(&wm_low) ||\r\n(rdev->disp_priority == 2)) {\r\nDRM_DEBUG_KMS("force priority b to high\n");\r\npriority_b_cnt |= PRIORITY_ALWAYS_ON;\r\n}\r\na.full = dfixed_const(1000);\r\nb.full = dfixed_const(mode->clock);\r\nb.full = dfixed_div(b, a);\r\nc.full = dfixed_const(latency_watermark_a);\r\nc.full = dfixed_mul(c, b);\r\nc.full = dfixed_mul(c, radeon_crtc->hsc);\r\nc.full = dfixed_div(c, a);\r\na.full = dfixed_const(16);\r\nc.full = dfixed_div(c, a);\r\npriority_a_mark = dfixed_trunc(c);\r\npriority_a_cnt |= priority_a_mark & PRIORITY_MARK_MASK;\r\na.full = dfixed_const(1000);\r\nb.full = dfixed_const(mode->clock);\r\nb.full = dfixed_div(b, a);\r\nc.full = dfixed_const(latency_watermark_b);\r\nc.full = dfixed_mul(c, b);\r\nc.full = dfixed_mul(c, radeon_crtc->hsc);\r\nc.full = dfixed_div(c, a);\r\na.full = dfixed_const(16);\r\nc.full = dfixed_div(c, a);\r\npriority_b_mark = dfixed_trunc(c);\r\npriority_b_cnt |= priority_b_mark & PRIORITY_MARK_MASK;\r\n}\r\narb_control3 = RREG32(PIPE0_ARBITRATION_CONTROL3 + pipe_offset);\r\ntmp = arb_control3;\r\ntmp &= ~LATENCY_WATERMARK_MASK(3);\r\ntmp |= LATENCY_WATERMARK_MASK(1);\r\nWREG32(PIPE0_ARBITRATION_CONTROL3 + pipe_offset, tmp);\r\nWREG32(PIPE0_LATENCY_CONTROL + pipe_offset,\r\n(LATENCY_LOW_WATERMARK(latency_watermark_a) |\r\nLATENCY_HIGH_WATERMARK(line_time)));\r\ntmp = RREG32(PIPE0_ARBITRATION_CONTROL3 + pipe_offset);\r\ntmp &= ~LATENCY_WATERMARK_MASK(3);\r\ntmp |= LATENCY_WATERMARK_MASK(2);\r\nWREG32(PIPE0_ARBITRATION_CONTROL3 + pipe_offset, tmp);\r\nWREG32(PIPE0_LATENCY_CONTROL + pipe_offset,\r\n(LATENCY_LOW_WATERMARK(latency_watermark_b) |\r\nLATENCY_HIGH_WATERMARK(line_time)));\r\nWREG32(PIPE0_ARBITRATION_CONTROL3 + pipe_offset, arb_control3);\r\nWREG32(PRIORITY_A_CNT + radeon_crtc->crtc_offset, priority_a_cnt);\r\nWREG32(PRIORITY_B_CNT + radeon_crtc->crtc_offset, priority_b_cnt);\r\nradeon_crtc->line_time = line_time;\r\nradeon_crtc->wm_high = latency_watermark_a;\r\nradeon_crtc->wm_low = latency_watermark_b;\r\n}\r\nvoid evergreen_bandwidth_update(struct radeon_device *rdev)\r\n{\r\nstruct drm_display_mode *mode0 = NULL;\r\nstruct drm_display_mode *mode1 = NULL;\r\nu32 num_heads = 0, lb_size;\r\nint i;\r\nif (!rdev->mode_info.mode_config_initialized)\r\nreturn;\r\nradeon_update_display_priority(rdev);\r\nfor (i = 0; i < rdev->num_crtc; i++) {\r\nif (rdev->mode_info.crtcs[i]->base.enabled)\r\nnum_heads++;\r\n}\r\nfor (i = 0; i < rdev->num_crtc; i += 2) {\r\nmode0 = &rdev->mode_info.crtcs[i]->base.mode;\r\nmode1 = &rdev->mode_info.crtcs[i+1]->base.mode;\r\nlb_size = evergreen_line_buffer_adjust(rdev, rdev->mode_info.crtcs[i], mode0, mode1);\r\nevergreen_program_watermarks(rdev, rdev->mode_info.crtcs[i], lb_size, num_heads);\r\nlb_size = evergreen_line_buffer_adjust(rdev, rdev->mode_info.crtcs[i+1], mode1, mode0);\r\nevergreen_program_watermarks(rdev, rdev->mode_info.crtcs[i+1], lb_size, num_heads);\r\n}\r\n}\r\nint evergreen_mc_wait_for_idle(struct radeon_device *rdev)\r\n{\r\nunsigned i;\r\nu32 tmp;\r\nfor (i = 0; i < rdev->usec_timeout; i++) {\r\ntmp = RREG32(SRBM_STATUS) & 0x1F00;\r\nif (!tmp)\r\nreturn 0;\r\nudelay(1);\r\n}\r\nreturn -1;\r\n}\r\nvoid evergreen_pcie_gart_tlb_flush(struct radeon_device *rdev)\r\n{\r\nunsigned i;\r\nu32 tmp;\r\nWREG32(HDP_MEM_COHERENCY_FLUSH_CNTL, 0x1);\r\nWREG32(VM_CONTEXT0_REQUEST_RESPONSE, REQUEST_TYPE(1));\r\nfor (i = 0; i < rdev->usec_timeout; i++) {\r\ntmp = RREG32(VM_CONTEXT0_REQUEST_RESPONSE);\r\ntmp = (tmp & RESPONSE_TYPE_MASK) >> RESPONSE_TYPE_SHIFT;\r\nif (tmp == 2) {\r\nprintk(KERN_WARNING "[drm] r600 flush TLB failed\n");\r\nreturn;\r\n}\r\nif (tmp) {\r\nreturn;\r\n}\r\nudelay(1);\r\n}\r\n}\r\nstatic int evergreen_pcie_gart_enable(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\nint r;\r\nif (rdev->gart.robj == NULL) {\r\ndev_err(rdev->dev, "No VRAM object for PCIE GART.\n");\r\nreturn -EINVAL;\r\n}\r\nr = radeon_gart_table_vram_pin(rdev);\r\nif (r)\r\nreturn r;\r\nWREG32(VM_L2_CNTL, ENABLE_L2_CACHE | ENABLE_L2_FRAGMENT_PROCESSING |\r\nENABLE_L2_PTE_CACHE_LRU_UPDATE_BY_WRITE |\r\nEFFECTIVE_L2_QUEUE_SIZE(7));\r\nWREG32(VM_L2_CNTL2, 0);\r\nWREG32(VM_L2_CNTL3, BANK_SELECT(0) | CACHE_UPDATE_MODE(2));\r\ntmp = ENABLE_L1_TLB | ENABLE_L1_FRAGMENT_PROCESSING |\r\nSYSTEM_ACCESS_MODE_NOT_IN_SYS |\r\nSYSTEM_APERTURE_UNMAPPED_ACCESS_PASS_THRU |\r\nEFFECTIVE_L1_TLB_SIZE(5) | EFFECTIVE_L1_QUEUE_SIZE(5);\r\nif (rdev->flags & RADEON_IS_IGP) {\r\nWREG32(FUS_MC_VM_MD_L1_TLB0_CNTL, tmp);\r\nWREG32(FUS_MC_VM_MD_L1_TLB1_CNTL, tmp);\r\nWREG32(FUS_MC_VM_MD_L1_TLB2_CNTL, tmp);\r\n} else {\r\nWREG32(MC_VM_MD_L1_TLB0_CNTL, tmp);\r\nWREG32(MC_VM_MD_L1_TLB1_CNTL, tmp);\r\nWREG32(MC_VM_MD_L1_TLB2_CNTL, tmp);\r\nif ((rdev->family == CHIP_JUNIPER) ||\r\n(rdev->family == CHIP_CYPRESS) ||\r\n(rdev->family == CHIP_HEMLOCK) ||\r\n(rdev->family == CHIP_BARTS))\r\nWREG32(MC_VM_MD_L1_TLB3_CNTL, tmp);\r\n}\r\nWREG32(MC_VM_MB_L1_TLB0_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB1_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB2_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB3_CNTL, tmp);\r\nWREG32(VM_CONTEXT0_PAGE_TABLE_START_ADDR, rdev->mc.gtt_start >> 12);\r\nWREG32(VM_CONTEXT0_PAGE_TABLE_END_ADDR, rdev->mc.gtt_end >> 12);\r\nWREG32(VM_CONTEXT0_PAGE_TABLE_BASE_ADDR, rdev->gart.table_addr >> 12);\r\nWREG32(VM_CONTEXT0_CNTL, ENABLE_CONTEXT | PAGE_TABLE_DEPTH(0) |\r\nRANGE_PROTECTION_FAULT_ENABLE_DEFAULT);\r\nWREG32(VM_CONTEXT0_PROTECTION_FAULT_DEFAULT_ADDR,\r\n(u32)(rdev->dummy_page.addr >> 12));\r\nWREG32(VM_CONTEXT1_CNTL, 0);\r\nevergreen_pcie_gart_tlb_flush(rdev);\r\nDRM_INFO("PCIE GART of %uM enabled (table at 0x%016llX).\n",\r\n(unsigned)(rdev->mc.gtt_size >> 20),\r\n(unsigned long long)rdev->gart.table_addr);\r\nrdev->gart.ready = true;\r\nreturn 0;\r\n}\r\nstatic void evergreen_pcie_gart_disable(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\nWREG32(VM_CONTEXT0_CNTL, 0);\r\nWREG32(VM_CONTEXT1_CNTL, 0);\r\nWREG32(VM_L2_CNTL, ENABLE_L2_FRAGMENT_PROCESSING |\r\nEFFECTIVE_L2_QUEUE_SIZE(7));\r\nWREG32(VM_L2_CNTL2, 0);\r\nWREG32(VM_L2_CNTL3, BANK_SELECT(0) | CACHE_UPDATE_MODE(2));\r\ntmp = EFFECTIVE_L1_TLB_SIZE(5) | EFFECTIVE_L1_QUEUE_SIZE(5);\r\nWREG32(MC_VM_MD_L1_TLB0_CNTL, tmp);\r\nWREG32(MC_VM_MD_L1_TLB1_CNTL, tmp);\r\nWREG32(MC_VM_MD_L1_TLB2_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB0_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB1_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB2_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB3_CNTL, tmp);\r\nradeon_gart_table_vram_unpin(rdev);\r\n}\r\nstatic void evergreen_pcie_gart_fini(struct radeon_device *rdev)\r\n{\r\nevergreen_pcie_gart_disable(rdev);\r\nradeon_gart_table_vram_free(rdev);\r\nradeon_gart_fini(rdev);\r\n}\r\nstatic void evergreen_agp_enable(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\nWREG32(VM_L2_CNTL, ENABLE_L2_CACHE | ENABLE_L2_FRAGMENT_PROCESSING |\r\nENABLE_L2_PTE_CACHE_LRU_UPDATE_BY_WRITE |\r\nEFFECTIVE_L2_QUEUE_SIZE(7));\r\nWREG32(VM_L2_CNTL2, 0);\r\nWREG32(VM_L2_CNTL3, BANK_SELECT(0) | CACHE_UPDATE_MODE(2));\r\ntmp = ENABLE_L1_TLB | ENABLE_L1_FRAGMENT_PROCESSING |\r\nSYSTEM_ACCESS_MODE_NOT_IN_SYS |\r\nSYSTEM_APERTURE_UNMAPPED_ACCESS_PASS_THRU |\r\nEFFECTIVE_L1_TLB_SIZE(5) | EFFECTIVE_L1_QUEUE_SIZE(5);\r\nWREG32(MC_VM_MD_L1_TLB0_CNTL, tmp);\r\nWREG32(MC_VM_MD_L1_TLB1_CNTL, tmp);\r\nWREG32(MC_VM_MD_L1_TLB2_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB0_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB1_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB2_CNTL, tmp);\r\nWREG32(MC_VM_MB_L1_TLB3_CNTL, tmp);\r\nWREG32(VM_CONTEXT0_CNTL, 0);\r\nWREG32(VM_CONTEXT1_CNTL, 0);\r\n}\r\nvoid evergreen_mc_stop(struct radeon_device *rdev, struct evergreen_mc_save *save)\r\n{\r\nu32 crtc_enabled, tmp, frame_count, blackout;\r\nint i, j;\r\nif (!ASIC_IS_NODCE(rdev)) {\r\nsave->vga_render_control = RREG32(VGA_RENDER_CONTROL);\r\nsave->vga_hdp_control = RREG32(VGA_HDP_CONTROL);\r\nWREG32(VGA_RENDER_CONTROL, 0);\r\n}\r\nfor (i = 0; i < rdev->num_crtc; i++) {\r\ncrtc_enabled = RREG32(EVERGREEN_CRTC_CONTROL + crtc_offsets[i]) & EVERGREEN_CRTC_MASTER_EN;\r\nif (crtc_enabled) {\r\nsave->crtc_enabled[i] = true;\r\nif (ASIC_IS_DCE6(rdev)) {\r\ntmp = RREG32(EVERGREEN_CRTC_BLANK_CONTROL + crtc_offsets[i]);\r\nif (!(tmp & EVERGREEN_CRTC_BLANK_DATA_EN)) {\r\nradeon_wait_for_vblank(rdev, i);\r\nWREG32(EVERGREEN_CRTC_UPDATE_LOCK + crtc_offsets[i], 1);\r\ntmp |= EVERGREEN_CRTC_BLANK_DATA_EN;\r\nWREG32(EVERGREEN_CRTC_BLANK_CONTROL + crtc_offsets[i], tmp);\r\nWREG32(EVERGREEN_CRTC_UPDATE_LOCK + crtc_offsets[i], 0);\r\n}\r\n} else {\r\ntmp = RREG32(EVERGREEN_CRTC_CONTROL + crtc_offsets[i]);\r\nif (!(tmp & EVERGREEN_CRTC_DISP_READ_REQUEST_DISABLE)) {\r\nradeon_wait_for_vblank(rdev, i);\r\nWREG32(EVERGREEN_CRTC_UPDATE_LOCK + crtc_offsets[i], 1);\r\ntmp |= EVERGREEN_CRTC_DISP_READ_REQUEST_DISABLE;\r\nWREG32(EVERGREEN_CRTC_CONTROL + crtc_offsets[i], tmp);\r\nWREG32(EVERGREEN_CRTC_UPDATE_LOCK + crtc_offsets[i], 0);\r\n}\r\n}\r\nframe_count = radeon_get_vblank_counter(rdev, i);\r\nfor (j = 0; j < rdev->usec_timeout; j++) {\r\nif (radeon_get_vblank_counter(rdev, i) != frame_count)\r\nbreak;\r\nudelay(1);\r\n}\r\nWREG32(EVERGREEN_CRTC_UPDATE_LOCK + crtc_offsets[i], 1);\r\ntmp = RREG32(EVERGREEN_CRTC_CONTROL + crtc_offsets[i]);\r\ntmp &= ~EVERGREEN_CRTC_MASTER_EN;\r\nWREG32(EVERGREEN_CRTC_CONTROL + crtc_offsets[i], tmp);\r\nWREG32(EVERGREEN_CRTC_UPDATE_LOCK + crtc_offsets[i], 0);\r\nsave->crtc_enabled[i] = false;\r\n} else {\r\nsave->crtc_enabled[i] = false;\r\n}\r\n}\r\nradeon_mc_wait_for_idle(rdev);\r\nblackout = RREG32(MC_SHARED_BLACKOUT_CNTL);\r\nif ((blackout & BLACKOUT_MODE_MASK) != 1) {\r\nWREG32(BIF_FB_EN, 0);\r\nblackout &= ~BLACKOUT_MODE_MASK;\r\nWREG32(MC_SHARED_BLACKOUT_CNTL, blackout | 1);\r\n}\r\nudelay(100);\r\nfor (i = 0; i < rdev->num_crtc; i++) {\r\nif (save->crtc_enabled[i]) {\r\ntmp = RREG32(EVERGREEN_GRPH_UPDATE + crtc_offsets[i]);\r\nif (!(tmp & EVERGREEN_GRPH_UPDATE_LOCK)) {\r\ntmp |= EVERGREEN_GRPH_UPDATE_LOCK;\r\nWREG32(EVERGREEN_GRPH_UPDATE + crtc_offsets[i], tmp);\r\n}\r\ntmp = RREG32(EVERGREEN_MASTER_UPDATE_LOCK + crtc_offsets[i]);\r\nif (!(tmp & 1)) {\r\ntmp |= 1;\r\nWREG32(EVERGREEN_MASTER_UPDATE_LOCK + crtc_offsets[i], tmp);\r\n}\r\n}\r\n}\r\n}\r\nvoid evergreen_mc_resume(struct radeon_device *rdev, struct evergreen_mc_save *save)\r\n{\r\nu32 tmp, frame_count;\r\nint i, j;\r\nfor (i = 0; i < rdev->num_crtc; i++) {\r\nWREG32(EVERGREEN_GRPH_PRIMARY_SURFACE_ADDRESS_HIGH + crtc_offsets[i],\r\nupper_32_bits(rdev->mc.vram_start));\r\nWREG32(EVERGREEN_GRPH_SECONDARY_SURFACE_ADDRESS_HIGH + crtc_offsets[i],\r\nupper_32_bits(rdev->mc.vram_start));\r\nWREG32(EVERGREEN_GRPH_PRIMARY_SURFACE_ADDRESS + crtc_offsets[i],\r\n(u32)rdev->mc.vram_start);\r\nWREG32(EVERGREEN_GRPH_SECONDARY_SURFACE_ADDRESS + crtc_offsets[i],\r\n(u32)rdev->mc.vram_start);\r\n}\r\nif (!ASIC_IS_NODCE(rdev)) {\r\nWREG32(EVERGREEN_VGA_MEMORY_BASE_ADDRESS_HIGH, upper_32_bits(rdev->mc.vram_start));\r\nWREG32(EVERGREEN_VGA_MEMORY_BASE_ADDRESS, (u32)rdev->mc.vram_start);\r\n}\r\nfor (i = 0; i < rdev->num_crtc; i++) {\r\nif (save->crtc_enabled[i]) {\r\ntmp = RREG32(EVERGREEN_MASTER_UPDATE_MODE + crtc_offsets[i]);\r\nif ((tmp & 0x7) != 3) {\r\ntmp &= ~0x7;\r\ntmp |= 0x3;\r\nWREG32(EVERGREEN_MASTER_UPDATE_MODE + crtc_offsets[i], tmp);\r\n}\r\ntmp = RREG32(EVERGREEN_GRPH_UPDATE + crtc_offsets[i]);\r\nif (tmp & EVERGREEN_GRPH_UPDATE_LOCK) {\r\ntmp &= ~EVERGREEN_GRPH_UPDATE_LOCK;\r\nWREG32(EVERGREEN_GRPH_UPDATE + crtc_offsets[i], tmp);\r\n}\r\ntmp = RREG32(EVERGREEN_MASTER_UPDATE_LOCK + crtc_offsets[i]);\r\nif (tmp & 1) {\r\ntmp &= ~1;\r\nWREG32(EVERGREEN_MASTER_UPDATE_LOCK + crtc_offsets[i], tmp);\r\n}\r\nfor (j = 0; j < rdev->usec_timeout; j++) {\r\ntmp = RREG32(EVERGREEN_GRPH_UPDATE + crtc_offsets[i]);\r\nif ((tmp & EVERGREEN_GRPH_SURFACE_UPDATE_PENDING) == 0)\r\nbreak;\r\nudelay(1);\r\n}\r\n}\r\n}\r\ntmp = RREG32(MC_SHARED_BLACKOUT_CNTL);\r\ntmp &= ~BLACKOUT_MODE_MASK;\r\nWREG32(MC_SHARED_BLACKOUT_CNTL, tmp);\r\nWREG32(BIF_FB_EN, FB_READ_EN | FB_WRITE_EN);\r\nfor (i = 0; i < rdev->num_crtc; i++) {\r\nif (save->crtc_enabled[i]) {\r\nif (ASIC_IS_DCE6(rdev)) {\r\ntmp = RREG32(EVERGREEN_CRTC_BLANK_CONTROL + crtc_offsets[i]);\r\ntmp &= ~EVERGREEN_CRTC_BLANK_DATA_EN;\r\nWREG32(EVERGREEN_CRTC_UPDATE_LOCK + crtc_offsets[i], 1);\r\nWREG32(EVERGREEN_CRTC_BLANK_CONTROL + crtc_offsets[i], tmp);\r\nWREG32(EVERGREEN_CRTC_UPDATE_LOCK + crtc_offsets[i], 0);\r\n} else {\r\ntmp = RREG32(EVERGREEN_CRTC_CONTROL + crtc_offsets[i]);\r\ntmp &= ~EVERGREEN_CRTC_DISP_READ_REQUEST_DISABLE;\r\nWREG32(EVERGREEN_CRTC_UPDATE_LOCK + crtc_offsets[i], 1);\r\nWREG32(EVERGREEN_CRTC_CONTROL + crtc_offsets[i], tmp);\r\nWREG32(EVERGREEN_CRTC_UPDATE_LOCK + crtc_offsets[i], 0);\r\n}\r\nframe_count = radeon_get_vblank_counter(rdev, i);\r\nfor (j = 0; j < rdev->usec_timeout; j++) {\r\nif (radeon_get_vblank_counter(rdev, i) != frame_count)\r\nbreak;\r\nudelay(1);\r\n}\r\n}\r\n}\r\nif (!ASIC_IS_NODCE(rdev)) {\r\nWREG32(VGA_HDP_CONTROL, save->vga_hdp_control);\r\nmdelay(1);\r\nWREG32(VGA_RENDER_CONTROL, save->vga_render_control);\r\n}\r\n}\r\nvoid evergreen_mc_program(struct radeon_device *rdev)\r\n{\r\nstruct evergreen_mc_save save;\r\nu32 tmp;\r\nint i, j;\r\nfor (i = 0, j = 0; i < 32; i++, j += 0x18) {\r\nWREG32((0x2c14 + j), 0x00000000);\r\nWREG32((0x2c18 + j), 0x00000000);\r\nWREG32((0x2c1c + j), 0x00000000);\r\nWREG32((0x2c20 + j), 0x00000000);\r\nWREG32((0x2c24 + j), 0x00000000);\r\n}\r\nWREG32(HDP_REG_COHERENCY_FLUSH_CNTL, 0);\r\nevergreen_mc_stop(rdev, &save);\r\nif (evergreen_mc_wait_for_idle(rdev)) {\r\ndev_warn(rdev->dev, "Wait for MC idle timedout !\n");\r\n}\r\nWREG32(VGA_HDP_CONTROL, VGA_MEMORY_DISABLE);\r\nif (rdev->flags & RADEON_IS_AGP) {\r\nif (rdev->mc.vram_start < rdev->mc.gtt_start) {\r\nWREG32(MC_VM_SYSTEM_APERTURE_LOW_ADDR,\r\nrdev->mc.vram_start >> 12);\r\nWREG32(MC_VM_SYSTEM_APERTURE_HIGH_ADDR,\r\nrdev->mc.gtt_end >> 12);\r\n} else {\r\nWREG32(MC_VM_SYSTEM_APERTURE_LOW_ADDR,\r\nrdev->mc.gtt_start >> 12);\r\nWREG32(MC_VM_SYSTEM_APERTURE_HIGH_ADDR,\r\nrdev->mc.vram_end >> 12);\r\n}\r\n} else {\r\nWREG32(MC_VM_SYSTEM_APERTURE_LOW_ADDR,\r\nrdev->mc.vram_start >> 12);\r\nWREG32(MC_VM_SYSTEM_APERTURE_HIGH_ADDR,\r\nrdev->mc.vram_end >> 12);\r\n}\r\nWREG32(MC_VM_SYSTEM_APERTURE_DEFAULT_ADDR, rdev->vram_scratch.gpu_addr >> 12);\r\nif ((rdev->family == CHIP_PALM) ||\r\n(rdev->family == CHIP_SUMO) ||\r\n(rdev->family == CHIP_SUMO2)) {\r\ntmp = RREG32(MC_FUS_VM_FB_OFFSET) & 0x000FFFFF;\r\ntmp |= ((rdev->mc.vram_end >> 20) & 0xF) << 24;\r\ntmp |= ((rdev->mc.vram_start >> 20) & 0xF) << 20;\r\nWREG32(MC_FUS_VM_FB_OFFSET, tmp);\r\n}\r\ntmp = ((rdev->mc.vram_end >> 24) & 0xFFFF) << 16;\r\ntmp |= ((rdev->mc.vram_start >> 24) & 0xFFFF);\r\nWREG32(MC_VM_FB_LOCATION, tmp);\r\nWREG32(HDP_NONSURFACE_BASE, (rdev->mc.vram_start >> 8));\r\nWREG32(HDP_NONSURFACE_INFO, (2 << 7) | (1 << 30));\r\nWREG32(HDP_NONSURFACE_SIZE, 0x3FFFFFFF);\r\nif (rdev->flags & RADEON_IS_AGP) {\r\nWREG32(MC_VM_AGP_TOP, rdev->mc.gtt_end >> 16);\r\nWREG32(MC_VM_AGP_BOT, rdev->mc.gtt_start >> 16);\r\nWREG32(MC_VM_AGP_BASE, rdev->mc.agp_base >> 22);\r\n} else {\r\nWREG32(MC_VM_AGP_BASE, 0);\r\nWREG32(MC_VM_AGP_TOP, 0x0FFFFFFF);\r\nWREG32(MC_VM_AGP_BOT, 0x0FFFFFFF);\r\n}\r\nif (evergreen_mc_wait_for_idle(rdev)) {\r\ndev_warn(rdev->dev, "Wait for MC idle timedout !\n");\r\n}\r\nevergreen_mc_resume(rdev, &save);\r\nrv515_vga_render_disable(rdev);\r\n}\r\nvoid evergreen_ring_ib_execute(struct radeon_device *rdev, struct radeon_ib *ib)\r\n{\r\nstruct radeon_ring *ring = &rdev->ring[ib->ring];\r\nu32 next_rptr;\r\nradeon_ring_write(ring, PACKET3(PACKET3_MODE_CONTROL, 0));\r\nradeon_ring_write(ring, 1);\r\nif (ring->rptr_save_reg) {\r\nnext_rptr = ring->wptr + 3 + 4;\r\nradeon_ring_write(ring, PACKET3(PACKET3_SET_CONFIG_REG, 1));\r\nradeon_ring_write(ring, ((ring->rptr_save_reg -\r\nPACKET3_SET_CONFIG_REG_START) >> 2));\r\nradeon_ring_write(ring, next_rptr);\r\n} else if (rdev->wb.enabled) {\r\nnext_rptr = ring->wptr + 5 + 4;\r\nradeon_ring_write(ring, PACKET3(PACKET3_MEM_WRITE, 3));\r\nradeon_ring_write(ring, ring->next_rptr_gpu_addr & 0xfffffffc);\r\nradeon_ring_write(ring, (upper_32_bits(ring->next_rptr_gpu_addr) & 0xff) | (1 << 18));\r\nradeon_ring_write(ring, next_rptr);\r\nradeon_ring_write(ring, 0);\r\n}\r\nradeon_ring_write(ring, PACKET3(PACKET3_INDIRECT_BUFFER, 2));\r\nradeon_ring_write(ring,\r\n#ifdef __BIG_ENDIAN\r\n(2 << 0) |\r\n#endif\r\n(ib->gpu_addr & 0xFFFFFFFC));\r\nradeon_ring_write(ring, upper_32_bits(ib->gpu_addr) & 0xFF);\r\nradeon_ring_write(ring, ib->length_dw);\r\n}\r\nstatic int evergreen_cp_load_microcode(struct radeon_device *rdev)\r\n{\r\nconst __be32 *fw_data;\r\nint i;\r\nif (!rdev->me_fw || !rdev->pfp_fw)\r\nreturn -EINVAL;\r\nr700_cp_stop(rdev);\r\nWREG32(CP_RB_CNTL,\r\n#ifdef __BIG_ENDIAN\r\nBUF_SWAP_32BIT |\r\n#endif\r\nRB_NO_UPDATE | RB_BLKSZ(15) | RB_BUFSZ(3));\r\nfw_data = (const __be32 *)rdev->pfp_fw->data;\r\nWREG32(CP_PFP_UCODE_ADDR, 0);\r\nfor (i = 0; i < EVERGREEN_PFP_UCODE_SIZE; i++)\r\nWREG32(CP_PFP_UCODE_DATA, be32_to_cpup(fw_data++));\r\nWREG32(CP_PFP_UCODE_ADDR, 0);\r\nfw_data = (const __be32 *)rdev->me_fw->data;\r\nWREG32(CP_ME_RAM_WADDR, 0);\r\nfor (i = 0; i < EVERGREEN_PM4_UCODE_SIZE; i++)\r\nWREG32(CP_ME_RAM_DATA, be32_to_cpup(fw_data++));\r\nWREG32(CP_PFP_UCODE_ADDR, 0);\r\nWREG32(CP_ME_RAM_WADDR, 0);\r\nWREG32(CP_ME_RAM_RADDR, 0);\r\nreturn 0;\r\n}\r\nstatic int evergreen_cp_start(struct radeon_device *rdev)\r\n{\r\nstruct radeon_ring *ring = &rdev->ring[RADEON_RING_TYPE_GFX_INDEX];\r\nint r, i;\r\nuint32_t cp_me;\r\nr = radeon_ring_lock(rdev, ring, 7);\r\nif (r) {\r\nDRM_ERROR("radeon: cp failed to lock ring (%d).\n", r);\r\nreturn r;\r\n}\r\nradeon_ring_write(ring, PACKET3(PACKET3_ME_INITIALIZE, 5));\r\nradeon_ring_write(ring, 0x1);\r\nradeon_ring_write(ring, 0x0);\r\nradeon_ring_write(ring, rdev->config.evergreen.max_hw_contexts - 1);\r\nradeon_ring_write(ring, PACKET3_ME_INITIALIZE_DEVICE_ID(1));\r\nradeon_ring_write(ring, 0);\r\nradeon_ring_write(ring, 0);\r\nradeon_ring_unlock_commit(rdev, ring, false);\r\ncp_me = 0xff;\r\nWREG32(CP_ME_CNTL, cp_me);\r\nr = radeon_ring_lock(rdev, ring, evergreen_default_size + 19);\r\nif (r) {\r\nDRM_ERROR("radeon: cp failed to lock ring (%d).\n", r);\r\nreturn r;\r\n}\r\nradeon_ring_write(ring, PACKET3(PACKET3_PREAMBLE_CNTL, 0));\r\nradeon_ring_write(ring, PACKET3_PREAMBLE_BEGIN_CLEAR_STATE);\r\nfor (i = 0; i < evergreen_default_size; i++)\r\nradeon_ring_write(ring, evergreen_default_state[i]);\r\nradeon_ring_write(ring, PACKET3(PACKET3_PREAMBLE_CNTL, 0));\r\nradeon_ring_write(ring, PACKET3_PREAMBLE_END_CLEAR_STATE);\r\nradeon_ring_write(ring, PACKET3(PACKET3_CLEAR_STATE, 0));\r\nradeon_ring_write(ring, 0);\r\nradeon_ring_write(ring, 0xc0026f00);\r\nradeon_ring_write(ring, 0x00000000);\r\nradeon_ring_write(ring, 0x00000000);\r\nradeon_ring_write(ring, 0x00000000);\r\nradeon_ring_write(ring, 0xc0036f00);\r\nradeon_ring_write(ring, 0x00000bc4);\r\nradeon_ring_write(ring, 0xffffffff);\r\nradeon_ring_write(ring, 0xffffffff);\r\nradeon_ring_write(ring, 0xffffffff);\r\nradeon_ring_write(ring, 0xc0026900);\r\nradeon_ring_write(ring, 0x00000316);\r\nradeon_ring_write(ring, 0x0000000e);\r\nradeon_ring_write(ring, 0x00000010);\r\nradeon_ring_unlock_commit(rdev, ring, false);\r\nreturn 0;\r\n}\r\nstatic int evergreen_cp_resume(struct radeon_device *rdev)\r\n{\r\nstruct radeon_ring *ring = &rdev->ring[RADEON_RING_TYPE_GFX_INDEX];\r\nu32 tmp;\r\nu32 rb_bufsz;\r\nint r;\r\nWREG32(GRBM_SOFT_RESET, (SOFT_RESET_CP |\r\nSOFT_RESET_PA |\r\nSOFT_RESET_SH |\r\nSOFT_RESET_VGT |\r\nSOFT_RESET_SPI |\r\nSOFT_RESET_SX));\r\nRREG32(GRBM_SOFT_RESET);\r\nmdelay(15);\r\nWREG32(GRBM_SOFT_RESET, 0);\r\nRREG32(GRBM_SOFT_RESET);\r\nrb_bufsz = order_base_2(ring->ring_size / 8);\r\ntmp = (order_base_2(RADEON_GPU_PAGE_SIZE/8) << 8) | rb_bufsz;\r\n#ifdef __BIG_ENDIAN\r\ntmp |= BUF_SWAP_32BIT;\r\n#endif\r\nWREG32(CP_RB_CNTL, tmp);\r\nWREG32(CP_SEM_WAIT_TIMER, 0x0);\r\nWREG32(CP_SEM_INCOMPLETE_TIMER_CNTL, 0x0);\r\nWREG32(CP_RB_WPTR_DELAY, 0);\r\nWREG32(CP_RB_CNTL, tmp | RB_RPTR_WR_ENA);\r\nWREG32(CP_RB_RPTR_WR, 0);\r\nring->wptr = 0;\r\nWREG32(CP_RB_WPTR, ring->wptr);\r\nWREG32(CP_RB_RPTR_ADDR,\r\n((rdev->wb.gpu_addr + RADEON_WB_CP_RPTR_OFFSET) & 0xFFFFFFFC));\r\nWREG32(CP_RB_RPTR_ADDR_HI, upper_32_bits(rdev->wb.gpu_addr + RADEON_WB_CP_RPTR_OFFSET) & 0xFF);\r\nWREG32(SCRATCH_ADDR, ((rdev->wb.gpu_addr + RADEON_WB_SCRATCH_OFFSET) >> 8) & 0xFFFFFFFF);\r\nif (rdev->wb.enabled)\r\nWREG32(SCRATCH_UMSK, 0xff);\r\nelse {\r\ntmp |= RB_NO_UPDATE;\r\nWREG32(SCRATCH_UMSK, 0);\r\n}\r\nmdelay(1);\r\nWREG32(CP_RB_CNTL, tmp);\r\nWREG32(CP_RB_BASE, ring->gpu_addr >> 8);\r\nWREG32(CP_DEBUG, (1 << 27) | (1 << 28));\r\nevergreen_cp_start(rdev);\r\nring->ready = true;\r\nr = radeon_ring_test(rdev, RADEON_RING_TYPE_GFX_INDEX, ring);\r\nif (r) {\r\nring->ready = false;\r\nreturn r;\r\n}\r\nreturn 0;\r\n}\r\nstatic void evergreen_gpu_init(struct radeon_device *rdev)\r\n{\r\nu32 gb_addr_config;\r\nu32 mc_shared_chmap, mc_arb_ramcfg;\r\nu32 sx_debug_1;\r\nu32 smx_dc_ctl0;\r\nu32 sq_config;\r\nu32 sq_lds_resource_mgmt;\r\nu32 sq_gpr_resource_mgmt_1;\r\nu32 sq_gpr_resource_mgmt_2;\r\nu32 sq_gpr_resource_mgmt_3;\r\nu32 sq_thread_resource_mgmt;\r\nu32 sq_thread_resource_mgmt_2;\r\nu32 sq_stack_resource_mgmt_1;\r\nu32 sq_stack_resource_mgmt_2;\r\nu32 sq_stack_resource_mgmt_3;\r\nu32 vgt_cache_invalidation;\r\nu32 hdp_host_path_cntl, tmp;\r\nu32 disabled_rb_mask;\r\nint i, j, ps_thread_count;\r\nswitch (rdev->family) {\r\ncase CHIP_CYPRESS:\r\ncase CHIP_HEMLOCK:\r\nrdev->config.evergreen.num_ses = 2;\r\nrdev->config.evergreen.max_pipes = 4;\r\nrdev->config.evergreen.max_tile_pipes = 8;\r\nrdev->config.evergreen.max_simds = 10;\r\nrdev->config.evergreen.max_backends = 4 * rdev->config.evergreen.num_ses;\r\nrdev->config.evergreen.max_gprs = 256;\r\nrdev->config.evergreen.max_threads = 248;\r\nrdev->config.evergreen.max_gs_threads = 32;\r\nrdev->config.evergreen.max_stack_entries = 512;\r\nrdev->config.evergreen.sx_num_of_sets = 4;\r\nrdev->config.evergreen.sx_max_export_size = 256;\r\nrdev->config.evergreen.sx_max_export_pos_size = 64;\r\nrdev->config.evergreen.sx_max_export_smx_size = 192;\r\nrdev->config.evergreen.max_hw_contexts = 8;\r\nrdev->config.evergreen.sq_num_cf_insts = 2;\r\nrdev->config.evergreen.sc_prim_fifo_size = 0x100;\r\nrdev->config.evergreen.sc_hiz_tile_fifo_size = 0x30;\r\nrdev->config.evergreen.sc_earlyz_tile_fifo_size = 0x130;\r\ngb_addr_config = CYPRESS_GB_ADDR_CONFIG_GOLDEN;\r\nbreak;\r\ncase CHIP_JUNIPER:\r\nrdev->config.evergreen.num_ses = 1;\r\nrdev->config.evergreen.max_pipes = 4;\r\nrdev->config.evergreen.max_tile_pipes = 4;\r\nrdev->config.evergreen.max_simds = 10;\r\nrdev->config.evergreen.max_backends = 4 * rdev->config.evergreen.num_ses;\r\nrdev->config.evergreen.max_gprs = 256;\r\nrdev->config.evergreen.max_threads = 248;\r\nrdev->config.evergreen.max_gs_threads = 32;\r\nrdev->config.evergreen.max_stack_entries = 512;\r\nrdev->config.evergreen.sx_num_of_sets = 4;\r\nrdev->config.evergreen.sx_max_export_size = 256;\r\nrdev->config.evergreen.sx_max_export_pos_size = 64;\r\nrdev->config.evergreen.sx_max_export_smx_size = 192;\r\nrdev->config.evergreen.max_hw_contexts = 8;\r\nrdev->config.evergreen.sq_num_cf_insts = 2;\r\nrdev->config.evergreen.sc_prim_fifo_size = 0x100;\r\nrdev->config.evergreen.sc_hiz_tile_fifo_size = 0x30;\r\nrdev->config.evergreen.sc_earlyz_tile_fifo_size = 0x130;\r\ngb_addr_config = JUNIPER_GB_ADDR_CONFIG_GOLDEN;\r\nbreak;\r\ncase CHIP_REDWOOD:\r\nrdev->config.evergreen.num_ses = 1;\r\nrdev->config.evergreen.max_pipes = 4;\r\nrdev->config.evergreen.max_tile_pipes = 4;\r\nrdev->config.evergreen.max_simds = 5;\r\nrdev->config.evergreen.max_backends = 2 * rdev->config.evergreen.num_ses;\r\nrdev->config.evergreen.max_gprs = 256;\r\nrdev->config.evergreen.max_threads = 248;\r\nrdev->config.evergreen.max_gs_threads = 32;\r\nrdev->config.evergreen.max_stack_entries = 256;\r\nrdev->config.evergreen.sx_num_of_sets = 4;\r\nrdev->config.evergreen.sx_max_export_size = 256;\r\nrdev->config.evergreen.sx_max_export_pos_size = 64;\r\nrdev->config.evergreen.sx_max_export_smx_size = 192;\r\nrdev->config.evergreen.max_hw_contexts = 8;\r\nrdev->config.evergreen.sq_num_cf_insts = 2;\r\nrdev->config.evergreen.sc_prim_fifo_size = 0x100;\r\nrdev->config.evergreen.sc_hiz_tile_fifo_size = 0x30;\r\nrdev->config.evergreen.sc_earlyz_tile_fifo_size = 0x130;\r\ngb_addr_config = REDWOOD_GB_ADDR_CONFIG_GOLDEN;\r\nbreak;\r\ncase CHIP_CEDAR:\r\ndefault:\r\nrdev->config.evergreen.num_ses = 1;\r\nrdev->config.evergreen.max_pipes = 2;\r\nrdev->config.evergreen.max_tile_pipes = 2;\r\nrdev->config.evergreen.max_simds = 2;\r\nrdev->config.evergreen.max_backends = 1 * rdev->config.evergreen.num_ses;\r\nrdev->config.evergreen.max_gprs = 256;\r\nrdev->config.evergreen.max_threads = 192;\r\nrdev->config.evergreen.max_gs_threads = 16;\r\nrdev->config.evergreen.max_stack_entries = 256;\r\nrdev->config.evergreen.sx_num_of_sets = 4;\r\nrdev->config.evergreen.sx_max_export_size = 128;\r\nrdev->config.evergreen.sx_max_export_pos_size = 32;\r\nrdev->config.evergreen.sx_max_export_smx_size = 96;\r\nrdev->config.evergreen.max_hw_contexts = 4;\r\nrdev->config.evergreen.sq_num_cf_insts = 1;\r\nrdev->config.evergreen.sc_prim_fifo_size = 0x40;\r\nrdev->config.evergreen.sc_hiz_tile_fifo_size = 0x30;\r\nrdev->config.evergreen.sc_earlyz_tile_fifo_size = 0x130;\r\ngb_addr_config = CEDAR_GB_ADDR_CONFIG_GOLDEN;\r\nbreak;\r\ncase CHIP_PALM:\r\nrdev->config.evergreen.num_ses = 1;\r\nrdev->config.evergreen.max_pipes = 2;\r\nrdev->config.evergreen.max_tile_pipes = 2;\r\nrdev->config.evergreen.max_simds = 2;\r\nrdev->config.evergreen.max_backends = 1 * rdev->config.evergreen.num_ses;\r\nrdev->config.evergreen.max_gprs = 256;\r\nrdev->config.evergreen.max_threads = 192;\r\nrdev->config.evergreen.max_gs_threads = 16;\r\nrdev->config.evergreen.max_stack_entries = 256;\r\nrdev->config.evergreen.sx_num_of_sets = 4;\r\nrdev->config.evergreen.sx_max_export_size = 128;\r\nrdev->config.evergreen.sx_max_export_pos_size = 32;\r\nrdev->config.evergreen.sx_max_export_smx_size = 96;\r\nrdev->config.evergreen.max_hw_contexts = 4;\r\nrdev->config.evergreen.sq_num_cf_insts = 1;\r\nrdev->config.evergreen.sc_prim_fifo_size = 0x40;\r\nrdev->config.evergreen.sc_hiz_tile_fifo_size = 0x30;\r\nrdev->config.evergreen.sc_earlyz_tile_fifo_size = 0x130;\r\ngb_addr_config = CEDAR_GB_ADDR_CONFIG_GOLDEN;\r\nbreak;\r\ncase CHIP_SUMO:\r\nrdev->config.evergreen.num_ses = 1;\r\nrdev->config.evergreen.max_pipes = 4;\r\nrdev->config.evergreen.max_tile_pipes = 4;\r\nif (rdev->pdev->device == 0x9648)\r\nrdev->config.evergreen.max_simds = 3;\r\nelse if ((rdev->pdev->device == 0x9647) ||\r\n(rdev->pdev->device == 0x964a))\r\nrdev->config.evergreen.max_simds = 4;\r\nelse\r\nrdev->config.evergreen.max_simds = 5;\r\nrdev->config.evergreen.max_backends = 2 * rdev->config.evergreen.num_ses;\r\nrdev->config.evergreen.max_gprs = 256;\r\nrdev->config.evergreen.max_threads = 248;\r\nrdev->config.evergreen.max_gs_threads = 32;\r\nrdev->config.evergreen.max_stack_entries = 256;\r\nrdev->config.evergreen.sx_num_of_sets = 4;\r\nrdev->config.evergreen.sx_max_export_size = 256;\r\nrdev->config.evergreen.sx_max_export_pos_size = 64;\r\nrdev->config.evergreen.sx_max_export_smx_size = 192;\r\nrdev->config.evergreen.max_hw_contexts = 8;\r\nrdev->config.evergreen.sq_num_cf_insts = 2;\r\nrdev->config.evergreen.sc_prim_fifo_size = 0x40;\r\nrdev->config.evergreen.sc_hiz_tile_fifo_size = 0x30;\r\nrdev->config.evergreen.sc_earlyz_tile_fifo_size = 0x130;\r\ngb_addr_config = SUMO_GB_ADDR_CONFIG_GOLDEN;\r\nbreak;\r\ncase CHIP_SUMO2:\r\nrdev->config.evergreen.num_ses = 1;\r\nrdev->config.evergreen.max_pipes = 4;\r\nrdev->config.evergreen.max_tile_pipes = 4;\r\nrdev->config.evergreen.max_simds = 2;\r\nrdev->config.evergreen.max_backends = 1 * rdev->config.evergreen.num_ses;\r\nrdev->config.evergreen.max_gprs = 256;\r\nrdev->config.evergreen.max_threads = 248;\r\nrdev->config.evergreen.max_gs_threads = 32;\r\nrdev->config.evergreen.max_stack_entries = 512;\r\nrdev->config.evergreen.sx_num_of_sets = 4;\r\nrdev->config.evergreen.sx_max_export_size = 256;\r\nrdev->config.evergreen.sx_max_export_pos_size = 64;\r\nrdev->config.evergreen.sx_max_export_smx_size = 192;\r\nrdev->config.evergreen.max_hw_contexts = 4;\r\nrdev->config.evergreen.sq_num_cf_insts = 2;\r\nrdev->config.evergreen.sc_prim_fifo_size = 0x40;\r\nrdev->config.evergreen.sc_hiz_tile_fifo_size = 0x30;\r\nrdev->config.evergreen.sc_earlyz_tile_fifo_size = 0x130;\r\ngb_addr_config = SUMO2_GB_ADDR_CONFIG_GOLDEN;\r\nbreak;\r\ncase CHIP_BARTS:\r\nrdev->config.evergreen.num_ses = 2;\r\nrdev->config.evergreen.max_pipes = 4;\r\nrdev->config.evergreen.max_tile_pipes = 8;\r\nrdev->config.evergreen.max_simds = 7;\r\nrdev->config.evergreen.max_backends = 4 * rdev->config.evergreen.num_ses;\r\nrdev->config.evergreen.max_gprs = 256;\r\nrdev->config.evergreen.max_threads = 248;\r\nrdev->config.evergreen.max_gs_threads = 32;\r\nrdev->config.evergreen.max_stack_entries = 512;\r\nrdev->config.evergreen.sx_num_of_sets = 4;\r\nrdev->config.evergreen.sx_max_export_size = 256;\r\nrdev->config.evergreen.sx_max_export_pos_size = 64;\r\nrdev->config.evergreen.sx_max_export_smx_size = 192;\r\nrdev->config.evergreen.max_hw_contexts = 8;\r\nrdev->config.evergreen.sq_num_cf_insts = 2;\r\nrdev->config.evergreen.sc_prim_fifo_size = 0x100;\r\nrdev->config.evergreen.sc_hiz_tile_fifo_size = 0x30;\r\nrdev->config.evergreen.sc_earlyz_tile_fifo_size = 0x130;\r\ngb_addr_config = BARTS_GB_ADDR_CONFIG_GOLDEN;\r\nbreak;\r\ncase CHIP_TURKS:\r\nrdev->config.evergreen.num_ses = 1;\r\nrdev->config.evergreen.max_pipes = 4;\r\nrdev->config.evergreen.max_tile_pipes = 4;\r\nrdev->config.evergreen.max_simds = 6;\r\nrdev->config.evergreen.max_backends = 2 * rdev->config.evergreen.num_ses;\r\nrdev->config.evergreen.max_gprs = 256;\r\nrdev->config.evergreen.max_threads = 248;\r\nrdev->config.evergreen.max_gs_threads = 32;\r\nrdev->config.evergreen.max_stack_entries = 256;\r\nrdev->config.evergreen.sx_num_of_sets = 4;\r\nrdev->config.evergreen.sx_max_export_size = 256;\r\nrdev->config.evergreen.sx_max_export_pos_size = 64;\r\nrdev->config.evergreen.sx_max_export_smx_size = 192;\r\nrdev->config.evergreen.max_hw_contexts = 8;\r\nrdev->config.evergreen.sq_num_cf_insts = 2;\r\nrdev->config.evergreen.sc_prim_fifo_size = 0x100;\r\nrdev->config.evergreen.sc_hiz_tile_fifo_size = 0x30;\r\nrdev->config.evergreen.sc_earlyz_tile_fifo_size = 0x130;\r\ngb_addr_config = TURKS_GB_ADDR_CONFIG_GOLDEN;\r\nbreak;\r\ncase CHIP_CAICOS:\r\nrdev->config.evergreen.num_ses = 1;\r\nrdev->config.evergreen.max_pipes = 2;\r\nrdev->config.evergreen.max_tile_pipes = 2;\r\nrdev->config.evergreen.max_simds = 2;\r\nrdev->config.evergreen.max_backends = 1 * rdev->config.evergreen.num_ses;\r\nrdev->config.evergreen.max_gprs = 256;\r\nrdev->config.evergreen.max_threads = 192;\r\nrdev->config.evergreen.max_gs_threads = 16;\r\nrdev->config.evergreen.max_stack_entries = 256;\r\nrdev->config.evergreen.sx_num_of_sets = 4;\r\nrdev->config.evergreen.sx_max_export_size = 128;\r\nrdev->config.evergreen.sx_max_export_pos_size = 32;\r\nrdev->config.evergreen.sx_max_export_smx_size = 96;\r\nrdev->config.evergreen.max_hw_contexts = 4;\r\nrdev->config.evergreen.sq_num_cf_insts = 1;\r\nrdev->config.evergreen.sc_prim_fifo_size = 0x40;\r\nrdev->config.evergreen.sc_hiz_tile_fifo_size = 0x30;\r\nrdev->config.evergreen.sc_earlyz_tile_fifo_size = 0x130;\r\ngb_addr_config = CAICOS_GB_ADDR_CONFIG_GOLDEN;\r\nbreak;\r\n}\r\nfor (i = 0, j = 0; i < 32; i++, j += 0x18) {\r\nWREG32((0x2c14 + j), 0x00000000);\r\nWREG32((0x2c18 + j), 0x00000000);\r\nWREG32((0x2c1c + j), 0x00000000);\r\nWREG32((0x2c20 + j), 0x00000000);\r\nWREG32((0x2c24 + j), 0x00000000);\r\n}\r\nWREG32(GRBM_CNTL, GRBM_READ_TIMEOUT(0xff));\r\nevergreen_fix_pci_max_read_req_size(rdev);\r\nmc_shared_chmap = RREG32(MC_SHARED_CHMAP);\r\nif ((rdev->family == CHIP_PALM) ||\r\n(rdev->family == CHIP_SUMO) ||\r\n(rdev->family == CHIP_SUMO2))\r\nmc_arb_ramcfg = RREG32(FUS_MC_ARB_RAMCFG);\r\nelse\r\nmc_arb_ramcfg = RREG32(MC_ARB_RAMCFG);\r\nrdev->config.evergreen.tile_config = 0;\r\nswitch (rdev->config.evergreen.max_tile_pipes) {\r\ncase 1:\r\ndefault:\r\nrdev->config.evergreen.tile_config |= (0 << 0);\r\nbreak;\r\ncase 2:\r\nrdev->config.evergreen.tile_config |= (1 << 0);\r\nbreak;\r\ncase 4:\r\nrdev->config.evergreen.tile_config |= (2 << 0);\r\nbreak;\r\ncase 8:\r\nrdev->config.evergreen.tile_config |= (3 << 0);\r\nbreak;\r\n}\r\nif (rdev->flags & RADEON_IS_IGP)\r\nrdev->config.evergreen.tile_config |= 1 << 4;\r\nelse {\r\nswitch ((mc_arb_ramcfg & NOOFBANK_MASK) >> NOOFBANK_SHIFT) {\r\ncase 0:\r\nrdev->config.evergreen.tile_config |= 0 << 4;\r\nbreak;\r\ncase 1:\r\nrdev->config.evergreen.tile_config |= 1 << 4;\r\nbreak;\r\ncase 2:\r\ndefault:\r\nrdev->config.evergreen.tile_config |= 2 << 4;\r\nbreak;\r\n}\r\n}\r\nrdev->config.evergreen.tile_config |= 0 << 8;\r\nrdev->config.evergreen.tile_config |=\r\n((gb_addr_config & 0x30000000) >> 28) << 12;\r\nif ((rdev->family >= CHIP_CEDAR) && (rdev->family <= CHIP_HEMLOCK)) {\r\nu32 efuse_straps_4;\r\nu32 efuse_straps_3;\r\nefuse_straps_4 = RREG32_RCU(0x204);\r\nefuse_straps_3 = RREG32_RCU(0x203);\r\ntmp = (((efuse_straps_4 & 0xf) << 4) |\r\n((efuse_straps_3 & 0xf0000000) >> 28));\r\n} else {\r\ntmp = 0;\r\nfor (i = (rdev->config.evergreen.num_ses - 1); i >= 0; i--) {\r\nu32 rb_disable_bitmap;\r\nWREG32(GRBM_GFX_INDEX, INSTANCE_BROADCAST_WRITES | SE_INDEX(i));\r\nWREG32(RLC_GFX_INDEX, INSTANCE_BROADCAST_WRITES | SE_INDEX(i));\r\nrb_disable_bitmap = (RREG32(CC_RB_BACKEND_DISABLE) & 0x00ff0000) >> 16;\r\ntmp <<= 4;\r\ntmp |= rb_disable_bitmap;\r\n}\r\n}\r\ndisabled_rb_mask = tmp;\r\ntmp = 0;\r\nfor (i = 0; i < rdev->config.evergreen.max_backends; i++)\r\ntmp |= (1 << i);\r\nif ((disabled_rb_mask & tmp) == tmp) {\r\nfor (i = 0; i < rdev->config.evergreen.max_backends; i++)\r\ndisabled_rb_mask &= ~(1 << i);\r\n}\r\nfor (i = 0; i < rdev->config.evergreen.num_ses; i++) {\r\nu32 simd_disable_bitmap;\r\nWREG32(GRBM_GFX_INDEX, INSTANCE_BROADCAST_WRITES | SE_INDEX(i));\r\nWREG32(RLC_GFX_INDEX, INSTANCE_BROADCAST_WRITES | SE_INDEX(i));\r\nsimd_disable_bitmap = (RREG32(CC_GC_SHADER_PIPE_CONFIG) & 0xffff0000) >> 16;\r\nsimd_disable_bitmap |= 0xffffffff << rdev->config.evergreen.max_simds;\r\ntmp <<= 16;\r\ntmp |= simd_disable_bitmap;\r\n}\r\nrdev->config.evergreen.active_simds = hweight32(~tmp);\r\nWREG32(GRBM_GFX_INDEX, INSTANCE_BROADCAST_WRITES | SE_BROADCAST_WRITES);\r\nWREG32(RLC_GFX_INDEX, INSTANCE_BROADCAST_WRITES | SE_BROADCAST_WRITES);\r\nWREG32(GB_ADDR_CONFIG, gb_addr_config);\r\nWREG32(DMIF_ADDR_CONFIG, gb_addr_config);\r\nWREG32(HDP_ADDR_CONFIG, gb_addr_config);\r\nWREG32(DMA_TILING_CONFIG, gb_addr_config);\r\nWREG32(UVD_UDEC_ADDR_CONFIG, gb_addr_config);\r\nWREG32(UVD_UDEC_DB_ADDR_CONFIG, gb_addr_config);\r\nWREG32(UVD_UDEC_DBW_ADDR_CONFIG, gb_addr_config);\r\nif ((rdev->config.evergreen.max_backends == 1) &&\r\n(rdev->flags & RADEON_IS_IGP)) {\r\nif ((disabled_rb_mask & 3) == 1) {\r\ntmp = 0x11111111;\r\n} else {\r\ntmp = 0x00000000;\r\n}\r\n} else {\r\ntmp = gb_addr_config & NUM_PIPES_MASK;\r\ntmp = r6xx_remap_render_backend(rdev, tmp, rdev->config.evergreen.max_backends,\r\nEVERGREEN_MAX_BACKENDS, disabled_rb_mask);\r\n}\r\nWREG32(GB_BACKEND_MAP, tmp);\r\nWREG32(CGTS_SYS_TCC_DISABLE, 0);\r\nWREG32(CGTS_TCC_DISABLE, 0);\r\nWREG32(CGTS_USER_SYS_TCC_DISABLE, 0);\r\nWREG32(CGTS_USER_TCC_DISABLE, 0);\r\nWREG32(CP_QUEUE_THRESHOLDS, (ROQ_IB1_START(0x16) |\r\nROQ_IB2_START(0x2b)));\r\nWREG32(CP_MEQ_THRESHOLDS, STQ_SPLIT(0x30));\r\nWREG32(TA_CNTL_AUX, (DISABLE_CUBE_ANISO |\r\nSYNC_GRADIENT |\r\nSYNC_WALKER |\r\nSYNC_ALIGNER));\r\nsx_debug_1 = RREG32(SX_DEBUG_1);\r\nsx_debug_1 |= ENABLE_NEW_SMX_ADDRESS;\r\nWREG32(SX_DEBUG_1, sx_debug_1);\r\nsmx_dc_ctl0 = RREG32(SMX_DC_CTL0);\r\nsmx_dc_ctl0 &= ~NUMBER_OF_SETS(0x1ff);\r\nsmx_dc_ctl0 |= NUMBER_OF_SETS(rdev->config.evergreen.sx_num_of_sets);\r\nWREG32(SMX_DC_CTL0, smx_dc_ctl0);\r\nif (rdev->family <= CHIP_SUMO2)\r\nWREG32(SMX_SAR_CTL0, 0x00010000);\r\nWREG32(SX_EXPORT_BUFFER_SIZES, (COLOR_BUFFER_SIZE((rdev->config.evergreen.sx_max_export_size / 4) - 1) |\r\nPOSITION_BUFFER_SIZE((rdev->config.evergreen.sx_max_export_pos_size / 4) - 1) |\r\nSMX_BUFFER_SIZE((rdev->config.evergreen.sx_max_export_smx_size / 4) - 1)));\r\nWREG32(PA_SC_FIFO_SIZE, (SC_PRIM_FIFO_SIZE(rdev->config.evergreen.sc_prim_fifo_size) |\r\nSC_HIZ_TILE_FIFO_SIZE(rdev->config.evergreen.sc_hiz_tile_fifo_size) |\r\nSC_EARLYZ_TILE_FIFO_SIZE(rdev->config.evergreen.sc_earlyz_tile_fifo_size)));\r\nWREG32(VGT_NUM_INSTANCES, 1);\r\nWREG32(SPI_CONFIG_CNTL, 0);\r\nWREG32(SPI_CONFIG_CNTL_1, VTX_DONE_DELAY(4));\r\nWREG32(CP_PERFMON_CNTL, 0);\r\nWREG32(SQ_MS_FIFO_SIZES, (CACHE_FIFO_SIZE(16 * rdev->config.evergreen.sq_num_cf_insts) |\r\nFETCH_FIFO_HIWATER(0x4) |\r\nDONE_FIFO_HIWATER(0xe0) |\r\nALU_UPDATE_FIFO_HIWATER(0x8)));\r\nsq_config = RREG32(SQ_CONFIG);\r\nsq_config &= ~(PS_PRIO(3) |\r\nVS_PRIO(3) |\r\nGS_PRIO(3) |\r\nES_PRIO(3));\r\nsq_config |= (VC_ENABLE |\r\nEXPORT_SRC_C |\r\nPS_PRIO(0) |\r\nVS_PRIO(1) |\r\nGS_PRIO(2) |\r\nES_PRIO(3));\r\nswitch (rdev->family) {\r\ncase CHIP_CEDAR:\r\ncase CHIP_PALM:\r\ncase CHIP_SUMO:\r\ncase CHIP_SUMO2:\r\ncase CHIP_CAICOS:\r\nsq_config &= ~VC_ENABLE;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nsq_lds_resource_mgmt = RREG32(SQ_LDS_RESOURCE_MGMT);\r\nsq_gpr_resource_mgmt_1 = NUM_PS_GPRS((rdev->config.evergreen.max_gprs - (4 * 2))* 12 / 32);\r\nsq_gpr_resource_mgmt_1 |= NUM_VS_GPRS((rdev->config.evergreen.max_gprs - (4 * 2)) * 6 / 32);\r\nsq_gpr_resource_mgmt_1 |= NUM_CLAUSE_TEMP_GPRS(4);\r\nsq_gpr_resource_mgmt_2 = NUM_GS_GPRS((rdev->config.evergreen.max_gprs - (4 * 2)) * 4 / 32);\r\nsq_gpr_resource_mgmt_2 |= NUM_ES_GPRS((rdev->config.evergreen.max_gprs - (4 * 2)) * 4 / 32);\r\nsq_gpr_resource_mgmt_3 = NUM_HS_GPRS((rdev->config.evergreen.max_gprs - (4 * 2)) * 3 / 32);\r\nsq_gpr_resource_mgmt_3 |= NUM_LS_GPRS((rdev->config.evergreen.max_gprs - (4 * 2)) * 3 / 32);\r\nswitch (rdev->family) {\r\ncase CHIP_CEDAR:\r\ncase CHIP_PALM:\r\ncase CHIP_SUMO:\r\ncase CHIP_SUMO2:\r\nps_thread_count = 96;\r\nbreak;\r\ndefault:\r\nps_thread_count = 128;\r\nbreak;\r\n}\r\nsq_thread_resource_mgmt = NUM_PS_THREADS(ps_thread_count);\r\nsq_thread_resource_mgmt |= NUM_VS_THREADS((((rdev->config.evergreen.max_threads - ps_thread_count) / 6) / 8) * 8);\r\nsq_thread_resource_mgmt |= NUM_GS_THREADS((((rdev->config.evergreen.max_threads - ps_thread_count) / 6) / 8) * 8);\r\nsq_thread_resource_mgmt |= NUM_ES_THREADS((((rdev->config.evergreen.max_threads - ps_thread_count) / 6) / 8) * 8);\r\nsq_thread_resource_mgmt_2 = NUM_HS_THREADS((((rdev->config.evergreen.max_threads - ps_thread_count) / 6) / 8) * 8);\r\nsq_thread_resource_mgmt_2 |= NUM_LS_THREADS((((rdev->config.evergreen.max_threads - ps_thread_count) / 6) / 8) * 8);\r\nsq_stack_resource_mgmt_1 = NUM_PS_STACK_ENTRIES((rdev->config.evergreen.max_stack_entries * 1) / 6);\r\nsq_stack_resource_mgmt_1 |= NUM_VS_STACK_ENTRIES((rdev->config.evergreen.max_stack_entries * 1) / 6);\r\nsq_stack_resource_mgmt_2 = NUM_GS_STACK_ENTRIES((rdev->config.evergreen.max_stack_entries * 1) / 6);\r\nsq_stack_resource_mgmt_2 |= NUM_ES_STACK_ENTRIES((rdev->config.evergreen.max_stack_entries * 1) / 6);\r\nsq_stack_resource_mgmt_3 = NUM_HS_STACK_ENTRIES((rdev->config.evergreen.max_stack_entries * 1) / 6);\r\nsq_stack_resource_mgmt_3 |= NUM_LS_STACK_ENTRIES((rdev->config.evergreen.max_stack_entries * 1) / 6);\r\nWREG32(SQ_CONFIG, sq_config);\r\nWREG32(SQ_GPR_RESOURCE_MGMT_1, sq_gpr_resource_mgmt_1);\r\nWREG32(SQ_GPR_RESOURCE_MGMT_2, sq_gpr_resource_mgmt_2);\r\nWREG32(SQ_GPR_RESOURCE_MGMT_3, sq_gpr_resource_mgmt_3);\r\nWREG32(SQ_THREAD_RESOURCE_MGMT, sq_thread_resource_mgmt);\r\nWREG32(SQ_THREAD_RESOURCE_MGMT_2, sq_thread_resource_mgmt_2);\r\nWREG32(SQ_STACK_RESOURCE_MGMT_1, sq_stack_resource_mgmt_1);\r\nWREG32(SQ_STACK_RESOURCE_MGMT_2, sq_stack_resource_mgmt_2);\r\nWREG32(SQ_STACK_RESOURCE_MGMT_3, sq_stack_resource_mgmt_3);\r\nWREG32(SQ_DYN_GPR_CNTL_PS_FLUSH_REQ, 0);\r\nWREG32(SQ_LDS_RESOURCE_MGMT, sq_lds_resource_mgmt);\r\nWREG32(PA_SC_FORCE_EOV_MAX_CNTS, (FORCE_EOV_MAX_CLK_CNT(4095) |\r\nFORCE_EOV_MAX_REZ_CNT(255)));\r\nswitch (rdev->family) {\r\ncase CHIP_CEDAR:\r\ncase CHIP_PALM:\r\ncase CHIP_SUMO:\r\ncase CHIP_SUMO2:\r\ncase CHIP_CAICOS:\r\nvgt_cache_invalidation = CACHE_INVALIDATION(TC_ONLY);\r\nbreak;\r\ndefault:\r\nvgt_cache_invalidation = CACHE_INVALIDATION(VC_AND_TC);\r\nbreak;\r\n}\r\nvgt_cache_invalidation |= AUTO_INVLD_EN(ES_AND_GS_AUTO);\r\nWREG32(VGT_CACHE_INVALIDATION, vgt_cache_invalidation);\r\nWREG32(VGT_GS_VERTEX_REUSE, 16);\r\nWREG32(PA_SU_LINE_STIPPLE_VALUE, 0);\r\nWREG32(PA_SC_LINE_STIPPLE_STATE, 0);\r\nWREG32(VGT_VERTEX_REUSE_BLOCK_CNTL, 14);\r\nWREG32(VGT_OUT_DEALLOC_CNTL, 16);\r\nWREG32(CB_PERF_CTR0_SEL_0, 0);\r\nWREG32(CB_PERF_CTR0_SEL_1, 0);\r\nWREG32(CB_PERF_CTR1_SEL_0, 0);\r\nWREG32(CB_PERF_CTR1_SEL_1, 0);\r\nWREG32(CB_PERF_CTR2_SEL_0, 0);\r\nWREG32(CB_PERF_CTR2_SEL_1, 0);\r\nWREG32(CB_PERF_CTR3_SEL_0, 0);\r\nWREG32(CB_PERF_CTR3_SEL_1, 0);\r\nWREG32(CB_COLOR0_BASE, 0);\r\nWREG32(CB_COLOR1_BASE, 0);\r\nWREG32(CB_COLOR2_BASE, 0);\r\nWREG32(CB_COLOR3_BASE, 0);\r\nWREG32(CB_COLOR4_BASE, 0);\r\nWREG32(CB_COLOR5_BASE, 0);\r\nWREG32(CB_COLOR6_BASE, 0);\r\nWREG32(CB_COLOR7_BASE, 0);\r\nWREG32(CB_COLOR8_BASE, 0);\r\nWREG32(CB_COLOR9_BASE, 0);\r\nWREG32(CB_COLOR10_BASE, 0);\r\nWREG32(CB_COLOR11_BASE, 0);\r\nfor (i = SQ_ALU_CONST_BUFFER_SIZE_PS_0; i < 0x28200; i += 4)\r\nWREG32(i, 0);\r\nfor (i = SQ_ALU_CONST_BUFFER_SIZE_HS_0; i < 0x29000; i += 4)\r\nWREG32(i, 0);\r\ntmp = RREG32(HDP_MISC_CNTL);\r\ntmp |= HDP_FLUSH_INVALIDATE_CACHE;\r\nWREG32(HDP_MISC_CNTL, tmp);\r\nhdp_host_path_cntl = RREG32(HDP_HOST_PATH_CNTL);\r\nWREG32(HDP_HOST_PATH_CNTL, hdp_host_path_cntl);\r\nWREG32(PA_CL_ENHANCE, CLIP_VTX_REORDER_ENA | NUM_CLIP_SEQ(3));\r\nudelay(50);\r\n}\r\nint evergreen_mc_init(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\nint chansize, numchan;\r\nrdev->mc.vram_is_ddr = true;\r\nif ((rdev->family == CHIP_PALM) ||\r\n(rdev->family == CHIP_SUMO) ||\r\n(rdev->family == CHIP_SUMO2))\r\ntmp = RREG32(FUS_MC_ARB_RAMCFG);\r\nelse\r\ntmp = RREG32(MC_ARB_RAMCFG);\r\nif (tmp & CHANSIZE_OVERRIDE) {\r\nchansize = 16;\r\n} else if (tmp & CHANSIZE_MASK) {\r\nchansize = 64;\r\n} else {\r\nchansize = 32;\r\n}\r\ntmp = RREG32(MC_SHARED_CHMAP);\r\nswitch ((tmp & NOOFCHAN_MASK) >> NOOFCHAN_SHIFT) {\r\ncase 0:\r\ndefault:\r\nnumchan = 1;\r\nbreak;\r\ncase 1:\r\nnumchan = 2;\r\nbreak;\r\ncase 2:\r\nnumchan = 4;\r\nbreak;\r\ncase 3:\r\nnumchan = 8;\r\nbreak;\r\n}\r\nrdev->mc.vram_width = numchan * chansize;\r\nrdev->mc.aper_base = pci_resource_start(rdev->pdev, 0);\r\nrdev->mc.aper_size = pci_resource_len(rdev->pdev, 0);\r\nif ((rdev->family == CHIP_PALM) ||\r\n(rdev->family == CHIP_SUMO) ||\r\n(rdev->family == CHIP_SUMO2)) {\r\nrdev->mc.mc_vram_size = RREG32(CONFIG_MEMSIZE);\r\nrdev->mc.real_vram_size = RREG32(CONFIG_MEMSIZE);\r\n} else {\r\nrdev->mc.mc_vram_size = RREG32(CONFIG_MEMSIZE) * 1024ULL * 1024ULL;\r\nrdev->mc.real_vram_size = RREG32(CONFIG_MEMSIZE) * 1024ULL * 1024ULL;\r\n}\r\nrdev->mc.visible_vram_size = rdev->mc.aper_size;\r\nr700_vram_gtt_location(rdev, &rdev->mc);\r\nradeon_update_bandwidth_info(rdev);\r\nreturn 0;\r\n}\r\nvoid evergreen_print_gpu_status_regs(struct radeon_device *rdev)\r\n{\r\ndev_info(rdev->dev, " GRBM_STATUS = 0x%08X\n",\r\nRREG32(GRBM_STATUS));\r\ndev_info(rdev->dev, " GRBM_STATUS_SE0 = 0x%08X\n",\r\nRREG32(GRBM_STATUS_SE0));\r\ndev_info(rdev->dev, " GRBM_STATUS_SE1 = 0x%08X\n",\r\nRREG32(GRBM_STATUS_SE1));\r\ndev_info(rdev->dev, " SRBM_STATUS = 0x%08X\n",\r\nRREG32(SRBM_STATUS));\r\ndev_info(rdev->dev, " SRBM_STATUS2 = 0x%08X\n",\r\nRREG32(SRBM_STATUS2));\r\ndev_info(rdev->dev, " R_008674_CP_STALLED_STAT1 = 0x%08X\n",\r\nRREG32(CP_STALLED_STAT1));\r\ndev_info(rdev->dev, " R_008678_CP_STALLED_STAT2 = 0x%08X\n",\r\nRREG32(CP_STALLED_STAT2));\r\ndev_info(rdev->dev, " R_00867C_CP_BUSY_STAT = 0x%08X\n",\r\nRREG32(CP_BUSY_STAT));\r\ndev_info(rdev->dev, " R_008680_CP_STAT = 0x%08X\n",\r\nRREG32(CP_STAT));\r\ndev_info(rdev->dev, " R_00D034_DMA_STATUS_REG = 0x%08X\n",\r\nRREG32(DMA_STATUS_REG));\r\nif (rdev->family >= CHIP_CAYMAN) {\r\ndev_info(rdev->dev, " R_00D834_DMA_STATUS_REG = 0x%08X\n",\r\nRREG32(DMA_STATUS_REG + 0x800));\r\n}\r\n}\r\nbool evergreen_is_display_hung(struct radeon_device *rdev)\r\n{\r\nu32 crtc_hung = 0;\r\nu32 crtc_status[6];\r\nu32 i, j, tmp;\r\nfor (i = 0; i < rdev->num_crtc; i++) {\r\nif (RREG32(EVERGREEN_CRTC_CONTROL + crtc_offsets[i]) & EVERGREEN_CRTC_MASTER_EN) {\r\ncrtc_status[i] = RREG32(EVERGREEN_CRTC_STATUS_HV_COUNT + crtc_offsets[i]);\r\ncrtc_hung |= (1 << i);\r\n}\r\n}\r\nfor (j = 0; j < 10; j++) {\r\nfor (i = 0; i < rdev->num_crtc; i++) {\r\nif (crtc_hung & (1 << i)) {\r\ntmp = RREG32(EVERGREEN_CRTC_STATUS_HV_COUNT + crtc_offsets[i]);\r\nif (tmp != crtc_status[i])\r\ncrtc_hung &= ~(1 << i);\r\n}\r\n}\r\nif (crtc_hung == 0)\r\nreturn false;\r\nudelay(100);\r\n}\r\nreturn true;\r\n}\r\nu32 evergreen_gpu_check_soft_reset(struct radeon_device *rdev)\r\n{\r\nu32 reset_mask = 0;\r\nu32 tmp;\r\ntmp = RREG32(GRBM_STATUS);\r\nif (tmp & (PA_BUSY | SC_BUSY |\r\nSH_BUSY | SX_BUSY |\r\nTA_BUSY | VGT_BUSY |\r\nDB_BUSY | CB_BUSY |\r\nSPI_BUSY | VGT_BUSY_NO_DMA))\r\nreset_mask |= RADEON_RESET_GFX;\r\nif (tmp & (CF_RQ_PENDING | PF_RQ_PENDING |\r\nCP_BUSY | CP_COHERENCY_BUSY))\r\nreset_mask |= RADEON_RESET_CP;\r\nif (tmp & GRBM_EE_BUSY)\r\nreset_mask |= RADEON_RESET_GRBM | RADEON_RESET_GFX | RADEON_RESET_CP;\r\ntmp = RREG32(DMA_STATUS_REG);\r\nif (!(tmp & DMA_IDLE))\r\nreset_mask |= RADEON_RESET_DMA;\r\ntmp = RREG32(SRBM_STATUS2);\r\nif (tmp & DMA_BUSY)\r\nreset_mask |= RADEON_RESET_DMA;\r\ntmp = RREG32(SRBM_STATUS);\r\nif (tmp & (RLC_RQ_PENDING | RLC_BUSY))\r\nreset_mask |= RADEON_RESET_RLC;\r\nif (tmp & IH_BUSY)\r\nreset_mask |= RADEON_RESET_IH;\r\nif (tmp & SEM_BUSY)\r\nreset_mask |= RADEON_RESET_SEM;\r\nif (tmp & GRBM_RQ_PENDING)\r\nreset_mask |= RADEON_RESET_GRBM;\r\nif (tmp & VMC_BUSY)\r\nreset_mask |= RADEON_RESET_VMC;\r\nif (tmp & (MCB_BUSY | MCB_NON_DISPLAY_BUSY |\r\nMCC_BUSY | MCD_BUSY))\r\nreset_mask |= RADEON_RESET_MC;\r\nif (evergreen_is_display_hung(rdev))\r\nreset_mask |= RADEON_RESET_DISPLAY;\r\ntmp = RREG32(VM_L2_STATUS);\r\nif (tmp & L2_BUSY)\r\nreset_mask |= RADEON_RESET_VMC;\r\nif (reset_mask & RADEON_RESET_MC) {\r\nDRM_DEBUG("MC busy: 0x%08X, clearing.\n", reset_mask);\r\nreset_mask &= ~RADEON_RESET_MC;\r\n}\r\nreturn reset_mask;\r\n}\r\nstatic void evergreen_gpu_soft_reset(struct radeon_device *rdev, u32 reset_mask)\r\n{\r\nstruct evergreen_mc_save save;\r\nu32 grbm_soft_reset = 0, srbm_soft_reset = 0;\r\nu32 tmp;\r\nif (reset_mask == 0)\r\nreturn;\r\ndev_info(rdev->dev, "GPU softreset: 0x%08X\n", reset_mask);\r\nevergreen_print_gpu_status_regs(rdev);\r\nWREG32(CP_ME_CNTL, CP_ME_HALT | CP_PFP_HALT);\r\nif (reset_mask & RADEON_RESET_DMA) {\r\ntmp = RREG32(DMA_RB_CNTL);\r\ntmp &= ~DMA_RB_ENABLE;\r\nWREG32(DMA_RB_CNTL, tmp);\r\n}\r\nudelay(50);\r\nevergreen_mc_stop(rdev, &save);\r\nif (evergreen_mc_wait_for_idle(rdev)) {\r\ndev_warn(rdev->dev, "Wait for MC idle timedout !\n");\r\n}\r\nif (reset_mask & (RADEON_RESET_GFX | RADEON_RESET_COMPUTE)) {\r\ngrbm_soft_reset |= SOFT_RESET_DB |\r\nSOFT_RESET_CB |\r\nSOFT_RESET_PA |\r\nSOFT_RESET_SC |\r\nSOFT_RESET_SPI |\r\nSOFT_RESET_SX |\r\nSOFT_RESET_SH |\r\nSOFT_RESET_TC |\r\nSOFT_RESET_TA |\r\nSOFT_RESET_VC |\r\nSOFT_RESET_VGT;\r\n}\r\nif (reset_mask & RADEON_RESET_CP) {\r\ngrbm_soft_reset |= SOFT_RESET_CP |\r\nSOFT_RESET_VGT;\r\nsrbm_soft_reset |= SOFT_RESET_GRBM;\r\n}\r\nif (reset_mask & RADEON_RESET_DMA)\r\nsrbm_soft_reset |= SOFT_RESET_DMA;\r\nif (reset_mask & RADEON_RESET_DISPLAY)\r\nsrbm_soft_reset |= SOFT_RESET_DC;\r\nif (reset_mask & RADEON_RESET_RLC)\r\nsrbm_soft_reset |= SOFT_RESET_RLC;\r\nif (reset_mask & RADEON_RESET_SEM)\r\nsrbm_soft_reset |= SOFT_RESET_SEM;\r\nif (reset_mask & RADEON_RESET_IH)\r\nsrbm_soft_reset |= SOFT_RESET_IH;\r\nif (reset_mask & RADEON_RESET_GRBM)\r\nsrbm_soft_reset |= SOFT_RESET_GRBM;\r\nif (reset_mask & RADEON_RESET_VMC)\r\nsrbm_soft_reset |= SOFT_RESET_VMC;\r\nif (!(rdev->flags & RADEON_IS_IGP)) {\r\nif (reset_mask & RADEON_RESET_MC)\r\nsrbm_soft_reset |= SOFT_RESET_MC;\r\n}\r\nif (grbm_soft_reset) {\r\ntmp = RREG32(GRBM_SOFT_RESET);\r\ntmp |= grbm_soft_reset;\r\ndev_info(rdev->dev, "GRBM_SOFT_RESET=0x%08X\n", tmp);\r\nWREG32(GRBM_SOFT_RESET, tmp);\r\ntmp = RREG32(GRBM_SOFT_RESET);\r\nudelay(50);\r\ntmp &= ~grbm_soft_reset;\r\nWREG32(GRBM_SOFT_RESET, tmp);\r\ntmp = RREG32(GRBM_SOFT_RESET);\r\n}\r\nif (srbm_soft_reset) {\r\ntmp = RREG32(SRBM_SOFT_RESET);\r\ntmp |= srbm_soft_reset;\r\ndev_info(rdev->dev, "SRBM_SOFT_RESET=0x%08X\n", tmp);\r\nWREG32(SRBM_SOFT_RESET, tmp);\r\ntmp = RREG32(SRBM_SOFT_RESET);\r\nudelay(50);\r\ntmp &= ~srbm_soft_reset;\r\nWREG32(SRBM_SOFT_RESET, tmp);\r\ntmp = RREG32(SRBM_SOFT_RESET);\r\n}\r\nudelay(50);\r\nevergreen_mc_resume(rdev, &save);\r\nudelay(50);\r\nevergreen_print_gpu_status_regs(rdev);\r\n}\r\nvoid evergreen_gpu_pci_config_reset(struct radeon_device *rdev)\r\n{\r\nstruct evergreen_mc_save save;\r\nu32 tmp, i;\r\ndev_info(rdev->dev, "GPU pci config reset\n");\r\nWREG32(CP_ME_CNTL, CP_ME_HALT | CP_PFP_HALT);\r\nudelay(50);\r\ntmp = RREG32(DMA_RB_CNTL);\r\ntmp &= ~DMA_RB_ENABLE;\r\nWREG32(DMA_RB_CNTL, tmp);\r\nr600_rlc_stop(rdev);\r\nudelay(50);\r\nrv770_set_clk_bypass_mode(rdev);\r\npci_clear_master(rdev->pdev);\r\nevergreen_mc_stop(rdev, &save);\r\nif (evergreen_mc_wait_for_idle(rdev)) {\r\ndev_warn(rdev->dev, "Wait for MC idle timed out !\n");\r\n}\r\nradeon_pci_config_reset(rdev);\r\nfor (i = 0; i < rdev->usec_timeout; i++) {\r\nif (RREG32(CONFIG_MEMSIZE) != 0xffffffff)\r\nbreak;\r\nudelay(1);\r\n}\r\n}\r\nint evergreen_asic_reset(struct radeon_device *rdev)\r\n{\r\nu32 reset_mask;\r\nreset_mask = evergreen_gpu_check_soft_reset(rdev);\r\nif (reset_mask)\r\nr600_set_bios_scratch_engine_hung(rdev, true);\r\nevergreen_gpu_soft_reset(rdev, reset_mask);\r\nreset_mask = evergreen_gpu_check_soft_reset(rdev);\r\nif (reset_mask && radeon_hard_reset)\r\nevergreen_gpu_pci_config_reset(rdev);\r\nreset_mask = evergreen_gpu_check_soft_reset(rdev);\r\nif (!reset_mask)\r\nr600_set_bios_scratch_engine_hung(rdev, false);\r\nreturn 0;\r\n}\r\nbool evergreen_gfx_is_lockup(struct radeon_device *rdev, struct radeon_ring *ring)\r\n{\r\nu32 reset_mask = evergreen_gpu_check_soft_reset(rdev);\r\nif (!(reset_mask & (RADEON_RESET_GFX |\r\nRADEON_RESET_COMPUTE |\r\nRADEON_RESET_CP))) {\r\nradeon_ring_lockup_update(rdev, ring);\r\nreturn false;\r\n}\r\nreturn radeon_ring_test_lockup(rdev, ring);\r\n}\r\nvoid sumo_rlc_fini(struct radeon_device *rdev)\r\n{\r\nint r;\r\nif (rdev->rlc.save_restore_obj) {\r\nr = radeon_bo_reserve(rdev->rlc.save_restore_obj, false);\r\nif (unlikely(r != 0))\r\ndev_warn(rdev->dev, "(%d) reserve RLC sr bo failed\n", r);\r\nradeon_bo_unpin(rdev->rlc.save_restore_obj);\r\nradeon_bo_unreserve(rdev->rlc.save_restore_obj);\r\nradeon_bo_unref(&rdev->rlc.save_restore_obj);\r\nrdev->rlc.save_restore_obj = NULL;\r\n}\r\nif (rdev->rlc.clear_state_obj) {\r\nr = radeon_bo_reserve(rdev->rlc.clear_state_obj, false);\r\nif (unlikely(r != 0))\r\ndev_warn(rdev->dev, "(%d) reserve RLC c bo failed\n", r);\r\nradeon_bo_unpin(rdev->rlc.clear_state_obj);\r\nradeon_bo_unreserve(rdev->rlc.clear_state_obj);\r\nradeon_bo_unref(&rdev->rlc.clear_state_obj);\r\nrdev->rlc.clear_state_obj = NULL;\r\n}\r\nif (rdev->rlc.cp_table_obj) {\r\nr = radeon_bo_reserve(rdev->rlc.cp_table_obj, false);\r\nif (unlikely(r != 0))\r\ndev_warn(rdev->dev, "(%d) reserve RLC cp table bo failed\n", r);\r\nradeon_bo_unpin(rdev->rlc.cp_table_obj);\r\nradeon_bo_unreserve(rdev->rlc.cp_table_obj);\r\nradeon_bo_unref(&rdev->rlc.cp_table_obj);\r\nrdev->rlc.cp_table_obj = NULL;\r\n}\r\n}\r\nint sumo_rlc_init(struct radeon_device *rdev)\r\n{\r\nconst u32 *src_ptr;\r\nvolatile u32 *dst_ptr;\r\nu32 dws, data, i, j, k, reg_num;\r\nu32 reg_list_num, reg_list_hdr_blk_index, reg_list_blk_index = 0;\r\nu64 reg_list_mc_addr;\r\nconst struct cs_section_def *cs_data;\r\nint r;\r\nsrc_ptr = rdev->rlc.reg_list;\r\ndws = rdev->rlc.reg_list_size;\r\nif (rdev->family >= CHIP_BONAIRE) {\r\ndws += (5 * 16) + 48 + 48 + 64;\r\n}\r\ncs_data = rdev->rlc.cs_data;\r\nif (src_ptr) {\r\nif (rdev->rlc.save_restore_obj == NULL) {\r\nr = radeon_bo_create(rdev, dws * 4, PAGE_SIZE, true,\r\nRADEON_GEM_DOMAIN_VRAM, 0, NULL,\r\nNULL, &rdev->rlc.save_restore_obj);\r\nif (r) {\r\ndev_warn(rdev->dev, "(%d) create RLC sr bo failed\n", r);\r\nreturn r;\r\n}\r\n}\r\nr = radeon_bo_reserve(rdev->rlc.save_restore_obj, false);\r\nif (unlikely(r != 0)) {\r\nsumo_rlc_fini(rdev);\r\nreturn r;\r\n}\r\nr = radeon_bo_pin(rdev->rlc.save_restore_obj, RADEON_GEM_DOMAIN_VRAM,\r\n&rdev->rlc.save_restore_gpu_addr);\r\nif (r) {\r\nradeon_bo_unreserve(rdev->rlc.save_restore_obj);\r\ndev_warn(rdev->dev, "(%d) pin RLC sr bo failed\n", r);\r\nsumo_rlc_fini(rdev);\r\nreturn r;\r\n}\r\nr = radeon_bo_kmap(rdev->rlc.save_restore_obj, (void **)&rdev->rlc.sr_ptr);\r\nif (r) {\r\ndev_warn(rdev->dev, "(%d) map RLC sr bo failed\n", r);\r\nsumo_rlc_fini(rdev);\r\nreturn r;\r\n}\r\ndst_ptr = rdev->rlc.sr_ptr;\r\nif (rdev->family >= CHIP_TAHITI) {\r\nfor (i = 0; i < rdev->rlc.reg_list_size; i++)\r\ndst_ptr[i] = cpu_to_le32(src_ptr[i]);\r\n} else {\r\nfor (i = 0; i < dws; i++) {\r\ndata = src_ptr[i] >> 2;\r\ni++;\r\nif (i < dws)\r\ndata |= (src_ptr[i] >> 2) << 16;\r\nj = (((i - 1) * 3) / 2);\r\ndst_ptr[j] = cpu_to_le32(data);\r\n}\r\nj = ((i * 3) / 2);\r\ndst_ptr[j] = cpu_to_le32(RLC_SAVE_RESTORE_LIST_END_MARKER);\r\n}\r\nradeon_bo_kunmap(rdev->rlc.save_restore_obj);\r\nradeon_bo_unreserve(rdev->rlc.save_restore_obj);\r\n}\r\nif (cs_data) {\r\nif (rdev->family >= CHIP_BONAIRE) {\r\nrdev->rlc.clear_state_size = dws = cik_get_csb_size(rdev);\r\n} else if (rdev->family >= CHIP_TAHITI) {\r\nrdev->rlc.clear_state_size = si_get_csb_size(rdev);\r\ndws = rdev->rlc.clear_state_size + (256 / 4);\r\n} else {\r\nreg_list_num = 0;\r\ndws = 0;\r\nfor (i = 0; cs_data[i].section != NULL; i++) {\r\nfor (j = 0; cs_data[i].section[j].extent != NULL; j++) {\r\nreg_list_num++;\r\ndws += cs_data[i].section[j].reg_count;\r\n}\r\n}\r\nreg_list_blk_index = (3 * reg_list_num + 2);\r\ndws += reg_list_blk_index;\r\nrdev->rlc.clear_state_size = dws;\r\n}\r\nif (rdev->rlc.clear_state_obj == NULL) {\r\nr = radeon_bo_create(rdev, dws * 4, PAGE_SIZE, true,\r\nRADEON_GEM_DOMAIN_VRAM, 0, NULL,\r\nNULL, &rdev->rlc.clear_state_obj);\r\nif (r) {\r\ndev_warn(rdev->dev, "(%d) create RLC c bo failed\n", r);\r\nsumo_rlc_fini(rdev);\r\nreturn r;\r\n}\r\n}\r\nr = radeon_bo_reserve(rdev->rlc.clear_state_obj, false);\r\nif (unlikely(r != 0)) {\r\nsumo_rlc_fini(rdev);\r\nreturn r;\r\n}\r\nr = radeon_bo_pin(rdev->rlc.clear_state_obj, RADEON_GEM_DOMAIN_VRAM,\r\n&rdev->rlc.clear_state_gpu_addr);\r\nif (r) {\r\nradeon_bo_unreserve(rdev->rlc.clear_state_obj);\r\ndev_warn(rdev->dev, "(%d) pin RLC c bo failed\n", r);\r\nsumo_rlc_fini(rdev);\r\nreturn r;\r\n}\r\nr = radeon_bo_kmap(rdev->rlc.clear_state_obj, (void **)&rdev->rlc.cs_ptr);\r\nif (r) {\r\ndev_warn(rdev->dev, "(%d) map RLC c bo failed\n", r);\r\nsumo_rlc_fini(rdev);\r\nreturn r;\r\n}\r\ndst_ptr = rdev->rlc.cs_ptr;\r\nif (rdev->family >= CHIP_BONAIRE) {\r\ncik_get_csb_buffer(rdev, dst_ptr);\r\n} else if (rdev->family >= CHIP_TAHITI) {\r\nreg_list_mc_addr = rdev->rlc.clear_state_gpu_addr + 256;\r\ndst_ptr[0] = cpu_to_le32(upper_32_bits(reg_list_mc_addr));\r\ndst_ptr[1] = cpu_to_le32(lower_32_bits(reg_list_mc_addr));\r\ndst_ptr[2] = cpu_to_le32(rdev->rlc.clear_state_size);\r\nsi_get_csb_buffer(rdev, &dst_ptr[(256/4)]);\r\n} else {\r\nreg_list_hdr_blk_index = 0;\r\nreg_list_mc_addr = rdev->rlc.clear_state_gpu_addr + (reg_list_blk_index * 4);\r\ndata = upper_32_bits(reg_list_mc_addr);\r\ndst_ptr[reg_list_hdr_blk_index] = cpu_to_le32(data);\r\nreg_list_hdr_blk_index++;\r\nfor (i = 0; cs_data[i].section != NULL; i++) {\r\nfor (j = 0; cs_data[i].section[j].extent != NULL; j++) {\r\nreg_num = cs_data[i].section[j].reg_count;\r\ndata = reg_list_mc_addr & 0xffffffff;\r\ndst_ptr[reg_list_hdr_blk_index] = cpu_to_le32(data);\r\nreg_list_hdr_blk_index++;\r\ndata = (cs_data[i].section[j].reg_index * 4) & 0xffffffff;\r\ndst_ptr[reg_list_hdr_blk_index] = cpu_to_le32(data);\r\nreg_list_hdr_blk_index++;\r\ndata = 0x08000000 | (reg_num * 4);\r\ndst_ptr[reg_list_hdr_blk_index] = cpu_to_le32(data);\r\nreg_list_hdr_blk_index++;\r\nfor (k = 0; k < reg_num; k++) {\r\ndata = cs_data[i].section[j].extent[k];\r\ndst_ptr[reg_list_blk_index + k] = cpu_to_le32(data);\r\n}\r\nreg_list_mc_addr += reg_num * 4;\r\nreg_list_blk_index += reg_num;\r\n}\r\n}\r\ndst_ptr[reg_list_hdr_blk_index] = cpu_to_le32(RLC_CLEAR_STATE_END_MARKER);\r\n}\r\nradeon_bo_kunmap(rdev->rlc.clear_state_obj);\r\nradeon_bo_unreserve(rdev->rlc.clear_state_obj);\r\n}\r\nif (rdev->rlc.cp_table_size) {\r\nif (rdev->rlc.cp_table_obj == NULL) {\r\nr = radeon_bo_create(rdev, rdev->rlc.cp_table_size,\r\nPAGE_SIZE, true,\r\nRADEON_GEM_DOMAIN_VRAM, 0, NULL,\r\nNULL, &rdev->rlc.cp_table_obj);\r\nif (r) {\r\ndev_warn(rdev->dev, "(%d) create RLC cp table bo failed\n", r);\r\nsumo_rlc_fini(rdev);\r\nreturn r;\r\n}\r\n}\r\nr = radeon_bo_reserve(rdev->rlc.cp_table_obj, false);\r\nif (unlikely(r != 0)) {\r\ndev_warn(rdev->dev, "(%d) reserve RLC cp table bo failed\n", r);\r\nsumo_rlc_fini(rdev);\r\nreturn r;\r\n}\r\nr = radeon_bo_pin(rdev->rlc.cp_table_obj, RADEON_GEM_DOMAIN_VRAM,\r\n&rdev->rlc.cp_table_gpu_addr);\r\nif (r) {\r\nradeon_bo_unreserve(rdev->rlc.cp_table_obj);\r\ndev_warn(rdev->dev, "(%d) pin RLC cp_table bo failed\n", r);\r\nsumo_rlc_fini(rdev);\r\nreturn r;\r\n}\r\nr = radeon_bo_kmap(rdev->rlc.cp_table_obj, (void **)&rdev->rlc.cp_table_ptr);\r\nif (r) {\r\ndev_warn(rdev->dev, "(%d) map RLC cp table bo failed\n", r);\r\nsumo_rlc_fini(rdev);\r\nreturn r;\r\n}\r\ncik_init_cp_pg_table(rdev);\r\nradeon_bo_kunmap(rdev->rlc.cp_table_obj);\r\nradeon_bo_unreserve(rdev->rlc.cp_table_obj);\r\n}\r\nreturn 0;\r\n}\r\nstatic void evergreen_rlc_start(struct radeon_device *rdev)\r\n{\r\nu32 mask = RLC_ENABLE;\r\nif (rdev->flags & RADEON_IS_IGP) {\r\nmask |= GFX_POWER_GATING_ENABLE | GFX_POWER_GATING_SRC;\r\n}\r\nWREG32(RLC_CNTL, mask);\r\n}\r\nint evergreen_rlc_resume(struct radeon_device *rdev)\r\n{\r\nu32 i;\r\nconst __be32 *fw_data;\r\nif (!rdev->rlc_fw)\r\nreturn -EINVAL;\r\nr600_rlc_stop(rdev);\r\nWREG32(RLC_HB_CNTL, 0);\r\nif (rdev->flags & RADEON_IS_IGP) {\r\nif (rdev->family == CHIP_ARUBA) {\r\nu32 always_on_bitmap =\r\n3 | (3 << (16 * rdev->config.cayman.max_shader_engines));\r\nu32 tmp = (RREG32(CC_GC_SHADER_PIPE_CONFIG) & 0xffff0000) >> 16;\r\ntmp |= 0xffffffff << rdev->config.cayman.max_simds_per_se;\r\ntmp = hweight32(~tmp);\r\nif (tmp == rdev->config.cayman.max_simds_per_se) {\r\nWREG32(TN_RLC_LB_ALWAYS_ACTIVE_SIMD_MASK, always_on_bitmap);\r\nWREG32(TN_RLC_LB_PARAMS, 0x00601004);\r\nWREG32(TN_RLC_LB_INIT_SIMD_MASK, 0xffffffff);\r\nWREG32(TN_RLC_LB_CNTR_INIT, 0x00000000);\r\nWREG32(TN_RLC_LB_CNTR_MAX, 0x00002000);\r\n}\r\n} else {\r\nWREG32(RLC_HB_WPTR_LSB_ADDR, 0);\r\nWREG32(RLC_HB_WPTR_MSB_ADDR, 0);\r\n}\r\nWREG32(TN_RLC_SAVE_AND_RESTORE_BASE, rdev->rlc.save_restore_gpu_addr >> 8);\r\nWREG32(TN_RLC_CLEAR_STATE_RESTORE_BASE, rdev->rlc.clear_state_gpu_addr >> 8);\r\n} else {\r\nWREG32(RLC_HB_BASE, 0);\r\nWREG32(RLC_HB_RPTR, 0);\r\nWREG32(RLC_HB_WPTR, 0);\r\nWREG32(RLC_HB_WPTR_LSB_ADDR, 0);\r\nWREG32(RLC_HB_WPTR_MSB_ADDR, 0);\r\n}\r\nWREG32(RLC_MC_CNTL, 0);\r\nWREG32(RLC_UCODE_CNTL, 0);\r\nfw_data = (const __be32 *)rdev->rlc_fw->data;\r\nif (rdev->family >= CHIP_ARUBA) {\r\nfor (i = 0; i < ARUBA_RLC_UCODE_SIZE; i++) {\r\nWREG32(RLC_UCODE_ADDR, i);\r\nWREG32(RLC_UCODE_DATA, be32_to_cpup(fw_data++));\r\n}\r\n} else if (rdev->family >= CHIP_CAYMAN) {\r\nfor (i = 0; i < CAYMAN_RLC_UCODE_SIZE; i++) {\r\nWREG32(RLC_UCODE_ADDR, i);\r\nWREG32(RLC_UCODE_DATA, be32_to_cpup(fw_data++));\r\n}\r\n} else {\r\nfor (i = 0; i < EVERGREEN_RLC_UCODE_SIZE; i++) {\r\nWREG32(RLC_UCODE_ADDR, i);\r\nWREG32(RLC_UCODE_DATA, be32_to_cpup(fw_data++));\r\n}\r\n}\r\nWREG32(RLC_UCODE_ADDR, 0);\r\nevergreen_rlc_start(rdev);\r\nreturn 0;\r\n}\r\nu32 evergreen_get_vblank_counter(struct radeon_device *rdev, int crtc)\r\n{\r\nif (crtc >= rdev->num_crtc)\r\nreturn 0;\r\nelse\r\nreturn RREG32(CRTC_STATUS_FRAME_COUNT + crtc_offsets[crtc]);\r\n}\r\nvoid evergreen_disable_interrupt_state(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\nif (rdev->family >= CHIP_CAYMAN) {\r\ncayman_cp_int_cntl_setup(rdev, 0,\r\nCNTX_BUSY_INT_ENABLE | CNTX_EMPTY_INT_ENABLE);\r\ncayman_cp_int_cntl_setup(rdev, 1, 0);\r\ncayman_cp_int_cntl_setup(rdev, 2, 0);\r\ntmp = RREG32(CAYMAN_DMA1_CNTL) & ~TRAP_ENABLE;\r\nWREG32(CAYMAN_DMA1_CNTL, tmp);\r\n} else\r\nWREG32(CP_INT_CNTL, CNTX_BUSY_INT_ENABLE | CNTX_EMPTY_INT_ENABLE);\r\ntmp = RREG32(DMA_CNTL) & ~TRAP_ENABLE;\r\nWREG32(DMA_CNTL, tmp);\r\nWREG32(GRBM_INT_CNTL, 0);\r\nWREG32(INT_MASK + EVERGREEN_CRTC0_REGISTER_OFFSET, 0);\r\nWREG32(INT_MASK + EVERGREEN_CRTC1_REGISTER_OFFSET, 0);\r\nif (rdev->num_crtc >= 4) {\r\nWREG32(INT_MASK + EVERGREEN_CRTC2_REGISTER_OFFSET, 0);\r\nWREG32(INT_MASK + EVERGREEN_CRTC3_REGISTER_OFFSET, 0);\r\n}\r\nif (rdev->num_crtc >= 6) {\r\nWREG32(INT_MASK + EVERGREEN_CRTC4_REGISTER_OFFSET, 0);\r\nWREG32(INT_MASK + EVERGREEN_CRTC5_REGISTER_OFFSET, 0);\r\n}\r\nWREG32(GRPH_INT_CONTROL + EVERGREEN_CRTC0_REGISTER_OFFSET, 0);\r\nWREG32(GRPH_INT_CONTROL + EVERGREEN_CRTC1_REGISTER_OFFSET, 0);\r\nif (rdev->num_crtc >= 4) {\r\nWREG32(GRPH_INT_CONTROL + EVERGREEN_CRTC2_REGISTER_OFFSET, 0);\r\nWREG32(GRPH_INT_CONTROL + EVERGREEN_CRTC3_REGISTER_OFFSET, 0);\r\n}\r\nif (rdev->num_crtc >= 6) {\r\nWREG32(GRPH_INT_CONTROL + EVERGREEN_CRTC4_REGISTER_OFFSET, 0);\r\nWREG32(GRPH_INT_CONTROL + EVERGREEN_CRTC5_REGISTER_OFFSET, 0);\r\n}\r\nif (!ASIC_IS_DCE5(rdev))\r\nWREG32(DACA_AUTODETECT_INT_CONTROL, 0);\r\nWREG32(DACB_AUTODETECT_INT_CONTROL, 0);\r\ntmp = RREG32(DC_HPD1_INT_CONTROL) & DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD1_INT_CONTROL, tmp);\r\ntmp = RREG32(DC_HPD2_INT_CONTROL) & DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD2_INT_CONTROL, tmp);\r\ntmp = RREG32(DC_HPD3_INT_CONTROL) & DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD3_INT_CONTROL, tmp);\r\ntmp = RREG32(DC_HPD4_INT_CONTROL) & DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD4_INT_CONTROL, tmp);\r\ntmp = RREG32(DC_HPD5_INT_CONTROL) & DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD5_INT_CONTROL, tmp);\r\ntmp = RREG32(DC_HPD6_INT_CONTROL) & DC_HPDx_INT_POLARITY;\r\nWREG32(DC_HPD6_INT_CONTROL, tmp);\r\n}\r\nint evergreen_irq_set(struct radeon_device *rdev)\r\n{\r\nu32 cp_int_cntl = CNTX_BUSY_INT_ENABLE | CNTX_EMPTY_INT_ENABLE;\r\nu32 cp_int_cntl1 = 0, cp_int_cntl2 = 0;\r\nu32 crtc1 = 0, crtc2 = 0, crtc3 = 0, crtc4 = 0, crtc5 = 0, crtc6 = 0;\r\nu32 hpd1, hpd2, hpd3, hpd4, hpd5, hpd6;\r\nu32 grbm_int_cntl = 0;\r\nu32 afmt1 = 0, afmt2 = 0, afmt3 = 0, afmt4 = 0, afmt5 = 0, afmt6 = 0;\r\nu32 dma_cntl, dma_cntl1 = 0;\r\nu32 thermal_int = 0;\r\nif (!rdev->irq.installed) {\r\nWARN(1, "Can't enable IRQ/MSI because no handler is installed\n");\r\nreturn -EINVAL;\r\n}\r\nif (!rdev->ih.enabled) {\r\nr600_disable_interrupts(rdev);\r\nevergreen_disable_interrupt_state(rdev);\r\nreturn 0;\r\n}\r\nhpd1 = RREG32(DC_HPD1_INT_CONTROL) & ~DC_HPDx_INT_EN;\r\nhpd2 = RREG32(DC_HPD2_INT_CONTROL) & ~DC_HPDx_INT_EN;\r\nhpd3 = RREG32(DC_HPD3_INT_CONTROL) & ~DC_HPDx_INT_EN;\r\nhpd4 = RREG32(DC_HPD4_INT_CONTROL) & ~DC_HPDx_INT_EN;\r\nhpd5 = RREG32(DC_HPD5_INT_CONTROL) & ~DC_HPDx_INT_EN;\r\nhpd6 = RREG32(DC_HPD6_INT_CONTROL) & ~DC_HPDx_INT_EN;\r\nif (rdev->family == CHIP_ARUBA)\r\nthermal_int = RREG32(TN_CG_THERMAL_INT_CTRL) &\r\n~(THERM_INT_MASK_HIGH | THERM_INT_MASK_LOW);\r\nelse\r\nthermal_int = RREG32(CG_THERMAL_INT) &\r\n~(THERM_INT_MASK_HIGH | THERM_INT_MASK_LOW);\r\nafmt1 = RREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC0_REGISTER_OFFSET) & ~AFMT_AZ_FORMAT_WTRIG_MASK;\r\nafmt2 = RREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC1_REGISTER_OFFSET) & ~AFMT_AZ_FORMAT_WTRIG_MASK;\r\nafmt3 = RREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC2_REGISTER_OFFSET) & ~AFMT_AZ_FORMAT_WTRIG_MASK;\r\nafmt4 = RREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC3_REGISTER_OFFSET) & ~AFMT_AZ_FORMAT_WTRIG_MASK;\r\nafmt5 = RREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC4_REGISTER_OFFSET) & ~AFMT_AZ_FORMAT_WTRIG_MASK;\r\nafmt6 = RREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC5_REGISTER_OFFSET) & ~AFMT_AZ_FORMAT_WTRIG_MASK;\r\ndma_cntl = RREG32(DMA_CNTL) & ~TRAP_ENABLE;\r\nif (rdev->family >= CHIP_CAYMAN) {\r\nif (atomic_read(&rdev->irq.ring_int[RADEON_RING_TYPE_GFX_INDEX])) {\r\nDRM_DEBUG("evergreen_irq_set: sw int gfx\n");\r\ncp_int_cntl |= TIME_STAMP_INT_ENABLE;\r\n}\r\nif (atomic_read(&rdev->irq.ring_int[CAYMAN_RING_TYPE_CP1_INDEX])) {\r\nDRM_DEBUG("evergreen_irq_set: sw int cp1\n");\r\ncp_int_cntl1 |= TIME_STAMP_INT_ENABLE;\r\n}\r\nif (atomic_read(&rdev->irq.ring_int[CAYMAN_RING_TYPE_CP2_INDEX])) {\r\nDRM_DEBUG("evergreen_irq_set: sw int cp2\n");\r\ncp_int_cntl2 |= TIME_STAMP_INT_ENABLE;\r\n}\r\n} else {\r\nif (atomic_read(&rdev->irq.ring_int[RADEON_RING_TYPE_GFX_INDEX])) {\r\nDRM_DEBUG("evergreen_irq_set: sw int gfx\n");\r\ncp_int_cntl |= RB_INT_ENABLE;\r\ncp_int_cntl |= TIME_STAMP_INT_ENABLE;\r\n}\r\n}\r\nif (atomic_read(&rdev->irq.ring_int[R600_RING_TYPE_DMA_INDEX])) {\r\nDRM_DEBUG("r600_irq_set: sw int dma\n");\r\ndma_cntl |= TRAP_ENABLE;\r\n}\r\nif (rdev->family >= CHIP_CAYMAN) {\r\ndma_cntl1 = RREG32(CAYMAN_DMA1_CNTL) & ~TRAP_ENABLE;\r\nif (atomic_read(&rdev->irq.ring_int[CAYMAN_RING_TYPE_DMA1_INDEX])) {\r\nDRM_DEBUG("r600_irq_set: sw int dma1\n");\r\ndma_cntl1 |= TRAP_ENABLE;\r\n}\r\n}\r\nif (rdev->irq.dpm_thermal) {\r\nDRM_DEBUG("dpm thermal\n");\r\nthermal_int |= THERM_INT_MASK_HIGH | THERM_INT_MASK_LOW;\r\n}\r\nif (rdev->irq.crtc_vblank_int[0] ||\r\natomic_read(&rdev->irq.pflip[0])) {\r\nDRM_DEBUG("evergreen_irq_set: vblank 0\n");\r\ncrtc1 |= VBLANK_INT_MASK;\r\n}\r\nif (rdev->irq.crtc_vblank_int[1] ||\r\natomic_read(&rdev->irq.pflip[1])) {\r\nDRM_DEBUG("evergreen_irq_set: vblank 1\n");\r\ncrtc2 |= VBLANK_INT_MASK;\r\n}\r\nif (rdev->irq.crtc_vblank_int[2] ||\r\natomic_read(&rdev->irq.pflip[2])) {\r\nDRM_DEBUG("evergreen_irq_set: vblank 2\n");\r\ncrtc3 |= VBLANK_INT_MASK;\r\n}\r\nif (rdev->irq.crtc_vblank_int[3] ||\r\natomic_read(&rdev->irq.pflip[3])) {\r\nDRM_DEBUG("evergreen_irq_set: vblank 3\n");\r\ncrtc4 |= VBLANK_INT_MASK;\r\n}\r\nif (rdev->irq.crtc_vblank_int[4] ||\r\natomic_read(&rdev->irq.pflip[4])) {\r\nDRM_DEBUG("evergreen_irq_set: vblank 4\n");\r\ncrtc5 |= VBLANK_INT_MASK;\r\n}\r\nif (rdev->irq.crtc_vblank_int[5] ||\r\natomic_read(&rdev->irq.pflip[5])) {\r\nDRM_DEBUG("evergreen_irq_set: vblank 5\n");\r\ncrtc6 |= VBLANK_INT_MASK;\r\n}\r\nif (rdev->irq.hpd[0]) {\r\nDRM_DEBUG("evergreen_irq_set: hpd 1\n");\r\nhpd1 |= DC_HPDx_INT_EN;\r\n}\r\nif (rdev->irq.hpd[1]) {\r\nDRM_DEBUG("evergreen_irq_set: hpd 2\n");\r\nhpd2 |= DC_HPDx_INT_EN;\r\n}\r\nif (rdev->irq.hpd[2]) {\r\nDRM_DEBUG("evergreen_irq_set: hpd 3\n");\r\nhpd3 |= DC_HPDx_INT_EN;\r\n}\r\nif (rdev->irq.hpd[3]) {\r\nDRM_DEBUG("evergreen_irq_set: hpd 4\n");\r\nhpd4 |= DC_HPDx_INT_EN;\r\n}\r\nif (rdev->irq.hpd[4]) {\r\nDRM_DEBUG("evergreen_irq_set: hpd 5\n");\r\nhpd5 |= DC_HPDx_INT_EN;\r\n}\r\nif (rdev->irq.hpd[5]) {\r\nDRM_DEBUG("evergreen_irq_set: hpd 6\n");\r\nhpd6 |= DC_HPDx_INT_EN;\r\n}\r\nif (rdev->irq.afmt[0]) {\r\nDRM_DEBUG("evergreen_irq_set: hdmi 0\n");\r\nafmt1 |= AFMT_AZ_FORMAT_WTRIG_MASK;\r\n}\r\nif (rdev->irq.afmt[1]) {\r\nDRM_DEBUG("evergreen_irq_set: hdmi 1\n");\r\nafmt2 |= AFMT_AZ_FORMAT_WTRIG_MASK;\r\n}\r\nif (rdev->irq.afmt[2]) {\r\nDRM_DEBUG("evergreen_irq_set: hdmi 2\n");\r\nafmt3 |= AFMT_AZ_FORMAT_WTRIG_MASK;\r\n}\r\nif (rdev->irq.afmt[3]) {\r\nDRM_DEBUG("evergreen_irq_set: hdmi 3\n");\r\nafmt4 |= AFMT_AZ_FORMAT_WTRIG_MASK;\r\n}\r\nif (rdev->irq.afmt[4]) {\r\nDRM_DEBUG("evergreen_irq_set: hdmi 4\n");\r\nafmt5 |= AFMT_AZ_FORMAT_WTRIG_MASK;\r\n}\r\nif (rdev->irq.afmt[5]) {\r\nDRM_DEBUG("evergreen_irq_set: hdmi 5\n");\r\nafmt6 |= AFMT_AZ_FORMAT_WTRIG_MASK;\r\n}\r\nif (rdev->family >= CHIP_CAYMAN) {\r\ncayman_cp_int_cntl_setup(rdev, 0, cp_int_cntl);\r\ncayman_cp_int_cntl_setup(rdev, 1, cp_int_cntl1);\r\ncayman_cp_int_cntl_setup(rdev, 2, cp_int_cntl2);\r\n} else\r\nWREG32(CP_INT_CNTL, cp_int_cntl);\r\nWREG32(DMA_CNTL, dma_cntl);\r\nif (rdev->family >= CHIP_CAYMAN)\r\nWREG32(CAYMAN_DMA1_CNTL, dma_cntl1);\r\nWREG32(GRBM_INT_CNTL, grbm_int_cntl);\r\nWREG32(INT_MASK + EVERGREEN_CRTC0_REGISTER_OFFSET, crtc1);\r\nWREG32(INT_MASK + EVERGREEN_CRTC1_REGISTER_OFFSET, crtc2);\r\nif (rdev->num_crtc >= 4) {\r\nWREG32(INT_MASK + EVERGREEN_CRTC2_REGISTER_OFFSET, crtc3);\r\nWREG32(INT_MASK + EVERGREEN_CRTC3_REGISTER_OFFSET, crtc4);\r\n}\r\nif (rdev->num_crtc >= 6) {\r\nWREG32(INT_MASK + EVERGREEN_CRTC4_REGISTER_OFFSET, crtc5);\r\nWREG32(INT_MASK + EVERGREEN_CRTC5_REGISTER_OFFSET, crtc6);\r\n}\r\nWREG32(GRPH_INT_CONTROL + EVERGREEN_CRTC0_REGISTER_OFFSET,\r\nGRPH_PFLIP_INT_MASK);\r\nWREG32(GRPH_INT_CONTROL + EVERGREEN_CRTC1_REGISTER_OFFSET,\r\nGRPH_PFLIP_INT_MASK);\r\nif (rdev->num_crtc >= 4) {\r\nWREG32(GRPH_INT_CONTROL + EVERGREEN_CRTC2_REGISTER_OFFSET,\r\nGRPH_PFLIP_INT_MASK);\r\nWREG32(GRPH_INT_CONTROL + EVERGREEN_CRTC3_REGISTER_OFFSET,\r\nGRPH_PFLIP_INT_MASK);\r\n}\r\nif (rdev->num_crtc >= 6) {\r\nWREG32(GRPH_INT_CONTROL + EVERGREEN_CRTC4_REGISTER_OFFSET,\r\nGRPH_PFLIP_INT_MASK);\r\nWREG32(GRPH_INT_CONTROL + EVERGREEN_CRTC5_REGISTER_OFFSET,\r\nGRPH_PFLIP_INT_MASK);\r\n}\r\nWREG32(DC_HPD1_INT_CONTROL, hpd1);\r\nWREG32(DC_HPD2_INT_CONTROL, hpd2);\r\nWREG32(DC_HPD3_INT_CONTROL, hpd3);\r\nWREG32(DC_HPD4_INT_CONTROL, hpd4);\r\nWREG32(DC_HPD5_INT_CONTROL, hpd5);\r\nWREG32(DC_HPD6_INT_CONTROL, hpd6);\r\nif (rdev->family == CHIP_ARUBA)\r\nWREG32(TN_CG_THERMAL_INT_CTRL, thermal_int);\r\nelse\r\nWREG32(CG_THERMAL_INT, thermal_int);\r\nWREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC0_REGISTER_OFFSET, afmt1);\r\nWREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC1_REGISTER_OFFSET, afmt2);\r\nWREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC2_REGISTER_OFFSET, afmt3);\r\nWREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC3_REGISTER_OFFSET, afmt4);\r\nWREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC4_REGISTER_OFFSET, afmt5);\r\nWREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC5_REGISTER_OFFSET, afmt6);\r\nreturn 0;\r\n}\r\nstatic void evergreen_irq_ack(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\nrdev->irq.stat_regs.evergreen.disp_int = RREG32(DISP_INTERRUPT_STATUS);\r\nrdev->irq.stat_regs.evergreen.disp_int_cont = RREG32(DISP_INTERRUPT_STATUS_CONTINUE);\r\nrdev->irq.stat_regs.evergreen.disp_int_cont2 = RREG32(DISP_INTERRUPT_STATUS_CONTINUE2);\r\nrdev->irq.stat_regs.evergreen.disp_int_cont3 = RREG32(DISP_INTERRUPT_STATUS_CONTINUE3);\r\nrdev->irq.stat_regs.evergreen.disp_int_cont4 = RREG32(DISP_INTERRUPT_STATUS_CONTINUE4);\r\nrdev->irq.stat_regs.evergreen.disp_int_cont5 = RREG32(DISP_INTERRUPT_STATUS_CONTINUE5);\r\nrdev->irq.stat_regs.evergreen.d1grph_int = RREG32(GRPH_INT_STATUS + EVERGREEN_CRTC0_REGISTER_OFFSET);\r\nrdev->irq.stat_regs.evergreen.d2grph_int = RREG32(GRPH_INT_STATUS + EVERGREEN_CRTC1_REGISTER_OFFSET);\r\nif (rdev->num_crtc >= 4) {\r\nrdev->irq.stat_regs.evergreen.d3grph_int = RREG32(GRPH_INT_STATUS + EVERGREEN_CRTC2_REGISTER_OFFSET);\r\nrdev->irq.stat_regs.evergreen.d4grph_int = RREG32(GRPH_INT_STATUS + EVERGREEN_CRTC3_REGISTER_OFFSET);\r\n}\r\nif (rdev->num_crtc >= 6) {\r\nrdev->irq.stat_regs.evergreen.d5grph_int = RREG32(GRPH_INT_STATUS + EVERGREEN_CRTC4_REGISTER_OFFSET);\r\nrdev->irq.stat_regs.evergreen.d6grph_int = RREG32(GRPH_INT_STATUS + EVERGREEN_CRTC5_REGISTER_OFFSET);\r\n}\r\nrdev->irq.stat_regs.evergreen.afmt_status1 = RREG32(AFMT_STATUS + EVERGREEN_CRTC0_REGISTER_OFFSET);\r\nrdev->irq.stat_regs.evergreen.afmt_status2 = RREG32(AFMT_STATUS + EVERGREEN_CRTC1_REGISTER_OFFSET);\r\nrdev->irq.stat_regs.evergreen.afmt_status3 = RREG32(AFMT_STATUS + EVERGREEN_CRTC2_REGISTER_OFFSET);\r\nrdev->irq.stat_regs.evergreen.afmt_status4 = RREG32(AFMT_STATUS + EVERGREEN_CRTC3_REGISTER_OFFSET);\r\nrdev->irq.stat_regs.evergreen.afmt_status5 = RREG32(AFMT_STATUS + EVERGREEN_CRTC4_REGISTER_OFFSET);\r\nrdev->irq.stat_regs.evergreen.afmt_status6 = RREG32(AFMT_STATUS + EVERGREEN_CRTC5_REGISTER_OFFSET);\r\nif (rdev->irq.stat_regs.evergreen.d1grph_int & GRPH_PFLIP_INT_OCCURRED)\r\nWREG32(GRPH_INT_STATUS + EVERGREEN_CRTC0_REGISTER_OFFSET, GRPH_PFLIP_INT_CLEAR);\r\nif (rdev->irq.stat_regs.evergreen.d2grph_int & GRPH_PFLIP_INT_OCCURRED)\r\nWREG32(GRPH_INT_STATUS + EVERGREEN_CRTC1_REGISTER_OFFSET, GRPH_PFLIP_INT_CLEAR);\r\nif (rdev->irq.stat_regs.evergreen.disp_int & LB_D1_VBLANK_INTERRUPT)\r\nWREG32(VBLANK_STATUS + EVERGREEN_CRTC0_REGISTER_OFFSET, VBLANK_ACK);\r\nif (rdev->irq.stat_regs.evergreen.disp_int & LB_D1_VLINE_INTERRUPT)\r\nWREG32(VLINE_STATUS + EVERGREEN_CRTC0_REGISTER_OFFSET, VLINE_ACK);\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont & LB_D2_VBLANK_INTERRUPT)\r\nWREG32(VBLANK_STATUS + EVERGREEN_CRTC1_REGISTER_OFFSET, VBLANK_ACK);\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont & LB_D2_VLINE_INTERRUPT)\r\nWREG32(VLINE_STATUS + EVERGREEN_CRTC1_REGISTER_OFFSET, VLINE_ACK);\r\nif (rdev->num_crtc >= 4) {\r\nif (rdev->irq.stat_regs.evergreen.d3grph_int & GRPH_PFLIP_INT_OCCURRED)\r\nWREG32(GRPH_INT_STATUS + EVERGREEN_CRTC2_REGISTER_OFFSET, GRPH_PFLIP_INT_CLEAR);\r\nif (rdev->irq.stat_regs.evergreen.d4grph_int & GRPH_PFLIP_INT_OCCURRED)\r\nWREG32(GRPH_INT_STATUS + EVERGREEN_CRTC3_REGISTER_OFFSET, GRPH_PFLIP_INT_CLEAR);\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont2 & LB_D3_VBLANK_INTERRUPT)\r\nWREG32(VBLANK_STATUS + EVERGREEN_CRTC2_REGISTER_OFFSET, VBLANK_ACK);\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont2 & LB_D3_VLINE_INTERRUPT)\r\nWREG32(VLINE_STATUS + EVERGREEN_CRTC2_REGISTER_OFFSET, VLINE_ACK);\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont3 & LB_D4_VBLANK_INTERRUPT)\r\nWREG32(VBLANK_STATUS + EVERGREEN_CRTC3_REGISTER_OFFSET, VBLANK_ACK);\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont3 & LB_D4_VLINE_INTERRUPT)\r\nWREG32(VLINE_STATUS + EVERGREEN_CRTC3_REGISTER_OFFSET, VLINE_ACK);\r\n}\r\nif (rdev->num_crtc >= 6) {\r\nif (rdev->irq.stat_regs.evergreen.d5grph_int & GRPH_PFLIP_INT_OCCURRED)\r\nWREG32(GRPH_INT_STATUS + EVERGREEN_CRTC4_REGISTER_OFFSET, GRPH_PFLIP_INT_CLEAR);\r\nif (rdev->irq.stat_regs.evergreen.d6grph_int & GRPH_PFLIP_INT_OCCURRED)\r\nWREG32(GRPH_INT_STATUS + EVERGREEN_CRTC5_REGISTER_OFFSET, GRPH_PFLIP_INT_CLEAR);\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont4 & LB_D5_VBLANK_INTERRUPT)\r\nWREG32(VBLANK_STATUS + EVERGREEN_CRTC4_REGISTER_OFFSET, VBLANK_ACK);\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont4 & LB_D5_VLINE_INTERRUPT)\r\nWREG32(VLINE_STATUS + EVERGREEN_CRTC4_REGISTER_OFFSET, VLINE_ACK);\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont5 & LB_D6_VBLANK_INTERRUPT)\r\nWREG32(VBLANK_STATUS + EVERGREEN_CRTC5_REGISTER_OFFSET, VBLANK_ACK);\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont5 & LB_D6_VLINE_INTERRUPT)\r\nWREG32(VLINE_STATUS + EVERGREEN_CRTC5_REGISTER_OFFSET, VLINE_ACK);\r\n}\r\nif (rdev->irq.stat_regs.evergreen.disp_int & DC_HPD1_INTERRUPT) {\r\ntmp = RREG32(DC_HPD1_INT_CONTROL);\r\ntmp |= DC_HPDx_INT_ACK;\r\nWREG32(DC_HPD1_INT_CONTROL, tmp);\r\n}\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont & DC_HPD2_INTERRUPT) {\r\ntmp = RREG32(DC_HPD2_INT_CONTROL);\r\ntmp |= DC_HPDx_INT_ACK;\r\nWREG32(DC_HPD2_INT_CONTROL, tmp);\r\n}\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont2 & DC_HPD3_INTERRUPT) {\r\ntmp = RREG32(DC_HPD3_INT_CONTROL);\r\ntmp |= DC_HPDx_INT_ACK;\r\nWREG32(DC_HPD3_INT_CONTROL, tmp);\r\n}\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont3 & DC_HPD4_INTERRUPT) {\r\ntmp = RREG32(DC_HPD4_INT_CONTROL);\r\ntmp |= DC_HPDx_INT_ACK;\r\nWREG32(DC_HPD4_INT_CONTROL, tmp);\r\n}\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont4 & DC_HPD5_INTERRUPT) {\r\ntmp = RREG32(DC_HPD5_INT_CONTROL);\r\ntmp |= DC_HPDx_INT_ACK;\r\nWREG32(DC_HPD5_INT_CONTROL, tmp);\r\n}\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont5 & DC_HPD6_INTERRUPT) {\r\ntmp = RREG32(DC_HPD5_INT_CONTROL);\r\ntmp |= DC_HPDx_INT_ACK;\r\nWREG32(DC_HPD6_INT_CONTROL, tmp);\r\n}\r\nif (rdev->irq.stat_regs.evergreen.afmt_status1 & AFMT_AZ_FORMAT_WTRIG) {\r\ntmp = RREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC0_REGISTER_OFFSET);\r\ntmp |= AFMT_AZ_FORMAT_WTRIG_ACK;\r\nWREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC0_REGISTER_OFFSET, tmp);\r\n}\r\nif (rdev->irq.stat_regs.evergreen.afmt_status2 & AFMT_AZ_FORMAT_WTRIG) {\r\ntmp = RREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC1_REGISTER_OFFSET);\r\ntmp |= AFMT_AZ_FORMAT_WTRIG_ACK;\r\nWREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC1_REGISTER_OFFSET, tmp);\r\n}\r\nif (rdev->irq.stat_regs.evergreen.afmt_status3 & AFMT_AZ_FORMAT_WTRIG) {\r\ntmp = RREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC2_REGISTER_OFFSET);\r\ntmp |= AFMT_AZ_FORMAT_WTRIG_ACK;\r\nWREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC2_REGISTER_OFFSET, tmp);\r\n}\r\nif (rdev->irq.stat_regs.evergreen.afmt_status4 & AFMT_AZ_FORMAT_WTRIG) {\r\ntmp = RREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC3_REGISTER_OFFSET);\r\ntmp |= AFMT_AZ_FORMAT_WTRIG_ACK;\r\nWREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC3_REGISTER_OFFSET, tmp);\r\n}\r\nif (rdev->irq.stat_regs.evergreen.afmt_status5 & AFMT_AZ_FORMAT_WTRIG) {\r\ntmp = RREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC4_REGISTER_OFFSET);\r\ntmp |= AFMT_AZ_FORMAT_WTRIG_ACK;\r\nWREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC4_REGISTER_OFFSET, tmp);\r\n}\r\nif (rdev->irq.stat_regs.evergreen.afmt_status6 & AFMT_AZ_FORMAT_WTRIG) {\r\ntmp = RREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC5_REGISTER_OFFSET);\r\ntmp |= AFMT_AZ_FORMAT_WTRIG_ACK;\r\nWREG32(AFMT_AUDIO_PACKET_CONTROL + EVERGREEN_CRTC5_REGISTER_OFFSET, tmp);\r\n}\r\n}\r\nstatic void evergreen_irq_disable(struct radeon_device *rdev)\r\n{\r\nr600_disable_interrupts(rdev);\r\nmdelay(1);\r\nevergreen_irq_ack(rdev);\r\nevergreen_disable_interrupt_state(rdev);\r\n}\r\nvoid evergreen_irq_suspend(struct radeon_device *rdev)\r\n{\r\nevergreen_irq_disable(rdev);\r\nr600_rlc_stop(rdev);\r\n}\r\nstatic u32 evergreen_get_ih_wptr(struct radeon_device *rdev)\r\n{\r\nu32 wptr, tmp;\r\nif (rdev->wb.enabled)\r\nwptr = le32_to_cpu(rdev->wb.wb[R600_WB_IH_WPTR_OFFSET/4]);\r\nelse\r\nwptr = RREG32(IH_RB_WPTR);\r\nif (wptr & RB_OVERFLOW) {\r\nwptr &= ~RB_OVERFLOW;\r\ndev_warn(rdev->dev, "IH ring buffer overflow (0x%08X, 0x%08X, 0x%08X)\n",\r\nwptr, rdev->ih.rptr, (wptr + 16) & rdev->ih.ptr_mask);\r\nrdev->ih.rptr = (wptr + 16) & rdev->ih.ptr_mask;\r\ntmp = RREG32(IH_RB_CNTL);\r\ntmp |= IH_WPTR_OVERFLOW_CLEAR;\r\nWREG32(IH_RB_CNTL, tmp);\r\n}\r\nreturn (wptr & rdev->ih.ptr_mask);\r\n}\r\nint evergreen_irq_process(struct radeon_device *rdev)\r\n{\r\nu32 wptr;\r\nu32 rptr;\r\nu32 src_id, src_data;\r\nu32 ring_index;\r\nbool queue_hotplug = false;\r\nbool queue_hdmi = false;\r\nbool queue_thermal = false;\r\nu32 status, addr;\r\nif (!rdev->ih.enabled || rdev->shutdown)\r\nreturn IRQ_NONE;\r\nwptr = evergreen_get_ih_wptr(rdev);\r\nrestart_ih:\r\nif (atomic_xchg(&rdev->ih.lock, 1))\r\nreturn IRQ_NONE;\r\nrptr = rdev->ih.rptr;\r\nDRM_DEBUG("r600_irq_process start: rptr %d, wptr %d\n", rptr, wptr);\r\nrmb();\r\nevergreen_irq_ack(rdev);\r\nwhile (rptr != wptr) {\r\nring_index = rptr / 4;\r\nsrc_id = le32_to_cpu(rdev->ih.ring[ring_index]) & 0xff;\r\nsrc_data = le32_to_cpu(rdev->ih.ring[ring_index + 1]) & 0xfffffff;\r\nswitch (src_id) {\r\ncase 1:\r\nswitch (src_data) {\r\ncase 0:\r\nif (rdev->irq.stat_regs.evergreen.disp_int & LB_D1_VBLANK_INTERRUPT) {\r\nif (rdev->irq.crtc_vblank_int[0]) {\r\ndrm_handle_vblank(rdev->ddev, 0);\r\nrdev->pm.vblank_sync = true;\r\nwake_up(&rdev->irq.vblank_queue);\r\n}\r\nif (atomic_read(&rdev->irq.pflip[0]))\r\nradeon_crtc_handle_vblank(rdev, 0);\r\nrdev->irq.stat_regs.evergreen.disp_int &= ~LB_D1_VBLANK_INTERRUPT;\r\nDRM_DEBUG("IH: D1 vblank\n");\r\n}\r\nbreak;\r\ncase 1:\r\nif (rdev->irq.stat_regs.evergreen.disp_int & LB_D1_VLINE_INTERRUPT) {\r\nrdev->irq.stat_regs.evergreen.disp_int &= ~LB_D1_VLINE_INTERRUPT;\r\nDRM_DEBUG("IH: D1 vline\n");\r\n}\r\nbreak;\r\ndefault:\r\nDRM_DEBUG("Unhandled interrupt: %d %d\n", src_id, src_data);\r\nbreak;\r\n}\r\nbreak;\r\ncase 2:\r\nswitch (src_data) {\r\ncase 0:\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont & LB_D2_VBLANK_INTERRUPT) {\r\nif (rdev->irq.crtc_vblank_int[1]) {\r\ndrm_handle_vblank(rdev->ddev, 1);\r\nrdev->pm.vblank_sync = true;\r\nwake_up(&rdev->irq.vblank_queue);\r\n}\r\nif (atomic_read(&rdev->irq.pflip[1]))\r\nradeon_crtc_handle_vblank(rdev, 1);\r\nrdev->irq.stat_regs.evergreen.disp_int_cont &= ~LB_D2_VBLANK_INTERRUPT;\r\nDRM_DEBUG("IH: D2 vblank\n");\r\n}\r\nbreak;\r\ncase 1:\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont & LB_D2_VLINE_INTERRUPT) {\r\nrdev->irq.stat_regs.evergreen.disp_int_cont &= ~LB_D2_VLINE_INTERRUPT;\r\nDRM_DEBUG("IH: D2 vline\n");\r\n}\r\nbreak;\r\ndefault:\r\nDRM_DEBUG("Unhandled interrupt: %d %d\n", src_id, src_data);\r\nbreak;\r\n}\r\nbreak;\r\ncase 3:\r\nswitch (src_data) {\r\ncase 0:\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont2 & LB_D3_VBLANK_INTERRUPT) {\r\nif (rdev->irq.crtc_vblank_int[2]) {\r\ndrm_handle_vblank(rdev->ddev, 2);\r\nrdev->pm.vblank_sync = true;\r\nwake_up(&rdev->irq.vblank_queue);\r\n}\r\nif (atomic_read(&rdev->irq.pflip[2]))\r\nradeon_crtc_handle_vblank(rdev, 2);\r\nrdev->irq.stat_regs.evergreen.disp_int_cont2 &= ~LB_D3_VBLANK_INTERRUPT;\r\nDRM_DEBUG("IH: D3 vblank\n");\r\n}\r\nbreak;\r\ncase 1:\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont2 & LB_D3_VLINE_INTERRUPT) {\r\nrdev->irq.stat_regs.evergreen.disp_int_cont2 &= ~LB_D3_VLINE_INTERRUPT;\r\nDRM_DEBUG("IH: D3 vline\n");\r\n}\r\nbreak;\r\ndefault:\r\nDRM_DEBUG("Unhandled interrupt: %d %d\n", src_id, src_data);\r\nbreak;\r\n}\r\nbreak;\r\ncase 4:\r\nswitch (src_data) {\r\ncase 0:\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont3 & LB_D4_VBLANK_INTERRUPT) {\r\nif (rdev->irq.crtc_vblank_int[3]) {\r\ndrm_handle_vblank(rdev->ddev, 3);\r\nrdev->pm.vblank_sync = true;\r\nwake_up(&rdev->irq.vblank_queue);\r\n}\r\nif (atomic_read(&rdev->irq.pflip[3]))\r\nradeon_crtc_handle_vblank(rdev, 3);\r\nrdev->irq.stat_regs.evergreen.disp_int_cont3 &= ~LB_D4_VBLANK_INTERRUPT;\r\nDRM_DEBUG("IH: D4 vblank\n");\r\n}\r\nbreak;\r\ncase 1:\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont3 & LB_D4_VLINE_INTERRUPT) {\r\nrdev->irq.stat_regs.evergreen.disp_int_cont3 &= ~LB_D4_VLINE_INTERRUPT;\r\nDRM_DEBUG("IH: D4 vline\n");\r\n}\r\nbreak;\r\ndefault:\r\nDRM_DEBUG("Unhandled interrupt: %d %d\n", src_id, src_data);\r\nbreak;\r\n}\r\nbreak;\r\ncase 5:\r\nswitch (src_data) {\r\ncase 0:\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont4 & LB_D5_VBLANK_INTERRUPT) {\r\nif (rdev->irq.crtc_vblank_int[4]) {\r\ndrm_handle_vblank(rdev->ddev, 4);\r\nrdev->pm.vblank_sync = true;\r\nwake_up(&rdev->irq.vblank_queue);\r\n}\r\nif (atomic_read(&rdev->irq.pflip[4]))\r\nradeon_crtc_handle_vblank(rdev, 4);\r\nrdev->irq.stat_regs.evergreen.disp_int_cont4 &= ~LB_D5_VBLANK_INTERRUPT;\r\nDRM_DEBUG("IH: D5 vblank\n");\r\n}\r\nbreak;\r\ncase 1:\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont4 & LB_D5_VLINE_INTERRUPT) {\r\nrdev->irq.stat_regs.evergreen.disp_int_cont4 &= ~LB_D5_VLINE_INTERRUPT;\r\nDRM_DEBUG("IH: D5 vline\n");\r\n}\r\nbreak;\r\ndefault:\r\nDRM_DEBUG("Unhandled interrupt: %d %d\n", src_id, src_data);\r\nbreak;\r\n}\r\nbreak;\r\ncase 6:\r\nswitch (src_data) {\r\ncase 0:\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont5 & LB_D6_VBLANK_INTERRUPT) {\r\nif (rdev->irq.crtc_vblank_int[5]) {\r\ndrm_handle_vblank(rdev->ddev, 5);\r\nrdev->pm.vblank_sync = true;\r\nwake_up(&rdev->irq.vblank_queue);\r\n}\r\nif (atomic_read(&rdev->irq.pflip[5]))\r\nradeon_crtc_handle_vblank(rdev, 5);\r\nrdev->irq.stat_regs.evergreen.disp_int_cont5 &= ~LB_D6_VBLANK_INTERRUPT;\r\nDRM_DEBUG("IH: D6 vblank\n");\r\n}\r\nbreak;\r\ncase 1:\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont5 & LB_D6_VLINE_INTERRUPT) {\r\nrdev->irq.stat_regs.evergreen.disp_int_cont5 &= ~LB_D6_VLINE_INTERRUPT;\r\nDRM_DEBUG("IH: D6 vline\n");\r\n}\r\nbreak;\r\ndefault:\r\nDRM_DEBUG("Unhandled interrupt: %d %d\n", src_id, src_data);\r\nbreak;\r\n}\r\nbreak;\r\ncase 8:\r\ncase 10:\r\ncase 12:\r\ncase 14:\r\ncase 16:\r\ncase 18:\r\nDRM_DEBUG("IH: D%d flip\n", ((src_id - 8) >> 1) + 1);\r\nif (radeon_use_pflipirq > 0)\r\nradeon_crtc_handle_flip(rdev, (src_id - 8) >> 1);\r\nbreak;\r\ncase 42:\r\nswitch (src_data) {\r\ncase 0:\r\nif (rdev->irq.stat_regs.evergreen.disp_int & DC_HPD1_INTERRUPT) {\r\nrdev->irq.stat_regs.evergreen.disp_int &= ~DC_HPD1_INTERRUPT;\r\nqueue_hotplug = true;\r\nDRM_DEBUG("IH: HPD1\n");\r\n}\r\nbreak;\r\ncase 1:\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont & DC_HPD2_INTERRUPT) {\r\nrdev->irq.stat_regs.evergreen.disp_int_cont &= ~DC_HPD2_INTERRUPT;\r\nqueue_hotplug = true;\r\nDRM_DEBUG("IH: HPD2\n");\r\n}\r\nbreak;\r\ncase 2:\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont2 & DC_HPD3_INTERRUPT) {\r\nrdev->irq.stat_regs.evergreen.disp_int_cont2 &= ~DC_HPD3_INTERRUPT;\r\nqueue_hotplug = true;\r\nDRM_DEBUG("IH: HPD3\n");\r\n}\r\nbreak;\r\ncase 3:\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont3 & DC_HPD4_INTERRUPT) {\r\nrdev->irq.stat_regs.evergreen.disp_int_cont3 &= ~DC_HPD4_INTERRUPT;\r\nqueue_hotplug = true;\r\nDRM_DEBUG("IH: HPD4\n");\r\n}\r\nbreak;\r\ncase 4:\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont4 & DC_HPD5_INTERRUPT) {\r\nrdev->irq.stat_regs.evergreen.disp_int_cont4 &= ~DC_HPD5_INTERRUPT;\r\nqueue_hotplug = true;\r\nDRM_DEBUG("IH: HPD5\n");\r\n}\r\nbreak;\r\ncase 5:\r\nif (rdev->irq.stat_regs.evergreen.disp_int_cont5 & DC_HPD6_INTERRUPT) {\r\nrdev->irq.stat_regs.evergreen.disp_int_cont5 &= ~DC_HPD6_INTERRUPT;\r\nqueue_hotplug = true;\r\nDRM_DEBUG("IH: HPD6\n");\r\n}\r\nbreak;\r\ndefault:\r\nDRM_DEBUG("Unhandled interrupt: %d %d\n", src_id, src_data);\r\nbreak;\r\n}\r\nbreak;\r\ncase 44:\r\nswitch (src_data) {\r\ncase 0:\r\nif (rdev->irq.stat_regs.evergreen.afmt_status1 & AFMT_AZ_FORMAT_WTRIG) {\r\nrdev->irq.stat_regs.evergreen.afmt_status1 &= ~AFMT_AZ_FORMAT_WTRIG;\r\nqueue_hdmi = true;\r\nDRM_DEBUG("IH: HDMI0\n");\r\n}\r\nbreak;\r\ncase 1:\r\nif (rdev->irq.stat_regs.evergreen.afmt_status2 & AFMT_AZ_FORMAT_WTRIG) {\r\nrdev->irq.stat_regs.evergreen.afmt_status2 &= ~AFMT_AZ_FORMAT_WTRIG;\r\nqueue_hdmi = true;\r\nDRM_DEBUG("IH: HDMI1\n");\r\n}\r\nbreak;\r\ncase 2:\r\nif (rdev->irq.stat_regs.evergreen.afmt_status3 & AFMT_AZ_FORMAT_WTRIG) {\r\nrdev->irq.stat_regs.evergreen.afmt_status3 &= ~AFMT_AZ_FORMAT_WTRIG;\r\nqueue_hdmi = true;\r\nDRM_DEBUG("IH: HDMI2\n");\r\n}\r\nbreak;\r\ncase 3:\r\nif (rdev->irq.stat_regs.evergreen.afmt_status4 & AFMT_AZ_FORMAT_WTRIG) {\r\nrdev->irq.stat_regs.evergreen.afmt_status4 &= ~AFMT_AZ_FORMAT_WTRIG;\r\nqueue_hdmi = true;\r\nDRM_DEBUG("IH: HDMI3\n");\r\n}\r\nbreak;\r\ncase 4:\r\nif (rdev->irq.stat_regs.evergreen.afmt_status5 & AFMT_AZ_FORMAT_WTRIG) {\r\nrdev->irq.stat_regs.evergreen.afmt_status5 &= ~AFMT_AZ_FORMAT_WTRIG;\r\nqueue_hdmi = true;\r\nDRM_DEBUG("IH: HDMI4\n");\r\n}\r\nbreak;\r\ncase 5:\r\nif (rdev->irq.stat_regs.evergreen.afmt_status6 & AFMT_AZ_FORMAT_WTRIG) {\r\nrdev->irq.stat_regs.evergreen.afmt_status6 &= ~AFMT_AZ_FORMAT_WTRIG;\r\nqueue_hdmi = true;\r\nDRM_DEBUG("IH: HDMI5\n");\r\n}\r\nbreak;\r\ndefault:\r\nDRM_ERROR("Unhandled interrupt: %d %d\n", src_id, src_data);\r\nbreak;\r\n}\r\ncase 124:\r\nDRM_DEBUG("IH: UVD int: 0x%08x\n", src_data);\r\nradeon_fence_process(rdev, R600_RING_TYPE_UVD_INDEX);\r\nbreak;\r\ncase 146:\r\ncase 147:\r\naddr = RREG32(VM_CONTEXT1_PROTECTION_FAULT_ADDR);\r\nstatus = RREG32(VM_CONTEXT1_PROTECTION_FAULT_STATUS);\r\nWREG32_P(VM_CONTEXT1_CNTL2, 1, ~1);\r\nif (addr == 0x0 && status == 0x0)\r\nbreak;\r\ndev_err(rdev->dev, "GPU fault detected: %d 0x%08x\n", src_id, src_data);\r\ndev_err(rdev->dev, " VM_CONTEXT1_PROTECTION_FAULT_ADDR 0x%08X\n",\r\naddr);\r\ndev_err(rdev->dev, " VM_CONTEXT1_PROTECTION_FAULT_STATUS 0x%08X\n",\r\nstatus);\r\ncayman_vm_decode_fault(rdev, status, addr);\r\nbreak;\r\ncase 176:\r\ncase 177:\r\ncase 178:\r\nDRM_DEBUG("IH: CP int: 0x%08x\n", src_data);\r\nradeon_fence_process(rdev, RADEON_RING_TYPE_GFX_INDEX);\r\nbreak;\r\ncase 181:\r\nDRM_DEBUG("IH: CP EOP\n");\r\nif (rdev->family >= CHIP_CAYMAN) {\r\nswitch (src_data) {\r\ncase 0:\r\nradeon_fence_process(rdev, RADEON_RING_TYPE_GFX_INDEX);\r\nbreak;\r\ncase 1:\r\nradeon_fence_process(rdev, CAYMAN_RING_TYPE_CP1_INDEX);\r\nbreak;\r\ncase 2:\r\nradeon_fence_process(rdev, CAYMAN_RING_TYPE_CP2_INDEX);\r\nbreak;\r\n}\r\n} else\r\nradeon_fence_process(rdev, RADEON_RING_TYPE_GFX_INDEX);\r\nbreak;\r\ncase 224:\r\nDRM_DEBUG("IH: DMA trap\n");\r\nradeon_fence_process(rdev, R600_RING_TYPE_DMA_INDEX);\r\nbreak;\r\ncase 230:\r\nDRM_DEBUG("IH: thermal low to high\n");\r\nrdev->pm.dpm.thermal.high_to_low = false;\r\nqueue_thermal = true;\r\nbreak;\r\ncase 231:\r\nDRM_DEBUG("IH: thermal high to low\n");\r\nrdev->pm.dpm.thermal.high_to_low = true;\r\nqueue_thermal = true;\r\nbreak;\r\ncase 233:\r\nDRM_DEBUG("IH: GUI idle\n");\r\nbreak;\r\ncase 244:\r\nif (rdev->family >= CHIP_CAYMAN) {\r\nDRM_DEBUG("IH: DMA1 trap\n");\r\nradeon_fence_process(rdev, CAYMAN_RING_TYPE_DMA1_INDEX);\r\n}\r\nbreak;\r\ndefault:\r\nDRM_DEBUG("Unhandled interrupt: %d %d\n", src_id, src_data);\r\nbreak;\r\n}\r\nrptr += 16;\r\nrptr &= rdev->ih.ptr_mask;\r\nWREG32(IH_RB_RPTR, rptr);\r\n}\r\nif (queue_hotplug)\r\nschedule_work(&rdev->hotplug_work);\r\nif (queue_hdmi)\r\nschedule_work(&rdev->audio_work);\r\nif (queue_thermal && rdev->pm.dpm_enabled)\r\nschedule_work(&rdev->pm.dpm.thermal.work);\r\nrdev->ih.rptr = rptr;\r\natomic_set(&rdev->ih.lock, 0);\r\nwptr = evergreen_get_ih_wptr(rdev);\r\nif (wptr != rptr)\r\ngoto restart_ih;\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int evergreen_startup(struct radeon_device *rdev)\r\n{\r\nstruct radeon_ring *ring;\r\nint r;\r\nevergreen_pcie_gen2_enable(rdev);\r\nevergreen_program_aspm(rdev);\r\nr = r600_vram_scratch_init(rdev);\r\nif (r)\r\nreturn r;\r\nevergreen_mc_program(rdev);\r\nif (ASIC_IS_DCE5(rdev) && !rdev->pm.dpm_enabled) {\r\nr = ni_mc_load_microcode(rdev);\r\nif (r) {\r\nDRM_ERROR("Failed to load MC firmware!\n");\r\nreturn r;\r\n}\r\n}\r\nif (rdev->flags & RADEON_IS_AGP) {\r\nevergreen_agp_enable(rdev);\r\n} else {\r\nr = evergreen_pcie_gart_enable(rdev);\r\nif (r)\r\nreturn r;\r\n}\r\nevergreen_gpu_init(rdev);\r\nif (rdev->flags & RADEON_IS_IGP) {\r\nrdev->rlc.reg_list = sumo_rlc_save_restore_register_list;\r\nrdev->rlc.reg_list_size =\r\n(u32)ARRAY_SIZE(sumo_rlc_save_restore_register_list);\r\nrdev->rlc.cs_data = evergreen_cs_data;\r\nr = sumo_rlc_init(rdev);\r\nif (r) {\r\nDRM_ERROR("Failed to init rlc BOs!\n");\r\nreturn r;\r\n}\r\n}\r\nr = radeon_wb_init(rdev);\r\nif (r)\r\nreturn r;\r\nr = radeon_fence_driver_start_ring(rdev, RADEON_RING_TYPE_GFX_INDEX);\r\nif (r) {\r\ndev_err(rdev->dev, "failed initializing CP fences (%d).\n", r);\r\nreturn r;\r\n}\r\nr = radeon_fence_driver_start_ring(rdev, R600_RING_TYPE_DMA_INDEX);\r\nif (r) {\r\ndev_err(rdev->dev, "failed initializing DMA fences (%d).\n", r);\r\nreturn r;\r\n}\r\nr = uvd_v2_2_resume(rdev);\r\nif (!r) {\r\nr = radeon_fence_driver_start_ring(rdev,\r\nR600_RING_TYPE_UVD_INDEX);\r\nif (r)\r\ndev_err(rdev->dev, "UVD fences init error (%d).\n", r);\r\n}\r\nif (r)\r\nrdev->ring[R600_RING_TYPE_UVD_INDEX].ring_size = 0;\r\nif (!rdev->irq.installed) {\r\nr = radeon_irq_kms_init(rdev);\r\nif (r)\r\nreturn r;\r\n}\r\nr = r600_irq_init(rdev);\r\nif (r) {\r\nDRM_ERROR("radeon: IH init failed (%d).\n", r);\r\nradeon_irq_kms_fini(rdev);\r\nreturn r;\r\n}\r\nevergreen_irq_set(rdev);\r\nring = &rdev->ring[RADEON_RING_TYPE_GFX_INDEX];\r\nr = radeon_ring_init(rdev, ring, ring->ring_size, RADEON_WB_CP_RPTR_OFFSET,\r\nRADEON_CP_PACKET2);\r\nif (r)\r\nreturn r;\r\nring = &rdev->ring[R600_RING_TYPE_DMA_INDEX];\r\nr = radeon_ring_init(rdev, ring, ring->ring_size, R600_WB_DMA_RPTR_OFFSET,\r\nDMA_PACKET(DMA_PACKET_NOP, 0, 0));\r\nif (r)\r\nreturn r;\r\nr = evergreen_cp_load_microcode(rdev);\r\nif (r)\r\nreturn r;\r\nr = evergreen_cp_resume(rdev);\r\nif (r)\r\nreturn r;\r\nr = r600_dma_resume(rdev);\r\nif (r)\r\nreturn r;\r\nring = &rdev->ring[R600_RING_TYPE_UVD_INDEX];\r\nif (ring->ring_size) {\r\nr = radeon_ring_init(rdev, ring, ring->ring_size, 0,\r\nRADEON_CP_PACKET2);\r\nif (!r)\r\nr = uvd_v1_0_init(rdev);\r\nif (r)\r\nDRM_ERROR("radeon: error initializing UVD (%d).\n", r);\r\n}\r\nr = radeon_ib_pool_init(rdev);\r\nif (r) {\r\ndev_err(rdev->dev, "IB initialization failed (%d).\n", r);\r\nreturn r;\r\n}\r\nr = r600_audio_init(rdev);\r\nif (r) {\r\nDRM_ERROR("radeon: audio init failed\n");\r\nreturn r;\r\n}\r\nreturn 0;\r\n}\r\nint evergreen_resume(struct radeon_device *rdev)\r\n{\r\nint r;\r\nif (radeon_asic_reset(rdev))\r\ndev_warn(rdev->dev, "GPU reset failed !\n");\r\natom_asic_init(rdev->mode_info.atom_context);\r\nevergreen_init_golden_registers(rdev);\r\nif (rdev->pm.pm_method == PM_METHOD_DPM)\r\nradeon_pm_resume(rdev);\r\nrdev->accel_working = true;\r\nr = evergreen_startup(rdev);\r\nif (r) {\r\nDRM_ERROR("evergreen startup failed on resume\n");\r\nrdev->accel_working = false;\r\nreturn r;\r\n}\r\nreturn r;\r\n}\r\nint evergreen_suspend(struct radeon_device *rdev)\r\n{\r\nradeon_pm_suspend(rdev);\r\nr600_audio_fini(rdev);\r\nuvd_v1_0_fini(rdev);\r\nradeon_uvd_suspend(rdev);\r\nr700_cp_stop(rdev);\r\nr600_dma_stop(rdev);\r\nevergreen_irq_suspend(rdev);\r\nradeon_wb_disable(rdev);\r\nevergreen_pcie_gart_disable(rdev);\r\nreturn 0;\r\n}\r\nint evergreen_init(struct radeon_device *rdev)\r\n{\r\nint r;\r\nif (!radeon_get_bios(rdev)) {\r\nif (ASIC_IS_AVIVO(rdev))\r\nreturn -EINVAL;\r\n}\r\nif (!rdev->is_atom_bios) {\r\ndev_err(rdev->dev, "Expecting atombios for evergreen GPU\n");\r\nreturn -EINVAL;\r\n}\r\nr = radeon_atombios_init(rdev);\r\nif (r)\r\nreturn r;\r\nif (radeon_asic_reset(rdev))\r\ndev_warn(rdev->dev, "GPU reset failed !\n");\r\nif (!radeon_card_posted(rdev)) {\r\nif (!rdev->bios) {\r\ndev_err(rdev->dev, "Card not posted and no BIOS - ignoring\n");\r\nreturn -EINVAL;\r\n}\r\nDRM_INFO("GPU not posted. posting now...\n");\r\natom_asic_init(rdev->mode_info.atom_context);\r\n}\r\nevergreen_init_golden_registers(rdev);\r\nr600_scratch_init(rdev);\r\nradeon_surface_init(rdev);\r\nradeon_get_clock_info(rdev->ddev);\r\nr = radeon_fence_driver_init(rdev);\r\nif (r)\r\nreturn r;\r\nif (rdev->flags & RADEON_IS_AGP) {\r\nr = radeon_agp_init(rdev);\r\nif (r)\r\nradeon_agp_disable(rdev);\r\n}\r\nr = evergreen_mc_init(rdev);\r\nif (r)\r\nreturn r;\r\nr = radeon_bo_init(rdev);\r\nif (r)\r\nreturn r;\r\nif (ASIC_IS_DCE5(rdev)) {\r\nif (!rdev->me_fw || !rdev->pfp_fw || !rdev->rlc_fw || !rdev->mc_fw) {\r\nr = ni_init_microcode(rdev);\r\nif (r) {\r\nDRM_ERROR("Failed to load firmware!\n");\r\nreturn r;\r\n}\r\n}\r\n} else {\r\nif (!rdev->me_fw || !rdev->pfp_fw || !rdev->rlc_fw) {\r\nr = r600_init_microcode(rdev);\r\nif (r) {\r\nDRM_ERROR("Failed to load firmware!\n");\r\nreturn r;\r\n}\r\n}\r\n}\r\nradeon_pm_init(rdev);\r\nrdev->ring[RADEON_RING_TYPE_GFX_INDEX].ring_obj = NULL;\r\nr600_ring_init(rdev, &rdev->ring[RADEON_RING_TYPE_GFX_INDEX], 1024 * 1024);\r\nrdev->ring[R600_RING_TYPE_DMA_INDEX].ring_obj = NULL;\r\nr600_ring_init(rdev, &rdev->ring[R600_RING_TYPE_DMA_INDEX], 64 * 1024);\r\nr = radeon_uvd_init(rdev);\r\nif (!r) {\r\nrdev->ring[R600_RING_TYPE_UVD_INDEX].ring_obj = NULL;\r\nr600_ring_init(rdev, &rdev->ring[R600_RING_TYPE_UVD_INDEX],\r\n4096);\r\n}\r\nrdev->ih.ring_obj = NULL;\r\nr600_ih_ring_init(rdev, 64 * 1024);\r\nr = r600_pcie_gart_init(rdev);\r\nif (r)\r\nreturn r;\r\nrdev->accel_working = true;\r\nr = evergreen_startup(rdev);\r\nif (r) {\r\ndev_err(rdev->dev, "disabling GPU acceleration\n");\r\nr700_cp_fini(rdev);\r\nr600_dma_fini(rdev);\r\nr600_irq_fini(rdev);\r\nif (rdev->flags & RADEON_IS_IGP)\r\nsumo_rlc_fini(rdev);\r\nradeon_wb_fini(rdev);\r\nradeon_ib_pool_fini(rdev);\r\nradeon_irq_kms_fini(rdev);\r\nevergreen_pcie_gart_fini(rdev);\r\nrdev->accel_working = false;\r\n}\r\nif (ASIC_IS_DCE5(rdev)) {\r\nif (!rdev->mc_fw && !(rdev->flags & RADEON_IS_IGP)) {\r\nDRM_ERROR("radeon: MC ucode required for NI+.\n");\r\nreturn -EINVAL;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nvoid evergreen_fini(struct radeon_device *rdev)\r\n{\r\nradeon_pm_fini(rdev);\r\nr600_audio_fini(rdev);\r\nr700_cp_fini(rdev);\r\nr600_dma_fini(rdev);\r\nr600_irq_fini(rdev);\r\nif (rdev->flags & RADEON_IS_IGP)\r\nsumo_rlc_fini(rdev);\r\nradeon_wb_fini(rdev);\r\nradeon_ib_pool_fini(rdev);\r\nradeon_irq_kms_fini(rdev);\r\nuvd_v1_0_fini(rdev);\r\nradeon_uvd_fini(rdev);\r\nevergreen_pcie_gart_fini(rdev);\r\nr600_vram_scratch_fini(rdev);\r\nradeon_gem_fini(rdev);\r\nradeon_fence_driver_fini(rdev);\r\nradeon_agp_fini(rdev);\r\nradeon_bo_fini(rdev);\r\nradeon_atombios_fini(rdev);\r\nkfree(rdev->bios);\r\nrdev->bios = NULL;\r\n}\r\nvoid evergreen_pcie_gen2_enable(struct radeon_device *rdev)\r\n{\r\nu32 link_width_cntl, speed_cntl;\r\nif (radeon_pcie_gen2 == 0)\r\nreturn;\r\nif (rdev->flags & RADEON_IS_IGP)\r\nreturn;\r\nif (!(rdev->flags & RADEON_IS_PCIE))\r\nreturn;\r\nif (ASIC_IS_X2(rdev))\r\nreturn;\r\nif ((rdev->pdev->bus->max_bus_speed != PCIE_SPEED_5_0GT) &&\r\n(rdev->pdev->bus->max_bus_speed != PCIE_SPEED_8_0GT))\r\nreturn;\r\nspeed_cntl = RREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL);\r\nif (speed_cntl & LC_CURRENT_DATA_RATE) {\r\nDRM_INFO("PCIE gen 2 link speeds already enabled\n");\r\nreturn;\r\n}\r\nDRM_INFO("enabling PCIE gen 2 link speeds, disable with radeon.pcie_gen2=0\n");\r\nif ((speed_cntl & LC_OTHER_SIDE_EVER_SENT_GEN2) ||\r\n(speed_cntl & LC_OTHER_SIDE_SUPPORTS_GEN2)) {\r\nlink_width_cntl = RREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL);\r\nlink_width_cntl &= ~LC_UPCONFIGURE_DIS;\r\nWREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL, link_width_cntl);\r\nspeed_cntl = RREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL);\r\nspeed_cntl &= ~LC_TARGET_LINK_SPEED_OVERRIDE_EN;\r\nWREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL, speed_cntl);\r\nspeed_cntl = RREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL);\r\nspeed_cntl |= LC_CLR_FAILED_SPD_CHANGE_CNT;\r\nWREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL, speed_cntl);\r\nspeed_cntl = RREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL);\r\nspeed_cntl &= ~LC_CLR_FAILED_SPD_CHANGE_CNT;\r\nWREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL, speed_cntl);\r\nspeed_cntl = RREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL);\r\nspeed_cntl |= LC_GEN2_EN_STRAP;\r\nWREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL, speed_cntl);\r\n} else {\r\nlink_width_cntl = RREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL);\r\nif (1)\r\nlink_width_cntl |= LC_UPCONFIGURE_DIS;\r\nelse\r\nlink_width_cntl &= ~LC_UPCONFIGURE_DIS;\r\nWREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL, link_width_cntl);\r\n}\r\n}\r\nvoid evergreen_program_aspm(struct radeon_device *rdev)\r\n{\r\nu32 data, orig;\r\nu32 pcie_lc_cntl, pcie_lc_cntl_old;\r\nbool disable_l0s, disable_l1 = false, disable_plloff_in_l1 = false;\r\nbool fusion_platform = false;\r\nif (radeon_aspm == 0)\r\nreturn;\r\nif (!(rdev->flags & RADEON_IS_PCIE))\r\nreturn;\r\nswitch (rdev->family) {\r\ncase CHIP_CYPRESS:\r\ncase CHIP_HEMLOCK:\r\ncase CHIP_JUNIPER:\r\ncase CHIP_REDWOOD:\r\ncase CHIP_CEDAR:\r\ncase CHIP_SUMO:\r\ncase CHIP_SUMO2:\r\ncase CHIP_PALM:\r\ncase CHIP_ARUBA:\r\ndisable_l0s = true;\r\nbreak;\r\ndefault:\r\ndisable_l0s = false;\r\nbreak;\r\n}\r\nif (rdev->flags & RADEON_IS_IGP)\r\nfusion_platform = true;\r\ndata = orig = RREG32_PIF_PHY0(PB0_PIF_PAIRING);\r\nif (fusion_platform)\r\ndata &= ~MULTI_PIF;\r\nelse\r\ndata |= MULTI_PIF;\r\nif (data != orig)\r\nWREG32_PIF_PHY0(PB0_PIF_PAIRING, data);\r\ndata = orig = RREG32_PIF_PHY1(PB1_PIF_PAIRING);\r\nif (fusion_platform)\r\ndata &= ~MULTI_PIF;\r\nelse\r\ndata |= MULTI_PIF;\r\nif (data != orig)\r\nWREG32_PIF_PHY1(PB1_PIF_PAIRING, data);\r\npcie_lc_cntl = pcie_lc_cntl_old = RREG32_PCIE_PORT(PCIE_LC_CNTL);\r\npcie_lc_cntl &= ~(LC_L0S_INACTIVITY_MASK | LC_L1_INACTIVITY_MASK);\r\nif (!disable_l0s) {\r\nif (rdev->family >= CHIP_BARTS)\r\npcie_lc_cntl |= LC_L0S_INACTIVITY(7);\r\nelse\r\npcie_lc_cntl |= LC_L0S_INACTIVITY(3);\r\n}\r\nif (!disable_l1) {\r\nif (rdev->family >= CHIP_BARTS)\r\npcie_lc_cntl |= LC_L1_INACTIVITY(7);\r\nelse\r\npcie_lc_cntl |= LC_L1_INACTIVITY(8);\r\nif (!disable_plloff_in_l1) {\r\ndata = orig = RREG32_PIF_PHY0(PB0_PIF_PWRDOWN_0);\r\ndata &= ~(PLL_POWER_STATE_IN_OFF_0_MASK | PLL_POWER_STATE_IN_TXS2_0_MASK);\r\ndata |= PLL_POWER_STATE_IN_OFF_0(7) | PLL_POWER_STATE_IN_TXS2_0(7);\r\nif (data != orig)\r\nWREG32_PIF_PHY0(PB0_PIF_PWRDOWN_0, data);\r\ndata = orig = RREG32_PIF_PHY0(PB0_PIF_PWRDOWN_1);\r\ndata &= ~(PLL_POWER_STATE_IN_OFF_1_MASK | PLL_POWER_STATE_IN_TXS2_1_MASK);\r\ndata |= PLL_POWER_STATE_IN_OFF_1(7) | PLL_POWER_STATE_IN_TXS2_1(7);\r\nif (data != orig)\r\nWREG32_PIF_PHY0(PB0_PIF_PWRDOWN_1, data);\r\ndata = orig = RREG32_PIF_PHY1(PB1_PIF_PWRDOWN_0);\r\ndata &= ~(PLL_POWER_STATE_IN_OFF_0_MASK | PLL_POWER_STATE_IN_TXS2_0_MASK);\r\ndata |= PLL_POWER_STATE_IN_OFF_0(7) | PLL_POWER_STATE_IN_TXS2_0(7);\r\nif (data != orig)\r\nWREG32_PIF_PHY1(PB1_PIF_PWRDOWN_0, data);\r\ndata = orig = RREG32_PIF_PHY1(PB1_PIF_PWRDOWN_1);\r\ndata &= ~(PLL_POWER_STATE_IN_OFF_1_MASK | PLL_POWER_STATE_IN_TXS2_1_MASK);\r\ndata |= PLL_POWER_STATE_IN_OFF_1(7) | PLL_POWER_STATE_IN_TXS2_1(7);\r\nif (data != orig)\r\nWREG32_PIF_PHY1(PB1_PIF_PWRDOWN_1, data);\r\nif (rdev->family >= CHIP_BARTS) {\r\ndata = orig = RREG32_PIF_PHY0(PB0_PIF_PWRDOWN_0);\r\ndata &= ~PLL_RAMP_UP_TIME_0_MASK;\r\ndata |= PLL_RAMP_UP_TIME_0(4);\r\nif (data != orig)\r\nWREG32_PIF_PHY0(PB0_PIF_PWRDOWN_0, data);\r\ndata = orig = RREG32_PIF_PHY0(PB0_PIF_PWRDOWN_1);\r\ndata &= ~PLL_RAMP_UP_TIME_1_MASK;\r\ndata |= PLL_RAMP_UP_TIME_1(4);\r\nif (data != orig)\r\nWREG32_PIF_PHY0(PB0_PIF_PWRDOWN_1, data);\r\ndata = orig = RREG32_PIF_PHY1(PB1_PIF_PWRDOWN_0);\r\ndata &= ~PLL_RAMP_UP_TIME_0_MASK;\r\ndata |= PLL_RAMP_UP_TIME_0(4);\r\nif (data != orig)\r\nWREG32_PIF_PHY1(PB1_PIF_PWRDOWN_0, data);\r\ndata = orig = RREG32_PIF_PHY1(PB1_PIF_PWRDOWN_1);\r\ndata &= ~PLL_RAMP_UP_TIME_1_MASK;\r\ndata |= PLL_RAMP_UP_TIME_1(4);\r\nif (data != orig)\r\nWREG32_PIF_PHY1(PB1_PIF_PWRDOWN_1, data);\r\n}\r\ndata = orig = RREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL);\r\ndata &= ~LC_DYN_LANES_PWR_STATE_MASK;\r\ndata |= LC_DYN_LANES_PWR_STATE(3);\r\nif (data != orig)\r\nWREG32_PCIE_PORT(PCIE_LC_LINK_WIDTH_CNTL, data);\r\nif (rdev->family >= CHIP_BARTS) {\r\ndata = orig = RREG32_PIF_PHY0(PB0_PIF_CNTL);\r\ndata &= ~LS2_EXIT_TIME_MASK;\r\ndata |= LS2_EXIT_TIME(1);\r\nif (data != orig)\r\nWREG32_PIF_PHY0(PB0_PIF_CNTL, data);\r\ndata = orig = RREG32_PIF_PHY1(PB1_PIF_CNTL);\r\ndata &= ~LS2_EXIT_TIME_MASK;\r\ndata |= LS2_EXIT_TIME(1);\r\nif (data != orig)\r\nWREG32_PIF_PHY1(PB1_PIF_CNTL, data);\r\n}\r\n}\r\n}\r\nif (rdev->family < CHIP_BARTS)\r\npcie_lc_cntl |= LC_PMI_TO_L1_DIS;\r\nif (pcie_lc_cntl != pcie_lc_cntl_old)\r\nWREG32_PCIE_PORT(PCIE_LC_CNTL, pcie_lc_cntl);\r\n}
