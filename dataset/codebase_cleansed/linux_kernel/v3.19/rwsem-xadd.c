void __init_rwsem(struct rw_semaphore *sem, const char *name,\r\nstruct lock_class_key *key)\r\n{\r\n#ifdef CONFIG_DEBUG_LOCK_ALLOC\r\ndebug_check_no_locks_freed((void *)sem, sizeof(*sem));\r\nlockdep_init_map(&sem->dep_map, name, key, 0);\r\n#endif\r\nsem->count = RWSEM_UNLOCKED_VALUE;\r\nraw_spin_lock_init(&sem->wait_lock);\r\nINIT_LIST_HEAD(&sem->wait_list);\r\n#ifdef CONFIG_RWSEM_SPIN_ON_OWNER\r\nsem->owner = NULL;\r\nosq_lock_init(&sem->osq);\r\n#endif\r\n}\r\nstatic struct rw_semaphore *\r\n__rwsem_do_wake(struct rw_semaphore *sem, enum rwsem_wake_type wake_type)\r\n{\r\nstruct rwsem_waiter *waiter;\r\nstruct task_struct *tsk;\r\nstruct list_head *next;\r\nlong oldcount, woken, loop, adjustment;\r\nwaiter = list_entry(sem->wait_list.next, struct rwsem_waiter, list);\r\nif (waiter->type == RWSEM_WAITING_FOR_WRITE) {\r\nif (wake_type == RWSEM_WAKE_ANY)\r\nwake_up_process(waiter->task);\r\ngoto out;\r\n}\r\nadjustment = 0;\r\nif (wake_type != RWSEM_WAKE_READ_OWNED) {\r\nadjustment = RWSEM_ACTIVE_READ_BIAS;\r\ntry_reader_grant:\r\noldcount = rwsem_atomic_update(adjustment, sem) - adjustment;\r\nif (unlikely(oldcount < RWSEM_WAITING_BIAS)) {\r\nif (rwsem_atomic_update(-adjustment, sem) &\r\nRWSEM_ACTIVE_MASK)\r\ngoto out;\r\ngoto try_reader_grant;\r\n}\r\n}\r\nwoken = 0;\r\ndo {\r\nwoken++;\r\nif (waiter->list.next == &sem->wait_list)\r\nbreak;\r\nwaiter = list_entry(waiter->list.next,\r\nstruct rwsem_waiter, list);\r\n} while (waiter->type != RWSEM_WAITING_FOR_WRITE);\r\nadjustment = woken * RWSEM_ACTIVE_READ_BIAS - adjustment;\r\nif (waiter->type != RWSEM_WAITING_FOR_WRITE)\r\nadjustment -= RWSEM_WAITING_BIAS;\r\nif (adjustment)\r\nrwsem_atomic_add(adjustment, sem);\r\nnext = sem->wait_list.next;\r\nloop = woken;\r\ndo {\r\nwaiter = list_entry(next, struct rwsem_waiter, list);\r\nnext = waiter->list.next;\r\ntsk = waiter->task;\r\nsmp_mb();\r\nwaiter->task = NULL;\r\nwake_up_process(tsk);\r\nput_task_struct(tsk);\r\n} while (--loop);\r\nsem->wait_list.next = next;\r\nnext->prev = &sem->wait_list;\r\nout:\r\nreturn sem;\r\n}\r\n__visible\r\nstruct rw_semaphore __sched *rwsem_down_read_failed(struct rw_semaphore *sem)\r\n{\r\nlong count, adjustment = -RWSEM_ACTIVE_READ_BIAS;\r\nstruct rwsem_waiter waiter;\r\nstruct task_struct *tsk = current;\r\nwaiter.task = tsk;\r\nwaiter.type = RWSEM_WAITING_FOR_READ;\r\nget_task_struct(tsk);\r\nraw_spin_lock_irq(&sem->wait_lock);\r\nif (list_empty(&sem->wait_list))\r\nadjustment += RWSEM_WAITING_BIAS;\r\nlist_add_tail(&waiter.list, &sem->wait_list);\r\ncount = rwsem_atomic_update(adjustment, sem);\r\nif (count == RWSEM_WAITING_BIAS ||\r\n(count > RWSEM_WAITING_BIAS &&\r\nadjustment != -RWSEM_ACTIVE_READ_BIAS))\r\nsem = __rwsem_do_wake(sem, RWSEM_WAKE_ANY);\r\nraw_spin_unlock_irq(&sem->wait_lock);\r\nwhile (true) {\r\nset_task_state(tsk, TASK_UNINTERRUPTIBLE);\r\nif (!waiter.task)\r\nbreak;\r\nschedule();\r\n}\r\ntsk->state = TASK_RUNNING;\r\nreturn sem;\r\n}\r\nstatic inline bool rwsem_try_write_lock(long count, struct rw_semaphore *sem)\r\n{\r\nif (count == RWSEM_WAITING_BIAS &&\r\ncmpxchg(&sem->count, RWSEM_WAITING_BIAS,\r\nRWSEM_ACTIVE_WRITE_BIAS) == RWSEM_WAITING_BIAS) {\r\nif (!list_is_singular(&sem->wait_list))\r\nrwsem_atomic_update(RWSEM_WAITING_BIAS, sem);\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic inline bool rwsem_try_write_lock_unqueued(struct rw_semaphore *sem)\r\n{\r\nlong old, count = ACCESS_ONCE(sem->count);\r\nwhile (true) {\r\nif (!(count == 0 || count == RWSEM_WAITING_BIAS))\r\nreturn false;\r\nold = cmpxchg(&sem->count, count, count + RWSEM_ACTIVE_WRITE_BIAS);\r\nif (old == count)\r\nreturn true;\r\ncount = old;\r\n}\r\n}\r\nstatic inline bool rwsem_can_spin_on_owner(struct rw_semaphore *sem)\r\n{\r\nstruct task_struct *owner;\r\nbool on_cpu = false;\r\nif (need_resched())\r\nreturn false;\r\nrcu_read_lock();\r\nowner = ACCESS_ONCE(sem->owner);\r\nif (owner)\r\non_cpu = owner->on_cpu;\r\nrcu_read_unlock();\r\nreturn on_cpu;\r\n}\r\nstatic inline bool owner_running(struct rw_semaphore *sem,\r\nstruct task_struct *owner)\r\n{\r\nif (sem->owner != owner)\r\nreturn false;\r\nbarrier();\r\nreturn owner->on_cpu;\r\n}\r\nstatic noinline\r\nbool rwsem_spin_on_owner(struct rw_semaphore *sem, struct task_struct *owner)\r\n{\r\nrcu_read_lock();\r\nwhile (owner_running(sem, owner)) {\r\nif (need_resched())\r\nbreak;\r\ncpu_relax_lowlatency();\r\n}\r\nrcu_read_unlock();\r\nreturn sem->owner == NULL;\r\n}\r\nstatic bool rwsem_optimistic_spin(struct rw_semaphore *sem)\r\n{\r\nstruct task_struct *owner;\r\nbool taken = false;\r\npreempt_disable();\r\nif (!rwsem_can_spin_on_owner(sem))\r\ngoto done;\r\nif (!osq_lock(&sem->osq))\r\ngoto done;\r\nwhile (true) {\r\nowner = ACCESS_ONCE(sem->owner);\r\nif (owner && !rwsem_spin_on_owner(sem, owner))\r\nbreak;\r\nif (rwsem_try_write_lock_unqueued(sem)) {\r\ntaken = true;\r\nbreak;\r\n}\r\nif (!owner && (need_resched() || rt_task(current)))\r\nbreak;\r\ncpu_relax_lowlatency();\r\n}\r\nosq_unlock(&sem->osq);\r\ndone:\r\npreempt_enable();\r\nreturn taken;\r\n}\r\nstatic bool rwsem_optimistic_spin(struct rw_semaphore *sem)\r\n{\r\nreturn false;\r\n}\r\n__visible\r\nstruct rw_semaphore __sched *rwsem_down_write_failed(struct rw_semaphore *sem)\r\n{\r\nlong count;\r\nbool waiting = true;\r\nstruct rwsem_waiter waiter;\r\ncount = rwsem_atomic_update(-RWSEM_ACTIVE_WRITE_BIAS, sem);\r\nif (rwsem_optimistic_spin(sem))\r\nreturn sem;\r\nwaiter.task = current;\r\nwaiter.type = RWSEM_WAITING_FOR_WRITE;\r\nraw_spin_lock_irq(&sem->wait_lock);\r\nif (list_empty(&sem->wait_list))\r\nwaiting = false;\r\nlist_add_tail(&waiter.list, &sem->wait_list);\r\nif (waiting) {\r\ncount = ACCESS_ONCE(sem->count);\r\nif (count > RWSEM_WAITING_BIAS)\r\nsem = __rwsem_do_wake(sem, RWSEM_WAKE_READERS);\r\n} else\r\ncount = rwsem_atomic_update(RWSEM_WAITING_BIAS, sem);\r\nset_current_state(TASK_UNINTERRUPTIBLE);\r\nwhile (true) {\r\nif (rwsem_try_write_lock(count, sem))\r\nbreak;\r\nraw_spin_unlock_irq(&sem->wait_lock);\r\ndo {\r\nschedule();\r\nset_current_state(TASK_UNINTERRUPTIBLE);\r\n} while ((count = sem->count) & RWSEM_ACTIVE_MASK);\r\nraw_spin_lock_irq(&sem->wait_lock);\r\n}\r\n__set_current_state(TASK_RUNNING);\r\nlist_del(&waiter.list);\r\nraw_spin_unlock_irq(&sem->wait_lock);\r\nreturn sem;\r\n}\r\n__visible\r\nstruct rw_semaphore *rwsem_wake(struct rw_semaphore *sem)\r\n{\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&sem->wait_lock, flags);\r\nif (!list_empty(&sem->wait_list))\r\nsem = __rwsem_do_wake(sem, RWSEM_WAKE_ANY);\r\nraw_spin_unlock_irqrestore(&sem->wait_lock, flags);\r\nreturn sem;\r\n}\r\n__visible\r\nstruct rw_semaphore *rwsem_downgrade_wake(struct rw_semaphore *sem)\r\n{\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&sem->wait_lock, flags);\r\nif (!list_empty(&sem->wait_list))\r\nsem = __rwsem_do_wake(sem, RWSEM_WAKE_READ_OWNED);\r\nraw_spin_unlock_irqrestore(&sem->wait_lock, flags);\r\nreturn sem;\r\n}
