void *ccc_key_init(const struct lu_context *ctx, struct lu_context_key *key)\r\n{\r\nstruct ccc_thread_info *info;\r\nOBD_SLAB_ALLOC_PTR_GFP(info, ccc_thread_kmem, GFP_NOFS);\r\nif (info == NULL)\r\ninfo = ERR_PTR(-ENOMEM);\r\nreturn info;\r\n}\r\nvoid ccc_key_fini(const struct lu_context *ctx,\r\nstruct lu_context_key *key, void *data)\r\n{\r\nstruct ccc_thread_info *info = data;\r\nOBD_SLAB_FREE_PTR(info, ccc_thread_kmem);\r\n}\r\nvoid *ccc_session_key_init(const struct lu_context *ctx,\r\nstruct lu_context_key *key)\r\n{\r\nstruct ccc_session *session;\r\nOBD_SLAB_ALLOC_PTR_GFP(session, ccc_session_kmem, GFP_NOFS);\r\nif (session == NULL)\r\nsession = ERR_PTR(-ENOMEM);\r\nreturn session;\r\n}\r\nvoid ccc_session_key_fini(const struct lu_context *ctx,\r\nstruct lu_context_key *key, void *data)\r\n{\r\nstruct ccc_session *session = data;\r\nOBD_SLAB_FREE_PTR(session, ccc_session_kmem);\r\n}\r\nint ccc_device_init(const struct lu_env *env, struct lu_device *d,\r\nconst char *name, struct lu_device *next)\r\n{\r\nstruct ccc_device *vdv;\r\nint rc;\r\nvdv = lu2ccc_dev(d);\r\nvdv->cdv_next = lu2cl_dev(next);\r\nLASSERT(d->ld_site != NULL && next->ld_type != NULL);\r\nnext->ld_site = d->ld_site;\r\nrc = next->ld_type->ldt_ops->ldto_device_init(\r\nenv, next, next->ld_type->ldt_name, NULL);\r\nif (rc == 0) {\r\nlu_device_get(next);\r\nlu_ref_add(&next->ld_reference, "lu-stack", &lu_site_init);\r\n}\r\nreturn rc;\r\n}\r\nstruct lu_device *ccc_device_fini(const struct lu_env *env,\r\nstruct lu_device *d)\r\n{\r\nreturn cl2lu_dev(lu2ccc_dev(d)->cdv_next);\r\n}\r\nstruct lu_device *ccc_device_alloc(const struct lu_env *env,\r\nstruct lu_device_type *t,\r\nstruct lustre_cfg *cfg,\r\nconst struct lu_device_operations *luops,\r\nconst struct cl_device_operations *clops)\r\n{\r\nstruct ccc_device *vdv;\r\nstruct lu_device *lud;\r\nstruct cl_site *site;\r\nint rc;\r\nOBD_ALLOC_PTR(vdv);\r\nif (vdv == NULL)\r\nreturn ERR_PTR(-ENOMEM);\r\nlud = &vdv->cdv_cl.cd_lu_dev;\r\ncl_device_init(&vdv->cdv_cl, t);\r\nccc2lu_dev(vdv)->ld_ops = luops;\r\nvdv->cdv_cl.cd_ops = clops;\r\nOBD_ALLOC_PTR(site);\r\nif (site != NULL) {\r\nrc = cl_site_init(site, &vdv->cdv_cl);\r\nif (rc == 0)\r\nrc = lu_site_init_finish(&site->cs_lu);\r\nelse {\r\nLASSERT(lud->ld_site == NULL);\r\nCERROR("Cannot init lu_site, rc %d.\n", rc);\r\nOBD_FREE_PTR(site);\r\n}\r\n} else\r\nrc = -ENOMEM;\r\nif (rc != 0) {\r\nccc_device_free(env, lud);\r\nlud = ERR_PTR(rc);\r\n}\r\nreturn lud;\r\n}\r\nstruct lu_device *ccc_device_free(const struct lu_env *env,\r\nstruct lu_device *d)\r\n{\r\nstruct ccc_device *vdv = lu2ccc_dev(d);\r\nstruct cl_site *site = lu2cl_site(d->ld_site);\r\nstruct lu_device *next = cl2lu_dev(vdv->cdv_next);\r\nif (d->ld_site != NULL) {\r\ncl_site_fini(site);\r\nOBD_FREE_PTR(site);\r\n}\r\ncl_device_fini(lu2cl_dev(d));\r\nOBD_FREE_PTR(vdv);\r\nreturn next;\r\n}\r\nint ccc_req_init(const struct lu_env *env, struct cl_device *dev,\r\nstruct cl_req *req)\r\n{\r\nstruct ccc_req *vrq;\r\nint result;\r\nOBD_SLAB_ALLOC_PTR_GFP(vrq, ccc_req_kmem, GFP_NOFS);\r\nif (vrq != NULL) {\r\ncl_req_slice_add(req, &vrq->crq_cl, dev, &ccc_req_ops);\r\nresult = 0;\r\n} else\r\nresult = -ENOMEM;\r\nreturn result;\r\n}\r\nint ccc_global_init(struct lu_device_type *device_type)\r\n{\r\nint result;\r\nresult = lu_kmem_init(ccc_caches);\r\nif (result)\r\nreturn result;\r\nresult = lu_device_type_init(device_type);\r\nif (result)\r\ngoto out_kmem;\r\nccc_inode_fini_env = cl_env_alloc(&dummy_refcheck,\r\nLCT_REMEMBER|LCT_NOREF);\r\nif (IS_ERR(ccc_inode_fini_env)) {\r\nresult = PTR_ERR(ccc_inode_fini_env);\r\ngoto out_device;\r\n}\r\nccc_inode_fini_env->le_ctx.lc_cookie = 0x4;\r\nreturn 0;\r\nout_device:\r\nlu_device_type_fini(device_type);\r\nout_kmem:\r\nlu_kmem_fini(ccc_caches);\r\nreturn result;\r\n}\r\nvoid ccc_global_fini(struct lu_device_type *device_type)\r\n{\r\nif (ccc_inode_fini_env != NULL) {\r\ncl_env_put(ccc_inode_fini_env, &dummy_refcheck);\r\nccc_inode_fini_env = NULL;\r\n}\r\nlu_device_type_fini(device_type);\r\nlu_kmem_fini(ccc_caches);\r\n}\r\nstruct lu_object *ccc_object_alloc(const struct lu_env *env,\r\nconst struct lu_object_header *unused,\r\nstruct lu_device *dev,\r\nconst struct cl_object_operations *clops,\r\nconst struct lu_object_operations *luops)\r\n{\r\nstruct ccc_object *vob;\r\nstruct lu_object *obj;\r\nOBD_SLAB_ALLOC_PTR_GFP(vob, ccc_object_kmem, GFP_NOFS);\r\nif (vob != NULL) {\r\nstruct cl_object_header *hdr;\r\nobj = ccc2lu(vob);\r\nhdr = &vob->cob_header;\r\ncl_object_header_init(hdr);\r\nlu_object_init(obj, &hdr->coh_lu, dev);\r\nlu_object_add_top(&hdr->coh_lu, obj);\r\nvob->cob_cl.co_ops = clops;\r\nobj->lo_ops = luops;\r\n} else\r\nobj = NULL;\r\nreturn obj;\r\n}\r\nint ccc_object_init0(const struct lu_env *env,\r\nstruct ccc_object *vob,\r\nconst struct cl_object_conf *conf)\r\n{\r\nvob->cob_inode = conf->coc_inode;\r\nvob->cob_transient_pages = 0;\r\ncl_object_page_init(&vob->cob_cl, sizeof(struct ccc_page));\r\nreturn 0;\r\n}\r\nint ccc_object_init(const struct lu_env *env, struct lu_object *obj,\r\nconst struct lu_object_conf *conf)\r\n{\r\nstruct ccc_device *dev = lu2ccc_dev(obj->lo_dev);\r\nstruct ccc_object *vob = lu2ccc(obj);\r\nstruct lu_object *below;\r\nstruct lu_device *under;\r\nint result;\r\nunder = &dev->cdv_next->cd_lu_dev;\r\nbelow = under->ld_ops->ldo_object_alloc(env, obj->lo_header, under);\r\nif (below != NULL) {\r\nconst struct cl_object_conf *cconf;\r\ncconf = lu2cl_conf(conf);\r\nINIT_LIST_HEAD(&vob->cob_pending_list);\r\nlu_object_add(obj, below);\r\nresult = ccc_object_init0(env, vob, cconf);\r\n} else\r\nresult = -ENOMEM;\r\nreturn result;\r\n}\r\nvoid ccc_object_free(const struct lu_env *env, struct lu_object *obj)\r\n{\r\nstruct ccc_object *vob = lu2ccc(obj);\r\nlu_object_fini(obj);\r\nlu_object_header_fini(obj->lo_header);\r\nOBD_SLAB_FREE_PTR(vob, ccc_object_kmem);\r\n}\r\nint ccc_lock_init(const struct lu_env *env,\r\nstruct cl_object *obj, struct cl_lock *lock,\r\nconst struct cl_io *unused,\r\nconst struct cl_lock_operations *lkops)\r\n{\r\nstruct ccc_lock *clk;\r\nint result;\r\nCLOBINVRNT(env, obj, ccc_object_invariant(obj));\r\nOBD_SLAB_ALLOC_PTR_GFP(clk, ccc_lock_kmem, GFP_NOFS);\r\nif (clk != NULL) {\r\ncl_lock_slice_add(lock, &clk->clk_cl, obj, lkops);\r\nresult = 0;\r\n} else\r\nresult = -ENOMEM;\r\nreturn result;\r\n}\r\nint ccc_attr_set(const struct lu_env *env, struct cl_object *obj,\r\nconst struct cl_attr *attr, unsigned valid)\r\n{\r\nreturn 0;\r\n}\r\nint ccc_object_glimpse(const struct lu_env *env,\r\nconst struct cl_object *obj, struct ost_lvb *lvb)\r\n{\r\nstruct inode *inode = ccc_object_inode(obj);\r\nlvb->lvb_mtime = cl_inode_mtime(inode);\r\nlvb->lvb_atime = cl_inode_atime(inode);\r\nlvb->lvb_ctime = cl_inode_ctime(inode);\r\nif (lvb->lvb_size > 0 && lvb->lvb_blocks == 0)\r\nlvb->lvb_blocks = dirty_cnt(inode);\r\nreturn 0;\r\n}\r\nint ccc_conf_set(const struct lu_env *env, struct cl_object *obj,\r\nconst struct cl_object_conf *conf)\r\n{\r\nreturn 0;\r\n}\r\nstatic void ccc_object_size_lock(struct cl_object *obj)\r\n{\r\nstruct inode *inode = ccc_object_inode(obj);\r\ncl_isize_lock(inode);\r\ncl_object_attr_lock(obj);\r\n}\r\nstatic void ccc_object_size_unlock(struct cl_object *obj)\r\n{\r\nstruct inode *inode = ccc_object_inode(obj);\r\ncl_object_attr_unlock(obj);\r\ncl_isize_unlock(inode);\r\n}\r\nstruct page *ccc_page_vmpage(const struct lu_env *env,\r\nconst struct cl_page_slice *slice)\r\n{\r\nreturn cl2vm_page(slice);\r\n}\r\nint ccc_page_is_under_lock(const struct lu_env *env,\r\nconst struct cl_page_slice *slice,\r\nstruct cl_io *io)\r\n{\r\nstruct ccc_io *cio = ccc_env_io(env);\r\nstruct cl_lock_descr *desc = &ccc_env_info(env)->cti_descr;\r\nstruct cl_page *page = slice->cpl_page;\r\nint result;\r\nif (io->ci_type == CIT_READ || io->ci_type == CIT_WRITE ||\r\nio->ci_type == CIT_FAULT) {\r\nif (cio->cui_fd->fd_flags & LL_FILE_GROUP_LOCKED)\r\nresult = -EBUSY;\r\nelse {\r\ndesc->cld_start = page->cp_index;\r\ndesc->cld_end = page->cp_index;\r\ndesc->cld_obj = page->cp_obj;\r\ndesc->cld_mode = CLM_READ;\r\nresult = cl_queue_match(&io->ci_lockset.cls_done,\r\ndesc) ? -EBUSY : 0;\r\n}\r\n} else\r\nresult = 0;\r\nreturn result;\r\n}\r\nint ccc_fail(const struct lu_env *env, const struct cl_page_slice *slice)\r\n{\r\nLBUG();\r\nreturn 0;\r\n}\r\nvoid ccc_transient_page_verify(const struct cl_page *page)\r\n{\r\n}\r\nint ccc_transient_page_own(const struct lu_env *env,\r\nconst struct cl_page_slice *slice,\r\nstruct cl_io *unused,\r\nint nonblock)\r\n{\r\nccc_transient_page_verify(slice->cpl_page);\r\nreturn 0;\r\n}\r\nvoid ccc_transient_page_assume(const struct lu_env *env,\r\nconst struct cl_page_slice *slice,\r\nstruct cl_io *unused)\r\n{\r\nccc_transient_page_verify(slice->cpl_page);\r\n}\r\nvoid ccc_transient_page_unassume(const struct lu_env *env,\r\nconst struct cl_page_slice *slice,\r\nstruct cl_io *unused)\r\n{\r\nccc_transient_page_verify(slice->cpl_page);\r\n}\r\nvoid ccc_transient_page_disown(const struct lu_env *env,\r\nconst struct cl_page_slice *slice,\r\nstruct cl_io *unused)\r\n{\r\nccc_transient_page_verify(slice->cpl_page);\r\n}\r\nvoid ccc_transient_page_discard(const struct lu_env *env,\r\nconst struct cl_page_slice *slice,\r\nstruct cl_io *unused)\r\n{\r\nstruct cl_page *page = slice->cpl_page;\r\nccc_transient_page_verify(slice->cpl_page);\r\ncl_page_delete(env, page);\r\n}\r\nint ccc_transient_page_prep(const struct lu_env *env,\r\nconst struct cl_page_slice *slice,\r\nstruct cl_io *unused)\r\n{\r\nreturn 0;\r\n}\r\nvoid ccc_lock_delete(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice)\r\n{\r\nCLOBINVRNT(env, slice->cls_obj, ccc_object_invariant(slice->cls_obj));\r\n}\r\nvoid ccc_lock_fini(const struct lu_env *env, struct cl_lock_slice *slice)\r\n{\r\nstruct ccc_lock *clk = cl2ccc_lock(slice);\r\nOBD_SLAB_FREE_PTR(clk, ccc_lock_kmem);\r\n}\r\nint ccc_lock_enqueue(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice,\r\nstruct cl_io *unused, __u32 enqflags)\r\n{\r\nCLOBINVRNT(env, slice->cls_obj, ccc_object_invariant(slice->cls_obj));\r\nreturn 0;\r\n}\r\nint ccc_lock_unuse(const struct lu_env *env, const struct cl_lock_slice *slice)\r\n{\r\nCLOBINVRNT(env, slice->cls_obj, ccc_object_invariant(slice->cls_obj));\r\nreturn 0;\r\n}\r\nint ccc_lock_wait(const struct lu_env *env, const struct cl_lock_slice *slice)\r\n{\r\nCLOBINVRNT(env, slice->cls_obj, ccc_object_invariant(slice->cls_obj));\r\nreturn 0;\r\n}\r\nint ccc_lock_fits_into(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice,\r\nconst struct cl_lock_descr *need,\r\nconst struct cl_io *io)\r\n{\r\nconst struct cl_lock *lock = slice->cls_lock;\r\nconst struct cl_lock_descr *descr = &lock->cll_descr;\r\nconst struct ccc_io *cio = ccc_env_io(env);\r\nint result;\r\nif (cio->cui_glimpse)\r\nresult = descr->cld_mode != CLM_WRITE;\r\nelse if (need->cld_mode != descr->cld_mode)\r\nresult = lock->cll_state >= CLS_ENQUEUED;\r\nelse\r\nresult = 1;\r\nreturn result;\r\n}\r\nvoid ccc_lock_state(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice,\r\nenum cl_lock_state state)\r\n{\r\nstruct cl_lock *lock = slice->cls_lock;\r\nif (state == CLS_HELD && lock->cll_state < CLS_HELD) {\r\nstruct cl_object *obj;\r\nstruct inode *inode;\r\nobj = slice->cls_obj;\r\ninode = ccc_object_inode(obj);\r\nif (lock->cll_descr.cld_start == 0 &&\r\nlock->cll_descr.cld_end == CL_PAGE_EOF)\r\ncl_merge_lvb(env, inode);\r\n}\r\n}\r\nvoid ccc_io_fini(const struct lu_env *env, const struct cl_io_slice *ios)\r\n{\r\nstruct cl_io *io = ios->cis_io;\r\nCLOBINVRNT(env, io->ci_obj, ccc_object_invariant(io->ci_obj));\r\n}\r\nint ccc_io_one_lock_index(const struct lu_env *env, struct cl_io *io,\r\n__u32 enqflags, enum cl_lock_mode mode,\r\npgoff_t start, pgoff_t end)\r\n{\r\nstruct ccc_io *cio = ccc_env_io(env);\r\nstruct cl_lock_descr *descr = &cio->cui_link.cill_descr;\r\nstruct cl_object *obj = io->ci_obj;\r\nCLOBINVRNT(env, obj, ccc_object_invariant(obj));\r\nCDEBUG(D_VFSTRACE, "lock: %d [%lu, %lu]\n", mode, start, end);\r\nmemset(&cio->cui_link, 0, sizeof(cio->cui_link));\r\nif (cio->cui_fd && (cio->cui_fd->fd_flags & LL_FILE_GROUP_LOCKED)) {\r\ndescr->cld_mode = CLM_GROUP;\r\ndescr->cld_gid = cio->cui_fd->fd_grouplock.cg_gid;\r\n} else {\r\ndescr->cld_mode = mode;\r\n}\r\ndescr->cld_obj = obj;\r\ndescr->cld_start = start;\r\ndescr->cld_end = end;\r\ndescr->cld_enq_flags = enqflags;\r\ncl_io_lock_add(env, io, &cio->cui_link);\r\nreturn 0;\r\n}\r\nvoid ccc_io_update_iov(const struct lu_env *env,\r\nstruct ccc_io *cio, struct cl_io *io)\r\n{\r\nsize_t size = io->u.ci_rw.crw_count;\r\nif (!cl_is_normalio(env, io) || cio->cui_iter == NULL)\r\nreturn;\r\niov_iter_truncate(cio->cui_iter, size);\r\n}\r\nint ccc_io_one_lock(const struct lu_env *env, struct cl_io *io,\r\n__u32 enqflags, enum cl_lock_mode mode,\r\nloff_t start, loff_t end)\r\n{\r\nstruct cl_object *obj = io->ci_obj;\r\nreturn ccc_io_one_lock_index(env, io, enqflags, mode,\r\ncl_index(obj, start), cl_index(obj, end));\r\n}\r\nvoid ccc_io_end(const struct lu_env *env, const struct cl_io_slice *ios)\r\n{\r\nCLOBINVRNT(env, ios->cis_io->ci_obj,\r\nccc_object_invariant(ios->cis_io->ci_obj));\r\n}\r\nvoid ccc_io_advance(const struct lu_env *env,\r\nconst struct cl_io_slice *ios,\r\nsize_t nob)\r\n{\r\nstruct ccc_io *cio = cl2ccc_io(env, ios);\r\nstruct cl_io *io = ios->cis_io;\r\nstruct cl_object *obj = ios->cis_io->ci_obj;\r\nCLOBINVRNT(env, obj, ccc_object_invariant(obj));\r\nif (!cl_is_normalio(env, io))\r\nreturn;\r\niov_iter_reexpand(cio->cui_iter, cio->cui_tot_count -= nob);\r\n}\r\nint ccc_prep_size(const struct lu_env *env, struct cl_object *obj,\r\nstruct cl_io *io, loff_t start, size_t count, int *exceed)\r\n{\r\nstruct cl_attr *attr = ccc_env_thread_attr(env);\r\nstruct inode *inode = ccc_object_inode(obj);\r\nloff_t pos = start + count - 1;\r\nloff_t kms;\r\nint result;\r\nccc_object_size_lock(obj);\r\nresult = cl_object_attr_get(env, obj, attr);\r\nif (result == 0) {\r\nkms = attr->cat_kms;\r\nif (pos > kms) {\r\nccc_object_size_unlock(obj);\r\nresult = cl_glimpse_lock(env, io, inode, obj, 0);\r\nif (result == 0 && exceed != NULL) {\r\nloff_t size = cl_isize_read(inode);\r\nloff_t cur_index = start >> PAGE_CACHE_SHIFT;\r\nloff_t size_index = ((size - 1) >> PAGE_CACHE_SHIFT);\r\nif ((size == 0 && cur_index != 0) ||\r\nsize_index < cur_index)\r\n*exceed = 1;\r\n}\r\nreturn result;\r\n} else {\r\nif (cl_isize_read(inode) < kms) {\r\ncl_isize_write_nolock(inode, kms);\r\nCDEBUG(D_VFSTRACE,\r\nDFID" updating i_size %llu\n",\r\nPFID(lu_object_fid(&obj->co_lu)),\r\n(__u64)cl_isize_read(inode));\r\n}\r\n}\r\n}\r\nccc_object_size_unlock(obj);\r\nreturn result;\r\n}\r\nvoid ccc_req_completion(const struct lu_env *env,\r\nconst struct cl_req_slice *slice, int ioret)\r\n{\r\nstruct ccc_req *vrq;\r\nif (ioret > 0)\r\ncl_stats_tally(slice->crs_dev, slice->crs_req->crq_type, ioret);\r\nvrq = cl2ccc_req(slice);\r\nOBD_SLAB_FREE_PTR(vrq, ccc_req_kmem);\r\n}\r\nvoid ccc_req_attr_set(const struct lu_env *env,\r\nconst struct cl_req_slice *slice,\r\nconst struct cl_object *obj,\r\nstruct cl_req_attr *attr, u64 flags)\r\n{\r\nstruct inode *inode;\r\nstruct obdo *oa;\r\nu32 valid_flags;\r\noa = attr->cra_oa;\r\ninode = ccc_object_inode(obj);\r\nvalid_flags = OBD_MD_FLTYPE;\r\nif ((flags & OBD_MD_FLOSSCAPA) != 0) {\r\nLASSERT(attr->cra_capa == NULL);\r\nattr->cra_capa = cl_capa_lookup(inode,\r\nslice->crs_req->crq_type);\r\n}\r\nif (slice->crs_req->crq_type == CRT_WRITE) {\r\nif (flags & OBD_MD_FLEPOCH) {\r\noa->o_valid |= OBD_MD_FLEPOCH;\r\noa->o_ioepoch = cl_i2info(inode)->lli_ioepoch;\r\nvalid_flags |= OBD_MD_FLMTIME | OBD_MD_FLCTIME |\r\nOBD_MD_FLUID | OBD_MD_FLGID;\r\n}\r\n}\r\nobdo_from_inode(oa, inode, valid_flags & flags);\r\nobdo_set_parent_fid(oa, &cl_i2info(inode)->lli_fid);\r\nmemcpy(attr->cra_jobid, cl_i2info(inode)->lli_jobid,\r\nJOBSTATS_JOBID_SIZE);\r\n}\r\nint cl_setattr_ost(struct inode *inode, const struct iattr *attr,\r\nstruct obd_capa *capa)\r\n{\r\nstruct lu_env *env;\r\nstruct cl_io *io;\r\nint result;\r\nint refcheck;\r\nenv = cl_env_get(&refcheck);\r\nif (IS_ERR(env))\r\nreturn PTR_ERR(env);\r\nio = ccc_env_thread_io(env);\r\nio->ci_obj = cl_i2info(inode)->lli_clob;\r\nio->u.ci_setattr.sa_attr.lvb_atime = LTIME_S(attr->ia_atime);\r\nio->u.ci_setattr.sa_attr.lvb_mtime = LTIME_S(attr->ia_mtime);\r\nio->u.ci_setattr.sa_attr.lvb_ctime = LTIME_S(attr->ia_ctime);\r\nio->u.ci_setattr.sa_attr.lvb_size = attr->ia_size;\r\nio->u.ci_setattr.sa_valid = attr->ia_valid;\r\nio->u.ci_setattr.sa_capa = capa;\r\nagain:\r\nif (cl_io_init(env, io, CIT_SETATTR, io->ci_obj) == 0) {\r\nstruct ccc_io *cio = ccc_env_io(env);\r\nif (attr->ia_valid & ATTR_FILE)\r\ncio->cui_fd = cl_iattr2fd(inode, attr);\r\nresult = cl_io_loop(env, io);\r\n} else {\r\nresult = io->ci_result;\r\n}\r\ncl_io_fini(env, io);\r\nif (unlikely(io->ci_need_restart))\r\ngoto again;\r\nif (result == -ENODATA && io->ci_restore_needed &&\r\nio->ci_result != -ENODATA)\r\nresult = 0;\r\ncl_env_put(env, &refcheck);\r\nreturn result;\r\n}\r\nstruct lu_device *ccc2lu_dev(struct ccc_device *vdv)\r\n{\r\nreturn &vdv->cdv_cl.cd_lu_dev;\r\n}\r\nstruct ccc_device *lu2ccc_dev(const struct lu_device *d)\r\n{\r\nreturn container_of0(d, struct ccc_device, cdv_cl.cd_lu_dev);\r\n}\r\nstruct ccc_device *cl2ccc_dev(const struct cl_device *d)\r\n{\r\nreturn container_of0(d, struct ccc_device, cdv_cl);\r\n}\r\nstruct lu_object *ccc2lu(struct ccc_object *vob)\r\n{\r\nreturn &vob->cob_cl.co_lu;\r\n}\r\nstruct ccc_object *lu2ccc(const struct lu_object *obj)\r\n{\r\nreturn container_of0(obj, struct ccc_object, cob_cl.co_lu);\r\n}\r\nstruct ccc_object *cl2ccc(const struct cl_object *obj)\r\n{\r\nreturn container_of0(obj, struct ccc_object, cob_cl);\r\n}\r\nstruct ccc_lock *cl2ccc_lock(const struct cl_lock_slice *slice)\r\n{\r\nreturn container_of(slice, struct ccc_lock, clk_cl);\r\n}\r\nstruct ccc_io *cl2ccc_io(const struct lu_env *env,\r\nconst struct cl_io_slice *slice)\r\n{\r\nstruct ccc_io *cio;\r\ncio = container_of(slice, struct ccc_io, cui_cl);\r\nLASSERT(cio == ccc_env_io(env));\r\nreturn cio;\r\n}\r\nstruct ccc_req *cl2ccc_req(const struct cl_req_slice *slice)\r\n{\r\nreturn container_of0(slice, struct ccc_req, crq_cl);\r\n}\r\nstruct page *cl2vm_page(const struct cl_page_slice *slice)\r\n{\r\nreturn cl2ccc_page(slice)->cpg_page;\r\n}\r\nint ccc_object_invariant(const struct cl_object *obj)\r\n{\r\nstruct inode *inode = ccc_object_inode(obj);\r\nstruct cl_inode_info *lli = cl_i2info(inode);\r\nreturn (S_ISREG(cl_inode_mode(inode)) ||\r\ncl_inode_mode(inode) == 0) && lli->lli_clob == obj;\r\n}\r\nstruct inode *ccc_object_inode(const struct cl_object *obj)\r\n{\r\nreturn cl2ccc(obj)->cob_inode;\r\n}\r\nstruct cl_page *ccc_vmpage_page_transient(struct page *vmpage)\r\n{\r\nKLASSERT(PageLocked(vmpage));\r\nreturn (struct cl_page *)vmpage->private;\r\n}\r\nint cl_file_inode_init(struct inode *inode, struct lustre_md *md)\r\n{\r\nstruct lu_env *env;\r\nstruct cl_inode_info *lli;\r\nstruct cl_object *clob;\r\nstruct lu_site *site;\r\nstruct lu_fid *fid;\r\nstruct cl_object_conf conf = {\r\n.coc_inode = inode,\r\n.u = {\r\n.coc_md = md\r\n}\r\n};\r\nint result = 0;\r\nint refcheck;\r\nLASSERT(md->body->valid & OBD_MD_FLID);\r\nLASSERT(S_ISREG(cl_inode_mode(inode)));\r\nenv = cl_env_get(&refcheck);\r\nif (IS_ERR(env))\r\nreturn PTR_ERR(env);\r\nsite = cl_i2sbi(inode)->ll_site;\r\nlli = cl_i2info(inode);\r\nfid = &lli->lli_fid;\r\nLASSERT(fid_is_sane(fid));\r\nif (lli->lli_clob == NULL) {\r\nLASSERT(inode->i_state & I_NEW);\r\nconf.coc_lu.loc_flags = LOC_F_NEW;\r\nclob = cl_object_find(env, lu2cl_dev(site->ls_top_dev),\r\nfid, &conf);\r\nif (!IS_ERR(clob)) {\r\nlli->lli_clob = clob;\r\nlli->lli_has_smd = lsm_has_objects(md->lsm);\r\nlu_object_ref_add(&clob->co_lu, "inode", inode);\r\n} else\r\nresult = PTR_ERR(clob);\r\n} else {\r\nresult = cl_conf_set(env, lli->lli_clob, &conf);\r\n}\r\ncl_env_put(env, &refcheck);\r\nif (result != 0)\r\nCERROR("Failure to initialize cl object "DFID": %d\n",\r\nPFID(fid), result);\r\nreturn result;\r\n}\r\nstatic void cl_object_put_last(struct lu_env *env, struct cl_object *obj)\r\n{\r\nstruct lu_object_header *header = obj->co_lu.lo_header;\r\nwait_queue_t waiter;\r\nif (unlikely(atomic_read(&header->loh_ref) != 1)) {\r\nstruct lu_site *site = obj->co_lu.lo_dev->ld_site;\r\nstruct lu_site_bkt_data *bkt;\r\nbkt = lu_site_bkt_from_fid(site, &header->loh_fid);\r\ninit_waitqueue_entry(&waiter, current);\r\nadd_wait_queue(&bkt->lsb_marche_funebre, &waiter);\r\nwhile (1) {\r\nset_current_state(TASK_UNINTERRUPTIBLE);\r\nif (atomic_read(&header->loh_ref) == 1)\r\nbreak;\r\nschedule();\r\n}\r\nset_current_state(TASK_RUNNING);\r\nremove_wait_queue(&bkt->lsb_marche_funebre, &waiter);\r\n}\r\ncl_object_put(env, obj);\r\n}\r\nvoid cl_inode_fini(struct inode *inode)\r\n{\r\nstruct lu_env *env;\r\nstruct cl_inode_info *lli = cl_i2info(inode);\r\nstruct cl_object *clob = lli->lli_clob;\r\nint refcheck;\r\nint emergency;\r\nif (clob != NULL) {\r\nvoid *cookie;\r\ncookie = cl_env_reenter();\r\nenv = cl_env_get(&refcheck);\r\nemergency = IS_ERR(env);\r\nif (emergency) {\r\nmutex_lock(&ccc_inode_fini_guard);\r\nLASSERT(ccc_inode_fini_env != NULL);\r\ncl_env_implant(ccc_inode_fini_env, &refcheck);\r\nenv = ccc_inode_fini_env;\r\n}\r\ncl_object_kill(env, clob);\r\nlu_object_ref_del(&clob->co_lu, "inode", inode);\r\ncl_object_put_last(env, clob);\r\nlli->lli_clob = NULL;\r\nif (emergency) {\r\ncl_env_unplant(ccc_inode_fini_env, &refcheck);\r\nmutex_unlock(&ccc_inode_fini_guard);\r\n} else\r\ncl_env_put(env, &refcheck);\r\ncl_env_reexit(cookie);\r\n}\r\n}\r\n__u16 ll_dirent_type_get(struct lu_dirent *ent)\r\n{\r\n__u16 type = 0;\r\nstruct luda_type *lt;\r\nint len = 0;\r\nif (le32_to_cpu(ent->lde_attrs) & LUDA_TYPE) {\r\nconst unsigned align = sizeof(struct luda_type) - 1;\r\nlen = le16_to_cpu(ent->lde_namelen);\r\nlen = (len + align) & ~align;\r\nlt = (void *)ent->lde_name + len;\r\ntype = IFTODT(le16_to_cpu(lt->lt_type));\r\n}\r\nreturn type;\r\n}\r\n__u64 cl_fid_build_ino(const struct lu_fid *fid, int api32)\r\n{\r\nif (BITS_PER_LONG == 32 || api32)\r\nreturn fid_flatten32(fid);\r\nelse\r\nreturn fid_flatten(fid);\r\n}\r\n__u32 cl_fid_build_gen(const struct lu_fid *fid)\r\n{\r\n__u32 gen;\r\nif (fid_is_igif(fid)) {\r\ngen = lu_igif_gen(fid);\r\nreturn gen;\r\n}\r\ngen = (fid_flatten(fid) >> 32);\r\nreturn gen;\r\n}\r\nstruct lov_stripe_md *ccc_inode_lsm_get(struct inode *inode)\r\n{\r\nreturn lov_lsm_get(cl_i2info(inode)->lli_clob);\r\n}\r\ninline void ccc_inode_lsm_put(struct inode *inode, struct lov_stripe_md *lsm)\r\n{\r\nlov_lsm_put(cl_i2info(inode)->lli_clob, lsm);\r\n}
