static unsigned long vb2_dc_get_contiguous_size(struct sg_table *sgt)\r\n{\r\nstruct scatterlist *s;\r\ndma_addr_t expected = sg_dma_address(sgt->sgl);\r\nunsigned int i;\r\nunsigned long size = 0;\r\nfor_each_sg(sgt->sgl, s, sgt->nents, i) {\r\nif (sg_dma_address(s) != expected)\r\nbreak;\r\nexpected = sg_dma_address(s) + sg_dma_len(s);\r\nsize += sg_dma_len(s);\r\n}\r\nreturn size;\r\n}\r\nstatic void *vb2_dc_cookie(void *buf_priv)\r\n{\r\nstruct vb2_dc_buf *buf = buf_priv;\r\nreturn &buf->dma_addr;\r\n}\r\nstatic void *vb2_dc_vaddr(void *buf_priv)\r\n{\r\nstruct vb2_dc_buf *buf = buf_priv;\r\nif (!buf->vaddr && buf->db_attach)\r\nbuf->vaddr = dma_buf_vmap(buf->db_attach->dmabuf);\r\nreturn buf->vaddr;\r\n}\r\nstatic unsigned int vb2_dc_num_users(void *buf_priv)\r\n{\r\nstruct vb2_dc_buf *buf = buf_priv;\r\nreturn atomic_read(&buf->refcount);\r\n}\r\nstatic void vb2_dc_prepare(void *buf_priv)\r\n{\r\nstruct vb2_dc_buf *buf = buf_priv;\r\nstruct sg_table *sgt = buf->dma_sgt;\r\nif (!sgt || buf->db_attach)\r\nreturn;\r\ndma_sync_sg_for_device(buf->dev, sgt->sgl, sgt->orig_nents,\r\nbuf->dma_dir);\r\n}\r\nstatic void vb2_dc_finish(void *buf_priv)\r\n{\r\nstruct vb2_dc_buf *buf = buf_priv;\r\nstruct sg_table *sgt = buf->dma_sgt;\r\nif (!sgt || buf->db_attach)\r\nreturn;\r\ndma_sync_sg_for_cpu(buf->dev, sgt->sgl, sgt->orig_nents, buf->dma_dir);\r\n}\r\nstatic void vb2_dc_put(void *buf_priv)\r\n{\r\nstruct vb2_dc_buf *buf = buf_priv;\r\nif (!atomic_dec_and_test(&buf->refcount))\r\nreturn;\r\nif (buf->sgt_base) {\r\nsg_free_table(buf->sgt_base);\r\nkfree(buf->sgt_base);\r\n}\r\ndma_free_attrs(buf->dev, buf->size, buf->cookie, buf->dma_addr,\r\n&buf->attrs);\r\nput_device(buf->dev);\r\nkfree(buf);\r\n}\r\nstatic void *vb2_dc_alloc(void *alloc_ctx, unsigned long size,\r\nenum dma_data_direction dma_dir, gfp_t gfp_flags)\r\n{\r\nstruct vb2_dc_conf *conf = alloc_ctx;\r\nstruct device *dev = conf->dev;\r\nstruct vb2_dc_buf *buf;\r\nbuf = kzalloc(sizeof *buf, GFP_KERNEL);\r\nif (!buf)\r\nreturn ERR_PTR(-ENOMEM);\r\nbuf->attrs = conf->attrs;\r\nbuf->cookie = dma_alloc_attrs(dev, size, &buf->dma_addr,\r\nGFP_KERNEL | gfp_flags, &buf->attrs);\r\nif (!buf->cookie) {\r\ndev_err(dev, "dma_alloc_coherent of size %ld failed\n", size);\r\nkfree(buf);\r\nreturn ERR_PTR(-ENOMEM);\r\n}\r\nif (!dma_get_attr(DMA_ATTR_NO_KERNEL_MAPPING, &buf->attrs))\r\nbuf->vaddr = buf->cookie;\r\nbuf->dev = get_device(dev);\r\nbuf->size = size;\r\nbuf->dma_dir = dma_dir;\r\nbuf->handler.refcount = &buf->refcount;\r\nbuf->handler.put = vb2_dc_put;\r\nbuf->handler.arg = buf;\r\natomic_inc(&buf->refcount);\r\nreturn buf;\r\n}\r\nstatic int vb2_dc_mmap(void *buf_priv, struct vm_area_struct *vma)\r\n{\r\nstruct vb2_dc_buf *buf = buf_priv;\r\nint ret;\r\nif (!buf) {\r\nprintk(KERN_ERR "No buffer to map\n");\r\nreturn -EINVAL;\r\n}\r\nvma->vm_pgoff = 0;\r\nret = dma_mmap_attrs(buf->dev, vma, buf->cookie,\r\nbuf->dma_addr, buf->size, &buf->attrs);\r\nif (ret) {\r\npr_err("Remapping memory failed, error: %d\n", ret);\r\nreturn ret;\r\n}\r\nvma->vm_flags |= VM_DONTEXPAND | VM_DONTDUMP;\r\nvma->vm_private_data = &buf->handler;\r\nvma->vm_ops = &vb2_common_vm_ops;\r\nvma->vm_ops->open(vma);\r\npr_debug("%s: mapped dma addr 0x%08lx at 0x%08lx, size %ld\n",\r\n__func__, (unsigned long)buf->dma_addr, vma->vm_start,\r\nbuf->size);\r\nreturn 0;\r\n}\r\nstatic int vb2_dc_dmabuf_ops_attach(struct dma_buf *dbuf, struct device *dev,\r\nstruct dma_buf_attachment *dbuf_attach)\r\n{\r\nstruct vb2_dc_attachment *attach;\r\nunsigned int i;\r\nstruct scatterlist *rd, *wr;\r\nstruct sg_table *sgt;\r\nstruct vb2_dc_buf *buf = dbuf->priv;\r\nint ret;\r\nattach = kzalloc(sizeof(*attach), GFP_KERNEL);\r\nif (!attach)\r\nreturn -ENOMEM;\r\nsgt = &attach->sgt;\r\nret = sg_alloc_table(sgt, buf->sgt_base->orig_nents, GFP_KERNEL);\r\nif (ret) {\r\nkfree(attach);\r\nreturn -ENOMEM;\r\n}\r\nrd = buf->sgt_base->sgl;\r\nwr = sgt->sgl;\r\nfor (i = 0; i < sgt->orig_nents; ++i) {\r\nsg_set_page(wr, sg_page(rd), rd->length, rd->offset);\r\nrd = sg_next(rd);\r\nwr = sg_next(wr);\r\n}\r\nattach->dma_dir = DMA_NONE;\r\ndbuf_attach->priv = attach;\r\nreturn 0;\r\n}\r\nstatic void vb2_dc_dmabuf_ops_detach(struct dma_buf *dbuf,\r\nstruct dma_buf_attachment *db_attach)\r\n{\r\nstruct vb2_dc_attachment *attach = db_attach->priv;\r\nstruct sg_table *sgt;\r\nif (!attach)\r\nreturn;\r\nsgt = &attach->sgt;\r\nif (attach->dma_dir != DMA_NONE)\r\ndma_unmap_sg(db_attach->dev, sgt->sgl, sgt->orig_nents,\r\nattach->dma_dir);\r\nsg_free_table(sgt);\r\nkfree(attach);\r\ndb_attach->priv = NULL;\r\n}\r\nstatic struct sg_table *vb2_dc_dmabuf_ops_map(\r\nstruct dma_buf_attachment *db_attach, enum dma_data_direction dma_dir)\r\n{\r\nstruct vb2_dc_attachment *attach = db_attach->priv;\r\nstruct mutex *lock = &db_attach->dmabuf->lock;\r\nstruct sg_table *sgt;\r\nmutex_lock(lock);\r\nsgt = &attach->sgt;\r\nif (attach->dma_dir == dma_dir) {\r\nmutex_unlock(lock);\r\nreturn sgt;\r\n}\r\nif (attach->dma_dir != DMA_NONE) {\r\ndma_unmap_sg(db_attach->dev, sgt->sgl, sgt->orig_nents,\r\nattach->dma_dir);\r\nattach->dma_dir = DMA_NONE;\r\n}\r\nsgt->nents = dma_map_sg(db_attach->dev, sgt->sgl, sgt->orig_nents,\r\ndma_dir);\r\nif (!sgt->nents) {\r\npr_err("failed to map scatterlist\n");\r\nmutex_unlock(lock);\r\nreturn ERR_PTR(-EIO);\r\n}\r\nattach->dma_dir = dma_dir;\r\nmutex_unlock(lock);\r\nreturn sgt;\r\n}\r\nstatic void vb2_dc_dmabuf_ops_unmap(struct dma_buf_attachment *db_attach,\r\nstruct sg_table *sgt, enum dma_data_direction dma_dir)\r\n{\r\n}\r\nstatic void vb2_dc_dmabuf_ops_release(struct dma_buf *dbuf)\r\n{\r\nvb2_dc_put(dbuf->priv);\r\n}\r\nstatic void *vb2_dc_dmabuf_ops_kmap(struct dma_buf *dbuf, unsigned long pgnum)\r\n{\r\nstruct vb2_dc_buf *buf = dbuf->priv;\r\nreturn buf->vaddr ? buf->vaddr + pgnum * PAGE_SIZE : NULL;\r\n}\r\nstatic void *vb2_dc_dmabuf_ops_vmap(struct dma_buf *dbuf)\r\n{\r\nstruct vb2_dc_buf *buf = dbuf->priv;\r\nreturn buf->vaddr;\r\n}\r\nstatic int vb2_dc_dmabuf_ops_mmap(struct dma_buf *dbuf,\r\nstruct vm_area_struct *vma)\r\n{\r\nreturn vb2_dc_mmap(dbuf->priv, vma);\r\n}\r\nstatic struct sg_table *vb2_dc_get_base_sgt(struct vb2_dc_buf *buf)\r\n{\r\nint ret;\r\nstruct sg_table *sgt;\r\nsgt = kmalloc(sizeof(*sgt), GFP_KERNEL);\r\nif (!sgt) {\r\ndev_err(buf->dev, "failed to alloc sg table\n");\r\nreturn NULL;\r\n}\r\nret = dma_get_sgtable_attrs(buf->dev, sgt, buf->cookie, buf->dma_addr,\r\nbuf->size, &buf->attrs);\r\nif (ret < 0) {\r\ndev_err(buf->dev, "failed to get scatterlist from DMA API\n");\r\nkfree(sgt);\r\nreturn NULL;\r\n}\r\nreturn sgt;\r\n}\r\nstatic struct dma_buf *vb2_dc_get_dmabuf(void *buf_priv, unsigned long flags)\r\n{\r\nstruct vb2_dc_buf *buf = buf_priv;\r\nstruct dma_buf *dbuf;\r\nDEFINE_DMA_BUF_EXPORT_INFO(exp_info);\r\nexp_info.ops = &vb2_dc_dmabuf_ops;\r\nexp_info.size = buf->size;\r\nexp_info.flags = flags;\r\nexp_info.priv = buf;\r\nif (!buf->sgt_base)\r\nbuf->sgt_base = vb2_dc_get_base_sgt(buf);\r\nif (WARN_ON(!buf->sgt_base))\r\nreturn NULL;\r\ndbuf = dma_buf_export(&exp_info);\r\nif (IS_ERR(dbuf))\r\nreturn NULL;\r\natomic_inc(&buf->refcount);\r\nreturn dbuf;\r\n}\r\nstatic void vb2_dc_put_userptr(void *buf_priv)\r\n{\r\nstruct vb2_dc_buf *buf = buf_priv;\r\nstruct sg_table *sgt = buf->dma_sgt;\r\nint i;\r\nstruct page **pages;\r\nif (sgt) {\r\nDEFINE_DMA_ATTRS(attrs);\r\ndma_set_attr(DMA_ATTR_SKIP_CPU_SYNC, &attrs);\r\ndma_unmap_sg_attrs(buf->dev, sgt->sgl, sgt->orig_nents,\r\nbuf->dma_dir, &attrs);\r\npages = frame_vector_pages(buf->vec);\r\nBUG_ON(IS_ERR(pages));\r\nfor (i = 0; i < frame_vector_count(buf->vec); i++)\r\nset_page_dirty_lock(pages[i]);\r\nsg_free_table(sgt);\r\nkfree(sgt);\r\n}\r\nvb2_destroy_framevec(buf->vec);\r\nkfree(buf);\r\n}\r\nstatic inline dma_addr_t vb2_dc_pfn_to_dma(struct device *dev, unsigned long pfn)\r\n{\r\nreturn (dma_addr_t)__arch_pfn_to_dma(dev, pfn);\r\n}\r\nstatic inline dma_addr_t vb2_dc_pfn_to_dma(struct device *dev, unsigned long pfn)\r\n{\r\nreturn (dma_addr_t)__pfn_to_bus(pfn);\r\n}\r\nstatic inline dma_addr_t vb2_dc_pfn_to_dma(struct device *dev, unsigned long pfn)\r\n{\r\nreturn (dma_addr_t)__pfn_to_phys(pfn);\r\n}\r\nstatic inline dma_addr_t vb2_dc_pfn_to_dma(struct device *dev, unsigned long pfn)\r\n{\r\nreturn (dma_addr_t)(pfn) << PAGE_SHIFT;\r\n}\r\nstatic void *vb2_dc_get_userptr(void *alloc_ctx, unsigned long vaddr,\r\nunsigned long size, enum dma_data_direction dma_dir)\r\n{\r\nstruct vb2_dc_conf *conf = alloc_ctx;\r\nstruct vb2_dc_buf *buf;\r\nstruct frame_vector *vec;\r\nunsigned long offset;\r\nint n_pages, i;\r\nint ret = 0;\r\nstruct sg_table *sgt;\r\nunsigned long contig_size;\r\nunsigned long dma_align = dma_get_cache_alignment();\r\nDEFINE_DMA_ATTRS(attrs);\r\ndma_set_attr(DMA_ATTR_SKIP_CPU_SYNC, &attrs);\r\nif (!IS_ALIGNED(vaddr | size, dma_align)) {\r\npr_debug("user data must be aligned to %lu bytes\n", dma_align);\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\nif (!size) {\r\npr_debug("size is zero\n");\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\nbuf = kzalloc(sizeof *buf, GFP_KERNEL);\r\nif (!buf)\r\nreturn ERR_PTR(-ENOMEM);\r\nbuf->dev = conf->dev;\r\nbuf->dma_dir = dma_dir;\r\noffset = vaddr & ~PAGE_MASK;\r\nvec = vb2_create_framevec(vaddr, size, dma_dir == DMA_FROM_DEVICE);\r\nif (IS_ERR(vec)) {\r\nret = PTR_ERR(vec);\r\ngoto fail_buf;\r\n}\r\nbuf->vec = vec;\r\nn_pages = frame_vector_count(vec);\r\nret = frame_vector_to_pages(vec);\r\nif (ret < 0) {\r\nunsigned long *nums = frame_vector_pfns(vec);\r\nfor (i = 1; i < n_pages; i++)\r\nif (nums[i-1] + 1 != nums[i])\r\ngoto fail_pfnvec;\r\nbuf->dma_addr = vb2_dc_pfn_to_dma(buf->dev, nums[0]);\r\ngoto out;\r\n}\r\nsgt = kzalloc(sizeof(*sgt), GFP_KERNEL);\r\nif (!sgt) {\r\npr_err("failed to allocate sg table\n");\r\nret = -ENOMEM;\r\ngoto fail_pfnvec;\r\n}\r\nret = sg_alloc_table_from_pages(sgt, frame_vector_pages(vec), n_pages,\r\noffset, size, GFP_KERNEL);\r\nif (ret) {\r\npr_err("failed to initialize sg table\n");\r\ngoto fail_sgt;\r\n}\r\nsgt->nents = dma_map_sg_attrs(buf->dev, sgt->sgl, sgt->orig_nents,\r\nbuf->dma_dir, &attrs);\r\nif (sgt->nents <= 0) {\r\npr_err("failed to map scatterlist\n");\r\nret = -EIO;\r\ngoto fail_sgt_init;\r\n}\r\ncontig_size = vb2_dc_get_contiguous_size(sgt);\r\nif (contig_size < size) {\r\npr_err("contiguous mapping is too small %lu/%lu\n",\r\ncontig_size, size);\r\nret = -EFAULT;\r\ngoto fail_map_sg;\r\n}\r\nbuf->dma_addr = sg_dma_address(sgt->sgl);\r\nbuf->dma_sgt = sgt;\r\nout:\r\nbuf->size = size;\r\nreturn buf;\r\nfail_map_sg:\r\ndma_unmap_sg_attrs(buf->dev, sgt->sgl, sgt->orig_nents,\r\nbuf->dma_dir, &attrs);\r\nfail_sgt_init:\r\nsg_free_table(sgt);\r\nfail_sgt:\r\nkfree(sgt);\r\nfail_pfnvec:\r\nvb2_destroy_framevec(vec);\r\nfail_buf:\r\nkfree(buf);\r\nreturn ERR_PTR(ret);\r\n}\r\nstatic int vb2_dc_map_dmabuf(void *mem_priv)\r\n{\r\nstruct vb2_dc_buf *buf = mem_priv;\r\nstruct sg_table *sgt;\r\nunsigned long contig_size;\r\nif (WARN_ON(!buf->db_attach)) {\r\npr_err("trying to pin a non attached buffer\n");\r\nreturn -EINVAL;\r\n}\r\nif (WARN_ON(buf->dma_sgt)) {\r\npr_err("dmabuf buffer is already pinned\n");\r\nreturn 0;\r\n}\r\nsgt = dma_buf_map_attachment(buf->db_attach, buf->dma_dir);\r\nif (IS_ERR(sgt)) {\r\npr_err("Error getting dmabuf scatterlist\n");\r\nreturn -EINVAL;\r\n}\r\ncontig_size = vb2_dc_get_contiguous_size(sgt);\r\nif (contig_size < buf->size) {\r\npr_err("contiguous chunk is too small %lu/%lu b\n",\r\ncontig_size, buf->size);\r\ndma_buf_unmap_attachment(buf->db_attach, sgt, buf->dma_dir);\r\nreturn -EFAULT;\r\n}\r\nbuf->dma_addr = sg_dma_address(sgt->sgl);\r\nbuf->dma_sgt = sgt;\r\nbuf->vaddr = NULL;\r\nreturn 0;\r\n}\r\nstatic void vb2_dc_unmap_dmabuf(void *mem_priv)\r\n{\r\nstruct vb2_dc_buf *buf = mem_priv;\r\nstruct sg_table *sgt = buf->dma_sgt;\r\nif (WARN_ON(!buf->db_attach)) {\r\npr_err("trying to unpin a not attached buffer\n");\r\nreturn;\r\n}\r\nif (WARN_ON(!sgt)) {\r\npr_err("dmabuf buffer is already unpinned\n");\r\nreturn;\r\n}\r\nif (buf->vaddr) {\r\ndma_buf_vunmap(buf->db_attach->dmabuf, buf->vaddr);\r\nbuf->vaddr = NULL;\r\n}\r\ndma_buf_unmap_attachment(buf->db_attach, sgt, buf->dma_dir);\r\nbuf->dma_addr = 0;\r\nbuf->dma_sgt = NULL;\r\n}\r\nstatic void vb2_dc_detach_dmabuf(void *mem_priv)\r\n{\r\nstruct vb2_dc_buf *buf = mem_priv;\r\nif (WARN_ON(buf->dma_addr))\r\nvb2_dc_unmap_dmabuf(buf);\r\ndma_buf_detach(buf->db_attach->dmabuf, buf->db_attach);\r\nkfree(buf);\r\n}\r\nstatic void *vb2_dc_attach_dmabuf(void *alloc_ctx, struct dma_buf *dbuf,\r\nunsigned long size, enum dma_data_direction dma_dir)\r\n{\r\nstruct vb2_dc_conf *conf = alloc_ctx;\r\nstruct vb2_dc_buf *buf;\r\nstruct dma_buf_attachment *dba;\r\nif (dbuf->size < size)\r\nreturn ERR_PTR(-EFAULT);\r\nbuf = kzalloc(sizeof(*buf), GFP_KERNEL);\r\nif (!buf)\r\nreturn ERR_PTR(-ENOMEM);\r\nbuf->dev = conf->dev;\r\ndba = dma_buf_attach(dbuf, buf->dev);\r\nif (IS_ERR(dba)) {\r\npr_err("failed to attach dmabuf\n");\r\nkfree(buf);\r\nreturn dba;\r\n}\r\nbuf->dma_dir = dma_dir;\r\nbuf->size = size;\r\nbuf->db_attach = dba;\r\nreturn buf;\r\n}\r\nvoid *vb2_dma_contig_init_ctx_attrs(struct device *dev,\r\nstruct dma_attrs *attrs)\r\n{\r\nstruct vb2_dc_conf *conf;\r\nconf = kzalloc(sizeof *conf, GFP_KERNEL);\r\nif (!conf)\r\nreturn ERR_PTR(-ENOMEM);\r\nconf->dev = dev;\r\nif (attrs)\r\nconf->attrs = *attrs;\r\nreturn conf;\r\n}\r\nvoid vb2_dma_contig_cleanup_ctx(void *alloc_ctx)\r\n{\r\nif (!IS_ERR_OR_NULL(alloc_ctx))\r\nkfree(alloc_ctx);\r\n}
