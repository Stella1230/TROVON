static int disabled_by_idle_boot_param(void)\r\n{\r\nreturn boot_option_idle_override == IDLE_POLL ||\r\nboot_option_idle_override == IDLE_HALT;\r\n}\r\nstatic int set_max_cstate(const struct dmi_system_id *id)\r\n{\r\nif (max_cstate > ACPI_PROCESSOR_MAX_POWER)\r\nreturn 0;\r\npr_notice("%s detected - limiting to C%ld max_cstate."\r\n" Override with \"processor.max_cstate=%d\"\n", id->ident,\r\n(long)id->driver_data, ACPI_PROCESSOR_MAX_POWER + 1);\r\nmax_cstate = (long)id->driver_data;\r\nreturn 0;\r\n}\r\nstatic void acpi_safe_halt(void)\r\n{\r\nif (!tif_need_resched()) {\r\nsafe_halt();\r\nlocal_irq_disable();\r\n}\r\n}\r\nstatic void lapic_timer_check_state(int state, struct acpi_processor *pr,\r\nstruct acpi_processor_cx *cx)\r\n{\r\nstruct acpi_processor_power *pwr = &pr->power;\r\nu8 type = local_apic_timer_c2_ok ? ACPI_STATE_C3 : ACPI_STATE_C2;\r\nif (cpu_has(&cpu_data(pr->id), X86_FEATURE_ARAT))\r\nreturn;\r\nif (amd_e400_c1e_detected)\r\ntype = ACPI_STATE_C1;\r\nif (pwr->timer_broadcast_on_state < state)\r\nreturn;\r\nif (cx->type >= type)\r\npr->power.timer_broadcast_on_state = state;\r\n}\r\nstatic void __lapic_timer_propagate_broadcast(void *arg)\r\n{\r\nstruct acpi_processor *pr = (struct acpi_processor *) arg;\r\nif (pr->power.timer_broadcast_on_state < INT_MAX)\r\ntick_broadcast_enable();\r\nelse\r\ntick_broadcast_disable();\r\n}\r\nstatic void lapic_timer_propagate_broadcast(struct acpi_processor *pr)\r\n{\r\nsmp_call_function_single(pr->id, __lapic_timer_propagate_broadcast,\r\n(void *)pr, 1);\r\n}\r\nstatic void lapic_timer_state_broadcast(struct acpi_processor *pr,\r\nstruct acpi_processor_cx *cx,\r\nint broadcast)\r\n{\r\nint state = cx - pr->power.states;\r\nif (state >= pr->power.timer_broadcast_on_state) {\r\nif (broadcast)\r\ntick_broadcast_enter();\r\nelse\r\ntick_broadcast_exit();\r\n}\r\n}\r\nstatic void lapic_timer_check_state(int state, struct acpi_processor *pr,\r\nstruct acpi_processor_cx *cstate) { }\r\nstatic void lapic_timer_propagate_broadcast(struct acpi_processor *pr) { }\r\nstatic void lapic_timer_state_broadcast(struct acpi_processor *pr,\r\nstruct acpi_processor_cx *cx,\r\nint broadcast)\r\n{\r\n}\r\nstatic void tsc_check_state(int state)\r\n{\r\nswitch (boot_cpu_data.x86_vendor) {\r\ncase X86_VENDOR_AMD:\r\ncase X86_VENDOR_INTEL:\r\nif (boot_cpu_has(X86_FEATURE_NONSTOP_TSC))\r\nreturn;\r\ndefault:\r\nif (state > ACPI_STATE_C1)\r\nmark_tsc_unstable("TSC halts in idle");\r\n}\r\n}\r\nstatic void tsc_check_state(int state) { return; }\r\nstatic int acpi_processor_get_power_info_fadt(struct acpi_processor *pr)\r\n{\r\nif (!pr->pblk)\r\nreturn -ENODEV;\r\npr->power.states[ACPI_STATE_C2].type = ACPI_STATE_C2;\r\npr->power.states[ACPI_STATE_C3].type = ACPI_STATE_C3;\r\n#ifndef CONFIG_HOTPLUG_CPU\r\nif ((num_online_cpus() > 1) &&\r\n!(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED))\r\nreturn -ENODEV;\r\n#endif\r\npr->power.states[ACPI_STATE_C2].address = pr->pblk + 4;\r\npr->power.states[ACPI_STATE_C3].address = pr->pblk + 5;\r\npr->power.states[ACPI_STATE_C2].latency = acpi_gbl_FADT.c2_latency;\r\npr->power.states[ACPI_STATE_C3].latency = acpi_gbl_FADT.c3_latency;\r\nif (acpi_gbl_FADT.c2_latency > ACPI_PROCESSOR_MAX_C2_LATENCY) {\r\nACPI_DEBUG_PRINT((ACPI_DB_INFO,\r\n"C2 latency too large [%d]\n", acpi_gbl_FADT.c2_latency));\r\npr->power.states[ACPI_STATE_C2].address = 0;\r\n}\r\nif (acpi_gbl_FADT.c3_latency > ACPI_PROCESSOR_MAX_C3_LATENCY) {\r\nACPI_DEBUG_PRINT((ACPI_DB_INFO,\r\n"C3 latency too large [%d]\n", acpi_gbl_FADT.c3_latency));\r\npr->power.states[ACPI_STATE_C3].address = 0;\r\n}\r\nACPI_DEBUG_PRINT((ACPI_DB_INFO,\r\n"lvl2[0x%08x] lvl3[0x%08x]\n",\r\npr->power.states[ACPI_STATE_C2].address,\r\npr->power.states[ACPI_STATE_C3].address));\r\nreturn 0;\r\n}\r\nstatic int acpi_processor_get_power_info_default(struct acpi_processor *pr)\r\n{\r\nif (!pr->power.states[ACPI_STATE_C1].valid) {\r\npr->power.states[ACPI_STATE_C1].type = ACPI_STATE_C1;\r\npr->power.states[ACPI_STATE_C1].valid = 1;\r\npr->power.states[ACPI_STATE_C1].entry_method = ACPI_CSTATE_HALT;\r\n}\r\npr->power.states[ACPI_STATE_C0].valid = 1;\r\nreturn 0;\r\n}\r\nstatic int acpi_processor_get_power_info_cst(struct acpi_processor *pr)\r\n{\r\nacpi_status status;\r\nu64 count;\r\nint current_count;\r\nint i, ret = 0;\r\nstruct acpi_buffer buffer = { ACPI_ALLOCATE_BUFFER, NULL };\r\nunion acpi_object *cst;\r\nif (nocst)\r\nreturn -ENODEV;\r\ncurrent_count = 0;\r\nstatus = acpi_evaluate_object(pr->handle, "_CST", NULL, &buffer);\r\nif (ACPI_FAILURE(status)) {\r\nACPI_DEBUG_PRINT((ACPI_DB_INFO, "No _CST, giving up\n"));\r\nreturn -ENODEV;\r\n}\r\ncst = buffer.pointer;\r\nif (!cst || (cst->type != ACPI_TYPE_PACKAGE) || cst->package.count < 2) {\r\npr_err("not enough elements in _CST\n");\r\nret = -EFAULT;\r\ngoto end;\r\n}\r\ncount = cst->package.elements[0].integer.value;\r\nif (count < 1 || count != cst->package.count - 1) {\r\npr_err("count given by _CST is not valid\n");\r\nret = -EFAULT;\r\ngoto end;\r\n}\r\npr->flags.has_cst = 1;\r\nfor (i = 1; i <= count; i++) {\r\nunion acpi_object *element;\r\nunion acpi_object *obj;\r\nstruct acpi_power_register *reg;\r\nstruct acpi_processor_cx cx;\r\nmemset(&cx, 0, sizeof(cx));\r\nelement = &(cst->package.elements[i]);\r\nif (element->type != ACPI_TYPE_PACKAGE)\r\ncontinue;\r\nif (element->package.count != 4)\r\ncontinue;\r\nobj = &(element->package.elements[0]);\r\nif (obj->type != ACPI_TYPE_BUFFER)\r\ncontinue;\r\nreg = (struct acpi_power_register *)obj->buffer.pointer;\r\nif (reg->space_id != ACPI_ADR_SPACE_SYSTEM_IO &&\r\n(reg->space_id != ACPI_ADR_SPACE_FIXED_HARDWARE))\r\ncontinue;\r\nobj = &(element->package.elements[1]);\r\nif (obj->type != ACPI_TYPE_INTEGER)\r\ncontinue;\r\ncx.type = obj->integer.value;\r\nif (i == 1 && cx.type != ACPI_STATE_C1)\r\ncurrent_count++;\r\ncx.address = reg->address;\r\ncx.index = current_count + 1;\r\ncx.entry_method = ACPI_CSTATE_SYSTEMIO;\r\nif (reg->space_id == ACPI_ADR_SPACE_FIXED_HARDWARE) {\r\nif (acpi_processor_ffh_cstate_probe\r\n(pr->id, &cx, reg) == 0) {\r\ncx.entry_method = ACPI_CSTATE_FFH;\r\n} else if (cx.type == ACPI_STATE_C1) {\r\ncx.entry_method = ACPI_CSTATE_HALT;\r\nsnprintf(cx.desc, ACPI_CX_DESC_LEN, "ACPI HLT");\r\n} else {\r\ncontinue;\r\n}\r\nif (cx.type == ACPI_STATE_C1 &&\r\n(boot_option_idle_override == IDLE_NOMWAIT)) {\r\ncx.entry_method = ACPI_CSTATE_HALT;\r\nsnprintf(cx.desc, ACPI_CX_DESC_LEN, "ACPI HLT");\r\n}\r\n} else {\r\nsnprintf(cx.desc, ACPI_CX_DESC_LEN, "ACPI IOPORT 0x%x",\r\ncx.address);\r\n}\r\nif (cx.type == ACPI_STATE_C1) {\r\ncx.valid = 1;\r\n}\r\nobj = &(element->package.elements[2]);\r\nif (obj->type != ACPI_TYPE_INTEGER)\r\ncontinue;\r\ncx.latency = obj->integer.value;\r\nobj = &(element->package.elements[3]);\r\nif (obj->type != ACPI_TYPE_INTEGER)\r\ncontinue;\r\ncurrent_count++;\r\nmemcpy(&(pr->power.states[current_count]), &cx, sizeof(cx));\r\nif (current_count >= (ACPI_PROCESSOR_MAX_POWER - 1)) {\r\npr_warn("Limiting number of power states to max (%d)\n",\r\nACPI_PROCESSOR_MAX_POWER);\r\npr_warn("Please increase ACPI_PROCESSOR_MAX_POWER if needed.\n");\r\nbreak;\r\n}\r\n}\r\nACPI_DEBUG_PRINT((ACPI_DB_INFO, "Found %d power states\n",\r\ncurrent_count));\r\nif (current_count < 2)\r\nret = -EFAULT;\r\nend:\r\nkfree(buffer.pointer);\r\nreturn ret;\r\n}\r\nstatic void acpi_processor_power_verify_c3(struct acpi_processor *pr,\r\nstruct acpi_processor_cx *cx)\r\n{\r\nstatic int bm_check_flag = -1;\r\nstatic int bm_control_flag = -1;\r\nif (!cx->address)\r\nreturn;\r\nelse if (errata.piix4.fdma) {\r\nACPI_DEBUG_PRINT((ACPI_DB_INFO,\r\n"C3 not supported on PIIX4 with Type-F DMA\n"));\r\nreturn;\r\n}\r\nif (bm_check_flag == -1) {\r\nacpi_processor_power_init_bm_check(&(pr->flags), pr->id);\r\nbm_check_flag = pr->flags.bm_check;\r\nbm_control_flag = pr->flags.bm_control;\r\n} else {\r\npr->flags.bm_check = bm_check_flag;\r\npr->flags.bm_control = bm_control_flag;\r\n}\r\nif (pr->flags.bm_check) {\r\nif (!pr->flags.bm_control) {\r\nif (pr->flags.has_cst != 1) {\r\nACPI_DEBUG_PRINT((ACPI_DB_INFO,\r\n"C3 support requires BM control\n"));\r\nreturn;\r\n} else {\r\nACPI_DEBUG_PRINT((ACPI_DB_INFO,\r\n"C3 support without BM control\n"));\r\n}\r\n}\r\n} else {\r\nif (!(acpi_gbl_FADT.flags & ACPI_FADT_WBINVD)) {\r\nACPI_DEBUG_PRINT((ACPI_DB_INFO,\r\n"Cache invalidation should work properly"\r\n" for C3 to be enabled on SMP systems\n"));\r\nreturn;\r\n}\r\n}\r\ncx->valid = 1;\r\nacpi_write_bit_register(ACPI_BITREG_BUS_MASTER_RLD, 1);\r\nreturn;\r\n}\r\nstatic int acpi_processor_power_verify(struct acpi_processor *pr)\r\n{\r\nunsigned int i;\r\nunsigned int working = 0;\r\npr->power.timer_broadcast_on_state = INT_MAX;\r\nfor (i = 1; i < ACPI_PROCESSOR_MAX_POWER && i <= max_cstate; i++) {\r\nstruct acpi_processor_cx *cx = &pr->power.states[i];\r\nswitch (cx->type) {\r\ncase ACPI_STATE_C1:\r\ncx->valid = 1;\r\nbreak;\r\ncase ACPI_STATE_C2:\r\nif (!cx->address)\r\nbreak;\r\ncx->valid = 1;\r\nbreak;\r\ncase ACPI_STATE_C3:\r\nacpi_processor_power_verify_c3(pr, cx);\r\nbreak;\r\n}\r\nif (!cx->valid)\r\ncontinue;\r\nlapic_timer_check_state(i, pr, cx);\r\ntsc_check_state(cx->type);\r\nworking++;\r\n}\r\nlapic_timer_propagate_broadcast(pr);\r\nreturn (working);\r\n}\r\nstatic int acpi_processor_get_power_info(struct acpi_processor *pr)\r\n{\r\nunsigned int i;\r\nint result;\r\nmemset(pr->power.states, 0, sizeof(pr->power.states));\r\nresult = acpi_processor_get_power_info_cst(pr);\r\nif (result == -ENODEV)\r\nresult = acpi_processor_get_power_info_fadt(pr);\r\nif (result)\r\nreturn result;\r\nacpi_processor_get_power_info_default(pr);\r\npr->power.count = acpi_processor_power_verify(pr);\r\nfor (i = 1; i < ACPI_PROCESSOR_MAX_POWER; i++) {\r\nif (pr->power.states[i].valid) {\r\npr->power.count = i;\r\nif (pr->power.states[i].type >= ACPI_STATE_C2)\r\npr->flags.power = 1;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int acpi_idle_bm_check(void)\r\n{\r\nu32 bm_status = 0;\r\nif (bm_check_disable)\r\nreturn 0;\r\nacpi_read_bit_register(ACPI_BITREG_BUS_MASTER_STATUS, &bm_status);\r\nif (bm_status)\r\nacpi_write_bit_register(ACPI_BITREG_BUS_MASTER_STATUS, 1);\r\nelse if (errata.piix4.bmisx) {\r\nif ((inb_p(errata.piix4.bmisx + 0x02) & 0x01)\r\n|| (inb_p(errata.piix4.bmisx + 0x0A) & 0x01))\r\nbm_status = 1;\r\n}\r\nreturn bm_status;\r\n}\r\nstatic void acpi_idle_do_entry(struct acpi_processor_cx *cx)\r\n{\r\nif (cx->entry_method == ACPI_CSTATE_FFH) {\r\nacpi_processor_ffh_cstate_enter(cx);\r\n} else if (cx->entry_method == ACPI_CSTATE_HALT) {\r\nacpi_safe_halt();\r\n} else {\r\ninb(cx->address);\r\ninl(acpi_gbl_FADT.xpm_timer_block.address);\r\n}\r\n}\r\nstatic int acpi_idle_play_dead(struct cpuidle_device *dev, int index)\r\n{\r\nstruct acpi_processor_cx *cx = per_cpu(acpi_cstate[index], dev->cpu);\r\nACPI_FLUSH_CPU_CACHE();\r\nwhile (1) {\r\nif (cx->entry_method == ACPI_CSTATE_HALT)\r\nsafe_halt();\r\nelse if (cx->entry_method == ACPI_CSTATE_SYSTEMIO) {\r\ninb(cx->address);\r\ninl(acpi_gbl_FADT.xpm_timer_block.address);\r\n} else\r\nreturn -ENODEV;\r\n}\r\nreturn 0;\r\n}\r\nstatic bool acpi_idle_fallback_to_c1(struct acpi_processor *pr)\r\n{\r\nreturn IS_ENABLED(CONFIG_HOTPLUG_CPU) && !pr->flags.has_cst &&\r\n!(acpi_gbl_FADT.flags & ACPI_FADT_C2_MP_SUPPORTED);\r\n}\r\nstatic void acpi_idle_enter_bm(struct acpi_processor *pr,\r\nstruct acpi_processor_cx *cx, bool timer_bc)\r\n{\r\nacpi_unlazy_tlb(smp_processor_id());\r\nif (timer_bc)\r\nlapic_timer_state_broadcast(pr, cx, 1);\r\nif (pr->flags.bm_control) {\r\nraw_spin_lock(&c3_lock);\r\nc3_cpu_count++;\r\nif (c3_cpu_count == num_online_cpus())\r\nacpi_write_bit_register(ACPI_BITREG_ARB_DISABLE, 1);\r\nraw_spin_unlock(&c3_lock);\r\n}\r\nacpi_idle_do_entry(cx);\r\nif (pr->flags.bm_control) {\r\nraw_spin_lock(&c3_lock);\r\nacpi_write_bit_register(ACPI_BITREG_ARB_DISABLE, 0);\r\nc3_cpu_count--;\r\nraw_spin_unlock(&c3_lock);\r\n}\r\nif (timer_bc)\r\nlapic_timer_state_broadcast(pr, cx, 0);\r\n}\r\nstatic int acpi_idle_enter(struct cpuidle_device *dev,\r\nstruct cpuidle_driver *drv, int index)\r\n{\r\nstruct acpi_processor_cx *cx = per_cpu(acpi_cstate[index], dev->cpu);\r\nstruct acpi_processor *pr;\r\npr = __this_cpu_read(processors);\r\nif (unlikely(!pr))\r\nreturn -EINVAL;\r\nif (cx->type != ACPI_STATE_C1) {\r\nif (acpi_idle_fallback_to_c1(pr) && num_online_cpus() > 1) {\r\nindex = CPUIDLE_DRIVER_STATE_START;\r\ncx = per_cpu(acpi_cstate[index], dev->cpu);\r\n} else if (cx->type == ACPI_STATE_C3 && pr->flags.bm_check) {\r\nif (cx->bm_sts_skip || !acpi_idle_bm_check()) {\r\nacpi_idle_enter_bm(pr, cx, true);\r\nreturn index;\r\n} else if (drv->safe_state_index >= 0) {\r\nindex = drv->safe_state_index;\r\ncx = per_cpu(acpi_cstate[index], dev->cpu);\r\n} else {\r\nacpi_safe_halt();\r\nreturn -EBUSY;\r\n}\r\n}\r\n}\r\nlapic_timer_state_broadcast(pr, cx, 1);\r\nif (cx->type == ACPI_STATE_C3)\r\nACPI_FLUSH_CPU_CACHE();\r\nacpi_idle_do_entry(cx);\r\nlapic_timer_state_broadcast(pr, cx, 0);\r\nreturn index;\r\n}\r\nstatic void acpi_idle_enter_freeze(struct cpuidle_device *dev,\r\nstruct cpuidle_driver *drv, int index)\r\n{\r\nstruct acpi_processor_cx *cx = per_cpu(acpi_cstate[index], dev->cpu);\r\nif (cx->type == ACPI_STATE_C3) {\r\nstruct acpi_processor *pr = __this_cpu_read(processors);\r\nif (unlikely(!pr))\r\nreturn;\r\nif (pr->flags.bm_check) {\r\nacpi_idle_enter_bm(pr, cx, false);\r\nreturn;\r\n} else {\r\nACPI_FLUSH_CPU_CACHE();\r\n}\r\n}\r\nacpi_idle_do_entry(cx);\r\n}\r\nstatic int acpi_processor_setup_cpuidle_cx(struct acpi_processor *pr,\r\nstruct cpuidle_device *dev)\r\n{\r\nint i, count = CPUIDLE_DRIVER_STATE_START;\r\nstruct acpi_processor_cx *cx;\r\nif (!pr->flags.power_setup_done)\r\nreturn -EINVAL;\r\nif (pr->flags.power == 0) {\r\nreturn -EINVAL;\r\n}\r\nif (!dev)\r\nreturn -EINVAL;\r\ndev->cpu = pr->id;\r\nif (max_cstate == 0)\r\nmax_cstate = 1;\r\nfor (i = 1; i < ACPI_PROCESSOR_MAX_POWER && i <= max_cstate; i++) {\r\ncx = &pr->power.states[i];\r\nif (!cx->valid)\r\ncontinue;\r\nper_cpu(acpi_cstate[count], dev->cpu) = cx;\r\ncount++;\r\nif (count == CPUIDLE_STATE_MAX)\r\nbreak;\r\n}\r\nif (!count)\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic int acpi_processor_setup_cpuidle_states(struct acpi_processor *pr)\r\n{\r\nint i, count = CPUIDLE_DRIVER_STATE_START;\r\nstruct acpi_processor_cx *cx;\r\nstruct cpuidle_state *state;\r\nstruct cpuidle_driver *drv = &acpi_idle_driver;\r\nif (!pr->flags.power_setup_done)\r\nreturn -EINVAL;\r\nif (pr->flags.power == 0)\r\nreturn -EINVAL;\r\ndrv->safe_state_index = -1;\r\nfor (i = CPUIDLE_DRIVER_STATE_START; i < CPUIDLE_STATE_MAX; i++) {\r\ndrv->states[i].name[0] = '\0';\r\ndrv->states[i].desc[0] = '\0';\r\n}\r\nif (max_cstate == 0)\r\nmax_cstate = 1;\r\nfor (i = 1; i < ACPI_PROCESSOR_MAX_POWER && i <= max_cstate; i++) {\r\ncx = &pr->power.states[i];\r\nif (!cx->valid)\r\ncontinue;\r\nstate = &drv->states[count];\r\nsnprintf(state->name, CPUIDLE_NAME_LEN, "C%d", i);\r\nstrncpy(state->desc, cx->desc, CPUIDLE_DESC_LEN);\r\nstate->exit_latency = cx->latency;\r\nstate->target_residency = cx->latency * latency_factor;\r\nstate->enter = acpi_idle_enter;\r\nstate->flags = 0;\r\nif (cx->type == ACPI_STATE_C1 || cx->type == ACPI_STATE_C2) {\r\nstate->enter_dead = acpi_idle_play_dead;\r\ndrv->safe_state_index = count;\r\n}\r\nif (cx->type != ACPI_STATE_C1 && !acpi_idle_fallback_to_c1(pr))\r\nstate->enter_freeze = acpi_idle_enter_freeze;\r\ncount++;\r\nif (count == CPUIDLE_STATE_MAX)\r\nbreak;\r\n}\r\ndrv->state_count = count;\r\nif (!count)\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nint acpi_processor_hotplug(struct acpi_processor *pr)\r\n{\r\nint ret = 0;\r\nstruct cpuidle_device *dev;\r\nif (disabled_by_idle_boot_param())\r\nreturn 0;\r\nif (nocst)\r\nreturn -ENODEV;\r\nif (!pr->flags.power_setup_done)\r\nreturn -ENODEV;\r\ndev = per_cpu(acpi_cpuidle_device, pr->id);\r\ncpuidle_pause_and_lock();\r\ncpuidle_disable_device(dev);\r\nacpi_processor_get_power_info(pr);\r\nif (pr->flags.power) {\r\nacpi_processor_setup_cpuidle_cx(pr, dev);\r\nret = cpuidle_enable_device(dev);\r\n}\r\ncpuidle_resume_and_unlock();\r\nreturn ret;\r\n}\r\nint acpi_processor_cst_has_changed(struct acpi_processor *pr)\r\n{\r\nint cpu;\r\nstruct acpi_processor *_pr;\r\nstruct cpuidle_device *dev;\r\nif (disabled_by_idle_boot_param())\r\nreturn 0;\r\nif (nocst)\r\nreturn -ENODEV;\r\nif (!pr->flags.power_setup_done)\r\nreturn -ENODEV;\r\nif (pr->id == 0 && cpuidle_get_driver() == &acpi_idle_driver) {\r\nget_online_cpus();\r\ncpuidle_pause_and_lock();\r\nfor_each_online_cpu(cpu) {\r\n_pr = per_cpu(processors, cpu);\r\nif (!_pr || !_pr->flags.power_setup_done)\r\ncontinue;\r\ndev = per_cpu(acpi_cpuidle_device, cpu);\r\ncpuidle_disable_device(dev);\r\n}\r\nacpi_processor_get_power_info(pr);\r\nacpi_processor_setup_cpuidle_states(pr);\r\nfor_each_online_cpu(cpu) {\r\n_pr = per_cpu(processors, cpu);\r\nif (!_pr || !_pr->flags.power_setup_done)\r\ncontinue;\r\nacpi_processor_get_power_info(_pr);\r\nif (_pr->flags.power) {\r\ndev = per_cpu(acpi_cpuidle_device, cpu);\r\nacpi_processor_setup_cpuidle_cx(_pr, dev);\r\ncpuidle_enable_device(dev);\r\n}\r\n}\r\ncpuidle_resume_and_unlock();\r\nput_online_cpus();\r\n}\r\nreturn 0;\r\n}\r\nint acpi_processor_power_init(struct acpi_processor *pr)\r\n{\r\nacpi_status status;\r\nint retval;\r\nstruct cpuidle_device *dev;\r\nstatic int first_run;\r\nif (disabled_by_idle_boot_param())\r\nreturn 0;\r\nif (!first_run) {\r\ndmi_check_system(processor_power_dmi_table);\r\nmax_cstate = acpi_processor_cstate_check(max_cstate);\r\nif (max_cstate < ACPI_C_STATES_MAX)\r\nprintk(KERN_NOTICE\r\n"ACPI: processor limited to max C-state %d\n",\r\nmax_cstate);\r\nfirst_run++;\r\n}\r\nif (acpi_gbl_FADT.cst_control && !nocst) {\r\nstatus =\r\nacpi_os_write_port(acpi_gbl_FADT.smi_command, acpi_gbl_FADT.cst_control, 8);\r\nif (ACPI_FAILURE(status)) {\r\nACPI_EXCEPTION((AE_INFO, status,\r\n"Notifying BIOS of _CST ability failed"));\r\n}\r\n}\r\nacpi_processor_get_power_info(pr);\r\npr->flags.power_setup_done = 1;\r\nif (pr->flags.power) {\r\nif (!acpi_processor_registered) {\r\nacpi_processor_setup_cpuidle_states(pr);\r\nretval = cpuidle_register_driver(&acpi_idle_driver);\r\nif (retval)\r\nreturn retval;\r\npr_debug("%s registered with cpuidle\n",\r\nacpi_idle_driver.name);\r\n}\r\ndev = kzalloc(sizeof(*dev), GFP_KERNEL);\r\nif (!dev)\r\nreturn -ENOMEM;\r\nper_cpu(acpi_cpuidle_device, pr->id) = dev;\r\nacpi_processor_setup_cpuidle_cx(pr, dev);\r\nretval = cpuidle_register_device(dev);\r\nif (retval) {\r\nif (acpi_processor_registered == 0)\r\ncpuidle_unregister_driver(&acpi_idle_driver);\r\nreturn retval;\r\n}\r\nacpi_processor_registered++;\r\n}\r\nreturn 0;\r\n}\r\nint acpi_processor_power_exit(struct acpi_processor *pr)\r\n{\r\nstruct cpuidle_device *dev = per_cpu(acpi_cpuidle_device, pr->id);\r\nif (disabled_by_idle_boot_param())\r\nreturn 0;\r\nif (pr->flags.power) {\r\ncpuidle_unregister_device(dev);\r\nacpi_processor_registered--;\r\nif (acpi_processor_registered == 0)\r\ncpuidle_unregister_driver(&acpi_idle_driver);\r\n}\r\npr->flags.power_setup_done = 0;\r\nreturn 0;\r\n}
