static int vmw_cmdbuf_cur_lock(struct vmw_cmdbuf_man *man, bool interruptible)\r\n{\r\nif (interruptible) {\r\nif (mutex_lock_interruptible(&man->cur_mutex))\r\nreturn -ERESTARTSYS;\r\n} else {\r\nmutex_lock(&man->cur_mutex);\r\n}\r\nreturn 0;\r\n}\r\nstatic void vmw_cmdbuf_cur_unlock(struct vmw_cmdbuf_man *man)\r\n{\r\nmutex_unlock(&man->cur_mutex);\r\n}\r\nstatic void vmw_cmdbuf_header_inline_free(struct vmw_cmdbuf_header *header)\r\n{\r\nstruct vmw_cmdbuf_dheader *dheader;\r\nif (WARN_ON_ONCE(!header->inline_space))\r\nreturn;\r\ndheader = container_of(header->cb_header, struct vmw_cmdbuf_dheader,\r\ncb_header);\r\ndma_pool_free(header->man->dheaders, dheader, header->handle);\r\nkfree(header);\r\n}\r\nstatic void __vmw_cmdbuf_header_free(struct vmw_cmdbuf_header *header)\r\n{\r\nstruct vmw_cmdbuf_man *man = header->man;\r\nlockdep_assert_held_once(&man->lock);\r\nif (header->inline_space) {\r\nvmw_cmdbuf_header_inline_free(header);\r\nreturn;\r\n}\r\ndrm_mm_remove_node(&header->node);\r\nwake_up_all(&man->alloc_queue);\r\nif (header->cb_header)\r\ndma_pool_free(man->headers, header->cb_header,\r\nheader->handle);\r\nkfree(header);\r\n}\r\nvoid vmw_cmdbuf_header_free(struct vmw_cmdbuf_header *header)\r\n{\r\nstruct vmw_cmdbuf_man *man = header->man;\r\nif (header->inline_space) {\r\nvmw_cmdbuf_header_inline_free(header);\r\nreturn;\r\n}\r\nspin_lock_bh(&man->lock);\r\n__vmw_cmdbuf_header_free(header);\r\nspin_unlock_bh(&man->lock);\r\n}\r\nstatic int vmw_cmdbuf_header_submit(struct vmw_cmdbuf_header *header)\r\n{\r\nstruct vmw_cmdbuf_man *man = header->man;\r\nu32 val;\r\nif (sizeof(header->handle) > 4)\r\nval = (header->handle >> 32);\r\nelse\r\nval = 0;\r\nvmw_write(man->dev_priv, SVGA_REG_COMMAND_HIGH, val);\r\nval = (header->handle & 0xFFFFFFFFULL);\r\nval |= header->cb_context & SVGA_CB_CONTEXT_MASK;\r\nvmw_write(man->dev_priv, SVGA_REG_COMMAND_LOW, val);\r\nreturn header->cb_header->status;\r\n}\r\nstatic void vmw_cmdbuf_ctx_init(struct vmw_cmdbuf_context *ctx)\r\n{\r\nINIT_LIST_HEAD(&ctx->hw_submitted);\r\nINIT_LIST_HEAD(&ctx->submitted);\r\nINIT_LIST_HEAD(&ctx->preempted);\r\nctx->num_hw_submitted = 0;\r\n}\r\nstatic void vmw_cmdbuf_ctx_submit(struct vmw_cmdbuf_man *man,\r\nstruct vmw_cmdbuf_context *ctx)\r\n{\r\nwhile (ctx->num_hw_submitted < man->max_hw_submitted &&\r\n!list_empty(&ctx->submitted)) {\r\nstruct vmw_cmdbuf_header *entry;\r\nSVGACBStatus status;\r\nentry = list_first_entry(&ctx->submitted,\r\nstruct vmw_cmdbuf_header,\r\nlist);\r\nstatus = vmw_cmdbuf_header_submit(entry);\r\nif (WARN_ON_ONCE(status == SVGA_CB_STATUS_QUEUE_FULL)) {\r\nentry->cb_header->status = SVGA_CB_STATUS_NONE;\r\nbreak;\r\n}\r\nlist_del(&entry->list);\r\nlist_add_tail(&entry->list, &ctx->hw_submitted);\r\nctx->num_hw_submitted++;\r\n}\r\n}\r\nstatic void vmw_cmdbuf_ctx_process(struct vmw_cmdbuf_man *man,\r\nstruct vmw_cmdbuf_context *ctx,\r\nint *notempty)\r\n{\r\nstruct vmw_cmdbuf_header *entry, *next;\r\nvmw_cmdbuf_ctx_submit(man, ctx);\r\nlist_for_each_entry_safe(entry, next, &ctx->hw_submitted, list) {\r\nSVGACBStatus status = entry->cb_header->status;\r\nif (status == SVGA_CB_STATUS_NONE)\r\nbreak;\r\nlist_del(&entry->list);\r\nwake_up_all(&man->idle_queue);\r\nctx->num_hw_submitted--;\r\nswitch (status) {\r\ncase SVGA_CB_STATUS_COMPLETED:\r\n__vmw_cmdbuf_header_free(entry);\r\nbreak;\r\ncase SVGA_CB_STATUS_COMMAND_ERROR:\r\ncase SVGA_CB_STATUS_CB_HEADER_ERROR:\r\nlist_add_tail(&entry->list, &man->error);\r\nschedule_work(&man->work);\r\nbreak;\r\ncase SVGA_CB_STATUS_PREEMPTED:\r\nlist_add(&entry->list, &ctx->preempted);\r\nbreak;\r\ndefault:\r\nWARN_ONCE(true, "Undefined command buffer status.\n");\r\n__vmw_cmdbuf_header_free(entry);\r\nbreak;\r\n}\r\n}\r\nvmw_cmdbuf_ctx_submit(man, ctx);\r\nif (!list_empty(&ctx->submitted))\r\n(*notempty)++;\r\n}\r\nstatic void vmw_cmdbuf_man_process(struct vmw_cmdbuf_man *man)\r\n{\r\nint notempty;\r\nstruct vmw_cmdbuf_context *ctx;\r\nint i;\r\nretry:\r\nnotempty = 0;\r\nfor_each_cmdbuf_ctx(man, i, ctx)\r\nvmw_cmdbuf_ctx_process(man, ctx, &notempty);\r\nif (man->irq_on && !notempty) {\r\nvmw_generic_waiter_remove(man->dev_priv,\r\nSVGA_IRQFLAG_COMMAND_BUFFER,\r\n&man->dev_priv->cmdbuf_waiters);\r\nman->irq_on = false;\r\n} else if (!man->irq_on && notempty) {\r\nvmw_generic_waiter_add(man->dev_priv,\r\nSVGA_IRQFLAG_COMMAND_BUFFER,\r\n&man->dev_priv->cmdbuf_waiters);\r\nman->irq_on = true;\r\ngoto retry;\r\n}\r\n}\r\nstatic void vmw_cmdbuf_ctx_add(struct vmw_cmdbuf_man *man,\r\nstruct vmw_cmdbuf_header *header,\r\nSVGACBContext cb_context)\r\n{\r\nif (!(header->cb_header->flags & SVGA_CB_FLAG_DX_CONTEXT))\r\nheader->cb_header->dxContext = 0;\r\nheader->cb_context = cb_context;\r\nlist_add_tail(&header->list, &man->ctx[cb_context].submitted);\r\nvmw_cmdbuf_man_process(man);\r\n}\r\nstatic void vmw_cmdbuf_man_tasklet(unsigned long data)\r\n{\r\nstruct vmw_cmdbuf_man *man = (struct vmw_cmdbuf_man *) data;\r\nspin_lock(&man->lock);\r\nvmw_cmdbuf_man_process(man);\r\nspin_unlock(&man->lock);\r\n}\r\nstatic void vmw_cmdbuf_work_func(struct work_struct *work)\r\n{\r\nstruct vmw_cmdbuf_man *man =\r\ncontainer_of(work, struct vmw_cmdbuf_man, work);\r\nstruct vmw_cmdbuf_header *entry, *next;\r\nuint32_t dummy;\r\nbool restart = false;\r\nspin_lock_bh(&man->lock);\r\nlist_for_each_entry_safe(entry, next, &man->error, list) {\r\nrestart = true;\r\nDRM_ERROR("Command buffer error.\n");\r\nlist_del(&entry->list);\r\n__vmw_cmdbuf_header_free(entry);\r\nwake_up_all(&man->idle_queue);\r\n}\r\nspin_unlock_bh(&man->lock);\r\nif (restart && vmw_cmdbuf_startstop(man, true))\r\nDRM_ERROR("Failed restarting command buffer context 0.\n");\r\nvmw_fifo_send_fence(man->dev_priv, &dummy);\r\n}\r\nstatic bool vmw_cmdbuf_man_idle(struct vmw_cmdbuf_man *man,\r\nbool check_preempted)\r\n{\r\nstruct vmw_cmdbuf_context *ctx;\r\nbool idle = false;\r\nint i;\r\nspin_lock_bh(&man->lock);\r\nvmw_cmdbuf_man_process(man);\r\nfor_each_cmdbuf_ctx(man, i, ctx) {\r\nif (!list_empty(&ctx->submitted) ||\r\n!list_empty(&ctx->hw_submitted) ||\r\n(check_preempted && !list_empty(&ctx->preempted)))\r\ngoto out_unlock;\r\n}\r\nidle = list_empty(&man->error);\r\nout_unlock:\r\nspin_unlock_bh(&man->lock);\r\nreturn idle;\r\n}\r\nstatic void __vmw_cmdbuf_cur_flush(struct vmw_cmdbuf_man *man)\r\n{\r\nstruct vmw_cmdbuf_header *cur = man->cur;\r\nWARN_ON(!mutex_is_locked(&man->cur_mutex));\r\nif (!cur)\r\nreturn;\r\nspin_lock_bh(&man->lock);\r\nif (man->cur_pos == 0) {\r\n__vmw_cmdbuf_header_free(cur);\r\ngoto out_unlock;\r\n}\r\nman->cur->cb_header->length = man->cur_pos;\r\nvmw_cmdbuf_ctx_add(man, man->cur, SVGA_CB_CONTEXT_0);\r\nout_unlock:\r\nspin_unlock_bh(&man->lock);\r\nman->cur = NULL;\r\nman->cur_pos = 0;\r\n}\r\nint vmw_cmdbuf_cur_flush(struct vmw_cmdbuf_man *man,\r\nbool interruptible)\r\n{\r\nint ret = vmw_cmdbuf_cur_lock(man, interruptible);\r\nif (ret)\r\nreturn ret;\r\n__vmw_cmdbuf_cur_flush(man);\r\nvmw_cmdbuf_cur_unlock(man);\r\nreturn 0;\r\n}\r\nint vmw_cmdbuf_idle(struct vmw_cmdbuf_man *man, bool interruptible,\r\nunsigned long timeout)\r\n{\r\nint ret;\r\nret = vmw_cmdbuf_cur_flush(man, interruptible);\r\nvmw_generic_waiter_add(man->dev_priv,\r\nSVGA_IRQFLAG_COMMAND_BUFFER,\r\n&man->dev_priv->cmdbuf_waiters);\r\nif (interruptible) {\r\nret = wait_event_interruptible_timeout\r\n(man->idle_queue, vmw_cmdbuf_man_idle(man, true),\r\ntimeout);\r\n} else {\r\nret = wait_event_timeout\r\n(man->idle_queue, vmw_cmdbuf_man_idle(man, true),\r\ntimeout);\r\n}\r\nvmw_generic_waiter_remove(man->dev_priv,\r\nSVGA_IRQFLAG_COMMAND_BUFFER,\r\n&man->dev_priv->cmdbuf_waiters);\r\nif (ret == 0) {\r\nif (!vmw_cmdbuf_man_idle(man, true))\r\nret = -EBUSY;\r\nelse\r\nret = 0;\r\n}\r\nif (ret > 0)\r\nret = 0;\r\nreturn ret;\r\n}\r\nstatic bool vmw_cmdbuf_try_alloc(struct vmw_cmdbuf_man *man,\r\nstruct vmw_cmdbuf_alloc_info *info)\r\n{\r\nint ret;\r\nif (info->done)\r\nreturn true;\r\nmemset(info->node, 0, sizeof(*info->node));\r\nspin_lock_bh(&man->lock);\r\nret = drm_mm_insert_node_generic(&man->mm, info->node, info->page_size,\r\n0, 0,\r\nDRM_MM_SEARCH_DEFAULT,\r\nDRM_MM_CREATE_DEFAULT);\r\nif (ret) {\r\nvmw_cmdbuf_man_process(man);\r\nret = drm_mm_insert_node_generic(&man->mm, info->node,\r\ninfo->page_size, 0, 0,\r\nDRM_MM_SEARCH_DEFAULT,\r\nDRM_MM_CREATE_DEFAULT);\r\n}\r\nspin_unlock_bh(&man->lock);\r\ninfo->done = !ret;\r\nreturn info->done;\r\n}\r\nstatic int vmw_cmdbuf_alloc_space(struct vmw_cmdbuf_man *man,\r\nstruct drm_mm_node *node,\r\nsize_t size,\r\nbool interruptible)\r\n{\r\nstruct vmw_cmdbuf_alloc_info info;\r\ninfo.page_size = PAGE_ALIGN(size) >> PAGE_SHIFT;\r\ninfo.node = node;\r\ninfo.done = false;\r\nif (interruptible) {\r\nif (mutex_lock_interruptible(&man->space_mutex))\r\nreturn -ERESTARTSYS;\r\n} else {\r\nmutex_lock(&man->space_mutex);\r\n}\r\nif (vmw_cmdbuf_try_alloc(man, &info))\r\ngoto out_unlock;\r\nvmw_generic_waiter_add(man->dev_priv,\r\nSVGA_IRQFLAG_COMMAND_BUFFER,\r\n&man->dev_priv->cmdbuf_waiters);\r\nif (interruptible) {\r\nint ret;\r\nret = wait_event_interruptible\r\n(man->alloc_queue, vmw_cmdbuf_try_alloc(man, &info));\r\nif (ret) {\r\nvmw_generic_waiter_remove\r\n(man->dev_priv, SVGA_IRQFLAG_COMMAND_BUFFER,\r\n&man->dev_priv->cmdbuf_waiters);\r\nmutex_unlock(&man->space_mutex);\r\nreturn ret;\r\n}\r\n} else {\r\nwait_event(man->alloc_queue, vmw_cmdbuf_try_alloc(man, &info));\r\n}\r\nvmw_generic_waiter_remove(man->dev_priv,\r\nSVGA_IRQFLAG_COMMAND_BUFFER,\r\n&man->dev_priv->cmdbuf_waiters);\r\nout_unlock:\r\nmutex_unlock(&man->space_mutex);\r\nreturn 0;\r\n}\r\nstatic int vmw_cmdbuf_space_pool(struct vmw_cmdbuf_man *man,\r\nstruct vmw_cmdbuf_header *header,\r\nsize_t size,\r\nbool interruptible)\r\n{\r\nSVGACBHeader *cb_hdr;\r\nsize_t offset;\r\nint ret;\r\nif (!man->has_pool)\r\nreturn -ENOMEM;\r\nret = vmw_cmdbuf_alloc_space(man, &header->node, size, interruptible);\r\nif (ret)\r\nreturn ret;\r\nheader->cb_header = dma_pool_alloc(man->headers, GFP_KERNEL,\r\n&header->handle);\r\nif (!header->cb_header) {\r\nret = -ENOMEM;\r\ngoto out_no_cb_header;\r\n}\r\nheader->size = header->node.size << PAGE_SHIFT;\r\ncb_hdr = header->cb_header;\r\noffset = header->node.start << PAGE_SHIFT;\r\nheader->cmd = man->map + offset;\r\nmemset(cb_hdr, 0, sizeof(*cb_hdr));\r\nif (man->using_mob) {\r\ncb_hdr->flags = SVGA_CB_FLAG_MOB;\r\ncb_hdr->ptr.mob.mobid = man->cmd_space->mem.start;\r\ncb_hdr->ptr.mob.mobOffset = offset;\r\n} else {\r\ncb_hdr->ptr.pa = (u64)man->handle + (u64)offset;\r\n}\r\nreturn 0;\r\nout_no_cb_header:\r\nspin_lock_bh(&man->lock);\r\ndrm_mm_remove_node(&header->node);\r\nspin_unlock_bh(&man->lock);\r\nreturn ret;\r\n}\r\nstatic int vmw_cmdbuf_space_inline(struct vmw_cmdbuf_man *man,\r\nstruct vmw_cmdbuf_header *header,\r\nint size)\r\n{\r\nstruct vmw_cmdbuf_dheader *dheader;\r\nSVGACBHeader *cb_hdr;\r\nif (WARN_ON_ONCE(size > VMW_CMDBUF_INLINE_SIZE))\r\nreturn -ENOMEM;\r\ndheader = dma_pool_alloc(man->dheaders, GFP_KERNEL,\r\n&header->handle);\r\nif (!dheader)\r\nreturn -ENOMEM;\r\nheader->inline_space = true;\r\nheader->size = VMW_CMDBUF_INLINE_SIZE;\r\ncb_hdr = &dheader->cb_header;\r\nheader->cb_header = cb_hdr;\r\nheader->cmd = dheader->cmd;\r\nmemset(dheader, 0, sizeof(*dheader));\r\ncb_hdr->status = SVGA_CB_STATUS_NONE;\r\ncb_hdr->flags = SVGA_CB_FLAG_NONE;\r\ncb_hdr->ptr.pa = (u64)header->handle +\r\n(u64)offsetof(struct vmw_cmdbuf_dheader, cmd);\r\nreturn 0;\r\n}\r\nvoid *vmw_cmdbuf_alloc(struct vmw_cmdbuf_man *man,\r\nsize_t size, bool interruptible,\r\nstruct vmw_cmdbuf_header **p_header)\r\n{\r\nstruct vmw_cmdbuf_header *header;\r\nint ret = 0;\r\n*p_header = NULL;\r\nheader = kzalloc(sizeof(*header), GFP_KERNEL);\r\nif (!header)\r\nreturn ERR_PTR(-ENOMEM);\r\nif (size <= VMW_CMDBUF_INLINE_SIZE)\r\nret = vmw_cmdbuf_space_inline(man, header, size);\r\nelse\r\nret = vmw_cmdbuf_space_pool(man, header, size, interruptible);\r\nif (ret) {\r\nkfree(header);\r\nreturn ERR_PTR(ret);\r\n}\r\nheader->man = man;\r\nINIT_LIST_HEAD(&header->list);\r\nheader->cb_header->status = SVGA_CB_STATUS_NONE;\r\n*p_header = header;\r\nreturn header->cmd;\r\n}\r\nstatic void *vmw_cmdbuf_reserve_cur(struct vmw_cmdbuf_man *man,\r\nsize_t size,\r\nint ctx_id,\r\nbool interruptible)\r\n{\r\nstruct vmw_cmdbuf_header *cur;\r\nvoid *ret;\r\nif (vmw_cmdbuf_cur_lock(man, interruptible))\r\nreturn ERR_PTR(-ERESTARTSYS);\r\ncur = man->cur;\r\nif (cur && (size + man->cur_pos > cur->size ||\r\n((cur->cb_header->flags & SVGA_CB_FLAG_DX_CONTEXT) &&\r\nctx_id != cur->cb_header->dxContext)))\r\n__vmw_cmdbuf_cur_flush(man);\r\nif (!man->cur) {\r\nret = vmw_cmdbuf_alloc(man,\r\nmax_t(size_t, size, man->default_size),\r\ninterruptible, &man->cur);\r\nif (IS_ERR(ret)) {\r\nvmw_cmdbuf_cur_unlock(man);\r\nreturn ret;\r\n}\r\ncur = man->cur;\r\n}\r\nif (ctx_id != SVGA3D_INVALID_ID) {\r\ncur->cb_header->flags |= SVGA_CB_FLAG_DX_CONTEXT;\r\ncur->cb_header->dxContext = ctx_id;\r\n}\r\ncur->reserved = size;\r\nreturn (void *) (man->cur->cmd + man->cur_pos);\r\n}\r\nstatic void vmw_cmdbuf_commit_cur(struct vmw_cmdbuf_man *man,\r\nsize_t size, bool flush)\r\n{\r\nstruct vmw_cmdbuf_header *cur = man->cur;\r\nWARN_ON(!mutex_is_locked(&man->cur_mutex));\r\nWARN_ON(size > cur->reserved);\r\nman->cur_pos += size;\r\nif (!size)\r\ncur->cb_header->flags &= ~SVGA_CB_FLAG_DX_CONTEXT;\r\nif (flush)\r\n__vmw_cmdbuf_cur_flush(man);\r\nvmw_cmdbuf_cur_unlock(man);\r\n}\r\nvoid *vmw_cmdbuf_reserve(struct vmw_cmdbuf_man *man, size_t size,\r\nint ctx_id, bool interruptible,\r\nstruct vmw_cmdbuf_header *header)\r\n{\r\nif (!header)\r\nreturn vmw_cmdbuf_reserve_cur(man, size, ctx_id, interruptible);\r\nif (size > header->size)\r\nreturn ERR_PTR(-EINVAL);\r\nif (ctx_id != SVGA3D_INVALID_ID) {\r\nheader->cb_header->flags |= SVGA_CB_FLAG_DX_CONTEXT;\r\nheader->cb_header->dxContext = ctx_id;\r\n}\r\nheader->reserved = size;\r\nreturn header->cmd;\r\n}\r\nvoid vmw_cmdbuf_commit(struct vmw_cmdbuf_man *man, size_t size,\r\nstruct vmw_cmdbuf_header *header, bool flush)\r\n{\r\nif (!header) {\r\nvmw_cmdbuf_commit_cur(man, size, flush);\r\nreturn;\r\n}\r\n(void) vmw_cmdbuf_cur_lock(man, false);\r\n__vmw_cmdbuf_cur_flush(man);\r\nWARN_ON(size > header->reserved);\r\nman->cur = header;\r\nman->cur_pos = size;\r\nif (!size)\r\nheader->cb_header->flags &= ~SVGA_CB_FLAG_DX_CONTEXT;\r\nif (flush)\r\n__vmw_cmdbuf_cur_flush(man);\r\nvmw_cmdbuf_cur_unlock(man);\r\n}\r\nvoid vmw_cmdbuf_tasklet_schedule(struct vmw_cmdbuf_man *man)\r\n{\r\nif (!man)\r\nreturn;\r\ntasklet_schedule(&man->tasklet);\r\n}\r\nstatic int vmw_cmdbuf_send_device_command(struct vmw_cmdbuf_man *man,\r\nconst void *command,\r\nsize_t size)\r\n{\r\nstruct vmw_cmdbuf_header *header;\r\nint status;\r\nvoid *cmd = vmw_cmdbuf_alloc(man, size, false, &header);\r\nif (IS_ERR(cmd))\r\nreturn PTR_ERR(cmd);\r\nmemcpy(cmd, command, size);\r\nheader->cb_header->length = size;\r\nheader->cb_context = SVGA_CB_CONTEXT_DEVICE;\r\nspin_lock_bh(&man->lock);\r\nstatus = vmw_cmdbuf_header_submit(header);\r\nspin_unlock_bh(&man->lock);\r\nvmw_cmdbuf_header_free(header);\r\nif (status != SVGA_CB_STATUS_COMPLETED) {\r\nDRM_ERROR("Device context command failed with status %d\n",\r\nstatus);\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic int vmw_cmdbuf_startstop(struct vmw_cmdbuf_man *man,\r\nbool enable)\r\n{\r\nstruct {\r\nuint32 id;\r\nSVGADCCmdStartStop body;\r\n} __packed cmd;\r\ncmd.id = SVGA_DC_CMD_START_STOP_CONTEXT;\r\ncmd.body.enable = (enable) ? 1 : 0;\r\ncmd.body.context = SVGA_CB_CONTEXT_0;\r\nreturn vmw_cmdbuf_send_device_command(man, &cmd, sizeof(cmd));\r\n}\r\nint vmw_cmdbuf_set_pool_size(struct vmw_cmdbuf_man *man,\r\nsize_t size, size_t default_size)\r\n{\r\nstruct vmw_private *dev_priv = man->dev_priv;\r\nbool dummy;\r\nint ret;\r\nif (man->has_pool)\r\nreturn -EINVAL;\r\nsize = PAGE_ALIGN(size);\r\nman->map = dma_alloc_coherent(&dev_priv->dev->pdev->dev, size,\r\n&man->handle, GFP_KERNEL);\r\nif (man->map) {\r\nman->using_mob = false;\r\n} else {\r\nif (!(dev_priv->capabilities & SVGA_CAP_DX))\r\nreturn -ENOMEM;\r\nret = ttm_bo_create(&dev_priv->bdev, size, ttm_bo_type_device,\r\n&vmw_mob_ne_placement, 0, false, NULL,\r\n&man->cmd_space);\r\nif (ret)\r\nreturn ret;\r\nman->using_mob = true;\r\nret = ttm_bo_kmap(man->cmd_space, 0, size >> PAGE_SHIFT,\r\n&man->map_obj);\r\nif (ret)\r\ngoto out_no_map;\r\nman->map = ttm_kmap_obj_virtual(&man->map_obj, &dummy);\r\n}\r\nman->size = size;\r\ndrm_mm_init(&man->mm, 0, size >> PAGE_SHIFT);\r\nman->has_pool = true;\r\nman->default_size = VMW_CMDBUF_INLINE_SIZE;\r\nDRM_INFO("Using command buffers with %s pool.\n",\r\n(man->using_mob) ? "MOB" : "DMA");\r\nreturn 0;\r\nout_no_map:\r\nif (man->using_mob)\r\nttm_bo_unref(&man->cmd_space);\r\nreturn ret;\r\n}\r\nstruct vmw_cmdbuf_man *vmw_cmdbuf_man_create(struct vmw_private *dev_priv)\r\n{\r\nstruct vmw_cmdbuf_man *man;\r\nstruct vmw_cmdbuf_context *ctx;\r\nint i;\r\nint ret;\r\nif (!(dev_priv->capabilities & SVGA_CAP_COMMAND_BUFFERS))\r\nreturn ERR_PTR(-ENOSYS);\r\nman = kzalloc(sizeof(*man), GFP_KERNEL);\r\nif (!man)\r\nreturn ERR_PTR(-ENOMEM);\r\nman->headers = dma_pool_create("vmwgfx cmdbuf",\r\n&dev_priv->dev->pdev->dev,\r\nsizeof(SVGACBHeader),\r\n64, PAGE_SIZE);\r\nif (!man->headers) {\r\nret = -ENOMEM;\r\ngoto out_no_pool;\r\n}\r\nman->dheaders = dma_pool_create("vmwgfx inline cmdbuf",\r\n&dev_priv->dev->pdev->dev,\r\nsizeof(struct vmw_cmdbuf_dheader),\r\n64, PAGE_SIZE);\r\nif (!man->dheaders) {\r\nret = -ENOMEM;\r\ngoto out_no_dpool;\r\n}\r\nfor_each_cmdbuf_ctx(man, i, ctx)\r\nvmw_cmdbuf_ctx_init(ctx);\r\nINIT_LIST_HEAD(&man->error);\r\nspin_lock_init(&man->lock);\r\nmutex_init(&man->cur_mutex);\r\nmutex_init(&man->space_mutex);\r\ntasklet_init(&man->tasklet, vmw_cmdbuf_man_tasklet,\r\n(unsigned long) man);\r\nman->default_size = VMW_CMDBUF_INLINE_SIZE;\r\ninit_waitqueue_head(&man->alloc_queue);\r\ninit_waitqueue_head(&man->idle_queue);\r\nman->dev_priv = dev_priv;\r\nman->max_hw_submitted = SVGA_CB_MAX_QUEUED_PER_CONTEXT - 1;\r\nINIT_WORK(&man->work, &vmw_cmdbuf_work_func);\r\nvmw_generic_waiter_add(dev_priv, SVGA_IRQFLAG_ERROR,\r\n&dev_priv->error_waiters);\r\nret = vmw_cmdbuf_startstop(man, true);\r\nif (ret) {\r\nDRM_ERROR("Failed starting command buffer context 0.\n");\r\nvmw_cmdbuf_man_destroy(man);\r\nreturn ERR_PTR(ret);\r\n}\r\nreturn man;\r\nout_no_dpool:\r\ndma_pool_destroy(man->headers);\r\nout_no_pool:\r\nkfree(man);\r\nreturn ERR_PTR(ret);\r\n}\r\nvoid vmw_cmdbuf_remove_pool(struct vmw_cmdbuf_man *man)\r\n{\r\nif (!man->has_pool)\r\nreturn;\r\nman->has_pool = false;\r\nman->default_size = VMW_CMDBUF_INLINE_SIZE;\r\n(void) vmw_cmdbuf_idle(man, false, 10*HZ);\r\nif (man->using_mob) {\r\n(void) ttm_bo_kunmap(&man->map_obj);\r\nttm_bo_unref(&man->cmd_space);\r\n} else {\r\ndma_free_coherent(&man->dev_priv->dev->pdev->dev,\r\nman->size, man->map, man->handle);\r\n}\r\n}\r\nvoid vmw_cmdbuf_man_destroy(struct vmw_cmdbuf_man *man)\r\n{\r\nWARN_ON_ONCE(man->has_pool);\r\n(void) vmw_cmdbuf_idle(man, false, 10*HZ);\r\nif (vmw_cmdbuf_startstop(man, false))\r\nDRM_ERROR("Failed stopping command buffer context 0.\n");\r\nvmw_generic_waiter_remove(man->dev_priv, SVGA_IRQFLAG_ERROR,\r\n&man->dev_priv->error_waiters);\r\ntasklet_kill(&man->tasklet);\r\n(void) cancel_work_sync(&man->work);\r\ndma_pool_destroy(man->dheaders);\r\ndma_pool_destroy(man->headers);\r\nmutex_destroy(&man->cur_mutex);\r\nmutex_destroy(&man->space_mutex);\r\nkfree(man);\r\n}
