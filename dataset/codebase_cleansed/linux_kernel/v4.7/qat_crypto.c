void qat_crypto_put_instance(struct qat_crypto_instance *inst)\r\n{\r\natomic_dec(&inst->refctr);\r\nadf_dev_put(inst->accel_dev);\r\n}\r\nstatic int qat_crypto_free_instances(struct adf_accel_dev *accel_dev)\r\n{\r\nstruct qat_crypto_instance *inst, *tmp;\r\nint i;\r\nlist_for_each_entry_safe(inst, tmp, &accel_dev->crypto_list, list) {\r\nfor (i = 0; i < atomic_read(&inst->refctr); i++)\r\nqat_crypto_put_instance(inst);\r\nif (inst->sym_tx)\r\nadf_remove_ring(inst->sym_tx);\r\nif (inst->sym_rx)\r\nadf_remove_ring(inst->sym_rx);\r\nif (inst->pke_tx)\r\nadf_remove_ring(inst->pke_tx);\r\nif (inst->pke_rx)\r\nadf_remove_ring(inst->pke_rx);\r\nlist_del(&inst->list);\r\nkfree(inst);\r\n}\r\nreturn 0;\r\n}\r\nstruct qat_crypto_instance *qat_crypto_get_instance_node(int node)\r\n{\r\nstruct adf_accel_dev *accel_dev = NULL, *tmp_dev;\r\nstruct qat_crypto_instance *inst = NULL, *tmp_inst;\r\nunsigned long best = ~0;\r\nlist_for_each_entry(tmp_dev, adf_devmgr_get_head(), list) {\r\nunsigned long ctr;\r\nif ((node == dev_to_node(&GET_DEV(tmp_dev)) ||\r\ndev_to_node(&GET_DEV(tmp_dev)) < 0) &&\r\nadf_dev_started(tmp_dev) &&\r\n!list_empty(&tmp_dev->crypto_list)) {\r\nctr = atomic_read(&tmp_dev->ref_count);\r\nif (best > ctr) {\r\naccel_dev = tmp_dev;\r\nbest = ctr;\r\n}\r\n}\r\n}\r\nif (!accel_dev) {\r\npr_info("QAT: Could not find a device on node %d\n", node);\r\nlist_for_each_entry(tmp_dev, adf_devmgr_get_head(), list) {\r\nif (adf_dev_started(tmp_dev) &&\r\n!list_empty(&tmp_dev->crypto_list)) {\r\naccel_dev = tmp_dev;\r\nbreak;\r\n}\r\n}\r\n}\r\nif (!accel_dev)\r\nreturn NULL;\r\nbest = ~0;\r\nlist_for_each_entry(tmp_inst, &accel_dev->crypto_list, list) {\r\nunsigned long ctr;\r\nctr = atomic_read(&tmp_inst->refctr);\r\nif (best > ctr) {\r\ninst = tmp_inst;\r\nbest = ctr;\r\n}\r\n}\r\nif (inst) {\r\nif (adf_dev_get(accel_dev)) {\r\ndev_err(&GET_DEV(accel_dev), "Could not increment dev refctr\n");\r\nreturn NULL;\r\n}\r\natomic_inc(&inst->refctr);\r\n}\r\nreturn inst;\r\n}\r\nint qat_crypto_dev_config(struct adf_accel_dev *accel_dev)\r\n{\r\nint cpus = num_online_cpus();\r\nint banks = GET_MAX_BANKS(accel_dev);\r\nint instances = min(cpus, banks);\r\nchar key[ADF_CFG_MAX_KEY_LEN_IN_BYTES];\r\nint i;\r\nunsigned long val;\r\nif (adf_cfg_section_add(accel_dev, ADF_KERNEL_SEC))\r\ngoto err;\r\nif (adf_cfg_section_add(accel_dev, "Accelerator0"))\r\ngoto err;\r\nfor (i = 0; i < instances; i++) {\r\nval = i;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_BANK_NUM, i);\r\nif (adf_cfg_add_key_value_param(accel_dev, ADF_KERNEL_SEC,\r\nkey, (void *)&val, ADF_DEC))\r\ngoto err;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_ETRMGR_CORE_AFFINITY,\r\ni);\r\nif (adf_cfg_add_key_value_param(accel_dev, ADF_KERNEL_SEC,\r\nkey, (void *)&val, ADF_DEC))\r\ngoto err;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_ASYM_SIZE, i);\r\nval = 128;\r\nif (adf_cfg_add_key_value_param(accel_dev, ADF_KERNEL_SEC,\r\nkey, (void *)&val, ADF_DEC))\r\ngoto err;\r\nval = 512;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_SYM_SIZE, i);\r\nif (adf_cfg_add_key_value_param(accel_dev, ADF_KERNEL_SEC,\r\nkey, (void *)&val, ADF_DEC))\r\ngoto err;\r\nval = 0;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_ASYM_TX, i);\r\nif (adf_cfg_add_key_value_param(accel_dev, ADF_KERNEL_SEC,\r\nkey, (void *)&val, ADF_DEC))\r\ngoto err;\r\nval = 2;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_SYM_TX, i);\r\nif (adf_cfg_add_key_value_param(accel_dev, ADF_KERNEL_SEC,\r\nkey, (void *)&val, ADF_DEC))\r\ngoto err;\r\nval = 8;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_ASYM_RX, i);\r\nif (adf_cfg_add_key_value_param(accel_dev, ADF_KERNEL_SEC,\r\nkey, (void *)&val, ADF_DEC))\r\ngoto err;\r\nval = 10;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_SYM_RX, i);\r\nif (adf_cfg_add_key_value_param(accel_dev, ADF_KERNEL_SEC,\r\nkey, (void *)&val, ADF_DEC))\r\ngoto err;\r\nval = ADF_COALESCING_DEF_TIME;\r\nsnprintf(key, sizeof(key), ADF_ETRMGR_COALESCE_TIMER_FORMAT, i);\r\nif (adf_cfg_add_key_value_param(accel_dev, "Accelerator0",\r\nkey, (void *)&val, ADF_DEC))\r\ngoto err;\r\n}\r\nval = i;\r\nif (adf_cfg_add_key_value_param(accel_dev, ADF_KERNEL_SEC,\r\nADF_NUM_CY, (void *)&val, ADF_DEC))\r\ngoto err;\r\nset_bit(ADF_STATUS_CONFIGURED, &accel_dev->status);\r\nreturn 0;\r\nerr:\r\ndev_err(&GET_DEV(accel_dev), "Failed to start QAT accel dev\n");\r\nreturn -EINVAL;\r\n}\r\nstatic int qat_crypto_create_instances(struct adf_accel_dev *accel_dev)\r\n{\r\nint i;\r\nunsigned long bank;\r\nunsigned long num_inst, num_msg_sym, num_msg_asym;\r\nint msg_size;\r\nstruct qat_crypto_instance *inst;\r\nchar key[ADF_CFG_MAX_KEY_LEN_IN_BYTES];\r\nchar val[ADF_CFG_MAX_VAL_LEN_IN_BYTES];\r\nINIT_LIST_HEAD(&accel_dev->crypto_list);\r\nstrlcpy(key, ADF_NUM_CY, sizeof(key));\r\nif (adf_cfg_get_param_value(accel_dev, SEC, key, val))\r\nreturn -EFAULT;\r\nif (kstrtoul(val, 0, &num_inst))\r\nreturn -EFAULT;\r\nfor (i = 0; i < num_inst; i++) {\r\ninst = kzalloc_node(sizeof(*inst), GFP_KERNEL,\r\ndev_to_node(&GET_DEV(accel_dev)));\r\nif (!inst)\r\ngoto err;\r\nlist_add_tail(&inst->list, &accel_dev->crypto_list);\r\ninst->id = i;\r\natomic_set(&inst->refctr, 0);\r\ninst->accel_dev = accel_dev;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_BANK_NUM, i);\r\nif (adf_cfg_get_param_value(accel_dev, SEC, key, val))\r\ngoto err;\r\nif (kstrtoul(val, 10, &bank))\r\ngoto err;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_SYM_SIZE, i);\r\nif (adf_cfg_get_param_value(accel_dev, SEC, key, val))\r\ngoto err;\r\nif (kstrtoul(val, 10, &num_msg_sym))\r\ngoto err;\r\nnum_msg_sym = num_msg_sym >> 1;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_ASYM_SIZE, i);\r\nif (adf_cfg_get_param_value(accel_dev, SEC, key, val))\r\ngoto err;\r\nif (kstrtoul(val, 10, &num_msg_asym))\r\ngoto err;\r\nnum_msg_asym = num_msg_asym >> 1;\r\nmsg_size = ICP_QAT_FW_REQ_DEFAULT_SZ;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_SYM_TX, i);\r\nif (adf_create_ring(accel_dev, SEC, bank, num_msg_sym,\r\nmsg_size, key, NULL, 0, &inst->sym_tx))\r\ngoto err;\r\nmsg_size = msg_size >> 1;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_ASYM_TX, i);\r\nif (adf_create_ring(accel_dev, SEC, bank, num_msg_asym,\r\nmsg_size, key, NULL, 0, &inst->pke_tx))\r\ngoto err;\r\nmsg_size = ICP_QAT_FW_RESP_DEFAULT_SZ;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_SYM_RX, i);\r\nif (adf_create_ring(accel_dev, SEC, bank, num_msg_sym,\r\nmsg_size, key, qat_alg_callback, 0,\r\n&inst->sym_rx))\r\ngoto err;\r\nsnprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_ASYM_RX, i);\r\nif (adf_create_ring(accel_dev, SEC, bank, num_msg_asym,\r\nmsg_size, key, qat_alg_asym_callback, 0,\r\n&inst->pke_rx))\r\ngoto err;\r\n}\r\nreturn 0;\r\nerr:\r\nqat_crypto_free_instances(accel_dev);\r\nreturn -ENOMEM;\r\n}\r\nstatic int qat_crypto_init(struct adf_accel_dev *accel_dev)\r\n{\r\nif (qat_crypto_create_instances(accel_dev))\r\nreturn -EFAULT;\r\nreturn 0;\r\n}\r\nstatic int qat_crypto_shutdown(struct adf_accel_dev *accel_dev)\r\n{\r\nreturn qat_crypto_free_instances(accel_dev);\r\n}\r\nstatic int qat_crypto_event_handler(struct adf_accel_dev *accel_dev,\r\nenum adf_event event)\r\n{\r\nint ret;\r\nswitch (event) {\r\ncase ADF_EVENT_INIT:\r\nret = qat_crypto_init(accel_dev);\r\nbreak;\r\ncase ADF_EVENT_SHUTDOWN:\r\nret = qat_crypto_shutdown(accel_dev);\r\nbreak;\r\ncase ADF_EVENT_RESTARTING:\r\ncase ADF_EVENT_RESTARTED:\r\ncase ADF_EVENT_START:\r\ncase ADF_EVENT_STOP:\r\ndefault:\r\nret = 0;\r\n}\r\nreturn ret;\r\n}\r\nint qat_crypto_register(void)\r\n{\r\nmemset(&qat_crypto, 0, sizeof(qat_crypto));\r\nqat_crypto.event_hld = qat_crypto_event_handler;\r\nqat_crypto.name = "qat_crypto";\r\nreturn adf_service_register(&qat_crypto);\r\n}\r\nint qat_crypto_unregister(void)\r\n{\r\nreturn adf_service_unregister(&qat_crypto);\r\n}
