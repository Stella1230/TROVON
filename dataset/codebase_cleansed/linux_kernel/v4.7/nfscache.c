static unsigned int\r\nnfsd_cache_size_limit(void)\r\n{\r\nunsigned int limit;\r\nunsigned long low_pages = totalram_pages - totalhigh_pages;\r\nlimit = (16 * int_sqrt(low_pages)) << (PAGE_SHIFT-10);\r\nreturn min_t(unsigned int, limit, 256*1024);\r\n}\r\nstatic unsigned int\r\nnfsd_hashsize(unsigned int limit)\r\n{\r\nreturn roundup_pow_of_two(limit / TARGET_BUCKET_SIZE);\r\n}\r\nstatic u32\r\nnfsd_cache_hash(__be32 xid)\r\n{\r\nreturn hash_32(be32_to_cpu(xid), maskbits);\r\n}\r\nstatic struct svc_cacherep *\r\nnfsd_reply_cache_alloc(void)\r\n{\r\nstruct svc_cacherep *rp;\r\nrp = kmem_cache_alloc(drc_slab, GFP_KERNEL);\r\nif (rp) {\r\nrp->c_state = RC_UNUSED;\r\nrp->c_type = RC_NOCACHE;\r\nINIT_LIST_HEAD(&rp->c_lru);\r\n}\r\nreturn rp;\r\n}\r\nstatic void\r\nnfsd_reply_cache_free_locked(struct svc_cacherep *rp)\r\n{\r\nif (rp->c_type == RC_REPLBUFF && rp->c_replvec.iov_base) {\r\ndrc_mem_usage -= rp->c_replvec.iov_len;\r\nkfree(rp->c_replvec.iov_base);\r\n}\r\nlist_del(&rp->c_lru);\r\natomic_dec(&num_drc_entries);\r\ndrc_mem_usage -= sizeof(*rp);\r\nkmem_cache_free(drc_slab, rp);\r\n}\r\nstatic void\r\nnfsd_reply_cache_free(struct nfsd_drc_bucket *b, struct svc_cacherep *rp)\r\n{\r\nspin_lock(&b->cache_lock);\r\nnfsd_reply_cache_free_locked(rp);\r\nspin_unlock(&b->cache_lock);\r\n}\r\nint nfsd_reply_cache_init(void)\r\n{\r\nunsigned int hashsize;\r\nunsigned int i;\r\nint status = 0;\r\nmax_drc_entries = nfsd_cache_size_limit();\r\natomic_set(&num_drc_entries, 0);\r\nhashsize = nfsd_hashsize(max_drc_entries);\r\nmaskbits = ilog2(hashsize);\r\nstatus = register_shrinker(&nfsd_reply_cache_shrinker);\r\nif (status)\r\nreturn status;\r\ndrc_slab = kmem_cache_create("nfsd_drc", sizeof(struct svc_cacherep),\r\n0, 0, NULL);\r\nif (!drc_slab)\r\ngoto out_nomem;\r\ndrc_hashtbl = kcalloc(hashsize, sizeof(*drc_hashtbl), GFP_KERNEL);\r\nif (!drc_hashtbl)\r\ngoto out_nomem;\r\nfor (i = 0; i < hashsize; i++) {\r\nINIT_LIST_HEAD(&drc_hashtbl[i].lru_head);\r\nspin_lock_init(&drc_hashtbl[i].cache_lock);\r\n}\r\ndrc_hashsize = hashsize;\r\nreturn 0;\r\nout_nomem:\r\nprintk(KERN_ERR "nfsd: failed to allocate reply cache\n");\r\nnfsd_reply_cache_shutdown();\r\nreturn -ENOMEM;\r\n}\r\nvoid nfsd_reply_cache_shutdown(void)\r\n{\r\nstruct svc_cacherep *rp;\r\nunsigned int i;\r\nunregister_shrinker(&nfsd_reply_cache_shrinker);\r\nfor (i = 0; i < drc_hashsize; i++) {\r\nstruct list_head *head = &drc_hashtbl[i].lru_head;\r\nwhile (!list_empty(head)) {\r\nrp = list_first_entry(head, struct svc_cacherep, c_lru);\r\nnfsd_reply_cache_free_locked(rp);\r\n}\r\n}\r\nkfree (drc_hashtbl);\r\ndrc_hashtbl = NULL;\r\ndrc_hashsize = 0;\r\nkmem_cache_destroy(drc_slab);\r\ndrc_slab = NULL;\r\n}\r\nstatic void\r\nlru_put_end(struct nfsd_drc_bucket *b, struct svc_cacherep *rp)\r\n{\r\nrp->c_timestamp = jiffies;\r\nlist_move_tail(&rp->c_lru, &b->lru_head);\r\n}\r\nstatic long\r\nprune_bucket(struct nfsd_drc_bucket *b)\r\n{\r\nstruct svc_cacherep *rp, *tmp;\r\nlong freed = 0;\r\nlist_for_each_entry_safe(rp, tmp, &b->lru_head, c_lru) {\r\nif (rp->c_state == RC_INPROG)\r\ncontinue;\r\nif (atomic_read(&num_drc_entries) <= max_drc_entries &&\r\ntime_before(jiffies, rp->c_timestamp + RC_EXPIRE))\r\nbreak;\r\nnfsd_reply_cache_free_locked(rp);\r\nfreed++;\r\n}\r\nreturn freed;\r\n}\r\nstatic long\r\nprune_cache_entries(void)\r\n{\r\nunsigned int i;\r\nlong freed = 0;\r\nfor (i = 0; i < drc_hashsize; i++) {\r\nstruct nfsd_drc_bucket *b = &drc_hashtbl[i];\r\nif (list_empty(&b->lru_head))\r\ncontinue;\r\nspin_lock(&b->cache_lock);\r\nfreed += prune_bucket(b);\r\nspin_unlock(&b->cache_lock);\r\n}\r\nreturn freed;\r\n}\r\nstatic unsigned long\r\nnfsd_reply_cache_count(struct shrinker *shrink, struct shrink_control *sc)\r\n{\r\nreturn atomic_read(&num_drc_entries);\r\n}\r\nstatic unsigned long\r\nnfsd_reply_cache_scan(struct shrinker *shrink, struct shrink_control *sc)\r\n{\r\nreturn prune_cache_entries();\r\n}\r\nstatic __wsum\r\nnfsd_cache_csum(struct svc_rqst *rqstp)\r\n{\r\nint idx;\r\nunsigned int base;\r\n__wsum csum;\r\nstruct xdr_buf *buf = &rqstp->rq_arg;\r\nconst unsigned char *p = buf->head[0].iov_base;\r\nsize_t csum_len = min_t(size_t, buf->head[0].iov_len + buf->page_len,\r\nRC_CSUMLEN);\r\nsize_t len = min(buf->head[0].iov_len, csum_len);\r\ncsum = csum_partial(p, len, 0);\r\ncsum_len -= len;\r\nidx = buf->page_base / PAGE_SIZE;\r\nbase = buf->page_base & ~PAGE_MASK;\r\nwhile (csum_len) {\r\np = page_address(buf->pages[idx]) + base;\r\nlen = min_t(size_t, PAGE_SIZE - base, csum_len);\r\ncsum = csum_partial(p, len, csum);\r\ncsum_len -= len;\r\nbase = 0;\r\n++idx;\r\n}\r\nreturn csum;\r\n}\r\nstatic bool\r\nnfsd_cache_match(struct svc_rqst *rqstp, __wsum csum, struct svc_cacherep *rp)\r\n{\r\nif (rqstp->rq_xid != rp->c_xid)\r\nreturn false;\r\nif (csum != rp->c_csum) {\r\n++payload_misses;\r\nreturn false;\r\n}\r\nif (rqstp->rq_proc != rp->c_proc ||\r\nrqstp->rq_prot != rp->c_prot ||\r\nrqstp->rq_vers != rp->c_vers ||\r\nrqstp->rq_arg.len != rp->c_len ||\r\n!rpc_cmp_addr(svc_addr(rqstp), (struct sockaddr *)&rp->c_addr) ||\r\nrpc_get_port(svc_addr(rqstp)) != rpc_get_port((struct sockaddr *)&rp->c_addr))\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic struct svc_cacherep *\r\nnfsd_cache_search(struct nfsd_drc_bucket *b, struct svc_rqst *rqstp,\r\n__wsum csum)\r\n{\r\nstruct svc_cacherep *rp, *ret = NULL;\r\nstruct list_head *rh = &b->lru_head;\r\nunsigned int entries = 0;\r\nlist_for_each_entry(rp, rh, c_lru) {\r\n++entries;\r\nif (nfsd_cache_match(rqstp, csum, rp)) {\r\nret = rp;\r\nbreak;\r\n}\r\n}\r\nif (entries > longest_chain) {\r\nlongest_chain = entries;\r\nlongest_chain_cachesize = atomic_read(&num_drc_entries);\r\n} else if (entries == longest_chain) {\r\nlongest_chain_cachesize = min_t(unsigned int,\r\nlongest_chain_cachesize,\r\natomic_read(&num_drc_entries));\r\n}\r\nreturn ret;\r\n}\r\nint\r\nnfsd_cache_lookup(struct svc_rqst *rqstp)\r\n{\r\nstruct svc_cacherep *rp, *found;\r\n__be32 xid = rqstp->rq_xid;\r\nu32 proto = rqstp->rq_prot,\r\nvers = rqstp->rq_vers,\r\nproc = rqstp->rq_proc;\r\n__wsum csum;\r\nu32 hash = nfsd_cache_hash(xid);\r\nstruct nfsd_drc_bucket *b = &drc_hashtbl[hash];\r\nunsigned long age;\r\nint type = rqstp->rq_cachetype;\r\nint rtn = RC_DOIT;\r\nrqstp->rq_cacherep = NULL;\r\nif (type == RC_NOCACHE) {\r\nnfsdstats.rcnocache++;\r\nreturn rtn;\r\n}\r\ncsum = nfsd_cache_csum(rqstp);\r\nrp = nfsd_reply_cache_alloc();\r\nspin_lock(&b->cache_lock);\r\nif (likely(rp)) {\r\natomic_inc(&num_drc_entries);\r\ndrc_mem_usage += sizeof(*rp);\r\n}\r\nprune_bucket(b);\r\nfound = nfsd_cache_search(b, rqstp, csum);\r\nif (found) {\r\nif (likely(rp))\r\nnfsd_reply_cache_free_locked(rp);\r\nrp = found;\r\ngoto found_entry;\r\n}\r\nif (!rp) {\r\ndprintk("nfsd: unable to allocate DRC entry!\n");\r\ngoto out;\r\n}\r\nnfsdstats.rcmisses++;\r\nrqstp->rq_cacherep = rp;\r\nrp->c_state = RC_INPROG;\r\nrp->c_xid = xid;\r\nrp->c_proc = proc;\r\nrpc_copy_addr((struct sockaddr *)&rp->c_addr, svc_addr(rqstp));\r\nrpc_set_port((struct sockaddr *)&rp->c_addr, rpc_get_port(svc_addr(rqstp)));\r\nrp->c_prot = proto;\r\nrp->c_vers = vers;\r\nrp->c_len = rqstp->rq_arg.len;\r\nrp->c_csum = csum;\r\nlru_put_end(b, rp);\r\nif (rp->c_type == RC_REPLBUFF) {\r\ndrc_mem_usage -= rp->c_replvec.iov_len;\r\nkfree(rp->c_replvec.iov_base);\r\nrp->c_replvec.iov_base = NULL;\r\n}\r\nrp->c_type = RC_NOCACHE;\r\nout:\r\nspin_unlock(&b->cache_lock);\r\nreturn rtn;\r\nfound_entry:\r\nnfsdstats.rchits++;\r\nage = jiffies - rp->c_timestamp;\r\nlru_put_end(b, rp);\r\nrtn = RC_DROPIT;\r\nif (rp->c_state == RC_INPROG || age < RC_DELAY)\r\ngoto out;\r\nrtn = RC_DOIT;\r\nif (!test_bit(RQ_SECURE, &rqstp->rq_flags) && rp->c_secure)\r\ngoto out;\r\nswitch (rp->c_type) {\r\ncase RC_NOCACHE:\r\nbreak;\r\ncase RC_REPLSTAT:\r\nsvc_putu32(&rqstp->rq_res.head[0], rp->c_replstat);\r\nrtn = RC_REPLY;\r\nbreak;\r\ncase RC_REPLBUFF:\r\nif (!nfsd_cache_append(rqstp, &rp->c_replvec))\r\ngoto out;\r\nrtn = RC_REPLY;\r\nbreak;\r\ndefault:\r\nprintk(KERN_WARNING "nfsd: bad repcache type %d\n", rp->c_type);\r\nnfsd_reply_cache_free_locked(rp);\r\n}\r\ngoto out;\r\n}\r\nvoid\r\nnfsd_cache_update(struct svc_rqst *rqstp, int cachetype, __be32 *statp)\r\n{\r\nstruct svc_cacherep *rp = rqstp->rq_cacherep;\r\nstruct kvec *resv = &rqstp->rq_res.head[0], *cachv;\r\nu32 hash;\r\nstruct nfsd_drc_bucket *b;\r\nint len;\r\nsize_t bufsize = 0;\r\nif (!rp)\r\nreturn;\r\nhash = nfsd_cache_hash(rp->c_xid);\r\nb = &drc_hashtbl[hash];\r\nlen = resv->iov_len - ((char*)statp - (char*)resv->iov_base);\r\nlen >>= 2;\r\nif (!statp || len > (256 >> 2)) {\r\nnfsd_reply_cache_free(b, rp);\r\nreturn;\r\n}\r\nswitch (cachetype) {\r\ncase RC_REPLSTAT:\r\nif (len != 1)\r\nprintk("nfsd: RC_REPLSTAT/reply len %d!\n",len);\r\nrp->c_replstat = *statp;\r\nbreak;\r\ncase RC_REPLBUFF:\r\ncachv = &rp->c_replvec;\r\nbufsize = len << 2;\r\ncachv->iov_base = kmalloc(bufsize, GFP_KERNEL);\r\nif (!cachv->iov_base) {\r\nnfsd_reply_cache_free(b, rp);\r\nreturn;\r\n}\r\ncachv->iov_len = bufsize;\r\nmemcpy(cachv->iov_base, statp, bufsize);\r\nbreak;\r\ncase RC_NOCACHE:\r\nnfsd_reply_cache_free(b, rp);\r\nreturn;\r\n}\r\nspin_lock(&b->cache_lock);\r\ndrc_mem_usage += bufsize;\r\nlru_put_end(b, rp);\r\nrp->c_secure = test_bit(RQ_SECURE, &rqstp->rq_flags);\r\nrp->c_type = cachetype;\r\nrp->c_state = RC_DONE;\r\nspin_unlock(&b->cache_lock);\r\nreturn;\r\n}\r\nstatic int\r\nnfsd_cache_append(struct svc_rqst *rqstp, struct kvec *data)\r\n{\r\nstruct kvec *vec = &rqstp->rq_res.head[0];\r\nif (vec->iov_len + data->iov_len > PAGE_SIZE) {\r\nprintk(KERN_WARNING "nfsd: cached reply too large (%Zd).\n",\r\ndata->iov_len);\r\nreturn 0;\r\n}\r\nmemcpy((char*)vec->iov_base + vec->iov_len, data->iov_base, data->iov_len);\r\nvec->iov_len += data->iov_len;\r\nreturn 1;\r\n}\r\nstatic int nfsd_reply_cache_stats_show(struct seq_file *m, void *v)\r\n{\r\nseq_printf(m, "max entries: %u\n", max_drc_entries);\r\nseq_printf(m, "num entries: %u\n",\r\natomic_read(&num_drc_entries));\r\nseq_printf(m, "hash buckets: %u\n", 1 << maskbits);\r\nseq_printf(m, "mem usage: %u\n", drc_mem_usage);\r\nseq_printf(m, "cache hits: %u\n", nfsdstats.rchits);\r\nseq_printf(m, "cache misses: %u\n", nfsdstats.rcmisses);\r\nseq_printf(m, "not cached: %u\n", nfsdstats.rcnocache);\r\nseq_printf(m, "payload misses: %u\n", payload_misses);\r\nseq_printf(m, "longest chain len: %u\n", longest_chain);\r\nseq_printf(m, "cachesize at longest: %u\n", longest_chain_cachesize);\r\nreturn 0;\r\n}\r\nint nfsd_reply_cache_stats_open(struct inode *inode, struct file *file)\r\n{\r\nreturn single_open(file, nfsd_reply_cache_stats_show, NULL);\r\n}
