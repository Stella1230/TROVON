struct kvmppc_spapr_tce_table *kvmppc_find_table(struct kvm_vcpu *vcpu,\r\nunsigned long liobn)\r\n{\r\nstruct kvm *kvm = vcpu->kvm;\r\nstruct kvmppc_spapr_tce_table *stt;\r\nlist_for_each_entry_lockless(stt, &kvm->arch.spapr_tce_tables, list)\r\nif (stt->liobn == liobn)\r\nreturn stt;\r\nreturn NULL;\r\n}\r\nlong kvmppc_ioba_validate(struct kvmppc_spapr_tce_table *stt,\r\nunsigned long ioba, unsigned long npages)\r\n{\r\nunsigned long mask = (1ULL << stt->page_shift) - 1;\r\nunsigned long idx = ioba >> stt->page_shift;\r\nif ((ioba & mask) || (idx < stt->offset) ||\r\n(idx - stt->offset + npages > stt->size) ||\r\n(idx + npages < idx))\r\nreturn H_PARAMETER;\r\nreturn H_SUCCESS;\r\n}\r\nlong kvmppc_tce_validate(struct kvmppc_spapr_tce_table *stt, unsigned long tce)\r\n{\r\nunsigned long page_mask = ~((1ULL << stt->page_shift) - 1);\r\nunsigned long mask = ~(page_mask | TCE_PCI_WRITE | TCE_PCI_READ);\r\nif (tce & mask)\r\nreturn H_PARAMETER;\r\nreturn H_SUCCESS;\r\n}\r\nstatic u64 *kvmppc_page_address(struct page *page)\r\n{\r\n#if defined(HASHED_PAGE_VIRTUAL) || defined(WANT_PAGE_VIRTUAL)\r\n#error TODO: fix to avoid page_address() here\r\n#endif\r\nreturn (u64 *) page_address(page);\r\n}\r\nvoid kvmppc_tce_put(struct kvmppc_spapr_tce_table *stt,\r\nunsigned long idx, unsigned long tce)\r\n{\r\nstruct page *page;\r\nu64 *tbl;\r\nidx -= stt->offset;\r\npage = stt->pages[idx / TCES_PER_PAGE];\r\ntbl = kvmppc_page_address(page);\r\ntbl[idx % TCES_PER_PAGE] = tce;\r\n}\r\nlong kvmppc_gpa_to_ua(struct kvm *kvm, unsigned long gpa,\r\nunsigned long *ua, unsigned long **prmap)\r\n{\r\nunsigned long gfn = gpa >> PAGE_SHIFT;\r\nstruct kvm_memory_slot *memslot;\r\nmemslot = search_memslots(kvm_memslots(kvm), gfn);\r\nif (!memslot)\r\nreturn -EINVAL;\r\n*ua = __gfn_to_hva_memslot(memslot, gfn) |\r\n(gpa & ~(PAGE_MASK | TCE_PCI_READ | TCE_PCI_WRITE));\r\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\r\nif (prmap)\r\n*prmap = &memslot->arch.rmap[gfn - memslot->base_gfn];\r\n#endif\r\nreturn 0;\r\n}\r\nlong kvmppc_rm_h_put_tce(struct kvm_vcpu *vcpu, unsigned long liobn,\r\nunsigned long ioba, unsigned long tce)\r\n{\r\nstruct kvmppc_spapr_tce_table *stt = kvmppc_find_table(vcpu, liobn);\r\nlong ret;\r\nif (!stt)\r\nreturn H_TOO_HARD;\r\nret = kvmppc_ioba_validate(stt, ioba, 1);\r\nif (ret != H_SUCCESS)\r\nreturn ret;\r\nret = kvmppc_tce_validate(stt, tce);\r\nif (ret != H_SUCCESS)\r\nreturn ret;\r\nkvmppc_tce_put(stt, ioba >> stt->page_shift, tce);\r\nreturn H_SUCCESS;\r\n}\r\nstatic long kvmppc_rm_ua_to_hpa(struct kvm_vcpu *vcpu,\r\nunsigned long ua, unsigned long *phpa)\r\n{\r\npte_t *ptep, pte;\r\nunsigned shift = 0;\r\nptep = __find_linux_pte_or_hugepte(vcpu->arch.pgdir, ua, NULL, &shift);\r\nif (!ptep || !pte_present(*ptep))\r\nreturn -ENXIO;\r\npte = *ptep;\r\nif (!shift)\r\nshift = PAGE_SHIFT;\r\nif (shift > PAGE_SHIFT)\r\nreturn -EAGAIN;\r\nif (!pte_young(pte))\r\nreturn -EAGAIN;\r\n*phpa = (pte_pfn(pte) << PAGE_SHIFT) | (ua & ((1ULL << shift) - 1)) |\r\n(ua & ~PAGE_MASK);\r\nreturn 0;\r\n}\r\nlong kvmppc_rm_h_put_tce_indirect(struct kvm_vcpu *vcpu,\r\nunsigned long liobn, unsigned long ioba,\r\nunsigned long tce_list, unsigned long npages)\r\n{\r\nstruct kvmppc_spapr_tce_table *stt;\r\nlong i, ret = H_SUCCESS;\r\nunsigned long tces, entry, ua = 0;\r\nunsigned long *rmap = NULL;\r\nstt = kvmppc_find_table(vcpu, liobn);\r\nif (!stt)\r\nreturn H_TOO_HARD;\r\nentry = ioba >> stt->page_shift;\r\nif (npages > 512)\r\nreturn H_PARAMETER;\r\nif (tce_list & (SZ_4K - 1))\r\nreturn H_PARAMETER;\r\nret = kvmppc_ioba_validate(stt, ioba, npages);\r\nif (ret != H_SUCCESS)\r\nreturn ret;\r\nif (kvmppc_gpa_to_ua(vcpu->kvm, tce_list, &ua, &rmap))\r\nreturn H_TOO_HARD;\r\nrmap = (void *) vmalloc_to_phys(rmap);\r\nlock_rmap(rmap);\r\nif (kvmppc_rm_ua_to_hpa(vcpu, ua, &tces)) {\r\nret = H_TOO_HARD;\r\ngoto unlock_exit;\r\n}\r\nfor (i = 0; i < npages; ++i) {\r\nunsigned long tce = be64_to_cpu(((u64 *)tces)[i]);\r\nret = kvmppc_tce_validate(stt, tce);\r\nif (ret != H_SUCCESS)\r\ngoto unlock_exit;\r\nkvmppc_tce_put(stt, entry + i, tce);\r\n}\r\nunlock_exit:\r\nunlock_rmap(rmap);\r\nreturn ret;\r\n}\r\nlong kvmppc_rm_h_stuff_tce(struct kvm_vcpu *vcpu,\r\nunsigned long liobn, unsigned long ioba,\r\nunsigned long tce_value, unsigned long npages)\r\n{\r\nstruct kvmppc_spapr_tce_table *stt;\r\nlong i, ret;\r\nstt = kvmppc_find_table(vcpu, liobn);\r\nif (!stt)\r\nreturn H_TOO_HARD;\r\nret = kvmppc_ioba_validate(stt, ioba, npages);\r\nif (ret != H_SUCCESS)\r\nreturn ret;\r\nif (tce_value & (TCE_PCI_WRITE | TCE_PCI_READ))\r\nreturn H_PARAMETER;\r\nfor (i = 0; i < npages; ++i, ioba += (1ULL << stt->page_shift))\r\nkvmppc_tce_put(stt, ioba >> stt->page_shift, tce_value);\r\nreturn H_SUCCESS;\r\n}\r\nlong kvmppc_h_get_tce(struct kvm_vcpu *vcpu, unsigned long liobn,\r\nunsigned long ioba)\r\n{\r\nstruct kvmppc_spapr_tce_table *stt = kvmppc_find_table(vcpu, liobn);\r\nlong ret;\r\nunsigned long idx;\r\nstruct page *page;\r\nu64 *tbl;\r\nif (!stt)\r\nreturn H_TOO_HARD;\r\nret = kvmppc_ioba_validate(stt, ioba, 1);\r\nif (ret != H_SUCCESS)\r\nreturn ret;\r\nidx = (ioba >> stt->page_shift) - stt->offset;\r\npage = stt->pages[idx / TCES_PER_PAGE];\r\ntbl = (u64 *)page_address(page);\r\nvcpu->arch.gpr[4] = tbl[idx % TCES_PER_PAGE];\r\nreturn H_SUCCESS;\r\n}
