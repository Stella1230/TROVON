struct ni_power_info *ni_get_pi(struct radeon_device *rdev)\r\n{\r\nstruct ni_power_info *pi = rdev->pm.dpm.priv;\r\nreturn pi;\r\n}\r\nstruct ni_ps *ni_get_ps(struct radeon_ps *rps)\r\n{\r\nstruct ni_ps *ps = rps->ps_priv;\r\nreturn ps;\r\n}\r\nstatic void ni_calculate_leakage_for_v_and_t_formula(const struct ni_leakage_coeffients *coeff,\r\nu16 v, s32 t,\r\nu32 ileakage,\r\nu32 *leakage)\r\n{\r\ns64 kt, kv, leakage_w, i_leakage, vddc, temperature;\r\ni_leakage = div64_s64(drm_int2fixp(ileakage), 1000);\r\nvddc = div64_s64(drm_int2fixp(v), 1000);\r\ntemperature = div64_s64(drm_int2fixp(t), 1000);\r\nkt = drm_fixp_mul(div64_s64(drm_int2fixp(coeff->at), 1000),\r\ndrm_fixp_exp(drm_fixp_mul(div64_s64(drm_int2fixp(coeff->bt), 1000), temperature)));\r\nkv = drm_fixp_mul(div64_s64(drm_int2fixp(coeff->av), 1000),\r\ndrm_fixp_exp(drm_fixp_mul(div64_s64(drm_int2fixp(coeff->bv), 1000), vddc)));\r\nleakage_w = drm_fixp_mul(drm_fixp_mul(drm_fixp_mul(i_leakage, kt), kv), vddc);\r\n*leakage = drm_fixp2int(leakage_w * 1000);\r\n}\r\nstatic void ni_calculate_leakage_for_v_and_t(struct radeon_device *rdev,\r\nconst struct ni_leakage_coeffients *coeff,\r\nu16 v,\r\ns32 t,\r\nu32 i_leakage,\r\nu32 *leakage)\r\n{\r\nni_calculate_leakage_for_v_and_t_formula(coeff, v, t, i_leakage, leakage);\r\n}\r\nbool ni_dpm_vblank_too_short(struct radeon_device *rdev)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nu32 vblank_time = r600_dpm_get_vblank_time(rdev);\r\nu32 switch_limit = pi->mem_gddr5 ? 450 : 0;\r\nif (vblank_time < switch_limit)\r\nreturn true;\r\nelse\r\nreturn false;\r\n}\r\nstatic void ni_apply_state_adjust_rules(struct radeon_device *rdev,\r\nstruct radeon_ps *rps)\r\n{\r\nstruct ni_ps *ps = ni_get_ps(rps);\r\nstruct radeon_clock_and_voltage_limits *max_limits;\r\nbool disable_mclk_switching;\r\nu32 mclk;\r\nu16 vddci;\r\nint i;\r\nif ((rdev->pm.dpm.new_active_crtc_count > 1) ||\r\nni_dpm_vblank_too_short(rdev))\r\ndisable_mclk_switching = true;\r\nelse\r\ndisable_mclk_switching = false;\r\nif (rdev->pm.dpm.ac_power)\r\nmax_limits = &rdev->pm.dpm.dyn_state.max_clock_voltage_on_ac;\r\nelse\r\nmax_limits = &rdev->pm.dpm.dyn_state.max_clock_voltage_on_dc;\r\nif (rdev->pm.dpm.ac_power == false) {\r\nfor (i = 0; i < ps->performance_level_count; i++) {\r\nif (ps->performance_levels[i].mclk > max_limits->mclk)\r\nps->performance_levels[i].mclk = max_limits->mclk;\r\nif (ps->performance_levels[i].sclk > max_limits->sclk)\r\nps->performance_levels[i].sclk = max_limits->sclk;\r\nif (ps->performance_levels[i].vddc > max_limits->vddc)\r\nps->performance_levels[i].vddc = max_limits->vddc;\r\nif (ps->performance_levels[i].vddci > max_limits->vddci)\r\nps->performance_levels[i].vddci = max_limits->vddci;\r\n}\r\n}\r\nif (disable_mclk_switching) {\r\nps->performance_levels[0].mclk =\r\nps->performance_levels[ps->performance_level_count - 1].mclk;\r\nps->performance_levels[0].vddci =\r\nps->performance_levels[ps->performance_level_count - 1].vddci;\r\n}\r\nbtc_skip_blacklist_clocks(rdev, max_limits->sclk, max_limits->mclk,\r\n&ps->performance_levels[0].sclk,\r\n&ps->performance_levels[0].mclk);\r\nfor (i = 1; i < ps->performance_level_count; i++) {\r\nif (ps->performance_levels[i].sclk < ps->performance_levels[i - 1].sclk)\r\nps->performance_levels[i].sclk = ps->performance_levels[i - 1].sclk;\r\nif (ps->performance_levels[i].vddc < ps->performance_levels[i - 1].vddc)\r\nps->performance_levels[i].vddc = ps->performance_levels[i - 1].vddc;\r\n}\r\nif (disable_mclk_switching) {\r\nmclk = ps->performance_levels[0].mclk;\r\nvddci = ps->performance_levels[0].vddci;\r\nfor (i = 1; i < ps->performance_level_count; i++) {\r\nif (mclk < ps->performance_levels[i].mclk)\r\nmclk = ps->performance_levels[i].mclk;\r\nif (vddci < ps->performance_levels[i].vddci)\r\nvddci = ps->performance_levels[i].vddci;\r\n}\r\nfor (i = 0; i < ps->performance_level_count; i++) {\r\nps->performance_levels[i].mclk = mclk;\r\nps->performance_levels[i].vddci = vddci;\r\n}\r\n} else {\r\nfor (i = 1; i < ps->performance_level_count; i++) {\r\nif (ps->performance_levels[i].mclk < ps->performance_levels[i - 1].mclk)\r\nps->performance_levels[i].mclk = ps->performance_levels[i - 1].mclk;\r\nif (ps->performance_levels[i].vddci < ps->performance_levels[i - 1].vddci)\r\nps->performance_levels[i].vddci = ps->performance_levels[i - 1].vddci;\r\n}\r\n}\r\nfor (i = 1; i < ps->performance_level_count; i++)\r\nbtc_skip_blacklist_clocks(rdev, max_limits->sclk, max_limits->mclk,\r\n&ps->performance_levels[i].sclk,\r\n&ps->performance_levels[i].mclk);\r\nfor (i = 0; i < ps->performance_level_count; i++)\r\nbtc_adjust_clock_combinations(rdev, max_limits,\r\n&ps->performance_levels[i]);\r\nfor (i = 0; i < ps->performance_level_count; i++) {\r\nbtc_apply_voltage_dependency_rules(&rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk,\r\nps->performance_levels[i].sclk,\r\nmax_limits->vddc, &ps->performance_levels[i].vddc);\r\nbtc_apply_voltage_dependency_rules(&rdev->pm.dpm.dyn_state.vddci_dependency_on_mclk,\r\nps->performance_levels[i].mclk,\r\nmax_limits->vddci, &ps->performance_levels[i].vddci);\r\nbtc_apply_voltage_dependency_rules(&rdev->pm.dpm.dyn_state.vddc_dependency_on_mclk,\r\nps->performance_levels[i].mclk,\r\nmax_limits->vddc, &ps->performance_levels[i].vddc);\r\nbtc_apply_voltage_dependency_rules(&rdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk,\r\nrdev->clock.current_dispclk,\r\nmax_limits->vddc, &ps->performance_levels[i].vddc);\r\n}\r\nfor (i = 0; i < ps->performance_level_count; i++) {\r\nbtc_apply_voltage_delta_rules(rdev,\r\nmax_limits->vddc, max_limits->vddci,\r\n&ps->performance_levels[i].vddc,\r\n&ps->performance_levels[i].vddci);\r\n}\r\nps->dc_compatible = true;\r\nfor (i = 0; i < ps->performance_level_count; i++) {\r\nif (ps->performance_levels[i].vddc > rdev->pm.dpm.dyn_state.max_clock_voltage_on_dc.vddc)\r\nps->dc_compatible = false;\r\nif (ps->performance_levels[i].vddc < rdev->pm.dpm.dyn_state.min_vddc_for_pcie_gen2)\r\nps->performance_levels[i].flags &= ~ATOM_PPLIB_R600_FLAGS_PCIEGEN2;\r\n}\r\n}\r\nstatic void ni_cg_clockgating_default(struct radeon_device *rdev)\r\n{\r\nu32 count;\r\nconst u32 *ps = NULL;\r\nps = (const u32 *)&cayman_cgcg_cgls_default;\r\ncount = CAYMAN_CGCG_CGLS_DEFAULT_LENGTH;\r\nbtc_program_mgcg_hw_sequence(rdev, ps, count);\r\n}\r\nstatic void ni_gfx_clockgating_enable(struct radeon_device *rdev,\r\nbool enable)\r\n{\r\nu32 count;\r\nconst u32 *ps = NULL;\r\nif (enable) {\r\nps = (const u32 *)&cayman_cgcg_cgls_enable;\r\ncount = CAYMAN_CGCG_CGLS_ENABLE_LENGTH;\r\n} else {\r\nps = (const u32 *)&cayman_cgcg_cgls_disable;\r\ncount = CAYMAN_CGCG_CGLS_DISABLE_LENGTH;\r\n}\r\nbtc_program_mgcg_hw_sequence(rdev, ps, count);\r\n}\r\nstatic void ni_mg_clockgating_default(struct radeon_device *rdev)\r\n{\r\nu32 count;\r\nconst u32 *ps = NULL;\r\nps = (const u32 *)&cayman_mgcg_default;\r\ncount = CAYMAN_MGCG_DEFAULT_LENGTH;\r\nbtc_program_mgcg_hw_sequence(rdev, ps, count);\r\n}\r\nstatic void ni_mg_clockgating_enable(struct radeon_device *rdev,\r\nbool enable)\r\n{\r\nu32 count;\r\nconst u32 *ps = NULL;\r\nif (enable) {\r\nps = (const u32 *)&cayman_mgcg_enable;\r\ncount = CAYMAN_MGCG_ENABLE_LENGTH;\r\n} else {\r\nps = (const u32 *)&cayman_mgcg_disable;\r\ncount = CAYMAN_MGCG_DISABLE_LENGTH;\r\n}\r\nbtc_program_mgcg_hw_sequence(rdev, ps, count);\r\n}\r\nstatic void ni_ls_clockgating_default(struct radeon_device *rdev)\r\n{\r\nu32 count;\r\nconst u32 *ps = NULL;\r\nps = (const u32 *)&cayman_sysls_default;\r\ncount = CAYMAN_SYSLS_DEFAULT_LENGTH;\r\nbtc_program_mgcg_hw_sequence(rdev, ps, count);\r\n}\r\nstatic void ni_ls_clockgating_enable(struct radeon_device *rdev,\r\nbool enable)\r\n{\r\nu32 count;\r\nconst u32 *ps = NULL;\r\nif (enable) {\r\nps = (const u32 *)&cayman_sysls_enable;\r\ncount = CAYMAN_SYSLS_ENABLE_LENGTH;\r\n} else {\r\nps = (const u32 *)&cayman_sysls_disable;\r\ncount = CAYMAN_SYSLS_DISABLE_LENGTH;\r\n}\r\nbtc_program_mgcg_hw_sequence(rdev, ps, count);\r\n}\r\nstatic int ni_patch_single_dependency_table_based_on_leakage(struct radeon_device *rdev,\r\nstruct radeon_clock_voltage_dependency_table *table)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nu32 i;\r\nif (table) {\r\nfor (i = 0; i < table->count; i++) {\r\nif (0xff01 == table->entries[i].v) {\r\nif (pi->max_vddc == 0)\r\nreturn -EINVAL;\r\ntable->entries[i].v = pi->max_vddc;\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int ni_patch_dependency_tables_based_on_leakage(struct radeon_device *rdev)\r\n{\r\nint ret = 0;\r\nret = ni_patch_single_dependency_table_based_on_leakage(rdev,\r\n&rdev->pm.dpm.dyn_state.vddc_dependency_on_sclk);\r\nret = ni_patch_single_dependency_table_based_on_leakage(rdev,\r\n&rdev->pm.dpm.dyn_state.vddc_dependency_on_mclk);\r\nreturn ret;\r\n}\r\nstatic void ni_stop_dpm(struct radeon_device *rdev)\r\n{\r\nWREG32_P(GENERAL_PWRMGT, 0, ~GLOBAL_PWRMGT_EN);\r\n}\r\nstatic PPSMC_Result ni_send_msg_to_smc_with_parameter(struct radeon_device *rdev,\r\nPPSMC_Msg msg, u32 parameter)\r\n{\r\nWREG32(SMC_SCRATCH0, parameter);\r\nreturn rv770_send_msg_to_smc(rdev, msg);\r\n}\r\nstatic int ni_restrict_performance_levels_before_switch(struct radeon_device *rdev)\r\n{\r\nif (rv770_send_msg_to_smc(rdev, PPSMC_MSG_NoForcedLevel) != PPSMC_Result_OK)\r\nreturn -EINVAL;\r\nreturn (ni_send_msg_to_smc_with_parameter(rdev, PPSMC_MSG_SetEnabledLevels, 1) == PPSMC_Result_OK) ?\r\n0 : -EINVAL;\r\n}\r\nint ni_dpm_force_performance_level(struct radeon_device *rdev,\r\nenum radeon_dpm_forced_level level)\r\n{\r\nif (level == RADEON_DPM_FORCED_LEVEL_HIGH) {\r\nif (ni_send_msg_to_smc_with_parameter(rdev, PPSMC_MSG_SetEnabledLevels, 0) != PPSMC_Result_OK)\r\nreturn -EINVAL;\r\nif (ni_send_msg_to_smc_with_parameter(rdev, PPSMC_MSG_SetForcedLevels, 1) != PPSMC_Result_OK)\r\nreturn -EINVAL;\r\n} else if (level == RADEON_DPM_FORCED_LEVEL_LOW) {\r\nif (ni_send_msg_to_smc_with_parameter(rdev, PPSMC_MSG_SetForcedLevels, 0) != PPSMC_Result_OK)\r\nreturn -EINVAL;\r\nif (ni_send_msg_to_smc_with_parameter(rdev, PPSMC_MSG_SetEnabledLevels, 1) != PPSMC_Result_OK)\r\nreturn -EINVAL;\r\n} else if (level == RADEON_DPM_FORCED_LEVEL_AUTO) {\r\nif (ni_send_msg_to_smc_with_parameter(rdev, PPSMC_MSG_SetForcedLevels, 0) != PPSMC_Result_OK)\r\nreturn -EINVAL;\r\nif (ni_send_msg_to_smc_with_parameter(rdev, PPSMC_MSG_SetEnabledLevels, 0) != PPSMC_Result_OK)\r\nreturn -EINVAL;\r\n}\r\nrdev->pm.dpm.forced_level = level;\r\nreturn 0;\r\n}\r\nstatic void ni_stop_smc(struct radeon_device *rdev)\r\n{\r\nu32 tmp;\r\nint i;\r\nfor (i = 0; i < rdev->usec_timeout; i++) {\r\ntmp = RREG32(LB_SYNC_RESET_SEL) & LB_SYNC_RESET_SEL_MASK;\r\nif (tmp != 1)\r\nbreak;\r\nudelay(1);\r\n}\r\nudelay(100);\r\nr7xx_stop_smc(rdev);\r\n}\r\nstatic int ni_process_firmware_header(struct radeon_device *rdev)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nu32 tmp;\r\nint ret;\r\nret = rv770_read_smc_sram_dword(rdev,\r\nNISLANDS_SMC_FIRMWARE_HEADER_LOCATION +\r\nNISLANDS_SMC_FIRMWARE_HEADER_stateTable,\r\n&tmp, pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\npi->state_table_start = (u16)tmp;\r\nret = rv770_read_smc_sram_dword(rdev,\r\nNISLANDS_SMC_FIRMWARE_HEADER_LOCATION +\r\nNISLANDS_SMC_FIRMWARE_HEADER_softRegisters,\r\n&tmp, pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\npi->soft_regs_start = (u16)tmp;\r\nret = rv770_read_smc_sram_dword(rdev,\r\nNISLANDS_SMC_FIRMWARE_HEADER_LOCATION +\r\nNISLANDS_SMC_FIRMWARE_HEADER_mcRegisterTable,\r\n&tmp, pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\neg_pi->mc_reg_table_start = (u16)tmp;\r\nret = rv770_read_smc_sram_dword(rdev,\r\nNISLANDS_SMC_FIRMWARE_HEADER_LOCATION +\r\nNISLANDS_SMC_FIRMWARE_HEADER_fanTable,\r\n&tmp, pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\nni_pi->fan_table_start = (u16)tmp;\r\nret = rv770_read_smc_sram_dword(rdev,\r\nNISLANDS_SMC_FIRMWARE_HEADER_LOCATION +\r\nNISLANDS_SMC_FIRMWARE_HEADER_mcArbDramAutoRefreshTable,\r\n&tmp, pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\nni_pi->arb_table_start = (u16)tmp;\r\nret = rv770_read_smc_sram_dword(rdev,\r\nNISLANDS_SMC_FIRMWARE_HEADER_LOCATION +\r\nNISLANDS_SMC_FIRMWARE_HEADER_cacTable,\r\n&tmp, pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\nni_pi->cac_table_start = (u16)tmp;\r\nret = rv770_read_smc_sram_dword(rdev,\r\nNISLANDS_SMC_FIRMWARE_HEADER_LOCATION +\r\nNISLANDS_SMC_FIRMWARE_HEADER_spllTable,\r\n&tmp, pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\nni_pi->spll_table_start = (u16)tmp;\r\nreturn ret;\r\n}\r\nstatic void ni_read_clock_registers(struct radeon_device *rdev)\r\n{\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nni_pi->clock_registers.cg_spll_func_cntl = RREG32(CG_SPLL_FUNC_CNTL);\r\nni_pi->clock_registers.cg_spll_func_cntl_2 = RREG32(CG_SPLL_FUNC_CNTL_2);\r\nni_pi->clock_registers.cg_spll_func_cntl_3 = RREG32(CG_SPLL_FUNC_CNTL_3);\r\nni_pi->clock_registers.cg_spll_func_cntl_4 = RREG32(CG_SPLL_FUNC_CNTL_4);\r\nni_pi->clock_registers.cg_spll_spread_spectrum = RREG32(CG_SPLL_SPREAD_SPECTRUM);\r\nni_pi->clock_registers.cg_spll_spread_spectrum_2 = RREG32(CG_SPLL_SPREAD_SPECTRUM_2);\r\nni_pi->clock_registers.mpll_ad_func_cntl = RREG32(MPLL_AD_FUNC_CNTL);\r\nni_pi->clock_registers.mpll_ad_func_cntl_2 = RREG32(MPLL_AD_FUNC_CNTL_2);\r\nni_pi->clock_registers.mpll_dq_func_cntl = RREG32(MPLL_DQ_FUNC_CNTL);\r\nni_pi->clock_registers.mpll_dq_func_cntl_2 = RREG32(MPLL_DQ_FUNC_CNTL_2);\r\nni_pi->clock_registers.mclk_pwrmgt_cntl = RREG32(MCLK_PWRMGT_CNTL);\r\nni_pi->clock_registers.dll_cntl = RREG32(DLL_CNTL);\r\nni_pi->clock_registers.mpll_ss1 = RREG32(MPLL_SS1);\r\nni_pi->clock_registers.mpll_ss2 = RREG32(MPLL_SS2);\r\n}\r\nstatic void ni_program_response_times(struct radeon_device *rdev)\r\n{\r\nu32 voltage_response_time, backbias_response_time, acpi_delay_time, vbi_time_out;\r\nu32 vddc_dly, bb_dly, acpi_dly, vbi_dly, mclk_switch_limit;\r\nu32 reference_clock;\r\nrv770_write_smc_soft_register(rdev, NI_SMC_SOFT_REGISTER_mvdd_chg_time, 1);\r\nvoltage_response_time = (u32)rdev->pm.dpm.voltage_response_time;\r\nbackbias_response_time = (u32)rdev->pm.dpm.backbias_response_time;\r\nif (voltage_response_time == 0)\r\nvoltage_response_time = 1000;\r\nif (backbias_response_time == 0)\r\nbackbias_response_time = 1000;\r\nacpi_delay_time = 15000;\r\nvbi_time_out = 100000;\r\nreference_clock = radeon_get_xclk(rdev);\r\nvddc_dly = (voltage_response_time * reference_clock) / 1600;\r\nbb_dly = (backbias_response_time * reference_clock) / 1600;\r\nacpi_dly = (acpi_delay_time * reference_clock) / 1600;\r\nvbi_dly = (vbi_time_out * reference_clock) / 1600;\r\nmclk_switch_limit = (460 * reference_clock) / 100;\r\nrv770_write_smc_soft_register(rdev, NI_SMC_SOFT_REGISTER_delay_vreg, vddc_dly);\r\nrv770_write_smc_soft_register(rdev, NI_SMC_SOFT_REGISTER_delay_bbias, bb_dly);\r\nrv770_write_smc_soft_register(rdev, NI_SMC_SOFT_REGISTER_delay_acpi, acpi_dly);\r\nrv770_write_smc_soft_register(rdev, NI_SMC_SOFT_REGISTER_mclk_chg_timeout, vbi_dly);\r\nrv770_write_smc_soft_register(rdev, NI_SMC_SOFT_REGISTER_mc_block_delay, 0xAA);\r\nrv770_write_smc_soft_register(rdev, NI_SMC_SOFT_REGISTER_mclk_switch_lim, mclk_switch_limit);\r\n}\r\nstatic void ni_populate_smc_voltage_table(struct radeon_device *rdev,\r\nstruct atom_voltage_table *voltage_table,\r\nNISLANDS_SMC_STATETABLE *table)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < voltage_table->count; i++) {\r\ntable->highSMIO[i] = 0;\r\ntable->lowSMIO[i] |= cpu_to_be32(voltage_table->entries[i].smio_low);\r\n}\r\n}\r\nstatic void ni_populate_smc_voltage_tables(struct radeon_device *rdev,\r\nNISLANDS_SMC_STATETABLE *table)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nunsigned char i;\r\nif (eg_pi->vddc_voltage_table.count) {\r\nni_populate_smc_voltage_table(rdev, &eg_pi->vddc_voltage_table, table);\r\ntable->voltageMaskTable.highMask[NISLANDS_SMC_VOLTAGEMASK_VDDC] = 0;\r\ntable->voltageMaskTable.lowMask[NISLANDS_SMC_VOLTAGEMASK_VDDC] =\r\ncpu_to_be32(eg_pi->vddc_voltage_table.mask_low);\r\nfor (i = 0; i < eg_pi->vddc_voltage_table.count; i++) {\r\nif (pi->max_vddc_in_table <= eg_pi->vddc_voltage_table.entries[i].value) {\r\ntable->maxVDDCIndexInPPTable = i;\r\nbreak;\r\n}\r\n}\r\n}\r\nif (eg_pi->vddci_voltage_table.count) {\r\nni_populate_smc_voltage_table(rdev, &eg_pi->vddci_voltage_table, table);\r\ntable->voltageMaskTable.highMask[NISLANDS_SMC_VOLTAGEMASK_VDDCI] = 0;\r\ntable->voltageMaskTable.lowMask[NISLANDS_SMC_VOLTAGEMASK_VDDCI] =\r\ncpu_to_be32(eg_pi->vddci_voltage_table.mask_low);\r\n}\r\n}\r\nstatic int ni_populate_voltage_value(struct radeon_device *rdev,\r\nstruct atom_voltage_table *table,\r\nu16 value,\r\nNISLANDS_SMC_VOLTAGE_VALUE *voltage)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < table->count; i++) {\r\nif (value <= table->entries[i].value) {\r\nvoltage->index = (u8)i;\r\nvoltage->value = cpu_to_be16(table->entries[i].value);\r\nbreak;\r\n}\r\n}\r\nif (i >= table->count)\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic void ni_populate_mvdd_value(struct radeon_device *rdev,\r\nu32 mclk,\r\nNISLANDS_SMC_VOLTAGE_VALUE *voltage)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nif (!pi->mvdd_control) {\r\nvoltage->index = eg_pi->mvdd_high_index;\r\nvoltage->value = cpu_to_be16(MVDD_HIGH_VALUE);\r\nreturn;\r\n}\r\nif (mclk <= pi->mvdd_split_frequency) {\r\nvoltage->index = eg_pi->mvdd_low_index;\r\nvoltage->value = cpu_to_be16(MVDD_LOW_VALUE);\r\n} else {\r\nvoltage->index = eg_pi->mvdd_high_index;\r\nvoltage->value = cpu_to_be16(MVDD_HIGH_VALUE);\r\n}\r\n}\r\nstatic int ni_get_std_voltage_value(struct radeon_device *rdev,\r\nNISLANDS_SMC_VOLTAGE_VALUE *voltage,\r\nu16 *std_voltage)\r\n{\r\nif (rdev->pm.dpm.dyn_state.cac_leakage_table.entries &&\r\n((u32)voltage->index < rdev->pm.dpm.dyn_state.cac_leakage_table.count))\r\n*std_voltage = rdev->pm.dpm.dyn_state.cac_leakage_table.entries[voltage->index].vddc;\r\nelse\r\n*std_voltage = be16_to_cpu(voltage->value);\r\nreturn 0;\r\n}\r\nstatic void ni_populate_std_voltage_value(struct radeon_device *rdev,\r\nu16 value, u8 index,\r\nNISLANDS_SMC_VOLTAGE_VALUE *voltage)\r\n{\r\nvoltage->index = index;\r\nvoltage->value = cpu_to_be16(value);\r\n}\r\nstatic u32 ni_get_smc_power_scaling_factor(struct radeon_device *rdev)\r\n{\r\nu32 xclk_period;\r\nu32 xclk = radeon_get_xclk(rdev);\r\nu32 tmp = RREG32(CG_CAC_CTRL) & TID_CNT_MASK;\r\nxclk_period = (1000000000UL / xclk);\r\nxclk_period /= 10000UL;\r\nreturn tmp * xclk_period;\r\n}\r\nstatic u32 ni_scale_power_for_smc(u32 power_in_watts, u32 scaling_factor)\r\n{\r\nreturn (power_in_watts * scaling_factor) << 2;\r\n}\r\nstatic u32 ni_calculate_power_boost_limit(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state,\r\nu32 near_tdp_limit)\r\n{\r\nstruct ni_ps *state = ni_get_ps(radeon_state);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nu32 power_boost_limit = 0;\r\nint ret;\r\nif (ni_pi->enable_power_containment &&\r\nni_pi->use_power_boost_limit) {\r\nNISLANDS_SMC_VOLTAGE_VALUE vddc;\r\nu16 std_vddc_med;\r\nu16 std_vddc_high;\r\nu64 tmp, n, d;\r\nif (state->performance_level_count < 3)\r\nreturn 0;\r\nret = ni_populate_voltage_value(rdev, &eg_pi->vddc_voltage_table,\r\nstate->performance_levels[state->performance_level_count - 2].vddc,\r\n&vddc);\r\nif (ret)\r\nreturn 0;\r\nret = ni_get_std_voltage_value(rdev, &vddc, &std_vddc_med);\r\nif (ret)\r\nreturn 0;\r\nret = ni_populate_voltage_value(rdev, &eg_pi->vddc_voltage_table,\r\nstate->performance_levels[state->performance_level_count - 1].vddc,\r\n&vddc);\r\nif (ret)\r\nreturn 0;\r\nret = ni_get_std_voltage_value(rdev, &vddc, &std_vddc_high);\r\nif (ret)\r\nreturn 0;\r\nn = ((u64)near_tdp_limit * ((u64)std_vddc_med * (u64)std_vddc_med) * 90);\r\nd = ((u64)std_vddc_high * (u64)std_vddc_high * 100);\r\ntmp = div64_u64(n, d);\r\nif (tmp >> 32)\r\nreturn 0;\r\npower_boost_limit = (u32)tmp;\r\n}\r\nreturn power_boost_limit;\r\n}\r\nstatic int ni_calculate_adjusted_tdp_limits(struct radeon_device *rdev,\r\nbool adjust_polarity,\r\nu32 tdp_adjustment,\r\nu32 *tdp_limit,\r\nu32 *near_tdp_limit)\r\n{\r\nif (tdp_adjustment > (u32)rdev->pm.dpm.tdp_od_limit)\r\nreturn -EINVAL;\r\nif (adjust_polarity) {\r\n*tdp_limit = ((100 + tdp_adjustment) * rdev->pm.dpm.tdp_limit) / 100;\r\n*near_tdp_limit = rdev->pm.dpm.near_tdp_limit + (*tdp_limit - rdev->pm.dpm.tdp_limit);\r\n} else {\r\n*tdp_limit = ((100 - tdp_adjustment) * rdev->pm.dpm.tdp_limit) / 100;\r\n*near_tdp_limit = rdev->pm.dpm.near_tdp_limit - (rdev->pm.dpm.tdp_limit - *tdp_limit);\r\n}\r\nreturn 0;\r\n}\r\nstatic int ni_populate_smc_tdp_limits(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nif (ni_pi->enable_power_containment) {\r\nNISLANDS_SMC_STATETABLE *smc_table = &ni_pi->smc_statetable;\r\nu32 scaling_factor = ni_get_smc_power_scaling_factor(rdev);\r\nu32 tdp_limit;\r\nu32 near_tdp_limit;\r\nu32 power_boost_limit;\r\nint ret;\r\nif (scaling_factor == 0)\r\nreturn -EINVAL;\r\nmemset(smc_table, 0, sizeof(NISLANDS_SMC_STATETABLE));\r\nret = ni_calculate_adjusted_tdp_limits(rdev,\r\nfalse,\r\nrdev->pm.dpm.tdp_adjustment,\r\n&tdp_limit,\r\n&near_tdp_limit);\r\nif (ret)\r\nreturn ret;\r\npower_boost_limit = ni_calculate_power_boost_limit(rdev, radeon_state,\r\nnear_tdp_limit);\r\nsmc_table->dpm2Params.TDPLimit =\r\ncpu_to_be32(ni_scale_power_for_smc(tdp_limit, scaling_factor));\r\nsmc_table->dpm2Params.NearTDPLimit =\r\ncpu_to_be32(ni_scale_power_for_smc(near_tdp_limit, scaling_factor));\r\nsmc_table->dpm2Params.SafePowerLimit =\r\ncpu_to_be32(ni_scale_power_for_smc((near_tdp_limit * NISLANDS_DPM2_TDP_SAFE_LIMIT_PERCENT) / 100,\r\nscaling_factor));\r\nsmc_table->dpm2Params.PowerBoostLimit =\r\ncpu_to_be32(ni_scale_power_for_smc(power_boost_limit, scaling_factor));\r\nret = rv770_copy_bytes_to_smc(rdev,\r\n(u16)(pi->state_table_start + offsetof(NISLANDS_SMC_STATETABLE, dpm2Params) +\r\noffsetof(PP_NIslands_DPM2Parameters, TDPLimit)),\r\n(u8 *)(&smc_table->dpm2Params.TDPLimit),\r\nsizeof(u32) * 4, pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nint ni_copy_and_switch_arb_sets(struct radeon_device *rdev,\r\nu32 arb_freq_src, u32 arb_freq_dest)\r\n{\r\nu32 mc_arb_dram_timing;\r\nu32 mc_arb_dram_timing2;\r\nu32 burst_time;\r\nu32 mc_cg_config;\r\nswitch (arb_freq_src) {\r\ncase MC_CG_ARB_FREQ_F0:\r\nmc_arb_dram_timing = RREG32(MC_ARB_DRAM_TIMING);\r\nmc_arb_dram_timing2 = RREG32(MC_ARB_DRAM_TIMING2);\r\nburst_time = (RREG32(MC_ARB_BURST_TIME) & STATE0_MASK) >> STATE0_SHIFT;\r\nbreak;\r\ncase MC_CG_ARB_FREQ_F1:\r\nmc_arb_dram_timing = RREG32(MC_ARB_DRAM_TIMING_1);\r\nmc_arb_dram_timing2 = RREG32(MC_ARB_DRAM_TIMING2_1);\r\nburst_time = (RREG32(MC_ARB_BURST_TIME) & STATE1_MASK) >> STATE1_SHIFT;\r\nbreak;\r\ncase MC_CG_ARB_FREQ_F2:\r\nmc_arb_dram_timing = RREG32(MC_ARB_DRAM_TIMING_2);\r\nmc_arb_dram_timing2 = RREG32(MC_ARB_DRAM_TIMING2_2);\r\nburst_time = (RREG32(MC_ARB_BURST_TIME) & STATE2_MASK) >> STATE2_SHIFT;\r\nbreak;\r\ncase MC_CG_ARB_FREQ_F3:\r\nmc_arb_dram_timing = RREG32(MC_ARB_DRAM_TIMING_3);\r\nmc_arb_dram_timing2 = RREG32(MC_ARB_DRAM_TIMING2_3);\r\nburst_time = (RREG32(MC_ARB_BURST_TIME) & STATE3_MASK) >> STATE3_SHIFT;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nswitch (arb_freq_dest) {\r\ncase MC_CG_ARB_FREQ_F0:\r\nWREG32(MC_ARB_DRAM_TIMING, mc_arb_dram_timing);\r\nWREG32(MC_ARB_DRAM_TIMING2, mc_arb_dram_timing2);\r\nWREG32_P(MC_ARB_BURST_TIME, STATE0(burst_time), ~STATE0_MASK);\r\nbreak;\r\ncase MC_CG_ARB_FREQ_F1:\r\nWREG32(MC_ARB_DRAM_TIMING_1, mc_arb_dram_timing);\r\nWREG32(MC_ARB_DRAM_TIMING2_1, mc_arb_dram_timing2);\r\nWREG32_P(MC_ARB_BURST_TIME, STATE1(burst_time), ~STATE1_MASK);\r\nbreak;\r\ncase MC_CG_ARB_FREQ_F2:\r\nWREG32(MC_ARB_DRAM_TIMING_2, mc_arb_dram_timing);\r\nWREG32(MC_ARB_DRAM_TIMING2_2, mc_arb_dram_timing2);\r\nWREG32_P(MC_ARB_BURST_TIME, STATE2(burst_time), ~STATE2_MASK);\r\nbreak;\r\ncase MC_CG_ARB_FREQ_F3:\r\nWREG32(MC_ARB_DRAM_TIMING_3, mc_arb_dram_timing);\r\nWREG32(MC_ARB_DRAM_TIMING2_3, mc_arb_dram_timing2);\r\nWREG32_P(MC_ARB_BURST_TIME, STATE3(burst_time), ~STATE3_MASK);\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nmc_cg_config = RREG32(MC_CG_CONFIG) | 0x0000000F;\r\nWREG32(MC_CG_CONFIG, mc_cg_config);\r\nWREG32_P(MC_ARB_CG, CG_ARB_REQ(arb_freq_dest), ~CG_ARB_REQ_MASK);\r\nreturn 0;\r\n}\r\nstatic int ni_init_arb_table_index(struct radeon_device *rdev)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nu32 tmp;\r\nint ret;\r\nret = rv770_read_smc_sram_dword(rdev, ni_pi->arb_table_start,\r\n&tmp, pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\ntmp &= 0x00FFFFFF;\r\ntmp |= ((u32)MC_CG_ARB_FREQ_F1) << 24;\r\nreturn rv770_write_smc_sram_dword(rdev, ni_pi->arb_table_start,\r\ntmp, pi->sram_end);\r\n}\r\nstatic int ni_initial_switch_from_arb_f0_to_f1(struct radeon_device *rdev)\r\n{\r\nreturn ni_copy_and_switch_arb_sets(rdev, MC_CG_ARB_FREQ_F0, MC_CG_ARB_FREQ_F1);\r\n}\r\nstatic int ni_force_switch_to_arb_f0(struct radeon_device *rdev)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nu32 tmp;\r\nint ret;\r\nret = rv770_read_smc_sram_dword(rdev, ni_pi->arb_table_start,\r\n&tmp, pi->sram_end);\r\nif (ret)\r\nreturn ret;\r\ntmp = (tmp >> 24) & 0xff;\r\nif (tmp == MC_CG_ARB_FREQ_F0)\r\nreturn 0;\r\nreturn ni_copy_and_switch_arb_sets(rdev, tmp, MC_CG_ARB_FREQ_F0);\r\n}\r\nstatic int ni_populate_memory_timing_parameters(struct radeon_device *rdev,\r\nstruct rv7xx_pl *pl,\r\nSMC_NIslands_MCArbDramTimingRegisterSet *arb_regs)\r\n{\r\nu32 dram_timing;\r\nu32 dram_timing2;\r\narb_regs->mc_arb_rfsh_rate =\r\n(u8)rv770_calculate_memory_refresh_rate(rdev, pl->sclk);\r\nradeon_atom_set_engine_dram_timings(rdev, pl->sclk, pl->mclk);\r\ndram_timing = RREG32(MC_ARB_DRAM_TIMING);\r\ndram_timing2 = RREG32(MC_ARB_DRAM_TIMING2);\r\narb_regs->mc_arb_dram_timing = cpu_to_be32(dram_timing);\r\narb_regs->mc_arb_dram_timing2 = cpu_to_be32(dram_timing2);\r\nreturn 0;\r\n}\r\nstatic int ni_do_program_memory_timing_parameters(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state,\r\nunsigned int first_arb_set)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nstruct ni_ps *state = ni_get_ps(radeon_state);\r\nSMC_NIslands_MCArbDramTimingRegisterSet arb_regs = { 0 };\r\nint i, ret = 0;\r\nfor (i = 0; i < state->performance_level_count; i++) {\r\nret = ni_populate_memory_timing_parameters(rdev, &state->performance_levels[i], &arb_regs);\r\nif (ret)\r\nbreak;\r\nret = rv770_copy_bytes_to_smc(rdev,\r\n(u16)(ni_pi->arb_table_start +\r\noffsetof(SMC_NIslands_MCArbDramTimingRegisters, data) +\r\nsizeof(SMC_NIslands_MCArbDramTimingRegisterSet) * (first_arb_set + i)),\r\n(u8 *)&arb_regs,\r\n(u16)sizeof(SMC_NIslands_MCArbDramTimingRegisterSet),\r\npi->sram_end);\r\nif (ret)\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nstatic int ni_program_memory_timing_parameters(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_new_state)\r\n{\r\nreturn ni_do_program_memory_timing_parameters(rdev, radeon_new_state,\r\nNISLANDS_DRIVER_STATE_ARB_INDEX);\r\n}\r\nstatic void ni_populate_initial_mvdd_value(struct radeon_device *rdev,\r\nstruct NISLANDS_SMC_VOLTAGE_VALUE *voltage)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nvoltage->index = eg_pi->mvdd_high_index;\r\nvoltage->value = cpu_to_be16(MVDD_HIGH_VALUE);\r\n}\r\nstatic int ni_populate_smc_initial_state(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_initial_state,\r\nNISLANDS_SMC_STATETABLE *table)\r\n{\r\nstruct ni_ps *initial_state = ni_get_ps(radeon_initial_state);\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nu32 reg;\r\nint ret;\r\ntable->initialState.levels[0].mclk.vMPLL_AD_FUNC_CNTL =\r\ncpu_to_be32(ni_pi->clock_registers.mpll_ad_func_cntl);\r\ntable->initialState.levels[0].mclk.vMPLL_AD_FUNC_CNTL_2 =\r\ncpu_to_be32(ni_pi->clock_registers.mpll_ad_func_cntl_2);\r\ntable->initialState.levels[0].mclk.vMPLL_DQ_FUNC_CNTL =\r\ncpu_to_be32(ni_pi->clock_registers.mpll_dq_func_cntl);\r\ntable->initialState.levels[0].mclk.vMPLL_DQ_FUNC_CNTL_2 =\r\ncpu_to_be32(ni_pi->clock_registers.mpll_dq_func_cntl_2);\r\ntable->initialState.levels[0].mclk.vMCLK_PWRMGT_CNTL =\r\ncpu_to_be32(ni_pi->clock_registers.mclk_pwrmgt_cntl);\r\ntable->initialState.levels[0].mclk.vDLL_CNTL =\r\ncpu_to_be32(ni_pi->clock_registers.dll_cntl);\r\ntable->initialState.levels[0].mclk.vMPLL_SS =\r\ncpu_to_be32(ni_pi->clock_registers.mpll_ss1);\r\ntable->initialState.levels[0].mclk.vMPLL_SS2 =\r\ncpu_to_be32(ni_pi->clock_registers.mpll_ss2);\r\ntable->initialState.levels[0].mclk.mclk_value =\r\ncpu_to_be32(initial_state->performance_levels[0].mclk);\r\ntable->initialState.levels[0].sclk.vCG_SPLL_FUNC_CNTL =\r\ncpu_to_be32(ni_pi->clock_registers.cg_spll_func_cntl);\r\ntable->initialState.levels[0].sclk.vCG_SPLL_FUNC_CNTL_2 =\r\ncpu_to_be32(ni_pi->clock_registers.cg_spll_func_cntl_2);\r\ntable->initialState.levels[0].sclk.vCG_SPLL_FUNC_CNTL_3 =\r\ncpu_to_be32(ni_pi->clock_registers.cg_spll_func_cntl_3);\r\ntable->initialState.levels[0].sclk.vCG_SPLL_FUNC_CNTL_4 =\r\ncpu_to_be32(ni_pi->clock_registers.cg_spll_func_cntl_4);\r\ntable->initialState.levels[0].sclk.vCG_SPLL_SPREAD_SPECTRUM =\r\ncpu_to_be32(ni_pi->clock_registers.cg_spll_spread_spectrum);\r\ntable->initialState.levels[0].sclk.vCG_SPLL_SPREAD_SPECTRUM_2 =\r\ncpu_to_be32(ni_pi->clock_registers.cg_spll_spread_spectrum_2);\r\ntable->initialState.levels[0].sclk.sclk_value =\r\ncpu_to_be32(initial_state->performance_levels[0].sclk);\r\ntable->initialState.levels[0].arbRefreshState =\r\nNISLANDS_INITIAL_STATE_ARB_INDEX;\r\ntable->initialState.levels[0].ACIndex = 0;\r\nret = ni_populate_voltage_value(rdev, &eg_pi->vddc_voltage_table,\r\ninitial_state->performance_levels[0].vddc,\r\n&table->initialState.levels[0].vddc);\r\nif (!ret) {\r\nu16 std_vddc;\r\nret = ni_get_std_voltage_value(rdev,\r\n&table->initialState.levels[0].vddc,\r\n&std_vddc);\r\nif (!ret)\r\nni_populate_std_voltage_value(rdev, std_vddc,\r\ntable->initialState.levels[0].vddc.index,\r\n&table->initialState.levels[0].std_vddc);\r\n}\r\nif (eg_pi->vddci_control)\r\nni_populate_voltage_value(rdev,\r\n&eg_pi->vddci_voltage_table,\r\ninitial_state->performance_levels[0].vddci,\r\n&table->initialState.levels[0].vddci);\r\nni_populate_initial_mvdd_value(rdev, &table->initialState.levels[0].mvdd);\r\nreg = CG_R(0xffff) | CG_L(0);\r\ntable->initialState.levels[0].aT = cpu_to_be32(reg);\r\ntable->initialState.levels[0].bSP = cpu_to_be32(pi->dsp);\r\nif (pi->boot_in_gen2)\r\ntable->initialState.levels[0].gen2PCIE = 1;\r\nelse\r\ntable->initialState.levels[0].gen2PCIE = 0;\r\nif (pi->mem_gddr5) {\r\ntable->initialState.levels[0].strobeMode =\r\ncypress_get_strobe_mode_settings(rdev,\r\ninitial_state->performance_levels[0].mclk);\r\nif (initial_state->performance_levels[0].mclk > pi->mclk_edc_enable_threshold)\r\ntable->initialState.levels[0].mcFlags = NISLANDS_SMC_MC_EDC_RD_FLAG | NISLANDS_SMC_MC_EDC_WR_FLAG;\r\nelse\r\ntable->initialState.levels[0].mcFlags = 0;\r\n}\r\ntable->initialState.levelCount = 1;\r\ntable->initialState.flags |= PPSMC_SWSTATE_FLAG_DC;\r\ntable->initialState.levels[0].dpm2.MaxPS = 0;\r\ntable->initialState.levels[0].dpm2.NearTDPDec = 0;\r\ntable->initialState.levels[0].dpm2.AboveSafeInc = 0;\r\ntable->initialState.levels[0].dpm2.BelowSafeInc = 0;\r\nreg = MIN_POWER_MASK | MAX_POWER_MASK;\r\ntable->initialState.levels[0].SQPowerThrottle = cpu_to_be32(reg);\r\nreg = MAX_POWER_DELTA_MASK | STI_SIZE_MASK | LTI_RATIO_MASK;\r\ntable->initialState.levels[0].SQPowerThrottle_2 = cpu_to_be32(reg);\r\nreturn 0;\r\n}\r\nstatic int ni_populate_smc_acpi_state(struct radeon_device *rdev,\r\nNISLANDS_SMC_STATETABLE *table)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nu32 mpll_ad_func_cntl = ni_pi->clock_registers.mpll_ad_func_cntl;\r\nu32 mpll_ad_func_cntl_2 = ni_pi->clock_registers.mpll_ad_func_cntl_2;\r\nu32 mpll_dq_func_cntl = ni_pi->clock_registers.mpll_dq_func_cntl;\r\nu32 mpll_dq_func_cntl_2 = ni_pi->clock_registers.mpll_dq_func_cntl_2;\r\nu32 spll_func_cntl = ni_pi->clock_registers.cg_spll_func_cntl;\r\nu32 spll_func_cntl_2 = ni_pi->clock_registers.cg_spll_func_cntl_2;\r\nu32 spll_func_cntl_3 = ni_pi->clock_registers.cg_spll_func_cntl_3;\r\nu32 spll_func_cntl_4 = ni_pi->clock_registers.cg_spll_func_cntl_4;\r\nu32 mclk_pwrmgt_cntl = ni_pi->clock_registers.mclk_pwrmgt_cntl;\r\nu32 dll_cntl = ni_pi->clock_registers.dll_cntl;\r\nu32 reg;\r\nint ret;\r\ntable->ACPIState = table->initialState;\r\ntable->ACPIState.flags &= ~PPSMC_SWSTATE_FLAG_DC;\r\nif (pi->acpi_vddc) {\r\nret = ni_populate_voltage_value(rdev,\r\n&eg_pi->vddc_voltage_table,\r\npi->acpi_vddc, &table->ACPIState.levels[0].vddc);\r\nif (!ret) {\r\nu16 std_vddc;\r\nret = ni_get_std_voltage_value(rdev,\r\n&table->ACPIState.levels[0].vddc, &std_vddc);\r\nif (!ret)\r\nni_populate_std_voltage_value(rdev, std_vddc,\r\ntable->ACPIState.levels[0].vddc.index,\r\n&table->ACPIState.levels[0].std_vddc);\r\n}\r\nif (pi->pcie_gen2) {\r\nif (pi->acpi_pcie_gen2)\r\ntable->ACPIState.levels[0].gen2PCIE = 1;\r\nelse\r\ntable->ACPIState.levels[0].gen2PCIE = 0;\r\n} else {\r\ntable->ACPIState.levels[0].gen2PCIE = 0;\r\n}\r\n} else {\r\nret = ni_populate_voltage_value(rdev,\r\n&eg_pi->vddc_voltage_table,\r\npi->min_vddc_in_table,\r\n&table->ACPIState.levels[0].vddc);\r\nif (!ret) {\r\nu16 std_vddc;\r\nret = ni_get_std_voltage_value(rdev,\r\n&table->ACPIState.levels[0].vddc,\r\n&std_vddc);\r\nif (!ret)\r\nni_populate_std_voltage_value(rdev, std_vddc,\r\ntable->ACPIState.levels[0].vddc.index,\r\n&table->ACPIState.levels[0].std_vddc);\r\n}\r\ntable->ACPIState.levels[0].gen2PCIE = 0;\r\n}\r\nif (eg_pi->acpi_vddci) {\r\nif (eg_pi->vddci_control)\r\nni_populate_voltage_value(rdev,\r\n&eg_pi->vddci_voltage_table,\r\neg_pi->acpi_vddci,\r\n&table->ACPIState.levels[0].vddci);\r\n}\r\nmpll_ad_func_cntl &= ~PDNB;\r\nmpll_ad_func_cntl_2 |= BIAS_GEN_PDNB | RESET_EN;\r\nif (pi->mem_gddr5)\r\nmpll_dq_func_cntl &= ~PDNB;\r\nmpll_dq_func_cntl_2 |= BIAS_GEN_PDNB | RESET_EN | BYPASS;\r\nmclk_pwrmgt_cntl |= (MRDCKA0_RESET |\r\nMRDCKA1_RESET |\r\nMRDCKB0_RESET |\r\nMRDCKB1_RESET |\r\nMRDCKC0_RESET |\r\nMRDCKC1_RESET |\r\nMRDCKD0_RESET |\r\nMRDCKD1_RESET);\r\nmclk_pwrmgt_cntl &= ~(MRDCKA0_PDNB |\r\nMRDCKA1_PDNB |\r\nMRDCKB0_PDNB |\r\nMRDCKB1_PDNB |\r\nMRDCKC0_PDNB |\r\nMRDCKC1_PDNB |\r\nMRDCKD0_PDNB |\r\nMRDCKD1_PDNB);\r\ndll_cntl |= (MRDCKA0_BYPASS |\r\nMRDCKA1_BYPASS |\r\nMRDCKB0_BYPASS |\r\nMRDCKB1_BYPASS |\r\nMRDCKC0_BYPASS |\r\nMRDCKC1_BYPASS |\r\nMRDCKD0_BYPASS |\r\nMRDCKD1_BYPASS);\r\nspll_func_cntl_2 &= ~SCLK_MUX_SEL_MASK;\r\nspll_func_cntl_2 |= SCLK_MUX_SEL(4);\r\ntable->ACPIState.levels[0].mclk.vMPLL_AD_FUNC_CNTL = cpu_to_be32(mpll_ad_func_cntl);\r\ntable->ACPIState.levels[0].mclk.vMPLL_AD_FUNC_CNTL_2 = cpu_to_be32(mpll_ad_func_cntl_2);\r\ntable->ACPIState.levels[0].mclk.vMPLL_DQ_FUNC_CNTL = cpu_to_be32(mpll_dq_func_cntl);\r\ntable->ACPIState.levels[0].mclk.vMPLL_DQ_FUNC_CNTL_2 = cpu_to_be32(mpll_dq_func_cntl_2);\r\ntable->ACPIState.levels[0].mclk.vMCLK_PWRMGT_CNTL = cpu_to_be32(mclk_pwrmgt_cntl);\r\ntable->ACPIState.levels[0].mclk.vDLL_CNTL = cpu_to_be32(dll_cntl);\r\ntable->ACPIState.levels[0].mclk.mclk_value = 0;\r\ntable->ACPIState.levels[0].sclk.vCG_SPLL_FUNC_CNTL = cpu_to_be32(spll_func_cntl);\r\ntable->ACPIState.levels[0].sclk.vCG_SPLL_FUNC_CNTL_2 = cpu_to_be32(spll_func_cntl_2);\r\ntable->ACPIState.levels[0].sclk.vCG_SPLL_FUNC_CNTL_3 = cpu_to_be32(spll_func_cntl_3);\r\ntable->ACPIState.levels[0].sclk.vCG_SPLL_FUNC_CNTL_4 = cpu_to_be32(spll_func_cntl_4);\r\ntable->ACPIState.levels[0].sclk.sclk_value = 0;\r\nni_populate_mvdd_value(rdev, 0, &table->ACPIState.levels[0].mvdd);\r\nif (eg_pi->dynamic_ac_timing)\r\ntable->ACPIState.levels[0].ACIndex = 1;\r\ntable->ACPIState.levels[0].dpm2.MaxPS = 0;\r\ntable->ACPIState.levels[0].dpm2.NearTDPDec = 0;\r\ntable->ACPIState.levels[0].dpm2.AboveSafeInc = 0;\r\ntable->ACPIState.levels[0].dpm2.BelowSafeInc = 0;\r\nreg = MIN_POWER_MASK | MAX_POWER_MASK;\r\ntable->ACPIState.levels[0].SQPowerThrottle = cpu_to_be32(reg);\r\nreg = MAX_POWER_DELTA_MASK | STI_SIZE_MASK | LTI_RATIO_MASK;\r\ntable->ACPIState.levels[0].SQPowerThrottle_2 = cpu_to_be32(reg);\r\nreturn 0;\r\n}\r\nstatic int ni_init_smc_table(struct radeon_device *rdev)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nint ret;\r\nstruct radeon_ps *radeon_boot_state = rdev->pm.dpm.boot_ps;\r\nNISLANDS_SMC_STATETABLE *table = &ni_pi->smc_statetable;\r\nmemset(table, 0, sizeof(NISLANDS_SMC_STATETABLE));\r\nni_populate_smc_voltage_tables(rdev, table);\r\nswitch (rdev->pm.int_thermal_type) {\r\ncase THERMAL_TYPE_NI:\r\ncase THERMAL_TYPE_EMC2103_WITH_INTERNAL:\r\ntable->thermalProtectType = PPSMC_THERMAL_PROTECT_TYPE_INTERNAL;\r\nbreak;\r\ncase THERMAL_TYPE_NONE:\r\ntable->thermalProtectType = PPSMC_THERMAL_PROTECT_TYPE_NONE;\r\nbreak;\r\ndefault:\r\ntable->thermalProtectType = PPSMC_THERMAL_PROTECT_TYPE_EXTERNAL;\r\nbreak;\r\n}\r\nif (rdev->pm.dpm.platform_caps & ATOM_PP_PLATFORM_CAP_HARDWAREDC)\r\ntable->systemFlags |= PPSMC_SYSTEMFLAG_GPIO_DC;\r\nif (rdev->pm.dpm.platform_caps & ATOM_PP_PLATFORM_CAP_REGULATOR_HOT)\r\ntable->systemFlags |= PPSMC_SYSTEMFLAG_REGULATOR_HOT;\r\nif (rdev->pm.dpm.platform_caps & ATOM_PP_PLATFORM_CAP_STEPVDDC)\r\ntable->systemFlags |= PPSMC_SYSTEMFLAG_STEPVDDC;\r\nif (pi->mem_gddr5)\r\ntable->systemFlags |= PPSMC_SYSTEMFLAG_GDDR5;\r\nret = ni_populate_smc_initial_state(rdev, radeon_boot_state, table);\r\nif (ret)\r\nreturn ret;\r\nret = ni_populate_smc_acpi_state(rdev, table);\r\nif (ret)\r\nreturn ret;\r\ntable->driverState = table->initialState;\r\ntable->ULVState = table->initialState;\r\nret = ni_do_program_memory_timing_parameters(rdev, radeon_boot_state,\r\nNISLANDS_INITIAL_STATE_ARB_INDEX);\r\nif (ret)\r\nreturn ret;\r\nreturn rv770_copy_bytes_to_smc(rdev, pi->state_table_start, (u8 *)table,\r\nsizeof(NISLANDS_SMC_STATETABLE), pi->sram_end);\r\n}\r\nstatic int ni_calculate_sclk_params(struct radeon_device *rdev,\r\nu32 engine_clock,\r\nNISLANDS_SMC_SCLK_VALUE *sclk)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nstruct atom_clock_dividers dividers;\r\nu32 spll_func_cntl = ni_pi->clock_registers.cg_spll_func_cntl;\r\nu32 spll_func_cntl_2 = ni_pi->clock_registers.cg_spll_func_cntl_2;\r\nu32 spll_func_cntl_3 = ni_pi->clock_registers.cg_spll_func_cntl_3;\r\nu32 spll_func_cntl_4 = ni_pi->clock_registers.cg_spll_func_cntl_4;\r\nu32 cg_spll_spread_spectrum = ni_pi->clock_registers.cg_spll_spread_spectrum;\r\nu32 cg_spll_spread_spectrum_2 = ni_pi->clock_registers.cg_spll_spread_spectrum_2;\r\nu64 tmp;\r\nu32 reference_clock = rdev->clock.spll.reference_freq;\r\nu32 reference_divider;\r\nu32 fbdiv;\r\nint ret;\r\nret = radeon_atom_get_clock_dividers(rdev, COMPUTE_ENGINE_PLL_PARAM,\r\nengine_clock, false, &dividers);\r\nif (ret)\r\nreturn ret;\r\nreference_divider = 1 + dividers.ref_div;\r\ntmp = (u64) engine_clock * reference_divider * dividers.post_div * 16834;\r\ndo_div(tmp, reference_clock);\r\nfbdiv = (u32) tmp;\r\nspll_func_cntl &= ~(SPLL_PDIV_A_MASK | SPLL_REF_DIV_MASK);\r\nspll_func_cntl |= SPLL_REF_DIV(dividers.ref_div);\r\nspll_func_cntl |= SPLL_PDIV_A(dividers.post_div);\r\nspll_func_cntl_2 &= ~SCLK_MUX_SEL_MASK;\r\nspll_func_cntl_2 |= SCLK_MUX_SEL(2);\r\nspll_func_cntl_3 &= ~SPLL_FB_DIV_MASK;\r\nspll_func_cntl_3 |= SPLL_FB_DIV(fbdiv);\r\nspll_func_cntl_3 |= SPLL_DITHEN;\r\nif (pi->sclk_ss) {\r\nstruct radeon_atom_ss ss;\r\nu32 vco_freq = engine_clock * dividers.post_div;\r\nif (radeon_atombios_get_asic_ss_info(rdev, &ss,\r\nASIC_INTERNAL_ENGINE_SS, vco_freq)) {\r\nu32 clk_s = reference_clock * 5 / (reference_divider * ss.rate);\r\nu32 clk_v = 4 * ss.percentage * fbdiv / (clk_s * 10000);\r\ncg_spll_spread_spectrum &= ~CLK_S_MASK;\r\ncg_spll_spread_spectrum |= CLK_S(clk_s);\r\ncg_spll_spread_spectrum |= SSEN;\r\ncg_spll_spread_spectrum_2 &= ~CLK_V_MASK;\r\ncg_spll_spread_spectrum_2 |= CLK_V(clk_v);\r\n}\r\n}\r\nsclk->sclk_value = engine_clock;\r\nsclk->vCG_SPLL_FUNC_CNTL = spll_func_cntl;\r\nsclk->vCG_SPLL_FUNC_CNTL_2 = spll_func_cntl_2;\r\nsclk->vCG_SPLL_FUNC_CNTL_3 = spll_func_cntl_3;\r\nsclk->vCG_SPLL_FUNC_CNTL_4 = spll_func_cntl_4;\r\nsclk->vCG_SPLL_SPREAD_SPECTRUM = cg_spll_spread_spectrum;\r\nsclk->vCG_SPLL_SPREAD_SPECTRUM_2 = cg_spll_spread_spectrum_2;\r\nreturn 0;\r\n}\r\nstatic int ni_populate_sclk_value(struct radeon_device *rdev,\r\nu32 engine_clock,\r\nNISLANDS_SMC_SCLK_VALUE *sclk)\r\n{\r\nNISLANDS_SMC_SCLK_VALUE sclk_tmp;\r\nint ret;\r\nret = ni_calculate_sclk_params(rdev, engine_clock, &sclk_tmp);\r\nif (!ret) {\r\nsclk->sclk_value = cpu_to_be32(sclk_tmp.sclk_value);\r\nsclk->vCG_SPLL_FUNC_CNTL = cpu_to_be32(sclk_tmp.vCG_SPLL_FUNC_CNTL);\r\nsclk->vCG_SPLL_FUNC_CNTL_2 = cpu_to_be32(sclk_tmp.vCG_SPLL_FUNC_CNTL_2);\r\nsclk->vCG_SPLL_FUNC_CNTL_3 = cpu_to_be32(sclk_tmp.vCG_SPLL_FUNC_CNTL_3);\r\nsclk->vCG_SPLL_FUNC_CNTL_4 = cpu_to_be32(sclk_tmp.vCG_SPLL_FUNC_CNTL_4);\r\nsclk->vCG_SPLL_SPREAD_SPECTRUM = cpu_to_be32(sclk_tmp.vCG_SPLL_SPREAD_SPECTRUM);\r\nsclk->vCG_SPLL_SPREAD_SPECTRUM_2 = cpu_to_be32(sclk_tmp.vCG_SPLL_SPREAD_SPECTRUM_2);\r\n}\r\nreturn ret;\r\n}\r\nstatic int ni_init_smc_spll_table(struct radeon_device *rdev)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nSMC_NISLANDS_SPLL_DIV_TABLE *spll_table;\r\nNISLANDS_SMC_SCLK_VALUE sclk_params;\r\nu32 fb_div;\r\nu32 p_div;\r\nu32 clk_s;\r\nu32 clk_v;\r\nu32 sclk = 0;\r\nint i, ret;\r\nu32 tmp;\r\nif (ni_pi->spll_table_start == 0)\r\nreturn -EINVAL;\r\nspll_table = kzalloc(sizeof(SMC_NISLANDS_SPLL_DIV_TABLE), GFP_KERNEL);\r\nif (spll_table == NULL)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < 256; i++) {\r\nret = ni_calculate_sclk_params(rdev, sclk, &sclk_params);\r\nif (ret)\r\nbreak;\r\np_div = (sclk_params.vCG_SPLL_FUNC_CNTL & SPLL_PDIV_A_MASK) >> SPLL_PDIV_A_SHIFT;\r\nfb_div = (sclk_params.vCG_SPLL_FUNC_CNTL_3 & SPLL_FB_DIV_MASK) >> SPLL_FB_DIV_SHIFT;\r\nclk_s = (sclk_params.vCG_SPLL_SPREAD_SPECTRUM & CLK_S_MASK) >> CLK_S_SHIFT;\r\nclk_v = (sclk_params.vCG_SPLL_SPREAD_SPECTRUM_2 & CLK_V_MASK) >> CLK_V_SHIFT;\r\nfb_div &= ~0x00001FFF;\r\nfb_div >>= 1;\r\nclk_v >>= 6;\r\nif (p_div & ~(SMC_NISLANDS_SPLL_DIV_TABLE_PDIV_MASK >> SMC_NISLANDS_SPLL_DIV_TABLE_PDIV_SHIFT))\r\nret = -EINVAL;\r\nif (clk_s & ~(SMC_NISLANDS_SPLL_DIV_TABLE_CLKS_MASK >> SMC_NISLANDS_SPLL_DIV_TABLE_CLKS_SHIFT))\r\nret = -EINVAL;\r\nif (clk_s & ~(SMC_NISLANDS_SPLL_DIV_TABLE_CLKS_MASK >> SMC_NISLANDS_SPLL_DIV_TABLE_CLKS_SHIFT))\r\nret = -EINVAL;\r\nif (clk_v & ~(SMC_NISLANDS_SPLL_DIV_TABLE_CLKV_MASK >> SMC_NISLANDS_SPLL_DIV_TABLE_CLKV_SHIFT))\r\nret = -EINVAL;\r\nif (ret)\r\nbreak;\r\ntmp = ((fb_div << SMC_NISLANDS_SPLL_DIV_TABLE_FBDIV_SHIFT) & SMC_NISLANDS_SPLL_DIV_TABLE_FBDIV_MASK) |\r\n((p_div << SMC_NISLANDS_SPLL_DIV_TABLE_PDIV_SHIFT) & SMC_NISLANDS_SPLL_DIV_TABLE_PDIV_MASK);\r\nspll_table->freq[i] = cpu_to_be32(tmp);\r\ntmp = ((clk_v << SMC_NISLANDS_SPLL_DIV_TABLE_CLKV_SHIFT) & SMC_NISLANDS_SPLL_DIV_TABLE_CLKV_MASK) |\r\n((clk_s << SMC_NISLANDS_SPLL_DIV_TABLE_CLKS_SHIFT) & SMC_NISLANDS_SPLL_DIV_TABLE_CLKS_MASK);\r\nspll_table->ss[i] = cpu_to_be32(tmp);\r\nsclk += 512;\r\n}\r\nif (!ret)\r\nret = rv770_copy_bytes_to_smc(rdev, ni_pi->spll_table_start, (u8 *)spll_table,\r\nsizeof(SMC_NISLANDS_SPLL_DIV_TABLE), pi->sram_end);\r\nkfree(spll_table);\r\nreturn ret;\r\n}\r\nstatic int ni_populate_mclk_value(struct radeon_device *rdev,\r\nu32 engine_clock,\r\nu32 memory_clock,\r\nNISLANDS_SMC_MCLK_VALUE *mclk,\r\nbool strobe_mode,\r\nbool dll_state_on)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nu32 mpll_ad_func_cntl = ni_pi->clock_registers.mpll_ad_func_cntl;\r\nu32 mpll_ad_func_cntl_2 = ni_pi->clock_registers.mpll_ad_func_cntl_2;\r\nu32 mpll_dq_func_cntl = ni_pi->clock_registers.mpll_dq_func_cntl;\r\nu32 mpll_dq_func_cntl_2 = ni_pi->clock_registers.mpll_dq_func_cntl_2;\r\nu32 mclk_pwrmgt_cntl = ni_pi->clock_registers.mclk_pwrmgt_cntl;\r\nu32 dll_cntl = ni_pi->clock_registers.dll_cntl;\r\nu32 mpll_ss1 = ni_pi->clock_registers.mpll_ss1;\r\nu32 mpll_ss2 = ni_pi->clock_registers.mpll_ss2;\r\nstruct atom_clock_dividers dividers;\r\nu32 ibias;\r\nu32 dll_speed;\r\nint ret;\r\nu32 mc_seq_misc7;\r\nret = radeon_atom_get_clock_dividers(rdev, COMPUTE_MEMORY_PLL_PARAM,\r\nmemory_clock, strobe_mode, &dividers);\r\nif (ret)\r\nreturn ret;\r\nif (!strobe_mode) {\r\nmc_seq_misc7 = RREG32(MC_SEQ_MISC7);\r\nif (mc_seq_misc7 & 0x8000000)\r\ndividers.post_div = 1;\r\n}\r\nibias = cypress_map_clkf_to_ibias(rdev, dividers.whole_fb_div);\r\nmpll_ad_func_cntl &= ~(CLKR_MASK |\r\nYCLK_POST_DIV_MASK |\r\nCLKF_MASK |\r\nCLKFRAC_MASK |\r\nIBIAS_MASK);\r\nmpll_ad_func_cntl |= CLKR(dividers.ref_div);\r\nmpll_ad_func_cntl |= YCLK_POST_DIV(dividers.post_div);\r\nmpll_ad_func_cntl |= CLKF(dividers.whole_fb_div);\r\nmpll_ad_func_cntl |= CLKFRAC(dividers.frac_fb_div);\r\nmpll_ad_func_cntl |= IBIAS(ibias);\r\nif (dividers.vco_mode)\r\nmpll_ad_func_cntl_2 |= VCO_MODE;\r\nelse\r\nmpll_ad_func_cntl_2 &= ~VCO_MODE;\r\nif (pi->mem_gddr5) {\r\nmpll_dq_func_cntl &= ~(CLKR_MASK |\r\nYCLK_POST_DIV_MASK |\r\nCLKF_MASK |\r\nCLKFRAC_MASK |\r\nIBIAS_MASK);\r\nmpll_dq_func_cntl |= CLKR(dividers.ref_div);\r\nmpll_dq_func_cntl |= YCLK_POST_DIV(dividers.post_div);\r\nmpll_dq_func_cntl |= CLKF(dividers.whole_fb_div);\r\nmpll_dq_func_cntl |= CLKFRAC(dividers.frac_fb_div);\r\nmpll_dq_func_cntl |= IBIAS(ibias);\r\nif (strobe_mode)\r\nmpll_dq_func_cntl &= ~PDNB;\r\nelse\r\nmpll_dq_func_cntl |= PDNB;\r\nif (dividers.vco_mode)\r\nmpll_dq_func_cntl_2 |= VCO_MODE;\r\nelse\r\nmpll_dq_func_cntl_2 &= ~VCO_MODE;\r\n}\r\nif (pi->mclk_ss) {\r\nstruct radeon_atom_ss ss;\r\nu32 vco_freq = memory_clock * dividers.post_div;\r\nif (radeon_atombios_get_asic_ss_info(rdev, &ss,\r\nASIC_INTERNAL_MEMORY_SS, vco_freq)) {\r\nu32 reference_clock = rdev->clock.mpll.reference_freq;\r\nu32 decoded_ref = rv740_get_decoded_reference_divider(dividers.ref_div);\r\nu32 clk_s = reference_clock * 5 / (decoded_ref * ss.rate);\r\nu32 clk_v = ss.percentage *\r\n(0x4000 * dividers.whole_fb_div + 0x800 * dividers.frac_fb_div) / (clk_s * 625);\r\nmpll_ss1 &= ~CLKV_MASK;\r\nmpll_ss1 |= CLKV(clk_v);\r\nmpll_ss2 &= ~CLKS_MASK;\r\nmpll_ss2 |= CLKS(clk_s);\r\n}\r\n}\r\ndll_speed = rv740_get_dll_speed(pi->mem_gddr5,\r\nmemory_clock);\r\nmclk_pwrmgt_cntl &= ~DLL_SPEED_MASK;\r\nmclk_pwrmgt_cntl |= DLL_SPEED(dll_speed);\r\nif (dll_state_on)\r\nmclk_pwrmgt_cntl |= (MRDCKA0_PDNB |\r\nMRDCKA1_PDNB |\r\nMRDCKB0_PDNB |\r\nMRDCKB1_PDNB |\r\nMRDCKC0_PDNB |\r\nMRDCKC1_PDNB |\r\nMRDCKD0_PDNB |\r\nMRDCKD1_PDNB);\r\nelse\r\nmclk_pwrmgt_cntl &= ~(MRDCKA0_PDNB |\r\nMRDCKA1_PDNB |\r\nMRDCKB0_PDNB |\r\nMRDCKB1_PDNB |\r\nMRDCKC0_PDNB |\r\nMRDCKC1_PDNB |\r\nMRDCKD0_PDNB |\r\nMRDCKD1_PDNB);\r\nmclk->mclk_value = cpu_to_be32(memory_clock);\r\nmclk->vMPLL_AD_FUNC_CNTL = cpu_to_be32(mpll_ad_func_cntl);\r\nmclk->vMPLL_AD_FUNC_CNTL_2 = cpu_to_be32(mpll_ad_func_cntl_2);\r\nmclk->vMPLL_DQ_FUNC_CNTL = cpu_to_be32(mpll_dq_func_cntl);\r\nmclk->vMPLL_DQ_FUNC_CNTL_2 = cpu_to_be32(mpll_dq_func_cntl_2);\r\nmclk->vMCLK_PWRMGT_CNTL = cpu_to_be32(mclk_pwrmgt_cntl);\r\nmclk->vDLL_CNTL = cpu_to_be32(dll_cntl);\r\nmclk->vMPLL_SS = cpu_to_be32(mpll_ss1);\r\nmclk->vMPLL_SS2 = cpu_to_be32(mpll_ss2);\r\nreturn 0;\r\n}\r\nstatic void ni_populate_smc_sp(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state,\r\nNISLANDS_SMC_SWSTATE *smc_state)\r\n{\r\nstruct ni_ps *ps = ni_get_ps(radeon_state);\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nint i;\r\nfor (i = 0; i < ps->performance_level_count - 1; i++)\r\nsmc_state->levels[i].bSP = cpu_to_be32(pi->dsp);\r\nsmc_state->levels[ps->performance_level_count - 1].bSP =\r\ncpu_to_be32(pi->psp);\r\n}\r\nstatic int ni_convert_power_level_to_smc(struct radeon_device *rdev,\r\nstruct rv7xx_pl *pl,\r\nNISLANDS_SMC_HW_PERFORMANCE_LEVEL *level)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nint ret;\r\nbool dll_state_on;\r\nu16 std_vddc;\r\nu32 tmp = RREG32(DC_STUTTER_CNTL);\r\nlevel->gen2PCIE = pi->pcie_gen2 ?\r\n((pl->flags & ATOM_PPLIB_R600_FLAGS_PCIEGEN2) ? 1 : 0) : 0;\r\nret = ni_populate_sclk_value(rdev, pl->sclk, &level->sclk);\r\nif (ret)\r\nreturn ret;\r\nlevel->mcFlags = 0;\r\nif (pi->mclk_stutter_mode_threshold &&\r\n(pl->mclk <= pi->mclk_stutter_mode_threshold) &&\r\n!eg_pi->uvd_enabled &&\r\n(tmp & DC_STUTTER_ENABLE_A) &&\r\n(tmp & DC_STUTTER_ENABLE_B))\r\nlevel->mcFlags |= NISLANDS_SMC_MC_STUTTER_EN;\r\nif (pi->mem_gddr5) {\r\nif (pl->mclk > pi->mclk_edc_enable_threshold)\r\nlevel->mcFlags |= NISLANDS_SMC_MC_EDC_RD_FLAG;\r\nif (pl->mclk > eg_pi->mclk_edc_wr_enable_threshold)\r\nlevel->mcFlags |= NISLANDS_SMC_MC_EDC_WR_FLAG;\r\nlevel->strobeMode = cypress_get_strobe_mode_settings(rdev, pl->mclk);\r\nif (level->strobeMode & NISLANDS_SMC_STROBE_ENABLE) {\r\nif (cypress_get_mclk_frequency_ratio(rdev, pl->mclk, true) >=\r\n((RREG32(MC_SEQ_MISC7) >> 16) & 0xf))\r\ndll_state_on = ((RREG32(MC_SEQ_MISC5) >> 1) & 0x1) ? true : false;\r\nelse\r\ndll_state_on = ((RREG32(MC_SEQ_MISC6) >> 1) & 0x1) ? true : false;\r\n} else {\r\ndll_state_on = false;\r\nif (pl->mclk > ni_pi->mclk_rtt_mode_threshold)\r\nlevel->mcFlags |= NISLANDS_SMC_MC_RTT_ENABLE;\r\n}\r\nret = ni_populate_mclk_value(rdev, pl->sclk, pl->mclk,\r\n&level->mclk,\r\n(level->strobeMode & NISLANDS_SMC_STROBE_ENABLE) != 0,\r\ndll_state_on);\r\n} else\r\nret = ni_populate_mclk_value(rdev, pl->sclk, pl->mclk, &level->mclk, 1, 1);\r\nif (ret)\r\nreturn ret;\r\nret = ni_populate_voltage_value(rdev, &eg_pi->vddc_voltage_table,\r\npl->vddc, &level->vddc);\r\nif (ret)\r\nreturn ret;\r\nret = ni_get_std_voltage_value(rdev, &level->vddc, &std_vddc);\r\nif (ret)\r\nreturn ret;\r\nni_populate_std_voltage_value(rdev, std_vddc,\r\nlevel->vddc.index, &level->std_vddc);\r\nif (eg_pi->vddci_control) {\r\nret = ni_populate_voltage_value(rdev, &eg_pi->vddci_voltage_table,\r\npl->vddci, &level->vddci);\r\nif (ret)\r\nreturn ret;\r\n}\r\nni_populate_mvdd_value(rdev, pl->mclk, &level->mvdd);\r\nreturn ret;\r\n}\r\nstatic int ni_populate_smc_t(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state,\r\nNISLANDS_SMC_SWSTATE *smc_state)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct ni_ps *state = ni_get_ps(radeon_state);\r\nu32 a_t;\r\nu32 t_l, t_h;\r\nu32 high_bsp;\r\nint i, ret;\r\nif (state->performance_level_count >= 9)\r\nreturn -EINVAL;\r\nif (state->performance_level_count < 2) {\r\na_t = CG_R(0xffff) | CG_L(0);\r\nsmc_state->levels[0].aT = cpu_to_be32(a_t);\r\nreturn 0;\r\n}\r\nsmc_state->levels[0].aT = cpu_to_be32(0);\r\nfor (i = 0; i <= state->performance_level_count - 2; i++) {\r\nif (eg_pi->uvd_enabled)\r\nret = r600_calculate_at(\r\n1000 * (i * (eg_pi->smu_uvd_hs ? 2 : 8) + 2),\r\n100 * R600_AH_DFLT,\r\nstate->performance_levels[i + 1].sclk,\r\nstate->performance_levels[i].sclk,\r\n&t_l,\r\n&t_h);\r\nelse\r\nret = r600_calculate_at(\r\n1000 * (i + 1),\r\n100 * R600_AH_DFLT,\r\nstate->performance_levels[i + 1].sclk,\r\nstate->performance_levels[i].sclk,\r\n&t_l,\r\n&t_h);\r\nif (ret) {\r\nt_h = (i + 1) * 1000 - 50 * R600_AH_DFLT;\r\nt_l = (i + 1) * 1000 + 50 * R600_AH_DFLT;\r\n}\r\na_t = be32_to_cpu(smc_state->levels[i].aT) & ~CG_R_MASK;\r\na_t |= CG_R(t_l * pi->bsp / 20000);\r\nsmc_state->levels[i].aT = cpu_to_be32(a_t);\r\nhigh_bsp = (i == state->performance_level_count - 2) ?\r\npi->pbsp : pi->bsp;\r\na_t = CG_R(0xffff) | CG_L(t_h * high_bsp / 20000);\r\nsmc_state->levels[i + 1].aT = cpu_to_be32(a_t);\r\n}\r\nreturn 0;\r\n}\r\nstatic int ni_populate_power_containment_values(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state,\r\nNISLANDS_SMC_SWSTATE *smc_state)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nstruct ni_ps *state = ni_get_ps(radeon_state);\r\nu32 prev_sclk;\r\nu32 max_sclk;\r\nu32 min_sclk;\r\nint i, ret;\r\nu32 tdp_limit;\r\nu32 near_tdp_limit;\r\nu32 power_boost_limit;\r\nu8 max_ps_percent;\r\nif (ni_pi->enable_power_containment == false)\r\nreturn 0;\r\nif (state->performance_level_count == 0)\r\nreturn -EINVAL;\r\nif (smc_state->levelCount != state->performance_level_count)\r\nreturn -EINVAL;\r\nret = ni_calculate_adjusted_tdp_limits(rdev,\r\nfalse,\r\nrdev->pm.dpm.tdp_adjustment,\r\n&tdp_limit,\r\n&near_tdp_limit);\r\nif (ret)\r\nreturn ret;\r\npower_boost_limit = ni_calculate_power_boost_limit(rdev, radeon_state, near_tdp_limit);\r\nret = rv770_write_smc_sram_dword(rdev,\r\npi->state_table_start +\r\noffsetof(NISLANDS_SMC_STATETABLE, dpm2Params) +\r\noffsetof(PP_NIslands_DPM2Parameters, PowerBoostLimit),\r\nni_scale_power_for_smc(power_boost_limit, ni_get_smc_power_scaling_factor(rdev)),\r\npi->sram_end);\r\nif (ret)\r\npower_boost_limit = 0;\r\nsmc_state->levels[0].dpm2.MaxPS = 0;\r\nsmc_state->levels[0].dpm2.NearTDPDec = 0;\r\nsmc_state->levels[0].dpm2.AboveSafeInc = 0;\r\nsmc_state->levels[0].dpm2.BelowSafeInc = 0;\r\nsmc_state->levels[0].stateFlags |= power_boost_limit ? PPSMC_STATEFLAG_POWERBOOST : 0;\r\nfor (i = 1; i < state->performance_level_count; i++) {\r\nprev_sclk = state->performance_levels[i-1].sclk;\r\nmax_sclk = state->performance_levels[i].sclk;\r\nmax_ps_percent = (i != (state->performance_level_count - 1)) ?\r\nNISLANDS_DPM2_MAXPS_PERCENT_M : NISLANDS_DPM2_MAXPS_PERCENT_H;\r\nif (max_sclk < prev_sclk)\r\nreturn -EINVAL;\r\nif ((max_ps_percent == 0) || (prev_sclk == max_sclk) || eg_pi->uvd_enabled)\r\nmin_sclk = max_sclk;\r\nelse if (1 == i)\r\nmin_sclk = prev_sclk;\r\nelse\r\nmin_sclk = (prev_sclk * (u32)max_ps_percent) / 100;\r\nif (min_sclk < state->performance_levels[0].sclk)\r\nmin_sclk = state->performance_levels[0].sclk;\r\nif (min_sclk == 0)\r\nreturn -EINVAL;\r\nsmc_state->levels[i].dpm2.MaxPS =\r\n(u8)((NISLANDS_DPM2_MAX_PULSE_SKIP * (max_sclk - min_sclk)) / max_sclk);\r\nsmc_state->levels[i].dpm2.NearTDPDec = NISLANDS_DPM2_NEAR_TDP_DEC;\r\nsmc_state->levels[i].dpm2.AboveSafeInc = NISLANDS_DPM2_ABOVE_SAFE_INC;\r\nsmc_state->levels[i].dpm2.BelowSafeInc = NISLANDS_DPM2_BELOW_SAFE_INC;\r\nsmc_state->levels[i].stateFlags |=\r\n((i != (state->performance_level_count - 1)) && power_boost_limit) ?\r\nPPSMC_STATEFLAG_POWERBOOST : 0;\r\n}\r\nreturn 0;\r\n}\r\nstatic int ni_populate_sq_ramping_values(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state,\r\nNISLANDS_SMC_SWSTATE *smc_state)\r\n{\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nstruct ni_ps *state = ni_get_ps(radeon_state);\r\nu32 sq_power_throttle;\r\nu32 sq_power_throttle2;\r\nbool enable_sq_ramping = ni_pi->enable_sq_ramping;\r\nint i;\r\nif (state->performance_level_count == 0)\r\nreturn -EINVAL;\r\nif (smc_state->levelCount != state->performance_level_count)\r\nreturn -EINVAL;\r\nif (rdev->pm.dpm.sq_ramping_threshold == 0)\r\nreturn -EINVAL;\r\nif (NISLANDS_DPM2_SQ_RAMP_MAX_POWER > (MAX_POWER_MASK >> MAX_POWER_SHIFT))\r\nenable_sq_ramping = false;\r\nif (NISLANDS_DPM2_SQ_RAMP_MIN_POWER > (MIN_POWER_MASK >> MIN_POWER_SHIFT))\r\nenable_sq_ramping = false;\r\nif (NISLANDS_DPM2_SQ_RAMP_MAX_POWER_DELTA > (MAX_POWER_DELTA_MASK >> MAX_POWER_DELTA_SHIFT))\r\nenable_sq_ramping = false;\r\nif (NISLANDS_DPM2_SQ_RAMP_STI_SIZE > (STI_SIZE_MASK >> STI_SIZE_SHIFT))\r\nenable_sq_ramping = false;\r\nif (NISLANDS_DPM2_SQ_RAMP_LTI_RATIO > (LTI_RATIO_MASK >> LTI_RATIO_SHIFT))\r\nenable_sq_ramping = false;\r\nfor (i = 0; i < state->performance_level_count; i++) {\r\nsq_power_throttle = 0;\r\nsq_power_throttle2 = 0;\r\nif ((state->performance_levels[i].sclk >= rdev->pm.dpm.sq_ramping_threshold) &&\r\nenable_sq_ramping) {\r\nsq_power_throttle |= MAX_POWER(NISLANDS_DPM2_SQ_RAMP_MAX_POWER);\r\nsq_power_throttle |= MIN_POWER(NISLANDS_DPM2_SQ_RAMP_MIN_POWER);\r\nsq_power_throttle2 |= MAX_POWER_DELTA(NISLANDS_DPM2_SQ_RAMP_MAX_POWER_DELTA);\r\nsq_power_throttle2 |= STI_SIZE(NISLANDS_DPM2_SQ_RAMP_STI_SIZE);\r\nsq_power_throttle2 |= LTI_RATIO(NISLANDS_DPM2_SQ_RAMP_LTI_RATIO);\r\n} else {\r\nsq_power_throttle |= MAX_POWER_MASK | MIN_POWER_MASK;\r\nsq_power_throttle2 |= MAX_POWER_DELTA_MASK | STI_SIZE_MASK | LTI_RATIO_MASK;\r\n}\r\nsmc_state->levels[i].SQPowerThrottle = cpu_to_be32(sq_power_throttle);\r\nsmc_state->levels[i].SQPowerThrottle_2 = cpu_to_be32(sq_power_throttle2);\r\n}\r\nreturn 0;\r\n}\r\nstatic int ni_enable_power_containment(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_new_state,\r\nbool enable)\r\n{\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nPPSMC_Result smc_result;\r\nint ret = 0;\r\nif (ni_pi->enable_power_containment) {\r\nif (enable) {\r\nif (!r600_is_uvd_state(radeon_new_state->class, radeon_new_state->class2)) {\r\nsmc_result = rv770_send_msg_to_smc(rdev, PPSMC_TDPClampingActive);\r\nif (smc_result != PPSMC_Result_OK) {\r\nret = -EINVAL;\r\nni_pi->pc_enabled = false;\r\n} else {\r\nni_pi->pc_enabled = true;\r\n}\r\n}\r\n} else {\r\nsmc_result = rv770_send_msg_to_smc(rdev, PPSMC_TDPClampingInactive);\r\nif (smc_result != PPSMC_Result_OK)\r\nret = -EINVAL;\r\nni_pi->pc_enabled = false;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic int ni_convert_power_state_to_smc(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state,\r\nNISLANDS_SMC_SWSTATE *smc_state)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nstruct ni_ps *state = ni_get_ps(radeon_state);\r\nint i, ret;\r\nu32 threshold = state->performance_levels[state->performance_level_count - 1].sclk * 100 / 100;\r\nif (!(radeon_state->caps & ATOM_PPLIB_DISALLOW_ON_DC))\r\nsmc_state->flags |= PPSMC_SWSTATE_FLAG_DC;\r\nsmc_state->levelCount = 0;\r\nif (state->performance_level_count > NISLANDS_MAX_SMC_PERFORMANCE_LEVELS_PER_SWSTATE)\r\nreturn -EINVAL;\r\nfor (i = 0; i < state->performance_level_count; i++) {\r\nret = ni_convert_power_level_to_smc(rdev, &state->performance_levels[i],\r\n&smc_state->levels[i]);\r\nsmc_state->levels[i].arbRefreshState =\r\n(u8)(NISLANDS_DRIVER_STATE_ARB_INDEX + i);\r\nif (ret)\r\nreturn ret;\r\nif (ni_pi->enable_power_containment)\r\nsmc_state->levels[i].displayWatermark =\r\n(state->performance_levels[i].sclk < threshold) ?\r\nPPSMC_DISPLAY_WATERMARK_LOW : PPSMC_DISPLAY_WATERMARK_HIGH;\r\nelse\r\nsmc_state->levels[i].displayWatermark = (i < 2) ?\r\nPPSMC_DISPLAY_WATERMARK_LOW : PPSMC_DISPLAY_WATERMARK_HIGH;\r\nif (eg_pi->dynamic_ac_timing)\r\nsmc_state->levels[i].ACIndex = NISLANDS_MCREGISTERTABLE_FIRST_DRIVERSTATE_SLOT + i;\r\nelse\r\nsmc_state->levels[i].ACIndex = 0;\r\nsmc_state->levelCount++;\r\n}\r\nrv770_write_smc_soft_register(rdev, NI_SMC_SOFT_REGISTER_watermark_threshold,\r\ncpu_to_be32(threshold / 512));\r\nni_populate_smc_sp(rdev, radeon_state, smc_state);\r\nret = ni_populate_power_containment_values(rdev, radeon_state, smc_state);\r\nif (ret)\r\nni_pi->enable_power_containment = false;\r\nret = ni_populate_sq_ramping_values(rdev, radeon_state, smc_state);\r\nif (ret)\r\nni_pi->enable_sq_ramping = false;\r\nreturn ni_populate_smc_t(rdev, radeon_state, smc_state);\r\n}\r\nstatic int ni_upload_sw_state(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_new_state)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nu16 address = pi->state_table_start +\r\noffsetof(NISLANDS_SMC_STATETABLE, driverState);\r\nu16 state_size = sizeof(NISLANDS_SMC_SWSTATE) +\r\n((NISLANDS_MAX_SMC_PERFORMANCE_LEVELS_PER_SWSTATE - 1) * sizeof(NISLANDS_SMC_HW_PERFORMANCE_LEVEL));\r\nint ret;\r\nNISLANDS_SMC_SWSTATE *smc_state = kzalloc(state_size, GFP_KERNEL);\r\nif (smc_state == NULL)\r\nreturn -ENOMEM;\r\nret = ni_convert_power_state_to_smc(rdev, radeon_new_state, smc_state);\r\nif (ret)\r\ngoto done;\r\nret = rv770_copy_bytes_to_smc(rdev, address, (u8 *)smc_state, state_size, pi->sram_end);\r\ndone:\r\nkfree(smc_state);\r\nreturn ret;\r\n}\r\nstatic int ni_set_mc_special_registers(struct radeon_device *rdev,\r\nstruct ni_mc_reg_table *table)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nu8 i, j, k;\r\nu32 temp_reg;\r\nfor (i = 0, j = table->last; i < table->last; i++) {\r\nswitch (table->mc_reg_address[i].s1) {\r\ncase MC_SEQ_MISC1 >> 2:\r\nif (j >= SMC_NISLANDS_MC_REGISTER_ARRAY_SIZE)\r\nreturn -EINVAL;\r\ntemp_reg = RREG32(MC_PMG_CMD_EMRS);\r\ntable->mc_reg_address[j].s1 = MC_PMG_CMD_EMRS >> 2;\r\ntable->mc_reg_address[j].s0 = MC_SEQ_PMG_CMD_EMRS_LP >> 2;\r\nfor (k = 0; k < table->num_entries; k++)\r\ntable->mc_reg_table_entry[k].mc_data[j] =\r\n((temp_reg & 0xffff0000)) |\r\n((table->mc_reg_table_entry[k].mc_data[i] & 0xffff0000) >> 16);\r\nj++;\r\nif (j >= SMC_NISLANDS_MC_REGISTER_ARRAY_SIZE)\r\nreturn -EINVAL;\r\ntemp_reg = RREG32(MC_PMG_CMD_MRS);\r\ntable->mc_reg_address[j].s1 = MC_PMG_CMD_MRS >> 2;\r\ntable->mc_reg_address[j].s0 = MC_SEQ_PMG_CMD_MRS_LP >> 2;\r\nfor(k = 0; k < table->num_entries; k++) {\r\ntable->mc_reg_table_entry[k].mc_data[j] =\r\n(temp_reg & 0xffff0000) |\r\n(table->mc_reg_table_entry[k].mc_data[i] & 0x0000ffff);\r\nif (!pi->mem_gddr5)\r\ntable->mc_reg_table_entry[k].mc_data[j] |= 0x100;\r\n}\r\nj++;\r\nif (j > SMC_NISLANDS_MC_REGISTER_ARRAY_SIZE)\r\nreturn -EINVAL;\r\nbreak;\r\ncase MC_SEQ_RESERVE_M >> 2:\r\ntemp_reg = RREG32(MC_PMG_CMD_MRS1);\r\ntable->mc_reg_address[j].s1 = MC_PMG_CMD_MRS1 >> 2;\r\ntable->mc_reg_address[j].s0 = MC_SEQ_PMG_CMD_MRS1_LP >> 2;\r\nfor (k = 0; k < table->num_entries; k++)\r\ntable->mc_reg_table_entry[k].mc_data[j] =\r\n(temp_reg & 0xffff0000) |\r\n(table->mc_reg_table_entry[k].mc_data[i] & 0x0000ffff);\r\nj++;\r\nif (j > SMC_NISLANDS_MC_REGISTER_ARRAY_SIZE)\r\nreturn -EINVAL;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\ntable->last = j;\r\nreturn 0;\r\n}\r\nstatic bool ni_check_s0_mc_reg_index(u16 in_reg, u16 *out_reg)\r\n{\r\nbool result = true;\r\nswitch (in_reg) {\r\ncase MC_SEQ_RAS_TIMING >> 2:\r\n*out_reg = MC_SEQ_RAS_TIMING_LP >> 2;\r\nbreak;\r\ncase MC_SEQ_CAS_TIMING >> 2:\r\n*out_reg = MC_SEQ_CAS_TIMING_LP >> 2;\r\nbreak;\r\ncase MC_SEQ_MISC_TIMING >> 2:\r\n*out_reg = MC_SEQ_MISC_TIMING_LP >> 2;\r\nbreak;\r\ncase MC_SEQ_MISC_TIMING2 >> 2:\r\n*out_reg = MC_SEQ_MISC_TIMING2_LP >> 2;\r\nbreak;\r\ncase MC_SEQ_RD_CTL_D0 >> 2:\r\n*out_reg = MC_SEQ_RD_CTL_D0_LP >> 2;\r\nbreak;\r\ncase MC_SEQ_RD_CTL_D1 >> 2:\r\n*out_reg = MC_SEQ_RD_CTL_D1_LP >> 2;\r\nbreak;\r\ncase MC_SEQ_WR_CTL_D0 >> 2:\r\n*out_reg = MC_SEQ_WR_CTL_D0_LP >> 2;\r\nbreak;\r\ncase MC_SEQ_WR_CTL_D1 >> 2:\r\n*out_reg = MC_SEQ_WR_CTL_D1_LP >> 2;\r\nbreak;\r\ncase MC_PMG_CMD_EMRS >> 2:\r\n*out_reg = MC_SEQ_PMG_CMD_EMRS_LP >> 2;\r\nbreak;\r\ncase MC_PMG_CMD_MRS >> 2:\r\n*out_reg = MC_SEQ_PMG_CMD_MRS_LP >> 2;\r\nbreak;\r\ncase MC_PMG_CMD_MRS1 >> 2:\r\n*out_reg = MC_SEQ_PMG_CMD_MRS1_LP >> 2;\r\nbreak;\r\ncase MC_SEQ_PMG_TIMING >> 2:\r\n*out_reg = MC_SEQ_PMG_TIMING_LP >> 2;\r\nbreak;\r\ncase MC_PMG_CMD_MRS2 >> 2:\r\n*out_reg = MC_SEQ_PMG_CMD_MRS2_LP >> 2;\r\nbreak;\r\ndefault:\r\nresult = false;\r\nbreak;\r\n}\r\nreturn result;\r\n}\r\nstatic void ni_set_valid_flag(struct ni_mc_reg_table *table)\r\n{\r\nu8 i, j;\r\nfor (i = 0; i < table->last; i++) {\r\nfor (j = 1; j < table->num_entries; j++) {\r\nif (table->mc_reg_table_entry[j-1].mc_data[i] != table->mc_reg_table_entry[j].mc_data[i]) {\r\ntable->valid_flag |= 1 << i;\r\nbreak;\r\n}\r\n}\r\n}\r\n}\r\nstatic void ni_set_s0_mc_reg_index(struct ni_mc_reg_table *table)\r\n{\r\nu32 i;\r\nu16 address;\r\nfor (i = 0; i < table->last; i++)\r\ntable->mc_reg_address[i].s0 =\r\nni_check_s0_mc_reg_index(table->mc_reg_address[i].s1, &address) ?\r\naddress : table->mc_reg_address[i].s1;\r\n}\r\nstatic int ni_copy_vbios_mc_reg_table(struct atom_mc_reg_table *table,\r\nstruct ni_mc_reg_table *ni_table)\r\n{\r\nu8 i, j;\r\nif (table->last > SMC_NISLANDS_MC_REGISTER_ARRAY_SIZE)\r\nreturn -EINVAL;\r\nif (table->num_entries > MAX_AC_TIMING_ENTRIES)\r\nreturn -EINVAL;\r\nfor (i = 0; i < table->last; i++)\r\nni_table->mc_reg_address[i].s1 = table->mc_reg_address[i].s1;\r\nni_table->last = table->last;\r\nfor (i = 0; i < table->num_entries; i++) {\r\nni_table->mc_reg_table_entry[i].mclk_max =\r\ntable->mc_reg_table_entry[i].mclk_max;\r\nfor (j = 0; j < table->last; j++)\r\nni_table->mc_reg_table_entry[i].mc_data[j] =\r\ntable->mc_reg_table_entry[i].mc_data[j];\r\n}\r\nni_table->num_entries = table->num_entries;\r\nreturn 0;\r\n}\r\nstatic int ni_initialize_mc_reg_table(struct radeon_device *rdev)\r\n{\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nint ret;\r\nstruct atom_mc_reg_table *table;\r\nstruct ni_mc_reg_table *ni_table = &ni_pi->mc_reg_table;\r\nu8 module_index = rv770_get_memory_module_index(rdev);\r\ntable = kzalloc(sizeof(struct atom_mc_reg_table), GFP_KERNEL);\r\nif (!table)\r\nreturn -ENOMEM;\r\nWREG32(MC_SEQ_RAS_TIMING_LP, RREG32(MC_SEQ_RAS_TIMING));\r\nWREG32(MC_SEQ_CAS_TIMING_LP, RREG32(MC_SEQ_CAS_TIMING));\r\nWREG32(MC_SEQ_MISC_TIMING_LP, RREG32(MC_SEQ_MISC_TIMING));\r\nWREG32(MC_SEQ_MISC_TIMING2_LP, RREG32(MC_SEQ_MISC_TIMING2));\r\nWREG32(MC_SEQ_PMG_CMD_EMRS_LP, RREG32(MC_PMG_CMD_EMRS));\r\nWREG32(MC_SEQ_PMG_CMD_MRS_LP, RREG32(MC_PMG_CMD_MRS));\r\nWREG32(MC_SEQ_PMG_CMD_MRS1_LP, RREG32(MC_PMG_CMD_MRS1));\r\nWREG32(MC_SEQ_WR_CTL_D0_LP, RREG32(MC_SEQ_WR_CTL_D0));\r\nWREG32(MC_SEQ_WR_CTL_D1_LP, RREG32(MC_SEQ_WR_CTL_D1));\r\nWREG32(MC_SEQ_RD_CTL_D0_LP, RREG32(MC_SEQ_RD_CTL_D0));\r\nWREG32(MC_SEQ_RD_CTL_D1_LP, RREG32(MC_SEQ_RD_CTL_D1));\r\nWREG32(MC_SEQ_PMG_TIMING_LP, RREG32(MC_SEQ_PMG_TIMING));\r\nWREG32(MC_SEQ_PMG_CMD_MRS2_LP, RREG32(MC_PMG_CMD_MRS2));\r\nret = radeon_atom_init_mc_reg_table(rdev, module_index, table);\r\nif (ret)\r\ngoto init_mc_done;\r\nret = ni_copy_vbios_mc_reg_table(table, ni_table);\r\nif (ret)\r\ngoto init_mc_done;\r\nni_set_s0_mc_reg_index(ni_table);\r\nret = ni_set_mc_special_registers(rdev, ni_table);\r\nif (ret)\r\ngoto init_mc_done;\r\nni_set_valid_flag(ni_table);\r\ninit_mc_done:\r\nkfree(table);\r\nreturn ret;\r\n}\r\nstatic void ni_populate_mc_reg_addresses(struct radeon_device *rdev,\r\nSMC_NIslands_MCRegisters *mc_reg_table)\r\n{\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nu32 i, j;\r\nfor (i = 0, j = 0; j < ni_pi->mc_reg_table.last; j++) {\r\nif (ni_pi->mc_reg_table.valid_flag & (1 << j)) {\r\nif (i >= SMC_NISLANDS_MC_REGISTER_ARRAY_SIZE)\r\nbreak;\r\nmc_reg_table->address[i].s0 =\r\ncpu_to_be16(ni_pi->mc_reg_table.mc_reg_address[j].s0);\r\nmc_reg_table->address[i].s1 =\r\ncpu_to_be16(ni_pi->mc_reg_table.mc_reg_address[j].s1);\r\ni++;\r\n}\r\n}\r\nmc_reg_table->last = (u8)i;\r\n}\r\nstatic void ni_convert_mc_registers(struct ni_mc_reg_entry *entry,\r\nSMC_NIslands_MCRegisterSet *data,\r\nu32 num_entries, u32 valid_flag)\r\n{\r\nu32 i, j;\r\nfor (i = 0, j = 0; j < num_entries; j++) {\r\nif (valid_flag & (1 << j)) {\r\ndata->value[i] = cpu_to_be32(entry->mc_data[j]);\r\ni++;\r\n}\r\n}\r\n}\r\nstatic void ni_convert_mc_reg_table_entry_to_smc(struct radeon_device *rdev,\r\nstruct rv7xx_pl *pl,\r\nSMC_NIslands_MCRegisterSet *mc_reg_table_data)\r\n{\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nu32 i = 0;\r\nfor (i = 0; i < ni_pi->mc_reg_table.num_entries; i++) {\r\nif (pl->mclk <= ni_pi->mc_reg_table.mc_reg_table_entry[i].mclk_max)\r\nbreak;\r\n}\r\nif ((i == ni_pi->mc_reg_table.num_entries) && (i > 0))\r\n--i;\r\nni_convert_mc_registers(&ni_pi->mc_reg_table.mc_reg_table_entry[i],\r\nmc_reg_table_data,\r\nni_pi->mc_reg_table.last,\r\nni_pi->mc_reg_table.valid_flag);\r\n}\r\nstatic void ni_convert_mc_reg_table_to_smc(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_state,\r\nSMC_NIslands_MCRegisters *mc_reg_table)\r\n{\r\nstruct ni_ps *state = ni_get_ps(radeon_state);\r\nint i;\r\nfor (i = 0; i < state->performance_level_count; i++) {\r\nni_convert_mc_reg_table_entry_to_smc(rdev,\r\n&state->performance_levels[i],\r\n&mc_reg_table->data[NISLANDS_MCREGISTERTABLE_FIRST_DRIVERSTATE_SLOT + i]);\r\n}\r\n}\r\nstatic int ni_populate_mc_reg_table(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_boot_state)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nstruct ni_ps *boot_state = ni_get_ps(radeon_boot_state);\r\nSMC_NIslands_MCRegisters *mc_reg_table = &ni_pi->smc_mc_reg_table;\r\nmemset(mc_reg_table, 0, sizeof(SMC_NIslands_MCRegisters));\r\nrv770_write_smc_soft_register(rdev, NI_SMC_SOFT_REGISTER_seq_index, 1);\r\nni_populate_mc_reg_addresses(rdev, mc_reg_table);\r\nni_convert_mc_reg_table_entry_to_smc(rdev, &boot_state->performance_levels[0],\r\n&mc_reg_table->data[0]);\r\nni_convert_mc_registers(&ni_pi->mc_reg_table.mc_reg_table_entry[0],\r\n&mc_reg_table->data[1],\r\nni_pi->mc_reg_table.last,\r\nni_pi->mc_reg_table.valid_flag);\r\nni_convert_mc_reg_table_to_smc(rdev, radeon_boot_state, mc_reg_table);\r\nreturn rv770_copy_bytes_to_smc(rdev, eg_pi->mc_reg_table_start,\r\n(u8 *)mc_reg_table,\r\nsizeof(SMC_NIslands_MCRegisters),\r\npi->sram_end);\r\n}\r\nstatic int ni_upload_mc_reg_table(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_new_state)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nstruct ni_ps *ni_new_state = ni_get_ps(radeon_new_state);\r\nSMC_NIslands_MCRegisters *mc_reg_table = &ni_pi->smc_mc_reg_table;\r\nu16 address;\r\nmemset(mc_reg_table, 0, sizeof(SMC_NIslands_MCRegisters));\r\nni_convert_mc_reg_table_to_smc(rdev, radeon_new_state, mc_reg_table);\r\naddress = eg_pi->mc_reg_table_start +\r\n(u16)offsetof(SMC_NIslands_MCRegisters, data[NISLANDS_MCREGISTERTABLE_FIRST_DRIVERSTATE_SLOT]);\r\nreturn rv770_copy_bytes_to_smc(rdev, address,\r\n(u8 *)&mc_reg_table->data[NISLANDS_MCREGISTERTABLE_FIRST_DRIVERSTATE_SLOT],\r\nsizeof(SMC_NIslands_MCRegisterSet) * ni_new_state->performance_level_count,\r\npi->sram_end);\r\n}\r\nstatic int ni_init_driver_calculated_leakage_table(struct radeon_device *rdev,\r\nPP_NIslands_CACTABLES *cac_tables)\r\n{\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nu32 leakage = 0;\r\nunsigned int i, j, table_size;\r\ns32 t;\r\nu32 smc_leakage, max_leakage = 0;\r\nu32 scaling_factor;\r\ntable_size = eg_pi->vddc_voltage_table.count;\r\nif (SMC_NISLANDS_LKGE_LUT_NUM_OF_VOLT_ENTRIES < table_size)\r\ntable_size = SMC_NISLANDS_LKGE_LUT_NUM_OF_VOLT_ENTRIES;\r\nscaling_factor = ni_get_smc_power_scaling_factor(rdev);\r\nfor (i = 0; i < SMC_NISLANDS_LKGE_LUT_NUM_OF_TEMP_ENTRIES; i++) {\r\nfor (j = 0; j < table_size; j++) {\r\nt = (1000 * ((i + 1) * 8));\r\nif (t < ni_pi->cac_data.leakage_minimum_temperature)\r\nt = ni_pi->cac_data.leakage_minimum_temperature;\r\nni_calculate_leakage_for_v_and_t(rdev,\r\n&ni_pi->cac_data.leakage_coefficients,\r\neg_pi->vddc_voltage_table.entries[j].value,\r\nt,\r\nni_pi->cac_data.i_leakage,\r\n&leakage);\r\nsmc_leakage = ni_scale_power_for_smc(leakage, scaling_factor) / 1000;\r\nif (smc_leakage > max_leakage)\r\nmax_leakage = smc_leakage;\r\ncac_tables->cac_lkge_lut[i][j] = cpu_to_be32(smc_leakage);\r\n}\r\n}\r\nfor (j = table_size; j < SMC_NISLANDS_LKGE_LUT_NUM_OF_VOLT_ENTRIES; j++) {\r\nfor (i = 0; i < SMC_NISLANDS_LKGE_LUT_NUM_OF_TEMP_ENTRIES; i++)\r\ncac_tables->cac_lkge_lut[i][j] = cpu_to_be32(max_leakage);\r\n}\r\nreturn 0;\r\n}\r\nstatic int ni_init_simplified_leakage_table(struct radeon_device *rdev,\r\nPP_NIslands_CACTABLES *cac_tables)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct radeon_cac_leakage_table *leakage_table =\r\n&rdev->pm.dpm.dyn_state.cac_leakage_table;\r\nu32 i, j, table_size;\r\nu32 smc_leakage, max_leakage = 0;\r\nu32 scaling_factor;\r\nif (!leakage_table)\r\nreturn -EINVAL;\r\ntable_size = leakage_table->count;\r\nif (eg_pi->vddc_voltage_table.count != table_size)\r\ntable_size = (eg_pi->vddc_voltage_table.count < leakage_table->count) ?\r\neg_pi->vddc_voltage_table.count : leakage_table->count;\r\nif (SMC_NISLANDS_LKGE_LUT_NUM_OF_VOLT_ENTRIES < table_size)\r\ntable_size = SMC_NISLANDS_LKGE_LUT_NUM_OF_VOLT_ENTRIES;\r\nif (table_size == 0)\r\nreturn -EINVAL;\r\nscaling_factor = ni_get_smc_power_scaling_factor(rdev);\r\nfor (j = 0; j < table_size; j++) {\r\nsmc_leakage = leakage_table->entries[j].leakage;\r\nif (smc_leakage > max_leakage)\r\nmax_leakage = smc_leakage;\r\nfor (i = 0; i < SMC_NISLANDS_LKGE_LUT_NUM_OF_TEMP_ENTRIES; i++)\r\ncac_tables->cac_lkge_lut[i][j] =\r\ncpu_to_be32(ni_scale_power_for_smc(smc_leakage, scaling_factor));\r\n}\r\nfor (j = table_size; j < SMC_NISLANDS_LKGE_LUT_NUM_OF_VOLT_ENTRIES; j++) {\r\nfor (i = 0; i < SMC_NISLANDS_LKGE_LUT_NUM_OF_TEMP_ENTRIES; i++)\r\ncac_tables->cac_lkge_lut[i][j] =\r\ncpu_to_be32(ni_scale_power_for_smc(max_leakage, scaling_factor));\r\n}\r\nreturn 0;\r\n}\r\nstatic int ni_initialize_smc_cac_tables(struct radeon_device *rdev)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nPP_NIslands_CACTABLES *cac_tables = NULL;\r\nint i, ret;\r\nu32 reg;\r\nif (ni_pi->enable_cac == false)\r\nreturn 0;\r\ncac_tables = kzalloc(sizeof(PP_NIslands_CACTABLES), GFP_KERNEL);\r\nif (!cac_tables)\r\nreturn -ENOMEM;\r\nreg = RREG32(CG_CAC_CTRL) & ~(TID_CNT_MASK | TID_UNIT_MASK);\r\nreg |= (TID_CNT(ni_pi->cac_weights->tid_cnt) |\r\nTID_UNIT(ni_pi->cac_weights->tid_unit));\r\nWREG32(CG_CAC_CTRL, reg);\r\nfor (i = 0; i < NISLANDS_DCCAC_MAX_LEVELS; i++)\r\nni_pi->dc_cac_table[i] = ni_pi->cac_weights->dc_cac[i];\r\nfor (i = 0; i < SMC_NISLANDS_BIF_LUT_NUM_OF_ENTRIES; i++)\r\ncac_tables->cac_bif_lut[i] = ni_pi->cac_weights->pcie_cac[i];\r\nni_pi->cac_data.i_leakage = rdev->pm.dpm.cac_leakage;\r\nni_pi->cac_data.pwr_const = 0;\r\nni_pi->cac_data.dc_cac_value = ni_pi->dc_cac_table[NISLANDS_DCCAC_LEVEL_0];\r\nni_pi->cac_data.bif_cac_value = 0;\r\nni_pi->cac_data.mc_wr_weight = ni_pi->cac_weights->mc_write_weight;\r\nni_pi->cac_data.mc_rd_weight = ni_pi->cac_weights->mc_read_weight;\r\nni_pi->cac_data.allow_ovrflw = 0;\r\nni_pi->cac_data.l2num_win_tdp = ni_pi->lta_window_size;\r\nni_pi->cac_data.num_win_tdp = 0;\r\nni_pi->cac_data.lts_truncate_n = ni_pi->lts_truncate;\r\nif (ni_pi->driver_calculate_cac_leakage)\r\nret = ni_init_driver_calculated_leakage_table(rdev, cac_tables);\r\nelse\r\nret = ni_init_simplified_leakage_table(rdev, cac_tables);\r\nif (ret)\r\ngoto done_free;\r\ncac_tables->pwr_const = cpu_to_be32(ni_pi->cac_data.pwr_const);\r\ncac_tables->dc_cacValue = cpu_to_be32(ni_pi->cac_data.dc_cac_value);\r\ncac_tables->bif_cacValue = cpu_to_be32(ni_pi->cac_data.bif_cac_value);\r\ncac_tables->AllowOvrflw = ni_pi->cac_data.allow_ovrflw;\r\ncac_tables->MCWrWeight = ni_pi->cac_data.mc_wr_weight;\r\ncac_tables->MCRdWeight = ni_pi->cac_data.mc_rd_weight;\r\ncac_tables->numWin_TDP = ni_pi->cac_data.num_win_tdp;\r\ncac_tables->l2numWin_TDP = ni_pi->cac_data.l2num_win_tdp;\r\ncac_tables->lts_truncate_n = ni_pi->cac_data.lts_truncate_n;\r\nret = rv770_copy_bytes_to_smc(rdev, ni_pi->cac_table_start, (u8 *)cac_tables,\r\nsizeof(PP_NIslands_CACTABLES), pi->sram_end);\r\ndone_free:\r\nif (ret) {\r\nni_pi->enable_cac = false;\r\nni_pi->enable_power_containment = false;\r\n}\r\nkfree(cac_tables);\r\nreturn 0;\r\n}\r\nstatic int ni_initialize_hardware_cac_manager(struct radeon_device *rdev)\r\n{\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nu32 reg;\r\nif (!ni_pi->enable_cac ||\r\n!ni_pi->cac_configuration_required)\r\nreturn 0;\r\nif (ni_pi->cac_weights == NULL)\r\nreturn -EINVAL;\r\nreg = RREG32_CG(CG_CAC_REGION_1_WEIGHT_0) & ~(WEIGHT_TCP_SIG0_MASK |\r\nWEIGHT_TCP_SIG1_MASK |\r\nWEIGHT_TA_SIG_MASK);\r\nreg |= (WEIGHT_TCP_SIG0(ni_pi->cac_weights->weight_tcp_sig0) |\r\nWEIGHT_TCP_SIG1(ni_pi->cac_weights->weight_tcp_sig1) |\r\nWEIGHT_TA_SIG(ni_pi->cac_weights->weight_ta_sig));\r\nWREG32_CG(CG_CAC_REGION_1_WEIGHT_0, reg);\r\nreg = RREG32_CG(CG_CAC_REGION_1_WEIGHT_1) & ~(WEIGHT_TCC_EN0_MASK |\r\nWEIGHT_TCC_EN1_MASK |\r\nWEIGHT_TCC_EN2_MASK);\r\nreg |= (WEIGHT_TCC_EN0(ni_pi->cac_weights->weight_tcc_en0) |\r\nWEIGHT_TCC_EN1(ni_pi->cac_weights->weight_tcc_en1) |\r\nWEIGHT_TCC_EN2(ni_pi->cac_weights->weight_tcc_en2));\r\nWREG32_CG(CG_CAC_REGION_1_WEIGHT_1, reg);\r\nreg = RREG32_CG(CG_CAC_REGION_2_WEIGHT_0) & ~(WEIGHT_CB_EN0_MASK |\r\nWEIGHT_CB_EN1_MASK |\r\nWEIGHT_CB_EN2_MASK |\r\nWEIGHT_CB_EN3_MASK);\r\nreg |= (WEIGHT_CB_EN0(ni_pi->cac_weights->weight_cb_en0) |\r\nWEIGHT_CB_EN1(ni_pi->cac_weights->weight_cb_en1) |\r\nWEIGHT_CB_EN2(ni_pi->cac_weights->weight_cb_en2) |\r\nWEIGHT_CB_EN3(ni_pi->cac_weights->weight_cb_en3));\r\nWREG32_CG(CG_CAC_REGION_2_WEIGHT_0, reg);\r\nreg = RREG32_CG(CG_CAC_REGION_2_WEIGHT_1) & ~(WEIGHT_DB_SIG0_MASK |\r\nWEIGHT_DB_SIG1_MASK |\r\nWEIGHT_DB_SIG2_MASK |\r\nWEIGHT_DB_SIG3_MASK);\r\nreg |= (WEIGHT_DB_SIG0(ni_pi->cac_weights->weight_db_sig0) |\r\nWEIGHT_DB_SIG1(ni_pi->cac_weights->weight_db_sig1) |\r\nWEIGHT_DB_SIG2(ni_pi->cac_weights->weight_db_sig2) |\r\nWEIGHT_DB_SIG3(ni_pi->cac_weights->weight_db_sig3));\r\nWREG32_CG(CG_CAC_REGION_2_WEIGHT_1, reg);\r\nreg = RREG32_CG(CG_CAC_REGION_2_WEIGHT_2) & ~(WEIGHT_SXM_SIG0_MASK |\r\nWEIGHT_SXM_SIG1_MASK |\r\nWEIGHT_SXM_SIG2_MASK |\r\nWEIGHT_SXS_SIG0_MASK |\r\nWEIGHT_SXS_SIG1_MASK);\r\nreg |= (WEIGHT_SXM_SIG0(ni_pi->cac_weights->weight_sxm_sig0) |\r\nWEIGHT_SXM_SIG1(ni_pi->cac_weights->weight_sxm_sig1) |\r\nWEIGHT_SXM_SIG2(ni_pi->cac_weights->weight_sxm_sig2) |\r\nWEIGHT_SXS_SIG0(ni_pi->cac_weights->weight_sxs_sig0) |\r\nWEIGHT_SXS_SIG1(ni_pi->cac_weights->weight_sxs_sig1));\r\nWREG32_CG(CG_CAC_REGION_2_WEIGHT_2, reg);\r\nreg = RREG32_CG(CG_CAC_REGION_3_WEIGHT_0) & ~(WEIGHT_XBR_0_MASK |\r\nWEIGHT_XBR_1_MASK |\r\nWEIGHT_XBR_2_MASK |\r\nWEIGHT_SPI_SIG0_MASK);\r\nreg |= (WEIGHT_XBR_0(ni_pi->cac_weights->weight_xbr_0) |\r\nWEIGHT_XBR_1(ni_pi->cac_weights->weight_xbr_1) |\r\nWEIGHT_XBR_2(ni_pi->cac_weights->weight_xbr_2) |\r\nWEIGHT_SPI_SIG0(ni_pi->cac_weights->weight_spi_sig0));\r\nWREG32_CG(CG_CAC_REGION_3_WEIGHT_0, reg);\r\nreg = RREG32_CG(CG_CAC_REGION_3_WEIGHT_1) & ~(WEIGHT_SPI_SIG1_MASK |\r\nWEIGHT_SPI_SIG2_MASK |\r\nWEIGHT_SPI_SIG3_MASK |\r\nWEIGHT_SPI_SIG4_MASK |\r\nWEIGHT_SPI_SIG5_MASK);\r\nreg |= (WEIGHT_SPI_SIG1(ni_pi->cac_weights->weight_spi_sig1) |\r\nWEIGHT_SPI_SIG2(ni_pi->cac_weights->weight_spi_sig2) |\r\nWEIGHT_SPI_SIG3(ni_pi->cac_weights->weight_spi_sig3) |\r\nWEIGHT_SPI_SIG4(ni_pi->cac_weights->weight_spi_sig4) |\r\nWEIGHT_SPI_SIG5(ni_pi->cac_weights->weight_spi_sig5));\r\nWREG32_CG(CG_CAC_REGION_3_WEIGHT_1, reg);\r\nreg = RREG32_CG(CG_CAC_REGION_4_WEIGHT_0) & ~(WEIGHT_LDS_SIG0_MASK |\r\nWEIGHT_LDS_SIG1_MASK |\r\nWEIGHT_SC_MASK);\r\nreg |= (WEIGHT_LDS_SIG0(ni_pi->cac_weights->weight_lds_sig0) |\r\nWEIGHT_LDS_SIG1(ni_pi->cac_weights->weight_lds_sig1) |\r\nWEIGHT_SC(ni_pi->cac_weights->weight_sc));\r\nWREG32_CG(CG_CAC_REGION_4_WEIGHT_0, reg);\r\nreg = RREG32_CG(CG_CAC_REGION_4_WEIGHT_1) & ~(WEIGHT_BIF_MASK |\r\nWEIGHT_CP_MASK |\r\nWEIGHT_PA_SIG0_MASK |\r\nWEIGHT_PA_SIG1_MASK |\r\nWEIGHT_VGT_SIG0_MASK);\r\nreg |= (WEIGHT_BIF(ni_pi->cac_weights->weight_bif) |\r\nWEIGHT_CP(ni_pi->cac_weights->weight_cp) |\r\nWEIGHT_PA_SIG0(ni_pi->cac_weights->weight_pa_sig0) |\r\nWEIGHT_PA_SIG1(ni_pi->cac_weights->weight_pa_sig1) |\r\nWEIGHT_VGT_SIG0(ni_pi->cac_weights->weight_vgt_sig0));\r\nWREG32_CG(CG_CAC_REGION_4_WEIGHT_1, reg);\r\nreg = RREG32_CG(CG_CAC_REGION_4_WEIGHT_2) & ~(WEIGHT_VGT_SIG1_MASK |\r\nWEIGHT_VGT_SIG2_MASK |\r\nWEIGHT_DC_SIG0_MASK |\r\nWEIGHT_DC_SIG1_MASK |\r\nWEIGHT_DC_SIG2_MASK);\r\nreg |= (WEIGHT_VGT_SIG1(ni_pi->cac_weights->weight_vgt_sig1) |\r\nWEIGHT_VGT_SIG2(ni_pi->cac_weights->weight_vgt_sig2) |\r\nWEIGHT_DC_SIG0(ni_pi->cac_weights->weight_dc_sig0) |\r\nWEIGHT_DC_SIG1(ni_pi->cac_weights->weight_dc_sig1) |\r\nWEIGHT_DC_SIG2(ni_pi->cac_weights->weight_dc_sig2));\r\nWREG32_CG(CG_CAC_REGION_4_WEIGHT_2, reg);\r\nreg = RREG32_CG(CG_CAC_REGION_4_WEIGHT_3) & ~(WEIGHT_DC_SIG3_MASK |\r\nWEIGHT_UVD_SIG0_MASK |\r\nWEIGHT_UVD_SIG1_MASK |\r\nWEIGHT_SPARE0_MASK |\r\nWEIGHT_SPARE1_MASK);\r\nreg |= (WEIGHT_DC_SIG3(ni_pi->cac_weights->weight_dc_sig3) |\r\nWEIGHT_UVD_SIG0(ni_pi->cac_weights->weight_uvd_sig0) |\r\nWEIGHT_UVD_SIG1(ni_pi->cac_weights->weight_uvd_sig1) |\r\nWEIGHT_SPARE0(ni_pi->cac_weights->weight_spare0) |\r\nWEIGHT_SPARE1(ni_pi->cac_weights->weight_spare1));\r\nWREG32_CG(CG_CAC_REGION_4_WEIGHT_3, reg);\r\nreg = RREG32_CG(CG_CAC_REGION_5_WEIGHT_0) & ~(WEIGHT_SQ_VSP_MASK |\r\nWEIGHT_SQ_VSP0_MASK);\r\nreg |= (WEIGHT_SQ_VSP(ni_pi->cac_weights->weight_sq_vsp) |\r\nWEIGHT_SQ_VSP0(ni_pi->cac_weights->weight_sq_vsp0));\r\nWREG32_CG(CG_CAC_REGION_5_WEIGHT_0, reg);\r\nreg = RREG32_CG(CG_CAC_REGION_5_WEIGHT_1) & ~(WEIGHT_SQ_GPR_MASK);\r\nreg |= WEIGHT_SQ_GPR(ni_pi->cac_weights->weight_sq_gpr);\r\nWREG32_CG(CG_CAC_REGION_5_WEIGHT_1, reg);\r\nreg = RREG32_CG(CG_CAC_REGION_4_OVERRIDE_4) & ~(OVR_MODE_SPARE_0_MASK |\r\nOVR_VAL_SPARE_0_MASK |\r\nOVR_MODE_SPARE_1_MASK |\r\nOVR_VAL_SPARE_1_MASK);\r\nreg |= (OVR_MODE_SPARE_0(ni_pi->cac_weights->ovr_mode_spare_0) |\r\nOVR_VAL_SPARE_0(ni_pi->cac_weights->ovr_val_spare_0) |\r\nOVR_MODE_SPARE_1(ni_pi->cac_weights->ovr_mode_spare_1) |\r\nOVR_VAL_SPARE_1(ni_pi->cac_weights->ovr_val_spare_1));\r\nWREG32_CG(CG_CAC_REGION_4_OVERRIDE_4, reg);\r\nreg = RREG32(SQ_CAC_THRESHOLD) & ~(VSP_MASK |\r\nVSP0_MASK |\r\nGPR_MASK);\r\nreg |= (VSP(ni_pi->cac_weights->vsp) |\r\nVSP0(ni_pi->cac_weights->vsp0) |\r\nGPR(ni_pi->cac_weights->gpr));\r\nWREG32(SQ_CAC_THRESHOLD, reg);\r\nreg = (MCDW_WR_ENABLE |\r\nMCDX_WR_ENABLE |\r\nMCDY_WR_ENABLE |\r\nMCDZ_WR_ENABLE |\r\nINDEX(0x09D4));\r\nWREG32(MC_CG_CONFIG, reg);\r\nreg = (READ_WEIGHT(ni_pi->cac_weights->mc_read_weight) |\r\nWRITE_WEIGHT(ni_pi->cac_weights->mc_write_weight) |\r\nALLOW_OVERFLOW);\r\nWREG32(MC_CG_DATAPORT, reg);\r\nreturn 0;\r\n}\r\nstatic int ni_enable_smc_cac(struct radeon_device *rdev,\r\nstruct radeon_ps *radeon_new_state,\r\nbool enable)\r\n{\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\nint ret = 0;\r\nPPSMC_Result smc_result;\r\nif (ni_pi->enable_cac) {\r\nif (enable) {\r\nif (!r600_is_uvd_state(radeon_new_state->class, radeon_new_state->class2)) {\r\nsmc_result = rv770_send_msg_to_smc(rdev, PPSMC_MSG_CollectCAC_PowerCorreln);\r\nif (ni_pi->support_cac_long_term_average) {\r\nsmc_result = rv770_send_msg_to_smc(rdev, PPSMC_CACLongTermAvgEnable);\r\nif (PPSMC_Result_OK != smc_result)\r\nni_pi->support_cac_long_term_average = false;\r\n}\r\nsmc_result = rv770_send_msg_to_smc(rdev, PPSMC_MSG_EnableCac);\r\nif (PPSMC_Result_OK != smc_result)\r\nret = -EINVAL;\r\nni_pi->cac_enabled = (PPSMC_Result_OK == smc_result) ? true : false;\r\n}\r\n} else if (ni_pi->cac_enabled) {\r\nsmc_result = rv770_send_msg_to_smc(rdev, PPSMC_MSG_DisableCac);\r\nni_pi->cac_enabled = false;\r\nif (ni_pi->support_cac_long_term_average) {\r\nsmc_result = rv770_send_msg_to_smc(rdev, PPSMC_CACLongTermAvgDisable);\r\nif (PPSMC_Result_OK != smc_result)\r\nni_pi->support_cac_long_term_average = false;\r\n}\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic int ni_pcie_performance_request(struct radeon_device *rdev,\r\nu8 perf_req, bool advertise)\r\n{\r\n#if defined(CONFIG_ACPI)\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nif ((perf_req == PCIE_PERF_REQ_PECI_GEN1) ||\r\n(perf_req == PCIE_PERF_REQ_PECI_GEN2)) {\r\nif (eg_pi->pcie_performance_request_registered == false)\r\nradeon_acpi_pcie_notify_device_ready(rdev);\r\neg_pi->pcie_performance_request_registered = true;\r\nreturn radeon_acpi_pcie_performance_request(rdev, perf_req, advertise);\r\n} else if ((perf_req == PCIE_PERF_REQ_REMOVE_REGISTRY) &&\r\neg_pi->pcie_performance_request_registered) {\r\neg_pi->pcie_performance_request_registered = false;\r\nreturn radeon_acpi_pcie_performance_request(rdev, perf_req, advertise);\r\n}\r\n#endif\r\nreturn 0;\r\n}\r\nstatic int ni_advertise_gen2_capability(struct radeon_device *rdev)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nu32 tmp;\r\ntmp = RREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL);\r\nif ((tmp & LC_OTHER_SIDE_EVER_SENT_GEN2) &&\r\n(tmp & LC_OTHER_SIDE_SUPPORTS_GEN2))\r\npi->pcie_gen2 = true;\r\nelse\r\npi->pcie_gen2 = false;\r\nif (!pi->pcie_gen2)\r\nni_pcie_performance_request(rdev, PCIE_PERF_REQ_PECI_GEN2, true);\r\nreturn 0;\r\n}\r\nstatic void ni_enable_bif_dynamic_pcie_gen2(struct radeon_device *rdev,\r\nbool enable)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nu32 tmp, bif;\r\ntmp = RREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL);\r\nif ((tmp & LC_OTHER_SIDE_EVER_SENT_GEN2) &&\r\n(tmp & LC_OTHER_SIDE_SUPPORTS_GEN2)) {\r\nif (enable) {\r\nif (!pi->boot_in_gen2) {\r\nbif = RREG32(CG_BIF_REQ_AND_RSP) & ~CG_CLIENT_REQ_MASK;\r\nbif |= CG_CLIENT_REQ(0xd);\r\nWREG32(CG_BIF_REQ_AND_RSP, bif);\r\n}\r\ntmp &= ~LC_HW_VOLTAGE_IF_CONTROL_MASK;\r\ntmp |= LC_HW_VOLTAGE_IF_CONTROL(1);\r\ntmp |= LC_GEN2_EN_STRAP;\r\ntmp |= LC_CLR_FAILED_SPD_CHANGE_CNT;\r\nWREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL, tmp);\r\nudelay(10);\r\ntmp &= ~LC_CLR_FAILED_SPD_CHANGE_CNT;\r\nWREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL, tmp);\r\n} else {\r\nif (!pi->boot_in_gen2) {\r\nbif = RREG32(CG_BIF_REQ_AND_RSP) & ~CG_CLIENT_REQ_MASK;\r\nbif |= CG_CLIENT_REQ(0xd);\r\nWREG32(CG_BIF_REQ_AND_RSP, bif);\r\ntmp &= ~LC_HW_VOLTAGE_IF_CONTROL_MASK;\r\ntmp &= ~LC_GEN2_EN_STRAP;\r\n}\r\nWREG32_PCIE_PORT(PCIE_LC_SPEED_CNTL, tmp);\r\n}\r\n}\r\n}\r\nstatic void ni_enable_dynamic_pcie_gen2(struct radeon_device *rdev,\r\nbool enable)\r\n{\r\nni_enable_bif_dynamic_pcie_gen2(rdev, enable);\r\nif (enable)\r\nWREG32_P(GENERAL_PWRMGT, ENABLE_GEN2PCIE, ~ENABLE_GEN2PCIE);\r\nelse\r\nWREG32_P(GENERAL_PWRMGT, 0, ~ENABLE_GEN2PCIE);\r\n}\r\nvoid ni_set_uvd_clock_before_set_eng_clock(struct radeon_device *rdev,\r\nstruct radeon_ps *new_ps,\r\nstruct radeon_ps *old_ps)\r\n{\r\nstruct ni_ps *new_state = ni_get_ps(new_ps);\r\nstruct ni_ps *current_state = ni_get_ps(old_ps);\r\nif ((new_ps->vclk == old_ps->vclk) &&\r\n(new_ps->dclk == old_ps->dclk))\r\nreturn;\r\nif (new_state->performance_levels[new_state->performance_level_count - 1].sclk >=\r\ncurrent_state->performance_levels[current_state->performance_level_count - 1].sclk)\r\nreturn;\r\nradeon_set_uvd_clocks(rdev, new_ps->vclk, new_ps->dclk);\r\n}\r\nvoid ni_set_uvd_clock_after_set_eng_clock(struct radeon_device *rdev,\r\nstruct radeon_ps *new_ps,\r\nstruct radeon_ps *old_ps)\r\n{\r\nstruct ni_ps *new_state = ni_get_ps(new_ps);\r\nstruct ni_ps *current_state = ni_get_ps(old_ps);\r\nif ((new_ps->vclk == old_ps->vclk) &&\r\n(new_ps->dclk == old_ps->dclk))\r\nreturn;\r\nif (new_state->performance_levels[new_state->performance_level_count - 1].sclk <\r\ncurrent_state->performance_levels[current_state->performance_level_count - 1].sclk)\r\nreturn;\r\nradeon_set_uvd_clocks(rdev, new_ps->vclk, new_ps->dclk);\r\n}\r\nvoid ni_dpm_setup_asic(struct radeon_device *rdev)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nint r;\r\nr = ni_mc_load_microcode(rdev);\r\nif (r)\r\nDRM_ERROR("Failed to load MC firmware!\n");\r\nni_read_clock_registers(rdev);\r\nbtc_read_arb_registers(rdev);\r\nrv770_get_memory_type(rdev);\r\nif (eg_pi->pcie_performance_request)\r\nni_advertise_gen2_capability(rdev);\r\nrv770_get_pcie_gen2_status(rdev);\r\nrv770_enable_acpi_pm(rdev);\r\n}\r\nvoid ni_update_current_ps(struct radeon_device *rdev,\r\nstruct radeon_ps *rps)\r\n{\r\nstruct ni_ps *new_ps = ni_get_ps(rps);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\neg_pi->current_rps = *rps;\r\nni_pi->current_ps = *new_ps;\r\neg_pi->current_rps.ps_priv = &ni_pi->current_ps;\r\n}\r\nvoid ni_update_requested_ps(struct radeon_device *rdev,\r\nstruct radeon_ps *rps)\r\n{\r\nstruct ni_ps *new_ps = ni_get_ps(rps);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct ni_power_info *ni_pi = ni_get_pi(rdev);\r\neg_pi->requested_rps = *rps;\r\nni_pi->requested_ps = *new_ps;\r\neg_pi->requested_rps.ps_priv = &ni_pi->requested_ps;\r\n}\r\nint ni_dpm_enable(struct radeon_device *rdev)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct radeon_ps *boot_ps = rdev->pm.dpm.boot_ps;\r\nint ret;\r\nif (pi->gfx_clock_gating)\r\nni_cg_clockgating_default(rdev);\r\nif (btc_dpm_enabled(rdev))\r\nreturn -EINVAL;\r\nif (pi->mg_clock_gating)\r\nni_mg_clockgating_default(rdev);\r\nif (eg_pi->ls_clock_gating)\r\nni_ls_clockgating_default(rdev);\r\nif (pi->voltage_control) {\r\nrv770_enable_voltage_control(rdev, true);\r\nret = cypress_construct_voltage_tables(rdev);\r\nif (ret) {\r\nDRM_ERROR("cypress_construct_voltage_tables failed\n");\r\nreturn ret;\r\n}\r\n}\r\nif (eg_pi->dynamic_ac_timing) {\r\nret = ni_initialize_mc_reg_table(rdev);\r\nif (ret)\r\neg_pi->dynamic_ac_timing = false;\r\n}\r\nif (pi->dynamic_ss)\r\ncypress_enable_spread_spectrum(rdev, true);\r\nif (pi->thermal_protection)\r\nrv770_enable_thermal_protection(rdev, true);\r\nrv770_setup_bsp(rdev);\r\nrv770_program_git(rdev);\r\nrv770_program_tp(rdev);\r\nrv770_program_tpp(rdev);\r\nrv770_program_sstp(rdev);\r\ncypress_enable_display_gap(rdev);\r\nrv770_program_vc(rdev);\r\nif (pi->dynamic_pcie_gen2)\r\nni_enable_dynamic_pcie_gen2(rdev, true);\r\nret = rv770_upload_firmware(rdev);\r\nif (ret) {\r\nDRM_ERROR("rv770_upload_firmware failed\n");\r\nreturn ret;\r\n}\r\nret = ni_process_firmware_header(rdev);\r\nif (ret) {\r\nDRM_ERROR("ni_process_firmware_header failed\n");\r\nreturn ret;\r\n}\r\nret = ni_initial_switch_from_arb_f0_to_f1(rdev);\r\nif (ret) {\r\nDRM_ERROR("ni_initial_switch_from_arb_f0_to_f1 failed\n");\r\nreturn ret;\r\n}\r\nret = ni_init_smc_table(rdev);\r\nif (ret) {\r\nDRM_ERROR("ni_init_smc_table failed\n");\r\nreturn ret;\r\n}\r\nret = ni_init_smc_spll_table(rdev);\r\nif (ret) {\r\nDRM_ERROR("ni_init_smc_spll_table failed\n");\r\nreturn ret;\r\n}\r\nret = ni_init_arb_table_index(rdev);\r\nif (ret) {\r\nDRM_ERROR("ni_init_arb_table_index failed\n");\r\nreturn ret;\r\n}\r\nif (eg_pi->dynamic_ac_timing) {\r\nret = ni_populate_mc_reg_table(rdev, boot_ps);\r\nif (ret) {\r\nDRM_ERROR("ni_populate_mc_reg_table failed\n");\r\nreturn ret;\r\n}\r\n}\r\nret = ni_initialize_smc_cac_tables(rdev);\r\nif (ret) {\r\nDRM_ERROR("ni_initialize_smc_cac_tables failed\n");\r\nreturn ret;\r\n}\r\nret = ni_initialize_hardware_cac_manager(rdev);\r\nif (ret) {\r\nDRM_ERROR("ni_initialize_hardware_cac_manager failed\n");\r\nreturn ret;\r\n}\r\nret = ni_populate_smc_tdp_limits(rdev, boot_ps);\r\nif (ret) {\r\nDRM_ERROR("ni_populate_smc_tdp_limits failed\n");\r\nreturn ret;\r\n}\r\nni_program_response_times(rdev);\r\nr7xx_start_smc(rdev);\r\nret = cypress_notify_smc_display_change(rdev, false);\r\nif (ret) {\r\nDRM_ERROR("cypress_notify_smc_display_change failed\n");\r\nreturn ret;\r\n}\r\ncypress_enable_sclk_control(rdev, true);\r\nif (eg_pi->memory_transition)\r\ncypress_enable_mclk_control(rdev, true);\r\ncypress_start_dpm(rdev);\r\nif (pi->gfx_clock_gating)\r\nni_gfx_clockgating_enable(rdev, true);\r\nif (pi->mg_clock_gating)\r\nni_mg_clockgating_enable(rdev, true);\r\nif (eg_pi->ls_clock_gating)\r\nni_ls_clockgating_enable(rdev, true);\r\nrv770_enable_auto_throttle_source(rdev, RADEON_DPM_AUTO_THROTTLE_SRC_THERMAL, true);\r\nni_update_current_ps(rdev, boot_ps);\r\nreturn 0;\r\n}\r\nvoid ni_dpm_disable(struct radeon_device *rdev)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct radeon_ps *boot_ps = rdev->pm.dpm.boot_ps;\r\nif (!btc_dpm_enabled(rdev))\r\nreturn;\r\nrv770_clear_vc(rdev);\r\nif (pi->thermal_protection)\r\nrv770_enable_thermal_protection(rdev, false);\r\nni_enable_power_containment(rdev, boot_ps, false);\r\nni_enable_smc_cac(rdev, boot_ps, false);\r\ncypress_enable_spread_spectrum(rdev, false);\r\nrv770_enable_auto_throttle_source(rdev, RADEON_DPM_AUTO_THROTTLE_SRC_THERMAL, false);\r\nif (pi->dynamic_pcie_gen2)\r\nni_enable_dynamic_pcie_gen2(rdev, false);\r\nif (rdev->irq.installed &&\r\nr600_is_internal_thermal_sensor(rdev->pm.int_thermal_type)) {\r\nrdev->irq.dpm_thermal = false;\r\nradeon_irq_set(rdev);\r\n}\r\nif (pi->gfx_clock_gating)\r\nni_gfx_clockgating_enable(rdev, false);\r\nif (pi->mg_clock_gating)\r\nni_mg_clockgating_enable(rdev, false);\r\nif (eg_pi->ls_clock_gating)\r\nni_ls_clockgating_enable(rdev, false);\r\nni_stop_dpm(rdev);\r\nbtc_reset_to_default(rdev);\r\nni_stop_smc(rdev);\r\nni_force_switch_to_arb_f0(rdev);\r\nni_update_current_ps(rdev, boot_ps);\r\n}\r\nstatic int ni_power_control_set_level(struct radeon_device *rdev)\r\n{\r\nstruct radeon_ps *new_ps = rdev->pm.dpm.requested_ps;\r\nint ret;\r\nret = ni_restrict_performance_levels_before_switch(rdev);\r\nif (ret)\r\nreturn ret;\r\nret = rv770_halt_smc(rdev);\r\nif (ret)\r\nreturn ret;\r\nret = ni_populate_smc_tdp_limits(rdev, new_ps);\r\nif (ret)\r\nreturn ret;\r\nret = rv770_resume_smc(rdev);\r\nif (ret)\r\nreturn ret;\r\nret = rv770_set_sw_state(rdev);\r\nif (ret)\r\nreturn ret;\r\nreturn 0;\r\n}\r\nint ni_dpm_pre_set_power_state(struct radeon_device *rdev)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct radeon_ps requested_ps = *rdev->pm.dpm.requested_ps;\r\nstruct radeon_ps *new_ps = &requested_ps;\r\nni_update_requested_ps(rdev, new_ps);\r\nni_apply_state_adjust_rules(rdev, &eg_pi->requested_rps);\r\nreturn 0;\r\n}\r\nint ni_dpm_set_power_state(struct radeon_device *rdev)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct radeon_ps *new_ps = &eg_pi->requested_rps;\r\nstruct radeon_ps *old_ps = &eg_pi->current_rps;\r\nint ret;\r\nret = ni_restrict_performance_levels_before_switch(rdev);\r\nif (ret) {\r\nDRM_ERROR("ni_restrict_performance_levels_before_switch failed\n");\r\nreturn ret;\r\n}\r\nni_set_uvd_clock_before_set_eng_clock(rdev, new_ps, old_ps);\r\nret = ni_enable_power_containment(rdev, new_ps, false);\r\nif (ret) {\r\nDRM_ERROR("ni_enable_power_containment failed\n");\r\nreturn ret;\r\n}\r\nret = ni_enable_smc_cac(rdev, new_ps, false);\r\nif (ret) {\r\nDRM_ERROR("ni_enable_smc_cac failed\n");\r\nreturn ret;\r\n}\r\nret = rv770_halt_smc(rdev);\r\nif (ret) {\r\nDRM_ERROR("rv770_halt_smc failed\n");\r\nreturn ret;\r\n}\r\nif (eg_pi->smu_uvd_hs)\r\nbtc_notify_uvd_to_smc(rdev, new_ps);\r\nret = ni_upload_sw_state(rdev, new_ps);\r\nif (ret) {\r\nDRM_ERROR("ni_upload_sw_state failed\n");\r\nreturn ret;\r\n}\r\nif (eg_pi->dynamic_ac_timing) {\r\nret = ni_upload_mc_reg_table(rdev, new_ps);\r\nif (ret) {\r\nDRM_ERROR("ni_upload_mc_reg_table failed\n");\r\nreturn ret;\r\n}\r\n}\r\nret = ni_program_memory_timing_parameters(rdev, new_ps);\r\nif (ret) {\r\nDRM_ERROR("ni_program_memory_timing_parameters failed\n");\r\nreturn ret;\r\n}\r\nret = rv770_resume_smc(rdev);\r\nif (ret) {\r\nDRM_ERROR("rv770_resume_smc failed\n");\r\nreturn ret;\r\n}\r\nret = rv770_set_sw_state(rdev);\r\nif (ret) {\r\nDRM_ERROR("rv770_set_sw_state failed\n");\r\nreturn ret;\r\n}\r\nni_set_uvd_clock_after_set_eng_clock(rdev, new_ps, old_ps);\r\nret = ni_enable_smc_cac(rdev, new_ps, true);\r\nif (ret) {\r\nDRM_ERROR("ni_enable_smc_cac failed\n");\r\nreturn ret;\r\n}\r\nret = ni_enable_power_containment(rdev, new_ps, true);\r\nif (ret) {\r\nDRM_ERROR("ni_enable_power_containment failed\n");\r\nreturn ret;\r\n}\r\nret = ni_power_control_set_level(rdev);\r\nif (ret) {\r\nDRM_ERROR("ni_power_control_set_level failed\n");\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nvoid ni_dpm_post_set_power_state(struct radeon_device *rdev)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct radeon_ps *new_ps = &eg_pi->requested_rps;\r\nni_update_current_ps(rdev, new_ps);\r\n}\r\nstatic void ni_parse_pplib_non_clock_info(struct radeon_device *rdev,\r\nstruct radeon_ps *rps,\r\nstruct _ATOM_PPLIB_NONCLOCK_INFO *non_clock_info,\r\nu8 table_rev)\r\n{\r\nrps->caps = le32_to_cpu(non_clock_info->ulCapsAndSettings);\r\nrps->class = le16_to_cpu(non_clock_info->usClassification);\r\nrps->class2 = le16_to_cpu(non_clock_info->usClassification2);\r\nif (ATOM_PPLIB_NONCLOCKINFO_VER1 < table_rev) {\r\nrps->vclk = le32_to_cpu(non_clock_info->ulVCLK);\r\nrps->dclk = le32_to_cpu(non_clock_info->ulDCLK);\r\n} else if (r600_is_uvd_state(rps->class, rps->class2)) {\r\nrps->vclk = RV770_DEFAULT_VCLK_FREQ;\r\nrps->dclk = RV770_DEFAULT_DCLK_FREQ;\r\n} else {\r\nrps->vclk = 0;\r\nrps->dclk = 0;\r\n}\r\nif (rps->class & ATOM_PPLIB_CLASSIFICATION_BOOT)\r\nrdev->pm.dpm.boot_ps = rps;\r\nif (rps->class & ATOM_PPLIB_CLASSIFICATION_UVDSTATE)\r\nrdev->pm.dpm.uvd_ps = rps;\r\n}\r\nstatic void ni_parse_pplib_clock_info(struct radeon_device *rdev,\r\nstruct radeon_ps *rps, int index,\r\nunion pplib_clock_info *clock_info)\r\n{\r\nstruct rv7xx_power_info *pi = rv770_get_pi(rdev);\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct ni_ps *ps = ni_get_ps(rps);\r\nstruct rv7xx_pl *pl = &ps->performance_levels[index];\r\nps->performance_level_count = index + 1;\r\npl->sclk = le16_to_cpu(clock_info->evergreen.usEngineClockLow);\r\npl->sclk |= clock_info->evergreen.ucEngineClockHigh << 16;\r\npl->mclk = le16_to_cpu(clock_info->evergreen.usMemoryClockLow);\r\npl->mclk |= clock_info->evergreen.ucMemoryClockHigh << 16;\r\npl->vddc = le16_to_cpu(clock_info->evergreen.usVDDC);\r\npl->vddci = le16_to_cpu(clock_info->evergreen.usVDDCI);\r\npl->flags = le32_to_cpu(clock_info->evergreen.ulFlags);\r\nif (pl->vddc == 0xff01) {\r\nif (pi->max_vddc)\r\npl->vddc = pi->max_vddc;\r\n}\r\nif (rps->class & ATOM_PPLIB_CLASSIFICATION_ACPI) {\r\npi->acpi_vddc = pl->vddc;\r\neg_pi->acpi_vddci = pl->vddci;\r\nif (ps->performance_levels[0].flags & ATOM_PPLIB_R600_FLAGS_PCIEGEN2)\r\npi->acpi_pcie_gen2 = true;\r\nelse\r\npi->acpi_pcie_gen2 = false;\r\n}\r\nif (rps->class2 & ATOM_PPLIB_CLASSIFICATION2_ULV) {\r\neg_pi->ulv.supported = true;\r\neg_pi->ulv.pl = pl;\r\n}\r\nif (pi->min_vddc_in_table > pl->vddc)\r\npi->min_vddc_in_table = pl->vddc;\r\nif (pi->max_vddc_in_table < pl->vddc)\r\npi->max_vddc_in_table = pl->vddc;\r\nif (rps->class & ATOM_PPLIB_CLASSIFICATION_BOOT) {\r\nu16 vddc, vddci, mvdd;\r\nradeon_atombios_get_default_voltages(rdev, &vddc, &vddci, &mvdd);\r\npl->mclk = rdev->clock.default_mclk;\r\npl->sclk = rdev->clock.default_sclk;\r\npl->vddc = vddc;\r\npl->vddci = vddci;\r\n}\r\nif ((rps->class & ATOM_PPLIB_CLASSIFICATION_UI_MASK) ==\r\nATOM_PPLIB_CLASSIFICATION_UI_PERFORMANCE) {\r\nrdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.sclk = pl->sclk;\r\nrdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.mclk = pl->mclk;\r\nrdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.vddc = pl->vddc;\r\nrdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.vddci = pl->vddci;\r\n}\r\n}\r\nstatic int ni_parse_power_table(struct radeon_device *rdev)\r\n{\r\nstruct radeon_mode_info *mode_info = &rdev->mode_info;\r\nstruct _ATOM_PPLIB_NONCLOCK_INFO *non_clock_info;\r\nunion pplib_power_state *power_state;\r\nint i, j;\r\nunion pplib_clock_info *clock_info;\r\nunion power_info *power_info;\r\nint index = GetIndexIntoMasterTable(DATA, PowerPlayInfo);\r\nu16 data_offset;\r\nu8 frev, crev;\r\nstruct ni_ps *ps;\r\nif (!atom_parse_data_header(mode_info->atom_context, index, NULL,\r\n&frev, &crev, &data_offset))\r\nreturn -EINVAL;\r\npower_info = (union power_info *)(mode_info->atom_context->bios + data_offset);\r\nrdev->pm.dpm.ps = kzalloc(sizeof(struct radeon_ps) *\r\npower_info->pplib.ucNumStates, GFP_KERNEL);\r\nif (!rdev->pm.dpm.ps)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < power_info->pplib.ucNumStates; i++) {\r\npower_state = (union pplib_power_state *)\r\n(mode_info->atom_context->bios + data_offset +\r\nle16_to_cpu(power_info->pplib.usStateArrayOffset) +\r\ni * power_info->pplib.ucStateEntrySize);\r\nnon_clock_info = (struct _ATOM_PPLIB_NONCLOCK_INFO *)\r\n(mode_info->atom_context->bios + data_offset +\r\nle16_to_cpu(power_info->pplib.usNonClockInfoArrayOffset) +\r\n(power_state->v1.ucNonClockStateIndex *\r\npower_info->pplib.ucNonClockSize));\r\nif (power_info->pplib.ucStateEntrySize - 1) {\r\nu8 *idx;\r\nps = kzalloc(sizeof(struct ni_ps), GFP_KERNEL);\r\nif (ps == NULL) {\r\nkfree(rdev->pm.dpm.ps);\r\nreturn -ENOMEM;\r\n}\r\nrdev->pm.dpm.ps[i].ps_priv = ps;\r\nni_parse_pplib_non_clock_info(rdev, &rdev->pm.dpm.ps[i],\r\nnon_clock_info,\r\npower_info->pplib.ucNonClockSize);\r\nidx = (u8 *)&power_state->v1.ucClockStateIndices[0];\r\nfor (j = 0; j < (power_info->pplib.ucStateEntrySize - 1); j++) {\r\nclock_info = (union pplib_clock_info *)\r\n(mode_info->atom_context->bios + data_offset +\r\nle16_to_cpu(power_info->pplib.usClockInfoArrayOffset) +\r\n(idx[j] * power_info->pplib.ucClockInfoSize));\r\nni_parse_pplib_clock_info(rdev,\r\n&rdev->pm.dpm.ps[i], j,\r\nclock_info);\r\n}\r\n}\r\n}\r\nrdev->pm.dpm.num_ps = power_info->pplib.ucNumStates;\r\nreturn 0;\r\n}\r\nint ni_dpm_init(struct radeon_device *rdev)\r\n{\r\nstruct rv7xx_power_info *pi;\r\nstruct evergreen_power_info *eg_pi;\r\nstruct ni_power_info *ni_pi;\r\nstruct atom_clock_dividers dividers;\r\nint ret;\r\nni_pi = kzalloc(sizeof(struct ni_power_info), GFP_KERNEL);\r\nif (ni_pi == NULL)\r\nreturn -ENOMEM;\r\nrdev->pm.dpm.priv = ni_pi;\r\neg_pi = &ni_pi->eg;\r\npi = &eg_pi->rv7xx;\r\nrv770_get_max_vddc(rdev);\r\neg_pi->ulv.supported = false;\r\npi->acpi_vddc = 0;\r\neg_pi->acpi_vddci = 0;\r\npi->min_vddc_in_table = 0;\r\npi->max_vddc_in_table = 0;\r\nret = r600_get_platform_caps(rdev);\r\nif (ret)\r\nreturn ret;\r\nret = ni_parse_power_table(rdev);\r\nif (ret)\r\nreturn ret;\r\nret = r600_parse_extended_power_table(rdev);\r\nif (ret)\r\nreturn ret;\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries =\r\nkzalloc(4 * sizeof(struct radeon_clock_voltage_dependency_entry), GFP_KERNEL);\r\nif (!rdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries) {\r\nr600_free_extended_power_table(rdev);\r\nreturn -ENOMEM;\r\n}\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.count = 4;\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[0].clk = 0;\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[0].v = 0;\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[1].clk = 36000;\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[1].v = 720;\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[2].clk = 54000;\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[2].v = 810;\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[3].clk = 72000;\r\nrdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries[3].v = 900;\r\nni_patch_dependency_tables_based_on_leakage(rdev);\r\nif (rdev->pm.dpm.voltage_response_time == 0)\r\nrdev->pm.dpm.voltage_response_time = R600_VOLTAGERESPONSETIME_DFLT;\r\nif (rdev->pm.dpm.backbias_response_time == 0)\r\nrdev->pm.dpm.backbias_response_time = R600_BACKBIASRESPONSETIME_DFLT;\r\nret = radeon_atom_get_clock_dividers(rdev, COMPUTE_ENGINE_PLL_PARAM,\r\n0, false, &dividers);\r\nif (ret)\r\npi->ref_div = dividers.ref_div + 1;\r\nelse\r\npi->ref_div = R600_REFERENCEDIVIDER_DFLT;\r\npi->rlp = RV770_RLP_DFLT;\r\npi->rmp = RV770_RMP_DFLT;\r\npi->lhp = RV770_LHP_DFLT;\r\npi->lmp = RV770_LMP_DFLT;\r\neg_pi->ats[0].rlp = RV770_RLP_DFLT;\r\neg_pi->ats[0].rmp = RV770_RMP_DFLT;\r\neg_pi->ats[0].lhp = RV770_LHP_DFLT;\r\neg_pi->ats[0].lmp = RV770_LMP_DFLT;\r\neg_pi->ats[1].rlp = BTC_RLP_UVD_DFLT;\r\neg_pi->ats[1].rmp = BTC_RMP_UVD_DFLT;\r\neg_pi->ats[1].lhp = BTC_LHP_UVD_DFLT;\r\neg_pi->ats[1].lmp = BTC_LMP_UVD_DFLT;\r\neg_pi->smu_uvd_hs = true;\r\nif (rdev->pdev->device == 0x6707) {\r\npi->mclk_strobe_mode_threshold = 55000;\r\npi->mclk_edc_enable_threshold = 55000;\r\neg_pi->mclk_edc_wr_enable_threshold = 55000;\r\n} else {\r\npi->mclk_strobe_mode_threshold = 40000;\r\npi->mclk_edc_enable_threshold = 40000;\r\neg_pi->mclk_edc_wr_enable_threshold = 40000;\r\n}\r\nni_pi->mclk_rtt_mode_threshold = eg_pi->mclk_edc_wr_enable_threshold;\r\npi->voltage_control =\r\nradeon_atom_is_voltage_gpio(rdev, SET_VOLTAGE_TYPE_ASIC_VDDC, 0);\r\npi->mvdd_control =\r\nradeon_atom_is_voltage_gpio(rdev, SET_VOLTAGE_TYPE_ASIC_MVDDC, 0);\r\neg_pi->vddci_control =\r\nradeon_atom_is_voltage_gpio(rdev, SET_VOLTAGE_TYPE_ASIC_VDDCI, 0);\r\nrv770_get_engine_memory_ss(rdev);\r\npi->asi = RV770_ASI_DFLT;\r\npi->pasi = CYPRESS_HASI_DFLT;\r\npi->vrc = CYPRESS_VRC_DFLT;\r\npi->power_gating = false;\r\npi->gfx_clock_gating = true;\r\npi->mg_clock_gating = true;\r\npi->mgcgtssm = true;\r\neg_pi->ls_clock_gating = false;\r\neg_pi->sclk_deep_sleep = false;\r\npi->dynamic_pcie_gen2 = true;\r\nif (rdev->pm.int_thermal_type != THERMAL_TYPE_NONE)\r\npi->thermal_protection = true;\r\nelse\r\npi->thermal_protection = false;\r\npi->display_gap = true;\r\npi->dcodt = true;\r\npi->ulps = true;\r\neg_pi->dynamic_ac_timing = true;\r\neg_pi->abm = true;\r\neg_pi->mcls = true;\r\neg_pi->light_sleep = true;\r\neg_pi->memory_transition = true;\r\n#if defined(CONFIG_ACPI)\r\neg_pi->pcie_performance_request =\r\nradeon_acpi_is_pcie_performance_request_supported(rdev);\r\n#else\r\neg_pi->pcie_performance_request = false;\r\n#endif\r\neg_pi->dll_default_on = false;\r\neg_pi->sclk_deep_sleep = false;\r\npi->mclk_stutter_mode_threshold = 0;\r\npi->sram_end = SMC_RAM_END;\r\nrdev->pm.dpm.dyn_state.mclk_sclk_ratio = 3;\r\nrdev->pm.dpm.dyn_state.vddc_vddci_delta = 200;\r\nrdev->pm.dpm.dyn_state.min_vddc_for_pcie_gen2 = 900;\r\nrdev->pm.dpm.dyn_state.valid_sclk_values.count = ARRAY_SIZE(btc_valid_sclk);\r\nrdev->pm.dpm.dyn_state.valid_sclk_values.values = btc_valid_sclk;\r\nrdev->pm.dpm.dyn_state.valid_mclk_values.count = 0;\r\nrdev->pm.dpm.dyn_state.valid_mclk_values.values = NULL;\r\nrdev->pm.dpm.dyn_state.sclk_mclk_delta = 12500;\r\nni_pi->cac_data.leakage_coefficients.at = 516;\r\nni_pi->cac_data.leakage_coefficients.bt = 18;\r\nni_pi->cac_data.leakage_coefficients.av = 51;\r\nni_pi->cac_data.leakage_coefficients.bv = 2957;\r\nswitch (rdev->pdev->device) {\r\ncase 0x6700:\r\ncase 0x6701:\r\ncase 0x6702:\r\ncase 0x6703:\r\ncase 0x6718:\r\nni_pi->cac_weights = &cac_weights_cayman_xt;\r\nbreak;\r\ncase 0x6705:\r\ncase 0x6719:\r\ncase 0x671D:\r\ncase 0x671C:\r\ndefault:\r\nni_pi->cac_weights = &cac_weights_cayman_pro;\r\nbreak;\r\ncase 0x6704:\r\ncase 0x6706:\r\ncase 0x6707:\r\ncase 0x6708:\r\ncase 0x6709:\r\nni_pi->cac_weights = &cac_weights_cayman_le;\r\nbreak;\r\n}\r\nif (ni_pi->cac_weights->enable_power_containment_by_default) {\r\nni_pi->enable_power_containment = true;\r\nni_pi->enable_cac = true;\r\nni_pi->enable_sq_ramping = true;\r\n} else {\r\nni_pi->enable_power_containment = false;\r\nni_pi->enable_cac = false;\r\nni_pi->enable_sq_ramping = false;\r\n}\r\nni_pi->driver_calculate_cac_leakage = false;\r\nni_pi->cac_configuration_required = true;\r\nif (ni_pi->cac_configuration_required) {\r\nni_pi->support_cac_long_term_average = true;\r\nni_pi->lta_window_size = ni_pi->cac_weights->l2_lta_window_size;\r\nni_pi->lts_truncate = ni_pi->cac_weights->lts_truncate;\r\n} else {\r\nni_pi->support_cac_long_term_average = false;\r\nni_pi->lta_window_size = 0;\r\nni_pi->lts_truncate = 0;\r\n}\r\nni_pi->use_power_boost_limit = true;\r\nif ((rdev->pm.dpm.dyn_state.max_clock_voltage_on_dc.sclk == 0) ||\r\n(rdev->pm.dpm.dyn_state.max_clock_voltage_on_dc.mclk == 0))\r\nrdev->pm.dpm.dyn_state.max_clock_voltage_on_dc =\r\nrdev->pm.dpm.dyn_state.max_clock_voltage_on_ac;\r\nreturn 0;\r\n}\r\nvoid ni_dpm_fini(struct radeon_device *rdev)\r\n{\r\nint i;\r\nfor (i = 0; i < rdev->pm.dpm.num_ps; i++) {\r\nkfree(rdev->pm.dpm.ps[i].ps_priv);\r\n}\r\nkfree(rdev->pm.dpm.ps);\r\nkfree(rdev->pm.dpm.priv);\r\nkfree(rdev->pm.dpm.dyn_state.vddc_dependency_on_dispclk.entries);\r\nr600_free_extended_power_table(rdev);\r\n}\r\nvoid ni_dpm_print_power_state(struct radeon_device *rdev,\r\nstruct radeon_ps *rps)\r\n{\r\nstruct ni_ps *ps = ni_get_ps(rps);\r\nstruct rv7xx_pl *pl;\r\nint i;\r\nr600_dpm_print_class_info(rps->class, rps->class2);\r\nr600_dpm_print_cap_info(rps->caps);\r\nprintk("\tuvd vclk: %d dclk: %d\n", rps->vclk, rps->dclk);\r\nfor (i = 0; i < ps->performance_level_count; i++) {\r\npl = &ps->performance_levels[i];\r\nif (rdev->family >= CHIP_TAHITI)\r\nprintk("\t\tpower level %d sclk: %u mclk: %u vddc: %u vddci: %u pcie gen: %u\n",\r\ni, pl->sclk, pl->mclk, pl->vddc, pl->vddci, pl->pcie_gen + 1);\r\nelse\r\nprintk("\t\tpower level %d sclk: %u mclk: %u vddc: %u vddci: %u\n",\r\ni, pl->sclk, pl->mclk, pl->vddc, pl->vddci);\r\n}\r\nr600_dpm_print_ps_status(rdev, rps);\r\n}\r\nvoid ni_dpm_debugfs_print_current_performance_level(struct radeon_device *rdev,\r\nstruct seq_file *m)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct radeon_ps *rps = &eg_pi->current_rps;\r\nstruct ni_ps *ps = ni_get_ps(rps);\r\nstruct rv7xx_pl *pl;\r\nu32 current_index =\r\n(RREG32(TARGET_AND_CURRENT_PROFILE_INDEX) & CURRENT_STATE_INDEX_MASK) >>\r\nCURRENT_STATE_INDEX_SHIFT;\r\nif (current_index >= ps->performance_level_count) {\r\nseq_printf(m, "invalid dpm profile %d\n", current_index);\r\n} else {\r\npl = &ps->performance_levels[current_index];\r\nseq_printf(m, "uvd vclk: %d dclk: %d\n", rps->vclk, rps->dclk);\r\nseq_printf(m, "power level %d sclk: %u mclk: %u vddc: %u vddci: %u\n",\r\ncurrent_index, pl->sclk, pl->mclk, pl->vddc, pl->vddci);\r\n}\r\n}\r\nu32 ni_dpm_get_current_sclk(struct radeon_device *rdev)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct radeon_ps *rps = &eg_pi->current_rps;\r\nstruct ni_ps *ps = ni_get_ps(rps);\r\nstruct rv7xx_pl *pl;\r\nu32 current_index =\r\n(RREG32(TARGET_AND_CURRENT_PROFILE_INDEX) & CURRENT_STATE_INDEX_MASK) >>\r\nCURRENT_STATE_INDEX_SHIFT;\r\nif (current_index >= ps->performance_level_count) {\r\nreturn 0;\r\n} else {\r\npl = &ps->performance_levels[current_index];\r\nreturn pl->sclk;\r\n}\r\n}\r\nu32 ni_dpm_get_current_mclk(struct radeon_device *rdev)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct radeon_ps *rps = &eg_pi->current_rps;\r\nstruct ni_ps *ps = ni_get_ps(rps);\r\nstruct rv7xx_pl *pl;\r\nu32 current_index =\r\n(RREG32(TARGET_AND_CURRENT_PROFILE_INDEX) & CURRENT_STATE_INDEX_MASK) >>\r\nCURRENT_STATE_INDEX_SHIFT;\r\nif (current_index >= ps->performance_level_count) {\r\nreturn 0;\r\n} else {\r\npl = &ps->performance_levels[current_index];\r\nreturn pl->mclk;\r\n}\r\n}\r\nu32 ni_dpm_get_sclk(struct radeon_device *rdev, bool low)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct ni_ps *requested_state = ni_get_ps(&eg_pi->requested_rps);\r\nif (low)\r\nreturn requested_state->performance_levels[0].sclk;\r\nelse\r\nreturn requested_state->performance_levels[requested_state->performance_level_count - 1].sclk;\r\n}\r\nu32 ni_dpm_get_mclk(struct radeon_device *rdev, bool low)\r\n{\r\nstruct evergreen_power_info *eg_pi = evergreen_get_pi(rdev);\r\nstruct ni_ps *requested_state = ni_get_ps(&eg_pi->requested_rps);\r\nif (low)\r\nreturn requested_state->performance_levels[0].mclk;\r\nelse\r\nreturn requested_state->performance_levels[requested_state->performance_level_count - 1].mclk;\r\n}
