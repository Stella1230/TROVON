void pgd_clear_bad(pgd_t *pgd)\r\n{\r\npgd_ERROR(*pgd);\r\npgd_clear(pgd);\r\n}\r\nvoid pud_clear_bad(pud_t *pud)\r\n{\r\npud_ERROR(*pud);\r\npud_clear(pud);\r\n}\r\nvoid pmd_clear_bad(pmd_t *pmd)\r\n{\r\npmd_ERROR(*pmd);\r\npmd_clear(pmd);\r\n}\r\nint ptep_set_access_flags(struct vm_area_struct *vma,\r\nunsigned long address, pte_t *ptep,\r\npte_t entry, int dirty)\r\n{\r\nint changed = !pte_same(*ptep, entry);\r\nif (changed) {\r\nset_pte_at(vma->vm_mm, address, ptep, entry);\r\nflush_tlb_fix_spurious_fault(vma, address);\r\n}\r\nreturn changed;\r\n}\r\nint ptep_clear_flush_young(struct vm_area_struct *vma,\r\nunsigned long address, pte_t *ptep)\r\n{\r\nint young;\r\nyoung = ptep_test_and_clear_young(vma, address, ptep);\r\nif (young)\r\nflush_tlb_page(vma, address);\r\nreturn young;\r\n}\r\npte_t ptep_clear_flush(struct vm_area_struct *vma, unsigned long address,\r\npte_t *ptep)\r\n{\r\nstruct mm_struct *mm = (vma)->vm_mm;\r\npte_t pte;\r\npte = ptep_get_and_clear(mm, address, ptep);\r\nif (pte_accessible(mm, pte))\r\nflush_tlb_page(vma, address);\r\nreturn pte;\r\n}\r\nint pmdp_set_access_flags(struct vm_area_struct *vma,\r\nunsigned long address, pmd_t *pmdp,\r\npmd_t entry, int dirty)\r\n{\r\nint changed = !pmd_same(*pmdp, entry);\r\nVM_BUG_ON(address & ~HPAGE_PMD_MASK);\r\nif (changed) {\r\nset_pmd_at(vma->vm_mm, address, pmdp, entry);\r\nflush_pmd_tlb_range(vma, address, address + HPAGE_PMD_SIZE);\r\n}\r\nreturn changed;\r\n}\r\nint pmdp_clear_flush_young(struct vm_area_struct *vma,\r\nunsigned long address, pmd_t *pmdp)\r\n{\r\nint young;\r\nVM_BUG_ON(address & ~HPAGE_PMD_MASK);\r\nyoung = pmdp_test_and_clear_young(vma, address, pmdp);\r\nif (young)\r\nflush_pmd_tlb_range(vma, address, address + HPAGE_PMD_SIZE);\r\nreturn young;\r\n}\r\npmd_t pmdp_huge_clear_flush(struct vm_area_struct *vma, unsigned long address,\r\npmd_t *pmdp)\r\n{\r\npmd_t pmd;\r\nVM_BUG_ON(address & ~HPAGE_PMD_MASK);\r\nVM_BUG_ON(!pmd_trans_huge(*pmdp) && !pmd_devmap(*pmdp));\r\npmd = pmdp_huge_get_and_clear(vma->vm_mm, address, pmdp);\r\nflush_pmd_tlb_range(vma, address, address + HPAGE_PMD_SIZE);\r\nreturn pmd;\r\n}\r\nvoid pgtable_trans_huge_deposit(struct mm_struct *mm, pmd_t *pmdp,\r\npgtable_t pgtable)\r\n{\r\nassert_spin_locked(pmd_lockptr(mm, pmdp));\r\nif (!pmd_huge_pte(mm, pmdp))\r\nINIT_LIST_HEAD(&pgtable->lru);\r\nelse\r\nlist_add(&pgtable->lru, &pmd_huge_pte(mm, pmdp)->lru);\r\npmd_huge_pte(mm, pmdp) = pgtable;\r\n}\r\npgtable_t pgtable_trans_huge_withdraw(struct mm_struct *mm, pmd_t *pmdp)\r\n{\r\npgtable_t pgtable;\r\nassert_spin_locked(pmd_lockptr(mm, pmdp));\r\npgtable = pmd_huge_pte(mm, pmdp);\r\npmd_huge_pte(mm, pmdp) = list_first_entry_or_null(&pgtable->lru,\r\nstruct page, lru);\r\nif (pmd_huge_pte(mm, pmdp))\r\nlist_del(&pgtable->lru);\r\nreturn pgtable;\r\n}\r\nvoid pmdp_invalidate(struct vm_area_struct *vma, unsigned long address,\r\npmd_t *pmdp)\r\n{\r\npmd_t entry = *pmdp;\r\nset_pmd_at(vma->vm_mm, address, pmdp, pmd_mknotpresent(entry));\r\nflush_pmd_tlb_range(vma, address, address + HPAGE_PMD_SIZE);\r\n}\r\npmd_t pmdp_collapse_flush(struct vm_area_struct *vma, unsigned long address,\r\npmd_t *pmdp)\r\n{\r\npmd_t pmd;\r\nVM_BUG_ON(address & ~HPAGE_PMD_MASK);\r\nVM_BUG_ON(pmd_trans_huge(*pmdp));\r\npmd = pmdp_huge_get_and_clear(vma->vm_mm, address, pmdp);\r\nflush_tlb_range(vma, address, address + HPAGE_PMD_SIZE);\r\nreturn pmd;\r\n}
