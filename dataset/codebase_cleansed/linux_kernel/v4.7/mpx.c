static inline unsigned long mpx_bd_size_bytes(struct mm_struct *mm)\r\n{\r\nif (is_64bit_mm(mm))\r\nreturn MPX_BD_SIZE_BYTES_64;\r\nelse\r\nreturn MPX_BD_SIZE_BYTES_32;\r\n}\r\nstatic inline unsigned long mpx_bt_size_bytes(struct mm_struct *mm)\r\n{\r\nif (is_64bit_mm(mm))\r\nreturn MPX_BT_SIZE_BYTES_64;\r\nelse\r\nreturn MPX_BT_SIZE_BYTES_32;\r\n}\r\nstatic unsigned long mpx_mmap(unsigned long len)\r\n{\r\nstruct mm_struct *mm = current->mm;\r\nunsigned long addr, populate;\r\nif (len != mpx_bt_size_bytes(mm))\r\nreturn -EINVAL;\r\ndown_write(&mm->mmap_sem);\r\naddr = do_mmap(NULL, 0, len, PROT_READ | PROT_WRITE,\r\nMAP_ANONYMOUS | MAP_PRIVATE, VM_MPX, 0, &populate);\r\nup_write(&mm->mmap_sem);\r\nif (populate)\r\nmm_populate(addr, populate);\r\nreturn addr;\r\n}\r\nstatic int get_reg_offset(struct insn *insn, struct pt_regs *regs,\r\nenum reg_type type)\r\n{\r\nint regno = 0;\r\nstatic const int regoff[] = {\r\noffsetof(struct pt_regs, ax),\r\noffsetof(struct pt_regs, cx),\r\noffsetof(struct pt_regs, dx),\r\noffsetof(struct pt_regs, bx),\r\noffsetof(struct pt_regs, sp),\r\noffsetof(struct pt_regs, bp),\r\noffsetof(struct pt_regs, si),\r\noffsetof(struct pt_regs, di),\r\n#ifdef CONFIG_X86_64\r\noffsetof(struct pt_regs, r8),\r\noffsetof(struct pt_regs, r9),\r\noffsetof(struct pt_regs, r10),\r\noffsetof(struct pt_regs, r11),\r\noffsetof(struct pt_regs, r12),\r\noffsetof(struct pt_regs, r13),\r\noffsetof(struct pt_regs, r14),\r\noffsetof(struct pt_regs, r15),\r\n#endif\r\n};\r\nint nr_registers = ARRAY_SIZE(regoff);\r\nif (IS_ENABLED(CONFIG_X86_64) && !insn->x86_64)\r\nnr_registers -= 8;\r\nswitch (type) {\r\ncase REG_TYPE_RM:\r\nregno = X86_MODRM_RM(insn->modrm.value);\r\nif (X86_REX_B(insn->rex_prefix.value))\r\nregno += 8;\r\nbreak;\r\ncase REG_TYPE_INDEX:\r\nregno = X86_SIB_INDEX(insn->sib.value);\r\nif (X86_REX_X(insn->rex_prefix.value))\r\nregno += 8;\r\nbreak;\r\ncase REG_TYPE_BASE:\r\nregno = X86_SIB_BASE(insn->sib.value);\r\nif (X86_REX_B(insn->rex_prefix.value))\r\nregno += 8;\r\nbreak;\r\ndefault:\r\npr_err("invalid register type");\r\nBUG();\r\nbreak;\r\n}\r\nif (regno >= nr_registers) {\r\nWARN_ONCE(1, "decoded an instruction with an invalid register");\r\nreturn -EINVAL;\r\n}\r\nreturn regoff[regno];\r\n}\r\nstatic void __user *mpx_get_addr_ref(struct insn *insn, struct pt_regs *regs)\r\n{\r\nunsigned long addr, base, indx;\r\nint addr_offset, base_offset, indx_offset;\r\ninsn_byte_t sib;\r\ninsn_get_modrm(insn);\r\ninsn_get_sib(insn);\r\nsib = insn->sib.value;\r\nif (X86_MODRM_MOD(insn->modrm.value) == 3) {\r\naddr_offset = get_reg_offset(insn, regs, REG_TYPE_RM);\r\nif (addr_offset < 0)\r\ngoto out_err;\r\naddr = regs_get_register(regs, addr_offset);\r\n} else {\r\nif (insn->sib.nbytes) {\r\nbase_offset = get_reg_offset(insn, regs, REG_TYPE_BASE);\r\nif (base_offset < 0)\r\ngoto out_err;\r\nindx_offset = get_reg_offset(insn, regs, REG_TYPE_INDEX);\r\nif (indx_offset < 0)\r\ngoto out_err;\r\nbase = regs_get_register(regs, base_offset);\r\nindx = regs_get_register(regs, indx_offset);\r\naddr = base + indx * (1 << X86_SIB_SCALE(sib));\r\n} else {\r\naddr_offset = get_reg_offset(insn, regs, REG_TYPE_RM);\r\nif (addr_offset < 0)\r\ngoto out_err;\r\naddr = regs_get_register(regs, addr_offset);\r\n}\r\naddr += insn->displacement.value;\r\n}\r\nreturn (void __user *)addr;\r\nout_err:\r\nreturn (void __user *)-1;\r\n}\r\nstatic int mpx_insn_decode(struct insn *insn,\r\nstruct pt_regs *regs)\r\n{\r\nunsigned char buf[MAX_INSN_SIZE];\r\nint x86_64 = !test_thread_flag(TIF_IA32);\r\nint not_copied;\r\nint nr_copied;\r\nnot_copied = copy_from_user(buf, (void __user *)regs->ip, sizeof(buf));\r\nnr_copied = sizeof(buf) - not_copied;\r\nif (!nr_copied)\r\nreturn -EFAULT;\r\ninsn_init(insn, buf, nr_copied, x86_64);\r\ninsn_get_length(insn);\r\nif (nr_copied < insn->length)\r\nreturn -EFAULT;\r\ninsn_get_opcode(insn);\r\nif (insn->opcode.bytes[0] != 0x0f)\r\ngoto bad_opcode;\r\nif ((insn->opcode.bytes[1] != 0x1a) &&\r\n(insn->opcode.bytes[1] != 0x1b))\r\ngoto bad_opcode;\r\nreturn 0;\r\nbad_opcode:\r\nreturn -EINVAL;\r\n}\r\nsiginfo_t *mpx_generate_siginfo(struct pt_regs *regs)\r\n{\r\nconst struct mpx_bndreg_state *bndregs;\r\nconst struct mpx_bndreg *bndreg;\r\nsiginfo_t *info = NULL;\r\nstruct insn insn;\r\nuint8_t bndregno;\r\nint err;\r\nerr = mpx_insn_decode(&insn, regs);\r\nif (err)\r\ngoto err_out;\r\ninsn_get_modrm(&insn);\r\nbndregno = X86_MODRM_REG(insn.modrm.value);\r\nif (bndregno > 3) {\r\nerr = -EINVAL;\r\ngoto err_out;\r\n}\r\nbndregs = get_xsave_field_ptr(XFEATURE_MASK_BNDREGS);\r\nif (!bndregs) {\r\nerr = -EINVAL;\r\ngoto err_out;\r\n}\r\nbndreg = &bndregs->bndreg[bndregno];\r\ninfo = kzalloc(sizeof(*info), GFP_KERNEL);\r\nif (!info) {\r\nerr = -ENOMEM;\r\ngoto err_out;\r\n}\r\ninfo->si_lower = (void __user *)(unsigned long)bndreg->lower_bound;\r\ninfo->si_upper = (void __user *)(unsigned long)~bndreg->upper_bound;\r\ninfo->si_addr_lsb = 0;\r\ninfo->si_signo = SIGSEGV;\r\ninfo->si_errno = 0;\r\ninfo->si_code = SEGV_BNDERR;\r\ninfo->si_addr = mpx_get_addr_ref(&insn, regs);\r\nif (info->si_addr == (void *)-1) {\r\nerr = -EINVAL;\r\ngoto err_out;\r\n}\r\ntrace_mpx_bounds_register_exception(info->si_addr, bndreg);\r\nreturn info;\r\nerr_out:\r\nkfree(info);\r\nreturn ERR_PTR(err);\r\n}\r\nstatic __user void *mpx_get_bounds_dir(void)\r\n{\r\nconst struct mpx_bndcsr *bndcsr;\r\nif (!cpu_feature_enabled(X86_FEATURE_MPX))\r\nreturn MPX_INVALID_BOUNDS_DIR;\r\nbndcsr = get_xsave_field_ptr(XFEATURE_MASK_BNDCSR);\r\nif (!bndcsr)\r\nreturn MPX_INVALID_BOUNDS_DIR;\r\nif (!(bndcsr->bndcfgu & MPX_BNDCFG_ENABLE_FLAG))\r\nreturn MPX_INVALID_BOUNDS_DIR;\r\nreturn (void __user *)(unsigned long)\r\n(bndcsr->bndcfgu & MPX_BNDCFG_ADDR_MASK);\r\n}\r\nint mpx_enable_management(void)\r\n{\r\nvoid __user *bd_base = MPX_INVALID_BOUNDS_DIR;\r\nstruct mm_struct *mm = current->mm;\r\nint ret = 0;\r\nbd_base = mpx_get_bounds_dir();\r\ndown_write(&mm->mmap_sem);\r\nmm->bd_addr = bd_base;\r\nif (mm->bd_addr == MPX_INVALID_BOUNDS_DIR)\r\nret = -ENXIO;\r\nup_write(&mm->mmap_sem);\r\nreturn ret;\r\n}\r\nint mpx_disable_management(void)\r\n{\r\nstruct mm_struct *mm = current->mm;\r\nif (!cpu_feature_enabled(X86_FEATURE_MPX))\r\nreturn -ENXIO;\r\ndown_write(&mm->mmap_sem);\r\nmm->bd_addr = MPX_INVALID_BOUNDS_DIR;\r\nup_write(&mm->mmap_sem);\r\nreturn 0;\r\n}\r\nstatic int mpx_cmpxchg_bd_entry(struct mm_struct *mm,\r\nunsigned long *curval,\r\nunsigned long __user *addr,\r\nunsigned long old_val, unsigned long new_val)\r\n{\r\nint ret;\r\nif (is_64bit_mm(mm)) {\r\nret = user_atomic_cmpxchg_inatomic(curval,\r\naddr, old_val, new_val);\r\n} else {\r\nu32 uninitialized_var(curval_32);\r\nu32 old_val_32 = old_val;\r\nu32 new_val_32 = new_val;\r\nu32 __user *addr_32 = (u32 __user *)addr;\r\nret = user_atomic_cmpxchg_inatomic(&curval_32,\r\naddr_32, old_val_32, new_val_32);\r\n*curval = curval_32;\r\n}\r\nreturn ret;\r\n}\r\nstatic int allocate_bt(struct mm_struct *mm, long __user *bd_entry)\r\n{\r\nunsigned long expected_old_val = 0;\r\nunsigned long actual_old_val = 0;\r\nunsigned long bt_addr;\r\nunsigned long bd_new_entry;\r\nint ret = 0;\r\nbt_addr = mpx_mmap(mpx_bt_size_bytes(mm));\r\nif (IS_ERR((void *)bt_addr))\r\nreturn PTR_ERR((void *)bt_addr);\r\nbd_new_entry = bt_addr | MPX_BD_ENTRY_VALID_FLAG;\r\nret = mpx_cmpxchg_bd_entry(mm, &actual_old_val, bd_entry,\r\nexpected_old_val, bd_new_entry);\r\nif (ret)\r\ngoto out_unmap;\r\nif (actual_old_val & MPX_BD_ENTRY_VALID_FLAG) {\r\nret = 0;\r\ngoto out_unmap;\r\n}\r\nif (expected_old_val != actual_old_val) {\r\nret = -EINVAL;\r\ngoto out_unmap;\r\n}\r\ntrace_mpx_new_bounds_table(bt_addr);\r\nreturn 0;\r\nout_unmap:\r\nvm_munmap(bt_addr, mpx_bt_size_bytes(mm));\r\nreturn ret;\r\n}\r\nstatic int do_mpx_bt_fault(void)\r\n{\r\nunsigned long bd_entry, bd_base;\r\nconst struct mpx_bndcsr *bndcsr;\r\nstruct mm_struct *mm = current->mm;\r\nbndcsr = get_xsave_field_ptr(XFEATURE_MASK_BNDCSR);\r\nif (!bndcsr)\r\nreturn -EINVAL;\r\nbd_base = bndcsr->bndcfgu & MPX_BNDCFG_ADDR_MASK;\r\nbd_entry = bndcsr->bndstatus & MPX_BNDSTA_ADDR_MASK;\r\nif ((bd_entry < bd_base) ||\r\n(bd_entry >= bd_base + mpx_bd_size_bytes(mm)))\r\nreturn -EINVAL;\r\nreturn allocate_bt(mm, (long __user *)bd_entry);\r\n}\r\nint mpx_handle_bd_fault(void)\r\n{\r\nif (!kernel_managing_mpx_tables(current->mm))\r\nreturn -EINVAL;\r\nif (do_mpx_bt_fault()) {\r\nforce_sig(SIGSEGV, current);\r\n}\r\nreturn 0;\r\n}\r\nstatic int mpx_resolve_fault(long __user *addr, int write)\r\n{\r\nlong gup_ret;\r\nint nr_pages = 1;\r\nint force = 0;\r\ngup_ret = get_user_pages((unsigned long)addr, nr_pages, write,\r\nforce, NULL, NULL);\r\nif (!gup_ret)\r\nreturn -EFAULT;\r\nif (gup_ret < 0)\r\nreturn gup_ret;\r\nreturn 0;\r\n}\r\nstatic unsigned long mpx_bd_entry_to_bt_addr(struct mm_struct *mm,\r\nunsigned long bd_entry)\r\n{\r\nunsigned long bt_addr = bd_entry;\r\nint align_to_bytes;\r\nbt_addr &= ~MPX_BD_ENTRY_VALID_FLAG;\r\nif (is_64bit_mm(mm))\r\nalign_to_bytes = 8;\r\nelse\r\nalign_to_bytes = 4;\r\nbt_addr &= ~(align_to_bytes-1);\r\nreturn bt_addr;\r\n}\r\nint get_user_bd_entry(struct mm_struct *mm, unsigned long *bd_entry_ret,\r\nlong __user *bd_entry_ptr)\r\n{\r\nu32 bd_entry_32;\r\nint ret;\r\nif (is_64bit_mm(mm))\r\nreturn get_user(*bd_entry_ret, bd_entry_ptr);\r\nret = get_user(bd_entry_32, (u32 __user *)bd_entry_ptr);\r\n*bd_entry_ret = bd_entry_32;\r\nreturn ret;\r\n}\r\nstatic int get_bt_addr(struct mm_struct *mm,\r\nlong __user *bd_entry_ptr,\r\nunsigned long *bt_addr_result)\r\n{\r\nint ret;\r\nint valid_bit;\r\nunsigned long bd_entry;\r\nunsigned long bt_addr;\r\nif (!access_ok(VERIFY_READ, (bd_entry_ptr), sizeof(*bd_entry_ptr)))\r\nreturn -EFAULT;\r\nwhile (1) {\r\nint need_write = 0;\r\npagefault_disable();\r\nret = get_user_bd_entry(mm, &bd_entry, bd_entry_ptr);\r\npagefault_enable();\r\nif (!ret)\r\nbreak;\r\nif (ret == -EFAULT)\r\nret = mpx_resolve_fault(bd_entry_ptr, need_write);\r\nif (ret)\r\nreturn ret;\r\n}\r\nvalid_bit = bd_entry & MPX_BD_ENTRY_VALID_FLAG;\r\nbt_addr = mpx_bd_entry_to_bt_addr(mm, bd_entry);\r\nif (!valid_bit && bt_addr)\r\nreturn -EINVAL;\r\nif (!valid_bit)\r\nreturn -ENOENT;\r\n*bt_addr_result = bt_addr;\r\nreturn 0;\r\n}\r\nstatic inline int bt_entry_size_bytes(struct mm_struct *mm)\r\n{\r\nif (is_64bit_mm(mm))\r\nreturn MPX_BT_ENTRY_BYTES_64;\r\nelse\r\nreturn MPX_BT_ENTRY_BYTES_32;\r\n}\r\nstatic unsigned long mpx_get_bt_entry_offset_bytes(struct mm_struct *mm,\r\nunsigned long addr)\r\n{\r\nunsigned long bt_table_nr_entries;\r\nunsigned long offset = addr;\r\nif (is_64bit_mm(mm)) {\r\noffset >>= 3;\r\nbt_table_nr_entries = MPX_BT_NR_ENTRIES_64;\r\n} else {\r\noffset >>= 2;\r\nbt_table_nr_entries = MPX_BT_NR_ENTRIES_32;\r\n}\r\noffset &= (bt_table_nr_entries-1);\r\noffset *= bt_entry_size_bytes(mm);\r\nreturn offset;\r\n}\r\nstatic inline unsigned long bd_entry_virt_space(struct mm_struct *mm)\r\n{\r\nunsigned long long virt_space;\r\nunsigned long long GB = (1ULL << 30);\r\nif (!is_64bit_mm(mm))\r\nreturn (4ULL * GB) / MPX_BD_NR_ENTRIES_32;\r\nvirt_space = (1ULL << boot_cpu_data.x86_virt_bits);\r\nreturn virt_space / MPX_BD_NR_ENTRIES_64;\r\n}\r\nstatic noinline int zap_bt_entries_mapping(struct mm_struct *mm,\r\nunsigned long bt_addr,\r\nunsigned long start_mapping, unsigned long end_mapping)\r\n{\r\nstruct vm_area_struct *vma;\r\nunsigned long addr, len;\r\nunsigned long start;\r\nunsigned long end;\r\nstart = bt_addr + mpx_get_bt_entry_offset_bytes(mm, start_mapping);\r\nend = bt_addr + mpx_get_bt_entry_offset_bytes(mm, end_mapping - 1);\r\nend += bt_entry_size_bytes(mm);\r\nvma = find_vma(mm, start);\r\nif (!vma || vma->vm_start > start)\r\nreturn -EINVAL;\r\naddr = start;\r\nwhile (vma && vma->vm_start < end) {\r\nif (!(vma->vm_flags & VM_MPX))\r\nreturn -EINVAL;\r\nlen = min(vma->vm_end, end) - addr;\r\nzap_page_range(vma, addr, len, NULL);\r\ntrace_mpx_unmap_zap(addr, addr+len);\r\nvma = vma->vm_next;\r\naddr = vma->vm_start;\r\n}\r\nreturn 0;\r\n}\r\nstatic unsigned long mpx_get_bd_entry_offset(struct mm_struct *mm,\r\nunsigned long addr)\r\n{\r\nif (is_64bit_mm(mm)) {\r\nint bd_entry_size = 8;\r\naddr &= ((1UL << boot_cpu_data.x86_virt_bits) - 1);\r\nreturn (addr / bd_entry_virt_space(mm)) * bd_entry_size;\r\n} else {\r\nint bd_entry_size = 4;\r\nreturn (addr / bd_entry_virt_space(mm)) * bd_entry_size;\r\n}\r\n}\r\nstatic int unmap_entire_bt(struct mm_struct *mm,\r\nlong __user *bd_entry, unsigned long bt_addr)\r\n{\r\nunsigned long expected_old_val = bt_addr | MPX_BD_ENTRY_VALID_FLAG;\r\nunsigned long uninitialized_var(actual_old_val);\r\nint ret;\r\nwhile (1) {\r\nint need_write = 1;\r\nunsigned long cleared_bd_entry = 0;\r\npagefault_disable();\r\nret = mpx_cmpxchg_bd_entry(mm, &actual_old_val,\r\nbd_entry, expected_old_val, cleared_bd_entry);\r\npagefault_enable();\r\nif (!ret)\r\nbreak;\r\nif (ret == -EFAULT)\r\nret = mpx_resolve_fault(bd_entry, need_write);\r\nif (ret)\r\nreturn ret;\r\n}\r\nif (actual_old_val != expected_old_val) {\r\nif (!actual_old_val)\r\nreturn 0;\r\nreturn -EINVAL;\r\n}\r\nreturn do_munmap(mm, bt_addr, mpx_bt_size_bytes(mm));\r\n}\r\nstatic int try_unmap_single_bt(struct mm_struct *mm,\r\nunsigned long start, unsigned long end)\r\n{\r\nstruct vm_area_struct *next;\r\nstruct vm_area_struct *prev;\r\nunsigned long bta_start_vaddr = start & ~(bd_entry_virt_space(mm)-1);\r\nunsigned long bta_end_vaddr = bta_start_vaddr + bd_entry_virt_space(mm);\r\nunsigned long uninitialized_var(bt_addr);\r\nvoid __user *bde_vaddr;\r\nint ret;\r\nnext = find_vma_prev(mm, start, &prev);\r\nwhile (next && (next->vm_flags & VM_MPX))\r\nnext = next->vm_next;\r\nwhile (prev && (prev->vm_flags & VM_MPX))\r\nprev = prev->vm_prev;\r\nnext = find_vma_prev(mm, start, &prev);\r\nif ((!prev || prev->vm_end <= bta_start_vaddr) &&\r\n(!next || next->vm_start >= bta_end_vaddr)) {\r\nstart = bta_start_vaddr;\r\nend = bta_end_vaddr;\r\n}\r\nbde_vaddr = mm->bd_addr + mpx_get_bd_entry_offset(mm, start);\r\nret = get_bt_addr(mm, bde_vaddr, &bt_addr);\r\nif (ret == -ENOENT) {\r\nret = 0;\r\nreturn 0;\r\n}\r\nif (ret)\r\nreturn ret;\r\nif ((start == bta_start_vaddr) &&\r\n(end == bta_end_vaddr))\r\nreturn unmap_entire_bt(mm, bde_vaddr, bt_addr);\r\nreturn zap_bt_entries_mapping(mm, bt_addr, start, end);\r\n}\r\nstatic int mpx_unmap_tables(struct mm_struct *mm,\r\nunsigned long start, unsigned long end)\r\n{\r\nunsigned long one_unmap_start;\r\ntrace_mpx_unmap_search(start, end);\r\none_unmap_start = start;\r\nwhile (one_unmap_start < end) {\r\nint ret;\r\nunsigned long next_unmap_start = ALIGN(one_unmap_start+1,\r\nbd_entry_virt_space(mm));\r\nunsigned long one_unmap_end = end;\r\nif (one_unmap_end > next_unmap_start)\r\none_unmap_end = next_unmap_start;\r\nret = try_unmap_single_bt(mm, one_unmap_start, one_unmap_end);\r\nif (ret)\r\nreturn ret;\r\none_unmap_start = next_unmap_start;\r\n}\r\nreturn 0;\r\n}\r\nvoid mpx_notify_unmap(struct mm_struct *mm, struct vm_area_struct *vma,\r\nunsigned long start, unsigned long end)\r\n{\r\nint ret;\r\nif (!kernel_managing_mpx_tables(current->mm))\r\nreturn;\r\ndo {\r\nif (vma->vm_flags & VM_MPX)\r\nreturn;\r\nvma = vma->vm_next;\r\n} while (vma && vma->vm_start < end);\r\nret = mpx_unmap_tables(mm, start, end);\r\nif (ret)\r\nforce_sig(SIGSEGV, current);\r\n}
