static inline u32 addr_fold(void *addr)\r\n{\r\nunsigned long a = (unsigned long)addr;\r\nreturn (a & 0xFFFFFFFF) ^ (BITS_PER_LONG > 32 ? a >> 32 : 0);\r\n}\r\nstatic u32 flow_get_src(const struct sk_buff *skb, const struct flow_keys *flow)\r\n{\r\n__be32 src = flow_get_u32_src(flow);\r\nif (src)\r\nreturn ntohl(src);\r\nreturn addr_fold(skb->sk);\r\n}\r\nstatic u32 flow_get_dst(const struct sk_buff *skb, const struct flow_keys *flow)\r\n{\r\n__be32 dst = flow_get_u32_dst(flow);\r\nif (dst)\r\nreturn ntohl(dst);\r\nreturn addr_fold(skb_dst(skb)) ^ (__force u16) tc_skb_protocol(skb);\r\n}\r\nstatic u32 flow_get_proto(const struct sk_buff *skb, const struct flow_keys *flow)\r\n{\r\nreturn flow->basic.ip_proto;\r\n}\r\nstatic u32 flow_get_proto_src(const struct sk_buff *skb, const struct flow_keys *flow)\r\n{\r\nif (flow->ports.ports)\r\nreturn ntohs(flow->ports.src);\r\nreturn addr_fold(skb->sk);\r\n}\r\nstatic u32 flow_get_proto_dst(const struct sk_buff *skb, const struct flow_keys *flow)\r\n{\r\nif (flow->ports.ports)\r\nreturn ntohs(flow->ports.dst);\r\nreturn addr_fold(skb_dst(skb)) ^ (__force u16) tc_skb_protocol(skb);\r\n}\r\nstatic u32 flow_get_iif(const struct sk_buff *skb)\r\n{\r\nreturn skb->skb_iif;\r\n}\r\nstatic u32 flow_get_priority(const struct sk_buff *skb)\r\n{\r\nreturn skb->priority;\r\n}\r\nstatic u32 flow_get_mark(const struct sk_buff *skb)\r\n{\r\nreturn skb->mark;\r\n}\r\nstatic u32 flow_get_nfct(const struct sk_buff *skb)\r\n{\r\n#if defined(CONFIG_NF_CONNTRACK) || defined(CONFIG_NF_CONNTRACK_MODULE)\r\nreturn addr_fold(skb->nfct);\r\n#else\r\nreturn 0;\r\n#endif\r\n}\r\nstatic u32 flow_get_nfct_src(const struct sk_buff *skb, const struct flow_keys *flow)\r\n{\r\nswitch (tc_skb_protocol(skb)) {\r\ncase htons(ETH_P_IP):\r\nreturn ntohl(CTTUPLE(skb, src.u3.ip));\r\ncase htons(ETH_P_IPV6):\r\nreturn ntohl(CTTUPLE(skb, src.u3.ip6[3]));\r\n}\r\nfallback:\r\nreturn flow_get_src(skb, flow);\r\n}\r\nstatic u32 flow_get_nfct_dst(const struct sk_buff *skb, const struct flow_keys *flow)\r\n{\r\nswitch (tc_skb_protocol(skb)) {\r\ncase htons(ETH_P_IP):\r\nreturn ntohl(CTTUPLE(skb, dst.u3.ip));\r\ncase htons(ETH_P_IPV6):\r\nreturn ntohl(CTTUPLE(skb, dst.u3.ip6[3]));\r\n}\r\nfallback:\r\nreturn flow_get_dst(skb, flow);\r\n}\r\nstatic u32 flow_get_nfct_proto_src(const struct sk_buff *skb, const struct flow_keys *flow)\r\n{\r\nreturn ntohs(CTTUPLE(skb, src.u.all));\r\nfallback:\r\nreturn flow_get_proto_src(skb, flow);\r\n}\r\nstatic u32 flow_get_nfct_proto_dst(const struct sk_buff *skb, const struct flow_keys *flow)\r\n{\r\nreturn ntohs(CTTUPLE(skb, dst.u.all));\r\nfallback:\r\nreturn flow_get_proto_dst(skb, flow);\r\n}\r\nstatic u32 flow_get_rtclassid(const struct sk_buff *skb)\r\n{\r\n#ifdef CONFIG_IP_ROUTE_CLASSID\r\nif (skb_dst(skb))\r\nreturn skb_dst(skb)->tclassid;\r\n#endif\r\nreturn 0;\r\n}\r\nstatic u32 flow_get_skuid(const struct sk_buff *skb)\r\n{\r\nstruct sock *sk = skb_to_full_sk(skb);\r\nif (sk && sk->sk_socket && sk->sk_socket->file) {\r\nkuid_t skuid = sk->sk_socket->file->f_cred->fsuid;\r\nreturn from_kuid(&init_user_ns, skuid);\r\n}\r\nreturn 0;\r\n}\r\nstatic u32 flow_get_skgid(const struct sk_buff *skb)\r\n{\r\nstruct sock *sk = skb_to_full_sk(skb);\r\nif (sk && sk->sk_socket && sk->sk_socket->file) {\r\nkgid_t skgid = sk->sk_socket->file->f_cred->fsgid;\r\nreturn from_kgid(&init_user_ns, skgid);\r\n}\r\nreturn 0;\r\n}\r\nstatic u32 flow_get_vlan_tag(const struct sk_buff *skb)\r\n{\r\nu16 uninitialized_var(tag);\r\nif (vlan_get_tag(skb, &tag) < 0)\r\nreturn 0;\r\nreturn tag & VLAN_VID_MASK;\r\n}\r\nstatic u32 flow_get_rxhash(struct sk_buff *skb)\r\n{\r\nreturn skb_get_hash(skb);\r\n}\r\nstatic u32 flow_key_get(struct sk_buff *skb, int key, struct flow_keys *flow)\r\n{\r\nswitch (key) {\r\ncase FLOW_KEY_SRC:\r\nreturn flow_get_src(skb, flow);\r\ncase FLOW_KEY_DST:\r\nreturn flow_get_dst(skb, flow);\r\ncase FLOW_KEY_PROTO:\r\nreturn flow_get_proto(skb, flow);\r\ncase FLOW_KEY_PROTO_SRC:\r\nreturn flow_get_proto_src(skb, flow);\r\ncase FLOW_KEY_PROTO_DST:\r\nreturn flow_get_proto_dst(skb, flow);\r\ncase FLOW_KEY_IIF:\r\nreturn flow_get_iif(skb);\r\ncase FLOW_KEY_PRIORITY:\r\nreturn flow_get_priority(skb);\r\ncase FLOW_KEY_MARK:\r\nreturn flow_get_mark(skb);\r\ncase FLOW_KEY_NFCT:\r\nreturn flow_get_nfct(skb);\r\ncase FLOW_KEY_NFCT_SRC:\r\nreturn flow_get_nfct_src(skb, flow);\r\ncase FLOW_KEY_NFCT_DST:\r\nreturn flow_get_nfct_dst(skb, flow);\r\ncase FLOW_KEY_NFCT_PROTO_SRC:\r\nreturn flow_get_nfct_proto_src(skb, flow);\r\ncase FLOW_KEY_NFCT_PROTO_DST:\r\nreturn flow_get_nfct_proto_dst(skb, flow);\r\ncase FLOW_KEY_RTCLASSID:\r\nreturn flow_get_rtclassid(skb);\r\ncase FLOW_KEY_SKUID:\r\nreturn flow_get_skuid(skb);\r\ncase FLOW_KEY_SKGID:\r\nreturn flow_get_skgid(skb);\r\ncase FLOW_KEY_VLAN_TAG:\r\nreturn flow_get_vlan_tag(skb);\r\ncase FLOW_KEY_RXHASH:\r\nreturn flow_get_rxhash(skb);\r\ndefault:\r\nWARN_ON(1);\r\nreturn 0;\r\n}\r\n}\r\nstatic int flow_classify(struct sk_buff *skb, const struct tcf_proto *tp,\r\nstruct tcf_result *res)\r\n{\r\nstruct flow_head *head = rcu_dereference_bh(tp->root);\r\nstruct flow_filter *f;\r\nu32 keymask;\r\nu32 classid;\r\nunsigned int n, key;\r\nint r;\r\nlist_for_each_entry_rcu(f, &head->filters, list) {\r\nu32 keys[FLOW_KEY_MAX + 1];\r\nstruct flow_keys flow_keys;\r\nif (!tcf_em_tree_match(skb, &f->ematches, NULL))\r\ncontinue;\r\nkeymask = f->keymask;\r\nif (keymask & FLOW_KEYS_NEEDED)\r\nskb_flow_dissect_flow_keys(skb, &flow_keys, 0);\r\nfor (n = 0; n < f->nkeys; n++) {\r\nkey = ffs(keymask) - 1;\r\nkeymask &= ~(1 << key);\r\nkeys[n] = flow_key_get(skb, key, &flow_keys);\r\n}\r\nif (f->mode == FLOW_MODE_HASH)\r\nclassid = jhash2(keys, f->nkeys, f->hashrnd);\r\nelse {\r\nclassid = keys[0];\r\nclassid = (classid & f->mask) ^ f->xor;\r\nclassid = (classid >> f->rshift) + f->addend;\r\n}\r\nif (f->divisor)\r\nclassid %= f->divisor;\r\nres->class = 0;\r\nres->classid = TC_H_MAKE(f->baseclass, f->baseclass + classid);\r\nr = tcf_exts_exec(skb, &f->exts, res);\r\nif (r < 0)\r\ncontinue;\r\nreturn r;\r\n}\r\nreturn -1;\r\n}\r\nstatic void flow_perturbation(unsigned long arg)\r\n{\r\nstruct flow_filter *f = (struct flow_filter *)arg;\r\nget_random_bytes(&f->hashrnd, 4);\r\nif (f->perturb_period)\r\nmod_timer(&f->perturb_timer, jiffies + f->perturb_period);\r\n}\r\nstatic void flow_destroy_filter(struct rcu_head *head)\r\n{\r\nstruct flow_filter *f = container_of(head, struct flow_filter, rcu);\r\ndel_timer_sync(&f->perturb_timer);\r\ntcf_exts_destroy(&f->exts);\r\ntcf_em_tree_destroy(&f->ematches);\r\nkfree(f);\r\n}\r\nstatic int flow_change(struct net *net, struct sk_buff *in_skb,\r\nstruct tcf_proto *tp, unsigned long base,\r\nu32 handle, struct nlattr **tca,\r\nunsigned long *arg, bool ovr)\r\n{\r\nstruct flow_head *head = rtnl_dereference(tp->root);\r\nstruct flow_filter *fold, *fnew;\r\nstruct nlattr *opt = tca[TCA_OPTIONS];\r\nstruct nlattr *tb[TCA_FLOW_MAX + 1];\r\nstruct tcf_exts e;\r\nstruct tcf_ematch_tree t;\r\nunsigned int nkeys = 0;\r\nunsigned int perturb_period = 0;\r\nu32 baseclass = 0;\r\nu32 keymask = 0;\r\nu32 mode;\r\nint err;\r\nif (opt == NULL)\r\nreturn -EINVAL;\r\nerr = nla_parse_nested(tb, TCA_FLOW_MAX, opt, flow_policy);\r\nif (err < 0)\r\nreturn err;\r\nif (tb[TCA_FLOW_BASECLASS]) {\r\nbaseclass = nla_get_u32(tb[TCA_FLOW_BASECLASS]);\r\nif (TC_H_MIN(baseclass) == 0)\r\nreturn -EINVAL;\r\n}\r\nif (tb[TCA_FLOW_KEYS]) {\r\nkeymask = nla_get_u32(tb[TCA_FLOW_KEYS]);\r\nnkeys = hweight32(keymask);\r\nif (nkeys == 0)\r\nreturn -EINVAL;\r\nif (fls(keymask) - 1 > FLOW_KEY_MAX)\r\nreturn -EOPNOTSUPP;\r\nif ((keymask & (FLOW_KEY_SKUID|FLOW_KEY_SKGID)) &&\r\nsk_user_ns(NETLINK_CB(in_skb).sk) != &init_user_ns)\r\nreturn -EOPNOTSUPP;\r\n}\r\ntcf_exts_init(&e, TCA_FLOW_ACT, TCA_FLOW_POLICE);\r\nerr = tcf_exts_validate(net, tp, tb, tca[TCA_RATE], &e, ovr);\r\nif (err < 0)\r\nreturn err;\r\nerr = tcf_em_tree_validate(tp, tb[TCA_FLOW_EMATCHES], &t);\r\nif (err < 0)\r\ngoto err1;\r\nerr = -ENOBUFS;\r\nfnew = kzalloc(sizeof(*fnew), GFP_KERNEL);\r\nif (!fnew)\r\ngoto err2;\r\ntcf_exts_init(&fnew->exts, TCA_FLOW_ACT, TCA_FLOW_POLICE);\r\nfold = (struct flow_filter *)*arg;\r\nif (fold) {\r\nerr = -EINVAL;\r\nif (fold->handle != handle && handle)\r\ngoto err2;\r\nfnew->tp = fold->tp;\r\nfnew->handle = fold->handle;\r\nfnew->nkeys = fold->nkeys;\r\nfnew->keymask = fold->keymask;\r\nfnew->mode = fold->mode;\r\nfnew->mask = fold->mask;\r\nfnew->xor = fold->xor;\r\nfnew->rshift = fold->rshift;\r\nfnew->addend = fold->addend;\r\nfnew->divisor = fold->divisor;\r\nfnew->baseclass = fold->baseclass;\r\nfnew->hashrnd = fold->hashrnd;\r\nmode = fold->mode;\r\nif (tb[TCA_FLOW_MODE])\r\nmode = nla_get_u32(tb[TCA_FLOW_MODE]);\r\nif (mode != FLOW_MODE_HASH && nkeys > 1)\r\ngoto err2;\r\nif (mode == FLOW_MODE_HASH)\r\nperturb_period = fold->perturb_period;\r\nif (tb[TCA_FLOW_PERTURB]) {\r\nif (mode != FLOW_MODE_HASH)\r\ngoto err2;\r\nperturb_period = nla_get_u32(tb[TCA_FLOW_PERTURB]) * HZ;\r\n}\r\n} else {\r\nerr = -EINVAL;\r\nif (!handle)\r\ngoto err2;\r\nif (!tb[TCA_FLOW_KEYS])\r\ngoto err2;\r\nmode = FLOW_MODE_MAP;\r\nif (tb[TCA_FLOW_MODE])\r\nmode = nla_get_u32(tb[TCA_FLOW_MODE]);\r\nif (mode != FLOW_MODE_HASH && nkeys > 1)\r\ngoto err2;\r\nif (tb[TCA_FLOW_PERTURB]) {\r\nif (mode != FLOW_MODE_HASH)\r\ngoto err2;\r\nperturb_period = nla_get_u32(tb[TCA_FLOW_PERTURB]) * HZ;\r\n}\r\nif (TC_H_MAJ(baseclass) == 0)\r\nbaseclass = TC_H_MAKE(tp->q->handle, baseclass);\r\nif (TC_H_MIN(baseclass) == 0)\r\nbaseclass = TC_H_MAKE(baseclass, 1);\r\nfnew->handle = handle;\r\nfnew->mask = ~0U;\r\nfnew->tp = tp;\r\nget_random_bytes(&fnew->hashrnd, 4);\r\n}\r\nfnew->perturb_timer.function = flow_perturbation;\r\nfnew->perturb_timer.data = (unsigned long)fnew;\r\ninit_timer_deferrable(&fnew->perturb_timer);\r\ntcf_exts_change(tp, &fnew->exts, &e);\r\ntcf_em_tree_change(tp, &fnew->ematches, &t);\r\nnetif_keep_dst(qdisc_dev(tp->q));\r\nif (tb[TCA_FLOW_KEYS]) {\r\nfnew->keymask = keymask;\r\nfnew->nkeys = nkeys;\r\n}\r\nfnew->mode = mode;\r\nif (tb[TCA_FLOW_MASK])\r\nfnew->mask = nla_get_u32(tb[TCA_FLOW_MASK]);\r\nif (tb[TCA_FLOW_XOR])\r\nfnew->xor = nla_get_u32(tb[TCA_FLOW_XOR]);\r\nif (tb[TCA_FLOW_RSHIFT])\r\nfnew->rshift = nla_get_u32(tb[TCA_FLOW_RSHIFT]);\r\nif (tb[TCA_FLOW_ADDEND])\r\nfnew->addend = nla_get_u32(tb[TCA_FLOW_ADDEND]);\r\nif (tb[TCA_FLOW_DIVISOR])\r\nfnew->divisor = nla_get_u32(tb[TCA_FLOW_DIVISOR]);\r\nif (baseclass)\r\nfnew->baseclass = baseclass;\r\nfnew->perturb_period = perturb_period;\r\nif (perturb_period)\r\nmod_timer(&fnew->perturb_timer, jiffies + perturb_period);\r\nif (*arg == 0)\r\nlist_add_tail_rcu(&fnew->list, &head->filters);\r\nelse\r\nlist_replace_rcu(&fold->list, &fnew->list);\r\n*arg = (unsigned long)fnew;\r\nif (fold)\r\ncall_rcu(&fold->rcu, flow_destroy_filter);\r\nreturn 0;\r\nerr2:\r\ntcf_em_tree_destroy(&t);\r\nkfree(fnew);\r\nerr1:\r\ntcf_exts_destroy(&e);\r\nreturn err;\r\n}\r\nstatic int flow_delete(struct tcf_proto *tp, unsigned long arg)\r\n{\r\nstruct flow_filter *f = (struct flow_filter *)arg;\r\nlist_del_rcu(&f->list);\r\ncall_rcu(&f->rcu, flow_destroy_filter);\r\nreturn 0;\r\n}\r\nstatic int flow_init(struct tcf_proto *tp)\r\n{\r\nstruct flow_head *head;\r\nhead = kzalloc(sizeof(*head), GFP_KERNEL);\r\nif (head == NULL)\r\nreturn -ENOBUFS;\r\nINIT_LIST_HEAD(&head->filters);\r\nrcu_assign_pointer(tp->root, head);\r\nreturn 0;\r\n}\r\nstatic bool flow_destroy(struct tcf_proto *tp, bool force)\r\n{\r\nstruct flow_head *head = rtnl_dereference(tp->root);\r\nstruct flow_filter *f, *next;\r\nif (!force && !list_empty(&head->filters))\r\nreturn false;\r\nlist_for_each_entry_safe(f, next, &head->filters, list) {\r\nlist_del_rcu(&f->list);\r\ncall_rcu(&f->rcu, flow_destroy_filter);\r\n}\r\nRCU_INIT_POINTER(tp->root, NULL);\r\nkfree_rcu(head, rcu);\r\nreturn true;\r\n}\r\nstatic unsigned long flow_get(struct tcf_proto *tp, u32 handle)\r\n{\r\nstruct flow_head *head = rtnl_dereference(tp->root);\r\nstruct flow_filter *f;\r\nlist_for_each_entry(f, &head->filters, list)\r\nif (f->handle == handle)\r\nreturn (unsigned long)f;\r\nreturn 0;\r\n}\r\nstatic int flow_dump(struct net *net, struct tcf_proto *tp, unsigned long fh,\r\nstruct sk_buff *skb, struct tcmsg *t)\r\n{\r\nstruct flow_filter *f = (struct flow_filter *)fh;\r\nstruct nlattr *nest;\r\nif (f == NULL)\r\nreturn skb->len;\r\nt->tcm_handle = f->handle;\r\nnest = nla_nest_start(skb, TCA_OPTIONS);\r\nif (nest == NULL)\r\ngoto nla_put_failure;\r\nif (nla_put_u32(skb, TCA_FLOW_KEYS, f->keymask) ||\r\nnla_put_u32(skb, TCA_FLOW_MODE, f->mode))\r\ngoto nla_put_failure;\r\nif (f->mask != ~0 || f->xor != 0) {\r\nif (nla_put_u32(skb, TCA_FLOW_MASK, f->mask) ||\r\nnla_put_u32(skb, TCA_FLOW_XOR, f->xor))\r\ngoto nla_put_failure;\r\n}\r\nif (f->rshift &&\r\nnla_put_u32(skb, TCA_FLOW_RSHIFT, f->rshift))\r\ngoto nla_put_failure;\r\nif (f->addend &&\r\nnla_put_u32(skb, TCA_FLOW_ADDEND, f->addend))\r\ngoto nla_put_failure;\r\nif (f->divisor &&\r\nnla_put_u32(skb, TCA_FLOW_DIVISOR, f->divisor))\r\ngoto nla_put_failure;\r\nif (f->baseclass &&\r\nnla_put_u32(skb, TCA_FLOW_BASECLASS, f->baseclass))\r\ngoto nla_put_failure;\r\nif (f->perturb_period &&\r\nnla_put_u32(skb, TCA_FLOW_PERTURB, f->perturb_period / HZ))\r\ngoto nla_put_failure;\r\nif (tcf_exts_dump(skb, &f->exts) < 0)\r\ngoto nla_put_failure;\r\n#ifdef CONFIG_NET_EMATCH\r\nif (f->ematches.hdr.nmatches &&\r\ntcf_em_tree_dump(skb, &f->ematches, TCA_FLOW_EMATCHES) < 0)\r\ngoto nla_put_failure;\r\n#endif\r\nnla_nest_end(skb, nest);\r\nif (tcf_exts_dump_stats(skb, &f->exts) < 0)\r\ngoto nla_put_failure;\r\nreturn skb->len;\r\nnla_put_failure:\r\nnla_nest_cancel(skb, nest);\r\nreturn -1;\r\n}\r\nstatic void flow_walk(struct tcf_proto *tp, struct tcf_walker *arg)\r\n{\r\nstruct flow_head *head = rtnl_dereference(tp->root);\r\nstruct flow_filter *f;\r\nlist_for_each_entry(f, &head->filters, list) {\r\nif (arg->count < arg->skip)\r\ngoto skip;\r\nif (arg->fn(tp, (unsigned long)f, arg) < 0) {\r\narg->stop = 1;\r\nbreak;\r\n}\r\nskip:\r\narg->count++;\r\n}\r\n}\r\nstatic int __init cls_flow_init(void)\r\n{\r\nreturn register_tcf_proto_ops(&cls_flow_ops);\r\n}\r\nstatic void __exit cls_flow_exit(void)\r\n{\r\nunregister_tcf_proto_ops(&cls_flow_ops);\r\n}
