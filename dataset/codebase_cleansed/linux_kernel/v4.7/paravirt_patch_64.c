unsigned paravirt_patch_ident_32(void *insnbuf, unsigned len)\r\n{\r\nreturn paravirt_patch_insns(insnbuf, len,\r\nstart__mov32, end__mov32);\r\n}\r\nunsigned paravirt_patch_ident_64(void *insnbuf, unsigned len)\r\n{\r\nreturn paravirt_patch_insns(insnbuf, len,\r\nstart__mov64, end__mov64);\r\n}\r\nunsigned native_patch(u8 type, u16 clobbers, void *ibuf,\r\nunsigned long addr, unsigned len)\r\n{\r\nconst unsigned char *start, *end;\r\nunsigned ret;\r\n#define PATCH_SITE(ops, x) \\r\ncase PARAVIRT_PATCH(ops.x): \\r\nstart = start_##ops##_##x; \\r\nend = end_##ops##_##x; \\r\ngoto patch_site\r\nswitch(type) {\r\nPATCH_SITE(pv_irq_ops, restore_fl);\r\nPATCH_SITE(pv_irq_ops, save_fl);\r\nPATCH_SITE(pv_irq_ops, irq_enable);\r\nPATCH_SITE(pv_irq_ops, irq_disable);\r\nPATCH_SITE(pv_cpu_ops, usergs_sysret64);\r\nPATCH_SITE(pv_cpu_ops, swapgs);\r\nPATCH_SITE(pv_mmu_ops, read_cr2);\r\nPATCH_SITE(pv_mmu_ops, read_cr3);\r\nPATCH_SITE(pv_mmu_ops, write_cr3);\r\nPATCH_SITE(pv_cpu_ops, clts);\r\nPATCH_SITE(pv_mmu_ops, flush_tlb_single);\r\nPATCH_SITE(pv_cpu_ops, wbinvd);\r\n#if defined(CONFIG_PARAVIRT_SPINLOCKS) && defined(CONFIG_QUEUED_SPINLOCKS)\r\ncase PARAVIRT_PATCH(pv_lock_ops.queued_spin_unlock):\r\nif (pv_is_native_spin_unlock()) {\r\nstart = start_pv_lock_ops_queued_spin_unlock;\r\nend = end_pv_lock_ops_queued_spin_unlock;\r\ngoto patch_site;\r\n}\r\n#endif\r\ndefault:\r\nret = paravirt_patch_default(type, clobbers, ibuf, addr, len);\r\nbreak;\r\npatch_site:\r\nret = paravirt_patch_insns(ibuf, len, start, end);\r\nbreak;\r\n}\r\n#undef PATCH_SITE\r\nreturn ret;\r\n}
