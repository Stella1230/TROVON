static void rocker_wait_reset(struct rocker_wait *wait)\r\n{\r\nwait->done = false;\r\nwait->nowait = false;\r\n}\r\nstatic void rocker_wait_init(struct rocker_wait *wait)\r\n{\r\ninit_waitqueue_head(&wait->wait);\r\nrocker_wait_reset(wait);\r\n}\r\nstatic struct rocker_wait *rocker_wait_create(void)\r\n{\r\nstruct rocker_wait *wait;\r\nwait = kzalloc(sizeof(*wait), GFP_KERNEL);\r\nif (!wait)\r\nreturn NULL;\r\nreturn wait;\r\n}\r\nstatic void rocker_wait_destroy(struct rocker_wait *wait)\r\n{\r\nkfree(wait);\r\n}\r\nstatic bool rocker_wait_event_timeout(struct rocker_wait *wait,\r\nunsigned long timeout)\r\n{\r\nwait_event_timeout(wait->wait, wait->done, HZ / 10);\r\nif (!wait->done)\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic void rocker_wait_wake_up(struct rocker_wait *wait)\r\n{\r\nwait->done = true;\r\nwake_up(&wait->wait);\r\n}\r\nstatic u32 rocker_msix_vector(const struct rocker *rocker, unsigned int vector)\r\n{\r\nreturn rocker->msix_entries[vector].vector;\r\n}\r\nstatic u32 rocker_msix_tx_vector(const struct rocker_port *rocker_port)\r\n{\r\nreturn rocker_msix_vector(rocker_port->rocker,\r\nROCKER_MSIX_VEC_TX(rocker_port->port_number));\r\n}\r\nstatic u32 rocker_msix_rx_vector(const struct rocker_port *rocker_port)\r\n{\r\nreturn rocker_msix_vector(rocker_port->rocker,\r\nROCKER_MSIX_VEC_RX(rocker_port->port_number));\r\n}\r\nstatic int rocker_reg_test(const struct rocker *rocker)\r\n{\r\nconst struct pci_dev *pdev = rocker->pdev;\r\nu64 test_reg;\r\nu64 rnd;\r\nrnd = prandom_u32();\r\nrnd >>= 1;\r\nrocker_write32(rocker, TEST_REG, rnd);\r\ntest_reg = rocker_read32(rocker, TEST_REG);\r\nif (test_reg != rnd * 2) {\r\ndev_err(&pdev->dev, "unexpected 32bit register value %08llx, expected %08llx\n",\r\ntest_reg, rnd * 2);\r\nreturn -EIO;\r\n}\r\nrnd = prandom_u32();\r\nrnd <<= 31;\r\nrnd |= prandom_u32();\r\nrocker_write64(rocker, TEST_REG64, rnd);\r\ntest_reg = rocker_read64(rocker, TEST_REG64);\r\nif (test_reg != rnd * 2) {\r\ndev_err(&pdev->dev, "unexpected 64bit register value %16llx, expected %16llx\n",\r\ntest_reg, rnd * 2);\r\nreturn -EIO;\r\n}\r\nreturn 0;\r\n}\r\nstatic int rocker_dma_test_one(const struct rocker *rocker,\r\nstruct rocker_wait *wait, u32 test_type,\r\ndma_addr_t dma_handle, const unsigned char *buf,\r\nconst unsigned char *expect, size_t size)\r\n{\r\nconst struct pci_dev *pdev = rocker->pdev;\r\nint i;\r\nrocker_wait_reset(wait);\r\nrocker_write32(rocker, TEST_DMA_CTRL, test_type);\r\nif (!rocker_wait_event_timeout(wait, HZ / 10)) {\r\ndev_err(&pdev->dev, "no interrupt received within a timeout\n");\r\nreturn -EIO;\r\n}\r\nfor (i = 0; i < size; i++) {\r\nif (buf[i] != expect[i]) {\r\ndev_err(&pdev->dev, "unexpected memory content %02x at byte %x\n, %02x expected",\r\nbuf[i], i, expect[i]);\r\nreturn -EIO;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int rocker_dma_test_offset(const struct rocker *rocker,\r\nstruct rocker_wait *wait, int offset)\r\n{\r\nstruct pci_dev *pdev = rocker->pdev;\r\nunsigned char *alloc;\r\nunsigned char *buf;\r\nunsigned char *expect;\r\ndma_addr_t dma_handle;\r\nint i;\r\nint err;\r\nalloc = kzalloc(ROCKER_TEST_DMA_BUF_SIZE * 2 + offset,\r\nGFP_KERNEL | GFP_DMA);\r\nif (!alloc)\r\nreturn -ENOMEM;\r\nbuf = alloc + offset;\r\nexpect = buf + ROCKER_TEST_DMA_BUF_SIZE;\r\ndma_handle = pci_map_single(pdev, buf, ROCKER_TEST_DMA_BUF_SIZE,\r\nPCI_DMA_BIDIRECTIONAL);\r\nif (pci_dma_mapping_error(pdev, dma_handle)) {\r\nerr = -EIO;\r\ngoto free_alloc;\r\n}\r\nrocker_write64(rocker, TEST_DMA_ADDR, dma_handle);\r\nrocker_write32(rocker, TEST_DMA_SIZE, ROCKER_TEST_DMA_BUF_SIZE);\r\nmemset(expect, ROCKER_TEST_DMA_FILL_PATTERN, ROCKER_TEST_DMA_BUF_SIZE);\r\nerr = rocker_dma_test_one(rocker, wait, ROCKER_TEST_DMA_CTRL_FILL,\r\ndma_handle, buf, expect,\r\nROCKER_TEST_DMA_BUF_SIZE);\r\nif (err)\r\ngoto unmap;\r\nmemset(expect, 0, ROCKER_TEST_DMA_BUF_SIZE);\r\nerr = rocker_dma_test_one(rocker, wait, ROCKER_TEST_DMA_CTRL_CLEAR,\r\ndma_handle, buf, expect,\r\nROCKER_TEST_DMA_BUF_SIZE);\r\nif (err)\r\ngoto unmap;\r\nprandom_bytes(buf, ROCKER_TEST_DMA_BUF_SIZE);\r\nfor (i = 0; i < ROCKER_TEST_DMA_BUF_SIZE; i++)\r\nexpect[i] = ~buf[i];\r\nerr = rocker_dma_test_one(rocker, wait, ROCKER_TEST_DMA_CTRL_INVERT,\r\ndma_handle, buf, expect,\r\nROCKER_TEST_DMA_BUF_SIZE);\r\nif (err)\r\ngoto unmap;\r\nunmap:\r\npci_unmap_single(pdev, dma_handle, ROCKER_TEST_DMA_BUF_SIZE,\r\nPCI_DMA_BIDIRECTIONAL);\r\nfree_alloc:\r\nkfree(alloc);\r\nreturn err;\r\n}\r\nstatic int rocker_dma_test(const struct rocker *rocker,\r\nstruct rocker_wait *wait)\r\n{\r\nint i;\r\nint err;\r\nfor (i = 0; i < 8; i++) {\r\nerr = rocker_dma_test_offset(rocker, wait, i);\r\nif (err)\r\nreturn err;\r\n}\r\nreturn 0;\r\n}\r\nstatic irqreturn_t rocker_test_irq_handler(int irq, void *dev_id)\r\n{\r\nstruct rocker_wait *wait = dev_id;\r\nrocker_wait_wake_up(wait);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int rocker_basic_hw_test(const struct rocker *rocker)\r\n{\r\nconst struct pci_dev *pdev = rocker->pdev;\r\nstruct rocker_wait wait;\r\nint err;\r\nerr = rocker_reg_test(rocker);\r\nif (err) {\r\ndev_err(&pdev->dev, "reg test failed\n");\r\nreturn err;\r\n}\r\nerr = request_irq(rocker_msix_vector(rocker, ROCKER_MSIX_VEC_TEST),\r\nrocker_test_irq_handler, 0,\r\nrocker_driver_name, &wait);\r\nif (err) {\r\ndev_err(&pdev->dev, "cannot assign test irq\n");\r\nreturn err;\r\n}\r\nrocker_wait_init(&wait);\r\nrocker_write32(rocker, TEST_IRQ, ROCKER_MSIX_VEC_TEST);\r\nif (!rocker_wait_event_timeout(&wait, HZ / 10)) {\r\ndev_err(&pdev->dev, "no interrupt received within a timeout\n");\r\nerr = -EIO;\r\ngoto free_irq;\r\n}\r\nerr = rocker_dma_test(rocker, &wait);\r\nif (err)\r\ndev_err(&pdev->dev, "dma test failed\n");\r\nfree_irq:\r\nfree_irq(rocker_msix_vector(rocker, ROCKER_MSIX_VEC_TEST), &wait);\r\nreturn err;\r\n}\r\nstatic u32 __pos_inc(u32 pos, size_t limit)\r\n{\r\nreturn ++pos == limit ? 0 : pos;\r\n}\r\nstatic int rocker_desc_err(const struct rocker_desc_info *desc_info)\r\n{\r\nint err = desc_info->desc->comp_err & ~ROCKER_DMA_DESC_COMP_ERR_GEN;\r\nswitch (err) {\r\ncase ROCKER_OK:\r\nreturn 0;\r\ncase -ROCKER_ENOENT:\r\nreturn -ENOENT;\r\ncase -ROCKER_ENXIO:\r\nreturn -ENXIO;\r\ncase -ROCKER_ENOMEM:\r\nreturn -ENOMEM;\r\ncase -ROCKER_EEXIST:\r\nreturn -EEXIST;\r\ncase -ROCKER_EINVAL:\r\nreturn -EINVAL;\r\ncase -ROCKER_EMSGSIZE:\r\nreturn -EMSGSIZE;\r\ncase -ROCKER_ENOTSUP:\r\nreturn -EOPNOTSUPP;\r\ncase -ROCKER_ENOBUFS:\r\nreturn -ENOBUFS;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic void rocker_desc_gen_clear(const struct rocker_desc_info *desc_info)\r\n{\r\ndesc_info->desc->comp_err &= ~ROCKER_DMA_DESC_COMP_ERR_GEN;\r\n}\r\nstatic bool rocker_desc_gen(const struct rocker_desc_info *desc_info)\r\n{\r\nu32 comp_err = desc_info->desc->comp_err;\r\nreturn comp_err & ROCKER_DMA_DESC_COMP_ERR_GEN ? true : false;\r\n}\r\nstatic void *\r\nrocker_desc_cookie_ptr_get(const struct rocker_desc_info *desc_info)\r\n{\r\nreturn (void *)(uintptr_t)desc_info->desc->cookie;\r\n}\r\nstatic void rocker_desc_cookie_ptr_set(const struct rocker_desc_info *desc_info,\r\nvoid *ptr)\r\n{\r\ndesc_info->desc->cookie = (uintptr_t) ptr;\r\n}\r\nstatic struct rocker_desc_info *\r\nrocker_desc_head_get(const struct rocker_dma_ring_info *info)\r\n{\r\nstatic struct rocker_desc_info *desc_info;\r\nu32 head = __pos_inc(info->head, info->size);\r\ndesc_info = &info->desc_info[info->head];\r\nif (head == info->tail)\r\nreturn NULL;\r\ndesc_info->tlv_size = 0;\r\nreturn desc_info;\r\n}\r\nstatic void rocker_desc_commit(const struct rocker_desc_info *desc_info)\r\n{\r\ndesc_info->desc->buf_size = desc_info->data_size;\r\ndesc_info->desc->tlv_size = desc_info->tlv_size;\r\n}\r\nstatic void rocker_desc_head_set(const struct rocker *rocker,\r\nstruct rocker_dma_ring_info *info,\r\nconst struct rocker_desc_info *desc_info)\r\n{\r\nu32 head = __pos_inc(info->head, info->size);\r\nBUG_ON(head == info->tail);\r\nrocker_desc_commit(desc_info);\r\ninfo->head = head;\r\nrocker_write32(rocker, DMA_DESC_HEAD(info->type), head);\r\n}\r\nstatic struct rocker_desc_info *\r\nrocker_desc_tail_get(struct rocker_dma_ring_info *info)\r\n{\r\nstatic struct rocker_desc_info *desc_info;\r\nif (info->tail == info->head)\r\nreturn NULL;\r\ndesc_info = &info->desc_info[info->tail];\r\nif (!rocker_desc_gen(desc_info))\r\nreturn NULL;\r\ninfo->tail = __pos_inc(info->tail, info->size);\r\ndesc_info->tlv_size = desc_info->desc->tlv_size;\r\nreturn desc_info;\r\n}\r\nstatic void rocker_dma_ring_credits_set(const struct rocker *rocker,\r\nconst struct rocker_dma_ring_info *info,\r\nu32 credits)\r\n{\r\nif (credits)\r\nrocker_write32(rocker, DMA_DESC_CREDITS(info->type), credits);\r\n}\r\nstatic unsigned long rocker_dma_ring_size_fix(size_t size)\r\n{\r\nreturn max(ROCKER_DMA_SIZE_MIN,\r\nmin(roundup_pow_of_two(size), ROCKER_DMA_SIZE_MAX));\r\n}\r\nstatic int rocker_dma_ring_create(const struct rocker *rocker,\r\nunsigned int type,\r\nsize_t size,\r\nstruct rocker_dma_ring_info *info)\r\n{\r\nint i;\r\nBUG_ON(size != rocker_dma_ring_size_fix(size));\r\ninfo->size = size;\r\ninfo->type = type;\r\ninfo->head = 0;\r\ninfo->tail = 0;\r\ninfo->desc_info = kcalloc(info->size, sizeof(*info->desc_info),\r\nGFP_KERNEL);\r\nif (!info->desc_info)\r\nreturn -ENOMEM;\r\ninfo->desc = pci_alloc_consistent(rocker->pdev,\r\ninfo->size * sizeof(*info->desc),\r\n&info->mapaddr);\r\nif (!info->desc) {\r\nkfree(info->desc_info);\r\nreturn -ENOMEM;\r\n}\r\nfor (i = 0; i < info->size; i++)\r\ninfo->desc_info[i].desc = &info->desc[i];\r\nrocker_write32(rocker, DMA_DESC_CTRL(info->type),\r\nROCKER_DMA_DESC_CTRL_RESET);\r\nrocker_write64(rocker, DMA_DESC_ADDR(info->type), info->mapaddr);\r\nrocker_write32(rocker, DMA_DESC_SIZE(info->type), info->size);\r\nreturn 0;\r\n}\r\nstatic void rocker_dma_ring_destroy(const struct rocker *rocker,\r\nconst struct rocker_dma_ring_info *info)\r\n{\r\nrocker_write64(rocker, DMA_DESC_ADDR(info->type), 0);\r\npci_free_consistent(rocker->pdev,\r\ninfo->size * sizeof(struct rocker_desc),\r\ninfo->desc, info->mapaddr);\r\nkfree(info->desc_info);\r\n}\r\nstatic void rocker_dma_ring_pass_to_producer(const struct rocker *rocker,\r\nstruct rocker_dma_ring_info *info)\r\n{\r\nint i;\r\nBUG_ON(info->head || info->tail);\r\nfor (i = 0; i < info->size - 1; i++)\r\nrocker_desc_head_set(rocker, info, &info->desc_info[i]);\r\nrocker_desc_commit(&info->desc_info[i]);\r\n}\r\nstatic int rocker_dma_ring_bufs_alloc(const struct rocker *rocker,\r\nconst struct rocker_dma_ring_info *info,\r\nint direction, size_t buf_size)\r\n{\r\nstruct pci_dev *pdev = rocker->pdev;\r\nint i;\r\nint err;\r\nfor (i = 0; i < info->size; i++) {\r\nstruct rocker_desc_info *desc_info = &info->desc_info[i];\r\nstruct rocker_desc *desc = &info->desc[i];\r\ndma_addr_t dma_handle;\r\nchar *buf;\r\nbuf = kzalloc(buf_size, GFP_KERNEL | GFP_DMA);\r\nif (!buf) {\r\nerr = -ENOMEM;\r\ngoto rollback;\r\n}\r\ndma_handle = pci_map_single(pdev, buf, buf_size, direction);\r\nif (pci_dma_mapping_error(pdev, dma_handle)) {\r\nkfree(buf);\r\nerr = -EIO;\r\ngoto rollback;\r\n}\r\ndesc_info->data = buf;\r\ndesc_info->data_size = buf_size;\r\ndma_unmap_addr_set(desc_info, mapaddr, dma_handle);\r\ndesc->buf_addr = dma_handle;\r\ndesc->buf_size = buf_size;\r\n}\r\nreturn 0;\r\nrollback:\r\nfor (i--; i >= 0; i--) {\r\nconst struct rocker_desc_info *desc_info = &info->desc_info[i];\r\npci_unmap_single(pdev, dma_unmap_addr(desc_info, mapaddr),\r\ndesc_info->data_size, direction);\r\nkfree(desc_info->data);\r\n}\r\nreturn err;\r\n}\r\nstatic void rocker_dma_ring_bufs_free(const struct rocker *rocker,\r\nconst struct rocker_dma_ring_info *info,\r\nint direction)\r\n{\r\nstruct pci_dev *pdev = rocker->pdev;\r\nint i;\r\nfor (i = 0; i < info->size; i++) {\r\nconst struct rocker_desc_info *desc_info = &info->desc_info[i];\r\nstruct rocker_desc *desc = &info->desc[i];\r\ndesc->buf_addr = 0;\r\ndesc->buf_size = 0;\r\npci_unmap_single(pdev, dma_unmap_addr(desc_info, mapaddr),\r\ndesc_info->data_size, direction);\r\nkfree(desc_info->data);\r\n}\r\n}\r\nstatic int rocker_dma_cmd_ring_wait_alloc(struct rocker_desc_info *desc_info)\r\n{\r\nstruct rocker_wait *wait;\r\nwait = rocker_wait_create();\r\nif (!wait)\r\nreturn -ENOMEM;\r\nrocker_desc_cookie_ptr_set(desc_info, wait);\r\nreturn 0;\r\n}\r\nstatic void\r\nrocker_dma_cmd_ring_wait_free(const struct rocker_desc_info *desc_info)\r\n{\r\nstruct rocker_wait *wait = rocker_desc_cookie_ptr_get(desc_info);\r\nrocker_wait_destroy(wait);\r\n}\r\nstatic int rocker_dma_cmd_ring_waits_alloc(const struct rocker *rocker)\r\n{\r\nconst struct rocker_dma_ring_info *cmd_ring = &rocker->cmd_ring;\r\nint i;\r\nint err;\r\nfor (i = 0; i < cmd_ring->size; i++) {\r\nerr = rocker_dma_cmd_ring_wait_alloc(&cmd_ring->desc_info[i]);\r\nif (err)\r\ngoto rollback;\r\n}\r\nreturn 0;\r\nrollback:\r\nfor (i--; i >= 0; i--)\r\nrocker_dma_cmd_ring_wait_free(&cmd_ring->desc_info[i]);\r\nreturn err;\r\n}\r\nstatic void rocker_dma_cmd_ring_waits_free(const struct rocker *rocker)\r\n{\r\nconst struct rocker_dma_ring_info *cmd_ring = &rocker->cmd_ring;\r\nint i;\r\nfor (i = 0; i < cmd_ring->size; i++)\r\nrocker_dma_cmd_ring_wait_free(&cmd_ring->desc_info[i]);\r\n}\r\nstatic int rocker_dma_rings_init(struct rocker *rocker)\r\n{\r\nconst struct pci_dev *pdev = rocker->pdev;\r\nint err;\r\nerr = rocker_dma_ring_create(rocker, ROCKER_DMA_CMD,\r\nROCKER_DMA_CMD_DEFAULT_SIZE,\r\n&rocker->cmd_ring);\r\nif (err) {\r\ndev_err(&pdev->dev, "failed to create command dma ring\n");\r\nreturn err;\r\n}\r\nspin_lock_init(&rocker->cmd_ring_lock);\r\nerr = rocker_dma_ring_bufs_alloc(rocker, &rocker->cmd_ring,\r\nPCI_DMA_BIDIRECTIONAL, PAGE_SIZE);\r\nif (err) {\r\ndev_err(&pdev->dev, "failed to alloc command dma ring buffers\n");\r\ngoto err_dma_cmd_ring_bufs_alloc;\r\n}\r\nerr = rocker_dma_cmd_ring_waits_alloc(rocker);\r\nif (err) {\r\ndev_err(&pdev->dev, "failed to alloc command dma ring waits\n");\r\ngoto err_dma_cmd_ring_waits_alloc;\r\n}\r\nerr = rocker_dma_ring_create(rocker, ROCKER_DMA_EVENT,\r\nROCKER_DMA_EVENT_DEFAULT_SIZE,\r\n&rocker->event_ring);\r\nif (err) {\r\ndev_err(&pdev->dev, "failed to create event dma ring\n");\r\ngoto err_dma_event_ring_create;\r\n}\r\nerr = rocker_dma_ring_bufs_alloc(rocker, &rocker->event_ring,\r\nPCI_DMA_FROMDEVICE, PAGE_SIZE);\r\nif (err) {\r\ndev_err(&pdev->dev, "failed to alloc event dma ring buffers\n");\r\ngoto err_dma_event_ring_bufs_alloc;\r\n}\r\nrocker_dma_ring_pass_to_producer(rocker, &rocker->event_ring);\r\nreturn 0;\r\nerr_dma_event_ring_bufs_alloc:\r\nrocker_dma_ring_destroy(rocker, &rocker->event_ring);\r\nerr_dma_event_ring_create:\r\nrocker_dma_ring_bufs_free(rocker, &rocker->cmd_ring,\r\nPCI_DMA_BIDIRECTIONAL);\r\nerr_dma_cmd_ring_waits_alloc:\r\nrocker_dma_cmd_ring_waits_free(rocker);\r\nerr_dma_cmd_ring_bufs_alloc:\r\nrocker_dma_ring_destroy(rocker, &rocker->cmd_ring);\r\nreturn err;\r\n}\r\nstatic void rocker_dma_rings_fini(struct rocker *rocker)\r\n{\r\nrocker_dma_ring_bufs_free(rocker, &rocker->event_ring,\r\nPCI_DMA_BIDIRECTIONAL);\r\nrocker_dma_ring_destroy(rocker, &rocker->event_ring);\r\nrocker_dma_cmd_ring_waits_free(rocker);\r\nrocker_dma_ring_bufs_free(rocker, &rocker->cmd_ring,\r\nPCI_DMA_BIDIRECTIONAL);\r\nrocker_dma_ring_destroy(rocker, &rocker->cmd_ring);\r\n}\r\nstatic int rocker_dma_rx_ring_skb_map(const struct rocker_port *rocker_port,\r\nstruct rocker_desc_info *desc_info,\r\nstruct sk_buff *skb, size_t buf_len)\r\n{\r\nconst struct rocker *rocker = rocker_port->rocker;\r\nstruct pci_dev *pdev = rocker->pdev;\r\ndma_addr_t dma_handle;\r\ndma_handle = pci_map_single(pdev, skb->data, buf_len,\r\nPCI_DMA_FROMDEVICE);\r\nif (pci_dma_mapping_error(pdev, dma_handle))\r\nreturn -EIO;\r\nif (rocker_tlv_put_u64(desc_info, ROCKER_TLV_RX_FRAG_ADDR, dma_handle))\r\ngoto tlv_put_failure;\r\nif (rocker_tlv_put_u16(desc_info, ROCKER_TLV_RX_FRAG_MAX_LEN, buf_len))\r\ngoto tlv_put_failure;\r\nreturn 0;\r\ntlv_put_failure:\r\npci_unmap_single(pdev, dma_handle, buf_len, PCI_DMA_FROMDEVICE);\r\ndesc_info->tlv_size = 0;\r\nreturn -EMSGSIZE;\r\n}\r\nstatic size_t rocker_port_rx_buf_len(const struct rocker_port *rocker_port)\r\n{\r\nreturn rocker_port->dev->mtu + ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN;\r\n}\r\nstatic int rocker_dma_rx_ring_skb_alloc(const struct rocker_port *rocker_port,\r\nstruct rocker_desc_info *desc_info)\r\n{\r\nstruct net_device *dev = rocker_port->dev;\r\nstruct sk_buff *skb;\r\nsize_t buf_len = rocker_port_rx_buf_len(rocker_port);\r\nint err;\r\nrocker_desc_cookie_ptr_set(desc_info, NULL);\r\ndesc_info->tlv_size = 0;\r\nskb = netdev_alloc_skb_ip_align(dev, buf_len);\r\nif (!skb)\r\nreturn -ENOMEM;\r\nerr = rocker_dma_rx_ring_skb_map(rocker_port, desc_info, skb, buf_len);\r\nif (err) {\r\ndev_kfree_skb_any(skb);\r\nreturn err;\r\n}\r\nrocker_desc_cookie_ptr_set(desc_info, skb);\r\nreturn 0;\r\n}\r\nstatic void rocker_dma_rx_ring_skb_unmap(const struct rocker *rocker,\r\nconst struct rocker_tlv **attrs)\r\n{\r\nstruct pci_dev *pdev = rocker->pdev;\r\ndma_addr_t dma_handle;\r\nsize_t len;\r\nif (!attrs[ROCKER_TLV_RX_FRAG_ADDR] ||\r\n!attrs[ROCKER_TLV_RX_FRAG_MAX_LEN])\r\nreturn;\r\ndma_handle = rocker_tlv_get_u64(attrs[ROCKER_TLV_RX_FRAG_ADDR]);\r\nlen = rocker_tlv_get_u16(attrs[ROCKER_TLV_RX_FRAG_MAX_LEN]);\r\npci_unmap_single(pdev, dma_handle, len, PCI_DMA_FROMDEVICE);\r\n}\r\nstatic void rocker_dma_rx_ring_skb_free(const struct rocker *rocker,\r\nconst struct rocker_desc_info *desc_info)\r\n{\r\nconst struct rocker_tlv *attrs[ROCKER_TLV_RX_MAX + 1];\r\nstruct sk_buff *skb = rocker_desc_cookie_ptr_get(desc_info);\r\nif (!skb)\r\nreturn;\r\nrocker_tlv_parse_desc(attrs, ROCKER_TLV_RX_MAX, desc_info);\r\nrocker_dma_rx_ring_skb_unmap(rocker, attrs);\r\ndev_kfree_skb_any(skb);\r\n}\r\nstatic int rocker_dma_rx_ring_skbs_alloc(const struct rocker_port *rocker_port)\r\n{\r\nconst struct rocker_dma_ring_info *rx_ring = &rocker_port->rx_ring;\r\nconst struct rocker *rocker = rocker_port->rocker;\r\nint i;\r\nint err;\r\nfor (i = 0; i < rx_ring->size; i++) {\r\nerr = rocker_dma_rx_ring_skb_alloc(rocker_port,\r\n&rx_ring->desc_info[i]);\r\nif (err)\r\ngoto rollback;\r\n}\r\nreturn 0;\r\nrollback:\r\nfor (i--; i >= 0; i--)\r\nrocker_dma_rx_ring_skb_free(rocker, &rx_ring->desc_info[i]);\r\nreturn err;\r\n}\r\nstatic void rocker_dma_rx_ring_skbs_free(const struct rocker_port *rocker_port)\r\n{\r\nconst struct rocker_dma_ring_info *rx_ring = &rocker_port->rx_ring;\r\nconst struct rocker *rocker = rocker_port->rocker;\r\nint i;\r\nfor (i = 0; i < rx_ring->size; i++)\r\nrocker_dma_rx_ring_skb_free(rocker, &rx_ring->desc_info[i]);\r\n}\r\nstatic int rocker_port_dma_rings_init(struct rocker_port *rocker_port)\r\n{\r\nstruct rocker *rocker = rocker_port->rocker;\r\nint err;\r\nerr = rocker_dma_ring_create(rocker,\r\nROCKER_DMA_TX(rocker_port->port_number),\r\nROCKER_DMA_TX_DEFAULT_SIZE,\r\n&rocker_port->tx_ring);\r\nif (err) {\r\nnetdev_err(rocker_port->dev, "failed to create tx dma ring\n");\r\nreturn err;\r\n}\r\nerr = rocker_dma_ring_bufs_alloc(rocker, &rocker_port->tx_ring,\r\nPCI_DMA_TODEVICE,\r\nROCKER_DMA_TX_DESC_SIZE);\r\nif (err) {\r\nnetdev_err(rocker_port->dev, "failed to alloc tx dma ring buffers\n");\r\ngoto err_dma_tx_ring_bufs_alloc;\r\n}\r\nerr = rocker_dma_ring_create(rocker,\r\nROCKER_DMA_RX(rocker_port->port_number),\r\nROCKER_DMA_RX_DEFAULT_SIZE,\r\n&rocker_port->rx_ring);\r\nif (err) {\r\nnetdev_err(rocker_port->dev, "failed to create rx dma ring\n");\r\ngoto err_dma_rx_ring_create;\r\n}\r\nerr = rocker_dma_ring_bufs_alloc(rocker, &rocker_port->rx_ring,\r\nPCI_DMA_BIDIRECTIONAL,\r\nROCKER_DMA_RX_DESC_SIZE);\r\nif (err) {\r\nnetdev_err(rocker_port->dev, "failed to alloc rx dma ring buffers\n");\r\ngoto err_dma_rx_ring_bufs_alloc;\r\n}\r\nerr = rocker_dma_rx_ring_skbs_alloc(rocker_port);\r\nif (err) {\r\nnetdev_err(rocker_port->dev, "failed to alloc rx dma ring skbs\n");\r\ngoto err_dma_rx_ring_skbs_alloc;\r\n}\r\nrocker_dma_ring_pass_to_producer(rocker, &rocker_port->rx_ring);\r\nreturn 0;\r\nerr_dma_rx_ring_skbs_alloc:\r\nrocker_dma_ring_bufs_free(rocker, &rocker_port->rx_ring,\r\nPCI_DMA_BIDIRECTIONAL);\r\nerr_dma_rx_ring_bufs_alloc:\r\nrocker_dma_ring_destroy(rocker, &rocker_port->rx_ring);\r\nerr_dma_rx_ring_create:\r\nrocker_dma_ring_bufs_free(rocker, &rocker_port->tx_ring,\r\nPCI_DMA_TODEVICE);\r\nerr_dma_tx_ring_bufs_alloc:\r\nrocker_dma_ring_destroy(rocker, &rocker_port->tx_ring);\r\nreturn err;\r\n}\r\nstatic void rocker_port_dma_rings_fini(struct rocker_port *rocker_port)\r\n{\r\nstruct rocker *rocker = rocker_port->rocker;\r\nrocker_dma_rx_ring_skbs_free(rocker_port);\r\nrocker_dma_ring_bufs_free(rocker, &rocker_port->rx_ring,\r\nPCI_DMA_BIDIRECTIONAL);\r\nrocker_dma_ring_destroy(rocker, &rocker_port->rx_ring);\r\nrocker_dma_ring_bufs_free(rocker, &rocker_port->tx_ring,\r\nPCI_DMA_TODEVICE);\r\nrocker_dma_ring_destroy(rocker, &rocker_port->tx_ring);\r\n}\r\nstatic void rocker_port_set_enable(const struct rocker_port *rocker_port,\r\nbool enable)\r\n{\r\nu64 val = rocker_read64(rocker_port->rocker, PORT_PHYS_ENABLE);\r\nif (enable)\r\nval |= 1ULL << rocker_port->pport;\r\nelse\r\nval &= ~(1ULL << rocker_port->pport);\r\nrocker_write64(rocker_port->rocker, PORT_PHYS_ENABLE, val);\r\n}\r\nstatic irqreturn_t rocker_cmd_irq_handler(int irq, void *dev_id)\r\n{\r\nstruct rocker *rocker = dev_id;\r\nconst struct rocker_desc_info *desc_info;\r\nstruct rocker_wait *wait;\r\nu32 credits = 0;\r\nspin_lock(&rocker->cmd_ring_lock);\r\nwhile ((desc_info = rocker_desc_tail_get(&rocker->cmd_ring))) {\r\nwait = rocker_desc_cookie_ptr_get(desc_info);\r\nif (wait->nowait) {\r\nrocker_desc_gen_clear(desc_info);\r\n} else {\r\nrocker_wait_wake_up(wait);\r\n}\r\ncredits++;\r\n}\r\nspin_unlock(&rocker->cmd_ring_lock);\r\nrocker_dma_ring_credits_set(rocker, &rocker->cmd_ring, credits);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void rocker_port_link_up(const struct rocker_port *rocker_port)\r\n{\r\nnetif_carrier_on(rocker_port->dev);\r\nnetdev_info(rocker_port->dev, "Link is up\n");\r\n}\r\nstatic void rocker_port_link_down(const struct rocker_port *rocker_port)\r\n{\r\nnetif_carrier_off(rocker_port->dev);\r\nnetdev_info(rocker_port->dev, "Link is down\n");\r\n}\r\nstatic int rocker_event_link_change(const struct rocker *rocker,\r\nconst struct rocker_tlv *info)\r\n{\r\nconst struct rocker_tlv *attrs[ROCKER_TLV_EVENT_LINK_CHANGED_MAX + 1];\r\nunsigned int port_number;\r\nbool link_up;\r\nstruct rocker_port *rocker_port;\r\nrocker_tlv_parse_nested(attrs, ROCKER_TLV_EVENT_LINK_CHANGED_MAX, info);\r\nif (!attrs[ROCKER_TLV_EVENT_LINK_CHANGED_PPORT] ||\r\n!attrs[ROCKER_TLV_EVENT_LINK_CHANGED_LINKUP])\r\nreturn -EIO;\r\nport_number =\r\nrocker_tlv_get_u32(attrs[ROCKER_TLV_EVENT_LINK_CHANGED_PPORT]) - 1;\r\nlink_up = rocker_tlv_get_u8(attrs[ROCKER_TLV_EVENT_LINK_CHANGED_LINKUP]);\r\nif (port_number >= rocker->port_count)\r\nreturn -EINVAL;\r\nrocker_port = rocker->ports[port_number];\r\nif (netif_carrier_ok(rocker_port->dev) != link_up) {\r\nif (link_up)\r\nrocker_port_link_up(rocker_port);\r\nelse\r\nrocker_port_link_down(rocker_port);\r\n}\r\nreturn 0;\r\n}\r\nstatic int rocker_event_mac_vlan_seen(const struct rocker *rocker,\r\nconst struct rocker_tlv *info)\r\n{\r\nconst struct rocker_tlv *attrs[ROCKER_TLV_EVENT_MAC_VLAN_MAX + 1];\r\nunsigned int port_number;\r\nstruct rocker_port *rocker_port;\r\nconst unsigned char *addr;\r\n__be16 vlan_id;\r\nrocker_tlv_parse_nested(attrs, ROCKER_TLV_EVENT_MAC_VLAN_MAX, info);\r\nif (!attrs[ROCKER_TLV_EVENT_MAC_VLAN_PPORT] ||\r\n!attrs[ROCKER_TLV_EVENT_MAC_VLAN_MAC] ||\r\n!attrs[ROCKER_TLV_EVENT_MAC_VLAN_VLAN_ID])\r\nreturn -EIO;\r\nport_number =\r\nrocker_tlv_get_u32(attrs[ROCKER_TLV_EVENT_MAC_VLAN_PPORT]) - 1;\r\naddr = rocker_tlv_data(attrs[ROCKER_TLV_EVENT_MAC_VLAN_MAC]);\r\nvlan_id = rocker_tlv_get_be16(attrs[ROCKER_TLV_EVENT_MAC_VLAN_VLAN_ID]);\r\nif (port_number >= rocker->port_count)\r\nreturn -EINVAL;\r\nrocker_port = rocker->ports[port_number];\r\nreturn rocker_world_port_ev_mac_vlan_seen(rocker_port, addr, vlan_id);\r\n}\r\nstatic int rocker_event_process(const struct rocker *rocker,\r\nconst struct rocker_desc_info *desc_info)\r\n{\r\nconst struct rocker_tlv *attrs[ROCKER_TLV_EVENT_MAX + 1];\r\nconst struct rocker_tlv *info;\r\nu16 type;\r\nrocker_tlv_parse_desc(attrs, ROCKER_TLV_EVENT_MAX, desc_info);\r\nif (!attrs[ROCKER_TLV_EVENT_TYPE] ||\r\n!attrs[ROCKER_TLV_EVENT_INFO])\r\nreturn -EIO;\r\ntype = rocker_tlv_get_u16(attrs[ROCKER_TLV_EVENT_TYPE]);\r\ninfo = attrs[ROCKER_TLV_EVENT_INFO];\r\nswitch (type) {\r\ncase ROCKER_TLV_EVENT_TYPE_LINK_CHANGED:\r\nreturn rocker_event_link_change(rocker, info);\r\ncase ROCKER_TLV_EVENT_TYPE_MAC_VLAN_SEEN:\r\nreturn rocker_event_mac_vlan_seen(rocker, info);\r\n}\r\nreturn -EOPNOTSUPP;\r\n}\r\nstatic irqreturn_t rocker_event_irq_handler(int irq, void *dev_id)\r\n{\r\nstruct rocker *rocker = dev_id;\r\nconst struct pci_dev *pdev = rocker->pdev;\r\nconst struct rocker_desc_info *desc_info;\r\nu32 credits = 0;\r\nint err;\r\nwhile ((desc_info = rocker_desc_tail_get(&rocker->event_ring))) {\r\nerr = rocker_desc_err(desc_info);\r\nif (err) {\r\ndev_err(&pdev->dev, "event desc received with err %d\n",\r\nerr);\r\n} else {\r\nerr = rocker_event_process(rocker, desc_info);\r\nif (err)\r\ndev_err(&pdev->dev, "event processing failed with err %d\n",\r\nerr);\r\n}\r\nrocker_desc_gen_clear(desc_info);\r\nrocker_desc_head_set(rocker, &rocker->event_ring, desc_info);\r\ncredits++;\r\n}\r\nrocker_dma_ring_credits_set(rocker, &rocker->event_ring, credits);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t rocker_tx_irq_handler(int irq, void *dev_id)\r\n{\r\nstruct rocker_port *rocker_port = dev_id;\r\nnapi_schedule(&rocker_port->napi_tx);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t rocker_rx_irq_handler(int irq, void *dev_id)\r\n{\r\nstruct rocker_port *rocker_port = dev_id;\r\nnapi_schedule(&rocker_port->napi_rx);\r\nreturn IRQ_HANDLED;\r\n}\r\nint rocker_cmd_exec(struct rocker_port *rocker_port, bool nowait,\r\nrocker_cmd_prep_cb_t prepare, void *prepare_priv,\r\nrocker_cmd_proc_cb_t process, void *process_priv)\r\n{\r\nstruct rocker *rocker = rocker_port->rocker;\r\nstruct rocker_desc_info *desc_info;\r\nstruct rocker_wait *wait;\r\nunsigned long lock_flags;\r\nint err;\r\nspin_lock_irqsave(&rocker->cmd_ring_lock, lock_flags);\r\ndesc_info = rocker_desc_head_get(&rocker->cmd_ring);\r\nif (!desc_info) {\r\nspin_unlock_irqrestore(&rocker->cmd_ring_lock, lock_flags);\r\nreturn -EAGAIN;\r\n}\r\nwait = rocker_desc_cookie_ptr_get(desc_info);\r\nrocker_wait_init(wait);\r\nwait->nowait = nowait;\r\nerr = prepare(rocker_port, desc_info, prepare_priv);\r\nif (err) {\r\nspin_unlock_irqrestore(&rocker->cmd_ring_lock, lock_flags);\r\nreturn err;\r\n}\r\nrocker_desc_head_set(rocker, &rocker->cmd_ring, desc_info);\r\nspin_unlock_irqrestore(&rocker->cmd_ring_lock, lock_flags);\r\nif (nowait)\r\nreturn 0;\r\nif (!rocker_wait_event_timeout(wait, HZ / 10))\r\nreturn -EIO;\r\nerr = rocker_desc_err(desc_info);\r\nif (err)\r\nreturn err;\r\nif (process)\r\nerr = process(rocker_port, desc_info, process_priv);\r\nrocker_desc_gen_clear(desc_info);\r\nreturn err;\r\n}\r\nstatic int\r\nrocker_cmd_get_port_settings_prep(const struct rocker_port *rocker_port,\r\nstruct rocker_desc_info *desc_info,\r\nvoid *priv)\r\n{\r\nstruct rocker_tlv *cmd_info;\r\nif (rocker_tlv_put_u16(desc_info, ROCKER_TLV_CMD_TYPE,\r\nROCKER_TLV_CMD_TYPE_GET_PORT_SETTINGS))\r\nreturn -EMSGSIZE;\r\ncmd_info = rocker_tlv_nest_start(desc_info, ROCKER_TLV_CMD_INFO);\r\nif (!cmd_info)\r\nreturn -EMSGSIZE;\r\nif (rocker_tlv_put_u32(desc_info, ROCKER_TLV_CMD_PORT_SETTINGS_PPORT,\r\nrocker_port->pport))\r\nreturn -EMSGSIZE;\r\nrocker_tlv_nest_end(desc_info, cmd_info);\r\nreturn 0;\r\n}\r\nstatic int\r\nrocker_cmd_get_port_settings_ethtool_proc(const struct rocker_port *rocker_port,\r\nconst struct rocker_desc_info *desc_info,\r\nvoid *priv)\r\n{\r\nstruct ethtool_cmd *ecmd = priv;\r\nconst struct rocker_tlv *attrs[ROCKER_TLV_CMD_MAX + 1];\r\nconst struct rocker_tlv *info_attrs[ROCKER_TLV_CMD_PORT_SETTINGS_MAX + 1];\r\nu32 speed;\r\nu8 duplex;\r\nu8 autoneg;\r\nrocker_tlv_parse_desc(attrs, ROCKER_TLV_CMD_MAX, desc_info);\r\nif (!attrs[ROCKER_TLV_CMD_INFO])\r\nreturn -EIO;\r\nrocker_tlv_parse_nested(info_attrs, ROCKER_TLV_CMD_PORT_SETTINGS_MAX,\r\nattrs[ROCKER_TLV_CMD_INFO]);\r\nif (!info_attrs[ROCKER_TLV_CMD_PORT_SETTINGS_SPEED] ||\r\n!info_attrs[ROCKER_TLV_CMD_PORT_SETTINGS_DUPLEX] ||\r\n!info_attrs[ROCKER_TLV_CMD_PORT_SETTINGS_AUTONEG])\r\nreturn -EIO;\r\nspeed = rocker_tlv_get_u32(info_attrs[ROCKER_TLV_CMD_PORT_SETTINGS_SPEED]);\r\nduplex = rocker_tlv_get_u8(info_attrs[ROCKER_TLV_CMD_PORT_SETTINGS_DUPLEX]);\r\nautoneg = rocker_tlv_get_u8(info_attrs[ROCKER_TLV_CMD_PORT_SETTINGS_AUTONEG]);\r\necmd->transceiver = XCVR_INTERNAL;\r\necmd->supported = SUPPORTED_TP;\r\necmd->phy_address = 0xff;\r\necmd->port = PORT_TP;\r\nethtool_cmd_speed_set(ecmd, speed);\r\necmd->duplex = duplex ? DUPLEX_FULL : DUPLEX_HALF;\r\necmd->autoneg = autoneg ? AUTONEG_ENABLE : AUTONEG_DISABLE;\r\nreturn 0;\r\n}\r\nstatic int\r\nrocker_cmd_get_port_settings_macaddr_proc(const struct rocker_port *rocker_port,\r\nconst struct rocker_desc_info *desc_info,\r\nvoid *priv)\r\n{\r\nunsigned char *macaddr = priv;\r\nconst struct rocker_tlv *attrs[ROCKER_TLV_CMD_MAX + 1];\r\nconst struct rocker_tlv *info_attrs[ROCKER_TLV_CMD_PORT_SETTINGS_MAX + 1];\r\nconst struct rocker_tlv *attr;\r\nrocker_tlv_parse_desc(attrs, ROCKER_TLV_CMD_MAX, desc_info);\r\nif (!attrs[ROCKER_TLV_CMD_INFO])\r\nreturn -EIO;\r\nrocker_tlv_parse_nested(info_attrs, ROCKER_TLV_CMD_PORT_SETTINGS_MAX,\r\nattrs[ROCKER_TLV_CMD_INFO]);\r\nattr = info_attrs[ROCKER_TLV_CMD_PORT_SETTINGS_MACADDR];\r\nif (!attr)\r\nreturn -EIO;\r\nif (rocker_tlv_len(attr) != ETH_ALEN)\r\nreturn -EINVAL;\r\nether_addr_copy(macaddr, rocker_tlv_data(attr));\r\nreturn 0;\r\n}\r\nstatic int\r\nrocker_cmd_get_port_settings_mode_proc(const struct rocker_port *rocker_port,\r\nconst struct rocker_desc_info *desc_info,\r\nvoid *priv)\r\n{\r\nu8 *p_mode = priv;\r\nconst struct rocker_tlv *attrs[ROCKER_TLV_CMD_MAX + 1];\r\nconst struct rocker_tlv *info_attrs[ROCKER_TLV_CMD_PORT_SETTINGS_MAX + 1];\r\nconst struct rocker_tlv *attr;\r\nrocker_tlv_parse_desc(attrs, ROCKER_TLV_CMD_MAX, desc_info);\r\nif (!attrs[ROCKER_TLV_CMD_INFO])\r\nreturn -EIO;\r\nrocker_tlv_parse_nested(info_attrs, ROCKER_TLV_CMD_PORT_SETTINGS_MAX,\r\nattrs[ROCKER_TLV_CMD_INFO]);\r\nattr = info_attrs[ROCKER_TLV_CMD_PORT_SETTINGS_MODE];\r\nif (!attr)\r\nreturn -EIO;\r\n*p_mode = rocker_tlv_get_u8(info_attrs[ROCKER_TLV_CMD_PORT_SETTINGS_MODE]);\r\nreturn 0;\r\n}\r\nstatic int\r\nrocker_cmd_get_port_settings_phys_name_proc(const struct rocker_port *rocker_port,\r\nconst struct rocker_desc_info *desc_info,\r\nvoid *priv)\r\n{\r\nconst struct rocker_tlv *info_attrs[ROCKER_TLV_CMD_PORT_SETTINGS_MAX + 1];\r\nconst struct rocker_tlv *attrs[ROCKER_TLV_CMD_MAX + 1];\r\nstruct port_name *name = priv;\r\nconst struct rocker_tlv *attr;\r\nsize_t i, j, len;\r\nconst char *str;\r\nrocker_tlv_parse_desc(attrs, ROCKER_TLV_CMD_MAX, desc_info);\r\nif (!attrs[ROCKER_TLV_CMD_INFO])\r\nreturn -EIO;\r\nrocker_tlv_parse_nested(info_attrs, ROCKER_TLV_CMD_PORT_SETTINGS_MAX,\r\nattrs[ROCKER_TLV_CMD_INFO]);\r\nattr = info_attrs[ROCKER_TLV_CMD_PORT_SETTINGS_PHYS_NAME];\r\nif (!attr)\r\nreturn -EIO;\r\nlen = min_t(size_t, rocker_tlv_len(attr), name->len);\r\nstr = rocker_tlv_data(attr);\r\nfor (i = j = 0; i < len; ++i) {\r\nif (isalnum(str[i])) {\r\nname->buf[j] = str[i];\r\nj++;\r\n}\r\n}\r\nif (j == 0)\r\nreturn -EIO;\r\nname->buf[j] = '\0';\r\nreturn 0;\r\n}\r\nstatic int\r\nrocker_cmd_set_port_settings_ethtool_prep(const struct rocker_port *rocker_port,\r\nstruct rocker_desc_info *desc_info,\r\nvoid *priv)\r\n{\r\nstruct ethtool_cmd *ecmd = priv;\r\nstruct rocker_tlv *cmd_info;\r\nif (rocker_tlv_put_u16(desc_info, ROCKER_TLV_CMD_TYPE,\r\nROCKER_TLV_CMD_TYPE_SET_PORT_SETTINGS))\r\nreturn -EMSGSIZE;\r\ncmd_info = rocker_tlv_nest_start(desc_info, ROCKER_TLV_CMD_INFO);\r\nif (!cmd_info)\r\nreturn -EMSGSIZE;\r\nif (rocker_tlv_put_u32(desc_info, ROCKER_TLV_CMD_PORT_SETTINGS_PPORT,\r\nrocker_port->pport))\r\nreturn -EMSGSIZE;\r\nif (rocker_tlv_put_u32(desc_info, ROCKER_TLV_CMD_PORT_SETTINGS_SPEED,\r\nethtool_cmd_speed(ecmd)))\r\nreturn -EMSGSIZE;\r\nif (rocker_tlv_put_u8(desc_info, ROCKER_TLV_CMD_PORT_SETTINGS_DUPLEX,\r\necmd->duplex))\r\nreturn -EMSGSIZE;\r\nif (rocker_tlv_put_u8(desc_info, ROCKER_TLV_CMD_PORT_SETTINGS_AUTONEG,\r\necmd->autoneg))\r\nreturn -EMSGSIZE;\r\nrocker_tlv_nest_end(desc_info, cmd_info);\r\nreturn 0;\r\n}\r\nstatic int\r\nrocker_cmd_set_port_settings_macaddr_prep(const struct rocker_port *rocker_port,\r\nstruct rocker_desc_info *desc_info,\r\nvoid *priv)\r\n{\r\nconst unsigned char *macaddr = priv;\r\nstruct rocker_tlv *cmd_info;\r\nif (rocker_tlv_put_u16(desc_info, ROCKER_TLV_CMD_TYPE,\r\nROCKER_TLV_CMD_TYPE_SET_PORT_SETTINGS))\r\nreturn -EMSGSIZE;\r\ncmd_info = rocker_tlv_nest_start(desc_info, ROCKER_TLV_CMD_INFO);\r\nif (!cmd_info)\r\nreturn -EMSGSIZE;\r\nif (rocker_tlv_put_u32(desc_info, ROCKER_TLV_CMD_PORT_SETTINGS_PPORT,\r\nrocker_port->pport))\r\nreturn -EMSGSIZE;\r\nif (rocker_tlv_put(desc_info, ROCKER_TLV_CMD_PORT_SETTINGS_MACADDR,\r\nETH_ALEN, macaddr))\r\nreturn -EMSGSIZE;\r\nrocker_tlv_nest_end(desc_info, cmd_info);\r\nreturn 0;\r\n}\r\nstatic int\r\nrocker_cmd_set_port_settings_mtu_prep(const struct rocker_port *rocker_port,\r\nstruct rocker_desc_info *desc_info,\r\nvoid *priv)\r\n{\r\nint mtu = *(int *)priv;\r\nstruct rocker_tlv *cmd_info;\r\nif (rocker_tlv_put_u16(desc_info, ROCKER_TLV_CMD_TYPE,\r\nROCKER_TLV_CMD_TYPE_SET_PORT_SETTINGS))\r\nreturn -EMSGSIZE;\r\ncmd_info = rocker_tlv_nest_start(desc_info, ROCKER_TLV_CMD_INFO);\r\nif (!cmd_info)\r\nreturn -EMSGSIZE;\r\nif (rocker_tlv_put_u32(desc_info, ROCKER_TLV_CMD_PORT_SETTINGS_PPORT,\r\nrocker_port->pport))\r\nreturn -EMSGSIZE;\r\nif (rocker_tlv_put_u16(desc_info, ROCKER_TLV_CMD_PORT_SETTINGS_MTU,\r\nmtu))\r\nreturn -EMSGSIZE;\r\nrocker_tlv_nest_end(desc_info, cmd_info);\r\nreturn 0;\r\n}\r\nstatic int\r\nrocker_cmd_set_port_learning_prep(const struct rocker_port *rocker_port,\r\nstruct rocker_desc_info *desc_info,\r\nvoid *priv)\r\n{\r\nbool learning = *(bool *)priv;\r\nstruct rocker_tlv *cmd_info;\r\nif (rocker_tlv_put_u16(desc_info, ROCKER_TLV_CMD_TYPE,\r\nROCKER_TLV_CMD_TYPE_SET_PORT_SETTINGS))\r\nreturn -EMSGSIZE;\r\ncmd_info = rocker_tlv_nest_start(desc_info, ROCKER_TLV_CMD_INFO);\r\nif (!cmd_info)\r\nreturn -EMSGSIZE;\r\nif (rocker_tlv_put_u32(desc_info, ROCKER_TLV_CMD_PORT_SETTINGS_PPORT,\r\nrocker_port->pport))\r\nreturn -EMSGSIZE;\r\nif (rocker_tlv_put_u8(desc_info, ROCKER_TLV_CMD_PORT_SETTINGS_LEARNING,\r\nlearning))\r\nreturn -EMSGSIZE;\r\nrocker_tlv_nest_end(desc_info, cmd_info);\r\nreturn 0;\r\n}\r\nstatic int rocker_cmd_get_port_settings_ethtool(struct rocker_port *rocker_port,\r\nstruct ethtool_cmd *ecmd)\r\n{\r\nreturn rocker_cmd_exec(rocker_port, false,\r\nrocker_cmd_get_port_settings_prep, NULL,\r\nrocker_cmd_get_port_settings_ethtool_proc,\r\necmd);\r\n}\r\nstatic int rocker_cmd_get_port_settings_macaddr(struct rocker_port *rocker_port,\r\nunsigned char *macaddr)\r\n{\r\nreturn rocker_cmd_exec(rocker_port, false,\r\nrocker_cmd_get_port_settings_prep, NULL,\r\nrocker_cmd_get_port_settings_macaddr_proc,\r\nmacaddr);\r\n}\r\nstatic int rocker_cmd_get_port_settings_mode(struct rocker_port *rocker_port,\r\nu8 *p_mode)\r\n{\r\nreturn rocker_cmd_exec(rocker_port, false,\r\nrocker_cmd_get_port_settings_prep, NULL,\r\nrocker_cmd_get_port_settings_mode_proc, p_mode);\r\n}\r\nstatic int rocker_cmd_set_port_settings_ethtool(struct rocker_port *rocker_port,\r\nstruct ethtool_cmd *ecmd)\r\n{\r\nreturn rocker_cmd_exec(rocker_port, false,\r\nrocker_cmd_set_port_settings_ethtool_prep,\r\necmd, NULL, NULL);\r\n}\r\nstatic int rocker_cmd_set_port_settings_macaddr(struct rocker_port *rocker_port,\r\nunsigned char *macaddr)\r\n{\r\nreturn rocker_cmd_exec(rocker_port, false,\r\nrocker_cmd_set_port_settings_macaddr_prep,\r\nmacaddr, NULL, NULL);\r\n}\r\nstatic int rocker_cmd_set_port_settings_mtu(struct rocker_port *rocker_port,\r\nint mtu)\r\n{\r\nreturn rocker_cmd_exec(rocker_port, false,\r\nrocker_cmd_set_port_settings_mtu_prep,\r\n&mtu, NULL, NULL);\r\n}\r\nint rocker_port_set_learning(struct rocker_port *rocker_port,\r\nbool learning)\r\n{\r\nreturn rocker_cmd_exec(rocker_port, false,\r\nrocker_cmd_set_port_learning_prep,\r\n&learning, NULL, NULL);\r\n}\r\nstatic struct rocker_world_ops *rocker_world_ops_find(u8 mode)\r\n{\r\nint i;\r\nfor (i = 0; i < ROCKER_WORLD_OPS_LEN; i++)\r\nif (rocker_world_ops[i]->mode == mode)\r\nreturn rocker_world_ops[i];\r\nreturn NULL;\r\n}\r\nstatic int rocker_world_init(struct rocker *rocker, u8 mode)\r\n{\r\nstruct rocker_world_ops *wops;\r\nint err;\r\nwops = rocker_world_ops_find(mode);\r\nif (!wops) {\r\ndev_err(&rocker->pdev->dev, "port mode \"%d\" is not supported\n",\r\nmode);\r\nreturn -EINVAL;\r\n}\r\nrocker->wops = wops;\r\nrocker->wpriv = kzalloc(wops->priv_size, GFP_KERNEL);\r\nif (!rocker->wpriv)\r\nreturn -ENOMEM;\r\nif (!wops->init)\r\nreturn 0;\r\nerr = wops->init(rocker);\r\nif (err)\r\nkfree(rocker->wpriv);\r\nreturn err;\r\n}\r\nstatic void rocker_world_fini(struct rocker *rocker)\r\n{\r\nstruct rocker_world_ops *wops = rocker->wops;\r\nif (!wops || !wops->fini)\r\nreturn;\r\nwops->fini(rocker);\r\nkfree(rocker->wpriv);\r\n}\r\nstatic int rocker_world_check_init(struct rocker_port *rocker_port)\r\n{\r\nstruct rocker *rocker = rocker_port->rocker;\r\nu8 mode;\r\nint err;\r\nerr = rocker_cmd_get_port_settings_mode(rocker_port, &mode);\r\nif (err) {\r\ndev_err(&rocker->pdev->dev, "failed to get port mode\n");\r\nreturn err;\r\n}\r\nif (rocker->wops) {\r\nif (rocker->wops->mode != mode) {\r\ndev_err(&rocker->pdev->dev, "hardware has ports in different worlds, which is not supported\n");\r\nreturn err;\r\n}\r\nreturn 0;\r\n}\r\nreturn rocker_world_init(rocker, mode);\r\n}\r\nstatic int rocker_world_port_pre_init(struct rocker_port *rocker_port)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nint err;\r\nrocker_port->wpriv = kzalloc(wops->port_priv_size, GFP_KERNEL);\r\nif (!rocker_port->wpriv)\r\nreturn -ENOMEM;\r\nif (!wops->port_pre_init)\r\nreturn 0;\r\nerr = wops->port_pre_init(rocker_port);\r\nif (err)\r\nkfree(rocker_port->wpriv);\r\nreturn 0;\r\n}\r\nstatic int rocker_world_port_init(struct rocker_port *rocker_port)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_init)\r\nreturn 0;\r\nreturn wops->port_init(rocker_port);\r\n}\r\nstatic void rocker_world_port_fini(struct rocker_port *rocker_port)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_fini)\r\nreturn;\r\nwops->port_fini(rocker_port);\r\n}\r\nstatic void rocker_world_port_post_fini(struct rocker_port *rocker_port)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_post_fini)\r\nreturn;\r\nwops->port_post_fini(rocker_port);\r\nkfree(rocker_port->wpriv);\r\n}\r\nstatic int rocker_world_port_open(struct rocker_port *rocker_port)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_open)\r\nreturn 0;\r\nreturn wops->port_open(rocker_port);\r\n}\r\nstatic void rocker_world_port_stop(struct rocker_port *rocker_port)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_stop)\r\nreturn;\r\nwops->port_stop(rocker_port);\r\n}\r\nstatic int rocker_world_port_attr_stp_state_set(struct rocker_port *rocker_port,\r\nu8 state,\r\nstruct switchdev_trans *trans)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_attr_stp_state_set)\r\nreturn -EOPNOTSUPP;\r\nreturn wops->port_attr_stp_state_set(rocker_port, state, trans);\r\n}\r\nstatic int\r\nrocker_world_port_attr_bridge_flags_set(struct rocker_port *rocker_port,\r\nunsigned long brport_flags,\r\nstruct switchdev_trans *trans)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_attr_bridge_flags_set)\r\nreturn -EOPNOTSUPP;\r\nreturn wops->port_attr_bridge_flags_set(rocker_port, brport_flags,\r\ntrans);\r\n}\r\nstatic int\r\nrocker_world_port_attr_bridge_flags_get(const struct rocker_port *rocker_port,\r\nunsigned long *p_brport_flags)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_attr_bridge_flags_get)\r\nreturn -EOPNOTSUPP;\r\nreturn wops->port_attr_bridge_flags_get(rocker_port, p_brport_flags);\r\n}\r\nstatic int\r\nrocker_world_port_attr_bridge_ageing_time_set(struct rocker_port *rocker_port,\r\nu32 ageing_time,\r\nstruct switchdev_trans *trans)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_attr_bridge_ageing_time_set)\r\nreturn -EOPNOTSUPP;\r\nreturn wops->port_attr_bridge_ageing_time_set(rocker_port, ageing_time,\r\ntrans);\r\n}\r\nstatic int\r\nrocker_world_port_obj_vlan_add(struct rocker_port *rocker_port,\r\nconst struct switchdev_obj_port_vlan *vlan,\r\nstruct switchdev_trans *trans)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_obj_vlan_add)\r\nreturn -EOPNOTSUPP;\r\nreturn wops->port_obj_vlan_add(rocker_port, vlan, trans);\r\n}\r\nstatic int\r\nrocker_world_port_obj_vlan_del(struct rocker_port *rocker_port,\r\nconst struct switchdev_obj_port_vlan *vlan)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_obj_vlan_del)\r\nreturn -EOPNOTSUPP;\r\nreturn wops->port_obj_vlan_del(rocker_port, vlan);\r\n}\r\nstatic int\r\nrocker_world_port_obj_vlan_dump(const struct rocker_port *rocker_port,\r\nstruct switchdev_obj_port_vlan *vlan,\r\nswitchdev_obj_dump_cb_t *cb)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_obj_vlan_dump)\r\nreturn -EOPNOTSUPP;\r\nreturn wops->port_obj_vlan_dump(rocker_port, vlan, cb);\r\n}\r\nstatic int\r\nrocker_world_port_obj_fib4_add(struct rocker_port *rocker_port,\r\nconst struct switchdev_obj_ipv4_fib *fib4,\r\nstruct switchdev_trans *trans)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_obj_fib4_add)\r\nreturn -EOPNOTSUPP;\r\nreturn wops->port_obj_fib4_add(rocker_port, fib4, trans);\r\n}\r\nstatic int\r\nrocker_world_port_obj_fib4_del(struct rocker_port *rocker_port,\r\nconst struct switchdev_obj_ipv4_fib *fib4)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_obj_fib4_del)\r\nreturn -EOPNOTSUPP;\r\nreturn wops->port_obj_fib4_del(rocker_port, fib4);\r\n}\r\nstatic int\r\nrocker_world_port_obj_fdb_add(struct rocker_port *rocker_port,\r\nconst struct switchdev_obj_port_fdb *fdb,\r\nstruct switchdev_trans *trans)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_obj_fdb_add)\r\nreturn -EOPNOTSUPP;\r\nreturn wops->port_obj_fdb_add(rocker_port, fdb, trans);\r\n}\r\nstatic int\r\nrocker_world_port_obj_fdb_del(struct rocker_port *rocker_port,\r\nconst struct switchdev_obj_port_fdb *fdb)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_obj_fdb_del)\r\nreturn -EOPNOTSUPP;\r\nreturn wops->port_obj_fdb_del(rocker_port, fdb);\r\n}\r\nstatic int\r\nrocker_world_port_obj_fdb_dump(const struct rocker_port *rocker_port,\r\nstruct switchdev_obj_port_fdb *fdb,\r\nswitchdev_obj_dump_cb_t *cb)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_obj_fdb_dump)\r\nreturn -EOPNOTSUPP;\r\nreturn wops->port_obj_fdb_dump(rocker_port, fdb, cb);\r\n}\r\nstatic int rocker_world_port_master_linked(struct rocker_port *rocker_port,\r\nstruct net_device *master)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_master_linked)\r\nreturn -EOPNOTSUPP;\r\nreturn wops->port_master_linked(rocker_port, master);\r\n}\r\nstatic int rocker_world_port_master_unlinked(struct rocker_port *rocker_port,\r\nstruct net_device *master)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_master_unlinked)\r\nreturn -EOPNOTSUPP;\r\nreturn wops->port_master_unlinked(rocker_port, master);\r\n}\r\nstatic int rocker_world_port_neigh_update(struct rocker_port *rocker_port,\r\nstruct neighbour *n)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_neigh_update)\r\nreturn -EOPNOTSUPP;\r\nreturn wops->port_neigh_update(rocker_port, n);\r\n}\r\nstatic int rocker_world_port_neigh_destroy(struct rocker_port *rocker_port,\r\nstruct neighbour *n)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_neigh_destroy)\r\nreturn -EOPNOTSUPP;\r\nreturn wops->port_neigh_destroy(rocker_port, n);\r\n}\r\nstatic int rocker_world_port_ev_mac_vlan_seen(struct rocker_port *rocker_port,\r\nconst unsigned char *addr,\r\n__be16 vlan_id)\r\n{\r\nstruct rocker_world_ops *wops = rocker_port->rocker->wops;\r\nif (!wops->port_ev_mac_vlan_seen)\r\nreturn -EOPNOTSUPP;\r\nreturn wops->port_ev_mac_vlan_seen(rocker_port, addr, vlan_id);\r\n}\r\nstatic int rocker_port_open(struct net_device *dev)\r\n{\r\nstruct rocker_port *rocker_port = netdev_priv(dev);\r\nint err;\r\nerr = rocker_port_dma_rings_init(rocker_port);\r\nif (err)\r\nreturn err;\r\nerr = request_irq(rocker_msix_tx_vector(rocker_port),\r\nrocker_tx_irq_handler, 0,\r\nrocker_driver_name, rocker_port);\r\nif (err) {\r\nnetdev_err(rocker_port->dev, "cannot assign tx irq\n");\r\ngoto err_request_tx_irq;\r\n}\r\nerr = request_irq(rocker_msix_rx_vector(rocker_port),\r\nrocker_rx_irq_handler, 0,\r\nrocker_driver_name, rocker_port);\r\nif (err) {\r\nnetdev_err(rocker_port->dev, "cannot assign rx irq\n");\r\ngoto err_request_rx_irq;\r\n}\r\nerr = rocker_world_port_open(rocker_port);\r\nif (err) {\r\nnetdev_err(rocker_port->dev, "cannot open port in world\n");\r\ngoto err_world_port_open;\r\n}\r\nnapi_enable(&rocker_port->napi_tx);\r\nnapi_enable(&rocker_port->napi_rx);\r\nif (!dev->proto_down)\r\nrocker_port_set_enable(rocker_port, true);\r\nnetif_start_queue(dev);\r\nreturn 0;\r\nerr_world_port_open:\r\nfree_irq(rocker_msix_rx_vector(rocker_port), rocker_port);\r\nerr_request_rx_irq:\r\nfree_irq(rocker_msix_tx_vector(rocker_port), rocker_port);\r\nerr_request_tx_irq:\r\nrocker_port_dma_rings_fini(rocker_port);\r\nreturn err;\r\n}\r\nstatic int rocker_port_stop(struct net_device *dev)\r\n{\r\nstruct rocker_port *rocker_port = netdev_priv(dev);\r\nnetif_stop_queue(dev);\r\nrocker_port_set_enable(rocker_port, false);\r\nnapi_disable(&rocker_port->napi_rx);\r\nnapi_disable(&rocker_port->napi_tx);\r\nrocker_world_port_stop(rocker_port);\r\nfree_irq(rocker_msix_rx_vector(rocker_port), rocker_port);\r\nfree_irq(rocker_msix_tx_vector(rocker_port), rocker_port);\r\nrocker_port_dma_rings_fini(rocker_port);\r\nreturn 0;\r\n}\r\nstatic void rocker_tx_desc_frags_unmap(const struct rocker_port *rocker_port,\r\nconst struct rocker_desc_info *desc_info)\r\n{\r\nconst struct rocker *rocker = rocker_port->rocker;\r\nstruct pci_dev *pdev = rocker->pdev;\r\nconst struct rocker_tlv *attrs[ROCKER_TLV_TX_MAX + 1];\r\nstruct rocker_tlv *attr;\r\nint rem;\r\nrocker_tlv_parse_desc(attrs, ROCKER_TLV_TX_MAX, desc_info);\r\nif (!attrs[ROCKER_TLV_TX_FRAGS])\r\nreturn;\r\nrocker_tlv_for_each_nested(attr, attrs[ROCKER_TLV_TX_FRAGS], rem) {\r\nconst struct rocker_tlv *frag_attrs[ROCKER_TLV_TX_FRAG_ATTR_MAX + 1];\r\ndma_addr_t dma_handle;\r\nsize_t len;\r\nif (rocker_tlv_type(attr) != ROCKER_TLV_TX_FRAG)\r\ncontinue;\r\nrocker_tlv_parse_nested(frag_attrs, ROCKER_TLV_TX_FRAG_ATTR_MAX,\r\nattr);\r\nif (!frag_attrs[ROCKER_TLV_TX_FRAG_ATTR_ADDR] ||\r\n!frag_attrs[ROCKER_TLV_TX_FRAG_ATTR_LEN])\r\ncontinue;\r\ndma_handle = rocker_tlv_get_u64(frag_attrs[ROCKER_TLV_TX_FRAG_ATTR_ADDR]);\r\nlen = rocker_tlv_get_u16(frag_attrs[ROCKER_TLV_TX_FRAG_ATTR_LEN]);\r\npci_unmap_single(pdev, dma_handle, len, DMA_TO_DEVICE);\r\n}\r\n}\r\nstatic int rocker_tx_desc_frag_map_put(const struct rocker_port *rocker_port,\r\nstruct rocker_desc_info *desc_info,\r\nchar *buf, size_t buf_len)\r\n{\r\nconst struct rocker *rocker = rocker_port->rocker;\r\nstruct pci_dev *pdev = rocker->pdev;\r\ndma_addr_t dma_handle;\r\nstruct rocker_tlv *frag;\r\ndma_handle = pci_map_single(pdev, buf, buf_len, DMA_TO_DEVICE);\r\nif (unlikely(pci_dma_mapping_error(pdev, dma_handle))) {\r\nif (net_ratelimit())\r\nnetdev_err(rocker_port->dev, "failed to dma map tx frag\n");\r\nreturn -EIO;\r\n}\r\nfrag = rocker_tlv_nest_start(desc_info, ROCKER_TLV_TX_FRAG);\r\nif (!frag)\r\ngoto unmap_frag;\r\nif (rocker_tlv_put_u64(desc_info, ROCKER_TLV_TX_FRAG_ATTR_ADDR,\r\ndma_handle))\r\ngoto nest_cancel;\r\nif (rocker_tlv_put_u16(desc_info, ROCKER_TLV_TX_FRAG_ATTR_LEN,\r\nbuf_len))\r\ngoto nest_cancel;\r\nrocker_tlv_nest_end(desc_info, frag);\r\nreturn 0;\r\nnest_cancel:\r\nrocker_tlv_nest_cancel(desc_info, frag);\r\nunmap_frag:\r\npci_unmap_single(pdev, dma_handle, buf_len, DMA_TO_DEVICE);\r\nreturn -EMSGSIZE;\r\n}\r\nstatic netdev_tx_t rocker_port_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct rocker_port *rocker_port = netdev_priv(dev);\r\nstruct rocker *rocker = rocker_port->rocker;\r\nstruct rocker_desc_info *desc_info;\r\nstruct rocker_tlv *frags;\r\nint i;\r\nint err;\r\ndesc_info = rocker_desc_head_get(&rocker_port->tx_ring);\r\nif (unlikely(!desc_info)) {\r\nif (net_ratelimit())\r\nnetdev_err(dev, "tx ring full when queue awake\n");\r\nreturn NETDEV_TX_BUSY;\r\n}\r\nrocker_desc_cookie_ptr_set(desc_info, skb);\r\nfrags = rocker_tlv_nest_start(desc_info, ROCKER_TLV_TX_FRAGS);\r\nif (!frags)\r\ngoto out;\r\nerr = rocker_tx_desc_frag_map_put(rocker_port, desc_info,\r\nskb->data, skb_headlen(skb));\r\nif (err)\r\ngoto nest_cancel;\r\nif (skb_shinfo(skb)->nr_frags > ROCKER_TX_FRAGS_MAX) {\r\nerr = skb_linearize(skb);\r\nif (err)\r\ngoto unmap_frags;\r\n}\r\nfor (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {\r\nconst skb_frag_t *frag = &skb_shinfo(skb)->frags[i];\r\nerr = rocker_tx_desc_frag_map_put(rocker_port, desc_info,\r\nskb_frag_address(frag),\r\nskb_frag_size(frag));\r\nif (err)\r\ngoto unmap_frags;\r\n}\r\nrocker_tlv_nest_end(desc_info, frags);\r\nrocker_desc_gen_clear(desc_info);\r\nrocker_desc_head_set(rocker, &rocker_port->tx_ring, desc_info);\r\ndesc_info = rocker_desc_head_get(&rocker_port->tx_ring);\r\nif (!desc_info)\r\nnetif_stop_queue(dev);\r\nreturn NETDEV_TX_OK;\r\nunmap_frags:\r\nrocker_tx_desc_frags_unmap(rocker_port, desc_info);\r\nnest_cancel:\r\nrocker_tlv_nest_cancel(desc_info, frags);\r\nout:\r\ndev_kfree_skb(skb);\r\ndev->stats.tx_dropped++;\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic int rocker_port_set_mac_address(struct net_device *dev, void *p)\r\n{\r\nstruct sockaddr *addr = p;\r\nstruct rocker_port *rocker_port = netdev_priv(dev);\r\nint err;\r\nif (!is_valid_ether_addr(addr->sa_data))\r\nreturn -EADDRNOTAVAIL;\r\nerr = rocker_cmd_set_port_settings_macaddr(rocker_port, addr->sa_data);\r\nif (err)\r\nreturn err;\r\nmemcpy(dev->dev_addr, addr->sa_data, dev->addr_len);\r\nreturn 0;\r\n}\r\nstatic int rocker_port_change_mtu(struct net_device *dev, int new_mtu)\r\n{\r\nstruct rocker_port *rocker_port = netdev_priv(dev);\r\nint running = netif_running(dev);\r\nint err;\r\n#define ROCKER_PORT_MIN_MTU 68\r\n#define ROCKER_PORT_MAX_MTU 9000\r\nif (new_mtu < ROCKER_PORT_MIN_MTU || new_mtu > ROCKER_PORT_MAX_MTU)\r\nreturn -EINVAL;\r\nif (running)\r\nrocker_port_stop(dev);\r\nnetdev_info(dev, "MTU change from %d to %d\n", dev->mtu, new_mtu);\r\ndev->mtu = new_mtu;\r\nerr = rocker_cmd_set_port_settings_mtu(rocker_port, new_mtu);\r\nif (err)\r\nreturn err;\r\nif (running)\r\nerr = rocker_port_open(dev);\r\nreturn err;\r\n}\r\nstatic int rocker_port_get_phys_port_name(struct net_device *dev,\r\nchar *buf, size_t len)\r\n{\r\nstruct rocker_port *rocker_port = netdev_priv(dev);\r\nstruct port_name name = { .buf = buf, .len = len };\r\nint err;\r\nerr = rocker_cmd_exec(rocker_port, false,\r\nrocker_cmd_get_port_settings_prep, NULL,\r\nrocker_cmd_get_port_settings_phys_name_proc,\r\n&name);\r\nreturn err ? -EOPNOTSUPP : 0;\r\n}\r\nstatic int rocker_port_change_proto_down(struct net_device *dev,\r\nbool proto_down)\r\n{\r\nstruct rocker_port *rocker_port = netdev_priv(dev);\r\nif (rocker_port->dev->flags & IFF_UP)\r\nrocker_port_set_enable(rocker_port, !proto_down);\r\nrocker_port->dev->proto_down = proto_down;\r\nreturn 0;\r\n}\r\nstatic void rocker_port_neigh_destroy(struct neighbour *n)\r\n{\r\nstruct rocker_port *rocker_port = netdev_priv(n->dev);\r\nint err;\r\nerr = rocker_world_port_neigh_destroy(rocker_port, n);\r\nif (err)\r\nnetdev_warn(rocker_port->dev, "failed to handle neigh destroy (err %d)\n",\r\nerr);\r\n}\r\nstatic int rocker_port_attr_get(struct net_device *dev,\r\nstruct switchdev_attr *attr)\r\n{\r\nconst struct rocker_port *rocker_port = netdev_priv(dev);\r\nconst struct rocker *rocker = rocker_port->rocker;\r\nint err = 0;\r\nswitch (attr->id) {\r\ncase SWITCHDEV_ATTR_ID_PORT_PARENT_ID:\r\nattr->u.ppid.id_len = sizeof(rocker->hw.id);\r\nmemcpy(&attr->u.ppid.id, &rocker->hw.id, attr->u.ppid.id_len);\r\nbreak;\r\ncase SWITCHDEV_ATTR_ID_PORT_BRIDGE_FLAGS:\r\nerr = rocker_world_port_attr_bridge_flags_get(rocker_port,\r\n&attr->u.brport_flags);\r\nbreak;\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\nreturn err;\r\n}\r\nstatic int rocker_port_attr_set(struct net_device *dev,\r\nconst struct switchdev_attr *attr,\r\nstruct switchdev_trans *trans)\r\n{\r\nstruct rocker_port *rocker_port = netdev_priv(dev);\r\nint err = 0;\r\nswitch (attr->id) {\r\ncase SWITCHDEV_ATTR_ID_PORT_STP_STATE:\r\nerr = rocker_world_port_attr_stp_state_set(rocker_port,\r\nattr->u.stp_state,\r\ntrans);\r\nbreak;\r\ncase SWITCHDEV_ATTR_ID_PORT_BRIDGE_FLAGS:\r\nerr = rocker_world_port_attr_bridge_flags_set(rocker_port,\r\nattr->u.brport_flags,\r\ntrans);\r\nbreak;\r\ncase SWITCHDEV_ATTR_ID_BRIDGE_AGEING_TIME:\r\nerr = rocker_world_port_attr_bridge_ageing_time_set(rocker_port,\r\nattr->u.ageing_time,\r\ntrans);\r\nbreak;\r\ndefault:\r\nerr = -EOPNOTSUPP;\r\nbreak;\r\n}\r\nreturn err;\r\n}\r\nstatic int rocker_port_obj_add(struct net_device *dev,\r\nconst struct switchdev_obj *obj,\r\nstruct switchdev_trans *trans)\r\n{\r\nstruct rocker_port *rocker_port = netdev_priv(dev);\r\nint err = 0;\r\nswitch (obj->id) {\r\ncase SWITCHDEV_OBJ_ID_PORT_VLAN:\r\nerr = rocker_world_port_obj_vlan_add(rocker_port,\r\nSWITCHDEV_OBJ_PORT_VLAN(obj),\r\ntrans);\r\nbreak;\r\ncase SWITCHDEV_OBJ_ID_IPV4_FIB:\r\nerr = rocker_world_port_obj_fib4_add(rocker_port,\r\nSWITCHDEV_OBJ_IPV4_FIB(obj),\r\ntrans);\r\nbreak;\r\ncase SWITCHDEV_OBJ_ID_PORT_FDB:\r\nerr = rocker_world_port_obj_fdb_add(rocker_port,\r\nSWITCHDEV_OBJ_PORT_FDB(obj),\r\ntrans);\r\nbreak;\r\ndefault:\r\nerr = -EOPNOTSUPP;\r\nbreak;\r\n}\r\nreturn err;\r\n}\r\nstatic int rocker_port_obj_del(struct net_device *dev,\r\nconst struct switchdev_obj *obj)\r\n{\r\nstruct rocker_port *rocker_port = netdev_priv(dev);\r\nint err = 0;\r\nswitch (obj->id) {\r\ncase SWITCHDEV_OBJ_ID_PORT_VLAN:\r\nerr = rocker_world_port_obj_vlan_del(rocker_port,\r\nSWITCHDEV_OBJ_PORT_VLAN(obj));\r\nbreak;\r\ncase SWITCHDEV_OBJ_ID_IPV4_FIB:\r\nerr = rocker_world_port_obj_fib4_del(rocker_port,\r\nSWITCHDEV_OBJ_IPV4_FIB(obj));\r\nbreak;\r\ncase SWITCHDEV_OBJ_ID_PORT_FDB:\r\nerr = rocker_world_port_obj_fdb_del(rocker_port,\r\nSWITCHDEV_OBJ_PORT_FDB(obj));\r\nbreak;\r\ndefault:\r\nerr = -EOPNOTSUPP;\r\nbreak;\r\n}\r\nreturn err;\r\n}\r\nstatic int rocker_port_obj_dump(struct net_device *dev,\r\nstruct switchdev_obj *obj,\r\nswitchdev_obj_dump_cb_t *cb)\r\n{\r\nconst struct rocker_port *rocker_port = netdev_priv(dev);\r\nint err = 0;\r\nswitch (obj->id) {\r\ncase SWITCHDEV_OBJ_ID_PORT_FDB:\r\nerr = rocker_world_port_obj_fdb_dump(rocker_port,\r\nSWITCHDEV_OBJ_PORT_FDB(obj),\r\ncb);\r\nbreak;\r\ncase SWITCHDEV_OBJ_ID_PORT_VLAN:\r\nerr = rocker_world_port_obj_vlan_dump(rocker_port,\r\nSWITCHDEV_OBJ_PORT_VLAN(obj),\r\ncb);\r\nbreak;\r\ndefault:\r\nerr = -EOPNOTSUPP;\r\nbreak;\r\n}\r\nreturn err;\r\n}\r\nstatic int rocker_port_get_settings(struct net_device *dev,\r\nstruct ethtool_cmd *ecmd)\r\n{\r\nstruct rocker_port *rocker_port = netdev_priv(dev);\r\nreturn rocker_cmd_get_port_settings_ethtool(rocker_port, ecmd);\r\n}\r\nstatic int rocker_port_set_settings(struct net_device *dev,\r\nstruct ethtool_cmd *ecmd)\r\n{\r\nstruct rocker_port *rocker_port = netdev_priv(dev);\r\nreturn rocker_cmd_set_port_settings_ethtool(rocker_port, ecmd);\r\n}\r\nstatic void rocker_port_get_drvinfo(struct net_device *dev,\r\nstruct ethtool_drvinfo *drvinfo)\r\n{\r\nstrlcpy(drvinfo->driver, rocker_driver_name, sizeof(drvinfo->driver));\r\nstrlcpy(drvinfo->version, UTS_RELEASE, sizeof(drvinfo->version));\r\n}\r\nstatic void rocker_port_get_strings(struct net_device *netdev, u32 stringset,\r\nu8 *data)\r\n{\r\nu8 *p = data;\r\nint i;\r\nswitch (stringset) {\r\ncase ETH_SS_STATS:\r\nfor (i = 0; i < ARRAY_SIZE(rocker_port_stats); i++) {\r\nmemcpy(p, rocker_port_stats[i].str, ETH_GSTRING_LEN);\r\np += ETH_GSTRING_LEN;\r\n}\r\nbreak;\r\n}\r\n}\r\nstatic int\r\nrocker_cmd_get_port_stats_prep(const struct rocker_port *rocker_port,\r\nstruct rocker_desc_info *desc_info,\r\nvoid *priv)\r\n{\r\nstruct rocker_tlv *cmd_stats;\r\nif (rocker_tlv_put_u16(desc_info, ROCKER_TLV_CMD_TYPE,\r\nROCKER_TLV_CMD_TYPE_GET_PORT_STATS))\r\nreturn -EMSGSIZE;\r\ncmd_stats = rocker_tlv_nest_start(desc_info, ROCKER_TLV_CMD_INFO);\r\nif (!cmd_stats)\r\nreturn -EMSGSIZE;\r\nif (rocker_tlv_put_u32(desc_info, ROCKER_TLV_CMD_PORT_STATS_PPORT,\r\nrocker_port->pport))\r\nreturn -EMSGSIZE;\r\nrocker_tlv_nest_end(desc_info, cmd_stats);\r\nreturn 0;\r\n}\r\nstatic int\r\nrocker_cmd_get_port_stats_ethtool_proc(const struct rocker_port *rocker_port,\r\nconst struct rocker_desc_info *desc_info,\r\nvoid *priv)\r\n{\r\nconst struct rocker_tlv *attrs[ROCKER_TLV_CMD_MAX + 1];\r\nconst struct rocker_tlv *stats_attrs[ROCKER_TLV_CMD_PORT_STATS_MAX + 1];\r\nconst struct rocker_tlv *pattr;\r\nu32 pport;\r\nu64 *data = priv;\r\nint i;\r\nrocker_tlv_parse_desc(attrs, ROCKER_TLV_CMD_MAX, desc_info);\r\nif (!attrs[ROCKER_TLV_CMD_INFO])\r\nreturn -EIO;\r\nrocker_tlv_parse_nested(stats_attrs, ROCKER_TLV_CMD_PORT_STATS_MAX,\r\nattrs[ROCKER_TLV_CMD_INFO]);\r\nif (!stats_attrs[ROCKER_TLV_CMD_PORT_STATS_PPORT])\r\nreturn -EIO;\r\npport = rocker_tlv_get_u32(stats_attrs[ROCKER_TLV_CMD_PORT_STATS_PPORT]);\r\nif (pport != rocker_port->pport)\r\nreturn -EIO;\r\nfor (i = 0; i < ARRAY_SIZE(rocker_port_stats); i++) {\r\npattr = stats_attrs[rocker_port_stats[i].type];\r\nif (!pattr)\r\ncontinue;\r\ndata[i] = rocker_tlv_get_u64(pattr);\r\n}\r\nreturn 0;\r\n}\r\nstatic int rocker_cmd_get_port_stats_ethtool(struct rocker_port *rocker_port,\r\nvoid *priv)\r\n{\r\nreturn rocker_cmd_exec(rocker_port, false,\r\nrocker_cmd_get_port_stats_prep, NULL,\r\nrocker_cmd_get_port_stats_ethtool_proc,\r\npriv);\r\n}\r\nstatic void rocker_port_get_stats(struct net_device *dev,\r\nstruct ethtool_stats *stats, u64 *data)\r\n{\r\nstruct rocker_port *rocker_port = netdev_priv(dev);\r\nif (rocker_cmd_get_port_stats_ethtool(rocker_port, data) != 0) {\r\nint i;\r\nfor (i = 0; i < ARRAY_SIZE(rocker_port_stats); ++i)\r\ndata[i] = 0;\r\n}\r\n}\r\nstatic int rocker_port_get_sset_count(struct net_device *netdev, int sset)\r\n{\r\nswitch (sset) {\r\ncase ETH_SS_STATS:\r\nreturn ROCKER_PORT_STATS_LEN;\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nstatic struct rocker_port *rocker_port_napi_tx_get(struct napi_struct *napi)\r\n{\r\nreturn container_of(napi, struct rocker_port, napi_tx);\r\n}\r\nstatic int rocker_port_poll_tx(struct napi_struct *napi, int budget)\r\n{\r\nstruct rocker_port *rocker_port = rocker_port_napi_tx_get(napi);\r\nconst struct rocker *rocker = rocker_port->rocker;\r\nconst struct rocker_desc_info *desc_info;\r\nu32 credits = 0;\r\nint err;\r\nwhile ((desc_info = rocker_desc_tail_get(&rocker_port->tx_ring))) {\r\nstruct sk_buff *skb;\r\nerr = rocker_desc_err(desc_info);\r\nif (err && net_ratelimit())\r\nnetdev_err(rocker_port->dev, "tx desc received with err %d\n",\r\nerr);\r\nrocker_tx_desc_frags_unmap(rocker_port, desc_info);\r\nskb = rocker_desc_cookie_ptr_get(desc_info);\r\nif (err == 0) {\r\nrocker_port->dev->stats.tx_packets++;\r\nrocker_port->dev->stats.tx_bytes += skb->len;\r\n} else {\r\nrocker_port->dev->stats.tx_errors++;\r\n}\r\ndev_kfree_skb_any(skb);\r\ncredits++;\r\n}\r\nif (credits && netif_queue_stopped(rocker_port->dev))\r\nnetif_wake_queue(rocker_port->dev);\r\nnapi_complete(napi);\r\nrocker_dma_ring_credits_set(rocker, &rocker_port->tx_ring, credits);\r\nreturn 0;\r\n}\r\nstatic int rocker_port_rx_proc(const struct rocker *rocker,\r\nconst struct rocker_port *rocker_port,\r\nstruct rocker_desc_info *desc_info)\r\n{\r\nconst struct rocker_tlv *attrs[ROCKER_TLV_RX_MAX + 1];\r\nstruct sk_buff *skb = rocker_desc_cookie_ptr_get(desc_info);\r\nsize_t rx_len;\r\nu16 rx_flags = 0;\r\nif (!skb)\r\nreturn -ENOENT;\r\nrocker_tlv_parse_desc(attrs, ROCKER_TLV_RX_MAX, desc_info);\r\nif (!attrs[ROCKER_TLV_RX_FRAG_LEN])\r\nreturn -EINVAL;\r\nif (attrs[ROCKER_TLV_RX_FLAGS])\r\nrx_flags = rocker_tlv_get_u16(attrs[ROCKER_TLV_RX_FLAGS]);\r\nrocker_dma_rx_ring_skb_unmap(rocker, attrs);\r\nrx_len = rocker_tlv_get_u16(attrs[ROCKER_TLV_RX_FRAG_LEN]);\r\nskb_put(skb, rx_len);\r\nskb->protocol = eth_type_trans(skb, rocker_port->dev);\r\nif (rx_flags & ROCKER_RX_FLAGS_FWD_OFFLOAD)\r\nskb->offload_fwd_mark = rocker_port->dev->offload_fwd_mark;\r\nrocker_port->dev->stats.rx_packets++;\r\nrocker_port->dev->stats.rx_bytes += skb->len;\r\nnetif_receive_skb(skb);\r\nreturn rocker_dma_rx_ring_skb_alloc(rocker_port, desc_info);\r\n}\r\nstatic struct rocker_port *rocker_port_napi_rx_get(struct napi_struct *napi)\r\n{\r\nreturn container_of(napi, struct rocker_port, napi_rx);\r\n}\r\nstatic int rocker_port_poll_rx(struct napi_struct *napi, int budget)\r\n{\r\nstruct rocker_port *rocker_port = rocker_port_napi_rx_get(napi);\r\nconst struct rocker *rocker = rocker_port->rocker;\r\nstruct rocker_desc_info *desc_info;\r\nu32 credits = 0;\r\nint err;\r\nwhile (credits < budget &&\r\n(desc_info = rocker_desc_tail_get(&rocker_port->rx_ring))) {\r\nerr = rocker_desc_err(desc_info);\r\nif (err) {\r\nif (net_ratelimit())\r\nnetdev_err(rocker_port->dev, "rx desc received with err %d\n",\r\nerr);\r\n} else {\r\nerr = rocker_port_rx_proc(rocker, rocker_port,\r\ndesc_info);\r\nif (err && net_ratelimit())\r\nnetdev_err(rocker_port->dev, "rx processing failed with err %d\n",\r\nerr);\r\n}\r\nif (err)\r\nrocker_port->dev->stats.rx_errors++;\r\nrocker_desc_gen_clear(desc_info);\r\nrocker_desc_head_set(rocker, &rocker_port->rx_ring, desc_info);\r\ncredits++;\r\n}\r\nif (credits < budget)\r\nnapi_complete(napi);\r\nrocker_dma_ring_credits_set(rocker, &rocker_port->rx_ring, credits);\r\nreturn credits;\r\n}\r\nstatic void rocker_carrier_init(const struct rocker_port *rocker_port)\r\n{\r\nconst struct rocker *rocker = rocker_port->rocker;\r\nu64 link_status = rocker_read64(rocker, PORT_PHYS_LINK_STATUS);\r\nbool link_up;\r\nlink_up = link_status & (1 << rocker_port->pport);\r\nif (link_up)\r\nnetif_carrier_on(rocker_port->dev);\r\nelse\r\nnetif_carrier_off(rocker_port->dev);\r\n}\r\nstatic void rocker_remove_ports(struct rocker *rocker)\r\n{\r\nstruct rocker_port *rocker_port;\r\nint i;\r\nfor (i = 0; i < rocker->port_count; i++) {\r\nrocker_port = rocker->ports[i];\r\nif (!rocker_port)\r\ncontinue;\r\nrocker_world_port_fini(rocker_port);\r\nunregister_netdev(rocker_port->dev);\r\nrocker_world_port_post_fini(rocker_port);\r\nfree_netdev(rocker_port->dev);\r\n}\r\nrocker_world_fini(rocker);\r\nkfree(rocker->ports);\r\n}\r\nstatic void rocker_port_dev_addr_init(struct rocker_port *rocker_port)\r\n{\r\nconst struct rocker *rocker = rocker_port->rocker;\r\nconst struct pci_dev *pdev = rocker->pdev;\r\nint err;\r\nerr = rocker_cmd_get_port_settings_macaddr(rocker_port,\r\nrocker_port->dev->dev_addr);\r\nif (err) {\r\ndev_warn(&pdev->dev, "failed to get mac address, using random\n");\r\neth_hw_addr_random(rocker_port->dev);\r\n}\r\n}\r\nstatic int rocker_probe_port(struct rocker *rocker, unsigned int port_number)\r\n{\r\nconst struct pci_dev *pdev = rocker->pdev;\r\nstruct rocker_port *rocker_port;\r\nstruct net_device *dev;\r\nint err;\r\ndev = alloc_etherdev(sizeof(struct rocker_port));\r\nif (!dev)\r\nreturn -ENOMEM;\r\nrocker_port = netdev_priv(dev);\r\nrocker_port->dev = dev;\r\nrocker_port->rocker = rocker;\r\nrocker_port->port_number = port_number;\r\nrocker_port->pport = port_number + 1;\r\nerr = rocker_world_check_init(rocker_port);\r\nif (err) {\r\ndev_err(&pdev->dev, "world init failed\n");\r\ngoto err_world_check_init;\r\n}\r\nrocker_port_dev_addr_init(rocker_port);\r\ndev->netdev_ops = &rocker_port_netdev_ops;\r\ndev->ethtool_ops = &rocker_port_ethtool_ops;\r\ndev->switchdev_ops = &rocker_port_switchdev_ops;\r\nnetif_tx_napi_add(dev, &rocker_port->napi_tx, rocker_port_poll_tx,\r\nNAPI_POLL_WEIGHT);\r\nnetif_napi_add(dev, &rocker_port->napi_rx, rocker_port_poll_rx,\r\nNAPI_POLL_WEIGHT);\r\nrocker_carrier_init(rocker_port);\r\ndev->features |= NETIF_F_NETNS_LOCAL | NETIF_F_SG;\r\nerr = rocker_world_port_pre_init(rocker_port);\r\nif (err) {\r\ndev_err(&pdev->dev, "port world pre-init failed\n");\r\ngoto err_world_port_pre_init;\r\n}\r\nerr = register_netdev(dev);\r\nif (err) {\r\ndev_err(&pdev->dev, "register_netdev failed\n");\r\ngoto err_register_netdev;\r\n}\r\nrocker->ports[port_number] = rocker_port;\r\nerr = rocker_world_port_init(rocker_port);\r\nif (err) {\r\ndev_err(&pdev->dev, "port world init failed\n");\r\ngoto err_world_port_init;\r\n}\r\nreturn 0;\r\nerr_world_port_init:\r\nrocker->ports[port_number] = NULL;\r\nunregister_netdev(dev);\r\nerr_register_netdev:\r\nrocker_world_port_post_fini(rocker_port);\r\nerr_world_port_pre_init:\r\nerr_world_check_init:\r\nfree_netdev(dev);\r\nreturn err;\r\n}\r\nstatic int rocker_probe_ports(struct rocker *rocker)\r\n{\r\nint i;\r\nsize_t alloc_size;\r\nint err;\r\nalloc_size = sizeof(struct rocker_port *) * rocker->port_count;\r\nrocker->ports = kzalloc(alloc_size, GFP_KERNEL);\r\nif (!rocker->ports)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < rocker->port_count; i++) {\r\nerr = rocker_probe_port(rocker, i);\r\nif (err)\r\ngoto remove_ports;\r\n}\r\nreturn 0;\r\nremove_ports:\r\nrocker_remove_ports(rocker);\r\nreturn err;\r\n}\r\nstatic int rocker_msix_init(struct rocker *rocker)\r\n{\r\nstruct pci_dev *pdev = rocker->pdev;\r\nint msix_entries;\r\nint i;\r\nint err;\r\nmsix_entries = pci_msix_vec_count(pdev);\r\nif (msix_entries < 0)\r\nreturn msix_entries;\r\nif (msix_entries != ROCKER_MSIX_VEC_COUNT(rocker->port_count))\r\nreturn -EINVAL;\r\nrocker->msix_entries = kmalloc_array(msix_entries,\r\nsizeof(struct msix_entry),\r\nGFP_KERNEL);\r\nif (!rocker->msix_entries)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < msix_entries; i++)\r\nrocker->msix_entries[i].entry = i;\r\nerr = pci_enable_msix_exact(pdev, rocker->msix_entries, msix_entries);\r\nif (err < 0)\r\ngoto err_enable_msix;\r\nreturn 0;\r\nerr_enable_msix:\r\nkfree(rocker->msix_entries);\r\nreturn err;\r\n}\r\nstatic void rocker_msix_fini(const struct rocker *rocker)\r\n{\r\npci_disable_msix(rocker->pdev);\r\nkfree(rocker->msix_entries);\r\n}\r\nstatic int rocker_probe(struct pci_dev *pdev, const struct pci_device_id *id)\r\n{\r\nstruct rocker *rocker;\r\nint err;\r\nrocker = kzalloc(sizeof(*rocker), GFP_KERNEL);\r\nif (!rocker)\r\nreturn -ENOMEM;\r\nerr = pci_enable_device(pdev);\r\nif (err) {\r\ndev_err(&pdev->dev, "pci_enable_device failed\n");\r\ngoto err_pci_enable_device;\r\n}\r\nerr = pci_request_regions(pdev, rocker_driver_name);\r\nif (err) {\r\ndev_err(&pdev->dev, "pci_request_regions failed\n");\r\ngoto err_pci_request_regions;\r\n}\r\nerr = pci_set_dma_mask(pdev, DMA_BIT_MASK(64));\r\nif (!err) {\r\nerr = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));\r\nif (err) {\r\ndev_err(&pdev->dev, "pci_set_consistent_dma_mask failed\n");\r\ngoto err_pci_set_dma_mask;\r\n}\r\n} else {\r\nerr = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (err) {\r\ndev_err(&pdev->dev, "pci_set_dma_mask failed\n");\r\ngoto err_pci_set_dma_mask;\r\n}\r\n}\r\nif (pci_resource_len(pdev, 0) < ROCKER_PCI_BAR0_SIZE) {\r\ndev_err(&pdev->dev, "invalid PCI region size\n");\r\nerr = -EINVAL;\r\ngoto err_pci_resource_len_check;\r\n}\r\nrocker->hw_addr = ioremap(pci_resource_start(pdev, 0),\r\npci_resource_len(pdev, 0));\r\nif (!rocker->hw_addr) {\r\ndev_err(&pdev->dev, "ioremap failed\n");\r\nerr = -EIO;\r\ngoto err_ioremap;\r\n}\r\npci_set_master(pdev);\r\nrocker->pdev = pdev;\r\npci_set_drvdata(pdev, rocker);\r\nrocker->port_count = rocker_read32(rocker, PORT_PHYS_COUNT);\r\nerr = rocker_msix_init(rocker);\r\nif (err) {\r\ndev_err(&pdev->dev, "MSI-X init failed\n");\r\ngoto err_msix_init;\r\n}\r\nerr = rocker_basic_hw_test(rocker);\r\nif (err) {\r\ndev_err(&pdev->dev, "basic hw test failed\n");\r\ngoto err_basic_hw_test;\r\n}\r\nrocker_write32(rocker, CONTROL, ROCKER_CONTROL_RESET);\r\nerr = rocker_dma_rings_init(rocker);\r\nif (err)\r\ngoto err_dma_rings_init;\r\nerr = request_irq(rocker_msix_vector(rocker, ROCKER_MSIX_VEC_CMD),\r\nrocker_cmd_irq_handler, 0,\r\nrocker_driver_name, rocker);\r\nif (err) {\r\ndev_err(&pdev->dev, "cannot assign cmd irq\n");\r\ngoto err_request_cmd_irq;\r\n}\r\nerr = request_irq(rocker_msix_vector(rocker, ROCKER_MSIX_VEC_EVENT),\r\nrocker_event_irq_handler, 0,\r\nrocker_driver_name, rocker);\r\nif (err) {\r\ndev_err(&pdev->dev, "cannot assign event irq\n");\r\ngoto err_request_event_irq;\r\n}\r\nrocker->hw.id = rocker_read64(rocker, SWITCH_ID);\r\nerr = rocker_probe_ports(rocker);\r\nif (err) {\r\ndev_err(&pdev->dev, "failed to probe ports\n");\r\ngoto err_probe_ports;\r\n}\r\ndev_info(&pdev->dev, "Rocker switch with id %*phN\n",\r\n(int)sizeof(rocker->hw.id), &rocker->hw.id);\r\nreturn 0;\r\nerr_probe_ports:\r\nfree_irq(rocker_msix_vector(rocker, ROCKER_MSIX_VEC_EVENT), rocker);\r\nerr_request_event_irq:\r\nfree_irq(rocker_msix_vector(rocker, ROCKER_MSIX_VEC_CMD), rocker);\r\nerr_request_cmd_irq:\r\nrocker_dma_rings_fini(rocker);\r\nerr_dma_rings_init:\r\nerr_basic_hw_test:\r\nrocker_msix_fini(rocker);\r\nerr_msix_init:\r\niounmap(rocker->hw_addr);\r\nerr_ioremap:\r\nerr_pci_resource_len_check:\r\nerr_pci_set_dma_mask:\r\npci_release_regions(pdev);\r\nerr_pci_request_regions:\r\npci_disable_device(pdev);\r\nerr_pci_enable_device:\r\nkfree(rocker);\r\nreturn err;\r\n}\r\nstatic void rocker_remove(struct pci_dev *pdev)\r\n{\r\nstruct rocker *rocker = pci_get_drvdata(pdev);\r\nrocker_write32(rocker, CONTROL, ROCKER_CONTROL_RESET);\r\nrocker_remove_ports(rocker);\r\nfree_irq(rocker_msix_vector(rocker, ROCKER_MSIX_VEC_EVENT), rocker);\r\nfree_irq(rocker_msix_vector(rocker, ROCKER_MSIX_VEC_CMD), rocker);\r\nrocker_dma_rings_fini(rocker);\r\nrocker_msix_fini(rocker);\r\niounmap(rocker->hw_addr);\r\npci_release_regions(rocker->pdev);\r\npci_disable_device(rocker->pdev);\r\nkfree(rocker);\r\n}\r\nstatic bool rocker_port_dev_check(const struct net_device *dev)\r\n{\r\nreturn dev->netdev_ops == &rocker_port_netdev_ops;\r\n}\r\nstatic int rocker_netdevice_event(struct notifier_block *unused,\r\nunsigned long event, void *ptr)\r\n{\r\nstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\r\nstruct netdev_notifier_changeupper_info *info;\r\nstruct rocker_port *rocker_port;\r\nint err;\r\nif (!rocker_port_dev_check(dev))\r\nreturn NOTIFY_DONE;\r\nswitch (event) {\r\ncase NETDEV_CHANGEUPPER:\r\ninfo = ptr;\r\nif (!info->master)\r\ngoto out;\r\nrocker_port = netdev_priv(dev);\r\nif (info->linking) {\r\nerr = rocker_world_port_master_linked(rocker_port,\r\ninfo->upper_dev);\r\nif (err)\r\nnetdev_warn(dev, "failed to reflect master linked (err %d)\n",\r\nerr);\r\n} else {\r\nerr = rocker_world_port_master_unlinked(rocker_port,\r\ninfo->upper_dev);\r\nif (err)\r\nnetdev_warn(dev, "failed to reflect master unlinked (err %d)\n",\r\nerr);\r\n}\r\n}\r\nout:\r\nreturn NOTIFY_DONE;\r\n}\r\nstatic int rocker_netevent_event(struct notifier_block *unused,\r\nunsigned long event, void *ptr)\r\n{\r\nstruct rocker_port *rocker_port;\r\nstruct net_device *dev;\r\nstruct neighbour *n = ptr;\r\nint err;\r\nswitch (event) {\r\ncase NETEVENT_NEIGH_UPDATE:\r\nif (n->tbl != &arp_tbl)\r\nreturn NOTIFY_DONE;\r\ndev = n->dev;\r\nif (!rocker_port_dev_check(dev))\r\nreturn NOTIFY_DONE;\r\nrocker_port = netdev_priv(dev);\r\nerr = rocker_world_port_neigh_update(rocker_port, n);\r\nif (err)\r\nnetdev_warn(dev, "failed to handle neigh update (err %d)\n",\r\nerr);\r\nbreak;\r\n}\r\nreturn NOTIFY_DONE;\r\n}\r\nstatic int __init rocker_module_init(void)\r\n{\r\nint err;\r\nregister_netdevice_notifier(&rocker_netdevice_nb);\r\nregister_netevent_notifier(&rocker_netevent_nb);\r\nerr = pci_register_driver(&rocker_pci_driver);\r\nif (err)\r\ngoto err_pci_register_driver;\r\nreturn 0;\r\nerr_pci_register_driver:\r\nunregister_netevent_notifier(&rocker_netevent_nb);\r\nunregister_netdevice_notifier(&rocker_netdevice_nb);\r\nreturn err;\r\n}\r\nstatic void __exit rocker_module_exit(void)\r\n{\r\nunregister_netevent_notifier(&rocker_netevent_nb);\r\nunregister_netdevice_notifier(&rocker_netdevice_nb);\r\npci_unregister_driver(&rocker_pci_driver);\r\n}
