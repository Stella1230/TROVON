static void vmw_resources_unreserve(struct vmw_sw_context *sw_context,\r\nbool backoff)\r\n{\r\nstruct vmw_resource_val_node *val;\r\nstruct list_head *list = &sw_context->resource_list;\r\nif (sw_context->dx_query_mob && !backoff)\r\nvmw_context_bind_dx_query(sw_context->dx_query_ctx,\r\nsw_context->dx_query_mob);\r\nlist_for_each_entry(val, list, head) {\r\nstruct vmw_resource *res = val->res;\r\nbool switch_backup =\r\n(backoff) ? false : val->switching_backup;\r\nif (unlikely(val->staged_bindings)) {\r\nif (!backoff) {\r\nvmw_binding_state_commit\r\n(vmw_context_binding_state(val->res),\r\nval->staged_bindings);\r\n}\r\nif (val->staged_bindings != sw_context->staged_bindings)\r\nvmw_binding_state_free(val->staged_bindings);\r\nelse\r\nsw_context->staged_bindings_inuse = false;\r\nval->staged_bindings = NULL;\r\n}\r\nvmw_resource_unreserve(res, switch_backup, val->new_backup,\r\nval->new_backup_offset);\r\nvmw_dmabuf_unreference(&val->new_backup);\r\n}\r\n}\r\nstatic int vmw_cmd_ctx_first_setup(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nstruct vmw_resource_val_node *node)\r\n{\r\nint ret;\r\nret = vmw_resource_context_res_add(dev_priv, sw_context, node->res);\r\nif (unlikely(ret != 0))\r\ngoto out_err;\r\nif (!sw_context->staged_bindings) {\r\nsw_context->staged_bindings =\r\nvmw_binding_state_alloc(dev_priv);\r\nif (IS_ERR(sw_context->staged_bindings)) {\r\nDRM_ERROR("Failed to allocate context binding "\r\n"information.\n");\r\nret = PTR_ERR(sw_context->staged_bindings);\r\nsw_context->staged_bindings = NULL;\r\ngoto out_err;\r\n}\r\n}\r\nif (sw_context->staged_bindings_inuse) {\r\nnode->staged_bindings = vmw_binding_state_alloc(dev_priv);\r\nif (IS_ERR(node->staged_bindings)) {\r\nDRM_ERROR("Failed to allocate context binding "\r\n"information.\n");\r\nret = PTR_ERR(node->staged_bindings);\r\nnode->staged_bindings = NULL;\r\ngoto out_err;\r\n}\r\n} else {\r\nnode->staged_bindings = sw_context->staged_bindings;\r\nsw_context->staged_bindings_inuse = true;\r\n}\r\nreturn 0;\r\nout_err:\r\nreturn ret;\r\n}\r\nstatic int vmw_resource_val_add(struct vmw_sw_context *sw_context,\r\nstruct vmw_resource *res,\r\nstruct vmw_resource_val_node **p_node)\r\n{\r\nstruct vmw_private *dev_priv = res->dev_priv;\r\nstruct vmw_resource_val_node *node;\r\nstruct drm_hash_item *hash;\r\nint ret;\r\nif (likely(drm_ht_find_item(&sw_context->res_ht, (unsigned long) res,\r\n&hash) == 0)) {\r\nnode = container_of(hash, struct vmw_resource_val_node, hash);\r\nnode->first_usage = false;\r\nif (unlikely(p_node != NULL))\r\n*p_node = node;\r\nreturn 0;\r\n}\r\nnode = kzalloc(sizeof(*node), GFP_KERNEL);\r\nif (unlikely(node == NULL)) {\r\nDRM_ERROR("Failed to allocate a resource validation "\r\n"entry.\n");\r\nreturn -ENOMEM;\r\n}\r\nnode->hash.key = (unsigned long) res;\r\nret = drm_ht_insert_item(&sw_context->res_ht, &node->hash);\r\nif (unlikely(ret != 0)) {\r\nDRM_ERROR("Failed to initialize a resource validation "\r\n"entry.\n");\r\nkfree(node);\r\nreturn ret;\r\n}\r\nnode->res = vmw_resource_reference(res);\r\nnode->first_usage = true;\r\nif (unlikely(p_node != NULL))\r\n*p_node = node;\r\nif (!dev_priv->has_mob) {\r\nlist_add_tail(&node->head, &sw_context->resource_list);\r\nreturn 0;\r\n}\r\nswitch (vmw_res_type(res)) {\r\ncase vmw_res_context:\r\ncase vmw_res_dx_context:\r\nlist_add(&node->head, &sw_context->ctx_resource_list);\r\nret = vmw_cmd_ctx_first_setup(dev_priv, sw_context, node);\r\nbreak;\r\ncase vmw_res_cotable:\r\nlist_add_tail(&node->head, &sw_context->ctx_resource_list);\r\nbreak;\r\ndefault:\r\nlist_add_tail(&node->head, &sw_context->resource_list);\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nstatic int vmw_view_res_val_add(struct vmw_sw_context *sw_context,\r\nstruct vmw_resource *view)\r\n{\r\nint ret;\r\nret = vmw_resource_val_add(sw_context, vmw_view_srf(view), NULL);\r\nif (ret)\r\nreturn ret;\r\nreturn vmw_resource_val_add(sw_context, view, NULL);\r\n}\r\nstatic int vmw_view_id_val_add(struct vmw_sw_context *sw_context,\r\nenum vmw_view_type view_type, u32 id)\r\n{\r\nstruct vmw_resource_val_node *ctx_node = sw_context->dx_ctx_node;\r\nstruct vmw_resource *view;\r\nint ret;\r\nif (!ctx_node) {\r\nDRM_ERROR("DX Context not set.\n");\r\nreturn -EINVAL;\r\n}\r\nview = vmw_view_lookup(sw_context->man, view_type, id);\r\nif (IS_ERR(view))\r\nreturn PTR_ERR(view);\r\nret = vmw_view_res_val_add(sw_context, view);\r\nvmw_resource_unreference(&view);\r\nreturn ret;\r\n}\r\nstatic int vmw_resource_context_res_add(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nstruct vmw_resource *ctx)\r\n{\r\nstruct list_head *binding_list;\r\nstruct vmw_ctx_bindinfo *entry;\r\nint ret = 0;\r\nstruct vmw_resource *res;\r\nu32 i;\r\nif (dev_priv->has_dx && vmw_res_type(ctx) == vmw_res_dx_context) {\r\nfor (i = 0; i < SVGA_COTABLE_DX10_MAX; ++i) {\r\nres = vmw_context_cotable(ctx, i);\r\nif (IS_ERR(res))\r\ncontinue;\r\nret = vmw_resource_val_add(sw_context, res, NULL);\r\nvmw_resource_unreference(&res);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n}\r\n}\r\nmutex_lock(&dev_priv->binding_mutex);\r\nbinding_list = vmw_context_binding_list(ctx);\r\nlist_for_each_entry(entry, binding_list, ctx_list) {\r\nres = vmw_resource_reference_unless_doomed(entry->res);\r\nif (unlikely(res == NULL))\r\ncontinue;\r\nif (vmw_res_type(entry->res) == vmw_res_view)\r\nret = vmw_view_res_val_add(sw_context, entry->res);\r\nelse\r\nret = vmw_resource_val_add(sw_context, entry->res,\r\nNULL);\r\nvmw_resource_unreference(&res);\r\nif (unlikely(ret != 0))\r\nbreak;\r\n}\r\nif (dev_priv->has_dx && vmw_res_type(ctx) == vmw_res_dx_context) {\r\nstruct vmw_dma_buffer *dx_query_mob;\r\ndx_query_mob = vmw_context_get_dx_query_mob(ctx);\r\nif (dx_query_mob)\r\nret = vmw_bo_to_validate_list(sw_context,\r\ndx_query_mob,\r\ntrue, NULL);\r\n}\r\nmutex_unlock(&dev_priv->binding_mutex);\r\nreturn ret;\r\n}\r\nstatic int vmw_resource_relocation_add(struct list_head *list,\r\nconst struct vmw_resource *res,\r\nunsigned long offset)\r\n{\r\nstruct vmw_resource_relocation *rel;\r\nrel = kmalloc(sizeof(*rel), GFP_KERNEL);\r\nif (unlikely(rel == NULL)) {\r\nDRM_ERROR("Failed to allocate a resource relocation.\n");\r\nreturn -ENOMEM;\r\n}\r\nrel->res = res;\r\nrel->offset = offset;\r\nlist_add_tail(&rel->head, list);\r\nreturn 0;\r\n}\r\nstatic void vmw_resource_relocations_free(struct list_head *list)\r\n{\r\nstruct vmw_resource_relocation *rel, *n;\r\nlist_for_each_entry_safe(rel, n, list, head) {\r\nlist_del(&rel->head);\r\nkfree(rel);\r\n}\r\n}\r\nstatic void vmw_resource_relocations_apply(uint32_t *cb,\r\nstruct list_head *list)\r\n{\r\nstruct vmw_resource_relocation *rel;\r\nlist_for_each_entry(rel, list, head) {\r\nif (likely(rel->res != NULL))\r\ncb[rel->offset] = rel->res->id;\r\nelse\r\ncb[rel->offset] = SVGA_3D_CMD_NOP;\r\n}\r\n}\r\nstatic int vmw_cmd_invalid(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nreturn capable(CAP_SYS_ADMIN) ? : -EINVAL;\r\n}\r\nstatic int vmw_cmd_ok(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nreturn 0;\r\n}\r\nstatic int vmw_bo_to_validate_list(struct vmw_sw_context *sw_context,\r\nstruct vmw_dma_buffer *vbo,\r\nbool validate_as_mob,\r\nuint32_t *p_val_node)\r\n{\r\nuint32_t val_node;\r\nstruct vmw_validate_buffer *vval_buf;\r\nstruct ttm_validate_buffer *val_buf;\r\nstruct drm_hash_item *hash;\r\nint ret;\r\nif (likely(drm_ht_find_item(&sw_context->res_ht, (unsigned long) vbo,\r\n&hash) == 0)) {\r\nvval_buf = container_of(hash, struct vmw_validate_buffer,\r\nhash);\r\nif (unlikely(vval_buf->validate_as_mob != validate_as_mob)) {\r\nDRM_ERROR("Inconsistent buffer usage.\n");\r\nreturn -EINVAL;\r\n}\r\nval_buf = &vval_buf->base;\r\nval_node = vval_buf - sw_context->val_bufs;\r\n} else {\r\nval_node = sw_context->cur_val_buf;\r\nif (unlikely(val_node >= VMWGFX_MAX_VALIDATIONS)) {\r\nDRM_ERROR("Max number of DMA buffers per submission "\r\n"exceeded.\n");\r\nreturn -EINVAL;\r\n}\r\nvval_buf = &sw_context->val_bufs[val_node];\r\nvval_buf->hash.key = (unsigned long) vbo;\r\nret = drm_ht_insert_item(&sw_context->res_ht, &vval_buf->hash);\r\nif (unlikely(ret != 0)) {\r\nDRM_ERROR("Failed to initialize a buffer validation "\r\n"entry.\n");\r\nreturn ret;\r\n}\r\n++sw_context->cur_val_buf;\r\nval_buf = &vval_buf->base;\r\nval_buf->bo = ttm_bo_reference(&vbo->base);\r\nval_buf->shared = false;\r\nlist_add_tail(&val_buf->head, &sw_context->validate_nodes);\r\nvval_buf->validate_as_mob = validate_as_mob;\r\n}\r\nif (p_val_node)\r\n*p_val_node = val_node;\r\nreturn 0;\r\n}\r\nstatic int vmw_resources_reserve(struct vmw_sw_context *sw_context)\r\n{\r\nstruct vmw_resource_val_node *val;\r\nint ret = 0;\r\nlist_for_each_entry(val, &sw_context->resource_list, head) {\r\nstruct vmw_resource *res = val->res;\r\nret = vmw_resource_reserve(res, true, val->no_buffer_needed);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nif (res->backup) {\r\nstruct vmw_dma_buffer *vbo = res->backup;\r\nret = vmw_bo_to_validate_list\r\n(sw_context, vbo,\r\nvmw_resource_needs_backup(res), NULL);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n}\r\n}\r\nif (sw_context->dx_query_mob) {\r\nstruct vmw_dma_buffer *expected_dx_query_mob;\r\nexpected_dx_query_mob =\r\nvmw_context_get_dx_query_mob(sw_context->dx_query_ctx);\r\nif (expected_dx_query_mob &&\r\nexpected_dx_query_mob != sw_context->dx_query_mob) {\r\nret = -EINVAL;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic int vmw_resources_validate(struct vmw_sw_context *sw_context)\r\n{\r\nstruct vmw_resource_val_node *val;\r\nint ret;\r\nlist_for_each_entry(val, &sw_context->resource_list, head) {\r\nstruct vmw_resource *res = val->res;\r\nstruct vmw_dma_buffer *backup = res->backup;\r\nret = vmw_resource_validate(res);\r\nif (unlikely(ret != 0)) {\r\nif (ret != -ERESTARTSYS)\r\nDRM_ERROR("Failed to validate resource.\n");\r\nreturn ret;\r\n}\r\nif (backup && res->backup && (backup != res->backup)) {\r\nstruct vmw_dma_buffer *vbo = res->backup;\r\nret = vmw_bo_to_validate_list\r\n(sw_context, vbo,\r\nvmw_resource_needs_backup(res), NULL);\r\nif (ret) {\r\nttm_bo_unreserve(&vbo->base);\r\nreturn ret;\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_res_reloc_add(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nuint32_t *id_loc,\r\nstruct vmw_resource *res,\r\nstruct vmw_resource_val_node **p_val)\r\n{\r\nint ret;\r\nstruct vmw_resource_val_node *node;\r\n*p_val = NULL;\r\nret = vmw_resource_relocation_add(&sw_context->res_relocations,\r\nres,\r\nid_loc - sw_context->buf_start);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nret = vmw_resource_val_add(sw_context, res, &node);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nif (p_val)\r\n*p_val = node;\r\nreturn 0;\r\n}\r\nstatic int\r\nvmw_cmd_res_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nenum vmw_res_type res_type,\r\nconst struct vmw_user_resource_conv *converter,\r\nuint32_t *id_loc,\r\nstruct vmw_resource_val_node **p_val)\r\n{\r\nstruct vmw_res_cache_entry *rcache =\r\n&sw_context->res_cache[res_type];\r\nstruct vmw_resource *res;\r\nstruct vmw_resource_val_node *node;\r\nint ret;\r\nif (*id_loc == SVGA3D_INVALID_ID) {\r\nif (p_val)\r\n*p_val = NULL;\r\nif (res_type == vmw_res_context) {\r\nDRM_ERROR("Illegal context invalid id.\n");\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nif (likely(rcache->valid && *id_loc == rcache->handle)) {\r\nconst struct vmw_resource *res = rcache->res;\r\nrcache->node->first_usage = false;\r\nif (p_val)\r\n*p_val = rcache->node;\r\nreturn vmw_resource_relocation_add\r\n(&sw_context->res_relocations, res,\r\nid_loc - sw_context->buf_start);\r\n}\r\nret = vmw_user_resource_lookup_handle(dev_priv,\r\nsw_context->fp->tfile,\r\n*id_loc,\r\nconverter,\r\n&res);\r\nif (unlikely(ret != 0)) {\r\nDRM_ERROR("Could not find or use resource 0x%08x.\n",\r\n(unsigned) *id_loc);\r\ndump_stack();\r\nreturn ret;\r\n}\r\nrcache->valid = true;\r\nrcache->res = res;\r\nrcache->handle = *id_loc;\r\nret = vmw_cmd_res_reloc_add(dev_priv, sw_context, id_loc,\r\nres, &node);\r\nif (unlikely(ret != 0))\r\ngoto out_no_reloc;\r\nrcache->node = node;\r\nif (p_val)\r\n*p_val = node;\r\nvmw_resource_unreference(&res);\r\nreturn 0;\r\nout_no_reloc:\r\nBUG_ON(sw_context->error_resource != NULL);\r\nsw_context->error_resource = res;\r\nreturn ret;\r\n}\r\nstatic int vmw_rebind_all_dx_query(struct vmw_resource *ctx_res)\r\n{\r\nstruct vmw_private *dev_priv = ctx_res->dev_priv;\r\nstruct vmw_dma_buffer *dx_query_mob;\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDXBindAllQuery body;\r\n} *cmd;\r\ndx_query_mob = vmw_context_get_dx_query_mob(ctx_res);\r\nif (!dx_query_mob || dx_query_mob->dx_query_ctx)\r\nreturn 0;\r\ncmd = vmw_fifo_reserve_dx(dev_priv, sizeof(*cmd), ctx_res->id);\r\nif (cmd == NULL) {\r\nDRM_ERROR("Failed to rebind queries.\n");\r\nreturn -ENOMEM;\r\n}\r\ncmd->header.id = SVGA_3D_CMD_DX_BIND_ALL_QUERY;\r\ncmd->header.size = sizeof(cmd->body);\r\ncmd->body.cid = ctx_res->id;\r\ncmd->body.mobid = dx_query_mob->base.mem.start;\r\nvmw_fifo_commit(dev_priv, sizeof(*cmd));\r\nvmw_context_bind_dx_query(ctx_res, dx_query_mob);\r\nreturn 0;\r\n}\r\nstatic int vmw_rebind_contexts(struct vmw_sw_context *sw_context)\r\n{\r\nstruct vmw_resource_val_node *val;\r\nint ret;\r\nlist_for_each_entry(val, &sw_context->resource_list, head) {\r\nif (unlikely(!val->staged_bindings))\r\nbreak;\r\nret = vmw_binding_rebind_all\r\n(vmw_context_binding_state(val->res));\r\nif (unlikely(ret != 0)) {\r\nif (ret != -ERESTARTSYS)\r\nDRM_ERROR("Failed to rebind context.\n");\r\nreturn ret;\r\n}\r\nret = vmw_rebind_all_dx_query(val->res);\r\nif (ret != 0)\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic int vmw_view_bindings_add(struct vmw_sw_context *sw_context,\r\nenum vmw_view_type view_type,\r\nenum vmw_ctx_binding_type binding_type,\r\nuint32 shader_slot,\r\nuint32 view_ids[], u32 num_views,\r\nu32 first_slot)\r\n{\r\nstruct vmw_resource_val_node *ctx_node = sw_context->dx_ctx_node;\r\nstruct vmw_cmdbuf_res_manager *man;\r\nu32 i;\r\nint ret;\r\nif (!ctx_node) {\r\nDRM_ERROR("DX Context not set.\n");\r\nreturn -EINVAL;\r\n}\r\nman = sw_context->man;\r\nfor (i = 0; i < num_views; ++i) {\r\nstruct vmw_ctx_bindinfo_view binding;\r\nstruct vmw_resource *view = NULL;\r\nif (view_ids[i] != SVGA3D_INVALID_ID) {\r\nview = vmw_view_lookup(man, view_type, view_ids[i]);\r\nif (IS_ERR(view)) {\r\nDRM_ERROR("View not found.\n");\r\nreturn PTR_ERR(view);\r\n}\r\nret = vmw_view_res_val_add(sw_context, view);\r\nif (ret) {\r\nDRM_ERROR("Could not add view to "\r\n"validation list.\n");\r\nvmw_resource_unreference(&view);\r\nreturn ret;\r\n}\r\n}\r\nbinding.bi.ctx = ctx_node->res;\r\nbinding.bi.res = view;\r\nbinding.bi.bt = binding_type;\r\nbinding.shader_slot = shader_slot;\r\nbinding.slot = first_slot + i;\r\nvmw_binding_add(ctx_node->staged_bindings, &binding.bi,\r\nshader_slot, binding.slot);\r\nif (view)\r\nvmw_resource_unreference(&view);\r\n}\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_cid_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_cid_cmd {\r\nSVGA3dCmdHeader header;\r\nuint32_t cid;\r\n} *cmd;\r\ncmd = container_of(header, struct vmw_cid_cmd, header);\r\nreturn vmw_cmd_res_check(dev_priv, sw_context, vmw_res_context,\r\nuser_context_converter, &cmd->cid, NULL);\r\n}\r\nstatic int vmw_cmd_set_render_target_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_sid_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdSetRenderTarget body;\r\n} *cmd;\r\nstruct vmw_resource_val_node *ctx_node;\r\nstruct vmw_resource_val_node *res_node;\r\nint ret;\r\ncmd = container_of(header, struct vmw_sid_cmd, header);\r\nif (cmd->body.type >= SVGA3D_RT_MAX) {\r\nDRM_ERROR("Illegal render target type %u.\n",\r\n(unsigned) cmd->body.type);\r\nreturn -EINVAL;\r\n}\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_context,\r\nuser_context_converter, &cmd->body.cid,\r\n&ctx_node);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->body.target.sid, &res_node);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nif (dev_priv->has_mob) {\r\nstruct vmw_ctx_bindinfo_view binding;\r\nbinding.bi.ctx = ctx_node->res;\r\nbinding.bi.res = res_node ? res_node->res : NULL;\r\nbinding.bi.bt = vmw_ctx_binding_rt;\r\nbinding.slot = cmd->body.type;\r\nvmw_binding_add(ctx_node->staged_bindings,\r\n&binding.bi, 0, binding.slot);\r\n}\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_surface_copy_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_sid_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdSurfaceCopy body;\r\n} *cmd;\r\nint ret;\r\ncmd = container_of(header, struct vmw_sid_cmd, header);\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->body.src.sid, NULL);\r\nif (ret)\r\nreturn ret;\r\nreturn vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->body.dest.sid, NULL);\r\n}\r\nstatic int vmw_cmd_buffer_copy_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDXBufferCopy body;\r\n} *cmd;\r\nint ret;\r\ncmd = container_of(header, typeof(*cmd), header);\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->body.src, NULL);\r\nif (ret != 0)\r\nreturn ret;\r\nreturn vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->body.dest, NULL);\r\n}\r\nstatic int vmw_cmd_pred_copy_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDXPredCopyRegion body;\r\n} *cmd;\r\nint ret;\r\ncmd = container_of(header, typeof(*cmd), header);\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->body.srcSid, NULL);\r\nif (ret != 0)\r\nreturn ret;\r\nreturn vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->body.dstSid, NULL);\r\n}\r\nstatic int vmw_cmd_stretch_blt_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_sid_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdSurfaceStretchBlt body;\r\n} *cmd;\r\nint ret;\r\ncmd = container_of(header, struct vmw_sid_cmd, header);\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->body.src.sid, NULL);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nreturn vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->body.dest.sid, NULL);\r\n}\r\nstatic int vmw_cmd_blt_surf_screen_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_sid_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdBlitSurfaceToScreen body;\r\n} *cmd;\r\ncmd = container_of(header, struct vmw_sid_cmd, header);\r\nreturn vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->body.srcImage.sid, NULL);\r\n}\r\nstatic int vmw_cmd_present_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_sid_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdPresent body;\r\n} *cmd;\r\ncmd = container_of(header, struct vmw_sid_cmd, header);\r\nreturn vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter, &cmd->body.sid,\r\nNULL);\r\n}\r\nstatic int vmw_query_bo_switch_prepare(struct vmw_private *dev_priv,\r\nstruct vmw_dma_buffer *new_query_bo,\r\nstruct vmw_sw_context *sw_context)\r\n{\r\nstruct vmw_res_cache_entry *ctx_entry =\r\n&sw_context->res_cache[vmw_res_context];\r\nint ret;\r\nBUG_ON(!ctx_entry->valid);\r\nsw_context->last_query_ctx = ctx_entry->res;\r\nif (unlikely(new_query_bo != sw_context->cur_query_bo)) {\r\nif (unlikely(new_query_bo->base.num_pages > 4)) {\r\nDRM_ERROR("Query buffer too large.\n");\r\nreturn -EINVAL;\r\n}\r\nif (unlikely(sw_context->cur_query_bo != NULL)) {\r\nsw_context->needs_post_query_barrier = true;\r\nret = vmw_bo_to_validate_list(sw_context,\r\nsw_context->cur_query_bo,\r\ndev_priv->has_mob, NULL);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n}\r\nsw_context->cur_query_bo = new_query_bo;\r\nret = vmw_bo_to_validate_list(sw_context,\r\ndev_priv->dummy_query_bo,\r\ndev_priv->has_mob, NULL);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic void vmw_query_bo_switch_commit(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context)\r\n{\r\nif (sw_context->needs_post_query_barrier) {\r\nstruct vmw_res_cache_entry *ctx_entry =\r\n&sw_context->res_cache[vmw_res_context];\r\nstruct vmw_resource *ctx;\r\nint ret;\r\nBUG_ON(!ctx_entry->valid);\r\nctx = ctx_entry->res;\r\nret = vmw_fifo_emit_dummy_query(dev_priv, ctx->id);\r\nif (unlikely(ret != 0))\r\nDRM_ERROR("Out of fifo space for dummy query.\n");\r\n}\r\nif (dev_priv->pinned_bo != sw_context->cur_query_bo) {\r\nif (dev_priv->pinned_bo) {\r\nvmw_bo_pin_reserved(dev_priv->pinned_bo, false);\r\nvmw_dmabuf_unreference(&dev_priv->pinned_bo);\r\n}\r\nif (!sw_context->needs_post_query_barrier) {\r\nvmw_bo_pin_reserved(sw_context->cur_query_bo, true);\r\nif (!dev_priv->dummy_query_bo_pinned) {\r\nvmw_bo_pin_reserved(dev_priv->dummy_query_bo,\r\ntrue);\r\ndev_priv->dummy_query_bo_pinned = true;\r\n}\r\nBUG_ON(sw_context->last_query_ctx == NULL);\r\ndev_priv->query_cid = sw_context->last_query_ctx->id;\r\ndev_priv->query_cid_valid = true;\r\ndev_priv->pinned_bo =\r\nvmw_dmabuf_reference(sw_context->cur_query_bo);\r\n}\r\n}\r\n}\r\nstatic int vmw_translate_mob_ptr(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGAMobId *id,\r\nstruct vmw_dma_buffer **vmw_bo_p)\r\n{\r\nstruct vmw_dma_buffer *vmw_bo = NULL;\r\nuint32_t handle = *id;\r\nstruct vmw_relocation *reloc;\r\nint ret;\r\nret = vmw_user_dmabuf_lookup(sw_context->fp->tfile, handle, &vmw_bo,\r\nNULL);\r\nif (unlikely(ret != 0)) {\r\nDRM_ERROR("Could not find or use MOB buffer.\n");\r\nret = -EINVAL;\r\ngoto out_no_reloc;\r\n}\r\nif (unlikely(sw_context->cur_reloc >= VMWGFX_MAX_RELOCATIONS)) {\r\nDRM_ERROR("Max number relocations per submission"\r\n" exceeded\n");\r\nret = -EINVAL;\r\ngoto out_no_reloc;\r\n}\r\nreloc = &sw_context->relocs[sw_context->cur_reloc++];\r\nreloc->mob_loc = id;\r\nreloc->location = NULL;\r\nret = vmw_bo_to_validate_list(sw_context, vmw_bo, true, &reloc->index);\r\nif (unlikely(ret != 0))\r\ngoto out_no_reloc;\r\n*vmw_bo_p = vmw_bo;\r\nreturn 0;\r\nout_no_reloc:\r\nvmw_dmabuf_unreference(&vmw_bo);\r\n*vmw_bo_p = NULL;\r\nreturn ret;\r\n}\r\nstatic int vmw_translate_guest_ptr(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGAGuestPtr *ptr,\r\nstruct vmw_dma_buffer **vmw_bo_p)\r\n{\r\nstruct vmw_dma_buffer *vmw_bo = NULL;\r\nuint32_t handle = ptr->gmrId;\r\nstruct vmw_relocation *reloc;\r\nint ret;\r\nret = vmw_user_dmabuf_lookup(sw_context->fp->tfile, handle, &vmw_bo,\r\nNULL);\r\nif (unlikely(ret != 0)) {\r\nDRM_ERROR("Could not find or use GMR region.\n");\r\nret = -EINVAL;\r\ngoto out_no_reloc;\r\n}\r\nif (unlikely(sw_context->cur_reloc >= VMWGFX_MAX_RELOCATIONS)) {\r\nDRM_ERROR("Max number relocations per submission"\r\n" exceeded\n");\r\nret = -EINVAL;\r\ngoto out_no_reloc;\r\n}\r\nreloc = &sw_context->relocs[sw_context->cur_reloc++];\r\nreloc->location = ptr;\r\nret = vmw_bo_to_validate_list(sw_context, vmw_bo, false, &reloc->index);\r\nif (unlikely(ret != 0))\r\ngoto out_no_reloc;\r\n*vmw_bo_p = vmw_bo;\r\nreturn 0;\r\nout_no_reloc:\r\nvmw_dmabuf_unreference(&vmw_bo);\r\n*vmw_bo_p = NULL;\r\nreturn ret;\r\n}\r\nstatic int vmw_cmd_dx_define_query(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_dx_define_query_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDXDefineQuery q;\r\n} *cmd;\r\nint ret;\r\nstruct vmw_resource_val_node *ctx_node = sw_context->dx_ctx_node;\r\nstruct vmw_resource *cotable_res;\r\nif (ctx_node == NULL) {\r\nDRM_ERROR("DX Context not set for query.\n");\r\nreturn -EINVAL;\r\n}\r\ncmd = container_of(header, struct vmw_dx_define_query_cmd, header);\r\nif (cmd->q.type < SVGA3D_QUERYTYPE_MIN ||\r\ncmd->q.type >= SVGA3D_QUERYTYPE_MAX)\r\nreturn -EINVAL;\r\ncotable_res = vmw_context_cotable(ctx_node->res, SVGA_COTABLE_DXQUERY);\r\nret = vmw_cotable_notify(cotable_res, cmd->q.queryId);\r\nvmw_resource_unreference(&cotable_res);\r\nreturn ret;\r\n}\r\nstatic int vmw_cmd_dx_bind_query(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_dx_bind_query_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDXBindQuery q;\r\n} *cmd;\r\nstruct vmw_dma_buffer *vmw_bo;\r\nint ret;\r\ncmd = container_of(header, struct vmw_dx_bind_query_cmd, header);\r\nret = vmw_translate_mob_ptr(dev_priv, sw_context, &cmd->q.mobid,\r\n&vmw_bo);\r\nif (ret != 0)\r\nreturn ret;\r\nsw_context->dx_query_mob = vmw_bo;\r\nsw_context->dx_query_ctx = sw_context->dx_ctx_node->res;\r\nvmw_dmabuf_unreference(&vmw_bo);\r\nreturn ret;\r\n}\r\nstatic int vmw_cmd_begin_gb_query(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_begin_gb_query_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdBeginGBQuery q;\r\n} *cmd;\r\ncmd = container_of(header, struct vmw_begin_gb_query_cmd,\r\nheader);\r\nreturn vmw_cmd_res_check(dev_priv, sw_context, vmw_res_context,\r\nuser_context_converter, &cmd->q.cid,\r\nNULL);\r\n}\r\nstatic int vmw_cmd_begin_query(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_begin_query_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdBeginQuery q;\r\n} *cmd;\r\ncmd = container_of(header, struct vmw_begin_query_cmd,\r\nheader);\r\nif (unlikely(dev_priv->has_mob)) {\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdBeginGBQuery q;\r\n} gb_cmd;\r\nBUG_ON(sizeof(gb_cmd) != sizeof(*cmd));\r\ngb_cmd.header.id = SVGA_3D_CMD_BEGIN_GB_QUERY;\r\ngb_cmd.header.size = cmd->header.size;\r\ngb_cmd.q.cid = cmd->q.cid;\r\ngb_cmd.q.type = cmd->q.type;\r\nmemcpy(cmd, &gb_cmd, sizeof(*cmd));\r\nreturn vmw_cmd_begin_gb_query(dev_priv, sw_context, header);\r\n}\r\nreturn vmw_cmd_res_check(dev_priv, sw_context, vmw_res_context,\r\nuser_context_converter, &cmd->q.cid,\r\nNULL);\r\n}\r\nstatic int vmw_cmd_end_gb_query(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_dma_buffer *vmw_bo;\r\nstruct vmw_query_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdEndGBQuery q;\r\n} *cmd;\r\nint ret;\r\ncmd = container_of(header, struct vmw_query_cmd, header);\r\nret = vmw_cmd_cid_check(dev_priv, sw_context, header);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nret = vmw_translate_mob_ptr(dev_priv, sw_context,\r\n&cmd->q.mobid,\r\n&vmw_bo);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nret = vmw_query_bo_switch_prepare(dev_priv, vmw_bo, sw_context);\r\nvmw_dmabuf_unreference(&vmw_bo);\r\nreturn ret;\r\n}\r\nstatic int vmw_cmd_end_query(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_dma_buffer *vmw_bo;\r\nstruct vmw_query_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdEndQuery q;\r\n} *cmd;\r\nint ret;\r\ncmd = container_of(header, struct vmw_query_cmd, header);\r\nif (dev_priv->has_mob) {\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdEndGBQuery q;\r\n} gb_cmd;\r\nBUG_ON(sizeof(gb_cmd) != sizeof(*cmd));\r\ngb_cmd.header.id = SVGA_3D_CMD_END_GB_QUERY;\r\ngb_cmd.header.size = cmd->header.size;\r\ngb_cmd.q.cid = cmd->q.cid;\r\ngb_cmd.q.type = cmd->q.type;\r\ngb_cmd.q.mobid = cmd->q.guestResult.gmrId;\r\ngb_cmd.q.offset = cmd->q.guestResult.offset;\r\nmemcpy(cmd, &gb_cmd, sizeof(*cmd));\r\nreturn vmw_cmd_end_gb_query(dev_priv, sw_context, header);\r\n}\r\nret = vmw_cmd_cid_check(dev_priv, sw_context, header);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nret = vmw_translate_guest_ptr(dev_priv, sw_context,\r\n&cmd->q.guestResult,\r\n&vmw_bo);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nret = vmw_query_bo_switch_prepare(dev_priv, vmw_bo, sw_context);\r\nvmw_dmabuf_unreference(&vmw_bo);\r\nreturn ret;\r\n}\r\nstatic int vmw_cmd_wait_gb_query(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_dma_buffer *vmw_bo;\r\nstruct vmw_query_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdWaitForGBQuery q;\r\n} *cmd;\r\nint ret;\r\ncmd = container_of(header, struct vmw_query_cmd, header);\r\nret = vmw_cmd_cid_check(dev_priv, sw_context, header);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nret = vmw_translate_mob_ptr(dev_priv, sw_context,\r\n&cmd->q.mobid,\r\n&vmw_bo);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nvmw_dmabuf_unreference(&vmw_bo);\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_wait_query(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_dma_buffer *vmw_bo;\r\nstruct vmw_query_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdWaitForQuery q;\r\n} *cmd;\r\nint ret;\r\ncmd = container_of(header, struct vmw_query_cmd, header);\r\nif (dev_priv->has_mob) {\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdWaitForGBQuery q;\r\n} gb_cmd;\r\nBUG_ON(sizeof(gb_cmd) != sizeof(*cmd));\r\ngb_cmd.header.id = SVGA_3D_CMD_WAIT_FOR_GB_QUERY;\r\ngb_cmd.header.size = cmd->header.size;\r\ngb_cmd.q.cid = cmd->q.cid;\r\ngb_cmd.q.type = cmd->q.type;\r\ngb_cmd.q.mobid = cmd->q.guestResult.gmrId;\r\ngb_cmd.q.offset = cmd->q.guestResult.offset;\r\nmemcpy(cmd, &gb_cmd, sizeof(*cmd));\r\nreturn vmw_cmd_wait_gb_query(dev_priv, sw_context, header);\r\n}\r\nret = vmw_cmd_cid_check(dev_priv, sw_context, header);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nret = vmw_translate_guest_ptr(dev_priv, sw_context,\r\n&cmd->q.guestResult,\r\n&vmw_bo);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nvmw_dmabuf_unreference(&vmw_bo);\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_dma(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_dma_buffer *vmw_bo = NULL;\r\nstruct vmw_surface *srf = NULL;\r\nstruct vmw_dma_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdSurfaceDMA dma;\r\n} *cmd;\r\nint ret;\r\nSVGA3dCmdSurfaceDMASuffix *suffix;\r\nuint32_t bo_size;\r\ncmd = container_of(header, struct vmw_dma_cmd, header);\r\nsuffix = (SVGA3dCmdSurfaceDMASuffix *)((unsigned long) &cmd->dma +\r\nheader->size - sizeof(*suffix));\r\nif (unlikely(suffix->suffixSize != sizeof(*suffix))) {\r\nDRM_ERROR("Invalid DMA suffix size.\n");\r\nreturn -EINVAL;\r\n}\r\nret = vmw_translate_guest_ptr(dev_priv, sw_context,\r\n&cmd->dma.guest.ptr,\r\n&vmw_bo);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nbo_size = vmw_bo->base.num_pages * PAGE_SIZE;\r\nif (unlikely(cmd->dma.guest.ptr.offset > bo_size)) {\r\nDRM_ERROR("Invalid DMA offset.\n");\r\nreturn -EINVAL;\r\n}\r\nbo_size -= cmd->dma.guest.ptr.offset;\r\nif (unlikely(suffix->maximumOffset > bo_size))\r\nsuffix->maximumOffset = bo_size;\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter, &cmd->dma.host.sid,\r\nNULL);\r\nif (unlikely(ret != 0)) {\r\nif (unlikely(ret != -ERESTARTSYS))\r\nDRM_ERROR("could not find surface for DMA.\n");\r\ngoto out_no_surface;\r\n}\r\nsrf = vmw_res_to_srf(sw_context->res_cache[vmw_res_surface].res);\r\nvmw_kms_cursor_snoop(srf, sw_context->fp->tfile, &vmw_bo->base,\r\nheader);\r\nout_no_surface:\r\nvmw_dmabuf_unreference(&vmw_bo);\r\nreturn ret;\r\n}\r\nstatic int vmw_cmd_draw(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_draw_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDrawPrimitives body;\r\n} *cmd;\r\nSVGA3dVertexDecl *decl = (SVGA3dVertexDecl *)(\r\n(unsigned long)header + sizeof(*cmd));\r\nSVGA3dPrimitiveRange *range;\r\nuint32_t i;\r\nuint32_t maxnum;\r\nint ret;\r\nret = vmw_cmd_cid_check(dev_priv, sw_context, header);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\ncmd = container_of(header, struct vmw_draw_cmd, header);\r\nmaxnum = (header->size - sizeof(cmd->body)) / sizeof(*decl);\r\nif (unlikely(cmd->body.numVertexDecls > maxnum)) {\r\nDRM_ERROR("Illegal number of vertex declarations.\n");\r\nreturn -EINVAL;\r\n}\r\nfor (i = 0; i < cmd->body.numVertexDecls; ++i, ++decl) {\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&decl->array.surfaceId, NULL);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n}\r\nmaxnum = (header->size - sizeof(cmd->body) -\r\ncmd->body.numVertexDecls * sizeof(*decl)) / sizeof(*range);\r\nif (unlikely(cmd->body.numRanges > maxnum)) {\r\nDRM_ERROR("Illegal number of index ranges.\n");\r\nreturn -EINVAL;\r\n}\r\nrange = (SVGA3dPrimitiveRange *) decl;\r\nfor (i = 0; i < cmd->body.numRanges; ++i, ++range) {\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&range->indexArray.surfaceId, NULL);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_tex_state(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_tex_state_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdSetTextureState state;\r\n} *cmd;\r\nSVGA3dTextureState *last_state = (SVGA3dTextureState *)\r\n((unsigned long) header + header->size + sizeof(header));\r\nSVGA3dTextureState *cur_state = (SVGA3dTextureState *)\r\n((unsigned long) header + sizeof(struct vmw_tex_state_cmd));\r\nstruct vmw_resource_val_node *ctx_node;\r\nstruct vmw_resource_val_node *res_node;\r\nint ret;\r\ncmd = container_of(header, struct vmw_tex_state_cmd,\r\nheader);\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_context,\r\nuser_context_converter, &cmd->state.cid,\r\n&ctx_node);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nfor (; cur_state < last_state; ++cur_state) {\r\nif (likely(cur_state->name != SVGA3D_TS_BIND_TEXTURE))\r\ncontinue;\r\nif (cur_state->stage >= SVGA3D_NUM_TEXTURE_UNITS) {\r\nDRM_ERROR("Illegal texture/sampler unit %u.\n",\r\n(unsigned) cur_state->stage);\r\nreturn -EINVAL;\r\n}\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cur_state->value, &res_node);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nif (dev_priv->has_mob) {\r\nstruct vmw_ctx_bindinfo_tex binding;\r\nbinding.bi.ctx = ctx_node->res;\r\nbinding.bi.res = res_node ? res_node->res : NULL;\r\nbinding.bi.bt = vmw_ctx_binding_tex;\r\nbinding.texture_stage = cur_state->stage;\r\nvmw_binding_add(ctx_node->staged_bindings, &binding.bi,\r\n0, binding.texture_stage);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_check_define_gmrfb(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nvoid *buf)\r\n{\r\nstruct vmw_dma_buffer *vmw_bo;\r\nint ret;\r\nstruct {\r\nuint32_t header;\r\nSVGAFifoCmdDefineGMRFB body;\r\n} *cmd = buf;\r\nret = vmw_translate_guest_ptr(dev_priv, sw_context,\r\n&cmd->body.ptr,\r\n&vmw_bo);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nvmw_dmabuf_unreference(&vmw_bo);\r\nreturn ret;\r\n}\r\nstatic int vmw_cmd_res_switch_backup(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nstruct vmw_resource_val_node *val_node,\r\nuint32_t *buf_id,\r\nunsigned long backup_offset)\r\n{\r\nstruct vmw_dma_buffer *dma_buf;\r\nint ret;\r\nret = vmw_translate_mob_ptr(dev_priv, sw_context, buf_id, &dma_buf);\r\nif (ret)\r\nreturn ret;\r\nval_node->switching_backup = true;\r\nif (val_node->first_usage)\r\nval_node->no_buffer_needed = true;\r\nvmw_dmabuf_unreference(&val_node->new_backup);\r\nval_node->new_backup = dma_buf;\r\nval_node->new_backup_offset = backup_offset;\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_switch_backup(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nenum vmw_res_type res_type,\r\nconst struct vmw_user_resource_conv\r\n*converter,\r\nuint32_t *res_id,\r\nuint32_t *buf_id,\r\nunsigned long backup_offset)\r\n{\r\nstruct vmw_resource_val_node *val_node;\r\nint ret;\r\nret = vmw_cmd_res_check(dev_priv, sw_context, res_type,\r\nconverter, res_id, &val_node);\r\nif (ret)\r\nreturn ret;\r\nreturn vmw_cmd_res_switch_backup(dev_priv, sw_context, val_node,\r\nbuf_id, backup_offset);\r\n}\r\nstatic int vmw_cmd_bind_gb_surface(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_bind_gb_surface_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdBindGBSurface body;\r\n} *cmd;\r\ncmd = container_of(header, struct vmw_bind_gb_surface_cmd, header);\r\nreturn vmw_cmd_switch_backup(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->body.sid, &cmd->body.mobid,\r\n0);\r\n}\r\nstatic int vmw_cmd_update_gb_image(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_gb_surface_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdUpdateGBImage body;\r\n} *cmd;\r\ncmd = container_of(header, struct vmw_gb_surface_cmd, header);\r\nreturn vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->body.image.sid, NULL);\r\n}\r\nstatic int vmw_cmd_update_gb_surface(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_gb_surface_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdUpdateGBSurface body;\r\n} *cmd;\r\ncmd = container_of(header, struct vmw_gb_surface_cmd, header);\r\nreturn vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->body.sid, NULL);\r\n}\r\nstatic int vmw_cmd_readback_gb_image(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_gb_surface_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdReadbackGBImage body;\r\n} *cmd;\r\ncmd = container_of(header, struct vmw_gb_surface_cmd, header);\r\nreturn vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->body.image.sid, NULL);\r\n}\r\nstatic int vmw_cmd_readback_gb_surface(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_gb_surface_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdReadbackGBSurface body;\r\n} *cmd;\r\ncmd = container_of(header, struct vmw_gb_surface_cmd, header);\r\nreturn vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->body.sid, NULL);\r\n}\r\nstatic int vmw_cmd_invalidate_gb_image(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_gb_surface_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdInvalidateGBImage body;\r\n} *cmd;\r\ncmd = container_of(header, struct vmw_gb_surface_cmd, header);\r\nreturn vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->body.image.sid, NULL);\r\n}\r\nstatic int vmw_cmd_invalidate_gb_surface(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_gb_surface_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdInvalidateGBSurface body;\r\n} *cmd;\r\ncmd = container_of(header, struct vmw_gb_surface_cmd, header);\r\nreturn vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->body.sid, NULL);\r\n}\r\nstatic int vmw_cmd_shader_define(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_shader_define_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDefineShader body;\r\n} *cmd;\r\nint ret;\r\nsize_t size;\r\nstruct vmw_resource_val_node *val;\r\ncmd = container_of(header, struct vmw_shader_define_cmd,\r\nheader);\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_context,\r\nuser_context_converter, &cmd->body.cid,\r\n&val);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nif (unlikely(!dev_priv->has_mob))\r\nreturn 0;\r\nsize = cmd->header.size - sizeof(cmd->body);\r\nret = vmw_compat_shader_add(dev_priv,\r\nvmw_context_res_man(val->res),\r\ncmd->body.shid, cmd + 1,\r\ncmd->body.type, size,\r\n&sw_context->staged_cmd_res);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nreturn vmw_resource_relocation_add(&sw_context->res_relocations,\r\nNULL, &cmd->header.id -\r\nsw_context->buf_start);\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_shader_destroy(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_shader_destroy_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDestroyShader body;\r\n} *cmd;\r\nint ret;\r\nstruct vmw_resource_val_node *val;\r\ncmd = container_of(header, struct vmw_shader_destroy_cmd,\r\nheader);\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_context,\r\nuser_context_converter, &cmd->body.cid,\r\n&val);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nif (unlikely(!dev_priv->has_mob))\r\nreturn 0;\r\nret = vmw_shader_remove(vmw_context_res_man(val->res),\r\ncmd->body.shid,\r\ncmd->body.type,\r\n&sw_context->staged_cmd_res);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nreturn vmw_resource_relocation_add(&sw_context->res_relocations,\r\nNULL, &cmd->header.id -\r\nsw_context->buf_start);\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_set_shader(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_set_shader_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdSetShader body;\r\n} *cmd;\r\nstruct vmw_resource_val_node *ctx_node, *res_node = NULL;\r\nstruct vmw_ctx_bindinfo_shader binding;\r\nstruct vmw_resource *res = NULL;\r\nint ret;\r\ncmd = container_of(header, struct vmw_set_shader_cmd,\r\nheader);\r\nif (cmd->body.type >= SVGA3D_SHADERTYPE_PREDX_MAX) {\r\nDRM_ERROR("Illegal shader type %u.\n",\r\n(unsigned) cmd->body.type);\r\nreturn -EINVAL;\r\n}\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_context,\r\nuser_context_converter, &cmd->body.cid,\r\n&ctx_node);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nif (!dev_priv->has_mob)\r\nreturn 0;\r\nif (cmd->body.shid != SVGA3D_INVALID_ID) {\r\nres = vmw_shader_lookup(vmw_context_res_man(ctx_node->res),\r\ncmd->body.shid,\r\ncmd->body.type);\r\nif (!IS_ERR(res)) {\r\nret = vmw_cmd_res_reloc_add(dev_priv, sw_context,\r\n&cmd->body.shid, res,\r\n&res_node);\r\nvmw_resource_unreference(&res);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n}\r\n}\r\nif (!res_node) {\r\nret = vmw_cmd_res_check(dev_priv, sw_context,\r\nvmw_res_shader,\r\nuser_shader_converter,\r\n&cmd->body.shid, &res_node);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n}\r\nbinding.bi.ctx = ctx_node->res;\r\nbinding.bi.res = res_node ? res_node->res : NULL;\r\nbinding.bi.bt = vmw_ctx_binding_shader;\r\nbinding.shader_slot = cmd->body.type - SVGA3D_SHADERTYPE_MIN;\r\nvmw_binding_add(ctx_node->staged_bindings, &binding.bi,\r\nbinding.shader_slot, 0);\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_set_shader_const(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_set_shader_const_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdSetShaderConst body;\r\n} *cmd;\r\nint ret;\r\ncmd = container_of(header, struct vmw_set_shader_const_cmd,\r\nheader);\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_context,\r\nuser_context_converter, &cmd->body.cid,\r\nNULL);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nif (dev_priv->has_mob)\r\nheader->id = SVGA_3D_CMD_SET_GB_SHADERCONSTS_INLINE;\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_bind_gb_shader(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_bind_gb_shader_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdBindGBShader body;\r\n} *cmd;\r\ncmd = container_of(header, struct vmw_bind_gb_shader_cmd,\r\nheader);\r\nreturn vmw_cmd_switch_backup(dev_priv, sw_context, vmw_res_shader,\r\nuser_shader_converter,\r\n&cmd->body.shid, &cmd->body.mobid,\r\ncmd->body.offsetInBytes);\r\n}\r\nstatic int\r\nvmw_cmd_dx_set_single_constant_buffer(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDXSetSingleConstantBuffer body;\r\n} *cmd;\r\nstruct vmw_resource_val_node *res_node = NULL;\r\nstruct vmw_resource_val_node *ctx_node = sw_context->dx_ctx_node;\r\nstruct vmw_ctx_bindinfo_cb binding;\r\nint ret;\r\nif (unlikely(ctx_node == NULL)) {\r\nDRM_ERROR("DX Context not set.\n");\r\nreturn -EINVAL;\r\n}\r\ncmd = container_of(header, typeof(*cmd), header);\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->body.sid, &res_node);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nbinding.bi.ctx = ctx_node->res;\r\nbinding.bi.res = res_node ? res_node->res : NULL;\r\nbinding.bi.bt = vmw_ctx_binding_cb;\r\nbinding.shader_slot = cmd->body.type - SVGA3D_SHADERTYPE_MIN;\r\nbinding.offset = cmd->body.offsetInBytes;\r\nbinding.size = cmd->body.sizeInBytes;\r\nbinding.slot = cmd->body.slot;\r\nif (binding.shader_slot >= SVGA3D_NUM_SHADERTYPE_DX10 ||\r\nbinding.slot >= SVGA3D_DX_MAX_CONSTBUFFERS) {\r\nDRM_ERROR("Illegal const buffer shader %u slot %u.\n",\r\n(unsigned) cmd->body.type,\r\n(unsigned) binding.slot);\r\nreturn -EINVAL;\r\n}\r\nvmw_binding_add(ctx_node->staged_bindings, &binding.bi,\r\nbinding.shader_slot, binding.slot);\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_dx_set_shader_res(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDXSetShaderResources body;\r\n} *cmd = container_of(header, typeof(*cmd), header);\r\nu32 num_sr_view = (cmd->header.size - sizeof(cmd->body)) /\r\nsizeof(SVGA3dShaderResourceViewId);\r\nif ((u64) cmd->body.startView + (u64) num_sr_view >\r\n(u64) SVGA3D_DX_MAX_SRVIEWS ||\r\ncmd->body.type >= SVGA3D_SHADERTYPE_DX10_MAX) {\r\nDRM_ERROR("Invalid shader binding.\n");\r\nreturn -EINVAL;\r\n}\r\nreturn vmw_view_bindings_add(sw_context, vmw_view_sr,\r\nvmw_ctx_binding_sr,\r\ncmd->body.type - SVGA3D_SHADERTYPE_MIN,\r\n(void *) &cmd[1], num_sr_view,\r\ncmd->body.startView);\r\n}\r\nstatic int vmw_cmd_dx_set_shader(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDXSetShader body;\r\n} *cmd;\r\nstruct vmw_resource *res = NULL;\r\nstruct vmw_resource_val_node *ctx_node = sw_context->dx_ctx_node;\r\nstruct vmw_ctx_bindinfo_shader binding;\r\nint ret = 0;\r\nif (unlikely(ctx_node == NULL)) {\r\nDRM_ERROR("DX Context not set.\n");\r\nreturn -EINVAL;\r\n}\r\ncmd = container_of(header, typeof(*cmd), header);\r\nif (cmd->body.type >= SVGA3D_SHADERTYPE_DX10_MAX) {\r\nDRM_ERROR("Illegal shader type %u.\n",\r\n(unsigned) cmd->body.type);\r\nreturn -EINVAL;\r\n}\r\nif (cmd->body.shaderId != SVGA3D_INVALID_ID) {\r\nres = vmw_shader_lookup(sw_context->man, cmd->body.shaderId, 0);\r\nif (IS_ERR(res)) {\r\nDRM_ERROR("Could not find shader for binding.\n");\r\nreturn PTR_ERR(res);\r\n}\r\nret = vmw_resource_val_add(sw_context, res, NULL);\r\nif (ret)\r\ngoto out_unref;\r\n}\r\nbinding.bi.ctx = ctx_node->res;\r\nbinding.bi.res = res;\r\nbinding.bi.bt = vmw_ctx_binding_dx_shader;\r\nbinding.shader_slot = cmd->body.type - SVGA3D_SHADERTYPE_MIN;\r\nvmw_binding_add(ctx_node->staged_bindings, &binding.bi,\r\nbinding.shader_slot, 0);\r\nout_unref:\r\nif (res)\r\nvmw_resource_unreference(&res);\r\nreturn ret;\r\n}\r\nstatic int vmw_cmd_dx_set_vertex_buffers(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_resource_val_node *ctx_node = sw_context->dx_ctx_node;\r\nstruct vmw_ctx_bindinfo_vb binding;\r\nstruct vmw_resource_val_node *res_node;\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDXSetVertexBuffers body;\r\nSVGA3dVertexBuffer buf[];\r\n} *cmd;\r\nint i, ret, num;\r\nif (unlikely(ctx_node == NULL)) {\r\nDRM_ERROR("DX Context not set.\n");\r\nreturn -EINVAL;\r\n}\r\ncmd = container_of(header, typeof(*cmd), header);\r\nnum = (cmd->header.size - sizeof(cmd->body)) /\r\nsizeof(SVGA3dVertexBuffer);\r\nif ((u64)num + (u64)cmd->body.startBuffer >\r\n(u64)SVGA3D_DX_MAX_VERTEXBUFFERS) {\r\nDRM_ERROR("Invalid number of vertex buffers.\n");\r\nreturn -EINVAL;\r\n}\r\nfor (i = 0; i < num; i++) {\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->buf[i].sid, &res_node);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nbinding.bi.ctx = ctx_node->res;\r\nbinding.bi.bt = vmw_ctx_binding_vb;\r\nbinding.bi.res = ((res_node) ? res_node->res : NULL);\r\nbinding.offset = cmd->buf[i].offset;\r\nbinding.stride = cmd->buf[i].stride;\r\nbinding.slot = i + cmd->body.startBuffer;\r\nvmw_binding_add(ctx_node->staged_bindings, &binding.bi,\r\n0, binding.slot);\r\n}\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_dx_set_index_buffer(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_resource_val_node *ctx_node = sw_context->dx_ctx_node;\r\nstruct vmw_ctx_bindinfo_ib binding;\r\nstruct vmw_resource_val_node *res_node;\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDXSetIndexBuffer body;\r\n} *cmd;\r\nint ret;\r\nif (unlikely(ctx_node == NULL)) {\r\nDRM_ERROR("DX Context not set.\n");\r\nreturn -EINVAL;\r\n}\r\ncmd = container_of(header, typeof(*cmd), header);\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->body.sid, &res_node);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nbinding.bi.ctx = ctx_node->res;\r\nbinding.bi.res = ((res_node) ? res_node->res : NULL);\r\nbinding.bi.bt = vmw_ctx_binding_ib;\r\nbinding.offset = cmd->body.offset;\r\nbinding.format = cmd->body.format;\r\nvmw_binding_add(ctx_node->staged_bindings, &binding.bi, 0, 0);\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_dx_set_rendertargets(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDXSetRenderTargets body;\r\n} *cmd = container_of(header, typeof(*cmd), header);\r\nint ret;\r\nu32 num_rt_view = (cmd->header.size - sizeof(cmd->body)) /\r\nsizeof(SVGA3dRenderTargetViewId);\r\nif (num_rt_view > SVGA3D_MAX_SIMULTANEOUS_RENDER_TARGETS) {\r\nDRM_ERROR("Invalid DX Rendertarget binding.\n");\r\nreturn -EINVAL;\r\n}\r\nret = vmw_view_bindings_add(sw_context, vmw_view_ds,\r\nvmw_ctx_binding_ds, 0,\r\n&cmd->body.depthStencilViewId, 1, 0);\r\nif (ret)\r\nreturn ret;\r\nreturn vmw_view_bindings_add(sw_context, vmw_view_rt,\r\nvmw_ctx_binding_dx_rt, 0,\r\n(void *)&cmd[1], num_rt_view, 0);\r\n}\r\nstatic int vmw_cmd_dx_clear_rendertarget_view(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDXClearRenderTargetView body;\r\n} *cmd = container_of(header, typeof(*cmd), header);\r\nreturn vmw_view_id_val_add(sw_context, vmw_view_rt,\r\ncmd->body.renderTargetViewId);\r\n}\r\nstatic int vmw_cmd_dx_clear_depthstencil_view(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDXClearDepthStencilView body;\r\n} *cmd = container_of(header, typeof(*cmd), header);\r\nreturn vmw_view_id_val_add(sw_context, vmw_view_ds,\r\ncmd->body.depthStencilViewId);\r\n}\r\nstatic int vmw_cmd_dx_view_define(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_resource_val_node *ctx_node = sw_context->dx_ctx_node;\r\nstruct vmw_resource_val_node *srf_node;\r\nstruct vmw_resource *res;\r\nenum vmw_view_type view_type;\r\nint ret;\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nuint32 defined_id;\r\nuint32 sid;\r\n} *cmd;\r\nif (unlikely(ctx_node == NULL)) {\r\nDRM_ERROR("DX Context not set.\n");\r\nreturn -EINVAL;\r\n}\r\nview_type = vmw_view_cmd_to_type(header->id);\r\ncmd = container_of(header, typeof(*cmd), header);\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->sid, &srf_node);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nres = vmw_context_cotable(ctx_node->res, vmw_view_cotables[view_type]);\r\nret = vmw_cotable_notify(res, cmd->defined_id);\r\nvmw_resource_unreference(&res);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nreturn vmw_view_add(sw_context->man,\r\nctx_node->res,\r\nsrf_node->res,\r\nview_type,\r\ncmd->defined_id,\r\nheader,\r\nheader->size + sizeof(*header),\r\n&sw_context->staged_cmd_res);\r\n}\r\nstatic int vmw_cmd_dx_set_so_targets(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_resource_val_node *ctx_node = sw_context->dx_ctx_node;\r\nstruct vmw_ctx_bindinfo_so binding;\r\nstruct vmw_resource_val_node *res_node;\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDXSetSOTargets body;\r\nSVGA3dSoTarget targets[];\r\n} *cmd;\r\nint i, ret, num;\r\nif (unlikely(ctx_node == NULL)) {\r\nDRM_ERROR("DX Context not set.\n");\r\nreturn -EINVAL;\r\n}\r\ncmd = container_of(header, typeof(*cmd), header);\r\nnum = (cmd->header.size - sizeof(cmd->body)) /\r\nsizeof(SVGA3dSoTarget);\r\nif (num > SVGA3D_DX_MAX_SOTARGETS) {\r\nDRM_ERROR("Invalid DX SO binding.\n");\r\nreturn -EINVAL;\r\n}\r\nfor (i = 0; i < num; i++) {\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->targets[i].sid, &res_node);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nbinding.bi.ctx = ctx_node->res;\r\nbinding.bi.res = ((res_node) ? res_node->res : NULL);\r\nbinding.bi.bt = vmw_ctx_binding_so,\r\nbinding.offset = cmd->targets[i].offset;\r\nbinding.size = cmd->targets[i].sizeInBytes;\r\nbinding.slot = i;\r\nvmw_binding_add(ctx_node->staged_bindings, &binding.bi,\r\n0, binding.slot);\r\n}\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_dx_so_define(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_resource_val_node *ctx_node = sw_context->dx_ctx_node;\r\nstruct vmw_resource *res;\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nuint32 defined_id;\r\n} *cmd;\r\nenum vmw_so_type so_type;\r\nint ret;\r\nif (unlikely(ctx_node == NULL)) {\r\nDRM_ERROR("DX Context not set.\n");\r\nreturn -EINVAL;\r\n}\r\nso_type = vmw_so_cmd_to_type(header->id);\r\nres = vmw_context_cotable(ctx_node->res, vmw_so_cotables[so_type]);\r\ncmd = container_of(header, typeof(*cmd), header);\r\nret = vmw_cotable_notify(res, cmd->defined_id);\r\nvmw_resource_unreference(&res);\r\nreturn ret;\r\n}\r\nstatic int vmw_cmd_dx_check_subresource(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nunion {\r\nSVGA3dCmdDXReadbackSubResource r_body;\r\nSVGA3dCmdDXInvalidateSubResource i_body;\r\nSVGA3dCmdDXUpdateSubResource u_body;\r\nSVGA3dSurfaceId sid;\r\n};\r\n} *cmd;\r\nBUILD_BUG_ON(offsetof(typeof(*cmd), r_body.sid) !=\r\noffsetof(typeof(*cmd), sid));\r\nBUILD_BUG_ON(offsetof(typeof(*cmd), i_body.sid) !=\r\noffsetof(typeof(*cmd), sid));\r\nBUILD_BUG_ON(offsetof(typeof(*cmd), u_body.sid) !=\r\noffsetof(typeof(*cmd), sid));\r\ncmd = container_of(header, typeof(*cmd), header);\r\nreturn vmw_cmd_res_check(dev_priv, sw_context, vmw_res_surface,\r\nuser_surface_converter,\r\n&cmd->sid, NULL);\r\n}\r\nstatic int vmw_cmd_dx_cid_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_resource_val_node *ctx_node = sw_context->dx_ctx_node;\r\nif (unlikely(ctx_node == NULL)) {\r\nDRM_ERROR("DX Context not set.\n");\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_dx_view_remove(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_resource_val_node *ctx_node = sw_context->dx_ctx_node;\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nunion vmw_view_destroy body;\r\n} *cmd = container_of(header, typeof(*cmd), header);\r\nenum vmw_view_type view_type = vmw_view_cmd_to_type(header->id);\r\nstruct vmw_resource *view;\r\nint ret;\r\nif (!ctx_node) {\r\nDRM_ERROR("DX Context not set.\n");\r\nreturn -EINVAL;\r\n}\r\nret = vmw_view_remove(sw_context->man,\r\ncmd->body.view_id, view_type,\r\n&sw_context->staged_cmd_res,\r\n&view);\r\nif (ret || !view)\r\nreturn ret;\r\nreturn vmw_view_res_val_add(sw_context, view);\r\n}\r\nstatic int vmw_cmd_dx_define_shader(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_resource_val_node *ctx_node = sw_context->dx_ctx_node;\r\nstruct vmw_resource *res;\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDXDefineShader body;\r\n} *cmd = container_of(header, typeof(*cmd), header);\r\nint ret;\r\nif (!ctx_node) {\r\nDRM_ERROR("DX Context not set.\n");\r\nreturn -EINVAL;\r\n}\r\nres = vmw_context_cotable(ctx_node->res, SVGA_COTABLE_DXSHADER);\r\nret = vmw_cotable_notify(res, cmd->body.shaderId);\r\nvmw_resource_unreference(&res);\r\nif (ret)\r\nreturn ret;\r\nreturn vmw_dx_shader_add(sw_context->man, ctx_node->res,\r\ncmd->body.shaderId, cmd->body.type,\r\n&sw_context->staged_cmd_res);\r\n}\r\nstatic int vmw_cmd_dx_destroy_shader(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_resource_val_node *ctx_node = sw_context->dx_ctx_node;\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDXDestroyShader body;\r\n} *cmd = container_of(header, typeof(*cmd), header);\r\nint ret;\r\nif (!ctx_node) {\r\nDRM_ERROR("DX Context not set.\n");\r\nreturn -EINVAL;\r\n}\r\nret = vmw_shader_remove(sw_context->man, cmd->body.shaderId, 0,\r\n&sw_context->staged_cmd_res);\r\nif (ret)\r\nDRM_ERROR("Could not find shader to remove.\n");\r\nreturn ret;\r\n}\r\nstatic int vmw_cmd_dx_bind_shader(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_resource_val_node *ctx_node;\r\nstruct vmw_resource_val_node *res_node;\r\nstruct vmw_resource *res;\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDXBindShader body;\r\n} *cmd = container_of(header, typeof(*cmd), header);\r\nint ret;\r\nif (cmd->body.cid != SVGA3D_INVALID_ID) {\r\nret = vmw_cmd_res_check(dev_priv, sw_context, vmw_res_context,\r\nuser_context_converter,\r\n&cmd->body.cid, &ctx_node);\r\nif (ret)\r\nreturn ret;\r\n} else {\r\nctx_node = sw_context->dx_ctx_node;\r\nif (!ctx_node) {\r\nDRM_ERROR("DX Context not set.\n");\r\nreturn -EINVAL;\r\n}\r\n}\r\nres = vmw_shader_lookup(vmw_context_res_man(ctx_node->res),\r\ncmd->body.shid, 0);\r\nif (IS_ERR(res)) {\r\nDRM_ERROR("Could not find shader to bind.\n");\r\nreturn PTR_ERR(res);\r\n}\r\nret = vmw_resource_val_add(sw_context, res, &res_node);\r\nif (ret) {\r\nDRM_ERROR("Error creating resource validation node.\n");\r\ngoto out_unref;\r\n}\r\nret = vmw_cmd_res_switch_backup(dev_priv, sw_context, res_node,\r\n&cmd->body.mobid,\r\ncmd->body.offsetInBytes);\r\nout_unref:\r\nvmw_resource_unreference(&res);\r\nreturn ret;\r\n}\r\nstatic int vmw_cmd_dx_genmips(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDXGenMips body;\r\n} *cmd = container_of(header, typeof(*cmd), header);\r\nreturn vmw_view_id_val_add(sw_context, vmw_view_sr,\r\ncmd->body.shaderResourceViewId);\r\n}\r\nstatic int vmw_cmd_check_not_3d(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nvoid *buf, uint32_t *size)\r\n{\r\nuint32_t size_remaining = *size;\r\nuint32_t cmd_id;\r\ncmd_id = ((uint32_t *)buf)[0];\r\nswitch (cmd_id) {\r\ncase SVGA_CMD_UPDATE:\r\n*size = sizeof(uint32_t) + sizeof(SVGAFifoCmdUpdate);\r\nbreak;\r\ncase SVGA_CMD_DEFINE_GMRFB:\r\n*size = sizeof(uint32_t) + sizeof(SVGAFifoCmdDefineGMRFB);\r\nbreak;\r\ncase SVGA_CMD_BLIT_GMRFB_TO_SCREEN:\r\n*size = sizeof(uint32_t) + sizeof(SVGAFifoCmdBlitGMRFBToScreen);\r\nbreak;\r\ncase SVGA_CMD_BLIT_SCREEN_TO_GMRFB:\r\n*size = sizeof(uint32_t) + sizeof(SVGAFifoCmdBlitGMRFBToScreen);\r\nbreak;\r\ndefault:\r\nDRM_ERROR("Unsupported SVGA command: %u.\n", cmd_id);\r\nreturn -EINVAL;\r\n}\r\nif (*size > size_remaining) {\r\nDRM_ERROR("Invalid SVGA command (size mismatch):"\r\n" %u.\n", cmd_id);\r\nreturn -EINVAL;\r\n}\r\nif (unlikely(!sw_context->kernel)) {\r\nDRM_ERROR("Kernel only SVGA command: %u.\n", cmd_id);\r\nreturn -EPERM;\r\n}\r\nif (cmd_id == SVGA_CMD_DEFINE_GMRFB)\r\nreturn vmw_cmd_check_define_gmrfb(dev_priv, sw_context, buf);\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nvoid *buf, uint32_t *size)\r\n{\r\nuint32_t cmd_id;\r\nuint32_t size_remaining = *size;\r\nSVGA3dCmdHeader *header = (SVGA3dCmdHeader *) buf;\r\nint ret;\r\nconst struct vmw_cmd_entry *entry;\r\nbool gb = dev_priv->capabilities & SVGA_CAP_GBOBJECTS;\r\ncmd_id = ((uint32_t *)buf)[0];\r\nif (unlikely(cmd_id < SVGA_CMD_MAX))\r\nreturn vmw_cmd_check_not_3d(dev_priv, sw_context, buf, size);\r\ncmd_id = header->id;\r\n*size = header->size + sizeof(SVGA3dCmdHeader);\r\ncmd_id -= SVGA_3D_CMD_BASE;\r\nif (unlikely(*size > size_remaining))\r\ngoto out_invalid;\r\nif (unlikely(cmd_id >= SVGA_3D_CMD_MAX - SVGA_3D_CMD_BASE))\r\ngoto out_invalid;\r\nentry = &vmw_cmd_entries[cmd_id];\r\nif (unlikely(!entry->func))\r\ngoto out_invalid;\r\nif (unlikely(!entry->user_allow && !sw_context->kernel))\r\ngoto out_privileged;\r\nif (unlikely(entry->gb_disable && gb))\r\ngoto out_old;\r\nif (unlikely(entry->gb_enable && !gb))\r\ngoto out_new;\r\nret = entry->func(dev_priv, sw_context, header);\r\nif (unlikely(ret != 0))\r\ngoto out_invalid;\r\nreturn 0;\r\nout_invalid:\r\nDRM_ERROR("Invalid SVGA3D command: %d\n",\r\ncmd_id + SVGA_3D_CMD_BASE);\r\nreturn -EINVAL;\r\nout_privileged:\r\nDRM_ERROR("Privileged SVGA3D command: %d\n",\r\ncmd_id + SVGA_3D_CMD_BASE);\r\nreturn -EPERM;\r\nout_old:\r\nDRM_ERROR("Deprecated (disallowed) SVGA3D command: %d\n",\r\ncmd_id + SVGA_3D_CMD_BASE);\r\nreturn -EINVAL;\r\nout_new:\r\nDRM_ERROR("SVGA3D command: %d not supported by virtual hardware.\n",\r\ncmd_id + SVGA_3D_CMD_BASE);\r\nreturn -EINVAL;\r\n}\r\nstatic int vmw_cmd_check_all(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nvoid *buf,\r\nuint32_t size)\r\n{\r\nint32_t cur_size = size;\r\nint ret;\r\nsw_context->buf_start = buf;\r\nwhile (cur_size > 0) {\r\nsize = cur_size;\r\nret = vmw_cmd_check(dev_priv, sw_context, buf, &size);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nbuf = (void *)((unsigned long) buf + size);\r\ncur_size -= size;\r\n}\r\nif (unlikely(cur_size != 0)) {\r\nDRM_ERROR("Command verifier out of sync.\n");\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic void vmw_free_relocations(struct vmw_sw_context *sw_context)\r\n{\r\nsw_context->cur_reloc = 0;\r\n}\r\nstatic void vmw_apply_relocations(struct vmw_sw_context *sw_context)\r\n{\r\nuint32_t i;\r\nstruct vmw_relocation *reloc;\r\nstruct ttm_validate_buffer *validate;\r\nstruct ttm_buffer_object *bo;\r\nfor (i = 0; i < sw_context->cur_reloc; ++i) {\r\nreloc = &sw_context->relocs[i];\r\nvalidate = &sw_context->val_bufs[reloc->index].base;\r\nbo = validate->bo;\r\nswitch (bo->mem.mem_type) {\r\ncase TTM_PL_VRAM:\r\nreloc->location->offset += bo->offset;\r\nreloc->location->gmrId = SVGA_GMR_FRAMEBUFFER;\r\nbreak;\r\ncase VMW_PL_GMR:\r\nreloc->location->gmrId = bo->mem.start;\r\nbreak;\r\ncase VMW_PL_MOB:\r\n*reloc->mob_loc = bo->mem.start;\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\n}\r\nvmw_free_relocations(sw_context);\r\n}\r\nstatic void vmw_resource_list_unreference(struct vmw_sw_context *sw_context,\r\nstruct list_head *list)\r\n{\r\nstruct vmw_resource_val_node *val, *val_next;\r\nlist_for_each_entry_safe(val, val_next, list, head) {\r\nlist_del_init(&val->head);\r\nvmw_resource_unreference(&val->res);\r\nif (val->staged_bindings) {\r\nif (val->staged_bindings != sw_context->staged_bindings)\r\nvmw_binding_state_free(val->staged_bindings);\r\nelse\r\nsw_context->staged_bindings_inuse = false;\r\nval->staged_bindings = NULL;\r\n}\r\nkfree(val);\r\n}\r\n}\r\nstatic void vmw_clear_validations(struct vmw_sw_context *sw_context)\r\n{\r\nstruct vmw_validate_buffer *entry, *next;\r\nstruct vmw_resource_val_node *val;\r\nlist_for_each_entry_safe(entry, next, &sw_context->validate_nodes,\r\nbase.head) {\r\nlist_del(&entry->base.head);\r\nttm_bo_unref(&entry->base.bo);\r\n(void) drm_ht_remove_item(&sw_context->res_ht, &entry->hash);\r\nsw_context->cur_val_buf--;\r\n}\r\nBUG_ON(sw_context->cur_val_buf != 0);\r\nlist_for_each_entry(val, &sw_context->resource_list, head)\r\n(void) drm_ht_remove_item(&sw_context->res_ht, &val->hash);\r\n}\r\nint vmw_validate_single_buffer(struct vmw_private *dev_priv,\r\nstruct ttm_buffer_object *bo,\r\nbool interruptible,\r\nbool validate_as_mob)\r\n{\r\nstruct vmw_dma_buffer *vbo = container_of(bo, struct vmw_dma_buffer,\r\nbase);\r\nint ret;\r\nif (vbo->pin_count > 0)\r\nreturn 0;\r\nif (validate_as_mob)\r\nreturn ttm_bo_validate(bo, &vmw_mob_placement, interruptible,\r\nfalse);\r\nret = ttm_bo_validate(bo, &vmw_vram_gmr_placement, interruptible,\r\nfalse);\r\nif (likely(ret == 0 || ret == -ERESTARTSYS))\r\nreturn ret;\r\nret = ttm_bo_validate(bo, &vmw_vram_placement, interruptible, false);\r\nreturn ret;\r\n}\r\nstatic int vmw_validate_buffers(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context)\r\n{\r\nstruct vmw_validate_buffer *entry;\r\nint ret;\r\nlist_for_each_entry(entry, &sw_context->validate_nodes, base.head) {\r\nret = vmw_validate_single_buffer(dev_priv, entry->base.bo,\r\ntrue,\r\nentry->validate_as_mob);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic int vmw_resize_cmd_bounce(struct vmw_sw_context *sw_context,\r\nuint32_t size)\r\n{\r\nif (likely(sw_context->cmd_bounce_size >= size))\r\nreturn 0;\r\nif (sw_context->cmd_bounce_size == 0)\r\nsw_context->cmd_bounce_size = VMWGFX_CMD_BOUNCE_INIT_SIZE;\r\nwhile (sw_context->cmd_bounce_size < size) {\r\nsw_context->cmd_bounce_size =\r\nPAGE_ALIGN(sw_context->cmd_bounce_size +\r\n(sw_context->cmd_bounce_size >> 1));\r\n}\r\nif (sw_context->cmd_bounce != NULL)\r\nvfree(sw_context->cmd_bounce);\r\nsw_context->cmd_bounce = vmalloc(sw_context->cmd_bounce_size);\r\nif (sw_context->cmd_bounce == NULL) {\r\nDRM_ERROR("Failed to allocate command bounce buffer.\n");\r\nsw_context->cmd_bounce_size = 0;\r\nreturn -ENOMEM;\r\n}\r\nreturn 0;\r\n}\r\nint vmw_execbuf_fence_commands(struct drm_file *file_priv,\r\nstruct vmw_private *dev_priv,\r\nstruct vmw_fence_obj **p_fence,\r\nuint32_t *p_handle)\r\n{\r\nuint32_t sequence;\r\nint ret;\r\nbool synced = false;\r\nBUG_ON(p_handle != NULL && file_priv == NULL);\r\nret = vmw_fifo_send_fence(dev_priv, &sequence);\r\nif (unlikely(ret != 0)) {\r\nDRM_ERROR("Fence submission error. Syncing.\n");\r\nsynced = true;\r\n}\r\nif (p_handle != NULL)\r\nret = vmw_user_fence_create(file_priv, dev_priv->fman,\r\nsequence, p_fence, p_handle);\r\nelse\r\nret = vmw_fence_create(dev_priv->fman, sequence, p_fence);\r\nif (unlikely(ret != 0 && !synced)) {\r\n(void) vmw_fallback_wait(dev_priv, false, false,\r\nsequence, false,\r\nVMW_FENCE_WAIT_TIMEOUT);\r\n*p_fence = NULL;\r\n}\r\nreturn 0;\r\n}\r\nvoid\r\nvmw_execbuf_copy_fence_user(struct vmw_private *dev_priv,\r\nstruct vmw_fpriv *vmw_fp,\r\nint ret,\r\nstruct drm_vmw_fence_rep __user *user_fence_rep,\r\nstruct vmw_fence_obj *fence,\r\nuint32_t fence_handle)\r\n{\r\nstruct drm_vmw_fence_rep fence_rep;\r\nif (user_fence_rep == NULL)\r\nreturn;\r\nmemset(&fence_rep, 0, sizeof(fence_rep));\r\nfence_rep.error = ret;\r\nif (ret == 0) {\r\nBUG_ON(fence == NULL);\r\nfence_rep.handle = fence_handle;\r\nfence_rep.seqno = fence->base.seqno;\r\nvmw_update_seqno(dev_priv, &dev_priv->fifo);\r\nfence_rep.passed_seqno = dev_priv->last_read_seqno;\r\n}\r\nret = copy_to_user(user_fence_rep, &fence_rep,\r\nsizeof(fence_rep));\r\nif (unlikely(ret != 0) && (fence_rep.error == 0)) {\r\nttm_ref_object_base_unref(vmw_fp->tfile,\r\nfence_handle, TTM_REF_USAGE);\r\nDRM_ERROR("Fence copy error. Syncing.\n");\r\n(void) vmw_fence_obj_wait(fence, false, false,\r\nVMW_FENCE_WAIT_TIMEOUT);\r\n}\r\n}\r\nstatic int vmw_execbuf_submit_fifo(struct vmw_private *dev_priv,\r\nvoid *kernel_commands,\r\nu32 command_size,\r\nstruct vmw_sw_context *sw_context)\r\n{\r\nvoid *cmd;\r\nif (sw_context->dx_ctx_node)\r\ncmd = vmw_fifo_reserve_dx(dev_priv, command_size,\r\nsw_context->dx_ctx_node->res->id);\r\nelse\r\ncmd = vmw_fifo_reserve(dev_priv, command_size);\r\nif (!cmd) {\r\nDRM_ERROR("Failed reserving fifo space for commands.\n");\r\nreturn -ENOMEM;\r\n}\r\nvmw_apply_relocations(sw_context);\r\nmemcpy(cmd, kernel_commands, command_size);\r\nvmw_resource_relocations_apply(cmd, &sw_context->res_relocations);\r\nvmw_resource_relocations_free(&sw_context->res_relocations);\r\nvmw_fifo_commit(dev_priv, command_size);\r\nreturn 0;\r\n}\r\nstatic int vmw_execbuf_submit_cmdbuf(struct vmw_private *dev_priv,\r\nstruct vmw_cmdbuf_header *header,\r\nu32 command_size,\r\nstruct vmw_sw_context *sw_context)\r\n{\r\nu32 id = ((sw_context->dx_ctx_node) ? sw_context->dx_ctx_node->res->id :\r\nSVGA3D_INVALID_ID);\r\nvoid *cmd = vmw_cmdbuf_reserve(dev_priv->cman, command_size,\r\nid, false, header);\r\nvmw_apply_relocations(sw_context);\r\nvmw_resource_relocations_apply(cmd, &sw_context->res_relocations);\r\nvmw_resource_relocations_free(&sw_context->res_relocations);\r\nvmw_cmdbuf_commit(dev_priv->cman, command_size, header, false);\r\nreturn 0;\r\n}\r\nstatic void *vmw_execbuf_cmdbuf(struct vmw_private *dev_priv,\r\nvoid __user *user_commands,\r\nvoid *kernel_commands,\r\nu32 command_size,\r\nstruct vmw_cmdbuf_header **header)\r\n{\r\nsize_t cmdbuf_size;\r\nint ret;\r\n*header = NULL;\r\nif (!dev_priv->cman || kernel_commands)\r\nreturn kernel_commands;\r\nif (command_size > SVGA_CB_MAX_SIZE) {\r\nDRM_ERROR("Command buffer is too large.\n");\r\nreturn ERR_PTR(-EINVAL);\r\n}\r\ncmdbuf_size = command_size + 512;\r\ncmdbuf_size = min_t(size_t, cmdbuf_size, SVGA_CB_MAX_SIZE);\r\nkernel_commands = vmw_cmdbuf_alloc(dev_priv->cman, cmdbuf_size,\r\ntrue, header);\r\nif (IS_ERR(kernel_commands))\r\nreturn kernel_commands;\r\nret = copy_from_user(kernel_commands, user_commands,\r\ncommand_size);\r\nif (ret) {\r\nDRM_ERROR("Failed copying commands.\n");\r\nvmw_cmdbuf_header_free(*header);\r\n*header = NULL;\r\nreturn ERR_PTR(-EFAULT);\r\n}\r\nreturn kernel_commands;\r\n}\r\nstatic int vmw_execbuf_tie_context(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nuint32_t handle)\r\n{\r\nstruct vmw_resource_val_node *ctx_node;\r\nstruct vmw_resource *res;\r\nint ret;\r\nif (handle == SVGA3D_INVALID_ID)\r\nreturn 0;\r\nret = vmw_user_resource_lookup_handle(dev_priv, sw_context->fp->tfile,\r\nhandle, user_context_converter,\r\n&res);\r\nif (unlikely(ret != 0)) {\r\nDRM_ERROR("Could not find or user DX context 0x%08x.\n",\r\n(unsigned) handle);\r\nreturn ret;\r\n}\r\nret = vmw_resource_val_add(sw_context, res, &ctx_node);\r\nif (unlikely(ret != 0))\r\ngoto out_err;\r\nsw_context->dx_ctx_node = ctx_node;\r\nsw_context->man = vmw_context_res_man(res);\r\nout_err:\r\nvmw_resource_unreference(&res);\r\nreturn ret;\r\n}\r\nint vmw_execbuf_process(struct drm_file *file_priv,\r\nstruct vmw_private *dev_priv,\r\nvoid __user *user_commands,\r\nvoid *kernel_commands,\r\nuint32_t command_size,\r\nuint64_t throttle_us,\r\nuint32_t dx_context_handle,\r\nstruct drm_vmw_fence_rep __user *user_fence_rep,\r\nstruct vmw_fence_obj **out_fence)\r\n{\r\nstruct vmw_sw_context *sw_context = &dev_priv->ctx;\r\nstruct vmw_fence_obj *fence = NULL;\r\nstruct vmw_resource *error_resource;\r\nstruct list_head resource_list;\r\nstruct vmw_cmdbuf_header *header;\r\nstruct ww_acquire_ctx ticket;\r\nuint32_t handle;\r\nint ret;\r\nif (throttle_us) {\r\nret = vmw_wait_lag(dev_priv, &dev_priv->fifo.marker_queue,\r\nthrottle_us);\r\nif (ret)\r\nreturn ret;\r\n}\r\nkernel_commands = vmw_execbuf_cmdbuf(dev_priv, user_commands,\r\nkernel_commands, command_size,\r\n&header);\r\nif (IS_ERR(kernel_commands))\r\nreturn PTR_ERR(kernel_commands);\r\nret = mutex_lock_interruptible(&dev_priv->cmdbuf_mutex);\r\nif (ret) {\r\nret = -ERESTARTSYS;\r\ngoto out_free_header;\r\n}\r\nsw_context->kernel = false;\r\nif (kernel_commands == NULL) {\r\nret = vmw_resize_cmd_bounce(sw_context, command_size);\r\nif (unlikely(ret != 0))\r\ngoto out_unlock;\r\nret = copy_from_user(sw_context->cmd_bounce,\r\nuser_commands, command_size);\r\nif (unlikely(ret != 0)) {\r\nret = -EFAULT;\r\nDRM_ERROR("Failed copying commands.\n");\r\ngoto out_unlock;\r\n}\r\nkernel_commands = sw_context->cmd_bounce;\r\n} else if (!header)\r\nsw_context->kernel = true;\r\nsw_context->fp = vmw_fpriv(file_priv);\r\nsw_context->cur_reloc = 0;\r\nsw_context->cur_val_buf = 0;\r\nINIT_LIST_HEAD(&sw_context->resource_list);\r\nINIT_LIST_HEAD(&sw_context->ctx_resource_list);\r\nsw_context->cur_query_bo = dev_priv->pinned_bo;\r\nsw_context->last_query_ctx = NULL;\r\nsw_context->needs_post_query_barrier = false;\r\nsw_context->dx_ctx_node = NULL;\r\nsw_context->dx_query_mob = NULL;\r\nsw_context->dx_query_ctx = NULL;\r\nmemset(sw_context->res_cache, 0, sizeof(sw_context->res_cache));\r\nINIT_LIST_HEAD(&sw_context->validate_nodes);\r\nINIT_LIST_HEAD(&sw_context->res_relocations);\r\nif (sw_context->staged_bindings)\r\nvmw_binding_state_reset(sw_context->staged_bindings);\r\nif (!sw_context->res_ht_initialized) {\r\nret = drm_ht_create(&sw_context->res_ht, VMW_RES_HT_ORDER);\r\nif (unlikely(ret != 0))\r\ngoto out_unlock;\r\nsw_context->res_ht_initialized = true;\r\n}\r\nINIT_LIST_HEAD(&sw_context->staged_cmd_res);\r\nINIT_LIST_HEAD(&resource_list);\r\nret = vmw_execbuf_tie_context(dev_priv, sw_context, dx_context_handle);\r\nif (unlikely(ret != 0)) {\r\nlist_splice_init(&sw_context->ctx_resource_list,\r\n&sw_context->resource_list);\r\ngoto out_err_nores;\r\n}\r\nret = vmw_cmd_check_all(dev_priv, sw_context, kernel_commands,\r\ncommand_size);\r\nlist_splice_init(&sw_context->ctx_resource_list,\r\n&sw_context->resource_list);\r\nif (unlikely(ret != 0))\r\ngoto out_err_nores;\r\nret = vmw_resources_reserve(sw_context);\r\nif (unlikely(ret != 0))\r\ngoto out_err_nores;\r\nret = ttm_eu_reserve_buffers(&ticket, &sw_context->validate_nodes,\r\ntrue, NULL);\r\nif (unlikely(ret != 0))\r\ngoto out_err_nores;\r\nret = vmw_validate_buffers(dev_priv, sw_context);\r\nif (unlikely(ret != 0))\r\ngoto out_err;\r\nret = vmw_resources_validate(sw_context);\r\nif (unlikely(ret != 0))\r\ngoto out_err;\r\nret = mutex_lock_interruptible(&dev_priv->binding_mutex);\r\nif (unlikely(ret != 0)) {\r\nret = -ERESTARTSYS;\r\ngoto out_err;\r\n}\r\nif (dev_priv->has_mob) {\r\nret = vmw_rebind_contexts(sw_context);\r\nif (unlikely(ret != 0))\r\ngoto out_unlock_binding;\r\n}\r\nif (!header) {\r\nret = vmw_execbuf_submit_fifo(dev_priv, kernel_commands,\r\ncommand_size, sw_context);\r\n} else {\r\nret = vmw_execbuf_submit_cmdbuf(dev_priv, header, command_size,\r\nsw_context);\r\nheader = NULL;\r\n}\r\nmutex_unlock(&dev_priv->binding_mutex);\r\nif (ret)\r\ngoto out_err;\r\nvmw_query_bo_switch_commit(dev_priv, sw_context);\r\nret = vmw_execbuf_fence_commands(file_priv, dev_priv,\r\n&fence,\r\n(user_fence_rep) ? &handle : NULL);\r\nif (ret != 0)\r\nDRM_ERROR("Fence submission error. Syncing.\n");\r\nvmw_resources_unreserve(sw_context, false);\r\nttm_eu_fence_buffer_objects(&ticket, &sw_context->validate_nodes,\r\n(void *) fence);\r\nif (unlikely(dev_priv->pinned_bo != NULL &&\r\n!dev_priv->query_cid_valid))\r\n__vmw_execbuf_release_pinned_bo(dev_priv, fence);\r\nvmw_clear_validations(sw_context);\r\nvmw_execbuf_copy_fence_user(dev_priv, vmw_fpriv(file_priv), ret,\r\nuser_fence_rep, fence, handle);\r\nif (unlikely(out_fence != NULL)) {\r\n*out_fence = fence;\r\nfence = NULL;\r\n} else if (likely(fence != NULL)) {\r\nvmw_fence_obj_unreference(&fence);\r\n}\r\nlist_splice_init(&sw_context->resource_list, &resource_list);\r\nvmw_cmdbuf_res_commit(&sw_context->staged_cmd_res);\r\nmutex_unlock(&dev_priv->cmdbuf_mutex);\r\nvmw_resource_list_unreference(sw_context, &resource_list);\r\nreturn 0;\r\nout_unlock_binding:\r\nmutex_unlock(&dev_priv->binding_mutex);\r\nout_err:\r\nttm_eu_backoff_reservation(&ticket, &sw_context->validate_nodes);\r\nout_err_nores:\r\nvmw_resources_unreserve(sw_context, true);\r\nvmw_resource_relocations_free(&sw_context->res_relocations);\r\nvmw_free_relocations(sw_context);\r\nvmw_clear_validations(sw_context);\r\nif (unlikely(dev_priv->pinned_bo != NULL &&\r\n!dev_priv->query_cid_valid))\r\n__vmw_execbuf_release_pinned_bo(dev_priv, NULL);\r\nout_unlock:\r\nlist_splice_init(&sw_context->resource_list, &resource_list);\r\nerror_resource = sw_context->error_resource;\r\nsw_context->error_resource = NULL;\r\nvmw_cmdbuf_res_revert(&sw_context->staged_cmd_res);\r\nmutex_unlock(&dev_priv->cmdbuf_mutex);\r\nvmw_resource_list_unreference(sw_context, &resource_list);\r\nif (unlikely(error_resource != NULL))\r\nvmw_resource_unreference(&error_resource);\r\nout_free_header:\r\nif (header)\r\nvmw_cmdbuf_header_free(header);\r\nreturn ret;\r\n}\r\nstatic void vmw_execbuf_unpin_panic(struct vmw_private *dev_priv)\r\n{\r\nDRM_ERROR("Can't unpin query buffer. Trying to recover.\n");\r\n(void) vmw_fallback_wait(dev_priv, false, true, 0, false, 10*HZ);\r\nvmw_bo_pin_reserved(dev_priv->pinned_bo, false);\r\nif (dev_priv->dummy_query_bo_pinned) {\r\nvmw_bo_pin_reserved(dev_priv->dummy_query_bo, false);\r\ndev_priv->dummy_query_bo_pinned = false;\r\n}\r\n}\r\nvoid __vmw_execbuf_release_pinned_bo(struct vmw_private *dev_priv,\r\nstruct vmw_fence_obj *fence)\r\n{\r\nint ret = 0;\r\nstruct list_head validate_list;\r\nstruct ttm_validate_buffer pinned_val, query_val;\r\nstruct vmw_fence_obj *lfence = NULL;\r\nstruct ww_acquire_ctx ticket;\r\nif (dev_priv->pinned_bo == NULL)\r\ngoto out_unlock;\r\nINIT_LIST_HEAD(&validate_list);\r\npinned_val.bo = ttm_bo_reference(&dev_priv->pinned_bo->base);\r\npinned_val.shared = false;\r\nlist_add_tail(&pinned_val.head, &validate_list);\r\nquery_val.bo = ttm_bo_reference(&dev_priv->dummy_query_bo->base);\r\nquery_val.shared = false;\r\nlist_add_tail(&query_val.head, &validate_list);\r\nret = ttm_eu_reserve_buffers(&ticket, &validate_list,\r\nfalse, NULL);\r\nif (unlikely(ret != 0)) {\r\nvmw_execbuf_unpin_panic(dev_priv);\r\ngoto out_no_reserve;\r\n}\r\nif (dev_priv->query_cid_valid) {\r\nBUG_ON(fence != NULL);\r\nret = vmw_fifo_emit_dummy_query(dev_priv, dev_priv->query_cid);\r\nif (unlikely(ret != 0)) {\r\nvmw_execbuf_unpin_panic(dev_priv);\r\ngoto out_no_emit;\r\n}\r\ndev_priv->query_cid_valid = false;\r\n}\r\nvmw_bo_pin_reserved(dev_priv->pinned_bo, false);\r\nif (dev_priv->dummy_query_bo_pinned) {\r\nvmw_bo_pin_reserved(dev_priv->dummy_query_bo, false);\r\ndev_priv->dummy_query_bo_pinned = false;\r\n}\r\nif (fence == NULL) {\r\n(void) vmw_execbuf_fence_commands(NULL, dev_priv, &lfence,\r\nNULL);\r\nfence = lfence;\r\n}\r\nttm_eu_fence_buffer_objects(&ticket, &validate_list, (void *) fence);\r\nif (lfence != NULL)\r\nvmw_fence_obj_unreference(&lfence);\r\nttm_bo_unref(&query_val.bo);\r\nttm_bo_unref(&pinned_val.bo);\r\nvmw_dmabuf_unreference(&dev_priv->pinned_bo);\r\nDRM_INFO("Dummy query bo pin count: %d\n",\r\ndev_priv->dummy_query_bo->pin_count);\r\nout_unlock:\r\nreturn;\r\nout_no_emit:\r\nttm_eu_backoff_reservation(&ticket, &validate_list);\r\nout_no_reserve:\r\nttm_bo_unref(&query_val.bo);\r\nttm_bo_unref(&pinned_val.bo);\r\nvmw_dmabuf_unreference(&dev_priv->pinned_bo);\r\n}\r\nvoid vmw_execbuf_release_pinned_bo(struct vmw_private *dev_priv)\r\n{\r\nmutex_lock(&dev_priv->cmdbuf_mutex);\r\nif (dev_priv->query_cid_valid)\r\n__vmw_execbuf_release_pinned_bo(dev_priv, NULL);\r\nmutex_unlock(&dev_priv->cmdbuf_mutex);\r\n}\r\nint vmw_execbuf_ioctl(struct drm_device *dev, unsigned long data,\r\nstruct drm_file *file_priv, size_t size)\r\n{\r\nstruct vmw_private *dev_priv = vmw_priv(dev);\r\nstruct drm_vmw_execbuf_arg arg;\r\nint ret;\r\nstatic const size_t copy_offset[] = {\r\noffsetof(struct drm_vmw_execbuf_arg, context_handle),\r\nsizeof(struct drm_vmw_execbuf_arg)};\r\nif (unlikely(size < copy_offset[0])) {\r\nDRM_ERROR("Invalid command size, ioctl %d\n",\r\nDRM_VMW_EXECBUF);\r\nreturn -EINVAL;\r\n}\r\nif (copy_from_user(&arg, (void __user *) data, copy_offset[0]) != 0)\r\nreturn -EFAULT;\r\nif (unlikely(arg.version > DRM_VMW_EXECBUF_VERSION ||\r\narg.version == 0)) {\r\nDRM_ERROR("Incorrect execbuf version.\n");\r\nreturn -EINVAL;\r\n}\r\nif (arg.version > 1 &&\r\ncopy_from_user(&arg.context_handle,\r\n(void __user *) (data + copy_offset[0]),\r\ncopy_offset[arg.version - 1] -\r\ncopy_offset[0]) != 0)\r\nreturn -EFAULT;\r\nswitch (arg.version) {\r\ncase 1:\r\narg.context_handle = (uint32_t) -1;\r\nbreak;\r\ncase 2:\r\nif (arg.pad64 != 0) {\r\nDRM_ERROR("Unused IOCTL data not set to zero.\n");\r\nreturn -EINVAL;\r\n}\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nret = ttm_read_lock(&dev_priv->reservation_sem, true);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nret = vmw_execbuf_process(file_priv, dev_priv,\r\n(void __user *)(unsigned long)arg.commands,\r\nNULL, arg.command_size, arg.throttle_us,\r\narg.context_handle,\r\n(void __user *)(unsigned long)arg.fence_rep,\r\nNULL);\r\nttm_read_unlock(&dev_priv->reservation_sem);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nvmw_kms_cursor_post_execbuf(dev_priv);\r\nreturn 0;\r\n}
