STATIC struct xfs_btree_cur *\r\nxfs_allocbt_dup_cursor(\r\nstruct xfs_btree_cur *cur)\r\n{\r\nreturn xfs_allocbt_init_cursor(cur->bc_mp, cur->bc_tp,\r\ncur->bc_private.a.agbp, cur->bc_private.a.agno,\r\ncur->bc_btnum);\r\n}\r\nSTATIC void\r\nxfs_allocbt_set_root(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_ptr *ptr,\r\nint inc)\r\n{\r\nstruct xfs_buf *agbp = cur->bc_private.a.agbp;\r\nstruct xfs_agf *agf = XFS_BUF_TO_AGF(agbp);\r\nxfs_agnumber_t seqno = be32_to_cpu(agf->agf_seqno);\r\nint btnum = cur->bc_btnum;\r\nstruct xfs_perag *pag = xfs_perag_get(cur->bc_mp, seqno);\r\nASSERT(ptr->s != 0);\r\nagf->agf_roots[btnum] = ptr->s;\r\nbe32_add_cpu(&agf->agf_levels[btnum], inc);\r\npag->pagf_levels[btnum] += inc;\r\nxfs_perag_put(pag);\r\nxfs_alloc_log_agf(cur->bc_tp, agbp, XFS_AGF_ROOTS | XFS_AGF_LEVELS);\r\n}\r\nSTATIC int\r\nxfs_allocbt_alloc_block(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_ptr *start,\r\nunion xfs_btree_ptr *new,\r\nint *stat)\r\n{\r\nint error;\r\nxfs_agblock_t bno;\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ENTRY);\r\nerror = xfs_alloc_get_freelist(cur->bc_tp, cur->bc_private.a.agbp,\r\n&bno, 1);\r\nif (error) {\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_ERROR);\r\nreturn error;\r\n}\r\nif (bno == NULLAGBLOCK) {\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 0;\r\nreturn 0;\r\n}\r\nxfs_extent_busy_reuse(cur->bc_mp, cur->bc_private.a.agno, bno, 1, false);\r\nxfs_trans_agbtree_delta(cur->bc_tp, 1);\r\nnew->s = cpu_to_be32(bno);\r\nXFS_BTREE_TRACE_CURSOR(cur, XBT_EXIT);\r\n*stat = 1;\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_allocbt_free_block(\r\nstruct xfs_btree_cur *cur,\r\nstruct xfs_buf *bp)\r\n{\r\nstruct xfs_buf *agbp = cur->bc_private.a.agbp;\r\nstruct xfs_agf *agf = XFS_BUF_TO_AGF(agbp);\r\nxfs_agblock_t bno;\r\nint error;\r\nbno = xfs_daddr_to_agbno(cur->bc_mp, XFS_BUF_ADDR(bp));\r\nerror = xfs_alloc_put_freelist(cur->bc_tp, agbp, NULL, bno, 1);\r\nif (error)\r\nreturn error;\r\nxfs_extent_busy_insert(cur->bc_tp, be32_to_cpu(agf->agf_seqno), bno, 1,\r\nXFS_EXTENT_BUSY_SKIP_DISCARD);\r\nxfs_trans_agbtree_delta(cur->bc_tp, -1);\r\nreturn 0;\r\n}\r\nSTATIC void\r\nxfs_allocbt_update_lastrec(\r\nstruct xfs_btree_cur *cur,\r\nstruct xfs_btree_block *block,\r\nunion xfs_btree_rec *rec,\r\nint ptr,\r\nint reason)\r\n{\r\nstruct xfs_agf *agf = XFS_BUF_TO_AGF(cur->bc_private.a.agbp);\r\nxfs_agnumber_t seqno = be32_to_cpu(agf->agf_seqno);\r\nstruct xfs_perag *pag;\r\n__be32 len;\r\nint numrecs;\r\nASSERT(cur->bc_btnum == XFS_BTNUM_CNT);\r\nswitch (reason) {\r\ncase LASTREC_UPDATE:\r\nif (ptr != xfs_btree_get_numrecs(block))\r\nreturn;\r\nlen = rec->alloc.ar_blockcount;\r\nbreak;\r\ncase LASTREC_INSREC:\r\nif (be32_to_cpu(rec->alloc.ar_blockcount) <=\r\nbe32_to_cpu(agf->agf_longest))\r\nreturn;\r\nlen = rec->alloc.ar_blockcount;\r\nbreak;\r\ncase LASTREC_DELREC:\r\nnumrecs = xfs_btree_get_numrecs(block);\r\nif (ptr <= numrecs)\r\nreturn;\r\nASSERT(ptr == numrecs + 1);\r\nif (numrecs) {\r\nxfs_alloc_rec_t *rrp;\r\nrrp = XFS_ALLOC_REC_ADDR(cur->bc_mp, block, numrecs);\r\nlen = rrp->ar_blockcount;\r\n} else {\r\nlen = 0;\r\n}\r\nbreak;\r\ndefault:\r\nASSERT(0);\r\nreturn;\r\n}\r\nagf->agf_longest = len;\r\npag = xfs_perag_get(cur->bc_mp, seqno);\r\npag->pagf_longest = be32_to_cpu(len);\r\nxfs_perag_put(pag);\r\nxfs_alloc_log_agf(cur->bc_tp, cur->bc_private.a.agbp, XFS_AGF_LONGEST);\r\n}\r\nSTATIC int\r\nxfs_allocbt_get_minrecs(\r\nstruct xfs_btree_cur *cur,\r\nint level)\r\n{\r\nreturn cur->bc_mp->m_alloc_mnr[level != 0];\r\n}\r\nSTATIC int\r\nxfs_allocbt_get_maxrecs(\r\nstruct xfs_btree_cur *cur,\r\nint level)\r\n{\r\nreturn cur->bc_mp->m_alloc_mxr[level != 0];\r\n}\r\nSTATIC void\r\nxfs_allocbt_init_key_from_rec(\r\nunion xfs_btree_key *key,\r\nunion xfs_btree_rec *rec)\r\n{\r\nASSERT(rec->alloc.ar_startblock != 0);\r\nkey->alloc.ar_startblock = rec->alloc.ar_startblock;\r\nkey->alloc.ar_blockcount = rec->alloc.ar_blockcount;\r\n}\r\nSTATIC void\r\nxfs_allocbt_init_rec_from_key(\r\nunion xfs_btree_key *key,\r\nunion xfs_btree_rec *rec)\r\n{\r\nASSERT(key->alloc.ar_startblock != 0);\r\nrec->alloc.ar_startblock = key->alloc.ar_startblock;\r\nrec->alloc.ar_blockcount = key->alloc.ar_blockcount;\r\n}\r\nSTATIC void\r\nxfs_allocbt_init_rec_from_cur(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_rec *rec)\r\n{\r\nASSERT(cur->bc_rec.a.ar_startblock != 0);\r\nrec->alloc.ar_startblock = cpu_to_be32(cur->bc_rec.a.ar_startblock);\r\nrec->alloc.ar_blockcount = cpu_to_be32(cur->bc_rec.a.ar_blockcount);\r\n}\r\nSTATIC void\r\nxfs_allocbt_init_ptr_from_cur(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_ptr *ptr)\r\n{\r\nstruct xfs_agf *agf = XFS_BUF_TO_AGF(cur->bc_private.a.agbp);\r\nASSERT(cur->bc_private.a.agno == be32_to_cpu(agf->agf_seqno));\r\nASSERT(agf->agf_roots[cur->bc_btnum] != 0);\r\nptr->s = agf->agf_roots[cur->bc_btnum];\r\n}\r\nSTATIC __int64_t\r\nxfs_allocbt_key_diff(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_key *key)\r\n{\r\nxfs_alloc_rec_incore_t *rec = &cur->bc_rec.a;\r\nxfs_alloc_key_t *kp = &key->alloc;\r\n__int64_t diff;\r\nif (cur->bc_btnum == XFS_BTNUM_BNO) {\r\nreturn (__int64_t)be32_to_cpu(kp->ar_startblock) -\r\nrec->ar_startblock;\r\n}\r\ndiff = (__int64_t)be32_to_cpu(kp->ar_blockcount) - rec->ar_blockcount;\r\nif (diff)\r\nreturn diff;\r\nreturn (__int64_t)be32_to_cpu(kp->ar_startblock) - rec->ar_startblock;\r\n}\r\nstatic bool\r\nxfs_allocbt_verify(\r\nstruct xfs_buf *bp)\r\n{\r\nstruct xfs_mount *mp = bp->b_target->bt_mount;\r\nstruct xfs_btree_block *block = XFS_BUF_TO_BLOCK(bp);\r\nstruct xfs_perag *pag = bp->b_pag;\r\nunsigned int level;\r\nlevel = be16_to_cpu(block->bb_level);\r\nswitch (block->bb_magic) {\r\ncase cpu_to_be32(XFS_ABTB_CRC_MAGIC):\r\nif (!xfs_btree_sblock_v5hdr_verify(bp))\r\nreturn false;\r\ncase cpu_to_be32(XFS_ABTB_MAGIC):\r\nif (pag && pag->pagf_init) {\r\nif (level >= pag->pagf_levels[XFS_BTNUM_BNOi])\r\nreturn false;\r\n} else if (level >= mp->m_ag_maxlevels)\r\nreturn false;\r\nbreak;\r\ncase cpu_to_be32(XFS_ABTC_CRC_MAGIC):\r\nif (!xfs_btree_sblock_v5hdr_verify(bp))\r\nreturn false;\r\ncase cpu_to_be32(XFS_ABTC_MAGIC):\r\nif (pag && pag->pagf_init) {\r\nif (level >= pag->pagf_levels[XFS_BTNUM_CNTi])\r\nreturn false;\r\n} else if (level >= mp->m_ag_maxlevels)\r\nreturn false;\r\nbreak;\r\ndefault:\r\nreturn false;\r\n}\r\nreturn xfs_btree_sblock_verify(bp, mp->m_alloc_mxr[level != 0]);\r\n}\r\nstatic void\r\nxfs_allocbt_read_verify(\r\nstruct xfs_buf *bp)\r\n{\r\nif (!xfs_btree_sblock_verify_crc(bp))\r\nxfs_buf_ioerror(bp, -EFSBADCRC);\r\nelse if (!xfs_allocbt_verify(bp))\r\nxfs_buf_ioerror(bp, -EFSCORRUPTED);\r\nif (bp->b_error) {\r\ntrace_xfs_btree_corrupt(bp, _RET_IP_);\r\nxfs_verifier_error(bp);\r\n}\r\n}\r\nstatic void\r\nxfs_allocbt_write_verify(\r\nstruct xfs_buf *bp)\r\n{\r\nif (!xfs_allocbt_verify(bp)) {\r\ntrace_xfs_btree_corrupt(bp, _RET_IP_);\r\nxfs_buf_ioerror(bp, -EFSCORRUPTED);\r\nxfs_verifier_error(bp);\r\nreturn;\r\n}\r\nxfs_btree_sblock_calc_crc(bp);\r\n}\r\nSTATIC int\r\nxfs_allocbt_keys_inorder(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_key *k1,\r\nunion xfs_btree_key *k2)\r\n{\r\nif (cur->bc_btnum == XFS_BTNUM_BNO) {\r\nreturn be32_to_cpu(k1->alloc.ar_startblock) <\r\nbe32_to_cpu(k2->alloc.ar_startblock);\r\n} else {\r\nreturn be32_to_cpu(k1->alloc.ar_blockcount) <\r\nbe32_to_cpu(k2->alloc.ar_blockcount) ||\r\n(k1->alloc.ar_blockcount == k2->alloc.ar_blockcount &&\r\nbe32_to_cpu(k1->alloc.ar_startblock) <\r\nbe32_to_cpu(k2->alloc.ar_startblock));\r\n}\r\n}\r\nSTATIC int\r\nxfs_allocbt_recs_inorder(\r\nstruct xfs_btree_cur *cur,\r\nunion xfs_btree_rec *r1,\r\nunion xfs_btree_rec *r2)\r\n{\r\nif (cur->bc_btnum == XFS_BTNUM_BNO) {\r\nreturn be32_to_cpu(r1->alloc.ar_startblock) +\r\nbe32_to_cpu(r1->alloc.ar_blockcount) <=\r\nbe32_to_cpu(r2->alloc.ar_startblock);\r\n} else {\r\nreturn be32_to_cpu(r1->alloc.ar_blockcount) <\r\nbe32_to_cpu(r2->alloc.ar_blockcount) ||\r\n(r1->alloc.ar_blockcount == r2->alloc.ar_blockcount &&\r\nbe32_to_cpu(r1->alloc.ar_startblock) <\r\nbe32_to_cpu(r2->alloc.ar_startblock));\r\n}\r\n}\r\nstruct xfs_btree_cur *\r\nxfs_allocbt_init_cursor(\r\nstruct xfs_mount *mp,\r\nstruct xfs_trans *tp,\r\nstruct xfs_buf *agbp,\r\nxfs_agnumber_t agno,\r\nxfs_btnum_t btnum)\r\n{\r\nstruct xfs_agf *agf = XFS_BUF_TO_AGF(agbp);\r\nstruct xfs_btree_cur *cur;\r\nASSERT(btnum == XFS_BTNUM_BNO || btnum == XFS_BTNUM_CNT);\r\ncur = kmem_zone_zalloc(xfs_btree_cur_zone, KM_SLEEP);\r\ncur->bc_tp = tp;\r\ncur->bc_mp = mp;\r\ncur->bc_btnum = btnum;\r\ncur->bc_blocklog = mp->m_sb.sb_blocklog;\r\ncur->bc_ops = &xfs_allocbt_ops;\r\nif (btnum == XFS_BTNUM_CNT) {\r\ncur->bc_nlevels = be32_to_cpu(agf->agf_levels[XFS_BTNUM_CNT]);\r\ncur->bc_flags = XFS_BTREE_LASTREC_UPDATE;\r\n} else {\r\ncur->bc_nlevels = be32_to_cpu(agf->agf_levels[XFS_BTNUM_BNO]);\r\n}\r\ncur->bc_private.a.agbp = agbp;\r\ncur->bc_private.a.agno = agno;\r\nif (xfs_sb_version_hascrc(&mp->m_sb))\r\ncur->bc_flags |= XFS_BTREE_CRC_BLOCKS;\r\nreturn cur;\r\n}\r\nint\r\nxfs_allocbt_maxrecs(\r\nstruct xfs_mount *mp,\r\nint blocklen,\r\nint leaf)\r\n{\r\nblocklen -= XFS_ALLOC_BLOCK_LEN(mp);\r\nif (leaf)\r\nreturn blocklen / sizeof(xfs_alloc_rec_t);\r\nreturn blocklen / (sizeof(xfs_alloc_key_t) + sizeof(xfs_alloc_ptr_t));\r\n}
