static bool ips_cpu_busy(struct ips_driver *ips)\r\n{\r\nif ((avenrun[0] >> FSHIFT) > 1)\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic void ips_cpu_raise(struct ips_driver *ips)\r\n{\r\nu64 turbo_override;\r\nu16 cur_tdp_limit, new_tdp_limit;\r\nif (!ips->cpu_turbo_enabled)\r\nreturn;\r\nrdmsrl(TURBO_POWER_CURRENT_LIMIT, turbo_override);\r\ncur_tdp_limit = turbo_override & TURBO_TDP_MASK;\r\nnew_tdp_limit = cur_tdp_limit + 8;\r\nif (((new_tdp_limit * 10) / 8) > ips->core_power_limit)\r\nnew_tdp_limit = cur_tdp_limit;\r\nthm_writew(THM_MPCPC, (new_tdp_limit * 10) / 8);\r\nturbo_override |= TURBO_TDC_OVR_EN | TURBO_TDP_OVR_EN;\r\nwrmsrl(TURBO_POWER_CURRENT_LIMIT, turbo_override);\r\nturbo_override &= ~TURBO_TDP_MASK;\r\nturbo_override |= new_tdp_limit;\r\nwrmsrl(TURBO_POWER_CURRENT_LIMIT, turbo_override);\r\n}\r\nstatic void ips_cpu_lower(struct ips_driver *ips)\r\n{\r\nu64 turbo_override;\r\nu16 cur_limit, new_limit;\r\nrdmsrl(TURBO_POWER_CURRENT_LIMIT, turbo_override);\r\ncur_limit = turbo_override & TURBO_TDP_MASK;\r\nnew_limit = cur_limit - 8;\r\nif (new_limit < (ips->orig_turbo_limit & TURBO_TDP_MASK))\r\nnew_limit = ips->orig_turbo_limit & TURBO_TDP_MASK;\r\nthm_writew(THM_MPCPC, (new_limit * 10) / 8);\r\nturbo_override |= TURBO_TDC_OVR_EN | TURBO_TDP_OVR_EN;\r\nwrmsrl(TURBO_POWER_CURRENT_LIMIT, turbo_override);\r\nturbo_override &= ~TURBO_TDP_MASK;\r\nturbo_override |= new_limit;\r\nwrmsrl(TURBO_POWER_CURRENT_LIMIT, turbo_override);\r\n}\r\nstatic void do_enable_cpu_turbo(void *data)\r\n{\r\nu64 perf_ctl;\r\nrdmsrl(IA32_PERF_CTL, perf_ctl);\r\nif (perf_ctl & IA32_PERF_TURBO_DIS) {\r\nperf_ctl &= ~IA32_PERF_TURBO_DIS;\r\nwrmsrl(IA32_PERF_CTL, perf_ctl);\r\n}\r\n}\r\nstatic void ips_enable_cpu_turbo(struct ips_driver *ips)\r\n{\r\nif (ips->__cpu_turbo_on)\r\nreturn;\r\nif (ips->turbo_toggle_allowed)\r\non_each_cpu(do_enable_cpu_turbo, ips, 1);\r\nips->__cpu_turbo_on = true;\r\n}\r\nstatic void do_disable_cpu_turbo(void *data)\r\n{\r\nu64 perf_ctl;\r\nrdmsrl(IA32_PERF_CTL, perf_ctl);\r\nif (!(perf_ctl & IA32_PERF_TURBO_DIS)) {\r\nperf_ctl |= IA32_PERF_TURBO_DIS;\r\nwrmsrl(IA32_PERF_CTL, perf_ctl);\r\n}\r\n}\r\nstatic void ips_disable_cpu_turbo(struct ips_driver *ips)\r\n{\r\nif (!ips->__cpu_turbo_on)\r\nreturn;\r\nif (ips->turbo_toggle_allowed)\r\non_each_cpu(do_disable_cpu_turbo, ips, 1);\r\nips->__cpu_turbo_on = false;\r\n}\r\nstatic bool ips_gpu_busy(struct ips_driver *ips)\r\n{\r\nif (!ips_gpu_turbo_enabled(ips))\r\nreturn false;\r\nreturn ips->gpu_busy();\r\n}\r\nstatic void ips_gpu_raise(struct ips_driver *ips)\r\n{\r\nif (!ips_gpu_turbo_enabled(ips))\r\nreturn;\r\nif (!ips->gpu_raise())\r\nips->gpu_turbo_enabled = false;\r\nreturn;\r\n}\r\nstatic void ips_gpu_lower(struct ips_driver *ips)\r\n{\r\nif (!ips_gpu_turbo_enabled(ips))\r\nreturn;\r\nif (!ips->gpu_lower())\r\nips->gpu_turbo_enabled = false;\r\nreturn;\r\n}\r\nstatic void ips_enable_gpu_turbo(struct ips_driver *ips)\r\n{\r\nif (ips->__gpu_turbo_on)\r\nreturn;\r\nips->__gpu_turbo_on = true;\r\n}\r\nstatic void ips_disable_gpu_turbo(struct ips_driver *ips)\r\n{\r\nif (!ips->__gpu_turbo_on)\r\nreturn;\r\nif (!ips->gpu_turbo_disable())\r\ndev_err(&ips->dev->dev, "failed to disable graphics turbo\n");\r\nelse\r\nips->__gpu_turbo_on = false;\r\n}\r\nstatic bool mcp_exceeded(struct ips_driver *ips)\r\n{\r\nunsigned long flags;\r\nbool ret = false;\r\nu32 temp_limit;\r\nu32 avg_power;\r\nspin_lock_irqsave(&ips->turbo_status_lock, flags);\r\ntemp_limit = ips->mcp_temp_limit * 100;\r\nif (ips->mcp_avg_temp > temp_limit)\r\nret = true;\r\navg_power = ips->cpu_avg_power + ips->mch_avg_power;\r\nif (avg_power > ips->mcp_power_limit)\r\nret = true;\r\nspin_unlock_irqrestore(&ips->turbo_status_lock, flags);\r\nreturn ret;\r\n}\r\nstatic bool cpu_exceeded(struct ips_driver *ips, int cpu)\r\n{\r\nunsigned long flags;\r\nint avg;\r\nbool ret = false;\r\nspin_lock_irqsave(&ips->turbo_status_lock, flags);\r\navg = cpu ? ips->ctv2_avg_temp : ips->ctv1_avg_temp;\r\nif (avg > (ips->limits->core_temp_limit * 100))\r\nret = true;\r\nif (ips->cpu_avg_power > ips->core_power_limit * 100)\r\nret = true;\r\nspin_unlock_irqrestore(&ips->turbo_status_lock, flags);\r\nif (ret)\r\ndev_info(&ips->dev->dev,\r\n"CPU power or thermal limit exceeded\n");\r\nreturn ret;\r\n}\r\nstatic bool mch_exceeded(struct ips_driver *ips)\r\n{\r\nunsigned long flags;\r\nbool ret = false;\r\nspin_lock_irqsave(&ips->turbo_status_lock, flags);\r\nif (ips->mch_avg_temp > (ips->limits->mch_temp_limit * 100))\r\nret = true;\r\nif (ips->mch_avg_power > ips->mch_power_limit)\r\nret = true;\r\nspin_unlock_irqrestore(&ips->turbo_status_lock, flags);\r\nreturn ret;\r\n}\r\nstatic void verify_limits(struct ips_driver *ips)\r\n{\r\nif (ips->mcp_power_limit < ips->limits->mcp_power_limit ||\r\nips->mcp_power_limit > 35000)\r\nips->mcp_power_limit = ips->limits->mcp_power_limit;\r\nif (ips->mcp_temp_limit < ips->limits->core_temp_limit ||\r\nips->mcp_temp_limit < ips->limits->mch_temp_limit ||\r\nips->mcp_temp_limit > 150)\r\nips->mcp_temp_limit = min(ips->limits->core_temp_limit,\r\nips->limits->mch_temp_limit);\r\n}\r\nstatic void update_turbo_limits(struct ips_driver *ips)\r\n{\r\nu32 hts = thm_readl(THM_HTS);\r\nips->cpu_turbo_enabled = !(hts & HTS_PCTD_DIS);\r\nips->cpu_turbo_enabled = false;\r\nif (ips->gpu_busy)\r\nips->gpu_turbo_enabled = !(hts & HTS_GTD_DIS);\r\nips->core_power_limit = thm_readw(THM_MPCPC);\r\nips->mch_power_limit = thm_readw(THM_MMGPC);\r\nips->mcp_temp_limit = thm_readw(THM_PTL);\r\nips->mcp_power_limit = thm_readw(THM_MPPC);\r\nverify_limits(ips);\r\n}\r\nstatic int ips_adjust(void *data)\r\n{\r\nstruct ips_driver *ips = data;\r\nunsigned long flags;\r\ndev_dbg(&ips->dev->dev, "starting ips-adjust thread\n");\r\ndo {\r\nbool cpu_busy = ips_cpu_busy(ips);\r\nbool gpu_busy = ips_gpu_busy(ips);\r\nspin_lock_irqsave(&ips->turbo_status_lock, flags);\r\nif (ips->poll_turbo_status)\r\nupdate_turbo_limits(ips);\r\nspin_unlock_irqrestore(&ips->turbo_status_lock, flags);\r\nif (ips->cpu_turbo_enabled)\r\nips_enable_cpu_turbo(ips);\r\nelse\r\nips_disable_cpu_turbo(ips);\r\nif (ips->gpu_turbo_enabled)\r\nips_enable_gpu_turbo(ips);\r\nelse\r\nips_disable_gpu_turbo(ips);\r\nif (mcp_exceeded(ips)) {\r\nips_cpu_lower(ips);\r\nips_gpu_lower(ips);\r\ngoto sleep;\r\n}\r\nif (!cpu_exceeded(ips, 0) && cpu_busy)\r\nips_cpu_raise(ips);\r\nelse\r\nips_cpu_lower(ips);\r\nif (!mch_exceeded(ips) && gpu_busy)\r\nips_gpu_raise(ips);\r\nelse\r\nips_gpu_lower(ips);\r\nsleep:\r\nschedule_timeout_interruptible(msecs_to_jiffies(IPS_ADJUST_PERIOD));\r\n} while (!kthread_should_stop());\r\ndev_dbg(&ips->dev->dev, "ips-adjust thread stopped\n");\r\nreturn 0;\r\n}\r\nstatic u16 calc_avg_temp(struct ips_driver *ips, u16 *array)\r\n{\r\nu64 total = 0;\r\nint i;\r\nu16 avg;\r\nfor (i = 0; i < IPS_SAMPLE_COUNT; i++)\r\ntotal += (u64)(array[i] * 100);\r\ndo_div(total, IPS_SAMPLE_COUNT);\r\navg = (u16)total;\r\nreturn avg;\r\n}\r\nstatic u16 read_mgtv(struct ips_driver *ips)\r\n{\r\nu16 ret;\r\nu64 slope, offset;\r\nu64 val;\r\nval = thm_readq(THM_MGTV);\r\nval = (val & TV_MASK) >> TV_SHIFT;\r\nslope = offset = thm_readw(THM_MGTA);\r\nslope = (slope & MGTA_SLOPE_MASK) >> MGTA_SLOPE_SHIFT;\r\noffset = offset & MGTA_OFFSET_MASK;\r\nret = ((val * slope + 0x40) >> 7) + offset;\r\nreturn 0;\r\n}\r\nstatic u16 read_ptv(struct ips_driver *ips)\r\n{\r\nu16 val, slope, offset;\r\nslope = (ips->pta_val & PTA_SLOPE_MASK) >> PTA_SLOPE_SHIFT;\r\noffset = ips->pta_val & PTA_OFFSET_MASK;\r\nval = thm_readw(THM_PTV) & PTV_MASK;\r\nreturn val;\r\n}\r\nstatic u16 read_ctv(struct ips_driver *ips, int cpu)\r\n{\r\nint reg = cpu ? THM_CTV2 : THM_CTV1;\r\nu16 val;\r\nval = thm_readw(reg);\r\nif (!(val & CTV_TEMP_ERROR))\r\nval = (val) >> 6;\r\nelse\r\nval = 0;\r\nreturn val;\r\n}\r\nstatic u32 get_cpu_power(struct ips_driver *ips, u32 *last, int period)\r\n{\r\nu32 val;\r\nu32 ret;\r\nval = thm_readl(THM_CEC);\r\nret = (((val - *last) * 1000) / period);\r\nret = (ret * 1000) / 65535;\r\n*last = val;\r\nreturn 0;\r\n}\r\nstatic u16 update_average_temp(u16 avg, u16 val)\r\n{\r\nu16 ret;\r\nret = (val * 100 / temp_decay_factor) +\r\n(((temp_decay_factor - 1) * avg) / temp_decay_factor);\r\nreturn ret;\r\n}\r\nstatic u16 update_average_power(u32 avg, u32 val)\r\n{\r\nu32 ret;\r\nret = (val / power_decay_factor) +\r\n(((power_decay_factor - 1) * avg) / power_decay_factor);\r\nreturn ret;\r\n}\r\nstatic u32 calc_avg_power(struct ips_driver *ips, u32 *array)\r\n{\r\nu64 total = 0;\r\nu32 avg;\r\nint i;\r\nfor (i = 0; i < IPS_SAMPLE_COUNT; i++)\r\ntotal += array[i];\r\ndo_div(total, IPS_SAMPLE_COUNT);\r\navg = (u32)total;\r\nreturn avg;\r\n}\r\nstatic void monitor_timeout(unsigned long arg)\r\n{\r\nwake_up_process((struct task_struct *)arg);\r\n}\r\nstatic int ips_monitor(void *data)\r\n{\r\nstruct ips_driver *ips = data;\r\nstruct timer_list timer;\r\nunsigned long seqno_timestamp, expire, last_msecs, last_sample_period;\r\nint i;\r\nu32 *cpu_samples, *mchp_samples, old_cpu_power;\r\nu16 *mcp_samples, *ctv1_samples, *ctv2_samples, *mch_samples;\r\nu8 cur_seqno, last_seqno;\r\nmcp_samples = kzalloc(sizeof(u16) * IPS_SAMPLE_COUNT, GFP_KERNEL);\r\nctv1_samples = kzalloc(sizeof(u16) * IPS_SAMPLE_COUNT, GFP_KERNEL);\r\nctv2_samples = kzalloc(sizeof(u16) * IPS_SAMPLE_COUNT, GFP_KERNEL);\r\nmch_samples = kzalloc(sizeof(u16) * IPS_SAMPLE_COUNT, GFP_KERNEL);\r\ncpu_samples = kzalloc(sizeof(u32) * IPS_SAMPLE_COUNT, GFP_KERNEL);\r\nmchp_samples = kzalloc(sizeof(u32) * IPS_SAMPLE_COUNT, GFP_KERNEL);\r\nif (!mcp_samples || !ctv1_samples || !ctv2_samples || !mch_samples ||\r\n!cpu_samples || !mchp_samples) {\r\ndev_err(&ips->dev->dev,\r\n"failed to allocate sample array, ips disabled\n");\r\nkfree(mcp_samples);\r\nkfree(ctv1_samples);\r\nkfree(ctv2_samples);\r\nkfree(mch_samples);\r\nkfree(cpu_samples);\r\nkfree(mchp_samples);\r\nreturn -ENOMEM;\r\n}\r\nlast_seqno = (thm_readl(THM_ITV) & ITV_ME_SEQNO_MASK) >>\r\nITV_ME_SEQNO_SHIFT;\r\nseqno_timestamp = get_jiffies_64();\r\nold_cpu_power = thm_readl(THM_CEC);\r\nschedule_timeout_interruptible(msecs_to_jiffies(IPS_SAMPLE_PERIOD));\r\nfor (i = 0; i < IPS_SAMPLE_COUNT; i++) {\r\nu32 mchp, cpu_power;\r\nu16 val;\r\nmcp_samples[i] = read_ptv(ips);\r\nval = read_ctv(ips, 0);\r\nctv1_samples[i] = val;\r\nval = read_ctv(ips, 1);\r\nctv2_samples[i] = val;\r\nval = read_mgtv(ips);\r\nmch_samples[i] = val;\r\ncpu_power = get_cpu_power(ips, &old_cpu_power,\r\nIPS_SAMPLE_PERIOD);\r\ncpu_samples[i] = cpu_power;\r\nif (ips->read_mch_val) {\r\nmchp = ips->read_mch_val();\r\nmchp_samples[i] = mchp;\r\n}\r\nschedule_timeout_interruptible(msecs_to_jiffies(IPS_SAMPLE_PERIOD));\r\nif (kthread_should_stop())\r\nbreak;\r\n}\r\nips->mcp_avg_temp = calc_avg_temp(ips, mcp_samples);\r\nips->ctv1_avg_temp = calc_avg_temp(ips, ctv1_samples);\r\nips->ctv2_avg_temp = calc_avg_temp(ips, ctv2_samples);\r\nips->mch_avg_temp = calc_avg_temp(ips, mch_samples);\r\nips->cpu_avg_power = calc_avg_power(ips, cpu_samples);\r\nips->mch_avg_power = calc_avg_power(ips, mchp_samples);\r\nkfree(mcp_samples);\r\nkfree(ctv1_samples);\r\nkfree(ctv2_samples);\r\nkfree(mch_samples);\r\nkfree(cpu_samples);\r\nkfree(mchp_samples);\r\nwake_up_process(ips->adjust);\r\nold_cpu_power = thm_readl(THM_CEC);\r\nschedule_timeout_interruptible(msecs_to_jiffies(IPS_SAMPLE_PERIOD));\r\nlast_sample_period = IPS_SAMPLE_PERIOD;\r\nsetup_deferrable_timer_on_stack(&timer, monitor_timeout,\r\n(unsigned long)current);\r\ndo {\r\nu32 cpu_val, mch_val;\r\nu16 val;\r\nval = read_ptv(ips);\r\nips->mcp_avg_temp = update_average_temp(ips->mcp_avg_temp, val);\r\nval = read_ctv(ips, 0);\r\nips->ctv1_avg_temp =\r\nupdate_average_temp(ips->ctv1_avg_temp, val);\r\ncpu_val = get_cpu_power(ips, &old_cpu_power,\r\nlast_sample_period);\r\nips->cpu_avg_power =\r\nupdate_average_power(ips->cpu_avg_power, cpu_val);\r\nif (ips->second_cpu) {\r\nval = read_ctv(ips, 1);\r\nips->ctv2_avg_temp =\r\nupdate_average_temp(ips->ctv2_avg_temp, val);\r\n}\r\nval = read_mgtv(ips);\r\nips->mch_avg_temp = update_average_temp(ips->mch_avg_temp, val);\r\nif (ips->read_mch_val) {\r\nmch_val = ips->read_mch_val();\r\nips->mch_avg_power =\r\nupdate_average_power(ips->mch_avg_power,\r\nmch_val);\r\n}\r\ncur_seqno = (thm_readl(THM_ITV) & ITV_ME_SEQNO_MASK) >>\r\nITV_ME_SEQNO_SHIFT;\r\nif (cur_seqno == last_seqno &&\r\ntime_after(jiffies, seqno_timestamp + HZ)) {\r\ndev_warn(&ips->dev->dev, "ME failed to update for more than 1s, likely hung\n");\r\n} else {\r\nseqno_timestamp = get_jiffies_64();\r\nlast_seqno = cur_seqno;\r\n}\r\nlast_msecs = jiffies_to_msecs(jiffies);\r\nexpire = jiffies + msecs_to_jiffies(IPS_SAMPLE_PERIOD);\r\n__set_current_state(TASK_INTERRUPTIBLE);\r\nmod_timer(&timer, expire);\r\nschedule();\r\nlast_sample_period = jiffies_to_msecs(jiffies) - last_msecs;\r\nif (!last_sample_period)\r\nlast_sample_period = 1;\r\n} while (!kthread_should_stop());\r\ndel_timer_sync(&timer);\r\ndestroy_timer_on_stack(&timer);\r\ndev_dbg(&ips->dev->dev, "ips-monitor thread stopped\n");\r\nreturn 0;\r\n}\r\nstatic irqreturn_t ips_irq_handler(int irq, void *arg)\r\n{\r\nstruct ips_driver *ips = arg;\r\nu8 tses = thm_readb(THM_TSES);\r\nu8 tes = thm_readb(THM_TES);\r\nif (!tses && !tes)\r\nreturn IRQ_NONE;\r\ndev_info(&ips->dev->dev, "TSES: 0x%02x\n", tses);\r\ndev_info(&ips->dev->dev, "TES: 0x%02x\n", tes);\r\nif (tes & 1) {\r\nu32 sts, tc1;\r\nsts = thm_readl(THM_STS);\r\ntc1 = thm_readl(THM_TC1);\r\nif (sts & STS_NVV) {\r\nspin_lock(&ips->turbo_status_lock);\r\nips->core_power_limit = (sts & STS_PCPL_MASK) >>\r\nSTS_PCPL_SHIFT;\r\nips->mch_power_limit = (sts & STS_GPL_MASK) >>\r\nSTS_GPL_SHIFT;\r\nips->cpu_turbo_enabled = !(sts & STS_PCTD_DIS);\r\nips->cpu_turbo_enabled = false;\r\nif (ips->gpu_busy)\r\nips->gpu_turbo_enabled = !(sts & STS_GTD_DIS);\r\nips->mcp_temp_limit = (sts & STS_PTL_MASK) >>\r\nSTS_PTL_SHIFT;\r\nips->mcp_power_limit = (tc1 & STS_PPL_MASK) >>\r\nSTS_PPL_SHIFT;\r\nverify_limits(ips);\r\nspin_unlock(&ips->turbo_status_lock);\r\nthm_writeb(THM_SEC, SEC_ACK);\r\n}\r\nthm_writeb(THM_TES, tes);\r\n}\r\nif (tses) {\r\ndev_warn(&ips->dev->dev,\r\n"thermal trip occurred, tses: 0x%04x\n", tses);\r\nthm_writeb(THM_TSES, tses);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void ips_debugfs_init(struct ips_driver *ips) { return; }\r\nstatic void ips_debugfs_cleanup(struct ips_driver *ips) { return; }\r\nstatic int show_cpu_temp(struct seq_file *m, void *data)\r\n{\r\nstruct ips_driver *ips = m->private;\r\nseq_printf(m, "%d.%02d\n", ips->ctv1_avg_temp / 100,\r\nips->ctv1_avg_temp % 100);\r\nreturn 0;\r\n}\r\nstatic int show_cpu_power(struct seq_file *m, void *data)\r\n{\r\nstruct ips_driver *ips = m->private;\r\nseq_printf(m, "%dmW\n", ips->cpu_avg_power);\r\nreturn 0;\r\n}\r\nstatic int show_cpu_clamp(struct seq_file *m, void *data)\r\n{\r\nu64 turbo_override;\r\nint tdp, tdc;\r\nrdmsrl(TURBO_POWER_CURRENT_LIMIT, turbo_override);\r\ntdp = (int)(turbo_override & TURBO_TDP_MASK);\r\ntdc = (int)((turbo_override & TURBO_TDC_MASK) >> TURBO_TDC_SHIFT);\r\ntdp = tdp * 10 / 8;\r\ntdc = tdc * 10 / 8;\r\nseq_printf(m, "%d.%dW %d.%dA\n", tdp / 10, tdp % 10,\r\ntdc / 10, tdc % 10);\r\nreturn 0;\r\n}\r\nstatic int show_mch_temp(struct seq_file *m, void *data)\r\n{\r\nstruct ips_driver *ips = m->private;\r\nseq_printf(m, "%d.%02d\n", ips->mch_avg_temp / 100,\r\nips->mch_avg_temp % 100);\r\nreturn 0;\r\n}\r\nstatic int show_mch_power(struct seq_file *m, void *data)\r\n{\r\nstruct ips_driver *ips = m->private;\r\nseq_printf(m, "%dmW\n", ips->mch_avg_power);\r\nreturn 0;\r\n}\r\nstatic int ips_debugfs_open(struct inode *inode, struct file *file)\r\n{\r\nstruct ips_debugfs_node *node = inode->i_private;\r\nreturn single_open(file, node->show, node->ips);\r\n}\r\nstatic void ips_debugfs_cleanup(struct ips_driver *ips)\r\n{\r\nif (ips->debug_root)\r\ndebugfs_remove_recursive(ips->debug_root);\r\nreturn;\r\n}\r\nstatic void ips_debugfs_init(struct ips_driver *ips)\r\n{\r\nint i;\r\nips->debug_root = debugfs_create_dir("ips", NULL);\r\nif (!ips->debug_root) {\r\ndev_err(&ips->dev->dev,\r\n"failed to create debugfs entries: %ld\n",\r\nPTR_ERR(ips->debug_root));\r\nreturn;\r\n}\r\nfor (i = 0; i < ARRAY_SIZE(ips_debug_files); i++) {\r\nstruct dentry *ent;\r\nstruct ips_debugfs_node *node = &ips_debug_files[i];\r\nnode->ips = ips;\r\nent = debugfs_create_file(node->name, S_IFREG | S_IRUGO,\r\nips->debug_root, node,\r\n&ips_debugfs_ops);\r\nif (!ent) {\r\ndev_err(&ips->dev->dev,\r\n"failed to create debug file: %ld\n",\r\nPTR_ERR(ent));\r\ngoto err_cleanup;\r\n}\r\n}\r\nreturn;\r\nerr_cleanup:\r\nips_debugfs_cleanup(ips);\r\nreturn;\r\n}\r\nstatic struct ips_mcp_limits *ips_detect_cpu(struct ips_driver *ips)\r\n{\r\nu64 turbo_power, misc_en;\r\nstruct ips_mcp_limits *limits = NULL;\r\nu16 tdp;\r\nif (!(boot_cpu_data.x86 == 6 && boot_cpu_data.x86_model == 37)) {\r\ndev_info(&ips->dev->dev, "Non-IPS CPU detected.\n");\r\ngoto out;\r\n}\r\nrdmsrl(IA32_MISC_ENABLE, misc_en);\r\nif (misc_en & IA32_MISC_TURBO_EN)\r\nips->turbo_toggle_allowed = true;\r\nelse\r\nips->turbo_toggle_allowed = false;\r\nif (strstr(boot_cpu_data.x86_model_id, "CPU M"))\r\nlimits = &ips_sv_limits;\r\nelse if (strstr(boot_cpu_data.x86_model_id, "CPU L"))\r\nlimits = &ips_lv_limits;\r\nelse if (strstr(boot_cpu_data.x86_model_id, "CPU U"))\r\nlimits = &ips_ulv_limits;\r\nelse {\r\ndev_info(&ips->dev->dev, "No CPUID match found.\n");\r\ngoto out;\r\n}\r\nrdmsrl(TURBO_POWER_CURRENT_LIMIT, turbo_power);\r\ntdp = turbo_power & TURBO_TDP_MASK;\r\nif (limits->core_power_limit != (tdp / 8) * 1000) {\r\ndev_info(&ips->dev->dev, "CPU TDP doesn't match expected value (found %d, expected %d)\n",\r\ntdp / 8, limits->core_power_limit / 1000);\r\nlimits->core_power_limit = (tdp / 8) * 1000;\r\n}\r\nout:\r\nreturn limits;\r\n}\r\nstatic bool ips_get_i915_syms(struct ips_driver *ips)\r\n{\r\nips->read_mch_val = symbol_get(i915_read_mch_val);\r\nif (!ips->read_mch_val)\r\ngoto out_err;\r\nips->gpu_raise = symbol_get(i915_gpu_raise);\r\nif (!ips->gpu_raise)\r\ngoto out_put_mch;\r\nips->gpu_lower = symbol_get(i915_gpu_lower);\r\nif (!ips->gpu_lower)\r\ngoto out_put_raise;\r\nips->gpu_busy = symbol_get(i915_gpu_busy);\r\nif (!ips->gpu_busy)\r\ngoto out_put_lower;\r\nips->gpu_turbo_disable = symbol_get(i915_gpu_turbo_disable);\r\nif (!ips->gpu_turbo_disable)\r\ngoto out_put_busy;\r\nreturn true;\r\nout_put_busy:\r\nsymbol_put(i915_gpu_busy);\r\nout_put_lower:\r\nsymbol_put(i915_gpu_lower);\r\nout_put_raise:\r\nsymbol_put(i915_gpu_raise);\r\nout_put_mch:\r\nsymbol_put(i915_read_mch_val);\r\nout_err:\r\nreturn false;\r\n}\r\nstatic bool\r\nips_gpu_turbo_enabled(struct ips_driver *ips)\r\n{\r\nif (!ips->gpu_busy && late_i915_load) {\r\nif (ips_get_i915_syms(ips)) {\r\ndev_info(&ips->dev->dev,\r\n"i915 driver attached, reenabling gpu turbo\n");\r\nips->gpu_turbo_enabled = !(thm_readl(THM_HTS) & HTS_GTD_DIS);\r\n}\r\n}\r\nreturn ips->gpu_turbo_enabled;\r\n}\r\nvoid\r\nips_link_to_i915_driver(void)\r\n{\r\nlate_i915_load = true;\r\n}\r\nstatic int ips_blacklist_callback(const struct dmi_system_id *id)\r\n{\r\npr_info("Blacklisted intel_ips for %s\n", id->ident);\r\nreturn 1;\r\n}\r\nstatic int ips_probe(struct pci_dev *dev, const struct pci_device_id *id)\r\n{\r\nu64 platform_info;\r\nstruct ips_driver *ips;\r\nu32 hts;\r\nint ret = 0;\r\nu16 htshi, trc, trc_required_mask;\r\nu8 tse;\r\nif (dmi_check_system(ips_blacklist))\r\nreturn -ENODEV;\r\nips = kzalloc(sizeof(struct ips_driver), GFP_KERNEL);\r\nif (!ips)\r\nreturn -ENOMEM;\r\npci_set_drvdata(dev, ips);\r\nips->dev = dev;\r\nips->limits = ips_detect_cpu(ips);\r\nif (!ips->limits) {\r\ndev_info(&dev->dev, "IPS not supported on this CPU\n");\r\nret = -ENXIO;\r\ngoto error_free;\r\n}\r\nspin_lock_init(&ips->turbo_status_lock);\r\nret = pci_enable_device(dev);\r\nif (ret) {\r\ndev_err(&dev->dev, "can't enable PCI device, aborting\n");\r\ngoto error_free;\r\n}\r\nif (!pci_resource_start(dev, 0)) {\r\ndev_err(&dev->dev, "TBAR not assigned, aborting\n");\r\nret = -ENXIO;\r\ngoto error_free;\r\n}\r\nret = pci_request_regions(dev, "ips thermal sensor");\r\nif (ret) {\r\ndev_err(&dev->dev, "thermal resource busy, aborting\n");\r\ngoto error_free;\r\n}\r\nips->regmap = ioremap(pci_resource_start(dev, 0),\r\npci_resource_len(dev, 0));\r\nif (!ips->regmap) {\r\ndev_err(&dev->dev, "failed to map thermal regs, aborting\n");\r\nret = -EBUSY;\r\ngoto error_release;\r\n}\r\ntse = thm_readb(THM_TSE);\r\nif (tse != TSE_EN) {\r\ndev_err(&dev->dev, "thermal device not enabled (0x%02x), aborting\n", tse);\r\nret = -ENXIO;\r\ngoto error_unmap;\r\n}\r\ntrc = thm_readw(THM_TRC);\r\ntrc_required_mask = TRC_CORE1_EN | TRC_CORE_PWR | TRC_MCH_EN;\r\nif ((trc & trc_required_mask) != trc_required_mask) {\r\ndev_err(&dev->dev, "thermal reporting for required devices not enabled, aborting\n");\r\nret = -ENXIO;\r\ngoto error_unmap;\r\n}\r\nif (trc & TRC_CORE2_EN)\r\nips->second_cpu = true;\r\nupdate_turbo_limits(ips);\r\ndev_dbg(&dev->dev, "max cpu power clamp: %dW\n",\r\nips->mcp_power_limit / 10);\r\ndev_dbg(&dev->dev, "max core power clamp: %dW\n",\r\nips->core_power_limit / 10);\r\nif (thm_readl(THM_PSC) & PSP_PBRT)\r\nips->poll_turbo_status = true;\r\nif (!ips_get_i915_syms(ips)) {\r\ndev_info(&dev->dev, "failed to get i915 symbols, graphics turbo disabled until i915 loads\n");\r\nips->gpu_turbo_enabled = false;\r\n} else {\r\ndev_dbg(&dev->dev, "graphics turbo enabled\n");\r\nips->gpu_turbo_enabled = true;\r\n}\r\nrdmsrl(PLATFORM_INFO, platform_info);\r\nif (!(platform_info & PLATFORM_TDP)) {\r\ndev_err(&dev->dev, "platform indicates TDP override unavailable, aborting\n");\r\nret = -ENODEV;\r\ngoto error_unmap;\r\n}\r\npci_disable_msi(dev);\r\nret = request_irq(dev->irq, ips_irq_handler, IRQF_SHARED, "ips",\r\nips);\r\nif (ret) {\r\ndev_err(&dev->dev, "request irq failed, aborting\n");\r\ngoto error_unmap;\r\n}\r\nthm_writeb(THM_TSPIEN, TSPIEN_AUX2_LOHI | TSPIEN_CRIT_LOHI |\r\nTSPIEN_HOT_LOHI | TSPIEN_AUX_LOHI);\r\nthm_writeb(THM_TEN, TEN_UPDATE_EN);\r\nips->cta_val = thm_readw(THM_CTA);\r\nips->pta_val = thm_readw(THM_PTA);\r\nips->mgta_val = thm_readw(THM_MGTA);\r\nrdmsrl(TURBO_POWER_CURRENT_LIMIT, ips->orig_turbo_limit);\r\nips_disable_cpu_turbo(ips);\r\nips->cpu_turbo_enabled = false;\r\nips->adjust = kthread_create(ips_adjust, ips, "ips-adjust");\r\nif (IS_ERR(ips->adjust)) {\r\ndev_err(&dev->dev,\r\n"failed to create thermal adjust thread, aborting\n");\r\nret = -ENOMEM;\r\ngoto error_free_irq;\r\n}\r\nips->monitor = kthread_run(ips_monitor, ips, "ips-monitor");\r\nif (IS_ERR(ips->monitor)) {\r\ndev_err(&dev->dev,\r\n"failed to create thermal monitor thread, aborting\n");\r\nret = -ENOMEM;\r\ngoto error_thread_cleanup;\r\n}\r\nhts = (ips->core_power_limit << HTS_PCPL_SHIFT) |\r\n(ips->mcp_temp_limit << HTS_PTL_SHIFT) | HTS_NVV;\r\nhtshi = HTS2_PRST_RUNNING << HTS2_PRST_SHIFT;\r\nthm_writew(THM_HTSHI, htshi);\r\nthm_writel(THM_HTS, hts);\r\nips_debugfs_init(ips);\r\ndev_info(&dev->dev, "IPS driver initialized, MCP temp limit %d\n",\r\nips->mcp_temp_limit);\r\nreturn ret;\r\nerror_thread_cleanup:\r\nkthread_stop(ips->adjust);\r\nerror_free_irq:\r\nfree_irq(ips->dev->irq, ips);\r\nerror_unmap:\r\niounmap(ips->regmap);\r\nerror_release:\r\npci_release_regions(dev);\r\nerror_free:\r\nkfree(ips);\r\nreturn ret;\r\n}\r\nstatic void ips_remove(struct pci_dev *dev)\r\n{\r\nstruct ips_driver *ips = pci_get_drvdata(dev);\r\nu64 turbo_override;\r\nif (!ips)\r\nreturn;\r\nips_debugfs_cleanup(ips);\r\nif (ips->read_mch_val)\r\nsymbol_put(i915_read_mch_val);\r\nif (ips->gpu_raise)\r\nsymbol_put(i915_gpu_raise);\r\nif (ips->gpu_lower)\r\nsymbol_put(i915_gpu_lower);\r\nif (ips->gpu_busy)\r\nsymbol_put(i915_gpu_busy);\r\nif (ips->gpu_turbo_disable)\r\nsymbol_put(i915_gpu_turbo_disable);\r\nrdmsrl(TURBO_POWER_CURRENT_LIMIT, turbo_override);\r\nturbo_override &= ~(TURBO_TDC_OVR_EN | TURBO_TDP_OVR_EN);\r\nwrmsrl(TURBO_POWER_CURRENT_LIMIT, turbo_override);\r\nwrmsrl(TURBO_POWER_CURRENT_LIMIT, ips->orig_turbo_limit);\r\nfree_irq(ips->dev->irq, ips);\r\nif (ips->adjust)\r\nkthread_stop(ips->adjust);\r\nif (ips->monitor)\r\nkthread_stop(ips->monitor);\r\niounmap(ips->regmap);\r\npci_release_regions(dev);\r\nkfree(ips);\r\ndev_dbg(&dev->dev, "IPS driver removed\n");\r\n}\r\nstatic void ips_shutdown(struct pci_dev *dev)\r\n{\r\n}
