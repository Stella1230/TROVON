static inline unsigned mk_qpn(struct rvt_qpn_table *qpt,\r\nstruct rvt_qpn_map *map, unsigned off)\r\n{\r\nreturn (map - qpt->map) * RVT_BITS_PER_PAGE + off;\r\n}\r\nstatic inline unsigned find_next_offset(struct rvt_qpn_table *qpt,\r\nstruct rvt_qpn_map *map, unsigned off,\r\nunsigned n)\r\n{\r\nif (qpt_mask) {\r\noff++;\r\nif (((off & qpt_mask) >> 1) >= n)\r\noff = (off | qpt_mask) + 2;\r\n} else {\r\noff = find_next_zero_bit(map->page, RVT_BITS_PER_PAGE, off);\r\n}\r\nreturn off;\r\n}\r\nstatic void get_map_page(struct rvt_qpn_table *qpt, struct rvt_qpn_map *map,\r\ngfp_t gfp)\r\n{\r\nunsigned long page = get_zeroed_page(gfp);\r\nspin_lock(&qpt->lock);\r\nif (map->page)\r\nfree_page(page);\r\nelse\r\nmap->page = (void *)page;\r\nspin_unlock(&qpt->lock);\r\n}\r\nint qib_alloc_qpn(struct rvt_dev_info *rdi, struct rvt_qpn_table *qpt,\r\nenum ib_qp_type type, u8 port, gfp_t gfp)\r\n{\r\nu32 i, offset, max_scan, qpn;\r\nstruct rvt_qpn_map *map;\r\nu32 ret;\r\nstruct qib_ibdev *verbs_dev = container_of(rdi, struct qib_ibdev, rdi);\r\nstruct qib_devdata *dd = container_of(verbs_dev, struct qib_devdata,\r\nverbs_dev);\r\nif (type == IB_QPT_SMI || type == IB_QPT_GSI) {\r\nunsigned n;\r\nret = type == IB_QPT_GSI;\r\nn = 1 << (ret + 2 * (port - 1));\r\nspin_lock(&qpt->lock);\r\nif (qpt->flags & n)\r\nret = -EINVAL;\r\nelse\r\nqpt->flags |= n;\r\nspin_unlock(&qpt->lock);\r\ngoto bail;\r\n}\r\nqpn = qpt->last + 2;\r\nif (qpn >= RVT_QPN_MAX)\r\nqpn = 2;\r\nif (qpt_mask && ((qpn & qpt_mask) >> 1) >= dd->n_krcv_queues)\r\nqpn = (qpn | qpt_mask) + 2;\r\noffset = qpn & RVT_BITS_PER_PAGE_MASK;\r\nmap = &qpt->map[qpn / RVT_BITS_PER_PAGE];\r\nmax_scan = qpt->nmaps - !offset;\r\nfor (i = 0;;) {\r\nif (unlikely(!map->page)) {\r\nget_map_page(qpt, map, gfp);\r\nif (unlikely(!map->page))\r\nbreak;\r\n}\r\ndo {\r\nif (!test_and_set_bit(offset, map->page)) {\r\nqpt->last = qpn;\r\nret = qpn;\r\ngoto bail;\r\n}\r\noffset = find_next_offset(qpt, map, offset,\r\ndd->n_krcv_queues);\r\nqpn = mk_qpn(qpt, map, offset);\r\n} while (offset < RVT_BITS_PER_PAGE && qpn < RVT_QPN_MAX);\r\nif (++i > max_scan) {\r\nif (qpt->nmaps == RVT_QPNMAP_ENTRIES)\r\nbreak;\r\nmap = &qpt->map[qpt->nmaps++];\r\noffset = 0;\r\n} else if (map < &qpt->map[qpt->nmaps]) {\r\n++map;\r\noffset = 0;\r\n} else {\r\nmap = &qpt->map[0];\r\noffset = 2;\r\n}\r\nqpn = mk_qpn(qpt, map, offset);\r\n}\r\nret = -ENOMEM;\r\nbail:\r\nreturn ret;\r\n}\r\nunsigned qib_free_all_qps(struct rvt_dev_info *rdi)\r\n{\r\nstruct qib_ibdev *verbs_dev = container_of(rdi, struct qib_ibdev, rdi);\r\nstruct qib_devdata *dd = container_of(verbs_dev, struct qib_devdata,\r\nverbs_dev);\r\nunsigned n, qp_inuse = 0;\r\nfor (n = 0; n < dd->num_pports; n++) {\r\nstruct qib_ibport *ibp = &dd->pport[n].ibport_data;\r\nrcu_read_lock();\r\nif (rcu_dereference(ibp->rvp.qp[0]))\r\nqp_inuse++;\r\nif (rcu_dereference(ibp->rvp.qp[1]))\r\nqp_inuse++;\r\nrcu_read_unlock();\r\n}\r\nreturn qp_inuse;\r\n}\r\nvoid qib_notify_qp_reset(struct rvt_qp *qp)\r\n{\r\nstruct qib_qp_priv *priv = qp->priv;\r\natomic_set(&priv->s_dma_busy, 0);\r\n}\r\nvoid qib_notify_error_qp(struct rvt_qp *qp)\r\n{\r\nstruct qib_qp_priv *priv = qp->priv;\r\nstruct qib_ibdev *dev = to_idev(qp->ibqp.device);\r\nspin_lock(&dev->rdi.pending_lock);\r\nif (!list_empty(&priv->iowait) && !(qp->s_flags & RVT_S_BUSY)) {\r\nqp->s_flags &= ~RVT_S_ANY_WAIT_IO;\r\nlist_del_init(&priv->iowait);\r\n}\r\nspin_unlock(&dev->rdi.pending_lock);\r\nif (!(qp->s_flags & RVT_S_BUSY)) {\r\nqp->s_hdrwords = 0;\r\nif (qp->s_rdma_mr) {\r\nrvt_put_mr(qp->s_rdma_mr);\r\nqp->s_rdma_mr = NULL;\r\n}\r\nif (priv->s_tx) {\r\nqib_put_txreq(priv->s_tx);\r\npriv->s_tx = NULL;\r\n}\r\n}\r\n}\r\nstatic int mtu_to_enum(u32 mtu)\r\n{\r\nint enum_mtu;\r\nswitch (mtu) {\r\ncase 4096:\r\nenum_mtu = IB_MTU_4096;\r\nbreak;\r\ncase 2048:\r\nenum_mtu = IB_MTU_2048;\r\nbreak;\r\ncase 1024:\r\nenum_mtu = IB_MTU_1024;\r\nbreak;\r\ncase 512:\r\nenum_mtu = IB_MTU_512;\r\nbreak;\r\ncase 256:\r\nenum_mtu = IB_MTU_256;\r\nbreak;\r\ndefault:\r\nenum_mtu = IB_MTU_2048;\r\n}\r\nreturn enum_mtu;\r\n}\r\nint qib_get_pmtu_from_attr(struct rvt_dev_info *rdi, struct rvt_qp *qp,\r\nstruct ib_qp_attr *attr)\r\n{\r\nint mtu, pmtu, pidx = qp->port_num - 1;\r\nstruct qib_ibdev *verbs_dev = container_of(rdi, struct qib_ibdev, rdi);\r\nstruct qib_devdata *dd = container_of(verbs_dev, struct qib_devdata,\r\nverbs_dev);\r\nmtu = ib_mtu_enum_to_int(attr->path_mtu);\r\nif (mtu == -1)\r\nreturn -EINVAL;\r\nif (mtu > dd->pport[pidx].ibmtu)\r\npmtu = mtu_to_enum(dd->pport[pidx].ibmtu);\r\nelse\r\npmtu = attr->path_mtu;\r\nreturn pmtu;\r\n}\r\nint qib_mtu_to_path_mtu(u32 mtu)\r\n{\r\nreturn mtu_to_enum(mtu);\r\n}\r\nu32 qib_mtu_from_qp(struct rvt_dev_info *rdi, struct rvt_qp *qp, u32 pmtu)\r\n{\r\nreturn ib_mtu_enum_to_int(pmtu);\r\n}\r\n__be32 qib_compute_aeth(struct rvt_qp *qp)\r\n{\r\nu32 aeth = qp->r_msn & QIB_MSN_MASK;\r\nif (qp->ibqp.srq) {\r\naeth |= QIB_AETH_CREDIT_INVAL << QIB_AETH_CREDIT_SHIFT;\r\n} else {\r\nu32 min, max, x;\r\nu32 credits;\r\nstruct rvt_rwq *wq = qp->r_rq.wq;\r\nu32 head;\r\nu32 tail;\r\nhead = wq->head;\r\nif (head >= qp->r_rq.size)\r\nhead = 0;\r\ntail = wq->tail;\r\nif (tail >= qp->r_rq.size)\r\ntail = 0;\r\ncredits = head - tail;\r\nif ((int)credits < 0)\r\ncredits += qp->r_rq.size;\r\nmin = 0;\r\nmax = 31;\r\nfor (;;) {\r\nx = (min + max) / 2;\r\nif (credit_table[x] == credits)\r\nbreak;\r\nif (credit_table[x] > credits)\r\nmax = x;\r\nelse if (min == x)\r\nbreak;\r\nelse\r\nmin = x;\r\n}\r\naeth |= x << QIB_AETH_CREDIT_SHIFT;\r\n}\r\nreturn cpu_to_be32(aeth);\r\n}\r\nvoid *qib_qp_priv_alloc(struct rvt_dev_info *rdi, struct rvt_qp *qp, gfp_t gfp)\r\n{\r\nstruct qib_qp_priv *priv;\r\npriv = kzalloc(sizeof(*priv), gfp);\r\nif (!priv)\r\nreturn ERR_PTR(-ENOMEM);\r\npriv->owner = qp;\r\npriv->s_hdr = kzalloc(sizeof(*priv->s_hdr), gfp);\r\nif (!priv->s_hdr) {\r\nkfree(priv);\r\nreturn ERR_PTR(-ENOMEM);\r\n}\r\ninit_waitqueue_head(&priv->wait_dma);\r\nINIT_WORK(&priv->s_work, _qib_do_send);\r\nINIT_LIST_HEAD(&priv->iowait);\r\nreturn priv;\r\n}\r\nvoid qib_qp_priv_free(struct rvt_dev_info *rdi, struct rvt_qp *qp)\r\n{\r\nstruct qib_qp_priv *priv = qp->priv;\r\nkfree(priv->s_hdr);\r\nkfree(priv);\r\n}\r\nvoid qib_stop_send_queue(struct rvt_qp *qp)\r\n{\r\nstruct qib_qp_priv *priv = qp->priv;\r\ncancel_work_sync(&priv->s_work);\r\ndel_timer_sync(&qp->s_timer);\r\n}\r\nvoid qib_quiesce_qp(struct rvt_qp *qp)\r\n{\r\nstruct qib_qp_priv *priv = qp->priv;\r\nwait_event(priv->wait_dma, !atomic_read(&priv->s_dma_busy));\r\nif (priv->s_tx) {\r\nqib_put_txreq(priv->s_tx);\r\npriv->s_tx = NULL;\r\n}\r\n}\r\nvoid qib_flush_qp_waiters(struct rvt_qp *qp)\r\n{\r\nstruct qib_qp_priv *priv = qp->priv;\r\nstruct qib_ibdev *dev = to_idev(qp->ibqp.device);\r\nspin_lock(&dev->rdi.pending_lock);\r\nif (!list_empty(&priv->iowait))\r\nlist_del_init(&priv->iowait);\r\nspin_unlock(&dev->rdi.pending_lock);\r\n}\r\nvoid qib_get_credit(struct rvt_qp *qp, u32 aeth)\r\n{\r\nu32 credit = (aeth >> QIB_AETH_CREDIT_SHIFT) & QIB_AETH_CREDIT_MASK;\r\nif (credit == QIB_AETH_CREDIT_INVAL) {\r\nif (!(qp->s_flags & RVT_S_UNLIMITED_CREDIT)) {\r\nqp->s_flags |= RVT_S_UNLIMITED_CREDIT;\r\nif (qp->s_flags & RVT_S_WAIT_SSN_CREDIT) {\r\nqp->s_flags &= ~RVT_S_WAIT_SSN_CREDIT;\r\nqib_schedule_send(qp);\r\n}\r\n}\r\n} else if (!(qp->s_flags & RVT_S_UNLIMITED_CREDIT)) {\r\ncredit = (aeth + credit_table[credit]) & QIB_MSN_MASK;\r\nif (qib_cmp24(credit, qp->s_lsn) > 0) {\r\nqp->s_lsn = credit;\r\nif (qp->s_flags & RVT_S_WAIT_SSN_CREDIT) {\r\nqp->s_flags &= ~RVT_S_WAIT_SSN_CREDIT;\r\nqib_schedule_send(qp);\r\n}\r\n}\r\n}\r\n}\r\nint qib_check_send_wqe(struct rvt_qp *qp,\r\nstruct rvt_swqe *wqe)\r\n{\r\nstruct rvt_ah *ah;\r\nint ret = 0;\r\nswitch (qp->ibqp.qp_type) {\r\ncase IB_QPT_RC:\r\ncase IB_QPT_UC:\r\nif (wqe->length > 0x80000000U)\r\nreturn -EINVAL;\r\nbreak;\r\ncase IB_QPT_SMI:\r\ncase IB_QPT_GSI:\r\ncase IB_QPT_UD:\r\nah = ibah_to_rvtah(wqe->ud_wr.ah);\r\nif (wqe->length > (1 << ah->log_pmtu))\r\nreturn -EINVAL;\r\nret = 1;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nstruct qib_qp_iter *qib_qp_iter_init(struct qib_ibdev *dev)\r\n{\r\nstruct qib_qp_iter *iter;\r\niter = kzalloc(sizeof(*iter), GFP_KERNEL);\r\nif (!iter)\r\nreturn NULL;\r\niter->dev = dev;\r\nif (qib_qp_iter_next(iter)) {\r\nkfree(iter);\r\nreturn NULL;\r\n}\r\nreturn iter;\r\n}\r\nint qib_qp_iter_next(struct qib_qp_iter *iter)\r\n{\r\nstruct qib_ibdev *dev = iter->dev;\r\nint n = iter->n;\r\nint ret = 1;\r\nstruct rvt_qp *pqp = iter->qp;\r\nstruct rvt_qp *qp;\r\nfor (; n < dev->rdi.qp_dev->qp_table_size; n++) {\r\nif (pqp)\r\nqp = rcu_dereference(pqp->next);\r\nelse\r\nqp = rcu_dereference(dev->rdi.qp_dev->qp_table[n]);\r\npqp = qp;\r\nif (qp) {\r\niter->qp = qp;\r\niter->n = n;\r\nreturn 0;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nvoid qib_qp_iter_print(struct seq_file *s, struct qib_qp_iter *iter)\r\n{\r\nstruct rvt_swqe *wqe;\r\nstruct rvt_qp *qp = iter->qp;\r\nstruct qib_qp_priv *priv = qp->priv;\r\nwqe = rvt_get_swqe_ptr(qp, qp->s_last);\r\nseq_printf(s,\r\n"N %d QP%u %s %u %u %u f=%x %u %u %u %u %u PSN %x %x %x %x %x (%u %u %u %u %u %u) QP%u LID %x\n",\r\niter->n,\r\nqp->ibqp.qp_num,\r\nqp_type_str[qp->ibqp.qp_type],\r\nqp->state,\r\nwqe->wr.opcode,\r\nqp->s_hdrwords,\r\nqp->s_flags,\r\natomic_read(&priv->s_dma_busy),\r\n!list_empty(&priv->iowait),\r\nqp->timeout,\r\nwqe->ssn,\r\nqp->s_lsn,\r\nqp->s_last_psn,\r\nqp->s_psn, qp->s_next_psn,\r\nqp->s_sending_psn, qp->s_sending_hpsn,\r\nqp->s_last, qp->s_acked, qp->s_cur,\r\nqp->s_tail, qp->s_head, qp->s_size,\r\nqp->remote_qpn,\r\nqp->remote_ah_attr.dlid);\r\n}
