static bool break_test(void)\r\n{\r\nreturn test_error || kthread_should_stop();\r\n}\r\nstatic enum event_status read_event(int cpu)\r\n{\r\nstruct ring_buffer_event *event;\r\nint *entry;\r\nu64 ts;\r\nevent = ring_buffer_consume(buffer, cpu, &ts, NULL);\r\nif (!event)\r\nreturn EVENT_DROPPED;\r\nentry = ring_buffer_event_data(event);\r\nif (*entry != cpu) {\r\nTEST_ERROR();\r\nreturn EVENT_DROPPED;\r\n}\r\nread++;\r\nreturn EVENT_FOUND;\r\n}\r\nstatic enum event_status read_page(int cpu)\r\n{\r\nstruct ring_buffer_event *event;\r\nstruct rb_page *rpage;\r\nunsigned long commit;\r\nvoid *bpage;\r\nint *entry;\r\nint ret;\r\nint inc;\r\nint i;\r\nbpage = ring_buffer_alloc_read_page(buffer, cpu);\r\nif (!bpage)\r\nreturn EVENT_DROPPED;\r\nret = ring_buffer_read_page(buffer, &bpage, PAGE_SIZE, cpu, 1);\r\nif (ret >= 0) {\r\nrpage = bpage;\r\ncommit = local_read(&rpage->commit) & 0xfffff;\r\nfor (i = 0; i < commit && !test_error ; i += inc) {\r\nif (i >= (PAGE_SIZE - offsetof(struct rb_page, data))) {\r\nTEST_ERROR();\r\nbreak;\r\n}\r\ninc = -1;\r\nevent = (void *)&rpage->data[i];\r\nswitch (event->type_len) {\r\ncase RINGBUF_TYPE_PADDING:\r\nif (!event->time_delta)\r\nTEST_ERROR();\r\ninc = event->array[0] + 4;\r\nbreak;\r\ncase RINGBUF_TYPE_TIME_EXTEND:\r\ninc = 8;\r\nbreak;\r\ncase 0:\r\nentry = ring_buffer_event_data(event);\r\nif (*entry != cpu) {\r\nTEST_ERROR();\r\nbreak;\r\n}\r\nread++;\r\nif (!event->array[0]) {\r\nTEST_ERROR();\r\nbreak;\r\n}\r\ninc = event->array[0] + 4;\r\nbreak;\r\ndefault:\r\nentry = ring_buffer_event_data(event);\r\nif (*entry != cpu) {\r\nTEST_ERROR();\r\nbreak;\r\n}\r\nread++;\r\ninc = ((event->type_len + 1) * 4);\r\n}\r\nif (test_error)\r\nbreak;\r\nif (inc <= 0) {\r\nTEST_ERROR();\r\nbreak;\r\n}\r\n}\r\n}\r\nring_buffer_free_read_page(buffer, bpage);\r\nif (ret < 0)\r\nreturn EVENT_DROPPED;\r\nreturn EVENT_FOUND;\r\n}\r\nstatic void ring_buffer_consumer(void)\r\n{\r\nread_events ^= 1;\r\nread = 0;\r\nwhile (!READ_ONCE(reader_finish)) {\r\nint found = 1;\r\nwhile (found && !test_error) {\r\nint cpu;\r\nfound = 0;\r\nfor_each_online_cpu(cpu) {\r\nenum event_status stat;\r\nif (read_events)\r\nstat = read_event(cpu);\r\nelse\r\nstat = read_page(cpu);\r\nif (test_error)\r\nbreak;\r\nif (stat == EVENT_FOUND)\r\nfound = 1;\r\n}\r\n}\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nif (reader_finish)\r\nbreak;\r\nschedule();\r\n}\r\n__set_current_state(TASK_RUNNING);\r\nreader_finish = 0;\r\ncomplete(&read_done);\r\n}\r\nstatic void ring_buffer_producer(void)\r\n{\r\nktime_t start_time, end_time, timeout;\r\nunsigned long long time;\r\nunsigned long long entries;\r\nunsigned long long overruns;\r\nunsigned long missed = 0;\r\nunsigned long hit = 0;\r\nunsigned long avg;\r\nint cnt = 0;\r\ntrace_printk("Starting ring buffer hammer\n");\r\nstart_time = ktime_get();\r\ntimeout = ktime_add_ns(start_time, RUN_TIME * NSEC_PER_SEC);\r\ndo {\r\nstruct ring_buffer_event *event;\r\nint *entry;\r\nint i;\r\nfor (i = 0; i < write_iteration; i++) {\r\nevent = ring_buffer_lock_reserve(buffer, 10);\r\nif (!event) {\r\nmissed++;\r\n} else {\r\nhit++;\r\nentry = ring_buffer_event_data(event);\r\n*entry = smp_processor_id();\r\nring_buffer_unlock_commit(buffer, event);\r\n}\r\n}\r\nend_time = ktime_get();\r\ncnt++;\r\nif (consumer && !(cnt % wakeup_interval))\r\nwake_up_process(consumer);\r\n#ifndef CONFIG_PREEMPT\r\nif (cnt % wakeup_interval)\r\ncond_resched();\r\n#endif\r\n} while (ktime_before(end_time, timeout) && !break_test());\r\ntrace_printk("End ring buffer hammer\n");\r\nif (consumer) {\r\ninit_completion(&read_start);\r\ninit_completion(&read_done);\r\nsmp_wmb();\r\nreader_finish = 1;\r\nwake_up_process(consumer);\r\nwait_for_completion(&read_done);\r\n}\r\ntime = ktime_us_delta(end_time, start_time);\r\nentries = ring_buffer_entries(buffer);\r\noverruns = ring_buffer_overruns(buffer);\r\nif (test_error)\r\ntrace_printk("ERROR!\n");\r\nif (!disable_reader) {\r\nif (consumer_fifo < 0)\r\ntrace_printk("Running Consumer at nice: %d\n",\r\nconsumer_nice);\r\nelse\r\ntrace_printk("Running Consumer at SCHED_FIFO %d\n",\r\nconsumer_fifo);\r\n}\r\nif (producer_fifo < 0)\r\ntrace_printk("Running Producer at nice: %d\n",\r\nproducer_nice);\r\nelse\r\ntrace_printk("Running Producer at SCHED_FIFO %d\n",\r\nproducer_fifo);\r\nif (producer_fifo < 0 && consumer_fifo < 0 &&\r\nproducer_nice == MAX_NICE && consumer_nice == MAX_NICE)\r\ntrace_printk("WARNING!!! This test is running at lowest priority.\n");\r\ntrace_printk("Time: %lld (usecs)\n", time);\r\ntrace_printk("Overruns: %lld\n", overruns);\r\nif (disable_reader)\r\ntrace_printk("Read: (reader disabled)\n");\r\nelse\r\ntrace_printk("Read: %ld (by %s)\n", read,\r\nread_events ? "events" : "pages");\r\ntrace_printk("Entries: %lld\n", entries);\r\ntrace_printk("Total: %lld\n", entries + overruns + read);\r\ntrace_printk("Missed: %ld\n", missed);\r\ntrace_printk("Hit: %ld\n", hit);\r\ndo_div(time, USEC_PER_MSEC);\r\nif (time)\r\nhit /= (long)time;\r\nelse\r\ntrace_printk("TIME IS ZERO??\n");\r\ntrace_printk("Entries per millisec: %ld\n", hit);\r\nif (hit) {\r\navg = NSEC_PER_MSEC / hit;\r\ntrace_printk("%ld ns per entry\n", avg);\r\n}\r\nif (missed) {\r\nif (time)\r\nmissed /= (long)time;\r\ntrace_printk("Total iterations per millisec: %ld\n",\r\nhit + missed);\r\nif (!(hit + missed)) {\r\ntrace_printk("hit + missed overflowed and totalled zero!\n");\r\nhit--;\r\n}\r\navg = NSEC_PER_MSEC / (hit + missed);\r\ntrace_printk("%ld ns per entry\n", avg);\r\n}\r\n}\r\nstatic void wait_to_die(void)\r\n{\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nwhile (!kthread_should_stop()) {\r\nschedule();\r\nset_current_state(TASK_INTERRUPTIBLE);\r\n}\r\n__set_current_state(TASK_RUNNING);\r\n}\r\nstatic int ring_buffer_consumer_thread(void *arg)\r\n{\r\nwhile (!break_test()) {\r\ncomplete(&read_start);\r\nring_buffer_consumer();\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nif (break_test())\r\nbreak;\r\nschedule();\r\n}\r\n__set_current_state(TASK_RUNNING);\r\nif (!kthread_should_stop())\r\nwait_to_die();\r\nreturn 0;\r\n}\r\nstatic int ring_buffer_producer_thread(void *arg)\r\n{\r\nwhile (!break_test()) {\r\nring_buffer_reset(buffer);\r\nif (consumer) {\r\nwake_up_process(consumer);\r\nwait_for_completion(&read_start);\r\n}\r\nring_buffer_producer();\r\nif (break_test())\r\ngoto out_kill;\r\ntrace_printk("Sleeping for 10 secs\n");\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nif (break_test())\r\ngoto out_kill;\r\nschedule_timeout(HZ * SLEEP_TIME);\r\n}\r\nout_kill:\r\n__set_current_state(TASK_RUNNING);\r\nif (!kthread_should_stop())\r\nwait_to_die();\r\nreturn 0;\r\n}\r\nstatic int __init ring_buffer_benchmark_init(void)\r\n{\r\nint ret;\r\nbuffer = ring_buffer_alloc(1000000, RB_FL_OVERWRITE);\r\nif (!buffer)\r\nreturn -ENOMEM;\r\nif (!disable_reader) {\r\nconsumer = kthread_create(ring_buffer_consumer_thread,\r\nNULL, "rb_consumer");\r\nret = PTR_ERR(consumer);\r\nif (IS_ERR(consumer))\r\ngoto out_fail;\r\n}\r\nproducer = kthread_run(ring_buffer_producer_thread,\r\nNULL, "rb_producer");\r\nret = PTR_ERR(producer);\r\nif (IS_ERR(producer))\r\ngoto out_kill;\r\nif (!disable_reader) {\r\nif (consumer_fifo >= 0) {\r\nstruct sched_param param = {\r\n.sched_priority = consumer_fifo\r\n};\r\nsched_setscheduler(consumer, SCHED_FIFO, &param);\r\n} else\r\nset_user_nice(consumer, consumer_nice);\r\n}\r\nif (producer_fifo >= 0) {\r\nstruct sched_param param = {\r\n.sched_priority = producer_fifo\r\n};\r\nsched_setscheduler(producer, SCHED_FIFO, &param);\r\n} else\r\nset_user_nice(producer, producer_nice);\r\nreturn 0;\r\nout_kill:\r\nif (consumer)\r\nkthread_stop(consumer);\r\nout_fail:\r\nring_buffer_free(buffer);\r\nreturn ret;\r\n}\r\nstatic void __exit ring_buffer_benchmark_exit(void)\r\n{\r\nkthread_stop(producer);\r\nif (consumer)\r\nkthread_stop(consumer);\r\nring_buffer_free(buffer);\r\n}
