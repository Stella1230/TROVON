static inline void rcu_batch_init(struct rcu_batch *b)\r\n{\r\nb->head = NULL;\r\nb->tail = &b->head;\r\n}\r\nstatic inline void rcu_batch_queue(struct rcu_batch *b, struct rcu_head *head)\r\n{\r\n*b->tail = head;\r\nb->tail = &head->next;\r\n}\r\nstatic inline bool rcu_batch_empty(struct rcu_batch *b)\r\n{\r\nreturn b->tail == &b->head;\r\n}\r\nstatic inline struct rcu_head *rcu_batch_dequeue(struct rcu_batch *b)\r\n{\r\nstruct rcu_head *head;\r\nif (rcu_batch_empty(b))\r\nreturn NULL;\r\nhead = b->head;\r\nb->head = head->next;\r\nif (b->tail == &head->next)\r\nrcu_batch_init(b);\r\nreturn head;\r\n}\r\nstatic inline void rcu_batch_move(struct rcu_batch *to, struct rcu_batch *from)\r\n{\r\nif (!rcu_batch_empty(from)) {\r\n*to->tail = from->head;\r\nto->tail = from->tail;\r\nrcu_batch_init(from);\r\n}\r\n}\r\nstatic int init_srcu_struct_fields(struct srcu_struct *sp)\r\n{\r\nsp->completed = 0;\r\nspin_lock_init(&sp->queue_lock);\r\nsp->running = false;\r\nrcu_batch_init(&sp->batch_queue);\r\nrcu_batch_init(&sp->batch_check0);\r\nrcu_batch_init(&sp->batch_check1);\r\nrcu_batch_init(&sp->batch_done);\r\nINIT_DELAYED_WORK(&sp->work, process_srcu);\r\nsp->per_cpu_ref = alloc_percpu(struct srcu_struct_array);\r\nreturn sp->per_cpu_ref ? 0 : -ENOMEM;\r\n}\r\nint __init_srcu_struct(struct srcu_struct *sp, const char *name,\r\nstruct lock_class_key *key)\r\n{\r\ndebug_check_no_locks_freed((void *)sp, sizeof(*sp));\r\nlockdep_init_map(&sp->dep_map, name, key, 0);\r\nreturn init_srcu_struct_fields(sp);\r\n}\r\nint init_srcu_struct(struct srcu_struct *sp)\r\n{\r\nreturn init_srcu_struct_fields(sp);\r\n}\r\nstatic unsigned long srcu_readers_seq_idx(struct srcu_struct *sp, int idx)\r\n{\r\nint cpu;\r\nunsigned long sum = 0;\r\nunsigned long t;\r\nfor_each_possible_cpu(cpu) {\r\nt = READ_ONCE(per_cpu_ptr(sp->per_cpu_ref, cpu)->seq[idx]);\r\nsum += t;\r\n}\r\nreturn sum;\r\n}\r\nstatic unsigned long srcu_readers_active_idx(struct srcu_struct *sp, int idx)\r\n{\r\nint cpu;\r\nunsigned long sum = 0;\r\nunsigned long t;\r\nfor_each_possible_cpu(cpu) {\r\nt = READ_ONCE(per_cpu_ptr(sp->per_cpu_ref, cpu)->c[idx]);\r\nsum += t;\r\n}\r\nreturn sum;\r\n}\r\nstatic bool srcu_readers_active_idx_check(struct srcu_struct *sp, int idx)\r\n{\r\nunsigned long seq;\r\nseq = srcu_readers_seq_idx(sp, idx);\r\nsmp_mb();\r\nif (srcu_readers_active_idx(sp, idx) != 0)\r\nreturn false;\r\nsmp_mb();\r\nreturn srcu_readers_seq_idx(sp, idx) == seq;\r\n}\r\nstatic bool srcu_readers_active(struct srcu_struct *sp)\r\n{\r\nint cpu;\r\nunsigned long sum = 0;\r\nfor_each_possible_cpu(cpu) {\r\nsum += READ_ONCE(per_cpu_ptr(sp->per_cpu_ref, cpu)->c[0]);\r\nsum += READ_ONCE(per_cpu_ptr(sp->per_cpu_ref, cpu)->c[1]);\r\n}\r\nreturn sum;\r\n}\r\nvoid cleanup_srcu_struct(struct srcu_struct *sp)\r\n{\r\nif (WARN_ON(srcu_readers_active(sp)))\r\nreturn;\r\nfree_percpu(sp->per_cpu_ref);\r\nsp->per_cpu_ref = NULL;\r\n}\r\nint __srcu_read_lock(struct srcu_struct *sp)\r\n{\r\nint idx;\r\nidx = READ_ONCE(sp->completed) & 0x1;\r\n__this_cpu_inc(sp->per_cpu_ref->c[idx]);\r\nsmp_mb();\r\n__this_cpu_inc(sp->per_cpu_ref->seq[idx]);\r\nreturn idx;\r\n}\r\nvoid __srcu_read_unlock(struct srcu_struct *sp, int idx)\r\n{\r\nsmp_mb();\r\nthis_cpu_dec(sp->per_cpu_ref->c[idx]);\r\n}\r\nstatic bool try_check_zero(struct srcu_struct *sp, int idx, int trycount)\r\n{\r\nfor (;;) {\r\nif (srcu_readers_active_idx_check(sp, idx))\r\nreturn true;\r\nif (--trycount <= 0)\r\nreturn false;\r\nudelay(SRCU_RETRY_CHECK_DELAY);\r\n}\r\n}\r\nstatic void srcu_flip(struct srcu_struct *sp)\r\n{\r\nsp->completed++;\r\n}\r\nvoid call_srcu(struct srcu_struct *sp, struct rcu_head *head,\r\nrcu_callback_t func)\r\n{\r\nunsigned long flags;\r\nhead->next = NULL;\r\nhead->func = func;\r\nspin_lock_irqsave(&sp->queue_lock, flags);\r\nrcu_batch_queue(&sp->batch_queue, head);\r\nif (!sp->running) {\r\nsp->running = true;\r\nqueue_delayed_work(system_power_efficient_wq, &sp->work, 0);\r\n}\r\nspin_unlock_irqrestore(&sp->queue_lock, flags);\r\n}\r\nstatic void __synchronize_srcu(struct srcu_struct *sp, int trycount)\r\n{\r\nstruct rcu_synchronize rcu;\r\nstruct rcu_head *head = &rcu.head;\r\nbool done = false;\r\nRCU_LOCKDEP_WARN(lock_is_held(&sp->dep_map) ||\r\nlock_is_held(&rcu_bh_lock_map) ||\r\nlock_is_held(&rcu_lock_map) ||\r\nlock_is_held(&rcu_sched_lock_map),\r\n"Illegal synchronize_srcu() in same-type SRCU (or in RCU) read-side critical section");\r\nmight_sleep();\r\ninit_completion(&rcu.completion);\r\nhead->next = NULL;\r\nhead->func = wakeme_after_rcu;\r\nspin_lock_irq(&sp->queue_lock);\r\nif (!sp->running) {\r\nsp->running = true;\r\nrcu_batch_queue(&sp->batch_check0, head);\r\nspin_unlock_irq(&sp->queue_lock);\r\nsrcu_advance_batches(sp, trycount);\r\nif (!rcu_batch_empty(&sp->batch_done)) {\r\nBUG_ON(sp->batch_done.head != head);\r\nrcu_batch_dequeue(&sp->batch_done);\r\ndone = true;\r\n}\r\nsrcu_reschedule(sp);\r\n} else {\r\nrcu_batch_queue(&sp->batch_queue, head);\r\nspin_unlock_irq(&sp->queue_lock);\r\n}\r\nif (!done)\r\nwait_for_completion(&rcu.completion);\r\n}\r\nvoid synchronize_srcu(struct srcu_struct *sp)\r\n{\r\n__synchronize_srcu(sp, (rcu_gp_is_expedited() && !rcu_gp_is_normal())\r\n? SYNCHRONIZE_SRCU_EXP_TRYCOUNT\r\n: SYNCHRONIZE_SRCU_TRYCOUNT);\r\n}\r\nvoid synchronize_srcu_expedited(struct srcu_struct *sp)\r\n{\r\n__synchronize_srcu(sp, SYNCHRONIZE_SRCU_EXP_TRYCOUNT);\r\n}\r\nvoid srcu_barrier(struct srcu_struct *sp)\r\n{\r\nsynchronize_srcu(sp);\r\n}\r\nunsigned long srcu_batches_completed(struct srcu_struct *sp)\r\n{\r\nreturn sp->completed;\r\n}\r\nstatic void srcu_collect_new(struct srcu_struct *sp)\r\n{\r\nif (!rcu_batch_empty(&sp->batch_queue)) {\r\nspin_lock_irq(&sp->queue_lock);\r\nrcu_batch_move(&sp->batch_check0, &sp->batch_queue);\r\nspin_unlock_irq(&sp->queue_lock);\r\n}\r\n}\r\nstatic void srcu_advance_batches(struct srcu_struct *sp, int trycount)\r\n{\r\nint idx = 1 ^ (sp->completed & 1);\r\nif (rcu_batch_empty(&sp->batch_check0) &&\r\nrcu_batch_empty(&sp->batch_check1))\r\nreturn;\r\nif (!try_check_zero(sp, idx, trycount))\r\nreturn;\r\nrcu_batch_move(&sp->batch_done, &sp->batch_check1);\r\nif (rcu_batch_empty(&sp->batch_check0))\r\nreturn;\r\nsrcu_flip(sp);\r\nrcu_batch_move(&sp->batch_check1, &sp->batch_check0);\r\ntrycount = trycount < 2 ? 2 : trycount;\r\nif (!try_check_zero(sp, idx^1, trycount))\r\nreturn;\r\nrcu_batch_move(&sp->batch_done, &sp->batch_check1);\r\n}\r\nstatic void srcu_invoke_callbacks(struct srcu_struct *sp)\r\n{\r\nint i;\r\nstruct rcu_head *head;\r\nfor (i = 0; i < SRCU_CALLBACK_BATCH; i++) {\r\nhead = rcu_batch_dequeue(&sp->batch_done);\r\nif (!head)\r\nbreak;\r\nlocal_bh_disable();\r\nhead->func(head);\r\nlocal_bh_enable();\r\n}\r\n}\r\nstatic void srcu_reschedule(struct srcu_struct *sp)\r\n{\r\nbool pending = true;\r\nif (rcu_batch_empty(&sp->batch_done) &&\r\nrcu_batch_empty(&sp->batch_check1) &&\r\nrcu_batch_empty(&sp->batch_check0) &&\r\nrcu_batch_empty(&sp->batch_queue)) {\r\nspin_lock_irq(&sp->queue_lock);\r\nif (rcu_batch_empty(&sp->batch_done) &&\r\nrcu_batch_empty(&sp->batch_check1) &&\r\nrcu_batch_empty(&sp->batch_check0) &&\r\nrcu_batch_empty(&sp->batch_queue)) {\r\nsp->running = false;\r\npending = false;\r\n}\r\nspin_unlock_irq(&sp->queue_lock);\r\n}\r\nif (pending)\r\nqueue_delayed_work(system_power_efficient_wq,\r\n&sp->work, SRCU_INTERVAL);\r\n}\r\nvoid process_srcu(struct work_struct *work)\r\n{\r\nstruct srcu_struct *sp;\r\nsp = container_of(work, struct srcu_struct, work.work);\r\nsrcu_collect_new(sp);\r\nsrcu_advance_batches(sp, 1);\r\nsrcu_invoke_callbacks(sp);\r\nsrcu_reschedule(sp);\r\n}
