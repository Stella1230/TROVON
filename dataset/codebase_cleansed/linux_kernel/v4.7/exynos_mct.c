static void exynos4_mct_write(unsigned int value, unsigned long offset)\r\n{\r\nunsigned long stat_addr;\r\nu32 mask;\r\nu32 i;\r\nwritel_relaxed(value, reg_base + offset);\r\nif (likely(offset >= EXYNOS4_MCT_L_BASE(0))) {\r\nstat_addr = (offset & EXYNOS4_MCT_L_MASK) + MCT_L_WSTAT_OFFSET;\r\nswitch (offset & ~EXYNOS4_MCT_L_MASK) {\r\ncase MCT_L_TCON_OFFSET:\r\nmask = 1 << 3;\r\nbreak;\r\ncase MCT_L_ICNTB_OFFSET:\r\nmask = 1 << 1;\r\nbreak;\r\ncase MCT_L_TCNTB_OFFSET:\r\nmask = 1 << 0;\r\nbreak;\r\ndefault:\r\nreturn;\r\n}\r\n} else {\r\nswitch (offset) {\r\ncase EXYNOS4_MCT_G_TCON:\r\nstat_addr = EXYNOS4_MCT_G_WSTAT;\r\nmask = 1 << 16;\r\nbreak;\r\ncase EXYNOS4_MCT_G_COMP0_L:\r\nstat_addr = EXYNOS4_MCT_G_WSTAT;\r\nmask = 1 << 0;\r\nbreak;\r\ncase EXYNOS4_MCT_G_COMP0_U:\r\nstat_addr = EXYNOS4_MCT_G_WSTAT;\r\nmask = 1 << 1;\r\nbreak;\r\ncase EXYNOS4_MCT_G_COMP0_ADD_INCR:\r\nstat_addr = EXYNOS4_MCT_G_WSTAT;\r\nmask = 1 << 2;\r\nbreak;\r\ncase EXYNOS4_MCT_G_CNT_L:\r\nstat_addr = EXYNOS4_MCT_G_CNT_WSTAT;\r\nmask = 1 << 0;\r\nbreak;\r\ncase EXYNOS4_MCT_G_CNT_U:\r\nstat_addr = EXYNOS4_MCT_G_CNT_WSTAT;\r\nmask = 1 << 1;\r\nbreak;\r\ndefault:\r\nreturn;\r\n}\r\n}\r\nfor (i = 0; i < loops_per_jiffy / 1000 * HZ; i++)\r\nif (readl_relaxed(reg_base + stat_addr) & mask) {\r\nwritel_relaxed(mask, reg_base + stat_addr);\r\nreturn;\r\n}\r\npanic("MCT hangs after writing %d (offset:0x%lx)\n", value, offset);\r\n}\r\nstatic void exynos4_mct_frc_start(void)\r\n{\r\nu32 reg;\r\nreg = readl_relaxed(reg_base + EXYNOS4_MCT_G_TCON);\r\nreg |= MCT_G_TCON_START;\r\nexynos4_mct_write(reg, EXYNOS4_MCT_G_TCON);\r\n}\r\nstatic u64 exynos4_read_count_64(void)\r\n{\r\nunsigned int lo, hi;\r\nu32 hi2 = readl_relaxed(reg_base + EXYNOS4_MCT_G_CNT_U);\r\ndo {\r\nhi = hi2;\r\nlo = readl_relaxed(reg_base + EXYNOS4_MCT_G_CNT_L);\r\nhi2 = readl_relaxed(reg_base + EXYNOS4_MCT_G_CNT_U);\r\n} while (hi != hi2);\r\nreturn ((cycle_t)hi << 32) | lo;\r\n}\r\nstatic u32 notrace exynos4_read_count_32(void)\r\n{\r\nreturn readl_relaxed(reg_base + EXYNOS4_MCT_G_CNT_L);\r\n}\r\nstatic cycle_t exynos4_frc_read(struct clocksource *cs)\r\n{\r\nreturn exynos4_read_count_32();\r\n}\r\nstatic void exynos4_frc_resume(struct clocksource *cs)\r\n{\r\nexynos4_mct_frc_start();\r\n}\r\nstatic u64 notrace exynos4_read_sched_clock(void)\r\n{\r\nreturn exynos4_read_count_32();\r\n}\r\nstatic cycles_t exynos4_read_current_timer(void)\r\n{\r\nBUILD_BUG_ON_MSG(sizeof(cycles_t) != sizeof(u32),\r\n"cycles_t needs to move to 32-bit for ARM64 usage");\r\nreturn exynos4_read_count_32();\r\n}\r\nstatic void __init exynos4_clocksource_init(void)\r\n{\r\nexynos4_mct_frc_start();\r\nexynos4_delay_timer.read_current_timer = &exynos4_read_current_timer;\r\nexynos4_delay_timer.freq = clk_rate;\r\nregister_current_timer_delay(&exynos4_delay_timer);\r\nif (clocksource_register_hz(&mct_frc, clk_rate))\r\npanic("%s: can't register clocksource\n", mct_frc.name);\r\nsched_clock_register(exynos4_read_sched_clock, 32, clk_rate);\r\n}\r\nstatic void exynos4_mct_comp0_stop(void)\r\n{\r\nunsigned int tcon;\r\ntcon = readl_relaxed(reg_base + EXYNOS4_MCT_G_TCON);\r\ntcon &= ~(MCT_G_TCON_COMP0_ENABLE | MCT_G_TCON_COMP0_AUTO_INC);\r\nexynos4_mct_write(tcon, EXYNOS4_MCT_G_TCON);\r\nexynos4_mct_write(0, EXYNOS4_MCT_G_INT_ENB);\r\n}\r\nstatic void exynos4_mct_comp0_start(bool periodic, unsigned long cycles)\r\n{\r\nunsigned int tcon;\r\ncycle_t comp_cycle;\r\ntcon = readl_relaxed(reg_base + EXYNOS4_MCT_G_TCON);\r\nif (periodic) {\r\ntcon |= MCT_G_TCON_COMP0_AUTO_INC;\r\nexynos4_mct_write(cycles, EXYNOS4_MCT_G_COMP0_ADD_INCR);\r\n}\r\ncomp_cycle = exynos4_read_count_64() + cycles;\r\nexynos4_mct_write((u32)comp_cycle, EXYNOS4_MCT_G_COMP0_L);\r\nexynos4_mct_write((u32)(comp_cycle >> 32), EXYNOS4_MCT_G_COMP0_U);\r\nexynos4_mct_write(0x1, EXYNOS4_MCT_G_INT_ENB);\r\ntcon |= MCT_G_TCON_COMP0_ENABLE;\r\nexynos4_mct_write(tcon , EXYNOS4_MCT_G_TCON);\r\n}\r\nstatic int exynos4_comp_set_next_event(unsigned long cycles,\r\nstruct clock_event_device *evt)\r\n{\r\nexynos4_mct_comp0_start(false, cycles);\r\nreturn 0;\r\n}\r\nstatic int mct_set_state_shutdown(struct clock_event_device *evt)\r\n{\r\nexynos4_mct_comp0_stop();\r\nreturn 0;\r\n}\r\nstatic int mct_set_state_periodic(struct clock_event_device *evt)\r\n{\r\nunsigned long cycles_per_jiffy;\r\ncycles_per_jiffy = (((unsigned long long)NSEC_PER_SEC / HZ * evt->mult)\r\n>> evt->shift);\r\nexynos4_mct_comp0_stop();\r\nexynos4_mct_comp0_start(true, cycles_per_jiffy);\r\nreturn 0;\r\n}\r\nstatic irqreturn_t exynos4_mct_comp_isr(int irq, void *dev_id)\r\n{\r\nstruct clock_event_device *evt = dev_id;\r\nexynos4_mct_write(0x1, EXYNOS4_MCT_G_INT_CSTAT);\r\nevt->event_handler(evt);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void exynos4_clockevent_init(void)\r\n{\r\nmct_comp_device.cpumask = cpumask_of(0);\r\nclockevents_config_and_register(&mct_comp_device, clk_rate,\r\n0xf, 0xffffffff);\r\nsetup_irq(mct_irqs[MCT_G0_IRQ], &mct_comp_event_irq);\r\n}\r\nstatic void exynos4_mct_tick_stop(struct mct_clock_event_device *mevt)\r\n{\r\nunsigned long tmp;\r\nunsigned long mask = MCT_L_TCON_INT_START | MCT_L_TCON_TIMER_START;\r\nunsigned long offset = mevt->base + MCT_L_TCON_OFFSET;\r\ntmp = readl_relaxed(reg_base + offset);\r\nif (tmp & mask) {\r\ntmp &= ~mask;\r\nexynos4_mct_write(tmp, offset);\r\n}\r\n}\r\nstatic void exynos4_mct_tick_start(unsigned long cycles,\r\nstruct mct_clock_event_device *mevt)\r\n{\r\nunsigned long tmp;\r\nexynos4_mct_tick_stop(mevt);\r\ntmp = (1 << 31) | cycles;\r\nexynos4_mct_write(tmp, mevt->base + MCT_L_ICNTB_OFFSET);\r\nexynos4_mct_write(0x1, mevt->base + MCT_L_INT_ENB_OFFSET);\r\ntmp = readl_relaxed(reg_base + mevt->base + MCT_L_TCON_OFFSET);\r\ntmp |= MCT_L_TCON_INT_START | MCT_L_TCON_TIMER_START |\r\nMCT_L_TCON_INTERVAL_MODE;\r\nexynos4_mct_write(tmp, mevt->base + MCT_L_TCON_OFFSET);\r\n}\r\nstatic int exynos4_tick_set_next_event(unsigned long cycles,\r\nstruct clock_event_device *evt)\r\n{\r\nstruct mct_clock_event_device *mevt;\r\nmevt = container_of(evt, struct mct_clock_event_device, evt);\r\nexynos4_mct_tick_start(cycles, mevt);\r\nreturn 0;\r\n}\r\nstatic int set_state_shutdown(struct clock_event_device *evt)\r\n{\r\nstruct mct_clock_event_device *mevt;\r\nmevt = container_of(evt, struct mct_clock_event_device, evt);\r\nexynos4_mct_tick_stop(mevt);\r\nreturn 0;\r\n}\r\nstatic int set_state_periodic(struct clock_event_device *evt)\r\n{\r\nstruct mct_clock_event_device *mevt;\r\nunsigned long cycles_per_jiffy;\r\nmevt = container_of(evt, struct mct_clock_event_device, evt);\r\ncycles_per_jiffy = (((unsigned long long)NSEC_PER_SEC / HZ * evt->mult)\r\n>> evt->shift);\r\nexynos4_mct_tick_stop(mevt);\r\nexynos4_mct_tick_start(cycles_per_jiffy, mevt);\r\nreturn 0;\r\n}\r\nstatic void exynos4_mct_tick_clear(struct mct_clock_event_device *mevt)\r\n{\r\nif (!clockevent_state_periodic(&mevt->evt))\r\nexynos4_mct_tick_stop(mevt);\r\nif (readl_relaxed(reg_base + mevt->base + MCT_L_INT_CSTAT_OFFSET) & 1)\r\nexynos4_mct_write(0x1, mevt->base + MCT_L_INT_CSTAT_OFFSET);\r\n}\r\nstatic irqreturn_t exynos4_mct_tick_isr(int irq, void *dev_id)\r\n{\r\nstruct mct_clock_event_device *mevt = dev_id;\r\nstruct clock_event_device *evt = &mevt->evt;\r\nexynos4_mct_tick_clear(mevt);\r\nevt->event_handler(evt);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int exynos4_local_timer_setup(struct mct_clock_event_device *mevt)\r\n{\r\nstruct clock_event_device *evt = &mevt->evt;\r\nunsigned int cpu = smp_processor_id();\r\nmevt->base = EXYNOS4_MCT_L_BASE(cpu);\r\nsnprintf(mevt->name, sizeof(mevt->name), "mct_tick%d", cpu);\r\nevt->name = mevt->name;\r\nevt->cpumask = cpumask_of(cpu);\r\nevt->set_next_event = exynos4_tick_set_next_event;\r\nevt->set_state_periodic = set_state_periodic;\r\nevt->set_state_shutdown = set_state_shutdown;\r\nevt->set_state_oneshot = set_state_shutdown;\r\nevt->set_state_oneshot_stopped = set_state_shutdown;\r\nevt->tick_resume = set_state_shutdown;\r\nevt->features = CLOCK_EVT_FEAT_PERIODIC | CLOCK_EVT_FEAT_ONESHOT;\r\nevt->rating = 450;\r\nexynos4_mct_write(TICK_BASE_CNT, mevt->base + MCT_L_TCNTB_OFFSET);\r\nif (mct_int_type == MCT_INT_SPI) {\r\nif (evt->irq == -1)\r\nreturn -EIO;\r\nirq_force_affinity(evt->irq, cpumask_of(cpu));\r\nenable_irq(evt->irq);\r\n} else {\r\nenable_percpu_irq(mct_irqs[MCT_L0_IRQ], 0);\r\n}\r\nclockevents_config_and_register(evt, clk_rate / (TICK_BASE_CNT + 1),\r\n0xf, 0x7fffffff);\r\nreturn 0;\r\n}\r\nstatic void exynos4_local_timer_stop(struct mct_clock_event_device *mevt)\r\n{\r\nstruct clock_event_device *evt = &mevt->evt;\r\nevt->set_state_shutdown(evt);\r\nif (mct_int_type == MCT_INT_SPI) {\r\nif (evt->irq != -1)\r\ndisable_irq_nosync(evt->irq);\r\n} else {\r\ndisable_percpu_irq(mct_irqs[MCT_L0_IRQ]);\r\n}\r\n}\r\nstatic int exynos4_mct_cpu_notify(struct notifier_block *self,\r\nunsigned long action, void *hcpu)\r\n{\r\nstruct mct_clock_event_device *mevt;\r\nswitch (action & ~CPU_TASKS_FROZEN) {\r\ncase CPU_STARTING:\r\nmevt = this_cpu_ptr(&percpu_mct_tick);\r\nexynos4_local_timer_setup(mevt);\r\nbreak;\r\ncase CPU_DYING:\r\nmevt = this_cpu_ptr(&percpu_mct_tick);\r\nexynos4_local_timer_stop(mevt);\r\nbreak;\r\n}\r\nreturn NOTIFY_OK;\r\n}\r\nstatic void __init exynos4_timer_resources(struct device_node *np, void __iomem *base)\r\n{\r\nint err, cpu;\r\nstruct mct_clock_event_device *mevt = this_cpu_ptr(&percpu_mct_tick);\r\nstruct clk *mct_clk, *tick_clk;\r\ntick_clk = np ? of_clk_get_by_name(np, "fin_pll") :\r\nclk_get(NULL, "fin_pll");\r\nif (IS_ERR(tick_clk))\r\npanic("%s: unable to determine tick clock rate\n", __func__);\r\nclk_rate = clk_get_rate(tick_clk);\r\nmct_clk = np ? of_clk_get_by_name(np, "mct") : clk_get(NULL, "mct");\r\nif (IS_ERR(mct_clk))\r\npanic("%s: unable to retrieve mct clock instance\n", __func__);\r\nclk_prepare_enable(mct_clk);\r\nreg_base = base;\r\nif (!reg_base)\r\npanic("%s: unable to ioremap mct address space\n", __func__);\r\nif (mct_int_type == MCT_INT_PPI) {\r\nerr = request_percpu_irq(mct_irqs[MCT_L0_IRQ],\r\nexynos4_mct_tick_isr, "MCT",\r\n&percpu_mct_tick);\r\nWARN(err, "MCT: can't request IRQ %d (%d)\n",\r\nmct_irqs[MCT_L0_IRQ], err);\r\n} else {\r\nfor_each_possible_cpu(cpu) {\r\nint mct_irq = mct_irqs[MCT_L0_IRQ + cpu];\r\nstruct mct_clock_event_device *pcpu_mevt =\r\nper_cpu_ptr(&percpu_mct_tick, cpu);\r\npcpu_mevt->evt.irq = -1;\r\nirq_set_status_flags(mct_irq, IRQ_NOAUTOEN);\r\nif (request_irq(mct_irq,\r\nexynos4_mct_tick_isr,\r\nIRQF_TIMER | IRQF_NOBALANCING,\r\npcpu_mevt->name, pcpu_mevt)) {\r\npr_err("exynos-mct: cannot register IRQ (cpu%d)\n",\r\ncpu);\r\ncontinue;\r\n}\r\npcpu_mevt->evt.irq = mct_irq;\r\n}\r\n}\r\nerr = register_cpu_notifier(&exynos4_mct_cpu_nb);\r\nif (err)\r\ngoto out_irq;\r\nexynos4_local_timer_setup(mevt);\r\nreturn;\r\nout_irq:\r\nfree_percpu_irq(mct_irqs[MCT_L0_IRQ], &percpu_mct_tick);\r\n}\r\nstatic void __init mct_init_dt(struct device_node *np, unsigned int int_type)\r\n{\r\nu32 nr_irqs, i;\r\nmct_int_type = int_type;\r\nmct_irqs[MCT_G0_IRQ] = irq_of_parse_and_map(np, MCT_G0_IRQ);\r\n#ifdef CONFIG_OF\r\nnr_irqs = of_irq_count(np);\r\n#else\r\nnr_irqs = 0;\r\n#endif\r\nfor (i = MCT_L0_IRQ; i < nr_irqs; i++)\r\nmct_irqs[i] = irq_of_parse_and_map(np, i);\r\nexynos4_timer_resources(np, of_iomap(np, 0));\r\nexynos4_clocksource_init();\r\nexynos4_clockevent_init();\r\n}\r\nstatic void __init mct_init_spi(struct device_node *np)\r\n{\r\nreturn mct_init_dt(np, MCT_INT_SPI);\r\n}\r\nstatic void __init mct_init_ppi(struct device_node *np)\r\n{\r\nreturn mct_init_dt(np, MCT_INT_PPI);\r\n}
