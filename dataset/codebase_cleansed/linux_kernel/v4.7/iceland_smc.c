static int iceland_set_smc_sram_address(struct amdgpu_device *adev,\r\nuint32_t smc_address, uint32_t limit)\r\n{\r\nuint32_t val;\r\nif (smc_address & 3)\r\nreturn -EINVAL;\r\nif ((smc_address + 3) > limit)\r\nreturn -EINVAL;\r\nWREG32(mmSMC_IND_INDEX_0, smc_address);\r\nval = RREG32(mmSMC_IND_ACCESS_CNTL);\r\nval = REG_SET_FIELD(val, SMC_IND_ACCESS_CNTL, AUTO_INCREMENT_IND_0, 0);\r\nWREG32(mmSMC_IND_ACCESS_CNTL, val);\r\nreturn 0;\r\n}\r\nstatic int iceland_copy_bytes_to_smc(struct amdgpu_device *adev,\r\nuint32_t smc_start_address,\r\nconst uint8_t *src,\r\nuint32_t byte_count, uint32_t limit)\r\n{\r\nuint32_t addr;\r\nuint32_t data, orig_data;\r\nint result = 0;\r\nuint32_t extra_shift;\r\nunsigned long flags;\r\nif (smc_start_address & 3)\r\nreturn -EINVAL;\r\nif ((smc_start_address + byte_count) > limit)\r\nreturn -EINVAL;\r\naddr = smc_start_address;\r\nspin_lock_irqsave(&adev->smc_idx_lock, flags);\r\nwhile (byte_count >= 4) {\r\ndata = (src[0] << 24) + (src[1] << 16) + (src[2] << 8) + src[3];\r\nresult = iceland_set_smc_sram_address(adev, addr, limit);\r\nif (result)\r\ngoto out;\r\nWREG32(mmSMC_IND_DATA_0, data);\r\nsrc += 4;\r\nbyte_count -= 4;\r\naddr += 4;\r\n}\r\nif (0 != byte_count) {\r\ndata = 0;\r\nresult = iceland_set_smc_sram_address(adev, addr, limit);\r\nif (result)\r\ngoto out;\r\norig_data = RREG32(mmSMC_IND_DATA_0);\r\nextra_shift = 8 * (4 - byte_count);\r\nwhile (byte_count > 0) {\r\ndata = (data << 8) + *src++;\r\nbyte_count--;\r\n}\r\ndata <<= extra_shift;\r\ndata |= (orig_data & ~((~0UL) << extra_shift));\r\nresult = iceland_set_smc_sram_address(adev, addr, limit);\r\nif (result)\r\ngoto out;\r\nWREG32(mmSMC_IND_DATA_0, data);\r\n}\r\nout:\r\nspin_unlock_irqrestore(&adev->smc_idx_lock, flags);\r\nreturn result;\r\n}\r\nvoid iceland_start_smc(struct amdgpu_device *adev)\r\n{\r\nuint32_t val = RREG32_SMC(ixSMC_SYSCON_RESET_CNTL);\r\nval = REG_SET_FIELD(val, SMC_SYSCON_RESET_CNTL, rst_reg, 0);\r\nWREG32_SMC(ixSMC_SYSCON_RESET_CNTL, val);\r\n}\r\nvoid iceland_reset_smc(struct amdgpu_device *adev)\r\n{\r\nuint32_t val = RREG32_SMC(ixSMC_SYSCON_RESET_CNTL);\r\nval = REG_SET_FIELD(val, SMC_SYSCON_RESET_CNTL, rst_reg, 1);\r\nWREG32_SMC(ixSMC_SYSCON_RESET_CNTL, val);\r\n}\r\nstatic int iceland_program_jump_on_start(struct amdgpu_device *adev)\r\n{\r\nstatic unsigned char data[] = {0xE0, 0x00, 0x80, 0x40};\r\niceland_copy_bytes_to_smc(adev, 0x0, data, 4, sizeof(data)+1);\r\nreturn 0;\r\n}\r\nvoid iceland_stop_smc_clock(struct amdgpu_device *adev)\r\n{\r\nuint32_t val = RREG32_SMC(ixSMC_SYSCON_CLOCK_CNTL_0);\r\nval = REG_SET_FIELD(val, SMC_SYSCON_CLOCK_CNTL_0, ck_disable, 1);\r\nWREG32_SMC(ixSMC_SYSCON_CLOCK_CNTL_0, val);\r\n}\r\nvoid iceland_start_smc_clock(struct amdgpu_device *adev)\r\n{\r\nuint32_t val = RREG32_SMC(ixSMC_SYSCON_CLOCK_CNTL_0);\r\nval = REG_SET_FIELD(val, SMC_SYSCON_CLOCK_CNTL_0, ck_disable, 0);\r\nWREG32_SMC(ixSMC_SYSCON_CLOCK_CNTL_0, val);\r\n}\r\nstatic bool iceland_is_smc_ram_running(struct amdgpu_device *adev)\r\n{\r\nuint32_t val = RREG32_SMC(ixSMC_SYSCON_CLOCK_CNTL_0);\r\nval = REG_GET_FIELD(val, SMC_SYSCON_CLOCK_CNTL_0, ck_disable);\r\nreturn ((0 == val) && (0x20100 <= RREG32_SMC(ixSMC_PC_C)));\r\n}\r\nstatic int wait_smu_response(struct amdgpu_device *adev)\r\n{\r\nint i;\r\nuint32_t val;\r\nfor (i = 0; i < adev->usec_timeout; i++) {\r\nval = RREG32(mmSMC_RESP_0);\r\nif (REG_GET_FIELD(val, SMC_RESP_0, SMC_RESP))\r\nbreak;\r\nudelay(1);\r\n}\r\nif (i == adev->usec_timeout)\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic int iceland_send_msg_to_smc(struct amdgpu_device *adev, PPSMC_Msg msg)\r\n{\r\nif (!iceland_is_smc_ram_running(adev))\r\nreturn -EINVAL;\r\nif (wait_smu_response(adev)) {\r\nDRM_ERROR("Failed to send previous message\n");\r\nreturn -EINVAL;\r\n}\r\nWREG32(mmSMC_MESSAGE_0, msg);\r\nif (wait_smu_response(adev)) {\r\nDRM_ERROR("Failed to send message\n");\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic int iceland_send_msg_to_smc_without_waiting(struct amdgpu_device *adev,\r\nPPSMC_Msg msg)\r\n{\r\nif (!iceland_is_smc_ram_running(adev))\r\nreturn -EINVAL;;\r\nif (wait_smu_response(adev)) {\r\nDRM_ERROR("Failed to send previous message\n");\r\nreturn -EINVAL;\r\n}\r\nWREG32(mmSMC_MESSAGE_0, msg);\r\nreturn 0;\r\n}\r\nstatic int iceland_send_msg_to_smc_with_parameter(struct amdgpu_device *adev,\r\nPPSMC_Msg msg,\r\nuint32_t parameter)\r\n{\r\nWREG32(mmSMC_MSG_ARG_0, parameter);\r\nreturn iceland_send_msg_to_smc(adev, msg);\r\n}\r\nstatic int iceland_send_msg_to_smc_with_parameter_without_waiting(\r\nstruct amdgpu_device *adev,\r\nPPSMC_Msg msg, uint32_t parameter)\r\n{\r\nWREG32(mmSMC_MSG_ARG_0, parameter);\r\nreturn iceland_send_msg_to_smc_without_waiting(adev, msg);\r\n}\r\nstatic int iceland_smu_upload_firmware_image(struct amdgpu_device *adev)\r\n{\r\nconst struct smc_firmware_header_v1_0 *hdr;\r\nuint32_t ucode_size;\r\nuint32_t ucode_start_address;\r\nconst uint8_t *src;\r\nuint32_t val;\r\nuint32_t byte_count;\r\nuint32_t data;\r\nunsigned long flags;\r\nint i;\r\nif (!adev->pm.fw)\r\nreturn -EINVAL;\r\nif (adev->virtualization.supports_sr_iov)\r\nreturn 0;\r\nhdr = (const struct smc_firmware_header_v1_0 *)adev->pm.fw->data;\r\namdgpu_ucode_print_smc_hdr(&hdr->header);\r\nadev->pm.fw_version = le32_to_cpu(hdr->header.ucode_version);\r\nucode_size = le32_to_cpu(hdr->header.ucode_size_bytes);\r\nucode_start_address = le32_to_cpu(hdr->ucode_start_addr);\r\nsrc = (const uint8_t *)\r\n(adev->pm.fw->data + le32_to_cpu(hdr->header.ucode_array_offset_bytes));\r\nif (ucode_size & 3) {\r\nDRM_ERROR("SMC ucode is not 4 bytes aligned\n");\r\nreturn -EINVAL;\r\n}\r\nif (ucode_size > ICELAND_SMC_SIZE) {\r\nDRM_ERROR("SMC address is beyond the SMC RAM area\n");\r\nreturn -EINVAL;\r\n}\r\nfor (i = 0; i < adev->usec_timeout; i++) {\r\nval = RREG32_SMC(ixRCU_UC_EVENTS);\r\nif (REG_GET_FIELD(val, RCU_UC_EVENTS, boot_seq_done) == 0)\r\nbreak;\r\nudelay(1);\r\n}\r\nval = RREG32_SMC(ixSMC_SYSCON_MISC_CNTL);\r\nWREG32_SMC(ixSMC_SYSCON_MISC_CNTL, val | 1);\r\niceland_stop_smc_clock(adev);\r\niceland_reset_smc(adev);\r\nspin_lock_irqsave(&adev->smc_idx_lock, flags);\r\nWREG32(mmSMC_IND_INDEX_0, ucode_start_address);\r\nval = RREG32(mmSMC_IND_ACCESS_CNTL);\r\nval = REG_SET_FIELD(val, SMC_IND_ACCESS_CNTL, AUTO_INCREMENT_IND_0, 1);\r\nWREG32(mmSMC_IND_ACCESS_CNTL, val);\r\nbyte_count = ucode_size;\r\nwhile (byte_count >= 4) {\r\ndata = (src[0] << 24) + (src[1] << 16) + (src[2] << 8) + src[3];\r\nWREG32(mmSMC_IND_DATA_0, data);\r\nsrc += 4;\r\nbyte_count -= 4;\r\n}\r\nval = RREG32(mmSMC_IND_ACCESS_CNTL);\r\nval = REG_SET_FIELD(val, SMC_IND_ACCESS_CNTL, AUTO_INCREMENT_IND_0, 0);\r\nWREG32(mmSMC_IND_ACCESS_CNTL, val);\r\nspin_unlock_irqrestore(&adev->smc_idx_lock, flags);\r\nreturn 0;\r\n}\r\nstatic int iceland_smu_start_smc(struct amdgpu_device *adev)\r\n{\r\nint i;\r\nuint32_t val;\r\niceland_program_jump_on_start(adev);\r\niceland_start_smc_clock(adev);\r\niceland_start_smc(adev);\r\nfor (i = 0; i < adev->usec_timeout; i++) {\r\nval = RREG32_SMC(ixFIRMWARE_FLAGS);\r\nif (REG_GET_FIELD(val, FIRMWARE_FLAGS, INTERRUPTS_ENABLED) == 1)\r\nbreak;\r\nudelay(1);\r\n}\r\nreturn 0;\r\n}\r\nstatic enum AMDGPU_UCODE_ID iceland_convert_fw_type(uint32_t fw_type)\r\n{\r\nswitch (fw_type) {\r\ncase UCODE_ID_SDMA0:\r\nreturn AMDGPU_UCODE_ID_SDMA0;\r\ncase UCODE_ID_SDMA1:\r\nreturn AMDGPU_UCODE_ID_SDMA1;\r\ncase UCODE_ID_CP_CE:\r\nreturn AMDGPU_UCODE_ID_CP_CE;\r\ncase UCODE_ID_CP_PFP:\r\nreturn AMDGPU_UCODE_ID_CP_PFP;\r\ncase UCODE_ID_CP_ME:\r\nreturn AMDGPU_UCODE_ID_CP_ME;\r\ncase UCODE_ID_CP_MEC:\r\ncase UCODE_ID_CP_MEC_JT1:\r\nreturn AMDGPU_UCODE_ID_CP_MEC1;\r\ncase UCODE_ID_CP_MEC_JT2:\r\nreturn AMDGPU_UCODE_ID_CP_MEC2;\r\ncase UCODE_ID_RLC_G:\r\nreturn AMDGPU_UCODE_ID_RLC_G;\r\ndefault:\r\nDRM_ERROR("ucode type is out of range!\n");\r\nreturn AMDGPU_UCODE_ID_MAXIMUM;\r\n}\r\n}\r\nstatic uint32_t iceland_smu_get_mask_for_fw_type(uint32_t fw_type)\r\n{\r\nswitch (fw_type) {\r\ncase AMDGPU_UCODE_ID_SDMA0:\r\nreturn UCODE_ID_SDMA0_MASK;\r\ncase AMDGPU_UCODE_ID_SDMA1:\r\nreturn UCODE_ID_SDMA1_MASK;\r\ncase AMDGPU_UCODE_ID_CP_CE:\r\nreturn UCODE_ID_CP_CE_MASK;\r\ncase AMDGPU_UCODE_ID_CP_PFP:\r\nreturn UCODE_ID_CP_PFP_MASK;\r\ncase AMDGPU_UCODE_ID_CP_ME:\r\nreturn UCODE_ID_CP_ME_MASK;\r\ncase AMDGPU_UCODE_ID_CP_MEC1:\r\nreturn UCODE_ID_CP_MEC_MASK | UCODE_ID_CP_MEC_JT1_MASK;\r\ncase AMDGPU_UCODE_ID_CP_MEC2:\r\nreturn UCODE_ID_CP_MEC_MASK;\r\ncase AMDGPU_UCODE_ID_RLC_G:\r\nreturn UCODE_ID_RLC_G_MASK;\r\ndefault:\r\nDRM_ERROR("ucode type is out of range!\n");\r\nreturn 0;\r\n}\r\n}\r\nstatic int iceland_smu_populate_single_firmware_entry(struct amdgpu_device *adev,\r\nuint32_t fw_type,\r\nstruct SMU_Entry *entry)\r\n{\r\nenum AMDGPU_UCODE_ID id = iceland_convert_fw_type(fw_type);\r\nstruct amdgpu_firmware_info *ucode = &adev->firmware.ucode[id];\r\nconst struct gfx_firmware_header_v1_0 *header = NULL;\r\nuint64_t gpu_addr;\r\nuint32_t data_size;\r\nif (ucode->fw == NULL)\r\nreturn -EINVAL;\r\ngpu_addr = ucode->mc_addr;\r\nheader = (const struct gfx_firmware_header_v1_0 *)ucode->fw->data;\r\ndata_size = le32_to_cpu(header->header.ucode_size_bytes);\r\nentry->version = (uint16_t)le32_to_cpu(header->header.ucode_version);\r\nentry->id = (uint16_t)fw_type;\r\nentry->image_addr_high = upper_32_bits(gpu_addr);\r\nentry->image_addr_low = lower_32_bits(gpu_addr);\r\nentry->meta_data_addr_high = 0;\r\nentry->meta_data_addr_low = 0;\r\nentry->data_size_byte = data_size;\r\nentry->num_register_entries = 0;\r\nentry->flags = 0;\r\nreturn 0;\r\n}\r\nstatic int iceland_smu_request_load_fw(struct amdgpu_device *adev)\r\n{\r\nstruct iceland_smu_private_data *private = (struct iceland_smu_private_data *)adev->smu.priv;\r\nstruct SMU_DRAMData_TOC *toc;\r\nuint32_t fw_to_load;\r\ntoc = (struct SMU_DRAMData_TOC *)private->header;\r\ntoc->num_entries = 0;\r\ntoc->structure_version = 1;\r\nif (!adev->firmware.smu_load)\r\nreturn 0;\r\nif (iceland_smu_populate_single_firmware_entry(adev, UCODE_ID_RLC_G,\r\n&toc->entry[toc->num_entries++])) {\r\nDRM_ERROR("Failed to get firmware entry for RLC\n");\r\nreturn -EINVAL;\r\n}\r\nif (iceland_smu_populate_single_firmware_entry(adev, UCODE_ID_CP_CE,\r\n&toc->entry[toc->num_entries++])) {\r\nDRM_ERROR("Failed to get firmware entry for CE\n");\r\nreturn -EINVAL;\r\n}\r\nif (iceland_smu_populate_single_firmware_entry(adev, UCODE_ID_CP_PFP,\r\n&toc->entry[toc->num_entries++])) {\r\nDRM_ERROR("Failed to get firmware entry for PFP\n");\r\nreturn -EINVAL;\r\n}\r\nif (iceland_smu_populate_single_firmware_entry(adev, UCODE_ID_CP_ME,\r\n&toc->entry[toc->num_entries++])) {\r\nDRM_ERROR("Failed to get firmware entry for ME\n");\r\nreturn -EINVAL;\r\n}\r\nif (iceland_smu_populate_single_firmware_entry(adev, UCODE_ID_CP_MEC,\r\n&toc->entry[toc->num_entries++])) {\r\nDRM_ERROR("Failed to get firmware entry for MEC\n");\r\nreturn -EINVAL;\r\n}\r\nif (iceland_smu_populate_single_firmware_entry(adev, UCODE_ID_CP_MEC_JT1,\r\n&toc->entry[toc->num_entries++])) {\r\nDRM_ERROR("Failed to get firmware entry for MEC_JT1\n");\r\nreturn -EINVAL;\r\n}\r\nif (iceland_smu_populate_single_firmware_entry(adev, UCODE_ID_SDMA0,\r\n&toc->entry[toc->num_entries++])) {\r\nDRM_ERROR("Failed to get firmware entry for SDMA0\n");\r\nreturn -EINVAL;\r\n}\r\nif (iceland_smu_populate_single_firmware_entry(adev, UCODE_ID_SDMA1,\r\n&toc->entry[toc->num_entries++])) {\r\nDRM_ERROR("Failed to get firmware entry for SDMA1\n");\r\nreturn -EINVAL;\r\n}\r\niceland_send_msg_to_smc_with_parameter(adev, PPSMC_MSG_DRV_DRAM_ADDR_HI, private->header_addr_high);\r\niceland_send_msg_to_smc_with_parameter(adev, PPSMC_MSG_DRV_DRAM_ADDR_LO, private->header_addr_low);\r\nfw_to_load = UCODE_ID_RLC_G_MASK |\r\nUCODE_ID_SDMA0_MASK |\r\nUCODE_ID_SDMA1_MASK |\r\nUCODE_ID_CP_CE_MASK |\r\nUCODE_ID_CP_ME_MASK |\r\nUCODE_ID_CP_PFP_MASK |\r\nUCODE_ID_CP_MEC_MASK |\r\nUCODE_ID_CP_MEC_JT1_MASK;\r\nif (iceland_send_msg_to_smc_with_parameter_without_waiting(adev, PPSMC_MSG_LoadUcodes, fw_to_load)) {\r\nDRM_ERROR("Fail to request SMU load ucode\n");\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic int iceland_smu_check_fw_load_finish(struct amdgpu_device *adev,\r\nuint32_t fw_type)\r\n{\r\nuint32_t fw_mask = iceland_smu_get_mask_for_fw_type(fw_type);\r\nint i;\r\nfor (i = 0; i < adev->usec_timeout; i++) {\r\nif (fw_mask == (RREG32_SMC(ixSOFT_REGISTERS_TABLE_27) & fw_mask))\r\nbreak;\r\nudelay(1);\r\n}\r\nif (i == adev->usec_timeout) {\r\nDRM_ERROR("check firmware loading failed\n");\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nint iceland_smu_start(struct amdgpu_device *adev)\r\n{\r\nint result;\r\nresult = iceland_smu_upload_firmware_image(adev);\r\nif (result)\r\nreturn result;\r\nresult = iceland_smu_start_smc(adev);\r\nif (result)\r\nreturn result;\r\nreturn iceland_smu_request_load_fw(adev);\r\n}\r\nint iceland_smu_init(struct amdgpu_device *adev)\r\n{\r\nstruct iceland_smu_private_data *private;\r\nuint32_t image_size = ((sizeof(struct SMU_DRAMData_TOC) / 4096) + 1) * 4096;\r\nstruct amdgpu_bo **toc_buf = &adev->smu.toc_buf;\r\nuint64_t mc_addr;\r\nvoid *toc_buf_ptr;\r\nint ret;\r\nprivate = kzalloc(sizeof(struct iceland_smu_private_data), GFP_KERNEL);\r\nif (NULL == private)\r\nreturn -ENOMEM;\r\nif (adev->firmware.smu_load)\r\namdgpu_ucode_init_bo(adev);\r\nadev->smu.priv = private;\r\nadev->smu.fw_flags = 0;\r\nret = amdgpu_bo_create(adev, image_size, PAGE_SIZE,\r\ntrue, AMDGPU_GEM_DOMAIN_VRAM,\r\nAMDGPU_GEM_CREATE_CPU_ACCESS_REQUIRED,\r\nNULL, NULL, toc_buf);\r\nif (ret) {\r\nDRM_ERROR("Failed to allocate memory for TOC buffer\n");\r\nreturn -ENOMEM;\r\n}\r\nret = amdgpu_bo_reserve(adev->smu.toc_buf, false);\r\nif (ret) {\r\namdgpu_bo_unref(&adev->smu.toc_buf);\r\nDRM_ERROR("Failed to reserve the TOC buffer\n");\r\nreturn -EINVAL;\r\n}\r\nret = amdgpu_bo_pin(adev->smu.toc_buf, AMDGPU_GEM_DOMAIN_VRAM, &mc_addr);\r\nif (ret) {\r\namdgpu_bo_unreserve(adev->smu.toc_buf);\r\namdgpu_bo_unref(&adev->smu.toc_buf);\r\nDRM_ERROR("Failed to pin the TOC buffer\n");\r\nreturn -EINVAL;\r\n}\r\nret = amdgpu_bo_kmap(*toc_buf, &toc_buf_ptr);\r\nif (ret) {\r\namdgpu_bo_unreserve(adev->smu.toc_buf);\r\namdgpu_bo_unref(&adev->smu.toc_buf);\r\nDRM_ERROR("Failed to map the TOC buffer\n");\r\nreturn -EINVAL;\r\n}\r\namdgpu_bo_unreserve(adev->smu.toc_buf);\r\nprivate->header_addr_low = lower_32_bits(mc_addr);\r\nprivate->header_addr_high = upper_32_bits(mc_addr);\r\nprivate->header = toc_buf_ptr;\r\nadev->smu.smumgr_funcs = &iceland_smumgr_funcs;\r\nreturn 0;\r\n}\r\nint iceland_smu_fini(struct amdgpu_device *adev)\r\n{\r\namdgpu_bo_unref(&adev->smu.toc_buf);\r\nkfree(adev->smu.priv);\r\nadev->smu.priv = NULL;\r\nif (adev->firmware.fw_buf)\r\namdgpu_ucode_fini_bo(adev);\r\nreturn 0;\r\n}
