int amdgpu_amdkfd_init(void)\r\n{\r\nint ret;\r\n#if defined(CONFIG_HSA_AMD_MODULE)\r\nint (*kgd2kfd_init_p)(unsigned, const struct kgd2kfd_calls**);\r\nkgd2kfd_init_p = symbol_request(kgd2kfd_init);\r\nif (kgd2kfd_init_p == NULL)\r\nreturn -ENOENT;\r\nret = kgd2kfd_init_p(KFD_INTERFACE_VERSION, &kgd2kfd);\r\nif (ret) {\r\nsymbol_put(kgd2kfd_init);\r\nkgd2kfd = NULL;\r\n}\r\n#elif defined(CONFIG_HSA_AMD)\r\nret = kgd2kfd_init(KFD_INTERFACE_VERSION, &kgd2kfd);\r\nif (ret)\r\nkgd2kfd = NULL;\r\n#else\r\nret = -ENOENT;\r\n#endif\r\nreturn ret;\r\n}\r\nbool amdgpu_amdkfd_load_interface(struct amdgpu_device *rdev)\r\n{\r\nswitch (rdev->asic_type) {\r\n#ifdef CONFIG_DRM_AMDGPU_CIK\r\ncase CHIP_KAVERI:\r\nkfd2kgd = amdgpu_amdkfd_gfx_7_get_functions();\r\nbreak;\r\n#endif\r\ncase CHIP_CARRIZO:\r\nkfd2kgd = amdgpu_amdkfd_gfx_8_0_get_functions();\r\nbreak;\r\ndefault:\r\nreturn false;\r\n}\r\nreturn true;\r\n}\r\nvoid amdgpu_amdkfd_fini(void)\r\n{\r\nif (kgd2kfd) {\r\nkgd2kfd->exit();\r\nsymbol_put(kgd2kfd_init);\r\n}\r\n}\r\nvoid amdgpu_amdkfd_device_probe(struct amdgpu_device *rdev)\r\n{\r\nif (kgd2kfd)\r\nrdev->kfd = kgd2kfd->probe((struct kgd_dev *)rdev,\r\nrdev->pdev, kfd2kgd);\r\n}\r\nvoid amdgpu_amdkfd_device_init(struct amdgpu_device *rdev)\r\n{\r\nif (rdev->kfd) {\r\nstruct kgd2kfd_shared_resources gpu_resources = {\r\n.compute_vmid_bitmap = 0xFF00,\r\n.first_compute_pipe = 1,\r\n.compute_pipe_count = 4 - 1,\r\n};\r\namdgpu_doorbell_get_kfd_info(rdev,\r\n&gpu_resources.doorbell_physical_address,\r\n&gpu_resources.doorbell_aperture_size,\r\n&gpu_resources.doorbell_start_offset);\r\nkgd2kfd->device_init(rdev->kfd, &gpu_resources);\r\n}\r\n}\r\nvoid amdgpu_amdkfd_device_fini(struct amdgpu_device *rdev)\r\n{\r\nif (rdev->kfd) {\r\nkgd2kfd->device_exit(rdev->kfd);\r\nrdev->kfd = NULL;\r\n}\r\n}\r\nvoid amdgpu_amdkfd_interrupt(struct amdgpu_device *rdev,\r\nconst void *ih_ring_entry)\r\n{\r\nif (rdev->kfd)\r\nkgd2kfd->interrupt(rdev->kfd, ih_ring_entry);\r\n}\r\nvoid amdgpu_amdkfd_suspend(struct amdgpu_device *rdev)\r\n{\r\nif (rdev->kfd)\r\nkgd2kfd->suspend(rdev->kfd);\r\n}\r\nint amdgpu_amdkfd_resume(struct amdgpu_device *rdev)\r\n{\r\nint r = 0;\r\nif (rdev->kfd)\r\nr = kgd2kfd->resume(rdev->kfd);\r\nreturn r;\r\n}\r\nu32 pool_to_domain(enum kgd_memory_pool p)\r\n{\r\nswitch (p) {\r\ncase KGD_POOL_FRAMEBUFFER: return AMDGPU_GEM_DOMAIN_VRAM;\r\ndefault: return AMDGPU_GEM_DOMAIN_GTT;\r\n}\r\n}\r\nint alloc_gtt_mem(struct kgd_dev *kgd, size_t size,\r\nvoid **mem_obj, uint64_t *gpu_addr,\r\nvoid **cpu_ptr)\r\n{\r\nstruct amdgpu_device *rdev = (struct amdgpu_device *)kgd;\r\nstruct kgd_mem **mem = (struct kgd_mem **) mem_obj;\r\nint r;\r\nBUG_ON(kgd == NULL);\r\nBUG_ON(gpu_addr == NULL);\r\nBUG_ON(cpu_ptr == NULL);\r\n*mem = kmalloc(sizeof(struct kgd_mem), GFP_KERNEL);\r\nif ((*mem) == NULL)\r\nreturn -ENOMEM;\r\nr = amdgpu_bo_create(rdev, size, PAGE_SIZE, true, AMDGPU_GEM_DOMAIN_GTT,\r\nAMDGPU_GEM_CREATE_CPU_GTT_USWC, NULL, NULL, &(*mem)->bo);\r\nif (r) {\r\ndev_err(rdev->dev,\r\n"failed to allocate BO for amdkfd (%d)\n", r);\r\nreturn r;\r\n}\r\nr = amdgpu_bo_reserve((*mem)->bo, true);\r\nif (r) {\r\ndev_err(rdev->dev, "(%d) failed to reserve bo for amdkfd\n", r);\r\ngoto allocate_mem_reserve_bo_failed;\r\n}\r\nr = amdgpu_bo_pin((*mem)->bo, AMDGPU_GEM_DOMAIN_GTT,\r\n&(*mem)->gpu_addr);\r\nif (r) {\r\ndev_err(rdev->dev, "(%d) failed to pin bo for amdkfd\n", r);\r\ngoto allocate_mem_pin_bo_failed;\r\n}\r\n*gpu_addr = (*mem)->gpu_addr;\r\nr = amdgpu_bo_kmap((*mem)->bo, &(*mem)->cpu_ptr);\r\nif (r) {\r\ndev_err(rdev->dev,\r\n"(%d) failed to map bo to kernel for amdkfd\n", r);\r\ngoto allocate_mem_kmap_bo_failed;\r\n}\r\n*cpu_ptr = (*mem)->cpu_ptr;\r\namdgpu_bo_unreserve((*mem)->bo);\r\nreturn 0;\r\nallocate_mem_kmap_bo_failed:\r\namdgpu_bo_unpin((*mem)->bo);\r\nallocate_mem_pin_bo_failed:\r\namdgpu_bo_unreserve((*mem)->bo);\r\nallocate_mem_reserve_bo_failed:\r\namdgpu_bo_unref(&(*mem)->bo);\r\nreturn r;\r\n}\r\nvoid free_gtt_mem(struct kgd_dev *kgd, void *mem_obj)\r\n{\r\nstruct kgd_mem *mem = (struct kgd_mem *) mem_obj;\r\nBUG_ON(mem == NULL);\r\namdgpu_bo_reserve(mem->bo, true);\r\namdgpu_bo_kunmap(mem->bo);\r\namdgpu_bo_unpin(mem->bo);\r\namdgpu_bo_unreserve(mem->bo);\r\namdgpu_bo_unref(&(mem->bo));\r\nkfree(mem);\r\n}\r\nuint64_t get_vmem_size(struct kgd_dev *kgd)\r\n{\r\nstruct amdgpu_device *rdev =\r\n(struct amdgpu_device *)kgd;\r\nBUG_ON(kgd == NULL);\r\nreturn rdev->mc.real_vram_size;\r\n}\r\nuint64_t get_gpu_clock_counter(struct kgd_dev *kgd)\r\n{\r\nstruct amdgpu_device *rdev = (struct amdgpu_device *)kgd;\r\nif (rdev->asic_funcs->get_gpu_clock_counter)\r\nreturn rdev->asic_funcs->get_gpu_clock_counter(rdev);\r\nreturn 0;\r\n}\r\nuint32_t get_max_engine_clock_in_mhz(struct kgd_dev *kgd)\r\n{\r\nstruct amdgpu_device *rdev = (struct amdgpu_device *)kgd;\r\nreturn rdev->pm.dpm.dyn_state.max_clock_voltage_on_ac.sclk / 100;\r\n}
