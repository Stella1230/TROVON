static int is_amd(void)\r\n{\r\nreturn cpu_vendor[0] == A32('A', 'u', 't', 'h') &&\r\ncpu_vendor[1] == A32('e', 'n', 't', 'i') &&\r\ncpu_vendor[2] == A32('c', 'A', 'M', 'D');\r\n}\r\nstatic int is_centaur(void)\r\n{\r\nreturn cpu_vendor[0] == A32('C', 'e', 'n', 't') &&\r\ncpu_vendor[1] == A32('a', 'u', 'r', 'H') &&\r\ncpu_vendor[2] == A32('a', 'u', 'l', 's');\r\n}\r\nstatic int is_transmeta(void)\r\n{\r\nreturn cpu_vendor[0] == A32('G', 'e', 'n', 'u') &&\r\ncpu_vendor[1] == A32('i', 'n', 'e', 'T') &&\r\ncpu_vendor[2] == A32('M', 'x', '8', '6');\r\n}\r\nstatic int is_intel(void)\r\n{\r\nreturn cpu_vendor[0] == A32('G', 'e', 'n', 'u') &&\r\ncpu_vendor[1] == A32('i', 'n', 'e', 'I') &&\r\ncpu_vendor[2] == A32('n', 't', 'e', 'l');\r\n}\r\nstatic int check_cpuflags(void)\r\n{\r\nu32 err;\r\nint i;\r\nerr = 0;\r\nfor (i = 0; i < NCAPINTS; i++) {\r\nerr_flags[i] = req_flags[i] & ~cpu.flags[i];\r\nif (err_flags[i])\r\nerr |= 1 << i;\r\n}\r\nreturn err;\r\n}\r\nint check_cpu(int *cpu_level_ptr, int *req_level_ptr, u32 **err_flags_ptr)\r\n{\r\nint err;\r\nmemset(&cpu.flags, 0, sizeof cpu.flags);\r\ncpu.level = 3;\r\nif (has_eflag(X86_EFLAGS_AC))\r\ncpu.level = 4;\r\nget_cpuflags();\r\nerr = check_cpuflags();\r\nif (test_bit(X86_FEATURE_LM, cpu.flags))\r\ncpu.level = 64;\r\nif (err == 0x01 &&\r\n!(err_flags[0] &\r\n~((1 << X86_FEATURE_XMM)|(1 << X86_FEATURE_XMM2))) &&\r\nis_amd()) {\r\nu32 ecx = MSR_K7_HWCR;\r\nu32 eax, edx;\r\nasm("rdmsr" : "=a" (eax), "=d" (edx) : "c" (ecx));\r\neax &= ~(1 << 15);\r\nasm("wrmsr" : : "a" (eax), "d" (edx), "c" (ecx));\r\nget_cpuflags();\r\nerr = check_cpuflags();\r\n} else if (err == 0x01 &&\r\n!(err_flags[0] & ~(1 << X86_FEATURE_CX8)) &&\r\nis_centaur() && cpu.model >= 6) {\r\nu32 ecx = MSR_VIA_FCR;\r\nu32 eax, edx;\r\nasm("rdmsr" : "=a" (eax), "=d" (edx) : "c" (ecx));\r\neax |= (1<<1)|(1<<7);\r\nasm("wrmsr" : : "a" (eax), "d" (edx), "c" (ecx));\r\nset_bit(X86_FEATURE_CX8, cpu.flags);\r\nerr = check_cpuflags();\r\n} else if (err == 0x01 && is_transmeta()) {\r\nu32 ecx = 0x80860004;\r\nu32 eax, edx;\r\nu32 level = 1;\r\nasm("rdmsr" : "=a" (eax), "=d" (edx) : "c" (ecx));\r\nasm("wrmsr" : : "a" (~0), "d" (edx), "c" (ecx));\r\nasm("cpuid"\r\n: "+a" (level), "=d" (cpu.flags[0])\r\n: : "ecx", "ebx");\r\nasm("wrmsr" : : "a" (eax), "d" (edx), "c" (ecx));\r\nerr = check_cpuflags();\r\n} else if (err == 0x01 &&\r\n!(err_flags[0] & ~(1 << X86_FEATURE_PAE)) &&\r\nis_intel() && cpu.level == 6 &&\r\n(cpu.model == 9 || cpu.model == 13)) {\r\nif (cmdline_find_option_bool("forcepae")) {\r\nputs("WARNING: Forcing PAE in CPU flags\n");\r\nset_bit(X86_FEATURE_PAE, cpu.flags);\r\nerr = check_cpuflags();\r\n}\r\nelse {\r\nputs("WARNING: PAE disabled. Use parameter 'forcepae' to enable at your own risk!\n");\r\n}\r\n}\r\nif (err_flags_ptr)\r\n*err_flags_ptr = err ? err_flags : NULL;\r\nif (cpu_level_ptr)\r\n*cpu_level_ptr = cpu.level;\r\nif (req_level_ptr)\r\n*req_level_ptr = req_level;\r\nreturn (cpu.level < req_level || err) ? -1 : 0;\r\n}
