__inline__ void\r\nqla2x00_start_timer(scsi_qla_host_t *vha, void *func, unsigned long interval)\r\n{\r\ninit_timer(&vha->timer);\r\nvha->timer.expires = jiffies + interval * HZ;\r\nvha->timer.data = (unsigned long)vha;\r\nvha->timer.function = (void (*)(unsigned long))func;\r\nadd_timer(&vha->timer);\r\nvha->timer_active = 1;\r\n}\r\nstatic inline void\r\nqla2x00_restart_timer(scsi_qla_host_t *vha, unsigned long interval)\r\n{\r\nif (vha->device_flags & DFLG_DEV_FAILED) {\r\nql_dbg(ql_dbg_timer, vha, 0x600d,\r\n"Device in a failed state, returning.\n");\r\nreturn;\r\n}\r\nmod_timer(&vha->timer, jiffies + interval * HZ);\r\n}\r\nstatic __inline__ void\r\nqla2x00_stop_timer(scsi_qla_host_t *vha)\r\n{\r\ndel_timer_sync(&vha->timer);\r\nvha->timer_active = 0;\r\n}\r\nstatic int qla2x00_alloc_queues(struct qla_hw_data *ha, struct req_que *req,\r\nstruct rsp_que *rsp)\r\n{\r\nscsi_qla_host_t *vha = pci_get_drvdata(ha->pdev);\r\nha->req_q_map = kzalloc(sizeof(struct req_que *) * ha->max_req_queues,\r\nGFP_KERNEL);\r\nif (!ha->req_q_map) {\r\nql_log(ql_log_fatal, vha, 0x003b,\r\n"Unable to allocate memory for request queue ptrs.\n");\r\ngoto fail_req_map;\r\n}\r\nha->rsp_q_map = kzalloc(sizeof(struct rsp_que *) * ha->max_rsp_queues,\r\nGFP_KERNEL);\r\nif (!ha->rsp_q_map) {\r\nql_log(ql_log_fatal, vha, 0x003c,\r\n"Unable to allocate memory for response queue ptrs.\n");\r\ngoto fail_rsp_map;\r\n}\r\nha->rsp_q_map[0] = rsp;\r\nha->req_q_map[0] = req;\r\nset_bit(0, ha->rsp_qid_map);\r\nset_bit(0, ha->req_qid_map);\r\nreturn 1;\r\nfail_rsp_map:\r\nkfree(ha->req_q_map);\r\nha->req_q_map = NULL;\r\nfail_req_map:\r\nreturn -ENOMEM;\r\n}\r\nstatic void qla2x00_free_req_que(struct qla_hw_data *ha, struct req_que *req)\r\n{\r\nif (IS_QLAFX00(ha)) {\r\nif (req && req->ring_fx00)\r\ndma_free_coherent(&ha->pdev->dev,\r\n(req->length_fx00 + 1) * sizeof(request_t),\r\nreq->ring_fx00, req->dma_fx00);\r\n} else if (req && req->ring)\r\ndma_free_coherent(&ha->pdev->dev,\r\n(req->length + 1) * sizeof(request_t),\r\nreq->ring, req->dma);\r\nif (req)\r\nkfree(req->outstanding_cmds);\r\nkfree(req);\r\nreq = NULL;\r\n}\r\nstatic void qla2x00_free_rsp_que(struct qla_hw_data *ha, struct rsp_que *rsp)\r\n{\r\nif (IS_QLAFX00(ha)) {\r\nif (rsp && rsp->ring)\r\ndma_free_coherent(&ha->pdev->dev,\r\n(rsp->length_fx00 + 1) * sizeof(request_t),\r\nrsp->ring_fx00, rsp->dma_fx00);\r\n} else if (rsp && rsp->ring) {\r\ndma_free_coherent(&ha->pdev->dev,\r\n(rsp->length + 1) * sizeof(response_t),\r\nrsp->ring, rsp->dma);\r\n}\r\nkfree(rsp);\r\nrsp = NULL;\r\n}\r\nstatic void qla2x00_free_queues(struct qla_hw_data *ha)\r\n{\r\nstruct req_que *req;\r\nstruct rsp_que *rsp;\r\nint cnt;\r\nfor (cnt = 0; cnt < ha->max_req_queues; cnt++) {\r\nif (!test_bit(cnt, ha->req_qid_map))\r\ncontinue;\r\nreq = ha->req_q_map[cnt];\r\nqla2x00_free_req_que(ha, req);\r\n}\r\nkfree(ha->req_q_map);\r\nha->req_q_map = NULL;\r\nfor (cnt = 0; cnt < ha->max_rsp_queues; cnt++) {\r\nif (!test_bit(cnt, ha->rsp_qid_map))\r\ncontinue;\r\nrsp = ha->rsp_q_map[cnt];\r\nqla2x00_free_rsp_que(ha, rsp);\r\n}\r\nkfree(ha->rsp_q_map);\r\nha->rsp_q_map = NULL;\r\n}\r\nstatic int qla25xx_setup_mode(struct scsi_qla_host *vha)\r\n{\r\nuint16_t options = 0;\r\nint ques, req, ret;\r\nstruct qla_hw_data *ha = vha->hw;\r\nif (!(ha->fw_attributes & BIT_6)) {\r\nql_log(ql_log_warn, vha, 0x00d8,\r\n"Firmware is not multi-queue capable.\n");\r\ngoto fail;\r\n}\r\nif (ql2xmultique_tag) {\r\noptions |= BIT_7;\r\nreq = qla25xx_create_req_que(ha, options, 0, 0, -1,\r\nQLA_DEFAULT_QUE_QOS);\r\nif (!req) {\r\nql_log(ql_log_warn, vha, 0x00e0,\r\n"Failed to create request queue.\n");\r\ngoto fail;\r\n}\r\nha->wq = alloc_workqueue("qla2xxx_wq", WQ_MEM_RECLAIM, 1);\r\nvha->req = ha->req_q_map[req];\r\noptions |= BIT_1;\r\nfor (ques = 1; ques < ha->max_rsp_queues; ques++) {\r\nret = qla25xx_create_rsp_que(ha, options, 0, 0, req);\r\nif (!ret) {\r\nql_log(ql_log_warn, vha, 0x00e8,\r\n"Failed to create response queue.\n");\r\ngoto fail2;\r\n}\r\n}\r\nha->flags.cpu_affinity_enabled = 1;\r\nql_dbg(ql_dbg_multiq, vha, 0xc007,\r\n"CPU affinity mode enabled, "\r\n"no. of response queues:%d no. of request queues:%d.\n",\r\nha->max_rsp_queues, ha->max_req_queues);\r\nql_dbg(ql_dbg_init, vha, 0x00e9,\r\n"CPU affinity mode enabled, "\r\n"no. of response queues:%d no. of request queues:%d.\n",\r\nha->max_rsp_queues, ha->max_req_queues);\r\n}\r\nreturn 0;\r\nfail2:\r\nqla25xx_delete_queues(vha);\r\ndestroy_workqueue(ha->wq);\r\nha->wq = NULL;\r\nvha->req = ha->req_q_map[0];\r\nfail:\r\nha->mqenable = 0;\r\nkfree(ha->req_q_map);\r\nkfree(ha->rsp_q_map);\r\nha->max_req_queues = ha->max_rsp_queues = 1;\r\nreturn 1;\r\n}\r\nstatic char *\r\nqla2x00_pci_info_str(struct scsi_qla_host *vha, char *str)\r\n{\r\nstruct qla_hw_data *ha = vha->hw;\r\nstatic char *pci_bus_modes[] = {\r\n"33", "66", "100", "133",\r\n};\r\nuint16_t pci_bus;\r\nstrcpy(str, "PCI");\r\npci_bus = (ha->pci_attr & (BIT_9 | BIT_10)) >> 9;\r\nif (pci_bus) {\r\nstrcat(str, "-X (");\r\nstrcat(str, pci_bus_modes[pci_bus]);\r\n} else {\r\npci_bus = (ha->pci_attr & BIT_8) >> 8;\r\nstrcat(str, " (");\r\nstrcat(str, pci_bus_modes[pci_bus]);\r\n}\r\nstrcat(str, " MHz)");\r\nreturn (str);\r\n}\r\nstatic char *\r\nqla24xx_pci_info_str(struct scsi_qla_host *vha, char *str)\r\n{\r\nstatic char *pci_bus_modes[] = { "33", "66", "100", "133", };\r\nstruct qla_hw_data *ha = vha->hw;\r\nuint32_t pci_bus;\r\nif (pci_is_pcie(ha->pdev)) {\r\nchar lwstr[6];\r\nuint32_t lstat, lspeed, lwidth;\r\npcie_capability_read_dword(ha->pdev, PCI_EXP_LNKCAP, &lstat);\r\nlspeed = lstat & PCI_EXP_LNKCAP_SLS;\r\nlwidth = (lstat & PCI_EXP_LNKCAP_MLW) >> 4;\r\nstrcpy(str, "PCIe (");\r\nswitch (lspeed) {\r\ncase 1:\r\nstrcat(str, "2.5GT/s ");\r\nbreak;\r\ncase 2:\r\nstrcat(str, "5.0GT/s ");\r\nbreak;\r\ncase 3:\r\nstrcat(str, "8.0GT/s ");\r\nbreak;\r\ndefault:\r\nstrcat(str, "<unknown> ");\r\nbreak;\r\n}\r\nsnprintf(lwstr, sizeof(lwstr), "x%d)", lwidth);\r\nstrcat(str, lwstr);\r\nreturn str;\r\n}\r\nstrcpy(str, "PCI");\r\npci_bus = (ha->pci_attr & CSRX_PCIX_BUS_MODE_MASK) >> 8;\r\nif (pci_bus == 0 || pci_bus == 8) {\r\nstrcat(str, " (");\r\nstrcat(str, pci_bus_modes[pci_bus >> 3]);\r\n} else {\r\nstrcat(str, "-X ");\r\nif (pci_bus & BIT_2)\r\nstrcat(str, "Mode 2");\r\nelse\r\nstrcat(str, "Mode 1");\r\nstrcat(str, " (");\r\nstrcat(str, pci_bus_modes[pci_bus & ~BIT_2]);\r\n}\r\nstrcat(str, " MHz)");\r\nreturn str;\r\n}\r\nstatic char *\r\nqla2x00_fw_version_str(struct scsi_qla_host *vha, char *str, size_t size)\r\n{\r\nchar un_str[10];\r\nstruct qla_hw_data *ha = vha->hw;\r\nsnprintf(str, size, "%d.%02d.%02d ", ha->fw_major_version,\r\nha->fw_minor_version, ha->fw_subminor_version);\r\nif (ha->fw_attributes & BIT_9) {\r\nstrcat(str, "FLX");\r\nreturn (str);\r\n}\r\nswitch (ha->fw_attributes & 0xFF) {\r\ncase 0x7:\r\nstrcat(str, "EF");\r\nbreak;\r\ncase 0x17:\r\nstrcat(str, "TP");\r\nbreak;\r\ncase 0x37:\r\nstrcat(str, "IP");\r\nbreak;\r\ncase 0x77:\r\nstrcat(str, "VI");\r\nbreak;\r\ndefault:\r\nsprintf(un_str, "(%x)", ha->fw_attributes);\r\nstrcat(str, un_str);\r\nbreak;\r\n}\r\nif (ha->fw_attributes & 0x100)\r\nstrcat(str, "X");\r\nreturn (str);\r\n}\r\nstatic char *\r\nqla24xx_fw_version_str(struct scsi_qla_host *vha, char *str, size_t size)\r\n{\r\nstruct qla_hw_data *ha = vha->hw;\r\nsnprintf(str, size, "%d.%02d.%02d (%x)", ha->fw_major_version,\r\nha->fw_minor_version, ha->fw_subminor_version, ha->fw_attributes);\r\nreturn str;\r\n}\r\nvoid\r\nqla2x00_sp_free_dma(void *vha, void *ptr)\r\n{\r\nsrb_t *sp = (srb_t *)ptr;\r\nstruct scsi_cmnd *cmd = GET_CMD_SP(sp);\r\nstruct qla_hw_data *ha = sp->fcport->vha->hw;\r\nvoid *ctx = GET_CMD_CTX_SP(sp);\r\nif (sp->flags & SRB_DMA_VALID) {\r\nscsi_dma_unmap(cmd);\r\nsp->flags &= ~SRB_DMA_VALID;\r\n}\r\nif (sp->flags & SRB_CRC_PROT_DMA_VALID) {\r\ndma_unmap_sg(&ha->pdev->dev, scsi_prot_sglist(cmd),\r\nscsi_prot_sg_count(cmd), cmd->sc_data_direction);\r\nsp->flags &= ~SRB_CRC_PROT_DMA_VALID;\r\n}\r\nif (sp->flags & SRB_CRC_CTX_DSD_VALID) {\r\nqla2x00_clean_dsd_pool(ha, sp, NULL);\r\nsp->flags &= ~SRB_CRC_CTX_DSD_VALID;\r\n}\r\nif (sp->flags & SRB_CRC_CTX_DMA_VALID) {\r\ndma_pool_free(ha->dl_dma_pool, ctx,\r\n((struct crc_context *)ctx)->crc_ctx_dma);\r\nsp->flags &= ~SRB_CRC_CTX_DMA_VALID;\r\n}\r\nif (sp->flags & SRB_FCP_CMND_DMA_VALID) {\r\nstruct ct6_dsd *ctx1 = (struct ct6_dsd *)ctx;\r\ndma_pool_free(ha->fcp_cmnd_dma_pool, ctx1->fcp_cmnd,\r\nctx1->fcp_cmnd_dma);\r\nlist_splice(&ctx1->dsd_list, &ha->gbl_dsd_list);\r\nha->gbl_dsd_inuse -= ctx1->dsd_use_cnt;\r\nha->gbl_dsd_avail += ctx1->dsd_use_cnt;\r\nmempool_free(ctx1, ha->ctx_mempool);\r\nctx1 = NULL;\r\n}\r\nCMD_SP(cmd) = NULL;\r\nqla2x00_rel_sp(sp->fcport->vha, sp);\r\n}\r\nstatic void\r\nqla2x00_sp_compl(void *data, void *ptr, int res)\r\n{\r\nstruct qla_hw_data *ha = (struct qla_hw_data *)data;\r\nsrb_t *sp = (srb_t *)ptr;\r\nstruct scsi_cmnd *cmd = GET_CMD_SP(sp);\r\ncmd->result = res;\r\nif (atomic_read(&sp->ref_count) == 0) {\r\nql_dbg(ql_dbg_io, sp->fcport->vha, 0x3015,\r\n"SP reference-count to ZERO -- sp=%p cmd=%p.\n",\r\nsp, GET_CMD_SP(sp));\r\nif (ql2xextended_error_logging & ql_dbg_io)\r\nWARN_ON(atomic_read(&sp->ref_count) == 0);\r\nreturn;\r\n}\r\nif (!atomic_dec_and_test(&sp->ref_count))\r\nreturn;\r\nqla2x00_sp_free_dma(ha, sp);\r\ncmd->scsi_done(cmd);\r\n}\r\nstatic int\r\nqla2xxx_queuecommand(struct Scsi_Host *host, struct scsi_cmnd *cmd)\r\n{\r\nscsi_qla_host_t *vha = shost_priv(host);\r\nfc_port_t *fcport = (struct fc_port *) cmd->device->hostdata;\r\nstruct fc_rport *rport = starget_to_rport(scsi_target(cmd->device));\r\nstruct qla_hw_data *ha = vha->hw;\r\nstruct scsi_qla_host *base_vha = pci_get_drvdata(ha->pdev);\r\nsrb_t *sp;\r\nint rval;\r\nif (ha->flags.eeh_busy) {\r\nif (ha->flags.pci_channel_io_perm_failure) {\r\nql_dbg(ql_dbg_aer, vha, 0x9010,\r\n"PCI Channel IO permanent failure, exiting "\r\n"cmd=%p.\n", cmd);\r\ncmd->result = DID_NO_CONNECT << 16;\r\n} else {\r\nql_dbg(ql_dbg_aer, vha, 0x9011,\r\n"EEH_Busy, Requeuing the cmd=%p.\n", cmd);\r\ncmd->result = DID_REQUEUE << 16;\r\n}\r\ngoto qc24_fail_command;\r\n}\r\nrval = fc_remote_port_chkready(rport);\r\nif (rval) {\r\ncmd->result = rval;\r\nql_dbg(ql_dbg_io + ql_dbg_verbose, vha, 0x3003,\r\n"fc_remote_port_chkready failed for cmd=%p, rval=0x%x.\n",\r\ncmd, rval);\r\ngoto qc24_fail_command;\r\n}\r\nif (!vha->flags.difdix_supported &&\r\nscsi_get_prot_op(cmd) != SCSI_PROT_NORMAL) {\r\nql_dbg(ql_dbg_io, vha, 0x3004,\r\n"DIF Cap not reg, fail DIF capable cmd's:%p.\n",\r\ncmd);\r\ncmd->result = DID_NO_CONNECT << 16;\r\ngoto qc24_fail_command;\r\n}\r\nif (!fcport) {\r\ncmd->result = DID_NO_CONNECT << 16;\r\ngoto qc24_fail_command;\r\n}\r\nif (atomic_read(&fcport->state) != FCS_ONLINE) {\r\nif (atomic_read(&fcport->state) == FCS_DEVICE_DEAD ||\r\natomic_read(&base_vha->loop_state) == LOOP_DEAD) {\r\nql_dbg(ql_dbg_io, vha, 0x3005,\r\n"Returning DNC, fcport_state=%d loop_state=%d.\n",\r\natomic_read(&fcport->state),\r\natomic_read(&base_vha->loop_state));\r\ncmd->result = DID_NO_CONNECT << 16;\r\ngoto qc24_fail_command;\r\n}\r\ngoto qc24_target_busy;\r\n}\r\nif (fcport->retry_delay_timestamp == 0) {\r\n} else if (time_after(jiffies, fcport->retry_delay_timestamp))\r\nfcport->retry_delay_timestamp = 0;\r\nelse\r\ngoto qc24_target_busy;\r\nsp = qla2x00_get_sp(vha, fcport, GFP_ATOMIC);\r\nif (!sp)\r\ngoto qc24_host_busy;\r\nsp->u.scmd.cmd = cmd;\r\nsp->type = SRB_SCSI_CMD;\r\natomic_set(&sp->ref_count, 1);\r\nCMD_SP(cmd) = (void *)sp;\r\nsp->free = qla2x00_sp_free_dma;\r\nsp->done = qla2x00_sp_compl;\r\nrval = ha->isp_ops->start_scsi(sp);\r\nif (rval != QLA_SUCCESS) {\r\nql_dbg(ql_dbg_io + ql_dbg_verbose, vha, 0x3013,\r\n"Start scsi failed rval=%d for cmd=%p.\n", rval, cmd);\r\ngoto qc24_host_busy_free_sp;\r\n}\r\nreturn 0;\r\nqc24_host_busy_free_sp:\r\nqla2x00_sp_free_dma(ha, sp);\r\nqc24_host_busy:\r\nreturn SCSI_MLQUEUE_HOST_BUSY;\r\nqc24_target_busy:\r\nreturn SCSI_MLQUEUE_TARGET_BUSY;\r\nqc24_fail_command:\r\ncmd->scsi_done(cmd);\r\nreturn 0;\r\n}\r\nstatic int\r\nqla2x00_eh_wait_on_command(struct scsi_cmnd *cmd)\r\n{\r\n#define ABORT_POLLING_PERIOD 1000\r\n#define ABORT_WAIT_ITER ((2 * 1000) / (ABORT_POLLING_PERIOD))\r\nunsigned long wait_iter = ABORT_WAIT_ITER;\r\nscsi_qla_host_t *vha = shost_priv(cmd->device->host);\r\nstruct qla_hw_data *ha = vha->hw;\r\nint ret = QLA_SUCCESS;\r\nif (unlikely(pci_channel_offline(ha->pdev)) || ha->flags.eeh_busy) {\r\nql_dbg(ql_dbg_taskm, vha, 0x8005,\r\n"Return:eh_wait.\n");\r\nreturn ret;\r\n}\r\nwhile (CMD_SP(cmd) && wait_iter--) {\r\nmsleep(ABORT_POLLING_PERIOD);\r\n}\r\nif (CMD_SP(cmd))\r\nret = QLA_FUNCTION_FAILED;\r\nreturn ret;\r\n}\r\nint\r\nqla2x00_wait_for_hba_online(scsi_qla_host_t *vha)\r\n{\r\nint return_status;\r\nunsigned long wait_online;\r\nstruct qla_hw_data *ha = vha->hw;\r\nscsi_qla_host_t *base_vha = pci_get_drvdata(ha->pdev);\r\nwait_online = jiffies + (MAX_LOOP_TIMEOUT * HZ);\r\nwhile (((test_bit(ISP_ABORT_NEEDED, &base_vha->dpc_flags)) ||\r\ntest_bit(ABORT_ISP_ACTIVE, &base_vha->dpc_flags) ||\r\ntest_bit(ISP_ABORT_RETRY, &base_vha->dpc_flags) ||\r\nha->dpc_active) && time_before(jiffies, wait_online)) {\r\nmsleep(1000);\r\n}\r\nif (base_vha->flags.online)\r\nreturn_status = QLA_SUCCESS;\r\nelse\r\nreturn_status = QLA_FUNCTION_FAILED;\r\nreturn (return_status);\r\n}\r\nstatic void\r\nqla2x00_wait_for_hba_ready(scsi_qla_host_t *vha)\r\n{\r\nstruct qla_hw_data *ha = vha->hw;\r\nwhile (((qla2x00_reset_active(vha)) || ha->dpc_active ||\r\nha->flags.mbox_busy) ||\r\ntest_bit(FX00_RESET_RECOVERY, &vha->dpc_flags) ||\r\ntest_bit(FX00_TARGET_SCAN, &vha->dpc_flags))\r\nmsleep(1000);\r\n}\r\nint\r\nqla2x00_wait_for_chip_reset(scsi_qla_host_t *vha)\r\n{\r\nint return_status;\r\nunsigned long wait_reset;\r\nstruct qla_hw_data *ha = vha->hw;\r\nscsi_qla_host_t *base_vha = pci_get_drvdata(ha->pdev);\r\nwait_reset = jiffies + (MAX_LOOP_TIMEOUT * HZ);\r\nwhile (((test_bit(ISP_ABORT_NEEDED, &base_vha->dpc_flags)) ||\r\ntest_bit(ABORT_ISP_ACTIVE, &base_vha->dpc_flags) ||\r\ntest_bit(ISP_ABORT_RETRY, &base_vha->dpc_flags) ||\r\nha->dpc_active) && time_before(jiffies, wait_reset)) {\r\nmsleep(1000);\r\nif (!test_bit(ISP_ABORT_NEEDED, &base_vha->dpc_flags) &&\r\nha->flags.chip_reset_done)\r\nbreak;\r\n}\r\nif (ha->flags.chip_reset_done)\r\nreturn_status = QLA_SUCCESS;\r\nelse\r\nreturn_status = QLA_FUNCTION_FAILED;\r\nreturn return_status;\r\n}\r\nstatic void\r\nsp_get(struct srb *sp)\r\n{\r\natomic_inc(&sp->ref_count);\r\n}\r\nstatic int\r\nqla2xxx_eh_abort(struct scsi_cmnd *cmd)\r\n{\r\nscsi_qla_host_t *vha = shost_priv(cmd->device->host);\r\nsrb_t *sp;\r\nint ret;\r\nunsigned int id;\r\nuint64_t lun;\r\nunsigned long flags;\r\nint rval, wait = 0;\r\nstruct qla_hw_data *ha = vha->hw;\r\nif (!CMD_SP(cmd))\r\nreturn SUCCESS;\r\nret = fc_block_scsi_eh(cmd);\r\nif (ret != 0)\r\nreturn ret;\r\nret = SUCCESS;\r\nid = cmd->device->id;\r\nlun = cmd->device->lun;\r\nspin_lock_irqsave(&ha->hardware_lock, flags);\r\nsp = (srb_t *) CMD_SP(cmd);\r\nif (!sp) {\r\nspin_unlock_irqrestore(&ha->hardware_lock, flags);\r\nreturn SUCCESS;\r\n}\r\nql_dbg(ql_dbg_taskm, vha, 0x8002,\r\n"Aborting from RISC nexus=%ld:%d:%llu sp=%p cmd=%p handle=%x\n",\r\nvha->host_no, id, lun, sp, cmd, sp->handle);\r\nsp_get(sp);\r\nspin_unlock_irqrestore(&ha->hardware_lock, flags);\r\nrval = ha->isp_ops->abort_command(sp);\r\nif (rval) {\r\nif (rval == QLA_FUNCTION_PARAMETER_ERROR)\r\nret = SUCCESS;\r\nelse\r\nret = FAILED;\r\nql_dbg(ql_dbg_taskm, vha, 0x8003,\r\n"Abort command mbx failed cmd=%p, rval=%x.\n", cmd, rval);\r\n} else {\r\nql_dbg(ql_dbg_taskm, vha, 0x8004,\r\n"Abort command mbx success cmd=%p.\n", cmd);\r\nwait = 1;\r\n}\r\nspin_lock_irqsave(&ha->hardware_lock, flags);\r\nsp->done(ha, sp, 0);\r\nspin_unlock_irqrestore(&ha->hardware_lock, flags);\r\nif (ret == FAILED && !CMD_SP(cmd))\r\nret = SUCCESS;\r\nif (wait) {\r\nif (qla2x00_eh_wait_on_command(cmd) != QLA_SUCCESS) {\r\nql_log(ql_log_warn, vha, 0x8006,\r\n"Abort handler timed out cmd=%p.\n", cmd);\r\nret = FAILED;\r\n}\r\n}\r\nql_log(ql_log_info, vha, 0x801c,\r\n"Abort command issued nexus=%ld:%d:%llu -- %d %x.\n",\r\nvha->host_no, id, lun, wait, ret);\r\nreturn ret;\r\n}\r\nint\r\nqla2x00_eh_wait_for_pending_commands(scsi_qla_host_t *vha, unsigned int t,\r\nuint64_t l, enum nexus_wait_type type)\r\n{\r\nint cnt, match, status;\r\nunsigned long flags;\r\nstruct qla_hw_data *ha = vha->hw;\r\nstruct req_que *req;\r\nsrb_t *sp;\r\nstruct scsi_cmnd *cmd;\r\nstatus = QLA_SUCCESS;\r\nspin_lock_irqsave(&ha->hardware_lock, flags);\r\nreq = vha->req;\r\nfor (cnt = 1; status == QLA_SUCCESS &&\r\ncnt < req->num_outstanding_cmds; cnt++) {\r\nsp = req->outstanding_cmds[cnt];\r\nif (!sp)\r\ncontinue;\r\nif (sp->type != SRB_SCSI_CMD)\r\ncontinue;\r\nif (vha->vp_idx != sp->fcport->vha->vp_idx)\r\ncontinue;\r\nmatch = 0;\r\ncmd = GET_CMD_SP(sp);\r\nswitch (type) {\r\ncase WAIT_HOST:\r\nmatch = 1;\r\nbreak;\r\ncase WAIT_TARGET:\r\nmatch = cmd->device->id == t;\r\nbreak;\r\ncase WAIT_LUN:\r\nmatch = (cmd->device->id == t &&\r\ncmd->device->lun == l);\r\nbreak;\r\n}\r\nif (!match)\r\ncontinue;\r\nspin_unlock_irqrestore(&ha->hardware_lock, flags);\r\nstatus = qla2x00_eh_wait_on_command(cmd);\r\nspin_lock_irqsave(&ha->hardware_lock, flags);\r\n}\r\nspin_unlock_irqrestore(&ha->hardware_lock, flags);\r\nreturn status;\r\n}\r\nstatic int\r\n__qla2xxx_eh_generic_reset(char *name, enum nexus_wait_type type,\r\nstruct scsi_cmnd *cmd, int (*do_reset)(struct fc_port *, uint64_t, int))\r\n{\r\nscsi_qla_host_t *vha = shost_priv(cmd->device->host);\r\nfc_port_t *fcport = (struct fc_port *) cmd->device->hostdata;\r\nint err;\r\nif (!fcport) {\r\nreturn FAILED;\r\n}\r\nerr = fc_block_scsi_eh(cmd);\r\nif (err != 0)\r\nreturn err;\r\nql_log(ql_log_info, vha, 0x8009,\r\n"%s RESET ISSUED nexus=%ld:%d:%llu cmd=%p.\n", name, vha->host_no,\r\ncmd->device->id, cmd->device->lun, cmd);\r\nerr = 0;\r\nif (qla2x00_wait_for_hba_online(vha) != QLA_SUCCESS) {\r\nql_log(ql_log_warn, vha, 0x800a,\r\n"Wait for hba online failed for cmd=%p.\n", cmd);\r\ngoto eh_reset_failed;\r\n}\r\nerr = 2;\r\nif (do_reset(fcport, cmd->device->lun, cmd->request->cpu + 1)\r\n!= QLA_SUCCESS) {\r\nql_log(ql_log_warn, vha, 0x800c,\r\n"do_reset failed for cmd=%p.\n", cmd);\r\ngoto eh_reset_failed;\r\n}\r\nerr = 3;\r\nif (qla2x00_eh_wait_for_pending_commands(vha, cmd->device->id,\r\ncmd->device->lun, type) != QLA_SUCCESS) {\r\nql_log(ql_log_warn, vha, 0x800d,\r\n"wait for pending cmds failed for cmd=%p.\n", cmd);\r\ngoto eh_reset_failed;\r\n}\r\nql_log(ql_log_info, vha, 0x800e,\r\n"%s RESET SUCCEEDED nexus:%ld:%d:%llu cmd=%p.\n", name,\r\nvha->host_no, cmd->device->id, cmd->device->lun, cmd);\r\nreturn SUCCESS;\r\neh_reset_failed:\r\nql_log(ql_log_info, vha, 0x800f,\r\n"%s RESET FAILED: %s nexus=%ld:%d:%llu cmd=%p.\n", name,\r\nreset_errors[err], vha->host_no, cmd->device->id, cmd->device->lun,\r\ncmd);\r\nreturn FAILED;\r\n}\r\nstatic int\r\nqla2xxx_eh_device_reset(struct scsi_cmnd *cmd)\r\n{\r\nscsi_qla_host_t *vha = shost_priv(cmd->device->host);\r\nstruct qla_hw_data *ha = vha->hw;\r\nreturn __qla2xxx_eh_generic_reset("DEVICE", WAIT_LUN, cmd,\r\nha->isp_ops->lun_reset);\r\n}\r\nstatic int\r\nqla2xxx_eh_target_reset(struct scsi_cmnd *cmd)\r\n{\r\nscsi_qla_host_t *vha = shost_priv(cmd->device->host);\r\nstruct qla_hw_data *ha = vha->hw;\r\nreturn __qla2xxx_eh_generic_reset("TARGET", WAIT_TARGET, cmd,\r\nha->isp_ops->target_reset);\r\n}\r\nstatic int\r\nqla2xxx_eh_bus_reset(struct scsi_cmnd *cmd)\r\n{\r\nscsi_qla_host_t *vha = shost_priv(cmd->device->host);\r\nfc_port_t *fcport = (struct fc_port *) cmd->device->hostdata;\r\nint ret = FAILED;\r\nunsigned int id;\r\nuint64_t lun;\r\nid = cmd->device->id;\r\nlun = cmd->device->lun;\r\nif (!fcport) {\r\nreturn ret;\r\n}\r\nret = fc_block_scsi_eh(cmd);\r\nif (ret != 0)\r\nreturn ret;\r\nret = FAILED;\r\nql_log(ql_log_info, vha, 0x8012,\r\n"BUS RESET ISSUED nexus=%ld:%d:%llu.\n", vha->host_no, id, lun);\r\nif (qla2x00_wait_for_hba_online(vha) != QLA_SUCCESS) {\r\nql_log(ql_log_fatal, vha, 0x8013,\r\n"Wait for hba online failed board disabled.\n");\r\ngoto eh_bus_reset_done;\r\n}\r\nif (qla2x00_loop_reset(vha) == QLA_SUCCESS)\r\nret = SUCCESS;\r\nif (ret == FAILED)\r\ngoto eh_bus_reset_done;\r\nif (qla2x00_eh_wait_for_pending_commands(vha, 0, 0, WAIT_HOST) !=\r\nQLA_SUCCESS) {\r\nql_log(ql_log_warn, vha, 0x8014,\r\n"Wait for pending commands failed.\n");\r\nret = FAILED;\r\n}\r\neh_bus_reset_done:\r\nql_log(ql_log_warn, vha, 0x802b,\r\n"BUS RESET %s nexus=%ld:%d:%llu.\n",\r\n(ret == FAILED) ? "FAILED" : "SUCCEEDED", vha->host_no, id, lun);\r\nreturn ret;\r\n}\r\nstatic int\r\nqla2xxx_eh_host_reset(struct scsi_cmnd *cmd)\r\n{\r\nscsi_qla_host_t *vha = shost_priv(cmd->device->host);\r\nstruct qla_hw_data *ha = vha->hw;\r\nint ret = FAILED;\r\nunsigned int id;\r\nuint64_t lun;\r\nscsi_qla_host_t *base_vha = pci_get_drvdata(ha->pdev);\r\nid = cmd->device->id;\r\nlun = cmd->device->lun;\r\nql_log(ql_log_info, vha, 0x8018,\r\n"ADAPTER RESET ISSUED nexus=%ld:%d:%llu.\n", vha->host_no, id, lun);\r\nif (qla2x00_reset_active(vha) || ha->optrom_state != QLA_SWAITING)\r\ngoto eh_host_reset_lock;\r\nif (vha != base_vha) {\r\nif (qla2x00_vp_abort_isp(vha))\r\ngoto eh_host_reset_lock;\r\n} else {\r\nif (IS_P3P_TYPE(vha->hw)) {\r\nif (!qla82xx_fcoe_ctx_reset(vha)) {\r\nret = SUCCESS;\r\ngoto eh_host_reset_lock;\r\n}\r\n}\r\nif (ha->wq)\r\nflush_workqueue(ha->wq);\r\nset_bit(ABORT_ISP_ACTIVE, &base_vha->dpc_flags);\r\nif (ha->isp_ops->abort_isp(base_vha)) {\r\nclear_bit(ABORT_ISP_ACTIVE, &base_vha->dpc_flags);\r\nset_bit(ISP_ABORT_NEEDED, &base_vha->dpc_flags);\r\nif (qla2x00_wait_for_hba_online(vha) != QLA_SUCCESS) {\r\nql_log(ql_log_warn, vha, 0x802a,\r\n"wait for hba online failed.\n");\r\ngoto eh_host_reset_lock;\r\n}\r\n}\r\nclear_bit(ABORT_ISP_ACTIVE, &base_vha->dpc_flags);\r\n}\r\nif (qla2x00_eh_wait_for_pending_commands(vha, 0, 0, WAIT_HOST) ==\r\nQLA_SUCCESS)\r\nret = SUCCESS;\r\neh_host_reset_lock:\r\nql_log(ql_log_info, vha, 0x8017,\r\n"ADAPTER RESET %s nexus=%ld:%d:%llu.\n",\r\n(ret == FAILED) ? "FAILED" : "SUCCEEDED", vha->host_no, id, lun);\r\nreturn ret;\r\n}\r\nint\r\nqla2x00_loop_reset(scsi_qla_host_t *vha)\r\n{\r\nint ret;\r\nstruct fc_port *fcport;\r\nstruct qla_hw_data *ha = vha->hw;\r\nif (IS_QLAFX00(ha)) {\r\nreturn qlafx00_loop_reset(vha);\r\n}\r\nif (ql2xtargetreset == 1 && ha->flags.enable_target_reset) {\r\nlist_for_each_entry(fcport, &vha->vp_fcports, list) {\r\nif (fcport->port_type != FCT_TARGET)\r\ncontinue;\r\nret = ha->isp_ops->target_reset(fcport, 0, 0);\r\nif (ret != QLA_SUCCESS) {\r\nql_dbg(ql_dbg_taskm, vha, 0x802c,\r\n"Bus Reset failed: Reset=%d "\r\n"d_id=%x.\n", ret, fcport->d_id.b24);\r\n}\r\n}\r\n}\r\nif (ha->flags.enable_lip_full_login && !IS_CNA_CAPABLE(ha)) {\r\natomic_set(&vha->loop_state, LOOP_DOWN);\r\natomic_set(&vha->loop_down_timer, LOOP_DOWN_TIME);\r\nqla2x00_mark_all_devices_lost(vha, 0);\r\nret = qla2x00_full_login_lip(vha);\r\nif (ret != QLA_SUCCESS) {\r\nql_dbg(ql_dbg_taskm, vha, 0x802d,\r\n"full_login_lip=%d.\n", ret);\r\n}\r\n}\r\nif (ha->flags.enable_lip_reset) {\r\nret = qla2x00_lip_reset(vha);\r\nif (ret != QLA_SUCCESS)\r\nql_dbg(ql_dbg_taskm, vha, 0x802e,\r\n"lip_reset failed (%d).\n", ret);\r\n}\r\nvha->marker_needed = 1;\r\nreturn QLA_SUCCESS;\r\n}\r\nvoid\r\nqla2x00_abort_all_cmds(scsi_qla_host_t *vha, int res)\r\n{\r\nint que, cnt;\r\nunsigned long flags;\r\nsrb_t *sp;\r\nstruct qla_hw_data *ha = vha->hw;\r\nstruct req_que *req;\r\nqlt_host_reset_handler(ha);\r\nspin_lock_irqsave(&ha->hardware_lock, flags);\r\nfor (que = 0; que < ha->max_req_queues; que++) {\r\nreq = ha->req_q_map[que];\r\nif (!req)\r\ncontinue;\r\nif (!req->outstanding_cmds)\r\ncontinue;\r\nfor (cnt = 1; cnt < req->num_outstanding_cmds; cnt++) {\r\nsp = req->outstanding_cmds[cnt];\r\nif (sp) {\r\nreq->outstanding_cmds[cnt] = NULL;\r\nsp->done(vha, sp, res);\r\n}\r\n}\r\n}\r\nspin_unlock_irqrestore(&ha->hardware_lock, flags);\r\n}\r\nstatic int\r\nqla2xxx_slave_alloc(struct scsi_device *sdev)\r\n{\r\nstruct fc_rport *rport = starget_to_rport(scsi_target(sdev));\r\nif (!rport || fc_remote_port_chkready(rport))\r\nreturn -ENXIO;\r\nsdev->hostdata = *(fc_port_t **)rport->dd_data;\r\nreturn 0;\r\n}\r\nstatic int\r\nqla2xxx_slave_configure(struct scsi_device *sdev)\r\n{\r\nscsi_qla_host_t *vha = shost_priv(sdev->host);\r\nstruct req_que *req = vha->req;\r\nif (IS_T10_PI_CAPABLE(vha->hw))\r\nblk_queue_update_dma_alignment(sdev->request_queue, 0x7);\r\nscsi_change_queue_depth(sdev, req->max_q_depth);\r\nreturn 0;\r\n}\r\nstatic void\r\nqla2xxx_slave_destroy(struct scsi_device *sdev)\r\n{\r\nsdev->hostdata = NULL;\r\n}\r\nstatic void\r\nqla2x00_config_dma_addressing(struct qla_hw_data *ha)\r\n{\r\nha->flags.enable_64bit_addressing = 0;\r\nif (!dma_set_mask(&ha->pdev->dev, DMA_BIT_MASK(64))) {\r\nif (MSD(dma_get_required_mask(&ha->pdev->dev)) &&\r\n!pci_set_consistent_dma_mask(ha->pdev, DMA_BIT_MASK(64))) {\r\nha->flags.enable_64bit_addressing = 1;\r\nha->isp_ops->calc_req_entries = qla2x00_calc_iocbs_64;\r\nha->isp_ops->build_iocbs = qla2x00_build_scsi_iocbs_64;\r\nreturn;\r\n}\r\n}\r\ndma_set_mask(&ha->pdev->dev, DMA_BIT_MASK(32));\r\npci_set_consistent_dma_mask(ha->pdev, DMA_BIT_MASK(32));\r\n}\r\nstatic void\r\nqla2x00_enable_intrs(struct qla_hw_data *ha)\r\n{\r\nunsigned long flags = 0;\r\nstruct device_reg_2xxx __iomem *reg = &ha->iobase->isp;\r\nspin_lock_irqsave(&ha->hardware_lock, flags);\r\nha->interrupts_on = 1;\r\nWRT_REG_WORD(&reg->ictrl, ICR_EN_INT | ICR_EN_RISC);\r\nRD_REG_WORD(&reg->ictrl);\r\nspin_unlock_irqrestore(&ha->hardware_lock, flags);\r\n}\r\nstatic void\r\nqla2x00_disable_intrs(struct qla_hw_data *ha)\r\n{\r\nunsigned long flags = 0;\r\nstruct device_reg_2xxx __iomem *reg = &ha->iobase->isp;\r\nspin_lock_irqsave(&ha->hardware_lock, flags);\r\nha->interrupts_on = 0;\r\nWRT_REG_WORD(&reg->ictrl, 0);\r\nRD_REG_WORD(&reg->ictrl);\r\nspin_unlock_irqrestore(&ha->hardware_lock, flags);\r\n}\r\nstatic void\r\nqla24xx_enable_intrs(struct qla_hw_data *ha)\r\n{\r\nunsigned long flags = 0;\r\nstruct device_reg_24xx __iomem *reg = &ha->iobase->isp24;\r\nspin_lock_irqsave(&ha->hardware_lock, flags);\r\nha->interrupts_on = 1;\r\nWRT_REG_DWORD(&reg->ictrl, ICRX_EN_RISC_INT);\r\nRD_REG_DWORD(&reg->ictrl);\r\nspin_unlock_irqrestore(&ha->hardware_lock, flags);\r\n}\r\nstatic void\r\nqla24xx_disable_intrs(struct qla_hw_data *ha)\r\n{\r\nunsigned long flags = 0;\r\nstruct device_reg_24xx __iomem *reg = &ha->iobase->isp24;\r\nif (IS_NOPOLLING_TYPE(ha))\r\nreturn;\r\nspin_lock_irqsave(&ha->hardware_lock, flags);\r\nha->interrupts_on = 0;\r\nWRT_REG_DWORD(&reg->ictrl, 0);\r\nRD_REG_DWORD(&reg->ictrl);\r\nspin_unlock_irqrestore(&ha->hardware_lock, flags);\r\n}\r\nstatic int\r\nqla2x00_iospace_config(struct qla_hw_data *ha)\r\n{\r\nresource_size_t pio;\r\nuint16_t msix;\r\nint cpus;\r\nif (pci_request_selected_regions(ha->pdev, ha->bars,\r\nQLA2XXX_DRIVER_NAME)) {\r\nql_log_pci(ql_log_fatal, ha->pdev, 0x0011,\r\n"Failed to reserve PIO/MMIO regions (%s), aborting.\n",\r\npci_name(ha->pdev));\r\ngoto iospace_error_exit;\r\n}\r\nif (!(ha->bars & 1))\r\ngoto skip_pio;\r\npio = pci_resource_start(ha->pdev, 0);\r\nif (pci_resource_flags(ha->pdev, 0) & IORESOURCE_IO) {\r\nif (pci_resource_len(ha->pdev, 0) < MIN_IOBASE_LEN) {\r\nql_log_pci(ql_log_warn, ha->pdev, 0x0012,\r\n"Invalid pci I/O region size (%s).\n",\r\npci_name(ha->pdev));\r\npio = 0;\r\n}\r\n} else {\r\nql_log_pci(ql_log_warn, ha->pdev, 0x0013,\r\n"Region #0 no a PIO resource (%s).\n",\r\npci_name(ha->pdev));\r\npio = 0;\r\n}\r\nha->pio_address = pio;\r\nql_dbg_pci(ql_dbg_init, ha->pdev, 0x0014,\r\n"PIO address=%llu.\n",\r\n(unsigned long long)ha->pio_address);\r\nskip_pio:\r\nif (!(pci_resource_flags(ha->pdev, 1) & IORESOURCE_MEM)) {\r\nql_log_pci(ql_log_fatal, ha->pdev, 0x0015,\r\n"Region #1 not an MMIO resource (%s), aborting.\n",\r\npci_name(ha->pdev));\r\ngoto iospace_error_exit;\r\n}\r\nif (pci_resource_len(ha->pdev, 1) < MIN_IOBASE_LEN) {\r\nql_log_pci(ql_log_fatal, ha->pdev, 0x0016,\r\n"Invalid PCI mem region size (%s), aborting.\n",\r\npci_name(ha->pdev));\r\ngoto iospace_error_exit;\r\n}\r\nha->iobase = ioremap(pci_resource_start(ha->pdev, 1), MIN_IOBASE_LEN);\r\nif (!ha->iobase) {\r\nql_log_pci(ql_log_fatal, ha->pdev, 0x0017,\r\n"Cannot remap MMIO (%s), aborting.\n",\r\npci_name(ha->pdev));\r\ngoto iospace_error_exit;\r\n}\r\nha->max_req_queues = ha->max_rsp_queues = 1;\r\nif ((ql2xmaxqueues <= 1 && !ql2xmultique_tag) ||\r\n(ql2xmaxqueues > 1 && ql2xmultique_tag) ||\r\n(!IS_QLA25XX(ha) && !IS_QLA81XX(ha)))\r\ngoto mqiobase_exit;\r\nha->mqiobase = ioremap(pci_resource_start(ha->pdev, 3),\r\npci_resource_len(ha->pdev, 3));\r\nif (ha->mqiobase) {\r\nql_dbg_pci(ql_dbg_init, ha->pdev, 0x0018,\r\n"MQIO Base=%p.\n", ha->mqiobase);\r\npci_read_config_word(ha->pdev, QLA_PCI_MSIX_CONTROL, &msix);\r\nha->msix_count = msix;\r\nif (ql2xmultique_tag) {\r\ncpus = num_online_cpus();\r\nha->max_rsp_queues = (ha->msix_count - 1 > cpus) ?\r\n(cpus + 1) : (ha->msix_count - 1);\r\nha->max_req_queues = 2;\r\n} else if (ql2xmaxqueues > 1) {\r\nha->max_req_queues = ql2xmaxqueues > QLA_MQ_SIZE ?\r\nQLA_MQ_SIZE : ql2xmaxqueues;\r\nql_dbg_pci(ql_dbg_multiq, ha->pdev, 0xc008,\r\n"QoS mode set, max no of request queues:%d.\n",\r\nha->max_req_queues);\r\nql_dbg_pci(ql_dbg_init, ha->pdev, 0x0019,\r\n"QoS mode set, max no of request queues:%d.\n",\r\nha->max_req_queues);\r\n}\r\nql_log_pci(ql_log_info, ha->pdev, 0x001a,\r\n"MSI-X vector count: %d.\n", msix);\r\n} else\r\nql_log_pci(ql_log_info, ha->pdev, 0x001b,\r\n"BAR 3 not enabled.\n");\r\nmqiobase_exit:\r\nha->msix_count = ha->max_rsp_queues + 1;\r\nql_dbg_pci(ql_dbg_init, ha->pdev, 0x001c,\r\n"MSIX Count:%d.\n", ha->msix_count);\r\nreturn (0);\r\niospace_error_exit:\r\nreturn (-ENOMEM);\r\n}\r\nstatic int\r\nqla83xx_iospace_config(struct qla_hw_data *ha)\r\n{\r\nuint16_t msix;\r\nint cpus;\r\nif (pci_request_selected_regions(ha->pdev, ha->bars,\r\nQLA2XXX_DRIVER_NAME)) {\r\nql_log_pci(ql_log_fatal, ha->pdev, 0x0117,\r\n"Failed to reserve PIO/MMIO regions (%s), aborting.\n",\r\npci_name(ha->pdev));\r\ngoto iospace_error_exit;\r\n}\r\nif (!(pci_resource_flags(ha->pdev, 0) & IORESOURCE_MEM)) {\r\nql_log_pci(ql_log_warn, ha->pdev, 0x0118,\r\n"Invalid pci I/O region size (%s).\n",\r\npci_name(ha->pdev));\r\ngoto iospace_error_exit;\r\n}\r\nif (pci_resource_len(ha->pdev, 0) < MIN_IOBASE_LEN) {\r\nql_log_pci(ql_log_warn, ha->pdev, 0x0119,\r\n"Invalid PCI mem region size (%s), aborting\n",\r\npci_name(ha->pdev));\r\ngoto iospace_error_exit;\r\n}\r\nha->iobase = ioremap(pci_resource_start(ha->pdev, 0), MIN_IOBASE_LEN);\r\nif (!ha->iobase) {\r\nql_log_pci(ql_log_fatal, ha->pdev, 0x011a,\r\n"Cannot remap MMIO (%s), aborting.\n",\r\npci_name(ha->pdev));\r\ngoto iospace_error_exit;\r\n}\r\nha->max_req_queues = ha->max_rsp_queues = 1;\r\nha->mqiobase = ioremap(pci_resource_start(ha->pdev, 4),\r\npci_resource_len(ha->pdev, 4));\r\nif (!ha->mqiobase) {\r\nql_log_pci(ql_log_fatal, ha->pdev, 0x011d,\r\n"BAR2/region4 not enabled\n");\r\ngoto mqiobase_exit;\r\n}\r\nha->msixbase = ioremap(pci_resource_start(ha->pdev, 2),\r\npci_resource_len(ha->pdev, 2));\r\nif (ha->msixbase) {\r\npci_read_config_word(ha->pdev,\r\nQLA_83XX_PCI_MSIX_CONTROL, &msix);\r\nha->msix_count = msix;\r\nif (ql2xmultique_tag) {\r\ncpus = num_online_cpus();\r\nha->max_rsp_queues = (ha->msix_count - 1 > cpus) ?\r\n(cpus + 1) : (ha->msix_count - 1);\r\nha->max_req_queues = 2;\r\n} else if (ql2xmaxqueues > 1) {\r\nha->max_req_queues = ql2xmaxqueues > QLA_MQ_SIZE ?\r\nQLA_MQ_SIZE : ql2xmaxqueues;\r\nql_dbg_pci(ql_dbg_multiq, ha->pdev, 0xc00c,\r\n"QoS mode set, max no of request queues:%d.\n",\r\nha->max_req_queues);\r\nql_dbg_pci(ql_dbg_init, ha->pdev, 0x011b,\r\n"QoS mode set, max no of request queues:%d.\n",\r\nha->max_req_queues);\r\n}\r\nql_log_pci(ql_log_info, ha->pdev, 0x011c,\r\n"MSI-X vector count: %d.\n", msix);\r\n} else\r\nql_log_pci(ql_log_info, ha->pdev, 0x011e,\r\n"BAR 1 not enabled.\n");\r\nmqiobase_exit:\r\nha->msix_count = ha->max_rsp_queues + 1;\r\nqlt_83xx_iospace_config(ha);\r\nql_dbg_pci(ql_dbg_init, ha->pdev, 0x011f,\r\n"MSIX Count:%d.\n", ha->msix_count);\r\nreturn 0;\r\niospace_error_exit:\r\nreturn -ENOMEM;\r\n}\r\nstatic inline void\r\nqla2x00_set_isp_flags(struct qla_hw_data *ha)\r\n{\r\nha->device_type = DT_EXTENDED_IDS;\r\nswitch (ha->pdev->device) {\r\ncase PCI_DEVICE_ID_QLOGIC_ISP2100:\r\nha->device_type |= DT_ISP2100;\r\nha->device_type &= ~DT_EXTENDED_IDS;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2100;\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISP2200:\r\nha->device_type |= DT_ISP2200;\r\nha->device_type &= ~DT_EXTENDED_IDS;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2100;\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISP2300:\r\nha->device_type |= DT_ISP2300;\r\nha->device_type |= DT_ZIO_SUPPORTED;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2300;\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISP2312:\r\nha->device_type |= DT_ISP2312;\r\nha->device_type |= DT_ZIO_SUPPORTED;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2300;\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISP2322:\r\nha->device_type |= DT_ISP2322;\r\nha->device_type |= DT_ZIO_SUPPORTED;\r\nif (ha->pdev->subsystem_vendor == 0x1028 &&\r\nha->pdev->subsystem_device == 0x0170)\r\nha->device_type |= DT_OEM_001;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2300;\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISP6312:\r\nha->device_type |= DT_ISP6312;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2300;\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISP6322:\r\nha->device_type |= DT_ISP6322;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2300;\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISP2422:\r\nha->device_type |= DT_ISP2422;\r\nha->device_type |= DT_ZIO_SUPPORTED;\r\nha->device_type |= DT_FWI2;\r\nha->device_type |= DT_IIDMA;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2400;\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISP2432:\r\nha->device_type |= DT_ISP2432;\r\nha->device_type |= DT_ZIO_SUPPORTED;\r\nha->device_type |= DT_FWI2;\r\nha->device_type |= DT_IIDMA;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2400;\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISP8432:\r\nha->device_type |= DT_ISP8432;\r\nha->device_type |= DT_ZIO_SUPPORTED;\r\nha->device_type |= DT_FWI2;\r\nha->device_type |= DT_IIDMA;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2400;\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISP5422:\r\nha->device_type |= DT_ISP5422;\r\nha->device_type |= DT_FWI2;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2400;\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISP5432:\r\nha->device_type |= DT_ISP5432;\r\nha->device_type |= DT_FWI2;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2400;\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISP2532:\r\nha->device_type |= DT_ISP2532;\r\nha->device_type |= DT_ZIO_SUPPORTED;\r\nha->device_type |= DT_FWI2;\r\nha->device_type |= DT_IIDMA;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2400;\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISP8001:\r\nha->device_type |= DT_ISP8001;\r\nha->device_type |= DT_ZIO_SUPPORTED;\r\nha->device_type |= DT_FWI2;\r\nha->device_type |= DT_IIDMA;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2400;\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISP8021:\r\nha->device_type |= DT_ISP8021;\r\nha->device_type |= DT_ZIO_SUPPORTED;\r\nha->device_type |= DT_FWI2;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2400;\r\nqla82xx_init_flags(ha);\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISP8044:\r\nha->device_type |= DT_ISP8044;\r\nha->device_type |= DT_ZIO_SUPPORTED;\r\nha->device_type |= DT_FWI2;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2400;\r\nqla82xx_init_flags(ha);\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISP2031:\r\nha->device_type |= DT_ISP2031;\r\nha->device_type |= DT_ZIO_SUPPORTED;\r\nha->device_type |= DT_FWI2;\r\nha->device_type |= DT_IIDMA;\r\nha->device_type |= DT_T10_PI;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2400;\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISP8031:\r\nha->device_type |= DT_ISP8031;\r\nha->device_type |= DT_ZIO_SUPPORTED;\r\nha->device_type |= DT_FWI2;\r\nha->device_type |= DT_IIDMA;\r\nha->device_type |= DT_T10_PI;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2400;\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISPF001:\r\nha->device_type |= DT_ISPFX00;\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISP2071:\r\nha->device_type |= DT_ISP2071;\r\nha->device_type |= DT_ZIO_SUPPORTED;\r\nha->device_type |= DT_FWI2;\r\nha->device_type |= DT_IIDMA;\r\nha->device_type |= DT_T10_PI;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2400;\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISP2271:\r\nha->device_type |= DT_ISP2271;\r\nha->device_type |= DT_ZIO_SUPPORTED;\r\nha->device_type |= DT_FWI2;\r\nha->device_type |= DT_IIDMA;\r\nha->device_type |= DT_T10_PI;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2400;\r\nbreak;\r\ncase PCI_DEVICE_ID_QLOGIC_ISP2261:\r\nha->device_type |= DT_ISP2261;\r\nha->device_type |= DT_ZIO_SUPPORTED;\r\nha->device_type |= DT_FWI2;\r\nha->device_type |= DT_IIDMA;\r\nha->device_type |= DT_T10_PI;\r\nha->fw_srisc_address = RISC_START_ADDRESS_2400;\r\nbreak;\r\n}\r\nif (IS_QLA82XX(ha))\r\nha->port_no = ha->portnum & 1;\r\nelse {\r\npci_read_config_byte(ha->pdev, PCI_INTERRUPT_PIN, &ha->port_no);\r\nif (IS_QLA27XX(ha))\r\nha->port_no--;\r\nelse\r\nha->port_no = !(ha->port_no & 1);\r\n}\r\nql_dbg_pci(ql_dbg_init, ha->pdev, 0x000b,\r\n"device_type=0x%x port=%d fw_srisc_address=0x%x.\n",\r\nha->device_type, ha->port_no, ha->fw_srisc_address);\r\n}\r\nstatic void\r\nqla2xxx_scan_start(struct Scsi_Host *shost)\r\n{\r\nscsi_qla_host_t *vha = shost_priv(shost);\r\nif (vha->hw->flags.running_gold_fw)\r\nreturn;\r\nset_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags);\r\nset_bit(LOCAL_LOOP_UPDATE, &vha->dpc_flags);\r\nset_bit(RSCN_UPDATE, &vha->dpc_flags);\r\nset_bit(NPIV_CONFIG_NEEDED, &vha->dpc_flags);\r\n}\r\nstatic int\r\nqla2xxx_scan_finished(struct Scsi_Host *shost, unsigned long time)\r\n{\r\nscsi_qla_host_t *vha = shost_priv(shost);\r\nif (!vha->host)\r\nreturn 1;\r\nif (time > vha->hw->loop_reset_delay * HZ)\r\nreturn 1;\r\nreturn atomic_read(&vha->loop_state) == LOOP_READY;\r\n}\r\nstatic int\r\nqla2x00_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)\r\n{\r\nint ret = -ENODEV;\r\nstruct Scsi_Host *host;\r\nscsi_qla_host_t *base_vha = NULL;\r\nstruct qla_hw_data *ha;\r\nchar pci_info[30];\r\nchar fw_str[30], wq_name[30];\r\nstruct scsi_host_template *sht;\r\nint bars, mem_only = 0;\r\nuint16_t req_length = 0, rsp_length = 0;\r\nstruct req_que *req = NULL;\r\nstruct rsp_que *rsp = NULL;\r\nbars = pci_select_bars(pdev, IORESOURCE_MEM | IORESOURCE_IO);\r\nsht = &qla2xxx_driver_template;\r\nif (pdev->device == PCI_DEVICE_ID_QLOGIC_ISP2422 ||\r\npdev->device == PCI_DEVICE_ID_QLOGIC_ISP2432 ||\r\npdev->device == PCI_DEVICE_ID_QLOGIC_ISP8432 ||\r\npdev->device == PCI_DEVICE_ID_QLOGIC_ISP5422 ||\r\npdev->device == PCI_DEVICE_ID_QLOGIC_ISP5432 ||\r\npdev->device == PCI_DEVICE_ID_QLOGIC_ISP2532 ||\r\npdev->device == PCI_DEVICE_ID_QLOGIC_ISP8001 ||\r\npdev->device == PCI_DEVICE_ID_QLOGIC_ISP8021 ||\r\npdev->device == PCI_DEVICE_ID_QLOGIC_ISP2031 ||\r\npdev->device == PCI_DEVICE_ID_QLOGIC_ISP8031 ||\r\npdev->device == PCI_DEVICE_ID_QLOGIC_ISPF001 ||\r\npdev->device == PCI_DEVICE_ID_QLOGIC_ISP8044 ||\r\npdev->device == PCI_DEVICE_ID_QLOGIC_ISP2071 ||\r\npdev->device == PCI_DEVICE_ID_QLOGIC_ISP2271 ||\r\npdev->device == PCI_DEVICE_ID_QLOGIC_ISP2261) {\r\nbars = pci_select_bars(pdev, IORESOURCE_MEM);\r\nmem_only = 1;\r\nql_dbg_pci(ql_dbg_init, pdev, 0x0007,\r\n"Mem only adapter.\n");\r\n}\r\nql_dbg_pci(ql_dbg_init, pdev, 0x0008,\r\n"Bars=%d.\n", bars);\r\nif (mem_only) {\r\nif (pci_enable_device_mem(pdev))\r\ngoto probe_out;\r\n} else {\r\nif (pci_enable_device(pdev))\r\ngoto probe_out;\r\n}\r\npci_enable_pcie_error_reporting(pdev);\r\nha = kzalloc(sizeof(struct qla_hw_data), GFP_KERNEL);\r\nif (!ha) {\r\nql_log_pci(ql_log_fatal, pdev, 0x0009,\r\n"Unable to allocate memory for ha.\n");\r\ngoto probe_out;\r\n}\r\nql_dbg_pci(ql_dbg_init, pdev, 0x000a,\r\n"Memory allocated for ha=%p.\n", ha);\r\nha->pdev = pdev;\r\nha->tgt.enable_class_2 = ql2xenableclass2;\r\nINIT_LIST_HEAD(&ha->tgt.q_full_list);\r\nspin_lock_init(&ha->tgt.q_full_lock);\r\nspin_lock_init(&ha->tgt.sess_lock);\r\nspin_lock_init(&ha->tgt.atio_lock);\r\nha->bars = bars;\r\nha->mem_only = mem_only;\r\nspin_lock_init(&ha->hardware_lock);\r\nspin_lock_init(&ha->vport_slock);\r\nmutex_init(&ha->selflogin_lock);\r\nmutex_init(&ha->optrom_mutex);\r\nqla2x00_set_isp_flags(ha);\r\nif (IS_QLA24XX(ha) || IS_QLA25XX(ha) || IS_QLA81XX(ha) ||\r\nIS_QLA83XX(ha) || IS_QLA27XX(ha))\r\npdev->needs_freset = 1;\r\nha->prev_topology = 0;\r\nha->init_cb_size = sizeof(init_cb_t);\r\nha->link_data_rate = PORT_SPEED_UNKNOWN;\r\nha->optrom_size = OPTROM_SIZE_2300;\r\nif (IS_QLA2100(ha)) {\r\nha->max_fibre_devices = MAX_FIBRE_DEVICES_2100;\r\nha->mbx_count = MAILBOX_REGISTER_COUNT_2100;\r\nreq_length = REQUEST_ENTRY_CNT_2100;\r\nrsp_length = RESPONSE_ENTRY_CNT_2100;\r\nha->max_loop_id = SNS_LAST_LOOP_ID_2100;\r\nha->gid_list_info_size = 4;\r\nha->flash_conf_off = ~0;\r\nha->flash_data_off = ~0;\r\nha->nvram_conf_off = ~0;\r\nha->nvram_data_off = ~0;\r\nha->isp_ops = &qla2100_isp_ops;\r\n} else if (IS_QLA2200(ha)) {\r\nha->max_fibre_devices = MAX_FIBRE_DEVICES_2100;\r\nha->mbx_count = MAILBOX_REGISTER_COUNT_2200;\r\nreq_length = REQUEST_ENTRY_CNT_2200;\r\nrsp_length = RESPONSE_ENTRY_CNT_2100;\r\nha->max_loop_id = SNS_LAST_LOOP_ID_2100;\r\nha->gid_list_info_size = 4;\r\nha->flash_conf_off = ~0;\r\nha->flash_data_off = ~0;\r\nha->nvram_conf_off = ~0;\r\nha->nvram_data_off = ~0;\r\nha->isp_ops = &qla2100_isp_ops;\r\n} else if (IS_QLA23XX(ha)) {\r\nha->max_fibre_devices = MAX_FIBRE_DEVICES_2100;\r\nha->mbx_count = MAILBOX_REGISTER_COUNT;\r\nreq_length = REQUEST_ENTRY_CNT_2200;\r\nrsp_length = RESPONSE_ENTRY_CNT_2300;\r\nha->max_loop_id = SNS_LAST_LOOP_ID_2300;\r\nha->gid_list_info_size = 6;\r\nif (IS_QLA2322(ha) || IS_QLA6322(ha))\r\nha->optrom_size = OPTROM_SIZE_2322;\r\nha->flash_conf_off = ~0;\r\nha->flash_data_off = ~0;\r\nha->nvram_conf_off = ~0;\r\nha->nvram_data_off = ~0;\r\nha->isp_ops = &qla2300_isp_ops;\r\n} else if (IS_QLA24XX_TYPE(ha)) {\r\nha->max_fibre_devices = MAX_FIBRE_DEVICES_2400;\r\nha->mbx_count = MAILBOX_REGISTER_COUNT;\r\nreq_length = REQUEST_ENTRY_CNT_24XX;\r\nrsp_length = RESPONSE_ENTRY_CNT_2300;\r\nha->tgt.atio_q_length = ATIO_ENTRY_CNT_24XX;\r\nha->max_loop_id = SNS_LAST_LOOP_ID_2300;\r\nha->init_cb_size = sizeof(struct mid_init_cb_24xx);\r\nha->gid_list_info_size = 8;\r\nha->optrom_size = OPTROM_SIZE_24XX;\r\nha->nvram_npiv_size = QLA_MAX_VPORTS_QLA24XX;\r\nha->isp_ops = &qla24xx_isp_ops;\r\nha->flash_conf_off = FARX_ACCESS_FLASH_CONF;\r\nha->flash_data_off = FARX_ACCESS_FLASH_DATA;\r\nha->nvram_conf_off = FARX_ACCESS_NVRAM_CONF;\r\nha->nvram_data_off = FARX_ACCESS_NVRAM_DATA;\r\n} else if (IS_QLA25XX(ha)) {\r\nha->max_fibre_devices = MAX_FIBRE_DEVICES_2400;\r\nha->mbx_count = MAILBOX_REGISTER_COUNT;\r\nreq_length = REQUEST_ENTRY_CNT_24XX;\r\nrsp_length = RESPONSE_ENTRY_CNT_2300;\r\nha->tgt.atio_q_length = ATIO_ENTRY_CNT_24XX;\r\nha->max_loop_id = SNS_LAST_LOOP_ID_2300;\r\nha->init_cb_size = sizeof(struct mid_init_cb_24xx);\r\nha->gid_list_info_size = 8;\r\nha->optrom_size = OPTROM_SIZE_25XX;\r\nha->nvram_npiv_size = QLA_MAX_VPORTS_QLA25XX;\r\nha->isp_ops = &qla25xx_isp_ops;\r\nha->flash_conf_off = FARX_ACCESS_FLASH_CONF;\r\nha->flash_data_off = FARX_ACCESS_FLASH_DATA;\r\nha->nvram_conf_off = FARX_ACCESS_NVRAM_CONF;\r\nha->nvram_data_off = FARX_ACCESS_NVRAM_DATA;\r\n} else if (IS_QLA81XX(ha)) {\r\nha->max_fibre_devices = MAX_FIBRE_DEVICES_2400;\r\nha->mbx_count = MAILBOX_REGISTER_COUNT;\r\nreq_length = REQUEST_ENTRY_CNT_24XX;\r\nrsp_length = RESPONSE_ENTRY_CNT_2300;\r\nha->tgt.atio_q_length = ATIO_ENTRY_CNT_24XX;\r\nha->max_loop_id = SNS_LAST_LOOP_ID_2300;\r\nha->init_cb_size = sizeof(struct mid_init_cb_81xx);\r\nha->gid_list_info_size = 8;\r\nha->optrom_size = OPTROM_SIZE_81XX;\r\nha->nvram_npiv_size = QLA_MAX_VPORTS_QLA25XX;\r\nha->isp_ops = &qla81xx_isp_ops;\r\nha->flash_conf_off = FARX_ACCESS_FLASH_CONF_81XX;\r\nha->flash_data_off = FARX_ACCESS_FLASH_DATA_81XX;\r\nha->nvram_conf_off = ~0;\r\nha->nvram_data_off = ~0;\r\n} else if (IS_QLA82XX(ha)) {\r\nha->max_fibre_devices = MAX_FIBRE_DEVICES_2400;\r\nha->mbx_count = MAILBOX_REGISTER_COUNT;\r\nreq_length = REQUEST_ENTRY_CNT_82XX;\r\nrsp_length = RESPONSE_ENTRY_CNT_82XX;\r\nha->max_loop_id = SNS_LAST_LOOP_ID_2300;\r\nha->init_cb_size = sizeof(struct mid_init_cb_81xx);\r\nha->gid_list_info_size = 8;\r\nha->optrom_size = OPTROM_SIZE_82XX;\r\nha->nvram_npiv_size = QLA_MAX_VPORTS_QLA25XX;\r\nha->isp_ops = &qla82xx_isp_ops;\r\nha->flash_conf_off = FARX_ACCESS_FLASH_CONF;\r\nha->flash_data_off = FARX_ACCESS_FLASH_DATA;\r\nha->nvram_conf_off = FARX_ACCESS_NVRAM_CONF;\r\nha->nvram_data_off = FARX_ACCESS_NVRAM_DATA;\r\n} else if (IS_QLA8044(ha)) {\r\nha->max_fibre_devices = MAX_FIBRE_DEVICES_2400;\r\nha->mbx_count = MAILBOX_REGISTER_COUNT;\r\nreq_length = REQUEST_ENTRY_CNT_82XX;\r\nrsp_length = RESPONSE_ENTRY_CNT_82XX;\r\nha->max_loop_id = SNS_LAST_LOOP_ID_2300;\r\nha->init_cb_size = sizeof(struct mid_init_cb_81xx);\r\nha->gid_list_info_size = 8;\r\nha->optrom_size = OPTROM_SIZE_83XX;\r\nha->nvram_npiv_size = QLA_MAX_VPORTS_QLA25XX;\r\nha->isp_ops = &qla8044_isp_ops;\r\nha->flash_conf_off = FARX_ACCESS_FLASH_CONF;\r\nha->flash_data_off = FARX_ACCESS_FLASH_DATA;\r\nha->nvram_conf_off = FARX_ACCESS_NVRAM_CONF;\r\nha->nvram_data_off = FARX_ACCESS_NVRAM_DATA;\r\n} else if (IS_QLA83XX(ha)) {\r\nha->portnum = PCI_FUNC(ha->pdev->devfn);\r\nha->max_fibre_devices = MAX_FIBRE_DEVICES_2400;\r\nha->mbx_count = MAILBOX_REGISTER_COUNT;\r\nreq_length = REQUEST_ENTRY_CNT_83XX;\r\nrsp_length = RESPONSE_ENTRY_CNT_83XX;\r\nha->tgt.atio_q_length = ATIO_ENTRY_CNT_24XX;\r\nha->max_loop_id = SNS_LAST_LOOP_ID_2300;\r\nha->init_cb_size = sizeof(struct mid_init_cb_81xx);\r\nha->gid_list_info_size = 8;\r\nha->optrom_size = OPTROM_SIZE_83XX;\r\nha->nvram_npiv_size = QLA_MAX_VPORTS_QLA25XX;\r\nha->isp_ops = &qla83xx_isp_ops;\r\nha->flash_conf_off = FARX_ACCESS_FLASH_CONF_81XX;\r\nha->flash_data_off = FARX_ACCESS_FLASH_DATA_81XX;\r\nha->nvram_conf_off = ~0;\r\nha->nvram_data_off = ~0;\r\n} else if (IS_QLAFX00(ha)) {\r\nha->max_fibre_devices = MAX_FIBRE_DEVICES_FX00;\r\nha->mbx_count = MAILBOX_REGISTER_COUNT_FX00;\r\nha->aen_mbx_count = AEN_MAILBOX_REGISTER_COUNT_FX00;\r\nreq_length = REQUEST_ENTRY_CNT_FX00;\r\nrsp_length = RESPONSE_ENTRY_CNT_FX00;\r\nha->isp_ops = &qlafx00_isp_ops;\r\nha->port_down_retry_count = 30;\r\nha->mr.fw_hbt_cnt = QLAFX00_HEARTBEAT_INTERVAL;\r\nha->mr.fw_reset_timer_tick = QLAFX00_RESET_INTERVAL;\r\nha->mr.fw_critemp_timer_tick = QLAFX00_CRITEMP_INTERVAL;\r\nha->mr.fw_hbt_en = 1;\r\nha->mr.host_info_resend = false;\r\nha->mr.hinfo_resend_timer_tick = QLAFX00_HINFO_RESEND_INTERVAL;\r\n} else if (IS_QLA27XX(ha)) {\r\nha->portnum = PCI_FUNC(ha->pdev->devfn);\r\nha->max_fibre_devices = MAX_FIBRE_DEVICES_2400;\r\nha->mbx_count = MAILBOX_REGISTER_COUNT;\r\nreq_length = REQUEST_ENTRY_CNT_83XX;\r\nrsp_length = RESPONSE_ENTRY_CNT_83XX;\r\nha->tgt.atio_q_length = ATIO_ENTRY_CNT_24XX;\r\nha->max_loop_id = SNS_LAST_LOOP_ID_2300;\r\nha->init_cb_size = sizeof(struct mid_init_cb_81xx);\r\nha->gid_list_info_size = 8;\r\nha->optrom_size = OPTROM_SIZE_83XX;\r\nha->nvram_npiv_size = QLA_MAX_VPORTS_QLA25XX;\r\nha->isp_ops = &qla27xx_isp_ops;\r\nha->flash_conf_off = FARX_ACCESS_FLASH_CONF_81XX;\r\nha->flash_data_off = FARX_ACCESS_FLASH_DATA_81XX;\r\nha->nvram_conf_off = ~0;\r\nha->nvram_data_off = ~0;\r\n}\r\nql_dbg_pci(ql_dbg_init, pdev, 0x001e,\r\n"mbx_count=%d, req_length=%d, "\r\n"rsp_length=%d, max_loop_id=%d, init_cb_size=%d, "\r\n"gid_list_info_size=%d, optrom_size=%d, nvram_npiv_size=%d, "\r\n"max_fibre_devices=%d.\n",\r\nha->mbx_count, req_length, rsp_length, ha->max_loop_id,\r\nha->init_cb_size, ha->gid_list_info_size, ha->optrom_size,\r\nha->nvram_npiv_size, ha->max_fibre_devices);\r\nql_dbg_pci(ql_dbg_init, pdev, 0x001f,\r\n"isp_ops=%p, flash_conf_off=%d, "\r\n"flash_data_off=%d, nvram_conf_off=%d, nvram_data_off=%d.\n",\r\nha->isp_ops, ha->flash_conf_off, ha->flash_data_off,\r\nha->nvram_conf_off, ha->nvram_data_off);\r\nret = ha->isp_ops->iospace_config(ha);\r\nif (ret)\r\ngoto iospace_config_failed;\r\nql_log_pci(ql_log_info, pdev, 0x001d,\r\n"Found an ISP%04X irq %d iobase 0x%p.\n",\r\npdev->device, pdev->irq, ha->iobase);\r\nmutex_init(&ha->vport_lock);\r\ninit_completion(&ha->mbx_cmd_comp);\r\ncomplete(&ha->mbx_cmd_comp);\r\ninit_completion(&ha->mbx_intr_comp);\r\ninit_completion(&ha->dcbx_comp);\r\ninit_completion(&ha->lb_portup_comp);\r\nset_bit(0, (unsigned long *) ha->vp_idx_map);\r\nqla2x00_config_dma_addressing(ha);\r\nql_dbg_pci(ql_dbg_init, pdev, 0x0020,\r\n"64 Bit addressing is %s.\n",\r\nha->flags.enable_64bit_addressing ? "enable" :\r\n"disable");\r\nret = qla2x00_mem_alloc(ha, req_length, rsp_length, &req, &rsp);\r\nif (ret) {\r\nql_log_pci(ql_log_fatal, pdev, 0x0031,\r\n"Failed to allocate memory for adapter, aborting.\n");\r\ngoto probe_hw_failed;\r\n}\r\nreq->max_q_depth = MAX_Q_DEPTH;\r\nif (ql2xmaxqdepth != 0 && ql2xmaxqdepth <= 0xffffU)\r\nreq->max_q_depth = ql2xmaxqdepth;\r\nbase_vha = qla2x00_create_host(sht, ha);\r\nif (!base_vha) {\r\nret = -ENOMEM;\r\nqla2x00_mem_free(ha);\r\nqla2x00_free_req_que(ha, req);\r\nqla2x00_free_rsp_que(ha, rsp);\r\ngoto probe_hw_failed;\r\n}\r\npci_set_drvdata(pdev, base_vha);\r\nset_bit(PFLG_DRIVER_PROBING, &base_vha->pci_flags);\r\nhost = base_vha->host;\r\nbase_vha->req = req;\r\nif (IS_QLA2XXX_MIDTYPE(ha))\r\nbase_vha->mgmt_svr_loop_id = 10 + base_vha->vp_idx;\r\nelse\r\nbase_vha->mgmt_svr_loop_id = MANAGEMENT_SERVER +\r\nbase_vha->vp_idx;\r\nha->mr.fcport.vha = base_vha;\r\nha->mr.fcport.port_type = FCT_UNKNOWN;\r\nha->mr.fcport.loop_id = FC_NO_LOOP_ID;\r\nqla2x00_set_fcport_state(&ha->mr.fcport, FCS_UNCONFIGURED);\r\nha->mr.fcport.supported_classes = FC_COS_UNSPECIFIED;\r\nha->mr.fcport.scan_state = 1;\r\nif (!IS_FWI2_CAPABLE(ha)) {\r\nif (IS_QLA2100(ha))\r\nhost->sg_tablesize = 32;\r\n} else {\r\nif (!IS_QLA82XX(ha))\r\nhost->sg_tablesize = QLA_SG_ALL;\r\n}\r\nhost->max_id = ha->max_fibre_devices;\r\nhost->cmd_per_lun = 3;\r\nhost->unique_id = host->host_no;\r\nif (IS_T10_PI_CAPABLE(ha) && ql2xenabledif)\r\nhost->max_cmd_len = 32;\r\nelse\r\nhost->max_cmd_len = MAX_CMDSZ;\r\nhost->max_channel = MAX_BUSES - 1;\r\nif (!IS_QLAFX00(ha) && !IS_FWI2_CAPABLE(ha) &&\r\nql2xmaxlun > 0xffff)\r\nhost->max_lun = 0xffff;\r\nelse\r\nhost->max_lun = ql2xmaxlun;\r\nhost->transportt = qla2xxx_transport_template;\r\nsht->vendor_id = (SCSI_NL_VID_TYPE_PCI | PCI_VENDOR_ID_QLOGIC);\r\nql_dbg(ql_dbg_init, base_vha, 0x0033,\r\n"max_id=%d this_id=%d "\r\n"cmd_per_len=%d unique_id=%d max_cmd_len=%d max_channel=%d "\r\n"max_lun=%llu transportt=%p, vendor_id=%llu.\n", host->max_id,\r\nhost->this_id, host->cmd_per_lun, host->unique_id,\r\nhost->max_cmd_len, host->max_channel, host->max_lun,\r\nhost->transportt, sht->vendor_id);\r\nque_init:\r\nif (!qla2x00_alloc_queues(ha, req, rsp)) {\r\nql_log(ql_log_fatal, base_vha, 0x003d,\r\n"Failed to allocate memory for queue pointers..."\r\n"aborting.\n");\r\ngoto probe_init_failed;\r\n}\r\nqlt_probe_one_stage1(base_vha, ha);\r\nret = qla2x00_request_irqs(ha, rsp);\r\nif (ret)\r\ngoto probe_init_failed;\r\npci_save_state(pdev);\r\nrsp->req = req;\r\nreq->rsp = rsp;\r\nif (IS_QLAFX00(ha)) {\r\nha->rsp_q_map[0] = rsp;\r\nha->req_q_map[0] = req;\r\nset_bit(0, ha->req_qid_map);\r\nset_bit(0, ha->rsp_qid_map);\r\n}\r\nreq->req_q_in = &ha->iobase->isp24.req_q_in;\r\nreq->req_q_out = &ha->iobase->isp24.req_q_out;\r\nrsp->rsp_q_in = &ha->iobase->isp24.rsp_q_in;\r\nrsp->rsp_q_out = &ha->iobase->isp24.rsp_q_out;\r\nif (ha->mqenable || IS_QLA83XX(ha) || IS_QLA27XX(ha)) {\r\nreq->req_q_in = &ha->mqiobase->isp25mq.req_q_in;\r\nreq->req_q_out = &ha->mqiobase->isp25mq.req_q_out;\r\nrsp->rsp_q_in = &ha->mqiobase->isp25mq.rsp_q_in;\r\nrsp->rsp_q_out = &ha->mqiobase->isp25mq.rsp_q_out;\r\n}\r\nif (IS_QLAFX00(ha)) {\r\nreq->req_q_in = &ha->iobase->ispfx00.req_q_in;\r\nreq->req_q_out = &ha->iobase->ispfx00.req_q_out;\r\nrsp->rsp_q_in = &ha->iobase->ispfx00.rsp_q_in;\r\nrsp->rsp_q_out = &ha->iobase->ispfx00.rsp_q_out;\r\n}\r\nif (IS_P3P_TYPE(ha)) {\r\nreq->req_q_out = &ha->iobase->isp82.req_q_out[0];\r\nrsp->rsp_q_in = &ha->iobase->isp82.rsp_q_in[0];\r\nrsp->rsp_q_out = &ha->iobase->isp82.rsp_q_out[0];\r\n}\r\nql_dbg(ql_dbg_multiq, base_vha, 0xc009,\r\n"rsp_q_map=%p req_q_map=%p rsp->req=%p req->rsp=%p.\n",\r\nha->rsp_q_map, ha->req_q_map, rsp->req, req->rsp);\r\nql_dbg(ql_dbg_multiq, base_vha, 0xc00a,\r\n"req->req_q_in=%p req->req_q_out=%p "\r\n"rsp->rsp_q_in=%p rsp->rsp_q_out=%p.\n",\r\nreq->req_q_in, req->req_q_out,\r\nrsp->rsp_q_in, rsp->rsp_q_out);\r\nql_dbg(ql_dbg_init, base_vha, 0x003e,\r\n"rsp_q_map=%p req_q_map=%p rsp->req=%p req->rsp=%p.\n",\r\nha->rsp_q_map, ha->req_q_map, rsp->req, req->rsp);\r\nql_dbg(ql_dbg_init, base_vha, 0x003f,\r\n"req->req_q_in=%p req->req_q_out=%p rsp->rsp_q_in=%p rsp->rsp_q_out=%p.\n",\r\nreq->req_q_in, req->req_q_out, rsp->rsp_q_in, rsp->rsp_q_out);\r\nif (ha->isp_ops->initialize_adapter(base_vha)) {\r\nql_log(ql_log_fatal, base_vha, 0x00d6,\r\n"Failed to initialize adapter - Adapter flags %x.\n",\r\nbase_vha->device_flags);\r\nif (IS_QLA82XX(ha)) {\r\nqla82xx_idc_lock(ha);\r\nqla82xx_wr_32(ha, QLA82XX_CRB_DEV_STATE,\r\nQLA8XXX_DEV_FAILED);\r\nqla82xx_idc_unlock(ha);\r\nql_log(ql_log_fatal, base_vha, 0x00d7,\r\n"HW State: FAILED.\n");\r\n} else if (IS_QLA8044(ha)) {\r\nqla8044_idc_lock(ha);\r\nqla8044_wr_direct(base_vha,\r\nQLA8044_CRB_DEV_STATE_INDEX,\r\nQLA8XXX_DEV_FAILED);\r\nqla8044_idc_unlock(ha);\r\nql_log(ql_log_fatal, base_vha, 0x0150,\r\n"HW State: FAILED.\n");\r\n}\r\nret = -ENODEV;\r\ngoto probe_failed;\r\n}\r\nif (IS_QLAFX00(ha))\r\nhost->can_queue = QLAFX00_MAX_CANQUEUE;\r\nelse\r\nhost->can_queue = req->num_outstanding_cmds - 10;\r\nql_dbg(ql_dbg_init, base_vha, 0x0032,\r\n"can_queue=%d, req=%p, mgmt_svr_loop_id=%d, sg_tablesize=%d.\n",\r\nhost->can_queue, base_vha->req,\r\nbase_vha->mgmt_svr_loop_id, host->sg_tablesize);\r\nif (ha->mqenable) {\r\nif (qla25xx_setup_mode(base_vha)) {\r\nql_log(ql_log_warn, base_vha, 0x00ec,\r\n"Failed to create queues, falling back to single queue mode.\n");\r\ngoto que_init;\r\n}\r\n}\r\nif (ha->flags.running_gold_fw)\r\ngoto skip_dpc;\r\nha->dpc_thread = kthread_create(qla2x00_do_dpc, ha,\r\n"%s_dpc", base_vha->host_str);\r\nif (IS_ERR(ha->dpc_thread)) {\r\nql_log(ql_log_fatal, base_vha, 0x00ed,\r\n"Failed to start DPC thread.\n");\r\nret = PTR_ERR(ha->dpc_thread);\r\ngoto probe_failed;\r\n}\r\nql_dbg(ql_dbg_init, base_vha, 0x00ee,\r\n"DPC thread started successfully.\n");\r\nqla2xxx_wake_dpc(base_vha);\r\nINIT_WORK(&ha->board_disable, qla2x00_disable_board_on_pci_error);\r\nif (IS_QLA8031(ha) || IS_MCTP_CAPABLE(ha)) {\r\nsprintf(wq_name, "qla2xxx_%lu_dpc_lp_wq", base_vha->host_no);\r\nha->dpc_lp_wq = create_singlethread_workqueue(wq_name);\r\nINIT_WORK(&ha->idc_aen, qla83xx_service_idc_aen);\r\nsprintf(wq_name, "qla2xxx_%lu_dpc_hp_wq", base_vha->host_no);\r\nha->dpc_hp_wq = create_singlethread_workqueue(wq_name);\r\nINIT_WORK(&ha->nic_core_reset, qla83xx_nic_core_reset_work);\r\nINIT_WORK(&ha->idc_state_handler,\r\nqla83xx_idc_state_handler_work);\r\nINIT_WORK(&ha->nic_core_unrecoverable,\r\nqla83xx_nic_core_unrecoverable_work);\r\n}\r\nskip_dpc:\r\nlist_add_tail(&base_vha->list, &ha->vp_list);\r\nbase_vha->host->irq = ha->pdev->irq;\r\nqla2x00_start_timer(base_vha, qla2x00_timer, WATCH_INTERVAL);\r\nql_dbg(ql_dbg_init, base_vha, 0x00ef,\r\n"Started qla2x00_timer with "\r\n"interval=%d.\n", WATCH_INTERVAL);\r\nql_dbg(ql_dbg_init, base_vha, 0x00f0,\r\n"Detected hba at address=%p.\n",\r\nha);\r\nif (IS_T10_PI_CAPABLE(ha) && ql2xenabledif) {\r\nif (ha->fw_attributes & BIT_4) {\r\nint prot = 0, guard;\r\nbase_vha->flags.difdix_supported = 1;\r\nql_dbg(ql_dbg_init, base_vha, 0x00f1,\r\n"Registering for DIF/DIX type 1 and 3 protection.\n");\r\nif (ql2xenabledif == 1)\r\nprot = SHOST_DIX_TYPE0_PROTECTION;\r\nscsi_host_set_prot(host,\r\nprot | SHOST_DIF_TYPE1_PROTECTION\r\n| SHOST_DIF_TYPE2_PROTECTION\r\n| SHOST_DIF_TYPE3_PROTECTION\r\n| SHOST_DIX_TYPE1_PROTECTION\r\n| SHOST_DIX_TYPE2_PROTECTION\r\n| SHOST_DIX_TYPE3_PROTECTION);\r\nguard = SHOST_DIX_GUARD_CRC;\r\nif (IS_PI_IPGUARD_CAPABLE(ha) &&\r\n(ql2xenabledif > 1 || IS_PI_DIFB_DIX0_CAPABLE(ha)))\r\nguard |= SHOST_DIX_GUARD_IP;\r\nscsi_host_set_guard(host, guard);\r\n} else\r\nbase_vha->flags.difdix_supported = 0;\r\n}\r\nha->isp_ops->enable_intrs(ha);\r\nif (IS_QLAFX00(ha)) {\r\nret = qlafx00_fx_disc(base_vha,\r\n&base_vha->hw->mr.fcport, FXDISC_GET_CONFIG_INFO);\r\nhost->sg_tablesize = (ha->mr.extended_io_enabled) ?\r\nQLA_SG_ALL : 128;\r\n}\r\nret = scsi_add_host(host, &pdev->dev);\r\nif (ret)\r\ngoto probe_failed;\r\nbase_vha->flags.init_done = 1;\r\nbase_vha->flags.online = 1;\r\nha->prev_minidump_failed = 0;\r\nql_dbg(ql_dbg_init, base_vha, 0x00f2,\r\n"Init done and hba is online.\n");\r\nif (qla_ini_mode_enabled(base_vha))\r\nscsi_scan_host(host);\r\nelse\r\nql_dbg(ql_dbg_init, base_vha, 0x0122,\r\n"skipping scsi_scan_host() for non-initiator port\n");\r\nqla2x00_alloc_sysfs_attr(base_vha);\r\nif (IS_QLAFX00(ha)) {\r\nret = qlafx00_fx_disc(base_vha,\r\n&base_vha->hw->mr.fcport, FXDISC_GET_PORT_INFO);\r\nret = qlafx00_fx_disc(base_vha,\r\n&base_vha->hw->mr.fcport, FXDISC_REG_HOST_INFO);\r\n}\r\nqla2x00_init_host_attr(base_vha);\r\nqla2x00_dfs_setup(base_vha);\r\nql_log(ql_log_info, base_vha, 0x00fb,\r\n"QLogic %s - %s.\n", ha->model_number, ha->model_desc);\r\nql_log(ql_log_info, base_vha, 0x00fc,\r\n"ISP%04X: %s @ %s hdma%c host#=%ld fw=%s.\n",\r\npdev->device, ha->isp_ops->pci_info_str(base_vha, pci_info),\r\npci_name(pdev), ha->flags.enable_64bit_addressing ? '+' : '-',\r\nbase_vha->host_no,\r\nha->isp_ops->fw_version_str(base_vha, fw_str, sizeof(fw_str)));\r\nqlt_add_target(ha, base_vha);\r\nclear_bit(PFLG_DRIVER_PROBING, &base_vha->pci_flags);\r\nreturn 0;\r\nprobe_init_failed:\r\nqla2x00_free_req_que(ha, req);\r\nha->req_q_map[0] = NULL;\r\nclear_bit(0, ha->req_qid_map);\r\nqla2x00_free_rsp_que(ha, rsp);\r\nha->rsp_q_map[0] = NULL;\r\nclear_bit(0, ha->rsp_qid_map);\r\nha->max_req_queues = ha->max_rsp_queues = 0;\r\nprobe_failed:\r\nif (base_vha->timer_active)\r\nqla2x00_stop_timer(base_vha);\r\nbase_vha->flags.online = 0;\r\nif (ha->dpc_thread) {\r\nstruct task_struct *t = ha->dpc_thread;\r\nha->dpc_thread = NULL;\r\nkthread_stop(t);\r\n}\r\nqla2x00_free_device(base_vha);\r\nscsi_host_put(base_vha->host);\r\nprobe_hw_failed:\r\nqla2x00_clear_drv_active(ha);\r\niospace_config_failed:\r\nif (IS_P3P_TYPE(ha)) {\r\nif (!ha->nx_pcibase)\r\niounmap((device_reg_t *)ha->nx_pcibase);\r\nif (!ql2xdbwr)\r\niounmap((device_reg_t *)ha->nxdb_wr_ptr);\r\n} else {\r\nif (ha->iobase)\r\niounmap(ha->iobase);\r\nif (ha->cregbase)\r\niounmap(ha->cregbase);\r\n}\r\npci_release_selected_regions(ha->pdev, ha->bars);\r\nkfree(ha);\r\nha = NULL;\r\nprobe_out:\r\npci_disable_device(pdev);\r\nreturn ret;\r\n}\r\nstatic void\r\nqla2x00_shutdown(struct pci_dev *pdev)\r\n{\r\nscsi_qla_host_t *vha;\r\nstruct qla_hw_data *ha;\r\nif (!atomic_read(&pdev->enable_cnt))\r\nreturn;\r\nvha = pci_get_drvdata(pdev);\r\nha = vha->hw;\r\nif (IS_QLAFX00(ha))\r\nqlafx00_driver_shutdown(vha, 20);\r\nif (ha->flags.fce_enabled) {\r\nqla2x00_disable_fce_trace(vha, NULL, NULL);\r\nha->flags.fce_enabled = 0;\r\n}\r\nif (ha->eft)\r\nqla2x00_disable_eft_trace(vha);\r\nqla2x00_try_to_stop_firmware(vha);\r\nvha->flags.online = 0;\r\nif (ha->interrupts_on) {\r\nvha->flags.init_done = 0;\r\nha->isp_ops->disable_intrs(ha);\r\n}\r\nqla2x00_free_irqs(vha);\r\nqla2x00_free_fw_dump(ha);\r\npci_disable_pcie_error_reporting(pdev);\r\npci_disable_device(pdev);\r\n}\r\nstatic void\r\nqla2x00_delete_all_vps(struct qla_hw_data *ha, scsi_qla_host_t *base_vha)\r\n{\r\nscsi_qla_host_t *vha;\r\nunsigned long flags;\r\nmutex_lock(&ha->vport_lock);\r\nwhile (ha->cur_vport_count) {\r\nspin_lock_irqsave(&ha->vport_slock, flags);\r\nBUG_ON(base_vha->list.next == &ha->vp_list);\r\nvha = list_first_entry(&base_vha->list, scsi_qla_host_t, list);\r\nscsi_host_get(vha->host);\r\nspin_unlock_irqrestore(&ha->vport_slock, flags);\r\nmutex_unlock(&ha->vport_lock);\r\nfc_vport_terminate(vha->fc_vport);\r\nscsi_host_put(vha->host);\r\nmutex_lock(&ha->vport_lock);\r\n}\r\nmutex_unlock(&ha->vport_lock);\r\n}\r\nstatic void\r\nqla2x00_destroy_deferred_work(struct qla_hw_data *ha)\r\n{\r\nif (ha->wq) {\r\nflush_workqueue(ha->wq);\r\ndestroy_workqueue(ha->wq);\r\nha->wq = NULL;\r\n}\r\nif (ha->dpc_lp_wq) {\r\ncancel_work_sync(&ha->idc_aen);\r\ndestroy_workqueue(ha->dpc_lp_wq);\r\nha->dpc_lp_wq = NULL;\r\n}\r\nif (ha->dpc_hp_wq) {\r\ncancel_work_sync(&ha->nic_core_reset);\r\ncancel_work_sync(&ha->idc_state_handler);\r\ncancel_work_sync(&ha->nic_core_unrecoverable);\r\ndestroy_workqueue(ha->dpc_hp_wq);\r\nha->dpc_hp_wq = NULL;\r\n}\r\nif (ha->dpc_thread) {\r\nstruct task_struct *t = ha->dpc_thread;\r\nha->dpc_thread = NULL;\r\nkthread_stop(t);\r\n}\r\n}\r\nstatic void\r\nqla2x00_unmap_iobases(struct qla_hw_data *ha)\r\n{\r\nif (IS_QLA82XX(ha)) {\r\niounmap((device_reg_t *)ha->nx_pcibase);\r\nif (!ql2xdbwr)\r\niounmap((device_reg_t *)ha->nxdb_wr_ptr);\r\n} else {\r\nif (ha->iobase)\r\niounmap(ha->iobase);\r\nif (ha->cregbase)\r\niounmap(ha->cregbase);\r\nif (ha->mqiobase)\r\niounmap(ha->mqiobase);\r\nif ((IS_QLA83XX(ha) || IS_QLA27XX(ha)) && ha->msixbase)\r\niounmap(ha->msixbase);\r\n}\r\n}\r\nstatic void\r\nqla2x00_clear_drv_active(struct qla_hw_data *ha)\r\n{\r\nif (IS_QLA8044(ha)) {\r\nqla8044_idc_lock(ha);\r\nqla8044_clear_drv_active(ha);\r\nqla8044_idc_unlock(ha);\r\n} else if (IS_QLA82XX(ha)) {\r\nqla82xx_idc_lock(ha);\r\nqla82xx_clear_drv_active(ha);\r\nqla82xx_idc_unlock(ha);\r\n}\r\n}\r\nstatic void\r\nqla2x00_remove_one(struct pci_dev *pdev)\r\n{\r\nscsi_qla_host_t *base_vha;\r\nstruct qla_hw_data *ha;\r\nbase_vha = pci_get_drvdata(pdev);\r\nha = base_vha->hw;\r\nset_bit(PFLG_DRIVER_REMOVING, &base_vha->pci_flags);\r\ncancel_work_sync(&ha->board_disable);\r\nif (!atomic_read(&pdev->enable_cnt)) {\r\nscsi_host_put(base_vha->host);\r\nkfree(ha);\r\npci_set_drvdata(pdev, NULL);\r\nreturn;\r\n}\r\nqla2x00_wait_for_hba_ready(base_vha);\r\nset_bit(UNLOADING, &base_vha->dpc_flags);\r\nif (IS_QLAFX00(ha))\r\nqlafx00_driver_shutdown(base_vha, 20);\r\nqla2x00_delete_all_vps(ha, base_vha);\r\nif (IS_QLA8031(ha)) {\r\nql_dbg(ql_dbg_p3p, base_vha, 0xb07e,\r\n"Clearing fcoe driver presence.\n");\r\nif (qla83xx_clear_drv_presence(base_vha) != QLA_SUCCESS)\r\nql_dbg(ql_dbg_p3p, base_vha, 0xb079,\r\n"Error while clearing DRV-Presence.\n");\r\n}\r\nqla2x00_abort_all_cmds(base_vha, DID_NO_CONNECT << 16);\r\nqla2x00_dfs_remove(base_vha);\r\nqla84xx_put_chip(base_vha);\r\nif (IS_QLA2031(ha))\r\nqla83xx_disable_laser(base_vha);\r\nif (base_vha->timer_active)\r\nqla2x00_stop_timer(base_vha);\r\nbase_vha->flags.online = 0;\r\nif (ha->exlogin_buf)\r\nqla2x00_free_exlogin_buffer(ha);\r\nif (ha->exchoffld_buf)\r\nqla2x00_free_exchoffld_buffer(ha);\r\nqla2x00_destroy_deferred_work(ha);\r\nqlt_remove_target(ha, base_vha);\r\nqla2x00_free_sysfs_attr(base_vha, true);\r\nfc_remove_host(base_vha->host);\r\nscsi_remove_host(base_vha->host);\r\nqla2x00_free_device(base_vha);\r\nqla2x00_clear_drv_active(ha);\r\nscsi_host_put(base_vha->host);\r\nqla2x00_unmap_iobases(ha);\r\npci_release_selected_regions(ha->pdev, ha->bars);\r\nkfree(ha);\r\nha = NULL;\r\npci_disable_pcie_error_reporting(pdev);\r\npci_disable_device(pdev);\r\n}\r\nstatic void\r\nqla2x00_free_device(scsi_qla_host_t *vha)\r\n{\r\nstruct qla_hw_data *ha = vha->hw;\r\nqla2x00_abort_all_cmds(vha, DID_NO_CONNECT << 16);\r\nif (vha->timer_active)\r\nqla2x00_stop_timer(vha);\r\nqla25xx_delete_queues(vha);\r\nif (ha->flags.fce_enabled)\r\nqla2x00_disable_fce_trace(vha, NULL, NULL);\r\nif (ha->eft)\r\nqla2x00_disable_eft_trace(vha);\r\nqla2x00_try_to_stop_firmware(vha);\r\nvha->flags.online = 0;\r\nif (ha->interrupts_on) {\r\nvha->flags.init_done = 0;\r\nha->isp_ops->disable_intrs(ha);\r\n}\r\nqla2x00_free_irqs(vha);\r\nqla2x00_free_fcports(vha);\r\nqla2x00_mem_free(ha);\r\nqla82xx_md_free(vha);\r\nqla2x00_free_queues(ha);\r\n}\r\nvoid qla2x00_free_fcports(struct scsi_qla_host *vha)\r\n{\r\nfc_port_t *fcport, *tfcport;\r\nlist_for_each_entry_safe(fcport, tfcport, &vha->vp_fcports, list) {\r\nlist_del(&fcport->list);\r\nqla2x00_clear_loop_id(fcport);\r\nkfree(fcport);\r\nfcport = NULL;\r\n}\r\n}\r\nstatic inline void\r\nqla2x00_schedule_rport_del(struct scsi_qla_host *vha, fc_port_t *fcport,\r\nint defer)\r\n{\r\nstruct fc_rport *rport;\r\nscsi_qla_host_t *base_vha;\r\nunsigned long flags;\r\nif (!fcport->rport)\r\nreturn;\r\nrport = fcport->rport;\r\nif (defer) {\r\nbase_vha = pci_get_drvdata(vha->hw->pdev);\r\nspin_lock_irqsave(vha->host->host_lock, flags);\r\nfcport->drport = rport;\r\nspin_unlock_irqrestore(vha->host->host_lock, flags);\r\nqlt_do_generation_tick(vha, &base_vha->total_fcport_update_gen);\r\nset_bit(FCPORT_UPDATE_NEEDED, &base_vha->dpc_flags);\r\nqla2xxx_wake_dpc(base_vha);\r\n} else {\r\nint now;\r\nif (rport)\r\nfc_remote_port_delete(rport);\r\nqlt_do_generation_tick(vha, &now);\r\nqlt_fc_port_deleted(vha, fcport, now);\r\n}\r\n}\r\nvoid qla2x00_mark_device_lost(scsi_qla_host_t *vha, fc_port_t *fcport,\r\nint do_login, int defer)\r\n{\r\nif (IS_QLAFX00(vha->hw)) {\r\nqla2x00_set_fcport_state(fcport, FCS_DEVICE_LOST);\r\nqla2x00_schedule_rport_del(vha, fcport, defer);\r\nreturn;\r\n}\r\nif (atomic_read(&fcport->state) == FCS_ONLINE &&\r\nvha->vp_idx == fcport->vha->vp_idx) {\r\nqla2x00_set_fcport_state(fcport, FCS_DEVICE_LOST);\r\nqla2x00_schedule_rport_del(vha, fcport, defer);\r\n}\r\nif (atomic_read(&fcport->state) != FCS_DEVICE_DEAD)\r\nqla2x00_set_fcport_state(fcport, FCS_DEVICE_LOST);\r\nif (!do_login)\r\nreturn;\r\nset_bit(RELOGIN_NEEDED, &vha->dpc_flags);\r\nif (fcport->login_retry == 0) {\r\nfcport->login_retry = vha->hw->login_retry_count;\r\nql_dbg(ql_dbg_disc, vha, 0x2067,\r\n"Port login retry %8phN, id = 0x%04x retry cnt=%d.\n",\r\nfcport->port_name, fcport->loop_id, fcport->login_retry);\r\n}\r\n}\r\nvoid\r\nqla2x00_mark_all_devices_lost(scsi_qla_host_t *vha, int defer)\r\n{\r\nfc_port_t *fcport;\r\nlist_for_each_entry(fcport, &vha->vp_fcports, list) {\r\nif (vha->vp_idx != 0 && vha->vp_idx != fcport->vha->vp_idx)\r\ncontinue;\r\nif (atomic_read(&fcport->state) == FCS_DEVICE_DEAD)\r\ncontinue;\r\nif (atomic_read(&fcport->state) == FCS_ONLINE) {\r\nqla2x00_set_fcport_state(fcport, FCS_DEVICE_LOST);\r\nif (defer)\r\nqla2x00_schedule_rport_del(vha, fcport, defer);\r\nelse if (vha->vp_idx == fcport->vha->vp_idx)\r\nqla2x00_schedule_rport_del(vha, fcport, defer);\r\n}\r\n}\r\n}\r\nstatic int\r\nqla2x00_mem_alloc(struct qla_hw_data *ha, uint16_t req_len, uint16_t rsp_len,\r\nstruct req_que **req, struct rsp_que **rsp)\r\n{\r\nchar name[16];\r\nha->init_cb = dma_alloc_coherent(&ha->pdev->dev, ha->init_cb_size,\r\n&ha->init_cb_dma, GFP_KERNEL);\r\nif (!ha->init_cb)\r\ngoto fail;\r\nif (qlt_mem_alloc(ha) < 0)\r\ngoto fail_free_init_cb;\r\nha->gid_list = dma_alloc_coherent(&ha->pdev->dev,\r\nqla2x00_gid_list_size(ha), &ha->gid_list_dma, GFP_KERNEL);\r\nif (!ha->gid_list)\r\ngoto fail_free_tgt_mem;\r\nha->srb_mempool = mempool_create_slab_pool(SRB_MIN_REQ, srb_cachep);\r\nif (!ha->srb_mempool)\r\ngoto fail_free_gid_list;\r\nif (IS_P3P_TYPE(ha)) {\r\nif (!ctx_cachep) {\r\nctx_cachep = kmem_cache_create("qla2xxx_ctx",\r\nsizeof(struct ct6_dsd), 0,\r\nSLAB_HWCACHE_ALIGN, NULL);\r\nif (!ctx_cachep)\r\ngoto fail_free_gid_list;\r\n}\r\nha->ctx_mempool = mempool_create_slab_pool(SRB_MIN_REQ,\r\nctx_cachep);\r\nif (!ha->ctx_mempool)\r\ngoto fail_free_srb_mempool;\r\nql_dbg_pci(ql_dbg_init, ha->pdev, 0x0021,\r\n"ctx_cachep=%p ctx_mempool=%p.\n",\r\nctx_cachep, ha->ctx_mempool);\r\n}\r\nha->nvram = kzalloc(MAX_NVRAM_SIZE, GFP_KERNEL);\r\nif (!ha->nvram)\r\ngoto fail_free_ctx_mempool;\r\nsnprintf(name, sizeof(name), "%s_%d", QLA2XXX_DRIVER_NAME,\r\nha->pdev->device);\r\nha->s_dma_pool = dma_pool_create(name, &ha->pdev->dev,\r\nDMA_POOL_SIZE, 8, 0);\r\nif (!ha->s_dma_pool)\r\ngoto fail_free_nvram;\r\nql_dbg_pci(ql_dbg_init, ha->pdev, 0x0022,\r\n"init_cb=%p gid_list=%p, srb_mempool=%p s_dma_pool=%p.\n",\r\nha->init_cb, ha->gid_list, ha->srb_mempool, ha->s_dma_pool);\r\nif (IS_P3P_TYPE(ha) || ql2xenabledif) {\r\nha->dl_dma_pool = dma_pool_create(name, &ha->pdev->dev,\r\nDSD_LIST_DMA_POOL_SIZE, 8, 0);\r\nif (!ha->dl_dma_pool) {\r\nql_log_pci(ql_log_fatal, ha->pdev, 0x0023,\r\n"Failed to allocate memory for dl_dma_pool.\n");\r\ngoto fail_s_dma_pool;\r\n}\r\nha->fcp_cmnd_dma_pool = dma_pool_create(name, &ha->pdev->dev,\r\nFCP_CMND_DMA_POOL_SIZE, 8, 0);\r\nif (!ha->fcp_cmnd_dma_pool) {\r\nql_log_pci(ql_log_fatal, ha->pdev, 0x0024,\r\n"Failed to allocate memory for fcp_cmnd_dma_pool.\n");\r\ngoto fail_dl_dma_pool;\r\n}\r\nql_dbg_pci(ql_dbg_init, ha->pdev, 0x0025,\r\n"dl_dma_pool=%p fcp_cmnd_dma_pool=%p.\n",\r\nha->dl_dma_pool, ha->fcp_cmnd_dma_pool);\r\n}\r\nif (IS_QLA2100(ha) || IS_QLA2200(ha)) {\r\nha->sns_cmd = dma_alloc_coherent(&ha->pdev->dev,\r\nsizeof(struct sns_cmd_pkt), &ha->sns_cmd_dma, GFP_KERNEL);\r\nif (!ha->sns_cmd)\r\ngoto fail_dma_pool;\r\nql_dbg_pci(ql_dbg_init, ha->pdev, 0x0026,\r\n"sns_cmd: %p.\n", ha->sns_cmd);\r\n} else {\r\nha->ms_iocb = dma_pool_alloc(ha->s_dma_pool, GFP_KERNEL,\r\n&ha->ms_iocb_dma);\r\nif (!ha->ms_iocb)\r\ngoto fail_dma_pool;\r\nha->ct_sns = dma_alloc_coherent(&ha->pdev->dev,\r\nsizeof(struct ct_sns_pkt), &ha->ct_sns_dma, GFP_KERNEL);\r\nif (!ha->ct_sns)\r\ngoto fail_free_ms_iocb;\r\nql_dbg_pci(ql_dbg_init, ha->pdev, 0x0027,\r\n"ms_iocb=%p ct_sns=%p.\n",\r\nha->ms_iocb, ha->ct_sns);\r\n}\r\n*req = kzalloc(sizeof(struct req_que), GFP_KERNEL);\r\nif (!*req) {\r\nql_log_pci(ql_log_fatal, ha->pdev, 0x0028,\r\n"Failed to allocate memory for req.\n");\r\ngoto fail_req;\r\n}\r\n(*req)->length = req_len;\r\n(*req)->ring = dma_alloc_coherent(&ha->pdev->dev,\r\n((*req)->length + 1) * sizeof(request_t),\r\n&(*req)->dma, GFP_KERNEL);\r\nif (!(*req)->ring) {\r\nql_log_pci(ql_log_fatal, ha->pdev, 0x0029,\r\n"Failed to allocate memory for req_ring.\n");\r\ngoto fail_req_ring;\r\n}\r\n*rsp = kzalloc(sizeof(struct rsp_que), GFP_KERNEL);\r\nif (!*rsp) {\r\nql_log_pci(ql_log_fatal, ha->pdev, 0x002a,\r\n"Failed to allocate memory for rsp.\n");\r\ngoto fail_rsp;\r\n}\r\n(*rsp)->hw = ha;\r\n(*rsp)->length = rsp_len;\r\n(*rsp)->ring = dma_alloc_coherent(&ha->pdev->dev,\r\n((*rsp)->length + 1) * sizeof(response_t),\r\n&(*rsp)->dma, GFP_KERNEL);\r\nif (!(*rsp)->ring) {\r\nql_log_pci(ql_log_fatal, ha->pdev, 0x002b,\r\n"Failed to allocate memory for rsp_ring.\n");\r\ngoto fail_rsp_ring;\r\n}\r\n(*req)->rsp = *rsp;\r\n(*rsp)->req = *req;\r\nql_dbg_pci(ql_dbg_init, ha->pdev, 0x002c,\r\n"req=%p req->length=%d req->ring=%p rsp=%p "\r\n"rsp->length=%d rsp->ring=%p.\n",\r\n*req, (*req)->length, (*req)->ring, *rsp, (*rsp)->length,\r\n(*rsp)->ring);\r\nif (ha->nvram_npiv_size) {\r\nha->npiv_info = kzalloc(sizeof(struct qla_npiv_entry) *\r\nha->nvram_npiv_size, GFP_KERNEL);\r\nif (!ha->npiv_info) {\r\nql_log_pci(ql_log_fatal, ha->pdev, 0x002d,\r\n"Failed to allocate memory for npiv_info.\n");\r\ngoto fail_npiv_info;\r\n}\r\n} else\r\nha->npiv_info = NULL;\r\nif (IS_CNA_CAPABLE(ha) || IS_QLA2031(ha) || IS_QLA27XX(ha)) {\r\nha->ex_init_cb = dma_pool_alloc(ha->s_dma_pool, GFP_KERNEL,\r\n&ha->ex_init_cb_dma);\r\nif (!ha->ex_init_cb)\r\ngoto fail_ex_init_cb;\r\nql_dbg_pci(ql_dbg_init, ha->pdev, 0x002e,\r\n"ex_init_cb=%p.\n", ha->ex_init_cb);\r\n}\r\nINIT_LIST_HEAD(&ha->gbl_dsd_list);\r\nif (!IS_FWI2_CAPABLE(ha)) {\r\nha->async_pd = dma_pool_alloc(ha->s_dma_pool, GFP_KERNEL,\r\n&ha->async_pd_dma);\r\nif (!ha->async_pd)\r\ngoto fail_async_pd;\r\nql_dbg_pci(ql_dbg_init, ha->pdev, 0x002f,\r\n"async_pd=%p.\n", ha->async_pd);\r\n}\r\nINIT_LIST_HEAD(&ha->vp_list);\r\nha->loop_id_map = kzalloc(BITS_TO_LONGS(LOOPID_MAP_SIZE) * sizeof(long),\r\nGFP_KERNEL);\r\nif (!ha->loop_id_map)\r\ngoto fail_async_pd;\r\nelse {\r\nqla2x00_set_reserved_loop_ids(ha);\r\nql_dbg_pci(ql_dbg_init, ha->pdev, 0x0123,\r\n"loop_id_map=%p.\n", ha->loop_id_map);\r\n}\r\nreturn 0;\r\nfail_async_pd:\r\ndma_pool_free(ha->s_dma_pool, ha->ex_init_cb, ha->ex_init_cb_dma);\r\nfail_ex_init_cb:\r\nkfree(ha->npiv_info);\r\nfail_npiv_info:\r\ndma_free_coherent(&ha->pdev->dev, ((*rsp)->length + 1) *\r\nsizeof(response_t), (*rsp)->ring, (*rsp)->dma);\r\n(*rsp)->ring = NULL;\r\n(*rsp)->dma = 0;\r\nfail_rsp_ring:\r\nkfree(*rsp);\r\nfail_rsp:\r\ndma_free_coherent(&ha->pdev->dev, ((*req)->length + 1) *\r\nsizeof(request_t), (*req)->ring, (*req)->dma);\r\n(*req)->ring = NULL;\r\n(*req)->dma = 0;\r\nfail_req_ring:\r\nkfree(*req);\r\nfail_req:\r\ndma_free_coherent(&ha->pdev->dev, sizeof(struct ct_sns_pkt),\r\nha->ct_sns, ha->ct_sns_dma);\r\nha->ct_sns = NULL;\r\nha->ct_sns_dma = 0;\r\nfail_free_ms_iocb:\r\ndma_pool_free(ha->s_dma_pool, ha->ms_iocb, ha->ms_iocb_dma);\r\nha->ms_iocb = NULL;\r\nha->ms_iocb_dma = 0;\r\nfail_dma_pool:\r\nif (IS_QLA82XX(ha) || ql2xenabledif) {\r\ndma_pool_destroy(ha->fcp_cmnd_dma_pool);\r\nha->fcp_cmnd_dma_pool = NULL;\r\n}\r\nfail_dl_dma_pool:\r\nif (IS_QLA82XX(ha) || ql2xenabledif) {\r\ndma_pool_destroy(ha->dl_dma_pool);\r\nha->dl_dma_pool = NULL;\r\n}\r\nfail_s_dma_pool:\r\ndma_pool_destroy(ha->s_dma_pool);\r\nha->s_dma_pool = NULL;\r\nfail_free_nvram:\r\nkfree(ha->nvram);\r\nha->nvram = NULL;\r\nfail_free_ctx_mempool:\r\nmempool_destroy(ha->ctx_mempool);\r\nha->ctx_mempool = NULL;\r\nfail_free_srb_mempool:\r\nmempool_destroy(ha->srb_mempool);\r\nha->srb_mempool = NULL;\r\nfail_free_gid_list:\r\ndma_free_coherent(&ha->pdev->dev, qla2x00_gid_list_size(ha),\r\nha->gid_list,\r\nha->gid_list_dma);\r\nha->gid_list = NULL;\r\nha->gid_list_dma = 0;\r\nfail_free_tgt_mem:\r\nqlt_mem_free(ha);\r\nfail_free_init_cb:\r\ndma_free_coherent(&ha->pdev->dev, ha->init_cb_size, ha->init_cb,\r\nha->init_cb_dma);\r\nha->init_cb = NULL;\r\nha->init_cb_dma = 0;\r\nfail:\r\nql_log(ql_log_fatal, NULL, 0x0030,\r\n"Memory allocation failure.\n");\r\nreturn -ENOMEM;\r\n}\r\nint\r\nqla2x00_set_exlogins_buffer(scsi_qla_host_t *vha)\r\n{\r\nint rval;\r\nuint16_t size, max_cnt, temp;\r\nstruct qla_hw_data *ha = vha->hw;\r\nif (!ql2xexlogins)\r\nreturn QLA_SUCCESS;\r\nql_log(ql_log_info, vha, 0xd021, "EXLOGIN count: %d.\n", ql2xexlogins);\r\nmax_cnt = 0;\r\nrval = qla_get_exlogin_status(vha, &size, &max_cnt);\r\nif (rval != QLA_SUCCESS) {\r\nql_log_pci(ql_log_fatal, ha->pdev, 0xd029,\r\n"Failed to get exlogin status.\n");\r\nreturn rval;\r\n}\r\ntemp = (ql2xexlogins > max_cnt) ? max_cnt : ql2xexlogins;\r\nha->exlogin_size = (size * temp);\r\nql_log(ql_log_info, vha, 0xd024,\r\n"EXLOGIN: max_logins=%d, portdb=0x%x, total=%d.\n",\r\nmax_cnt, size, temp);\r\nql_log(ql_log_info, vha, 0xd025, "EXLOGIN: requested size=0x%x\n",\r\nha->exlogin_size);\r\nha->exlogin_buf = dma_alloc_coherent(&ha->pdev->dev,\r\nha->exlogin_size, &ha->exlogin_buf_dma, GFP_KERNEL);\r\nif (!ha->exlogin_buf) {\r\nql_log_pci(ql_log_fatal, ha->pdev, 0xd02a,\r\n"Failed to allocate memory for exlogin_buf_dma.\n");\r\nreturn -ENOMEM;\r\n}\r\nrval = qla_set_exlogin_mem_cfg(vha, ha->exlogin_buf_dma);\r\nif (rval) {\r\nql_log(ql_log_fatal, vha, 0x00cf,\r\n"Setup extended login buffer ****FAILED****.\n");\r\nqla2x00_free_exlogin_buffer(ha);\r\n}\r\nreturn rval;\r\n}\r\nvoid\r\nqla2x00_free_exlogin_buffer(struct qla_hw_data *ha)\r\n{\r\nif (ha->exlogin_buf) {\r\ndma_free_coherent(&ha->pdev->dev, ha->exlogin_size,\r\nha->exlogin_buf, ha->exlogin_buf_dma);\r\nha->exlogin_buf = NULL;\r\nha->exlogin_size = 0;\r\n}\r\n}\r\nint\r\nqla2x00_set_exchoffld_buffer(scsi_qla_host_t *vha)\r\n{\r\nint rval;\r\nuint16_t size, max_cnt, temp;\r\nstruct qla_hw_data *ha = vha->hw;\r\nif (!ql2xexchoffld)\r\nreturn QLA_SUCCESS;\r\nql_log(ql_log_info, vha, 0xd014,\r\n"Exchange offload count: %d.\n", ql2xexlogins);\r\nmax_cnt = 0;\r\nrval = qla_get_exchoffld_status(vha, &size, &max_cnt);\r\nif (rval != QLA_SUCCESS) {\r\nql_log_pci(ql_log_fatal, ha->pdev, 0xd012,\r\n"Failed to get exlogin status.\n");\r\nreturn rval;\r\n}\r\ntemp = (ql2xexchoffld > max_cnt) ? max_cnt : ql2xexchoffld;\r\nha->exchoffld_size = (size * temp);\r\nql_log(ql_log_info, vha, 0xd016,\r\n"Exchange offload: max_count=%d, buffers=0x%x, total=%d.\n",\r\nmax_cnt, size, temp);\r\nql_log(ql_log_info, vha, 0xd017,\r\n"Exchange Buffers requested size = 0x%x\n", ha->exchoffld_size);\r\nha->exchoffld_buf = dma_alloc_coherent(&ha->pdev->dev,\r\nha->exchoffld_size, &ha->exchoffld_buf_dma, GFP_KERNEL);\r\nif (!ha->exchoffld_buf) {\r\nql_log_pci(ql_log_fatal, ha->pdev, 0xd013,\r\n"Failed to allocate memory for exchoffld_buf_dma.\n");\r\nreturn -ENOMEM;\r\n}\r\nrval = qla_set_exchoffld_mem_cfg(vha, ha->exchoffld_buf_dma);\r\nif (rval) {\r\nql_log(ql_log_fatal, vha, 0xd02e,\r\n"Setup exchange offload buffer ****FAILED****.\n");\r\nqla2x00_free_exchoffld_buffer(ha);\r\n}\r\nreturn rval;\r\n}\r\nvoid\r\nqla2x00_free_exchoffld_buffer(struct qla_hw_data *ha)\r\n{\r\nif (ha->exchoffld_buf) {\r\ndma_free_coherent(&ha->pdev->dev, ha->exchoffld_size,\r\nha->exchoffld_buf, ha->exchoffld_buf_dma);\r\nha->exchoffld_buf = NULL;\r\nha->exchoffld_size = 0;\r\n}\r\n}\r\nstatic void\r\nqla2x00_free_fw_dump(struct qla_hw_data *ha)\r\n{\r\nif (ha->fce)\r\ndma_free_coherent(&ha->pdev->dev,\r\nFCE_SIZE, ha->fce, ha->fce_dma);\r\nif (ha->eft)\r\ndma_free_coherent(&ha->pdev->dev,\r\nEFT_SIZE, ha->eft, ha->eft_dma);\r\nif (ha->fw_dump)\r\nvfree(ha->fw_dump);\r\nif (ha->fw_dump_template)\r\nvfree(ha->fw_dump_template);\r\nha->fce = NULL;\r\nha->fce_dma = 0;\r\nha->eft = NULL;\r\nha->eft_dma = 0;\r\nha->fw_dumped = 0;\r\nha->fw_dump_cap_flags = 0;\r\nha->fw_dump_reading = 0;\r\nha->fw_dump = NULL;\r\nha->fw_dump_len = 0;\r\nha->fw_dump_template = NULL;\r\nha->fw_dump_template_len = 0;\r\n}\r\nstatic void\r\nqla2x00_mem_free(struct qla_hw_data *ha)\r\n{\r\nqla2x00_free_fw_dump(ha);\r\nif (ha->mctp_dump)\r\ndma_free_coherent(&ha->pdev->dev, MCTP_DUMP_SIZE, ha->mctp_dump,\r\nha->mctp_dump_dma);\r\nif (ha->srb_mempool)\r\nmempool_destroy(ha->srb_mempool);\r\nif (ha->dcbx_tlv)\r\ndma_free_coherent(&ha->pdev->dev, DCBX_TLV_DATA_SIZE,\r\nha->dcbx_tlv, ha->dcbx_tlv_dma);\r\nif (ha->xgmac_data)\r\ndma_free_coherent(&ha->pdev->dev, XGMAC_DATA_SIZE,\r\nha->xgmac_data, ha->xgmac_data_dma);\r\nif (ha->sns_cmd)\r\ndma_free_coherent(&ha->pdev->dev, sizeof(struct sns_cmd_pkt),\r\nha->sns_cmd, ha->sns_cmd_dma);\r\nif (ha->ct_sns)\r\ndma_free_coherent(&ha->pdev->dev, sizeof(struct ct_sns_pkt),\r\nha->ct_sns, ha->ct_sns_dma);\r\nif (ha->sfp_data)\r\ndma_pool_free(ha->s_dma_pool, ha->sfp_data, ha->sfp_data_dma);\r\nif (ha->ms_iocb)\r\ndma_pool_free(ha->s_dma_pool, ha->ms_iocb, ha->ms_iocb_dma);\r\nif (ha->ex_init_cb)\r\ndma_pool_free(ha->s_dma_pool,\r\nha->ex_init_cb, ha->ex_init_cb_dma);\r\nif (ha->async_pd)\r\ndma_pool_free(ha->s_dma_pool, ha->async_pd, ha->async_pd_dma);\r\nif (ha->s_dma_pool)\r\ndma_pool_destroy(ha->s_dma_pool);\r\nif (ha->gid_list)\r\ndma_free_coherent(&ha->pdev->dev, qla2x00_gid_list_size(ha),\r\nha->gid_list, ha->gid_list_dma);\r\nif (IS_QLA82XX(ha)) {\r\nif (!list_empty(&ha->gbl_dsd_list)) {\r\nstruct dsd_dma *dsd_ptr, *tdsd_ptr;\r\nlist_for_each_entry_safe(dsd_ptr,\r\ntdsd_ptr, &ha->gbl_dsd_list, list) {\r\ndma_pool_free(ha->dl_dma_pool,\r\ndsd_ptr->dsd_addr, dsd_ptr->dsd_list_dma);\r\nlist_del(&dsd_ptr->list);\r\nkfree(dsd_ptr);\r\n}\r\n}\r\n}\r\nif (ha->dl_dma_pool)\r\ndma_pool_destroy(ha->dl_dma_pool);\r\nif (ha->fcp_cmnd_dma_pool)\r\ndma_pool_destroy(ha->fcp_cmnd_dma_pool);\r\nif (ha->ctx_mempool)\r\nmempool_destroy(ha->ctx_mempool);\r\nqlt_mem_free(ha);\r\nif (ha->init_cb)\r\ndma_free_coherent(&ha->pdev->dev, ha->init_cb_size,\r\nha->init_cb, ha->init_cb_dma);\r\nvfree(ha->optrom_buffer);\r\nkfree(ha->nvram);\r\nkfree(ha->npiv_info);\r\nkfree(ha->swl);\r\nkfree(ha->loop_id_map);\r\nha->srb_mempool = NULL;\r\nha->ctx_mempool = NULL;\r\nha->sns_cmd = NULL;\r\nha->sns_cmd_dma = 0;\r\nha->ct_sns = NULL;\r\nha->ct_sns_dma = 0;\r\nha->ms_iocb = NULL;\r\nha->ms_iocb_dma = 0;\r\nha->init_cb = NULL;\r\nha->init_cb_dma = 0;\r\nha->ex_init_cb = NULL;\r\nha->ex_init_cb_dma = 0;\r\nha->async_pd = NULL;\r\nha->async_pd_dma = 0;\r\nha->s_dma_pool = NULL;\r\nha->dl_dma_pool = NULL;\r\nha->fcp_cmnd_dma_pool = NULL;\r\nha->gid_list = NULL;\r\nha->gid_list_dma = 0;\r\nha->tgt.atio_ring = NULL;\r\nha->tgt.atio_dma = 0;\r\nha->tgt.tgt_vp_map = NULL;\r\n}\r\nstruct scsi_qla_host *qla2x00_create_host(struct scsi_host_template *sht,\r\nstruct qla_hw_data *ha)\r\n{\r\nstruct Scsi_Host *host;\r\nstruct scsi_qla_host *vha = NULL;\r\nhost = scsi_host_alloc(sht, sizeof(scsi_qla_host_t));\r\nif (host == NULL) {\r\nql_log_pci(ql_log_fatal, ha->pdev, 0x0107,\r\n"Failed to allocate host from the scsi layer, aborting.\n");\r\ngoto fail;\r\n}\r\nvha = shost_priv(host);\r\nmemset(vha, 0, sizeof(scsi_qla_host_t));\r\nvha->host = host;\r\nvha->host_no = host->host_no;\r\nvha->hw = ha;\r\nINIT_LIST_HEAD(&vha->vp_fcports);\r\nINIT_LIST_HEAD(&vha->work_list);\r\nINIT_LIST_HEAD(&vha->list);\r\nINIT_LIST_HEAD(&vha->qla_cmd_list);\r\nINIT_LIST_HEAD(&vha->qla_sess_op_cmd_list);\r\nINIT_LIST_HEAD(&vha->logo_list);\r\nINIT_LIST_HEAD(&vha->plogi_ack_list);\r\nspin_lock_init(&vha->work_lock);\r\nspin_lock_init(&vha->cmd_list_lock);\r\nsprintf(vha->host_str, "%s_%ld", QLA2XXX_DRIVER_NAME, vha->host_no);\r\nql_dbg(ql_dbg_init, vha, 0x0041,\r\n"Allocated the host=%p hw=%p vha=%p dev_name=%s",\r\nvha->host, vha->hw, vha,\r\ndev_name(&(ha->pdev->dev)));\r\nreturn vha;\r\nfail:\r\nreturn vha;\r\n}\r\nstatic struct qla_work_evt *\r\nqla2x00_alloc_work(struct scsi_qla_host *vha, enum qla_work_type type)\r\n{\r\nstruct qla_work_evt *e;\r\nuint8_t bail;\r\nQLA_VHA_MARK_BUSY(vha, bail);\r\nif (bail)\r\nreturn NULL;\r\ne = kzalloc(sizeof(struct qla_work_evt), GFP_ATOMIC);\r\nif (!e) {\r\nQLA_VHA_MARK_NOT_BUSY(vha);\r\nreturn NULL;\r\n}\r\nINIT_LIST_HEAD(&e->list);\r\ne->type = type;\r\ne->flags = QLA_EVT_FLAG_FREE;\r\nreturn e;\r\n}\r\nstatic int\r\nqla2x00_post_work(struct scsi_qla_host *vha, struct qla_work_evt *e)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&vha->work_lock, flags);\r\nlist_add_tail(&e->list, &vha->work_list);\r\nspin_unlock_irqrestore(&vha->work_lock, flags);\r\nqla2xxx_wake_dpc(vha);\r\nreturn QLA_SUCCESS;\r\n}\r\nint\r\nqla2x00_post_aen_work(struct scsi_qla_host *vha, enum fc_host_event_code code,\r\nu32 data)\r\n{\r\nstruct qla_work_evt *e;\r\ne = qla2x00_alloc_work(vha, QLA_EVT_AEN);\r\nif (!e)\r\nreturn QLA_FUNCTION_FAILED;\r\ne->u.aen.code = code;\r\ne->u.aen.data = data;\r\nreturn qla2x00_post_work(vha, e);\r\n}\r\nint\r\nqla2x00_post_idc_ack_work(struct scsi_qla_host *vha, uint16_t *mb)\r\n{\r\nstruct qla_work_evt *e;\r\ne = qla2x00_alloc_work(vha, QLA_EVT_IDC_ACK);\r\nif (!e)\r\nreturn QLA_FUNCTION_FAILED;\r\nmemcpy(e->u.idc_ack.mb, mb, QLA_IDC_ACK_REGS * sizeof(uint16_t));\r\nreturn qla2x00_post_work(vha, e);\r\n}\r\nint\r\nqla2x00_post_uevent_work(struct scsi_qla_host *vha, u32 code)\r\n{\r\nstruct qla_work_evt *e;\r\ne = qla2x00_alloc_work(vha, QLA_EVT_UEVENT);\r\nif (!e)\r\nreturn QLA_FUNCTION_FAILED;\r\ne->u.uevent.code = code;\r\nreturn qla2x00_post_work(vha, e);\r\n}\r\nstatic void\r\nqla2x00_uevent_emit(struct scsi_qla_host *vha, u32 code)\r\n{\r\nchar event_string[40];\r\nchar *envp[] = { event_string, NULL };\r\nswitch (code) {\r\ncase QLA_UEVENT_CODE_FW_DUMP:\r\nsnprintf(event_string, sizeof(event_string), "FW_DUMP=%ld",\r\nvha->host_no);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nkobject_uevent_env(&vha->hw->pdev->dev.kobj, KOBJ_CHANGE, envp);\r\n}\r\nint\r\nqlafx00_post_aenfx_work(struct scsi_qla_host *vha, uint32_t evtcode,\r\nuint32_t *data, int cnt)\r\n{\r\nstruct qla_work_evt *e;\r\ne = qla2x00_alloc_work(vha, QLA_EVT_AENFX);\r\nif (!e)\r\nreturn QLA_FUNCTION_FAILED;\r\ne->u.aenfx.evtcode = evtcode;\r\ne->u.aenfx.count = cnt;\r\nmemcpy(e->u.aenfx.mbx, data, sizeof(*data) * cnt);\r\nreturn qla2x00_post_work(vha, e);\r\n}\r\nvoid\r\nqla2x00_do_work(struct scsi_qla_host *vha)\r\n{\r\nstruct qla_work_evt *e, *tmp;\r\nunsigned long flags;\r\nLIST_HEAD(work);\r\nspin_lock_irqsave(&vha->work_lock, flags);\r\nlist_splice_init(&vha->work_list, &work);\r\nspin_unlock_irqrestore(&vha->work_lock, flags);\r\nlist_for_each_entry_safe(e, tmp, &work, list) {\r\nlist_del_init(&e->list);\r\nswitch (e->type) {\r\ncase QLA_EVT_AEN:\r\nfc_host_post_event(vha->host, fc_get_event_number(),\r\ne->u.aen.code, e->u.aen.data);\r\nbreak;\r\ncase QLA_EVT_IDC_ACK:\r\nqla81xx_idc_ack(vha, e->u.idc_ack.mb);\r\nbreak;\r\ncase QLA_EVT_ASYNC_LOGIN:\r\nqla2x00_async_login(vha, e->u.logio.fcport,\r\ne->u.logio.data);\r\nbreak;\r\ncase QLA_EVT_ASYNC_LOGIN_DONE:\r\nqla2x00_async_login_done(vha, e->u.logio.fcport,\r\ne->u.logio.data);\r\nbreak;\r\ncase QLA_EVT_ASYNC_LOGOUT:\r\nqla2x00_async_logout(vha, e->u.logio.fcport);\r\nbreak;\r\ncase QLA_EVT_ASYNC_LOGOUT_DONE:\r\nqla2x00_async_logout_done(vha, e->u.logio.fcport,\r\ne->u.logio.data);\r\nbreak;\r\ncase QLA_EVT_ASYNC_ADISC:\r\nqla2x00_async_adisc(vha, e->u.logio.fcport,\r\ne->u.logio.data);\r\nbreak;\r\ncase QLA_EVT_ASYNC_ADISC_DONE:\r\nqla2x00_async_adisc_done(vha, e->u.logio.fcport,\r\ne->u.logio.data);\r\nbreak;\r\ncase QLA_EVT_UEVENT:\r\nqla2x00_uevent_emit(vha, e->u.uevent.code);\r\nbreak;\r\ncase QLA_EVT_AENFX:\r\nqlafx00_process_aen(vha, e);\r\nbreak;\r\n}\r\nif (e->flags & QLA_EVT_FLAG_FREE)\r\nkfree(e);\r\nQLA_VHA_MARK_NOT_BUSY(vha);\r\n}\r\n}\r\nvoid qla2x00_relogin(struct scsi_qla_host *vha)\r\n{\r\nfc_port_t *fcport;\r\nint status;\r\nuint16_t next_loopid = 0;\r\nstruct qla_hw_data *ha = vha->hw;\r\nuint16_t data[2];\r\nlist_for_each_entry(fcport, &vha->vp_fcports, list) {\r\nif (atomic_read(&fcport->state) != FCS_ONLINE &&\r\nfcport->login_retry && !(fcport->flags & FCF_ASYNC_SENT)) {\r\nfcport->login_retry--;\r\nif (fcport->flags & FCF_FABRIC_DEVICE) {\r\nif (fcport->flags & FCF_FCP2_DEVICE)\r\nha->isp_ops->fabric_logout(vha,\r\nfcport->loop_id,\r\nfcport->d_id.b.domain,\r\nfcport->d_id.b.area,\r\nfcport->d_id.b.al_pa);\r\nif (fcport->loop_id == FC_NO_LOOP_ID) {\r\nfcport->loop_id = next_loopid =\r\nha->min_external_loopid;\r\nstatus = qla2x00_find_new_loop_id(\r\nvha, fcport);\r\nif (status != QLA_SUCCESS) {\r\nbreak;\r\n}\r\n}\r\nif (IS_ALOGIO_CAPABLE(ha)) {\r\nfcport->flags |= FCF_ASYNC_SENT;\r\ndata[0] = 0;\r\ndata[1] = QLA_LOGIO_LOGIN_RETRIED;\r\nstatus = qla2x00_post_async_login_work(\r\nvha, fcport, data);\r\nif (status == QLA_SUCCESS)\r\ncontinue;\r\nstatus = 1;\r\n} else {\r\nstatus = qla2x00_fabric_login(vha,\r\nfcport, &next_loopid);\r\nif (status == QLA_SUCCESS) {\r\nint status2;\r\nuint8_t opts;\r\nopts = 0;\r\nif (fcport->flags &\r\nFCF_FCP2_DEVICE)\r\nopts |= BIT_1;\r\nstatus2 =\r\nqla2x00_get_port_database(\r\nvha, fcport, opts);\r\nif (status2 != QLA_SUCCESS)\r\nstatus = 1;\r\n}\r\n}\r\n} else\r\nstatus = qla2x00_local_device_login(vha,\r\nfcport);\r\nif (status == QLA_SUCCESS) {\r\nfcport->old_loop_id = fcport->loop_id;\r\nql_dbg(ql_dbg_disc, vha, 0x2003,\r\n"Port login OK: logged in ID 0x%x.\n",\r\nfcport->loop_id);\r\nqla2x00_update_fcport(vha, fcport);\r\n} else if (status == 1) {\r\nset_bit(RELOGIN_NEEDED, &vha->dpc_flags);\r\nql_dbg(ql_dbg_disc, vha, 0x2007,\r\n"Retrying %d login again loop_id 0x%x.\n",\r\nfcport->login_retry, fcport->loop_id);\r\n} else {\r\nfcport->login_retry = 0;\r\n}\r\nif (fcport->login_retry == 0 && status != QLA_SUCCESS)\r\nqla2x00_clear_loop_id(fcport);\r\n}\r\nif (test_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags))\r\nbreak;\r\n}\r\n}\r\nvoid\r\nqla83xx_schedule_work(scsi_qla_host_t *base_vha, int work_code)\r\n{\r\nstruct qla_hw_data *ha = base_vha->hw;\r\nswitch (work_code) {\r\ncase MBA_IDC_AEN:\r\nif (ha->dpc_lp_wq)\r\nqueue_work(ha->dpc_lp_wq, &ha->idc_aen);\r\nbreak;\r\ncase QLA83XX_NIC_CORE_RESET:\r\nif (!ha->flags.nic_core_reset_hdlr_active) {\r\nif (ha->dpc_hp_wq)\r\nqueue_work(ha->dpc_hp_wq, &ha->nic_core_reset);\r\n} else\r\nql_dbg(ql_dbg_p3p, base_vha, 0xb05e,\r\n"NIC Core reset is already active. Skip "\r\n"scheduling it again.\n");\r\nbreak;\r\ncase QLA83XX_IDC_STATE_HANDLER:\r\nif (ha->dpc_hp_wq)\r\nqueue_work(ha->dpc_hp_wq, &ha->idc_state_handler);\r\nbreak;\r\ncase QLA83XX_NIC_CORE_UNRECOVERABLE:\r\nif (ha->dpc_hp_wq)\r\nqueue_work(ha->dpc_hp_wq, &ha->nic_core_unrecoverable);\r\nbreak;\r\ndefault:\r\nql_log(ql_log_warn, base_vha, 0xb05f,\r\n"Unknown work-code=0x%x.\n", work_code);\r\n}\r\nreturn;\r\n}\r\nvoid\r\nqla83xx_nic_core_unrecoverable_work(struct work_struct *work)\r\n{\r\nstruct qla_hw_data *ha =\r\ncontainer_of(work, struct qla_hw_data, nic_core_unrecoverable);\r\nscsi_qla_host_t *base_vha = pci_get_drvdata(ha->pdev);\r\nuint32_t dev_state = 0;\r\nqla83xx_idc_lock(base_vha, 0);\r\nqla83xx_rd_reg(base_vha, QLA83XX_IDC_DEV_STATE, &dev_state);\r\nqla83xx_reset_ownership(base_vha);\r\nif (ha->flags.nic_core_reset_owner) {\r\nha->flags.nic_core_reset_owner = 0;\r\nqla83xx_wr_reg(base_vha, QLA83XX_IDC_DEV_STATE,\r\nQLA8XXX_DEV_FAILED);\r\nql_log(ql_log_info, base_vha, 0xb060, "HW State: FAILED.\n");\r\nqla83xx_schedule_work(base_vha, QLA83XX_IDC_STATE_HANDLER);\r\n}\r\nqla83xx_idc_unlock(base_vha, 0);\r\n}\r\nvoid\r\nqla83xx_idc_state_handler_work(struct work_struct *work)\r\n{\r\nstruct qla_hw_data *ha =\r\ncontainer_of(work, struct qla_hw_data, idc_state_handler);\r\nscsi_qla_host_t *base_vha = pci_get_drvdata(ha->pdev);\r\nuint32_t dev_state = 0;\r\nqla83xx_idc_lock(base_vha, 0);\r\nqla83xx_rd_reg(base_vha, QLA83XX_IDC_DEV_STATE, &dev_state);\r\nif (dev_state == QLA8XXX_DEV_FAILED ||\r\ndev_state == QLA8XXX_DEV_NEED_QUIESCENT)\r\nqla83xx_idc_state_handler(base_vha);\r\nqla83xx_idc_unlock(base_vha, 0);\r\n}\r\nstatic int\r\nqla83xx_check_nic_core_fw_alive(scsi_qla_host_t *base_vha)\r\n{\r\nint rval = QLA_SUCCESS;\r\nunsigned long heart_beat_wait = jiffies + (1 * HZ);\r\nuint32_t heart_beat_counter1, heart_beat_counter2;\r\ndo {\r\nif (time_after(jiffies, heart_beat_wait)) {\r\nql_dbg(ql_dbg_p3p, base_vha, 0xb07c,\r\n"Nic Core f/w is not alive.\n");\r\nrval = QLA_FUNCTION_FAILED;\r\nbreak;\r\n}\r\nqla83xx_idc_lock(base_vha, 0);\r\nqla83xx_rd_reg(base_vha, QLA83XX_FW_HEARTBEAT,\r\n&heart_beat_counter1);\r\nqla83xx_idc_unlock(base_vha, 0);\r\nmsleep(100);\r\nqla83xx_idc_lock(base_vha, 0);\r\nqla83xx_rd_reg(base_vha, QLA83XX_FW_HEARTBEAT,\r\n&heart_beat_counter2);\r\nqla83xx_idc_unlock(base_vha, 0);\r\n} while (heart_beat_counter1 == heart_beat_counter2);\r\nreturn rval;\r\n}\r\nvoid\r\nqla83xx_nic_core_reset_work(struct work_struct *work)\r\n{\r\nstruct qla_hw_data *ha =\r\ncontainer_of(work, struct qla_hw_data, nic_core_reset);\r\nscsi_qla_host_t *base_vha = pci_get_drvdata(ha->pdev);\r\nuint32_t dev_state = 0;\r\nif (IS_QLA2031(ha)) {\r\nif (qla2xxx_mctp_dump(base_vha) != QLA_SUCCESS)\r\nql_log(ql_log_warn, base_vha, 0xb081,\r\n"Failed to dump mctp\n");\r\nreturn;\r\n}\r\nif (!ha->flags.nic_core_reset_hdlr_active) {\r\nif (qla83xx_check_nic_core_fw_alive(base_vha) == QLA_SUCCESS) {\r\nqla83xx_idc_lock(base_vha, 0);\r\nqla83xx_rd_reg(base_vha, QLA83XX_IDC_DEV_STATE,\r\n&dev_state);\r\nqla83xx_idc_unlock(base_vha, 0);\r\nif (dev_state != QLA8XXX_DEV_NEED_RESET) {\r\nql_dbg(ql_dbg_p3p, base_vha, 0xb07a,\r\n"Nic Core f/w is alive.\n");\r\nreturn;\r\n}\r\n}\r\nha->flags.nic_core_reset_hdlr_active = 1;\r\nif (qla83xx_nic_core_reset(base_vha)) {\r\nql_dbg(ql_dbg_p3p, base_vha, 0xb061,\r\n"NIC Core reset failed.\n");\r\n}\r\nha->flags.nic_core_reset_hdlr_active = 0;\r\n}\r\n}\r\nvoid\r\nqla83xx_service_idc_aen(struct work_struct *work)\r\n{\r\nstruct qla_hw_data *ha =\r\ncontainer_of(work, struct qla_hw_data, idc_aen);\r\nscsi_qla_host_t *base_vha = pci_get_drvdata(ha->pdev);\r\nuint32_t dev_state, idc_control;\r\nqla83xx_idc_lock(base_vha, 0);\r\nqla83xx_rd_reg(base_vha, QLA83XX_IDC_DEV_STATE, &dev_state);\r\nqla83xx_rd_reg(base_vha, QLA83XX_IDC_CONTROL, &idc_control);\r\nqla83xx_idc_unlock(base_vha, 0);\r\nif (dev_state == QLA8XXX_DEV_NEED_RESET) {\r\nif (idc_control & QLA83XX_IDC_GRACEFUL_RESET) {\r\nql_dbg(ql_dbg_p3p, base_vha, 0xb062,\r\n"Application requested NIC Core Reset.\n");\r\nqla83xx_schedule_work(base_vha, QLA83XX_NIC_CORE_RESET);\r\n} else if (qla83xx_check_nic_core_fw_alive(base_vha) ==\r\nQLA_SUCCESS) {\r\nql_dbg(ql_dbg_p3p, base_vha, 0xb07b,\r\n"Other protocol driver requested NIC Core Reset.\n");\r\nqla83xx_schedule_work(base_vha, QLA83XX_NIC_CORE_RESET);\r\n}\r\n} else if (dev_state == QLA8XXX_DEV_FAILED ||\r\ndev_state == QLA8XXX_DEV_NEED_QUIESCENT) {\r\nqla83xx_schedule_work(base_vha, QLA83XX_IDC_STATE_HANDLER);\r\n}\r\n}\r\nstatic void\r\nqla83xx_wait_logic(void)\r\n{\r\nint i;\r\nif (!in_interrupt()) {\r\nmsleep(100);\r\nschedule();\r\n} else {\r\nfor (i = 0; i < 20; i++)\r\ncpu_relax();\r\n}\r\n}\r\nstatic int\r\nqla83xx_force_lock_recovery(scsi_qla_host_t *base_vha)\r\n{\r\nint rval;\r\nuint32_t data;\r\nuint32_t idc_lck_rcvry_stage_mask = 0x3;\r\nuint32_t idc_lck_rcvry_owner_mask = 0x3c;\r\nstruct qla_hw_data *ha = base_vha->hw;\r\nql_dbg(ql_dbg_p3p, base_vha, 0xb086,\r\n"Trying force recovery of the IDC lock.\n");\r\nrval = qla83xx_rd_reg(base_vha, QLA83XX_IDC_LOCK_RECOVERY, &data);\r\nif (rval)\r\nreturn rval;\r\nif ((data & idc_lck_rcvry_stage_mask) > 0) {\r\nreturn QLA_SUCCESS;\r\n} else {\r\ndata = (IDC_LOCK_RECOVERY_STAGE1) | (ha->portnum << 2);\r\nrval = qla83xx_wr_reg(base_vha, QLA83XX_IDC_LOCK_RECOVERY,\r\ndata);\r\nif (rval)\r\nreturn rval;\r\nmsleep(200);\r\nrval = qla83xx_rd_reg(base_vha, QLA83XX_IDC_LOCK_RECOVERY,\r\n&data);\r\nif (rval)\r\nreturn rval;\r\nif (((data & idc_lck_rcvry_owner_mask) >> 2) == ha->portnum) {\r\ndata &= (IDC_LOCK_RECOVERY_STAGE2 |\r\n~(idc_lck_rcvry_stage_mask));\r\nrval = qla83xx_wr_reg(base_vha,\r\nQLA83XX_IDC_LOCK_RECOVERY, data);\r\nif (rval)\r\nreturn rval;\r\nrval = qla83xx_rd_reg(base_vha, QLA83XX_DRIVER_UNLOCK,\r\n&data);\r\nif (rval)\r\nreturn rval;\r\nrval = qla83xx_wr_reg(base_vha, QLA83XX_DRIVER_LOCKID,\r\n0xff);\r\nif (rval)\r\nreturn rval;\r\nrval = qla83xx_wr_reg(base_vha,\r\nQLA83XX_IDC_LOCK_RECOVERY, 0x0);\r\nif (rval)\r\nreturn rval;\r\n} else\r\nreturn QLA_SUCCESS;\r\n}\r\nreturn rval;\r\n}\r\nstatic int\r\nqla83xx_idc_lock_recovery(scsi_qla_host_t *base_vha)\r\n{\r\nint rval = QLA_SUCCESS;\r\nuint32_t o_drv_lockid, n_drv_lockid;\r\nunsigned long lock_recovery_timeout;\r\nlock_recovery_timeout = jiffies + QLA83XX_MAX_LOCK_RECOVERY_WAIT;\r\nretry_lockid:\r\nrval = qla83xx_rd_reg(base_vha, QLA83XX_DRIVER_LOCKID, &o_drv_lockid);\r\nif (rval)\r\ngoto exit;\r\nif (time_after_eq(jiffies, lock_recovery_timeout)) {\r\nif (qla83xx_force_lock_recovery(base_vha) == QLA_SUCCESS)\r\nreturn QLA_SUCCESS;\r\nelse\r\nreturn QLA_FUNCTION_FAILED;\r\n}\r\nrval = qla83xx_rd_reg(base_vha, QLA83XX_DRIVER_LOCKID, &n_drv_lockid);\r\nif (rval)\r\ngoto exit;\r\nif (o_drv_lockid == n_drv_lockid) {\r\nqla83xx_wait_logic();\r\ngoto retry_lockid;\r\n} else\r\nreturn QLA_SUCCESS;\r\nexit:\r\nreturn rval;\r\n}\r\nvoid\r\nqla83xx_idc_lock(scsi_qla_host_t *base_vha, uint16_t requester_id)\r\n{\r\nuint16_t options = (requester_id << 15) | BIT_6;\r\nuint32_t data;\r\nuint32_t lock_owner;\r\nstruct qla_hw_data *ha = base_vha->hw;\r\nretry_lock:\r\nif (qla83xx_rd_reg(base_vha, QLA83XX_DRIVER_LOCK, &data)\r\n== QLA_SUCCESS) {\r\nif (data) {\r\nqla83xx_wr_reg(base_vha, QLA83XX_DRIVER_LOCKID,\r\nha->portnum);\r\n} else {\r\nqla83xx_rd_reg(base_vha, QLA83XX_DRIVER_LOCKID,\r\n&lock_owner);\r\nql_dbg(ql_dbg_p3p, base_vha, 0xb063,\r\n"Failed to acquire IDC lock, acquired by %d, "\r\n"retrying...\n", lock_owner);\r\nif (qla83xx_idc_lock_recovery(base_vha)\r\n== QLA_SUCCESS) {\r\nqla83xx_wait_logic();\r\ngoto retry_lock;\r\n} else\r\nql_log(ql_log_warn, base_vha, 0xb075,\r\n"IDC Lock recovery FAILED.\n");\r\n}\r\n}\r\nreturn;\r\nretry_lock2:\r\nif (qla83xx_access_control(base_vha, options, 0, 0, NULL)) {\r\nql_dbg(ql_dbg_p3p, base_vha, 0xb072,\r\n"Failed to acquire IDC lock. retrying...\n");\r\nif (qla83xx_idc_lock_recovery(base_vha) == QLA_SUCCESS) {\r\nqla83xx_wait_logic();\r\ngoto retry_lock2;\r\n} else\r\nql_log(ql_log_warn, base_vha, 0xb076,\r\n"IDC Lock recovery FAILED.\n");\r\n}\r\nreturn;\r\n}\r\nvoid\r\nqla83xx_idc_unlock(scsi_qla_host_t *base_vha, uint16_t requester_id)\r\n{\r\n#if 0\r\nuint16_t options = (requester_id << 15) | BIT_7;\r\n#endif\r\nuint16_t retry;\r\nuint32_t data;\r\nstruct qla_hw_data *ha = base_vha->hw;\r\nretry = 0;\r\nretry_unlock:\r\nif (qla83xx_rd_reg(base_vha, QLA83XX_DRIVER_LOCKID, &data)\r\n== QLA_SUCCESS) {\r\nif (data == ha->portnum) {\r\nqla83xx_rd_reg(base_vha, QLA83XX_DRIVER_UNLOCK, &data);\r\nqla83xx_wr_reg(base_vha, QLA83XX_DRIVER_LOCKID, 0xff);\r\n} else if (retry < 10) {\r\nqla83xx_wait_logic();\r\nretry++;\r\nql_dbg(ql_dbg_p3p, base_vha, 0xb064,\r\n"Failed to release IDC lock, retyring=%d\n", retry);\r\ngoto retry_unlock;\r\n}\r\n} else if (retry < 10) {\r\nqla83xx_wait_logic();\r\nretry++;\r\nql_dbg(ql_dbg_p3p, base_vha, 0xb065,\r\n"Failed to read drv-lockid, retyring=%d\n", retry);\r\ngoto retry_unlock;\r\n}\r\nreturn;\r\n#if 0\r\nretry = 0;\r\nretry_unlock2:\r\nif (qla83xx_access_control(base_vha, options, 0, 0, NULL)) {\r\nif (retry < 10) {\r\nqla83xx_wait_logic();\r\nretry++;\r\nql_dbg(ql_dbg_p3p, base_vha, 0xb066,\r\n"Failed to release IDC lock, retyring=%d\n", retry);\r\ngoto retry_unlock2;\r\n}\r\n}\r\nreturn;\r\n#endif\r\n}\r\nint\r\n__qla83xx_set_drv_presence(scsi_qla_host_t *vha)\r\n{\r\nint rval = QLA_SUCCESS;\r\nstruct qla_hw_data *ha = vha->hw;\r\nuint32_t drv_presence;\r\nrval = qla83xx_rd_reg(vha, QLA83XX_IDC_DRV_PRESENCE, &drv_presence);\r\nif (rval == QLA_SUCCESS) {\r\ndrv_presence |= (1 << ha->portnum);\r\nrval = qla83xx_wr_reg(vha, QLA83XX_IDC_DRV_PRESENCE,\r\ndrv_presence);\r\n}\r\nreturn rval;\r\n}\r\nint\r\nqla83xx_set_drv_presence(scsi_qla_host_t *vha)\r\n{\r\nint rval = QLA_SUCCESS;\r\nqla83xx_idc_lock(vha, 0);\r\nrval = __qla83xx_set_drv_presence(vha);\r\nqla83xx_idc_unlock(vha, 0);\r\nreturn rval;\r\n}\r\nint\r\n__qla83xx_clear_drv_presence(scsi_qla_host_t *vha)\r\n{\r\nint rval = QLA_SUCCESS;\r\nstruct qla_hw_data *ha = vha->hw;\r\nuint32_t drv_presence;\r\nrval = qla83xx_rd_reg(vha, QLA83XX_IDC_DRV_PRESENCE, &drv_presence);\r\nif (rval == QLA_SUCCESS) {\r\ndrv_presence &= ~(1 << ha->portnum);\r\nrval = qla83xx_wr_reg(vha, QLA83XX_IDC_DRV_PRESENCE,\r\ndrv_presence);\r\n}\r\nreturn rval;\r\n}\r\nint\r\nqla83xx_clear_drv_presence(scsi_qla_host_t *vha)\r\n{\r\nint rval = QLA_SUCCESS;\r\nqla83xx_idc_lock(vha, 0);\r\nrval = __qla83xx_clear_drv_presence(vha);\r\nqla83xx_idc_unlock(vha, 0);\r\nreturn rval;\r\n}\r\nstatic void\r\nqla83xx_need_reset_handler(scsi_qla_host_t *vha)\r\n{\r\nstruct qla_hw_data *ha = vha->hw;\r\nuint32_t drv_ack, drv_presence;\r\nunsigned long ack_timeout;\r\nack_timeout = jiffies + (ha->fcoe_reset_timeout * HZ);\r\nwhile (1) {\r\nqla83xx_rd_reg(vha, QLA83XX_IDC_DRIVER_ACK, &drv_ack);\r\nqla83xx_rd_reg(vha, QLA83XX_IDC_DRV_PRESENCE, &drv_presence);\r\nif ((drv_ack & drv_presence) == drv_presence)\r\nbreak;\r\nif (time_after_eq(jiffies, ack_timeout)) {\r\nql_log(ql_log_warn, vha, 0xb067,\r\n"RESET ACK TIMEOUT! drv_presence=0x%x "\r\n"drv_ack=0x%x\n", drv_presence, drv_ack);\r\nif (drv_ack != drv_presence)\r\nqla83xx_wr_reg(vha, QLA83XX_IDC_DRV_PRESENCE,\r\ndrv_ack);\r\nbreak;\r\n}\r\nqla83xx_idc_unlock(vha, 0);\r\nmsleep(1000);\r\nqla83xx_idc_lock(vha, 0);\r\n}\r\nqla83xx_wr_reg(vha, QLA83XX_IDC_DEV_STATE, QLA8XXX_DEV_COLD);\r\nql_log(ql_log_info, vha, 0xb068, "HW State: COLD/RE-INIT.\n");\r\n}\r\nstatic int\r\nqla83xx_device_bootstrap(scsi_qla_host_t *vha)\r\n{\r\nint rval = QLA_SUCCESS;\r\nuint32_t idc_control;\r\nqla83xx_wr_reg(vha, QLA83XX_IDC_DEV_STATE, QLA8XXX_DEV_INITIALIZING);\r\nql_log(ql_log_info, vha, 0xb069, "HW State: INITIALIZING.\n");\r\n__qla83xx_get_idc_control(vha, &idc_control);\r\nidc_control &= ~QLA83XX_IDC_GRACEFUL_RESET;\r\n__qla83xx_set_idc_control(vha, 0);\r\nqla83xx_idc_unlock(vha, 0);\r\nrval = qla83xx_restart_nic_firmware(vha);\r\nqla83xx_idc_lock(vha, 0);\r\nif (rval != QLA_SUCCESS) {\r\nql_log(ql_log_fatal, vha, 0xb06a,\r\n"Failed to restart NIC f/w.\n");\r\nqla83xx_wr_reg(vha, QLA83XX_IDC_DEV_STATE, QLA8XXX_DEV_FAILED);\r\nql_log(ql_log_info, vha, 0xb06b, "HW State: FAILED.\n");\r\n} else {\r\nql_dbg(ql_dbg_p3p, vha, 0xb06c,\r\n"Success in restarting nic f/w.\n");\r\nqla83xx_wr_reg(vha, QLA83XX_IDC_DEV_STATE, QLA8XXX_DEV_READY);\r\nql_log(ql_log_info, vha, 0xb06d, "HW State: READY.\n");\r\n}\r\nreturn rval;\r\n}\r\nint\r\nqla83xx_idc_state_handler(scsi_qla_host_t *base_vha)\r\n{\r\nstruct qla_hw_data *ha = base_vha->hw;\r\nint rval = QLA_SUCCESS;\r\nunsigned long dev_init_timeout;\r\nuint32_t dev_state;\r\ndev_init_timeout = jiffies + (ha->fcoe_dev_init_timeout * HZ);\r\nwhile (1) {\r\nif (time_after_eq(jiffies, dev_init_timeout)) {\r\nql_log(ql_log_warn, base_vha, 0xb06e,\r\n"Initialization TIMEOUT!\n");\r\nqla83xx_wr_reg(base_vha, QLA83XX_IDC_DEV_STATE,\r\nQLA8XXX_DEV_FAILED);\r\nql_log(ql_log_info, base_vha, 0xb06f,\r\n"HW State: FAILED.\n");\r\n}\r\nqla83xx_rd_reg(base_vha, QLA83XX_IDC_DEV_STATE, &dev_state);\r\nswitch (dev_state) {\r\ncase QLA8XXX_DEV_READY:\r\nif (ha->flags.nic_core_reset_owner)\r\nqla83xx_idc_audit(base_vha,\r\nIDC_AUDIT_COMPLETION);\r\nha->flags.nic_core_reset_owner = 0;\r\nql_dbg(ql_dbg_p3p, base_vha, 0xb070,\r\n"Reset_owner reset by 0x%x.\n",\r\nha->portnum);\r\ngoto exit;\r\ncase QLA8XXX_DEV_COLD:\r\nif (ha->flags.nic_core_reset_owner)\r\nrval = qla83xx_device_bootstrap(base_vha);\r\nelse {\r\nqla83xx_idc_unlock(base_vha, 0);\r\nmsleep(1000);\r\nqla83xx_idc_lock(base_vha, 0);\r\n}\r\nbreak;\r\ncase QLA8XXX_DEV_INITIALIZING:\r\nqla83xx_idc_unlock(base_vha, 0);\r\nmsleep(1000);\r\nqla83xx_idc_lock(base_vha, 0);\r\nbreak;\r\ncase QLA8XXX_DEV_NEED_RESET:\r\nif (!ql2xdontresethba && ha->flags.nic_core_reset_owner)\r\nqla83xx_need_reset_handler(base_vha);\r\nelse {\r\nqla83xx_idc_unlock(base_vha, 0);\r\nmsleep(1000);\r\nqla83xx_idc_lock(base_vha, 0);\r\n}\r\ndev_init_timeout = jiffies +\r\n(ha->fcoe_dev_init_timeout * HZ);\r\nbreak;\r\ncase QLA8XXX_DEV_NEED_QUIESCENT:\r\nqla83xx_idc_unlock(base_vha, 0);\r\nmsleep(1000);\r\nqla83xx_idc_lock(base_vha, 0);\r\nbreak;\r\ncase QLA8XXX_DEV_QUIESCENT:\r\nif (ha->flags.quiesce_owner)\r\ngoto exit;\r\nqla83xx_idc_unlock(base_vha, 0);\r\nmsleep(1000);\r\nqla83xx_idc_lock(base_vha, 0);\r\ndev_init_timeout = jiffies +\r\n(ha->fcoe_dev_init_timeout * HZ);\r\nbreak;\r\ncase QLA8XXX_DEV_FAILED:\r\nif (ha->flags.nic_core_reset_owner)\r\nqla83xx_idc_audit(base_vha,\r\nIDC_AUDIT_COMPLETION);\r\nha->flags.nic_core_reset_owner = 0;\r\n__qla83xx_clear_drv_presence(base_vha);\r\nqla83xx_idc_unlock(base_vha, 0);\r\nqla8xxx_dev_failed_handler(base_vha);\r\nrval = QLA_FUNCTION_FAILED;\r\nqla83xx_idc_lock(base_vha, 0);\r\ngoto exit;\r\ncase QLA8XXX_BAD_VALUE:\r\nqla83xx_idc_unlock(base_vha, 0);\r\nmsleep(1000);\r\nqla83xx_idc_lock(base_vha, 0);\r\nbreak;\r\ndefault:\r\nql_log(ql_log_warn, base_vha, 0xb071,\r\n"Unknown Device State: %x.\n", dev_state);\r\nqla83xx_idc_unlock(base_vha, 0);\r\nqla8xxx_dev_failed_handler(base_vha);\r\nrval = QLA_FUNCTION_FAILED;\r\nqla83xx_idc_lock(base_vha, 0);\r\ngoto exit;\r\n}\r\n}\r\nexit:\r\nreturn rval;\r\n}\r\nvoid\r\nqla2x00_disable_board_on_pci_error(struct work_struct *work)\r\n{\r\nstruct qla_hw_data *ha = container_of(work, struct qla_hw_data,\r\nboard_disable);\r\nstruct pci_dev *pdev = ha->pdev;\r\nscsi_qla_host_t *base_vha = pci_get_drvdata(ha->pdev);\r\nql_log(ql_log_warn, base_vha, 0x015b,\r\n"Disabling adapter.\n");\r\nset_bit(UNLOADING, &base_vha->dpc_flags);\r\nqla2x00_delete_all_vps(ha, base_vha);\r\nqla2x00_abort_all_cmds(base_vha, DID_NO_CONNECT << 16);\r\nqla2x00_dfs_remove(base_vha);\r\nqla84xx_put_chip(base_vha);\r\nif (base_vha->timer_active)\r\nqla2x00_stop_timer(base_vha);\r\nbase_vha->flags.online = 0;\r\nqla2x00_destroy_deferred_work(ha);\r\nqla2x00_free_sysfs_attr(base_vha, false);\r\nfc_remove_host(base_vha->host);\r\nscsi_remove_host(base_vha->host);\r\nbase_vha->flags.init_done = 0;\r\nqla25xx_delete_queues(base_vha);\r\nqla2x00_free_irqs(base_vha);\r\nqla2x00_free_fcports(base_vha);\r\nqla2x00_mem_free(ha);\r\nqla82xx_md_free(base_vha);\r\nqla2x00_free_queues(ha);\r\nqla2x00_unmap_iobases(ha);\r\npci_release_selected_regions(ha->pdev, ha->bars);\r\npci_disable_pcie_error_reporting(pdev);\r\npci_disable_device(pdev);\r\n}\r\nstatic int\r\nqla2x00_do_dpc(void *data)\r\n{\r\nscsi_qla_host_t *base_vha;\r\nstruct qla_hw_data *ha;\r\nha = (struct qla_hw_data *)data;\r\nbase_vha = pci_get_drvdata(ha->pdev);\r\nset_user_nice(current, MIN_NICE);\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nwhile (!kthread_should_stop()) {\r\nql_dbg(ql_dbg_dpc, base_vha, 0x4000,\r\n"DPC handler sleeping.\n");\r\nschedule();\r\nif (!base_vha->flags.init_done || ha->flags.mbox_busy)\r\ngoto end_loop;\r\nif (ha->flags.eeh_busy) {\r\nql_dbg(ql_dbg_dpc, base_vha, 0x4003,\r\n"eeh_busy=%d.\n", ha->flags.eeh_busy);\r\ngoto end_loop;\r\n}\r\nha->dpc_active = 1;\r\nql_dbg(ql_dbg_dpc + ql_dbg_verbose, base_vha, 0x4001,\r\n"DPC handler waking up, dpc_flags=0x%lx.\n",\r\nbase_vha->dpc_flags);\r\nqla2x00_do_work(base_vha);\r\nif (IS_P3P_TYPE(ha)) {\r\nif (IS_QLA8044(ha)) {\r\nif (test_and_clear_bit(ISP_UNRECOVERABLE,\r\n&base_vha->dpc_flags)) {\r\nqla8044_idc_lock(ha);\r\nqla8044_wr_direct(base_vha,\r\nQLA8044_CRB_DEV_STATE_INDEX,\r\nQLA8XXX_DEV_FAILED);\r\nqla8044_idc_unlock(ha);\r\nql_log(ql_log_info, base_vha, 0x4004,\r\n"HW State: FAILED.\n");\r\nqla8044_device_state_handler(base_vha);\r\ncontinue;\r\n}\r\n} else {\r\nif (test_and_clear_bit(ISP_UNRECOVERABLE,\r\n&base_vha->dpc_flags)) {\r\nqla82xx_idc_lock(ha);\r\nqla82xx_wr_32(ha, QLA82XX_CRB_DEV_STATE,\r\nQLA8XXX_DEV_FAILED);\r\nqla82xx_idc_unlock(ha);\r\nql_log(ql_log_info, base_vha, 0x0151,\r\n"HW State: FAILED.\n");\r\nqla82xx_device_state_handler(base_vha);\r\ncontinue;\r\n}\r\n}\r\nif (test_and_clear_bit(FCOE_CTX_RESET_NEEDED,\r\n&base_vha->dpc_flags)) {\r\nql_dbg(ql_dbg_dpc, base_vha, 0x4005,\r\n"FCoE context reset scheduled.\n");\r\nif (!(test_and_set_bit(ABORT_ISP_ACTIVE,\r\n&base_vha->dpc_flags))) {\r\nif (qla82xx_fcoe_ctx_reset(base_vha)) {\r\nset_bit(ISP_ABORT_NEEDED,\r\n&base_vha->dpc_flags);\r\n}\r\nclear_bit(ABORT_ISP_ACTIVE,\r\n&base_vha->dpc_flags);\r\n}\r\nql_dbg(ql_dbg_dpc, base_vha, 0x4006,\r\n"FCoE context reset end.\n");\r\n}\r\n} else if (IS_QLAFX00(ha)) {\r\nif (test_and_clear_bit(ISP_UNRECOVERABLE,\r\n&base_vha->dpc_flags)) {\r\nql_dbg(ql_dbg_dpc, base_vha, 0x4020,\r\n"Firmware Reset Recovery\n");\r\nif (qlafx00_reset_initialize(base_vha)) {\r\nif (!test_bit(UNLOADING,\r\n&base_vha->dpc_flags)) {\r\nset_bit(ISP_UNRECOVERABLE,\r\n&base_vha->dpc_flags);\r\nql_dbg(ql_dbg_dpc, base_vha,\r\n0x4021,\r\n"Reset Recovery Failed\n");\r\n}\r\n}\r\n}\r\nif (test_and_clear_bit(FX00_TARGET_SCAN,\r\n&base_vha->dpc_flags)) {\r\nql_dbg(ql_dbg_dpc, base_vha, 0x4022,\r\n"ISPFx00 Target Scan scheduled\n");\r\nif (qlafx00_rescan_isp(base_vha)) {\r\nif (!test_bit(UNLOADING,\r\n&base_vha->dpc_flags))\r\nset_bit(ISP_UNRECOVERABLE,\r\n&base_vha->dpc_flags);\r\nql_dbg(ql_dbg_dpc, base_vha, 0x401e,\r\n"ISPFx00 Target Scan Failed\n");\r\n}\r\nql_dbg(ql_dbg_dpc, base_vha, 0x401f,\r\n"ISPFx00 Target Scan End\n");\r\n}\r\nif (test_and_clear_bit(FX00_HOST_INFO_RESEND,\r\n&base_vha->dpc_flags)) {\r\nql_dbg(ql_dbg_dpc, base_vha, 0x4023,\r\n"ISPFx00 Host Info resend scheduled\n");\r\nqlafx00_fx_disc(base_vha,\r\n&base_vha->hw->mr.fcport,\r\nFXDISC_REG_HOST_INFO);\r\n}\r\n}\r\nif (test_and_clear_bit(ISP_ABORT_NEEDED,\r\n&base_vha->dpc_flags)) {\r\nql_dbg(ql_dbg_dpc, base_vha, 0x4007,\r\n"ISP abort scheduled.\n");\r\nif (!(test_and_set_bit(ABORT_ISP_ACTIVE,\r\n&base_vha->dpc_flags))) {\r\nif (ha->isp_ops->abort_isp(base_vha)) {\r\nset_bit(ISP_ABORT_NEEDED,\r\n&base_vha->dpc_flags);\r\n}\r\nclear_bit(ABORT_ISP_ACTIVE,\r\n&base_vha->dpc_flags);\r\n}\r\nql_dbg(ql_dbg_dpc, base_vha, 0x4008,\r\n"ISP abort end.\n");\r\n}\r\nif (test_and_clear_bit(FCPORT_UPDATE_NEEDED,\r\n&base_vha->dpc_flags)) {\r\nqla2x00_update_fcports(base_vha);\r\n}\r\nif (test_bit(SCR_PENDING, &base_vha->dpc_flags)) {\r\nint ret;\r\nret = qla2x00_send_change_request(base_vha, 0x3, 0);\r\nif (ret != QLA_SUCCESS)\r\nql_log(ql_log_warn, base_vha, 0x121,\r\n"Failed to enable receiving of RSCN "\r\n"requests: 0x%x.\n", ret);\r\nclear_bit(SCR_PENDING, &base_vha->dpc_flags);\r\n}\r\nif (IS_QLAFX00(ha))\r\ngoto loop_resync_check;\r\nif (test_bit(ISP_QUIESCE_NEEDED, &base_vha->dpc_flags)) {\r\nql_dbg(ql_dbg_dpc, base_vha, 0x4009,\r\n"Quiescence mode scheduled.\n");\r\nif (IS_P3P_TYPE(ha)) {\r\nif (IS_QLA82XX(ha))\r\nqla82xx_device_state_handler(base_vha);\r\nif (IS_QLA8044(ha))\r\nqla8044_device_state_handler(base_vha);\r\nclear_bit(ISP_QUIESCE_NEEDED,\r\n&base_vha->dpc_flags);\r\nif (!ha->flags.quiesce_owner) {\r\nqla2x00_perform_loop_resync(base_vha);\r\nif (IS_QLA82XX(ha)) {\r\nqla82xx_idc_lock(ha);\r\nqla82xx_clear_qsnt_ready(\r\nbase_vha);\r\nqla82xx_idc_unlock(ha);\r\n} else if (IS_QLA8044(ha)) {\r\nqla8044_idc_lock(ha);\r\nqla8044_clear_qsnt_ready(\r\nbase_vha);\r\nqla8044_idc_unlock(ha);\r\n}\r\n}\r\n} else {\r\nclear_bit(ISP_QUIESCE_NEEDED,\r\n&base_vha->dpc_flags);\r\nqla2x00_quiesce_io(base_vha);\r\n}\r\nql_dbg(ql_dbg_dpc, base_vha, 0x400a,\r\n"Quiescence mode end.\n");\r\n}\r\nif (test_and_clear_bit(RESET_MARKER_NEEDED,\r\n&base_vha->dpc_flags) &&\r\n(!(test_and_set_bit(RESET_ACTIVE, &base_vha->dpc_flags)))) {\r\nql_dbg(ql_dbg_dpc, base_vha, 0x400b,\r\n"Reset marker scheduled.\n");\r\nqla2x00_rst_aen(base_vha);\r\nclear_bit(RESET_ACTIVE, &base_vha->dpc_flags);\r\nql_dbg(ql_dbg_dpc, base_vha, 0x400c,\r\n"Reset marker end.\n");\r\n}\r\nif ((test_and_clear_bit(RELOGIN_NEEDED,\r\n&base_vha->dpc_flags)) &&\r\n!test_bit(LOOP_RESYNC_NEEDED, &base_vha->dpc_flags) &&\r\natomic_read(&base_vha->loop_state) != LOOP_DOWN) {\r\nql_dbg(ql_dbg_dpc, base_vha, 0x400d,\r\n"Relogin scheduled.\n");\r\nqla2x00_relogin(base_vha);\r\nql_dbg(ql_dbg_dpc, base_vha, 0x400e,\r\n"Relogin end.\n");\r\n}\r\nloop_resync_check:\r\nif (test_and_clear_bit(LOOP_RESYNC_NEEDED,\r\n&base_vha->dpc_flags)) {\r\nql_dbg(ql_dbg_dpc, base_vha, 0x400f,\r\n"Loop resync scheduled.\n");\r\nif (!(test_and_set_bit(LOOP_RESYNC_ACTIVE,\r\n&base_vha->dpc_flags))) {\r\nqla2x00_loop_resync(base_vha);\r\nclear_bit(LOOP_RESYNC_ACTIVE,\r\n&base_vha->dpc_flags);\r\n}\r\nql_dbg(ql_dbg_dpc, base_vha, 0x4010,\r\n"Loop resync end.\n");\r\n}\r\nif (IS_QLAFX00(ha))\r\ngoto intr_on_check;\r\nif (test_bit(NPIV_CONFIG_NEEDED, &base_vha->dpc_flags) &&\r\natomic_read(&base_vha->loop_state) == LOOP_READY) {\r\nclear_bit(NPIV_CONFIG_NEEDED, &base_vha->dpc_flags);\r\nqla2xxx_flash_npiv_conf(base_vha);\r\n}\r\nintr_on_check:\r\nif (!ha->interrupts_on)\r\nha->isp_ops->enable_intrs(ha);\r\nif (test_and_clear_bit(BEACON_BLINK_NEEDED,\r\n&base_vha->dpc_flags)) {\r\nif (ha->beacon_blink_led == 1)\r\nha->isp_ops->beacon_blink(base_vha);\r\n}\r\nif (!IS_QLAFX00(ha))\r\nqla2x00_do_dpc_all_vps(base_vha);\r\nha->dpc_active = 0;\r\nend_loop:\r\nset_current_state(TASK_INTERRUPTIBLE);\r\n}\r\n__set_current_state(TASK_RUNNING);\r\nql_dbg(ql_dbg_dpc, base_vha, 0x4011,\r\n"DPC handler exiting.\n");\r\nha->dpc_active = 0;\r\nqla2x00_abort_all_cmds(base_vha, DID_NO_CONNECT << 16);\r\nreturn 0;\r\n}\r\nvoid\r\nqla2xxx_wake_dpc(struct scsi_qla_host *vha)\r\n{\r\nstruct qla_hw_data *ha = vha->hw;\r\nstruct task_struct *t = ha->dpc_thread;\r\nif (!test_bit(UNLOADING, &vha->dpc_flags) && t)\r\nwake_up_process(t);\r\n}\r\nstatic void\r\nqla2x00_rst_aen(scsi_qla_host_t *vha)\r\n{\r\nif (vha->flags.online && !vha->flags.reset_active &&\r\n!atomic_read(&vha->loop_down_timer) &&\r\n!(test_bit(ABORT_ISP_ACTIVE, &vha->dpc_flags))) {\r\ndo {\r\nclear_bit(RESET_MARKER_NEEDED, &vha->dpc_flags);\r\nvha->marker_needed = 1;\r\n} while (!atomic_read(&vha->loop_down_timer) &&\r\n(test_bit(RESET_MARKER_NEEDED, &vha->dpc_flags)));\r\n}\r\n}\r\nvoid\r\nqla2x00_timer(scsi_qla_host_t *vha)\r\n{\r\nunsigned long cpu_flags = 0;\r\nint start_dpc = 0;\r\nint index;\r\nsrb_t *sp;\r\nuint16_t w;\r\nstruct qla_hw_data *ha = vha->hw;\r\nstruct req_que *req;\r\nif (ha->flags.eeh_busy) {\r\nql_dbg(ql_dbg_timer, vha, 0x6000,\r\n"EEH = %d, restarting timer.\n",\r\nha->flags.eeh_busy);\r\nqla2x00_restart_timer(vha, WATCH_INTERVAL);\r\nreturn;\r\n}\r\nif (!pci_channel_offline(ha->pdev)) {\r\npci_read_config_word(ha->pdev, PCI_VENDOR_ID, &w);\r\nqla2x00_check_reg16_for_disconnect(vha, w);\r\n}\r\nif (!vha->vp_idx && IS_P3P_TYPE(ha)) {\r\nif (test_bit(ISP_QUIESCE_NEEDED, &vha->dpc_flags))\r\nstart_dpc++;\r\nif (IS_QLA82XX(ha))\r\nqla82xx_watchdog(vha);\r\nelse if (IS_QLA8044(ha))\r\nqla8044_watchdog(vha);\r\n}\r\nif (!vha->vp_idx && IS_QLAFX00(ha))\r\nqlafx00_timer_routine(vha);\r\nif (atomic_read(&vha->loop_down_timer) > 0 &&\r\n!(test_bit(ABORT_ISP_ACTIVE, &vha->dpc_flags)) &&\r\n!(test_bit(FCOE_CTX_RESET_NEEDED, &vha->dpc_flags))\r\n&& vha->flags.online) {\r\nif (atomic_read(&vha->loop_down_timer) ==\r\nvha->loop_down_abort_time) {\r\nql_log(ql_log_info, vha, 0x6008,\r\n"Loop down - aborting the queues before time expires.\n");\r\nif (!IS_QLA2100(ha) && vha->link_down_timeout)\r\natomic_set(&vha->loop_state, LOOP_DEAD);\r\nif (!vha->vp_idx) {\r\nspin_lock_irqsave(&ha->hardware_lock,\r\ncpu_flags);\r\nreq = ha->req_q_map[0];\r\nfor (index = 1;\r\nindex < req->num_outstanding_cmds;\r\nindex++) {\r\nfc_port_t *sfcp;\r\nsp = req->outstanding_cmds[index];\r\nif (!sp)\r\ncontinue;\r\nif (sp->type != SRB_SCSI_CMD)\r\ncontinue;\r\nsfcp = sp->fcport;\r\nif (!(sfcp->flags & FCF_FCP2_DEVICE))\r\ncontinue;\r\nif (IS_QLA82XX(ha))\r\nset_bit(FCOE_CTX_RESET_NEEDED,\r\n&vha->dpc_flags);\r\nelse\r\nset_bit(ISP_ABORT_NEEDED,\r\n&vha->dpc_flags);\r\nbreak;\r\n}\r\nspin_unlock_irqrestore(&ha->hardware_lock,\r\ncpu_flags);\r\n}\r\nstart_dpc++;\r\n}\r\nif (atomic_dec_and_test(&vha->loop_down_timer) != 0) {\r\nif (!(vha->device_flags & DFLG_NO_CABLE)) {\r\nql_log(ql_log_warn, vha, 0x6009,\r\n"Loop down - aborting ISP.\n");\r\nif (IS_QLA82XX(ha))\r\nset_bit(FCOE_CTX_RESET_NEEDED,\r\n&vha->dpc_flags);\r\nelse\r\nset_bit(ISP_ABORT_NEEDED,\r\n&vha->dpc_flags);\r\n}\r\n}\r\nql_dbg(ql_dbg_timer, vha, 0x600a,\r\n"Loop down - seconds remaining %d.\n",\r\natomic_read(&vha->loop_down_timer));\r\n}\r\nif (!vha->vp_idx && (ha->beacon_blink_led == 1)) {\r\nif (!IS_P3P_TYPE(ha)) {\r\nset_bit(BEACON_BLINK_NEEDED, &vha->dpc_flags);\r\nstart_dpc++;\r\n}\r\n}\r\nif (!list_empty(&vha->work_list))\r\nstart_dpc++;\r\nif ((test_bit(ISP_ABORT_NEEDED, &vha->dpc_flags) ||\r\ntest_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags) ||\r\ntest_bit(FCPORT_UPDATE_NEEDED, &vha->dpc_flags) ||\r\nstart_dpc ||\r\ntest_bit(RESET_MARKER_NEEDED, &vha->dpc_flags) ||\r\ntest_bit(BEACON_BLINK_NEEDED, &vha->dpc_flags) ||\r\ntest_bit(ISP_UNRECOVERABLE, &vha->dpc_flags) ||\r\ntest_bit(FCOE_CTX_RESET_NEEDED, &vha->dpc_flags) ||\r\ntest_bit(VP_DPC_NEEDED, &vha->dpc_flags) ||\r\ntest_bit(RELOGIN_NEEDED, &vha->dpc_flags))) {\r\nql_dbg(ql_dbg_timer, vha, 0x600b,\r\n"isp_abort_needed=%d loop_resync_needed=%d "\r\n"fcport_update_needed=%d start_dpc=%d "\r\n"reset_marker_needed=%d",\r\ntest_bit(ISP_ABORT_NEEDED, &vha->dpc_flags),\r\ntest_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags),\r\ntest_bit(FCPORT_UPDATE_NEEDED, &vha->dpc_flags),\r\nstart_dpc,\r\ntest_bit(RESET_MARKER_NEEDED, &vha->dpc_flags));\r\nql_dbg(ql_dbg_timer, vha, 0x600c,\r\n"beacon_blink_needed=%d isp_unrecoverable=%d "\r\n"fcoe_ctx_reset_needed=%d vp_dpc_needed=%d "\r\n"relogin_needed=%d.\n",\r\ntest_bit(BEACON_BLINK_NEEDED, &vha->dpc_flags),\r\ntest_bit(ISP_UNRECOVERABLE, &vha->dpc_flags),\r\ntest_bit(FCOE_CTX_RESET_NEEDED, &vha->dpc_flags),\r\ntest_bit(VP_DPC_NEEDED, &vha->dpc_flags),\r\ntest_bit(RELOGIN_NEEDED, &vha->dpc_flags));\r\nqla2xxx_wake_dpc(vha);\r\n}\r\nqla2x00_restart_timer(vha, WATCH_INTERVAL);\r\n}\r\nstruct fw_blob *\r\nqla2x00_request_firmware(scsi_qla_host_t *vha)\r\n{\r\nstruct qla_hw_data *ha = vha->hw;\r\nstruct fw_blob *blob;\r\nif (IS_QLA2100(ha)) {\r\nblob = &qla_fw_blobs[FW_ISP21XX];\r\n} else if (IS_QLA2200(ha)) {\r\nblob = &qla_fw_blobs[FW_ISP22XX];\r\n} else if (IS_QLA2300(ha) || IS_QLA2312(ha) || IS_QLA6312(ha)) {\r\nblob = &qla_fw_blobs[FW_ISP2300];\r\n} else if (IS_QLA2322(ha) || IS_QLA6322(ha)) {\r\nblob = &qla_fw_blobs[FW_ISP2322];\r\n} else if (IS_QLA24XX_TYPE(ha)) {\r\nblob = &qla_fw_blobs[FW_ISP24XX];\r\n} else if (IS_QLA25XX(ha)) {\r\nblob = &qla_fw_blobs[FW_ISP25XX];\r\n} else if (IS_QLA81XX(ha)) {\r\nblob = &qla_fw_blobs[FW_ISP81XX];\r\n} else if (IS_QLA82XX(ha)) {\r\nblob = &qla_fw_blobs[FW_ISP82XX];\r\n} else if (IS_QLA2031(ha)) {\r\nblob = &qla_fw_blobs[FW_ISP2031];\r\n} else if (IS_QLA8031(ha)) {\r\nblob = &qla_fw_blobs[FW_ISP8031];\r\n} else if (IS_QLA27XX(ha)) {\r\nblob = &qla_fw_blobs[FW_ISP27XX];\r\n} else {\r\nreturn NULL;\r\n}\r\nmutex_lock(&qla_fw_lock);\r\nif (blob->fw)\r\ngoto out;\r\nif (request_firmware(&blob->fw, blob->name, &ha->pdev->dev)) {\r\nql_log(ql_log_warn, vha, 0x0063,\r\n"Failed to load firmware image (%s).\n", blob->name);\r\nblob->fw = NULL;\r\nblob = NULL;\r\ngoto out;\r\n}\r\nout:\r\nmutex_unlock(&qla_fw_lock);\r\nreturn blob;\r\n}\r\nstatic void\r\nqla2x00_release_firmware(void)\r\n{\r\nint idx;\r\nmutex_lock(&qla_fw_lock);\r\nfor (idx = 0; idx < FW_BLOBS; idx++)\r\nrelease_firmware(qla_fw_blobs[idx].fw);\r\nmutex_unlock(&qla_fw_lock);\r\n}\r\nstatic pci_ers_result_t\r\nqla2xxx_pci_error_detected(struct pci_dev *pdev, pci_channel_state_t state)\r\n{\r\nscsi_qla_host_t *vha = pci_get_drvdata(pdev);\r\nstruct qla_hw_data *ha = vha->hw;\r\nql_dbg(ql_dbg_aer, vha, 0x9000,\r\n"PCI error detected, state %x.\n", state);\r\nswitch (state) {\r\ncase pci_channel_io_normal:\r\nha->flags.eeh_busy = 0;\r\nreturn PCI_ERS_RESULT_CAN_RECOVER;\r\ncase pci_channel_io_frozen:\r\nha->flags.eeh_busy = 1;\r\nif (IS_QLA82XX(ha)) {\r\nha->flags.isp82xx_fw_hung = 1;\r\nql_dbg(ql_dbg_aer, vha, 0x9001, "Pci channel io frozen\n");\r\nqla82xx_clear_pending_mbx(vha);\r\n}\r\nqla2x00_free_irqs(vha);\r\npci_disable_device(pdev);\r\nqla2x00_abort_all_cmds(vha, DID_RESET << 16);\r\nreturn PCI_ERS_RESULT_NEED_RESET;\r\ncase pci_channel_io_perm_failure:\r\nha->flags.pci_channel_io_perm_failure = 1;\r\nqla2x00_abort_all_cmds(vha, DID_NO_CONNECT << 16);\r\nreturn PCI_ERS_RESULT_DISCONNECT;\r\n}\r\nreturn PCI_ERS_RESULT_NEED_RESET;\r\n}\r\nstatic pci_ers_result_t\r\nqla2xxx_pci_mmio_enabled(struct pci_dev *pdev)\r\n{\r\nint risc_paused = 0;\r\nuint32_t stat;\r\nunsigned long flags;\r\nscsi_qla_host_t *base_vha = pci_get_drvdata(pdev);\r\nstruct qla_hw_data *ha = base_vha->hw;\r\nstruct device_reg_2xxx __iomem *reg = &ha->iobase->isp;\r\nstruct device_reg_24xx __iomem *reg24 = &ha->iobase->isp24;\r\nif (IS_QLA82XX(ha))\r\nreturn PCI_ERS_RESULT_RECOVERED;\r\nspin_lock_irqsave(&ha->hardware_lock, flags);\r\nif (IS_QLA2100(ha) || IS_QLA2200(ha)){\r\nstat = RD_REG_DWORD(&reg->hccr);\r\nif (stat & HCCR_RISC_PAUSE)\r\nrisc_paused = 1;\r\n} else if (IS_QLA23XX(ha)) {\r\nstat = RD_REG_DWORD(&reg->u.isp2300.host_status);\r\nif (stat & HSR_RISC_PAUSED)\r\nrisc_paused = 1;\r\n} else if (IS_FWI2_CAPABLE(ha)) {\r\nstat = RD_REG_DWORD(&reg24->host_status);\r\nif (stat & HSRX_RISC_PAUSED)\r\nrisc_paused = 1;\r\n}\r\nspin_unlock_irqrestore(&ha->hardware_lock, flags);\r\nif (risc_paused) {\r\nql_log(ql_log_info, base_vha, 0x9003,\r\n"RISC paused -- mmio_enabled, Dumping firmware.\n");\r\nha->isp_ops->fw_dump(base_vha, 0);\r\nreturn PCI_ERS_RESULT_NEED_RESET;\r\n} else\r\nreturn PCI_ERS_RESULT_RECOVERED;\r\n}\r\nstatic uint32_t\r\nqla82xx_error_recovery(scsi_qla_host_t *base_vha)\r\n{\r\nuint32_t rval = QLA_FUNCTION_FAILED;\r\nuint32_t drv_active = 0;\r\nstruct qla_hw_data *ha = base_vha->hw;\r\nint fn;\r\nstruct pci_dev *other_pdev = NULL;\r\nql_dbg(ql_dbg_aer, base_vha, 0x9006,\r\n"Entered %s.\n", __func__);\r\nset_bit(ABORT_ISP_ACTIVE, &base_vha->dpc_flags);\r\nif (base_vha->flags.online) {\r\nqla2x00_abort_isp_cleanup(base_vha);\r\n}\r\nfn = PCI_FUNC(ha->pdev->devfn);\r\nwhile (fn > 0) {\r\nfn--;\r\nql_dbg(ql_dbg_aer, base_vha, 0x9007,\r\n"Finding pci device at function = 0x%x.\n", fn);\r\nother_pdev =\r\npci_get_domain_bus_and_slot(pci_domain_nr(ha->pdev->bus),\r\nha->pdev->bus->number, PCI_DEVFN(PCI_SLOT(ha->pdev->devfn),\r\nfn));\r\nif (!other_pdev)\r\ncontinue;\r\nif (atomic_read(&other_pdev->enable_cnt)) {\r\nql_dbg(ql_dbg_aer, base_vha, 0x9008,\r\n"Found PCI func available and enable at 0x%x.\n",\r\nfn);\r\npci_dev_put(other_pdev);\r\nbreak;\r\n}\r\npci_dev_put(other_pdev);\r\n}\r\nif (!fn) {\r\nql_dbg(ql_dbg_aer, base_vha, 0x9009,\r\n"This devfn is reset owner = 0x%x.\n",\r\nha->pdev->devfn);\r\nqla82xx_idc_lock(ha);\r\nqla82xx_wr_32(ha, QLA82XX_CRB_DEV_STATE,\r\nQLA8XXX_DEV_INITIALIZING);\r\nqla82xx_wr_32(ha, QLA82XX_CRB_DRV_IDC_VERSION,\r\nQLA82XX_IDC_VERSION);\r\ndrv_active = qla82xx_rd_32(ha, QLA82XX_CRB_DRV_ACTIVE);\r\nql_dbg(ql_dbg_aer, base_vha, 0x900a,\r\n"drv_active = 0x%x.\n", drv_active);\r\nqla82xx_idc_unlock(ha);\r\nif (drv_active)\r\nrval = qla82xx_start_firmware(base_vha);\r\nelse\r\nrval = QLA_SUCCESS;\r\nqla82xx_idc_lock(ha);\r\nif (rval != QLA_SUCCESS) {\r\nql_log(ql_log_info, base_vha, 0x900b,\r\n"HW State: FAILED.\n");\r\nqla82xx_clear_drv_active(ha);\r\nqla82xx_wr_32(ha, QLA82XX_CRB_DEV_STATE,\r\nQLA8XXX_DEV_FAILED);\r\n} else {\r\nql_log(ql_log_info, base_vha, 0x900c,\r\n"HW State: READY.\n");\r\nqla82xx_wr_32(ha, QLA82XX_CRB_DEV_STATE,\r\nQLA8XXX_DEV_READY);\r\nqla82xx_idc_unlock(ha);\r\nha->flags.isp82xx_fw_hung = 0;\r\nrval = qla82xx_restart_isp(base_vha);\r\nqla82xx_idc_lock(ha);\r\nqla82xx_wr_32(ha, QLA82XX_CRB_DRV_STATE, 0);\r\nqla82xx_set_drv_active(base_vha);\r\n}\r\nqla82xx_idc_unlock(ha);\r\n} else {\r\nql_dbg(ql_dbg_aer, base_vha, 0x900d,\r\n"This devfn is not reset owner = 0x%x.\n",\r\nha->pdev->devfn);\r\nif ((qla82xx_rd_32(ha, QLA82XX_CRB_DEV_STATE) ==\r\nQLA8XXX_DEV_READY)) {\r\nha->flags.isp82xx_fw_hung = 0;\r\nrval = qla82xx_restart_isp(base_vha);\r\nqla82xx_idc_lock(ha);\r\nqla82xx_set_drv_active(base_vha);\r\nqla82xx_idc_unlock(ha);\r\n}\r\n}\r\nclear_bit(ABORT_ISP_ACTIVE, &base_vha->dpc_flags);\r\nreturn rval;\r\n}\r\nstatic pci_ers_result_t\r\nqla2xxx_pci_slot_reset(struct pci_dev *pdev)\r\n{\r\npci_ers_result_t ret = PCI_ERS_RESULT_DISCONNECT;\r\nscsi_qla_host_t *base_vha = pci_get_drvdata(pdev);\r\nstruct qla_hw_data *ha = base_vha->hw;\r\nstruct rsp_que *rsp;\r\nint rc, retries = 10;\r\nql_dbg(ql_dbg_aer, base_vha, 0x9004,\r\n"Slot Reset.\n");\r\npdev->error_state = pci_channel_io_normal;\r\npci_restore_state(pdev);\r\npci_save_state(pdev);\r\nif (ha->mem_only)\r\nrc = pci_enable_device_mem(pdev);\r\nelse\r\nrc = pci_enable_device(pdev);\r\nif (rc) {\r\nql_log(ql_log_warn, base_vha, 0x9005,\r\n"Can't re-enable PCI device after reset.\n");\r\ngoto exit_slot_reset;\r\n}\r\nrsp = ha->rsp_q_map[0];\r\nif (qla2x00_request_irqs(ha, rsp))\r\ngoto exit_slot_reset;\r\nif (ha->isp_ops->pci_config(base_vha))\r\ngoto exit_slot_reset;\r\nif (IS_QLA82XX(ha)) {\r\nif (qla82xx_error_recovery(base_vha) == QLA_SUCCESS) {\r\nret = PCI_ERS_RESULT_RECOVERED;\r\ngoto exit_slot_reset;\r\n} else\r\ngoto exit_slot_reset;\r\n}\r\nwhile (ha->flags.mbox_busy && retries--)\r\nmsleep(1000);\r\nset_bit(ABORT_ISP_ACTIVE, &base_vha->dpc_flags);\r\nif (ha->isp_ops->abort_isp(base_vha) == QLA_SUCCESS)\r\nret = PCI_ERS_RESULT_RECOVERED;\r\nclear_bit(ABORT_ISP_ACTIVE, &base_vha->dpc_flags);\r\nexit_slot_reset:\r\nql_dbg(ql_dbg_aer, base_vha, 0x900e,\r\n"slot_reset return %x.\n", ret);\r\nreturn ret;\r\n}\r\nstatic void\r\nqla2xxx_pci_resume(struct pci_dev *pdev)\r\n{\r\nscsi_qla_host_t *base_vha = pci_get_drvdata(pdev);\r\nstruct qla_hw_data *ha = base_vha->hw;\r\nint ret;\r\nql_dbg(ql_dbg_aer, base_vha, 0x900f,\r\n"pci_resume.\n");\r\nret = qla2x00_wait_for_hba_online(base_vha);\r\nif (ret != QLA_SUCCESS) {\r\nql_log(ql_log_fatal, base_vha, 0x9002,\r\n"The device failed to resume I/O from slot/link_reset.\n");\r\n}\r\npci_cleanup_aer_uncorrect_error_status(pdev);\r\nha->flags.eeh_busy = 0;\r\n}\r\nstatic void\r\nqla83xx_disable_laser(scsi_qla_host_t *vha)\r\n{\r\nuint32_t reg, data, fn;\r\nstruct qla_hw_data *ha = vha->hw;\r\nstruct device_reg_24xx __iomem *isp_reg = &ha->iobase->isp24;\r\nql_dbg(ql_dbg_init, vha, 0x004b,\r\n"Disabling Laser for hba: %p\n", vha);\r\nfn = (RD_REG_DWORD(&isp_reg->ctrl_status) &\r\n(BIT_15|BIT_14|BIT_13|BIT_12));\r\nfn = (fn >> 12);\r\nif (fn & 1)\r\nreg = PORT_1_2031;\r\nelse\r\nreg = PORT_0_2031;\r\ndata = LASER_OFF_2031;\r\nqla83xx_wr_reg(vha, reg, data);\r\n}\r\nstatic int __init\r\nqla2x00_module_init(void)\r\n{\r\nint ret = 0;\r\nsrb_cachep = kmem_cache_create("qla2xxx_srbs", sizeof(srb_t), 0,\r\nSLAB_HWCACHE_ALIGN, NULL);\r\nif (srb_cachep == NULL) {\r\nql_log(ql_log_fatal, NULL, 0x0001,\r\n"Unable to allocate SRB cache...Failing load!.\n");\r\nreturn -ENOMEM;\r\n}\r\nret = qlt_init();\r\nif (ret < 0) {\r\nkmem_cache_destroy(srb_cachep);\r\nreturn ret;\r\n} else if (ret > 0) {\r\nqla2xxx_transport_functions.disable_target_scan = 1;\r\nqla2xxx_transport_vport_functions.disable_target_scan = 1;\r\n}\r\nstrcpy(qla2x00_version_str, QLA2XXX_VERSION);\r\nif (ql2xextended_error_logging)\r\nstrcat(qla2x00_version_str, "-debug");\r\nqla2xxx_transport_template =\r\nfc_attach_transport(&qla2xxx_transport_functions);\r\nif (!qla2xxx_transport_template) {\r\nkmem_cache_destroy(srb_cachep);\r\nql_log(ql_log_fatal, NULL, 0x0002,\r\n"fc_attach_transport failed...Failing load!.\n");\r\nqlt_exit();\r\nreturn -ENODEV;\r\n}\r\napidev_major = register_chrdev(0, QLA2XXX_APIDEV, &apidev_fops);\r\nif (apidev_major < 0) {\r\nql_log(ql_log_fatal, NULL, 0x0003,\r\n"Unable to register char device %s.\n", QLA2XXX_APIDEV);\r\n}\r\nqla2xxx_transport_vport_template =\r\nfc_attach_transport(&qla2xxx_transport_vport_functions);\r\nif (!qla2xxx_transport_vport_template) {\r\nkmem_cache_destroy(srb_cachep);\r\nqlt_exit();\r\nfc_release_transport(qla2xxx_transport_template);\r\nql_log(ql_log_fatal, NULL, 0x0004,\r\n"fc_attach_transport vport failed...Failing load!.\n");\r\nreturn -ENODEV;\r\n}\r\nql_log(ql_log_info, NULL, 0x0005,\r\n"QLogic Fibre Channel HBA Driver: %s.\n",\r\nqla2x00_version_str);\r\nret = pci_register_driver(&qla2xxx_pci_driver);\r\nif (ret) {\r\nkmem_cache_destroy(srb_cachep);\r\nqlt_exit();\r\nfc_release_transport(qla2xxx_transport_template);\r\nfc_release_transport(qla2xxx_transport_vport_template);\r\nql_log(ql_log_fatal, NULL, 0x0006,\r\n"pci_register_driver failed...ret=%d Failing load!.\n",\r\nret);\r\n}\r\nreturn ret;\r\n}\r\nstatic void __exit\r\nqla2x00_module_exit(void)\r\n{\r\nunregister_chrdev(apidev_major, QLA2XXX_APIDEV);\r\npci_unregister_driver(&qla2xxx_pci_driver);\r\nqla2x00_release_firmware();\r\nkmem_cache_destroy(srb_cachep);\r\nqlt_exit();\r\nif (ctx_cachep)\r\nkmem_cache_destroy(ctx_cachep);\r\nfc_release_transport(qla2xxx_transport_template);\r\nfc_release_transport(qla2xxx_transport_vport_template);\r\n}
