int qib_pcie_init(struct pci_dev *pdev, const struct pci_device_id *ent)\r\n{\r\nint ret;\r\nret = pci_enable_device(pdev);\r\nif (ret) {\r\nqib_early_err(&pdev->dev, "pci enable failed: error %d\n",\r\n-ret);\r\ngoto done;\r\n}\r\nret = pci_request_regions(pdev, QIB_DRV_NAME);\r\nif (ret) {\r\nqib_devinfo(pdev, "pci_request_regions fails: err %d\n", -ret);\r\ngoto bail;\r\n}\r\nret = pci_set_dma_mask(pdev, DMA_BIT_MASK(64));\r\nif (ret) {\r\nret = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (ret) {\r\nqib_devinfo(pdev, "Unable to set DMA mask: %d\n", ret);\r\ngoto bail;\r\n}\r\nret = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));\r\n} else\r\nret = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));\r\nif (ret) {\r\nqib_early_err(&pdev->dev,\r\n"Unable to set DMA consistent mask: %d\n", ret);\r\ngoto bail;\r\n}\r\npci_set_master(pdev);\r\nret = pci_enable_pcie_error_reporting(pdev);\r\nif (ret) {\r\nqib_early_err(&pdev->dev,\r\n"Unable to enable pcie error reporting: %d\n",\r\nret);\r\nret = 0;\r\n}\r\ngoto done;\r\nbail:\r\npci_disable_device(pdev);\r\npci_release_regions(pdev);\r\ndone:\r\nreturn ret;\r\n}\r\nint qib_pcie_ddinit(struct qib_devdata *dd, struct pci_dev *pdev,\r\nconst struct pci_device_id *ent)\r\n{\r\nunsigned long len;\r\nresource_size_t addr;\r\ndd->pcidev = pdev;\r\npci_set_drvdata(pdev, dd);\r\naddr = pci_resource_start(pdev, 0);\r\nlen = pci_resource_len(pdev, 0);\r\n#if defined(__powerpc__)\r\ndd->kregbase = __ioremap(addr, len, _PAGE_NO_CACHE | _PAGE_WRITETHRU);\r\n#else\r\ndd->kregbase = ioremap_nocache(addr, len);\r\n#endif\r\nif (!dd->kregbase)\r\nreturn -ENOMEM;\r\ndd->kregend = (u64 __iomem *)((void __iomem *) dd->kregbase + len);\r\ndd->physaddr = addr;\r\ndd->pcibar0 = addr;\r\ndd->pcibar1 = addr >> 32;\r\ndd->deviceid = ent->device;\r\ndd->vendorid = ent->vendor;\r\nreturn 0;\r\n}\r\nvoid qib_pcie_ddcleanup(struct qib_devdata *dd)\r\n{\r\nu64 __iomem *base = (void __iomem *) dd->kregbase;\r\ndd->kregbase = NULL;\r\niounmap(base);\r\nif (dd->piobase)\r\niounmap(dd->piobase);\r\nif (dd->userbase)\r\niounmap(dd->userbase);\r\nif (dd->piovl15base)\r\niounmap(dd->piovl15base);\r\npci_disable_device(dd->pcidev);\r\npci_release_regions(dd->pcidev);\r\npci_set_drvdata(dd->pcidev, NULL);\r\n}\r\nstatic void qib_msix_setup(struct qib_devdata *dd, int pos, u32 *msixcnt,\r\nstruct qib_msix_entry *qib_msix_entry)\r\n{\r\nint ret;\r\nu32 tabsize = 0;\r\nu16 msix_flags;\r\nstruct msix_entry *msix_entry;\r\nint i;\r\nmsix_entry = kmalloc(*msixcnt * sizeof(*msix_entry), GFP_KERNEL);\r\nif (!msix_entry) {\r\nret = -ENOMEM;\r\ngoto do_intx;\r\n}\r\nfor (i = 0; i < *msixcnt; i++)\r\nmsix_entry[i] = qib_msix_entry[i].msix;\r\npci_read_config_word(dd->pcidev, pos + PCI_MSIX_FLAGS, &msix_flags);\r\ntabsize = 1 + (msix_flags & PCI_MSIX_FLAGS_QSIZE);\r\nif (tabsize > *msixcnt)\r\ntabsize = *msixcnt;\r\nret = pci_enable_msix(dd->pcidev, msix_entry, tabsize);\r\nif (ret > 0) {\r\ntabsize = ret;\r\nret = pci_enable_msix(dd->pcidev, msix_entry, tabsize);\r\n}\r\ndo_intx:\r\nif (ret) {\r\nqib_dev_err(dd, "pci_enable_msix %d vectors failed: %d, "\r\n"falling back to INTx\n", tabsize, ret);\r\ntabsize = 0;\r\n}\r\nfor (i = 0; i < tabsize; i++)\r\nqib_msix_entry[i].msix = msix_entry[i];\r\nkfree(msix_entry);\r\n*msixcnt = tabsize;\r\nif (ret)\r\nqib_enable_intx(dd->pcidev);\r\n}\r\nstatic int qib_msi_setup(struct qib_devdata *dd, int pos)\r\n{\r\nstruct pci_dev *pdev = dd->pcidev;\r\nu16 control;\r\nint ret;\r\nret = pci_enable_msi(pdev);\r\nif (ret)\r\nqib_dev_err(dd, "pci_enable_msi failed: %d, "\r\n"interrupts may not work\n", ret);\r\npci_read_config_dword(pdev, pos + PCI_MSI_ADDRESS_LO,\r\n&dd->msi_lo);\r\npci_read_config_dword(pdev, pos + PCI_MSI_ADDRESS_HI,\r\n&dd->msi_hi);\r\npci_read_config_word(pdev, pos + PCI_MSI_FLAGS, &control);\r\npci_read_config_word(pdev, pos + ((control & PCI_MSI_FLAGS_64BIT)\r\n? 12 : 8),\r\n&dd->msi_data);\r\nreturn ret;\r\n}\r\nint qib_pcie_params(struct qib_devdata *dd, u32 minw, u32 *nent,\r\nstruct qib_msix_entry *entry)\r\n{\r\nu16 linkstat, speed;\r\nint pos = 0, pose, ret = 1;\r\npose = pci_pcie_cap(dd->pcidev);\r\nif (!pose) {\r\nqib_dev_err(dd, "Can't find PCI Express capability!\n");\r\ndd->lbus_width = 1;\r\ndd->lbus_speed = 2500;\r\ngoto bail;\r\n}\r\npos = pci_find_capability(dd->pcidev, PCI_CAP_ID_MSIX);\r\nif (nent && *nent && pos) {\r\nqib_msix_setup(dd, pos, nent, entry);\r\nret = 0;\r\n} else {\r\npos = pci_find_capability(dd->pcidev, PCI_CAP_ID_MSI);\r\nif (pos)\r\nret = qib_msi_setup(dd, pos);\r\nelse\r\nqib_dev_err(dd, "No PCI MSI or MSIx capability!\n");\r\n}\r\nif (!pos)\r\nqib_enable_intx(dd->pcidev);\r\npci_read_config_word(dd->pcidev, pose + PCI_EXP_LNKSTA, &linkstat);\r\nspeed = linkstat & 0xf;\r\nlinkstat >>= 4;\r\nlinkstat &= 0x1f;\r\ndd->lbus_width = linkstat;\r\nswitch (speed) {\r\ncase 1:\r\ndd->lbus_speed = 2500;\r\nbreak;\r\ncase 2:\r\ndd->lbus_speed = 5000;\r\nbreak;\r\ndefault:\r\ndd->lbus_speed = 2500;\r\nbreak;\r\n}\r\nif (minw && linkstat < minw)\r\nqib_dev_err(dd,\r\n"PCIe width %u (x%u HCA), performance reduced\n",\r\nlinkstat, minw);\r\nqib_tune_pcie_caps(dd);\r\nqib_tune_pcie_coalesce(dd);\r\nbail:\r\nsnprintf(dd->lbus_info, sizeof(dd->lbus_info),\r\n"PCIe,%uMHz,x%u\n", dd->lbus_speed, dd->lbus_width);\r\nreturn ret;\r\n}\r\nint qib_reinit_intr(struct qib_devdata *dd)\r\n{\r\nint pos;\r\nu16 control;\r\nint ret = 0;\r\nif (!dd->msi_lo)\r\ngoto bail;\r\npos = pci_find_capability(dd->pcidev, PCI_CAP_ID_MSI);\r\nif (!pos) {\r\nqib_dev_err(dd, "Can't find MSI capability, "\r\n"can't restore MSI settings\n");\r\nret = 0;\r\ngoto bail;\r\n}\r\npci_write_config_dword(dd->pcidev, pos + PCI_MSI_ADDRESS_LO,\r\ndd->msi_lo);\r\npci_write_config_dword(dd->pcidev, pos + PCI_MSI_ADDRESS_HI,\r\ndd->msi_hi);\r\npci_read_config_word(dd->pcidev, pos + PCI_MSI_FLAGS, &control);\r\nif (!(control & PCI_MSI_FLAGS_ENABLE)) {\r\ncontrol |= PCI_MSI_FLAGS_ENABLE;\r\npci_write_config_word(dd->pcidev, pos + PCI_MSI_FLAGS,\r\ncontrol);\r\n}\r\npci_write_config_word(dd->pcidev, pos +\r\n((control & PCI_MSI_FLAGS_64BIT) ? 12 : 8),\r\ndd->msi_data);\r\nret = 1;\r\nbail:\r\nif (!ret && (dd->flags & QIB_HAS_INTX)) {\r\nqib_enable_intx(dd->pcidev);\r\nret = 1;\r\n}\r\npci_set_master(dd->pcidev);\r\nreturn ret;\r\n}\r\nvoid qib_nomsi(struct qib_devdata *dd)\r\n{\r\ndd->msi_lo = 0;\r\npci_disable_msi(dd->pcidev);\r\n}\r\nvoid qib_nomsix(struct qib_devdata *dd)\r\n{\r\npci_disable_msix(dd->pcidev);\r\n}\r\nvoid qib_enable_intx(struct pci_dev *pdev)\r\n{\r\nu16 cw, new;\r\nint pos;\r\npci_read_config_word(pdev, PCI_COMMAND, &cw);\r\nnew = cw & ~PCI_COMMAND_INTX_DISABLE;\r\nif (new != cw)\r\npci_write_config_word(pdev, PCI_COMMAND, new);\r\npos = pci_find_capability(pdev, PCI_CAP_ID_MSI);\r\nif (pos) {\r\npci_read_config_word(pdev, pos + PCI_MSI_FLAGS, &cw);\r\nnew = cw & ~PCI_MSI_FLAGS_ENABLE;\r\nif (new != cw)\r\npci_write_config_word(pdev, pos + PCI_MSI_FLAGS, new);\r\n}\r\npos = pci_find_capability(pdev, PCI_CAP_ID_MSIX);\r\nif (pos) {\r\npci_read_config_word(pdev, pos + PCI_MSIX_FLAGS, &cw);\r\nnew = cw & ~PCI_MSIX_FLAGS_ENABLE;\r\nif (new != cw)\r\npci_write_config_word(pdev, pos + PCI_MSIX_FLAGS, new);\r\n}\r\n}\r\nvoid qib_pcie_getcmd(struct qib_devdata *dd, u16 *cmd, u8 *iline, u8 *cline)\r\n{\r\npci_read_config_word(dd->pcidev, PCI_COMMAND, cmd);\r\npci_read_config_byte(dd->pcidev, PCI_INTERRUPT_LINE, iline);\r\npci_read_config_byte(dd->pcidev, PCI_CACHE_LINE_SIZE, cline);\r\n}\r\nvoid qib_pcie_reenable(struct qib_devdata *dd, u16 cmd, u8 iline, u8 cline)\r\n{\r\nint r;\r\nr = pci_write_config_dword(dd->pcidev, PCI_BASE_ADDRESS_0,\r\ndd->pcibar0);\r\nif (r)\r\nqib_dev_err(dd, "rewrite of BAR0 failed: %d\n", r);\r\nr = pci_write_config_dword(dd->pcidev, PCI_BASE_ADDRESS_1,\r\ndd->pcibar1);\r\nif (r)\r\nqib_dev_err(dd, "rewrite of BAR1 failed: %d\n", r);\r\npci_write_config_word(dd->pcidev, PCI_COMMAND, cmd);\r\npci_write_config_byte(dd->pcidev, PCI_INTERRUPT_LINE, iline);\r\npci_write_config_byte(dd->pcidev, PCI_CACHE_LINE_SIZE, cline);\r\nr = pci_enable_device(dd->pcidev);\r\nif (r)\r\nqib_dev_err(dd, "pci_enable_device failed after "\r\n"reset: %d\n", r);\r\n}\r\nstatic int fld2val(int wd, int mask)\r\n{\r\nint lsbmask;\r\nif (!mask)\r\nreturn 0;\r\nwd &= mask;\r\nlsbmask = mask ^ (mask & (mask - 1));\r\nwd /= lsbmask;\r\nreturn wd;\r\n}\r\nstatic int val2fld(int wd, int mask)\r\n{\r\nint lsbmask;\r\nif (!mask)\r\nreturn 0;\r\nlsbmask = mask ^ (mask & (mask - 1));\r\nwd *= lsbmask;\r\nreturn wd;\r\n}\r\nstatic int qib_tune_pcie_coalesce(struct qib_devdata *dd)\r\n{\r\nint r;\r\nstruct pci_dev *parent;\r\nint ppos;\r\nu16 devid;\r\nu32 mask, bits, val;\r\nif (!qib_pcie_coalesce)\r\nreturn 0;\r\nparent = dd->pcidev->bus->self;\r\nif (parent->bus->parent) {\r\nqib_devinfo(dd->pcidev, "Parent not root\n");\r\nreturn 1;\r\n}\r\nppos = pci_pcie_cap(parent);\r\nif (!ppos)\r\nreturn 1;\r\nif (parent->vendor != 0x8086)\r\nreturn 1;\r\ndevid = parent->device;\r\nif (devid >= 0x25e2 && devid <= 0x25fa) {\r\nif (parent->revision <= 0xb2)\r\nbits = 1U << 10;\r\nelse\r\nbits = 7U << 10;\r\nmask = (3U << 24) | (7U << 10);\r\n} else if (devid >= 0x65e2 && devid <= 0x65fa) {\r\nbits = 1U << 10;\r\nmask = (3U << 24) | (7U << 10);\r\n} else if (devid >= 0x4021 && devid <= 0x402e) {\r\nbits = 7U << 10;\r\nmask = 7U << 10;\r\n} else if (devid >= 0x3604 && devid <= 0x360a) {\r\nbits = 7U << 10;\r\nmask = (3U << 24) | (7U << 10);\r\n} else {\r\nreturn 1;\r\n}\r\npci_read_config_dword(parent, 0x48, &val);\r\nval &= ~mask;\r\nval |= bits;\r\nr = pci_write_config_dword(parent, 0x48, val);\r\nreturn 0;\r\n}\r\nstatic int qib_tune_pcie_caps(struct qib_devdata *dd)\r\n{\r\nint ret = 1;\r\nstruct pci_dev *parent;\r\nint ppos, epos;\r\nu16 pcaps, pctl, ecaps, ectl;\r\nint rc_sup, ep_sup;\r\nint rc_cur, ep_cur;\r\nparent = dd->pcidev->bus->self;\r\nif (parent->bus->parent) {\r\nqib_devinfo(dd->pcidev, "Parent not root\n");\r\ngoto bail;\r\n}\r\nppos = pci_pcie_cap(parent);\r\nif (ppos) {\r\npci_read_config_word(parent, ppos + PCI_EXP_DEVCAP, &pcaps);\r\npci_read_config_word(parent, ppos + PCI_EXP_DEVCTL, &pctl);\r\n} else\r\ngoto bail;\r\nepos = pci_pcie_cap(dd->pcidev);\r\nif (epos) {\r\npci_read_config_word(dd->pcidev, epos + PCI_EXP_DEVCAP, &ecaps);\r\npci_read_config_word(dd->pcidev, epos + PCI_EXP_DEVCTL, &ectl);\r\n} else\r\ngoto bail;\r\nret = 0;\r\nrc_sup = fld2val(pcaps, PCI_EXP_DEVCAP_PAYLOAD);\r\nep_sup = fld2val(ecaps, PCI_EXP_DEVCAP_PAYLOAD);\r\nif (rc_sup > ep_sup)\r\nrc_sup = ep_sup;\r\nrc_cur = fld2val(pctl, PCI_EXP_DEVCTL_PAYLOAD);\r\nep_cur = fld2val(ectl, PCI_EXP_DEVCTL_PAYLOAD);\r\nif (rc_sup > (qib_pcie_caps & 7))\r\nrc_sup = qib_pcie_caps & 7;\r\nif (rc_sup > rc_cur) {\r\nrc_cur = rc_sup;\r\npctl = (pctl & ~PCI_EXP_DEVCTL_PAYLOAD) |\r\nval2fld(rc_cur, PCI_EXP_DEVCTL_PAYLOAD);\r\npci_write_config_word(parent, ppos + PCI_EXP_DEVCTL, pctl);\r\n}\r\nif (rc_sup > ep_cur) {\r\nep_cur = rc_sup;\r\nectl = (ectl & ~PCI_EXP_DEVCTL_PAYLOAD) |\r\nval2fld(ep_cur, PCI_EXP_DEVCTL_PAYLOAD);\r\npci_write_config_word(dd->pcidev, epos + PCI_EXP_DEVCTL, ectl);\r\n}\r\nrc_sup = 5;\r\nif (rc_sup > ((qib_pcie_caps >> 4) & 7))\r\nrc_sup = (qib_pcie_caps >> 4) & 7;\r\nrc_cur = fld2val(pctl, PCI_EXP_DEVCTL_READRQ);\r\nep_cur = fld2val(ectl, PCI_EXP_DEVCTL_READRQ);\r\nif (rc_sup > rc_cur) {\r\nrc_cur = rc_sup;\r\npctl = (pctl & ~PCI_EXP_DEVCTL_READRQ) |\r\nval2fld(rc_cur, PCI_EXP_DEVCTL_READRQ);\r\npci_write_config_word(parent, ppos + PCI_EXP_DEVCTL, pctl);\r\n}\r\nif (rc_sup > ep_cur) {\r\nep_cur = rc_sup;\r\nectl = (ectl & ~PCI_EXP_DEVCTL_READRQ) |\r\nval2fld(ep_cur, PCI_EXP_DEVCTL_READRQ);\r\npci_write_config_word(dd->pcidev, epos + PCI_EXP_DEVCTL, ectl);\r\n}\r\nbail:\r\nreturn ret;\r\n}\r\nstatic pci_ers_result_t\r\nqib_pci_error_detected(struct pci_dev *pdev, pci_channel_state_t state)\r\n{\r\nstruct qib_devdata *dd = pci_get_drvdata(pdev);\r\npci_ers_result_t ret = PCI_ERS_RESULT_RECOVERED;\r\nswitch (state) {\r\ncase pci_channel_io_normal:\r\nqib_devinfo(pdev, "State Normal, ignoring\n");\r\nbreak;\r\ncase pci_channel_io_frozen:\r\nqib_devinfo(pdev, "State Frozen, requesting reset\n");\r\npci_disable_device(pdev);\r\nret = PCI_ERS_RESULT_NEED_RESET;\r\nbreak;\r\ncase pci_channel_io_perm_failure:\r\nqib_devinfo(pdev, "State Permanent Failure, disabling\n");\r\nif (dd) {\r\ndd->flags &= ~QIB_PRESENT;\r\nqib_disable_after_error(dd);\r\n}\r\nret = PCI_ERS_RESULT_DISCONNECT;\r\nbreak;\r\ndefault:\r\nqib_devinfo(pdev, "QIB PCI errors detected (state %d)\n",\r\nstate);\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nstatic pci_ers_result_t\r\nqib_pci_mmio_enabled(struct pci_dev *pdev)\r\n{\r\nu64 words = 0U;\r\nstruct qib_devdata *dd = pci_get_drvdata(pdev);\r\npci_ers_result_t ret = PCI_ERS_RESULT_RECOVERED;\r\nif (dd && dd->pport) {\r\nwords = dd->f_portcntr(dd->pport, QIBPORTCNTR_WORDRCV);\r\nif (words == ~0ULL)\r\nret = PCI_ERS_RESULT_NEED_RESET;\r\n}\r\nqib_devinfo(pdev, "QIB mmio_enabled function called, "\r\n"read wordscntr %Lx, returning %d\n", words, ret);\r\nreturn ret;\r\n}\r\nstatic pci_ers_result_t\r\nqib_pci_slot_reset(struct pci_dev *pdev)\r\n{\r\nqib_devinfo(pdev, "QIB link_reset function called, ignored\n");\r\nreturn PCI_ERS_RESULT_CAN_RECOVER;\r\n}\r\nstatic pci_ers_result_t\r\nqib_pci_link_reset(struct pci_dev *pdev)\r\n{\r\nqib_devinfo(pdev, "QIB link_reset function called, ignored\n");\r\nreturn PCI_ERS_RESULT_CAN_RECOVER;\r\n}\r\nstatic void\r\nqib_pci_resume(struct pci_dev *pdev)\r\n{\r\nstruct qib_devdata *dd = pci_get_drvdata(pdev);\r\nqib_devinfo(pdev, "QIB resume function called\n");\r\npci_cleanup_aer_uncorrect_error_status(pdev);\r\nqib_init(dd, 1);\r\n}
