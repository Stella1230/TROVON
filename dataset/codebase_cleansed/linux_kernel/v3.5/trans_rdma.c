static int parse_opts(char *params, struct p9_rdma_opts *opts)\r\n{\r\nchar *p;\r\nsubstring_t args[MAX_OPT_ARGS];\r\nint option;\r\nchar *options, *tmp_options;\r\nopts->port = P9_PORT;\r\nopts->sq_depth = P9_RDMA_SQ_DEPTH;\r\nopts->rq_depth = P9_RDMA_RQ_DEPTH;\r\nopts->timeout = P9_RDMA_TIMEOUT;\r\nif (!params)\r\nreturn 0;\r\ntmp_options = kstrdup(params, GFP_KERNEL);\r\nif (!tmp_options) {\r\np9_debug(P9_DEBUG_ERROR,\r\n"failed to allocate copy of option string\n");\r\nreturn -ENOMEM;\r\n}\r\noptions = tmp_options;\r\nwhile ((p = strsep(&options, ",")) != NULL) {\r\nint token;\r\nint r;\r\nif (!*p)\r\ncontinue;\r\ntoken = match_token(p, tokens, args);\r\nr = match_int(&args[0], &option);\r\nif (r < 0) {\r\np9_debug(P9_DEBUG_ERROR,\r\n"integer field, but no integer?\n");\r\ncontinue;\r\n}\r\nswitch (token) {\r\ncase Opt_port:\r\nopts->port = option;\r\nbreak;\r\ncase Opt_sq_depth:\r\nopts->sq_depth = option;\r\nbreak;\r\ncase Opt_rq_depth:\r\nopts->rq_depth = option;\r\nbreak;\r\ncase Opt_timeout:\r\nopts->timeout = option;\r\nbreak;\r\ndefault:\r\ncontinue;\r\n}\r\n}\r\nopts->rq_depth = max(opts->rq_depth, opts->sq_depth);\r\nkfree(tmp_options);\r\nreturn 0;\r\n}\r\nstatic int\r\np9_cm_event_handler(struct rdma_cm_id *id, struct rdma_cm_event *event)\r\n{\r\nstruct p9_client *c = id->context;\r\nstruct p9_trans_rdma *rdma = c->trans;\r\nswitch (event->event) {\r\ncase RDMA_CM_EVENT_ADDR_RESOLVED:\r\nBUG_ON(rdma->state != P9_RDMA_INIT);\r\nrdma->state = P9_RDMA_ADDR_RESOLVED;\r\nbreak;\r\ncase RDMA_CM_EVENT_ROUTE_RESOLVED:\r\nBUG_ON(rdma->state != P9_RDMA_ADDR_RESOLVED);\r\nrdma->state = P9_RDMA_ROUTE_RESOLVED;\r\nbreak;\r\ncase RDMA_CM_EVENT_ESTABLISHED:\r\nBUG_ON(rdma->state != P9_RDMA_ROUTE_RESOLVED);\r\nrdma->state = P9_RDMA_CONNECTED;\r\nbreak;\r\ncase RDMA_CM_EVENT_DISCONNECTED:\r\nif (rdma)\r\nrdma->state = P9_RDMA_CLOSED;\r\nif (c)\r\nc->status = Disconnected;\r\nbreak;\r\ncase RDMA_CM_EVENT_TIMEWAIT_EXIT:\r\nbreak;\r\ncase RDMA_CM_EVENT_ADDR_CHANGE:\r\ncase RDMA_CM_EVENT_ROUTE_ERROR:\r\ncase RDMA_CM_EVENT_DEVICE_REMOVAL:\r\ncase RDMA_CM_EVENT_MULTICAST_JOIN:\r\ncase RDMA_CM_EVENT_MULTICAST_ERROR:\r\ncase RDMA_CM_EVENT_REJECTED:\r\ncase RDMA_CM_EVENT_CONNECT_REQUEST:\r\ncase RDMA_CM_EVENT_CONNECT_RESPONSE:\r\ncase RDMA_CM_EVENT_CONNECT_ERROR:\r\ncase RDMA_CM_EVENT_ADDR_ERROR:\r\ncase RDMA_CM_EVENT_UNREACHABLE:\r\nc->status = Disconnected;\r\nrdma_disconnect(rdma->cm_id);\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\ncomplete(&rdma->cm_done);\r\nreturn 0;\r\n}\r\nstatic void\r\nhandle_recv(struct p9_client *client, struct p9_trans_rdma *rdma,\r\nstruct p9_rdma_context *c, enum ib_wc_status status, u32 byte_len)\r\n{\r\nstruct p9_req_t *req;\r\nint err = 0;\r\nint16_t tag;\r\nreq = NULL;\r\nib_dma_unmap_single(rdma->cm_id->device, c->busa, client->msize,\r\nDMA_FROM_DEVICE);\r\nif (status != IB_WC_SUCCESS)\r\ngoto err_out;\r\nerr = p9_parse_header(c->rc, NULL, NULL, &tag, 1);\r\nif (err)\r\ngoto err_out;\r\nreq = p9_tag_lookup(client, tag);\r\nif (!req)\r\ngoto err_out;\r\nreq->rc = c->rc;\r\nreq->status = REQ_STATUS_RCVD;\r\np9_client_cb(client, req);\r\nreturn;\r\nerr_out:\r\np9_debug(P9_DEBUG_ERROR, "req %p err %d status %d\n", req, err, status);\r\nrdma->state = P9_RDMA_FLUSHING;\r\nclient->status = Disconnected;\r\n}\r\nstatic void\r\nhandle_send(struct p9_client *client, struct p9_trans_rdma *rdma,\r\nstruct p9_rdma_context *c, enum ib_wc_status status, u32 byte_len)\r\n{\r\nib_dma_unmap_single(rdma->cm_id->device,\r\nc->busa, c->req->tc->size,\r\nDMA_TO_DEVICE);\r\n}\r\nstatic void qp_event_handler(struct ib_event *event, void *context)\r\n{\r\np9_debug(P9_DEBUG_ERROR, "QP event %d context %p\n",\r\nevent->event, context);\r\n}\r\nstatic void cq_comp_handler(struct ib_cq *cq, void *cq_context)\r\n{\r\nstruct p9_client *client = cq_context;\r\nstruct p9_trans_rdma *rdma = client->trans;\r\nint ret;\r\nstruct ib_wc wc;\r\nib_req_notify_cq(rdma->cq, IB_CQ_NEXT_COMP);\r\nwhile ((ret = ib_poll_cq(cq, 1, &wc)) > 0) {\r\nstruct p9_rdma_context *c = (void *) (unsigned long) wc.wr_id;\r\nswitch (c->wc_op) {\r\ncase IB_WC_RECV:\r\natomic_dec(&rdma->rq_count);\r\nhandle_recv(client, rdma, c, wc.status, wc.byte_len);\r\nbreak;\r\ncase IB_WC_SEND:\r\nhandle_send(client, rdma, c, wc.status, wc.byte_len);\r\nup(&rdma->sq_sem);\r\nbreak;\r\ndefault:\r\npr_err("unexpected completion type, c->wc_op=%d, wc.opcode=%d, status=%d\n",\r\nc->wc_op, wc.opcode, wc.status);\r\nbreak;\r\n}\r\nkfree(c);\r\n}\r\n}\r\nstatic void cq_event_handler(struct ib_event *e, void *v)\r\n{\r\np9_debug(P9_DEBUG_ERROR, "CQ event %d context %p\n", e->event, v);\r\n}\r\nstatic void rdma_destroy_trans(struct p9_trans_rdma *rdma)\r\n{\r\nif (!rdma)\r\nreturn;\r\nif (rdma->dma_mr && !IS_ERR(rdma->dma_mr))\r\nib_dereg_mr(rdma->dma_mr);\r\nif (rdma->qp && !IS_ERR(rdma->qp))\r\nib_destroy_qp(rdma->qp);\r\nif (rdma->pd && !IS_ERR(rdma->pd))\r\nib_dealloc_pd(rdma->pd);\r\nif (rdma->cq && !IS_ERR(rdma->cq))\r\nib_destroy_cq(rdma->cq);\r\nif (rdma->cm_id && !IS_ERR(rdma->cm_id))\r\nrdma_destroy_id(rdma->cm_id);\r\nkfree(rdma);\r\n}\r\nstatic int\r\npost_recv(struct p9_client *client, struct p9_rdma_context *c)\r\n{\r\nstruct p9_trans_rdma *rdma = client->trans;\r\nstruct ib_recv_wr wr, *bad_wr;\r\nstruct ib_sge sge;\r\nc->busa = ib_dma_map_single(rdma->cm_id->device,\r\nc->rc->sdata, client->msize,\r\nDMA_FROM_DEVICE);\r\nif (ib_dma_mapping_error(rdma->cm_id->device, c->busa))\r\ngoto error;\r\nsge.addr = c->busa;\r\nsge.length = client->msize;\r\nsge.lkey = rdma->lkey;\r\nwr.next = NULL;\r\nc->wc_op = IB_WC_RECV;\r\nwr.wr_id = (unsigned long) c;\r\nwr.sg_list = &sge;\r\nwr.num_sge = 1;\r\nreturn ib_post_recv(rdma->qp, &wr, &bad_wr);\r\nerror:\r\np9_debug(P9_DEBUG_ERROR, "EIO\n");\r\nreturn -EIO;\r\n}\r\nstatic int rdma_request(struct p9_client *client, struct p9_req_t *req)\r\n{\r\nstruct p9_trans_rdma *rdma = client->trans;\r\nstruct ib_send_wr wr, *bad_wr;\r\nstruct ib_sge sge;\r\nint err = 0;\r\nunsigned long flags;\r\nstruct p9_rdma_context *c = NULL;\r\nstruct p9_rdma_context *rpl_context = NULL;\r\nrpl_context = kmalloc(sizeof *rpl_context, GFP_NOFS);\r\nif (!rpl_context) {\r\nerr = -ENOMEM;\r\ngoto err_close;\r\n}\r\nif (!req->rc) {\r\nreq->rc = kmalloc(sizeof(struct p9_fcall)+client->msize,\r\nGFP_NOFS);\r\nif (req->rc) {\r\nreq->rc->sdata = (char *) req->rc +\r\nsizeof(struct p9_fcall);\r\nreq->rc->capacity = client->msize;\r\n}\r\n}\r\nrpl_context->rc = req->rc;\r\nif (!rpl_context->rc) {\r\nerr = -ENOMEM;\r\ngoto err_free2;\r\n}\r\nif (atomic_inc_return(&rdma->rq_count) <= rdma->rq_depth) {\r\nerr = post_recv(client, rpl_context);\r\nif (err)\r\ngoto err_free1;\r\n} else\r\natomic_dec(&rdma->rq_count);\r\nreq->rc = NULL;\r\nc = kmalloc(sizeof *c, GFP_NOFS);\r\nif (!c) {\r\nerr = -ENOMEM;\r\ngoto err_free1;\r\n}\r\nc->req = req;\r\nc->busa = ib_dma_map_single(rdma->cm_id->device,\r\nc->req->tc->sdata, c->req->tc->size,\r\nDMA_TO_DEVICE);\r\nif (ib_dma_mapping_error(rdma->cm_id->device, c->busa))\r\ngoto error;\r\nsge.addr = c->busa;\r\nsge.length = c->req->tc->size;\r\nsge.lkey = rdma->lkey;\r\nwr.next = NULL;\r\nc->wc_op = IB_WC_SEND;\r\nwr.wr_id = (unsigned long) c;\r\nwr.opcode = IB_WR_SEND;\r\nwr.send_flags = IB_SEND_SIGNALED;\r\nwr.sg_list = &sge;\r\nwr.num_sge = 1;\r\nif (down_interruptible(&rdma->sq_sem))\r\ngoto error;\r\nreturn ib_post_send(rdma->qp, &wr, &bad_wr);\r\nerror:\r\nkfree(c);\r\nkfree(rpl_context->rc);\r\nkfree(rpl_context);\r\np9_debug(P9_DEBUG_ERROR, "EIO\n");\r\nreturn -EIO;\r\nerr_free1:\r\nkfree(rpl_context->rc);\r\nerr_free2:\r\nkfree(rpl_context);\r\nerr_close:\r\nspin_lock_irqsave(&rdma->req_lock, flags);\r\nif (rdma->state < P9_RDMA_CLOSING) {\r\nrdma->state = P9_RDMA_CLOSING;\r\nspin_unlock_irqrestore(&rdma->req_lock, flags);\r\nrdma_disconnect(rdma->cm_id);\r\n} else\r\nspin_unlock_irqrestore(&rdma->req_lock, flags);\r\nreturn err;\r\n}\r\nstatic void rdma_close(struct p9_client *client)\r\n{\r\nstruct p9_trans_rdma *rdma;\r\nif (!client)\r\nreturn;\r\nrdma = client->trans;\r\nif (!rdma)\r\nreturn;\r\nclient->status = Disconnected;\r\nrdma_disconnect(rdma->cm_id);\r\nrdma_destroy_trans(rdma);\r\n}\r\nstatic struct p9_trans_rdma *alloc_rdma(struct p9_rdma_opts *opts)\r\n{\r\nstruct p9_trans_rdma *rdma;\r\nrdma = kzalloc(sizeof(struct p9_trans_rdma), GFP_KERNEL);\r\nif (!rdma)\r\nreturn NULL;\r\nrdma->sq_depth = opts->sq_depth;\r\nrdma->rq_depth = opts->rq_depth;\r\nrdma->timeout = opts->timeout;\r\nspin_lock_init(&rdma->req_lock);\r\ninit_completion(&rdma->cm_done);\r\nsema_init(&rdma->sq_sem, rdma->sq_depth);\r\natomic_set(&rdma->rq_count, 0);\r\nreturn rdma;\r\n}\r\nstatic int rdma_cancel(struct p9_client *client, struct p9_req_t *req)\r\n{\r\nreturn 1;\r\n}\r\nstatic int\r\nrdma_create_trans(struct p9_client *client, const char *addr, char *args)\r\n{\r\nint err;\r\nstruct p9_rdma_opts opts;\r\nstruct p9_trans_rdma *rdma;\r\nstruct rdma_conn_param conn_param;\r\nstruct ib_qp_init_attr qp_attr;\r\nstruct ib_device_attr devattr;\r\nerr = parse_opts(args, &opts);\r\nif (err < 0)\r\nreturn err;\r\nrdma = alloc_rdma(&opts);\r\nif (!rdma)\r\nreturn -ENOMEM;\r\nrdma->cm_id = rdma_create_id(p9_cm_event_handler, client, RDMA_PS_TCP,\r\nIB_QPT_RC);\r\nif (IS_ERR(rdma->cm_id))\r\ngoto error;\r\nclient->trans = rdma;\r\nrdma->addr.sin_family = AF_INET;\r\nrdma->addr.sin_addr.s_addr = in_aton(addr);\r\nrdma->addr.sin_port = htons(opts.port);\r\nerr = rdma_resolve_addr(rdma->cm_id, NULL,\r\n(struct sockaddr *)&rdma->addr,\r\nrdma->timeout);\r\nif (err)\r\ngoto error;\r\nerr = wait_for_completion_interruptible(&rdma->cm_done);\r\nif (err || (rdma->state != P9_RDMA_ADDR_RESOLVED))\r\ngoto error;\r\nerr = rdma_resolve_route(rdma->cm_id, rdma->timeout);\r\nif (err)\r\ngoto error;\r\nerr = wait_for_completion_interruptible(&rdma->cm_done);\r\nif (err || (rdma->state != P9_RDMA_ROUTE_RESOLVED))\r\ngoto error;\r\nerr = ib_query_device(rdma->cm_id->device, &devattr);\r\nif (err)\r\ngoto error;\r\nrdma->cq = ib_create_cq(rdma->cm_id->device, cq_comp_handler,\r\ncq_event_handler, client,\r\nopts.sq_depth + opts.rq_depth + 1, 0);\r\nif (IS_ERR(rdma->cq))\r\ngoto error;\r\nib_req_notify_cq(rdma->cq, IB_CQ_NEXT_COMP);\r\nrdma->pd = ib_alloc_pd(rdma->cm_id->device);\r\nif (IS_ERR(rdma->pd))\r\ngoto error;\r\nrdma->dma_mr = NULL;\r\nif (devattr.device_cap_flags & IB_DEVICE_LOCAL_DMA_LKEY)\r\nrdma->lkey = rdma->cm_id->device->local_dma_lkey;\r\nelse {\r\nrdma->dma_mr = ib_get_dma_mr(rdma->pd, IB_ACCESS_LOCAL_WRITE);\r\nif (IS_ERR(rdma->dma_mr))\r\ngoto error;\r\nrdma->lkey = rdma->dma_mr->lkey;\r\n}\r\nmemset(&qp_attr, 0, sizeof qp_attr);\r\nqp_attr.event_handler = qp_event_handler;\r\nqp_attr.qp_context = client;\r\nqp_attr.cap.max_send_wr = opts.sq_depth;\r\nqp_attr.cap.max_recv_wr = opts.rq_depth;\r\nqp_attr.cap.max_send_sge = P9_RDMA_SEND_SGE;\r\nqp_attr.cap.max_recv_sge = P9_RDMA_RECV_SGE;\r\nqp_attr.sq_sig_type = IB_SIGNAL_REQ_WR;\r\nqp_attr.qp_type = IB_QPT_RC;\r\nqp_attr.send_cq = rdma->cq;\r\nqp_attr.recv_cq = rdma->cq;\r\nerr = rdma_create_qp(rdma->cm_id, rdma->pd, &qp_attr);\r\nif (err)\r\ngoto error;\r\nrdma->qp = rdma->cm_id->qp;\r\nmemset(&conn_param, 0, sizeof(conn_param));\r\nconn_param.private_data = NULL;\r\nconn_param.private_data_len = 0;\r\nconn_param.responder_resources = P9_RDMA_IRD;\r\nconn_param.initiator_depth = P9_RDMA_ORD;\r\nerr = rdma_connect(rdma->cm_id, &conn_param);\r\nif (err)\r\ngoto error;\r\nerr = wait_for_completion_interruptible(&rdma->cm_done);\r\nif (err || (rdma->state != P9_RDMA_CONNECTED))\r\ngoto error;\r\nclient->status = Connected;\r\nreturn 0;\r\nerror:\r\nrdma_destroy_trans(rdma);\r\nreturn -ENOTCONN;\r\n}\r\nstatic int __init p9_trans_rdma_init(void)\r\n{\r\nv9fs_register_trans(&p9_rdma_trans);\r\nreturn 0;\r\n}\r\nstatic void __exit p9_trans_rdma_exit(void)\r\n{\r\nv9fs_unregister_trans(&p9_rdma_trans);\r\n}
