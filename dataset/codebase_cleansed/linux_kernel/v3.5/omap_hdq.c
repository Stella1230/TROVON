static inline u8 hdq_reg_in(struct hdq_data *hdq_data, u32 offset)\r\n{\r\nreturn __raw_readb(hdq_data->hdq_base + offset);\r\n}\r\nstatic inline void hdq_reg_out(struct hdq_data *hdq_data, u32 offset, u8 val)\r\n{\r\n__raw_writeb(val, hdq_data->hdq_base + offset);\r\n}\r\nstatic inline u8 hdq_reg_merge(struct hdq_data *hdq_data, u32 offset,\r\nu8 val, u8 mask)\r\n{\r\nu8 new_val = (__raw_readb(hdq_data->hdq_base + offset) & ~mask)\r\n| (val & mask);\r\n__raw_writeb(new_val, hdq_data->hdq_base + offset);\r\nreturn new_val;\r\n}\r\nstatic int hdq_wait_for_flag(struct hdq_data *hdq_data, u32 offset,\r\nu8 flag, u8 flag_set, u8 *status)\r\n{\r\nint ret = 0;\r\nunsigned long timeout = jiffies + OMAP_HDQ_TIMEOUT;\r\nif (flag_set == OMAP_HDQ_FLAG_CLEAR) {\r\nwhile (((*status = hdq_reg_in(hdq_data, offset)) & flag)\r\n&& time_before(jiffies, timeout)) {\r\nschedule_timeout_uninterruptible(1);\r\n}\r\nif (*status & flag)\r\nret = -ETIMEDOUT;\r\n} else if (flag_set == OMAP_HDQ_FLAG_SET) {\r\nwhile (!((*status = hdq_reg_in(hdq_data, offset)) & flag)\r\n&& time_before(jiffies, timeout)) {\r\nschedule_timeout_uninterruptible(1);\r\n}\r\nif (!(*status & flag))\r\nret = -ETIMEDOUT;\r\n} else\r\nreturn -EINVAL;\r\nreturn ret;\r\n}\r\nstatic int hdq_write_byte(struct hdq_data *hdq_data, u8 val, u8 *status)\r\n{\r\nint ret;\r\nu8 tmp_status;\r\nunsigned long irqflags;\r\n*status = 0;\r\nspin_lock_irqsave(&hdq_data->hdq_spinlock, irqflags);\r\nhdq_reg_in(hdq_data, OMAP_HDQ_INT_STATUS);\r\nhdq_data->hdq_irqstatus = 0;\r\nspin_unlock_irqrestore(&hdq_data->hdq_spinlock, irqflags);\r\nhdq_reg_out(hdq_data, OMAP_HDQ_TX_DATA, val);\r\nhdq_reg_merge(hdq_data, OMAP_HDQ_CTRL_STATUS, OMAP_HDQ_CTRL_STATUS_GO,\r\nOMAP_HDQ_CTRL_STATUS_DIR | OMAP_HDQ_CTRL_STATUS_GO);\r\nret = wait_event_timeout(hdq_wait_queue,\r\nhdq_data->hdq_irqstatus, OMAP_HDQ_TIMEOUT);\r\nif (ret == 0) {\r\ndev_dbg(hdq_data->dev, "TX wait elapsed\n");\r\ngoto out;\r\n}\r\n*status = hdq_data->hdq_irqstatus;\r\nif (!(*status & OMAP_HDQ_INT_STATUS_TXCOMPLETE)) {\r\ndev_dbg(hdq_data->dev, "timeout waiting for"\r\n"TXCOMPLETE/RXCOMPLETE, %x", *status);\r\nret = -ETIMEDOUT;\r\ngoto out;\r\n}\r\nret = hdq_wait_for_flag(hdq_data, OMAP_HDQ_CTRL_STATUS,\r\nOMAP_HDQ_CTRL_STATUS_GO,\r\nOMAP_HDQ_FLAG_CLEAR, &tmp_status);\r\nif (ret) {\r\ndev_dbg(hdq_data->dev, "timeout waiting GO bit"\r\n"return to zero, %x", tmp_status);\r\n}\r\nout:\r\nreturn ret;\r\n}\r\nstatic irqreturn_t hdq_isr(int irq, void *_hdq)\r\n{\r\nstruct hdq_data *hdq_data = _hdq;\r\nunsigned long irqflags;\r\nspin_lock_irqsave(&hdq_data->hdq_spinlock, irqflags);\r\nhdq_data->hdq_irqstatus = hdq_reg_in(hdq_data, OMAP_HDQ_INT_STATUS);\r\nspin_unlock_irqrestore(&hdq_data->hdq_spinlock, irqflags);\r\ndev_dbg(hdq_data->dev, "hdq_isr: %x", hdq_data->hdq_irqstatus);\r\nif (hdq_data->hdq_irqstatus &\r\n(OMAP_HDQ_INT_STATUS_TXCOMPLETE | OMAP_HDQ_INT_STATUS_RXCOMPLETE\r\n| OMAP_HDQ_INT_STATUS_TIMEOUT)) {\r\nwake_up(&hdq_wait_queue);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic u8 omap_w1_reset_bus(void *_hdq)\r\n{\r\nreturn 0;\r\n}\r\nstatic void omap_w1_search_bus(void *_hdq, struct w1_master *master_dev,\r\nu8 search_type, w1_slave_found_callback slave_found)\r\n{\r\nu64 module_id, rn_le, cs, id;\r\nif (w1_id)\r\nmodule_id = w1_id;\r\nelse\r\nmodule_id = 0x1;\r\nrn_le = cpu_to_le64(module_id);\r\ncs = w1_calc_crc8((u8 *)&rn_le, 7);\r\nid = (cs << 56) | module_id;\r\nslave_found(master_dev, id);\r\n}\r\nstatic int _omap_hdq_reset(struct hdq_data *hdq_data)\r\n{\r\nint ret;\r\nu8 tmp_status;\r\nhdq_reg_out(hdq_data, OMAP_HDQ_SYSCONFIG, OMAP_HDQ_SYSCONFIG_SOFTRESET);\r\nhdq_reg_out(hdq_data, OMAP_HDQ_CTRL_STATUS,\r\nOMAP_HDQ_CTRL_STATUS_CLOCKENABLE |\r\nOMAP_HDQ_CTRL_STATUS_INTERRUPTMASK);\r\nret = hdq_wait_for_flag(hdq_data, OMAP_HDQ_SYSSTATUS,\r\nOMAP_HDQ_SYSSTATUS_RESETDONE, OMAP_HDQ_FLAG_SET, &tmp_status);\r\nif (ret)\r\ndev_dbg(hdq_data->dev, "timeout waiting HDQ reset, %x",\r\ntmp_status);\r\nelse {\r\nhdq_reg_out(hdq_data, OMAP_HDQ_CTRL_STATUS,\r\nOMAP_HDQ_CTRL_STATUS_CLOCKENABLE |\r\nOMAP_HDQ_CTRL_STATUS_INTERRUPTMASK);\r\nhdq_reg_out(hdq_data, OMAP_HDQ_SYSCONFIG,\r\nOMAP_HDQ_SYSCONFIG_AUTOIDLE);\r\n}\r\nreturn ret;\r\n}\r\nstatic int omap_hdq_break(struct hdq_data *hdq_data)\r\n{\r\nint ret = 0;\r\nu8 tmp_status;\r\nunsigned long irqflags;\r\nret = mutex_lock_interruptible(&hdq_data->hdq_mutex);\r\nif (ret < 0) {\r\ndev_dbg(hdq_data->dev, "Could not acquire mutex\n");\r\nret = -EINTR;\r\ngoto rtn;\r\n}\r\nspin_lock_irqsave(&hdq_data->hdq_spinlock, irqflags);\r\nhdq_reg_in(hdq_data, OMAP_HDQ_INT_STATUS);\r\nhdq_data->hdq_irqstatus = 0;\r\nspin_unlock_irqrestore(&hdq_data->hdq_spinlock, irqflags);\r\nhdq_reg_merge(hdq_data, OMAP_HDQ_CTRL_STATUS,\r\nOMAP_HDQ_CTRL_STATUS_INITIALIZATION | OMAP_HDQ_CTRL_STATUS_GO,\r\nOMAP_HDQ_CTRL_STATUS_DIR | OMAP_HDQ_CTRL_STATUS_INITIALIZATION |\r\nOMAP_HDQ_CTRL_STATUS_GO);\r\nret = wait_event_timeout(hdq_wait_queue,\r\nhdq_data->hdq_irqstatus, OMAP_HDQ_TIMEOUT);\r\nif (ret == 0) {\r\ndev_dbg(hdq_data->dev, "break wait elapsed\n");\r\nret = -EINTR;\r\ngoto out;\r\n}\r\ntmp_status = hdq_data->hdq_irqstatus;\r\nif (!(tmp_status & OMAP_HDQ_INT_STATUS_TIMEOUT)) {\r\ndev_dbg(hdq_data->dev, "timeout waiting for TIMEOUT, %x",\r\ntmp_status);\r\nret = -ETIMEDOUT;\r\ngoto out;\r\n}\r\nret = hdq_wait_for_flag(hdq_data, OMAP_HDQ_CTRL_STATUS,\r\nOMAP_HDQ_CTRL_STATUS_INITIALIZATION |\r\nOMAP_HDQ_CTRL_STATUS_GO, OMAP_HDQ_FLAG_CLEAR,\r\n&tmp_status);\r\nif (ret)\r\ndev_dbg(hdq_data->dev, "timeout waiting INIT&GO bits"\r\n"return to zero, %x", tmp_status);\r\nout:\r\nmutex_unlock(&hdq_data->hdq_mutex);\r\nrtn:\r\nreturn ret;\r\n}\r\nstatic int hdq_read_byte(struct hdq_data *hdq_data, u8 *val)\r\n{\r\nint ret = 0;\r\nu8 status;\r\nunsigned long timeout = jiffies + OMAP_HDQ_TIMEOUT;\r\nret = mutex_lock_interruptible(&hdq_data->hdq_mutex);\r\nif (ret < 0) {\r\nret = -EINTR;\r\ngoto rtn;\r\n}\r\nif (!hdq_data->hdq_usecount) {\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nif (!(hdq_data->hdq_irqstatus & OMAP_HDQ_INT_STATUS_RXCOMPLETE)) {\r\nhdq_reg_merge(hdq_data, OMAP_HDQ_CTRL_STATUS,\r\nOMAP_HDQ_CTRL_STATUS_DIR | OMAP_HDQ_CTRL_STATUS_GO,\r\nOMAP_HDQ_CTRL_STATUS_DIR | OMAP_HDQ_CTRL_STATUS_GO);\r\nwhile (!(hdq_data->hdq_irqstatus\r\n& OMAP_HDQ_INT_STATUS_RXCOMPLETE)\r\n&& time_before(jiffies, timeout)) {\r\nschedule_timeout_uninterruptible(1);\r\n}\r\nhdq_reg_merge(hdq_data, OMAP_HDQ_CTRL_STATUS, 0,\r\nOMAP_HDQ_CTRL_STATUS_DIR);\r\nstatus = hdq_data->hdq_irqstatus;\r\nif (!(status & OMAP_HDQ_INT_STATUS_RXCOMPLETE)) {\r\ndev_dbg(hdq_data->dev, "timeout waiting for"\r\n"RXCOMPLETE, %x", status);\r\nret = -ETIMEDOUT;\r\ngoto out;\r\n}\r\n}\r\n*val = hdq_reg_in(hdq_data, OMAP_HDQ_RX_DATA);\r\nout:\r\nmutex_unlock(&hdq_data->hdq_mutex);\r\nrtn:\r\nreturn 0;\r\n}\r\nstatic int omap_hdq_get(struct hdq_data *hdq_data)\r\n{\r\nint ret = 0;\r\nret = mutex_lock_interruptible(&hdq_data->hdq_mutex);\r\nif (ret < 0) {\r\nret = -EINTR;\r\ngoto rtn;\r\n}\r\nif (OMAP_HDQ_MAX_USER == hdq_data->hdq_usecount) {\r\ndev_dbg(hdq_data->dev, "attempt to exceed the max use count");\r\nret = -EINVAL;\r\ngoto out;\r\n} else {\r\nhdq_data->hdq_usecount++;\r\ntry_module_get(THIS_MODULE);\r\nif (1 == hdq_data->hdq_usecount) {\r\nif (clk_enable(hdq_data->hdq_ick)) {\r\ndev_dbg(hdq_data->dev, "Can not enable ick\n");\r\nret = -ENODEV;\r\ngoto clk_err;\r\n}\r\nif (clk_enable(hdq_data->hdq_fck)) {\r\ndev_dbg(hdq_data->dev, "Can not enable fck\n");\r\nclk_disable(hdq_data->hdq_ick);\r\nret = -ENODEV;\r\ngoto clk_err;\r\n}\r\nif (!(hdq_reg_in(hdq_data, OMAP_HDQ_SYSSTATUS) &\r\nOMAP_HDQ_SYSSTATUS_RESETDONE)) {\r\nret = _omap_hdq_reset(hdq_data);\r\nif (ret)\r\nhdq_data->hdq_usecount--;\r\n} else {\r\nhdq_reg_out(hdq_data, OMAP_HDQ_CTRL_STATUS,\r\nOMAP_HDQ_CTRL_STATUS_CLOCKENABLE |\r\nOMAP_HDQ_CTRL_STATUS_INTERRUPTMASK);\r\nhdq_reg_out(hdq_data, OMAP_HDQ_SYSCONFIG,\r\nOMAP_HDQ_SYSCONFIG_AUTOIDLE);\r\nhdq_reg_in(hdq_data, OMAP_HDQ_INT_STATUS);\r\n}\r\n}\r\n}\r\nclk_err:\r\nclk_put(hdq_data->hdq_ick);\r\nclk_put(hdq_data->hdq_fck);\r\nout:\r\nmutex_unlock(&hdq_data->hdq_mutex);\r\nrtn:\r\nreturn ret;\r\n}\r\nstatic int omap_hdq_put(struct hdq_data *hdq_data)\r\n{\r\nint ret = 0;\r\nret = mutex_lock_interruptible(&hdq_data->hdq_mutex);\r\nif (ret < 0)\r\nreturn -EINTR;\r\nif (0 == hdq_data->hdq_usecount) {\r\ndev_dbg(hdq_data->dev, "attempt to decrement use count"\r\n"when it is zero");\r\nret = -EINVAL;\r\n} else {\r\nhdq_data->hdq_usecount--;\r\nmodule_put(THIS_MODULE);\r\nif (0 == hdq_data->hdq_usecount) {\r\nclk_disable(hdq_data->hdq_ick);\r\nclk_disable(hdq_data->hdq_fck);\r\n}\r\n}\r\nmutex_unlock(&hdq_data->hdq_mutex);\r\nreturn ret;\r\n}\r\nstatic u8 omap_w1_read_byte(void *_hdq)\r\n{\r\nstruct hdq_data *hdq_data = _hdq;\r\nu8 val = 0;\r\nint ret;\r\nret = hdq_read_byte(hdq_data, &val);\r\nif (ret) {\r\nret = mutex_lock_interruptible(&hdq_data->hdq_mutex);\r\nif (ret < 0) {\r\ndev_dbg(hdq_data->dev, "Could not acquire mutex\n");\r\nreturn -EINTR;\r\n}\r\nhdq_data->init_trans = 0;\r\nmutex_unlock(&hdq_data->hdq_mutex);\r\nomap_hdq_put(hdq_data);\r\nreturn -1;\r\n}\r\nif (hdq_data->init_trans) {\r\nret = mutex_lock_interruptible(&hdq_data->hdq_mutex);\r\nif (ret < 0) {\r\ndev_dbg(hdq_data->dev, "Could not acquire mutex\n");\r\nreturn -EINTR;\r\n}\r\nhdq_data->init_trans = 0;\r\nmutex_unlock(&hdq_data->hdq_mutex);\r\nomap_hdq_put(hdq_data);\r\n}\r\nreturn val;\r\n}\r\nstatic void omap_w1_write_byte(void *_hdq, u8 byte)\r\n{\r\nstruct hdq_data *hdq_data = _hdq;\r\nint ret;\r\nu8 status;\r\nif (hdq_data->init_trans == 0)\r\nomap_hdq_get(hdq_data);\r\nret = mutex_lock_interruptible(&hdq_data->hdq_mutex);\r\nif (ret < 0) {\r\ndev_dbg(hdq_data->dev, "Could not acquire mutex\n");\r\nreturn;\r\n}\r\nhdq_data->init_trans++;\r\nmutex_unlock(&hdq_data->hdq_mutex);\r\nret = hdq_write_byte(hdq_data, byte, &status);\r\nif (ret == 0) {\r\ndev_dbg(hdq_data->dev, "TX failure:Ctrl status %x\n", status);\r\nreturn;\r\n}\r\nif (hdq_data->init_trans > 1) {\r\nomap_hdq_put(hdq_data);\r\nret = mutex_lock_interruptible(&hdq_data->hdq_mutex);\r\nif (ret < 0) {\r\ndev_dbg(hdq_data->dev, "Could not acquire mutex\n");\r\nreturn;\r\n}\r\nhdq_data->init_trans = 0;\r\nmutex_unlock(&hdq_data->hdq_mutex);\r\n}\r\nreturn;\r\n}\r\nstatic int __devinit omap_hdq_probe(struct platform_device *pdev)\r\n{\r\nstruct hdq_data *hdq_data;\r\nstruct resource *res;\r\nint ret, irq;\r\nu8 rev;\r\nhdq_data = kmalloc(sizeof(*hdq_data), GFP_KERNEL);\r\nif (!hdq_data) {\r\ndev_dbg(&pdev->dev, "unable to allocate memory\n");\r\nret = -ENOMEM;\r\ngoto err_kmalloc;\r\n}\r\nhdq_data->dev = &pdev->dev;\r\nplatform_set_drvdata(pdev, hdq_data);\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nif (!res) {\r\ndev_dbg(&pdev->dev, "unable to get resource\n");\r\nret = -ENXIO;\r\ngoto err_resource;\r\n}\r\nhdq_data->hdq_base = ioremap(res->start, SZ_4K);\r\nif (!hdq_data->hdq_base) {\r\ndev_dbg(&pdev->dev, "ioremap failed\n");\r\nret = -EINVAL;\r\ngoto err_ioremap;\r\n}\r\nhdq_data->hdq_ick = clk_get(&pdev->dev, "ick");\r\nif (IS_ERR(hdq_data->hdq_ick)) {\r\ndev_dbg(&pdev->dev, "Can't get HDQ ick clock object\n");\r\nret = PTR_ERR(hdq_data->hdq_ick);\r\ngoto err_ick;\r\n}\r\nhdq_data->hdq_fck = clk_get(&pdev->dev, "fck");\r\nif (IS_ERR(hdq_data->hdq_fck)) {\r\ndev_dbg(&pdev->dev, "Can't get HDQ fck clock object\n");\r\nret = PTR_ERR(hdq_data->hdq_fck);\r\ngoto err_fck;\r\n}\r\nhdq_data->hdq_usecount = 0;\r\nmutex_init(&hdq_data->hdq_mutex);\r\nif (clk_enable(hdq_data->hdq_ick)) {\r\ndev_dbg(&pdev->dev, "Can not enable ick\n");\r\nret = -ENODEV;\r\ngoto err_intfclk;\r\n}\r\nif (clk_enable(hdq_data->hdq_fck)) {\r\ndev_dbg(&pdev->dev, "Can not enable fck\n");\r\nret = -ENODEV;\r\ngoto err_fnclk;\r\n}\r\nrev = hdq_reg_in(hdq_data, OMAP_HDQ_REVISION);\r\ndev_info(&pdev->dev, "OMAP HDQ Hardware Rev %c.%c. Driver in %s mode\n",\r\n(rev >> 4) + '0', (rev & 0x0f) + '0', "Interrupt");\r\nspin_lock_init(&hdq_data->hdq_spinlock);\r\nirq = platform_get_irq(pdev, 0);\r\nif (irq < 0) {\r\nret = -ENXIO;\r\ngoto err_irq;\r\n}\r\nret = request_irq(irq, hdq_isr, IRQF_DISABLED, "omap_hdq", hdq_data);\r\nif (ret < 0) {\r\ndev_dbg(&pdev->dev, "could not request irq\n");\r\ngoto err_irq;\r\n}\r\nomap_hdq_break(hdq_data);\r\nclk_disable(hdq_data->hdq_ick);\r\nclk_disable(hdq_data->hdq_fck);\r\nomap_w1_master.data = hdq_data;\r\nret = w1_add_master_device(&omap_w1_master);\r\nif (ret) {\r\ndev_dbg(&pdev->dev, "Failure in registering w1 master\n");\r\ngoto err_w1;\r\n}\r\nreturn 0;\r\nerr_w1:\r\nerr_irq:\r\nclk_disable(hdq_data->hdq_fck);\r\nerr_fnclk:\r\nclk_disable(hdq_data->hdq_ick);\r\nerr_intfclk:\r\nclk_put(hdq_data->hdq_fck);\r\nerr_fck:\r\nclk_put(hdq_data->hdq_ick);\r\nerr_ick:\r\niounmap(hdq_data->hdq_base);\r\nerr_ioremap:\r\nerr_resource:\r\nplatform_set_drvdata(pdev, NULL);\r\nkfree(hdq_data);\r\nerr_kmalloc:\r\nreturn ret;\r\n}\r\nstatic int omap_hdq_remove(struct platform_device *pdev)\r\n{\r\nstruct hdq_data *hdq_data = platform_get_drvdata(pdev);\r\nmutex_lock(&hdq_data->hdq_mutex);\r\nif (hdq_data->hdq_usecount) {\r\ndev_dbg(&pdev->dev, "removed when use count is not zero\n");\r\nmutex_unlock(&hdq_data->hdq_mutex);\r\nreturn -EBUSY;\r\n}\r\nmutex_unlock(&hdq_data->hdq_mutex);\r\nclk_put(hdq_data->hdq_ick);\r\nclk_put(hdq_data->hdq_fck);\r\nfree_irq(INT_24XX_HDQ_IRQ, hdq_data);\r\nplatform_set_drvdata(pdev, NULL);\r\niounmap(hdq_data->hdq_base);\r\nkfree(hdq_data);\r\nreturn 0;\r\n}\r\nstatic int __init\r\nomap_hdq_init(void)\r\n{\r\nreturn platform_driver_register(&omap_hdq_driver);\r\n}\r\nstatic void __exit\r\nomap_hdq_exit(void)\r\n{\r\nplatform_driver_unregister(&omap_hdq_driver);\r\n}
