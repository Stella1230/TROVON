static int vmw_cmd_invalid(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nreturn capable(CAP_SYS_ADMIN) ? : -EINVAL;\r\n}\r\nstatic int vmw_cmd_ok(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nreturn 0;\r\n}\r\nstatic void vmw_resource_to_validate_list(struct vmw_sw_context *sw_context,\r\nstruct vmw_resource **p_res)\r\n{\r\nstruct vmw_resource *res = *p_res;\r\nif (list_empty(&res->validate_head)) {\r\nlist_add_tail(&res->validate_head, &sw_context->resource_list);\r\n*p_res = NULL;\r\n} else\r\nvmw_resource_unreference(p_res);\r\n}\r\nstatic int vmw_bo_to_validate_list(struct vmw_sw_context *sw_context,\r\nstruct ttm_buffer_object *bo,\r\nuint32_t fence_flags,\r\nuint32_t *p_val_node)\r\n{\r\nuint32_t val_node;\r\nstruct ttm_validate_buffer *val_buf;\r\nval_node = vmw_dmabuf_validate_node(bo, sw_context->cur_val_buf);\r\nif (unlikely(val_node >= VMWGFX_MAX_VALIDATIONS)) {\r\nDRM_ERROR("Max number of DMA buffers per submission"\r\n" exceeded.\n");\r\nreturn -EINVAL;\r\n}\r\nval_buf = &sw_context->val_bufs[val_node];\r\nif (unlikely(val_node == sw_context->cur_val_buf)) {\r\nval_buf->new_sync_obj_arg = NULL;\r\nval_buf->bo = ttm_bo_reference(bo);\r\nlist_add_tail(&val_buf->head, &sw_context->validate_nodes);\r\n++sw_context->cur_val_buf;\r\n}\r\nval_buf->new_sync_obj_arg = (void *)\r\n((unsigned long) val_buf->new_sync_obj_arg | fence_flags);\r\nsw_context->fence_flags |= fence_flags;\r\nif (p_val_node)\r\n*p_val_node = val_node;\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_cid_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_resource *ctx;\r\nstruct vmw_cid_cmd {\r\nSVGA3dCmdHeader header;\r\n__le32 cid;\r\n} *cmd;\r\nint ret;\r\ncmd = container_of(header, struct vmw_cid_cmd, header);\r\nif (likely(sw_context->cid_valid && cmd->cid == sw_context->last_cid))\r\nreturn 0;\r\nret = vmw_context_check(dev_priv, sw_context->tfile, cmd->cid,\r\n&ctx);\r\nif (unlikely(ret != 0)) {\r\nDRM_ERROR("Could not find or use context %u\n",\r\n(unsigned) cmd->cid);\r\nreturn ret;\r\n}\r\nsw_context->last_cid = cmd->cid;\r\nsw_context->cid_valid = true;\r\nsw_context->cur_ctx = ctx;\r\nvmw_resource_to_validate_list(sw_context, &ctx);\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_sid_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nuint32_t *sid)\r\n{\r\nstruct vmw_surface *srf;\r\nint ret;\r\nstruct vmw_resource *res;\r\nif (*sid == SVGA3D_INVALID_ID)\r\nreturn 0;\r\nif (likely((sw_context->sid_valid &&\r\n*sid == sw_context->last_sid))) {\r\n*sid = sw_context->sid_translation;\r\nreturn 0;\r\n}\r\nret = vmw_user_surface_lookup_handle(dev_priv,\r\nsw_context->tfile,\r\n*sid, &srf);\r\nif (unlikely(ret != 0)) {\r\nDRM_ERROR("Could ot find or use surface 0x%08x "\r\n"address 0x%08lx\n",\r\n(unsigned int) *sid,\r\n(unsigned long) sid);\r\nreturn ret;\r\n}\r\nret = vmw_surface_validate(dev_priv, srf);\r\nif (unlikely(ret != 0)) {\r\nif (ret != -ERESTARTSYS)\r\nDRM_ERROR("Could not validate surface.\n");\r\nvmw_surface_unreference(&srf);\r\nreturn ret;\r\n}\r\nsw_context->last_sid = *sid;\r\nsw_context->sid_valid = true;\r\nsw_context->sid_translation = srf->res.id;\r\n*sid = sw_context->sid_translation;\r\nres = &srf->res;\r\nvmw_resource_to_validate_list(sw_context, &res);\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_set_render_target_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_sid_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdSetRenderTarget body;\r\n} *cmd;\r\nint ret;\r\nret = vmw_cmd_cid_check(dev_priv, sw_context, header);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\ncmd = container_of(header, struct vmw_sid_cmd, header);\r\nret = vmw_cmd_sid_check(dev_priv, sw_context, &cmd->body.target.sid);\r\nreturn ret;\r\n}\r\nstatic int vmw_cmd_surface_copy_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_sid_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdSurfaceCopy body;\r\n} *cmd;\r\nint ret;\r\ncmd = container_of(header, struct vmw_sid_cmd, header);\r\nret = vmw_cmd_sid_check(dev_priv, sw_context, &cmd->body.src.sid);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nreturn vmw_cmd_sid_check(dev_priv, sw_context, &cmd->body.dest.sid);\r\n}\r\nstatic int vmw_cmd_stretch_blt_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_sid_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdSurfaceStretchBlt body;\r\n} *cmd;\r\nint ret;\r\ncmd = container_of(header, struct vmw_sid_cmd, header);\r\nret = vmw_cmd_sid_check(dev_priv, sw_context, &cmd->body.src.sid);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nreturn vmw_cmd_sid_check(dev_priv, sw_context, &cmd->body.dest.sid);\r\n}\r\nstatic int vmw_cmd_blt_surf_screen_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_sid_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdBlitSurfaceToScreen body;\r\n} *cmd;\r\ncmd = container_of(header, struct vmw_sid_cmd, header);\r\nif (unlikely(!sw_context->kernel)) {\r\nDRM_ERROR("Kernel only SVGA3d command: %u.\n", cmd->header.id);\r\nreturn -EPERM;\r\n}\r\nreturn vmw_cmd_sid_check(dev_priv, sw_context, &cmd->body.srcImage.sid);\r\n}\r\nstatic int vmw_cmd_present_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_sid_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdPresent body;\r\n} *cmd;\r\ncmd = container_of(header, struct vmw_sid_cmd, header);\r\nif (unlikely(!sw_context->kernel)) {\r\nDRM_ERROR("Kernel only SVGA3d command: %u.\n", cmd->header.id);\r\nreturn -EPERM;\r\n}\r\nreturn vmw_cmd_sid_check(dev_priv, sw_context, &cmd->body.sid);\r\n}\r\nstatic int vmw_query_bo_switch_prepare(struct vmw_private *dev_priv,\r\nuint32_t cid,\r\nstruct ttm_buffer_object *new_query_bo,\r\nstruct vmw_sw_context *sw_context)\r\n{\r\nint ret;\r\nbool add_cid = false;\r\nuint32_t cid_to_add;\r\nif (unlikely(new_query_bo != sw_context->cur_query_bo)) {\r\nif (unlikely(new_query_bo->num_pages > 4)) {\r\nDRM_ERROR("Query buffer too large.\n");\r\nreturn -EINVAL;\r\n}\r\nif (unlikely(sw_context->cur_query_bo != NULL)) {\r\nBUG_ON(!sw_context->query_cid_valid);\r\nadd_cid = true;\r\ncid_to_add = sw_context->cur_query_cid;\r\nret = vmw_bo_to_validate_list(sw_context,\r\nsw_context->cur_query_bo,\r\nDRM_VMW_FENCE_FLAG_EXEC,\r\nNULL);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n}\r\nsw_context->cur_query_bo = new_query_bo;\r\nret = vmw_bo_to_validate_list(sw_context,\r\ndev_priv->dummy_query_bo,\r\nDRM_VMW_FENCE_FLAG_EXEC,\r\nNULL);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n}\r\nif (unlikely(cid != sw_context->cur_query_cid &&\r\nsw_context->query_cid_valid)) {\r\nadd_cid = true;\r\ncid_to_add = sw_context->cur_query_cid;\r\n}\r\nsw_context->cur_query_cid = cid;\r\nsw_context->query_cid_valid = true;\r\nif (add_cid) {\r\nstruct vmw_resource *ctx = sw_context->cur_ctx;\r\nif (list_empty(&ctx->query_head))\r\nlist_add_tail(&ctx->query_head,\r\n&sw_context->query_list);\r\nret = vmw_bo_to_validate_list(sw_context,\r\ndev_priv->dummy_query_bo,\r\nDRM_VMW_FENCE_FLAG_EXEC,\r\nNULL);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic void vmw_query_bo_switch_commit(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context)\r\n{\r\nstruct vmw_resource *ctx, *next_ctx;\r\nint ret;\r\nlist_for_each_entry_safe(ctx, next_ctx, &sw_context->query_list,\r\nquery_head) {\r\nlist_del_init(&ctx->query_head);\r\nBUG_ON(list_empty(&ctx->validate_head));\r\nret = vmw_fifo_emit_dummy_query(dev_priv, ctx->id);\r\nif (unlikely(ret != 0))\r\nDRM_ERROR("Out of fifo space for dummy query.\n");\r\n}\r\nif (dev_priv->pinned_bo != sw_context->cur_query_bo) {\r\nif (dev_priv->pinned_bo) {\r\nvmw_bo_pin(dev_priv->pinned_bo, false);\r\nttm_bo_unref(&dev_priv->pinned_bo);\r\n}\r\nvmw_bo_pin(sw_context->cur_query_bo, true);\r\nvmw_bo_pin(dev_priv->dummy_query_bo, true);\r\ndev_priv->dummy_query_bo_pinned = true;\r\ndev_priv->query_cid = sw_context->cur_query_cid;\r\ndev_priv->pinned_bo =\r\nttm_bo_reference(sw_context->cur_query_bo);\r\n}\r\n}\r\nstatic void vmw_query_switch_backoff(struct vmw_sw_context *sw_context)\r\n{\r\nstruct list_head *list, *next;\r\nlist_for_each_safe(list, next, &sw_context->query_list) {\r\nlist_del_init(list);\r\n}\r\n}\r\nstatic int vmw_translate_guest_ptr(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGAGuestPtr *ptr,\r\nstruct vmw_dma_buffer **vmw_bo_p)\r\n{\r\nstruct vmw_dma_buffer *vmw_bo = NULL;\r\nstruct ttm_buffer_object *bo;\r\nuint32_t handle = ptr->gmrId;\r\nstruct vmw_relocation *reloc;\r\nint ret;\r\nret = vmw_user_dmabuf_lookup(sw_context->tfile, handle, &vmw_bo);\r\nif (unlikely(ret != 0)) {\r\nDRM_ERROR("Could not find or use GMR region.\n");\r\nreturn -EINVAL;\r\n}\r\nbo = &vmw_bo->base;\r\nif (unlikely(sw_context->cur_reloc >= VMWGFX_MAX_RELOCATIONS)) {\r\nDRM_ERROR("Max number relocations per submission"\r\n" exceeded\n");\r\nret = -EINVAL;\r\ngoto out_no_reloc;\r\n}\r\nreloc = &sw_context->relocs[sw_context->cur_reloc++];\r\nreloc->location = ptr;\r\nret = vmw_bo_to_validate_list(sw_context, bo, DRM_VMW_FENCE_FLAG_EXEC,\r\n&reloc->index);\r\nif (unlikely(ret != 0))\r\ngoto out_no_reloc;\r\n*vmw_bo_p = vmw_bo;\r\nreturn 0;\r\nout_no_reloc:\r\nvmw_dmabuf_unreference(&vmw_bo);\r\nvmw_bo_p = NULL;\r\nreturn ret;\r\n}\r\nstatic int vmw_cmd_end_query(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_dma_buffer *vmw_bo;\r\nstruct vmw_query_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdEndQuery q;\r\n} *cmd;\r\nint ret;\r\ncmd = container_of(header, struct vmw_query_cmd, header);\r\nret = vmw_cmd_cid_check(dev_priv, sw_context, header);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nret = vmw_translate_guest_ptr(dev_priv, sw_context,\r\n&cmd->q.guestResult,\r\n&vmw_bo);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nret = vmw_query_bo_switch_prepare(dev_priv, cmd->q.cid,\r\n&vmw_bo->base, sw_context);\r\nvmw_dmabuf_unreference(&vmw_bo);\r\nreturn ret;\r\n}\r\nstatic int vmw_cmd_wait_query(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_dma_buffer *vmw_bo;\r\nstruct vmw_query_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdWaitForQuery q;\r\n} *cmd;\r\nint ret;\r\nstruct vmw_resource *ctx;\r\ncmd = container_of(header, struct vmw_query_cmd, header);\r\nret = vmw_cmd_cid_check(dev_priv, sw_context, header);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nret = vmw_translate_guest_ptr(dev_priv, sw_context,\r\n&cmd->q.guestResult,\r\n&vmw_bo);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nvmw_dmabuf_unreference(&vmw_bo);\r\nctx = sw_context->cur_ctx;\r\nif (!list_empty(&ctx->query_head))\r\nlist_del_init(&ctx->query_head);\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_dma(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_dma_buffer *vmw_bo = NULL;\r\nstruct ttm_buffer_object *bo;\r\nstruct vmw_surface *srf = NULL;\r\nstruct vmw_dma_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdSurfaceDMA dma;\r\n} *cmd;\r\nint ret;\r\nstruct vmw_resource *res;\r\ncmd = container_of(header, struct vmw_dma_cmd, header);\r\nret = vmw_translate_guest_ptr(dev_priv, sw_context,\r\n&cmd->dma.guest.ptr,\r\n&vmw_bo);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nbo = &vmw_bo->base;\r\nret = vmw_user_surface_lookup_handle(dev_priv, sw_context->tfile,\r\ncmd->dma.host.sid, &srf);\r\nif (ret) {\r\nDRM_ERROR("could not find surface\n");\r\ngoto out_no_reloc;\r\n}\r\nret = vmw_surface_validate(dev_priv, srf);\r\nif (unlikely(ret != 0)) {\r\nif (ret != -ERESTARTSYS)\r\nDRM_ERROR("Culd not validate surface.\n");\r\ngoto out_no_validate;\r\n}\r\ncmd->dma.host.sid = srf->res.id;\r\nvmw_kms_cursor_snoop(srf, sw_context->tfile, bo, header);\r\nvmw_dmabuf_unreference(&vmw_bo);\r\nres = &srf->res;\r\nvmw_resource_to_validate_list(sw_context, &res);\r\nreturn 0;\r\nout_no_validate:\r\nvmw_surface_unreference(&srf);\r\nout_no_reloc:\r\nvmw_dmabuf_unreference(&vmw_bo);\r\nreturn ret;\r\n}\r\nstatic int vmw_cmd_draw(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_draw_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdDrawPrimitives body;\r\n} *cmd;\r\nSVGA3dVertexDecl *decl = (SVGA3dVertexDecl *)(\r\n(unsigned long)header + sizeof(*cmd));\r\nSVGA3dPrimitiveRange *range;\r\nuint32_t i;\r\nuint32_t maxnum;\r\nint ret;\r\nret = vmw_cmd_cid_check(dev_priv, sw_context, header);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\ncmd = container_of(header, struct vmw_draw_cmd, header);\r\nmaxnum = (header->size - sizeof(cmd->body)) / sizeof(*decl);\r\nif (unlikely(cmd->body.numVertexDecls > maxnum)) {\r\nDRM_ERROR("Illegal number of vertex declarations.\n");\r\nreturn -EINVAL;\r\n}\r\nfor (i = 0; i < cmd->body.numVertexDecls; ++i, ++decl) {\r\nret = vmw_cmd_sid_check(dev_priv, sw_context,\r\n&decl->array.surfaceId);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n}\r\nmaxnum = (header->size - sizeof(cmd->body) -\r\ncmd->body.numVertexDecls * sizeof(*decl)) / sizeof(*range);\r\nif (unlikely(cmd->body.numRanges > maxnum)) {\r\nDRM_ERROR("Illegal number of index ranges.\n");\r\nreturn -EINVAL;\r\n}\r\nrange = (SVGA3dPrimitiveRange *) decl;\r\nfor (i = 0; i < cmd->body.numRanges; ++i, ++range) {\r\nret = vmw_cmd_sid_check(dev_priv, sw_context,\r\n&range->indexArray.surfaceId);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_tex_state(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nSVGA3dCmdHeader *header)\r\n{\r\nstruct vmw_tex_state_cmd {\r\nSVGA3dCmdHeader header;\r\nSVGA3dCmdSetTextureState state;\r\n};\r\nSVGA3dTextureState *last_state = (SVGA3dTextureState *)\r\n((unsigned long) header + header->size + sizeof(header));\r\nSVGA3dTextureState *cur_state = (SVGA3dTextureState *)\r\n((unsigned long) header + sizeof(struct vmw_tex_state_cmd));\r\nint ret;\r\nret = vmw_cmd_cid_check(dev_priv, sw_context, header);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nfor (; cur_state < last_state; ++cur_state) {\r\nif (likely(cur_state->name != SVGA3D_TS_BIND_TEXTURE))\r\ncontinue;\r\nret = vmw_cmd_sid_check(dev_priv, sw_context,\r\n&cur_state->value);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_check_define_gmrfb(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nvoid *buf)\r\n{\r\nstruct vmw_dma_buffer *vmw_bo;\r\nint ret;\r\nstruct {\r\nuint32_t header;\r\nSVGAFifoCmdDefineGMRFB body;\r\n} *cmd = buf;\r\nret = vmw_translate_guest_ptr(dev_priv, sw_context,\r\n&cmd->body.ptr,\r\n&vmw_bo);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nvmw_dmabuf_unreference(&vmw_bo);\r\nreturn ret;\r\n}\r\nstatic int vmw_cmd_check_not_3d(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nvoid *buf, uint32_t *size)\r\n{\r\nuint32_t size_remaining = *size;\r\nuint32_t cmd_id;\r\ncmd_id = le32_to_cpu(((uint32_t *)buf)[0]);\r\nswitch (cmd_id) {\r\ncase SVGA_CMD_UPDATE:\r\n*size = sizeof(uint32_t) + sizeof(SVGAFifoCmdUpdate);\r\nbreak;\r\ncase SVGA_CMD_DEFINE_GMRFB:\r\n*size = sizeof(uint32_t) + sizeof(SVGAFifoCmdDefineGMRFB);\r\nbreak;\r\ncase SVGA_CMD_BLIT_GMRFB_TO_SCREEN:\r\n*size = sizeof(uint32_t) + sizeof(SVGAFifoCmdBlitGMRFBToScreen);\r\nbreak;\r\ncase SVGA_CMD_BLIT_SCREEN_TO_GMRFB:\r\n*size = sizeof(uint32_t) + sizeof(SVGAFifoCmdBlitGMRFBToScreen);\r\nbreak;\r\ndefault:\r\nDRM_ERROR("Unsupported SVGA command: %u.\n", cmd_id);\r\nreturn -EINVAL;\r\n}\r\nif (*size > size_remaining) {\r\nDRM_ERROR("Invalid SVGA command (size mismatch):"\r\n" %u.\n", cmd_id);\r\nreturn -EINVAL;\r\n}\r\nif (unlikely(!sw_context->kernel)) {\r\nDRM_ERROR("Kernel only SVGA command: %u.\n", cmd_id);\r\nreturn -EPERM;\r\n}\r\nif (cmd_id == SVGA_CMD_DEFINE_GMRFB)\r\nreturn vmw_cmd_check_define_gmrfb(dev_priv, sw_context, buf);\r\nreturn 0;\r\n}\r\nstatic int vmw_cmd_check(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nvoid *buf, uint32_t *size)\r\n{\r\nuint32_t cmd_id;\r\nuint32_t size_remaining = *size;\r\nSVGA3dCmdHeader *header = (SVGA3dCmdHeader *) buf;\r\nint ret;\r\ncmd_id = le32_to_cpu(((uint32_t *)buf)[0]);\r\nif (unlikely(cmd_id < SVGA_CMD_MAX))\r\nreturn vmw_cmd_check_not_3d(dev_priv, sw_context, buf, size);\r\ncmd_id = le32_to_cpu(header->id);\r\n*size = le32_to_cpu(header->size) + sizeof(SVGA3dCmdHeader);\r\ncmd_id -= SVGA_3D_CMD_BASE;\r\nif (unlikely(*size > size_remaining))\r\ngoto out_err;\r\nif (unlikely(cmd_id >= SVGA_3D_CMD_MAX - SVGA_3D_CMD_BASE))\r\ngoto out_err;\r\nret = vmw_cmd_funcs[cmd_id](dev_priv, sw_context, header);\r\nif (unlikely(ret != 0))\r\ngoto out_err;\r\nreturn 0;\r\nout_err:\r\nDRM_ERROR("Illegal / Invalid SVGA3D command: %d\n",\r\ncmd_id + SVGA_3D_CMD_BASE);\r\nreturn -EINVAL;\r\n}\r\nstatic int vmw_cmd_check_all(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context,\r\nvoid *buf,\r\nuint32_t size)\r\n{\r\nint32_t cur_size = size;\r\nint ret;\r\nwhile (cur_size > 0) {\r\nsize = cur_size;\r\nret = vmw_cmd_check(dev_priv, sw_context, buf, &size);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nbuf = (void *)((unsigned long) buf + size);\r\ncur_size -= size;\r\n}\r\nif (unlikely(cur_size != 0)) {\r\nDRM_ERROR("Command verifier out of sync.\n");\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic void vmw_free_relocations(struct vmw_sw_context *sw_context)\r\n{\r\nsw_context->cur_reloc = 0;\r\n}\r\nstatic void vmw_apply_relocations(struct vmw_sw_context *sw_context)\r\n{\r\nuint32_t i;\r\nstruct vmw_relocation *reloc;\r\nstruct ttm_validate_buffer *validate;\r\nstruct ttm_buffer_object *bo;\r\nfor (i = 0; i < sw_context->cur_reloc; ++i) {\r\nreloc = &sw_context->relocs[i];\r\nvalidate = &sw_context->val_bufs[reloc->index];\r\nbo = validate->bo;\r\nif (bo->mem.mem_type == TTM_PL_VRAM) {\r\nreloc->location->offset += bo->offset;\r\nreloc->location->gmrId = SVGA_GMR_FRAMEBUFFER;\r\n} else\r\nreloc->location->gmrId = bo->mem.start;\r\n}\r\nvmw_free_relocations(sw_context);\r\n}\r\nstatic void vmw_clear_validations(struct vmw_sw_context *sw_context)\r\n{\r\nstruct ttm_validate_buffer *entry, *next;\r\nstruct vmw_resource *res, *res_next;\r\nlist_for_each_entry_safe(entry, next, &sw_context->validate_nodes,\r\nhead) {\r\nlist_del(&entry->head);\r\nvmw_dmabuf_validate_clear(entry->bo);\r\nttm_bo_unref(&entry->bo);\r\nsw_context->cur_val_buf--;\r\n}\r\nBUG_ON(sw_context->cur_val_buf != 0);\r\nvmw_resource_unreserve(&sw_context->resource_list);\r\nlist_for_each_entry_safe(res, res_next, &sw_context->resource_list,\r\nvalidate_head) {\r\nlist_del_init(&res->validate_head);\r\nvmw_resource_unreference(&res);\r\n}\r\n}\r\nstatic int vmw_validate_single_buffer(struct vmw_private *dev_priv,\r\nstruct ttm_buffer_object *bo)\r\n{\r\nint ret;\r\nif (bo == dev_priv->pinned_bo ||\r\n(bo == dev_priv->dummy_query_bo &&\r\ndev_priv->dummy_query_bo_pinned))\r\nreturn 0;\r\nret = ttm_bo_validate(bo, &vmw_vram_gmr_placement, true, false, false);\r\nif (likely(ret == 0 || ret == -ERESTARTSYS))\r\nreturn ret;\r\nDRM_INFO("Falling through to VRAM.\n");\r\nret = ttm_bo_validate(bo, &vmw_vram_placement, true, false, false);\r\nreturn ret;\r\n}\r\nstatic int vmw_validate_buffers(struct vmw_private *dev_priv,\r\nstruct vmw_sw_context *sw_context)\r\n{\r\nstruct ttm_validate_buffer *entry;\r\nint ret;\r\nlist_for_each_entry(entry, &sw_context->validate_nodes, head) {\r\nret = vmw_validate_single_buffer(dev_priv, entry->bo);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic int vmw_resize_cmd_bounce(struct vmw_sw_context *sw_context,\r\nuint32_t size)\r\n{\r\nif (likely(sw_context->cmd_bounce_size >= size))\r\nreturn 0;\r\nif (sw_context->cmd_bounce_size == 0)\r\nsw_context->cmd_bounce_size = VMWGFX_CMD_BOUNCE_INIT_SIZE;\r\nwhile (sw_context->cmd_bounce_size < size) {\r\nsw_context->cmd_bounce_size =\r\nPAGE_ALIGN(sw_context->cmd_bounce_size +\r\n(sw_context->cmd_bounce_size >> 1));\r\n}\r\nif (sw_context->cmd_bounce != NULL)\r\nvfree(sw_context->cmd_bounce);\r\nsw_context->cmd_bounce = vmalloc(sw_context->cmd_bounce_size);\r\nif (sw_context->cmd_bounce == NULL) {\r\nDRM_ERROR("Failed to allocate command bounce buffer.\n");\r\nsw_context->cmd_bounce_size = 0;\r\nreturn -ENOMEM;\r\n}\r\nreturn 0;\r\n}\r\nint vmw_execbuf_fence_commands(struct drm_file *file_priv,\r\nstruct vmw_private *dev_priv,\r\nstruct vmw_fence_obj **p_fence,\r\nuint32_t *p_handle)\r\n{\r\nuint32_t sequence;\r\nint ret;\r\nbool synced = false;\r\nBUG_ON(p_handle != NULL && file_priv == NULL);\r\nret = vmw_fifo_send_fence(dev_priv, &sequence);\r\nif (unlikely(ret != 0)) {\r\nDRM_ERROR("Fence submission error. Syncing.\n");\r\nsynced = true;\r\n}\r\nif (p_handle != NULL)\r\nret = vmw_user_fence_create(file_priv, dev_priv->fman,\r\nsequence,\r\nDRM_VMW_FENCE_FLAG_EXEC,\r\np_fence, p_handle);\r\nelse\r\nret = vmw_fence_create(dev_priv->fman, sequence,\r\nDRM_VMW_FENCE_FLAG_EXEC,\r\np_fence);\r\nif (unlikely(ret != 0 && !synced)) {\r\n(void) vmw_fallback_wait(dev_priv, false, false,\r\nsequence, false,\r\nVMW_FENCE_WAIT_TIMEOUT);\r\n*p_fence = NULL;\r\n}\r\nreturn 0;\r\n}\r\nvoid\r\nvmw_execbuf_copy_fence_user(struct vmw_private *dev_priv,\r\nstruct vmw_fpriv *vmw_fp,\r\nint ret,\r\nstruct drm_vmw_fence_rep __user *user_fence_rep,\r\nstruct vmw_fence_obj *fence,\r\nuint32_t fence_handle)\r\n{\r\nstruct drm_vmw_fence_rep fence_rep;\r\nif (user_fence_rep == NULL)\r\nreturn;\r\nmemset(&fence_rep, 0, sizeof(fence_rep));\r\nfence_rep.error = ret;\r\nif (ret == 0) {\r\nBUG_ON(fence == NULL);\r\nfence_rep.handle = fence_handle;\r\nfence_rep.seqno = fence->seqno;\r\nvmw_update_seqno(dev_priv, &dev_priv->fifo);\r\nfence_rep.passed_seqno = dev_priv->last_read_seqno;\r\n}\r\nret = copy_to_user(user_fence_rep, &fence_rep,\r\nsizeof(fence_rep));\r\nif (unlikely(ret != 0) && (fence_rep.error == 0)) {\r\nttm_ref_object_base_unref(vmw_fp->tfile,\r\nfence_handle, TTM_REF_USAGE);\r\nDRM_ERROR("Fence copy error. Syncing.\n");\r\n(void) vmw_fence_obj_wait(fence, fence->signal_mask,\r\nfalse, false,\r\nVMW_FENCE_WAIT_TIMEOUT);\r\n}\r\n}\r\nint vmw_execbuf_process(struct drm_file *file_priv,\r\nstruct vmw_private *dev_priv,\r\nvoid __user *user_commands,\r\nvoid *kernel_commands,\r\nuint32_t command_size,\r\nuint64_t throttle_us,\r\nstruct drm_vmw_fence_rep __user *user_fence_rep,\r\nstruct vmw_fence_obj **out_fence)\r\n{\r\nstruct vmw_sw_context *sw_context = &dev_priv->ctx;\r\nstruct vmw_fence_obj *fence = NULL;\r\nuint32_t handle;\r\nvoid *cmd;\r\nint ret;\r\nret = mutex_lock_interruptible(&dev_priv->cmdbuf_mutex);\r\nif (unlikely(ret != 0))\r\nreturn -ERESTARTSYS;\r\nif (kernel_commands == NULL) {\r\nsw_context->kernel = false;\r\nret = vmw_resize_cmd_bounce(sw_context, command_size);\r\nif (unlikely(ret != 0))\r\ngoto out_unlock;\r\nret = copy_from_user(sw_context->cmd_bounce,\r\nuser_commands, command_size);\r\nif (unlikely(ret != 0)) {\r\nret = -EFAULT;\r\nDRM_ERROR("Failed copying commands.\n");\r\ngoto out_unlock;\r\n}\r\nkernel_commands = sw_context->cmd_bounce;\r\n} else\r\nsw_context->kernel = true;\r\nsw_context->tfile = vmw_fpriv(file_priv)->tfile;\r\nsw_context->cid_valid = false;\r\nsw_context->sid_valid = false;\r\nsw_context->cur_reloc = 0;\r\nsw_context->cur_val_buf = 0;\r\nsw_context->fence_flags = 0;\r\nINIT_LIST_HEAD(&sw_context->query_list);\r\nINIT_LIST_HEAD(&sw_context->resource_list);\r\nsw_context->cur_query_bo = dev_priv->pinned_bo;\r\nsw_context->cur_query_cid = dev_priv->query_cid;\r\nsw_context->query_cid_valid = (dev_priv->pinned_bo != NULL);\r\nINIT_LIST_HEAD(&sw_context->validate_nodes);\r\nret = vmw_cmd_check_all(dev_priv, sw_context, kernel_commands,\r\ncommand_size);\r\nif (unlikely(ret != 0))\r\ngoto out_err;\r\nret = ttm_eu_reserve_buffers(&sw_context->validate_nodes);\r\nif (unlikely(ret != 0))\r\ngoto out_err;\r\nret = vmw_validate_buffers(dev_priv, sw_context);\r\nif (unlikely(ret != 0))\r\ngoto out_err;\r\nvmw_apply_relocations(sw_context);\r\nif (throttle_us) {\r\nret = vmw_wait_lag(dev_priv, &dev_priv->fifo.marker_queue,\r\nthrottle_us);\r\nif (unlikely(ret != 0))\r\ngoto out_throttle;\r\n}\r\ncmd = vmw_fifo_reserve(dev_priv, command_size);\r\nif (unlikely(cmd == NULL)) {\r\nDRM_ERROR("Failed reserving fifo space for commands.\n");\r\nret = -ENOMEM;\r\ngoto out_throttle;\r\n}\r\nmemcpy(cmd, kernel_commands, command_size);\r\nvmw_fifo_commit(dev_priv, command_size);\r\nvmw_query_bo_switch_commit(dev_priv, sw_context);\r\nret = vmw_execbuf_fence_commands(file_priv, dev_priv,\r\n&fence,\r\n(user_fence_rep) ? &handle : NULL);\r\nif (ret != 0)\r\nDRM_ERROR("Fence submission error. Syncing.\n");\r\nttm_eu_fence_buffer_objects(&sw_context->validate_nodes,\r\n(void *) fence);\r\nvmw_clear_validations(sw_context);\r\nvmw_execbuf_copy_fence_user(dev_priv, vmw_fpriv(file_priv), ret,\r\nuser_fence_rep, fence, handle);\r\nif (unlikely(out_fence != NULL)) {\r\n*out_fence = fence;\r\nfence = NULL;\r\n} else if (likely(fence != NULL)) {\r\nvmw_fence_obj_unreference(&fence);\r\n}\r\nmutex_unlock(&dev_priv->cmdbuf_mutex);\r\nreturn 0;\r\nout_err:\r\nvmw_free_relocations(sw_context);\r\nout_throttle:\r\nvmw_query_switch_backoff(sw_context);\r\nttm_eu_backoff_reservation(&sw_context->validate_nodes);\r\nvmw_clear_validations(sw_context);\r\nout_unlock:\r\nmutex_unlock(&dev_priv->cmdbuf_mutex);\r\nreturn ret;\r\n}\r\nstatic void vmw_execbuf_unpin_panic(struct vmw_private *dev_priv)\r\n{\r\nDRM_ERROR("Can't unpin query buffer. Trying to recover.\n");\r\n(void) vmw_fallback_wait(dev_priv, false, true, 0, false, 10*HZ);\r\nvmw_bo_pin(dev_priv->pinned_bo, false);\r\nvmw_bo_pin(dev_priv->dummy_query_bo, false);\r\ndev_priv->dummy_query_bo_pinned = false;\r\n}\r\nvoid vmw_execbuf_release_pinned_bo(struct vmw_private *dev_priv,\r\nbool only_on_cid_match, uint32_t cid)\r\n{\r\nint ret = 0;\r\nstruct list_head validate_list;\r\nstruct ttm_validate_buffer pinned_val, query_val;\r\nstruct vmw_fence_obj *fence;\r\nmutex_lock(&dev_priv->cmdbuf_mutex);\r\nif (dev_priv->pinned_bo == NULL)\r\ngoto out_unlock;\r\nif (only_on_cid_match && cid != dev_priv->query_cid)\r\ngoto out_unlock;\r\nINIT_LIST_HEAD(&validate_list);\r\npinned_val.new_sync_obj_arg = (void *)(unsigned long)\r\nDRM_VMW_FENCE_FLAG_EXEC;\r\npinned_val.bo = ttm_bo_reference(dev_priv->pinned_bo);\r\nlist_add_tail(&pinned_val.head, &validate_list);\r\nquery_val.new_sync_obj_arg = pinned_val.new_sync_obj_arg;\r\nquery_val.bo = ttm_bo_reference(dev_priv->dummy_query_bo);\r\nlist_add_tail(&query_val.head, &validate_list);\r\ndo {\r\nret = ttm_eu_reserve_buffers(&validate_list);\r\n} while (ret == -ERESTARTSYS);\r\nif (unlikely(ret != 0)) {\r\nvmw_execbuf_unpin_panic(dev_priv);\r\ngoto out_no_reserve;\r\n}\r\nret = vmw_fifo_emit_dummy_query(dev_priv, dev_priv->query_cid);\r\nif (unlikely(ret != 0)) {\r\nvmw_execbuf_unpin_panic(dev_priv);\r\ngoto out_no_emit;\r\n}\r\nvmw_bo_pin(dev_priv->pinned_bo, false);\r\nvmw_bo_pin(dev_priv->dummy_query_bo, false);\r\ndev_priv->dummy_query_bo_pinned = false;\r\n(void) vmw_execbuf_fence_commands(NULL, dev_priv, &fence, NULL);\r\nttm_eu_fence_buffer_objects(&validate_list, (void *) fence);\r\nttm_bo_unref(&query_val.bo);\r\nttm_bo_unref(&pinned_val.bo);\r\nttm_bo_unref(&dev_priv->pinned_bo);\r\nout_unlock:\r\nmutex_unlock(&dev_priv->cmdbuf_mutex);\r\nreturn;\r\nout_no_emit:\r\nttm_eu_backoff_reservation(&validate_list);\r\nout_no_reserve:\r\nttm_bo_unref(&query_val.bo);\r\nttm_bo_unref(&pinned_val.bo);\r\nttm_bo_unref(&dev_priv->pinned_bo);\r\nmutex_unlock(&dev_priv->cmdbuf_mutex);\r\n}\r\nint vmw_execbuf_ioctl(struct drm_device *dev, void *data,\r\nstruct drm_file *file_priv)\r\n{\r\nstruct vmw_private *dev_priv = vmw_priv(dev);\r\nstruct drm_vmw_execbuf_arg *arg = (struct drm_vmw_execbuf_arg *)data;\r\nstruct vmw_master *vmaster = vmw_master(file_priv->master);\r\nint ret;\r\nif (unlikely(arg->version != DRM_VMW_EXECBUF_VERSION)) {\r\nDRM_ERROR("Incorrect execbuf version.\n");\r\nDRM_ERROR("You're running outdated experimental "\r\n"vmwgfx user-space drivers.");\r\nreturn -EINVAL;\r\n}\r\nret = ttm_read_lock(&vmaster->lock, true);\r\nif (unlikely(ret != 0))\r\nreturn ret;\r\nret = vmw_execbuf_process(file_priv, dev_priv,\r\n(void __user *)(unsigned long)arg->commands,\r\nNULL, arg->command_size, arg->throttle_us,\r\n(void __user *)(unsigned long)arg->fence_rep,\r\nNULL);\r\nif (unlikely(ret != 0))\r\ngoto out_unlock;\r\nvmw_kms_cursor_post_execbuf(dev_priv);\r\nout_unlock:\r\nttm_read_unlock(&vmaster->lock);\r\nreturn ret;\r\n}
