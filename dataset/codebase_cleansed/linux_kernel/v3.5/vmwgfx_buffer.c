static int vmw_ttm_bind(struct ttm_tt *ttm, struct ttm_mem_reg *bo_mem)\r\n{\r\nstruct vmw_ttm_tt *vmw_be = container_of(ttm, struct vmw_ttm_tt, ttm);\r\nvmw_be->gmr_id = bo_mem->start;\r\nreturn vmw_gmr_bind(vmw_be->dev_priv, ttm->pages,\r\nttm->num_pages, vmw_be->gmr_id);\r\n}\r\nstatic int vmw_ttm_unbind(struct ttm_tt *ttm)\r\n{\r\nstruct vmw_ttm_tt *vmw_be = container_of(ttm, struct vmw_ttm_tt, ttm);\r\nvmw_gmr_unbind(vmw_be->dev_priv, vmw_be->gmr_id);\r\nreturn 0;\r\n}\r\nstatic void vmw_ttm_destroy(struct ttm_tt *ttm)\r\n{\r\nstruct vmw_ttm_tt *vmw_be = container_of(ttm, struct vmw_ttm_tt, ttm);\r\nttm_tt_fini(ttm);\r\nkfree(vmw_be);\r\n}\r\nstruct ttm_tt *vmw_ttm_tt_create(struct ttm_bo_device *bdev,\r\nunsigned long size, uint32_t page_flags,\r\nstruct page *dummy_read_page)\r\n{\r\nstruct vmw_ttm_tt *vmw_be;\r\nvmw_be = kmalloc(sizeof(*vmw_be), GFP_KERNEL);\r\nif (!vmw_be)\r\nreturn NULL;\r\nvmw_be->ttm.func = &vmw_ttm_func;\r\nvmw_be->dev_priv = container_of(bdev, struct vmw_private, bdev);\r\nif (ttm_tt_init(&vmw_be->ttm, bdev, size, page_flags, dummy_read_page)) {\r\nkfree(vmw_be);\r\nreturn NULL;\r\n}\r\nreturn &vmw_be->ttm;\r\n}\r\nint vmw_invalidate_caches(struct ttm_bo_device *bdev, uint32_t flags)\r\n{\r\nreturn 0;\r\n}\r\nint vmw_init_mem_type(struct ttm_bo_device *bdev, uint32_t type,\r\nstruct ttm_mem_type_manager *man)\r\n{\r\nswitch (type) {\r\ncase TTM_PL_SYSTEM:\r\nman->flags = TTM_MEMTYPE_FLAG_MAPPABLE;\r\nman->available_caching = TTM_PL_FLAG_CACHED;\r\nman->default_caching = TTM_PL_FLAG_CACHED;\r\nbreak;\r\ncase TTM_PL_VRAM:\r\nman->func = &ttm_bo_manager_func;\r\nman->gpu_offset = 0;\r\nman->flags = TTM_MEMTYPE_FLAG_FIXED | TTM_MEMTYPE_FLAG_MAPPABLE;\r\nman->available_caching = TTM_PL_FLAG_CACHED;\r\nman->default_caching = TTM_PL_FLAG_CACHED;\r\nbreak;\r\ncase VMW_PL_GMR:\r\nman->func = &vmw_gmrid_manager_func;\r\nman->gpu_offset = 0;\r\nman->flags = TTM_MEMTYPE_FLAG_CMA | TTM_MEMTYPE_FLAG_MAPPABLE;\r\nman->available_caching = TTM_PL_FLAG_CACHED;\r\nman->default_caching = TTM_PL_FLAG_CACHED;\r\nbreak;\r\ndefault:\r\nDRM_ERROR("Unsupported memory type %u\n", (unsigned)type);\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nvoid vmw_evict_flags(struct ttm_buffer_object *bo,\r\nstruct ttm_placement *placement)\r\n{\r\n*placement = vmw_sys_placement;\r\n}\r\nstatic int vmw_verify_access(struct ttm_buffer_object *bo, struct file *filp)\r\n{\r\nreturn 0;\r\n}\r\nstatic int vmw_ttm_io_mem_reserve(struct ttm_bo_device *bdev, struct ttm_mem_reg *mem)\r\n{\r\nstruct ttm_mem_type_manager *man = &bdev->man[mem->mem_type];\r\nstruct vmw_private *dev_priv = container_of(bdev, struct vmw_private, bdev);\r\nmem->bus.addr = NULL;\r\nmem->bus.is_iomem = false;\r\nmem->bus.offset = 0;\r\nmem->bus.size = mem->num_pages << PAGE_SHIFT;\r\nmem->bus.base = 0;\r\nif (!(man->flags & TTM_MEMTYPE_FLAG_MAPPABLE))\r\nreturn -EINVAL;\r\nswitch (mem->mem_type) {\r\ncase TTM_PL_SYSTEM:\r\ncase VMW_PL_GMR:\r\nreturn 0;\r\ncase TTM_PL_VRAM:\r\nmem->bus.offset = mem->start << PAGE_SHIFT;\r\nmem->bus.base = dev_priv->vram_start;\r\nmem->bus.is_iomem = true;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic void vmw_ttm_io_mem_free(struct ttm_bo_device *bdev, struct ttm_mem_reg *mem)\r\n{\r\n}\r\nstatic int vmw_ttm_fault_reserve_notify(struct ttm_buffer_object *bo)\r\n{\r\nreturn 0;\r\n}\r\nstatic void *vmw_sync_obj_ref(void *sync_obj)\r\n{\r\nreturn (void *)\r\nvmw_fence_obj_reference((struct vmw_fence_obj *) sync_obj);\r\n}\r\nstatic void vmw_sync_obj_unref(void **sync_obj)\r\n{\r\nvmw_fence_obj_unreference((struct vmw_fence_obj **) sync_obj);\r\n}\r\nstatic int vmw_sync_obj_flush(void *sync_obj, void *sync_arg)\r\n{\r\nvmw_fence_obj_flush((struct vmw_fence_obj *) sync_obj);\r\nreturn 0;\r\n}\r\nstatic bool vmw_sync_obj_signaled(void *sync_obj, void *sync_arg)\r\n{\r\nunsigned long flags = (unsigned long) sync_arg;\r\nreturn vmw_fence_obj_signaled((struct vmw_fence_obj *) sync_obj,\r\n(uint32_t) flags);\r\n}\r\nstatic int vmw_sync_obj_wait(void *sync_obj, void *sync_arg,\r\nbool lazy, bool interruptible)\r\n{\r\nunsigned long flags = (unsigned long) sync_arg;\r\nreturn vmw_fence_obj_wait((struct vmw_fence_obj *) sync_obj,\r\n(uint32_t) flags,\r\nlazy, interruptible,\r\nVMW_FENCE_WAIT_TIMEOUT);\r\n}
