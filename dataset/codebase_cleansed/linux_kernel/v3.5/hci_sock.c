static inline int hci_test_bit(int nr, void *addr)\r\n{\r\nreturn *((__u32 *) addr + (nr >> 5)) & ((__u32) 1 << (nr & 31));\r\n}\r\nvoid hci_send_to_sock(struct hci_dev *hdev, struct sk_buff *skb)\r\n{\r\nstruct sock *sk;\r\nstruct hlist_node *node;\r\nstruct sk_buff *skb_copy = NULL;\r\nBT_DBG("hdev %p len %d", hdev, skb->len);\r\nread_lock(&hci_sk_list.lock);\r\nsk_for_each(sk, node, &hci_sk_list.head) {\r\nstruct hci_filter *flt;\r\nstruct sk_buff *nskb;\r\nif (sk->sk_state != BT_BOUND || hci_pi(sk)->hdev != hdev)\r\ncontinue;\r\nif (skb->sk == sk)\r\ncontinue;\r\nif (hci_pi(sk)->channel != HCI_CHANNEL_RAW)\r\ncontinue;\r\nflt = &hci_pi(sk)->filter;\r\nif (!test_bit((bt_cb(skb)->pkt_type == HCI_VENDOR_PKT) ?\r\n0 : (bt_cb(skb)->pkt_type & HCI_FLT_TYPE_BITS), &flt->type_mask))\r\ncontinue;\r\nif (bt_cb(skb)->pkt_type == HCI_EVENT_PKT) {\r\nregister int evt = (*(__u8 *)skb->data & HCI_FLT_EVENT_BITS);\r\nif (!hci_test_bit(evt, &flt->event_mask))\r\ncontinue;\r\nif (flt->opcode &&\r\n((evt == HCI_EV_CMD_COMPLETE &&\r\nflt->opcode !=\r\nget_unaligned((__le16 *)(skb->data + 3))) ||\r\n(evt == HCI_EV_CMD_STATUS &&\r\nflt->opcode !=\r\nget_unaligned((__le16 *)(skb->data + 4)))))\r\ncontinue;\r\n}\r\nif (!skb_copy) {\r\nskb_copy = __pskb_copy(skb, 1, GFP_ATOMIC);\r\nif (!skb_copy)\r\ncontinue;\r\nmemcpy(skb_push(skb_copy, 1), &bt_cb(skb)->pkt_type, 1);\r\n}\r\nnskb = skb_clone(skb_copy, GFP_ATOMIC);\r\nif (!nskb)\r\ncontinue;\r\nif (sock_queue_rcv_skb(sk, nskb))\r\nkfree_skb(nskb);\r\n}\r\nread_unlock(&hci_sk_list.lock);\r\nkfree_skb(skb_copy);\r\n}\r\nvoid hci_send_to_control(struct sk_buff *skb, struct sock *skip_sk)\r\n{\r\nstruct sock *sk;\r\nstruct hlist_node *node;\r\nBT_DBG("len %d", skb->len);\r\nread_lock(&hci_sk_list.lock);\r\nsk_for_each(sk, node, &hci_sk_list.head) {\r\nstruct sk_buff *nskb;\r\nif (sk == skip_sk)\r\ncontinue;\r\nif (sk->sk_state != BT_BOUND)\r\ncontinue;\r\nif (hci_pi(sk)->channel != HCI_CHANNEL_CONTROL)\r\ncontinue;\r\nnskb = skb_clone(skb, GFP_ATOMIC);\r\nif (!nskb)\r\ncontinue;\r\nif (sock_queue_rcv_skb(sk, nskb))\r\nkfree_skb(nskb);\r\n}\r\nread_unlock(&hci_sk_list.lock);\r\n}\r\nvoid hci_send_to_monitor(struct hci_dev *hdev, struct sk_buff *skb)\r\n{\r\nstruct sock *sk;\r\nstruct hlist_node *node;\r\nstruct sk_buff *skb_copy = NULL;\r\n__le16 opcode;\r\nif (!atomic_read(&monitor_promisc))\r\nreturn;\r\nBT_DBG("hdev %p len %d", hdev, skb->len);\r\nswitch (bt_cb(skb)->pkt_type) {\r\ncase HCI_COMMAND_PKT:\r\nopcode = __constant_cpu_to_le16(HCI_MON_COMMAND_PKT);\r\nbreak;\r\ncase HCI_EVENT_PKT:\r\nopcode = __constant_cpu_to_le16(HCI_MON_EVENT_PKT);\r\nbreak;\r\ncase HCI_ACLDATA_PKT:\r\nif (bt_cb(skb)->incoming)\r\nopcode = __constant_cpu_to_le16(HCI_MON_ACL_RX_PKT);\r\nelse\r\nopcode = __constant_cpu_to_le16(HCI_MON_ACL_TX_PKT);\r\nbreak;\r\ncase HCI_SCODATA_PKT:\r\nif (bt_cb(skb)->incoming)\r\nopcode = __constant_cpu_to_le16(HCI_MON_SCO_RX_PKT);\r\nelse\r\nopcode = __constant_cpu_to_le16(HCI_MON_SCO_TX_PKT);\r\nbreak;\r\ndefault:\r\nreturn;\r\n}\r\nread_lock(&hci_sk_list.lock);\r\nsk_for_each(sk, node, &hci_sk_list.head) {\r\nstruct sk_buff *nskb;\r\nif (sk->sk_state != BT_BOUND)\r\ncontinue;\r\nif (hci_pi(sk)->channel != HCI_CHANNEL_MONITOR)\r\ncontinue;\r\nif (!skb_copy) {\r\nstruct hci_mon_hdr *hdr;\r\nskb_copy = __pskb_copy(skb, HCI_MON_HDR_SIZE, GFP_ATOMIC);\r\nif (!skb_copy)\r\ncontinue;\r\nhdr = (void *) skb_push(skb_copy, HCI_MON_HDR_SIZE);\r\nhdr->opcode = opcode;\r\nhdr->index = cpu_to_le16(hdev->id);\r\nhdr->len = cpu_to_le16(skb->len);\r\n}\r\nnskb = skb_clone(skb_copy, GFP_ATOMIC);\r\nif (!nskb)\r\ncontinue;\r\nif (sock_queue_rcv_skb(sk, nskb))\r\nkfree_skb(nskb);\r\n}\r\nread_unlock(&hci_sk_list.lock);\r\nkfree_skb(skb_copy);\r\n}\r\nstatic void send_monitor_event(struct sk_buff *skb)\r\n{\r\nstruct sock *sk;\r\nstruct hlist_node *node;\r\nBT_DBG("len %d", skb->len);\r\nread_lock(&hci_sk_list.lock);\r\nsk_for_each(sk, node, &hci_sk_list.head) {\r\nstruct sk_buff *nskb;\r\nif (sk->sk_state != BT_BOUND)\r\ncontinue;\r\nif (hci_pi(sk)->channel != HCI_CHANNEL_MONITOR)\r\ncontinue;\r\nnskb = skb_clone(skb, GFP_ATOMIC);\r\nif (!nskb)\r\ncontinue;\r\nif (sock_queue_rcv_skb(sk, nskb))\r\nkfree_skb(nskb);\r\n}\r\nread_unlock(&hci_sk_list.lock);\r\n}\r\nstatic struct sk_buff *create_monitor_event(struct hci_dev *hdev, int event)\r\n{\r\nstruct hci_mon_hdr *hdr;\r\nstruct hci_mon_new_index *ni;\r\nstruct sk_buff *skb;\r\n__le16 opcode;\r\nswitch (event) {\r\ncase HCI_DEV_REG:\r\nskb = bt_skb_alloc(HCI_MON_NEW_INDEX_SIZE, GFP_ATOMIC);\r\nif (!skb)\r\nreturn NULL;\r\nni = (void *) skb_put(skb, HCI_MON_NEW_INDEX_SIZE);\r\nni->type = hdev->dev_type;\r\nni->bus = hdev->bus;\r\nbacpy(&ni->bdaddr, &hdev->bdaddr);\r\nmemcpy(ni->name, hdev->name, 8);\r\nopcode = __constant_cpu_to_le16(HCI_MON_NEW_INDEX);\r\nbreak;\r\ncase HCI_DEV_UNREG:\r\nskb = bt_skb_alloc(0, GFP_ATOMIC);\r\nif (!skb)\r\nreturn NULL;\r\nopcode = __constant_cpu_to_le16(HCI_MON_DEL_INDEX);\r\nbreak;\r\ndefault:\r\nreturn NULL;\r\n}\r\n__net_timestamp(skb);\r\nhdr = (void *) skb_push(skb, HCI_MON_HDR_SIZE);\r\nhdr->opcode = opcode;\r\nhdr->index = cpu_to_le16(hdev->id);\r\nhdr->len = cpu_to_le16(skb->len - HCI_MON_HDR_SIZE);\r\nreturn skb;\r\n}\r\nstatic void send_monitor_replay(struct sock *sk)\r\n{\r\nstruct hci_dev *hdev;\r\nread_lock(&hci_dev_list_lock);\r\nlist_for_each_entry(hdev, &hci_dev_list, list) {\r\nstruct sk_buff *skb;\r\nskb = create_monitor_event(hdev, HCI_DEV_REG);\r\nif (!skb)\r\ncontinue;\r\nif (sock_queue_rcv_skb(sk, skb))\r\nkfree_skb(skb);\r\n}\r\nread_unlock(&hci_dev_list_lock);\r\n}\r\nstatic void hci_si_event(struct hci_dev *hdev, int type, int dlen, void *data)\r\n{\r\nstruct hci_event_hdr *hdr;\r\nstruct hci_ev_stack_internal *ev;\r\nstruct sk_buff *skb;\r\nskb = bt_skb_alloc(HCI_EVENT_HDR_SIZE + sizeof(*ev) + dlen, GFP_ATOMIC);\r\nif (!skb)\r\nreturn;\r\nhdr = (void *) skb_put(skb, HCI_EVENT_HDR_SIZE);\r\nhdr->evt = HCI_EV_STACK_INTERNAL;\r\nhdr->plen = sizeof(*ev) + dlen;\r\nev = (void *) skb_put(skb, sizeof(*ev) + dlen);\r\nev->type = type;\r\nmemcpy(ev->data, data, dlen);\r\nbt_cb(skb)->incoming = 1;\r\n__net_timestamp(skb);\r\nbt_cb(skb)->pkt_type = HCI_EVENT_PKT;\r\nskb->dev = (void *) hdev;\r\nhci_send_to_sock(hdev, skb);\r\nkfree_skb(skb);\r\n}\r\nvoid hci_sock_dev_event(struct hci_dev *hdev, int event)\r\n{\r\nstruct hci_ev_si_device ev;\r\nBT_DBG("hdev %s event %d", hdev->name, event);\r\nif (atomic_read(&monitor_promisc)) {\r\nstruct sk_buff *skb;\r\nskb = create_monitor_event(hdev, event);\r\nif (skb) {\r\nsend_monitor_event(skb);\r\nkfree_skb(skb);\r\n}\r\n}\r\nev.event = event;\r\nev.dev_id = hdev->id;\r\nhci_si_event(NULL, HCI_EV_SI_DEVICE, sizeof(ev), &ev);\r\nif (event == HCI_DEV_UNREG) {\r\nstruct sock *sk;\r\nstruct hlist_node *node;\r\nread_lock(&hci_sk_list.lock);\r\nsk_for_each(sk, node, &hci_sk_list.head) {\r\nbh_lock_sock_nested(sk);\r\nif (hci_pi(sk)->hdev == hdev) {\r\nhci_pi(sk)->hdev = NULL;\r\nsk->sk_err = EPIPE;\r\nsk->sk_state = BT_OPEN;\r\nsk->sk_state_change(sk);\r\nhci_dev_put(hdev);\r\n}\r\nbh_unlock_sock(sk);\r\n}\r\nread_unlock(&hci_sk_list.lock);\r\n}\r\n}\r\nstatic int hci_sock_release(struct socket *sock)\r\n{\r\nstruct sock *sk = sock->sk;\r\nstruct hci_dev *hdev;\r\nBT_DBG("sock %p sk %p", sock, sk);\r\nif (!sk)\r\nreturn 0;\r\nhdev = hci_pi(sk)->hdev;\r\nif (hci_pi(sk)->channel == HCI_CHANNEL_MONITOR)\r\natomic_dec(&monitor_promisc);\r\nbt_sock_unlink(&hci_sk_list, sk);\r\nif (hdev) {\r\natomic_dec(&hdev->promisc);\r\nhci_dev_put(hdev);\r\n}\r\nsock_orphan(sk);\r\nskb_queue_purge(&sk->sk_receive_queue);\r\nskb_queue_purge(&sk->sk_write_queue);\r\nsock_put(sk);\r\nreturn 0;\r\n}\r\nstatic int hci_sock_blacklist_add(struct hci_dev *hdev, void __user *arg)\r\n{\r\nbdaddr_t bdaddr;\r\nint err;\r\nif (copy_from_user(&bdaddr, arg, sizeof(bdaddr)))\r\nreturn -EFAULT;\r\nhci_dev_lock(hdev);\r\nerr = hci_blacklist_add(hdev, &bdaddr, 0);\r\nhci_dev_unlock(hdev);\r\nreturn err;\r\n}\r\nstatic int hci_sock_blacklist_del(struct hci_dev *hdev, void __user *arg)\r\n{\r\nbdaddr_t bdaddr;\r\nint err;\r\nif (copy_from_user(&bdaddr, arg, sizeof(bdaddr)))\r\nreturn -EFAULT;\r\nhci_dev_lock(hdev);\r\nerr = hci_blacklist_del(hdev, &bdaddr, 0);\r\nhci_dev_unlock(hdev);\r\nreturn err;\r\n}\r\nstatic inline int hci_sock_bound_ioctl(struct sock *sk, unsigned int cmd, unsigned long arg)\r\n{\r\nstruct hci_dev *hdev = hci_pi(sk)->hdev;\r\nif (!hdev)\r\nreturn -EBADFD;\r\nswitch (cmd) {\r\ncase HCISETRAW:\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EACCES;\r\nif (test_bit(HCI_QUIRK_RAW_DEVICE, &hdev->quirks))\r\nreturn -EPERM;\r\nif (arg)\r\nset_bit(HCI_RAW, &hdev->flags);\r\nelse\r\nclear_bit(HCI_RAW, &hdev->flags);\r\nreturn 0;\r\ncase HCIGETCONNINFO:\r\nreturn hci_get_conn_info(hdev, (void __user *) arg);\r\ncase HCIGETAUTHINFO:\r\nreturn hci_get_auth_info(hdev, (void __user *) arg);\r\ncase HCIBLOCKADDR:\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EACCES;\r\nreturn hci_sock_blacklist_add(hdev, (void __user *) arg);\r\ncase HCIUNBLOCKADDR:\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EACCES;\r\nreturn hci_sock_blacklist_del(hdev, (void __user *) arg);\r\ndefault:\r\nif (hdev->ioctl)\r\nreturn hdev->ioctl(hdev, cmd, arg);\r\nreturn -EINVAL;\r\n}\r\n}\r\nstatic int hci_sock_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)\r\n{\r\nstruct sock *sk = sock->sk;\r\nvoid __user *argp = (void __user *) arg;\r\nint err;\r\nBT_DBG("cmd %x arg %lx", cmd, arg);\r\nswitch (cmd) {\r\ncase HCIGETDEVLIST:\r\nreturn hci_get_dev_list(argp);\r\ncase HCIGETDEVINFO:\r\nreturn hci_get_dev_info(argp);\r\ncase HCIGETCONNLIST:\r\nreturn hci_get_conn_list(argp);\r\ncase HCIDEVUP:\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EACCES;\r\nreturn hci_dev_open(arg);\r\ncase HCIDEVDOWN:\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EACCES;\r\nreturn hci_dev_close(arg);\r\ncase HCIDEVRESET:\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EACCES;\r\nreturn hci_dev_reset(arg);\r\ncase HCIDEVRESTAT:\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EACCES;\r\nreturn hci_dev_reset_stat(arg);\r\ncase HCISETSCAN:\r\ncase HCISETAUTH:\r\ncase HCISETENCRYPT:\r\ncase HCISETPTYPE:\r\ncase HCISETLINKPOL:\r\ncase HCISETLINKMODE:\r\ncase HCISETACLMTU:\r\ncase HCISETSCOMTU:\r\nif (!capable(CAP_NET_ADMIN))\r\nreturn -EACCES;\r\nreturn hci_dev_cmd(cmd, argp);\r\ncase HCIINQUIRY:\r\nreturn hci_inquiry(argp);\r\ndefault:\r\nlock_sock(sk);\r\nerr = hci_sock_bound_ioctl(sk, cmd, arg);\r\nrelease_sock(sk);\r\nreturn err;\r\n}\r\n}\r\nstatic int hci_sock_bind(struct socket *sock, struct sockaddr *addr, int addr_len)\r\n{\r\nstruct sockaddr_hci haddr;\r\nstruct sock *sk = sock->sk;\r\nstruct hci_dev *hdev = NULL;\r\nint len, err = 0;\r\nBT_DBG("sock %p sk %p", sock, sk);\r\nif (!addr)\r\nreturn -EINVAL;\r\nmemset(&haddr, 0, sizeof(haddr));\r\nlen = min_t(unsigned int, sizeof(haddr), addr_len);\r\nmemcpy(&haddr, addr, len);\r\nif (haddr.hci_family != AF_BLUETOOTH)\r\nreturn -EINVAL;\r\nlock_sock(sk);\r\nif (sk->sk_state == BT_BOUND) {\r\nerr = -EALREADY;\r\ngoto done;\r\n}\r\nswitch (haddr.hci_channel) {\r\ncase HCI_CHANNEL_RAW:\r\nif (hci_pi(sk)->hdev) {\r\nerr = -EALREADY;\r\ngoto done;\r\n}\r\nif (haddr.hci_dev != HCI_DEV_NONE) {\r\nhdev = hci_dev_get(haddr.hci_dev);\r\nif (!hdev) {\r\nerr = -ENODEV;\r\ngoto done;\r\n}\r\natomic_inc(&hdev->promisc);\r\n}\r\nhci_pi(sk)->hdev = hdev;\r\nbreak;\r\ncase HCI_CHANNEL_CONTROL:\r\nif (haddr.hci_dev != HCI_DEV_NONE) {\r\nerr = -EINVAL;\r\ngoto done;\r\n}\r\nif (!capable(CAP_NET_ADMIN)) {\r\nerr = -EPERM;\r\ngoto done;\r\n}\r\nbreak;\r\ncase HCI_CHANNEL_MONITOR:\r\nif (haddr.hci_dev != HCI_DEV_NONE) {\r\nerr = -EINVAL;\r\ngoto done;\r\n}\r\nif (!capable(CAP_NET_RAW)) {\r\nerr = -EPERM;\r\ngoto done;\r\n}\r\nsend_monitor_replay(sk);\r\natomic_inc(&monitor_promisc);\r\nbreak;\r\ndefault:\r\nerr = -EINVAL;\r\ngoto done;\r\n}\r\nhci_pi(sk)->channel = haddr.hci_channel;\r\nsk->sk_state = BT_BOUND;\r\ndone:\r\nrelease_sock(sk);\r\nreturn err;\r\n}\r\nstatic int hci_sock_getname(struct socket *sock, struct sockaddr *addr, int *addr_len, int peer)\r\n{\r\nstruct sockaddr_hci *haddr = (struct sockaddr_hci *) addr;\r\nstruct sock *sk = sock->sk;\r\nstruct hci_dev *hdev = hci_pi(sk)->hdev;\r\nBT_DBG("sock %p sk %p", sock, sk);\r\nif (!hdev)\r\nreturn -EBADFD;\r\nlock_sock(sk);\r\n*addr_len = sizeof(*haddr);\r\nhaddr->hci_family = AF_BLUETOOTH;\r\nhaddr->hci_dev = hdev->id;\r\nrelease_sock(sk);\r\nreturn 0;\r\n}\r\nstatic inline void hci_sock_cmsg(struct sock *sk, struct msghdr *msg, struct sk_buff *skb)\r\n{\r\n__u32 mask = hci_pi(sk)->cmsg_mask;\r\nif (mask & HCI_CMSG_DIR) {\r\nint incoming = bt_cb(skb)->incoming;\r\nput_cmsg(msg, SOL_HCI, HCI_CMSG_DIR, sizeof(incoming), &incoming);\r\n}\r\nif (mask & HCI_CMSG_TSTAMP) {\r\n#ifdef CONFIG_COMPAT\r\nstruct compat_timeval ctv;\r\n#endif\r\nstruct timeval tv;\r\nvoid *data;\r\nint len;\r\nskb_get_timestamp(skb, &tv);\r\ndata = &tv;\r\nlen = sizeof(tv);\r\n#ifdef CONFIG_COMPAT\r\nif (!COMPAT_USE_64BIT_TIME &&\r\n(msg->msg_flags & MSG_CMSG_COMPAT)) {\r\nctv.tv_sec = tv.tv_sec;\r\nctv.tv_usec = tv.tv_usec;\r\ndata = &ctv;\r\nlen = sizeof(ctv);\r\n}\r\n#endif\r\nput_cmsg(msg, SOL_HCI, HCI_CMSG_TSTAMP, len, data);\r\n}\r\n}\r\nstatic int hci_sock_recvmsg(struct kiocb *iocb, struct socket *sock,\r\nstruct msghdr *msg, size_t len, int flags)\r\n{\r\nint noblock = flags & MSG_DONTWAIT;\r\nstruct sock *sk = sock->sk;\r\nstruct sk_buff *skb;\r\nint copied, err;\r\nBT_DBG("sock %p, sk %p", sock, sk);\r\nif (flags & (MSG_OOB))\r\nreturn -EOPNOTSUPP;\r\nif (sk->sk_state == BT_CLOSED)\r\nreturn 0;\r\nskb = skb_recv_datagram(sk, flags, noblock, &err);\r\nif (!skb)\r\nreturn err;\r\nmsg->msg_namelen = 0;\r\ncopied = skb->len;\r\nif (len < copied) {\r\nmsg->msg_flags |= MSG_TRUNC;\r\ncopied = len;\r\n}\r\nskb_reset_transport_header(skb);\r\nerr = skb_copy_datagram_iovec(skb, 0, msg->msg_iov, copied);\r\nswitch (hci_pi(sk)->channel) {\r\ncase HCI_CHANNEL_RAW:\r\nhci_sock_cmsg(sk, msg, skb);\r\nbreak;\r\ncase HCI_CHANNEL_CONTROL:\r\ncase HCI_CHANNEL_MONITOR:\r\nsock_recv_timestamp(msg, sk, skb);\r\nbreak;\r\n}\r\nskb_free_datagram(sk, skb);\r\nreturn err ? : copied;\r\n}\r\nstatic int hci_sock_sendmsg(struct kiocb *iocb, struct socket *sock,\r\nstruct msghdr *msg, size_t len)\r\n{\r\nstruct sock *sk = sock->sk;\r\nstruct hci_dev *hdev;\r\nstruct sk_buff *skb;\r\nint err;\r\nBT_DBG("sock %p sk %p", sock, sk);\r\nif (msg->msg_flags & MSG_OOB)\r\nreturn -EOPNOTSUPP;\r\nif (msg->msg_flags & ~(MSG_DONTWAIT|MSG_NOSIGNAL|MSG_ERRQUEUE))\r\nreturn -EINVAL;\r\nif (len < 4 || len > HCI_MAX_FRAME_SIZE)\r\nreturn -EINVAL;\r\nlock_sock(sk);\r\nswitch (hci_pi(sk)->channel) {\r\ncase HCI_CHANNEL_RAW:\r\nbreak;\r\ncase HCI_CHANNEL_CONTROL:\r\nerr = mgmt_control(sk, msg, len);\r\ngoto done;\r\ncase HCI_CHANNEL_MONITOR:\r\nerr = -EOPNOTSUPP;\r\ngoto done;\r\ndefault:\r\nerr = -EINVAL;\r\ngoto done;\r\n}\r\nhdev = hci_pi(sk)->hdev;\r\nif (!hdev) {\r\nerr = -EBADFD;\r\ngoto done;\r\n}\r\nif (!test_bit(HCI_UP, &hdev->flags)) {\r\nerr = -ENETDOWN;\r\ngoto done;\r\n}\r\nskb = bt_skb_send_alloc(sk, len, msg->msg_flags & MSG_DONTWAIT, &err);\r\nif (!skb)\r\ngoto done;\r\nif (memcpy_fromiovec(skb_put(skb, len), msg->msg_iov, len)) {\r\nerr = -EFAULT;\r\ngoto drop;\r\n}\r\nbt_cb(skb)->pkt_type = *((unsigned char *) skb->data);\r\nskb_pull(skb, 1);\r\nskb->dev = (void *) hdev;\r\nif (bt_cb(skb)->pkt_type == HCI_COMMAND_PKT) {\r\nu16 opcode = get_unaligned_le16(skb->data);\r\nu16 ogf = hci_opcode_ogf(opcode);\r\nu16 ocf = hci_opcode_ocf(opcode);\r\nif (((ogf > HCI_SFLT_MAX_OGF) ||\r\n!hci_test_bit(ocf & HCI_FLT_OCF_BITS, &hci_sec_filter.ocf_mask[ogf])) &&\r\n!capable(CAP_NET_RAW)) {\r\nerr = -EPERM;\r\ngoto drop;\r\n}\r\nif (test_bit(HCI_RAW, &hdev->flags) || (ogf == 0x3f)) {\r\nskb_queue_tail(&hdev->raw_q, skb);\r\nqueue_work(hdev->workqueue, &hdev->tx_work);\r\n} else {\r\nskb_queue_tail(&hdev->cmd_q, skb);\r\nqueue_work(hdev->workqueue, &hdev->cmd_work);\r\n}\r\n} else {\r\nif (!capable(CAP_NET_RAW)) {\r\nerr = -EPERM;\r\ngoto drop;\r\n}\r\nskb_queue_tail(&hdev->raw_q, skb);\r\nqueue_work(hdev->workqueue, &hdev->tx_work);\r\n}\r\nerr = len;\r\ndone:\r\nrelease_sock(sk);\r\nreturn err;\r\ndrop:\r\nkfree_skb(skb);\r\ngoto done;\r\n}\r\nstatic int hci_sock_setsockopt(struct socket *sock, int level, int optname, char __user *optval, unsigned int len)\r\n{\r\nstruct hci_ufilter uf = { .opcode = 0 };\r\nstruct sock *sk = sock->sk;\r\nint err = 0, opt = 0;\r\nBT_DBG("sk %p, opt %d", sk, optname);\r\nlock_sock(sk);\r\nif (hci_pi(sk)->channel != HCI_CHANNEL_RAW) {\r\nerr = -EINVAL;\r\ngoto done;\r\n}\r\nswitch (optname) {\r\ncase HCI_DATA_DIR:\r\nif (get_user(opt, (int __user *)optval)) {\r\nerr = -EFAULT;\r\nbreak;\r\n}\r\nif (opt)\r\nhci_pi(sk)->cmsg_mask |= HCI_CMSG_DIR;\r\nelse\r\nhci_pi(sk)->cmsg_mask &= ~HCI_CMSG_DIR;\r\nbreak;\r\ncase HCI_TIME_STAMP:\r\nif (get_user(opt, (int __user *)optval)) {\r\nerr = -EFAULT;\r\nbreak;\r\n}\r\nif (opt)\r\nhci_pi(sk)->cmsg_mask |= HCI_CMSG_TSTAMP;\r\nelse\r\nhci_pi(sk)->cmsg_mask &= ~HCI_CMSG_TSTAMP;\r\nbreak;\r\ncase HCI_FILTER:\r\n{\r\nstruct hci_filter *f = &hci_pi(sk)->filter;\r\nuf.type_mask = f->type_mask;\r\nuf.opcode = f->opcode;\r\nuf.event_mask[0] = *((u32 *) f->event_mask + 0);\r\nuf.event_mask[1] = *((u32 *) f->event_mask + 1);\r\n}\r\nlen = min_t(unsigned int, len, sizeof(uf));\r\nif (copy_from_user(&uf, optval, len)) {\r\nerr = -EFAULT;\r\nbreak;\r\n}\r\nif (!capable(CAP_NET_RAW)) {\r\nuf.type_mask &= hci_sec_filter.type_mask;\r\nuf.event_mask[0] &= *((u32 *) hci_sec_filter.event_mask + 0);\r\nuf.event_mask[1] &= *((u32 *) hci_sec_filter.event_mask + 1);\r\n}\r\n{\r\nstruct hci_filter *f = &hci_pi(sk)->filter;\r\nf->type_mask = uf.type_mask;\r\nf->opcode = uf.opcode;\r\n*((u32 *) f->event_mask + 0) = uf.event_mask[0];\r\n*((u32 *) f->event_mask + 1) = uf.event_mask[1];\r\n}\r\nbreak;\r\ndefault:\r\nerr = -ENOPROTOOPT;\r\nbreak;\r\n}\r\ndone:\r\nrelease_sock(sk);\r\nreturn err;\r\n}\r\nstatic int hci_sock_getsockopt(struct socket *sock, int level, int optname, char __user *optval, int __user *optlen)\r\n{\r\nstruct hci_ufilter uf;\r\nstruct sock *sk = sock->sk;\r\nint len, opt, err = 0;\r\nBT_DBG("sk %p, opt %d", sk, optname);\r\nif (get_user(len, optlen))\r\nreturn -EFAULT;\r\nlock_sock(sk);\r\nif (hci_pi(sk)->channel != HCI_CHANNEL_RAW) {\r\nerr = -EINVAL;\r\ngoto done;\r\n}\r\nswitch (optname) {\r\ncase HCI_DATA_DIR:\r\nif (hci_pi(sk)->cmsg_mask & HCI_CMSG_DIR)\r\nopt = 1;\r\nelse\r\nopt = 0;\r\nif (put_user(opt, optval))\r\nerr = -EFAULT;\r\nbreak;\r\ncase HCI_TIME_STAMP:\r\nif (hci_pi(sk)->cmsg_mask & HCI_CMSG_TSTAMP)\r\nopt = 1;\r\nelse\r\nopt = 0;\r\nif (put_user(opt, optval))\r\nerr = -EFAULT;\r\nbreak;\r\ncase HCI_FILTER:\r\n{\r\nstruct hci_filter *f = &hci_pi(sk)->filter;\r\nuf.type_mask = f->type_mask;\r\nuf.opcode = f->opcode;\r\nuf.event_mask[0] = *((u32 *) f->event_mask + 0);\r\nuf.event_mask[1] = *((u32 *) f->event_mask + 1);\r\n}\r\nlen = min_t(unsigned int, len, sizeof(uf));\r\nif (copy_to_user(optval, &uf, len))\r\nerr = -EFAULT;\r\nbreak;\r\ndefault:\r\nerr = -ENOPROTOOPT;\r\nbreak;\r\n}\r\ndone:\r\nrelease_sock(sk);\r\nreturn err;\r\n}\r\nstatic int hci_sock_create(struct net *net, struct socket *sock, int protocol,\r\nint kern)\r\n{\r\nstruct sock *sk;\r\nBT_DBG("sock %p", sock);\r\nif (sock->type != SOCK_RAW)\r\nreturn -ESOCKTNOSUPPORT;\r\nsock->ops = &hci_sock_ops;\r\nsk = sk_alloc(net, PF_BLUETOOTH, GFP_ATOMIC, &hci_sk_proto);\r\nif (!sk)\r\nreturn -ENOMEM;\r\nsock_init_data(sock, sk);\r\nsock_reset_flag(sk, SOCK_ZAPPED);\r\nsk->sk_protocol = protocol;\r\nsock->state = SS_UNCONNECTED;\r\nsk->sk_state = BT_OPEN;\r\nbt_sock_link(&hci_sk_list, sk);\r\nreturn 0;\r\n}\r\nint __init hci_sock_init(void)\r\n{\r\nint err;\r\nerr = proto_register(&hci_sk_proto, 0);\r\nif (err < 0)\r\nreturn err;\r\nerr = bt_sock_register(BTPROTO_HCI, &hci_sock_family_ops);\r\nif (err < 0)\r\ngoto error;\r\nBT_INFO("HCI socket layer initialized");\r\nreturn 0;\r\nerror:\r\nBT_ERR("HCI socket registration failed");\r\nproto_unregister(&hci_sk_proto);\r\nreturn err;\r\n}\r\nvoid hci_sock_cleanup(void)\r\n{\r\nif (bt_sock_unregister(BTPROTO_HCI) < 0)\r\nBT_ERR("HCI socket unregistration failed");\r\nproto_unregister(&hci_sk_proto);\r\n}
