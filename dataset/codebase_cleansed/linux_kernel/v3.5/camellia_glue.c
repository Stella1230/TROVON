static inline void camellia_enc_blk(struct camellia_ctx *ctx, u8 *dst,\r\nconst u8 *src)\r\n{\r\n__camellia_enc_blk(ctx, dst, src, false);\r\n}\r\nstatic inline void camellia_enc_blk_xor(struct camellia_ctx *ctx, u8 *dst,\r\nconst u8 *src)\r\n{\r\n__camellia_enc_blk(ctx, dst, src, true);\r\n}\r\nstatic inline void camellia_enc_blk_2way(struct camellia_ctx *ctx, u8 *dst,\r\nconst u8 *src)\r\n{\r\n__camellia_enc_blk_2way(ctx, dst, src, false);\r\n}\r\nstatic inline void camellia_enc_blk_xor_2way(struct camellia_ctx *ctx, u8 *dst,\r\nconst u8 *src)\r\n{\r\n__camellia_enc_blk_2way(ctx, dst, src, true);\r\n}\r\nstatic void camellia_encrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\r\n{\r\ncamellia_enc_blk(crypto_tfm_ctx(tfm), dst, src);\r\n}\r\nstatic void camellia_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)\r\n{\r\ncamellia_dec_blk(crypto_tfm_ctx(tfm), dst, src);\r\n}\r\nstatic void camellia_setup_tail(u64 *subkey, u64 *subRL, int max)\r\n{\r\nu64 kw4, tt;\r\nu32 dw, tl, tr;\r\nsubRL[3] ^= subRL[1];\r\nsubRL[5] ^= subRL[1];\r\nsubRL[7] ^= subRL[1];\r\nsubRL[1] ^= (subRL[1] & ~subRL[9]) << 32;\r\ndw = (subRL[1] & subRL[9]) >> 32,\r\nsubRL[1] ^= rol32(dw, 1);\r\nsubRL[11] ^= subRL[1];\r\nsubRL[13] ^= subRL[1];\r\nsubRL[15] ^= subRL[1];\r\nsubRL[1] ^= (subRL[1] & ~subRL[17]) << 32;\r\ndw = (subRL[1] & subRL[17]) >> 32,\r\nsubRL[1] ^= rol32(dw, 1);\r\nsubRL[19] ^= subRL[1];\r\nsubRL[21] ^= subRL[1];\r\nsubRL[23] ^= subRL[1];\r\nif (max == 24) {\r\nsubRL[24] ^= subRL[1];\r\nkw4 = subRL[25];\r\n} else {\r\nsubRL[1] ^= (subRL[1] & ~subRL[25]) << 32;\r\ndw = (subRL[1] & subRL[25]) >> 32,\r\nsubRL[1] ^= rol32(dw, 1);\r\nsubRL[27] ^= subRL[1];\r\nsubRL[29] ^= subRL[1];\r\nsubRL[31] ^= subRL[1];\r\nsubRL[32] ^= subRL[1];\r\nkw4 = subRL[33];\r\nsubRL[30] ^= kw4;\r\nsubRL[28] ^= kw4;\r\nsubRL[26] ^= kw4;\r\nkw4 ^= (kw4 & ~subRL[24]) << 32;\r\ndw = (kw4 & subRL[24]) >> 32,\r\nkw4 ^= rol32(dw, 1);\r\n}\r\nsubRL[22] ^= kw4;\r\nsubRL[20] ^= kw4;\r\nsubRL[18] ^= kw4;\r\nkw4 ^= (kw4 & ~subRL[16]) << 32;\r\ndw = (kw4 & subRL[16]) >> 32,\r\nkw4 ^= rol32(dw, 1);\r\nsubRL[14] ^= kw4;\r\nsubRL[12] ^= kw4;\r\nsubRL[10] ^= kw4;\r\nkw4 ^= (kw4 & ~subRL[8]) << 32;\r\ndw = (kw4 & subRL[8]) >> 32,\r\nkw4 ^= rol32(dw, 1);\r\nsubRL[6] ^= kw4;\r\nsubRL[4] ^= kw4;\r\nsubRL[2] ^= kw4;\r\nsubRL[0] ^= kw4;\r\nSET_SUBKEY_LR(0, subRL[0] ^ subRL[2]);\r\nSET_SUBKEY_LR(2, subRL[3]);\r\nSET_SUBKEY_LR(3, subRL[2] ^ subRL[4]);\r\nSET_SUBKEY_LR(4, subRL[3] ^ subRL[5]);\r\nSET_SUBKEY_LR(5, subRL[4] ^ subRL[6]);\r\nSET_SUBKEY_LR(6, subRL[5] ^ subRL[7]);\r\ntl = (subRL[10] >> 32) ^ (subRL[10] & ~subRL[8]);\r\ndw = tl & (subRL[8] >> 32),\r\ntr = subRL[10] ^ rol32(dw, 1);\r\ntt = (tr | ((u64)tl << 32));\r\nSET_SUBKEY_LR(7, subRL[6] ^ tt);\r\nSET_SUBKEY_LR(8, subRL[8]);\r\nSET_SUBKEY_LR(9, subRL[9]);\r\ntl = (subRL[7] >> 32) ^ (subRL[7] & ~subRL[9]);\r\ndw = tl & (subRL[9] >> 32),\r\ntr = subRL[7] ^ rol32(dw, 1);\r\ntt = (tr | ((u64)tl << 32));\r\nSET_SUBKEY_LR(10, subRL[11] ^ tt);\r\nSET_SUBKEY_LR(11, subRL[10] ^ subRL[12]);\r\nSET_SUBKEY_LR(12, subRL[11] ^ subRL[13]);\r\nSET_SUBKEY_LR(13, subRL[12] ^ subRL[14]);\r\nSET_SUBKEY_LR(14, subRL[13] ^ subRL[15]);\r\ntl = (subRL[18] >> 32) ^ (subRL[18] & ~subRL[16]);\r\ndw = tl & (subRL[16] >> 32),\r\ntr = subRL[18] ^ rol32(dw, 1);\r\ntt = (tr | ((u64)tl << 32));\r\nSET_SUBKEY_LR(15, subRL[14] ^ tt);\r\nSET_SUBKEY_LR(16, subRL[16]);\r\nSET_SUBKEY_LR(17, subRL[17]);\r\ntl = (subRL[15] >> 32) ^ (subRL[15] & ~subRL[17]);\r\ndw = tl & (subRL[17] >> 32),\r\ntr = subRL[15] ^ rol32(dw, 1);\r\ntt = (tr | ((u64)tl << 32));\r\nSET_SUBKEY_LR(18, subRL[19] ^ tt);\r\nSET_SUBKEY_LR(19, subRL[18] ^ subRL[20]);\r\nSET_SUBKEY_LR(20, subRL[19] ^ subRL[21]);\r\nSET_SUBKEY_LR(21, subRL[20] ^ subRL[22]);\r\nSET_SUBKEY_LR(22, subRL[21] ^ subRL[23]);\r\nif (max == 24) {\r\nSET_SUBKEY_LR(23, subRL[22]);\r\nSET_SUBKEY_LR(24, subRL[24] ^ subRL[23]);\r\n} else {\r\ntl = (subRL[26] >> 32) ^ (subRL[26] & ~subRL[24]);\r\ndw = tl & (subRL[24] >> 32),\r\ntr = subRL[26] ^ rol32(dw, 1);\r\ntt = (tr | ((u64)tl << 32));\r\nSET_SUBKEY_LR(23, subRL[22] ^ tt);\r\nSET_SUBKEY_LR(24, subRL[24]);\r\nSET_SUBKEY_LR(25, subRL[25]);\r\ntl = (subRL[23] >> 32) ^ (subRL[23] & ~subRL[25]);\r\ndw = tl & (subRL[25] >> 32),\r\ntr = subRL[23] ^ rol32(dw, 1);\r\ntt = (tr | ((u64)tl << 32));\r\nSET_SUBKEY_LR(26, subRL[27] ^ tt);\r\nSET_SUBKEY_LR(27, subRL[26] ^ subRL[28]);\r\nSET_SUBKEY_LR(28, subRL[27] ^ subRL[29]);\r\nSET_SUBKEY_LR(29, subRL[28] ^ subRL[30]);\r\nSET_SUBKEY_LR(30, subRL[29] ^ subRL[31]);\r\nSET_SUBKEY_LR(31, subRL[30]);\r\nSET_SUBKEY_LR(32, subRL[32] ^ subRL[31]);\r\n}\r\n}\r\nstatic void camellia_setup128(const unsigned char *key, u64 *subkey)\r\n{\r\nu64 kl, kr, ww;\r\nu64 subRL[26];\r\nkl = get_unaligned_be64(key);\r\nkr = get_unaligned_be64(key + 8);\r\nsubRL[0] = kl;\r\nsubRL[1] = kr;\r\nROLDQ(kl, kr, 15);\r\nsubRL[4] = kl;\r\nsubRL[5] = kr;\r\nROLDQ(kl, kr, 30);\r\nsubRL[10] = kl;\r\nsubRL[11] = kr;\r\nROLDQ(kl, kr, 15);\r\nsubRL[13] = kr;\r\nROLDQ(kl, kr, 17);\r\nsubRL[16] = kl;\r\nsubRL[17] = kr;\r\nROLDQ(kl, kr, 17);\r\nsubRL[18] = kl;\r\nsubRL[19] = kr;\r\nROLDQ(kl, kr, 17);\r\nsubRL[22] = kl;\r\nsubRL[23] = kr;\r\nkl = subRL[0];\r\nkr = subRL[1];\r\nCAMELLIA_F(kl, CAMELLIA_SIGMA1L, CAMELLIA_SIGMA1R, ww);\r\nkr ^= ww;\r\nCAMELLIA_F(kr, CAMELLIA_SIGMA2L, CAMELLIA_SIGMA2R, kl);\r\nCAMELLIA_F(kl, CAMELLIA_SIGMA3L, CAMELLIA_SIGMA3R, kr);\r\nkr ^= ww;\r\nCAMELLIA_F(kr, CAMELLIA_SIGMA4L, CAMELLIA_SIGMA4R, ww);\r\nkl ^= ww;\r\nsubRL[2] = kl;\r\nsubRL[3] = kr;\r\nROLDQ(kl, kr, 15);\r\nsubRL[6] = kl;\r\nsubRL[7] = kr;\r\nROLDQ(kl, kr, 15);\r\nsubRL[8] = kl;\r\nsubRL[9] = kr;\r\nROLDQ(kl, kr, 15);\r\nsubRL[12] = kl;\r\nROLDQ(kl, kr, 15);\r\nsubRL[14] = kl;\r\nsubRL[15] = kr;\r\nROLDQ(kl, kr, 34);\r\nsubRL[20] = kl;\r\nsubRL[21] = kr;\r\nROLDQ(kl, kr, 17);\r\nsubRL[24] = kl;\r\nsubRL[25] = kr;\r\ncamellia_setup_tail(subkey, subRL, 24);\r\n}\r\nstatic void camellia_setup256(const unsigned char *key, u64 *subkey)\r\n{\r\nu64 kl, kr;\r\nu64 krl, krr;\r\nu64 ww;\r\nu64 subRL[34];\r\nkl = get_unaligned_be64(key);\r\nkr = get_unaligned_be64(key + 8);\r\nkrl = get_unaligned_be64(key + 16);\r\nkrr = get_unaligned_be64(key + 24);\r\nsubRL[0] = kl;\r\nsubRL[1] = kr;\r\nROLDQ(kl, kr, 45);\r\nsubRL[12] = kl;\r\nsubRL[13] = kr;\r\nROLDQ(kl, kr, 15);\r\nsubRL[16] = kl;\r\nsubRL[17] = kr;\r\nROLDQ(kl, kr, 17);\r\nsubRL[22] = kl;\r\nsubRL[23] = kr;\r\nROLDQ(kl, kr, 34);\r\nsubRL[30] = kl;\r\nsubRL[31] = kr;\r\nROLDQ(krl, krr, 15);\r\nsubRL[4] = krl;\r\nsubRL[5] = krr;\r\nROLDQ(krl, krr, 15);\r\nsubRL[8] = krl;\r\nsubRL[9] = krr;\r\nROLDQ(krl, krr, 30);\r\nsubRL[18] = krl;\r\nsubRL[19] = krr;\r\nROLDQ(krl, krr, 34);\r\nsubRL[26] = krl;\r\nsubRL[27] = krr;\r\nROLDQ(krl, krr, 34);\r\nkl = subRL[0] ^ krl;\r\nkr = subRL[1] ^ krr;\r\nCAMELLIA_F(kl, CAMELLIA_SIGMA1L, CAMELLIA_SIGMA1R, ww);\r\nkr ^= ww;\r\nCAMELLIA_F(kr, CAMELLIA_SIGMA2L, CAMELLIA_SIGMA2R, kl);\r\nkl ^= krl;\r\nCAMELLIA_F(kl, CAMELLIA_SIGMA3L, CAMELLIA_SIGMA3R, kr);\r\nkr ^= ww ^ krr;\r\nCAMELLIA_F(kr, CAMELLIA_SIGMA4L, CAMELLIA_SIGMA4R, ww);\r\nkl ^= ww;\r\nkrl ^= kl;\r\nkrr ^= kr;\r\nCAMELLIA_F(krl, CAMELLIA_SIGMA5L, CAMELLIA_SIGMA5R, ww);\r\nkrr ^= ww;\r\nCAMELLIA_F(krr, CAMELLIA_SIGMA6L, CAMELLIA_SIGMA6R, ww);\r\nkrl ^= ww;\r\nROLDQ(kl, kr, 15);\r\nsubRL[6] = kl;\r\nsubRL[7] = kr;\r\nROLDQ(kl, kr, 30);\r\nsubRL[14] = kl;\r\nsubRL[15] = kr;\r\nROLDQ(kl, kr, 32);\r\nsubRL[24] = kl;\r\nsubRL[25] = kr;\r\nROLDQ(kl, kr, 17);\r\nsubRL[28] = kl;\r\nsubRL[29] = kr;\r\nsubRL[2] = krl;\r\nsubRL[3] = krr;\r\nROLDQ(krl, krr, 30);\r\nsubRL[10] = krl;\r\nsubRL[11] = krr;\r\nROLDQ(krl, krr, 30);\r\nsubRL[20] = krl;\r\nsubRL[21] = krr;\r\nROLDQ(krl, krr, 51);\r\nsubRL[32] = krl;\r\nsubRL[33] = krr;\r\ncamellia_setup_tail(subkey, subRL, 32);\r\n}\r\nstatic void camellia_setup192(const unsigned char *key, u64 *subkey)\r\n{\r\nunsigned char kk[32];\r\nu64 krl, krr;\r\nmemcpy(kk, key, 24);\r\nmemcpy((unsigned char *)&krl, key+16, 8);\r\nkrr = ~krl;\r\nmemcpy(kk+24, (unsigned char *)&krr, 8);\r\ncamellia_setup256(kk, subkey);\r\n}\r\nstatic int __camellia_setkey(struct camellia_ctx *cctx,\r\nconst unsigned char *key,\r\nunsigned int key_len, u32 *flags)\r\n{\r\nif (key_len != 16 && key_len != 24 && key_len != 32) {\r\n*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\r\nreturn -EINVAL;\r\n}\r\ncctx->key_length = key_len;\r\nswitch (key_len) {\r\ncase 16:\r\ncamellia_setup128(key, cctx->key_table);\r\nbreak;\r\ncase 24:\r\ncamellia_setup192(key, cctx->key_table);\r\nbreak;\r\ncase 32:\r\ncamellia_setup256(key, cctx->key_table);\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nstatic int camellia_setkey(struct crypto_tfm *tfm, const u8 *in_key,\r\nunsigned int key_len)\r\n{\r\nreturn __camellia_setkey(crypto_tfm_ctx(tfm), in_key, key_len,\r\n&tfm->crt_flags);\r\n}\r\nstatic int ecb_crypt(struct blkcipher_desc *desc, struct blkcipher_walk *walk,\r\nvoid (*fn)(struct camellia_ctx *, u8 *, const u8 *),\r\nvoid (*fn_2way)(struct camellia_ctx *, u8 *, const u8 *))\r\n{\r\nstruct camellia_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nunsigned int bsize = CAMELLIA_BLOCK_SIZE;\r\nunsigned int nbytes;\r\nint err;\r\nerr = blkcipher_walk_virt(desc, walk);\r\nwhile ((nbytes = walk->nbytes)) {\r\nu8 *wsrc = walk->src.virt.addr;\r\nu8 *wdst = walk->dst.virt.addr;\r\nif (nbytes >= bsize * 2) {\r\ndo {\r\nfn_2way(ctx, wdst, wsrc);\r\nwsrc += bsize * 2;\r\nwdst += bsize * 2;\r\nnbytes -= bsize * 2;\r\n} while (nbytes >= bsize * 2);\r\nif (nbytes < bsize)\r\ngoto done;\r\n}\r\ndo {\r\nfn(ctx, wdst, wsrc);\r\nwsrc += bsize;\r\nwdst += bsize;\r\nnbytes -= bsize;\r\n} while (nbytes >= bsize);\r\ndone:\r\nerr = blkcipher_walk_done(desc, walk, nbytes);\r\n}\r\nreturn err;\r\n}\r\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct blkcipher_walk walk;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nreturn ecb_crypt(desc, &walk, camellia_enc_blk, camellia_enc_blk_2way);\r\n}\r\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct blkcipher_walk walk;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nreturn ecb_crypt(desc, &walk, camellia_dec_blk, camellia_dec_blk_2way);\r\n}\r\nstatic unsigned int __cbc_encrypt(struct blkcipher_desc *desc,\r\nstruct blkcipher_walk *walk)\r\n{\r\nstruct camellia_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nunsigned int bsize = CAMELLIA_BLOCK_SIZE;\r\nunsigned int nbytes = walk->nbytes;\r\nu128 *src = (u128 *)walk->src.virt.addr;\r\nu128 *dst = (u128 *)walk->dst.virt.addr;\r\nu128 *iv = (u128 *)walk->iv;\r\ndo {\r\nu128_xor(dst, src, iv);\r\ncamellia_enc_blk(ctx, (u8 *)dst, (u8 *)dst);\r\niv = dst;\r\nsrc += 1;\r\ndst += 1;\r\nnbytes -= bsize;\r\n} while (nbytes >= bsize);\r\nu128_xor((u128 *)walk->iv, (u128 *)walk->iv, iv);\r\nreturn nbytes;\r\n}\r\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct blkcipher_walk walk;\r\nint err;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt(desc, &walk);\r\nwhile ((nbytes = walk.nbytes)) {\r\nnbytes = __cbc_encrypt(desc, &walk);\r\nerr = blkcipher_walk_done(desc, &walk, nbytes);\r\n}\r\nreturn err;\r\n}\r\nstatic unsigned int __cbc_decrypt(struct blkcipher_desc *desc,\r\nstruct blkcipher_walk *walk)\r\n{\r\nstruct camellia_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nunsigned int bsize = CAMELLIA_BLOCK_SIZE;\r\nunsigned int nbytes = walk->nbytes;\r\nu128 *src = (u128 *)walk->src.virt.addr;\r\nu128 *dst = (u128 *)walk->dst.virt.addr;\r\nu128 ivs[2 - 1];\r\nu128 last_iv;\r\nsrc += nbytes / bsize - 1;\r\ndst += nbytes / bsize - 1;\r\nlast_iv = *src;\r\nif (nbytes >= bsize * 2) {\r\ndo {\r\nnbytes -= bsize * (2 - 1);\r\nsrc -= 2 - 1;\r\ndst -= 2 - 1;\r\nivs[0] = src[0];\r\ncamellia_dec_blk_2way(ctx, (u8 *)dst, (u8 *)src);\r\nu128_xor(dst + 1, dst + 1, ivs + 0);\r\nnbytes -= bsize;\r\nif (nbytes < bsize)\r\ngoto done;\r\nu128_xor(dst, dst, src - 1);\r\nsrc -= 1;\r\ndst -= 1;\r\n} while (nbytes >= bsize * 2);\r\nif (nbytes < bsize)\r\ngoto done;\r\n}\r\nfor (;;) {\r\ncamellia_dec_blk(ctx, (u8 *)dst, (u8 *)src);\r\nnbytes -= bsize;\r\nif (nbytes < bsize)\r\nbreak;\r\nu128_xor(dst, dst, src - 1);\r\nsrc -= 1;\r\ndst -= 1;\r\n}\r\ndone:\r\nu128_xor(dst, dst, (u128 *)walk->iv);\r\n*(u128 *)walk->iv = last_iv;\r\nreturn nbytes;\r\n}\r\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct blkcipher_walk walk;\r\nint err;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt(desc, &walk);\r\nwhile ((nbytes = walk.nbytes)) {\r\nnbytes = __cbc_decrypt(desc, &walk);\r\nerr = blkcipher_walk_done(desc, &walk, nbytes);\r\n}\r\nreturn err;\r\n}\r\nstatic inline void u128_to_be128(be128 *dst, const u128 *src)\r\n{\r\ndst->a = cpu_to_be64(src->a);\r\ndst->b = cpu_to_be64(src->b);\r\n}\r\nstatic inline void be128_to_u128(u128 *dst, const be128 *src)\r\n{\r\ndst->a = be64_to_cpu(src->a);\r\ndst->b = be64_to_cpu(src->b);\r\n}\r\nstatic inline void u128_inc(u128 *i)\r\n{\r\ni->b++;\r\nif (!i->b)\r\ni->a++;\r\n}\r\nstatic void ctr_crypt_final(struct blkcipher_desc *desc,\r\nstruct blkcipher_walk *walk)\r\n{\r\nstruct camellia_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nu8 keystream[CAMELLIA_BLOCK_SIZE];\r\nu8 *src = walk->src.virt.addr;\r\nu8 *dst = walk->dst.virt.addr;\r\nunsigned int nbytes = walk->nbytes;\r\nu128 ctrblk;\r\nmemcpy(keystream, src, nbytes);\r\ncamellia_enc_blk_xor(ctx, keystream, walk->iv);\r\nmemcpy(dst, keystream, nbytes);\r\nbe128_to_u128(&ctrblk, (be128 *)walk->iv);\r\nu128_inc(&ctrblk);\r\nu128_to_be128((be128 *)walk->iv, &ctrblk);\r\n}\r\nstatic unsigned int __ctr_crypt(struct blkcipher_desc *desc,\r\nstruct blkcipher_walk *walk)\r\n{\r\nstruct camellia_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nunsigned int bsize = CAMELLIA_BLOCK_SIZE;\r\nunsigned int nbytes = walk->nbytes;\r\nu128 *src = (u128 *)walk->src.virt.addr;\r\nu128 *dst = (u128 *)walk->dst.virt.addr;\r\nu128 ctrblk;\r\nbe128 ctrblocks[2];\r\nbe128_to_u128(&ctrblk, (be128 *)walk->iv);\r\nif (nbytes >= bsize * 2) {\r\ndo {\r\nif (dst != src) {\r\ndst[0] = src[0];\r\ndst[1] = src[1];\r\n}\r\nu128_to_be128(&ctrblocks[0], &ctrblk);\r\nu128_inc(&ctrblk);\r\nu128_to_be128(&ctrblocks[1], &ctrblk);\r\nu128_inc(&ctrblk);\r\ncamellia_enc_blk_xor_2way(ctx, (u8 *)dst,\r\n(u8 *)ctrblocks);\r\nsrc += 2;\r\ndst += 2;\r\nnbytes -= bsize * 2;\r\n} while (nbytes >= bsize * 2);\r\nif (nbytes < bsize)\r\ngoto done;\r\n}\r\ndo {\r\nif (dst != src)\r\n*dst = *src;\r\nu128_to_be128(&ctrblocks[0], &ctrblk);\r\nu128_inc(&ctrblk);\r\ncamellia_enc_blk_xor(ctx, (u8 *)dst, (u8 *)ctrblocks);\r\nsrc += 1;\r\ndst += 1;\r\nnbytes -= bsize;\r\n} while (nbytes >= bsize);\r\ndone:\r\nu128_to_be128((be128 *)walk->iv, &ctrblk);\r\nreturn nbytes;\r\n}\r\nstatic int ctr_crypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct blkcipher_walk walk;\r\nint err;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt_block(desc, &walk, CAMELLIA_BLOCK_SIZE);\r\nwhile ((nbytes = walk.nbytes) >= CAMELLIA_BLOCK_SIZE) {\r\nnbytes = __ctr_crypt(desc, &walk);\r\nerr = blkcipher_walk_done(desc, &walk, nbytes);\r\n}\r\nif (walk.nbytes) {\r\nctr_crypt_final(desc, &walk);\r\nerr = blkcipher_walk_done(desc, &walk, 0);\r\n}\r\nreturn err;\r\n}\r\nstatic void encrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\r\n{\r\nconst unsigned int bsize = CAMELLIA_BLOCK_SIZE;\r\nstruct camellia_ctx *ctx = priv;\r\nint i;\r\nwhile (nbytes >= 2 * bsize) {\r\ncamellia_enc_blk_2way(ctx, srcdst, srcdst);\r\nsrcdst += bsize * 2;\r\nnbytes -= bsize * 2;\r\n}\r\nfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\r\ncamellia_enc_blk(ctx, srcdst, srcdst);\r\n}\r\nstatic void decrypt_callback(void *priv, u8 *srcdst, unsigned int nbytes)\r\n{\r\nconst unsigned int bsize = CAMELLIA_BLOCK_SIZE;\r\nstruct camellia_ctx *ctx = priv;\r\nint i;\r\nwhile (nbytes >= 2 * bsize) {\r\ncamellia_dec_blk_2way(ctx, srcdst, srcdst);\r\nsrcdst += bsize * 2;\r\nnbytes -= bsize * 2;\r\n}\r\nfor (i = 0; i < nbytes / bsize; i++, srcdst += bsize)\r\ncamellia_dec_blk(ctx, srcdst, srcdst);\r\n}\r\nstatic int lrw_camellia_setkey(struct crypto_tfm *tfm, const u8 *key,\r\nunsigned int keylen)\r\n{\r\nstruct camellia_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\r\nint err;\r\nerr = __camellia_setkey(&ctx->camellia_ctx, key,\r\nkeylen - CAMELLIA_BLOCK_SIZE,\r\n&tfm->crt_flags);\r\nif (err)\r\nreturn err;\r\nreturn lrw_init_table(&ctx->lrw_table,\r\nkey + keylen - CAMELLIA_BLOCK_SIZE);\r\n}\r\nstatic int lrw_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct camellia_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nbe128 buf[2 * 4];\r\nstruct lrw_crypt_req req = {\r\n.tbuf = buf,\r\n.tbuflen = sizeof(buf),\r\n.table_ctx = &ctx->lrw_table,\r\n.crypt_ctx = &ctx->camellia_ctx,\r\n.crypt_fn = encrypt_callback,\r\n};\r\nreturn lrw_crypt(desc, dst, src, nbytes, &req);\r\n}\r\nstatic int lrw_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct camellia_lrw_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nbe128 buf[2 * 4];\r\nstruct lrw_crypt_req req = {\r\n.tbuf = buf,\r\n.tbuflen = sizeof(buf),\r\n.table_ctx = &ctx->lrw_table,\r\n.crypt_ctx = &ctx->camellia_ctx,\r\n.crypt_fn = decrypt_callback,\r\n};\r\nreturn lrw_crypt(desc, dst, src, nbytes, &req);\r\n}\r\nstatic void lrw_exit_tfm(struct crypto_tfm *tfm)\r\n{\r\nstruct camellia_lrw_ctx *ctx = crypto_tfm_ctx(tfm);\r\nlrw_free_table(&ctx->lrw_table);\r\n}\r\nstatic int xts_camellia_setkey(struct crypto_tfm *tfm, const u8 *key,\r\nunsigned int keylen)\r\n{\r\nstruct camellia_xts_ctx *ctx = crypto_tfm_ctx(tfm);\r\nu32 *flags = &tfm->crt_flags;\r\nint err;\r\nif (keylen % 2) {\r\n*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\r\nreturn -EINVAL;\r\n}\r\nerr = __camellia_setkey(&ctx->crypt_ctx, key, keylen / 2, flags);\r\nif (err)\r\nreturn err;\r\nreturn __camellia_setkey(&ctx->tweak_ctx, key + keylen / 2, keylen / 2,\r\nflags);\r\n}\r\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct camellia_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nbe128 buf[2 * 4];\r\nstruct xts_crypt_req req = {\r\n.tbuf = buf,\r\n.tbuflen = sizeof(buf),\r\n.tweak_ctx = &ctx->tweak_ctx,\r\n.tweak_fn = XTS_TWEAK_CAST(camellia_enc_blk),\r\n.crypt_ctx = &ctx->crypt_ctx,\r\n.crypt_fn = encrypt_callback,\r\n};\r\nreturn xts_crypt(desc, dst, src, nbytes, &req);\r\n}\r\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct camellia_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nbe128 buf[2 * 4];\r\nstruct xts_crypt_req req = {\r\n.tbuf = buf,\r\n.tbuflen = sizeof(buf),\r\n.tweak_ctx = &ctx->tweak_ctx,\r\n.tweak_fn = XTS_TWEAK_CAST(camellia_enc_blk),\r\n.crypt_ctx = &ctx->crypt_ctx,\r\n.crypt_fn = decrypt_callback,\r\n};\r\nreturn xts_crypt(desc, dst, src, nbytes, &req);\r\n}\r\nstatic bool is_blacklisted_cpu(void)\r\n{\r\nif (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)\r\nreturn false;\r\nif (boot_cpu_data.x86 == 0x0f) {\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic int __init init(void)\r\n{\r\nif (!force && is_blacklisted_cpu()) {\r\nprintk(KERN_INFO\r\n"camellia-x86_64: performance on this CPU "\r\n"would be suboptimal: disabling "\r\n"camellia-x86_64.\n");\r\nreturn -ENODEV;\r\n}\r\nreturn crypto_register_algs(camellia_algs, ARRAY_SIZE(camellia_algs));\r\n}\r\nstatic void __exit fini(void)\r\n{\r\ncrypto_unregister_algs(camellia_algs, ARRAY_SIZE(camellia_algs));\r\n}
