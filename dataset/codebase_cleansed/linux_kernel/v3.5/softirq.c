static void wakeup_softirqd(void)\r\n{\r\nstruct task_struct *tsk = __this_cpu_read(ksoftirqd);\r\nif (tsk && tsk->state != TASK_RUNNING)\r\nwake_up_process(tsk);\r\n}\r\nstatic void __local_bh_disable(unsigned long ip, unsigned int cnt)\r\n{\r\nunsigned long flags;\r\nWARN_ON_ONCE(in_irq());\r\nraw_local_irq_save(flags);\r\npreempt_count() += cnt;\r\nif (softirq_count() == cnt)\r\ntrace_softirqs_off(ip);\r\nraw_local_irq_restore(flags);\r\nif (preempt_count() == cnt)\r\ntrace_preempt_off(CALLER_ADDR0, get_parent_ip(CALLER_ADDR1));\r\n}\r\nstatic inline void __local_bh_disable(unsigned long ip, unsigned int cnt)\r\n{\r\nadd_preempt_count(cnt);\r\nbarrier();\r\n}\r\nvoid local_bh_disable(void)\r\n{\r\n__local_bh_disable((unsigned long)__builtin_return_address(0),\r\nSOFTIRQ_DISABLE_OFFSET);\r\n}\r\nstatic void __local_bh_enable(unsigned int cnt)\r\n{\r\nWARN_ON_ONCE(in_irq());\r\nWARN_ON_ONCE(!irqs_disabled());\r\nif (softirq_count() == cnt)\r\ntrace_softirqs_on((unsigned long)__builtin_return_address(0));\r\nsub_preempt_count(cnt);\r\n}\r\nvoid _local_bh_enable(void)\r\n{\r\n__local_bh_enable(SOFTIRQ_DISABLE_OFFSET);\r\n}\r\nstatic inline void _local_bh_enable_ip(unsigned long ip)\r\n{\r\nWARN_ON_ONCE(in_irq() || irqs_disabled());\r\n#ifdef CONFIG_TRACE_IRQFLAGS\r\nlocal_irq_disable();\r\n#endif\r\nif (softirq_count() == SOFTIRQ_DISABLE_OFFSET)\r\ntrace_softirqs_on(ip);\r\nsub_preempt_count(SOFTIRQ_DISABLE_OFFSET - 1);\r\nif (unlikely(!in_interrupt() && local_softirq_pending()))\r\ndo_softirq();\r\ndec_preempt_count();\r\n#ifdef CONFIG_TRACE_IRQFLAGS\r\nlocal_irq_enable();\r\n#endif\r\npreempt_check_resched();\r\n}\r\nvoid local_bh_enable(void)\r\n{\r\n_local_bh_enable_ip((unsigned long)__builtin_return_address(0));\r\n}\r\nvoid local_bh_enable_ip(unsigned long ip)\r\n{\r\n_local_bh_enable_ip(ip);\r\n}\r\nasmlinkage void __do_softirq(void)\r\n{\r\nstruct softirq_action *h;\r\n__u32 pending;\r\nint max_restart = MAX_SOFTIRQ_RESTART;\r\nint cpu;\r\npending = local_softirq_pending();\r\naccount_system_vtime(current);\r\n__local_bh_disable((unsigned long)__builtin_return_address(0),\r\nSOFTIRQ_OFFSET);\r\nlockdep_softirq_enter();\r\ncpu = smp_processor_id();\r\nrestart:\r\nset_softirq_pending(0);\r\nlocal_irq_enable();\r\nh = softirq_vec;\r\ndo {\r\nif (pending & 1) {\r\nunsigned int vec_nr = h - softirq_vec;\r\nint prev_count = preempt_count();\r\nkstat_incr_softirqs_this_cpu(vec_nr);\r\ntrace_softirq_entry(vec_nr);\r\nh->action(h);\r\ntrace_softirq_exit(vec_nr);\r\nif (unlikely(prev_count != preempt_count())) {\r\nprintk(KERN_ERR "huh, entered softirq %u %s %p"\r\n"with preempt_count %08x,"\r\n" exited with %08x?\n", vec_nr,\r\nsoftirq_to_name[vec_nr], h->action,\r\nprev_count, preempt_count());\r\npreempt_count() = prev_count;\r\n}\r\nrcu_bh_qs(cpu);\r\n}\r\nh++;\r\npending >>= 1;\r\n} while (pending);\r\nlocal_irq_disable();\r\npending = local_softirq_pending();\r\nif (pending && --max_restart)\r\ngoto restart;\r\nif (pending)\r\nwakeup_softirqd();\r\nlockdep_softirq_exit();\r\naccount_system_vtime(current);\r\n__local_bh_enable(SOFTIRQ_OFFSET);\r\n}\r\nasmlinkage void do_softirq(void)\r\n{\r\n__u32 pending;\r\nunsigned long flags;\r\nif (in_interrupt())\r\nreturn;\r\nlocal_irq_save(flags);\r\npending = local_softirq_pending();\r\nif (pending)\r\n__do_softirq();\r\nlocal_irq_restore(flags);\r\n}\r\nvoid irq_enter(void)\r\n{\r\nint cpu = smp_processor_id();\r\nrcu_irq_enter();\r\nif (is_idle_task(current) && !in_interrupt()) {\r\nlocal_bh_disable();\r\ntick_check_idle(cpu);\r\n_local_bh_enable();\r\n}\r\n__irq_enter();\r\n}\r\nstatic inline void invoke_softirq(void)\r\n{\r\nif (!force_irqthreads) {\r\n#ifdef __ARCH_IRQ_EXIT_IRQS_DISABLED\r\n__do_softirq();\r\n#else\r\ndo_softirq();\r\n#endif\r\n} else {\r\n__local_bh_disable((unsigned long)__builtin_return_address(0),\r\nSOFTIRQ_OFFSET);\r\nwakeup_softirqd();\r\n__local_bh_enable(SOFTIRQ_OFFSET);\r\n}\r\n}\r\nvoid irq_exit(void)\r\n{\r\naccount_system_vtime(current);\r\ntrace_hardirq_exit();\r\nsub_preempt_count(IRQ_EXIT_OFFSET);\r\nif (!in_interrupt() && local_softirq_pending())\r\ninvoke_softirq();\r\n#ifdef CONFIG_NO_HZ\r\nif (idle_cpu(smp_processor_id()) && !in_interrupt() && !need_resched())\r\ntick_nohz_irq_exit();\r\n#endif\r\nrcu_irq_exit();\r\nsched_preempt_enable_no_resched();\r\n}\r\ninline void raise_softirq_irqoff(unsigned int nr)\r\n{\r\n__raise_softirq_irqoff(nr);\r\nif (!in_interrupt())\r\nwakeup_softirqd();\r\n}\r\nvoid raise_softirq(unsigned int nr)\r\n{\r\nunsigned long flags;\r\nlocal_irq_save(flags);\r\nraise_softirq_irqoff(nr);\r\nlocal_irq_restore(flags);\r\n}\r\nvoid __raise_softirq_irqoff(unsigned int nr)\r\n{\r\ntrace_softirq_raise(nr);\r\nor_softirq_pending(1UL << nr);\r\n}\r\nvoid open_softirq(int nr, void (*action)(struct softirq_action *))\r\n{\r\nsoftirq_vec[nr].action = action;\r\n}\r\nvoid __tasklet_schedule(struct tasklet_struct *t)\r\n{\r\nunsigned long flags;\r\nlocal_irq_save(flags);\r\nt->next = NULL;\r\n*__this_cpu_read(tasklet_vec.tail) = t;\r\n__this_cpu_write(tasklet_vec.tail, &(t->next));\r\nraise_softirq_irqoff(TASKLET_SOFTIRQ);\r\nlocal_irq_restore(flags);\r\n}\r\nvoid __tasklet_hi_schedule(struct tasklet_struct *t)\r\n{\r\nunsigned long flags;\r\nlocal_irq_save(flags);\r\nt->next = NULL;\r\n*__this_cpu_read(tasklet_hi_vec.tail) = t;\r\n__this_cpu_write(tasklet_hi_vec.tail, &(t->next));\r\nraise_softirq_irqoff(HI_SOFTIRQ);\r\nlocal_irq_restore(flags);\r\n}\r\nvoid __tasklet_hi_schedule_first(struct tasklet_struct *t)\r\n{\r\nBUG_ON(!irqs_disabled());\r\nt->next = __this_cpu_read(tasklet_hi_vec.head);\r\n__this_cpu_write(tasklet_hi_vec.head, t);\r\n__raise_softirq_irqoff(HI_SOFTIRQ);\r\n}\r\nstatic void tasklet_action(struct softirq_action *a)\r\n{\r\nstruct tasklet_struct *list;\r\nlocal_irq_disable();\r\nlist = __this_cpu_read(tasklet_vec.head);\r\n__this_cpu_write(tasklet_vec.head, NULL);\r\n__this_cpu_write(tasklet_vec.tail, &__get_cpu_var(tasklet_vec).head);\r\nlocal_irq_enable();\r\nwhile (list) {\r\nstruct tasklet_struct *t = list;\r\nlist = list->next;\r\nif (tasklet_trylock(t)) {\r\nif (!atomic_read(&t->count)) {\r\nif (!test_and_clear_bit(TASKLET_STATE_SCHED, &t->state))\r\nBUG();\r\nt->func(t->data);\r\ntasklet_unlock(t);\r\ncontinue;\r\n}\r\ntasklet_unlock(t);\r\n}\r\nlocal_irq_disable();\r\nt->next = NULL;\r\n*__this_cpu_read(tasklet_vec.tail) = t;\r\n__this_cpu_write(tasklet_vec.tail, &(t->next));\r\n__raise_softirq_irqoff(TASKLET_SOFTIRQ);\r\nlocal_irq_enable();\r\n}\r\n}\r\nstatic void tasklet_hi_action(struct softirq_action *a)\r\n{\r\nstruct tasklet_struct *list;\r\nlocal_irq_disable();\r\nlist = __this_cpu_read(tasklet_hi_vec.head);\r\n__this_cpu_write(tasklet_hi_vec.head, NULL);\r\n__this_cpu_write(tasklet_hi_vec.tail, &__get_cpu_var(tasklet_hi_vec).head);\r\nlocal_irq_enable();\r\nwhile (list) {\r\nstruct tasklet_struct *t = list;\r\nlist = list->next;\r\nif (tasklet_trylock(t)) {\r\nif (!atomic_read(&t->count)) {\r\nif (!test_and_clear_bit(TASKLET_STATE_SCHED, &t->state))\r\nBUG();\r\nt->func(t->data);\r\ntasklet_unlock(t);\r\ncontinue;\r\n}\r\ntasklet_unlock(t);\r\n}\r\nlocal_irq_disable();\r\nt->next = NULL;\r\n*__this_cpu_read(tasklet_hi_vec.tail) = t;\r\n__this_cpu_write(tasklet_hi_vec.tail, &(t->next));\r\n__raise_softirq_irqoff(HI_SOFTIRQ);\r\nlocal_irq_enable();\r\n}\r\n}\r\nvoid tasklet_init(struct tasklet_struct *t,\r\nvoid (*func)(unsigned long), unsigned long data)\r\n{\r\nt->next = NULL;\r\nt->state = 0;\r\natomic_set(&t->count, 0);\r\nt->func = func;\r\nt->data = data;\r\n}\r\nvoid tasklet_kill(struct tasklet_struct *t)\r\n{\r\nif (in_interrupt())\r\nprintk("Attempt to kill tasklet from interrupt\n");\r\nwhile (test_and_set_bit(TASKLET_STATE_SCHED, &t->state)) {\r\ndo {\r\nyield();\r\n} while (test_bit(TASKLET_STATE_SCHED, &t->state));\r\n}\r\ntasklet_unlock_wait(t);\r\nclear_bit(TASKLET_STATE_SCHED, &t->state);\r\n}\r\nstatic enum hrtimer_restart __hrtimer_tasklet_trampoline(struct hrtimer *timer)\r\n{\r\nstruct tasklet_hrtimer *ttimer =\r\ncontainer_of(timer, struct tasklet_hrtimer, timer);\r\ntasklet_hi_schedule(&ttimer->tasklet);\r\nreturn HRTIMER_NORESTART;\r\n}\r\nstatic void __tasklet_hrtimer_trampoline(unsigned long data)\r\n{\r\nstruct tasklet_hrtimer *ttimer = (void *)data;\r\nenum hrtimer_restart restart;\r\nrestart = ttimer->function(&ttimer->timer);\r\nif (restart != HRTIMER_NORESTART)\r\nhrtimer_restart(&ttimer->timer);\r\n}\r\nstatic void __local_trigger(struct call_single_data *cp, int softirq)\r\n{\r\nstruct list_head *head = &__get_cpu_var(softirq_work_list[softirq]);\r\nlist_add_tail(&cp->list, head);\r\nif (head->next == &cp->list)\r\nraise_softirq_irqoff(softirq);\r\n}\r\nstatic void remote_softirq_receive(void *data)\r\n{\r\nstruct call_single_data *cp = data;\r\nunsigned long flags;\r\nint softirq;\r\nsoftirq = cp->priv;\r\nlocal_irq_save(flags);\r\n__local_trigger(cp, softirq);\r\nlocal_irq_restore(flags);\r\n}\r\nstatic int __try_remote_softirq(struct call_single_data *cp, int cpu, int softirq)\r\n{\r\nif (cpu_online(cpu)) {\r\ncp->func = remote_softirq_receive;\r\ncp->info = cp;\r\ncp->flags = 0;\r\ncp->priv = softirq;\r\n__smp_call_function_single(cpu, cp, 0);\r\nreturn 0;\r\n}\r\nreturn 1;\r\n}\r\nstatic int __try_remote_softirq(struct call_single_data *cp, int cpu, int softirq)\r\n{\r\nreturn 1;\r\n}\r\nvoid __send_remote_softirq(struct call_single_data *cp, int cpu, int this_cpu, int softirq)\r\n{\r\nif (cpu == this_cpu || __try_remote_softirq(cp, cpu, softirq))\r\n__local_trigger(cp, softirq);\r\n}\r\nvoid send_remote_softirq(struct call_single_data *cp, int cpu, int softirq)\r\n{\r\nunsigned long flags;\r\nint this_cpu;\r\nlocal_irq_save(flags);\r\nthis_cpu = smp_processor_id();\r\n__send_remote_softirq(cp, cpu, this_cpu, softirq);\r\nlocal_irq_restore(flags);\r\n}\r\nstatic int __cpuinit remote_softirq_cpu_notify(struct notifier_block *self,\r\nunsigned long action, void *hcpu)\r\n{\r\nif (action == CPU_DEAD || action == CPU_DEAD_FROZEN) {\r\nint cpu = (unsigned long) hcpu;\r\nint i;\r\nlocal_irq_disable();\r\nfor (i = 0; i < NR_SOFTIRQS; i++) {\r\nstruct list_head *head = &per_cpu(softirq_work_list[i], cpu);\r\nstruct list_head *local_head;\r\nif (list_empty(head))\r\ncontinue;\r\nlocal_head = &__get_cpu_var(softirq_work_list[i]);\r\nlist_splice_init(head, local_head);\r\nraise_softirq_irqoff(i);\r\n}\r\nlocal_irq_enable();\r\n}\r\nreturn NOTIFY_OK;\r\n}\r\nvoid __init softirq_init(void)\r\n{\r\nint cpu;\r\nfor_each_possible_cpu(cpu) {\r\nint i;\r\nper_cpu(tasklet_vec, cpu).tail =\r\n&per_cpu(tasklet_vec, cpu).head;\r\nper_cpu(tasklet_hi_vec, cpu).tail =\r\n&per_cpu(tasklet_hi_vec, cpu).head;\r\nfor (i = 0; i < NR_SOFTIRQS; i++)\r\nINIT_LIST_HEAD(&per_cpu(softirq_work_list[i], cpu));\r\n}\r\nregister_hotcpu_notifier(&remote_softirq_cpu_notifier);\r\nopen_softirq(TASKLET_SOFTIRQ, tasklet_action);\r\nopen_softirq(HI_SOFTIRQ, tasklet_hi_action);\r\n}\r\nstatic int run_ksoftirqd(void * __bind_cpu)\r\n{\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nwhile (!kthread_should_stop()) {\r\npreempt_disable();\r\nif (!local_softirq_pending()) {\r\nschedule_preempt_disabled();\r\n}\r\n__set_current_state(TASK_RUNNING);\r\nwhile (local_softirq_pending()) {\r\nif (cpu_is_offline((long)__bind_cpu))\r\ngoto wait_to_die;\r\nlocal_irq_disable();\r\nif (local_softirq_pending())\r\n__do_softirq();\r\nlocal_irq_enable();\r\nsched_preempt_enable_no_resched();\r\ncond_resched();\r\npreempt_disable();\r\nrcu_note_context_switch((long)__bind_cpu);\r\n}\r\npreempt_enable();\r\nset_current_state(TASK_INTERRUPTIBLE);\r\n}\r\n__set_current_state(TASK_RUNNING);\r\nreturn 0;\r\nwait_to_die:\r\npreempt_enable();\r\nset_current_state(TASK_INTERRUPTIBLE);\r\nwhile (!kthread_should_stop()) {\r\nschedule();\r\nset_current_state(TASK_INTERRUPTIBLE);\r\n}\r\n__set_current_state(TASK_RUNNING);\r\nreturn 0;\r\n}\r\nvoid tasklet_kill_immediate(struct tasklet_struct *t, unsigned int cpu)\r\n{\r\nstruct tasklet_struct **i;\r\nBUG_ON(cpu_online(cpu));\r\nBUG_ON(test_bit(TASKLET_STATE_RUN, &t->state));\r\nif (!test_bit(TASKLET_STATE_SCHED, &t->state))\r\nreturn;\r\nfor (i = &per_cpu(tasklet_vec, cpu).head; *i; i = &(*i)->next) {\r\nif (*i == t) {\r\n*i = t->next;\r\nif (*i == NULL)\r\nper_cpu(tasklet_vec, cpu).tail = i;\r\nreturn;\r\n}\r\n}\r\nBUG();\r\n}\r\nstatic void takeover_tasklets(unsigned int cpu)\r\n{\r\nlocal_irq_disable();\r\nif (&per_cpu(tasklet_vec, cpu).head != per_cpu(tasklet_vec, cpu).tail) {\r\n*__this_cpu_read(tasklet_vec.tail) = per_cpu(tasklet_vec, cpu).head;\r\nthis_cpu_write(tasklet_vec.tail, per_cpu(tasklet_vec, cpu).tail);\r\nper_cpu(tasklet_vec, cpu).head = NULL;\r\nper_cpu(tasklet_vec, cpu).tail = &per_cpu(tasklet_vec, cpu).head;\r\n}\r\nraise_softirq_irqoff(TASKLET_SOFTIRQ);\r\nif (&per_cpu(tasklet_hi_vec, cpu).head != per_cpu(tasklet_hi_vec, cpu).tail) {\r\n*__this_cpu_read(tasklet_hi_vec.tail) = per_cpu(tasklet_hi_vec, cpu).head;\r\n__this_cpu_write(tasklet_hi_vec.tail, per_cpu(tasklet_hi_vec, cpu).tail);\r\nper_cpu(tasklet_hi_vec, cpu).head = NULL;\r\nper_cpu(tasklet_hi_vec, cpu).tail = &per_cpu(tasklet_hi_vec, cpu).head;\r\n}\r\nraise_softirq_irqoff(HI_SOFTIRQ);\r\nlocal_irq_enable();\r\n}\r\nstatic int __cpuinit cpu_callback(struct notifier_block *nfb,\r\nunsigned long action,\r\nvoid *hcpu)\r\n{\r\nint hotcpu = (unsigned long)hcpu;\r\nstruct task_struct *p;\r\nswitch (action) {\r\ncase CPU_UP_PREPARE:\r\ncase CPU_UP_PREPARE_FROZEN:\r\np = kthread_create_on_node(run_ksoftirqd,\r\nhcpu,\r\ncpu_to_node(hotcpu),\r\n"ksoftirqd/%d", hotcpu);\r\nif (IS_ERR(p)) {\r\nprintk("ksoftirqd for %i failed\n", hotcpu);\r\nreturn notifier_from_errno(PTR_ERR(p));\r\n}\r\nkthread_bind(p, hotcpu);\r\nper_cpu(ksoftirqd, hotcpu) = p;\r\nbreak;\r\ncase CPU_ONLINE:\r\ncase CPU_ONLINE_FROZEN:\r\nwake_up_process(per_cpu(ksoftirqd, hotcpu));\r\nbreak;\r\n#ifdef CONFIG_HOTPLUG_CPU\r\ncase CPU_UP_CANCELED:\r\ncase CPU_UP_CANCELED_FROZEN:\r\nif (!per_cpu(ksoftirqd, hotcpu))\r\nbreak;\r\nkthread_bind(per_cpu(ksoftirqd, hotcpu),\r\ncpumask_any(cpu_online_mask));\r\ncase CPU_DEAD:\r\ncase CPU_DEAD_FROZEN: {\r\nstatic const struct sched_param param = {\r\n.sched_priority = MAX_RT_PRIO-1\r\n};\r\np = per_cpu(ksoftirqd, hotcpu);\r\nper_cpu(ksoftirqd, hotcpu) = NULL;\r\nsched_setscheduler_nocheck(p, SCHED_FIFO, &param);\r\nkthread_stop(p);\r\ntakeover_tasklets(hotcpu);\r\nbreak;\r\n}\r\n#endif\r\n}\r\nreturn NOTIFY_OK;\r\n}\r\nstatic __init int spawn_ksoftirqd(void)\r\n{\r\nvoid *cpu = (void *)(long)smp_processor_id();\r\nint err = cpu_callback(&cpu_nfb, CPU_UP_PREPARE, cpu);\r\nBUG_ON(err != NOTIFY_OK);\r\ncpu_callback(&cpu_nfb, CPU_ONLINE, cpu);\r\nregister_cpu_notifier(&cpu_nfb);\r\nreturn 0;\r\n}\r\nint __init __weak early_irq_init(void)\r\n{\r\nreturn 0;\r\n}\r\nint __init __weak arch_probe_nr_irqs(void)\r\n{\r\nreturn NR_IRQS_LEGACY;\r\n}\r\nint __init __weak arch_early_irq_init(void)\r\n{\r\nreturn 0;\r\n}
