static int oz_def_app_init(void)\r\n{\r\nreturn 0;\r\n}\r\nstatic void oz_def_app_term(void)\r\n{\r\n}\r\nstatic int oz_def_app_start(struct oz_pd *pd, int resume)\r\n{\r\nreturn 0;\r\n}\r\nstatic void oz_def_app_stop(struct oz_pd *pd, int pause)\r\n{\r\n}\r\nstatic void oz_def_app_rx(struct oz_pd *pd, struct oz_elt *elt)\r\n{\r\n}\r\nvoid oz_pd_set_state(struct oz_pd *pd, unsigned state)\r\n{\r\npd->state = state;\r\noz_event_log(OZ_EVT_PD_STATE, 0, 0, 0, state);\r\n#ifdef WANT_TRACE\r\nswitch (state) {\r\ncase OZ_PD_S_IDLE:\r\noz_trace("PD State: OZ_PD_S_IDLE\n");\r\nbreak;\r\ncase OZ_PD_S_CONNECTED:\r\noz_trace("PD State: OZ_PD_S_CONNECTED\n");\r\nbreak;\r\ncase OZ_PD_S_STOPPED:\r\noz_trace("PD State: OZ_PD_S_STOPPED\n");\r\nbreak;\r\ncase OZ_PD_S_SLEEP:\r\noz_trace("PD State: OZ_PD_S_SLEEP\n");\r\nbreak;\r\n}\r\n#endif\r\n}\r\nvoid oz_pd_get(struct oz_pd *pd)\r\n{\r\natomic_inc(&pd->ref_count);\r\n}\r\nvoid oz_pd_put(struct oz_pd *pd)\r\n{\r\nif (atomic_dec_and_test(&pd->ref_count))\r\noz_pd_destroy(pd);\r\n}\r\nstruct oz_pd *oz_pd_alloc(u8 *mac_addr)\r\n{\r\nstruct oz_pd *pd = kzalloc(sizeof(struct oz_pd), GFP_ATOMIC);\r\nif (pd) {\r\nint i;\r\natomic_set(&pd->ref_count, 2);\r\nfor (i = 0; i < OZ_APPID_MAX; i++)\r\nspin_lock_init(&pd->app_lock[i]);\r\npd->last_rx_pkt_num = 0xffffffff;\r\noz_pd_set_state(pd, OZ_PD_S_IDLE);\r\npd->max_tx_size = OZ_MAX_TX_SIZE;\r\nmemcpy(pd->mac_addr, mac_addr, ETH_ALEN);\r\nif (0 != oz_elt_buf_init(&pd->elt_buff)) {\r\nkfree(pd);\r\npd = 0;\r\n}\r\nspin_lock_init(&pd->tx_frame_lock);\r\nINIT_LIST_HEAD(&pd->tx_queue);\r\nINIT_LIST_HEAD(&pd->farewell_list);\r\npd->last_sent_frame = &pd->tx_queue;\r\nspin_lock_init(&pd->stream_lock);\r\nINIT_LIST_HEAD(&pd->stream_list);\r\n}\r\nreturn pd;\r\n}\r\nvoid oz_pd_destroy(struct oz_pd *pd)\r\n{\r\nstruct list_head *e;\r\nstruct oz_tx_frame *f;\r\nstruct oz_isoc_stream *st;\r\nstruct oz_farewell *fwell;\r\noz_trace("Destroying PD\n");\r\ne = pd->stream_list.next;\r\nwhile (e != &pd->stream_list) {\r\nst = container_of(e, struct oz_isoc_stream, link);\r\ne = e->next;\r\noz_isoc_stream_free(st);\r\n}\r\ne = pd->tx_queue.next;\r\nwhile (e != &pd->tx_queue) {\r\nf = container_of(e, struct oz_tx_frame, link);\r\ne = e->next;\r\noz_retire_frame(pd, f);\r\n}\r\noz_elt_buf_term(&pd->elt_buff);\r\ne = pd->farewell_list.next;\r\nwhile (e != &pd->farewell_list) {\r\nfwell = container_of(e, struct oz_farewell, link);\r\ne = e->next;\r\nkfree(fwell);\r\n}\r\nwhile (pd->tx_pool) {\r\ne = pd->tx_pool;\r\npd->tx_pool = e->next;\r\nkfree(container_of(e, struct oz_tx_frame, link));\r\n}\r\nif (pd->net_dev)\r\ndev_put(pd->net_dev);\r\nkfree(pd);\r\n}\r\nint oz_services_start(struct oz_pd *pd, u16 apps, int resume)\r\n{\r\nstruct oz_app_if *ai;\r\nint rc = 0;\r\noz_trace("oz_services_start(0x%x) resume(%d)\n", apps, resume);\r\nfor (ai = g_app_if; ai < &g_app_if[OZ_APPID_MAX]; ai++) {\r\nif (apps & (1<<ai->app_id)) {\r\nif (ai->start(pd, resume)) {\r\nrc = -1;\r\noz_trace("Unabled to start service %d\n",\r\nai->app_id);\r\nbreak;\r\n}\r\noz_polling_lock_bh();\r\npd->total_apps |= (1<<ai->app_id);\r\nif (resume)\r\npd->paused_apps &= ~(1<<ai->app_id);\r\noz_polling_unlock_bh();\r\n}\r\n}\r\nreturn rc;\r\n}\r\nvoid oz_services_stop(struct oz_pd *pd, u16 apps, int pause)\r\n{\r\nstruct oz_app_if *ai;\r\noz_trace("oz_stop_services(0x%x) pause(%d)\n", apps, pause);\r\nfor (ai = g_app_if; ai < &g_app_if[OZ_APPID_MAX]; ai++) {\r\nif (apps & (1<<ai->app_id)) {\r\noz_polling_lock_bh();\r\nif (pause) {\r\npd->paused_apps |= (1<<ai->app_id);\r\n} else {\r\npd->total_apps &= ~(1<<ai->app_id);\r\npd->paused_apps &= ~(1<<ai->app_id);\r\n}\r\noz_polling_unlock_bh();\r\nai->stop(pd, pause);\r\n}\r\n}\r\n}\r\nvoid oz_pd_heartbeat(struct oz_pd *pd, u16 apps)\r\n{\r\nstruct oz_app_if *ai;\r\nint more = 0;\r\nfor (ai = g_app_if; ai < &g_app_if[OZ_APPID_MAX]; ai++) {\r\nif (ai->heartbeat && (apps & (1<<ai->app_id))) {\r\nif (ai->heartbeat(pd))\r\nmore = 1;\r\n}\r\n}\r\nif (more)\r\noz_pd_request_heartbeat(pd);\r\nif (pd->mode & OZ_F_ISOC_ANYTIME) {\r\nint count = 8;\r\nwhile (count-- && (oz_send_isoc_frame(pd) >= 0))\r\n;\r\n}\r\n}\r\nvoid oz_pd_stop(struct oz_pd *pd)\r\n{\r\nu16 stop_apps = 0;\r\noz_trace("oz_pd_stop() State = 0x%x\n", pd->state);\r\noz_pd_indicate_farewells(pd);\r\noz_polling_lock_bh();\r\nstop_apps = pd->total_apps;\r\npd->total_apps = 0;\r\npd->paused_apps = 0;\r\noz_polling_unlock_bh();\r\noz_services_stop(pd, stop_apps, 0);\r\noz_polling_lock_bh();\r\noz_pd_set_state(pd, OZ_PD_S_STOPPED);\r\nlist_del(&pd->link);\r\noz_polling_unlock_bh();\r\noz_trace("pd ref count = %d\n", atomic_read(&pd->ref_count));\r\noz_timer_delete(pd, 0);\r\noz_pd_put(pd);\r\n}\r\nint oz_pd_sleep(struct oz_pd *pd)\r\n{\r\nint do_stop = 0;\r\nu16 stop_apps = 0;\r\noz_polling_lock_bh();\r\nif (pd->state & (OZ_PD_S_SLEEP | OZ_PD_S_STOPPED)) {\r\noz_polling_unlock_bh();\r\nreturn 0;\r\n}\r\nif (pd->keep_alive_j && pd->session_id) {\r\noz_pd_set_state(pd, OZ_PD_S_SLEEP);\r\npd->pulse_time_j = jiffies + pd->keep_alive_j;\r\noz_trace("Sleep Now %lu until %lu\n",\r\njiffies, pd->pulse_time_j);\r\n} else {\r\ndo_stop = 1;\r\n}\r\nstop_apps = pd->total_apps;\r\noz_polling_unlock_bh();\r\nif (do_stop) {\r\noz_pd_stop(pd);\r\n} else {\r\noz_services_stop(pd, stop_apps, 1);\r\noz_timer_add(pd, OZ_TIMER_STOP, jiffies + pd->keep_alive_j, 1);\r\n}\r\nreturn do_stop;\r\n}\r\nstatic struct oz_tx_frame *oz_tx_frame_alloc(struct oz_pd *pd)\r\n{\r\nstruct oz_tx_frame *f = 0;\r\nspin_lock_bh(&pd->tx_frame_lock);\r\nif (pd->tx_pool) {\r\nf = container_of(pd->tx_pool, struct oz_tx_frame, link);\r\npd->tx_pool = pd->tx_pool->next;\r\npd->tx_pool_count--;\r\n}\r\nspin_unlock_bh(&pd->tx_frame_lock);\r\nif (f == 0)\r\nf = kmalloc(sizeof(struct oz_tx_frame), GFP_ATOMIC);\r\nif (f) {\r\nf->total_size = sizeof(struct oz_hdr);\r\nINIT_LIST_HEAD(&f->link);\r\nINIT_LIST_HEAD(&f->elt_list);\r\n}\r\nreturn f;\r\n}\r\nstatic void oz_tx_frame_free(struct oz_pd *pd, struct oz_tx_frame *f)\r\n{\r\nspin_lock_bh(&pd->tx_frame_lock);\r\nif (pd->tx_pool_count < OZ_MAX_TX_POOL_SIZE) {\r\nf->link.next = pd->tx_pool;\r\npd->tx_pool = &f->link;\r\npd->tx_pool_count++;\r\nf = 0;\r\n}\r\nspin_unlock_bh(&pd->tx_frame_lock);\r\nif (f)\r\nkfree(f);\r\n}\r\nint oz_prepare_frame(struct oz_pd *pd, int empty)\r\n{\r\nstruct oz_tx_frame *f;\r\nif ((pd->mode & OZ_MODE_MASK) != OZ_MODE_TRIGGERED)\r\nreturn -1;\r\nif (pd->nb_queued_frames >= OZ_MAX_QUEUED_FRAMES)\r\nreturn -1;\r\nif (!empty && !oz_are_elts_available(&pd->elt_buff))\r\nreturn -1;\r\nf = oz_tx_frame_alloc(pd);\r\nif (f == 0)\r\nreturn -1;\r\nf->hdr.control =\r\n(OZ_PROTOCOL_VERSION<<OZ_VERSION_SHIFT) | OZ_F_ACK_REQUESTED;\r\n++pd->last_tx_pkt_num;\r\nput_unaligned(cpu_to_le32(pd->last_tx_pkt_num), &f->hdr.pkt_num);\r\nif (empty == 0) {\r\noz_select_elts_for_tx(&pd->elt_buff, 0, &f->total_size,\r\npd->max_tx_size, &f->elt_list);\r\n}\r\nspin_lock(&pd->tx_frame_lock);\r\nlist_add_tail(&f->link, &pd->tx_queue);\r\npd->nb_queued_frames++;\r\nspin_unlock(&pd->tx_frame_lock);\r\nreturn 0;\r\n}\r\nstatic struct sk_buff *oz_build_frame(struct oz_pd *pd, struct oz_tx_frame *f)\r\n{\r\nstruct sk_buff *skb = 0;\r\nstruct net_device *dev = pd->net_dev;\r\nstruct oz_hdr *oz_hdr;\r\nstruct oz_elt *elt;\r\nstruct list_head *e;\r\nskb = alloc_skb(f->total_size + OZ_ALLOCATED_SPACE(dev), GFP_ATOMIC);\r\nif (skb == 0)\r\nreturn 0;\r\nskb_reserve(skb, LL_RESERVED_SPACE(dev));\r\nskb_reset_network_header(skb);\r\nskb->dev = dev;\r\nskb->protocol = htons(OZ_ETHERTYPE);\r\nif (dev_hard_header(skb, dev, OZ_ETHERTYPE, pd->mac_addr,\r\ndev->dev_addr, skb->len) < 0)\r\ngoto fail;\r\noz_hdr = (struct oz_hdr *)skb_put(skb, f->total_size);\r\nf->hdr.last_pkt_num = pd->trigger_pkt_num & OZ_LAST_PN_MASK;\r\nmemcpy(oz_hdr, &f->hdr, sizeof(struct oz_hdr));\r\nelt = (struct oz_elt *)(oz_hdr+1);\r\nfor (e = f->elt_list.next; e != &f->elt_list; e = e->next) {\r\nstruct oz_elt_info *ei;\r\nei = container_of(e, struct oz_elt_info, link);\r\nmemcpy(elt, ei->data, ei->length);\r\nelt = oz_next_elt(elt);\r\n}\r\nreturn skb;\r\nfail:\r\nkfree_skb(skb);\r\nreturn 0;\r\n}\r\nstatic void oz_retire_frame(struct oz_pd *pd, struct oz_tx_frame *f)\r\n{\r\nstruct list_head *e;\r\nstruct oz_elt_info *ei;\r\ne = f->elt_list.next;\r\nwhile (e != &f->elt_list) {\r\nei = container_of(e, struct oz_elt_info, link);\r\ne = e->next;\r\nlist_del_init(&ei->link);\r\nif (ei->callback)\r\nei->callback(pd, ei->context);\r\nspin_lock_bh(&pd->elt_buff.lock);\r\noz_elt_info_free(&pd->elt_buff, ei);\r\nspin_unlock_bh(&pd->elt_buff.lock);\r\n}\r\noz_tx_frame_free(pd, f);\r\nif (pd->elt_buff.free_elts > pd->elt_buff.max_free_elts)\r\noz_trim_elt_pool(&pd->elt_buff);\r\n}\r\nstatic int oz_send_next_queued_frame(struct oz_pd *pd, int *more_data)\r\n{\r\nstruct sk_buff *skb;\r\nstruct oz_tx_frame *f;\r\nstruct list_head *e;\r\n*more_data = 0;\r\nspin_lock(&pd->tx_frame_lock);\r\ne = pd->last_sent_frame->next;\r\nif (e == &pd->tx_queue) {\r\nspin_unlock(&pd->tx_frame_lock);\r\nreturn -1;\r\n}\r\npd->last_sent_frame = e;\r\nif (e->next != &pd->tx_queue)\r\n*more_data = 1;\r\nf = container_of(e, struct oz_tx_frame, link);\r\nskb = oz_build_frame(pd, f);\r\nspin_unlock(&pd->tx_frame_lock);\r\noz_trace2(OZ_TRACE_TX_FRAMES, "TX frame PN=0x%x\n", f->hdr.pkt_num);\r\nif (skb) {\r\noz_event_log(OZ_EVT_TX_FRAME,\r\n0,\r\n(((u16)f->hdr.control)<<8)|f->hdr.last_pkt_num,\r\n0, f->hdr.pkt_num);\r\nif (dev_queue_xmit(skb) < 0)\r\nreturn -1;\r\n}\r\nreturn 0;\r\n}\r\nvoid oz_send_queued_frames(struct oz_pd *pd, int backlog)\r\n{\r\nint more;\r\nif (backlog < OZ_MAX_QUEUED_FRAMES) {\r\nif (oz_send_next_queued_frame(pd, &more) >= 0) {\r\nwhile (more && oz_send_next_queued_frame(pd, &more))\r\n;\r\n} else {\r\nif (((pd->mode & OZ_F_ISOC_ANYTIME) == 0)\r\n|| (pd->isoc_sent == 0)) {\r\nif (oz_prepare_frame(pd, 1) >= 0)\r\noz_send_next_queued_frame(pd, &more);\r\n}\r\n}\r\n} else {\r\noz_send_next_queued_frame(pd, &more);\r\n}\r\n}\r\nstatic int oz_send_isoc_frame(struct oz_pd *pd)\r\n{\r\nstruct sk_buff *skb = 0;\r\nstruct net_device *dev = pd->net_dev;\r\nstruct oz_hdr *oz_hdr;\r\nstruct oz_elt *elt;\r\nstruct list_head *e;\r\nstruct list_head list;\r\nint total_size = sizeof(struct oz_hdr);\r\nINIT_LIST_HEAD(&list);\r\noz_select_elts_for_tx(&pd->elt_buff, 1, &total_size,\r\npd->max_tx_size, &list);\r\nif (list.next == &list)\r\nreturn 0;\r\nskb = alloc_skb(total_size + OZ_ALLOCATED_SPACE(dev), GFP_ATOMIC);\r\nif (skb == 0) {\r\noz_trace("Cannot alloc skb\n");\r\noz_elt_info_free_chain(&pd->elt_buff, &list);\r\nreturn -1;\r\n}\r\nskb_reserve(skb, LL_RESERVED_SPACE(dev));\r\nskb_reset_network_header(skb);\r\nskb->dev = dev;\r\nskb->protocol = htons(OZ_ETHERTYPE);\r\nif (dev_hard_header(skb, dev, OZ_ETHERTYPE, pd->mac_addr,\r\ndev->dev_addr, skb->len) < 0) {\r\nkfree_skb(skb);\r\nreturn -1;\r\n}\r\noz_hdr = (struct oz_hdr *)skb_put(skb, total_size);\r\noz_hdr->control = (OZ_PROTOCOL_VERSION<<OZ_VERSION_SHIFT) | OZ_F_ISOC;\r\noz_hdr->last_pkt_num = pd->trigger_pkt_num & OZ_LAST_PN_MASK;\r\nelt = (struct oz_elt *)(oz_hdr+1);\r\nfor (e = list.next; e != &list; e = e->next) {\r\nstruct oz_elt_info *ei;\r\nei = container_of(e, struct oz_elt_info, link);\r\nmemcpy(elt, ei->data, ei->length);\r\nelt = oz_next_elt(elt);\r\n}\r\noz_event_log(OZ_EVT_TX_ISOC, 0, 0, 0, 0);\r\ndev_queue_xmit(skb);\r\noz_elt_info_free_chain(&pd->elt_buff, &list);\r\nreturn 0;\r\n}\r\nvoid oz_retire_tx_frames(struct oz_pd *pd, u8 lpn)\r\n{\r\nstruct list_head *e;\r\nstruct oz_tx_frame *f;\r\nstruct list_head *first = 0;\r\nstruct list_head *last = 0;\r\nu8 diff;\r\nu32 pkt_num;\r\nspin_lock(&pd->tx_frame_lock);\r\ne = pd->tx_queue.next;\r\nwhile (e != &pd->tx_queue) {\r\nf = container_of(e, struct oz_tx_frame, link);\r\npkt_num = le32_to_cpu(get_unaligned(&f->hdr.pkt_num));\r\ndiff = (lpn - (pkt_num & OZ_LAST_PN_MASK)) & OZ_LAST_PN_MASK;\r\nif (diff > OZ_LAST_PN_HALF_CYCLE)\r\nbreak;\r\nif (first == 0)\r\nfirst = e;\r\nlast = e;\r\ne = e->next;\r\npd->nb_queued_frames--;\r\n}\r\nif (first) {\r\nlast->next->prev = &pd->tx_queue;\r\npd->tx_queue.next = last->next;\r\nlast->next = 0;\r\n}\r\npd->last_sent_frame = &pd->tx_queue;\r\nspin_unlock(&pd->tx_frame_lock);\r\nwhile (first) {\r\nf = container_of(first, struct oz_tx_frame, link);\r\nfirst = first->next;\r\noz_retire_frame(pd, f);\r\n}\r\n}\r\nstatic struct oz_isoc_stream *pd_stream_find(struct oz_pd *pd, u8 ep_num)\r\n{\r\nstruct list_head *e;\r\nstruct oz_isoc_stream *st;\r\nlist_for_each(e, &pd->stream_list) {\r\nst = container_of(e, struct oz_isoc_stream, link);\r\nif (st->ep_num == ep_num)\r\nreturn st;\r\n}\r\nreturn 0;\r\n}\r\nint oz_isoc_stream_create(struct oz_pd *pd, u8 ep_num)\r\n{\r\nstruct oz_isoc_stream *st =\r\nkzalloc(sizeof(struct oz_isoc_stream), GFP_ATOMIC);\r\nif (!st)\r\nreturn -ENOMEM;\r\nst->ep_num = ep_num;\r\nspin_lock_bh(&pd->stream_lock);\r\nif (!pd_stream_find(pd, ep_num)) {\r\nlist_add(&st->link, &pd->stream_list);\r\nst = 0;\r\n}\r\nspin_unlock_bh(&pd->stream_lock);\r\nif (st)\r\nkfree(st);\r\nreturn 0;\r\n}\r\nstatic void oz_isoc_stream_free(struct oz_isoc_stream *st)\r\n{\r\nif (st->skb)\r\nkfree_skb(st->skb);\r\nkfree(st);\r\n}\r\nint oz_isoc_stream_delete(struct oz_pd *pd, u8 ep_num)\r\n{\r\nstruct oz_isoc_stream *st;\r\nspin_lock_bh(&pd->stream_lock);\r\nst = pd_stream_find(pd, ep_num);\r\nif (st)\r\nlist_del(&st->link);\r\nspin_unlock_bh(&pd->stream_lock);\r\nif (st)\r\noz_isoc_stream_free(st);\r\nreturn 0;\r\n}\r\nstatic void oz_isoc_destructor(struct sk_buff *skb)\r\n{\r\natomic_dec(&g_submitted_isoc);\r\noz_event_log(OZ_EVT_TX_ISOC_DONE, atomic_read(&g_submitted_isoc),\r\n0, skb, 0);\r\n}\r\nint oz_send_isoc_unit(struct oz_pd *pd, u8 ep_num, u8 *data, int len)\r\n{\r\nstruct net_device *dev = pd->net_dev;\r\nstruct oz_isoc_stream *st;\r\nu8 nb_units = 0;\r\nstruct sk_buff *skb = 0;\r\nstruct oz_hdr *oz_hdr = 0;\r\nint size = 0;\r\nspin_lock_bh(&pd->stream_lock);\r\nst = pd_stream_find(pd, ep_num);\r\nif (st) {\r\nskb = st->skb;\r\nst->skb = 0;\r\nnb_units = st->nb_units;\r\nst->nb_units = 0;\r\noz_hdr = st->oz_hdr;\r\nsize = st->size;\r\n}\r\nspin_unlock_bh(&pd->stream_lock);\r\nif (!st)\r\nreturn 0;\r\nif (!skb) {\r\nskb = alloc_skb(pd->max_tx_size + OZ_ALLOCATED_SPACE(dev),\r\nGFP_ATOMIC);\r\nif (skb == 0)\r\nreturn 0;\r\nskb_reserve(skb, LL_RESERVED_SPACE(dev));\r\nskb_reset_network_header(skb);\r\nskb->dev = dev;\r\nskb->protocol = htons(OZ_ETHERTYPE);\r\nsize = sizeof(struct oz_hdr) + sizeof(struct oz_isoc_large);\r\noz_hdr = (struct oz_hdr *)skb_put(skb, size);\r\n}\r\nmemcpy(skb_put(skb, len), data, len);\r\nsize += len;\r\nif (++nb_units < pd->ms_per_isoc) {\r\nspin_lock_bh(&pd->stream_lock);\r\nst->skb = skb;\r\nst->nb_units = nb_units;\r\nst->oz_hdr = oz_hdr;\r\nst->size = size;\r\nspin_unlock_bh(&pd->stream_lock);\r\n} else {\r\nstruct oz_hdr oz;\r\nstruct oz_isoc_large iso;\r\nspin_lock_bh(&pd->stream_lock);\r\niso.frame_number = st->frame_num;\r\nst->frame_num += nb_units;\r\nspin_unlock_bh(&pd->stream_lock);\r\noz.control =\r\n(OZ_PROTOCOL_VERSION<<OZ_VERSION_SHIFT) | OZ_F_ISOC;\r\noz.last_pkt_num = pd->trigger_pkt_num & OZ_LAST_PN_MASK;\r\noz.pkt_num = 0;\r\niso.endpoint = ep_num;\r\niso.format = OZ_DATA_F_ISOC_LARGE;\r\niso.ms_data = nb_units;\r\nmemcpy(oz_hdr, &oz, sizeof(oz));\r\nmemcpy(oz_hdr+1, &iso, sizeof(iso));\r\nif (dev_hard_header(skb, dev, OZ_ETHERTYPE, pd->mac_addr,\r\ndev->dev_addr, skb->len) < 0) {\r\nkfree_skb(skb);\r\nreturn -1;\r\n}\r\nif (atomic_read(&g_submitted_isoc) < OZ_MAX_SUBMITTED_ISOC) {\r\nskb->destructor = oz_isoc_destructor;\r\natomic_inc(&g_submitted_isoc);\r\noz_event_log(OZ_EVT_TX_ISOC, nb_units, iso.frame_number,\r\nskb, atomic_read(&g_submitted_isoc));\r\nif (dev_queue_xmit(skb) < 0)\r\nreturn -1;\r\n} else {\r\noz_event_log(OZ_EVT_TX_ISOC_DROP, 0, 0, 0, 0);\r\nkfree_skb(skb);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nvoid oz_apps_init(void)\r\n{\r\nint i;\r\nfor (i = 0; i < OZ_APPID_MAX; i++)\r\nif (g_app_if[i].init)\r\ng_app_if[i].init();\r\n}\r\nvoid oz_apps_term(void)\r\n{\r\nint i;\r\nfor (i = 0; i < OZ_APPID_MAX; i++)\r\nif (g_app_if[i].term)\r\ng_app_if[i].term();\r\n}\r\nvoid oz_handle_app_elt(struct oz_pd *pd, u8 app_id, struct oz_elt *elt)\r\n{\r\nstruct oz_app_if *ai;\r\nif (app_id == 0 || app_id > OZ_APPID_MAX)\r\nreturn;\r\nai = &g_app_if[app_id-1];\r\nai->rx(pd, elt);\r\n}\r\nvoid oz_pd_indicate_farewells(struct oz_pd *pd)\r\n{\r\nstruct oz_farewell *f;\r\nstruct oz_app_if *ai = &g_app_if[OZ_APPID_USB-1];\r\nwhile (1) {\r\noz_polling_lock_bh();\r\nif (list_empty(&pd->farewell_list)) {\r\noz_polling_unlock_bh();\r\nbreak;\r\n}\r\nf = list_first_entry(&pd->farewell_list,\r\nstruct oz_farewell, link);\r\nlist_del(&f->link);\r\noz_polling_unlock_bh();\r\nif (ai->farewell)\r\nai->farewell(pd, f->ep_num, f->report, f->len);\r\nkfree(f);\r\n}\r\n}
