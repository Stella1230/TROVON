static struct bteinfo_s *bte_if_on_node(nasid_t nasid, int interface)\r\n{\r\nnodepda_t *tmp_nodepda;\r\nif (nasid_to_cnodeid(nasid) == -1)\r\nreturn (struct bteinfo_s *)NULL;\r\ntmp_nodepda = NODEPDA(nasid_to_cnodeid(nasid));\r\nreturn &tmp_nodepda->bte_if[interface];\r\n}\r\nstatic inline void bte_start_transfer(struct bteinfo_s *bte, u64 len, u64 mode)\r\n{\r\nif (is_shub2()) {\r\nBTE_CTRL_STORE(bte, (IBLS_BUSY | ((len) | (mode) << 24)));\r\n} else {\r\nBTE_LNSTAT_STORE(bte, len);\r\nBTE_CTRL_STORE(bte, mode);\r\n}\r\n}\r\nbte_result_t bte_copy(u64 src, u64 dest, u64 len, u64 mode, void *notification)\r\n{\r\nu64 transfer_size;\r\nu64 transfer_stat;\r\nu64 notif_phys_addr;\r\nstruct bteinfo_s *bte;\r\nbte_result_t bte_status;\r\nunsigned long irq_flags;\r\nunsigned long itc_end = 0;\r\nint nasid_to_try[MAX_NODES_TO_TRY];\r\nint my_nasid = cpuid_to_nasid(raw_smp_processor_id());\r\nint bte_if_index, nasid_index;\r\nint bte_first, btes_per_node = BTES_PER_NODE;\r\nBTE_PRINTK(("bte_copy(0x%lx, 0x%lx, 0x%lx, 0x%lx, 0x%p)\n",\r\nsrc, dest, len, mode, notification));\r\nif (len == 0) {\r\nreturn BTE_SUCCESS;\r\n}\r\nBUG_ON(len & L1_CACHE_MASK);\r\nBUG_ON(src & L1_CACHE_MASK);\r\nBUG_ON(dest & L1_CACHE_MASK);\r\nBUG_ON(len > BTE_MAX_XFER);\r\nbte_first = raw_smp_processor_id() % btes_per_node;\r\nif (mode & BTE_USE_DEST) {\r\nnasid_to_try[0] = NASID_GET(dest);\r\nif (mode & BTE_USE_ANY) {\r\nnasid_to_try[1] = my_nasid;\r\n} else {\r\nnasid_to_try[1] = (int)NULL;\r\n}\r\n} else {\r\nnasid_to_try[0] = my_nasid;\r\nif (mode & BTE_USE_ANY) {\r\nnasid_to_try[1] = NASID_GET(dest);\r\n} else {\r\nnasid_to_try[1] = (int)NULL;\r\n}\r\n}\r\nretry_bteop:\r\ndo {\r\nlocal_irq_save(irq_flags);\r\nbte_if_index = bte_first;\r\nnasid_index = 0;\r\nwhile (nasid_index < MAX_NODES_TO_TRY) {\r\nbte = bte_if_on_node(nasid_to_try[nasid_index],bte_if_index);\r\nif (bte == NULL) {\r\nnasid_index++;\r\ncontinue;\r\n}\r\nif (spin_trylock(&bte->spinlock)) {\r\nif (!(*bte->most_rcnt_na & BTE_WORD_AVAILABLE) ||\r\n(BTE_LNSTAT_LOAD(bte) & BTE_ACTIVE)) {\r\nspin_unlock(&bte->spinlock);\r\n} else {\r\nbreak;\r\n}\r\n}\r\nbte_if_index = (bte_if_index + 1) % btes_per_node;\r\nif (bte_if_index == bte_first) {\r\nnasid_index++;\r\n}\r\nbte = NULL;\r\n}\r\nif (bte != NULL) {\r\nbreak;\r\n}\r\nlocal_irq_restore(irq_flags);\r\nif (!(mode & BTE_WACQUIRE)) {\r\nreturn BTEFAIL_NOTAVAIL;\r\n}\r\n} while (1);\r\nif (notification == NULL) {\r\nbte->most_rcnt_na = &bte->notify;\r\n} else {\r\nbte->most_rcnt_na = notification;\r\n}\r\ntransfer_size = ((len >> L1_CACHE_SHIFT) & BTE_LEN_MASK);\r\n*bte->most_rcnt_na = BTE_WORD_BUSY;\r\nnotif_phys_addr = (u64)bte->most_rcnt_na;\r\nBTE_PRINTKV(("IBSA = 0x%lx)\n", src));\r\nBTE_SRC_STORE(bte, src);\r\nBTE_PRINTKV(("IBDA = 0x%lx)\n", dest));\r\nBTE_DEST_STORE(bte, dest);\r\nBTE_PRINTKV(("IBNA = 0x%lx)\n", notif_phys_addr));\r\nBTE_NOTIF_STORE(bte, notif_phys_addr);\r\nBTE_PRINTK(("IBCT = 0x%lx)\n", BTE_VALID_MODE(mode)));\r\nbte_start_transfer(bte, transfer_size, BTE_VALID_MODE(mode));\r\nitc_end = ia64_get_itc() + (40000000 * local_cpu_data->cyc_per_usec);\r\nspin_unlock_irqrestore(&bte->spinlock, irq_flags);\r\nif (notification != NULL) {\r\nreturn BTE_SUCCESS;\r\n}\r\nwhile ((transfer_stat = *bte->most_rcnt_na) == BTE_WORD_BUSY) {\r\ncpu_relax();\r\nif (ia64_get_itc() > itc_end) {\r\nBTE_PRINTK(("BTE timeout nasid 0x%x bte%d IBLS = 0x%lx na 0x%lx\n",\r\nNASID_GET(bte->bte_base_addr), bte->bte_num,\r\nBTE_LNSTAT_LOAD(bte), *bte->most_rcnt_na) );\r\nbte->bte_error_count++;\r\nbte->bh_error = IBLS_ERROR;\r\nbte_error_handler((unsigned long)NODEPDA(bte->bte_cnode));\r\n*bte->most_rcnt_na = BTE_WORD_AVAILABLE;\r\ngoto retry_bteop;\r\n}\r\n}\r\nBTE_PRINTKV((" Delay Done. IBLS = 0x%lx, most_rcnt_na = 0x%lx\n",\r\nBTE_LNSTAT_LOAD(bte), *bte->most_rcnt_na));\r\nif (transfer_stat & IBLS_ERROR) {\r\nbte_status = BTE_GET_ERROR_STATUS(transfer_stat);\r\n} else {\r\nbte_status = BTE_SUCCESS;\r\n}\r\n*bte->most_rcnt_na = BTE_WORD_AVAILABLE;\r\nBTE_PRINTK(("Returning status is 0x%lx and most_rcnt_na is 0x%lx\n",\r\nBTE_LNSTAT_LOAD(bte), *bte->most_rcnt_na));\r\nreturn bte_status;\r\n}\r\nbte_result_t bte_unaligned_copy(u64 src, u64 dest, u64 len, u64 mode)\r\n{\r\nint destFirstCacheOffset;\r\nu64 headBteSource;\r\nu64 headBteLen;\r\nu64 headBcopySrcOffset;\r\nu64 headBcopyDest;\r\nu64 headBcopyLen;\r\nu64 footBteSource;\r\nu64 footBteLen;\r\nu64 footBcopyDest;\r\nu64 footBcopyLen;\r\nbte_result_t rv;\r\nchar *bteBlock, *bteBlock_unaligned;\r\nif (len == 0) {\r\nreturn BTE_SUCCESS;\r\n}\r\nbteBlock_unaligned = kmalloc(len + 3 * L1_CACHE_BYTES, GFP_KERNEL);\r\nif (bteBlock_unaligned == NULL) {\r\nreturn BTEFAIL_NOTAVAIL;\r\n}\r\nbteBlock = (char *)L1_CACHE_ALIGN((u64) bteBlock_unaligned);\r\nheadBcopySrcOffset = src & L1_CACHE_MASK;\r\ndestFirstCacheOffset = dest & L1_CACHE_MASK;\r\nif (headBcopySrcOffset == destFirstCacheOffset) {\r\nheadBteSource = src & ~L1_CACHE_MASK;\r\nheadBcopyDest = dest;\r\nif (headBcopySrcOffset) {\r\nheadBcopyLen =\r\n(len >\r\n(L1_CACHE_BYTES -\r\nheadBcopySrcOffset) ? L1_CACHE_BYTES\r\n- headBcopySrcOffset : len);\r\nheadBteLen = L1_CACHE_BYTES;\r\n} else {\r\nheadBcopyLen = 0;\r\nheadBteLen = 0;\r\n}\r\nif (len > headBcopyLen) {\r\nfootBcopyLen = (len - headBcopyLen) & L1_CACHE_MASK;\r\nfootBteLen = L1_CACHE_BYTES;\r\nfootBteSource = src + len - footBcopyLen;\r\nfootBcopyDest = dest + len - footBcopyLen;\r\nif (footBcopyDest == (headBcopyDest + headBcopyLen)) {\r\nheadBcopyLen += footBcopyLen;\r\nheadBteLen += footBteLen;\r\n} else if (footBcopyLen > 0) {\r\nrv = bte_copy(footBteSource,\r\nia64_tpa((unsigned long)bteBlock),\r\nfootBteLen, mode, NULL);\r\nif (rv != BTE_SUCCESS) {\r\nkfree(bteBlock_unaligned);\r\nreturn rv;\r\n}\r\nmemcpy(__va(footBcopyDest),\r\n(char *)bteBlock, footBcopyLen);\r\n}\r\n} else {\r\nfootBcopyLen = 0;\r\nfootBteLen = 0;\r\n}\r\nif (len > (headBcopyLen + footBcopyLen)) {\r\nrv = bte_copy((src + headBcopyLen),\r\n(dest +\r\nheadBcopyLen),\r\n(len - headBcopyLen -\r\nfootBcopyLen), mode, NULL);\r\nif (rv != BTE_SUCCESS) {\r\nkfree(bteBlock_unaligned);\r\nreturn rv;\r\n}\r\n}\r\n} else {\r\nheadBcopySrcOffset = src & L1_CACHE_MASK;\r\nheadBcopyDest = dest;\r\nheadBcopyLen = len;\r\nheadBteSource = src - headBcopySrcOffset;\r\nheadBteLen = L1_CACHE_ALIGN(len + headBcopySrcOffset);\r\n}\r\nif (headBcopyLen > 0) {\r\nrv = bte_copy(headBteSource,\r\nia64_tpa((unsigned long)bteBlock), headBteLen,\r\nmode, NULL);\r\nif (rv != BTE_SUCCESS) {\r\nkfree(bteBlock_unaligned);\r\nreturn rv;\r\n}\r\nmemcpy(__va(headBcopyDest), ((char *)bteBlock +\r\nheadBcopySrcOffset), headBcopyLen);\r\n}\r\nkfree(bteBlock_unaligned);\r\nreturn BTE_SUCCESS;\r\n}\r\nvoid bte_init_node(nodepda_t * mynodepda, cnodeid_t cnode)\r\n{\r\nint i;\r\nspin_lock_init(&mynodepda->bte_recovery_lock);\r\ninit_timer(&mynodepda->bte_recovery_timer);\r\nmynodepda->bte_recovery_timer.function = bte_error_handler;\r\nmynodepda->bte_recovery_timer.data = (unsigned long)mynodepda;\r\nfor (i = 0; i < BTES_PER_NODE; i++) {\r\nu64 *base_addr;\r\nbase_addr = (u64 *)\r\nREMOTE_HUB_ADDR(cnodeid_to_nasid(cnode), BTE_BASE_ADDR(i));\r\nmynodepda->bte_if[i].bte_base_addr = base_addr;\r\nmynodepda->bte_if[i].bte_source_addr = BTE_SOURCE_ADDR(base_addr);\r\nmynodepda->bte_if[i].bte_destination_addr = BTE_DEST_ADDR(base_addr);\r\nmynodepda->bte_if[i].bte_control_addr = BTE_CTRL_ADDR(base_addr);\r\nmynodepda->bte_if[i].bte_notify_addr = BTE_NOTIF_ADDR(base_addr);\r\nmynodepda->bte_if[i].most_rcnt_na =\r\n&(mynodepda->bte_if[i].notify);\r\nmynodepda->bte_if[i].notify = BTE_WORD_AVAILABLE;\r\nspin_lock_init(&mynodepda->bte_if[i].spinlock);\r\nmynodepda->bte_if[i].bte_cnode = cnode;\r\nmynodepda->bte_if[i].bte_error_count = 0;\r\nmynodepda->bte_if[i].bte_num = i;\r\nmynodepda->bte_if[i].cleanup_active = 0;\r\nmynodepda->bte_if[i].bh_error = 0;\r\n}\r\n}
