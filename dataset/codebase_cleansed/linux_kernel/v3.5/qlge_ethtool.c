static int ql_update_ring_coalescing(struct ql_adapter *qdev)\r\n{\r\nint i, status = 0;\r\nstruct rx_ring *rx_ring;\r\nstruct cqicb *cqicb;\r\nif (!netif_running(qdev->ndev))\r\nreturn status;\r\ncqicb = (struct cqicb *)&qdev->rx_ring[qdev->rss_ring_count];\r\nif (le16_to_cpu(cqicb->irq_delay) != qdev->tx_coalesce_usecs ||\r\nle16_to_cpu(cqicb->pkt_delay) !=\r\nqdev->tx_max_coalesced_frames) {\r\nfor (i = qdev->rss_ring_count; i < qdev->rx_ring_count; i++) {\r\nrx_ring = &qdev->rx_ring[i];\r\ncqicb = (struct cqicb *)rx_ring;\r\ncqicb->irq_delay = cpu_to_le16(qdev->tx_coalesce_usecs);\r\ncqicb->pkt_delay =\r\ncpu_to_le16(qdev->tx_max_coalesced_frames);\r\ncqicb->flags = FLAGS_LI;\r\nstatus = ql_write_cfg(qdev, cqicb, sizeof(*cqicb),\r\nCFG_LCQ, rx_ring->cq_id);\r\nif (status) {\r\nnetif_err(qdev, ifup, qdev->ndev,\r\n"Failed to load CQICB.\n");\r\ngoto exit;\r\n}\r\n}\r\n}\r\ncqicb = (struct cqicb *)&qdev->rx_ring[0];\r\nif (le16_to_cpu(cqicb->irq_delay) != qdev->rx_coalesce_usecs ||\r\nle16_to_cpu(cqicb->pkt_delay) !=\r\nqdev->rx_max_coalesced_frames) {\r\nfor (i = 0; i < qdev->rss_ring_count; i++, rx_ring++) {\r\nrx_ring = &qdev->rx_ring[i];\r\ncqicb = (struct cqicb *)rx_ring;\r\ncqicb->irq_delay = cpu_to_le16(qdev->rx_coalesce_usecs);\r\ncqicb->pkt_delay =\r\ncpu_to_le16(qdev->rx_max_coalesced_frames);\r\ncqicb->flags = FLAGS_LI;\r\nstatus = ql_write_cfg(qdev, cqicb, sizeof(*cqicb),\r\nCFG_LCQ, rx_ring->cq_id);\r\nif (status) {\r\nnetif_err(qdev, ifup, qdev->ndev,\r\n"Failed to load CQICB.\n");\r\ngoto exit;\r\n}\r\n}\r\n}\r\nexit:\r\nreturn status;\r\n}\r\nstatic void ql_update_stats(struct ql_adapter *qdev)\r\n{\r\nu32 i;\r\nu64 data;\r\nu64 *iter = &qdev->nic_stats.tx_pkts;\r\nspin_lock(&qdev->stats_lock);\r\nif (ql_sem_spinlock(qdev, qdev->xg_sem_mask)) {\r\nnetif_err(qdev, drv, qdev->ndev,\r\n"Couldn't get xgmac sem.\n");\r\ngoto quit;\r\n}\r\nfor (i = 0x200; i < 0x280; i += 8) {\r\nif (ql_read_xgmac_reg64(qdev, i, &data)) {\r\nnetif_err(qdev, drv, qdev->ndev,\r\n"Error reading status register 0x%.04x.\n",\r\ni);\r\ngoto end;\r\n} else\r\n*iter = data;\r\niter++;\r\n}\r\nfor (i = 0x300; i < 0x3d0; i += 8) {\r\nif (ql_read_xgmac_reg64(qdev, i, &data)) {\r\nnetif_err(qdev, drv, qdev->ndev,\r\n"Error reading status register 0x%.04x.\n",\r\ni);\r\ngoto end;\r\n} else\r\n*iter = data;\r\niter++;\r\n}\r\nfor (i = 0x500; i < 0x540; i += 8) {\r\nif (ql_read_xgmac_reg64(qdev, i, &data)) {\r\nnetif_err(qdev, drv, qdev->ndev,\r\n"Error reading status register 0x%.04x.\n",\r\ni);\r\ngoto end;\r\n} else\r\n*iter = data;\r\niter++;\r\n}\r\nfor (i = 0x568; i < 0x5a8; i += 8) {\r\nif (ql_read_xgmac_reg64(qdev, i, &data)) {\r\nnetif_err(qdev, drv, qdev->ndev,\r\n"Error reading status register 0x%.04x.\n",\r\ni);\r\ngoto end;\r\n} else\r\n*iter = data;\r\niter++;\r\n}\r\nif (ql_read_xgmac_reg64(qdev, 0x5b8, &data)) {\r\nnetif_err(qdev, drv, qdev->ndev,\r\n"Error reading status register 0x%.04x.\n", i);\r\ngoto end;\r\n} else\r\n*iter = data;\r\nend:\r\nql_sem_unlock(qdev, qdev->xg_sem_mask);\r\nquit:\r\nspin_unlock(&qdev->stats_lock);\r\nQL_DUMP_STAT(qdev);\r\n}\r\nstatic void ql_get_strings(struct net_device *dev, u32 stringset, u8 *buf)\r\n{\r\nswitch (stringset) {\r\ncase ETH_SS_STATS:\r\nmemcpy(buf, ql_stats_str_arr, sizeof(ql_stats_str_arr));\r\nbreak;\r\n}\r\n}\r\nstatic int ql_get_sset_count(struct net_device *dev, int sset)\r\n{\r\nswitch (sset) {\r\ncase ETH_SS_TEST:\r\nreturn QLGE_TEST_LEN;\r\ncase ETH_SS_STATS:\r\nreturn ARRAY_SIZE(ql_stats_str_arr);\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nstatic void\r\nql_get_ethtool_stats(struct net_device *ndev,\r\nstruct ethtool_stats *stats, u64 *data)\r\n{\r\nstruct ql_adapter *qdev = netdev_priv(ndev);\r\nstruct nic_stats *s = &qdev->nic_stats;\r\nql_update_stats(qdev);\r\n*data++ = s->tx_pkts;\r\n*data++ = s->tx_bytes;\r\n*data++ = s->tx_mcast_pkts;\r\n*data++ = s->tx_bcast_pkts;\r\n*data++ = s->tx_ucast_pkts;\r\n*data++ = s->tx_ctl_pkts;\r\n*data++ = s->tx_pause_pkts;\r\n*data++ = s->tx_64_pkt;\r\n*data++ = s->tx_65_to_127_pkt;\r\n*data++ = s->tx_128_to_255_pkt;\r\n*data++ = s->tx_256_511_pkt;\r\n*data++ = s->tx_512_to_1023_pkt;\r\n*data++ = s->tx_1024_to_1518_pkt;\r\n*data++ = s->tx_1519_to_max_pkt;\r\n*data++ = s->tx_undersize_pkt;\r\n*data++ = s->tx_oversize_pkt;\r\n*data++ = s->rx_bytes;\r\n*data++ = s->rx_bytes_ok;\r\n*data++ = s->rx_pkts;\r\n*data++ = s->rx_pkts_ok;\r\n*data++ = s->rx_bcast_pkts;\r\n*data++ = s->rx_mcast_pkts;\r\n*data++ = s->rx_ucast_pkts;\r\n*data++ = s->rx_undersize_pkts;\r\n*data++ = s->rx_oversize_pkts;\r\n*data++ = s->rx_jabber_pkts;\r\n*data++ = s->rx_undersize_fcerr_pkts;\r\n*data++ = s->rx_drop_events;\r\n*data++ = s->rx_fcerr_pkts;\r\n*data++ = s->rx_align_err;\r\n*data++ = s->rx_symbol_err;\r\n*data++ = s->rx_mac_err;\r\n*data++ = s->rx_ctl_pkts;\r\n*data++ = s->rx_pause_pkts;\r\n*data++ = s->rx_64_pkts;\r\n*data++ = s->rx_65_to_127_pkts;\r\n*data++ = s->rx_128_255_pkts;\r\n*data++ = s->rx_256_511_pkts;\r\n*data++ = s->rx_512_to_1023_pkts;\r\n*data++ = s->rx_1024_to_1518_pkts;\r\n*data++ = s->rx_1519_to_max_pkts;\r\n*data++ = s->rx_len_err_pkts;\r\n*data++ = s->tx_cbfc_pause_frames0;\r\n*data++ = s->tx_cbfc_pause_frames1;\r\n*data++ = s->tx_cbfc_pause_frames2;\r\n*data++ = s->tx_cbfc_pause_frames3;\r\n*data++ = s->tx_cbfc_pause_frames4;\r\n*data++ = s->tx_cbfc_pause_frames5;\r\n*data++ = s->tx_cbfc_pause_frames6;\r\n*data++ = s->tx_cbfc_pause_frames7;\r\n*data++ = s->rx_cbfc_pause_frames0;\r\n*data++ = s->rx_cbfc_pause_frames1;\r\n*data++ = s->rx_cbfc_pause_frames2;\r\n*data++ = s->rx_cbfc_pause_frames3;\r\n*data++ = s->rx_cbfc_pause_frames4;\r\n*data++ = s->rx_cbfc_pause_frames5;\r\n*data++ = s->rx_cbfc_pause_frames6;\r\n*data++ = s->rx_cbfc_pause_frames7;\r\n*data++ = s->rx_nic_fifo_drop;\r\n}\r\nstatic int ql_get_settings(struct net_device *ndev,\r\nstruct ethtool_cmd *ecmd)\r\n{\r\nstruct ql_adapter *qdev = netdev_priv(ndev);\r\necmd->supported = SUPPORTED_10000baseT_Full;\r\necmd->advertising = ADVERTISED_10000baseT_Full;\r\necmd->autoneg = AUTONEG_ENABLE;\r\necmd->transceiver = XCVR_EXTERNAL;\r\nif ((qdev->link_status & STS_LINK_TYPE_MASK) ==\r\nSTS_LINK_TYPE_10GBASET) {\r\necmd->supported |= (SUPPORTED_TP | SUPPORTED_Autoneg);\r\necmd->advertising |= (ADVERTISED_TP | ADVERTISED_Autoneg);\r\necmd->port = PORT_TP;\r\n} else {\r\necmd->supported |= SUPPORTED_FIBRE;\r\necmd->advertising |= ADVERTISED_FIBRE;\r\necmd->port = PORT_FIBRE;\r\n}\r\nethtool_cmd_speed_set(ecmd, SPEED_10000);\r\necmd->duplex = DUPLEX_FULL;\r\nreturn 0;\r\n}\r\nstatic void ql_get_drvinfo(struct net_device *ndev,\r\nstruct ethtool_drvinfo *drvinfo)\r\n{\r\nstruct ql_adapter *qdev = netdev_priv(ndev);\r\nstrlcpy(drvinfo->driver, qlge_driver_name, sizeof(drvinfo->driver));\r\nstrlcpy(drvinfo->version, qlge_driver_version,\r\nsizeof(drvinfo->version));\r\nsnprintf(drvinfo->fw_version, sizeof(drvinfo->fw_version),\r\n"v%d.%d.%d",\r\n(qdev->fw_rev_id & 0x00ff0000) >> 16,\r\n(qdev->fw_rev_id & 0x0000ff00) >> 8,\r\n(qdev->fw_rev_id & 0x000000ff));\r\nstrlcpy(drvinfo->bus_info, pci_name(qdev->pdev),\r\nsizeof(drvinfo->bus_info));\r\ndrvinfo->n_stats = 0;\r\ndrvinfo->testinfo_len = 0;\r\nif (!test_bit(QL_FRC_COREDUMP, &qdev->flags))\r\ndrvinfo->regdump_len = sizeof(struct ql_mpi_coredump);\r\nelse\r\ndrvinfo->regdump_len = sizeof(struct ql_reg_dump);\r\ndrvinfo->eedump_len = 0;\r\n}\r\nstatic void ql_get_wol(struct net_device *ndev, struct ethtool_wolinfo *wol)\r\n{\r\nstruct ql_adapter *qdev = netdev_priv(ndev);\r\nwol->supported = WAKE_MAGIC;\r\nwol->wolopts = qdev->wol;\r\n}\r\nstatic int ql_set_wol(struct net_device *ndev, struct ethtool_wolinfo *wol)\r\n{\r\nstruct ql_adapter *qdev = netdev_priv(ndev);\r\nint status;\r\nif (wol->wolopts & ~WAKE_MAGIC)\r\nreturn -EINVAL;\r\nqdev->wol = wol->wolopts;\r\nnetif_info(qdev, drv, qdev->ndev, "Set wol option 0x%x\n", qdev->wol);\r\nif (!qdev->wol) {\r\nu32 wol = 0;\r\nstatus = ql_mb_wol_mode(qdev, wol);\r\nnetif_err(qdev, drv, qdev->ndev, "WOL %s (wol code 0x%x)\n",\r\nstatus == 0 ? "cleared successfully" : "clear failed",\r\nwol);\r\n}\r\nreturn 0;\r\n}\r\nstatic int ql_set_phys_id(struct net_device *ndev,\r\nenum ethtool_phys_id_state state)\r\n{\r\nstruct ql_adapter *qdev = netdev_priv(ndev);\r\nswitch (state) {\r\ncase ETHTOOL_ID_ACTIVE:\r\nif (ql_mb_get_led_cfg(qdev))\r\nreturn -EIO;\r\nql_mb_set_led_cfg(qdev, QL_LED_BLINK);\r\nreturn 0;\r\ncase ETHTOOL_ID_INACTIVE:\r\nif (ql_mb_set_led_cfg(qdev, qdev->led_config))\r\nreturn -EIO;\r\nreturn 0;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n}\r\nstatic int ql_start_loopback(struct ql_adapter *qdev)\r\n{\r\nif (netif_carrier_ok(qdev->ndev)) {\r\nset_bit(QL_LB_LINK_UP, &qdev->flags);\r\nnetif_carrier_off(qdev->ndev);\r\n} else\r\nclear_bit(QL_LB_LINK_UP, &qdev->flags);\r\nqdev->link_config |= CFG_LOOPBACK_PCS;\r\nreturn ql_mb_set_port_cfg(qdev);\r\n}\r\nstatic void ql_stop_loopback(struct ql_adapter *qdev)\r\n{\r\nqdev->link_config &= ~CFG_LOOPBACK_PCS;\r\nql_mb_set_port_cfg(qdev);\r\nif (test_bit(QL_LB_LINK_UP, &qdev->flags)) {\r\nnetif_carrier_on(qdev->ndev);\r\nclear_bit(QL_LB_LINK_UP, &qdev->flags);\r\n}\r\n}\r\nstatic void ql_create_lb_frame(struct sk_buff *skb,\r\nunsigned int frame_size)\r\n{\r\nmemset(skb->data, 0xFF, frame_size);\r\nframe_size &= ~1;\r\nmemset(&skb->data[frame_size / 2], 0xAA, frame_size / 2 - 1);\r\nmemset(&skb->data[frame_size / 2 + 10], 0xBE, 1);\r\nmemset(&skb->data[frame_size / 2 + 12], 0xAF, 1);\r\n}\r\nvoid ql_check_lb_frame(struct ql_adapter *qdev,\r\nstruct sk_buff *skb)\r\n{\r\nunsigned int frame_size = skb->len;\r\nif ((*(skb->data + 3) == 0xFF) &&\r\n(*(skb->data + frame_size / 2 + 10) == 0xBE) &&\r\n(*(skb->data + frame_size / 2 + 12) == 0xAF)) {\r\natomic_dec(&qdev->lb_count);\r\nreturn;\r\n}\r\n}\r\nstatic int ql_run_loopback_test(struct ql_adapter *qdev)\r\n{\r\nint i;\r\nnetdev_tx_t rc;\r\nstruct sk_buff *skb;\r\nunsigned int size = SMALL_BUF_MAP_SIZE;\r\nfor (i = 0; i < 64; i++) {\r\nskb = netdev_alloc_skb(qdev->ndev, size);\r\nif (!skb)\r\nreturn -ENOMEM;\r\nskb->queue_mapping = 0;\r\nskb_put(skb, size);\r\nql_create_lb_frame(skb, size);\r\nrc = ql_lb_send(skb, qdev->ndev);\r\nif (rc != NETDEV_TX_OK)\r\nreturn -EPIPE;\r\natomic_inc(&qdev->lb_count);\r\n}\r\nmsleep(2);\r\nql_clean_lb_rx_ring(&qdev->rx_ring[0], 128);\r\nreturn atomic_read(&qdev->lb_count) ? -EIO : 0;\r\n}\r\nstatic int ql_loopback_test(struct ql_adapter *qdev, u64 *data)\r\n{\r\n*data = ql_start_loopback(qdev);\r\nif (*data)\r\ngoto out;\r\n*data = ql_run_loopback_test(qdev);\r\nout:\r\nql_stop_loopback(qdev);\r\nreturn *data;\r\n}\r\nstatic void ql_self_test(struct net_device *ndev,\r\nstruct ethtool_test *eth_test, u64 *data)\r\n{\r\nstruct ql_adapter *qdev = netdev_priv(ndev);\r\nif (netif_running(ndev)) {\r\nset_bit(QL_SELFTEST, &qdev->flags);\r\nif (eth_test->flags == ETH_TEST_FL_OFFLINE) {\r\nif (ql_loopback_test(qdev, &data[0]))\r\neth_test->flags |= ETH_TEST_FL_FAILED;\r\n} else {\r\ndata[0] = 0;\r\n}\r\nclear_bit(QL_SELFTEST, &qdev->flags);\r\nmsleep_interruptible(4 * 1000);\r\n} else {\r\nnetif_err(qdev, drv, qdev->ndev,\r\n"is down, Loopback test will fail.\n");\r\neth_test->flags |= ETH_TEST_FL_FAILED;\r\n}\r\n}\r\nstatic int ql_get_regs_len(struct net_device *ndev)\r\n{\r\nstruct ql_adapter *qdev = netdev_priv(ndev);\r\nif (!test_bit(QL_FRC_COREDUMP, &qdev->flags))\r\nreturn sizeof(struct ql_mpi_coredump);\r\nelse\r\nreturn sizeof(struct ql_reg_dump);\r\n}\r\nstatic void ql_get_regs(struct net_device *ndev,\r\nstruct ethtool_regs *regs, void *p)\r\n{\r\nstruct ql_adapter *qdev = netdev_priv(ndev);\r\nql_get_dump(qdev, p);\r\nqdev->core_is_dumped = 0;\r\nif (!test_bit(QL_FRC_COREDUMP, &qdev->flags))\r\nregs->len = sizeof(struct ql_mpi_coredump);\r\nelse\r\nregs->len = sizeof(struct ql_reg_dump);\r\n}\r\nstatic int ql_get_coalesce(struct net_device *dev, struct ethtool_coalesce *c)\r\n{\r\nstruct ql_adapter *qdev = netdev_priv(dev);\r\nc->rx_coalesce_usecs = qdev->rx_coalesce_usecs;\r\nc->tx_coalesce_usecs = qdev->tx_coalesce_usecs;\r\nc->rx_max_coalesced_frames = qdev->rx_max_coalesced_frames;\r\nc->tx_max_coalesced_frames = qdev->tx_max_coalesced_frames;\r\nreturn 0;\r\n}\r\nstatic int ql_set_coalesce(struct net_device *ndev, struct ethtool_coalesce *c)\r\n{\r\nstruct ql_adapter *qdev = netdev_priv(ndev);\r\nif (c->rx_coalesce_usecs > qdev->rx_ring_size / 2)\r\nreturn -EINVAL;\r\nif (c->rx_max_coalesced_frames > MAX_INTER_FRAME_WAIT)\r\nreturn -EINVAL;\r\nif (c->tx_coalesce_usecs > qdev->tx_ring_size / 2)\r\nreturn -EINVAL;\r\nif (c->tx_max_coalesced_frames > MAX_INTER_FRAME_WAIT)\r\nreturn -EINVAL;\r\nif (qdev->rx_coalesce_usecs == c->rx_coalesce_usecs &&\r\nqdev->tx_coalesce_usecs == c->tx_coalesce_usecs &&\r\nqdev->rx_max_coalesced_frames == c->rx_max_coalesced_frames &&\r\nqdev->tx_max_coalesced_frames == c->tx_max_coalesced_frames)\r\nreturn 0;\r\nqdev->rx_coalesce_usecs = c->rx_coalesce_usecs;\r\nqdev->tx_coalesce_usecs = c->tx_coalesce_usecs;\r\nqdev->rx_max_coalesced_frames = c->rx_max_coalesced_frames;\r\nqdev->tx_max_coalesced_frames = c->tx_max_coalesced_frames;\r\nreturn ql_update_ring_coalescing(qdev);\r\n}\r\nstatic void ql_get_pauseparam(struct net_device *netdev,\r\nstruct ethtool_pauseparam *pause)\r\n{\r\nstruct ql_adapter *qdev = netdev_priv(netdev);\r\nql_mb_get_port_cfg(qdev);\r\nif (qdev->link_config & CFG_PAUSE_STD) {\r\npause->rx_pause = 1;\r\npause->tx_pause = 1;\r\n}\r\n}\r\nstatic int ql_set_pauseparam(struct net_device *netdev,\r\nstruct ethtool_pauseparam *pause)\r\n{\r\nstruct ql_adapter *qdev = netdev_priv(netdev);\r\nint status = 0;\r\nif ((pause->rx_pause) && (pause->tx_pause))\r\nqdev->link_config |= CFG_PAUSE_STD;\r\nelse if (!pause->rx_pause && !pause->tx_pause)\r\nqdev->link_config &= ~CFG_PAUSE_STD;\r\nelse\r\nreturn -EINVAL;\r\nstatus = ql_mb_set_port_cfg(qdev);\r\nreturn status;\r\n}\r\nstatic u32 ql_get_msglevel(struct net_device *ndev)\r\n{\r\nstruct ql_adapter *qdev = netdev_priv(ndev);\r\nreturn qdev->msg_enable;\r\n}\r\nstatic void ql_set_msglevel(struct net_device *ndev, u32 value)\r\n{\r\nstruct ql_adapter *qdev = netdev_priv(ndev);\r\nqdev->msg_enable = value;\r\n}
