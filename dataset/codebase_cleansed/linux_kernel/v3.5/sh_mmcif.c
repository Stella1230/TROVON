static inline void sh_mmcif_bitset(struct sh_mmcif_host *host,\r\nunsigned int reg, u32 val)\r\n{\r\nwritel(val | readl(host->addr + reg), host->addr + reg);\r\n}\r\nstatic inline void sh_mmcif_bitclr(struct sh_mmcif_host *host,\r\nunsigned int reg, u32 val)\r\n{\r\nwritel(~val & readl(host->addr + reg), host->addr + reg);\r\n}\r\nstatic void mmcif_dma_complete(void *arg)\r\n{\r\nstruct sh_mmcif_host *host = arg;\r\nstruct mmc_data *data = host->mrq->data;\r\ndev_dbg(&host->pd->dev, "Command completed\n");\r\nif (WARN(!data, "%s: NULL data in DMA completion!\n",\r\ndev_name(&host->pd->dev)))\r\nreturn;\r\nif (data->flags & MMC_DATA_READ)\r\ndma_unmap_sg(host->chan_rx->device->dev,\r\ndata->sg, data->sg_len,\r\nDMA_FROM_DEVICE);\r\nelse\r\ndma_unmap_sg(host->chan_tx->device->dev,\r\ndata->sg, data->sg_len,\r\nDMA_TO_DEVICE);\r\ncomplete(&host->dma_complete);\r\n}\r\nstatic void sh_mmcif_start_dma_rx(struct sh_mmcif_host *host)\r\n{\r\nstruct mmc_data *data = host->mrq->data;\r\nstruct scatterlist *sg = data->sg;\r\nstruct dma_async_tx_descriptor *desc = NULL;\r\nstruct dma_chan *chan = host->chan_rx;\r\ndma_cookie_t cookie = -EINVAL;\r\nint ret;\r\nret = dma_map_sg(chan->device->dev, sg, data->sg_len,\r\nDMA_FROM_DEVICE);\r\nif (ret > 0) {\r\nhost->dma_active = true;\r\ndesc = dmaengine_prep_slave_sg(chan, sg, ret,\r\nDMA_DEV_TO_MEM, DMA_PREP_INTERRUPT | DMA_CTRL_ACK);\r\n}\r\nif (desc) {\r\ndesc->callback = mmcif_dma_complete;\r\ndesc->callback_param = host;\r\ncookie = dmaengine_submit(desc);\r\nsh_mmcif_bitset(host, MMCIF_CE_BUF_ACC, BUF_ACC_DMAREN);\r\ndma_async_issue_pending(chan);\r\n}\r\ndev_dbg(&host->pd->dev, "%s(): mapped %d -> %d, cookie %d\n",\r\n__func__, data->sg_len, ret, cookie);\r\nif (!desc) {\r\nif (ret >= 0)\r\nret = -EIO;\r\nhost->chan_rx = NULL;\r\nhost->dma_active = false;\r\ndma_release_channel(chan);\r\nchan = host->chan_tx;\r\nif (chan) {\r\nhost->chan_tx = NULL;\r\ndma_release_channel(chan);\r\n}\r\ndev_warn(&host->pd->dev,\r\n"DMA failed: %d, falling back to PIO\n", ret);\r\nsh_mmcif_bitclr(host, MMCIF_CE_BUF_ACC, BUF_ACC_DMAREN | BUF_ACC_DMAWEN);\r\n}\r\ndev_dbg(&host->pd->dev, "%s(): desc %p, cookie %d, sg[%d]\n", __func__,\r\ndesc, cookie, data->sg_len);\r\n}\r\nstatic void sh_mmcif_start_dma_tx(struct sh_mmcif_host *host)\r\n{\r\nstruct mmc_data *data = host->mrq->data;\r\nstruct scatterlist *sg = data->sg;\r\nstruct dma_async_tx_descriptor *desc = NULL;\r\nstruct dma_chan *chan = host->chan_tx;\r\ndma_cookie_t cookie = -EINVAL;\r\nint ret;\r\nret = dma_map_sg(chan->device->dev, sg, data->sg_len,\r\nDMA_TO_DEVICE);\r\nif (ret > 0) {\r\nhost->dma_active = true;\r\ndesc = dmaengine_prep_slave_sg(chan, sg, ret,\r\nDMA_MEM_TO_DEV, DMA_PREP_INTERRUPT | DMA_CTRL_ACK);\r\n}\r\nif (desc) {\r\ndesc->callback = mmcif_dma_complete;\r\ndesc->callback_param = host;\r\ncookie = dmaengine_submit(desc);\r\nsh_mmcif_bitset(host, MMCIF_CE_BUF_ACC, BUF_ACC_DMAWEN);\r\ndma_async_issue_pending(chan);\r\n}\r\ndev_dbg(&host->pd->dev, "%s(): mapped %d -> %d, cookie %d\n",\r\n__func__, data->sg_len, ret, cookie);\r\nif (!desc) {\r\nif (ret >= 0)\r\nret = -EIO;\r\nhost->chan_tx = NULL;\r\nhost->dma_active = false;\r\ndma_release_channel(chan);\r\nchan = host->chan_rx;\r\nif (chan) {\r\nhost->chan_rx = NULL;\r\ndma_release_channel(chan);\r\n}\r\ndev_warn(&host->pd->dev,\r\n"DMA failed: %d, falling back to PIO\n", ret);\r\nsh_mmcif_bitclr(host, MMCIF_CE_BUF_ACC, BUF_ACC_DMAREN | BUF_ACC_DMAWEN);\r\n}\r\ndev_dbg(&host->pd->dev, "%s(): desc %p, cookie %d\n", __func__,\r\ndesc, cookie);\r\n}\r\nstatic bool sh_mmcif_filter(struct dma_chan *chan, void *arg)\r\n{\r\ndev_dbg(chan->device->dev, "%s: slave data %p\n", __func__, arg);\r\nchan->private = arg;\r\nreturn true;\r\n}\r\nstatic void sh_mmcif_request_dma(struct sh_mmcif_host *host,\r\nstruct sh_mmcif_plat_data *pdata)\r\n{\r\nstruct sh_dmae_slave *tx, *rx;\r\nhost->dma_active = false;\r\nif (pdata->dma) {\r\ndev_warn(&host->pd->dev,\r\n"Update your platform to use embedded DMA slave IDs\n");\r\ntx = &pdata->dma->chan_priv_tx;\r\nrx = &pdata->dma->chan_priv_rx;\r\n} else {\r\ntx = &host->dma_slave_tx;\r\ntx->slave_id = pdata->slave_id_tx;\r\nrx = &host->dma_slave_rx;\r\nrx->slave_id = pdata->slave_id_rx;\r\n}\r\nif (tx->slave_id > 0 && rx->slave_id > 0) {\r\ndma_cap_mask_t mask;\r\ndma_cap_zero(mask);\r\ndma_cap_set(DMA_SLAVE, mask);\r\nhost->chan_tx = dma_request_channel(mask, sh_mmcif_filter, tx);\r\ndev_dbg(&host->pd->dev, "%s: TX: got channel %p\n", __func__,\r\nhost->chan_tx);\r\nif (!host->chan_tx)\r\nreturn;\r\nhost->chan_rx = dma_request_channel(mask, sh_mmcif_filter, rx);\r\ndev_dbg(&host->pd->dev, "%s: RX: got channel %p\n", __func__,\r\nhost->chan_rx);\r\nif (!host->chan_rx) {\r\ndma_release_channel(host->chan_tx);\r\nhost->chan_tx = NULL;\r\nreturn;\r\n}\r\ninit_completion(&host->dma_complete);\r\n}\r\n}\r\nstatic void sh_mmcif_release_dma(struct sh_mmcif_host *host)\r\n{\r\nsh_mmcif_bitclr(host, MMCIF_CE_BUF_ACC, BUF_ACC_DMAREN | BUF_ACC_DMAWEN);\r\nif (host->chan_tx) {\r\nstruct dma_chan *chan = host->chan_tx;\r\nhost->chan_tx = NULL;\r\ndma_release_channel(chan);\r\n}\r\nif (host->chan_rx) {\r\nstruct dma_chan *chan = host->chan_rx;\r\nhost->chan_rx = NULL;\r\ndma_release_channel(chan);\r\n}\r\nhost->dma_active = false;\r\n}\r\nstatic void sh_mmcif_clock_control(struct sh_mmcif_host *host, unsigned int clk)\r\n{\r\nstruct sh_mmcif_plat_data *p = host->pd->dev.platform_data;\r\nsh_mmcif_bitclr(host, MMCIF_CE_CLK_CTRL, CLK_ENABLE);\r\nsh_mmcif_bitclr(host, MMCIF_CE_CLK_CTRL, CLK_CLEAR);\r\nif (!clk)\r\nreturn;\r\nif (p->sup_pclk && clk == host->clk)\r\nsh_mmcif_bitset(host, MMCIF_CE_CLK_CTRL, CLK_SUP_PCLK);\r\nelse\r\nsh_mmcif_bitset(host, MMCIF_CE_CLK_CTRL, CLK_CLEAR &\r\n((fls(DIV_ROUND_UP(host->clk,\r\nclk) - 1) - 1) << 16));\r\nsh_mmcif_bitset(host, MMCIF_CE_CLK_CTRL, CLK_ENABLE);\r\n}\r\nstatic void sh_mmcif_sync_reset(struct sh_mmcif_host *host)\r\n{\r\nu32 tmp;\r\ntmp = 0x010f0000 & sh_mmcif_readl(host->addr, MMCIF_CE_CLK_CTRL);\r\nsh_mmcif_writel(host->addr, MMCIF_CE_VERSION, SOFT_RST_ON);\r\nsh_mmcif_writel(host->addr, MMCIF_CE_VERSION, SOFT_RST_OFF);\r\nsh_mmcif_bitset(host, MMCIF_CE_CLK_CTRL, tmp |\r\nSRSPTO_256 | SRBSYTO_29 | SRWDTO_29 | SCCSTO_29);\r\nsh_mmcif_bitset(host, MMCIF_CE_BUF_ACC, BUF_ACC_ATYP);\r\n}\r\nstatic int sh_mmcif_error_manage(struct sh_mmcif_host *host)\r\n{\r\nu32 state1, state2;\r\nint ret, timeout;\r\nhost->sd_error = false;\r\nstate1 = sh_mmcif_readl(host->addr, MMCIF_CE_HOST_STS1);\r\nstate2 = sh_mmcif_readl(host->addr, MMCIF_CE_HOST_STS2);\r\ndev_dbg(&host->pd->dev, "ERR HOST_STS1 = %08x\n", state1);\r\ndev_dbg(&host->pd->dev, "ERR HOST_STS2 = %08x\n", state2);\r\nif (state1 & STS1_CMDSEQ) {\r\nsh_mmcif_bitset(host, MMCIF_CE_CMD_CTRL, CMD_CTRL_BREAK);\r\nsh_mmcif_bitset(host, MMCIF_CE_CMD_CTRL, ~CMD_CTRL_BREAK);\r\nfor (timeout = 10000000; timeout; timeout--) {\r\nif (!(sh_mmcif_readl(host->addr, MMCIF_CE_HOST_STS1)\r\n& STS1_CMDSEQ))\r\nbreak;\r\nmdelay(1);\r\n}\r\nif (!timeout) {\r\ndev_err(&host->pd->dev,\r\n"Forced end of command sequence timeout err\n");\r\nreturn -EIO;\r\n}\r\nsh_mmcif_sync_reset(host);\r\ndev_dbg(&host->pd->dev, "Forced end of command sequence\n");\r\nreturn -EIO;\r\n}\r\nif (state2 & STS2_CRC_ERR) {\r\ndev_dbg(&host->pd->dev, ": CRC error\n");\r\nret = -EIO;\r\n} else if (state2 & STS2_TIMEOUT_ERR) {\r\ndev_dbg(&host->pd->dev, ": Timeout\n");\r\nret = -ETIMEDOUT;\r\n} else {\r\ndev_dbg(&host->pd->dev, ": End/Index error\n");\r\nret = -EIO;\r\n}\r\nreturn ret;\r\n}\r\nstatic bool sh_mmcif_next_block(struct sh_mmcif_host *host, u32 *p)\r\n{\r\nstruct mmc_data *data = host->mrq->data;\r\nhost->sg_blkidx += host->blocksize;\r\nBUG_ON(host->sg_blkidx > data->sg->length);\r\nif (host->sg_blkidx == data->sg->length) {\r\nhost->sg_blkidx = 0;\r\nif (++host->sg_idx < data->sg_len)\r\nhost->pio_ptr = sg_virt(++data->sg);\r\n} else {\r\nhost->pio_ptr = p;\r\n}\r\nif (host->sg_idx == data->sg_len)\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic void sh_mmcif_single_read(struct sh_mmcif_host *host,\r\nstruct mmc_request *mrq)\r\n{\r\nhost->blocksize = (sh_mmcif_readl(host->addr, MMCIF_CE_BLOCK_SET) &\r\nBLOCK_SIZE_MASK) + 3;\r\nhost->wait_for = MMCIF_WAIT_FOR_READ;\r\nschedule_delayed_work(&host->timeout_work, host->timeout);\r\nsh_mmcif_bitset(host, MMCIF_CE_INT_MASK, MASK_MBUFREN);\r\n}\r\nstatic bool sh_mmcif_read_block(struct sh_mmcif_host *host)\r\n{\r\nstruct mmc_data *data = host->mrq->data;\r\nu32 *p = sg_virt(data->sg);\r\nint i;\r\nif (host->sd_error) {\r\ndata->error = sh_mmcif_error_manage(host);\r\nreturn false;\r\n}\r\nfor (i = 0; i < host->blocksize / 4; i++)\r\n*p++ = sh_mmcif_readl(host->addr, MMCIF_CE_DATA);\r\nsh_mmcif_bitset(host, MMCIF_CE_INT_MASK, MASK_MBUFRE);\r\nhost->wait_for = MMCIF_WAIT_FOR_READ_END;\r\nreturn true;\r\n}\r\nstatic void sh_mmcif_multi_read(struct sh_mmcif_host *host,\r\nstruct mmc_request *mrq)\r\n{\r\nstruct mmc_data *data = mrq->data;\r\nif (!data->sg_len || !data->sg->length)\r\nreturn;\r\nhost->blocksize = sh_mmcif_readl(host->addr, MMCIF_CE_BLOCK_SET) &\r\nBLOCK_SIZE_MASK;\r\nhost->wait_for = MMCIF_WAIT_FOR_MREAD;\r\nhost->sg_idx = 0;\r\nhost->sg_blkidx = 0;\r\nhost->pio_ptr = sg_virt(data->sg);\r\nschedule_delayed_work(&host->timeout_work, host->timeout);\r\nsh_mmcif_bitset(host, MMCIF_CE_INT_MASK, MASK_MBUFREN);\r\n}\r\nstatic bool sh_mmcif_mread_block(struct sh_mmcif_host *host)\r\n{\r\nstruct mmc_data *data = host->mrq->data;\r\nu32 *p = host->pio_ptr;\r\nint i;\r\nif (host->sd_error) {\r\ndata->error = sh_mmcif_error_manage(host);\r\nreturn false;\r\n}\r\nBUG_ON(!data->sg->length);\r\nfor (i = 0; i < host->blocksize / 4; i++)\r\n*p++ = sh_mmcif_readl(host->addr, MMCIF_CE_DATA);\r\nif (!sh_mmcif_next_block(host, p))\r\nreturn false;\r\nschedule_delayed_work(&host->timeout_work, host->timeout);\r\nsh_mmcif_bitset(host, MMCIF_CE_INT_MASK, MASK_MBUFREN);\r\nreturn true;\r\n}\r\nstatic void sh_mmcif_single_write(struct sh_mmcif_host *host,\r\nstruct mmc_request *mrq)\r\n{\r\nhost->blocksize = (sh_mmcif_readl(host->addr, MMCIF_CE_BLOCK_SET) &\r\nBLOCK_SIZE_MASK) + 3;\r\nhost->wait_for = MMCIF_WAIT_FOR_WRITE;\r\nschedule_delayed_work(&host->timeout_work, host->timeout);\r\nsh_mmcif_bitset(host, MMCIF_CE_INT_MASK, MASK_MBUFWEN);\r\n}\r\nstatic bool sh_mmcif_write_block(struct sh_mmcif_host *host)\r\n{\r\nstruct mmc_data *data = host->mrq->data;\r\nu32 *p = sg_virt(data->sg);\r\nint i;\r\nif (host->sd_error) {\r\ndata->error = sh_mmcif_error_manage(host);\r\nreturn false;\r\n}\r\nfor (i = 0; i < host->blocksize / 4; i++)\r\nsh_mmcif_writel(host->addr, MMCIF_CE_DATA, *p++);\r\nsh_mmcif_bitset(host, MMCIF_CE_INT_MASK, MASK_MDTRANE);\r\nhost->wait_for = MMCIF_WAIT_FOR_WRITE_END;\r\nreturn true;\r\n}\r\nstatic void sh_mmcif_multi_write(struct sh_mmcif_host *host,\r\nstruct mmc_request *mrq)\r\n{\r\nstruct mmc_data *data = mrq->data;\r\nif (!data->sg_len || !data->sg->length)\r\nreturn;\r\nhost->blocksize = sh_mmcif_readl(host->addr, MMCIF_CE_BLOCK_SET) &\r\nBLOCK_SIZE_MASK;\r\nhost->wait_for = MMCIF_WAIT_FOR_MWRITE;\r\nhost->sg_idx = 0;\r\nhost->sg_blkidx = 0;\r\nhost->pio_ptr = sg_virt(data->sg);\r\nschedule_delayed_work(&host->timeout_work, host->timeout);\r\nsh_mmcif_bitset(host, MMCIF_CE_INT_MASK, MASK_MBUFWEN);\r\n}\r\nstatic bool sh_mmcif_mwrite_block(struct sh_mmcif_host *host)\r\n{\r\nstruct mmc_data *data = host->mrq->data;\r\nu32 *p = host->pio_ptr;\r\nint i;\r\nif (host->sd_error) {\r\ndata->error = sh_mmcif_error_manage(host);\r\nreturn false;\r\n}\r\nBUG_ON(!data->sg->length);\r\nfor (i = 0; i < host->blocksize / 4; i++)\r\nsh_mmcif_writel(host->addr, MMCIF_CE_DATA, *p++);\r\nif (!sh_mmcif_next_block(host, p))\r\nreturn false;\r\nschedule_delayed_work(&host->timeout_work, host->timeout);\r\nsh_mmcif_bitset(host, MMCIF_CE_INT_MASK, MASK_MBUFWEN);\r\nreturn true;\r\n}\r\nstatic void sh_mmcif_get_response(struct sh_mmcif_host *host,\r\nstruct mmc_command *cmd)\r\n{\r\nif (cmd->flags & MMC_RSP_136) {\r\ncmd->resp[0] = sh_mmcif_readl(host->addr, MMCIF_CE_RESP3);\r\ncmd->resp[1] = sh_mmcif_readl(host->addr, MMCIF_CE_RESP2);\r\ncmd->resp[2] = sh_mmcif_readl(host->addr, MMCIF_CE_RESP1);\r\ncmd->resp[3] = sh_mmcif_readl(host->addr, MMCIF_CE_RESP0);\r\n} else\r\ncmd->resp[0] = sh_mmcif_readl(host->addr, MMCIF_CE_RESP0);\r\n}\r\nstatic void sh_mmcif_get_cmd12response(struct sh_mmcif_host *host,\r\nstruct mmc_command *cmd)\r\n{\r\ncmd->resp[0] = sh_mmcif_readl(host->addr, MMCIF_CE_RESP_CMD12);\r\n}\r\nstatic u32 sh_mmcif_set_cmd(struct sh_mmcif_host *host,\r\nstruct mmc_request *mrq)\r\n{\r\nstruct mmc_data *data = mrq->data;\r\nstruct mmc_command *cmd = mrq->cmd;\r\nu32 opc = cmd->opcode;\r\nu32 tmp = 0;\r\nswitch (mmc_resp_type(cmd)) {\r\ncase MMC_RSP_NONE:\r\ntmp |= CMD_SET_RTYP_NO;\r\nbreak;\r\ncase MMC_RSP_R1:\r\ncase MMC_RSP_R1B:\r\ncase MMC_RSP_R3:\r\ntmp |= CMD_SET_RTYP_6B;\r\nbreak;\r\ncase MMC_RSP_R2:\r\ntmp |= CMD_SET_RTYP_17B;\r\nbreak;\r\ndefault:\r\ndev_err(&host->pd->dev, "Unsupported response type.\n");\r\nbreak;\r\n}\r\nswitch (opc) {\r\ncase MMC_SWITCH:\r\ncase MMC_STOP_TRANSMISSION:\r\ncase MMC_SET_WRITE_PROT:\r\ncase MMC_CLR_WRITE_PROT:\r\ncase MMC_ERASE:\r\ntmp |= CMD_SET_RBSY;\r\nbreak;\r\n}\r\nif (data) {\r\ntmp |= CMD_SET_WDAT;\r\nswitch (host->bus_width) {\r\ncase MMC_BUS_WIDTH_1:\r\ntmp |= CMD_SET_DATW_1;\r\nbreak;\r\ncase MMC_BUS_WIDTH_4:\r\ntmp |= CMD_SET_DATW_4;\r\nbreak;\r\ncase MMC_BUS_WIDTH_8:\r\ntmp |= CMD_SET_DATW_8;\r\nbreak;\r\ndefault:\r\ndev_err(&host->pd->dev, "Unsupported bus width.\n");\r\nbreak;\r\n}\r\n}\r\nif (opc == MMC_WRITE_BLOCK || opc == MMC_WRITE_MULTIPLE_BLOCK)\r\ntmp |= CMD_SET_DWEN;\r\nif (opc == MMC_READ_MULTIPLE_BLOCK || opc == MMC_WRITE_MULTIPLE_BLOCK) {\r\ntmp |= CMD_SET_CMLTE | CMD_SET_CMD12EN;\r\nsh_mmcif_bitset(host, MMCIF_CE_BLOCK_SET,\r\ndata->blocks << 16);\r\n}\r\nif (opc == MMC_SEND_OP_COND || opc == MMC_ALL_SEND_CID ||\r\nopc == MMC_SEND_CSD || opc == MMC_SEND_CID)\r\ntmp |= CMD_SET_RIDXC_BITS;\r\nif (opc == MMC_SEND_OP_COND)\r\ntmp |= CMD_SET_CRC7C_BITS;\r\nif (opc == MMC_ALL_SEND_CID ||\r\nopc == MMC_SEND_CSD || opc == MMC_SEND_CID)\r\ntmp |= CMD_SET_CRC7C_INTERNAL;\r\nreturn (opc << 24) | tmp;\r\n}\r\nstatic int sh_mmcif_data_trans(struct sh_mmcif_host *host,\r\nstruct mmc_request *mrq, u32 opc)\r\n{\r\nswitch (opc) {\r\ncase MMC_READ_MULTIPLE_BLOCK:\r\nsh_mmcif_multi_read(host, mrq);\r\nreturn 0;\r\ncase MMC_WRITE_MULTIPLE_BLOCK:\r\nsh_mmcif_multi_write(host, mrq);\r\nreturn 0;\r\ncase MMC_WRITE_BLOCK:\r\nsh_mmcif_single_write(host, mrq);\r\nreturn 0;\r\ncase MMC_READ_SINGLE_BLOCK:\r\ncase MMC_SEND_EXT_CSD:\r\nsh_mmcif_single_read(host, mrq);\r\nreturn 0;\r\ndefault:\r\ndev_err(&host->pd->dev, "UNSUPPORTED CMD = d'%08d\n", opc);\r\nreturn -EINVAL;\r\n}\r\n}\r\nstatic void sh_mmcif_start_cmd(struct sh_mmcif_host *host,\r\nstruct mmc_request *mrq)\r\n{\r\nstruct mmc_command *cmd = mrq->cmd;\r\nu32 opc = cmd->opcode;\r\nu32 mask;\r\nswitch (opc) {\r\ncase MMC_SWITCH:\r\ncase MMC_STOP_TRANSMISSION:\r\ncase MMC_SET_WRITE_PROT:\r\ncase MMC_CLR_WRITE_PROT:\r\ncase MMC_ERASE:\r\nmask = MASK_START_CMD | MASK_MRBSYE;\r\nbreak;\r\ndefault:\r\nmask = MASK_START_CMD | MASK_MCRSPE;\r\nbreak;\r\n}\r\nif (mrq->data) {\r\nsh_mmcif_writel(host->addr, MMCIF_CE_BLOCK_SET, 0);\r\nsh_mmcif_writel(host->addr, MMCIF_CE_BLOCK_SET,\r\nmrq->data->blksz);\r\n}\r\nopc = sh_mmcif_set_cmd(host, mrq);\r\nsh_mmcif_writel(host->addr, MMCIF_CE_INT, 0xD80430C0);\r\nsh_mmcif_writel(host->addr, MMCIF_CE_INT_MASK, mask);\r\nsh_mmcif_writel(host->addr, MMCIF_CE_ARG, cmd->arg);\r\nsh_mmcif_writel(host->addr, MMCIF_CE_CMD_SET, opc);\r\nhost->wait_for = MMCIF_WAIT_FOR_CMD;\r\nschedule_delayed_work(&host->timeout_work, host->timeout);\r\n}\r\nstatic void sh_mmcif_stop_cmd(struct sh_mmcif_host *host,\r\nstruct mmc_request *mrq)\r\n{\r\nswitch (mrq->cmd->opcode) {\r\ncase MMC_READ_MULTIPLE_BLOCK:\r\nsh_mmcif_bitset(host, MMCIF_CE_INT_MASK, MASK_MCMD12DRE);\r\nbreak;\r\ncase MMC_WRITE_MULTIPLE_BLOCK:\r\nsh_mmcif_bitset(host, MMCIF_CE_INT_MASK, MASK_MCMD12RBE);\r\nbreak;\r\ndefault:\r\ndev_err(&host->pd->dev, "unsupported stop cmd\n");\r\nmrq->stop->error = sh_mmcif_error_manage(host);\r\nreturn;\r\n}\r\nhost->wait_for = MMCIF_WAIT_FOR_STOP;\r\nschedule_delayed_work(&host->timeout_work, host->timeout);\r\n}\r\nstatic void sh_mmcif_request(struct mmc_host *mmc, struct mmc_request *mrq)\r\n{\r\nstruct sh_mmcif_host *host = mmc_priv(mmc);\r\nunsigned long flags;\r\nspin_lock_irqsave(&host->lock, flags);\r\nif (host->state != STATE_IDLE) {\r\nspin_unlock_irqrestore(&host->lock, flags);\r\nmrq->cmd->error = -EAGAIN;\r\nmmc_request_done(mmc, mrq);\r\nreturn;\r\n}\r\nhost->state = STATE_REQUEST;\r\nspin_unlock_irqrestore(&host->lock, flags);\r\nswitch (mrq->cmd->opcode) {\r\ncase SD_IO_SEND_OP_COND:\r\ncase MMC_APP_CMD:\r\nhost->state = STATE_IDLE;\r\nmrq->cmd->error = -ETIMEDOUT;\r\nmmc_request_done(mmc, mrq);\r\nreturn;\r\ncase MMC_SEND_EXT_CSD:\r\nif (!mrq->data) {\r\nhost->state = STATE_IDLE;\r\nmrq->cmd->error = -ETIMEDOUT;\r\nmmc_request_done(mmc, mrq);\r\nreturn;\r\n}\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nhost->mrq = mrq;\r\nsh_mmcif_start_cmd(host, mrq);\r\n}\r\nstatic void sh_mmcif_set_ios(struct mmc_host *mmc, struct mmc_ios *ios)\r\n{\r\nstruct sh_mmcif_host *host = mmc_priv(mmc);\r\nstruct sh_mmcif_plat_data *p = host->pd->dev.platform_data;\r\nunsigned long flags;\r\nspin_lock_irqsave(&host->lock, flags);\r\nif (host->state != STATE_IDLE) {\r\nspin_unlock_irqrestore(&host->lock, flags);\r\nreturn;\r\n}\r\nhost->state = STATE_IOS;\r\nspin_unlock_irqrestore(&host->lock, flags);\r\nif (ios->power_mode == MMC_POWER_UP) {\r\nif (!host->card_present) {\r\nsh_mmcif_request_dma(host, host->pd->dev.platform_data);\r\nhost->card_present = true;\r\n}\r\n} else if (ios->power_mode == MMC_POWER_OFF || !ios->clock) {\r\nsh_mmcif_clock_control(host, 0);\r\nif (ios->power_mode == MMC_POWER_OFF) {\r\nif (host->card_present) {\r\nsh_mmcif_release_dma(host);\r\nhost->card_present = false;\r\n}\r\n}\r\nif (host->power) {\r\npm_runtime_put(&host->pd->dev);\r\nhost->power = false;\r\nif (p->down_pwr && ios->power_mode == MMC_POWER_OFF)\r\np->down_pwr(host->pd);\r\n}\r\nhost->state = STATE_IDLE;\r\nreturn;\r\n}\r\nif (ios->clock) {\r\nif (!host->power) {\r\nif (p->set_pwr)\r\np->set_pwr(host->pd, ios->power_mode);\r\npm_runtime_get_sync(&host->pd->dev);\r\nhost->power = true;\r\nsh_mmcif_sync_reset(host);\r\n}\r\nsh_mmcif_clock_control(host, ios->clock);\r\n}\r\nhost->bus_width = ios->bus_width;\r\nhost->state = STATE_IDLE;\r\n}\r\nstatic int sh_mmcif_get_cd(struct mmc_host *mmc)\r\n{\r\nstruct sh_mmcif_host *host = mmc_priv(mmc);\r\nstruct sh_mmcif_plat_data *p = host->pd->dev.platform_data;\r\nif (!p->get_cd)\r\nreturn -ENOSYS;\r\nelse\r\nreturn p->get_cd(host->pd);\r\n}\r\nstatic bool sh_mmcif_end_cmd(struct sh_mmcif_host *host)\r\n{\r\nstruct mmc_command *cmd = host->mrq->cmd;\r\nstruct mmc_data *data = host->mrq->data;\r\nlong time;\r\nif (host->sd_error) {\r\nswitch (cmd->opcode) {\r\ncase MMC_ALL_SEND_CID:\r\ncase MMC_SELECT_CARD:\r\ncase MMC_APP_CMD:\r\ncmd->error = -ETIMEDOUT;\r\nhost->sd_error = false;\r\nbreak;\r\ndefault:\r\ncmd->error = sh_mmcif_error_manage(host);\r\ndev_dbg(&host->pd->dev, "Cmd(d'%d) error %d\n",\r\ncmd->opcode, cmd->error);\r\nbreak;\r\n}\r\nreturn false;\r\n}\r\nif (!(cmd->flags & MMC_RSP_PRESENT)) {\r\ncmd->error = 0;\r\nreturn false;\r\n}\r\nsh_mmcif_get_response(host, cmd);\r\nif (!data)\r\nreturn false;\r\nif (data->flags & MMC_DATA_READ) {\r\nif (host->chan_rx)\r\nsh_mmcif_start_dma_rx(host);\r\n} else {\r\nif (host->chan_tx)\r\nsh_mmcif_start_dma_tx(host);\r\n}\r\nif (!host->dma_active) {\r\ndata->error = sh_mmcif_data_trans(host, host->mrq, cmd->opcode);\r\nif (!data->error)\r\nreturn true;\r\nreturn false;\r\n}\r\ntime = wait_for_completion_interruptible_timeout(&host->dma_complete,\r\nhost->timeout);\r\nif (host->sd_error) {\r\ndev_err(host->mmc->parent,\r\n"Error IRQ while waiting for DMA completion!\n");\r\nif (data->flags & MMC_DATA_READ)\r\ndmaengine_terminate_all(host->chan_rx);\r\nelse\r\ndmaengine_terminate_all(host->chan_tx);\r\ndata->error = sh_mmcif_error_manage(host);\r\n} else if (!time) {\r\ndata->error = -ETIMEDOUT;\r\n} else if (time < 0) {\r\ndata->error = time;\r\n}\r\nsh_mmcif_bitclr(host, MMCIF_CE_BUF_ACC,\r\nBUF_ACC_DMAREN | BUF_ACC_DMAWEN);\r\nhost->dma_active = false;\r\nif (data->error)\r\ndata->bytes_xfered = 0;\r\nreturn false;\r\n}\r\nstatic irqreturn_t sh_mmcif_irqt(int irq, void *dev_id)\r\n{\r\nstruct sh_mmcif_host *host = dev_id;\r\nstruct mmc_request *mrq = host->mrq;\r\nstruct mmc_data *data = mrq->data;\r\ncancel_delayed_work_sync(&host->timeout_work);\r\nswitch (host->wait_for) {\r\ncase MMCIF_WAIT_FOR_REQUEST:\r\nreturn IRQ_HANDLED;\r\ncase MMCIF_WAIT_FOR_CMD:\r\nif (sh_mmcif_end_cmd(host))\r\nreturn IRQ_HANDLED;\r\nbreak;\r\ncase MMCIF_WAIT_FOR_MREAD:\r\nif (sh_mmcif_mread_block(host))\r\nreturn IRQ_HANDLED;\r\nbreak;\r\ncase MMCIF_WAIT_FOR_READ:\r\nif (sh_mmcif_read_block(host))\r\nreturn IRQ_HANDLED;\r\nbreak;\r\ncase MMCIF_WAIT_FOR_MWRITE:\r\nif (sh_mmcif_mwrite_block(host))\r\nreturn IRQ_HANDLED;\r\nbreak;\r\ncase MMCIF_WAIT_FOR_WRITE:\r\nif (sh_mmcif_write_block(host))\r\nreturn IRQ_HANDLED;\r\nbreak;\r\ncase MMCIF_WAIT_FOR_STOP:\r\nif (host->sd_error) {\r\nmrq->stop->error = sh_mmcif_error_manage(host);\r\nbreak;\r\n}\r\nsh_mmcif_get_cmd12response(host, mrq->stop);\r\nmrq->stop->error = 0;\r\nbreak;\r\ncase MMCIF_WAIT_FOR_READ_END:\r\ncase MMCIF_WAIT_FOR_WRITE_END:\r\nif (host->sd_error)\r\ndata->error = sh_mmcif_error_manage(host);\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\nif (host->wait_for != MMCIF_WAIT_FOR_STOP) {\r\nif (!mrq->cmd->error && data && !data->error)\r\ndata->bytes_xfered =\r\ndata->blocks * data->blksz;\r\nif (mrq->stop && !mrq->cmd->error && (!data || !data->error)) {\r\nsh_mmcif_stop_cmd(host, mrq);\r\nif (!mrq->stop->error)\r\nreturn IRQ_HANDLED;\r\n}\r\n}\r\nhost->wait_for = MMCIF_WAIT_FOR_REQUEST;\r\nhost->state = STATE_IDLE;\r\nhost->mrq = NULL;\r\nmmc_request_done(host->mmc, mrq);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t sh_mmcif_intr(int irq, void *dev_id)\r\n{\r\nstruct sh_mmcif_host *host = dev_id;\r\nu32 state;\r\nint err = 0;\r\nstate = sh_mmcif_readl(host->addr, MMCIF_CE_INT);\r\nif (state & INT_ERR_STS) {\r\nsh_mmcif_writel(host->addr, MMCIF_CE_INT, ~state);\r\nsh_mmcif_bitclr(host, MMCIF_CE_INT_MASK, state);\r\nerr = 1;\r\n} else if (state & INT_RBSYE) {\r\nsh_mmcif_writel(host->addr, MMCIF_CE_INT,\r\n~(INT_RBSYE | INT_CRSPE));\r\nsh_mmcif_bitclr(host, MMCIF_CE_INT_MASK, MASK_MRBSYE);\r\n} else if (state & INT_CRSPE) {\r\nsh_mmcif_writel(host->addr, MMCIF_CE_INT, ~INT_CRSPE);\r\nsh_mmcif_bitclr(host, MMCIF_CE_INT_MASK, MASK_MCRSPE);\r\n} else if (state & INT_BUFREN) {\r\nsh_mmcif_writel(host->addr, MMCIF_CE_INT, ~INT_BUFREN);\r\nsh_mmcif_bitclr(host, MMCIF_CE_INT_MASK, MASK_MBUFREN);\r\n} else if (state & INT_BUFWEN) {\r\nsh_mmcif_writel(host->addr, MMCIF_CE_INT, ~INT_BUFWEN);\r\nsh_mmcif_bitclr(host, MMCIF_CE_INT_MASK, MASK_MBUFWEN);\r\n} else if (state & INT_CMD12DRE) {\r\nsh_mmcif_writel(host->addr, MMCIF_CE_INT,\r\n~(INT_CMD12DRE | INT_CMD12RBE |\r\nINT_CMD12CRE | INT_BUFRE));\r\nsh_mmcif_bitclr(host, MMCIF_CE_INT_MASK, MASK_MCMD12DRE);\r\n} else if (state & INT_BUFRE) {\r\nsh_mmcif_writel(host->addr, MMCIF_CE_INT, ~INT_BUFRE);\r\nsh_mmcif_bitclr(host, MMCIF_CE_INT_MASK, MASK_MBUFRE);\r\n} else if (state & INT_DTRANE) {\r\nsh_mmcif_writel(host->addr, MMCIF_CE_INT, ~INT_DTRANE);\r\nsh_mmcif_bitclr(host, MMCIF_CE_INT_MASK, MASK_MDTRANE);\r\n} else if (state & INT_CMD12RBE) {\r\nsh_mmcif_writel(host->addr, MMCIF_CE_INT,\r\n~(INT_CMD12RBE | INT_CMD12CRE));\r\nsh_mmcif_bitclr(host, MMCIF_CE_INT_MASK, MASK_MCMD12RBE);\r\n} else {\r\ndev_dbg(&host->pd->dev, "Unsupported interrupt: 0x%x\n", state);\r\nsh_mmcif_writel(host->addr, MMCIF_CE_INT, ~state);\r\nsh_mmcif_bitclr(host, MMCIF_CE_INT_MASK, state);\r\nerr = 1;\r\n}\r\nif (err) {\r\nhost->sd_error = true;\r\ndev_dbg(&host->pd->dev, "int err state = %08x\n", state);\r\n}\r\nif (state & ~(INT_CMD12RBE | INT_CMD12CRE)) {\r\nif (!host->dma_active)\r\nreturn IRQ_WAKE_THREAD;\r\nelse if (host->sd_error)\r\nmmcif_dma_complete(host);\r\n} else {\r\ndev_dbg(&host->pd->dev, "Unexpected IRQ 0x%x\n", state);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void mmcif_timeout_work(struct work_struct *work)\r\n{\r\nstruct delayed_work *d = container_of(work, struct delayed_work, work);\r\nstruct sh_mmcif_host *host = container_of(d, struct sh_mmcif_host, timeout_work);\r\nstruct mmc_request *mrq = host->mrq;\r\nif (host->dying)\r\nreturn;\r\nswitch (host->wait_for) {\r\ncase MMCIF_WAIT_FOR_CMD:\r\nmrq->cmd->error = sh_mmcif_error_manage(host);\r\nbreak;\r\ncase MMCIF_WAIT_FOR_STOP:\r\nmrq->stop->error = sh_mmcif_error_manage(host);\r\nbreak;\r\ncase MMCIF_WAIT_FOR_MREAD:\r\ncase MMCIF_WAIT_FOR_MWRITE:\r\ncase MMCIF_WAIT_FOR_READ:\r\ncase MMCIF_WAIT_FOR_WRITE:\r\ncase MMCIF_WAIT_FOR_READ_END:\r\ncase MMCIF_WAIT_FOR_WRITE_END:\r\nmrq->data->error = sh_mmcif_error_manage(host);\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\nhost->state = STATE_IDLE;\r\nhost->wait_for = MMCIF_WAIT_FOR_REQUEST;\r\nhost->mrq = NULL;\r\nmmc_request_done(host->mmc, mrq);\r\n}\r\nstatic int __devinit sh_mmcif_probe(struct platform_device *pdev)\r\n{\r\nint ret = 0, irq[2];\r\nstruct mmc_host *mmc;\r\nstruct sh_mmcif_host *host;\r\nstruct sh_mmcif_plat_data *pd;\r\nstruct resource *res;\r\nvoid __iomem *reg;\r\nchar clk_name[8];\r\nirq[0] = platform_get_irq(pdev, 0);\r\nirq[1] = platform_get_irq(pdev, 1);\r\nif (irq[0] < 0 || irq[1] < 0) {\r\ndev_err(&pdev->dev, "Get irq error\n");\r\nreturn -ENXIO;\r\n}\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nif (!res) {\r\ndev_err(&pdev->dev, "platform_get_resource error.\n");\r\nreturn -ENXIO;\r\n}\r\nreg = ioremap(res->start, resource_size(res));\r\nif (!reg) {\r\ndev_err(&pdev->dev, "ioremap error.\n");\r\nreturn -ENOMEM;\r\n}\r\npd = pdev->dev.platform_data;\r\nif (!pd) {\r\ndev_err(&pdev->dev, "sh_mmcif plat data error.\n");\r\nret = -ENXIO;\r\ngoto clean_up;\r\n}\r\nmmc = mmc_alloc_host(sizeof(struct sh_mmcif_host), &pdev->dev);\r\nif (!mmc) {\r\nret = -ENOMEM;\r\ngoto clean_up;\r\n}\r\nhost = mmc_priv(mmc);\r\nhost->mmc = mmc;\r\nhost->addr = reg;\r\nhost->timeout = 1000;\r\nsnprintf(clk_name, sizeof(clk_name), "mmc%d", pdev->id);\r\nhost->hclk = clk_get(&pdev->dev, clk_name);\r\nif (IS_ERR(host->hclk)) {\r\ndev_err(&pdev->dev, "cannot get clock \"%s\"\n", clk_name);\r\nret = PTR_ERR(host->hclk);\r\ngoto clean_up1;\r\n}\r\nclk_enable(host->hclk);\r\nhost->clk = clk_get_rate(host->hclk);\r\nhost->pd = pdev;\r\nspin_lock_init(&host->lock);\r\nmmc->ops = &sh_mmcif_ops;\r\nmmc->f_max = host->clk / 2;\r\nmmc->f_min = host->clk / 512;\r\nif (pd->ocr)\r\nmmc->ocr_avail = pd->ocr;\r\nmmc->caps = MMC_CAP_MMC_HIGHSPEED;\r\nif (pd->caps)\r\nmmc->caps |= pd->caps;\r\nmmc->max_segs = 32;\r\nmmc->max_blk_size = 512;\r\nmmc->max_req_size = PAGE_CACHE_SIZE * mmc->max_segs;\r\nmmc->max_blk_count = mmc->max_req_size / mmc->max_blk_size;\r\nmmc->max_seg_size = mmc->max_req_size;\r\nsh_mmcif_sync_reset(host);\r\nplatform_set_drvdata(pdev, host);\r\npm_runtime_enable(&pdev->dev);\r\nhost->power = false;\r\nret = pm_runtime_resume(&pdev->dev);\r\nif (ret < 0)\r\ngoto clean_up2;\r\nINIT_DELAYED_WORK(&host->timeout_work, mmcif_timeout_work);\r\nsh_mmcif_writel(host->addr, MMCIF_CE_INT_MASK, MASK_ALL);\r\nret = request_threaded_irq(irq[0], sh_mmcif_intr, sh_mmcif_irqt, 0, "sh_mmc:error", host);\r\nif (ret) {\r\ndev_err(&pdev->dev, "request_irq error (sh_mmc:error)\n");\r\ngoto clean_up3;\r\n}\r\nret = request_threaded_irq(irq[1], sh_mmcif_intr, sh_mmcif_irqt, 0, "sh_mmc:int", host);\r\nif (ret) {\r\ndev_err(&pdev->dev, "request_irq error (sh_mmc:int)\n");\r\ngoto clean_up4;\r\n}\r\nret = mmc_add_host(mmc);\r\nif (ret < 0)\r\ngoto clean_up5;\r\ndev_pm_qos_expose_latency_limit(&pdev->dev, 100);\r\ndev_info(&pdev->dev, "driver version %s\n", DRIVER_VERSION);\r\ndev_dbg(&pdev->dev, "chip ver H'%04x\n",\r\nsh_mmcif_readl(host->addr, MMCIF_CE_VERSION) & 0x0000ffff);\r\nreturn ret;\r\nclean_up5:\r\nfree_irq(irq[1], host);\r\nclean_up4:\r\nfree_irq(irq[0], host);\r\nclean_up3:\r\npm_runtime_suspend(&pdev->dev);\r\nclean_up2:\r\npm_runtime_disable(&pdev->dev);\r\nclk_disable(host->hclk);\r\nclean_up1:\r\nmmc_free_host(mmc);\r\nclean_up:\r\nif (reg)\r\niounmap(reg);\r\nreturn ret;\r\n}\r\nstatic int __devexit sh_mmcif_remove(struct platform_device *pdev)\r\n{\r\nstruct sh_mmcif_host *host = platform_get_drvdata(pdev);\r\nint irq[2];\r\nhost->dying = true;\r\npm_runtime_get_sync(&pdev->dev);\r\ndev_pm_qos_hide_latency_limit(&pdev->dev);\r\nmmc_remove_host(host->mmc);\r\nsh_mmcif_writel(host->addr, MMCIF_CE_INT_MASK, MASK_ALL);\r\ncancel_delayed_work_sync(&host->timeout_work);\r\nif (host->addr)\r\niounmap(host->addr);\r\nirq[0] = platform_get_irq(pdev, 0);\r\nirq[1] = platform_get_irq(pdev, 1);\r\nfree_irq(irq[0], host);\r\nfree_irq(irq[1], host);\r\nplatform_set_drvdata(pdev, NULL);\r\nclk_disable(host->hclk);\r\nmmc_free_host(host->mmc);\r\npm_runtime_put_sync(&pdev->dev);\r\npm_runtime_disable(&pdev->dev);\r\nreturn 0;\r\n}\r\nstatic int sh_mmcif_suspend(struct device *dev)\r\n{\r\nstruct platform_device *pdev = to_platform_device(dev);\r\nstruct sh_mmcif_host *host = platform_get_drvdata(pdev);\r\nint ret = mmc_suspend_host(host->mmc);\r\nif (!ret) {\r\nsh_mmcif_writel(host->addr, MMCIF_CE_INT_MASK, MASK_ALL);\r\nclk_disable(host->hclk);\r\n}\r\nreturn ret;\r\n}\r\nstatic int sh_mmcif_resume(struct device *dev)\r\n{\r\nstruct platform_device *pdev = to_platform_device(dev);\r\nstruct sh_mmcif_host *host = platform_get_drvdata(pdev);\r\nclk_enable(host->hclk);\r\nreturn mmc_resume_host(host->mmc);\r\n}
