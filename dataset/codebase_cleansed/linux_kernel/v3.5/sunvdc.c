static inline struct vdc_port *to_vdc_port(struct vio_driver_state *vio)\r\n{\r\nreturn container_of(vio, struct vdc_port, vio);\r\n}\r\nstatic inline u32 vdc_tx_dring_avail(struct vio_dring_state *dr)\r\n{\r\nreturn vio_dring_avail(dr, VDC_TX_RING_SIZE);\r\n}\r\nstatic int vdc_getgeo(struct block_device *bdev, struct hd_geometry *geo)\r\n{\r\nstruct gendisk *disk = bdev->bd_disk;\r\nstruct vdc_port *port = disk->private_data;\r\ngeo->heads = (u8) port->geom.num_hd;\r\ngeo->sectors = (u8) port->geom.num_sec;\r\ngeo->cylinders = port->geom.num_cyl;\r\nreturn 0;\r\n}\r\nstatic void vdc_finish(struct vio_driver_state *vio, int err, int waiting_for)\r\n{\r\nif (vio->cmp &&\r\n(waiting_for == -1 ||\r\nvio->cmp->waiting_for == waiting_for)) {\r\nvio->cmp->err = err;\r\ncomplete(&vio->cmp->com);\r\nvio->cmp = NULL;\r\n}\r\n}\r\nstatic void vdc_handshake_complete(struct vio_driver_state *vio)\r\n{\r\nvdc_finish(vio, 0, WAITING_FOR_LINK_UP);\r\n}\r\nstatic int vdc_handle_unknown(struct vdc_port *port, void *arg)\r\n{\r\nstruct vio_msg_tag *pkt = arg;\r\nprintk(KERN_ERR PFX "Received unknown msg [%02x:%02x:%04x:%08x]\n",\r\npkt->type, pkt->stype, pkt->stype_env, pkt->sid);\r\nprintk(KERN_ERR PFX "Resetting connection.\n");\r\nldc_disconnect(port->vio.lp);\r\nreturn -ECONNRESET;\r\n}\r\nstatic int vdc_send_attr(struct vio_driver_state *vio)\r\n{\r\nstruct vdc_port *port = to_vdc_port(vio);\r\nstruct vio_disk_attr_info pkt;\r\nmemset(&pkt, 0, sizeof(pkt));\r\npkt.tag.type = VIO_TYPE_CTRL;\r\npkt.tag.stype = VIO_SUBTYPE_INFO;\r\npkt.tag.stype_env = VIO_ATTR_INFO;\r\npkt.tag.sid = vio_send_sid(vio);\r\npkt.xfer_mode = VIO_DRING_MODE;\r\npkt.vdisk_block_size = port->vdisk_block_size;\r\npkt.max_xfer_size = port->max_xfer_size;\r\nviodbg(HS, "SEND ATTR xfer_mode[0x%x] blksz[%u] max_xfer[%llu]\n",\r\npkt.xfer_mode, pkt.vdisk_block_size, pkt.max_xfer_size);\r\nreturn vio_ldc_send(&port->vio, &pkt, sizeof(pkt));\r\n}\r\nstatic int vdc_handle_attr(struct vio_driver_state *vio, void *arg)\r\n{\r\nstruct vdc_port *port = to_vdc_port(vio);\r\nstruct vio_disk_attr_info *pkt = arg;\r\nviodbg(HS, "GOT ATTR stype[0x%x] ops[%llx] disk_size[%llu] disk_type[%x] "\r\n"xfer_mode[0x%x] blksz[%u] max_xfer[%llu]\n",\r\npkt->tag.stype, pkt->operations,\r\npkt->vdisk_size, pkt->vdisk_type,\r\npkt->xfer_mode, pkt->vdisk_block_size,\r\npkt->max_xfer_size);\r\nif (pkt->tag.stype == VIO_SUBTYPE_ACK) {\r\nswitch (pkt->vdisk_type) {\r\ncase VD_DISK_TYPE_DISK:\r\ncase VD_DISK_TYPE_SLICE:\r\nbreak;\r\ndefault:\r\nprintk(KERN_ERR PFX "%s: Bogus vdisk_type 0x%x\n",\r\nvio->name, pkt->vdisk_type);\r\nreturn -ECONNRESET;\r\n}\r\nif (pkt->vdisk_block_size > port->vdisk_block_size) {\r\nprintk(KERN_ERR PFX "%s: BLOCK size increased "\r\n"%u --> %u\n",\r\nvio->name,\r\nport->vdisk_block_size, pkt->vdisk_block_size);\r\nreturn -ECONNRESET;\r\n}\r\nport->operations = pkt->operations;\r\nport->vdisk_size = pkt->vdisk_size;\r\nport->vdisk_type = pkt->vdisk_type;\r\nif (pkt->max_xfer_size < port->max_xfer_size)\r\nport->max_xfer_size = pkt->max_xfer_size;\r\nport->vdisk_block_size = pkt->vdisk_block_size;\r\nreturn 0;\r\n} else {\r\nprintk(KERN_ERR PFX "%s: Attribute NACK\n", vio->name);\r\nreturn -ECONNRESET;\r\n}\r\n}\r\nstatic void vdc_end_special(struct vdc_port *port, struct vio_disk_desc *desc)\r\n{\r\nint err = desc->status;\r\nvdc_finish(&port->vio, -err, WAITING_FOR_GEN_CMD);\r\n}\r\nstatic void vdc_end_one(struct vdc_port *port, struct vio_dring_state *dr,\r\nunsigned int index)\r\n{\r\nstruct vio_disk_desc *desc = vio_dring_entry(dr, index);\r\nstruct vdc_req_entry *rqe = &port->rq_arr[index];\r\nstruct request *req;\r\nif (unlikely(desc->hdr.state != VIO_DESC_DONE))\r\nreturn;\r\nldc_unmap(port->vio.lp, desc->cookies, desc->ncookies);\r\ndesc->hdr.state = VIO_DESC_FREE;\r\ndr->cons = (index + 1) & (VDC_TX_RING_SIZE - 1);\r\nreq = rqe->req;\r\nif (req == NULL) {\r\nvdc_end_special(port, desc);\r\nreturn;\r\n}\r\nrqe->req = NULL;\r\n__blk_end_request(req, (desc->status ? -EIO : 0), desc->size);\r\nif (blk_queue_stopped(port->disk->queue))\r\nblk_start_queue(port->disk->queue);\r\n}\r\nstatic int vdc_ack(struct vdc_port *port, void *msgbuf)\r\n{\r\nstruct vio_dring_state *dr = &port->vio.drings[VIO_DRIVER_TX_RING];\r\nstruct vio_dring_data *pkt = msgbuf;\r\nif (unlikely(pkt->dring_ident != dr->ident ||\r\npkt->start_idx != pkt->end_idx ||\r\npkt->start_idx >= VDC_TX_RING_SIZE))\r\nreturn 0;\r\nvdc_end_one(port, dr, pkt->start_idx);\r\nreturn 0;\r\n}\r\nstatic int vdc_nack(struct vdc_port *port, void *msgbuf)\r\n{\r\nreturn 0;\r\n}\r\nstatic void vdc_event(void *arg, int event)\r\n{\r\nstruct vdc_port *port = arg;\r\nstruct vio_driver_state *vio = &port->vio;\r\nunsigned long flags;\r\nint err;\r\nspin_lock_irqsave(&vio->lock, flags);\r\nif (unlikely(event == LDC_EVENT_RESET ||\r\nevent == LDC_EVENT_UP)) {\r\nvio_link_state_change(vio, event);\r\nspin_unlock_irqrestore(&vio->lock, flags);\r\nreturn;\r\n}\r\nif (unlikely(event != LDC_EVENT_DATA_READY)) {\r\nprintk(KERN_WARNING PFX "Unexpected LDC event %d\n", event);\r\nspin_unlock_irqrestore(&vio->lock, flags);\r\nreturn;\r\n}\r\nerr = 0;\r\nwhile (1) {\r\nunion {\r\nstruct vio_msg_tag tag;\r\nu64 raw[8];\r\n} msgbuf;\r\nerr = ldc_read(vio->lp, &msgbuf, sizeof(msgbuf));\r\nif (unlikely(err < 0)) {\r\nif (err == -ECONNRESET)\r\nvio_conn_reset(vio);\r\nbreak;\r\n}\r\nif (err == 0)\r\nbreak;\r\nviodbg(DATA, "TAG [%02x:%02x:%04x:%08x]\n",\r\nmsgbuf.tag.type,\r\nmsgbuf.tag.stype,\r\nmsgbuf.tag.stype_env,\r\nmsgbuf.tag.sid);\r\nerr = vio_validate_sid(vio, &msgbuf.tag);\r\nif (err < 0)\r\nbreak;\r\nif (likely(msgbuf.tag.type == VIO_TYPE_DATA)) {\r\nif (msgbuf.tag.stype == VIO_SUBTYPE_ACK)\r\nerr = vdc_ack(port, &msgbuf);\r\nelse if (msgbuf.tag.stype == VIO_SUBTYPE_NACK)\r\nerr = vdc_nack(port, &msgbuf);\r\nelse\r\nerr = vdc_handle_unknown(port, &msgbuf);\r\n} else if (msgbuf.tag.type == VIO_TYPE_CTRL) {\r\nerr = vio_control_pkt_engine(vio, &msgbuf);\r\n} else {\r\nerr = vdc_handle_unknown(port, &msgbuf);\r\n}\r\nif (err < 0)\r\nbreak;\r\n}\r\nif (err < 0)\r\nvdc_finish(&port->vio, err, WAITING_FOR_ANY);\r\nspin_unlock_irqrestore(&vio->lock, flags);\r\n}\r\nstatic int __vdc_tx_trigger(struct vdc_port *port)\r\n{\r\nstruct vio_dring_state *dr = &port->vio.drings[VIO_DRIVER_TX_RING];\r\nstruct vio_dring_data hdr = {\r\n.tag = {\r\n.type = VIO_TYPE_DATA,\r\n.stype = VIO_SUBTYPE_INFO,\r\n.stype_env = VIO_DRING_DATA,\r\n.sid = vio_send_sid(&port->vio),\r\n},\r\n.dring_ident = dr->ident,\r\n.start_idx = dr->prod,\r\n.end_idx = dr->prod,\r\n};\r\nint err, delay;\r\nhdr.seq = dr->snd_nxt;\r\ndelay = 1;\r\ndo {\r\nerr = vio_ldc_send(&port->vio, &hdr, sizeof(hdr));\r\nif (err > 0) {\r\ndr->snd_nxt++;\r\nbreak;\r\n}\r\nudelay(delay);\r\nif ((delay <<= 1) > 128)\r\ndelay = 128;\r\n} while (err == -EAGAIN);\r\nreturn err;\r\n}\r\nstatic int __send_request(struct request *req)\r\n{\r\nstruct vdc_port *port = req->rq_disk->private_data;\r\nstruct vio_dring_state *dr = &port->vio.drings[VIO_DRIVER_TX_RING];\r\nstruct scatterlist sg[port->ring_cookies];\r\nstruct vdc_req_entry *rqe;\r\nstruct vio_disk_desc *desc;\r\nunsigned int map_perm;\r\nint nsg, err, i;\r\nu64 len;\r\nu8 op;\r\nmap_perm = LDC_MAP_SHADOW | LDC_MAP_DIRECT | LDC_MAP_IO;\r\nif (rq_data_dir(req) == READ) {\r\nmap_perm |= LDC_MAP_W;\r\nop = VD_OP_BREAD;\r\n} else {\r\nmap_perm |= LDC_MAP_R;\r\nop = VD_OP_BWRITE;\r\n}\r\nsg_init_table(sg, port->ring_cookies);\r\nnsg = blk_rq_map_sg(req->q, req, sg);\r\nlen = 0;\r\nfor (i = 0; i < nsg; i++)\r\nlen += sg[i].length;\r\nif (unlikely(vdc_tx_dring_avail(dr) < 1)) {\r\nblk_stop_queue(port->disk->queue);\r\nerr = -ENOMEM;\r\ngoto out;\r\n}\r\ndesc = vio_dring_cur(dr);\r\nerr = ldc_map_sg(port->vio.lp, sg, nsg,\r\ndesc->cookies, port->ring_cookies,\r\nmap_perm);\r\nif (err < 0) {\r\nprintk(KERN_ERR PFX "ldc_map_sg() failure, err=%d.\n", err);\r\nreturn err;\r\n}\r\nrqe = &port->rq_arr[dr->prod];\r\nrqe->req = req;\r\ndesc->hdr.ack = VIO_ACK_ENABLE;\r\ndesc->req_id = port->req_id;\r\ndesc->operation = op;\r\nif (port->vdisk_type == VD_DISK_TYPE_DISK) {\r\ndesc->slice = 0xff;\r\n} else {\r\ndesc->slice = 0;\r\n}\r\ndesc->status = ~0;\r\ndesc->offset = (blk_rq_pos(req) << 9) / port->vdisk_block_size;\r\ndesc->size = len;\r\ndesc->ncookies = err;\r\nwmb();\r\ndesc->hdr.state = VIO_DESC_READY;\r\nerr = __vdc_tx_trigger(port);\r\nif (err < 0) {\r\nprintk(KERN_ERR PFX "vdc_tx_trigger() failure, err=%d\n", err);\r\n} else {\r\nport->req_id++;\r\ndr->prod = (dr->prod + 1) & (VDC_TX_RING_SIZE - 1);\r\n}\r\nout:\r\nreturn err;\r\n}\r\nstatic void do_vdc_request(struct request_queue *q)\r\n{\r\nwhile (1) {\r\nstruct request *req = blk_fetch_request(q);\r\nif (!req)\r\nbreak;\r\nif (__send_request(req) < 0)\r\n__blk_end_request_all(req, -EIO);\r\n}\r\n}\r\nstatic int generic_request(struct vdc_port *port, u8 op, void *buf, int len)\r\n{\r\nstruct vio_dring_state *dr;\r\nstruct vio_completion comp;\r\nstruct vio_disk_desc *desc;\r\nunsigned int map_perm;\r\nunsigned long flags;\r\nint op_len, err;\r\nvoid *req_buf;\r\nif (!(((u64)1 << ((u64)op - 1)) & port->operations))\r\nreturn -EOPNOTSUPP;\r\nswitch (op) {\r\ncase VD_OP_BREAD:\r\ncase VD_OP_BWRITE:\r\ndefault:\r\nreturn -EINVAL;\r\ncase VD_OP_FLUSH:\r\nop_len = 0;\r\nmap_perm = 0;\r\nbreak;\r\ncase VD_OP_GET_WCE:\r\nop_len = sizeof(u32);\r\nmap_perm = LDC_MAP_W;\r\nbreak;\r\ncase VD_OP_SET_WCE:\r\nop_len = sizeof(u32);\r\nmap_perm = LDC_MAP_R;\r\nbreak;\r\ncase VD_OP_GET_VTOC:\r\nop_len = sizeof(struct vio_disk_vtoc);\r\nmap_perm = LDC_MAP_W;\r\nbreak;\r\ncase VD_OP_SET_VTOC:\r\nop_len = sizeof(struct vio_disk_vtoc);\r\nmap_perm = LDC_MAP_R;\r\nbreak;\r\ncase VD_OP_GET_DISKGEOM:\r\nop_len = sizeof(struct vio_disk_geom);\r\nmap_perm = LDC_MAP_W;\r\nbreak;\r\ncase VD_OP_SET_DISKGEOM:\r\nop_len = sizeof(struct vio_disk_geom);\r\nmap_perm = LDC_MAP_R;\r\nbreak;\r\ncase VD_OP_SCSICMD:\r\nop_len = 16;\r\nmap_perm = LDC_MAP_RW;\r\nbreak;\r\ncase VD_OP_GET_DEVID:\r\nop_len = sizeof(struct vio_disk_devid);\r\nmap_perm = LDC_MAP_W;\r\nbreak;\r\ncase VD_OP_GET_EFI:\r\ncase VD_OP_SET_EFI:\r\nreturn -EOPNOTSUPP;\r\nbreak;\r\n};\r\nmap_perm |= LDC_MAP_SHADOW | LDC_MAP_DIRECT | LDC_MAP_IO;\r\nop_len = (op_len + 7) & ~7;\r\nreq_buf = kzalloc(op_len, GFP_KERNEL);\r\nif (!req_buf)\r\nreturn -ENOMEM;\r\nif (len > op_len)\r\nlen = op_len;\r\nif (map_perm & LDC_MAP_R)\r\nmemcpy(req_buf, buf, len);\r\nspin_lock_irqsave(&port->vio.lock, flags);\r\ndr = &port->vio.drings[VIO_DRIVER_TX_RING];\r\ndesc = vio_dring_cur(dr);\r\nerr = ldc_map_single(port->vio.lp, req_buf, op_len,\r\ndesc->cookies, port->ring_cookies,\r\nmap_perm);\r\nif (err < 0) {\r\nspin_unlock_irqrestore(&port->vio.lock, flags);\r\nkfree(req_buf);\r\nreturn err;\r\n}\r\ninit_completion(&comp.com);\r\ncomp.waiting_for = WAITING_FOR_GEN_CMD;\r\nport->vio.cmp = &comp;\r\ndesc->hdr.ack = VIO_ACK_ENABLE;\r\ndesc->req_id = port->req_id;\r\ndesc->operation = op;\r\ndesc->slice = 0;\r\ndesc->status = ~0;\r\ndesc->offset = 0;\r\ndesc->size = op_len;\r\ndesc->ncookies = err;\r\nwmb();\r\ndesc->hdr.state = VIO_DESC_READY;\r\nerr = __vdc_tx_trigger(port);\r\nif (err >= 0) {\r\nport->req_id++;\r\ndr->prod = (dr->prod + 1) & (VDC_TX_RING_SIZE - 1);\r\nspin_unlock_irqrestore(&port->vio.lock, flags);\r\nwait_for_completion(&comp.com);\r\nerr = comp.err;\r\n} else {\r\nport->vio.cmp = NULL;\r\nspin_unlock_irqrestore(&port->vio.lock, flags);\r\n}\r\nif (map_perm & LDC_MAP_W)\r\nmemcpy(buf, req_buf, len);\r\nkfree(req_buf);\r\nreturn err;\r\n}\r\nstatic int __devinit vdc_alloc_tx_ring(struct vdc_port *port)\r\n{\r\nstruct vio_dring_state *dr = &port->vio.drings[VIO_DRIVER_TX_RING];\r\nunsigned long len, entry_size;\r\nint ncookies;\r\nvoid *dring;\r\nentry_size = sizeof(struct vio_disk_desc) +\r\n(sizeof(struct ldc_trans_cookie) * port->ring_cookies);\r\nlen = (VDC_TX_RING_SIZE * entry_size);\r\nncookies = VIO_MAX_RING_COOKIES;\r\ndring = ldc_alloc_exp_dring(port->vio.lp, len,\r\ndr->cookies, &ncookies,\r\n(LDC_MAP_SHADOW |\r\nLDC_MAP_DIRECT |\r\nLDC_MAP_RW));\r\nif (IS_ERR(dring))\r\nreturn PTR_ERR(dring);\r\ndr->base = dring;\r\ndr->entry_size = entry_size;\r\ndr->num_entries = VDC_TX_RING_SIZE;\r\ndr->prod = dr->cons = 0;\r\ndr->pending = VDC_TX_RING_SIZE;\r\ndr->ncookies = ncookies;\r\nreturn 0;\r\n}\r\nstatic void vdc_free_tx_ring(struct vdc_port *port)\r\n{\r\nstruct vio_dring_state *dr = &port->vio.drings[VIO_DRIVER_TX_RING];\r\nif (dr->base) {\r\nldc_free_exp_dring(port->vio.lp, dr->base,\r\n(dr->entry_size * dr->num_entries),\r\ndr->cookies, dr->ncookies);\r\ndr->base = NULL;\r\ndr->entry_size = 0;\r\ndr->num_entries = 0;\r\ndr->pending = 0;\r\ndr->ncookies = 0;\r\n}\r\n}\r\nstatic int probe_disk(struct vdc_port *port)\r\n{\r\nstruct vio_completion comp;\r\nstruct request_queue *q;\r\nstruct gendisk *g;\r\nint err;\r\ninit_completion(&comp.com);\r\ncomp.err = 0;\r\ncomp.waiting_for = WAITING_FOR_LINK_UP;\r\nport->vio.cmp = &comp;\r\nvio_port_up(&port->vio);\r\nwait_for_completion(&comp.com);\r\nif (comp.err)\r\nreturn comp.err;\r\nerr = generic_request(port, VD_OP_GET_VTOC,\r\n&port->label, sizeof(port->label));\r\nif (err < 0) {\r\nprintk(KERN_ERR PFX "VD_OP_GET_VTOC returns error %d\n", err);\r\nreturn err;\r\n}\r\nerr = generic_request(port, VD_OP_GET_DISKGEOM,\r\n&port->geom, sizeof(port->geom));\r\nif (err < 0) {\r\nprintk(KERN_ERR PFX "VD_OP_GET_DISKGEOM returns "\r\n"error %d\n", err);\r\nreturn err;\r\n}\r\nport->vdisk_size = ((u64)port->geom.num_cyl *\r\n(u64)port->geom.num_hd *\r\n(u64)port->geom.num_sec);\r\nq = blk_init_queue(do_vdc_request, &port->vio.lock);\r\nif (!q) {\r\nprintk(KERN_ERR PFX "%s: Could not allocate queue.\n",\r\nport->vio.name);\r\nreturn -ENOMEM;\r\n}\r\ng = alloc_disk(1 << PARTITION_SHIFT);\r\nif (!g) {\r\nprintk(KERN_ERR PFX "%s: Could not allocate gendisk.\n",\r\nport->vio.name);\r\nblk_cleanup_queue(q);\r\nreturn -ENOMEM;\r\n}\r\nport->disk = g;\r\nblk_queue_max_segments(q, port->ring_cookies);\r\nblk_queue_max_hw_sectors(q, port->max_xfer_size);\r\ng->major = vdc_major;\r\ng->first_minor = port->vio.vdev->dev_no << PARTITION_SHIFT;\r\nstrcpy(g->disk_name, port->disk_name);\r\ng->fops = &vdc_fops;\r\ng->queue = q;\r\ng->private_data = port;\r\ng->driverfs_dev = &port->vio.vdev->dev;\r\nset_capacity(g, port->vdisk_size);\r\nprintk(KERN_INFO PFX "%s: %u sectors (%u MB)\n",\r\ng->disk_name,\r\nport->vdisk_size, (port->vdisk_size >> (20 - 9)));\r\nadd_disk(g);\r\nreturn 0;\r\n}\r\nstatic void __devinit print_version(void)\r\n{\r\nstatic int version_printed;\r\nif (version_printed++ == 0)\r\nprintk(KERN_INFO "%s", version);\r\n}\r\nstatic int __devinit vdc_port_probe(struct vio_dev *vdev,\r\nconst struct vio_device_id *id)\r\n{\r\nstruct mdesc_handle *hp;\r\nstruct vdc_port *port;\r\nint err;\r\nprint_version();\r\nhp = mdesc_grab();\r\nerr = -ENODEV;\r\nif ((vdev->dev_no << PARTITION_SHIFT) & ~(u64)MINORMASK) {\r\nprintk(KERN_ERR PFX "Port id [%llu] too large.\n",\r\nvdev->dev_no);\r\ngoto err_out_release_mdesc;\r\n}\r\nport = kzalloc(sizeof(*port), GFP_KERNEL);\r\nerr = -ENOMEM;\r\nif (!port) {\r\nprintk(KERN_ERR PFX "Cannot allocate vdc_port.\n");\r\ngoto err_out_release_mdesc;\r\n}\r\nif (vdev->dev_no >= 26)\r\nsnprintf(port->disk_name, sizeof(port->disk_name),\r\nVDCBLK_NAME "%c%c",\r\n'a' + ((int)vdev->dev_no / 26) - 1,\r\n'a' + ((int)vdev->dev_no % 26));\r\nelse\r\nsnprintf(port->disk_name, sizeof(port->disk_name),\r\nVDCBLK_NAME "%c", 'a' + ((int)vdev->dev_no % 26));\r\nerr = vio_driver_init(&port->vio, vdev, VDEV_DISK,\r\nvdc_versions, ARRAY_SIZE(vdc_versions),\r\n&vdc_vio_ops, port->disk_name);\r\nif (err)\r\ngoto err_out_free_port;\r\nport->vdisk_block_size = 512;\r\nport->max_xfer_size = ((128 * 1024) / port->vdisk_block_size);\r\nport->ring_cookies = ((port->max_xfer_size *\r\nport->vdisk_block_size) / PAGE_SIZE) + 2;\r\nerr = vio_ldc_alloc(&port->vio, &vdc_ldc_cfg, port);\r\nif (err)\r\ngoto err_out_free_port;\r\nerr = vdc_alloc_tx_ring(port);\r\nif (err)\r\ngoto err_out_free_ldc;\r\nerr = probe_disk(port);\r\nif (err)\r\ngoto err_out_free_tx_ring;\r\ndev_set_drvdata(&vdev->dev, port);\r\nmdesc_release(hp);\r\nreturn 0;\r\nerr_out_free_tx_ring:\r\nvdc_free_tx_ring(port);\r\nerr_out_free_ldc:\r\nvio_ldc_free(&port->vio);\r\nerr_out_free_port:\r\nkfree(port);\r\nerr_out_release_mdesc:\r\nmdesc_release(hp);\r\nreturn err;\r\n}\r\nstatic int vdc_port_remove(struct vio_dev *vdev)\r\n{\r\nstruct vdc_port *port = dev_get_drvdata(&vdev->dev);\r\nif (port) {\r\ndel_timer_sync(&port->vio.timer);\r\nvdc_free_tx_ring(port);\r\nvio_ldc_free(&port->vio);\r\ndev_set_drvdata(&vdev->dev, NULL);\r\nkfree(port);\r\n}\r\nreturn 0;\r\n}\r\nstatic int __init vdc_init(void)\r\n{\r\nint err;\r\nerr = register_blkdev(0, VDCBLK_NAME);\r\nif (err < 0)\r\ngoto out_err;\r\nvdc_major = err;\r\nerr = vio_register_driver(&vdc_port_driver);\r\nif (err)\r\ngoto out_unregister_blkdev;\r\nreturn 0;\r\nout_unregister_blkdev:\r\nunregister_blkdev(vdc_major, VDCBLK_NAME);\r\nvdc_major = 0;\r\nout_err:\r\nreturn err;\r\n}\r\nstatic void __exit vdc_exit(void)\r\n{\r\nvio_unregister_driver(&vdc_port_driver);\r\nunregister_blkdev(vdc_major, VDCBLK_NAME);\r\n}
