int __first_cpu(const cpumask_t *srcp)\r\n{\r\nreturn min_t(int, NR_CPUS, find_first_bit(srcp->bits, NR_CPUS));\r\n}\r\nint __next_cpu(int n, const cpumask_t *srcp)\r\n{\r\nreturn min_t(int, NR_CPUS, find_next_bit(srcp->bits, NR_CPUS, n+1));\r\n}\r\nint __next_cpu_nr(int n, const cpumask_t *srcp)\r\n{\r\nreturn min_t(int, nr_cpu_ids,\r\nfind_next_bit(srcp->bits, nr_cpu_ids, n+1));\r\n}\r\nint cpumask_next_and(int n, const struct cpumask *src1p,\r\nconst struct cpumask *src2p)\r\n{\r\nwhile ((n = cpumask_next(n, src1p)) < nr_cpu_ids)\r\nif (cpumask_test_cpu(n, src2p))\r\nbreak;\r\nreturn n;\r\n}\r\nint cpumask_any_but(const struct cpumask *mask, unsigned int cpu)\r\n{\r\nunsigned int i;\r\ncpumask_check(cpu);\r\nfor_each_cpu(i, mask)\r\nif (i != cpu)\r\nbreak;\r\nreturn i;\r\n}\r\nbool alloc_cpumask_var_node(cpumask_var_t *mask, gfp_t flags, int node)\r\n{\r\n*mask = kmalloc_node(cpumask_size(), flags, node);\r\n#ifdef CONFIG_DEBUG_PER_CPU_MAPS\r\nif (!*mask) {\r\nprintk(KERN_ERR "=> alloc_cpumask_var: failed!\n");\r\ndump_stack();\r\n}\r\n#endif\r\nif (*mask) {\r\nunsigned char *ptr = (unsigned char *)cpumask_bits(*mask);\r\nunsigned int tail;\r\ntail = BITS_TO_LONGS(NR_CPUS - nr_cpumask_bits) * sizeof(long);\r\nmemset(ptr + cpumask_size() - tail, 0, tail);\r\n}\r\nreturn *mask != NULL;\r\n}\r\nbool zalloc_cpumask_var_node(cpumask_var_t *mask, gfp_t flags, int node)\r\n{\r\nreturn alloc_cpumask_var_node(mask, flags | __GFP_ZERO, node);\r\n}\r\nbool alloc_cpumask_var(cpumask_var_t *mask, gfp_t flags)\r\n{\r\nreturn alloc_cpumask_var_node(mask, flags, NUMA_NO_NODE);\r\n}\r\nbool zalloc_cpumask_var(cpumask_var_t *mask, gfp_t flags)\r\n{\r\nreturn alloc_cpumask_var(mask, flags | __GFP_ZERO);\r\n}\r\nvoid __init alloc_bootmem_cpumask_var(cpumask_var_t *mask)\r\n{\r\n*mask = alloc_bootmem(cpumask_size());\r\n}\r\nvoid free_cpumask_var(cpumask_var_t mask)\r\n{\r\nkfree(mask);\r\n}\r\nvoid __init free_bootmem_cpumask_var(cpumask_var_t mask)\r\n{\r\nfree_bootmem((unsigned long)mask, cpumask_size());\r\n}
