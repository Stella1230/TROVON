static int wsp_pcie_read_config(struct pci_bus *bus, unsigned int devfn,\r\nint offset, int len, u32 *val)\r\n{\r\nstruct pci_controller *hose;\r\nint suboff;\r\nu64 addr;\r\nhose = pci_bus_to_host(bus);\r\nif (hose == NULL)\r\nreturn PCIBIOS_DEVICE_NOT_FOUND;\r\nif (offset >= 0x1000)\r\nreturn PCIBIOS_BAD_REGISTER_NUMBER;\r\naddr = PCIE_REG_CA_ENABLE |\r\n((u64)bus->number) << PCIE_REG_CA_BUS_SHIFT |\r\n((u64)devfn) << PCIE_REG_CA_FUNC_SHIFT |\r\n((u64)offset & ~3) << PCIE_REG_CA_REG_SHIFT;\r\nsuboff = offset & 3;\r\nswitch (len) {\r\ncase 1:\r\naddr |= (0x8ul >> suboff) << PCIE_REG_CA_BE_SHIFT;\r\nout_be64(hose->cfg_data + PCIE_REG_CONFIG_ADDRESS, addr);\r\n*val = (in_le32(hose->cfg_data + PCIE_REG_CONFIG_DATA)\r\n>> (suboff << 3)) & 0xff;\r\ncfg_debug("read 1 %02x:%02x:%02x + %02x/%x addr=0x%llx val=%02x\n",\r\nbus->number, devfn >> 3, devfn & 7,\r\noffset, suboff, addr, *val);\r\nbreak;\r\ncase 2:\r\naddr |= (0xcul >> suboff) << PCIE_REG_CA_BE_SHIFT;\r\nout_be64(hose->cfg_data + PCIE_REG_CONFIG_ADDRESS, addr);\r\n*val = (in_le32(hose->cfg_data + PCIE_REG_CONFIG_DATA)\r\n>> (suboff << 3)) & 0xffff;\r\ncfg_debug("read 2 %02x:%02x:%02x + %02x/%x addr=0x%llx val=%04x\n",\r\nbus->number, devfn >> 3, devfn & 7,\r\noffset, suboff, addr, *val);\r\nbreak;\r\ndefault:\r\naddr |= 0xful << PCIE_REG_CA_BE_SHIFT;\r\nout_be64(hose->cfg_data + PCIE_REG_CONFIG_ADDRESS, addr);\r\n*val = in_le32(hose->cfg_data + PCIE_REG_CONFIG_DATA);\r\ncfg_debug("read 4 %02x:%02x:%02x + %02x/%x addr=0x%llx val=%08x\n",\r\nbus->number, devfn >> 3, devfn & 7,\r\noffset, suboff, addr, *val);\r\nbreak;\r\n}\r\nreturn PCIBIOS_SUCCESSFUL;\r\n}\r\nstatic int wsp_pcie_write_config(struct pci_bus *bus, unsigned int devfn,\r\nint offset, int len, u32 val)\r\n{\r\nstruct pci_controller *hose;\r\nint suboff;\r\nu64 addr;\r\nhose = pci_bus_to_host(bus);\r\nif (hose == NULL)\r\nreturn PCIBIOS_DEVICE_NOT_FOUND;\r\nif (offset >= 0x1000)\r\nreturn PCIBIOS_BAD_REGISTER_NUMBER;\r\naddr = PCIE_REG_CA_ENABLE |\r\n((u64)bus->number) << PCIE_REG_CA_BUS_SHIFT |\r\n((u64)devfn) << PCIE_REG_CA_FUNC_SHIFT |\r\n((u64)offset & ~3) << PCIE_REG_CA_REG_SHIFT;\r\nsuboff = offset & 3;\r\nswitch (len) {\r\ncase 1:\r\naddr |= (0x8ul >> suboff) << PCIE_REG_CA_BE_SHIFT;\r\nval <<= suboff << 3;\r\nout_be64(hose->cfg_data + PCIE_REG_CONFIG_ADDRESS, addr);\r\nout_le32(hose->cfg_data + PCIE_REG_CONFIG_DATA, val);\r\ncfg_debug("write 1 %02x:%02x:%02x + %02x/%x addr=0x%llx val=%02x\n",\r\nbus->number, devfn >> 3, devfn & 7,\r\noffset, suboff, addr, val);\r\nbreak;\r\ncase 2:\r\naddr |= (0xcul >> suboff) << PCIE_REG_CA_BE_SHIFT;\r\nval <<= suboff << 3;\r\nout_be64(hose->cfg_data + PCIE_REG_CONFIG_ADDRESS, addr);\r\nout_le32(hose->cfg_data + PCIE_REG_CONFIG_DATA, val);\r\ncfg_debug("write 2 %02x:%02x:%02x + %02x/%x addr=0x%llx val=%04x\n",\r\nbus->number, devfn >> 3, devfn & 7,\r\noffset, suboff, addr, val);\r\nbreak;\r\ndefault:\r\naddr |= 0xful << PCIE_REG_CA_BE_SHIFT;\r\nout_be64(hose->cfg_data + PCIE_REG_CONFIG_ADDRESS, addr);\r\nout_le32(hose->cfg_data + PCIE_REG_CONFIG_DATA, val);\r\ncfg_debug("write 4 %02x:%02x:%02x + %02x/%x addr=0x%llx val=%08x\n",\r\nbus->number, devfn >> 3, devfn & 7,\r\noffset, suboff, addr, val);\r\nbreak;\r\n}\r\nreturn PCIBIOS_SUCCESSFUL;\r\n}\r\nstatic int tce_build_wsp(struct iommu_table *tbl, long index, long npages,\r\nunsigned long uaddr, enum dma_data_direction direction,\r\nstruct dma_attrs *attrs)\r\n{\r\nstruct wsp_dma_table *ptbl = container_of(tbl,\r\nstruct wsp_dma_table,\r\ntable);\r\nu64 proto_tce;\r\nu64 *tcep;\r\nu64 rpn;\r\nproto_tce = TCE_PCI_READ;\r\n#ifdef CONFIG_WSP_DD1_WORKAROUND_DD1_TCE_BUGS\r\nproto_tce |= TCE_PCI_WRITE;\r\n#else\r\nif (direction != DMA_TO_DEVICE)\r\nproto_tce |= TCE_PCI_WRITE;\r\n#endif\r\nwhile (npages--) {\r\ntcep = (u64 *)page_address(ptbl->tces[index >> 16]);\r\ntcep += (index & 0xffff);\r\nrpn = __pa(uaddr) >> TCE_SHIFT;\r\n*tcep = proto_tce | (rpn & TCE_RPN_MASK) << TCE_RPN_SHIFT;\r\ndma_debug("[DMA] TCE %p set to 0x%016llx (dma addr: 0x%lx)\n",\r\ntcep, *tcep, (tbl->it_offset + index) << IOMMU_PAGE_SHIFT);\r\nuaddr += TCE_PAGE_SIZE;\r\nindex++;\r\n}\r\nreturn 0;\r\n}\r\nstatic void tce_free_wsp(struct iommu_table *tbl, long index, long npages)\r\n{\r\nstruct wsp_dma_table *ptbl = container_of(tbl,\r\nstruct wsp_dma_table,\r\ntable);\r\n#ifndef CONFIG_WSP_DD1_WORKAROUND_DD1_TCE_BUGS\r\nstruct pci_controller *hose = ptbl->phb->hose;\r\n#endif\r\nu64 *tcep;\r\nwhile (npages--) {\r\ntcep = (u64 *)page_address(ptbl->tces[index >> 16]);\r\ntcep += (index & 0xffff);\r\ndma_debug("[DMA] TCE %p cleared\n", tcep);\r\n*tcep = 0;\r\n#ifndef CONFIG_WSP_DD1_WORKAROUND_DD1_TCE_BUGS\r\nout_be64(hose->cfg_data + PCIE_REG_TCE_KILL,\r\nPCIE_REG_TCEKILL_SINGLE | PCIE_REG_TCEKILL_PS_4K |\r\n(__pa(tcep) & PCIE_REG_TCEKILL_ADDR_MASK));\r\n#endif\r\nindex++;\r\n}\r\n}\r\nstatic struct wsp_dma_table *wsp_pci_create_dma32_table(struct wsp_phb *phb,\r\nunsigned int region,\r\nstruct pci_dev *validate)\r\n{\r\nstruct pci_controller *hose = phb->hose;\r\nunsigned long size = phb->dma32_region_size;\r\nunsigned long addr = phb->dma32_region_size * region + phb->dma32_base;\r\nstruct wsp_dma_table *tbl;\r\nint tvts_per_table, i, tvt, nid;\r\nunsigned long flags;\r\nnid = of_node_to_nid(phb->hose->dn);\r\ntvts_per_table = size / 0x10000000;\r\nif (tvts_per_table == 0)\r\ntvts_per_table = 1;\r\ntvt = region * tvts_per_table;\r\npr_debug(" Region : %d\n", region);\r\npr_debug(" DMA range : 0x%08lx..0x%08lx\n", addr, addr + size - 1);\r\npr_debug(" Number of TVTs : %d\n", tvts_per_table);\r\npr_debug(" Base TVT : %d\n", tvt);\r\npr_debug(" Node : %d\n", nid);\r\ntbl = kzalloc_node(sizeof(struct wsp_dma_table), GFP_KERNEL, nid);\r\nif (!tbl)\r\nreturn ERR_PTR(-ENOMEM);\r\ntbl->phb = phb;\r\nfor (i = 0; i < tvts_per_table; i++) {\r\nu64 tvt_data1, tvt_data0;\r\ntbl->tces[i] = alloc_pages_node(nid, GFP_KERNEL, get_order(0x80000));\r\nif (tbl->tces[i] == NULL)\r\ngoto fail;\r\nmemset(page_address(tbl->tces[i]), 0, 0x80000);\r\npr_debug(" TCE table %d at : %p\n", i, page_address(tbl->tces[i]));\r\ntvt_data0 = 2ull << IODA_TVT0_TCE_TABLE_SIZE_SHIFT;\r\ntvt_data1 = 1ull << IODA_TVT1_IO_PAGE_SIZE_SHIFT;\r\ntvt_data0 |= __pa(page_address(tbl->tces[i])) << IODA_TVT0_TTA_SHIFT;\r\nif (validate) {\r\ntvt_data0 |= IODA_TVT0_BUSNUM_VALID_MASK;\r\ntvt_data0 |= validate->bus->number;\r\ntvt_data1 |= IODA_TVT1_DEVNUM_VALID;\r\ntvt_data1 |= ((u64)PCI_SLOT(validate->devfn))\r\n<< IODA_TVT1_DEVNUM_VALUE_SHIFT;\r\ntvt_data1 |= IODA_TVT1_FUNCNUM_VALID;\r\ntvt_data1 |= ((u64)PCI_FUNC(validate->devfn))\r\n<< IODA_TVT1_FUNCNUM_VALUE_SHIFT;\r\n}\r\nspin_lock_irqsave(&phb->lock, flags);\r\nout_be64(hose->cfg_data + PCIE_REG_IODA_ADDR,\r\n(tvt + i) | PCIE_REG_IODA_AD_TBL_TVT);\r\nout_be64(hose->cfg_data + PCIE_REG_IODA_DATA1, tvt_data1);\r\nout_be64(hose->cfg_data + PCIE_REG_IODA_DATA0, tvt_data0);\r\nspin_unlock_irqrestore(&phb->lock, flags);\r\n}\r\ntbl->table.it_blocksize = 16;\r\ntbl->table.it_offset = addr >> IOMMU_PAGE_SHIFT;\r\ntbl->table.it_size = size >> IOMMU_PAGE_SHIFT;\r\niommu_init_table(&tbl->table, nid);\r\nlist_add(&tbl->link, &phb->dma_tables);\r\nreturn tbl;\r\nfail:\r\npr_debug(" Failed to allocate a 256M TCE table !\n");\r\nfor (i = 0; i < tvts_per_table; i++)\r\nif (tbl->tces[i])\r\n__free_pages(tbl->tces[i], get_order(0x80000));\r\nkfree(tbl);\r\nreturn ERR_PTR(-ENOMEM);\r\n}\r\nstatic void __devinit wsp_pci_dma_dev_setup(struct pci_dev *pdev)\r\n{\r\nstruct dev_archdata *archdata = &pdev->dev.archdata;\r\nstruct pci_controller *hose = pci_bus_to_host(pdev->bus);\r\nstruct wsp_phb *phb = hose->private_data;\r\nstruct wsp_dma_table *table = NULL;\r\nunsigned long flags;\r\nint i;\r\nif (pdev->hdr_type == PCI_HEADER_TYPE_BRIDGE)\r\nreturn;\r\npr_debug("%s: Setting up DMA...\n", pci_name(pdev));\r\nspin_lock_irqsave(&phb->lock, flags);\r\nif (phb->dma32_num_regions == 1) {\r\nspin_unlock_irqrestore(&phb->lock, flags);\r\nif (list_empty(&phb->dma_tables))\r\ntable = wsp_pci_create_dma32_table(phb, 0, NULL);\r\nelse\r\ntable = list_first_entry(&phb->dma_tables,\r\nstruct wsp_dma_table,\r\nlink);\r\n} else {\r\nfor (i = 0; i < phb->dma32_num_regions && !table; i++) {\r\nif (__test_and_set_bit(i, &phb->dma32_map))\r\ncontinue;\r\nspin_unlock_irqrestore(&phb->lock, flags);\r\ntable = wsp_pci_create_dma32_table(phb, i, pdev);\r\n}\r\n}\r\nif (IS_ERR(table)) {\r\npr_err("%s: Failed to create DMA table, err %ld !\n",\r\npci_name(pdev), PTR_ERR(table));\r\nreturn;\r\n}\r\nif (table) {\r\npr_info("%s: Setup iommu: 32-bit DMA region 0x%08lx..0x%08lx\n",\r\npci_name(pdev),\r\ntable->table.it_offset << IOMMU_PAGE_SHIFT,\r\n(table->table.it_offset << IOMMU_PAGE_SHIFT)\r\n+ phb->dma32_region_size - 1);\r\narchdata->dma_data.iommu_table_base = &table->table;\r\nreturn;\r\n}\r\nspin_unlock_irqrestore(&phb->lock, flags);\r\npr_err("%s: Out of DMA space !\n", pci_name(pdev));\r\n}\r\nstatic void __init wsp_pcie_configure_hw(struct pci_controller *hose)\r\n{\r\nu64 val;\r\nint i;\r\n#define DUMP_REG(x) \\r\npr_debug("%-30s : 0x%016llx\n", #x, in_be64(hose->cfg_data + x))\r\nval = in_be64(hose->cfg_data + PCIE_REG_SYS_CFG1);\r\npr_debug("PCI-E SYS_CFG1 : 0x%llx\n", val);\r\nout_be64(hose->cfg_data + PCIE_REG_SYS_CFG1,\r\n(val & ~PCIE_REG_SYS_CFG1_CLASS_CODE) | (PCI_CLASS_BRIDGE_PCI << 8));\r\npr_debug("PCI-E SYS_CFG1 : 0x%llx\n", in_be64(hose->cfg_data + PCIE_REG_SYS_CFG1));\r\n#ifdef CONFIG_WSP_DD1_WORKAROUND_DD1_TCE_BUGS\r\nout_be64(hose->cfg_data + 0xe50,\r\nin_be64(hose->cfg_data + 0xe50) | (3ull << 62));\r\nprintk("PCI-E DEBUG CONTROL 5 = 0x%llx\n", in_be64(hose->cfg_data + 0xe50));\r\n#endif\r\nout_be64(hose->cfg_data + PCIE_REG_IO_BASE_ADDR, hose->io_base_phys);\r\nout_be64(hose->cfg_data + PCIE_REG_IO_BASE_MASK,\r\n(~(hose->io_resource.end - hose->io_resource.start)) &\r\n0x3fffffff000ul);\r\nout_be64(hose->cfg_data + PCIE_REG_IO_START_ADDR, 0 | 1);\r\nout_be64(hose->cfg_data + PCIE_REG_M32A_BASE_ADDR,\r\nhose->mem_resources[0].start);\r\nprintk("Want to write to M32A_BASE_MASK : 0x%llx\n",\r\n(~(hose->mem_resources[0].end -\r\nhose->mem_resources[0].start)) & 0x3ffffff0000ul);\r\nout_be64(hose->cfg_data + PCIE_REG_M32A_BASE_MASK,\r\n(~(hose->mem_resources[0].end -\r\nhose->mem_resources[0].start)) & 0x3ffffff0000ul);\r\nout_be64(hose->cfg_data + PCIE_REG_M32A_START_ADDR,\r\n(hose->mem_resources[0].start - hose->pci_mem_offset) | 1);\r\nfor (i = 0; i < IODA_TVT_COUNT; i++) {\r\nout_be64(hose->cfg_data + PCIE_REG_IODA_ADDR,\r\nPCIE_REG_IODA_AD_TBL_TVT | i);\r\nout_be64(hose->cfg_data + PCIE_REG_IODA_DATA1, 0);\r\nout_be64(hose->cfg_data + PCIE_REG_IODA_DATA0, 0);\r\n}\r\nout_be64(hose->cfg_data + PCIE_REG_PHB_CONFIG,\r\nin_be64(hose->cfg_data + PCIE_REG_PHB_CONFIG) |\r\nPCIE_REG_PHBC_64B_TCE_EN);\r\nval = PCIE_REG_PHBC_32BIT_MSI_EN |\r\nPCIE_REG_PHBC_IO_EN |\r\nPCIE_REG_PHBC_64BIT_MSI_EN |\r\nPCIE_REG_PHBC_M32A_EN;\r\nif (iommu_is_off)\r\nval |= PCIE_REG_PHBC_DMA_XLATE_BYPASS;\r\npr_debug("Will write config: 0x%llx\n", val);\r\nout_be64(hose->cfg_data + PCIE_REG_PHB_CONFIG, val);\r\nout_be64(hose->cfg_data + 0xe00,\r\nin_be64(hose->cfg_data + 0xe00) | 0x0008000000000000ull);\r\nout_be64(hose->cfg_data + PCIE_REG_DMA_ERR_STATUS_MASK, 0x8000000000000000ull);\r\nout_be64(hose->cfg_data + PCIE_REG_DMA_ERR1_STATUS_MASK, 0x8000000000000000ull);\r\nout_be64(hose->cfg_data + PCIE_UTL_SYS_BUS_AGENT_ERR_SEV, 0);\r\nout_be64(hose->cfg_data + PCIE_UTL_RC_ERR_SEVERITY, 0);\r\nout_be64(hose->cfg_data + PCIE_UTL_PCIE_PORT_ERROR_SEV, 0);\r\nout_be64(hose->cfg_data + PCIE_UTL_SYS_BUS_AGENT_IRQ_EN, 0xffffffff00000000ull);\r\nout_be64(hose->cfg_data + PCIE_UTL_PCIE_PORT_IRQ_EN, 0xff5fffff00000000ull);\r\nout_be64(hose->cfg_data + PCIE_UTL_EP_ERR_IRQ_EN, 0xffffffff00000000ull);\r\nDUMP_REG(PCIE_REG_IO_BASE_ADDR);\r\nDUMP_REG(PCIE_REG_IO_BASE_MASK);\r\nDUMP_REG(PCIE_REG_IO_START_ADDR);\r\nDUMP_REG(PCIE_REG_M32A_BASE_ADDR);\r\nDUMP_REG(PCIE_REG_M32A_BASE_MASK);\r\nDUMP_REG(PCIE_REG_M32A_START_ADDR);\r\nDUMP_REG(PCIE_REG_M32B_BASE_ADDR);\r\nDUMP_REG(PCIE_REG_M32B_BASE_MASK);\r\nDUMP_REG(PCIE_REG_M32B_START_ADDR);\r\nDUMP_REG(PCIE_REG_M64_BASE_ADDR);\r\nDUMP_REG(PCIE_REG_M64_BASE_MASK);\r\nDUMP_REG(PCIE_REG_M64_START_ADDR);\r\nDUMP_REG(PCIE_REG_PHB_CONFIG);\r\n}\r\nstatic void wsp_pci_wait_io_idle(struct wsp_phb *phb, unsigned long port)\r\n{\r\nu64 val;\r\nint i;\r\nfor (i = 0; i < 10000; i++) {\r\nval = in_be64(phb->hose->cfg_data + 0xe08);\r\nif ((val & 0x1900000000000000ull) == 0x0100000000000000ull)\r\nreturn;\r\nudelay(1);\r\n}\r\npr_warning("PCI IO timeout on domain %d port 0x%lx\n",\r\nphb->hose->global_number, port);\r\n}\r\nstatic int __init wsp_setup_one_phb(struct device_node *np)\r\n{\r\nstruct pci_controller *hose;\r\nstruct wsp_phb *phb;\r\npr_info("PCI: Setting up PCIe host bridge 0x%s\n", np->full_name);\r\nphb = zalloc_maybe_bootmem(sizeof(struct wsp_phb), GFP_KERNEL);\r\nif (!phb)\r\nreturn -ENOMEM;\r\nhose = pcibios_alloc_controller(np);\r\nif (!hose) {\r\nreturn -ENOMEM;\r\n}\r\nhose->private_data = phb;\r\nphb->hose = hose;\r\nINIT_LIST_HEAD(&phb->dma_tables);\r\nspin_lock_init(&phb->lock);\r\nhose->first_busno = 0;\r\nhose->last_busno = 0xff;\r\nhose->cfg_data = of_iomap(hose->dn, 0);\r\npr_debug("PCIe registers mapped at 0x%p\n", hose->cfg_data);\r\npci_process_bridge_OF_ranges(hose, np, 0);\r\npci_add_flags(PCI_REASSIGN_ALL_BUS | PCI_REASSIGN_ALL_RSRC |\r\nPCI_ENABLE_PROC_DOMAINS);\r\nphb->dma32_base = 0;\r\nphb->dma32_num_regions = NUM_DMA32_REGIONS;\r\nif (phb->dma32_num_regions > MAX_TABLE_TVT_COUNT) {\r\npr_warning("IOMMU: Clamped to %d DMA32 regions\n",\r\nMAX_TABLE_TVT_COUNT);\r\nphb->dma32_num_regions = MAX_TABLE_TVT_COUNT;\r\n}\r\nphb->dma32_region_size = 0x80000000 / phb->dma32_num_regions;\r\nBUG_ON(!is_power_of_2(phb->dma32_region_size));\r\nhose->ops = &wsp_pcie_pci_ops;\r\nwsp_pcie_configure_hw(hose);\r\niowa_register_bus(hose, &wsp_pci_iops, NULL, phb);\r\n#ifdef CONFIG_PCI_MSI\r\nwsp_setup_phb_msi(hose);\r\n#endif\r\nlist_add(&phb->all, &wsp_phbs);\r\nreturn 0;\r\n}\r\nvoid __init wsp_setup_pci(void)\r\n{\r\nstruct device_node *np;\r\nint rc;\r\nfor_each_compatible_node(np, "pciex", PCIE_COMPATIBLE) {\r\nrc = wsp_setup_one_phb(np);\r\nif (rc)\r\npr_err("Failed to setup PCIe bridge %s, rc=%d\n",\r\nnp->full_name, rc);\r\n}\r\npci_devs_phb_init();\r\nif (iommu_is_off) {\r\npr_info("PCI-E: Disabled TCEs, using direct DMA\n");\r\nset_pci_dma_ops(&dma_direct_ops);\r\n} else {\r\nppc_md.pci_dma_dev_setup = wsp_pci_dma_dev_setup;\r\nppc_md.tce_build = tce_build_wsp;\r\nppc_md.tce_free = tce_free_wsp;\r\nset_pci_dma_ops(&dma_iommu_ops);\r\n}\r\n}\r\nstatic int __init wsp_pci_get_err_irq_no_dt(struct device_node *np)\r\n{\r\nconst u32 *prop;\r\nint hw_irq;\r\nnp = of_get_next_child(np, NULL);\r\nif (np == NULL)\r\nreturn 0;\r\nprop = of_get_property(np, "interrupt-map", NULL);\r\nif (prop == NULL)\r\nreturn 0;\r\nhw_irq = prop[5] & 0xf;\r\nif (hw_irq < 5)\r\nhw_irq = 4;\r\nelse\r\nhw_irq = 9;\r\nhw_irq |= prop[5] & ~0xf;\r\nerr_debug("PCI: Using 0x%x as error IRQ for %s\n",\r\nhw_irq, np->parent->full_name);\r\nreturn irq_create_mapping(NULL, hw_irq);\r\n}\r\nstatic int wsp_pci_regs_show(struct seq_file *m, void *private)\r\n{\r\nstruct wsp_phb *phb = m->private;\r\nstruct pci_controller *hose = phb->hose;\r\nint i;\r\nfor (i = 0; i < ARRAY_SIZE(wsp_pci_regs); i++) {\r\nif (wsp_pci_regs[i].offset == 0xc08 ||\r\nwsp_pci_regs[i].offset == 0xc10 ||\r\nwsp_pci_regs[i].offset == 0xc38 ||\r\nwsp_pci_regs[i].offset == 0xc40)\r\ncontinue;\r\nseq_printf(m, "0x%03x: 0x%016llx %s\n",\r\nwsp_pci_regs[i].offset,\r\nin_be64(hose->cfg_data + wsp_pci_regs[i].offset),\r\nwsp_pci_regs[i].name);\r\n}\r\nreturn 0;\r\n}\r\nstatic int wsp_pci_regs_open(struct inode *inode, struct file *file)\r\n{\r\nreturn single_open(file, wsp_pci_regs_show, inode->i_private);\r\n}\r\nstatic int wsp_pci_reg_set(void *data, u64 val)\r\n{\r\nout_be64((void __iomem *)data, val);\r\nreturn 0;\r\n}\r\nstatic int wsp_pci_reg_get(void *data, u64 *val)\r\n{\r\n*val = in_be64((void __iomem *)data);\r\nreturn 0;\r\n}\r\nstatic irqreturn_t wsp_pci_err_irq(int irq, void *dev_id)\r\n{\r\nstruct wsp_phb *phb = dev_id;\r\nstruct pci_controller *hose = phb->hose;\r\nirqreturn_t handled = IRQ_NONE;\r\nstruct wsp_pcie_err_log_data ed;\r\npr_err("PCI: Error interrupt on %s (PHB %d)\n",\r\nhose->dn->full_name, hose->global_number);\r\nagain:\r\nmemset(&ed, 0, sizeof(ed));\r\ned.utl_sys_err = in_be64(hose->cfg_data + PCIE_UTL_SYS_BUS_AGENT_STATUS);\r\nif (ed.utl_sys_err)\r\nout_be64(hose->cfg_data + PCIE_UTL_SYS_BUS_AGENT_STATUS, ed.utl_sys_err);\r\ned.utl_port_err = in_be64(hose->cfg_data + PCIE_UTL_PCIE_PORT_STATUS);\r\nif (ed.utl_port_err)\r\nout_be64(hose->cfg_data + PCIE_UTL_PCIE_PORT_STATUS, ed.utl_port_err);\r\ned.utl_rc_err = in_be64(hose->cfg_data + PCIE_UTL_RC_STATUS);\r\nif (ed.utl_rc_err)\r\nout_be64(hose->cfg_data + PCIE_UTL_RC_STATUS, ed.utl_rc_err);\r\ned.phb_err = in_be64(hose->cfg_data + PCIE_REG_PHB_ERR_STATUS);\r\nif (ed.phb_err) {\r\ned.phb_err1 = in_be64(hose->cfg_data + PCIE_REG_PHB_ERR1_STATUS);\r\ned.phb_log0 = in_be64(hose->cfg_data + PCIE_REG_PHB_ERR_LOG_0);\r\ned.phb_log1 = in_be64(hose->cfg_data + PCIE_REG_PHB_ERR_LOG_1);\r\nout_be64(hose->cfg_data + PCIE_REG_PHB_ERR1_STATUS, 0);\r\nout_be64(hose->cfg_data + PCIE_REG_PHB_ERR_STATUS, 0);\r\n}\r\ned.mmio_err = in_be64(hose->cfg_data + PCIE_REG_MMIO_ERR_STATUS);\r\nif (ed.mmio_err) {\r\ned.mmio_err1 = in_be64(hose->cfg_data + PCIE_REG_MMIO_ERR1_STATUS);\r\ned.mmio_log0 = in_be64(hose->cfg_data + PCIE_REG_MMIO_ERR_LOG_0);\r\ned.mmio_log1 = in_be64(hose->cfg_data + PCIE_REG_MMIO_ERR_LOG_1);\r\nout_be64(hose->cfg_data + PCIE_REG_MMIO_ERR1_STATUS, 0);\r\nout_be64(hose->cfg_data + PCIE_REG_MMIO_ERR_STATUS, 0);\r\n}\r\ned.dma_err = in_be64(hose->cfg_data + PCIE_REG_DMA_ERR_STATUS);\r\nif (ed.dma_err) {\r\ned.dma_err1 = in_be64(hose->cfg_data + PCIE_REG_DMA_ERR1_STATUS);\r\ned.dma_log0 = in_be64(hose->cfg_data + PCIE_REG_DMA_ERR_LOG_0);\r\ned.dma_log1 = in_be64(hose->cfg_data + PCIE_REG_DMA_ERR_LOG_1);\r\nout_be64(hose->cfg_data + PCIE_REG_DMA_ERR1_STATUS, 0);\r\nout_be64(hose->cfg_data + PCIE_REG_DMA_ERR_STATUS, 0);\r\n}\r\nif (ed.phb_err) {\r\npr_err(" PHB Error Status : 0x%016llx\n", ed.phb_err);\r\npr_err(" PHB First Error Status: 0x%016llx\n", ed.phb_err1);\r\npr_err(" PHB Error Log 0 : 0x%016llx\n", ed.phb_log0);\r\npr_err(" PHB Error Log 1 : 0x%016llx\n", ed.phb_log1);\r\n}\r\nif (ed.mmio_err) {\r\npr_err(" MMIO Error Status : 0x%016llx\n", ed.mmio_err);\r\npr_err(" MMIO First Error Status: 0x%016llx\n", ed.mmio_err1);\r\npr_err(" MMIO Error Log 0 : 0x%016llx\n", ed.mmio_log0);\r\npr_err(" MMIO Error Log 1 : 0x%016llx\n", ed.mmio_log1);\r\n}\r\nif (ed.dma_err) {\r\npr_err(" DMA Error Status : 0x%016llx\n", ed.dma_err);\r\npr_err(" DMA First Error Status: 0x%016llx\n", ed.dma_err1);\r\npr_err(" DMA Error Log 0 : 0x%016llx\n", ed.dma_log0);\r\npr_err(" DMA Error Log 1 : 0x%016llx\n", ed.dma_log1);\r\n}\r\nif (ed.utl_sys_err)\r\npr_err(" UTL Sys Error Status : 0x%016llx\n", ed.utl_sys_err);\r\nif (ed.utl_port_err)\r\npr_err(" UTL Port Error Status : 0x%016llx\n", ed.utl_port_err);\r\nif (ed.utl_rc_err)\r\npr_err(" UTL RC Error Status : 0x%016llx\n", ed.utl_rc_err);\r\nif (ed.dma_err || ed.mmio_err || ed.phb_err) {\r\nhandled = IRQ_HANDLED;\r\ngoto again;\r\n}\r\nreturn handled;\r\n}\r\nstatic void __init wsp_setup_pci_err_reporting(struct wsp_phb *phb)\r\n{\r\nstruct pci_controller *hose = phb->hose;\r\nint err_irq, i, rc;\r\nchar fname[16];\r\nsprintf(fname, "phb%d", phb->hose->global_number);\r\nphb->ddir = debugfs_create_dir(fname, powerpc_debugfs_root);\r\nif (phb->ddir) {\r\nstruct dentry *d = debugfs_create_dir("regs", phb->ddir);\r\nchar tmp[64];\r\nfor (i = 0; i < ARRAY_SIZE(wsp_pci_regs); i++) {\r\nsprintf(tmp, "%03x_%s", wsp_pci_regs[i].offset,\r\nwsp_pci_regs[i].name);\r\ndebugfs_create_file(tmp, 0600, d,\r\nhose->cfg_data + wsp_pci_regs[i].offset,\r\n&wsp_pci_reg_fops);\r\n}\r\ndebugfs_create_file("all_regs", 0600, phb->ddir, phb, &wsp_pci_regs_fops);\r\n}\r\nerr_irq = irq_of_parse_and_map(hose->dn, 0);\r\nif (err_irq == 0)\r\nerr_irq = wsp_pci_get_err_irq_no_dt(hose->dn);\r\nif (err_irq == 0) {\r\npr_err("PCI: Failed to fetch error interrupt for %s\n",\r\nhose->dn->full_name);\r\nreturn;\r\n}\r\nrc = request_irq(err_irq, wsp_pci_err_irq, 0, "wsp_pci error", phb);\r\nif (rc) {\r\npr_err("PCI: Failed to request interrupt for %s\n",\r\nhose->dn->full_name);\r\n}\r\nout_be64(hose->cfg_data + PCIE_REG_PHB_ERR_IRQ_ENABLE, 0xffffffffffffffffull);\r\nout_be64(hose->cfg_data + PCIE_REG_MMIO_ERR_IRQ_ENABLE, 0xffffffffffffffffull);\r\nout_be64(hose->cfg_data + PCIE_REG_DMA_ERR_IRQ_ENABLE, 0xffffffffffffffffull);\r\n}\r\nstatic int __init wsp_setup_pci_late(void)\r\n{\r\nstruct wsp_phb *phb;\r\nlist_for_each_entry(phb, &wsp_phbs, all)\r\nwsp_setup_pci_err_reporting(phb);\r\nreturn 0;\r\n}
