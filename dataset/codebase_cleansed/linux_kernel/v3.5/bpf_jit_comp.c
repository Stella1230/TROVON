static inline u8 *emit_code(u8 *ptr, u32 bytes, unsigned int len)\r\n{\r\nif (len == 1)\r\n*ptr = bytes;\r\nelse if (len == 2)\r\n*(u16 *)ptr = bytes;\r\nelse {\r\n*(u32 *)ptr = bytes;\r\nbarrier();\r\n}\r\nreturn ptr + len;\r\n}\r\nstatic inline bool is_imm8(int value)\r\n{\r\nreturn value <= 127 && value >= -128;\r\n}\r\nstatic inline bool is_near(int offset)\r\n{\r\nreturn offset <= 127 && offset >= -128;\r\n}\r\nstatic inline void bpf_flush_icache(void *start, void *end)\r\n{\r\nmm_segment_t old_fs = get_fs();\r\nset_fs(KERNEL_DS);\r\nsmp_wmb();\r\nflush_icache_range((unsigned long)start, (unsigned long)end);\r\nset_fs(old_fs);\r\n}\r\nvoid bpf_jit_compile(struct sk_filter *fp)\r\n{\r\nu8 temp[64];\r\nu8 *prog;\r\nunsigned int proglen, oldproglen = 0;\r\nint ilen, i;\r\nint t_offset, f_offset;\r\nu8 t_op, f_op, seen = 0, pass;\r\nu8 *image = NULL;\r\nu8 *func;\r\nint pc_ret0 = -1;\r\nunsigned int cleanup_addr;\r\nunsigned int *addrs;\r\nconst struct sock_filter *filter = fp->insns;\r\nint flen = fp->len;\r\nif (!bpf_jit_enable)\r\nreturn;\r\naddrs = kmalloc(flen * sizeof(*addrs), GFP_KERNEL);\r\nif (addrs == NULL)\r\nreturn;\r\nfor (proglen = 0, i = 0; i < flen; i++) {\r\nproglen += 64;\r\naddrs[i] = proglen;\r\n}\r\ncleanup_addr = proglen;\r\nfor (pass = 0; pass < 10; pass++) {\r\nu8 seen_or_pass0 = (pass == 0) ? (SEEN_XREG | SEEN_DATAREF | SEEN_MEM) : seen;\r\nproglen = 0;\r\nprog = temp;\r\nif (seen_or_pass0) {\r\nEMIT4(0x55, 0x48, 0x89, 0xe5);\r\nEMIT4(0x48, 0x83, 0xec, 96);\r\nif (seen_or_pass0 & (SEEN_XREG | SEEN_DATAREF))\r\nEMIT4(0x48, 0x89, 0x5d, 0xf8);\r\nif (seen_or_pass0 & SEEN_XREG)\r\nCLEAR_X();\r\nif (seen_or_pass0 & SEEN_DATAREF) {\r\nif (offsetof(struct sk_buff, len) <= 127)\r\nEMIT4(0x44, 0x8b, 0x4f, offsetof(struct sk_buff, len));\r\nelse {\r\nEMIT3(0x44, 0x8b, 0x8f);\r\nEMIT(offsetof(struct sk_buff, len), 4);\r\n}\r\nif (is_imm8(offsetof(struct sk_buff, data_len)))\r\nEMIT4(0x44, 0x2b, 0x4f, offsetof(struct sk_buff, data_len));\r\nelse {\r\nEMIT3(0x44, 0x2b, 0x8f);\r\nEMIT(offsetof(struct sk_buff, data_len), 4);\r\n}\r\nif (is_imm8(offsetof(struct sk_buff, data)))\r\nEMIT4(0x4c, 0x8b, 0x47, offsetof(struct sk_buff, data));\r\nelse {\r\nEMIT3(0x4c, 0x8b, 0x87);\r\nEMIT(offsetof(struct sk_buff, data), 4);\r\n}\r\n}\r\n}\r\nswitch (filter[0].code) {\r\ncase BPF_S_RET_K:\r\ncase BPF_S_LD_W_LEN:\r\ncase BPF_S_ANC_PROTOCOL:\r\ncase BPF_S_ANC_IFINDEX:\r\ncase BPF_S_ANC_MARK:\r\ncase BPF_S_ANC_RXHASH:\r\ncase BPF_S_ANC_CPU:\r\ncase BPF_S_ANC_QUEUE:\r\ncase BPF_S_LD_W_ABS:\r\ncase BPF_S_LD_H_ABS:\r\ncase BPF_S_LD_B_ABS:\r\nbreak;\r\ndefault:\r\nCLEAR_A();\r\n}\r\nfor (i = 0; i < flen; i++) {\r\nunsigned int K = filter[i].k;\r\nswitch (filter[i].code) {\r\ncase BPF_S_ALU_ADD_X:\r\nseen |= SEEN_XREG;\r\nEMIT2(0x01, 0xd8);\r\nbreak;\r\ncase BPF_S_ALU_ADD_K:\r\nif (!K)\r\nbreak;\r\nif (is_imm8(K))\r\nEMIT3(0x83, 0xc0, K);\r\nelse\r\nEMIT1_off32(0x05, K);\r\nbreak;\r\ncase BPF_S_ALU_SUB_X:\r\nseen |= SEEN_XREG;\r\nEMIT2(0x29, 0xd8);\r\nbreak;\r\ncase BPF_S_ALU_SUB_K:\r\nif (!K)\r\nbreak;\r\nif (is_imm8(K))\r\nEMIT3(0x83, 0xe8, K);\r\nelse\r\nEMIT1_off32(0x2d, K);\r\nbreak;\r\ncase BPF_S_ALU_MUL_X:\r\nseen |= SEEN_XREG;\r\nEMIT3(0x0f, 0xaf, 0xc3);\r\nbreak;\r\ncase BPF_S_ALU_MUL_K:\r\nif (is_imm8(K))\r\nEMIT3(0x6b, 0xc0, K);\r\nelse {\r\nEMIT2(0x69, 0xc0);\r\nEMIT(K, 4);\r\n}\r\nbreak;\r\ncase BPF_S_ALU_DIV_X:\r\nseen |= SEEN_XREG;\r\nEMIT2(0x85, 0xdb);\r\nif (pc_ret0 > 0) {\r\nEMIT_COND_JMP(X86_JE, addrs[pc_ret0 - 1] -\r\n(addrs[i] - 4));\r\n} else {\r\nEMIT_COND_JMP(X86_JNE, 2 + 5);\r\nCLEAR_A();\r\nEMIT1_off32(0xe9, cleanup_addr - (addrs[i] - 4));\r\n}\r\nEMIT4(0x31, 0xd2, 0xf7, 0xf3);\r\nbreak;\r\ncase BPF_S_ALU_DIV_K:\r\nEMIT3(0x48, 0x69, 0xc0);\r\nEMIT(K, 4);\r\nEMIT4(0x48, 0xc1, 0xe8, 0x20);\r\nbreak;\r\ncase BPF_S_ALU_AND_X:\r\nseen |= SEEN_XREG;\r\nEMIT2(0x21, 0xd8);\r\nbreak;\r\ncase BPF_S_ALU_AND_K:\r\nif (K >= 0xFFFFFF00) {\r\nEMIT2(0x24, K & 0xFF);\r\n} else if (K >= 0xFFFF0000) {\r\nEMIT2(0x66, 0x25);\r\nEMIT(K, 2);\r\n} else {\r\nEMIT1_off32(0x25, K);\r\n}\r\nbreak;\r\ncase BPF_S_ALU_OR_X:\r\nseen |= SEEN_XREG;\r\nEMIT2(0x09, 0xd8);\r\nbreak;\r\ncase BPF_S_ALU_OR_K:\r\nif (is_imm8(K))\r\nEMIT3(0x83, 0xc8, K);\r\nelse\r\nEMIT1_off32(0x0d, K);\r\nbreak;\r\ncase BPF_S_ALU_LSH_X:\r\nseen |= SEEN_XREG;\r\nEMIT4(0x89, 0xd9, 0xd3, 0xe0);\r\nbreak;\r\ncase BPF_S_ALU_LSH_K:\r\nif (K == 0)\r\nbreak;\r\nelse if (K == 1)\r\nEMIT2(0xd1, 0xe0);\r\nelse\r\nEMIT3(0xc1, 0xe0, K);\r\nbreak;\r\ncase BPF_S_ALU_RSH_X:\r\nseen |= SEEN_XREG;\r\nEMIT4(0x89, 0xd9, 0xd3, 0xe8);\r\nbreak;\r\ncase BPF_S_ALU_RSH_K:\r\nif (K == 0)\r\nbreak;\r\nelse if (K == 1)\r\nEMIT2(0xd1, 0xe8);\r\nelse\r\nEMIT3(0xc1, 0xe8, K);\r\nbreak;\r\ncase BPF_S_ALU_NEG:\r\nEMIT2(0xf7, 0xd8);\r\nbreak;\r\ncase BPF_S_RET_K:\r\nif (!K) {\r\nif (pc_ret0 == -1)\r\npc_ret0 = i;\r\nCLEAR_A();\r\n} else {\r\nEMIT1_off32(0xb8, K);\r\n}\r\ncase BPF_S_RET_A:\r\nif (seen_or_pass0) {\r\nif (i != flen - 1) {\r\nEMIT_JMP(cleanup_addr - addrs[i]);\r\nbreak;\r\n}\r\nif (seen_or_pass0 & SEEN_XREG)\r\nEMIT4(0x48, 0x8b, 0x5d, 0xf8);\r\nEMIT1(0xc9);\r\n}\r\nEMIT1(0xc3);\r\nbreak;\r\ncase BPF_S_MISC_TAX:\r\nseen |= SEEN_XREG;\r\nEMIT2(0x89, 0xc3);\r\nbreak;\r\ncase BPF_S_MISC_TXA:\r\nseen |= SEEN_XREG;\r\nEMIT2(0x89, 0xd8);\r\nbreak;\r\ncase BPF_S_LD_IMM:\r\nif (!K)\r\nCLEAR_A();\r\nelse\r\nEMIT1_off32(0xb8, K);\r\nbreak;\r\ncase BPF_S_LDX_IMM:\r\nseen |= SEEN_XREG;\r\nif (!K)\r\nCLEAR_X();\r\nelse\r\nEMIT1_off32(0xbb, K);\r\nbreak;\r\ncase BPF_S_LD_MEM:\r\nseen |= SEEN_MEM;\r\nEMIT3(0x8b, 0x45, 0xf0 - K*4);\r\nbreak;\r\ncase BPF_S_LDX_MEM:\r\nseen |= SEEN_XREG | SEEN_MEM;\r\nEMIT3(0x8b, 0x5d, 0xf0 - K*4);\r\nbreak;\r\ncase BPF_S_ST:\r\nseen |= SEEN_MEM;\r\nEMIT3(0x89, 0x45, 0xf0 - K*4);\r\nbreak;\r\ncase BPF_S_STX:\r\nseen |= SEEN_XREG | SEEN_MEM;\r\nEMIT3(0x89, 0x5d, 0xf0 - K*4);\r\nbreak;\r\ncase BPF_S_LD_W_LEN:\r\nBUILD_BUG_ON(FIELD_SIZEOF(struct sk_buff, len) != 4);\r\nif (is_imm8(offsetof(struct sk_buff, len)))\r\nEMIT3(0x8b, 0x47, offsetof(struct sk_buff, len));\r\nelse {\r\nEMIT2(0x8b, 0x87);\r\nEMIT(offsetof(struct sk_buff, len), 4);\r\n}\r\nbreak;\r\ncase BPF_S_LDX_W_LEN:\r\nseen |= SEEN_XREG;\r\nif (is_imm8(offsetof(struct sk_buff, len)))\r\nEMIT3(0x8b, 0x5f, offsetof(struct sk_buff, len));\r\nelse {\r\nEMIT2(0x8b, 0x9f);\r\nEMIT(offsetof(struct sk_buff, len), 4);\r\n}\r\nbreak;\r\ncase BPF_S_ANC_PROTOCOL:\r\nBUILD_BUG_ON(FIELD_SIZEOF(struct sk_buff, protocol) != 2);\r\nif (is_imm8(offsetof(struct sk_buff, protocol))) {\r\nEMIT4(0x0f, 0xb7, 0x47, offsetof(struct sk_buff, protocol));\r\n} else {\r\nEMIT3(0x0f, 0xb7, 0x87);\r\nEMIT(offsetof(struct sk_buff, protocol), 4);\r\n}\r\nEMIT2(0x86, 0xc4);\r\nbreak;\r\ncase BPF_S_ANC_IFINDEX:\r\nif (is_imm8(offsetof(struct sk_buff, dev))) {\r\nEMIT4(0x48, 0x8b, 0x47, offsetof(struct sk_buff, dev));\r\n} else {\r\nEMIT3(0x48, 0x8b, 0x87);\r\nEMIT(offsetof(struct sk_buff, dev), 4);\r\n}\r\nEMIT3(0x48, 0x85, 0xc0);\r\nEMIT_COND_JMP(X86_JE, cleanup_addr - (addrs[i] - 6));\r\nBUILD_BUG_ON(FIELD_SIZEOF(struct net_device, ifindex) != 4);\r\nEMIT2(0x8b, 0x80);\r\nEMIT(offsetof(struct net_device, ifindex), 4);\r\nbreak;\r\ncase BPF_S_ANC_MARK:\r\nBUILD_BUG_ON(FIELD_SIZEOF(struct sk_buff, mark) != 4);\r\nif (is_imm8(offsetof(struct sk_buff, mark))) {\r\nEMIT3(0x8b, 0x47, offsetof(struct sk_buff, mark));\r\n} else {\r\nEMIT2(0x8b, 0x87);\r\nEMIT(offsetof(struct sk_buff, mark), 4);\r\n}\r\nbreak;\r\ncase BPF_S_ANC_RXHASH:\r\nBUILD_BUG_ON(FIELD_SIZEOF(struct sk_buff, rxhash) != 4);\r\nif (is_imm8(offsetof(struct sk_buff, rxhash))) {\r\nEMIT3(0x8b, 0x47, offsetof(struct sk_buff, rxhash));\r\n} else {\r\nEMIT2(0x8b, 0x87);\r\nEMIT(offsetof(struct sk_buff, rxhash), 4);\r\n}\r\nbreak;\r\ncase BPF_S_ANC_QUEUE:\r\nBUILD_BUG_ON(FIELD_SIZEOF(struct sk_buff, queue_mapping) != 2);\r\nif (is_imm8(offsetof(struct sk_buff, queue_mapping))) {\r\nEMIT4(0x0f, 0xb7, 0x47, offsetof(struct sk_buff, queue_mapping));\r\n} else {\r\nEMIT3(0x0f, 0xb7, 0x87);\r\nEMIT(offsetof(struct sk_buff, queue_mapping), 4);\r\n}\r\nbreak;\r\ncase BPF_S_ANC_CPU:\r\n#ifdef CONFIG_SMP\r\nEMIT4(0x65, 0x8b, 0x04, 0x25);\r\nEMIT((u32)(unsigned long)&cpu_number, 4);\r\n#else\r\nCLEAR_A();\r\n#endif\r\nbreak;\r\ncase BPF_S_LD_W_ABS:\r\nfunc = CHOOSE_LOAD_FUNC(K, sk_load_word);\r\ncommon_load: seen |= SEEN_DATAREF;\r\nt_offset = func - (image + addrs[i]);\r\nEMIT1_off32(0xbe, K);\r\nEMIT1_off32(0xe8, t_offset);\r\nbreak;\r\ncase BPF_S_LD_H_ABS:\r\nfunc = CHOOSE_LOAD_FUNC(K, sk_load_half);\r\ngoto common_load;\r\ncase BPF_S_LD_B_ABS:\r\nfunc = CHOOSE_LOAD_FUNC(K, sk_load_byte);\r\ngoto common_load;\r\ncase BPF_S_LDX_B_MSH:\r\nfunc = CHOOSE_LOAD_FUNC(K, sk_load_byte_msh);\r\nseen |= SEEN_DATAREF | SEEN_XREG;\r\nt_offset = func - (image + addrs[i]);\r\nEMIT1_off32(0xbe, K);\r\nEMIT1_off32(0xe8, t_offset);\r\nbreak;\r\ncase BPF_S_LD_W_IND:\r\nfunc = sk_load_word;\r\ncommon_load_ind: seen |= SEEN_DATAREF | SEEN_XREG;\r\nt_offset = func - (image + addrs[i]);\r\nif (K) {\r\nif (is_imm8(K)) {\r\nEMIT3(0x8d, 0x73, K);\r\n} else {\r\nEMIT2(0x8d, 0xb3);\r\nEMIT(K, 4);\r\n}\r\n} else {\r\nEMIT2(0x89,0xde);\r\n}\r\nEMIT1_off32(0xe8, t_offset);\r\nbreak;\r\ncase BPF_S_LD_H_IND:\r\nfunc = sk_load_half;\r\ngoto common_load_ind;\r\ncase BPF_S_LD_B_IND:\r\nfunc = sk_load_byte;\r\ngoto common_load_ind;\r\ncase BPF_S_JMP_JA:\r\nt_offset = addrs[i + K] - addrs[i];\r\nEMIT_JMP(t_offset);\r\nbreak;\r\nCOND_SEL(BPF_S_JMP_JGT_K, X86_JA, X86_JBE);\r\nCOND_SEL(BPF_S_JMP_JGE_K, X86_JAE, X86_JB);\r\nCOND_SEL(BPF_S_JMP_JEQ_K, X86_JE, X86_JNE);\r\nCOND_SEL(BPF_S_JMP_JSET_K,X86_JNE, X86_JE);\r\nCOND_SEL(BPF_S_JMP_JGT_X, X86_JA, X86_JBE);\r\nCOND_SEL(BPF_S_JMP_JGE_X, X86_JAE, X86_JB);\r\nCOND_SEL(BPF_S_JMP_JEQ_X, X86_JE, X86_JNE);\r\nCOND_SEL(BPF_S_JMP_JSET_X,X86_JNE, X86_JE);\r\ncond_branch: f_offset = addrs[i + filter[i].jf] - addrs[i];\r\nt_offset = addrs[i + filter[i].jt] - addrs[i];\r\nif (filter[i].jt == filter[i].jf) {\r\nEMIT_JMP(t_offset);\r\nbreak;\r\n}\r\nswitch (filter[i].code) {\r\ncase BPF_S_JMP_JGT_X:\r\ncase BPF_S_JMP_JGE_X:\r\ncase BPF_S_JMP_JEQ_X:\r\nseen |= SEEN_XREG;\r\nEMIT2(0x39, 0xd8);\r\nbreak;\r\ncase BPF_S_JMP_JSET_X:\r\nseen |= SEEN_XREG;\r\nEMIT2(0x85, 0xd8);\r\nbreak;\r\ncase BPF_S_JMP_JEQ_K:\r\nif (K == 0) {\r\nEMIT2(0x85, 0xc0);\r\nbreak;\r\n}\r\ncase BPF_S_JMP_JGT_K:\r\ncase BPF_S_JMP_JGE_K:\r\nif (K <= 127)\r\nEMIT3(0x83, 0xf8, K);\r\nelse\r\nEMIT1_off32(0x3d, K);\r\nbreak;\r\ncase BPF_S_JMP_JSET_K:\r\nif (K <= 0xFF)\r\nEMIT2(0xa8, K);\r\nelse if (!(K & 0xFFFF00FF))\r\nEMIT3(0xf6, 0xc4, K >> 8);\r\nelse if (K <= 0xFFFF) {\r\nEMIT2(0x66, 0xa9);\r\nEMIT(K, 2);\r\n} else {\r\nEMIT1_off32(0xa9, K);\r\n}\r\nbreak;\r\n}\r\nif (filter[i].jt != 0) {\r\nif (filter[i].jf && f_offset)\r\nt_offset += is_near(f_offset) ? 2 : 5;\r\nEMIT_COND_JMP(t_op, t_offset);\r\nif (filter[i].jf)\r\nEMIT_JMP(f_offset);\r\nbreak;\r\n}\r\nEMIT_COND_JMP(f_op, f_offset);\r\nbreak;\r\ndefault:\r\ngoto out;\r\n}\r\nilen = prog - temp;\r\nif (image) {\r\nif (unlikely(proglen + ilen > oldproglen)) {\r\npr_err("bpb_jit_compile fatal error\n");\r\nkfree(addrs);\r\nmodule_free(NULL, image);\r\nreturn;\r\n}\r\nmemcpy(image + proglen, temp, ilen);\r\n}\r\nproglen += ilen;\r\naddrs[i] = proglen;\r\nprog = temp;\r\n}\r\ncleanup_addr = proglen - 1;\r\nif (seen_or_pass0)\r\ncleanup_addr -= 1;\r\nif (seen_or_pass0 & SEEN_XREG)\r\ncleanup_addr -= 4;\r\nif (image) {\r\nif (proglen != oldproglen)\r\npr_err("bpb_jit_compile proglen=%u != oldproglen=%u\n", proglen, oldproglen);\r\nbreak;\r\n}\r\nif (proglen == oldproglen) {\r\nimage = module_alloc(max_t(unsigned int,\r\nproglen,\r\nsizeof(struct work_struct)));\r\nif (!image)\r\ngoto out;\r\n}\r\noldproglen = proglen;\r\n}\r\nif (bpf_jit_enable > 1)\r\npr_err("flen=%d proglen=%u pass=%d image=%p\n",\r\nflen, proglen, pass, image);\r\nif (image) {\r\nif (bpf_jit_enable > 1)\r\nprint_hex_dump(KERN_ERR, "JIT code: ", DUMP_PREFIX_ADDRESS,\r\n16, 1, image, proglen, false);\r\nbpf_flush_icache(image, image + proglen);\r\nfp->bpf_func = (void *)image;\r\n}\r\nout:\r\nkfree(addrs);\r\nreturn;\r\n}\r\nstatic void jit_free_defer(struct work_struct *arg)\r\n{\r\nmodule_free(NULL, arg);\r\n}\r\nvoid bpf_jit_free(struct sk_filter *fp)\r\n{\r\nif (fp->bpf_func != sk_run_filter) {\r\nstruct work_struct *work = (struct work_struct *)fp->bpf_func;\r\nINIT_WORK(work, jit_free_defer);\r\nschedule_work(work);\r\n}\r\n}
