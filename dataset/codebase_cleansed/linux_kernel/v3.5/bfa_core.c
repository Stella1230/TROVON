static void\r\nbfa_com_port_attach(struct bfa_s *bfa)\r\n{\r\nstruct bfa_port_s *port = &bfa->modules.port;\r\nstruct bfa_mem_dma_s *port_dma = BFA_MEM_PORT_DMA(bfa);\r\nbfa_port_attach(port, &bfa->ioc, bfa, bfa->trcmod);\r\nbfa_port_mem_claim(port, port_dma->kva_curp, port_dma->dma_curp);\r\n}\r\nstatic void\r\nbfa_com_ablk_attach(struct bfa_s *bfa)\r\n{\r\nstruct bfa_ablk_s *ablk = &bfa->modules.ablk;\r\nstruct bfa_mem_dma_s *ablk_dma = BFA_MEM_ABLK_DMA(bfa);\r\nbfa_ablk_attach(ablk, &bfa->ioc);\r\nbfa_ablk_memclaim(ablk, ablk_dma->kva_curp, ablk_dma->dma_curp);\r\n}\r\nstatic void\r\nbfa_com_cee_attach(struct bfa_s *bfa)\r\n{\r\nstruct bfa_cee_s *cee = &bfa->modules.cee;\r\nstruct bfa_mem_dma_s *cee_dma = BFA_MEM_CEE_DMA(bfa);\r\ncee->trcmod = bfa->trcmod;\r\nbfa_cee_attach(cee, &bfa->ioc, bfa);\r\nbfa_cee_mem_claim(cee, cee_dma->kva_curp, cee_dma->dma_curp);\r\n}\r\nstatic void\r\nbfa_com_sfp_attach(struct bfa_s *bfa)\r\n{\r\nstruct bfa_sfp_s *sfp = BFA_SFP_MOD(bfa);\r\nstruct bfa_mem_dma_s *sfp_dma = BFA_MEM_SFP_DMA(bfa);\r\nbfa_sfp_attach(sfp, &bfa->ioc, bfa, bfa->trcmod);\r\nbfa_sfp_memclaim(sfp, sfp_dma->kva_curp, sfp_dma->dma_curp);\r\n}\r\nstatic void\r\nbfa_com_flash_attach(struct bfa_s *bfa, bfa_boolean_t mincfg)\r\n{\r\nstruct bfa_flash_s *flash = BFA_FLASH(bfa);\r\nstruct bfa_mem_dma_s *flash_dma = BFA_MEM_FLASH_DMA(bfa);\r\nbfa_flash_attach(flash, &bfa->ioc, bfa, bfa->trcmod, mincfg);\r\nbfa_flash_memclaim(flash, flash_dma->kva_curp,\r\nflash_dma->dma_curp, mincfg);\r\n}\r\nstatic void\r\nbfa_com_diag_attach(struct bfa_s *bfa)\r\n{\r\nstruct bfa_diag_s *diag = BFA_DIAG_MOD(bfa);\r\nstruct bfa_mem_dma_s *diag_dma = BFA_MEM_DIAG_DMA(bfa);\r\nbfa_diag_attach(diag, &bfa->ioc, bfa, bfa_fcport_beacon, bfa->trcmod);\r\nbfa_diag_memclaim(diag, diag_dma->kva_curp, diag_dma->dma_curp);\r\n}\r\nstatic void\r\nbfa_com_phy_attach(struct bfa_s *bfa, bfa_boolean_t mincfg)\r\n{\r\nstruct bfa_phy_s *phy = BFA_PHY(bfa);\r\nstruct bfa_mem_dma_s *phy_dma = BFA_MEM_PHY_DMA(bfa);\r\nbfa_phy_attach(phy, &bfa->ioc, bfa, bfa->trcmod, mincfg);\r\nbfa_phy_memclaim(phy, phy_dma->kva_curp, phy_dma->dma_curp, mincfg);\r\n}\r\nstatic void\r\nbfa_iocfc_sm_stopped_entry(struct bfa_iocfc_s *iocfc)\r\n{\r\n}\r\nstatic void\r\nbfa_iocfc_sm_stopped(struct bfa_iocfc_s *iocfc, enum iocfc_event event)\r\n{\r\nbfa_trc(iocfc->bfa, event);\r\nswitch (event) {\r\ncase IOCFC_E_INIT:\r\ncase IOCFC_E_ENABLE:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_initing);\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(iocfc->bfa, event);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\nbfa_iocfc_sm_initing_entry(struct bfa_iocfc_s *iocfc)\r\n{\r\nbfa_ioc_enable(&iocfc->bfa->ioc);\r\n}\r\nstatic void\r\nbfa_iocfc_sm_initing(struct bfa_iocfc_s *iocfc, enum iocfc_event event)\r\n{\r\nbfa_trc(iocfc->bfa, event);\r\nswitch (event) {\r\ncase IOCFC_E_IOC_ENABLED:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_dconf_read);\r\nbreak;\r\ncase IOCFC_E_IOC_FAILED:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_init_failed);\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(iocfc->bfa, event);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\nbfa_iocfc_sm_dconf_read_entry(struct bfa_iocfc_s *iocfc)\r\n{\r\nbfa_dconf_modinit(iocfc->bfa);\r\n}\r\nstatic void\r\nbfa_iocfc_sm_dconf_read(struct bfa_iocfc_s *iocfc, enum iocfc_event event)\r\n{\r\nbfa_trc(iocfc->bfa, event);\r\nswitch (event) {\r\ncase IOCFC_E_DCONF_DONE:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_init_cfg_wait);\r\nbreak;\r\ncase IOCFC_E_IOC_FAILED:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_init_failed);\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(iocfc->bfa, event);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\nbfa_iocfc_sm_init_cfg_wait_entry(struct bfa_iocfc_s *iocfc)\r\n{\r\nbfa_iocfc_send_cfg(iocfc->bfa);\r\n}\r\nstatic void\r\nbfa_iocfc_sm_init_cfg_wait(struct bfa_iocfc_s *iocfc, enum iocfc_event event)\r\n{\r\nbfa_trc(iocfc->bfa, event);\r\nswitch (event) {\r\ncase IOCFC_E_CFG_DONE:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_init_cfg_done);\r\nbreak;\r\ncase IOCFC_E_IOC_FAILED:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_init_failed);\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(iocfc->bfa, event);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\nbfa_iocfc_sm_init_cfg_done_entry(struct bfa_iocfc_s *iocfc)\r\n{\r\niocfc->bfa->iocfc.op_status = BFA_STATUS_OK;\r\nbfa_cb_queue(iocfc->bfa, &iocfc->bfa->iocfc.init_hcb_qe,\r\nbfa_iocfc_init_cb, iocfc->bfa);\r\n}\r\nstatic void\r\nbfa_iocfc_sm_init_cfg_done(struct bfa_iocfc_s *iocfc, enum iocfc_event event)\r\n{\r\nbfa_trc(iocfc->bfa, event);\r\nswitch (event) {\r\ncase IOCFC_E_START:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_operational);\r\nbreak;\r\ncase IOCFC_E_STOP:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_stopping);\r\nbreak;\r\ncase IOCFC_E_DISABLE:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_disabling);\r\nbreak;\r\ncase IOCFC_E_IOC_FAILED:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_failed);\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(iocfc->bfa, event);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\nbfa_iocfc_sm_operational_entry(struct bfa_iocfc_s *iocfc)\r\n{\r\nbfa_fcport_init(iocfc->bfa);\r\nbfa_iocfc_start_submod(iocfc->bfa);\r\n}\r\nstatic void\r\nbfa_iocfc_sm_operational(struct bfa_iocfc_s *iocfc, enum iocfc_event event)\r\n{\r\nbfa_trc(iocfc->bfa, event);\r\nswitch (event) {\r\ncase IOCFC_E_STOP:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_dconf_write);\r\nbreak;\r\ncase IOCFC_E_DISABLE:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_disabling);\r\nbreak;\r\ncase IOCFC_E_IOC_FAILED:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_failed);\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(iocfc->bfa, event);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\nbfa_iocfc_sm_dconf_write_entry(struct bfa_iocfc_s *iocfc)\r\n{\r\nbfa_dconf_modexit(iocfc->bfa);\r\n}\r\nstatic void\r\nbfa_iocfc_sm_dconf_write(struct bfa_iocfc_s *iocfc, enum iocfc_event event)\r\n{\r\nbfa_trc(iocfc->bfa, event);\r\nswitch (event) {\r\ncase IOCFC_E_DCONF_DONE:\r\ncase IOCFC_E_IOC_FAILED:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_stopping);\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(iocfc->bfa, event);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\nbfa_iocfc_sm_stopping_entry(struct bfa_iocfc_s *iocfc)\r\n{\r\nbfa_ioc_disable(&iocfc->bfa->ioc);\r\n}\r\nstatic void\r\nbfa_iocfc_sm_stopping(struct bfa_iocfc_s *iocfc, enum iocfc_event event)\r\n{\r\nbfa_trc(iocfc->bfa, event);\r\nswitch (event) {\r\ncase IOCFC_E_IOC_DISABLED:\r\nbfa_isr_disable(iocfc->bfa);\r\nbfa_iocfc_disable_submod(iocfc->bfa);\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_stopped);\r\niocfc->bfa->iocfc.op_status = BFA_STATUS_OK;\r\nbfa_cb_queue(iocfc->bfa, &iocfc->bfa->iocfc.stop_hcb_qe,\r\nbfa_iocfc_stop_cb, iocfc->bfa);\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(iocfc->bfa, event);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\nbfa_iocfc_sm_enabling_entry(struct bfa_iocfc_s *iocfc)\r\n{\r\nbfa_ioc_enable(&iocfc->bfa->ioc);\r\n}\r\nstatic void\r\nbfa_iocfc_sm_enabling(struct bfa_iocfc_s *iocfc, enum iocfc_event event)\r\n{\r\nbfa_trc(iocfc->bfa, event);\r\nswitch (event) {\r\ncase IOCFC_E_IOC_ENABLED:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_cfg_wait);\r\nbreak;\r\ncase IOCFC_E_IOC_FAILED:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_failed);\r\nif (iocfc->bfa->iocfc.cb_reqd == BFA_FALSE)\r\nbreak;\r\niocfc->bfa->iocfc.op_status = BFA_STATUS_FAILED;\r\nbfa_cb_queue(iocfc->bfa, &iocfc->bfa->iocfc.en_hcb_qe,\r\nbfa_iocfc_enable_cb, iocfc->bfa);\r\niocfc->bfa->iocfc.cb_reqd = BFA_FALSE;\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(iocfc->bfa, event);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\nbfa_iocfc_sm_cfg_wait_entry(struct bfa_iocfc_s *iocfc)\r\n{\r\nbfa_iocfc_send_cfg(iocfc->bfa);\r\n}\r\nstatic void\r\nbfa_iocfc_sm_cfg_wait(struct bfa_iocfc_s *iocfc, enum iocfc_event event)\r\n{\r\nbfa_trc(iocfc->bfa, event);\r\nswitch (event) {\r\ncase IOCFC_E_CFG_DONE:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_operational);\r\nif (iocfc->bfa->iocfc.cb_reqd == BFA_FALSE)\r\nbreak;\r\niocfc->bfa->iocfc.op_status = BFA_STATUS_OK;\r\nbfa_cb_queue(iocfc->bfa, &iocfc->bfa->iocfc.en_hcb_qe,\r\nbfa_iocfc_enable_cb, iocfc->bfa);\r\niocfc->bfa->iocfc.cb_reqd = BFA_FALSE;\r\nbreak;\r\ncase IOCFC_E_IOC_FAILED:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_failed);\r\nif (iocfc->bfa->iocfc.cb_reqd == BFA_FALSE)\r\nbreak;\r\niocfc->bfa->iocfc.op_status = BFA_STATUS_FAILED;\r\nbfa_cb_queue(iocfc->bfa, &iocfc->bfa->iocfc.en_hcb_qe,\r\nbfa_iocfc_enable_cb, iocfc->bfa);\r\niocfc->bfa->iocfc.cb_reqd = BFA_FALSE;\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(iocfc->bfa, event);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\nbfa_iocfc_sm_disabling_entry(struct bfa_iocfc_s *iocfc)\r\n{\r\nbfa_ioc_disable(&iocfc->bfa->ioc);\r\n}\r\nstatic void\r\nbfa_iocfc_sm_disabling(struct bfa_iocfc_s *iocfc, enum iocfc_event event)\r\n{\r\nbfa_trc(iocfc->bfa, event);\r\nswitch (event) {\r\ncase IOCFC_E_IOC_DISABLED:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_disabled);\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(iocfc->bfa, event);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\nbfa_iocfc_sm_disabled_entry(struct bfa_iocfc_s *iocfc)\r\n{\r\nbfa_isr_disable(iocfc->bfa);\r\nbfa_iocfc_disable_submod(iocfc->bfa);\r\niocfc->bfa->iocfc.op_status = BFA_STATUS_OK;\r\nbfa_cb_queue(iocfc->bfa, &iocfc->bfa->iocfc.dis_hcb_qe,\r\nbfa_iocfc_disable_cb, iocfc->bfa);\r\n}\r\nstatic void\r\nbfa_iocfc_sm_disabled(struct bfa_iocfc_s *iocfc, enum iocfc_event event)\r\n{\r\nbfa_trc(iocfc->bfa, event);\r\nswitch (event) {\r\ncase IOCFC_E_STOP:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_dconf_write);\r\nbreak;\r\ncase IOCFC_E_ENABLE:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_enabling);\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(iocfc->bfa, event);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\nbfa_iocfc_sm_failed_entry(struct bfa_iocfc_s *iocfc)\r\n{\r\nbfa_isr_disable(iocfc->bfa);\r\nbfa_iocfc_disable_submod(iocfc->bfa);\r\n}\r\nstatic void\r\nbfa_iocfc_sm_failed(struct bfa_iocfc_s *iocfc, enum iocfc_event event)\r\n{\r\nbfa_trc(iocfc->bfa, event);\r\nswitch (event) {\r\ncase IOCFC_E_STOP:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_dconf_write);\r\nbreak;\r\ncase IOCFC_E_DISABLE:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_disabling);\r\nbreak;\r\ncase IOCFC_E_IOC_ENABLED:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_cfg_wait);\r\nbreak;\r\ncase IOCFC_E_IOC_FAILED:\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(iocfc->bfa, event);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\nbfa_iocfc_sm_init_failed_entry(struct bfa_iocfc_s *iocfc)\r\n{\r\nbfa_isr_disable(iocfc->bfa);\r\niocfc->bfa->iocfc.op_status = BFA_STATUS_FAILED;\r\nbfa_cb_queue(iocfc->bfa, &iocfc->bfa->iocfc.init_hcb_qe,\r\nbfa_iocfc_init_cb, iocfc->bfa);\r\n}\r\nstatic void\r\nbfa_iocfc_sm_init_failed(struct bfa_iocfc_s *iocfc, enum iocfc_event event)\r\n{\r\nbfa_trc(iocfc->bfa, event);\r\nswitch (event) {\r\ncase IOCFC_E_STOP:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_stopping);\r\nbreak;\r\ncase IOCFC_E_DISABLE:\r\nbfa_ioc_disable(&iocfc->bfa->ioc);\r\nbreak;\r\ncase IOCFC_E_IOC_ENABLED:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_dconf_read);\r\nbreak;\r\ncase IOCFC_E_IOC_DISABLED:\r\nbfa_fsm_set_state(iocfc, bfa_iocfc_sm_stopped);\r\niocfc->bfa->iocfc.op_status = BFA_STATUS_OK;\r\nbfa_cb_queue(iocfc->bfa, &iocfc->bfa->iocfc.dis_hcb_qe,\r\nbfa_iocfc_disable_cb, iocfc->bfa);\r\nbreak;\r\ncase IOCFC_E_IOC_FAILED:\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(iocfc->bfa, event);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\nbfa_reqq_resume(struct bfa_s *bfa, int qid)\r\n{\r\nstruct list_head *waitq, *qe, *qen;\r\nstruct bfa_reqq_wait_s *wqe;\r\nwaitq = bfa_reqq(bfa, qid);\r\nlist_for_each_safe(qe, qen, waitq) {\r\nif (bfa_reqq_full(bfa, qid))\r\nbreak;\r\nlist_del(qe);\r\nwqe = (struct bfa_reqq_wait_s *) qe;\r\nwqe->qresume(wqe->cbarg);\r\n}\r\n}\r\nbfa_boolean_t\r\nbfa_isr_rspq(struct bfa_s *bfa, int qid)\r\n{\r\nstruct bfi_msg_s *m;\r\nu32 pi, ci;\r\nstruct list_head *waitq;\r\nbfa_boolean_t ret;\r\nci = bfa_rspq_ci(bfa, qid);\r\npi = bfa_rspq_pi(bfa, qid);\r\nret = (ci != pi);\r\nwhile (ci != pi) {\r\nm = bfa_rspq_elem(bfa, qid, ci);\r\nWARN_ON(m->mhdr.msg_class >= BFI_MC_MAX);\r\nbfa_isrs[m->mhdr.msg_class] (bfa, m);\r\nCQ_INCR(ci, bfa->iocfc.cfg.drvcfg.num_rspq_elems);\r\n}\r\nbfa_isr_rspq_ack(bfa, qid, ci);\r\nwaitq = bfa_reqq(bfa, qid);\r\nif (!list_empty(waitq))\r\nbfa_reqq_resume(bfa, qid);\r\nreturn ret;\r\n}\r\nstatic inline void\r\nbfa_isr_reqq(struct bfa_s *bfa, int qid)\r\n{\r\nstruct list_head *waitq;\r\nbfa_isr_reqq_ack(bfa, qid);\r\nwaitq = bfa_reqq(bfa, qid);\r\nif (!list_empty(waitq))\r\nbfa_reqq_resume(bfa, qid);\r\n}\r\nvoid\r\nbfa_msix_all(struct bfa_s *bfa, int vec)\r\n{\r\nu32 intr, qintr;\r\nint queue;\r\nintr = readl(bfa->iocfc.bfa_regs.intr_status);\r\nif (!intr)\r\nreturn;\r\nqintr = intr & __HFN_INT_RME_MASK;\r\nif (qintr && bfa->queue_process) {\r\nfor (queue = 0; queue < BFI_IOC_MAX_CQS; queue++)\r\nbfa_isr_rspq(bfa, queue);\r\n}\r\nintr &= ~qintr;\r\nif (!intr)\r\nreturn;\r\nqintr = intr & __HFN_INT_CPE_MASK;\r\nif (qintr && bfa->queue_process) {\r\nfor (queue = 0; queue < BFI_IOC_MAX_CQS; queue++)\r\nbfa_isr_reqq(bfa, queue);\r\n}\r\nintr &= ~qintr;\r\nif (!intr)\r\nreturn;\r\nbfa_msix_lpu_err(bfa, intr);\r\n}\r\nbfa_boolean_t\r\nbfa_intx(struct bfa_s *bfa)\r\n{\r\nu32 intr, qintr;\r\nint queue;\r\nbfa_boolean_t rspq_comp = BFA_FALSE;\r\nintr = readl(bfa->iocfc.bfa_regs.intr_status);\r\nqintr = intr & (__HFN_INT_RME_MASK | __HFN_INT_CPE_MASK);\r\nif (qintr)\r\nwritel(qintr, bfa->iocfc.bfa_regs.intr_status);\r\nif (bfa->queue_process) {\r\nfor (queue = 0; queue < BFI_IOC_MAX_CQS; queue++)\r\nif (bfa_isr_rspq(bfa, queue))\r\nrspq_comp = BFA_TRUE;\r\n}\r\nif (!intr)\r\nreturn (qintr | rspq_comp) ? BFA_TRUE : BFA_FALSE;\r\nqintr = intr & __HFN_INT_CPE_MASK;\r\nif (qintr && bfa->queue_process) {\r\nfor (queue = 0; queue < BFI_IOC_MAX_CQS; queue++)\r\nbfa_isr_reqq(bfa, queue);\r\n}\r\nintr &= ~qintr;\r\nif (!intr)\r\nreturn BFA_TRUE;\r\nbfa_msix_lpu_err(bfa, intr);\r\nreturn BFA_TRUE;\r\n}\r\nvoid\r\nbfa_isr_enable(struct bfa_s *bfa)\r\n{\r\nu32 umsk;\r\nint pci_func = bfa_ioc_pcifn(&bfa->ioc);\r\nbfa_trc(bfa, pci_func);\r\nbfa_msix_ctrl_install(bfa);\r\nif (bfa_asic_id_ct2(bfa->ioc.pcidev.device_id)) {\r\numsk = __HFN_INT_ERR_MASK_CT2;\r\numsk |= pci_func == 0 ?\r\n__HFN_INT_FN0_MASK_CT2 : __HFN_INT_FN1_MASK_CT2;\r\n} else {\r\numsk = __HFN_INT_ERR_MASK;\r\numsk |= pci_func == 0 ? __HFN_INT_FN0_MASK : __HFN_INT_FN1_MASK;\r\n}\r\nwritel(umsk, bfa->iocfc.bfa_regs.intr_status);\r\nwritel(~umsk, bfa->iocfc.bfa_regs.intr_mask);\r\nbfa->iocfc.intr_mask = ~umsk;\r\nbfa_isr_mode_set(bfa, bfa->msix.nvecs != 0);\r\n}\r\nvoid\r\nbfa_isr_disable(struct bfa_s *bfa)\r\n{\r\nbfa_isr_mode_set(bfa, BFA_FALSE);\r\nwritel(-1L, bfa->iocfc.bfa_regs.intr_mask);\r\nbfa_msix_uninstall(bfa);\r\n}\r\nvoid\r\nbfa_msix_reqq(struct bfa_s *bfa, int vec)\r\n{\r\nbfa_isr_reqq(bfa, vec - bfa->iocfc.hwif.cpe_vec_q0);\r\n}\r\nvoid\r\nbfa_isr_unhandled(struct bfa_s *bfa, struct bfi_msg_s *m)\r\n{\r\nbfa_trc(bfa, m->mhdr.msg_class);\r\nbfa_trc(bfa, m->mhdr.msg_id);\r\nbfa_trc(bfa, m->mhdr.mtag.i2htok);\r\nWARN_ON(1);\r\nbfa_trc_stop(bfa->trcmod);\r\n}\r\nvoid\r\nbfa_msix_rspq(struct bfa_s *bfa, int vec)\r\n{\r\nbfa_isr_rspq(bfa, vec - bfa->iocfc.hwif.rme_vec_q0);\r\n}\r\nvoid\r\nbfa_msix_lpu_err(struct bfa_s *bfa, int vec)\r\n{\r\nu32 intr, curr_value;\r\nbfa_boolean_t lpu_isr, halt_isr, pss_isr;\r\nintr = readl(bfa->iocfc.bfa_regs.intr_status);\r\nif (bfa_asic_id_ct2(bfa->ioc.pcidev.device_id)) {\r\nhalt_isr = intr & __HFN_INT_CPQ_HALT_CT2;\r\npss_isr = intr & __HFN_INT_ERR_PSS_CT2;\r\nlpu_isr = intr & (__HFN_INT_MBOX_LPU0_CT2 |\r\n__HFN_INT_MBOX_LPU1_CT2);\r\nintr &= __HFN_INT_ERR_MASK_CT2;\r\n} else {\r\nhalt_isr = bfa_asic_id_ct(bfa->ioc.pcidev.device_id) ?\r\n(intr & __HFN_INT_LL_HALT) : 0;\r\npss_isr = intr & __HFN_INT_ERR_PSS;\r\nlpu_isr = intr & (__HFN_INT_MBOX_LPU0 | __HFN_INT_MBOX_LPU1);\r\nintr &= __HFN_INT_ERR_MASK;\r\n}\r\nif (lpu_isr)\r\nbfa_ioc_mbox_isr(&bfa->ioc);\r\nif (intr) {\r\nif (halt_isr) {\r\ncurr_value = readl(bfa->ioc.ioc_regs.ll_halt);\r\ncurr_value &= ~__FW_INIT_HALT_P;\r\nwritel(curr_value, bfa->ioc.ioc_regs.ll_halt);\r\n}\r\nif (pss_isr) {\r\ncurr_value = readl(\r\nbfa->ioc.ioc_regs.pss_err_status_reg);\r\nwritel(curr_value,\r\nbfa->ioc.ioc_regs.pss_err_status_reg);\r\n}\r\nwritel(intr, bfa->iocfc.bfa_regs.intr_status);\r\nbfa_ioc_error_isr(&bfa->ioc);\r\n}\r\n}\r\nstatic void\r\nbfa_iocfc_send_cfg(void *bfa_arg)\r\n{\r\nstruct bfa_s *bfa = bfa_arg;\r\nstruct bfa_iocfc_s *iocfc = &bfa->iocfc;\r\nstruct bfi_iocfc_cfg_req_s cfg_req;\r\nstruct bfi_iocfc_cfg_s *cfg_info = iocfc->cfginfo;\r\nstruct bfa_iocfc_cfg_s *cfg = &iocfc->cfg;\r\nint i;\r\nWARN_ON(cfg->fwcfg.num_cqs > BFI_IOC_MAX_CQS);\r\nbfa_trc(bfa, cfg->fwcfg.num_cqs);\r\nbfa_iocfc_reset_queues(bfa);\r\ncfg_info->single_msix_vec = 0;\r\nif (bfa->msix.nvecs == 1)\r\ncfg_info->single_msix_vec = 1;\r\ncfg_info->endian_sig = BFI_IOC_ENDIAN_SIG;\r\ncfg_info->num_cqs = cfg->fwcfg.num_cqs;\r\ncfg_info->num_ioim_reqs = cpu_to_be16(cfg->fwcfg.num_ioim_reqs);\r\ncfg_info->num_fwtio_reqs = cpu_to_be16(cfg->fwcfg.num_fwtio_reqs);\r\nbfa_dma_be_addr_set(cfg_info->cfgrsp_addr, iocfc->cfgrsp_dma.pa);\r\nfor (i = 0; i < cfg->fwcfg.num_cqs; i++) {\r\nbfa_dma_be_addr_set(cfg_info->req_cq_ba[i],\r\niocfc->req_cq_ba[i].pa);\r\nbfa_dma_be_addr_set(cfg_info->req_shadow_ci[i],\r\niocfc->req_cq_shadow_ci[i].pa);\r\ncfg_info->req_cq_elems[i] =\r\ncpu_to_be16(cfg->drvcfg.num_reqq_elems);\r\nbfa_dma_be_addr_set(cfg_info->rsp_cq_ba[i],\r\niocfc->rsp_cq_ba[i].pa);\r\nbfa_dma_be_addr_set(cfg_info->rsp_shadow_pi[i],\r\niocfc->rsp_cq_shadow_pi[i].pa);\r\ncfg_info->rsp_cq_elems[i] =\r\ncpu_to_be16(cfg->drvcfg.num_rspq_elems);\r\n}\r\nif (bfa_fsm_cmp_state(iocfc, bfa_iocfc_sm_init_cfg_wait))\r\ncfg_info->intr_attr.coalesce = BFA_TRUE;\r\nbfi_h2i_set(cfg_req.mh, BFI_MC_IOCFC, BFI_IOCFC_H2I_CFG_REQ,\r\nbfa_fn_lpu(bfa));\r\nbfa_dma_be_addr_set(cfg_req.ioc_cfg_dma_addr, iocfc->cfg_info.pa);\r\nbfa_ioc_mbox_send(&bfa->ioc, &cfg_req,\r\nsizeof(struct bfi_iocfc_cfg_req_s));\r\n}\r\nstatic void\r\nbfa_iocfc_init_mem(struct bfa_s *bfa, void *bfad, struct bfa_iocfc_cfg_s *cfg,\r\nstruct bfa_pcidev_s *pcidev)\r\n{\r\nstruct bfa_iocfc_s *iocfc = &bfa->iocfc;\r\nbfa->bfad = bfad;\r\niocfc->bfa = bfa;\r\niocfc->cfg = *cfg;\r\nif (bfa_asic_id_ctc(bfa_ioc_devid(&bfa->ioc))) {\r\niocfc->hwif.hw_reginit = bfa_hwct_reginit;\r\niocfc->hwif.hw_reqq_ack = bfa_hwct_reqq_ack;\r\niocfc->hwif.hw_rspq_ack = bfa_hwct_rspq_ack;\r\niocfc->hwif.hw_msix_init = bfa_hwct_msix_init;\r\niocfc->hwif.hw_msix_ctrl_install = bfa_hwct_msix_ctrl_install;\r\niocfc->hwif.hw_msix_queue_install = bfa_hwct_msix_queue_install;\r\niocfc->hwif.hw_msix_uninstall = bfa_hwct_msix_uninstall;\r\niocfc->hwif.hw_isr_mode_set = bfa_hwct_isr_mode_set;\r\niocfc->hwif.hw_msix_getvecs = bfa_hwct_msix_getvecs;\r\niocfc->hwif.hw_msix_get_rme_range = bfa_hwct_msix_get_rme_range;\r\niocfc->hwif.rme_vec_q0 = BFI_MSIX_RME_QMIN_CT;\r\niocfc->hwif.cpe_vec_q0 = BFI_MSIX_CPE_QMIN_CT;\r\n} else {\r\niocfc->hwif.hw_reginit = bfa_hwcb_reginit;\r\niocfc->hwif.hw_reqq_ack = NULL;\r\niocfc->hwif.hw_rspq_ack = bfa_hwcb_rspq_ack;\r\niocfc->hwif.hw_msix_init = bfa_hwcb_msix_init;\r\niocfc->hwif.hw_msix_ctrl_install = bfa_hwcb_msix_ctrl_install;\r\niocfc->hwif.hw_msix_queue_install = bfa_hwcb_msix_queue_install;\r\niocfc->hwif.hw_msix_uninstall = bfa_hwcb_msix_uninstall;\r\niocfc->hwif.hw_isr_mode_set = bfa_hwcb_isr_mode_set;\r\niocfc->hwif.hw_msix_getvecs = bfa_hwcb_msix_getvecs;\r\niocfc->hwif.hw_msix_get_rme_range = bfa_hwcb_msix_get_rme_range;\r\niocfc->hwif.rme_vec_q0 = BFI_MSIX_RME_QMIN_CB +\r\nbfa_ioc_pcifn(&bfa->ioc) * BFI_IOC_MAX_CQS;\r\niocfc->hwif.cpe_vec_q0 = BFI_MSIX_CPE_QMIN_CB +\r\nbfa_ioc_pcifn(&bfa->ioc) * BFI_IOC_MAX_CQS;\r\n}\r\nif (bfa_asic_id_ct2(bfa_ioc_devid(&bfa->ioc))) {\r\niocfc->hwif.hw_reginit = bfa_hwct2_reginit;\r\niocfc->hwif.hw_isr_mode_set = NULL;\r\niocfc->hwif.hw_rspq_ack = bfa_hwct2_rspq_ack;\r\n}\r\niocfc->hwif.hw_reginit(bfa);\r\nbfa->msix.nvecs = 0;\r\n}\r\nstatic void\r\nbfa_iocfc_mem_claim(struct bfa_s *bfa, struct bfa_iocfc_cfg_s *cfg)\r\n{\r\nu8 *dm_kva = NULL;\r\nu64 dm_pa = 0;\r\nint i, per_reqq_sz, per_rspq_sz, dbgsz;\r\nstruct bfa_iocfc_s *iocfc = &bfa->iocfc;\r\nstruct bfa_mem_dma_s *ioc_dma = BFA_MEM_IOC_DMA(bfa);\r\nstruct bfa_mem_dma_s *iocfc_dma = BFA_MEM_IOCFC_DMA(bfa);\r\nstruct bfa_mem_dma_s *reqq_dma, *rspq_dma;\r\nbfa_ioc_mem_claim(&bfa->ioc, bfa_mem_dma_virt(ioc_dma),\r\nbfa_mem_dma_phys(ioc_dma));\r\nper_reqq_sz = BFA_ROUNDUP((cfg->drvcfg.num_reqq_elems * BFI_LMSG_SZ),\r\nBFA_DMA_ALIGN_SZ);\r\nper_rspq_sz = BFA_ROUNDUP((cfg->drvcfg.num_rspq_elems * BFI_LMSG_SZ),\r\nBFA_DMA_ALIGN_SZ);\r\nfor (i = 0; i < cfg->fwcfg.num_cqs; i++) {\r\nreqq_dma = BFA_MEM_REQQ_DMA(bfa, i);\r\niocfc->req_cq_ba[i].kva = bfa_mem_dma_virt(reqq_dma);\r\niocfc->req_cq_ba[i].pa = bfa_mem_dma_phys(reqq_dma);\r\nmemset(iocfc->req_cq_ba[i].kva, 0, per_reqq_sz);\r\nrspq_dma = BFA_MEM_RSPQ_DMA(bfa, i);\r\niocfc->rsp_cq_ba[i].kva = bfa_mem_dma_virt(rspq_dma);\r\niocfc->rsp_cq_ba[i].pa = bfa_mem_dma_phys(rspq_dma);\r\nmemset(iocfc->rsp_cq_ba[i].kva, 0, per_rspq_sz);\r\n}\r\ndm_kva = bfa_mem_dma_virt(iocfc_dma);\r\ndm_pa = bfa_mem_dma_phys(iocfc_dma);\r\nfor (i = 0; i < cfg->fwcfg.num_cqs; i++) {\r\niocfc->req_cq_shadow_ci[i].kva = dm_kva;\r\niocfc->req_cq_shadow_ci[i].pa = dm_pa;\r\ndm_kva += BFA_CACHELINE_SZ;\r\ndm_pa += BFA_CACHELINE_SZ;\r\niocfc->rsp_cq_shadow_pi[i].kva = dm_kva;\r\niocfc->rsp_cq_shadow_pi[i].pa = dm_pa;\r\ndm_kva += BFA_CACHELINE_SZ;\r\ndm_pa += BFA_CACHELINE_SZ;\r\n}\r\nbfa->iocfc.cfg_info.kva = dm_kva;\r\nbfa->iocfc.cfg_info.pa = dm_pa;\r\nbfa->iocfc.cfginfo = (struct bfi_iocfc_cfg_s *) dm_kva;\r\ndm_kva += BFA_ROUNDUP(sizeof(struct bfi_iocfc_cfg_s), BFA_CACHELINE_SZ);\r\ndm_pa += BFA_ROUNDUP(sizeof(struct bfi_iocfc_cfg_s), BFA_CACHELINE_SZ);\r\nbfa->iocfc.cfgrsp_dma.kva = dm_kva;\r\nbfa->iocfc.cfgrsp_dma.pa = dm_pa;\r\nbfa->iocfc.cfgrsp = (struct bfi_iocfc_cfgrsp_s *) dm_kva;\r\ndm_kva += BFA_ROUNDUP(sizeof(struct bfi_iocfc_cfgrsp_s),\r\nBFA_CACHELINE_SZ);\r\ndm_pa += BFA_ROUNDUP(sizeof(struct bfi_iocfc_cfgrsp_s),\r\nBFA_CACHELINE_SZ);\r\ndbgsz = (bfa_auto_recover) ? BFA_DBG_FWTRC_LEN : 0;\r\nif (dbgsz > 0) {\r\nbfa_ioc_debug_memclaim(&bfa->ioc, bfa_mem_kva_curp(iocfc));\r\nbfa_mem_kva_curp(iocfc) += dbgsz;\r\n}\r\n}\r\nstatic void\r\nbfa_iocfc_start_submod(struct bfa_s *bfa)\r\n{\r\nint i;\r\nbfa->queue_process = BFA_TRUE;\r\nfor (i = 0; i < BFI_IOC_MAX_CQS; i++)\r\nbfa_isr_rspq_ack(bfa, i, bfa_rspq_ci(bfa, i));\r\nfor (i = 0; hal_mods[i]; i++)\r\nhal_mods[i]->start(bfa);\r\nbfa->iocfc.submod_enabled = BFA_TRUE;\r\n}\r\nstatic void\r\nbfa_iocfc_disable_submod(struct bfa_s *bfa)\r\n{\r\nint i;\r\nif (bfa->iocfc.submod_enabled == BFA_FALSE)\r\nreturn;\r\nfor (i = 0; hal_mods[i]; i++)\r\nhal_mods[i]->iocdisable(bfa);\r\nbfa->iocfc.submod_enabled = BFA_FALSE;\r\n}\r\nstatic void\r\nbfa_iocfc_init_cb(void *bfa_arg, bfa_boolean_t complete)\r\n{\r\nstruct bfa_s *bfa = bfa_arg;\r\nif (complete)\r\nbfa_cb_init(bfa->bfad, bfa->iocfc.op_status);\r\n}\r\nstatic void\r\nbfa_iocfc_stop_cb(void *bfa_arg, bfa_boolean_t compl)\r\n{\r\nstruct bfa_s *bfa = bfa_arg;\r\nstruct bfad_s *bfad = bfa->bfad;\r\nif (compl)\r\ncomplete(&bfad->comp);\r\n}\r\nstatic void\r\nbfa_iocfc_enable_cb(void *bfa_arg, bfa_boolean_t compl)\r\n{\r\nstruct bfa_s *bfa = bfa_arg;\r\nstruct bfad_s *bfad = bfa->bfad;\r\nif (compl)\r\ncomplete(&bfad->enable_comp);\r\n}\r\nstatic void\r\nbfa_iocfc_disable_cb(void *bfa_arg, bfa_boolean_t compl)\r\n{\r\nstruct bfa_s *bfa = bfa_arg;\r\nstruct bfad_s *bfad = bfa->bfad;\r\nif (compl)\r\ncomplete(&bfad->disable_comp);\r\n}\r\nstatic void\r\nbfa_iocfc_qreg(struct bfa_s *bfa, struct bfi_iocfc_qreg_s *qreg)\r\n{\r\nint i;\r\nstruct bfa_iocfc_regs_s *r = &bfa->iocfc.bfa_regs;\r\nvoid __iomem *kva = bfa_ioc_bar0(&bfa->ioc);\r\nfor (i = 0; i < BFI_IOC_MAX_CQS; i++) {\r\nbfa->iocfc.hw_qid[i] = qreg->hw_qid[i];\r\nr->cpe_q_ci[i] = kva + be32_to_cpu(qreg->cpe_q_ci_off[i]);\r\nr->cpe_q_pi[i] = kva + be32_to_cpu(qreg->cpe_q_pi_off[i]);\r\nr->cpe_q_ctrl[i] = kva + be32_to_cpu(qreg->cpe_qctl_off[i]);\r\nr->rme_q_ci[i] = kva + be32_to_cpu(qreg->rme_q_ci_off[i]);\r\nr->rme_q_pi[i] = kva + be32_to_cpu(qreg->rme_q_pi_off[i]);\r\nr->rme_q_ctrl[i] = kva + be32_to_cpu(qreg->rme_qctl_off[i]);\r\n}\r\n}\r\nstatic void\r\nbfa_iocfc_res_recfg(struct bfa_s *bfa, struct bfa_iocfc_fwcfg_s *fwcfg)\r\n{\r\nbfa_fcxp_res_recfg(bfa, fwcfg->num_fcxp_reqs);\r\nbfa_uf_res_recfg(bfa, fwcfg->num_uf_bufs);\r\nbfa_rport_res_recfg(bfa, fwcfg->num_rports);\r\nbfa_fcp_res_recfg(bfa, fwcfg->num_ioim_reqs);\r\nbfa_tskim_res_recfg(bfa, fwcfg->num_tskim_reqs);\r\n}\r\nstatic void\r\nbfa_iocfc_cfgrsp(struct bfa_s *bfa)\r\n{\r\nstruct bfa_iocfc_s *iocfc = &bfa->iocfc;\r\nstruct bfi_iocfc_cfgrsp_s *cfgrsp = iocfc->cfgrsp;\r\nstruct bfa_iocfc_fwcfg_s *fwcfg = &cfgrsp->fwcfg;\r\nfwcfg->num_cqs = fwcfg->num_cqs;\r\nfwcfg->num_ioim_reqs = be16_to_cpu(fwcfg->num_ioim_reqs);\r\nfwcfg->num_fwtio_reqs = be16_to_cpu(fwcfg->num_fwtio_reqs);\r\nfwcfg->num_tskim_reqs = be16_to_cpu(fwcfg->num_tskim_reqs);\r\nfwcfg->num_fcxp_reqs = be16_to_cpu(fwcfg->num_fcxp_reqs);\r\nfwcfg->num_uf_bufs = be16_to_cpu(fwcfg->num_uf_bufs);\r\nfwcfg->num_rports = be16_to_cpu(fwcfg->num_rports);\r\nbfa_iocfc_qreg(bfa, &cfgrsp->qreg);\r\nbfa_iocfc_res_recfg(bfa, fwcfg);\r\nbfa_msix_queue_install(bfa);\r\nif (bfa->iocfc.cfgrsp->pbc_cfg.pbc_pwwn != 0) {\r\nbfa->ioc.attr->pwwn = bfa->iocfc.cfgrsp->pbc_cfg.pbc_pwwn;\r\nbfa->ioc.attr->nwwn = bfa->iocfc.cfgrsp->pbc_cfg.pbc_nwwn;\r\nbfa_fsm_send_event(iocfc, IOCFC_E_CFG_DONE);\r\n}\r\n}\r\nvoid\r\nbfa_iocfc_reset_queues(struct bfa_s *bfa)\r\n{\r\nint q;\r\nfor (q = 0; q < BFI_IOC_MAX_CQS; q++) {\r\nbfa_reqq_ci(bfa, q) = 0;\r\nbfa_reqq_pi(bfa, q) = 0;\r\nbfa_rspq_ci(bfa, q) = 0;\r\nbfa_rspq_pi(bfa, q) = 0;\r\n}\r\n}\r\nstatic void\r\nbfa_iocfc_process_faa_addr(struct bfa_s *bfa, struct bfi_faa_addr_msg_s *msg)\r\n{\r\nstruct bfa_iocfc_s *iocfc = &bfa->iocfc;\r\nstruct bfi_iocfc_cfgrsp_s *cfgrsp = iocfc->cfgrsp;\r\ncfgrsp->pbc_cfg.pbc_pwwn = msg->pwwn;\r\ncfgrsp->pbc_cfg.pbc_nwwn = msg->nwwn;\r\nbfa->ioc.attr->pwwn = msg->pwwn;\r\nbfa->ioc.attr->nwwn = msg->nwwn;\r\nbfa_fsm_send_event(iocfc, IOCFC_E_CFG_DONE);\r\n}\r\nstatic bfa_status_t\r\nbfa_faa_validate_request(struct bfa_s *bfa)\r\n{\r\nenum bfa_ioc_type_e ioc_type = bfa_get_type(bfa);\r\nu32 card_type = bfa->ioc.attr->card_type;\r\nif (bfa_ioc_is_operational(&bfa->ioc)) {\r\nif ((ioc_type != BFA_IOC_TYPE_FC) || bfa_mfg_is_mezz(card_type))\r\nreturn BFA_STATUS_FEATURE_NOT_SUPPORTED;\r\n} else {\r\nreturn BFA_STATUS_IOC_NON_OP;\r\n}\r\nreturn BFA_STATUS_OK;\r\n}\r\nbfa_status_t\r\nbfa_faa_query(struct bfa_s *bfa, struct bfa_faa_attr_s *attr,\r\nbfa_cb_iocfc_t cbfn, void *cbarg)\r\n{\r\nstruct bfi_faa_query_s faa_attr_req;\r\nstruct bfa_iocfc_s *iocfc = &bfa->iocfc;\r\nbfa_status_t status;\r\niocfc->faa_args.faa_attr = attr;\r\niocfc->faa_args.faa_cb.faa_cbfn = cbfn;\r\niocfc->faa_args.faa_cb.faa_cbarg = cbarg;\r\nstatus = bfa_faa_validate_request(bfa);\r\nif (status != BFA_STATUS_OK)\r\nreturn status;\r\nif (iocfc->faa_args.busy == BFA_TRUE)\r\nreturn BFA_STATUS_DEVBUSY;\r\niocfc->faa_args.busy = BFA_TRUE;\r\nmemset(&faa_attr_req, 0, sizeof(struct bfi_faa_query_s));\r\nbfi_h2i_set(faa_attr_req.mh, BFI_MC_IOCFC,\r\nBFI_IOCFC_H2I_FAA_QUERY_REQ, bfa_fn_lpu(bfa));\r\nbfa_ioc_mbox_send(&bfa->ioc, &faa_attr_req,\r\nsizeof(struct bfi_faa_query_s));\r\nreturn BFA_STATUS_OK;\r\n}\r\nstatic void\r\nbfa_faa_query_reply(struct bfa_iocfc_s *iocfc,\r\nbfi_faa_query_rsp_t *rsp)\r\n{\r\nvoid *cbarg = iocfc->faa_args.faa_cb.faa_cbarg;\r\nif (iocfc->faa_args.faa_attr) {\r\niocfc->faa_args.faa_attr->faa = rsp->faa;\r\niocfc->faa_args.faa_attr->faa_state = rsp->faa_status;\r\niocfc->faa_args.faa_attr->pwwn_source = rsp->addr_source;\r\n}\r\nWARN_ON(!iocfc->faa_args.faa_cb.faa_cbfn);\r\niocfc->faa_args.faa_cb.faa_cbfn(cbarg, BFA_STATUS_OK);\r\niocfc->faa_args.busy = BFA_FALSE;\r\n}\r\nstatic void\r\nbfa_iocfc_enable_cbfn(void *bfa_arg, enum bfa_status status)\r\n{\r\nstruct bfa_s *bfa = bfa_arg;\r\nif (status == BFA_STATUS_OK)\r\nbfa_fsm_send_event(&bfa->iocfc, IOCFC_E_IOC_ENABLED);\r\nelse\r\nbfa_fsm_send_event(&bfa->iocfc, IOCFC_E_IOC_FAILED);\r\n}\r\nstatic void\r\nbfa_iocfc_disable_cbfn(void *bfa_arg)\r\n{\r\nstruct bfa_s *bfa = bfa_arg;\r\nbfa_fsm_send_event(&bfa->iocfc, IOCFC_E_IOC_DISABLED);\r\n}\r\nstatic void\r\nbfa_iocfc_hbfail_cbfn(void *bfa_arg)\r\n{\r\nstruct bfa_s *bfa = bfa_arg;\r\nbfa->queue_process = BFA_FALSE;\r\nbfa_fsm_send_event(&bfa->iocfc, IOCFC_E_IOC_FAILED);\r\n}\r\nstatic void\r\nbfa_iocfc_reset_cbfn(void *bfa_arg)\r\n{\r\nstruct bfa_s *bfa = bfa_arg;\r\nbfa_iocfc_reset_queues(bfa);\r\nbfa_isr_enable(bfa);\r\n}\r\nvoid\r\nbfa_iocfc_meminfo(struct bfa_iocfc_cfg_s *cfg, struct bfa_meminfo_s *meminfo,\r\nstruct bfa_s *bfa)\r\n{\r\nint q, per_reqq_sz, per_rspq_sz;\r\nstruct bfa_mem_dma_s *ioc_dma = BFA_MEM_IOC_DMA(bfa);\r\nstruct bfa_mem_dma_s *iocfc_dma = BFA_MEM_IOCFC_DMA(bfa);\r\nstruct bfa_mem_kva_s *iocfc_kva = BFA_MEM_IOCFC_KVA(bfa);\r\nu32 dm_len = 0;\r\nbfa_mem_dma_setup(meminfo, ioc_dma,\r\nBFA_ROUNDUP(sizeof(struct bfi_ioc_attr_s), BFA_DMA_ALIGN_SZ));\r\nper_reqq_sz = BFA_ROUNDUP((cfg->drvcfg.num_reqq_elems * BFI_LMSG_SZ),\r\nBFA_DMA_ALIGN_SZ);\r\nper_rspq_sz = BFA_ROUNDUP((cfg->drvcfg.num_rspq_elems * BFI_LMSG_SZ),\r\nBFA_DMA_ALIGN_SZ);\r\nfor (q = 0; q < cfg->fwcfg.num_cqs; q++) {\r\nbfa_mem_dma_setup(meminfo, BFA_MEM_REQQ_DMA(bfa, q),\r\nper_reqq_sz);\r\nbfa_mem_dma_setup(meminfo, BFA_MEM_RSPQ_DMA(bfa, q),\r\nper_rspq_sz);\r\n}\r\nfor (q = 0; q < cfg->fwcfg.num_cqs; q++)\r\ndm_len += (2 * BFA_CACHELINE_SZ);\r\ndm_len += BFA_ROUNDUP(sizeof(struct bfi_iocfc_cfg_s), BFA_CACHELINE_SZ);\r\ndm_len += BFA_ROUNDUP(sizeof(struct bfi_iocfc_cfgrsp_s),\r\nBFA_CACHELINE_SZ);\r\nbfa_mem_dma_setup(meminfo, iocfc_dma, dm_len);\r\nbfa_mem_kva_setup(meminfo, iocfc_kva,\r\n((bfa_auto_recover) ? BFA_DBG_FWTRC_LEN : 0));\r\n}\r\nvoid\r\nbfa_iocfc_attach(struct bfa_s *bfa, void *bfad, struct bfa_iocfc_cfg_s *cfg,\r\nstruct bfa_pcidev_s *pcidev)\r\n{\r\nint i;\r\nstruct bfa_ioc_s *ioc = &bfa->ioc;\r\nbfa_iocfc_cbfn.enable_cbfn = bfa_iocfc_enable_cbfn;\r\nbfa_iocfc_cbfn.disable_cbfn = bfa_iocfc_disable_cbfn;\r\nbfa_iocfc_cbfn.hbfail_cbfn = bfa_iocfc_hbfail_cbfn;\r\nbfa_iocfc_cbfn.reset_cbfn = bfa_iocfc_reset_cbfn;\r\nioc->trcmod = bfa->trcmod;\r\nbfa_ioc_attach(&bfa->ioc, bfa, &bfa_iocfc_cbfn, &bfa->timer_mod);\r\nbfa_ioc_pci_init(&bfa->ioc, pcidev, BFI_PCIFN_CLASS_FC);\r\nbfa_ioc_mbox_register(&bfa->ioc, bfa_mbox_isrs);\r\nbfa_iocfc_init_mem(bfa, bfad, cfg, pcidev);\r\nbfa_iocfc_mem_claim(bfa, cfg);\r\nINIT_LIST_HEAD(&bfa->timer_mod.timer_q);\r\nINIT_LIST_HEAD(&bfa->comp_q);\r\nfor (i = 0; i < BFI_IOC_MAX_CQS; i++)\r\nINIT_LIST_HEAD(&bfa->reqq_waitq[i]);\r\nbfa->iocfc.cb_reqd = BFA_FALSE;\r\nbfa->iocfc.op_status = BFA_STATUS_OK;\r\nbfa->iocfc.submod_enabled = BFA_FALSE;\r\nbfa_fsm_set_state(&bfa->iocfc, bfa_iocfc_sm_stopped);\r\n}\r\nvoid\r\nbfa_iocfc_init(struct bfa_s *bfa)\r\n{\r\nbfa_fsm_send_event(&bfa->iocfc, IOCFC_E_INIT);\r\n}\r\nvoid\r\nbfa_iocfc_start(struct bfa_s *bfa)\r\n{\r\nbfa_fsm_send_event(&bfa->iocfc, IOCFC_E_START);\r\n}\r\nvoid\r\nbfa_iocfc_stop(struct bfa_s *bfa)\r\n{\r\nbfa->queue_process = BFA_FALSE;\r\nbfa_fsm_send_event(&bfa->iocfc, IOCFC_E_STOP);\r\n}\r\nvoid\r\nbfa_iocfc_isr(void *bfaarg, struct bfi_mbmsg_s *m)\r\n{\r\nstruct bfa_s *bfa = bfaarg;\r\nstruct bfa_iocfc_s *iocfc = &bfa->iocfc;\r\nunion bfi_iocfc_i2h_msg_u *msg;\r\nmsg = (union bfi_iocfc_i2h_msg_u *) m;\r\nbfa_trc(bfa, msg->mh.msg_id);\r\nswitch (msg->mh.msg_id) {\r\ncase BFI_IOCFC_I2H_CFG_REPLY:\r\nbfa_iocfc_cfgrsp(bfa);\r\nbreak;\r\ncase BFI_IOCFC_I2H_UPDATEQ_RSP:\r\niocfc->updateq_cbfn(iocfc->updateq_cbarg, BFA_STATUS_OK);\r\nbreak;\r\ncase BFI_IOCFC_I2H_ADDR_MSG:\r\nbfa_iocfc_process_faa_addr(bfa,\r\n(struct bfi_faa_addr_msg_s *)msg);\r\nbreak;\r\ncase BFI_IOCFC_I2H_FAA_QUERY_RSP:\r\nbfa_faa_query_reply(iocfc, (bfi_faa_query_rsp_t *)msg);\r\nbreak;\r\ndefault:\r\nWARN_ON(1);\r\n}\r\n}\r\nvoid\r\nbfa_iocfc_get_attr(struct bfa_s *bfa, struct bfa_iocfc_attr_s *attr)\r\n{\r\nstruct bfa_iocfc_s *iocfc = &bfa->iocfc;\r\nattr->intr_attr.coalesce = iocfc->cfginfo->intr_attr.coalesce;\r\nattr->intr_attr.delay = iocfc->cfginfo->intr_attr.delay ?\r\nbe16_to_cpu(iocfc->cfginfo->intr_attr.delay) :\r\nbe16_to_cpu(iocfc->cfgrsp->intr_attr.delay);\r\nattr->intr_attr.latency = iocfc->cfginfo->intr_attr.latency ?\r\nbe16_to_cpu(iocfc->cfginfo->intr_attr.latency) :\r\nbe16_to_cpu(iocfc->cfgrsp->intr_attr.latency);\r\nattr->config = iocfc->cfg;\r\n}\r\nbfa_status_t\r\nbfa_iocfc_israttr_set(struct bfa_s *bfa, struct bfa_iocfc_intr_attr_s *attr)\r\n{\r\nstruct bfa_iocfc_s *iocfc = &bfa->iocfc;\r\nstruct bfi_iocfc_set_intr_req_s *m;\r\niocfc->cfginfo->intr_attr.coalesce = attr->coalesce;\r\niocfc->cfginfo->intr_attr.delay = cpu_to_be16(attr->delay);\r\niocfc->cfginfo->intr_attr.latency = cpu_to_be16(attr->latency);\r\nif (!bfa_iocfc_is_operational(bfa))\r\nreturn BFA_STATUS_OK;\r\nm = bfa_reqq_next(bfa, BFA_REQQ_IOC);\r\nif (!m)\r\nreturn BFA_STATUS_DEVBUSY;\r\nbfi_h2i_set(m->mh, BFI_MC_IOCFC, BFI_IOCFC_H2I_SET_INTR_REQ,\r\nbfa_fn_lpu(bfa));\r\nm->coalesce = iocfc->cfginfo->intr_attr.coalesce;\r\nm->delay = iocfc->cfginfo->intr_attr.delay;\r\nm->latency = iocfc->cfginfo->intr_attr.latency;\r\nbfa_trc(bfa, attr->delay);\r\nbfa_trc(bfa, attr->latency);\r\nbfa_reqq_produce(bfa, BFA_REQQ_IOC, m->mh);\r\nreturn BFA_STATUS_OK;\r\n}\r\nvoid\r\nbfa_iocfc_set_snsbase(struct bfa_s *bfa, int seg_no, u64 snsbase_pa)\r\n{\r\nstruct bfa_iocfc_s *iocfc = &bfa->iocfc;\r\niocfc->cfginfo->sense_buf_len = (BFI_IOIM_SNSLEN - 1);\r\nbfa_dma_be_addr_set(iocfc->cfginfo->ioim_snsbase[seg_no], snsbase_pa);\r\n}\r\nvoid\r\nbfa_iocfc_enable(struct bfa_s *bfa)\r\n{\r\nbfa_plog_str(bfa->plog, BFA_PL_MID_HAL, BFA_PL_EID_MISC, 0,\r\n"IOC Enable");\r\nbfa->iocfc.cb_reqd = BFA_TRUE;\r\nbfa_fsm_send_event(&bfa->iocfc, IOCFC_E_ENABLE);\r\n}\r\nvoid\r\nbfa_iocfc_disable(struct bfa_s *bfa)\r\n{\r\nbfa_plog_str(bfa->plog, BFA_PL_MID_HAL, BFA_PL_EID_MISC, 0,\r\n"IOC Disable");\r\nbfa->queue_process = BFA_FALSE;\r\nbfa_fsm_send_event(&bfa->iocfc, IOCFC_E_DISABLE);\r\n}\r\nbfa_boolean_t\r\nbfa_iocfc_is_operational(struct bfa_s *bfa)\r\n{\r\nreturn bfa_ioc_is_operational(&bfa->ioc) &&\r\nbfa_fsm_cmp_state(&bfa->iocfc, bfa_iocfc_sm_operational);\r\n}\r\nvoid\r\nbfa_iocfc_get_bootwwns(struct bfa_s *bfa, u8 *nwwns, wwn_t *wwns)\r\n{\r\nstruct bfa_iocfc_s *iocfc = &bfa->iocfc;\r\nstruct bfi_iocfc_cfgrsp_s *cfgrsp = iocfc->cfgrsp;\r\nint i;\r\nif (cfgrsp->pbc_cfg.boot_enabled && cfgrsp->pbc_cfg.nbluns) {\r\nbfa_trc(bfa, cfgrsp->pbc_cfg.nbluns);\r\n*nwwns = cfgrsp->pbc_cfg.nbluns;\r\nfor (i = 0; i < cfgrsp->pbc_cfg.nbluns; i++)\r\nwwns[i] = cfgrsp->pbc_cfg.blun[i].tgt_pwwn;\r\nreturn;\r\n}\r\n*nwwns = cfgrsp->bootwwns.nwwns;\r\nmemcpy(wwns, cfgrsp->bootwwns.wwn, sizeof(cfgrsp->bootwwns.wwn));\r\n}\r\nint\r\nbfa_iocfc_get_pbc_vports(struct bfa_s *bfa, struct bfi_pbc_vport_s *pbc_vport)\r\n{\r\nstruct bfa_iocfc_s *iocfc = &bfa->iocfc;\r\nstruct bfi_iocfc_cfgrsp_s *cfgrsp = iocfc->cfgrsp;\r\nmemcpy(pbc_vport, cfgrsp->pbc_cfg.vport, sizeof(cfgrsp->pbc_cfg.vport));\r\nreturn cfgrsp->pbc_cfg.nvports;\r\n}\r\nvoid\r\nbfa_cfg_get_meminfo(struct bfa_iocfc_cfg_s *cfg, struct bfa_meminfo_s *meminfo,\r\nstruct bfa_s *bfa)\r\n{\r\nint i;\r\nstruct bfa_mem_dma_s *port_dma = BFA_MEM_PORT_DMA(bfa);\r\nstruct bfa_mem_dma_s *ablk_dma = BFA_MEM_ABLK_DMA(bfa);\r\nstruct bfa_mem_dma_s *cee_dma = BFA_MEM_CEE_DMA(bfa);\r\nstruct bfa_mem_dma_s *sfp_dma = BFA_MEM_SFP_DMA(bfa);\r\nstruct bfa_mem_dma_s *flash_dma = BFA_MEM_FLASH_DMA(bfa);\r\nstruct bfa_mem_dma_s *diag_dma = BFA_MEM_DIAG_DMA(bfa);\r\nstruct bfa_mem_dma_s *phy_dma = BFA_MEM_PHY_DMA(bfa);\r\nWARN_ON((cfg == NULL) || (meminfo == NULL));\r\nmemset((void *)meminfo, 0, sizeof(struct bfa_meminfo_s));\r\nINIT_LIST_HEAD(&meminfo->dma_info.qe);\r\nINIT_LIST_HEAD(&meminfo->kva_info.qe);\r\nbfa_iocfc_meminfo(cfg, meminfo, bfa);\r\nfor (i = 0; hal_mods[i]; i++)\r\nhal_mods[i]->meminfo(cfg, meminfo, bfa);\r\nbfa_mem_dma_setup(meminfo, port_dma, bfa_port_meminfo());\r\nbfa_mem_dma_setup(meminfo, ablk_dma, bfa_ablk_meminfo());\r\nbfa_mem_dma_setup(meminfo, cee_dma, bfa_cee_meminfo());\r\nbfa_mem_dma_setup(meminfo, sfp_dma, bfa_sfp_meminfo());\r\nbfa_mem_dma_setup(meminfo, flash_dma,\r\nbfa_flash_meminfo(cfg->drvcfg.min_cfg));\r\nbfa_mem_dma_setup(meminfo, diag_dma, bfa_diag_meminfo());\r\nbfa_mem_dma_setup(meminfo, phy_dma,\r\nbfa_phy_meminfo(cfg->drvcfg.min_cfg));\r\n}\r\nvoid\r\nbfa_attach(struct bfa_s *bfa, void *bfad, struct bfa_iocfc_cfg_s *cfg,\r\nstruct bfa_meminfo_s *meminfo, struct bfa_pcidev_s *pcidev)\r\n{\r\nint i;\r\nstruct bfa_mem_dma_s *dma_info, *dma_elem;\r\nstruct bfa_mem_kva_s *kva_info, *kva_elem;\r\nstruct list_head *dm_qe, *km_qe;\r\nbfa->fcs = BFA_FALSE;\r\nWARN_ON((cfg == NULL) || (meminfo == NULL));\r\ndma_info = &meminfo->dma_info;\r\ndma_info->kva_curp = dma_info->kva;\r\ndma_info->dma_curp = dma_info->dma;\r\nkva_info = &meminfo->kva_info;\r\nkva_info->kva_curp = kva_info->kva;\r\nlist_for_each(dm_qe, &dma_info->qe) {\r\ndma_elem = (struct bfa_mem_dma_s *) dm_qe;\r\ndma_elem->kva_curp = dma_elem->kva;\r\ndma_elem->dma_curp = dma_elem->dma;\r\n}\r\nlist_for_each(km_qe, &kva_info->qe) {\r\nkva_elem = (struct bfa_mem_kva_s *) km_qe;\r\nkva_elem->kva_curp = kva_elem->kva;\r\n}\r\nbfa_iocfc_attach(bfa, bfad, cfg, pcidev);\r\nfor (i = 0; hal_mods[i]; i++)\r\nhal_mods[i]->attach(bfa, bfad, cfg, pcidev);\r\nbfa_com_port_attach(bfa);\r\nbfa_com_ablk_attach(bfa);\r\nbfa_com_cee_attach(bfa);\r\nbfa_com_sfp_attach(bfa);\r\nbfa_com_flash_attach(bfa, cfg->drvcfg.min_cfg);\r\nbfa_com_diag_attach(bfa);\r\nbfa_com_phy_attach(bfa, cfg->drvcfg.min_cfg);\r\n}\r\nvoid\r\nbfa_detach(struct bfa_s *bfa)\r\n{\r\nint i;\r\nfor (i = 0; hal_mods[i]; i++)\r\nhal_mods[i]->detach(bfa);\r\nbfa_ioc_detach(&bfa->ioc);\r\n}\r\nvoid\r\nbfa_comp_deq(struct bfa_s *bfa, struct list_head *comp_q)\r\n{\r\nINIT_LIST_HEAD(comp_q);\r\nlist_splice_tail_init(&bfa->comp_q, comp_q);\r\n}\r\nvoid\r\nbfa_comp_process(struct bfa_s *bfa, struct list_head *comp_q)\r\n{\r\nstruct list_head *qe;\r\nstruct list_head *qen;\r\nstruct bfa_cb_qe_s *hcb_qe;\r\nbfa_cb_cbfn_status_t cbfn;\r\nlist_for_each_safe(qe, qen, comp_q) {\r\nhcb_qe = (struct bfa_cb_qe_s *) qe;\r\nif (hcb_qe->pre_rmv) {\r\nlist_del(qe);\r\ncbfn = (bfa_cb_cbfn_status_t)(hcb_qe->cbfn);\r\ncbfn(hcb_qe->cbarg, hcb_qe->fw_status);\r\n} else\r\nhcb_qe->cbfn(hcb_qe->cbarg, BFA_TRUE);\r\n}\r\n}\r\nvoid\r\nbfa_comp_free(struct bfa_s *bfa, struct list_head *comp_q)\r\n{\r\nstruct list_head *qe;\r\nstruct bfa_cb_qe_s *hcb_qe;\r\nwhile (!list_empty(comp_q)) {\r\nbfa_q_deq(comp_q, &qe);\r\nhcb_qe = (struct bfa_cb_qe_s *) qe;\r\nWARN_ON(hcb_qe->pre_rmv);\r\nhcb_qe->cbfn(hcb_qe->cbarg, BFA_FALSE);\r\n}\r\n}\r\nvoid\r\nbfa_get_pciids(struct bfa_pciid_s **pciids, int *npciids)\r\n{\r\nstatic struct bfa_pciid_s __pciids[] = {\r\n{BFA_PCI_VENDOR_ID_BROCADE, BFA_PCI_DEVICE_ID_FC_8G2P},\r\n{BFA_PCI_VENDOR_ID_BROCADE, BFA_PCI_DEVICE_ID_FC_8G1P},\r\n{BFA_PCI_VENDOR_ID_BROCADE, BFA_PCI_DEVICE_ID_CT},\r\n{BFA_PCI_VENDOR_ID_BROCADE, BFA_PCI_DEVICE_ID_CT_FC},\r\n};\r\n*npciids = sizeof(__pciids) / sizeof(__pciids[0]);\r\n*pciids = __pciids;\r\n}\r\nvoid\r\nbfa_cfg_get_default(struct bfa_iocfc_cfg_s *cfg)\r\n{\r\ncfg->fwcfg.num_fabrics = DEF_CFG_NUM_FABRICS;\r\ncfg->fwcfg.num_lports = DEF_CFG_NUM_LPORTS;\r\ncfg->fwcfg.num_rports = DEF_CFG_NUM_RPORTS;\r\ncfg->fwcfg.num_ioim_reqs = DEF_CFG_NUM_IOIM_REQS;\r\ncfg->fwcfg.num_tskim_reqs = DEF_CFG_NUM_TSKIM_REQS;\r\ncfg->fwcfg.num_fcxp_reqs = DEF_CFG_NUM_FCXP_REQS;\r\ncfg->fwcfg.num_uf_bufs = DEF_CFG_NUM_UF_BUFS;\r\ncfg->fwcfg.num_cqs = DEF_CFG_NUM_CQS;\r\ncfg->fwcfg.num_fwtio_reqs = 0;\r\ncfg->drvcfg.num_reqq_elems = DEF_CFG_NUM_REQQ_ELEMS;\r\ncfg->drvcfg.num_rspq_elems = DEF_CFG_NUM_RSPQ_ELEMS;\r\ncfg->drvcfg.num_sgpgs = DEF_CFG_NUM_SGPGS;\r\ncfg->drvcfg.num_sboot_tgts = DEF_CFG_NUM_SBOOT_TGTS;\r\ncfg->drvcfg.num_sboot_luns = DEF_CFG_NUM_SBOOT_LUNS;\r\ncfg->drvcfg.path_tov = BFA_FCPIM_PATHTOV_DEF;\r\ncfg->drvcfg.ioc_recover = BFA_FALSE;\r\ncfg->drvcfg.delay_comp = BFA_FALSE;\r\n}\r\nvoid\r\nbfa_cfg_get_min(struct bfa_iocfc_cfg_s *cfg)\r\n{\r\nbfa_cfg_get_default(cfg);\r\ncfg->fwcfg.num_ioim_reqs = BFA_IOIM_MIN;\r\ncfg->fwcfg.num_tskim_reqs = BFA_TSKIM_MIN;\r\ncfg->fwcfg.num_fcxp_reqs = BFA_FCXP_MIN;\r\ncfg->fwcfg.num_uf_bufs = BFA_UF_MIN;\r\ncfg->fwcfg.num_rports = BFA_RPORT_MIN;\r\ncfg->fwcfg.num_fwtio_reqs = 0;\r\ncfg->drvcfg.num_sgpgs = BFA_SGPG_MIN;\r\ncfg->drvcfg.num_reqq_elems = BFA_REQQ_NELEMS_MIN;\r\ncfg->drvcfg.num_rspq_elems = BFA_RSPQ_NELEMS_MIN;\r\ncfg->drvcfg.min_cfg = BFA_TRUE;\r\n}
