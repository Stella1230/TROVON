static inline void inc_snd_pages(int order)\r\n{\r\nsnd_allocated_pages += 1 << order;\r\n}\r\nstatic inline void dec_snd_pages(int order)\r\n{\r\nsnd_allocated_pages -= 1 << order;\r\n}\r\nvoid *snd_malloc_pages(size_t size, gfp_t gfp_flags)\r\n{\r\nint pg;\r\nvoid *res;\r\nif (WARN_ON(!size))\r\nreturn NULL;\r\nif (WARN_ON(!gfp_flags))\r\nreturn NULL;\r\ngfp_flags |= __GFP_COMP;\r\npg = get_order(size);\r\nif ((res = (void *) __get_free_pages(gfp_flags, pg)) != NULL)\r\ninc_snd_pages(pg);\r\nreturn res;\r\n}\r\nvoid snd_free_pages(void *ptr, size_t size)\r\n{\r\nint pg;\r\nif (ptr == NULL)\r\nreturn;\r\npg = get_order(size);\r\ndec_snd_pages(pg);\r\nfree_pages((unsigned long) ptr, pg);\r\n}\r\nstatic void *snd_malloc_dev_pages(struct device *dev, size_t size, dma_addr_t *dma)\r\n{\r\nint pg;\r\nvoid *res;\r\ngfp_t gfp_flags;\r\nif (WARN_ON(!dma))\r\nreturn NULL;\r\npg = get_order(size);\r\ngfp_flags = GFP_KERNEL\r\n| __GFP_COMP\r\n| __GFP_NORETRY\r\n| __GFP_NOWARN;\r\nres = dma_alloc_coherent(dev, PAGE_SIZE << pg, dma, gfp_flags);\r\nif (res != NULL)\r\ninc_snd_pages(pg);\r\nreturn res;\r\n}\r\nstatic void snd_free_dev_pages(struct device *dev, size_t size, void *ptr,\r\ndma_addr_t dma)\r\n{\r\nint pg;\r\nif (ptr == NULL)\r\nreturn;\r\npg = get_order(size);\r\ndec_snd_pages(pg);\r\ndma_free_coherent(dev, PAGE_SIZE << pg, ptr, dma);\r\n}\r\nint snd_dma_alloc_pages(int type, struct device *device, size_t size,\r\nstruct snd_dma_buffer *dmab)\r\n{\r\nif (WARN_ON(!size))\r\nreturn -ENXIO;\r\nif (WARN_ON(!dmab))\r\nreturn -ENXIO;\r\ndmab->dev.type = type;\r\ndmab->dev.dev = device;\r\ndmab->bytes = 0;\r\nswitch (type) {\r\ncase SNDRV_DMA_TYPE_CONTINUOUS:\r\ndmab->area = snd_malloc_pages(size,\r\n(__force gfp_t)(unsigned long)device);\r\ndmab->addr = 0;\r\nbreak;\r\n#ifdef CONFIG_HAS_DMA\r\ncase SNDRV_DMA_TYPE_DEV:\r\ndmab->area = snd_malloc_dev_pages(device, size, &dmab->addr);\r\nbreak;\r\n#endif\r\n#ifdef CONFIG_SND_DMA_SGBUF\r\ncase SNDRV_DMA_TYPE_DEV_SG:\r\nsnd_malloc_sgbuf_pages(device, size, dmab, NULL);\r\nbreak;\r\n#endif\r\ndefault:\r\nprintk(KERN_ERR "snd-malloc: invalid device type %d\n", type);\r\ndmab->area = NULL;\r\ndmab->addr = 0;\r\nreturn -ENXIO;\r\n}\r\nif (! dmab->area)\r\nreturn -ENOMEM;\r\ndmab->bytes = size;\r\nreturn 0;\r\n}\r\nint snd_dma_alloc_pages_fallback(int type, struct device *device, size_t size,\r\nstruct snd_dma_buffer *dmab)\r\n{\r\nint err;\r\nwhile ((err = snd_dma_alloc_pages(type, device, size, dmab)) < 0) {\r\nsize_t aligned_size;\r\nif (err != -ENOMEM)\r\nreturn err;\r\nif (size <= PAGE_SIZE)\r\nreturn -ENOMEM;\r\naligned_size = PAGE_SIZE << get_order(size);\r\nif (size != aligned_size)\r\nsize = aligned_size;\r\nelse\r\nsize >>= 1;\r\n}\r\nif (! dmab->area)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nvoid snd_dma_free_pages(struct snd_dma_buffer *dmab)\r\n{\r\nswitch (dmab->dev.type) {\r\ncase SNDRV_DMA_TYPE_CONTINUOUS:\r\nsnd_free_pages(dmab->area, dmab->bytes);\r\nbreak;\r\n#ifdef CONFIG_HAS_DMA\r\ncase SNDRV_DMA_TYPE_DEV:\r\nsnd_free_dev_pages(dmab->dev.dev, dmab->bytes, dmab->area, dmab->addr);\r\nbreak;\r\n#endif\r\n#ifdef CONFIG_SND_DMA_SGBUF\r\ncase SNDRV_DMA_TYPE_DEV_SG:\r\nsnd_free_sgbuf_pages(dmab);\r\nbreak;\r\n#endif\r\ndefault:\r\nprintk(KERN_ERR "snd-malloc: invalid device type %d\n", dmab->dev.type);\r\n}\r\n}\r\nsize_t snd_dma_get_reserved_buf(struct snd_dma_buffer *dmab, unsigned int id)\r\n{\r\nstruct snd_mem_list *mem;\r\nif (WARN_ON(!dmab))\r\nreturn 0;\r\nmutex_lock(&list_mutex);\r\nlist_for_each_entry(mem, &mem_list_head, list) {\r\nif (mem->id == id &&\r\n(mem->buffer.dev.dev == NULL || dmab->dev.dev == NULL ||\r\n! memcmp(&mem->buffer.dev, &dmab->dev, sizeof(dmab->dev)))) {\r\nstruct device *dev = dmab->dev.dev;\r\nlist_del(&mem->list);\r\n*dmab = mem->buffer;\r\nif (dmab->dev.dev == NULL)\r\ndmab->dev.dev = dev;\r\nkfree(mem);\r\nmutex_unlock(&list_mutex);\r\nreturn dmab->bytes;\r\n}\r\n}\r\nmutex_unlock(&list_mutex);\r\nreturn 0;\r\n}\r\nint snd_dma_reserve_buf(struct snd_dma_buffer *dmab, unsigned int id)\r\n{\r\nstruct snd_mem_list *mem;\r\nif (WARN_ON(!dmab))\r\nreturn -EINVAL;\r\nmem = kmalloc(sizeof(*mem), GFP_KERNEL);\r\nif (! mem)\r\nreturn -ENOMEM;\r\nmutex_lock(&list_mutex);\r\nmem->buffer = *dmab;\r\nmem->id = id;\r\nlist_add_tail(&mem->list, &mem_list_head);\r\nmutex_unlock(&list_mutex);\r\nreturn 0;\r\n}\r\nstatic void free_all_reserved_pages(void)\r\n{\r\nstruct list_head *p;\r\nstruct snd_mem_list *mem;\r\nmutex_lock(&list_mutex);\r\nwhile (! list_empty(&mem_list_head)) {\r\np = mem_list_head.next;\r\nmem = list_entry(p, struct snd_mem_list, list);\r\nlist_del(p);\r\nsnd_dma_free_pages(&mem->buffer);\r\nkfree(mem);\r\n}\r\nmutex_unlock(&list_mutex);\r\n}\r\nstatic int snd_mem_proc_read(struct seq_file *seq, void *offset)\r\n{\r\nlong pages = snd_allocated_pages >> (PAGE_SHIFT-12);\r\nstruct snd_mem_list *mem;\r\nint devno;\r\nstatic char *types[] = { "UNKNOWN", "CONT", "DEV", "DEV-SG" };\r\nmutex_lock(&list_mutex);\r\nseq_printf(seq, "pages : %li bytes (%li pages per %likB)\n",\r\npages * PAGE_SIZE, pages, PAGE_SIZE / 1024);\r\ndevno = 0;\r\nlist_for_each_entry(mem, &mem_list_head, list) {\r\ndevno++;\r\nseq_printf(seq, "buffer %d : ID %08x : type %s\n",\r\ndevno, mem->id, types[mem->buffer.dev.type]);\r\nseq_printf(seq, " addr = 0x%lx, size = %d bytes\n",\r\n(unsigned long)mem->buffer.addr,\r\n(int)mem->buffer.bytes);\r\n}\r\nmutex_unlock(&list_mutex);\r\nreturn 0;\r\n}\r\nstatic int snd_mem_proc_open(struct inode *inode, struct file *file)\r\n{\r\nreturn single_open(file, snd_mem_proc_read, NULL);\r\n}\r\nstatic ssize_t snd_mem_proc_write(struct file *file, const char __user * buffer,\r\nsize_t count, loff_t * ppos)\r\n{\r\nchar buf[128];\r\nchar *token, *p;\r\nif (count > sizeof(buf) - 1)\r\nreturn -EINVAL;\r\nif (copy_from_user(buf, buffer, count))\r\nreturn -EFAULT;\r\nbuf[count] = '\0';\r\np = buf;\r\ntoken = gettoken(&p);\r\nif (! token || *token == '#')\r\nreturn count;\r\nif (strcmp(token, "add") == 0) {\r\nchar *endp;\r\nint vendor, device, size, buffers;\r\nlong mask;\r\nint i, alloced;\r\nstruct pci_dev *pci;\r\nif ((token = gettoken(&p)) == NULL ||\r\n(vendor = simple_strtol(token, NULL, 0)) <= 0 ||\r\n(token = gettoken(&p)) == NULL ||\r\n(device = simple_strtol(token, NULL, 0)) <= 0 ||\r\n(token = gettoken(&p)) == NULL ||\r\n(mask = simple_strtol(token, NULL, 0)) < 0 ||\r\n(token = gettoken(&p)) == NULL ||\r\n(size = memparse(token, &endp)) < 64*1024 ||\r\nsize > 16*1024*1024 ||\r\n(token = gettoken(&p)) == NULL ||\r\n(buffers = simple_strtol(token, NULL, 0)) <= 0 ||\r\nbuffers > 4) {\r\nprintk(KERN_ERR "snd-page-alloc: invalid proc write format\n");\r\nreturn count;\r\n}\r\nvendor &= 0xffff;\r\ndevice &= 0xffff;\r\nalloced = 0;\r\npci = NULL;\r\nwhile ((pci = pci_get_device(vendor, device, pci)) != NULL) {\r\nif (mask > 0 && mask < 0xffffffff) {\r\nif (pci_set_dma_mask(pci, mask) < 0 ||\r\npci_set_consistent_dma_mask(pci, mask) < 0) {\r\nprintk(KERN_ERR "snd-page-alloc: cannot set DMA mask %lx for pci %04x:%04x\n", mask, vendor, device);\r\npci_dev_put(pci);\r\nreturn count;\r\n}\r\n}\r\nfor (i = 0; i < buffers; i++) {\r\nstruct snd_dma_buffer dmab;\r\nmemset(&dmab, 0, sizeof(dmab));\r\nif (snd_dma_alloc_pages(SNDRV_DMA_TYPE_DEV, snd_dma_pci_data(pci),\r\nsize, &dmab) < 0) {\r\nprintk(KERN_ERR "snd-page-alloc: cannot allocate buffer pages (size = %d)\n", size);\r\npci_dev_put(pci);\r\nreturn count;\r\n}\r\nsnd_dma_reserve_buf(&dmab, snd_dma_pci_buf_id(pci));\r\n}\r\nalloced++;\r\n}\r\nif (! alloced) {\r\nfor (i = 0; i < buffers; i++) {\r\nstruct snd_dma_buffer dmab;\r\nmemset(&dmab, 0, sizeof(dmab));\r\nif (snd_dma_alloc_pages(SNDRV_DMA_TYPE_DEV, NULL,\r\nsize, &dmab) < 0) {\r\nprintk(KERN_ERR "snd-page-alloc: cannot allocate buffer pages (size = %d)\n", size);\r\nbreak;\r\n}\r\nsnd_dma_reserve_buf(&dmab, (unsigned int)((vendor << 16) | device));\r\n}\r\n}\r\n} else if (strcmp(token, "erase") == 0)\r\nfree_all_reserved_pages();\r\nelse\r\nprintk(KERN_ERR "snd-page-alloc: invalid proc cmd\n");\r\nreturn count;\r\n}\r\nstatic int __init snd_mem_init(void)\r\n{\r\n#ifdef CONFIG_PROC_FS\r\nsnd_mem_proc = proc_create(SND_MEM_PROC_FILE, 0644, NULL,\r\n&snd_mem_proc_fops);\r\n#endif\r\nreturn 0;\r\n}\r\nstatic void __exit snd_mem_exit(void)\r\n{\r\nremove_proc_entry(SND_MEM_PROC_FILE, NULL);\r\nfree_all_reserved_pages();\r\nif (snd_allocated_pages > 0)\r\nprintk(KERN_ERR "snd-malloc: Memory leak? pages not freed = %li\n", snd_allocated_pages);\r\n}
