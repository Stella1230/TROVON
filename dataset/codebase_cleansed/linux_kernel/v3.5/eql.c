static void eql_timer(unsigned long param)\r\n{\r\nequalizer_t *eql = (equalizer_t *) param;\r\nstruct list_head *this, *tmp, *head;\r\nspin_lock(&eql->queue.lock);\r\nhead = &eql->queue.all_slaves;\r\nlist_for_each_safe(this, tmp, head) {\r\nslave_t *slave = list_entry(this, slave_t, list);\r\nif ((slave->dev->flags & IFF_UP) == IFF_UP) {\r\nslave->bytes_queued -= slave->priority_Bps;\r\nif (slave->bytes_queued < 0)\r\nslave->bytes_queued = 0;\r\n} else {\r\neql_kill_one_slave(&eql->queue, slave);\r\n}\r\n}\r\nspin_unlock(&eql->queue.lock);\r\neql->timer.expires = jiffies + EQL_DEFAULT_RESCHED_IVAL;\r\nadd_timer(&eql->timer);\r\n}\r\nstatic void __init eql_setup(struct net_device *dev)\r\n{\r\nequalizer_t *eql = netdev_priv(dev);\r\ninit_timer(&eql->timer);\r\neql->timer.data = (unsigned long) eql;\r\neql->timer.expires = jiffies + EQL_DEFAULT_RESCHED_IVAL;\r\neql->timer.function = eql_timer;\r\nspin_lock_init(&eql->queue.lock);\r\nINIT_LIST_HEAD(&eql->queue.all_slaves);\r\neql->queue.master_dev = dev;\r\ndev->netdev_ops = &eql_netdev_ops;\r\ndev->mtu = EQL_DEFAULT_MTU;\r\ndev->flags = IFF_MASTER;\r\ndev->type = ARPHRD_SLIP;\r\ndev->tx_queue_len = 5;\r\ndev->priv_flags &= ~IFF_XMIT_DST_RELEASE;\r\n}\r\nstatic int eql_open(struct net_device *dev)\r\n{\r\nequalizer_t *eql = netdev_priv(dev);\r\nnetdev_info(dev,\r\n"remember to turn off Van-Jacobson compression on your slave devices\n");\r\nBUG_ON(!list_empty(&eql->queue.all_slaves));\r\neql->min_slaves = 1;\r\neql->max_slaves = EQL_DEFAULT_MAX_SLAVES;\r\nadd_timer(&eql->timer);\r\nreturn 0;\r\n}\r\nstatic void eql_kill_one_slave(slave_queue_t *queue, slave_t *slave)\r\n{\r\nlist_del(&slave->list);\r\nqueue->num_slaves--;\r\nslave->dev->flags &= ~IFF_SLAVE;\r\ndev_put(slave->dev);\r\nkfree(slave);\r\n}\r\nstatic void eql_kill_slave_queue(slave_queue_t *queue)\r\n{\r\nstruct list_head *head, *tmp, *this;\r\nspin_lock_bh(&queue->lock);\r\nhead = &queue->all_slaves;\r\nlist_for_each_safe(this, tmp, head) {\r\nslave_t *s = list_entry(this, slave_t, list);\r\neql_kill_one_slave(queue, s);\r\n}\r\nspin_unlock_bh(&queue->lock);\r\n}\r\nstatic int eql_close(struct net_device *dev)\r\n{\r\nequalizer_t *eql = netdev_priv(dev);\r\ndel_timer_sync(&eql->timer);\r\neql_kill_slave_queue(&eql->queue);\r\nreturn 0;\r\n}\r\nstatic int eql_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\r\n{\r\nif (cmd != EQL_GETMASTRCFG && cmd != EQL_GETSLAVECFG &&\r\n!capable(CAP_NET_ADMIN))\r\nreturn -EPERM;\r\nswitch (cmd) {\r\ncase EQL_ENSLAVE:\r\nreturn eql_enslave(dev, ifr->ifr_data);\r\ncase EQL_EMANCIPATE:\r\nreturn eql_emancipate(dev, ifr->ifr_data);\r\ncase EQL_GETSLAVECFG:\r\nreturn eql_g_slave_cfg(dev, ifr->ifr_data);\r\ncase EQL_SETSLAVECFG:\r\nreturn eql_s_slave_cfg(dev, ifr->ifr_data);\r\ncase EQL_GETMASTRCFG:\r\nreturn eql_g_master_cfg(dev, ifr->ifr_data);\r\ncase EQL_SETMASTRCFG:\r\nreturn eql_s_master_cfg(dev, ifr->ifr_data);\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nstatic slave_t *__eql_schedule_slaves(slave_queue_t *queue)\r\n{\r\nunsigned long best_load = ~0UL;\r\nstruct list_head *this, *tmp, *head;\r\nslave_t *best_slave;\r\nbest_slave = NULL;\r\nhead = &queue->all_slaves;\r\nlist_for_each_safe(this, tmp, head) {\r\nslave_t *slave = list_entry(this, slave_t, list);\r\nunsigned long slave_load, bytes_queued, priority_Bps;\r\nbytes_queued = slave->bytes_queued;\r\npriority_Bps = slave->priority_Bps;\r\nif ((slave->dev->flags & IFF_UP) == IFF_UP) {\r\nslave_load = (~0UL - (~0UL / 2)) -\r\n(priority_Bps) + bytes_queued * 8;\r\nif (slave_load < best_load) {\r\nbest_load = slave_load;\r\nbest_slave = slave;\r\n}\r\n} else {\r\neql_kill_one_slave(queue, slave);\r\n}\r\n}\r\nreturn best_slave;\r\n}\r\nstatic netdev_tx_t eql_slave_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nequalizer_t *eql = netdev_priv(dev);\r\nslave_t *slave;\r\nspin_lock(&eql->queue.lock);\r\nslave = __eql_schedule_slaves(&eql->queue);\r\nif (slave) {\r\nstruct net_device *slave_dev = slave->dev;\r\nskb->dev = slave_dev;\r\nskb->priority = TC_PRIO_FILLER;\r\nslave->bytes_queued += skb->len;\r\ndev_queue_xmit(skb);\r\ndev->stats.tx_packets++;\r\n} else {\r\ndev->stats.tx_dropped++;\r\ndev_kfree_skb(skb);\r\n}\r\nspin_unlock(&eql->queue.lock);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic slave_t *__eql_find_slave_dev(slave_queue_t *queue, struct net_device *dev)\r\n{\r\nstruct list_head *this, *head;\r\nhead = &queue->all_slaves;\r\nlist_for_each(this, head) {\r\nslave_t *slave = list_entry(this, slave_t, list);\r\nif (slave->dev == dev)\r\nreturn slave;\r\n}\r\nreturn NULL;\r\n}\r\nstatic inline int eql_is_full(slave_queue_t *queue)\r\n{\r\nequalizer_t *eql = netdev_priv(queue->master_dev);\r\nif (queue->num_slaves >= eql->max_slaves)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int __eql_insert_slave(slave_queue_t *queue, slave_t *slave)\r\n{\r\nif (!eql_is_full(queue)) {\r\nslave_t *duplicate_slave = NULL;\r\nduplicate_slave = __eql_find_slave_dev(queue, slave->dev);\r\nif (duplicate_slave)\r\neql_kill_one_slave(queue, duplicate_slave);\r\nlist_add(&slave->list, &queue->all_slaves);\r\nqueue->num_slaves++;\r\nslave->dev->flags |= IFF_SLAVE;\r\nreturn 0;\r\n}\r\nreturn -ENOSPC;\r\n}\r\nstatic int eql_enslave(struct net_device *master_dev, slaving_request_t __user *srqp)\r\n{\r\nstruct net_device *slave_dev;\r\nslaving_request_t srq;\r\nif (copy_from_user(&srq, srqp, sizeof (slaving_request_t)))\r\nreturn -EFAULT;\r\nslave_dev = dev_get_by_name(&init_net, srq.slave_name);\r\nif (slave_dev) {\r\nif ((master_dev->flags & IFF_UP) == IFF_UP) {\r\nif (!eql_is_master(slave_dev) &&\r\n!eql_is_slave(slave_dev)) {\r\nslave_t *s = kmalloc(sizeof(*s), GFP_KERNEL);\r\nequalizer_t *eql = netdev_priv(master_dev);\r\nint ret;\r\nif (!s) {\r\ndev_put(slave_dev);\r\nreturn -ENOMEM;\r\n}\r\nmemset(s, 0, sizeof(*s));\r\ns->dev = slave_dev;\r\ns->priority = srq.priority;\r\ns->priority_bps = srq.priority;\r\ns->priority_Bps = srq.priority / 8;\r\nspin_lock_bh(&eql->queue.lock);\r\nret = __eql_insert_slave(&eql->queue, s);\r\nif (ret) {\r\ndev_put(slave_dev);\r\nkfree(s);\r\n}\r\nspin_unlock_bh(&eql->queue.lock);\r\nreturn ret;\r\n}\r\n}\r\ndev_put(slave_dev);\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic int eql_emancipate(struct net_device *master_dev, slaving_request_t __user *srqp)\r\n{\r\nequalizer_t *eql = netdev_priv(master_dev);\r\nstruct net_device *slave_dev;\r\nslaving_request_t srq;\r\nint ret;\r\nif (copy_from_user(&srq, srqp, sizeof (slaving_request_t)))\r\nreturn -EFAULT;\r\nslave_dev = dev_get_by_name(&init_net, srq.slave_name);\r\nret = -EINVAL;\r\nif (slave_dev) {\r\nspin_lock_bh(&eql->queue.lock);\r\nif (eql_is_slave(slave_dev)) {\r\nslave_t *slave = __eql_find_slave_dev(&eql->queue,\r\nslave_dev);\r\nif (slave) {\r\neql_kill_one_slave(&eql->queue, slave);\r\nret = 0;\r\n}\r\n}\r\ndev_put(slave_dev);\r\nspin_unlock_bh(&eql->queue.lock);\r\n}\r\nreturn ret;\r\n}\r\nstatic int eql_g_slave_cfg(struct net_device *dev, slave_config_t __user *scp)\r\n{\r\nequalizer_t *eql = netdev_priv(dev);\r\nslave_t *slave;\r\nstruct net_device *slave_dev;\r\nslave_config_t sc;\r\nint ret;\r\nif (copy_from_user(&sc, scp, sizeof (slave_config_t)))\r\nreturn -EFAULT;\r\nslave_dev = dev_get_by_name(&init_net, sc.slave_name);\r\nif (!slave_dev)\r\nreturn -ENODEV;\r\nret = -EINVAL;\r\nspin_lock_bh(&eql->queue.lock);\r\nif (eql_is_slave(slave_dev)) {\r\nslave = __eql_find_slave_dev(&eql->queue, slave_dev);\r\nif (slave) {\r\nsc.priority = slave->priority;\r\nret = 0;\r\n}\r\n}\r\nspin_unlock_bh(&eql->queue.lock);\r\ndev_put(slave_dev);\r\nif (!ret && copy_to_user(scp, &sc, sizeof (slave_config_t)))\r\nret = -EFAULT;\r\nreturn ret;\r\n}\r\nstatic int eql_s_slave_cfg(struct net_device *dev, slave_config_t __user *scp)\r\n{\r\nslave_t *slave;\r\nequalizer_t *eql;\r\nstruct net_device *slave_dev;\r\nslave_config_t sc;\r\nint ret;\r\nif (copy_from_user(&sc, scp, sizeof (slave_config_t)))\r\nreturn -EFAULT;\r\nslave_dev = dev_get_by_name(&init_net, sc.slave_name);\r\nif (!slave_dev)\r\nreturn -ENODEV;\r\nret = -EINVAL;\r\neql = netdev_priv(dev);\r\nspin_lock_bh(&eql->queue.lock);\r\nif (eql_is_slave(slave_dev)) {\r\nslave = __eql_find_slave_dev(&eql->queue, slave_dev);\r\nif (slave) {\r\nslave->priority = sc.priority;\r\nslave->priority_bps = sc.priority;\r\nslave->priority_Bps = sc.priority / 8;\r\nret = 0;\r\n}\r\n}\r\nspin_unlock_bh(&eql->queue.lock);\r\ndev_put(slave_dev);\r\nreturn ret;\r\n}\r\nstatic int eql_g_master_cfg(struct net_device *dev, master_config_t __user *mcp)\r\n{\r\nequalizer_t *eql;\r\nmaster_config_t mc;\r\nmemset(&mc, 0, sizeof(master_config_t));\r\nif (eql_is_master(dev)) {\r\neql = netdev_priv(dev);\r\nmc.max_slaves = eql->max_slaves;\r\nmc.min_slaves = eql->min_slaves;\r\nif (copy_to_user(mcp, &mc, sizeof (master_config_t)))\r\nreturn -EFAULT;\r\nreturn 0;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic int eql_s_master_cfg(struct net_device *dev, master_config_t __user *mcp)\r\n{\r\nequalizer_t *eql;\r\nmaster_config_t mc;\r\nif (copy_from_user(&mc, mcp, sizeof (master_config_t)))\r\nreturn -EFAULT;\r\nif (eql_is_master(dev)) {\r\neql = netdev_priv(dev);\r\neql->max_slaves = mc.max_slaves;\r\neql->min_slaves = mc.min_slaves;\r\nreturn 0;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic int __init eql_init_module(void)\r\n{\r\nint err;\r\npr_info("%s\n", version);\r\ndev_eql = alloc_netdev(sizeof(equalizer_t), "eql", eql_setup);\r\nif (!dev_eql)\r\nreturn -ENOMEM;\r\nerr = register_netdev(dev_eql);\r\nif (err)\r\nfree_netdev(dev_eql);\r\nreturn err;\r\n}\r\nstatic void __exit eql_cleanup_module(void)\r\n{\r\nunregister_netdev(dev_eql);\r\nfree_netdev(dev_eql);\r\n}
