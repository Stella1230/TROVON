static void *early_alloc_pgtable(unsigned long size)\r\n{\r\nvoid *pt;\r\nif (init_bootmem_done)\r\npt = __alloc_bootmem(size, size, __pa(MAX_DMA_ADDRESS));\r\nelse\r\npt = __va(memblock_alloc_base(size, size,\r\n__pa(MAX_DMA_ADDRESS)));\r\nmemset(pt, 0, size);\r\nreturn pt;\r\n}\r\nint map_kernel_page(unsigned long ea, unsigned long pa, int flags)\r\n{\r\npgd_t *pgdp;\r\npud_t *pudp;\r\npmd_t *pmdp;\r\npte_t *ptep;\r\nif (slab_is_available()) {\r\npgdp = pgd_offset_k(ea);\r\npudp = pud_alloc(&init_mm, pgdp, ea);\r\nif (!pudp)\r\nreturn -ENOMEM;\r\npmdp = pmd_alloc(&init_mm, pudp, ea);\r\nif (!pmdp)\r\nreturn -ENOMEM;\r\nptep = pte_alloc_kernel(pmdp, ea);\r\nif (!ptep)\r\nreturn -ENOMEM;\r\nset_pte_at(&init_mm, ea, ptep, pfn_pte(pa >> PAGE_SHIFT,\r\n__pgprot(flags)));\r\n} else {\r\n#ifdef CONFIG_PPC_MMU_NOHASH\r\npgdp = pgd_offset_k(ea);\r\n#ifdef PUD_TABLE_SIZE\r\nif (pgd_none(*pgdp)) {\r\npudp = early_alloc_pgtable(PUD_TABLE_SIZE);\r\nBUG_ON(pudp == NULL);\r\npgd_populate(&init_mm, pgdp, pudp);\r\n}\r\n#endif\r\npudp = pud_offset(pgdp, ea);\r\nif (pud_none(*pudp)) {\r\npmdp = early_alloc_pgtable(PMD_TABLE_SIZE);\r\nBUG_ON(pmdp == NULL);\r\npud_populate(&init_mm, pudp, pmdp);\r\n}\r\npmdp = pmd_offset(pudp, ea);\r\nif (!pmd_present(*pmdp)) {\r\nptep = early_alloc_pgtable(PAGE_SIZE);\r\nBUG_ON(ptep == NULL);\r\npmd_populate_kernel(&init_mm, pmdp, ptep);\r\n}\r\nptep = pte_offset_kernel(pmdp, ea);\r\nset_pte_at(&init_mm, ea, ptep, pfn_pte(pa >> PAGE_SHIFT,\r\n__pgprot(flags)));\r\n#else\r\nif (htab_bolt_mapping(ea, ea + PAGE_SIZE, pa, flags,\r\nmmu_io_psize, mmu_kernel_ssize)) {\r\nprintk(KERN_ERR "Failed to do bolted mapping IO "\r\n"memory at %016lx !\n", pa);\r\nreturn -ENOMEM;\r\n}\r\n#endif\r\n}\r\nreturn 0;\r\n}\r\nvoid __iomem * __ioremap_at(phys_addr_t pa, void *ea, unsigned long size,\r\nunsigned long flags)\r\n{\r\nunsigned long i;\r\nif ((flags & _PAGE_PRESENT) == 0)\r\nflags |= pgprot_val(PAGE_KERNEL);\r\nif (flags & _PAGE_NO_CACHE)\r\nflags &= ~_PAGE_COHERENT;\r\nif (flags & _PAGE_4K_PFN)\r\nreturn NULL;\r\nWARN_ON(pa & ~PAGE_MASK);\r\nWARN_ON(((unsigned long)ea) & ~PAGE_MASK);\r\nWARN_ON(size & ~PAGE_MASK);\r\nfor (i = 0; i < size; i += PAGE_SIZE)\r\nif (map_kernel_page((unsigned long)ea+i, pa+i, flags))\r\nreturn NULL;\r\nreturn (void __iomem *)ea;\r\n}\r\nvoid __iounmap_at(void *ea, unsigned long size)\r\n{\r\nWARN_ON(((unsigned long)ea) & ~PAGE_MASK);\r\nWARN_ON(size & ~PAGE_MASK);\r\nunmap_kernel_range((unsigned long)ea, size);\r\n}\r\nvoid __iomem * __ioremap_caller(phys_addr_t addr, unsigned long size,\r\nunsigned long flags, void *caller)\r\n{\r\nphys_addr_t paligned;\r\nvoid __iomem *ret;\r\npaligned = addr & PAGE_MASK;\r\nsize = PAGE_ALIGN(addr + size) - paligned;\r\nif ((size == 0) || (paligned == 0))\r\nreturn NULL;\r\nif (mem_init_done) {\r\nstruct vm_struct *area;\r\narea = __get_vm_area_caller(size, VM_IOREMAP,\r\nioremap_bot, IOREMAP_END,\r\ncaller);\r\nif (area == NULL)\r\nreturn NULL;\r\narea->phys_addr = paligned;\r\nret = __ioremap_at(paligned, area->addr, size, flags);\r\nif (!ret)\r\nvunmap(area->addr);\r\n} else {\r\nret = __ioremap_at(paligned, (void *)ioremap_bot, size, flags);\r\nif (ret)\r\nioremap_bot += size;\r\n}\r\nif (ret)\r\nret += addr & ~PAGE_MASK;\r\nreturn ret;\r\n}\r\nvoid __iomem * __ioremap(phys_addr_t addr, unsigned long size,\r\nunsigned long flags)\r\n{\r\nreturn __ioremap_caller(addr, size, flags, __builtin_return_address(0));\r\n}\r\nvoid __iomem * ioremap(phys_addr_t addr, unsigned long size)\r\n{\r\nunsigned long flags = _PAGE_NO_CACHE | _PAGE_GUARDED;\r\nvoid *caller = __builtin_return_address(0);\r\nif (ppc_md.ioremap)\r\nreturn ppc_md.ioremap(addr, size, flags, caller);\r\nreturn __ioremap_caller(addr, size, flags, caller);\r\n}\r\nvoid __iomem * ioremap_wc(phys_addr_t addr, unsigned long size)\r\n{\r\nunsigned long flags = _PAGE_NO_CACHE;\r\nvoid *caller = __builtin_return_address(0);\r\nif (ppc_md.ioremap)\r\nreturn ppc_md.ioremap(addr, size, flags, caller);\r\nreturn __ioremap_caller(addr, size, flags, caller);\r\n}\r\nvoid __iomem * ioremap_prot(phys_addr_t addr, unsigned long size,\r\nunsigned long flags)\r\n{\r\nvoid *caller = __builtin_return_address(0);\r\nif (flags & _PAGE_RW)\r\nflags |= _PAGE_DIRTY;\r\nflags &= ~(_PAGE_USER | _PAGE_EXEC);\r\n#ifdef _PAGE_BAP_SR\r\nflags |= _PAGE_BAP_SR;\r\n#endif\r\nif (ppc_md.ioremap)\r\nreturn ppc_md.ioremap(addr, size, flags, caller);\r\nreturn __ioremap_caller(addr, size, flags, caller);\r\n}\r\nvoid __iounmap(volatile void __iomem *token)\r\n{\r\nvoid *addr;\r\nif (!mem_init_done)\r\nreturn;\r\naddr = (void *) ((unsigned long __force)\r\nPCI_FIX_ADDR(token) & PAGE_MASK);\r\nif ((unsigned long)addr < ioremap_bot) {\r\nprintk(KERN_WARNING "Attempt to iounmap early bolted mapping"\r\n" at 0x%p\n", addr);\r\nreturn;\r\n}\r\nvunmap(addr);\r\n}\r\nvoid iounmap(volatile void __iomem *token)\r\n{\r\nif (ppc_md.iounmap)\r\nppc_md.iounmap(token);\r\nelse\r\n__iounmap(token);\r\n}
