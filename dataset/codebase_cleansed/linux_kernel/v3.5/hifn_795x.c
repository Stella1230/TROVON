static inline u32 hifn_read_0(struct hifn_device *dev, u32 reg)\r\n{\r\nu32 ret;\r\nret = readl(dev->bar[0] + reg);\r\nreturn ret;\r\n}\r\nstatic inline u32 hifn_read_1(struct hifn_device *dev, u32 reg)\r\n{\r\nu32 ret;\r\nret = readl(dev->bar[1] + reg);\r\nreturn ret;\r\n}\r\nstatic inline void hifn_write_0(struct hifn_device *dev, u32 reg, u32 val)\r\n{\r\nwritel((__force u32)cpu_to_le32(val), dev->bar[0] + reg);\r\n}\r\nstatic inline void hifn_write_1(struct hifn_device *dev, u32 reg, u32 val)\r\n{\r\nwritel((__force u32)cpu_to_le32(val), dev->bar[1] + reg);\r\n}\r\nstatic void hifn_wait_puc(struct hifn_device *dev)\r\n{\r\nint i;\r\nu32 ret;\r\nfor (i=10000; i > 0; --i) {\r\nret = hifn_read_0(dev, HIFN_0_PUCTRL);\r\nif (!(ret & HIFN_PUCTRL_RESET))\r\nbreak;\r\nudelay(1);\r\n}\r\nif (!i)\r\ndprintk("%s: Failed to reset PUC unit.\n", dev->name);\r\n}\r\nstatic void hifn_reset_puc(struct hifn_device *dev)\r\n{\r\nhifn_write_0(dev, HIFN_0_PUCTRL, HIFN_PUCTRL_DMAENA);\r\nhifn_wait_puc(dev);\r\n}\r\nstatic void hifn_stop_device(struct hifn_device *dev)\r\n{\r\nhifn_write_1(dev, HIFN_1_DMA_CSR,\r\nHIFN_DMACSR_D_CTRL_DIS | HIFN_DMACSR_R_CTRL_DIS |\r\nHIFN_DMACSR_S_CTRL_DIS | HIFN_DMACSR_C_CTRL_DIS);\r\nhifn_write_0(dev, HIFN_0_PUIER, 0);\r\nhifn_write_1(dev, HIFN_1_DMA_IER, 0);\r\n}\r\nstatic void hifn_reset_dma(struct hifn_device *dev, int full)\r\n{\r\nhifn_stop_device(dev);\r\nhifn_write_1(dev, HIFN_1_DMA_CNFG, HIFN_DMACNFG_MSTRESET |\r\nHIFN_DMACNFG_DMARESET | HIFN_DMACNFG_MODE);\r\nmdelay(1);\r\nif (full) {\r\nhifn_write_1(dev, HIFN_1_DMA_CNFG, HIFN_DMACNFG_MODE);\r\nmdelay(1);\r\n} else {\r\nhifn_write_1(dev, HIFN_1_DMA_CNFG, HIFN_DMACNFG_MODE |\r\nHIFN_DMACNFG_MSTRESET);\r\nhifn_reset_puc(dev);\r\n}\r\nhifn_write_1(dev, HIFN_1_DMA_CNFG, HIFN_DMACNFG_MSTRESET |\r\nHIFN_DMACNFG_DMARESET | HIFN_DMACNFG_MODE);\r\nhifn_reset_puc(dev);\r\n}\r\nstatic u32 hifn_next_signature(u_int32_t a, u_int cnt)\r\n{\r\nint i;\r\nu32 v;\r\nfor (i = 0; i < cnt; i++) {\r\nv = a & 0x80080125;\r\nv ^= v >> 16;\r\nv ^= v >> 8;\r\nv ^= v >> 4;\r\nv ^= v >> 2;\r\nv ^= v >> 1;\r\na = (v & 1) ^ (a << 1);\r\n}\r\nreturn a;\r\n}\r\nstatic int hifn_rng_data_present(struct hwrng *rng, int wait)\r\n{\r\nstruct hifn_device *dev = (struct hifn_device *)rng->priv;\r\ns64 nsec;\r\nnsec = ktime_to_ns(ktime_sub(ktime_get(), dev->rngtime));\r\nnsec -= dev->rng_wait_time;\r\nif (nsec <= 0)\r\nreturn 1;\r\nif (!wait)\r\nreturn 0;\r\nndelay(nsec);\r\nreturn 1;\r\n}\r\nstatic int hifn_rng_data_read(struct hwrng *rng, u32 *data)\r\n{\r\nstruct hifn_device *dev = (struct hifn_device *)rng->priv;\r\n*data = hifn_read_1(dev, HIFN_1_RNG_DATA);\r\ndev->rngtime = ktime_get();\r\nreturn 4;\r\n}\r\nstatic int hifn_register_rng(struct hifn_device *dev)\r\n{\r\ndev->rng_wait_time = DIV_ROUND_UP(NSEC_PER_SEC, dev->pk_clk_freq) *\r\n256;\r\ndev->rng.name = dev->name;\r\ndev->rng.data_present = hifn_rng_data_present,\r\ndev->rng.data_read = hifn_rng_data_read,\r\ndev->rng.priv = (unsigned long)dev;\r\nreturn hwrng_register(&dev->rng);\r\n}\r\nstatic void hifn_unregister_rng(struct hifn_device *dev)\r\n{\r\nhwrng_unregister(&dev->rng);\r\n}\r\nstatic int hifn_init_pubrng(struct hifn_device *dev)\r\n{\r\nint i;\r\nhifn_write_1(dev, HIFN_1_PUB_RESET, hifn_read_1(dev, HIFN_1_PUB_RESET) |\r\nHIFN_PUBRST_RESET);\r\nfor (i=100; i > 0; --i) {\r\nmdelay(1);\r\nif ((hifn_read_1(dev, HIFN_1_PUB_RESET) & HIFN_PUBRST_RESET) == 0)\r\nbreak;\r\n}\r\nif (!i)\r\ndprintk("Chip %s: Failed to initialise public key engine.\n",\r\ndev->name);\r\nelse {\r\nhifn_write_1(dev, HIFN_1_PUB_IEN, HIFN_PUBIEN_DONE);\r\ndev->dmareg |= HIFN_DMAIER_PUBDONE;\r\nhifn_write_1(dev, HIFN_1_DMA_IER, dev->dmareg);\r\ndprintk("Chip %s: Public key engine has been successfully "\r\n"initialised.\n", dev->name);\r\n}\r\nhifn_write_1(dev, HIFN_1_RNG_CONFIG,\r\nhifn_read_1(dev, HIFN_1_RNG_CONFIG) | HIFN_RNGCFG_ENA);\r\ndprintk("Chip %s: RNG engine has been successfully initialised.\n",\r\ndev->name);\r\n#ifdef CONFIG_CRYPTO_DEV_HIFN_795X_RNG\r\nhifn_read_1(dev, HIFN_1_RNG_DATA);\r\ndev->rngtime = ktime_get();\r\n#endif\r\nreturn 0;\r\n}\r\nstatic int hifn_enable_crypto(struct hifn_device *dev)\r\n{\r\nu32 dmacfg, addr;\r\nchar *offtbl = NULL;\r\nint i;\r\nfor (i = 0; i < ARRAY_SIZE(pci2id); i++) {\r\nif (pci2id[i].pci_vendor == dev->pdev->vendor &&\r\npci2id[i].pci_prod == dev->pdev->device) {\r\nofftbl = pci2id[i].card_id;\r\nbreak;\r\n}\r\n}\r\nif (offtbl == NULL) {\r\ndprintk("Chip %s: Unknown card!\n", dev->name);\r\nreturn -ENODEV;\r\n}\r\ndmacfg = hifn_read_1(dev, HIFN_1_DMA_CNFG);\r\nhifn_write_1(dev, HIFN_1_DMA_CNFG,\r\nHIFN_DMACNFG_UNLOCK | HIFN_DMACNFG_MSTRESET |\r\nHIFN_DMACNFG_DMARESET | HIFN_DMACNFG_MODE);\r\nmdelay(1);\r\naddr = hifn_read_1(dev, HIFN_1_UNLOCK_SECRET1);\r\nmdelay(1);\r\nhifn_write_1(dev, HIFN_1_UNLOCK_SECRET2, 0);\r\nmdelay(1);\r\nfor (i=0; i<12; ++i) {\r\naddr = hifn_next_signature(addr, offtbl[i] + 0x101);\r\nhifn_write_1(dev, HIFN_1_UNLOCK_SECRET2, addr);\r\nmdelay(1);\r\n}\r\nhifn_write_1(dev, HIFN_1_DMA_CNFG, dmacfg);\r\ndprintk("Chip %s: %s.\n", dev->name, pci_name(dev->pdev));\r\nreturn 0;\r\n}\r\nstatic void hifn_init_dma(struct hifn_device *dev)\r\n{\r\nstruct hifn_dma *dma = (struct hifn_dma *)dev->desc_virt;\r\nu32 dptr = dev->desc_dma;\r\nint i;\r\nfor (i=0; i<HIFN_D_CMD_RSIZE; ++i)\r\ndma->cmdr[i].p = __cpu_to_le32(dptr +\r\noffsetof(struct hifn_dma, command_bufs[i][0]));\r\nfor (i=0; i<HIFN_D_RES_RSIZE; ++i)\r\ndma->resr[i].p = __cpu_to_le32(dptr +\r\noffsetof(struct hifn_dma, result_bufs[i][0]));\r\ndma->cmdr[HIFN_D_CMD_RSIZE].p = __cpu_to_le32(dptr +\r\noffsetof(struct hifn_dma, cmdr[0]));\r\ndma->srcr[HIFN_D_SRC_RSIZE].p = __cpu_to_le32(dptr +\r\noffsetof(struct hifn_dma, srcr[0]));\r\ndma->dstr[HIFN_D_DST_RSIZE].p = __cpu_to_le32(dptr +\r\noffsetof(struct hifn_dma, dstr[0]));\r\ndma->resr[HIFN_D_RES_RSIZE].p = __cpu_to_le32(dptr +\r\noffsetof(struct hifn_dma, resr[0]));\r\ndma->cmdu = dma->srcu = dma->dstu = dma->resu = 0;\r\ndma->cmdi = dma->srci = dma->dsti = dma->resi = 0;\r\ndma->cmdk = dma->srck = dma->dstk = dma->resk = 0;\r\n}\r\nstatic void hifn_init_pll(struct hifn_device *dev)\r\n{\r\nunsigned int freq, m;\r\nu32 pllcfg;\r\npllcfg = HIFN_1_PLL | HIFN_PLL_RESERVED_1;\r\nif (strncmp(hifn_pll_ref, "ext", 3) == 0)\r\npllcfg |= HIFN_PLL_REF_CLK_PLL;\r\nelse\r\npllcfg |= HIFN_PLL_REF_CLK_HBI;\r\nif (hifn_pll_ref[3] != '\0')\r\nfreq = simple_strtoul(hifn_pll_ref + 3, NULL, 10);\r\nelse {\r\nfreq = 66;\r\nprintk(KERN_INFO "hifn795x: assuming %uMHz clock speed, "\r\n"override with hifn_pll_ref=%.3s<frequency>\n",\r\nfreq, hifn_pll_ref);\r\n}\r\nm = HIFN_PLL_FCK_MAX / freq;\r\npllcfg |= (m / 2 - 1) << HIFN_PLL_ND_SHIFT;\r\nif (m <= 8)\r\npllcfg |= HIFN_PLL_IS_1_8;\r\nelse\r\npllcfg |= HIFN_PLL_IS_9_12;\r\nhifn_write_1(dev, HIFN_1_PLL, pllcfg |\r\nHIFN_PLL_PK_CLK_HBI | HIFN_PLL_PE_CLK_HBI | HIFN_PLL_BP);\r\nmdelay(10);\r\nhifn_write_1(dev, HIFN_1_PLL, pllcfg |\r\nHIFN_PLL_PK_CLK_HBI | HIFN_PLL_PE_CLK_HBI);\r\nhifn_write_1(dev, HIFN_1_PLL, pllcfg |\r\nHIFN_PLL_PK_CLK_PLL | HIFN_PLL_PE_CLK_PLL);\r\ndev->pk_clk_freq = 1000000 * (freq + 1) * m / 2;\r\n}\r\nstatic void hifn_init_registers(struct hifn_device *dev)\r\n{\r\nu32 dptr = dev->desc_dma;\r\nhifn_write_0(dev, HIFN_0_PUCTRL, HIFN_PUCTRL_DMAENA);\r\nhifn_write_0(dev, HIFN_0_FIFOCNFG, HIFN_FIFOCNFG_THRESHOLD);\r\nhifn_write_0(dev, HIFN_0_PUIER, HIFN_PUIER_DSTOVER);\r\nhifn_write_1(dev, HIFN_1_DMA_CRAR, dptr +\r\noffsetof(struct hifn_dma, cmdr[0]));\r\nhifn_write_1(dev, HIFN_1_DMA_SRAR, dptr +\r\noffsetof(struct hifn_dma, srcr[0]));\r\nhifn_write_1(dev, HIFN_1_DMA_DRAR, dptr +\r\noffsetof(struct hifn_dma, dstr[0]));\r\nhifn_write_1(dev, HIFN_1_DMA_RRAR, dptr +\r\noffsetof(struct hifn_dma, resr[0]));\r\nmdelay(2);\r\n#if 0\r\nhifn_write_1(dev, HIFN_1_DMA_CSR,\r\nHIFN_DMACSR_D_CTRL_DIS | HIFN_DMACSR_R_CTRL_DIS |\r\nHIFN_DMACSR_S_CTRL_DIS | HIFN_DMACSR_C_CTRL_DIS |\r\nHIFN_DMACSR_D_ABORT | HIFN_DMACSR_D_DONE | HIFN_DMACSR_D_LAST |\r\nHIFN_DMACSR_D_WAIT | HIFN_DMACSR_D_OVER |\r\nHIFN_DMACSR_R_ABORT | HIFN_DMACSR_R_DONE | HIFN_DMACSR_R_LAST |\r\nHIFN_DMACSR_R_WAIT | HIFN_DMACSR_R_OVER |\r\nHIFN_DMACSR_S_ABORT | HIFN_DMACSR_S_DONE | HIFN_DMACSR_S_LAST |\r\nHIFN_DMACSR_S_WAIT |\r\nHIFN_DMACSR_C_ABORT | HIFN_DMACSR_C_DONE | HIFN_DMACSR_C_LAST |\r\nHIFN_DMACSR_C_WAIT |\r\nHIFN_DMACSR_ENGINE |\r\nHIFN_DMACSR_PUBDONE);\r\n#else\r\nhifn_write_1(dev, HIFN_1_DMA_CSR,\r\nHIFN_DMACSR_C_CTRL_ENA | HIFN_DMACSR_S_CTRL_ENA |\r\nHIFN_DMACSR_D_CTRL_ENA | HIFN_DMACSR_R_CTRL_ENA |\r\nHIFN_DMACSR_D_ABORT | HIFN_DMACSR_D_DONE | HIFN_DMACSR_D_LAST |\r\nHIFN_DMACSR_D_WAIT | HIFN_DMACSR_D_OVER |\r\nHIFN_DMACSR_R_ABORT | HIFN_DMACSR_R_DONE | HIFN_DMACSR_R_LAST |\r\nHIFN_DMACSR_R_WAIT | HIFN_DMACSR_R_OVER |\r\nHIFN_DMACSR_S_ABORT | HIFN_DMACSR_S_DONE | HIFN_DMACSR_S_LAST |\r\nHIFN_DMACSR_S_WAIT |\r\nHIFN_DMACSR_C_ABORT | HIFN_DMACSR_C_DONE | HIFN_DMACSR_C_LAST |\r\nHIFN_DMACSR_C_WAIT |\r\nHIFN_DMACSR_ENGINE |\r\nHIFN_DMACSR_PUBDONE);\r\n#endif\r\nhifn_read_1(dev, HIFN_1_DMA_CSR);\r\ndev->dmareg |= HIFN_DMAIER_R_DONE | HIFN_DMAIER_C_ABORT |\r\nHIFN_DMAIER_D_OVER | HIFN_DMAIER_R_OVER |\r\nHIFN_DMAIER_S_ABORT | HIFN_DMAIER_D_ABORT | HIFN_DMAIER_R_ABORT |\r\nHIFN_DMAIER_ENGINE;\r\ndev->dmareg &= ~HIFN_DMAIER_C_WAIT;\r\nhifn_write_1(dev, HIFN_1_DMA_IER, dev->dmareg);\r\nhifn_read_1(dev, HIFN_1_DMA_IER);\r\n#if 0\r\nhifn_write_0(dev, HIFN_0_PUCNFG, HIFN_PUCNFG_ENCCNFG |\r\nHIFN_PUCNFG_DRFR_128 | HIFN_PUCNFG_TCALLPHASES |\r\nHIFN_PUCNFG_TCDRVTOTEM | HIFN_PUCNFG_BUS32 |\r\nHIFN_PUCNFG_DRAM);\r\n#else\r\nhifn_write_0(dev, HIFN_0_PUCNFG, 0x10342);\r\n#endif\r\nhifn_init_pll(dev);\r\nhifn_write_0(dev, HIFN_0_PUISR, HIFN_PUISR_DSTOVER);\r\nhifn_write_1(dev, HIFN_1_DMA_CNFG, HIFN_DMACNFG_MSTRESET |\r\nHIFN_DMACNFG_DMARESET | HIFN_DMACNFG_MODE | HIFN_DMACNFG_LAST |\r\n((HIFN_POLL_FREQUENCY << 16 ) & HIFN_DMACNFG_POLLFREQ) |\r\n((HIFN_POLL_SCALAR << 8) & HIFN_DMACNFG_POLLINVAL));\r\n}\r\nstatic int hifn_setup_base_command(struct hifn_device *dev, u8 *buf,\r\nunsigned dlen, unsigned slen, u16 mask, u8 snum)\r\n{\r\nstruct hifn_base_command *base_cmd;\r\nu8 *buf_pos = buf;\r\nbase_cmd = (struct hifn_base_command *)buf_pos;\r\nbase_cmd->masks = __cpu_to_le16(mask);\r\nbase_cmd->total_source_count =\r\n__cpu_to_le16(slen & HIFN_BASE_CMD_LENMASK_LO);\r\nbase_cmd->total_dest_count =\r\n__cpu_to_le16(dlen & HIFN_BASE_CMD_LENMASK_LO);\r\ndlen >>= 16;\r\nslen >>= 16;\r\nbase_cmd->session_num = __cpu_to_le16(snum |\r\n((slen << HIFN_BASE_CMD_SRCLEN_S) & HIFN_BASE_CMD_SRCLEN_M) |\r\n((dlen << HIFN_BASE_CMD_DSTLEN_S) & HIFN_BASE_CMD_DSTLEN_M));\r\nreturn sizeof(struct hifn_base_command);\r\n}\r\nstatic int hifn_setup_crypto_command(struct hifn_device *dev,\r\nu8 *buf, unsigned dlen, unsigned slen,\r\nu8 *key, int keylen, u8 *iv, int ivsize, u16 mode)\r\n{\r\nstruct hifn_dma *dma = (struct hifn_dma *)dev->desc_virt;\r\nstruct hifn_crypt_command *cry_cmd;\r\nu8 *buf_pos = buf;\r\nu16 cmd_len;\r\ncry_cmd = (struct hifn_crypt_command *)buf_pos;\r\ncry_cmd->source_count = __cpu_to_le16(dlen & 0xffff);\r\ndlen >>= 16;\r\ncry_cmd->masks = __cpu_to_le16(mode |\r\n((dlen << HIFN_CRYPT_CMD_SRCLEN_S) &\r\nHIFN_CRYPT_CMD_SRCLEN_M));\r\ncry_cmd->header_skip = 0;\r\ncry_cmd->reserved = 0;\r\nbuf_pos += sizeof(struct hifn_crypt_command);\r\ndma->cmdu++;\r\nif (dma->cmdu > 1) {\r\ndev->dmareg |= HIFN_DMAIER_C_WAIT;\r\nhifn_write_1(dev, HIFN_1_DMA_IER, dev->dmareg);\r\n}\r\nif (keylen) {\r\nmemcpy(buf_pos, key, keylen);\r\nbuf_pos += keylen;\r\n}\r\nif (ivsize) {\r\nmemcpy(buf_pos, iv, ivsize);\r\nbuf_pos += ivsize;\r\n}\r\ncmd_len = buf_pos - buf;\r\nreturn cmd_len;\r\n}\r\nstatic int hifn_setup_cmd_desc(struct hifn_device *dev,\r\nstruct hifn_context *ctx, struct hifn_request_context *rctx,\r\nvoid *priv, unsigned int nbytes)\r\n{\r\nstruct hifn_dma *dma = (struct hifn_dma *)dev->desc_virt;\r\nint cmd_len, sa_idx;\r\nu8 *buf, *buf_pos;\r\nu16 mask;\r\nsa_idx = dma->cmdi;\r\nbuf_pos = buf = dma->command_bufs[dma->cmdi];\r\nmask = 0;\r\nswitch (rctx->op) {\r\ncase ACRYPTO_OP_DECRYPT:\r\nmask = HIFN_BASE_CMD_CRYPT | HIFN_BASE_CMD_DECODE;\r\nbreak;\r\ncase ACRYPTO_OP_ENCRYPT:\r\nmask = HIFN_BASE_CMD_CRYPT;\r\nbreak;\r\ncase ACRYPTO_OP_HMAC:\r\nmask = HIFN_BASE_CMD_MAC;\r\nbreak;\r\ndefault:\r\ngoto err_out;\r\n}\r\nbuf_pos += hifn_setup_base_command(dev, buf_pos, nbytes,\r\nnbytes, mask, dev->snum);\r\nif (rctx->op == ACRYPTO_OP_ENCRYPT || rctx->op == ACRYPTO_OP_DECRYPT) {\r\nu16 md = 0;\r\nif (ctx->keysize)\r\nmd |= HIFN_CRYPT_CMD_NEW_KEY;\r\nif (rctx->iv && rctx->mode != ACRYPTO_MODE_ECB)\r\nmd |= HIFN_CRYPT_CMD_NEW_IV;\r\nswitch (rctx->mode) {\r\ncase ACRYPTO_MODE_ECB:\r\nmd |= HIFN_CRYPT_CMD_MODE_ECB;\r\nbreak;\r\ncase ACRYPTO_MODE_CBC:\r\nmd |= HIFN_CRYPT_CMD_MODE_CBC;\r\nbreak;\r\ncase ACRYPTO_MODE_CFB:\r\nmd |= HIFN_CRYPT_CMD_MODE_CFB;\r\nbreak;\r\ncase ACRYPTO_MODE_OFB:\r\nmd |= HIFN_CRYPT_CMD_MODE_OFB;\r\nbreak;\r\ndefault:\r\ngoto err_out;\r\n}\r\nswitch (rctx->type) {\r\ncase ACRYPTO_TYPE_AES_128:\r\nif (ctx->keysize != 16)\r\ngoto err_out;\r\nmd |= HIFN_CRYPT_CMD_KSZ_128 |\r\nHIFN_CRYPT_CMD_ALG_AES;\r\nbreak;\r\ncase ACRYPTO_TYPE_AES_192:\r\nif (ctx->keysize != 24)\r\ngoto err_out;\r\nmd |= HIFN_CRYPT_CMD_KSZ_192 |\r\nHIFN_CRYPT_CMD_ALG_AES;\r\nbreak;\r\ncase ACRYPTO_TYPE_AES_256:\r\nif (ctx->keysize != 32)\r\ngoto err_out;\r\nmd |= HIFN_CRYPT_CMD_KSZ_256 |\r\nHIFN_CRYPT_CMD_ALG_AES;\r\nbreak;\r\ncase ACRYPTO_TYPE_3DES:\r\nif (ctx->keysize != 24)\r\ngoto err_out;\r\nmd |= HIFN_CRYPT_CMD_ALG_3DES;\r\nbreak;\r\ncase ACRYPTO_TYPE_DES:\r\nif (ctx->keysize != 8)\r\ngoto err_out;\r\nmd |= HIFN_CRYPT_CMD_ALG_DES;\r\nbreak;\r\ndefault:\r\ngoto err_out;\r\n}\r\nbuf_pos += hifn_setup_crypto_command(dev, buf_pos,\r\nnbytes, nbytes, ctx->key, ctx->keysize,\r\nrctx->iv, rctx->ivsize, md);\r\n}\r\ndev->sa[sa_idx] = priv;\r\ndev->started++;\r\ncmd_len = buf_pos - buf;\r\ndma->cmdr[dma->cmdi].l = __cpu_to_le32(cmd_len | HIFN_D_VALID |\r\nHIFN_D_LAST | HIFN_D_MASKDONEIRQ);\r\nif (++dma->cmdi == HIFN_D_CMD_RSIZE) {\r\ndma->cmdr[dma->cmdi].l = __cpu_to_le32(\r\nHIFN_D_VALID | HIFN_D_LAST |\r\nHIFN_D_MASKDONEIRQ | HIFN_D_JUMP);\r\ndma->cmdi = 0;\r\n} else\r\ndma->cmdr[dma->cmdi-1].l |= __cpu_to_le32(HIFN_D_VALID);\r\nif (!(dev->flags & HIFN_FLAG_CMD_BUSY)) {\r\nhifn_write_1(dev, HIFN_1_DMA_CSR, HIFN_DMACSR_C_CTRL_ENA);\r\ndev->flags |= HIFN_FLAG_CMD_BUSY;\r\n}\r\nreturn 0;\r\nerr_out:\r\nreturn -EINVAL;\r\n}\r\nstatic int hifn_setup_src_desc(struct hifn_device *dev, struct page *page,\r\nunsigned int offset, unsigned int size, int last)\r\n{\r\nstruct hifn_dma *dma = (struct hifn_dma *)dev->desc_virt;\r\nint idx;\r\ndma_addr_t addr;\r\naddr = pci_map_page(dev->pdev, page, offset, size, PCI_DMA_TODEVICE);\r\nidx = dma->srci;\r\ndma->srcr[idx].p = __cpu_to_le32(addr);\r\ndma->srcr[idx].l = __cpu_to_le32(size | HIFN_D_VALID |\r\nHIFN_D_MASKDONEIRQ | (last ? HIFN_D_LAST : 0));\r\nif (++idx == HIFN_D_SRC_RSIZE) {\r\ndma->srcr[idx].l = __cpu_to_le32(HIFN_D_VALID |\r\nHIFN_D_JUMP | HIFN_D_MASKDONEIRQ |\r\n(last ? HIFN_D_LAST : 0));\r\nidx = 0;\r\n}\r\ndma->srci = idx;\r\ndma->srcu++;\r\nif (!(dev->flags & HIFN_FLAG_SRC_BUSY)) {\r\nhifn_write_1(dev, HIFN_1_DMA_CSR, HIFN_DMACSR_S_CTRL_ENA);\r\ndev->flags |= HIFN_FLAG_SRC_BUSY;\r\n}\r\nreturn size;\r\n}\r\nstatic void hifn_setup_res_desc(struct hifn_device *dev)\r\n{\r\nstruct hifn_dma *dma = (struct hifn_dma *)dev->desc_virt;\r\ndma->resr[dma->resi].l = __cpu_to_le32(HIFN_USED_RESULT |\r\nHIFN_D_VALID | HIFN_D_LAST);\r\nif (++dma->resi == HIFN_D_RES_RSIZE) {\r\ndma->resr[HIFN_D_RES_RSIZE].l = __cpu_to_le32(HIFN_D_VALID |\r\nHIFN_D_JUMP | HIFN_D_MASKDONEIRQ | HIFN_D_LAST);\r\ndma->resi = 0;\r\n}\r\ndma->resu++;\r\nif (!(dev->flags & HIFN_FLAG_RES_BUSY)) {\r\nhifn_write_1(dev, HIFN_1_DMA_CSR, HIFN_DMACSR_R_CTRL_ENA);\r\ndev->flags |= HIFN_FLAG_RES_BUSY;\r\n}\r\n}\r\nstatic void hifn_setup_dst_desc(struct hifn_device *dev, struct page *page,\r\nunsigned offset, unsigned size, int last)\r\n{\r\nstruct hifn_dma *dma = (struct hifn_dma *)dev->desc_virt;\r\nint idx;\r\ndma_addr_t addr;\r\naddr = pci_map_page(dev->pdev, page, offset, size, PCI_DMA_FROMDEVICE);\r\nidx = dma->dsti;\r\ndma->dstr[idx].p = __cpu_to_le32(addr);\r\ndma->dstr[idx].l = __cpu_to_le32(size | HIFN_D_VALID |\r\nHIFN_D_MASKDONEIRQ | (last ? HIFN_D_LAST : 0));\r\nif (++idx == HIFN_D_DST_RSIZE) {\r\ndma->dstr[idx].l = __cpu_to_le32(HIFN_D_VALID |\r\nHIFN_D_JUMP | HIFN_D_MASKDONEIRQ |\r\n(last ? HIFN_D_LAST : 0));\r\nidx = 0;\r\n}\r\ndma->dsti = idx;\r\ndma->dstu++;\r\nif (!(dev->flags & HIFN_FLAG_DST_BUSY)) {\r\nhifn_write_1(dev, HIFN_1_DMA_CSR, HIFN_DMACSR_D_CTRL_ENA);\r\ndev->flags |= HIFN_FLAG_DST_BUSY;\r\n}\r\n}\r\nstatic int hifn_setup_dma(struct hifn_device *dev,\r\nstruct hifn_context *ctx, struct hifn_request_context *rctx,\r\nstruct scatterlist *src, struct scatterlist *dst,\r\nunsigned int nbytes, void *priv)\r\n{\r\nstruct scatterlist *t;\r\nstruct page *spage, *dpage;\r\nunsigned int soff, doff;\r\nunsigned int n, len;\r\nn = nbytes;\r\nwhile (n) {\r\nspage = sg_page(src);\r\nsoff = src->offset;\r\nlen = min(src->length, n);\r\nhifn_setup_src_desc(dev, spage, soff, len, n - len == 0);\r\nsrc++;\r\nn -= len;\r\n}\r\nt = &rctx->walk.cache[0];\r\nn = nbytes;\r\nwhile (n) {\r\nif (t->length && rctx->walk.flags & ASYNC_FLAGS_MISALIGNED) {\r\nBUG_ON(!sg_page(t));\r\ndpage = sg_page(t);\r\ndoff = 0;\r\nlen = t->length;\r\n} else {\r\nBUG_ON(!sg_page(dst));\r\ndpage = sg_page(dst);\r\ndoff = dst->offset;\r\nlen = dst->length;\r\n}\r\nlen = min(len, n);\r\nhifn_setup_dst_desc(dev, dpage, doff, len, n - len == 0);\r\ndst++;\r\nt++;\r\nn -= len;\r\n}\r\nhifn_setup_cmd_desc(dev, ctx, rctx, priv, nbytes);\r\nhifn_setup_res_desc(dev);\r\nreturn 0;\r\n}\r\nstatic int hifn_cipher_walk_init(struct hifn_cipher_walk *w,\r\nint num, gfp_t gfp_flags)\r\n{\r\nint i;\r\nnum = min(ASYNC_SCATTERLIST_CACHE, num);\r\nsg_init_table(w->cache, num);\r\nw->num = 0;\r\nfor (i=0; i<num; ++i) {\r\nstruct page *page = alloc_page(gfp_flags);\r\nstruct scatterlist *s;\r\nif (!page)\r\nbreak;\r\ns = &w->cache[i];\r\nsg_set_page(s, page, PAGE_SIZE, 0);\r\nw->num++;\r\n}\r\nreturn i;\r\n}\r\nstatic void hifn_cipher_walk_exit(struct hifn_cipher_walk *w)\r\n{\r\nint i;\r\nfor (i=0; i<w->num; ++i) {\r\nstruct scatterlist *s = &w->cache[i];\r\n__free_page(sg_page(s));\r\ns->length = 0;\r\n}\r\nw->num = 0;\r\n}\r\nstatic int ablkcipher_add(unsigned int *drestp, struct scatterlist *dst,\r\nunsigned int size, unsigned int *nbytesp)\r\n{\r\nunsigned int copy, drest = *drestp, nbytes = *nbytesp;\r\nint idx = 0;\r\nif (drest < size || size > nbytes)\r\nreturn -EINVAL;\r\nwhile (size) {\r\ncopy = min3(drest, size, dst->length);\r\nsize -= copy;\r\ndrest -= copy;\r\nnbytes -= copy;\r\ndprintk("%s: copy: %u, size: %u, drest: %u, nbytes: %u.\n",\r\n__func__, copy, size, drest, nbytes);\r\ndst++;\r\nidx++;\r\n}\r\n*nbytesp = nbytes;\r\n*drestp = drest;\r\nreturn idx;\r\n}\r\nstatic int hifn_cipher_walk(struct ablkcipher_request *req,\r\nstruct hifn_cipher_walk *w)\r\n{\r\nstruct scatterlist *dst, *t;\r\nunsigned int nbytes = req->nbytes, offset, copy, diff;\r\nint idx, tidx, err;\r\ntidx = idx = 0;\r\noffset = 0;\r\nwhile (nbytes) {\r\nif (idx >= w->num && (w->flags & ASYNC_FLAGS_MISALIGNED))\r\nreturn -EINVAL;\r\ndst = &req->dst[idx];\r\ndprintk("\n%s: dlen: %u, doff: %u, offset: %u, nbytes: %u.\n",\r\n__func__, dst->length, dst->offset, offset, nbytes);\r\nif (!IS_ALIGNED(dst->offset, HIFN_D_DST_DALIGN) ||\r\n!IS_ALIGNED(dst->length, HIFN_D_DST_DALIGN) ||\r\noffset) {\r\nunsigned slen = min(dst->length - offset, nbytes);\r\nunsigned dlen = PAGE_SIZE;\r\nt = &w->cache[idx];\r\nerr = ablkcipher_add(&dlen, dst, slen, &nbytes);\r\nif (err < 0)\r\nreturn err;\r\nidx += err;\r\ncopy = slen & ~(HIFN_D_DST_DALIGN - 1);\r\ndiff = slen & (HIFN_D_DST_DALIGN - 1);\r\nif (dlen < nbytes) {\r\nnbytes += diff;\r\nprintk(KERN_ERR "%s: dlen: %u, nbytes: %u,"\r\n"slen: %u, offset: %u.\n",\r\n__func__, dlen, nbytes, slen, offset);\r\nprintk(KERN_ERR "%s: please contact author to fix this "\r\n"issue, generally you should not catch "\r\n"this path under any condition but who "\r\n"knows how did you use crypto code.\n"\r\n"Thank you.\n", __func__);\r\nBUG();\r\n} else {\r\ncopy += diff + nbytes;\r\ndst = &req->dst[idx];\r\nerr = ablkcipher_add(&dlen, dst, nbytes, &nbytes);\r\nif (err < 0)\r\nreturn err;\r\nidx += err;\r\n}\r\nt->length = copy;\r\nt->offset = offset;\r\n} else {\r\nnbytes -= min(dst->length, nbytes);\r\nidx++;\r\n}\r\ntidx++;\r\n}\r\nreturn tidx;\r\n}\r\nstatic int hifn_setup_session(struct ablkcipher_request *req)\r\n{\r\nstruct hifn_context *ctx = crypto_tfm_ctx(req->base.tfm);\r\nstruct hifn_request_context *rctx = ablkcipher_request_ctx(req);\r\nstruct hifn_device *dev = ctx->dev;\r\nunsigned long dlen, flags;\r\nunsigned int nbytes = req->nbytes, idx = 0;\r\nint err = -EINVAL, sg_num;\r\nstruct scatterlist *dst;\r\nif (rctx->iv && !rctx->ivsize && rctx->mode != ACRYPTO_MODE_ECB)\r\ngoto err_out_exit;\r\nrctx->walk.flags = 0;\r\nwhile (nbytes) {\r\ndst = &req->dst[idx];\r\ndlen = min(dst->length, nbytes);\r\nif (!IS_ALIGNED(dst->offset, HIFN_D_DST_DALIGN) ||\r\n!IS_ALIGNED(dlen, HIFN_D_DST_DALIGN))\r\nrctx->walk.flags |= ASYNC_FLAGS_MISALIGNED;\r\nnbytes -= dlen;\r\nidx++;\r\n}\r\nif (rctx->walk.flags & ASYNC_FLAGS_MISALIGNED) {\r\nerr = hifn_cipher_walk_init(&rctx->walk, idx, GFP_ATOMIC);\r\nif (err < 0)\r\nreturn err;\r\n}\r\nsg_num = hifn_cipher_walk(req, &rctx->walk);\r\nif (sg_num < 0) {\r\nerr = sg_num;\r\ngoto err_out_exit;\r\n}\r\nspin_lock_irqsave(&dev->lock, flags);\r\nif (dev->started + sg_num > HIFN_QUEUE_LENGTH) {\r\nerr = -EAGAIN;\r\ngoto err_out;\r\n}\r\nerr = hifn_setup_dma(dev, ctx, rctx, req->src, req->dst, req->nbytes, req);\r\nif (err)\r\ngoto err_out;\r\ndev->snum++;\r\ndev->active = HIFN_DEFAULT_ACTIVE_NUM;\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\nreturn 0;\r\nerr_out:\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\nerr_out_exit:\r\nif (err) {\r\nprintk("%s: iv: %p [%d], key: %p [%d], mode: %u, op: %u, "\r\n"type: %u, err: %d.\n",\r\ndev->name, rctx->iv, rctx->ivsize,\r\nctx->key, ctx->keysize,\r\nrctx->mode, rctx->op, rctx->type, err);\r\n}\r\nreturn err;\r\n}\r\nstatic int hifn_test(struct hifn_device *dev, int encdec, u8 snum)\r\n{\r\nint n, err;\r\nu8 src[16];\r\nstruct hifn_context ctx;\r\nstruct hifn_request_context rctx;\r\nu8 fips_aes_ecb_from_zero[16] = {\r\n0x66, 0xE9, 0x4B, 0xD4,\r\n0xEF, 0x8A, 0x2C, 0x3B,\r\n0x88, 0x4C, 0xFA, 0x59,\r\n0xCA, 0x34, 0x2B, 0x2E};\r\nstruct scatterlist sg;\r\nmemset(src, 0, sizeof(src));\r\nmemset(ctx.key, 0, sizeof(ctx.key));\r\nctx.dev = dev;\r\nctx.keysize = 16;\r\nrctx.ivsize = 0;\r\nrctx.iv = NULL;\r\nrctx.op = (encdec)?ACRYPTO_OP_ENCRYPT:ACRYPTO_OP_DECRYPT;\r\nrctx.mode = ACRYPTO_MODE_ECB;\r\nrctx.type = ACRYPTO_TYPE_AES_128;\r\nrctx.walk.cache[0].length = 0;\r\nsg_init_one(&sg, &src, sizeof(src));\r\nerr = hifn_setup_dma(dev, &ctx, &rctx, &sg, &sg, sizeof(src), NULL);\r\nif (err)\r\ngoto err_out;\r\ndev->started = 0;\r\nmsleep(200);\r\ndprintk("%s: decoded: ", dev->name);\r\nfor (n=0; n<sizeof(src); ++n)\r\ndprintk("%02x ", src[n]);\r\ndprintk("\n");\r\ndprintk("%s: FIPS : ", dev->name);\r\nfor (n=0; n<sizeof(fips_aes_ecb_from_zero); ++n)\r\ndprintk("%02x ", fips_aes_ecb_from_zero[n]);\r\ndprintk("\n");\r\nif (!memcmp(src, fips_aes_ecb_from_zero, sizeof(fips_aes_ecb_from_zero))) {\r\nprintk(KERN_INFO "%s: AES 128 ECB test has been successfully "\r\n"passed.\n", dev->name);\r\nreturn 0;\r\n}\r\nerr_out:\r\nprintk(KERN_INFO "%s: AES 128 ECB test has been failed.\n", dev->name);\r\nreturn -1;\r\n}\r\nstatic int hifn_start_device(struct hifn_device *dev)\r\n{\r\nint err;\r\ndev->started = dev->active = 0;\r\nhifn_reset_dma(dev, 1);\r\nerr = hifn_enable_crypto(dev);\r\nif (err)\r\nreturn err;\r\nhifn_reset_puc(dev);\r\nhifn_init_dma(dev);\r\nhifn_init_registers(dev);\r\nhifn_init_pubrng(dev);\r\nreturn 0;\r\n}\r\nstatic int ablkcipher_get(void *saddr, unsigned int *srestp, unsigned int offset,\r\nstruct scatterlist *dst, unsigned int size, unsigned int *nbytesp)\r\n{\r\nunsigned int srest = *srestp, nbytes = *nbytesp, copy;\r\nvoid *daddr;\r\nint idx = 0;\r\nif (srest < size || size > nbytes)\r\nreturn -EINVAL;\r\nwhile (size) {\r\ncopy = min3(srest, dst->length, size);\r\ndaddr = kmap_atomic(sg_page(dst));\r\nmemcpy(daddr + dst->offset + offset, saddr, copy);\r\nkunmap_atomic(daddr);\r\nnbytes -= copy;\r\nsize -= copy;\r\nsrest -= copy;\r\nsaddr += copy;\r\noffset = 0;\r\ndprintk("%s: copy: %u, size: %u, srest: %u, nbytes: %u.\n",\r\n__func__, copy, size, srest, nbytes);\r\ndst++;\r\nidx++;\r\n}\r\n*nbytesp = nbytes;\r\n*srestp = srest;\r\nreturn idx;\r\n}\r\nstatic inline void hifn_complete_sa(struct hifn_device *dev, int i)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&dev->lock, flags);\r\ndev->sa[i] = NULL;\r\ndev->started--;\r\nif (dev->started < 0)\r\nprintk("%s: started: %d.\n", __func__, dev->started);\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\nBUG_ON(dev->started < 0);\r\n}\r\nstatic void hifn_process_ready(struct ablkcipher_request *req, int error)\r\n{\r\nstruct hifn_request_context *rctx = ablkcipher_request_ctx(req);\r\nif (rctx->walk.flags & ASYNC_FLAGS_MISALIGNED) {\r\nunsigned int nbytes = req->nbytes;\r\nint idx = 0, err;\r\nstruct scatterlist *dst, *t;\r\nvoid *saddr;\r\nwhile (nbytes) {\r\nt = &rctx->walk.cache[idx];\r\ndst = &req->dst[idx];\r\ndprintk("\n%s: sg_page(t): %p, t->length: %u, "\r\n"sg_page(dst): %p, dst->length: %u, "\r\n"nbytes: %u.\n",\r\n__func__, sg_page(t), t->length,\r\nsg_page(dst), dst->length, nbytes);\r\nif (!t->length) {\r\nnbytes -= min(dst->length, nbytes);\r\nidx++;\r\ncontinue;\r\n}\r\nsaddr = kmap_atomic(sg_page(t));\r\nerr = ablkcipher_get(saddr, &t->length, t->offset,\r\ndst, nbytes, &nbytes);\r\nif (err < 0) {\r\nkunmap_atomic(saddr);\r\nbreak;\r\n}\r\nidx += err;\r\nkunmap_atomic(saddr);\r\n}\r\nhifn_cipher_walk_exit(&rctx->walk);\r\n}\r\nreq->base.complete(&req->base, error);\r\n}\r\nstatic void hifn_clear_rings(struct hifn_device *dev, int error)\r\n{\r\nstruct hifn_dma *dma = (struct hifn_dma *)dev->desc_virt;\r\nint i, u;\r\ndprintk("%s: ring cleanup 1: i: %d.%d.%d.%d, u: %d.%d.%d.%d, "\r\n"k: %d.%d.%d.%d.\n",\r\ndev->name,\r\ndma->cmdi, dma->srci, dma->dsti, dma->resi,\r\ndma->cmdu, dma->srcu, dma->dstu, dma->resu,\r\ndma->cmdk, dma->srck, dma->dstk, dma->resk);\r\ni = dma->resk; u = dma->resu;\r\nwhile (u != 0) {\r\nif (dma->resr[i].l & __cpu_to_le32(HIFN_D_VALID))\r\nbreak;\r\nif (dev->sa[i]) {\r\ndev->success++;\r\ndev->reset = 0;\r\nhifn_process_ready(dev->sa[i], error);\r\nhifn_complete_sa(dev, i);\r\n}\r\nif (++i == HIFN_D_RES_RSIZE)\r\ni = 0;\r\nu--;\r\n}\r\ndma->resk = i; dma->resu = u;\r\ni = dma->srck; u = dma->srcu;\r\nwhile (u != 0) {\r\nif (dma->srcr[i].l & __cpu_to_le32(HIFN_D_VALID))\r\nbreak;\r\nif (++i == HIFN_D_SRC_RSIZE)\r\ni = 0;\r\nu--;\r\n}\r\ndma->srck = i; dma->srcu = u;\r\ni = dma->cmdk; u = dma->cmdu;\r\nwhile (u != 0) {\r\nif (dma->cmdr[i].l & __cpu_to_le32(HIFN_D_VALID))\r\nbreak;\r\nif (++i == HIFN_D_CMD_RSIZE)\r\ni = 0;\r\nu--;\r\n}\r\ndma->cmdk = i; dma->cmdu = u;\r\ni = dma->dstk; u = dma->dstu;\r\nwhile (u != 0) {\r\nif (dma->dstr[i].l & __cpu_to_le32(HIFN_D_VALID))\r\nbreak;\r\nif (++i == HIFN_D_DST_RSIZE)\r\ni = 0;\r\nu--;\r\n}\r\ndma->dstk = i; dma->dstu = u;\r\ndprintk("%s: ring cleanup 2: i: %d.%d.%d.%d, u: %d.%d.%d.%d, "\r\n"k: %d.%d.%d.%d.\n",\r\ndev->name,\r\ndma->cmdi, dma->srci, dma->dsti, dma->resi,\r\ndma->cmdu, dma->srcu, dma->dstu, dma->resu,\r\ndma->cmdk, dma->srck, dma->dstk, dma->resk);\r\n}\r\nstatic void hifn_work(struct work_struct *work)\r\n{\r\nstruct delayed_work *dw = to_delayed_work(work);\r\nstruct hifn_device *dev = container_of(dw, struct hifn_device, work);\r\nunsigned long flags;\r\nint reset = 0;\r\nu32 r = 0;\r\nspin_lock_irqsave(&dev->lock, flags);\r\nif (dev->active == 0) {\r\nstruct hifn_dma *dma = (struct hifn_dma *)dev->desc_virt;\r\nif (dma->cmdu == 0 && (dev->flags & HIFN_FLAG_CMD_BUSY)) {\r\ndev->flags &= ~HIFN_FLAG_CMD_BUSY;\r\nr |= HIFN_DMACSR_C_CTRL_DIS;\r\n}\r\nif (dma->srcu == 0 && (dev->flags & HIFN_FLAG_SRC_BUSY)) {\r\ndev->flags &= ~HIFN_FLAG_SRC_BUSY;\r\nr |= HIFN_DMACSR_S_CTRL_DIS;\r\n}\r\nif (dma->dstu == 0 && (dev->flags & HIFN_FLAG_DST_BUSY)) {\r\ndev->flags &= ~HIFN_FLAG_DST_BUSY;\r\nr |= HIFN_DMACSR_D_CTRL_DIS;\r\n}\r\nif (dma->resu == 0 && (dev->flags & HIFN_FLAG_RES_BUSY)) {\r\ndev->flags &= ~HIFN_FLAG_RES_BUSY;\r\nr |= HIFN_DMACSR_R_CTRL_DIS;\r\n}\r\nif (r)\r\nhifn_write_1(dev, HIFN_1_DMA_CSR, r);\r\n} else\r\ndev->active--;\r\nif ((dev->prev_success == dev->success) && dev->started)\r\nreset = 1;\r\ndev->prev_success = dev->success;\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\nif (reset) {\r\nif (++dev->reset >= 5) {\r\nint i;\r\nstruct hifn_dma *dma = (struct hifn_dma *)dev->desc_virt;\r\nprintk("%s: r: %08x, active: %d, started: %d, "\r\n"success: %lu: qlen: %u/%u, reset: %d.\n",\r\ndev->name, r, dev->active, dev->started,\r\ndev->success, dev->queue.qlen, dev->queue.max_qlen,\r\nreset);\r\nprintk("%s: res: ", __func__);\r\nfor (i=0; i<HIFN_D_RES_RSIZE; ++i) {\r\nprintk("%x.%p ", dma->resr[i].l, dev->sa[i]);\r\nif (dev->sa[i]) {\r\nhifn_process_ready(dev->sa[i], -ENODEV);\r\nhifn_complete_sa(dev, i);\r\n}\r\n}\r\nprintk("\n");\r\nhifn_reset_dma(dev, 1);\r\nhifn_stop_device(dev);\r\nhifn_start_device(dev);\r\ndev->reset = 0;\r\n}\r\ntasklet_schedule(&dev->tasklet);\r\n}\r\nschedule_delayed_work(&dev->work, HZ);\r\n}\r\nstatic irqreturn_t hifn_interrupt(int irq, void *data)\r\n{\r\nstruct hifn_device *dev = (struct hifn_device *)data;\r\nstruct hifn_dma *dma = (struct hifn_dma *)dev->desc_virt;\r\nu32 dmacsr, restart;\r\ndmacsr = hifn_read_1(dev, HIFN_1_DMA_CSR);\r\ndprintk("%s: 1 dmacsr: %08x, dmareg: %08x, res: %08x [%d], "\r\n"i: %d.%d.%d.%d, u: %d.%d.%d.%d.\n",\r\ndev->name, dmacsr, dev->dmareg, dmacsr & dev->dmareg, dma->cmdi,\r\ndma->cmdi, dma->srci, dma->dsti, dma->resi,\r\ndma->cmdu, dma->srcu, dma->dstu, dma->resu);\r\nif ((dmacsr & dev->dmareg) == 0)\r\nreturn IRQ_NONE;\r\nhifn_write_1(dev, HIFN_1_DMA_CSR, dmacsr & dev->dmareg);\r\nif (dmacsr & HIFN_DMACSR_ENGINE)\r\nhifn_write_0(dev, HIFN_0_PUISR, hifn_read_0(dev, HIFN_0_PUISR));\r\nif (dmacsr & HIFN_DMACSR_PUBDONE)\r\nhifn_write_1(dev, HIFN_1_PUB_STATUS,\r\nhifn_read_1(dev, HIFN_1_PUB_STATUS) | HIFN_PUBSTS_DONE);\r\nrestart = dmacsr & (HIFN_DMACSR_R_OVER | HIFN_DMACSR_D_OVER);\r\nif (restart) {\r\nu32 puisr = hifn_read_0(dev, HIFN_0_PUISR);\r\nprintk(KERN_WARNING "%s: overflow: r: %d, d: %d, puisr: %08x, d: %u.\n",\r\ndev->name, !!(dmacsr & HIFN_DMACSR_R_OVER),\r\n!!(dmacsr & HIFN_DMACSR_D_OVER),\r\npuisr, !!(puisr & HIFN_PUISR_DSTOVER));\r\nif (!!(puisr & HIFN_PUISR_DSTOVER))\r\nhifn_write_0(dev, HIFN_0_PUISR, HIFN_PUISR_DSTOVER);\r\nhifn_write_1(dev, HIFN_1_DMA_CSR, dmacsr & (HIFN_DMACSR_R_OVER |\r\nHIFN_DMACSR_D_OVER));\r\n}\r\nrestart = dmacsr & (HIFN_DMACSR_C_ABORT | HIFN_DMACSR_S_ABORT |\r\nHIFN_DMACSR_D_ABORT | HIFN_DMACSR_R_ABORT);\r\nif (restart) {\r\nprintk(KERN_WARNING "%s: abort: c: %d, s: %d, d: %d, r: %d.\n",\r\ndev->name, !!(dmacsr & HIFN_DMACSR_C_ABORT),\r\n!!(dmacsr & HIFN_DMACSR_S_ABORT),\r\n!!(dmacsr & HIFN_DMACSR_D_ABORT),\r\n!!(dmacsr & HIFN_DMACSR_R_ABORT));\r\nhifn_reset_dma(dev, 1);\r\nhifn_init_dma(dev);\r\nhifn_init_registers(dev);\r\n}\r\nif ((dmacsr & HIFN_DMACSR_C_WAIT) && (dma->cmdu == 0)) {\r\ndprintk("%s: wait on command.\n", dev->name);\r\ndev->dmareg &= ~(HIFN_DMAIER_C_WAIT);\r\nhifn_write_1(dev, HIFN_1_DMA_IER, dev->dmareg);\r\n}\r\ntasklet_schedule(&dev->tasklet);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void hifn_flush(struct hifn_device *dev)\r\n{\r\nunsigned long flags;\r\nstruct crypto_async_request *async_req;\r\nstruct ablkcipher_request *req;\r\nstruct hifn_dma *dma = (struct hifn_dma *)dev->desc_virt;\r\nint i;\r\nfor (i=0; i<HIFN_D_RES_RSIZE; ++i) {\r\nstruct hifn_desc *d = &dma->resr[i];\r\nif (dev->sa[i]) {\r\nhifn_process_ready(dev->sa[i],\r\n(d->l & __cpu_to_le32(HIFN_D_VALID))?-ENODEV:0);\r\nhifn_complete_sa(dev, i);\r\n}\r\n}\r\nspin_lock_irqsave(&dev->lock, flags);\r\nwhile ((async_req = crypto_dequeue_request(&dev->queue))) {\r\nreq = container_of(async_req, struct ablkcipher_request, base);\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\nhifn_process_ready(req, -ENODEV);\r\nspin_lock_irqsave(&dev->lock, flags);\r\n}\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\n}\r\nstatic int hifn_setkey(struct crypto_ablkcipher *cipher, const u8 *key,\r\nunsigned int len)\r\n{\r\nstruct crypto_tfm *tfm = crypto_ablkcipher_tfm(cipher);\r\nstruct hifn_context *ctx = crypto_tfm_ctx(tfm);\r\nstruct hifn_device *dev = ctx->dev;\r\nif (len > HIFN_MAX_CRYPT_KEY_LENGTH) {\r\ncrypto_ablkcipher_set_flags(cipher, CRYPTO_TFM_RES_BAD_KEY_LEN);\r\nreturn -1;\r\n}\r\nif (len == HIFN_DES_KEY_LENGTH) {\r\nu32 tmp[DES_EXPKEY_WORDS];\r\nint ret = des_ekey(tmp, key);\r\nif (unlikely(ret == 0) && (tfm->crt_flags & CRYPTO_TFM_REQ_WEAK_KEY)) {\r\ntfm->crt_flags |= CRYPTO_TFM_RES_WEAK_KEY;\r\nreturn -EINVAL;\r\n}\r\n}\r\ndev->flags &= ~HIFN_FLAG_OLD_KEY;\r\nmemcpy(ctx->key, key, len);\r\nctx->keysize = len;\r\nreturn 0;\r\n}\r\nstatic int hifn_handle_req(struct ablkcipher_request *req)\r\n{\r\nstruct hifn_context *ctx = crypto_tfm_ctx(req->base.tfm);\r\nstruct hifn_device *dev = ctx->dev;\r\nint err = -EAGAIN;\r\nif (dev->started + DIV_ROUND_UP(req->nbytes, PAGE_SIZE) <= HIFN_QUEUE_LENGTH)\r\nerr = hifn_setup_session(req);\r\nif (err == -EAGAIN) {\r\nunsigned long flags;\r\nspin_lock_irqsave(&dev->lock, flags);\r\nerr = ablkcipher_enqueue_request(&dev->queue, req);\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\n}\r\nreturn err;\r\n}\r\nstatic int hifn_setup_crypto_req(struct ablkcipher_request *req, u8 op,\r\nu8 type, u8 mode)\r\n{\r\nstruct hifn_context *ctx = crypto_tfm_ctx(req->base.tfm);\r\nstruct hifn_request_context *rctx = ablkcipher_request_ctx(req);\r\nunsigned ivsize;\r\nivsize = crypto_ablkcipher_ivsize(crypto_ablkcipher_reqtfm(req));\r\nif (req->info && mode != ACRYPTO_MODE_ECB) {\r\nif (type == ACRYPTO_TYPE_AES_128)\r\nivsize = HIFN_AES_IV_LENGTH;\r\nelse if (type == ACRYPTO_TYPE_DES)\r\nivsize = HIFN_DES_KEY_LENGTH;\r\nelse if (type == ACRYPTO_TYPE_3DES)\r\nivsize = HIFN_3DES_KEY_LENGTH;\r\n}\r\nif (ctx->keysize != 16 && type == ACRYPTO_TYPE_AES_128) {\r\nif (ctx->keysize == 24)\r\ntype = ACRYPTO_TYPE_AES_192;\r\nelse if (ctx->keysize == 32)\r\ntype = ACRYPTO_TYPE_AES_256;\r\n}\r\nrctx->op = op;\r\nrctx->mode = mode;\r\nrctx->type = type;\r\nrctx->iv = req->info;\r\nrctx->ivsize = ivsize;\r\nreturn hifn_handle_req(req);\r\n}\r\nstatic int hifn_process_queue(struct hifn_device *dev)\r\n{\r\nstruct crypto_async_request *async_req, *backlog;\r\nstruct ablkcipher_request *req;\r\nunsigned long flags;\r\nint err = 0;\r\nwhile (dev->started < HIFN_QUEUE_LENGTH) {\r\nspin_lock_irqsave(&dev->lock, flags);\r\nbacklog = crypto_get_backlog(&dev->queue);\r\nasync_req = crypto_dequeue_request(&dev->queue);\r\nspin_unlock_irqrestore(&dev->lock, flags);\r\nif (!async_req)\r\nbreak;\r\nif (backlog)\r\nbacklog->complete(backlog, -EINPROGRESS);\r\nreq = container_of(async_req, struct ablkcipher_request, base);\r\nerr = hifn_handle_req(req);\r\nif (err)\r\nbreak;\r\n}\r\nreturn err;\r\n}\r\nstatic int hifn_setup_crypto(struct ablkcipher_request *req, u8 op,\r\nu8 type, u8 mode)\r\n{\r\nint err;\r\nstruct hifn_context *ctx = crypto_tfm_ctx(req->base.tfm);\r\nstruct hifn_device *dev = ctx->dev;\r\nerr = hifn_setup_crypto_req(req, op, type, mode);\r\nif (err)\r\nreturn err;\r\nif (dev->started < HIFN_QUEUE_LENGTH && dev->queue.qlen)\r\nhifn_process_queue(dev);\r\nreturn -EINPROGRESS;\r\n}\r\nstatic inline int hifn_encrypt_aes_ecb(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_ENCRYPT,\r\nACRYPTO_TYPE_AES_128, ACRYPTO_MODE_ECB);\r\n}\r\nstatic inline int hifn_encrypt_aes_cbc(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_ENCRYPT,\r\nACRYPTO_TYPE_AES_128, ACRYPTO_MODE_CBC);\r\n}\r\nstatic inline int hifn_encrypt_aes_cfb(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_ENCRYPT,\r\nACRYPTO_TYPE_AES_128, ACRYPTO_MODE_CFB);\r\n}\r\nstatic inline int hifn_encrypt_aes_ofb(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_ENCRYPT,\r\nACRYPTO_TYPE_AES_128, ACRYPTO_MODE_OFB);\r\n}\r\nstatic inline int hifn_decrypt_aes_ecb(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_DECRYPT,\r\nACRYPTO_TYPE_AES_128, ACRYPTO_MODE_ECB);\r\n}\r\nstatic inline int hifn_decrypt_aes_cbc(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_DECRYPT,\r\nACRYPTO_TYPE_AES_128, ACRYPTO_MODE_CBC);\r\n}\r\nstatic inline int hifn_decrypt_aes_cfb(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_DECRYPT,\r\nACRYPTO_TYPE_AES_128, ACRYPTO_MODE_CFB);\r\n}\r\nstatic inline int hifn_decrypt_aes_ofb(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_DECRYPT,\r\nACRYPTO_TYPE_AES_128, ACRYPTO_MODE_OFB);\r\n}\r\nstatic inline int hifn_encrypt_des_ecb(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_ENCRYPT,\r\nACRYPTO_TYPE_DES, ACRYPTO_MODE_ECB);\r\n}\r\nstatic inline int hifn_encrypt_des_cbc(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_ENCRYPT,\r\nACRYPTO_TYPE_DES, ACRYPTO_MODE_CBC);\r\n}\r\nstatic inline int hifn_encrypt_des_cfb(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_ENCRYPT,\r\nACRYPTO_TYPE_DES, ACRYPTO_MODE_CFB);\r\n}\r\nstatic inline int hifn_encrypt_des_ofb(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_ENCRYPT,\r\nACRYPTO_TYPE_DES, ACRYPTO_MODE_OFB);\r\n}\r\nstatic inline int hifn_decrypt_des_ecb(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_DECRYPT,\r\nACRYPTO_TYPE_DES, ACRYPTO_MODE_ECB);\r\n}\r\nstatic inline int hifn_decrypt_des_cbc(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_DECRYPT,\r\nACRYPTO_TYPE_DES, ACRYPTO_MODE_CBC);\r\n}\r\nstatic inline int hifn_decrypt_des_cfb(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_DECRYPT,\r\nACRYPTO_TYPE_DES, ACRYPTO_MODE_CFB);\r\n}\r\nstatic inline int hifn_decrypt_des_ofb(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_DECRYPT,\r\nACRYPTO_TYPE_DES, ACRYPTO_MODE_OFB);\r\n}\r\nstatic inline int hifn_encrypt_3des_ecb(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_ENCRYPT,\r\nACRYPTO_TYPE_3DES, ACRYPTO_MODE_ECB);\r\n}\r\nstatic inline int hifn_encrypt_3des_cbc(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_ENCRYPT,\r\nACRYPTO_TYPE_3DES, ACRYPTO_MODE_CBC);\r\n}\r\nstatic inline int hifn_encrypt_3des_cfb(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_ENCRYPT,\r\nACRYPTO_TYPE_3DES, ACRYPTO_MODE_CFB);\r\n}\r\nstatic inline int hifn_encrypt_3des_ofb(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_ENCRYPT,\r\nACRYPTO_TYPE_3DES, ACRYPTO_MODE_OFB);\r\n}\r\nstatic inline int hifn_decrypt_3des_ecb(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_DECRYPT,\r\nACRYPTO_TYPE_3DES, ACRYPTO_MODE_ECB);\r\n}\r\nstatic inline int hifn_decrypt_3des_cbc(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_DECRYPT,\r\nACRYPTO_TYPE_3DES, ACRYPTO_MODE_CBC);\r\n}\r\nstatic inline int hifn_decrypt_3des_cfb(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_DECRYPT,\r\nACRYPTO_TYPE_3DES, ACRYPTO_MODE_CFB);\r\n}\r\nstatic inline int hifn_decrypt_3des_ofb(struct ablkcipher_request *req)\r\n{\r\nreturn hifn_setup_crypto(req, ACRYPTO_OP_DECRYPT,\r\nACRYPTO_TYPE_3DES, ACRYPTO_MODE_OFB);\r\n}\r\nstatic int hifn_cra_init(struct crypto_tfm *tfm)\r\n{\r\nstruct crypto_alg *alg = tfm->__crt_alg;\r\nstruct hifn_crypto_alg *ha = crypto_alg_to_hifn(alg);\r\nstruct hifn_context *ctx = crypto_tfm_ctx(tfm);\r\nctx->dev = ha->dev;\r\ntfm->crt_ablkcipher.reqsize = sizeof(struct hifn_request_context);\r\nreturn 0;\r\n}\r\nstatic int hifn_alg_alloc(struct hifn_device *dev, struct hifn_alg_template *t)\r\n{\r\nstruct hifn_crypto_alg *alg;\r\nint err;\r\nalg = kzalloc(sizeof(struct hifn_crypto_alg), GFP_KERNEL);\r\nif (!alg)\r\nreturn -ENOMEM;\r\nsnprintf(alg->alg.cra_name, CRYPTO_MAX_ALG_NAME, "%s", t->name);\r\nsnprintf(alg->alg.cra_driver_name, CRYPTO_MAX_ALG_NAME, "%s-%s",\r\nt->drv_name, dev->name);\r\nalg->alg.cra_priority = 300;\r\nalg->alg.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER |\r\nCRYPTO_ALG_KERN_DRIVER_ONLY | CRYPTO_ALG_ASYNC;\r\nalg->alg.cra_blocksize = t->bsize;\r\nalg->alg.cra_ctxsize = sizeof(struct hifn_context);\r\nalg->alg.cra_alignmask = 0;\r\nalg->alg.cra_type = &crypto_ablkcipher_type;\r\nalg->alg.cra_module = THIS_MODULE;\r\nalg->alg.cra_u.ablkcipher = t->ablkcipher;\r\nalg->alg.cra_init = hifn_cra_init;\r\nalg->dev = dev;\r\nlist_add_tail(&alg->entry, &dev->alg_list);\r\nerr = crypto_register_alg(&alg->alg);\r\nif (err) {\r\nlist_del(&alg->entry);\r\nkfree(alg);\r\n}\r\nreturn err;\r\n}\r\nstatic void hifn_unregister_alg(struct hifn_device *dev)\r\n{\r\nstruct hifn_crypto_alg *a, *n;\r\nlist_for_each_entry_safe(a, n, &dev->alg_list, entry) {\r\nlist_del(&a->entry);\r\ncrypto_unregister_alg(&a->alg);\r\nkfree(a);\r\n}\r\n}\r\nstatic int hifn_register_alg(struct hifn_device *dev)\r\n{\r\nint i, err;\r\nfor (i=0; i<ARRAY_SIZE(hifn_alg_templates); ++i) {\r\nerr = hifn_alg_alloc(dev, &hifn_alg_templates[i]);\r\nif (err)\r\ngoto err_out_exit;\r\n}\r\nreturn 0;\r\nerr_out_exit:\r\nhifn_unregister_alg(dev);\r\nreturn err;\r\n}\r\nstatic void hifn_tasklet_callback(unsigned long data)\r\n{\r\nstruct hifn_device *dev = (struct hifn_device *)data;\r\nhifn_clear_rings(dev, 0);\r\nif (dev->started < HIFN_QUEUE_LENGTH && dev->queue.qlen)\r\nhifn_process_queue(dev);\r\n}\r\nstatic int __devinit hifn_probe(struct pci_dev *pdev, const struct pci_device_id *id)\r\n{\r\nint err, i;\r\nstruct hifn_device *dev;\r\nchar name[8];\r\nerr = pci_enable_device(pdev);\r\nif (err)\r\nreturn err;\r\npci_set_master(pdev);\r\nerr = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (err)\r\ngoto err_out_disable_pci_device;\r\nsnprintf(name, sizeof(name), "hifn%d",\r\natomic_inc_return(&hifn_dev_number)-1);\r\nerr = pci_request_regions(pdev, name);\r\nif (err)\r\ngoto err_out_disable_pci_device;\r\nif (pci_resource_len(pdev, 0) < HIFN_BAR0_SIZE ||\r\npci_resource_len(pdev, 1) < HIFN_BAR1_SIZE ||\r\npci_resource_len(pdev, 2) < HIFN_BAR2_SIZE) {\r\ndprintk("%s: Broken hardware - I/O regions are too small.\n",\r\npci_name(pdev));\r\nerr = -ENODEV;\r\ngoto err_out_free_regions;\r\n}\r\ndev = kzalloc(sizeof(struct hifn_device) + sizeof(struct crypto_alg),\r\nGFP_KERNEL);\r\nif (!dev) {\r\nerr = -ENOMEM;\r\ngoto err_out_free_regions;\r\n}\r\nINIT_LIST_HEAD(&dev->alg_list);\r\nsnprintf(dev->name, sizeof(dev->name), "%s", name);\r\nspin_lock_init(&dev->lock);\r\nfor (i=0; i<3; ++i) {\r\nunsigned long addr, size;\r\naddr = pci_resource_start(pdev, i);\r\nsize = pci_resource_len(pdev, i);\r\ndev->bar[i] = ioremap_nocache(addr, size);\r\nif (!dev->bar[i])\r\ngoto err_out_unmap_bars;\r\n}\r\ndev->desc_virt = pci_alloc_consistent(pdev, sizeof(struct hifn_dma),\r\n&dev->desc_dma);\r\nif (!dev->desc_virt) {\r\ndprintk("Failed to allocate descriptor rings.\n");\r\ngoto err_out_unmap_bars;\r\n}\r\nmemset(dev->desc_virt, 0, sizeof(struct hifn_dma));\r\ndev->pdev = pdev;\r\ndev->irq = pdev->irq;\r\nfor (i=0; i<HIFN_D_RES_RSIZE; ++i)\r\ndev->sa[i] = NULL;\r\npci_set_drvdata(pdev, dev);\r\ntasklet_init(&dev->tasklet, hifn_tasklet_callback, (unsigned long)dev);\r\ncrypto_init_queue(&dev->queue, 1);\r\nerr = request_irq(dev->irq, hifn_interrupt, IRQF_SHARED, dev->name, dev);\r\nif (err) {\r\ndprintk("Failed to request IRQ%d: err: %d.\n", dev->irq, err);\r\ndev->irq = 0;\r\ngoto err_out_free_desc;\r\n}\r\nerr = hifn_start_device(dev);\r\nif (err)\r\ngoto err_out_free_irq;\r\nerr = hifn_test(dev, 1, 0);\r\nif (err)\r\ngoto err_out_stop_device;\r\nerr = hifn_register_rng(dev);\r\nif (err)\r\ngoto err_out_stop_device;\r\nerr = hifn_register_alg(dev);\r\nif (err)\r\ngoto err_out_unregister_rng;\r\nINIT_DELAYED_WORK(&dev->work, hifn_work);\r\nschedule_delayed_work(&dev->work, HZ);\r\ndprintk("HIFN crypto accelerator card at %s has been "\r\n"successfully registered as %s.\n",\r\npci_name(pdev), dev->name);\r\nreturn 0;\r\nerr_out_unregister_rng:\r\nhifn_unregister_rng(dev);\r\nerr_out_stop_device:\r\nhifn_reset_dma(dev, 1);\r\nhifn_stop_device(dev);\r\nerr_out_free_irq:\r\nfree_irq(dev->irq, dev->name);\r\ntasklet_kill(&dev->tasklet);\r\nerr_out_free_desc:\r\npci_free_consistent(pdev, sizeof(struct hifn_dma),\r\ndev->desc_virt, dev->desc_dma);\r\nerr_out_unmap_bars:\r\nfor (i=0; i<3; ++i)\r\nif (dev->bar[i])\r\niounmap(dev->bar[i]);\r\nerr_out_free_regions:\r\npci_release_regions(pdev);\r\nerr_out_disable_pci_device:\r\npci_disable_device(pdev);\r\nreturn err;\r\n}\r\nstatic void __devexit hifn_remove(struct pci_dev *pdev)\r\n{\r\nint i;\r\nstruct hifn_device *dev;\r\ndev = pci_get_drvdata(pdev);\r\nif (dev) {\r\ncancel_delayed_work_sync(&dev->work);\r\nhifn_unregister_rng(dev);\r\nhifn_unregister_alg(dev);\r\nhifn_reset_dma(dev, 1);\r\nhifn_stop_device(dev);\r\nfree_irq(dev->irq, dev->name);\r\ntasklet_kill(&dev->tasklet);\r\nhifn_flush(dev);\r\npci_free_consistent(pdev, sizeof(struct hifn_dma),\r\ndev->desc_virt, dev->desc_dma);\r\nfor (i=0; i<3; ++i)\r\nif (dev->bar[i])\r\niounmap(dev->bar[i]);\r\nkfree(dev);\r\n}\r\npci_release_regions(pdev);\r\npci_disable_device(pdev);\r\n}\r\nstatic int __init hifn_init(void)\r\n{\r\nunsigned int freq;\r\nint err;\r\nBUILD_BUG_ON(sizeof(dma_addr_t) != 4);\r\nif (strncmp(hifn_pll_ref, "ext", 3) &&\r\nstrncmp(hifn_pll_ref, "pci", 3)) {\r\nprintk(KERN_ERR "hifn795x: invalid hifn_pll_ref clock, "\r\n"must be pci or ext");\r\nreturn -EINVAL;\r\n}\r\nif (hifn_pll_ref[3] != '\0') {\r\nfreq = simple_strtoul(hifn_pll_ref + 3, NULL, 10);\r\nif (freq < 20 || freq > 100) {\r\nprintk(KERN_ERR "hifn795x: invalid hifn_pll_ref "\r\n"frequency, must be in the range "\r\n"of 20-100");\r\nreturn -EINVAL;\r\n}\r\n}\r\nerr = pci_register_driver(&hifn_pci_driver);\r\nif (err < 0) {\r\ndprintk("Failed to register PCI driver for %s device.\n",\r\nhifn_pci_driver.name);\r\nreturn -ENODEV;\r\n}\r\nprintk(KERN_INFO "Driver for HIFN 795x crypto accelerator chip "\r\n"has been successfully registered.\n");\r\nreturn 0;\r\n}\r\nstatic void __exit hifn_fini(void)\r\n{\r\npci_unregister_driver(&hifn_pci_driver);\r\nprintk(KERN_INFO "Driver for HIFN 795x crypto accelerator chip "\r\n"has been successfully unregistered.\n");\r\n}
