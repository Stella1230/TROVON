void fnic_handle_link(struct work_struct *work)\r\n{\r\nstruct fnic *fnic = container_of(work, struct fnic, link_work);\r\nunsigned long flags;\r\nint old_link_status;\r\nu32 old_link_down_cnt;\r\nspin_lock_irqsave(&fnic->fnic_lock, flags);\r\nif (fnic->stop_rx_link_events) {\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nreturn;\r\n}\r\nold_link_down_cnt = fnic->link_down_cnt;\r\nold_link_status = fnic->link_status;\r\nfnic->link_status = vnic_dev_link_status(fnic->vdev);\r\nfnic->link_down_cnt = vnic_dev_link_down_cnt(fnic->vdev);\r\nif (old_link_status == fnic->link_status) {\r\nif (!fnic->link_status)\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nelse {\r\nif (old_link_down_cnt != fnic->link_down_cnt) {\r\nfnic->lport->host_stats.link_failure_count++;\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nFNIC_FCS_DBG(KERN_DEBUG, fnic->lport->host,\r\n"link down\n");\r\nfcoe_ctlr_link_down(&fnic->ctlr);\r\nFNIC_FCS_DBG(KERN_DEBUG, fnic->lport->host,\r\n"link up\n");\r\nfcoe_ctlr_link_up(&fnic->ctlr);\r\n} else\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\n}\r\n} else if (fnic->link_status) {\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nFNIC_FCS_DBG(KERN_DEBUG, fnic->lport->host, "link up\n");\r\nfcoe_ctlr_link_up(&fnic->ctlr);\r\n} else {\r\nfnic->lport->host_stats.link_failure_count++;\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nFNIC_FCS_DBG(KERN_DEBUG, fnic->lport->host, "link down\n");\r\nfcoe_ctlr_link_down(&fnic->ctlr);\r\n}\r\n}\r\nvoid fnic_handle_frame(struct work_struct *work)\r\n{\r\nstruct fnic *fnic = container_of(work, struct fnic, frame_work);\r\nstruct fc_lport *lp = fnic->lport;\r\nunsigned long flags;\r\nstruct sk_buff *skb;\r\nstruct fc_frame *fp;\r\nwhile ((skb = skb_dequeue(&fnic->frame_queue))) {\r\nspin_lock_irqsave(&fnic->fnic_lock, flags);\r\nif (fnic->stop_rx_link_events) {\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\ndev_kfree_skb(skb);\r\nreturn;\r\n}\r\nfp = (struct fc_frame *)skb;\r\nif (fnic->state != FNIC_IN_FC_MODE &&\r\nfnic->state != FNIC_IN_ETH_MODE) {\r\nskb_queue_head(&fnic->frame_queue, skb);\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nreturn;\r\n}\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nfc_exch_recv(lp, fp);\r\n}\r\n}\r\nstatic inline int fnic_import_rq_eth_pkt(struct fnic *fnic, struct sk_buff *skb)\r\n{\r\nstruct fc_frame *fp;\r\nstruct ethhdr *eh;\r\nstruct fcoe_hdr *fcoe_hdr;\r\nstruct fcoe_crc_eof *ft;\r\neh = (struct ethhdr *)skb->data;\r\nif (eh->h_proto == htons(ETH_P_8021Q)) {\r\nmemmove((u8 *)eh + VLAN_HLEN, eh, ETH_ALEN * 2);\r\neh = (struct ethhdr *)skb_pull(skb, VLAN_HLEN);\r\nskb_reset_mac_header(skb);\r\n}\r\nif (eh->h_proto == htons(ETH_P_FIP)) {\r\nskb_pull(skb, sizeof(*eh));\r\nfcoe_ctlr_recv(&fnic->ctlr, skb);\r\nreturn 1;\r\n}\r\nif (eh->h_proto != htons(ETH_P_FCOE))\r\ngoto drop;\r\nskb_set_network_header(skb, sizeof(*eh));\r\nskb_pull(skb, sizeof(*eh));\r\nfcoe_hdr = (struct fcoe_hdr *)skb->data;\r\nif (FC_FCOE_DECAPS_VER(fcoe_hdr) != FC_FCOE_VER)\r\ngoto drop;\r\nfp = (struct fc_frame *)skb;\r\nfc_frame_init(fp);\r\nfr_sof(fp) = fcoe_hdr->fcoe_sof;\r\nskb_pull(skb, sizeof(struct fcoe_hdr));\r\nskb_reset_transport_header(skb);\r\nft = (struct fcoe_crc_eof *)(skb->data + skb->len - sizeof(*ft));\r\nfr_eof(fp) = ft->fcoe_eof;\r\nskb_trim(skb, skb->len - sizeof(*ft));\r\nreturn 0;\r\ndrop:\r\ndev_kfree_skb_irq(skb);\r\nreturn -1;\r\n}\r\nvoid fnic_update_mac_locked(struct fnic *fnic, u8 *new)\r\n{\r\nu8 *ctl = fnic->ctlr.ctl_src_addr;\r\nu8 *data = fnic->data_src_addr;\r\nif (is_zero_ether_addr(new))\r\nnew = ctl;\r\nif (!compare_ether_addr(data, new))\r\nreturn;\r\nFNIC_FCS_DBG(KERN_DEBUG, fnic->lport->host, "update_mac %pM\n", new);\r\nif (!is_zero_ether_addr(data) && compare_ether_addr(data, ctl))\r\nvnic_dev_del_addr(fnic->vdev, data);\r\nmemcpy(data, new, ETH_ALEN);\r\nif (compare_ether_addr(new, ctl))\r\nvnic_dev_add_addr(fnic->vdev, new);\r\n}\r\nvoid fnic_update_mac(struct fc_lport *lport, u8 *new)\r\n{\r\nstruct fnic *fnic = lport_priv(lport);\r\nspin_lock_irq(&fnic->fnic_lock);\r\nfnic_update_mac_locked(fnic, new);\r\nspin_unlock_irq(&fnic->fnic_lock);\r\n}\r\nvoid fnic_set_port_id(struct fc_lport *lport, u32 port_id, struct fc_frame *fp)\r\n{\r\nstruct fnic *fnic = lport_priv(lport);\r\nu8 *mac;\r\nint ret;\r\nFNIC_FCS_DBG(KERN_DEBUG, lport->host, "set port_id %x fp %p\n",\r\nport_id, fp);\r\nif (!port_id) {\r\nfnic_update_mac(lport, fnic->ctlr.ctl_src_addr);\r\nfnic_set_eth_mode(fnic);\r\nreturn;\r\n}\r\nif (fp) {\r\nmac = fr_cb(fp)->granted_mac;\r\nif (is_zero_ether_addr(mac)) {\r\nfcoe_ctlr_recv_flogi(&fnic->ctlr, lport, fp);\r\n}\r\nfnic_update_mac(lport, mac);\r\n}\r\nspin_lock_irq(&fnic->fnic_lock);\r\nif (fnic->state == FNIC_IN_ETH_MODE || fnic->state == FNIC_IN_FC_MODE)\r\nfnic->state = FNIC_IN_ETH_TRANS_FC_MODE;\r\nelse {\r\nFNIC_FCS_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Unexpected fnic state %s while"\r\n" processing flogi resp\n",\r\nfnic_state_to_str(fnic->state));\r\nspin_unlock_irq(&fnic->fnic_lock);\r\nreturn;\r\n}\r\nspin_unlock_irq(&fnic->fnic_lock);\r\nret = fnic_flogi_reg_handler(fnic, port_id);\r\nif (ret < 0) {\r\nspin_lock_irq(&fnic->fnic_lock);\r\nif (fnic->state == FNIC_IN_ETH_TRANS_FC_MODE)\r\nfnic->state = FNIC_IN_ETH_MODE;\r\nspin_unlock_irq(&fnic->fnic_lock);\r\n}\r\n}\r\nstatic int fnic_rq_cmpl_handler_cont(struct vnic_dev *vdev,\r\nstruct cq_desc *cq_desc, u8 type,\r\nu16 q_number, u16 completed_index,\r\nvoid *opaque)\r\n{\r\nstruct fnic *fnic = vnic_dev_priv(vdev);\r\nvnic_rq_service(&fnic->rq[q_number], cq_desc, completed_index,\r\nVNIC_RQ_RETURN_DESC, fnic_rq_cmpl_frame_recv,\r\nNULL);\r\nreturn 0;\r\n}\r\nint fnic_rq_cmpl_handler(struct fnic *fnic, int rq_work_to_do)\r\n{\r\nunsigned int tot_rq_work_done = 0, cur_work_done;\r\nunsigned int i;\r\nint err;\r\nfor (i = 0; i < fnic->rq_count; i++) {\r\ncur_work_done = vnic_cq_service(&fnic->cq[i], rq_work_to_do,\r\nfnic_rq_cmpl_handler_cont,\r\nNULL);\r\nif (cur_work_done) {\r\nerr = vnic_rq_fill(&fnic->rq[i], fnic_alloc_rq_frame);\r\nif (err)\r\nshost_printk(KERN_ERR, fnic->lport->host,\r\n"fnic_alloc_rq_frame can't alloc"\r\n" frame\n");\r\n}\r\ntot_rq_work_done += cur_work_done;\r\n}\r\nreturn tot_rq_work_done;\r\n}\r\nint fnic_alloc_rq_frame(struct vnic_rq *rq)\r\n{\r\nstruct fnic *fnic = vnic_dev_priv(rq->vdev);\r\nstruct sk_buff *skb;\r\nu16 len;\r\ndma_addr_t pa;\r\nlen = FC_FRAME_HEADROOM + FC_MAX_FRAME + FC_FRAME_TAILROOM;\r\nskb = dev_alloc_skb(len);\r\nif (!skb) {\r\nFNIC_FCS_DBG(KERN_DEBUG, fnic->lport->host,\r\n"Unable to allocate RQ sk_buff\n");\r\nreturn -ENOMEM;\r\n}\r\nskb_reset_mac_header(skb);\r\nskb_reset_transport_header(skb);\r\nskb_reset_network_header(skb);\r\nskb_put(skb, len);\r\npa = pci_map_single(fnic->pdev, skb->data, len, PCI_DMA_FROMDEVICE);\r\nfnic_queue_rq_desc(rq, skb, pa, len);\r\nreturn 0;\r\n}\r\nvoid fnic_free_rq_buf(struct vnic_rq *rq, struct vnic_rq_buf *buf)\r\n{\r\nstruct fc_frame *fp = buf->os_buf;\r\nstruct fnic *fnic = vnic_dev_priv(rq->vdev);\r\npci_unmap_single(fnic->pdev, buf->dma_addr, buf->len,\r\nPCI_DMA_FROMDEVICE);\r\ndev_kfree_skb(fp_skb(fp));\r\nbuf->os_buf = NULL;\r\n}\r\nvoid fnic_eth_send(struct fcoe_ctlr *fip, struct sk_buff *skb)\r\n{\r\nstruct fnic *fnic = fnic_from_ctlr(fip);\r\nstruct vnic_wq *wq = &fnic->wq[0];\r\ndma_addr_t pa;\r\nstruct ethhdr *eth_hdr;\r\nstruct vlan_ethhdr *vlan_hdr;\r\nunsigned long flags;\r\nif (!fnic->vlan_hw_insert) {\r\neth_hdr = (struct ethhdr *)skb_mac_header(skb);\r\nvlan_hdr = (struct vlan_ethhdr *)skb_push(skb,\r\nsizeof(*vlan_hdr) - sizeof(*eth_hdr));\r\nmemcpy(vlan_hdr, eth_hdr, 2 * ETH_ALEN);\r\nvlan_hdr->h_vlan_proto = htons(ETH_P_8021Q);\r\nvlan_hdr->h_vlan_encapsulated_proto = eth_hdr->h_proto;\r\nvlan_hdr->h_vlan_TCI = htons(fnic->vlan_id);\r\n}\r\npa = pci_map_single(fnic->pdev, skb->data, skb->len, PCI_DMA_TODEVICE);\r\nspin_lock_irqsave(&fnic->wq_lock[0], flags);\r\nif (!vnic_wq_desc_avail(wq)) {\r\npci_unmap_single(fnic->pdev, pa, skb->len, PCI_DMA_TODEVICE);\r\nspin_unlock_irqrestore(&fnic->wq_lock[0], flags);\r\nkfree_skb(skb);\r\nreturn;\r\n}\r\nfnic_queue_wq_eth_desc(wq, skb, pa, skb->len,\r\nfnic->vlan_hw_insert, fnic->vlan_id, 1);\r\nspin_unlock_irqrestore(&fnic->wq_lock[0], flags);\r\n}\r\nstatic int fnic_send_frame(struct fnic *fnic, struct fc_frame *fp)\r\n{\r\nstruct vnic_wq *wq = &fnic->wq[0];\r\nstruct sk_buff *skb;\r\ndma_addr_t pa;\r\nstruct ethhdr *eth_hdr;\r\nstruct vlan_ethhdr *vlan_hdr;\r\nstruct fcoe_hdr *fcoe_hdr;\r\nstruct fc_frame_header *fh;\r\nu32 tot_len, eth_hdr_len;\r\nint ret = 0;\r\nunsigned long flags;\r\nfh = fc_frame_header_get(fp);\r\nskb = fp_skb(fp);\r\nif (unlikely(fh->fh_r_ctl == FC_RCTL_ELS_REQ) &&\r\nfcoe_ctlr_els_send(&fnic->ctlr, fnic->lport, skb))\r\nreturn 0;\r\nif (!fnic->vlan_hw_insert) {\r\neth_hdr_len = sizeof(*vlan_hdr) + sizeof(*fcoe_hdr);\r\nvlan_hdr = (struct vlan_ethhdr *)skb_push(skb, eth_hdr_len);\r\neth_hdr = (struct ethhdr *)vlan_hdr;\r\nvlan_hdr->h_vlan_proto = htons(ETH_P_8021Q);\r\nvlan_hdr->h_vlan_encapsulated_proto = htons(ETH_P_FCOE);\r\nvlan_hdr->h_vlan_TCI = htons(fnic->vlan_id);\r\nfcoe_hdr = (struct fcoe_hdr *)(vlan_hdr + 1);\r\n} else {\r\neth_hdr_len = sizeof(*eth_hdr) + sizeof(*fcoe_hdr);\r\neth_hdr = (struct ethhdr *)skb_push(skb, eth_hdr_len);\r\neth_hdr->h_proto = htons(ETH_P_FCOE);\r\nfcoe_hdr = (struct fcoe_hdr *)(eth_hdr + 1);\r\n}\r\nif (fnic->ctlr.map_dest)\r\nfc_fcoe_set_mac(eth_hdr->h_dest, fh->fh_d_id);\r\nelse\r\nmemcpy(eth_hdr->h_dest, fnic->ctlr.dest_addr, ETH_ALEN);\r\nmemcpy(eth_hdr->h_source, fnic->data_src_addr, ETH_ALEN);\r\ntot_len = skb->len;\r\nBUG_ON(tot_len % 4);\r\nmemset(fcoe_hdr, 0, sizeof(*fcoe_hdr));\r\nfcoe_hdr->fcoe_sof = fr_sof(fp);\r\nif (FC_FCOE_VER)\r\nFC_FCOE_ENCAPS_VER(fcoe_hdr, FC_FCOE_VER);\r\npa = pci_map_single(fnic->pdev, eth_hdr, tot_len, PCI_DMA_TODEVICE);\r\nspin_lock_irqsave(&fnic->wq_lock[0], flags);\r\nif (!vnic_wq_desc_avail(wq)) {\r\npci_unmap_single(fnic->pdev, pa,\r\ntot_len, PCI_DMA_TODEVICE);\r\nret = -1;\r\ngoto fnic_send_frame_end;\r\n}\r\nfnic_queue_wq_desc(wq, skb, pa, tot_len, fr_eof(fp),\r\nfnic->vlan_hw_insert, fnic->vlan_id, 1, 1, 1);\r\nfnic_send_frame_end:\r\nspin_unlock_irqrestore(&fnic->wq_lock[0], flags);\r\nif (ret)\r\ndev_kfree_skb_any(fp_skb(fp));\r\nreturn ret;\r\n}\r\nint fnic_send(struct fc_lport *lp, struct fc_frame *fp)\r\n{\r\nstruct fnic *fnic = lport_priv(lp);\r\nunsigned long flags;\r\nif (fnic->in_remove) {\r\ndev_kfree_skb(fp_skb(fp));\r\nreturn -1;\r\n}\r\nspin_lock_irqsave(&fnic->fnic_lock, flags);\r\nif (fnic->state != FNIC_IN_FC_MODE && fnic->state != FNIC_IN_ETH_MODE) {\r\nskb_queue_tail(&fnic->tx_queue, fp_skb(fp));\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nreturn 0;\r\n}\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nreturn fnic_send_frame(fnic, fp);\r\n}\r\nvoid fnic_flush_tx(struct fnic *fnic)\r\n{\r\nstruct sk_buff *skb;\r\nstruct fc_frame *fp;\r\nwhile ((skb = skb_dequeue(&fnic->tx_queue))) {\r\nfp = (struct fc_frame *)skb;\r\nfnic_send_frame(fnic, fp);\r\n}\r\n}\r\nstatic void fnic_set_eth_mode(struct fnic *fnic)\r\n{\r\nunsigned long flags;\r\nenum fnic_state old_state;\r\nint ret;\r\nspin_lock_irqsave(&fnic->fnic_lock, flags);\r\nagain:\r\nold_state = fnic->state;\r\nswitch (old_state) {\r\ncase FNIC_IN_FC_MODE:\r\ncase FNIC_IN_ETH_TRANS_FC_MODE:\r\ndefault:\r\nfnic->state = FNIC_IN_FC_TRANS_ETH_MODE;\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\nret = fnic_fw_reset_handler(fnic);\r\nspin_lock_irqsave(&fnic->fnic_lock, flags);\r\nif (fnic->state != FNIC_IN_FC_TRANS_ETH_MODE)\r\ngoto again;\r\nif (ret)\r\nfnic->state = old_state;\r\nbreak;\r\ncase FNIC_IN_FC_TRANS_ETH_MODE:\r\ncase FNIC_IN_ETH_MODE:\r\nbreak;\r\n}\r\nspin_unlock_irqrestore(&fnic->fnic_lock, flags);\r\n}\r\nstatic void fnic_wq_complete_frame_send(struct vnic_wq *wq,\r\nstruct cq_desc *cq_desc,\r\nstruct vnic_wq_buf *buf, void *opaque)\r\n{\r\nstruct sk_buff *skb = buf->os_buf;\r\nstruct fc_frame *fp = (struct fc_frame *)skb;\r\nstruct fnic *fnic = vnic_dev_priv(wq->vdev);\r\npci_unmap_single(fnic->pdev, buf->dma_addr,\r\nbuf->len, PCI_DMA_TODEVICE);\r\ndev_kfree_skb_irq(fp_skb(fp));\r\nbuf->os_buf = NULL;\r\n}\r\nstatic int fnic_wq_cmpl_handler_cont(struct vnic_dev *vdev,\r\nstruct cq_desc *cq_desc, u8 type,\r\nu16 q_number, u16 completed_index,\r\nvoid *opaque)\r\n{\r\nstruct fnic *fnic = vnic_dev_priv(vdev);\r\nunsigned long flags;\r\nspin_lock_irqsave(&fnic->wq_lock[q_number], flags);\r\nvnic_wq_service(&fnic->wq[q_number], cq_desc, completed_index,\r\nfnic_wq_complete_frame_send, NULL);\r\nspin_unlock_irqrestore(&fnic->wq_lock[q_number], flags);\r\nreturn 0;\r\n}\r\nint fnic_wq_cmpl_handler(struct fnic *fnic, int work_to_do)\r\n{\r\nunsigned int wq_work_done = 0;\r\nunsigned int i;\r\nfor (i = 0; i < fnic->raw_wq_count; i++) {\r\nwq_work_done += vnic_cq_service(&fnic->cq[fnic->rq_count+i],\r\nwork_to_do,\r\nfnic_wq_cmpl_handler_cont,\r\nNULL);\r\n}\r\nreturn wq_work_done;\r\n}\r\nvoid fnic_free_wq_buf(struct vnic_wq *wq, struct vnic_wq_buf *buf)\r\n{\r\nstruct fc_frame *fp = buf->os_buf;\r\nstruct fnic *fnic = vnic_dev_priv(wq->vdev);\r\npci_unmap_single(fnic->pdev, buf->dma_addr,\r\nbuf->len, PCI_DMA_TODEVICE);\r\ndev_kfree_skb(fp_skb(fp));\r\nbuf->os_buf = NULL;\r\n}
