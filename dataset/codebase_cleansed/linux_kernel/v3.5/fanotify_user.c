static struct fsnotify_event *get_one_event(struct fsnotify_group *group,\r\nsize_t count)\r\n{\r\nBUG_ON(!mutex_is_locked(&group->notification_mutex));\r\npr_debug("%s: group=%p count=%zd\n", __func__, group, count);\r\nif (fsnotify_notify_queue_is_empty(group))\r\nreturn NULL;\r\nif (FAN_EVENT_METADATA_LEN > count)\r\nreturn ERR_PTR(-EINVAL);\r\nreturn fsnotify_remove_notify_event(group);\r\n}\r\nstatic int create_fd(struct fsnotify_group *group, struct fsnotify_event *event)\r\n{\r\nint client_fd;\r\nstruct dentry *dentry;\r\nstruct vfsmount *mnt;\r\nstruct file *new_file;\r\npr_debug("%s: group=%p event=%p\n", __func__, group, event);\r\nclient_fd = get_unused_fd();\r\nif (client_fd < 0)\r\nreturn client_fd;\r\nif (event->data_type != FSNOTIFY_EVENT_PATH) {\r\nWARN_ON(1);\r\nput_unused_fd(client_fd);\r\nreturn -EINVAL;\r\n}\r\ndentry = dget(event->path.dentry);\r\nmnt = mntget(event->path.mnt);\r\nif (dentry && mnt)\r\nnew_file = dentry_open(dentry, mnt,\r\ngroup->fanotify_data.f_flags | FMODE_NONOTIFY,\r\ncurrent_cred());\r\nelse\r\nnew_file = ERR_PTR(-EOVERFLOW);\r\nif (IS_ERR(new_file)) {\r\nput_unused_fd(client_fd);\r\nclient_fd = PTR_ERR(new_file);\r\n} else {\r\nfd_install(client_fd, new_file);\r\n}\r\nreturn client_fd;\r\n}\r\nstatic int fill_event_metadata(struct fsnotify_group *group,\r\nstruct fanotify_event_metadata *metadata,\r\nstruct fsnotify_event *event)\r\n{\r\nint ret = 0;\r\npr_debug("%s: group=%p metadata=%p event=%p\n", __func__,\r\ngroup, metadata, event);\r\nmetadata->event_len = FAN_EVENT_METADATA_LEN;\r\nmetadata->metadata_len = FAN_EVENT_METADATA_LEN;\r\nmetadata->vers = FANOTIFY_METADATA_VERSION;\r\nmetadata->mask = event->mask & FAN_ALL_OUTGOING_EVENTS;\r\nmetadata->pid = pid_vnr(event->tgid);\r\nif (unlikely(event->mask & FAN_Q_OVERFLOW))\r\nmetadata->fd = FAN_NOFD;\r\nelse {\r\nmetadata->fd = create_fd(group, event);\r\nif (metadata->fd < 0)\r\nret = metadata->fd;\r\n}\r\nreturn ret;\r\n}\r\nstatic struct fanotify_response_event *dequeue_re(struct fsnotify_group *group,\r\n__s32 fd)\r\n{\r\nstruct fanotify_response_event *re, *return_re = NULL;\r\nmutex_lock(&group->fanotify_data.access_mutex);\r\nlist_for_each_entry(re, &group->fanotify_data.access_list, list) {\r\nif (re->fd != fd)\r\ncontinue;\r\nlist_del_init(&re->list);\r\nreturn_re = re;\r\nbreak;\r\n}\r\nmutex_unlock(&group->fanotify_data.access_mutex);\r\npr_debug("%s: found return_re=%p\n", __func__, return_re);\r\nreturn return_re;\r\n}\r\nstatic int process_access_response(struct fsnotify_group *group,\r\nstruct fanotify_response *response_struct)\r\n{\r\nstruct fanotify_response_event *re;\r\n__s32 fd = response_struct->fd;\r\n__u32 response = response_struct->response;\r\npr_debug("%s: group=%p fd=%d response=%d\n", __func__, group,\r\nfd, response);\r\nswitch (response) {\r\ncase FAN_ALLOW:\r\ncase FAN_DENY:\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nif (fd < 0)\r\nreturn -EINVAL;\r\nre = dequeue_re(group, fd);\r\nif (!re)\r\nreturn -ENOENT;\r\nre->event->response = response;\r\nwake_up(&group->fanotify_data.access_waitq);\r\nkmem_cache_free(fanotify_response_event_cache, re);\r\nreturn 0;\r\n}\r\nstatic int prepare_for_access_response(struct fsnotify_group *group,\r\nstruct fsnotify_event *event,\r\n__s32 fd)\r\n{\r\nstruct fanotify_response_event *re;\r\nif (!(event->mask & FAN_ALL_PERM_EVENTS))\r\nreturn 0;\r\nre = kmem_cache_alloc(fanotify_response_event_cache, GFP_KERNEL);\r\nif (!re)\r\nreturn -ENOMEM;\r\nre->event = event;\r\nre->fd = fd;\r\nmutex_lock(&group->fanotify_data.access_mutex);\r\nif (atomic_read(&group->fanotify_data.bypass_perm)) {\r\nmutex_unlock(&group->fanotify_data.access_mutex);\r\nkmem_cache_free(fanotify_response_event_cache, re);\r\nevent->response = FAN_ALLOW;\r\nreturn 0;\r\n}\r\nlist_add_tail(&re->list, &group->fanotify_data.access_list);\r\nmutex_unlock(&group->fanotify_data.access_mutex);\r\nreturn 0;\r\n}\r\nstatic void remove_access_response(struct fsnotify_group *group,\r\nstruct fsnotify_event *event,\r\n__s32 fd)\r\n{\r\nstruct fanotify_response_event *re;\r\nif (!(event->mask & FAN_ALL_PERM_EVENTS))\r\nreturn;\r\nre = dequeue_re(group, fd);\r\nif (!re)\r\nreturn;\r\nBUG_ON(re->event != event);\r\nkmem_cache_free(fanotify_response_event_cache, re);\r\nreturn;\r\n}\r\nstatic int prepare_for_access_response(struct fsnotify_group *group,\r\nstruct fsnotify_event *event,\r\n__s32 fd)\r\n{\r\nreturn 0;\r\n}\r\nstatic void remove_access_response(struct fsnotify_group *group,\r\nstruct fsnotify_event *event,\r\n__s32 fd)\r\n{\r\nreturn;\r\n}\r\nstatic ssize_t copy_event_to_user(struct fsnotify_group *group,\r\nstruct fsnotify_event *event,\r\nchar __user *buf)\r\n{\r\nstruct fanotify_event_metadata fanotify_event_metadata;\r\nint fd, ret;\r\npr_debug("%s: group=%p event=%p\n", __func__, group, event);\r\nret = fill_event_metadata(group, &fanotify_event_metadata, event);\r\nif (ret < 0)\r\ngoto out;\r\nfd = fanotify_event_metadata.fd;\r\nret = prepare_for_access_response(group, event, fd);\r\nif (ret)\r\ngoto out_close_fd;\r\nret = -EFAULT;\r\nif (copy_to_user(buf, &fanotify_event_metadata,\r\nfanotify_event_metadata.event_len))\r\ngoto out_kill_access_response;\r\nreturn fanotify_event_metadata.event_len;\r\nout_kill_access_response:\r\nremove_access_response(group, event, fd);\r\nout_close_fd:\r\nif (fd != FAN_NOFD)\r\nsys_close(fd);\r\nout:\r\n#ifdef CONFIG_FANOTIFY_ACCESS_PERMISSIONS\r\nif (event->mask & FAN_ALL_PERM_EVENTS) {\r\nevent->response = FAN_DENY;\r\nwake_up(&group->fanotify_data.access_waitq);\r\n}\r\n#endif\r\nreturn ret;\r\n}\r\nstatic unsigned int fanotify_poll(struct file *file, poll_table *wait)\r\n{\r\nstruct fsnotify_group *group = file->private_data;\r\nint ret = 0;\r\npoll_wait(file, &group->notification_waitq, wait);\r\nmutex_lock(&group->notification_mutex);\r\nif (!fsnotify_notify_queue_is_empty(group))\r\nret = POLLIN | POLLRDNORM;\r\nmutex_unlock(&group->notification_mutex);\r\nreturn ret;\r\n}\r\nstatic ssize_t fanotify_read(struct file *file, char __user *buf,\r\nsize_t count, loff_t *pos)\r\n{\r\nstruct fsnotify_group *group;\r\nstruct fsnotify_event *kevent;\r\nchar __user *start;\r\nint ret;\r\nDEFINE_WAIT(wait);\r\nstart = buf;\r\ngroup = file->private_data;\r\npr_debug("%s: group=%p\n", __func__, group);\r\nwhile (1) {\r\nprepare_to_wait(&group->notification_waitq, &wait, TASK_INTERRUPTIBLE);\r\nmutex_lock(&group->notification_mutex);\r\nkevent = get_one_event(group, count);\r\nmutex_unlock(&group->notification_mutex);\r\nif (kevent) {\r\nret = PTR_ERR(kevent);\r\nif (IS_ERR(kevent))\r\nbreak;\r\nret = copy_event_to_user(group, kevent, buf);\r\nfsnotify_put_event(kevent);\r\nif (ret < 0)\r\nbreak;\r\nbuf += ret;\r\ncount -= ret;\r\ncontinue;\r\n}\r\nret = -EAGAIN;\r\nif (file->f_flags & O_NONBLOCK)\r\nbreak;\r\nret = -ERESTARTSYS;\r\nif (signal_pending(current))\r\nbreak;\r\nif (start != buf)\r\nbreak;\r\nschedule();\r\n}\r\nfinish_wait(&group->notification_waitq, &wait);\r\nif (start != buf && ret != -EFAULT)\r\nret = buf - start;\r\nreturn ret;\r\n}\r\nstatic ssize_t fanotify_write(struct file *file, const char __user *buf, size_t count, loff_t *pos)\r\n{\r\n#ifdef CONFIG_FANOTIFY_ACCESS_PERMISSIONS\r\nstruct fanotify_response response = { .fd = -1, .response = -1 };\r\nstruct fsnotify_group *group;\r\nint ret;\r\ngroup = file->private_data;\r\nif (count > sizeof(response))\r\ncount = sizeof(response);\r\npr_debug("%s: group=%p count=%zu\n", __func__, group, count);\r\nif (copy_from_user(&response, buf, count))\r\nreturn -EFAULT;\r\nret = process_access_response(group, &response);\r\nif (ret < 0)\r\ncount = ret;\r\nreturn count;\r\n#else\r\nreturn -EINVAL;\r\n#endif\r\n}\r\nstatic int fanotify_release(struct inode *ignored, struct file *file)\r\n{\r\nstruct fsnotify_group *group = file->private_data;\r\n#ifdef CONFIG_FANOTIFY_ACCESS_PERMISSIONS\r\nstruct fanotify_response_event *re, *lre;\r\nmutex_lock(&group->fanotify_data.access_mutex);\r\natomic_inc(&group->fanotify_data.bypass_perm);\r\nlist_for_each_entry_safe(re, lre, &group->fanotify_data.access_list, list) {\r\npr_debug("%s: found group=%p re=%p event=%p\n", __func__, group,\r\nre, re->event);\r\nlist_del_init(&re->list);\r\nre->event->response = FAN_ALLOW;\r\nkmem_cache_free(fanotify_response_event_cache, re);\r\n}\r\nmutex_unlock(&group->fanotify_data.access_mutex);\r\nwake_up(&group->fanotify_data.access_waitq);\r\n#endif\r\nfsnotify_put_group(group);\r\nreturn 0;\r\n}\r\nstatic long fanotify_ioctl(struct file *file, unsigned int cmd, unsigned long arg)\r\n{\r\nstruct fsnotify_group *group;\r\nstruct fsnotify_event_holder *holder;\r\nvoid __user *p;\r\nint ret = -ENOTTY;\r\nsize_t send_len = 0;\r\ngroup = file->private_data;\r\np = (void __user *) arg;\r\nswitch (cmd) {\r\ncase FIONREAD:\r\nmutex_lock(&group->notification_mutex);\r\nlist_for_each_entry(holder, &group->notification_list, event_list)\r\nsend_len += FAN_EVENT_METADATA_LEN;\r\nmutex_unlock(&group->notification_mutex);\r\nret = put_user(send_len, (int __user *) p);\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nstatic void fanotify_free_mark(struct fsnotify_mark *fsn_mark)\r\n{\r\nkmem_cache_free(fanotify_mark_cache, fsn_mark);\r\n}\r\nstatic int fanotify_find_path(int dfd, const char __user *filename,\r\nstruct path *path, unsigned int flags)\r\n{\r\nint ret;\r\npr_debug("%s: dfd=%d filename=%p flags=%x\n", __func__,\r\ndfd, filename, flags);\r\nif (filename == NULL) {\r\nstruct file *file;\r\nint fput_needed;\r\nret = -EBADF;\r\nfile = fget_light(dfd, &fput_needed);\r\nif (!file)\r\ngoto out;\r\nret = -ENOTDIR;\r\nif ((flags & FAN_MARK_ONLYDIR) &&\r\n!(S_ISDIR(file->f_path.dentry->d_inode->i_mode))) {\r\nfput_light(file, fput_needed);\r\ngoto out;\r\n}\r\n*path = file->f_path;\r\npath_get(path);\r\nfput_light(file, fput_needed);\r\n} else {\r\nunsigned int lookup_flags = 0;\r\nif (!(flags & FAN_MARK_DONT_FOLLOW))\r\nlookup_flags |= LOOKUP_FOLLOW;\r\nif (flags & FAN_MARK_ONLYDIR)\r\nlookup_flags |= LOOKUP_DIRECTORY;\r\nret = user_path_at(dfd, filename, lookup_flags, path);\r\nif (ret)\r\ngoto out;\r\n}\r\nret = inode_permission(path->dentry->d_inode, MAY_READ);\r\nif (ret)\r\npath_put(path);\r\nout:\r\nreturn ret;\r\n}\r\nstatic __u32 fanotify_mark_remove_from_mask(struct fsnotify_mark *fsn_mark,\r\n__u32 mask,\r\nunsigned int flags)\r\n{\r\n__u32 oldmask;\r\nspin_lock(&fsn_mark->lock);\r\nif (!(flags & FAN_MARK_IGNORED_MASK)) {\r\noldmask = fsn_mark->mask;\r\nfsnotify_set_mark_mask_locked(fsn_mark, (oldmask & ~mask));\r\n} else {\r\noldmask = fsn_mark->ignored_mask;\r\nfsnotify_set_mark_ignored_mask_locked(fsn_mark, (oldmask & ~mask));\r\n}\r\nspin_unlock(&fsn_mark->lock);\r\nif (!(oldmask & ~mask))\r\nfsnotify_destroy_mark(fsn_mark);\r\nreturn mask & oldmask;\r\n}\r\nstatic int fanotify_remove_vfsmount_mark(struct fsnotify_group *group,\r\nstruct vfsmount *mnt, __u32 mask,\r\nunsigned int flags)\r\n{\r\nstruct fsnotify_mark *fsn_mark = NULL;\r\n__u32 removed;\r\nfsn_mark = fsnotify_find_vfsmount_mark(group, mnt);\r\nif (!fsn_mark)\r\nreturn -ENOENT;\r\nremoved = fanotify_mark_remove_from_mask(fsn_mark, mask, flags);\r\nfsnotify_put_mark(fsn_mark);\r\nif (removed & real_mount(mnt)->mnt_fsnotify_mask)\r\nfsnotify_recalc_vfsmount_mask(mnt);\r\nreturn 0;\r\n}\r\nstatic int fanotify_remove_inode_mark(struct fsnotify_group *group,\r\nstruct inode *inode, __u32 mask,\r\nunsigned int flags)\r\n{\r\nstruct fsnotify_mark *fsn_mark = NULL;\r\n__u32 removed;\r\nfsn_mark = fsnotify_find_inode_mark(group, inode);\r\nif (!fsn_mark)\r\nreturn -ENOENT;\r\nremoved = fanotify_mark_remove_from_mask(fsn_mark, mask, flags);\r\nfsnotify_put_mark(fsn_mark);\r\nif (removed & inode->i_fsnotify_mask)\r\nfsnotify_recalc_inode_mask(inode);\r\nreturn 0;\r\n}\r\nstatic __u32 fanotify_mark_add_to_mask(struct fsnotify_mark *fsn_mark,\r\n__u32 mask,\r\nunsigned int flags)\r\n{\r\n__u32 oldmask = -1;\r\nspin_lock(&fsn_mark->lock);\r\nif (!(flags & FAN_MARK_IGNORED_MASK)) {\r\noldmask = fsn_mark->mask;\r\nfsnotify_set_mark_mask_locked(fsn_mark, (oldmask | mask));\r\n} else {\r\n__u32 tmask = fsn_mark->ignored_mask | mask;\r\nfsnotify_set_mark_ignored_mask_locked(fsn_mark, tmask);\r\nif (flags & FAN_MARK_IGNORED_SURV_MODIFY)\r\nfsn_mark->flags |= FSNOTIFY_MARK_FLAG_IGNORED_SURV_MODIFY;\r\n}\r\nif (!(flags & FAN_MARK_ONDIR)) {\r\n__u32 tmask = fsn_mark->ignored_mask | FAN_ONDIR;\r\nfsnotify_set_mark_ignored_mask_locked(fsn_mark, tmask);\r\n}\r\nspin_unlock(&fsn_mark->lock);\r\nreturn mask & ~oldmask;\r\n}\r\nstatic int fanotify_add_vfsmount_mark(struct fsnotify_group *group,\r\nstruct vfsmount *mnt, __u32 mask,\r\nunsigned int flags)\r\n{\r\nstruct fsnotify_mark *fsn_mark;\r\n__u32 added;\r\nint ret = 0;\r\nfsn_mark = fsnotify_find_vfsmount_mark(group, mnt);\r\nif (!fsn_mark) {\r\nif (atomic_read(&group->num_marks) > group->fanotify_data.max_marks)\r\nreturn -ENOSPC;\r\nfsn_mark = kmem_cache_alloc(fanotify_mark_cache, GFP_KERNEL);\r\nif (!fsn_mark)\r\nreturn -ENOMEM;\r\nfsnotify_init_mark(fsn_mark, fanotify_free_mark);\r\nret = fsnotify_add_mark(fsn_mark, group, NULL, mnt, 0);\r\nif (ret)\r\ngoto err;\r\n}\r\nadded = fanotify_mark_add_to_mask(fsn_mark, mask, flags);\r\nif (added & ~real_mount(mnt)->mnt_fsnotify_mask)\r\nfsnotify_recalc_vfsmount_mask(mnt);\r\nerr:\r\nfsnotify_put_mark(fsn_mark);\r\nreturn ret;\r\n}\r\nstatic int fanotify_add_inode_mark(struct fsnotify_group *group,\r\nstruct inode *inode, __u32 mask,\r\nunsigned int flags)\r\n{\r\nstruct fsnotify_mark *fsn_mark;\r\n__u32 added;\r\nint ret = 0;\r\npr_debug("%s: group=%p inode=%p\n", __func__, group, inode);\r\nif ((flags & FAN_MARK_IGNORED_MASK) &&\r\n!(flags & FAN_MARK_IGNORED_SURV_MODIFY) &&\r\n(atomic_read(&inode->i_writecount) > 0))\r\nreturn 0;\r\nfsn_mark = fsnotify_find_inode_mark(group, inode);\r\nif (!fsn_mark) {\r\nif (atomic_read(&group->num_marks) > group->fanotify_data.max_marks)\r\nreturn -ENOSPC;\r\nfsn_mark = kmem_cache_alloc(fanotify_mark_cache, GFP_KERNEL);\r\nif (!fsn_mark)\r\nreturn -ENOMEM;\r\nfsnotify_init_mark(fsn_mark, fanotify_free_mark);\r\nret = fsnotify_add_mark(fsn_mark, group, inode, NULL, 0);\r\nif (ret)\r\ngoto err;\r\n}\r\nadded = fanotify_mark_add_to_mask(fsn_mark, mask, flags);\r\nif (added & ~inode->i_fsnotify_mask)\r\nfsnotify_recalc_inode_mask(inode);\r\nerr:\r\nfsnotify_put_mark(fsn_mark);\r\nreturn ret;\r\n}\r\nSYSCALL_DEFINE(fanotify_mark)(int fanotify_fd, unsigned int flags,\r\n__u64 mask, int dfd,\r\nconst char __user * pathname)\r\n{\r\nstruct inode *inode = NULL;\r\nstruct vfsmount *mnt = NULL;\r\nstruct fsnotify_group *group;\r\nstruct file *filp;\r\nstruct path path;\r\nint ret, fput_needed;\r\npr_debug("%s: fanotify_fd=%d flags=%x dfd=%d pathname=%p mask=%llx\n",\r\n__func__, fanotify_fd, flags, dfd, pathname, mask);\r\nif (mask & ((__u64)0xffffffff << 32))\r\nreturn -EINVAL;\r\nif (flags & ~FAN_ALL_MARK_FLAGS)\r\nreturn -EINVAL;\r\nswitch (flags & (FAN_MARK_ADD | FAN_MARK_REMOVE | FAN_MARK_FLUSH)) {\r\ncase FAN_MARK_ADD:\r\ncase FAN_MARK_REMOVE:\r\nif (!mask)\r\nreturn -EINVAL;\r\ncase FAN_MARK_FLUSH:\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nif (mask & FAN_ONDIR) {\r\nflags |= FAN_MARK_ONDIR;\r\nmask &= ~FAN_ONDIR;\r\n}\r\n#ifdef CONFIG_FANOTIFY_ACCESS_PERMISSIONS\r\nif (mask & ~(FAN_ALL_EVENTS | FAN_ALL_PERM_EVENTS | FAN_EVENT_ON_CHILD))\r\n#else\r\nif (mask & ~(FAN_ALL_EVENTS | FAN_EVENT_ON_CHILD))\r\n#endif\r\nreturn -EINVAL;\r\nfilp = fget_light(fanotify_fd, &fput_needed);\r\nif (unlikely(!filp))\r\nreturn -EBADF;\r\nret = -EINVAL;\r\nif (unlikely(filp->f_op != &fanotify_fops))\r\ngoto fput_and_out;\r\ngroup = filp->private_data;\r\nret = -EINVAL;\r\nif (mask & FAN_ALL_PERM_EVENTS &&\r\ngroup->priority == FS_PRIO_0)\r\ngoto fput_and_out;\r\nret = fanotify_find_path(dfd, pathname, &path, flags);\r\nif (ret)\r\ngoto fput_and_out;\r\nif (!(flags & FAN_MARK_MOUNT))\r\ninode = path.dentry->d_inode;\r\nelse\r\nmnt = path.mnt;\r\nswitch (flags & (FAN_MARK_ADD | FAN_MARK_REMOVE | FAN_MARK_FLUSH)) {\r\ncase FAN_MARK_ADD:\r\nif (flags & FAN_MARK_MOUNT)\r\nret = fanotify_add_vfsmount_mark(group, mnt, mask, flags);\r\nelse\r\nret = fanotify_add_inode_mark(group, inode, mask, flags);\r\nbreak;\r\ncase FAN_MARK_REMOVE:\r\nif (flags & FAN_MARK_MOUNT)\r\nret = fanotify_remove_vfsmount_mark(group, mnt, mask, flags);\r\nelse\r\nret = fanotify_remove_inode_mark(group, inode, mask, flags);\r\nbreak;\r\ncase FAN_MARK_FLUSH:\r\nif (flags & FAN_MARK_MOUNT)\r\nfsnotify_clear_vfsmount_marks_by_group(group);\r\nelse\r\nfsnotify_clear_inode_marks_by_group(group);\r\nbreak;\r\ndefault:\r\nret = -EINVAL;\r\n}\r\npath_put(&path);\r\nfput_and_out:\r\nfput_light(filp, fput_needed);\r\nreturn ret;\r\n}\r\nasmlinkage long SyS_fanotify_mark(long fanotify_fd, long flags, __u64 mask,\r\nlong dfd, long pathname)\r\n{\r\nreturn SYSC_fanotify_mark((int) fanotify_fd, (unsigned int) flags,\r\nmask, (int) dfd,\r\n(const char __user *) pathname);\r\n}\r\nstatic int __init fanotify_user_setup(void)\r\n{\r\nfanotify_mark_cache = KMEM_CACHE(fsnotify_mark, SLAB_PANIC);\r\nfanotify_response_event_cache = KMEM_CACHE(fanotify_response_event,\r\nSLAB_PANIC);\r\nreturn 0;\r\n}
