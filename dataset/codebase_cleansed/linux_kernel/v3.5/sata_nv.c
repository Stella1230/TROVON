static void nv_adma_register_mode(struct ata_port *ap)\r\n{\r\nstruct nv_adma_port_priv *pp = ap->private_data;\r\nvoid __iomem *mmio = pp->ctl_block;\r\nu16 tmp, status;\r\nint count = 0;\r\nif (pp->flags & NV_ADMA_PORT_REGISTER_MODE)\r\nreturn;\r\nstatus = readw(mmio + NV_ADMA_STAT);\r\nwhile (!(status & NV_ADMA_STAT_IDLE) && count < 20) {\r\nndelay(50);\r\nstatus = readw(mmio + NV_ADMA_STAT);\r\ncount++;\r\n}\r\nif (count == 20)\r\nata_port_warn(ap, "timeout waiting for ADMA IDLE, stat=0x%hx\n",\r\nstatus);\r\ntmp = readw(mmio + NV_ADMA_CTL);\r\nwritew(tmp & ~NV_ADMA_CTL_GO, mmio + NV_ADMA_CTL);\r\ncount = 0;\r\nstatus = readw(mmio + NV_ADMA_STAT);\r\nwhile (!(status & NV_ADMA_STAT_LEGACY) && count < 20) {\r\nndelay(50);\r\nstatus = readw(mmio + NV_ADMA_STAT);\r\ncount++;\r\n}\r\nif (count == 20)\r\nata_port_warn(ap,\r\n"timeout waiting for ADMA LEGACY, stat=0x%hx\n",\r\nstatus);\r\npp->flags |= NV_ADMA_PORT_REGISTER_MODE;\r\n}\r\nstatic void nv_adma_mode(struct ata_port *ap)\r\n{\r\nstruct nv_adma_port_priv *pp = ap->private_data;\r\nvoid __iomem *mmio = pp->ctl_block;\r\nu16 tmp, status;\r\nint count = 0;\r\nif (!(pp->flags & NV_ADMA_PORT_REGISTER_MODE))\r\nreturn;\r\nWARN_ON(pp->flags & NV_ADMA_ATAPI_SETUP_COMPLETE);\r\ntmp = readw(mmio + NV_ADMA_CTL);\r\nwritew(tmp | NV_ADMA_CTL_GO, mmio + NV_ADMA_CTL);\r\nstatus = readw(mmio + NV_ADMA_STAT);\r\nwhile (((status & NV_ADMA_STAT_LEGACY) ||\r\n!(status & NV_ADMA_STAT_IDLE)) && count < 20) {\r\nndelay(50);\r\nstatus = readw(mmio + NV_ADMA_STAT);\r\ncount++;\r\n}\r\nif (count == 20)\r\nata_port_warn(ap,\r\n"timeout waiting for ADMA LEGACY clear and IDLE, stat=0x%hx\n",\r\nstatus);\r\npp->flags &= ~NV_ADMA_PORT_REGISTER_MODE;\r\n}\r\nstatic int nv_adma_slave_config(struct scsi_device *sdev)\r\n{\r\nstruct ata_port *ap = ata_shost_to_port(sdev->host);\r\nstruct nv_adma_port_priv *pp = ap->private_data;\r\nstruct nv_adma_port_priv *port0, *port1;\r\nstruct scsi_device *sdev0, *sdev1;\r\nstruct pci_dev *pdev = to_pci_dev(ap->host->dev);\r\nunsigned long segment_boundary, flags;\r\nunsigned short sg_tablesize;\r\nint rc;\r\nint adma_enable;\r\nu32 current_reg, new_reg, config_mask;\r\nrc = ata_scsi_slave_config(sdev);\r\nif (sdev->id >= ATA_MAX_DEVICES || sdev->channel || sdev->lun)\r\nreturn rc;\r\nspin_lock_irqsave(ap->lock, flags);\r\nif (ap->link.device[sdev->id].class == ATA_DEV_ATAPI) {\r\nsegment_boundary = ATA_DMA_BOUNDARY;\r\nsg_tablesize = LIBATA_MAX_PRD - 1;\r\nadma_enable = 0;\r\nnv_adma_register_mode(ap);\r\n} else {\r\nsegment_boundary = NV_ADMA_DMA_BOUNDARY;\r\nsg_tablesize = NV_ADMA_SGTBL_TOTAL_LEN;\r\nadma_enable = 1;\r\n}\r\npci_read_config_dword(pdev, NV_MCP_SATA_CFG_20, &current_reg);\r\nif (ap->port_no == 1)\r\nconfig_mask = NV_MCP_SATA_CFG_20_PORT1_EN |\r\nNV_MCP_SATA_CFG_20_PORT1_PWB_EN;\r\nelse\r\nconfig_mask = NV_MCP_SATA_CFG_20_PORT0_EN |\r\nNV_MCP_SATA_CFG_20_PORT0_PWB_EN;\r\nif (adma_enable) {\r\nnew_reg = current_reg | config_mask;\r\npp->flags &= ~NV_ADMA_ATAPI_SETUP_COMPLETE;\r\n} else {\r\nnew_reg = current_reg & ~config_mask;\r\npp->flags |= NV_ADMA_ATAPI_SETUP_COMPLETE;\r\n}\r\nif (current_reg != new_reg)\r\npci_write_config_dword(pdev, NV_MCP_SATA_CFG_20, new_reg);\r\nport0 = ap->host->ports[0]->private_data;\r\nport1 = ap->host->ports[1]->private_data;\r\nsdev0 = ap->host->ports[0]->link.device[0].sdev;\r\nsdev1 = ap->host->ports[1]->link.device[0].sdev;\r\nif ((port0->flags & NV_ADMA_ATAPI_SETUP_COMPLETE) ||\r\n(port1->flags & NV_ADMA_ATAPI_SETUP_COMPLETE)) {\r\nif (sdev0)\r\nblk_queue_bounce_limit(sdev0->request_queue,\r\nATA_DMA_MASK);\r\nif (sdev1)\r\nblk_queue_bounce_limit(sdev1->request_queue,\r\nATA_DMA_MASK);\r\npci_set_dma_mask(pdev, ATA_DMA_MASK);\r\n} else {\r\npci_set_dma_mask(pdev, pp->adma_dma_mask);\r\nif (sdev0)\r\nblk_queue_bounce_limit(sdev0->request_queue,\r\npp->adma_dma_mask);\r\nif (sdev1)\r\nblk_queue_bounce_limit(sdev1->request_queue,\r\npp->adma_dma_mask);\r\n}\r\nblk_queue_segment_boundary(sdev->request_queue, segment_boundary);\r\nblk_queue_max_segments(sdev->request_queue, sg_tablesize);\r\nata_port_info(ap,\r\n"DMA mask 0x%llX, segment boundary 0x%lX, hw segs %hu\n",\r\n(unsigned long long)*ap->host->dev->dma_mask,\r\nsegment_boundary, sg_tablesize);\r\nspin_unlock_irqrestore(ap->lock, flags);\r\nreturn rc;\r\n}\r\nstatic int nv_adma_check_atapi_dma(struct ata_queued_cmd *qc)\r\n{\r\nstruct nv_adma_port_priv *pp = qc->ap->private_data;\r\nreturn !(pp->flags & NV_ADMA_ATAPI_SETUP_COMPLETE);\r\n}\r\nstatic void nv_adma_tf_read(struct ata_port *ap, struct ata_taskfile *tf)\r\n{\r\nnv_adma_register_mode(ap);\r\nata_sff_tf_read(ap, tf);\r\n}\r\nstatic unsigned int nv_adma_tf_to_cpb(struct ata_taskfile *tf, __le16 *cpb)\r\n{\r\nunsigned int idx = 0;\r\nif (tf->flags & ATA_TFLAG_ISADDR) {\r\nif (tf->flags & ATA_TFLAG_LBA48) {\r\ncpb[idx++] = cpu_to_le16((ATA_REG_ERR << 8) | tf->hob_feature | WNB);\r\ncpb[idx++] = cpu_to_le16((ATA_REG_NSECT << 8) | tf->hob_nsect);\r\ncpb[idx++] = cpu_to_le16((ATA_REG_LBAL << 8) | tf->hob_lbal);\r\ncpb[idx++] = cpu_to_le16((ATA_REG_LBAM << 8) | tf->hob_lbam);\r\ncpb[idx++] = cpu_to_le16((ATA_REG_LBAH << 8) | tf->hob_lbah);\r\ncpb[idx++] = cpu_to_le16((ATA_REG_ERR << 8) | tf->feature);\r\n} else\r\ncpb[idx++] = cpu_to_le16((ATA_REG_ERR << 8) | tf->feature | WNB);\r\ncpb[idx++] = cpu_to_le16((ATA_REG_NSECT << 8) | tf->nsect);\r\ncpb[idx++] = cpu_to_le16((ATA_REG_LBAL << 8) | tf->lbal);\r\ncpb[idx++] = cpu_to_le16((ATA_REG_LBAM << 8) | tf->lbam);\r\ncpb[idx++] = cpu_to_le16((ATA_REG_LBAH << 8) | tf->lbah);\r\n}\r\nif (tf->flags & ATA_TFLAG_DEVICE)\r\ncpb[idx++] = cpu_to_le16((ATA_REG_DEVICE << 8) | tf->device);\r\ncpb[idx++] = cpu_to_le16((ATA_REG_CMD << 8) | tf->command | CMDEND);\r\nwhile (idx < 12)\r\ncpb[idx++] = cpu_to_le16(IGN);\r\nreturn idx;\r\n}\r\nstatic int nv_adma_check_cpb(struct ata_port *ap, int cpb_num, int force_err)\r\n{\r\nstruct nv_adma_port_priv *pp = ap->private_data;\r\nu8 flags = pp->cpb[cpb_num].resp_flags;\r\nVPRINTK("CPB %d, flags=0x%x\n", cpb_num, flags);\r\nif (unlikely((force_err ||\r\nflags & (NV_CPB_RESP_ATA_ERR |\r\nNV_CPB_RESP_CMD_ERR |\r\nNV_CPB_RESP_CPB_ERR)))) {\r\nstruct ata_eh_info *ehi = &ap->link.eh_info;\r\nint freeze = 0;\r\nata_ehi_clear_desc(ehi);\r\n__ata_ehi_push_desc(ehi, "CPB resp_flags 0x%x: ", flags);\r\nif (flags & NV_CPB_RESP_ATA_ERR) {\r\nata_ehi_push_desc(ehi, "ATA error");\r\nehi->err_mask |= AC_ERR_DEV;\r\n} else if (flags & NV_CPB_RESP_CMD_ERR) {\r\nata_ehi_push_desc(ehi, "CMD error");\r\nehi->err_mask |= AC_ERR_DEV;\r\n} else if (flags & NV_CPB_RESP_CPB_ERR) {\r\nata_ehi_push_desc(ehi, "CPB error");\r\nehi->err_mask |= AC_ERR_SYSTEM;\r\nfreeze = 1;\r\n} else {\r\nata_ehi_push_desc(ehi, "unknown");\r\nehi->err_mask |= AC_ERR_OTHER;\r\nfreeze = 1;\r\n}\r\nif (freeze)\r\nata_port_freeze(ap);\r\nelse\r\nata_port_abort(ap);\r\nreturn -1;\r\n}\r\nif (likely(flags & NV_CPB_RESP_DONE))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int nv_host_intr(struct ata_port *ap, u8 irq_stat)\r\n{\r\nstruct ata_queued_cmd *qc = ata_qc_from_tag(ap, ap->link.active_tag);\r\nif (unlikely(irq_stat & (NV_INT_ADDED | NV_INT_REMOVED))) {\r\nata_port_freeze(ap);\r\nreturn 1;\r\n}\r\nif (!(irq_stat & NV_INT_DEV))\r\nreturn 0;\r\nif (unlikely(!qc || (qc->tf.flags & ATA_TFLAG_POLLING))) {\r\nata_sff_check_status(ap);\r\nreturn 1;\r\n}\r\nreturn ata_bmdma_port_intr(ap, qc);\r\n}\r\nstatic irqreturn_t nv_adma_interrupt(int irq, void *dev_instance)\r\n{\r\nstruct ata_host *host = dev_instance;\r\nint i, handled = 0;\r\nu32 notifier_clears[2];\r\nspin_lock(&host->lock);\r\nfor (i = 0; i < host->n_ports; i++) {\r\nstruct ata_port *ap = host->ports[i];\r\nstruct nv_adma_port_priv *pp = ap->private_data;\r\nvoid __iomem *mmio = pp->ctl_block;\r\nu16 status;\r\nu32 gen_ctl;\r\nu32 notifier, notifier_error;\r\nnotifier_clears[i] = 0;\r\nif (pp->flags & NV_ADMA_ATAPI_SETUP_COMPLETE) {\r\nu8 irq_stat = readb(host->iomap[NV_MMIO_BAR] + NV_INT_STATUS_CK804)\r\n>> (NV_INT_PORT_SHIFT * i);\r\nhandled += nv_host_intr(ap, irq_stat);\r\ncontinue;\r\n}\r\nif (pp->flags & NV_ADMA_PORT_REGISTER_MODE) {\r\nu8 irq_stat = readb(host->iomap[NV_MMIO_BAR] + NV_INT_STATUS_CK804)\r\n>> (NV_INT_PORT_SHIFT * i);\r\nif (ata_tag_valid(ap->link.active_tag))\r\nirq_stat |= NV_INT_DEV;\r\nhandled += nv_host_intr(ap, irq_stat);\r\n}\r\nnotifier = readl(mmio + NV_ADMA_NOTIFIER);\r\nnotifier_error = readl(mmio + NV_ADMA_NOTIFIER_ERROR);\r\nnotifier_clears[i] = notifier | notifier_error;\r\ngen_ctl = readl(pp->gen_block + NV_ADMA_GEN_CTL);\r\nif (!NV_ADMA_CHECK_INTR(gen_ctl, ap->port_no) && !notifier &&\r\n!notifier_error)\r\ncontinue;\r\nstatus = readw(mmio + NV_ADMA_STAT);\r\nwritew(status, mmio + NV_ADMA_STAT);\r\nreadw(mmio + NV_ADMA_STAT);\r\nrmb();\r\nhandled++;\r\nif (unlikely(status & (NV_ADMA_STAT_HOTPLUG |\r\nNV_ADMA_STAT_HOTUNPLUG |\r\nNV_ADMA_STAT_TIMEOUT |\r\nNV_ADMA_STAT_SERROR))) {\r\nstruct ata_eh_info *ehi = &ap->link.eh_info;\r\nata_ehi_clear_desc(ehi);\r\n__ata_ehi_push_desc(ehi, "ADMA status 0x%08x: ", status);\r\nif (status & NV_ADMA_STAT_TIMEOUT) {\r\nehi->err_mask |= AC_ERR_SYSTEM;\r\nata_ehi_push_desc(ehi, "timeout");\r\n} else if (status & NV_ADMA_STAT_HOTPLUG) {\r\nata_ehi_hotplugged(ehi);\r\nata_ehi_push_desc(ehi, "hotplug");\r\n} else if (status & NV_ADMA_STAT_HOTUNPLUG) {\r\nata_ehi_hotplugged(ehi);\r\nata_ehi_push_desc(ehi, "hot unplug");\r\n} else if (status & NV_ADMA_STAT_SERROR) {\r\nata_ehi_push_desc(ehi, "SError");\r\n} else\r\nata_ehi_push_desc(ehi, "unknown");\r\nata_port_freeze(ap);\r\ncontinue;\r\n}\r\nif (status & (NV_ADMA_STAT_DONE |\r\nNV_ADMA_STAT_CPBERR |\r\nNV_ADMA_STAT_CMD_COMPLETE)) {\r\nu32 check_commands = notifier_clears[i];\r\nu32 done_mask = 0;\r\nint pos, rc;\r\nif (status & NV_ADMA_STAT_CPBERR) {\r\nif (ata_tag_valid(ap->link.active_tag))\r\ncheck_commands = 1 <<\r\nap->link.active_tag;\r\nelse\r\ncheck_commands = ap->link.sactive;\r\n}\r\nwhile ((pos = ffs(check_commands))) {\r\npos--;\r\nrc = nv_adma_check_cpb(ap, pos,\r\nnotifier_error & (1 << pos));\r\nif (rc > 0)\r\ndone_mask |= 1 << pos;\r\nelse if (unlikely(rc < 0))\r\ncheck_commands = 0;\r\ncheck_commands &= ~(1 << pos);\r\n}\r\nata_qc_complete_multiple(ap, ap->qc_active ^ done_mask);\r\n}\r\n}\r\nif (notifier_clears[0] || notifier_clears[1]) {\r\nstruct nv_adma_port_priv *pp = host->ports[0]->private_data;\r\nwritel(notifier_clears[0], pp->notifier_clear_block);\r\npp = host->ports[1]->private_data;\r\nwritel(notifier_clears[1], pp->notifier_clear_block);\r\n}\r\nspin_unlock(&host->lock);\r\nreturn IRQ_RETVAL(handled);\r\n}\r\nstatic void nv_adma_freeze(struct ata_port *ap)\r\n{\r\nstruct nv_adma_port_priv *pp = ap->private_data;\r\nvoid __iomem *mmio = pp->ctl_block;\r\nu16 tmp;\r\nnv_ck804_freeze(ap);\r\nif (pp->flags & NV_ADMA_ATAPI_SETUP_COMPLETE)\r\nreturn;\r\nwriteb(NV_INT_ALL << (ap->port_no * NV_INT_PORT_SHIFT),\r\nap->host->iomap[NV_MMIO_BAR] + NV_INT_STATUS_CK804);\r\ntmp = readw(mmio + NV_ADMA_CTL);\r\nwritew(tmp & ~(NV_ADMA_CTL_AIEN | NV_ADMA_CTL_HOTPLUG_IEN),\r\nmmio + NV_ADMA_CTL);\r\nreadw(mmio + NV_ADMA_CTL);\r\n}\r\nstatic void nv_adma_thaw(struct ata_port *ap)\r\n{\r\nstruct nv_adma_port_priv *pp = ap->private_data;\r\nvoid __iomem *mmio = pp->ctl_block;\r\nu16 tmp;\r\nnv_ck804_thaw(ap);\r\nif (pp->flags & NV_ADMA_ATAPI_SETUP_COMPLETE)\r\nreturn;\r\ntmp = readw(mmio + NV_ADMA_CTL);\r\nwritew(tmp | (NV_ADMA_CTL_AIEN | NV_ADMA_CTL_HOTPLUG_IEN),\r\nmmio + NV_ADMA_CTL);\r\nreadw(mmio + NV_ADMA_CTL);\r\n}\r\nstatic void nv_adma_irq_clear(struct ata_port *ap)\r\n{\r\nstruct nv_adma_port_priv *pp = ap->private_data;\r\nvoid __iomem *mmio = pp->ctl_block;\r\nu32 notifier_clears[2];\r\nif (pp->flags & NV_ADMA_ATAPI_SETUP_COMPLETE) {\r\nata_bmdma_irq_clear(ap);\r\nreturn;\r\n}\r\nwriteb(NV_INT_ALL << (ap->port_no * NV_INT_PORT_SHIFT),\r\nap->host->iomap[NV_MMIO_BAR] + NV_INT_STATUS_CK804);\r\nwritew(0xffff, mmio + NV_ADMA_STAT);\r\nif (ap->port_no == 0) {\r\nnotifier_clears[0] = 0xFFFFFFFF;\r\nnotifier_clears[1] = 0;\r\n} else {\r\nnotifier_clears[0] = 0;\r\nnotifier_clears[1] = 0xFFFFFFFF;\r\n}\r\npp = ap->host->ports[0]->private_data;\r\nwritel(notifier_clears[0], pp->notifier_clear_block);\r\npp = ap->host->ports[1]->private_data;\r\nwritel(notifier_clears[1], pp->notifier_clear_block);\r\n}\r\nstatic void nv_adma_post_internal_cmd(struct ata_queued_cmd *qc)\r\n{\r\nstruct nv_adma_port_priv *pp = qc->ap->private_data;\r\nif (pp->flags & NV_ADMA_PORT_REGISTER_MODE)\r\nata_bmdma_post_internal_cmd(qc);\r\n}\r\nstatic int nv_adma_port_start(struct ata_port *ap)\r\n{\r\nstruct device *dev = ap->host->dev;\r\nstruct nv_adma_port_priv *pp;\r\nint rc;\r\nvoid *mem;\r\ndma_addr_t mem_dma;\r\nvoid __iomem *mmio;\r\nstruct pci_dev *pdev = to_pci_dev(dev);\r\nu16 tmp;\r\nVPRINTK("ENTER\n");\r\nrc = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (rc)\r\nreturn rc;\r\nrc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (rc)\r\nreturn rc;\r\nrc = ata_bmdma_port_start(ap);\r\nif (rc)\r\nreturn rc;\r\npp = devm_kzalloc(dev, sizeof(*pp), GFP_KERNEL);\r\nif (!pp)\r\nreturn -ENOMEM;\r\nmmio = ap->host->iomap[NV_MMIO_BAR] + NV_ADMA_PORT +\r\nap->port_no * NV_ADMA_PORT_SIZE;\r\npp->ctl_block = mmio;\r\npp->gen_block = ap->host->iomap[NV_MMIO_BAR] + NV_ADMA_GEN;\r\npp->notifier_clear_block = pp->gen_block +\r\nNV_ADMA_NOTIFIER_CLEAR + (4 * ap->port_no);\r\npci_set_dma_mask(pdev, DMA_BIT_MASK(64));\r\npci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));\r\npp->adma_dma_mask = *dev->dma_mask;\r\nmem = dmam_alloc_coherent(dev, NV_ADMA_PORT_PRIV_DMA_SZ,\r\n&mem_dma, GFP_KERNEL);\r\nif (!mem)\r\nreturn -ENOMEM;\r\nmemset(mem, 0, NV_ADMA_PORT_PRIV_DMA_SZ);\r\npp->cpb = mem;\r\npp->cpb_dma = mem_dma;\r\nwritel(mem_dma & 0xFFFFFFFF, mmio + NV_ADMA_CPB_BASE_LOW);\r\nwritel((mem_dma >> 16) >> 16, mmio + NV_ADMA_CPB_BASE_HIGH);\r\nmem += NV_ADMA_MAX_CPBS * NV_ADMA_CPB_SZ;\r\nmem_dma += NV_ADMA_MAX_CPBS * NV_ADMA_CPB_SZ;\r\npp->aprd = mem;\r\npp->aprd_dma = mem_dma;\r\nap->private_data = pp;\r\nwritew(0xffff, mmio + NV_ADMA_STAT);\r\npp->flags = NV_ADMA_PORT_REGISTER_MODE;\r\nwritew(0, mmio + NV_ADMA_CPB_COUNT);\r\ntmp = readw(mmio + NV_ADMA_CTL);\r\nwritew((tmp & ~NV_ADMA_CTL_GO) | NV_ADMA_CTL_AIEN |\r\nNV_ADMA_CTL_HOTPLUG_IEN, mmio + NV_ADMA_CTL);\r\ntmp = readw(mmio + NV_ADMA_CTL);\r\nwritew(tmp | NV_ADMA_CTL_CHANNEL_RESET, mmio + NV_ADMA_CTL);\r\nreadw(mmio + NV_ADMA_CTL);\r\nudelay(1);\r\nwritew(tmp & ~NV_ADMA_CTL_CHANNEL_RESET, mmio + NV_ADMA_CTL);\r\nreadw(mmio + NV_ADMA_CTL);\r\nreturn 0;\r\n}\r\nstatic void nv_adma_port_stop(struct ata_port *ap)\r\n{\r\nstruct nv_adma_port_priv *pp = ap->private_data;\r\nvoid __iomem *mmio = pp->ctl_block;\r\nVPRINTK("ENTER\n");\r\nwritew(0, mmio + NV_ADMA_CTL);\r\n}\r\nstatic int nv_adma_port_suspend(struct ata_port *ap, pm_message_t mesg)\r\n{\r\nstruct nv_adma_port_priv *pp = ap->private_data;\r\nvoid __iomem *mmio = pp->ctl_block;\r\nnv_adma_register_mode(ap);\r\nwritew(0, mmio + NV_ADMA_CPB_COUNT);\r\nwritew(0, mmio + NV_ADMA_CTL);\r\nreturn 0;\r\n}\r\nstatic int nv_adma_port_resume(struct ata_port *ap)\r\n{\r\nstruct nv_adma_port_priv *pp = ap->private_data;\r\nvoid __iomem *mmio = pp->ctl_block;\r\nu16 tmp;\r\nwritel(pp->cpb_dma & 0xFFFFFFFF, mmio + NV_ADMA_CPB_BASE_LOW);\r\nwritel((pp->cpb_dma >> 16) >> 16, mmio + NV_ADMA_CPB_BASE_HIGH);\r\nwritew(0xffff, mmio + NV_ADMA_STAT);\r\npp->flags |= NV_ADMA_PORT_REGISTER_MODE;\r\nwritew(0, mmio + NV_ADMA_CPB_COUNT);\r\ntmp = readw(mmio + NV_ADMA_CTL);\r\nwritew((tmp & ~NV_ADMA_CTL_GO) | NV_ADMA_CTL_AIEN |\r\nNV_ADMA_CTL_HOTPLUG_IEN, mmio + NV_ADMA_CTL);\r\ntmp = readw(mmio + NV_ADMA_CTL);\r\nwritew(tmp | NV_ADMA_CTL_CHANNEL_RESET, mmio + NV_ADMA_CTL);\r\nreadw(mmio + NV_ADMA_CTL);\r\nudelay(1);\r\nwritew(tmp & ~NV_ADMA_CTL_CHANNEL_RESET, mmio + NV_ADMA_CTL);\r\nreadw(mmio + NV_ADMA_CTL);\r\nreturn 0;\r\n}\r\nstatic void nv_adma_setup_port(struct ata_port *ap)\r\n{\r\nvoid __iomem *mmio = ap->host->iomap[NV_MMIO_BAR];\r\nstruct ata_ioports *ioport = &ap->ioaddr;\r\nVPRINTK("ENTER\n");\r\nmmio += NV_ADMA_PORT + ap->port_no * NV_ADMA_PORT_SIZE;\r\nioport->cmd_addr = mmio;\r\nioport->data_addr = mmio + (ATA_REG_DATA * 4);\r\nioport->error_addr =\r\nioport->feature_addr = mmio + (ATA_REG_ERR * 4);\r\nioport->nsect_addr = mmio + (ATA_REG_NSECT * 4);\r\nioport->lbal_addr = mmio + (ATA_REG_LBAL * 4);\r\nioport->lbam_addr = mmio + (ATA_REG_LBAM * 4);\r\nioport->lbah_addr = mmio + (ATA_REG_LBAH * 4);\r\nioport->device_addr = mmio + (ATA_REG_DEVICE * 4);\r\nioport->status_addr =\r\nioport->command_addr = mmio + (ATA_REG_STATUS * 4);\r\nioport->altstatus_addr =\r\nioport->ctl_addr = mmio + 0x20;\r\n}\r\nstatic int nv_adma_host_init(struct ata_host *host)\r\n{\r\nstruct pci_dev *pdev = to_pci_dev(host->dev);\r\nunsigned int i;\r\nu32 tmp32;\r\nVPRINTK("ENTER\n");\r\npci_read_config_dword(pdev, NV_MCP_SATA_CFG_20, &tmp32);\r\ntmp32 |= NV_MCP_SATA_CFG_20_PORT0_EN |\r\nNV_MCP_SATA_CFG_20_PORT0_PWB_EN |\r\nNV_MCP_SATA_CFG_20_PORT1_EN |\r\nNV_MCP_SATA_CFG_20_PORT1_PWB_EN;\r\npci_write_config_dword(pdev, NV_MCP_SATA_CFG_20, tmp32);\r\nfor (i = 0; i < host->n_ports; i++)\r\nnv_adma_setup_port(host->ports[i]);\r\nreturn 0;\r\n}\r\nstatic void nv_adma_fill_aprd(struct ata_queued_cmd *qc,\r\nstruct scatterlist *sg,\r\nint idx,\r\nstruct nv_adma_prd *aprd)\r\n{\r\nu8 flags = 0;\r\nif (qc->tf.flags & ATA_TFLAG_WRITE)\r\nflags |= NV_APRD_WRITE;\r\nif (idx == qc->n_elem - 1)\r\nflags |= NV_APRD_END;\r\nelse if (idx != 4)\r\nflags |= NV_APRD_CONT;\r\naprd->addr = cpu_to_le64(((u64)sg_dma_address(sg)));\r\naprd->len = cpu_to_le32(((u32)sg_dma_len(sg)));\r\naprd->flags = flags;\r\naprd->packet_len = 0;\r\n}\r\nstatic void nv_adma_fill_sg(struct ata_queued_cmd *qc, struct nv_adma_cpb *cpb)\r\n{\r\nstruct nv_adma_port_priv *pp = qc->ap->private_data;\r\nstruct nv_adma_prd *aprd;\r\nstruct scatterlist *sg;\r\nunsigned int si;\r\nVPRINTK("ENTER\n");\r\nfor_each_sg(qc->sg, sg, qc->n_elem, si) {\r\naprd = (si < 5) ? &cpb->aprd[si] :\r\n&pp->aprd[NV_ADMA_SGTBL_LEN * qc->tag + (si-5)];\r\nnv_adma_fill_aprd(qc, sg, si, aprd);\r\n}\r\nif (si > 5)\r\ncpb->next_aprd = cpu_to_le64(((u64)(pp->aprd_dma + NV_ADMA_SGTBL_SZ * qc->tag)));\r\nelse\r\ncpb->next_aprd = cpu_to_le64(0);\r\n}\r\nstatic int nv_adma_use_reg_mode(struct ata_queued_cmd *qc)\r\n{\r\nstruct nv_adma_port_priv *pp = qc->ap->private_data;\r\nif ((pp->flags & NV_ADMA_ATAPI_SETUP_COMPLETE) ||\r\n(qc->tf.flags & ATA_TFLAG_POLLING))\r\nreturn 1;\r\nif ((qc->flags & ATA_QCFLAG_DMAMAP) ||\r\n(qc->tf.protocol == ATA_PROT_NODATA))\r\nreturn 0;\r\nreturn 1;\r\n}\r\nstatic void nv_adma_qc_prep(struct ata_queued_cmd *qc)\r\n{\r\nstruct nv_adma_port_priv *pp = qc->ap->private_data;\r\nstruct nv_adma_cpb *cpb = &pp->cpb[qc->tag];\r\nu8 ctl_flags = NV_CPB_CTL_CPB_VALID |\r\nNV_CPB_CTL_IEN;\r\nif (nv_adma_use_reg_mode(qc)) {\r\nBUG_ON(!(pp->flags & NV_ADMA_ATAPI_SETUP_COMPLETE) &&\r\n(qc->flags & ATA_QCFLAG_DMAMAP));\r\nnv_adma_register_mode(qc->ap);\r\nata_bmdma_qc_prep(qc);\r\nreturn;\r\n}\r\ncpb->resp_flags = NV_CPB_RESP_DONE;\r\nwmb();\r\ncpb->ctl_flags = 0;\r\nwmb();\r\ncpb->len = 3;\r\ncpb->tag = qc->tag;\r\ncpb->next_cpb_idx = 0;\r\nif (qc->tf.protocol == ATA_PROT_NCQ)\r\nctl_flags |= NV_CPB_CTL_QUEUE | NV_CPB_CTL_FPDMA;\r\nVPRINTK("qc->flags = 0x%lx\n", qc->flags);\r\nnv_adma_tf_to_cpb(&qc->tf, cpb->tf);\r\nif (qc->flags & ATA_QCFLAG_DMAMAP) {\r\nnv_adma_fill_sg(qc, cpb);\r\nctl_flags |= NV_CPB_CTL_APRD_VALID;\r\n} else\r\nmemset(&cpb->aprd[0], 0, sizeof(struct nv_adma_prd) * 5);\r\nwmb();\r\ncpb->ctl_flags = ctl_flags;\r\nwmb();\r\ncpb->resp_flags = 0;\r\n}\r\nstatic unsigned int nv_adma_qc_issue(struct ata_queued_cmd *qc)\r\n{\r\nstruct nv_adma_port_priv *pp = qc->ap->private_data;\r\nvoid __iomem *mmio = pp->ctl_block;\r\nint curr_ncq = (qc->tf.protocol == ATA_PROT_NCQ);\r\nVPRINTK("ENTER\n");\r\nif (unlikely(qc->tf.protocol == ATA_PROT_NCQ &&\r\n(qc->flags & ATA_QCFLAG_RESULT_TF))) {\r\nata_dev_err(qc->dev, "NCQ w/ RESULT_TF not allowed\n");\r\nreturn AC_ERR_SYSTEM;\r\n}\r\nif (nv_adma_use_reg_mode(qc)) {\r\nVPRINTK("using ATA register mode: 0x%lx\n", qc->flags);\r\nBUG_ON(!(pp->flags & NV_ADMA_ATAPI_SETUP_COMPLETE) &&\r\n(qc->flags & ATA_QCFLAG_DMAMAP));\r\nnv_adma_register_mode(qc->ap);\r\nreturn ata_bmdma_qc_issue(qc);\r\n} else\r\nnv_adma_mode(qc->ap);\r\nwmb();\r\nif (curr_ncq != pp->last_issue_ncq) {\r\nudelay(20);\r\npp->last_issue_ncq = curr_ncq;\r\n}\r\nwritew(qc->tag, mmio + NV_ADMA_APPEND);\r\nDPRINTK("Issued tag %u\n", qc->tag);\r\nreturn 0;\r\n}\r\nstatic irqreturn_t nv_generic_interrupt(int irq, void *dev_instance)\r\n{\r\nstruct ata_host *host = dev_instance;\r\nunsigned int i;\r\nunsigned int handled = 0;\r\nunsigned long flags;\r\nspin_lock_irqsave(&host->lock, flags);\r\nfor (i = 0; i < host->n_ports; i++) {\r\nstruct ata_port *ap = host->ports[i];\r\nstruct ata_queued_cmd *qc;\r\nqc = ata_qc_from_tag(ap, ap->link.active_tag);\r\nif (qc && (!(qc->tf.flags & ATA_TFLAG_POLLING))) {\r\nhandled += ata_bmdma_port_intr(ap, qc);\r\n} else {\r\nap->ops->sff_check_status(ap);\r\n}\r\n}\r\nspin_unlock_irqrestore(&host->lock, flags);\r\nreturn IRQ_RETVAL(handled);\r\n}\r\nstatic irqreturn_t nv_do_interrupt(struct ata_host *host, u8 irq_stat)\r\n{\r\nint i, handled = 0;\r\nfor (i = 0; i < host->n_ports; i++) {\r\nhandled += nv_host_intr(host->ports[i], irq_stat);\r\nirq_stat >>= NV_INT_PORT_SHIFT;\r\n}\r\nreturn IRQ_RETVAL(handled);\r\n}\r\nstatic irqreturn_t nv_nf2_interrupt(int irq, void *dev_instance)\r\n{\r\nstruct ata_host *host = dev_instance;\r\nu8 irq_stat;\r\nirqreturn_t ret;\r\nspin_lock(&host->lock);\r\nirq_stat = ioread8(host->ports[0]->ioaddr.scr_addr + NV_INT_STATUS);\r\nret = nv_do_interrupt(host, irq_stat);\r\nspin_unlock(&host->lock);\r\nreturn ret;\r\n}\r\nstatic irqreturn_t nv_ck804_interrupt(int irq, void *dev_instance)\r\n{\r\nstruct ata_host *host = dev_instance;\r\nu8 irq_stat;\r\nirqreturn_t ret;\r\nspin_lock(&host->lock);\r\nirq_stat = readb(host->iomap[NV_MMIO_BAR] + NV_INT_STATUS_CK804);\r\nret = nv_do_interrupt(host, irq_stat);\r\nspin_unlock(&host->lock);\r\nreturn ret;\r\n}\r\nstatic int nv_scr_read(struct ata_link *link, unsigned int sc_reg, u32 *val)\r\n{\r\nif (sc_reg > SCR_CONTROL)\r\nreturn -EINVAL;\r\n*val = ioread32(link->ap->ioaddr.scr_addr + (sc_reg * 4));\r\nreturn 0;\r\n}\r\nstatic int nv_scr_write(struct ata_link *link, unsigned int sc_reg, u32 val)\r\n{\r\nif (sc_reg > SCR_CONTROL)\r\nreturn -EINVAL;\r\niowrite32(val, link->ap->ioaddr.scr_addr + (sc_reg * 4));\r\nreturn 0;\r\n}\r\nstatic int nv_hardreset(struct ata_link *link, unsigned int *class,\r\nunsigned long deadline)\r\n{\r\nstruct ata_eh_context *ehc = &link->eh_context;\r\nif (!(link->ap->pflags & ATA_PFLAG_LOADING) &&\r\n!ata_dev_enabled(link->device))\r\nsata_link_hardreset(link, sata_deb_timing_hotplug, deadline,\r\nNULL, NULL);\r\nelse {\r\nconst unsigned long *timing = sata_ehc_deb_timing(ehc);\r\nint rc;\r\nif (!(ehc->i.flags & ATA_EHI_QUIET))\r\nata_link_info(link,\r\n"nv: skipping hardreset on occupied port\n");\r\nrc = sata_link_resume(link, timing, deadline);\r\nif (rc && rc != -EOPNOTSUPP)\r\nata_link_warn(link, "failed to resume link (errno=%d)\n",\r\nrc);\r\n}\r\nreturn -EAGAIN;\r\n}\r\nstatic void nv_nf2_freeze(struct ata_port *ap)\r\n{\r\nvoid __iomem *scr_addr = ap->host->ports[0]->ioaddr.scr_addr;\r\nint shift = ap->port_no * NV_INT_PORT_SHIFT;\r\nu8 mask;\r\nmask = ioread8(scr_addr + NV_INT_ENABLE);\r\nmask &= ~(NV_INT_ALL << shift);\r\niowrite8(mask, scr_addr + NV_INT_ENABLE);\r\n}\r\nstatic void nv_nf2_thaw(struct ata_port *ap)\r\n{\r\nvoid __iomem *scr_addr = ap->host->ports[0]->ioaddr.scr_addr;\r\nint shift = ap->port_no * NV_INT_PORT_SHIFT;\r\nu8 mask;\r\niowrite8(NV_INT_ALL << shift, scr_addr + NV_INT_STATUS);\r\nmask = ioread8(scr_addr + NV_INT_ENABLE);\r\nmask |= (NV_INT_MASK << shift);\r\niowrite8(mask, scr_addr + NV_INT_ENABLE);\r\n}\r\nstatic void nv_ck804_freeze(struct ata_port *ap)\r\n{\r\nvoid __iomem *mmio_base = ap->host->iomap[NV_MMIO_BAR];\r\nint shift = ap->port_no * NV_INT_PORT_SHIFT;\r\nu8 mask;\r\nmask = readb(mmio_base + NV_INT_ENABLE_CK804);\r\nmask &= ~(NV_INT_ALL << shift);\r\nwriteb(mask, mmio_base + NV_INT_ENABLE_CK804);\r\n}\r\nstatic void nv_ck804_thaw(struct ata_port *ap)\r\n{\r\nvoid __iomem *mmio_base = ap->host->iomap[NV_MMIO_BAR];\r\nint shift = ap->port_no * NV_INT_PORT_SHIFT;\r\nu8 mask;\r\nwriteb(NV_INT_ALL << shift, mmio_base + NV_INT_STATUS_CK804);\r\nmask = readb(mmio_base + NV_INT_ENABLE_CK804);\r\nmask |= (NV_INT_MASK << shift);\r\nwriteb(mask, mmio_base + NV_INT_ENABLE_CK804);\r\n}\r\nstatic void nv_mcp55_freeze(struct ata_port *ap)\r\n{\r\nvoid __iomem *mmio_base = ap->host->iomap[NV_MMIO_BAR];\r\nint shift = ap->port_no * NV_INT_PORT_SHIFT_MCP55;\r\nu32 mask;\r\nwritel(NV_INT_ALL_MCP55 << shift, mmio_base + NV_INT_STATUS_MCP55);\r\nmask = readl(mmio_base + NV_INT_ENABLE_MCP55);\r\nmask &= ~(NV_INT_ALL_MCP55 << shift);\r\nwritel(mask, mmio_base + NV_INT_ENABLE_MCP55);\r\n}\r\nstatic void nv_mcp55_thaw(struct ata_port *ap)\r\n{\r\nvoid __iomem *mmio_base = ap->host->iomap[NV_MMIO_BAR];\r\nint shift = ap->port_no * NV_INT_PORT_SHIFT_MCP55;\r\nu32 mask;\r\nwritel(NV_INT_ALL_MCP55 << shift, mmio_base + NV_INT_STATUS_MCP55);\r\nmask = readl(mmio_base + NV_INT_ENABLE_MCP55);\r\nmask |= (NV_INT_MASK_MCP55 << shift);\r\nwritel(mask, mmio_base + NV_INT_ENABLE_MCP55);\r\n}\r\nstatic void nv_adma_error_handler(struct ata_port *ap)\r\n{\r\nstruct nv_adma_port_priv *pp = ap->private_data;\r\nif (!(pp->flags & NV_ADMA_PORT_REGISTER_MODE)) {\r\nvoid __iomem *mmio = pp->ctl_block;\r\nint i;\r\nu16 tmp;\r\nif (ata_tag_valid(ap->link.active_tag) || ap->link.sactive) {\r\nu32 notifier = readl(mmio + NV_ADMA_NOTIFIER);\r\nu32 notifier_error = readl(mmio + NV_ADMA_NOTIFIER_ERROR);\r\nu32 gen_ctl = readl(pp->gen_block + NV_ADMA_GEN_CTL);\r\nu32 status = readw(mmio + NV_ADMA_STAT);\r\nu8 cpb_count = readb(mmio + NV_ADMA_CPB_COUNT);\r\nu8 next_cpb_idx = readb(mmio + NV_ADMA_NEXT_CPB_IDX);\r\nata_port_err(ap,\r\n"EH in ADMA mode, notifier 0x%X "\r\n"notifier_error 0x%X gen_ctl 0x%X status 0x%X "\r\n"next cpb count 0x%X next cpb idx 0x%x\n",\r\nnotifier, notifier_error, gen_ctl, status,\r\ncpb_count, next_cpb_idx);\r\nfor (i = 0; i < NV_ADMA_MAX_CPBS; i++) {\r\nstruct nv_adma_cpb *cpb = &pp->cpb[i];\r\nif ((ata_tag_valid(ap->link.active_tag) && i == ap->link.active_tag) ||\r\nap->link.sactive & (1 << i))\r\nata_port_err(ap,\r\n"CPB %d: ctl_flags 0x%x, resp_flags 0x%x\n",\r\ni, cpb->ctl_flags, cpb->resp_flags);\r\n}\r\n}\r\nnv_adma_register_mode(ap);\r\nfor (i = 0; i < NV_ADMA_MAX_CPBS; i++)\r\npp->cpb[i].ctl_flags &= ~NV_CPB_CTL_CPB_VALID;\r\nwritew(0, mmio + NV_ADMA_CPB_COUNT);\r\ntmp = readw(mmio + NV_ADMA_CTL);\r\nwritew(tmp | NV_ADMA_CTL_CHANNEL_RESET, mmio + NV_ADMA_CTL);\r\nreadw(mmio + NV_ADMA_CTL);\r\nudelay(1);\r\nwritew(tmp & ~NV_ADMA_CTL_CHANNEL_RESET, mmio + NV_ADMA_CTL);\r\nreadw(mmio + NV_ADMA_CTL);\r\n}\r\nata_bmdma_error_handler(ap);\r\n}\r\nstatic void nv_swncq_qc_to_dq(struct ata_port *ap, struct ata_queued_cmd *qc)\r\n{\r\nstruct nv_swncq_port_priv *pp = ap->private_data;\r\nstruct defer_queue *dq = &pp->defer_queue;\r\nWARN_ON(dq->tail - dq->head == ATA_MAX_QUEUE);\r\ndq->defer_bits |= (1 << qc->tag);\r\ndq->tag[dq->tail++ & (ATA_MAX_QUEUE - 1)] = qc->tag;\r\n}\r\nstatic struct ata_queued_cmd *nv_swncq_qc_from_dq(struct ata_port *ap)\r\n{\r\nstruct nv_swncq_port_priv *pp = ap->private_data;\r\nstruct defer_queue *dq = &pp->defer_queue;\r\nunsigned int tag;\r\nif (dq->head == dq->tail)\r\nreturn NULL;\r\ntag = dq->tag[dq->head & (ATA_MAX_QUEUE - 1)];\r\ndq->tag[dq->head++ & (ATA_MAX_QUEUE - 1)] = ATA_TAG_POISON;\r\nWARN_ON(!(dq->defer_bits & (1 << tag)));\r\ndq->defer_bits &= ~(1 << tag);\r\nreturn ata_qc_from_tag(ap, tag);\r\n}\r\nstatic void nv_swncq_fis_reinit(struct ata_port *ap)\r\n{\r\nstruct nv_swncq_port_priv *pp = ap->private_data;\r\npp->dhfis_bits = 0;\r\npp->dmafis_bits = 0;\r\npp->sdbfis_bits = 0;\r\npp->ncq_flags = 0;\r\n}\r\nstatic void nv_swncq_pp_reinit(struct ata_port *ap)\r\n{\r\nstruct nv_swncq_port_priv *pp = ap->private_data;\r\nstruct defer_queue *dq = &pp->defer_queue;\r\ndq->head = 0;\r\ndq->tail = 0;\r\ndq->defer_bits = 0;\r\npp->qc_active = 0;\r\npp->last_issue_tag = ATA_TAG_POISON;\r\nnv_swncq_fis_reinit(ap);\r\n}\r\nstatic void nv_swncq_irq_clear(struct ata_port *ap, u16 fis)\r\n{\r\nstruct nv_swncq_port_priv *pp = ap->private_data;\r\nwritew(fis, pp->irq_block);\r\n}\r\nstatic void __ata_bmdma_stop(struct ata_port *ap)\r\n{\r\nstruct ata_queued_cmd qc;\r\nqc.ap = ap;\r\nata_bmdma_stop(&qc);\r\n}\r\nstatic void nv_swncq_ncq_stop(struct ata_port *ap)\r\n{\r\nstruct nv_swncq_port_priv *pp = ap->private_data;\r\nunsigned int i;\r\nu32 sactive;\r\nu32 done_mask;\r\nata_port_err(ap, "EH in SWNCQ mode,QC:qc_active 0x%X sactive 0x%X\n",\r\nap->qc_active, ap->link.sactive);\r\nata_port_err(ap,\r\n"SWNCQ:qc_active 0x%X defer_bits 0x%X last_issue_tag 0x%x\n "\r\n"dhfis 0x%X dmafis 0x%X sdbfis 0x%X\n",\r\npp->qc_active, pp->defer_queue.defer_bits, pp->last_issue_tag,\r\npp->dhfis_bits, pp->dmafis_bits, pp->sdbfis_bits);\r\nata_port_err(ap, "ATA_REG 0x%X ERR_REG 0x%X\n",\r\nap->ops->sff_check_status(ap),\r\nioread8(ap->ioaddr.error_addr));\r\nsactive = readl(pp->sactive_block);\r\ndone_mask = pp->qc_active ^ sactive;\r\nata_port_err(ap, "tag : dhfis dmafis sdbfis sactive\n");\r\nfor (i = 0; i < ATA_MAX_QUEUE; i++) {\r\nu8 err = 0;\r\nif (pp->qc_active & (1 << i))\r\nerr = 0;\r\nelse if (done_mask & (1 << i))\r\nerr = 1;\r\nelse\r\ncontinue;\r\nata_port_err(ap,\r\n"tag 0x%x: %01x %01x %01x %01x %s\n", i,\r\n(pp->dhfis_bits >> i) & 0x1,\r\n(pp->dmafis_bits >> i) & 0x1,\r\n(pp->sdbfis_bits >> i) & 0x1,\r\n(sactive >> i) & 0x1,\r\n(err ? "error! tag doesn't exit" : " "));\r\n}\r\nnv_swncq_pp_reinit(ap);\r\nap->ops->sff_irq_clear(ap);\r\n__ata_bmdma_stop(ap);\r\nnv_swncq_irq_clear(ap, 0xffff);\r\n}\r\nstatic void nv_swncq_error_handler(struct ata_port *ap)\r\n{\r\nstruct ata_eh_context *ehc = &ap->link.eh_context;\r\nif (ap->link.sactive) {\r\nnv_swncq_ncq_stop(ap);\r\nehc->i.action |= ATA_EH_RESET;\r\n}\r\nata_bmdma_error_handler(ap);\r\n}\r\nstatic int nv_swncq_port_suspend(struct ata_port *ap, pm_message_t mesg)\r\n{\r\nvoid __iomem *mmio = ap->host->iomap[NV_MMIO_BAR];\r\nu32 tmp;\r\nwritel(~0, mmio + NV_INT_STATUS_MCP55);\r\nwritel(0, mmio + NV_INT_ENABLE_MCP55);\r\ntmp = readl(mmio + NV_CTL_MCP55);\r\ntmp &= ~(NV_CTL_PRI_SWNCQ | NV_CTL_SEC_SWNCQ);\r\nwritel(tmp, mmio + NV_CTL_MCP55);\r\nreturn 0;\r\n}\r\nstatic int nv_swncq_port_resume(struct ata_port *ap)\r\n{\r\nvoid __iomem *mmio = ap->host->iomap[NV_MMIO_BAR];\r\nu32 tmp;\r\nwritel(~0, mmio + NV_INT_STATUS_MCP55);\r\nwritel(0x00fd00fd, mmio + NV_INT_ENABLE_MCP55);\r\ntmp = readl(mmio + NV_CTL_MCP55);\r\nwritel(tmp | NV_CTL_PRI_SWNCQ | NV_CTL_SEC_SWNCQ, mmio + NV_CTL_MCP55);\r\nreturn 0;\r\n}\r\nstatic void nv_swncq_host_init(struct ata_host *host)\r\n{\r\nu32 tmp;\r\nvoid __iomem *mmio = host->iomap[NV_MMIO_BAR];\r\nstruct pci_dev *pdev = to_pci_dev(host->dev);\r\nu8 regval;\r\npci_read_config_byte(pdev, 0x7f, &regval);\r\nregval &= ~(1 << 7);\r\npci_write_config_byte(pdev, 0x7f, regval);\r\ntmp = readl(mmio + NV_CTL_MCP55);\r\nVPRINTK("HOST_CTL:0x%X\n", tmp);\r\nwritel(tmp | NV_CTL_PRI_SWNCQ | NV_CTL_SEC_SWNCQ, mmio + NV_CTL_MCP55);\r\ntmp = readl(mmio + NV_INT_ENABLE_MCP55);\r\nVPRINTK("HOST_ENABLE:0x%X\n", tmp);\r\nwritel(tmp | 0x00fd00fd, mmio + NV_INT_ENABLE_MCP55);\r\nwritel(~0x0, mmio + NV_INT_STATUS_MCP55);\r\n}\r\nstatic int nv_swncq_slave_config(struct scsi_device *sdev)\r\n{\r\nstruct ata_port *ap = ata_shost_to_port(sdev->host);\r\nstruct pci_dev *pdev = to_pci_dev(ap->host->dev);\r\nstruct ata_device *dev;\r\nint rc;\r\nu8 rev;\r\nu8 check_maxtor = 0;\r\nunsigned char model_num[ATA_ID_PROD_LEN + 1];\r\nrc = ata_scsi_slave_config(sdev);\r\nif (sdev->id >= ATA_MAX_DEVICES || sdev->channel || sdev->lun)\r\nreturn rc;\r\ndev = &ap->link.device[sdev->id];\r\nif (!(ap->flags & ATA_FLAG_NCQ) || dev->class == ATA_DEV_ATAPI)\r\nreturn rc;\r\nif (pdev->device == PCI_DEVICE_ID_NVIDIA_NFORCE_MCP51_SATA ||\r\npdev->device == PCI_DEVICE_ID_NVIDIA_NFORCE_MCP51_SATA2)\r\ncheck_maxtor = 1;\r\nif (pdev->device == PCI_DEVICE_ID_NVIDIA_NFORCE_MCP55_SATA ||\r\npdev->device == PCI_DEVICE_ID_NVIDIA_NFORCE_MCP55_SATA2) {\r\npci_read_config_byte(pdev, 0x8, &rev);\r\nif (rev <= 0xa2)\r\ncheck_maxtor = 1;\r\n}\r\nif (!check_maxtor)\r\nreturn rc;\r\nata_id_c_string(dev->id, model_num, ATA_ID_PROD, sizeof(model_num));\r\nif (strncmp(model_num, "Maxtor", 6) == 0) {\r\nata_scsi_change_queue_depth(sdev, 1, SCSI_QDEPTH_DEFAULT);\r\nata_dev_notice(dev, "Disabling SWNCQ mode (depth %x)\n",\r\nsdev->queue_depth);\r\n}\r\nreturn rc;\r\n}\r\nstatic int nv_swncq_port_start(struct ata_port *ap)\r\n{\r\nstruct device *dev = ap->host->dev;\r\nvoid __iomem *mmio = ap->host->iomap[NV_MMIO_BAR];\r\nstruct nv_swncq_port_priv *pp;\r\nint rc;\r\nrc = ata_bmdma_port_start(ap);\r\nif (rc)\r\nreturn rc;\r\npp = devm_kzalloc(dev, sizeof(*pp), GFP_KERNEL);\r\nif (!pp)\r\nreturn -ENOMEM;\r\npp->prd = dmam_alloc_coherent(dev, ATA_PRD_TBL_SZ * ATA_MAX_QUEUE,\r\n&pp->prd_dma, GFP_KERNEL);\r\nif (!pp->prd)\r\nreturn -ENOMEM;\r\nmemset(pp->prd, 0, ATA_PRD_TBL_SZ * ATA_MAX_QUEUE);\r\nap->private_data = pp;\r\npp->sactive_block = ap->ioaddr.scr_addr + 4 * SCR_ACTIVE;\r\npp->irq_block = mmio + NV_INT_STATUS_MCP55 + ap->port_no * 2;\r\npp->tag_block = mmio + NV_NCQ_REG_MCP55 + ap->port_no * 2;\r\nreturn 0;\r\n}\r\nstatic void nv_swncq_qc_prep(struct ata_queued_cmd *qc)\r\n{\r\nif (qc->tf.protocol != ATA_PROT_NCQ) {\r\nata_bmdma_qc_prep(qc);\r\nreturn;\r\n}\r\nif (!(qc->flags & ATA_QCFLAG_DMAMAP))\r\nreturn;\r\nnv_swncq_fill_sg(qc);\r\n}\r\nstatic void nv_swncq_fill_sg(struct ata_queued_cmd *qc)\r\n{\r\nstruct ata_port *ap = qc->ap;\r\nstruct scatterlist *sg;\r\nstruct nv_swncq_port_priv *pp = ap->private_data;\r\nstruct ata_bmdma_prd *prd;\r\nunsigned int si, idx;\r\nprd = pp->prd + ATA_MAX_PRD * qc->tag;\r\nidx = 0;\r\nfor_each_sg(qc->sg, sg, qc->n_elem, si) {\r\nu32 addr, offset;\r\nu32 sg_len, len;\r\naddr = (u32)sg_dma_address(sg);\r\nsg_len = sg_dma_len(sg);\r\nwhile (sg_len) {\r\noffset = addr & 0xffff;\r\nlen = sg_len;\r\nif ((offset + sg_len) > 0x10000)\r\nlen = 0x10000 - offset;\r\nprd[idx].addr = cpu_to_le32(addr);\r\nprd[idx].flags_len = cpu_to_le32(len & 0xffff);\r\nidx++;\r\nsg_len -= len;\r\naddr += len;\r\n}\r\n}\r\nprd[idx - 1].flags_len |= cpu_to_le32(ATA_PRD_EOT);\r\n}\r\nstatic unsigned int nv_swncq_issue_atacmd(struct ata_port *ap,\r\nstruct ata_queued_cmd *qc)\r\n{\r\nstruct nv_swncq_port_priv *pp = ap->private_data;\r\nif (qc == NULL)\r\nreturn 0;\r\nDPRINTK("Enter\n");\r\nwritel((1 << qc->tag), pp->sactive_block);\r\npp->last_issue_tag = qc->tag;\r\npp->dhfis_bits &= ~(1 << qc->tag);\r\npp->dmafis_bits &= ~(1 << qc->tag);\r\npp->qc_active |= (0x1 << qc->tag);\r\nap->ops->sff_tf_load(ap, &qc->tf);\r\nap->ops->sff_exec_command(ap, &qc->tf);\r\nDPRINTK("Issued tag %u\n", qc->tag);\r\nreturn 0;\r\n}\r\nstatic unsigned int nv_swncq_qc_issue(struct ata_queued_cmd *qc)\r\n{\r\nstruct ata_port *ap = qc->ap;\r\nstruct nv_swncq_port_priv *pp = ap->private_data;\r\nif (qc->tf.protocol != ATA_PROT_NCQ)\r\nreturn ata_bmdma_qc_issue(qc);\r\nDPRINTK("Enter\n");\r\nif (!pp->qc_active)\r\nnv_swncq_issue_atacmd(ap, qc);\r\nelse\r\nnv_swncq_qc_to_dq(ap, qc);\r\nreturn 0;\r\n}\r\nstatic void nv_swncq_hotplug(struct ata_port *ap, u32 fis)\r\n{\r\nu32 serror;\r\nstruct ata_eh_info *ehi = &ap->link.eh_info;\r\nata_ehi_clear_desc(ehi);\r\nsata_scr_read(&ap->link, SCR_ERROR, &serror);\r\nsata_scr_write(&ap->link, SCR_ERROR, serror);\r\nif (fis & NV_SWNCQ_IRQ_ADDED)\r\nata_ehi_push_desc(ehi, "hot plug");\r\nelse if (fis & NV_SWNCQ_IRQ_REMOVED)\r\nata_ehi_push_desc(ehi, "hot unplug");\r\nata_ehi_hotplugged(ehi);\r\nehi->serror |= serror;\r\nata_port_freeze(ap);\r\n}\r\nstatic int nv_swncq_sdbfis(struct ata_port *ap)\r\n{\r\nstruct ata_queued_cmd *qc;\r\nstruct nv_swncq_port_priv *pp = ap->private_data;\r\nstruct ata_eh_info *ehi = &ap->link.eh_info;\r\nu32 sactive;\r\nu32 done_mask;\r\nu8 host_stat;\r\nu8 lack_dhfis = 0;\r\nhost_stat = ap->ops->bmdma_status(ap);\r\nif (unlikely(host_stat & ATA_DMA_ERR)) {\r\nata_ehi_clear_desc(ehi);\r\nata_ehi_push_desc(ehi, "BMDMA stat 0x%x", host_stat);\r\nehi->err_mask |= AC_ERR_HOST_BUS;\r\nehi->action |= ATA_EH_RESET;\r\nreturn -EINVAL;\r\n}\r\nap->ops->sff_irq_clear(ap);\r\n__ata_bmdma_stop(ap);\r\nsactive = readl(pp->sactive_block);\r\ndone_mask = pp->qc_active ^ sactive;\r\npp->qc_active &= ~done_mask;\r\npp->dhfis_bits &= ~done_mask;\r\npp->dmafis_bits &= ~done_mask;\r\npp->sdbfis_bits |= done_mask;\r\nata_qc_complete_multiple(ap, ap->qc_active ^ done_mask);\r\nif (!ap->qc_active) {\r\nDPRINTK("over\n");\r\nnv_swncq_pp_reinit(ap);\r\nreturn 0;\r\n}\r\nif (pp->qc_active & pp->dhfis_bits)\r\nreturn 0;\r\nif ((pp->ncq_flags & ncq_saw_backout) ||\r\n(pp->qc_active ^ pp->dhfis_bits))\r\nlack_dhfis = 1;\r\nDPRINTK("id 0x%x QC: qc_active 0x%x,"\r\n"SWNCQ:qc_active 0x%X defer_bits %X "\r\n"dhfis 0x%X dmafis 0x%X last_issue_tag %x\n",\r\nap->print_id, ap->qc_active, pp->qc_active,\r\npp->defer_queue.defer_bits, pp->dhfis_bits,\r\npp->dmafis_bits, pp->last_issue_tag);\r\nnv_swncq_fis_reinit(ap);\r\nif (lack_dhfis) {\r\nqc = ata_qc_from_tag(ap, pp->last_issue_tag);\r\nnv_swncq_issue_atacmd(ap, qc);\r\nreturn 0;\r\n}\r\nif (pp->defer_queue.defer_bits) {\r\nqc = nv_swncq_qc_from_dq(ap);\r\nWARN_ON(qc == NULL);\r\nnv_swncq_issue_atacmd(ap, qc);\r\n}\r\nreturn 0;\r\n}\r\nstatic inline u32 nv_swncq_tag(struct ata_port *ap)\r\n{\r\nstruct nv_swncq_port_priv *pp = ap->private_data;\r\nu32 tag;\r\ntag = readb(pp->tag_block) >> 2;\r\nreturn (tag & 0x1f);\r\n}\r\nstatic void nv_swncq_dmafis(struct ata_port *ap)\r\n{\r\nstruct ata_queued_cmd *qc;\r\nunsigned int rw;\r\nu8 dmactl;\r\nu32 tag;\r\nstruct nv_swncq_port_priv *pp = ap->private_data;\r\n__ata_bmdma_stop(ap);\r\ntag = nv_swncq_tag(ap);\r\nDPRINTK("dma setup tag 0x%x\n", tag);\r\nqc = ata_qc_from_tag(ap, tag);\r\nif (unlikely(!qc))\r\nreturn;\r\nrw = qc->tf.flags & ATA_TFLAG_WRITE;\r\niowrite32(pp->prd_dma + ATA_PRD_TBL_SZ * qc->tag,\r\nap->ioaddr.bmdma_addr + ATA_DMA_TABLE_OFS);\r\ndmactl = ioread8(ap->ioaddr.bmdma_addr + ATA_DMA_CMD);\r\ndmactl &= ~ATA_DMA_WR;\r\nif (!rw)\r\ndmactl |= ATA_DMA_WR;\r\niowrite8(dmactl | ATA_DMA_START, ap->ioaddr.bmdma_addr + ATA_DMA_CMD);\r\n}\r\nstatic void nv_swncq_host_interrupt(struct ata_port *ap, u16 fis)\r\n{\r\nstruct nv_swncq_port_priv *pp = ap->private_data;\r\nstruct ata_queued_cmd *qc;\r\nstruct ata_eh_info *ehi = &ap->link.eh_info;\r\nu32 serror;\r\nu8 ata_stat;\r\nata_stat = ap->ops->sff_check_status(ap);\r\nnv_swncq_irq_clear(ap, fis);\r\nif (!fis)\r\nreturn;\r\nif (ap->pflags & ATA_PFLAG_FROZEN)\r\nreturn;\r\nif (fis & NV_SWNCQ_IRQ_HOTPLUG) {\r\nnv_swncq_hotplug(ap, fis);\r\nreturn;\r\n}\r\nif (!pp->qc_active)\r\nreturn;\r\nif (ap->ops->scr_read(&ap->link, SCR_ERROR, &serror))\r\nreturn;\r\nap->ops->scr_write(&ap->link, SCR_ERROR, serror);\r\nif (ata_stat & ATA_ERR) {\r\nata_ehi_clear_desc(ehi);\r\nata_ehi_push_desc(ehi, "Ata error. fis:0x%X", fis);\r\nehi->err_mask |= AC_ERR_DEV;\r\nehi->serror |= serror;\r\nehi->action |= ATA_EH_RESET;\r\nata_port_freeze(ap);\r\nreturn;\r\n}\r\nif (fis & NV_SWNCQ_IRQ_BACKOUT) {\r\npp->ncq_flags |= ncq_saw_backout;\r\n}\r\nif (fis & NV_SWNCQ_IRQ_SDBFIS) {\r\npp->ncq_flags |= ncq_saw_sdb;\r\nDPRINTK("id 0x%x SWNCQ: qc_active 0x%X "\r\n"dhfis 0x%X dmafis 0x%X sactive 0x%X\n",\r\nap->print_id, pp->qc_active, pp->dhfis_bits,\r\npp->dmafis_bits, readl(pp->sactive_block));\r\nif (nv_swncq_sdbfis(ap) < 0)\r\ngoto irq_error;\r\n}\r\nif (fis & NV_SWNCQ_IRQ_DHREGFIS) {\r\npp->dhfis_bits |= (0x1 << pp->last_issue_tag);\r\npp->ncq_flags |= ncq_saw_d2h;\r\nif (pp->ncq_flags & (ncq_saw_sdb | ncq_saw_backout)) {\r\nata_ehi_push_desc(ehi, "illegal fis transaction");\r\nehi->err_mask |= AC_ERR_HSM;\r\nehi->action |= ATA_EH_RESET;\r\ngoto irq_error;\r\n}\r\nif (!(fis & NV_SWNCQ_IRQ_DMASETUP) &&\r\n!(pp->ncq_flags & ncq_saw_dmas)) {\r\nata_stat = ap->ops->sff_check_status(ap);\r\nif (ata_stat & ATA_BUSY)\r\ngoto irq_exit;\r\nif (pp->defer_queue.defer_bits) {\r\nDPRINTK("send next command\n");\r\nqc = nv_swncq_qc_from_dq(ap);\r\nnv_swncq_issue_atacmd(ap, qc);\r\n}\r\n}\r\n}\r\nif (fis & NV_SWNCQ_IRQ_DMASETUP) {\r\npp->dmafis_bits |= (0x1 << nv_swncq_tag(ap));\r\npp->ncq_flags |= ncq_saw_dmas;\r\nnv_swncq_dmafis(ap);\r\n}\r\nirq_exit:\r\nreturn;\r\nirq_error:\r\nata_ehi_push_desc(ehi, "fis:0x%x", fis);\r\nata_port_freeze(ap);\r\nreturn;\r\n}\r\nstatic irqreturn_t nv_swncq_interrupt(int irq, void *dev_instance)\r\n{\r\nstruct ata_host *host = dev_instance;\r\nunsigned int i;\r\nunsigned int handled = 0;\r\nunsigned long flags;\r\nu32 irq_stat;\r\nspin_lock_irqsave(&host->lock, flags);\r\nirq_stat = readl(host->iomap[NV_MMIO_BAR] + NV_INT_STATUS_MCP55);\r\nfor (i = 0; i < host->n_ports; i++) {\r\nstruct ata_port *ap = host->ports[i];\r\nif (ap->link.sactive) {\r\nnv_swncq_host_interrupt(ap, (u16)irq_stat);\r\nhandled = 1;\r\n} else {\r\nif (irq_stat)\r\nnv_swncq_irq_clear(ap, 0xfff0);\r\nhandled += nv_host_intr(ap, (u8)irq_stat);\r\n}\r\nirq_stat >>= NV_INT_PORT_SHIFT_MCP55;\r\n}\r\nspin_unlock_irqrestore(&host->lock, flags);\r\nreturn IRQ_RETVAL(handled);\r\n}\r\nstatic int nv_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)\r\n{\r\nconst struct ata_port_info *ppi[] = { NULL, NULL };\r\nstruct nv_pi_priv *ipriv;\r\nstruct ata_host *host;\r\nstruct nv_host_priv *hpriv;\r\nint rc;\r\nu32 bar;\r\nvoid __iomem *base;\r\nunsigned long type = ent->driver_data;\r\nfor (bar = 0; bar < 6; bar++)\r\nif (pci_resource_start(pdev, bar) == 0)\r\nreturn -ENODEV;\r\nata_print_version_once(&pdev->dev, DRV_VERSION);\r\nrc = pcim_enable_device(pdev);\r\nif (rc)\r\nreturn rc;\r\nif (type == CK804 && adma_enabled) {\r\ndev_notice(&pdev->dev, "Using ADMA mode\n");\r\ntype = ADMA;\r\n} else if (type == MCP5x && swncq_enabled) {\r\ndev_notice(&pdev->dev, "Using SWNCQ mode\n");\r\ntype = SWNCQ;\r\n}\r\nppi[0] = &nv_port_info[type];\r\nipriv = ppi[0]->private_data;\r\nrc = ata_pci_bmdma_prepare_host(pdev, ppi, &host);\r\nif (rc)\r\nreturn rc;\r\nhpriv = devm_kzalloc(&pdev->dev, sizeof(*hpriv), GFP_KERNEL);\r\nif (!hpriv)\r\nreturn -ENOMEM;\r\nhpriv->type = type;\r\nhost->private_data = hpriv;\r\nrc = pcim_iomap_regions(pdev, 1 << NV_MMIO_BAR, DRV_NAME);\r\nif (rc)\r\nreturn rc;\r\nbase = host->iomap[NV_MMIO_BAR];\r\nhost->ports[0]->ioaddr.scr_addr = base + NV_PORT0_SCR_REG_OFFSET;\r\nhost->ports[1]->ioaddr.scr_addr = base + NV_PORT1_SCR_REG_OFFSET;\r\nif (type >= CK804) {\r\nu8 regval;\r\npci_read_config_byte(pdev, NV_MCP_SATA_CFG_20, &regval);\r\nregval |= NV_MCP_SATA_CFG_20_SATA_SPACE_EN;\r\npci_write_config_byte(pdev, NV_MCP_SATA_CFG_20, regval);\r\n}\r\nif (type == ADMA) {\r\nrc = nv_adma_host_init(host);\r\nif (rc)\r\nreturn rc;\r\n} else if (type == SWNCQ)\r\nnv_swncq_host_init(host);\r\nif (msi_enabled) {\r\ndev_notice(&pdev->dev, "Using MSI\n");\r\npci_enable_msi(pdev);\r\n}\r\npci_set_master(pdev);\r\nreturn ata_pci_sff_activate_host(host, ipriv->irq_handler, ipriv->sht);\r\n}\r\nstatic int nv_pci_device_resume(struct pci_dev *pdev)\r\n{\r\nstruct ata_host *host = dev_get_drvdata(&pdev->dev);\r\nstruct nv_host_priv *hpriv = host->private_data;\r\nint rc;\r\nrc = ata_pci_device_do_resume(pdev);\r\nif (rc)\r\nreturn rc;\r\nif (pdev->dev.power.power_state.event == PM_EVENT_SUSPEND) {\r\nif (hpriv->type >= CK804) {\r\nu8 regval;\r\npci_read_config_byte(pdev, NV_MCP_SATA_CFG_20, &regval);\r\nregval |= NV_MCP_SATA_CFG_20_SATA_SPACE_EN;\r\npci_write_config_byte(pdev, NV_MCP_SATA_CFG_20, regval);\r\n}\r\nif (hpriv->type == ADMA) {\r\nu32 tmp32;\r\nstruct nv_adma_port_priv *pp;\r\npci_read_config_dword(pdev, NV_MCP_SATA_CFG_20, &tmp32);\r\npp = host->ports[0]->private_data;\r\nif (pp->flags & NV_ADMA_ATAPI_SETUP_COMPLETE)\r\ntmp32 &= ~(NV_MCP_SATA_CFG_20_PORT0_EN |\r\nNV_MCP_SATA_CFG_20_PORT0_PWB_EN);\r\nelse\r\ntmp32 |= (NV_MCP_SATA_CFG_20_PORT0_EN |\r\nNV_MCP_SATA_CFG_20_PORT0_PWB_EN);\r\npp = host->ports[1]->private_data;\r\nif (pp->flags & NV_ADMA_ATAPI_SETUP_COMPLETE)\r\ntmp32 &= ~(NV_MCP_SATA_CFG_20_PORT1_EN |\r\nNV_MCP_SATA_CFG_20_PORT1_PWB_EN);\r\nelse\r\ntmp32 |= (NV_MCP_SATA_CFG_20_PORT1_EN |\r\nNV_MCP_SATA_CFG_20_PORT1_PWB_EN);\r\npci_write_config_dword(pdev, NV_MCP_SATA_CFG_20, tmp32);\r\n}\r\n}\r\nata_host_resume(host);\r\nreturn 0;\r\n}\r\nstatic void nv_ck804_host_stop(struct ata_host *host)\r\n{\r\nstruct pci_dev *pdev = to_pci_dev(host->dev);\r\nu8 regval;\r\npci_read_config_byte(pdev, NV_MCP_SATA_CFG_20, &regval);\r\nregval &= ~NV_MCP_SATA_CFG_20_SATA_SPACE_EN;\r\npci_write_config_byte(pdev, NV_MCP_SATA_CFG_20, regval);\r\n}\r\nstatic void nv_adma_host_stop(struct ata_host *host)\r\n{\r\nstruct pci_dev *pdev = to_pci_dev(host->dev);\r\nu32 tmp32;\r\npci_read_config_dword(pdev, NV_MCP_SATA_CFG_20, &tmp32);\r\ntmp32 &= ~(NV_MCP_SATA_CFG_20_PORT0_EN |\r\nNV_MCP_SATA_CFG_20_PORT0_PWB_EN |\r\nNV_MCP_SATA_CFG_20_PORT1_EN |\r\nNV_MCP_SATA_CFG_20_PORT1_PWB_EN);\r\npci_write_config_dword(pdev, NV_MCP_SATA_CFG_20, tmp32);\r\nnv_ck804_host_stop(host);\r\n}\r\nstatic int __init nv_init(void)\r\n{\r\nreturn pci_register_driver(&nv_pci_driver);\r\n}\r\nstatic void __exit nv_exit(void)\r\n{\r\npci_unregister_driver(&nv_pci_driver);\r\n}
