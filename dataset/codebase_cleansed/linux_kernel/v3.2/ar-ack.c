void __rxrpc_propose_ACK(struct rxrpc_call *call, u8 ack_reason,\r\n__be32 serial, bool immediate)\r\n{\r\nunsigned long expiry;\r\ns8 prior = rxrpc_ack_priority[ack_reason];\r\nASSERTCMP(prior, >, 0);\r\n_enter("{%d},%s,%%%x,%u",\r\ncall->debug_id, rxrpc_acks[ack_reason], ntohl(serial),\r\nimmediate);\r\nif (prior < rxrpc_ack_priority[call->ackr_reason]) {\r\nif (immediate)\r\ngoto cancel_timer;\r\nreturn;\r\n}\r\nif (prior == rxrpc_ack_priority[call->ackr_reason]) {\r\nif (prior <= 4)\r\ncall->ackr_serial = serial;\r\nif (immediate)\r\ngoto cancel_timer;\r\nreturn;\r\n}\r\ncall->ackr_reason = ack_reason;\r\ncall->ackr_serial = serial;\r\nswitch (ack_reason) {\r\ncase RXRPC_ACK_DELAY:\r\n_debug("run delay timer");\r\ncall->ack_timer.expires = jiffies + rxrpc_ack_timeout * HZ;\r\nadd_timer(&call->ack_timer);\r\nreturn;\r\ncase RXRPC_ACK_IDLE:\r\nif (!immediate) {\r\n_debug("run defer timer");\r\nexpiry = 1;\r\ngoto run_timer;\r\n}\r\ngoto cancel_timer;\r\ncase RXRPC_ACK_REQUESTED:\r\nif (!rxrpc_ack_defer)\r\ngoto cancel_timer;\r\nif (!immediate || serial == cpu_to_be32(1)) {\r\n_debug("run defer timer");\r\nexpiry = rxrpc_ack_defer;\r\ngoto run_timer;\r\n}\r\ndefault:\r\n_debug("immediate ACK");\r\ngoto cancel_timer;\r\n}\r\nrun_timer:\r\nexpiry += jiffies;\r\nif (!timer_pending(&call->ack_timer) ||\r\ntime_after(call->ack_timer.expires, expiry))\r\nmod_timer(&call->ack_timer, expiry);\r\nreturn;\r\ncancel_timer:\r\n_debug("cancel timer %%%u", ntohl(serial));\r\ntry_to_del_timer_sync(&call->ack_timer);\r\nread_lock_bh(&call->state_lock);\r\nif (call->state <= RXRPC_CALL_COMPLETE &&\r\n!test_and_set_bit(RXRPC_CALL_ACK, &call->events))\r\nrxrpc_queue_call(call);\r\nread_unlock_bh(&call->state_lock);\r\n}\r\nvoid rxrpc_propose_ACK(struct rxrpc_call *call, u8 ack_reason,\r\n__be32 serial, bool immediate)\r\n{\r\ns8 prior = rxrpc_ack_priority[ack_reason];\r\nif (prior > rxrpc_ack_priority[call->ackr_reason]) {\r\nspin_lock_bh(&call->lock);\r\n__rxrpc_propose_ACK(call, ack_reason, serial, immediate);\r\nspin_unlock_bh(&call->lock);\r\n}\r\n}\r\nstatic void rxrpc_set_resend(struct rxrpc_call *call, u8 resend,\r\nunsigned long resend_at)\r\n{\r\nread_lock_bh(&call->state_lock);\r\nif (call->state >= RXRPC_CALL_COMPLETE)\r\nresend = 0;\r\nif (resend & 1) {\r\n_debug("SET RESEND");\r\nset_bit(RXRPC_CALL_RESEND, &call->events);\r\n}\r\nif (resend & 2) {\r\n_debug("MODIFY RESEND TIMER");\r\nset_bit(RXRPC_CALL_RUN_RTIMER, &call->flags);\r\nmod_timer(&call->resend_timer, resend_at);\r\n} else {\r\n_debug("KILL RESEND TIMER");\r\ndel_timer_sync(&call->resend_timer);\r\nclear_bit(RXRPC_CALL_RESEND_TIMER, &call->events);\r\nclear_bit(RXRPC_CALL_RUN_RTIMER, &call->flags);\r\n}\r\nread_unlock_bh(&call->state_lock);\r\n}\r\nstatic void rxrpc_resend(struct rxrpc_call *call)\r\n{\r\nstruct rxrpc_skb_priv *sp;\r\nstruct rxrpc_header *hdr;\r\nstruct sk_buff *txb;\r\nunsigned long *p_txb, resend_at;\r\nint loop, stop;\r\nu8 resend;\r\n_enter("{%d,%d,%d,%d},",\r\ncall->acks_hard, call->acks_unacked,\r\natomic_read(&call->sequence),\r\nCIRC_CNT(call->acks_head, call->acks_tail, call->acks_winsz));\r\nstop = 0;\r\nresend = 0;\r\nresend_at = 0;\r\nfor (loop = call->acks_tail;\r\nloop != call->acks_head || stop;\r\nloop = (loop + 1) & (call->acks_winsz - 1)\r\n) {\r\np_txb = call->acks_window + loop;\r\nsmp_read_barrier_depends();\r\nif (*p_txb & 1)\r\ncontinue;\r\ntxb = (struct sk_buff *) *p_txb;\r\nsp = rxrpc_skb(txb);\r\nif (sp->need_resend) {\r\nsp->need_resend = 0;\r\nsp->hdr.serial =\r\nhtonl(atomic_inc_return(&call->conn->serial));\r\nhdr = (struct rxrpc_header *) txb->head;\r\nhdr->serial = sp->hdr.serial;\r\n_proto("Tx DATA %%%u { #%d }",\r\nntohl(sp->hdr.serial), ntohl(sp->hdr.seq));\r\nif (rxrpc_send_packet(call->conn->trans, txb) < 0) {\r\nstop = 0;\r\nsp->resend_at = jiffies + 3;\r\n} else {\r\nsp->resend_at =\r\njiffies + rxrpc_resend_timeout * HZ;\r\n}\r\n}\r\nif (time_after_eq(jiffies + 1, sp->resend_at)) {\r\nsp->need_resend = 1;\r\nresend |= 1;\r\n} else if (resend & 2) {\r\nif (time_before(sp->resend_at, resend_at))\r\nresend_at = sp->resend_at;\r\n} else {\r\nresend_at = sp->resend_at;\r\nresend |= 2;\r\n}\r\n}\r\nrxrpc_set_resend(call, resend, resend_at);\r\n_leave("");\r\n}\r\nstatic void rxrpc_resend_timer(struct rxrpc_call *call)\r\n{\r\nstruct rxrpc_skb_priv *sp;\r\nstruct sk_buff *txb;\r\nunsigned long *p_txb, resend_at;\r\nint loop;\r\nu8 resend;\r\n_enter("%d,%d,%d",\r\ncall->acks_tail, call->acks_unacked, call->acks_head);\r\nif (call->state >= RXRPC_CALL_COMPLETE)\r\nreturn;\r\nresend = 0;\r\nresend_at = 0;\r\nfor (loop = call->acks_unacked;\r\nloop != call->acks_head;\r\nloop = (loop + 1) & (call->acks_winsz - 1)\r\n) {\r\np_txb = call->acks_window + loop;\r\nsmp_read_barrier_depends();\r\ntxb = (struct sk_buff *) (*p_txb & ~1);\r\nsp = rxrpc_skb(txb);\r\nASSERT(!(*p_txb & 1));\r\nif (sp->need_resend) {\r\n;\r\n} else if (time_after_eq(jiffies + 1, sp->resend_at)) {\r\nsp->need_resend = 1;\r\nresend |= 1;\r\n} else if (resend & 2) {\r\nif (time_before(sp->resend_at, resend_at))\r\nresend_at = sp->resend_at;\r\n} else {\r\nresend_at = sp->resend_at;\r\nresend |= 2;\r\n}\r\n}\r\nrxrpc_set_resend(call, resend, resend_at);\r\n_leave("");\r\n}\r\nstatic int rxrpc_process_soft_ACKs(struct rxrpc_call *call,\r\nstruct rxrpc_ackpacket *ack,\r\nstruct sk_buff *skb)\r\n{\r\nstruct rxrpc_skb_priv *sp;\r\nstruct sk_buff *txb;\r\nunsigned long *p_txb, resend_at;\r\nint loop;\r\nu8 sacks[RXRPC_MAXACKS], resend;\r\n_enter("{%d,%d},{%d},",\r\ncall->acks_hard,\r\nCIRC_CNT(call->acks_head, call->acks_tail, call->acks_winsz),\r\nack->nAcks);\r\nif (skb_copy_bits(skb, 0, sacks, ack->nAcks) < 0)\r\ngoto protocol_error;\r\nresend = 0;\r\nresend_at = 0;\r\nfor (loop = 0; loop < ack->nAcks; loop++) {\r\np_txb = call->acks_window;\r\np_txb += (call->acks_tail + loop) & (call->acks_winsz - 1);\r\nsmp_read_barrier_depends();\r\ntxb = (struct sk_buff *) (*p_txb & ~1);\r\nsp = rxrpc_skb(txb);\r\nswitch (sacks[loop]) {\r\ncase RXRPC_ACK_TYPE_ACK:\r\nsp->need_resend = 0;\r\n*p_txb |= 1;\r\nbreak;\r\ncase RXRPC_ACK_TYPE_NACK:\r\nsp->need_resend = 1;\r\n*p_txb &= ~1;\r\nresend = 1;\r\nbreak;\r\ndefault:\r\n_debug("Unsupported ACK type %d", sacks[loop]);\r\ngoto protocol_error;\r\n}\r\n}\r\nsmp_mb();\r\ncall->acks_unacked = (call->acks_tail + loop) & (call->acks_winsz - 1);\r\nfor (loop = call->acks_unacked;\r\nloop != call->acks_head;\r\nloop = (loop + 1) & (call->acks_winsz - 1)\r\n) {\r\np_txb = call->acks_window + loop;\r\nsmp_read_barrier_depends();\r\ntxb = (struct sk_buff *) (*p_txb & ~1);\r\nsp = rxrpc_skb(txb);\r\nif (*p_txb & 1) {\r\nsp->need_resend = 1;\r\n*p_txb &= ~1;\r\nresend |= 1;\r\n} else if (sp->need_resend) {\r\n;\r\n} else if (time_after_eq(jiffies + 1, sp->resend_at)) {\r\nsp->need_resend = 1;\r\nresend |= 1;\r\n} else if (resend & 2) {\r\nif (time_before(sp->resend_at, resend_at))\r\nresend_at = sp->resend_at;\r\n} else {\r\nresend_at = sp->resend_at;\r\nresend |= 2;\r\n}\r\n}\r\nrxrpc_set_resend(call, resend, resend_at);\r\n_leave(" = 0");\r\nreturn 0;\r\nprotocol_error:\r\n_leave(" = -EPROTO");\r\nreturn -EPROTO;\r\n}\r\nstatic void rxrpc_rotate_tx_window(struct rxrpc_call *call, u32 hard)\r\n{\r\nunsigned long _skb;\r\nint tail = call->acks_tail, old_tail;\r\nint win = CIRC_CNT(call->acks_head, tail, call->acks_winsz);\r\n_enter("{%u,%u},%u", call->acks_hard, win, hard);\r\nASSERTCMP(hard - call->acks_hard, <=, win);\r\nwhile (call->acks_hard < hard) {\r\nsmp_read_barrier_depends();\r\n_skb = call->acks_window[tail] & ~1;\r\nrxrpc_free_skb((struct sk_buff *) _skb);\r\nold_tail = tail;\r\ntail = (tail + 1) & (call->acks_winsz - 1);\r\ncall->acks_tail = tail;\r\nif (call->acks_unacked == old_tail)\r\ncall->acks_unacked = tail;\r\ncall->acks_hard++;\r\n}\r\nwake_up(&call->tx_waitq);\r\n}\r\nstatic void rxrpc_clear_tx_window(struct rxrpc_call *call)\r\n{\r\nrxrpc_rotate_tx_window(call, atomic_read(&call->sequence));\r\n}\r\nstatic int rxrpc_drain_rx_oos_queue(struct rxrpc_call *call)\r\n{\r\nstruct rxrpc_skb_priv *sp;\r\nstruct sk_buff *skb;\r\nbool terminal;\r\nint ret;\r\n_enter("{%d,%d}", call->rx_data_post, call->rx_first_oos);\r\nspin_lock_bh(&call->lock);\r\nret = -ECONNRESET;\r\nif (test_bit(RXRPC_CALL_RELEASED, &call->flags))\r\ngoto socket_unavailable;\r\nskb = skb_dequeue(&call->rx_oos_queue);\r\nif (skb) {\r\nsp = rxrpc_skb(skb);\r\n_debug("drain OOS packet %d [%d]",\r\nntohl(sp->hdr.seq), call->rx_first_oos);\r\nif (ntohl(sp->hdr.seq) != call->rx_first_oos) {\r\nskb_queue_head(&call->rx_oos_queue, skb);\r\ncall->rx_first_oos = ntohl(rxrpc_skb(skb)->hdr.seq);\r\n_debug("requeue %p {%u}", skb, call->rx_first_oos);\r\n} else {\r\nskb->mark = RXRPC_SKB_MARK_DATA;\r\nterminal = ((sp->hdr.flags & RXRPC_LAST_PACKET) &&\r\n!(sp->hdr.flags & RXRPC_CLIENT_INITIATED));\r\nret = rxrpc_queue_rcv_skb(call, skb, true, terminal);\r\nBUG_ON(ret < 0);\r\n_debug("drain #%u", call->rx_data_post);\r\ncall->rx_data_post++;\r\nskb = skb_peek(&call->rx_oos_queue);\r\nif (skb)\r\ncall->rx_first_oos =\r\nntohl(rxrpc_skb(skb)->hdr.seq);\r\nelse\r\ncall->rx_first_oos = 0;\r\n_debug("peek %p {%u}", skb, call->rx_first_oos);\r\n}\r\n}\r\nret = 0;\r\nsocket_unavailable:\r\nspin_unlock_bh(&call->lock);\r\n_leave(" = %d", ret);\r\nreturn ret;\r\n}\r\nstatic void rxrpc_insert_oos_packet(struct rxrpc_call *call,\r\nstruct sk_buff *skb)\r\n{\r\nstruct rxrpc_skb_priv *sp, *psp;\r\nstruct sk_buff *p;\r\nu32 seq;\r\nsp = rxrpc_skb(skb);\r\nseq = ntohl(sp->hdr.seq);\r\n_enter(",,{%u}", seq);\r\nskb->destructor = rxrpc_packet_destructor;\r\nASSERTCMP(sp->call, ==, NULL);\r\nsp->call = call;\r\nrxrpc_get_call(call);\r\nspin_lock_bh(&call->lock);\r\nskb_queue_walk(&call->rx_oos_queue, p) {\r\npsp = rxrpc_skb(p);\r\nif (ntohl(psp->hdr.seq) > seq) {\r\n_debug("insert oos #%u before #%u",\r\nseq, ntohl(psp->hdr.seq));\r\nskb_insert(p, skb, &call->rx_oos_queue);\r\ngoto inserted;\r\n}\r\n}\r\n_debug("append oos #%u", seq);\r\nskb_queue_tail(&call->rx_oos_queue, skb);\r\ninserted:\r\nif (call->rx_first_oos == 0 || seq < call->rx_first_oos)\r\ncall->rx_first_oos = seq;\r\nread_lock(&call->state_lock);\r\nif (call->state < RXRPC_CALL_COMPLETE &&\r\ncall->rx_data_post == call->rx_first_oos) {\r\n_debug("drain rx oos now");\r\nset_bit(RXRPC_CALL_DRAIN_RX_OOS, &call->events);\r\n}\r\nread_unlock(&call->state_lock);\r\nspin_unlock_bh(&call->lock);\r\n_leave(" [stored #%u]", call->rx_first_oos);\r\n}\r\nstatic void rxrpc_zap_tx_window(struct rxrpc_call *call)\r\n{\r\nstruct rxrpc_skb_priv *sp;\r\nstruct sk_buff *skb;\r\nunsigned long _skb, *acks_window;\r\nu8 winsz = call->acks_winsz;\r\nint tail;\r\nacks_window = call->acks_window;\r\ncall->acks_window = NULL;\r\nwhile (CIRC_CNT(call->acks_head, call->acks_tail, winsz) > 0) {\r\ntail = call->acks_tail;\r\nsmp_read_barrier_depends();\r\n_skb = acks_window[tail] & ~1;\r\nsmp_mb();\r\ncall->acks_tail = (call->acks_tail + 1) & (winsz - 1);\r\nskb = (struct sk_buff *) _skb;\r\nsp = rxrpc_skb(skb);\r\n_debug("+++ clear Tx %u", ntohl(sp->hdr.seq));\r\nrxrpc_free_skb(skb);\r\n}\r\nkfree(acks_window);\r\n}\r\nstatic void rxrpc_extract_ackinfo(struct rxrpc_call *call, struct sk_buff *skb,\r\nunsigned latest, int nAcks)\r\n{\r\nstruct rxrpc_ackinfo ackinfo;\r\nstruct rxrpc_peer *peer;\r\nunsigned mtu;\r\nif (skb_copy_bits(skb, nAcks + 3, &ackinfo, sizeof(ackinfo)) < 0) {\r\n_leave(" [no ackinfo]");\r\nreturn;\r\n}\r\n_proto("Rx ACK %%%u Info { rx=%u max=%u rwin=%u jm=%u }",\r\nlatest,\r\nntohl(ackinfo.rxMTU), ntohl(ackinfo.maxMTU),\r\nntohl(ackinfo.rwind), ntohl(ackinfo.jumbo_max));\r\nmtu = min(ntohl(ackinfo.rxMTU), ntohl(ackinfo.maxMTU));\r\npeer = call->conn->trans->peer;\r\nif (mtu < peer->maxdata) {\r\nspin_lock_bh(&peer->lock);\r\npeer->maxdata = mtu;\r\npeer->mtu = mtu + peer->hdrsize;\r\nspin_unlock_bh(&peer->lock);\r\n_net("Net MTU %u (maxdata %u)", peer->mtu, peer->maxdata);\r\n}\r\n}\r\nstatic int rxrpc_process_rx_queue(struct rxrpc_call *call,\r\nu32 *_abort_code)\r\n{\r\nstruct rxrpc_ackpacket ack;\r\nstruct rxrpc_skb_priv *sp;\r\nstruct sk_buff *skb;\r\nbool post_ACK;\r\nint latest;\r\nu32 hard, tx;\r\n_enter("");\r\nprocess_further:\r\nskb = skb_dequeue(&call->rx_queue);\r\nif (!skb)\r\nreturn -EAGAIN;\r\n_net("deferred skb %p", skb);\r\nsp = rxrpc_skb(skb);\r\n_debug("process %s [st %d]", rxrpc_pkts[sp->hdr.type], call->state);\r\npost_ACK = false;\r\nswitch (sp->hdr.type) {\r\ncase RXRPC_PACKET_TYPE_DATA:\r\n_proto("OOSQ DATA %%%u { #%u }",\r\nntohl(sp->hdr.serial), ntohl(sp->hdr.seq));\r\nif (rxrpc_verify_packet(call, skb, _abort_code) < 0)\r\ngoto protocol_error;\r\nrxrpc_insert_oos_packet(call, skb);\r\ngoto process_further;\r\ncase RXRPC_PACKET_TYPE_ACK:\r\nif (skb_copy_bits(skb, 0, &ack, sizeof(ack)) < 0) {\r\n_debug("extraction failure");\r\ngoto protocol_error;\r\n}\r\nif (!skb_pull(skb, sizeof(ack)))\r\nBUG();\r\nlatest = ntohl(sp->hdr.serial);\r\nhard = ntohl(ack.firstPacket);\r\ntx = atomic_read(&call->sequence);\r\n_proto("Rx ACK %%%u { m=%hu f=#%u p=#%u s=%%%u r=%s n=%u }",\r\nlatest,\r\nntohs(ack.maxSkew),\r\nhard,\r\nntohl(ack.previousPacket),\r\nntohl(ack.serial),\r\nrxrpc_acks[ack.reason],\r\nack.nAcks);\r\nrxrpc_extract_ackinfo(call, skb, latest, ack.nAcks);\r\nif (ack.reason == RXRPC_ACK_PING) {\r\n_proto("Rx ACK %%%u PING Request", latest);\r\nrxrpc_propose_ACK(call, RXRPC_ACK_PING_RESPONSE,\r\nsp->hdr.serial, true);\r\n}\r\nif (latest - call->acks_latest <= 0) {\r\n_debug("discard ACK %d <= %d",\r\nlatest, call->acks_latest);\r\ngoto discard;\r\n}\r\ncall->acks_latest = latest;\r\nif (call->state != RXRPC_CALL_CLIENT_SEND_REQUEST &&\r\ncall->state != RXRPC_CALL_CLIENT_AWAIT_REPLY &&\r\ncall->state != RXRPC_CALL_SERVER_SEND_REPLY &&\r\ncall->state != RXRPC_CALL_SERVER_AWAIT_ACK)\r\ngoto discard;\r\n_debug("Tx=%d H=%u S=%d", tx, call->acks_hard, call->state);\r\nif (hard > 0) {\r\nif (hard - 1 > tx) {\r\n_debug("hard-ACK'd packet %d not transmitted"\r\n" (%d top)",\r\nhard - 1, tx);\r\ngoto protocol_error;\r\n}\r\nif ((call->state == RXRPC_CALL_CLIENT_AWAIT_REPLY ||\r\ncall->state == RXRPC_CALL_SERVER_AWAIT_ACK) &&\r\nhard > tx)\r\ngoto all_acked;\r\nsmp_rmb();\r\nrxrpc_rotate_tx_window(call, hard - 1);\r\n}\r\nif (ack.nAcks > 0) {\r\nif (hard - 1 + ack.nAcks > tx) {\r\n_debug("soft-ACK'd packet %d+%d not"\r\n" transmitted (%d top)",\r\nhard - 1, ack.nAcks, tx);\r\ngoto protocol_error;\r\n}\r\nif (rxrpc_process_soft_ACKs(call, &ack, skb) < 0)\r\ngoto protocol_error;\r\n}\r\ngoto discard;\r\ncase RXRPC_PACKET_TYPE_ACKALL:\r\ngoto all_acked;\r\ncase RXRPC_PACKET_TYPE_BUSY:\r\ncase RXRPC_PACKET_TYPE_ABORT:\r\nBUG();\r\ncase RXRPC_PACKET_TYPE_CHALLENGE:\r\ncase RXRPC_PACKET_TYPE_RESPONSE:\r\ncase RXRPC_PACKET_TYPE_DEBUG:\r\nBUG();\r\n}\r\nall_acked:\r\nwrite_lock_bh(&call->state_lock);\r\n_debug("ack all %d", call->state);\r\nswitch (call->state) {\r\ncase RXRPC_CALL_CLIENT_AWAIT_REPLY:\r\ncall->state = RXRPC_CALL_CLIENT_RECV_REPLY;\r\nbreak;\r\ncase RXRPC_CALL_SERVER_AWAIT_ACK:\r\n_debug("srv complete");\r\ncall->state = RXRPC_CALL_COMPLETE;\r\npost_ACK = true;\r\nbreak;\r\ncase RXRPC_CALL_CLIENT_SEND_REQUEST:\r\ncase RXRPC_CALL_SERVER_RECV_REQUEST:\r\ngoto protocol_error_unlock;\r\ndefault:\r\nwrite_unlock_bh(&call->state_lock);\r\ngoto discard;\r\n}\r\nwrite_unlock_bh(&call->state_lock);\r\n_debug("clear Tx %d",\r\nCIRC_CNT(call->acks_head, call->acks_tail, call->acks_winsz));\r\ndel_timer_sync(&call->resend_timer);\r\nclear_bit(RXRPC_CALL_RUN_RTIMER, &call->flags);\r\nclear_bit(RXRPC_CALL_RESEND_TIMER, &call->events);\r\nif (call->acks_window)\r\nrxrpc_zap_tx_window(call);\r\nif (post_ACK) {\r\n_debug("post ACK");\r\nskb->mark = RXRPC_SKB_MARK_FINAL_ACK;\r\nsp->call = call;\r\nrxrpc_get_call(call);\r\nspin_lock_bh(&call->lock);\r\nif (rxrpc_queue_rcv_skb(call, skb, true, true) < 0)\r\nBUG();\r\nspin_unlock_bh(&call->lock);\r\ngoto process_further;\r\n}\r\ndiscard:\r\nrxrpc_free_skb(skb);\r\ngoto process_further;\r\nprotocol_error_unlock:\r\nwrite_unlock_bh(&call->state_lock);\r\nprotocol_error:\r\nrxrpc_free_skb(skb);\r\n_leave(" = -EPROTO");\r\nreturn -EPROTO;\r\n}\r\nstatic int rxrpc_post_message(struct rxrpc_call *call, u32 mark, u32 error,\r\nbool fatal)\r\n{\r\nstruct rxrpc_skb_priv *sp;\r\nstruct sk_buff *skb;\r\nint ret;\r\n_enter("{%d,%lx},%u,%u,%d",\r\ncall->debug_id, call->flags, mark, error, fatal);\r\nif (fatal) {\r\ndel_timer_sync(&call->resend_timer);\r\ndel_timer_sync(&call->ack_timer);\r\nclear_bit(RXRPC_CALL_RUN_RTIMER, &call->flags);\r\n}\r\nif (mark != RXRPC_SKB_MARK_NEW_CALL &&\r\n!test_bit(RXRPC_CALL_HAS_USERID, &call->flags)) {\r\n_leave("[no userid]");\r\nreturn 0;\r\n}\r\nif (!test_bit(RXRPC_CALL_TERMINAL_MSG, &call->flags)) {\r\nskb = alloc_skb(0, GFP_NOFS);\r\nif (!skb)\r\nreturn -ENOMEM;\r\nrxrpc_new_skb(skb);\r\nskb->mark = mark;\r\nsp = rxrpc_skb(skb);\r\nmemset(sp, 0, sizeof(*sp));\r\nsp->error = error;\r\nsp->call = call;\r\nrxrpc_get_call(call);\r\nspin_lock_bh(&call->lock);\r\nret = rxrpc_queue_rcv_skb(call, skb, true, fatal);\r\nspin_unlock_bh(&call->lock);\r\nBUG_ON(ret < 0);\r\n}\r\nreturn 0;\r\n}\r\nvoid rxrpc_process_call(struct work_struct *work)\r\n{\r\nstruct rxrpc_call *call =\r\ncontainer_of(work, struct rxrpc_call, processor);\r\nstruct rxrpc_ackpacket ack;\r\nstruct rxrpc_ackinfo ackinfo;\r\nstruct rxrpc_header hdr;\r\nstruct msghdr msg;\r\nstruct kvec iov[5];\r\nunsigned long bits;\r\n__be32 data, pad;\r\nsize_t len;\r\nint genbit, loop, nbit, ioc, ret, mtu;\r\nu32 abort_code = RX_PROTOCOL_ERROR;\r\nu8 *acks = NULL;\r\n_enter("{%d,%s,%lx} [%lu]",\r\ncall->debug_id, rxrpc_call_states[call->state], call->events,\r\n(jiffies - call->creation_jif) / (HZ / 10));\r\nif (test_and_set_bit(RXRPC_CALL_PROC_BUSY, &call->flags)) {\r\n_debug("XXXXXXXXXXXXX RUNNING ON MULTIPLE CPUS XXXXXXXXXXXXX");\r\nreturn;\r\n}\r\nmsg.msg_name = &call->conn->trans->peer->srx.transport.sin;\r\nmsg.msg_namelen = sizeof(call->conn->trans->peer->srx.transport.sin);\r\nmsg.msg_control = NULL;\r\nmsg.msg_controllen = 0;\r\nmsg.msg_flags = 0;\r\nhdr.epoch = call->conn->epoch;\r\nhdr.cid = call->cid;\r\nhdr.callNumber = call->call_id;\r\nhdr.seq = 0;\r\nhdr.type = RXRPC_PACKET_TYPE_ACK;\r\nhdr.flags = call->conn->out_clientflag;\r\nhdr.userStatus = 0;\r\nhdr.securityIndex = call->conn->security_ix;\r\nhdr._rsvd = 0;\r\nhdr.serviceId = call->conn->service_id;\r\nmemset(iov, 0, sizeof(iov));\r\niov[0].iov_base = &hdr;\r\niov[0].iov_len = sizeof(hdr);\r\nif (test_bit(RXRPC_CALL_RELEASE, &call->events)) {\r\nrxrpc_release_call(call);\r\nclear_bit(RXRPC_CALL_RELEASE, &call->events);\r\n}\r\nif (test_bit(RXRPC_CALL_RCVD_ERROR, &call->events)) {\r\nint error;\r\nclear_bit(RXRPC_CALL_CONN_ABORT, &call->events);\r\nclear_bit(RXRPC_CALL_REJECT_BUSY, &call->events);\r\nclear_bit(RXRPC_CALL_ABORT, &call->events);\r\nerror = call->conn->trans->peer->net_error;\r\n_debug("post net error %d", error);\r\nif (rxrpc_post_message(call, RXRPC_SKB_MARK_NET_ERROR,\r\nerror, true) < 0)\r\ngoto no_mem;\r\nclear_bit(RXRPC_CALL_RCVD_ERROR, &call->events);\r\ngoto kill_ACKs;\r\n}\r\nif (test_bit(RXRPC_CALL_CONN_ABORT, &call->events)) {\r\nASSERTCMP(call->state, >, RXRPC_CALL_COMPLETE);\r\nclear_bit(RXRPC_CALL_REJECT_BUSY, &call->events);\r\nclear_bit(RXRPC_CALL_ABORT, &call->events);\r\n_debug("post conn abort");\r\nif (rxrpc_post_message(call, RXRPC_SKB_MARK_LOCAL_ERROR,\r\ncall->conn->error, true) < 0)\r\ngoto no_mem;\r\nclear_bit(RXRPC_CALL_CONN_ABORT, &call->events);\r\ngoto kill_ACKs;\r\n}\r\nif (test_bit(RXRPC_CALL_REJECT_BUSY, &call->events)) {\r\nhdr.type = RXRPC_PACKET_TYPE_BUSY;\r\ngenbit = RXRPC_CALL_REJECT_BUSY;\r\ngoto send_message;\r\n}\r\nif (test_bit(RXRPC_CALL_ABORT, &call->events)) {\r\nASSERTCMP(call->state, >, RXRPC_CALL_COMPLETE);\r\nif (rxrpc_post_message(call, RXRPC_SKB_MARK_LOCAL_ERROR,\r\nECONNABORTED, true) < 0)\r\ngoto no_mem;\r\nhdr.type = RXRPC_PACKET_TYPE_ABORT;\r\ndata = htonl(call->abort_code);\r\niov[1].iov_base = &data;\r\niov[1].iov_len = sizeof(data);\r\ngenbit = RXRPC_CALL_ABORT;\r\ngoto send_message;\r\n}\r\nif (test_bit(RXRPC_CALL_ACK_FINAL, &call->events)) {\r\ngenbit = RXRPC_CALL_ACK_FINAL;\r\nack.bufferSpace = htons(8);\r\nack.maxSkew = 0;\r\nack.serial = 0;\r\nack.reason = RXRPC_ACK_IDLE;\r\nack.nAcks = 0;\r\ncall->ackr_reason = 0;\r\nspin_lock_bh(&call->lock);\r\nack.serial = call->ackr_serial;\r\nack.previousPacket = call->ackr_prev_seq;\r\nack.firstPacket = htonl(call->rx_data_eaten + 1);\r\nspin_unlock_bh(&call->lock);\r\npad = 0;\r\niov[1].iov_base = &ack;\r\niov[1].iov_len = sizeof(ack);\r\niov[2].iov_base = &pad;\r\niov[2].iov_len = 3;\r\niov[3].iov_base = &ackinfo;\r\niov[3].iov_len = sizeof(ackinfo);\r\ngoto send_ACK;\r\n}\r\nif (call->events & ((1 << RXRPC_CALL_RCVD_BUSY) |\r\n(1 << RXRPC_CALL_RCVD_ABORT))\r\n) {\r\nu32 mark;\r\nif (test_bit(RXRPC_CALL_RCVD_ABORT, &call->events))\r\nmark = RXRPC_SKB_MARK_REMOTE_ABORT;\r\nelse\r\nmark = RXRPC_SKB_MARK_BUSY;\r\n_debug("post abort/busy");\r\nrxrpc_clear_tx_window(call);\r\nif (rxrpc_post_message(call, mark, ECONNABORTED, true) < 0)\r\ngoto no_mem;\r\nclear_bit(RXRPC_CALL_RCVD_BUSY, &call->events);\r\nclear_bit(RXRPC_CALL_RCVD_ABORT, &call->events);\r\ngoto kill_ACKs;\r\n}\r\nif (test_and_clear_bit(RXRPC_CALL_RCVD_ACKALL, &call->events)) {\r\n_debug("do implicit ackall");\r\nrxrpc_clear_tx_window(call);\r\n}\r\nif (test_bit(RXRPC_CALL_LIFE_TIMER, &call->events)) {\r\nwrite_lock_bh(&call->state_lock);\r\nif (call->state <= RXRPC_CALL_COMPLETE) {\r\ncall->state = RXRPC_CALL_LOCALLY_ABORTED;\r\ncall->abort_code = RX_CALL_TIMEOUT;\r\nset_bit(RXRPC_CALL_ABORT, &call->events);\r\n}\r\nwrite_unlock_bh(&call->state_lock);\r\n_debug("post timeout");\r\nif (rxrpc_post_message(call, RXRPC_SKB_MARK_LOCAL_ERROR,\r\nETIME, true) < 0)\r\ngoto no_mem;\r\nclear_bit(RXRPC_CALL_LIFE_TIMER, &call->events);\r\ngoto kill_ACKs;\r\n}\r\nif (!skb_queue_empty(&call->rx_queue)) {\r\nswitch (rxrpc_process_rx_queue(call, &abort_code)) {\r\ncase 0:\r\ncase -EAGAIN:\r\nbreak;\r\ncase -ENOMEM:\r\ngoto no_mem;\r\ncase -EKEYEXPIRED:\r\ncase -EKEYREJECTED:\r\ncase -EPROTO:\r\nrxrpc_abort_call(call, abort_code);\r\ngoto kill_ACKs;\r\n}\r\n}\r\nif (test_and_clear_bit(RXRPC_CALL_RESEND_TIMER, &call->events))\r\nrxrpc_resend_timer(call);\r\nif (test_and_clear_bit(RXRPC_CALL_RESEND, &call->events))\r\nrxrpc_resend(call);\r\nif (test_bit(RXRPC_CALL_ACK, &call->events)) {\r\n_debug("send ACK: window: %d - %d { %lx }",\r\ncall->rx_data_eaten, call->ackr_win_top,\r\ncall->ackr_window[0]);\r\nif (call->state > RXRPC_CALL_SERVER_ACK_REQUEST &&\r\ncall->ackr_reason != RXRPC_ACK_PING_RESPONSE) {\r\nclear_bit(RXRPC_CALL_ACK, &call->events);\r\ngoto maybe_reschedule;\r\n}\r\ngenbit = RXRPC_CALL_ACK;\r\nacks = kzalloc(call->ackr_win_top - call->rx_data_eaten,\r\nGFP_NOFS);\r\nif (!acks)\r\ngoto no_mem;\r\nack.bufferSpace = htons(8);\r\nack.maxSkew = 0;\r\nack.serial = 0;\r\nack.reason = 0;\r\nspin_lock_bh(&call->lock);\r\nack.reason = call->ackr_reason;\r\nack.serial = call->ackr_serial;\r\nack.previousPacket = call->ackr_prev_seq;\r\nack.firstPacket = htonl(call->rx_data_eaten + 1);\r\nack.nAcks = 0;\r\nfor (loop = 0; loop < RXRPC_ACKR_WINDOW_ASZ; loop++) {\r\nnbit = loop * BITS_PER_LONG;\r\nfor (bits = call->ackr_window[loop]; bits; bits >>= 1\r\n) {\r\n_debug("- l=%d n=%d b=%lx", loop, nbit, bits);\r\nif (bits & 1) {\r\nacks[nbit] = RXRPC_ACK_TYPE_ACK;\r\nack.nAcks = nbit + 1;\r\n}\r\nnbit++;\r\n}\r\n}\r\ncall->ackr_reason = 0;\r\nspin_unlock_bh(&call->lock);\r\npad = 0;\r\niov[1].iov_base = &ack;\r\niov[1].iov_len = sizeof(ack);\r\niov[2].iov_base = acks;\r\niov[2].iov_len = ack.nAcks;\r\niov[3].iov_base = &pad;\r\niov[3].iov_len = 3;\r\niov[4].iov_base = &ackinfo;\r\niov[4].iov_len = sizeof(ackinfo);\r\nswitch (ack.reason) {\r\ncase RXRPC_ACK_REQUESTED:\r\ncase RXRPC_ACK_DUPLICATE:\r\ncase RXRPC_ACK_OUT_OF_SEQUENCE:\r\ncase RXRPC_ACK_EXCEEDS_WINDOW:\r\ncase RXRPC_ACK_NOSPACE:\r\ncase RXRPC_ACK_PING:\r\ncase RXRPC_ACK_PING_RESPONSE:\r\ngoto send_ACK_with_skew;\r\ncase RXRPC_ACK_DELAY:\r\ncase RXRPC_ACK_IDLE:\r\ngoto send_ACK;\r\n}\r\n}\r\nif (test_and_clear_bit(RXRPC_CALL_SECURED, &call->events)) {\r\n_debug("secured");\r\nspin_lock_bh(&call->lock);\r\nif (call->state == RXRPC_CALL_SERVER_SECURING) {\r\n_debug("securing");\r\nwrite_lock(&call->conn->lock);\r\nif (!test_bit(RXRPC_CALL_RELEASED, &call->flags) &&\r\n!test_bit(RXRPC_CALL_RELEASE, &call->events)) {\r\n_debug("not released");\r\ncall->state = RXRPC_CALL_SERVER_ACCEPTING;\r\nlist_move_tail(&call->accept_link,\r\n&call->socket->acceptq);\r\n}\r\nwrite_unlock(&call->conn->lock);\r\nread_lock(&call->state_lock);\r\nif (call->state < RXRPC_CALL_COMPLETE)\r\nset_bit(RXRPC_CALL_POST_ACCEPT, &call->events);\r\nread_unlock(&call->state_lock);\r\n}\r\nspin_unlock_bh(&call->lock);\r\nif (!test_bit(RXRPC_CALL_POST_ACCEPT, &call->events))\r\ngoto maybe_reschedule;\r\n}\r\nif (test_bit(RXRPC_CALL_POST_ACCEPT, &call->events)) {\r\n_debug("post accept");\r\nif (rxrpc_post_message(call, RXRPC_SKB_MARK_NEW_CALL,\r\n0, false) < 0)\r\ngoto no_mem;\r\nclear_bit(RXRPC_CALL_POST_ACCEPT, &call->events);\r\ngoto maybe_reschedule;\r\n}\r\nif (test_and_clear_bit(RXRPC_CALL_ACCEPTED, &call->events)) {\r\n_debug("accepted");\r\nASSERTCMP(call->rx_data_post, ==, 0);\r\ncall->rx_data_post = 1;\r\nread_lock_bh(&call->state_lock);\r\nif (call->state < RXRPC_CALL_COMPLETE)\r\nset_bit(RXRPC_CALL_DRAIN_RX_OOS, &call->events);\r\nread_unlock_bh(&call->state_lock);\r\n}\r\nif (test_and_clear_bit(RXRPC_CALL_DRAIN_RX_OOS, &call->events)) {\r\nwhile (call->rx_data_post == call->rx_first_oos)\r\nif (rxrpc_drain_rx_oos_queue(call) < 0)\r\nbreak;\r\ngoto maybe_reschedule;\r\n}\r\ngoto maybe_reschedule;\r\nsend_ACK_with_skew:\r\nack.maxSkew = htons(atomic_read(&call->conn->hi_serial) -\r\nntohl(ack.serial));\r\nsend_ACK:\r\nmtu = call->conn->trans->peer->if_mtu;\r\nmtu -= call->conn->trans->peer->hdrsize;\r\nackinfo.maxMTU = htonl(mtu);\r\nackinfo.rwind = htonl(32);\r\nackinfo.rxMTU = htonl(5692);\r\nackinfo.jumbo_max = htonl(4);\r\nhdr.serial = htonl(atomic_inc_return(&call->conn->serial));\r\n_proto("Tx ACK %%%u { m=%hu f=#%u p=#%u s=%%%u r=%s n=%u }",\r\nntohl(hdr.serial),\r\nntohs(ack.maxSkew),\r\nntohl(ack.firstPacket),\r\nntohl(ack.previousPacket),\r\nntohl(ack.serial),\r\nrxrpc_acks[ack.reason],\r\nack.nAcks);\r\ndel_timer_sync(&call->ack_timer);\r\nif (ack.nAcks > 0)\r\nset_bit(RXRPC_CALL_TX_SOFT_ACK, &call->flags);\r\ngoto send_message_2;\r\nsend_message:\r\n_debug("send message");\r\nhdr.serial = htonl(atomic_inc_return(&call->conn->serial));\r\n_proto("Tx %s %%%u", rxrpc_pkts[hdr.type], ntohl(hdr.serial));\r\nsend_message_2:\r\nlen = iov[0].iov_len;\r\nioc = 1;\r\nif (iov[4].iov_len) {\r\nioc = 5;\r\nlen += iov[4].iov_len;\r\nlen += iov[3].iov_len;\r\nlen += iov[2].iov_len;\r\nlen += iov[1].iov_len;\r\n} else if (iov[3].iov_len) {\r\nioc = 4;\r\nlen += iov[3].iov_len;\r\nlen += iov[2].iov_len;\r\nlen += iov[1].iov_len;\r\n} else if (iov[2].iov_len) {\r\nioc = 3;\r\nlen += iov[2].iov_len;\r\nlen += iov[1].iov_len;\r\n} else if (iov[1].iov_len) {\r\nioc = 2;\r\nlen += iov[1].iov_len;\r\n}\r\nret = kernel_sendmsg(call->conn->trans->local->socket,\r\n&msg, iov, ioc, len);\r\nif (ret < 0) {\r\n_debug("sendmsg failed: %d", ret);\r\nread_lock_bh(&call->state_lock);\r\nif (call->state < RXRPC_CALL_DEAD)\r\nrxrpc_queue_call(call);\r\nread_unlock_bh(&call->state_lock);\r\ngoto error;\r\n}\r\nswitch (genbit) {\r\ncase RXRPC_CALL_ABORT:\r\nclear_bit(genbit, &call->events);\r\nclear_bit(RXRPC_CALL_RCVD_ABORT, &call->events);\r\ngoto kill_ACKs;\r\ncase RXRPC_CALL_ACK_FINAL:\r\nwrite_lock_bh(&call->state_lock);\r\nif (call->state == RXRPC_CALL_CLIENT_FINAL_ACK)\r\ncall->state = RXRPC_CALL_COMPLETE;\r\nwrite_unlock_bh(&call->state_lock);\r\ngoto kill_ACKs;\r\ndefault:\r\nclear_bit(genbit, &call->events);\r\nswitch (call->state) {\r\ncase RXRPC_CALL_CLIENT_AWAIT_REPLY:\r\ncase RXRPC_CALL_CLIENT_RECV_REPLY:\r\ncase RXRPC_CALL_SERVER_RECV_REQUEST:\r\ncase RXRPC_CALL_SERVER_ACK_REQUEST:\r\n_debug("start ACK timer");\r\nrxrpc_propose_ACK(call, RXRPC_ACK_DELAY,\r\ncall->ackr_serial, false);\r\ndefault:\r\nbreak;\r\n}\r\ngoto maybe_reschedule;\r\n}\r\nkill_ACKs:\r\ndel_timer_sync(&call->ack_timer);\r\nif (test_and_clear_bit(RXRPC_CALL_ACK_FINAL, &call->events))\r\nrxrpc_put_call(call);\r\nclear_bit(RXRPC_CALL_ACK, &call->events);\r\nmaybe_reschedule:\r\nif (call->events || !skb_queue_empty(&call->rx_queue)) {\r\nread_lock_bh(&call->state_lock);\r\nif (call->state < RXRPC_CALL_DEAD)\r\nrxrpc_queue_call(call);\r\nread_unlock_bh(&call->state_lock);\r\n}\r\nif (call->state >= RXRPC_CALL_COMPLETE &&\r\n!list_empty(&call->accept_link)) {\r\n_debug("X unlinking once-pending call %p { e=%lx f=%lx c=%x }",\r\ncall, call->events, call->flags,\r\nntohl(call->conn->cid));\r\nread_lock_bh(&call->state_lock);\r\nif (!test_bit(RXRPC_CALL_RELEASED, &call->flags) &&\r\n!test_and_set_bit(RXRPC_CALL_RELEASE, &call->events))\r\nrxrpc_queue_call(call);\r\nread_unlock_bh(&call->state_lock);\r\n}\r\nerror:\r\nclear_bit(RXRPC_CALL_PROC_BUSY, &call->flags);\r\nkfree(acks);\r\nif (call->events && !work_pending(&call->processor)) {\r\n_debug("jumpstart %x", ntohl(call->conn->cid));\r\nrxrpc_queue_call(call);\r\n}\r\n_leave("");\r\nreturn;\r\nno_mem:\r\n_debug("out of memory");\r\ngoto maybe_reschedule;\r\n}
