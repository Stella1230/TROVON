static int _drbd_md_sync_page_io(struct drbd_conf *mdev,\r\nstruct drbd_backing_dev *bdev,\r\nstruct page *page, sector_t sector,\r\nint rw, int size)\r\n{\r\nstruct bio *bio;\r\nstruct drbd_md_io md_io;\r\nint ok;\r\nmd_io.mdev = mdev;\r\ninit_completion(&md_io.event);\r\nmd_io.error = 0;\r\nif ((rw & WRITE) && !test_bit(MD_NO_FUA, &mdev->flags))\r\nrw |= REQ_FUA | REQ_FLUSH;\r\nrw |= REQ_SYNC;\r\nbio = bio_alloc(GFP_NOIO, 1);\r\nbio->bi_bdev = bdev->md_bdev;\r\nbio->bi_sector = sector;\r\nok = (bio_add_page(bio, page, size, 0) == size);\r\nif (!ok)\r\ngoto out;\r\nbio->bi_private = &md_io;\r\nbio->bi_end_io = drbd_md_io_complete;\r\nbio->bi_rw = rw;\r\nif (drbd_insert_fault(mdev, (rw & WRITE) ? DRBD_FAULT_MD_WR : DRBD_FAULT_MD_RD))\r\nbio_endio(bio, -EIO);\r\nelse\r\nsubmit_bio(rw, bio);\r\nwait_for_completion(&md_io.event);\r\nok = bio_flagged(bio, BIO_UPTODATE) && md_io.error == 0;\r\nout:\r\nbio_put(bio);\r\nreturn ok;\r\n}\r\nint drbd_md_sync_page_io(struct drbd_conf *mdev, struct drbd_backing_dev *bdev,\r\nsector_t sector, int rw)\r\n{\r\nint logical_block_size, mask, ok;\r\nint offset = 0;\r\nstruct page *iop = mdev->md_io_page;\r\nD_ASSERT(mutex_is_locked(&mdev->md_io_mutex));\r\nBUG_ON(!bdev->md_bdev);\r\nlogical_block_size = bdev_logical_block_size(bdev->md_bdev);\r\nif (logical_block_size == 0)\r\nlogical_block_size = MD_SECTOR_SIZE;\r\nif (logical_block_size != MD_SECTOR_SIZE) {\r\nmask = (logical_block_size / MD_SECTOR_SIZE) - 1;\r\nD_ASSERT(mask == 1 || mask == 3 || mask == 7);\r\nD_ASSERT(logical_block_size == (mask+1) * MD_SECTOR_SIZE);\r\noffset = sector & mask;\r\nsector = sector & ~mask;\r\niop = mdev->md_io_tmpp;\r\nif (rw & WRITE) {\r\nvoid *p = page_address(mdev->md_io_page);\r\nvoid *hp = page_address(mdev->md_io_tmpp);\r\nok = _drbd_md_sync_page_io(mdev, bdev, iop, sector,\r\nREAD, logical_block_size);\r\nif (unlikely(!ok)) {\r\ndev_err(DEV, "drbd_md_sync_page_io(,%llus,"\r\n"READ [logical_block_size!=512]) failed!\n",\r\n(unsigned long long)sector);\r\nreturn 0;\r\n}\r\nmemcpy(hp + offset*MD_SECTOR_SIZE, p, MD_SECTOR_SIZE);\r\n}\r\n}\r\nif (sector < drbd_md_first_sector(bdev) ||\r\nsector > drbd_md_last_sector(bdev))\r\ndev_alert(DEV, "%s [%d]:%s(,%llus,%s) out of range md access!\n",\r\ncurrent->comm, current->pid, __func__,\r\n(unsigned long long)sector, (rw & WRITE) ? "WRITE" : "READ");\r\nok = _drbd_md_sync_page_io(mdev, bdev, iop, sector, rw, logical_block_size);\r\nif (unlikely(!ok)) {\r\ndev_err(DEV, "drbd_md_sync_page_io(,%llus,%s) failed!\n",\r\n(unsigned long long)sector, (rw & WRITE) ? "WRITE" : "READ");\r\nreturn 0;\r\n}\r\nif (logical_block_size != MD_SECTOR_SIZE && !(rw & WRITE)) {\r\nvoid *p = page_address(mdev->md_io_page);\r\nvoid *hp = page_address(mdev->md_io_tmpp);\r\nmemcpy(p, hp + offset*MD_SECTOR_SIZE, MD_SECTOR_SIZE);\r\n}\r\nreturn ok;\r\n}\r\nstatic struct lc_element *_al_get(struct drbd_conf *mdev, unsigned int enr)\r\n{\r\nstruct lc_element *al_ext;\r\nstruct lc_element *tmp;\r\nunsigned long al_flags = 0;\r\nint wake;\r\nspin_lock_irq(&mdev->al_lock);\r\ntmp = lc_find(mdev->resync, enr/AL_EXT_PER_BM_SECT);\r\nif (unlikely(tmp != NULL)) {\r\nstruct bm_extent *bm_ext = lc_entry(tmp, struct bm_extent, lce);\r\nif (test_bit(BME_NO_WRITES, &bm_ext->flags)) {\r\nwake = !test_and_set_bit(BME_PRIORITY, &bm_ext->flags);\r\nspin_unlock_irq(&mdev->al_lock);\r\nif (wake)\r\nwake_up(&mdev->al_wait);\r\nreturn NULL;\r\n}\r\n}\r\nal_ext = lc_get(mdev->act_log, enr);\r\nal_flags = mdev->act_log->flags;\r\nspin_unlock_irq(&mdev->al_lock);\r\nreturn al_ext;\r\n}\r\nvoid drbd_al_begin_io(struct drbd_conf *mdev, sector_t sector)\r\n{\r\nunsigned int enr = (sector >> (AL_EXTENT_SHIFT-9));\r\nstruct lc_element *al_ext;\r\nstruct update_al_work al_work;\r\nD_ASSERT(atomic_read(&mdev->local_cnt) > 0);\r\nwait_event(mdev->al_wait, (al_ext = _al_get(mdev, enr)));\r\nif (al_ext->lc_number != enr) {\r\ninit_completion(&al_work.event);\r\nal_work.al_ext = al_ext;\r\nal_work.enr = enr;\r\nal_work.old_enr = al_ext->lc_number;\r\nal_work.w.cb = w_al_write_transaction;\r\ndrbd_queue_work_front(&mdev->data.work, &al_work.w);\r\nwait_for_completion(&al_work.event);\r\nmdev->al_writ_cnt++;\r\nspin_lock_irq(&mdev->al_lock);\r\nlc_changed(mdev->act_log, al_ext);\r\nspin_unlock_irq(&mdev->al_lock);\r\nwake_up(&mdev->al_wait);\r\n}\r\n}\r\nvoid drbd_al_complete_io(struct drbd_conf *mdev, sector_t sector)\r\n{\r\nunsigned int enr = (sector >> (AL_EXTENT_SHIFT-9));\r\nstruct lc_element *extent;\r\nunsigned long flags;\r\nspin_lock_irqsave(&mdev->al_lock, flags);\r\nextent = lc_find(mdev->act_log, enr);\r\nif (!extent) {\r\nspin_unlock_irqrestore(&mdev->al_lock, flags);\r\ndev_err(DEV, "al_complete_io() called on inactive extent %u\n", enr);\r\nreturn;\r\n}\r\nif (lc_put(mdev->act_log, extent) == 0)\r\nwake_up(&mdev->al_wait);\r\nspin_unlock_irqrestore(&mdev->al_lock, flags);\r\n}\r\nstatic unsigned int al_extent_to_bm_page(unsigned int al_enr)\r\n{\r\nreturn al_enr >>\r\n((PAGE_SHIFT + 3) -\r\n(AL_EXTENT_SHIFT - BM_BLOCK_SHIFT));\r\n}\r\nstatic unsigned int rs_extent_to_bm_page(unsigned int rs_enr)\r\n{\r\nreturn rs_enr >>\r\n((PAGE_SHIFT + 3) -\r\n(BM_EXT_SHIFT - BM_BLOCK_SHIFT));\r\n}\r\nint\r\nw_al_write_transaction(struct drbd_conf *mdev, struct drbd_work *w, int unused)\r\n{\r\nstruct update_al_work *aw = container_of(w, struct update_al_work, w);\r\nstruct lc_element *updated = aw->al_ext;\r\nconst unsigned int new_enr = aw->enr;\r\nconst unsigned int evicted = aw->old_enr;\r\nstruct al_transaction *buffer;\r\nsector_t sector;\r\nint i, n, mx;\r\nunsigned int extent_nr;\r\nu32 xor_sum = 0;\r\nif (!get_ldev(mdev)) {\r\ndev_err(DEV,\r\n"disk is %s, cannot start al transaction (-%d +%d)\n",\r\ndrbd_disk_str(mdev->state.disk), evicted, new_enr);\r\ncomplete(&((struct update_al_work *)w)->event);\r\nreturn 1;\r\n}\r\nif (mdev->state.conn < C_CONNECTED && evicted != LC_FREE)\r\ndrbd_bm_write_page(mdev, al_extent_to_bm_page(evicted));\r\nif (mdev->state.disk < D_INCONSISTENT) {\r\ndev_err(DEV,\r\n"disk is %s, cannot write al transaction (-%d +%d)\n",\r\ndrbd_disk_str(mdev->state.disk), evicted, new_enr);\r\ncomplete(&((struct update_al_work *)w)->event);\r\nput_ldev(mdev);\r\nreturn 1;\r\n}\r\nmutex_lock(&mdev->md_io_mutex);\r\nbuffer = (struct al_transaction *)page_address(mdev->md_io_page);\r\nbuffer->magic = __constant_cpu_to_be32(DRBD_MAGIC);\r\nbuffer->tr_number = cpu_to_be32(mdev->al_tr_number);\r\nn = lc_index_of(mdev->act_log, updated);\r\nbuffer->updates[0].pos = cpu_to_be32(n);\r\nbuffer->updates[0].extent = cpu_to_be32(new_enr);\r\nxor_sum ^= new_enr;\r\nmx = min_t(int, AL_EXTENTS_PT,\r\nmdev->act_log->nr_elements - mdev->al_tr_cycle);\r\nfor (i = 0; i < mx; i++) {\r\nunsigned idx = mdev->al_tr_cycle + i;\r\nextent_nr = lc_element_by_index(mdev->act_log, idx)->lc_number;\r\nbuffer->updates[i+1].pos = cpu_to_be32(idx);\r\nbuffer->updates[i+1].extent = cpu_to_be32(extent_nr);\r\nxor_sum ^= extent_nr;\r\n}\r\nfor (; i < AL_EXTENTS_PT; i++) {\r\nbuffer->updates[i+1].pos = __constant_cpu_to_be32(-1);\r\nbuffer->updates[i+1].extent = __constant_cpu_to_be32(LC_FREE);\r\nxor_sum ^= LC_FREE;\r\n}\r\nmdev->al_tr_cycle += AL_EXTENTS_PT;\r\nif (mdev->al_tr_cycle >= mdev->act_log->nr_elements)\r\nmdev->al_tr_cycle = 0;\r\nbuffer->xor_sum = cpu_to_be32(xor_sum);\r\nsector = mdev->ldev->md.md_offset\r\n+ mdev->ldev->md.al_offset + mdev->al_tr_pos;\r\nif (!drbd_md_sync_page_io(mdev, mdev->ldev, sector, WRITE))\r\ndrbd_chk_io_error(mdev, 1, true);\r\nif (++mdev->al_tr_pos >\r\ndiv_ceil(mdev->act_log->nr_elements, AL_EXTENTS_PT))\r\nmdev->al_tr_pos = 0;\r\nD_ASSERT(mdev->al_tr_pos < MD_AL_MAX_SIZE);\r\nmdev->al_tr_number++;\r\nmutex_unlock(&mdev->md_io_mutex);\r\ncomplete(&((struct update_al_work *)w)->event);\r\nput_ldev(mdev);\r\nreturn 1;\r\n}\r\nstatic int drbd_al_read_tr(struct drbd_conf *mdev,\r\nstruct drbd_backing_dev *bdev,\r\nstruct al_transaction *b,\r\nint index)\r\n{\r\nsector_t sector;\r\nint rv, i;\r\nu32 xor_sum = 0;\r\nsector = bdev->md.md_offset + bdev->md.al_offset + index;\r\nif (!drbd_md_sync_page_io(mdev, bdev, sector, READ))\r\nreturn -1;\r\nrv = (be32_to_cpu(b->magic) == DRBD_MAGIC);\r\nfor (i = 0; i < AL_EXTENTS_PT + 1; i++)\r\nxor_sum ^= be32_to_cpu(b->updates[i].extent);\r\nrv &= (xor_sum == be32_to_cpu(b->xor_sum));\r\nreturn rv;\r\n}\r\nint drbd_al_read_log(struct drbd_conf *mdev, struct drbd_backing_dev *bdev)\r\n{\r\nstruct al_transaction *buffer;\r\nint i;\r\nint rv;\r\nint mx;\r\nint active_extents = 0;\r\nint transactions = 0;\r\nint found_valid = 0;\r\nint from = 0;\r\nint to = 0;\r\nu32 from_tnr = 0;\r\nu32 to_tnr = 0;\r\nu32 cnr;\r\nmx = div_ceil(mdev->act_log->nr_elements, AL_EXTENTS_PT);\r\nmutex_lock(&mdev->md_io_mutex);\r\nbuffer = page_address(mdev->md_io_page);\r\nfor (i = 0; i <= mx; i++) {\r\nrv = drbd_al_read_tr(mdev, bdev, buffer, i);\r\nif (rv == 0)\r\ncontinue;\r\nif (rv == -1) {\r\nmutex_unlock(&mdev->md_io_mutex);\r\nreturn 0;\r\n}\r\ncnr = be32_to_cpu(buffer->tr_number);\r\nif (++found_valid == 1) {\r\nfrom = i;\r\nto = i;\r\nfrom_tnr = cnr;\r\nto_tnr = cnr;\r\ncontinue;\r\n}\r\nif ((int)cnr - (int)from_tnr < 0) {\r\nD_ASSERT(from_tnr - cnr + i - from == mx+1);\r\nfrom = i;\r\nfrom_tnr = cnr;\r\n}\r\nif ((int)cnr - (int)to_tnr > 0) {\r\nD_ASSERT(cnr - to_tnr == i - to);\r\nto = i;\r\nto_tnr = cnr;\r\n}\r\n}\r\nif (!found_valid) {\r\ndev_warn(DEV, "No usable activity log found.\n");\r\nmutex_unlock(&mdev->md_io_mutex);\r\nreturn 1;\r\n}\r\ni = from;\r\nwhile (1) {\r\nint j, pos;\r\nunsigned int extent_nr;\r\nunsigned int trn;\r\nrv = drbd_al_read_tr(mdev, bdev, buffer, i);\r\nERR_IF(rv == 0) goto cancel;\r\nif (rv == -1) {\r\nmutex_unlock(&mdev->md_io_mutex);\r\nreturn 0;\r\n}\r\ntrn = be32_to_cpu(buffer->tr_number);\r\nspin_lock_irq(&mdev->al_lock);\r\nfor (j = AL_EXTENTS_PT; j >= 0; j--) {\r\npos = be32_to_cpu(buffer->updates[j].pos);\r\nextent_nr = be32_to_cpu(buffer->updates[j].extent);\r\nif (extent_nr == LC_FREE)\r\ncontinue;\r\nlc_set(mdev->act_log, extent_nr, pos);\r\nactive_extents++;\r\n}\r\nspin_unlock_irq(&mdev->al_lock);\r\ntransactions++;\r\ncancel:\r\nif (i == to)\r\nbreak;\r\ni++;\r\nif (i > mx)\r\ni = 0;\r\n}\r\nmdev->al_tr_number = to_tnr+1;\r\nmdev->al_tr_pos = to;\r\nif (++mdev->al_tr_pos >\r\ndiv_ceil(mdev->act_log->nr_elements, AL_EXTENTS_PT))\r\nmdev->al_tr_pos = 0;\r\nmutex_unlock(&mdev->md_io_mutex);\r\ndev_info(DEV, "Found %d transactions (%d active extents) in activity log.\n",\r\ntransactions, active_extents);\r\nreturn 1;\r\n}\r\nvoid drbd_al_apply_to_bm(struct drbd_conf *mdev)\r\n{\r\nunsigned int enr;\r\nunsigned long add = 0;\r\nchar ppb[10];\r\nint i, tmp;\r\nwait_event(mdev->al_wait, lc_try_lock(mdev->act_log));\r\nfor (i = 0; i < mdev->act_log->nr_elements; i++) {\r\nenr = lc_element_by_index(mdev->act_log, i)->lc_number;\r\nif (enr == LC_FREE)\r\ncontinue;\r\ntmp = drbd_bm_ALe_set_all(mdev, enr);\r\ndynamic_dev_dbg(DEV, "AL: set %d bits in extent %u\n", tmp, enr);\r\nadd += tmp;\r\n}\r\nlc_unlock(mdev->act_log);\r\nwake_up(&mdev->al_wait);\r\ndev_info(DEV, "Marked additional %s as out-of-sync based on AL.\n",\r\nppsize(ppb, Bit2KB(add)));\r\n}\r\nstatic int _try_lc_del(struct drbd_conf *mdev, struct lc_element *al_ext)\r\n{\r\nint rv;\r\nspin_lock_irq(&mdev->al_lock);\r\nrv = (al_ext->refcnt == 0);\r\nif (likely(rv))\r\nlc_del(mdev->act_log, al_ext);\r\nspin_unlock_irq(&mdev->al_lock);\r\nreturn rv;\r\n}\r\nvoid drbd_al_shrink(struct drbd_conf *mdev)\r\n{\r\nstruct lc_element *al_ext;\r\nint i;\r\nD_ASSERT(test_bit(__LC_DIRTY, &mdev->act_log->flags));\r\nfor (i = 0; i < mdev->act_log->nr_elements; i++) {\r\nal_ext = lc_element_by_index(mdev->act_log, i);\r\nif (al_ext->lc_number == LC_FREE)\r\ncontinue;\r\nwait_event(mdev->al_wait, _try_lc_del(mdev, al_ext));\r\n}\r\nwake_up(&mdev->al_wait);\r\n}\r\nstatic int w_update_odbm(struct drbd_conf *mdev, struct drbd_work *w, int unused)\r\n{\r\nstruct update_odbm_work *udw = container_of(w, struct update_odbm_work, w);\r\nif (!get_ldev(mdev)) {\r\nif (__ratelimit(&drbd_ratelimit_state))\r\ndev_warn(DEV, "Can not update on disk bitmap, local IO disabled.\n");\r\nkfree(udw);\r\nreturn 1;\r\n}\r\ndrbd_bm_write_page(mdev, rs_extent_to_bm_page(udw->enr));\r\nput_ldev(mdev);\r\nkfree(udw);\r\nif (drbd_bm_total_weight(mdev) <= mdev->rs_failed) {\r\nswitch (mdev->state.conn) {\r\ncase C_SYNC_SOURCE: case C_SYNC_TARGET:\r\ncase C_PAUSED_SYNC_S: case C_PAUSED_SYNC_T:\r\ndrbd_resync_finished(mdev);\r\ndefault:\r\nbreak;\r\n}\r\n}\r\ndrbd_bcast_sync_progress(mdev);\r\nreturn 1;\r\n}\r\nstatic void drbd_try_clear_on_disk_bm(struct drbd_conf *mdev, sector_t sector,\r\nint count, int success)\r\n{\r\nstruct lc_element *e;\r\nstruct update_odbm_work *udw;\r\nunsigned int enr;\r\nD_ASSERT(atomic_read(&mdev->local_cnt));\r\nenr = BM_SECT_TO_EXT(sector);\r\ne = lc_get(mdev->resync, enr);\r\nif (e) {\r\nstruct bm_extent *ext = lc_entry(e, struct bm_extent, lce);\r\nif (ext->lce.lc_number == enr) {\r\nif (success)\r\next->rs_left -= count;\r\nelse\r\next->rs_failed += count;\r\nif (ext->rs_left < ext->rs_failed) {\r\ndev_err(DEV, "BAD! sector=%llus enr=%u rs_left=%d "\r\n"rs_failed=%d count=%d\n",\r\n(unsigned long long)sector,\r\next->lce.lc_number, ext->rs_left,\r\next->rs_failed, count);\r\ndump_stack();\r\nlc_put(mdev->resync, &ext->lce);\r\ndrbd_force_state(mdev, NS(conn, C_DISCONNECTING));\r\nreturn;\r\n}\r\n} else {\r\nint rs_left = drbd_bm_e_weight(mdev, enr);\r\nif (ext->flags != 0) {\r\ndev_warn(DEV, "changing resync lce: %d[%u;%02lx]"\r\n" -> %d[%u;00]\n",\r\next->lce.lc_number, ext->rs_left,\r\next->flags, enr, rs_left);\r\next->flags = 0;\r\n}\r\nif (ext->rs_failed) {\r\ndev_warn(DEV, "Kicking resync_lru element enr=%u "\r\n"out with rs_failed=%d\n",\r\next->lce.lc_number, ext->rs_failed);\r\n}\r\next->rs_left = rs_left;\r\next->rs_failed = success ? 0 : count;\r\nlc_changed(mdev->resync, &ext->lce);\r\n}\r\nlc_put(mdev->resync, &ext->lce);\r\nif (ext->rs_left == ext->rs_failed) {\r\next->rs_failed = 0;\r\nudw = kmalloc(sizeof(*udw), GFP_ATOMIC);\r\nif (udw) {\r\nudw->enr = ext->lce.lc_number;\r\nudw->w.cb = w_update_odbm;\r\ndrbd_queue_work_front(&mdev->data.work, &udw->w);\r\n} else {\r\ndev_warn(DEV, "Could not kmalloc an udw\n");\r\n}\r\n}\r\n} else {\r\ndev_err(DEV, "lc_get() failed! locked=%d/%d flags=%lu\n",\r\nmdev->resync_locked,\r\nmdev->resync->nr_elements,\r\nmdev->resync->flags);\r\n}\r\n}\r\nvoid drbd_advance_rs_marks(struct drbd_conf *mdev, unsigned long still_to_go)\r\n{\r\nunsigned long now = jiffies;\r\nunsigned long last = mdev->rs_mark_time[mdev->rs_last_mark];\r\nint next = (mdev->rs_last_mark + 1) % DRBD_SYNC_MARKS;\r\nif (time_after_eq(now, last + DRBD_SYNC_MARK_STEP)) {\r\nif (mdev->rs_mark_left[mdev->rs_last_mark] != still_to_go &&\r\nmdev->state.conn != C_PAUSED_SYNC_T &&\r\nmdev->state.conn != C_PAUSED_SYNC_S) {\r\nmdev->rs_mark_time[next] = now;\r\nmdev->rs_mark_left[next] = still_to_go;\r\nmdev->rs_last_mark = next;\r\n}\r\n}\r\n}\r\nvoid __drbd_set_in_sync(struct drbd_conf *mdev, sector_t sector, int size,\r\nconst char *file, const unsigned int line)\r\n{\r\nunsigned long sbnr, ebnr, lbnr;\r\nunsigned long count = 0;\r\nsector_t esector, nr_sectors;\r\nint wake_up = 0;\r\nunsigned long flags;\r\nif (size <= 0 || (size & 0x1ff) != 0 || size > DRBD_MAX_BIO_SIZE) {\r\ndev_err(DEV, "drbd_set_in_sync: sector=%llus size=%d nonsense!\n",\r\n(unsigned long long)sector, size);\r\nreturn;\r\n}\r\nnr_sectors = drbd_get_capacity(mdev->this_bdev);\r\nesector = sector + (size >> 9) - 1;\r\nERR_IF(sector >= nr_sectors) return;\r\nERR_IF(esector >= nr_sectors) esector = (nr_sectors-1);\r\nlbnr = BM_SECT_TO_BIT(nr_sectors-1);\r\nif (unlikely(esector < BM_SECT_PER_BIT-1))\r\nreturn;\r\nif (unlikely(esector == (nr_sectors-1)))\r\nebnr = lbnr;\r\nelse\r\nebnr = BM_SECT_TO_BIT(esector - (BM_SECT_PER_BIT-1));\r\nsbnr = BM_SECT_TO_BIT(sector + BM_SECT_PER_BIT-1);\r\nif (sbnr > ebnr)\r\nreturn;\r\ncount = drbd_bm_clear_bits(mdev, sbnr, ebnr);\r\nif (count && get_ldev(mdev)) {\r\ndrbd_advance_rs_marks(mdev, drbd_bm_total_weight(mdev));\r\nspin_lock_irqsave(&mdev->al_lock, flags);\r\ndrbd_try_clear_on_disk_bm(mdev, sector, count, true);\r\nspin_unlock_irqrestore(&mdev->al_lock, flags);\r\nwake_up = 1;\r\nput_ldev(mdev);\r\n}\r\nif (wake_up)\r\nwake_up(&mdev->al_wait);\r\n}\r\nint __drbd_set_out_of_sync(struct drbd_conf *mdev, sector_t sector, int size,\r\nconst char *file, const unsigned int line)\r\n{\r\nunsigned long sbnr, ebnr, lbnr, flags;\r\nsector_t esector, nr_sectors;\r\nunsigned int enr, count = 0;\r\nstruct lc_element *e;\r\nif (size <= 0 || (size & 0x1ff) != 0 || size > DRBD_MAX_BIO_SIZE) {\r\ndev_err(DEV, "sector: %llus, size: %d\n",\r\n(unsigned long long)sector, size);\r\nreturn 0;\r\n}\r\nif (!get_ldev(mdev))\r\nreturn 0;\r\nnr_sectors = drbd_get_capacity(mdev->this_bdev);\r\nesector = sector + (size >> 9) - 1;\r\nERR_IF(sector >= nr_sectors)\r\ngoto out;\r\nERR_IF(esector >= nr_sectors)\r\nesector = (nr_sectors-1);\r\nlbnr = BM_SECT_TO_BIT(nr_sectors-1);\r\nsbnr = BM_SECT_TO_BIT(sector);\r\nebnr = BM_SECT_TO_BIT(esector);\r\nspin_lock_irqsave(&mdev->al_lock, flags);\r\ncount = drbd_bm_set_bits(mdev, sbnr, ebnr);\r\nenr = BM_SECT_TO_EXT(sector);\r\ne = lc_find(mdev->resync, enr);\r\nif (e)\r\nlc_entry(e, struct bm_extent, lce)->rs_left += count;\r\nspin_unlock_irqrestore(&mdev->al_lock, flags);\r\nout:\r\nput_ldev(mdev);\r\nreturn count;\r\n}\r\nstatic\r\nstruct bm_extent *_bme_get(struct drbd_conf *mdev, unsigned int enr)\r\n{\r\nstruct lc_element *e;\r\nstruct bm_extent *bm_ext;\r\nint wakeup = 0;\r\nunsigned long rs_flags;\r\nspin_lock_irq(&mdev->al_lock);\r\nif (mdev->resync_locked > mdev->resync->nr_elements/2) {\r\nspin_unlock_irq(&mdev->al_lock);\r\nreturn NULL;\r\n}\r\ne = lc_get(mdev->resync, enr);\r\nbm_ext = e ? lc_entry(e, struct bm_extent, lce) : NULL;\r\nif (bm_ext) {\r\nif (bm_ext->lce.lc_number != enr) {\r\nbm_ext->rs_left = drbd_bm_e_weight(mdev, enr);\r\nbm_ext->rs_failed = 0;\r\nlc_changed(mdev->resync, &bm_ext->lce);\r\nwakeup = 1;\r\n}\r\nif (bm_ext->lce.refcnt == 1)\r\nmdev->resync_locked++;\r\nset_bit(BME_NO_WRITES, &bm_ext->flags);\r\n}\r\nrs_flags = mdev->resync->flags;\r\nspin_unlock_irq(&mdev->al_lock);\r\nif (wakeup)\r\nwake_up(&mdev->al_wait);\r\nif (!bm_ext) {\r\nif (rs_flags & LC_STARVING)\r\ndev_warn(DEV, "Have to wait for element"\r\n" (resync LRU too small?)\n");\r\nBUG_ON(rs_flags & LC_DIRTY);\r\n}\r\nreturn bm_ext;\r\n}\r\nstatic int _is_in_al(struct drbd_conf *mdev, unsigned int enr)\r\n{\r\nstruct lc_element *al_ext;\r\nint rv = 0;\r\nspin_lock_irq(&mdev->al_lock);\r\nif (unlikely(enr == mdev->act_log->new_number))\r\nrv = 1;\r\nelse {\r\nal_ext = lc_find(mdev->act_log, enr);\r\nif (al_ext) {\r\nif (al_ext->refcnt)\r\nrv = 1;\r\n}\r\n}\r\nspin_unlock_irq(&mdev->al_lock);\r\nreturn rv;\r\n}\r\nint drbd_rs_begin_io(struct drbd_conf *mdev, sector_t sector)\r\n{\r\nunsigned int enr = BM_SECT_TO_EXT(sector);\r\nstruct bm_extent *bm_ext;\r\nint i, sig;\r\nint sa = 200;\r\nretry:\r\nsig = wait_event_interruptible(mdev->al_wait,\r\n(bm_ext = _bme_get(mdev, enr)));\r\nif (sig)\r\nreturn -EINTR;\r\nif (test_bit(BME_LOCKED, &bm_ext->flags))\r\nreturn 0;\r\nfor (i = 0; i < AL_EXT_PER_BM_SECT; i++) {\r\nsig = wait_event_interruptible(mdev->al_wait,\r\n!_is_in_al(mdev, enr * AL_EXT_PER_BM_SECT + i) ||\r\ntest_bit(BME_PRIORITY, &bm_ext->flags));\r\nif (sig || (test_bit(BME_PRIORITY, &bm_ext->flags) && sa)) {\r\nspin_lock_irq(&mdev->al_lock);\r\nif (lc_put(mdev->resync, &bm_ext->lce) == 0) {\r\nbm_ext->flags = 0;\r\nmdev->resync_locked--;\r\nwake_up(&mdev->al_wait);\r\n}\r\nspin_unlock_irq(&mdev->al_lock);\r\nif (sig)\r\nreturn -EINTR;\r\nif (schedule_timeout_interruptible(HZ/10))\r\nreturn -EINTR;\r\nif (sa && --sa == 0)\r\ndev_warn(DEV,"drbd_rs_begin_io() stepped aside for 20sec."\r\n"Resync stalled?\n");\r\ngoto retry;\r\n}\r\n}\r\nset_bit(BME_LOCKED, &bm_ext->flags);\r\nreturn 0;\r\n}\r\nint drbd_try_rs_begin_io(struct drbd_conf *mdev, sector_t sector)\r\n{\r\nunsigned int enr = BM_SECT_TO_EXT(sector);\r\nconst unsigned int al_enr = enr*AL_EXT_PER_BM_SECT;\r\nstruct lc_element *e;\r\nstruct bm_extent *bm_ext;\r\nint i;\r\nspin_lock_irq(&mdev->al_lock);\r\nif (mdev->resync_wenr != LC_FREE && mdev->resync_wenr != enr) {\r\ne = lc_find(mdev->resync, mdev->resync_wenr);\r\nbm_ext = e ? lc_entry(e, struct bm_extent, lce) : NULL;\r\nif (bm_ext) {\r\nD_ASSERT(!test_bit(BME_LOCKED, &bm_ext->flags));\r\nD_ASSERT(test_bit(BME_NO_WRITES, &bm_ext->flags));\r\nclear_bit(BME_NO_WRITES, &bm_ext->flags);\r\nmdev->resync_wenr = LC_FREE;\r\nif (lc_put(mdev->resync, &bm_ext->lce) == 0)\r\nmdev->resync_locked--;\r\nwake_up(&mdev->al_wait);\r\n} else {\r\ndev_alert(DEV, "LOGIC BUG\n");\r\n}\r\n}\r\ne = lc_try_get(mdev->resync, enr);\r\nbm_ext = e ? lc_entry(e, struct bm_extent, lce) : NULL;\r\nif (bm_ext) {\r\nif (test_bit(BME_LOCKED, &bm_ext->flags))\r\ngoto proceed;\r\nif (!test_and_set_bit(BME_NO_WRITES, &bm_ext->flags)) {\r\nmdev->resync_locked++;\r\n} else {\r\nbm_ext->lce.refcnt--;\r\nD_ASSERT(bm_ext->lce.refcnt > 0);\r\n}\r\ngoto check_al;\r\n} else {\r\nif (mdev->resync_locked > mdev->resync->nr_elements-3)\r\ngoto try_again;\r\ne = lc_get(mdev->resync, enr);\r\nbm_ext = e ? lc_entry(e, struct bm_extent, lce) : NULL;\r\nif (!bm_ext) {\r\nconst unsigned long rs_flags = mdev->resync->flags;\r\nif (rs_flags & LC_STARVING)\r\ndev_warn(DEV, "Have to wait for element"\r\n" (resync LRU too small?)\n");\r\nBUG_ON(rs_flags & LC_DIRTY);\r\ngoto try_again;\r\n}\r\nif (bm_ext->lce.lc_number != enr) {\r\nbm_ext->rs_left = drbd_bm_e_weight(mdev, enr);\r\nbm_ext->rs_failed = 0;\r\nlc_changed(mdev->resync, &bm_ext->lce);\r\nwake_up(&mdev->al_wait);\r\nD_ASSERT(test_bit(BME_LOCKED, &bm_ext->flags) == 0);\r\n}\r\nset_bit(BME_NO_WRITES, &bm_ext->flags);\r\nD_ASSERT(bm_ext->lce.refcnt == 1);\r\nmdev->resync_locked++;\r\ngoto check_al;\r\n}\r\ncheck_al:\r\nfor (i = 0; i < AL_EXT_PER_BM_SECT; i++) {\r\nif (unlikely(al_enr+i == mdev->act_log->new_number))\r\ngoto try_again;\r\nif (lc_is_used(mdev->act_log, al_enr+i))\r\ngoto try_again;\r\n}\r\nset_bit(BME_LOCKED, &bm_ext->flags);\r\nproceed:\r\nmdev->resync_wenr = LC_FREE;\r\nspin_unlock_irq(&mdev->al_lock);\r\nreturn 0;\r\ntry_again:\r\nif (bm_ext)\r\nmdev->resync_wenr = enr;\r\nspin_unlock_irq(&mdev->al_lock);\r\nreturn -EAGAIN;\r\n}\r\nvoid drbd_rs_complete_io(struct drbd_conf *mdev, sector_t sector)\r\n{\r\nunsigned int enr = BM_SECT_TO_EXT(sector);\r\nstruct lc_element *e;\r\nstruct bm_extent *bm_ext;\r\nunsigned long flags;\r\nspin_lock_irqsave(&mdev->al_lock, flags);\r\ne = lc_find(mdev->resync, enr);\r\nbm_ext = e ? lc_entry(e, struct bm_extent, lce) : NULL;\r\nif (!bm_ext) {\r\nspin_unlock_irqrestore(&mdev->al_lock, flags);\r\nif (__ratelimit(&drbd_ratelimit_state))\r\ndev_err(DEV, "drbd_rs_complete_io() called, but extent not found\n");\r\nreturn;\r\n}\r\nif (bm_ext->lce.refcnt == 0) {\r\nspin_unlock_irqrestore(&mdev->al_lock, flags);\r\ndev_err(DEV, "drbd_rs_complete_io(,%llu [=%u]) called, "\r\n"but refcnt is 0!?\n",\r\n(unsigned long long)sector, enr);\r\nreturn;\r\n}\r\nif (lc_put(mdev->resync, &bm_ext->lce) == 0) {\r\nbm_ext->flags = 0;\r\nmdev->resync_locked--;\r\nwake_up(&mdev->al_wait);\r\n}\r\nspin_unlock_irqrestore(&mdev->al_lock, flags);\r\n}\r\nvoid drbd_rs_cancel_all(struct drbd_conf *mdev)\r\n{\r\nspin_lock_irq(&mdev->al_lock);\r\nif (get_ldev_if_state(mdev, D_FAILED)) {\r\nlc_reset(mdev->resync);\r\nput_ldev(mdev);\r\n}\r\nmdev->resync_locked = 0;\r\nmdev->resync_wenr = LC_FREE;\r\nspin_unlock_irq(&mdev->al_lock);\r\nwake_up(&mdev->al_wait);\r\n}\r\nint drbd_rs_del_all(struct drbd_conf *mdev)\r\n{\r\nstruct lc_element *e;\r\nstruct bm_extent *bm_ext;\r\nint i;\r\nspin_lock_irq(&mdev->al_lock);\r\nif (get_ldev_if_state(mdev, D_FAILED)) {\r\nfor (i = 0; i < mdev->resync->nr_elements; i++) {\r\ne = lc_element_by_index(mdev->resync, i);\r\nbm_ext = lc_entry(e, struct bm_extent, lce);\r\nif (bm_ext->lce.lc_number == LC_FREE)\r\ncontinue;\r\nif (bm_ext->lce.lc_number == mdev->resync_wenr) {\r\ndev_info(DEV, "dropping %u in drbd_rs_del_all, apparently"\r\n" got 'synced' by application io\n",\r\nmdev->resync_wenr);\r\nD_ASSERT(!test_bit(BME_LOCKED, &bm_ext->flags));\r\nD_ASSERT(test_bit(BME_NO_WRITES, &bm_ext->flags));\r\nclear_bit(BME_NO_WRITES, &bm_ext->flags);\r\nmdev->resync_wenr = LC_FREE;\r\nlc_put(mdev->resync, &bm_ext->lce);\r\n}\r\nif (bm_ext->lce.refcnt != 0) {\r\ndev_info(DEV, "Retrying drbd_rs_del_all() later. "\r\n"refcnt=%d\n", bm_ext->lce.refcnt);\r\nput_ldev(mdev);\r\nspin_unlock_irq(&mdev->al_lock);\r\nreturn -EAGAIN;\r\n}\r\nD_ASSERT(!test_bit(BME_LOCKED, &bm_ext->flags));\r\nD_ASSERT(!test_bit(BME_NO_WRITES, &bm_ext->flags));\r\nlc_del(mdev->resync, &bm_ext->lce);\r\n}\r\nD_ASSERT(mdev->resync->used == 0);\r\nput_ldev(mdev);\r\n}\r\nspin_unlock_irq(&mdev->al_lock);\r\nreturn 0;\r\n}\r\nvoid drbd_rs_failed_io(struct drbd_conf *mdev, sector_t sector, int size)\r\n{\r\nunsigned long sbnr, ebnr, lbnr;\r\nunsigned long count;\r\nsector_t esector, nr_sectors;\r\nint wake_up = 0;\r\nif (size <= 0 || (size & 0x1ff) != 0 || size > DRBD_MAX_BIO_SIZE) {\r\ndev_err(DEV, "drbd_rs_failed_io: sector=%llus size=%d nonsense!\n",\r\n(unsigned long long)sector, size);\r\nreturn;\r\n}\r\nnr_sectors = drbd_get_capacity(mdev->this_bdev);\r\nesector = sector + (size >> 9) - 1;\r\nERR_IF(sector >= nr_sectors) return;\r\nERR_IF(esector >= nr_sectors) esector = (nr_sectors-1);\r\nlbnr = BM_SECT_TO_BIT(nr_sectors-1);\r\nif (unlikely(esector < BM_SECT_PER_BIT-1))\r\nreturn;\r\nif (unlikely(esector == (nr_sectors-1)))\r\nebnr = lbnr;\r\nelse\r\nebnr = BM_SECT_TO_BIT(esector - (BM_SECT_PER_BIT-1));\r\nsbnr = BM_SECT_TO_BIT(sector + BM_SECT_PER_BIT-1);\r\nif (sbnr > ebnr)\r\nreturn;\r\nspin_lock_irq(&mdev->al_lock);\r\ncount = drbd_bm_count_bits(mdev, sbnr, ebnr);\r\nif (count) {\r\nmdev->rs_failed += count;\r\nif (get_ldev(mdev)) {\r\ndrbd_try_clear_on_disk_bm(mdev, sector, count, false);\r\nput_ldev(mdev);\r\n}\r\nwake_up = 1;\r\n}\r\nspin_unlock_irq(&mdev->al_lock);\r\nif (wake_up)\r\nwake_up(&mdev->al_wait);\r\n}
