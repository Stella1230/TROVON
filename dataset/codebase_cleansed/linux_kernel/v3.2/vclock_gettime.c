notrace static cycle_t vread_tsc(void)\r\n{\r\ncycle_t ret;\r\nu64 last;\r\nrdtsc_barrier();\r\nret = (cycle_t)vget_cycles();\r\nlast = VVAR(vsyscall_gtod_data).clock.cycle_last;\r\nif (likely(ret >= last))\r\nreturn ret;\r\nasm volatile ("");\r\nreturn last;\r\n}\r\nstatic notrace cycle_t vread_hpet(void)\r\n{\r\nreturn readl((const void __iomem *)fix_to_virt(VSYSCALL_HPET) + 0xf0);\r\n}\r\nnotrace static long vdso_fallback_gettime(long clock, struct timespec *ts)\r\n{\r\nlong ret;\r\nasm("syscall" : "=a" (ret) :\r\n"0" (__NR_clock_gettime),"D" (clock), "S" (ts) : "memory");\r\nreturn ret;\r\n}\r\nnotrace static inline long vgetns(void)\r\n{\r\nlong v;\r\ncycles_t cycles;\r\nif (gtod->clock.vclock_mode == VCLOCK_TSC)\r\ncycles = vread_tsc();\r\nelse\r\ncycles = vread_hpet();\r\nv = (cycles - gtod->clock.cycle_last) & gtod->clock.mask;\r\nreturn (v * gtod->clock.mult) >> gtod->clock.shift;\r\n}\r\nnotrace static noinline int do_realtime(struct timespec *ts)\r\n{\r\nunsigned long seq, ns;\r\ndo {\r\nseq = read_seqbegin(&gtod->lock);\r\nts->tv_sec = gtod->wall_time_sec;\r\nts->tv_nsec = gtod->wall_time_nsec;\r\nns = vgetns();\r\n} while (unlikely(read_seqretry(&gtod->lock, seq)));\r\ntimespec_add_ns(ts, ns);\r\nreturn 0;\r\n}\r\nnotrace static noinline int do_monotonic(struct timespec *ts)\r\n{\r\nunsigned long seq, ns, secs;\r\ndo {\r\nseq = read_seqbegin(&gtod->lock);\r\nsecs = gtod->wall_time_sec;\r\nns = gtod->wall_time_nsec + vgetns();\r\nsecs += gtod->wall_to_monotonic.tv_sec;\r\nns += gtod->wall_to_monotonic.tv_nsec;\r\n} while (unlikely(read_seqretry(&gtod->lock, seq)));\r\nwhile (ns >= NSEC_PER_SEC) {\r\nns -= NSEC_PER_SEC;\r\n++secs;\r\n}\r\nts->tv_sec = secs;\r\nts->tv_nsec = ns;\r\nreturn 0;\r\n}\r\nnotrace static noinline int do_realtime_coarse(struct timespec *ts)\r\n{\r\nunsigned long seq;\r\ndo {\r\nseq = read_seqbegin(&gtod->lock);\r\nts->tv_sec = gtod->wall_time_coarse.tv_sec;\r\nts->tv_nsec = gtod->wall_time_coarse.tv_nsec;\r\n} while (unlikely(read_seqretry(&gtod->lock, seq)));\r\nreturn 0;\r\n}\r\nnotrace static noinline int do_monotonic_coarse(struct timespec *ts)\r\n{\r\nunsigned long seq, ns, secs;\r\ndo {\r\nseq = read_seqbegin(&gtod->lock);\r\nsecs = gtod->wall_time_coarse.tv_sec;\r\nns = gtod->wall_time_coarse.tv_nsec;\r\nsecs += gtod->wall_to_monotonic.tv_sec;\r\nns += gtod->wall_to_monotonic.tv_nsec;\r\n} while (unlikely(read_seqretry(&gtod->lock, seq)));\r\nif (ns >= NSEC_PER_SEC) {\r\nns -= NSEC_PER_SEC;\r\n++secs;\r\n}\r\nts->tv_sec = secs;\r\nts->tv_nsec = ns;\r\nreturn 0;\r\n}\r\nnotrace int __vdso_clock_gettime(clockid_t clock, struct timespec *ts)\r\n{\r\nswitch (clock) {\r\ncase CLOCK_REALTIME:\r\nif (likely(gtod->clock.vclock_mode != VCLOCK_NONE))\r\nreturn do_realtime(ts);\r\nbreak;\r\ncase CLOCK_MONOTONIC:\r\nif (likely(gtod->clock.vclock_mode != VCLOCK_NONE))\r\nreturn do_monotonic(ts);\r\nbreak;\r\ncase CLOCK_REALTIME_COARSE:\r\nreturn do_realtime_coarse(ts);\r\ncase CLOCK_MONOTONIC_COARSE:\r\nreturn do_monotonic_coarse(ts);\r\n}\r\nreturn vdso_fallback_gettime(clock, ts);\r\n}\r\nnotrace int __vdso_gettimeofday(struct timeval *tv, struct timezone *tz)\r\n{\r\nlong ret;\r\nif (likely(gtod->clock.vclock_mode != VCLOCK_NONE)) {\r\nif (likely(tv != NULL)) {\r\nBUILD_BUG_ON(offsetof(struct timeval, tv_usec) !=\r\noffsetof(struct timespec, tv_nsec) ||\r\nsizeof(*tv) != sizeof(struct timespec));\r\ndo_realtime((struct timespec *)tv);\r\ntv->tv_usec /= 1000;\r\n}\r\nif (unlikely(tz != NULL)) {\r\ntz->tz_minuteswest = gtod->sys_tz.tz_minuteswest;\r\ntz->tz_dsttime = gtod->sys_tz.tz_dsttime;\r\n}\r\nreturn 0;\r\n}\r\nasm("syscall" : "=a" (ret) :\r\n"0" (__NR_gettimeofday), "D" (tv), "S" (tz) : "memory");\r\nreturn ret;\r\n}\r\nnotrace time_t __vdso_time(time_t *t)\r\n{\r\ntime_t result = ACCESS_ONCE(VVAR(vsyscall_gtod_data).wall_time_sec);\r\nif (t)\r\n*t = result;\r\nreturn result;\r\n}
