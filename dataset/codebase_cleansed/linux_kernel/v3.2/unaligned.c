static void\r\ndump (const char *str, void *vp, size_t len)\r\n{\r\nunsigned char *cp = vp;\r\nint i;\r\nprintk("%s", str);\r\nfor (i = 0; i < len; ++i)\r\nprintk (" %02x", *cp++);\r\nprintk("\n");\r\n}\r\nstatic void\r\ninvala_gr (int regno)\r\n{\r\n# define F(reg) case reg: ia64_invala_gr(reg); break\r\nswitch (regno) {\r\nF( 0); F( 1); F( 2); F( 3); F( 4); F( 5); F( 6); F( 7);\r\nF( 8); F( 9); F( 10); F( 11); F( 12); F( 13); F( 14); F( 15);\r\nF( 16); F( 17); F( 18); F( 19); F( 20); F( 21); F( 22); F( 23);\r\nF( 24); F( 25); F( 26); F( 27); F( 28); F( 29); F( 30); F( 31);\r\nF( 32); F( 33); F( 34); F( 35); F( 36); F( 37); F( 38); F( 39);\r\nF( 40); F( 41); F( 42); F( 43); F( 44); F( 45); F( 46); F( 47);\r\nF( 48); F( 49); F( 50); F( 51); F( 52); F( 53); F( 54); F( 55);\r\nF( 56); F( 57); F( 58); F( 59); F( 60); F( 61); F( 62); F( 63);\r\nF( 64); F( 65); F( 66); F( 67); F( 68); F( 69); F( 70); F( 71);\r\nF( 72); F( 73); F( 74); F( 75); F( 76); F( 77); F( 78); F( 79);\r\nF( 80); F( 81); F( 82); F( 83); F( 84); F( 85); F( 86); F( 87);\r\nF( 88); F( 89); F( 90); F( 91); F( 92); F( 93); F( 94); F( 95);\r\nF( 96); F( 97); F( 98); F( 99); F(100); F(101); F(102); F(103);\r\nF(104); F(105); F(106); F(107); F(108); F(109); F(110); F(111);\r\nF(112); F(113); F(114); F(115); F(116); F(117); F(118); F(119);\r\nF(120); F(121); F(122); F(123); F(124); F(125); F(126); F(127);\r\n}\r\n# undef F\r\n}\r\nstatic void\r\ninvala_fr (int regno)\r\n{\r\n# define F(reg) case reg: ia64_invala_fr(reg); break\r\nswitch (regno) {\r\nF( 0); F( 1); F( 2); F( 3); F( 4); F( 5); F( 6); F( 7);\r\nF( 8); F( 9); F( 10); F( 11); F( 12); F( 13); F( 14); F( 15);\r\nF( 16); F( 17); F( 18); F( 19); F( 20); F( 21); F( 22); F( 23);\r\nF( 24); F( 25); F( 26); F( 27); F( 28); F( 29); F( 30); F( 31);\r\nF( 32); F( 33); F( 34); F( 35); F( 36); F( 37); F( 38); F( 39);\r\nF( 40); F( 41); F( 42); F( 43); F( 44); F( 45); F( 46); F( 47);\r\nF( 48); F( 49); F( 50); F( 51); F( 52); F( 53); F( 54); F( 55);\r\nF( 56); F( 57); F( 58); F( 59); F( 60); F( 61); F( 62); F( 63);\r\nF( 64); F( 65); F( 66); F( 67); F( 68); F( 69); F( 70); F( 71);\r\nF( 72); F( 73); F( 74); F( 75); F( 76); F( 77); F( 78); F( 79);\r\nF( 80); F( 81); F( 82); F( 83); F( 84); F( 85); F( 86); F( 87);\r\nF( 88); F( 89); F( 90); F( 91); F( 92); F( 93); F( 94); F( 95);\r\nF( 96); F( 97); F( 98); F( 99); F(100); F(101); F(102); F(103);\r\nF(104); F(105); F(106); F(107); F(108); F(109); F(110); F(111);\r\nF(112); F(113); F(114); F(115); F(116); F(117); F(118); F(119);\r\nF(120); F(121); F(122); F(123); F(124); F(125); F(126); F(127);\r\n}\r\n# undef F\r\n}\r\nstatic inline unsigned long\r\nrotate_reg (unsigned long sor, unsigned long rrb, unsigned long reg)\r\n{\r\nreg += rrb;\r\nif (reg >= sor)\r\nreg -= sor;\r\nreturn reg;\r\n}\r\nstatic void\r\nset_rse_reg (struct pt_regs *regs, unsigned long r1, unsigned long val, int nat)\r\n{\r\nstruct switch_stack *sw = (struct switch_stack *) regs - 1;\r\nunsigned long *bsp, *bspstore, *addr, *rnat_addr, *ubs_end;\r\nunsigned long *kbs = (void *) current + IA64_RBS_OFFSET;\r\nunsigned long rnats, nat_mask;\r\nunsigned long on_kbs;\r\nlong sof = (regs->cr_ifs) & 0x7f;\r\nlong sor = 8 * ((regs->cr_ifs >> 14) & 0xf);\r\nlong rrb_gr = (regs->cr_ifs >> 18) & 0x7f;\r\nlong ridx = r1 - 32;\r\nif (ridx >= sof) {\r\nDPRINT("ignoring write to r%lu; only %lu registers are allocated!\n", r1, sof);\r\nreturn;\r\n}\r\nif (ridx < sor)\r\nridx = rotate_reg(sor, rrb_gr, ridx);\r\nDPRINT("r%lu, sw.bspstore=%lx pt.bspstore=%lx sof=%ld sol=%ld ridx=%ld\n",\r\nr1, sw->ar_bspstore, regs->ar_bspstore, sof, (regs->cr_ifs >> 7) & 0x7f, ridx);\r\non_kbs = ia64_rse_num_regs(kbs, (unsigned long *) sw->ar_bspstore);\r\naddr = ia64_rse_skip_regs((unsigned long *) sw->ar_bspstore, -sof + ridx);\r\nif (addr >= kbs) {\r\nrnat_addr = ia64_rse_rnat_addr(addr);\r\nif ((unsigned long) rnat_addr >= sw->ar_bspstore)\r\nrnat_addr = &sw->ar_rnat;\r\nnat_mask = 1UL << ia64_rse_slot_num(addr);\r\n*addr = val;\r\nif (nat)\r\n*rnat_addr |= nat_mask;\r\nelse\r\n*rnat_addr &= ~nat_mask;\r\nreturn;\r\n}\r\nif (!user_stack(current, regs)) {\r\nDPRINT("ignoring kernel write to r%lu; register isn't on the kernel RBS!", r1);\r\nreturn;\r\n}\r\nbspstore = (unsigned long *)regs->ar_bspstore;\r\nubs_end = ia64_rse_skip_regs(bspstore, on_kbs);\r\nbsp = ia64_rse_skip_regs(ubs_end, -sof);\r\naddr = ia64_rse_skip_regs(bsp, ridx);\r\nDPRINT("ubs_end=%p bsp=%p addr=%p\n", (void *) ubs_end, (void *) bsp, (void *) addr);\r\nia64_poke(current, sw, (unsigned long) ubs_end, (unsigned long) addr, val);\r\nrnat_addr = ia64_rse_rnat_addr(addr);\r\nia64_peek(current, sw, (unsigned long) ubs_end, (unsigned long) rnat_addr, &rnats);\r\nDPRINT("rnat @%p = 0x%lx nat=%d old nat=%ld\n",\r\n(void *) rnat_addr, rnats, nat, (rnats >> ia64_rse_slot_num(addr)) & 1);\r\nnat_mask = 1UL << ia64_rse_slot_num(addr);\r\nif (nat)\r\nrnats |= nat_mask;\r\nelse\r\nrnats &= ~nat_mask;\r\nia64_poke(current, sw, (unsigned long) ubs_end, (unsigned long) rnat_addr, rnats);\r\nDPRINT("rnat changed to @%p = 0x%lx\n", (void *) rnat_addr, rnats);\r\n}\r\nstatic void\r\nget_rse_reg (struct pt_regs *regs, unsigned long r1, unsigned long *val, int *nat)\r\n{\r\nstruct switch_stack *sw = (struct switch_stack *) regs - 1;\r\nunsigned long *bsp, *addr, *rnat_addr, *ubs_end, *bspstore;\r\nunsigned long *kbs = (void *) current + IA64_RBS_OFFSET;\r\nunsigned long rnats, nat_mask;\r\nunsigned long on_kbs;\r\nlong sof = (regs->cr_ifs) & 0x7f;\r\nlong sor = 8 * ((regs->cr_ifs >> 14) & 0xf);\r\nlong rrb_gr = (regs->cr_ifs >> 18) & 0x7f;\r\nlong ridx = r1 - 32;\r\nif (ridx >= sof) {\r\nDPRINT("ignoring read from r%lu; only %lu registers are allocated!\n", r1, sof);\r\ngoto fail;\r\n}\r\nif (ridx < sor)\r\nridx = rotate_reg(sor, rrb_gr, ridx);\r\nDPRINT("r%lu, sw.bspstore=%lx pt.bspstore=%lx sof=%ld sol=%ld ridx=%ld\n",\r\nr1, sw->ar_bspstore, regs->ar_bspstore, sof, (regs->cr_ifs >> 7) & 0x7f, ridx);\r\non_kbs = ia64_rse_num_regs(kbs, (unsigned long *) sw->ar_bspstore);\r\naddr = ia64_rse_skip_regs((unsigned long *) sw->ar_bspstore, -sof + ridx);\r\nif (addr >= kbs) {\r\n*val = *addr;\r\nif (nat) {\r\nrnat_addr = ia64_rse_rnat_addr(addr);\r\nif ((unsigned long) rnat_addr >= sw->ar_bspstore)\r\nrnat_addr = &sw->ar_rnat;\r\nnat_mask = 1UL << ia64_rse_slot_num(addr);\r\n*nat = (*rnat_addr & nat_mask) != 0;\r\n}\r\nreturn;\r\n}\r\nif (!user_stack(current, regs)) {\r\nDPRINT("ignoring kernel read of r%lu; register isn't on the RBS!", r1);\r\ngoto fail;\r\n}\r\nbspstore = (unsigned long *)regs->ar_bspstore;\r\nubs_end = ia64_rse_skip_regs(bspstore, on_kbs);\r\nbsp = ia64_rse_skip_regs(ubs_end, -sof);\r\naddr = ia64_rse_skip_regs(bsp, ridx);\r\nDPRINT("ubs_end=%p bsp=%p addr=%p\n", (void *) ubs_end, (void *) bsp, (void *) addr);\r\nia64_peek(current, sw, (unsigned long) ubs_end, (unsigned long) addr, val);\r\nif (nat) {\r\nrnat_addr = ia64_rse_rnat_addr(addr);\r\nnat_mask = 1UL << ia64_rse_slot_num(addr);\r\nDPRINT("rnat @%p = 0x%lx\n", (void *) rnat_addr, rnats);\r\nia64_peek(current, sw, (unsigned long) ubs_end, (unsigned long) rnat_addr, &rnats);\r\n*nat = (rnats & nat_mask) != 0;\r\n}\r\nreturn;\r\nfail:\r\n*val = 0;\r\nif (nat)\r\n*nat = 0;\r\nreturn;\r\n}\r\nstatic void\r\nsetreg (unsigned long regnum, unsigned long val, int nat, struct pt_regs *regs)\r\n{\r\nstruct switch_stack *sw = (struct switch_stack *) regs - 1;\r\nunsigned long addr;\r\nunsigned long bitmask;\r\nunsigned long *unat;\r\nif (regnum >= IA64_FIRST_STACKED_GR) {\r\nset_rse_reg(regs, regnum, val, nat);\r\nreturn;\r\n}\r\nif (GR_IN_SW(regnum)) {\r\naddr = (unsigned long)sw;\r\nunat = &sw->ar_unat;\r\n} else {\r\naddr = (unsigned long)regs;\r\nunat = &sw->caller_unat;\r\n}\r\nDPRINT("tmp_base=%lx switch_stack=%s offset=%d\n",\r\naddr, unat==&sw->ar_unat ? "yes":"no", GR_OFFS(regnum));\r\naddr += GR_OFFS(regnum);\r\n*(unsigned long *)addr = val;\r\nbitmask = 1UL << (addr >> 3 & 0x3f);\r\nDPRINT("*0x%lx=0x%lx NaT=%d prev_unat @%p=%lx\n", addr, val, nat, (void *) unat, *unat);\r\nif (nat) {\r\n*unat |= bitmask;\r\n} else {\r\n*unat &= ~bitmask;\r\n}\r\nDPRINT("*0x%lx=0x%lx NaT=%d new unat: %p=%lx\n", addr, val, nat, (void *) unat,*unat);\r\n}\r\nstatic inline unsigned long\r\nfph_index (struct pt_regs *regs, long regnum)\r\n{\r\nunsigned long rrb_fr = (regs->cr_ifs >> 25) & 0x7f;\r\nreturn rotate_reg(96, rrb_fr, (regnum - IA64_FIRST_ROTATING_FR));\r\n}\r\nstatic void\r\nsetfpreg (unsigned long regnum, struct ia64_fpreg *fpval, struct pt_regs *regs)\r\n{\r\nstruct switch_stack *sw = (struct switch_stack *)regs - 1;\r\nunsigned long addr;\r\nif (regnum >= IA64_FIRST_ROTATING_FR) {\r\nia64_sync_fph(current);\r\ncurrent->thread.fph[fph_index(regs, regnum)] = *fpval;\r\n} else {\r\nif (FR_IN_SW(regnum)) {\r\naddr = (unsigned long)sw;\r\n} else {\r\naddr = (unsigned long)regs;\r\n}\r\nDPRINT("tmp_base=%lx offset=%d\n", addr, FR_OFFS(regnum));\r\naddr += FR_OFFS(regnum);\r\n*(struct ia64_fpreg *)addr = *fpval;\r\nregs->cr_ipsr |= IA64_PSR_MFL;\r\n}\r\n}\r\nstatic inline void\r\nfloat_spill_f0 (struct ia64_fpreg *final)\r\n{\r\nia64_stf_spill(final, 0);\r\n}\r\nstatic inline void\r\nfloat_spill_f1 (struct ia64_fpreg *final)\r\n{\r\nia64_stf_spill(final, 1);\r\n}\r\nstatic void\r\ngetfpreg (unsigned long regnum, struct ia64_fpreg *fpval, struct pt_regs *regs)\r\n{\r\nstruct switch_stack *sw = (struct switch_stack *) regs - 1;\r\nunsigned long addr;\r\nif (regnum >= IA64_FIRST_ROTATING_FR) {\r\nia64_flush_fph(current);\r\n*fpval = current->thread.fph[fph_index(regs, regnum)];\r\n} else {\r\nswitch(regnum) {\r\ncase 0:\r\nfloat_spill_f0(fpval);\r\nbreak;\r\ncase 1:\r\nfloat_spill_f1(fpval);\r\nbreak;\r\ndefault:\r\naddr = FR_IN_SW(regnum) ? (unsigned long)sw\r\n: (unsigned long)regs;\r\nDPRINT("is_sw=%d tmp_base=%lx offset=0x%x\n",\r\nFR_IN_SW(regnum), addr, FR_OFFS(regnum));\r\naddr += FR_OFFS(regnum);\r\n*fpval = *(struct ia64_fpreg *)addr;\r\n}\r\n}\r\n}\r\nstatic void\r\ngetreg (unsigned long regnum, unsigned long *val, int *nat, struct pt_regs *regs)\r\n{\r\nstruct switch_stack *sw = (struct switch_stack *) regs - 1;\r\nunsigned long addr, *unat;\r\nif (regnum >= IA64_FIRST_STACKED_GR) {\r\nget_rse_reg(regs, regnum, val, nat);\r\nreturn;\r\n}\r\nif (regnum == 0) {\r\n*val = 0;\r\nif (nat)\r\n*nat = 0;\r\nreturn;\r\n}\r\nif (GR_IN_SW(regnum)) {\r\naddr = (unsigned long)sw;\r\nunat = &sw->ar_unat;\r\n} else {\r\naddr = (unsigned long)regs;\r\nunat = &sw->caller_unat;\r\n}\r\nDPRINT("addr_base=%lx offset=0x%x\n", addr, GR_OFFS(regnum));\r\naddr += GR_OFFS(regnum);\r\n*val = *(unsigned long *)addr;\r\nif (nat)\r\n*nat = (*unat >> (addr >> 3 & 0x3f)) & 0x1UL;\r\n}\r\nstatic void\r\nemulate_load_updates (update_t type, load_store_t ld, struct pt_regs *regs, unsigned long ifa)\r\n{\r\nif (ld.x6_op == 1 || ld.x6_op == 3) {\r\nprintk(KERN_ERR "%s: register update on speculative load, error\n", __func__);\r\nif (die_if_kernel("unaligned reference on speculative load with register update\n",\r\nregs, 30))\r\nreturn;\r\n}\r\nif (type == UPD_IMMEDIATE) {\r\nunsigned long imm;\r\nimm = ld.x << 7 | ld.imm;\r\nif (ld.m) imm |= SIGN_EXT9;\r\nifa += imm;\r\nsetreg(ld.r3, ifa, 0, regs);\r\nDPRINT("ld.x=%d ld.m=%d imm=%ld r3=0x%lx\n", ld.x, ld.m, imm, ifa);\r\n} else if (ld.m) {\r\nunsigned long r2;\r\nint nat_r2;\r\ngetreg(ld.imm, &r2, &nat_r2, regs);\r\nifa += r2;\r\nsetreg(ld.r3, ifa, nat_r2, regs);\r\nDPRINT("imm=%d r2=%ld r3=0x%lx nat_r2=%d\n",ld.imm, r2, ifa, nat_r2);\r\n}\r\n}\r\nstatic int\r\nemulate_load_int (unsigned long ifa, load_store_t ld, struct pt_regs *regs)\r\n{\r\nunsigned int len = 1 << ld.x6_sz;\r\nunsigned long val = 0;\r\nif (len != 2 && len != 4 && len != 8) {\r\nDPRINT("unknown size: x6=%d\n", ld.x6_sz);\r\nreturn -1;\r\n}\r\nif (copy_from_user(&val, (void __user *) ifa, len))\r\nreturn -1;\r\nsetreg(ld.r1, val, 0, regs);\r\nif (ld.op == 0x5 || ld.m)\r\nemulate_load_updates(ld.op == 0x5 ? UPD_IMMEDIATE: UPD_REG, ld, regs, ifa);\r\nif (ld.x6_op == 0x5 || ld.x6_op == 0xa)\r\nmb();\r\nif (ld.x6_op == 0x2)\r\ninvala_gr(ld.r1);\r\nreturn 0;\r\n}\r\nstatic int\r\nemulate_store_int (unsigned long ifa, load_store_t ld, struct pt_regs *regs)\r\n{\r\nunsigned long r2;\r\nunsigned int len = 1 << ld.x6_sz;\r\ngetreg(ld.imm, &r2, NULL, regs);\r\nDPRINT("st%d [%lx]=%lx\n", len, ifa, r2);\r\nif (len != 2 && len != 4 && len != 8) {\r\nDPRINT("unknown size: x6=%d\n", ld.x6_sz);\r\nreturn -1;\r\n}\r\nif (copy_to_user((void __user *) ifa, &r2, len))\r\nreturn -1;\r\nif (ld.op == 0x5) {\r\nunsigned long imm;\r\nimm = ld.x << 7 | ld.r1;\r\nif (ld.m) imm |= SIGN_EXT9;\r\nifa += imm;\r\nDPRINT("imm=%lx r3=%lx\n", imm, ifa);\r\nsetreg(ld.r3, ifa, 0, regs);\r\n}\r\nia64_invala();\r\nif (ld.x6_op == 0xd)\r\nmb();\r\nreturn 0;\r\n}\r\nstatic inline void\r\nmem2float_extended (struct ia64_fpreg *init, struct ia64_fpreg *final)\r\n{\r\nia64_ldfe(6, init);\r\nia64_stop();\r\nia64_stf_spill(final, 6);\r\n}\r\nstatic inline void\r\nmem2float_integer (struct ia64_fpreg *init, struct ia64_fpreg *final)\r\n{\r\nia64_ldf8(6, init);\r\nia64_stop();\r\nia64_stf_spill(final, 6);\r\n}\r\nstatic inline void\r\nmem2float_single (struct ia64_fpreg *init, struct ia64_fpreg *final)\r\n{\r\nia64_ldfs(6, init);\r\nia64_stop();\r\nia64_stf_spill(final, 6);\r\n}\r\nstatic inline void\r\nmem2float_double (struct ia64_fpreg *init, struct ia64_fpreg *final)\r\n{\r\nia64_ldfd(6, init);\r\nia64_stop();\r\nia64_stf_spill(final, 6);\r\n}\r\nstatic inline void\r\nfloat2mem_extended (struct ia64_fpreg *init, struct ia64_fpreg *final)\r\n{\r\nia64_ldf_fill(6, init);\r\nia64_stop();\r\nia64_stfe(final, 6);\r\n}\r\nstatic inline void\r\nfloat2mem_integer (struct ia64_fpreg *init, struct ia64_fpreg *final)\r\n{\r\nia64_ldf_fill(6, init);\r\nia64_stop();\r\nia64_stf8(final, 6);\r\n}\r\nstatic inline void\r\nfloat2mem_single (struct ia64_fpreg *init, struct ia64_fpreg *final)\r\n{\r\nia64_ldf_fill(6, init);\r\nia64_stop();\r\nia64_stfs(final, 6);\r\n}\r\nstatic inline void\r\nfloat2mem_double (struct ia64_fpreg *init, struct ia64_fpreg *final)\r\n{\r\nia64_ldf_fill(6, init);\r\nia64_stop();\r\nia64_stfd(final, 6);\r\n}\r\nstatic int\r\nemulate_load_floatpair (unsigned long ifa, load_store_t ld, struct pt_regs *regs)\r\n{\r\nstruct ia64_fpreg fpr_init[2];\r\nstruct ia64_fpreg fpr_final[2];\r\nunsigned long len = float_fsz[ld.x6_sz];\r\nmemset(&fpr_init, 0, sizeof(fpr_init));\r\nmemset(&fpr_final, 0, sizeof(fpr_final));\r\nif (ld.x6_op != 0x2) {\r\nif (copy_from_user(&fpr_init[0], (void __user *) ifa, len)\r\n|| copy_from_user(&fpr_init[1], (void __user *) (ifa + len), len))\r\nreturn -1;\r\nDPRINT("ld.r1=%d ld.imm=%d x6_sz=%d\n", ld.r1, ld.imm, ld.x6_sz);\r\nDDUMP("frp_init =", &fpr_init, 2*len);\r\nswitch( ld.x6_sz ) {\r\ncase 0:\r\nmem2float_extended(&fpr_init[0], &fpr_final[0]);\r\nmem2float_extended(&fpr_init[1], &fpr_final[1]);\r\nbreak;\r\ncase 1:\r\nmem2float_integer(&fpr_init[0], &fpr_final[0]);\r\nmem2float_integer(&fpr_init[1], &fpr_final[1]);\r\nbreak;\r\ncase 2:\r\nmem2float_single(&fpr_init[0], &fpr_final[0]);\r\nmem2float_single(&fpr_init[1], &fpr_final[1]);\r\nbreak;\r\ncase 3:\r\nmem2float_double(&fpr_init[0], &fpr_final[0]);\r\nmem2float_double(&fpr_init[1], &fpr_final[1]);\r\nbreak;\r\n}\r\nDDUMP("fpr_final =", &fpr_final, 2*len);\r\nsetfpreg(ld.r1, &fpr_final[0], regs);\r\nsetfpreg(ld.imm, &fpr_final[1], regs);\r\n}\r\nif (ld.m) {\r\nifa += len<<1;\r\nif (ld.x6_op == 1 || ld.x6_op == 3)\r\nprintk(KERN_ERR "%s: register update on speculative load pair, error\n",\r\n__func__);\r\nsetreg(ld.r3, ifa, 0, regs);\r\n}\r\nif (ld.x6_op == 0x2) {\r\ninvala_fr(ld.r1);\r\ninvala_fr(ld.imm);\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\nemulate_load_float (unsigned long ifa, load_store_t ld, struct pt_regs *regs)\r\n{\r\nstruct ia64_fpreg fpr_init;\r\nstruct ia64_fpreg fpr_final;\r\nunsigned long len = float_fsz[ld.x6_sz];\r\nmemset(&fpr_init,0, sizeof(fpr_init));\r\nmemset(&fpr_final,0, sizeof(fpr_final));\r\nif (ld.x6_op != 0x2) {\r\nif (copy_from_user(&fpr_init, (void __user *) ifa, len))\r\nreturn -1;\r\nDPRINT("ld.r1=%d x6_sz=%d\n", ld.r1, ld.x6_sz);\r\nDDUMP("fpr_init =", &fpr_init, len);\r\nswitch( ld.x6_sz ) {\r\ncase 0:\r\nmem2float_extended(&fpr_init, &fpr_final);\r\nbreak;\r\ncase 1:\r\nmem2float_integer(&fpr_init, &fpr_final);\r\nbreak;\r\ncase 2:\r\nmem2float_single(&fpr_init, &fpr_final);\r\nbreak;\r\ncase 3:\r\nmem2float_double(&fpr_init, &fpr_final);\r\nbreak;\r\n}\r\nDDUMP("fpr_final =", &fpr_final, len);\r\nsetfpreg(ld.r1, &fpr_final, regs);\r\n}\r\nif (ld.op == 0x7 || ld.m)\r\nemulate_load_updates(ld.op == 0x7 ? UPD_IMMEDIATE: UPD_REG, ld, regs, ifa);\r\nif (ld.x6_op == 0x2)\r\ninvala_fr(ld.r1);\r\nreturn 0;\r\n}\r\nstatic int\r\nemulate_store_float (unsigned long ifa, load_store_t ld, struct pt_regs *regs)\r\n{\r\nstruct ia64_fpreg fpr_init;\r\nstruct ia64_fpreg fpr_final;\r\nunsigned long len = float_fsz[ld.x6_sz];\r\nmemset(&fpr_init,0, sizeof(fpr_init));\r\nmemset(&fpr_final,0, sizeof(fpr_final));\r\ngetfpreg(ld.imm, &fpr_init, regs);\r\nswitch( ld.x6_sz ) {\r\ncase 0:\r\nfloat2mem_extended(&fpr_init, &fpr_final);\r\nbreak;\r\ncase 1:\r\nfloat2mem_integer(&fpr_init, &fpr_final);\r\nbreak;\r\ncase 2:\r\nfloat2mem_single(&fpr_init, &fpr_final);\r\nbreak;\r\ncase 3:\r\nfloat2mem_double(&fpr_init, &fpr_final);\r\nbreak;\r\n}\r\nDPRINT("ld.r1=%d x6_sz=%d\n", ld.r1, ld.x6_sz);\r\nDDUMP("fpr_init =", &fpr_init, len);\r\nDDUMP("fpr_final =", &fpr_final, len);\r\nif (copy_to_user((void __user *) ifa, &fpr_final, len))\r\nreturn -1;\r\nif (ld.op == 0x7) {\r\nunsigned long imm;\r\nimm = ld.x << 7 | ld.r1;\r\nif (ld.m)\r\nimm |= SIGN_EXT9;\r\nifa += imm;\r\nDPRINT("imm=%lx r3=%lx\n", imm, ifa);\r\nsetreg(ld.r3, ifa, 0, regs);\r\n}\r\nia64_invala();\r\nreturn 0;\r\n}\r\nvoid\r\nia64_handle_unaligned (unsigned long ifa, struct pt_regs *regs)\r\n{\r\nstruct ia64_psr *ipsr = ia64_psr(regs);\r\nmm_segment_t old_fs = get_fs();\r\nunsigned long bundle[2];\r\nunsigned long opcode;\r\nstruct siginfo si;\r\nconst struct exception_table_entry *eh = NULL;\r\nunion {\r\nunsigned long l;\r\nload_store_t insn;\r\n} u;\r\nint ret = -1;\r\nif (ia64_psr(regs)->be) {\r\nif (die_if_kernel("big-endian unaligned accesses are not supported", regs, 0))\r\nreturn;\r\ngoto force_sigbus;\r\n}\r\nif (!user_mode(regs))\r\neh = search_exception_tables(regs->cr_iip + ia64_psr(regs)->ri);\r\nif (user_mode(regs) || eh) {\r\nif ((current->thread.flags & IA64_THREAD_UAC_SIGBUS) != 0)\r\ngoto force_sigbus;\r\nif (!no_unaligned_warning &&\r\n!(current->thread.flags & IA64_THREAD_UAC_NOPRINT) &&\r\n__ratelimit(&logging_rate_limit))\r\n{\r\nchar buf[200];\r\nsize_t len;\r\nlen = sprintf(buf, "%s(%d): unaligned access to 0x%016lx, "\r\n"ip=0x%016lx\n\r", current->comm,\r\ntask_pid_nr(current),\r\nifa, regs->cr_iip + ipsr->ri);\r\nif (user_mode(regs))\r\ntty_write_message(current->signal->tty, buf);\r\nbuf[len-1] = '\0';\r\nprintk(KERN_WARNING "%s", buf);\r\n} else {\r\nif (no_unaligned_warning) {\r\nprintk_once(KERN_WARNING "%s(%d) encountered an "\r\n"unaligned exception which required\n"\r\n"kernel assistance, which degrades "\r\n"the performance of the application.\n"\r\n"Unaligned exception warnings have "\r\n"been disabled by the system "\r\n"administrator\n"\r\n"echo 0 > /proc/sys/kernel/ignore-"\r\n"unaligned-usertrap to re-enable\n",\r\ncurrent->comm, task_pid_nr(current));\r\n}\r\n}\r\n} else {\r\nif (__ratelimit(&logging_rate_limit)) {\r\nprintk(KERN_WARNING "kernel unaligned access to 0x%016lx, ip=0x%016lx\n",\r\nifa, regs->cr_iip + ipsr->ri);\r\nif (unaligned_dump_stack)\r\ndump_stack();\r\n}\r\nset_fs(KERNEL_DS);\r\n}\r\nDPRINT("iip=%lx ifa=%lx isr=%lx (ei=%d, sp=%d)\n",\r\nregs->cr_iip, ifa, regs->cr_ipsr, ipsr->ri, ipsr->it);\r\nif (__copy_from_user(bundle, (void __user *) regs->cr_iip, 16))\r\ngoto failure;\r\nswitch (ipsr->ri) {\r\ncase 0: u.l = (bundle[0] >> 5); break;\r\ncase 1: u.l = (bundle[0] >> 46) | (bundle[1] << 18); break;\r\ncase 2: u.l = (bundle[1] >> 23); break;\r\n}\r\nopcode = (u.l >> IA64_OPCODE_SHIFT) & IA64_OPCODE_MASK;\r\nDPRINT("opcode=%lx ld.qp=%d ld.r1=%d ld.imm=%d ld.r3=%d ld.x=%d ld.hint=%d "\r\n"ld.x6=0x%x ld.m=%d ld.op=%d\n", opcode, u.insn.qp, u.insn.r1, u.insn.imm,\r\nu.insn.r3, u.insn.x, u.insn.hint, u.insn.x6_sz, u.insn.m, u.insn.op);\r\nswitch (opcode) {\r\ncase LDS_OP:\r\ncase LDSA_OP:\r\nif (u.insn.x)\r\ngoto failure;\r\ncase LDS_IMM_OP:\r\ncase LDSA_IMM_OP:\r\ncase LDFS_OP:\r\ncase LDFSA_OP:\r\ncase LDFS_IMM_OP:\r\nDPRINT("forcing PSR_ED\n");\r\nregs->cr_ipsr |= IA64_PSR_ED;\r\ngoto done;\r\ncase LD_OP:\r\ncase LDA_OP:\r\ncase LDBIAS_OP:\r\ncase LDACQ_OP:\r\ncase LDCCLR_OP:\r\ncase LDCNC_OP:\r\ncase LDCCLRACQ_OP:\r\nif (u.insn.x)\r\ngoto failure;\r\ncase LD_IMM_OP:\r\ncase LDA_IMM_OP:\r\ncase LDBIAS_IMM_OP:\r\ncase LDACQ_IMM_OP:\r\ncase LDCCLR_IMM_OP:\r\ncase LDCNC_IMM_OP:\r\ncase LDCCLRACQ_IMM_OP:\r\nret = emulate_load_int(ifa, u.insn, regs);\r\nbreak;\r\ncase ST_OP:\r\ncase STREL_OP:\r\nif (u.insn.x)\r\ngoto failure;\r\ncase ST_IMM_OP:\r\ncase STREL_IMM_OP:\r\nret = emulate_store_int(ifa, u.insn, regs);\r\nbreak;\r\ncase LDF_OP:\r\ncase LDFA_OP:\r\ncase LDFCCLR_OP:\r\ncase LDFCNC_OP:\r\nif (u.insn.x)\r\nret = emulate_load_floatpair(ifa, u.insn, regs);\r\nelse\r\nret = emulate_load_float(ifa, u.insn, regs);\r\nbreak;\r\ncase LDF_IMM_OP:\r\ncase LDFA_IMM_OP:\r\ncase LDFCCLR_IMM_OP:\r\ncase LDFCNC_IMM_OP:\r\nret = emulate_load_float(ifa, u.insn, regs);\r\nbreak;\r\ncase STF_OP:\r\ncase STF_IMM_OP:\r\nret = emulate_store_float(ifa, u.insn, regs);\r\nbreak;\r\ndefault:\r\ngoto failure;\r\n}\r\nDPRINT("ret=%d\n", ret);\r\nif (ret)\r\ngoto failure;\r\nif (ipsr->ri == 2)\r\nregs->cr_iip += 16;\r\nipsr->ri = (ipsr->ri + 1) & 0x3;\r\nDPRINT("ipsr->ri=%d iip=%lx\n", ipsr->ri, regs->cr_iip);\r\ndone:\r\nset_fs(old_fs);\r\nreturn;\r\nfailure:\r\nif (!user_mode(regs)) {\r\nif (eh) {\r\nia64_handle_exception(regs, eh);\r\ngoto done;\r\n}\r\nif (die_if_kernel("error during unaligned kernel access\n", regs, ret))\r\nreturn;\r\n}\r\nforce_sigbus:\r\nsi.si_signo = SIGBUS;\r\nsi.si_errno = 0;\r\nsi.si_code = BUS_ADRALN;\r\nsi.si_addr = (void __user *) ifa;\r\nsi.si_flags = 0;\r\nsi.si_isr = 0;\r\nsi.si_imm = 0;\r\nforce_sig_info(SIGBUS, &si, current);\r\ngoto done;\r\n}
