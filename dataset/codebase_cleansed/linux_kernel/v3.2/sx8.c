static int carm_bdev_getgeo(struct block_device *bdev, struct hd_geometry *geo)\r\n{\r\nstruct carm_port *port = bdev->bd_disk->private_data;\r\ngeo->heads = (u8) port->dev_geom_head;\r\ngeo->sectors = (u8) port->dev_geom_sect;\r\ngeo->cylinders = port->dev_geom_cyl;\r\nreturn 0;\r\n}\r\nstatic inline int carm_lookup_bucket(u32 msg_size)\r\n{\r\nint i;\r\nfor (i = 0; i < ARRAY_SIZE(msg_sizes); i++)\r\nif (msg_size <= msg_sizes[i])\r\nreturn i;\r\nreturn -ENOENT;\r\n}\r\nstatic void carm_init_buckets(void __iomem *mmio)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < ARRAY_SIZE(msg_sizes); i++)\r\nwritel(msg_sizes[i], mmio + CARM_CMS0 + (4 * i));\r\n}\r\nstatic inline void *carm_ref_msg(struct carm_host *host,\r\nunsigned int msg_idx)\r\n{\r\nreturn host->msg_base + (msg_idx * CARM_MSG_SIZE);\r\n}\r\nstatic inline dma_addr_t carm_ref_msg_dma(struct carm_host *host,\r\nunsigned int msg_idx)\r\n{\r\nreturn host->msg_dma + (msg_idx * CARM_MSG_SIZE);\r\n}\r\nstatic int carm_send_msg(struct carm_host *host,\r\nstruct carm_request *crq)\r\n{\r\nvoid __iomem *mmio = host->mmio;\r\nu32 msg = (u32) carm_ref_msg_dma(host, crq->tag);\r\nu32 cm_bucket = crq->msg_bucket;\r\nu32 tmp;\r\nint rc = 0;\r\nVPRINTK("ENTER\n");\r\ntmp = readl(mmio + CARM_HMUC);\r\nif (tmp & CARM_Q_FULL) {\r\n#if 0\r\ntmp = readl(mmio + CARM_INT_MASK);\r\ntmp |= INT_Q_AVAILABLE;\r\nwritel(tmp, mmio + CARM_INT_MASK);\r\nreadl(mmio + CARM_INT_MASK);\r\n#endif\r\nDPRINTK("host msg queue full\n");\r\nrc = -EBUSY;\r\n} else {\r\nwritel(msg | (cm_bucket << 1), mmio + CARM_IHQP);\r\nreadl(mmio + CARM_IHQP);\r\n}\r\nreturn rc;\r\n}\r\nstatic struct carm_request *carm_get_request(struct carm_host *host)\r\n{\r\nunsigned int i;\r\nif (host->hw_sg_used >= (CARM_MAX_HOST_SG - CARM_MAX_REQ_SG))\r\nreturn NULL;\r\nfor (i = 0; i < max_queue; i++)\r\nif ((host->msg_alloc & (1ULL << i)) == 0) {\r\nstruct carm_request *crq = &host->req[i];\r\ncrq->port = NULL;\r\ncrq->n_elem = 0;\r\nhost->msg_alloc |= (1ULL << i);\r\nhost->n_msgs++;\r\nassert(host->n_msgs <= CARM_MAX_REQ);\r\nsg_init_table(crq->sg, CARM_MAX_REQ_SG);\r\nreturn crq;\r\n}\r\nDPRINTK("no request available, returning NULL\n");\r\nreturn NULL;\r\n}\r\nstatic int carm_put_request(struct carm_host *host, struct carm_request *crq)\r\n{\r\nassert(crq->tag < max_queue);\r\nif (unlikely((host->msg_alloc & (1ULL << crq->tag)) == 0))\r\nreturn -EINVAL;\r\nassert(host->hw_sg_used >= crq->n_elem);\r\nhost->msg_alloc &= ~(1ULL << crq->tag);\r\nhost->hw_sg_used -= crq->n_elem;\r\nhost->n_msgs--;\r\nreturn 0;\r\n}\r\nstatic struct carm_request *carm_get_special(struct carm_host *host)\r\n{\r\nunsigned long flags;\r\nstruct carm_request *crq = NULL;\r\nstruct request *rq;\r\nint tries = 5000;\r\nwhile (tries-- > 0) {\r\nspin_lock_irqsave(&host->lock, flags);\r\ncrq = carm_get_request(host);\r\nspin_unlock_irqrestore(&host->lock, flags);\r\nif (crq)\r\nbreak;\r\nmsleep(10);\r\n}\r\nif (!crq)\r\nreturn NULL;\r\nrq = blk_get_request(host->oob_q, WRITE , GFP_KERNEL);\r\nif (!rq) {\r\nspin_lock_irqsave(&host->lock, flags);\r\ncarm_put_request(host, crq);\r\nspin_unlock_irqrestore(&host->lock, flags);\r\nreturn NULL;\r\n}\r\ncrq->rq = rq;\r\nreturn crq;\r\n}\r\nstatic int carm_array_info (struct carm_host *host, unsigned int array_idx)\r\n{\r\nstruct carm_msg_ioctl *ioc;\r\nunsigned int idx;\r\nu32 msg_data;\r\ndma_addr_t msg_dma;\r\nstruct carm_request *crq;\r\nint rc;\r\ncrq = carm_get_special(host);\r\nif (!crq) {\r\nrc = -ENOMEM;\r\ngoto err_out;\r\n}\r\nidx = crq->tag;\r\nioc = carm_ref_msg(host, idx);\r\nmsg_dma = carm_ref_msg_dma(host, idx);\r\nmsg_data = (u32) (msg_dma + sizeof(struct carm_array_info));\r\ncrq->msg_type = CARM_MSG_ARRAY;\r\ncrq->msg_subtype = CARM_ARRAY_INFO;\r\nrc = carm_lookup_bucket(sizeof(struct carm_msg_ioctl) +\r\nsizeof(struct carm_array_info));\r\nBUG_ON(rc < 0);\r\ncrq->msg_bucket = (u32) rc;\r\nmemset(ioc, 0, sizeof(*ioc));\r\nioc->type = CARM_MSG_ARRAY;\r\nioc->subtype = CARM_ARRAY_INFO;\r\nioc->array_id = (u8) array_idx;\r\nioc->handle = cpu_to_le32(TAG_ENCODE(idx));\r\nioc->data_addr = cpu_to_le32(msg_data);\r\nspin_lock_irq(&host->lock);\r\nassert(host->state == HST_DEV_SCAN_START ||\r\nhost->state == HST_DEV_SCAN);\r\nspin_unlock_irq(&host->lock);\r\nDPRINTK("blk_insert_request, tag == %u\n", idx);\r\nblk_insert_request(host->oob_q, crq->rq, 1, crq);\r\nreturn 0;\r\nerr_out:\r\nspin_lock_irq(&host->lock);\r\nhost->state = HST_ERROR;\r\nspin_unlock_irq(&host->lock);\r\nreturn rc;\r\n}\r\nstatic int carm_send_special (struct carm_host *host, carm_sspc_t func)\r\n{\r\nstruct carm_request *crq;\r\nstruct carm_msg_ioctl *ioc;\r\nvoid *mem;\r\nunsigned int idx, msg_size;\r\nint rc;\r\ncrq = carm_get_special(host);\r\nif (!crq)\r\nreturn -ENOMEM;\r\nidx = crq->tag;\r\nmem = carm_ref_msg(host, idx);\r\nmsg_size = func(host, idx, mem);\r\nioc = mem;\r\ncrq->msg_type = ioc->type;\r\ncrq->msg_subtype = ioc->subtype;\r\nrc = carm_lookup_bucket(msg_size);\r\nBUG_ON(rc < 0);\r\ncrq->msg_bucket = (u32) rc;\r\nDPRINTK("blk_insert_request, tag == %u\n", idx);\r\nblk_insert_request(host->oob_q, crq->rq, 1, crq);\r\nreturn 0;\r\n}\r\nstatic unsigned int carm_fill_sync_time(struct carm_host *host,\r\nunsigned int idx, void *mem)\r\n{\r\nstruct timeval tv;\r\nstruct carm_msg_sync_time *st = mem;\r\ndo_gettimeofday(&tv);\r\nmemset(st, 0, sizeof(*st));\r\nst->type = CARM_MSG_MISC;\r\nst->subtype = MISC_SET_TIME;\r\nst->handle = cpu_to_le32(TAG_ENCODE(idx));\r\nst->timestamp = cpu_to_le32(tv.tv_sec);\r\nreturn sizeof(struct carm_msg_sync_time);\r\n}\r\nstatic unsigned int carm_fill_alloc_buf(struct carm_host *host,\r\nunsigned int idx, void *mem)\r\n{\r\nstruct carm_msg_allocbuf *ab = mem;\r\nmemset(ab, 0, sizeof(*ab));\r\nab->type = CARM_MSG_MISC;\r\nab->subtype = MISC_ALLOC_MEM;\r\nab->handle = cpu_to_le32(TAG_ENCODE(idx));\r\nab->n_sg = 1;\r\nab->sg_type = SGT_32BIT;\r\nab->addr = cpu_to_le32(host->shm_dma + (PDC_SHM_SIZE >> 1));\r\nab->len = cpu_to_le32(PDC_SHM_SIZE >> 1);\r\nab->evt_pool = cpu_to_le32(host->shm_dma + (16 * 1024));\r\nab->n_evt = cpu_to_le32(1024);\r\nab->rbuf_pool = cpu_to_le32(host->shm_dma);\r\nab->n_rbuf = cpu_to_le32(RMSG_Q_LEN);\r\nab->msg_pool = cpu_to_le32(host->shm_dma + RBUF_LEN);\r\nab->n_msg = cpu_to_le32(CARM_Q_LEN);\r\nab->sg[0].start = cpu_to_le32(host->shm_dma + (PDC_SHM_SIZE >> 1));\r\nab->sg[0].len = cpu_to_le32(65536);\r\nreturn sizeof(struct carm_msg_allocbuf);\r\n}\r\nstatic unsigned int carm_fill_scan_channels(struct carm_host *host,\r\nunsigned int idx, void *mem)\r\n{\r\nstruct carm_msg_ioctl *ioc = mem;\r\nu32 msg_data = (u32) (carm_ref_msg_dma(host, idx) +\r\nIOC_SCAN_CHAN_OFFSET);\r\nmemset(ioc, 0, sizeof(*ioc));\r\nioc->type = CARM_MSG_IOCTL;\r\nioc->subtype = CARM_IOC_SCAN_CHAN;\r\nioc->handle = cpu_to_le32(TAG_ENCODE(idx));\r\nioc->data_addr = cpu_to_le32(msg_data);\r\nmem += IOC_SCAN_CHAN_OFFSET;\r\nmemset(mem, IOC_SCAN_CHAN_NODEV, CARM_MAX_PORTS);\r\nreturn IOC_SCAN_CHAN_OFFSET + CARM_MAX_PORTS;\r\n}\r\nstatic unsigned int carm_fill_get_fw_ver(struct carm_host *host,\r\nunsigned int idx, void *mem)\r\n{\r\nstruct carm_msg_get_fw_ver *ioc = mem;\r\nu32 msg_data = (u32) (carm_ref_msg_dma(host, idx) + sizeof(*ioc));\r\nmemset(ioc, 0, sizeof(*ioc));\r\nioc->type = CARM_MSG_MISC;\r\nioc->subtype = MISC_GET_FW_VER;\r\nioc->handle = cpu_to_le32(TAG_ENCODE(idx));\r\nioc->data_addr = cpu_to_le32(msg_data);\r\nreturn sizeof(struct carm_msg_get_fw_ver) +\r\nsizeof(struct carm_fw_ver);\r\n}\r\nstatic inline void carm_end_request_queued(struct carm_host *host,\r\nstruct carm_request *crq,\r\nint error)\r\n{\r\nstruct request *req = crq->rq;\r\nint rc;\r\n__blk_end_request_all(req, error);\r\nrc = carm_put_request(host, crq);\r\nassert(rc == 0);\r\n}\r\nstatic inline void carm_push_q (struct carm_host *host, struct request_queue *q)\r\n{\r\nunsigned int idx = host->wait_q_prod % CARM_MAX_WAIT_Q;\r\nblk_stop_queue(q);\r\nVPRINTK("STOPPED QUEUE %p\n", q);\r\nhost->wait_q[idx] = q;\r\nhost->wait_q_prod++;\r\nBUG_ON(host->wait_q_prod == host->wait_q_cons);\r\n}\r\nstatic inline struct request_queue *carm_pop_q(struct carm_host *host)\r\n{\r\nunsigned int idx;\r\nif (host->wait_q_prod == host->wait_q_cons)\r\nreturn NULL;\r\nidx = host->wait_q_cons % CARM_MAX_WAIT_Q;\r\nhost->wait_q_cons++;\r\nreturn host->wait_q[idx];\r\n}\r\nstatic inline void carm_round_robin(struct carm_host *host)\r\n{\r\nstruct request_queue *q = carm_pop_q(host);\r\nif (q) {\r\nblk_start_queue(q);\r\nVPRINTK("STARTED QUEUE %p\n", q);\r\n}\r\n}\r\nstatic inline void carm_end_rq(struct carm_host *host, struct carm_request *crq,\r\nint error)\r\n{\r\ncarm_end_request_queued(host, crq, error);\r\nif (max_queue == 1)\r\ncarm_round_robin(host);\r\nelse if ((host->n_msgs <= CARM_MSG_LOW_WATER) &&\r\n(host->hw_sg_used <= CARM_SG_LOW_WATER)) {\r\ncarm_round_robin(host);\r\n}\r\n}\r\nstatic void carm_oob_rq_fn(struct request_queue *q)\r\n{\r\nstruct carm_host *host = q->queuedata;\r\nstruct carm_request *crq;\r\nstruct request *rq;\r\nint rc;\r\nwhile (1) {\r\nDPRINTK("get req\n");\r\nrq = blk_fetch_request(q);\r\nif (!rq)\r\nbreak;\r\ncrq = rq->special;\r\nassert(crq != NULL);\r\nassert(crq->rq == rq);\r\ncrq->n_elem = 0;\r\nDPRINTK("send req\n");\r\nrc = carm_send_msg(host, crq);\r\nif (rc) {\r\nblk_requeue_request(q, rq);\r\ncarm_push_q(host, q);\r\nreturn;\r\n}\r\n}\r\n}\r\nstatic void carm_rq_fn(struct request_queue *q)\r\n{\r\nstruct carm_port *port = q->queuedata;\r\nstruct carm_host *host = port->host;\r\nstruct carm_msg_rw *msg;\r\nstruct carm_request *crq;\r\nstruct request *rq;\r\nstruct scatterlist *sg;\r\nint writing = 0, pci_dir, i, n_elem, rc;\r\nu32 tmp;\r\nunsigned int msg_size;\r\nqueue_one_request:\r\nVPRINTK("get req\n");\r\nrq = blk_peek_request(q);\r\nif (!rq)\r\nreturn;\r\ncrq = carm_get_request(host);\r\nif (!crq) {\r\ncarm_push_q(host, q);\r\nreturn;\r\n}\r\ncrq->rq = rq;\r\nblk_start_request(rq);\r\nif (rq_data_dir(rq) == WRITE) {\r\nwriting = 1;\r\npci_dir = PCI_DMA_TODEVICE;\r\n} else {\r\npci_dir = PCI_DMA_FROMDEVICE;\r\n}\r\nsg = &crq->sg[0];\r\nn_elem = blk_rq_map_sg(q, rq, sg);\r\nif (n_elem <= 0) {\r\ncarm_end_rq(host, crq, -EIO);\r\nreturn;\r\n}\r\nn_elem = pci_map_sg(host->pdev, sg, n_elem, pci_dir);\r\nif (n_elem <= 0) {\r\ncarm_end_rq(host, crq, -EIO);\r\nreturn;\r\n}\r\ncrq->n_elem = n_elem;\r\ncrq->port = port;\r\nhost->hw_sg_used += n_elem;\r\nVPRINTK("build msg\n");\r\nmsg = (struct carm_msg_rw *) carm_ref_msg(host, crq->tag);\r\nif (writing) {\r\nmsg->type = CARM_MSG_WRITE;\r\ncrq->msg_type = CARM_MSG_WRITE;\r\n} else {\r\nmsg->type = CARM_MSG_READ;\r\ncrq->msg_type = CARM_MSG_READ;\r\n}\r\nmsg->id = port->port_no;\r\nmsg->sg_count = n_elem;\r\nmsg->sg_type = SGT_32BIT;\r\nmsg->handle = cpu_to_le32(TAG_ENCODE(crq->tag));\r\nmsg->lba = cpu_to_le32(blk_rq_pos(rq) & 0xffffffff);\r\ntmp = (blk_rq_pos(rq) >> 16) >> 16;\r\nmsg->lba_high = cpu_to_le16( (u16) tmp );\r\nmsg->lba_count = cpu_to_le16(blk_rq_sectors(rq));\r\nmsg_size = sizeof(struct carm_msg_rw) - sizeof(msg->sg);\r\nfor (i = 0; i < n_elem; i++) {\r\nstruct carm_msg_sg *carm_sg = &msg->sg[i];\r\ncarm_sg->start = cpu_to_le32(sg_dma_address(&crq->sg[i]));\r\ncarm_sg->len = cpu_to_le32(sg_dma_len(&crq->sg[i]));\r\nmsg_size += sizeof(struct carm_msg_sg);\r\n}\r\nrc = carm_lookup_bucket(msg_size);\r\nBUG_ON(rc < 0);\r\ncrq->msg_bucket = (u32) rc;\r\nVPRINTK("send msg, tag == %u\n", crq->tag);\r\nrc = carm_send_msg(host, crq);\r\nif (rc) {\r\ncarm_put_request(host, crq);\r\nblk_requeue_request(q, rq);\r\ncarm_push_q(host, q);\r\nreturn;\r\n}\r\ngoto queue_one_request;\r\n}\r\nstatic void carm_handle_array_info(struct carm_host *host,\r\nstruct carm_request *crq, u8 *mem,\r\nint error)\r\n{\r\nstruct carm_port *port;\r\nu8 *msg_data = mem + sizeof(struct carm_array_info);\r\nstruct carm_array_info *desc = (struct carm_array_info *) msg_data;\r\nu64 lo, hi;\r\nint cur_port;\r\nsize_t slen;\r\nDPRINTK("ENTER\n");\r\ncarm_end_rq(host, crq, error);\r\nif (error)\r\ngoto out;\r\nif (le32_to_cpu(desc->array_status) & ARRAY_NO_EXIST)\r\ngoto out;\r\ncur_port = host->cur_scan_dev;\r\nif ((cur_port < 0) || (cur_port >= CARM_MAX_PORTS)) {\r\nprintk(KERN_ERR PFX "BUG: cur_scan_dev==%d, array_id==%d\n",\r\ncur_port, (int) desc->array_id);\r\ngoto out;\r\n}\r\nport = &host->port[cur_port];\r\nlo = (u64) le32_to_cpu(desc->size);\r\nhi = (u64) le16_to_cpu(desc->size_hi);\r\nport->capacity = lo | (hi << 32);\r\nport->dev_geom_head = le16_to_cpu(desc->head);\r\nport->dev_geom_sect = le16_to_cpu(desc->sect);\r\nport->dev_geom_cyl = le16_to_cpu(desc->cyl);\r\nhost->dev_active |= (1 << cur_port);\r\nstrncpy(port->name, desc->name, sizeof(port->name));\r\nport->name[sizeof(port->name) - 1] = 0;\r\nslen = strlen(port->name);\r\nwhile (slen && (port->name[slen - 1] == ' ')) {\r\nport->name[slen - 1] = 0;\r\nslen--;\r\n}\r\nprintk(KERN_INFO DRV_NAME "(%s): port %u device %Lu sectors\n",\r\npci_name(host->pdev), port->port_no,\r\n(unsigned long long) port->capacity);\r\nprintk(KERN_INFO DRV_NAME "(%s): port %u device \"%s\"\n",\r\npci_name(host->pdev), port->port_no, port->name);\r\nout:\r\nassert(host->state == HST_DEV_SCAN);\r\nschedule_work(&host->fsm_task);\r\n}\r\nstatic void carm_handle_scan_chan(struct carm_host *host,\r\nstruct carm_request *crq, u8 *mem,\r\nint error)\r\n{\r\nu8 *msg_data = mem + IOC_SCAN_CHAN_OFFSET;\r\nunsigned int i, dev_count = 0;\r\nint new_state = HST_DEV_SCAN_START;\r\nDPRINTK("ENTER\n");\r\ncarm_end_rq(host, crq, error);\r\nif (error) {\r\nnew_state = HST_ERROR;\r\ngoto out;\r\n}\r\nfor (i = 0; i < 8; i++)\r\nif (msg_data[i] == 0) {\r\nhost->dev_present |= (1 << i);\r\ndev_count++;\r\n}\r\nprintk(KERN_INFO DRV_NAME "(%s): found %u interesting devices\n",\r\npci_name(host->pdev), dev_count);\r\nout:\r\nassert(host->state == HST_PORT_SCAN);\r\nhost->state = new_state;\r\nschedule_work(&host->fsm_task);\r\n}\r\nstatic void carm_handle_generic(struct carm_host *host,\r\nstruct carm_request *crq, int error,\r\nint cur_state, int next_state)\r\n{\r\nDPRINTK("ENTER\n");\r\ncarm_end_rq(host, crq, error);\r\nassert(host->state == cur_state);\r\nif (error)\r\nhost->state = HST_ERROR;\r\nelse\r\nhost->state = next_state;\r\nschedule_work(&host->fsm_task);\r\n}\r\nstatic inline void carm_handle_rw(struct carm_host *host,\r\nstruct carm_request *crq, int error)\r\n{\r\nint pci_dir;\r\nVPRINTK("ENTER\n");\r\nif (rq_data_dir(crq->rq) == WRITE)\r\npci_dir = PCI_DMA_TODEVICE;\r\nelse\r\npci_dir = PCI_DMA_FROMDEVICE;\r\npci_unmap_sg(host->pdev, &crq->sg[0], crq->n_elem, pci_dir);\r\ncarm_end_rq(host, crq, error);\r\n}\r\nstatic inline void carm_handle_resp(struct carm_host *host,\r\n__le32 ret_handle_le, u32 status)\r\n{\r\nu32 handle = le32_to_cpu(ret_handle_le);\r\nunsigned int msg_idx;\r\nstruct carm_request *crq;\r\nint error = (status == RMSG_OK) ? 0 : -EIO;\r\nu8 *mem;\r\nVPRINTK("ENTER, handle == 0x%x\n", handle);\r\nif (unlikely(!TAG_VALID(handle))) {\r\nprintk(KERN_ERR DRV_NAME "(%s): BUG: invalid tag 0x%x\n",\r\npci_name(host->pdev), handle);\r\nreturn;\r\n}\r\nmsg_idx = TAG_DECODE(handle);\r\nVPRINTK("tag == %u\n", msg_idx);\r\ncrq = &host->req[msg_idx];\r\nif (likely(crq->msg_type == CARM_MSG_READ ||\r\ncrq->msg_type == CARM_MSG_WRITE)) {\r\ncarm_handle_rw(host, crq, error);\r\nreturn;\r\n}\r\nmem = carm_ref_msg(host, msg_idx);\r\nswitch (crq->msg_type) {\r\ncase CARM_MSG_IOCTL: {\r\nswitch (crq->msg_subtype) {\r\ncase CARM_IOC_SCAN_CHAN:\r\ncarm_handle_scan_chan(host, crq, mem, error);\r\nbreak;\r\ndefault:\r\ngoto err_out;\r\n}\r\nbreak;\r\n}\r\ncase CARM_MSG_MISC: {\r\nswitch (crq->msg_subtype) {\r\ncase MISC_ALLOC_MEM:\r\ncarm_handle_generic(host, crq, error,\r\nHST_ALLOC_BUF, HST_SYNC_TIME);\r\nbreak;\r\ncase MISC_SET_TIME:\r\ncarm_handle_generic(host, crq, error,\r\nHST_SYNC_TIME, HST_GET_FW_VER);\r\nbreak;\r\ncase MISC_GET_FW_VER: {\r\nstruct carm_fw_ver *ver = (struct carm_fw_ver *)\r\nmem + sizeof(struct carm_msg_get_fw_ver);\r\nif (!error) {\r\nhost->fw_ver = le32_to_cpu(ver->version);\r\nhost->flags |= (ver->features & FL_FW_VER_MASK);\r\n}\r\ncarm_handle_generic(host, crq, error,\r\nHST_GET_FW_VER, HST_PORT_SCAN);\r\nbreak;\r\n}\r\ndefault:\r\ngoto err_out;\r\n}\r\nbreak;\r\n}\r\ncase CARM_MSG_ARRAY: {\r\nswitch (crq->msg_subtype) {\r\ncase CARM_ARRAY_INFO:\r\ncarm_handle_array_info(host, crq, mem, error);\r\nbreak;\r\ndefault:\r\ngoto err_out;\r\n}\r\nbreak;\r\n}\r\ndefault:\r\ngoto err_out;\r\n}\r\nreturn;\r\nerr_out:\r\nprintk(KERN_WARNING DRV_NAME "(%s): BUG: unhandled message type %d/%d\n",\r\npci_name(host->pdev), crq->msg_type, crq->msg_subtype);\r\ncarm_end_rq(host, crq, -EIO);\r\n}\r\nstatic inline void carm_handle_responses(struct carm_host *host)\r\n{\r\nvoid __iomem *mmio = host->mmio;\r\nstruct carm_response *resp = (struct carm_response *) host->shm;\r\nunsigned int work = 0;\r\nunsigned int idx = host->resp_idx % RMSG_Q_LEN;\r\nwhile (1) {\r\nu32 status = le32_to_cpu(resp[idx].status);\r\nif (status == 0xffffffff) {\r\nVPRINTK("ending response on index %u\n", idx);\r\nwritel(idx << 3, mmio + CARM_RESP_IDX);\r\nbreak;\r\n}\r\nelse if ((status & (1 << 31)) == 0) {\r\nVPRINTK("handling msg response on index %u\n", idx);\r\ncarm_handle_resp(host, resp[idx].ret_handle, status);\r\nresp[idx].status = cpu_to_le32(0xffffffff);\r\n}\r\nelse if ((status & 0xff000000) == (1 << 31)) {\r\nu8 *evt_type_ptr = (u8 *) &resp[idx];\r\nu8 evt_type = *evt_type_ptr;\r\nprintk(KERN_WARNING DRV_NAME "(%s): unhandled event type %d\n",\r\npci_name(host->pdev), (int) evt_type);\r\nresp[idx].status = cpu_to_le32(0xffffffff);\r\n}\r\nidx = NEXT_RESP(idx);\r\nwork++;\r\n}\r\nVPRINTK("EXIT, work==%u\n", work);\r\nhost->resp_idx += work;\r\n}\r\nstatic irqreturn_t carm_interrupt(int irq, void *__host)\r\n{\r\nstruct carm_host *host = __host;\r\nvoid __iomem *mmio;\r\nu32 mask;\r\nint handled = 0;\r\nunsigned long flags;\r\nif (!host) {\r\nVPRINTK("no host\n");\r\nreturn IRQ_NONE;\r\n}\r\nspin_lock_irqsave(&host->lock, flags);\r\nmmio = host->mmio;\r\nmask = readl(mmio + CARM_INT_STAT);\r\nif (mask == 0 || mask == 0xffffffff) {\r\nVPRINTK("no work, mask == 0x%x\n", mask);\r\ngoto out;\r\n}\r\nif (mask & INT_ACK_MASK)\r\nwritel(mask, mmio + CARM_INT_STAT);\r\nif (unlikely(host->state == HST_INVALID)) {\r\nVPRINTK("not initialized yet, mask = 0x%x\n", mask);\r\ngoto out;\r\n}\r\nif (mask & CARM_HAVE_RESP) {\r\nhandled = 1;\r\ncarm_handle_responses(host);\r\n}\r\nout:\r\nspin_unlock_irqrestore(&host->lock, flags);\r\nVPRINTK("EXIT\n");\r\nreturn IRQ_RETVAL(handled);\r\n}\r\nstatic void carm_fsm_task (struct work_struct *work)\r\n{\r\nstruct carm_host *host =\r\ncontainer_of(work, struct carm_host, fsm_task);\r\nunsigned long flags;\r\nunsigned int state;\r\nint rc, i, next_dev;\r\nint reschedule = 0;\r\nint new_state = HST_INVALID;\r\nspin_lock_irqsave(&host->lock, flags);\r\nstate = host->state;\r\nspin_unlock_irqrestore(&host->lock, flags);\r\nDPRINTK("ENTER, state == %s\n", state_name[state]);\r\nswitch (state) {\r\ncase HST_PROBE_START:\r\nnew_state = HST_ALLOC_BUF;\r\nreschedule = 1;\r\nbreak;\r\ncase HST_ALLOC_BUF:\r\nrc = carm_send_special(host, carm_fill_alloc_buf);\r\nif (rc) {\r\nnew_state = HST_ERROR;\r\nreschedule = 1;\r\n}\r\nbreak;\r\ncase HST_SYNC_TIME:\r\nrc = carm_send_special(host, carm_fill_sync_time);\r\nif (rc) {\r\nnew_state = HST_ERROR;\r\nreschedule = 1;\r\n}\r\nbreak;\r\ncase HST_GET_FW_VER:\r\nrc = carm_send_special(host, carm_fill_get_fw_ver);\r\nif (rc) {\r\nnew_state = HST_ERROR;\r\nreschedule = 1;\r\n}\r\nbreak;\r\ncase HST_PORT_SCAN:\r\nrc = carm_send_special(host, carm_fill_scan_channels);\r\nif (rc) {\r\nnew_state = HST_ERROR;\r\nreschedule = 1;\r\n}\r\nbreak;\r\ncase HST_DEV_SCAN_START:\r\nhost->cur_scan_dev = -1;\r\nnew_state = HST_DEV_SCAN;\r\nreschedule = 1;\r\nbreak;\r\ncase HST_DEV_SCAN:\r\nnext_dev = -1;\r\nfor (i = host->cur_scan_dev + 1; i < CARM_MAX_PORTS; i++)\r\nif (host->dev_present & (1 << i)) {\r\nnext_dev = i;\r\nbreak;\r\n}\r\nif (next_dev >= 0) {\r\nhost->cur_scan_dev = next_dev;\r\nrc = carm_array_info(host, next_dev);\r\nif (rc) {\r\nnew_state = HST_ERROR;\r\nreschedule = 1;\r\n}\r\n} else {\r\nnew_state = HST_DEV_ACTIVATE;\r\nreschedule = 1;\r\n}\r\nbreak;\r\ncase HST_DEV_ACTIVATE: {\r\nint activated = 0;\r\nfor (i = 0; i < CARM_MAX_PORTS; i++)\r\nif (host->dev_active & (1 << i)) {\r\nstruct carm_port *port = &host->port[i];\r\nstruct gendisk *disk = port->disk;\r\nset_capacity(disk, port->capacity);\r\nadd_disk(disk);\r\nactivated++;\r\n}\r\nprintk(KERN_INFO DRV_NAME "(%s): %d ports activated\n",\r\npci_name(host->pdev), activated);\r\nnew_state = HST_PROBE_FINISHED;\r\nreschedule = 1;\r\nbreak;\r\n}\r\ncase HST_PROBE_FINISHED:\r\ncomplete(&host->probe_comp);\r\nbreak;\r\ncase HST_ERROR:\r\nbreak;\r\ndefault:\r\nprintk(KERN_ERR PFX "BUG: unknown state %d\n", state);\r\nassert(0);\r\nbreak;\r\n}\r\nif (new_state != HST_INVALID) {\r\nspin_lock_irqsave(&host->lock, flags);\r\nhost->state = new_state;\r\nspin_unlock_irqrestore(&host->lock, flags);\r\n}\r\nif (reschedule)\r\nschedule_work(&host->fsm_task);\r\n}\r\nstatic int carm_init_wait(void __iomem *mmio, u32 bits, unsigned int test_bit)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < 50000; i++) {\r\nu32 tmp = readl(mmio + CARM_LMUC);\r\nudelay(100);\r\nif (test_bit) {\r\nif ((tmp & bits) == bits)\r\nreturn 0;\r\n} else {\r\nif ((tmp & bits) == 0)\r\nreturn 0;\r\n}\r\ncond_resched();\r\n}\r\nprintk(KERN_ERR PFX "carm_init_wait timeout, bits == 0x%x, test_bit == %s\n",\r\nbits, test_bit ? "yes" : "no");\r\nreturn -EBUSY;\r\n}\r\nstatic void carm_init_responses(struct carm_host *host)\r\n{\r\nvoid __iomem *mmio = host->mmio;\r\nunsigned int i;\r\nstruct carm_response *resp = (struct carm_response *) host->shm;\r\nfor (i = 0; i < RMSG_Q_LEN; i++)\r\nresp[i].status = cpu_to_le32(0xffffffff);\r\nwritel(0, mmio + CARM_RESP_IDX);\r\n}\r\nstatic int carm_init_host(struct carm_host *host)\r\n{\r\nvoid __iomem *mmio = host->mmio;\r\nu32 tmp;\r\nu8 tmp8;\r\nint rc;\r\nDPRINTK("ENTER\n");\r\nwritel(0, mmio + CARM_INT_MASK);\r\ntmp8 = readb(mmio + CARM_INITC);\r\nif (tmp8 & 0x01) {\r\ntmp8 &= ~0x01;\r\nwriteb(tmp8, mmio + CARM_INITC);\r\nreadb(mmio + CARM_INITC);\r\nDPRINTK("snooze...\n");\r\nmsleep(5000);\r\n}\r\ntmp = readl(mmio + CARM_HMUC);\r\nif (tmp & CARM_CME) {\r\nDPRINTK("CME bit present, waiting\n");\r\nrc = carm_init_wait(mmio, CARM_CME, 1);\r\nif (rc) {\r\nDPRINTK("EXIT, carm_init_wait 1 failed\n");\r\nreturn rc;\r\n}\r\n}\r\nif (tmp & CARM_RME) {\r\nDPRINTK("RME bit present, waiting\n");\r\nrc = carm_init_wait(mmio, CARM_RME, 1);\r\nif (rc) {\r\nDPRINTK("EXIT, carm_init_wait 2 failed\n");\r\nreturn rc;\r\n}\r\n}\r\ntmp &= ~(CARM_RME | CARM_CME);\r\nwritel(tmp, mmio + CARM_HMUC);\r\nreadl(mmio + CARM_HMUC);\r\nrc = carm_init_wait(mmio, CARM_RME | CARM_CME, 0);\r\nif (rc) {\r\nDPRINTK("EXIT, carm_init_wait 3 failed\n");\r\nreturn rc;\r\n}\r\ncarm_init_buckets(mmio);\r\nwritel(host->shm_dma & 0xffffffff, mmio + RBUF_ADDR_LO);\r\nwritel((host->shm_dma >> 16) >> 16, mmio + RBUF_ADDR_HI);\r\nwritel(RBUF_LEN, mmio + RBUF_BYTE_SZ);\r\ntmp = readl(mmio + CARM_HMUC);\r\ntmp |= (CARM_RME | CARM_CME | CARM_WZBC);\r\nwritel(tmp, mmio + CARM_HMUC);\r\nreadl(mmio + CARM_HMUC);\r\nrc = carm_init_wait(mmio, CARM_RME | CARM_CME, 1);\r\nif (rc) {\r\nDPRINTK("EXIT, carm_init_wait 4 failed\n");\r\nreturn rc;\r\n}\r\nwritel(0, mmio + CARM_HMPHA);\r\nwritel(INT_DEF_MASK, mmio + CARM_INT_MASK);\r\ncarm_init_responses(host);\r\nspin_lock_irq(&host->lock);\r\nassert(host->state == HST_INVALID);\r\nhost->state = HST_PROBE_START;\r\nspin_unlock_irq(&host->lock);\r\nschedule_work(&host->fsm_task);\r\nDPRINTK("EXIT\n");\r\nreturn 0;\r\n}\r\nstatic int carm_init_disks(struct carm_host *host)\r\n{\r\nunsigned int i;\r\nint rc = 0;\r\nfor (i = 0; i < CARM_MAX_PORTS; i++) {\r\nstruct gendisk *disk;\r\nstruct request_queue *q;\r\nstruct carm_port *port;\r\nport = &host->port[i];\r\nport->host = host;\r\nport->port_no = i;\r\ndisk = alloc_disk(CARM_MINORS_PER_MAJOR);\r\nif (!disk) {\r\nrc = -ENOMEM;\r\nbreak;\r\n}\r\nport->disk = disk;\r\nsprintf(disk->disk_name, DRV_NAME "/%u",\r\n(unsigned int) (host->id * CARM_MAX_PORTS) + i);\r\ndisk->major = host->major;\r\ndisk->first_minor = i * CARM_MINORS_PER_MAJOR;\r\ndisk->fops = &carm_bd_ops;\r\ndisk->private_data = port;\r\nq = blk_init_queue(carm_rq_fn, &host->lock);\r\nif (!q) {\r\nrc = -ENOMEM;\r\nbreak;\r\n}\r\ndisk->queue = q;\r\nblk_queue_max_segments(q, CARM_MAX_REQ_SG);\r\nblk_queue_segment_boundary(q, CARM_SG_BOUNDARY);\r\nq->queuedata = port;\r\n}\r\nreturn rc;\r\n}\r\nstatic void carm_free_disks(struct carm_host *host)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < CARM_MAX_PORTS; i++) {\r\nstruct gendisk *disk = host->port[i].disk;\r\nif (disk) {\r\nstruct request_queue *q = disk->queue;\r\nif (disk->flags & GENHD_FL_UP)\r\ndel_gendisk(disk);\r\nif (q)\r\nblk_cleanup_queue(q);\r\nput_disk(disk);\r\n}\r\n}\r\n}\r\nstatic int carm_init_shm(struct carm_host *host)\r\n{\r\nhost->shm = pci_alloc_consistent(host->pdev, CARM_SHM_SIZE,\r\n&host->shm_dma);\r\nif (!host->shm)\r\nreturn -ENOMEM;\r\nhost->msg_base = host->shm + RBUF_LEN;\r\nhost->msg_dma = host->shm_dma + RBUF_LEN;\r\nmemset(host->shm, 0xff, RBUF_LEN);\r\nmemset(host->msg_base, 0, PDC_SHM_SIZE - RBUF_LEN);\r\nreturn 0;\r\n}\r\nstatic int carm_init_one (struct pci_dev *pdev, const struct pci_device_id *ent)\r\n{\r\nstruct carm_host *host;\r\nunsigned int pci_dac;\r\nint rc;\r\nstruct request_queue *q;\r\nunsigned int i;\r\nprintk_once(KERN_DEBUG DRV_NAME " version " DRV_VERSION "\n");\r\nrc = pci_enable_device(pdev);\r\nif (rc)\r\nreturn rc;\r\nrc = pci_request_regions(pdev, DRV_NAME);\r\nif (rc)\r\ngoto err_out;\r\n#ifdef IF_64BIT_DMA_IS_POSSIBLE\r\nrc = pci_set_dma_mask(pdev, DMA_BIT_MASK(64));\r\nif (!rc) {\r\nrc = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));\r\nif (rc) {\r\nprintk(KERN_ERR DRV_NAME "(%s): consistent DMA mask failure\n",\r\npci_name(pdev));\r\ngoto err_out_regions;\r\n}\r\npci_dac = 1;\r\n} else {\r\n#endif\r\nrc = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (rc) {\r\nprintk(KERN_ERR DRV_NAME "(%s): DMA mask failure\n",\r\npci_name(pdev));\r\ngoto err_out_regions;\r\n}\r\npci_dac = 0;\r\n#ifdef IF_64BIT_DMA_IS_POSSIBLE\r\n}\r\n#endif\r\nhost = kzalloc(sizeof(*host), GFP_KERNEL);\r\nif (!host) {\r\nprintk(KERN_ERR DRV_NAME "(%s): memory alloc failure\n",\r\npci_name(pdev));\r\nrc = -ENOMEM;\r\ngoto err_out_regions;\r\n}\r\nhost->pdev = pdev;\r\nhost->flags = pci_dac ? FL_DAC : 0;\r\nspin_lock_init(&host->lock);\r\nINIT_WORK(&host->fsm_task, carm_fsm_task);\r\ninit_completion(&host->probe_comp);\r\nfor (i = 0; i < ARRAY_SIZE(host->req); i++)\r\nhost->req[i].tag = i;\r\nhost->mmio = ioremap(pci_resource_start(pdev, 0),\r\npci_resource_len(pdev, 0));\r\nif (!host->mmio) {\r\nprintk(KERN_ERR DRV_NAME "(%s): MMIO alloc failure\n",\r\npci_name(pdev));\r\nrc = -ENOMEM;\r\ngoto err_out_kfree;\r\n}\r\nrc = carm_init_shm(host);\r\nif (rc) {\r\nprintk(KERN_ERR DRV_NAME "(%s): DMA SHM alloc failure\n",\r\npci_name(pdev));\r\ngoto err_out_iounmap;\r\n}\r\nq = blk_init_queue(carm_oob_rq_fn, &host->lock);\r\nif (!q) {\r\nprintk(KERN_ERR DRV_NAME "(%s): OOB queue alloc failure\n",\r\npci_name(pdev));\r\nrc = -ENOMEM;\r\ngoto err_out_pci_free;\r\n}\r\nhost->oob_q = q;\r\nq->queuedata = host;\r\nif (!test_and_set_bit(0, &carm_major_alloc))\r\nhost->major = 160;\r\nelse if (!test_and_set_bit(1, &carm_major_alloc))\r\nhost->major = 161;\r\nelse\r\nhost->flags |= FL_DYN_MAJOR;\r\nhost->id = carm_host_id;\r\nsprintf(host->name, DRV_NAME "%d", carm_host_id);\r\nrc = register_blkdev(host->major, host->name);\r\nif (rc < 0)\r\ngoto err_out_free_majors;\r\nif (host->flags & FL_DYN_MAJOR)\r\nhost->major = rc;\r\nrc = carm_init_disks(host);\r\nif (rc)\r\ngoto err_out_blkdev_disks;\r\npci_set_master(pdev);\r\nrc = request_irq(pdev->irq, carm_interrupt, IRQF_SHARED, DRV_NAME, host);\r\nif (rc) {\r\nprintk(KERN_ERR DRV_NAME "(%s): irq alloc failure\n",\r\npci_name(pdev));\r\ngoto err_out_blkdev_disks;\r\n}\r\nrc = carm_init_host(host);\r\nif (rc)\r\ngoto err_out_free_irq;\r\nDPRINTK("waiting for probe_comp\n");\r\nwait_for_completion(&host->probe_comp);\r\nprintk(KERN_INFO "%s: pci %s, ports %d, io %llx, irq %u, major %d\n",\r\nhost->name, pci_name(pdev), (int) CARM_MAX_PORTS,\r\n(unsigned long long)pci_resource_start(pdev, 0),\r\npdev->irq, host->major);\r\ncarm_host_id++;\r\npci_set_drvdata(pdev, host);\r\nreturn 0;\r\nerr_out_free_irq:\r\nfree_irq(pdev->irq, host);\r\nerr_out_blkdev_disks:\r\ncarm_free_disks(host);\r\nunregister_blkdev(host->major, host->name);\r\nerr_out_free_majors:\r\nif (host->major == 160)\r\nclear_bit(0, &carm_major_alloc);\r\nelse if (host->major == 161)\r\nclear_bit(1, &carm_major_alloc);\r\nblk_cleanup_queue(host->oob_q);\r\nerr_out_pci_free:\r\npci_free_consistent(pdev, CARM_SHM_SIZE, host->shm, host->shm_dma);\r\nerr_out_iounmap:\r\niounmap(host->mmio);\r\nerr_out_kfree:\r\nkfree(host);\r\nerr_out_regions:\r\npci_release_regions(pdev);\r\nerr_out:\r\npci_disable_device(pdev);\r\nreturn rc;\r\n}\r\nstatic void carm_remove_one (struct pci_dev *pdev)\r\n{\r\nstruct carm_host *host = pci_get_drvdata(pdev);\r\nif (!host) {\r\nprintk(KERN_ERR PFX "BUG: no host data for PCI(%s)\n",\r\npci_name(pdev));\r\nreturn;\r\n}\r\nfree_irq(pdev->irq, host);\r\ncarm_free_disks(host);\r\nunregister_blkdev(host->major, host->name);\r\nif (host->major == 160)\r\nclear_bit(0, &carm_major_alloc);\r\nelse if (host->major == 161)\r\nclear_bit(1, &carm_major_alloc);\r\nblk_cleanup_queue(host->oob_q);\r\npci_free_consistent(pdev, CARM_SHM_SIZE, host->shm, host->shm_dma);\r\niounmap(host->mmio);\r\nkfree(host);\r\npci_release_regions(pdev);\r\npci_disable_device(pdev);\r\npci_set_drvdata(pdev, NULL);\r\n}\r\nstatic int __init carm_init(void)\r\n{\r\nreturn pci_register_driver(&carm_driver);\r\n}\r\nstatic void __exit carm_exit(void)\r\n{\r\npci_unregister_driver(&carm_driver);\r\n}
