static inline int kvm_irq_line_state(unsigned long *irq_state,\r\nint irq_source_id, int level)\r\n{\r\nif (level)\r\nset_bit(irq_source_id, irq_state);\r\nelse\r\nclear_bit(irq_source_id, irq_state);\r\nreturn !!(*irq_state);\r\n}\r\nstatic int kvm_set_pic_irq(struct kvm_kernel_irq_routing_entry *e,\r\nstruct kvm *kvm, int irq_source_id, int level)\r\n{\r\n#ifdef CONFIG_X86\r\nstruct kvm_pic *pic = pic_irqchip(kvm);\r\nlevel = kvm_irq_line_state(&pic->irq_states[e->irqchip.pin],\r\nirq_source_id, level);\r\nreturn kvm_pic_set_irq(pic, e->irqchip.pin, level);\r\n#else\r\nreturn -1;\r\n#endif\r\n}\r\nstatic int kvm_set_ioapic_irq(struct kvm_kernel_irq_routing_entry *e,\r\nstruct kvm *kvm, int irq_source_id, int level)\r\n{\r\nstruct kvm_ioapic *ioapic = kvm->arch.vioapic;\r\nlevel = kvm_irq_line_state(&ioapic->irq_states[e->irqchip.pin],\r\nirq_source_id, level);\r\nreturn kvm_ioapic_set_irq(ioapic, e->irqchip.pin, level);\r\n}\r\ninline static bool kvm_is_dm_lowest_prio(struct kvm_lapic_irq *irq)\r\n{\r\n#ifdef CONFIG_IA64\r\nreturn irq->delivery_mode ==\r\n(IOSAPIC_LOWEST_PRIORITY << IOSAPIC_DELIVERY_SHIFT);\r\n#else\r\nreturn irq->delivery_mode == APIC_DM_LOWEST;\r\n#endif\r\n}\r\nint kvm_irq_delivery_to_apic(struct kvm *kvm, struct kvm_lapic *src,\r\nstruct kvm_lapic_irq *irq)\r\n{\r\nint i, r = -1;\r\nstruct kvm_vcpu *vcpu, *lowest = NULL;\r\nif (irq->dest_mode == 0 && irq->dest_id == 0xff &&\r\nkvm_is_dm_lowest_prio(irq))\r\nprintk(KERN_INFO "kvm: apic: phys broadcast and lowest prio\n");\r\nkvm_for_each_vcpu(i, vcpu, kvm) {\r\nif (!kvm_apic_present(vcpu))\r\ncontinue;\r\nif (!kvm_apic_match_dest(vcpu, src, irq->shorthand,\r\nirq->dest_id, irq->dest_mode))\r\ncontinue;\r\nif (!kvm_is_dm_lowest_prio(irq)) {\r\nif (r < 0)\r\nr = 0;\r\nr += kvm_apic_set_irq(vcpu, irq);\r\n} else if (kvm_lapic_enabled(vcpu)) {\r\nif (!lowest)\r\nlowest = vcpu;\r\nelse if (kvm_apic_compare_prio(vcpu, lowest) < 0)\r\nlowest = vcpu;\r\n}\r\n}\r\nif (lowest)\r\nr = kvm_apic_set_irq(lowest, irq);\r\nreturn r;\r\n}\r\nint kvm_set_msi(struct kvm_kernel_irq_routing_entry *e,\r\nstruct kvm *kvm, int irq_source_id, int level)\r\n{\r\nstruct kvm_lapic_irq irq;\r\nif (!level)\r\nreturn -1;\r\ntrace_kvm_msi_set_irq(e->msi.address_lo, e->msi.data);\r\nirq.dest_id = (e->msi.address_lo &\r\nMSI_ADDR_DEST_ID_MASK) >> MSI_ADDR_DEST_ID_SHIFT;\r\nirq.vector = (e->msi.data &\r\nMSI_DATA_VECTOR_MASK) >> MSI_DATA_VECTOR_SHIFT;\r\nirq.dest_mode = (1 << MSI_ADDR_DEST_MODE_SHIFT) & e->msi.address_lo;\r\nirq.trig_mode = (1 << MSI_DATA_TRIGGER_SHIFT) & e->msi.data;\r\nirq.delivery_mode = e->msi.data & 0x700;\r\nirq.level = 1;\r\nirq.shorthand = 0;\r\nreturn kvm_irq_delivery_to_apic(kvm, NULL, &irq);\r\n}\r\nint kvm_set_irq(struct kvm *kvm, int irq_source_id, u32 irq, int level)\r\n{\r\nstruct kvm_kernel_irq_routing_entry *e, irq_set[KVM_NR_IRQCHIPS];\r\nint ret = -1, i = 0;\r\nstruct kvm_irq_routing_table *irq_rt;\r\nstruct hlist_node *n;\r\ntrace_kvm_set_irq(irq, level, irq_source_id);\r\nrcu_read_lock();\r\nirq_rt = rcu_dereference(kvm->irq_routing);\r\nif (irq < irq_rt->nr_rt_entries)\r\nhlist_for_each_entry(e, n, &irq_rt->map[irq], link)\r\nirq_set[i++] = *e;\r\nrcu_read_unlock();\r\nwhile(i--) {\r\nint r;\r\nr = irq_set[i].set(&irq_set[i], kvm, irq_source_id, level);\r\nif (r < 0)\r\ncontinue;\r\nret = r + ((ret < 0) ? 0 : ret);\r\n}\r\nreturn ret;\r\n}\r\nvoid kvm_notify_acked_irq(struct kvm *kvm, unsigned irqchip, unsigned pin)\r\n{\r\nstruct kvm_irq_ack_notifier *kian;\r\nstruct hlist_node *n;\r\nint gsi;\r\ntrace_kvm_ack_irq(irqchip, pin);\r\nrcu_read_lock();\r\ngsi = rcu_dereference(kvm->irq_routing)->chip[irqchip][pin];\r\nif (gsi != -1)\r\nhlist_for_each_entry_rcu(kian, n, &kvm->irq_ack_notifier_list,\r\nlink)\r\nif (kian->gsi == gsi)\r\nkian->irq_acked(kian);\r\nrcu_read_unlock();\r\n}\r\nvoid kvm_register_irq_ack_notifier(struct kvm *kvm,\r\nstruct kvm_irq_ack_notifier *kian)\r\n{\r\nmutex_lock(&kvm->irq_lock);\r\nhlist_add_head_rcu(&kian->link, &kvm->irq_ack_notifier_list);\r\nmutex_unlock(&kvm->irq_lock);\r\n}\r\nvoid kvm_unregister_irq_ack_notifier(struct kvm *kvm,\r\nstruct kvm_irq_ack_notifier *kian)\r\n{\r\nmutex_lock(&kvm->irq_lock);\r\nhlist_del_init_rcu(&kian->link);\r\nmutex_unlock(&kvm->irq_lock);\r\nsynchronize_rcu();\r\n}\r\nint kvm_request_irq_source_id(struct kvm *kvm)\r\n{\r\nunsigned long *bitmap = &kvm->arch.irq_sources_bitmap;\r\nint irq_source_id;\r\nmutex_lock(&kvm->irq_lock);\r\nirq_source_id = find_first_zero_bit(bitmap, BITS_PER_LONG);\r\nif (irq_source_id >= BITS_PER_LONG) {\r\nprintk(KERN_WARNING "kvm: exhaust allocatable IRQ sources!\n");\r\nirq_source_id = -EFAULT;\r\ngoto unlock;\r\n}\r\nASSERT(irq_source_id != KVM_USERSPACE_IRQ_SOURCE_ID);\r\nset_bit(irq_source_id, bitmap);\r\nunlock:\r\nmutex_unlock(&kvm->irq_lock);\r\nreturn irq_source_id;\r\n}\r\nvoid kvm_free_irq_source_id(struct kvm *kvm, int irq_source_id)\r\n{\r\nint i;\r\nASSERT(irq_source_id != KVM_USERSPACE_IRQ_SOURCE_ID);\r\nmutex_lock(&kvm->irq_lock);\r\nif (irq_source_id < 0 ||\r\nirq_source_id >= BITS_PER_LONG) {\r\nprintk(KERN_ERR "kvm: IRQ source ID out of range!\n");\r\ngoto unlock;\r\n}\r\nclear_bit(irq_source_id, &kvm->arch.irq_sources_bitmap);\r\nif (!irqchip_in_kernel(kvm))\r\ngoto unlock;\r\nfor (i = 0; i < KVM_IOAPIC_NUM_PINS; i++) {\r\nclear_bit(irq_source_id, &kvm->arch.vioapic->irq_states[i]);\r\nif (i >= 16)\r\ncontinue;\r\n#ifdef CONFIG_X86\r\nclear_bit(irq_source_id, &pic_irqchip(kvm)->irq_states[i]);\r\n#endif\r\n}\r\nunlock:\r\nmutex_unlock(&kvm->irq_lock);\r\n}\r\nvoid kvm_register_irq_mask_notifier(struct kvm *kvm, int irq,\r\nstruct kvm_irq_mask_notifier *kimn)\r\n{\r\nmutex_lock(&kvm->irq_lock);\r\nkimn->irq = irq;\r\nhlist_add_head_rcu(&kimn->link, &kvm->mask_notifier_list);\r\nmutex_unlock(&kvm->irq_lock);\r\n}\r\nvoid kvm_unregister_irq_mask_notifier(struct kvm *kvm, int irq,\r\nstruct kvm_irq_mask_notifier *kimn)\r\n{\r\nmutex_lock(&kvm->irq_lock);\r\nhlist_del_rcu(&kimn->link);\r\nmutex_unlock(&kvm->irq_lock);\r\nsynchronize_rcu();\r\n}\r\nvoid kvm_fire_mask_notifiers(struct kvm *kvm, unsigned irqchip, unsigned pin,\r\nbool mask)\r\n{\r\nstruct kvm_irq_mask_notifier *kimn;\r\nstruct hlist_node *n;\r\nint gsi;\r\nrcu_read_lock();\r\ngsi = rcu_dereference(kvm->irq_routing)->chip[irqchip][pin];\r\nif (gsi != -1)\r\nhlist_for_each_entry_rcu(kimn, n, &kvm->mask_notifier_list, link)\r\nif (kimn->irq == gsi)\r\nkimn->func(kimn, mask);\r\nrcu_read_unlock();\r\n}\r\nvoid kvm_free_irq_routing(struct kvm *kvm)\r\n{\r\nkfree(kvm->irq_routing);\r\n}\r\nstatic int setup_routing_entry(struct kvm_irq_routing_table *rt,\r\nstruct kvm_kernel_irq_routing_entry *e,\r\nconst struct kvm_irq_routing_entry *ue)\r\n{\r\nint r = -EINVAL;\r\nint delta;\r\nunsigned max_pin;\r\nstruct kvm_kernel_irq_routing_entry *ei;\r\nstruct hlist_node *n;\r\nhlist_for_each_entry(ei, n, &rt->map[ue->gsi], link)\r\nif (ei->type == KVM_IRQ_ROUTING_MSI ||\r\nue->u.irqchip.irqchip == ei->irqchip.irqchip)\r\nreturn r;\r\ne->gsi = ue->gsi;\r\ne->type = ue->type;\r\nswitch (ue->type) {\r\ncase KVM_IRQ_ROUTING_IRQCHIP:\r\ndelta = 0;\r\nswitch (ue->u.irqchip.irqchip) {\r\ncase KVM_IRQCHIP_PIC_MASTER:\r\ne->set = kvm_set_pic_irq;\r\nmax_pin = 16;\r\nbreak;\r\ncase KVM_IRQCHIP_PIC_SLAVE:\r\ne->set = kvm_set_pic_irq;\r\nmax_pin = 16;\r\ndelta = 8;\r\nbreak;\r\ncase KVM_IRQCHIP_IOAPIC:\r\nmax_pin = KVM_IOAPIC_NUM_PINS;\r\ne->set = kvm_set_ioapic_irq;\r\nbreak;\r\ndefault:\r\ngoto out;\r\n}\r\ne->irqchip.irqchip = ue->u.irqchip.irqchip;\r\ne->irqchip.pin = ue->u.irqchip.pin + delta;\r\nif (e->irqchip.pin >= max_pin)\r\ngoto out;\r\nrt->chip[ue->u.irqchip.irqchip][e->irqchip.pin] = ue->gsi;\r\nbreak;\r\ncase KVM_IRQ_ROUTING_MSI:\r\ne->set = kvm_set_msi;\r\ne->msi.address_lo = ue->u.msi.address_lo;\r\ne->msi.address_hi = ue->u.msi.address_hi;\r\ne->msi.data = ue->u.msi.data;\r\nbreak;\r\ndefault:\r\ngoto out;\r\n}\r\nhlist_add_head(&e->link, &rt->map[e->gsi]);\r\nr = 0;\r\nout:\r\nreturn r;\r\n}\r\nint kvm_set_irq_routing(struct kvm *kvm,\r\nconst struct kvm_irq_routing_entry *ue,\r\nunsigned nr,\r\nunsigned flags)\r\n{\r\nstruct kvm_irq_routing_table *new, *old;\r\nu32 i, j, nr_rt_entries = 0;\r\nint r;\r\nfor (i = 0; i < nr; ++i) {\r\nif (ue[i].gsi >= KVM_MAX_IRQ_ROUTES)\r\nreturn -EINVAL;\r\nnr_rt_entries = max(nr_rt_entries, ue[i].gsi);\r\n}\r\nnr_rt_entries += 1;\r\nnew = kzalloc(sizeof(*new) + (nr_rt_entries * sizeof(struct hlist_head))\r\n+ (nr * sizeof(struct kvm_kernel_irq_routing_entry)),\r\nGFP_KERNEL);\r\nif (!new)\r\nreturn -ENOMEM;\r\nnew->rt_entries = (void *)&new->map[nr_rt_entries];\r\nnew->nr_rt_entries = nr_rt_entries;\r\nfor (i = 0; i < 3; i++)\r\nfor (j = 0; j < KVM_IOAPIC_NUM_PINS; j++)\r\nnew->chip[i][j] = -1;\r\nfor (i = 0; i < nr; ++i) {\r\nr = -EINVAL;\r\nif (ue->flags)\r\ngoto out;\r\nr = setup_routing_entry(new, &new->rt_entries[i], ue);\r\nif (r)\r\ngoto out;\r\n++ue;\r\n}\r\nmutex_lock(&kvm->irq_lock);\r\nold = kvm->irq_routing;\r\nkvm_irq_routing_update(kvm, new);\r\nmutex_unlock(&kvm->irq_lock);\r\nsynchronize_rcu();\r\nnew = old;\r\nr = 0;\r\nout:\r\nkfree(new);\r\nreturn r;\r\n}\r\nint kvm_setup_default_irq_routing(struct kvm *kvm)\r\n{\r\nreturn kvm_set_irq_routing(kvm, default_routing,\r\nARRAY_SIZE(default_routing), 0);\r\n}
