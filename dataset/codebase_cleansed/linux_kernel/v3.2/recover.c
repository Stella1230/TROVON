static void dlm_wait_timer_fn(unsigned long data)\r\n{\r\nstruct dlm_ls *ls = (struct dlm_ls *) data;\r\nmod_timer(&ls->ls_timer, jiffies + (dlm_config.ci_recover_timer * HZ));\r\nwake_up(&ls->ls_wait_general);\r\n}\r\nint dlm_wait_function(struct dlm_ls *ls, int (*testfn) (struct dlm_ls *ls))\r\n{\r\nint error = 0;\r\ninit_timer(&ls->ls_timer);\r\nls->ls_timer.function = dlm_wait_timer_fn;\r\nls->ls_timer.data = (long) ls;\r\nls->ls_timer.expires = jiffies + (dlm_config.ci_recover_timer * HZ);\r\nadd_timer(&ls->ls_timer);\r\nwait_event(ls->ls_wait_general, testfn(ls) || dlm_recovery_stopped(ls));\r\ndel_timer_sync(&ls->ls_timer);\r\nif (dlm_recovery_stopped(ls)) {\r\nlog_debug(ls, "dlm_wait_function aborted");\r\nerror = -EINTR;\r\n}\r\nreturn error;\r\n}\r\nuint32_t dlm_recover_status(struct dlm_ls *ls)\r\n{\r\nuint32_t status;\r\nspin_lock(&ls->ls_recover_lock);\r\nstatus = ls->ls_recover_status;\r\nspin_unlock(&ls->ls_recover_lock);\r\nreturn status;\r\n}\r\nvoid dlm_set_recover_status(struct dlm_ls *ls, uint32_t status)\r\n{\r\nspin_lock(&ls->ls_recover_lock);\r\nls->ls_recover_status |= status;\r\nspin_unlock(&ls->ls_recover_lock);\r\n}\r\nstatic int wait_status_all(struct dlm_ls *ls, uint32_t wait_status)\r\n{\r\nstruct dlm_rcom *rc = ls->ls_recover_buf;\r\nstruct dlm_member *memb;\r\nint error = 0, delay;\r\nlist_for_each_entry(memb, &ls->ls_nodes, list) {\r\ndelay = 0;\r\nfor (;;) {\r\nif (dlm_recovery_stopped(ls)) {\r\nerror = -EINTR;\r\ngoto out;\r\n}\r\nerror = dlm_rcom_status(ls, memb->nodeid);\r\nif (error)\r\ngoto out;\r\nif (rc->rc_result & wait_status)\r\nbreak;\r\nif (delay < 1000)\r\ndelay += 20;\r\nmsleep(delay);\r\n}\r\n}\r\nout:\r\nreturn error;\r\n}\r\nstatic int wait_status_low(struct dlm_ls *ls, uint32_t wait_status)\r\n{\r\nstruct dlm_rcom *rc = ls->ls_recover_buf;\r\nint error = 0, delay = 0, nodeid = ls->ls_low_nodeid;\r\nfor (;;) {\r\nif (dlm_recovery_stopped(ls)) {\r\nerror = -EINTR;\r\ngoto out;\r\n}\r\nerror = dlm_rcom_status(ls, nodeid);\r\nif (error)\r\nbreak;\r\nif (rc->rc_result & wait_status)\r\nbreak;\r\nif (delay < 1000)\r\ndelay += 20;\r\nmsleep(delay);\r\n}\r\nout:\r\nreturn error;\r\n}\r\nstatic int wait_status(struct dlm_ls *ls, uint32_t status)\r\n{\r\nuint32_t status_all = status << 1;\r\nint error;\r\nif (ls->ls_low_nodeid == dlm_our_nodeid()) {\r\nerror = wait_status_all(ls, status);\r\nif (!error)\r\ndlm_set_recover_status(ls, status_all);\r\n} else\r\nerror = wait_status_low(ls, status_all);\r\nreturn error;\r\n}\r\nint dlm_recover_members_wait(struct dlm_ls *ls)\r\n{\r\nreturn wait_status(ls, DLM_RS_NODES);\r\n}\r\nint dlm_recover_directory_wait(struct dlm_ls *ls)\r\n{\r\nreturn wait_status(ls, DLM_RS_DIR);\r\n}\r\nint dlm_recover_locks_wait(struct dlm_ls *ls)\r\n{\r\nreturn wait_status(ls, DLM_RS_LOCKS);\r\n}\r\nint dlm_recover_done_wait(struct dlm_ls *ls)\r\n{\r\nreturn wait_status(ls, DLM_RS_DONE);\r\n}\r\nstatic int recover_list_empty(struct dlm_ls *ls)\r\n{\r\nint empty;\r\nspin_lock(&ls->ls_recover_list_lock);\r\nempty = list_empty(&ls->ls_recover_list);\r\nspin_unlock(&ls->ls_recover_list_lock);\r\nreturn empty;\r\n}\r\nstatic void recover_list_add(struct dlm_rsb *r)\r\n{\r\nstruct dlm_ls *ls = r->res_ls;\r\nspin_lock(&ls->ls_recover_list_lock);\r\nif (list_empty(&r->res_recover_list)) {\r\nlist_add_tail(&r->res_recover_list, &ls->ls_recover_list);\r\nls->ls_recover_list_count++;\r\ndlm_hold_rsb(r);\r\n}\r\nspin_unlock(&ls->ls_recover_list_lock);\r\n}\r\nstatic void recover_list_del(struct dlm_rsb *r)\r\n{\r\nstruct dlm_ls *ls = r->res_ls;\r\nspin_lock(&ls->ls_recover_list_lock);\r\nlist_del_init(&r->res_recover_list);\r\nls->ls_recover_list_count--;\r\nspin_unlock(&ls->ls_recover_list_lock);\r\ndlm_put_rsb(r);\r\n}\r\nstatic struct dlm_rsb *recover_list_find(struct dlm_ls *ls, uint64_t id)\r\n{\r\nstruct dlm_rsb *r = NULL;\r\nspin_lock(&ls->ls_recover_list_lock);\r\nlist_for_each_entry(r, &ls->ls_recover_list, res_recover_list) {\r\nif (id == (unsigned long) r)\r\ngoto out;\r\n}\r\nr = NULL;\r\nout:\r\nspin_unlock(&ls->ls_recover_list_lock);\r\nreturn r;\r\n}\r\nstatic void recover_list_clear(struct dlm_ls *ls)\r\n{\r\nstruct dlm_rsb *r, *s;\r\nspin_lock(&ls->ls_recover_list_lock);\r\nlist_for_each_entry_safe(r, s, &ls->ls_recover_list, res_recover_list) {\r\nlist_del_init(&r->res_recover_list);\r\nr->res_recover_locks_count = 0;\r\ndlm_put_rsb(r);\r\nls->ls_recover_list_count--;\r\n}\r\nif (ls->ls_recover_list_count != 0) {\r\nlog_error(ls, "warning: recover_list_count %d",\r\nls->ls_recover_list_count);\r\nls->ls_recover_list_count = 0;\r\n}\r\nspin_unlock(&ls->ls_recover_list_lock);\r\n}\r\nstatic void set_lock_master(struct list_head *queue, int nodeid)\r\n{\r\nstruct dlm_lkb *lkb;\r\nlist_for_each_entry(lkb, queue, lkb_statequeue)\r\nif (!(lkb->lkb_flags & DLM_IFL_MSTCPY))\r\nlkb->lkb_nodeid = nodeid;\r\n}\r\nstatic void set_master_lkbs(struct dlm_rsb *r)\r\n{\r\nset_lock_master(&r->res_grantqueue, r->res_nodeid);\r\nset_lock_master(&r->res_convertqueue, r->res_nodeid);\r\nset_lock_master(&r->res_waitqueue, r->res_nodeid);\r\n}\r\nstatic void set_new_master(struct dlm_rsb *r, int nodeid)\r\n{\r\nlock_rsb(r);\r\nr->res_nodeid = nodeid;\r\nset_master_lkbs(r);\r\nrsb_set_flag(r, RSB_NEW_MASTER);\r\nrsb_set_flag(r, RSB_NEW_MASTER2);\r\nunlock_rsb(r);\r\n}\r\nstatic int recover_master(struct dlm_rsb *r)\r\n{\r\nstruct dlm_ls *ls = r->res_ls;\r\nint error, dir_nodeid, ret_nodeid, our_nodeid = dlm_our_nodeid();\r\ndir_nodeid = dlm_dir_nodeid(r);\r\nif (dir_nodeid == our_nodeid) {\r\nerror = dlm_dir_lookup(ls, our_nodeid, r->res_name,\r\nr->res_length, &ret_nodeid);\r\nif (error)\r\nlog_error(ls, "recover dir lookup error %d", error);\r\nif (ret_nodeid == our_nodeid)\r\nret_nodeid = 0;\r\nset_new_master(r, ret_nodeid);\r\n} else {\r\nrecover_list_add(r);\r\nerror = dlm_send_rcom_lookup(r, dir_nodeid);\r\n}\r\nreturn error;\r\n}\r\nstatic int recover_master_static(struct dlm_rsb *r)\r\n{\r\nint master = dlm_dir_nodeid(r);\r\nif (master == dlm_our_nodeid())\r\nmaster = 0;\r\nif (r->res_nodeid != master) {\r\nif (is_master(r))\r\ndlm_purge_mstcpy_locks(r);\r\nset_new_master(r, master);\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nint dlm_recover_masters(struct dlm_ls *ls)\r\n{\r\nstruct dlm_rsb *r;\r\nint error = 0, count = 0;\r\nlog_debug(ls, "dlm_recover_masters");\r\ndown_read(&ls->ls_root_sem);\r\nlist_for_each_entry(r, &ls->ls_root_list, res_root_list) {\r\nif (dlm_recovery_stopped(ls)) {\r\nup_read(&ls->ls_root_sem);\r\nerror = -EINTR;\r\ngoto out;\r\n}\r\nif (dlm_no_directory(ls))\r\ncount += recover_master_static(r);\r\nelse if (!is_master(r) &&\r\n(dlm_is_removed(ls, r->res_nodeid) ||\r\nrsb_flag(r, RSB_NEW_MASTER))) {\r\nrecover_master(r);\r\ncount++;\r\n}\r\nschedule();\r\n}\r\nup_read(&ls->ls_root_sem);\r\nlog_debug(ls, "dlm_recover_masters %d resources", count);\r\nerror = dlm_wait_function(ls, &recover_list_empty);\r\nout:\r\nif (error)\r\nrecover_list_clear(ls);\r\nreturn error;\r\n}\r\nint dlm_recover_master_reply(struct dlm_ls *ls, struct dlm_rcom *rc)\r\n{\r\nstruct dlm_rsb *r;\r\nint nodeid;\r\nr = recover_list_find(ls, rc->rc_id);\r\nif (!r) {\r\nlog_error(ls, "dlm_recover_master_reply no id %llx",\r\n(unsigned long long)rc->rc_id);\r\ngoto out;\r\n}\r\nnodeid = rc->rc_result;\r\nif (nodeid == dlm_our_nodeid())\r\nnodeid = 0;\r\nset_new_master(r, nodeid);\r\nrecover_list_del(r);\r\nif (recover_list_empty(ls))\r\nwake_up(&ls->ls_wait_general);\r\nout:\r\nreturn 0;\r\n}\r\nstatic int recover_locks_queue(struct dlm_rsb *r, struct list_head *head)\r\n{\r\nstruct dlm_lkb *lkb;\r\nint error = 0;\r\nlist_for_each_entry(lkb, head, lkb_statequeue) {\r\nerror = dlm_send_rcom_lock(r, lkb);\r\nif (error)\r\nbreak;\r\nr->res_recover_locks_count++;\r\n}\r\nreturn error;\r\n}\r\nstatic int recover_locks(struct dlm_rsb *r)\r\n{\r\nint error = 0;\r\nlock_rsb(r);\r\nDLM_ASSERT(!r->res_recover_locks_count, dlm_dump_rsb(r););\r\nerror = recover_locks_queue(r, &r->res_grantqueue);\r\nif (error)\r\ngoto out;\r\nerror = recover_locks_queue(r, &r->res_convertqueue);\r\nif (error)\r\ngoto out;\r\nerror = recover_locks_queue(r, &r->res_waitqueue);\r\nif (error)\r\ngoto out;\r\nif (r->res_recover_locks_count)\r\nrecover_list_add(r);\r\nelse\r\nrsb_clear_flag(r, RSB_NEW_MASTER);\r\nout:\r\nunlock_rsb(r);\r\nreturn error;\r\n}\r\nint dlm_recover_locks(struct dlm_ls *ls)\r\n{\r\nstruct dlm_rsb *r;\r\nint error, count = 0;\r\nlog_debug(ls, "dlm_recover_locks");\r\ndown_read(&ls->ls_root_sem);\r\nlist_for_each_entry(r, &ls->ls_root_list, res_root_list) {\r\nif (is_master(r)) {\r\nrsb_clear_flag(r, RSB_NEW_MASTER);\r\ncontinue;\r\n}\r\nif (!rsb_flag(r, RSB_NEW_MASTER))\r\ncontinue;\r\nif (dlm_recovery_stopped(ls)) {\r\nerror = -EINTR;\r\nup_read(&ls->ls_root_sem);\r\ngoto out;\r\n}\r\nerror = recover_locks(r);\r\nif (error) {\r\nup_read(&ls->ls_root_sem);\r\ngoto out;\r\n}\r\ncount += r->res_recover_locks_count;\r\n}\r\nup_read(&ls->ls_root_sem);\r\nlog_debug(ls, "dlm_recover_locks %d locks", count);\r\nerror = dlm_wait_function(ls, &recover_list_empty);\r\nout:\r\nif (error)\r\nrecover_list_clear(ls);\r\nelse\r\ndlm_set_recover_status(ls, DLM_RS_LOCKS);\r\nreturn error;\r\n}\r\nvoid dlm_recovered_lock(struct dlm_rsb *r)\r\n{\r\nDLM_ASSERT(rsb_flag(r, RSB_NEW_MASTER), dlm_dump_rsb(r););\r\nr->res_recover_locks_count--;\r\nif (!r->res_recover_locks_count) {\r\nrsb_clear_flag(r, RSB_NEW_MASTER);\r\nrecover_list_del(r);\r\n}\r\nif (recover_list_empty(r->res_ls))\r\nwake_up(&r->res_ls->ls_wait_general);\r\n}\r\nstatic void recover_lvb(struct dlm_rsb *r)\r\n{\r\nstruct dlm_lkb *lkb, *high_lkb = NULL;\r\nuint32_t high_seq = 0;\r\nint lock_lvb_exists = 0;\r\nint big_lock_exists = 0;\r\nint lvblen = r->res_ls->ls_lvblen;\r\nlist_for_each_entry(lkb, &r->res_grantqueue, lkb_statequeue) {\r\nif (!(lkb->lkb_exflags & DLM_LKF_VALBLK))\r\ncontinue;\r\nlock_lvb_exists = 1;\r\nif (lkb->lkb_grmode > DLM_LOCK_CR) {\r\nbig_lock_exists = 1;\r\ngoto setflag;\r\n}\r\nif (((int)lkb->lkb_lvbseq - (int)high_seq) >= 0) {\r\nhigh_lkb = lkb;\r\nhigh_seq = lkb->lkb_lvbseq;\r\n}\r\n}\r\nlist_for_each_entry(lkb, &r->res_convertqueue, lkb_statequeue) {\r\nif (!(lkb->lkb_exflags & DLM_LKF_VALBLK))\r\ncontinue;\r\nlock_lvb_exists = 1;\r\nif (lkb->lkb_grmode > DLM_LOCK_CR) {\r\nbig_lock_exists = 1;\r\ngoto setflag;\r\n}\r\nif (((int)lkb->lkb_lvbseq - (int)high_seq) >= 0) {\r\nhigh_lkb = lkb;\r\nhigh_seq = lkb->lkb_lvbseq;\r\n}\r\n}\r\nsetflag:\r\nif (!lock_lvb_exists)\r\ngoto out;\r\nif (!big_lock_exists)\r\nrsb_set_flag(r, RSB_VALNOTVALID);\r\nif (!rsb_flag(r, RSB_NEW_MASTER2))\r\ngoto out;\r\nif (!r->res_lvbptr) {\r\nr->res_lvbptr = dlm_allocate_lvb(r->res_ls);\r\nif (!r->res_lvbptr)\r\ngoto out;\r\n}\r\nif (big_lock_exists) {\r\nr->res_lvbseq = lkb->lkb_lvbseq;\r\nmemcpy(r->res_lvbptr, lkb->lkb_lvbptr, lvblen);\r\n} else if (high_lkb) {\r\nr->res_lvbseq = high_lkb->lkb_lvbseq;\r\nmemcpy(r->res_lvbptr, high_lkb->lkb_lvbptr, lvblen);\r\n} else {\r\nr->res_lvbseq = 0;\r\nmemset(r->res_lvbptr, 0, lvblen);\r\n}\r\nout:\r\nreturn;\r\n}\r\nstatic void recover_conversion(struct dlm_rsb *r)\r\n{\r\nstruct dlm_lkb *lkb;\r\nint grmode = -1;\r\nlist_for_each_entry(lkb, &r->res_grantqueue, lkb_statequeue) {\r\nif (lkb->lkb_grmode == DLM_LOCK_PR ||\r\nlkb->lkb_grmode == DLM_LOCK_CW) {\r\ngrmode = lkb->lkb_grmode;\r\nbreak;\r\n}\r\n}\r\nlist_for_each_entry(lkb, &r->res_convertqueue, lkb_statequeue) {\r\nif (lkb->lkb_grmode != DLM_LOCK_IV)\r\ncontinue;\r\nif (grmode == -1)\r\nlkb->lkb_grmode = lkb->lkb_rqmode;\r\nelse\r\nlkb->lkb_grmode = grmode;\r\n}\r\n}\r\nstatic void set_locks_purged(struct dlm_rsb *r)\r\n{\r\nif (!list_empty(&r->res_waitqueue) || !list_empty(&r->res_convertqueue))\r\nrsb_set_flag(r, RSB_LOCKS_PURGED);\r\n}\r\nvoid dlm_recover_rsbs(struct dlm_ls *ls)\r\n{\r\nstruct dlm_rsb *r;\r\nint count = 0;\r\nlog_debug(ls, "dlm_recover_rsbs");\r\ndown_read(&ls->ls_root_sem);\r\nlist_for_each_entry(r, &ls->ls_root_list, res_root_list) {\r\nlock_rsb(r);\r\nif (is_master(r)) {\r\nif (rsb_flag(r, RSB_RECOVER_CONVERT))\r\nrecover_conversion(r);\r\nif (rsb_flag(r, RSB_NEW_MASTER2))\r\nset_locks_purged(r);\r\nrecover_lvb(r);\r\ncount++;\r\n}\r\nrsb_clear_flag(r, RSB_RECOVER_CONVERT);\r\nrsb_clear_flag(r, RSB_NEW_MASTER2);\r\nunlock_rsb(r);\r\n}\r\nup_read(&ls->ls_root_sem);\r\nlog_debug(ls, "dlm_recover_rsbs %d rsbs", count);\r\n}\r\nint dlm_create_root_list(struct dlm_ls *ls)\r\n{\r\nstruct dlm_rsb *r;\r\nint i, error = 0;\r\ndown_write(&ls->ls_root_sem);\r\nif (!list_empty(&ls->ls_root_list)) {\r\nlog_error(ls, "root list not empty");\r\nerror = -EINVAL;\r\ngoto out;\r\n}\r\nfor (i = 0; i < ls->ls_rsbtbl_size; i++) {\r\nspin_lock(&ls->ls_rsbtbl[i].lock);\r\nlist_for_each_entry(r, &ls->ls_rsbtbl[i].list, res_hashchain) {\r\nlist_add(&r->res_root_list, &ls->ls_root_list);\r\ndlm_hold_rsb(r);\r\n}\r\nif (dlm_no_directory(ls)) {\r\nspin_unlock(&ls->ls_rsbtbl[i].lock);\r\ncontinue;\r\n}\r\nlist_for_each_entry(r, &ls->ls_rsbtbl[i].toss, res_hashchain) {\r\nlist_add(&r->res_root_list, &ls->ls_root_list);\r\ndlm_hold_rsb(r);\r\n}\r\nspin_unlock(&ls->ls_rsbtbl[i].lock);\r\n}\r\nout:\r\nup_write(&ls->ls_root_sem);\r\nreturn error;\r\n}\r\nvoid dlm_release_root_list(struct dlm_ls *ls)\r\n{\r\nstruct dlm_rsb *r, *safe;\r\ndown_write(&ls->ls_root_sem);\r\nlist_for_each_entry_safe(r, safe, &ls->ls_root_list, res_root_list) {\r\nlist_del_init(&r->res_root_list);\r\ndlm_put_rsb(r);\r\n}\r\nup_write(&ls->ls_root_sem);\r\n}\r\nvoid dlm_clear_toss_list(struct dlm_ls *ls)\r\n{\r\nstruct dlm_rsb *r, *safe;\r\nint i;\r\nfor (i = 0; i < ls->ls_rsbtbl_size; i++) {\r\nspin_lock(&ls->ls_rsbtbl[i].lock);\r\nlist_for_each_entry_safe(r, safe, &ls->ls_rsbtbl[i].toss,\r\nres_hashchain) {\r\nif (dlm_no_directory(ls) || !is_master(r)) {\r\nlist_del(&r->res_hashchain);\r\ndlm_free_rsb(r);\r\n}\r\n}\r\nspin_unlock(&ls->ls_rsbtbl[i].lock);\r\n}\r\n}
