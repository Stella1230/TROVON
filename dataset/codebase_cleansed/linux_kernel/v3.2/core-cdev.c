static inline void client_get(struct client *client)\r\n{\r\nkref_get(&client->kref);\r\n}\r\nstatic void client_release(struct kref *kref)\r\n{\r\nstruct client *client = container_of(kref, struct client, kref);\r\nfw_device_put(client->device);\r\nkfree(client);\r\n}\r\nstatic void client_put(struct client *client)\r\n{\r\nkref_put(&client->kref, client_release);\r\n}\r\nstatic void schedule_iso_resource(struct iso_resource *r, unsigned long delay)\r\n{\r\nclient_get(r->client);\r\nif (!queue_delayed_work(fw_workqueue, &r->work, delay))\r\nclient_put(r->client);\r\n}\r\nstatic void schedule_if_iso_resource(struct client_resource *resource)\r\n{\r\nif (resource->release == release_iso_resource)\r\nschedule_iso_resource(container_of(resource,\r\nstruct iso_resource, resource), 0);\r\n}\r\nstatic void __user *u64_to_uptr(u64 value)\r\n{\r\nif (is_compat_task())\r\nreturn compat_ptr(value);\r\nelse\r\nreturn (void __user *)(unsigned long)value;\r\n}\r\nstatic u64 uptr_to_u64(void __user *ptr)\r\n{\r\nif (is_compat_task())\r\nreturn ptr_to_compat(ptr);\r\nelse\r\nreturn (u64)(unsigned long)ptr;\r\n}\r\nstatic inline void __user *u64_to_uptr(u64 value)\r\n{\r\nreturn (void __user *)(unsigned long)value;\r\n}\r\nstatic inline u64 uptr_to_u64(void __user *ptr)\r\n{\r\nreturn (u64)(unsigned long)ptr;\r\n}\r\nstatic int fw_device_op_open(struct inode *inode, struct file *file)\r\n{\r\nstruct fw_device *device;\r\nstruct client *client;\r\ndevice = fw_device_get_by_devt(inode->i_rdev);\r\nif (device == NULL)\r\nreturn -ENODEV;\r\nif (fw_device_is_shutdown(device)) {\r\nfw_device_put(device);\r\nreturn -ENODEV;\r\n}\r\nclient = kzalloc(sizeof(*client), GFP_KERNEL);\r\nif (client == NULL) {\r\nfw_device_put(device);\r\nreturn -ENOMEM;\r\n}\r\nclient->device = device;\r\nspin_lock_init(&client->lock);\r\nidr_init(&client->resource_idr);\r\nINIT_LIST_HEAD(&client->event_list);\r\ninit_waitqueue_head(&client->wait);\r\ninit_waitqueue_head(&client->tx_flush_wait);\r\nINIT_LIST_HEAD(&client->phy_receiver_link);\r\nINIT_LIST_HEAD(&client->link);\r\nkref_init(&client->kref);\r\nfile->private_data = client;\r\nreturn nonseekable_open(inode, file);\r\n}\r\nstatic void queue_event(struct client *client, struct event *event,\r\nvoid *data0, size_t size0, void *data1, size_t size1)\r\n{\r\nunsigned long flags;\r\nevent->v[0].data = data0;\r\nevent->v[0].size = size0;\r\nevent->v[1].data = data1;\r\nevent->v[1].size = size1;\r\nspin_lock_irqsave(&client->lock, flags);\r\nif (client->in_shutdown)\r\nkfree(event);\r\nelse\r\nlist_add_tail(&event->link, &client->event_list);\r\nspin_unlock_irqrestore(&client->lock, flags);\r\nwake_up_interruptible(&client->wait);\r\n}\r\nstatic int dequeue_event(struct client *client,\r\nchar __user *buffer, size_t count)\r\n{\r\nstruct event *event;\r\nsize_t size, total;\r\nint i, ret;\r\nret = wait_event_interruptible(client->wait,\r\n!list_empty(&client->event_list) ||\r\nfw_device_is_shutdown(client->device));\r\nif (ret < 0)\r\nreturn ret;\r\nif (list_empty(&client->event_list) &&\r\nfw_device_is_shutdown(client->device))\r\nreturn -ENODEV;\r\nspin_lock_irq(&client->lock);\r\nevent = list_first_entry(&client->event_list, struct event, link);\r\nlist_del(&event->link);\r\nspin_unlock_irq(&client->lock);\r\ntotal = 0;\r\nfor (i = 0; i < ARRAY_SIZE(event->v) && total < count; i++) {\r\nsize = min(event->v[i].size, count - total);\r\nif (copy_to_user(buffer + total, event->v[i].data, size)) {\r\nret = -EFAULT;\r\ngoto out;\r\n}\r\ntotal += size;\r\n}\r\nret = total;\r\nout:\r\nkfree(event);\r\nreturn ret;\r\n}\r\nstatic ssize_t fw_device_op_read(struct file *file, char __user *buffer,\r\nsize_t count, loff_t *offset)\r\n{\r\nstruct client *client = file->private_data;\r\nreturn dequeue_event(client, buffer, count);\r\n}\r\nstatic void fill_bus_reset_event(struct fw_cdev_event_bus_reset *event,\r\nstruct client *client)\r\n{\r\nstruct fw_card *card = client->device->card;\r\nspin_lock_irq(&card->lock);\r\nevent->closure = client->bus_reset_closure;\r\nevent->type = FW_CDEV_EVENT_BUS_RESET;\r\nevent->generation = client->device->generation;\r\nevent->node_id = client->device->node_id;\r\nevent->local_node_id = card->local_node->node_id;\r\nevent->bm_node_id = card->bm_node_id;\r\nevent->irm_node_id = card->irm_node->node_id;\r\nevent->root_node_id = card->root_node->node_id;\r\nspin_unlock_irq(&card->lock);\r\n}\r\nstatic void for_each_client(struct fw_device *device,\r\nvoid (*callback)(struct client *client))\r\n{\r\nstruct client *c;\r\nmutex_lock(&device->client_list_mutex);\r\nlist_for_each_entry(c, &device->client_list, link)\r\ncallback(c);\r\nmutex_unlock(&device->client_list_mutex);\r\n}\r\nstatic int schedule_reallocations(int id, void *p, void *data)\r\n{\r\nschedule_if_iso_resource(p);\r\nreturn 0;\r\n}\r\nstatic void queue_bus_reset_event(struct client *client)\r\n{\r\nstruct bus_reset_event *e;\r\ne = kzalloc(sizeof(*e), GFP_KERNEL);\r\nif (e == NULL) {\r\nfw_notify("Out of memory when allocating event\n");\r\nreturn;\r\n}\r\nfill_bus_reset_event(&e->reset, client);\r\nqueue_event(client, &e->event,\r\n&e->reset, sizeof(e->reset), NULL, 0);\r\nspin_lock_irq(&client->lock);\r\nidr_for_each(&client->resource_idr, schedule_reallocations, client);\r\nspin_unlock_irq(&client->lock);\r\n}\r\nvoid fw_device_cdev_update(struct fw_device *device)\r\n{\r\nfor_each_client(device, queue_bus_reset_event);\r\n}\r\nstatic void wake_up_client(struct client *client)\r\n{\r\nwake_up_interruptible(&client->wait);\r\n}\r\nvoid fw_device_cdev_remove(struct fw_device *device)\r\n{\r\nfor_each_client(device, wake_up_client);\r\n}\r\nstatic int ioctl_get_info(struct client *client, union ioctl_arg *arg)\r\n{\r\nstruct fw_cdev_get_info *a = &arg->get_info;\r\nstruct fw_cdev_event_bus_reset bus_reset;\r\nunsigned long ret = 0;\r\nclient->version = a->version;\r\na->version = FW_CDEV_KERNEL_VERSION;\r\na->card = client->device->card->index;\r\ndown_read(&fw_device_rwsem);\r\nif (a->rom != 0) {\r\nsize_t want = a->rom_length;\r\nsize_t have = client->device->config_rom_length * 4;\r\nret = copy_to_user(u64_to_uptr(a->rom),\r\nclient->device->config_rom, min(want, have));\r\n}\r\na->rom_length = client->device->config_rom_length * 4;\r\nup_read(&fw_device_rwsem);\r\nif (ret != 0)\r\nreturn -EFAULT;\r\nmutex_lock(&client->device->client_list_mutex);\r\nclient->bus_reset_closure = a->bus_reset_closure;\r\nif (a->bus_reset != 0) {\r\nfill_bus_reset_event(&bus_reset, client);\r\nret = copy_to_user(u64_to_uptr(a->bus_reset),\r\n&bus_reset, sizeof(bus_reset));\r\n}\r\nif (ret == 0 && list_empty(&client->link))\r\nlist_add_tail(&client->link, &client->device->client_list);\r\nmutex_unlock(&client->device->client_list_mutex);\r\nreturn ret ? -EFAULT : 0;\r\n}\r\nstatic int add_client_resource(struct client *client,\r\nstruct client_resource *resource, gfp_t gfp_mask)\r\n{\r\nunsigned long flags;\r\nint ret;\r\nretry:\r\nif (idr_pre_get(&client->resource_idr, gfp_mask) == 0)\r\nreturn -ENOMEM;\r\nspin_lock_irqsave(&client->lock, flags);\r\nif (client->in_shutdown)\r\nret = -ECANCELED;\r\nelse\r\nret = idr_get_new(&client->resource_idr, resource,\r\n&resource->handle);\r\nif (ret >= 0) {\r\nclient_get(client);\r\nschedule_if_iso_resource(resource);\r\n}\r\nspin_unlock_irqrestore(&client->lock, flags);\r\nif (ret == -EAGAIN)\r\ngoto retry;\r\nreturn ret < 0 ? ret : 0;\r\n}\r\nstatic int release_client_resource(struct client *client, u32 handle,\r\nclient_resource_release_fn_t release,\r\nstruct client_resource **return_resource)\r\n{\r\nstruct client_resource *resource;\r\nspin_lock_irq(&client->lock);\r\nif (client->in_shutdown)\r\nresource = NULL;\r\nelse\r\nresource = idr_find(&client->resource_idr, handle);\r\nif (resource && resource->release == release)\r\nidr_remove(&client->resource_idr, handle);\r\nspin_unlock_irq(&client->lock);\r\nif (!(resource && resource->release == release))\r\nreturn -EINVAL;\r\nif (return_resource)\r\n*return_resource = resource;\r\nelse\r\nresource->release(client, resource);\r\nclient_put(client);\r\nreturn 0;\r\n}\r\nstatic void release_transaction(struct client *client,\r\nstruct client_resource *resource)\r\n{\r\n}\r\nstatic void complete_transaction(struct fw_card *card, int rcode,\r\nvoid *payload, size_t length, void *data)\r\n{\r\nstruct outbound_transaction_event *e = data;\r\nstruct fw_cdev_event_response *rsp = &e->response;\r\nstruct client *client = e->client;\r\nunsigned long flags;\r\nif (length < rsp->length)\r\nrsp->length = length;\r\nif (rcode == RCODE_COMPLETE)\r\nmemcpy(rsp->data, payload, rsp->length);\r\nspin_lock_irqsave(&client->lock, flags);\r\nidr_remove(&client->resource_idr, e->r.resource.handle);\r\nif (client->in_shutdown)\r\nwake_up(&client->tx_flush_wait);\r\nspin_unlock_irqrestore(&client->lock, flags);\r\nrsp->type = FW_CDEV_EVENT_RESPONSE;\r\nrsp->rcode = rcode;\r\nif (rsp->length <= sizeof(*rsp) - offsetof(typeof(*rsp), data))\r\nqueue_event(client, &e->event, rsp, sizeof(*rsp),\r\nrsp->data, rsp->length);\r\nelse\r\nqueue_event(client, &e->event, rsp, sizeof(*rsp) + rsp->length,\r\nNULL, 0);\r\nclient_put(client);\r\n}\r\nstatic int init_request(struct client *client,\r\nstruct fw_cdev_send_request *request,\r\nint destination_id, int speed)\r\n{\r\nstruct outbound_transaction_event *e;\r\nint ret;\r\nif (request->tcode != TCODE_STREAM_DATA &&\r\n(request->length > 4096 || request->length > 512 << speed))\r\nreturn -EIO;\r\nif (request->tcode == TCODE_WRITE_QUADLET_REQUEST &&\r\nrequest->length < 4)\r\nreturn -EINVAL;\r\ne = kmalloc(sizeof(*e) + request->length, GFP_KERNEL);\r\nif (e == NULL)\r\nreturn -ENOMEM;\r\ne->client = client;\r\ne->response.length = request->length;\r\ne->response.closure = request->closure;\r\nif (request->data &&\r\ncopy_from_user(e->response.data,\r\nu64_to_uptr(request->data), request->length)) {\r\nret = -EFAULT;\r\ngoto failed;\r\n}\r\ne->r.resource.release = release_transaction;\r\nret = add_client_resource(client, &e->r.resource, GFP_KERNEL);\r\nif (ret < 0)\r\ngoto failed;\r\nfw_send_request(client->device->card, &e->r.transaction,\r\nrequest->tcode, destination_id, request->generation,\r\nspeed, request->offset, e->response.data,\r\nrequest->length, complete_transaction, e);\r\nreturn 0;\r\nfailed:\r\nkfree(e);\r\nreturn ret;\r\n}\r\nstatic int ioctl_send_request(struct client *client, union ioctl_arg *arg)\r\n{\r\nswitch (arg->send_request.tcode) {\r\ncase TCODE_WRITE_QUADLET_REQUEST:\r\ncase TCODE_WRITE_BLOCK_REQUEST:\r\ncase TCODE_READ_QUADLET_REQUEST:\r\ncase TCODE_READ_BLOCK_REQUEST:\r\ncase TCODE_LOCK_MASK_SWAP:\r\ncase TCODE_LOCK_COMPARE_SWAP:\r\ncase TCODE_LOCK_FETCH_ADD:\r\ncase TCODE_LOCK_LITTLE_ADD:\r\ncase TCODE_LOCK_BOUNDED_ADD:\r\ncase TCODE_LOCK_WRAP_ADD:\r\ncase TCODE_LOCK_VENDOR_DEPENDENT:\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn init_request(client, &arg->send_request, client->device->node_id,\r\nclient->device->max_speed);\r\n}\r\nstatic inline bool is_fcp_request(struct fw_request *request)\r\n{\r\nreturn request == NULL;\r\n}\r\nstatic void release_request(struct client *client,\r\nstruct client_resource *resource)\r\n{\r\nstruct inbound_transaction_resource *r = container_of(resource,\r\nstruct inbound_transaction_resource, resource);\r\nif (is_fcp_request(r->request))\r\nkfree(r->data);\r\nelse\r\nfw_send_response(r->card, r->request, RCODE_CONFLICT_ERROR);\r\nfw_card_put(r->card);\r\nkfree(r);\r\n}\r\nstatic void handle_request(struct fw_card *card, struct fw_request *request,\r\nint tcode, int destination, int source,\r\nint generation, unsigned long long offset,\r\nvoid *payload, size_t length, void *callback_data)\r\n{\r\nstruct address_handler_resource *handler = callback_data;\r\nstruct inbound_transaction_resource *r;\r\nstruct inbound_transaction_event *e;\r\nsize_t event_size0;\r\nvoid *fcp_frame = NULL;\r\nint ret;\r\nfw_card_get(card);\r\nr = kmalloc(sizeof(*r), GFP_ATOMIC);\r\ne = kmalloc(sizeof(*e), GFP_ATOMIC);\r\nif (r == NULL || e == NULL) {\r\nfw_notify("Out of memory when allocating event\n");\r\ngoto failed;\r\n}\r\nr->card = card;\r\nr->request = request;\r\nr->data = payload;\r\nr->length = length;\r\nif (is_fcp_request(request)) {\r\nfcp_frame = kmemdup(payload, length, GFP_ATOMIC);\r\nif (fcp_frame == NULL)\r\ngoto failed;\r\nr->data = fcp_frame;\r\n}\r\nr->resource.release = release_request;\r\nret = add_client_resource(handler->client, &r->resource, GFP_ATOMIC);\r\nif (ret < 0)\r\ngoto failed;\r\nif (handler->client->version < FW_CDEV_VERSION_EVENT_REQUEST2) {\r\nstruct fw_cdev_event_request *req = &e->req.request;\r\nif (tcode & 0x10)\r\ntcode = TCODE_LOCK_REQUEST;\r\nreq->type = FW_CDEV_EVENT_REQUEST;\r\nreq->tcode = tcode;\r\nreq->offset = offset;\r\nreq->length = length;\r\nreq->handle = r->resource.handle;\r\nreq->closure = handler->closure;\r\nevent_size0 = sizeof(*req);\r\n} else {\r\nstruct fw_cdev_event_request2 *req = &e->req.request2;\r\nreq->type = FW_CDEV_EVENT_REQUEST2;\r\nreq->tcode = tcode;\r\nreq->offset = offset;\r\nreq->source_node_id = source;\r\nreq->destination_node_id = destination;\r\nreq->card = card->index;\r\nreq->generation = generation;\r\nreq->length = length;\r\nreq->handle = r->resource.handle;\r\nreq->closure = handler->closure;\r\nevent_size0 = sizeof(*req);\r\n}\r\nqueue_event(handler->client, &e->event,\r\n&e->req, event_size0, r->data, length);\r\nreturn;\r\nfailed:\r\nkfree(r);\r\nkfree(e);\r\nkfree(fcp_frame);\r\nif (!is_fcp_request(request))\r\nfw_send_response(card, request, RCODE_CONFLICT_ERROR);\r\nfw_card_put(card);\r\n}\r\nstatic void release_address_handler(struct client *client,\r\nstruct client_resource *resource)\r\n{\r\nstruct address_handler_resource *r =\r\ncontainer_of(resource, struct address_handler_resource, resource);\r\nfw_core_remove_address_handler(&r->handler);\r\nkfree(r);\r\n}\r\nstatic int ioctl_allocate(struct client *client, union ioctl_arg *arg)\r\n{\r\nstruct fw_cdev_allocate *a = &arg->allocate;\r\nstruct address_handler_resource *r;\r\nstruct fw_address_region region;\r\nint ret;\r\nr = kmalloc(sizeof(*r), GFP_KERNEL);\r\nif (r == NULL)\r\nreturn -ENOMEM;\r\nregion.start = a->offset;\r\nif (client->version < FW_CDEV_VERSION_ALLOCATE_REGION_END)\r\nregion.end = a->offset + a->length;\r\nelse\r\nregion.end = a->region_end;\r\nr->handler.length = a->length;\r\nr->handler.address_callback = handle_request;\r\nr->handler.callback_data = r;\r\nr->closure = a->closure;\r\nr->client = client;\r\nret = fw_core_add_address_handler(&r->handler, &region);\r\nif (ret < 0) {\r\nkfree(r);\r\nreturn ret;\r\n}\r\na->offset = r->handler.offset;\r\nr->resource.release = release_address_handler;\r\nret = add_client_resource(client, &r->resource, GFP_KERNEL);\r\nif (ret < 0) {\r\nrelease_address_handler(client, &r->resource);\r\nreturn ret;\r\n}\r\na->handle = r->resource.handle;\r\nreturn 0;\r\n}\r\nstatic int ioctl_deallocate(struct client *client, union ioctl_arg *arg)\r\n{\r\nreturn release_client_resource(client, arg->deallocate.handle,\r\nrelease_address_handler, NULL);\r\n}\r\nstatic int ioctl_send_response(struct client *client, union ioctl_arg *arg)\r\n{\r\nstruct fw_cdev_send_response *a = &arg->send_response;\r\nstruct client_resource *resource;\r\nstruct inbound_transaction_resource *r;\r\nint ret = 0;\r\nif (release_client_resource(client, a->handle,\r\nrelease_request, &resource) < 0)\r\nreturn -EINVAL;\r\nr = container_of(resource, struct inbound_transaction_resource,\r\nresource);\r\nif (is_fcp_request(r->request))\r\ngoto out;\r\nif (a->length != fw_get_response_length(r->request)) {\r\nret = -EINVAL;\r\nkfree(r->request);\r\ngoto out;\r\n}\r\nif (copy_from_user(r->data, u64_to_uptr(a->data), a->length)) {\r\nret = -EFAULT;\r\nkfree(r->request);\r\ngoto out;\r\n}\r\nfw_send_response(r->card, r->request, a->rcode);\r\nout:\r\nfw_card_put(r->card);\r\nkfree(r);\r\nreturn ret;\r\n}\r\nstatic int ioctl_initiate_bus_reset(struct client *client, union ioctl_arg *arg)\r\n{\r\nfw_schedule_bus_reset(client->device->card, true,\r\narg->initiate_bus_reset.type == FW_CDEV_SHORT_RESET);\r\nreturn 0;\r\n}\r\nstatic void release_descriptor(struct client *client,\r\nstruct client_resource *resource)\r\n{\r\nstruct descriptor_resource *r =\r\ncontainer_of(resource, struct descriptor_resource, resource);\r\nfw_core_remove_descriptor(&r->descriptor);\r\nkfree(r);\r\n}\r\nstatic int ioctl_add_descriptor(struct client *client, union ioctl_arg *arg)\r\n{\r\nstruct fw_cdev_add_descriptor *a = &arg->add_descriptor;\r\nstruct descriptor_resource *r;\r\nint ret;\r\nif (!client->device->is_local)\r\nreturn -ENOSYS;\r\nif (a->length > 256)\r\nreturn -EINVAL;\r\nr = kmalloc(sizeof(*r) + a->length * 4, GFP_KERNEL);\r\nif (r == NULL)\r\nreturn -ENOMEM;\r\nif (copy_from_user(r->data, u64_to_uptr(a->data), a->length * 4)) {\r\nret = -EFAULT;\r\ngoto failed;\r\n}\r\nr->descriptor.length = a->length;\r\nr->descriptor.immediate = a->immediate;\r\nr->descriptor.key = a->key;\r\nr->descriptor.data = r->data;\r\nret = fw_core_add_descriptor(&r->descriptor);\r\nif (ret < 0)\r\ngoto failed;\r\nr->resource.release = release_descriptor;\r\nret = add_client_resource(client, &r->resource, GFP_KERNEL);\r\nif (ret < 0) {\r\nfw_core_remove_descriptor(&r->descriptor);\r\ngoto failed;\r\n}\r\na->handle = r->resource.handle;\r\nreturn 0;\r\nfailed:\r\nkfree(r);\r\nreturn ret;\r\n}\r\nstatic int ioctl_remove_descriptor(struct client *client, union ioctl_arg *arg)\r\n{\r\nreturn release_client_resource(client, arg->remove_descriptor.handle,\r\nrelease_descriptor, NULL);\r\n}\r\nstatic void iso_callback(struct fw_iso_context *context, u32 cycle,\r\nsize_t header_length, void *header, void *data)\r\n{\r\nstruct client *client = data;\r\nstruct iso_interrupt_event *e;\r\ne = kmalloc(sizeof(*e) + header_length, GFP_ATOMIC);\r\nif (e == NULL) {\r\nfw_notify("Out of memory when allocating event\n");\r\nreturn;\r\n}\r\ne->interrupt.type = FW_CDEV_EVENT_ISO_INTERRUPT;\r\ne->interrupt.closure = client->iso_closure;\r\ne->interrupt.cycle = cycle;\r\ne->interrupt.header_length = header_length;\r\nmemcpy(e->interrupt.header, header, header_length);\r\nqueue_event(client, &e->event, &e->interrupt,\r\nsizeof(e->interrupt) + header_length, NULL, 0);\r\n}\r\nstatic void iso_mc_callback(struct fw_iso_context *context,\r\ndma_addr_t completed, void *data)\r\n{\r\nstruct client *client = data;\r\nstruct iso_interrupt_mc_event *e;\r\ne = kmalloc(sizeof(*e), GFP_ATOMIC);\r\nif (e == NULL) {\r\nfw_notify("Out of memory when allocating event\n");\r\nreturn;\r\n}\r\ne->interrupt.type = FW_CDEV_EVENT_ISO_INTERRUPT_MULTICHANNEL;\r\ne->interrupt.closure = client->iso_closure;\r\ne->interrupt.completed = fw_iso_buffer_lookup(&client->buffer,\r\ncompleted);\r\nqueue_event(client, &e->event, &e->interrupt,\r\nsizeof(e->interrupt), NULL, 0);\r\n}\r\nstatic int ioctl_create_iso_context(struct client *client, union ioctl_arg *arg)\r\n{\r\nstruct fw_cdev_create_iso_context *a = &arg->create_iso_context;\r\nstruct fw_iso_context *context;\r\nfw_iso_callback_t cb;\r\nBUILD_BUG_ON(FW_CDEV_ISO_CONTEXT_TRANSMIT != FW_ISO_CONTEXT_TRANSMIT ||\r\nFW_CDEV_ISO_CONTEXT_RECEIVE != FW_ISO_CONTEXT_RECEIVE ||\r\nFW_CDEV_ISO_CONTEXT_RECEIVE_MULTICHANNEL !=\r\nFW_ISO_CONTEXT_RECEIVE_MULTICHANNEL);\r\nswitch (a->type) {\r\ncase FW_ISO_CONTEXT_TRANSMIT:\r\nif (a->speed > SCODE_3200 || a->channel > 63)\r\nreturn -EINVAL;\r\ncb = iso_callback;\r\nbreak;\r\ncase FW_ISO_CONTEXT_RECEIVE:\r\nif (a->header_size < 4 || (a->header_size & 3) ||\r\na->channel > 63)\r\nreturn -EINVAL;\r\ncb = iso_callback;\r\nbreak;\r\ncase FW_ISO_CONTEXT_RECEIVE_MULTICHANNEL:\r\ncb = (fw_iso_callback_t)iso_mc_callback;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\ncontext = fw_iso_context_create(client->device->card, a->type,\r\na->channel, a->speed, a->header_size, cb, client);\r\nif (IS_ERR(context))\r\nreturn PTR_ERR(context);\r\nspin_lock_irq(&client->lock);\r\nif (client->iso_context != NULL) {\r\nspin_unlock_irq(&client->lock);\r\nfw_iso_context_destroy(context);\r\nreturn -EBUSY;\r\n}\r\nclient->iso_closure = a->closure;\r\nclient->iso_context = context;\r\nspin_unlock_irq(&client->lock);\r\na->handle = 0;\r\nreturn 0;\r\n}\r\nstatic int ioctl_set_iso_channels(struct client *client, union ioctl_arg *arg)\r\n{\r\nstruct fw_cdev_set_iso_channels *a = &arg->set_iso_channels;\r\nstruct fw_iso_context *ctx = client->iso_context;\r\nif (ctx == NULL || a->handle != 0)\r\nreturn -EINVAL;\r\nreturn fw_iso_context_set_channels(ctx, &a->channels);\r\n}\r\nstatic int ioctl_queue_iso(struct client *client, union ioctl_arg *arg)\r\n{\r\nstruct fw_cdev_queue_iso *a = &arg->queue_iso;\r\nstruct fw_cdev_iso_packet __user *p, *end, *next;\r\nstruct fw_iso_context *ctx = client->iso_context;\r\nunsigned long payload, buffer_end, transmit_header_bytes = 0;\r\nu32 control;\r\nint count;\r\nstruct {\r\nstruct fw_iso_packet packet;\r\nu8 header[256];\r\n} u;\r\nif (ctx == NULL || a->handle != 0)\r\nreturn -EINVAL;\r\npayload = (unsigned long)a->data - client->vm_start;\r\nbuffer_end = client->buffer.page_count << PAGE_SHIFT;\r\nif (a->data == 0 || client->buffer.pages == NULL ||\r\npayload >= buffer_end) {\r\npayload = 0;\r\nbuffer_end = 0;\r\n}\r\nif (ctx->type == FW_ISO_CONTEXT_RECEIVE_MULTICHANNEL && payload & 3)\r\nreturn -EINVAL;\r\np = (struct fw_cdev_iso_packet __user *)u64_to_uptr(a->packets);\r\nif (!access_ok(VERIFY_READ, p, a->size))\r\nreturn -EFAULT;\r\nend = (void __user *)p + a->size;\r\ncount = 0;\r\nwhile (p < end) {\r\nif (get_user(control, &p->control))\r\nreturn -EFAULT;\r\nu.packet.payload_length = GET_PAYLOAD_LENGTH(control);\r\nu.packet.interrupt = GET_INTERRUPT(control);\r\nu.packet.skip = GET_SKIP(control);\r\nu.packet.tag = GET_TAG(control);\r\nu.packet.sy = GET_SY(control);\r\nu.packet.header_length = GET_HEADER_LENGTH(control);\r\nswitch (ctx->type) {\r\ncase FW_ISO_CONTEXT_TRANSMIT:\r\nif (u.packet.header_length & 3)\r\nreturn -EINVAL;\r\ntransmit_header_bytes = u.packet.header_length;\r\nbreak;\r\ncase FW_ISO_CONTEXT_RECEIVE:\r\nif (u.packet.header_length == 0 ||\r\nu.packet.header_length % ctx->header_size != 0)\r\nreturn -EINVAL;\r\nbreak;\r\ncase FW_ISO_CONTEXT_RECEIVE_MULTICHANNEL:\r\nif (u.packet.payload_length == 0 ||\r\nu.packet.payload_length & 3)\r\nreturn -EINVAL;\r\nbreak;\r\n}\r\nnext = (struct fw_cdev_iso_packet __user *)\r\n&p->header[transmit_header_bytes / 4];\r\nif (next > end)\r\nreturn -EINVAL;\r\nif (__copy_from_user\r\n(u.packet.header, p->header, transmit_header_bytes))\r\nreturn -EFAULT;\r\nif (u.packet.skip && ctx->type == FW_ISO_CONTEXT_TRANSMIT &&\r\nu.packet.header_length + u.packet.payload_length > 0)\r\nreturn -EINVAL;\r\nif (payload + u.packet.payload_length > buffer_end)\r\nreturn -EINVAL;\r\nif (fw_iso_context_queue(ctx, &u.packet,\r\n&client->buffer, payload))\r\nbreak;\r\np = next;\r\npayload += u.packet.payload_length;\r\ncount++;\r\n}\r\nfw_iso_context_queue_flush(ctx);\r\na->size -= uptr_to_u64(p) - a->packets;\r\na->packets = uptr_to_u64(p);\r\na->data = client->vm_start + payload;\r\nreturn count;\r\n}\r\nstatic int ioctl_start_iso(struct client *client, union ioctl_arg *arg)\r\n{\r\nstruct fw_cdev_start_iso *a = &arg->start_iso;\r\nBUILD_BUG_ON(\r\nFW_CDEV_ISO_CONTEXT_MATCH_TAG0 != FW_ISO_CONTEXT_MATCH_TAG0 ||\r\nFW_CDEV_ISO_CONTEXT_MATCH_TAG1 != FW_ISO_CONTEXT_MATCH_TAG1 ||\r\nFW_CDEV_ISO_CONTEXT_MATCH_TAG2 != FW_ISO_CONTEXT_MATCH_TAG2 ||\r\nFW_CDEV_ISO_CONTEXT_MATCH_TAG3 != FW_ISO_CONTEXT_MATCH_TAG3 ||\r\nFW_CDEV_ISO_CONTEXT_MATCH_ALL_TAGS != FW_ISO_CONTEXT_MATCH_ALL_TAGS);\r\nif (client->iso_context == NULL || a->handle != 0)\r\nreturn -EINVAL;\r\nif (client->iso_context->type == FW_ISO_CONTEXT_RECEIVE &&\r\n(a->tags == 0 || a->tags > 15 || a->sync > 15))\r\nreturn -EINVAL;\r\nreturn fw_iso_context_start(client->iso_context,\r\na->cycle, a->sync, a->tags);\r\n}\r\nstatic int ioctl_stop_iso(struct client *client, union ioctl_arg *arg)\r\n{\r\nstruct fw_cdev_stop_iso *a = &arg->stop_iso;\r\nif (client->iso_context == NULL || a->handle != 0)\r\nreturn -EINVAL;\r\nreturn fw_iso_context_stop(client->iso_context);\r\n}\r\nstatic int ioctl_get_cycle_timer2(struct client *client, union ioctl_arg *arg)\r\n{\r\nstruct fw_cdev_get_cycle_timer2 *a = &arg->get_cycle_timer2;\r\nstruct fw_card *card = client->device->card;\r\nstruct timespec ts = {0, 0};\r\nu32 cycle_time;\r\nint ret = 0;\r\nlocal_irq_disable();\r\ncycle_time = card->driver->read_csr(card, CSR_CYCLE_TIME);\r\nswitch (a->clk_id) {\r\ncase CLOCK_REALTIME: getnstimeofday(&ts); break;\r\ncase CLOCK_MONOTONIC: do_posix_clock_monotonic_gettime(&ts); break;\r\ncase CLOCK_MONOTONIC_RAW: getrawmonotonic(&ts); break;\r\ndefault:\r\nret = -EINVAL;\r\n}\r\nlocal_irq_enable();\r\na->tv_sec = ts.tv_sec;\r\na->tv_nsec = ts.tv_nsec;\r\na->cycle_timer = cycle_time;\r\nreturn ret;\r\n}\r\nstatic int ioctl_get_cycle_timer(struct client *client, union ioctl_arg *arg)\r\n{\r\nstruct fw_cdev_get_cycle_timer *a = &arg->get_cycle_timer;\r\nstruct fw_cdev_get_cycle_timer2 ct2;\r\nct2.clk_id = CLOCK_REALTIME;\r\nioctl_get_cycle_timer2(client, (union ioctl_arg *)&ct2);\r\na->local_time = ct2.tv_sec * USEC_PER_SEC + ct2.tv_nsec / NSEC_PER_USEC;\r\na->cycle_timer = ct2.cycle_timer;\r\nreturn 0;\r\n}\r\nstatic void iso_resource_work(struct work_struct *work)\r\n{\r\nstruct iso_resource_event *e;\r\nstruct iso_resource *r =\r\ncontainer_of(work, struct iso_resource, work.work);\r\nstruct client *client = r->client;\r\nint generation, channel, bandwidth, todo;\r\nbool skip, free, success;\r\nspin_lock_irq(&client->lock);\r\ngeneration = client->device->generation;\r\ntodo = r->todo;\r\nif (todo == ISO_RES_ALLOC &&\r\ntime_before64(get_jiffies_64(),\r\nclient->device->card->reset_jiffies + HZ)) {\r\nschedule_iso_resource(r, DIV_ROUND_UP(HZ, 3));\r\nskip = true;\r\n} else {\r\nskip = todo == ISO_RES_REALLOC &&\r\nr->generation == generation;\r\n}\r\nfree = todo == ISO_RES_DEALLOC ||\r\ntodo == ISO_RES_ALLOC_ONCE ||\r\ntodo == ISO_RES_DEALLOC_ONCE;\r\nr->generation = generation;\r\nspin_unlock_irq(&client->lock);\r\nif (skip)\r\ngoto out;\r\nbandwidth = r->bandwidth;\r\nfw_iso_resource_manage(client->device->card, generation,\r\nr->channels, &channel, &bandwidth,\r\ntodo == ISO_RES_ALLOC ||\r\ntodo == ISO_RES_REALLOC ||\r\ntodo == ISO_RES_ALLOC_ONCE);\r\nif (channel == -EAGAIN &&\r\n(todo == ISO_RES_ALLOC || todo == ISO_RES_REALLOC))\r\ngoto out;\r\nsuccess = channel >= 0 || bandwidth > 0;\r\nspin_lock_irq(&client->lock);\r\nif (r->todo == ISO_RES_ALLOC)\r\nr->todo = ISO_RES_REALLOC;\r\nif (r->todo == ISO_RES_REALLOC && !success &&\r\n!client->in_shutdown &&\r\nidr_find(&client->resource_idr, r->resource.handle)) {\r\nidr_remove(&client->resource_idr, r->resource.handle);\r\nclient_put(client);\r\nfree = true;\r\n}\r\nspin_unlock_irq(&client->lock);\r\nif (todo == ISO_RES_ALLOC && channel >= 0)\r\nr->channels = 1ULL << channel;\r\nif (todo == ISO_RES_REALLOC && success)\r\ngoto out;\r\nif (todo == ISO_RES_ALLOC || todo == ISO_RES_ALLOC_ONCE) {\r\ne = r->e_alloc;\r\nr->e_alloc = NULL;\r\n} else {\r\ne = r->e_dealloc;\r\nr->e_dealloc = NULL;\r\n}\r\ne->iso_resource.handle = r->resource.handle;\r\ne->iso_resource.channel = channel;\r\ne->iso_resource.bandwidth = bandwidth;\r\nqueue_event(client, &e->event,\r\n&e->iso_resource, sizeof(e->iso_resource), NULL, 0);\r\nif (free) {\r\ncancel_delayed_work(&r->work);\r\nkfree(r->e_alloc);\r\nkfree(r->e_dealloc);\r\nkfree(r);\r\n}\r\nout:\r\nclient_put(client);\r\n}\r\nstatic void release_iso_resource(struct client *client,\r\nstruct client_resource *resource)\r\n{\r\nstruct iso_resource *r =\r\ncontainer_of(resource, struct iso_resource, resource);\r\nspin_lock_irq(&client->lock);\r\nr->todo = ISO_RES_DEALLOC;\r\nschedule_iso_resource(r, 0);\r\nspin_unlock_irq(&client->lock);\r\n}\r\nstatic int init_iso_resource(struct client *client,\r\nstruct fw_cdev_allocate_iso_resource *request, int todo)\r\n{\r\nstruct iso_resource_event *e1, *e2;\r\nstruct iso_resource *r;\r\nint ret;\r\nif ((request->channels == 0 && request->bandwidth == 0) ||\r\nrequest->bandwidth > BANDWIDTH_AVAILABLE_INITIAL ||\r\nrequest->bandwidth < 0)\r\nreturn -EINVAL;\r\nr = kmalloc(sizeof(*r), GFP_KERNEL);\r\ne1 = kmalloc(sizeof(*e1), GFP_KERNEL);\r\ne2 = kmalloc(sizeof(*e2), GFP_KERNEL);\r\nif (r == NULL || e1 == NULL || e2 == NULL) {\r\nret = -ENOMEM;\r\ngoto fail;\r\n}\r\nINIT_DELAYED_WORK(&r->work, iso_resource_work);\r\nr->client = client;\r\nr->todo = todo;\r\nr->generation = -1;\r\nr->channels = request->channels;\r\nr->bandwidth = request->bandwidth;\r\nr->e_alloc = e1;\r\nr->e_dealloc = e2;\r\ne1->iso_resource.closure = request->closure;\r\ne1->iso_resource.type = FW_CDEV_EVENT_ISO_RESOURCE_ALLOCATED;\r\ne2->iso_resource.closure = request->closure;\r\ne2->iso_resource.type = FW_CDEV_EVENT_ISO_RESOURCE_DEALLOCATED;\r\nif (todo == ISO_RES_ALLOC) {\r\nr->resource.release = release_iso_resource;\r\nret = add_client_resource(client, &r->resource, GFP_KERNEL);\r\nif (ret < 0)\r\ngoto fail;\r\n} else {\r\nr->resource.release = NULL;\r\nr->resource.handle = -1;\r\nschedule_iso_resource(r, 0);\r\n}\r\nrequest->handle = r->resource.handle;\r\nreturn 0;\r\nfail:\r\nkfree(r);\r\nkfree(e1);\r\nkfree(e2);\r\nreturn ret;\r\n}\r\nstatic int ioctl_allocate_iso_resource(struct client *client,\r\nunion ioctl_arg *arg)\r\n{\r\nreturn init_iso_resource(client,\r\n&arg->allocate_iso_resource, ISO_RES_ALLOC);\r\n}\r\nstatic int ioctl_deallocate_iso_resource(struct client *client,\r\nunion ioctl_arg *arg)\r\n{\r\nreturn release_client_resource(client,\r\narg->deallocate.handle, release_iso_resource, NULL);\r\n}\r\nstatic int ioctl_allocate_iso_resource_once(struct client *client,\r\nunion ioctl_arg *arg)\r\n{\r\nreturn init_iso_resource(client,\r\n&arg->allocate_iso_resource, ISO_RES_ALLOC_ONCE);\r\n}\r\nstatic int ioctl_deallocate_iso_resource_once(struct client *client,\r\nunion ioctl_arg *arg)\r\n{\r\nreturn init_iso_resource(client,\r\n&arg->allocate_iso_resource, ISO_RES_DEALLOC_ONCE);\r\n}\r\nstatic int ioctl_get_speed(struct client *client, union ioctl_arg *arg)\r\n{\r\nreturn client->device->max_speed;\r\n}\r\nstatic int ioctl_send_broadcast_request(struct client *client,\r\nunion ioctl_arg *arg)\r\n{\r\nstruct fw_cdev_send_request *a = &arg->send_request;\r\nswitch (a->tcode) {\r\ncase TCODE_WRITE_QUADLET_REQUEST:\r\ncase TCODE_WRITE_BLOCK_REQUEST:\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nif (a->offset < CSR_REGISTER_BASE + CSR_CONFIG_ROM_END)\r\nreturn -EACCES;\r\nreturn init_request(client, a, LOCAL_BUS | 0x3f, SCODE_100);\r\n}\r\nstatic int ioctl_send_stream_packet(struct client *client, union ioctl_arg *arg)\r\n{\r\nstruct fw_cdev_send_stream_packet *a = &arg->send_stream_packet;\r\nstruct fw_cdev_send_request request;\r\nint dest;\r\nif (a->speed > client->device->card->link_speed ||\r\na->length > 1024 << a->speed)\r\nreturn -EIO;\r\nif (a->tag > 3 || a->channel > 63 || a->sy > 15)\r\nreturn -EINVAL;\r\ndest = fw_stream_packet_destination_id(a->tag, a->channel, a->sy);\r\nrequest.tcode = TCODE_STREAM_DATA;\r\nrequest.length = a->length;\r\nrequest.closure = a->closure;\r\nrequest.data = a->data;\r\nrequest.generation = a->generation;\r\nreturn init_request(client, &request, dest, a->speed);\r\n}\r\nstatic void outbound_phy_packet_callback(struct fw_packet *packet,\r\nstruct fw_card *card, int status)\r\n{\r\nstruct outbound_phy_packet_event *e =\r\ncontainer_of(packet, struct outbound_phy_packet_event, p);\r\nswitch (status) {\r\ncase ACK_COMPLETE: e->phy_packet.rcode = RCODE_COMPLETE; break;\r\ncase ACK_PENDING: e->phy_packet.rcode = RCODE_COMPLETE; break;\r\ncase ACK_BUSY_X:\r\ncase ACK_BUSY_A:\r\ncase ACK_BUSY_B: e->phy_packet.rcode = RCODE_BUSY; break;\r\ncase ACK_DATA_ERROR: e->phy_packet.rcode = RCODE_DATA_ERROR; break;\r\ncase ACK_TYPE_ERROR: e->phy_packet.rcode = RCODE_TYPE_ERROR; break;\r\ndefault: e->phy_packet.rcode = status; break;\r\n}\r\ne->phy_packet.data[0] = packet->timestamp;\r\nqueue_event(e->client, &e->event, &e->phy_packet,\r\nsizeof(e->phy_packet) + e->phy_packet.length, NULL, 0);\r\nclient_put(e->client);\r\n}\r\nstatic int ioctl_send_phy_packet(struct client *client, union ioctl_arg *arg)\r\n{\r\nstruct fw_cdev_send_phy_packet *a = &arg->send_phy_packet;\r\nstruct fw_card *card = client->device->card;\r\nstruct outbound_phy_packet_event *e;\r\nif (!client->device->is_local)\r\nreturn -ENOSYS;\r\ne = kzalloc(sizeof(*e) + 4, GFP_KERNEL);\r\nif (e == NULL)\r\nreturn -ENOMEM;\r\nclient_get(client);\r\ne->client = client;\r\ne->p.speed = SCODE_100;\r\ne->p.generation = a->generation;\r\ne->p.header[0] = TCODE_LINK_INTERNAL << 4;\r\ne->p.header[1] = a->data[0];\r\ne->p.header[2] = a->data[1];\r\ne->p.header_length = 12;\r\ne->p.callback = outbound_phy_packet_callback;\r\ne->phy_packet.closure = a->closure;\r\ne->phy_packet.type = FW_CDEV_EVENT_PHY_PACKET_SENT;\r\nif (is_ping_packet(a->data))\r\ne->phy_packet.length = 4;\r\ncard->driver->send_request(card, &e->p);\r\nreturn 0;\r\n}\r\nstatic int ioctl_receive_phy_packets(struct client *client, union ioctl_arg *arg)\r\n{\r\nstruct fw_cdev_receive_phy_packets *a = &arg->receive_phy_packets;\r\nstruct fw_card *card = client->device->card;\r\nif (!client->device->is_local)\r\nreturn -ENOSYS;\r\nspin_lock_irq(&card->lock);\r\nlist_move_tail(&client->phy_receiver_link, &card->phy_receiver_list);\r\nclient->phy_receiver_closure = a->closure;\r\nspin_unlock_irq(&card->lock);\r\nreturn 0;\r\n}\r\nvoid fw_cdev_handle_phy_packet(struct fw_card *card, struct fw_packet *p)\r\n{\r\nstruct client *client;\r\nstruct inbound_phy_packet_event *e;\r\nunsigned long flags;\r\nspin_lock_irqsave(&card->lock, flags);\r\nlist_for_each_entry(client, &card->phy_receiver_list, phy_receiver_link) {\r\ne = kmalloc(sizeof(*e) + 8, GFP_ATOMIC);\r\nif (e == NULL) {\r\nfw_notify("Out of memory when allocating event\n");\r\nbreak;\r\n}\r\ne->phy_packet.closure = client->phy_receiver_closure;\r\ne->phy_packet.type = FW_CDEV_EVENT_PHY_PACKET_RECEIVED;\r\ne->phy_packet.rcode = RCODE_COMPLETE;\r\ne->phy_packet.length = 8;\r\ne->phy_packet.data[0] = p->header[1];\r\ne->phy_packet.data[1] = p->header[2];\r\nqueue_event(client, &e->event,\r\n&e->phy_packet, sizeof(e->phy_packet) + 8, NULL, 0);\r\n}\r\nspin_unlock_irqrestore(&card->lock, flags);\r\n}\r\nstatic int dispatch_ioctl(struct client *client,\r\nunsigned int cmd, void __user *arg)\r\n{\r\nunion ioctl_arg buffer;\r\nint ret;\r\nif (fw_device_is_shutdown(client->device))\r\nreturn -ENODEV;\r\nif (_IOC_TYPE(cmd) != '#' ||\r\n_IOC_NR(cmd) >= ARRAY_SIZE(ioctl_handlers) ||\r\n_IOC_SIZE(cmd) > sizeof(buffer))\r\nreturn -ENOTTY;\r\nif (_IOC_DIR(cmd) == _IOC_READ)\r\nmemset(&buffer, 0, _IOC_SIZE(cmd));\r\nif (_IOC_DIR(cmd) & _IOC_WRITE)\r\nif (copy_from_user(&buffer, arg, _IOC_SIZE(cmd)))\r\nreturn -EFAULT;\r\nret = ioctl_handlers[_IOC_NR(cmd)](client, &buffer);\r\nif (ret < 0)\r\nreturn ret;\r\nif (_IOC_DIR(cmd) & _IOC_READ)\r\nif (copy_to_user(arg, &buffer, _IOC_SIZE(cmd)))\r\nreturn -EFAULT;\r\nreturn ret;\r\n}\r\nstatic long fw_device_op_ioctl(struct file *file,\r\nunsigned int cmd, unsigned long arg)\r\n{\r\nreturn dispatch_ioctl(file->private_data, cmd, (void __user *)arg);\r\n}\r\nstatic long fw_device_op_compat_ioctl(struct file *file,\r\nunsigned int cmd, unsigned long arg)\r\n{\r\nreturn dispatch_ioctl(file->private_data, cmd, compat_ptr(arg));\r\n}\r\nstatic int fw_device_op_mmap(struct file *file, struct vm_area_struct *vma)\r\n{\r\nstruct client *client = file->private_data;\r\nenum dma_data_direction direction;\r\nunsigned long size;\r\nint page_count, ret;\r\nif (fw_device_is_shutdown(client->device))\r\nreturn -ENODEV;\r\nif (client->buffer.pages != NULL)\r\nreturn -EBUSY;\r\nif (!(vma->vm_flags & VM_SHARED))\r\nreturn -EINVAL;\r\nif (vma->vm_start & ~PAGE_MASK)\r\nreturn -EINVAL;\r\nclient->vm_start = vma->vm_start;\r\nsize = vma->vm_end - vma->vm_start;\r\npage_count = size >> PAGE_SHIFT;\r\nif (size & ~PAGE_MASK)\r\nreturn -EINVAL;\r\nif (vma->vm_flags & VM_WRITE)\r\ndirection = DMA_TO_DEVICE;\r\nelse\r\ndirection = DMA_FROM_DEVICE;\r\nret = fw_iso_buffer_init(&client->buffer, client->device->card,\r\npage_count, direction);\r\nif (ret < 0)\r\nreturn ret;\r\nret = fw_iso_buffer_map(&client->buffer, vma);\r\nif (ret < 0)\r\nfw_iso_buffer_destroy(&client->buffer, client->device->card);\r\nreturn ret;\r\n}\r\nstatic int is_outbound_transaction_resource(int id, void *p, void *data)\r\n{\r\nstruct client_resource *resource = p;\r\nreturn resource->release == release_transaction;\r\n}\r\nstatic int has_outbound_transactions(struct client *client)\r\n{\r\nint ret;\r\nspin_lock_irq(&client->lock);\r\nret = idr_for_each(&client->resource_idr,\r\nis_outbound_transaction_resource, NULL);\r\nspin_unlock_irq(&client->lock);\r\nreturn ret;\r\n}\r\nstatic int shutdown_resource(int id, void *p, void *data)\r\n{\r\nstruct client_resource *resource = p;\r\nstruct client *client = data;\r\nresource->release(client, resource);\r\nclient_put(client);\r\nreturn 0;\r\n}\r\nstatic int fw_device_op_release(struct inode *inode, struct file *file)\r\n{\r\nstruct client *client = file->private_data;\r\nstruct event *event, *next_event;\r\nspin_lock_irq(&client->device->card->lock);\r\nlist_del(&client->phy_receiver_link);\r\nspin_unlock_irq(&client->device->card->lock);\r\nmutex_lock(&client->device->client_list_mutex);\r\nlist_del(&client->link);\r\nmutex_unlock(&client->device->client_list_mutex);\r\nif (client->iso_context)\r\nfw_iso_context_destroy(client->iso_context);\r\nif (client->buffer.pages)\r\nfw_iso_buffer_destroy(&client->buffer, client->device->card);\r\nspin_lock_irq(&client->lock);\r\nclient->in_shutdown = true;\r\nspin_unlock_irq(&client->lock);\r\nwait_event(client->tx_flush_wait, !has_outbound_transactions(client));\r\nidr_for_each(&client->resource_idr, shutdown_resource, client);\r\nidr_remove_all(&client->resource_idr);\r\nidr_destroy(&client->resource_idr);\r\nlist_for_each_entry_safe(event, next_event, &client->event_list, link)\r\nkfree(event);\r\nclient_put(client);\r\nreturn 0;\r\n}\r\nstatic unsigned int fw_device_op_poll(struct file *file, poll_table * pt)\r\n{\r\nstruct client *client = file->private_data;\r\nunsigned int mask = 0;\r\npoll_wait(file, &client->wait, pt);\r\nif (fw_device_is_shutdown(client->device))\r\nmask |= POLLHUP | POLLERR;\r\nif (!list_empty(&client->event_list))\r\nmask |= POLLIN | POLLRDNORM;\r\nreturn mask;\r\n}
