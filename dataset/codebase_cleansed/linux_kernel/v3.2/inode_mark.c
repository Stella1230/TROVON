static void fsnotify_recalc_inode_mask_locked(struct inode *inode)\r\n{\r\nstruct fsnotify_mark *mark;\r\nstruct hlist_node *pos;\r\n__u32 new_mask = 0;\r\nassert_spin_locked(&inode->i_lock);\r\nhlist_for_each_entry(mark, pos, &inode->i_fsnotify_marks, i.i_list)\r\nnew_mask |= mark->mask;\r\ninode->i_fsnotify_mask = new_mask;\r\n}\r\nvoid fsnotify_recalc_inode_mask(struct inode *inode)\r\n{\r\nspin_lock(&inode->i_lock);\r\nfsnotify_recalc_inode_mask_locked(inode);\r\nspin_unlock(&inode->i_lock);\r\n__fsnotify_update_child_dentry_flags(inode);\r\n}\r\nvoid fsnotify_destroy_inode_mark(struct fsnotify_mark *mark)\r\n{\r\nstruct inode *inode = mark->i.inode;\r\nassert_spin_locked(&mark->lock);\r\nassert_spin_locked(&mark->group->mark_lock);\r\nspin_lock(&inode->i_lock);\r\nhlist_del_init_rcu(&mark->i.i_list);\r\nmark->i.inode = NULL;\r\nfsnotify_recalc_inode_mask_locked(inode);\r\nspin_unlock(&inode->i_lock);\r\n}\r\nvoid fsnotify_clear_marks_by_inode(struct inode *inode)\r\n{\r\nstruct fsnotify_mark *mark, *lmark;\r\nstruct hlist_node *pos, *n;\r\nLIST_HEAD(free_list);\r\nspin_lock(&inode->i_lock);\r\nhlist_for_each_entry_safe(mark, pos, n, &inode->i_fsnotify_marks, i.i_list) {\r\nlist_add(&mark->i.free_i_list, &free_list);\r\nhlist_del_init_rcu(&mark->i.i_list);\r\nfsnotify_get_mark(mark);\r\n}\r\nspin_unlock(&inode->i_lock);\r\nlist_for_each_entry_safe(mark, lmark, &free_list, i.free_i_list) {\r\nfsnotify_destroy_mark(mark);\r\nfsnotify_put_mark(mark);\r\n}\r\n}\r\nvoid fsnotify_clear_inode_marks_by_group(struct fsnotify_group *group)\r\n{\r\nfsnotify_clear_marks_by_group_flags(group, FSNOTIFY_MARK_FLAG_INODE);\r\n}\r\nstruct fsnotify_mark *fsnotify_find_inode_mark_locked(struct fsnotify_group *group,\r\nstruct inode *inode)\r\n{\r\nstruct fsnotify_mark *mark;\r\nstruct hlist_node *pos;\r\nassert_spin_locked(&inode->i_lock);\r\nhlist_for_each_entry(mark, pos, &inode->i_fsnotify_marks, i.i_list) {\r\nif (mark->group == group) {\r\nfsnotify_get_mark(mark);\r\nreturn mark;\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nstruct fsnotify_mark *fsnotify_find_inode_mark(struct fsnotify_group *group,\r\nstruct inode *inode)\r\n{\r\nstruct fsnotify_mark *mark;\r\nspin_lock(&inode->i_lock);\r\nmark = fsnotify_find_inode_mark_locked(group, inode);\r\nspin_unlock(&inode->i_lock);\r\nreturn mark;\r\n}\r\nvoid fsnotify_set_inode_mark_mask_locked(struct fsnotify_mark *mark,\r\n__u32 mask)\r\n{\r\nstruct inode *inode;\r\nassert_spin_locked(&mark->lock);\r\nif (mask &&\r\nmark->i.inode &&\r\n!(mark->flags & FSNOTIFY_MARK_FLAG_OBJECT_PINNED)) {\r\nmark->flags |= FSNOTIFY_MARK_FLAG_OBJECT_PINNED;\r\ninode = igrab(mark->i.inode);\r\nBUG_ON(!inode);\r\n}\r\n}\r\nint fsnotify_add_inode_mark(struct fsnotify_mark *mark,\r\nstruct fsnotify_group *group, struct inode *inode,\r\nint allow_dups)\r\n{\r\nstruct fsnotify_mark *lmark;\r\nstruct hlist_node *node, *last = NULL;\r\nint ret = 0;\r\nmark->flags |= FSNOTIFY_MARK_FLAG_INODE;\r\nassert_spin_locked(&mark->lock);\r\nassert_spin_locked(&group->mark_lock);\r\nspin_lock(&inode->i_lock);\r\nmark->i.inode = inode;\r\nif (hlist_empty(&inode->i_fsnotify_marks)) {\r\nhlist_add_head_rcu(&mark->i.i_list, &inode->i_fsnotify_marks);\r\ngoto out;\r\n}\r\nhlist_for_each_entry(lmark, node, &inode->i_fsnotify_marks, i.i_list) {\r\nlast = node;\r\nif ((lmark->group == group) && !allow_dups) {\r\nret = -EEXIST;\r\ngoto out;\r\n}\r\nif (mark->group->priority < lmark->group->priority)\r\ncontinue;\r\nif ((mark->group->priority == lmark->group->priority) &&\r\n(mark->group < lmark->group))\r\ncontinue;\r\nhlist_add_before_rcu(&mark->i.i_list, &lmark->i.i_list);\r\ngoto out;\r\n}\r\nBUG_ON(last == NULL);\r\nhlist_add_after_rcu(last, &mark->i.i_list);\r\nout:\r\nfsnotify_recalc_inode_mask_locked(inode);\r\nspin_unlock(&inode->i_lock);\r\nreturn ret;\r\n}\r\nvoid fsnotify_unmount_inodes(struct list_head *list)\r\n{\r\nstruct inode *inode, *next_i, *need_iput = NULL;\r\nspin_lock(&inode_sb_list_lock);\r\nlist_for_each_entry_safe(inode, next_i, list, i_sb_list) {\r\nstruct inode *need_iput_tmp;\r\nspin_lock(&inode->i_lock);\r\nif (inode->i_state & (I_FREEING|I_WILL_FREE|I_NEW)) {\r\nspin_unlock(&inode->i_lock);\r\ncontinue;\r\n}\r\nif (!atomic_read(&inode->i_count)) {\r\nspin_unlock(&inode->i_lock);\r\ncontinue;\r\n}\r\nneed_iput_tmp = need_iput;\r\nneed_iput = NULL;\r\nif (inode != need_iput_tmp)\r\n__iget(inode);\r\nelse\r\nneed_iput_tmp = NULL;\r\nspin_unlock(&inode->i_lock);\r\nif ((&next_i->i_sb_list != list) &&\r\natomic_read(&next_i->i_count)) {\r\nspin_lock(&next_i->i_lock);\r\nif (!(next_i->i_state & (I_FREEING | I_WILL_FREE))) {\r\n__iget(next_i);\r\nneed_iput = next_i;\r\n}\r\nspin_unlock(&next_i->i_lock);\r\n}\r\nspin_unlock(&inode_sb_list_lock);\r\nif (need_iput_tmp)\r\niput(need_iput_tmp);\r\nfsnotify(inode, FS_UNMOUNT, inode, FSNOTIFY_EVENT_INODE, NULL, 0);\r\nfsnotify_inode_delete(inode);\r\niput(inode);\r\nspin_lock(&inode_sb_list_lock);\r\n}\r\nspin_unlock(&inode_sb_list_lock);\r\n}
