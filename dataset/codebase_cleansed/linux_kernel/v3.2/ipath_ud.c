static void ipath_ud_loopback(struct ipath_qp *sqp, struct ipath_swqe *swqe)\r\n{\r\nstruct ipath_ibdev *dev = to_idev(sqp->ibqp.device);\r\nstruct ipath_qp *qp;\r\nstruct ib_ah_attr *ah_attr;\r\nunsigned long flags;\r\nstruct ipath_rq *rq;\r\nstruct ipath_srq *srq;\r\nstruct ipath_sge_state rsge;\r\nstruct ipath_sge *sge;\r\nstruct ipath_rwq *wq;\r\nstruct ipath_rwqe *wqe;\r\nvoid (*handler)(struct ib_event *, void *);\r\nstruct ib_wc wc;\r\nu32 tail;\r\nu32 rlen;\r\nu32 length;\r\nqp = ipath_lookup_qpn(&dev->qp_table, swqe->wr.wr.ud.remote_qpn);\r\nif (!qp || !(ib_ipath_state_ops[qp->state] & IPATH_PROCESS_RECV_OK)) {\r\ndev->n_pkt_drops++;\r\ngoto done;\r\n}\r\nif (unlikely(qp->ibqp.qp_num &&\r\n((int) swqe->wr.wr.ud.remote_qkey < 0 ?\r\nsqp->qkey : swqe->wr.wr.ud.remote_qkey) != qp->qkey)) {\r\ndev->qkey_violations++;\r\ndev->n_pkt_drops++;\r\ngoto drop;\r\n}\r\nlength = swqe->length;\r\nmemset(&wc, 0, sizeof wc);\r\nwc.byte_len = length + sizeof(struct ib_grh);\r\nif (swqe->wr.opcode == IB_WR_SEND_WITH_IMM) {\r\nwc.wc_flags = IB_WC_WITH_IMM;\r\nwc.ex.imm_data = swqe->wr.ex.imm_data;\r\n}\r\nif (qp->ibqp.srq) {\r\nsrq = to_isrq(qp->ibqp.srq);\r\nhandler = srq->ibsrq.event_handler;\r\nrq = &srq->rq;\r\n} else {\r\nsrq = NULL;\r\nhandler = NULL;\r\nrq = &qp->r_rq;\r\n}\r\nspin_lock_irqsave(&rq->lock, flags);\r\nwq = rq->wq;\r\ntail = wq->tail;\r\nif (tail >= rq->size)\r\ntail = 0;\r\nif (unlikely(tail == wq->head)) {\r\nspin_unlock_irqrestore(&rq->lock, flags);\r\ndev->n_pkt_drops++;\r\ngoto drop;\r\n}\r\nwqe = get_rwqe_ptr(rq, tail);\r\nrsge.sg_list = qp->r_ud_sg_list;\r\nif (!ipath_init_sge(qp, wqe, &rlen, &rsge)) {\r\nspin_unlock_irqrestore(&rq->lock, flags);\r\ndev->n_pkt_drops++;\r\ngoto drop;\r\n}\r\nif (wc.byte_len > rlen) {\r\nspin_unlock_irqrestore(&rq->lock, flags);\r\ndev->n_pkt_drops++;\r\ngoto drop;\r\n}\r\nif (++tail >= rq->size)\r\ntail = 0;\r\nwq->tail = tail;\r\nwc.wr_id = wqe->wr_id;\r\nif (handler) {\r\nu32 n;\r\nn = wq->head;\r\nif (n >= rq->size)\r\nn = 0;\r\nif (n < tail)\r\nn += rq->size - tail;\r\nelse\r\nn -= tail;\r\nif (n < srq->limit) {\r\nstruct ib_event ev;\r\nsrq->limit = 0;\r\nspin_unlock_irqrestore(&rq->lock, flags);\r\nev.device = qp->ibqp.device;\r\nev.element.srq = qp->ibqp.srq;\r\nev.event = IB_EVENT_SRQ_LIMIT_REACHED;\r\nhandler(&ev, srq->ibsrq.srq_context);\r\n} else\r\nspin_unlock_irqrestore(&rq->lock, flags);\r\n} else\r\nspin_unlock_irqrestore(&rq->lock, flags);\r\nah_attr = &to_iah(swqe->wr.wr.ud.ah)->attr;\r\nif (ah_attr->ah_flags & IB_AH_GRH) {\r\nipath_copy_sge(&rsge, &ah_attr->grh, sizeof(struct ib_grh));\r\nwc.wc_flags |= IB_WC_GRH;\r\n} else\r\nipath_skip_sge(&rsge, sizeof(struct ib_grh));\r\nsge = swqe->sg_list;\r\nwhile (length) {\r\nu32 len = sge->length;\r\nif (len > length)\r\nlen = length;\r\nif (len > sge->sge_length)\r\nlen = sge->sge_length;\r\nBUG_ON(len == 0);\r\nipath_copy_sge(&rsge, sge->vaddr, len);\r\nsge->vaddr += len;\r\nsge->length -= len;\r\nsge->sge_length -= len;\r\nif (sge->sge_length == 0) {\r\nif (--swqe->wr.num_sge)\r\nsge++;\r\n} else if (sge->length == 0 && sge->mr != NULL) {\r\nif (++sge->n >= IPATH_SEGSZ) {\r\nif (++sge->m >= sge->mr->mapsz)\r\nbreak;\r\nsge->n = 0;\r\n}\r\nsge->vaddr =\r\nsge->mr->map[sge->m]->segs[sge->n].vaddr;\r\nsge->length =\r\nsge->mr->map[sge->m]->segs[sge->n].length;\r\n}\r\nlength -= len;\r\n}\r\nwc.status = IB_WC_SUCCESS;\r\nwc.opcode = IB_WC_RECV;\r\nwc.qp = &qp->ibqp;\r\nwc.src_qp = sqp->ibqp.qp_num;\r\nwc.pkey_index = 0;\r\nwc.slid = dev->dd->ipath_lid |\r\n(ah_attr->src_path_bits &\r\n((1 << dev->dd->ipath_lmc) - 1));\r\nwc.sl = ah_attr->sl;\r\nwc.dlid_path_bits =\r\nah_attr->dlid & ((1 << dev->dd->ipath_lmc) - 1);\r\nwc.port_num = 1;\r\nipath_cq_enter(to_icq(qp->ibqp.recv_cq), &wc,\r\nswqe->wr.send_flags & IB_SEND_SOLICITED);\r\ndrop:\r\nif (atomic_dec_and_test(&qp->refcount))\r\nwake_up(&qp->wait);\r\ndone:;\r\n}\r\nint ipath_make_ud_req(struct ipath_qp *qp)\r\n{\r\nstruct ipath_ibdev *dev = to_idev(qp->ibqp.device);\r\nstruct ipath_other_headers *ohdr;\r\nstruct ib_ah_attr *ah_attr;\r\nstruct ipath_swqe *wqe;\r\nunsigned long flags;\r\nu32 nwords;\r\nu32 extra_bytes;\r\nu32 bth0;\r\nu16 lrh0;\r\nu16 lid;\r\nint ret = 0;\r\nint next_cur;\r\nspin_lock_irqsave(&qp->s_lock, flags);\r\nif (!(ib_ipath_state_ops[qp->state] & IPATH_PROCESS_NEXT_SEND_OK)) {\r\nif (!(ib_ipath_state_ops[qp->state] & IPATH_FLUSH_SEND))\r\ngoto bail;\r\nif (qp->s_last == qp->s_head)\r\ngoto bail;\r\nif (atomic_read(&qp->s_dma_busy)) {\r\nqp->s_flags |= IPATH_S_WAIT_DMA;\r\ngoto bail;\r\n}\r\nwqe = get_swqe_ptr(qp, qp->s_last);\r\nipath_send_complete(qp, wqe, IB_WC_WR_FLUSH_ERR);\r\ngoto done;\r\n}\r\nif (qp->s_cur == qp->s_head)\r\ngoto bail;\r\nwqe = get_swqe_ptr(qp, qp->s_cur);\r\nnext_cur = qp->s_cur + 1;\r\nif (next_cur >= qp->s_size)\r\nnext_cur = 0;\r\nah_attr = &to_iah(wqe->wr.wr.ud.ah)->attr;\r\nif (ah_attr->dlid >= IPATH_MULTICAST_LID_BASE) {\r\nif (ah_attr->dlid != IPATH_PERMISSIVE_LID)\r\ndev->n_multicast_xmit++;\r\nelse\r\ndev->n_unicast_xmit++;\r\n} else {\r\ndev->n_unicast_xmit++;\r\nlid = ah_attr->dlid & ~((1 << dev->dd->ipath_lmc) - 1);\r\nif (unlikely(lid == dev->dd->ipath_lid)) {\r\nif (atomic_read(&qp->s_dma_busy)) {\r\nqp->s_flags |= IPATH_S_WAIT_DMA;\r\ngoto bail;\r\n}\r\nqp->s_cur = next_cur;\r\nspin_unlock_irqrestore(&qp->s_lock, flags);\r\nipath_ud_loopback(qp, wqe);\r\nspin_lock_irqsave(&qp->s_lock, flags);\r\nipath_send_complete(qp, wqe, IB_WC_SUCCESS);\r\ngoto done;\r\n}\r\n}\r\nqp->s_cur = next_cur;\r\nextra_bytes = -wqe->length & 3;\r\nnwords = (wqe->length + extra_bytes) >> 2;\r\nqp->s_hdrwords = 7;\r\nqp->s_cur_size = wqe->length;\r\nqp->s_cur_sge = &qp->s_sge;\r\nqp->s_dmult = ah_attr->static_rate;\r\nqp->s_wqe = wqe;\r\nqp->s_sge.sge = wqe->sg_list[0];\r\nqp->s_sge.sg_list = wqe->sg_list + 1;\r\nqp->s_sge.num_sge = wqe->wr.num_sge;\r\nif (ah_attr->ah_flags & IB_AH_GRH) {\r\nqp->s_hdrwords += ipath_make_grh(dev, &qp->s_hdr.u.l.grh,\r\n&ah_attr->grh,\r\nqp->s_hdrwords, nwords);\r\nlrh0 = IPATH_LRH_GRH;\r\nohdr = &qp->s_hdr.u.l.oth;\r\n} else {\r\nlrh0 = IPATH_LRH_BTH;\r\nohdr = &qp->s_hdr.u.oth;\r\n}\r\nif (wqe->wr.opcode == IB_WR_SEND_WITH_IMM) {\r\nqp->s_hdrwords++;\r\nohdr->u.ud.imm_data = wqe->wr.ex.imm_data;\r\nbth0 = IB_OPCODE_UD_SEND_ONLY_WITH_IMMEDIATE << 24;\r\n} else\r\nbth0 = IB_OPCODE_UD_SEND_ONLY << 24;\r\nlrh0 |= ah_attr->sl << 4;\r\nif (qp->ibqp.qp_type == IB_QPT_SMI)\r\nlrh0 |= 0xF000;\r\nqp->s_hdr.lrh[0] = cpu_to_be16(lrh0);\r\nqp->s_hdr.lrh[1] = cpu_to_be16(ah_attr->dlid);\r\nqp->s_hdr.lrh[2] = cpu_to_be16(qp->s_hdrwords + nwords +\r\nSIZE_OF_CRC);\r\nlid = dev->dd->ipath_lid;\r\nif (lid) {\r\nlid |= ah_attr->src_path_bits &\r\n((1 << dev->dd->ipath_lmc) - 1);\r\nqp->s_hdr.lrh[3] = cpu_to_be16(lid);\r\n} else\r\nqp->s_hdr.lrh[3] = IB_LID_PERMISSIVE;\r\nif (wqe->wr.send_flags & IB_SEND_SOLICITED)\r\nbth0 |= 1 << 23;\r\nbth0 |= extra_bytes << 20;\r\nbth0 |= qp->ibqp.qp_type == IB_QPT_SMI ? IPATH_DEFAULT_P_KEY :\r\nipath_get_pkey(dev->dd, qp->s_pkey_index);\r\nohdr->bth[0] = cpu_to_be32(bth0);\r\nohdr->bth[1] = ah_attr->dlid >= IPATH_MULTICAST_LID_BASE &&\r\nah_attr->dlid != IPATH_PERMISSIVE_LID ?\r\ncpu_to_be32(IPATH_MULTICAST_QPN) :\r\ncpu_to_be32(wqe->wr.wr.ud.remote_qpn);\r\nohdr->bth[2] = cpu_to_be32(qp->s_next_psn++ & IPATH_PSN_MASK);\r\nohdr->u.ud.deth[0] = cpu_to_be32((int)wqe->wr.wr.ud.remote_qkey < 0 ?\r\nqp->qkey : wqe->wr.wr.ud.remote_qkey);\r\nohdr->u.ud.deth[1] = cpu_to_be32(qp->ibqp.qp_num);\r\ndone:\r\nret = 1;\r\ngoto unlock;\r\nbail:\r\nqp->s_flags &= ~IPATH_S_BUSY;\r\nunlock:\r\nspin_unlock_irqrestore(&qp->s_lock, flags);\r\nreturn ret;\r\n}\r\nvoid ipath_ud_rcv(struct ipath_ibdev *dev, struct ipath_ib_header *hdr,\r\nint has_grh, void *data, u32 tlen, struct ipath_qp *qp)\r\n{\r\nstruct ipath_other_headers *ohdr;\r\nint opcode;\r\nu32 hdrsize;\r\nu32 pad;\r\nstruct ib_wc wc;\r\nu32 qkey;\r\nu32 src_qp;\r\nu16 dlid;\r\nint header_in_data;\r\nif (!has_grh) {\r\nohdr = &hdr->u.oth;\r\nhdrsize = 8 + 12 + 8;\r\nqkey = be32_to_cpu(ohdr->u.ud.deth[0]);\r\nsrc_qp = be32_to_cpu(ohdr->u.ud.deth[1]);\r\nheader_in_data = 0;\r\n} else {\r\nohdr = &hdr->u.l.oth;\r\nhdrsize = 8 + 40 + 12 + 8;\r\nheader_in_data = dev->dd->ipath_rcvhdrentsize == 16;\r\nif (header_in_data) {\r\nqkey = be32_to_cpu(((__be32 *) data)[1]);\r\nsrc_qp = be32_to_cpu(((__be32 *) data)[2]);\r\ndata += 12;\r\n} else {\r\nqkey = be32_to_cpu(ohdr->u.ud.deth[0]);\r\nsrc_qp = be32_to_cpu(ohdr->u.ud.deth[1]);\r\n}\r\n}\r\nsrc_qp &= IPATH_QPN_MASK;\r\nif (qp->ibqp.qp_num) {\r\nif (unlikely(hdr->lrh[1] == IB_LID_PERMISSIVE ||\r\nhdr->lrh[3] == IB_LID_PERMISSIVE)) {\r\ndev->n_pkt_drops++;\r\ngoto bail;\r\n}\r\nif (unlikely(qkey != qp->qkey)) {\r\ndev->qkey_violations++;\r\ndev->n_pkt_drops++;\r\ngoto bail;\r\n}\r\n} else if (hdr->lrh[1] == IB_LID_PERMISSIVE ||\r\nhdr->lrh[3] == IB_LID_PERMISSIVE) {\r\nstruct ib_smp *smp = (struct ib_smp *) data;\r\nif (smp->mgmt_class != IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE) {\r\ndev->n_pkt_drops++;\r\ngoto bail;\r\n}\r\n}\r\nopcode = be32_to_cpu(ohdr->bth[0]) >> 24;\r\nif (qp->ibqp.qp_num > 1 &&\r\nopcode == IB_OPCODE_UD_SEND_ONLY_WITH_IMMEDIATE) {\r\nif (header_in_data) {\r\nwc.ex.imm_data = *(__be32 *) data;\r\ndata += sizeof(__be32);\r\n} else\r\nwc.ex.imm_data = ohdr->u.ud.imm_data;\r\nwc.wc_flags = IB_WC_WITH_IMM;\r\nhdrsize += sizeof(u32);\r\n} else if (opcode == IB_OPCODE_UD_SEND_ONLY) {\r\nwc.ex.imm_data = 0;\r\nwc.wc_flags = 0;\r\n} else {\r\ndev->n_pkt_drops++;\r\ngoto bail;\r\n}\r\npad = (be32_to_cpu(ohdr->bth[0]) >> 20) & 3;\r\nif (unlikely(tlen < (hdrsize + pad + 4))) {\r\ndev->n_pkt_drops++;\r\ngoto bail;\r\n}\r\ntlen -= hdrsize + pad + 4;\r\nif (unlikely((qp->ibqp.qp_num == 0 &&\r\n(tlen != 256 ||\r\n(be16_to_cpu(hdr->lrh[0]) >> 12) != 15)) ||\r\n(qp->ibqp.qp_num == 1 &&\r\n(tlen != 256 ||\r\n(be16_to_cpu(hdr->lrh[0]) >> 12) == 15)))) {\r\ndev->n_pkt_drops++;\r\ngoto bail;\r\n}\r\nwc.byte_len = tlen + sizeof(struct ib_grh);\r\nif (qp->r_flags & IPATH_R_REUSE_SGE)\r\nqp->r_flags &= ~IPATH_R_REUSE_SGE;\r\nelse if (!ipath_get_rwqe(qp, 0)) {\r\nif (qp->ibqp.qp_num == 0)\r\ndev->n_vl15_dropped++;\r\nelse\r\ndev->rcv_errors++;\r\ngoto bail;\r\n}\r\nif (wc.byte_len > qp->r_len) {\r\nqp->r_flags |= IPATH_R_REUSE_SGE;\r\ndev->n_pkt_drops++;\r\ngoto bail;\r\n}\r\nif (has_grh) {\r\nipath_copy_sge(&qp->r_sge, &hdr->u.l.grh,\r\nsizeof(struct ib_grh));\r\nwc.wc_flags |= IB_WC_GRH;\r\n} else\r\nipath_skip_sge(&qp->r_sge, sizeof(struct ib_grh));\r\nipath_copy_sge(&qp->r_sge, data,\r\nwc.byte_len - sizeof(struct ib_grh));\r\nif (!test_and_clear_bit(IPATH_R_WRID_VALID, &qp->r_aflags))\r\ngoto bail;\r\nwc.wr_id = qp->r_wr_id;\r\nwc.status = IB_WC_SUCCESS;\r\nwc.opcode = IB_WC_RECV;\r\nwc.vendor_err = 0;\r\nwc.qp = &qp->ibqp;\r\nwc.src_qp = src_qp;\r\nwc.pkey_index = 0;\r\nwc.slid = be16_to_cpu(hdr->lrh[3]);\r\nwc.sl = (be16_to_cpu(hdr->lrh[0]) >> 4) & 0xF;\r\ndlid = be16_to_cpu(hdr->lrh[1]);\r\nwc.dlid_path_bits = dlid >= IPATH_MULTICAST_LID_BASE ? 0 :\r\ndlid & ((1 << dev->dd->ipath_lmc) - 1);\r\nwc.port_num = 1;\r\nipath_cq_enter(to_icq(qp->ibqp.recv_cq), &wc,\r\n(ohdr->bth[0] &\r\ncpu_to_be32(1 << 23)) != 0);\r\nbail:;\r\n}
