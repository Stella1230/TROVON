static int mthca_update_rate(struct mthca_dev *dev, u8 port_num)\r\n{\r\nstruct ib_port_attr *tprops = NULL;\r\nint ret;\r\ntprops = kmalloc(sizeof *tprops, GFP_KERNEL);\r\nif (!tprops)\r\nreturn -ENOMEM;\r\nret = ib_query_port(&dev->ib_dev, port_num, tprops);\r\nif (ret) {\r\nprintk(KERN_WARNING "ib_query_port failed (%d) for %s port %d\n",\r\nret, dev->ib_dev.name, port_num);\r\ngoto out;\r\n}\r\ndev->rate[port_num - 1] = tprops->active_speed *\r\nib_width_enum_to_int(tprops->active_width);\r\nout:\r\nkfree(tprops);\r\nreturn ret;\r\n}\r\nstatic void update_sm_ah(struct mthca_dev *dev,\r\nu8 port_num, u16 lid, u8 sl)\r\n{\r\nstruct ib_ah *new_ah;\r\nstruct ib_ah_attr ah_attr;\r\nunsigned long flags;\r\nif (!dev->send_agent[port_num - 1][0])\r\nreturn;\r\nmemset(&ah_attr, 0, sizeof ah_attr);\r\nah_attr.dlid = lid;\r\nah_attr.sl = sl;\r\nah_attr.port_num = port_num;\r\nnew_ah = ib_create_ah(dev->send_agent[port_num - 1][0]->qp->pd,\r\n&ah_attr);\r\nif (IS_ERR(new_ah))\r\nreturn;\r\nspin_lock_irqsave(&dev->sm_lock, flags);\r\nif (dev->sm_ah[port_num - 1])\r\nib_destroy_ah(dev->sm_ah[port_num - 1]);\r\ndev->sm_ah[port_num - 1] = new_ah;\r\nspin_unlock_irqrestore(&dev->sm_lock, flags);\r\n}\r\nstatic void smp_snoop(struct ib_device *ibdev,\r\nu8 port_num,\r\nstruct ib_mad *mad,\r\nu16 prev_lid)\r\n{\r\nstruct ib_event event;\r\nif ((mad->mad_hdr.mgmt_class == IB_MGMT_CLASS_SUBN_LID_ROUTED ||\r\nmad->mad_hdr.mgmt_class == IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE) &&\r\nmad->mad_hdr.method == IB_MGMT_METHOD_SET) {\r\nif (mad->mad_hdr.attr_id == IB_SMP_ATTR_PORT_INFO) {\r\nstruct ib_port_info *pinfo =\r\n(struct ib_port_info *) ((struct ib_smp *) mad)->data;\r\nu16 lid = be16_to_cpu(pinfo->lid);\r\nmthca_update_rate(to_mdev(ibdev), port_num);\r\nupdate_sm_ah(to_mdev(ibdev), port_num,\r\nbe16_to_cpu(pinfo->sm_lid),\r\npinfo->neighbormtu_mastersmsl & 0xf);\r\nevent.device = ibdev;\r\nevent.element.port_num = port_num;\r\nif (pinfo->clientrereg_resv_subnetto & 0x80) {\r\nevent.event = IB_EVENT_CLIENT_REREGISTER;\r\nib_dispatch_event(&event);\r\n}\r\nif (prev_lid != lid) {\r\nevent.event = IB_EVENT_LID_CHANGE;\r\nib_dispatch_event(&event);\r\n}\r\n}\r\nif (mad->mad_hdr.attr_id == IB_SMP_ATTR_PKEY_TABLE) {\r\nevent.device = ibdev;\r\nevent.event = IB_EVENT_PKEY_CHANGE;\r\nevent.element.port_num = port_num;\r\nib_dispatch_event(&event);\r\n}\r\n}\r\n}\r\nstatic void node_desc_override(struct ib_device *dev,\r\nstruct ib_mad *mad)\r\n{\r\nif ((mad->mad_hdr.mgmt_class == IB_MGMT_CLASS_SUBN_LID_ROUTED ||\r\nmad->mad_hdr.mgmt_class == IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE) &&\r\nmad->mad_hdr.method == IB_MGMT_METHOD_GET_RESP &&\r\nmad->mad_hdr.attr_id == IB_SMP_ATTR_NODE_DESC) {\r\nmutex_lock(&to_mdev(dev)->cap_mask_mutex);\r\nmemcpy(((struct ib_smp *) mad)->data, dev->node_desc, 64);\r\nmutex_unlock(&to_mdev(dev)->cap_mask_mutex);\r\n}\r\n}\r\nstatic void forward_trap(struct mthca_dev *dev,\r\nu8 port_num,\r\nstruct ib_mad *mad)\r\n{\r\nint qpn = mad->mad_hdr.mgmt_class != IB_MGMT_CLASS_SUBN_LID_ROUTED;\r\nstruct ib_mad_send_buf *send_buf;\r\nstruct ib_mad_agent *agent = dev->send_agent[port_num - 1][qpn];\r\nint ret;\r\nunsigned long flags;\r\nif (agent) {\r\nsend_buf = ib_create_send_mad(agent, qpn, 0, 0, IB_MGMT_MAD_HDR,\r\nIB_MGMT_MAD_DATA, GFP_ATOMIC);\r\nif (IS_ERR(send_buf))\r\nreturn;\r\nspin_lock_irqsave(&dev->sm_lock, flags);\r\nmemcpy(send_buf->mad, mad, sizeof *mad);\r\nif ((send_buf->ah = dev->sm_ah[port_num - 1]))\r\nret = ib_post_send_mad(send_buf, NULL);\r\nelse\r\nret = -EINVAL;\r\nspin_unlock_irqrestore(&dev->sm_lock, flags);\r\nif (ret)\r\nib_free_send_mad(send_buf);\r\n}\r\n}\r\nint mthca_process_mad(struct ib_device *ibdev,\r\nint mad_flags,\r\nu8 port_num,\r\nstruct ib_wc *in_wc,\r\nstruct ib_grh *in_grh,\r\nstruct ib_mad *in_mad,\r\nstruct ib_mad *out_mad)\r\n{\r\nint err;\r\nu16 slid = in_wc ? in_wc->slid : be16_to_cpu(IB_LID_PERMISSIVE);\r\nu16 prev_lid = 0;\r\nstruct ib_port_attr pattr;\r\nif (in_mad->mad_hdr.method == IB_MGMT_METHOD_TRAP &&\r\nslid == 0) {\r\nforward_trap(to_mdev(ibdev), port_num, in_mad);\r\nreturn IB_MAD_RESULT_SUCCESS | IB_MAD_RESULT_CONSUMED;\r\n}\r\nif (in_mad->mad_hdr.mgmt_class == IB_MGMT_CLASS_SUBN_LID_ROUTED ||\r\nin_mad->mad_hdr.mgmt_class == IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE) {\r\nif (in_mad->mad_hdr.method != IB_MGMT_METHOD_GET &&\r\nin_mad->mad_hdr.method != IB_MGMT_METHOD_SET &&\r\nin_mad->mad_hdr.method != IB_MGMT_METHOD_TRAP_REPRESS)\r\nreturn IB_MAD_RESULT_SUCCESS;\r\nif (in_mad->mad_hdr.attr_id == IB_SMP_ATTR_SM_INFO ||\r\n((in_mad->mad_hdr.attr_id & IB_SMP_ATTR_VENDOR_MASK) ==\r\nIB_SMP_ATTR_VENDOR_MASK))\r\nreturn IB_MAD_RESULT_SUCCESS;\r\n} else if (in_mad->mad_hdr.mgmt_class == IB_MGMT_CLASS_PERF_MGMT ||\r\nin_mad->mad_hdr.mgmt_class == MTHCA_VENDOR_CLASS1 ||\r\nin_mad->mad_hdr.mgmt_class == MTHCA_VENDOR_CLASS2) {\r\nif (in_mad->mad_hdr.method != IB_MGMT_METHOD_GET &&\r\nin_mad->mad_hdr.method != IB_MGMT_METHOD_SET)\r\nreturn IB_MAD_RESULT_SUCCESS;\r\n} else\r\nreturn IB_MAD_RESULT_SUCCESS;\r\nif ((in_mad->mad_hdr.mgmt_class == IB_MGMT_CLASS_SUBN_LID_ROUTED ||\r\nin_mad->mad_hdr.mgmt_class == IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE) &&\r\nin_mad->mad_hdr.method == IB_MGMT_METHOD_SET &&\r\nin_mad->mad_hdr.attr_id == IB_SMP_ATTR_PORT_INFO &&\r\n!ib_query_port(ibdev, port_num, &pattr))\r\nprev_lid = pattr.lid;\r\nerr = mthca_MAD_IFC(to_mdev(ibdev),\r\nmad_flags & IB_MAD_IGNORE_MKEY,\r\nmad_flags & IB_MAD_IGNORE_BKEY,\r\nport_num, in_wc, in_grh, in_mad, out_mad);\r\nif (err == -EBADMSG)\r\nreturn IB_MAD_RESULT_SUCCESS;\r\nelse if (err) {\r\nmthca_err(to_mdev(ibdev), "MAD_IFC returned %d\n", err);\r\nreturn IB_MAD_RESULT_FAILURE;\r\n}\r\nif (!out_mad->mad_hdr.status) {\r\nsmp_snoop(ibdev, port_num, in_mad, prev_lid);\r\nnode_desc_override(ibdev, out_mad);\r\n}\r\nif (in_mad->mad_hdr.mgmt_class == IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE)\r\nout_mad->mad_hdr.status |= cpu_to_be16(1 << 15);\r\nif (in_mad->mad_hdr.method == IB_MGMT_METHOD_TRAP_REPRESS)\r\nreturn IB_MAD_RESULT_SUCCESS | IB_MAD_RESULT_CONSUMED;\r\nreturn IB_MAD_RESULT_SUCCESS | IB_MAD_RESULT_REPLY;\r\n}\r\nstatic void send_handler(struct ib_mad_agent *agent,\r\nstruct ib_mad_send_wc *mad_send_wc)\r\n{\r\nib_free_send_mad(mad_send_wc->send_buf);\r\n}\r\nint mthca_create_agents(struct mthca_dev *dev)\r\n{\r\nstruct ib_mad_agent *agent;\r\nint p, q;\r\nint ret;\r\nspin_lock_init(&dev->sm_lock);\r\nfor (p = 0; p < dev->limits.num_ports; ++p)\r\nfor (q = 0; q <= 1; ++q) {\r\nagent = ib_register_mad_agent(&dev->ib_dev, p + 1,\r\nq ? IB_QPT_GSI : IB_QPT_SMI,\r\nNULL, 0, send_handler,\r\nNULL, NULL);\r\nif (IS_ERR(agent)) {\r\nret = PTR_ERR(agent);\r\ngoto err;\r\n}\r\ndev->send_agent[p][q] = agent;\r\n}\r\nfor (p = 1; p <= dev->limits.num_ports; ++p) {\r\nret = mthca_update_rate(dev, p);\r\nif (ret) {\r\nmthca_err(dev, "Failed to obtain port %d rate."\r\n" aborting.\n", p);\r\ngoto err;\r\n}\r\n}\r\nreturn 0;\r\nerr:\r\nfor (p = 0; p < dev->limits.num_ports; ++p)\r\nfor (q = 0; q <= 1; ++q)\r\nif (dev->send_agent[p][q])\r\nib_unregister_mad_agent(dev->send_agent[p][q]);\r\nreturn ret;\r\n}\r\nvoid mthca_free_agents(struct mthca_dev *dev)\r\n{\r\nstruct ib_mad_agent *agent;\r\nint p, q;\r\nfor (p = 0; p < dev->limits.num_ports; ++p) {\r\nfor (q = 0; q <= 1; ++q) {\r\nagent = dev->send_agent[p][q];\r\ndev->send_agent[p][q] = NULL;\r\nib_unregister_mad_agent(agent);\r\n}\r\nif (dev->sm_ah[p])\r\nib_destroy_ah(dev->sm_ah[p]);\r\n}\r\n}
