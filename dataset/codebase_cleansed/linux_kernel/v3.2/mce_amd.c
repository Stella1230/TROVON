static int lvt_off_valid(struct threshold_block *b, int apic, u32 lo, u32 hi)\r\n{\r\nint msr = (hi & MASK_LVTOFF_HI) >> 20;\r\nif (apic < 0) {\r\npr_err(FW_BUG "cpu %d, failed to setup threshold interrupt "\r\n"for bank %d, block %d (MSR%08X=0x%x%08x)\n", b->cpu,\r\nb->bank, b->block, b->address, hi, lo);\r\nreturn 0;\r\n}\r\nif (apic != msr) {\r\npr_err(FW_BUG "cpu %d, invalid threshold interrupt offset %d "\r\n"for bank %d, block %d (MSR%08X=0x%x%08x)\n",\r\nb->cpu, apic, b->bank, b->block, b->address, hi, lo);\r\nreturn 0;\r\n}\r\nreturn 1;\r\n}\r\nstatic void threshold_restart_bank(void *_tr)\r\n{\r\nstruct thresh_restart *tr = _tr;\r\nu32 hi, lo;\r\nrdmsr(tr->b->address, lo, hi);\r\nif (tr->b->threshold_limit < (hi & THRESHOLD_MAX))\r\ntr->reset = 1;\r\nif (tr->reset) {\r\nhi =\r\n(hi & ~(MASK_ERR_COUNT_HI | MASK_OVERFLOW_HI)) |\r\n(THRESHOLD_MAX - tr->b->threshold_limit);\r\n} else if (tr->old_limit) {\r\nint new_count = (hi & THRESHOLD_MAX) +\r\n(tr->old_limit - tr->b->threshold_limit);\r\nhi = (hi & ~MASK_ERR_COUNT_HI) |\r\n(new_count & THRESHOLD_MAX);\r\n}\r\nif (tr->set_lvt_off) {\r\nif (lvt_off_valid(tr->b, tr->lvt_off, lo, hi)) {\r\nhi &= ~MASK_LVTOFF_HI;\r\nhi |= tr->lvt_off << 20;\r\n}\r\n}\r\ntr->b->interrupt_enable ?\r\n(hi = (hi & ~MASK_INT_TYPE_HI) | INT_TYPE_APIC) :\r\n(hi &= ~MASK_INT_TYPE_HI);\r\nhi |= MASK_COUNT_EN_HI;\r\nwrmsr(tr->b->address, lo, hi);\r\n}\r\nstatic void mce_threshold_block_init(struct threshold_block *b, int offset)\r\n{\r\nstruct thresh_restart tr = {\r\n.b = b,\r\n.set_lvt_off = 1,\r\n.lvt_off = offset,\r\n};\r\nb->threshold_limit = THRESHOLD_MAX;\r\nthreshold_restart_bank(&tr);\r\n}\r\nstatic int setup_APIC_mce(int reserved, int new)\r\n{\r\nif (reserved < 0 && !setup_APIC_eilvt(new, THRESHOLD_APIC_VECTOR,\r\nAPIC_EILVT_MSG_FIX, 0))\r\nreturn new;\r\nreturn reserved;\r\n}\r\nvoid mce_amd_feature_init(struct cpuinfo_x86 *c)\r\n{\r\nstruct threshold_block b;\r\nunsigned int cpu = smp_processor_id();\r\nu32 low = 0, high = 0, address = 0;\r\nunsigned int bank, block;\r\nint offset = -1;\r\nfor (bank = 0; bank < NR_BANKS; ++bank) {\r\nfor (block = 0; block < NR_BLOCKS; ++block) {\r\nif (block == 0)\r\naddress = MSR_IA32_MC0_MISC + bank * 4;\r\nelse if (block == 1) {\r\naddress = (low & MASK_BLKPTR_LO) >> 21;\r\nif (!address)\r\nbreak;\r\naddress += MCG_XBLK_ADDR;\r\n} else\r\n++address;\r\nif (rdmsr_safe(address, &low, &high))\r\nbreak;\r\nif (!(high & MASK_VALID_HI))\r\ncontinue;\r\nif (!(high & MASK_CNTP_HI) ||\r\n(high & MASK_LOCKED_HI))\r\ncontinue;\r\nif (!block)\r\nper_cpu(bank_map, cpu) |= (1 << bank);\r\n#ifdef CONFIG_SMP\r\nif (shared_bank[bank] && c->cpu_core_id)\r\nbreak;\r\n#endif\r\noffset = setup_APIC_mce(offset,\r\n(high & MASK_LVTOFF_HI) >> 20);\r\nmemset(&b, 0, sizeof(b));\r\nb.cpu = cpu;\r\nb.bank = bank;\r\nb.block = block;\r\nb.address = address;\r\nmce_threshold_block_init(&b, offset);\r\nmce_threshold_vector = amd_threshold_interrupt;\r\n}\r\n}\r\n}\r\nstatic void amd_threshold_interrupt(void)\r\n{\r\nu32 low = 0, high = 0, address = 0;\r\nunsigned int bank, block;\r\nstruct mce m;\r\nmce_setup(&m);\r\nfor (bank = 0; bank < NR_BANKS; ++bank) {\r\nif (!(per_cpu(bank_map, m.cpu) & (1 << bank)))\r\ncontinue;\r\nfor (block = 0; block < NR_BLOCKS; ++block) {\r\nif (block == 0) {\r\naddress = MSR_IA32_MC0_MISC + bank * 4;\r\n} else if (block == 1) {\r\naddress = (low & MASK_BLKPTR_LO) >> 21;\r\nif (!address)\r\nbreak;\r\naddress += MCG_XBLK_ADDR;\r\n} else {\r\n++address;\r\n}\r\nif (rdmsr_safe(address, &low, &high))\r\nbreak;\r\nif (!(high & MASK_VALID_HI)) {\r\nif (block)\r\ncontinue;\r\nelse\r\nbreak;\r\n}\r\nif (!(high & MASK_CNTP_HI) ||\r\n(high & MASK_LOCKED_HI))\r\ncontinue;\r\nmachine_check_poll(MCP_TIMESTAMP,\r\n&__get_cpu_var(mce_poll_banks));\r\nif (high & MASK_OVERFLOW_HI) {\r\nrdmsrl(address, m.misc);\r\nrdmsrl(MSR_IA32_MC0_STATUS + bank * 4,\r\nm.status);\r\nm.bank = K8_MCE_THRESHOLD_BASE\r\n+ bank * NR_BLOCKS\r\n+ block;\r\nmce_log(&m);\r\nreturn;\r\n}\r\n}\r\n}\r\n}\r\nstatic ssize_t\r\nstore_interrupt_enable(struct threshold_block *b, const char *buf, size_t size)\r\n{\r\nstruct thresh_restart tr;\r\nunsigned long new;\r\nif (strict_strtoul(buf, 0, &new) < 0)\r\nreturn -EINVAL;\r\nb->interrupt_enable = !!new;\r\nmemset(&tr, 0, sizeof(tr));\r\ntr.b = b;\r\nsmp_call_function_single(b->cpu, threshold_restart_bank, &tr, 1);\r\nreturn size;\r\n}\r\nstatic ssize_t\r\nstore_threshold_limit(struct threshold_block *b, const char *buf, size_t size)\r\n{\r\nstruct thresh_restart tr;\r\nunsigned long new;\r\nif (strict_strtoul(buf, 0, &new) < 0)\r\nreturn -EINVAL;\r\nif (new > THRESHOLD_MAX)\r\nnew = THRESHOLD_MAX;\r\nif (new < 1)\r\nnew = 1;\r\nmemset(&tr, 0, sizeof(tr));\r\ntr.old_limit = b->threshold_limit;\r\nb->threshold_limit = new;\r\ntr.b = b;\r\nsmp_call_function_single(b->cpu, threshold_restart_bank, &tr, 1);\r\nreturn size;\r\n}\r\nstatic void local_error_count_handler(void *_tbcc)\r\n{\r\nstruct threshold_block_cross_cpu *tbcc = _tbcc;\r\nstruct threshold_block *b = tbcc->tb;\r\nu32 low, high;\r\nrdmsr(b->address, low, high);\r\ntbcc->retval = (high & 0xFFF) - (THRESHOLD_MAX - b->threshold_limit);\r\n}\r\nstatic ssize_t show_error_count(struct threshold_block *b, char *buf)\r\n{\r\nstruct threshold_block_cross_cpu tbcc = { .tb = b, };\r\nsmp_call_function_single(b->cpu, local_error_count_handler, &tbcc, 1);\r\nreturn sprintf(buf, "%lx\n", tbcc.retval);\r\n}\r\nstatic ssize_t store_error_count(struct threshold_block *b,\r\nconst char *buf, size_t count)\r\n{\r\nstruct thresh_restart tr = { .b = b, .reset = 1, .old_limit = 0 };\r\nsmp_call_function_single(b->cpu, threshold_restart_bank, &tr, 1);\r\nreturn 1;\r\n}\r\nstatic ssize_t show(struct kobject *kobj, struct attribute *attr, char *buf)\r\n{\r\nstruct threshold_block *b = to_block(kobj);\r\nstruct threshold_attr *a = to_attr(attr);\r\nssize_t ret;\r\nret = a->show ? a->show(b, buf) : -EIO;\r\nreturn ret;\r\n}\r\nstatic ssize_t store(struct kobject *kobj, struct attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nstruct threshold_block *b = to_block(kobj);\r\nstruct threshold_attr *a = to_attr(attr);\r\nssize_t ret;\r\nret = a->store ? a->store(b, buf, count) : -EIO;\r\nreturn ret;\r\n}\r\nstatic __cpuinit int allocate_threshold_blocks(unsigned int cpu,\r\nunsigned int bank,\r\nunsigned int block,\r\nu32 address)\r\n{\r\nstruct threshold_block *b = NULL;\r\nu32 low, high;\r\nint err;\r\nif ((bank >= NR_BANKS) || (block >= NR_BLOCKS))\r\nreturn 0;\r\nif (rdmsr_safe_on_cpu(cpu, address, &low, &high))\r\nreturn 0;\r\nif (!(high & MASK_VALID_HI)) {\r\nif (block)\r\ngoto recurse;\r\nelse\r\nreturn 0;\r\n}\r\nif (!(high & MASK_CNTP_HI) ||\r\n(high & MASK_LOCKED_HI))\r\ngoto recurse;\r\nb = kzalloc(sizeof(struct threshold_block), GFP_KERNEL);\r\nif (!b)\r\nreturn -ENOMEM;\r\nb->block = block;\r\nb->bank = bank;\r\nb->cpu = cpu;\r\nb->address = address;\r\nb->interrupt_enable = 0;\r\nb->threshold_limit = THRESHOLD_MAX;\r\nINIT_LIST_HEAD(&b->miscj);\r\nif (per_cpu(threshold_banks, cpu)[bank]->blocks) {\r\nlist_add(&b->miscj,\r\n&per_cpu(threshold_banks, cpu)[bank]->blocks->miscj);\r\n} else {\r\nper_cpu(threshold_banks, cpu)[bank]->blocks = b;\r\n}\r\nerr = kobject_init_and_add(&b->kobj, &threshold_ktype,\r\nper_cpu(threshold_banks, cpu)[bank]->kobj,\r\n"misc%i", block);\r\nif (err)\r\ngoto out_free;\r\nrecurse:\r\nif (!block) {\r\naddress = (low & MASK_BLKPTR_LO) >> 21;\r\nif (!address)\r\nreturn 0;\r\naddress += MCG_XBLK_ADDR;\r\n} else {\r\n++address;\r\n}\r\nerr = allocate_threshold_blocks(cpu, bank, ++block, address);\r\nif (err)\r\ngoto out_free;\r\nif (b)\r\nkobject_uevent(&b->kobj, KOBJ_ADD);\r\nreturn err;\r\nout_free:\r\nif (b) {\r\nkobject_put(&b->kobj);\r\nlist_del(&b->miscj);\r\nkfree(b);\r\n}\r\nreturn err;\r\n}\r\nstatic __cpuinit long\r\nlocal_allocate_threshold_blocks(int cpu, unsigned int bank)\r\n{\r\nreturn allocate_threshold_blocks(cpu, bank, 0,\r\nMSR_IA32_MC0_MISC + bank * 4);\r\n}\r\nstatic __cpuinit int threshold_create_bank(unsigned int cpu, unsigned int bank)\r\n{\r\nint i, err = 0;\r\nstruct threshold_bank *b = NULL;\r\nchar name[32];\r\nsprintf(name, "threshold_bank%i", bank);\r\n#ifdef CONFIG_SMP\r\nif (cpu_data(cpu).cpu_core_id && shared_bank[bank]) {\r\ni = cpumask_first(cpu_llc_shared_mask(cpu));\r\nif (cpu_data(i).cpu_core_id)\r\ngoto out;\r\nif (per_cpu(threshold_banks, cpu)[bank])\r\ngoto out;\r\nb = per_cpu(threshold_banks, i)[bank];\r\nif (!b)\r\ngoto out;\r\nerr = sysfs_create_link(&per_cpu(mce_sysdev, cpu).kobj,\r\nb->kobj, name);\r\nif (err)\r\ngoto out;\r\ncpumask_copy(b->cpus, cpu_llc_shared_mask(cpu));\r\nper_cpu(threshold_banks, cpu)[bank] = b;\r\ngoto out;\r\n}\r\n#endif\r\nb = kzalloc(sizeof(struct threshold_bank), GFP_KERNEL);\r\nif (!b) {\r\nerr = -ENOMEM;\r\ngoto out;\r\n}\r\nif (!zalloc_cpumask_var(&b->cpus, GFP_KERNEL)) {\r\nkfree(b);\r\nerr = -ENOMEM;\r\ngoto out;\r\n}\r\nb->kobj = kobject_create_and_add(name, &per_cpu(mce_sysdev, cpu).kobj);\r\nif (!b->kobj)\r\ngoto out_free;\r\n#ifndef CONFIG_SMP\r\ncpumask_setall(b->cpus);\r\n#else\r\ncpumask_set_cpu(cpu, b->cpus);\r\n#endif\r\nper_cpu(threshold_banks, cpu)[bank] = b;\r\nerr = local_allocate_threshold_blocks(cpu, bank);\r\nif (err)\r\ngoto out_free;\r\nfor_each_cpu(i, b->cpus) {\r\nif (i == cpu)\r\ncontinue;\r\nerr = sysfs_create_link(&per_cpu(mce_sysdev, i).kobj,\r\nb->kobj, name);\r\nif (err)\r\ngoto out;\r\nper_cpu(threshold_banks, i)[bank] = b;\r\n}\r\ngoto out;\r\nout_free:\r\nper_cpu(threshold_banks, cpu)[bank] = NULL;\r\nfree_cpumask_var(b->cpus);\r\nkfree(b);\r\nout:\r\nreturn err;\r\n}\r\nstatic __cpuinit int threshold_create_device(unsigned int cpu)\r\n{\r\nunsigned int bank;\r\nint err = 0;\r\nfor (bank = 0; bank < NR_BANKS; ++bank) {\r\nif (!(per_cpu(bank_map, cpu) & (1 << bank)))\r\ncontinue;\r\nerr = threshold_create_bank(cpu, bank);\r\nif (err)\r\nreturn err;\r\n}\r\nreturn err;\r\n}\r\nstatic void deallocate_threshold_block(unsigned int cpu,\r\nunsigned int bank)\r\n{\r\nstruct threshold_block *pos = NULL;\r\nstruct threshold_block *tmp = NULL;\r\nstruct threshold_bank *head = per_cpu(threshold_banks, cpu)[bank];\r\nif (!head)\r\nreturn;\r\nlist_for_each_entry_safe(pos, tmp, &head->blocks->miscj, miscj) {\r\nkobject_put(&pos->kobj);\r\nlist_del(&pos->miscj);\r\nkfree(pos);\r\n}\r\nkfree(per_cpu(threshold_banks, cpu)[bank]->blocks);\r\nper_cpu(threshold_banks, cpu)[bank]->blocks = NULL;\r\n}\r\nstatic void threshold_remove_bank(unsigned int cpu, int bank)\r\n{\r\nstruct threshold_bank *b;\r\nchar name[32];\r\nint i = 0;\r\nb = per_cpu(threshold_banks, cpu)[bank];\r\nif (!b)\r\nreturn;\r\nif (!b->blocks)\r\ngoto free_out;\r\nsprintf(name, "threshold_bank%i", bank);\r\n#ifdef CONFIG_SMP\r\nif (shared_bank[bank] && b->blocks->cpu != cpu) {\r\nsysfs_remove_link(&per_cpu(mce_sysdev, cpu).kobj, name);\r\nper_cpu(threshold_banks, cpu)[bank] = NULL;\r\nreturn;\r\n}\r\n#endif\r\nfor_each_cpu(i, b->cpus) {\r\nif (i == cpu)\r\ncontinue;\r\nsysfs_remove_link(&per_cpu(mce_sysdev, i).kobj, name);\r\nper_cpu(threshold_banks, i)[bank] = NULL;\r\n}\r\ndeallocate_threshold_block(cpu, bank);\r\nfree_out:\r\nkobject_del(b->kobj);\r\nkobject_put(b->kobj);\r\nfree_cpumask_var(b->cpus);\r\nkfree(b);\r\nper_cpu(threshold_banks, cpu)[bank] = NULL;\r\n}\r\nstatic void threshold_remove_device(unsigned int cpu)\r\n{\r\nunsigned int bank;\r\nfor (bank = 0; bank < NR_BANKS; ++bank) {\r\nif (!(per_cpu(bank_map, cpu) & (1 << bank)))\r\ncontinue;\r\nthreshold_remove_bank(cpu, bank);\r\n}\r\n}\r\nstatic void __cpuinit\r\namd_64_threshold_cpu_callback(unsigned long action, unsigned int cpu)\r\n{\r\nswitch (action) {\r\ncase CPU_ONLINE:\r\ncase CPU_ONLINE_FROZEN:\r\nthreshold_create_device(cpu);\r\nbreak;\r\ncase CPU_DEAD:\r\ncase CPU_DEAD_FROZEN:\r\nthreshold_remove_device(cpu);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nstatic __init int threshold_init_device(void)\r\n{\r\nunsigned lcpu = 0;\r\nfor_each_online_cpu(lcpu) {\r\nint err = threshold_create_device(lcpu);\r\nif (err)\r\nreturn err;\r\n}\r\nthreshold_cpu_callback = amd_64_threshold_cpu_callback;\r\nreturn 0;\r\n}
