static unsigned long idt_address(u32 lo, u32 hi)\r\n{\r\nreturn (lo & 0x0000FFFF) | (hi & 0xFFFF0000);\r\n}\r\nstatic int idt_type(u32 lo, u32 hi)\r\n{\r\nreturn (hi >> 8) & 0xF;\r\n}\r\nstatic bool idt_present(u32 lo, u32 hi)\r\n{\r\nreturn (hi & 0x8000);\r\n}\r\nstatic void push_guest_stack(struct lg_cpu *cpu, unsigned long *gstack, u32 val)\r\n{\r\n*gstack -= 4;\r\nlgwrite(cpu, *gstack, u32, val);\r\n}\r\nstatic void set_guest_interrupt(struct lg_cpu *cpu, u32 lo, u32 hi,\r\nbool has_err)\r\n{\r\nunsigned long gstack, origstack;\r\nu32 eflags, ss, irq_enable;\r\nunsigned long virtstack;\r\nif ((cpu->regs->ss&0x3) != GUEST_PL) {\r\nvirtstack = cpu->esp1;\r\nss = cpu->ss1;\r\norigstack = gstack = guest_pa(cpu, virtstack);\r\npush_guest_stack(cpu, &gstack, cpu->regs->ss);\r\npush_guest_stack(cpu, &gstack, cpu->regs->esp);\r\n} else {\r\nvirtstack = cpu->regs->esp;\r\nss = cpu->regs->ss;\r\norigstack = gstack = guest_pa(cpu, virtstack);\r\n}\r\neflags = cpu->regs->eflags;\r\nif (get_user(irq_enable, &cpu->lg->lguest_data->irq_enabled) == 0\r\n&& !(irq_enable & X86_EFLAGS_IF))\r\neflags &= ~X86_EFLAGS_IF;\r\npush_guest_stack(cpu, &gstack, eflags);\r\npush_guest_stack(cpu, &gstack, cpu->regs->cs);\r\npush_guest_stack(cpu, &gstack, cpu->regs->eip);\r\nif (has_err)\r\npush_guest_stack(cpu, &gstack, cpu->regs->errcode);\r\ncpu->regs->ss = ss;\r\ncpu->regs->esp = virtstack + (gstack - origstack);\r\ncpu->regs->cs = (__KERNEL_CS|GUEST_PL);\r\ncpu->regs->eip = idt_address(lo, hi);\r\nif (idt_type(lo, hi) == 0xE)\r\nif (put_user(0, &cpu->lg->lguest_data->irq_enabled))\r\nkill_guest(cpu, "Disabling interrupts");\r\n}\r\nunsigned int interrupt_pending(struct lg_cpu *cpu, bool *more)\r\n{\r\nunsigned int irq;\r\nDECLARE_BITMAP(blk, LGUEST_IRQS);\r\nif (!cpu->lg->lguest_data)\r\nreturn LGUEST_IRQS;\r\nif (copy_from_user(&blk, cpu->lg->lguest_data->blocked_interrupts,\r\nsizeof(blk)))\r\nreturn LGUEST_IRQS;\r\nbitmap_andnot(blk, cpu->irqs_pending, blk, LGUEST_IRQS);\r\nirq = find_first_bit(blk, LGUEST_IRQS);\r\n*more = find_next_bit(blk, LGUEST_IRQS, irq+1);\r\nreturn irq;\r\n}\r\nvoid try_deliver_interrupt(struct lg_cpu *cpu, unsigned int irq, bool more)\r\n{\r\nstruct desc_struct *idt;\r\nBUG_ON(irq >= LGUEST_IRQS);\r\nif (cpu->regs->eip >= cpu->lg->noirq_start &&\r\n(cpu->regs->eip < cpu->lg->noirq_end))\r\nreturn;\r\nif (cpu->halted) {\r\nif (put_user(X86_EFLAGS_IF, &cpu->lg->lguest_data->irq_enabled))\r\nkill_guest(cpu, "Re-enabling interrupts");\r\ncpu->halted = 0;\r\n} else {\r\nu32 irq_enabled;\r\nif (get_user(irq_enabled, &cpu->lg->lguest_data->irq_enabled))\r\nirq_enabled = 0;\r\nif (!irq_enabled) {\r\nput_user(X86_EFLAGS_IF,\r\n&cpu->lg->lguest_data->irq_pending);\r\nreturn;\r\n}\r\n}\r\nidt = &cpu->arch.idt[FIRST_EXTERNAL_VECTOR+irq];\r\nif (idt_present(idt->a, idt->b)) {\r\nclear_bit(irq, cpu->irqs_pending);\r\nset_guest_interrupt(cpu, idt->a, idt->b, false);\r\n}\r\nwrite_timestamp(cpu);\r\nif (!more)\r\nput_user(0, &cpu->lg->lguest_data->irq_pending);\r\n}\r\nvoid set_interrupt(struct lg_cpu *cpu, unsigned int irq)\r\n{\r\nset_bit(irq, cpu->irqs_pending);\r\nif (!wake_up_process(cpu->tsk))\r\nkick_process(cpu->tsk);\r\n}\r\nstatic bool could_be_syscall(unsigned int num)\r\n{\r\nreturn num == SYSCALL_VECTOR || num == syscall_vector;\r\n}\r\nbool check_syscall_vector(struct lguest *lg)\r\n{\r\nu32 vector;\r\nif (get_user(vector, &lg->lguest_data->syscall_vec))\r\nreturn false;\r\nreturn could_be_syscall(vector);\r\n}\r\nint init_interrupts(void)\r\n{\r\nif (syscall_vector != SYSCALL_VECTOR) {\r\nif (test_bit(syscall_vector, used_vectors) ||\r\nvector_used_by_percpu_irq(syscall_vector)) {\r\nprintk(KERN_ERR "lg: couldn't reserve syscall %u\n",\r\nsyscall_vector);\r\nreturn -EBUSY;\r\n}\r\nset_bit(syscall_vector, used_vectors);\r\n}\r\nreturn 0;\r\n}\r\nvoid free_interrupts(void)\r\n{\r\nif (syscall_vector != SYSCALL_VECTOR)\r\nclear_bit(syscall_vector, used_vectors);\r\n}\r\nstatic bool has_err(unsigned int trap)\r\n{\r\nreturn (trap == 8 || (trap >= 10 && trap <= 14) || trap == 17);\r\n}\r\nbool deliver_trap(struct lg_cpu *cpu, unsigned int num)\r\n{\r\nif (num >= ARRAY_SIZE(cpu->arch.idt))\r\nreturn false;\r\nif (!idt_present(cpu->arch.idt[num].a, cpu->arch.idt[num].b))\r\nreturn false;\r\nset_guest_interrupt(cpu, cpu->arch.idt[num].a,\r\ncpu->arch.idt[num].b, has_err(num));\r\nreturn true;\r\n}\r\nstatic bool direct_trap(unsigned int num)\r\n{\r\nif (num >= FIRST_EXTERNAL_VECTOR && !could_be_syscall(num))\r\nreturn false;\r\nreturn num != 14 && num != 13 && num != 7 && num != LGUEST_TRAP_ENTRY;\r\n}\r\nvoid pin_stack_pages(struct lg_cpu *cpu)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < cpu->lg->stack_pages; i++)\r\npin_page(cpu, cpu->esp1 - 1 - i * PAGE_SIZE);\r\n}\r\nvoid guest_set_stack(struct lg_cpu *cpu, u32 seg, u32 esp, unsigned int pages)\r\n{\r\nif ((seg & 0x3) != GUEST_PL)\r\nkill_guest(cpu, "bad stack segment %i", seg);\r\nif (pages > 2)\r\nkill_guest(cpu, "bad stack pages %u", pages);\r\ncpu->ss1 = seg;\r\ncpu->esp1 = esp;\r\ncpu->lg->stack_pages = pages;\r\npin_stack_pages(cpu);\r\n}\r\nstatic void set_trap(struct lg_cpu *cpu, struct desc_struct *trap,\r\nunsigned int num, u32 lo, u32 hi)\r\n{\r\nu8 type = idt_type(lo, hi);\r\nif (!idt_present(lo, hi)) {\r\ntrap->a = trap->b = 0;\r\nreturn;\r\n}\r\nif (type != 0xE && type != 0xF)\r\nkill_guest(cpu, "bad IDT type %i", type);\r\ntrap->a = ((__KERNEL_CS|GUEST_PL)<<16) | (lo&0x0000FFFF);\r\ntrap->b = (hi&0xFFFFEF00);\r\n}\r\nvoid load_guest_idt_entry(struct lg_cpu *cpu, unsigned int num, u32 lo, u32 hi)\r\n{\r\nif (num == 2 || num == 8 || num == 15 || num == LGUEST_TRAP_ENTRY)\r\nreturn;\r\ncpu->changed |= CHANGED_IDT;\r\nif (num >= ARRAY_SIZE(cpu->arch.idt))\r\nkill_guest(cpu, "Setting idt entry %u", num);\r\nelse\r\nset_trap(cpu, &cpu->arch.idt[num], num, lo, hi);\r\n}\r\nstatic void default_idt_entry(struct desc_struct *idt,\r\nint trap,\r\nconst unsigned long handler,\r\nconst struct desc_struct *base)\r\n{\r\nu32 flags = 0x8e00;\r\nif (trap == LGUEST_TRAP_ENTRY)\r\nflags |= (GUEST_PL << 13);\r\nelse if (base)\r\nflags |= (base->b & 0x6000);\r\nidt->a = (LGUEST_CS<<16) | (handler&0x0000FFFF);\r\nidt->b = (handler&0xFFFF0000) | flags;\r\n}\r\nvoid setup_default_idt_entries(struct lguest_ro_state *state,\r\nconst unsigned long *def)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < ARRAY_SIZE(state->guest_idt); i++)\r\ndefault_idt_entry(&state->guest_idt[i], i, def[i], NULL);\r\n}\r\nvoid copy_traps(const struct lg_cpu *cpu, struct desc_struct *idt,\r\nconst unsigned long *def)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < ARRAY_SIZE(cpu->arch.idt); i++) {\r\nconst struct desc_struct *gidt = &cpu->arch.idt[i];\r\nif (!direct_trap(i))\r\ncontinue;\r\nif (idt_type(gidt->a, gidt->b) == 0xF)\r\nidt[i] = *gidt;\r\nelse\r\ndefault_idt_entry(&idt[i], i, def[i], gidt);\r\n}\r\n}\r\nvoid guest_set_clockevent(struct lg_cpu *cpu, unsigned long delta)\r\n{\r\nktime_t expires;\r\nif (unlikely(delta == 0)) {\r\nhrtimer_cancel(&cpu->hrt);\r\nreturn;\r\n}\r\nexpires = ktime_add_ns(ktime_get_real(), delta);\r\nhrtimer_start(&cpu->hrt, expires, HRTIMER_MODE_ABS);\r\n}\r\nstatic enum hrtimer_restart clockdev_fn(struct hrtimer *timer)\r\n{\r\nstruct lg_cpu *cpu = container_of(timer, struct lg_cpu, hrt);\r\nset_interrupt(cpu, 0);\r\nreturn HRTIMER_NORESTART;\r\n}\r\nvoid init_clockdev(struct lg_cpu *cpu)\r\n{\r\nhrtimer_init(&cpu->hrt, CLOCK_REALTIME, HRTIMER_MODE_ABS);\r\ncpu->hrt.function = clockdev_fn;\r\n}
