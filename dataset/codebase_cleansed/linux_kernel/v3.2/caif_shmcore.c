static int shm_netdev_open(struct net_device *shm_netdev)\r\n{\r\nnetif_wake_queue(shm_netdev);\r\nreturn 0;\r\n}\r\nstatic int shm_netdev_close(struct net_device *shm_netdev)\r\n{\r\nnetif_stop_queue(shm_netdev);\r\nreturn 0;\r\n}\r\nint caif_shmdrv_rx_cb(u32 mbx_msg, void *priv)\r\n{\r\nstruct buf_list *pbuf;\r\nstruct shmdrv_layer *pshm_drv;\r\nstruct list_head *pos;\r\nu32 avail_emptybuff = 0;\r\nunsigned long flags = 0;\r\npshm_drv = priv;\r\nif (mbx_msg & SHM_FULL_MASK) {\r\nint idx;\r\nspin_lock_irqsave(&pshm_drv->lock, flags);\r\nif (list_empty(&pshm_drv->rx_empty_list)) {\r\nspin_unlock_irqrestore(&pshm_drv->lock, flags);\r\npr_warn("No empty Rx buffers to fill: "\r\n"mbx_msg:%x\n", mbx_msg);\r\ngoto err_sync;\r\n}\r\npbuf =\r\nlist_entry(pshm_drv->rx_empty_list.next,\r\nstruct buf_list, list);\r\nidx = pbuf->index;\r\nif (idx != SHM_GET_FULL(mbx_msg)) {\r\npr_warn(\r\n"phyif_shm_mbx_msg_cb: RX full out of sync:"\r\n" idx:%d, msg:%x SHM_GET_FULL(mbx_msg):%x\n",\r\nidx, mbx_msg, SHM_GET_FULL(mbx_msg));\r\nspin_unlock_irqrestore(&pshm_drv->lock, flags);\r\ngoto err_sync;\r\n}\r\nlist_del_init(&pbuf->list);\r\nlist_add_tail(&pbuf->list, &pshm_drv->rx_full_list);\r\nspin_unlock_irqrestore(&pshm_drv->lock, flags);\r\nif (!work_pending(&pshm_drv->shm_rx_work))\r\nqueue_work(pshm_drv->pshm_rx_workqueue,\r\n&pshm_drv->shm_rx_work);\r\n}\r\nif (mbx_msg & SHM_EMPTY_MASK) {\r\nint idx;\r\nspin_lock_irqsave(&pshm_drv->lock, flags);\r\nif (list_empty(&pshm_drv->tx_full_list)) {\r\npr_warn("No TX to empty: msg:%x\n", mbx_msg);\r\nspin_unlock_irqrestore(&pshm_drv->lock, flags);\r\ngoto err_sync;\r\n}\r\npbuf =\r\nlist_entry(pshm_drv->tx_full_list.next,\r\nstruct buf_list, list);\r\nidx = pbuf->index;\r\nif (idx != SHM_GET_EMPTY(mbx_msg)) {\r\nspin_unlock_irqrestore(&pshm_drv->lock, flags);\r\npr_warn("TX empty "\r\n"out of sync:idx:%d, msg:%x\n", idx, mbx_msg);\r\ngoto err_sync;\r\n}\r\nlist_del_init(&pbuf->list);\r\npbuf->frames = 0;\r\npbuf->frm_ofs = SHM_CAIF_FRM_OFS;\r\nlist_add_tail(&pbuf->list, &pshm_drv->tx_empty_list);\r\nlist_for_each(pos, &pshm_drv->tx_empty_list)\r\navail_emptybuff++;\r\nif ((avail_emptybuff > HIGH_WATERMARK) &&\r\n(!pshm_drv->tx_empty_available)) {\r\npshm_drv->tx_empty_available = 1;\r\npshm_drv->cfdev.flowctrl\r\n(pshm_drv->pshm_dev->pshm_netdev,\r\nCAIF_FLOW_ON);\r\nspin_unlock_irqrestore(&pshm_drv->lock, flags);\r\nif (!work_pending(&pshm_drv->shm_tx_work))\r\nqueue_work(pshm_drv->pshm_tx_workqueue,\r\n&pshm_drv->shm_tx_work);\r\n} else\r\nspin_unlock_irqrestore(&pshm_drv->lock, flags);\r\n}\r\nreturn 0;\r\nerr_sync:\r\nreturn -EIO;\r\n}\r\nstatic void shm_rx_work_func(struct work_struct *rx_work)\r\n{\r\nstruct shmdrv_layer *pshm_drv;\r\nstruct buf_list *pbuf;\r\nunsigned long flags = 0;\r\nstruct sk_buff *skb;\r\nchar *p;\r\nint ret;\r\npshm_drv = container_of(rx_work, struct shmdrv_layer, shm_rx_work);\r\nwhile (1) {\r\nstruct shm_pck_desc *pck_desc;\r\nspin_lock_irqsave(&pshm_drv->lock, flags);\r\nif (list_empty(&pshm_drv->rx_full_list)) {\r\nspin_unlock_irqrestore(&pshm_drv->lock, flags);\r\nbreak;\r\n}\r\npbuf =\r\nlist_entry(pshm_drv->rx_full_list.next, struct buf_list,\r\nlist);\r\nlist_del_init(&pbuf->list);\r\npck_desc = (struct shm_pck_desc *) pbuf->desc_vptr;\r\nwhile (pck_desc->frm_ofs) {\r\nunsigned int frm_buf_ofs;\r\nunsigned int frm_pck_ofs;\r\nunsigned int frm_pck_len;\r\nif (pck_desc->frm_ofs <\r\n(pbuf->phy_addr - pshm_drv->shm_base_addr))\r\nbreak;\r\nif (pck_desc->frm_ofs >\r\n((pbuf->phy_addr - pshm_drv->shm_base_addr) +\r\npbuf->len))\r\nbreak;\r\nfrm_buf_ofs =\r\npck_desc->frm_ofs - (pbuf->phy_addr -\r\npshm_drv->shm_base_addr);\r\nfrm_pck_ofs =\r\nfrm_buf_ofs + SHM_HDR_LEN +\r\n(*(pbuf->desc_vptr + frm_buf_ofs));\r\nfrm_pck_len =\r\n(pck_desc->frm_len - SHM_HDR_LEN -\r\n(*(pbuf->desc_vptr + frm_buf_ofs)));\r\nif ((frm_pck_ofs + pck_desc->frm_len) > pbuf->len)\r\nbreak;\r\nskb = netdev_alloc_skb(pshm_drv->pshm_dev->pshm_netdev,\r\nfrm_pck_len + 1);\r\nBUG_ON(skb == NULL);\r\np = skb_put(skb, frm_pck_len);\r\nmemcpy(p, pbuf->desc_vptr + frm_pck_ofs, frm_pck_len);\r\nskb->protocol = htons(ETH_P_CAIF);\r\nskb_reset_mac_header(skb);\r\nskb->dev = pshm_drv->pshm_dev->pshm_netdev;\r\nret = netif_rx_ni(skb);\r\nif (!ret) {\r\npshm_drv->pshm_dev->pshm_netdev->stats.\r\nrx_packets++;\r\npshm_drv->pshm_dev->pshm_netdev->stats.\r\nrx_bytes += pck_desc->frm_len;\r\n} else\r\n++pshm_drv->pshm_dev->pshm_netdev->stats.\r\nrx_dropped;\r\npck_desc++;\r\n}\r\nlist_add_tail(&pbuf->list, &pshm_drv->rx_pend_list);\r\nspin_unlock_irqrestore(&pshm_drv->lock, flags);\r\n}\r\nif (!work_pending(&pshm_drv->shm_tx_work))\r\nqueue_work(pshm_drv->pshm_tx_workqueue, &pshm_drv->shm_tx_work);\r\n}\r\nstatic void shm_tx_work_func(struct work_struct *tx_work)\r\n{\r\nu32 mbox_msg;\r\nunsigned int frmlen, avail_emptybuff, append = 0;\r\nunsigned long flags = 0;\r\nstruct buf_list *pbuf = NULL;\r\nstruct shmdrv_layer *pshm_drv;\r\nstruct shm_caif_frm *frm;\r\nstruct sk_buff *skb;\r\nstruct shm_pck_desc *pck_desc;\r\nstruct list_head *pos;\r\npshm_drv = container_of(tx_work, struct shmdrv_layer, shm_tx_work);\r\ndo {\r\nmbox_msg = 0x00;\r\navail_emptybuff = 0;\r\nspin_lock_irqsave(&pshm_drv->lock, flags);\r\nif (!list_empty(&pshm_drv->rx_pend_list)) {\r\npbuf = list_entry(pshm_drv->rx_pend_list.next,\r\nstruct buf_list, list);\r\nlist_del_init(&pbuf->list);\r\nlist_add_tail(&pbuf->list, &pshm_drv->rx_empty_list);\r\nmbox_msg |= SHM_SET_EMPTY(pbuf->index);\r\n}\r\nskb = skb_peek(&pshm_drv->sk_qhead);\r\nif (skb == NULL)\r\ngoto send_msg;\r\nlist_for_each(pos, &pshm_drv->tx_empty_list)\r\navail_emptybuff++;\r\nif ((avail_emptybuff < LOW_WATERMARK) &&\r\npshm_drv->tx_empty_available) {\r\npshm_drv->tx_empty_available = 0;\r\npshm_drv->cfdev.flowctrl\r\n(pshm_drv->pshm_dev->pshm_netdev,\r\nCAIF_FLOW_OFF);\r\n}\r\nif (list_empty(&pshm_drv->tx_empty_list))\r\ngoto send_msg;\r\npbuf = list_entry(pshm_drv->tx_empty_list.next,\r\nstruct buf_list, list);\r\ndo {\r\nif (append) {\r\nskb = skb_peek(&pshm_drv->sk_qhead);\r\nif (skb == NULL)\r\nbreak;\r\n}\r\nfrm = (struct shm_caif_frm *)\r\n(pbuf->desc_vptr + pbuf->frm_ofs);\r\nfrm->hdr_ofs = 0;\r\nfrmlen = 0;\r\nfrmlen += SHM_HDR_LEN + frm->hdr_ofs + skb->len;\r\nif (frmlen % SHM_FRM_PAD_LEN)\r\nfrmlen += SHM_FRM_PAD_LEN -\r\n(frmlen % SHM_FRM_PAD_LEN);\r\nif (frmlen >= (pbuf->len - pbuf->frm_ofs))\r\nbreak;\r\nif (!append) {\r\nlist_del_init(&pbuf->list);\r\nappend = 1;\r\n}\r\nskb = skb_dequeue(&pshm_drv->sk_qhead);\r\nskb_copy_bits(skb, 0, pbuf->desc_vptr +\r\npbuf->frm_ofs + SHM_HDR_LEN +\r\nfrm->hdr_ofs, skb->len);\r\npshm_drv->pshm_dev->pshm_netdev->stats.tx_packets++;\r\npshm_drv->pshm_dev->pshm_netdev->stats.tx_bytes +=\r\nfrmlen;\r\ndev_kfree_skb(skb);\r\npck_desc = (struct shm_pck_desc *) (pbuf->desc_vptr);\r\npck_desc += pbuf->frames;\r\npck_desc->frm_ofs = (pbuf->phy_addr -\r\npshm_drv->shm_base_addr) +\r\npbuf->frm_ofs;\r\npck_desc->frm_len = frmlen;\r\npck_desc++;\r\npck_desc->frm_ofs = 0;\r\npbuf->frames++;\r\npbuf->frm_ofs += frmlen + (frmlen % 32);\r\n} while (pbuf->frames < SHM_MAX_FRMS_PER_BUF);\r\nlist_add_tail(&pbuf->list, &pshm_drv->tx_full_list);\r\nappend = 0;\r\nmbox_msg |= SHM_SET_FULL(pbuf->index);\r\nsend_msg:\r\nspin_unlock_irqrestore(&pshm_drv->lock, flags);\r\nif (mbox_msg)\r\npshm_drv->pshm_dev->pshmdev_mbxsend\r\n(pshm_drv->pshm_dev->shm_id, mbox_msg);\r\n} while (mbox_msg);\r\n}\r\nstatic int shm_netdev_tx(struct sk_buff *skb, struct net_device *shm_netdev)\r\n{\r\nstruct shmdrv_layer *pshm_drv;\r\nunsigned long flags = 0;\r\npshm_drv = netdev_priv(shm_netdev);\r\nspin_lock_irqsave(&pshm_drv->lock, flags);\r\nskb_queue_tail(&pshm_drv->sk_qhead, skb);\r\nspin_unlock_irqrestore(&pshm_drv->lock, flags);\r\nif (!work_pending(&pshm_drv->shm_tx_work))\r\nqueue_work(pshm_drv->pshm_tx_workqueue, &pshm_drv->shm_tx_work);\r\nreturn 0;\r\n}\r\nstatic void shm_netdev_setup(struct net_device *pshm_netdev)\r\n{\r\nstruct shmdrv_layer *pshm_drv;\r\npshm_netdev->netdev_ops = &netdev_ops;\r\npshm_netdev->mtu = CAIF_MAX_MTU;\r\npshm_netdev->type = ARPHRD_CAIF;\r\npshm_netdev->hard_header_len = CAIF_NEEDED_HEADROOM;\r\npshm_netdev->tx_queue_len = 0;\r\npshm_netdev->destructor = free_netdev;\r\npshm_drv = netdev_priv(pshm_netdev);\r\nmemset(pshm_drv, 0, sizeof(struct shmdrv_layer));\r\npshm_drv->cfdev.link_select = CAIF_LINK_LOW_LATENCY;\r\n}\r\nint caif_shmcore_probe(struct shmdev_layer *pshm_dev)\r\n{\r\nint result, j;\r\nstruct shmdrv_layer *pshm_drv = NULL;\r\npshm_dev->pshm_netdev = alloc_netdev(sizeof(struct shmdrv_layer),\r\n"cfshm%d", shm_netdev_setup);\r\nif (!pshm_dev->pshm_netdev)\r\nreturn -ENOMEM;\r\npshm_drv = netdev_priv(pshm_dev->pshm_netdev);\r\npshm_drv->pshm_dev = pshm_dev;\r\nif ((pshm_dev->pshmdev_mbxsetup\r\n(caif_shmdrv_rx_cb, pshm_dev, pshm_drv)) != 0) {\r\npr_warn("Could not config. SHM Mailbox,"\r\n" Bailing out.....\n");\r\nfree_netdev(pshm_dev->pshm_netdev);\r\nreturn -ENODEV;\r\n}\r\nskb_queue_head_init(&pshm_drv->sk_qhead);\r\npr_info("SHM DEVICE[%d] PROBED BY DRIVER, NEW SHM DRIVER"\r\n" INSTANCE AT pshm_drv =0x%p\n",\r\npshm_drv->pshm_dev->shm_id, pshm_drv);\r\nif (pshm_dev->shm_total_sz <\r\n(NR_TX_BUF * TX_BUF_SZ + NR_RX_BUF * RX_BUF_SZ)) {\r\npr_warn("ERROR, Amount of available"\r\n" Phys. SHM cannot accommodate current SHM "\r\n"driver configuration, Bailing out ...\n");\r\nfree_netdev(pshm_dev->pshm_netdev);\r\nreturn -ENOMEM;\r\n}\r\npshm_drv->shm_base_addr = pshm_dev->shm_base_addr;\r\npshm_drv->shm_tx_addr = pshm_drv->shm_base_addr;\r\nif (pshm_dev->shm_loopback)\r\npshm_drv->shm_rx_addr = pshm_drv->shm_tx_addr;\r\nelse\r\npshm_drv->shm_rx_addr = pshm_dev->shm_base_addr +\r\n(NR_TX_BUF * TX_BUF_SZ);\r\nINIT_LIST_HEAD(&pshm_drv->tx_empty_list);\r\nINIT_LIST_HEAD(&pshm_drv->tx_pend_list);\r\nINIT_LIST_HEAD(&pshm_drv->tx_full_list);\r\nINIT_LIST_HEAD(&pshm_drv->rx_empty_list);\r\nINIT_LIST_HEAD(&pshm_drv->rx_pend_list);\r\nINIT_LIST_HEAD(&pshm_drv->rx_full_list);\r\nINIT_WORK(&pshm_drv->shm_tx_work, shm_tx_work_func);\r\nINIT_WORK(&pshm_drv->shm_rx_work, shm_rx_work_func);\r\npshm_drv->pshm_tx_workqueue =\r\ncreate_singlethread_workqueue("shm_tx_work");\r\npshm_drv->pshm_rx_workqueue =\r\ncreate_singlethread_workqueue("shm_rx_work");\r\nfor (j = 0; j < NR_TX_BUF; j++) {\r\nstruct buf_list *tx_buf =\r\nkmalloc(sizeof(struct buf_list), GFP_KERNEL);\r\nif (tx_buf == NULL) {\r\npr_warn("ERROR, Could not"\r\n" allocate dynamic mem. for tx_buf,"\r\n" Bailing out ...\n");\r\nfree_netdev(pshm_dev->pshm_netdev);\r\nreturn -ENOMEM;\r\n}\r\ntx_buf->index = j;\r\ntx_buf->phy_addr = pshm_drv->shm_tx_addr + (TX_BUF_SZ * j);\r\ntx_buf->len = TX_BUF_SZ;\r\ntx_buf->frames = 0;\r\ntx_buf->frm_ofs = SHM_CAIF_FRM_OFS;\r\nif (pshm_dev->shm_loopback)\r\ntx_buf->desc_vptr = (char *)tx_buf->phy_addr;\r\nelse\r\ntx_buf->desc_vptr =\r\nioremap(tx_buf->phy_addr, TX_BUF_SZ);\r\nlist_add_tail(&tx_buf->list, &pshm_drv->tx_empty_list);\r\n}\r\nfor (j = 0; j < NR_RX_BUF; j++) {\r\nstruct buf_list *rx_buf =\r\nkmalloc(sizeof(struct buf_list), GFP_KERNEL);\r\nif (rx_buf == NULL) {\r\npr_warn("ERROR, Could not"\r\n" allocate dynamic mem.for rx_buf,"\r\n" Bailing out ...\n");\r\nfree_netdev(pshm_dev->pshm_netdev);\r\nreturn -ENOMEM;\r\n}\r\nrx_buf->index = j;\r\nrx_buf->phy_addr = pshm_drv->shm_rx_addr + (RX_BUF_SZ * j);\r\nrx_buf->len = RX_BUF_SZ;\r\nif (pshm_dev->shm_loopback)\r\nrx_buf->desc_vptr = (char *)rx_buf->phy_addr;\r\nelse\r\nrx_buf->desc_vptr =\r\nioremap(rx_buf->phy_addr, RX_BUF_SZ);\r\nlist_add_tail(&rx_buf->list, &pshm_drv->rx_empty_list);\r\n}\r\npshm_drv->tx_empty_available = 1;\r\nresult = register_netdev(pshm_dev->pshm_netdev);\r\nif (result)\r\npr_warn("ERROR[%d], SHM could not, "\r\n"register with NW FRMWK Bailing out ...\n", result);\r\nreturn result;\r\n}\r\nvoid caif_shmcore_remove(struct net_device *pshm_netdev)\r\n{\r\nstruct buf_list *pbuf;\r\nstruct shmdrv_layer *pshm_drv = NULL;\r\npshm_drv = netdev_priv(pshm_netdev);\r\nwhile (!(list_empty(&pshm_drv->tx_pend_list))) {\r\npbuf =\r\nlist_entry(pshm_drv->tx_pend_list.next,\r\nstruct buf_list, list);\r\nlist_del(&pbuf->list);\r\nkfree(pbuf);\r\n}\r\nwhile (!(list_empty(&pshm_drv->tx_full_list))) {\r\npbuf =\r\nlist_entry(pshm_drv->tx_full_list.next,\r\nstruct buf_list, list);\r\nlist_del(&pbuf->list);\r\nkfree(pbuf);\r\n}\r\nwhile (!(list_empty(&pshm_drv->tx_empty_list))) {\r\npbuf =\r\nlist_entry(pshm_drv->tx_empty_list.next,\r\nstruct buf_list, list);\r\nlist_del(&pbuf->list);\r\nkfree(pbuf);\r\n}\r\nwhile (!(list_empty(&pshm_drv->rx_full_list))) {\r\npbuf =\r\nlist_entry(pshm_drv->tx_full_list.next,\r\nstruct buf_list, list);\r\nlist_del(&pbuf->list);\r\nkfree(pbuf);\r\n}\r\nwhile (!(list_empty(&pshm_drv->rx_pend_list))) {\r\npbuf =\r\nlist_entry(pshm_drv->tx_pend_list.next,\r\nstruct buf_list, list);\r\nlist_del(&pbuf->list);\r\nkfree(pbuf);\r\n}\r\nwhile (!(list_empty(&pshm_drv->rx_empty_list))) {\r\npbuf =\r\nlist_entry(pshm_drv->rx_empty_list.next,\r\nstruct buf_list, list);\r\nlist_del(&pbuf->list);\r\nkfree(pbuf);\r\n}\r\ndestroy_workqueue(pshm_drv->pshm_tx_workqueue);\r\ndestroy_workqueue(pshm_drv->pshm_rx_workqueue);\r\nunregister_netdev(pshm_netdev);\r\n}
