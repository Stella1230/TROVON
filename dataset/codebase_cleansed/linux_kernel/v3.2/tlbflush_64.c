static inline void print_prots(pgprot_t prot)\r\n{\r\nprintk("prot is 0x%016llx\n",pgprot_val(prot));\r\nprintk("%s %s %s %s %s\n",PPROT(_PAGE_SHARED),PPROT(_PAGE_READ),\r\nPPROT(_PAGE_EXECUTE),PPROT(_PAGE_WRITE),PPROT(_PAGE_USER));\r\n}\r\nstatic inline void print_vma(struct vm_area_struct *vma)\r\n{\r\nprintk("vma start 0x%08lx\n", vma->vm_start);\r\nprintk("vma end 0x%08lx\n", vma->vm_end);\r\nprint_prots(vma->vm_page_prot);\r\nprintk("vm_flags 0x%08lx\n", vma->vm_flags);\r\n}\r\nstatic inline void print_task(struct task_struct *tsk)\r\n{\r\nprintk("Task pid %d\n", task_pid_nr(tsk));\r\n}\r\nstatic pte_t *lookup_pte(struct mm_struct *mm, unsigned long address)\r\n{\r\npgd_t *dir;\r\npud_t *pud;\r\npmd_t *pmd;\r\npte_t *pte;\r\npte_t entry;\r\ndir = pgd_offset(mm, address);\r\nif (pgd_none(*dir))\r\nreturn NULL;\r\npud = pud_offset(dir, address);\r\nif (pud_none(*pud))\r\nreturn NULL;\r\npmd = pmd_offset(pud, address);\r\nif (pmd_none(*pmd))\r\nreturn NULL;\r\npte = pte_offset_kernel(pmd, address);\r\nentry = *pte;\r\nif (pte_none(entry) || !pte_present(entry))\r\nreturn NULL;\r\nreturn pte;\r\n}\r\nasmlinkage void do_page_fault(struct pt_regs *regs, unsigned long writeaccess,\r\nunsigned long textaccess, unsigned long address)\r\n{\r\nstruct task_struct *tsk;\r\nstruct mm_struct *mm;\r\nstruct vm_area_struct * vma;\r\nconst struct exception_table_entry *fixup;\r\npte_t *pte;\r\nint fault;\r\ntsk = current;\r\nmm = tsk->mm;\r\nlocal_irq_enable();\r\nperf_sw_event(PERF_COUNT_SW_PAGE_FAULTS, 1, regs, address);\r\nif (in_atomic() || !mm)\r\ngoto no_context;\r\ndown_read(&mm->mmap_sem);\r\nvma = find_vma(mm, address);\r\nif (!vma) {\r\n#ifdef DEBUG_FAULT\r\nprint_task(tsk);\r\nprintk("%s:%d fault, address is 0x%08x PC %016Lx textaccess %d writeaccess %d\n",\r\n__func__, __LINE__,\r\naddress,regs->pc,textaccess,writeaccess);\r\nshow_regs(regs);\r\n#endif\r\ngoto bad_area;\r\n}\r\nif (vma->vm_start <= address) {\r\ngoto good_area;\r\n}\r\nif (!(vma->vm_flags & VM_GROWSDOWN)) {\r\n#ifdef DEBUG_FAULT\r\nprint_task(tsk);\r\nprintk("%s:%d fault, address is 0x%08x PC %016Lx textaccess %d writeaccess %d\n",\r\n__func__, __LINE__,\r\naddress,regs->pc,textaccess,writeaccess);\r\nshow_regs(regs);\r\nprint_vma(vma);\r\n#endif\r\ngoto bad_area;\r\n}\r\nif (expand_stack(vma, address)) {\r\n#ifdef DEBUG_FAULT\r\nprint_task(tsk);\r\nprintk("%s:%d fault, address is 0x%08x PC %016Lx textaccess %d writeaccess %d\n",\r\n__func__, __LINE__,\r\naddress,regs->pc,textaccess,writeaccess);\r\nshow_regs(regs);\r\n#endif\r\ngoto bad_area;\r\n}\r\ngood_area:\r\nif (textaccess) {\r\nif (!(vma->vm_flags & VM_EXEC))\r\ngoto bad_area;\r\n} else {\r\nif (writeaccess) {\r\nif (!(vma->vm_flags & VM_WRITE))\r\ngoto bad_area;\r\n} else {\r\nif (!(vma->vm_flags & VM_READ))\r\ngoto bad_area;\r\n}\r\n}\r\nfault = handle_mm_fault(mm, vma, address, writeaccess ? FAULT_FLAG_WRITE : 0);\r\nif (unlikely(fault & VM_FAULT_ERROR)) {\r\nif (fault & VM_FAULT_OOM)\r\ngoto out_of_memory;\r\nelse if (fault & VM_FAULT_SIGBUS)\r\ngoto do_sigbus;\r\nBUG();\r\n}\r\nif (fault & VM_FAULT_MAJOR) {\r\ntsk->maj_flt++;\r\nperf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MAJ, 1,\r\nregs, address);\r\n} else {\r\ntsk->min_flt++;\r\nperf_sw_event(PERF_COUNT_SW_PAGE_FAULTS_MIN, 1,\r\nregs, address);\r\n}\r\npte = lookup_pte (mm, address);\r\nif (!pte) {\r\ngoto no_pte;\r\n}\r\n__do_tlb_refill(address, textaccess, pte);\r\nno_pte:\r\nup_read(&mm->mmap_sem);\r\nreturn;\r\nbad_area:\r\n#ifdef DEBUG_FAULT\r\nprintk("fault:bad area\n");\r\n#endif\r\nup_read(&mm->mmap_sem);\r\nif (user_mode(regs)) {\r\nstatic int count=0;\r\nsiginfo_t info;\r\nif (count < 4) {\r\ncount++;\r\nprintk("user mode bad_area address=%08lx pid=%d (%s) pc=%08lx\n",\r\naddress, task_pid_nr(current), current->comm,\r\n(unsigned long) regs->pc);\r\n#if 0\r\nshow_regs(regs);\r\n#endif\r\n}\r\nif (is_global_init(tsk)) {\r\npanic("INIT had user mode bad_area\n");\r\n}\r\ntsk->thread.address = address;\r\ntsk->thread.error_code = writeaccess;\r\ninfo.si_signo = SIGSEGV;\r\ninfo.si_errno = 0;\r\ninfo.si_addr = (void *) address;\r\nforce_sig_info(SIGSEGV, &info, tsk);\r\nreturn;\r\n}\r\nno_context:\r\n#ifdef DEBUG_FAULT\r\nprintk("fault:No context\n");\r\n#endif\r\nfixup = search_exception_tables(regs->pc);\r\nif (fixup) {\r\nregs->pc = fixup->fixup;\r\nreturn;\r\n}\r\nif (address < PAGE_SIZE)\r\nprintk(KERN_ALERT "Unable to handle kernel NULL pointer dereference");\r\nelse\r\nprintk(KERN_ALERT "Unable to handle kernel paging request");\r\nprintk(" at virtual address %08lx\n", address);\r\nprintk(KERN_ALERT "pc = %08Lx%08Lx\n", regs->pc >> 32, regs->pc & 0xffffffff);\r\ndie("Oops", regs, writeaccess);\r\ndo_exit(SIGKILL);\r\nout_of_memory:\r\nup_read(&mm->mmap_sem);\r\nif (!user_mode(regs))\r\ngoto no_context;\r\npagefault_out_of_memory();\r\nreturn;\r\ndo_sigbus:\r\nprintk("fault:Do sigbus\n");\r\nup_read(&mm->mmap_sem);\r\ntsk->thread.address = address;\r\ntsk->thread.error_code = writeaccess;\r\ntsk->thread.trap_no = 14;\r\nforce_sig(SIGBUS, tsk);\r\nif (!user_mode(regs))\r\ngoto no_context;\r\n}\r\nvoid local_flush_tlb_one(unsigned long asid, unsigned long page)\r\n{\r\nunsigned long long match, pteh=0, lpage;\r\nunsigned long tlb;\r\nlpage = neff_sign_extend(page);\r\nmatch = (asid << PTEH_ASID_SHIFT) | PTEH_VALID;\r\nmatch |= lpage;\r\nfor_each_itlb_entry(tlb) {\r\nasm volatile ("getcfg %1, 0, %0"\r\n: "=r" (pteh)\r\n: "r" (tlb) );\r\nif (pteh == match) {\r\n__flush_tlb_slot(tlb);\r\nbreak;\r\n}\r\n}\r\nfor_each_dtlb_entry(tlb) {\r\nasm volatile ("getcfg %1, 0, %0"\r\n: "=r" (pteh)\r\n: "r" (tlb) );\r\nif (pteh == match) {\r\n__flush_tlb_slot(tlb);\r\nbreak;\r\n}\r\n}\r\n}\r\nvoid local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)\r\n{\r\nunsigned long flags;\r\nif (vma->vm_mm) {\r\npage &= PAGE_MASK;\r\nlocal_irq_save(flags);\r\nlocal_flush_tlb_one(get_asid(), page);\r\nlocal_irq_restore(flags);\r\n}\r\n}\r\nvoid local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,\r\nunsigned long end)\r\n{\r\nunsigned long flags;\r\nunsigned long long match, pteh=0, pteh_epn, pteh_low;\r\nunsigned long tlb;\r\nunsigned int cpu = smp_processor_id();\r\nstruct mm_struct *mm;\r\nmm = vma->vm_mm;\r\nif (cpu_context(cpu, mm) == NO_CONTEXT)\r\nreturn;\r\nlocal_irq_save(flags);\r\nstart &= PAGE_MASK;\r\nend &= PAGE_MASK;\r\nmatch = (cpu_asid(cpu, mm) << PTEH_ASID_SHIFT) | PTEH_VALID;\r\nfor_each_itlb_entry(tlb) {\r\nasm volatile ("getcfg %1, 0, %0"\r\n: "=r" (pteh)\r\n: "r" (tlb) );\r\npteh_epn = pteh & PAGE_MASK;\r\npteh_low = pteh & ~PAGE_MASK;\r\nif (pteh_low == match && pteh_epn >= start && pteh_epn <= end)\r\n__flush_tlb_slot(tlb);\r\n}\r\nfor_each_dtlb_entry(tlb) {\r\nasm volatile ("getcfg %1, 0, %0"\r\n: "=r" (pteh)\r\n: "r" (tlb) );\r\npteh_epn = pteh & PAGE_MASK;\r\npteh_low = pteh & ~PAGE_MASK;\r\nif (pteh_low == match && pteh_epn >= start && pteh_epn <= end)\r\n__flush_tlb_slot(tlb);\r\n}\r\nlocal_irq_restore(flags);\r\n}\r\nvoid local_flush_tlb_mm(struct mm_struct *mm)\r\n{\r\nunsigned long flags;\r\nunsigned int cpu = smp_processor_id();\r\nif (cpu_context(cpu, mm) == NO_CONTEXT)\r\nreturn;\r\nlocal_irq_save(flags);\r\ncpu_context(cpu, mm) = NO_CONTEXT;\r\nif (mm == current->mm)\r\nactivate_context(mm, cpu);\r\nlocal_irq_restore(flags);\r\n}\r\nvoid local_flush_tlb_all(void)\r\n{\r\nunsigned long flags, tlb;\r\nlocal_irq_save(flags);\r\nfor_each_itlb_entry(tlb)\r\n__flush_tlb_slot(tlb);\r\nfor_each_dtlb_entry(tlb)\r\n__flush_tlb_slot(tlb);\r\nlocal_irq_restore(flags);\r\n}\r\nvoid local_flush_tlb_kernel_range(unsigned long start, unsigned long end)\r\n{\r\nflush_tlb_all();\r\n}\r\nvoid __flush_tlb_global(void)\r\n{\r\nflush_tlb_all();\r\n}\r\nvoid __update_tlb(struct vm_area_struct *vma, unsigned long address, pte_t pte)\r\n{\r\n}
