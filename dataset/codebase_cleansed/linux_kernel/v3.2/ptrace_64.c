static inline int get_stack_long(struct task_struct *task, int offset)\r\n{\r\nunsigned char *stack;\r\nstack = (unsigned char *)(task->thread.uregs);\r\nstack += offset;\r\nreturn (*((int *)stack));\r\n}\r\nstatic inline unsigned long\r\nget_fpu_long(struct task_struct *task, unsigned long addr)\r\n{\r\nunsigned long tmp;\r\nstruct pt_regs *regs;\r\nregs = (struct pt_regs*)((unsigned char *)task + THREAD_SIZE) - 1;\r\nif (!tsk_used_math(task)) {\r\nif (addr == offsetof(struct user_fpu_struct, fpscr)) {\r\ntmp = FPSCR_INIT;\r\n} else {\r\ntmp = 0xffffffffUL;\r\n}\r\nreturn tmp;\r\n}\r\nif (last_task_used_math == task) {\r\nenable_fpu();\r\nsave_fpu(task);\r\ndisable_fpu();\r\nlast_task_used_math = 0;\r\nregs->sr |= SR_FD;\r\n}\r\ntmp = ((long *)task->thread.xstate)[addr / sizeof(unsigned long)];\r\nreturn tmp;\r\n}\r\nstatic inline int put_stack_long(struct task_struct *task, int offset,\r\nunsigned long data)\r\n{\r\nunsigned char *stack;\r\nstack = (unsigned char *)(task->thread.uregs);\r\nstack += offset;\r\n*(unsigned long *) stack = data;\r\nreturn 0;\r\n}\r\nstatic inline int\r\nput_fpu_long(struct task_struct *task, unsigned long addr, unsigned long data)\r\n{\r\nstruct pt_regs *regs;\r\nregs = (struct pt_regs*)((unsigned char *)task + THREAD_SIZE) - 1;\r\nif (!tsk_used_math(task)) {\r\ninit_fpu(task);\r\n} else if (last_task_used_math == task) {\r\nenable_fpu();\r\nsave_fpu(task);\r\ndisable_fpu();\r\nlast_task_used_math = 0;\r\nregs->sr |= SR_FD;\r\n}\r\n((long *)task->thread.xstate)[addr / sizeof(unsigned long)] = data;\r\nreturn 0;\r\n}\r\nvoid user_enable_single_step(struct task_struct *child)\r\n{\r\nstruct pt_regs *regs = child->thread.uregs;\r\nregs->sr |= SR_SSTEP;\r\nset_tsk_thread_flag(child, TIF_SINGLESTEP);\r\n}\r\nvoid user_disable_single_step(struct task_struct *child)\r\n{\r\nstruct pt_regs *regs = child->thread.uregs;\r\nregs->sr &= ~SR_SSTEP;\r\nclear_tsk_thread_flag(child, TIF_SINGLESTEP);\r\n}\r\nstatic int genregs_get(struct task_struct *target,\r\nconst struct user_regset *regset,\r\nunsigned int pos, unsigned int count,\r\nvoid *kbuf, void __user *ubuf)\r\n{\r\nconst struct pt_regs *regs = task_pt_regs(target);\r\nint ret;\r\nret = user_regset_copyout(&pos, &count, &kbuf, &ubuf,\r\n&regs->pc,\r\n0, 3 * sizeof(unsigned long long));\r\nif (!ret)\r\nret = user_regset_copyout(&pos, &count, &kbuf, &ubuf,\r\nregs->regs,\r\noffsetof(struct pt_regs, regs[0]),\r\n63 * sizeof(unsigned long long));\r\nif (!ret)\r\nret = user_regset_copyout(&pos, &count, &kbuf, &ubuf,\r\nregs->tregs,\r\noffsetof(struct pt_regs, tregs[0]),\r\n8 * sizeof(unsigned long long));\r\nif (!ret)\r\nret = user_regset_copyout_zero(&pos, &count, &kbuf, &ubuf,\r\nsizeof(struct pt_regs), -1);\r\nreturn ret;\r\n}\r\nstatic int genregs_set(struct task_struct *target,\r\nconst struct user_regset *regset,\r\nunsigned int pos, unsigned int count,\r\nconst void *kbuf, const void __user *ubuf)\r\n{\r\nstruct pt_regs *regs = task_pt_regs(target);\r\nint ret;\r\nret = user_regset_copyin(&pos, &count, &kbuf, &ubuf,\r\n&regs->pc,\r\n0, 3 * sizeof(unsigned long long));\r\nif (!ret && count > 0)\r\nret = user_regset_copyin(&pos, &count, &kbuf, &ubuf,\r\nregs->regs,\r\noffsetof(struct pt_regs, regs[0]),\r\n63 * sizeof(unsigned long long));\r\nif (!ret && count > 0)\r\nret = user_regset_copyin(&pos, &count, &kbuf, &ubuf,\r\nregs->tregs,\r\noffsetof(struct pt_regs, tregs[0]),\r\n8 * sizeof(unsigned long long));\r\nif (!ret)\r\nret = user_regset_copyin_ignore(&pos, &count, &kbuf, &ubuf,\r\nsizeof(struct pt_regs), -1);\r\nreturn ret;\r\n}\r\nint fpregs_get(struct task_struct *target,\r\nconst struct user_regset *regset,\r\nunsigned int pos, unsigned int count,\r\nvoid *kbuf, void __user *ubuf)\r\n{\r\nint ret;\r\nret = init_fpu(target);\r\nif (ret)\r\nreturn ret;\r\nreturn user_regset_copyout(&pos, &count, &kbuf, &ubuf,\r\n&target->thread.xstate->hardfpu, 0, -1);\r\n}\r\nstatic int fpregs_set(struct task_struct *target,\r\nconst struct user_regset *regset,\r\nunsigned int pos, unsigned int count,\r\nconst void *kbuf, const void __user *ubuf)\r\n{\r\nint ret;\r\nret = init_fpu(target);\r\nif (ret)\r\nreturn ret;\r\nset_stopped_child_used_math(target);\r\nreturn user_regset_copyin(&pos, &count, &kbuf, &ubuf,\r\n&target->thread.xstate->hardfpu, 0, -1);\r\n}\r\nstatic int fpregs_active(struct task_struct *target,\r\nconst struct user_regset *regset)\r\n{\r\nreturn tsk_used_math(target) ? regset->n : 0;\r\n}\r\nconst struct user_regset_view *task_user_regset_view(struct task_struct *task)\r\n{\r\nreturn &user_sh64_native_view;\r\n}\r\nlong arch_ptrace(struct task_struct *child, long request,\r\nunsigned long addr, unsigned long data)\r\n{\r\nint ret;\r\nunsigned long __user *datap = (unsigned long __user *) data;\r\nswitch (request) {\r\ncase PTRACE_PEEKUSR: {\r\nunsigned long tmp;\r\nret = -EIO;\r\nif ((addr & 3) || addr < 0)\r\nbreak;\r\nif (addr < sizeof(struct pt_regs))\r\ntmp = get_stack_long(child, addr);\r\nelse if ((addr >= offsetof(struct user, fpu)) &&\r\n(addr < offsetof(struct user, u_fpvalid))) {\r\nunsigned long index;\r\nret = init_fpu(child);\r\nif (ret)\r\nbreak;\r\nindex = addr - offsetof(struct user, fpu);\r\ntmp = get_fpu_long(child, index);\r\n} else if (addr == offsetof(struct user, u_fpvalid)) {\r\ntmp = !!tsk_used_math(child);\r\n} else {\r\nbreak;\r\n}\r\nret = put_user(tmp, datap);\r\nbreak;\r\n}\r\ncase PTRACE_POKEUSR:\r\nret = -EIO;\r\nif ((addr & 3) || addr < 0)\r\nbreak;\r\nif (addr < sizeof(struct pt_regs)) {\r\nif (addr == offsetof (struct pt_regs, sr)+4)\r\n{\r\nret = 0;\r\nbreak;\r\n}\r\nif (addr == offsetof (struct pt_regs, sr))\r\n{\r\nlong cursr = get_stack_long(child, addr);\r\ndata &= ~(SR_MASK);\r\ndata |= (cursr & SR_MASK);\r\n}\r\nret = put_stack_long(child, addr, data);\r\n}\r\nelse if ((addr >= offsetof(struct user, fpu)) &&\r\n(addr < offsetof(struct user, u_fpvalid))) {\r\nunsigned long index;\r\nret = init_fpu(child);\r\nif (ret)\r\nbreak;\r\nindex = addr - offsetof(struct user, fpu);\r\nret = put_fpu_long(child, index, data);\r\n}\r\nbreak;\r\ncase PTRACE_GETREGS:\r\nreturn copy_regset_to_user(child, &user_sh64_native_view,\r\nREGSET_GENERAL,\r\n0, sizeof(struct pt_regs),\r\ndatap);\r\ncase PTRACE_SETREGS:\r\nreturn copy_regset_from_user(child, &user_sh64_native_view,\r\nREGSET_GENERAL,\r\n0, sizeof(struct pt_regs),\r\ndatap);\r\n#ifdef CONFIG_SH_FPU\r\ncase PTRACE_GETFPREGS:\r\nreturn copy_regset_to_user(child, &user_sh64_native_view,\r\nREGSET_FPU,\r\n0, sizeof(struct user_fpu_struct),\r\ndatap);\r\ncase PTRACE_SETFPREGS:\r\nreturn copy_regset_from_user(child, &user_sh64_native_view,\r\nREGSET_FPU,\r\n0, sizeof(struct user_fpu_struct),\r\ndatap);\r\n#endif\r\ndefault:\r\nret = ptrace_request(child, request, addr, data);\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nasmlinkage int sh64_ptrace(long request, long pid,\r\nunsigned long addr, unsigned long data)\r\n{\r\n#define WPC_DBRMODE 0x0d104008\r\nstatic unsigned long first_call;\r\nif (!test_and_set_bit(0, &first_call)) {\r\nprintk("DBRMODE set to 0 to permit native debugging\n");\r\npoke_real_address_q(WPC_DBRMODE, 0);\r\n}\r\nreturn sys_ptrace(request, pid, addr, data);\r\n}\r\nstatic inline int audit_arch(void)\r\n{\r\nint arch = EM_SH;\r\n#ifdef CONFIG_64BIT\r\narch |= __AUDIT_ARCH_64BIT;\r\n#endif\r\n#ifdef CONFIG_CPU_LITTLE_ENDIAN\r\narch |= __AUDIT_ARCH_LE;\r\n#endif\r\nreturn arch;\r\n}\r\nasmlinkage long long do_syscall_trace_enter(struct pt_regs *regs)\r\n{\r\nlong long ret = 0;\r\nsecure_computing(regs->regs[9]);\r\nif (test_thread_flag(TIF_SYSCALL_TRACE) &&\r\ntracehook_report_syscall_entry(regs))\r\nret = -1LL;\r\nif (unlikely(test_thread_flag(TIF_SYSCALL_TRACEPOINT)))\r\ntrace_sys_enter(regs, regs->regs[9]);\r\nif (unlikely(current->audit_context))\r\naudit_syscall_entry(audit_arch(), regs->regs[1],\r\nregs->regs[2], regs->regs[3],\r\nregs->regs[4], regs->regs[5]);\r\nreturn ret ?: regs->regs[9];\r\n}\r\nasmlinkage void do_syscall_trace_leave(struct pt_regs *regs)\r\n{\r\nint step;\r\nif (unlikely(current->audit_context))\r\naudit_syscall_exit(AUDITSC_RESULT(regs->regs[9]),\r\nregs->regs[9]);\r\nif (unlikely(test_thread_flag(TIF_SYSCALL_TRACEPOINT)))\r\ntrace_sys_exit(regs, regs->regs[9]);\r\nstep = test_thread_flag(TIF_SINGLESTEP);\r\nif (step || test_thread_flag(TIF_SYSCALL_TRACE))\r\ntracehook_report_syscall_exit(regs, step);\r\n}\r\nasmlinkage void do_single_step(unsigned long long vec, struct pt_regs *regs)\r\n{\r\nlocal_irq_enable();\r\nregs->sr &= ~SR_SSTEP;\r\nforce_sig(SIGTRAP, current);\r\n}\r\nvoid ptrace_disable(struct task_struct *child)\r\n{\r\nuser_disable_single_step(child);\r\n}
