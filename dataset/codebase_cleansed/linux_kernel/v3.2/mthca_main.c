static int mthca_tune_pci(struct mthca_dev *mdev)\r\n{\r\nif (!tune_pci)\r\nreturn 0;\r\nif (pci_find_capability(mdev->pdev, PCI_CAP_ID_PCIX)) {\r\nif (pcix_set_mmrbc(mdev->pdev, pcix_get_max_mmrbc(mdev->pdev))) {\r\nmthca_err(mdev, "Couldn't set PCI-X max read count, "\r\n"aborting.\n");\r\nreturn -ENODEV;\r\n}\r\n} else if (!(mdev->mthca_flags & MTHCA_FLAG_PCIE))\r\nmthca_info(mdev, "No PCI-X capability, not setting RBC.\n");\r\nif (pci_is_pcie(mdev->pdev)) {\r\nif (pcie_set_readrq(mdev->pdev, 4096)) {\r\nmthca_err(mdev, "Couldn't write PCI Express read request, "\r\n"aborting.\n");\r\nreturn -ENODEV;\r\n}\r\n} else if (mdev->mthca_flags & MTHCA_FLAG_PCIE)\r\nmthca_info(mdev, "No PCI Express capability, "\r\n"not setting Max Read Request Size.\n");\r\nreturn 0;\r\n}\r\nstatic int mthca_dev_lim(struct mthca_dev *mdev, struct mthca_dev_lim *dev_lim)\r\n{\r\nint err;\r\nmdev->limits.mtt_seg_size = (1 << log_mtts_per_seg) * 8;\r\nerr = mthca_QUERY_DEV_LIM(mdev, dev_lim);\r\nif (err) {\r\nmthca_err(mdev, "QUERY_DEV_LIM command returned %d"\r\n", aborting.\n", err);\r\nreturn err;\r\n}\r\nif (dev_lim->min_page_sz > PAGE_SIZE) {\r\nmthca_err(mdev, "HCA minimum page size of %d bigger than "\r\n"kernel PAGE_SIZE of %ld, aborting.\n",\r\ndev_lim->min_page_sz, PAGE_SIZE);\r\nreturn -ENODEV;\r\n}\r\nif (dev_lim->num_ports > MTHCA_MAX_PORTS) {\r\nmthca_err(mdev, "HCA has %d ports, but we only support %d, "\r\n"aborting.\n",\r\ndev_lim->num_ports, MTHCA_MAX_PORTS);\r\nreturn -ENODEV;\r\n}\r\nif (dev_lim->uar_size > pci_resource_len(mdev->pdev, 2)) {\r\nmthca_err(mdev, "HCA reported UAR size of 0x%x bigger than "\r\n"PCI resource 2 size of 0x%llx, aborting.\n",\r\ndev_lim->uar_size,\r\n(unsigned long long)pci_resource_len(mdev->pdev, 2));\r\nreturn -ENODEV;\r\n}\r\nmdev->limits.num_ports = dev_lim->num_ports;\r\nmdev->limits.vl_cap = dev_lim->max_vl;\r\nmdev->limits.mtu_cap = dev_lim->max_mtu;\r\nmdev->limits.gid_table_len = dev_lim->max_gids;\r\nmdev->limits.pkey_table_len = dev_lim->max_pkeys;\r\nmdev->limits.local_ca_ack_delay = dev_lim->local_ca_ack_delay;\r\nmdev->limits.max_sg = min_t(int, dev_lim->max_sg,\r\n(dev_lim->max_desc_sz -\r\nsizeof (struct mthca_next_seg) -\r\n(mthca_is_memfree(mdev) ?\r\nsizeof (struct mthca_arbel_ud_seg) :\r\nsizeof (struct mthca_tavor_ud_seg))) /\r\nsizeof (struct mthca_data_seg));\r\nmdev->limits.max_wqes = dev_lim->max_qp_sz;\r\nmdev->limits.max_qp_init_rdma = dev_lim->max_requester_per_qp;\r\nmdev->limits.reserved_qps = dev_lim->reserved_qps;\r\nmdev->limits.max_srq_wqes = dev_lim->max_srq_sz;\r\nmdev->limits.reserved_srqs = dev_lim->reserved_srqs;\r\nmdev->limits.reserved_eecs = dev_lim->reserved_eecs;\r\nmdev->limits.max_desc_sz = dev_lim->max_desc_sz;\r\nmdev->limits.max_srq_sge = mthca_max_srq_sge(mdev);\r\nmdev->limits.max_cqes = dev_lim->max_cq_sz - 1;\r\nmdev->limits.reserved_cqs = dev_lim->reserved_cqs;\r\nmdev->limits.reserved_eqs = dev_lim->reserved_eqs;\r\nmdev->limits.reserved_mtts = dev_lim->reserved_mtts;\r\nmdev->limits.reserved_mrws = dev_lim->reserved_mrws;\r\nmdev->limits.reserved_uars = dev_lim->reserved_uars;\r\nmdev->limits.reserved_pds = dev_lim->reserved_pds;\r\nmdev->limits.port_width_cap = dev_lim->max_port_width;\r\nmdev->limits.page_size_cap = ~(u32) (dev_lim->min_page_sz - 1);\r\nmdev->limits.flags = dev_lim->flags;\r\nif (dev_lim->stat_rate_support)\r\nmdev->limits.stat_rate_support = dev_lim->stat_rate_support;\r\nelse if (mdev->mthca_flags & MTHCA_FLAG_SINAI_OPT)\r\nmdev->limits.stat_rate_support = 0xf;\r\nelse\r\nmdev->limits.stat_rate_support = 0x3;\r\nmdev->device_cap_flags = IB_DEVICE_CHANGE_PHY_PORT |\r\nIB_DEVICE_PORT_ACTIVE_EVENT |\r\nIB_DEVICE_SYS_IMAGE_GUID |\r\nIB_DEVICE_RC_RNR_NAK_GEN;\r\nif (dev_lim->flags & DEV_LIM_FLAG_BAD_PKEY_CNTR)\r\nmdev->device_cap_flags |= IB_DEVICE_BAD_PKEY_CNTR;\r\nif (dev_lim->flags & DEV_LIM_FLAG_BAD_QKEY_CNTR)\r\nmdev->device_cap_flags |= IB_DEVICE_BAD_QKEY_CNTR;\r\nif (dev_lim->flags & DEV_LIM_FLAG_RAW_MULTI)\r\nmdev->device_cap_flags |= IB_DEVICE_RAW_MULTI;\r\nif (dev_lim->flags & DEV_LIM_FLAG_AUTO_PATH_MIG)\r\nmdev->device_cap_flags |= IB_DEVICE_AUTO_PATH_MIG;\r\nif (dev_lim->flags & DEV_LIM_FLAG_UD_AV_PORT_ENFORCE)\r\nmdev->device_cap_flags |= IB_DEVICE_UD_AV_PORT_ENFORCE;\r\nif (dev_lim->flags & DEV_LIM_FLAG_SRQ)\r\nmdev->mthca_flags |= MTHCA_FLAG_SRQ;\r\nif (mthca_is_memfree(mdev))\r\nif (dev_lim->flags & DEV_LIM_FLAG_IPOIB_CSUM)\r\nmdev->device_cap_flags |= IB_DEVICE_UD_IP_CSUM;\r\nreturn 0;\r\n}\r\nstatic int mthca_init_tavor(struct mthca_dev *mdev)\r\n{\r\ns64 size;\r\nint err;\r\nstruct mthca_dev_lim dev_lim;\r\nstruct mthca_profile profile;\r\nstruct mthca_init_hca_param init_hca;\r\nerr = mthca_SYS_EN(mdev);\r\nif (err) {\r\nmthca_err(mdev, "SYS_EN command returned %d, aborting.\n", err);\r\nreturn err;\r\n}\r\nerr = mthca_QUERY_FW(mdev);\r\nif (err) {\r\nmthca_err(mdev, "QUERY_FW command returned %d,"\r\n" aborting.\n", err);\r\ngoto err_disable;\r\n}\r\nerr = mthca_QUERY_DDR(mdev);\r\nif (err) {\r\nmthca_err(mdev, "QUERY_DDR command returned %d, aborting.\n", err);\r\ngoto err_disable;\r\n}\r\nerr = mthca_dev_lim(mdev, &dev_lim);\r\nif (err) {\r\nmthca_err(mdev, "QUERY_DEV_LIM command returned %d, aborting.\n", err);\r\ngoto err_disable;\r\n}\r\nprofile = hca_profile;\r\nprofile.num_uar = dev_lim.uar_size / PAGE_SIZE;\r\nprofile.uarc_size = 0;\r\nif (mdev->mthca_flags & MTHCA_FLAG_SRQ)\r\nprofile.num_srq = dev_lim.max_srqs;\r\nsize = mthca_make_profile(mdev, &profile, &dev_lim, &init_hca);\r\nif (size < 0) {\r\nerr = size;\r\ngoto err_disable;\r\n}\r\nerr = mthca_INIT_HCA(mdev, &init_hca);\r\nif (err) {\r\nmthca_err(mdev, "INIT_HCA command returned %d, aborting.\n", err);\r\ngoto err_disable;\r\n}\r\nreturn 0;\r\nerr_disable:\r\nmthca_SYS_DIS(mdev);\r\nreturn err;\r\n}\r\nstatic int mthca_load_fw(struct mthca_dev *mdev)\r\n{\r\nint err;\r\nmdev->fw.arbel.fw_icm =\r\nmthca_alloc_icm(mdev, mdev->fw.arbel.fw_pages,\r\nGFP_HIGHUSER | __GFP_NOWARN, 0);\r\nif (!mdev->fw.arbel.fw_icm) {\r\nmthca_err(mdev, "Couldn't allocate FW area, aborting.\n");\r\nreturn -ENOMEM;\r\n}\r\nerr = mthca_MAP_FA(mdev, mdev->fw.arbel.fw_icm);\r\nif (err) {\r\nmthca_err(mdev, "MAP_FA command returned %d, aborting.\n", err);\r\ngoto err_free;\r\n}\r\nerr = mthca_RUN_FW(mdev);\r\nif (err) {\r\nmthca_err(mdev, "RUN_FW command returned %d, aborting.\n", err);\r\ngoto err_unmap_fa;\r\n}\r\nreturn 0;\r\nerr_unmap_fa:\r\nmthca_UNMAP_FA(mdev);\r\nerr_free:\r\nmthca_free_icm(mdev, mdev->fw.arbel.fw_icm, 0);\r\nreturn err;\r\n}\r\nstatic int mthca_init_icm(struct mthca_dev *mdev,\r\nstruct mthca_dev_lim *dev_lim,\r\nstruct mthca_init_hca_param *init_hca,\r\nu64 icm_size)\r\n{\r\nu64 aux_pages;\r\nint err;\r\nerr = mthca_SET_ICM_SIZE(mdev, icm_size, &aux_pages);\r\nif (err) {\r\nmthca_err(mdev, "SET_ICM_SIZE command returned %d, aborting.\n", err);\r\nreturn err;\r\n}\r\nmthca_dbg(mdev, "%lld KB of HCA context requires %lld KB aux memory.\n",\r\n(unsigned long long) icm_size >> 10,\r\n(unsigned long long) aux_pages << 2);\r\nmdev->fw.arbel.aux_icm = mthca_alloc_icm(mdev, aux_pages,\r\nGFP_HIGHUSER | __GFP_NOWARN, 0);\r\nif (!mdev->fw.arbel.aux_icm) {\r\nmthca_err(mdev, "Couldn't allocate aux memory, aborting.\n");\r\nreturn -ENOMEM;\r\n}\r\nerr = mthca_MAP_ICM_AUX(mdev, mdev->fw.arbel.aux_icm);\r\nif (err) {\r\nmthca_err(mdev, "MAP_ICM_AUX returned %d, aborting.\n", err);\r\ngoto err_free_aux;\r\n}\r\nerr = mthca_map_eq_icm(mdev, init_hca->eqc_base);\r\nif (err) {\r\nmthca_err(mdev, "Failed to map EQ context memory, aborting.\n");\r\ngoto err_unmap_aux;\r\n}\r\nmdev->limits.reserved_mtts = ALIGN(mdev->limits.reserved_mtts * mdev->limits.mtt_seg_size,\r\ndma_get_cache_alignment()) / mdev->limits.mtt_seg_size;\r\nmdev->mr_table.mtt_table = mthca_alloc_icm_table(mdev, init_hca->mtt_base,\r\nmdev->limits.mtt_seg_size,\r\nmdev->limits.num_mtt_segs,\r\nmdev->limits.reserved_mtts,\r\n1, 0);\r\nif (!mdev->mr_table.mtt_table) {\r\nmthca_err(mdev, "Failed to map MTT context memory, aborting.\n");\r\nerr = -ENOMEM;\r\ngoto err_unmap_eq;\r\n}\r\nmdev->mr_table.mpt_table = mthca_alloc_icm_table(mdev, init_hca->mpt_base,\r\ndev_lim->mpt_entry_sz,\r\nmdev->limits.num_mpts,\r\nmdev->limits.reserved_mrws,\r\n1, 1);\r\nif (!mdev->mr_table.mpt_table) {\r\nmthca_err(mdev, "Failed to map MPT context memory, aborting.\n");\r\nerr = -ENOMEM;\r\ngoto err_unmap_mtt;\r\n}\r\nmdev->qp_table.qp_table = mthca_alloc_icm_table(mdev, init_hca->qpc_base,\r\ndev_lim->qpc_entry_sz,\r\nmdev->limits.num_qps,\r\nmdev->limits.reserved_qps,\r\n0, 0);\r\nif (!mdev->qp_table.qp_table) {\r\nmthca_err(mdev, "Failed to map QP context memory, aborting.\n");\r\nerr = -ENOMEM;\r\ngoto err_unmap_mpt;\r\n}\r\nmdev->qp_table.eqp_table = mthca_alloc_icm_table(mdev, init_hca->eqpc_base,\r\ndev_lim->eqpc_entry_sz,\r\nmdev->limits.num_qps,\r\nmdev->limits.reserved_qps,\r\n0, 0);\r\nif (!mdev->qp_table.eqp_table) {\r\nmthca_err(mdev, "Failed to map EQP context memory, aborting.\n");\r\nerr = -ENOMEM;\r\ngoto err_unmap_qp;\r\n}\r\nmdev->qp_table.rdb_table = mthca_alloc_icm_table(mdev, init_hca->rdb_base,\r\nMTHCA_RDB_ENTRY_SIZE,\r\nmdev->limits.num_qps <<\r\nmdev->qp_table.rdb_shift, 0,\r\n0, 0);\r\nif (!mdev->qp_table.rdb_table) {\r\nmthca_err(mdev, "Failed to map RDB context memory, aborting\n");\r\nerr = -ENOMEM;\r\ngoto err_unmap_eqp;\r\n}\r\nmdev->cq_table.table = mthca_alloc_icm_table(mdev, init_hca->cqc_base,\r\ndev_lim->cqc_entry_sz,\r\nmdev->limits.num_cqs,\r\nmdev->limits.reserved_cqs,\r\n0, 0);\r\nif (!mdev->cq_table.table) {\r\nmthca_err(mdev, "Failed to map CQ context memory, aborting.\n");\r\nerr = -ENOMEM;\r\ngoto err_unmap_rdb;\r\n}\r\nif (mdev->mthca_flags & MTHCA_FLAG_SRQ) {\r\nmdev->srq_table.table =\r\nmthca_alloc_icm_table(mdev, init_hca->srqc_base,\r\ndev_lim->srq_entry_sz,\r\nmdev->limits.num_srqs,\r\nmdev->limits.reserved_srqs,\r\n0, 0);\r\nif (!mdev->srq_table.table) {\r\nmthca_err(mdev, "Failed to map SRQ context memory, "\r\n"aborting.\n");\r\nerr = -ENOMEM;\r\ngoto err_unmap_cq;\r\n}\r\n}\r\nmdev->mcg_table.table = mthca_alloc_icm_table(mdev, init_hca->mc_base,\r\nMTHCA_MGM_ENTRY_SIZE,\r\nmdev->limits.num_mgms +\r\nmdev->limits.num_amgms,\r\nmdev->limits.num_mgms +\r\nmdev->limits.num_amgms,\r\n0, 0);\r\nif (!mdev->mcg_table.table) {\r\nmthca_err(mdev, "Failed to map MCG context memory, aborting.\n");\r\nerr = -ENOMEM;\r\ngoto err_unmap_srq;\r\n}\r\nreturn 0;\r\nerr_unmap_srq:\r\nif (mdev->mthca_flags & MTHCA_FLAG_SRQ)\r\nmthca_free_icm_table(mdev, mdev->srq_table.table);\r\nerr_unmap_cq:\r\nmthca_free_icm_table(mdev, mdev->cq_table.table);\r\nerr_unmap_rdb:\r\nmthca_free_icm_table(mdev, mdev->qp_table.rdb_table);\r\nerr_unmap_eqp:\r\nmthca_free_icm_table(mdev, mdev->qp_table.eqp_table);\r\nerr_unmap_qp:\r\nmthca_free_icm_table(mdev, mdev->qp_table.qp_table);\r\nerr_unmap_mpt:\r\nmthca_free_icm_table(mdev, mdev->mr_table.mpt_table);\r\nerr_unmap_mtt:\r\nmthca_free_icm_table(mdev, mdev->mr_table.mtt_table);\r\nerr_unmap_eq:\r\nmthca_unmap_eq_icm(mdev);\r\nerr_unmap_aux:\r\nmthca_UNMAP_ICM_AUX(mdev);\r\nerr_free_aux:\r\nmthca_free_icm(mdev, mdev->fw.arbel.aux_icm, 0);\r\nreturn err;\r\n}\r\nstatic void mthca_free_icms(struct mthca_dev *mdev)\r\n{\r\nmthca_free_icm_table(mdev, mdev->mcg_table.table);\r\nif (mdev->mthca_flags & MTHCA_FLAG_SRQ)\r\nmthca_free_icm_table(mdev, mdev->srq_table.table);\r\nmthca_free_icm_table(mdev, mdev->cq_table.table);\r\nmthca_free_icm_table(mdev, mdev->qp_table.rdb_table);\r\nmthca_free_icm_table(mdev, mdev->qp_table.eqp_table);\r\nmthca_free_icm_table(mdev, mdev->qp_table.qp_table);\r\nmthca_free_icm_table(mdev, mdev->mr_table.mpt_table);\r\nmthca_free_icm_table(mdev, mdev->mr_table.mtt_table);\r\nmthca_unmap_eq_icm(mdev);\r\nmthca_UNMAP_ICM_AUX(mdev);\r\nmthca_free_icm(mdev, mdev->fw.arbel.aux_icm, 0);\r\n}\r\nstatic int mthca_init_arbel(struct mthca_dev *mdev)\r\n{\r\nstruct mthca_dev_lim dev_lim;\r\nstruct mthca_profile profile;\r\nstruct mthca_init_hca_param init_hca;\r\ns64 icm_size;\r\nint err;\r\nerr = mthca_QUERY_FW(mdev);\r\nif (err) {\r\nmthca_err(mdev, "QUERY_FW command failed %d, aborting.\n", err);\r\nreturn err;\r\n}\r\nerr = mthca_ENABLE_LAM(mdev);\r\nif (err == -EAGAIN) {\r\nmthca_dbg(mdev, "No HCA-attached memory (running in MemFree mode)\n");\r\nmdev->mthca_flags |= MTHCA_FLAG_NO_LAM;\r\n} else if (err) {\r\nmthca_err(mdev, "ENABLE_LAM returned %d, aborting.\n", err);\r\nreturn err;\r\n}\r\nerr = mthca_load_fw(mdev);\r\nif (err) {\r\nmthca_err(mdev, "Loading FW returned %d, aborting.\n", err);\r\ngoto err_disable;\r\n}\r\nerr = mthca_dev_lim(mdev, &dev_lim);\r\nif (err) {\r\nmthca_err(mdev, "QUERY_DEV_LIM returned %d, aborting.\n", err);\r\ngoto err_stop_fw;\r\n}\r\nprofile = hca_profile;\r\nprofile.num_uar = dev_lim.uar_size / PAGE_SIZE;\r\nprofile.num_udav = 0;\r\nif (mdev->mthca_flags & MTHCA_FLAG_SRQ)\r\nprofile.num_srq = dev_lim.max_srqs;\r\nicm_size = mthca_make_profile(mdev, &profile, &dev_lim, &init_hca);\r\nif (icm_size < 0) {\r\nerr = icm_size;\r\ngoto err_stop_fw;\r\n}\r\nerr = mthca_init_icm(mdev, &dev_lim, &init_hca, icm_size);\r\nif (err)\r\ngoto err_stop_fw;\r\nerr = mthca_INIT_HCA(mdev, &init_hca);\r\nif (err) {\r\nmthca_err(mdev, "INIT_HCA command returned %d, aborting.\n", err);\r\ngoto err_free_icm;\r\n}\r\nreturn 0;\r\nerr_free_icm:\r\nmthca_free_icms(mdev);\r\nerr_stop_fw:\r\nmthca_UNMAP_FA(mdev);\r\nmthca_free_icm(mdev, mdev->fw.arbel.fw_icm, 0);\r\nerr_disable:\r\nif (!(mdev->mthca_flags & MTHCA_FLAG_NO_LAM))\r\nmthca_DISABLE_LAM(mdev);\r\nreturn err;\r\n}\r\nstatic void mthca_close_hca(struct mthca_dev *mdev)\r\n{\r\nmthca_CLOSE_HCA(mdev, 0);\r\nif (mthca_is_memfree(mdev)) {\r\nmthca_free_icms(mdev);\r\nmthca_UNMAP_FA(mdev);\r\nmthca_free_icm(mdev, mdev->fw.arbel.fw_icm, 0);\r\nif (!(mdev->mthca_flags & MTHCA_FLAG_NO_LAM))\r\nmthca_DISABLE_LAM(mdev);\r\n} else\r\nmthca_SYS_DIS(mdev);\r\n}\r\nstatic int mthca_init_hca(struct mthca_dev *mdev)\r\n{\r\nint err;\r\nstruct mthca_adapter adapter;\r\nif (mthca_is_memfree(mdev))\r\nerr = mthca_init_arbel(mdev);\r\nelse\r\nerr = mthca_init_tavor(mdev);\r\nif (err)\r\nreturn err;\r\nerr = mthca_QUERY_ADAPTER(mdev, &adapter);\r\nif (err) {\r\nmthca_err(mdev, "QUERY_ADAPTER command returned %d, aborting.\n", err);\r\ngoto err_close;\r\n}\r\nmdev->eq_table.inta_pin = adapter.inta_pin;\r\nif (!mthca_is_memfree(mdev))\r\nmdev->rev_id = adapter.revision_id;\r\nmemcpy(mdev->board_id, adapter.board_id, sizeof mdev->board_id);\r\nreturn 0;\r\nerr_close:\r\nmthca_close_hca(mdev);\r\nreturn err;\r\n}\r\nstatic int mthca_setup_hca(struct mthca_dev *dev)\r\n{\r\nint err;\r\nMTHCA_INIT_DOORBELL_LOCK(&dev->doorbell_lock);\r\nerr = mthca_init_uar_table(dev);\r\nif (err) {\r\nmthca_err(dev, "Failed to initialize "\r\n"user access region table, aborting.\n");\r\nreturn err;\r\n}\r\nerr = mthca_uar_alloc(dev, &dev->driver_uar);\r\nif (err) {\r\nmthca_err(dev, "Failed to allocate driver access region, "\r\n"aborting.\n");\r\ngoto err_uar_table_free;\r\n}\r\ndev->kar = ioremap((phys_addr_t) dev->driver_uar.pfn << PAGE_SHIFT, PAGE_SIZE);\r\nif (!dev->kar) {\r\nmthca_err(dev, "Couldn't map kernel access region, "\r\n"aborting.\n");\r\nerr = -ENOMEM;\r\ngoto err_uar_free;\r\n}\r\nerr = mthca_init_pd_table(dev);\r\nif (err) {\r\nmthca_err(dev, "Failed to initialize "\r\n"protection domain table, aborting.\n");\r\ngoto err_kar_unmap;\r\n}\r\nerr = mthca_init_mr_table(dev);\r\nif (err) {\r\nmthca_err(dev, "Failed to initialize "\r\n"memory region table, aborting.\n");\r\ngoto err_pd_table_free;\r\n}\r\nerr = mthca_pd_alloc(dev, 1, &dev->driver_pd);\r\nif (err) {\r\nmthca_err(dev, "Failed to create driver PD, "\r\n"aborting.\n");\r\ngoto err_mr_table_free;\r\n}\r\nerr = mthca_init_eq_table(dev);\r\nif (err) {\r\nmthca_err(dev, "Failed to initialize "\r\n"event queue table, aborting.\n");\r\ngoto err_pd_free;\r\n}\r\nerr = mthca_cmd_use_events(dev);\r\nif (err) {\r\nmthca_err(dev, "Failed to switch to event-driven "\r\n"firmware commands, aborting.\n");\r\ngoto err_eq_table_free;\r\n}\r\nerr = mthca_NOP(dev);\r\nif (err) {\r\nif (dev->mthca_flags & MTHCA_FLAG_MSI_X) {\r\nmthca_warn(dev, "NOP command failed to generate interrupt "\r\n"(IRQ %d).\n",\r\ndev->eq_table.eq[MTHCA_EQ_CMD].msi_x_vector);\r\nmthca_warn(dev, "Trying again with MSI-X disabled.\n");\r\n} else {\r\nmthca_err(dev, "NOP command failed to generate interrupt "\r\n"(IRQ %d), aborting.\n",\r\ndev->pdev->irq);\r\nmthca_err(dev, "BIOS or ACPI interrupt routing problem?\n");\r\n}\r\ngoto err_cmd_poll;\r\n}\r\nmthca_dbg(dev, "NOP command IRQ test passed\n");\r\nerr = mthca_init_cq_table(dev);\r\nif (err) {\r\nmthca_err(dev, "Failed to initialize "\r\n"completion queue table, aborting.\n");\r\ngoto err_cmd_poll;\r\n}\r\nerr = mthca_init_srq_table(dev);\r\nif (err) {\r\nmthca_err(dev, "Failed to initialize "\r\n"shared receive queue table, aborting.\n");\r\ngoto err_cq_table_free;\r\n}\r\nerr = mthca_init_qp_table(dev);\r\nif (err) {\r\nmthca_err(dev, "Failed to initialize "\r\n"queue pair table, aborting.\n");\r\ngoto err_srq_table_free;\r\n}\r\nerr = mthca_init_av_table(dev);\r\nif (err) {\r\nmthca_err(dev, "Failed to initialize "\r\n"address vector table, aborting.\n");\r\ngoto err_qp_table_free;\r\n}\r\nerr = mthca_init_mcg_table(dev);\r\nif (err) {\r\nmthca_err(dev, "Failed to initialize "\r\n"multicast group table, aborting.\n");\r\ngoto err_av_table_free;\r\n}\r\nreturn 0;\r\nerr_av_table_free:\r\nmthca_cleanup_av_table(dev);\r\nerr_qp_table_free:\r\nmthca_cleanup_qp_table(dev);\r\nerr_srq_table_free:\r\nmthca_cleanup_srq_table(dev);\r\nerr_cq_table_free:\r\nmthca_cleanup_cq_table(dev);\r\nerr_cmd_poll:\r\nmthca_cmd_use_polling(dev);\r\nerr_eq_table_free:\r\nmthca_cleanup_eq_table(dev);\r\nerr_pd_free:\r\nmthca_pd_free(dev, &dev->driver_pd);\r\nerr_mr_table_free:\r\nmthca_cleanup_mr_table(dev);\r\nerr_pd_table_free:\r\nmthca_cleanup_pd_table(dev);\r\nerr_kar_unmap:\r\niounmap(dev->kar);\r\nerr_uar_free:\r\nmthca_uar_free(dev, &dev->driver_uar);\r\nerr_uar_table_free:\r\nmthca_cleanup_uar_table(dev);\r\nreturn err;\r\n}\r\nstatic int mthca_enable_msi_x(struct mthca_dev *mdev)\r\n{\r\nstruct msix_entry entries[3];\r\nint err;\r\nentries[0].entry = 0;\r\nentries[1].entry = 1;\r\nentries[2].entry = 2;\r\nerr = pci_enable_msix(mdev->pdev, entries, ARRAY_SIZE(entries));\r\nif (err) {\r\nif (err > 0)\r\nmthca_info(mdev, "Only %d MSI-X vectors available, "\r\n"not using MSI-X\n", err);\r\nreturn err;\r\n}\r\nmdev->eq_table.eq[MTHCA_EQ_COMP ].msi_x_vector = entries[0].vector;\r\nmdev->eq_table.eq[MTHCA_EQ_ASYNC].msi_x_vector = entries[1].vector;\r\nmdev->eq_table.eq[MTHCA_EQ_CMD ].msi_x_vector = entries[2].vector;\r\nreturn 0;\r\n}\r\nstatic int __mthca_init_one(struct pci_dev *pdev, int hca_type)\r\n{\r\nint ddr_hidden = 0;\r\nint err;\r\nstruct mthca_dev *mdev;\r\nprintk(KERN_INFO PFX "Initializing %s\n",\r\npci_name(pdev));\r\nerr = pci_enable_device(pdev);\r\nif (err) {\r\ndev_err(&pdev->dev, "Cannot enable PCI device, "\r\n"aborting.\n");\r\nreturn err;\r\n}\r\nif (!(pci_resource_flags(pdev, 0) & IORESOURCE_MEM) ||\r\npci_resource_len(pdev, 0) != 1 << 20) {\r\ndev_err(&pdev->dev, "Missing DCS, aborting.\n");\r\nerr = -ENODEV;\r\ngoto err_disable_pdev;\r\n}\r\nif (!(pci_resource_flags(pdev, 2) & IORESOURCE_MEM)) {\r\ndev_err(&pdev->dev, "Missing UAR, aborting.\n");\r\nerr = -ENODEV;\r\ngoto err_disable_pdev;\r\n}\r\nif (!(pci_resource_flags(pdev, 4) & IORESOURCE_MEM))\r\nddr_hidden = 1;\r\nerr = pci_request_regions(pdev, DRV_NAME);\r\nif (err) {\r\ndev_err(&pdev->dev, "Cannot obtain PCI resources, "\r\n"aborting.\n");\r\ngoto err_disable_pdev;\r\n}\r\npci_set_master(pdev);\r\nerr = pci_set_dma_mask(pdev, DMA_BIT_MASK(64));\r\nif (err) {\r\ndev_warn(&pdev->dev, "Warning: couldn't set 64-bit PCI DMA mask.\n");\r\nerr = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (err) {\r\ndev_err(&pdev->dev, "Can't set PCI DMA mask, aborting.\n");\r\ngoto err_free_res;\r\n}\r\n}\r\nerr = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));\r\nif (err) {\r\ndev_warn(&pdev->dev, "Warning: couldn't set 64-bit "\r\n"consistent PCI DMA mask.\n");\r\nerr = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (err) {\r\ndev_err(&pdev->dev, "Can't set consistent PCI DMA mask, "\r\n"aborting.\n");\r\ngoto err_free_res;\r\n}\r\n}\r\ndma_set_max_seg_size(&pdev->dev, 1024 * 1024 * 1024);\r\nmdev = (struct mthca_dev *) ib_alloc_device(sizeof *mdev);\r\nif (!mdev) {\r\ndev_err(&pdev->dev, "Device struct alloc failed, "\r\n"aborting.\n");\r\nerr = -ENOMEM;\r\ngoto err_free_res;\r\n}\r\nmdev->pdev = pdev;\r\nmdev->mthca_flags = mthca_hca_table[hca_type].flags;\r\nif (ddr_hidden)\r\nmdev->mthca_flags |= MTHCA_FLAG_DDR_HIDDEN;\r\nerr = mthca_reset(mdev);\r\nif (err) {\r\nmthca_err(mdev, "Failed to reset HCA, aborting.\n");\r\ngoto err_free_dev;\r\n}\r\nif (mthca_cmd_init(mdev)) {\r\nmthca_err(mdev, "Failed to init command interface, aborting.\n");\r\ngoto err_free_dev;\r\n}\r\nerr = mthca_tune_pci(mdev);\r\nif (err)\r\ngoto err_cmd;\r\nerr = mthca_init_hca(mdev);\r\nif (err)\r\ngoto err_cmd;\r\nif (mdev->fw_ver < mthca_hca_table[hca_type].latest_fw) {\r\nmthca_warn(mdev, "HCA FW version %d.%d.%03d is old (%d.%d.%03d is current).\n",\r\n(int) (mdev->fw_ver >> 32), (int) (mdev->fw_ver >> 16) & 0xffff,\r\n(int) (mdev->fw_ver & 0xffff),\r\n(int) (mthca_hca_table[hca_type].latest_fw >> 32),\r\n(int) (mthca_hca_table[hca_type].latest_fw >> 16) & 0xffff,\r\n(int) (mthca_hca_table[hca_type].latest_fw & 0xffff));\r\nmthca_warn(mdev, "If you have problems, try updating your HCA FW.\n");\r\n}\r\nif (msi_x && !mthca_enable_msi_x(mdev))\r\nmdev->mthca_flags |= MTHCA_FLAG_MSI_X;\r\nerr = mthca_setup_hca(mdev);\r\nif (err == -EBUSY && (mdev->mthca_flags & MTHCA_FLAG_MSI_X)) {\r\nif (mdev->mthca_flags & MTHCA_FLAG_MSI_X)\r\npci_disable_msix(pdev);\r\nmdev->mthca_flags &= ~MTHCA_FLAG_MSI_X;\r\nerr = mthca_setup_hca(mdev);\r\n}\r\nif (err)\r\ngoto err_close;\r\nerr = mthca_register_device(mdev);\r\nif (err)\r\ngoto err_cleanup;\r\nerr = mthca_create_agents(mdev);\r\nif (err)\r\ngoto err_unregister;\r\npci_set_drvdata(pdev, mdev);\r\nmdev->hca_type = hca_type;\r\nmdev->active = true;\r\nreturn 0;\r\nerr_unregister:\r\nmthca_unregister_device(mdev);\r\nerr_cleanup:\r\nmthca_cleanup_mcg_table(mdev);\r\nmthca_cleanup_av_table(mdev);\r\nmthca_cleanup_qp_table(mdev);\r\nmthca_cleanup_srq_table(mdev);\r\nmthca_cleanup_cq_table(mdev);\r\nmthca_cmd_use_polling(mdev);\r\nmthca_cleanup_eq_table(mdev);\r\nmthca_pd_free(mdev, &mdev->driver_pd);\r\nmthca_cleanup_mr_table(mdev);\r\nmthca_cleanup_pd_table(mdev);\r\nmthca_cleanup_uar_table(mdev);\r\nerr_close:\r\nif (mdev->mthca_flags & MTHCA_FLAG_MSI_X)\r\npci_disable_msix(pdev);\r\nmthca_close_hca(mdev);\r\nerr_cmd:\r\nmthca_cmd_cleanup(mdev);\r\nerr_free_dev:\r\nib_dealloc_device(&mdev->ib_dev);\r\nerr_free_res:\r\npci_release_regions(pdev);\r\nerr_disable_pdev:\r\npci_disable_device(pdev);\r\npci_set_drvdata(pdev, NULL);\r\nreturn err;\r\n}\r\nstatic void __mthca_remove_one(struct pci_dev *pdev)\r\n{\r\nstruct mthca_dev *mdev = pci_get_drvdata(pdev);\r\nint p;\r\nif (mdev) {\r\nmthca_free_agents(mdev);\r\nmthca_unregister_device(mdev);\r\nfor (p = 1; p <= mdev->limits.num_ports; ++p)\r\nmthca_CLOSE_IB(mdev, p);\r\nmthca_cleanup_mcg_table(mdev);\r\nmthca_cleanup_av_table(mdev);\r\nmthca_cleanup_qp_table(mdev);\r\nmthca_cleanup_srq_table(mdev);\r\nmthca_cleanup_cq_table(mdev);\r\nmthca_cmd_use_polling(mdev);\r\nmthca_cleanup_eq_table(mdev);\r\nmthca_pd_free(mdev, &mdev->driver_pd);\r\nmthca_cleanup_mr_table(mdev);\r\nmthca_cleanup_pd_table(mdev);\r\niounmap(mdev->kar);\r\nmthca_uar_free(mdev, &mdev->driver_uar);\r\nmthca_cleanup_uar_table(mdev);\r\nmthca_close_hca(mdev);\r\nmthca_cmd_cleanup(mdev);\r\nif (mdev->mthca_flags & MTHCA_FLAG_MSI_X)\r\npci_disable_msix(pdev);\r\nib_dealloc_device(&mdev->ib_dev);\r\npci_release_regions(pdev);\r\npci_disable_device(pdev);\r\npci_set_drvdata(pdev, NULL);\r\n}\r\n}\r\nint __mthca_restart_one(struct pci_dev *pdev)\r\n{\r\nstruct mthca_dev *mdev;\r\nint hca_type;\r\nmdev = pci_get_drvdata(pdev);\r\nif (!mdev)\r\nreturn -ENODEV;\r\nhca_type = mdev->hca_type;\r\n__mthca_remove_one(pdev);\r\nreturn __mthca_init_one(pdev, hca_type);\r\n}\r\nstatic int __devinit mthca_init_one(struct pci_dev *pdev,\r\nconst struct pci_device_id *id)\r\n{\r\nint ret;\r\nmutex_lock(&mthca_device_mutex);\r\nprintk_once(KERN_INFO "%s", mthca_version);\r\nif (id->driver_data >= ARRAY_SIZE(mthca_hca_table)) {\r\nprintk(KERN_ERR PFX "%s has invalid driver data %lx\n",\r\npci_name(pdev), id->driver_data);\r\nmutex_unlock(&mthca_device_mutex);\r\nreturn -ENODEV;\r\n}\r\nret = __mthca_init_one(pdev, id->driver_data);\r\nmutex_unlock(&mthca_device_mutex);\r\nreturn ret;\r\n}\r\nstatic void __devexit mthca_remove_one(struct pci_dev *pdev)\r\n{\r\nmutex_lock(&mthca_device_mutex);\r\n__mthca_remove_one(pdev);\r\nmutex_unlock(&mthca_device_mutex);\r\n}\r\nstatic void __init __mthca_check_profile_val(const char *name, int *pval,\r\nint pval_default)\r\n{\r\nint old_pval = *pval;\r\nif (old_pval <= 0)\r\n*pval = pval_default;\r\nelse\r\n*pval = roundup_pow_of_two(old_pval);\r\nif (old_pval != *pval) {\r\nprintk(KERN_WARNING PFX "Invalid value %d for %s in module parameter.\n",\r\nold_pval, name);\r\nprintk(KERN_WARNING PFX "Corrected %s to %d.\n", name, *pval);\r\n}\r\n}\r\nstatic void __init mthca_validate_profile(void)\r\n{\r\nmthca_check_profile_val(num_qp, MTHCA_DEFAULT_NUM_QP);\r\nmthca_check_profile_val(rdb_per_qp, MTHCA_DEFAULT_RDB_PER_QP);\r\nmthca_check_profile_val(num_cq, MTHCA_DEFAULT_NUM_CQ);\r\nmthca_check_profile_val(num_mcg, MTHCA_DEFAULT_NUM_MCG);\r\nmthca_check_profile_val(num_mpt, MTHCA_DEFAULT_NUM_MPT);\r\nmthca_check_profile_val(num_mtt, MTHCA_DEFAULT_NUM_MTT);\r\nmthca_check_profile_val(num_udav, MTHCA_DEFAULT_NUM_UDAV);\r\nmthca_check_profile_val(fmr_reserved_mtts, MTHCA_DEFAULT_NUM_RESERVED_MTTS);\r\nif (hca_profile.fmr_reserved_mtts >= hca_profile.num_mtt) {\r\nprintk(KERN_WARNING PFX "Invalid fmr_reserved_mtts module parameter %d.\n",\r\nhca_profile.fmr_reserved_mtts);\r\nprintk(KERN_WARNING PFX "(Must be smaller than num_mtt %d)\n",\r\nhca_profile.num_mtt);\r\nhca_profile.fmr_reserved_mtts = hca_profile.num_mtt / 2;\r\nprintk(KERN_WARNING PFX "Corrected fmr_reserved_mtts to %d.\n",\r\nhca_profile.fmr_reserved_mtts);\r\n}\r\nif ((log_mtts_per_seg < 1) || (log_mtts_per_seg > 5)) {\r\nprintk(KERN_WARNING PFX "bad log_mtts_per_seg (%d). Using default - %d\n",\r\nlog_mtts_per_seg, ilog2(MTHCA_MTT_SEG_SIZE / 8));\r\nlog_mtts_per_seg = ilog2(MTHCA_MTT_SEG_SIZE / 8);\r\n}\r\n}\r\nstatic int __init mthca_init(void)\r\n{\r\nint ret;\r\nmthca_validate_profile();\r\nret = mthca_catas_init();\r\nif (ret)\r\nreturn ret;\r\nret = pci_register_driver(&mthca_driver);\r\nif (ret < 0) {\r\nmthca_catas_cleanup();\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nstatic void __exit mthca_cleanup(void)\r\n{\r\npci_unregister_driver(&mthca_driver);\r\nmthca_catas_cleanup();\r\n}
