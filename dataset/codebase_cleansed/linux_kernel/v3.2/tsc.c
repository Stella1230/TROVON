u64 native_sched_clock(void)\r\n{\r\nu64 this_offset;\r\nif (unlikely(tsc_disabled)) {\r\nreturn (jiffies_64 - INITIAL_JIFFIES) * (1000000000 / HZ);\r\n}\r\nrdtscll(this_offset);\r\nreturn __cycles_2_ns(this_offset);\r\n}\r\nunsigned long long sched_clock(void)\r\n{\r\nreturn paravirt_sched_clock();\r\n}\r\nint check_tsc_unstable(void)\r\n{\r\nreturn tsc_unstable;\r\n}\r\nint __init notsc_setup(char *str)\r\n{\r\nprintk(KERN_WARNING "notsc: Kernel compiled with CONFIG_X86_TSC, "\r\n"cannot disable TSC completely.\n");\r\ntsc_disabled = 1;\r\nreturn 1;\r\n}\r\nint __init notsc_setup(char *str)\r\n{\r\nsetup_clear_cpu_cap(X86_FEATURE_TSC);\r\nreturn 1;\r\n}\r\nstatic int __init tsc_setup(char *str)\r\n{\r\nif (!strcmp(str, "reliable"))\r\ntsc_clocksource_reliable = 1;\r\nif (!strncmp(str, "noirqtime", 9))\r\nno_sched_irq_time = 1;\r\nreturn 1;\r\n}\r\nstatic u64 tsc_read_refs(u64 *p, int hpet)\r\n{\r\nu64 t1, t2;\r\nint i;\r\nfor (i = 0; i < MAX_RETRIES; i++) {\r\nt1 = get_cycles();\r\nif (hpet)\r\n*p = hpet_readl(HPET_COUNTER) & 0xFFFFFFFF;\r\nelse\r\n*p = acpi_pm_read_early();\r\nt2 = get_cycles();\r\nif ((t2 - t1) < SMI_TRESHOLD)\r\nreturn t2;\r\n}\r\nreturn ULLONG_MAX;\r\n}\r\nstatic unsigned long calc_hpet_ref(u64 deltatsc, u64 hpet1, u64 hpet2)\r\n{\r\nu64 tmp;\r\nif (hpet2 < hpet1)\r\nhpet2 += 0x100000000ULL;\r\nhpet2 -= hpet1;\r\ntmp = ((u64)hpet2 * hpet_readl(HPET_PERIOD));\r\ndo_div(tmp, 1000000);\r\ndo_div(deltatsc, tmp);\r\nreturn (unsigned long) deltatsc;\r\n}\r\nstatic unsigned long calc_pmtimer_ref(u64 deltatsc, u64 pm1, u64 pm2)\r\n{\r\nu64 tmp;\r\nif (!pm1 && !pm2)\r\nreturn ULONG_MAX;\r\nif (pm2 < pm1)\r\npm2 += (u64)ACPI_PM_OVRRUN;\r\npm2 -= pm1;\r\ntmp = pm2 * 1000000000LL;\r\ndo_div(tmp, PMTMR_TICKS_PER_SEC);\r\ndo_div(deltatsc, tmp);\r\nreturn (unsigned long) deltatsc;\r\n}\r\nstatic unsigned long pit_calibrate_tsc(u32 latch, unsigned long ms, int loopmin)\r\n{\r\nu64 tsc, t1, t2, delta;\r\nunsigned long tscmin, tscmax;\r\nint pitcnt;\r\noutb((inb(0x61) & ~0x02) | 0x01, 0x61);\r\noutb(0xb0, 0x43);\r\noutb(latch & 0xff, 0x42);\r\noutb(latch >> 8, 0x42);\r\ntsc = t1 = t2 = get_cycles();\r\npitcnt = 0;\r\ntscmax = 0;\r\ntscmin = ULONG_MAX;\r\nwhile ((inb(0x61) & 0x20) == 0) {\r\nt2 = get_cycles();\r\ndelta = t2 - tsc;\r\ntsc = t2;\r\nif ((unsigned long) delta < tscmin)\r\ntscmin = (unsigned int) delta;\r\nif ((unsigned long) delta > tscmax)\r\ntscmax = (unsigned int) delta;\r\npitcnt++;\r\n}\r\nif (pitcnt < loopmin || tscmax > 10 * tscmin)\r\nreturn ULONG_MAX;\r\ndelta = t2 - t1;\r\ndo_div(delta, ms);\r\nreturn delta;\r\n}\r\nstatic inline int pit_verify_msb(unsigned char val)\r\n{\r\ninb(0x42);\r\nreturn inb(0x42) == val;\r\n}\r\nstatic inline int pit_expect_msb(unsigned char val, u64 *tscp, unsigned long *deltap)\r\n{\r\nint count;\r\nu64 tsc = 0;\r\nfor (count = 0; count < 50000; count++) {\r\nif (!pit_verify_msb(val))\r\nbreak;\r\ntsc = get_cycles();\r\n}\r\n*deltap = get_cycles() - tsc;\r\n*tscp = tsc;\r\nreturn count > 5;\r\n}\r\nstatic unsigned long quick_pit_calibrate(void)\r\n{\r\nint i;\r\nu64 tsc, delta;\r\nunsigned long d1, d2;\r\noutb((inb(0x61) & ~0x02) | 0x01, 0x61);\r\noutb(0xb0, 0x43);\r\noutb(0xff, 0x42);\r\noutb(0xff, 0x42);\r\npit_verify_msb(0);\r\nif (pit_expect_msb(0xff, &tsc, &d1)) {\r\nfor (i = 1; i <= MAX_QUICK_PIT_ITERATIONS; i++) {\r\nif (!pit_expect_msb(0xff-i, &delta, &d2))\r\nbreak;\r\ndelta -= tsc;\r\nif (d1+d2 >= delta >> 11)\r\ncontinue;\r\nif (!pit_verify_msb(0xfe - i))\r\nbreak;\r\ngoto success;\r\n}\r\n}\r\nprintk("Fast TSC calibration failed\n");\r\nreturn 0;\r\nsuccess:\r\ndelta += (long)(d2 - d1)/2;\r\ndelta *= PIT_TICK_RATE;\r\ndo_div(delta, i*256*1000);\r\nprintk("Fast TSC calibration using PIT\n");\r\nreturn delta;\r\n}\r\nunsigned long native_calibrate_tsc(void)\r\n{\r\nu64 tsc1, tsc2, delta, ref1, ref2;\r\nunsigned long tsc_pit_min = ULONG_MAX, tsc_ref_min = ULONG_MAX;\r\nunsigned long flags, latch, ms, fast_calibrate;\r\nint hpet = is_hpet_enabled(), i, loopmin;\r\nlocal_irq_save(flags);\r\nfast_calibrate = quick_pit_calibrate();\r\nlocal_irq_restore(flags);\r\nif (fast_calibrate)\r\nreturn fast_calibrate;\r\nlatch = CAL_LATCH;\r\nms = CAL_MS;\r\nloopmin = CAL_PIT_LOOPS;\r\nfor (i = 0; i < 3; i++) {\r\nunsigned long tsc_pit_khz;\r\nlocal_irq_save(flags);\r\ntsc1 = tsc_read_refs(&ref1, hpet);\r\ntsc_pit_khz = pit_calibrate_tsc(latch, ms, loopmin);\r\ntsc2 = tsc_read_refs(&ref2, hpet);\r\nlocal_irq_restore(flags);\r\ntsc_pit_min = min(tsc_pit_min, tsc_pit_khz);\r\nif (ref1 == ref2)\r\ncontinue;\r\nif (tsc1 == ULLONG_MAX || tsc2 == ULLONG_MAX)\r\ncontinue;\r\ntsc2 = (tsc2 - tsc1) * 1000000LL;\r\nif (hpet)\r\ntsc2 = calc_hpet_ref(tsc2, ref1, ref2);\r\nelse\r\ntsc2 = calc_pmtimer_ref(tsc2, ref1, ref2);\r\ntsc_ref_min = min(tsc_ref_min, (unsigned long) tsc2);\r\ndelta = ((u64) tsc_pit_min) * 100;\r\ndo_div(delta, tsc_ref_min);\r\nif (delta >= 90 && delta <= 110) {\r\nprintk(KERN_INFO\r\n"TSC: PIT calibration matches %s. %d loops\n",\r\nhpet ? "HPET" : "PMTIMER", i + 1);\r\nreturn tsc_ref_min;\r\n}\r\nif (i == 1 && tsc_pit_min == ULONG_MAX) {\r\nlatch = CAL2_LATCH;\r\nms = CAL2_MS;\r\nloopmin = CAL2_PIT_LOOPS;\r\n}\r\n}\r\nif (tsc_pit_min == ULONG_MAX) {\r\nprintk(KERN_WARNING "TSC: Unable to calibrate against PIT\n");\r\nif (!hpet && !ref1 && !ref2) {\r\nprintk("TSC: No reference (HPET/PMTIMER) available\n");\r\nreturn 0;\r\n}\r\nif (tsc_ref_min == ULONG_MAX) {\r\nprintk(KERN_WARNING "TSC: HPET/PMTIMER calibration "\r\n"failed.\n");\r\nreturn 0;\r\n}\r\nprintk(KERN_INFO "TSC: using %s reference calibration\n",\r\nhpet ? "HPET" : "PMTIMER");\r\nreturn tsc_ref_min;\r\n}\r\nif (!hpet && !ref1 && !ref2) {\r\nprintk(KERN_INFO "TSC: Using PIT calibration value\n");\r\nreturn tsc_pit_min;\r\n}\r\nif (tsc_ref_min == ULONG_MAX) {\r\nprintk(KERN_WARNING "TSC: HPET/PMTIMER calibration failed. "\r\n"Using PIT calibration\n");\r\nreturn tsc_pit_min;\r\n}\r\nprintk(KERN_WARNING "TSC: PIT calibration deviates from %s: %lu %lu.\n",\r\nhpet ? "HPET" : "PMTIMER", tsc_pit_min, tsc_ref_min);\r\nprintk(KERN_INFO "TSC: Using PIT calibration value\n");\r\nreturn tsc_pit_min;\r\n}\r\nint recalibrate_cpu_khz(void)\r\n{\r\n#ifndef CONFIG_SMP\r\nunsigned long cpu_khz_old = cpu_khz;\r\nif (cpu_has_tsc) {\r\ntsc_khz = x86_platform.calibrate_tsc();\r\ncpu_khz = tsc_khz;\r\ncpu_data(0).loops_per_jiffy =\r\ncpufreq_scale(cpu_data(0).loops_per_jiffy,\r\ncpu_khz_old, cpu_khz);\r\nreturn 0;\r\n} else\r\nreturn -ENODEV;\r\n#else\r\nreturn -ENODEV;\r\n#endif\r\n}\r\nstatic void set_cyc2ns_scale(unsigned long cpu_khz, int cpu)\r\n{\r\nunsigned long long tsc_now, ns_now, *offset;\r\nunsigned long flags, *scale;\r\nlocal_irq_save(flags);\r\nsched_clock_idle_sleep_event();\r\nscale = &per_cpu(cyc2ns, cpu);\r\noffset = &per_cpu(cyc2ns_offset, cpu);\r\nrdtscll(tsc_now);\r\nns_now = __cycles_2_ns(tsc_now);\r\nif (cpu_khz) {\r\n*scale = (NSEC_PER_MSEC << CYC2NS_SCALE_FACTOR)/cpu_khz;\r\n*offset = ns_now - (tsc_now * *scale >> CYC2NS_SCALE_FACTOR);\r\n}\r\nsched_clock_idle_wakeup_event(0);\r\nlocal_irq_restore(flags);\r\n}\r\nvoid save_sched_clock_state(void)\r\n{\r\nif (!sched_clock_stable)\r\nreturn;\r\ncyc2ns_suspend = sched_clock();\r\n}\r\nvoid restore_sched_clock_state(void)\r\n{\r\nunsigned long long offset;\r\nunsigned long flags;\r\nint cpu;\r\nif (!sched_clock_stable)\r\nreturn;\r\nlocal_irq_save(flags);\r\n__this_cpu_write(cyc2ns_offset, 0);\r\noffset = cyc2ns_suspend - sched_clock();\r\nfor_each_possible_cpu(cpu)\r\nper_cpu(cyc2ns_offset, cpu) = offset;\r\nlocal_irq_restore(flags);\r\n}\r\nstatic int time_cpufreq_notifier(struct notifier_block *nb, unsigned long val,\r\nvoid *data)\r\n{\r\nstruct cpufreq_freqs *freq = data;\r\nunsigned long *lpj;\r\nif (cpu_has(&cpu_data(freq->cpu), X86_FEATURE_CONSTANT_TSC))\r\nreturn 0;\r\nlpj = &boot_cpu_data.loops_per_jiffy;\r\n#ifdef CONFIG_SMP\r\nif (!(freq->flags & CPUFREQ_CONST_LOOPS))\r\nlpj = &cpu_data(freq->cpu).loops_per_jiffy;\r\n#endif\r\nif (!ref_freq) {\r\nref_freq = freq->old;\r\nloops_per_jiffy_ref = *lpj;\r\ntsc_khz_ref = tsc_khz;\r\n}\r\nif ((val == CPUFREQ_PRECHANGE && freq->old < freq->new) ||\r\n(val == CPUFREQ_POSTCHANGE && freq->old > freq->new) ||\r\n(val == CPUFREQ_RESUMECHANGE)) {\r\n*lpj = cpufreq_scale(loops_per_jiffy_ref, ref_freq, freq->new);\r\ntsc_khz = cpufreq_scale(tsc_khz_ref, ref_freq, freq->new);\r\nif (!(freq->flags & CPUFREQ_CONST_LOOPS))\r\nmark_tsc_unstable("cpufreq changes");\r\n}\r\nset_cyc2ns_scale(tsc_khz, freq->cpu);\r\nreturn 0;\r\n}\r\nstatic int __init cpufreq_tsc(void)\r\n{\r\nif (!cpu_has_tsc)\r\nreturn 0;\r\nif (boot_cpu_has(X86_FEATURE_CONSTANT_TSC))\r\nreturn 0;\r\ncpufreq_register_notifier(&time_cpufreq_notifier_block,\r\nCPUFREQ_TRANSITION_NOTIFIER);\r\nreturn 0;\r\n}\r\nstatic cycle_t read_tsc(struct clocksource *cs)\r\n{\r\ncycle_t ret = (cycle_t)get_cycles();\r\nreturn ret >= clocksource_tsc.cycle_last ?\r\nret : clocksource_tsc.cycle_last;\r\n}\r\nstatic void resume_tsc(struct clocksource *cs)\r\n{\r\nclocksource_tsc.cycle_last = 0;\r\n}\r\nvoid mark_tsc_unstable(char *reason)\r\n{\r\nif (!tsc_unstable) {\r\ntsc_unstable = 1;\r\nsched_clock_stable = 0;\r\ndisable_sched_clock_irqtime();\r\nprintk(KERN_INFO "Marking TSC unstable due to %s\n", reason);\r\nif (clocksource_tsc.mult)\r\nclocksource_mark_unstable(&clocksource_tsc);\r\nelse {\r\nclocksource_tsc.flags |= CLOCK_SOURCE_UNSTABLE;\r\nclocksource_tsc.rating = 0;\r\n}\r\n}\r\n}\r\nstatic void __init check_system_tsc_reliable(void)\r\n{\r\n#ifdef CONFIG_MGEODE_LX\r\n#define RTSC_SUSP 0x100\r\nunsigned long res_low, res_high;\r\nrdmsr_safe(MSR_GEODE_BUSCONT_CONF0, &res_low, &res_high);\r\nif (res_low & RTSC_SUSP)\r\ntsc_clocksource_reliable = 1;\r\n#endif\r\nif (boot_cpu_has(X86_FEATURE_TSC_RELIABLE))\r\ntsc_clocksource_reliable = 1;\r\n}\r\n__cpuinit int unsynchronized_tsc(void)\r\n{\r\nif (!cpu_has_tsc || tsc_unstable)\r\nreturn 1;\r\n#ifdef CONFIG_SMP\r\nif (apic_is_clustered_box())\r\nreturn 1;\r\n#endif\r\nif (boot_cpu_has(X86_FEATURE_CONSTANT_TSC))\r\nreturn 0;\r\nif (tsc_clocksource_reliable)\r\nreturn 0;\r\nif (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL) {\r\nif (num_possible_cpus() > 1)\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic void tsc_refine_calibration_work(struct work_struct *work)\r\n{\r\nstatic u64 tsc_start = -1, ref_start;\r\nstatic int hpet;\r\nu64 tsc_stop, ref_stop, delta;\r\nunsigned long freq;\r\nif (check_tsc_unstable())\r\ngoto out;\r\nif (tsc_start == -1) {\r\nhpet = is_hpet_enabled();\r\nschedule_delayed_work(&tsc_irqwork, HZ);\r\ntsc_start = tsc_read_refs(&ref_start, hpet);\r\nreturn;\r\n}\r\ntsc_stop = tsc_read_refs(&ref_stop, hpet);\r\nif (ref_start == ref_stop)\r\ngoto out;\r\nif (tsc_start == ULLONG_MAX || tsc_stop == ULLONG_MAX)\r\ngoto out;\r\ndelta = tsc_stop - tsc_start;\r\ndelta *= 1000000LL;\r\nif (hpet)\r\nfreq = calc_hpet_ref(delta, ref_start, ref_stop);\r\nelse\r\nfreq = calc_pmtimer_ref(delta, ref_start, ref_stop);\r\nif (abs(tsc_khz - freq) > tsc_khz/100)\r\ngoto out;\r\ntsc_khz = freq;\r\nprintk(KERN_INFO "Refined TSC clocksource calibration: "\r\n"%lu.%03lu MHz.\n", (unsigned long)tsc_khz / 1000,\r\n(unsigned long)tsc_khz % 1000);\r\nout:\r\nclocksource_register_khz(&clocksource_tsc, tsc_khz);\r\n}\r\nstatic int __init init_tsc_clocksource(void)\r\n{\r\nif (!cpu_has_tsc || tsc_disabled > 0 || !tsc_khz)\r\nreturn 0;\r\nif (tsc_clocksource_reliable)\r\nclocksource_tsc.flags &= ~CLOCK_SOURCE_MUST_VERIFY;\r\nif (check_tsc_unstable()) {\r\nclocksource_tsc.rating = 0;\r\nclocksource_tsc.flags &= ~CLOCK_SOURCE_IS_CONTINUOUS;\r\n}\r\nschedule_delayed_work(&tsc_irqwork, 0);\r\nreturn 0;\r\n}\r\nvoid __init tsc_init(void)\r\n{\r\nu64 lpj;\r\nint cpu;\r\nx86_init.timers.tsc_pre_init();\r\nif (!cpu_has_tsc)\r\nreturn;\r\ntsc_khz = x86_platform.calibrate_tsc();\r\ncpu_khz = tsc_khz;\r\nif (!tsc_khz) {\r\nmark_tsc_unstable("could not calculate TSC khz");\r\nreturn;\r\n}\r\nprintk("Detected %lu.%03lu MHz processor.\n",\r\n(unsigned long)cpu_khz / 1000,\r\n(unsigned long)cpu_khz % 1000);\r\nfor_each_possible_cpu(cpu)\r\nset_cyc2ns_scale(cpu_khz, cpu);\r\nif (tsc_disabled > 0)\r\nreturn;\r\ntsc_disabled = 0;\r\nif (!no_sched_irq_time)\r\nenable_sched_clock_irqtime();\r\nlpj = ((u64)tsc_khz * 1000);\r\ndo_div(lpj, HZ);\r\nlpj_fine = lpj;\r\nuse_tsc_delay();\r\nif (unsynchronized_tsc())\r\nmark_tsc_unstable("TSCs unsynchronized");\r\ncheck_system_tsc_reliable();\r\n}
