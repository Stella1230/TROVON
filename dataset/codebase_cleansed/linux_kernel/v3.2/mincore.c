static void mincore_hugetlb_page_range(struct vm_area_struct *vma,\r\nunsigned long addr, unsigned long end,\r\nunsigned char *vec)\r\n{\r\n#ifdef CONFIG_HUGETLB_PAGE\r\nstruct hstate *h;\r\nh = hstate_vma(vma);\r\nwhile (1) {\r\nunsigned char present;\r\npte_t *ptep;\r\nptep = huge_pte_offset(current->mm,\r\naddr & huge_page_mask(h));\r\npresent = ptep && !huge_pte_none(huge_ptep_get(ptep));\r\nwhile (1) {\r\n*vec = present;\r\nvec++;\r\naddr += PAGE_SIZE;\r\nif (addr == end)\r\nreturn;\r\nif (!(addr & ~huge_page_mask(h)))\r\nbreak;\r\n}\r\n}\r\n#else\r\nBUG();\r\n#endif\r\n}\r\nstatic unsigned char mincore_page(struct address_space *mapping, pgoff_t pgoff)\r\n{\r\nunsigned char present = 0;\r\nstruct page *page;\r\npage = find_get_page(mapping, pgoff);\r\n#ifdef CONFIG_SWAP\r\nif (radix_tree_exceptional_entry(page)) {\r\nswp_entry_t swap = radix_to_swp_entry(page);\r\npage = find_get_page(&swapper_space, swap.val);\r\n}\r\n#endif\r\nif (page) {\r\npresent = PageUptodate(page);\r\npage_cache_release(page);\r\n}\r\nreturn present;\r\n}\r\nstatic void mincore_unmapped_range(struct vm_area_struct *vma,\r\nunsigned long addr, unsigned long end,\r\nunsigned char *vec)\r\n{\r\nunsigned long nr = (end - addr) >> PAGE_SHIFT;\r\nint i;\r\nif (vma->vm_file) {\r\npgoff_t pgoff;\r\npgoff = linear_page_index(vma, addr);\r\nfor (i = 0; i < nr; i++, pgoff++)\r\nvec[i] = mincore_page(vma->vm_file->f_mapping, pgoff);\r\n} else {\r\nfor (i = 0; i < nr; i++)\r\nvec[i] = 0;\r\n}\r\n}\r\nstatic void mincore_pte_range(struct vm_area_struct *vma, pmd_t *pmd,\r\nunsigned long addr, unsigned long end,\r\nunsigned char *vec)\r\n{\r\nunsigned long next;\r\nspinlock_t *ptl;\r\npte_t *ptep;\r\nptep = pte_offset_map_lock(vma->vm_mm, pmd, addr, &ptl);\r\ndo {\r\npte_t pte = *ptep;\r\npgoff_t pgoff;\r\nnext = addr + PAGE_SIZE;\r\nif (pte_none(pte))\r\nmincore_unmapped_range(vma, addr, next, vec);\r\nelse if (pte_present(pte))\r\n*vec = 1;\r\nelse if (pte_file(pte)) {\r\npgoff = pte_to_pgoff(pte);\r\n*vec = mincore_page(vma->vm_file->f_mapping, pgoff);\r\n} else {\r\nswp_entry_t entry = pte_to_swp_entry(pte);\r\nif (is_migration_entry(entry)) {\r\n*vec = 1;\r\n} else {\r\n#ifdef CONFIG_SWAP\r\npgoff = entry.val;\r\n*vec = mincore_page(&swapper_space, pgoff);\r\n#else\r\nWARN_ON(1);\r\n*vec = 1;\r\n#endif\r\n}\r\n}\r\nvec++;\r\n} while (ptep++, addr = next, addr != end);\r\npte_unmap_unlock(ptep - 1, ptl);\r\n}\r\nstatic void mincore_pmd_range(struct vm_area_struct *vma, pud_t *pud,\r\nunsigned long addr, unsigned long end,\r\nunsigned char *vec)\r\n{\r\nunsigned long next;\r\npmd_t *pmd;\r\npmd = pmd_offset(pud, addr);\r\ndo {\r\nnext = pmd_addr_end(addr, end);\r\nif (pmd_trans_huge(*pmd)) {\r\nif (mincore_huge_pmd(vma, pmd, addr, next, vec)) {\r\nvec += (next - addr) >> PAGE_SHIFT;\r\ncontinue;\r\n}\r\n}\r\nif (pmd_none_or_clear_bad(pmd))\r\nmincore_unmapped_range(vma, addr, next, vec);\r\nelse\r\nmincore_pte_range(vma, pmd, addr, next, vec);\r\nvec += (next - addr) >> PAGE_SHIFT;\r\n} while (pmd++, addr = next, addr != end);\r\n}\r\nstatic void mincore_pud_range(struct vm_area_struct *vma, pgd_t *pgd,\r\nunsigned long addr, unsigned long end,\r\nunsigned char *vec)\r\n{\r\nunsigned long next;\r\npud_t *pud;\r\npud = pud_offset(pgd, addr);\r\ndo {\r\nnext = pud_addr_end(addr, end);\r\nif (pud_none_or_clear_bad(pud))\r\nmincore_unmapped_range(vma, addr, next, vec);\r\nelse\r\nmincore_pmd_range(vma, pud, addr, next, vec);\r\nvec += (next - addr) >> PAGE_SHIFT;\r\n} while (pud++, addr = next, addr != end);\r\n}\r\nstatic void mincore_page_range(struct vm_area_struct *vma,\r\nunsigned long addr, unsigned long end,\r\nunsigned char *vec)\r\n{\r\nunsigned long next;\r\npgd_t *pgd;\r\npgd = pgd_offset(vma->vm_mm, addr);\r\ndo {\r\nnext = pgd_addr_end(addr, end);\r\nif (pgd_none_or_clear_bad(pgd))\r\nmincore_unmapped_range(vma, addr, next, vec);\r\nelse\r\nmincore_pud_range(vma, pgd, addr, next, vec);\r\nvec += (next - addr) >> PAGE_SHIFT;\r\n} while (pgd++, addr = next, addr != end);\r\n}\r\nstatic long do_mincore(unsigned long addr, unsigned long pages, unsigned char *vec)\r\n{\r\nstruct vm_area_struct *vma;\r\nunsigned long end;\r\nvma = find_vma(current->mm, addr);\r\nif (!vma || addr < vma->vm_start)\r\nreturn -ENOMEM;\r\nend = min(vma->vm_end, addr + (pages << PAGE_SHIFT));\r\nif (is_vm_hugetlb_page(vma)) {\r\nmincore_hugetlb_page_range(vma, addr, end, vec);\r\nreturn (end - addr) >> PAGE_SHIFT;\r\n}\r\nend = pmd_addr_end(addr, end);\r\nif (is_vm_hugetlb_page(vma))\r\nmincore_hugetlb_page_range(vma, addr, end, vec);\r\nelse\r\nmincore_page_range(vma, addr, end, vec);\r\nreturn (end - addr) >> PAGE_SHIFT;\r\n}
