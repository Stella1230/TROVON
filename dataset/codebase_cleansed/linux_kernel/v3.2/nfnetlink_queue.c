static inline u_int8_t instance_hashfn(u_int16_t queue_num)\r\n{\r\nreturn ((queue_num >> 8) | queue_num) % INSTANCE_BUCKETS;\r\n}\r\nstatic struct nfqnl_instance *\r\ninstance_lookup(u_int16_t queue_num)\r\n{\r\nstruct hlist_head *head;\r\nstruct hlist_node *pos;\r\nstruct nfqnl_instance *inst;\r\nhead = &instance_table[instance_hashfn(queue_num)];\r\nhlist_for_each_entry_rcu(inst, pos, head, hlist) {\r\nif (inst->queue_num == queue_num)\r\nreturn inst;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct nfqnl_instance *\r\ninstance_create(u_int16_t queue_num, int pid)\r\n{\r\nstruct nfqnl_instance *inst;\r\nunsigned int h;\r\nint err;\r\nspin_lock(&instances_lock);\r\nif (instance_lookup(queue_num)) {\r\nerr = -EEXIST;\r\ngoto out_unlock;\r\n}\r\ninst = kzalloc(sizeof(*inst), GFP_ATOMIC);\r\nif (!inst) {\r\nerr = -ENOMEM;\r\ngoto out_unlock;\r\n}\r\ninst->queue_num = queue_num;\r\ninst->peer_pid = pid;\r\ninst->queue_maxlen = NFQNL_QMAX_DEFAULT;\r\ninst->copy_range = 0xfffff;\r\ninst->copy_mode = NFQNL_COPY_NONE;\r\nspin_lock_init(&inst->lock);\r\nINIT_LIST_HEAD(&inst->queue_list);\r\nif (!try_module_get(THIS_MODULE)) {\r\nerr = -EAGAIN;\r\ngoto out_free;\r\n}\r\nh = instance_hashfn(queue_num);\r\nhlist_add_head_rcu(&inst->hlist, &instance_table[h]);\r\nspin_unlock(&instances_lock);\r\nreturn inst;\r\nout_free:\r\nkfree(inst);\r\nout_unlock:\r\nspin_unlock(&instances_lock);\r\nreturn ERR_PTR(err);\r\n}\r\nstatic void\r\ninstance_destroy_rcu(struct rcu_head *head)\r\n{\r\nstruct nfqnl_instance *inst = container_of(head, struct nfqnl_instance,\r\nrcu);\r\nnfqnl_flush(inst, NULL, 0);\r\nkfree(inst);\r\nmodule_put(THIS_MODULE);\r\n}\r\nstatic void\r\n__instance_destroy(struct nfqnl_instance *inst)\r\n{\r\nhlist_del_rcu(&inst->hlist);\r\ncall_rcu(&inst->rcu, instance_destroy_rcu);\r\n}\r\nstatic void\r\ninstance_destroy(struct nfqnl_instance *inst)\r\n{\r\nspin_lock(&instances_lock);\r\n__instance_destroy(inst);\r\nspin_unlock(&instances_lock);\r\n}\r\nstatic inline void\r\n__enqueue_entry(struct nfqnl_instance *queue, struct nf_queue_entry *entry)\r\n{\r\nlist_add_tail(&entry->list, &queue->queue_list);\r\nqueue->queue_total++;\r\n}\r\nstatic void\r\n__dequeue_entry(struct nfqnl_instance *queue, struct nf_queue_entry *entry)\r\n{\r\nlist_del(&entry->list);\r\nqueue->queue_total--;\r\n}\r\nstatic struct nf_queue_entry *\r\nfind_dequeue_entry(struct nfqnl_instance *queue, unsigned int id)\r\n{\r\nstruct nf_queue_entry *entry = NULL, *i;\r\nspin_lock_bh(&queue->lock);\r\nlist_for_each_entry(i, &queue->queue_list, list) {\r\nif (i->id == id) {\r\nentry = i;\r\nbreak;\r\n}\r\n}\r\nif (entry)\r\n__dequeue_entry(queue, entry);\r\nspin_unlock_bh(&queue->lock);\r\nreturn entry;\r\n}\r\nstatic void\r\nnfqnl_flush(struct nfqnl_instance *queue, nfqnl_cmpfn cmpfn, unsigned long data)\r\n{\r\nstruct nf_queue_entry *entry, *next;\r\nspin_lock_bh(&queue->lock);\r\nlist_for_each_entry_safe(entry, next, &queue->queue_list, list) {\r\nif (!cmpfn || cmpfn(entry, data)) {\r\nlist_del(&entry->list);\r\nqueue->queue_total--;\r\nnf_reinject(entry, NF_DROP);\r\n}\r\n}\r\nspin_unlock_bh(&queue->lock);\r\n}\r\nstatic struct sk_buff *\r\nnfqnl_build_packet_message(struct nfqnl_instance *queue,\r\nstruct nf_queue_entry *entry,\r\n__be32 **packet_id_ptr)\r\n{\r\nsk_buff_data_t old_tail;\r\nsize_t size;\r\nsize_t data_len = 0;\r\nstruct sk_buff *skb;\r\nstruct nlattr *nla;\r\nstruct nfqnl_msg_packet_hdr *pmsg;\r\nstruct nlmsghdr *nlh;\r\nstruct nfgenmsg *nfmsg;\r\nstruct sk_buff *entskb = entry->skb;\r\nstruct net_device *indev;\r\nstruct net_device *outdev;\r\nsize = NLMSG_SPACE(sizeof(struct nfgenmsg))\r\n+ nla_total_size(sizeof(struct nfqnl_msg_packet_hdr))\r\n+ nla_total_size(sizeof(u_int32_t))\r\n+ nla_total_size(sizeof(u_int32_t))\r\n#ifdef CONFIG_BRIDGE_NETFILTER\r\n+ nla_total_size(sizeof(u_int32_t))\r\n+ nla_total_size(sizeof(u_int32_t))\r\n#endif\r\n+ nla_total_size(sizeof(u_int32_t))\r\n+ nla_total_size(sizeof(struct nfqnl_msg_packet_hw))\r\n+ nla_total_size(sizeof(struct nfqnl_msg_packet_timestamp));\r\noutdev = entry->outdev;\r\nswitch ((enum nfqnl_config_mode)ACCESS_ONCE(queue->copy_mode)) {\r\ncase NFQNL_COPY_META:\r\ncase NFQNL_COPY_NONE:\r\nbreak;\r\ncase NFQNL_COPY_PACKET:\r\nif (entskb->ip_summed == CHECKSUM_PARTIAL &&\r\nskb_checksum_help(entskb))\r\nreturn NULL;\r\ndata_len = ACCESS_ONCE(queue->copy_range);\r\nif (data_len == 0 || data_len > entskb->len)\r\ndata_len = entskb->len;\r\nsize += nla_total_size(data_len);\r\nbreak;\r\n}\r\nskb = alloc_skb(size, GFP_ATOMIC);\r\nif (!skb)\r\ngoto nlmsg_failure;\r\nold_tail = skb->tail;\r\nnlh = NLMSG_PUT(skb, 0, 0,\r\nNFNL_SUBSYS_QUEUE << 8 | NFQNL_MSG_PACKET,\r\nsizeof(struct nfgenmsg));\r\nnfmsg = NLMSG_DATA(nlh);\r\nnfmsg->nfgen_family = entry->pf;\r\nnfmsg->version = NFNETLINK_V0;\r\nnfmsg->res_id = htons(queue->queue_num);\r\nnla = __nla_reserve(skb, NFQA_PACKET_HDR, sizeof(*pmsg));\r\npmsg = nla_data(nla);\r\npmsg->hw_protocol = entskb->protocol;\r\npmsg->hook = entry->hook;\r\n*packet_id_ptr = &pmsg->packet_id;\r\nindev = entry->indev;\r\nif (indev) {\r\n#ifndef CONFIG_BRIDGE_NETFILTER\r\nNLA_PUT_BE32(skb, NFQA_IFINDEX_INDEV, htonl(indev->ifindex));\r\n#else\r\nif (entry->pf == PF_BRIDGE) {\r\nNLA_PUT_BE32(skb, NFQA_IFINDEX_PHYSINDEV,\r\nhtonl(indev->ifindex));\r\nNLA_PUT_BE32(skb, NFQA_IFINDEX_INDEV,\r\nhtonl(br_port_get_rcu(indev)->br->dev->ifindex));\r\n} else {\r\nNLA_PUT_BE32(skb, NFQA_IFINDEX_INDEV,\r\nhtonl(indev->ifindex));\r\nif (entskb->nf_bridge && entskb->nf_bridge->physindev)\r\nNLA_PUT_BE32(skb, NFQA_IFINDEX_PHYSINDEV,\r\nhtonl(entskb->nf_bridge->physindev->ifindex));\r\n}\r\n#endif\r\n}\r\nif (outdev) {\r\n#ifndef CONFIG_BRIDGE_NETFILTER\r\nNLA_PUT_BE32(skb, NFQA_IFINDEX_OUTDEV, htonl(outdev->ifindex));\r\n#else\r\nif (entry->pf == PF_BRIDGE) {\r\nNLA_PUT_BE32(skb, NFQA_IFINDEX_PHYSOUTDEV,\r\nhtonl(outdev->ifindex));\r\nNLA_PUT_BE32(skb, NFQA_IFINDEX_OUTDEV,\r\nhtonl(br_port_get_rcu(outdev)->br->dev->ifindex));\r\n} else {\r\nNLA_PUT_BE32(skb, NFQA_IFINDEX_OUTDEV,\r\nhtonl(outdev->ifindex));\r\nif (entskb->nf_bridge && entskb->nf_bridge->physoutdev)\r\nNLA_PUT_BE32(skb, NFQA_IFINDEX_PHYSOUTDEV,\r\nhtonl(entskb->nf_bridge->physoutdev->ifindex));\r\n}\r\n#endif\r\n}\r\nif (entskb->mark)\r\nNLA_PUT_BE32(skb, NFQA_MARK, htonl(entskb->mark));\r\nif (indev && entskb->dev &&\r\nentskb->mac_header != entskb->network_header) {\r\nstruct nfqnl_msg_packet_hw phw;\r\nint len = dev_parse_header(entskb, phw.hw_addr);\r\nif (len) {\r\nphw.hw_addrlen = htons(len);\r\nNLA_PUT(skb, NFQA_HWADDR, sizeof(phw), &phw);\r\n}\r\n}\r\nif (entskb->tstamp.tv64) {\r\nstruct nfqnl_msg_packet_timestamp ts;\r\nstruct timeval tv = ktime_to_timeval(entskb->tstamp);\r\nts.sec = cpu_to_be64(tv.tv_sec);\r\nts.usec = cpu_to_be64(tv.tv_usec);\r\nNLA_PUT(skb, NFQA_TIMESTAMP, sizeof(ts), &ts);\r\n}\r\nif (data_len) {\r\nstruct nlattr *nla;\r\nint sz = nla_attr_size(data_len);\r\nif (skb_tailroom(skb) < nla_total_size(data_len)) {\r\nprintk(KERN_WARNING "nf_queue: no tailroom!\n");\r\ngoto nlmsg_failure;\r\n}\r\nnla = (struct nlattr *)skb_put(skb, nla_total_size(data_len));\r\nnla->nla_type = NFQA_PAYLOAD;\r\nnla->nla_len = sz;\r\nif (skb_copy_bits(entskb, 0, nla_data(nla), data_len))\r\nBUG();\r\n}\r\nnlh->nlmsg_len = skb->tail - old_tail;\r\nreturn skb;\r\nnlmsg_failure:\r\nnla_put_failure:\r\nif (skb)\r\nkfree_skb(skb);\r\nif (net_ratelimit())\r\nprintk(KERN_ERR "nf_queue: error creating packet message\n");\r\nreturn NULL;\r\n}\r\nstatic int\r\nnfqnl_enqueue_packet(struct nf_queue_entry *entry, unsigned int queuenum)\r\n{\r\nstruct sk_buff *nskb;\r\nstruct nfqnl_instance *queue;\r\nint err = -ENOBUFS;\r\n__be32 *packet_id_ptr;\r\nqueue = instance_lookup(queuenum);\r\nif (!queue) {\r\nerr = -ESRCH;\r\ngoto err_out;\r\n}\r\nif (queue->copy_mode == NFQNL_COPY_NONE) {\r\nerr = -EINVAL;\r\ngoto err_out;\r\n}\r\nnskb = nfqnl_build_packet_message(queue, entry, &packet_id_ptr);\r\nif (nskb == NULL) {\r\nerr = -ENOMEM;\r\ngoto err_out;\r\n}\r\nspin_lock_bh(&queue->lock);\r\nif (!queue->peer_pid) {\r\nerr = -EINVAL;\r\ngoto err_out_free_nskb;\r\n}\r\nif (queue->queue_total >= queue->queue_maxlen) {\r\nqueue->queue_dropped++;\r\nif (net_ratelimit())\r\nprintk(KERN_WARNING "nf_queue: full at %d entries, "\r\n"dropping packets(s).\n",\r\nqueue->queue_total);\r\ngoto err_out_free_nskb;\r\n}\r\nentry->id = ++queue->id_sequence;\r\n*packet_id_ptr = htonl(entry->id);\r\nerr = nfnetlink_unicast(nskb, &init_net, queue->peer_pid, MSG_DONTWAIT);\r\nif (err < 0) {\r\nqueue->queue_user_dropped++;\r\ngoto err_out_unlock;\r\n}\r\n__enqueue_entry(queue, entry);\r\nspin_unlock_bh(&queue->lock);\r\nreturn 0;\r\nerr_out_free_nskb:\r\nkfree_skb(nskb);\r\nerr_out_unlock:\r\nspin_unlock_bh(&queue->lock);\r\nerr_out:\r\nreturn err;\r\n}\r\nstatic int\r\nnfqnl_mangle(void *data, int data_len, struct nf_queue_entry *e)\r\n{\r\nstruct sk_buff *nskb;\r\nint diff;\r\ndiff = data_len - e->skb->len;\r\nif (diff < 0) {\r\nif (pskb_trim(e->skb, data_len))\r\nreturn -ENOMEM;\r\n} else if (diff > 0) {\r\nif (data_len > 0xFFFF)\r\nreturn -EINVAL;\r\nif (diff > skb_tailroom(e->skb)) {\r\nnskb = skb_copy_expand(e->skb, skb_headroom(e->skb),\r\ndiff, GFP_ATOMIC);\r\nif (!nskb) {\r\nprintk(KERN_WARNING "nf_queue: OOM "\r\n"in mangle, dropping packet\n");\r\nreturn -ENOMEM;\r\n}\r\nkfree_skb(e->skb);\r\ne->skb = nskb;\r\n}\r\nskb_put(e->skb, diff);\r\n}\r\nif (!skb_make_writable(e->skb, data_len))\r\nreturn -ENOMEM;\r\nskb_copy_to_linear_data(e->skb, data, data_len);\r\ne->skb->ip_summed = CHECKSUM_NONE;\r\nreturn 0;\r\n}\r\nstatic int\r\nnfqnl_set_mode(struct nfqnl_instance *queue,\r\nunsigned char mode, unsigned int range)\r\n{\r\nint status = 0;\r\nspin_lock_bh(&queue->lock);\r\nswitch (mode) {\r\ncase NFQNL_COPY_NONE:\r\ncase NFQNL_COPY_META:\r\nqueue->copy_mode = mode;\r\nqueue->copy_range = 0;\r\nbreak;\r\ncase NFQNL_COPY_PACKET:\r\nqueue->copy_mode = mode;\r\nif (range > 0xffff)\r\nqueue->copy_range = 0xffff;\r\nelse\r\nqueue->copy_range = range;\r\nbreak;\r\ndefault:\r\nstatus = -EINVAL;\r\n}\r\nspin_unlock_bh(&queue->lock);\r\nreturn status;\r\n}\r\nstatic int\r\ndev_cmp(struct nf_queue_entry *entry, unsigned long ifindex)\r\n{\r\nif (entry->indev)\r\nif (entry->indev->ifindex == ifindex)\r\nreturn 1;\r\nif (entry->outdev)\r\nif (entry->outdev->ifindex == ifindex)\r\nreturn 1;\r\n#ifdef CONFIG_BRIDGE_NETFILTER\r\nif (entry->skb->nf_bridge) {\r\nif (entry->skb->nf_bridge->physindev &&\r\nentry->skb->nf_bridge->physindev->ifindex == ifindex)\r\nreturn 1;\r\nif (entry->skb->nf_bridge->physoutdev &&\r\nentry->skb->nf_bridge->physoutdev->ifindex == ifindex)\r\nreturn 1;\r\n}\r\n#endif\r\nreturn 0;\r\n}\r\nstatic void\r\nnfqnl_dev_drop(int ifindex)\r\n{\r\nint i;\r\nrcu_read_lock();\r\nfor (i = 0; i < INSTANCE_BUCKETS; i++) {\r\nstruct hlist_node *tmp;\r\nstruct nfqnl_instance *inst;\r\nstruct hlist_head *head = &instance_table[i];\r\nhlist_for_each_entry_rcu(inst, tmp, head, hlist)\r\nnfqnl_flush(inst, dev_cmp, ifindex);\r\n}\r\nrcu_read_unlock();\r\n}\r\nstatic int\r\nnfqnl_rcv_dev_event(struct notifier_block *this,\r\nunsigned long event, void *ptr)\r\n{\r\nstruct net_device *dev = ptr;\r\nif (!net_eq(dev_net(dev), &init_net))\r\nreturn NOTIFY_DONE;\r\nif (event == NETDEV_DOWN)\r\nnfqnl_dev_drop(dev->ifindex);\r\nreturn NOTIFY_DONE;\r\n}\r\nstatic int\r\nnfqnl_rcv_nl_event(struct notifier_block *this,\r\nunsigned long event, void *ptr)\r\n{\r\nstruct netlink_notify *n = ptr;\r\nif (event == NETLINK_URELEASE && n->protocol == NETLINK_NETFILTER) {\r\nint i;\r\nspin_lock(&instances_lock);\r\nfor (i = 0; i < INSTANCE_BUCKETS; i++) {\r\nstruct hlist_node *tmp, *t2;\r\nstruct nfqnl_instance *inst;\r\nstruct hlist_head *head = &instance_table[i];\r\nhlist_for_each_entry_safe(inst, tmp, t2, head, hlist) {\r\nif ((n->net == &init_net) &&\r\n(n->pid == inst->peer_pid))\r\n__instance_destroy(inst);\r\n}\r\n}\r\nspin_unlock(&instances_lock);\r\n}\r\nreturn NOTIFY_DONE;\r\n}\r\nstatic struct nfqnl_instance *verdict_instance_lookup(u16 queue_num, int nlpid)\r\n{\r\nstruct nfqnl_instance *queue;\r\nqueue = instance_lookup(queue_num);\r\nif (!queue)\r\nreturn ERR_PTR(-ENODEV);\r\nif (queue->peer_pid != nlpid)\r\nreturn ERR_PTR(-EPERM);\r\nreturn queue;\r\n}\r\nstatic struct nfqnl_msg_verdict_hdr*\r\nverdicthdr_get(const struct nlattr * const nfqa[])\r\n{\r\nstruct nfqnl_msg_verdict_hdr *vhdr;\r\nunsigned int verdict;\r\nif (!nfqa[NFQA_VERDICT_HDR])\r\nreturn NULL;\r\nvhdr = nla_data(nfqa[NFQA_VERDICT_HDR]);\r\nverdict = ntohl(vhdr->verdict) & NF_VERDICT_MASK;\r\nif (verdict > NF_MAX_VERDICT || verdict == NF_STOLEN)\r\nreturn NULL;\r\nreturn vhdr;\r\n}\r\nstatic int nfq_id_after(unsigned int id, unsigned int max)\r\n{\r\nreturn (int)(id - max) > 0;\r\n}\r\nstatic int\r\nnfqnl_recv_verdict_batch(struct sock *ctnl, struct sk_buff *skb,\r\nconst struct nlmsghdr *nlh,\r\nconst struct nlattr * const nfqa[])\r\n{\r\nstruct nfgenmsg *nfmsg = NLMSG_DATA(nlh);\r\nstruct nf_queue_entry *entry, *tmp;\r\nunsigned int verdict, maxid;\r\nstruct nfqnl_msg_verdict_hdr *vhdr;\r\nstruct nfqnl_instance *queue;\r\nLIST_HEAD(batch_list);\r\nu16 queue_num = ntohs(nfmsg->res_id);\r\nqueue = verdict_instance_lookup(queue_num, NETLINK_CB(skb).pid);\r\nif (IS_ERR(queue))\r\nreturn PTR_ERR(queue);\r\nvhdr = verdicthdr_get(nfqa);\r\nif (!vhdr)\r\nreturn -EINVAL;\r\nverdict = ntohl(vhdr->verdict);\r\nmaxid = ntohl(vhdr->id);\r\nspin_lock_bh(&queue->lock);\r\nlist_for_each_entry_safe(entry, tmp, &queue->queue_list, list) {\r\nif (nfq_id_after(entry->id, maxid))\r\nbreak;\r\n__dequeue_entry(queue, entry);\r\nlist_add_tail(&entry->list, &batch_list);\r\n}\r\nspin_unlock_bh(&queue->lock);\r\nif (list_empty(&batch_list))\r\nreturn -ENOENT;\r\nlist_for_each_entry_safe(entry, tmp, &batch_list, list) {\r\nif (nfqa[NFQA_MARK])\r\nentry->skb->mark = ntohl(nla_get_be32(nfqa[NFQA_MARK]));\r\nnf_reinject(entry, verdict);\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\nnfqnl_recv_verdict(struct sock *ctnl, struct sk_buff *skb,\r\nconst struct nlmsghdr *nlh,\r\nconst struct nlattr * const nfqa[])\r\n{\r\nstruct nfgenmsg *nfmsg = NLMSG_DATA(nlh);\r\nu_int16_t queue_num = ntohs(nfmsg->res_id);\r\nstruct nfqnl_msg_verdict_hdr *vhdr;\r\nstruct nfqnl_instance *queue;\r\nunsigned int verdict;\r\nstruct nf_queue_entry *entry;\r\nqueue = instance_lookup(queue_num);\r\nif (!queue)\r\nqueue = verdict_instance_lookup(queue_num, NETLINK_CB(skb).pid);\r\nif (IS_ERR(queue))\r\nreturn PTR_ERR(queue);\r\nvhdr = verdicthdr_get(nfqa);\r\nif (!vhdr)\r\nreturn -EINVAL;\r\nverdict = ntohl(vhdr->verdict);\r\nentry = find_dequeue_entry(queue, ntohl(vhdr->id));\r\nif (entry == NULL)\r\nreturn -ENOENT;\r\nif (nfqa[NFQA_PAYLOAD]) {\r\nif (nfqnl_mangle(nla_data(nfqa[NFQA_PAYLOAD]),\r\nnla_len(nfqa[NFQA_PAYLOAD]), entry) < 0)\r\nverdict = NF_DROP;\r\n}\r\nif (nfqa[NFQA_MARK])\r\nentry->skb->mark = ntohl(nla_get_be32(nfqa[NFQA_MARK]));\r\nnf_reinject(entry, verdict);\r\nreturn 0;\r\n}\r\nstatic int\r\nnfqnl_recv_unsupp(struct sock *ctnl, struct sk_buff *skb,\r\nconst struct nlmsghdr *nlh,\r\nconst struct nlattr * const nfqa[])\r\n{\r\nreturn -ENOTSUPP;\r\n}\r\nstatic int\r\nnfqnl_recv_config(struct sock *ctnl, struct sk_buff *skb,\r\nconst struct nlmsghdr *nlh,\r\nconst struct nlattr * const nfqa[])\r\n{\r\nstruct nfgenmsg *nfmsg = NLMSG_DATA(nlh);\r\nu_int16_t queue_num = ntohs(nfmsg->res_id);\r\nstruct nfqnl_instance *queue;\r\nstruct nfqnl_msg_config_cmd *cmd = NULL;\r\nint ret = 0;\r\nif (nfqa[NFQA_CFG_CMD]) {\r\ncmd = nla_data(nfqa[NFQA_CFG_CMD]);\r\nswitch (cmd->command) {\r\ncase NFQNL_CFG_CMD_PF_BIND:\r\nreturn nf_register_queue_handler(ntohs(cmd->pf),\r\n&nfqh);\r\ncase NFQNL_CFG_CMD_PF_UNBIND:\r\nreturn nf_unregister_queue_handler(ntohs(cmd->pf),\r\n&nfqh);\r\n}\r\n}\r\nrcu_read_lock();\r\nqueue = instance_lookup(queue_num);\r\nif (queue && queue->peer_pid != NETLINK_CB(skb).pid) {\r\nret = -EPERM;\r\ngoto err_out_unlock;\r\n}\r\nif (cmd != NULL) {\r\nswitch (cmd->command) {\r\ncase NFQNL_CFG_CMD_BIND:\r\nif (queue) {\r\nret = -EBUSY;\r\ngoto err_out_unlock;\r\n}\r\nqueue = instance_create(queue_num, NETLINK_CB(skb).pid);\r\nif (IS_ERR(queue)) {\r\nret = PTR_ERR(queue);\r\ngoto err_out_unlock;\r\n}\r\nbreak;\r\ncase NFQNL_CFG_CMD_UNBIND:\r\nif (!queue) {\r\nret = -ENODEV;\r\ngoto err_out_unlock;\r\n}\r\ninstance_destroy(queue);\r\nbreak;\r\ncase NFQNL_CFG_CMD_PF_BIND:\r\ncase NFQNL_CFG_CMD_PF_UNBIND:\r\nbreak;\r\ndefault:\r\nret = -ENOTSUPP;\r\nbreak;\r\n}\r\n}\r\nif (nfqa[NFQA_CFG_PARAMS]) {\r\nstruct nfqnl_msg_config_params *params;\r\nif (!queue) {\r\nret = -ENODEV;\r\ngoto err_out_unlock;\r\n}\r\nparams = nla_data(nfqa[NFQA_CFG_PARAMS]);\r\nnfqnl_set_mode(queue, params->copy_mode,\r\nntohl(params->copy_range));\r\n}\r\nif (nfqa[NFQA_CFG_QUEUE_MAXLEN]) {\r\n__be32 *queue_maxlen;\r\nif (!queue) {\r\nret = -ENODEV;\r\ngoto err_out_unlock;\r\n}\r\nqueue_maxlen = nla_data(nfqa[NFQA_CFG_QUEUE_MAXLEN]);\r\nspin_lock_bh(&queue->lock);\r\nqueue->queue_maxlen = ntohl(*queue_maxlen);\r\nspin_unlock_bh(&queue->lock);\r\n}\r\nerr_out_unlock:\r\nrcu_read_unlock();\r\nreturn ret;\r\n}\r\nstatic struct hlist_node *get_first(struct seq_file *seq)\r\n{\r\nstruct iter_state *st = seq->private;\r\nif (!st)\r\nreturn NULL;\r\nfor (st->bucket = 0; st->bucket < INSTANCE_BUCKETS; st->bucket++) {\r\nif (!hlist_empty(&instance_table[st->bucket]))\r\nreturn instance_table[st->bucket].first;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct hlist_node *get_next(struct seq_file *seq, struct hlist_node *h)\r\n{\r\nstruct iter_state *st = seq->private;\r\nh = h->next;\r\nwhile (!h) {\r\nif (++st->bucket >= INSTANCE_BUCKETS)\r\nreturn NULL;\r\nh = instance_table[st->bucket].first;\r\n}\r\nreturn h;\r\n}\r\nstatic struct hlist_node *get_idx(struct seq_file *seq, loff_t pos)\r\n{\r\nstruct hlist_node *head;\r\nhead = get_first(seq);\r\nif (head)\r\nwhile (pos && (head = get_next(seq, head)))\r\npos--;\r\nreturn pos ? NULL : head;\r\n}\r\nstatic void *seq_start(struct seq_file *seq, loff_t *pos)\r\n__acquires(instances_lock)\r\n{\r\nspin_lock(&instances_lock);\r\nreturn get_idx(seq, *pos);\r\n}\r\nstatic void *seq_next(struct seq_file *s, void *v, loff_t *pos)\r\n{\r\n(*pos)++;\r\nreturn get_next(s, v);\r\n}\r\nstatic void seq_stop(struct seq_file *s, void *v)\r\n__releases(instances_lock)\r\n{\r\nspin_unlock(&instances_lock);\r\n}\r\nstatic int seq_show(struct seq_file *s, void *v)\r\n{\r\nconst struct nfqnl_instance *inst = v;\r\nreturn seq_printf(s, "%5d %6d %5d %1d %5d %5d %5d %8d %2d\n",\r\ninst->queue_num,\r\ninst->peer_pid, inst->queue_total,\r\ninst->copy_mode, inst->copy_range,\r\ninst->queue_dropped, inst->queue_user_dropped,\r\ninst->id_sequence, 1);\r\n}\r\nstatic int nfqnl_open(struct inode *inode, struct file *file)\r\n{\r\nreturn seq_open_private(file, &nfqnl_seq_ops,\r\nsizeof(struct iter_state));\r\n}\r\nstatic int __init nfnetlink_queue_init(void)\r\n{\r\nint i, status = -ENOMEM;\r\nfor (i = 0; i < INSTANCE_BUCKETS; i++)\r\nINIT_HLIST_HEAD(&instance_table[i]);\r\nnetlink_register_notifier(&nfqnl_rtnl_notifier);\r\nstatus = nfnetlink_subsys_register(&nfqnl_subsys);\r\nif (status < 0) {\r\nprintk(KERN_ERR "nf_queue: failed to create netlink socket\n");\r\ngoto cleanup_netlink_notifier;\r\n}\r\n#ifdef CONFIG_PROC_FS\r\nif (!proc_create("nfnetlink_queue", 0440,\r\nproc_net_netfilter, &nfqnl_file_ops))\r\ngoto cleanup_subsys;\r\n#endif\r\nregister_netdevice_notifier(&nfqnl_dev_notifier);\r\nreturn status;\r\n#ifdef CONFIG_PROC_FS\r\ncleanup_subsys:\r\nnfnetlink_subsys_unregister(&nfqnl_subsys);\r\n#endif\r\ncleanup_netlink_notifier:\r\nnetlink_unregister_notifier(&nfqnl_rtnl_notifier);\r\nreturn status;\r\n}\r\nstatic void __exit nfnetlink_queue_fini(void)\r\n{\r\nnf_unregister_queue_handlers(&nfqh);\r\nunregister_netdevice_notifier(&nfqnl_dev_notifier);\r\n#ifdef CONFIG_PROC_FS\r\nremove_proc_entry("nfnetlink_queue", proc_net_netfilter);\r\n#endif\r\nnfnetlink_subsys_unregister(&nfqnl_subsys);\r\nnetlink_unregister_notifier(&nfqnl_rtnl_notifier);\r\nrcu_barrier();\r\n}
