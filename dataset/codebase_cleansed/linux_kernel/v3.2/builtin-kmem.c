static void init_cpunode_map(void)\r\n{\r\nFILE *fp;\r\nint i;\r\nfp = fopen("/sys/devices/system/cpu/kernel_max", "r");\r\nif (!fp) {\r\nmax_cpu_num = 4096;\r\nreturn;\r\n}\r\nif (fscanf(fp, "%d", &max_cpu_num) < 1)\r\ndie("Failed to read 'kernel_max' from sysfs");\r\nmax_cpu_num++;\r\ncpunode_map = calloc(max_cpu_num, sizeof(int));\r\nif (!cpunode_map)\r\ndie("calloc");\r\nfor (i = 0; i < max_cpu_num; i++)\r\ncpunode_map[i] = -1;\r\nfclose(fp);\r\n}\r\nstatic void setup_cpunode_map(void)\r\n{\r\nstruct dirent *dent1, *dent2;\r\nDIR *dir1, *dir2;\r\nunsigned int cpu, mem;\r\nchar buf[PATH_MAX];\r\ninit_cpunode_map();\r\ndir1 = opendir(PATH_SYS_NODE);\r\nif (!dir1)\r\nreturn;\r\nwhile ((dent1 = readdir(dir1)) != NULL) {\r\nif (dent1->d_type != DT_DIR ||\r\nsscanf(dent1->d_name, "node%u", &mem) < 1)\r\ncontinue;\r\nsnprintf(buf, PATH_MAX, "%s/%s", PATH_SYS_NODE, dent1->d_name);\r\ndir2 = opendir(buf);\r\nif (!dir2)\r\ncontinue;\r\nwhile ((dent2 = readdir(dir2)) != NULL) {\r\nif (dent2->d_type != DT_LNK ||\r\nsscanf(dent2->d_name, "cpu%u", &cpu) < 1)\r\ncontinue;\r\ncpunode_map[cpu] = mem;\r\n}\r\n}\r\n}\r\nstatic void insert_alloc_stat(unsigned long call_site, unsigned long ptr,\r\nint bytes_req, int bytes_alloc, int cpu)\r\n{\r\nstruct rb_node **node = &root_alloc_stat.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct alloc_stat *data = NULL;\r\nwhile (*node) {\r\nparent = *node;\r\ndata = rb_entry(*node, struct alloc_stat, node);\r\nif (ptr > data->ptr)\r\nnode = &(*node)->rb_right;\r\nelse if (ptr < data->ptr)\r\nnode = &(*node)->rb_left;\r\nelse\r\nbreak;\r\n}\r\nif (data && data->ptr == ptr) {\r\ndata->hit++;\r\ndata->bytes_req += bytes_req;\r\ndata->bytes_alloc += bytes_alloc;\r\n} else {\r\ndata = malloc(sizeof(*data));\r\nif (!data)\r\ndie("malloc");\r\ndata->ptr = ptr;\r\ndata->pingpong = 0;\r\ndata->hit = 1;\r\ndata->bytes_req = bytes_req;\r\ndata->bytes_alloc = bytes_alloc;\r\nrb_link_node(&data->node, parent, node);\r\nrb_insert_color(&data->node, &root_alloc_stat);\r\n}\r\ndata->call_site = call_site;\r\ndata->alloc_cpu = cpu;\r\n}\r\nstatic void insert_caller_stat(unsigned long call_site,\r\nint bytes_req, int bytes_alloc)\r\n{\r\nstruct rb_node **node = &root_caller_stat.rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct alloc_stat *data = NULL;\r\nwhile (*node) {\r\nparent = *node;\r\ndata = rb_entry(*node, struct alloc_stat, node);\r\nif (call_site > data->call_site)\r\nnode = &(*node)->rb_right;\r\nelse if (call_site < data->call_site)\r\nnode = &(*node)->rb_left;\r\nelse\r\nbreak;\r\n}\r\nif (data && data->call_site == call_site) {\r\ndata->hit++;\r\ndata->bytes_req += bytes_req;\r\ndata->bytes_alloc += bytes_alloc;\r\n} else {\r\ndata = malloc(sizeof(*data));\r\nif (!data)\r\ndie("malloc");\r\ndata->call_site = call_site;\r\ndata->pingpong = 0;\r\ndata->hit = 1;\r\ndata->bytes_req = bytes_req;\r\ndata->bytes_alloc = bytes_alloc;\r\nrb_link_node(&data->node, parent, node);\r\nrb_insert_color(&data->node, &root_caller_stat);\r\n}\r\n}\r\nstatic void process_alloc_event(void *data,\r\nstruct event *event,\r\nint cpu,\r\nu64 timestamp __used,\r\nstruct thread *thread __used,\r\nint node)\r\n{\r\nunsigned long call_site;\r\nunsigned long ptr;\r\nint bytes_req;\r\nint bytes_alloc;\r\nint node1, node2;\r\nptr = raw_field_value(event, "ptr", data);\r\ncall_site = raw_field_value(event, "call_site", data);\r\nbytes_req = raw_field_value(event, "bytes_req", data);\r\nbytes_alloc = raw_field_value(event, "bytes_alloc", data);\r\ninsert_alloc_stat(call_site, ptr, bytes_req, bytes_alloc, cpu);\r\ninsert_caller_stat(call_site, bytes_req, bytes_alloc);\r\ntotal_requested += bytes_req;\r\ntotal_allocated += bytes_alloc;\r\nif (node) {\r\nnode1 = cpunode_map[cpu];\r\nnode2 = raw_field_value(event, "node", data);\r\nif (node1 != node2)\r\nnr_cross_allocs++;\r\n}\r\nnr_allocs++;\r\n}\r\nstatic struct alloc_stat *search_alloc_stat(unsigned long ptr,\r\nunsigned long call_site,\r\nstruct rb_root *root,\r\nsort_fn_t sort_fn)\r\n{\r\nstruct rb_node *node = root->rb_node;\r\nstruct alloc_stat key = { .ptr = ptr, .call_site = call_site };\r\nwhile (node) {\r\nstruct alloc_stat *data;\r\nint cmp;\r\ndata = rb_entry(node, struct alloc_stat, node);\r\ncmp = sort_fn(&key, data);\r\nif (cmp < 0)\r\nnode = node->rb_left;\r\nelse if (cmp > 0)\r\nnode = node->rb_right;\r\nelse\r\nreturn data;\r\n}\r\nreturn NULL;\r\n}\r\nstatic void process_free_event(void *data,\r\nstruct event *event,\r\nint cpu,\r\nu64 timestamp __used,\r\nstruct thread *thread __used)\r\n{\r\nunsigned long ptr;\r\nstruct alloc_stat *s_alloc, *s_caller;\r\nptr = raw_field_value(event, "ptr", data);\r\ns_alloc = search_alloc_stat(ptr, 0, &root_alloc_stat, ptr_cmp);\r\nif (!s_alloc)\r\nreturn;\r\nif (cpu != s_alloc->alloc_cpu) {\r\ns_alloc->pingpong++;\r\ns_caller = search_alloc_stat(0, s_alloc->call_site,\r\n&root_caller_stat, callsite_cmp);\r\nassert(s_caller);\r\ns_caller->pingpong++;\r\n}\r\ns_alloc->alloc_cpu = -1;\r\n}\r\nstatic void process_raw_event(union perf_event *raw_event __used, void *data,\r\nint cpu, u64 timestamp, struct thread *thread)\r\n{\r\nstruct event *event;\r\nint type;\r\ntype = trace_parse_common_type(data);\r\nevent = trace_find_event(type);\r\nif (!strcmp(event->name, "kmalloc") ||\r\n!strcmp(event->name, "kmem_cache_alloc")) {\r\nprocess_alloc_event(data, event, cpu, timestamp, thread, 0);\r\nreturn;\r\n}\r\nif (!strcmp(event->name, "kmalloc_node") ||\r\n!strcmp(event->name, "kmem_cache_alloc_node")) {\r\nprocess_alloc_event(data, event, cpu, timestamp, thread, 1);\r\nreturn;\r\n}\r\nif (!strcmp(event->name, "kfree") ||\r\n!strcmp(event->name, "kmem_cache_free")) {\r\nprocess_free_event(data, event, cpu, timestamp, thread);\r\nreturn;\r\n}\r\n}\r\nstatic int process_sample_event(union perf_event *event,\r\nstruct perf_sample *sample,\r\nstruct perf_evsel *evsel __used,\r\nstruct perf_session *session)\r\n{\r\nstruct thread *thread = perf_session__findnew(session, event->ip.pid);\r\nif (thread == NULL) {\r\npr_debug("problem processing %d event, skipping it.\n",\r\nevent->header.type);\r\nreturn -1;\r\n}\r\ndump_printf(" ... thread: %s:%d\n", thread->comm, thread->pid);\r\nprocess_raw_event(event, sample->raw_data, sample->cpu,\r\nsample->time, thread);\r\nreturn 0;\r\n}\r\nstatic double fragmentation(unsigned long n_req, unsigned long n_alloc)\r\n{\r\nif (n_alloc == 0)\r\nreturn 0.0;\r\nelse\r\nreturn 100.0 - (100.0 * n_req / n_alloc);\r\n}\r\nstatic void __print_result(struct rb_root *root, struct perf_session *session,\r\nint n_lines, int is_caller)\r\n{\r\nstruct rb_node *next;\r\nstruct machine *machine;\r\nprintf("%.102s\n", graph_dotted_line);\r\nprintf(" %-34s |", is_caller ? "Callsite": "Alloc Ptr");\r\nprintf(" Total_alloc/Per | Total_req/Per | Hit | Ping-pong | Frag\n");\r\nprintf("%.102s\n", graph_dotted_line);\r\nnext = rb_first(root);\r\nmachine = perf_session__find_host_machine(session);\r\nif (!machine) {\r\npr_err("__print_result: couldn't find kernel information\n");\r\nreturn;\r\n}\r\nwhile (next && n_lines--) {\r\nstruct alloc_stat *data = rb_entry(next, struct alloc_stat,\r\nnode);\r\nstruct symbol *sym = NULL;\r\nstruct map *map;\r\nchar buf[BUFSIZ];\r\nu64 addr;\r\nif (is_caller) {\r\naddr = data->call_site;\r\nif (!raw_ip)\r\nsym = machine__find_kernel_function(machine, addr, &map, NULL);\r\n} else\r\naddr = data->ptr;\r\nif (sym != NULL)\r\nsnprintf(buf, sizeof(buf), "%s+%" PRIx64 "", sym->name,\r\naddr - map->unmap_ip(map, sym->start));\r\nelse\r\nsnprintf(buf, sizeof(buf), "%#" PRIx64 "", addr);\r\nprintf(" %-34s |", buf);\r\nprintf(" %9llu/%-5lu | %9llu/%-5lu | %8lu | %8lu | %6.3f%%\n",\r\n(unsigned long long)data->bytes_alloc,\r\n(unsigned long)data->bytes_alloc / data->hit,\r\n(unsigned long long)data->bytes_req,\r\n(unsigned long)data->bytes_req / data->hit,\r\n(unsigned long)data->hit,\r\n(unsigned long)data->pingpong,\r\nfragmentation(data->bytes_req, data->bytes_alloc));\r\nnext = rb_next(next);\r\n}\r\nif (n_lines == -1)\r\nprintf(" ... | ... | ... | ... | ... | ... \n");\r\nprintf("%.102s\n", graph_dotted_line);\r\n}\r\nstatic void print_summary(void)\r\n{\r\nprintf("\nSUMMARY\n=======\n");\r\nprintf("Total bytes requested: %lu\n", total_requested);\r\nprintf("Total bytes allocated: %lu\n", total_allocated);\r\nprintf("Total bytes wasted on internal fragmentation: %lu\n",\r\ntotal_allocated - total_requested);\r\nprintf("Internal fragmentation: %f%%\n",\r\nfragmentation(total_requested, total_allocated));\r\nprintf("Cross CPU allocations: %lu/%lu\n", nr_cross_allocs, nr_allocs);\r\n}\r\nstatic void print_result(struct perf_session *session)\r\n{\r\nif (caller_flag)\r\n__print_result(&root_caller_sorted, session, caller_lines, 1);\r\nif (alloc_flag)\r\n__print_result(&root_alloc_sorted, session, alloc_lines, 0);\r\nprint_summary();\r\n}\r\nstatic void sort_insert(struct rb_root *root, struct alloc_stat *data,\r\nstruct list_head *sort_list)\r\n{\r\nstruct rb_node **new = &(root->rb_node);\r\nstruct rb_node *parent = NULL;\r\nstruct sort_dimension *sort;\r\nwhile (*new) {\r\nstruct alloc_stat *this;\r\nint cmp = 0;\r\nthis = rb_entry(*new, struct alloc_stat, node);\r\nparent = *new;\r\nlist_for_each_entry(sort, sort_list, list) {\r\ncmp = sort->cmp(data, this);\r\nif (cmp)\r\nbreak;\r\n}\r\nif (cmp > 0)\r\nnew = &((*new)->rb_left);\r\nelse\r\nnew = &((*new)->rb_right);\r\n}\r\nrb_link_node(&data->node, parent, new);\r\nrb_insert_color(&data->node, root);\r\n}\r\nstatic void __sort_result(struct rb_root *root, struct rb_root *root_sorted,\r\nstruct list_head *sort_list)\r\n{\r\nstruct rb_node *node;\r\nstruct alloc_stat *data;\r\nfor (;;) {\r\nnode = rb_first(root);\r\nif (!node)\r\nbreak;\r\nrb_erase(node, root);\r\ndata = rb_entry(node, struct alloc_stat, node);\r\nsort_insert(root_sorted, data, sort_list);\r\n}\r\n}\r\nstatic void sort_result(void)\r\n{\r\n__sort_result(&root_alloc_stat, &root_alloc_sorted, &alloc_sort);\r\n__sort_result(&root_caller_stat, &root_caller_sorted, &caller_sort);\r\n}\r\nstatic int __cmd_kmem(void)\r\n{\r\nint err = -EINVAL;\r\nstruct perf_session *session = perf_session__new(input_name, O_RDONLY,\r\n0, false, &event_ops);\r\nif (session == NULL)\r\nreturn -ENOMEM;\r\nif (perf_session__create_kernel_maps(session) < 0)\r\ngoto out_delete;\r\nif (!perf_session__has_traces(session, "kmem record"))\r\ngoto out_delete;\r\nsetup_pager();\r\nerr = perf_session__process_events(session, &event_ops);\r\nif (err != 0)\r\ngoto out_delete;\r\nsort_result();\r\nprint_result(session);\r\nout_delete:\r\nperf_session__delete(session);\r\nreturn err;\r\n}\r\nstatic int ptr_cmp(struct alloc_stat *l, struct alloc_stat *r)\r\n{\r\nif (l->ptr < r->ptr)\r\nreturn -1;\r\nelse if (l->ptr > r->ptr)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int callsite_cmp(struct alloc_stat *l, struct alloc_stat *r)\r\n{\r\nif (l->call_site < r->call_site)\r\nreturn -1;\r\nelse if (l->call_site > r->call_site)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int hit_cmp(struct alloc_stat *l, struct alloc_stat *r)\r\n{\r\nif (l->hit < r->hit)\r\nreturn -1;\r\nelse if (l->hit > r->hit)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int bytes_cmp(struct alloc_stat *l, struct alloc_stat *r)\r\n{\r\nif (l->bytes_alloc < r->bytes_alloc)\r\nreturn -1;\r\nelse if (l->bytes_alloc > r->bytes_alloc)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int frag_cmp(struct alloc_stat *l, struct alloc_stat *r)\r\n{\r\ndouble x, y;\r\nx = fragmentation(l->bytes_req, l->bytes_alloc);\r\ny = fragmentation(r->bytes_req, r->bytes_alloc);\r\nif (x < y)\r\nreturn -1;\r\nelse if (x > y)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int pingpong_cmp(struct alloc_stat *l, struct alloc_stat *r)\r\n{\r\nif (l->pingpong < r->pingpong)\r\nreturn -1;\r\nelse if (l->pingpong > r->pingpong)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int sort_dimension__add(const char *tok, struct list_head *list)\r\n{\r\nstruct sort_dimension *sort;\r\nint i;\r\nfor (i = 0; i < NUM_AVAIL_SORTS; i++) {\r\nif (!strcmp(avail_sorts[i]->name, tok)) {\r\nsort = malloc(sizeof(*sort));\r\nif (!sort)\r\ndie("malloc");\r\nmemcpy(sort, avail_sorts[i], sizeof(*sort));\r\nlist_add_tail(&sort->list, list);\r\nreturn 0;\r\n}\r\n}\r\nreturn -1;\r\n}\r\nstatic int setup_sorting(struct list_head *sort_list, const char *arg)\r\n{\r\nchar *tok;\r\nchar *str = strdup(arg);\r\nif (!str)\r\ndie("strdup");\r\nwhile (true) {\r\ntok = strsep(&str, ",");\r\nif (!tok)\r\nbreak;\r\nif (sort_dimension__add(tok, sort_list) < 0) {\r\nerror("Unknown --sort key: '%s'", tok);\r\nreturn -1;\r\n}\r\n}\r\nfree(str);\r\nreturn 0;\r\n}\r\nstatic int parse_sort_opt(const struct option *opt __used,\r\nconst char *arg, int unset __used)\r\n{\r\nif (!arg)\r\nreturn -1;\r\nif (caller_flag > alloc_flag)\r\nreturn setup_sorting(&caller_sort, arg);\r\nelse\r\nreturn setup_sorting(&alloc_sort, arg);\r\nreturn 0;\r\n}\r\nstatic int parse_caller_opt(const struct option *opt __used,\r\nconst char *arg __used, int unset __used)\r\n{\r\ncaller_flag = (alloc_flag + 1);\r\nreturn 0;\r\n}\r\nstatic int parse_alloc_opt(const struct option *opt __used,\r\nconst char *arg __used, int unset __used)\r\n{\r\nalloc_flag = (caller_flag + 1);\r\nreturn 0;\r\n}\r\nstatic int parse_line_opt(const struct option *opt __used,\r\nconst char *arg, int unset __used)\r\n{\r\nint lines;\r\nif (!arg)\r\nreturn -1;\r\nlines = strtoul(arg, NULL, 10);\r\nif (caller_flag > alloc_flag)\r\ncaller_lines = lines;\r\nelse\r\nalloc_lines = lines;\r\nreturn 0;\r\n}\r\nstatic int __cmd_record(int argc, const char **argv)\r\n{\r\nunsigned int rec_argc, i, j;\r\nconst char **rec_argv;\r\nrec_argc = ARRAY_SIZE(record_args) + argc - 1;\r\nrec_argv = calloc(rec_argc + 1, sizeof(char *));\r\nif (rec_argv == NULL)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < ARRAY_SIZE(record_args); i++)\r\nrec_argv[i] = strdup(record_args[i]);\r\nfor (j = 1; j < (unsigned int)argc; j++, i++)\r\nrec_argv[i] = argv[j];\r\nreturn cmd_record(i, rec_argv, NULL);\r\n}\r\nint cmd_kmem(int argc, const char **argv, const char *prefix __used)\r\n{\r\nargc = parse_options(argc, argv, kmem_options, kmem_usage, 0);\r\nif (!argc)\r\nusage_with_options(kmem_usage, kmem_options);\r\nsymbol__init();\r\nif (!strncmp(argv[0], "rec", 3)) {\r\nreturn __cmd_record(argc, argv);\r\n} else if (!strcmp(argv[0], "stat")) {\r\nsetup_cpunode_map();\r\nif (list_empty(&caller_sort))\r\nsetup_sorting(&caller_sort, default_sort_order);\r\nif (list_empty(&alloc_sort))\r\nsetup_sorting(&alloc_sort, default_sort_order);\r\nreturn __cmd_kmem();\r\n} else\r\nusage_with_options(kmem_usage, kmem_options);\r\nreturn 0;\r\n}
