static inline void file_free_rcu(struct rcu_head *head)\r\n{\r\nstruct file *f = container_of(head, struct file, f_u.fu_rcuhead);\r\nput_cred(f->f_cred);\r\nkmem_cache_free(filp_cachep, f);\r\n}\r\nstatic inline void file_free(struct file *f)\r\n{\r\npercpu_counter_dec(&nr_files);\r\nfile_check_state(f);\r\ncall_rcu(&f->f_u.fu_rcuhead, file_free_rcu);\r\n}\r\nstatic long get_nr_files(void)\r\n{\r\nreturn percpu_counter_read_positive(&nr_files);\r\n}\r\nunsigned long get_max_files(void)\r\n{\r\nreturn files_stat.max_files;\r\n}\r\nint proc_nr_files(ctl_table *table, int write,\r\nvoid __user *buffer, size_t *lenp, loff_t *ppos)\r\n{\r\nfiles_stat.nr_files = get_nr_files();\r\nreturn proc_doulongvec_minmax(table, write, buffer, lenp, ppos);\r\n}\r\nint proc_nr_files(ctl_table *table, int write,\r\nvoid __user *buffer, size_t *lenp, loff_t *ppos)\r\n{\r\nreturn -ENOSYS;\r\n}\r\nstruct file *get_empty_filp(void)\r\n{\r\nconst struct cred *cred = current_cred();\r\nstatic long old_max;\r\nstruct file * f;\r\nif (get_nr_files() >= files_stat.max_files && !capable(CAP_SYS_ADMIN)) {\r\nif (percpu_counter_sum_positive(&nr_files) >= files_stat.max_files)\r\ngoto over;\r\n}\r\nf = kmem_cache_zalloc(filp_cachep, GFP_KERNEL);\r\nif (f == NULL)\r\ngoto fail;\r\npercpu_counter_inc(&nr_files);\r\nf->f_cred = get_cred(cred);\r\nif (security_file_alloc(f))\r\ngoto fail_sec;\r\nINIT_LIST_HEAD(&f->f_u.fu_list);\r\natomic_long_set(&f->f_count, 1);\r\nrwlock_init(&f->f_owner.lock);\r\nspin_lock_init(&f->f_lock);\r\neventpoll_init_file(f);\r\nreturn f;\r\nover:\r\nif (get_nr_files() > old_max) {\r\npr_info("VFS: file-max limit %lu reached\n", get_max_files());\r\nold_max = get_nr_files();\r\n}\r\ngoto fail;\r\nfail_sec:\r\nfile_free(f);\r\nfail:\r\nreturn NULL;\r\n}\r\nstruct file *alloc_file(struct path *path, fmode_t mode,\r\nconst struct file_operations *fop)\r\n{\r\nstruct file *file;\r\nfile = get_empty_filp();\r\nif (!file)\r\nreturn NULL;\r\nfile->f_path = *path;\r\nfile->f_mapping = path->dentry->d_inode->i_mapping;\r\nfile->f_mode = mode;\r\nfile->f_op = fop;\r\nif ((mode & FMODE_WRITE) && !special_file(path->dentry->d_inode->i_mode)) {\r\nfile_take_write(file);\r\nWARN_ON(mnt_clone_write(path->mnt));\r\n}\r\nif ((mode & (FMODE_READ | FMODE_WRITE)) == FMODE_READ)\r\ni_readcount_inc(path->dentry->d_inode);\r\nreturn file;\r\n}\r\nvoid drop_file_write_access(struct file *file)\r\n{\r\nstruct vfsmount *mnt = file->f_path.mnt;\r\nstruct dentry *dentry = file->f_path.dentry;\r\nstruct inode *inode = dentry->d_inode;\r\nput_write_access(inode);\r\nif (special_file(inode->i_mode))\r\nreturn;\r\nif (file_check_writeable(file) != 0)\r\nreturn;\r\nmnt_drop_write(mnt);\r\nfile_release_write(file);\r\n}\r\nstatic void __fput(struct file *file)\r\n{\r\nstruct dentry *dentry = file->f_path.dentry;\r\nstruct vfsmount *mnt = file->f_path.mnt;\r\nstruct inode *inode = dentry->d_inode;\r\nmight_sleep();\r\nfsnotify_close(file);\r\neventpoll_release(file);\r\nlocks_remove_flock(file);\r\nif (unlikely(file->f_flags & FASYNC)) {\r\nif (file->f_op && file->f_op->fasync)\r\nfile->f_op->fasync(-1, file, 0);\r\n}\r\nif (file->f_op && file->f_op->release)\r\nfile->f_op->release(inode, file);\r\nsecurity_file_free(file);\r\nima_file_free(file);\r\nif (unlikely(S_ISCHR(inode->i_mode) && inode->i_cdev != NULL &&\r\n!(file->f_mode & FMODE_PATH))) {\r\ncdev_put(inode->i_cdev);\r\n}\r\nfops_put(file->f_op);\r\nput_pid(file->f_owner.pid);\r\nfile_sb_list_del(file);\r\nif ((file->f_mode & (FMODE_READ | FMODE_WRITE)) == FMODE_READ)\r\ni_readcount_dec(inode);\r\nif (file->f_mode & FMODE_WRITE)\r\ndrop_file_write_access(file);\r\nfile->f_path.dentry = NULL;\r\nfile->f_path.mnt = NULL;\r\nfile_free(file);\r\ndput(dentry);\r\nmntput(mnt);\r\n}\r\nvoid fput(struct file *file)\r\n{\r\nif (atomic_long_dec_and_test(&file->f_count))\r\n__fput(file);\r\n}\r\nstruct file *fget(unsigned int fd)\r\n{\r\nstruct file *file;\r\nstruct files_struct *files = current->files;\r\nrcu_read_lock();\r\nfile = fcheck_files(files, fd);\r\nif (file) {\r\nif (file->f_mode & FMODE_PATH ||\r\n!atomic_long_inc_not_zero(&file->f_count))\r\nfile = NULL;\r\n}\r\nrcu_read_unlock();\r\nreturn file;\r\n}\r\nstruct file *fget_raw(unsigned int fd)\r\n{\r\nstruct file *file;\r\nstruct files_struct *files = current->files;\r\nrcu_read_lock();\r\nfile = fcheck_files(files, fd);\r\nif (file) {\r\nif (!atomic_long_inc_not_zero(&file->f_count))\r\nfile = NULL;\r\n}\r\nrcu_read_unlock();\r\nreturn file;\r\n}\r\nstruct file *fget_light(unsigned int fd, int *fput_needed)\r\n{\r\nstruct file *file;\r\nstruct files_struct *files = current->files;\r\n*fput_needed = 0;\r\nif (atomic_read(&files->count) == 1) {\r\nfile = fcheck_files(files, fd);\r\nif (file && (file->f_mode & FMODE_PATH))\r\nfile = NULL;\r\n} else {\r\nrcu_read_lock();\r\nfile = fcheck_files(files, fd);\r\nif (file) {\r\nif (!(file->f_mode & FMODE_PATH) &&\r\natomic_long_inc_not_zero(&file->f_count))\r\n*fput_needed = 1;\r\nelse\r\nfile = NULL;\r\n}\r\nrcu_read_unlock();\r\n}\r\nreturn file;\r\n}\r\nstruct file *fget_raw_light(unsigned int fd, int *fput_needed)\r\n{\r\nstruct file *file;\r\nstruct files_struct *files = current->files;\r\n*fput_needed = 0;\r\nif (atomic_read(&files->count) == 1) {\r\nfile = fcheck_files(files, fd);\r\n} else {\r\nrcu_read_lock();\r\nfile = fcheck_files(files, fd);\r\nif (file) {\r\nif (atomic_long_inc_not_zero(&file->f_count))\r\n*fput_needed = 1;\r\nelse\r\nfile = NULL;\r\n}\r\nrcu_read_unlock();\r\n}\r\nreturn file;\r\n}\r\nvoid put_filp(struct file *file)\r\n{\r\nif (atomic_long_dec_and_test(&file->f_count)) {\r\nsecurity_file_free(file);\r\nfile_sb_list_del(file);\r\nfile_free(file);\r\n}\r\n}\r\nstatic inline int file_list_cpu(struct file *file)\r\n{\r\n#ifdef CONFIG_SMP\r\nreturn file->f_sb_list_cpu;\r\n#else\r\nreturn smp_processor_id();\r\n#endif\r\n}\r\nstatic inline void __file_sb_list_add(struct file *file, struct super_block *sb)\r\n{\r\nstruct list_head *list;\r\n#ifdef CONFIG_SMP\r\nint cpu;\r\ncpu = smp_processor_id();\r\nfile->f_sb_list_cpu = cpu;\r\nlist = per_cpu_ptr(sb->s_files, cpu);\r\n#else\r\nlist = &sb->s_files;\r\n#endif\r\nlist_add(&file->f_u.fu_list, list);\r\n}\r\nvoid file_sb_list_add(struct file *file, struct super_block *sb)\r\n{\r\nlg_local_lock(files_lglock);\r\n__file_sb_list_add(file, sb);\r\nlg_local_unlock(files_lglock);\r\n}\r\nvoid file_sb_list_del(struct file *file)\r\n{\r\nif (!list_empty(&file->f_u.fu_list)) {\r\nlg_local_lock_cpu(files_lglock, file_list_cpu(file));\r\nlist_del_init(&file->f_u.fu_list);\r\nlg_local_unlock_cpu(files_lglock, file_list_cpu(file));\r\n}\r\n}\r\nint fs_may_remount_ro(struct super_block *sb)\r\n{\r\nstruct file *file;\r\nlg_global_lock(files_lglock);\r\ndo_file_list_for_each_entry(sb, file) {\r\nstruct inode *inode = file->f_path.dentry->d_inode;\r\nif (inode->i_nlink == 0)\r\ngoto too_bad;\r\nif (S_ISREG(inode->i_mode) && (file->f_mode & FMODE_WRITE))\r\ngoto too_bad;\r\n} while_file_list_for_each_entry;\r\nlg_global_unlock(files_lglock);\r\nreturn 1;\r\ntoo_bad:\r\nlg_global_unlock(files_lglock);\r\nreturn 0;\r\n}\r\nvoid mark_files_ro(struct super_block *sb)\r\n{\r\nstruct file *f;\r\nretry:\r\nlg_global_lock(files_lglock);\r\ndo_file_list_for_each_entry(sb, f) {\r\nstruct vfsmount *mnt;\r\nif (!S_ISREG(f->f_path.dentry->d_inode->i_mode))\r\ncontinue;\r\nif (!file_count(f))\r\ncontinue;\r\nif (!(f->f_mode & FMODE_WRITE))\r\ncontinue;\r\nspin_lock(&f->f_lock);\r\nf->f_mode &= ~FMODE_WRITE;\r\nspin_unlock(&f->f_lock);\r\nif (file_check_writeable(f) != 0)\r\ncontinue;\r\nfile_release_write(f);\r\nmnt = mntget(f->f_path.mnt);\r\nlg_global_unlock(files_lglock);\r\nmnt_drop_write(mnt);\r\nmntput(mnt);\r\ngoto retry;\r\n} while_file_list_for_each_entry;\r\nlg_global_unlock(files_lglock);\r\n}\r\nvoid __init files_init(unsigned long mempages)\r\n{\r\nunsigned long n;\r\nfilp_cachep = kmem_cache_create("filp", sizeof(struct file), 0,\r\nSLAB_HWCACHE_ALIGN | SLAB_PANIC, NULL);\r\nn = (mempages * (PAGE_SIZE / 1024)) / 10;\r\nfiles_stat.max_files = max_t(unsigned long, n, NR_FILE);\r\nfiles_defer_init();\r\nlg_lock_init(files_lglock);\r\npercpu_counter_init(&nr_files, 0);\r\n}
