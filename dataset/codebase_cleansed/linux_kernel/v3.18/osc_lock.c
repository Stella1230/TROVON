int osc_lock_is_lockless(const struct osc_lock *olck)\r\n{\r\nreturn (olck->ols_cl.cls_ops == &osc_lock_lockless_ops);\r\n}\r\nstatic struct ldlm_lock *osc_handle_ptr(struct lustre_handle *handle)\r\n{\r\nstruct ldlm_lock *lock;\r\nlock = ldlm_handle2lock(handle);\r\nif (lock != NULL)\r\nLDLM_LOCK_PUT(lock);\r\nreturn lock;\r\n}\r\nstatic int osc_lock_invariant(struct osc_lock *ols)\r\n{\r\nstruct ldlm_lock *lock = osc_handle_ptr(&ols->ols_handle);\r\nstruct ldlm_lock *olock = ols->ols_lock;\r\nint handle_used = lustre_handle_is_used(&ols->ols_handle);\r\nif (ergo(osc_lock_is_lockless(ols),\r\nols->ols_locklessable && ols->ols_lock == NULL))\r\nreturn 1;\r\nif (! ergo(olock != NULL, handle_used))\r\nreturn 0;\r\nif (! ergo(olock != NULL,\r\nolock->l_handle.h_cookie == ols->ols_handle.cookie))\r\nreturn 0;\r\nif (! ergo(handle_used,\r\nergo(lock != NULL && olock != NULL, lock == olock) &&\r\nergo(lock == NULL, olock == NULL)))\r\nreturn 0;\r\nif (! ergo(ols->ols_state == OLS_CANCELLED,\r\nolock == NULL && !handle_used))\r\nreturn 0;\r\nif (! ergo(olock != NULL && ols->ols_state < OLS_CANCELLED,\r\n((olock->l_flags & LDLM_FL_DESTROYED) == 0)))\r\nreturn 0;\r\nif (! ergo(ols->ols_state == OLS_GRANTED,\r\nolock != NULL &&\r\nolock->l_req_mode == olock->l_granted_mode &&\r\nols->ols_hold))\r\nreturn 0;\r\nreturn 1;\r\n}\r\nstatic void osc_lock_detach(const struct lu_env *env, struct osc_lock *olck)\r\n{\r\nstruct ldlm_lock *dlmlock;\r\nspin_lock(&osc_ast_guard);\r\ndlmlock = olck->ols_lock;\r\nif (dlmlock == NULL) {\r\nspin_unlock(&osc_ast_guard);\r\nreturn;\r\n}\r\nolck->ols_lock = NULL;\r\ndlmlock->l_ast_data = NULL;\r\nolck->ols_handle.cookie = 0ULL;\r\nspin_unlock(&osc_ast_guard);\r\nlock_res_and_lock(dlmlock);\r\nif (dlmlock->l_granted_mode == dlmlock->l_req_mode) {\r\nstruct cl_object *obj = olck->ols_cl.cls_obj;\r\nstruct cl_attr *attr = &osc_env_info(env)->oti_attr;\r\n__u64 old_kms;\r\ncl_object_attr_lock(obj);\r\nold_kms = cl2osc(obj)->oo_oinfo->loi_kms;\r\nattr->cat_kms = ldlm_extent_shift_kms(dlmlock, old_kms);\r\ncl_object_attr_set(env, obj, attr, CAT_KMS);\r\ncl_object_attr_unlock(obj);\r\n}\r\nunlock_res_and_lock(dlmlock);\r\nLASSERT(olck->ols_has_ref);\r\nlu_ref_del(&dlmlock->l_reference, "osc_lock", olck);\r\nLDLM_LOCK_RELEASE(dlmlock);\r\nolck->ols_has_ref = 0;\r\n}\r\nstatic int osc_lock_unhold(struct osc_lock *ols)\r\n{\r\nint result = 0;\r\nif (ols->ols_hold) {\r\nols->ols_hold = 0;\r\nresult = osc_cancel_base(&ols->ols_handle,\r\nols->ols_einfo.ei_mode);\r\n}\r\nreturn result;\r\n}\r\nstatic int osc_lock_unuse(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice)\r\n{\r\nstruct osc_lock *ols = cl2osc_lock(slice);\r\nLINVRNT(osc_lock_invariant(ols));\r\nswitch (ols->ols_state) {\r\ncase OLS_NEW:\r\nLASSERT(!ols->ols_hold);\r\nLASSERT(ols->ols_agl);\r\nreturn 0;\r\ncase OLS_UPCALL_RECEIVED:\r\nosc_lock_unhold(ols);\r\ncase OLS_ENQUEUED:\r\nLASSERT(!ols->ols_hold);\r\nosc_lock_detach(env, ols);\r\nols->ols_state = OLS_NEW;\r\nreturn 0;\r\ncase OLS_GRANTED:\r\nLASSERT(!ols->ols_glimpse);\r\nLASSERT(ols->ols_hold);\r\nols->ols_state = OLS_RELEASED;\r\nreturn osc_lock_unhold(ols);\r\ndefault:\r\nCERROR("Impossible state: %d\n", ols->ols_state);\r\nLBUG();\r\n}\r\n}\r\nstatic void osc_lock_fini(const struct lu_env *env,\r\nstruct cl_lock_slice *slice)\r\n{\r\nstruct osc_lock *ols = cl2osc_lock(slice);\r\nLINVRNT(osc_lock_invariant(ols));\r\nosc_lock_unhold(ols);\r\nLASSERT(ols->ols_lock == NULL);\r\nLASSERT(atomic_read(&ols->ols_pageref) == 0 ||\r\natomic_read(&ols->ols_pageref) == _PAGEREF_MAGIC);\r\nOBD_SLAB_FREE_PTR(ols, osc_lock_kmem);\r\n}\r\nstatic void osc_lock_build_policy(const struct lu_env *env,\r\nconst struct cl_lock *lock,\r\nldlm_policy_data_t *policy)\r\n{\r\nconst struct cl_lock_descr *d = &lock->cll_descr;\r\nosc_index2policy(policy, d->cld_obj, d->cld_start, d->cld_end);\r\npolicy->l_extent.gid = d->cld_gid;\r\n}\r\nstatic __u64 osc_enq2ldlm_flags(__u32 enqflags)\r\n{\r\n__u64 result = 0;\r\nLASSERT((enqflags & ~CEF_MASK) == 0);\r\nif (enqflags & CEF_NONBLOCK)\r\nresult |= LDLM_FL_BLOCK_NOWAIT;\r\nif (enqflags & CEF_ASYNC)\r\nresult |= LDLM_FL_HAS_INTENT;\r\nif (enqflags & CEF_DISCARD_DATA)\r\nresult |= LDLM_FL_AST_DISCARD_DATA;\r\nreturn result;\r\n}\r\nstatic struct osc_lock *osc_ast_data_get(struct ldlm_lock *dlm_lock)\r\n{\r\nstruct osc_lock *olck;\r\nlock_res_and_lock(dlm_lock);\r\nspin_lock(&osc_ast_guard);\r\nolck = dlm_lock->l_ast_data;\r\nif (olck != NULL) {\r\nstruct cl_lock *lock = olck->ols_cl.cls_lock;\r\nif (lock->cll_state < CLS_FREEING || olck->ols_has_ref) {\r\ncl_lock_get_trust(lock);\r\nlu_ref_add_atomic(&lock->cll_reference,\r\n"ast", current);\r\n} else\r\nolck = NULL;\r\n}\r\nspin_unlock(&osc_ast_guard);\r\nunlock_res_and_lock(dlm_lock);\r\nreturn olck;\r\n}\r\nstatic void osc_ast_data_put(const struct lu_env *env, struct osc_lock *olck)\r\n{\r\nstruct cl_lock *lock;\r\nlock = olck->ols_cl.cls_lock;\r\nlu_ref_del(&lock->cll_reference, "ast", current);\r\ncl_lock_put(env, lock);\r\n}\r\nstatic void osc_lock_lvb_update(const struct lu_env *env, struct osc_lock *olck,\r\nint rc)\r\n{\r\nstruct ost_lvb *lvb;\r\nstruct cl_object *obj;\r\nstruct lov_oinfo *oinfo;\r\nstruct cl_attr *attr;\r\nunsigned valid;\r\nif (!(olck->ols_flags & LDLM_FL_LVB_READY))\r\nreturn;\r\nlvb = &olck->ols_lvb;\r\nobj = olck->ols_cl.cls_obj;\r\noinfo = cl2osc(obj)->oo_oinfo;\r\nattr = &osc_env_info(env)->oti_attr;\r\nvalid = CAT_BLOCKS | CAT_ATIME | CAT_CTIME | CAT_MTIME | CAT_SIZE;\r\ncl_lvb2attr(attr, lvb);\r\ncl_object_attr_lock(obj);\r\nif (rc == 0) {\r\nstruct ldlm_lock *dlmlock;\r\n__u64 size;\r\ndlmlock = olck->ols_lock;\r\nLASSERT(dlmlock != NULL);\r\n*lvb = *(struct ost_lvb *)dlmlock->l_lvb_data;\r\nsize = lvb->lvb_size;\r\nif (size > dlmlock->l_policy_data.l_extent.end)\r\nsize = dlmlock->l_policy_data.l_extent.end + 1;\r\nif (size >= oinfo->loi_kms) {\r\nLDLM_DEBUG(dlmlock, "lock acquired, setting rss=%llu, kms=%llu",\r\nlvb->lvb_size, size);\r\nvalid |= CAT_KMS;\r\nattr->cat_kms = size;\r\n} else {\r\nLDLM_DEBUG(dlmlock, "lock acquired, setting rss=%llu; leaving kms=%llu, end=%llu",\r\nlvb->lvb_size, oinfo->loi_kms,\r\ndlmlock->l_policy_data.l_extent.end);\r\n}\r\nldlm_lock_allow_match_locked(dlmlock);\r\n} else if (rc == -ENAVAIL && olck->ols_glimpse) {\r\nCDEBUG(D_INODE, "glimpsed, setting rss=%llu; leaving kms=%llu\n",\r\nlvb->lvb_size, oinfo->loi_kms);\r\n} else\r\nvalid = 0;\r\nif (valid != 0)\r\ncl_object_attr_set(env, obj, attr, valid);\r\ncl_object_attr_unlock(obj);\r\n}\r\nstatic void osc_lock_granted(const struct lu_env *env, struct osc_lock *olck,\r\nstruct ldlm_lock *dlmlock, int rc)\r\n{\r\nstruct ldlm_extent *ext;\r\nstruct cl_lock *lock;\r\nstruct cl_lock_descr *descr;\r\nLASSERT(dlmlock->l_granted_mode == dlmlock->l_req_mode);\r\nif (olck->ols_state < OLS_GRANTED) {\r\nlock = olck->ols_cl.cls_lock;\r\next = &dlmlock->l_policy_data.l_extent;\r\ndescr = &osc_env_info(env)->oti_descr;\r\ndescr->cld_obj = lock->cll_descr.cld_obj;\r\ndescr->cld_mode = osc_ldlm2cl_lock(dlmlock->l_granted_mode);\r\ndescr->cld_start = cl_index(descr->cld_obj, ext->start);\r\ndescr->cld_end = cl_index(descr->cld_obj, ext->end);\r\ndescr->cld_gid = ext->gid;\r\nolck->ols_state = OLS_GRANTED;\r\nosc_lock_lvb_update(env, olck, rc);\r\nunlock_res_and_lock(dlmlock);\r\ncl_lock_modify(env, lock, descr);\r\ncl_lock_signal(env, lock);\r\nLINVRNT(osc_lock_invariant(olck));\r\nlock_res_and_lock(dlmlock);\r\n}\r\n}\r\nstatic void osc_lock_upcall0(const struct lu_env *env, struct osc_lock *olck)\r\n{\r\nstruct ldlm_lock *dlmlock;\r\ndlmlock = ldlm_handle2lock_long(&olck->ols_handle, 0);\r\nLASSERT(dlmlock != NULL);\r\nlock_res_and_lock(dlmlock);\r\nspin_lock(&osc_ast_guard);\r\nLASSERT(dlmlock->l_ast_data == olck);\r\nLASSERT(olck->ols_lock == NULL);\r\nolck->ols_lock = dlmlock;\r\nspin_unlock(&osc_ast_guard);\r\nif (dlmlock->l_granted_mode == dlmlock->l_req_mode)\r\nosc_lock_granted(env, olck, dlmlock, 0);\r\nunlock_res_and_lock(dlmlock);\r\nldlm_lock_addref(&olck->ols_handle, olck->ols_einfo.ei_mode);\r\nolck->ols_hold = 1;\r\nlu_ref_add(&dlmlock->l_reference, "osc_lock", olck);\r\nolck->ols_has_ref = 1;\r\n}\r\nstatic int osc_lock_upcall(void *cookie, int errcode)\r\n{\r\nstruct osc_lock *olck = cookie;\r\nstruct cl_lock_slice *slice = &olck->ols_cl;\r\nstruct cl_lock *lock = slice->cls_lock;\r\nstruct lu_env *env;\r\nstruct cl_env_nest nest;\r\nenv = cl_env_nested_get(&nest);\r\nif (!IS_ERR(env)) {\r\nint rc;\r\ncl_lock_mutex_get(env, lock);\r\nLASSERT(lock->cll_state >= CLS_QUEUING);\r\nif (olck->ols_state == OLS_ENQUEUED) {\r\nolck->ols_state = OLS_UPCALL_RECEIVED;\r\nrc = ldlm_error2errno(errcode);\r\n} else if (olck->ols_state == OLS_CANCELLED) {\r\nrc = -EIO;\r\n} else {\r\nCERROR("Impossible state: %d\n", olck->ols_state);\r\nLBUG();\r\n}\r\nif (rc) {\r\nstruct ldlm_lock *dlmlock;\r\ndlmlock = ldlm_handle2lock(&olck->ols_handle);\r\nif (dlmlock != NULL) {\r\nlock_res_and_lock(dlmlock);\r\nspin_lock(&osc_ast_guard);\r\nLASSERT(olck->ols_lock == NULL);\r\ndlmlock->l_ast_data = NULL;\r\nolck->ols_handle.cookie = 0ULL;\r\nspin_unlock(&osc_ast_guard);\r\nldlm_lock_fail_match_locked(dlmlock);\r\nunlock_res_and_lock(dlmlock);\r\nLDLM_LOCK_PUT(dlmlock);\r\n}\r\n} else {\r\nif (olck->ols_glimpse)\r\nolck->ols_glimpse = 0;\r\nosc_lock_upcall0(env, olck);\r\n}\r\nif (olck->ols_locklessable && rc == -EUSERS) {\r\nosc_object_set_contended(cl2osc(slice->cls_obj));\r\nLASSERT(slice->cls_ops == &osc_lock_ops);\r\nosc_lock_to_lockless(env, olck, 1);\r\nolck->ols_state = OLS_GRANTED;\r\nrc = 0;\r\n} else if (olck->ols_glimpse && rc == -ENAVAIL) {\r\nosc_lock_lvb_update(env, olck, rc);\r\ncl_lock_delete(env, lock);\r\nrc = 0;\r\n}\r\nif (rc == 0) {\r\nif (olck->ols_agl) {\r\nlock->cll_flags |= CLF_FROM_UPCALL;\r\ncl_wait_try(env, lock);\r\nlock->cll_flags &= ~CLF_FROM_UPCALL;\r\nif (!olck->ols_glimpse)\r\nolck->ols_agl = 0;\r\n}\r\ncl_lock_signal(env, lock);\r\ncl_unuse_try(env, lock);\r\n} else {\r\ncl_lock_user_del(env, lock);\r\ncl_lock_error(env, lock, rc);\r\n}\r\ncl_lock_hold_release(env, lock, "upcall", lock);\r\ncl_lock_mutex_put(env, lock);\r\nlu_ref_del(&lock->cll_reference, "upcall", lock);\r\ncl_lock_put(env, lock);\r\ncl_env_nested_put(&nest, env);\r\n} else {\r\nLBUG();\r\n}\r\nreturn errcode;\r\n}\r\nstatic void osc_lock_blocking(const struct lu_env *env,\r\nstruct ldlm_lock *dlmlock,\r\nstruct osc_lock *olck, int blocking)\r\n{\r\nstruct cl_lock *lock = olck->ols_cl.cls_lock;\r\nLASSERT(olck->ols_lock == dlmlock);\r\nCLASSERT(OLS_BLOCKED < OLS_CANCELLED);\r\nLASSERT(!osc_lock_is_lockless(olck));\r\nosc_lock_unhold(olck);\r\nif (blocking && olck->ols_state < OLS_BLOCKED)\r\nolck->ols_state = OLS_BLOCKED;\r\ncl_lock_cancel(env, lock);\r\ncl_lock_delete(env, lock);\r\n}\r\nstatic int osc_dlm_blocking_ast0(const struct lu_env *env,\r\nstruct ldlm_lock *dlmlock,\r\nvoid *data, int flag)\r\n{\r\nstruct osc_lock *olck;\r\nstruct cl_lock *lock;\r\nint result;\r\nint cancel;\r\nLASSERT(flag == LDLM_CB_BLOCKING || flag == LDLM_CB_CANCELING);\r\ncancel = 0;\r\nolck = osc_ast_data_get(dlmlock);\r\nif (olck != NULL) {\r\nlock = olck->ols_cl.cls_lock;\r\ncl_lock_mutex_get(env, lock);\r\nLINVRNT(osc_lock_invariant(olck));\r\nif (olck->ols_ast_wait) {\r\ncl_lock_signal(env, lock);\r\nolck->ols_ast_wait = 0;\r\n}\r\nif (olck == dlmlock->l_ast_data) {\r\nLASSERT(data == olck);\r\nosc_lock_blocking(env, dlmlock,\r\nolck, flag == LDLM_CB_BLOCKING);\r\n} else\r\ncancel = 1;\r\ncl_lock_mutex_put(env, lock);\r\nosc_ast_data_put(env, olck);\r\n} else\r\ncancel = (flag == LDLM_CB_BLOCKING);\r\nif (cancel) {\r\nstruct lustre_handle *lockh;\r\nlockh = &osc_env_info(env)->oti_handle;\r\nldlm_lock2handle(dlmlock, lockh);\r\nresult = ldlm_cli_cancel(lockh, LCF_ASYNC);\r\n} else\r\nresult = 0;\r\nreturn result;\r\n}\r\nstatic int osc_ldlm_blocking_ast(struct ldlm_lock *dlmlock,\r\nstruct ldlm_lock_desc *new, void *data,\r\nint flag)\r\n{\r\nstruct lu_env *env;\r\nstruct cl_env_nest nest;\r\nint result;\r\nenv = cl_env_nested_get(&nest);\r\nif (!IS_ERR(env)) {\r\nresult = osc_dlm_blocking_ast0(env, dlmlock, data, flag);\r\ncl_env_nested_put(&nest, env);\r\n} else {\r\nresult = PTR_ERR(env);\r\nLBUG();\r\n}\r\nif (result != 0) {\r\nif (result == -ENODATA)\r\nresult = 0;\r\nelse\r\nCERROR("BAST failed: %d\n", result);\r\n}\r\nreturn result;\r\n}\r\nstatic int osc_ldlm_completion_ast(struct ldlm_lock *dlmlock,\r\n__u64 flags, void *data)\r\n{\r\nstruct cl_env_nest nest;\r\nstruct lu_env *env;\r\nstruct osc_lock *olck;\r\nstruct cl_lock *lock;\r\nint result;\r\nint dlmrc;\r\ndlmrc = ldlm_completion_ast_async(dlmlock, flags, data);\r\nenv = cl_env_nested_get(&nest);\r\nif (!IS_ERR(env)) {\r\nolck = osc_ast_data_get(dlmlock);\r\nif (olck != NULL) {\r\nlock = olck->ols_cl.cls_lock;\r\ncl_lock_mutex_get(env, lock);\r\nLASSERT(dlmlock->l_lvb_data != NULL);\r\nlock_res_and_lock(dlmlock);\r\nolck->ols_lvb = *(struct ost_lvb *)dlmlock->l_lvb_data;\r\nif (olck->ols_lock == NULL) {\r\n} else if (dlmlock->l_granted_mode ==\r\ndlmlock->l_req_mode) {\r\nosc_lock_granted(env, olck, dlmlock, dlmrc);\r\n}\r\nunlock_res_and_lock(dlmlock);\r\nif (dlmrc != 0) {\r\nCL_LOCK_DEBUG(D_ERROR, env, lock,\r\n"dlmlock returned %d\n", dlmrc);\r\ncl_lock_error(env, lock, dlmrc);\r\n}\r\ncl_lock_mutex_put(env, lock);\r\nosc_ast_data_put(env, olck);\r\nresult = 0;\r\n} else\r\nresult = -ELDLM_NO_LOCK_DATA;\r\ncl_env_nested_put(&nest, env);\r\n} else\r\nresult = PTR_ERR(env);\r\nreturn dlmrc ?: result;\r\n}\r\nstatic int osc_ldlm_glimpse_ast(struct ldlm_lock *dlmlock, void *data)\r\n{\r\nstruct ptlrpc_request *req = data;\r\nstruct osc_lock *olck;\r\nstruct cl_lock *lock;\r\nstruct cl_object *obj;\r\nstruct cl_env_nest nest;\r\nstruct lu_env *env;\r\nstruct ost_lvb *lvb;\r\nstruct req_capsule *cap;\r\nint result;\r\nLASSERT(lustre_msg_get_opc(req->rq_reqmsg) == LDLM_GL_CALLBACK);\r\nenv = cl_env_nested_get(&nest);\r\nif (!IS_ERR(env)) {\r\nolck = osc_ast_data_get(dlmlock);\r\nif (olck != NULL) {\r\nlock = olck->ols_cl.cls_lock;\r\ncap = &req->rq_pill;\r\nreq_capsule_extend(cap, &RQF_LDLM_GL_CALLBACK);\r\nreq_capsule_set_size(cap, &RMF_DLM_LVB, RCL_SERVER,\r\nsizeof(*lvb));\r\nresult = req_capsule_server_pack(cap);\r\nif (result == 0) {\r\nlvb = req_capsule_server_get(cap, &RMF_DLM_LVB);\r\nobj = lock->cll_descr.cld_obj;\r\nresult = cl_object_glimpse(env, obj, lvb);\r\n}\r\nif (!exp_connect_lvb_type(req->rq_export))\r\nreq_capsule_shrink(&req->rq_pill,\r\n&RMF_DLM_LVB,\r\nsizeof(struct ost_lvb_v1),\r\nRCL_SERVER);\r\nosc_ast_data_put(env, olck);\r\n} else {\r\nlustre_pack_reply(req, 1, NULL, NULL);\r\nresult = -ELDLM_NO_LOCK_DATA;\r\n}\r\ncl_env_nested_put(&nest, env);\r\n} else\r\nresult = PTR_ERR(env);\r\nreq->rq_status = result;\r\nreturn result;\r\n}\r\nstatic unsigned long osc_lock_weigh(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice)\r\n{\r\nreturn cl_object_header(slice->cls_obj)->coh_pages;\r\n}\r\nstatic void osc_lock_build_einfo(const struct lu_env *env,\r\nconst struct cl_lock *clock,\r\nstruct osc_lock *lock,\r\nstruct ldlm_enqueue_info *einfo)\r\n{\r\nenum cl_lock_mode mode;\r\nmode = clock->cll_descr.cld_mode;\r\nif (mode == CLM_PHANTOM)\r\nmode = CLM_READ;\r\neinfo->ei_type = LDLM_EXTENT;\r\neinfo->ei_mode = osc_cl_lock2ldlm(mode);\r\neinfo->ei_cb_bl = osc_ldlm_blocking_ast;\r\neinfo->ei_cb_cp = osc_ldlm_completion_ast;\r\neinfo->ei_cb_gl = osc_ldlm_glimpse_ast;\r\neinfo->ei_cbdata = lock;\r\n}\r\nstatic void osc_lock_to_lockless(const struct lu_env *env,\r\nstruct osc_lock *ols, int force)\r\n{\r\nstruct cl_lock_slice *slice = &ols->ols_cl;\r\nLASSERT(ols->ols_state == OLS_NEW ||\r\nols->ols_state == OLS_UPCALL_RECEIVED);\r\nif (force) {\r\nols->ols_locklessable = 1;\r\nslice->cls_ops = &osc_lock_lockless_ops;\r\n} else {\r\nstruct osc_io *oio = osc_env_io(env);\r\nstruct cl_io *io = oio->oi_cl.cis_io;\r\nstruct cl_object *obj = slice->cls_obj;\r\nstruct osc_object *oob = cl2osc(obj);\r\nconst struct osc_device *osd = lu2osc_dev(obj->co_lu.lo_dev);\r\nstruct obd_connect_data *ocd;\r\nLASSERT(io->ci_lockreq == CILR_MANDATORY ||\r\nio->ci_lockreq == CILR_MAYBE ||\r\nio->ci_lockreq == CILR_NEVER);\r\nocd = &class_exp2cliimp(osc_export(oob))->imp_connect_data;\r\nols->ols_locklessable = (io->ci_type != CIT_SETATTR) &&\r\n(io->ci_lockreq == CILR_MAYBE) &&\r\n(ocd->ocd_connect_flags & OBD_CONNECT_SRVLOCK);\r\nif (io->ci_lockreq == CILR_NEVER ||\r\n(ols->ols_locklessable && osc_object_is_contended(oob)) ||\r\n(cl_io_is_trunc(io) &&\r\n(ocd->ocd_connect_flags & OBD_CONNECT_TRUNCLOCK) &&\r\nosd->od_lockless_truncate)) {\r\nols->ols_locklessable = 1;\r\nslice->cls_ops = &osc_lock_lockless_ops;\r\n}\r\n}\r\nLASSERT(ergo(ols->ols_glimpse, !osc_lock_is_lockless(ols)));\r\n}\r\nstatic int osc_lock_compatible(const struct osc_lock *qing,\r\nconst struct osc_lock *qed)\r\n{\r\nenum cl_lock_mode qing_mode;\r\nenum cl_lock_mode qed_mode;\r\nqing_mode = qing->ols_cl.cls_lock->cll_descr.cld_mode;\r\nif (qed->ols_glimpse &&\r\n(qed->ols_state >= OLS_UPCALL_RECEIVED || qing_mode == CLM_READ))\r\nreturn 1;\r\nqed_mode = qed->ols_cl.cls_lock->cll_descr.cld_mode;\r\nreturn ((qing_mode == CLM_READ) && (qed_mode == CLM_READ));\r\n}\r\nstatic int osc_lock_enqueue_wait(const struct lu_env *env,\r\nconst struct osc_lock *olck)\r\n{\r\nstruct cl_lock *lock = olck->ols_cl.cls_lock;\r\nstruct cl_lock_descr *descr = &lock->cll_descr;\r\nstruct cl_object_header *hdr = cl_object_header(descr->cld_obj);\r\nstruct cl_lock *scan;\r\nstruct cl_lock *conflict= NULL;\r\nint lockless = osc_lock_is_lockless(olck);\r\nint rc = 0;\r\nLASSERT(cl_lock_is_mutexed(lock));\r\nif (olck->ols_glimpse)\r\nreturn 0;\r\nspin_lock(&hdr->coh_lock_guard);\r\nlist_for_each_entry(scan, &hdr->coh_locks, cll_linkage) {\r\nstruct cl_lock_descr *cld = &scan->cll_descr;\r\nconst struct osc_lock *scan_ols;\r\nif (scan == lock)\r\nbreak;\r\nif (scan->cll_state < CLS_QUEUING ||\r\nscan->cll_state == CLS_FREEING ||\r\ncld->cld_start > descr->cld_end ||\r\ncld->cld_end < descr->cld_start)\r\ncontinue;\r\nif (scan->cll_descr.cld_mode == CLM_GROUP) {\r\nLASSERT(descr->cld_mode != CLM_GROUP ||\r\ndescr->cld_gid != scan->cll_descr.cld_gid);\r\ncontinue;\r\n}\r\nscan_ols = osc_lock_at(scan);\r\nif (!lockless && osc_lock_compatible(olck, scan_ols))\r\ncontinue;\r\ncl_lock_get_trust(scan);\r\nconflict = scan;\r\nbreak;\r\n}\r\nspin_unlock(&hdr->coh_lock_guard);\r\nif (conflict) {\r\nif (lock->cll_descr.cld_mode == CLM_GROUP) {\r\nCDEBUG(D_DLMTRACE, "group lock %p is conflicted "\r\n"with %p, no wait, send to server\n",\r\nlock, conflict);\r\ncl_lock_put(env, conflict);\r\nrc = 0;\r\n} else {\r\nCDEBUG(D_DLMTRACE, "lock %p is conflicted with %p, "\r\n"will wait\n",\r\nlock, conflict);\r\nLASSERT(lock->cll_conflict == NULL);\r\nlu_ref_add(&conflict->cll_reference, "cancel-wait",\r\nlock);\r\nlock->cll_conflict = conflict;\r\nrc = CLO_WAIT;\r\n}\r\n}\r\nreturn rc;\r\n}\r\nstatic int osc_lock_enqueue(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice,\r\nstruct cl_io *unused, __u32 enqflags)\r\n{\r\nstruct osc_lock *ols = cl2osc_lock(slice);\r\nstruct cl_lock *lock = ols->ols_cl.cls_lock;\r\nint result;\r\nLASSERT(cl_lock_is_mutexed(lock));\r\nLASSERTF(ols->ols_state == OLS_NEW,\r\n"Impossible state: %d\n", ols->ols_state);\r\nLASSERTF(ergo(ols->ols_glimpse, lock->cll_descr.cld_mode <= CLM_READ),\r\n"lock = %p, ols = %p\n", lock, ols);\r\nresult = osc_lock_enqueue_wait(env, ols);\r\nif (result == 0) {\r\nif (!osc_lock_is_lockless(ols)) {\r\nstruct osc_object *obj = cl2osc(slice->cls_obj);\r\nstruct osc_thread_info *info = osc_env_info(env);\r\nstruct ldlm_res_id *resname = &info->oti_resname;\r\nldlm_policy_data_t *policy = &info->oti_policy;\r\nstruct ldlm_enqueue_info *einfo = &ols->ols_einfo;\r\ncl_lock_hold_add(env, lock, "upcall", lock);\r\ncl_lock_user_add(env, lock);\r\nols->ols_state = OLS_ENQUEUED;\r\nostid_build_res_name(&obj->oo_oinfo->loi_oi, resname);\r\nosc_lock_build_policy(env, lock, policy);\r\nresult = osc_enqueue_base(osc_export(obj), resname,\r\n&ols->ols_flags, policy,\r\n&ols->ols_lvb,\r\nobj->oo_oinfo->loi_kms_valid,\r\nosc_lock_upcall,\r\nols, einfo, &ols->ols_handle,\r\nPTLRPCD_SET, 1, ols->ols_agl);\r\nif (result != 0) {\r\ncl_lock_user_del(env, lock);\r\ncl_lock_unhold(env, lock, "upcall", lock);\r\nif (unlikely(result == -ECANCELED)) {\r\nols->ols_state = OLS_NEW;\r\nresult = 0;\r\n}\r\n}\r\n} else {\r\nols->ols_state = OLS_GRANTED;\r\nols->ols_owner = osc_env_io(env);\r\n}\r\n}\r\nLASSERT(ergo(ols->ols_glimpse, !osc_lock_is_lockless(ols)));\r\nreturn result;\r\n}\r\nstatic int osc_lock_wait(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice)\r\n{\r\nstruct osc_lock *olck = cl2osc_lock(slice);\r\nstruct cl_lock *lock = olck->ols_cl.cls_lock;\r\nLINVRNT(osc_lock_invariant(olck));\r\nif (olck->ols_glimpse && olck->ols_state >= OLS_UPCALL_RECEIVED) {\r\nif (olck->ols_flags & LDLM_FL_LVB_READY) {\r\nreturn 0;\r\n} else if (olck->ols_agl) {\r\nif (lock->cll_flags & CLF_FROM_UPCALL)\r\nreturn -ENAVAIL;\r\nelse\r\nolck->ols_state = OLS_NEW;\r\n} else {\r\nLASSERT(lock->cll_error);\r\nreturn lock->cll_error;\r\n}\r\n}\r\nif (olck->ols_state == OLS_NEW) {\r\nint rc;\r\nLASSERT(olck->ols_agl);\r\nolck->ols_agl = 0;\r\nolck->ols_flags &= ~LDLM_FL_BLOCK_NOWAIT;\r\nrc = osc_lock_enqueue(env, slice, NULL, CEF_ASYNC | CEF_MUST);\r\nif (rc != 0)\r\nreturn rc;\r\nelse\r\nreturn CLO_REENQUEUED;\r\n}\r\nLASSERT(equi(olck->ols_state >= OLS_UPCALL_RECEIVED &&\r\nlock->cll_error == 0, olck->ols_lock != NULL));\r\nreturn lock->cll_error ?: olck->ols_state >= OLS_GRANTED ? 0 : CLO_WAIT;\r\n}\r\nstatic int osc_lock_use(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice)\r\n{\r\nstruct osc_lock *olck = cl2osc_lock(slice);\r\nint rc;\r\nLASSERT(!olck->ols_hold);\r\nrc = ldlm_lock_addref_try(&olck->ols_handle, olck->ols_einfo.ei_mode);\r\nif (rc == 0) {\r\nolck->ols_hold = 1;\r\nolck->ols_state = OLS_GRANTED;\r\n} else {\r\nstruct cl_lock *lock;\r\nlock = slice->cls_lock;\r\nLASSERT(lock->cll_state == CLS_INTRANSIT);\r\nLASSERT(lock->cll_users > 0);\r\nolck->ols_ast_wait = 1;\r\nrc = CLO_WAIT;\r\n}\r\nreturn rc;\r\n}\r\nstatic int osc_lock_flush(struct osc_lock *ols, int discard)\r\n{\r\nstruct cl_lock *lock = ols->ols_cl.cls_lock;\r\nstruct cl_env_nest nest;\r\nstruct lu_env *env;\r\nint result = 0;\r\nenv = cl_env_nested_get(&nest);\r\nif (!IS_ERR(env)) {\r\nstruct osc_object *obj = cl2osc(ols->ols_cl.cls_obj);\r\nstruct cl_lock_descr *descr = &lock->cll_descr;\r\nint rc = 0;\r\nif (descr->cld_mode >= CLM_WRITE) {\r\nresult = osc_cache_writeback_range(env, obj,\r\ndescr->cld_start, descr->cld_end,\r\n1, discard);\r\nLDLM_DEBUG(ols->ols_lock,\r\n"lock %p: %d pages were %s.\n", lock, result,\r\ndiscard ? "discarded" : "written");\r\nif (result > 0)\r\nresult = 0;\r\n}\r\nrc = cl_lock_discard_pages(env, lock);\r\nif (result == 0 && rc < 0)\r\nresult = rc;\r\ncl_env_nested_put(&nest, env);\r\n} else\r\nresult = PTR_ERR(env);\r\nif (result == 0) {\r\nols->ols_flush = 1;\r\nLINVRNT(!osc_lock_has_pages(ols));\r\n}\r\nreturn result;\r\n}\r\nstatic void osc_lock_cancel(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice)\r\n{\r\nstruct cl_lock *lock = slice->cls_lock;\r\nstruct osc_lock *olck = cl2osc_lock(slice);\r\nstruct ldlm_lock *dlmlock = olck->ols_lock;\r\nint result = 0;\r\nint discard;\r\nLASSERT(cl_lock_is_mutexed(lock));\r\nLINVRNT(osc_lock_invariant(olck));\r\nif (dlmlock != NULL) {\r\nint do_cancel;\r\ndiscard = !!(dlmlock->l_flags & LDLM_FL_DISCARD_DATA);\r\nif (olck->ols_state >= OLS_GRANTED)\r\nresult = osc_lock_flush(olck, discard);\r\nosc_lock_unhold(olck);\r\nlock_res_and_lock(dlmlock);\r\ndo_cancel = (dlmlock->l_readers == 0 &&\r\ndlmlock->l_writers == 0);\r\ndlmlock->l_flags |= LDLM_FL_CBPENDING;\r\nunlock_res_and_lock(dlmlock);\r\nif (do_cancel)\r\nresult = ldlm_cli_cancel(&olck->ols_handle, LCF_ASYNC);\r\nif (result < 0)\r\nCL_LOCK_DEBUG(D_ERROR, env, lock,\r\n"lock %p cancel failure with error(%d)\n",\r\nlock, result);\r\n}\r\nolck->ols_state = OLS_CANCELLED;\r\nolck->ols_flags &= ~LDLM_FL_LVB_READY;\r\nosc_lock_detach(env, olck);\r\n}\r\nstatic int osc_lock_has_pages(struct osc_lock *olck)\r\n{\r\nreturn 0;\r\n}\r\nstatic void osc_lock_delete(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice)\r\n{\r\nstruct osc_lock *olck;\r\nolck = cl2osc_lock(slice);\r\nif (olck->ols_glimpse) {\r\nLASSERT(!olck->ols_hold);\r\nLASSERT(!olck->ols_lock);\r\nreturn;\r\n}\r\nLINVRNT(osc_lock_invariant(olck));\r\nLINVRNT(!osc_lock_has_pages(olck));\r\nosc_lock_unhold(olck);\r\nosc_lock_detach(env, olck);\r\n}\r\nstatic void osc_lock_state(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice,\r\nenum cl_lock_state state)\r\n{\r\nstruct osc_lock *lock = cl2osc_lock(slice);\r\nLINVRNT(osc_lock_invariant(lock));\r\nif (state == CLS_HELD && slice->cls_lock->cll_state != CLS_HELD) {\r\nstruct osc_io *oio = osc_env_io(env);\r\nLASSERT(lock->ols_owner == NULL);\r\nlock->ols_owner = oio;\r\n} else if (state != CLS_HELD)\r\nlock->ols_owner = NULL;\r\n}\r\nstatic int osc_lock_print(const struct lu_env *env, void *cookie,\r\nlu_printer_t p, const struct cl_lock_slice *slice)\r\n{\r\nstruct osc_lock *lock = cl2osc_lock(slice);\r\n(*p)(env, cookie, "%p %#16llx %#llx %d %p ",\r\nlock->ols_lock, lock->ols_flags, lock->ols_handle.cookie,\r\nlock->ols_state, lock->ols_owner);\r\nosc_lvb_print(env, cookie, p, &lock->ols_lvb);\r\nreturn 0;\r\n}\r\nstatic int osc_lock_fits_into(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice,\r\nconst struct cl_lock_descr *need,\r\nconst struct cl_io *io)\r\n{\r\nstruct osc_lock *ols = cl2osc_lock(slice);\r\nif (need->cld_enq_flags & CEF_NEVER)\r\nreturn 0;\r\nif (ols->ols_state >= OLS_CANCELLED)\r\nreturn 0;\r\nif (need->cld_mode == CLM_PHANTOM) {\r\nif (ols->ols_agl)\r\nreturn !(ols->ols_state > OLS_RELEASED);\r\nif (ols->ols_state < OLS_GRANTED ||\r\nols->ols_state > OLS_RELEASED)\r\nreturn 0;\r\n} else if (need->cld_enq_flags & CEF_MUST) {\r\nif (ols->ols_state < OLS_UPCALL_RECEIVED &&\r\nols->ols_locklessable)\r\nreturn 0;\r\n}\r\nreturn 1;\r\n}\r\nstatic int osc_lock_lockless_unuse(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice)\r\n{\r\nstruct osc_lock *ols = cl2osc_lock(slice);\r\nstruct cl_lock *lock = slice->cls_lock;\r\nLASSERT(ols->ols_state == OLS_GRANTED);\r\nLINVRNT(osc_lock_invariant(ols));\r\ncl_lock_cancel(env, lock);\r\ncl_lock_delete(env, lock);\r\nreturn 0;\r\n}\r\nstatic void osc_lock_lockless_cancel(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice)\r\n{\r\nstruct osc_lock *ols = cl2osc_lock(slice);\r\nint result;\r\nresult = osc_lock_flush(ols, 0);\r\nif (result)\r\nCERROR("Pages for lockless lock %p were not purged(%d)\n",\r\nols, result);\r\nols->ols_state = OLS_CANCELLED;\r\n}\r\nstatic int osc_lock_lockless_wait(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice)\r\n{\r\nstruct osc_lock *olck = cl2osc_lock(slice);\r\nstruct cl_lock *lock = olck->ols_cl.cls_lock;\r\nLINVRNT(osc_lock_invariant(olck));\r\nLASSERT(olck->ols_state >= OLS_UPCALL_RECEIVED);\r\nreturn lock->cll_error;\r\n}\r\nstatic void osc_lock_lockless_state(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice,\r\nenum cl_lock_state state)\r\n{\r\nstruct osc_lock *lock = cl2osc_lock(slice);\r\nLINVRNT(osc_lock_invariant(lock));\r\nif (state == CLS_HELD) {\r\nstruct osc_io *oio = osc_env_io(env);\r\nLASSERT(ergo(lock->ols_owner, lock->ols_owner == oio));\r\nlock->ols_owner = oio;\r\nif (cl_object_same(oio->oi_cl.cis_obj, slice->cls_obj))\r\noio->oi_lockless = 1;\r\n}\r\n}\r\nstatic int osc_lock_lockless_fits_into(const struct lu_env *env,\r\nconst struct cl_lock_slice *slice,\r\nconst struct cl_lock_descr *need,\r\nconst struct cl_io *io)\r\n{\r\nstruct osc_lock *lock = cl2osc_lock(slice);\r\nif (!(need->cld_enq_flags & CEF_NEVER))\r\nreturn 0;\r\nreturn (lock->ols_owner == osc_env_io(env));\r\n}\r\nint osc_lock_init(const struct lu_env *env,\r\nstruct cl_object *obj, struct cl_lock *lock,\r\nconst struct cl_io *unused)\r\n{\r\nstruct osc_lock *clk;\r\nint result;\r\nOBD_SLAB_ALLOC_PTR_GFP(clk, osc_lock_kmem, GFP_NOFS);\r\nif (clk != NULL) {\r\n__u32 enqflags = lock->cll_descr.cld_enq_flags;\r\nosc_lock_build_einfo(env, lock, clk, &clk->ols_einfo);\r\natomic_set(&clk->ols_pageref, 0);\r\nclk->ols_state = OLS_NEW;\r\nclk->ols_flags = osc_enq2ldlm_flags(enqflags);\r\nclk->ols_agl = !!(enqflags & CEF_AGL);\r\nif (clk->ols_agl)\r\nclk->ols_flags |= LDLM_FL_BLOCK_NOWAIT;\r\nif (clk->ols_flags & LDLM_FL_HAS_INTENT)\r\nclk->ols_glimpse = 1;\r\ncl_lock_slice_add(lock, &clk->ols_cl, obj, &osc_lock_ops);\r\nif (!(enqflags & CEF_MUST))\r\nosc_lock_to_lockless(env, clk, (enqflags & CEF_NEVER));\r\nif (clk->ols_locklessable && !(enqflags & CEF_DISCARD_DATA))\r\nclk->ols_flags |= LDLM_FL_DENY_ON_CONTENTION;\r\nLDLM_DEBUG_NOLOCK("lock %p, osc lock %p, flags %llx\n",\r\nlock, clk, clk->ols_flags);\r\nresult = 0;\r\n} else\r\nresult = -ENOMEM;\r\nreturn result;\r\n}\r\nint osc_dlm_lock_pageref(struct ldlm_lock *dlm)\r\n{\r\nstruct osc_lock *olock;\r\nint rc = 0;\r\nspin_lock(&osc_ast_guard);\r\nolock = dlm->l_ast_data;\r\nif (olock != NULL &&\r\natomic_add_return(_PAGEREF_MAGIC,\r\n&olock->ols_pageref) != _PAGEREF_MAGIC) {\r\natomic_sub(_PAGEREF_MAGIC, &olock->ols_pageref);\r\nrc = 1;\r\n}\r\nspin_unlock(&osc_ast_guard);\r\nreturn rc;\r\n}
