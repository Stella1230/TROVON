u64 hw_nmi_get_sample_period(int watchdog_thresh)\r\n{\r\nreturn (u64)(cpu_khz) * 1000 * watchdog_thresh;\r\n}\r\nvoid arch_trigger_all_cpu_backtrace(bool include_self)\r\n{\r\nint i;\r\nint cpu = get_cpu();\r\nif (test_and_set_bit(0, &backtrace_flag)) {\r\nput_cpu();\r\nreturn;\r\n}\r\ncpumask_copy(to_cpumask(backtrace_mask), cpu_online_mask);\r\nif (!include_self)\r\ncpumask_clear_cpu(cpu, to_cpumask(backtrace_mask));\r\nif (!cpumask_empty(to_cpumask(backtrace_mask))) {\r\npr_info("sending NMI to %s CPUs:\n",\r\n(include_self ? "all" : "other"));\r\napic->send_IPI_mask(to_cpumask(backtrace_mask), NMI_VECTOR);\r\n}\r\nfor (i = 0; i < 10 * 1000; i++) {\r\nif (cpumask_empty(to_cpumask(backtrace_mask)))\r\nbreak;\r\nmdelay(1);\r\ntouch_softlockup_watchdog();\r\n}\r\nclear_bit(0, &backtrace_flag);\r\nsmp_mb__after_atomic();\r\nput_cpu();\r\n}\r\nstatic int\r\narch_trigger_all_cpu_backtrace_handler(unsigned int cmd, struct pt_regs *regs)\r\n{\r\nint cpu;\r\ncpu = smp_processor_id();\r\nif (cpumask_test_cpu(cpu, to_cpumask(backtrace_mask))) {\r\nstatic arch_spinlock_t lock = __ARCH_SPIN_LOCK_UNLOCKED;\r\narch_spin_lock(&lock);\r\nprintk(KERN_WARNING "NMI backtrace for cpu %d\n", cpu);\r\nshow_regs(regs);\r\narch_spin_unlock(&lock);\r\ncpumask_clear_cpu(cpu, to_cpumask(backtrace_mask));\r\nreturn NMI_HANDLED;\r\n}\r\nreturn NMI_DONE;\r\n}\r\nstatic int __init register_trigger_all_cpu_backtrace(void)\r\n{\r\nregister_nmi_handler(NMI_LOCAL, arch_trigger_all_cpu_backtrace_handler,\r\n0, "arch_bt");\r\nreturn 0;\r\n}
