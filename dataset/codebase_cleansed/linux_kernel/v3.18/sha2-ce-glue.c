static int sha224_init(struct shash_desc *desc)\r\n{\r\nstruct sha256_state *sctx = shash_desc_ctx(desc);\r\n*sctx = (struct sha256_state){\r\n.state = {\r\nSHA224_H0, SHA224_H1, SHA224_H2, SHA224_H3,\r\nSHA224_H4, SHA224_H5, SHA224_H6, SHA224_H7,\r\n}\r\n};\r\nreturn 0;\r\n}\r\nstatic int sha256_init(struct shash_desc *desc)\r\n{\r\nstruct sha256_state *sctx = shash_desc_ctx(desc);\r\n*sctx = (struct sha256_state){\r\n.state = {\r\nSHA256_H0, SHA256_H1, SHA256_H2, SHA256_H3,\r\nSHA256_H4, SHA256_H5, SHA256_H6, SHA256_H7,\r\n}\r\n};\r\nreturn 0;\r\n}\r\nstatic int sha2_update(struct shash_desc *desc, const u8 *data,\r\nunsigned int len)\r\n{\r\nstruct sha256_state *sctx = shash_desc_ctx(desc);\r\nunsigned int partial = sctx->count % SHA256_BLOCK_SIZE;\r\nsctx->count += len;\r\nif ((partial + len) >= SHA256_BLOCK_SIZE) {\r\nint blocks;\r\nif (partial) {\r\nint p = SHA256_BLOCK_SIZE - partial;\r\nmemcpy(sctx->buf + partial, data, p);\r\ndata += p;\r\nlen -= p;\r\n}\r\nblocks = len / SHA256_BLOCK_SIZE;\r\nlen %= SHA256_BLOCK_SIZE;\r\nkernel_neon_begin_partial(28);\r\nsha2_ce_transform(blocks, data, sctx->state,\r\npartial ? sctx->buf : NULL, 0);\r\nkernel_neon_end();\r\ndata += blocks * SHA256_BLOCK_SIZE;\r\npartial = 0;\r\n}\r\nif (len)\r\nmemcpy(sctx->buf + partial, data, len);\r\nreturn 0;\r\n}\r\nstatic void sha2_final(struct shash_desc *desc)\r\n{\r\nstatic const u8 padding[SHA256_BLOCK_SIZE] = { 0x80, };\r\nstruct sha256_state *sctx = shash_desc_ctx(desc);\r\n__be64 bits = cpu_to_be64(sctx->count << 3);\r\nu32 padlen = SHA256_BLOCK_SIZE\r\n- ((sctx->count + sizeof(bits)) % SHA256_BLOCK_SIZE);\r\nsha2_update(desc, padding, padlen);\r\nsha2_update(desc, (const u8 *)&bits, sizeof(bits));\r\n}\r\nstatic int sha224_final(struct shash_desc *desc, u8 *out)\r\n{\r\nstruct sha256_state *sctx = shash_desc_ctx(desc);\r\n__be32 *dst = (__be32 *)out;\r\nint i;\r\nsha2_final(desc);\r\nfor (i = 0; i < SHA224_DIGEST_SIZE / sizeof(__be32); i++)\r\nput_unaligned_be32(sctx->state[i], dst++);\r\n*sctx = (struct sha256_state){};\r\nreturn 0;\r\n}\r\nstatic int sha256_final(struct shash_desc *desc, u8 *out)\r\n{\r\nstruct sha256_state *sctx = shash_desc_ctx(desc);\r\n__be32 *dst = (__be32 *)out;\r\nint i;\r\nsha2_final(desc);\r\nfor (i = 0; i < SHA256_DIGEST_SIZE / sizeof(__be32); i++)\r\nput_unaligned_be32(sctx->state[i], dst++);\r\n*sctx = (struct sha256_state){};\r\nreturn 0;\r\n}\r\nstatic void sha2_finup(struct shash_desc *desc, const u8 *data,\r\nunsigned int len)\r\n{\r\nstruct sha256_state *sctx = shash_desc_ctx(desc);\r\nint blocks;\r\nif (sctx->count || !len || (len % SHA256_BLOCK_SIZE)) {\r\nsha2_update(desc, data, len);\r\nsha2_final(desc);\r\nreturn;\r\n}\r\nblocks = len / SHA256_BLOCK_SIZE;\r\nkernel_neon_begin_partial(28);\r\nsha2_ce_transform(blocks, data, sctx->state, NULL, len);\r\nkernel_neon_end();\r\n}\r\nstatic int sha224_finup(struct shash_desc *desc, const u8 *data,\r\nunsigned int len, u8 *out)\r\n{\r\nstruct sha256_state *sctx = shash_desc_ctx(desc);\r\n__be32 *dst = (__be32 *)out;\r\nint i;\r\nsha2_finup(desc, data, len);\r\nfor (i = 0; i < SHA224_DIGEST_SIZE / sizeof(__be32); i++)\r\nput_unaligned_be32(sctx->state[i], dst++);\r\n*sctx = (struct sha256_state){};\r\nreturn 0;\r\n}\r\nstatic int sha256_finup(struct shash_desc *desc, const u8 *data,\r\nunsigned int len, u8 *out)\r\n{\r\nstruct sha256_state *sctx = shash_desc_ctx(desc);\r\n__be32 *dst = (__be32 *)out;\r\nint i;\r\nsha2_finup(desc, data, len);\r\nfor (i = 0; i < SHA256_DIGEST_SIZE / sizeof(__be32); i++)\r\nput_unaligned_be32(sctx->state[i], dst++);\r\n*sctx = (struct sha256_state){};\r\nreturn 0;\r\n}\r\nstatic int sha2_export(struct shash_desc *desc, void *out)\r\n{\r\nstruct sha256_state *sctx = shash_desc_ctx(desc);\r\nstruct sha256_state *dst = out;\r\n*dst = *sctx;\r\nreturn 0;\r\n}\r\nstatic int sha2_import(struct shash_desc *desc, const void *in)\r\n{\r\nstruct sha256_state *sctx = shash_desc_ctx(desc);\r\nstruct sha256_state const *src = in;\r\n*sctx = *src;\r\nreturn 0;\r\n}\r\nstatic int __init sha2_ce_mod_init(void)\r\n{\r\nreturn crypto_register_shashes(algs, ARRAY_SIZE(algs));\r\n}\r\nstatic void __exit sha2_ce_mod_fini(void)\r\n{\r\ncrypto_unregister_shashes(algs, ARRAY_SIZE(algs));\r\n}
