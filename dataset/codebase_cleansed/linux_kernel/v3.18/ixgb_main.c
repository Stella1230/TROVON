static int __init\r\nixgb_init_module(void)\r\n{\r\npr_info("%s - version %s\n", ixgb_driver_string, ixgb_driver_version);\r\npr_info("%s\n", ixgb_copyright);\r\nreturn pci_register_driver(&ixgb_driver);\r\n}\r\nstatic void __exit\r\nixgb_exit_module(void)\r\n{\r\npci_unregister_driver(&ixgb_driver);\r\n}\r\nstatic void\r\nixgb_irq_disable(struct ixgb_adapter *adapter)\r\n{\r\nIXGB_WRITE_REG(&adapter->hw, IMC, ~0);\r\nIXGB_WRITE_FLUSH(&adapter->hw);\r\nsynchronize_irq(adapter->pdev->irq);\r\n}\r\nstatic void\r\nixgb_irq_enable(struct ixgb_adapter *adapter)\r\n{\r\nu32 val = IXGB_INT_RXT0 | IXGB_INT_RXDMT0 |\r\nIXGB_INT_TXDW | IXGB_INT_LSC;\r\nif (adapter->hw.subsystem_vendor_id == PCI_VENDOR_ID_SUN)\r\nval |= IXGB_INT_GPI0;\r\nIXGB_WRITE_REG(&adapter->hw, IMS, val);\r\nIXGB_WRITE_FLUSH(&adapter->hw);\r\n}\r\nint\r\nixgb_up(struct ixgb_adapter *adapter)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nint err, irq_flags = IRQF_SHARED;\r\nint max_frame = netdev->mtu + ENET_HEADER_SIZE + ENET_FCS_LENGTH;\r\nstruct ixgb_hw *hw = &adapter->hw;\r\nixgb_rar_set(hw, netdev->dev_addr, 0);\r\nixgb_set_multi(netdev);\r\nixgb_restore_vlan(adapter);\r\nixgb_configure_tx(adapter);\r\nixgb_setup_rctl(adapter);\r\nixgb_configure_rx(adapter);\r\nixgb_alloc_rx_buffers(adapter, IXGB_DESC_UNUSED(&adapter->rx_ring));\r\nIXGB_WRITE_REG(&adapter->hw, IMC, 0xffffffff);\r\nif (IXGB_READ_REG(&adapter->hw, STATUS) & IXGB_STATUS_PCIX_MODE) {\r\nerr = pci_enable_msi(adapter->pdev);\r\nif (!err) {\r\nadapter->have_msi = true;\r\nirq_flags = 0;\r\n}\r\n}\r\nerr = request_irq(adapter->pdev->irq, ixgb_intr, irq_flags,\r\nnetdev->name, netdev);\r\nif (err) {\r\nif (adapter->have_msi)\r\npci_disable_msi(adapter->pdev);\r\nnetif_err(adapter, probe, adapter->netdev,\r\n"Unable to allocate interrupt Error: %d\n", err);\r\nreturn err;\r\n}\r\nif ((hw->max_frame_size != max_frame) ||\r\n(hw->max_frame_size !=\r\n(IXGB_READ_REG(hw, MFS) >> IXGB_MFS_SHIFT))) {\r\nhw->max_frame_size = max_frame;\r\nIXGB_WRITE_REG(hw, MFS, hw->max_frame_size << IXGB_MFS_SHIFT);\r\nif (hw->max_frame_size >\r\nIXGB_MAX_ENET_FRAME_SIZE_WITHOUT_FCS + ENET_FCS_LENGTH) {\r\nu32 ctrl0 = IXGB_READ_REG(hw, CTRL0);\r\nif (!(ctrl0 & IXGB_CTRL0_JFE)) {\r\nctrl0 |= IXGB_CTRL0_JFE;\r\nIXGB_WRITE_REG(hw, CTRL0, ctrl0);\r\n}\r\n}\r\n}\r\nclear_bit(__IXGB_DOWN, &adapter->flags);\r\nnapi_enable(&adapter->napi);\r\nixgb_irq_enable(adapter);\r\nnetif_wake_queue(netdev);\r\nmod_timer(&adapter->watchdog_timer, jiffies);\r\nreturn 0;\r\n}\r\nvoid\r\nixgb_down(struct ixgb_adapter *adapter, bool kill_watchdog)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nset_bit(__IXGB_DOWN, &adapter->flags);\r\nnapi_disable(&adapter->napi);\r\nixgb_irq_disable(adapter);\r\nfree_irq(adapter->pdev->irq, netdev);\r\nif (adapter->have_msi)\r\npci_disable_msi(adapter->pdev);\r\nif (kill_watchdog)\r\ndel_timer_sync(&adapter->watchdog_timer);\r\nadapter->link_speed = 0;\r\nadapter->link_duplex = 0;\r\nnetif_carrier_off(netdev);\r\nnetif_stop_queue(netdev);\r\nixgb_reset(adapter);\r\nixgb_clean_tx_ring(adapter);\r\nixgb_clean_rx_ring(adapter);\r\n}\r\nvoid\r\nixgb_reset(struct ixgb_adapter *adapter)\r\n{\r\nstruct ixgb_hw *hw = &adapter->hw;\r\nixgb_adapter_stop(hw);\r\nif (!ixgb_init_hw(hw))\r\nnetif_err(adapter, probe, adapter->netdev, "ixgb_init_hw failed\n");\r\nIXGB_WRITE_REG(hw, MFS, hw->max_frame_size << IXGB_MFS_SHIFT);\r\nif (hw->max_frame_size >\r\nIXGB_MAX_ENET_FRAME_SIZE_WITHOUT_FCS + ENET_FCS_LENGTH) {\r\nu32 ctrl0 = IXGB_READ_REG(hw, CTRL0);\r\nif (!(ctrl0 & IXGB_CTRL0_JFE)) {\r\nctrl0 |= IXGB_CTRL0_JFE;\r\nIXGB_WRITE_REG(hw, CTRL0, ctrl0);\r\n}\r\n}\r\n}\r\nstatic netdev_features_t\r\nixgb_fix_features(struct net_device *netdev, netdev_features_t features)\r\n{\r\nif (!(features & NETIF_F_HW_VLAN_CTAG_RX))\r\nfeatures &= ~NETIF_F_HW_VLAN_CTAG_TX;\r\nreturn features;\r\n}\r\nstatic int\r\nixgb_set_features(struct net_device *netdev, netdev_features_t features)\r\n{\r\nstruct ixgb_adapter *adapter = netdev_priv(netdev);\r\nnetdev_features_t changed = features ^ netdev->features;\r\nif (!(changed & (NETIF_F_RXCSUM|NETIF_F_HW_VLAN_CTAG_RX)))\r\nreturn 0;\r\nadapter->rx_csum = !!(features & NETIF_F_RXCSUM);\r\nif (netif_running(netdev)) {\r\nixgb_down(adapter, true);\r\nixgb_up(adapter);\r\nixgb_set_speed_duplex(netdev);\r\n} else\r\nixgb_reset(adapter);\r\nreturn 0;\r\n}\r\nstatic int\r\nixgb_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\r\n{\r\nstruct net_device *netdev = NULL;\r\nstruct ixgb_adapter *adapter;\r\nstatic int cards_found = 0;\r\nint pci_using_dac;\r\nint i;\r\nint err;\r\nerr = pci_enable_device(pdev);\r\nif (err)\r\nreturn err;\r\npci_using_dac = 0;\r\nerr = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64));\r\nif (!err) {\r\npci_using_dac = 1;\r\n} else {\r\nerr = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32));\r\nif (err) {\r\npr_err("No usable DMA configuration, aborting\n");\r\ngoto err_dma_mask;\r\n}\r\n}\r\nerr = pci_request_regions(pdev, ixgb_driver_name);\r\nif (err)\r\ngoto err_request_regions;\r\npci_set_master(pdev);\r\nnetdev = alloc_etherdev(sizeof(struct ixgb_adapter));\r\nif (!netdev) {\r\nerr = -ENOMEM;\r\ngoto err_alloc_etherdev;\r\n}\r\nSET_NETDEV_DEV(netdev, &pdev->dev);\r\npci_set_drvdata(pdev, netdev);\r\nadapter = netdev_priv(netdev);\r\nadapter->netdev = netdev;\r\nadapter->pdev = pdev;\r\nadapter->hw.back = adapter;\r\nadapter->msg_enable = netif_msg_init(debug, DEFAULT_MSG_ENABLE);\r\nadapter->hw.hw_addr = pci_ioremap_bar(pdev, BAR_0);\r\nif (!adapter->hw.hw_addr) {\r\nerr = -EIO;\r\ngoto err_ioremap;\r\n}\r\nfor (i = BAR_1; i <= BAR_5; i++) {\r\nif (pci_resource_len(pdev, i) == 0)\r\ncontinue;\r\nif (pci_resource_flags(pdev, i) & IORESOURCE_IO) {\r\nadapter->hw.io_base = pci_resource_start(pdev, i);\r\nbreak;\r\n}\r\n}\r\nnetdev->netdev_ops = &ixgb_netdev_ops;\r\nixgb_set_ethtool_ops(netdev);\r\nnetdev->watchdog_timeo = 5 * HZ;\r\nnetif_napi_add(netdev, &adapter->napi, ixgb_clean, 64);\r\nstrncpy(netdev->name, pci_name(pdev), sizeof(netdev->name) - 1);\r\nadapter->bd_number = cards_found;\r\nadapter->link_speed = 0;\r\nadapter->link_duplex = 0;\r\nerr = ixgb_sw_init(adapter);\r\nif (err)\r\ngoto err_sw_init;\r\nnetdev->hw_features = NETIF_F_SG |\r\nNETIF_F_TSO |\r\nNETIF_F_HW_CSUM |\r\nNETIF_F_HW_VLAN_CTAG_TX |\r\nNETIF_F_HW_VLAN_CTAG_RX;\r\nnetdev->features = netdev->hw_features |\r\nNETIF_F_HW_VLAN_CTAG_FILTER;\r\nnetdev->hw_features |= NETIF_F_RXCSUM;\r\nif (pci_using_dac) {\r\nnetdev->features |= NETIF_F_HIGHDMA;\r\nnetdev->vlan_features |= NETIF_F_HIGHDMA;\r\n}\r\nif (!ixgb_validate_eeprom_checksum(&adapter->hw)) {\r\nnetif_err(adapter, probe, adapter->netdev,\r\n"The EEPROM Checksum Is Not Valid\n");\r\nerr = -EIO;\r\ngoto err_eeprom;\r\n}\r\nixgb_get_ee_mac_addr(&adapter->hw, netdev->dev_addr);\r\nif (!is_valid_ether_addr(netdev->dev_addr)) {\r\nnetif_err(adapter, probe, adapter->netdev, "Invalid MAC Address\n");\r\nerr = -EIO;\r\ngoto err_eeprom;\r\n}\r\nadapter->part_num = ixgb_get_ee_pba_number(&adapter->hw);\r\ninit_timer(&adapter->watchdog_timer);\r\nadapter->watchdog_timer.function = ixgb_watchdog;\r\nadapter->watchdog_timer.data = (unsigned long)adapter;\r\nINIT_WORK(&adapter->tx_timeout_task, ixgb_tx_timeout_task);\r\nstrcpy(netdev->name, "eth%d");\r\nerr = register_netdev(netdev);\r\nif (err)\r\ngoto err_register;\r\nnetif_carrier_off(netdev);\r\nnetif_info(adapter, probe, adapter->netdev,\r\n"Intel(R) PRO/10GbE Network Connection\n");\r\nixgb_check_options(adapter);\r\nixgb_reset(adapter);\r\ncards_found++;\r\nreturn 0;\r\nerr_register:\r\nerr_sw_init:\r\nerr_eeprom:\r\niounmap(adapter->hw.hw_addr);\r\nerr_ioremap:\r\nfree_netdev(netdev);\r\nerr_alloc_etherdev:\r\npci_release_regions(pdev);\r\nerr_request_regions:\r\nerr_dma_mask:\r\npci_disable_device(pdev);\r\nreturn err;\r\n}\r\nstatic void\r\nixgb_remove(struct pci_dev *pdev)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct ixgb_adapter *adapter = netdev_priv(netdev);\r\ncancel_work_sync(&adapter->tx_timeout_task);\r\nunregister_netdev(netdev);\r\niounmap(adapter->hw.hw_addr);\r\npci_release_regions(pdev);\r\nfree_netdev(netdev);\r\npci_disable_device(pdev);\r\n}\r\nstatic int\r\nixgb_sw_init(struct ixgb_adapter *adapter)\r\n{\r\nstruct ixgb_hw *hw = &adapter->hw;\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nhw->vendor_id = pdev->vendor;\r\nhw->device_id = pdev->device;\r\nhw->subsystem_vendor_id = pdev->subsystem_vendor;\r\nhw->subsystem_id = pdev->subsystem_device;\r\nhw->max_frame_size = netdev->mtu + ENET_HEADER_SIZE + ENET_FCS_LENGTH;\r\nadapter->rx_buffer_len = hw->max_frame_size + 8;\r\nif ((hw->device_id == IXGB_DEVICE_ID_82597EX) ||\r\n(hw->device_id == IXGB_DEVICE_ID_82597EX_CX4) ||\r\n(hw->device_id == IXGB_DEVICE_ID_82597EX_LR) ||\r\n(hw->device_id == IXGB_DEVICE_ID_82597EX_SR))\r\nhw->mac_type = ixgb_82597;\r\nelse {\r\nnetif_err(adapter, probe, adapter->netdev, "unsupported device id\n");\r\n}\r\nhw->fc.send_xon = 1;\r\nset_bit(__IXGB_DOWN, &adapter->flags);\r\nreturn 0;\r\n}\r\nstatic int\r\nixgb_open(struct net_device *netdev)\r\n{\r\nstruct ixgb_adapter *adapter = netdev_priv(netdev);\r\nint err;\r\nerr = ixgb_setup_tx_resources(adapter);\r\nif (err)\r\ngoto err_setup_tx;\r\nnetif_carrier_off(netdev);\r\nerr = ixgb_setup_rx_resources(adapter);\r\nif (err)\r\ngoto err_setup_rx;\r\nerr = ixgb_up(adapter);\r\nif (err)\r\ngoto err_up;\r\nnetif_start_queue(netdev);\r\nreturn 0;\r\nerr_up:\r\nixgb_free_rx_resources(adapter);\r\nerr_setup_rx:\r\nixgb_free_tx_resources(adapter);\r\nerr_setup_tx:\r\nixgb_reset(adapter);\r\nreturn err;\r\n}\r\nstatic int\r\nixgb_close(struct net_device *netdev)\r\n{\r\nstruct ixgb_adapter *adapter = netdev_priv(netdev);\r\nixgb_down(adapter, true);\r\nixgb_free_tx_resources(adapter);\r\nixgb_free_rx_resources(adapter);\r\nreturn 0;\r\n}\r\nint\r\nixgb_setup_tx_resources(struct ixgb_adapter *adapter)\r\n{\r\nstruct ixgb_desc_ring *txdr = &adapter->tx_ring;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nint size;\r\nsize = sizeof(struct ixgb_buffer) * txdr->count;\r\ntxdr->buffer_info = vzalloc(size);\r\nif (!txdr->buffer_info)\r\nreturn -ENOMEM;\r\ntxdr->size = txdr->count * sizeof(struct ixgb_tx_desc);\r\ntxdr->size = ALIGN(txdr->size, 4096);\r\ntxdr->desc = dma_zalloc_coherent(&pdev->dev, txdr->size, &txdr->dma,\r\nGFP_KERNEL);\r\nif (!txdr->desc) {\r\nvfree(txdr->buffer_info);\r\nreturn -ENOMEM;\r\n}\r\ntxdr->next_to_use = 0;\r\ntxdr->next_to_clean = 0;\r\nreturn 0;\r\n}\r\nstatic void\r\nixgb_configure_tx(struct ixgb_adapter *adapter)\r\n{\r\nu64 tdba = adapter->tx_ring.dma;\r\nu32 tdlen = adapter->tx_ring.count * sizeof(struct ixgb_tx_desc);\r\nu32 tctl;\r\nstruct ixgb_hw *hw = &adapter->hw;\r\nIXGB_WRITE_REG(hw, TDBAL, (tdba & 0x00000000ffffffffULL));\r\nIXGB_WRITE_REG(hw, TDBAH, (tdba >> 32));\r\nIXGB_WRITE_REG(hw, TDLEN, tdlen);\r\nIXGB_WRITE_REG(hw, TDH, 0);\r\nIXGB_WRITE_REG(hw, TDT, 0);\r\nIXGB_WRITE_REG(hw, TIDV, adapter->tx_int_delay);\r\ntctl = IXGB_TCTL_TCE | IXGB_TCTL_TXEN | IXGB_TCTL_TPDE;\r\nIXGB_WRITE_REG(hw, TCTL, tctl);\r\nadapter->tx_cmd_type =\r\nIXGB_TX_DESC_TYPE |\r\n(adapter->tx_int_delay_enable ? IXGB_TX_DESC_CMD_IDE : 0);\r\n}\r\nint\r\nixgb_setup_rx_resources(struct ixgb_adapter *adapter)\r\n{\r\nstruct ixgb_desc_ring *rxdr = &adapter->rx_ring;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nint size;\r\nsize = sizeof(struct ixgb_buffer) * rxdr->count;\r\nrxdr->buffer_info = vzalloc(size);\r\nif (!rxdr->buffer_info)\r\nreturn -ENOMEM;\r\nrxdr->size = rxdr->count * sizeof(struct ixgb_rx_desc);\r\nrxdr->size = ALIGN(rxdr->size, 4096);\r\nrxdr->desc = dma_alloc_coherent(&pdev->dev, rxdr->size, &rxdr->dma,\r\nGFP_KERNEL);\r\nif (!rxdr->desc) {\r\nvfree(rxdr->buffer_info);\r\nreturn -ENOMEM;\r\n}\r\nmemset(rxdr->desc, 0, rxdr->size);\r\nrxdr->next_to_clean = 0;\r\nrxdr->next_to_use = 0;\r\nreturn 0;\r\n}\r\nstatic void\r\nixgb_setup_rctl(struct ixgb_adapter *adapter)\r\n{\r\nu32 rctl;\r\nrctl = IXGB_READ_REG(&adapter->hw, RCTL);\r\nrctl &= ~(3 << IXGB_RCTL_MO_SHIFT);\r\nrctl |=\r\nIXGB_RCTL_BAM | IXGB_RCTL_RDMTS_1_2 |\r\nIXGB_RCTL_RXEN | IXGB_RCTL_CFF |\r\n(adapter->hw.mc_filter_type << IXGB_RCTL_MO_SHIFT);\r\nrctl |= IXGB_RCTL_SECRC;\r\nif (adapter->rx_buffer_len <= IXGB_RXBUFFER_2048)\r\nrctl |= IXGB_RCTL_BSIZE_2048;\r\nelse if (adapter->rx_buffer_len <= IXGB_RXBUFFER_4096)\r\nrctl |= IXGB_RCTL_BSIZE_4096;\r\nelse if (adapter->rx_buffer_len <= IXGB_RXBUFFER_8192)\r\nrctl |= IXGB_RCTL_BSIZE_8192;\r\nelse if (adapter->rx_buffer_len <= IXGB_RXBUFFER_16384)\r\nrctl |= IXGB_RCTL_BSIZE_16384;\r\nIXGB_WRITE_REG(&adapter->hw, RCTL, rctl);\r\n}\r\nstatic void\r\nixgb_configure_rx(struct ixgb_adapter *adapter)\r\n{\r\nu64 rdba = adapter->rx_ring.dma;\r\nu32 rdlen = adapter->rx_ring.count * sizeof(struct ixgb_rx_desc);\r\nstruct ixgb_hw *hw = &adapter->hw;\r\nu32 rctl;\r\nu32 rxcsum;\r\nrctl = IXGB_READ_REG(hw, RCTL);\r\nIXGB_WRITE_REG(hw, RCTL, rctl & ~IXGB_RCTL_RXEN);\r\nIXGB_WRITE_REG(hw, RDTR, adapter->rx_int_delay);\r\nIXGB_WRITE_REG(hw, RDBAL, (rdba & 0x00000000ffffffffULL));\r\nIXGB_WRITE_REG(hw, RDBAH, (rdba >> 32));\r\nIXGB_WRITE_REG(hw, RDLEN, rdlen);\r\nIXGB_WRITE_REG(hw, RDH, 0);\r\nIXGB_WRITE_REG(hw, RDT, 0);\r\nIXGB_WRITE_REG(hw, RXDCTL, 0);\r\nif (adapter->rx_csum) {\r\nrxcsum = IXGB_READ_REG(hw, RXCSUM);\r\nrxcsum |= IXGB_RXCSUM_TUOFL;\r\nIXGB_WRITE_REG(hw, RXCSUM, rxcsum);\r\n}\r\nIXGB_WRITE_REG(hw, RCTL, rctl);\r\n}\r\nvoid\r\nixgb_free_tx_resources(struct ixgb_adapter *adapter)\r\n{\r\nstruct pci_dev *pdev = adapter->pdev;\r\nixgb_clean_tx_ring(adapter);\r\nvfree(adapter->tx_ring.buffer_info);\r\nadapter->tx_ring.buffer_info = NULL;\r\ndma_free_coherent(&pdev->dev, adapter->tx_ring.size,\r\nadapter->tx_ring.desc, adapter->tx_ring.dma);\r\nadapter->tx_ring.desc = NULL;\r\n}\r\nstatic void\r\nixgb_unmap_and_free_tx_resource(struct ixgb_adapter *adapter,\r\nstruct ixgb_buffer *buffer_info)\r\n{\r\nif (buffer_info->dma) {\r\nif (buffer_info->mapped_as_page)\r\ndma_unmap_page(&adapter->pdev->dev, buffer_info->dma,\r\nbuffer_info->length, DMA_TO_DEVICE);\r\nelse\r\ndma_unmap_single(&adapter->pdev->dev, buffer_info->dma,\r\nbuffer_info->length, DMA_TO_DEVICE);\r\nbuffer_info->dma = 0;\r\n}\r\nif (buffer_info->skb) {\r\ndev_kfree_skb_any(buffer_info->skb);\r\nbuffer_info->skb = NULL;\r\n}\r\nbuffer_info->time_stamp = 0;\r\n}\r\nstatic void\r\nixgb_clean_tx_ring(struct ixgb_adapter *adapter)\r\n{\r\nstruct ixgb_desc_ring *tx_ring = &adapter->tx_ring;\r\nstruct ixgb_buffer *buffer_info;\r\nunsigned long size;\r\nunsigned int i;\r\nfor (i = 0; i < tx_ring->count; i++) {\r\nbuffer_info = &tx_ring->buffer_info[i];\r\nixgb_unmap_and_free_tx_resource(adapter, buffer_info);\r\n}\r\nsize = sizeof(struct ixgb_buffer) * tx_ring->count;\r\nmemset(tx_ring->buffer_info, 0, size);\r\nmemset(tx_ring->desc, 0, tx_ring->size);\r\ntx_ring->next_to_use = 0;\r\ntx_ring->next_to_clean = 0;\r\nIXGB_WRITE_REG(&adapter->hw, TDH, 0);\r\nIXGB_WRITE_REG(&adapter->hw, TDT, 0);\r\n}\r\nvoid\r\nixgb_free_rx_resources(struct ixgb_adapter *adapter)\r\n{\r\nstruct ixgb_desc_ring *rx_ring = &adapter->rx_ring;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nixgb_clean_rx_ring(adapter);\r\nvfree(rx_ring->buffer_info);\r\nrx_ring->buffer_info = NULL;\r\ndma_free_coherent(&pdev->dev, rx_ring->size, rx_ring->desc,\r\nrx_ring->dma);\r\nrx_ring->desc = NULL;\r\n}\r\nstatic void\r\nixgb_clean_rx_ring(struct ixgb_adapter *adapter)\r\n{\r\nstruct ixgb_desc_ring *rx_ring = &adapter->rx_ring;\r\nstruct ixgb_buffer *buffer_info;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nunsigned long size;\r\nunsigned int i;\r\nfor (i = 0; i < rx_ring->count; i++) {\r\nbuffer_info = &rx_ring->buffer_info[i];\r\nif (buffer_info->dma) {\r\ndma_unmap_single(&pdev->dev,\r\nbuffer_info->dma,\r\nbuffer_info->length,\r\nDMA_FROM_DEVICE);\r\nbuffer_info->dma = 0;\r\nbuffer_info->length = 0;\r\n}\r\nif (buffer_info->skb) {\r\ndev_kfree_skb(buffer_info->skb);\r\nbuffer_info->skb = NULL;\r\n}\r\n}\r\nsize = sizeof(struct ixgb_buffer) * rx_ring->count;\r\nmemset(rx_ring->buffer_info, 0, size);\r\nmemset(rx_ring->desc, 0, rx_ring->size);\r\nrx_ring->next_to_clean = 0;\r\nrx_ring->next_to_use = 0;\r\nIXGB_WRITE_REG(&adapter->hw, RDH, 0);\r\nIXGB_WRITE_REG(&adapter->hw, RDT, 0);\r\n}\r\nstatic int\r\nixgb_set_mac(struct net_device *netdev, void *p)\r\n{\r\nstruct ixgb_adapter *adapter = netdev_priv(netdev);\r\nstruct sockaddr *addr = p;\r\nif (!is_valid_ether_addr(addr->sa_data))\r\nreturn -EADDRNOTAVAIL;\r\nmemcpy(netdev->dev_addr, addr->sa_data, netdev->addr_len);\r\nixgb_rar_set(&adapter->hw, addr->sa_data, 0);\r\nreturn 0;\r\n}\r\nstatic void\r\nixgb_set_multi(struct net_device *netdev)\r\n{\r\nstruct ixgb_adapter *adapter = netdev_priv(netdev);\r\nstruct ixgb_hw *hw = &adapter->hw;\r\nstruct netdev_hw_addr *ha;\r\nu32 rctl;\r\nrctl = IXGB_READ_REG(hw, RCTL);\r\nif (netdev->flags & IFF_PROMISC) {\r\nrctl |= (IXGB_RCTL_UPE | IXGB_RCTL_MPE);\r\nrctl &= ~IXGB_RCTL_CFIEN;\r\nrctl &= ~IXGB_RCTL_VFE;\r\n} else {\r\nif (netdev->flags & IFF_ALLMULTI) {\r\nrctl |= IXGB_RCTL_MPE;\r\nrctl &= ~IXGB_RCTL_UPE;\r\n} else {\r\nrctl &= ~(IXGB_RCTL_UPE | IXGB_RCTL_MPE);\r\n}\r\nrctl |= IXGB_RCTL_VFE;\r\nrctl &= ~IXGB_RCTL_CFIEN;\r\n}\r\nif (netdev_mc_count(netdev) > IXGB_MAX_NUM_MULTICAST_ADDRESSES) {\r\nrctl |= IXGB_RCTL_MPE;\r\nIXGB_WRITE_REG(hw, RCTL, rctl);\r\n} else {\r\nu8 *mta = kmalloc(IXGB_MAX_NUM_MULTICAST_ADDRESSES *\r\nETH_ALEN, GFP_ATOMIC);\r\nu8 *addr;\r\nif (!mta)\r\ngoto alloc_failed;\r\nIXGB_WRITE_REG(hw, RCTL, rctl);\r\naddr = mta;\r\nnetdev_for_each_mc_addr(ha, netdev) {\r\nmemcpy(addr, ha->addr, ETH_ALEN);\r\naddr += ETH_ALEN;\r\n}\r\nixgb_mc_addr_list_update(hw, mta, netdev_mc_count(netdev), 0);\r\nkfree(mta);\r\n}\r\nalloc_failed:\r\nif (netdev->features & NETIF_F_HW_VLAN_CTAG_RX)\r\nixgb_vlan_strip_enable(adapter);\r\nelse\r\nixgb_vlan_strip_disable(adapter);\r\n}\r\nstatic void\r\nixgb_watchdog(unsigned long data)\r\n{\r\nstruct ixgb_adapter *adapter = (struct ixgb_adapter *)data;\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct ixgb_desc_ring *txdr = &adapter->tx_ring;\r\nixgb_check_for_link(&adapter->hw);\r\nif (ixgb_check_for_bad_link(&adapter->hw)) {\r\nnetif_stop_queue(netdev);\r\n}\r\nif (adapter->hw.link_up) {\r\nif (!netif_carrier_ok(netdev)) {\r\nnetdev_info(netdev,\r\n"NIC Link is Up 10 Gbps Full Duplex, Flow Control: %s\n",\r\n(adapter->hw.fc.type == ixgb_fc_full) ?\r\n"RX/TX" :\r\n(adapter->hw.fc.type == ixgb_fc_rx_pause) ?\r\n"RX" :\r\n(adapter->hw.fc.type == ixgb_fc_tx_pause) ?\r\n"TX" : "None");\r\nadapter->link_speed = 10000;\r\nadapter->link_duplex = FULL_DUPLEX;\r\nnetif_carrier_on(netdev);\r\n}\r\n} else {\r\nif (netif_carrier_ok(netdev)) {\r\nadapter->link_speed = 0;\r\nadapter->link_duplex = 0;\r\nnetdev_info(netdev, "NIC Link is Down\n");\r\nnetif_carrier_off(netdev);\r\n}\r\n}\r\nixgb_update_stats(adapter);\r\nif (!netif_carrier_ok(netdev)) {\r\nif (IXGB_DESC_UNUSED(txdr) + 1 < txdr->count) {\r\nschedule_work(&adapter->tx_timeout_task);\r\nreturn;\r\n}\r\n}\r\nadapter->detect_tx_hung = true;\r\nIXGB_WRITE_REG(&adapter->hw, ICS, IXGB_INT_TXDW);\r\nmod_timer(&adapter->watchdog_timer, jiffies + 2 * HZ);\r\n}\r\nstatic int\r\nixgb_tso(struct ixgb_adapter *adapter, struct sk_buff *skb)\r\n{\r\nstruct ixgb_context_desc *context_desc;\r\nunsigned int i;\r\nu8 ipcss, ipcso, tucss, tucso, hdr_len;\r\nu16 ipcse, tucse, mss;\r\nif (likely(skb_is_gso(skb))) {\r\nstruct ixgb_buffer *buffer_info;\r\nstruct iphdr *iph;\r\nint err;\r\nerr = skb_cow_head(skb, 0);\r\nif (err < 0)\r\nreturn err;\r\nhdr_len = skb_transport_offset(skb) + tcp_hdrlen(skb);\r\nmss = skb_shinfo(skb)->gso_size;\r\niph = ip_hdr(skb);\r\niph->tot_len = 0;\r\niph->check = 0;\r\ntcp_hdr(skb)->check = ~csum_tcpudp_magic(iph->saddr,\r\niph->daddr, 0,\r\nIPPROTO_TCP, 0);\r\nipcss = skb_network_offset(skb);\r\nipcso = (void *)&(iph->check) - (void *)skb->data;\r\nipcse = skb_transport_offset(skb) - 1;\r\ntucss = skb_transport_offset(skb);\r\ntucso = (void *)&(tcp_hdr(skb)->check) - (void *)skb->data;\r\ntucse = 0;\r\ni = adapter->tx_ring.next_to_use;\r\ncontext_desc = IXGB_CONTEXT_DESC(adapter->tx_ring, i);\r\nbuffer_info = &adapter->tx_ring.buffer_info[i];\r\nWARN_ON(buffer_info->dma != 0);\r\ncontext_desc->ipcss = ipcss;\r\ncontext_desc->ipcso = ipcso;\r\ncontext_desc->ipcse = cpu_to_le16(ipcse);\r\ncontext_desc->tucss = tucss;\r\ncontext_desc->tucso = tucso;\r\ncontext_desc->tucse = cpu_to_le16(tucse);\r\ncontext_desc->mss = cpu_to_le16(mss);\r\ncontext_desc->hdr_len = hdr_len;\r\ncontext_desc->status = 0;\r\ncontext_desc->cmd_type_len = cpu_to_le32(\r\nIXGB_CONTEXT_DESC_TYPE\r\n| IXGB_CONTEXT_DESC_CMD_TSE\r\n| IXGB_CONTEXT_DESC_CMD_IP\r\n| IXGB_CONTEXT_DESC_CMD_TCP\r\n| IXGB_CONTEXT_DESC_CMD_IDE\r\n| (skb->len - (hdr_len)));\r\nif (++i == adapter->tx_ring.count) i = 0;\r\nadapter->tx_ring.next_to_use = i;\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic bool\r\nixgb_tx_csum(struct ixgb_adapter *adapter, struct sk_buff *skb)\r\n{\r\nstruct ixgb_context_desc *context_desc;\r\nunsigned int i;\r\nu8 css, cso;\r\nif (likely(skb->ip_summed == CHECKSUM_PARTIAL)) {\r\nstruct ixgb_buffer *buffer_info;\r\ncss = skb_checksum_start_offset(skb);\r\ncso = css + skb->csum_offset;\r\ni = adapter->tx_ring.next_to_use;\r\ncontext_desc = IXGB_CONTEXT_DESC(adapter->tx_ring, i);\r\nbuffer_info = &adapter->tx_ring.buffer_info[i];\r\nWARN_ON(buffer_info->dma != 0);\r\ncontext_desc->tucss = css;\r\ncontext_desc->tucso = cso;\r\ncontext_desc->tucse = 0;\r\n*(u32 *)&(context_desc->ipcss) = 0;\r\ncontext_desc->status = 0;\r\ncontext_desc->hdr_len = 0;\r\ncontext_desc->mss = 0;\r\ncontext_desc->cmd_type_len =\r\ncpu_to_le32(IXGB_CONTEXT_DESC_TYPE\r\n| IXGB_TX_DESC_CMD_IDE);\r\nif (++i == adapter->tx_ring.count) i = 0;\r\nadapter->tx_ring.next_to_use = i;\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic int\r\nixgb_tx_map(struct ixgb_adapter *adapter, struct sk_buff *skb,\r\nunsigned int first)\r\n{\r\nstruct ixgb_desc_ring *tx_ring = &adapter->tx_ring;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nstruct ixgb_buffer *buffer_info;\r\nint len = skb_headlen(skb);\r\nunsigned int offset = 0, size, count = 0, i;\r\nunsigned int mss = skb_shinfo(skb)->gso_size;\r\nunsigned int nr_frags = skb_shinfo(skb)->nr_frags;\r\nunsigned int f;\r\ni = tx_ring->next_to_use;\r\nwhile (len) {\r\nbuffer_info = &tx_ring->buffer_info[i];\r\nsize = min(len, IXGB_MAX_DATA_PER_TXD);\r\nif (unlikely(mss && !nr_frags && size == len && size > 8))\r\nsize -= 4;\r\nbuffer_info->length = size;\r\nWARN_ON(buffer_info->dma != 0);\r\nbuffer_info->time_stamp = jiffies;\r\nbuffer_info->mapped_as_page = false;\r\nbuffer_info->dma = dma_map_single(&pdev->dev,\r\nskb->data + offset,\r\nsize, DMA_TO_DEVICE);\r\nif (dma_mapping_error(&pdev->dev, buffer_info->dma))\r\ngoto dma_error;\r\nbuffer_info->next_to_watch = 0;\r\nlen -= size;\r\noffset += size;\r\ncount++;\r\nif (len) {\r\ni++;\r\nif (i == tx_ring->count)\r\ni = 0;\r\n}\r\n}\r\nfor (f = 0; f < nr_frags; f++) {\r\nconst struct skb_frag_struct *frag;\r\nfrag = &skb_shinfo(skb)->frags[f];\r\nlen = skb_frag_size(frag);\r\noffset = 0;\r\nwhile (len) {\r\ni++;\r\nif (i == tx_ring->count)\r\ni = 0;\r\nbuffer_info = &tx_ring->buffer_info[i];\r\nsize = min(len, IXGB_MAX_DATA_PER_TXD);\r\nif (unlikely(mss && (f == (nr_frags - 1))\r\n&& size == len && size > 8))\r\nsize -= 4;\r\nbuffer_info->length = size;\r\nbuffer_info->time_stamp = jiffies;\r\nbuffer_info->mapped_as_page = true;\r\nbuffer_info->dma =\r\nskb_frag_dma_map(&pdev->dev, frag, offset, size,\r\nDMA_TO_DEVICE);\r\nif (dma_mapping_error(&pdev->dev, buffer_info->dma))\r\ngoto dma_error;\r\nbuffer_info->next_to_watch = 0;\r\nlen -= size;\r\noffset += size;\r\ncount++;\r\n}\r\n}\r\ntx_ring->buffer_info[i].skb = skb;\r\ntx_ring->buffer_info[first].next_to_watch = i;\r\nreturn count;\r\ndma_error:\r\ndev_err(&pdev->dev, "TX DMA map failed\n");\r\nbuffer_info->dma = 0;\r\nif (count)\r\ncount--;\r\nwhile (count--) {\r\nif (i==0)\r\ni += tx_ring->count;\r\ni--;\r\nbuffer_info = &tx_ring->buffer_info[i];\r\nixgb_unmap_and_free_tx_resource(adapter, buffer_info);\r\n}\r\nreturn 0;\r\n}\r\nstatic void\r\nixgb_tx_queue(struct ixgb_adapter *adapter, int count, int vlan_id,int tx_flags)\r\n{\r\nstruct ixgb_desc_ring *tx_ring = &adapter->tx_ring;\r\nstruct ixgb_tx_desc *tx_desc = NULL;\r\nstruct ixgb_buffer *buffer_info;\r\nu32 cmd_type_len = adapter->tx_cmd_type;\r\nu8 status = 0;\r\nu8 popts = 0;\r\nunsigned int i;\r\nif (tx_flags & IXGB_TX_FLAGS_TSO) {\r\ncmd_type_len |= IXGB_TX_DESC_CMD_TSE;\r\npopts |= (IXGB_TX_DESC_POPTS_IXSM | IXGB_TX_DESC_POPTS_TXSM);\r\n}\r\nif (tx_flags & IXGB_TX_FLAGS_CSUM)\r\npopts |= IXGB_TX_DESC_POPTS_TXSM;\r\nif (tx_flags & IXGB_TX_FLAGS_VLAN)\r\ncmd_type_len |= IXGB_TX_DESC_CMD_VLE;\r\ni = tx_ring->next_to_use;\r\nwhile (count--) {\r\nbuffer_info = &tx_ring->buffer_info[i];\r\ntx_desc = IXGB_TX_DESC(*tx_ring, i);\r\ntx_desc->buff_addr = cpu_to_le64(buffer_info->dma);\r\ntx_desc->cmd_type_len =\r\ncpu_to_le32(cmd_type_len | buffer_info->length);\r\ntx_desc->status = status;\r\ntx_desc->popts = popts;\r\ntx_desc->vlan = cpu_to_le16(vlan_id);\r\nif (++i == tx_ring->count) i = 0;\r\n}\r\ntx_desc->cmd_type_len |=\r\ncpu_to_le32(IXGB_TX_DESC_CMD_EOP | IXGB_TX_DESC_CMD_RS);\r\nwmb();\r\ntx_ring->next_to_use = i;\r\nIXGB_WRITE_REG(&adapter->hw, TDT, i);\r\n}\r\nstatic int __ixgb_maybe_stop_tx(struct net_device *netdev, int size)\r\n{\r\nstruct ixgb_adapter *adapter = netdev_priv(netdev);\r\nstruct ixgb_desc_ring *tx_ring = &adapter->tx_ring;\r\nnetif_stop_queue(netdev);\r\nsmp_mb();\r\nif (likely(IXGB_DESC_UNUSED(tx_ring) < size))\r\nreturn -EBUSY;\r\nnetif_start_queue(netdev);\r\n++adapter->restart_queue;\r\nreturn 0;\r\n}\r\nstatic int ixgb_maybe_stop_tx(struct net_device *netdev,\r\nstruct ixgb_desc_ring *tx_ring, int size)\r\n{\r\nif (likely(IXGB_DESC_UNUSED(tx_ring) >= size))\r\nreturn 0;\r\nreturn __ixgb_maybe_stop_tx(netdev, size);\r\n}\r\nstatic netdev_tx_t\r\nixgb_xmit_frame(struct sk_buff *skb, struct net_device *netdev)\r\n{\r\nstruct ixgb_adapter *adapter = netdev_priv(netdev);\r\nunsigned int first;\r\nunsigned int tx_flags = 0;\r\nint vlan_id = 0;\r\nint count = 0;\r\nint tso;\r\nif (test_bit(__IXGB_DOWN, &adapter->flags)) {\r\ndev_kfree_skb_any(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nif (skb->len <= 0) {\r\ndev_kfree_skb_any(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nif (unlikely(ixgb_maybe_stop_tx(netdev, &adapter->tx_ring,\r\nDESC_NEEDED)))\r\nreturn NETDEV_TX_BUSY;\r\nif (vlan_tx_tag_present(skb)) {\r\ntx_flags |= IXGB_TX_FLAGS_VLAN;\r\nvlan_id = vlan_tx_tag_get(skb);\r\n}\r\nfirst = adapter->tx_ring.next_to_use;\r\ntso = ixgb_tso(adapter, skb);\r\nif (tso < 0) {\r\ndev_kfree_skb_any(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nif (likely(tso))\r\ntx_flags |= IXGB_TX_FLAGS_TSO;\r\nelse if (ixgb_tx_csum(adapter, skb))\r\ntx_flags |= IXGB_TX_FLAGS_CSUM;\r\ncount = ixgb_tx_map(adapter, skb, first);\r\nif (count) {\r\nixgb_tx_queue(adapter, count, vlan_id, tx_flags);\r\nixgb_maybe_stop_tx(netdev, &adapter->tx_ring, DESC_NEEDED);\r\n} else {\r\ndev_kfree_skb_any(skb);\r\nadapter->tx_ring.buffer_info[first].time_stamp = 0;\r\nadapter->tx_ring.next_to_use = first;\r\n}\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void\r\nixgb_tx_timeout(struct net_device *netdev)\r\n{\r\nstruct ixgb_adapter *adapter = netdev_priv(netdev);\r\nschedule_work(&adapter->tx_timeout_task);\r\n}\r\nstatic void\r\nixgb_tx_timeout_task(struct work_struct *work)\r\n{\r\nstruct ixgb_adapter *adapter =\r\ncontainer_of(work, struct ixgb_adapter, tx_timeout_task);\r\nadapter->tx_timeout_count++;\r\nixgb_down(adapter, true);\r\nixgb_up(adapter);\r\n}\r\nstatic struct net_device_stats *\r\nixgb_get_stats(struct net_device *netdev)\r\n{\r\nreturn &netdev->stats;\r\n}\r\nstatic int\r\nixgb_change_mtu(struct net_device *netdev, int new_mtu)\r\n{\r\nstruct ixgb_adapter *adapter = netdev_priv(netdev);\r\nint max_frame = new_mtu + ENET_HEADER_SIZE + ENET_FCS_LENGTH;\r\nint old_max_frame = netdev->mtu + ENET_HEADER_SIZE + ENET_FCS_LENGTH;\r\nif ((new_mtu < 68) ||\r\n(max_frame > IXGB_MAX_JUMBO_FRAME_SIZE + ENET_FCS_LENGTH)) {\r\nnetif_err(adapter, probe, adapter->netdev,\r\n"Invalid MTU setting %d\n", new_mtu);\r\nreturn -EINVAL;\r\n}\r\nif (old_max_frame == max_frame)\r\nreturn 0;\r\nif (netif_running(netdev))\r\nixgb_down(adapter, true);\r\nadapter->rx_buffer_len = max_frame + 8;\r\nnetdev->mtu = new_mtu;\r\nif (netif_running(netdev))\r\nixgb_up(adapter);\r\nreturn 0;\r\n}\r\nvoid\r\nixgb_update_stats(struct ixgb_adapter *adapter)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nif (pci_channel_offline(pdev))\r\nreturn;\r\nif ((netdev->flags & IFF_PROMISC) || (netdev->flags & IFF_ALLMULTI) ||\r\n(netdev_mc_count(netdev) > IXGB_MAX_NUM_MULTICAST_ADDRESSES)) {\r\nu64 multi = IXGB_READ_REG(&adapter->hw, MPRCL);\r\nu32 bcast_l = IXGB_READ_REG(&adapter->hw, BPRCL);\r\nu32 bcast_h = IXGB_READ_REG(&adapter->hw, BPRCH);\r\nu64 bcast = ((u64)bcast_h << 32) | bcast_l;\r\nmulti |= ((u64)IXGB_READ_REG(&adapter->hw, MPRCH) << 32);\r\nif (multi >= bcast)\r\nmulti -= bcast;\r\nadapter->stats.mprcl += (multi & 0xFFFFFFFF);\r\nadapter->stats.mprch += (multi >> 32);\r\nadapter->stats.bprcl += bcast_l;\r\nadapter->stats.bprch += bcast_h;\r\n} else {\r\nadapter->stats.mprcl += IXGB_READ_REG(&adapter->hw, MPRCL);\r\nadapter->stats.mprch += IXGB_READ_REG(&adapter->hw, MPRCH);\r\nadapter->stats.bprcl += IXGB_READ_REG(&adapter->hw, BPRCL);\r\nadapter->stats.bprch += IXGB_READ_REG(&adapter->hw, BPRCH);\r\n}\r\nadapter->stats.tprl += IXGB_READ_REG(&adapter->hw, TPRL);\r\nadapter->stats.tprh += IXGB_READ_REG(&adapter->hw, TPRH);\r\nadapter->stats.gprcl += IXGB_READ_REG(&adapter->hw, GPRCL);\r\nadapter->stats.gprch += IXGB_READ_REG(&adapter->hw, GPRCH);\r\nadapter->stats.uprcl += IXGB_READ_REG(&adapter->hw, UPRCL);\r\nadapter->stats.uprch += IXGB_READ_REG(&adapter->hw, UPRCH);\r\nadapter->stats.vprcl += IXGB_READ_REG(&adapter->hw, VPRCL);\r\nadapter->stats.vprch += IXGB_READ_REG(&adapter->hw, VPRCH);\r\nadapter->stats.jprcl += IXGB_READ_REG(&adapter->hw, JPRCL);\r\nadapter->stats.jprch += IXGB_READ_REG(&adapter->hw, JPRCH);\r\nadapter->stats.gorcl += IXGB_READ_REG(&adapter->hw, GORCL);\r\nadapter->stats.gorch += IXGB_READ_REG(&adapter->hw, GORCH);\r\nadapter->stats.torl += IXGB_READ_REG(&adapter->hw, TORL);\r\nadapter->stats.torh += IXGB_READ_REG(&adapter->hw, TORH);\r\nadapter->stats.rnbc += IXGB_READ_REG(&adapter->hw, RNBC);\r\nadapter->stats.ruc += IXGB_READ_REG(&adapter->hw, RUC);\r\nadapter->stats.roc += IXGB_READ_REG(&adapter->hw, ROC);\r\nadapter->stats.rlec += IXGB_READ_REG(&adapter->hw, RLEC);\r\nadapter->stats.crcerrs += IXGB_READ_REG(&adapter->hw, CRCERRS);\r\nadapter->stats.icbc += IXGB_READ_REG(&adapter->hw, ICBC);\r\nadapter->stats.ecbc += IXGB_READ_REG(&adapter->hw, ECBC);\r\nadapter->stats.mpc += IXGB_READ_REG(&adapter->hw, MPC);\r\nadapter->stats.tptl += IXGB_READ_REG(&adapter->hw, TPTL);\r\nadapter->stats.tpth += IXGB_READ_REG(&adapter->hw, TPTH);\r\nadapter->stats.gptcl += IXGB_READ_REG(&adapter->hw, GPTCL);\r\nadapter->stats.gptch += IXGB_READ_REG(&adapter->hw, GPTCH);\r\nadapter->stats.bptcl += IXGB_READ_REG(&adapter->hw, BPTCL);\r\nadapter->stats.bptch += IXGB_READ_REG(&adapter->hw, BPTCH);\r\nadapter->stats.mptcl += IXGB_READ_REG(&adapter->hw, MPTCL);\r\nadapter->stats.mptch += IXGB_READ_REG(&adapter->hw, MPTCH);\r\nadapter->stats.uptcl += IXGB_READ_REG(&adapter->hw, UPTCL);\r\nadapter->stats.uptch += IXGB_READ_REG(&adapter->hw, UPTCH);\r\nadapter->stats.vptcl += IXGB_READ_REG(&adapter->hw, VPTCL);\r\nadapter->stats.vptch += IXGB_READ_REG(&adapter->hw, VPTCH);\r\nadapter->stats.jptcl += IXGB_READ_REG(&adapter->hw, JPTCL);\r\nadapter->stats.jptch += IXGB_READ_REG(&adapter->hw, JPTCH);\r\nadapter->stats.gotcl += IXGB_READ_REG(&adapter->hw, GOTCL);\r\nadapter->stats.gotch += IXGB_READ_REG(&adapter->hw, GOTCH);\r\nadapter->stats.totl += IXGB_READ_REG(&adapter->hw, TOTL);\r\nadapter->stats.toth += IXGB_READ_REG(&adapter->hw, TOTH);\r\nadapter->stats.dc += IXGB_READ_REG(&adapter->hw, DC);\r\nadapter->stats.plt64c += IXGB_READ_REG(&adapter->hw, PLT64C);\r\nadapter->stats.tsctc += IXGB_READ_REG(&adapter->hw, TSCTC);\r\nadapter->stats.tsctfc += IXGB_READ_REG(&adapter->hw, TSCTFC);\r\nadapter->stats.ibic += IXGB_READ_REG(&adapter->hw, IBIC);\r\nadapter->stats.rfc += IXGB_READ_REG(&adapter->hw, RFC);\r\nadapter->stats.lfc += IXGB_READ_REG(&adapter->hw, LFC);\r\nadapter->stats.pfrc += IXGB_READ_REG(&adapter->hw, PFRC);\r\nadapter->stats.pftc += IXGB_READ_REG(&adapter->hw, PFTC);\r\nadapter->stats.mcfrc += IXGB_READ_REG(&adapter->hw, MCFRC);\r\nadapter->stats.mcftc += IXGB_READ_REG(&adapter->hw, MCFTC);\r\nadapter->stats.xonrxc += IXGB_READ_REG(&adapter->hw, XONRXC);\r\nadapter->stats.xontxc += IXGB_READ_REG(&adapter->hw, XONTXC);\r\nadapter->stats.xoffrxc += IXGB_READ_REG(&adapter->hw, XOFFRXC);\r\nadapter->stats.xofftxc += IXGB_READ_REG(&adapter->hw, XOFFTXC);\r\nadapter->stats.rjc += IXGB_READ_REG(&adapter->hw, RJC);\r\nnetdev->stats.rx_packets = adapter->stats.gprcl;\r\nnetdev->stats.tx_packets = adapter->stats.gptcl;\r\nnetdev->stats.rx_bytes = adapter->stats.gorcl;\r\nnetdev->stats.tx_bytes = adapter->stats.gotcl;\r\nnetdev->stats.multicast = adapter->stats.mprcl;\r\nnetdev->stats.collisions = 0;\r\nnetdev->stats.rx_errors =\r\nadapter->stats.crcerrs +\r\nadapter->stats.ruc +\r\nadapter->stats.roc +\r\nadapter->stats.icbc +\r\nadapter->stats.ecbc + adapter->stats.mpc;\r\nnetdev->stats.rx_crc_errors = adapter->stats.crcerrs;\r\nnetdev->stats.rx_fifo_errors = adapter->stats.mpc;\r\nnetdev->stats.rx_missed_errors = adapter->stats.mpc;\r\nnetdev->stats.rx_over_errors = adapter->stats.mpc;\r\nnetdev->stats.tx_errors = 0;\r\nnetdev->stats.rx_frame_errors = 0;\r\nnetdev->stats.tx_aborted_errors = 0;\r\nnetdev->stats.tx_carrier_errors = 0;\r\nnetdev->stats.tx_fifo_errors = 0;\r\nnetdev->stats.tx_heartbeat_errors = 0;\r\nnetdev->stats.tx_window_errors = 0;\r\n}\r\nstatic irqreturn_t\r\nixgb_intr(int irq, void *data)\r\n{\r\nstruct net_device *netdev = data;\r\nstruct ixgb_adapter *adapter = netdev_priv(netdev);\r\nstruct ixgb_hw *hw = &adapter->hw;\r\nu32 icr = IXGB_READ_REG(hw, ICR);\r\nif (unlikely(!icr))\r\nreturn IRQ_NONE;\r\nif (unlikely(icr & (IXGB_INT_RXSEQ | IXGB_INT_LSC)))\r\nif (!test_bit(__IXGB_DOWN, &adapter->flags))\r\nmod_timer(&adapter->watchdog_timer, jiffies);\r\nif (napi_schedule_prep(&adapter->napi)) {\r\nIXGB_WRITE_REG(&adapter->hw, IMC, ~0);\r\n__napi_schedule(&adapter->napi);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int\r\nixgb_clean(struct napi_struct *napi, int budget)\r\n{\r\nstruct ixgb_adapter *adapter = container_of(napi, struct ixgb_adapter, napi);\r\nint work_done = 0;\r\nixgb_clean_tx_irq(adapter);\r\nixgb_clean_rx_irq(adapter, &work_done, budget);\r\nif (work_done < budget) {\r\nnapi_complete(napi);\r\nif (!test_bit(__IXGB_DOWN, &adapter->flags))\r\nixgb_irq_enable(adapter);\r\n}\r\nreturn work_done;\r\n}\r\nstatic bool\r\nixgb_clean_tx_irq(struct ixgb_adapter *adapter)\r\n{\r\nstruct ixgb_desc_ring *tx_ring = &adapter->tx_ring;\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct ixgb_tx_desc *tx_desc, *eop_desc;\r\nstruct ixgb_buffer *buffer_info;\r\nunsigned int i, eop;\r\nbool cleaned = false;\r\ni = tx_ring->next_to_clean;\r\neop = tx_ring->buffer_info[i].next_to_watch;\r\neop_desc = IXGB_TX_DESC(*tx_ring, eop);\r\nwhile (eop_desc->status & IXGB_TX_DESC_STATUS_DD) {\r\nrmb();\r\nfor (cleaned = false; !cleaned; ) {\r\ntx_desc = IXGB_TX_DESC(*tx_ring, i);\r\nbuffer_info = &tx_ring->buffer_info[i];\r\nif (tx_desc->popts &\r\n(IXGB_TX_DESC_POPTS_TXSM |\r\nIXGB_TX_DESC_POPTS_IXSM))\r\nadapter->hw_csum_tx_good++;\r\nixgb_unmap_and_free_tx_resource(adapter, buffer_info);\r\n*(u32 *)&(tx_desc->status) = 0;\r\ncleaned = (i == eop);\r\nif (++i == tx_ring->count) i = 0;\r\n}\r\neop = tx_ring->buffer_info[i].next_to_watch;\r\neop_desc = IXGB_TX_DESC(*tx_ring, eop);\r\n}\r\ntx_ring->next_to_clean = i;\r\nif (unlikely(cleaned && netif_carrier_ok(netdev) &&\r\nIXGB_DESC_UNUSED(tx_ring) >= DESC_NEEDED)) {\r\nsmp_mb();\r\nif (netif_queue_stopped(netdev) &&\r\n!(test_bit(__IXGB_DOWN, &adapter->flags))) {\r\nnetif_wake_queue(netdev);\r\n++adapter->restart_queue;\r\n}\r\n}\r\nif (adapter->detect_tx_hung) {\r\nadapter->detect_tx_hung = false;\r\nif (tx_ring->buffer_info[eop].time_stamp &&\r\ntime_after(jiffies, tx_ring->buffer_info[eop].time_stamp + HZ)\r\n&& !(IXGB_READ_REG(&adapter->hw, STATUS) &\r\nIXGB_STATUS_TXOFF)) {\r\nnetif_err(adapter, drv, adapter->netdev,\r\n"Detected Tx Unit Hang\n"\r\n" TDH <%x>\n"\r\n" TDT <%x>\n"\r\n" next_to_use <%x>\n"\r\n" next_to_clean <%x>\n"\r\n"buffer_info[next_to_clean]\n"\r\n" time_stamp <%lx>\n"\r\n" next_to_watch <%x>\n"\r\n" jiffies <%lx>\n"\r\n" next_to_watch.status <%x>\n",\r\nIXGB_READ_REG(&adapter->hw, TDH),\r\nIXGB_READ_REG(&adapter->hw, TDT),\r\ntx_ring->next_to_use,\r\ntx_ring->next_to_clean,\r\ntx_ring->buffer_info[eop].time_stamp,\r\neop,\r\njiffies,\r\neop_desc->status);\r\nnetif_stop_queue(netdev);\r\n}\r\n}\r\nreturn cleaned;\r\n}\r\nstatic void\r\nixgb_rx_checksum(struct ixgb_adapter *adapter,\r\nstruct ixgb_rx_desc *rx_desc,\r\nstruct sk_buff *skb)\r\n{\r\nif ((rx_desc->status & IXGB_RX_DESC_STATUS_IXSM) ||\r\n(!(rx_desc->status & IXGB_RX_DESC_STATUS_TCPCS))) {\r\nskb_checksum_none_assert(skb);\r\nreturn;\r\n}\r\nif (rx_desc->errors & IXGB_RX_DESC_ERRORS_TCPE) {\r\nskb_checksum_none_assert(skb);\r\nadapter->hw_csum_rx_error++;\r\n} else {\r\nskb->ip_summed = CHECKSUM_UNNECESSARY;\r\nadapter->hw_csum_rx_good++;\r\n}\r\n}\r\nstatic void ixgb_check_copybreak(struct net_device *netdev,\r\nstruct ixgb_buffer *buffer_info,\r\nu32 length, struct sk_buff **skb)\r\n{\r\nstruct sk_buff *new_skb;\r\nif (length > copybreak)\r\nreturn;\r\nnew_skb = netdev_alloc_skb_ip_align(netdev, length);\r\nif (!new_skb)\r\nreturn;\r\nskb_copy_to_linear_data_offset(new_skb, -NET_IP_ALIGN,\r\n(*skb)->data - NET_IP_ALIGN,\r\nlength + NET_IP_ALIGN);\r\nbuffer_info->skb = *skb;\r\n*skb = new_skb;\r\n}\r\nstatic bool\r\nixgb_clean_rx_irq(struct ixgb_adapter *adapter, int *work_done, int work_to_do)\r\n{\r\nstruct ixgb_desc_ring *rx_ring = &adapter->rx_ring;\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nstruct ixgb_rx_desc *rx_desc, *next_rxd;\r\nstruct ixgb_buffer *buffer_info, *next_buffer, *next2_buffer;\r\nu32 length;\r\nunsigned int i, j;\r\nint cleaned_count = 0;\r\nbool cleaned = false;\r\ni = rx_ring->next_to_clean;\r\nrx_desc = IXGB_RX_DESC(*rx_ring, i);\r\nbuffer_info = &rx_ring->buffer_info[i];\r\nwhile (rx_desc->status & IXGB_RX_DESC_STATUS_DD) {\r\nstruct sk_buff *skb;\r\nu8 status;\r\nif (*work_done >= work_to_do)\r\nbreak;\r\n(*work_done)++;\r\nrmb();\r\nstatus = rx_desc->status;\r\nskb = buffer_info->skb;\r\nbuffer_info->skb = NULL;\r\nprefetch(skb->data - NET_IP_ALIGN);\r\nif (++i == rx_ring->count)\r\ni = 0;\r\nnext_rxd = IXGB_RX_DESC(*rx_ring, i);\r\nprefetch(next_rxd);\r\nj = i + 1;\r\nif (j == rx_ring->count)\r\nj = 0;\r\nnext2_buffer = &rx_ring->buffer_info[j];\r\nprefetch(next2_buffer);\r\nnext_buffer = &rx_ring->buffer_info[i];\r\ncleaned = true;\r\ncleaned_count++;\r\ndma_unmap_single(&pdev->dev,\r\nbuffer_info->dma,\r\nbuffer_info->length,\r\nDMA_FROM_DEVICE);\r\nbuffer_info->dma = 0;\r\nlength = le16_to_cpu(rx_desc->length);\r\nrx_desc->length = 0;\r\nif (unlikely(!(status & IXGB_RX_DESC_STATUS_EOP))) {\r\npr_debug("Receive packet consumed multiple buffers length<%x>\n",\r\nlength);\r\ndev_kfree_skb_irq(skb);\r\ngoto rxdesc_done;\r\n}\r\nif (unlikely(rx_desc->errors &\r\n(IXGB_RX_DESC_ERRORS_CE | IXGB_RX_DESC_ERRORS_SE |\r\nIXGB_RX_DESC_ERRORS_P | IXGB_RX_DESC_ERRORS_RXE))) {\r\ndev_kfree_skb_irq(skb);\r\ngoto rxdesc_done;\r\n}\r\nixgb_check_copybreak(netdev, buffer_info, length, &skb);\r\nskb_put(skb, length);\r\nixgb_rx_checksum(adapter, rx_desc, skb);\r\nskb->protocol = eth_type_trans(skb, netdev);\r\nif (status & IXGB_RX_DESC_STATUS_VP)\r\n__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q),\r\nle16_to_cpu(rx_desc->special));\r\nnetif_receive_skb(skb);\r\nrxdesc_done:\r\nrx_desc->status = 0;\r\nif (unlikely(cleaned_count >= IXGB_RX_BUFFER_WRITE)) {\r\nixgb_alloc_rx_buffers(adapter, cleaned_count);\r\ncleaned_count = 0;\r\n}\r\nrx_desc = next_rxd;\r\nbuffer_info = next_buffer;\r\n}\r\nrx_ring->next_to_clean = i;\r\ncleaned_count = IXGB_DESC_UNUSED(rx_ring);\r\nif (cleaned_count)\r\nixgb_alloc_rx_buffers(adapter, cleaned_count);\r\nreturn cleaned;\r\n}\r\nstatic void\r\nixgb_alloc_rx_buffers(struct ixgb_adapter *adapter, int cleaned_count)\r\n{\r\nstruct ixgb_desc_ring *rx_ring = &adapter->rx_ring;\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nstruct ixgb_rx_desc *rx_desc;\r\nstruct ixgb_buffer *buffer_info;\r\nstruct sk_buff *skb;\r\nunsigned int i;\r\nlong cleancount;\r\ni = rx_ring->next_to_use;\r\nbuffer_info = &rx_ring->buffer_info[i];\r\ncleancount = IXGB_DESC_UNUSED(rx_ring);\r\nwhile (--cleancount > 2 && cleaned_count--) {\r\nskb = buffer_info->skb;\r\nif (skb) {\r\nskb_trim(skb, 0);\r\ngoto map_skb;\r\n}\r\nskb = netdev_alloc_skb_ip_align(netdev, adapter->rx_buffer_len);\r\nif (unlikely(!skb)) {\r\nadapter->alloc_rx_buff_failed++;\r\nbreak;\r\n}\r\nbuffer_info->skb = skb;\r\nbuffer_info->length = adapter->rx_buffer_len;\r\nmap_skb:\r\nbuffer_info->dma = dma_map_single(&pdev->dev,\r\nskb->data,\r\nadapter->rx_buffer_len,\r\nDMA_FROM_DEVICE);\r\nif (dma_mapping_error(&pdev->dev, buffer_info->dma)) {\r\nadapter->alloc_rx_buff_failed++;\r\nbreak;\r\n}\r\nrx_desc = IXGB_RX_DESC(*rx_ring, i);\r\nrx_desc->buff_addr = cpu_to_le64(buffer_info->dma);\r\nrx_desc->status = 0;\r\nif (++i == rx_ring->count)\r\ni = 0;\r\nbuffer_info = &rx_ring->buffer_info[i];\r\n}\r\nif (likely(rx_ring->next_to_use != i)) {\r\nrx_ring->next_to_use = i;\r\nif (unlikely(i-- == 0))\r\ni = (rx_ring->count - 1);\r\nwmb();\r\nIXGB_WRITE_REG(&adapter->hw, RDT, i);\r\n}\r\n}\r\nstatic void\r\nixgb_vlan_strip_enable(struct ixgb_adapter *adapter)\r\n{\r\nu32 ctrl;\r\nctrl = IXGB_READ_REG(&adapter->hw, CTRL0);\r\nctrl |= IXGB_CTRL0_VME;\r\nIXGB_WRITE_REG(&adapter->hw, CTRL0, ctrl);\r\n}\r\nstatic void\r\nixgb_vlan_strip_disable(struct ixgb_adapter *adapter)\r\n{\r\nu32 ctrl;\r\nctrl = IXGB_READ_REG(&adapter->hw, CTRL0);\r\nctrl &= ~IXGB_CTRL0_VME;\r\nIXGB_WRITE_REG(&adapter->hw, CTRL0, ctrl);\r\n}\r\nstatic int\r\nixgb_vlan_rx_add_vid(struct net_device *netdev, __be16 proto, u16 vid)\r\n{\r\nstruct ixgb_adapter *adapter = netdev_priv(netdev);\r\nu32 vfta, index;\r\nindex = (vid >> 5) & 0x7F;\r\nvfta = IXGB_READ_REG_ARRAY(&adapter->hw, VFTA, index);\r\nvfta |= (1 << (vid & 0x1F));\r\nixgb_write_vfta(&adapter->hw, index, vfta);\r\nset_bit(vid, adapter->active_vlans);\r\nreturn 0;\r\n}\r\nstatic int\r\nixgb_vlan_rx_kill_vid(struct net_device *netdev, __be16 proto, u16 vid)\r\n{\r\nstruct ixgb_adapter *adapter = netdev_priv(netdev);\r\nu32 vfta, index;\r\nindex = (vid >> 5) & 0x7F;\r\nvfta = IXGB_READ_REG_ARRAY(&adapter->hw, VFTA, index);\r\nvfta &= ~(1 << (vid & 0x1F));\r\nixgb_write_vfta(&adapter->hw, index, vfta);\r\nclear_bit(vid, adapter->active_vlans);\r\nreturn 0;\r\n}\r\nstatic void\r\nixgb_restore_vlan(struct ixgb_adapter *adapter)\r\n{\r\nu16 vid;\r\nfor_each_set_bit(vid, adapter->active_vlans, VLAN_N_VID)\r\nixgb_vlan_rx_add_vid(adapter->netdev, htons(ETH_P_8021Q), vid);\r\n}\r\nstatic void ixgb_netpoll(struct net_device *dev)\r\n{\r\nstruct ixgb_adapter *adapter = netdev_priv(dev);\r\ndisable_irq(adapter->pdev->irq);\r\nixgb_intr(adapter->pdev->irq, dev);\r\nenable_irq(adapter->pdev->irq);\r\n}\r\nstatic pci_ers_result_t ixgb_io_error_detected(struct pci_dev *pdev,\r\nenum pci_channel_state state)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct ixgb_adapter *adapter = netdev_priv(netdev);\r\nnetif_device_detach(netdev);\r\nif (state == pci_channel_io_perm_failure)\r\nreturn PCI_ERS_RESULT_DISCONNECT;\r\nif (netif_running(netdev))\r\nixgb_down(adapter, true);\r\npci_disable_device(pdev);\r\nreturn PCI_ERS_RESULT_NEED_RESET;\r\n}\r\nstatic pci_ers_result_t ixgb_io_slot_reset(struct pci_dev *pdev)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct ixgb_adapter *adapter = netdev_priv(netdev);\r\nif (pci_enable_device(pdev)) {\r\nnetif_err(adapter, probe, adapter->netdev,\r\n"Cannot re-enable PCI device after reset\n");\r\nreturn PCI_ERS_RESULT_DISCONNECT;\r\n}\r\nif (0 != PCI_FUNC (pdev->devfn))\r\nreturn PCI_ERS_RESULT_RECOVERED;\r\npci_set_master(pdev);\r\nnetif_carrier_off(netdev);\r\nnetif_stop_queue(netdev);\r\nixgb_reset(adapter);\r\nif (!ixgb_validate_eeprom_checksum(&adapter->hw)) {\r\nnetif_err(adapter, probe, adapter->netdev,\r\n"After reset, the EEPROM checksum is not valid\n");\r\nreturn PCI_ERS_RESULT_DISCONNECT;\r\n}\r\nixgb_get_ee_mac_addr(&adapter->hw, netdev->dev_addr);\r\nmemcpy(netdev->perm_addr, netdev->dev_addr, netdev->addr_len);\r\nif (!is_valid_ether_addr(netdev->perm_addr)) {\r\nnetif_err(adapter, probe, adapter->netdev,\r\n"After reset, invalid MAC address\n");\r\nreturn PCI_ERS_RESULT_DISCONNECT;\r\n}\r\nreturn PCI_ERS_RESULT_RECOVERED;\r\n}\r\nstatic void ixgb_io_resume(struct pci_dev *pdev)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct ixgb_adapter *adapter = netdev_priv(netdev);\r\npci_set_master(pdev);\r\nif (netif_running(netdev)) {\r\nif (ixgb_up(adapter)) {\r\npr_err("can't bring device back up after reset\n");\r\nreturn;\r\n}\r\n}\r\nnetif_device_attach(netdev);\r\nmod_timer(&adapter->watchdog_timer, jiffies);\r\n}
