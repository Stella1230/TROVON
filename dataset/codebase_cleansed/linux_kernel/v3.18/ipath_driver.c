const char *ipath_get_unit_name(int unit)\r\n{\r\nstatic char iname[16];\r\nsnprintf(iname, sizeof iname, "infinipath%u", unit);\r\nreturn iname;\r\n}\r\nstatic inline void read_bars(struct ipath_devdata *dd, struct pci_dev *dev,\r\nu32 *bar0, u32 *bar1)\r\n{\r\nint ret;\r\nret = pci_read_config_dword(dev, PCI_BASE_ADDRESS_0, bar0);\r\nif (ret)\r\nipath_dev_err(dd, "failed to read bar0 before enable: "\r\n"error %d\n", -ret);\r\nret = pci_read_config_dword(dev, PCI_BASE_ADDRESS_1, bar1);\r\nif (ret)\r\nipath_dev_err(dd, "failed to read bar1 before enable: "\r\n"error %d\n", -ret);\r\nipath_dbg("Read bar0 %x bar1 %x\n", *bar0, *bar1);\r\n}\r\nstatic void ipath_free_devdata(struct pci_dev *pdev,\r\nstruct ipath_devdata *dd)\r\n{\r\nunsigned long flags;\r\npci_set_drvdata(pdev, NULL);\r\nif (dd->ipath_unit != -1) {\r\nspin_lock_irqsave(&ipath_devs_lock, flags);\r\nidr_remove(&unit_table, dd->ipath_unit);\r\nlist_del(&dd->ipath_list);\r\nspin_unlock_irqrestore(&ipath_devs_lock, flags);\r\n}\r\nvfree(dd);\r\n}\r\nstatic struct ipath_devdata *ipath_alloc_devdata(struct pci_dev *pdev)\r\n{\r\nunsigned long flags;\r\nstruct ipath_devdata *dd;\r\nint ret;\r\ndd = vzalloc(sizeof(*dd));\r\nif (!dd) {\r\ndd = ERR_PTR(-ENOMEM);\r\ngoto bail;\r\n}\r\ndd->ipath_unit = -1;\r\nidr_preload(GFP_KERNEL);\r\nspin_lock_irqsave(&ipath_devs_lock, flags);\r\nret = idr_alloc(&unit_table, dd, 0, 0, GFP_NOWAIT);\r\nif (ret < 0) {\r\nprintk(KERN_ERR IPATH_DRV_NAME\r\n": Could not allocate unit ID: error %d\n", -ret);\r\nipath_free_devdata(pdev, dd);\r\ndd = ERR_PTR(ret);\r\ngoto bail_unlock;\r\n}\r\ndd->ipath_unit = ret;\r\ndd->pcidev = pdev;\r\npci_set_drvdata(pdev, dd);\r\nlist_add(&dd->ipath_list, &ipath_dev_list);\r\nbail_unlock:\r\nspin_unlock_irqrestore(&ipath_devs_lock, flags);\r\nidr_preload_end();\r\nbail:\r\nreturn dd;\r\n}\r\nstatic inline struct ipath_devdata *__ipath_lookup(int unit)\r\n{\r\nreturn idr_find(&unit_table, unit);\r\n}\r\nstruct ipath_devdata *ipath_lookup(int unit)\r\n{\r\nstruct ipath_devdata *dd;\r\nunsigned long flags;\r\nspin_lock_irqsave(&ipath_devs_lock, flags);\r\ndd = __ipath_lookup(unit);\r\nspin_unlock_irqrestore(&ipath_devs_lock, flags);\r\nreturn dd;\r\n}\r\nint ipath_count_units(int *npresentp, int *nupp, int *maxportsp)\r\n{\r\nint nunits, npresent, nup;\r\nstruct ipath_devdata *dd;\r\nunsigned long flags;\r\nint maxports;\r\nnunits = npresent = nup = maxports = 0;\r\nspin_lock_irqsave(&ipath_devs_lock, flags);\r\nlist_for_each_entry(dd, &ipath_dev_list, ipath_list) {\r\nnunits++;\r\nif ((dd->ipath_flags & IPATH_PRESENT) && dd->ipath_kregbase)\r\nnpresent++;\r\nif (dd->ipath_lid &&\r\n!(dd->ipath_flags & (IPATH_DISABLED | IPATH_LINKDOWN\r\n| IPATH_LINKUNK)))\r\nnup++;\r\nif (dd->ipath_cfgports > maxports)\r\nmaxports = dd->ipath_cfgports;\r\n}\r\nspin_unlock_irqrestore(&ipath_devs_lock, flags);\r\nif (npresentp)\r\n*npresentp = npresent;\r\nif (nupp)\r\n*nupp = nup;\r\nif (maxportsp)\r\n*maxportsp = maxports;\r\nreturn nunits;\r\n}\r\nstatic void ipath_verify_pioperf(struct ipath_devdata *dd)\r\n{\r\nu32 pbnum, cnt, lcnt;\r\nu32 __iomem *piobuf;\r\nu32 *addr;\r\nu64 msecs, emsecs;\r\npiobuf = ipath_getpiobuf(dd, 0, &pbnum);\r\nif (!piobuf) {\r\ndev_info(&dd->pcidev->dev,\r\n"No PIObufs for checking perf, skipping\n");\r\nreturn;\r\n}\r\ncnt = 1024;\r\naddr = vmalloc(cnt);\r\nif (!addr) {\r\ndev_info(&dd->pcidev->dev,\r\n"Couldn't get memory for checking PIO perf,"\r\n" skipping\n");\r\ngoto done;\r\n}\r\npreempt_disable();\r\nmsecs = 1 + jiffies_to_msecs(jiffies);\r\nfor (lcnt = 0; lcnt < 10000U; lcnt++) {\r\nif (jiffies_to_msecs(jiffies) >= msecs)\r\nbreak;\r\nudelay(1);\r\n}\r\nipath_disable_armlaunch(dd);\r\nif ((dd->ipath_flags & IPATH_HAS_PBC_CNT))\r\nwriteq(1UL << 63, piobuf);\r\nelse\r\nwriteq(0, piobuf);\r\nipath_flush_wc();\r\nmsecs = jiffies_to_msecs(jiffies);\r\nfor (emsecs = lcnt = 0; emsecs <= 5UL; lcnt++) {\r\n__iowrite32_copy(piobuf + 64, addr, cnt >> 2);\r\nemsecs = jiffies_to_msecs(jiffies) - msecs;\r\n}\r\nif (lcnt < (emsecs * 1024U))\r\nipath_dev_err(dd,\r\n"Performance problem: bandwidth to PIO buffers is "\r\n"only %u MiB/sec\n",\r\nlcnt / (u32) emsecs);\r\nelse\r\nipath_dbg("PIO buffer bandwidth %u MiB/sec is OK\n",\r\nlcnt / (u32) emsecs);\r\npreempt_enable();\r\nvfree(addr);\r\ndone:\r\nipath_disarm_piobufs(dd, pbnum, 1);\r\nipath_enable_armlaunch(dd);\r\n}\r\nstatic int ipath_init_one(struct pci_dev *pdev, const struct pci_device_id *ent)\r\n{\r\nint ret, len, j;\r\nstruct ipath_devdata *dd;\r\nunsigned long long addr;\r\nu32 bar0 = 0, bar1 = 0;\r\ndd = ipath_alloc_devdata(pdev);\r\nif (IS_ERR(dd)) {\r\nret = PTR_ERR(dd);\r\nprintk(KERN_ERR IPATH_DRV_NAME\r\n": Could not allocate devdata: error %d\n", -ret);\r\ngoto bail;\r\n}\r\nipath_cdbg(VERBOSE, "initializing unit #%u\n", dd->ipath_unit);\r\nret = pci_enable_device(pdev);\r\nif (ret) {\r\nipath_dev_err(dd, "enable unit %d failed: error %d\n",\r\ndd->ipath_unit, -ret);\r\ngoto bail_devdata;\r\n}\r\naddr = pci_resource_start(pdev, 0);\r\nlen = pci_resource_len(pdev, 0);\r\nipath_cdbg(VERBOSE, "regbase (0) %llx len %d irq %d, vend %x/%x "\r\n"driver_data %lx\n", addr, len, pdev->irq, ent->vendor,\r\nent->device, ent->driver_data);\r\nread_bars(dd, pdev, &bar0, &bar1);\r\nif (!bar1 && !(bar0 & ~0xf)) {\r\nif (addr) {\r\ndev_info(&pdev->dev, "BAR is 0 (probable RESET), "\r\n"rewriting as %llx\n", addr);\r\nret = pci_write_config_dword(\r\npdev, PCI_BASE_ADDRESS_0, addr);\r\nif (ret) {\r\nipath_dev_err(dd, "rewrite of BAR0 "\r\n"failed: err %d\n", -ret);\r\ngoto bail_disable;\r\n}\r\nret = pci_write_config_dword(\r\npdev, PCI_BASE_ADDRESS_1, addr >> 32);\r\nif (ret) {\r\nipath_dev_err(dd, "rewrite of BAR1 "\r\n"failed: err %d\n", -ret);\r\ngoto bail_disable;\r\n}\r\n} else {\r\nipath_dev_err(dd, "BAR is 0 (probable RESET), "\r\n"not usable until reboot\n");\r\nret = -ENODEV;\r\ngoto bail_disable;\r\n}\r\n}\r\nret = pci_request_regions(pdev, IPATH_DRV_NAME);\r\nif (ret) {\r\ndev_info(&pdev->dev, "pci_request_regions unit %u fails: "\r\n"err %d\n", dd->ipath_unit, -ret);\r\ngoto bail_disable;\r\n}\r\nret = pci_set_dma_mask(pdev, DMA_BIT_MASK(64));\r\nif (ret) {\r\nret = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (ret) {\r\ndev_info(&pdev->dev,\r\n"Unable to set DMA mask for unit %u: %d\n",\r\ndd->ipath_unit, ret);\r\ngoto bail_regions;\r\n}\r\nelse {\r\nipath_dbg("No 64bit DMA mask, used 32 bit mask\n");\r\nret = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (ret)\r\ndev_info(&pdev->dev,\r\n"Unable to set DMA consistent mask "\r\n"for unit %u: %d\n",\r\ndd->ipath_unit, ret);\r\n}\r\n}\r\nelse {\r\nret = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));\r\nif (ret)\r\ndev_info(&pdev->dev,\r\n"Unable to set DMA consistent mask "\r\n"for unit %u: %d\n",\r\ndd->ipath_unit, ret);\r\n}\r\npci_set_master(pdev);\r\ndd->ipath_pcibar0 = addr;\r\ndd->ipath_pcibar1 = addr >> 32;\r\ndd->ipath_deviceid = ent->device;\r\ndd->ipath_vendorid = ent->vendor;\r\nswitch (ent->device) {\r\ncase PCI_DEVICE_ID_INFINIPATH_HT:\r\nipath_init_iba6110_funcs(dd);\r\nbreak;\r\ndefault:\r\nipath_dev_err(dd, "Found unknown QLogic deviceid 0x%x, "\r\n"failing\n", ent->device);\r\nreturn -ENODEV;\r\n}\r\nfor (j = 0; j < 6; j++) {\r\nif (!pdev->resource[j].start)\r\ncontinue;\r\nipath_cdbg(VERBOSE, "BAR %d %pR, len %llx\n",\r\nj, &pdev->resource[j],\r\n(unsigned long long)pci_resource_len(pdev, j));\r\n}\r\nif (!addr) {\r\nipath_dev_err(dd, "No valid address in BAR 0!\n");\r\nret = -ENODEV;\r\ngoto bail_regions;\r\n}\r\ndd->ipath_pcirev = pdev->revision;\r\n#if defined(__powerpc__)\r\ndd->ipath_kregbase = __ioremap(addr, len,\r\n(_PAGE_NO_CACHE|_PAGE_WRITETHRU));\r\n#else\r\ndd->ipath_kregbase = ioremap_nocache(addr, len);\r\n#endif\r\nif (!dd->ipath_kregbase) {\r\nipath_dbg("Unable to map io addr %llx to kvirt, failing\n",\r\naddr);\r\nret = -ENOMEM;\r\ngoto bail_iounmap;\r\n}\r\ndd->ipath_kregend = (u64 __iomem *)\r\n((void __iomem *)dd->ipath_kregbase + len);\r\ndd->ipath_physaddr = addr;\r\nipath_cdbg(VERBOSE, "mapped io addr %llx to kregbase %p\n",\r\naddr, dd->ipath_kregbase);\r\nif (dd->ipath_f_bus(dd, pdev))\r\nipath_dev_err(dd, "Failed to setup config space; "\r\n"continuing anyway\n");\r\nif (!dd->ipath_irq)\r\nipath_dev_err(dd, "irq is 0, BIOS error? Interrupts won't "\r\n"work\n");\r\nelse {\r\nret = request_irq(dd->ipath_irq, ipath_intr, IRQF_SHARED,\r\nIPATH_DRV_NAME, dd);\r\nif (ret) {\r\nipath_dev_err(dd, "Couldn't setup irq handler, "\r\n"irq=%d: %d\n", dd->ipath_irq, ret);\r\ngoto bail_iounmap;\r\n}\r\n}\r\nret = ipath_init_chip(dd, 0);\r\nif (ret)\r\ngoto bail_irqsetup;\r\nret = ipath_enable_wc(dd);\r\nif (ret) {\r\nipath_dev_err(dd, "Write combining not enabled "\r\n"(err %d): performance may be poor\n",\r\n-ret);\r\nret = 0;\r\n}\r\nipath_verify_pioperf(dd);\r\nipath_device_create_group(&pdev->dev, dd);\r\nipathfs_add_device(dd);\r\nipath_user_add(dd);\r\nipath_diag_add(dd);\r\nipath_register_ib_device(dd);\r\ngoto bail;\r\nbail_irqsetup:\r\ncleanup_device(dd);\r\nif (dd->ipath_irq)\r\ndd->ipath_f_free_irq(dd);\r\nif (dd->ipath_f_cleanup)\r\ndd->ipath_f_cleanup(dd);\r\nbail_iounmap:\r\niounmap((volatile void __iomem *) dd->ipath_kregbase);\r\nbail_regions:\r\npci_release_regions(pdev);\r\nbail_disable:\r\npci_disable_device(pdev);\r\nbail_devdata:\r\nipath_free_devdata(pdev, dd);\r\nbail:\r\nreturn ret;\r\n}\r\nstatic void cleanup_device(struct ipath_devdata *dd)\r\n{\r\nint port;\r\nstruct ipath_portdata **tmp;\r\nunsigned long flags;\r\nif (*dd->ipath_statusp & IPATH_STATUS_CHIP_PRESENT) {\r\n*dd->ipath_statusp &= ~IPATH_STATUS_CHIP_PRESENT;\r\nif (dd->ipath_kregbase) {\r\ndd->ipath_kregbase = NULL;\r\ndd->ipath_uregbase = 0;\r\ndd->ipath_sregbase = 0;\r\ndd->ipath_cregbase = 0;\r\ndd->ipath_kregsize = 0;\r\n}\r\nipath_disable_wc(dd);\r\n}\r\nif (dd->ipath_spectriggerhit)\r\ndev_info(&dd->pcidev->dev, "%lu special trigger hits\n",\r\ndd->ipath_spectriggerhit);\r\nif (dd->ipath_pioavailregs_dma) {\r\ndma_free_coherent(&dd->pcidev->dev, PAGE_SIZE,\r\n(void *) dd->ipath_pioavailregs_dma,\r\ndd->ipath_pioavailregs_phys);\r\ndd->ipath_pioavailregs_dma = NULL;\r\n}\r\nif (dd->ipath_dummy_hdrq) {\r\ndma_free_coherent(&dd->pcidev->dev,\r\ndd->ipath_pd[0]->port_rcvhdrq_size,\r\ndd->ipath_dummy_hdrq, dd->ipath_dummy_hdrq_phys);\r\ndd->ipath_dummy_hdrq = NULL;\r\n}\r\nif (dd->ipath_pageshadow) {\r\nstruct page **tmpp = dd->ipath_pageshadow;\r\ndma_addr_t *tmpd = dd->ipath_physshadow;\r\nint i, cnt = 0;\r\nipath_cdbg(VERBOSE, "Unlocking any expTID pages still "\r\n"locked\n");\r\nfor (port = 0; port < dd->ipath_cfgports; port++) {\r\nint port_tidbase = port * dd->ipath_rcvtidcnt;\r\nint maxtid = port_tidbase + dd->ipath_rcvtidcnt;\r\nfor (i = port_tidbase; i < maxtid; i++) {\r\nif (!tmpp[i])\r\ncontinue;\r\npci_unmap_page(dd->pcidev, tmpd[i],\r\nPAGE_SIZE, PCI_DMA_FROMDEVICE);\r\nipath_release_user_pages(&tmpp[i], 1);\r\ntmpp[i] = NULL;\r\ncnt++;\r\n}\r\n}\r\nif (cnt) {\r\nipath_stats.sps_pageunlocks += cnt;\r\nipath_cdbg(VERBOSE, "There were still %u expTID "\r\n"entries locked\n", cnt);\r\n}\r\nif (ipath_stats.sps_pagelocks ||\r\nipath_stats.sps_pageunlocks)\r\nipath_cdbg(VERBOSE, "%llu pages locked, %llu "\r\n"unlocked via ipath_m{un}lock\n",\r\n(unsigned long long)\r\nipath_stats.sps_pagelocks,\r\n(unsigned long long)\r\nipath_stats.sps_pageunlocks);\r\nipath_cdbg(VERBOSE, "Free shadow page tid array at %p\n",\r\ndd->ipath_pageshadow);\r\ntmpp = dd->ipath_pageshadow;\r\ndd->ipath_pageshadow = NULL;\r\nvfree(tmpp);\r\ndd->ipath_egrtidbase = NULL;\r\n}\r\nspin_lock_irqsave(&dd->ipath_uctxt_lock, flags);\r\ntmp = dd->ipath_pd;\r\ndd->ipath_pd = NULL;\r\nspin_unlock_irqrestore(&dd->ipath_uctxt_lock, flags);\r\nfor (port = 0; port < dd->ipath_portcnt; port++) {\r\nstruct ipath_portdata *pd = tmp[port];\r\ntmp[port] = NULL;\r\nipath_free_pddata(dd, pd);\r\n}\r\nkfree(tmp);\r\n}\r\nstatic void ipath_remove_one(struct pci_dev *pdev)\r\n{\r\nstruct ipath_devdata *dd = pci_get_drvdata(pdev);\r\nipath_cdbg(VERBOSE, "removing, pdev=%p, dd=%p\n", pdev, dd);\r\nipath_shutdown_device(dd);\r\nflush_workqueue(ib_wq);\r\nif (dd->verbs_dev)\r\nipath_unregister_ib_device(dd->verbs_dev);\r\nipath_diag_remove(dd);\r\nipath_user_remove(dd);\r\nipathfs_remove_device(dd);\r\nipath_device_remove_group(&pdev->dev, dd);\r\nipath_cdbg(VERBOSE, "Releasing pci memory regions, dd %p, "\r\n"unit %u\n", dd, (u32) dd->ipath_unit);\r\ncleanup_device(dd);\r\nif (dd->ipath_irq) {\r\nipath_cdbg(VERBOSE, "unit %u free irq %d\n",\r\ndd->ipath_unit, dd->ipath_irq);\r\ndd->ipath_f_free_irq(dd);\r\n} else\r\nipath_dbg("irq is 0, not doing free_irq "\r\n"for unit %u\n", dd->ipath_unit);\r\nif (dd->ipath_f_cleanup)\r\ndd->ipath_f_cleanup(dd);\r\nipath_cdbg(VERBOSE, "Unmapping kregbase %p\n", dd->ipath_kregbase);\r\niounmap((volatile void __iomem *) dd->ipath_kregbase);\r\npci_release_regions(pdev);\r\nipath_cdbg(VERBOSE, "calling pci_disable_device\n");\r\npci_disable_device(pdev);\r\nipath_free_devdata(pdev, dd);\r\n}\r\nvoid ipath_disarm_piobufs(struct ipath_devdata *dd, unsigned first,\r\nunsigned cnt)\r\n{\r\nunsigned i, last = first + cnt;\r\nunsigned long flags;\r\nipath_cdbg(PKT, "disarm %u PIObufs first=%u\n", cnt, first);\r\nfor (i = first; i < last; i++) {\r\nspin_lock_irqsave(&dd->ipath_sendctrl_lock, flags);\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_sendctrl,\r\ndd->ipath_sendctrl | INFINIPATH_S_DISARM |\r\n(i << INFINIPATH_S_DISARMPIOBUF_SHIFT));\r\nipath_read_kreg64(dd, dd->ipath_kregs->kr_scratch);\r\nspin_unlock_irqrestore(&dd->ipath_sendctrl_lock, flags);\r\n}\r\nipath_force_pio_avail_update(dd);\r\n}\r\nint ipath_wait_linkstate(struct ipath_devdata *dd, u32 state, int msecs)\r\n{\r\ndd->ipath_state_wanted = state;\r\nwait_event_interruptible_timeout(ipath_state_wait,\r\n(dd->ipath_flags & state),\r\nmsecs_to_jiffies(msecs));\r\ndd->ipath_state_wanted = 0;\r\nif (!(dd->ipath_flags & state)) {\r\nu64 val;\r\nipath_cdbg(VERBOSE, "Didn't reach linkstate %s within %u"\r\n" ms\n",\r\n(state & IPATH_LINKINIT) ? "INIT" :\r\n((state & IPATH_LINKDOWN) ? "DOWN" :\r\n((state & IPATH_LINKARMED) ? "ARM" : "ACTIVE")),\r\nmsecs);\r\nval = ipath_read_kreg64(dd, dd->ipath_kregs->kr_ibcstatus);\r\nipath_cdbg(VERBOSE, "ibcc=%llx ibcstatus=%llx (%s)\n",\r\n(unsigned long long) ipath_read_kreg64(\r\ndd, dd->ipath_kregs->kr_ibcctrl),\r\n(unsigned long long) val,\r\nipath_ibcstatus_str[val & dd->ibcs_lts_mask]);\r\n}\r\nreturn (dd->ipath_flags & state) ? 0 : -ETIMEDOUT;\r\n}\r\nstatic void decode_sdma_errs(struct ipath_devdata *dd, ipath_err_t err,\r\nchar *buf, size_t blen)\r\n{\r\nstatic const struct {\r\nipath_err_t err;\r\nconst char *msg;\r\n} errs[] = {\r\n{ INFINIPATH_E_SDMAGENMISMATCH, "SDmaGenMismatch" },\r\n{ INFINIPATH_E_SDMAOUTOFBOUND, "SDmaOutOfBound" },\r\n{ INFINIPATH_E_SDMATAILOUTOFBOUND, "SDmaTailOutOfBound" },\r\n{ INFINIPATH_E_SDMABASE, "SDmaBase" },\r\n{ INFINIPATH_E_SDMA1STDESC, "SDma1stDesc" },\r\n{ INFINIPATH_E_SDMARPYTAG, "SDmaRpyTag" },\r\n{ INFINIPATH_E_SDMADWEN, "SDmaDwEn" },\r\n{ INFINIPATH_E_SDMAMISSINGDW, "SDmaMissingDw" },\r\n{ INFINIPATH_E_SDMAUNEXPDATA, "SDmaUnexpData" },\r\n{ INFINIPATH_E_SDMADESCADDRMISALIGN, "SDmaDescAddrMisalign" },\r\n{ INFINIPATH_E_SENDBUFMISUSE, "SendBufMisuse" },\r\n{ INFINIPATH_E_SDMADISABLED, "SDmaDisabled" },\r\n};\r\nint i;\r\nint expected;\r\nsize_t bidx = 0;\r\nfor (i = 0; i < ARRAY_SIZE(errs); i++) {\r\nexpected = (errs[i].err != INFINIPATH_E_SDMADISABLED) ? 0 :\r\ntest_bit(IPATH_SDMA_ABORTING, &dd->ipath_sdma_status);\r\nif ((err & errs[i].err) && !expected)\r\nbidx += snprintf(buf + bidx, blen - bidx,\r\n"%s ", errs[i].msg);\r\n}\r\n}\r\nint ipath_decode_err(struct ipath_devdata *dd, char *buf, size_t blen,\r\nipath_err_t err)\r\n{\r\nint iserr = 1;\r\n*buf = '\0';\r\nif (err & INFINIPATH_E_PKTERRS) {\r\nif (!(err & ~INFINIPATH_E_PKTERRS))\r\niserr = 0;\r\nif (ipath_debug & __IPATH_ERRPKTDBG) {\r\nif (err & INFINIPATH_E_REBP)\r\nstrlcat(buf, "EBP ", blen);\r\nif (err & INFINIPATH_E_RVCRC)\r\nstrlcat(buf, "VCRC ", blen);\r\nif (err & INFINIPATH_E_RICRC) {\r\nstrlcat(buf, "CRC ", blen);\r\nerr &= INFINIPATH_E_RICRC;\r\n}\r\nif (err & INFINIPATH_E_RSHORTPKTLEN)\r\nstrlcat(buf, "rshortpktlen ", blen);\r\nif (err & INFINIPATH_E_SDROPPEDDATAPKT)\r\nstrlcat(buf, "sdroppeddatapkt ", blen);\r\nif (err & INFINIPATH_E_SPKTLEN)\r\nstrlcat(buf, "spktlen ", blen);\r\n}\r\nif ((err & INFINIPATH_E_RICRC) &&\r\n!(err&(INFINIPATH_E_RVCRC|INFINIPATH_E_REBP)))\r\nstrlcat(buf, "CRC ", blen);\r\nif (!iserr)\r\ngoto done;\r\n}\r\nif (err & INFINIPATH_E_RHDRLEN)\r\nstrlcat(buf, "rhdrlen ", blen);\r\nif (err & INFINIPATH_E_RBADTID)\r\nstrlcat(buf, "rbadtid ", blen);\r\nif (err & INFINIPATH_E_RBADVERSION)\r\nstrlcat(buf, "rbadversion ", blen);\r\nif (err & INFINIPATH_E_RHDR)\r\nstrlcat(buf, "rhdr ", blen);\r\nif (err & INFINIPATH_E_SENDSPECIALTRIGGER)\r\nstrlcat(buf, "sendspecialtrigger ", blen);\r\nif (err & INFINIPATH_E_RLONGPKTLEN)\r\nstrlcat(buf, "rlongpktlen ", blen);\r\nif (err & INFINIPATH_E_RMAXPKTLEN)\r\nstrlcat(buf, "rmaxpktlen ", blen);\r\nif (err & INFINIPATH_E_RMINPKTLEN)\r\nstrlcat(buf, "rminpktlen ", blen);\r\nif (err & INFINIPATH_E_SMINPKTLEN)\r\nstrlcat(buf, "sminpktlen ", blen);\r\nif (err & INFINIPATH_E_RFORMATERR)\r\nstrlcat(buf, "rformaterr ", blen);\r\nif (err & INFINIPATH_E_RUNSUPVL)\r\nstrlcat(buf, "runsupvl ", blen);\r\nif (err & INFINIPATH_E_RUNEXPCHAR)\r\nstrlcat(buf, "runexpchar ", blen);\r\nif (err & INFINIPATH_E_RIBFLOW)\r\nstrlcat(buf, "ribflow ", blen);\r\nif (err & INFINIPATH_E_SUNDERRUN)\r\nstrlcat(buf, "sunderrun ", blen);\r\nif (err & INFINIPATH_E_SPIOARMLAUNCH)\r\nstrlcat(buf, "spioarmlaunch ", blen);\r\nif (err & INFINIPATH_E_SUNEXPERRPKTNUM)\r\nstrlcat(buf, "sunexperrpktnum ", blen);\r\nif (err & INFINIPATH_E_SDROPPEDSMPPKT)\r\nstrlcat(buf, "sdroppedsmppkt ", blen);\r\nif (err & INFINIPATH_E_SMAXPKTLEN)\r\nstrlcat(buf, "smaxpktlen ", blen);\r\nif (err & INFINIPATH_E_SUNSUPVL)\r\nstrlcat(buf, "sunsupVL ", blen);\r\nif (err & INFINIPATH_E_INVALIDADDR)\r\nstrlcat(buf, "invalidaddr ", blen);\r\nif (err & INFINIPATH_E_RRCVEGRFULL)\r\nstrlcat(buf, "rcvegrfull ", blen);\r\nif (err & INFINIPATH_E_RRCVHDRFULL)\r\nstrlcat(buf, "rcvhdrfull ", blen);\r\nif (err & INFINIPATH_E_IBSTATUSCHANGED)\r\nstrlcat(buf, "ibcstatuschg ", blen);\r\nif (err & INFINIPATH_E_RIBLOSTLINK)\r\nstrlcat(buf, "riblostlink ", blen);\r\nif (err & INFINIPATH_E_HARDWARE)\r\nstrlcat(buf, "hardware ", blen);\r\nif (err & INFINIPATH_E_RESET)\r\nstrlcat(buf, "reset ", blen);\r\nif (err & INFINIPATH_E_SDMAERRS)\r\ndecode_sdma_errs(dd, err, buf, blen);\r\nif (err & INFINIPATH_E_INVALIDEEPCMD)\r\nstrlcat(buf, "invalideepromcmd ", blen);\r\ndone:\r\nreturn iserr;\r\n}\r\nstatic void get_rhf_errstring(u32 err, char *msg, size_t len)\r\n{\r\n*msg = '\0';\r\nif (err & INFINIPATH_RHF_H_ICRCERR)\r\nstrlcat(msg, "icrcerr ", len);\r\nif (err & INFINIPATH_RHF_H_VCRCERR)\r\nstrlcat(msg, "vcrcerr ", len);\r\nif (err & INFINIPATH_RHF_H_PARITYERR)\r\nstrlcat(msg, "parityerr ", len);\r\nif (err & INFINIPATH_RHF_H_LENERR)\r\nstrlcat(msg, "lenerr ", len);\r\nif (err & INFINIPATH_RHF_H_MTUERR)\r\nstrlcat(msg, "mtuerr ", len);\r\nif (err & INFINIPATH_RHF_H_IHDRERR)\r\nstrlcat(msg, "ipathhdrerr ", len);\r\nif (err & INFINIPATH_RHF_H_TIDERR)\r\nstrlcat(msg, "tiderr ", len);\r\nif (err & INFINIPATH_RHF_H_MKERR)\r\nstrlcat(msg, "invalid ipathhdr ", len);\r\nif (err & INFINIPATH_RHF_H_IBERR)\r\nstrlcat(msg, "iberr ", len);\r\nif (err & INFINIPATH_RHF_L_SWA)\r\nstrlcat(msg, "swA ", len);\r\nif (err & INFINIPATH_RHF_L_SWB)\r\nstrlcat(msg, "swB ", len);\r\n}\r\nstatic inline void *ipath_get_egrbuf(struct ipath_devdata *dd, u32 bufnum)\r\n{\r\nreturn dd->ipath_port0_skbinfo ?\r\n(void *) dd->ipath_port0_skbinfo[bufnum].skb->data : NULL;\r\n}\r\nstruct sk_buff *ipath_alloc_skb(struct ipath_devdata *dd,\r\ngfp_t gfp_mask)\r\n{\r\nstruct sk_buff *skb;\r\nu32 len;\r\nlen = dd->ipath_ibmaxlen + 4;\r\nif (dd->ipath_flags & IPATH_4BYTE_TID) {\r\nlen += 2047;\r\n}\r\nskb = __dev_alloc_skb(len, gfp_mask);\r\nif (!skb) {\r\nipath_dev_err(dd, "Failed to allocate skbuff, length %u\n",\r\nlen);\r\ngoto bail;\r\n}\r\nskb_reserve(skb, 4);\r\nif (dd->ipath_flags & IPATH_4BYTE_TID) {\r\nu32 una = (unsigned long)skb->data & 2047;\r\nif (una)\r\nskb_reserve(skb, 2048 - una);\r\n}\r\nbail:\r\nreturn skb;\r\n}\r\nstatic void ipath_rcv_hdrerr(struct ipath_devdata *dd,\r\nu32 eflags,\r\nu32 l,\r\nu32 etail,\r\n__le32 *rhf_addr,\r\nstruct ipath_message_header *hdr)\r\n{\r\nchar emsg[128];\r\nget_rhf_errstring(eflags, emsg, sizeof emsg);\r\nipath_cdbg(PKT, "RHFerrs %x hdrqtail=%x typ=%u "\r\n"tlen=%x opcode=%x egridx=%x: %s\n",\r\neflags, l,\r\nipath_hdrget_rcv_type(rhf_addr),\r\nipath_hdrget_length_in_bytes(rhf_addr),\r\nbe32_to_cpu(hdr->bth[0]) >> 24,\r\netail, emsg);\r\nif (eflags & (INFINIPATH_RHF_H_ICRCERR | INFINIPATH_RHF_H_VCRCERR)) {\r\nu8 n = (dd->ipath_ibcctrl >>\r\nINFINIPATH_IBCC_PHYERRTHRESHOLD_SHIFT) &\r\nINFINIPATH_IBCC_PHYERRTHRESHOLD_MASK;\r\nif (++dd->ipath_lli_counter > n) {\r\ndd->ipath_lli_counter = 0;\r\ndd->ipath_lli_errors++;\r\n}\r\n}\r\n}\r\nvoid ipath_kreceive(struct ipath_portdata *pd)\r\n{\r\nstruct ipath_devdata *dd = pd->port_dd;\r\n__le32 *rhf_addr;\r\nvoid *ebuf;\r\nconst u32 rsize = dd->ipath_rcvhdrentsize;\r\nconst u32 maxcnt = dd->ipath_rcvhdrcnt * rsize;\r\nu32 etail = -1, l, hdrqtail;\r\nstruct ipath_message_header *hdr;\r\nu32 eflags, i, etype, tlen, pkttot = 0, updegr = 0, reloop = 0;\r\nstatic u64 totcalls;\r\nint last;\r\nl = pd->port_head;\r\nrhf_addr = (__le32 *) pd->port_rcvhdrq + l + dd->ipath_rhf_offset;\r\nif (dd->ipath_flags & IPATH_NODMA_RTAIL) {\r\nu32 seq = ipath_hdrget_seq(rhf_addr);\r\nif (seq != pd->port_seq_cnt)\r\ngoto bail;\r\nhdrqtail = 0;\r\n} else {\r\nhdrqtail = ipath_get_rcvhdrtail(pd);\r\nif (l == hdrqtail)\r\ngoto bail;\r\nsmp_rmb();\r\n}\r\nreloop:\r\nfor (last = 0, i = 1; !last; i += !last) {\r\nhdr = dd->ipath_f_get_msgheader(dd, rhf_addr);\r\neflags = ipath_hdrget_err_flags(rhf_addr);\r\netype = ipath_hdrget_rcv_type(rhf_addr);\r\ntlen = ipath_hdrget_length_in_bytes(rhf_addr);\r\nebuf = NULL;\r\nif ((dd->ipath_flags & IPATH_NODMA_RTAIL) ?\r\nipath_hdrget_use_egr_buf(rhf_addr) :\r\n(etype != RCVHQ_RCV_TYPE_EXPECTED)) {\r\netail = ipath_hdrget_index(rhf_addr);\r\nupdegr = 1;\r\nif (tlen > sizeof(*hdr) ||\r\netype == RCVHQ_RCV_TYPE_NON_KD)\r\nebuf = ipath_get_egrbuf(dd, etail);\r\n}\r\nif (etype != RCVHQ_RCV_TYPE_NON_KD &&\r\netype != RCVHQ_RCV_TYPE_ERROR &&\r\nipath_hdrget_ipath_ver(hdr->iph.ver_port_tid_offset) !=\r\nIPS_PROTO_VERSION)\r\nipath_cdbg(PKT, "Bad InfiniPath protocol version "\r\n"%x\n", etype);\r\nif (unlikely(eflags))\r\nipath_rcv_hdrerr(dd, eflags, l, etail, rhf_addr, hdr);\r\nelse if (etype == RCVHQ_RCV_TYPE_NON_KD) {\r\nipath_ib_rcv(dd->verbs_dev, (u32 *)hdr, ebuf, tlen);\r\nif (dd->ipath_lli_counter)\r\ndd->ipath_lli_counter--;\r\n} else if (etype == RCVHQ_RCV_TYPE_EAGER) {\r\nu8 opcode = be32_to_cpu(hdr->bth[0]) >> 24;\r\nu32 qp = be32_to_cpu(hdr->bth[1]) & 0xffffff;\r\nipath_cdbg(PKT, "typ %x, opcode %x (eager, "\r\n"qp=%x), len %x; ignored\n",\r\netype, opcode, qp, tlen);\r\n}\r\nelse if (etype == RCVHQ_RCV_TYPE_EXPECTED)\r\nipath_dbg("Bug: Expected TID, opcode %x; ignored\n",\r\nbe32_to_cpu(hdr->bth[0]) >> 24);\r\nelse {\r\nipath_cdbg(ERRPKT, "Error Pkt, but no eflags! egrbuf"\r\n" %x, len %x hdrq+%x rhf: %Lx\n",\r\netail, tlen, l, (unsigned long long)\r\nle64_to_cpu(*(__le64 *) rhf_addr));\r\nif (ipath_debug & __IPATH_ERRPKTDBG) {\r\nu32 j, *d, dw = rsize-2;\r\nif (rsize > (tlen>>2))\r\ndw = tlen>>2;\r\nd = (u32 *)hdr;\r\nprintk(KERN_DEBUG "EPkt rcvhdr(%x dw):\n",\r\ndw);\r\nfor (j = 0; j < dw; j++)\r\nprintk(KERN_DEBUG "%8x%s", d[j],\r\n(j%8) == 7 ? "\n" : " ");\r\nprintk(KERN_DEBUG ".\n");\r\n}\r\n}\r\nl += rsize;\r\nif (l >= maxcnt)\r\nl = 0;\r\nrhf_addr = (__le32 *) pd->port_rcvhdrq +\r\nl + dd->ipath_rhf_offset;\r\nif (dd->ipath_flags & IPATH_NODMA_RTAIL) {\r\nu32 seq = ipath_hdrget_seq(rhf_addr);\r\nif (++pd->port_seq_cnt > 13)\r\npd->port_seq_cnt = 1;\r\nif (seq != pd->port_seq_cnt)\r\nlast = 1;\r\n} else if (l == hdrqtail)\r\nlast = 1;\r\nif (last || !(i & 0xf)) {\r\nu64 lval = l;\r\nif (last)\r\nlval |= dd->ipath_rhdrhead_intr_off;\r\nipath_write_ureg(dd, ur_rcvhdrhead, lval,\r\npd->port_port);\r\nif (updegr) {\r\nipath_write_ureg(dd, ur_rcvegrindexhead,\r\netail, pd->port_port);\r\nupdegr = 0;\r\n}\r\n}\r\n}\r\nif (!dd->ipath_rhdrhead_intr_off && !reloop &&\r\n!(dd->ipath_flags & IPATH_NODMA_RTAIL)) {\r\nu32 hqtail = ipath_get_rcvhdrtail(pd);\r\nif (hqtail != hdrqtail) {\r\nhdrqtail = hqtail;\r\nreloop = 1;\r\ngoto reloop;\r\n}\r\n}\r\npkttot += i;\r\npd->port_head = l;\r\nif (pkttot > ipath_stats.sps_maxpkts_call)\r\nipath_stats.sps_maxpkts_call = pkttot;\r\nipath_stats.sps_port0pkts += pkttot;\r\nipath_stats.sps_avgpkts_call =\r\nipath_stats.sps_port0pkts / ++totcalls;\r\nbail:;\r\n}\r\nstatic void ipath_update_pio_bufs(struct ipath_devdata *dd)\r\n{\r\nunsigned long flags;\r\nint i;\r\nconst unsigned piobregs = (unsigned)dd->ipath_pioavregs;\r\nif (!dd->ipath_pioavailregs_dma) {\r\nipath_dbg("Update shadow pioavail, but regs_dma NULL!\n");\r\nreturn;\r\n}\r\nif (ipath_debug & __IPATH_VERBDBG) {\r\nvolatile __le64 *dma = dd->ipath_pioavailregs_dma;\r\nunsigned long *shadow = dd->ipath_pioavailshadow;\r\nipath_cdbg(PKT, "Refill avail, dma0=%llx shad0=%lx, "\r\n"d1=%llx s1=%lx, d2=%llx s2=%lx, d3=%llx "\r\n"s3=%lx\n",\r\n(unsigned long long) le64_to_cpu(dma[0]),\r\nshadow[0],\r\n(unsigned long long) le64_to_cpu(dma[1]),\r\nshadow[1],\r\n(unsigned long long) le64_to_cpu(dma[2]),\r\nshadow[2],\r\n(unsigned long long) le64_to_cpu(dma[3]),\r\nshadow[3]);\r\nif (piobregs > 4)\r\nipath_cdbg(\r\nPKT, "2nd group, dma4=%llx shad4=%lx, "\r\n"d5=%llx s5=%lx, d6=%llx s6=%lx, "\r\n"d7=%llx s7=%lx\n",\r\n(unsigned long long) le64_to_cpu(dma[4]),\r\nshadow[4],\r\n(unsigned long long) le64_to_cpu(dma[5]),\r\nshadow[5],\r\n(unsigned long long) le64_to_cpu(dma[6]),\r\nshadow[6],\r\n(unsigned long long) le64_to_cpu(dma[7]),\r\nshadow[7]);\r\n}\r\nspin_lock_irqsave(&ipath_pioavail_lock, flags);\r\nfor (i = 0; i < piobregs; i++) {\r\nu64 pchbusy, pchg, piov, pnew;\r\nif (i > 3 && (dd->ipath_flags & IPATH_SWAP_PIOBUFS))\r\npiov = le64_to_cpu(dd->ipath_pioavailregs_dma[i ^ 1]);\r\nelse\r\npiov = le64_to_cpu(dd->ipath_pioavailregs_dma[i]);\r\npchg = dd->ipath_pioavailkernel[i] &\r\n~(dd->ipath_pioavailshadow[i] ^ piov);\r\npchbusy = pchg << INFINIPATH_SENDPIOAVAIL_BUSY_SHIFT;\r\nif (pchg && (pchbusy & dd->ipath_pioavailshadow[i])) {\r\npnew = dd->ipath_pioavailshadow[i] & ~pchbusy;\r\npnew |= piov & pchbusy;\r\ndd->ipath_pioavailshadow[i] = pnew;\r\n}\r\n}\r\nspin_unlock_irqrestore(&ipath_pioavail_lock, flags);\r\n}\r\nstatic void ipath_reset_availshadow(struct ipath_devdata *dd)\r\n{\r\nint i, im;\r\nunsigned long flags;\r\nspin_lock_irqsave(&ipath_pioavail_lock, flags);\r\nfor (i = 0; i < dd->ipath_pioavregs; i++) {\r\nu64 val, oldval;\r\nim = (i > 3 && (dd->ipath_flags & IPATH_SWAP_PIOBUFS)) ?\r\ni ^ 1 : i;\r\nval = le64_to_cpu(dd->ipath_pioavailregs_dma[im]);\r\noldval = dd->ipath_pioavailshadow[i];\r\ndd->ipath_pioavailshadow[i] = val |\r\n((~dd->ipath_pioavailkernel[i] <<\r\nINFINIPATH_SENDPIOAVAIL_BUSY_SHIFT) &\r\n0xaaaaaaaaaaaaaaaaULL);\r\nif (oldval != dd->ipath_pioavailshadow[i])\r\nipath_dbg("shadow[%d] was %Lx, now %lx\n",\r\ni, (unsigned long long) oldval,\r\ndd->ipath_pioavailshadow[i]);\r\n}\r\nspin_unlock_irqrestore(&ipath_pioavail_lock, flags);\r\n}\r\nint ipath_setrcvhdrsize(struct ipath_devdata *dd, unsigned rhdrsize)\r\n{\r\nint ret = 0;\r\nif (dd->ipath_flags & IPATH_RCVHDRSZ_SET) {\r\nif (dd->ipath_rcvhdrsize != rhdrsize) {\r\ndev_info(&dd->pcidev->dev,\r\n"Error: can't set protocol header "\r\n"size %u, already %u\n",\r\nrhdrsize, dd->ipath_rcvhdrsize);\r\nret = -EAGAIN;\r\n} else\r\nipath_cdbg(VERBOSE, "Reuse same protocol header "\r\n"size %u\n", dd->ipath_rcvhdrsize);\r\n} else if (rhdrsize > (dd->ipath_rcvhdrentsize -\r\n(sizeof(u64) / sizeof(u32)))) {\r\nipath_dbg("Error: can't set protocol header size %u "\r\n"(> max %u)\n", rhdrsize,\r\ndd->ipath_rcvhdrentsize -\r\n(u32) (sizeof(u64) / sizeof(u32)));\r\nret = -EOVERFLOW;\r\n} else {\r\ndd->ipath_flags |= IPATH_RCVHDRSZ_SET;\r\ndd->ipath_rcvhdrsize = rhdrsize;\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_rcvhdrsize,\r\ndd->ipath_rcvhdrsize);\r\nipath_cdbg(VERBOSE, "Set protocol header size to %u\n",\r\ndd->ipath_rcvhdrsize);\r\n}\r\nreturn ret;\r\n}\r\nstatic noinline void no_pio_bufs(struct ipath_devdata *dd)\r\n{\r\nunsigned long *shadow = dd->ipath_pioavailshadow;\r\n__le64 *dma = (__le64 *)dd->ipath_pioavailregs_dma;\r\ndd->ipath_upd_pio_shadow = 1;\r\nipath_stats.sps_nopiobufs++;\r\nif (!(++dd->ipath_consec_nopiobuf % 100000)) {\r\nipath_force_pio_avail_update(dd);\r\nipath_dbg("%u tries no piobufavail ts%lx; dmacopy: "\r\n"%llx %llx %llx %llx\n"\r\n"ipath shadow: %lx %lx %lx %lx\n",\r\ndd->ipath_consec_nopiobuf,\r\n(unsigned long)get_cycles(),\r\n(unsigned long long) le64_to_cpu(dma[0]),\r\n(unsigned long long) le64_to_cpu(dma[1]),\r\n(unsigned long long) le64_to_cpu(dma[2]),\r\n(unsigned long long) le64_to_cpu(dma[3]),\r\nshadow[0], shadow[1], shadow[2], shadow[3]);\r\nif ((dd->ipath_piobcnt2k + dd->ipath_piobcnt4k) >\r\n(sizeof(shadow[0]) * 4 * 4))\r\nipath_dbg("2nd group: dmacopy: "\r\n"%llx %llx %llx %llx\n"\r\n"ipath shadow: %lx %lx %lx %lx\n",\r\n(unsigned long long)le64_to_cpu(dma[4]),\r\n(unsigned long long)le64_to_cpu(dma[5]),\r\n(unsigned long long)le64_to_cpu(dma[6]),\r\n(unsigned long long)le64_to_cpu(dma[7]),\r\nshadow[4], shadow[5], shadow[6], shadow[7]);\r\nipath_reset_availshadow(dd);\r\n}\r\n}\r\nstatic u32 __iomem *ipath_getpiobuf_range(struct ipath_devdata *dd,\r\nu32 *pbufnum, u32 first, u32 last, u32 firsti)\r\n{\r\nint i, j, updated = 0;\r\nunsigned piobcnt;\r\nunsigned long flags;\r\nunsigned long *shadow = dd->ipath_pioavailshadow;\r\nu32 __iomem *buf;\r\npiobcnt = last - first;\r\nif (dd->ipath_upd_pio_shadow) {\r\nipath_update_pio_bufs(dd);\r\nupdated++;\r\ni = first;\r\n} else\r\ni = firsti;\r\nrescan:\r\nspin_lock_irqsave(&ipath_pioavail_lock, flags);\r\nfor (j = 0; j < piobcnt; j++, i++) {\r\nif (i >= last)\r\ni = first;\r\nif (__test_and_set_bit((2 * i) + 1, shadow))\r\ncontinue;\r\n__change_bit(2 * i, shadow);\r\nbreak;\r\n}\r\nspin_unlock_irqrestore(&ipath_pioavail_lock, flags);\r\nif (j == piobcnt) {\r\nif (!updated) {\r\nipath_update_pio_bufs(dd);\r\nupdated++;\r\ni = first;\r\ngoto rescan;\r\n} else if (updated == 1 && piobcnt <=\r\n((dd->ipath_sendctrl\r\n>> INFINIPATH_S_UPDTHRESH_SHIFT) &\r\nINFINIPATH_S_UPDTHRESH_MASK)) {\r\nipath_force_pio_avail_update(dd);\r\nipath_update_pio_bufs(dd);\r\nupdated++;\r\ni = first;\r\ngoto rescan;\r\n}\r\nno_pio_bufs(dd);\r\nbuf = NULL;\r\n} else {\r\nif (i < dd->ipath_piobcnt2k)\r\nbuf = (u32 __iomem *) (dd->ipath_pio2kbase +\r\ni * dd->ipath_palign);\r\nelse\r\nbuf = (u32 __iomem *)\r\n(dd->ipath_pio4kbase +\r\n(i - dd->ipath_piobcnt2k) * dd->ipath_4kalign);\r\nif (pbufnum)\r\n*pbufnum = i;\r\n}\r\nreturn buf;\r\n}\r\nu32 __iomem *ipath_getpiobuf(struct ipath_devdata *dd, u32 plen, u32 *pbufnum)\r\n{\r\nu32 __iomem *buf;\r\nu32 pnum, nbufs;\r\nu32 first, lasti;\r\nif (plen + 1 >= IPATH_SMALLBUF_DWORDS) {\r\nfirst = dd->ipath_piobcnt2k;\r\nlasti = dd->ipath_lastpioindexl;\r\n} else {\r\nfirst = 0;\r\nlasti = dd->ipath_lastpioindex;\r\n}\r\nnbufs = dd->ipath_piobcnt2k + dd->ipath_piobcnt4k;\r\nbuf = ipath_getpiobuf_range(dd, &pnum, first, nbufs, lasti);\r\nif (buf) {\r\nif (plen + 1 >= IPATH_SMALLBUF_DWORDS)\r\ndd->ipath_lastpioindexl = pnum + 1;\r\nelse\r\ndd->ipath_lastpioindex = pnum + 1;\r\nif (dd->ipath_upd_pio_shadow)\r\ndd->ipath_upd_pio_shadow = 0;\r\nif (dd->ipath_consec_nopiobuf)\r\ndd->ipath_consec_nopiobuf = 0;\r\nipath_cdbg(VERBOSE, "Return piobuf%u %uk @ %p\n",\r\npnum, (pnum < dd->ipath_piobcnt2k) ? 2 : 4, buf);\r\nif (pbufnum)\r\n*pbufnum = pnum;\r\n}\r\nreturn buf;\r\n}\r\nvoid ipath_chg_pioavailkernel(struct ipath_devdata *dd, unsigned start,\r\nunsigned len, int avail)\r\n{\r\nunsigned long flags;\r\nunsigned end, cnt = 0;\r\nstart *= 2;\r\nend = start + len * 2;\r\nspin_lock_irqsave(&ipath_pioavail_lock, flags);\r\nwhile (start < end) {\r\nif (avail) {\r\nunsigned long dma;\r\nint i, im;\r\ni = start / BITS_PER_LONG;\r\nim = (i > 3 && (dd->ipath_flags & IPATH_SWAP_PIOBUFS)) ?\r\ni ^ 1 : i;\r\n__clear_bit(INFINIPATH_SENDPIOAVAIL_BUSY_SHIFT\r\n+ start, dd->ipath_pioavailshadow);\r\ndma = (unsigned long) le64_to_cpu(\r\ndd->ipath_pioavailregs_dma[im]);\r\nif (test_bit((INFINIPATH_SENDPIOAVAIL_CHECK_SHIFT\r\n+ start) % BITS_PER_LONG, &dma))\r\n__set_bit(INFINIPATH_SENDPIOAVAIL_CHECK_SHIFT\r\n+ start, dd->ipath_pioavailshadow);\r\nelse\r\n__clear_bit(INFINIPATH_SENDPIOAVAIL_CHECK_SHIFT\r\n+ start, dd->ipath_pioavailshadow);\r\n__set_bit(start, dd->ipath_pioavailkernel);\r\n} else {\r\n__set_bit(start + INFINIPATH_SENDPIOAVAIL_BUSY_SHIFT,\r\ndd->ipath_pioavailshadow);\r\n__clear_bit(start, dd->ipath_pioavailkernel);\r\n}\r\nstart += 2;\r\n}\r\nif (dd->ipath_pioupd_thresh) {\r\nend = 2 * (dd->ipath_piobcnt2k + dd->ipath_piobcnt4k);\r\ncnt = bitmap_weight(dd->ipath_pioavailkernel, end);\r\n}\r\nspin_unlock_irqrestore(&ipath_pioavail_lock, flags);\r\nif (!avail && len < cnt)\r\ncnt = len;\r\nif (cnt < dd->ipath_pioupd_thresh) {\r\ndd->ipath_pioupd_thresh = cnt;\r\nipath_dbg("Decreased pio update threshold to %u\n",\r\ndd->ipath_pioupd_thresh);\r\nspin_lock_irqsave(&dd->ipath_sendctrl_lock, flags);\r\ndd->ipath_sendctrl &= ~(INFINIPATH_S_UPDTHRESH_MASK\r\n<< INFINIPATH_S_UPDTHRESH_SHIFT);\r\ndd->ipath_sendctrl |= dd->ipath_pioupd_thresh\r\n<< INFINIPATH_S_UPDTHRESH_SHIFT;\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_sendctrl,\r\ndd->ipath_sendctrl);\r\nspin_unlock_irqrestore(&dd->ipath_sendctrl_lock, flags);\r\n}\r\n}\r\nint ipath_create_rcvhdrq(struct ipath_devdata *dd,\r\nstruct ipath_portdata *pd)\r\n{\r\nint ret = 0;\r\nif (!pd->port_rcvhdrq) {\r\ndma_addr_t phys_hdrqtail;\r\ngfp_t gfp_flags = GFP_USER | __GFP_COMP;\r\nint amt = ALIGN(dd->ipath_rcvhdrcnt * dd->ipath_rcvhdrentsize *\r\nsizeof(u32), PAGE_SIZE);\r\npd->port_rcvhdrq = dma_alloc_coherent(\r\n&dd->pcidev->dev, amt, &pd->port_rcvhdrq_phys,\r\ngfp_flags);\r\nif (!pd->port_rcvhdrq) {\r\nipath_dev_err(dd, "attempt to allocate %d bytes "\r\n"for port %u rcvhdrq failed\n",\r\namt, pd->port_port);\r\nret = -ENOMEM;\r\ngoto bail;\r\n}\r\nif (!(dd->ipath_flags & IPATH_NODMA_RTAIL)) {\r\npd->port_rcvhdrtail_kvaddr = dma_alloc_coherent(\r\n&dd->pcidev->dev, PAGE_SIZE, &phys_hdrqtail,\r\nGFP_KERNEL);\r\nif (!pd->port_rcvhdrtail_kvaddr) {\r\nipath_dev_err(dd, "attempt to allocate 1 page "\r\n"for port %u rcvhdrqtailaddr "\r\n"failed\n", pd->port_port);\r\nret = -ENOMEM;\r\ndma_free_coherent(&dd->pcidev->dev, amt,\r\npd->port_rcvhdrq,\r\npd->port_rcvhdrq_phys);\r\npd->port_rcvhdrq = NULL;\r\ngoto bail;\r\n}\r\npd->port_rcvhdrqtailaddr_phys = phys_hdrqtail;\r\nipath_cdbg(VERBOSE, "port %d hdrtailaddr, %llx "\r\n"physical\n", pd->port_port,\r\n(unsigned long long) phys_hdrqtail);\r\n}\r\npd->port_rcvhdrq_size = amt;\r\nipath_cdbg(VERBOSE, "%d pages at %p (phys %lx) size=%lu "\r\n"for port %u rcvhdr Q\n",\r\namt >> PAGE_SHIFT, pd->port_rcvhdrq,\r\n(unsigned long) pd->port_rcvhdrq_phys,\r\n(unsigned long) pd->port_rcvhdrq_size,\r\npd->port_port);\r\n}\r\nelse\r\nipath_cdbg(VERBOSE, "reuse port %d rcvhdrq @%p %llx phys; "\r\n"hdrtailaddr@%p %llx physical\n",\r\npd->port_port, pd->port_rcvhdrq,\r\n(unsigned long long) pd->port_rcvhdrq_phys,\r\npd->port_rcvhdrtail_kvaddr, (unsigned long long)\r\npd->port_rcvhdrqtailaddr_phys);\r\nmemset(pd->port_rcvhdrq, 0, pd->port_rcvhdrq_size);\r\nif (pd->port_rcvhdrtail_kvaddr)\r\nmemset(pd->port_rcvhdrtail_kvaddr, 0, PAGE_SIZE);\r\nipath_write_kreg_port(dd, dd->ipath_kregs->kr_rcvhdrtailaddr,\r\npd->port_port, pd->port_rcvhdrqtailaddr_phys);\r\nipath_write_kreg_port(dd, dd->ipath_kregs->kr_rcvhdraddr,\r\npd->port_port, pd->port_rcvhdrq_phys);\r\nbail:\r\nreturn ret;\r\n}\r\nvoid ipath_cancel_sends(struct ipath_devdata *dd, int restore_sendctrl)\r\n{\r\nunsigned long flags;\r\nif (dd->ipath_flags & IPATH_IB_AUTONEG_INPROG) {\r\nipath_cdbg(VERBOSE, "Ignore while in autonegotiation\n");\r\ngoto bail;\r\n}\r\nif (dd->ipath_flags & IPATH_HAS_SEND_DMA) {\r\nint skip_cancel;\r\nunsigned long *statp = &dd->ipath_sdma_status;\r\nspin_lock_irqsave(&dd->ipath_sdma_lock, flags);\r\nskip_cancel =\r\ntest_and_set_bit(IPATH_SDMA_ABORTING, statp)\r\n&& !test_bit(IPATH_SDMA_DISABLED, statp);\r\nspin_unlock_irqrestore(&dd->ipath_sdma_lock, flags);\r\nif (skip_cancel)\r\ngoto bail;\r\n}\r\nipath_dbg("Cancelling all in-progress send buffers\n");\r\ndd->ipath_lastcancel = jiffies + HZ / 2;\r\nspin_lock_irqsave(&dd->ipath_sendctrl_lock, flags);\r\ndd->ipath_sendctrl &= ~(INFINIPATH_S_PIOBUFAVAILUPD\r\n| INFINIPATH_S_PIOENABLE);\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_sendctrl,\r\ndd->ipath_sendctrl | INFINIPATH_S_ABORT);\r\nipath_read_kreg64(dd, dd->ipath_kregs->kr_scratch);\r\nspin_unlock_irqrestore(&dd->ipath_sendctrl_lock, flags);\r\nipath_disarm_piobufs(dd, 0,\r\ndd->ipath_piobcnt2k + dd->ipath_piobcnt4k);\r\nif (dd->ipath_flags & IPATH_HAS_SEND_DMA)\r\nset_bit(IPATH_SDMA_DISARMED, &dd->ipath_sdma_status);\r\nif (restore_sendctrl) {\r\nspin_lock_irqsave(&dd->ipath_sendctrl_lock, flags);\r\ndd->ipath_sendctrl |= INFINIPATH_S_PIOBUFAVAILUPD |\r\nINFINIPATH_S_PIOENABLE;\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_sendctrl,\r\ndd->ipath_sendctrl);\r\nipath_read_kreg64(dd, dd->ipath_kregs->kr_scratch);\r\nspin_unlock_irqrestore(&dd->ipath_sendctrl_lock, flags);\r\n}\r\nif ((dd->ipath_flags & IPATH_HAS_SEND_DMA) &&\r\n!test_bit(IPATH_SDMA_DISABLED, &dd->ipath_sdma_status) &&\r\ntest_bit(IPATH_SDMA_RUNNING, &dd->ipath_sdma_status)) {\r\nspin_lock_irqsave(&dd->ipath_sdma_lock, flags);\r\ndd->ipath_sdma_abort_intr_timeout = jiffies + HZ;\r\ndd->ipath_sdma_reset_wait = 200;\r\nif (!test_bit(IPATH_SDMA_SHUTDOWN, &dd->ipath_sdma_status))\r\ntasklet_hi_schedule(&dd->ipath_sdma_abort_task);\r\nspin_unlock_irqrestore(&dd->ipath_sdma_lock, flags);\r\n}\r\nbail:;\r\n}\r\nvoid ipath_force_pio_avail_update(struct ipath_devdata *dd)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&dd->ipath_sendctrl_lock, flags);\r\nif (dd->ipath_sendctrl & INFINIPATH_S_PIOBUFAVAILUPD) {\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_sendctrl,\r\ndd->ipath_sendctrl & ~INFINIPATH_S_PIOBUFAVAILUPD);\r\nipath_read_kreg64(dd, dd->ipath_kregs->kr_scratch);\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_sendctrl,\r\ndd->ipath_sendctrl);\r\nipath_read_kreg64(dd, dd->ipath_kregs->kr_scratch);\r\n}\r\nspin_unlock_irqrestore(&dd->ipath_sendctrl_lock, flags);\r\n}\r\nstatic void ipath_set_ib_lstate(struct ipath_devdata *dd, int linkcmd,\r\nint linitcmd)\r\n{\r\nu64 mod_wd;\r\nstatic const char *what[4] = {\r\n[0] = "NOP",\r\n[INFINIPATH_IBCC_LINKCMD_DOWN] = "DOWN",\r\n[INFINIPATH_IBCC_LINKCMD_ARMED] = "ARMED",\r\n[INFINIPATH_IBCC_LINKCMD_ACTIVE] = "ACTIVE"\r\n};\r\nif (linitcmd == INFINIPATH_IBCC_LINKINITCMD_DISABLE) {\r\npreempt_disable();\r\ndd->ipath_flags |= IPATH_IB_LINK_DISABLED;\r\npreempt_enable();\r\n} else if (linitcmd) {\r\npreempt_disable();\r\ndd->ipath_flags &= ~IPATH_IB_LINK_DISABLED;\r\npreempt_enable();\r\n}\r\nmod_wd = (linkcmd << dd->ibcc_lc_shift) |\r\n(linitcmd << INFINIPATH_IBCC_LINKINITCMD_SHIFT);\r\nipath_cdbg(VERBOSE,\r\n"Moving unit %u to %s (initcmd=0x%x), current ltstate is %s\n",\r\ndd->ipath_unit, what[linkcmd], linitcmd,\r\nipath_ibcstatus_str[ipath_ib_linktrstate(dd,\r\nipath_read_kreg64(dd, dd->ipath_kregs->kr_ibcstatus))]);\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_ibcctrl,\r\ndd->ipath_ibcctrl | mod_wd);\r\n(void) ipath_read_kreg64(dd, dd->ipath_kregs->kr_ibcstatus);\r\n}\r\nint ipath_set_linkstate(struct ipath_devdata *dd, u8 newstate)\r\n{\r\nu32 lstate;\r\nint ret;\r\nswitch (newstate) {\r\ncase IPATH_IB_LINKDOWN_ONLY:\r\nipath_set_ib_lstate(dd, INFINIPATH_IBCC_LINKCMD_DOWN, 0);\r\nret = 0;\r\ngoto bail;\r\ncase IPATH_IB_LINKDOWN:\r\nipath_set_ib_lstate(dd, INFINIPATH_IBCC_LINKCMD_DOWN,\r\nINFINIPATH_IBCC_LINKINITCMD_POLL);\r\nret = 0;\r\ngoto bail;\r\ncase IPATH_IB_LINKDOWN_SLEEP:\r\nipath_set_ib_lstate(dd, INFINIPATH_IBCC_LINKCMD_DOWN,\r\nINFINIPATH_IBCC_LINKINITCMD_SLEEP);\r\nret = 0;\r\ngoto bail;\r\ncase IPATH_IB_LINKDOWN_DISABLE:\r\nipath_set_ib_lstate(dd, INFINIPATH_IBCC_LINKCMD_DOWN,\r\nINFINIPATH_IBCC_LINKINITCMD_DISABLE);\r\nret = 0;\r\ngoto bail;\r\ncase IPATH_IB_LINKARM:\r\nif (dd->ipath_flags & IPATH_LINKARMED) {\r\nret = 0;\r\ngoto bail;\r\n}\r\nif (!(dd->ipath_flags &\r\n(IPATH_LINKINIT | IPATH_LINKACTIVE))) {\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nipath_set_ib_lstate(dd, INFINIPATH_IBCC_LINKCMD_ARMED, 0);\r\nlstate = IPATH_LINKARMED | IPATH_LINKACTIVE;\r\nbreak;\r\ncase IPATH_IB_LINKACTIVE:\r\nif (dd->ipath_flags & IPATH_LINKACTIVE) {\r\nret = 0;\r\ngoto bail;\r\n}\r\nif (!(dd->ipath_flags & IPATH_LINKARMED)) {\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nipath_set_ib_lstate(dd, INFINIPATH_IBCC_LINKCMD_ACTIVE, 0);\r\nlstate = IPATH_LINKACTIVE;\r\nbreak;\r\ncase IPATH_IB_LINK_LOOPBACK:\r\ndev_info(&dd->pcidev->dev, "Enabling IB local loopback\n");\r\ndd->ipath_ibcctrl |= INFINIPATH_IBCC_LOOPBACK;\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_ibcctrl,\r\ndd->ipath_ibcctrl);\r\ndd->ipath_f_set_ib_cfg(dd, IPATH_IB_CFG_HRTBT,\r\nIPATH_IB_HRTBT_OFF);\r\nret = 0;\r\ngoto bail;\r\ncase IPATH_IB_LINK_EXTERNAL:\r\ndev_info(&dd->pcidev->dev,\r\n"Disabling IB local loopback (normal)\n");\r\ndd->ipath_f_set_ib_cfg(dd, IPATH_IB_CFG_HRTBT,\r\nIPATH_IB_HRTBT_ON);\r\ndd->ipath_ibcctrl &= ~INFINIPATH_IBCC_LOOPBACK;\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_ibcctrl,\r\ndd->ipath_ibcctrl);\r\nret = 0;\r\ngoto bail;\r\ncase IPATH_IB_LINK_HRTBT:\r\nret = dd->ipath_f_set_ib_cfg(dd, IPATH_IB_CFG_HRTBT,\r\nIPATH_IB_HRTBT_ON);\r\ngoto bail;\r\ncase IPATH_IB_LINK_NO_HRTBT:\r\nret = dd->ipath_f_set_ib_cfg(dd, IPATH_IB_CFG_HRTBT,\r\nIPATH_IB_HRTBT_OFF);\r\ngoto bail;\r\ndefault:\r\nipath_dbg("Invalid linkstate 0x%x requested\n", newstate);\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nret = ipath_wait_linkstate(dd, lstate, 2000);\r\nbail:\r\nreturn ret;\r\n}\r\nint ipath_set_mtu(struct ipath_devdata *dd, u16 arg)\r\n{\r\nu32 piosize;\r\nint changed = 0;\r\nint ret;\r\nif (arg != 256 && arg != 512 && arg != 1024 && arg != 2048 &&\r\n(arg != 4096 || !ipath_mtu4096)) {\r\nipath_dbg("Trying to set invalid mtu %u, failing\n", arg);\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nif (dd->ipath_ibmtu == arg) {\r\nret = 0;\r\ngoto bail;\r\n}\r\npiosize = dd->ipath_ibmaxlen;\r\ndd->ipath_ibmtu = arg;\r\nif (arg >= (piosize - IPATH_PIO_MAXIBHDR)) {\r\nif (piosize != dd->ipath_init_ibmaxlen) {\r\nif (arg > piosize && arg <= dd->ipath_init_ibmaxlen)\r\npiosize = dd->ipath_init_ibmaxlen;\r\ndd->ipath_ibmaxlen = piosize;\r\nchanged = 1;\r\n}\r\n} else if ((arg + IPATH_PIO_MAXIBHDR) != dd->ipath_ibmaxlen) {\r\npiosize = arg + IPATH_PIO_MAXIBHDR;\r\nipath_cdbg(VERBOSE, "ibmaxlen was 0x%x, setting to 0x%x "\r\n"(mtu 0x%x)\n", dd->ipath_ibmaxlen, piosize,\r\narg);\r\ndd->ipath_ibmaxlen = piosize;\r\nchanged = 1;\r\n}\r\nif (changed) {\r\nu64 ibc = dd->ipath_ibcctrl, ibdw;\r\ndd->ipath_ibmaxlen = piosize - 2 * sizeof(u32);\r\nibdw = (dd->ipath_ibmaxlen >> 2) + 1;\r\nibc &= ~(INFINIPATH_IBCC_MAXPKTLEN_MASK <<\r\ndd->ibcc_mpl_shift);\r\nibc |= ibdw << dd->ibcc_mpl_shift;\r\ndd->ipath_ibcctrl = ibc;\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_ibcctrl,\r\ndd->ipath_ibcctrl);\r\ndd->ipath_f_tidtemplate(dd);\r\n}\r\nret = 0;\r\nbail:\r\nreturn ret;\r\n}\r\nint ipath_set_lid(struct ipath_devdata *dd, u32 lid, u8 lmc)\r\n{\r\ndd->ipath_lid = lid;\r\ndd->ipath_lmc = lmc;\r\ndd->ipath_f_set_ib_cfg(dd, IPATH_IB_CFG_LIDLMC, lid |\r\n(~((1U << lmc) - 1)) << 16);\r\ndev_info(&dd->pcidev->dev, "We got a lid: 0x%x\n", lid);\r\nreturn 0;\r\n}\r\nvoid ipath_write_kreg_port(const struct ipath_devdata *dd, ipath_kreg regno,\r\nunsigned port, u64 value)\r\n{\r\nu16 where;\r\nif (port < dd->ipath_portcnt &&\r\n(regno == dd->ipath_kregs->kr_rcvhdraddr ||\r\nregno == dd->ipath_kregs->kr_rcvhdrtailaddr))\r\nwhere = regno + port;\r\nelse\r\nwhere = -1;\r\nipath_write_kreg(dd, where, value);\r\n}\r\nstatic void ipath_run_led_override(unsigned long opaque)\r\n{\r\nstruct ipath_devdata *dd = (struct ipath_devdata *)opaque;\r\nint timeoff;\r\nint pidx;\r\nu64 lstate, ltstate, val;\r\nif (!(dd->ipath_flags & IPATH_INITTED))\r\nreturn;\r\npidx = dd->ipath_led_override_phase++ & 1;\r\ndd->ipath_led_override = dd->ipath_led_override_vals[pidx];\r\ntimeoff = dd->ipath_led_override_timeoff;\r\nval = ipath_read_kreg64(dd, dd->ipath_kregs->kr_ibcstatus);\r\nltstate = ipath_ib_linktrstate(dd, val);\r\nlstate = ipath_ib_linkstate(dd, val);\r\ndd->ipath_f_setextled(dd, lstate, ltstate);\r\nmod_timer(&dd->ipath_led_override_timer, jiffies + timeoff);\r\n}\r\nvoid ipath_set_led_override(struct ipath_devdata *dd, unsigned int val)\r\n{\r\nint timeoff, freq;\r\nif (!(dd->ipath_flags & IPATH_INITTED))\r\nreturn;\r\ntimeoff = HZ;\r\nfreq = (val & LED_OVER_FREQ_MASK) >> LED_OVER_FREQ_SHIFT;\r\nif (freq) {\r\ndd->ipath_led_override_vals[0] = val & 0xF;\r\ndd->ipath_led_override_vals[1] = (val >> 4) & 0xF;\r\ntimeoff = (HZ << 4)/freq;\r\n} else {\r\ndd->ipath_led_override_vals[0] = val & 0xF;\r\ndd->ipath_led_override_vals[1] = val & 0xF;\r\n}\r\ndd->ipath_led_override_timeoff = timeoff;\r\nif (atomic_inc_return(&dd->ipath_led_override_timer_active) == 1) {\r\ninit_timer(&dd->ipath_led_override_timer);\r\ndd->ipath_led_override_timer.function =\r\nipath_run_led_override;\r\ndd->ipath_led_override_timer.data = (unsigned long) dd;\r\ndd->ipath_led_override_timer.expires = jiffies + 1;\r\nadd_timer(&dd->ipath_led_override_timer);\r\n} else\r\natomic_dec(&dd->ipath_led_override_timer_active);\r\n}\r\nvoid ipath_shutdown_device(struct ipath_devdata *dd)\r\n{\r\nunsigned long flags;\r\nipath_dbg("Shutting down the device\n");\r\nipath_hol_up(dd);\r\ndd->ipath_flags |= IPATH_LINKUNK;\r\ndd->ipath_flags &= ~(IPATH_INITTED | IPATH_LINKDOWN |\r\nIPATH_LINKINIT | IPATH_LINKARMED |\r\nIPATH_LINKACTIVE);\r\n*dd->ipath_statusp &= ~(IPATH_STATUS_IB_CONF |\r\nIPATH_STATUS_IB_READY);\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_intmask, 0ULL);\r\ndd->ipath_rcvctrl = 0;\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_rcvctrl,\r\ndd->ipath_rcvctrl);\r\nif (dd->ipath_flags & IPATH_HAS_SEND_DMA)\r\nteardown_sdma(dd);\r\nspin_lock_irqsave(&dd->ipath_sendctrl_lock, flags);\r\ndd->ipath_sendctrl = 0;\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_sendctrl, dd->ipath_sendctrl);\r\nipath_read_kreg64(dd, dd->ipath_kregs->kr_scratch);\r\nspin_unlock_irqrestore(&dd->ipath_sendctrl_lock, flags);\r\nudelay(5);\r\ndd->ipath_f_setextled(dd, 0, 0);\r\nipath_set_ib_lstate(dd, 0, INFINIPATH_IBCC_LINKINITCMD_DISABLE);\r\nipath_cancel_sends(dd, 0);\r\nsignal_ib_event(dd, IB_EVENT_PORT_ERR);\r\ndd->ipath_control &= ~INFINIPATH_C_LINKENABLE;\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_control,\r\ndd->ipath_control | INFINIPATH_C_FREEZEMODE);\r\ndd->ipath_f_quiet_serdes(dd);\r\ndel_timer_sync(&dd->ipath_hol_timer);\r\nif (dd->ipath_stats_timer_active) {\r\ndel_timer_sync(&dd->ipath_stats_timer);\r\ndd->ipath_stats_timer_active = 0;\r\n}\r\nif (dd->ipath_intrchk_timer.data) {\r\ndel_timer_sync(&dd->ipath_intrchk_timer);\r\ndd->ipath_intrchk_timer.data = 0;\r\n}\r\nif (atomic_read(&dd->ipath_led_override_timer_active)) {\r\ndel_timer_sync(&dd->ipath_led_override_timer);\r\natomic_set(&dd->ipath_led_override_timer_active, 0);\r\n}\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_hwerrclear,\r\n~0ULL & ~INFINIPATH_HWE_MEMBISTFAILED);\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_errorclear, -1LL);\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_intclear, -1LL);\r\nipath_cdbg(VERBOSE, "Flush time and errors to EEPROM\n");\r\nipath_update_eeprom_log(dd);\r\n}\r\nvoid ipath_free_pddata(struct ipath_devdata *dd, struct ipath_portdata *pd)\r\n{\r\nif (!pd)\r\nreturn;\r\nif (pd->port_rcvhdrq) {\r\nipath_cdbg(VERBOSE, "free closed port %d rcvhdrq @ %p "\r\n"(size=%lu)\n", pd->port_port, pd->port_rcvhdrq,\r\n(unsigned long) pd->port_rcvhdrq_size);\r\ndma_free_coherent(&dd->pcidev->dev, pd->port_rcvhdrq_size,\r\npd->port_rcvhdrq, pd->port_rcvhdrq_phys);\r\npd->port_rcvhdrq = NULL;\r\nif (pd->port_rcvhdrtail_kvaddr) {\r\ndma_free_coherent(&dd->pcidev->dev, PAGE_SIZE,\r\npd->port_rcvhdrtail_kvaddr,\r\npd->port_rcvhdrqtailaddr_phys);\r\npd->port_rcvhdrtail_kvaddr = NULL;\r\n}\r\n}\r\nif (pd->port_port && pd->port_rcvegrbuf) {\r\nunsigned e;\r\nfor (e = 0; e < pd->port_rcvegrbuf_chunks; e++) {\r\nvoid *base = pd->port_rcvegrbuf[e];\r\nsize_t size = pd->port_rcvegrbuf_size;\r\nipath_cdbg(VERBOSE, "egrbuf free(%p, %lu), "\r\n"chunk %u/%u\n", base,\r\n(unsigned long) size,\r\ne, pd->port_rcvegrbuf_chunks);\r\ndma_free_coherent(&dd->pcidev->dev, size,\r\nbase, pd->port_rcvegrbuf_phys[e]);\r\n}\r\nkfree(pd->port_rcvegrbuf);\r\npd->port_rcvegrbuf = NULL;\r\nkfree(pd->port_rcvegrbuf_phys);\r\npd->port_rcvegrbuf_phys = NULL;\r\npd->port_rcvegrbuf_chunks = 0;\r\n} else if (pd->port_port == 0 && dd->ipath_port0_skbinfo) {\r\nunsigned e;\r\nstruct ipath_skbinfo *skbinfo = dd->ipath_port0_skbinfo;\r\ndd->ipath_port0_skbinfo = NULL;\r\nipath_cdbg(VERBOSE, "free closed port %d "\r\n"ipath_port0_skbinfo @ %p\n", pd->port_port,\r\nskbinfo);\r\nfor (e = 0; e < dd->ipath_p0_rcvegrcnt; e++)\r\nif (skbinfo[e].skb) {\r\npci_unmap_single(dd->pcidev, skbinfo[e].phys,\r\ndd->ipath_ibmaxlen,\r\nPCI_DMA_FROMDEVICE);\r\ndev_kfree_skb(skbinfo[e].skb);\r\n}\r\nvfree(skbinfo);\r\n}\r\nkfree(pd->port_tid_pg_list);\r\nvfree(pd->subport_uregbase);\r\nvfree(pd->subport_rcvegrbuf);\r\nvfree(pd->subport_rcvhdr_base);\r\nkfree(pd);\r\n}\r\nstatic int __init infinipath_init(void)\r\n{\r\nint ret;\r\nif (ipath_debug & __IPATH_DBG)\r\nprintk(KERN_INFO DRIVER_LOAD_MSG "%s", ib_ipath_version);\r\nidr_init(&unit_table);\r\nret = pci_register_driver(&ipath_driver);\r\nif (ret < 0) {\r\nprintk(KERN_ERR IPATH_DRV_NAME\r\n": Unable to register driver: error %d\n", -ret);\r\ngoto bail_unit;\r\n}\r\nret = ipath_init_ipathfs();\r\nif (ret < 0) {\r\nprintk(KERN_ERR IPATH_DRV_NAME ": Unable to create "\r\n"ipathfs: error %d\n", -ret);\r\ngoto bail_pci;\r\n}\r\ngoto bail;\r\nbail_pci:\r\npci_unregister_driver(&ipath_driver);\r\nbail_unit:\r\nidr_destroy(&unit_table);\r\nbail:\r\nreturn ret;\r\n}\r\nstatic void __exit infinipath_cleanup(void)\r\n{\r\nipath_exit_ipathfs();\r\nipath_cdbg(VERBOSE, "Unregistering pci driver\n");\r\npci_unregister_driver(&ipath_driver);\r\nidr_destroy(&unit_table);\r\n}\r\nint ipath_reset_device(int unit)\r\n{\r\nint ret, i;\r\nstruct ipath_devdata *dd = ipath_lookup(unit);\r\nunsigned long flags;\r\nif (!dd) {\r\nret = -ENODEV;\r\ngoto bail;\r\n}\r\nif (atomic_read(&dd->ipath_led_override_timer_active)) {\r\ndel_timer_sync(&dd->ipath_led_override_timer);\r\natomic_set(&dd->ipath_led_override_timer_active, 0);\r\n}\r\ndd->ipath_led_override = LED_OVER_BOTH_OFF;\r\ndd->ipath_f_setextled(dd, 0, 0);\r\ndev_info(&dd->pcidev->dev, "Reset on unit %u requested\n", unit);\r\nif (!dd->ipath_kregbase || !(dd->ipath_flags & IPATH_PRESENT)) {\r\ndev_info(&dd->pcidev->dev, "Invalid unit number %u or "\r\n"not initialized or not present\n", unit);\r\nret = -ENXIO;\r\ngoto bail;\r\n}\r\nspin_lock_irqsave(&dd->ipath_uctxt_lock, flags);\r\nif (dd->ipath_pd)\r\nfor (i = 1; i < dd->ipath_cfgports; i++) {\r\nif (!dd->ipath_pd[i] || !dd->ipath_pd[i]->port_cnt)\r\ncontinue;\r\nspin_unlock_irqrestore(&dd->ipath_uctxt_lock, flags);\r\nipath_dbg("unit %u port %d is in use "\r\n"(PID %u cmd %s), can't reset\n",\r\nunit, i,\r\npid_nr(dd->ipath_pd[i]->port_pid),\r\ndd->ipath_pd[i]->port_comm);\r\nret = -EBUSY;\r\ngoto bail;\r\n}\r\nspin_unlock_irqrestore(&dd->ipath_uctxt_lock, flags);\r\nif (dd->ipath_flags & IPATH_HAS_SEND_DMA)\r\nteardown_sdma(dd);\r\ndd->ipath_flags &= ~IPATH_INITTED;\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_intmask, 0ULL);\r\nret = dd->ipath_f_reset(dd);\r\nif (ret == 1) {\r\nipath_dbg("Reinitializing unit %u after reset attempt\n",\r\nunit);\r\nret = ipath_init_chip(dd, 1);\r\n} else\r\nret = -EAGAIN;\r\nif (ret)\r\nipath_dev_err(dd, "Reinitialize unit %u after "\r\n"reset failed with %d\n", unit, ret);\r\nelse\r\ndev_info(&dd->pcidev->dev, "Reinitialized unit %u after "\r\n"resetting\n", unit);\r\nbail:\r\nreturn ret;\r\n}\r\nstatic int ipath_signal_procs(struct ipath_devdata *dd, int sig)\r\n{\r\nint i, sub, any = 0;\r\nstruct pid *pid;\r\nunsigned long flags;\r\nif (!dd->ipath_pd)\r\nreturn 0;\r\nspin_lock_irqsave(&dd->ipath_uctxt_lock, flags);\r\nfor (i = 1; i < dd->ipath_cfgports; i++) {\r\nif (!dd->ipath_pd[i] || !dd->ipath_pd[i]->port_cnt)\r\ncontinue;\r\npid = dd->ipath_pd[i]->port_pid;\r\nif (!pid)\r\ncontinue;\r\ndev_info(&dd->pcidev->dev, "context %d in use "\r\n"(PID %u), sending signal %d\n",\r\ni, pid_nr(pid), sig);\r\nkill_pid(pid, sig, 1);\r\nany++;\r\nfor (sub = 0; sub < INFINIPATH_MAX_SUBPORT; sub++) {\r\npid = dd->ipath_pd[i]->port_subpid[sub];\r\nif (!pid)\r\ncontinue;\r\ndev_info(&dd->pcidev->dev, "sub-context "\r\n"%d:%d in use (PID %u), sending "\r\n"signal %d\n", i, sub, pid_nr(pid), sig);\r\nkill_pid(pid, sig, 1);\r\nany++;\r\n}\r\n}\r\nspin_unlock_irqrestore(&dd->ipath_uctxt_lock, flags);\r\nreturn any;\r\n}\r\nstatic void ipath_hol_signal_down(struct ipath_devdata *dd)\r\n{\r\nif (ipath_signal_procs(dd, SIGSTOP))\r\nipath_dbg("Stopped some processes\n");\r\nipath_cancel_sends(dd, 1);\r\n}\r\nstatic void ipath_hol_signal_up(struct ipath_devdata *dd)\r\n{\r\nif (ipath_signal_procs(dd, SIGCONT))\r\nipath_dbg("Continued some processes\n");\r\n}\r\nvoid ipath_hol_down(struct ipath_devdata *dd)\r\n{\r\ndd->ipath_hol_state = IPATH_HOL_DOWN;\r\nipath_hol_signal_down(dd);\r\ndd->ipath_hol_next = IPATH_HOL_DOWNCONT;\r\ndd->ipath_hol_timer.expires = jiffies +\r\nmsecs_to_jiffies(ipath_hol_timeout_ms);\r\nmod_timer(&dd->ipath_hol_timer, dd->ipath_hol_timer.expires);\r\n}\r\nvoid ipath_hol_up(struct ipath_devdata *dd)\r\n{\r\nipath_hol_signal_up(dd);\r\ndd->ipath_hol_state = IPATH_HOL_UP;\r\n}\r\nvoid ipath_hol_event(unsigned long opaque)\r\n{\r\nstruct ipath_devdata *dd = (struct ipath_devdata *)opaque;\r\nif (dd->ipath_hol_next == IPATH_HOL_DOWNSTOP\r\n&& dd->ipath_hol_state != IPATH_HOL_UP) {\r\ndd->ipath_hol_next = IPATH_HOL_DOWNCONT;\r\nipath_dbg("Stopping processes\n");\r\nipath_hol_signal_down(dd);\r\n} else {\r\ndd->ipath_hol_next = IPATH_HOL_DOWNSTOP;\r\nipath_dbg("Continuing processes\n");\r\nipath_hol_signal_up(dd);\r\n}\r\nif (dd->ipath_hol_state == IPATH_HOL_UP)\r\nipath_dbg("link's up, don't resched timer\n");\r\nelse {\r\ndd->ipath_hol_timer.expires = jiffies +\r\nmsecs_to_jiffies(ipath_hol_timeout_ms);\r\nmod_timer(&dd->ipath_hol_timer,\r\ndd->ipath_hol_timer.expires);\r\n}\r\n}\r\nint ipath_set_rx_pol_inv(struct ipath_devdata *dd, u8 new_pol_inv)\r\n{\r\nu64 val;\r\nif (new_pol_inv > INFINIPATH_XGXS_RX_POL_MASK)\r\nreturn -1;\r\nif (dd->ipath_rx_pol_inv != new_pol_inv) {\r\ndd->ipath_rx_pol_inv = new_pol_inv;\r\nval = ipath_read_kreg64(dd, dd->ipath_kregs->kr_xgxsconfig);\r\nval &= ~(INFINIPATH_XGXS_RX_POL_MASK <<\r\nINFINIPATH_XGXS_RX_POL_SHIFT);\r\nval |= ((u64)dd->ipath_rx_pol_inv) <<\r\nINFINIPATH_XGXS_RX_POL_SHIFT;\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_xgxsconfig, val);\r\n}\r\nreturn 0;\r\n}\r\nvoid ipath_enable_armlaunch(struct ipath_devdata *dd)\r\n{\r\ndd->ipath_lasterror &= ~INFINIPATH_E_SPIOARMLAUNCH;\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_errorclear,\r\nINFINIPATH_E_SPIOARMLAUNCH);\r\ndd->ipath_errormask |= INFINIPATH_E_SPIOARMLAUNCH;\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_errormask,\r\ndd->ipath_errormask);\r\n}\r\nvoid ipath_disable_armlaunch(struct ipath_devdata *dd)\r\n{\r\ndd->ipath_maskederrs &= ~INFINIPATH_E_SPIOARMLAUNCH;\r\ndd->ipath_errormask &= ~INFINIPATH_E_SPIOARMLAUNCH;\r\nipath_write_kreg(dd, dd->ipath_kregs->kr_errormask,\r\ndd->ipath_errormask);\r\n}
