static int ics_deliver_irq(struct kvmppc_xics *xics, u32 irq, u32 level)\r\n{\r\nstruct ics_irq_state *state;\r\nstruct kvmppc_ics *ics;\r\nu16 src;\r\nXICS_DBG("ics deliver %#x (level: %d)\n", irq, level);\r\nics = kvmppc_xics_find_ics(xics, irq, &src);\r\nif (!ics) {\r\nXICS_DBG("ics_deliver_irq: IRQ 0x%06x not found !\n", irq);\r\nreturn -EINVAL;\r\n}\r\nstate = &ics->irq_state[src];\r\nif (!state->exists)\r\nreturn -EINVAL;\r\nif (level == 1 || level == KVM_INTERRUPT_SET_LEVEL)\r\nstate->asserted = 1;\r\nelse if (level == 0 || level == KVM_INTERRUPT_UNSET) {\r\nstate->asserted = 0;\r\nreturn 0;\r\n}\r\nicp_deliver_irq(xics, NULL, irq);\r\nreturn 0;\r\n}\r\nstatic void ics_check_resend(struct kvmppc_xics *xics, struct kvmppc_ics *ics,\r\nstruct kvmppc_icp *icp)\r\n{\r\nint i;\r\nmutex_lock(&ics->lock);\r\nfor (i = 0; i < KVMPPC_XICS_IRQ_PER_ICS; i++) {\r\nstruct ics_irq_state *state = &ics->irq_state[i];\r\nif (!state->resend)\r\ncontinue;\r\nXICS_DBG("resend %#x prio %#x\n", state->number,\r\nstate->priority);\r\nmutex_unlock(&ics->lock);\r\nicp_deliver_irq(xics, icp, state->number);\r\nmutex_lock(&ics->lock);\r\n}\r\nmutex_unlock(&ics->lock);\r\n}\r\nstatic bool write_xive(struct kvmppc_xics *xics, struct kvmppc_ics *ics,\r\nstruct ics_irq_state *state,\r\nu32 server, u32 priority, u32 saved_priority)\r\n{\r\nbool deliver;\r\nmutex_lock(&ics->lock);\r\nstate->server = server;\r\nstate->priority = priority;\r\nstate->saved_priority = saved_priority;\r\ndeliver = false;\r\nif ((state->masked_pending || state->resend) && priority != MASKED) {\r\nstate->masked_pending = 0;\r\ndeliver = true;\r\n}\r\nmutex_unlock(&ics->lock);\r\nreturn deliver;\r\n}\r\nint kvmppc_xics_set_xive(struct kvm *kvm, u32 irq, u32 server, u32 priority)\r\n{\r\nstruct kvmppc_xics *xics = kvm->arch.xics;\r\nstruct kvmppc_icp *icp;\r\nstruct kvmppc_ics *ics;\r\nstruct ics_irq_state *state;\r\nu16 src;\r\nif (!xics)\r\nreturn -ENODEV;\r\nics = kvmppc_xics_find_ics(xics, irq, &src);\r\nif (!ics)\r\nreturn -EINVAL;\r\nstate = &ics->irq_state[src];\r\nicp = kvmppc_xics_find_server(kvm, server);\r\nif (!icp)\r\nreturn -EINVAL;\r\nXICS_DBG("set_xive %#x server %#x prio %#x MP:%d RS:%d\n",\r\nirq, server, priority,\r\nstate->masked_pending, state->resend);\r\nif (write_xive(xics, ics, state, server, priority, priority))\r\nicp_deliver_irq(xics, icp, irq);\r\nreturn 0;\r\n}\r\nint kvmppc_xics_get_xive(struct kvm *kvm, u32 irq, u32 *server, u32 *priority)\r\n{\r\nstruct kvmppc_xics *xics = kvm->arch.xics;\r\nstruct kvmppc_ics *ics;\r\nstruct ics_irq_state *state;\r\nu16 src;\r\nif (!xics)\r\nreturn -ENODEV;\r\nics = kvmppc_xics_find_ics(xics, irq, &src);\r\nif (!ics)\r\nreturn -EINVAL;\r\nstate = &ics->irq_state[src];\r\nmutex_lock(&ics->lock);\r\n*server = state->server;\r\n*priority = state->priority;\r\nmutex_unlock(&ics->lock);\r\nreturn 0;\r\n}\r\nint kvmppc_xics_int_on(struct kvm *kvm, u32 irq)\r\n{\r\nstruct kvmppc_xics *xics = kvm->arch.xics;\r\nstruct kvmppc_icp *icp;\r\nstruct kvmppc_ics *ics;\r\nstruct ics_irq_state *state;\r\nu16 src;\r\nif (!xics)\r\nreturn -ENODEV;\r\nics = kvmppc_xics_find_ics(xics, irq, &src);\r\nif (!ics)\r\nreturn -EINVAL;\r\nstate = &ics->irq_state[src];\r\nicp = kvmppc_xics_find_server(kvm, state->server);\r\nif (!icp)\r\nreturn -EINVAL;\r\nif (write_xive(xics, ics, state, state->server, state->saved_priority,\r\nstate->saved_priority))\r\nicp_deliver_irq(xics, icp, irq);\r\nreturn 0;\r\n}\r\nint kvmppc_xics_int_off(struct kvm *kvm, u32 irq)\r\n{\r\nstruct kvmppc_xics *xics = kvm->arch.xics;\r\nstruct kvmppc_ics *ics;\r\nstruct ics_irq_state *state;\r\nu16 src;\r\nif (!xics)\r\nreturn -ENODEV;\r\nics = kvmppc_xics_find_ics(xics, irq, &src);\r\nif (!ics)\r\nreturn -EINVAL;\r\nstate = &ics->irq_state[src];\r\nwrite_xive(xics, ics, state, state->server, MASKED, state->priority);\r\nreturn 0;\r\n}\r\nstatic inline bool icp_try_update(struct kvmppc_icp *icp,\r\nunion kvmppc_icp_state old,\r\nunion kvmppc_icp_state new,\r\nbool change_self)\r\n{\r\nbool success;\r\nnew.out_ee = (new.xisr && (new.pending_pri < new.cppr));\r\nsuccess = cmpxchg64(&icp->state.raw, old.raw, new.raw) == old.raw;\r\nif (!success)\r\ngoto bail;\r\nXICS_DBG("UPD [%04x] - C:%02x M:%02x PP: %02x PI:%06x R:%d O:%d\n",\r\nicp->server_num,\r\nold.cppr, old.mfrr, old.pending_pri, old.xisr,\r\nold.need_resend, old.out_ee);\r\nXICS_DBG("UPD - C:%02x M:%02x PP: %02x PI:%06x R:%d O:%d\n",\r\nnew.cppr, new.mfrr, new.pending_pri, new.xisr,\r\nnew.need_resend, new.out_ee);\r\nif (new.out_ee) {\r\nkvmppc_book3s_queue_irqprio(icp->vcpu,\r\nBOOK3S_INTERRUPT_EXTERNAL_LEVEL);\r\nif (!change_self)\r\nkvmppc_fast_vcpu_kick(icp->vcpu);\r\n}\r\nbail:\r\nreturn success;\r\n}\r\nstatic void icp_check_resend(struct kvmppc_xics *xics,\r\nstruct kvmppc_icp *icp)\r\n{\r\nu32 icsid;\r\nsmp_rmb();\r\nfor_each_set_bit(icsid, icp->resend_map, xics->max_icsid + 1) {\r\nstruct kvmppc_ics *ics = xics->ics[icsid];\r\nif (!test_and_clear_bit(icsid, icp->resend_map))\r\ncontinue;\r\nif (!ics)\r\ncontinue;\r\nics_check_resend(xics, ics, icp);\r\n}\r\n}\r\nstatic bool icp_try_to_deliver(struct kvmppc_icp *icp, u32 irq, u8 priority,\r\nu32 *reject)\r\n{\r\nunion kvmppc_icp_state old_state, new_state;\r\nbool success;\r\nXICS_DBG("try deliver %#x(P:%#x) to server %#x\n", irq, priority,\r\nicp->server_num);\r\ndo {\r\nold_state = new_state = ACCESS_ONCE(icp->state);\r\n*reject = 0;\r\nsuccess = new_state.cppr > priority &&\r\nnew_state.mfrr > priority &&\r\nnew_state.pending_pri > priority;\r\nif (success) {\r\n*reject = new_state.xisr;\r\nnew_state.xisr = irq;\r\nnew_state.pending_pri = priority;\r\n} else {\r\nnew_state.need_resend = true;\r\n}\r\n} while (!icp_try_update(icp, old_state, new_state, false));\r\nreturn success;\r\n}\r\nstatic void icp_deliver_irq(struct kvmppc_xics *xics, struct kvmppc_icp *icp,\r\nu32 new_irq)\r\n{\r\nstruct ics_irq_state *state;\r\nstruct kvmppc_ics *ics;\r\nu32 reject;\r\nu16 src;\r\nagain:\r\nics = kvmppc_xics_find_ics(xics, new_irq, &src);\r\nif (!ics) {\r\nXICS_DBG("icp_deliver_irq: IRQ 0x%06x not found !\n", new_irq);\r\nreturn;\r\n}\r\nstate = &ics->irq_state[src];\r\nmutex_lock(&ics->lock);\r\nif (!icp || state->server != icp->server_num) {\r\nicp = kvmppc_xics_find_server(xics->kvm, state->server);\r\nif (!icp) {\r\npr_warn("icp_deliver_irq: IRQ 0x%06x server 0x%x not found !\n",\r\nnew_irq, state->server);\r\ngoto out;\r\n}\r\n}\r\nstate->resend = 0;\r\nif (state->priority == MASKED) {\r\nXICS_DBG("irq %#x masked pending\n", new_irq);\r\nstate->masked_pending = 1;\r\ngoto out;\r\n}\r\nif (icp_try_to_deliver(icp, new_irq, state->priority, &reject)) {\r\nif (reject && reject != XICS_IPI) {\r\nmutex_unlock(&ics->lock);\r\nnew_irq = reject;\r\ngoto again;\r\n}\r\n} else {\r\nset_bit(ics->icsid, icp->resend_map);\r\nstate->resend = 1;\r\nsmp_mb();\r\nif (!icp->state.need_resend) {\r\nmutex_unlock(&ics->lock);\r\ngoto again;\r\n}\r\n}\r\nout:\r\nmutex_unlock(&ics->lock);\r\n}\r\nstatic void icp_down_cppr(struct kvmppc_xics *xics, struct kvmppc_icp *icp,\r\nu8 new_cppr)\r\n{\r\nunion kvmppc_icp_state old_state, new_state;\r\nbool resend;\r\ndo {\r\nold_state = new_state = ACCESS_ONCE(icp->state);\r\nnew_state.cppr = new_cppr;\r\nif (new_state.mfrr < new_cppr &&\r\nnew_state.mfrr <= new_state.pending_pri) {\r\nWARN_ON(new_state.xisr != XICS_IPI &&\r\nnew_state.xisr != 0);\r\nnew_state.pending_pri = new_state.mfrr;\r\nnew_state.xisr = XICS_IPI;\r\n}\r\nresend = new_state.need_resend;\r\nnew_state.need_resend = 0;\r\n} while (!icp_try_update(icp, old_state, new_state, true));\r\nif (resend)\r\nicp_check_resend(xics, icp);\r\n}\r\nstatic noinline unsigned long kvmppc_h_xirr(struct kvm_vcpu *vcpu)\r\n{\r\nunion kvmppc_icp_state old_state, new_state;\r\nstruct kvmppc_icp *icp = vcpu->arch.icp;\r\nu32 xirr;\r\nkvmppc_book3s_dequeue_irqprio(icp->vcpu,\r\nBOOK3S_INTERRUPT_EXTERNAL_LEVEL);\r\ndo {\r\nold_state = new_state = ACCESS_ONCE(icp->state);\r\nxirr = old_state.xisr | (((u32)old_state.cppr) << 24);\r\nif (!old_state.xisr)\r\nbreak;\r\nnew_state.cppr = new_state.pending_pri;\r\nnew_state.pending_pri = 0xff;\r\nnew_state.xisr = 0;\r\n} while (!icp_try_update(icp, old_state, new_state, true));\r\nXICS_DBG("h_xirr vcpu %d xirr %#x\n", vcpu->vcpu_id, xirr);\r\nreturn xirr;\r\n}\r\nstatic noinline int kvmppc_h_ipi(struct kvm_vcpu *vcpu, unsigned long server,\r\nunsigned long mfrr)\r\n{\r\nunion kvmppc_icp_state old_state, new_state;\r\nstruct kvmppc_xics *xics = vcpu->kvm->arch.xics;\r\nstruct kvmppc_icp *icp;\r\nu32 reject;\r\nbool resend;\r\nbool local;\r\nXICS_DBG("h_ipi vcpu %d to server %lu mfrr %#lx\n",\r\nvcpu->vcpu_id, server, mfrr);\r\nicp = vcpu->arch.icp;\r\nlocal = icp->server_num == server;\r\nif (!local) {\r\nicp = kvmppc_xics_find_server(vcpu->kvm, server);\r\nif (!icp)\r\nreturn H_PARAMETER;\r\n}\r\ndo {\r\nold_state = new_state = ACCESS_ONCE(icp->state);\r\nnew_state.mfrr = mfrr;\r\nreject = 0;\r\nresend = false;\r\nif (mfrr < new_state.cppr) {\r\nif (mfrr <= new_state.pending_pri)\r\nreject = new_state.xisr;\r\nnew_state.pending_pri = mfrr;\r\nnew_state.xisr = XICS_IPI;\r\n}\r\nif (mfrr > old_state.mfrr && mfrr > new_state.cppr) {\r\nresend = new_state.need_resend;\r\nnew_state.need_resend = 0;\r\n}\r\n} while (!icp_try_update(icp, old_state, new_state, local));\r\nif (reject && reject != XICS_IPI)\r\nicp_deliver_irq(xics, icp, reject);\r\nif (resend)\r\nicp_check_resend(xics, icp);\r\nreturn H_SUCCESS;\r\n}\r\nstatic int kvmppc_h_ipoll(struct kvm_vcpu *vcpu, unsigned long server)\r\n{\r\nunion kvmppc_icp_state state;\r\nstruct kvmppc_icp *icp;\r\nicp = vcpu->arch.icp;\r\nif (icp->server_num != server) {\r\nicp = kvmppc_xics_find_server(vcpu->kvm, server);\r\nif (!icp)\r\nreturn H_PARAMETER;\r\n}\r\nstate = ACCESS_ONCE(icp->state);\r\nkvmppc_set_gpr(vcpu, 4, ((u32)state.cppr << 24) | state.xisr);\r\nkvmppc_set_gpr(vcpu, 5, state.mfrr);\r\nreturn H_SUCCESS;\r\n}\r\nstatic noinline void kvmppc_h_cppr(struct kvm_vcpu *vcpu, unsigned long cppr)\r\n{\r\nunion kvmppc_icp_state old_state, new_state;\r\nstruct kvmppc_xics *xics = vcpu->kvm->arch.xics;\r\nstruct kvmppc_icp *icp = vcpu->arch.icp;\r\nu32 reject;\r\nXICS_DBG("h_cppr vcpu %d cppr %#lx\n", vcpu->vcpu_id, cppr);\r\nif (cppr > icp->state.cppr)\r\nicp_down_cppr(xics, icp, cppr);\r\nelse if (cppr == icp->state.cppr)\r\nreturn;\r\nkvmppc_book3s_dequeue_irqprio(icp->vcpu,\r\nBOOK3S_INTERRUPT_EXTERNAL_LEVEL);\r\ndo {\r\nold_state = new_state = ACCESS_ONCE(icp->state);\r\nreject = 0;\r\nnew_state.cppr = cppr;\r\nif (cppr <= new_state.pending_pri) {\r\nreject = new_state.xisr;\r\nnew_state.xisr = 0;\r\nnew_state.pending_pri = 0xff;\r\n}\r\n} while (!icp_try_update(icp, old_state, new_state, true));\r\nif (reject && reject != XICS_IPI)\r\nicp_deliver_irq(xics, icp, reject);\r\n}\r\nstatic noinline int kvmppc_h_eoi(struct kvm_vcpu *vcpu, unsigned long xirr)\r\n{\r\nstruct kvmppc_xics *xics = vcpu->kvm->arch.xics;\r\nstruct kvmppc_icp *icp = vcpu->arch.icp;\r\nstruct kvmppc_ics *ics;\r\nstruct ics_irq_state *state;\r\nu32 irq = xirr & 0x00ffffff;\r\nu16 src;\r\nXICS_DBG("h_eoi vcpu %d eoi %#lx\n", vcpu->vcpu_id, xirr);\r\nicp_down_cppr(xics, icp, xirr >> 24);\r\nif (irq == XICS_IPI)\r\nreturn H_SUCCESS;\r\nics = kvmppc_xics_find_ics(xics, irq, &src);\r\nif (!ics) {\r\nXICS_DBG("h_eoi: IRQ 0x%06x not found !\n", irq);\r\nreturn H_PARAMETER;\r\n}\r\nstate = &ics->irq_state[src];\r\nif (state->asserted)\r\nicp_deliver_irq(xics, icp, irq);\r\nkvm_notify_acked_irq(vcpu->kvm, 0, irq);\r\nreturn H_SUCCESS;\r\n}\r\nstatic noinline int kvmppc_xics_rm_complete(struct kvm_vcpu *vcpu, u32 hcall)\r\n{\r\nstruct kvmppc_xics *xics = vcpu->kvm->arch.xics;\r\nstruct kvmppc_icp *icp = vcpu->arch.icp;\r\nXICS_DBG("XICS_RM: H_%x completing, act: %x state: %lx tgt: %p\n",\r\nhcall, icp->rm_action, icp->rm_dbgstate.raw, icp->rm_dbgtgt);\r\nif (icp->rm_action & XICS_RM_KICK_VCPU)\r\nkvmppc_fast_vcpu_kick(icp->rm_kick_target);\r\nif (icp->rm_action & XICS_RM_CHECK_RESEND)\r\nicp_check_resend(xics, icp);\r\nif (icp->rm_action & XICS_RM_REJECT)\r\nicp_deliver_irq(xics, icp, icp->rm_reject);\r\nif (icp->rm_action & XICS_RM_NOTIFY_EOI)\r\nkvm_notify_acked_irq(vcpu->kvm, 0, icp->rm_eoied_irq);\r\nicp->rm_action = 0;\r\nreturn H_SUCCESS;\r\n}\r\nint kvmppc_xics_hcall(struct kvm_vcpu *vcpu, u32 req)\r\n{\r\nstruct kvmppc_xics *xics = vcpu->kvm->arch.xics;\r\nunsigned long res;\r\nint rc = H_SUCCESS;\r\nif (!xics || !vcpu->arch.icp)\r\nreturn H_HARDWARE;\r\nswitch (req) {\r\ncase H_XIRR_X:\r\nres = kvmppc_h_xirr(vcpu);\r\nkvmppc_set_gpr(vcpu, 4, res);\r\nkvmppc_set_gpr(vcpu, 5, get_tb());\r\nreturn rc;\r\ncase H_IPOLL:\r\nrc = kvmppc_h_ipoll(vcpu, kvmppc_get_gpr(vcpu, 4));\r\nreturn rc;\r\n}\r\nif (xics->real_mode && is_kvmppc_hv_enabled(vcpu->kvm))\r\nreturn kvmppc_xics_rm_complete(vcpu, req);\r\nswitch (req) {\r\ncase H_XIRR:\r\nres = kvmppc_h_xirr(vcpu);\r\nkvmppc_set_gpr(vcpu, 4, res);\r\nbreak;\r\ncase H_CPPR:\r\nkvmppc_h_cppr(vcpu, kvmppc_get_gpr(vcpu, 4));\r\nbreak;\r\ncase H_EOI:\r\nrc = kvmppc_h_eoi(vcpu, kvmppc_get_gpr(vcpu, 4));\r\nbreak;\r\ncase H_IPI:\r\nrc = kvmppc_h_ipi(vcpu, kvmppc_get_gpr(vcpu, 4),\r\nkvmppc_get_gpr(vcpu, 5));\r\nbreak;\r\n}\r\nreturn rc;\r\n}\r\nstatic int xics_debug_show(struct seq_file *m, void *private)\r\n{\r\nstruct kvmppc_xics *xics = m->private;\r\nstruct kvm *kvm = xics->kvm;\r\nstruct kvm_vcpu *vcpu;\r\nint icsid, i;\r\nif (!kvm)\r\nreturn 0;\r\nseq_printf(m, "=========\nICP state\n=========\n");\r\nkvm_for_each_vcpu(i, vcpu, kvm) {\r\nstruct kvmppc_icp *icp = vcpu->arch.icp;\r\nunion kvmppc_icp_state state;\r\nif (!icp)\r\ncontinue;\r\nstate.raw = ACCESS_ONCE(icp->state.raw);\r\nseq_printf(m, "cpu server %#lx XIRR:%#x PPRI:%#x CPPR:%#x MFRR:%#x OUT:%d NR:%d\n",\r\nicp->server_num, state.xisr,\r\nstate.pending_pri, state.cppr, state.mfrr,\r\nstate.out_ee, state.need_resend);\r\n}\r\nfor (icsid = 0; icsid <= KVMPPC_XICS_MAX_ICS_ID; icsid++) {\r\nstruct kvmppc_ics *ics = xics->ics[icsid];\r\nif (!ics)\r\ncontinue;\r\nseq_printf(m, "=========\nICS state for ICS 0x%x\n=========\n",\r\nicsid);\r\nmutex_lock(&ics->lock);\r\nfor (i = 0; i < KVMPPC_XICS_IRQ_PER_ICS; i++) {\r\nstruct ics_irq_state *irq = &ics->irq_state[i];\r\nseq_printf(m, "irq 0x%06x: server %#x prio %#x save prio %#x asserted %d resend %d masked pending %d\n",\r\nirq->number, irq->server, irq->priority,\r\nirq->saved_priority, irq->asserted,\r\nirq->resend, irq->masked_pending);\r\n}\r\nmutex_unlock(&ics->lock);\r\n}\r\nreturn 0;\r\n}\r\nstatic int xics_debug_open(struct inode *inode, struct file *file)\r\n{\r\nreturn single_open(file, xics_debug_show, inode->i_private);\r\n}\r\nstatic void xics_debugfs_init(struct kvmppc_xics *xics)\r\n{\r\nchar *name;\r\nname = kasprintf(GFP_KERNEL, "kvm-xics-%p", xics);\r\nif (!name) {\r\npr_err("%s: no memory for name\n", __func__);\r\nreturn;\r\n}\r\nxics->dentry = debugfs_create_file(name, S_IRUGO, powerpc_debugfs_root,\r\nxics, &xics_debug_fops);\r\npr_debug("%s: created %s\n", __func__, name);\r\nkfree(name);\r\n}\r\nstatic struct kvmppc_ics *kvmppc_xics_create_ics(struct kvm *kvm,\r\nstruct kvmppc_xics *xics, int irq)\r\n{\r\nstruct kvmppc_ics *ics;\r\nint i, icsid;\r\nicsid = irq >> KVMPPC_XICS_ICS_SHIFT;\r\nmutex_lock(&kvm->lock);\r\nif (xics->ics[icsid])\r\ngoto out;\r\nics = kzalloc(sizeof(struct kvmppc_ics), GFP_KERNEL);\r\nif (!ics)\r\ngoto out;\r\nmutex_init(&ics->lock);\r\nics->icsid = icsid;\r\nfor (i = 0; i < KVMPPC_XICS_IRQ_PER_ICS; i++) {\r\nics->irq_state[i].number = (icsid << KVMPPC_XICS_ICS_SHIFT) | i;\r\nics->irq_state[i].priority = MASKED;\r\nics->irq_state[i].saved_priority = MASKED;\r\n}\r\nsmp_wmb();\r\nxics->ics[icsid] = ics;\r\nif (icsid > xics->max_icsid)\r\nxics->max_icsid = icsid;\r\nout:\r\nmutex_unlock(&kvm->lock);\r\nreturn xics->ics[icsid];\r\n}\r\nint kvmppc_xics_create_icp(struct kvm_vcpu *vcpu, unsigned long server_num)\r\n{\r\nstruct kvmppc_icp *icp;\r\nif (!vcpu->kvm->arch.xics)\r\nreturn -ENODEV;\r\nif (kvmppc_xics_find_server(vcpu->kvm, server_num))\r\nreturn -EEXIST;\r\nicp = kzalloc(sizeof(struct kvmppc_icp), GFP_KERNEL);\r\nif (!icp)\r\nreturn -ENOMEM;\r\nicp->vcpu = vcpu;\r\nicp->server_num = server_num;\r\nicp->state.mfrr = MASKED;\r\nicp->state.pending_pri = MASKED;\r\nvcpu->arch.icp = icp;\r\nXICS_DBG("created server for vcpu %d\n", vcpu->vcpu_id);\r\nreturn 0;\r\n}\r\nu64 kvmppc_xics_get_icp(struct kvm_vcpu *vcpu)\r\n{\r\nstruct kvmppc_icp *icp = vcpu->arch.icp;\r\nunion kvmppc_icp_state state;\r\nif (!icp)\r\nreturn 0;\r\nstate = icp->state;\r\nreturn ((u64)state.cppr << KVM_REG_PPC_ICP_CPPR_SHIFT) |\r\n((u64)state.xisr << KVM_REG_PPC_ICP_XISR_SHIFT) |\r\n((u64)state.mfrr << KVM_REG_PPC_ICP_MFRR_SHIFT) |\r\n((u64)state.pending_pri << KVM_REG_PPC_ICP_PPRI_SHIFT);\r\n}\r\nint kvmppc_xics_set_icp(struct kvm_vcpu *vcpu, u64 icpval)\r\n{\r\nstruct kvmppc_icp *icp = vcpu->arch.icp;\r\nstruct kvmppc_xics *xics = vcpu->kvm->arch.xics;\r\nunion kvmppc_icp_state old_state, new_state;\r\nstruct kvmppc_ics *ics;\r\nu8 cppr, mfrr, pending_pri;\r\nu32 xisr;\r\nu16 src;\r\nbool resend;\r\nif (!icp || !xics)\r\nreturn -ENOENT;\r\ncppr = icpval >> KVM_REG_PPC_ICP_CPPR_SHIFT;\r\nxisr = (icpval >> KVM_REG_PPC_ICP_XISR_SHIFT) &\r\nKVM_REG_PPC_ICP_XISR_MASK;\r\nmfrr = icpval >> KVM_REG_PPC_ICP_MFRR_SHIFT;\r\npending_pri = icpval >> KVM_REG_PPC_ICP_PPRI_SHIFT;\r\nif (xisr == 0) {\r\nif (pending_pri != 0xff)\r\nreturn -EINVAL;\r\n} else if (xisr == XICS_IPI) {\r\nif (pending_pri != mfrr || pending_pri >= cppr)\r\nreturn -EINVAL;\r\n} else {\r\nif (pending_pri >= mfrr || pending_pri >= cppr)\r\nreturn -EINVAL;\r\nics = kvmppc_xics_find_ics(xics, xisr, &src);\r\nif (!ics)\r\nreturn -EINVAL;\r\n}\r\nnew_state.raw = 0;\r\nnew_state.cppr = cppr;\r\nnew_state.xisr = xisr;\r\nnew_state.mfrr = mfrr;\r\nnew_state.pending_pri = pending_pri;\r\nkvmppc_book3s_dequeue_irqprio(icp->vcpu,\r\nBOOK3S_INTERRUPT_EXTERNAL_LEVEL);\r\ndo {\r\nold_state = ACCESS_ONCE(icp->state);\r\nif (new_state.mfrr <= old_state.mfrr) {\r\nresend = false;\r\nnew_state.need_resend = old_state.need_resend;\r\n} else {\r\nresend = old_state.need_resend;\r\nnew_state.need_resend = 0;\r\n}\r\n} while (!icp_try_update(icp, old_state, new_state, false));\r\nif (resend)\r\nicp_check_resend(xics, icp);\r\nreturn 0;\r\n}\r\nstatic int xics_get_source(struct kvmppc_xics *xics, long irq, u64 addr)\r\n{\r\nint ret;\r\nstruct kvmppc_ics *ics;\r\nstruct ics_irq_state *irqp;\r\nu64 __user *ubufp = (u64 __user *) addr;\r\nu16 idx;\r\nu64 val, prio;\r\nics = kvmppc_xics_find_ics(xics, irq, &idx);\r\nif (!ics)\r\nreturn -ENOENT;\r\nirqp = &ics->irq_state[idx];\r\nmutex_lock(&ics->lock);\r\nret = -ENOENT;\r\nif (irqp->exists) {\r\nval = irqp->server;\r\nprio = irqp->priority;\r\nif (prio == MASKED) {\r\nval |= KVM_XICS_MASKED;\r\nprio = irqp->saved_priority;\r\n}\r\nval |= prio << KVM_XICS_PRIORITY_SHIFT;\r\nif (irqp->asserted)\r\nval |= KVM_XICS_LEVEL_SENSITIVE | KVM_XICS_PENDING;\r\nelse if (irqp->masked_pending || irqp->resend)\r\nval |= KVM_XICS_PENDING;\r\nret = 0;\r\n}\r\nmutex_unlock(&ics->lock);\r\nif (!ret && put_user(val, ubufp))\r\nret = -EFAULT;\r\nreturn ret;\r\n}\r\nstatic int xics_set_source(struct kvmppc_xics *xics, long irq, u64 addr)\r\n{\r\nstruct kvmppc_ics *ics;\r\nstruct ics_irq_state *irqp;\r\nu64 __user *ubufp = (u64 __user *) addr;\r\nu16 idx;\r\nu64 val;\r\nu8 prio;\r\nu32 server;\r\nif (irq < KVMPPC_XICS_FIRST_IRQ || irq >= KVMPPC_XICS_NR_IRQS)\r\nreturn -ENOENT;\r\nics = kvmppc_xics_find_ics(xics, irq, &idx);\r\nif (!ics) {\r\nics = kvmppc_xics_create_ics(xics->kvm, xics, irq);\r\nif (!ics)\r\nreturn -ENOMEM;\r\n}\r\nirqp = &ics->irq_state[idx];\r\nif (get_user(val, ubufp))\r\nreturn -EFAULT;\r\nserver = val & KVM_XICS_DESTINATION_MASK;\r\nprio = val >> KVM_XICS_PRIORITY_SHIFT;\r\nif (prio != MASKED &&\r\nkvmppc_xics_find_server(xics->kvm, server) == NULL)\r\nreturn -EINVAL;\r\nmutex_lock(&ics->lock);\r\nirqp->server = server;\r\nirqp->saved_priority = prio;\r\nif (val & KVM_XICS_MASKED)\r\nprio = MASKED;\r\nirqp->priority = prio;\r\nirqp->resend = 0;\r\nirqp->masked_pending = 0;\r\nirqp->asserted = 0;\r\nif ((val & KVM_XICS_PENDING) && (val & KVM_XICS_LEVEL_SENSITIVE))\r\nirqp->asserted = 1;\r\nirqp->exists = 1;\r\nmutex_unlock(&ics->lock);\r\nif (val & KVM_XICS_PENDING)\r\nicp_deliver_irq(xics, NULL, irqp->number);\r\nreturn 0;\r\n}\r\nint kvm_set_irq(struct kvm *kvm, int irq_source_id, u32 irq, int level,\r\nbool line_status)\r\n{\r\nstruct kvmppc_xics *xics = kvm->arch.xics;\r\nreturn ics_deliver_irq(xics, irq, level);\r\n}\r\nint kvm_set_msi(struct kvm_kernel_irq_routing_entry *irq_entry, struct kvm *kvm,\r\nint irq_source_id, int level, bool line_status)\r\n{\r\nif (!level)\r\nreturn -1;\r\nreturn kvm_set_irq(kvm, irq_source_id, irq_entry->gsi,\r\nlevel, line_status);\r\n}\r\nstatic int xics_set_attr(struct kvm_device *dev, struct kvm_device_attr *attr)\r\n{\r\nstruct kvmppc_xics *xics = dev->private;\r\nswitch (attr->group) {\r\ncase KVM_DEV_XICS_GRP_SOURCES:\r\nreturn xics_set_source(xics, attr->attr, attr->addr);\r\n}\r\nreturn -ENXIO;\r\n}\r\nstatic int xics_get_attr(struct kvm_device *dev, struct kvm_device_attr *attr)\r\n{\r\nstruct kvmppc_xics *xics = dev->private;\r\nswitch (attr->group) {\r\ncase KVM_DEV_XICS_GRP_SOURCES:\r\nreturn xics_get_source(xics, attr->attr, attr->addr);\r\n}\r\nreturn -ENXIO;\r\n}\r\nstatic int xics_has_attr(struct kvm_device *dev, struct kvm_device_attr *attr)\r\n{\r\nswitch (attr->group) {\r\ncase KVM_DEV_XICS_GRP_SOURCES:\r\nif (attr->attr >= KVMPPC_XICS_FIRST_IRQ &&\r\nattr->attr < KVMPPC_XICS_NR_IRQS)\r\nreturn 0;\r\nbreak;\r\n}\r\nreturn -ENXIO;\r\n}\r\nstatic void kvmppc_xics_free(struct kvm_device *dev)\r\n{\r\nstruct kvmppc_xics *xics = dev->private;\r\nint i;\r\nstruct kvm *kvm = xics->kvm;\r\ndebugfs_remove(xics->dentry);\r\nif (kvm)\r\nkvm->arch.xics = NULL;\r\nfor (i = 0; i <= xics->max_icsid; i++)\r\nkfree(xics->ics[i]);\r\nkfree(xics);\r\nkfree(dev);\r\n}\r\nstatic int kvmppc_xics_create(struct kvm_device *dev, u32 type)\r\n{\r\nstruct kvmppc_xics *xics;\r\nstruct kvm *kvm = dev->kvm;\r\nint ret = 0;\r\nxics = kzalloc(sizeof(*xics), GFP_KERNEL);\r\nif (!xics)\r\nreturn -ENOMEM;\r\ndev->private = xics;\r\nxics->dev = dev;\r\nxics->kvm = kvm;\r\nmutex_lock(&kvm->lock);\r\nif (kvm->arch.xics)\r\nret = -EEXIST;\r\nelse\r\nkvm->arch.xics = xics;\r\nmutex_unlock(&kvm->lock);\r\nif (ret) {\r\nkfree(xics);\r\nreturn ret;\r\n}\r\nxics_debugfs_init(xics);\r\n#ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE\r\nif (cpu_has_feature(CPU_FTR_ARCH_206)) {\r\nxics->real_mode = ENABLE_REALMODE;\r\nxics->real_mode_dbg = DEBUG_REALMODE;\r\n}\r\n#endif\r\nreturn 0;\r\n}\r\nint kvmppc_xics_connect_vcpu(struct kvm_device *dev, struct kvm_vcpu *vcpu,\r\nu32 xcpu)\r\n{\r\nstruct kvmppc_xics *xics = dev->private;\r\nint r = -EBUSY;\r\nif (dev->ops != &kvm_xics_ops)\r\nreturn -EPERM;\r\nif (xics->kvm != vcpu->kvm)\r\nreturn -EPERM;\r\nif (vcpu->arch.irq_type)\r\nreturn -EBUSY;\r\nr = kvmppc_xics_create_icp(vcpu, xcpu);\r\nif (!r)\r\nvcpu->arch.irq_type = KVMPPC_IRQ_XICS;\r\nreturn r;\r\n}\r\nvoid kvmppc_xics_free_icp(struct kvm_vcpu *vcpu)\r\n{\r\nif (!vcpu->arch.icp)\r\nreturn;\r\nkfree(vcpu->arch.icp);\r\nvcpu->arch.icp = NULL;\r\nvcpu->arch.irq_type = KVMPPC_IRQ_DEFAULT;\r\n}\r\nstatic int xics_set_irq(struct kvm_kernel_irq_routing_entry *e,\r\nstruct kvm *kvm, int irq_source_id, int level,\r\nbool line_status)\r\n{\r\nreturn kvm_set_irq(kvm, irq_source_id, e->gsi, level, line_status);\r\n}\r\nint kvm_irq_map_gsi(struct kvm *kvm,\r\nstruct kvm_kernel_irq_routing_entry *entries, int gsi)\r\n{\r\nentries->gsi = gsi;\r\nentries->type = KVM_IRQ_ROUTING_IRQCHIP;\r\nentries->set = xics_set_irq;\r\nentries->irqchip.irqchip = 0;\r\nentries->irqchip.pin = gsi;\r\nreturn 1;\r\n}\r\nint kvm_irq_map_chip_pin(struct kvm *kvm, unsigned irqchip, unsigned pin)\r\n{\r\nreturn pin;\r\n}
