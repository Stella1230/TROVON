static int caam_reset_hw_jr(struct device *dev)\r\n{\r\nstruct caam_drv_private_jr *jrp = dev_get_drvdata(dev);\r\nunsigned int timeout = 100000;\r\nsetbits32(&jrp->rregs->rconfig_lo, JRCFG_IMSK);\r\nwr_reg32(&jrp->rregs->jrcommand, JRCR_RESET);\r\nwhile (((rd_reg32(&jrp->rregs->jrintstatus) & JRINT_ERR_HALT_MASK) ==\r\nJRINT_ERR_HALT_INPROGRESS) && --timeout)\r\ncpu_relax();\r\nif ((rd_reg32(&jrp->rregs->jrintstatus) & JRINT_ERR_HALT_MASK) !=\r\nJRINT_ERR_HALT_COMPLETE || timeout == 0) {\r\ndev_err(dev, "failed to flush job ring %d\n", jrp->ridx);\r\nreturn -EIO;\r\n}\r\ntimeout = 100000;\r\nwr_reg32(&jrp->rregs->jrcommand, JRCR_RESET);\r\nwhile ((rd_reg32(&jrp->rregs->jrcommand) & JRCR_RESET) && --timeout)\r\ncpu_relax();\r\nif (timeout == 0) {\r\ndev_err(dev, "failed to reset job ring %d\n", jrp->ridx);\r\nreturn -EIO;\r\n}\r\nclrbits32(&jrp->rregs->rconfig_lo, JRCFG_IMSK);\r\nreturn 0;\r\n}\r\nint caam_jr_shutdown(struct device *dev)\r\n{\r\nstruct caam_drv_private_jr *jrp = dev_get_drvdata(dev);\r\ndma_addr_t inpbusaddr, outbusaddr;\r\nint ret;\r\nret = caam_reset_hw_jr(dev);\r\ntasklet_kill(&jrp->irqtask);\r\nfree_irq(jrp->irq, dev);\r\ninpbusaddr = rd_reg64(&jrp->rregs->inpring_base);\r\noutbusaddr = rd_reg64(&jrp->rregs->outring_base);\r\ndma_free_coherent(dev, sizeof(dma_addr_t) * JOBR_DEPTH,\r\njrp->inpring, inpbusaddr);\r\ndma_free_coherent(dev, sizeof(struct jr_outentry) * JOBR_DEPTH,\r\njrp->outring, outbusaddr);\r\nkfree(jrp->entinfo);\r\nreturn ret;\r\n}\r\nstatic int caam_jr_remove(struct platform_device *pdev)\r\n{\r\nint ret;\r\nstruct device *jrdev;\r\nstruct caam_drv_private_jr *jrpriv;\r\njrdev = &pdev->dev;\r\njrpriv = dev_get_drvdata(jrdev);\r\nif (atomic_read(&jrpriv->tfm_count)) {\r\ndev_err(jrdev, "Device is busy\n");\r\nreturn -EBUSY;\r\n}\r\nspin_lock(&driver_data.jr_alloc_lock);\r\nlist_del(&jrpriv->list_node);\r\nspin_unlock(&driver_data.jr_alloc_lock);\r\nret = caam_jr_shutdown(jrdev);\r\nif (ret)\r\ndev_err(jrdev, "Failed to shut down job ring\n");\r\nirq_dispose_mapping(jrpriv->irq);\r\nreturn ret;\r\n}\r\nstatic irqreturn_t caam_jr_interrupt(int irq, void *st_dev)\r\n{\r\nstruct device *dev = st_dev;\r\nstruct caam_drv_private_jr *jrp = dev_get_drvdata(dev);\r\nu32 irqstate;\r\nirqstate = rd_reg32(&jrp->rregs->jrintstatus);\r\nif (!irqstate)\r\nreturn IRQ_NONE;\r\nif (irqstate & JRINT_JR_ERROR) {\r\ndev_err(dev, "job ring error: irqstate: %08x\n", irqstate);\r\nBUG();\r\n}\r\nsetbits32(&jrp->rregs->rconfig_lo, JRCFG_IMSK);\r\nwr_reg32(&jrp->rregs->jrintstatus, irqstate);\r\npreempt_disable();\r\ntasklet_schedule(&jrp->irqtask);\r\npreempt_enable();\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void caam_jr_dequeue(unsigned long devarg)\r\n{\r\nint hw_idx, sw_idx, i, head, tail;\r\nstruct device *dev = (struct device *)devarg;\r\nstruct caam_drv_private_jr *jrp = dev_get_drvdata(dev);\r\nvoid (*usercall)(struct device *dev, u32 *desc, u32 status, void *arg);\r\nu32 *userdesc, userstatus;\r\nvoid *userarg;\r\nwhile (rd_reg32(&jrp->rregs->outring_used)) {\r\nhead = ACCESS_ONCE(jrp->head);\r\nspin_lock(&jrp->outlock);\r\nsw_idx = tail = jrp->tail;\r\nhw_idx = jrp->out_ring_read_index;\r\nfor (i = 0; CIRC_CNT(head, tail + i, JOBR_DEPTH) >= 1; i++) {\r\nsw_idx = (tail + i) & (JOBR_DEPTH - 1);\r\nsmp_read_barrier_depends();\r\nif (jrp->outring[hw_idx].desc ==\r\njrp->entinfo[sw_idx].desc_addr_dma)\r\nbreak;\r\n}\r\nBUG_ON(CIRC_CNT(head, tail + i, JOBR_DEPTH) <= 0);\r\ndma_unmap_single(dev, jrp->outring[hw_idx].desc,\r\njrp->entinfo[sw_idx].desc_size,\r\nDMA_TO_DEVICE);\r\njrp->entinfo[sw_idx].desc_addr_dma = 0;\r\nusercall = jrp->entinfo[sw_idx].callbk;\r\nuserarg = jrp->entinfo[sw_idx].cbkarg;\r\nuserdesc = jrp->entinfo[sw_idx].desc_addr_virt;\r\nuserstatus = jrp->outring[hw_idx].jrstatus;\r\nwr_reg32(&jrp->rregs->outring_rmvd, 1);\r\njrp->out_ring_read_index = (jrp->out_ring_read_index + 1) &\r\n(JOBR_DEPTH - 1);\r\nif (sw_idx == tail) {\r\ndo {\r\ntail = (tail + 1) & (JOBR_DEPTH - 1);\r\nsmp_read_barrier_depends();\r\n} while (CIRC_CNT(head, tail, JOBR_DEPTH) >= 1 &&\r\njrp->entinfo[tail].desc_addr_dma == 0);\r\njrp->tail = tail;\r\n}\r\nspin_unlock(&jrp->outlock);\r\nusercall(dev, userdesc, userstatus, userarg);\r\n}\r\nclrbits32(&jrp->rregs->rconfig_lo, JRCFG_IMSK);\r\n}\r\nstruct device *caam_jr_alloc(void)\r\n{\r\nstruct caam_drv_private_jr *jrpriv, *min_jrpriv = NULL;\r\nstruct device *dev = NULL;\r\nint min_tfm_cnt = INT_MAX;\r\nint tfm_cnt;\r\nspin_lock(&driver_data.jr_alloc_lock);\r\nif (list_empty(&driver_data.jr_list)) {\r\nspin_unlock(&driver_data.jr_alloc_lock);\r\nreturn ERR_PTR(-ENODEV);\r\n}\r\nlist_for_each_entry(jrpriv, &driver_data.jr_list, list_node) {\r\ntfm_cnt = atomic_read(&jrpriv->tfm_count);\r\nif (tfm_cnt < min_tfm_cnt) {\r\nmin_tfm_cnt = tfm_cnt;\r\nmin_jrpriv = jrpriv;\r\n}\r\nif (!min_tfm_cnt)\r\nbreak;\r\n}\r\nif (min_jrpriv) {\r\natomic_inc(&min_jrpriv->tfm_count);\r\ndev = min_jrpriv->dev;\r\n}\r\nspin_unlock(&driver_data.jr_alloc_lock);\r\nreturn dev;\r\n}\r\nvoid caam_jr_free(struct device *rdev)\r\n{\r\nstruct caam_drv_private_jr *jrpriv = dev_get_drvdata(rdev);\r\natomic_dec(&jrpriv->tfm_count);\r\n}\r\nint caam_jr_enqueue(struct device *dev, u32 *desc,\r\nvoid (*cbk)(struct device *dev, u32 *desc,\r\nu32 status, void *areq),\r\nvoid *areq)\r\n{\r\nstruct caam_drv_private_jr *jrp = dev_get_drvdata(dev);\r\nstruct caam_jrentry_info *head_entry;\r\nint head, tail, desc_size;\r\ndma_addr_t desc_dma;\r\ndesc_size = (*desc & HDR_JD_LENGTH_MASK) * sizeof(u32);\r\ndesc_dma = dma_map_single(dev, desc, desc_size, DMA_TO_DEVICE);\r\nif (dma_mapping_error(dev, desc_dma)) {\r\ndev_err(dev, "caam_jr_enqueue(): can't map jobdesc\n");\r\nreturn -EIO;\r\n}\r\nspin_lock_bh(&jrp->inplock);\r\nhead = jrp->head;\r\ntail = ACCESS_ONCE(jrp->tail);\r\nif (!rd_reg32(&jrp->rregs->inpring_avail) ||\r\nCIRC_SPACE(head, tail, JOBR_DEPTH) <= 0) {\r\nspin_unlock_bh(&jrp->inplock);\r\ndma_unmap_single(dev, desc_dma, desc_size, DMA_TO_DEVICE);\r\nreturn -EBUSY;\r\n}\r\nhead_entry = &jrp->entinfo[head];\r\nhead_entry->desc_addr_virt = desc;\r\nhead_entry->desc_size = desc_size;\r\nhead_entry->callbk = (void *)cbk;\r\nhead_entry->cbkarg = areq;\r\nhead_entry->desc_addr_dma = desc_dma;\r\njrp->inpring[jrp->inp_ring_write_index] = desc_dma;\r\nsmp_wmb();\r\njrp->inp_ring_write_index = (jrp->inp_ring_write_index + 1) &\r\n(JOBR_DEPTH - 1);\r\njrp->head = (head + 1) & (JOBR_DEPTH - 1);\r\nwr_reg32(&jrp->rregs->inpring_jobadd, 1);\r\nspin_unlock_bh(&jrp->inplock);\r\nreturn 0;\r\n}\r\nstatic int caam_jr_init(struct device *dev)\r\n{\r\nstruct caam_drv_private_jr *jrp;\r\ndma_addr_t inpbusaddr, outbusaddr;\r\nint i, error;\r\njrp = dev_get_drvdata(dev);\r\ntasklet_init(&jrp->irqtask, caam_jr_dequeue, (unsigned long)dev);\r\nerror = request_irq(jrp->irq, caam_jr_interrupt, IRQF_SHARED,\r\ndev_name(dev), dev);\r\nif (error) {\r\ndev_err(dev, "can't connect JobR %d interrupt (%d)\n",\r\njrp->ridx, jrp->irq);\r\nirq_dispose_mapping(jrp->irq);\r\njrp->irq = 0;\r\nreturn -EINVAL;\r\n}\r\nerror = caam_reset_hw_jr(dev);\r\nif (error)\r\nreturn error;\r\njrp->inpring = dma_alloc_coherent(dev, sizeof(dma_addr_t) * JOBR_DEPTH,\r\n&inpbusaddr, GFP_KERNEL);\r\njrp->outring = dma_alloc_coherent(dev, sizeof(struct jr_outentry) *\r\nJOBR_DEPTH, &outbusaddr, GFP_KERNEL);\r\njrp->entinfo = kzalloc(sizeof(struct caam_jrentry_info) * JOBR_DEPTH,\r\nGFP_KERNEL);\r\nif ((jrp->inpring == NULL) || (jrp->outring == NULL) ||\r\n(jrp->entinfo == NULL)) {\r\ndev_err(dev, "can't allocate job rings for %d\n",\r\njrp->ridx);\r\nreturn -ENOMEM;\r\n}\r\nfor (i = 0; i < JOBR_DEPTH; i++)\r\njrp->entinfo[i].desc_addr_dma = !0;\r\njrp->inp_ring_write_index = 0;\r\njrp->out_ring_read_index = 0;\r\njrp->head = 0;\r\njrp->tail = 0;\r\nwr_reg64(&jrp->rregs->inpring_base, inpbusaddr);\r\nwr_reg64(&jrp->rregs->outring_base, outbusaddr);\r\nwr_reg32(&jrp->rregs->inpring_size, JOBR_DEPTH);\r\nwr_reg32(&jrp->rregs->outring_size, JOBR_DEPTH);\r\njrp->ringsize = JOBR_DEPTH;\r\nspin_lock_init(&jrp->inplock);\r\nspin_lock_init(&jrp->outlock);\r\nsetbits32(&jrp->rregs->rconfig_lo, JOBR_INTC |\r\n(JOBR_INTC_COUNT_THLD << JRCFG_ICDCT_SHIFT) |\r\n(JOBR_INTC_TIME_THLD << JRCFG_ICTT_SHIFT));\r\nreturn 0;\r\n}\r\nstatic int caam_jr_probe(struct platform_device *pdev)\r\n{\r\nstruct device *jrdev;\r\nstruct device_node *nprop;\r\nstruct caam_job_ring __iomem *ctrl;\r\nstruct caam_drv_private_jr *jrpriv;\r\nstatic int total_jobrs;\r\nint error;\r\njrdev = &pdev->dev;\r\njrpriv = devm_kmalloc(jrdev, sizeof(struct caam_drv_private_jr),\r\nGFP_KERNEL);\r\nif (!jrpriv)\r\nreturn -ENOMEM;\r\ndev_set_drvdata(jrdev, jrpriv);\r\njrpriv->ridx = total_jobrs++;\r\nnprop = pdev->dev.of_node;\r\nctrl = of_iomap(nprop, 0);\r\nif (!ctrl) {\r\ndev_err(jrdev, "of_iomap() failed\n");\r\nreturn -ENOMEM;\r\n}\r\njrpriv->rregs = (struct caam_job_ring __force *)ctrl;\r\nif (sizeof(dma_addr_t) == sizeof(u64))\r\nif (of_device_is_compatible(nprop, "fsl,sec-v5.0-job-ring"))\r\ndma_set_mask_and_coherent(jrdev, DMA_BIT_MASK(40));\r\nelse\r\ndma_set_mask_and_coherent(jrdev, DMA_BIT_MASK(36));\r\nelse\r\ndma_set_mask_and_coherent(jrdev, DMA_BIT_MASK(32));\r\njrpriv->irq = irq_of_parse_and_map(nprop, 0);\r\nerror = caam_jr_init(jrdev);\r\nif (error)\r\nreturn error;\r\njrpriv->dev = jrdev;\r\nspin_lock(&driver_data.jr_alloc_lock);\r\nlist_add_tail(&jrpriv->list_node, &driver_data.jr_list);\r\nspin_unlock(&driver_data.jr_alloc_lock);\r\natomic_set(&jrpriv->tfm_count, 0);\r\nreturn 0;\r\n}\r\nstatic int __init jr_driver_init(void)\r\n{\r\nspin_lock_init(&driver_data.jr_alloc_lock);\r\nINIT_LIST_HEAD(&driver_data.jr_list);\r\nreturn platform_driver_register(&caam_jr_driver);\r\n}\r\nstatic void __exit jr_driver_exit(void)\r\n{\r\nplatform_driver_unregister(&caam_jr_driver);\r\n}
