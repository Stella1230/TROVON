static void\r\nbfad_sm_uninit(struct bfad_s *bfad, enum bfad_sm_event event)\r\n{\r\nbfa_trc(bfad, event);\r\nswitch (event) {\r\ncase BFAD_E_CREATE:\r\nbfa_sm_set_state(bfad, bfad_sm_created);\r\nbfad->bfad_tsk = kthread_create(bfad_worker, (void *) bfad,\r\n"%s", "bfad_worker");\r\nif (IS_ERR(bfad->bfad_tsk)) {\r\nprintk(KERN_INFO "bfad[%d]: Kernel thread "\r\n"creation failed!\n", bfad->inst_no);\r\nbfa_sm_send_event(bfad, BFAD_E_KTHREAD_CREATE_FAILED);\r\n}\r\nbfa_sm_send_event(bfad, BFAD_E_INIT);\r\nbreak;\r\ncase BFAD_E_STOP:\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(bfad, event);\r\n}\r\n}\r\nstatic void\r\nbfad_sm_created(struct bfad_s *bfad, enum bfad_sm_event event)\r\n{\r\nunsigned long flags;\r\nbfa_status_t ret;\r\nbfa_trc(bfad, event);\r\nswitch (event) {\r\ncase BFAD_E_INIT:\r\nbfa_sm_set_state(bfad, bfad_sm_initializing);\r\ninit_completion(&bfad->comp);\r\nif (bfad_setup_intr(bfad)) {\r\nprintk(KERN_WARNING "bfad%d: bfad_setup_intr failed\n",\r\nbfad->inst_no);\r\nbfa_sm_send_event(bfad, BFAD_E_INIT_FAILED);\r\nbreak;\r\n}\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfa_iocfc_init(&bfad->bfa);\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nif ((bfad->bfad_flags & BFAD_MSIX_ON) &&\r\nbfad_install_msix_handler(bfad)) {\r\nprintk(KERN_WARNING "%s: install_msix failed, bfad%d\n",\r\n__func__, bfad->inst_no);\r\n}\r\nbfad_init_timer(bfad);\r\nwait_for_completion(&bfad->comp);\r\nif ((bfad->bfad_flags & BFAD_HAL_INIT_DONE)) {\r\nbfa_sm_send_event(bfad, BFAD_E_INIT_SUCCESS);\r\n} else {\r\nprintk(KERN_WARNING\r\n"bfa %s: bfa init failed\n",\r\nbfad->pci_name);\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfa_fcs_init(&bfad->bfa_fcs);\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nret = bfad_cfg_pport(bfad, BFA_LPORT_ROLE_FCP_IM);\r\nif (ret != BFA_STATUS_OK) {\r\ninit_completion(&bfad->comp);\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfad->pport.flags |= BFAD_PORT_DELETE;\r\nbfa_fcs_exit(&bfad->bfa_fcs);\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nwait_for_completion(&bfad->comp);\r\nbfa_sm_send_event(bfad, BFAD_E_INIT_FAILED);\r\nbreak;\r\n}\r\nbfad->bfad_flags |= BFAD_HAL_INIT_FAIL;\r\nbfa_sm_send_event(bfad, BFAD_E_HAL_INIT_FAILED);\r\n}\r\nbreak;\r\ncase BFAD_E_KTHREAD_CREATE_FAILED:\r\nbfa_sm_set_state(bfad, bfad_sm_uninit);\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(bfad, event);\r\n}\r\n}\r\nstatic void\r\nbfad_sm_initializing(struct bfad_s *bfad, enum bfad_sm_event event)\r\n{\r\nint retval;\r\nunsigned long flags;\r\nbfa_trc(bfad, event);\r\nswitch (event) {\r\ncase BFAD_E_INIT_SUCCESS:\r\nkthread_stop(bfad->bfad_tsk);\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfad->bfad_tsk = NULL;\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nretval = bfad_start_ops(bfad);\r\nif (retval != BFA_STATUS_OK) {\r\nbfa_sm_set_state(bfad, bfad_sm_failed);\r\nbreak;\r\n}\r\nbfa_sm_set_state(bfad, bfad_sm_operational);\r\nbreak;\r\ncase BFAD_E_INIT_FAILED:\r\nbfa_sm_set_state(bfad, bfad_sm_uninit);\r\nkthread_stop(bfad->bfad_tsk);\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfad->bfad_tsk = NULL;\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nbreak;\r\ncase BFAD_E_HAL_INIT_FAILED:\r\nbfa_sm_set_state(bfad, bfad_sm_failed);\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(bfad, event);\r\n}\r\n}\r\nstatic void\r\nbfad_sm_failed(struct bfad_s *bfad, enum bfad_sm_event event)\r\n{\r\nint retval;\r\nbfa_trc(bfad, event);\r\nswitch (event) {\r\ncase BFAD_E_INIT_SUCCESS:\r\nretval = bfad_start_ops(bfad);\r\nif (retval != BFA_STATUS_OK)\r\nbreak;\r\nbfa_sm_set_state(bfad, bfad_sm_operational);\r\nbreak;\r\ncase BFAD_E_STOP:\r\nbfa_sm_set_state(bfad, bfad_sm_fcs_exit);\r\nbfa_sm_send_event(bfad, BFAD_E_FCS_EXIT_COMP);\r\nbreak;\r\ncase BFAD_E_EXIT_COMP:\r\nbfa_sm_set_state(bfad, bfad_sm_uninit);\r\nbfad_remove_intr(bfad);\r\ndel_timer_sync(&bfad->hal_tmo);\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(bfad, event);\r\n}\r\n}\r\nstatic void\r\nbfad_sm_operational(struct bfad_s *bfad, enum bfad_sm_event event)\r\n{\r\nbfa_trc(bfad, event);\r\nswitch (event) {\r\ncase BFAD_E_STOP:\r\nbfa_sm_set_state(bfad, bfad_sm_fcs_exit);\r\nbfad_fcs_stop(bfad);\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(bfad, event);\r\n}\r\n}\r\nstatic void\r\nbfad_sm_fcs_exit(struct bfad_s *bfad, enum bfad_sm_event event)\r\n{\r\nbfa_trc(bfad, event);\r\nswitch (event) {\r\ncase BFAD_E_FCS_EXIT_COMP:\r\nbfa_sm_set_state(bfad, bfad_sm_stopping);\r\nbfad_stop(bfad);\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(bfad, event);\r\n}\r\n}\r\nstatic void\r\nbfad_sm_stopping(struct bfad_s *bfad, enum bfad_sm_event event)\r\n{\r\nbfa_trc(bfad, event);\r\nswitch (event) {\r\ncase BFAD_E_EXIT_COMP:\r\nbfa_sm_set_state(bfad, bfad_sm_uninit);\r\nbfad_remove_intr(bfad);\r\ndel_timer_sync(&bfad->hal_tmo);\r\nbfad_im_probe_undo(bfad);\r\nbfad->bfad_flags &= ~BFAD_FC4_PROBE_DONE;\r\nbfad_uncfg_pport(bfad);\r\nbreak;\r\ndefault:\r\nbfa_sm_fault(bfad, event);\r\nbreak;\r\n}\r\n}\r\nvoid\r\nbfad_hcb_comp(void *arg, bfa_status_t status)\r\n{\r\nstruct bfad_hal_comp *fcomp = (struct bfad_hal_comp *)arg;\r\nfcomp->status = status;\r\ncomplete(&fcomp->comp);\r\n}\r\nvoid\r\nbfa_cb_init(void *drv, bfa_status_t init_status)\r\n{\r\nstruct bfad_s *bfad = drv;\r\nif (init_status == BFA_STATUS_OK) {\r\nbfad->bfad_flags |= BFAD_HAL_INIT_DONE;\r\nif ((bfad->bfad_flags & BFAD_HAL_INIT_FAIL)) {\r\nbfad->bfad_flags &= ~BFAD_HAL_INIT_FAIL;\r\nwake_up_process(bfad->bfad_tsk);\r\n}\r\n}\r\ncomplete(&bfad->comp);\r\n}\r\nstruct bfad_port_s *\r\nbfa_fcb_lport_new(struct bfad_s *bfad, struct bfa_fcs_lport_s *port,\r\nenum bfa_lport_role roles, struct bfad_vf_s *vf_drv,\r\nstruct bfad_vport_s *vp_drv)\r\n{\r\nbfa_status_t rc;\r\nstruct bfad_port_s *port_drv;\r\nif (!vp_drv && !vf_drv) {\r\nport_drv = &bfad->pport;\r\nport_drv->pvb_type = BFAD_PORT_PHYS_BASE;\r\n} else if (!vp_drv && vf_drv) {\r\nport_drv = &vf_drv->base_port;\r\nport_drv->pvb_type = BFAD_PORT_VF_BASE;\r\n} else if (vp_drv && !vf_drv) {\r\nport_drv = &vp_drv->drv_port;\r\nport_drv->pvb_type = BFAD_PORT_PHYS_VPORT;\r\n} else {\r\nport_drv = &vp_drv->drv_port;\r\nport_drv->pvb_type = BFAD_PORT_VF_VPORT;\r\n}\r\nport_drv->fcs_port = port;\r\nport_drv->roles = roles;\r\nif (roles & BFA_LPORT_ROLE_FCP_IM) {\r\nrc = bfad_im_port_new(bfad, port_drv);\r\nif (rc != BFA_STATUS_OK) {\r\nbfad_im_port_delete(bfad, port_drv);\r\nport_drv = NULL;\r\n}\r\n}\r\nreturn port_drv;\r\n}\r\nbfa_status_t\r\nbfa_fcb_rport_alloc(struct bfad_s *bfad, struct bfa_fcs_rport_s **rport,\r\nstruct bfad_rport_s **rport_drv)\r\n{\r\nbfa_status_t rc = BFA_STATUS_OK;\r\n*rport_drv = kzalloc(sizeof(struct bfad_rport_s), GFP_ATOMIC);\r\nif (*rport_drv == NULL) {\r\nrc = BFA_STATUS_ENOMEM;\r\ngoto ext;\r\n}\r\n*rport = &(*rport_drv)->fcs_rport;\r\next:\r\nreturn rc;\r\n}\r\nvoid\r\nbfa_fcb_pbc_vport_create(struct bfad_s *bfad, struct bfi_pbc_vport_s pbc_vport)\r\n{\r\nstruct bfa_lport_cfg_s port_cfg = {0};\r\nstruct bfad_vport_s *vport;\r\nint rc;\r\nvport = kzalloc(sizeof(struct bfad_vport_s), GFP_ATOMIC);\r\nif (!vport) {\r\nbfa_trc(bfad, 0);\r\nreturn;\r\n}\r\nvport->drv_port.bfad = bfad;\r\nport_cfg.roles = BFA_LPORT_ROLE_FCP_IM;\r\nport_cfg.pwwn = pbc_vport.vp_pwwn;\r\nport_cfg.nwwn = pbc_vport.vp_nwwn;\r\nport_cfg.preboot_vp = BFA_TRUE;\r\nrc = bfa_fcs_pbc_vport_create(&vport->fcs_vport, &bfad->bfa_fcs, 0,\r\n&port_cfg, vport);\r\nif (rc != BFA_STATUS_OK) {\r\nbfa_trc(bfad, 0);\r\nreturn;\r\n}\r\nlist_add_tail(&vport->list_entry, &bfad->pbc_vport_list);\r\n}\r\nvoid\r\nbfad_hal_mem_release(struct bfad_s *bfad)\r\n{\r\nstruct bfa_meminfo_s *hal_meminfo = &bfad->meminfo;\r\nstruct bfa_mem_dma_s *dma_info, *dma_elem;\r\nstruct bfa_mem_kva_s *kva_info, *kva_elem;\r\nstruct list_head *dm_qe, *km_qe;\r\ndma_info = &hal_meminfo->dma_info;\r\nkva_info = &hal_meminfo->kva_info;\r\nlist_for_each(km_qe, &kva_info->qe) {\r\nkva_elem = (struct bfa_mem_kva_s *) km_qe;\r\nvfree(kva_elem->kva);\r\n}\r\nlist_for_each(dm_qe, &dma_info->qe) {\r\ndma_elem = (struct bfa_mem_dma_s *) dm_qe;\r\ndma_free_coherent(&bfad->pcidev->dev,\r\ndma_elem->mem_len, dma_elem->kva,\r\n(dma_addr_t) dma_elem->dma);\r\n}\r\nmemset(hal_meminfo, 0, sizeof(struct bfa_meminfo_s));\r\n}\r\nvoid\r\nbfad_update_hal_cfg(struct bfa_iocfc_cfg_s *bfa_cfg)\r\n{\r\nif (num_rports > 0)\r\nbfa_cfg->fwcfg.num_rports = num_rports;\r\nif (num_ios > 0)\r\nbfa_cfg->fwcfg.num_ioim_reqs = num_ios;\r\nif (num_tms > 0)\r\nbfa_cfg->fwcfg.num_tskim_reqs = num_tms;\r\nif (num_fcxps > 0 && num_fcxps <= BFA_FCXP_MAX)\r\nbfa_cfg->fwcfg.num_fcxp_reqs = num_fcxps;\r\nif (num_ufbufs > 0 && num_ufbufs <= BFA_UF_MAX)\r\nbfa_cfg->fwcfg.num_uf_bufs = num_ufbufs;\r\nif (reqq_size > 0)\r\nbfa_cfg->drvcfg.num_reqq_elems = reqq_size;\r\nif (rspq_size > 0)\r\nbfa_cfg->drvcfg.num_rspq_elems = rspq_size;\r\nif (num_sgpgs > 0 && num_sgpgs <= BFA_SGPG_MAX)\r\nbfa_cfg->drvcfg.num_sgpgs = num_sgpgs;\r\nnum_rports = bfa_cfg->fwcfg.num_rports;\r\nnum_ios = bfa_cfg->fwcfg.num_ioim_reqs;\r\nnum_tms = bfa_cfg->fwcfg.num_tskim_reqs;\r\nnum_fcxps = bfa_cfg->fwcfg.num_fcxp_reqs;\r\nnum_ufbufs = bfa_cfg->fwcfg.num_uf_bufs;\r\nreqq_size = bfa_cfg->drvcfg.num_reqq_elems;\r\nrspq_size = bfa_cfg->drvcfg.num_rspq_elems;\r\nnum_sgpgs = bfa_cfg->drvcfg.num_sgpgs;\r\n}\r\nbfa_status_t\r\nbfad_hal_mem_alloc(struct bfad_s *bfad)\r\n{\r\nstruct bfa_meminfo_s *hal_meminfo = &bfad->meminfo;\r\nstruct bfa_mem_dma_s *dma_info, *dma_elem;\r\nstruct bfa_mem_kva_s *kva_info, *kva_elem;\r\nstruct list_head *dm_qe, *km_qe;\r\nbfa_status_t rc = BFA_STATUS_OK;\r\ndma_addr_t phys_addr;\r\nbfa_cfg_get_default(&bfad->ioc_cfg);\r\nbfad_update_hal_cfg(&bfad->ioc_cfg);\r\nbfad->cfg_data.ioc_queue_depth = bfad->ioc_cfg.fwcfg.num_ioim_reqs;\r\nbfa_cfg_get_meminfo(&bfad->ioc_cfg, hal_meminfo, &bfad->bfa);\r\ndma_info = &hal_meminfo->dma_info;\r\nkva_info = &hal_meminfo->kva_info;\r\nlist_for_each(km_qe, &kva_info->qe) {\r\nkva_elem = (struct bfa_mem_kva_s *) km_qe;\r\nkva_elem->kva = vmalloc(kva_elem->mem_len);\r\nif (kva_elem->kva == NULL) {\r\nbfad_hal_mem_release(bfad);\r\nrc = BFA_STATUS_ENOMEM;\r\ngoto ext;\r\n}\r\nmemset(kva_elem->kva, 0, kva_elem->mem_len);\r\n}\r\nlist_for_each(dm_qe, &dma_info->qe) {\r\ndma_elem = (struct bfa_mem_dma_s *) dm_qe;\r\ndma_elem->kva = dma_alloc_coherent(&bfad->pcidev->dev,\r\ndma_elem->mem_len,\r\n&phys_addr, GFP_KERNEL);\r\nif (dma_elem->kva == NULL) {\r\nbfad_hal_mem_release(bfad);\r\nrc = BFA_STATUS_ENOMEM;\r\ngoto ext;\r\n}\r\ndma_elem->dma = phys_addr;\r\nmemset(dma_elem->kva, 0, dma_elem->mem_len);\r\n}\r\next:\r\nreturn rc;\r\n}\r\nbfa_status_t\r\nbfad_vport_create(struct bfad_s *bfad, u16 vf_id,\r\nstruct bfa_lport_cfg_s *port_cfg, struct device *dev)\r\n{\r\nstruct bfad_vport_s *vport;\r\nint rc = BFA_STATUS_OK;\r\nunsigned long flags;\r\nstruct completion fcomp;\r\nvport = kzalloc(sizeof(struct bfad_vport_s), GFP_KERNEL);\r\nif (!vport) {\r\nrc = BFA_STATUS_ENOMEM;\r\ngoto ext;\r\n}\r\nvport->drv_port.bfad = bfad;\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nrc = bfa_fcs_vport_create(&vport->fcs_vport, &bfad->bfa_fcs, vf_id,\r\nport_cfg, vport);\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nif (rc != BFA_STATUS_OK)\r\ngoto ext_free_vport;\r\nif (port_cfg->roles & BFA_LPORT_ROLE_FCP_IM) {\r\nrc = bfad_im_scsi_host_alloc(bfad, vport->drv_port.im_port,\r\ndev);\r\nif (rc != BFA_STATUS_OK)\r\ngoto ext_free_fcs_vport;\r\n}\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfa_fcs_vport_start(&vport->fcs_vport);\r\nlist_add_tail(&vport->list_entry, &bfad->vport_list);\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nreturn BFA_STATUS_OK;\r\next_free_fcs_vport:\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nvport->comp_del = &fcomp;\r\ninit_completion(vport->comp_del);\r\nbfa_fcs_vport_delete(&vport->fcs_vport);\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nwait_for_completion(vport->comp_del);\r\next_free_vport:\r\nkfree(vport);\r\next:\r\nreturn rc;\r\n}\r\nvoid\r\nbfad_bfa_tmo(unsigned long data)\r\n{\r\nstruct bfad_s *bfad = (struct bfad_s *) data;\r\nunsigned long flags;\r\nstruct list_head doneq;\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfa_timer_beat(&bfad->bfa.timer_mod);\r\nbfa_comp_deq(&bfad->bfa, &doneq);\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nif (!list_empty(&doneq)) {\r\nbfa_comp_process(&bfad->bfa, &doneq);\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfa_comp_free(&bfad->bfa, &doneq);\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\n}\r\nmod_timer(&bfad->hal_tmo,\r\njiffies + msecs_to_jiffies(BFA_TIMER_FREQ));\r\n}\r\nvoid\r\nbfad_init_timer(struct bfad_s *bfad)\r\n{\r\ninit_timer(&bfad->hal_tmo);\r\nbfad->hal_tmo.function = bfad_bfa_tmo;\r\nbfad->hal_tmo.data = (unsigned long)bfad;\r\nmod_timer(&bfad->hal_tmo,\r\njiffies + msecs_to_jiffies(BFA_TIMER_FREQ));\r\n}\r\nint\r\nbfad_pci_init(struct pci_dev *pdev, struct bfad_s *bfad)\r\n{\r\nint rc = -ENODEV;\r\nif (pci_enable_device(pdev)) {\r\nprintk(KERN_ERR "pci_enable_device fail %p\n", pdev);\r\ngoto out;\r\n}\r\nif (pci_request_regions(pdev, BFAD_DRIVER_NAME))\r\ngoto out_disable_device;\r\npci_set_master(pdev);\r\nif ((pci_set_dma_mask(pdev, DMA_BIT_MASK(64)) != 0) ||\r\n(pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64)) != 0)) {\r\nif ((pci_set_dma_mask(pdev, DMA_BIT_MASK(32)) != 0) ||\r\n(pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32)) != 0)) {\r\nprintk(KERN_ERR "pci_set_dma_mask fail %p\n", pdev);\r\ngoto out_release_region;\r\n}\r\n}\r\npci_enable_pcie_error_reporting(pdev);\r\nbfad->pci_bar0_kva = pci_iomap(pdev, 0, pci_resource_len(pdev, 0));\r\nbfad->pci_bar2_kva = pci_iomap(pdev, 2, pci_resource_len(pdev, 2));\r\nif (bfad->pci_bar0_kva == NULL) {\r\nprintk(KERN_ERR "Fail to map bar0\n");\r\ngoto out_release_region;\r\n}\r\nbfad->hal_pcidev.pci_slot = PCI_SLOT(pdev->devfn);\r\nbfad->hal_pcidev.pci_func = PCI_FUNC(pdev->devfn);\r\nbfad->hal_pcidev.pci_bar_kva = bfad->pci_bar0_kva;\r\nbfad->hal_pcidev.device_id = pdev->device;\r\nbfad->hal_pcidev.ssid = pdev->subsystem_device;\r\nbfad->pci_name = pci_name(pdev);\r\nbfad->pci_attr.vendor_id = pdev->vendor;\r\nbfad->pci_attr.device_id = pdev->device;\r\nbfad->pci_attr.ssid = pdev->subsystem_device;\r\nbfad->pci_attr.ssvid = pdev->subsystem_vendor;\r\nbfad->pci_attr.pcifn = PCI_FUNC(pdev->devfn);\r\nbfad->pcidev = pdev;\r\nif (pci_is_pcie(pdev) && pcie_max_read_reqsz) {\r\nif (pcie_max_read_reqsz >= 128 &&\r\npcie_max_read_reqsz <= 4096 &&\r\nis_power_of_2(pcie_max_read_reqsz)) {\r\nint max_rq = pcie_get_readrq(pdev);\r\nprintk(KERN_WARNING "BFA[%s]: "\r\n"pcie_max_read_request_size is %d, "\r\n"reset to %d\n", bfad->pci_name, max_rq,\r\npcie_max_read_reqsz);\r\npcie_set_readrq(pdev, pcie_max_read_reqsz);\r\n} else {\r\nprintk(KERN_WARNING "BFA[%s]: invalid "\r\n"pcie_max_read_request_size %d ignored\n",\r\nbfad->pci_name, pcie_max_read_reqsz);\r\n}\r\n}\r\npci_save_state(pdev);\r\nreturn 0;\r\nout_release_region:\r\npci_release_regions(pdev);\r\nout_disable_device:\r\npci_disable_device(pdev);\r\nout:\r\nreturn rc;\r\n}\r\nvoid\r\nbfad_pci_uninit(struct pci_dev *pdev, struct bfad_s *bfad)\r\n{\r\npci_iounmap(pdev, bfad->pci_bar0_kva);\r\npci_iounmap(pdev, bfad->pci_bar2_kva);\r\npci_release_regions(pdev);\r\npci_disable_pcie_error_reporting(pdev);\r\npci_disable_device(pdev);\r\n}\r\nbfa_status_t\r\nbfad_drv_init(struct bfad_s *bfad)\r\n{\r\nbfa_status_t rc;\r\nunsigned long flags;\r\nbfad->cfg_data.rport_del_timeout = rport_del_timeout;\r\nbfad->cfg_data.lun_queue_depth = bfa_lun_queue_depth;\r\nbfad->cfg_data.io_max_sge = bfa_io_max_sge;\r\nbfad->cfg_data.binding_method = FCP_PWWN_BINDING;\r\nrc = bfad_hal_mem_alloc(bfad);\r\nif (rc != BFA_STATUS_OK) {\r\nprintk(KERN_WARNING "bfad%d bfad_hal_mem_alloc failure\n",\r\nbfad->inst_no);\r\nprintk(KERN_WARNING\r\n"Not enough memory to attach all Brocade HBA ports, %s",\r\n"System may need more memory.\n");\r\nreturn BFA_STATUS_FAILED;\r\n}\r\nbfad->bfa.trcmod = bfad->trcmod;\r\nbfad->bfa.plog = &bfad->plog_buf;\r\nbfa_plog_init(&bfad->plog_buf);\r\nbfa_plog_str(&bfad->plog_buf, BFA_PL_MID_DRVR, BFA_PL_EID_DRIVER_START,\r\n0, "Driver Attach");\r\nbfa_attach(&bfad->bfa, bfad, &bfad->ioc_cfg, &bfad->meminfo,\r\n&bfad->hal_pcidev);\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfad->bfa_fcs.trcmod = bfad->trcmod;\r\nbfa_fcs_attach(&bfad->bfa_fcs, &bfad->bfa, bfad, BFA_FALSE);\r\nbfad->bfa_fcs.fdmi_enabled = fdmi_enable;\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nbfad->bfad_flags |= BFAD_DRV_INIT_DONE;\r\nreturn BFA_STATUS_OK;\r\n}\r\nvoid\r\nbfad_drv_uninit(struct bfad_s *bfad)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\ninit_completion(&bfad->comp);\r\nbfa_iocfc_stop(&bfad->bfa);\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nwait_for_completion(&bfad->comp);\r\ndel_timer_sync(&bfad->hal_tmo);\r\nbfa_isr_disable(&bfad->bfa);\r\nbfa_detach(&bfad->bfa);\r\nbfad_remove_intr(bfad);\r\nbfad_hal_mem_release(bfad);\r\nbfad->bfad_flags &= ~BFAD_DRV_INIT_DONE;\r\n}\r\nvoid\r\nbfad_drv_start(struct bfad_s *bfad)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfa_iocfc_start(&bfad->bfa);\r\nbfa_fcs_pbc_vport_init(&bfad->bfa_fcs);\r\nbfa_fcs_fabric_modstart(&bfad->bfa_fcs);\r\nbfad->bfad_flags |= BFAD_HAL_START_DONE;\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nif (bfad->im)\r\nflush_workqueue(bfad->im->drv_workq);\r\n}\r\nvoid\r\nbfad_fcs_stop(struct bfad_s *bfad)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\ninit_completion(&bfad->comp);\r\nbfad->pport.flags |= BFAD_PORT_DELETE;\r\nbfa_fcs_exit(&bfad->bfa_fcs);\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nwait_for_completion(&bfad->comp);\r\nbfa_sm_send_event(bfad, BFAD_E_FCS_EXIT_COMP);\r\n}\r\nvoid\r\nbfad_stop(struct bfad_s *bfad)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\ninit_completion(&bfad->comp);\r\nbfa_iocfc_stop(&bfad->bfa);\r\nbfad->bfad_flags &= ~BFAD_HAL_START_DONE;\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nwait_for_completion(&bfad->comp);\r\nbfa_sm_send_event(bfad, BFAD_E_EXIT_COMP);\r\n}\r\nbfa_status_t\r\nbfad_cfg_pport(struct bfad_s *bfad, enum bfa_lport_role role)\r\n{\r\nint rc = BFA_STATUS_OK;\r\nif ((supported_fc4s & BFA_LPORT_ROLE_FCP_IM) &&\r\n(role & BFA_LPORT_ROLE_FCP_IM)) {\r\nif (bfad->pport.im_port == NULL) {\r\nrc = BFA_STATUS_FAILED;\r\ngoto out;\r\n}\r\nrc = bfad_im_scsi_host_alloc(bfad, bfad->pport.im_port,\r\n&bfad->pcidev->dev);\r\nif (rc != BFA_STATUS_OK)\r\ngoto out;\r\nbfad->pport.roles |= BFA_LPORT_ROLE_FCP_IM;\r\n}\r\nbfad->bfad_flags |= BFAD_CFG_PPORT_DONE;\r\nout:\r\nreturn rc;\r\n}\r\nvoid\r\nbfad_uncfg_pport(struct bfad_s *bfad)\r\n{\r\nif ((supported_fc4s & BFA_LPORT_ROLE_FCP_IM) &&\r\n(bfad->pport.roles & BFA_LPORT_ROLE_FCP_IM)) {\r\nbfad_im_scsi_host_free(bfad, bfad->pport.im_port);\r\nbfad_im_port_clean(bfad->pport.im_port);\r\nkfree(bfad->pport.im_port);\r\nbfad->pport.roles &= ~BFA_LPORT_ROLE_FCP_IM;\r\n}\r\nbfad->bfad_flags &= ~BFAD_CFG_PPORT_DONE;\r\n}\r\nbfa_status_t\r\nbfad_start_ops(struct bfad_s *bfad) {\r\nint retval;\r\nunsigned long flags;\r\nstruct bfad_vport_s *vport, *vport_new;\r\nstruct bfa_fcs_driver_info_s driver_info;\r\nif (max_xfer_size < BFAD_MIN_SECTORS >> 1)\r\nmax_xfer_size = BFAD_MIN_SECTORS >> 1;\r\nif (max_xfer_size > BFAD_MAX_SECTORS >> 1)\r\nmax_xfer_size = BFAD_MAX_SECTORS >> 1;\r\nmemset(&driver_info, 0, sizeof(driver_info));\r\nstrncpy(driver_info.version, BFAD_DRIVER_VERSION,\r\nsizeof(driver_info.version) - 1);\r\nif (host_name)\r\nstrncpy(driver_info.host_machine_name, host_name,\r\nsizeof(driver_info.host_machine_name) - 1);\r\nif (os_name)\r\nstrncpy(driver_info.host_os_name, os_name,\r\nsizeof(driver_info.host_os_name) - 1);\r\nif (os_patch)\r\nstrncpy(driver_info.host_os_patch, os_patch,\r\nsizeof(driver_info.host_os_patch) - 1);\r\nstrncpy(driver_info.os_device_name, bfad->pci_name,\r\nsizeof(driver_info.os_device_name) - 1);\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfa_fcs_driver_info_init(&bfad->bfa_fcs, &driver_info);\r\nif (bfad->bfad_flags & BFAD_CFG_PPORT_DONE)\r\nbfa_fcs_update_cfg(&bfad->bfa_fcs);\r\nelse\r\nbfa_fcs_init(&bfad->bfa_fcs);\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nif (!(bfad->bfad_flags & BFAD_CFG_PPORT_DONE)) {\r\nretval = bfad_cfg_pport(bfad, BFA_LPORT_ROLE_FCP_IM);\r\nif (retval != BFA_STATUS_OK)\r\nreturn BFA_STATUS_FAILED;\r\n}\r\nbfad_fc_host_init(bfad->pport.im_port);\r\nretval = bfad_im_probe(bfad);\r\nif (retval != BFA_STATUS_OK) {\r\nprintk(KERN_WARNING "bfad_im_probe failed\n");\r\nif (bfa_sm_cmp_state(bfad, bfad_sm_initializing))\r\nbfa_sm_set_state(bfad, bfad_sm_failed);\r\nreturn BFA_STATUS_FAILED;\r\n} else\r\nbfad->bfad_flags |= BFAD_FC4_PROBE_DONE;\r\nbfad_drv_start(bfad);\r\nlist_for_each_entry_safe(vport, vport_new, &bfad->pbc_vport_list,\r\nlist_entry) {\r\nstruct fc_vport_identifiers vid;\r\nstruct fc_vport *fc_vport;\r\nchar pwwn_buf[BFA_STRING_32];\r\nmemset(&vid, 0, sizeof(vid));\r\nvid.roles = FC_PORT_ROLE_FCP_INITIATOR;\r\nvid.vport_type = FC_PORTTYPE_NPIV;\r\nvid.disable = false;\r\nvid.node_name = wwn_to_u64((u8 *)\r\n(&((vport->fcs_vport).lport.port_cfg.nwwn)));\r\nvid.port_name = wwn_to_u64((u8 *)\r\n(&((vport->fcs_vport).lport.port_cfg.pwwn)));\r\nfc_vport = fc_vport_create(bfad->pport.im_port->shost, 0, &vid);\r\nif (!fc_vport) {\r\nwwn2str(pwwn_buf, vid.port_name);\r\nprintk(KERN_WARNING "bfad%d: failed to create pbc vport"\r\n" %s\n", bfad->inst_no, pwwn_buf);\r\n}\r\nlist_del(&vport->list_entry);\r\nkfree(vport);\r\n}\r\nif (bfa_linkup_delay < 0) {\r\nbfa_linkup_delay = bfad_get_linkup_delay(bfad);\r\nbfad_rport_online_wait(bfad);\r\nbfa_linkup_delay = -1;\r\n} else\r\nbfad_rport_online_wait(bfad);\r\nBFA_LOG(KERN_INFO, bfad, bfa_log_level, "bfa device claimed\n");\r\nreturn BFA_STATUS_OK;\r\n}\r\nint\r\nbfad_worker(void *ptr)\r\n{\r\nstruct bfad_s *bfad;\r\nunsigned long flags;\r\nbfad = (struct bfad_s *)ptr;\r\nwhile (!kthread_should_stop()) {\r\nbfa_sm_send_event(bfad, BFAD_E_INIT_SUCCESS);\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfad->bfad_tsk = NULL;\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nirqreturn_t\r\nbfad_intx(int irq, void *dev_id)\r\n{\r\nstruct bfad_s *bfad = dev_id;\r\nstruct list_head doneq;\r\nunsigned long flags;\r\nbfa_boolean_t rc;\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nrc = bfa_intx(&bfad->bfa);\r\nif (!rc) {\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nreturn IRQ_NONE;\r\n}\r\nbfa_comp_deq(&bfad->bfa, &doneq);\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nif (!list_empty(&doneq)) {\r\nbfa_comp_process(&bfad->bfa, &doneq);\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfa_comp_free(&bfad->bfa, &doneq);\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t\r\nbfad_msix(int irq, void *dev_id)\r\n{\r\nstruct bfad_msix_s *vec = dev_id;\r\nstruct bfad_s *bfad = vec->bfad;\r\nstruct list_head doneq;\r\nunsigned long flags;\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfa_msix(&bfad->bfa, vec->msix.entry);\r\nbfa_comp_deq(&bfad->bfa, &doneq);\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nif (!list_empty(&doneq)) {\r\nbfa_comp_process(&bfad->bfa, &doneq);\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfa_comp_free(&bfad->bfa, &doneq);\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void\r\nbfad_init_msix_entry(struct bfad_s *bfad, struct msix_entry *msix_entries,\r\nint mask, int max_bit)\r\n{\r\nint i;\r\nint match = 0x00000001;\r\nfor (i = 0, bfad->nvec = 0; i < MAX_MSIX_ENTRY; i++) {\r\nif (mask & match) {\r\nbfad->msix_tab[bfad->nvec].msix.entry = i;\r\nbfad->msix_tab[bfad->nvec].bfad = bfad;\r\nmsix_entries[bfad->nvec].entry = i;\r\nbfad->nvec++;\r\n}\r\nmatch <<= 1;\r\n}\r\n}\r\nint\r\nbfad_install_msix_handler(struct bfad_s *bfad)\r\n{\r\nint i, error = 0;\r\nfor (i = 0; i < bfad->nvec; i++) {\r\nsprintf(bfad->msix_tab[i].name, "bfa-%s-%s",\r\nbfad->pci_name,\r\n((bfa_asic_id_cb(bfad->hal_pcidev.device_id)) ?\r\nmsix_name_cb[i] : msix_name_ct[i]));\r\nerror = request_irq(bfad->msix_tab[i].msix.vector,\r\n(irq_handler_t) bfad_msix, 0,\r\nbfad->msix_tab[i].name, &bfad->msix_tab[i]);\r\nbfa_trc(bfad, i);\r\nbfa_trc(bfad, bfad->msix_tab[i].msix.vector);\r\nif (error) {\r\nint j;\r\nfor (j = 0; j < i; j++)\r\nfree_irq(bfad->msix_tab[j].msix.vector,\r\n&bfad->msix_tab[j]);\r\nbfad->bfad_flags &= ~BFAD_MSIX_ON;\r\npci_disable_msix(bfad->pcidev);\r\nreturn 1;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint\r\nbfad_setup_intr(struct bfad_s *bfad)\r\n{\r\nint error;\r\nu32 mask = 0, i, num_bit = 0, max_bit = 0;\r\nstruct msix_entry msix_entries[MAX_MSIX_ENTRY];\r\nstruct pci_dev *pdev = bfad->pcidev;\r\nu16 reg;\r\nbfa_msix_getvecs(&bfad->bfa, &mask, &num_bit, &max_bit);\r\nbfad_init_msix_entry(bfad, msix_entries, mask, max_bit);\r\nif ((bfa_asic_id_ctc(pdev->device) && !msix_disable_ct) ||\r\n(bfa_asic_id_cb(pdev->device) && !msix_disable_cb)) {\r\nerror = pci_enable_msix_exact(bfad->pcidev,\r\nmsix_entries, bfad->nvec);\r\nif (error == -ENOSPC && bfa_asic_id_ctc(pdev->device)) {\r\nprintk(KERN_WARNING "bfa %s: trying one msix "\r\n"vector failed to allocate %d[%d]\n",\r\nbfad->pci_name, bfad->nvec, error);\r\nbfad->nvec = 1;\r\nerror = pci_enable_msix_exact(bfad->pcidev,\r\nmsix_entries, 1);\r\n}\r\nif (error) {\r\nprintk(KERN_WARNING "bfad%d: "\r\n"pci_enable_msix_exact failed (%d), "\r\n"use line based.\n",\r\nbfad->inst_no, error);\r\ngoto line_based;\r\n}\r\npci_read_config_word(pdev, PCI_COMMAND, &reg);\r\nif (!(reg & PCI_COMMAND_INTX_DISABLE))\r\npci_write_config_word(pdev, PCI_COMMAND,\r\nreg | PCI_COMMAND_INTX_DISABLE);\r\nfor (i = 0; i < bfad->nvec; i++) {\r\nbfa_trc(bfad, msix_entries[i].vector);\r\nbfad->msix_tab[i].msix.vector = msix_entries[i].vector;\r\n}\r\nbfa_msix_init(&bfad->bfa, bfad->nvec);\r\nbfad->bfad_flags |= BFAD_MSIX_ON;\r\nreturn 0;\r\n}\r\nline_based:\r\nerror = request_irq(bfad->pcidev->irq, (irq_handler_t)bfad_intx,\r\nBFAD_IRQ_FLAGS, BFAD_DRIVER_NAME, bfad);\r\nif (error)\r\nreturn error;\r\nbfad->bfad_flags |= BFAD_INTX_ON;\r\nreturn 0;\r\n}\r\nvoid\r\nbfad_remove_intr(struct bfad_s *bfad)\r\n{\r\nint i;\r\nif (bfad->bfad_flags & BFAD_MSIX_ON) {\r\nfor (i = 0; i < bfad->nvec; i++)\r\nfree_irq(bfad->msix_tab[i].msix.vector,\r\n&bfad->msix_tab[i]);\r\npci_disable_msix(bfad->pcidev);\r\nbfad->bfad_flags &= ~BFAD_MSIX_ON;\r\n} else if (bfad->bfad_flags & BFAD_INTX_ON) {\r\nfree_irq(bfad->pcidev->irq, bfad);\r\n}\r\n}\r\nint\r\nbfad_pci_probe(struct pci_dev *pdev, const struct pci_device_id *pid)\r\n{\r\nstruct bfad_s *bfad;\r\nint error = -ENODEV, retval, i;\r\nif ((pdev->device == BFA_PCI_DEVICE_ID_FC_8G1P) &&\r\n(PCI_FUNC(pdev->devfn) != 0))\r\nreturn -ENODEV;\r\nbfad = kzalloc(sizeof(struct bfad_s), GFP_KERNEL);\r\nif (!bfad) {\r\nerror = -ENOMEM;\r\ngoto out;\r\n}\r\nbfad->trcmod = kzalloc(sizeof(struct bfa_trc_mod_s), GFP_KERNEL);\r\nif (!bfad->trcmod) {\r\nprintk(KERN_WARNING "Error alloc trace buffer!\n");\r\nerror = -ENOMEM;\r\ngoto out_alloc_trace_failure;\r\n}\r\nbfa_trc_init(bfad->trcmod);\r\nbfa_trc(bfad, bfad_inst);\r\nINIT_LIST_HEAD(&bfad->free_aen_q);\r\nINIT_LIST_HEAD(&bfad->active_aen_q);\r\nfor (i = 0; i < BFA_AEN_MAX_ENTRY; i++)\r\nlist_add_tail(&bfad->aen_list[i].qe, &bfad->free_aen_q);\r\nif (!(bfad_load_fwimg(pdev))) {\r\nkfree(bfad->trcmod);\r\ngoto out_alloc_trace_failure;\r\n}\r\nretval = bfad_pci_init(pdev, bfad);\r\nif (retval) {\r\nprintk(KERN_WARNING "bfad_pci_init failure!\n");\r\nerror = retval;\r\ngoto out_pci_init_failure;\r\n}\r\nmutex_lock(&bfad_mutex);\r\nbfad->inst_no = bfad_inst++;\r\nlist_add_tail(&bfad->list_entry, &bfad_list);\r\nmutex_unlock(&bfad_mutex);\r\nbfa_sm_set_state(bfad, bfad_sm_uninit);\r\nspin_lock_init(&bfad->bfad_lock);\r\nspin_lock_init(&bfad->bfad_aen_spinlock);\r\npci_set_drvdata(pdev, bfad);\r\nbfad->ref_count = 0;\r\nbfad->pport.bfad = bfad;\r\nINIT_LIST_HEAD(&bfad->pbc_vport_list);\r\nINIT_LIST_HEAD(&bfad->vport_list);\r\nif (bfa_debugfs_enable)\r\nbfad_debugfs_init(&bfad->pport);\r\nretval = bfad_drv_init(bfad);\r\nif (retval != BFA_STATUS_OK)\r\ngoto out_drv_init_failure;\r\nbfa_sm_send_event(bfad, BFAD_E_CREATE);\r\nif (bfa_sm_cmp_state(bfad, bfad_sm_uninit))\r\ngoto out_bfad_sm_failure;\r\nreturn 0;\r\nout_bfad_sm_failure:\r\nbfad_hal_mem_release(bfad);\r\nout_drv_init_failure:\r\nkfree(bfad->regdata);\r\nbfad_debugfs_exit(&bfad->pport);\r\nmutex_lock(&bfad_mutex);\r\nbfad_inst--;\r\nlist_del(&bfad->list_entry);\r\nmutex_unlock(&bfad_mutex);\r\nbfad_pci_uninit(pdev, bfad);\r\nout_pci_init_failure:\r\nkfree(bfad->trcmod);\r\nout_alloc_trace_failure:\r\nkfree(bfad);\r\nout:\r\nreturn error;\r\n}\r\nvoid\r\nbfad_pci_remove(struct pci_dev *pdev)\r\n{\r\nstruct bfad_s *bfad = pci_get_drvdata(pdev);\r\nunsigned long flags;\r\nbfa_trc(bfad, bfad->inst_no);\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nif (bfad->bfad_tsk != NULL) {\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nkthread_stop(bfad->bfad_tsk);\r\n} else {\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\n}\r\nbfa_sm_send_event(bfad, BFAD_E_STOP);\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfa_detach(&bfad->bfa);\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nbfad_hal_mem_release(bfad);\r\nkfree(bfad->regdata);\r\nbfad_debugfs_exit(&bfad->pport);\r\nmutex_lock(&bfad_mutex);\r\nbfad_inst--;\r\nlist_del(&bfad->list_entry);\r\nmutex_unlock(&bfad_mutex);\r\nbfad_pci_uninit(pdev, bfad);\r\nkfree(bfad->trcmod);\r\nkfree(bfad);\r\n}\r\nstatic pci_ers_result_t\r\nbfad_pci_error_detected(struct pci_dev *pdev, pci_channel_state_t state)\r\n{\r\nstruct bfad_s *bfad = pci_get_drvdata(pdev);\r\nunsigned long flags;\r\npci_ers_result_t ret = PCI_ERS_RESULT_NONE;\r\ndev_printk(KERN_ERR, &pdev->dev,\r\n"error detected state: %d - flags: 0x%x\n",\r\nstate, bfad->bfad_flags);\r\nswitch (state) {\r\ncase pci_channel_io_normal:\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfad->bfad_flags &= ~BFAD_EEH_BUSY;\r\nbfa_ioc_suspend(&bfad->bfa.ioc);\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\ndel_timer_sync(&bfad->hal_tmo);\r\nret = PCI_ERS_RESULT_CAN_RECOVER;\r\nbreak;\r\ncase pci_channel_io_frozen:\r\ninit_completion(&bfad->comp);\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfad->bfad_flags |= BFAD_EEH_BUSY;\r\nbfa_ioc_suspend(&bfad->bfa.ioc);\r\nbfa_fcs_stop(&bfad->bfa_fcs);\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nwait_for_completion(&bfad->comp);\r\nbfad_remove_intr(bfad);\r\ndel_timer_sync(&bfad->hal_tmo);\r\npci_disable_device(pdev);\r\nret = PCI_ERS_RESULT_NEED_RESET;\r\nbreak;\r\ncase pci_channel_io_perm_failure:\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfad->bfad_flags |= BFAD_EEH_BUSY |\r\nBFAD_EEH_PCI_CHANNEL_IO_PERM_FAILURE;\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nret = PCI_ERS_RESULT_DISCONNECT;\r\nbreak;\r\ndefault:\r\nWARN_ON(1);\r\n}\r\nreturn ret;\r\n}\r\nint\r\nrestart_bfa(struct bfad_s *bfad)\r\n{\r\nunsigned long flags;\r\nstruct pci_dev *pdev = bfad->pcidev;\r\nbfa_attach(&bfad->bfa, bfad, &bfad->ioc_cfg,\r\n&bfad->meminfo, &bfad->hal_pcidev);\r\nif (bfad_setup_intr(bfad)) {\r\ndev_printk(KERN_WARNING, &pdev->dev,\r\n"%s: bfad_setup_intr failed\n", bfad->pci_name);\r\nbfa_sm_send_event(bfad, BFAD_E_INIT_FAILED);\r\nreturn -1;\r\n}\r\ninit_completion(&bfad->comp);\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfa_iocfc_init(&bfad->bfa);\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nif ((bfad->bfad_flags & BFAD_MSIX_ON) &&\r\nbfad_install_msix_handler(bfad))\r\ndev_printk(KERN_WARNING, &pdev->dev,\r\n"%s: install_msix failed.\n", bfad->pci_name);\r\nbfad_init_timer(bfad);\r\nwait_for_completion(&bfad->comp);\r\nbfad_drv_start(bfad);\r\nreturn 0;\r\n}\r\nstatic pci_ers_result_t\r\nbfad_pci_slot_reset(struct pci_dev *pdev)\r\n{\r\nstruct bfad_s *bfad = pci_get_drvdata(pdev);\r\nu8 byte;\r\ndev_printk(KERN_ERR, &pdev->dev,\r\n"bfad_pci_slot_reset flags: 0x%x\n", bfad->bfad_flags);\r\nif (pci_enable_device(pdev)) {\r\ndev_printk(KERN_ERR, &pdev->dev, "Cannot re-enable "\r\n"PCI device after reset.\n");\r\nreturn PCI_ERS_RESULT_DISCONNECT;\r\n}\r\npci_restore_state(pdev);\r\npci_read_config_byte(pdev, 0x68, &byte);\r\nif (byte == 0xff) {\r\ndev_printk(KERN_ERR, &pdev->dev,\r\n"slot_reset failed ... got another PCI error !\n");\r\ngoto out_disable_device;\r\n}\r\npci_save_state(pdev);\r\npci_set_master(pdev);\r\nif (pci_set_dma_mask(bfad->pcidev, DMA_BIT_MASK(64)) != 0)\r\nif (pci_set_dma_mask(bfad->pcidev, DMA_BIT_MASK(32)) != 0)\r\ngoto out_disable_device;\r\npci_cleanup_aer_uncorrect_error_status(pdev);\r\nif (restart_bfa(bfad) == -1)\r\ngoto out_disable_device;\r\npci_enable_pcie_error_reporting(pdev);\r\ndev_printk(KERN_WARNING, &pdev->dev,\r\n"slot_reset completed flags: 0x%x!\n", bfad->bfad_flags);\r\nreturn PCI_ERS_RESULT_RECOVERED;\r\nout_disable_device:\r\npci_disable_device(pdev);\r\nreturn PCI_ERS_RESULT_DISCONNECT;\r\n}\r\nstatic pci_ers_result_t\r\nbfad_pci_mmio_enabled(struct pci_dev *pdev)\r\n{\r\nunsigned long flags;\r\nstruct bfad_s *bfad = pci_get_drvdata(pdev);\r\ndev_printk(KERN_INFO, &pdev->dev, "mmio_enabled\n");\r\nbfa_ioc_debug_save_ftrc(&bfad->bfa.ioc);\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\ninit_completion(&bfad->comp);\r\nbfa_fcs_stop(&bfad->bfa_fcs);\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\nwait_for_completion(&bfad->comp);\r\nbfad_remove_intr(bfad);\r\ndel_timer_sync(&bfad->hal_tmo);\r\npci_disable_device(pdev);\r\nreturn PCI_ERS_RESULT_NEED_RESET;\r\n}\r\nstatic void\r\nbfad_pci_resume(struct pci_dev *pdev)\r\n{\r\nunsigned long flags;\r\nstruct bfad_s *bfad = pci_get_drvdata(pdev);\r\ndev_printk(KERN_WARNING, &pdev->dev, "resume\n");\r\nbfad_rport_online_wait(bfad);\r\nspin_lock_irqsave(&bfad->bfad_lock, flags);\r\nbfad->bfad_flags &= ~BFAD_EEH_BUSY;\r\nspin_unlock_irqrestore(&bfad->bfad_lock, flags);\r\n}\r\nstatic int __init\r\nbfad_init(void)\r\n{\r\nint error = 0;\r\nprintk(KERN_INFO "Brocade BFA FC/FCOE SCSI driver - version: %s\n",\r\nBFAD_DRIVER_VERSION);\r\nif (num_sgpgs > 0)\r\nnum_sgpgs_parm = num_sgpgs;\r\nerror = bfad_im_module_init();\r\nif (error) {\r\nerror = -ENOMEM;\r\nprintk(KERN_WARNING "bfad_im_module_init failure\n");\r\ngoto ext;\r\n}\r\nif (strcmp(FCPI_NAME, " fcpim") == 0)\r\nsupported_fc4s |= BFA_LPORT_ROLE_FCP_IM;\r\nbfa_auto_recover = ioc_auto_recover;\r\nbfa_fcs_rport_set_del_timeout(rport_del_timeout);\r\nbfa_fcs_rport_set_max_logins(max_rport_logins);\r\nerror = pci_register_driver(&bfad_pci_driver);\r\nif (error) {\r\nprintk(KERN_WARNING "pci_register_driver failure\n");\r\ngoto ext;\r\n}\r\nreturn 0;\r\next:\r\nbfad_im_module_exit();\r\nreturn error;\r\n}\r\nstatic void __exit\r\nbfad_exit(void)\r\n{\r\npci_unregister_driver(&bfad_pci_driver);\r\nbfad_im_module_exit();\r\nbfad_free_fwimg();\r\n}\r\nstatic void\r\nbfad_read_firmware(struct pci_dev *pdev, u32 **bfi_image,\r\nu32 *bfi_image_size, char *fw_name)\r\n{\r\nconst struct firmware *fw;\r\nif (request_firmware(&fw, fw_name, &pdev->dev)) {\r\nprintk(KERN_ALERT "Can't locate firmware %s\n", fw_name);\r\n*bfi_image = NULL;\r\ngoto out;\r\n}\r\n*bfi_image = vmalloc(fw->size);\r\nif (NULL == *bfi_image) {\r\nprintk(KERN_ALERT "Fail to allocate buffer for fw image "\r\n"size=%x!\n", (u32) fw->size);\r\ngoto out;\r\n}\r\nmemcpy(*bfi_image, fw->data, fw->size);\r\n*bfi_image_size = fw->size/sizeof(u32);\r\nout:\r\nrelease_firmware(fw);\r\n}\r\nstatic u32 *\r\nbfad_load_fwimg(struct pci_dev *pdev)\r\n{\r\nif (bfa_asic_id_ct2(pdev->device)) {\r\nif (bfi_image_ct2_size == 0)\r\nbfad_read_firmware(pdev, &bfi_image_ct2,\r\n&bfi_image_ct2_size, BFAD_FW_FILE_CT2);\r\nreturn bfi_image_ct2;\r\n} else if (bfa_asic_id_ct(pdev->device)) {\r\nif (bfi_image_ct_size == 0)\r\nbfad_read_firmware(pdev, &bfi_image_ct,\r\n&bfi_image_ct_size, BFAD_FW_FILE_CT);\r\nreturn bfi_image_ct;\r\n} else if (bfa_asic_id_cb(pdev->device)) {\r\nif (bfi_image_cb_size == 0)\r\nbfad_read_firmware(pdev, &bfi_image_cb,\r\n&bfi_image_cb_size, BFAD_FW_FILE_CB);\r\nreturn bfi_image_cb;\r\n}\r\nreturn NULL;\r\n}\r\nstatic void\r\nbfad_free_fwimg(void)\r\n{\r\nif (bfi_image_ct2_size && bfi_image_ct2)\r\nvfree(bfi_image_ct2);\r\nif (bfi_image_ct_size && bfi_image_ct)\r\nvfree(bfi_image_ct);\r\nif (bfi_image_cb_size && bfi_image_cb)\r\nvfree(bfi_image_cb);\r\n}
