static int __sigp_sense(struct kvm_vcpu *vcpu, u16 cpu_addr,\r\nu64 *reg)\r\n{\r\nstruct kvm_s390_local_interrupt *li;\r\nstruct kvm_vcpu *dst_vcpu = NULL;\r\nint cpuflags;\r\nint rc;\r\nif (cpu_addr >= KVM_MAX_VCPUS)\r\nreturn SIGP_CC_NOT_OPERATIONAL;\r\ndst_vcpu = kvm_get_vcpu(vcpu->kvm, cpu_addr);\r\nif (!dst_vcpu)\r\nreturn SIGP_CC_NOT_OPERATIONAL;\r\nli = &dst_vcpu->arch.local_int;\r\ncpuflags = atomic_read(li->cpuflags);\r\nif (!(cpuflags & (CPUSTAT_ECALL_PEND | CPUSTAT_STOPPED)))\r\nrc = SIGP_CC_ORDER_CODE_ACCEPTED;\r\nelse {\r\n*reg &= 0xffffffff00000000UL;\r\nif (cpuflags & CPUSTAT_ECALL_PEND)\r\n*reg |= SIGP_STATUS_EXT_CALL_PENDING;\r\nif (cpuflags & CPUSTAT_STOPPED)\r\n*reg |= SIGP_STATUS_STOPPED;\r\nrc = SIGP_CC_STATUS_STORED;\r\n}\r\nVCPU_EVENT(vcpu, 4, "sensed status of cpu %x rc %x", cpu_addr, rc);\r\nreturn rc;\r\n}\r\nstatic int __sigp_emergency(struct kvm_vcpu *vcpu, u16 cpu_addr)\r\n{\r\nstruct kvm_s390_interrupt s390int = {\r\n.type = KVM_S390_INT_EMERGENCY,\r\n.parm = vcpu->vcpu_id,\r\n};\r\nstruct kvm_vcpu *dst_vcpu = NULL;\r\nint rc = 0;\r\nif (cpu_addr < KVM_MAX_VCPUS)\r\ndst_vcpu = kvm_get_vcpu(vcpu->kvm, cpu_addr);\r\nif (!dst_vcpu)\r\nreturn SIGP_CC_NOT_OPERATIONAL;\r\nrc = kvm_s390_inject_vcpu(dst_vcpu, &s390int);\r\nif (!rc)\r\nVCPU_EVENT(vcpu, 4, "sent sigp emerg to cpu %x", cpu_addr);\r\nreturn rc ? rc : SIGP_CC_ORDER_CODE_ACCEPTED;\r\n}\r\nstatic int __sigp_conditional_emergency(struct kvm_vcpu *vcpu, u16 cpu_addr,\r\nu16 asn, u64 *reg)\r\n{\r\nstruct kvm_vcpu *dst_vcpu = NULL;\r\nconst u64 psw_int_mask = PSW_MASK_IO | PSW_MASK_EXT;\r\nu16 p_asn, s_asn;\r\npsw_t *psw;\r\nu32 flags;\r\nif (cpu_addr < KVM_MAX_VCPUS)\r\ndst_vcpu = kvm_get_vcpu(vcpu->kvm, cpu_addr);\r\nif (!dst_vcpu)\r\nreturn SIGP_CC_NOT_OPERATIONAL;\r\nflags = atomic_read(&dst_vcpu->arch.sie_block->cpuflags);\r\npsw = &dst_vcpu->arch.sie_block->gpsw;\r\np_asn = dst_vcpu->arch.sie_block->gcr[4] & 0xffff;\r\ns_asn = dst_vcpu->arch.sie_block->gcr[3] & 0xffff;\r\nif (!(flags & CPUSTAT_STOPPED)\r\n|| (psw->mask & psw_int_mask) != psw_int_mask\r\n|| ((flags & CPUSTAT_WAIT) && psw->addr != 0)\r\n|| (!(flags & CPUSTAT_WAIT) && (asn == p_asn || asn == s_asn))) {\r\nreturn __sigp_emergency(vcpu, cpu_addr);\r\n} else {\r\n*reg &= 0xffffffff00000000UL;\r\n*reg |= SIGP_STATUS_INCORRECT_STATE;\r\nreturn SIGP_CC_STATUS_STORED;\r\n}\r\n}\r\nstatic int __sigp_external_call(struct kvm_vcpu *vcpu, u16 cpu_addr)\r\n{\r\nstruct kvm_s390_interrupt s390int = {\r\n.type = KVM_S390_INT_EXTERNAL_CALL,\r\n.parm = vcpu->vcpu_id,\r\n};\r\nstruct kvm_vcpu *dst_vcpu = NULL;\r\nint rc;\r\nif (cpu_addr < KVM_MAX_VCPUS)\r\ndst_vcpu = kvm_get_vcpu(vcpu->kvm, cpu_addr);\r\nif (!dst_vcpu)\r\nreturn SIGP_CC_NOT_OPERATIONAL;\r\nrc = kvm_s390_inject_vcpu(dst_vcpu, &s390int);\r\nif (!rc)\r\nVCPU_EVENT(vcpu, 4, "sent sigp ext call to cpu %x", cpu_addr);\r\nreturn rc ? rc : SIGP_CC_ORDER_CODE_ACCEPTED;\r\n}\r\nstatic int __inject_sigp_stop(struct kvm_vcpu *dst_vcpu, int action)\r\n{\r\nstruct kvm_s390_local_interrupt *li = &dst_vcpu->arch.local_int;\r\nstruct kvm_s390_interrupt_info *inti;\r\nint rc = SIGP_CC_ORDER_CODE_ACCEPTED;\r\ninti = kzalloc(sizeof(*inti), GFP_ATOMIC);\r\nif (!inti)\r\nreturn -ENOMEM;\r\ninti->type = KVM_S390_SIGP_STOP;\r\nspin_lock(&li->lock);\r\nif (li->action_bits & ACTION_STOP_ON_STOP) {\r\nkfree(inti);\r\nrc = SIGP_CC_BUSY;\r\ngoto out;\r\n}\r\nif ((atomic_read(li->cpuflags) & CPUSTAT_STOPPED)) {\r\nkfree(inti);\r\nif ((action & ACTION_STORE_ON_STOP) != 0)\r\nrc = -ESHUTDOWN;\r\ngoto out;\r\n}\r\nlist_add_tail(&inti->list, &li->list);\r\natomic_set(&li->active, 1);\r\nli->action_bits |= action;\r\natomic_set_mask(CPUSTAT_STOP_INT, li->cpuflags);\r\nkvm_s390_vcpu_wakeup(dst_vcpu);\r\nout:\r\nspin_unlock(&li->lock);\r\nreturn rc;\r\n}\r\nstatic int __sigp_stop(struct kvm_vcpu *vcpu, u16 cpu_addr, int action)\r\n{\r\nstruct kvm_vcpu *dst_vcpu = NULL;\r\nint rc;\r\nif (cpu_addr >= KVM_MAX_VCPUS)\r\nreturn SIGP_CC_NOT_OPERATIONAL;\r\ndst_vcpu = kvm_get_vcpu(vcpu->kvm, cpu_addr);\r\nif (!dst_vcpu)\r\nreturn SIGP_CC_NOT_OPERATIONAL;\r\nrc = __inject_sigp_stop(dst_vcpu, action);\r\nVCPU_EVENT(vcpu, 4, "sent sigp stop to cpu %x", cpu_addr);\r\nif ((action & ACTION_STORE_ON_STOP) != 0 && rc == -ESHUTDOWN) {\r\nrc = kvm_s390_store_status_unloaded(dst_vcpu,\r\nKVM_S390_STORE_STATUS_NOADDR);\r\n}\r\nreturn rc;\r\n}\r\nstatic int __sigp_set_arch(struct kvm_vcpu *vcpu, u32 parameter)\r\n{\r\nint rc;\r\nunsigned int i;\r\nstruct kvm_vcpu *v;\r\nswitch (parameter & 0xff) {\r\ncase 0:\r\nrc = SIGP_CC_NOT_OPERATIONAL;\r\nbreak;\r\ncase 1:\r\ncase 2:\r\nkvm_for_each_vcpu(i, v, vcpu->kvm) {\r\nv->arch.pfault_token = KVM_S390_PFAULT_TOKEN_INVALID;\r\nkvm_clear_async_pf_completion_queue(v);\r\n}\r\nrc = SIGP_CC_ORDER_CODE_ACCEPTED;\r\nbreak;\r\ndefault:\r\nrc = -EOPNOTSUPP;\r\n}\r\nreturn rc;\r\n}\r\nstatic int __sigp_set_prefix(struct kvm_vcpu *vcpu, u16 cpu_addr, u32 address,\r\nu64 *reg)\r\n{\r\nstruct kvm_s390_local_interrupt *li;\r\nstruct kvm_vcpu *dst_vcpu = NULL;\r\nstruct kvm_s390_interrupt_info *inti;\r\nint rc;\r\nif (cpu_addr < KVM_MAX_VCPUS)\r\ndst_vcpu = kvm_get_vcpu(vcpu->kvm, cpu_addr);\r\nif (!dst_vcpu)\r\nreturn SIGP_CC_NOT_OPERATIONAL;\r\nli = &dst_vcpu->arch.local_int;\r\naddress &= 0x7fffe000u;\r\nif (kvm_is_error_gpa(vcpu->kvm, address)) {\r\n*reg &= 0xffffffff00000000UL;\r\n*reg |= SIGP_STATUS_INVALID_PARAMETER;\r\nreturn SIGP_CC_STATUS_STORED;\r\n}\r\ninti = kzalloc(sizeof(*inti), GFP_KERNEL);\r\nif (!inti)\r\nreturn SIGP_CC_BUSY;\r\nspin_lock(&li->lock);\r\nif (!(atomic_read(li->cpuflags) & CPUSTAT_STOPPED)) {\r\n*reg &= 0xffffffff00000000UL;\r\n*reg |= SIGP_STATUS_INCORRECT_STATE;\r\nrc = SIGP_CC_STATUS_STORED;\r\nkfree(inti);\r\ngoto out_li;\r\n}\r\ninti->type = KVM_S390_SIGP_SET_PREFIX;\r\ninti->prefix.address = address;\r\nlist_add_tail(&inti->list, &li->list);\r\natomic_set(&li->active, 1);\r\nkvm_s390_vcpu_wakeup(dst_vcpu);\r\nrc = SIGP_CC_ORDER_CODE_ACCEPTED;\r\nVCPU_EVENT(vcpu, 4, "set prefix of cpu %02x to %x", cpu_addr, address);\r\nout_li:\r\nspin_unlock(&li->lock);\r\nreturn rc;\r\n}\r\nstatic int __sigp_store_status_at_addr(struct kvm_vcpu *vcpu, u16 cpu_id,\r\nu32 addr, u64 *reg)\r\n{\r\nstruct kvm_vcpu *dst_vcpu = NULL;\r\nint flags;\r\nint rc;\r\nif (cpu_id < KVM_MAX_VCPUS)\r\ndst_vcpu = kvm_get_vcpu(vcpu->kvm, cpu_id);\r\nif (!dst_vcpu)\r\nreturn SIGP_CC_NOT_OPERATIONAL;\r\nspin_lock(&dst_vcpu->arch.local_int.lock);\r\nflags = atomic_read(dst_vcpu->arch.local_int.cpuflags);\r\nspin_unlock(&dst_vcpu->arch.local_int.lock);\r\nif (!(flags & CPUSTAT_STOPPED)) {\r\n*reg &= 0xffffffff00000000UL;\r\n*reg |= SIGP_STATUS_INCORRECT_STATE;\r\nreturn SIGP_CC_STATUS_STORED;\r\n}\r\naddr &= 0x7ffffe00;\r\nrc = kvm_s390_store_status_unloaded(dst_vcpu, addr);\r\nif (rc == -EFAULT) {\r\n*reg &= 0xffffffff00000000UL;\r\n*reg |= SIGP_STATUS_INVALID_PARAMETER;\r\nrc = SIGP_CC_STATUS_STORED;\r\n}\r\nreturn rc;\r\n}\r\nstatic int __sigp_sense_running(struct kvm_vcpu *vcpu, u16 cpu_addr,\r\nu64 *reg)\r\n{\r\nstruct kvm_s390_local_interrupt *li;\r\nstruct kvm_vcpu *dst_vcpu = NULL;\r\nint rc;\r\nif (cpu_addr >= KVM_MAX_VCPUS)\r\nreturn SIGP_CC_NOT_OPERATIONAL;\r\ndst_vcpu = kvm_get_vcpu(vcpu->kvm, cpu_addr);\r\nif (!dst_vcpu)\r\nreturn SIGP_CC_NOT_OPERATIONAL;\r\nli = &dst_vcpu->arch.local_int;\r\nif (atomic_read(li->cpuflags) & CPUSTAT_RUNNING) {\r\nrc = SIGP_CC_ORDER_CODE_ACCEPTED;\r\n} else {\r\n*reg &= 0xffffffff00000000UL;\r\n*reg |= SIGP_STATUS_NOT_RUNNING;\r\nrc = SIGP_CC_STATUS_STORED;\r\n}\r\nVCPU_EVENT(vcpu, 4, "sensed running status of cpu %x rc %x", cpu_addr,\r\nrc);\r\nreturn rc;\r\n}\r\nstatic int sigp_check_callable(struct kvm_vcpu *vcpu, u16 cpu_addr)\r\n{\r\nstruct kvm_s390_local_interrupt *li;\r\nint rc = SIGP_CC_ORDER_CODE_ACCEPTED;\r\nstruct kvm_vcpu *dst_vcpu = NULL;\r\nif (cpu_addr >= KVM_MAX_VCPUS)\r\nreturn SIGP_CC_NOT_OPERATIONAL;\r\ndst_vcpu = kvm_get_vcpu(vcpu->kvm, cpu_addr);\r\nif (!dst_vcpu)\r\nreturn SIGP_CC_NOT_OPERATIONAL;\r\nli = &dst_vcpu->arch.local_int;\r\nspin_lock(&li->lock);\r\nif (li->action_bits & ACTION_STOP_ON_STOP)\r\nrc = SIGP_CC_BUSY;\r\nspin_unlock(&li->lock);\r\nreturn rc;\r\n}\r\nint kvm_s390_handle_sigp(struct kvm_vcpu *vcpu)\r\n{\r\nint r1 = (vcpu->arch.sie_block->ipa & 0x00f0) >> 4;\r\nint r3 = vcpu->arch.sie_block->ipa & 0x000f;\r\nu32 parameter;\r\nu16 cpu_addr = vcpu->run->s.regs.gprs[r3];\r\nu8 order_code;\r\nint rc;\r\nif (vcpu->arch.sie_block->gpsw.mask & PSW_MASK_PSTATE)\r\nreturn kvm_s390_inject_program_int(vcpu, PGM_PRIVILEGED_OP);\r\norder_code = kvm_s390_get_base_disp_rs(vcpu);\r\nif (r1 % 2)\r\nparameter = vcpu->run->s.regs.gprs[r1];\r\nelse\r\nparameter = vcpu->run->s.regs.gprs[r1 + 1];\r\ntrace_kvm_s390_handle_sigp(vcpu, order_code, cpu_addr, parameter);\r\nswitch (order_code) {\r\ncase SIGP_SENSE:\r\nvcpu->stat.instruction_sigp_sense++;\r\nrc = __sigp_sense(vcpu, cpu_addr,\r\n&vcpu->run->s.regs.gprs[r1]);\r\nbreak;\r\ncase SIGP_EXTERNAL_CALL:\r\nvcpu->stat.instruction_sigp_external_call++;\r\nrc = __sigp_external_call(vcpu, cpu_addr);\r\nbreak;\r\ncase SIGP_EMERGENCY_SIGNAL:\r\nvcpu->stat.instruction_sigp_emergency++;\r\nrc = __sigp_emergency(vcpu, cpu_addr);\r\nbreak;\r\ncase SIGP_STOP:\r\nvcpu->stat.instruction_sigp_stop++;\r\nrc = __sigp_stop(vcpu, cpu_addr, ACTION_STOP_ON_STOP);\r\nbreak;\r\ncase SIGP_STOP_AND_STORE_STATUS:\r\nvcpu->stat.instruction_sigp_stop++;\r\nrc = __sigp_stop(vcpu, cpu_addr, ACTION_STORE_ON_STOP |\r\nACTION_STOP_ON_STOP);\r\nbreak;\r\ncase SIGP_STORE_STATUS_AT_ADDRESS:\r\nrc = __sigp_store_status_at_addr(vcpu, cpu_addr, parameter,\r\n&vcpu->run->s.regs.gprs[r1]);\r\nbreak;\r\ncase SIGP_SET_ARCHITECTURE:\r\nvcpu->stat.instruction_sigp_arch++;\r\nrc = __sigp_set_arch(vcpu, parameter);\r\nbreak;\r\ncase SIGP_SET_PREFIX:\r\nvcpu->stat.instruction_sigp_prefix++;\r\nrc = __sigp_set_prefix(vcpu, cpu_addr, parameter,\r\n&vcpu->run->s.regs.gprs[r1]);\r\nbreak;\r\ncase SIGP_COND_EMERGENCY_SIGNAL:\r\nrc = __sigp_conditional_emergency(vcpu, cpu_addr, parameter,\r\n&vcpu->run->s.regs.gprs[r1]);\r\nbreak;\r\ncase SIGP_SENSE_RUNNING:\r\nvcpu->stat.instruction_sigp_sense_running++;\r\nrc = __sigp_sense_running(vcpu, cpu_addr,\r\n&vcpu->run->s.regs.gprs[r1]);\r\nbreak;\r\ncase SIGP_START:\r\nrc = sigp_check_callable(vcpu, cpu_addr);\r\nif (rc == SIGP_CC_ORDER_CODE_ACCEPTED)\r\nrc = -EOPNOTSUPP;\r\nbreak;\r\ncase SIGP_RESTART:\r\nvcpu->stat.instruction_sigp_restart++;\r\nrc = sigp_check_callable(vcpu, cpu_addr);\r\nif (rc == SIGP_CC_ORDER_CODE_ACCEPTED) {\r\nVCPU_EVENT(vcpu, 4,\r\n"sigp restart %x to handle userspace",\r\ncpu_addr);\r\nrc = -EOPNOTSUPP;\r\n}\r\nbreak;\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\nif (rc < 0)\r\nreturn rc;\r\nkvm_s390_set_psw_cc(vcpu, rc);\r\nreturn 0;\r\n}\r\nint kvm_s390_handle_sigp_pei(struct kvm_vcpu *vcpu)\r\n{\r\nint r3 = vcpu->arch.sie_block->ipa & 0x000f;\r\nu16 cpu_addr = vcpu->run->s.regs.gprs[r3];\r\nstruct kvm_vcpu *dest_vcpu;\r\nu8 order_code = kvm_s390_get_base_disp_rs(vcpu);\r\ntrace_kvm_s390_handle_sigp_pei(vcpu, order_code, cpu_addr);\r\nif (order_code == SIGP_EXTERNAL_CALL) {\r\ndest_vcpu = kvm_get_vcpu(vcpu->kvm, cpu_addr);\r\nBUG_ON(dest_vcpu == NULL);\r\nkvm_s390_vcpu_wakeup(dest_vcpu);\r\nkvm_s390_set_psw_cc(vcpu, SIGP_CC_ORDER_CODE_ACCEPTED);\r\nreturn 0;\r\n}\r\nreturn -EOPNOTSUPP;\r\n}
