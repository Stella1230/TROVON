static int atl1_validate_option(int *value, struct atl1_option *opt,\r\nstruct pci_dev *pdev)\r\n{\r\nif (*value == OPTION_UNSET) {\r\n*value = opt->def;\r\nreturn 0;\r\n}\r\nswitch (opt->type) {\r\ncase enable_option:\r\nswitch (*value) {\r\ncase OPTION_ENABLED:\r\ndev_info(&pdev->dev, "%s enabled\n", opt->name);\r\nreturn 0;\r\ncase OPTION_DISABLED:\r\ndev_info(&pdev->dev, "%s disabled\n", opt->name);\r\nreturn 0;\r\n}\r\nbreak;\r\ncase range_option:\r\nif (*value >= opt->arg.r.min && *value <= opt->arg.r.max) {\r\ndev_info(&pdev->dev, "%s set to %i\n", opt->name,\r\n*value);\r\nreturn 0;\r\n}\r\nbreak;\r\ncase list_option:{\r\nint i;\r\nstruct atl1_opt_list *ent;\r\nfor (i = 0; i < opt->arg.l.nr; i++) {\r\nent = &opt->arg.l.p[i];\r\nif (*value == ent->i) {\r\nif (ent->str[0] != '\0')\r\ndev_info(&pdev->dev, "%s\n",\r\nent->str);\r\nreturn 0;\r\n}\r\n}\r\n}\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\ndev_info(&pdev->dev, "invalid %s specified (%i) %s\n",\r\nopt->name, *value, opt->err);\r\n*value = opt->def;\r\nreturn -1;\r\n}\r\nstatic void atl1_check_options(struct atl1_adapter *adapter)\r\n{\r\nstruct pci_dev *pdev = adapter->pdev;\r\nint bd = adapter->bd_number;\r\nif (bd >= ATL1_MAX_NIC) {\r\ndev_notice(&pdev->dev, "no configuration for board#%i\n", bd);\r\ndev_notice(&pdev->dev, "using defaults for all values\n");\r\n}\r\n{\r\nstruct atl1_option opt = {\r\n.type = range_option,\r\n.name = "Interrupt Moderator Timer",\r\n.err = "using default of "\r\n__MODULE_STRING(DEFAULT_INT_MOD_CNT),\r\n.def = DEFAULT_INT_MOD_CNT,\r\n.arg = {.r = {.min = MIN_INT_MOD_CNT,\r\n.max = MAX_INT_MOD_CNT} }\r\n};\r\nint val;\r\nif (num_int_mod_timer > bd) {\r\nval = int_mod_timer[bd];\r\natl1_validate_option(&val, &opt, pdev);\r\nadapter->imt = (u16) val;\r\n} else\r\nadapter->imt = (u16) (opt.def);\r\n}\r\n}\r\nstatic s32 atl1_reset_hw(struct atl1_hw *hw)\r\n{\r\nstruct pci_dev *pdev = hw->back->pdev;\r\nstruct atl1_adapter *adapter = hw->back;\r\nu32 icr;\r\nint i;\r\niowrite32(MASTER_CTRL_SOFT_RST, hw->hw_addr + REG_MASTER_CTRL);\r\nioread32(hw->hw_addr + REG_MASTER_CTRL);\r\niowrite16(1, hw->hw_addr + REG_PHY_ENABLE);\r\nioread16(hw->hw_addr + REG_PHY_ENABLE);\r\nmsleep(1);\r\nfor (i = 0; i < 10; i++) {\r\nicr = ioread32(hw->hw_addr + REG_IDLE_STATUS);\r\nif (!icr)\r\nbreak;\r\nmsleep(1);\r\ncpu_relax();\r\n}\r\nif (icr) {\r\nif (netif_msg_hw(adapter))\r\ndev_dbg(&pdev->dev, "ICR = 0x%x\n", icr);\r\nreturn icr;\r\n}\r\nreturn 0;\r\n}\r\nstatic int atl1_check_eeprom_exist(struct atl1_hw *hw)\r\n{\r\nu32 value;\r\nvalue = ioread32(hw->hw_addr + REG_SPI_FLASH_CTRL);\r\nif (value & SPI_FLASH_CTRL_EN_VPD) {\r\nvalue &= ~SPI_FLASH_CTRL_EN_VPD;\r\niowrite32(value, hw->hw_addr + REG_SPI_FLASH_CTRL);\r\n}\r\nvalue = ioread16(hw->hw_addr + REG_PCIE_CAP_LIST);\r\nreturn ((value & 0xFF00) == 0x6C00) ? 0 : 1;\r\n}\r\nstatic bool atl1_read_eeprom(struct atl1_hw *hw, u32 offset, u32 *p_value)\r\n{\r\nint i;\r\nu32 control;\r\nif (offset & 3)\r\nreturn false;\r\niowrite32(0, hw->hw_addr + REG_VPD_DATA);\r\ncontrol = (offset & VPD_CAP_VPD_ADDR_MASK) << VPD_CAP_VPD_ADDR_SHIFT;\r\niowrite32(control, hw->hw_addr + REG_VPD_CAP);\r\nioread32(hw->hw_addr + REG_VPD_CAP);\r\nfor (i = 0; i < 10; i++) {\r\nmsleep(2);\r\ncontrol = ioread32(hw->hw_addr + REG_VPD_CAP);\r\nif (control & VPD_CAP_VPD_FLAG)\r\nbreak;\r\n}\r\nif (control & VPD_CAP_VPD_FLAG) {\r\n*p_value = ioread32(hw->hw_addr + REG_VPD_DATA);\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic s32 atl1_read_phy_reg(struct atl1_hw *hw, u16 reg_addr, u16 *phy_data)\r\n{\r\nu32 val;\r\nint i;\r\nval = ((u32) (reg_addr & MDIO_REG_ADDR_MASK)) << MDIO_REG_ADDR_SHIFT |\r\nMDIO_START | MDIO_SUP_PREAMBLE | MDIO_RW | MDIO_CLK_25_4 <<\r\nMDIO_CLK_SEL_SHIFT;\r\niowrite32(val, hw->hw_addr + REG_MDIO_CTRL);\r\nioread32(hw->hw_addr + REG_MDIO_CTRL);\r\nfor (i = 0; i < MDIO_WAIT_TIMES; i++) {\r\nudelay(2);\r\nval = ioread32(hw->hw_addr + REG_MDIO_CTRL);\r\nif (!(val & (MDIO_START | MDIO_BUSY)))\r\nbreak;\r\n}\r\nif (!(val & (MDIO_START | MDIO_BUSY))) {\r\n*phy_data = (u16) val;\r\nreturn 0;\r\n}\r\nreturn ATLX_ERR_PHY;\r\n}\r\nstatic bool atl1_spi_read(struct atl1_hw *hw, u32 addr, u32 *buf)\r\n{\r\nint i;\r\nu32 value;\r\niowrite32(0, hw->hw_addr + REG_SPI_DATA);\r\niowrite32(addr, hw->hw_addr + REG_SPI_ADDR);\r\nvalue = SPI_FLASH_CTRL_WAIT_READY |\r\n(CUSTOM_SPI_CS_SETUP & SPI_FLASH_CTRL_CS_SETUP_MASK) <<\r\nSPI_FLASH_CTRL_CS_SETUP_SHIFT | (CUSTOM_SPI_CLK_HI &\r\nSPI_FLASH_CTRL_CLK_HI_MASK) <<\r\nSPI_FLASH_CTRL_CLK_HI_SHIFT | (CUSTOM_SPI_CLK_LO &\r\nSPI_FLASH_CTRL_CLK_LO_MASK) <<\r\nSPI_FLASH_CTRL_CLK_LO_SHIFT | (CUSTOM_SPI_CS_HOLD &\r\nSPI_FLASH_CTRL_CS_HOLD_MASK) <<\r\nSPI_FLASH_CTRL_CS_HOLD_SHIFT | (CUSTOM_SPI_CS_HI &\r\nSPI_FLASH_CTRL_CS_HI_MASK) <<\r\nSPI_FLASH_CTRL_CS_HI_SHIFT | (1 & SPI_FLASH_CTRL_INS_MASK) <<\r\nSPI_FLASH_CTRL_INS_SHIFT;\r\niowrite32(value, hw->hw_addr + REG_SPI_FLASH_CTRL);\r\nvalue |= SPI_FLASH_CTRL_START;\r\niowrite32(value, hw->hw_addr + REG_SPI_FLASH_CTRL);\r\nioread32(hw->hw_addr + REG_SPI_FLASH_CTRL);\r\nfor (i = 0; i < 10; i++) {\r\nmsleep(1);\r\nvalue = ioread32(hw->hw_addr + REG_SPI_FLASH_CTRL);\r\nif (!(value & SPI_FLASH_CTRL_START))\r\nbreak;\r\n}\r\nif (value & SPI_FLASH_CTRL_START)\r\nreturn false;\r\n*buf = ioread32(hw->hw_addr + REG_SPI_DATA);\r\nreturn true;\r\n}\r\nstatic int atl1_get_permanent_address(struct atl1_hw *hw)\r\n{\r\nu32 addr[2];\r\nu32 i, control;\r\nu16 reg;\r\nu8 eth_addr[ETH_ALEN];\r\nbool key_valid;\r\nif (is_valid_ether_addr(hw->perm_mac_addr))\r\nreturn 0;\r\naddr[0] = addr[1] = 0;\r\nif (!atl1_check_eeprom_exist(hw)) {\r\nreg = 0;\r\nkey_valid = false;\r\ni = 0;\r\nwhile (1) {\r\nif (atl1_read_eeprom(hw, i + 0x100, &control)) {\r\nif (key_valid) {\r\nif (reg == REG_MAC_STA_ADDR)\r\naddr[0] = control;\r\nelse if (reg == (REG_MAC_STA_ADDR + 4))\r\naddr[1] = control;\r\nkey_valid = false;\r\n} else if ((control & 0xff) == 0x5A) {\r\nkey_valid = true;\r\nreg = (u16) (control >> 16);\r\n} else\r\nbreak;\r\n} else\r\nbreak;\r\ni += 4;\r\n}\r\n*(u32 *) &eth_addr[2] = swab32(addr[0]);\r\n*(u16 *) &eth_addr[0] = swab16(*(u16 *) &addr[1]);\r\nif (is_valid_ether_addr(eth_addr)) {\r\nmemcpy(hw->perm_mac_addr, eth_addr, ETH_ALEN);\r\nreturn 0;\r\n}\r\n}\r\naddr[0] = addr[1] = 0;\r\nreg = 0;\r\nkey_valid = false;\r\ni = 0;\r\nwhile (1) {\r\nif (atl1_spi_read(hw, i + 0x1f000, &control)) {\r\nif (key_valid) {\r\nif (reg == REG_MAC_STA_ADDR)\r\naddr[0] = control;\r\nelse if (reg == (REG_MAC_STA_ADDR + 4))\r\naddr[1] = control;\r\nkey_valid = false;\r\n} else if ((control & 0xff) == 0x5A) {\r\nkey_valid = true;\r\nreg = (u16) (control >> 16);\r\n} else\r\nbreak;\r\n} else\r\nbreak;\r\ni += 4;\r\n}\r\n*(u32 *) &eth_addr[2] = swab32(addr[0]);\r\n*(u16 *) &eth_addr[0] = swab16(*(u16 *) &addr[1]);\r\nif (is_valid_ether_addr(eth_addr)) {\r\nmemcpy(hw->perm_mac_addr, eth_addr, ETH_ALEN);\r\nreturn 0;\r\n}\r\naddr[0] = ioread32(hw->hw_addr + REG_MAC_STA_ADDR);\r\naddr[1] = ioread16(hw->hw_addr + (REG_MAC_STA_ADDR + 4));\r\n*(u32 *) &eth_addr[2] = swab32(addr[0]);\r\n*(u16 *) &eth_addr[0] = swab16(*(u16 *) &addr[1]);\r\nif (is_valid_ether_addr(eth_addr)) {\r\nmemcpy(hw->perm_mac_addr, eth_addr, ETH_ALEN);\r\nreturn 0;\r\n}\r\nreturn 1;\r\n}\r\nstatic s32 atl1_read_mac_addr(struct atl1_hw *hw)\r\n{\r\ns32 ret = 0;\r\nu16 i;\r\nif (atl1_get_permanent_address(hw)) {\r\neth_random_addr(hw->perm_mac_addr);\r\nret = 1;\r\n}\r\nfor (i = 0; i < ETH_ALEN; i++)\r\nhw->mac_addr[i] = hw->perm_mac_addr[i];\r\nreturn ret;\r\n}\r\nstatic u32 atl1_hash_mc_addr(struct atl1_hw *hw, u8 *mc_addr)\r\n{\r\nu32 crc32, value = 0;\r\nint i;\r\ncrc32 = ether_crc_le(6, mc_addr);\r\nfor (i = 0; i < 32; i++)\r\nvalue |= (((crc32 >> i) & 1) << (31 - i));\r\nreturn value;\r\n}\r\nstatic void atl1_hash_set(struct atl1_hw *hw, u32 hash_value)\r\n{\r\nu32 hash_bit, hash_reg;\r\nu32 mta;\r\nhash_reg = (hash_value >> 31) & 0x1;\r\nhash_bit = (hash_value >> 26) & 0x1F;\r\nmta = ioread32((hw->hw_addr + REG_RX_HASH_TABLE) + (hash_reg << 2));\r\nmta |= (1 << hash_bit);\r\niowrite32(mta, (hw->hw_addr + REG_RX_HASH_TABLE) + (hash_reg << 2));\r\n}\r\nstatic s32 atl1_write_phy_reg(struct atl1_hw *hw, u32 reg_addr, u16 phy_data)\r\n{\r\nint i;\r\nu32 val;\r\nval = ((u32) (phy_data & MDIO_DATA_MASK)) << MDIO_DATA_SHIFT |\r\n(reg_addr & MDIO_REG_ADDR_MASK) << MDIO_REG_ADDR_SHIFT |\r\nMDIO_SUP_PREAMBLE |\r\nMDIO_START | MDIO_CLK_25_4 << MDIO_CLK_SEL_SHIFT;\r\niowrite32(val, hw->hw_addr + REG_MDIO_CTRL);\r\nioread32(hw->hw_addr + REG_MDIO_CTRL);\r\nfor (i = 0; i < MDIO_WAIT_TIMES; i++) {\r\nudelay(2);\r\nval = ioread32(hw->hw_addr + REG_MDIO_CTRL);\r\nif (!(val & (MDIO_START | MDIO_BUSY)))\r\nbreak;\r\n}\r\nif (!(val & (MDIO_START | MDIO_BUSY)))\r\nreturn 0;\r\nreturn ATLX_ERR_PHY;\r\n}\r\nstatic s32 atl1_phy_leave_power_saving(struct atl1_hw *hw)\r\n{\r\ns32 ret;\r\nret = atl1_write_phy_reg(hw, 29, 0x0029);\r\nif (ret)\r\nreturn ret;\r\nreturn atl1_write_phy_reg(hw, 30, 0);\r\n}\r\nstatic s32 atl1_phy_reset(struct atl1_hw *hw)\r\n{\r\nstruct pci_dev *pdev = hw->back->pdev;\r\nstruct atl1_adapter *adapter = hw->back;\r\ns32 ret_val;\r\nu16 phy_data;\r\nif (hw->media_type == MEDIA_TYPE_AUTO_SENSOR ||\r\nhw->media_type == MEDIA_TYPE_1000M_FULL)\r\nphy_data = MII_CR_RESET | MII_CR_AUTO_NEG_EN;\r\nelse {\r\nswitch (hw->media_type) {\r\ncase MEDIA_TYPE_100M_FULL:\r\nphy_data =\r\nMII_CR_FULL_DUPLEX | MII_CR_SPEED_100 |\r\nMII_CR_RESET;\r\nbreak;\r\ncase MEDIA_TYPE_100M_HALF:\r\nphy_data = MII_CR_SPEED_100 | MII_CR_RESET;\r\nbreak;\r\ncase MEDIA_TYPE_10M_FULL:\r\nphy_data =\r\nMII_CR_FULL_DUPLEX | MII_CR_SPEED_10 | MII_CR_RESET;\r\nbreak;\r\ndefault:\r\nphy_data = MII_CR_SPEED_10 | MII_CR_RESET;\r\nbreak;\r\n}\r\n}\r\nret_val = atl1_write_phy_reg(hw, MII_BMCR, phy_data);\r\nif (ret_val) {\r\nu32 val;\r\nint i;\r\nif (netif_msg_hw(adapter))\r\ndev_dbg(&pdev->dev, "pcie phy link down\n");\r\nfor (i = 0; i < 25; i++) {\r\nmsleep(1);\r\nval = ioread32(hw->hw_addr + REG_MDIO_CTRL);\r\nif (!(val & (MDIO_START | MDIO_BUSY)))\r\nbreak;\r\n}\r\nif ((val & (MDIO_START | MDIO_BUSY)) != 0) {\r\nif (netif_msg_hw(adapter))\r\ndev_warn(&pdev->dev,\r\n"pcie link down at least 25ms\n");\r\nreturn ret_val;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic s32 atl1_phy_setup_autoneg_adv(struct atl1_hw *hw)\r\n{\r\ns32 ret_val;\r\ns16 mii_autoneg_adv_reg;\r\ns16 mii_1000t_ctrl_reg;\r\nmii_autoneg_adv_reg = MII_AR_DEFAULT_CAP_MASK;\r\nmii_1000t_ctrl_reg = MII_ATLX_CR_1000T_DEFAULT_CAP_MASK;\r\nmii_autoneg_adv_reg &= ~MII_AR_SPEED_MASK;\r\nmii_1000t_ctrl_reg &= ~MII_ATLX_CR_1000T_SPEED_MASK;\r\nswitch (hw->media_type) {\r\ncase MEDIA_TYPE_AUTO_SENSOR:\r\nmii_autoneg_adv_reg |= (MII_AR_10T_HD_CAPS |\r\nMII_AR_10T_FD_CAPS |\r\nMII_AR_100TX_HD_CAPS |\r\nMII_AR_100TX_FD_CAPS);\r\nmii_1000t_ctrl_reg |= MII_ATLX_CR_1000T_FD_CAPS;\r\nbreak;\r\ncase MEDIA_TYPE_1000M_FULL:\r\nmii_1000t_ctrl_reg |= MII_ATLX_CR_1000T_FD_CAPS;\r\nbreak;\r\ncase MEDIA_TYPE_100M_FULL:\r\nmii_autoneg_adv_reg |= MII_AR_100TX_FD_CAPS;\r\nbreak;\r\ncase MEDIA_TYPE_100M_HALF:\r\nmii_autoneg_adv_reg |= MII_AR_100TX_HD_CAPS;\r\nbreak;\r\ncase MEDIA_TYPE_10M_FULL:\r\nmii_autoneg_adv_reg |= MII_AR_10T_FD_CAPS;\r\nbreak;\r\ndefault:\r\nmii_autoneg_adv_reg |= MII_AR_10T_HD_CAPS;\r\nbreak;\r\n}\r\nmii_autoneg_adv_reg |= (MII_AR_ASM_DIR | MII_AR_PAUSE);\r\nhw->mii_autoneg_adv_reg = mii_autoneg_adv_reg;\r\nhw->mii_1000t_ctrl_reg = mii_1000t_ctrl_reg;\r\nret_val = atl1_write_phy_reg(hw, MII_ADVERTISE, mii_autoneg_adv_reg);\r\nif (ret_val)\r\nreturn ret_val;\r\nret_val = atl1_write_phy_reg(hw, MII_ATLX_CR, mii_1000t_ctrl_reg);\r\nif (ret_val)\r\nreturn ret_val;\r\nreturn 0;\r\n}\r\nstatic s32 atl1_setup_link(struct atl1_hw *hw)\r\n{\r\nstruct pci_dev *pdev = hw->back->pdev;\r\nstruct atl1_adapter *adapter = hw->back;\r\ns32 ret_val;\r\nret_val = atl1_phy_setup_autoneg_adv(hw);\r\nif (ret_val) {\r\nif (netif_msg_link(adapter))\r\ndev_dbg(&pdev->dev,\r\n"error setting up autonegotiation\n");\r\nreturn ret_val;\r\n}\r\nret_val = atl1_phy_reset(hw);\r\nif (ret_val) {\r\nif (netif_msg_link(adapter))\r\ndev_dbg(&pdev->dev, "error resetting phy\n");\r\nreturn ret_val;\r\n}\r\nhw->phy_configured = true;\r\nreturn ret_val;\r\n}\r\nstatic void atl1_init_flash_opcode(struct atl1_hw *hw)\r\n{\r\nif (hw->flash_vendor >= ARRAY_SIZE(flash_table))\r\nhw->flash_vendor = 0;\r\niowrite8(flash_table[hw->flash_vendor].cmd_program,\r\nhw->hw_addr + REG_SPI_FLASH_OP_PROGRAM);\r\niowrite8(flash_table[hw->flash_vendor].cmd_sector_erase,\r\nhw->hw_addr + REG_SPI_FLASH_OP_SC_ERASE);\r\niowrite8(flash_table[hw->flash_vendor].cmd_chip_erase,\r\nhw->hw_addr + REG_SPI_FLASH_OP_CHIP_ERASE);\r\niowrite8(flash_table[hw->flash_vendor].cmd_rdid,\r\nhw->hw_addr + REG_SPI_FLASH_OP_RDID);\r\niowrite8(flash_table[hw->flash_vendor].cmd_wren,\r\nhw->hw_addr + REG_SPI_FLASH_OP_WREN);\r\niowrite8(flash_table[hw->flash_vendor].cmd_rdsr,\r\nhw->hw_addr + REG_SPI_FLASH_OP_RDSR);\r\niowrite8(flash_table[hw->flash_vendor].cmd_wrsr,\r\nhw->hw_addr + REG_SPI_FLASH_OP_WRSR);\r\niowrite8(flash_table[hw->flash_vendor].cmd_read,\r\nhw->hw_addr + REG_SPI_FLASH_OP_READ);\r\n}\r\nstatic s32 atl1_init_hw(struct atl1_hw *hw)\r\n{\r\nu32 ret_val = 0;\r\niowrite32(0, hw->hw_addr + REG_RX_HASH_TABLE);\r\niowrite32(0, (hw->hw_addr + REG_RX_HASH_TABLE) + (1 << 2));\r\natl1_init_flash_opcode(hw);\r\nif (!hw->phy_configured) {\r\nret_val = atl1_write_phy_reg(hw, 18, 0xC00);\r\nif (ret_val)\r\nreturn ret_val;\r\nret_val = atl1_phy_leave_power_saving(hw);\r\nif (ret_val)\r\nreturn ret_val;\r\nret_val = atl1_setup_link(hw);\r\n}\r\nreturn ret_val;\r\n}\r\nstatic s32 atl1_get_speed_and_duplex(struct atl1_hw *hw, u16 *speed, u16 *duplex)\r\n{\r\nstruct pci_dev *pdev = hw->back->pdev;\r\nstruct atl1_adapter *adapter = hw->back;\r\ns32 ret_val;\r\nu16 phy_data;\r\nret_val = atl1_read_phy_reg(hw, MII_ATLX_PSSR, &phy_data);\r\nif (ret_val)\r\nreturn ret_val;\r\nif (!(phy_data & MII_ATLX_PSSR_SPD_DPLX_RESOLVED))\r\nreturn ATLX_ERR_PHY_RES;\r\nswitch (phy_data & MII_ATLX_PSSR_SPEED) {\r\ncase MII_ATLX_PSSR_1000MBS:\r\n*speed = SPEED_1000;\r\nbreak;\r\ncase MII_ATLX_PSSR_100MBS:\r\n*speed = SPEED_100;\r\nbreak;\r\ncase MII_ATLX_PSSR_10MBS:\r\n*speed = SPEED_10;\r\nbreak;\r\ndefault:\r\nif (netif_msg_hw(adapter))\r\ndev_dbg(&pdev->dev, "error getting speed\n");\r\nreturn ATLX_ERR_PHY_SPEED;\r\n}\r\nif (phy_data & MII_ATLX_PSSR_DPLX)\r\n*duplex = FULL_DUPLEX;\r\nelse\r\n*duplex = HALF_DUPLEX;\r\nreturn 0;\r\n}\r\nstatic void atl1_set_mac_addr(struct atl1_hw *hw)\r\n{\r\nu32 value;\r\nvalue = (((u32) hw->mac_addr[2]) << 24) |\r\n(((u32) hw->mac_addr[3]) << 16) |\r\n(((u32) hw->mac_addr[4]) << 8) | (((u32) hw->mac_addr[5]));\r\niowrite32(value, hw->hw_addr + REG_MAC_STA_ADDR);\r\nvalue = (((u32) hw->mac_addr[0]) << 8) | (((u32) hw->mac_addr[1]));\r\niowrite32(value, (hw->hw_addr + REG_MAC_STA_ADDR) + (1 << 2));\r\n}\r\nstatic int atl1_sw_init(struct atl1_adapter *adapter)\r\n{\r\nstruct atl1_hw *hw = &adapter->hw;\r\nstruct net_device *netdev = adapter->netdev;\r\nhw->max_frame_size = netdev->mtu + ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN;\r\nhw->min_frame_size = ETH_ZLEN + ETH_FCS_LEN;\r\nadapter->wol = 0;\r\ndevice_set_wakeup_enable(&adapter->pdev->dev, false);\r\nadapter->rx_buffer_len = (hw->max_frame_size + 7) & ~7;\r\nadapter->ict = 50000;\r\nadapter->link_speed = SPEED_0;\r\nadapter->link_duplex = FULL_DUPLEX;\r\nhw->phy_configured = false;\r\nhw->preamble_len = 7;\r\nhw->ipgt = 0x60;\r\nhw->min_ifg = 0x50;\r\nhw->ipgr1 = 0x40;\r\nhw->ipgr2 = 0x60;\r\nhw->max_retry = 0xf;\r\nhw->lcol = 0x37;\r\nhw->jam_ipg = 7;\r\nhw->rfd_burst = 8;\r\nhw->rrd_burst = 8;\r\nhw->rfd_fetch_gap = 1;\r\nhw->rx_jumbo_th = adapter->rx_buffer_len / 8;\r\nhw->rx_jumbo_lkah = 1;\r\nhw->rrd_ret_timer = 16;\r\nhw->tpd_burst = 4;\r\nhw->tpd_fetch_th = 16;\r\nhw->txf_burst = 0x100;\r\nhw->tx_jumbo_task_th = (hw->max_frame_size + 7) >> 3;\r\nhw->tpd_fetch_gap = 1;\r\nhw->rcb_value = atl1_rcb_64;\r\nhw->dma_ord = atl1_dma_ord_enh;\r\nhw->dmar_block = atl1_dma_req_256;\r\nhw->dmaw_block = atl1_dma_req_256;\r\nhw->cmb_rrd = 4;\r\nhw->cmb_tpd = 4;\r\nhw->cmb_rx_timer = 1;\r\nhw->cmb_tx_timer = 1;\r\nhw->smb_timer = 100000;\r\nspin_lock_init(&adapter->lock);\r\nspin_lock_init(&adapter->mb_lock);\r\nreturn 0;\r\n}\r\nstatic int mdio_read(struct net_device *netdev, int phy_id, int reg_num)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\nu16 result;\r\natl1_read_phy_reg(&adapter->hw, reg_num & 0x1f, &result);\r\nreturn result;\r\n}\r\nstatic void mdio_write(struct net_device *netdev, int phy_id, int reg_num,\r\nint val)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\natl1_write_phy_reg(&adapter->hw, reg_num, val);\r\n}\r\nstatic int atl1_mii_ioctl(struct net_device *netdev, struct ifreq *ifr, int cmd)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\nunsigned long flags;\r\nint retval;\r\nif (!netif_running(netdev))\r\nreturn -EINVAL;\r\nspin_lock_irqsave(&adapter->lock, flags);\r\nretval = generic_mii_ioctl(&adapter->mii, if_mii(ifr), cmd, NULL);\r\nspin_unlock_irqrestore(&adapter->lock, flags);\r\nreturn retval;\r\n}\r\nstatic s32 atl1_setup_ring_resources(struct atl1_adapter *adapter)\r\n{\r\nstruct atl1_tpd_ring *tpd_ring = &adapter->tpd_ring;\r\nstruct atl1_rfd_ring *rfd_ring = &adapter->rfd_ring;\r\nstruct atl1_rrd_ring *rrd_ring = &adapter->rrd_ring;\r\nstruct atl1_ring_header *ring_header = &adapter->ring_header;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nint size;\r\nu8 offset = 0;\r\nsize = sizeof(struct atl1_buffer) * (tpd_ring->count + rfd_ring->count);\r\ntpd_ring->buffer_info = kzalloc(size, GFP_KERNEL);\r\nif (unlikely(!tpd_ring->buffer_info)) {\r\nif (netif_msg_drv(adapter))\r\ndev_err(&pdev->dev, "kzalloc failed , size = D%d\n",\r\nsize);\r\ngoto err_nomem;\r\n}\r\nrfd_ring->buffer_info =\r\n(tpd_ring->buffer_info + tpd_ring->count);\r\nring_header->size = size =\r\nsizeof(struct tx_packet_desc) * tpd_ring->count\r\n+ sizeof(struct rx_free_desc) * rfd_ring->count\r\n+ sizeof(struct rx_return_desc) * rrd_ring->count\r\n+ sizeof(struct coals_msg_block)\r\n+ sizeof(struct stats_msg_block)\r\n+ 40;\r\nring_header->desc = pci_alloc_consistent(pdev, ring_header->size,\r\n&ring_header->dma);\r\nif (unlikely(!ring_header->desc)) {\r\nif (netif_msg_drv(adapter))\r\ndev_err(&pdev->dev, "pci_alloc_consistent failed\n");\r\ngoto err_nomem;\r\n}\r\nmemset(ring_header->desc, 0, ring_header->size);\r\ntpd_ring->dma = ring_header->dma;\r\noffset = (tpd_ring->dma & 0x7) ? (8 - (ring_header->dma & 0x7)) : 0;\r\ntpd_ring->dma += offset;\r\ntpd_ring->desc = (u8 *) ring_header->desc + offset;\r\ntpd_ring->size = sizeof(struct tx_packet_desc) * tpd_ring->count;\r\nrfd_ring->dma = tpd_ring->dma + tpd_ring->size;\r\noffset = (rfd_ring->dma & 0x7) ? (8 - (rfd_ring->dma & 0x7)) : 0;\r\nrfd_ring->dma += offset;\r\nrfd_ring->desc = (u8 *) tpd_ring->desc + (tpd_ring->size + offset);\r\nrfd_ring->size = sizeof(struct rx_free_desc) * rfd_ring->count;\r\nrrd_ring->dma = rfd_ring->dma + rfd_ring->size;\r\noffset = (rrd_ring->dma & 0x7) ? (8 - (rrd_ring->dma & 0x7)) : 0;\r\nrrd_ring->dma += offset;\r\nrrd_ring->desc = (u8 *) rfd_ring->desc + (rfd_ring->size + offset);\r\nrrd_ring->size = sizeof(struct rx_return_desc) * rrd_ring->count;\r\nadapter->cmb.dma = rrd_ring->dma + rrd_ring->size;\r\noffset = (adapter->cmb.dma & 0x7) ? (8 - (adapter->cmb.dma & 0x7)) : 0;\r\nadapter->cmb.dma += offset;\r\nadapter->cmb.cmb = (struct coals_msg_block *)\r\n((u8 *) rrd_ring->desc + (rrd_ring->size + offset));\r\nadapter->smb.dma = adapter->cmb.dma + sizeof(struct coals_msg_block);\r\noffset = (adapter->smb.dma & 0x7) ? (8 - (adapter->smb.dma & 0x7)) : 0;\r\nadapter->smb.dma += offset;\r\nadapter->smb.smb = (struct stats_msg_block *)\r\n((u8 *) adapter->cmb.cmb +\r\n(sizeof(struct coals_msg_block) + offset));\r\nreturn 0;\r\nerr_nomem:\r\nkfree(tpd_ring->buffer_info);\r\nreturn -ENOMEM;\r\n}\r\nstatic void atl1_init_ring_ptrs(struct atl1_adapter *adapter)\r\n{\r\nstruct atl1_tpd_ring *tpd_ring = &adapter->tpd_ring;\r\nstruct atl1_rfd_ring *rfd_ring = &adapter->rfd_ring;\r\nstruct atl1_rrd_ring *rrd_ring = &adapter->rrd_ring;\r\natomic_set(&tpd_ring->next_to_use, 0);\r\natomic_set(&tpd_ring->next_to_clean, 0);\r\nrfd_ring->next_to_clean = 0;\r\natomic_set(&rfd_ring->next_to_use, 0);\r\nrrd_ring->next_to_use = 0;\r\natomic_set(&rrd_ring->next_to_clean, 0);\r\n}\r\nstatic void atl1_clean_rx_ring(struct atl1_adapter *adapter)\r\n{\r\nstruct atl1_rfd_ring *rfd_ring = &adapter->rfd_ring;\r\nstruct atl1_rrd_ring *rrd_ring = &adapter->rrd_ring;\r\nstruct atl1_buffer *buffer_info;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nunsigned long size;\r\nunsigned int i;\r\nfor (i = 0; i < rfd_ring->count; i++) {\r\nbuffer_info = &rfd_ring->buffer_info[i];\r\nif (buffer_info->dma) {\r\npci_unmap_page(pdev, buffer_info->dma,\r\nbuffer_info->length, PCI_DMA_FROMDEVICE);\r\nbuffer_info->dma = 0;\r\n}\r\nif (buffer_info->skb) {\r\ndev_kfree_skb(buffer_info->skb);\r\nbuffer_info->skb = NULL;\r\n}\r\n}\r\nsize = sizeof(struct atl1_buffer) * rfd_ring->count;\r\nmemset(rfd_ring->buffer_info, 0, size);\r\nmemset(rfd_ring->desc, 0, rfd_ring->size);\r\nrfd_ring->next_to_clean = 0;\r\natomic_set(&rfd_ring->next_to_use, 0);\r\nrrd_ring->next_to_use = 0;\r\natomic_set(&rrd_ring->next_to_clean, 0);\r\n}\r\nstatic void atl1_clean_tx_ring(struct atl1_adapter *adapter)\r\n{\r\nstruct atl1_tpd_ring *tpd_ring = &adapter->tpd_ring;\r\nstruct atl1_buffer *buffer_info;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nunsigned long size;\r\nunsigned int i;\r\nfor (i = 0; i < tpd_ring->count; i++) {\r\nbuffer_info = &tpd_ring->buffer_info[i];\r\nif (buffer_info->dma) {\r\npci_unmap_page(pdev, buffer_info->dma,\r\nbuffer_info->length, PCI_DMA_TODEVICE);\r\nbuffer_info->dma = 0;\r\n}\r\n}\r\nfor (i = 0; i < tpd_ring->count; i++) {\r\nbuffer_info = &tpd_ring->buffer_info[i];\r\nif (buffer_info->skb) {\r\ndev_kfree_skb_any(buffer_info->skb);\r\nbuffer_info->skb = NULL;\r\n}\r\n}\r\nsize = sizeof(struct atl1_buffer) * tpd_ring->count;\r\nmemset(tpd_ring->buffer_info, 0, size);\r\nmemset(tpd_ring->desc, 0, tpd_ring->size);\r\natomic_set(&tpd_ring->next_to_use, 0);\r\natomic_set(&tpd_ring->next_to_clean, 0);\r\n}\r\nstatic void atl1_free_ring_resources(struct atl1_adapter *adapter)\r\n{\r\nstruct pci_dev *pdev = adapter->pdev;\r\nstruct atl1_tpd_ring *tpd_ring = &adapter->tpd_ring;\r\nstruct atl1_rfd_ring *rfd_ring = &adapter->rfd_ring;\r\nstruct atl1_rrd_ring *rrd_ring = &adapter->rrd_ring;\r\nstruct atl1_ring_header *ring_header = &adapter->ring_header;\r\natl1_clean_tx_ring(adapter);\r\natl1_clean_rx_ring(adapter);\r\nkfree(tpd_ring->buffer_info);\r\npci_free_consistent(pdev, ring_header->size, ring_header->desc,\r\nring_header->dma);\r\ntpd_ring->buffer_info = NULL;\r\ntpd_ring->desc = NULL;\r\ntpd_ring->dma = 0;\r\nrfd_ring->buffer_info = NULL;\r\nrfd_ring->desc = NULL;\r\nrfd_ring->dma = 0;\r\nrrd_ring->desc = NULL;\r\nrrd_ring->dma = 0;\r\nadapter->cmb.dma = 0;\r\nadapter->cmb.cmb = NULL;\r\nadapter->smb.dma = 0;\r\nadapter->smb.smb = NULL;\r\n}\r\nstatic void atl1_setup_mac_ctrl(struct atl1_adapter *adapter)\r\n{\r\nu32 value;\r\nstruct atl1_hw *hw = &adapter->hw;\r\nstruct net_device *netdev = adapter->netdev;\r\nvalue = MAC_CTRL_TX_EN | MAC_CTRL_RX_EN;\r\nif (FULL_DUPLEX == adapter->link_duplex)\r\nvalue |= MAC_CTRL_DUPLX;\r\nvalue |= ((u32) ((SPEED_1000 == adapter->link_speed) ?\r\nMAC_CTRL_SPEED_1000 : MAC_CTRL_SPEED_10_100) <<\r\nMAC_CTRL_SPEED_SHIFT);\r\nvalue |= (MAC_CTRL_TX_FLOW | MAC_CTRL_RX_FLOW);\r\nvalue |= (MAC_CTRL_ADD_CRC | MAC_CTRL_PAD);\r\nvalue |= (((u32) adapter->hw.preamble_len\r\n& MAC_CTRL_PRMLEN_MASK) << MAC_CTRL_PRMLEN_SHIFT);\r\n__atlx_vlan_mode(netdev->features, &value);\r\nvalue |= MAC_CTRL_BC_EN;\r\nif (netdev->flags & IFF_PROMISC)\r\nvalue |= MAC_CTRL_PROMIS_EN;\r\nelse if (netdev->flags & IFF_ALLMULTI)\r\nvalue |= MAC_CTRL_MC_ALL_EN;\r\niowrite32(value, hw->hw_addr + REG_MAC_CTRL);\r\n}\r\nstatic u32 atl1_check_link(struct atl1_adapter *adapter)\r\n{\r\nstruct atl1_hw *hw = &adapter->hw;\r\nstruct net_device *netdev = adapter->netdev;\r\nu32 ret_val;\r\nu16 speed, duplex, phy_data;\r\nint reconfig = 0;\r\natl1_read_phy_reg(hw, MII_BMSR, &phy_data);\r\natl1_read_phy_reg(hw, MII_BMSR, &phy_data);\r\nif (!(phy_data & BMSR_LSTATUS)) {\r\nif (netif_carrier_ok(netdev)) {\r\nif (netif_msg_link(adapter))\r\ndev_info(&adapter->pdev->dev, "link is down\n");\r\nadapter->link_speed = SPEED_0;\r\nnetif_carrier_off(netdev);\r\n}\r\nreturn 0;\r\n}\r\nret_val = atl1_get_speed_and_duplex(hw, &speed, &duplex);\r\nif (ret_val)\r\nreturn ret_val;\r\nswitch (hw->media_type) {\r\ncase MEDIA_TYPE_1000M_FULL:\r\nif (speed != SPEED_1000 || duplex != FULL_DUPLEX)\r\nreconfig = 1;\r\nbreak;\r\ncase MEDIA_TYPE_100M_FULL:\r\nif (speed != SPEED_100 || duplex != FULL_DUPLEX)\r\nreconfig = 1;\r\nbreak;\r\ncase MEDIA_TYPE_100M_HALF:\r\nif (speed != SPEED_100 || duplex != HALF_DUPLEX)\r\nreconfig = 1;\r\nbreak;\r\ncase MEDIA_TYPE_10M_FULL:\r\nif (speed != SPEED_10 || duplex != FULL_DUPLEX)\r\nreconfig = 1;\r\nbreak;\r\ncase MEDIA_TYPE_10M_HALF:\r\nif (speed != SPEED_10 || duplex != HALF_DUPLEX)\r\nreconfig = 1;\r\nbreak;\r\n}\r\nif (!reconfig) {\r\nif (adapter->link_speed != speed ||\r\nadapter->link_duplex != duplex) {\r\nadapter->link_speed = speed;\r\nadapter->link_duplex = duplex;\r\natl1_setup_mac_ctrl(adapter);\r\nif (netif_msg_link(adapter))\r\ndev_info(&adapter->pdev->dev,\r\n"%s link is up %d Mbps %s\n",\r\nnetdev->name, adapter->link_speed,\r\nadapter->link_duplex == FULL_DUPLEX ?\r\n"full duplex" : "half duplex");\r\n}\r\nif (!netif_carrier_ok(netdev)) {\r\nnetif_carrier_on(netdev);\r\n}\r\nreturn 0;\r\n}\r\nif (netif_carrier_ok(netdev)) {\r\nadapter->link_speed = SPEED_0;\r\nnetif_carrier_off(netdev);\r\nnetif_stop_queue(netdev);\r\n}\r\nif (hw->media_type != MEDIA_TYPE_AUTO_SENSOR &&\r\nhw->media_type != MEDIA_TYPE_1000M_FULL) {\r\nswitch (hw->media_type) {\r\ncase MEDIA_TYPE_100M_FULL:\r\nphy_data = MII_CR_FULL_DUPLEX | MII_CR_SPEED_100 |\r\nMII_CR_RESET;\r\nbreak;\r\ncase MEDIA_TYPE_100M_HALF:\r\nphy_data = MII_CR_SPEED_100 | MII_CR_RESET;\r\nbreak;\r\ncase MEDIA_TYPE_10M_FULL:\r\nphy_data =\r\nMII_CR_FULL_DUPLEX | MII_CR_SPEED_10 | MII_CR_RESET;\r\nbreak;\r\ndefault:\r\nphy_data = MII_CR_SPEED_10 | MII_CR_RESET;\r\nbreak;\r\n}\r\natl1_write_phy_reg(hw, MII_BMCR, phy_data);\r\nreturn 0;\r\n}\r\nif (!adapter->phy_timer_pending) {\r\nadapter->phy_timer_pending = true;\r\nmod_timer(&adapter->phy_config_timer,\r\nround_jiffies(jiffies + 3 * HZ));\r\n}\r\nreturn 0;\r\n}\r\nstatic void set_flow_ctrl_old(struct atl1_adapter *adapter)\r\n{\r\nu32 hi, lo, value;\r\nvalue = adapter->rfd_ring.count;\r\nhi = value / 16;\r\nif (hi < 2)\r\nhi = 2;\r\nlo = value * 7 / 8;\r\nvalue = ((hi & RXQ_RXF_PAUSE_TH_HI_MASK) << RXQ_RXF_PAUSE_TH_HI_SHIFT) |\r\n((lo & RXQ_RXF_PAUSE_TH_LO_MASK) << RXQ_RXF_PAUSE_TH_LO_SHIFT);\r\niowrite32(value, adapter->hw.hw_addr + REG_RXQ_RXF_PAUSE_THRESH);\r\nvalue = adapter->rrd_ring.count;\r\nlo = value / 16;\r\nhi = value * 7 / 8;\r\nif (lo < 2)\r\nlo = 2;\r\nvalue = ((hi & RXQ_RRD_PAUSE_TH_HI_MASK) << RXQ_RRD_PAUSE_TH_HI_SHIFT) |\r\n((lo & RXQ_RRD_PAUSE_TH_LO_MASK) << RXQ_RRD_PAUSE_TH_LO_SHIFT);\r\niowrite32(value, adapter->hw.hw_addr + REG_RXQ_RRD_PAUSE_THRESH);\r\n}\r\nstatic void set_flow_ctrl_new(struct atl1_hw *hw)\r\n{\r\nu32 hi, lo, value;\r\nvalue = ioread32(hw->hw_addr + REG_SRAM_RXF_LEN);\r\nlo = value / 16;\r\nif (lo < 192)\r\nlo = 192;\r\nhi = value * 7 / 8;\r\nif (hi < lo)\r\nhi = lo + 16;\r\nvalue = ((hi & RXQ_RXF_PAUSE_TH_HI_MASK) << RXQ_RXF_PAUSE_TH_HI_SHIFT) |\r\n((lo & RXQ_RXF_PAUSE_TH_LO_MASK) << RXQ_RXF_PAUSE_TH_LO_SHIFT);\r\niowrite32(value, hw->hw_addr + REG_RXQ_RXF_PAUSE_THRESH);\r\nvalue = ioread32(hw->hw_addr + REG_SRAM_RRD_LEN);\r\nlo = value / 8;\r\nhi = value * 7 / 8;\r\nif (lo < 2)\r\nlo = 2;\r\nif (hi < lo)\r\nhi = lo + 3;\r\nvalue = ((hi & RXQ_RRD_PAUSE_TH_HI_MASK) << RXQ_RRD_PAUSE_TH_HI_SHIFT) |\r\n((lo & RXQ_RRD_PAUSE_TH_LO_MASK) << RXQ_RRD_PAUSE_TH_LO_SHIFT);\r\niowrite32(value, hw->hw_addr + REG_RXQ_RRD_PAUSE_THRESH);\r\n}\r\nstatic u32 atl1_configure(struct atl1_adapter *adapter)\r\n{\r\nstruct atl1_hw *hw = &adapter->hw;\r\nu32 value;\r\niowrite32(0xffffffff, adapter->hw.hw_addr + REG_ISR);\r\nvalue = (((u32) hw->mac_addr[2]) << 24) |\r\n(((u32) hw->mac_addr[3]) << 16) |\r\n(((u32) hw->mac_addr[4]) << 8) |\r\n(((u32) hw->mac_addr[5]));\r\niowrite32(value, hw->hw_addr + REG_MAC_STA_ADDR);\r\nvalue = (((u32) hw->mac_addr[0]) << 8) | (((u32) hw->mac_addr[1]));\r\niowrite32(value, hw->hw_addr + (REG_MAC_STA_ADDR + 4));\r\niowrite32((u32) ((adapter->tpd_ring.dma & 0xffffffff00000000ULL) >> 32),\r\nhw->hw_addr + REG_DESC_BASE_ADDR_HI);\r\niowrite32((u32) (adapter->rfd_ring.dma & 0x00000000ffffffffULL),\r\nhw->hw_addr + REG_DESC_RFD_ADDR_LO);\r\niowrite32((u32) (adapter->rrd_ring.dma & 0x00000000ffffffffULL),\r\nhw->hw_addr + REG_DESC_RRD_ADDR_LO);\r\niowrite32((u32) (adapter->tpd_ring.dma & 0x00000000ffffffffULL),\r\nhw->hw_addr + REG_DESC_TPD_ADDR_LO);\r\niowrite32((u32) (adapter->cmb.dma & 0x00000000ffffffffULL),\r\nhw->hw_addr + REG_DESC_CMB_ADDR_LO);\r\niowrite32((u32) (adapter->smb.dma & 0x00000000ffffffffULL),\r\nhw->hw_addr + REG_DESC_SMB_ADDR_LO);\r\nvalue = adapter->rrd_ring.count;\r\nvalue <<= 16;\r\nvalue += adapter->rfd_ring.count;\r\niowrite32(value, hw->hw_addr + REG_DESC_RFD_RRD_RING_SIZE);\r\niowrite32(adapter->tpd_ring.count, hw->hw_addr +\r\nREG_DESC_TPD_RING_SIZE);\r\niowrite32(1, hw->hw_addr + REG_LOAD_PTR);\r\nvalue = ((atomic_read(&adapter->tpd_ring.next_to_use)\r\n& MB_TPD_PROD_INDX_MASK) << MB_TPD_PROD_INDX_SHIFT) |\r\n((atomic_read(&adapter->rrd_ring.next_to_clean)\r\n& MB_RRD_CONS_INDX_MASK) << MB_RRD_CONS_INDX_SHIFT) |\r\n((atomic_read(&adapter->rfd_ring.next_to_use)\r\n& MB_RFD_PROD_INDX_MASK) << MB_RFD_PROD_INDX_SHIFT);\r\niowrite32(value, hw->hw_addr + REG_MAILBOX);\r\nvalue = (((u32) hw->ipgt & MAC_IPG_IFG_IPGT_MASK)\r\n<< MAC_IPG_IFG_IPGT_SHIFT) |\r\n(((u32) hw->min_ifg & MAC_IPG_IFG_MIFG_MASK)\r\n<< MAC_IPG_IFG_MIFG_SHIFT) |\r\n(((u32) hw->ipgr1 & MAC_IPG_IFG_IPGR1_MASK)\r\n<< MAC_IPG_IFG_IPGR1_SHIFT) |\r\n(((u32) hw->ipgr2 & MAC_IPG_IFG_IPGR2_MASK)\r\n<< MAC_IPG_IFG_IPGR2_SHIFT);\r\niowrite32(value, hw->hw_addr + REG_MAC_IPG_IFG);\r\nvalue = ((u32) hw->lcol & MAC_HALF_DUPLX_CTRL_LCOL_MASK) |\r\n(((u32) hw->max_retry & MAC_HALF_DUPLX_CTRL_RETRY_MASK)\r\n<< MAC_HALF_DUPLX_CTRL_RETRY_SHIFT) |\r\nMAC_HALF_DUPLX_CTRL_EXC_DEF_EN |\r\n(0xa << MAC_HALF_DUPLX_CTRL_ABEBT_SHIFT) |\r\n(((u32) hw->jam_ipg & MAC_HALF_DUPLX_CTRL_JAMIPG_MASK)\r\n<< MAC_HALF_DUPLX_CTRL_JAMIPG_SHIFT);\r\niowrite32(value, hw->hw_addr + REG_MAC_HALF_DUPLX_CTRL);\r\niowrite16(adapter->imt, hw->hw_addr + REG_IRQ_MODU_TIMER_INIT);\r\niowrite32(MASTER_CTRL_ITIMER_EN, hw->hw_addr + REG_MASTER_CTRL);\r\niowrite16(adapter->ict, hw->hw_addr + REG_CMBDISDMA_TIMER);\r\niowrite32(hw->max_frame_size, hw->hw_addr + REG_MTU);\r\nvalue = (((u32) hw->rx_jumbo_th & RXQ_JMBOSZ_TH_MASK)\r\n<< RXQ_JMBOSZ_TH_SHIFT) |\r\n(((u32) hw->rx_jumbo_lkah & RXQ_JMBO_LKAH_MASK)\r\n<< RXQ_JMBO_LKAH_SHIFT) |\r\n(((u32) hw->rrd_ret_timer & RXQ_RRD_TIMER_MASK)\r\n<< RXQ_RRD_TIMER_SHIFT);\r\niowrite32(value, hw->hw_addr + REG_RXQ_JMBOSZ_RRDTIM);\r\nswitch (hw->dev_rev) {\r\ncase 0x8001:\r\ncase 0x9001:\r\ncase 0x9002:\r\ncase 0x9003:\r\nset_flow_ctrl_old(adapter);\r\nbreak;\r\ndefault:\r\nset_flow_ctrl_new(hw);\r\nbreak;\r\n}\r\nvalue = (((u32) hw->tpd_burst & TXQ_CTRL_TPD_BURST_NUM_MASK)\r\n<< TXQ_CTRL_TPD_BURST_NUM_SHIFT) |\r\n(((u32) hw->txf_burst & TXQ_CTRL_TXF_BURST_NUM_MASK)\r\n<< TXQ_CTRL_TXF_BURST_NUM_SHIFT) |\r\n(((u32) hw->tpd_fetch_th & TXQ_CTRL_TPD_FETCH_TH_MASK)\r\n<< TXQ_CTRL_TPD_FETCH_TH_SHIFT) | TXQ_CTRL_ENH_MODE |\r\nTXQ_CTRL_EN;\r\niowrite32(value, hw->hw_addr + REG_TXQ_CTRL);\r\nvalue = (((u32) hw->tx_jumbo_task_th & TX_JUMBO_TASK_TH_MASK)\r\n<< TX_JUMBO_TASK_TH_SHIFT) |\r\n(((u32) hw->tpd_fetch_gap & TX_TPD_MIN_IPG_MASK)\r\n<< TX_TPD_MIN_IPG_SHIFT);\r\niowrite32(value, hw->hw_addr + REG_TX_JUMBO_TASK_TH_TPD_IPG);\r\nvalue = (((u32) hw->rfd_burst & RXQ_CTRL_RFD_BURST_NUM_MASK)\r\n<< RXQ_CTRL_RFD_BURST_NUM_SHIFT) |\r\n(((u32) hw->rrd_burst & RXQ_CTRL_RRD_BURST_THRESH_MASK)\r\n<< RXQ_CTRL_RRD_BURST_THRESH_SHIFT) |\r\n(((u32) hw->rfd_fetch_gap & RXQ_CTRL_RFD_PREF_MIN_IPG_MASK)\r\n<< RXQ_CTRL_RFD_PREF_MIN_IPG_SHIFT) | RXQ_CTRL_CUT_THRU_EN |\r\nRXQ_CTRL_EN;\r\niowrite32(value, hw->hw_addr + REG_RXQ_CTRL);\r\nvalue = ((((u32) hw->dmar_block) & DMA_CTRL_DMAR_BURST_LEN_MASK)\r\n<< DMA_CTRL_DMAR_BURST_LEN_SHIFT) |\r\n((((u32) hw->dmaw_block) & DMA_CTRL_DMAW_BURST_LEN_MASK)\r\n<< DMA_CTRL_DMAW_BURST_LEN_SHIFT) | DMA_CTRL_DMAR_EN |\r\nDMA_CTRL_DMAW_EN;\r\nvalue |= (u32) hw->dma_ord;\r\nif (atl1_rcb_128 == hw->rcb_value)\r\nvalue |= DMA_CTRL_RCB_VALUE;\r\niowrite32(value, hw->hw_addr + REG_DMA_CTRL);\r\nvalue = (hw->cmb_tpd > adapter->tpd_ring.count) ?\r\nhw->cmb_tpd : adapter->tpd_ring.count;\r\nvalue <<= 16;\r\nvalue |= hw->cmb_rrd;\r\niowrite32(value, hw->hw_addr + REG_CMB_WRITE_TH);\r\nvalue = hw->cmb_rx_timer | ((u32) hw->cmb_tx_timer << 16);\r\niowrite32(value, hw->hw_addr + REG_CMB_WRITE_TIMER);\r\niowrite32(hw->smb_timer, hw->hw_addr + REG_SMB_TIMER);\r\nvalue = CSMB_CTRL_CMB_EN | CSMB_CTRL_SMB_EN;\r\niowrite32(value, hw->hw_addr + REG_CSMB_CTRL);\r\nvalue = ioread32(adapter->hw.hw_addr + REG_ISR);\r\nif (unlikely((value & ISR_PHY_LINKDOWN) != 0))\r\nvalue = 1;\r\nelse\r\nvalue = 0;\r\niowrite32(0x3fffffff, adapter->hw.hw_addr + REG_ISR);\r\niowrite32(0, adapter->hw.hw_addr + REG_ISR);\r\nreturn value;\r\n}\r\nstatic void atl1_pcie_patch(struct atl1_adapter *adapter)\r\n{\r\nu32 value;\r\nvalue = 0x6500;\r\niowrite32(value, adapter->hw.hw_addr + 0x12FC);\r\nvalue = ioread32(adapter->hw.hw_addr + 0x1008);\r\nvalue |= 0x8000;\r\niowrite32(value, adapter->hw.hw_addr + 0x1008);\r\n}\r\nstatic void atl1_via_workaround(struct atl1_adapter *adapter)\r\n{\r\nunsigned long value;\r\nvalue = ioread16(adapter->hw.hw_addr + PCI_COMMAND);\r\nif (value & PCI_COMMAND_INTX_DISABLE)\r\nvalue &= ~PCI_COMMAND_INTX_DISABLE;\r\niowrite32(value, adapter->hw.hw_addr + PCI_COMMAND);\r\n}\r\nstatic void atl1_inc_smb(struct atl1_adapter *adapter)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct stats_msg_block *smb = adapter->smb.smb;\r\nu64 new_rx_errors = smb->rx_frag +\r\nsmb->rx_fcs_err +\r\nsmb->rx_len_err +\r\nsmb->rx_sz_ov +\r\nsmb->rx_rxf_ov +\r\nsmb->rx_rrd_ov +\r\nsmb->rx_align_err;\r\nu64 new_tx_errors = smb->tx_late_col +\r\nsmb->tx_abort_col +\r\nsmb->tx_underrun +\r\nsmb->tx_trunc;\r\nadapter->soft_stats.rx_packets += smb->rx_ok + new_rx_errors;\r\nadapter->soft_stats.tx_packets += smb->tx_ok + new_tx_errors;\r\nadapter->soft_stats.rx_bytes += smb->rx_byte_cnt;\r\nadapter->soft_stats.tx_bytes += smb->tx_byte_cnt;\r\nadapter->soft_stats.multicast += smb->rx_mcast;\r\nadapter->soft_stats.collisions += smb->tx_1_col +\r\nsmb->tx_2_col +\r\nsmb->tx_late_col +\r\nsmb->tx_abort_col;\r\nadapter->soft_stats.rx_errors += new_rx_errors;\r\nadapter->soft_stats.rx_fifo_errors += smb->rx_rxf_ov;\r\nadapter->soft_stats.rx_length_errors += smb->rx_len_err;\r\nadapter->soft_stats.rx_crc_errors += smb->rx_fcs_err;\r\nadapter->soft_stats.rx_frame_errors += smb->rx_align_err;\r\nadapter->soft_stats.rx_pause += smb->rx_pause;\r\nadapter->soft_stats.rx_rrd_ov += smb->rx_rrd_ov;\r\nadapter->soft_stats.rx_trunc += smb->rx_sz_ov;\r\nadapter->soft_stats.tx_errors += new_tx_errors;\r\nadapter->soft_stats.tx_fifo_errors += smb->tx_underrun;\r\nadapter->soft_stats.tx_aborted_errors += smb->tx_abort_col;\r\nadapter->soft_stats.tx_window_errors += smb->tx_late_col;\r\nadapter->soft_stats.excecol += smb->tx_abort_col;\r\nadapter->soft_stats.deffer += smb->tx_defer;\r\nadapter->soft_stats.scc += smb->tx_1_col;\r\nadapter->soft_stats.mcc += smb->tx_2_col;\r\nadapter->soft_stats.latecol += smb->tx_late_col;\r\nadapter->soft_stats.tx_underun += smb->tx_underrun;\r\nadapter->soft_stats.tx_trunc += smb->tx_trunc;\r\nadapter->soft_stats.tx_pause += smb->tx_pause;\r\nnetdev->stats.rx_bytes = adapter->soft_stats.rx_bytes;\r\nnetdev->stats.tx_bytes = adapter->soft_stats.tx_bytes;\r\nnetdev->stats.multicast = adapter->soft_stats.multicast;\r\nnetdev->stats.collisions = adapter->soft_stats.collisions;\r\nnetdev->stats.rx_errors = adapter->soft_stats.rx_errors;\r\nnetdev->stats.rx_length_errors =\r\nadapter->soft_stats.rx_length_errors;\r\nnetdev->stats.rx_crc_errors = adapter->soft_stats.rx_crc_errors;\r\nnetdev->stats.rx_frame_errors =\r\nadapter->soft_stats.rx_frame_errors;\r\nnetdev->stats.rx_fifo_errors = adapter->soft_stats.rx_fifo_errors;\r\nnetdev->stats.rx_dropped = adapter->soft_stats.rx_rrd_ov;\r\nnetdev->stats.tx_errors = adapter->soft_stats.tx_errors;\r\nnetdev->stats.tx_fifo_errors = adapter->soft_stats.tx_fifo_errors;\r\nnetdev->stats.tx_aborted_errors =\r\nadapter->soft_stats.tx_aborted_errors;\r\nnetdev->stats.tx_window_errors =\r\nadapter->soft_stats.tx_window_errors;\r\nnetdev->stats.tx_carrier_errors =\r\nadapter->soft_stats.tx_carrier_errors;\r\nnetdev->stats.rx_packets = adapter->soft_stats.rx_packets;\r\nnetdev->stats.tx_packets = adapter->soft_stats.tx_packets;\r\n}\r\nstatic void atl1_update_mailbox(struct atl1_adapter *adapter)\r\n{\r\nunsigned long flags;\r\nu32 tpd_next_to_use;\r\nu32 rfd_next_to_use;\r\nu32 rrd_next_to_clean;\r\nu32 value;\r\nspin_lock_irqsave(&adapter->mb_lock, flags);\r\ntpd_next_to_use = atomic_read(&adapter->tpd_ring.next_to_use);\r\nrfd_next_to_use = atomic_read(&adapter->rfd_ring.next_to_use);\r\nrrd_next_to_clean = atomic_read(&adapter->rrd_ring.next_to_clean);\r\nvalue = ((rfd_next_to_use & MB_RFD_PROD_INDX_MASK) <<\r\nMB_RFD_PROD_INDX_SHIFT) |\r\n((rrd_next_to_clean & MB_RRD_CONS_INDX_MASK) <<\r\nMB_RRD_CONS_INDX_SHIFT) |\r\n((tpd_next_to_use & MB_TPD_PROD_INDX_MASK) <<\r\nMB_TPD_PROD_INDX_SHIFT);\r\niowrite32(value, adapter->hw.hw_addr + REG_MAILBOX);\r\nspin_unlock_irqrestore(&adapter->mb_lock, flags);\r\n}\r\nstatic void atl1_clean_alloc_flag(struct atl1_adapter *adapter,\r\nstruct rx_return_desc *rrd, u16 offset)\r\n{\r\nstruct atl1_rfd_ring *rfd_ring = &adapter->rfd_ring;\r\nwhile (rfd_ring->next_to_clean != (rrd->buf_indx + offset)) {\r\nrfd_ring->buffer_info[rfd_ring->next_to_clean].alloced = 0;\r\nif (++rfd_ring->next_to_clean == rfd_ring->count) {\r\nrfd_ring->next_to_clean = 0;\r\n}\r\n}\r\n}\r\nstatic void atl1_update_rfd_index(struct atl1_adapter *adapter,\r\nstruct rx_return_desc *rrd)\r\n{\r\nu16 num_buf;\r\nnum_buf = (rrd->xsz.xsum_sz.pkt_size + adapter->rx_buffer_len - 1) /\r\nadapter->rx_buffer_len;\r\nif (rrd->num_buf == num_buf)\r\natl1_clean_alloc_flag(adapter, rrd, num_buf);\r\n}\r\nstatic void atl1_rx_checksum(struct atl1_adapter *adapter,\r\nstruct rx_return_desc *rrd, struct sk_buff *skb)\r\n{\r\nstruct pci_dev *pdev = adapter->pdev;\r\nskb_checksum_none_assert(skb);\r\nif (unlikely(rrd->pkt_flg & PACKET_FLAG_ERR)) {\r\nif (rrd->err_flg & (ERR_FLAG_CRC | ERR_FLAG_TRUNC |\r\nERR_FLAG_CODE | ERR_FLAG_OV)) {\r\nadapter->hw_csum_err++;\r\nif (netif_msg_rx_err(adapter))\r\ndev_printk(KERN_DEBUG, &pdev->dev,\r\n"rx checksum error\n");\r\nreturn;\r\n}\r\n}\r\nif (!(rrd->pkt_flg & PACKET_FLAG_IPV4))\r\nreturn;\r\nif (likely(!(rrd->err_flg &\r\n(ERR_FLAG_IP_CHKSUM | ERR_FLAG_L4_CHKSUM)))) {\r\nskb->ip_summed = CHECKSUM_UNNECESSARY;\r\nadapter->hw_csum_good++;\r\nreturn;\r\n}\r\n}\r\nstatic u16 atl1_alloc_rx_buffers(struct atl1_adapter *adapter)\r\n{\r\nstruct atl1_rfd_ring *rfd_ring = &adapter->rfd_ring;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nstruct page *page;\r\nunsigned long offset;\r\nstruct atl1_buffer *buffer_info, *next_info;\r\nstruct sk_buff *skb;\r\nu16 num_alloc = 0;\r\nu16 rfd_next_to_use, next_next;\r\nstruct rx_free_desc *rfd_desc;\r\nnext_next = rfd_next_to_use = atomic_read(&rfd_ring->next_to_use);\r\nif (++next_next == rfd_ring->count)\r\nnext_next = 0;\r\nbuffer_info = &rfd_ring->buffer_info[rfd_next_to_use];\r\nnext_info = &rfd_ring->buffer_info[next_next];\r\nwhile (!buffer_info->alloced && !next_info->alloced) {\r\nif (buffer_info->skb) {\r\nbuffer_info->alloced = 1;\r\ngoto next;\r\n}\r\nrfd_desc = ATL1_RFD_DESC(rfd_ring, rfd_next_to_use);\r\nskb = netdev_alloc_skb_ip_align(adapter->netdev,\r\nadapter->rx_buffer_len);\r\nif (unlikely(!skb)) {\r\nadapter->soft_stats.rx_dropped++;\r\nbreak;\r\n}\r\nbuffer_info->alloced = 1;\r\nbuffer_info->skb = skb;\r\nbuffer_info->length = (u16) adapter->rx_buffer_len;\r\npage = virt_to_page(skb->data);\r\noffset = (unsigned long)skb->data & ~PAGE_MASK;\r\nbuffer_info->dma = pci_map_page(pdev, page, offset,\r\nadapter->rx_buffer_len,\r\nPCI_DMA_FROMDEVICE);\r\nrfd_desc->buffer_addr = cpu_to_le64(buffer_info->dma);\r\nrfd_desc->buf_len = cpu_to_le16(adapter->rx_buffer_len);\r\nrfd_desc->coalese = 0;\r\nnext:\r\nrfd_next_to_use = next_next;\r\nif (unlikely(++next_next == rfd_ring->count))\r\nnext_next = 0;\r\nbuffer_info = &rfd_ring->buffer_info[rfd_next_to_use];\r\nnext_info = &rfd_ring->buffer_info[next_next];\r\nnum_alloc++;\r\n}\r\nif (num_alloc) {\r\nwmb();\r\natomic_set(&rfd_ring->next_to_use, (int)rfd_next_to_use);\r\n}\r\nreturn num_alloc;\r\n}\r\nstatic int atl1_intr_rx(struct atl1_adapter *adapter, int budget)\r\n{\r\nint i, count;\r\nu16 length;\r\nu16 rrd_next_to_clean;\r\nu32 value;\r\nstruct atl1_rfd_ring *rfd_ring = &adapter->rfd_ring;\r\nstruct atl1_rrd_ring *rrd_ring = &adapter->rrd_ring;\r\nstruct atl1_buffer *buffer_info;\r\nstruct rx_return_desc *rrd;\r\nstruct sk_buff *skb;\r\ncount = 0;\r\nrrd_next_to_clean = atomic_read(&rrd_ring->next_to_clean);\r\nwhile (count < budget) {\r\nrrd = ATL1_RRD_DESC(rrd_ring, rrd_next_to_clean);\r\ni = 1;\r\nif (likely(rrd->xsz.valid)) {\r\nchk_rrd:\r\nif (likely(rrd->num_buf == 1))\r\ngoto rrd_ok;\r\nelse if (netif_msg_rx_err(adapter)) {\r\ndev_printk(KERN_DEBUG, &adapter->pdev->dev,\r\n"unexpected RRD buffer count\n");\r\ndev_printk(KERN_DEBUG, &adapter->pdev->dev,\r\n"rx_buf_len = %d\n",\r\nadapter->rx_buffer_len);\r\ndev_printk(KERN_DEBUG, &adapter->pdev->dev,\r\n"RRD num_buf = %d\n",\r\nrrd->num_buf);\r\ndev_printk(KERN_DEBUG, &adapter->pdev->dev,\r\n"RRD pkt_len = %d\n",\r\nrrd->xsz.xsum_sz.pkt_size);\r\ndev_printk(KERN_DEBUG, &adapter->pdev->dev,\r\n"RRD pkt_flg = 0x%08X\n",\r\nrrd->pkt_flg);\r\ndev_printk(KERN_DEBUG, &adapter->pdev->dev,\r\n"RRD err_flg = 0x%08X\n",\r\nrrd->err_flg);\r\ndev_printk(KERN_DEBUG, &adapter->pdev->dev,\r\n"RRD vlan_tag = 0x%08X\n",\r\nrrd->vlan_tag);\r\n}\r\nif (unlikely(i-- > 0)) {\r\nudelay(1);\r\ngoto chk_rrd;\r\n}\r\nif (netif_msg_rx_err(adapter))\r\ndev_printk(KERN_DEBUG, &adapter->pdev->dev,\r\n"bad RRD\n");\r\nif (rrd->num_buf > 1)\r\natl1_update_rfd_index(adapter, rrd);\r\nrrd->xsz.valid = 0;\r\nif (++rrd_next_to_clean == rrd_ring->count)\r\nrrd_next_to_clean = 0;\r\ncount++;\r\ncontinue;\r\n} else {\r\nbreak;\r\n}\r\nrrd_ok:\r\natl1_clean_alloc_flag(adapter, rrd, 0);\r\nbuffer_info = &rfd_ring->buffer_info[rrd->buf_indx];\r\nif (++rfd_ring->next_to_clean == rfd_ring->count)\r\nrfd_ring->next_to_clean = 0;\r\nif (++rrd_next_to_clean == rrd_ring->count)\r\nrrd_next_to_clean = 0;\r\ncount++;\r\nif (unlikely(rrd->pkt_flg & PACKET_FLAG_ERR)) {\r\nif (!(rrd->err_flg &\r\n(ERR_FLAG_IP_CHKSUM | ERR_FLAG_L4_CHKSUM\r\n| ERR_FLAG_LEN))) {\r\nbuffer_info->alloced = 0;\r\nrrd->xsz.valid = 0;\r\ncontinue;\r\n}\r\n}\r\npci_unmap_page(adapter->pdev, buffer_info->dma,\r\nbuffer_info->length, PCI_DMA_FROMDEVICE);\r\nbuffer_info->dma = 0;\r\nskb = buffer_info->skb;\r\nlength = le16_to_cpu(rrd->xsz.xsum_sz.pkt_size);\r\nskb_put(skb, length - ETH_FCS_LEN);\r\natl1_rx_checksum(adapter, rrd, skb);\r\nskb->protocol = eth_type_trans(skb, adapter->netdev);\r\nif (rrd->pkt_flg & PACKET_FLAG_VLAN_INS) {\r\nu16 vlan_tag = (rrd->vlan_tag >> 4) |\r\n((rrd->vlan_tag & 7) << 13) |\r\n((rrd->vlan_tag & 8) << 9);\r\n__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vlan_tag);\r\n}\r\nnetif_receive_skb(skb);\r\nbuffer_info->skb = NULL;\r\nbuffer_info->alloced = 0;\r\nrrd->xsz.valid = 0;\r\n}\r\natomic_set(&rrd_ring->next_to_clean, rrd_next_to_clean);\r\natl1_alloc_rx_buffers(adapter);\r\nif (count) {\r\nu32 tpd_next_to_use;\r\nu32 rfd_next_to_use;\r\nspin_lock(&adapter->mb_lock);\r\ntpd_next_to_use = atomic_read(&adapter->tpd_ring.next_to_use);\r\nrfd_next_to_use =\r\natomic_read(&adapter->rfd_ring.next_to_use);\r\nrrd_next_to_clean =\r\natomic_read(&adapter->rrd_ring.next_to_clean);\r\nvalue = ((rfd_next_to_use & MB_RFD_PROD_INDX_MASK) <<\r\nMB_RFD_PROD_INDX_SHIFT) |\r\n((rrd_next_to_clean & MB_RRD_CONS_INDX_MASK) <<\r\nMB_RRD_CONS_INDX_SHIFT) |\r\n((tpd_next_to_use & MB_TPD_PROD_INDX_MASK) <<\r\nMB_TPD_PROD_INDX_SHIFT);\r\niowrite32(value, adapter->hw.hw_addr + REG_MAILBOX);\r\nspin_unlock(&adapter->mb_lock);\r\n}\r\nreturn count;\r\n}\r\nstatic int atl1_intr_tx(struct atl1_adapter *adapter)\r\n{\r\nstruct atl1_tpd_ring *tpd_ring = &adapter->tpd_ring;\r\nstruct atl1_buffer *buffer_info;\r\nu16 sw_tpd_next_to_clean;\r\nu16 cmb_tpd_next_to_clean;\r\nint count = 0;\r\nsw_tpd_next_to_clean = atomic_read(&tpd_ring->next_to_clean);\r\ncmb_tpd_next_to_clean = le16_to_cpu(adapter->cmb.cmb->tpd_cons_idx);\r\nwhile (cmb_tpd_next_to_clean != sw_tpd_next_to_clean) {\r\nbuffer_info = &tpd_ring->buffer_info[sw_tpd_next_to_clean];\r\nif (buffer_info->dma) {\r\npci_unmap_page(adapter->pdev, buffer_info->dma,\r\nbuffer_info->length, PCI_DMA_TODEVICE);\r\nbuffer_info->dma = 0;\r\n}\r\nif (buffer_info->skb) {\r\ndev_kfree_skb_irq(buffer_info->skb);\r\nbuffer_info->skb = NULL;\r\n}\r\nif (++sw_tpd_next_to_clean == tpd_ring->count)\r\nsw_tpd_next_to_clean = 0;\r\ncount++;\r\n}\r\natomic_set(&tpd_ring->next_to_clean, sw_tpd_next_to_clean);\r\nif (netif_queue_stopped(adapter->netdev) &&\r\nnetif_carrier_ok(adapter->netdev))\r\nnetif_wake_queue(adapter->netdev);\r\nreturn count;\r\n}\r\nstatic u16 atl1_tpd_avail(struct atl1_tpd_ring *tpd_ring)\r\n{\r\nu16 next_to_clean = atomic_read(&tpd_ring->next_to_clean);\r\nu16 next_to_use = atomic_read(&tpd_ring->next_to_use);\r\nreturn (next_to_clean > next_to_use) ?\r\nnext_to_clean - next_to_use - 1 :\r\ntpd_ring->count + next_to_clean - next_to_use - 1;\r\n}\r\nstatic int atl1_tso(struct atl1_adapter *adapter, struct sk_buff *skb,\r\nstruct tx_packet_desc *ptpd)\r\n{\r\nu8 hdr_len, ip_off;\r\nu32 real_len;\r\nif (skb_shinfo(skb)->gso_size) {\r\nint err;\r\nerr = skb_cow_head(skb, 0);\r\nif (err < 0)\r\nreturn err;\r\nif (skb->protocol == htons(ETH_P_IP)) {\r\nstruct iphdr *iph = ip_hdr(skb);\r\nreal_len = (((unsigned char *)iph - skb->data) +\r\nntohs(iph->tot_len));\r\nif (real_len < skb->len)\r\npskb_trim(skb, real_len);\r\nhdr_len = (skb_transport_offset(skb) + tcp_hdrlen(skb));\r\nif (skb->len == hdr_len) {\r\niph->check = 0;\r\ntcp_hdr(skb)->check =\r\n~csum_tcpudp_magic(iph->saddr,\r\niph->daddr, tcp_hdrlen(skb),\r\nIPPROTO_TCP, 0);\r\nptpd->word3 |= (iph->ihl & TPD_IPHL_MASK) <<\r\nTPD_IPHL_SHIFT;\r\nptpd->word3 |= ((tcp_hdrlen(skb) >> 2) &\r\nTPD_TCPHDRLEN_MASK) <<\r\nTPD_TCPHDRLEN_SHIFT;\r\nptpd->word3 |= 1 << TPD_IP_CSUM_SHIFT;\r\nptpd->word3 |= 1 << TPD_TCP_CSUM_SHIFT;\r\nreturn 1;\r\n}\r\niph->check = 0;\r\ntcp_hdr(skb)->check = ~csum_tcpudp_magic(iph->saddr,\r\niph->daddr, 0, IPPROTO_TCP, 0);\r\nip_off = (unsigned char *)iph -\r\n(unsigned char *) skb_network_header(skb);\r\nif (ip_off == 8)\r\nptpd->word3 |= 1 << TPD_ETHTYPE_SHIFT;\r\nelse if (ip_off != 0)\r\nreturn -2;\r\nptpd->word3 |= (iph->ihl & TPD_IPHL_MASK) <<\r\nTPD_IPHL_SHIFT;\r\nptpd->word3 |= ((tcp_hdrlen(skb) >> 2) &\r\nTPD_TCPHDRLEN_MASK) << TPD_TCPHDRLEN_SHIFT;\r\nptpd->word3 |= (skb_shinfo(skb)->gso_size &\r\nTPD_MSS_MASK) << TPD_MSS_SHIFT;\r\nptpd->word3 |= 1 << TPD_SEGMENT_EN_SHIFT;\r\nreturn 3;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int atl1_tx_csum(struct atl1_adapter *adapter, struct sk_buff *skb,\r\nstruct tx_packet_desc *ptpd)\r\n{\r\nu8 css, cso;\r\nif (likely(skb->ip_summed == CHECKSUM_PARTIAL)) {\r\ncss = skb_checksum_start_offset(skb);\r\ncso = css + (u8) skb->csum_offset;\r\nif (unlikely(css & 0x1)) {\r\nif (netif_msg_tx_err(adapter))\r\ndev_printk(KERN_DEBUG, &adapter->pdev->dev,\r\n"payload offset not an even number\n");\r\nreturn -1;\r\n}\r\nptpd->word3 |= (css & TPD_PLOADOFFSET_MASK) <<\r\nTPD_PLOADOFFSET_SHIFT;\r\nptpd->word3 |= (cso & TPD_CCSUMOFFSET_MASK) <<\r\nTPD_CCSUMOFFSET_SHIFT;\r\nptpd->word3 |= 1 << TPD_CUST_CSUM_EN_SHIFT;\r\nreturn true;\r\n}\r\nreturn 0;\r\n}\r\nstatic void atl1_tx_map(struct atl1_adapter *adapter, struct sk_buff *skb,\r\nstruct tx_packet_desc *ptpd)\r\n{\r\nstruct atl1_tpd_ring *tpd_ring = &adapter->tpd_ring;\r\nstruct atl1_buffer *buffer_info;\r\nu16 buf_len = skb->len;\r\nstruct page *page;\r\nunsigned long offset;\r\nunsigned int nr_frags;\r\nunsigned int f;\r\nint retval;\r\nu16 next_to_use;\r\nu16 data_len;\r\nu8 hdr_len;\r\nbuf_len -= skb->data_len;\r\nnr_frags = skb_shinfo(skb)->nr_frags;\r\nnext_to_use = atomic_read(&tpd_ring->next_to_use);\r\nbuffer_info = &tpd_ring->buffer_info[next_to_use];\r\nBUG_ON(buffer_info->skb);\r\nbuffer_info->skb = NULL;\r\nretval = (ptpd->word3 >> TPD_SEGMENT_EN_SHIFT) & TPD_SEGMENT_EN_MASK;\r\nif (retval) {\r\nhdr_len = skb_transport_offset(skb) + tcp_hdrlen(skb);\r\nbuffer_info->length = hdr_len;\r\npage = virt_to_page(skb->data);\r\noffset = (unsigned long)skb->data & ~PAGE_MASK;\r\nbuffer_info->dma = pci_map_page(adapter->pdev, page,\r\noffset, hdr_len,\r\nPCI_DMA_TODEVICE);\r\nif (++next_to_use == tpd_ring->count)\r\nnext_to_use = 0;\r\nif (buf_len > hdr_len) {\r\nint i, nseg;\r\ndata_len = buf_len - hdr_len;\r\nnseg = (data_len + ATL1_MAX_TX_BUF_LEN - 1) /\r\nATL1_MAX_TX_BUF_LEN;\r\nfor (i = 0; i < nseg; i++) {\r\nbuffer_info =\r\n&tpd_ring->buffer_info[next_to_use];\r\nbuffer_info->skb = NULL;\r\nbuffer_info->length =\r\n(ATL1_MAX_TX_BUF_LEN >=\r\ndata_len) ? ATL1_MAX_TX_BUF_LEN : data_len;\r\ndata_len -= buffer_info->length;\r\npage = virt_to_page(skb->data +\r\n(hdr_len + i * ATL1_MAX_TX_BUF_LEN));\r\noffset = (unsigned long)(skb->data +\r\n(hdr_len + i * ATL1_MAX_TX_BUF_LEN)) &\r\n~PAGE_MASK;\r\nbuffer_info->dma = pci_map_page(adapter->pdev,\r\npage, offset, buffer_info->length,\r\nPCI_DMA_TODEVICE);\r\nif (++next_to_use == tpd_ring->count)\r\nnext_to_use = 0;\r\n}\r\n}\r\n} else {\r\nbuffer_info->length = buf_len;\r\npage = virt_to_page(skb->data);\r\noffset = (unsigned long)skb->data & ~PAGE_MASK;\r\nbuffer_info->dma = pci_map_page(adapter->pdev, page,\r\noffset, buf_len, PCI_DMA_TODEVICE);\r\nif (++next_to_use == tpd_ring->count)\r\nnext_to_use = 0;\r\n}\r\nfor (f = 0; f < nr_frags; f++) {\r\nconst struct skb_frag_struct *frag;\r\nu16 i, nseg;\r\nfrag = &skb_shinfo(skb)->frags[f];\r\nbuf_len = skb_frag_size(frag);\r\nnseg = (buf_len + ATL1_MAX_TX_BUF_LEN - 1) /\r\nATL1_MAX_TX_BUF_LEN;\r\nfor (i = 0; i < nseg; i++) {\r\nbuffer_info = &tpd_ring->buffer_info[next_to_use];\r\nBUG_ON(buffer_info->skb);\r\nbuffer_info->skb = NULL;\r\nbuffer_info->length = (buf_len > ATL1_MAX_TX_BUF_LEN) ?\r\nATL1_MAX_TX_BUF_LEN : buf_len;\r\nbuf_len -= buffer_info->length;\r\nbuffer_info->dma = skb_frag_dma_map(&adapter->pdev->dev,\r\nfrag, i * ATL1_MAX_TX_BUF_LEN,\r\nbuffer_info->length, DMA_TO_DEVICE);\r\nif (++next_to_use == tpd_ring->count)\r\nnext_to_use = 0;\r\n}\r\n}\r\nbuffer_info->skb = skb;\r\n}\r\nstatic void atl1_tx_queue(struct atl1_adapter *adapter, u16 count,\r\nstruct tx_packet_desc *ptpd)\r\n{\r\nstruct atl1_tpd_ring *tpd_ring = &adapter->tpd_ring;\r\nstruct atl1_buffer *buffer_info;\r\nstruct tx_packet_desc *tpd;\r\nu16 j;\r\nu32 val;\r\nu16 next_to_use = (u16) atomic_read(&tpd_ring->next_to_use);\r\nfor (j = 0; j < count; j++) {\r\nbuffer_info = &tpd_ring->buffer_info[next_to_use];\r\ntpd = ATL1_TPD_DESC(&adapter->tpd_ring, next_to_use);\r\nif (tpd != ptpd)\r\nmemcpy(tpd, ptpd, sizeof(struct tx_packet_desc));\r\ntpd->buffer_addr = cpu_to_le64(buffer_info->dma);\r\ntpd->word2 &= ~(TPD_BUFLEN_MASK << TPD_BUFLEN_SHIFT);\r\ntpd->word2 |= (cpu_to_le16(buffer_info->length) &\r\nTPD_BUFLEN_MASK) << TPD_BUFLEN_SHIFT;\r\nval = (tpd->word3 >> TPD_SEGMENT_EN_SHIFT) &\r\nTPD_SEGMENT_EN_MASK;\r\nif (val) {\r\nif (!j)\r\ntpd->word3 |= 1 << TPD_HDRFLAG_SHIFT;\r\nelse\r\ntpd->word3 &= ~(1 << TPD_HDRFLAG_SHIFT);\r\n}\r\nif (j == (count - 1))\r\ntpd->word3 |= 1 << TPD_EOP_SHIFT;\r\nif (++next_to_use == tpd_ring->count)\r\nnext_to_use = 0;\r\n}\r\nwmb();\r\natomic_set(&tpd_ring->next_to_use, next_to_use);\r\n}\r\nstatic netdev_tx_t atl1_xmit_frame(struct sk_buff *skb,\r\nstruct net_device *netdev)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\nstruct atl1_tpd_ring *tpd_ring = &adapter->tpd_ring;\r\nint len;\r\nint tso;\r\nint count = 1;\r\nint ret_val;\r\nstruct tx_packet_desc *ptpd;\r\nu16 vlan_tag;\r\nunsigned int nr_frags = 0;\r\nunsigned int mss = 0;\r\nunsigned int f;\r\nunsigned int proto_hdr_len;\r\nlen = skb_headlen(skb);\r\nif (unlikely(skb->len <= 0)) {\r\ndev_kfree_skb_any(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nnr_frags = skb_shinfo(skb)->nr_frags;\r\nfor (f = 0; f < nr_frags; f++) {\r\nunsigned int f_size = skb_frag_size(&skb_shinfo(skb)->frags[f]);\r\ncount += (f_size + ATL1_MAX_TX_BUF_LEN - 1) /\r\nATL1_MAX_TX_BUF_LEN;\r\n}\r\nmss = skb_shinfo(skb)->gso_size;\r\nif (mss) {\r\nif (skb->protocol == htons(ETH_P_IP)) {\r\nproto_hdr_len = (skb_transport_offset(skb) +\r\ntcp_hdrlen(skb));\r\nif (unlikely(proto_hdr_len > len)) {\r\ndev_kfree_skb_any(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nif (proto_hdr_len != len)\r\ncount += (len - proto_hdr_len +\r\nATL1_MAX_TX_BUF_LEN - 1) /\r\nATL1_MAX_TX_BUF_LEN;\r\n}\r\n}\r\nif (atl1_tpd_avail(&adapter->tpd_ring) < count) {\r\nnetif_stop_queue(netdev);\r\nif (netif_msg_tx_queued(adapter))\r\ndev_printk(KERN_DEBUG, &adapter->pdev->dev,\r\n"tx busy\n");\r\nreturn NETDEV_TX_BUSY;\r\n}\r\nptpd = ATL1_TPD_DESC(tpd_ring,\r\n(u16) atomic_read(&tpd_ring->next_to_use));\r\nmemset(ptpd, 0, sizeof(struct tx_packet_desc));\r\nif (vlan_tx_tag_present(skb)) {\r\nvlan_tag = vlan_tx_tag_get(skb);\r\nvlan_tag = (vlan_tag << 4) | (vlan_tag >> 13) |\r\n((vlan_tag >> 9) & 0x8);\r\nptpd->word3 |= 1 << TPD_INS_VL_TAG_SHIFT;\r\nptpd->word2 |= (vlan_tag & TPD_VLANTAG_MASK) <<\r\nTPD_VLANTAG_SHIFT;\r\n}\r\ntso = atl1_tso(adapter, skb, ptpd);\r\nif (tso < 0) {\r\ndev_kfree_skb_any(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nif (!tso) {\r\nret_val = atl1_tx_csum(adapter, skb, ptpd);\r\nif (ret_val < 0) {\r\ndev_kfree_skb_any(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\n}\r\natl1_tx_map(adapter, skb, ptpd);\r\natl1_tx_queue(adapter, count, ptpd);\r\natl1_update_mailbox(adapter);\r\nmmiowb();\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic int atl1_rings_clean(struct napi_struct *napi, int budget)\r\n{\r\nstruct atl1_adapter *adapter = container_of(napi, struct atl1_adapter, napi);\r\nint work_done = atl1_intr_rx(adapter, budget);\r\nif (atl1_intr_tx(adapter))\r\nwork_done = budget;\r\nif (work_done >= budget)\r\nreturn work_done;\r\nnapi_complete(napi);\r\nif (likely(adapter->int_enabled))\r\natlx_imr_set(adapter, IMR_NORMAL_MASK);\r\nreturn work_done;\r\n}\r\nstatic inline int atl1_sched_rings_clean(struct atl1_adapter* adapter)\r\n{\r\nif (!napi_schedule_prep(&adapter->napi))\r\nreturn 0;\r\n__napi_schedule(&adapter->napi);\r\nif (!adapter->int_enabled)\r\nreturn 1;\r\natlx_imr_set(adapter, IMR_NORXTX_MASK);\r\nreturn 1;\r\n}\r\nstatic irqreturn_t atl1_intr(int irq, void *data)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(data);\r\nu32 status;\r\nstatus = adapter->cmb.cmb->int_stats;\r\nif (!status)\r\nreturn IRQ_NONE;\r\nadapter->cmb.cmb->int_stats = status & (ISR_CMB_TX | ISR_CMB_RX);\r\nif (status & ISR_GPHY)\r\natlx_clear_phy_int(adapter);\r\niowrite32(status | ISR_DIS_INT, adapter->hw.hw_addr + REG_ISR);\r\nif (status & ISR_SMB)\r\natl1_inc_smb(adapter);\r\nif (status & ISR_PHY_LINKDOWN) {\r\nif (netif_msg_intr(adapter))\r\ndev_printk(KERN_DEBUG, &adapter->pdev->dev,\r\n"pcie phy link down %x\n", status);\r\nif (netif_running(adapter->netdev)) {\r\natlx_irq_disable(adapter);\r\nschedule_work(&adapter->reset_dev_task);\r\nreturn IRQ_HANDLED;\r\n}\r\n}\r\nif (status & (ISR_DMAR_TO_RST | ISR_DMAW_TO_RST)) {\r\nif (netif_msg_intr(adapter))\r\ndev_printk(KERN_DEBUG, &adapter->pdev->dev,\r\n"pcie DMA r/w error (status = 0x%x)\n",\r\nstatus);\r\natlx_irq_disable(adapter);\r\nschedule_work(&adapter->reset_dev_task);\r\nreturn IRQ_HANDLED;\r\n}\r\nif (status & ISR_GPHY) {\r\nadapter->soft_stats.tx_carrier_errors++;\r\natl1_check_for_link(adapter);\r\n}\r\nif (status & (ISR_CMB_TX | ISR_CMB_RX) &&\r\natl1_sched_rings_clean(adapter))\r\nadapter->cmb.cmb->int_stats = adapter->cmb.cmb->int_stats &\r\n~(ISR_CMB_TX | ISR_CMB_RX);\r\nif (unlikely(status & (ISR_RXF_OV | ISR_RFD_UNRUN |\r\nISR_RRD_OV | ISR_HOST_RFD_UNRUN |\r\nISR_HOST_RRD_OV))) {\r\nif (netif_msg_intr(adapter))\r\ndev_printk(KERN_DEBUG,\r\n&adapter->pdev->dev,\r\n"rx exception, ISR = 0x%x\n",\r\nstatus);\r\natl1_sched_rings_clean(adapter);\r\n}\r\niowrite32(ISR_DIS_SMB | ISR_DIS_DMA, adapter->hw.hw_addr + REG_ISR);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void atl1_phy_config(unsigned long data)\r\n{\r\nstruct atl1_adapter *adapter = (struct atl1_adapter *)data;\r\nstruct atl1_hw *hw = &adapter->hw;\r\nunsigned long flags;\r\nspin_lock_irqsave(&adapter->lock, flags);\r\nadapter->phy_timer_pending = false;\r\natl1_write_phy_reg(hw, MII_ADVERTISE, hw->mii_autoneg_adv_reg);\r\natl1_write_phy_reg(hw, MII_ATLX_CR, hw->mii_1000t_ctrl_reg);\r\natl1_write_phy_reg(hw, MII_BMCR, MII_CR_RESET | MII_CR_AUTO_NEG_EN);\r\nspin_unlock_irqrestore(&adapter->lock, flags);\r\n}\r\nstatic int atl1_reset(struct atl1_adapter *adapter)\r\n{\r\nint ret;\r\nret = atl1_reset_hw(&adapter->hw);\r\nif (ret)\r\nreturn ret;\r\nreturn atl1_init_hw(&adapter->hw);\r\n}\r\nstatic s32 atl1_up(struct atl1_adapter *adapter)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nint err;\r\nint irq_flags = 0;\r\natlx_set_multi(netdev);\r\natl1_init_ring_ptrs(adapter);\r\natlx_restore_vlan(adapter);\r\nerr = atl1_alloc_rx_buffers(adapter);\r\nif (unlikely(!err))\r\nreturn -ENOMEM;\r\nif (unlikely(atl1_configure(adapter))) {\r\nerr = -EIO;\r\ngoto err_up;\r\n}\r\nerr = pci_enable_msi(adapter->pdev);\r\nif (err) {\r\nif (netif_msg_ifup(adapter))\r\ndev_info(&adapter->pdev->dev,\r\n"Unable to enable MSI: %d\n", err);\r\nirq_flags |= IRQF_SHARED;\r\n}\r\nerr = request_irq(adapter->pdev->irq, atl1_intr, irq_flags,\r\nnetdev->name, netdev);\r\nif (unlikely(err))\r\ngoto err_up;\r\nnapi_enable(&adapter->napi);\r\natlx_irq_enable(adapter);\r\natl1_check_link(adapter);\r\nnetif_start_queue(netdev);\r\nreturn 0;\r\nerr_up:\r\npci_disable_msi(adapter->pdev);\r\natl1_clean_rx_ring(adapter);\r\nreturn err;\r\n}\r\nstatic void atl1_down(struct atl1_adapter *adapter)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nnapi_disable(&adapter->napi);\r\nnetif_stop_queue(netdev);\r\ndel_timer_sync(&adapter->phy_config_timer);\r\nadapter->phy_timer_pending = false;\r\natlx_irq_disable(adapter);\r\nfree_irq(adapter->pdev->irq, netdev);\r\npci_disable_msi(adapter->pdev);\r\natl1_reset_hw(&adapter->hw);\r\nadapter->cmb.cmb->int_stats = 0;\r\nadapter->link_speed = SPEED_0;\r\nadapter->link_duplex = -1;\r\nnetif_carrier_off(netdev);\r\natl1_clean_tx_ring(adapter);\r\natl1_clean_rx_ring(adapter);\r\n}\r\nstatic void atl1_reset_dev_task(struct work_struct *work)\r\n{\r\nstruct atl1_adapter *adapter =\r\ncontainer_of(work, struct atl1_adapter, reset_dev_task);\r\nstruct net_device *netdev = adapter->netdev;\r\nnetif_device_detach(netdev);\r\natl1_down(adapter);\r\natl1_up(adapter);\r\nnetif_device_attach(netdev);\r\n}\r\nstatic int atl1_change_mtu(struct net_device *netdev, int new_mtu)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\nint old_mtu = netdev->mtu;\r\nint max_frame = new_mtu + ETH_HLEN + ETH_FCS_LEN + VLAN_HLEN;\r\nif ((max_frame < ETH_ZLEN + ETH_FCS_LEN) ||\r\n(max_frame > MAX_JUMBO_FRAME_SIZE)) {\r\nif (netif_msg_link(adapter))\r\ndev_warn(&adapter->pdev->dev, "invalid MTU setting\n");\r\nreturn -EINVAL;\r\n}\r\nadapter->hw.max_frame_size = max_frame;\r\nadapter->hw.tx_jumbo_task_th = (max_frame + 7) >> 3;\r\nadapter->rx_buffer_len = (max_frame + 7) & ~7;\r\nadapter->hw.rx_jumbo_th = adapter->rx_buffer_len / 8;\r\nnetdev->mtu = new_mtu;\r\nif ((old_mtu != new_mtu) && netif_running(netdev)) {\r\natl1_down(adapter);\r\natl1_up(adapter);\r\n}\r\nreturn 0;\r\n}\r\nstatic int atl1_open(struct net_device *netdev)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\nint err;\r\nnetif_carrier_off(netdev);\r\nerr = atl1_setup_ring_resources(adapter);\r\nif (err)\r\nreturn err;\r\nerr = atl1_up(adapter);\r\nif (err)\r\ngoto err_up;\r\nreturn 0;\r\nerr_up:\r\natl1_reset(adapter);\r\nreturn err;\r\n}\r\nstatic int atl1_close(struct net_device *netdev)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\natl1_down(adapter);\r\natl1_free_ring_resources(adapter);\r\nreturn 0;\r\n}\r\nstatic int atl1_suspend(struct device *dev)\r\n{\r\nstruct pci_dev *pdev = to_pci_dev(dev);\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\nstruct atl1_hw *hw = &adapter->hw;\r\nu32 ctrl = 0;\r\nu32 wufc = adapter->wol;\r\nu32 val;\r\nu16 speed;\r\nu16 duplex;\r\nnetif_device_detach(netdev);\r\nif (netif_running(netdev))\r\natl1_down(adapter);\r\natl1_read_phy_reg(hw, MII_BMSR, (u16 *) & ctrl);\r\natl1_read_phy_reg(hw, MII_BMSR, (u16 *) & ctrl);\r\nval = ctrl & BMSR_LSTATUS;\r\nif (val)\r\nwufc &= ~ATLX_WUFC_LNKC;\r\nif (!wufc)\r\ngoto disable_wol;\r\nif (val) {\r\nval = atl1_get_speed_and_duplex(hw, &speed, &duplex);\r\nif (val) {\r\nif (netif_msg_ifdown(adapter))\r\ndev_printk(KERN_DEBUG, &pdev->dev,\r\n"error getting speed/duplex\n");\r\ngoto disable_wol;\r\n}\r\nctrl = 0;\r\nif (wufc & ATLX_WUFC_MAG)\r\nctrl |= (WOL_MAGIC_EN | WOL_MAGIC_PME_EN);\r\niowrite32(ctrl, hw->hw_addr + REG_WOL_CTRL);\r\nioread32(hw->hw_addr + REG_WOL_CTRL);\r\nctrl = MAC_CTRL_RX_EN;\r\nctrl |= ((u32)((speed == SPEED_1000) ? MAC_CTRL_SPEED_1000 :\r\nMAC_CTRL_SPEED_10_100) << MAC_CTRL_SPEED_SHIFT);\r\nif (duplex == FULL_DUPLEX)\r\nctrl |= MAC_CTRL_DUPLX;\r\nctrl |= (((u32)adapter->hw.preamble_len &\r\nMAC_CTRL_PRMLEN_MASK) << MAC_CTRL_PRMLEN_SHIFT);\r\n__atlx_vlan_mode(netdev->features, &ctrl);\r\nif (wufc & ATLX_WUFC_MAG)\r\nctrl |= MAC_CTRL_BC_EN;\r\niowrite32(ctrl, hw->hw_addr + REG_MAC_CTRL);\r\nioread32(hw->hw_addr + REG_MAC_CTRL);\r\nctrl = ioread32(hw->hw_addr + REG_PCIE_PHYMISC);\r\nctrl |= PCIE_PHYMISC_FORCE_RCV_DET;\r\niowrite32(ctrl, hw->hw_addr + REG_PCIE_PHYMISC);\r\nioread32(hw->hw_addr + REG_PCIE_PHYMISC);\r\n} else {\r\nctrl |= (WOL_LINK_CHG_EN | WOL_LINK_CHG_PME_EN);\r\niowrite32(ctrl, hw->hw_addr + REG_WOL_CTRL);\r\nioread32(hw->hw_addr + REG_WOL_CTRL);\r\niowrite32(0, hw->hw_addr + REG_MAC_CTRL);\r\nioread32(hw->hw_addr + REG_MAC_CTRL);\r\nhw->phy_configured = false;\r\n}\r\nreturn 0;\r\ndisable_wol:\r\niowrite32(0, hw->hw_addr + REG_WOL_CTRL);\r\nioread32(hw->hw_addr + REG_WOL_CTRL);\r\nctrl = ioread32(hw->hw_addr + REG_PCIE_PHYMISC);\r\nctrl |= PCIE_PHYMISC_FORCE_RCV_DET;\r\niowrite32(ctrl, hw->hw_addr + REG_PCIE_PHYMISC);\r\nioread32(hw->hw_addr + REG_PCIE_PHYMISC);\r\nhw->phy_configured = false;\r\nreturn 0;\r\n}\r\nstatic int atl1_resume(struct device *dev)\r\n{\r\nstruct pci_dev *pdev = to_pci_dev(dev);\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\niowrite32(0, adapter->hw.hw_addr + REG_WOL_CTRL);\r\natl1_reset_hw(&adapter->hw);\r\nif (netif_running(netdev)) {\r\nadapter->cmb.cmb->int_stats = 0;\r\natl1_up(adapter);\r\n}\r\nnetif_device_attach(netdev);\r\nreturn 0;\r\n}\r\nstatic void atl1_shutdown(struct pci_dev *pdev)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\n#ifdef CONFIG_PM_SLEEP\r\natl1_suspend(&pdev->dev);\r\n#endif\r\npci_wake_from_d3(pdev, adapter->wol);\r\npci_set_power_state(pdev, PCI_D3hot);\r\n}\r\nstatic void atl1_poll_controller(struct net_device *netdev)\r\n{\r\ndisable_irq(netdev->irq);\r\natl1_intr(netdev->irq, netdev);\r\nenable_irq(netdev->irq);\r\n}\r\nstatic int atl1_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\r\n{\r\nstruct net_device *netdev;\r\nstruct atl1_adapter *adapter;\r\nstatic int cards_found = 0;\r\nint err;\r\nerr = pci_enable_device(pdev);\r\nif (err)\r\nreturn err;\r\nerr = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (err) {\r\ndev_err(&pdev->dev, "no usable DMA configuration\n");\r\ngoto err_dma;\r\n}\r\nerr = pci_request_regions(pdev, ATLX_DRIVER_NAME);\r\nif (err)\r\ngoto err_request_regions;\r\npci_set_master(pdev);\r\nnetdev = alloc_etherdev(sizeof(struct atl1_adapter));\r\nif (!netdev) {\r\nerr = -ENOMEM;\r\ngoto err_alloc_etherdev;\r\n}\r\nSET_NETDEV_DEV(netdev, &pdev->dev);\r\npci_set_drvdata(pdev, netdev);\r\nadapter = netdev_priv(netdev);\r\nadapter->netdev = netdev;\r\nadapter->pdev = pdev;\r\nadapter->hw.back = adapter;\r\nadapter->msg_enable = netif_msg_init(debug, atl1_default_msg);\r\nadapter->hw.hw_addr = pci_iomap(pdev, 0, 0);\r\nif (!adapter->hw.hw_addr) {\r\nerr = -EIO;\r\ngoto err_pci_iomap;\r\n}\r\nadapter->hw.dev_rev = ioread16(adapter->hw.hw_addr +\r\n(REG_MASTER_CTRL + 2));\r\nif (netif_msg_probe(adapter))\r\ndev_info(&pdev->dev, "version %s\n", ATLX_DRIVER_VERSION);\r\nadapter->rfd_ring.count = adapter->rrd_ring.count = ATL1_DEFAULT_RFD;\r\nadapter->tpd_ring.count = ATL1_DEFAULT_TPD;\r\nadapter->mii.dev = netdev;\r\nadapter->mii.mdio_read = mdio_read;\r\nadapter->mii.mdio_write = mdio_write;\r\nadapter->mii.phy_id_mask = 0x1f;\r\nadapter->mii.reg_num_mask = 0x1f;\r\nnetdev->netdev_ops = &atl1_netdev_ops;\r\nnetdev->watchdog_timeo = 5 * HZ;\r\nnetif_napi_add(netdev, &adapter->napi, atl1_rings_clean, 64);\r\nnetdev->ethtool_ops = &atl1_ethtool_ops;\r\nadapter->bd_number = cards_found;\r\nerr = atl1_sw_init(adapter);\r\nif (err)\r\ngoto err_common;\r\nnetdev->features = NETIF_F_HW_CSUM;\r\nnetdev->features |= NETIF_F_SG;\r\nnetdev->features |= (NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_CTAG_RX);\r\nnetdev->hw_features = NETIF_F_HW_CSUM | NETIF_F_SG | NETIF_F_TSO |\r\nNETIF_F_HW_VLAN_CTAG_RX;\r\nnetdev->features |= NETIF_F_RXCSUM;\r\niowrite16(0, adapter->hw.hw_addr + REG_PHY_ENABLE);\r\nif (atl1_reset_hw(&adapter->hw)) {\r\nerr = -EIO;\r\ngoto err_common;\r\n}\r\nif (atl1_read_mac_addr(&adapter->hw)) {\r\nnetdev->addr_assign_type = NET_ADDR_RANDOM;\r\n}\r\nmemcpy(netdev->dev_addr, adapter->hw.mac_addr, netdev->addr_len);\r\nif (!is_valid_ether_addr(netdev->dev_addr)) {\r\nerr = -EIO;\r\ngoto err_common;\r\n}\r\natl1_check_options(adapter);\r\nerr = atl1_init_hw(&adapter->hw);\r\nif (err) {\r\nerr = -EIO;\r\ngoto err_common;\r\n}\r\natl1_pcie_patch(adapter);\r\nnetif_carrier_off(netdev);\r\nsetup_timer(&adapter->phy_config_timer, atl1_phy_config,\r\n(unsigned long)adapter);\r\nadapter->phy_timer_pending = false;\r\nINIT_WORK(&adapter->reset_dev_task, atl1_reset_dev_task);\r\nINIT_WORK(&adapter->link_chg_task, atlx_link_chg_task);\r\nerr = register_netdev(netdev);\r\nif (err)\r\ngoto err_common;\r\ncards_found++;\r\natl1_via_workaround(adapter);\r\nreturn 0;\r\nerr_common:\r\npci_iounmap(pdev, adapter->hw.hw_addr);\r\nerr_pci_iomap:\r\nfree_netdev(netdev);\r\nerr_alloc_etherdev:\r\npci_release_regions(pdev);\r\nerr_dma:\r\nerr_request_regions:\r\npci_disable_device(pdev);\r\nreturn err;\r\n}\r\nstatic void atl1_remove(struct pci_dev *pdev)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct atl1_adapter *adapter;\r\nif (!netdev)\r\nreturn;\r\nadapter = netdev_priv(netdev);\r\nif (!ether_addr_equal_unaligned(adapter->hw.mac_addr,\r\nadapter->hw.perm_mac_addr)) {\r\nmemcpy(adapter->hw.mac_addr, adapter->hw.perm_mac_addr,\r\nETH_ALEN);\r\natl1_set_mac_addr(&adapter->hw);\r\n}\r\niowrite16(0, adapter->hw.hw_addr + REG_PHY_ENABLE);\r\nunregister_netdev(netdev);\r\npci_iounmap(pdev, adapter->hw.hw_addr);\r\npci_release_regions(pdev);\r\nfree_netdev(netdev);\r\npci_disable_device(pdev);\r\n}\r\nstatic void atl1_get_ethtool_stats(struct net_device *netdev,\r\nstruct ethtool_stats *stats, u64 *data)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\nint i;\r\nchar *p;\r\nfor (i = 0; i < ARRAY_SIZE(atl1_gstrings_stats); i++) {\r\np = (char *)adapter+atl1_gstrings_stats[i].stat_offset;\r\ndata[i] = (atl1_gstrings_stats[i].sizeof_stat ==\r\nsizeof(u64)) ? *(u64 *)p : *(u32 *)p;\r\n}\r\n}\r\nstatic int atl1_get_sset_count(struct net_device *netdev, int sset)\r\n{\r\nswitch (sset) {\r\ncase ETH_SS_STATS:\r\nreturn ARRAY_SIZE(atl1_gstrings_stats);\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nstatic int atl1_get_settings(struct net_device *netdev,\r\nstruct ethtool_cmd *ecmd)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\nstruct atl1_hw *hw = &adapter->hw;\r\necmd->supported = (SUPPORTED_10baseT_Half |\r\nSUPPORTED_10baseT_Full |\r\nSUPPORTED_100baseT_Half |\r\nSUPPORTED_100baseT_Full |\r\nSUPPORTED_1000baseT_Full |\r\nSUPPORTED_Autoneg | SUPPORTED_TP);\r\necmd->advertising = ADVERTISED_TP;\r\nif (hw->media_type == MEDIA_TYPE_AUTO_SENSOR ||\r\nhw->media_type == MEDIA_TYPE_1000M_FULL) {\r\necmd->advertising |= ADVERTISED_Autoneg;\r\nif (hw->media_type == MEDIA_TYPE_AUTO_SENSOR) {\r\necmd->advertising |= ADVERTISED_Autoneg;\r\necmd->advertising |=\r\n(ADVERTISED_10baseT_Half |\r\nADVERTISED_10baseT_Full |\r\nADVERTISED_100baseT_Half |\r\nADVERTISED_100baseT_Full |\r\nADVERTISED_1000baseT_Full);\r\n} else\r\necmd->advertising |= (ADVERTISED_1000baseT_Full);\r\n}\r\necmd->port = PORT_TP;\r\necmd->phy_address = 0;\r\necmd->transceiver = XCVR_INTERNAL;\r\nif (netif_carrier_ok(adapter->netdev)) {\r\nu16 link_speed, link_duplex;\r\natl1_get_speed_and_duplex(hw, &link_speed, &link_duplex);\r\nethtool_cmd_speed_set(ecmd, link_speed);\r\nif (link_duplex == FULL_DUPLEX)\r\necmd->duplex = DUPLEX_FULL;\r\nelse\r\necmd->duplex = DUPLEX_HALF;\r\n} else {\r\nethtool_cmd_speed_set(ecmd, SPEED_UNKNOWN);\r\necmd->duplex = DUPLEX_UNKNOWN;\r\n}\r\nif (hw->media_type == MEDIA_TYPE_AUTO_SENSOR ||\r\nhw->media_type == MEDIA_TYPE_1000M_FULL)\r\necmd->autoneg = AUTONEG_ENABLE;\r\nelse\r\necmd->autoneg = AUTONEG_DISABLE;\r\nreturn 0;\r\n}\r\nstatic int atl1_set_settings(struct net_device *netdev,\r\nstruct ethtool_cmd *ecmd)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\nstruct atl1_hw *hw = &adapter->hw;\r\nu16 phy_data;\r\nint ret_val = 0;\r\nu16 old_media_type = hw->media_type;\r\nif (netif_running(adapter->netdev)) {\r\nif (netif_msg_link(adapter))\r\ndev_dbg(&adapter->pdev->dev,\r\n"ethtool shutting down adapter\n");\r\natl1_down(adapter);\r\n}\r\nif (ecmd->autoneg == AUTONEG_ENABLE)\r\nhw->media_type = MEDIA_TYPE_AUTO_SENSOR;\r\nelse {\r\nu32 speed = ethtool_cmd_speed(ecmd);\r\nif (speed == SPEED_1000) {\r\nif (ecmd->duplex != DUPLEX_FULL) {\r\nif (netif_msg_link(adapter))\r\ndev_warn(&adapter->pdev->dev,\r\n"1000M half is invalid\n");\r\nret_val = -EINVAL;\r\ngoto exit_sset;\r\n}\r\nhw->media_type = MEDIA_TYPE_1000M_FULL;\r\n} else if (speed == SPEED_100) {\r\nif (ecmd->duplex == DUPLEX_FULL)\r\nhw->media_type = MEDIA_TYPE_100M_FULL;\r\nelse\r\nhw->media_type = MEDIA_TYPE_100M_HALF;\r\n} else {\r\nif (ecmd->duplex == DUPLEX_FULL)\r\nhw->media_type = MEDIA_TYPE_10M_FULL;\r\nelse\r\nhw->media_type = MEDIA_TYPE_10M_HALF;\r\n}\r\n}\r\nswitch (hw->media_type) {\r\ncase MEDIA_TYPE_AUTO_SENSOR:\r\necmd->advertising =\r\nADVERTISED_10baseT_Half |\r\nADVERTISED_10baseT_Full |\r\nADVERTISED_100baseT_Half |\r\nADVERTISED_100baseT_Full |\r\nADVERTISED_1000baseT_Full |\r\nADVERTISED_Autoneg | ADVERTISED_TP;\r\nbreak;\r\ncase MEDIA_TYPE_1000M_FULL:\r\necmd->advertising =\r\nADVERTISED_1000baseT_Full |\r\nADVERTISED_Autoneg | ADVERTISED_TP;\r\nbreak;\r\ndefault:\r\necmd->advertising = 0;\r\nbreak;\r\n}\r\nif (atl1_phy_setup_autoneg_adv(hw)) {\r\nret_val = -EINVAL;\r\nif (netif_msg_link(adapter))\r\ndev_warn(&adapter->pdev->dev,\r\n"invalid ethtool speed/duplex setting\n");\r\ngoto exit_sset;\r\n}\r\nif (hw->media_type == MEDIA_TYPE_AUTO_SENSOR ||\r\nhw->media_type == MEDIA_TYPE_1000M_FULL)\r\nphy_data = MII_CR_RESET | MII_CR_AUTO_NEG_EN;\r\nelse {\r\nswitch (hw->media_type) {\r\ncase MEDIA_TYPE_100M_FULL:\r\nphy_data =\r\nMII_CR_FULL_DUPLEX | MII_CR_SPEED_100 |\r\nMII_CR_RESET;\r\nbreak;\r\ncase MEDIA_TYPE_100M_HALF:\r\nphy_data = MII_CR_SPEED_100 | MII_CR_RESET;\r\nbreak;\r\ncase MEDIA_TYPE_10M_FULL:\r\nphy_data =\r\nMII_CR_FULL_DUPLEX | MII_CR_SPEED_10 | MII_CR_RESET;\r\nbreak;\r\ndefault:\r\nphy_data = MII_CR_SPEED_10 | MII_CR_RESET;\r\nbreak;\r\n}\r\n}\r\natl1_write_phy_reg(hw, MII_BMCR, phy_data);\r\nexit_sset:\r\nif (ret_val)\r\nhw->media_type = old_media_type;\r\nif (netif_running(adapter->netdev)) {\r\nif (netif_msg_link(adapter))\r\ndev_dbg(&adapter->pdev->dev,\r\n"ethtool starting adapter\n");\r\natl1_up(adapter);\r\n} else if (!ret_val) {\r\nif (netif_msg_link(adapter))\r\ndev_dbg(&adapter->pdev->dev,\r\n"ethtool resetting adapter\n");\r\natl1_reset(adapter);\r\n}\r\nreturn ret_val;\r\n}\r\nstatic void atl1_get_drvinfo(struct net_device *netdev,\r\nstruct ethtool_drvinfo *drvinfo)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\nstrlcpy(drvinfo->driver, ATLX_DRIVER_NAME, sizeof(drvinfo->driver));\r\nstrlcpy(drvinfo->version, ATLX_DRIVER_VERSION,\r\nsizeof(drvinfo->version));\r\nstrlcpy(drvinfo->bus_info, pci_name(adapter->pdev),\r\nsizeof(drvinfo->bus_info));\r\ndrvinfo->eedump_len = ATL1_EEDUMP_LEN;\r\n}\r\nstatic void atl1_get_wol(struct net_device *netdev,\r\nstruct ethtool_wolinfo *wol)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\nwol->supported = WAKE_MAGIC;\r\nwol->wolopts = 0;\r\nif (adapter->wol & ATLX_WUFC_MAG)\r\nwol->wolopts |= WAKE_MAGIC;\r\n}\r\nstatic int atl1_set_wol(struct net_device *netdev,\r\nstruct ethtool_wolinfo *wol)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\nif (wol->wolopts & (WAKE_PHY | WAKE_UCAST | WAKE_MCAST | WAKE_BCAST |\r\nWAKE_ARP | WAKE_MAGICSECURE))\r\nreturn -EOPNOTSUPP;\r\nadapter->wol = 0;\r\nif (wol->wolopts & WAKE_MAGIC)\r\nadapter->wol |= ATLX_WUFC_MAG;\r\ndevice_set_wakeup_enable(&adapter->pdev->dev, adapter->wol);\r\nreturn 0;\r\n}\r\nstatic u32 atl1_get_msglevel(struct net_device *netdev)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\nreturn adapter->msg_enable;\r\n}\r\nstatic void atl1_set_msglevel(struct net_device *netdev, u32 value)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\nadapter->msg_enable = value;\r\n}\r\nstatic int atl1_get_regs_len(struct net_device *netdev)\r\n{\r\nreturn ATL1_REG_COUNT * sizeof(u32);\r\n}\r\nstatic void atl1_get_regs(struct net_device *netdev, struct ethtool_regs *regs,\r\nvoid *p)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\nstruct atl1_hw *hw = &adapter->hw;\r\nunsigned int i;\r\nu32 *regbuf = p;\r\nfor (i = 0; i < ATL1_REG_COUNT; i++) {\r\nswitch (i) {\r\ncase 6 ... 9:\r\ncase 14:\r\ncase 29 ... 31:\r\ncase 34 ... 63:\r\ncase 75 ... 127:\r\ncase 136 ... 1023:\r\ncase 1027 ... 1087:\r\ncase 1091 ... 1151:\r\ncase 1194 ... 1195:\r\ncase 1200 ... 1201:\r\ncase 1206 ... 1213:\r\ncase 1216 ... 1279:\r\ncase 1290 ... 1311:\r\ncase 1323 ... 1343:\r\ncase 1358 ... 1359:\r\ncase 1368 ... 1375:\r\ncase 1378 ... 1383:\r\ncase 1388 ... 1391:\r\ncase 1393 ... 1395:\r\ncase 1402 ... 1403:\r\ncase 1410 ... 1471:\r\ncase 1522 ... 1535:\r\nregbuf[i] = 0;\r\nbreak;\r\ndefault:\r\nregbuf[i] = ioread32(hw->hw_addr + (i * sizeof(u32)));\r\n}\r\n}\r\n}\r\nstatic void atl1_get_ringparam(struct net_device *netdev,\r\nstruct ethtool_ringparam *ring)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\nstruct atl1_tpd_ring *txdr = &adapter->tpd_ring;\r\nstruct atl1_rfd_ring *rxdr = &adapter->rfd_ring;\r\nring->rx_max_pending = ATL1_MAX_RFD;\r\nring->tx_max_pending = ATL1_MAX_TPD;\r\nring->rx_pending = rxdr->count;\r\nring->tx_pending = txdr->count;\r\n}\r\nstatic int atl1_set_ringparam(struct net_device *netdev,\r\nstruct ethtool_ringparam *ring)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\nstruct atl1_tpd_ring *tpdr = &adapter->tpd_ring;\r\nstruct atl1_rrd_ring *rrdr = &adapter->rrd_ring;\r\nstruct atl1_rfd_ring *rfdr = &adapter->rfd_ring;\r\nstruct atl1_tpd_ring tpd_old, tpd_new;\r\nstruct atl1_rfd_ring rfd_old, rfd_new;\r\nstruct atl1_rrd_ring rrd_old, rrd_new;\r\nstruct atl1_ring_header rhdr_old, rhdr_new;\r\nstruct atl1_smb smb;\r\nstruct atl1_cmb cmb;\r\nint err;\r\ntpd_old = adapter->tpd_ring;\r\nrfd_old = adapter->rfd_ring;\r\nrrd_old = adapter->rrd_ring;\r\nrhdr_old = adapter->ring_header;\r\nif (netif_running(adapter->netdev))\r\natl1_down(adapter);\r\nrfdr->count = (u16) max(ring->rx_pending, (u32) ATL1_MIN_RFD);\r\nrfdr->count = rfdr->count > ATL1_MAX_RFD ? ATL1_MAX_RFD :\r\nrfdr->count;\r\nrfdr->count = (rfdr->count + 3) & ~3;\r\nrrdr->count = rfdr->count;\r\ntpdr->count = (u16) max(ring->tx_pending, (u32) ATL1_MIN_TPD);\r\ntpdr->count = tpdr->count > ATL1_MAX_TPD ? ATL1_MAX_TPD :\r\ntpdr->count;\r\ntpdr->count = (tpdr->count + 3) & ~3;\r\nif (netif_running(adapter->netdev)) {\r\nerr = atl1_setup_ring_resources(adapter);\r\nif (err)\r\ngoto err_setup_ring;\r\nrfd_new = adapter->rfd_ring;\r\nrrd_new = adapter->rrd_ring;\r\ntpd_new = adapter->tpd_ring;\r\nrhdr_new = adapter->ring_header;\r\nadapter->rfd_ring = rfd_old;\r\nadapter->rrd_ring = rrd_old;\r\nadapter->tpd_ring = tpd_old;\r\nadapter->ring_header = rhdr_old;\r\nsmb = adapter->smb;\r\ncmb = adapter->cmb;\r\natl1_free_ring_resources(adapter);\r\nadapter->rfd_ring = rfd_new;\r\nadapter->rrd_ring = rrd_new;\r\nadapter->tpd_ring = tpd_new;\r\nadapter->ring_header = rhdr_new;\r\nadapter->smb = smb;\r\nadapter->cmb = cmb;\r\nerr = atl1_up(adapter);\r\nif (err)\r\nreturn err;\r\n}\r\nreturn 0;\r\nerr_setup_ring:\r\nadapter->rfd_ring = rfd_old;\r\nadapter->rrd_ring = rrd_old;\r\nadapter->tpd_ring = tpd_old;\r\nadapter->ring_header = rhdr_old;\r\natl1_up(adapter);\r\nreturn err;\r\n}\r\nstatic void atl1_get_pauseparam(struct net_device *netdev,\r\nstruct ethtool_pauseparam *epause)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\nstruct atl1_hw *hw = &adapter->hw;\r\nif (hw->media_type == MEDIA_TYPE_AUTO_SENSOR ||\r\nhw->media_type == MEDIA_TYPE_1000M_FULL) {\r\nepause->autoneg = AUTONEG_ENABLE;\r\n} else {\r\nepause->autoneg = AUTONEG_DISABLE;\r\n}\r\nepause->rx_pause = 1;\r\nepause->tx_pause = 1;\r\n}\r\nstatic int atl1_set_pauseparam(struct net_device *netdev,\r\nstruct ethtool_pauseparam *epause)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\nstruct atl1_hw *hw = &adapter->hw;\r\nif (hw->media_type == MEDIA_TYPE_AUTO_SENSOR ||\r\nhw->media_type == MEDIA_TYPE_1000M_FULL) {\r\nepause->autoneg = AUTONEG_ENABLE;\r\n} else {\r\nepause->autoneg = AUTONEG_DISABLE;\r\n}\r\nepause->rx_pause = 1;\r\nepause->tx_pause = 1;\r\nreturn 0;\r\n}\r\nstatic void atl1_get_strings(struct net_device *netdev, u32 stringset,\r\nu8 *data)\r\n{\r\nu8 *p = data;\r\nint i;\r\nswitch (stringset) {\r\ncase ETH_SS_STATS:\r\nfor (i = 0; i < ARRAY_SIZE(atl1_gstrings_stats); i++) {\r\nmemcpy(p, atl1_gstrings_stats[i].stat_string,\r\nETH_GSTRING_LEN);\r\np += ETH_GSTRING_LEN;\r\n}\r\nbreak;\r\n}\r\n}\r\nstatic int atl1_nway_reset(struct net_device *netdev)\r\n{\r\nstruct atl1_adapter *adapter = netdev_priv(netdev);\r\nstruct atl1_hw *hw = &adapter->hw;\r\nif (netif_running(netdev)) {\r\nu16 phy_data;\r\natl1_down(adapter);\r\nif (hw->media_type == MEDIA_TYPE_AUTO_SENSOR ||\r\nhw->media_type == MEDIA_TYPE_1000M_FULL) {\r\nphy_data = MII_CR_RESET | MII_CR_AUTO_NEG_EN;\r\n} else {\r\nswitch (hw->media_type) {\r\ncase MEDIA_TYPE_100M_FULL:\r\nphy_data = MII_CR_FULL_DUPLEX |\r\nMII_CR_SPEED_100 | MII_CR_RESET;\r\nbreak;\r\ncase MEDIA_TYPE_100M_HALF:\r\nphy_data = MII_CR_SPEED_100 | MII_CR_RESET;\r\nbreak;\r\ncase MEDIA_TYPE_10M_FULL:\r\nphy_data = MII_CR_FULL_DUPLEX |\r\nMII_CR_SPEED_10 | MII_CR_RESET;\r\nbreak;\r\ndefault:\r\nphy_data = MII_CR_SPEED_10 | MII_CR_RESET;\r\n}\r\n}\r\natl1_write_phy_reg(hw, MII_BMCR, phy_data);\r\natl1_up(adapter);\r\n}\r\nreturn 0;\r\n}
