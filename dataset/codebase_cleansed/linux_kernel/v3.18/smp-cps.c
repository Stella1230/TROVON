static unsigned core_vpe_count(unsigned core)\r\n{\r\nunsigned cfg;\r\nif (!config_enabled(CONFIG_MIPS_MT_SMP) || !cpu_has_mipsmt)\r\nreturn 1;\r\nwrite_gcr_cl_other(core << CM_GCR_Cx_OTHER_CORENUM_SHF);\r\ncfg = read_gcr_co_config() & CM_GCR_Cx_CONFIG_PVPE_MSK;\r\nreturn (cfg >> CM_GCR_Cx_CONFIG_PVPE_SHF) + 1;\r\n}\r\nstatic void __init cps_smp_setup(void)\r\n{\r\nunsigned int ncores, nvpes, core_vpes;\r\nint c, v;\r\nncores = mips_cm_numcores();\r\npr_info("VPE topology ");\r\nfor (c = nvpes = 0; c < ncores; c++) {\r\ncore_vpes = core_vpe_count(c);\r\npr_cont("%c%u", c ? ',' : '{', core_vpes);\r\nif (!c)\r\nsmp_num_siblings = core_vpes;\r\nfor (v = 0; v < min_t(int, core_vpes, NR_CPUS - nvpes); v++) {\r\ncpu_data[nvpes + v].core = c;\r\n#ifdef CONFIG_MIPS_MT_SMP\r\ncpu_data[nvpes + v].vpe_id = v;\r\n#endif\r\n}\r\nnvpes += core_vpes;\r\n}\r\npr_cont("} total %u\n", nvpes);\r\nfor (v = 0; v < min_t(unsigned, nvpes, NR_CPUS); v++) {\r\nset_cpu_possible(v, true);\r\nset_cpu_present(v, true);\r\n__cpu_number_map[v] = v;\r\n__cpu_logical_map[v] = v;\r\n}\r\nchange_c0_config(CONF_CM_CMASK, 0x5);\r\nbitmap_set(core_power, 0, 1);\r\nmips_cps_core_init();\r\nwrite_gcr_cl_coherence(0xff);\r\n}\r\nstatic void __init cps_prepare_cpus(unsigned int max_cpus)\r\n{\r\nunsigned ncores, core_vpes, c, cca;\r\nbool cca_unsuitable;\r\nu32 *entry_code;\r\nmips_mt_set_cpuoptions();\r\ncca = read_c0_config() & CONF_CM_CMASK;\r\nswitch (cca) {\r\ncase 0x4:\r\ncase 0x5:\r\ncca_unsuitable = false;\r\nbreak;\r\ndefault:\r\ncca_unsuitable = true;\r\n}\r\nncores = mips_cm_numcores();\r\nif (cca_unsuitable && ncores > 1) {\r\npr_warn("Using only one core due to unsuitable CCA 0x%x\n",\r\ncca);\r\nfor_each_present_cpu(c) {\r\nif (cpu_data[c].core)\r\nset_cpu_present(c, false);\r\n}\r\n}\r\nentry_code = (u32 *)&mips_cps_core_entry;\r\nUASM_i_LA(&entry_code, 3, (long)mips_cm_base);\r\nuasm_i_addiu(&entry_code, 16, 0, cca);\r\nblast_dcache_range((unsigned long)&mips_cps_core_entry,\r\n(unsigned long)entry_code);\r\nbc_wback_inv((unsigned long)&mips_cps_core_entry,\r\n(void *)entry_code - (void *)&mips_cps_core_entry);\r\n__sync();\r\nmips_cps_core_bootcfg = kcalloc(ncores, sizeof(*mips_cps_core_bootcfg),\r\nGFP_KERNEL);\r\nif (!mips_cps_core_bootcfg) {\r\npr_err("Failed to allocate boot config for %u cores\n", ncores);\r\ngoto err_out;\r\n}\r\nfor (c = 0; c < ncores; c++) {\r\ncore_vpes = core_vpe_count(c);\r\nmips_cps_core_bootcfg[c].vpe_config = kcalloc(core_vpes,\r\nsizeof(*mips_cps_core_bootcfg[c].vpe_config),\r\nGFP_KERNEL);\r\nif (!mips_cps_core_bootcfg[c].vpe_config) {\r\npr_err("Failed to allocate %u VPE boot configs\n",\r\ncore_vpes);\r\ngoto err_out;\r\n}\r\n}\r\natomic_set(&mips_cps_core_bootcfg[current_cpu_data.core].vpe_mask,\r\n1 << cpu_vpe_id(&current_cpu_data));\r\nreturn;\r\nerr_out:\r\nif (mips_cps_core_bootcfg) {\r\nfor (c = 0; c < ncores; c++)\r\nkfree(mips_cps_core_bootcfg[c].vpe_config);\r\nkfree(mips_cps_core_bootcfg);\r\nmips_cps_core_bootcfg = NULL;\r\n}\r\nfor_each_possible_cpu(c) {\r\nif (c == 0)\r\ncontinue;\r\nset_cpu_present(c, false);\r\n}\r\n}\r\nstatic void boot_core(unsigned core)\r\n{\r\nu32 access;\r\nwrite_gcr_cl_other(core << CM_GCR_Cx_OTHER_CORENUM_SHF);\r\nwrite_gcr_co_reset_base(CKSEG1ADDR((unsigned long)mips_cps_core_entry));\r\nwrite_gcr_co_coherence(0);\r\naccess = read_gcr_access();\r\naccess |= 1 << (CM_GCR_ACCESS_ACCESSEN_SHF + core);\r\nwrite_gcr_access(access);\r\nif (mips_cpc_present()) {\r\nmips_cpc_lock_other(core);\r\nwrite_cpc_co_cmd(CPC_Cx_CMD_RESET);\r\nmips_cpc_unlock_other();\r\n} else {\r\nwrite_gcr_co_reset_release(0);\r\n}\r\nbitmap_set(core_power, core, 1);\r\n}\r\nstatic void remote_vpe_boot(void *dummy)\r\n{\r\nmips_cps_boot_vpes();\r\n}\r\nstatic void cps_boot_secondary(int cpu, struct task_struct *idle)\r\n{\r\nunsigned core = cpu_data[cpu].core;\r\nunsigned vpe_id = cpu_vpe_id(&cpu_data[cpu]);\r\nstruct core_boot_config *core_cfg = &mips_cps_core_bootcfg[core];\r\nstruct vpe_boot_config *vpe_cfg = &core_cfg->vpe_config[vpe_id];\r\nunsigned int remote;\r\nint err;\r\nvpe_cfg->pc = (unsigned long)&smp_bootstrap;\r\nvpe_cfg->sp = __KSTK_TOS(idle);\r\nvpe_cfg->gp = (unsigned long)task_thread_info(idle);\r\natomic_or(1 << cpu_vpe_id(&cpu_data[cpu]), &core_cfg->vpe_mask);\r\npreempt_disable();\r\nif (!test_bit(core, core_power)) {\r\nboot_core(core);\r\ngoto out;\r\n}\r\nif (core != current_cpu_data.core) {\r\nfor (remote = 0; remote < NR_CPUS; remote++) {\r\nif (cpu_data[remote].core != core)\r\ncontinue;\r\nif (cpu_online(remote))\r\nbreak;\r\n}\r\nBUG_ON(remote >= NR_CPUS);\r\nerr = smp_call_function_single(remote, remote_vpe_boot,\r\nNULL, 1);\r\nif (err)\r\npanic("Failed to call remote CPU\n");\r\ngoto out;\r\n}\r\nBUG_ON(!cpu_has_mipsmt);\r\nmips_cps_boot_vpes();\r\nout:\r\npreempt_enable();\r\n}\r\nstatic void cps_init_secondary(void)\r\n{\r\nif (cpu_has_mipsmt)\r\ndmt();\r\nchange_c0_status(ST0_IM, STATUSF_IP3 | STATUSF_IP4 |\r\nSTATUSF_IP6 | STATUSF_IP7);\r\n}\r\nstatic void cps_smp_finish(void)\r\n{\r\nwrite_c0_compare(read_c0_count() + (8 * mips_hpt_frequency / HZ));\r\n#ifdef CONFIG_MIPS_MT_FPAFF\r\nif (cpu_has_fpu)\r\ncpu_set(smp_processor_id(), mt_fpu_cpumask);\r\n#endif\r\nlocal_irq_enable();\r\n}\r\nstatic int cps_cpu_disable(void)\r\n{\r\nunsigned cpu = smp_processor_id();\r\nstruct core_boot_config *core_cfg;\r\nif (!cpu)\r\nreturn -EBUSY;\r\nif (!cps_pm_support_state(CPS_PM_POWER_GATED))\r\nreturn -EINVAL;\r\ncore_cfg = &mips_cps_core_bootcfg[current_cpu_data.core];\r\natomic_sub(1 << cpu_vpe_id(&current_cpu_data), &core_cfg->vpe_mask);\r\nsmp_mb__after_atomic();\r\nset_cpu_online(cpu, false);\r\ncpu_clear(cpu, cpu_callin_map);\r\nreturn 0;\r\n}\r\nvoid play_dead(void)\r\n{\r\nunsigned cpu, core;\r\nlocal_irq_disable();\r\nidle_task_exit();\r\ncpu = smp_processor_id();\r\ncpu_death = CPU_DEATH_POWER;\r\nif (cpu_has_mipsmt) {\r\ncore = cpu_data[cpu].core;\r\nfor_each_online_cpu(cpu_death_sibling) {\r\nif (cpu_data[cpu_death_sibling].core != core)\r\ncontinue;\r\ncpu_death = CPU_DEATH_HALT;\r\nbreak;\r\n}\r\n}\r\ncomplete(&cpu_death_chosen);\r\nif (cpu_death == CPU_DEATH_HALT) {\r\nwrite_c0_tchalt(TCHALT_H);\r\ninstruction_hazard();\r\n} else {\r\ncps_pm_enter_state(CPS_PM_POWER_GATED);\r\n}\r\npanic("Failed to offline CPU %u", cpu);\r\n}\r\nstatic void wait_for_sibling_halt(void *ptr_cpu)\r\n{\r\nunsigned cpu = (unsigned)ptr_cpu;\r\nunsigned vpe_id = cpu_vpe_id(&cpu_data[cpu]);\r\nunsigned halted;\r\nunsigned long flags;\r\ndo {\r\nlocal_irq_save(flags);\r\nsettc(vpe_id);\r\nhalted = read_tc_c0_tchalt();\r\nlocal_irq_restore(flags);\r\n} while (!(halted & TCHALT_H));\r\n}\r\nstatic void cps_cpu_die(unsigned int cpu)\r\n{\r\nunsigned core = cpu_data[cpu].core;\r\nunsigned stat;\r\nint err;\r\nif (!wait_for_completion_timeout(&cpu_death_chosen,\r\nmsecs_to_jiffies(5000))) {\r\npr_err("CPU%u: didn't offline\n", cpu);\r\nreturn;\r\n}\r\nif (cpu_death == CPU_DEATH_POWER) {\r\ndo {\r\nmips_cpc_lock_other(core);\r\nstat = read_cpc_co_stat_conf();\r\nstat &= CPC_Cx_STAT_CONF_SEQSTATE_MSK;\r\nmips_cpc_unlock_other();\r\n} while (stat != CPC_Cx_STAT_CONF_SEQSTATE_D0 &&\r\nstat != CPC_Cx_STAT_CONF_SEQSTATE_D2 &&\r\nstat != CPC_Cx_STAT_CONF_SEQSTATE_U2);\r\nbitmap_clear(core_power, core, 1);\r\n} else if (cpu_has_mipsmt) {\r\nerr = smp_call_function_single(cpu_death_sibling,\r\nwait_for_sibling_halt,\r\n(void *)cpu, 1);\r\nif (err)\r\npanic("Failed to call remote sibling CPU\n");\r\n}\r\n}\r\nbool mips_cps_smp_in_use(void)\r\n{\r\nextern struct plat_smp_ops *mp_ops;\r\nreturn mp_ops == &cps_smp_ops;\r\n}\r\nint register_cps_smp_ops(void)\r\n{\r\nif (!mips_cm_present()) {\r\npr_warn("MIPS CPS SMP unable to proceed without a CM\n");\r\nreturn -ENODEV;\r\n}\r\nif (!(read_gcr_gic_status() & CM_GCR_GIC_STATUS_EX_MSK)) {\r\npr_warn("MIPS CPS SMP unable to proceed without a GIC\n");\r\nreturn -ENODEV;\r\n}\r\nregister_smp_ops(&cps_smp_ops);\r\nreturn 0;\r\n}
