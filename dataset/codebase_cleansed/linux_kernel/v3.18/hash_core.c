static void release_hash_device(struct hash_device_data *device_data)\r\n{\r\nspin_lock(&device_data->ctx_lock);\r\ndevice_data->current_ctx->device = NULL;\r\ndevice_data->current_ctx = NULL;\r\nspin_unlock(&device_data->ctx_lock);\r\nup(&driver_data.device_allocation);\r\n}\r\nstatic void hash_dma_setup_channel(struct hash_device_data *device_data,\r\nstruct device *dev)\r\n{\r\nstruct hash_platform_data *platform_data = dev->platform_data;\r\nstruct dma_slave_config conf = {\r\n.direction = DMA_MEM_TO_DEV,\r\n.dst_addr = device_data->phybase + HASH_DMA_FIFO,\r\n.dst_addr_width = DMA_SLAVE_BUSWIDTH_2_BYTES,\r\n.dst_maxburst = 16,\r\n};\r\ndma_cap_zero(device_data->dma.mask);\r\ndma_cap_set(DMA_SLAVE, device_data->dma.mask);\r\ndevice_data->dma.cfg_mem2hash = platform_data->mem_to_engine;\r\ndevice_data->dma.chan_mem2hash =\r\ndma_request_channel(device_data->dma.mask,\r\nplatform_data->dma_filter,\r\ndevice_data->dma.cfg_mem2hash);\r\ndmaengine_slave_config(device_data->dma.chan_mem2hash, &conf);\r\ninit_completion(&device_data->dma.complete);\r\n}\r\nstatic void hash_dma_callback(void *data)\r\n{\r\nstruct hash_ctx *ctx = data;\r\ncomplete(&ctx->device->dma.complete);\r\n}\r\nstatic int hash_set_dma_transfer(struct hash_ctx *ctx, struct scatterlist *sg,\r\nint len, enum dma_data_direction direction)\r\n{\r\nstruct dma_async_tx_descriptor *desc = NULL;\r\nstruct dma_chan *channel = NULL;\r\ndma_cookie_t cookie;\r\nif (direction != DMA_TO_DEVICE) {\r\ndev_err(ctx->device->dev, "%s: Invalid DMA direction\n",\r\n__func__);\r\nreturn -EFAULT;\r\n}\r\nsg->length = ALIGN(sg->length, HASH_DMA_ALIGN_SIZE);\r\nchannel = ctx->device->dma.chan_mem2hash;\r\nctx->device->dma.sg = sg;\r\nctx->device->dma.sg_len = dma_map_sg(channel->device->dev,\r\nctx->device->dma.sg, ctx->device->dma.nents,\r\ndirection);\r\nif (!ctx->device->dma.sg_len) {\r\ndev_err(ctx->device->dev, "%s: Could not map the sg list (TO_DEVICE)\n",\r\n__func__);\r\nreturn -EFAULT;\r\n}\r\ndev_dbg(ctx->device->dev, "%s: Setting up DMA for buffer (TO_DEVICE)\n",\r\n__func__);\r\ndesc = dmaengine_prep_slave_sg(channel,\r\nctx->device->dma.sg, ctx->device->dma.sg_len,\r\ndirection, DMA_CTRL_ACK | DMA_PREP_INTERRUPT);\r\nif (!desc) {\r\ndev_err(ctx->device->dev,\r\n"%s: device_prep_slave_sg() failed!\n", __func__);\r\nreturn -EFAULT;\r\n}\r\ndesc->callback = hash_dma_callback;\r\ndesc->callback_param = ctx;\r\ncookie = dmaengine_submit(desc);\r\ndma_async_issue_pending(channel);\r\nreturn 0;\r\n}\r\nstatic void hash_dma_done(struct hash_ctx *ctx)\r\n{\r\nstruct dma_chan *chan;\r\nchan = ctx->device->dma.chan_mem2hash;\r\ndmaengine_device_control(chan, DMA_TERMINATE_ALL, 0);\r\ndma_unmap_sg(chan->device->dev, ctx->device->dma.sg,\r\nctx->device->dma.sg_len, DMA_TO_DEVICE);\r\n}\r\nstatic int hash_dma_write(struct hash_ctx *ctx,\r\nstruct scatterlist *sg, int len)\r\n{\r\nint error = hash_set_dma_transfer(ctx, sg, len, DMA_TO_DEVICE);\r\nif (error) {\r\ndev_dbg(ctx->device->dev,\r\n"%s: hash_set_dma_transfer() failed\n", __func__);\r\nreturn error;\r\n}\r\nreturn len;\r\n}\r\nstatic int get_empty_message_digest(\r\nstruct hash_device_data *device_data,\r\nu8 *zero_hash, u32 *zero_hash_size, bool *zero_digest)\r\n{\r\nint ret = 0;\r\nstruct hash_ctx *ctx = device_data->current_ctx;\r\n*zero_digest = false;\r\nif (HASH_OPER_MODE_HASH == ctx->config.oper_mode) {\r\nif (HASH_ALGO_SHA1 == ctx->config.algorithm) {\r\nmemcpy(zero_hash, &zero_message_hash_sha1[0],\r\nSHA1_DIGEST_SIZE);\r\n*zero_hash_size = SHA1_DIGEST_SIZE;\r\n*zero_digest = true;\r\n} else if (HASH_ALGO_SHA256 ==\r\nctx->config.algorithm) {\r\nmemcpy(zero_hash, &zero_message_hash_sha256[0],\r\nSHA256_DIGEST_SIZE);\r\n*zero_hash_size = SHA256_DIGEST_SIZE;\r\n*zero_digest = true;\r\n} else {\r\ndev_err(device_data->dev, "%s: Incorrect algorithm!\n",\r\n__func__);\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\n} else if (HASH_OPER_MODE_HMAC == ctx->config.oper_mode) {\r\nif (!ctx->keylen) {\r\nif (HASH_ALGO_SHA1 == ctx->config.algorithm) {\r\nmemcpy(zero_hash, &zero_message_hmac_sha1[0],\r\nSHA1_DIGEST_SIZE);\r\n*zero_hash_size = SHA1_DIGEST_SIZE;\r\n*zero_digest = true;\r\n} else if (HASH_ALGO_SHA256 == ctx->config.algorithm) {\r\nmemcpy(zero_hash, &zero_message_hmac_sha256[0],\r\nSHA256_DIGEST_SIZE);\r\n*zero_hash_size = SHA256_DIGEST_SIZE;\r\n*zero_digest = true;\r\n} else {\r\ndev_err(device_data->dev, "%s: Incorrect algorithm!\n",\r\n__func__);\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\n} else {\r\ndev_dbg(device_data->dev,\r\n"%s: Continue hash calculation, since hmac key available\n",\r\n__func__);\r\n}\r\n}\r\nout:\r\nreturn ret;\r\n}\r\nstatic int hash_disable_power(struct hash_device_data *device_data,\r\nbool save_device_state)\r\n{\r\nint ret = 0;\r\nstruct device *dev = device_data->dev;\r\nspin_lock(&device_data->power_state_lock);\r\nif (!device_data->power_state)\r\ngoto out;\r\nif (save_device_state) {\r\nhash_save_state(device_data,\r\n&device_data->state);\r\ndevice_data->restore_dev_state = true;\r\n}\r\nclk_disable(device_data->clk);\r\nret = regulator_disable(device_data->regulator);\r\nif (ret)\r\ndev_err(dev, "%s: regulator_disable() failed!\n", __func__);\r\ndevice_data->power_state = false;\r\nout:\r\nspin_unlock(&device_data->power_state_lock);\r\nreturn ret;\r\n}\r\nstatic int hash_enable_power(struct hash_device_data *device_data,\r\nbool restore_device_state)\r\n{\r\nint ret = 0;\r\nstruct device *dev = device_data->dev;\r\nspin_lock(&device_data->power_state_lock);\r\nif (!device_data->power_state) {\r\nret = regulator_enable(device_data->regulator);\r\nif (ret) {\r\ndev_err(dev, "%s: regulator_enable() failed!\n",\r\n__func__);\r\ngoto out;\r\n}\r\nret = clk_enable(device_data->clk);\r\nif (ret) {\r\ndev_err(dev, "%s: clk_enable() failed!\n", __func__);\r\nret = regulator_disable(\r\ndevice_data->regulator);\r\ngoto out;\r\n}\r\ndevice_data->power_state = true;\r\n}\r\nif (device_data->restore_dev_state) {\r\nif (restore_device_state) {\r\ndevice_data->restore_dev_state = false;\r\nhash_resume_state(device_data, &device_data->state);\r\n}\r\n}\r\nout:\r\nspin_unlock(&device_data->power_state_lock);\r\nreturn ret;\r\n}\r\nstatic int hash_get_device_data(struct hash_ctx *ctx,\r\nstruct hash_device_data **device_data)\r\n{\r\nint ret;\r\nstruct klist_iter device_iterator;\r\nstruct klist_node *device_node;\r\nstruct hash_device_data *local_device_data = NULL;\r\nret = down_interruptible(&driver_data.device_allocation);\r\nif (ret)\r\nreturn ret;\r\nklist_iter_init(&driver_data.device_list, &device_iterator);\r\ndevice_node = klist_next(&device_iterator);\r\nwhile (device_node) {\r\nlocal_device_data = container_of(device_node,\r\nstruct hash_device_data, list_node);\r\nspin_lock(&local_device_data->ctx_lock);\r\nif (local_device_data->current_ctx) {\r\ndevice_node = klist_next(&device_iterator);\r\n} else {\r\nlocal_device_data->current_ctx = ctx;\r\nctx->device = local_device_data;\r\nspin_unlock(&local_device_data->ctx_lock);\r\nbreak;\r\n}\r\nspin_unlock(&local_device_data->ctx_lock);\r\n}\r\nklist_iter_exit(&device_iterator);\r\nif (!device_node) {\r\nreturn -EBUSY;\r\n}\r\n*device_data = local_device_data;\r\nreturn 0;\r\n}\r\nstatic void hash_hw_write_key(struct hash_device_data *device_data,\r\nconst u8 *key, unsigned int keylen)\r\n{\r\nu32 word = 0;\r\nint nwords = 1;\r\nHASH_CLEAR_BITS(&device_data->base->str, HASH_STR_NBLW_MASK);\r\nwhile (keylen >= 4) {\r\nu32 *key_word = (u32 *)key;\r\nHASH_SET_DIN(key_word, nwords);\r\nkeylen -= 4;\r\nkey += 4;\r\n}\r\nif (keylen) {\r\nword = 0;\r\nwhile (keylen) {\r\nword |= (key[keylen - 1] << (8 * (keylen - 1)));\r\nkeylen--;\r\n}\r\nHASH_SET_DIN(&word, nwords);\r\n}\r\nwhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\r\ncpu_relax();\r\nHASH_SET_DCAL;\r\nwhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\r\ncpu_relax();\r\n}\r\nstatic int init_hash_hw(struct hash_device_data *device_data,\r\nstruct hash_ctx *ctx)\r\n{\r\nint ret = 0;\r\nret = hash_setconfiguration(device_data, &ctx->config);\r\nif (ret) {\r\ndev_err(device_data->dev, "%s: hash_setconfiguration() failed!\n",\r\n__func__);\r\nreturn ret;\r\n}\r\nhash_begin(device_data, ctx);\r\nif (ctx->config.oper_mode == HASH_OPER_MODE_HMAC)\r\nhash_hw_write_key(device_data, ctx->key, ctx->keylen);\r\nreturn ret;\r\n}\r\nstatic int hash_get_nents(struct scatterlist *sg, int size, bool *aligned)\r\n{\r\nint nents = 0;\r\nbool aligned_data = true;\r\nwhile (size > 0 && sg) {\r\nnents++;\r\nsize -= sg->length;\r\nif ((aligned && !IS_ALIGNED(sg->offset, HASH_DMA_ALIGN_SIZE)) ||\r\n(!IS_ALIGNED(sg->length, HASH_DMA_ALIGN_SIZE) && size > 0))\r\naligned_data = false;\r\nsg = sg_next(sg);\r\n}\r\nif (aligned)\r\n*aligned = aligned_data;\r\nif (size != 0)\r\nreturn -EFAULT;\r\nreturn nents;\r\n}\r\nstatic bool hash_dma_valid_data(struct scatterlist *sg, int datasize)\r\n{\r\nbool aligned;\r\nif (hash_get_nents(sg, datasize, &aligned) < 1)\r\nreturn false;\r\nreturn aligned;\r\n}\r\nstatic int hash_init(struct ahash_request *req)\r\n{\r\nstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\r\nstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\r\nstruct hash_req_ctx *req_ctx = ahash_request_ctx(req);\r\nif (!ctx->key)\r\nctx->keylen = 0;\r\nmemset(&req_ctx->state, 0, sizeof(struct hash_state));\r\nreq_ctx->updated = 0;\r\nif (hash_mode == HASH_MODE_DMA) {\r\nif (req->nbytes < HASH_DMA_ALIGN_SIZE) {\r\nreq_ctx->dma_mode = false;\r\npr_debug("%s: DMA mode, but direct to CPU mode for data size < %d\n",\r\n__func__, HASH_DMA_ALIGN_SIZE);\r\n} else {\r\nif (req->nbytes >= HASH_DMA_PERFORMANCE_MIN_SIZE &&\r\nhash_dma_valid_data(req->src, req->nbytes)) {\r\nreq_ctx->dma_mode = true;\r\n} else {\r\nreq_ctx->dma_mode = false;\r\npr_debug("%s: DMA mode, but use CPU mode for datalength < %d or non-aligned data, except in last nent\n",\r\n__func__,\r\nHASH_DMA_PERFORMANCE_MIN_SIZE);\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void hash_processblock(struct hash_device_data *device_data,\r\nconst u32 *message, int length)\r\n{\r\nint len = length / HASH_BYTES_PER_WORD;\r\nHASH_CLEAR_BITS(&device_data->base->str, HASH_STR_NBLW_MASK);\r\nHASH_SET_DIN(message, len);\r\n}\r\nstatic void hash_messagepad(struct hash_device_data *device_data,\r\nconst u32 *message, u8 index_bytes)\r\n{\r\nint nwords = 1;\r\nHASH_CLEAR_BITS(&device_data->base->str, HASH_STR_NBLW_MASK);\r\nwhile (index_bytes >= 4) {\r\nHASH_SET_DIN(message, nwords);\r\nindex_bytes -= 4;\r\nmessage++;\r\n}\r\nif (index_bytes)\r\nHASH_SET_DIN(message, nwords);\r\nwhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\r\ncpu_relax();\r\nHASH_SET_NBLW(index_bytes * 8);\r\ndev_dbg(device_data->dev, "%s: DIN=0x%08x NBLW=%lu\n",\r\n__func__, readl_relaxed(&device_data->base->din),\r\nreadl_relaxed(&device_data->base->str) & HASH_STR_NBLW_MASK);\r\nHASH_SET_DCAL;\r\ndev_dbg(device_data->dev, "%s: after dcal -> DIN=0x%08x NBLW=%lu\n",\r\n__func__, readl_relaxed(&device_data->base->din),\r\nreadl_relaxed(&device_data->base->str) & HASH_STR_NBLW_MASK);\r\nwhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\r\ncpu_relax();\r\n}\r\nstatic void hash_incrementlength(struct hash_req_ctx *ctx, u32 incr)\r\n{\r\nctx->state.length.low_word += incr;\r\nif (ctx->state.length.low_word < incr)\r\nctx->state.length.high_word++;\r\n}\r\nint hash_setconfiguration(struct hash_device_data *device_data,\r\nstruct hash_config *config)\r\n{\r\nint ret = 0;\r\nif (config->algorithm != HASH_ALGO_SHA1 &&\r\nconfig->algorithm != HASH_ALGO_SHA256)\r\nreturn -EPERM;\r\nHASH_SET_DATA_FORMAT(config->data_format);\r\nswitch (config->algorithm) {\r\ncase HASH_ALGO_SHA1:\r\nHASH_SET_BITS(&device_data->base->cr, HASH_CR_ALGO_MASK);\r\nbreak;\r\ncase HASH_ALGO_SHA256:\r\nHASH_CLEAR_BITS(&device_data->base->cr, HASH_CR_ALGO_MASK);\r\nbreak;\r\ndefault:\r\ndev_err(device_data->dev, "%s: Incorrect algorithm\n",\r\n__func__);\r\nreturn -EPERM;\r\n}\r\nif (HASH_OPER_MODE_HASH == config->oper_mode)\r\nHASH_CLEAR_BITS(&device_data->base->cr,\r\nHASH_CR_MODE_MASK);\r\nelse if (HASH_OPER_MODE_HMAC == config->oper_mode) {\r\nHASH_SET_BITS(&device_data->base->cr, HASH_CR_MODE_MASK);\r\nif (device_data->current_ctx->keylen > HASH_BLOCK_SIZE) {\r\ndev_dbg(device_data->dev, "%s: LKEY set\n", __func__);\r\nHASH_SET_BITS(&device_data->base->cr,\r\nHASH_CR_LKEY_MASK);\r\n} else {\r\ndev_dbg(device_data->dev, "%s: LKEY cleared\n",\r\n__func__);\r\nHASH_CLEAR_BITS(&device_data->base->cr,\r\nHASH_CR_LKEY_MASK);\r\n}\r\n} else {\r\nret = -EPERM;\r\ndev_err(device_data->dev, "%s: HASH_INVALID_PARAMETER!\n",\r\n__func__);\r\n}\r\nreturn ret;\r\n}\r\nvoid hash_begin(struct hash_device_data *device_data, struct hash_ctx *ctx)\r\n{\r\nwhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\r\ncpu_relax();\r\nHASH_INITIALIZE;\r\nHASH_CLEAR_BITS(&device_data->base->str, HASH_STR_NBLW_MASK);\r\n}\r\nstatic int hash_process_data(struct hash_device_data *device_data,\r\nstruct hash_ctx *ctx, struct hash_req_ctx *req_ctx,\r\nint msg_length, u8 *data_buffer, u8 *buffer,\r\nu8 *index)\r\n{\r\nint ret = 0;\r\nu32 count;\r\ndo {\r\nif ((*index + msg_length) < HASH_BLOCK_SIZE) {\r\nfor (count = 0; count < msg_length; count++) {\r\nbuffer[*index + count] =\r\n*(data_buffer + count);\r\n}\r\n*index += msg_length;\r\nmsg_length = 0;\r\n} else {\r\nif (req_ctx->updated) {\r\nret = hash_resume_state(device_data,\r\n&device_data->state);\r\nmemmove(req_ctx->state.buffer,\r\ndevice_data->state.buffer,\r\nHASH_BLOCK_SIZE / sizeof(u32));\r\nif (ret) {\r\ndev_err(device_data->dev,\r\n"%s: hash_resume_state() failed!\n",\r\n__func__);\r\ngoto out;\r\n}\r\n} else {\r\nret = init_hash_hw(device_data, ctx);\r\nif (ret) {\r\ndev_err(device_data->dev,\r\n"%s: init_hash_hw() failed!\n",\r\n__func__);\r\ngoto out;\r\n}\r\nreq_ctx->updated = 1;\r\n}\r\nif ((0 == (((u32)data_buffer) % 4)) &&\r\n(0 == *index))\r\nhash_processblock(device_data,\r\n(const u32 *)data_buffer,\r\nHASH_BLOCK_SIZE);\r\nelse {\r\nfor (count = 0;\r\ncount < (u32)(HASH_BLOCK_SIZE - *index);\r\ncount++) {\r\nbuffer[*index + count] =\r\n*(data_buffer + count);\r\n}\r\nhash_processblock(device_data,\r\n(const u32 *)buffer,\r\nHASH_BLOCK_SIZE);\r\n}\r\nhash_incrementlength(req_ctx, HASH_BLOCK_SIZE);\r\ndata_buffer += (HASH_BLOCK_SIZE - *index);\r\nmsg_length -= (HASH_BLOCK_SIZE - *index);\r\n*index = 0;\r\nret = hash_save_state(device_data,\r\n&device_data->state);\r\nmemmove(device_data->state.buffer,\r\nreq_ctx->state.buffer,\r\nHASH_BLOCK_SIZE / sizeof(u32));\r\nif (ret) {\r\ndev_err(device_data->dev, "%s: hash_save_state() failed!\n",\r\n__func__);\r\ngoto out;\r\n}\r\n}\r\n} while (msg_length != 0);\r\nout:\r\nreturn ret;\r\n}\r\nstatic int hash_dma_final(struct ahash_request *req)\r\n{\r\nint ret = 0;\r\nstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\r\nstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\r\nstruct hash_req_ctx *req_ctx = ahash_request_ctx(req);\r\nstruct hash_device_data *device_data;\r\nu8 digest[SHA256_DIGEST_SIZE];\r\nint bytes_written = 0;\r\nret = hash_get_device_data(ctx, &device_data);\r\nif (ret)\r\nreturn ret;\r\ndev_dbg(device_data->dev, "%s: (ctx=0x%x)!\n", __func__, (u32) ctx);\r\nif (req_ctx->updated) {\r\nret = hash_resume_state(device_data, &device_data->state);\r\nif (ret) {\r\ndev_err(device_data->dev, "%s: hash_resume_state() failed!\n",\r\n__func__);\r\ngoto out;\r\n}\r\n}\r\nif (!req_ctx->updated) {\r\nret = hash_setconfiguration(device_data, &ctx->config);\r\nif (ret) {\r\ndev_err(device_data->dev,\r\n"%s: hash_setconfiguration() failed!\n",\r\n__func__);\r\ngoto out;\r\n}\r\nif (hash_mode != HASH_MODE_DMA || !req_ctx->dma_mode) {\r\nHASH_CLEAR_BITS(&device_data->base->cr,\r\nHASH_CR_DMAE_MASK);\r\n} else {\r\nHASH_SET_BITS(&device_data->base->cr,\r\nHASH_CR_DMAE_MASK);\r\nHASH_SET_BITS(&device_data->base->cr,\r\nHASH_CR_PRIVN_MASK);\r\n}\r\nHASH_INITIALIZE;\r\nif (ctx->config.oper_mode == HASH_OPER_MODE_HMAC)\r\nhash_hw_write_key(device_data, ctx->key, ctx->keylen);\r\nHASH_SET_NBLW((req->nbytes * 8) % 32);\r\nreq_ctx->updated = 1;\r\n}\r\nctx->device->dma.nents = hash_get_nents(req->src, req->nbytes, NULL);\r\nif (!ctx->device->dma.nents) {\r\ndev_err(device_data->dev, "%s: ctx->device->dma.nents = 0\n",\r\n__func__);\r\nret = ctx->device->dma.nents;\r\ngoto out;\r\n}\r\nbytes_written = hash_dma_write(ctx, req->src, req->nbytes);\r\nif (bytes_written != req->nbytes) {\r\ndev_err(device_data->dev, "%s: hash_dma_write() failed!\n",\r\n__func__);\r\nret = bytes_written;\r\ngoto out;\r\n}\r\nwait_for_completion(&ctx->device->dma.complete);\r\nhash_dma_done(ctx);\r\nwhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\r\ncpu_relax();\r\nif (ctx->config.oper_mode == HASH_OPER_MODE_HMAC && ctx->key) {\r\nunsigned int keylen = ctx->keylen;\r\nu8 *key = ctx->key;\r\ndev_dbg(device_data->dev, "%s: keylen: %d\n",\r\n__func__, ctx->keylen);\r\nhash_hw_write_key(device_data, key, keylen);\r\n}\r\nhash_get_digest(device_data, digest, ctx->config.algorithm);\r\nmemcpy(req->result, digest, ctx->digestsize);\r\nout:\r\nrelease_hash_device(device_data);\r\nkfree(ctx->key);\r\nreturn ret;\r\n}\r\nstatic int hash_hw_final(struct ahash_request *req)\r\n{\r\nint ret = 0;\r\nstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\r\nstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\r\nstruct hash_req_ctx *req_ctx = ahash_request_ctx(req);\r\nstruct hash_device_data *device_data;\r\nu8 digest[SHA256_DIGEST_SIZE];\r\nret = hash_get_device_data(ctx, &device_data);\r\nif (ret)\r\nreturn ret;\r\ndev_dbg(device_data->dev, "%s: (ctx=0x%x)!\n", __func__, (u32) ctx);\r\nif (req_ctx->updated) {\r\nret = hash_resume_state(device_data, &device_data->state);\r\nif (ret) {\r\ndev_err(device_data->dev,\r\n"%s: hash_resume_state() failed!\n", __func__);\r\ngoto out;\r\n}\r\n} else if (req->nbytes == 0 && ctx->keylen == 0) {\r\nu8 zero_hash[SHA256_DIGEST_SIZE];\r\nu32 zero_hash_size = 0;\r\nbool zero_digest = false;\r\nret = get_empty_message_digest(device_data, &zero_hash[0],\r\n&zero_hash_size, &zero_digest);\r\nif (!ret && likely(zero_hash_size == ctx->digestsize) &&\r\nzero_digest) {\r\nmemcpy(req->result, &zero_hash[0], ctx->digestsize);\r\ngoto out;\r\n} else if (!ret && !zero_digest) {\r\ndev_dbg(device_data->dev,\r\n"%s: HMAC zero msg with key, continue...\n",\r\n__func__);\r\n} else {\r\ndev_err(device_data->dev,\r\n"%s: ret=%d, or wrong digest size? %s\n",\r\n__func__, ret,\r\nzero_hash_size == ctx->digestsize ?\r\n"true" : "false");\r\ngoto out;\r\n}\r\n} else if (req->nbytes == 0 && ctx->keylen > 0) {\r\ndev_err(device_data->dev, "%s: Empty message with keylength > 0, NOT supported\n",\r\n__func__);\r\ngoto out;\r\n}\r\nif (!req_ctx->updated) {\r\nret = init_hash_hw(device_data, ctx);\r\nif (ret) {\r\ndev_err(device_data->dev,\r\n"%s: init_hash_hw() failed!\n", __func__);\r\ngoto out;\r\n}\r\n}\r\nif (req_ctx->state.index) {\r\nhash_messagepad(device_data, req_ctx->state.buffer,\r\nreq_ctx->state.index);\r\n} else {\r\nHASH_SET_DCAL;\r\nwhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\r\ncpu_relax();\r\n}\r\nif (ctx->config.oper_mode == HASH_OPER_MODE_HMAC && ctx->key) {\r\nunsigned int keylen = ctx->keylen;\r\nu8 *key = ctx->key;\r\ndev_dbg(device_data->dev, "%s: keylen: %d\n",\r\n__func__, ctx->keylen);\r\nhash_hw_write_key(device_data, key, keylen);\r\n}\r\nhash_get_digest(device_data, digest, ctx->config.algorithm);\r\nmemcpy(req->result, digest, ctx->digestsize);\r\nout:\r\nrelease_hash_device(device_data);\r\nkfree(ctx->key);\r\nreturn ret;\r\n}\r\nint hash_hw_update(struct ahash_request *req)\r\n{\r\nint ret = 0;\r\nu8 index = 0;\r\nu8 *buffer;\r\nstruct hash_device_data *device_data;\r\nu8 *data_buffer;\r\nstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\r\nstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\r\nstruct hash_req_ctx *req_ctx = ahash_request_ctx(req);\r\nstruct crypto_hash_walk walk;\r\nint msg_length = crypto_hash_walk_first(req, &walk);\r\nif (msg_length == 0)\r\nreturn ret;\r\nindex = req_ctx->state.index;\r\nbuffer = (u8 *)req_ctx->state.buffer;\r\nif (msg_length > (req_ctx->state.length.low_word + msg_length) &&\r\nHASH_HIGH_WORD_MAX_VAL == req_ctx->state.length.high_word) {\r\npr_err("%s: HASH_MSG_LENGTH_OVERFLOW!\n", __func__);\r\nreturn -EPERM;\r\n}\r\nret = hash_get_device_data(ctx, &device_data);\r\nif (ret)\r\nreturn ret;\r\nwhile (0 != msg_length) {\r\ndata_buffer = walk.data;\r\nret = hash_process_data(device_data, ctx, req_ctx, msg_length,\r\ndata_buffer, buffer, &index);\r\nif (ret) {\r\ndev_err(device_data->dev, "%s: hash_internal_hw_update() failed!\n",\r\n__func__);\r\ngoto out;\r\n}\r\nmsg_length = crypto_hash_walk_done(&walk, 0);\r\n}\r\nreq_ctx->state.index = index;\r\ndev_dbg(device_data->dev, "%s: indata length=%d, bin=%d\n",\r\n__func__, req_ctx->state.index, req_ctx->state.bit_index);\r\nout:\r\nrelease_hash_device(device_data);\r\nreturn ret;\r\n}\r\nint hash_resume_state(struct hash_device_data *device_data,\r\nconst struct hash_state *device_state)\r\n{\r\nu32 temp_cr;\r\ns32 count;\r\nint hash_mode = HASH_OPER_MODE_HASH;\r\nif (NULL == device_state) {\r\ndev_err(device_data->dev, "%s: HASH_INVALID_PARAMETER!\n",\r\n__func__);\r\nreturn -EPERM;\r\n}\r\nif (device_state->index > HASH_BLOCK_SIZE ||\r\n(device_state->length.low_word % HASH_BLOCK_SIZE) != 0) {\r\ndev_err(device_data->dev, "%s: HASH_INVALID_PARAMETER!\n",\r\n__func__);\r\nreturn -EPERM;\r\n}\r\nHASH_INITIALIZE;\r\ntemp_cr = device_state->temp_cr;\r\nwritel_relaxed(temp_cr & HASH_CR_RESUME_MASK, &device_data->base->cr);\r\nif (readl(&device_data->base->cr) & HASH_CR_MODE_MASK)\r\nhash_mode = HASH_OPER_MODE_HMAC;\r\nelse\r\nhash_mode = HASH_OPER_MODE_HASH;\r\nfor (count = 0; count < HASH_CSR_COUNT; count++) {\r\nif ((count >= 36) && (hash_mode == HASH_OPER_MODE_HASH))\r\nbreak;\r\nwritel_relaxed(device_state->csr[count],\r\n&device_data->base->csrx[count]);\r\n}\r\nwritel_relaxed(device_state->csfull, &device_data->base->csfull);\r\nwritel_relaxed(device_state->csdatain, &device_data->base->csdatain);\r\nwritel_relaxed(device_state->str_reg, &device_data->base->str);\r\nwritel_relaxed(temp_cr, &device_data->base->cr);\r\nreturn 0;\r\n}\r\nint hash_save_state(struct hash_device_data *device_data,\r\nstruct hash_state *device_state)\r\n{\r\nu32 temp_cr;\r\nu32 count;\r\nint hash_mode = HASH_OPER_MODE_HASH;\r\nif (NULL == device_state) {\r\ndev_err(device_data->dev, "%s: HASH_INVALID_PARAMETER!\n",\r\n__func__);\r\nreturn -ENOTSUPP;\r\n}\r\nwhile (readl(&device_data->base->str) & HASH_STR_DCAL_MASK)\r\ncpu_relax();\r\ntemp_cr = readl_relaxed(&device_data->base->cr);\r\ndevice_state->str_reg = readl_relaxed(&device_data->base->str);\r\ndevice_state->din_reg = readl_relaxed(&device_data->base->din);\r\nif (readl(&device_data->base->cr) & HASH_CR_MODE_MASK)\r\nhash_mode = HASH_OPER_MODE_HMAC;\r\nelse\r\nhash_mode = HASH_OPER_MODE_HASH;\r\nfor (count = 0; count < HASH_CSR_COUNT; count++) {\r\nif ((count >= 36) && (hash_mode == HASH_OPER_MODE_HASH))\r\nbreak;\r\ndevice_state->csr[count] =\r\nreadl_relaxed(&device_data->base->csrx[count]);\r\n}\r\ndevice_state->csfull = readl_relaxed(&device_data->base->csfull);\r\ndevice_state->csdatain = readl_relaxed(&device_data->base->csdatain);\r\ndevice_state->temp_cr = temp_cr;\r\nreturn 0;\r\n}\r\nint hash_check_hw(struct hash_device_data *device_data)\r\n{\r\nif (HASH_P_ID0 == readl_relaxed(&device_data->base->periphid0) &&\r\nHASH_P_ID1 == readl_relaxed(&device_data->base->periphid1) &&\r\nHASH_P_ID2 == readl_relaxed(&device_data->base->periphid2) &&\r\nHASH_P_ID3 == readl_relaxed(&device_data->base->periphid3) &&\r\nHASH_CELL_ID0 == readl_relaxed(&device_data->base->cellid0) &&\r\nHASH_CELL_ID1 == readl_relaxed(&device_data->base->cellid1) &&\r\nHASH_CELL_ID2 == readl_relaxed(&device_data->base->cellid2) &&\r\nHASH_CELL_ID3 == readl_relaxed(&device_data->base->cellid3)) {\r\nreturn 0;\r\n}\r\ndev_err(device_data->dev, "%s: HASH_UNSUPPORTED_HW!\n", __func__);\r\nreturn -ENOTSUPP;\r\n}\r\nvoid hash_get_digest(struct hash_device_data *device_data,\r\nu8 *digest, int algorithm)\r\n{\r\nu32 temp_hx_val, count;\r\nint loop_ctr;\r\nif (algorithm != HASH_ALGO_SHA1 && algorithm != HASH_ALGO_SHA256) {\r\ndev_err(device_data->dev, "%s: Incorrect algorithm %d\n",\r\n__func__, algorithm);\r\nreturn;\r\n}\r\nif (algorithm == HASH_ALGO_SHA1)\r\nloop_ctr = SHA1_DIGEST_SIZE / sizeof(u32);\r\nelse\r\nloop_ctr = SHA256_DIGEST_SIZE / sizeof(u32);\r\ndev_dbg(device_data->dev, "%s: digest array:(0x%x)\n",\r\n__func__, (u32) digest);\r\nfor (count = 0; count < loop_ctr; count++) {\r\ntemp_hx_val = readl_relaxed(&device_data->base->hx[count]);\r\ndigest[count * 4] = (u8) ((temp_hx_val >> 24) & 0xFF);\r\ndigest[count * 4 + 1] = (u8) ((temp_hx_val >> 16) & 0xFF);\r\ndigest[count * 4 + 2] = (u8) ((temp_hx_val >> 8) & 0xFF);\r\ndigest[count * 4 + 3] = (u8) ((temp_hx_val >> 0) & 0xFF);\r\n}\r\n}\r\nstatic int ahash_update(struct ahash_request *req)\r\n{\r\nint ret = 0;\r\nstruct hash_req_ctx *req_ctx = ahash_request_ctx(req);\r\nif (hash_mode != HASH_MODE_DMA || !req_ctx->dma_mode)\r\nret = hash_hw_update(req);\r\nif (ret) {\r\npr_err("%s: hash_hw_update() failed!\n", __func__);\r\n}\r\nreturn ret;\r\n}\r\nstatic int ahash_final(struct ahash_request *req)\r\n{\r\nint ret = 0;\r\nstruct hash_req_ctx *req_ctx = ahash_request_ctx(req);\r\npr_debug("%s: data size: %d\n", __func__, req->nbytes);\r\nif ((hash_mode == HASH_MODE_DMA) && req_ctx->dma_mode)\r\nret = hash_dma_final(req);\r\nelse\r\nret = hash_hw_final(req);\r\nif (ret) {\r\npr_err("%s: hash_hw/dma_final() failed\n", __func__);\r\n}\r\nreturn ret;\r\n}\r\nstatic int hash_setkey(struct crypto_ahash *tfm,\r\nconst u8 *key, unsigned int keylen, int alg)\r\n{\r\nint ret = 0;\r\nstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\r\nctx->key = kmemdup(key, keylen, GFP_KERNEL);\r\nif (!ctx->key) {\r\npr_err("%s: Failed to allocate ctx->key for %d\n",\r\n__func__, alg);\r\nreturn -ENOMEM;\r\n}\r\nctx->keylen = keylen;\r\nreturn ret;\r\n}\r\nstatic int ahash_sha1_init(struct ahash_request *req)\r\n{\r\nstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\r\nstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\r\nctx->config.data_format = HASH_DATA_8_BITS;\r\nctx->config.algorithm = HASH_ALGO_SHA1;\r\nctx->config.oper_mode = HASH_OPER_MODE_HASH;\r\nctx->digestsize = SHA1_DIGEST_SIZE;\r\nreturn hash_init(req);\r\n}\r\nstatic int ahash_sha256_init(struct ahash_request *req)\r\n{\r\nstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\r\nstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\r\nctx->config.data_format = HASH_DATA_8_BITS;\r\nctx->config.algorithm = HASH_ALGO_SHA256;\r\nctx->config.oper_mode = HASH_OPER_MODE_HASH;\r\nctx->digestsize = SHA256_DIGEST_SIZE;\r\nreturn hash_init(req);\r\n}\r\nstatic int ahash_sha1_digest(struct ahash_request *req)\r\n{\r\nint ret2, ret1;\r\nret1 = ahash_sha1_init(req);\r\nif (ret1)\r\ngoto out;\r\nret1 = ahash_update(req);\r\nret2 = ahash_final(req);\r\nout:\r\nreturn ret1 ? ret1 : ret2;\r\n}\r\nstatic int ahash_sha256_digest(struct ahash_request *req)\r\n{\r\nint ret2, ret1;\r\nret1 = ahash_sha256_init(req);\r\nif (ret1)\r\ngoto out;\r\nret1 = ahash_update(req);\r\nret2 = ahash_final(req);\r\nout:\r\nreturn ret1 ? ret1 : ret2;\r\n}\r\nstatic int hmac_sha1_init(struct ahash_request *req)\r\n{\r\nstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\r\nstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\r\nctx->config.data_format = HASH_DATA_8_BITS;\r\nctx->config.algorithm = HASH_ALGO_SHA1;\r\nctx->config.oper_mode = HASH_OPER_MODE_HMAC;\r\nctx->digestsize = SHA1_DIGEST_SIZE;\r\nreturn hash_init(req);\r\n}\r\nstatic int hmac_sha256_init(struct ahash_request *req)\r\n{\r\nstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\r\nstruct hash_ctx *ctx = crypto_ahash_ctx(tfm);\r\nctx->config.data_format = HASH_DATA_8_BITS;\r\nctx->config.algorithm = HASH_ALGO_SHA256;\r\nctx->config.oper_mode = HASH_OPER_MODE_HMAC;\r\nctx->digestsize = SHA256_DIGEST_SIZE;\r\nreturn hash_init(req);\r\n}\r\nstatic int hmac_sha1_digest(struct ahash_request *req)\r\n{\r\nint ret2, ret1;\r\nret1 = hmac_sha1_init(req);\r\nif (ret1)\r\ngoto out;\r\nret1 = ahash_update(req);\r\nret2 = ahash_final(req);\r\nout:\r\nreturn ret1 ? ret1 : ret2;\r\n}\r\nstatic int hmac_sha256_digest(struct ahash_request *req)\r\n{\r\nint ret2, ret1;\r\nret1 = hmac_sha256_init(req);\r\nif (ret1)\r\ngoto out;\r\nret1 = ahash_update(req);\r\nret2 = ahash_final(req);\r\nout:\r\nreturn ret1 ? ret1 : ret2;\r\n}\r\nstatic int hmac_sha1_setkey(struct crypto_ahash *tfm,\r\nconst u8 *key, unsigned int keylen)\r\n{\r\nreturn hash_setkey(tfm, key, keylen, HASH_ALGO_SHA1);\r\n}\r\nstatic int hmac_sha256_setkey(struct crypto_ahash *tfm,\r\nconst u8 *key, unsigned int keylen)\r\n{\r\nreturn hash_setkey(tfm, key, keylen, HASH_ALGO_SHA256);\r\n}\r\nstatic int hash_cra_init(struct crypto_tfm *tfm)\r\n{\r\nstruct hash_ctx *ctx = crypto_tfm_ctx(tfm);\r\nstruct crypto_alg *alg = tfm->__crt_alg;\r\nstruct hash_algo_template *hash_alg;\r\nhash_alg = container_of(__crypto_ahash_alg(alg),\r\nstruct hash_algo_template,\r\nhash);\r\ncrypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),\r\nsizeof(struct hash_req_ctx));\r\nctx->config.data_format = HASH_DATA_8_BITS;\r\nctx->config.algorithm = hash_alg->conf.algorithm;\r\nctx->config.oper_mode = hash_alg->conf.oper_mode;\r\nctx->digestsize = hash_alg->hash.halg.digestsize;\r\nreturn 0;\r\n}\r\nstatic int ahash_algs_register_all(struct hash_device_data *device_data)\r\n{\r\nint ret;\r\nint i;\r\nint count;\r\nfor (i = 0; i < ARRAY_SIZE(hash_algs); i++) {\r\nret = crypto_register_ahash(&hash_algs[i].hash);\r\nif (ret) {\r\ncount = i;\r\ndev_err(device_data->dev, "%s: alg registration failed\n",\r\nhash_algs[i].hash.halg.base.cra_driver_name);\r\ngoto unreg;\r\n}\r\n}\r\nreturn 0;\r\nunreg:\r\nfor (i = 0; i < count; i++)\r\ncrypto_unregister_ahash(&hash_algs[i].hash);\r\nreturn ret;\r\n}\r\nstatic void ahash_algs_unregister_all(struct hash_device_data *device_data)\r\n{\r\nint i;\r\nfor (i = 0; i < ARRAY_SIZE(hash_algs); i++)\r\ncrypto_unregister_ahash(&hash_algs[i].hash);\r\n}\r\nstatic int ux500_hash_probe(struct platform_device *pdev)\r\n{\r\nint ret = 0;\r\nstruct resource *res = NULL;\r\nstruct hash_device_data *device_data;\r\nstruct device *dev = &pdev->dev;\r\ndevice_data = kzalloc(sizeof(*device_data), GFP_ATOMIC);\r\nif (!device_data) {\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\ndevice_data->dev = dev;\r\ndevice_data->current_ctx = NULL;\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nif (!res) {\r\ndev_dbg(dev, "%s: platform_get_resource() failed!\n", __func__);\r\nret = -ENODEV;\r\ngoto out_kfree;\r\n}\r\nres = request_mem_region(res->start, resource_size(res), pdev->name);\r\nif (res == NULL) {\r\ndev_dbg(dev, "%s: request_mem_region() failed!\n", __func__);\r\nret = -EBUSY;\r\ngoto out_kfree;\r\n}\r\ndevice_data->phybase = res->start;\r\ndevice_data->base = ioremap(res->start, resource_size(res));\r\nif (!device_data->base) {\r\ndev_err(dev, "%s: ioremap() failed!\n", __func__);\r\nret = -ENOMEM;\r\ngoto out_free_mem;\r\n}\r\nspin_lock_init(&device_data->ctx_lock);\r\nspin_lock_init(&device_data->power_state_lock);\r\ndevice_data->regulator = regulator_get(dev, "v-ape");\r\nif (IS_ERR(device_data->regulator)) {\r\ndev_err(dev, "%s: regulator_get() failed!\n", __func__);\r\nret = PTR_ERR(device_data->regulator);\r\ndevice_data->regulator = NULL;\r\ngoto out_unmap;\r\n}\r\ndevice_data->clk = clk_get(dev, NULL);\r\nif (IS_ERR(device_data->clk)) {\r\ndev_err(dev, "%s: clk_get() failed!\n", __func__);\r\nret = PTR_ERR(device_data->clk);\r\ngoto out_regulator;\r\n}\r\nret = clk_prepare(device_data->clk);\r\nif (ret) {\r\ndev_err(dev, "%s: clk_prepare() failed!\n", __func__);\r\ngoto out_clk;\r\n}\r\nret = hash_enable_power(device_data, false);\r\nif (ret) {\r\ndev_err(dev, "%s: hash_enable_power() failed!\n", __func__);\r\ngoto out_clk_unprepare;\r\n}\r\nret = hash_check_hw(device_data);\r\nif (ret) {\r\ndev_err(dev, "%s: hash_check_hw() failed!\n", __func__);\r\ngoto out_power;\r\n}\r\nif (hash_mode == HASH_MODE_DMA)\r\nhash_dma_setup_channel(device_data, dev);\r\nplatform_set_drvdata(pdev, device_data);\r\nklist_add_tail(&device_data->list_node, &driver_data.device_list);\r\nup(&driver_data.device_allocation);\r\nret = ahash_algs_register_all(device_data);\r\nif (ret) {\r\ndev_err(dev, "%s: ahash_algs_register_all() failed!\n",\r\n__func__);\r\ngoto out_power;\r\n}\r\ndev_info(dev, "successfully registered\n");\r\nreturn 0;\r\nout_power:\r\nhash_disable_power(device_data, false);\r\nout_clk_unprepare:\r\nclk_unprepare(device_data->clk);\r\nout_clk:\r\nclk_put(device_data->clk);\r\nout_regulator:\r\nregulator_put(device_data->regulator);\r\nout_unmap:\r\niounmap(device_data->base);\r\nout_free_mem:\r\nrelease_mem_region(res->start, resource_size(res));\r\nout_kfree:\r\nkfree(device_data);\r\nout:\r\nreturn ret;\r\n}\r\nstatic int ux500_hash_remove(struct platform_device *pdev)\r\n{\r\nstruct resource *res;\r\nstruct hash_device_data *device_data;\r\nstruct device *dev = &pdev->dev;\r\ndevice_data = platform_get_drvdata(pdev);\r\nif (!device_data) {\r\ndev_err(dev, "%s: platform_get_drvdata() failed!\n", __func__);\r\nreturn -ENOMEM;\r\n}\r\nif (down_trylock(&driver_data.device_allocation))\r\nreturn -EBUSY;\r\nspin_lock(&device_data->ctx_lock);\r\nif (device_data->current_ctx) {\r\nspin_unlock(&device_data->ctx_lock);\r\nup(&driver_data.device_allocation);\r\nreturn -EBUSY;\r\n}\r\nspin_unlock(&device_data->ctx_lock);\r\nif (klist_node_attached(&device_data->list_node))\r\nklist_remove(&device_data->list_node);\r\nif (list_empty(&driver_data.device_list.k_list))\r\nahash_algs_unregister_all(device_data);\r\nif (hash_disable_power(device_data, false))\r\ndev_err(dev, "%s: hash_disable_power() failed\n",\r\n__func__);\r\nclk_unprepare(device_data->clk);\r\nclk_put(device_data->clk);\r\nregulator_put(device_data->regulator);\r\niounmap(device_data->base);\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nif (res)\r\nrelease_mem_region(res->start, resource_size(res));\r\nkfree(device_data);\r\nreturn 0;\r\n}\r\nstatic void ux500_hash_shutdown(struct platform_device *pdev)\r\n{\r\nstruct resource *res = NULL;\r\nstruct hash_device_data *device_data;\r\ndevice_data = platform_get_drvdata(pdev);\r\nif (!device_data) {\r\ndev_err(&pdev->dev, "%s: platform_get_drvdata() failed!\n",\r\n__func__);\r\nreturn;\r\n}\r\nspin_lock(&device_data->ctx_lock);\r\nif (!device_data->current_ctx) {\r\nif (down_trylock(&driver_data.device_allocation))\r\ndev_dbg(&pdev->dev, "%s: Cryp still in use! Shutting down anyway...\n",\r\n__func__);\r\ndevice_data->current_ctx++;\r\n}\r\nspin_unlock(&device_data->ctx_lock);\r\nif (klist_node_attached(&device_data->list_node))\r\nklist_remove(&device_data->list_node);\r\nif (list_empty(&driver_data.device_list.k_list))\r\nahash_algs_unregister_all(device_data);\r\niounmap(device_data->base);\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nif (res)\r\nrelease_mem_region(res->start, resource_size(res));\r\nif (hash_disable_power(device_data, false))\r\ndev_err(&pdev->dev, "%s: hash_disable_power() failed\n",\r\n__func__);\r\n}\r\nstatic int ux500_hash_suspend(struct device *dev)\r\n{\r\nint ret;\r\nstruct hash_device_data *device_data;\r\nstruct hash_ctx *temp_ctx = NULL;\r\ndevice_data = dev_get_drvdata(dev);\r\nif (!device_data) {\r\ndev_err(dev, "%s: platform_get_drvdata() failed!\n", __func__);\r\nreturn -ENOMEM;\r\n}\r\nspin_lock(&device_data->ctx_lock);\r\nif (!device_data->current_ctx)\r\ndevice_data->current_ctx++;\r\nspin_unlock(&device_data->ctx_lock);\r\nif (device_data->current_ctx == ++temp_ctx) {\r\nif (down_interruptible(&driver_data.device_allocation))\r\ndev_dbg(dev, "%s: down_interruptible() failed\n",\r\n__func__);\r\nret = hash_disable_power(device_data, false);\r\n} else {\r\nret = hash_disable_power(device_data, true);\r\n}\r\nif (ret)\r\ndev_err(dev, "%s: hash_disable_power()\n", __func__);\r\nreturn ret;\r\n}\r\nstatic int ux500_hash_resume(struct device *dev)\r\n{\r\nint ret = 0;\r\nstruct hash_device_data *device_data;\r\nstruct hash_ctx *temp_ctx = NULL;\r\ndevice_data = dev_get_drvdata(dev);\r\nif (!device_data) {\r\ndev_err(dev, "%s: platform_get_drvdata() failed!\n", __func__);\r\nreturn -ENOMEM;\r\n}\r\nspin_lock(&device_data->ctx_lock);\r\nif (device_data->current_ctx == ++temp_ctx)\r\ndevice_data->current_ctx = NULL;\r\nspin_unlock(&device_data->ctx_lock);\r\nif (!device_data->current_ctx)\r\nup(&driver_data.device_allocation);\r\nelse\r\nret = hash_enable_power(device_data, true);\r\nif (ret)\r\ndev_err(dev, "%s: hash_enable_power() failed!\n", __func__);\r\nreturn ret;\r\n}\r\nstatic int __init ux500_hash_mod_init(void)\r\n{\r\nklist_init(&driver_data.device_list, NULL, NULL);\r\nsema_init(&driver_data.device_allocation, 0);\r\nreturn platform_driver_register(&hash_driver);\r\n}\r\nstatic void __exit ux500_hash_mod_fini(void)\r\n{\r\nplatform_driver_unregister(&hash_driver);\r\n}
