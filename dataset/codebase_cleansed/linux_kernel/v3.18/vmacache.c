void vmacache_flush_all(struct mm_struct *mm)\r\n{\r\nstruct task_struct *g, *p;\r\nif (atomic_read(&mm->mm_users) == 1)\r\nreturn;\r\nrcu_read_lock();\r\nfor_each_process_thread(g, p) {\r\nif (mm == p->mm)\r\nvmacache_flush(p);\r\n}\r\nrcu_read_unlock();\r\n}\r\nstatic bool vmacache_valid_mm(struct mm_struct *mm)\r\n{\r\nreturn current->mm == mm && !(current->flags & PF_KTHREAD);\r\n}\r\nvoid vmacache_update(unsigned long addr, struct vm_area_struct *newvma)\r\n{\r\nif (vmacache_valid_mm(newvma->vm_mm))\r\ncurrent->vmacache[VMACACHE_HASH(addr)] = newvma;\r\n}\r\nstatic bool vmacache_valid(struct mm_struct *mm)\r\n{\r\nstruct task_struct *curr;\r\nif (!vmacache_valid_mm(mm))\r\nreturn false;\r\ncurr = current;\r\nif (mm->vmacache_seqnum != curr->vmacache_seqnum) {\r\ncurr->vmacache_seqnum = mm->vmacache_seqnum;\r\nvmacache_flush(curr);\r\nreturn false;\r\n}\r\nreturn true;\r\n}\r\nstruct vm_area_struct *vmacache_find(struct mm_struct *mm, unsigned long addr)\r\n{\r\nint i;\r\nif (!vmacache_valid(mm))\r\nreturn NULL;\r\ncount_vm_vmacache_event(VMACACHE_FIND_CALLS);\r\nfor (i = 0; i < VMACACHE_SIZE; i++) {\r\nstruct vm_area_struct *vma = current->vmacache[i];\r\nif (!vma)\r\ncontinue;\r\nif (WARN_ON_ONCE(vma->vm_mm != mm))\r\nbreak;\r\nif (vma->vm_start <= addr && vma->vm_end > addr) {\r\ncount_vm_vmacache_event(VMACACHE_FIND_HITS);\r\nreturn vma;\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nstruct vm_area_struct *vmacache_find_exact(struct mm_struct *mm,\r\nunsigned long start,\r\nunsigned long end)\r\n{\r\nint i;\r\nif (!vmacache_valid(mm))\r\nreturn NULL;\r\ncount_vm_vmacache_event(VMACACHE_FIND_CALLS);\r\nfor (i = 0; i < VMACACHE_SIZE; i++) {\r\nstruct vm_area_struct *vma = current->vmacache[i];\r\nif (vma && vma->vm_start == start && vma->vm_end == end) {\r\ncount_vm_vmacache_event(VMACACHE_FIND_HITS);\r\nreturn vma;\r\n}\r\n}\r\nreturn NULL;\r\n}
