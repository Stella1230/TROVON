static inline u32 qib_read_ureg32(const struct qib_devdata *dd,\r\nenum qib_ureg regno, int ctxt)\r\n{\r\nif (!dd->kregbase || !(dd->flags & QIB_PRESENT))\r\nreturn 0;\r\nreturn readl(regno + (u64 __iomem *)(\r\n(dd->ureg_align * ctxt) + (dd->userbase ?\r\n(char __iomem *)dd->userbase :\r\n(char __iomem *)dd->kregbase + dd->uregbase)));\r\n}\r\nstatic inline u64 qib_read_ureg(const struct qib_devdata *dd,\r\nenum qib_ureg regno, int ctxt)\r\n{\r\nif (!dd->kregbase || !(dd->flags & QIB_PRESENT))\r\nreturn 0;\r\nreturn readq(regno + (u64 __iomem *)(\r\n(dd->ureg_align * ctxt) + (dd->userbase ?\r\n(char __iomem *)dd->userbase :\r\n(char __iomem *)dd->kregbase + dd->uregbase)));\r\n}\r\nstatic inline void qib_write_ureg(const struct qib_devdata *dd,\r\nenum qib_ureg regno, u64 value, int ctxt)\r\n{\r\nu64 __iomem *ubase;\r\nif (dd->userbase)\r\nubase = (u64 __iomem *)\r\n((char __iomem *) dd->userbase +\r\ndd->ureg_align * ctxt);\r\nelse\r\nubase = (u64 __iomem *)\r\n(dd->uregbase +\r\n(char __iomem *) dd->kregbase +\r\ndd->ureg_align * ctxt);\r\nif (dd->kregbase && (dd->flags & QIB_PRESENT))\r\nwriteq(value, &ubase[regno]);\r\n}\r\nstatic inline u32 qib_read_kreg32(const struct qib_devdata *dd,\r\nconst u32 regno)\r\n{\r\nif (!dd->kregbase || !(dd->flags & QIB_PRESENT))\r\nreturn -1;\r\nreturn readl((u32 __iomem *) &dd->kregbase[regno]);\r\n}\r\nstatic inline u64 qib_read_kreg64(const struct qib_devdata *dd,\r\nconst u32 regno)\r\n{\r\nif (!dd->kregbase || !(dd->flags & QIB_PRESENT))\r\nreturn -1;\r\nreturn readq(&dd->kregbase[regno]);\r\n}\r\nstatic inline void qib_write_kreg(const struct qib_devdata *dd,\r\nconst u32 regno, u64 value)\r\n{\r\nif (dd->kregbase && (dd->flags & QIB_PRESENT))\r\nwriteq(value, &dd->kregbase[regno]);\r\n}\r\nstatic inline u64 qib_read_kreg_port(const struct qib_pportdata *ppd,\r\nconst u16 regno)\r\n{\r\nif (!ppd->cpspec->kpregbase || !(ppd->dd->flags & QIB_PRESENT))\r\nreturn 0ULL;\r\nreturn readq(&ppd->cpspec->kpregbase[regno]);\r\n}\r\nstatic inline void qib_write_kreg_port(const struct qib_pportdata *ppd,\r\nconst u16 regno, u64 value)\r\n{\r\nif (ppd->cpspec && ppd->dd && ppd->cpspec->kpregbase &&\r\n(ppd->dd->flags & QIB_PRESENT))\r\nwriteq(value, &ppd->cpspec->kpregbase[regno]);\r\n}\r\nstatic inline void qib_write_kreg_ctxt(const struct qib_devdata *dd,\r\nconst u16 regno, unsigned ctxt,\r\nu64 value)\r\n{\r\nqib_write_kreg(dd, regno + ctxt, value);\r\n}\r\nstatic inline u64 read_7322_creg(const struct qib_devdata *dd, u16 regno)\r\n{\r\nif (!dd->cspec->cregbase || !(dd->flags & QIB_PRESENT))\r\nreturn 0;\r\nreturn readq(&dd->cspec->cregbase[regno]);\r\n}\r\nstatic inline u32 read_7322_creg32(const struct qib_devdata *dd, u16 regno)\r\n{\r\nif (!dd->cspec->cregbase || !(dd->flags & QIB_PRESENT))\r\nreturn 0;\r\nreturn readl(&dd->cspec->cregbase[regno]);\r\n}\r\nstatic inline void write_7322_creg_port(const struct qib_pportdata *ppd,\r\nu16 regno, u64 value)\r\n{\r\nif (ppd->cpspec && ppd->cpspec->cpregbase &&\r\n(ppd->dd->flags & QIB_PRESENT))\r\nwriteq(value, &ppd->cpspec->cpregbase[regno]);\r\n}\r\nstatic inline u64 read_7322_creg_port(const struct qib_pportdata *ppd,\r\nu16 regno)\r\n{\r\nif (!ppd->cpspec || !ppd->cpspec->cpregbase ||\r\n!(ppd->dd->flags & QIB_PRESENT))\r\nreturn 0;\r\nreturn readq(&ppd->cpspec->cpregbase[regno]);\r\n}\r\nstatic inline u32 read_7322_creg32_port(const struct qib_pportdata *ppd,\r\nu16 regno)\r\n{\r\nif (!ppd->cpspec || !ppd->cpspec->cpregbase ||\r\n!(ppd->dd->flags & QIB_PRESENT))\r\nreturn 0;\r\nreturn readl(&ppd->cpspec->cpregbase[regno]);\r\n}\r\nstatic void qib_disarm_7322_senderrbufs(struct qib_pportdata *ppd)\r\n{\r\nstruct qib_devdata *dd = ppd->dd;\r\nu32 i;\r\nint any;\r\nu32 piobcnt = dd->piobcnt2k + dd->piobcnt4k + NUM_VL15_BUFS;\r\nu32 regcnt = (piobcnt + BITS_PER_LONG - 1) / BITS_PER_LONG;\r\nunsigned long sbuf[4];\r\nany = 0;\r\nfor (i = 0; i < regcnt; ++i) {\r\nsbuf[i] = qib_read_kreg64(dd, kr_sendbuffererror + i);\r\nif (sbuf[i]) {\r\nany = 1;\r\nqib_write_kreg(dd, kr_sendbuffererror + i, sbuf[i]);\r\n}\r\n}\r\nif (any)\r\nqib_disarm_piobufs_set(dd, sbuf, piobcnt);\r\n}\r\nstatic void err_decode(char *msg, size_t len, u64 errs,\r\nconst struct qib_hwerror_msgs *msp)\r\n{\r\nu64 these, lmask;\r\nint took, multi, n = 0;\r\nwhile (errs && msp && msp->mask) {\r\nmulti = (msp->mask & (msp->mask - 1));\r\nwhile (errs & msp->mask) {\r\nthese = (errs & msp->mask);\r\nlmask = (these & (these - 1)) ^ these;\r\nif (len) {\r\nif (n++) {\r\n*msg++ = ',';\r\nlen--;\r\n}\r\nBUG_ON(!msp->sz);\r\ntook = min_t(size_t, msp->sz - (size_t)1, len);\r\nmemcpy(msg, msp->msg, took);\r\nlen -= took;\r\nmsg += took;\r\nif (len)\r\n*msg = '\0';\r\n}\r\nerrs &= ~lmask;\r\nif (len && multi) {\r\nint idx = -1;\r\nwhile (lmask & msp->mask) {\r\n++idx;\r\nlmask >>= 1;\r\n}\r\ntook = scnprintf(msg, len, "_%d", idx);\r\nlen -= took;\r\nmsg += took;\r\n}\r\n}\r\n++msp;\r\n}\r\nif (len && errs)\r\nsnprintf(msg, len, "%sMORE:%llX", n ? "," : "",\r\n(unsigned long long) errs);\r\n}\r\nstatic void flush_fifo(struct qib_pportdata *ppd)\r\n{\r\nstruct qib_devdata *dd = ppd->dd;\r\nu32 __iomem *piobuf;\r\nu32 bufn;\r\nu32 *hdr;\r\nu64 pbc;\r\nconst unsigned hdrwords = 7;\r\nstatic struct qib_ib_header ibhdr = {\r\n.lrh[0] = cpu_to_be16(0xF000 | QIB_LRH_BTH),\r\n.lrh[1] = IB_LID_PERMISSIVE,\r\n.lrh[2] = cpu_to_be16(hdrwords + SIZE_OF_CRC),\r\n.lrh[3] = IB_LID_PERMISSIVE,\r\n.u.oth.bth[0] = cpu_to_be32(\r\n(IB_OPCODE_UD_SEND_ONLY << 24) | QIB_DEFAULT_P_KEY),\r\n.u.oth.bth[1] = cpu_to_be32(0),\r\n.u.oth.bth[2] = cpu_to_be32(0),\r\n.u.oth.u.ud.deth[0] = cpu_to_be32(0),\r\n.u.oth.u.ud.deth[1] = cpu_to_be32(0),\r\n};\r\npbc = PBC_7322_VL15_SEND |\r\n(((u64)ppd->hw_pidx) << (PBC_PORT_SEL_LSB + 32)) |\r\n(hdrwords + SIZE_OF_CRC);\r\npiobuf = qib_7322_getsendbuf(ppd, pbc, &bufn);\r\nif (!piobuf)\r\nreturn;\r\nwriteq(pbc, piobuf);\r\nhdr = (u32 *) &ibhdr;\r\nif (dd->flags & QIB_PIO_FLUSH_WC) {\r\nqib_flush_wc();\r\nqib_pio_copy(piobuf + 2, hdr, hdrwords - 1);\r\nqib_flush_wc();\r\n__raw_writel(hdr[hdrwords - 1], piobuf + hdrwords + 1);\r\nqib_flush_wc();\r\n} else\r\nqib_pio_copy(piobuf + 2, hdr, hdrwords);\r\nqib_sendbuf_done(dd, bufn);\r\n}\r\nstatic void qib_7322_sdma_sendctrl(struct qib_pportdata *ppd, unsigned op)\r\n{\r\nstruct qib_devdata *dd = ppd->dd;\r\nu64 set_sendctrl = 0;\r\nu64 clr_sendctrl = 0;\r\nif (op & QIB_SDMA_SENDCTRL_OP_ENABLE)\r\nset_sendctrl |= SYM_MASK(SendCtrl_0, SDmaEnable);\r\nelse\r\nclr_sendctrl |= SYM_MASK(SendCtrl_0, SDmaEnable);\r\nif (op & QIB_SDMA_SENDCTRL_OP_INTENABLE)\r\nset_sendctrl |= SYM_MASK(SendCtrl_0, SDmaIntEnable);\r\nelse\r\nclr_sendctrl |= SYM_MASK(SendCtrl_0, SDmaIntEnable);\r\nif (op & QIB_SDMA_SENDCTRL_OP_HALT)\r\nset_sendctrl |= SYM_MASK(SendCtrl_0, SDmaHalt);\r\nelse\r\nclr_sendctrl |= SYM_MASK(SendCtrl_0, SDmaHalt);\r\nif (op & QIB_SDMA_SENDCTRL_OP_DRAIN)\r\nset_sendctrl |= SYM_MASK(SendCtrl_0, TxeBypassIbc) |\r\nSYM_MASK(SendCtrl_0, TxeAbortIbc) |\r\nSYM_MASK(SendCtrl_0, TxeDrainRmFifo);\r\nelse\r\nclr_sendctrl |= SYM_MASK(SendCtrl_0, TxeBypassIbc) |\r\nSYM_MASK(SendCtrl_0, TxeAbortIbc) |\r\nSYM_MASK(SendCtrl_0, TxeDrainRmFifo);\r\nspin_lock(&dd->sendctrl_lock);\r\nif (op & QIB_SDMA_SENDCTRL_OP_DRAIN) {\r\nppd->p_sendctrl &= ~SYM_MASK(SendCtrl_0, SendEnable);\r\nqib_write_kreg_port(ppd, krp_sendctrl, ppd->p_sendctrl);\r\nqib_write_kreg(dd, kr_scratch, 0);\r\n}\r\nppd->p_sendctrl |= set_sendctrl;\r\nppd->p_sendctrl &= ~clr_sendctrl;\r\nif (op & QIB_SDMA_SENDCTRL_OP_CLEANUP)\r\nqib_write_kreg_port(ppd, krp_sendctrl,\r\nppd->p_sendctrl |\r\nSYM_MASK(SendCtrl_0, SDmaCleanup));\r\nelse\r\nqib_write_kreg_port(ppd, krp_sendctrl, ppd->p_sendctrl);\r\nqib_write_kreg(dd, kr_scratch, 0);\r\nif (op & QIB_SDMA_SENDCTRL_OP_DRAIN) {\r\nppd->p_sendctrl |= SYM_MASK(SendCtrl_0, SendEnable);\r\nqib_write_kreg_port(ppd, krp_sendctrl, ppd->p_sendctrl);\r\nqib_write_kreg(dd, kr_scratch, 0);\r\n}\r\nspin_unlock(&dd->sendctrl_lock);\r\nif ((op & QIB_SDMA_SENDCTRL_OP_DRAIN) && ppd->dd->cspec->r1)\r\nflush_fifo(ppd);\r\n}\r\nstatic void qib_7322_sdma_hw_clean_up(struct qib_pportdata *ppd)\r\n{\r\n__qib_sdma_process_event(ppd, qib_sdma_event_e50_hw_cleaned);\r\n}\r\nstatic void qib_sdma_7322_setlengen(struct qib_pportdata *ppd)\r\n{\r\nqib_write_kreg_port(ppd, krp_senddmalengen, ppd->sdma_descq_cnt);\r\nqib_write_kreg_port(ppd, krp_senddmalengen,\r\nppd->sdma_descq_cnt |\r\n(1ULL << QIB_7322_SendDmaLenGen_0_Generation_MSB));\r\n}\r\nstatic void qib_sdma_update_7322_tail(struct qib_pportdata *ppd, u16 tail)\r\n{\r\nwmb();\r\nppd->sdma_descq_tail = tail;\r\nqib_write_kreg_port(ppd, krp_senddmatail, tail);\r\n}\r\nstatic void qib_7322_sdma_hw_start_up(struct qib_pportdata *ppd)\r\n{\r\nsendctrl_7322_mod(ppd, QIB_SENDCTRL_FLUSH);\r\nqib_sdma_7322_setlengen(ppd);\r\nqib_sdma_update_7322_tail(ppd, 0);\r\nppd->sdma_head_dma[0] = 0;\r\nqib_7322_sdma_sendctrl(ppd,\r\nppd->sdma_state.current_op | QIB_SDMA_SENDCTRL_OP_CLEANUP);\r\n}\r\nstatic void sdma_7322_p_errors(struct qib_pportdata *ppd, u64 errs)\r\n{\r\nunsigned long flags;\r\nstruct qib_devdata *dd = ppd->dd;\r\nerrs &= QIB_E_P_SDMAERRS;\r\nerr_decode(ppd->cpspec->sdmamsgbuf, sizeof(ppd->cpspec->sdmamsgbuf),\r\nerrs, qib_7322p_error_msgs);\r\nif (errs & QIB_E_P_SDMAUNEXPDATA)\r\nqib_dev_err(dd, "IB%u:%u SDmaUnexpData\n", dd->unit,\r\nppd->port);\r\nspin_lock_irqsave(&ppd->sdma_lock, flags);\r\nif (errs != QIB_E_P_SDMAHALT) {\r\nqib_dev_porterr(dd, ppd->port,\r\n"SDMA %s 0x%016llx %s\n",\r\nqib_sdma_state_names[ppd->sdma_state.current_state],\r\nerrs, ppd->cpspec->sdmamsgbuf);\r\ndump_sdma_7322_state(ppd);\r\n}\r\nswitch (ppd->sdma_state.current_state) {\r\ncase qib_sdma_state_s00_hw_down:\r\nbreak;\r\ncase qib_sdma_state_s10_hw_start_up_wait:\r\nif (errs & QIB_E_P_SDMAHALT)\r\n__qib_sdma_process_event(ppd,\r\nqib_sdma_event_e20_hw_started);\r\nbreak;\r\ncase qib_sdma_state_s20_idle:\r\nbreak;\r\ncase qib_sdma_state_s30_sw_clean_up_wait:\r\nbreak;\r\ncase qib_sdma_state_s40_hw_clean_up_wait:\r\nif (errs & QIB_E_P_SDMAHALT)\r\n__qib_sdma_process_event(ppd,\r\nqib_sdma_event_e50_hw_cleaned);\r\nbreak;\r\ncase qib_sdma_state_s50_hw_halt_wait:\r\nif (errs & QIB_E_P_SDMAHALT)\r\n__qib_sdma_process_event(ppd,\r\nqib_sdma_event_e60_hw_halted);\r\nbreak;\r\ncase qib_sdma_state_s99_running:\r\n__qib_sdma_process_event(ppd, qib_sdma_event_e7322_err_halted);\r\n__qib_sdma_process_event(ppd, qib_sdma_event_e60_hw_halted);\r\nbreak;\r\n}\r\nspin_unlock_irqrestore(&ppd->sdma_lock, flags);\r\n}\r\nstatic noinline void handle_7322_errors(struct qib_devdata *dd)\r\n{\r\nchar *msg;\r\nu64 iserr = 0;\r\nu64 errs;\r\nu64 mask;\r\nint log_idx;\r\nqib_stats.sps_errints++;\r\nerrs = qib_read_kreg64(dd, kr_errstatus);\r\nif (!errs) {\r\nqib_devinfo(dd->pcidev,\r\n"device error interrupt, but no error bits set!\n");\r\ngoto done;\r\n}\r\nerrs &= dd->cspec->errormask;\r\nmsg = dd->cspec->emsgbuf;\r\nif (errs & QIB_E_HARDWARE) {\r\n*msg = '\0';\r\nqib_7322_handle_hwerrors(dd, msg, sizeof dd->cspec->emsgbuf);\r\n} else\r\nfor (log_idx = 0; log_idx < QIB_EEP_LOG_CNT; ++log_idx)\r\nif (errs & dd->eep_st_masks[log_idx].errs_to_log)\r\nqib_inc_eeprom_err(dd, log_idx, 1);\r\nif (errs & QIB_E_SPKTERRS) {\r\nqib_disarm_7322_senderrbufs(dd->pport);\r\nqib_stats.sps_txerrs++;\r\n} else if (errs & QIB_E_INVALIDADDR)\r\nqib_stats.sps_txerrs++;\r\nelse if (errs & QIB_E_ARMLAUNCH) {\r\nqib_stats.sps_txerrs++;\r\nqib_disarm_7322_senderrbufs(dd->pport);\r\n}\r\nqib_write_kreg(dd, kr_errclear, errs);\r\nmask = QIB_E_HARDWARE;\r\n*msg = '\0';\r\nerr_decode(msg, sizeof dd->cspec->emsgbuf, errs & ~mask,\r\nqib_7322error_msgs);\r\nif (errs & QIB_E_RESET) {\r\nint pidx;\r\nqib_dev_err(dd,\r\n"Got reset, requires re-init (unload and reload driver)\n");\r\ndd->flags &= ~QIB_INITTED;\r\n*dd->devstatusp |= QIB_STATUS_HWERROR;\r\nfor (pidx = 0; pidx < dd->num_pports; ++pidx)\r\nif (dd->pport[pidx].link_speed_supported)\r\n*dd->pport[pidx].statusp &= ~QIB_STATUS_IB_CONF;\r\n}\r\nif (*msg && iserr)\r\nqib_dev_err(dd, "%s error\n", msg);\r\nif (errs & (ERR_MASK(RcvEgrFullErr) | ERR_MASK(RcvHdrFullErr))) {\r\nqib_handle_urcv(dd, ~0U);\r\nif (errs & ERR_MASK(RcvEgrFullErr))\r\nqib_stats.sps_buffull++;\r\nelse\r\nqib_stats.sps_hdrfull++;\r\n}\r\ndone:\r\nreturn;\r\n}\r\nstatic void qib_error_tasklet(unsigned long data)\r\n{\r\nstruct qib_devdata *dd = (struct qib_devdata *)data;\r\nhandle_7322_errors(dd);\r\nqib_write_kreg(dd, kr_errmask, dd->cspec->errormask);\r\n}\r\nstatic void reenable_chase(unsigned long opaque)\r\n{\r\nstruct qib_pportdata *ppd = (struct qib_pportdata *)opaque;\r\nppd->cpspec->chase_timer.expires = 0;\r\nqib_set_ib_7322_lstate(ppd, QLOGIC_IB_IBCC_LINKCMD_DOWN,\r\nQLOGIC_IB_IBCC_LINKINITCMD_POLL);\r\n}\r\nstatic void disable_chase(struct qib_pportdata *ppd, unsigned long tnow,\r\nu8 ibclt)\r\n{\r\nppd->cpspec->chase_end = 0;\r\nif (!qib_chase)\r\nreturn;\r\nqib_set_ib_7322_lstate(ppd, QLOGIC_IB_IBCC_LINKCMD_DOWN,\r\nQLOGIC_IB_IBCC_LINKINITCMD_DISABLE);\r\nppd->cpspec->chase_timer.expires = jiffies + QIB_CHASE_DIS_TIME;\r\nadd_timer(&ppd->cpspec->chase_timer);\r\n}\r\nstatic void handle_serdes_issues(struct qib_pportdata *ppd, u64 ibcst)\r\n{\r\nu8 ibclt;\r\nunsigned long tnow;\r\nibclt = (u8)SYM_FIELD(ibcst, IBCStatusA_0, LinkTrainingState);\r\nswitch (ibclt) {\r\ncase IB_7322_LT_STATE_CFGRCVFCFG:\r\ncase IB_7322_LT_STATE_CFGWAITRMT:\r\ncase IB_7322_LT_STATE_TXREVLANES:\r\ncase IB_7322_LT_STATE_CFGENH:\r\ntnow = jiffies;\r\nif (ppd->cpspec->chase_end &&\r\ntime_after(tnow, ppd->cpspec->chase_end))\r\ndisable_chase(ppd, tnow, ibclt);\r\nelse if (!ppd->cpspec->chase_end)\r\nppd->cpspec->chase_end = tnow + QIB_CHASE_TIME;\r\nbreak;\r\ndefault:\r\nppd->cpspec->chase_end = 0;\r\nbreak;\r\n}\r\nif (((ibclt >= IB_7322_LT_STATE_CFGTEST &&\r\nibclt <= IB_7322_LT_STATE_CFGWAITENH) ||\r\nibclt == IB_7322_LT_STATE_LINKUP) &&\r\n(ibcst & SYM_MASK(IBCStatusA_0, LinkSpeedQDR))) {\r\nforce_h1(ppd);\r\nppd->cpspec->qdr_reforce = 1;\r\nif (!ppd->dd->cspec->r1)\r\nserdes_7322_los_enable(ppd, 0);\r\n} else if (ppd->cpspec->qdr_reforce &&\r\n(ibcst & SYM_MASK(IBCStatusA_0, LinkSpeedQDR)) &&\r\n(ibclt == IB_7322_LT_STATE_CFGENH ||\r\nibclt == IB_7322_LT_STATE_CFGIDLE ||\r\nibclt == IB_7322_LT_STATE_LINKUP))\r\nforce_h1(ppd);\r\nif ((IS_QMH(ppd->dd) || IS_QME(ppd->dd)) &&\r\nppd->link_speed_enabled == QIB_IB_QDR &&\r\n(ibclt == IB_7322_LT_STATE_CFGTEST ||\r\nibclt == IB_7322_LT_STATE_CFGENH ||\r\n(ibclt >= IB_7322_LT_STATE_POLLACTIVE &&\r\nibclt <= IB_7322_LT_STATE_SLEEPQUIET)))\r\nadj_tx_serdes(ppd);\r\nif (ibclt != IB_7322_LT_STATE_LINKUP) {\r\nu8 ltstate = qib_7322_phys_portstate(ibcst);\r\nu8 pibclt = (u8)SYM_FIELD(ppd->lastibcstat, IBCStatusA_0,\r\nLinkTrainingState);\r\nif (!ppd->dd->cspec->r1 &&\r\npibclt == IB_7322_LT_STATE_LINKUP &&\r\nltstate != IB_PHYSPORTSTATE_LINK_ERR_RECOVER &&\r\nltstate != IB_PHYSPORTSTATE_RECOVERY_RETRAIN &&\r\nltstate != IB_PHYSPORTSTATE_RECOVERY_WAITRMT &&\r\nltstate != IB_PHYSPORTSTATE_RECOVERY_IDLE)\r\nserdes_7322_los_enable(ppd, 1);\r\nif (!ppd->cpspec->qdr_dfe_on &&\r\nibclt <= IB_7322_LT_STATE_SLEEPQUIET) {\r\nppd->cpspec->qdr_dfe_on = 1;\r\nppd->cpspec->qdr_dfe_time = 0;\r\nqib_write_kreg_port(ppd, krp_static_adapt_dis(2),\r\nppd->dd->cspec->r1 ?\r\nQDR_STATIC_ADAPT_DOWN_R1 :\r\nQDR_STATIC_ADAPT_DOWN);\r\npr_info(\r\n"IB%u:%u re-enabled QDR adaptation ibclt %x\n",\r\nppd->dd->unit, ppd->port, ibclt);\r\n}\r\n}\r\n}\r\nstatic noinline void handle_7322_p_errors(struct qib_pportdata *ppd)\r\n{\r\nchar *msg;\r\nu64 ignore_this_time = 0, iserr = 0, errs, fmask;\r\nstruct qib_devdata *dd = ppd->dd;\r\nfmask = qib_read_kreg64(dd, kr_act_fmask);\r\nif (!fmask)\r\ncheck_7322_rxe_status(ppd);\r\nerrs = qib_read_kreg_port(ppd, krp_errstatus);\r\nif (!errs)\r\nqib_devinfo(dd->pcidev,\r\n"Port%d error interrupt, but no error bits set!\n",\r\nppd->port);\r\nif (!fmask)\r\nerrs &= ~QIB_E_P_IBSTATUSCHANGED;\r\nif (!errs)\r\ngoto done;\r\nmsg = ppd->cpspec->epmsgbuf;\r\n*msg = '\0';\r\nif (errs & ~QIB_E_P_BITSEXTANT) {\r\nerr_decode(msg, sizeof ppd->cpspec->epmsgbuf,\r\nerrs & ~QIB_E_P_BITSEXTANT, qib_7322p_error_msgs);\r\nif (!*msg)\r\nsnprintf(msg, sizeof ppd->cpspec->epmsgbuf,\r\n"no others");\r\nqib_dev_porterr(dd, ppd->port,\r\n"error interrupt with unknown errors 0x%016Lx set (and %s)\n",\r\n(errs & ~QIB_E_P_BITSEXTANT), msg);\r\n*msg = '\0';\r\n}\r\nif (errs & QIB_E_P_SHDR) {\r\nu64 symptom;\r\nsymptom = qib_read_kreg_port(ppd, krp_sendhdrsymptom);\r\nqib_write_kreg_port(ppd, krp_sendhdrsymptom, 0);\r\nerr_decode(msg, sizeof ppd->cpspec->epmsgbuf, symptom,\r\nhdrchk_msgs);\r\n*msg = '\0';\r\n}\r\nif (errs & QIB_E_P_SPKTERRS) {\r\nif ((errs & QIB_E_P_LINK_PKTERRS) &&\r\n!(ppd->lflags & QIBL_LINKACTIVE)) {\r\nerr_decode(msg, sizeof ppd->cpspec->epmsgbuf,\r\n(errs & QIB_E_P_LINK_PKTERRS),\r\nqib_7322p_error_msgs);\r\n*msg = '\0';\r\nignore_this_time = errs & QIB_E_P_LINK_PKTERRS;\r\n}\r\nqib_disarm_7322_senderrbufs(ppd);\r\n} else if ((errs & QIB_E_P_LINK_PKTERRS) &&\r\n!(ppd->lflags & QIBL_LINKACTIVE)) {\r\nerr_decode(msg, sizeof ppd->cpspec->epmsgbuf, errs,\r\nqib_7322p_error_msgs);\r\nignore_this_time = errs & QIB_E_P_LINK_PKTERRS;\r\n*msg = '\0';\r\n}\r\nqib_write_kreg_port(ppd, krp_errclear, errs);\r\nerrs &= ~ignore_this_time;\r\nif (!errs)\r\ngoto done;\r\nif (errs & QIB_E_P_RPKTERRS)\r\nqib_stats.sps_rcverrs++;\r\nif (errs & QIB_E_P_SPKTERRS)\r\nqib_stats.sps_txerrs++;\r\niserr = errs & ~(QIB_E_P_RPKTERRS | QIB_E_P_PKTERRS);\r\nif (errs & QIB_E_P_SDMAERRS)\r\nsdma_7322_p_errors(ppd, errs);\r\nif (errs & QIB_E_P_IBSTATUSCHANGED) {\r\nu64 ibcs;\r\nu8 ltstate;\r\nibcs = qib_read_kreg_port(ppd, krp_ibcstatus_a);\r\nltstate = qib_7322_phys_portstate(ibcs);\r\nif (!(ppd->lflags & QIBL_IB_AUTONEG_INPROG))\r\nhandle_serdes_issues(ppd, ibcs);\r\nif (!(ppd->cpspec->ibcctrl_a &\r\nSYM_MASK(IBCCtrlA_0, IBStatIntReductionEn))) {\r\nppd->cpspec->ibcctrl_a |=\r\nSYM_MASK(IBCCtrlA_0, IBStatIntReductionEn);\r\nqib_write_kreg_port(ppd, krp_ibcctrl_a,\r\nppd->cpspec->ibcctrl_a);\r\n}\r\nppd->link_width_active =\r\n(ibcs & SYM_MASK(IBCStatusA_0, LinkWidthActive)) ?\r\nIB_WIDTH_4X : IB_WIDTH_1X;\r\nppd->link_speed_active = (ibcs & SYM_MASK(IBCStatusA_0,\r\nLinkSpeedQDR)) ? QIB_IB_QDR : (ibcs &\r\nSYM_MASK(IBCStatusA_0, LinkSpeedActive)) ?\r\nQIB_IB_DDR : QIB_IB_SDR;\r\nif ((ppd->lflags & QIBL_IB_LINK_DISABLED) && ltstate !=\r\nIB_PHYSPORTSTATE_DISABLED)\r\nqib_set_ib_7322_lstate(ppd, 0,\r\nQLOGIC_IB_IBCC_LINKINITCMD_DISABLE);\r\nelse\r\nif (ltstate != IB_PHYSPORTSTATE_LINK_ERR_RECOVER &&\r\nltstate != IB_PHYSPORTSTATE_RECOVERY_RETRAIN &&\r\nltstate != IB_PHYSPORTSTATE_RECOVERY_WAITRMT &&\r\nltstate != IB_PHYSPORTSTATE_RECOVERY_IDLE)\r\nqib_handle_e_ibstatuschanged(ppd, ibcs);\r\n}\r\nif (*msg && iserr)\r\nqib_dev_porterr(dd, ppd->port, "%s error\n", msg);\r\nif (ppd->state_wanted & ppd->lflags)\r\nwake_up_interruptible(&ppd->state_wait);\r\ndone:\r\nreturn;\r\n}\r\nstatic void qib_7322_set_intr_state(struct qib_devdata *dd, u32 enable)\r\n{\r\nif (enable) {\r\nif (dd->flags & QIB_BADINTR)\r\nreturn;\r\nqib_write_kreg(dd, kr_intmask, dd->cspec->int_enable_mask);\r\nqib_write_kreg(dd, kr_intclear, 0ULL);\r\nif (dd->cspec->num_msix_entries) {\r\nu64 val = qib_read_kreg64(dd, kr_intgranted);\r\nif (val)\r\nqib_write_kreg(dd, kr_intgranted, val);\r\n}\r\n} else\r\nqib_write_kreg(dd, kr_intmask, 0ULL);\r\n}\r\nstatic void qib_7322_clear_freeze(struct qib_devdata *dd)\r\n{\r\nint pidx;\r\nqib_write_kreg(dd, kr_errmask, 0ULL);\r\nfor (pidx = 0; pidx < dd->num_pports; ++pidx)\r\nif (dd->pport[pidx].link_speed_supported)\r\nqib_write_kreg_port(dd->pport + pidx, krp_errmask,\r\n0ULL);\r\nqib_7322_set_intr_state(dd, 0);\r\nqib_write_kreg(dd, kr_control, dd->control);\r\nqib_read_kreg32(dd, kr_scratch);\r\nqib_write_kreg(dd, kr_hwerrclear, 0ULL);\r\nqib_write_kreg(dd, kr_errclear, E_SPKT_ERRS_IGNORE);\r\nqib_write_kreg(dd, kr_errmask, dd->cspec->errormask);\r\nfor (pidx = 0; pidx < dd->num_pports; ++pidx) {\r\nif (!dd->pport[pidx].link_speed_supported)\r\ncontinue;\r\nqib_write_kreg_port(dd->pport + pidx, krp_errclear, ~0Ull);\r\nqib_write_kreg_port(dd->pport + pidx, krp_errmask, ~0Ull);\r\n}\r\nqib_7322_set_intr_state(dd, 1);\r\n}\r\nstatic void qib_7322_handle_hwerrors(struct qib_devdata *dd, char *msg,\r\nsize_t msgl)\r\n{\r\nu64 hwerrs;\r\nu32 ctrl;\r\nint isfatal = 0;\r\nhwerrs = qib_read_kreg64(dd, kr_hwerrstatus);\r\nif (!hwerrs)\r\ngoto bail;\r\nif (hwerrs == ~0ULL) {\r\nqib_dev_err(dd,\r\n"Read of hardware error status failed (all bits set); ignoring\n");\r\ngoto bail;\r\n}\r\nqib_stats.sps_hwerrs++;\r\nqib_write_kreg(dd, kr_hwerrclear, hwerrs &\r\n~HWE_MASK(PowerOnBISTFailed));\r\nhwerrs &= dd->cspec->hwerrmask;\r\nif (hwerrs)\r\nqib_devinfo(dd->pcidev,\r\n"Hardware error: hwerr=0x%llx (cleared)\n",\r\n(unsigned long long) hwerrs);\r\nctrl = qib_read_kreg32(dd, kr_control);\r\nif ((ctrl & SYM_MASK(Control, FreezeMode)) && !dd->diag_client) {\r\nif ((hwerrs & ~HWE_MASK(LATriggered)) ||\r\ndd->cspec->stay_in_freeze) {\r\nif (dd->flags & QIB_INITTED)\r\nisfatal = 1;\r\n} else\r\nqib_7322_clear_freeze(dd);\r\n}\r\nif (hwerrs & HWE_MASK(PowerOnBISTFailed)) {\r\nisfatal = 1;\r\nstrlcpy(msg,\r\n"[Memory BIST test failed, InfiniPath hardware unusable]",\r\nmsgl);\r\ndd->cspec->hwerrmask &= ~HWE_MASK(PowerOnBISTFailed);\r\nqib_write_kreg(dd, kr_hwerrmask, dd->cspec->hwerrmask);\r\n}\r\nerr_decode(msg, msgl, hwerrs, qib_7322_hwerror_msgs);\r\nqib_dev_err(dd, "%s hardware error\n", msg);\r\nif (hwerrs &\r\n(SYM_MASK(HwErrMask, SDmaMemReadErrMask_0) |\r\nSYM_MASK(HwErrMask, SDmaMemReadErrMask_1))) {\r\nint pidx = 0;\r\nint err;\r\nunsigned long flags;\r\nstruct qib_pportdata *ppd = dd->pport;\r\nfor (; pidx < dd->num_pports; ++pidx, ppd++) {\r\nerr = 0;\r\nif (pidx == 0 && (hwerrs &\r\nSYM_MASK(HwErrMask, SDmaMemReadErrMask_0)))\r\nerr++;\r\nif (pidx == 1 && (hwerrs &\r\nSYM_MASK(HwErrMask, SDmaMemReadErrMask_1)))\r\nerr++;\r\nif (err) {\r\nspin_lock_irqsave(&ppd->sdma_lock, flags);\r\ndump_sdma_7322_state(ppd);\r\nspin_unlock_irqrestore(&ppd->sdma_lock, flags);\r\n}\r\n}\r\n}\r\nif (isfatal && !dd->diag_client) {\r\nqib_dev_err(dd,\r\n"Fatal Hardware Error, no longer usable, SN %.16s\n",\r\ndd->serial);\r\nif (dd->freezemsg)\r\nsnprintf(dd->freezemsg, dd->freezelen,\r\n"{%s}", msg);\r\nqib_disable_after_error(dd);\r\n}\r\nbail:;\r\n}\r\nstatic void qib_7322_init_hwerrors(struct qib_devdata *dd)\r\n{\r\nint pidx;\r\nu64 extsval;\r\nextsval = qib_read_kreg64(dd, kr_extstatus);\r\nif (!(extsval & (QIB_EXTS_MEMBIST_DISABLED |\r\nQIB_EXTS_MEMBIST_ENDTEST)))\r\nqib_dev_err(dd, "MemBIST did not complete!\n");\r\nqib_write_kreg(dd, kr_hwerrclear, ~HWE_MASK(PowerOnBISTFailed));\r\nqib_write_kreg(dd, kr_hwerrmask, dd->cspec->hwerrmask);\r\nqib_write_kreg(dd, kr_errclear, ~0ULL);\r\nqib_write_kreg(dd, kr_errmask, ~0ULL);\r\ndd->cspec->errormask = qib_read_kreg64(dd, kr_errmask);\r\nfor (pidx = 0; pidx < dd->num_pports; ++pidx)\r\nif (dd->pport[pidx].link_speed_supported)\r\nqib_write_kreg_port(dd->pport + pidx, krp_errmask,\r\n~0ULL);\r\n}\r\nstatic void qib_set_7322_armlaunch(struct qib_devdata *dd, u32 enable)\r\n{\r\nif (enable) {\r\nqib_write_kreg(dd, kr_errclear, QIB_E_SPIOARMLAUNCH);\r\ndd->cspec->errormask |= QIB_E_SPIOARMLAUNCH;\r\n} else\r\ndd->cspec->errormask &= ~QIB_E_SPIOARMLAUNCH;\r\nqib_write_kreg(dd, kr_errmask, dd->cspec->errormask);\r\n}\r\nstatic void qib_set_ib_7322_lstate(struct qib_pportdata *ppd, u16 linkcmd,\r\nu16 linitcmd)\r\n{\r\nu64 mod_wd;\r\nstruct qib_devdata *dd = ppd->dd;\r\nunsigned long flags;\r\nif (linitcmd == QLOGIC_IB_IBCC_LINKINITCMD_DISABLE) {\r\nqib_7322_mini_pcs_reset(ppd);\r\nspin_lock_irqsave(&ppd->lflags_lock, flags);\r\nppd->lflags |= QIBL_IB_LINK_DISABLED;\r\nspin_unlock_irqrestore(&ppd->lflags_lock, flags);\r\n} else if (linitcmd || linkcmd == QLOGIC_IB_IBCC_LINKCMD_DOWN) {\r\nspin_lock_irqsave(&ppd->lflags_lock, flags);\r\nppd->lflags &= ~QIBL_IB_LINK_DISABLED;\r\nspin_unlock_irqrestore(&ppd->lflags_lock, flags);\r\nppd->cpspec->ibcctrl_a &=\r\n~SYM_MASK(IBCCtrlA_0, IBStatIntReductionEn);\r\n}\r\nmod_wd = (linkcmd << IBA7322_IBCC_LINKCMD_SHIFT) |\r\n(linitcmd << QLOGIC_IB_IBCC_LINKINITCMD_SHIFT);\r\nqib_write_kreg_port(ppd, krp_ibcctrl_a, ppd->cpspec->ibcctrl_a |\r\nmod_wd);\r\nqib_write_kreg(dd, kr_scratch, 0);\r\n}\r\nstatic void set_vls(struct qib_pportdata *ppd)\r\n{\r\nint i, numvls, totcred, cred_vl, vl0extra;\r\nstruct qib_devdata *dd = ppd->dd;\r\nu64 val;\r\nnumvls = qib_num_vls(ppd->vls_operational);\r\ntotcred = NUM_RCV_BUF_UNITS(dd);\r\ncred_vl = (2 * 288 + RCV_BUF_UNITSZ - 1) / RCV_BUF_UNITSZ;\r\ntotcred -= cred_vl;\r\nqib_write_kreg_port(ppd, krp_rxcreditvl15, (u64) cred_vl);\r\ncred_vl = totcred / numvls;\r\nvl0extra = totcred - cred_vl * numvls;\r\nqib_write_kreg_port(ppd, krp_rxcreditvl0, cred_vl + vl0extra);\r\nfor (i = 1; i < numvls; i++)\r\nqib_write_kreg_port(ppd, krp_rxcreditvl0 + i, cred_vl);\r\nfor (; i < 8; i++)\r\nqib_write_kreg_port(ppd, krp_rxcreditvl0 + i, 0);\r\nval = qib_read_kreg_port(ppd, krp_ibsdtestiftx);\r\nval |= SYM_MASK(IB_SDTEST_IF_TX_0, CREDIT_CHANGE);\r\nqib_write_kreg_port(ppd, krp_ibsdtestiftx, val);\r\nqib_write_kreg(dd, kr_scratch, 0ULL);\r\nval &= ~SYM_MASK(IB_SDTEST_IF_TX_0, CREDIT_CHANGE);\r\nqib_write_kreg_port(ppd, krp_ibsdtestiftx, val);\r\nfor (i = 0; i < numvls; i++)\r\nval = qib_read_kreg_port(ppd, krp_rxcreditvl0 + i);\r\nval = qib_read_kreg_port(ppd, krp_rxcreditvl15);\r\nppd->cpspec->ibcctrl_a = (ppd->cpspec->ibcctrl_a &\r\n~SYM_MASK(IBCCtrlA_0, NumVLane)) |\r\n((u64)(numvls - 1) << SYM_LSB(IBCCtrlA_0, NumVLane));\r\nqib_write_kreg_port(ppd, krp_ibcctrl_a, ppd->cpspec->ibcctrl_a);\r\nqib_write_kreg(dd, kr_scratch, 0ULL);\r\n}\r\nstatic int qib_7322_bringup_serdes(struct qib_pportdata *ppd)\r\n{\r\nstruct qib_devdata *dd = ppd->dd;\r\nu64 val, guid, ibc;\r\nunsigned long flags;\r\nint ret = 0;\r\nppd->cpspec->ibcctrl_a &= ~SYM_MASK(IBCCtrlA_0, IBLinkEn);\r\nqib_write_kreg_port(ppd, krp_ibcctrl_a, ppd->cpspec->ibcctrl_a);\r\nqib_write_kreg(dd, kr_scratch, 0ULL);\r\nqib_write_kreg_port(ppd, krp_tx_deemph_override,\r\nSYM_MASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\r\nreset_tx_deemphasis_override));\r\nif (qib_compat_ddr_negotiate) {\r\nppd->cpspec->ibdeltainprog = 1;\r\nppd->cpspec->ibsymsnap = read_7322_creg32_port(ppd,\r\ncrp_ibsymbolerr);\r\nppd->cpspec->iblnkerrsnap = read_7322_creg32_port(ppd,\r\ncrp_iblinkerrrecov);\r\n}\r\nibc = 0x5ULL << SYM_LSB(IBCCtrlA_0, FlowCtrlWaterMark);\r\nibc |= 24ULL << SYM_LSB(IBCCtrlA_0, FlowCtrlPeriod);\r\nibc |= 0xfULL << SYM_LSB(IBCCtrlA_0, PhyerrThreshold);\r\nibc |= 0xfULL << SYM_LSB(IBCCtrlA_0, OverrunThreshold);\r\nibc |= ((u64)(ppd->ibmaxlen >> 2) + 1) <<\r\nSYM_LSB(IBCCtrlA_0, MaxPktLen);\r\nppd->cpspec->ibcctrl_a = ibc;\r\nqib_7322_mini_pcs_reset(ppd);\r\nif (!ppd->cpspec->ibcctrl_b) {\r\nunsigned lse = ppd->link_speed_enabled;\r\nppd->cpspec->ibcctrl_b = qib_read_kreg_port(ppd,\r\nkrp_ibcctrl_b);\r\nppd->cpspec->ibcctrl_b &= ~(IBA7322_IBC_SPEED_QDR |\r\nIBA7322_IBC_SPEED_DDR |\r\nIBA7322_IBC_SPEED_SDR |\r\nIBA7322_IBC_WIDTH_AUTONEG |\r\nSYM_MASK(IBCCtrlB_0, IB_LANE_REV_SUPPORTED));\r\nif (lse & (lse - 1))\r\nppd->cpspec->ibcctrl_b |=\r\n(lse << IBA7322_IBC_SPEED_LSB) |\r\nIBA7322_IBC_IBTA_1_2_MASK |\r\nIBA7322_IBC_MAX_SPEED_MASK;\r\nelse\r\nppd->cpspec->ibcctrl_b |= (lse == QIB_IB_QDR) ?\r\nIBA7322_IBC_SPEED_QDR |\r\nIBA7322_IBC_IBTA_1_2_MASK :\r\n(lse == QIB_IB_DDR) ?\r\nIBA7322_IBC_SPEED_DDR :\r\nIBA7322_IBC_SPEED_SDR;\r\nif ((ppd->link_width_enabled & (IB_WIDTH_1X | IB_WIDTH_4X)) ==\r\n(IB_WIDTH_1X | IB_WIDTH_4X))\r\nppd->cpspec->ibcctrl_b |= IBA7322_IBC_WIDTH_AUTONEG;\r\nelse\r\nppd->cpspec->ibcctrl_b |=\r\nppd->link_width_enabled == IB_WIDTH_4X ?\r\nIBA7322_IBC_WIDTH_4X_ONLY :\r\nIBA7322_IBC_WIDTH_1X_ONLY;\r\nppd->cpspec->ibcctrl_b |= (IBA7322_IBC_RXPOL_MASK |\r\nIBA7322_IBC_HRTBT_MASK);\r\n}\r\nqib_write_kreg_port(ppd, krp_ibcctrl_b, ppd->cpspec->ibcctrl_b);\r\nval = qib_read_kreg_port(ppd, krp_ibcctrl_c);\r\nval &= ~SYM_MASK(IBCCtrlC_0, IB_FRONT_PORCH);\r\nval |= 0xfULL << SYM_LSB(IBCCtrlC_0, IB_FRONT_PORCH);\r\nqib_write_kreg_port(ppd, krp_ibcctrl_c, val);\r\nserdes_7322_init(ppd);\r\nguid = be64_to_cpu(ppd->guid);\r\nif (!guid) {\r\nif (dd->base_guid)\r\nguid = be64_to_cpu(dd->base_guid) + ppd->port - 1;\r\nppd->guid = cpu_to_be64(guid);\r\n}\r\nqib_write_kreg_port(ppd, krp_hrtbt_guid, guid);\r\nqib_write_kreg(dd, kr_scratch, 0);\r\nppd->cpspec->ibcctrl_a |= SYM_MASK(IBCCtrlA_0, IBLinkEn);\r\nset_vls(ppd);\r\nval = ppd->cpspec->ibcctrl_a | (QLOGIC_IB_IBCC_LINKINITCMD_DISABLE <<\r\nQLOGIC_IB_IBCC_LINKINITCMD_SHIFT);\r\nqib_write_kreg_port(ppd, krp_ibcctrl_a, val);\r\nqib_write_kreg(dd, kr_scratch, 0ULL);\r\nppd->cpspec->ibcctrl_a = val & ~SYM_MASK(IBCCtrlA_0, LinkInitCmd);\r\nspin_lock_irqsave(&dd->cspec->rcvmod_lock, flags);\r\nppd->p_rcvctrl |= SYM_MASK(RcvCtrl_0, RcvIBPortEnable);\r\nqib_write_kreg_port(ppd, krp_rcvctrl, ppd->p_rcvctrl);\r\nspin_unlock_irqrestore(&dd->cspec->rcvmod_lock, flags);\r\nval = qib_read_kreg_port(ppd, krp_errmask);\r\nqib_write_kreg_port(ppd, krp_errmask,\r\nval | ERR_MASK_N(IBStatusChanged));\r\nreturn ret;\r\n}\r\nstatic void qib_7322_mini_quiet_serdes(struct qib_pportdata *ppd)\r\n{\r\nu64 val;\r\nunsigned long flags;\r\nqib_set_ib_7322_lstate(ppd, 0, QLOGIC_IB_IBCC_LINKINITCMD_DISABLE);\r\nspin_lock_irqsave(&ppd->lflags_lock, flags);\r\nppd->lflags &= ~QIBL_IB_AUTONEG_INPROG;\r\nspin_unlock_irqrestore(&ppd->lflags_lock, flags);\r\nwake_up(&ppd->cpspec->autoneg_wait);\r\ncancel_delayed_work_sync(&ppd->cpspec->autoneg_work);\r\nif (ppd->dd->cspec->r1)\r\ncancel_delayed_work_sync(&ppd->cpspec->ipg_work);\r\nppd->cpspec->chase_end = 0;\r\nif (ppd->cpspec->chase_timer.data)\r\ndel_timer_sync(&ppd->cpspec->chase_timer);\r\nppd->cpspec->ibcctrl_a &= ~SYM_MASK(IBCCtrlA_0, IBLinkEn);\r\nqib_7322_mini_pcs_reset(ppd);\r\nif (ppd->cpspec->ibsymdelta || ppd->cpspec->iblnkerrdelta ||\r\nppd->cpspec->ibdeltainprog || ppd->cpspec->iblnkdowndelta) {\r\nstruct qib_devdata *dd = ppd->dd;\r\nu64 diagc;\r\ndiagc = qib_read_kreg64(dd, kr_hwdiagctrl);\r\nqib_write_kreg(dd, kr_hwdiagctrl,\r\ndiagc | SYM_MASK(HwDiagCtrl, CounterWrEnable));\r\nif (ppd->cpspec->ibsymdelta || ppd->cpspec->ibdeltainprog) {\r\nval = read_7322_creg32_port(ppd, crp_ibsymbolerr);\r\nif (ppd->cpspec->ibdeltainprog)\r\nval -= val - ppd->cpspec->ibsymsnap;\r\nval -= ppd->cpspec->ibsymdelta;\r\nwrite_7322_creg_port(ppd, crp_ibsymbolerr, val);\r\n}\r\nif (ppd->cpspec->iblnkerrdelta || ppd->cpspec->ibdeltainprog) {\r\nval = read_7322_creg32_port(ppd, crp_iblinkerrrecov);\r\nif (ppd->cpspec->ibdeltainprog)\r\nval -= val - ppd->cpspec->iblnkerrsnap;\r\nval -= ppd->cpspec->iblnkerrdelta;\r\nwrite_7322_creg_port(ppd, crp_iblinkerrrecov, val);\r\n}\r\nif (ppd->cpspec->iblnkdowndelta) {\r\nval = read_7322_creg32_port(ppd, crp_iblinkdown);\r\nval += ppd->cpspec->iblnkdowndelta;\r\nwrite_7322_creg_port(ppd, crp_iblinkdown, val);\r\n}\r\nqib_write_kreg(dd, kr_hwdiagctrl, diagc);\r\n}\r\n}\r\nstatic void qib_setup_7322_setextled(struct qib_pportdata *ppd, u32 on)\r\n{\r\nstruct qib_devdata *dd = ppd->dd;\r\nu64 extctl, ledblink = 0, val;\r\nunsigned long flags;\r\nint yel, grn;\r\nif (dd->diag_client)\r\nreturn;\r\nif (ppd->led_override) {\r\ngrn = (ppd->led_override & QIB_LED_PHYS);\r\nyel = (ppd->led_override & QIB_LED_LOG);\r\n} else if (on) {\r\nval = qib_read_kreg_port(ppd, krp_ibcstatus_a);\r\ngrn = qib_7322_phys_portstate(val) ==\r\nIB_PHYSPORTSTATE_LINKUP;\r\nyel = qib_7322_iblink_state(val) == IB_PORT_ACTIVE;\r\n} else {\r\ngrn = 0;\r\nyel = 0;\r\n}\r\nspin_lock_irqsave(&dd->cspec->gpio_lock, flags);\r\nextctl = dd->cspec->extctrl & (ppd->port == 1 ?\r\n~ExtLED_IB1_MASK : ~ExtLED_IB2_MASK);\r\nif (grn) {\r\nextctl |= ppd->port == 1 ? ExtLED_IB1_GRN : ExtLED_IB2_GRN;\r\nledblink = ((66600 * 1000UL / 4) << IBA7322_LEDBLINK_ON_SHIFT) |\r\n((187500 * 1000UL / 4) << IBA7322_LEDBLINK_OFF_SHIFT);\r\n}\r\nif (yel)\r\nextctl |= ppd->port == 1 ? ExtLED_IB1_YEL : ExtLED_IB2_YEL;\r\ndd->cspec->extctrl = extctl;\r\nqib_write_kreg(dd, kr_extctrl, dd->cspec->extctrl);\r\nspin_unlock_irqrestore(&dd->cspec->gpio_lock, flags);\r\nif (ledblink)\r\nqib_write_kreg_port(ppd, krp_rcvpktledcnt, ledblink);\r\n}\r\nstatic int qib_7322_notify_dca(struct qib_devdata *dd, unsigned long event)\r\n{\r\nswitch (event) {\r\ncase DCA_PROVIDER_ADD:\r\nif (dd->flags & QIB_DCA_ENABLED)\r\nbreak;\r\nif (!dca_add_requester(&dd->pcidev->dev)) {\r\nqib_devinfo(dd->pcidev, "DCA enabled\n");\r\ndd->flags |= QIB_DCA_ENABLED;\r\nqib_setup_dca(dd);\r\n}\r\nbreak;\r\ncase DCA_PROVIDER_REMOVE:\r\nif (dd->flags & QIB_DCA_ENABLED) {\r\ndca_remove_requester(&dd->pcidev->dev);\r\ndd->flags &= ~QIB_DCA_ENABLED;\r\ndd->cspec->dca_ctrl = 0;\r\nqib_write_kreg(dd, KREG_IDX(DCACtrlA),\r\ndd->cspec->dca_ctrl);\r\n}\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nstatic void qib_update_rhdrq_dca(struct qib_ctxtdata *rcd, int cpu)\r\n{\r\nstruct qib_devdata *dd = rcd->dd;\r\nstruct qib_chip_specific *cspec = dd->cspec;\r\nif (!(dd->flags & QIB_DCA_ENABLED))\r\nreturn;\r\nif (cspec->rhdr_cpu[rcd->ctxt] != cpu) {\r\nconst struct dca_reg_map *rmp;\r\ncspec->rhdr_cpu[rcd->ctxt] = cpu;\r\nrmp = &dca_rcvhdr_reg_map[rcd->ctxt];\r\ncspec->dca_rcvhdr_ctrl[rmp->shadow_inx] &= rmp->mask;\r\ncspec->dca_rcvhdr_ctrl[rmp->shadow_inx] |=\r\n(u64) dca3_get_tag(&dd->pcidev->dev, cpu) << rmp->lsb;\r\nqib_devinfo(dd->pcidev,\r\n"Ctxt %d cpu %d dca %llx\n", rcd->ctxt, cpu,\r\n(long long) cspec->dca_rcvhdr_ctrl[rmp->shadow_inx]);\r\nqib_write_kreg(dd, rmp->regno,\r\ncspec->dca_rcvhdr_ctrl[rmp->shadow_inx]);\r\ncspec->dca_ctrl |= SYM_MASK(DCACtrlA, RcvHdrqDCAEnable);\r\nqib_write_kreg(dd, KREG_IDX(DCACtrlA), cspec->dca_ctrl);\r\n}\r\n}\r\nstatic void qib_update_sdma_dca(struct qib_pportdata *ppd, int cpu)\r\n{\r\nstruct qib_devdata *dd = ppd->dd;\r\nstruct qib_chip_specific *cspec = dd->cspec;\r\nunsigned pidx = ppd->port - 1;\r\nif (!(dd->flags & QIB_DCA_ENABLED))\r\nreturn;\r\nif (cspec->sdma_cpu[pidx] != cpu) {\r\ncspec->sdma_cpu[pidx] = cpu;\r\ncspec->dca_rcvhdr_ctrl[4] &= ~(ppd->hw_pidx ?\r\nSYM_MASK(DCACtrlF, SendDma1DCAOPH) :\r\nSYM_MASK(DCACtrlF, SendDma0DCAOPH));\r\ncspec->dca_rcvhdr_ctrl[4] |=\r\n(u64) dca3_get_tag(&dd->pcidev->dev, cpu) <<\r\n(ppd->hw_pidx ?\r\nSYM_LSB(DCACtrlF, SendDma1DCAOPH) :\r\nSYM_LSB(DCACtrlF, SendDma0DCAOPH));\r\nqib_devinfo(dd->pcidev,\r\n"sdma %d cpu %d dca %llx\n", ppd->hw_pidx, cpu,\r\n(long long) cspec->dca_rcvhdr_ctrl[4]);\r\nqib_write_kreg(dd, KREG_IDX(DCACtrlF),\r\ncspec->dca_rcvhdr_ctrl[4]);\r\ncspec->dca_ctrl |= ppd->hw_pidx ?\r\nSYM_MASK(DCACtrlA, SendDMAHead1DCAEnable) :\r\nSYM_MASK(DCACtrlA, SendDMAHead0DCAEnable);\r\nqib_write_kreg(dd, KREG_IDX(DCACtrlA), cspec->dca_ctrl);\r\n}\r\n}\r\nstatic void qib_setup_dca(struct qib_devdata *dd)\r\n{\r\nstruct qib_chip_specific *cspec = dd->cspec;\r\nint i;\r\nfor (i = 0; i < ARRAY_SIZE(cspec->rhdr_cpu); i++)\r\ncspec->rhdr_cpu[i] = -1;\r\nfor (i = 0; i < ARRAY_SIZE(cspec->sdma_cpu); i++)\r\ncspec->sdma_cpu[i] = -1;\r\ncspec->dca_rcvhdr_ctrl[0] =\r\n(1ULL << SYM_LSB(DCACtrlB, RcvHdrq0DCAXfrCnt)) |\r\n(1ULL << SYM_LSB(DCACtrlB, RcvHdrq1DCAXfrCnt)) |\r\n(1ULL << SYM_LSB(DCACtrlB, RcvHdrq2DCAXfrCnt)) |\r\n(1ULL << SYM_LSB(DCACtrlB, RcvHdrq3DCAXfrCnt));\r\ncspec->dca_rcvhdr_ctrl[1] =\r\n(1ULL << SYM_LSB(DCACtrlC, RcvHdrq4DCAXfrCnt)) |\r\n(1ULL << SYM_LSB(DCACtrlC, RcvHdrq5DCAXfrCnt)) |\r\n(1ULL << SYM_LSB(DCACtrlC, RcvHdrq6DCAXfrCnt)) |\r\n(1ULL << SYM_LSB(DCACtrlC, RcvHdrq7DCAXfrCnt));\r\ncspec->dca_rcvhdr_ctrl[2] =\r\n(1ULL << SYM_LSB(DCACtrlD, RcvHdrq8DCAXfrCnt)) |\r\n(1ULL << SYM_LSB(DCACtrlD, RcvHdrq9DCAXfrCnt)) |\r\n(1ULL << SYM_LSB(DCACtrlD, RcvHdrq10DCAXfrCnt)) |\r\n(1ULL << SYM_LSB(DCACtrlD, RcvHdrq11DCAXfrCnt));\r\ncspec->dca_rcvhdr_ctrl[3] =\r\n(1ULL << SYM_LSB(DCACtrlE, RcvHdrq12DCAXfrCnt)) |\r\n(1ULL << SYM_LSB(DCACtrlE, RcvHdrq13DCAXfrCnt)) |\r\n(1ULL << SYM_LSB(DCACtrlE, RcvHdrq14DCAXfrCnt)) |\r\n(1ULL << SYM_LSB(DCACtrlE, RcvHdrq15DCAXfrCnt));\r\ncspec->dca_rcvhdr_ctrl[4] =\r\n(1ULL << SYM_LSB(DCACtrlF, RcvHdrq16DCAXfrCnt)) |\r\n(1ULL << SYM_LSB(DCACtrlF, RcvHdrq17DCAXfrCnt));\r\nfor (i = 0; i < ARRAY_SIZE(cspec->sdma_cpu); i++)\r\nqib_write_kreg(dd, KREG_IDX(DCACtrlB) + i,\r\ncspec->dca_rcvhdr_ctrl[i]);\r\nfor (i = 0; i < cspec->num_msix_entries; i++)\r\nsetup_dca_notifier(dd, &cspec->msix_entries[i]);\r\n}\r\nstatic void qib_irq_notifier_notify(struct irq_affinity_notify *notify,\r\nconst cpumask_t *mask)\r\n{\r\nstruct qib_irq_notify *n =\r\ncontainer_of(notify, struct qib_irq_notify, notify);\r\nint cpu = cpumask_first(mask);\r\nif (n->rcv) {\r\nstruct qib_ctxtdata *rcd = (struct qib_ctxtdata *)n->arg;\r\nqib_update_rhdrq_dca(rcd, cpu);\r\n} else {\r\nstruct qib_pportdata *ppd = (struct qib_pportdata *)n->arg;\r\nqib_update_sdma_dca(ppd, cpu);\r\n}\r\n}\r\nstatic void qib_irq_notifier_release(struct kref *ref)\r\n{\r\nstruct qib_irq_notify *n =\r\ncontainer_of(ref, struct qib_irq_notify, notify.kref);\r\nstruct qib_devdata *dd;\r\nif (n->rcv) {\r\nstruct qib_ctxtdata *rcd = (struct qib_ctxtdata *)n->arg;\r\ndd = rcd->dd;\r\n} else {\r\nstruct qib_pportdata *ppd = (struct qib_pportdata *)n->arg;\r\ndd = ppd->dd;\r\n}\r\nqib_devinfo(dd->pcidev,\r\n"release on HCA notify 0x%p n 0x%p\n", ref, n);\r\nkfree(n);\r\n}\r\nstatic void qib_7322_nomsix(struct qib_devdata *dd)\r\n{\r\nu64 intgranted;\r\nint n;\r\ndd->cspec->main_int_mask = ~0ULL;\r\nn = dd->cspec->num_msix_entries;\r\nif (n) {\r\nint i;\r\ndd->cspec->num_msix_entries = 0;\r\nfor (i = 0; i < n; i++) {\r\n#ifdef CONFIG_INFINIBAND_QIB_DCA\r\nreset_dca_notifier(dd, &dd->cspec->msix_entries[i]);\r\n#endif\r\nirq_set_affinity_hint(\r\ndd->cspec->msix_entries[i].msix.vector, NULL);\r\nfree_cpumask_var(dd->cspec->msix_entries[i].mask);\r\nfree_irq(dd->cspec->msix_entries[i].msix.vector,\r\ndd->cspec->msix_entries[i].arg);\r\n}\r\nqib_nomsix(dd);\r\n}\r\nintgranted = qib_read_kreg64(dd, kr_intgranted);\r\nif (intgranted)\r\nqib_write_kreg(dd, kr_intgranted, intgranted);\r\n}\r\nstatic void qib_7322_free_irq(struct qib_devdata *dd)\r\n{\r\nif (dd->cspec->irq) {\r\nfree_irq(dd->cspec->irq, dd);\r\ndd->cspec->irq = 0;\r\n}\r\nqib_7322_nomsix(dd);\r\n}\r\nstatic void qib_setup_7322_cleanup(struct qib_devdata *dd)\r\n{\r\nint i;\r\n#ifdef CONFIG_INFINIBAND_QIB_DCA\r\nif (dd->flags & QIB_DCA_ENABLED) {\r\ndca_remove_requester(&dd->pcidev->dev);\r\ndd->flags &= ~QIB_DCA_ENABLED;\r\ndd->cspec->dca_ctrl = 0;\r\nqib_write_kreg(dd, KREG_IDX(DCACtrlA), dd->cspec->dca_ctrl);\r\n}\r\n#endif\r\nqib_7322_free_irq(dd);\r\nkfree(dd->cspec->cntrs);\r\nkfree(dd->cspec->sendchkenable);\r\nkfree(dd->cspec->sendgrhchk);\r\nkfree(dd->cspec->sendibchk);\r\nkfree(dd->cspec->msix_entries);\r\nfor (i = 0; i < dd->num_pports; i++) {\r\nunsigned long flags;\r\nu32 mask = QSFP_GPIO_MOD_PRS_N |\r\n(QSFP_GPIO_MOD_PRS_N << QSFP_GPIO_PORT2_SHIFT);\r\nkfree(dd->pport[i].cpspec->portcntrs);\r\nif (dd->flags & QIB_HAS_QSFP) {\r\nspin_lock_irqsave(&dd->cspec->gpio_lock, flags);\r\ndd->cspec->gpio_mask &= ~mask;\r\nqib_write_kreg(dd, kr_gpio_mask, dd->cspec->gpio_mask);\r\nspin_unlock_irqrestore(&dd->cspec->gpio_lock, flags);\r\nqib_qsfp_deinit(&dd->pport[i].cpspec->qsfp_data);\r\n}\r\nif (dd->pport[i].ibport_data.smi_ah)\r\nib_destroy_ah(&dd->pport[i].ibport_data.smi_ah->ibah);\r\n}\r\n}\r\nstatic void sdma_7322_intr(struct qib_devdata *dd, u64 istat)\r\n{\r\nstruct qib_pportdata *ppd0 = &dd->pport[0];\r\nstruct qib_pportdata *ppd1 = &dd->pport[1];\r\nu64 intr0 = istat & (INT_MASK_P(SDma, 0) |\r\nINT_MASK_P(SDmaIdle, 0) | INT_MASK_P(SDmaProgress, 0));\r\nu64 intr1 = istat & (INT_MASK_P(SDma, 1) |\r\nINT_MASK_P(SDmaIdle, 1) | INT_MASK_P(SDmaProgress, 1));\r\nif (intr0)\r\nqib_sdma_intr(ppd0);\r\nif (intr1)\r\nqib_sdma_intr(ppd1);\r\nif (istat & INT_MASK_PM(SDmaCleanupDone, 0))\r\nqib_sdma_process_event(ppd0, qib_sdma_event_e20_hw_started);\r\nif (istat & INT_MASK_PM(SDmaCleanupDone, 1))\r\nqib_sdma_process_event(ppd1, qib_sdma_event_e20_hw_started);\r\n}\r\nstatic void qib_wantpiobuf_7322_intr(struct qib_devdata *dd, u32 needint)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&dd->sendctrl_lock, flags);\r\nif (needint)\r\ndd->sendctrl |= SYM_MASK(SendCtrl, SendIntBufAvail);\r\nelse\r\ndd->sendctrl &= ~SYM_MASK(SendCtrl, SendIntBufAvail);\r\nqib_write_kreg(dd, kr_sendctrl, dd->sendctrl);\r\nqib_write_kreg(dd, kr_scratch, 0ULL);\r\nspin_unlock_irqrestore(&dd->sendctrl_lock, flags);\r\n}\r\nstatic noinline void unknown_7322_ibits(struct qib_devdata *dd, u64 istat)\r\n{\r\nu64 kills;\r\nchar msg[128];\r\nkills = istat & ~QIB_I_BITSEXTANT;\r\nqib_dev_err(dd,\r\n"Clearing reserved interrupt(s) 0x%016llx: %s\n",\r\n(unsigned long long) kills, msg);\r\nqib_write_kreg(dd, kr_intmask, (dd->cspec->int_enable_mask & ~kills));\r\n}\r\nstatic noinline void unknown_7322_gpio_intr(struct qib_devdata *dd)\r\n{\r\nu32 gpiostatus;\r\nint handled = 0;\r\nint pidx;\r\ngpiostatus = qib_read_kreg32(dd, kr_gpio_status);\r\nqib_write_kreg(dd, kr_gpio_clear, gpiostatus);\r\nfor (pidx = 0; pidx < dd->num_pports && (dd->flags & QIB_HAS_QSFP);\r\n++pidx) {\r\nstruct qib_pportdata *ppd;\r\nstruct qib_qsfp_data *qd;\r\nu32 mask;\r\nif (!dd->pport[pidx].link_speed_supported)\r\ncontinue;\r\nmask = QSFP_GPIO_MOD_PRS_N;\r\nppd = dd->pport + pidx;\r\nmask <<= (QSFP_GPIO_PORT2_SHIFT * ppd->hw_pidx);\r\nif (gpiostatus & dd->cspec->gpio_mask & mask) {\r\nu64 pins;\r\nqd = &ppd->cpspec->qsfp_data;\r\ngpiostatus &= ~mask;\r\npins = qib_read_kreg64(dd, kr_extstatus);\r\npins >>= SYM_LSB(EXTStatus, GPIOIn);\r\nif (!(pins & mask)) {\r\n++handled;\r\nqd->t_insert = jiffies;\r\nqueue_work(ib_wq, &qd->work);\r\n}\r\n}\r\n}\r\nif (gpiostatus && !handled) {\r\nconst u32 mask = qib_read_kreg32(dd, kr_gpio_mask);\r\nu32 gpio_irq = mask & gpiostatus;\r\ndd->cspec->gpio_mask &= ~gpio_irq;\r\nqib_write_kreg(dd, kr_gpio_mask, dd->cspec->gpio_mask);\r\n}\r\n}\r\nstatic noinline void unlikely_7322_intr(struct qib_devdata *dd, u64 istat)\r\n{\r\nif (istat & ~QIB_I_BITSEXTANT)\r\nunknown_7322_ibits(dd, istat);\r\nif (istat & QIB_I_GPIO)\r\nunknown_7322_gpio_intr(dd);\r\nif (istat & QIB_I_C_ERROR) {\r\nqib_write_kreg(dd, kr_errmask, 0ULL);\r\ntasklet_schedule(&dd->error_tasklet);\r\n}\r\nif (istat & INT_MASK_P(Err, 0) && dd->rcd[0])\r\nhandle_7322_p_errors(dd->rcd[0]->ppd);\r\nif (istat & INT_MASK_P(Err, 1) && dd->rcd[1])\r\nhandle_7322_p_errors(dd->rcd[1]->ppd);\r\n}\r\nstatic void adjust_rcv_timeout(struct qib_ctxtdata *rcd, int npkts)\r\n{\r\nstruct qib_devdata *dd = rcd->dd;\r\nu32 timeout = dd->cspec->rcvavail_timeout[rcd->ctxt];\r\nif (npkts < rcv_int_count && timeout > 2)\r\ntimeout >>= 1;\r\nelse if (npkts >= rcv_int_count && timeout < rcv_int_timeout)\r\ntimeout = min(timeout << 1, rcv_int_timeout);\r\nelse\r\nreturn;\r\ndd->cspec->rcvavail_timeout[rcd->ctxt] = timeout;\r\nqib_write_kreg(dd, kr_rcvavailtimeout + rcd->ctxt, timeout);\r\n}\r\nstatic irqreturn_t qib_7322intr(int irq, void *data)\r\n{\r\nstruct qib_devdata *dd = data;\r\nirqreturn_t ret;\r\nu64 istat;\r\nu64 ctxtrbits;\r\nu64 rmask;\r\nunsigned i;\r\nu32 npkts;\r\nif ((dd->flags & (QIB_PRESENT | QIB_BADINTR)) != QIB_PRESENT) {\r\nret = IRQ_HANDLED;\r\ngoto bail;\r\n}\r\nistat = qib_read_kreg64(dd, kr_intstatus);\r\nif (unlikely(istat == ~0ULL)) {\r\nqib_bad_intrstatus(dd);\r\nqib_dev_err(dd, "Interrupt status all f's, skipping\n");\r\nret = IRQ_NONE;\r\ngoto bail;\r\n}\r\nistat &= dd->cspec->main_int_mask;\r\nif (unlikely(!istat)) {\r\nret = IRQ_NONE;\r\ngoto bail;\r\n}\r\nthis_cpu_inc(*dd->int_counter);\r\nif (unlikely(istat & (~QIB_I_BITSEXTANT | QIB_I_GPIO |\r\nQIB_I_C_ERROR | INT_MASK_P(Err, 0) |\r\nINT_MASK_P(Err, 1))))\r\nunlikely_7322_intr(dd, istat);\r\nqib_write_kreg(dd, kr_intclear, istat);\r\nctxtrbits = istat & (QIB_I_RCVAVAIL_MASK | QIB_I_RCVURG_MASK);\r\nif (ctxtrbits) {\r\nrmask = (1ULL << QIB_I_RCVAVAIL_LSB) |\r\n(1ULL << QIB_I_RCVURG_LSB);\r\nfor (i = 0; i < dd->first_user_ctxt; i++) {\r\nif (ctxtrbits & rmask) {\r\nctxtrbits &= ~rmask;\r\nif (dd->rcd[i])\r\nqib_kreceive(dd->rcd[i], NULL, &npkts);\r\n}\r\nrmask <<= 1;\r\n}\r\nif (ctxtrbits) {\r\nctxtrbits = (ctxtrbits >> QIB_I_RCVAVAIL_LSB) |\r\n(ctxtrbits >> QIB_I_RCVURG_LSB);\r\nqib_handle_urcv(dd, ctxtrbits);\r\n}\r\n}\r\nif (istat & (QIB_I_P_SDMAINT(0) | QIB_I_P_SDMAINT(1)))\r\nsdma_7322_intr(dd, istat);\r\nif ((istat & QIB_I_SPIOBUFAVAIL) && (dd->flags & QIB_INITTED))\r\nqib_ib_piobufavail(dd);\r\nret = IRQ_HANDLED;\r\nbail:\r\nreturn ret;\r\n}\r\nstatic irqreturn_t qib_7322pintr(int irq, void *data)\r\n{\r\nstruct qib_ctxtdata *rcd = data;\r\nstruct qib_devdata *dd = rcd->dd;\r\nu32 npkts;\r\nif ((dd->flags & (QIB_PRESENT | QIB_BADINTR)) != QIB_PRESENT)\r\nreturn IRQ_HANDLED;\r\nthis_cpu_inc(*dd->int_counter);\r\nqib_write_kreg(dd, kr_intclear, ((1ULL << QIB_I_RCVAVAIL_LSB) |\r\n(1ULL << QIB_I_RCVURG_LSB)) << rcd->ctxt);\r\nqib_kreceive(rcd, NULL, &npkts);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t qib_7322bufavail(int irq, void *data)\r\n{\r\nstruct qib_devdata *dd = data;\r\nif ((dd->flags & (QIB_PRESENT | QIB_BADINTR)) != QIB_PRESENT)\r\nreturn IRQ_HANDLED;\r\nthis_cpu_inc(*dd->int_counter);\r\nqib_write_kreg(dd, kr_intclear, QIB_I_SPIOBUFAVAIL);\r\nif (dd->flags & QIB_INITTED)\r\nqib_ib_piobufavail(dd);\r\nelse\r\nqib_wantpiobuf_7322_intr(dd, 0);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t sdma_intr(int irq, void *data)\r\n{\r\nstruct qib_pportdata *ppd = data;\r\nstruct qib_devdata *dd = ppd->dd;\r\nif ((dd->flags & (QIB_PRESENT | QIB_BADINTR)) != QIB_PRESENT)\r\nreturn IRQ_HANDLED;\r\nthis_cpu_inc(*dd->int_counter);\r\nqib_write_kreg(dd, kr_intclear, ppd->hw_pidx ?\r\nINT_MASK_P(SDma, 1) : INT_MASK_P(SDma, 0));\r\nqib_sdma_intr(ppd);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t sdma_idle_intr(int irq, void *data)\r\n{\r\nstruct qib_pportdata *ppd = data;\r\nstruct qib_devdata *dd = ppd->dd;\r\nif ((dd->flags & (QIB_PRESENT | QIB_BADINTR)) != QIB_PRESENT)\r\nreturn IRQ_HANDLED;\r\nthis_cpu_inc(*dd->int_counter);\r\nqib_write_kreg(dd, kr_intclear, ppd->hw_pidx ?\r\nINT_MASK_P(SDmaIdle, 1) : INT_MASK_P(SDmaIdle, 0));\r\nqib_sdma_intr(ppd);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t sdma_progress_intr(int irq, void *data)\r\n{\r\nstruct qib_pportdata *ppd = data;\r\nstruct qib_devdata *dd = ppd->dd;\r\nif ((dd->flags & (QIB_PRESENT | QIB_BADINTR)) != QIB_PRESENT)\r\nreturn IRQ_HANDLED;\r\nthis_cpu_inc(*dd->int_counter);\r\nqib_write_kreg(dd, kr_intclear, ppd->hw_pidx ?\r\nINT_MASK_P(SDmaProgress, 1) :\r\nINT_MASK_P(SDmaProgress, 0));\r\nqib_sdma_intr(ppd);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t sdma_cleanup_intr(int irq, void *data)\r\n{\r\nstruct qib_pportdata *ppd = data;\r\nstruct qib_devdata *dd = ppd->dd;\r\nif ((dd->flags & (QIB_PRESENT | QIB_BADINTR)) != QIB_PRESENT)\r\nreturn IRQ_HANDLED;\r\nthis_cpu_inc(*dd->int_counter);\r\nqib_write_kreg(dd, kr_intclear, ppd->hw_pidx ?\r\nINT_MASK_PM(SDmaCleanupDone, 1) :\r\nINT_MASK_PM(SDmaCleanupDone, 0));\r\nqib_sdma_process_event(ppd, qib_sdma_event_e20_hw_started);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void reset_dca_notifier(struct qib_devdata *dd, struct qib_msix_entry *m)\r\n{\r\nif (!m->dca)\r\nreturn;\r\nqib_devinfo(dd->pcidev,\r\n"Disabling notifier on HCA %d irq %d\n",\r\ndd->unit,\r\nm->msix.vector);\r\nirq_set_affinity_notifier(\r\nm->msix.vector,\r\nNULL);\r\nm->notifier = NULL;\r\n}\r\nstatic void setup_dca_notifier(struct qib_devdata *dd, struct qib_msix_entry *m)\r\n{\r\nstruct qib_irq_notify *n;\r\nif (!m->dca)\r\nreturn;\r\nn = kzalloc(sizeof(*n), GFP_KERNEL);\r\nif (n) {\r\nint ret;\r\nm->notifier = n;\r\nn->notify.irq = m->msix.vector;\r\nn->notify.notify = qib_irq_notifier_notify;\r\nn->notify.release = qib_irq_notifier_release;\r\nn->arg = m->arg;\r\nn->rcv = m->rcv;\r\nqib_devinfo(dd->pcidev,\r\n"set notifier irq %d rcv %d notify %p\n",\r\nn->notify.irq, n->rcv, &n->notify);\r\nret = irq_set_affinity_notifier(\r\nn->notify.irq,\r\n&n->notify);\r\nif (ret) {\r\nm->notifier = NULL;\r\nkfree(n);\r\n}\r\n}\r\n}\r\nstatic void qib_setup_7322_interrupt(struct qib_devdata *dd, int clearpend)\r\n{\r\nint ret, i, msixnum;\r\nu64 redirect[6];\r\nu64 mask;\r\nconst struct cpumask *local_mask;\r\nint firstcpu, secondcpu = 0, currrcvcpu = 0;\r\nif (!dd->num_pports)\r\nreturn;\r\nif (clearpend) {\r\nqib_7322_set_intr_state(dd, 0);\r\nqib_7322_init_hwerrors(dd);\r\nqib_write_kreg(dd, kr_intclear, ~0ULL);\r\nqib_write_kreg(dd, kr_intgranted, ~0ULL);\r\nqib_write_kreg(dd, kr_vecclr_wo_int, ~0ULL);\r\n}\r\nif (!dd->cspec->num_msix_entries) {\r\ntry_intx:\r\nif (!dd->pcidev->irq) {\r\nqib_dev_err(dd,\r\n"irq is 0, BIOS error? Interrupts won't work\n");\r\ngoto bail;\r\n}\r\nret = request_irq(dd->pcidev->irq, qib_7322intr,\r\nIRQF_SHARED, QIB_DRV_NAME, dd);\r\nif (ret) {\r\nqib_dev_err(dd,\r\n"Couldn't setup INTx interrupt (irq=%d): %d\n",\r\ndd->pcidev->irq, ret);\r\ngoto bail;\r\n}\r\ndd->cspec->irq = dd->pcidev->irq;\r\ndd->cspec->main_int_mask = ~0ULL;\r\ngoto bail;\r\n}\r\nmemset(redirect, 0, sizeof redirect);\r\nmask = ~0ULL;\r\nmsixnum = 0;\r\nlocal_mask = cpumask_of_pcibus(dd->pcidev->bus);\r\nfirstcpu = cpumask_first(local_mask);\r\nif (firstcpu >= nr_cpu_ids ||\r\ncpumask_weight(local_mask) == num_online_cpus()) {\r\nlocal_mask = topology_core_cpumask(0);\r\nfirstcpu = cpumask_first(local_mask);\r\n}\r\nif (firstcpu < nr_cpu_ids) {\r\nsecondcpu = cpumask_next(firstcpu, local_mask);\r\nif (secondcpu >= nr_cpu_ids)\r\nsecondcpu = firstcpu;\r\ncurrrcvcpu = secondcpu;\r\n}\r\nfor (i = 0; msixnum < dd->cspec->num_msix_entries; i++) {\r\nirq_handler_t handler;\r\nvoid *arg;\r\nu64 val;\r\nint lsb, reg, sh;\r\n#ifdef CONFIG_INFINIBAND_QIB_DCA\r\nint dca = 0;\r\n#endif\r\ndd->cspec->msix_entries[msixnum].\r\nname[sizeof(dd->cspec->msix_entries[msixnum].name) - 1]\r\n= '\0';\r\nif (i < ARRAY_SIZE(irq_table)) {\r\nif (irq_table[i].port) {\r\nif (irq_table[i].port > dd->num_pports)\r\ncontinue;\r\narg = dd->pport + irq_table[i].port - 1;\r\n} else\r\narg = dd;\r\n#ifdef CONFIG_INFINIBAND_QIB_DCA\r\ndca = irq_table[i].dca;\r\n#endif\r\nlsb = irq_table[i].lsb;\r\nhandler = irq_table[i].handler;\r\nsnprintf(dd->cspec->msix_entries[msixnum].name,\r\nsizeof(dd->cspec->msix_entries[msixnum].name)\r\n- 1,\r\nQIB_DRV_NAME "%d%s", dd->unit,\r\nirq_table[i].name);\r\n} else {\r\nunsigned ctxt;\r\nctxt = i - ARRAY_SIZE(irq_table);\r\narg = dd->rcd[ctxt];\r\nif (!arg)\r\ncontinue;\r\nif (qib_krcvq01_no_msi && ctxt < 2)\r\ncontinue;\r\n#ifdef CONFIG_INFINIBAND_QIB_DCA\r\ndca = 1;\r\n#endif\r\nlsb = QIB_I_RCVAVAIL_LSB + ctxt;\r\nhandler = qib_7322pintr;\r\nsnprintf(dd->cspec->msix_entries[msixnum].name,\r\nsizeof(dd->cspec->msix_entries[msixnum].name)\r\n- 1,\r\nQIB_DRV_NAME "%d (kctx)", dd->unit);\r\n}\r\nret = request_irq(\r\ndd->cspec->msix_entries[msixnum].msix.vector,\r\nhandler, 0, dd->cspec->msix_entries[msixnum].name,\r\narg);\r\nif (ret) {\r\nqib_dev_err(dd,\r\n"Couldn't setup MSIx interrupt (vec=%d, irq=%d): %d\n",\r\nmsixnum,\r\ndd->cspec->msix_entries[msixnum].msix.vector,\r\nret);\r\nqib_7322_nomsix(dd);\r\ngoto try_intx;\r\n}\r\ndd->cspec->msix_entries[msixnum].arg = arg;\r\n#ifdef CONFIG_INFINIBAND_QIB_DCA\r\ndd->cspec->msix_entries[msixnum].dca = dca;\r\ndd->cspec->msix_entries[msixnum].rcv =\r\nhandler == qib_7322pintr;\r\n#endif\r\nif (lsb >= 0) {\r\nreg = lsb / IBA7322_REDIRECT_VEC_PER_REG;\r\nsh = (lsb % IBA7322_REDIRECT_VEC_PER_REG) *\r\nSYM_LSB(IntRedirect0, vec1);\r\nmask &= ~(1ULL << lsb);\r\nredirect[reg] |= ((u64) msixnum) << sh;\r\n}\r\nval = qib_read_kreg64(dd, 2 * msixnum + 1 +\r\n(QIB_7322_MsixTable_OFFS / sizeof(u64)));\r\nif (firstcpu < nr_cpu_ids &&\r\nzalloc_cpumask_var(\r\n&dd->cspec->msix_entries[msixnum].mask,\r\nGFP_KERNEL)) {\r\nif (handler == qib_7322pintr) {\r\ncpumask_set_cpu(currrcvcpu,\r\ndd->cspec->msix_entries[msixnum].mask);\r\ncurrrcvcpu = cpumask_next(currrcvcpu,\r\nlocal_mask);\r\nif (currrcvcpu >= nr_cpu_ids)\r\ncurrrcvcpu = secondcpu;\r\n} else {\r\ncpumask_set_cpu(firstcpu,\r\ndd->cspec->msix_entries[msixnum].mask);\r\n}\r\nirq_set_affinity_hint(\r\ndd->cspec->msix_entries[msixnum].msix.vector,\r\ndd->cspec->msix_entries[msixnum].mask);\r\n}\r\nmsixnum++;\r\n}\r\nfor (i = 0; i < ARRAY_SIZE(redirect); i++)\r\nqib_write_kreg(dd, kr_intredirect + i, redirect[i]);\r\ndd->cspec->main_int_mask = mask;\r\ntasklet_init(&dd->error_tasklet, qib_error_tasklet,\r\n(unsigned long)dd);\r\nbail:;\r\n}\r\nstatic unsigned qib_7322_boardname(struct qib_devdata *dd)\r\n{\r\nchar *n;\r\nu32 boardid, namelen;\r\nunsigned features = DUAL_PORT_CAP;\r\nboardid = SYM_FIELD(dd->revision, Revision, BoardID);\r\nswitch (boardid) {\r\ncase 0:\r\nn = "InfiniPath_QLE7342_Emulation";\r\nbreak;\r\ncase 1:\r\nn = "InfiniPath_QLE7340";\r\ndd->flags |= QIB_HAS_QSFP;\r\nfeatures = PORT_SPD_CAP;\r\nbreak;\r\ncase 2:\r\nn = "InfiniPath_QLE7342";\r\ndd->flags |= QIB_HAS_QSFP;\r\nbreak;\r\ncase 3:\r\nn = "InfiniPath_QMI7342";\r\nbreak;\r\ncase 4:\r\nn = "InfiniPath_Unsupported7342";\r\nqib_dev_err(dd, "Unsupported version of QMH7342\n");\r\nfeatures = 0;\r\nbreak;\r\ncase BOARD_QMH7342:\r\nn = "InfiniPath_QMH7342";\r\nfeatures = 0x24;\r\nbreak;\r\ncase BOARD_QME7342:\r\nn = "InfiniPath_QME7342";\r\nbreak;\r\ncase 8:\r\nn = "InfiniPath_QME7362";\r\ndd->flags |= QIB_HAS_QSFP;\r\nbreak;\r\ncase 15:\r\nn = "InfiniPath_QLE7342_TEST";\r\ndd->flags |= QIB_HAS_QSFP;\r\nbreak;\r\ndefault:\r\nn = "InfiniPath_QLE73xy_UNKNOWN";\r\nqib_dev_err(dd, "Unknown 7322 board type %u\n", boardid);\r\nbreak;\r\n}\r\ndd->board_atten = 1;\r\nnamelen = strlen(n) + 1;\r\ndd->boardname = kmalloc(namelen, GFP_KERNEL);\r\nif (!dd->boardname)\r\nqib_dev_err(dd, "Failed allocation for board name: %s\n", n);\r\nelse\r\nsnprintf(dd->boardname, namelen, "%s", n);\r\nsnprintf(dd->boardversion, sizeof(dd->boardversion),\r\n"ChipABI %u.%u, %s, InfiniPath%u %u.%u, SW Compat %u\n",\r\nQIB_CHIP_VERS_MAJ, QIB_CHIP_VERS_MIN, dd->boardname,\r\n(unsigned)SYM_FIELD(dd->revision, Revision_R, Arch),\r\ndd->majrev, dd->minrev,\r\n(unsigned)SYM_FIELD(dd->revision, Revision_R, SW));\r\nif (qib_singleport && (features >> PORT_SPD_CAP_SHIFT) & PORT_SPD_CAP) {\r\nqib_devinfo(dd->pcidev,\r\n"IB%u: Forced to single port mode by module parameter\n",\r\ndd->unit);\r\nfeatures &= PORT_SPD_CAP;\r\n}\r\nreturn features;\r\n}\r\nstatic int qib_do_7322_reset(struct qib_devdata *dd)\r\n{\r\nu64 val;\r\nu64 *msix_vecsave;\r\nint i, msix_entries, ret = 1;\r\nu16 cmdval;\r\nu8 int_line, clinesz;\r\nunsigned long flags;\r\nqib_dev_err(dd, "Resetting InfiniPath unit %u\n", dd->unit);\r\nqib_pcie_getcmd(dd, &cmdval, &int_line, &clinesz);\r\nmsix_entries = dd->cspec->num_msix_entries;\r\nqib_7322_set_intr_state(dd, 0);\r\nif (msix_entries) {\r\nqib_7322_nomsix(dd);\r\nmsix_vecsave = kmalloc(2 * dd->cspec->num_msix_entries *\r\nsizeof(u64), GFP_KERNEL);\r\nif (!msix_vecsave)\r\nqib_dev_err(dd, "No mem to save MSIx data\n");\r\n} else\r\nmsix_vecsave = NULL;\r\nfor (i = 0; i < msix_entries; i++) {\r\nu64 vecaddr, vecdata;\r\nvecaddr = qib_read_kreg64(dd, 2 * i +\r\n(QIB_7322_MsixTable_OFFS / sizeof(u64)));\r\nvecdata = qib_read_kreg64(dd, 1 + 2 * i +\r\n(QIB_7322_MsixTable_OFFS / sizeof(u64)));\r\nif (msix_vecsave) {\r\nmsix_vecsave[2 * i] = vecaddr;\r\nmsix_vecsave[1 + 2 * i] = vecdata & ~0x100000000ULL;\r\n}\r\n}\r\ndd->pport->cpspec->ibdeltainprog = 0;\r\ndd->pport->cpspec->ibsymdelta = 0;\r\ndd->pport->cpspec->iblnkerrdelta = 0;\r\ndd->pport->cpspec->ibmalfdelta = 0;\r\ndd->z_int_counter = qib_int_counter(dd);\r\ndd->flags &= ~(QIB_INITTED | QIB_PRESENT | QIB_BADINTR);\r\ndd->flags |= QIB_DOING_RESET;\r\nval = dd->control | QLOGIC_IB_C_RESET;\r\nwriteq(val, &dd->kregbase[kr_control]);\r\nfor (i = 1; i <= 5; i++) {\r\nmsleep(1000 + (1 + i) * 3000);\r\nqib_pcie_reenable(dd, cmdval, int_line, clinesz);\r\nval = readq(&dd->kregbase[kr_revision]);\r\nif (val == dd->revision)\r\nbreak;\r\nif (i == 5) {\r\nqib_dev_err(dd,\r\n"Failed to initialize after reset, unusable\n");\r\nret = 0;\r\ngoto bail;\r\n}\r\n}\r\ndd->flags |= QIB_PRESENT;\r\nif (msix_entries) {\r\nfor (i = 0; i < msix_entries; i++) {\r\ndd->cspec->msix_entries[i].msix.entry = i;\r\nif (!msix_vecsave || !msix_vecsave[2 * i])\r\ncontinue;\r\nqib_write_kreg(dd, 2 * i +\r\n(QIB_7322_MsixTable_OFFS / sizeof(u64)),\r\nmsix_vecsave[2 * i]);\r\nqib_write_kreg(dd, 1 + 2 * i +\r\n(QIB_7322_MsixTable_OFFS / sizeof(u64)),\r\nmsix_vecsave[1 + 2 * i]);\r\n}\r\n}\r\nfor (i = 0; i < dd->num_pports; ++i)\r\nwrite_7322_init_portregs(&dd->pport[i]);\r\nwrite_7322_initregs(dd);\r\nif (qib_pcie_params(dd, dd->lbus_width,\r\n&dd->cspec->num_msix_entries,\r\ndd->cspec->msix_entries))\r\nqib_dev_err(dd,\r\n"Reset failed to setup PCIe or interrupts; continuing anyway\n");\r\nqib_setup_7322_interrupt(dd, 1);\r\nfor (i = 0; i < dd->num_pports; ++i) {\r\nstruct qib_pportdata *ppd = &dd->pport[i];\r\nspin_lock_irqsave(&ppd->lflags_lock, flags);\r\nppd->lflags |= QIBL_IB_FORCE_NOTIFY;\r\nppd->lflags &= ~QIBL_IB_AUTONEG_FAILED;\r\nspin_unlock_irqrestore(&ppd->lflags_lock, flags);\r\n}\r\nbail:\r\ndd->flags &= ~QIB_DOING_RESET;\r\nkfree(msix_vecsave);\r\nreturn ret;\r\n}\r\nstatic void qib_7322_put_tid(struct qib_devdata *dd, u64 __iomem *tidptr,\r\nu32 type, unsigned long pa)\r\n{\r\nif (!(dd->flags & QIB_PRESENT))\r\nreturn;\r\nif (pa != dd->tidinvalid) {\r\nu64 chippa = pa >> IBA7322_TID_PA_SHIFT;\r\nif (pa != (chippa << IBA7322_TID_PA_SHIFT)) {\r\nqib_dev_err(dd, "Physaddr %lx not 2KB aligned!\n",\r\npa);\r\nreturn;\r\n}\r\nif (chippa >= (1UL << IBA7322_TID_SZ_SHIFT)) {\r\nqib_dev_err(dd,\r\n"Physical page address 0x%lx larger than supported\n",\r\npa);\r\nreturn;\r\n}\r\nif (type == RCVHQ_RCV_TYPE_EAGER)\r\nchippa |= dd->tidtemplate;\r\nelse\r\nchippa |= IBA7322_TID_SZ_4K;\r\npa = chippa;\r\n}\r\nwriteq(pa, tidptr);\r\nmmiowb();\r\n}\r\nstatic void qib_7322_clear_tids(struct qib_devdata *dd,\r\nstruct qib_ctxtdata *rcd)\r\n{\r\nu64 __iomem *tidbase;\r\nunsigned long tidinv;\r\nu32 ctxt;\r\nint i;\r\nif (!dd->kregbase || !rcd)\r\nreturn;\r\nctxt = rcd->ctxt;\r\ntidinv = dd->tidinvalid;\r\ntidbase = (u64 __iomem *)\r\n((char __iomem *) dd->kregbase +\r\ndd->rcvtidbase +\r\nctxt * dd->rcvtidcnt * sizeof(*tidbase));\r\nfor (i = 0; i < dd->rcvtidcnt; i++)\r\nqib_7322_put_tid(dd, &tidbase[i], RCVHQ_RCV_TYPE_EXPECTED,\r\ntidinv);\r\ntidbase = (u64 __iomem *)\r\n((char __iomem *) dd->kregbase +\r\ndd->rcvegrbase +\r\nrcd->rcvegr_tid_base * sizeof(*tidbase));\r\nfor (i = 0; i < rcd->rcvegrcnt; i++)\r\nqib_7322_put_tid(dd, &tidbase[i], RCVHQ_RCV_TYPE_EAGER,\r\ntidinv);\r\n}\r\nstatic void qib_7322_tidtemplate(struct qib_devdata *dd)\r\n{\r\nif (dd->rcvegrbufsize == 2048)\r\ndd->tidtemplate = IBA7322_TID_SZ_2K;\r\nelse if (dd->rcvegrbufsize == 4096)\r\ndd->tidtemplate = IBA7322_TID_SZ_4K;\r\ndd->tidinvalid = 0;\r\n}\r\nstatic int qib_7322_get_base_info(struct qib_ctxtdata *rcd,\r\nstruct qib_base_info *kinfo)\r\n{\r\nkinfo->spi_runtime_flags |= QIB_RUNTIME_CTXT_MSB_IN_QP |\r\nQIB_RUNTIME_PCIE | QIB_RUNTIME_NODMA_RTAIL |\r\nQIB_RUNTIME_HDRSUPP | QIB_RUNTIME_SDMA;\r\nif (rcd->dd->cspec->r1)\r\nkinfo->spi_runtime_flags |= QIB_RUNTIME_RCHK;\r\nif (rcd->dd->flags & QIB_USE_SPCL_TRIG)\r\nkinfo->spi_runtime_flags |= QIB_RUNTIME_SPECIAL_TRIGGER;\r\nreturn 0;\r\n}\r\nstatic struct qib_message_header *\r\nqib_7322_get_msgheader(struct qib_devdata *dd, __le32 *rhf_addr)\r\n{\r\nu32 offset = qib_hdrget_offset(rhf_addr);\r\nreturn (struct qib_message_header *)\r\n(rhf_addr - dd->rhf_offset + offset);\r\n}\r\nstatic void qib_7322_config_ctxts(struct qib_devdata *dd)\r\n{\r\nunsigned long flags;\r\nu32 nchipctxts;\r\nnchipctxts = qib_read_kreg32(dd, kr_contextcnt);\r\ndd->cspec->numctxts = nchipctxts;\r\nif (qib_n_krcv_queues > 1 && dd->num_pports) {\r\ndd->first_user_ctxt = NUM_IB_PORTS +\r\n(qib_n_krcv_queues - 1) * dd->num_pports;\r\nif (dd->first_user_ctxt > nchipctxts)\r\ndd->first_user_ctxt = nchipctxts;\r\ndd->n_krcv_queues = dd->first_user_ctxt / dd->num_pports;\r\n} else {\r\ndd->first_user_ctxt = NUM_IB_PORTS;\r\ndd->n_krcv_queues = 1;\r\n}\r\nif (!qib_cfgctxts) {\r\nint nctxts = dd->first_user_ctxt + num_online_cpus();\r\nif (nctxts <= 6)\r\ndd->ctxtcnt = 6;\r\nelse if (nctxts <= 10)\r\ndd->ctxtcnt = 10;\r\nelse if (nctxts <= nchipctxts)\r\ndd->ctxtcnt = nchipctxts;\r\n} else if (qib_cfgctxts < dd->num_pports)\r\ndd->ctxtcnt = dd->num_pports;\r\nelse if (qib_cfgctxts <= nchipctxts)\r\ndd->ctxtcnt = qib_cfgctxts;\r\nif (!dd->ctxtcnt)\r\ndd->ctxtcnt = nchipctxts;\r\nspin_lock_irqsave(&dd->cspec->rcvmod_lock, flags);\r\nif (dd->ctxtcnt > 10)\r\ndd->rcvctrl |= 2ULL << SYM_LSB(RcvCtrl, ContextCfg);\r\nelse if (dd->ctxtcnt > 6)\r\ndd->rcvctrl |= 1ULL << SYM_LSB(RcvCtrl, ContextCfg);\r\ndd->rcvctrl |= 5ULL << SYM_LSB(RcvCtrl, XrcTypeCode);\r\nqib_write_kreg(dd, kr_rcvctrl, dd->rcvctrl);\r\nspin_unlock_irqrestore(&dd->cspec->rcvmod_lock, flags);\r\ndd->cspec->rcvegrcnt = qib_read_kreg32(dd, kr_rcvegrcnt);\r\nif (qib_rcvhdrcnt)\r\ndd->rcvhdrcnt = max(dd->cspec->rcvegrcnt, qib_rcvhdrcnt);\r\nelse\r\ndd->rcvhdrcnt = 2 * max(dd->cspec->rcvegrcnt,\r\ndd->num_pports > 1 ? 1024U : 2048U);\r\n}\r\nstatic int qib_7322_get_ib_cfg(struct qib_pportdata *ppd, int which)\r\n{\r\nint lsb, ret = 0;\r\nu64 maskr;\r\nswitch (which) {\r\ncase QIB_IB_CFG_LWID_ENB:\r\nret = ppd->link_width_enabled;\r\ngoto done;\r\ncase QIB_IB_CFG_LWID:\r\nret = ppd->link_width_active;\r\ngoto done;\r\ncase QIB_IB_CFG_SPD_ENB:\r\nret = ppd->link_speed_enabled;\r\ngoto done;\r\ncase QIB_IB_CFG_SPD:\r\nret = ppd->link_speed_active;\r\ngoto done;\r\ncase QIB_IB_CFG_RXPOL_ENB:\r\nlsb = SYM_LSB(IBCCtrlB_0, IB_POLARITY_REV_SUPP);\r\nmaskr = SYM_RMASK(IBCCtrlB_0, IB_POLARITY_REV_SUPP);\r\nbreak;\r\ncase QIB_IB_CFG_LREV_ENB:\r\nlsb = SYM_LSB(IBCCtrlB_0, IB_LANE_REV_SUPPORTED);\r\nmaskr = SYM_RMASK(IBCCtrlB_0, IB_LANE_REV_SUPPORTED);\r\nbreak;\r\ncase QIB_IB_CFG_LINKLATENCY:\r\nret = qib_read_kreg_port(ppd, krp_ibcstatus_b) &\r\nSYM_MASK(IBCStatusB_0, LinkRoundTripLatency);\r\ngoto done;\r\ncase QIB_IB_CFG_OP_VLS:\r\nret = ppd->vls_operational;\r\ngoto done;\r\ncase QIB_IB_CFG_VL_HIGH_CAP:\r\nret = 16;\r\ngoto done;\r\ncase QIB_IB_CFG_VL_LOW_CAP:\r\nret = 16;\r\ngoto done;\r\ncase QIB_IB_CFG_OVERRUN_THRESH:\r\nret = SYM_FIELD(ppd->cpspec->ibcctrl_a, IBCCtrlA_0,\r\nOverrunThreshold);\r\ngoto done;\r\ncase QIB_IB_CFG_PHYERR_THRESH:\r\nret = SYM_FIELD(ppd->cpspec->ibcctrl_a, IBCCtrlA_0,\r\nPhyerrThreshold);\r\ngoto done;\r\ncase QIB_IB_CFG_LINKDEFAULT:\r\nret = (ppd->cpspec->ibcctrl_a &\r\nSYM_MASK(IBCCtrlA_0, LinkDownDefaultState)) ?\r\nIB_LINKINITCMD_SLEEP : IB_LINKINITCMD_POLL;\r\ngoto done;\r\ncase QIB_IB_CFG_HRTBT:\r\nlsb = IBA7322_IBC_HRTBT_LSB;\r\nmaskr = IBA7322_IBC_HRTBT_RMASK;\r\nbreak;\r\ncase QIB_IB_CFG_PMA_TICKS:\r\nif (ppd->link_speed_active == QIB_IB_QDR)\r\nret = 3;\r\nelse if (ppd->link_speed_active == QIB_IB_DDR)\r\nret = 1;\r\nelse\r\nret = 0;\r\ngoto done;\r\ndefault:\r\nret = -EINVAL;\r\ngoto done;\r\n}\r\nret = (int)((ppd->cpspec->ibcctrl_b >> lsb) & maskr);\r\ndone:\r\nreturn ret;\r\n}\r\nstatic int qib_7322_set_ib_cfg(struct qib_pportdata *ppd, int which, u32 val)\r\n{\r\nstruct qib_devdata *dd = ppd->dd;\r\nu64 maskr;\r\nint lsb, ret = 0;\r\nu16 lcmd, licmd;\r\nunsigned long flags;\r\nswitch (which) {\r\ncase QIB_IB_CFG_LIDLMC:\r\nlsb = IBA7322_IBC_DLIDLMC_SHIFT;\r\nmaskr = IBA7322_IBC_DLIDLMC_MASK;\r\nqib_write_kreg_port(ppd, krp_sendslid,\r\nval & (val >> 16) & SendIBSLIDAssignMask);\r\nqib_write_kreg_port(ppd, krp_sendslidmask,\r\n(val >> 16) & SendIBSLMCMask);\r\nbreak;\r\ncase QIB_IB_CFG_LWID_ENB:\r\nppd->link_width_enabled = val;\r\nif (val == IB_WIDTH_1X)\r\nval = 0;\r\nelse if (val == IB_WIDTH_4X)\r\nval = 1;\r\nelse\r\nval = 3;\r\nmaskr = SYM_RMASK(IBCCtrlB_0, IB_NUM_CHANNELS);\r\nlsb = SYM_LSB(IBCCtrlB_0, IB_NUM_CHANNELS);\r\nbreak;\r\ncase QIB_IB_CFG_SPD_ENB:\r\nppd->link_speed_enabled = val;\r\nval <<= IBA7322_IBC_SPEED_LSB;\r\nmaskr = IBA7322_IBC_SPEED_MASK | IBA7322_IBC_IBTA_1_2_MASK |\r\nIBA7322_IBC_MAX_SPEED_MASK;\r\nif (val & (val - 1)) {\r\nval |= IBA7322_IBC_IBTA_1_2_MASK |\r\nIBA7322_IBC_MAX_SPEED_MASK;\r\nspin_lock_irqsave(&ppd->lflags_lock, flags);\r\nppd->lflags &= ~QIBL_IB_AUTONEG_FAILED;\r\nspin_unlock_irqrestore(&ppd->lflags_lock, flags);\r\n} else if (val & IBA7322_IBC_SPEED_QDR)\r\nval |= IBA7322_IBC_IBTA_1_2_MASK;\r\nlsb = SYM_LSB(IBCCtrlB_0, IB_ENHANCED_MODE);\r\nbreak;\r\ncase QIB_IB_CFG_RXPOL_ENB:\r\nlsb = SYM_LSB(IBCCtrlB_0, IB_POLARITY_REV_SUPP);\r\nmaskr = SYM_RMASK(IBCCtrlB_0, IB_POLARITY_REV_SUPP);\r\nbreak;\r\ncase QIB_IB_CFG_LREV_ENB:\r\nlsb = SYM_LSB(IBCCtrlB_0, IB_LANE_REV_SUPPORTED);\r\nmaskr = SYM_RMASK(IBCCtrlB_0, IB_LANE_REV_SUPPORTED);\r\nbreak;\r\ncase QIB_IB_CFG_OVERRUN_THRESH:\r\nmaskr = SYM_FIELD(ppd->cpspec->ibcctrl_a, IBCCtrlA_0,\r\nOverrunThreshold);\r\nif (maskr != val) {\r\nppd->cpspec->ibcctrl_a &=\r\n~SYM_MASK(IBCCtrlA_0, OverrunThreshold);\r\nppd->cpspec->ibcctrl_a |= (u64) val <<\r\nSYM_LSB(IBCCtrlA_0, OverrunThreshold);\r\nqib_write_kreg_port(ppd, krp_ibcctrl_a,\r\nppd->cpspec->ibcctrl_a);\r\nqib_write_kreg(dd, kr_scratch, 0ULL);\r\n}\r\ngoto bail;\r\ncase QIB_IB_CFG_PHYERR_THRESH:\r\nmaskr = SYM_FIELD(ppd->cpspec->ibcctrl_a, IBCCtrlA_0,\r\nPhyerrThreshold);\r\nif (maskr != val) {\r\nppd->cpspec->ibcctrl_a &=\r\n~SYM_MASK(IBCCtrlA_0, PhyerrThreshold);\r\nppd->cpspec->ibcctrl_a |= (u64) val <<\r\nSYM_LSB(IBCCtrlA_0, PhyerrThreshold);\r\nqib_write_kreg_port(ppd, krp_ibcctrl_a,\r\nppd->cpspec->ibcctrl_a);\r\nqib_write_kreg(dd, kr_scratch, 0ULL);\r\n}\r\ngoto bail;\r\ncase QIB_IB_CFG_PKEYS:\r\nmaskr = (u64) ppd->pkeys[0] | ((u64) ppd->pkeys[1] << 16) |\r\n((u64) ppd->pkeys[2] << 32) |\r\n((u64) ppd->pkeys[3] << 48);\r\nqib_write_kreg_port(ppd, krp_partitionkey, maskr);\r\ngoto bail;\r\ncase QIB_IB_CFG_LINKDEFAULT:\r\nif (val == IB_LINKINITCMD_POLL)\r\nppd->cpspec->ibcctrl_a &=\r\n~SYM_MASK(IBCCtrlA_0, LinkDownDefaultState);\r\nelse\r\nppd->cpspec->ibcctrl_a |=\r\nSYM_MASK(IBCCtrlA_0, LinkDownDefaultState);\r\nqib_write_kreg_port(ppd, krp_ibcctrl_a, ppd->cpspec->ibcctrl_a);\r\nqib_write_kreg(dd, kr_scratch, 0ULL);\r\ngoto bail;\r\ncase QIB_IB_CFG_MTU:\r\nval = (ppd->ibmaxlen >> 2) + 1;\r\nppd->cpspec->ibcctrl_a &= ~SYM_MASK(IBCCtrlA_0, MaxPktLen);\r\nppd->cpspec->ibcctrl_a |= (u64)val <<\r\nSYM_LSB(IBCCtrlA_0, MaxPktLen);\r\nqib_write_kreg_port(ppd, krp_ibcctrl_a,\r\nppd->cpspec->ibcctrl_a);\r\nqib_write_kreg(dd, kr_scratch, 0ULL);\r\ngoto bail;\r\ncase QIB_IB_CFG_LSTATE:\r\nswitch (val & 0xffff0000) {\r\ncase IB_LINKCMD_DOWN:\r\nlcmd = QLOGIC_IB_IBCC_LINKCMD_DOWN;\r\nppd->cpspec->ibmalfusesnap = 1;\r\nppd->cpspec->ibmalfsnap = read_7322_creg32_port(ppd,\r\ncrp_errlink);\r\nif (!ppd->cpspec->ibdeltainprog &&\r\nqib_compat_ddr_negotiate) {\r\nppd->cpspec->ibdeltainprog = 1;\r\nppd->cpspec->ibsymsnap =\r\nread_7322_creg32_port(ppd,\r\ncrp_ibsymbolerr);\r\nppd->cpspec->iblnkerrsnap =\r\nread_7322_creg32_port(ppd,\r\ncrp_iblinkerrrecov);\r\n}\r\nbreak;\r\ncase IB_LINKCMD_ARMED:\r\nlcmd = QLOGIC_IB_IBCC_LINKCMD_ARMED;\r\nif (ppd->cpspec->ibmalfusesnap) {\r\nppd->cpspec->ibmalfusesnap = 0;\r\nppd->cpspec->ibmalfdelta +=\r\nread_7322_creg32_port(ppd,\r\ncrp_errlink) -\r\nppd->cpspec->ibmalfsnap;\r\n}\r\nbreak;\r\ncase IB_LINKCMD_ACTIVE:\r\nlcmd = QLOGIC_IB_IBCC_LINKCMD_ACTIVE;\r\nbreak;\r\ndefault:\r\nret = -EINVAL;\r\nqib_dev_err(dd, "bad linkcmd req 0x%x\n", val >> 16);\r\ngoto bail;\r\n}\r\nswitch (val & 0xffff) {\r\ncase IB_LINKINITCMD_NOP:\r\nlicmd = 0;\r\nbreak;\r\ncase IB_LINKINITCMD_POLL:\r\nlicmd = QLOGIC_IB_IBCC_LINKINITCMD_POLL;\r\nbreak;\r\ncase IB_LINKINITCMD_SLEEP:\r\nlicmd = QLOGIC_IB_IBCC_LINKINITCMD_SLEEP;\r\nbreak;\r\ncase IB_LINKINITCMD_DISABLE:\r\nlicmd = QLOGIC_IB_IBCC_LINKINITCMD_DISABLE;\r\nppd->cpspec->chase_end = 0;\r\nif (ppd->cpspec->chase_timer.expires) {\r\ndel_timer_sync(&ppd->cpspec->chase_timer);\r\nppd->cpspec->chase_timer.expires = 0;\r\n}\r\nbreak;\r\ndefault:\r\nret = -EINVAL;\r\nqib_dev_err(dd, "bad linkinitcmd req 0x%x\n",\r\nval & 0xffff);\r\ngoto bail;\r\n}\r\nqib_set_ib_7322_lstate(ppd, lcmd, licmd);\r\ngoto bail;\r\ncase QIB_IB_CFG_OP_VLS:\r\nif (ppd->vls_operational != val) {\r\nppd->vls_operational = val;\r\nset_vls(ppd);\r\n}\r\ngoto bail;\r\ncase QIB_IB_CFG_VL_HIGH_LIMIT:\r\nqib_write_kreg_port(ppd, krp_highprio_limit, val);\r\ngoto bail;\r\ncase QIB_IB_CFG_HRTBT:\r\nif (val > 3) {\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nlsb = IBA7322_IBC_HRTBT_LSB;\r\nmaskr = IBA7322_IBC_HRTBT_RMASK;\r\nbreak;\r\ncase QIB_IB_CFG_PORT:\r\nif (ppd->dd->cspec->r1) {\r\ncancel_delayed_work(&ppd->cpspec->ipg_work);\r\nppd->cpspec->ipg_tries = 0;\r\n}\r\ngoto bail;\r\ndefault:\r\nret = -EINVAL;\r\ngoto bail;\r\n}\r\nppd->cpspec->ibcctrl_b &= ~(maskr << lsb);\r\nppd->cpspec->ibcctrl_b |= (((u64) val & maskr) << lsb);\r\nqib_write_kreg_port(ppd, krp_ibcctrl_b, ppd->cpspec->ibcctrl_b);\r\nqib_write_kreg(dd, kr_scratch, 0);\r\nbail:\r\nreturn ret;\r\n}\r\nstatic int qib_7322_set_loopback(struct qib_pportdata *ppd, const char *what)\r\n{\r\nint ret = 0;\r\nu64 val, ctrlb;\r\nif (!strncmp(what, "ibc", 3)) {\r\nppd->cpspec->ibcctrl_a |= SYM_MASK(IBCCtrlA_0,\r\nLoopback);\r\nval = 0;\r\nqib_devinfo(ppd->dd->pcidev, "Enabling IB%u:%u IBC loopback\n",\r\nppd->dd->unit, ppd->port);\r\n} else if (!strncmp(what, "off", 3)) {\r\nppd->cpspec->ibcctrl_a &= ~SYM_MASK(IBCCtrlA_0,\r\nLoopback);\r\nval = IBA7322_IBC_HRTBT_RMASK << IBA7322_IBC_HRTBT_LSB;\r\nqib_devinfo(ppd->dd->pcidev,\r\n"Disabling IB%u:%u IBC loopback (normal)\n",\r\nppd->dd->unit, ppd->port);\r\n} else\r\nret = -EINVAL;\r\nif (!ret) {\r\nqib_write_kreg_port(ppd, krp_ibcctrl_a,\r\nppd->cpspec->ibcctrl_a);\r\nctrlb = ppd->cpspec->ibcctrl_b & ~(IBA7322_IBC_HRTBT_MASK\r\n<< IBA7322_IBC_HRTBT_LSB);\r\nppd->cpspec->ibcctrl_b = ctrlb | val;\r\nqib_write_kreg_port(ppd, krp_ibcctrl_b,\r\nppd->cpspec->ibcctrl_b);\r\nqib_write_kreg(ppd->dd, kr_scratch, 0);\r\n}\r\nreturn ret;\r\n}\r\nstatic void get_vl_weights(struct qib_pportdata *ppd, unsigned regno,\r\nstruct ib_vl_weight_elem *vl)\r\n{\r\nunsigned i;\r\nfor (i = 0; i < 16; i++, regno++, vl++) {\r\nu32 val = qib_read_kreg_port(ppd, regno);\r\nvl->vl = (val >> SYM_LSB(LowPriority0_0, VirtualLane)) &\r\nSYM_RMASK(LowPriority0_0, VirtualLane);\r\nvl->weight = (val >> SYM_LSB(LowPriority0_0, Weight)) &\r\nSYM_RMASK(LowPriority0_0, Weight);\r\n}\r\n}\r\nstatic void set_vl_weights(struct qib_pportdata *ppd, unsigned regno,\r\nstruct ib_vl_weight_elem *vl)\r\n{\r\nunsigned i;\r\nfor (i = 0; i < 16; i++, regno++, vl++) {\r\nu64 val;\r\nval = ((vl->vl & SYM_RMASK(LowPriority0_0, VirtualLane)) <<\r\nSYM_LSB(LowPriority0_0, VirtualLane)) |\r\n((vl->weight & SYM_RMASK(LowPriority0_0, Weight)) <<\r\nSYM_LSB(LowPriority0_0, Weight));\r\nqib_write_kreg_port(ppd, regno, val);\r\n}\r\nif (!(ppd->p_sendctrl & SYM_MASK(SendCtrl_0, IBVLArbiterEn))) {\r\nstruct qib_devdata *dd = ppd->dd;\r\nunsigned long flags;\r\nspin_lock_irqsave(&dd->sendctrl_lock, flags);\r\nppd->p_sendctrl |= SYM_MASK(SendCtrl_0, IBVLArbiterEn);\r\nqib_write_kreg_port(ppd, krp_sendctrl, ppd->p_sendctrl);\r\nqib_write_kreg(dd, kr_scratch, 0);\r\nspin_unlock_irqrestore(&dd->sendctrl_lock, flags);\r\n}\r\n}\r\nstatic int qib_7322_get_ib_table(struct qib_pportdata *ppd, int which, void *t)\r\n{\r\nswitch (which) {\r\ncase QIB_IB_TBL_VL_HIGH_ARB:\r\nget_vl_weights(ppd, krp_highprio_0, t);\r\nbreak;\r\ncase QIB_IB_TBL_VL_LOW_ARB:\r\nget_vl_weights(ppd, krp_lowprio_0, t);\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic int qib_7322_set_ib_table(struct qib_pportdata *ppd, int which, void *t)\r\n{\r\nswitch (which) {\r\ncase QIB_IB_TBL_VL_HIGH_ARB:\r\nset_vl_weights(ppd, krp_highprio_0, t);\r\nbreak;\r\ncase QIB_IB_TBL_VL_LOW_ARB:\r\nset_vl_weights(ppd, krp_lowprio_0, t);\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic void qib_update_7322_usrhead(struct qib_ctxtdata *rcd, u64 hd,\r\nu32 updegr, u32 egrhd, u32 npkts)\r\n{\r\nif (hd >> IBA7322_HDRHEAD_PKTINT_SHIFT)\r\nadjust_rcv_timeout(rcd, npkts);\r\nif (updegr)\r\nqib_write_ureg(rcd->dd, ur_rcvegrindexhead, egrhd, rcd->ctxt);\r\nmmiowb();\r\nqib_write_ureg(rcd->dd, ur_rcvhdrhead, hd, rcd->ctxt);\r\nqib_write_ureg(rcd->dd, ur_rcvhdrhead, hd, rcd->ctxt);\r\nmmiowb();\r\n}\r\nstatic u32 qib_7322_hdrqempty(struct qib_ctxtdata *rcd)\r\n{\r\nu32 head, tail;\r\nhead = qib_read_ureg32(rcd->dd, ur_rcvhdrhead, rcd->ctxt);\r\nif (rcd->rcvhdrtail_kvaddr)\r\ntail = qib_get_rcvhdrtail(rcd);\r\nelse\r\ntail = qib_read_ureg32(rcd->dd, ur_rcvhdrtail, rcd->ctxt);\r\nreturn head == tail;\r\n}\r\nstatic void rcvctrl_7322_mod(struct qib_pportdata *ppd, unsigned int op,\r\nint ctxt)\r\n{\r\nstruct qib_devdata *dd = ppd->dd;\r\nstruct qib_ctxtdata *rcd;\r\nu64 mask, val;\r\nunsigned long flags;\r\nspin_lock_irqsave(&dd->cspec->rcvmod_lock, flags);\r\nif (op & QIB_RCVCTRL_TIDFLOW_ENB)\r\ndd->rcvctrl |= SYM_MASK(RcvCtrl, TidFlowEnable);\r\nif (op & QIB_RCVCTRL_TIDFLOW_DIS)\r\ndd->rcvctrl &= ~SYM_MASK(RcvCtrl, TidFlowEnable);\r\nif (op & QIB_RCVCTRL_TAILUPD_ENB)\r\ndd->rcvctrl |= SYM_MASK(RcvCtrl, TailUpd);\r\nif (op & QIB_RCVCTRL_TAILUPD_DIS)\r\ndd->rcvctrl &= ~SYM_MASK(RcvCtrl, TailUpd);\r\nif (op & QIB_RCVCTRL_PKEY_ENB)\r\nppd->p_rcvctrl &= ~SYM_MASK(RcvCtrl_0, RcvPartitionKeyDisable);\r\nif (op & QIB_RCVCTRL_PKEY_DIS)\r\nppd->p_rcvctrl |= SYM_MASK(RcvCtrl_0, RcvPartitionKeyDisable);\r\nif (ctxt < 0) {\r\nmask = (1ULL << dd->ctxtcnt) - 1;\r\nrcd = NULL;\r\n} else {\r\nmask = (1ULL << ctxt);\r\nrcd = dd->rcd[ctxt];\r\n}\r\nif ((op & QIB_RCVCTRL_CTXT_ENB) && rcd) {\r\nppd->p_rcvctrl |=\r\n(mask << SYM_LSB(RcvCtrl_0, ContextEnableKernel));\r\nif (!(dd->flags & QIB_NODMA_RTAIL)) {\r\nop |= QIB_RCVCTRL_TAILUPD_ENB;\r\ndd->rcvctrl |= SYM_MASK(RcvCtrl, TailUpd);\r\n}\r\nqib_write_kreg_ctxt(dd, krc_rcvhdrtailaddr, ctxt,\r\nrcd->rcvhdrqtailaddr_phys);\r\nqib_write_kreg_ctxt(dd, krc_rcvhdraddr, ctxt,\r\nrcd->rcvhdrq_phys);\r\nrcd->seq_cnt = 1;\r\n}\r\nif (op & QIB_RCVCTRL_CTXT_DIS)\r\nppd->p_rcvctrl &=\r\n~(mask << SYM_LSB(RcvCtrl_0, ContextEnableKernel));\r\nif (op & QIB_RCVCTRL_BP_ENB)\r\ndd->rcvctrl |= mask << SYM_LSB(RcvCtrl, dontDropRHQFull);\r\nif (op & QIB_RCVCTRL_BP_DIS)\r\ndd->rcvctrl &= ~(mask << SYM_LSB(RcvCtrl, dontDropRHQFull));\r\nif (op & QIB_RCVCTRL_INTRAVAIL_ENB)\r\ndd->rcvctrl |= (mask << SYM_LSB(RcvCtrl, IntrAvail));\r\nif (op & QIB_RCVCTRL_INTRAVAIL_DIS)\r\ndd->rcvctrl &= ~(mask << SYM_LSB(RcvCtrl, IntrAvail));\r\nif (op == 0 || (op & RCVCTRL_COMMON_MODS))\r\nqib_write_kreg(dd, kr_rcvctrl, dd->rcvctrl);\r\nif (op == 0 || (op & RCVCTRL_PORT_MODS))\r\nqib_write_kreg_port(ppd, krp_rcvctrl, ppd->p_rcvctrl);\r\nif ((op & QIB_RCVCTRL_CTXT_ENB) && dd->rcd[ctxt]) {\r\nval = qib_read_ureg32(dd, ur_rcvegrindextail, ctxt);\r\nqib_write_ureg(dd, ur_rcvegrindexhead, val, ctxt);\r\n(void) qib_read_kreg32(dd, kr_scratch);\r\nval = qib_read_ureg32(dd, ur_rcvhdrtail, ctxt);\r\ndd->rcd[ctxt]->head = val;\r\nif (ctxt < dd->first_user_ctxt)\r\nval |= dd->rhdrhead_intr_off;\r\nqib_write_ureg(dd, ur_rcvhdrhead, val, ctxt);\r\n} else if ((op & QIB_RCVCTRL_INTRAVAIL_ENB) &&\r\ndd->rcd[ctxt] && dd->rhdrhead_intr_off) {\r\nval = dd->rcd[ctxt]->head | dd->rhdrhead_intr_off;\r\nqib_write_ureg(dd, ur_rcvhdrhead, val, ctxt);\r\n}\r\nif (op & QIB_RCVCTRL_CTXT_DIS) {\r\nunsigned f;\r\nif (ctxt >= 0) {\r\nqib_write_kreg_ctxt(dd, krc_rcvhdrtailaddr, ctxt, 0);\r\nqib_write_kreg_ctxt(dd, krc_rcvhdraddr, ctxt, 0);\r\nfor (f = 0; f < NUM_TIDFLOWS_CTXT; f++)\r\nqib_write_ureg(dd, ur_rcvflowtable + f,\r\nTIDFLOW_ERRBITS, ctxt);\r\n} else {\r\nunsigned i;\r\nfor (i = 0; i < dd->cfgctxts; i++) {\r\nqib_write_kreg_ctxt(dd, krc_rcvhdrtailaddr,\r\ni, 0);\r\nqib_write_kreg_ctxt(dd, krc_rcvhdraddr, i, 0);\r\nfor (f = 0; f < NUM_TIDFLOWS_CTXT; f++)\r\nqib_write_ureg(dd, ur_rcvflowtable + f,\r\nTIDFLOW_ERRBITS, i);\r\n}\r\n}\r\n}\r\nspin_unlock_irqrestore(&dd->cspec->rcvmod_lock, flags);\r\n}\r\nstatic void sendctrl_7322_mod(struct qib_pportdata *ppd, u32 op)\r\n{\r\nstruct qib_devdata *dd = ppd->dd;\r\nu64 tmp_dd_sendctrl;\r\nunsigned long flags;\r\nspin_lock_irqsave(&dd->sendctrl_lock, flags);\r\nif (op & QIB_SENDCTRL_CLEAR)\r\ndd->sendctrl = 0;\r\nif (op & QIB_SENDCTRL_AVAIL_DIS)\r\ndd->sendctrl &= ~SYM_MASK(SendCtrl, SendBufAvailUpd);\r\nelse if (op & QIB_SENDCTRL_AVAIL_ENB) {\r\ndd->sendctrl |= SYM_MASK(SendCtrl, SendBufAvailUpd);\r\nif (dd->flags & QIB_USE_SPCL_TRIG)\r\ndd->sendctrl |= SYM_MASK(SendCtrl, SpecialTriggerEn);\r\n}\r\nif (op & QIB_SENDCTRL_SEND_DIS)\r\nppd->p_sendctrl &= ~SYM_MASK(SendCtrl_0, SendEnable);\r\nelse if (op & QIB_SENDCTRL_SEND_ENB)\r\nppd->p_sendctrl |= SYM_MASK(SendCtrl_0, SendEnable);\r\nif (op & QIB_SENDCTRL_DISARM_ALL) {\r\nu32 i, last;\r\ntmp_dd_sendctrl = dd->sendctrl;\r\nlast = dd->piobcnt2k + dd->piobcnt4k + NUM_VL15_BUFS;\r\ntmp_dd_sendctrl &= ~SYM_MASK(SendCtrl, SendBufAvailUpd);\r\nfor (i = 0; i < last; i++) {\r\nqib_write_kreg(dd, kr_sendctrl,\r\ntmp_dd_sendctrl |\r\nSYM_MASK(SendCtrl, Disarm) | i);\r\nqib_write_kreg(dd, kr_scratch, 0);\r\n}\r\n}\r\nif (op & QIB_SENDCTRL_FLUSH) {\r\nu64 tmp_ppd_sendctrl = ppd->p_sendctrl;\r\ntmp_ppd_sendctrl |=\r\nSYM_MASK(SendCtrl_0, TxeDrainRmFifo) |\r\nSYM_MASK(SendCtrl_0, TxeDrainLaFifo) |\r\nSYM_MASK(SendCtrl_0, TxeBypassIbc);\r\nqib_write_kreg_port(ppd, krp_sendctrl, tmp_ppd_sendctrl);\r\nqib_write_kreg(dd, kr_scratch, 0);\r\n}\r\ntmp_dd_sendctrl = dd->sendctrl;\r\nif (op & QIB_SENDCTRL_DISARM)\r\ntmp_dd_sendctrl |= SYM_MASK(SendCtrl, Disarm) |\r\n((op & QIB_7322_SendCtrl_DisarmSendBuf_RMASK) <<\r\nSYM_LSB(SendCtrl, DisarmSendBuf));\r\nif ((op & QIB_SENDCTRL_AVAIL_BLIP) &&\r\n(dd->sendctrl & SYM_MASK(SendCtrl, SendBufAvailUpd)))\r\ntmp_dd_sendctrl &= ~SYM_MASK(SendCtrl, SendBufAvailUpd);\r\nif (op == 0 || (op & SENDCTRL_COMMON_MODS)) {\r\nqib_write_kreg(dd, kr_sendctrl, tmp_dd_sendctrl);\r\nqib_write_kreg(dd, kr_scratch, 0);\r\n}\r\nif (op == 0 || (op & SENDCTRL_PORT_MODS)) {\r\nqib_write_kreg_port(ppd, krp_sendctrl, ppd->p_sendctrl);\r\nqib_write_kreg(dd, kr_scratch, 0);\r\n}\r\nif (op & QIB_SENDCTRL_AVAIL_BLIP) {\r\nqib_write_kreg(dd, kr_sendctrl, dd->sendctrl);\r\nqib_write_kreg(dd, kr_scratch, 0);\r\n}\r\nspin_unlock_irqrestore(&dd->sendctrl_lock, flags);\r\nif (op & QIB_SENDCTRL_FLUSH) {\r\nu32 v;\r\nv = qib_read_kreg32(dd, kr_scratch);\r\nqib_write_kreg(dd, kr_scratch, v);\r\nv = qib_read_kreg32(dd, kr_scratch);\r\nqib_write_kreg(dd, kr_scratch, v);\r\nqib_read_kreg32(dd, kr_scratch);\r\n}\r\n}\r\nstatic u64 qib_portcntr_7322(struct qib_pportdata *ppd, u32 reg)\r\n{\r\nstruct qib_devdata *dd = ppd->dd;\r\nu64 ret = 0ULL;\r\nu16 creg;\r\nstatic const u32 xlator[] = {\r\n[QIBPORTCNTR_PKTSEND] = crp_pktsend | _PORT_64BIT_FLAG,\r\n[QIBPORTCNTR_WORDSEND] = crp_wordsend | _PORT_64BIT_FLAG,\r\n[QIBPORTCNTR_PSXMITDATA] = crp_psxmitdatacount,\r\n[QIBPORTCNTR_PSXMITPKTS] = crp_psxmitpktscount,\r\n[QIBPORTCNTR_PSXMITWAIT] = crp_psxmitwaitcount,\r\n[QIBPORTCNTR_SENDSTALL] = crp_sendstall,\r\n[QIBPORTCNTR_PKTRCV] = crp_pktrcv | _PORT_64BIT_FLAG,\r\n[QIBPORTCNTR_PSRCVDATA] = crp_psrcvdatacount,\r\n[QIBPORTCNTR_PSRCVPKTS] = crp_psrcvpktscount,\r\n[QIBPORTCNTR_RCVEBP] = crp_rcvebp,\r\n[QIBPORTCNTR_RCVOVFL] = crp_rcvovfl,\r\n[QIBPORTCNTR_WORDRCV] = crp_wordrcv | _PORT_64BIT_FLAG,\r\n[QIBPORTCNTR_RXDROPPKT] = 0xffff,\r\n[QIBPORTCNTR_RXLOCALPHYERR] = crp_rxotherlocalphyerr,\r\n[QIBPORTCNTR_RXVLERR] = crp_rxvlerr,\r\n[QIBPORTCNTR_ERRICRC] = crp_erricrc,\r\n[QIBPORTCNTR_ERRVCRC] = crp_errvcrc,\r\n[QIBPORTCNTR_ERRLPCRC] = crp_errlpcrc,\r\n[QIBPORTCNTR_BADFORMAT] = crp_badformat,\r\n[QIBPORTCNTR_ERR_RLEN] = crp_err_rlen,\r\n[QIBPORTCNTR_IBSYMBOLERR] = crp_ibsymbolerr,\r\n[QIBPORTCNTR_INVALIDRLEN] = crp_invalidrlen,\r\n[QIBPORTCNTR_UNSUPVL] = crp_txunsupvl,\r\n[QIBPORTCNTR_EXCESSBUFOVFL] = crp_excessbufferovfl,\r\n[QIBPORTCNTR_ERRLINK] = crp_errlink,\r\n[QIBPORTCNTR_IBLINKDOWN] = crp_iblinkdown,\r\n[QIBPORTCNTR_IBLINKERRRECOV] = crp_iblinkerrrecov,\r\n[QIBPORTCNTR_LLI] = crp_locallinkintegrityerr,\r\n[QIBPORTCNTR_VL15PKTDROP] = crp_vl15droppedpkt,\r\n[QIBPORTCNTR_ERRPKEY] = crp_errpkey,\r\n[QIBPORTCNTR_PSINTERVAL] = krp_psinterval,\r\n[QIBPORTCNTR_PSSTART] = krp_psstart,\r\n[QIBPORTCNTR_PSSTAT] = krp_psstat,\r\n[QIBPORTCNTR_KHDROVFL] = 0xffff,\r\n};\r\nif (reg >= ARRAY_SIZE(xlator)) {\r\nqib_devinfo(ppd->dd->pcidev,\r\n"Unimplemented portcounter %u\n", reg);\r\ngoto done;\r\n}\r\ncreg = xlator[reg] & _PORT_CNTR_IDXMASK;\r\nif (reg == QIBPORTCNTR_KHDROVFL) {\r\nint i;\r\nfor (i = 0; dd->rcd && i < dd->first_user_ctxt; i++) {\r\nstruct qib_ctxtdata *rcd = dd->rcd[i];\r\nif (!rcd || rcd->ppd != ppd)\r\ncontinue;\r\nret += read_7322_creg32(dd, cr_base_egrovfl + i);\r\n}\r\ngoto done;\r\n} else if (reg == QIBPORTCNTR_RXDROPPKT) {\r\ngoto done;\r\n} else if (reg == QIBPORTCNTR_PSINTERVAL ||\r\nreg == QIBPORTCNTR_PSSTART || reg == QIBPORTCNTR_PSSTAT) {\r\nret = qib_read_kreg_port(ppd, creg);\r\ngoto done;\r\n}\r\nif (xlator[reg] & _PORT_64BIT_FLAG)\r\nret = read_7322_creg_port(ppd, creg);\r\nelse\r\nret = read_7322_creg32_port(ppd, creg);\r\nif (creg == crp_ibsymbolerr) {\r\nif (ppd->cpspec->ibdeltainprog)\r\nret -= ret - ppd->cpspec->ibsymsnap;\r\nret -= ppd->cpspec->ibsymdelta;\r\n} else if (creg == crp_iblinkerrrecov) {\r\nif (ppd->cpspec->ibdeltainprog)\r\nret -= ret - ppd->cpspec->iblnkerrsnap;\r\nret -= ppd->cpspec->iblnkerrdelta;\r\n} else if (creg == crp_errlink)\r\nret -= ppd->cpspec->ibmalfdelta;\r\nelse if (creg == crp_iblinkdown)\r\nret += ppd->cpspec->iblnkdowndelta;\r\ndone:\r\nreturn ret;\r\n}\r\nstatic void init_7322_cntrnames(struct qib_devdata *dd)\r\n{\r\nint i, j = 0;\r\nchar *s;\r\nfor (i = 0, s = (char *)cntr7322names; s && j <= dd->cfgctxts;\r\ni++) {\r\nif (!j && !strncmp("Ctxt0EgrOvfl", s + 1, 12))\r\nj = 1;\r\ns = strchr(s + 1, '\n');\r\nif (s && j)\r\nj++;\r\n}\r\ndd->cspec->ncntrs = i;\r\nif (!s)\r\ndd->cspec->cntrnamelen = sizeof(cntr7322names) - 1;\r\nelse\r\ndd->cspec->cntrnamelen = 1 + s - cntr7322names;\r\ndd->cspec->cntrs = kmalloc(dd->cspec->ncntrs\r\n* sizeof(u64), GFP_KERNEL);\r\nif (!dd->cspec->cntrs)\r\nqib_dev_err(dd, "Failed allocation for counters\n");\r\nfor (i = 0, s = (char *)portcntr7322names; s; i++)\r\ns = strchr(s + 1, '\n');\r\ndd->cspec->nportcntrs = i - 1;\r\ndd->cspec->portcntrnamelen = sizeof(portcntr7322names) - 1;\r\nfor (i = 0; i < dd->num_pports; ++i) {\r\ndd->pport[i].cpspec->portcntrs = kmalloc(dd->cspec->nportcntrs\r\n* sizeof(u64), GFP_KERNEL);\r\nif (!dd->pport[i].cpspec->portcntrs)\r\nqib_dev_err(dd,\r\n"Failed allocation for portcounters\n");\r\n}\r\n}\r\nstatic u32 qib_read_7322cntrs(struct qib_devdata *dd, loff_t pos, char **namep,\r\nu64 **cntrp)\r\n{\r\nu32 ret;\r\nif (namep) {\r\nret = dd->cspec->cntrnamelen;\r\nif (pos >= ret)\r\nret = 0;\r\nelse\r\n*namep = (char *) cntr7322names;\r\n} else {\r\nu64 *cntr = dd->cspec->cntrs;\r\nint i;\r\nret = dd->cspec->ncntrs * sizeof(u64);\r\nif (!cntr || pos >= ret) {\r\nret = 0;\r\ngoto done;\r\n}\r\n*cntrp = cntr;\r\nfor (i = 0; i < dd->cspec->ncntrs; i++)\r\nif (cntr7322indices[i] & _PORT_64BIT_FLAG)\r\n*cntr++ = read_7322_creg(dd,\r\ncntr7322indices[i] &\r\n_PORT_CNTR_IDXMASK);\r\nelse\r\n*cntr++ = read_7322_creg32(dd,\r\ncntr7322indices[i]);\r\n}\r\ndone:\r\nreturn ret;\r\n}\r\nstatic u32 qib_read_7322portcntrs(struct qib_devdata *dd, loff_t pos, u32 port,\r\nchar **namep, u64 **cntrp)\r\n{\r\nu32 ret;\r\nif (namep) {\r\nret = dd->cspec->portcntrnamelen;\r\nif (pos >= ret)\r\nret = 0;\r\nelse\r\n*namep = (char *)portcntr7322names;\r\n} else {\r\nstruct qib_pportdata *ppd = &dd->pport[port];\r\nu64 *cntr = ppd->cpspec->portcntrs;\r\nint i;\r\nret = dd->cspec->nportcntrs * sizeof(u64);\r\nif (!cntr || pos >= ret) {\r\nret = 0;\r\ngoto done;\r\n}\r\n*cntrp = cntr;\r\nfor (i = 0; i < dd->cspec->nportcntrs; i++) {\r\nif (portcntr7322indices[i] & _PORT_VIRT_FLAG)\r\n*cntr++ = qib_portcntr_7322(ppd,\r\nportcntr7322indices[i] &\r\n_PORT_CNTR_IDXMASK);\r\nelse if (portcntr7322indices[i] & _PORT_64BIT_FLAG)\r\n*cntr++ = read_7322_creg_port(ppd,\r\nportcntr7322indices[i] &\r\n_PORT_CNTR_IDXMASK);\r\nelse\r\n*cntr++ = read_7322_creg32_port(ppd,\r\nportcntr7322indices[i]);\r\n}\r\n}\r\ndone:\r\nreturn ret;\r\n}\r\nstatic void qib_get_7322_faststats(unsigned long opaque)\r\n{\r\nstruct qib_devdata *dd = (struct qib_devdata *) opaque;\r\nstruct qib_pportdata *ppd;\r\nunsigned long flags;\r\nu64 traffic_wds;\r\nint pidx;\r\nfor (pidx = 0; pidx < dd->num_pports; ++pidx) {\r\nppd = dd->pport + pidx;\r\nif (!ppd->link_speed_supported || !(dd->flags & QIB_INITTED)\r\n|| dd->diag_client)\r\ncontinue;\r\ntraffic_wds = qib_portcntr_7322(ppd, QIBPORTCNTR_WORDRCV) +\r\nqib_portcntr_7322(ppd, QIBPORTCNTR_WORDSEND);\r\nspin_lock_irqsave(&ppd->dd->eep_st_lock, flags);\r\ntraffic_wds -= ppd->dd->traffic_wds;\r\nppd->dd->traffic_wds += traffic_wds;\r\nif (traffic_wds >= QIB_TRAFFIC_ACTIVE_THRESHOLD)\r\natomic_add(ACTIVITY_TIMER, &ppd->dd->active_time);\r\nspin_unlock_irqrestore(&ppd->dd->eep_st_lock, flags);\r\nif (ppd->cpspec->qdr_dfe_on && (ppd->link_speed_active &\r\nQIB_IB_QDR) &&\r\n(ppd->lflags & (QIBL_LINKINIT | QIBL_LINKARMED |\r\nQIBL_LINKACTIVE)) &&\r\nppd->cpspec->qdr_dfe_time &&\r\ntime_is_before_jiffies(ppd->cpspec->qdr_dfe_time)) {\r\nppd->cpspec->qdr_dfe_on = 0;\r\nqib_write_kreg_port(ppd, krp_static_adapt_dis(2),\r\nppd->dd->cspec->r1 ?\r\nQDR_STATIC_ADAPT_INIT_R1 :\r\nQDR_STATIC_ADAPT_INIT);\r\nforce_h1(ppd);\r\n}\r\n}\r\nmod_timer(&dd->stats_timer, jiffies + HZ * ACTIVITY_TIMER);\r\n}\r\nstatic int qib_7322_intr_fallback(struct qib_devdata *dd)\r\n{\r\nif (!dd->cspec->num_msix_entries)\r\nreturn 0;\r\nqib_devinfo(dd->pcidev,\r\n"MSIx interrupt not detected, trying INTx interrupts\n");\r\nqib_7322_nomsix(dd);\r\nqib_enable_intx(dd->pcidev);\r\nqib_setup_7322_interrupt(dd, 0);\r\nreturn 1;\r\n}\r\nstatic void qib_7322_mini_pcs_reset(struct qib_pportdata *ppd)\r\n{\r\nu64 val;\r\nstruct qib_devdata *dd = ppd->dd;\r\nconst u64 reset_bits = SYM_MASK(IBPCSConfig_0, xcv_rreset) |\r\nSYM_MASK(IBPCSConfig_0, xcv_treset) |\r\nSYM_MASK(IBPCSConfig_0, tx_rx_reset);\r\nval = qib_read_kreg_port(ppd, krp_ib_pcsconfig);\r\nqib_write_kreg(dd, kr_hwerrmask,\r\ndd->cspec->hwerrmask & ~HWE_MASK(statusValidNoEop));\r\nqib_write_kreg_port(ppd, krp_ibcctrl_a,\r\nppd->cpspec->ibcctrl_a &\r\n~SYM_MASK(IBCCtrlA_0, IBLinkEn));\r\nqib_write_kreg_port(ppd, krp_ib_pcsconfig, val | reset_bits);\r\nqib_read_kreg32(dd, kr_scratch);\r\nqib_write_kreg_port(ppd, krp_ib_pcsconfig, val & ~reset_bits);\r\nqib_write_kreg_port(ppd, krp_ibcctrl_a, ppd->cpspec->ibcctrl_a);\r\nqib_write_kreg(dd, kr_scratch, 0ULL);\r\nqib_write_kreg(dd, kr_hwerrclear,\r\nSYM_MASK(HwErrClear, statusValidNoEopClear));\r\nqib_write_kreg(dd, kr_hwerrmask, dd->cspec->hwerrmask);\r\n}\r\nstatic void autoneg_7322_sendpkt(struct qib_pportdata *ppd, u32 *hdr,\r\nu32 dcnt, u32 *data)\r\n{\r\nint i;\r\nu64 pbc;\r\nu32 __iomem *piobuf;\r\nu32 pnum, control, len;\r\nstruct qib_devdata *dd = ppd->dd;\r\ni = 0;\r\nlen = 7 + dcnt + 1;\r\ncontrol = qib_7322_setpbc_control(ppd, len, 0, 15);\r\npbc = ((u64) control << 32) | len;\r\nwhile (!(piobuf = qib_7322_getsendbuf(ppd, pbc, &pnum))) {\r\nif (i++ > 15)\r\nreturn;\r\nudelay(2);\r\n}\r\ndd->f_txchk_change(dd, pnum, 1, TXCHK_CHG_TYPE_DIS1, NULL);\r\nwriteq(pbc, piobuf);\r\nqib_flush_wc();\r\nqib_pio_copy(piobuf + 2, hdr, 7);\r\nqib_pio_copy(piobuf + 9, data, dcnt);\r\nif (dd->flags & QIB_USE_SPCL_TRIG) {\r\nu32 spcl_off = (pnum >= dd->piobcnt2k) ? 2047 : 1023;\r\nqib_flush_wc();\r\n__raw_writel(0xaebecede, piobuf + spcl_off);\r\n}\r\nqib_flush_wc();\r\nqib_sendbuf_done(dd, pnum);\r\ndd->f_txchk_change(dd, pnum, 1, TXCHK_CHG_TYPE_ENAB1, NULL);\r\n}\r\nstatic void qib_autoneg_7322_send(struct qib_pportdata *ppd, int which)\r\n{\r\nstruct qib_devdata *dd = ppd->dd;\r\nstatic u32 swapped;\r\nu32 dw, i, hcnt, dcnt, *data;\r\nstatic u32 hdr[7] = { 0xf002ffff, 0x48ffff, 0x6400abba };\r\nstatic u32 madpayload_start[0x40] = {\r\n0x1810103, 0x1, 0x0, 0x0, 0x2c90000, 0x2c9, 0x0, 0x0,\r\n0xffffffff, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0,\r\n0x1, 0x1388, 0x15e, 0x1,\r\n};\r\nstatic u32 madpayload_done[0x40] = {\r\n0x1810103, 0x1, 0x0, 0x0, 0x2c90000, 0x2c9, 0x0, 0x0,\r\n0xffffffff, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0,\r\n0x40000001, 0x1388, 0x15e,\r\n};\r\ndcnt = ARRAY_SIZE(madpayload_start);\r\nhcnt = ARRAY_SIZE(hdr);\r\nif (!swapped) {\r\nfor (i = 0; i < hcnt; i++) {\r\ndw = (__force u32) cpu_to_be32(hdr[i]);\r\nhdr[i] = dw;\r\n}\r\nfor (i = 0; i < dcnt; i++) {\r\ndw = (__force u32) cpu_to_be32(madpayload_start[i]);\r\nmadpayload_start[i] = dw;\r\ndw = (__force u32) cpu_to_be32(madpayload_done[i]);\r\nmadpayload_done[i] = dw;\r\n}\r\nswapped = 1;\r\n}\r\ndata = which ? madpayload_done : madpayload_start;\r\nautoneg_7322_sendpkt(ppd, hdr, dcnt, data);\r\nqib_read_kreg64(dd, kr_scratch);\r\nudelay(2);\r\nautoneg_7322_sendpkt(ppd, hdr, dcnt, data);\r\nqib_read_kreg64(dd, kr_scratch);\r\nudelay(2);\r\n}\r\nstatic void set_7322_ibspeed_fast(struct qib_pportdata *ppd, u32 speed)\r\n{\r\nu64 newctrlb;\r\nnewctrlb = ppd->cpspec->ibcctrl_b & ~(IBA7322_IBC_SPEED_MASK |\r\nIBA7322_IBC_IBTA_1_2_MASK |\r\nIBA7322_IBC_MAX_SPEED_MASK);\r\nif (speed & (speed - 1))\r\nnewctrlb |= (speed << IBA7322_IBC_SPEED_LSB) |\r\nIBA7322_IBC_IBTA_1_2_MASK |\r\nIBA7322_IBC_MAX_SPEED_MASK;\r\nelse\r\nnewctrlb |= speed == QIB_IB_QDR ?\r\nIBA7322_IBC_SPEED_QDR | IBA7322_IBC_IBTA_1_2_MASK :\r\n((speed == QIB_IB_DDR ?\r\nIBA7322_IBC_SPEED_DDR : IBA7322_IBC_SPEED_SDR));\r\nif (newctrlb == ppd->cpspec->ibcctrl_b)\r\nreturn;\r\nppd->cpspec->ibcctrl_b = newctrlb;\r\nqib_write_kreg_port(ppd, krp_ibcctrl_b, ppd->cpspec->ibcctrl_b);\r\nqib_write_kreg(ppd->dd, kr_scratch, 0);\r\n}\r\nstatic void try_7322_autoneg(struct qib_pportdata *ppd)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(&ppd->lflags_lock, flags);\r\nppd->lflags |= QIBL_IB_AUTONEG_INPROG;\r\nspin_unlock_irqrestore(&ppd->lflags_lock, flags);\r\nqib_autoneg_7322_send(ppd, 0);\r\nset_7322_ibspeed_fast(ppd, QIB_IB_DDR);\r\nqib_7322_mini_pcs_reset(ppd);\r\nqueue_delayed_work(ib_wq, &ppd->cpspec->autoneg_work,\r\nmsecs_to_jiffies(2));\r\n}\r\nstatic void autoneg_7322_work(struct work_struct *work)\r\n{\r\nstruct qib_pportdata *ppd;\r\nstruct qib_devdata *dd;\r\nu64 startms;\r\nu32 i;\r\nunsigned long flags;\r\nppd = container_of(work, struct qib_chippport_specific,\r\nautoneg_work.work)->ppd;\r\ndd = ppd->dd;\r\nstartms = jiffies_to_msecs(jiffies);\r\nfor (i = 0; i < 25; i++) {\r\nif (SYM_FIELD(ppd->lastibcstat, IBCStatusA_0, LinkState)\r\n== IB_7322_LT_STATE_POLLQUIET) {\r\nqib_set_linkstate(ppd, QIB_IB_LINKDOWN_DISABLE);\r\nbreak;\r\n}\r\nudelay(100);\r\n}\r\nif (!(ppd->lflags & QIBL_IB_AUTONEG_INPROG))\r\ngoto done;\r\nif (wait_event_timeout(ppd->cpspec->autoneg_wait,\r\n!(ppd->lflags & QIBL_IB_AUTONEG_INPROG),\r\nmsecs_to_jiffies(90)))\r\ngoto done;\r\nqib_7322_mini_pcs_reset(ppd);\r\nif (wait_event_timeout(ppd->cpspec->autoneg_wait,\r\n!(ppd->lflags & QIBL_IB_AUTONEG_INPROG),\r\nmsecs_to_jiffies(1700)))\r\ngoto done;\r\nqib_7322_mini_pcs_reset(ppd);\r\nset_7322_ibspeed_fast(ppd, QIB_IB_SDR);\r\nwait_event_timeout(ppd->cpspec->autoneg_wait,\r\n!(ppd->lflags & QIBL_IB_AUTONEG_INPROG),\r\nmsecs_to_jiffies(250));\r\ndone:\r\nif (ppd->lflags & QIBL_IB_AUTONEG_INPROG) {\r\nspin_lock_irqsave(&ppd->lflags_lock, flags);\r\nppd->lflags &= ~QIBL_IB_AUTONEG_INPROG;\r\nif (ppd->cpspec->autoneg_tries == AUTONEG_TRIES) {\r\nppd->lflags |= QIBL_IB_AUTONEG_FAILED;\r\nppd->cpspec->autoneg_tries = 0;\r\n}\r\nspin_unlock_irqrestore(&ppd->lflags_lock, flags);\r\nset_7322_ibspeed_fast(ppd, ppd->link_speed_enabled);\r\n}\r\n}\r\nstatic void try_7322_ipg(struct qib_pportdata *ppd)\r\n{\r\nstruct qib_ibport *ibp = &ppd->ibport_data;\r\nstruct ib_mad_send_buf *send_buf;\r\nstruct ib_mad_agent *agent;\r\nstruct ib_smp *smp;\r\nunsigned delay;\r\nint ret;\r\nagent = ibp->send_agent;\r\nif (!agent)\r\ngoto retry;\r\nsend_buf = ib_create_send_mad(agent, 0, 0, 0, IB_MGMT_MAD_HDR,\r\nIB_MGMT_MAD_DATA, GFP_ATOMIC);\r\nif (IS_ERR(send_buf))\r\ngoto retry;\r\nif (!ibp->smi_ah) {\r\nstruct ib_ah *ah;\r\nah = qib_create_qp0_ah(ibp, be16_to_cpu(IB_LID_PERMISSIVE));\r\nif (IS_ERR(ah))\r\nret = PTR_ERR(ah);\r\nelse {\r\nsend_buf->ah = ah;\r\nibp->smi_ah = to_iah(ah);\r\nret = 0;\r\n}\r\n} else {\r\nsend_buf->ah = &ibp->smi_ah->ibah;\r\nret = 0;\r\n}\r\nsmp = send_buf->mad;\r\nsmp->base_version = IB_MGMT_BASE_VERSION;\r\nsmp->mgmt_class = IB_MGMT_CLASS_SUBN_DIRECTED_ROUTE;\r\nsmp->class_version = 1;\r\nsmp->method = IB_MGMT_METHOD_SEND;\r\nsmp->hop_cnt = 1;\r\nsmp->attr_id = QIB_VENDOR_IPG;\r\nsmp->attr_mod = 0;\r\nif (!ret)\r\nret = ib_post_send_mad(send_buf, NULL);\r\nif (ret)\r\nib_free_send_mad(send_buf);\r\nretry:\r\ndelay = 2 << ppd->cpspec->ipg_tries;\r\nqueue_delayed_work(ib_wq, &ppd->cpspec->ipg_work,\r\nmsecs_to_jiffies(delay));\r\n}\r\nstatic void ipg_7322_work(struct work_struct *work)\r\n{\r\nstruct qib_pportdata *ppd;\r\nppd = container_of(work, struct qib_chippport_specific,\r\nipg_work.work)->ppd;\r\nif ((ppd->lflags & (QIBL_LINKINIT | QIBL_LINKARMED | QIBL_LINKACTIVE))\r\n&& ++ppd->cpspec->ipg_tries <= 10)\r\ntry_7322_ipg(ppd);\r\n}\r\nstatic u32 qib_7322_iblink_state(u64 ibcs)\r\n{\r\nu32 state = (u32)SYM_FIELD(ibcs, IBCStatusA_0, LinkState);\r\nswitch (state) {\r\ncase IB_7322_L_STATE_INIT:\r\nstate = IB_PORT_INIT;\r\nbreak;\r\ncase IB_7322_L_STATE_ARM:\r\nstate = IB_PORT_ARMED;\r\nbreak;\r\ncase IB_7322_L_STATE_ACTIVE:\r\ncase IB_7322_L_STATE_ACT_DEFER:\r\nstate = IB_PORT_ACTIVE;\r\nbreak;\r\ndefault:\r\ncase IB_7322_L_STATE_DOWN:\r\nstate = IB_PORT_DOWN;\r\nbreak;\r\n}\r\nreturn state;\r\n}\r\nstatic u8 qib_7322_phys_portstate(u64 ibcs)\r\n{\r\nu8 state = (u8)SYM_FIELD(ibcs, IBCStatusA_0, LinkTrainingState);\r\nreturn qib_7322_physportstate[state];\r\n}\r\nstatic int qib_7322_ib_updown(struct qib_pportdata *ppd, int ibup, u64 ibcs)\r\n{\r\nint ret = 0, symadj = 0;\r\nunsigned long flags;\r\nint mult;\r\nspin_lock_irqsave(&ppd->lflags_lock, flags);\r\nppd->lflags &= ~QIBL_IB_FORCE_NOTIFY;\r\nspin_unlock_irqrestore(&ppd->lflags_lock, flags);\r\nif (ibcs & SYM_MASK(IBCStatusA_0, LinkSpeedQDR)) {\r\nppd->link_speed_active = QIB_IB_QDR;\r\nmult = 4;\r\n} else if (ibcs & SYM_MASK(IBCStatusA_0, LinkSpeedActive)) {\r\nppd->link_speed_active = QIB_IB_DDR;\r\nmult = 2;\r\n} else {\r\nppd->link_speed_active = QIB_IB_SDR;\r\nmult = 1;\r\n}\r\nif (ibcs & SYM_MASK(IBCStatusA_0, LinkWidthActive)) {\r\nppd->link_width_active = IB_WIDTH_4X;\r\nmult *= 4;\r\n} else\r\nppd->link_width_active = IB_WIDTH_1X;\r\nppd->delay_mult = ib_rate_to_delay[mult_to_ib_rate(mult)];\r\nif (!ibup) {\r\nu64 clr;\r\nppd->cpspec->ipg_tries = 0;\r\nclr = qib_read_kreg_port(ppd, krp_ibcstatus_b) &\r\n(SYM_MASK(IBCStatusB_0, heartbeat_timed_out) |\r\nSYM_MASK(IBCStatusB_0, heartbeat_crosstalk));\r\nif (clr)\r\nqib_write_kreg_port(ppd, krp_ibcstatus_b, clr);\r\nif (!(ppd->lflags & (QIBL_IB_AUTONEG_FAILED |\r\nQIBL_IB_AUTONEG_INPROG)))\r\nset_7322_ibspeed_fast(ppd, ppd->link_speed_enabled);\r\nif (!(ppd->lflags & QIBL_IB_AUTONEG_INPROG)) {\r\nstruct qib_qsfp_data *qd =\r\n&ppd->cpspec->qsfp_data;\r\nqib_write_kreg_port(ppd, krp_tx_deemph_override,\r\nSYM_MASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\r\nreset_tx_deemphasis_override));\r\nqib_cancel_sends(ppd);\r\nqib_7322_mini_pcs_reset(ppd);\r\nif (ppd->dd->flags & QIB_HAS_QSFP) {\r\nqd->t_insert = jiffies;\r\nqueue_work(ib_wq, &qd->work);\r\n}\r\nspin_lock_irqsave(&ppd->sdma_lock, flags);\r\nif (__qib_sdma_running(ppd))\r\n__qib_sdma_process_event(ppd,\r\nqib_sdma_event_e70_go_idle);\r\nspin_unlock_irqrestore(&ppd->sdma_lock, flags);\r\n}\r\nclr = read_7322_creg32_port(ppd, crp_iblinkdown);\r\nif (clr == ppd->cpspec->iblnkdownsnap)\r\nppd->cpspec->iblnkdowndelta++;\r\n} else {\r\nif (qib_compat_ddr_negotiate &&\r\n!(ppd->lflags & (QIBL_IB_AUTONEG_FAILED |\r\nQIBL_IB_AUTONEG_INPROG)) &&\r\nppd->link_speed_active == QIB_IB_SDR &&\r\n(ppd->link_speed_enabled & QIB_IB_DDR)\r\n&& ppd->cpspec->autoneg_tries < AUTONEG_TRIES) {\r\n++ppd->cpspec->autoneg_tries;\r\nif (!ppd->cpspec->ibdeltainprog) {\r\nppd->cpspec->ibdeltainprog = 1;\r\nppd->cpspec->ibsymdelta +=\r\nread_7322_creg32_port(ppd,\r\ncrp_ibsymbolerr) -\r\nppd->cpspec->ibsymsnap;\r\nppd->cpspec->iblnkerrdelta +=\r\nread_7322_creg32_port(ppd,\r\ncrp_iblinkerrrecov) -\r\nppd->cpspec->iblnkerrsnap;\r\n}\r\ntry_7322_autoneg(ppd);\r\nret = 1;\r\n} else if ((ppd->lflags & QIBL_IB_AUTONEG_INPROG) &&\r\nppd->link_speed_active == QIB_IB_SDR) {\r\nqib_autoneg_7322_send(ppd, 1);\r\nset_7322_ibspeed_fast(ppd, QIB_IB_DDR);\r\nqib_7322_mini_pcs_reset(ppd);\r\nudelay(2);\r\nret = 1;\r\n} else if ((ppd->lflags & QIBL_IB_AUTONEG_INPROG) &&\r\n(ppd->link_speed_active & QIB_IB_DDR)) {\r\nspin_lock_irqsave(&ppd->lflags_lock, flags);\r\nppd->lflags &= ~(QIBL_IB_AUTONEG_INPROG |\r\nQIBL_IB_AUTONEG_FAILED);\r\nspin_unlock_irqrestore(&ppd->lflags_lock, flags);\r\nppd->cpspec->autoneg_tries = 0;\r\nset_7322_ibspeed_fast(ppd, ppd->link_speed_enabled);\r\nwake_up(&ppd->cpspec->autoneg_wait);\r\nsymadj = 1;\r\n} else if (ppd->lflags & QIBL_IB_AUTONEG_FAILED) {\r\nspin_lock_irqsave(&ppd->lflags_lock, flags);\r\nppd->lflags &= ~QIBL_IB_AUTONEG_FAILED;\r\nspin_unlock_irqrestore(&ppd->lflags_lock, flags);\r\nppd->cpspec->ibcctrl_b |= IBA7322_IBC_IBTA_1_2_MASK;\r\nsymadj = 1;\r\n}\r\nif (!(ppd->lflags & QIBL_IB_AUTONEG_INPROG)) {\r\nsymadj = 1;\r\nif (ppd->dd->cspec->r1 && ppd->cpspec->ipg_tries <= 10)\r\ntry_7322_ipg(ppd);\r\nif (!ppd->cpspec->recovery_init)\r\nsetup_7322_link_recovery(ppd, 0);\r\nppd->cpspec->qdr_dfe_time = jiffies +\r\nmsecs_to_jiffies(QDR_DFE_DISABLE_DELAY);\r\n}\r\nppd->cpspec->ibmalfusesnap = 0;\r\nppd->cpspec->ibmalfsnap = read_7322_creg32_port(ppd,\r\ncrp_errlink);\r\n}\r\nif (symadj) {\r\nppd->cpspec->iblnkdownsnap =\r\nread_7322_creg32_port(ppd, crp_iblinkdown);\r\nif (ppd->cpspec->ibdeltainprog) {\r\nppd->cpspec->ibdeltainprog = 0;\r\nppd->cpspec->ibsymdelta += read_7322_creg32_port(ppd,\r\ncrp_ibsymbolerr) - ppd->cpspec->ibsymsnap;\r\nppd->cpspec->iblnkerrdelta += read_7322_creg32_port(ppd,\r\ncrp_iblinkerrrecov) - ppd->cpspec->iblnkerrsnap;\r\n}\r\n} else if (!ibup && qib_compat_ddr_negotiate &&\r\n!ppd->cpspec->ibdeltainprog &&\r\n!(ppd->lflags & QIBL_IB_AUTONEG_INPROG)) {\r\nppd->cpspec->ibdeltainprog = 1;\r\nppd->cpspec->ibsymsnap = read_7322_creg32_port(ppd,\r\ncrp_ibsymbolerr);\r\nppd->cpspec->iblnkerrsnap = read_7322_creg32_port(ppd,\r\ncrp_iblinkerrrecov);\r\n}\r\nif (!ret)\r\nqib_setup_7322_setextled(ppd, ibup);\r\nreturn ret;\r\n}\r\nstatic int gpio_7322_mod(struct qib_devdata *dd, u32 out, u32 dir, u32 mask)\r\n{\r\nu64 read_val, new_out;\r\nunsigned long flags;\r\nif (mask) {\r\ndir &= mask;\r\nout &= mask;\r\nspin_lock_irqsave(&dd->cspec->gpio_lock, flags);\r\ndd->cspec->extctrl &= ~((u64)mask << SYM_LSB(EXTCtrl, GPIOOe));\r\ndd->cspec->extctrl |= ((u64) dir << SYM_LSB(EXTCtrl, GPIOOe));\r\nnew_out = (dd->cspec->gpio_out & ~mask) | out;\r\nqib_write_kreg(dd, kr_extctrl, dd->cspec->extctrl);\r\nqib_write_kreg(dd, kr_gpio_out, new_out);\r\ndd->cspec->gpio_out = new_out;\r\nspin_unlock_irqrestore(&dd->cspec->gpio_lock, flags);\r\n}\r\nread_val = qib_read_kreg64(dd, kr_extstatus);\r\nreturn SYM_FIELD(read_val, EXTStatus, GPIOIn);\r\n}\r\nstatic int qib_7322_eeprom_wen(struct qib_devdata *dd, int wen)\r\n{\r\nint prev_wen;\r\nu32 mask;\r\nmask = 1 << QIB_EEPROM_WEN_NUM;\r\nprev_wen = ~gpio_7322_mod(dd, 0, 0, 0) >> QIB_EEPROM_WEN_NUM;\r\ngpio_7322_mod(dd, wen ? 0 : mask, mask, mask);\r\nreturn prev_wen & 1;\r\n}\r\nstatic void get_7322_chip_params(struct qib_devdata *dd)\r\n{\r\nu64 val;\r\nu32 piobufs;\r\nint mtu;\r\ndd->palign = qib_read_kreg32(dd, kr_pagealign);\r\ndd->uregbase = qib_read_kreg32(dd, kr_userregbase);\r\ndd->rcvtidcnt = qib_read_kreg32(dd, kr_rcvtidcnt);\r\ndd->rcvtidbase = qib_read_kreg32(dd, kr_rcvtidbase);\r\ndd->rcvegrbase = qib_read_kreg32(dd, kr_rcvegrbase);\r\ndd->piobufbase = qib_read_kreg64(dd, kr_sendpiobufbase);\r\ndd->pio2k_bufbase = dd->piobufbase & 0xffffffff;\r\nval = qib_read_kreg64(dd, kr_sendpiobufcnt);\r\ndd->piobcnt2k = val & ~0U;\r\ndd->piobcnt4k = val >> 32;\r\nval = qib_read_kreg64(dd, kr_sendpiosize);\r\ndd->piosize2k = val & ~0U;\r\ndd->piosize4k = val >> 32;\r\nmtu = ib_mtu_enum_to_int(qib_ibmtu);\r\nif (mtu == -1)\r\nmtu = QIB_DEFAULT_MTU;\r\ndd->pport[0].ibmtu = (u32)mtu;\r\ndd->pport[1].ibmtu = (u32)mtu;\r\ndd->pio2kbase = (u32 __iomem *)\r\n((char __iomem *) dd->kregbase + dd->pio2k_bufbase);\r\ndd->pio4kbase = (u32 __iomem *)\r\n((char __iomem *) dd->kregbase +\r\n(dd->piobufbase >> 32));\r\ndd->align4k = ALIGN(dd->piosize4k, dd->palign);\r\npiobufs = dd->piobcnt4k + dd->piobcnt2k + NUM_VL15_BUFS;\r\ndd->pioavregs = ALIGN(piobufs, sizeof(u64) * BITS_PER_BYTE / 2) /\r\n(sizeof(u64) * BITS_PER_BYTE / 2);\r\n}\r\nstatic void qib_7322_set_baseaddrs(struct qib_devdata *dd)\r\n{\r\nu32 cregbase;\r\ncregbase = qib_read_kreg32(dd, kr_counterregbase);\r\ndd->cspec->cregbase = (u64 __iomem *)(cregbase +\r\n(char __iomem *)dd->kregbase);\r\ndd->egrtidbase = (u64 __iomem *)\r\n((char __iomem *) dd->kregbase + dd->rcvegrbase);\r\ndd->pport[0].cpspec->kpregbase =\r\n(u64 __iomem *)((char __iomem *)dd->kregbase);\r\ndd->pport[1].cpspec->kpregbase =\r\n(u64 __iomem *)(dd->palign +\r\n(char __iomem *)dd->kregbase);\r\ndd->pport[0].cpspec->cpregbase =\r\n(u64 __iomem *)(qib_read_kreg_port(&dd->pport[0],\r\nkr_counterregbase) + (char __iomem *)dd->kregbase);\r\ndd->pport[1].cpspec->cpregbase =\r\n(u64 __iomem *)(qib_read_kreg_port(&dd->pport[1],\r\nkr_counterregbase) + (char __iomem *)dd->kregbase);\r\n}\r\nstatic int sendctrl_hook(struct qib_devdata *dd,\r\nconst struct diag_observer *op, u32 offs,\r\nu64 *data, u64 mask, int only_32)\r\n{\r\nunsigned long flags;\r\nunsigned idx;\r\nunsigned pidx;\r\nstruct qib_pportdata *ppd = NULL;\r\nu64 local_data, all_bits;\r\nfor (pidx = 0; pidx < dd->num_pports; ++pidx) {\r\nu64 __iomem *psptr;\r\nu32 psoffs;\r\nppd = dd->pport + pidx;\r\nif (!ppd->cpspec->kpregbase)\r\ncontinue;\r\npsptr = ppd->cpspec->kpregbase + krp_sendctrl;\r\npsoffs = (u32) (psptr - dd->kregbase) * sizeof(*psptr);\r\nif (psoffs == offs)\r\nbreak;\r\n}\r\nif (pidx >= dd->num_pports)\r\nppd = NULL;\r\nidx = offs / sizeof(u64);\r\nall_bits = ~0ULL;\r\nif (only_32)\r\nall_bits >>= 32;\r\nspin_lock_irqsave(&dd->sendctrl_lock, flags);\r\nif (!ppd || (mask & all_bits) != all_bits) {\r\nif (only_32)\r\nlocal_data = (u64)qib_read_kreg32(dd, idx);\r\nelse\r\nlocal_data = qib_read_kreg64(dd, idx);\r\n*data = (local_data & ~mask) | (*data & mask);\r\n}\r\nif (mask) {\r\nu64 sval, tval;\r\nif (ppd) {\r\nsval = ppd->p_sendctrl & ~mask;\r\nsval |= *data & SENDCTRL_SHADOWED & mask;\r\nppd->p_sendctrl = sval;\r\n} else\r\nsval = *data & SENDCTRL_SHADOWED & mask;\r\ntval = sval | (*data & ~SENDCTRL_SHADOWED & mask);\r\nqib_write_kreg(dd, idx, tval);\r\nqib_write_kreg(dd, kr_scratch, 0Ull);\r\n}\r\nspin_unlock_irqrestore(&dd->sendctrl_lock, flags);\r\nreturn only_32 ? 4 : 8;\r\n}\r\nstatic void qsfp_7322_event(struct work_struct *work)\r\n{\r\nstruct qib_qsfp_data *qd;\r\nstruct qib_pportdata *ppd;\r\nunsigned long pwrup;\r\nunsigned long flags;\r\nint ret;\r\nu32 le2;\r\nqd = container_of(work, struct qib_qsfp_data, work);\r\nppd = qd->ppd;\r\npwrup = qd->t_insert +\r\nmsecs_to_jiffies(QSFP_PWR_LAG_MSEC - QSFP_MODPRS_LAG_MSEC);\r\nmdelay(QSFP_MODPRS_LAG_MSEC);\r\nif (!qib_qsfp_mod_present(ppd)) {\r\nppd->cpspec->qsfp_data.modpresent = 0;\r\nqib_set_ib_7322_lstate(ppd, 0,\r\nQLOGIC_IB_IBCC_LINKINITCMD_DISABLE);\r\nspin_lock_irqsave(&ppd->lflags_lock, flags);\r\nppd->lflags &= ~QIBL_LINKV;\r\nspin_unlock_irqrestore(&ppd->lflags_lock, flags);\r\n} else {\r\nwhile (1) {\r\nif (time_is_before_jiffies(pwrup))\r\nbreak;\r\nmsleep(20);\r\n}\r\nret = qib_refresh_qsfp_cache(ppd, &qd->cache);\r\nif (!ret && !ppd->dd->cspec->r1) {\r\nif (QSFP_IS_ACTIVE_FAR(qd->cache.tech))\r\nle2 = LE2_QME;\r\nelse if (qd->cache.atten[1] >= qib_long_atten &&\r\nQSFP_IS_CU(qd->cache.tech))\r\nle2 = LE2_5m;\r\nelse\r\nle2 = LE2_DEFAULT;\r\n} else\r\nle2 = LE2_DEFAULT;\r\nibsd_wr_allchans(ppd, 13, (le2 << 7), BMASK(9, 7));\r\ninit_txdds_table(ppd, 0);\r\nif (!ppd->cpspec->qsfp_data.modpresent &&\r\n(ppd->lflags & (QIBL_LINKV | QIBL_IB_LINK_DISABLED))) {\r\nppd->cpspec->qsfp_data.modpresent = 1;\r\nqib_set_ib_7322_lstate(ppd, 0,\r\nQLOGIC_IB_IBCC_LINKINITCMD_SLEEP);\r\nspin_lock_irqsave(&ppd->lflags_lock, flags);\r\nppd->lflags |= QIBL_LINKV;\r\nspin_unlock_irqrestore(&ppd->lflags_lock, flags);\r\n}\r\n}\r\n}\r\nstatic void qib_init_7322_qsfp(struct qib_pportdata *ppd)\r\n{\r\nunsigned long flags;\r\nstruct qib_qsfp_data *qd = &ppd->cpspec->qsfp_data;\r\nstruct qib_devdata *dd = ppd->dd;\r\nu64 mod_prs_bit = QSFP_GPIO_MOD_PRS_N;\r\nmod_prs_bit <<= (QSFP_GPIO_PORT2_SHIFT * ppd->hw_pidx);\r\nqd->ppd = ppd;\r\nqib_qsfp_init(qd, qsfp_7322_event);\r\nspin_lock_irqsave(&dd->cspec->gpio_lock, flags);\r\ndd->cspec->extctrl |= (mod_prs_bit << SYM_LSB(EXTCtrl, GPIOInvert));\r\ndd->cspec->gpio_mask |= mod_prs_bit;\r\nqib_write_kreg(dd, kr_extctrl, dd->cspec->extctrl);\r\nqib_write_kreg(dd, kr_gpio_mask, dd->cspec->gpio_mask);\r\nspin_unlock_irqrestore(&dd->cspec->gpio_lock, flags);\r\n}\r\nstatic void set_no_qsfp_atten(struct qib_devdata *dd, int change)\r\n{\r\nchar *nxt, *str;\r\nu32 pidx, unit, port, deflt, h1;\r\nunsigned long val;\r\nint any = 0, seth1;\r\nint txdds_size;\r\nstr = txselect_list;\r\ndeflt = simple_strtoul(str, &nxt, 0);\r\nfor (pidx = 0; pidx < dd->num_pports; ++pidx)\r\ndd->pport[pidx].cpspec->no_eep = deflt;\r\ntxdds_size = TXDDS_TABLE_SZ + TXDDS_EXTRA_SZ;\r\nif (IS_QME(dd) || IS_QMH(dd))\r\ntxdds_size += TXDDS_MFG_SZ;\r\nwhile (*nxt && nxt[1]) {\r\nstr = ++nxt;\r\nunit = simple_strtoul(str, &nxt, 0);\r\nif (nxt == str || !*nxt || *nxt != ',') {\r\nwhile (*nxt && *nxt++ != ' ')\r\n;\r\ncontinue;\r\n}\r\nstr = ++nxt;\r\nport = simple_strtoul(str, &nxt, 0);\r\nif (nxt == str || *nxt != '=') {\r\nwhile (*nxt && *nxt++ != ' ')\r\n;\r\ncontinue;\r\n}\r\nstr = ++nxt;\r\nval = simple_strtoul(str, &nxt, 0);\r\nif (nxt == str) {\r\nwhile (*nxt && *nxt++ != ' ')\r\n;\r\ncontinue;\r\n}\r\nif (val >= txdds_size)\r\ncontinue;\r\nseth1 = 0;\r\nh1 = 0;\r\nif (*nxt == ',' && nxt[1]) {\r\nstr = ++nxt;\r\nh1 = (u32)simple_strtoul(str, &nxt, 0);\r\nif (nxt == str)\r\nwhile (*nxt && *nxt++ != ' ')\r\n;\r\nelse\r\nseth1 = 1;\r\n}\r\nfor (pidx = 0; dd->unit == unit && pidx < dd->num_pports;\r\n++pidx) {\r\nstruct qib_pportdata *ppd = &dd->pport[pidx];\r\nif (ppd->port != port || !ppd->link_speed_supported)\r\ncontinue;\r\nppd->cpspec->no_eep = val;\r\nif (seth1)\r\nppd->cpspec->h1_val = h1;\r\ninit_txdds_table(ppd, 1);\r\nif (IS_QMH(dd) || IS_QME(dd))\r\nqib_set_ib_7322_lstate(ppd, 0,\r\nQLOGIC_IB_IBCC_LINKINITCMD_SLEEP);\r\nany++;\r\n}\r\nif (*nxt == '\n')\r\nbreak;\r\n}\r\nif (change && !any) {\r\nfor (pidx = 0; pidx < dd->num_pports; ++pidx)\r\nif (dd->pport[pidx].link_speed_supported)\r\ninit_txdds_table(&dd->pport[pidx], 0);\r\n}\r\n}\r\nstatic int setup_txselect(const char *str, struct kernel_param *kp)\r\n{\r\nstruct qib_devdata *dd;\r\nunsigned long val;\r\nchar *n;\r\nif (strlen(str) >= MAX_ATTEN_LEN) {\r\npr_info("txselect_values string too long\n");\r\nreturn -ENOSPC;\r\n}\r\nval = simple_strtoul(str, &n, 0);\r\nif (n == str || val >= (TXDDS_TABLE_SZ + TXDDS_EXTRA_SZ +\r\nTXDDS_MFG_SZ)) {\r\npr_info("txselect_values must start with a number < %d\n",\r\nTXDDS_TABLE_SZ + TXDDS_EXTRA_SZ + TXDDS_MFG_SZ);\r\nreturn -EINVAL;\r\n}\r\nstrcpy(txselect_list, str);\r\nlist_for_each_entry(dd, &qib_dev_list, list)\r\nif (dd->deviceid == PCI_DEVICE_ID_QLOGIC_IB_7322)\r\nset_no_qsfp_atten(dd, 1);\r\nreturn 0;\r\n}\r\nstatic int qib_late_7322_initreg(struct qib_devdata *dd)\r\n{\r\nint ret = 0, n;\r\nu64 val;\r\nqib_write_kreg(dd, kr_rcvhdrentsize, dd->rcvhdrentsize);\r\nqib_write_kreg(dd, kr_rcvhdrsize, dd->rcvhdrsize);\r\nqib_write_kreg(dd, kr_rcvhdrcnt, dd->rcvhdrcnt);\r\nqib_write_kreg(dd, kr_sendpioavailaddr, dd->pioavailregs_phys);\r\nval = qib_read_kreg64(dd, kr_sendpioavailaddr);\r\nif (val != dd->pioavailregs_phys) {\r\nqib_dev_err(dd,\r\n"Catastrophic software error, SendPIOAvailAddr written as %lx, read back as %llx\n",\r\n(unsigned long) dd->pioavailregs_phys,\r\n(unsigned long long) val);\r\nret = -EINVAL;\r\n}\r\nn = dd->piobcnt2k + dd->piobcnt4k + NUM_VL15_BUFS;\r\nqib_7322_txchk_change(dd, 0, n, TXCHK_CHG_TYPE_KERN, NULL);\r\nqib_7322_txchk_change(dd, 0, n, TXCHK_CHG_TYPE_ENAB1, NULL);\r\nqib_register_observer(dd, &sendctrl_0_observer);\r\nqib_register_observer(dd, &sendctrl_1_observer);\r\ndd->control &= ~QLOGIC_IB_C_SDMAFETCHPRIOEN;\r\nqib_write_kreg(dd, kr_control, dd->control);\r\nset_no_qsfp_atten(dd, 0);\r\nfor (n = 0; n < dd->num_pports; ++n) {\r\nstruct qib_pportdata *ppd = dd->pport + n;\r\nqib_write_kreg_port(ppd, krp_senddmaprioritythld,\r\nsdma_fetch_prio & 0xf);\r\nif (dd->flags & QIB_HAS_QSFP)\r\nqib_init_7322_qsfp(ppd);\r\n}\r\ndd->control |= QLOGIC_IB_C_SDMAFETCHPRIOEN;\r\nqib_write_kreg(dd, kr_control, dd->control);\r\nreturn ret;\r\n}\r\nstatic void write_7322_init_portregs(struct qib_pportdata *ppd)\r\n{\r\nu64 val;\r\nint i;\r\nif (!ppd->link_speed_supported) {\r\nfor (i = 1; i < 8; i++)\r\nqib_write_kreg_port(ppd, krp_rxcreditvl0 + i, 0);\r\nqib_write_kreg_port(ppd, krp_ibcctrl_b, 0);\r\nqib_write_kreg(ppd->dd, kr_scratch, 0);\r\nreturn;\r\n}\r\nval = qib_read_kreg_port(ppd, krp_ibsdtestiftx);\r\nval &= ~SYM_MASK(IB_SDTEST_IF_TX_0, VL_CAP);\r\nval |= (u64)(ppd->vls_supported - 1) <<\r\nSYM_LSB(IB_SDTEST_IF_TX_0, VL_CAP);\r\nqib_write_kreg_port(ppd, krp_ibsdtestiftx, val);\r\nqib_write_kreg_port(ppd, krp_rcvbthqp, QIB_KD_QP);\r\nqib_write_kreg_port(ppd, krp_sendcheckcontrol, IBA7322_SENDCHK_PKEY |\r\nIBA7322_SENDCHK_BTHQP | IBA7322_SENDCHK_SLID |\r\nIBA7322_SENDCHK_RAW_IPV6 | IBA7322_SENDCHK_MINSZ);\r\nqib_write_kreg_port(ppd, krp_ncmodectrl,\r\nSYM_MASK(IBNCModeCtrl_0, ScrambleCapLocal));\r\nqib_write_kreg_port(ppd, krp_senddmabufmask0, 0);\r\nqib_write_kreg_port(ppd, krp_senddmabufmask1, 0);\r\nqib_write_kreg_port(ppd, krp_senddmabufmask2, 0);\r\nif (ppd->dd->cspec->r1)\r\nppd->p_sendctrl |= SYM_MASK(SendCtrl_0, ForceCreditUpToDate);\r\n}\r\nstatic void write_7322_initregs(struct qib_devdata *dd)\r\n{\r\nstruct qib_pportdata *ppd;\r\nint i, pidx;\r\nu64 val;\r\nqib_write_kreg(dd, KREG_IDX(RcvQPMulticastContext_1), 1);\r\nfor (pidx = 0; pidx < dd->num_pports; ++pidx) {\r\nunsigned n, regno;\r\nunsigned long flags;\r\nif (dd->n_krcv_queues < 2 ||\r\n!dd->pport[pidx].link_speed_supported)\r\ncontinue;\r\nppd = &dd->pport[pidx];\r\nspin_lock_irqsave(&dd->cspec->rcvmod_lock, flags);\r\nppd->p_rcvctrl |= SYM_MASK(RcvCtrl_0, RcvQPMapEnable);\r\nspin_unlock_irqrestore(&dd->cspec->rcvmod_lock, flags);\r\nregno = krp_rcvqpmaptable;\r\nval = 0;\r\nif (dd->num_pports > 1)\r\nn = dd->first_user_ctxt / dd->num_pports;\r\nelse\r\nn = dd->first_user_ctxt - 1;\r\nfor (i = 0; i < 32; ) {\r\nunsigned ctxt;\r\nif (dd->num_pports > 1)\r\nctxt = (i % n) * dd->num_pports + pidx;\r\nelse if (i % n)\r\nctxt = (i % n) + 1;\r\nelse\r\nctxt = ppd->hw_pidx;\r\nval |= ctxt << (5 * (i % 6));\r\ni++;\r\nif (i % 6 == 0) {\r\nqib_write_kreg_port(ppd, regno, val);\r\nval = 0;\r\nregno++;\r\n}\r\n}\r\nqib_write_kreg_port(ppd, regno, val);\r\n}\r\nfor (i = 0; i < dd->first_user_ctxt; i++) {\r\ndd->cspec->rcvavail_timeout[i] = rcv_int_timeout;\r\nqib_write_kreg(dd, kr_rcvavailtimeout + i, rcv_int_timeout);\r\n}\r\nval = TIDFLOW_ERRBITS;\r\nfor (i = 0; i < dd->cfgctxts; i++) {\r\nint flow;\r\nfor (flow = 0; flow < NUM_TIDFLOWS_CTXT; flow++)\r\nqib_write_ureg(dd, ur_rcvflowtable+flow, val, i);\r\n}\r\nif (dd->num_pports)\r\nsetup_7322_link_recovery(dd->pport, dd->num_pports > 1);\r\n}\r\nstatic int qib_init_7322_variables(struct qib_devdata *dd)\r\n{\r\nstruct qib_pportdata *ppd;\r\nunsigned features, pidx, sbufcnt;\r\nint ret, mtu;\r\nu32 sbufs, updthresh;\r\nppd = (struct qib_pportdata *)(dd + 1);\r\ndd->pport = ppd;\r\nppd[0].dd = dd;\r\nppd[1].dd = dd;\r\ndd->cspec = (struct qib_chip_specific *)(ppd + 2);\r\nppd[0].cpspec = (struct qib_chippport_specific *)(dd->cspec + 1);\r\nppd[1].cpspec = &ppd[0].cpspec[1];\r\nppd[0].cpspec->ppd = &ppd[0];\r\nppd[1].cpspec->ppd = &ppd[1];\r\nspin_lock_init(&dd->cspec->rcvmod_lock);\r\nspin_lock_init(&dd->cspec->gpio_lock);\r\ndd->revision = readq(&dd->kregbase[kr_revision]);\r\nif ((dd->revision & 0xffffffffU) == 0xffffffffU) {\r\nqib_dev_err(dd,\r\n"Revision register read failure, giving up initialization\n");\r\nret = -ENODEV;\r\ngoto bail;\r\n}\r\ndd->flags |= QIB_PRESENT;\r\ndd->majrev = (u8) SYM_FIELD(dd->revision, Revision_R, ChipRevMajor);\r\ndd->minrev = (u8) SYM_FIELD(dd->revision, Revision_R, ChipRevMinor);\r\ndd->cspec->r1 = dd->minrev == 1;\r\nget_7322_chip_params(dd);\r\nfeatures = qib_7322_boardname(dd);\r\nsbufcnt = dd->piobcnt2k + dd->piobcnt4k +\r\nNUM_VL15_BUFS + BITS_PER_LONG - 1;\r\nsbufcnt /= BITS_PER_LONG;\r\ndd->cspec->sendchkenable = kmalloc(sbufcnt *\r\nsizeof(*dd->cspec->sendchkenable), GFP_KERNEL);\r\ndd->cspec->sendgrhchk = kmalloc(sbufcnt *\r\nsizeof(*dd->cspec->sendgrhchk), GFP_KERNEL);\r\ndd->cspec->sendibchk = kmalloc(sbufcnt *\r\nsizeof(*dd->cspec->sendibchk), GFP_KERNEL);\r\nif (!dd->cspec->sendchkenable || !dd->cspec->sendgrhchk ||\r\n!dd->cspec->sendibchk) {\r\nqib_dev_err(dd, "Failed allocation for hdrchk bitmaps\n");\r\nret = -ENOMEM;\r\ngoto bail;\r\n}\r\nppd = dd->pport;\r\ndd->gpio_sda_num = _QIB_GPIO_SDA_NUM;\r\ndd->gpio_scl_num = _QIB_GPIO_SCL_NUM;\r\ndd->twsi_eeprom_dev = QIB_TWSI_EEPROM_DEV;\r\ndd->flags |= QIB_HAS_INTX | QIB_HAS_LINK_LATENCY |\r\nQIB_NODMA_RTAIL | QIB_HAS_VLSUPP | QIB_HAS_HDRSUPP |\r\nQIB_HAS_THRESH_UPDATE |\r\n(sdma_idle_cnt ? QIB_HAS_SDMA_TIMEOUT : 0);\r\ndd->flags |= qib_special_trigger ?\r\nQIB_USE_SPCL_TRIG : QIB_HAS_SEND_DMA;\r\nqib_7322_set_baseaddrs(dd);\r\nmtu = ib_mtu_enum_to_int(qib_ibmtu);\r\nif (mtu == -1)\r\nmtu = QIB_DEFAULT_MTU;\r\ndd->cspec->int_enable_mask = QIB_I_BITSEXTANT;\r\ndd->cspec->hwerrmask = ~0ULL;\r\ndd->cspec->hwerrmask &=\r\n~(SYM_MASK(HwErrMask, IBSerdesPClkNotDetectMask_0) |\r\nSYM_MASK(HwErrMask, IBSerdesPClkNotDetectMask_1) |\r\nHWE_MASK(LATriggered));\r\nfor (pidx = 0; pidx < NUM_IB_PORTS; ++pidx) {\r\nstruct qib_chippport_specific *cp = ppd->cpspec;\r\nppd->link_speed_supported = features & PORT_SPD_CAP;\r\nfeatures >>= PORT_SPD_CAP_SHIFT;\r\nif (!ppd->link_speed_supported) {\r\ndd->skip_kctxt_mask |= 1 << pidx;\r\nif (pidx == 0) {\r\nqib_write_kreg_port(ppd, krp_rcvctrl, 0);\r\nqib_write_kreg_port(ppd, krp_ibcctrl_a, 0);\r\nppd[0] = ppd[1];\r\ndd->cspec->hwerrmask &= ~(SYM_MASK(HwErrMask,\r\nIBSerdesPClkNotDetectMask_0)\r\n| SYM_MASK(HwErrMask,\r\nSDmaMemReadErrMask_0));\r\ndd->cspec->int_enable_mask &= ~(\r\nSYM_MASK(IntMask, SDmaCleanupDoneMask_0) |\r\nSYM_MASK(IntMask, SDmaIdleIntMask_0) |\r\nSYM_MASK(IntMask, SDmaProgressIntMask_0) |\r\nSYM_MASK(IntMask, SDmaIntMask_0) |\r\nSYM_MASK(IntMask, ErrIntMask_0) |\r\nSYM_MASK(IntMask, SendDoneIntMask_0));\r\n} else {\r\nqib_write_kreg_port(ppd, krp_rcvctrl, 0);\r\nqib_write_kreg_port(ppd, krp_ibcctrl_a, 0);\r\ndd->cspec->hwerrmask &= ~(SYM_MASK(HwErrMask,\r\nIBSerdesPClkNotDetectMask_1)\r\n| SYM_MASK(HwErrMask,\r\nSDmaMemReadErrMask_1));\r\ndd->cspec->int_enable_mask &= ~(\r\nSYM_MASK(IntMask, SDmaCleanupDoneMask_1) |\r\nSYM_MASK(IntMask, SDmaIdleIntMask_1) |\r\nSYM_MASK(IntMask, SDmaProgressIntMask_1) |\r\nSYM_MASK(IntMask, SDmaIntMask_1) |\r\nSYM_MASK(IntMask, ErrIntMask_1) |\r\nSYM_MASK(IntMask, SendDoneIntMask_1));\r\n}\r\ncontinue;\r\n}\r\ndd->num_pports++;\r\nret = qib_init_pportdata(ppd, dd, pidx, dd->num_pports);\r\nif (ret) {\r\ndd->num_pports--;\r\ngoto bail;\r\n}\r\nppd->link_width_supported = IB_WIDTH_1X | IB_WIDTH_4X;\r\nppd->link_width_enabled = IB_WIDTH_4X;\r\nppd->link_speed_enabled = ppd->link_speed_supported;\r\nppd->link_width_active = IB_WIDTH_4X;\r\nppd->link_speed_active = QIB_IB_SDR;\r\nppd->delay_mult = ib_rate_to_delay[IB_RATE_10_GBPS];\r\nswitch (qib_num_cfg_vls) {\r\ncase 1:\r\nppd->vls_supported = IB_VL_VL0;\r\nbreak;\r\ncase 2:\r\nppd->vls_supported = IB_VL_VL0_1;\r\nbreak;\r\ndefault:\r\nqib_devinfo(dd->pcidev,\r\n"Invalid num_vls %u, using 4 VLs\n",\r\nqib_num_cfg_vls);\r\nqib_num_cfg_vls = 4;\r\ncase 4:\r\nppd->vls_supported = IB_VL_VL0_3;\r\nbreak;\r\ncase 8:\r\nif (mtu <= 2048)\r\nppd->vls_supported = IB_VL_VL0_7;\r\nelse {\r\nqib_devinfo(dd->pcidev,\r\n"Invalid num_vls %u for MTU %d "\r\n", using 4 VLs\n",\r\nqib_num_cfg_vls, mtu);\r\nppd->vls_supported = IB_VL_VL0_3;\r\nqib_num_cfg_vls = 4;\r\n}\r\nbreak;\r\n}\r\nppd->vls_operational = ppd->vls_supported;\r\ninit_waitqueue_head(&cp->autoneg_wait);\r\nINIT_DELAYED_WORK(&cp->autoneg_work,\r\nautoneg_7322_work);\r\nif (ppd->dd->cspec->r1)\r\nINIT_DELAYED_WORK(&cp->ipg_work, ipg_7322_work);\r\nif (!(dd->flags & QIB_HAS_QSFP)) {\r\nif (!IS_QMH(dd) && !IS_QME(dd))\r\nqib_devinfo(dd->pcidev,\r\n"IB%u:%u: Unknown mezzanine card type\n",\r\ndd->unit, ppd->port);\r\ncp->h1_val = IS_QMH(dd) ? H1_FORCE_QMH : H1_FORCE_QME;\r\nppd->cpspec->no_eep = IS_QMH(dd) ?\r\nTXDDS_TABLE_SZ + 2 : TXDDS_TABLE_SZ + 4;\r\n} else\r\ncp->h1_val = H1_FORCE_VAL;\r\nif (!qib_mini_init)\r\nwrite_7322_init_portregs(ppd);\r\ninit_timer(&cp->chase_timer);\r\ncp->chase_timer.function = reenable_chase;\r\ncp->chase_timer.data = (unsigned long)ppd;\r\nppd++;\r\n}\r\ndd->rcvhdrentsize = qib_rcvhdrentsize ?\r\nqib_rcvhdrentsize : QIB_RCVHDR_ENTSIZE;\r\ndd->rcvhdrsize = qib_rcvhdrsize ?\r\nqib_rcvhdrsize : QIB_DFLT_RCVHDRSIZE;\r\ndd->rhf_offset = dd->rcvhdrentsize - sizeof(u64) / sizeof(u32);\r\ndd->rcvegrbufsize = max(mtu, 2048);\r\nBUG_ON(!is_power_of_2(dd->rcvegrbufsize));\r\ndd->rcvegrbufsize_shift = ilog2(dd->rcvegrbufsize);\r\nqib_7322_tidtemplate(dd);\r\ndd->rhdrhead_intr_off =\r\n(u64) rcv_int_count << IBA7322_HDRHEAD_PKTINT_SHIFT;\r\ninit_timer(&dd->stats_timer);\r\ndd->stats_timer.function = qib_get_7322_faststats;\r\ndd->stats_timer.data = (unsigned long) dd;\r\ndd->ureg_align = 0x10000;\r\ndd->piosize2kmax_dwords = dd->piosize2k >> 2;\r\nqib_7322_config_ctxts(dd);\r\nqib_set_ctxtcnt(dd);\r\nif (qib_wc_pat) {\r\nresource_size_t vl15off;\r\nret = init_chip_wc_pat(dd, 0);\r\nif (ret)\r\ngoto bail;\r\nvl15off = dd->physaddr + (dd->piobufbase >> 32) +\r\ndd->piobcnt4k * dd->align4k;\r\ndd->piovl15base = ioremap_nocache(vl15off,\r\nNUM_VL15_BUFS * dd->align4k);\r\nif (!dd->piovl15base) {\r\nret = -ENOMEM;\r\ngoto bail;\r\n}\r\n}\r\nqib_7322_set_baseaddrs(dd);\r\nret = 0;\r\nif (qib_mini_init)\r\ngoto bail;\r\nif (!dd->num_pports) {\r\nqib_dev_err(dd, "No ports enabled, giving up initialization\n");\r\ngoto bail;\r\n}\r\nwrite_7322_initregs(dd);\r\nret = qib_create_ctxts(dd);\r\ninit_7322_cntrnames(dd);\r\nupdthresh = 8U;\r\nif (dd->flags & QIB_HAS_SEND_DMA) {\r\ndd->cspec->sdmabufcnt = dd->piobcnt4k;\r\nsbufs = updthresh > 3 ? updthresh : 3;\r\n} else {\r\ndd->cspec->sdmabufcnt = 0;\r\nsbufs = dd->piobcnt4k;\r\n}\r\ndd->cspec->lastbuf_for_pio = dd->piobcnt2k + dd->piobcnt4k -\r\ndd->cspec->sdmabufcnt;\r\ndd->lastctxt_piobuf = dd->cspec->lastbuf_for_pio - sbufs;\r\ndd->cspec->lastbuf_for_pio--;\r\ndd->last_pio = dd->cspec->lastbuf_for_pio;\r\ndd->pbufsctxt = (dd->cfgctxts > dd->first_user_ctxt) ?\r\ndd->lastctxt_piobuf / (dd->cfgctxts - dd->first_user_ctxt) : 0;\r\nif (dd->pbufsctxt >= 2 && dd->pbufsctxt - 2 < updthresh)\r\nupdthresh = dd->pbufsctxt - 2;\r\ndd->cspec->updthresh_dflt = updthresh;\r\ndd->cspec->updthresh = updthresh;\r\ndd->sendctrl |= ((updthresh & SYM_RMASK(SendCtrl, AvailUpdThld))\r\n<< SYM_LSB(SendCtrl, AvailUpdThld)) |\r\nSYM_MASK(SendCtrl, SendBufAvailPad64Byte);\r\ndd->psxmitwait_supported = 1;\r\ndd->psxmitwait_check_rate = QIB_7322_PSXMITWAIT_CHECK_RATE;\r\nbail:\r\nif (!dd->ctxtcnt)\r\ndd->ctxtcnt = 1;\r\nreturn ret;\r\n}\r\nstatic u32 __iomem *qib_7322_getsendbuf(struct qib_pportdata *ppd, u64 pbc,\r\nu32 *pbufnum)\r\n{\r\nu32 first, last, plen = pbc & QIB_PBC_LENGTH_MASK;\r\nstruct qib_devdata *dd = ppd->dd;\r\nif (pbc & PBC_7322_VL15_SEND) {\r\nfirst = dd->piobcnt2k + dd->piobcnt4k + ppd->hw_pidx;\r\nlast = first;\r\n} else {\r\nif ((plen + 1) > dd->piosize2kmax_dwords)\r\nfirst = dd->piobcnt2k;\r\nelse\r\nfirst = 0;\r\nlast = dd->cspec->lastbuf_for_pio;\r\n}\r\nreturn qib_getsendbuf_range(dd, pbufnum, first, last);\r\n}\r\nstatic void qib_set_cntr_7322_sample(struct qib_pportdata *ppd, u32 intv,\r\nu32 start)\r\n{\r\nqib_write_kreg_port(ppd, krp_psinterval, intv);\r\nqib_write_kreg_port(ppd, krp_psstart, start);\r\n}\r\nstatic void qib_sdma_set_7322_desc_cnt(struct qib_pportdata *ppd, unsigned cnt)\r\n{\r\nqib_write_kreg_port(ppd, krp_senddmadesccnt, cnt);\r\n}\r\nstatic void dump_sdma_7322_state(struct qib_pportdata *ppd)\r\n{\r\nu64 reg, reg1, reg2;\r\nreg = qib_read_kreg_port(ppd, krp_senddmastatus);\r\nqib_dev_porterr(ppd->dd, ppd->port,\r\n"SDMA senddmastatus: 0x%016llx\n", reg);\r\nreg = qib_read_kreg_port(ppd, krp_sendctrl);\r\nqib_dev_porterr(ppd->dd, ppd->port,\r\n"SDMA sendctrl: 0x%016llx\n", reg);\r\nreg = qib_read_kreg_port(ppd, krp_senddmabase);\r\nqib_dev_porterr(ppd->dd, ppd->port,\r\n"SDMA senddmabase: 0x%016llx\n", reg);\r\nreg = qib_read_kreg_port(ppd, krp_senddmabufmask0);\r\nreg1 = qib_read_kreg_port(ppd, krp_senddmabufmask1);\r\nreg2 = qib_read_kreg_port(ppd, krp_senddmabufmask2);\r\nqib_dev_porterr(ppd->dd, ppd->port,\r\n"SDMA senddmabufmask 0:%llx 1:%llx 2:%llx\n",\r\nreg, reg1, reg2);\r\nreg = qib_read_kreg_port(ppd, krp_senddmabuf_use0);\r\nqib_write_kreg_port(ppd, krp_senddmabuf_use0, reg);\r\nreg1 = qib_read_kreg_port(ppd, krp_senddmabuf_use1);\r\nqib_write_kreg_port(ppd, krp_senddmabuf_use0, reg1);\r\nreg2 = qib_read_kreg_port(ppd, krp_senddmabuf_use2);\r\nqib_write_kreg_port(ppd, krp_senddmabuf_use0, reg2);\r\nqib_dev_porterr(ppd->dd, ppd->port,\r\n"SDMA current senddmabuf_use 0:%llx 1:%llx 2:%llx\n",\r\nreg, reg1, reg2);\r\nreg = qib_read_kreg_port(ppd, krp_senddmabuf_use0);\r\nreg1 = qib_read_kreg_port(ppd, krp_senddmabuf_use1);\r\nreg2 = qib_read_kreg_port(ppd, krp_senddmabuf_use2);\r\nqib_dev_porterr(ppd->dd, ppd->port,\r\n"SDMA cleared senddmabuf_use 0:%llx 1:%llx 2:%llx\n",\r\nreg, reg1, reg2);\r\nreg = qib_read_kreg_port(ppd, krp_senddmatail);\r\nqib_dev_porterr(ppd->dd, ppd->port,\r\n"SDMA senddmatail: 0x%016llx\n", reg);\r\nreg = qib_read_kreg_port(ppd, krp_senddmahead);\r\nqib_dev_porterr(ppd->dd, ppd->port,\r\n"SDMA senddmahead: 0x%016llx\n", reg);\r\nreg = qib_read_kreg_port(ppd, krp_senddmaheadaddr);\r\nqib_dev_porterr(ppd->dd, ppd->port,\r\n"SDMA senddmaheadaddr: 0x%016llx\n", reg);\r\nreg = qib_read_kreg_port(ppd, krp_senddmalengen);\r\nqib_dev_porterr(ppd->dd, ppd->port,\r\n"SDMA senddmalengen: 0x%016llx\n", reg);\r\nreg = qib_read_kreg_port(ppd, krp_senddmadesccnt);\r\nqib_dev_porterr(ppd->dd, ppd->port,\r\n"SDMA senddmadesccnt: 0x%016llx\n", reg);\r\nreg = qib_read_kreg_port(ppd, krp_senddmaidlecnt);\r\nqib_dev_porterr(ppd->dd, ppd->port,\r\n"SDMA senddmaidlecnt: 0x%016llx\n", reg);\r\nreg = qib_read_kreg_port(ppd, krp_senddmaprioritythld);\r\nqib_dev_porterr(ppd->dd, ppd->port,\r\n"SDMA senddmapriorityhld: 0x%016llx\n", reg);\r\nreg = qib_read_kreg_port(ppd, krp_senddmareloadcnt);\r\nqib_dev_porterr(ppd->dd, ppd->port,\r\n"SDMA senddmareloadcnt: 0x%016llx\n", reg);\r\ndump_sdma_state(ppd);\r\n}\r\nstatic void qib_7322_sdma_init_early(struct qib_pportdata *ppd)\r\n{\r\nppd->sdma_state.set_state_action = sdma_7322_action_table;\r\n}\r\nstatic int init_sdma_7322_regs(struct qib_pportdata *ppd)\r\n{\r\nstruct qib_devdata *dd = ppd->dd;\r\nunsigned lastbuf, erstbuf;\r\nu64 senddmabufmask[3] = { 0 };\r\nint n, ret = 0;\r\nqib_write_kreg_port(ppd, krp_senddmabase, ppd->sdma_descq_phys);\r\nqib_sdma_7322_setlengen(ppd);\r\nqib_sdma_update_7322_tail(ppd, 0);\r\nqib_write_kreg_port(ppd, krp_senddmareloadcnt, sdma_idle_cnt);\r\nqib_write_kreg_port(ppd, krp_senddmadesccnt, 0);\r\nqib_write_kreg_port(ppd, krp_senddmaheadaddr, ppd->sdma_head_phys);\r\nif (dd->num_pports)\r\nn = dd->cspec->sdmabufcnt / dd->num_pports;\r\nelse\r\nn = dd->cspec->sdmabufcnt;\r\nerstbuf = (dd->piobcnt2k + dd->piobcnt4k) -\r\n((dd->num_pports == 1 || ppd->port == 2) ? n :\r\ndd->cspec->sdmabufcnt);\r\nlastbuf = erstbuf + n;\r\nppd->sdma_state.first_sendbuf = erstbuf;\r\nppd->sdma_state.last_sendbuf = lastbuf;\r\nfor (; erstbuf < lastbuf; ++erstbuf) {\r\nunsigned word = erstbuf / BITS_PER_LONG;\r\nunsigned bit = erstbuf & (BITS_PER_LONG - 1);\r\nBUG_ON(word >= 3);\r\nsenddmabufmask[word] |= 1ULL << bit;\r\n}\r\nqib_write_kreg_port(ppd, krp_senddmabufmask0, senddmabufmask[0]);\r\nqib_write_kreg_port(ppd, krp_senddmabufmask1, senddmabufmask[1]);\r\nqib_write_kreg_port(ppd, krp_senddmabufmask2, senddmabufmask[2]);\r\nreturn ret;\r\n}\r\nstatic u16 qib_sdma_7322_gethead(struct qib_pportdata *ppd)\r\n{\r\nstruct qib_devdata *dd = ppd->dd;\r\nint sane;\r\nint use_dmahead;\r\nu16 swhead;\r\nu16 swtail;\r\nu16 cnt;\r\nu16 hwhead;\r\nuse_dmahead = __qib_sdma_running(ppd) &&\r\n(dd->flags & QIB_HAS_SDMA_TIMEOUT);\r\nretry:\r\nhwhead = use_dmahead ?\r\n(u16) le64_to_cpu(*ppd->sdma_head_dma) :\r\n(u16) qib_read_kreg_port(ppd, krp_senddmahead);\r\nswhead = ppd->sdma_descq_head;\r\nswtail = ppd->sdma_descq_tail;\r\ncnt = ppd->sdma_descq_cnt;\r\nif (swhead < swtail)\r\nsane = (hwhead >= swhead) & (hwhead <= swtail);\r\nelse if (swhead > swtail)\r\nsane = ((hwhead >= swhead) && (hwhead < cnt)) ||\r\n(hwhead <= swtail);\r\nelse\r\nsane = (hwhead == swhead);\r\nif (unlikely(!sane)) {\r\nif (use_dmahead) {\r\nuse_dmahead = 0;\r\ngoto retry;\r\n}\r\nhwhead = swhead;\r\n}\r\nreturn hwhead;\r\n}\r\nstatic int qib_sdma_7322_busy(struct qib_pportdata *ppd)\r\n{\r\nu64 hwstatus = qib_read_kreg_port(ppd, krp_senddmastatus);\r\nreturn (hwstatus & SYM_MASK(SendDmaStatus_0, ScoreBoardDrainInProg)) ||\r\n(hwstatus & SYM_MASK(SendDmaStatus_0, HaltInProg)) ||\r\n!(hwstatus & SYM_MASK(SendDmaStatus_0, InternalSDmaHalt)) ||\r\n!(hwstatus & SYM_MASK(SendDmaStatus_0, ScbEmpty));\r\n}\r\nstatic u32 qib_7322_setpbc_control(struct qib_pportdata *ppd, u32 plen,\r\nu8 srate, u8 vl)\r\n{\r\nu8 snd_mult = ppd->delay_mult;\r\nu8 rcv_mult = ib_rate_to_delay[srate];\r\nu32 ret;\r\nret = rcv_mult > snd_mult ? ((plen + 1) >> 1) * snd_mult : 0;\r\nif (vl == 15)\r\nret |= PBC_7322_VL15_SEND_CTRL;\r\nelse\r\nret |= vl << PBC_VL_NUM_LSB;\r\nret |= ((u32)(ppd->hw_pidx)) << PBC_PORT_SEL_LSB;\r\nreturn ret;\r\n}\r\nstatic void qib_7322_initvl15_bufs(struct qib_devdata *dd)\r\n{\r\nunsigned vl15bufs;\r\nvl15bufs = dd->piobcnt2k + dd->piobcnt4k;\r\nqib_chg_pioavailkernel(dd, vl15bufs, NUM_VL15_BUFS,\r\nTXCHK_CHG_TYPE_KERN, NULL);\r\n}\r\nstatic void qib_7322_init_ctxt(struct qib_ctxtdata *rcd)\r\n{\r\nif (rcd->ctxt < NUM_IB_PORTS) {\r\nif (rcd->dd->num_pports > 1) {\r\nrcd->rcvegrcnt = KCTXT0_EGRCNT / 2;\r\nrcd->rcvegr_tid_base = rcd->ctxt ? rcd->rcvegrcnt : 0;\r\n} else {\r\nrcd->rcvegrcnt = KCTXT0_EGRCNT;\r\nrcd->rcvegr_tid_base = 0;\r\n}\r\n} else {\r\nrcd->rcvegrcnt = rcd->dd->cspec->rcvegrcnt;\r\nrcd->rcvegr_tid_base = KCTXT0_EGRCNT +\r\n(rcd->ctxt - NUM_IB_PORTS) * rcd->rcvegrcnt;\r\n}\r\n}\r\nstatic void qib_7322_txchk_change(struct qib_devdata *dd, u32 start,\r\nu32 len, u32 which, struct qib_ctxtdata *rcd)\r\n{\r\nint i;\r\nconst int last = start + len - 1;\r\nconst int lastr = last / BITS_PER_LONG;\r\nu32 sleeps = 0;\r\nint wait = rcd != NULL;\r\nunsigned long flags;\r\nwhile (wait) {\r\nunsigned long shadow;\r\nint cstart, previ = -1;\r\nfor (cstart = start; cstart <= last; cstart++) {\r\ni = ((2 * cstart) + QLOGIC_IB_SENDPIOAVAIL_BUSY_SHIFT)\r\n/ BITS_PER_LONG;\r\nif (i != previ) {\r\nshadow = (unsigned long)\r\nle64_to_cpu(dd->pioavailregs_dma[i]);\r\nprevi = i;\r\n}\r\nif (test_bit(((2 * cstart) +\r\nQLOGIC_IB_SENDPIOAVAIL_BUSY_SHIFT)\r\n% BITS_PER_LONG, &shadow))\r\nbreak;\r\n}\r\nif (cstart > last)\r\nbreak;\r\nif (sleeps == QTXSLEEPS)\r\nbreak;\r\nsendctrl_7322_mod(dd->pport, QIB_SENDCTRL_AVAIL_BLIP);\r\nsleeps++;\r\nmsleep(20);\r\n}\r\nswitch (which) {\r\ncase TXCHK_CHG_TYPE_DIS1:\r\nfor (i = start; i <= last; i++)\r\nclear_bit(i, dd->cspec->sendchkenable);\r\nbreak;\r\ncase TXCHK_CHG_TYPE_ENAB1:\r\nqib_read_kreg32(dd, kr_scratch);\r\nfor (i = start; i <= last; i++)\r\nset_bit(i, dd->cspec->sendchkenable);\r\nbreak;\r\ncase TXCHK_CHG_TYPE_KERN:\r\nfor (i = start; i <= last; i++) {\r\nset_bit(i, dd->cspec->sendibchk);\r\nclear_bit(i, dd->cspec->sendgrhchk);\r\n}\r\nspin_lock_irqsave(&dd->uctxt_lock, flags);\r\nfor (i = dd->first_user_ctxt;\r\ndd->cspec->updthresh != dd->cspec->updthresh_dflt\r\n&& i < dd->cfgctxts; i++)\r\nif (dd->rcd[i] && dd->rcd[i]->subctxt_cnt &&\r\n((dd->rcd[i]->piocnt / dd->rcd[i]->subctxt_cnt) - 1)\r\n< dd->cspec->updthresh_dflt)\r\nbreak;\r\nspin_unlock_irqrestore(&dd->uctxt_lock, flags);\r\nif (i == dd->cfgctxts) {\r\nspin_lock_irqsave(&dd->sendctrl_lock, flags);\r\ndd->cspec->updthresh = dd->cspec->updthresh_dflt;\r\ndd->sendctrl &= ~SYM_MASK(SendCtrl, AvailUpdThld);\r\ndd->sendctrl |= (dd->cspec->updthresh &\r\nSYM_RMASK(SendCtrl, AvailUpdThld)) <<\r\nSYM_LSB(SendCtrl, AvailUpdThld);\r\nspin_unlock_irqrestore(&dd->sendctrl_lock, flags);\r\nsendctrl_7322_mod(dd->pport, QIB_SENDCTRL_AVAIL_BLIP);\r\n}\r\nbreak;\r\ncase TXCHK_CHG_TYPE_USER:\r\nfor (i = start; i <= last; i++) {\r\nclear_bit(i, dd->cspec->sendibchk);\r\nset_bit(i, dd->cspec->sendgrhchk);\r\n}\r\nspin_lock_irqsave(&dd->sendctrl_lock, flags);\r\nif (rcd && rcd->subctxt_cnt && ((rcd->piocnt\r\n/ rcd->subctxt_cnt) - 1) < dd->cspec->updthresh) {\r\ndd->cspec->updthresh = (rcd->piocnt /\r\nrcd->subctxt_cnt) - 1;\r\ndd->sendctrl &= ~SYM_MASK(SendCtrl, AvailUpdThld);\r\ndd->sendctrl |= (dd->cspec->updthresh &\r\nSYM_RMASK(SendCtrl, AvailUpdThld))\r\n<< SYM_LSB(SendCtrl, AvailUpdThld);\r\nspin_unlock_irqrestore(&dd->sendctrl_lock, flags);\r\nsendctrl_7322_mod(dd->pport, QIB_SENDCTRL_AVAIL_BLIP);\r\n} else\r\nspin_unlock_irqrestore(&dd->sendctrl_lock, flags);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nfor (i = start / BITS_PER_LONG; which >= 2 && i <= lastr; ++i)\r\nqib_write_kreg(dd, kr_sendcheckmask + i,\r\ndd->cspec->sendchkenable[i]);\r\nfor (i = start / BITS_PER_LONG; which < 2 && i <= lastr; ++i) {\r\nqib_write_kreg(dd, kr_sendgrhcheckmask + i,\r\ndd->cspec->sendgrhchk[i]);\r\nqib_write_kreg(dd, kr_sendibpktmask + i,\r\ndd->cspec->sendibchk[i]);\r\n}\r\nqib_read_kreg32(dd, kr_scratch);\r\n}\r\nstatic void writescratch(struct qib_devdata *dd, u32 val)\r\n{\r\nqib_write_kreg(dd, kr_scratch, val);\r\n}\r\nstatic int qib_7322_tempsense_rd(struct qib_devdata *dd, int regnum)\r\n{\r\nreturn -ENXIO;\r\n}\r\nstruct qib_devdata *qib_init_iba7322_funcs(struct pci_dev *pdev,\r\nconst struct pci_device_id *ent)\r\n{\r\nstruct qib_devdata *dd;\r\nint ret, i;\r\nu32 tabsize, actual_cnt = 0;\r\ndd = qib_alloc_devdata(pdev,\r\nNUM_IB_PORTS * sizeof(struct qib_pportdata) +\r\nsizeof(struct qib_chip_specific) +\r\nNUM_IB_PORTS * sizeof(struct qib_chippport_specific));\r\nif (IS_ERR(dd))\r\ngoto bail;\r\ndd->f_bringup_serdes = qib_7322_bringup_serdes;\r\ndd->f_cleanup = qib_setup_7322_cleanup;\r\ndd->f_clear_tids = qib_7322_clear_tids;\r\ndd->f_free_irq = qib_7322_free_irq;\r\ndd->f_get_base_info = qib_7322_get_base_info;\r\ndd->f_get_msgheader = qib_7322_get_msgheader;\r\ndd->f_getsendbuf = qib_7322_getsendbuf;\r\ndd->f_gpio_mod = gpio_7322_mod;\r\ndd->f_eeprom_wen = qib_7322_eeprom_wen;\r\ndd->f_hdrqempty = qib_7322_hdrqempty;\r\ndd->f_ib_updown = qib_7322_ib_updown;\r\ndd->f_init_ctxt = qib_7322_init_ctxt;\r\ndd->f_initvl15_bufs = qib_7322_initvl15_bufs;\r\ndd->f_intr_fallback = qib_7322_intr_fallback;\r\ndd->f_late_initreg = qib_late_7322_initreg;\r\ndd->f_setpbc_control = qib_7322_setpbc_control;\r\ndd->f_portcntr = qib_portcntr_7322;\r\ndd->f_put_tid = qib_7322_put_tid;\r\ndd->f_quiet_serdes = qib_7322_mini_quiet_serdes;\r\ndd->f_rcvctrl = rcvctrl_7322_mod;\r\ndd->f_read_cntrs = qib_read_7322cntrs;\r\ndd->f_read_portcntrs = qib_read_7322portcntrs;\r\ndd->f_reset = qib_do_7322_reset;\r\ndd->f_init_sdma_regs = init_sdma_7322_regs;\r\ndd->f_sdma_busy = qib_sdma_7322_busy;\r\ndd->f_sdma_gethead = qib_sdma_7322_gethead;\r\ndd->f_sdma_sendctrl = qib_7322_sdma_sendctrl;\r\ndd->f_sdma_set_desc_cnt = qib_sdma_set_7322_desc_cnt;\r\ndd->f_sdma_update_tail = qib_sdma_update_7322_tail;\r\ndd->f_sendctrl = sendctrl_7322_mod;\r\ndd->f_set_armlaunch = qib_set_7322_armlaunch;\r\ndd->f_set_cntr_sample = qib_set_cntr_7322_sample;\r\ndd->f_iblink_state = qib_7322_iblink_state;\r\ndd->f_ibphys_portstate = qib_7322_phys_portstate;\r\ndd->f_get_ib_cfg = qib_7322_get_ib_cfg;\r\ndd->f_set_ib_cfg = qib_7322_set_ib_cfg;\r\ndd->f_set_ib_loopback = qib_7322_set_loopback;\r\ndd->f_get_ib_table = qib_7322_get_ib_table;\r\ndd->f_set_ib_table = qib_7322_set_ib_table;\r\ndd->f_set_intr_state = qib_7322_set_intr_state;\r\ndd->f_setextled = qib_setup_7322_setextled;\r\ndd->f_txchk_change = qib_7322_txchk_change;\r\ndd->f_update_usrhead = qib_update_7322_usrhead;\r\ndd->f_wantpiobuf_intr = qib_wantpiobuf_7322_intr;\r\ndd->f_xgxs_reset = qib_7322_mini_pcs_reset;\r\ndd->f_sdma_hw_clean_up = qib_7322_sdma_hw_clean_up;\r\ndd->f_sdma_hw_start_up = qib_7322_sdma_hw_start_up;\r\ndd->f_sdma_init_early = qib_7322_sdma_init_early;\r\ndd->f_writescratch = writescratch;\r\ndd->f_tempsense_rd = qib_7322_tempsense_rd;\r\n#ifdef CONFIG_INFINIBAND_QIB_DCA\r\ndd->f_notify_dca = qib_7322_notify_dca;\r\n#endif\r\nret = qib_pcie_ddinit(dd, pdev, ent);\r\nif (ret < 0)\r\ngoto bail_free;\r\nret = qib_init_7322_variables(dd);\r\nif (ret)\r\ngoto bail_cleanup;\r\nif (qib_mini_init || !dd->num_pports)\r\ngoto bail;\r\ntabsize = dd->first_user_ctxt + ARRAY_SIZE(irq_table);\r\nfor (i = 0; i < tabsize; i++)\r\nif ((i < ARRAY_SIZE(irq_table) &&\r\nirq_table[i].port <= dd->num_pports) ||\r\n(i >= ARRAY_SIZE(irq_table) &&\r\ndd->rcd[i - ARRAY_SIZE(irq_table)]))\r\nactual_cnt++;\r\nif (qib_krcvq01_no_msi)\r\nactual_cnt -= dd->num_pports;\r\ntabsize = actual_cnt;\r\ndd->cspec->msix_entries = kzalloc(tabsize *\r\nsizeof(struct qib_msix_entry), GFP_KERNEL);\r\nif (!dd->cspec->msix_entries) {\r\nqib_dev_err(dd, "No memory for MSIx table\n");\r\ntabsize = 0;\r\n}\r\nfor (i = 0; i < tabsize; i++)\r\ndd->cspec->msix_entries[i].msix.entry = i;\r\nif (qib_pcie_params(dd, 8, &tabsize, dd->cspec->msix_entries))\r\nqib_dev_err(dd,\r\n"Failed to setup PCIe or interrupts; continuing anyway\n");\r\ndd->cspec->num_msix_entries = tabsize;\r\nqib_setup_7322_interrupt(dd, 1);\r\nqib_write_kreg(dd, kr_hwdiagctrl, 0);\r\n#ifdef CONFIG_INFINIBAND_QIB_DCA\r\nif (!dca_add_requester(&pdev->dev)) {\r\nqib_devinfo(dd->pcidev, "DCA enabled\n");\r\ndd->flags |= QIB_DCA_ENABLED;\r\nqib_setup_dca(dd);\r\n}\r\n#endif\r\ngoto bail;\r\nbail_cleanup:\r\nqib_pcie_ddcleanup(dd);\r\nbail_free:\r\nqib_free_devdata(dd);\r\ndd = ERR_PTR(ret);\r\nbail:\r\nreturn dd;\r\n}\r\nstatic void set_txdds(struct qib_pportdata *ppd, int ridx,\r\nconst struct txdds_ent *tp)\r\n{\r\nstruct qib_devdata *dd = ppd->dd;\r\nu32 pack_ent;\r\nint regidx;\r\nregidx = KREG_IBPORT_IDX(IBSD_DDS_MAP_TABLE) + ridx;\r\nif (ppd->hw_pidx)\r\nregidx += (dd->palign / sizeof(u64));\r\npack_ent = tp->amp << DDS_ENT_AMP_LSB;\r\npack_ent |= tp->main << DDS_ENT_MAIN_LSB;\r\npack_ent |= tp->pre << DDS_ENT_PRE_LSB;\r\npack_ent |= tp->post << DDS_ENT_POST_LSB;\r\nqib_write_kreg(dd, regidx, pack_ent);\r\nqib_write_kreg(ppd->dd, kr_scratch, 0);\r\n}\r\nstatic const struct txdds_ent *get_atten_table(const struct txdds_ent *txdds,\r\nunsigned atten)\r\n{\r\nif (atten <= 2)\r\natten = 1;\r\nelse if (atten > TXDDS_TABLE_SZ)\r\natten = TXDDS_TABLE_SZ - 1;\r\nelse\r\natten--;\r\nreturn txdds + atten;\r\n}\r\nstatic void find_best_ent(struct qib_pportdata *ppd,\r\nconst struct txdds_ent **sdr_dds,\r\nconst struct txdds_ent **ddr_dds,\r\nconst struct txdds_ent **qdr_dds, int override)\r\n{\r\nstruct qib_qsfp_cache *qd = &ppd->cpspec->qsfp_data.cache;\r\nint idx;\r\nfor (idx = 0; !override && idx < ARRAY_SIZE(vendor_txdds); ++idx) {\r\nconst struct vendor_txdds_ent *v = vendor_txdds + idx;\r\nif (!memcmp(v->oui, qd->oui, QSFP_VOUI_LEN) &&\r\n(!v->partnum ||\r\n!memcmp(v->partnum, qd->partnum, QSFP_PN_LEN))) {\r\n*sdr_dds = &v->sdr;\r\n*ddr_dds = &v->ddr;\r\n*qdr_dds = &v->qdr;\r\nreturn;\r\n}\r\n}\r\nif (!override && QSFP_IS_ACTIVE(qd->tech)) {\r\n*sdr_dds = txdds_sdr + ppd->dd->board_atten;\r\n*ddr_dds = txdds_ddr + ppd->dd->board_atten;\r\n*qdr_dds = txdds_qdr + ppd->dd->board_atten;\r\nreturn;\r\n}\r\nif (!override && QSFP_HAS_ATTEN(qd->tech) && (qd->atten[0] ||\r\nqd->atten[1])) {\r\n*sdr_dds = get_atten_table(txdds_sdr, qd->atten[0]);\r\n*ddr_dds = get_atten_table(txdds_ddr, qd->atten[0]);\r\n*qdr_dds = get_atten_table(txdds_qdr, qd->atten[1]);\r\nreturn;\r\n} else if (ppd->cpspec->no_eep < TXDDS_TABLE_SZ) {\r\nidx = ppd->cpspec->no_eep;\r\n*sdr_dds = &txdds_sdr[idx];\r\n*ddr_dds = &txdds_ddr[idx];\r\n*qdr_dds = &txdds_qdr[idx];\r\n} else if (ppd->cpspec->no_eep < (TXDDS_TABLE_SZ + TXDDS_EXTRA_SZ)) {\r\nidx = ppd->cpspec->no_eep - TXDDS_TABLE_SZ;\r\n*sdr_dds = &txdds_extra_sdr[idx];\r\n*ddr_dds = &txdds_extra_ddr[idx];\r\n*qdr_dds = &txdds_extra_qdr[idx];\r\n} else if ((IS_QME(ppd->dd) || IS_QMH(ppd->dd)) &&\r\nppd->cpspec->no_eep < (TXDDS_TABLE_SZ + TXDDS_EXTRA_SZ +\r\nTXDDS_MFG_SZ)) {\r\nidx = ppd->cpspec->no_eep - (TXDDS_TABLE_SZ + TXDDS_EXTRA_SZ);\r\npr_info("IB%u:%u use idx %u into txdds_mfg\n",\r\nppd->dd->unit, ppd->port, idx);\r\n*sdr_dds = &txdds_extra_mfg[idx];\r\n*ddr_dds = &txdds_extra_mfg[idx];\r\n*qdr_dds = &txdds_extra_mfg[idx];\r\n} else {\r\n*sdr_dds = txdds_sdr + qib_long_atten;\r\n*ddr_dds = txdds_ddr + qib_long_atten;\r\n*qdr_dds = txdds_qdr + qib_long_atten;\r\n}\r\n}\r\nstatic void init_txdds_table(struct qib_pportdata *ppd, int override)\r\n{\r\nconst struct txdds_ent *sdr_dds, *ddr_dds, *qdr_dds;\r\nstruct txdds_ent *dds;\r\nint idx;\r\nint single_ent = 0;\r\nfind_best_ent(ppd, &sdr_dds, &ddr_dds, &qdr_dds, override);\r\nif (!(ppd->dd->flags & QIB_HAS_QSFP) || override)\r\nsingle_ent = 1;\r\nset_txdds(ppd, 0, sdr_dds);\r\nset_txdds(ppd, TXDDS_TABLE_SZ, ddr_dds);\r\nset_txdds(ppd, 2 * TXDDS_TABLE_SZ, qdr_dds);\r\nif (ppd->lflags & (QIBL_LINKINIT | QIBL_LINKARMED |\r\nQIBL_LINKACTIVE)) {\r\ndds = (struct txdds_ent *)(ppd->link_speed_active ==\r\nQIB_IB_QDR ? qdr_dds :\r\n(ppd->link_speed_active ==\r\nQIB_IB_DDR ? ddr_dds : sdr_dds));\r\nwrite_tx_serdes_param(ppd, dds);\r\n}\r\nfor (idx = 1; idx < ARRAY_SIZE(txdds_sdr); ++idx) {\r\nset_txdds(ppd, idx, single_ent ? sdr_dds : txdds_sdr + idx);\r\nset_txdds(ppd, idx + TXDDS_TABLE_SZ,\r\nsingle_ent ? ddr_dds : txdds_ddr + idx);\r\nset_txdds(ppd, idx + 2 * TXDDS_TABLE_SZ,\r\nsingle_ent ? qdr_dds : txdds_qdr + idx);\r\n}\r\n}\r\nstatic u32 ahb_mod(struct qib_devdata *dd, int quad, int chan, int addr,\r\nu32 data, u32 mask)\r\n{\r\nu32 rd_data, wr_data, sz_mask;\r\nu64 trans, acc, prev_acc;\r\nu32 ret = 0xBAD0BAD;\r\nint tries;\r\nprev_acc = qib_read_kreg64(dd, KR_AHB_ACC);\r\nacc = (quad << 1) | 1;\r\nqib_write_kreg(dd, KR_AHB_ACC, acc);\r\nfor (tries = 1; tries < AHB_TRANS_TRIES; ++tries) {\r\ntrans = qib_read_kreg64(dd, KR_AHB_TRANS);\r\nif (trans & AHB_TRANS_RDY)\r\nbreak;\r\n}\r\nif (tries >= AHB_TRANS_TRIES) {\r\nqib_dev_err(dd, "No ahb_rdy in %d tries\n", AHB_TRANS_TRIES);\r\ngoto bail;\r\n}\r\nsz_mask = (1UL << ((quad == 1) ? 32 : 16)) - 1;\r\nwr_data = data & mask & sz_mask;\r\nif ((~mask & sz_mask) != 0) {\r\ntrans = ((chan << 6) | addr) << (AHB_ADDR_LSB + 1);\r\nqib_write_kreg(dd, KR_AHB_TRANS, trans);\r\nfor (tries = 1; tries < AHB_TRANS_TRIES; ++tries) {\r\ntrans = qib_read_kreg64(dd, KR_AHB_TRANS);\r\nif (trans & AHB_TRANS_RDY)\r\nbreak;\r\n}\r\nif (tries >= AHB_TRANS_TRIES) {\r\nqib_dev_err(dd, "No Rd ahb_rdy in %d tries\n",\r\nAHB_TRANS_TRIES);\r\ngoto bail;\r\n}\r\ntrans = qib_read_kreg64(dd, KR_AHB_TRANS);\r\nrd_data = (uint32_t)(trans >> AHB_DATA_LSB);\r\nwr_data |= (rd_data & ~mask & sz_mask);\r\n}\r\nif (mask & sz_mask) {\r\ntrans = ((chan << 6) | addr) << (AHB_ADDR_LSB + 1);\r\ntrans |= ((uint64_t)wr_data << AHB_DATA_LSB);\r\ntrans |= AHB_WR;\r\nqib_write_kreg(dd, KR_AHB_TRANS, trans);\r\nfor (tries = 1; tries < AHB_TRANS_TRIES; ++tries) {\r\ntrans = qib_read_kreg64(dd, KR_AHB_TRANS);\r\nif (trans & AHB_TRANS_RDY)\r\nbreak;\r\n}\r\nif (tries >= AHB_TRANS_TRIES) {\r\nqib_dev_err(dd, "No Wr ahb_rdy in %d tries\n",\r\nAHB_TRANS_TRIES);\r\ngoto bail;\r\n}\r\n}\r\nret = wr_data;\r\nbail:\r\nqib_write_kreg(dd, KR_AHB_ACC, prev_acc);\r\nreturn ret;\r\n}\r\nstatic void ibsd_wr_allchans(struct qib_pportdata *ppd, int addr, unsigned data,\r\nunsigned mask)\r\n{\r\nstruct qib_devdata *dd = ppd->dd;\r\nint chan;\r\nu32 rbc;\r\nfor (chan = 0; chan < SERDES_CHANS; ++chan) {\r\nahb_mod(dd, IBSD(ppd->hw_pidx), (chan + (chan >> 1)), addr,\r\ndata, mask);\r\nrbc = ahb_mod(dd, IBSD(ppd->hw_pidx), (chan + (chan >> 1)),\r\naddr, 0, 0);\r\n}\r\n}\r\nstatic void serdes_7322_los_enable(struct qib_pportdata *ppd, int enable)\r\n{\r\nu64 data = qib_read_kreg_port(ppd, krp_serdesctrl);\r\nu8 state = SYM_FIELD(data, IBSerdesCtrl_0, RXLOSEN);\r\nif (enable && !state) {\r\npr_info("IB%u:%u Turning LOS on\n",\r\nppd->dd->unit, ppd->port);\r\ndata |= SYM_MASK(IBSerdesCtrl_0, RXLOSEN);\r\n} else if (!enable && state) {\r\npr_info("IB%u:%u Turning LOS off\n",\r\nppd->dd->unit, ppd->port);\r\ndata &= ~SYM_MASK(IBSerdesCtrl_0, RXLOSEN);\r\n}\r\nqib_write_kreg_port(ppd, krp_serdesctrl, data);\r\n}\r\nstatic int serdes_7322_init(struct qib_pportdata *ppd)\r\n{\r\nint ret = 0;\r\nif (ppd->dd->cspec->r1)\r\nret = serdes_7322_init_old(ppd);\r\nelse\r\nret = serdes_7322_init_new(ppd);\r\nreturn ret;\r\n}\r\nstatic int serdes_7322_init_old(struct qib_pportdata *ppd)\r\n{\r\nu32 le_val;\r\ninit_txdds_table(ppd, 0);\r\nqib_write_kreg_port(ppd, krp_tx_deemph_override,\r\nSYM_MASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\r\nreset_tx_deemphasis_override));\r\nibsd_wr_allchans(ppd, 2, 0, BMASK(11, 9));\r\nibsd_wr_allchans(ppd, 11, (1 << 11), BMASK(12, 11));\r\nibsd_wr_allchans(ppd, 13, (1 << 6), (1 << 6));\r\nle_val = IS_QME(ppd->dd) ? LE2_QME : LE2_DEFAULT;\r\nibsd_wr_allchans(ppd, 13, (le_val << 7), BMASK(9, 7));\r\nle_val = IS_QME(ppd->dd) ? 0 : 1;\r\nibsd_wr_allchans(ppd, 13, (le_val << 5), (1 << 5));\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 10, 0 << 14, 1 << 14);\r\nibsd_wr_allchans(ppd, 5, (0 << 8), BMASK(9, 8));\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 5, 8 << 11, BMASK(14, 11));\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 7, 8 << 4, BMASK(7, 4));\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 8, 8 << 11, BMASK(14, 11));\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 10, 8 << 4, BMASK(7, 4));\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 6, 4 << 0, BMASK(3, 0));\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 7, 4 << 8, BMASK(11, 8));\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 9, 4 << 0, BMASK(3, 0));\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 10, 4 << 8, BMASK(11, 8));\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 9, 1 << 15, 1 << 15);\r\nibsd_wr_allchans(ppd, 14, (1 << 3), BMASK(5, 3));\r\nibsd_wr_allchans(ppd, 20, (2 << 10), BMASK(12, 10));\r\nibsd_wr_allchans(ppd, 20, (4 << 13), BMASK(15, 13));\r\nserdes_7322_los_enable(ppd, 1);\r\nibsd_wr_allchans(ppd, 9, 0 << 15, 1 << 15);\r\nibsd_wr_allchans(ppd, 16, 0 << 0, BMASK(1, 0));\r\nle_val = (ppd->dd->cspec->r1 || IS_QME(ppd->dd)) ? 0xb6c0 : 0x6bac;\r\nibsd_wr_allchans(ppd, 21, le_val, 0xfffe);\r\nqib_write_kreg_port(ppd, krp_static_adapt_dis(0), 0ULL);\r\nqib_write_kreg_port(ppd, krp_static_adapt_dis(1), 0ULL);\r\nqib_write_kreg_port(ppd, krp_static_adapt_dis(2),\r\nppd->dd->cspec->r1 ?\r\nQDR_STATIC_ADAPT_DOWN_R1 : QDR_STATIC_ADAPT_DOWN);\r\nppd->cpspec->qdr_dfe_on = 1;\r\nibsd_wr_allchans(ppd, 38, 0 << 10, 1 << 10);\r\nibsd_wr_allchans(ppd, 12, 1 << 4, 1 << 4);\r\nif (!ppd->dd->cspec->r1) {\r\nibsd_wr_allchans(ppd, 12, 1 << 12, 1 << 12);\r\nibsd_wr_allchans(ppd, 12, 2 << 8, 0x0f << 8);\r\n}\r\nibsd_wr_allchans(ppd, 2, 15 << 5, BMASK(8, 5));\r\nreturn 0;\r\n}\r\nstatic int serdes_7322_init_new(struct qib_pportdata *ppd)\r\n{\r\nunsigned long tend;\r\nu32 le_val, rxcaldone;\r\nint chan, chan_done = (1 << SERDES_CHANS) - 1;\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 10, 0 << 14, 1 << 14);\r\nqib_write_kreg_port(ppd, krp_tx_deemph_override,\r\nSYM_MASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\r\nreset_tx_deemphasis_override));\r\nibsd_wr_allchans(ppd, 1, 0, BMASK(9, 1));\r\nibsd_wr_allchans(ppd, 13, 0, BMASK(5, 5));\r\nibsd_wr_allchans(ppd, 1, 0, BMASK(15, 15));\r\nibsd_wr_allchans(ppd, 13, 0, BMASK(6, 6));\r\nibsd_wr_allchans(ppd, 5, 0, BMASK(0, 0));\r\nibsd_wr_allchans(ppd, 12, 0, BMASK(12, 12));\r\nibsd_wr_allchans(ppd, 2, 0, BMASK(3, 3));\r\nibsd_wr_allchans(ppd, 2, 0, BMASK(4, 4));\r\nibsd_wr_allchans(ppd, 13, 0, BMASK(13, 13));\r\nibsd_wr_allchans(ppd, 4, 0, BMASK(10, 10));\r\nibsd_wr_allchans(ppd, 12, 0, BMASK(4, 4));\r\nibsd_wr_allchans(ppd, 2, (1 << 15), BMASK(15, 15));\r\nibsd_wr_allchans(ppd, 5, 0, BMASK(9, 8));\r\nibsd_wr_allchans(ppd, 12, (1 << 5), BMASK(5, 5));\r\nibsd_wr_allchans(ppd, 2, (4 << 12), BMASK(14, 12));\r\nibsd_wr_allchans(ppd, 16, 0, BMASK(1, 0));\r\nif (!ppd->dd->cspec->r1) {\r\nibsd_wr_allchans(ppd, 12, 1 << 12, BMASK(12, 12));\r\nibsd_wr_allchans(ppd, 12, 2 << 8, BMASK(11, 8));\r\n} else {\r\nibsd_wr_allchans(ppd, 19, (3 << 11), BMASK(13, 11));\r\n}\r\nibsd_wr_allchans(ppd, 0, 0, BMASK(15, 13));\r\nmsleep(20);\r\nibsd_wr_allchans(ppd, 0, (1 << 14), BMASK(14, 14));\r\nmsleep(20);\r\nibsd_wr_allchans(ppd, 0, (1 << 13), BMASK(13, 13));\r\nmsleep(20);\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 5, 8 << 11, BMASK(14, 11));\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 7, 8 << 4, BMASK(7, 4));\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 8, 8 << 11, BMASK(14, 11));\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 10, 8 << 4, BMASK(7, 4));\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 6, 4 << 0, BMASK(3, 0));\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 7, 4 << 8, BMASK(11, 8));\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 9, 4 << 0, BMASK(3, 0));\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 10, 4 << 8, BMASK(11, 8));\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), 5, 9, 1 << 15, 1 << 15);\r\nibsd_wr_allchans(ppd, 14, (1 << 3), BMASK(5, 3));\r\nibsd_wr_allchans(ppd, 20, (2 << 10), BMASK(12, 10));\r\nibsd_wr_allchans(ppd, 20, (4 << 13), BMASK(15, 13));\r\nserdes_7322_los_enable(ppd, 1);\r\nibsd_wr_allchans(ppd, 38, 0 << 10, 1 << 10);\r\nibsd_wr_allchans(ppd, 15, 1, BMASK(0, 0));\r\nibsd_wr_allchans(ppd, 12, (1 << 4), BMASK(4, 4));\r\nmsleep(20);\r\nibsd_wr_allchans(ppd, 4, (1 << 10), BMASK(10, 10));\r\ntend = jiffies + msecs_to_jiffies(500);\r\nwhile (chan_done && !time_is_before_jiffies(tend)) {\r\nmsleep(20);\r\nfor (chan = 0; chan < SERDES_CHANS; ++chan) {\r\nrxcaldone = ahb_mod(ppd->dd, IBSD(ppd->hw_pidx),\r\n(chan + (chan >> 1)),\r\n25, 0, 0);\r\nif ((~rxcaldone & (u32)BMASK(9, 9)) == 0 &&\r\n(~chan_done & (1 << chan)) == 0)\r\nchan_done &= ~(1 << chan);\r\n}\r\n}\r\nif (chan_done) {\r\npr_info("Serdes %d calibration not done after .5 sec: 0x%x\n",\r\nIBSD(ppd->hw_pidx), chan_done);\r\n} else {\r\nfor (chan = 0; chan < SERDES_CHANS; ++chan) {\r\nrxcaldone = ahb_mod(ppd->dd, IBSD(ppd->hw_pidx),\r\n(chan + (chan >> 1)),\r\n25, 0, 0);\r\nif ((~rxcaldone & (u32)BMASK(10, 10)) == 0)\r\npr_info("Serdes %d chan %d calibration failed\n",\r\nIBSD(ppd->hw_pidx), chan);\r\n}\r\n}\r\nibsd_wr_allchans(ppd, 4, 0, BMASK(10, 10));\r\nmsleep(20);\r\nle_val = IS_QME(ppd->dd) ? LE2_QME : LE2_DEFAULT;\r\nibsd_wr_allchans(ppd, 13, (le_val << 7), BMASK(9, 7));\r\nibsd_wr_allchans(ppd, 3, (7 << 5), BMASK(7, 5));\r\nibsd_wr_allchans(ppd, 13, (1 << 6), BMASK(6, 6));\r\nmsleep(20);\r\nibsd_wr_allchans(ppd, 1, 1, BMASK(9, 1));\r\nle_val = (ppd->dd->cspec->r1 || IS_QME(ppd->dd)) ? 0xb6c0 : 0x6bac;\r\nibsd_wr_allchans(ppd, 21, le_val, 0xfffe);\r\nibsd_wr_allchans(ppd, 5, 0, BMASK(0, 0));\r\nmsleep(20);\r\nibsd_wr_allchans(ppd, 2, (15 << 5), BMASK(8, 5));\r\nibsd_wr_allchans(ppd, 2, (1 << 4), BMASK(4, 4));\r\nibsd_wr_allchans(ppd, 2, 0, BMASK(11, 9));\r\nibsd_wr_allchans(ppd, 2, (1 << 3), BMASK(3, 3));\r\nmsleep(50);\r\nqib_write_kreg_port(ppd, krp_static_adapt_dis(0), 0ULL);\r\nqib_write_kreg_port(ppd, krp_static_adapt_dis(1), 0ULL);\r\nqib_write_kreg_port(ppd, krp_static_adapt_dis(2),\r\nppd->dd->cspec->r1 ?\r\nQDR_STATIC_ADAPT_DOWN_R1 : QDR_STATIC_ADAPT_DOWN);\r\nppd->cpspec->qdr_dfe_on = 1;\r\nibsd_wr_allchans(ppd, 13, (0 << 5), (1 << 5));\r\nibsd_wr_allchans(ppd, 1, (0 << 15), BMASK(15, 15));\r\nmsleep(20);\r\nibsd_wr_allchans(ppd, 12, (1 << 12), BMASK(12, 12));\r\nibsd_wr_allchans(ppd, 12, (1 << 13), BMASK(13, 13));\r\nibsd_wr_allchans(ppd, 11, (1 << 11), BMASK(12, 11));\r\nibsd_wr_allchans(ppd, 12, (3 << 2), BMASK(3, 2));\r\ninit_txdds_table(ppd, 0);\r\nreturn 0;\r\n}\r\nstatic void set_man_code(struct qib_pportdata *ppd, int chan, int code)\r\n{\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), (chan + (chan >> 1)),\r\n9, code << 9, 0x3f << 9);\r\n}\r\nstatic void set_man_mode_h1(struct qib_pportdata *ppd, int chan,\r\nint enable, u32 tapenable)\r\n{\r\nif (enable)\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), (chan + (chan >> 1)),\r\n1, 3 << 10, 0x1f << 10);\r\nelse\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), (chan + (chan >> 1)),\r\n1, 0, 0x1f << 10);\r\n}\r\nstatic void clock_man(struct qib_pportdata *ppd, int chan)\r\n{\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), (chan + (chan >> 1)),\r\n4, 0x4000, 0x4000);\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), (chan + (chan >> 1)),\r\n4, 0, 0x4000);\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), (chan + (chan >> 1)),\r\n4, 0x4000, 0x4000);\r\nahb_mod(ppd->dd, IBSD(ppd->hw_pidx), (chan + (chan >> 1)),\r\n4, 0, 0x4000);\r\n}\r\nstatic void write_tx_serdes_param(struct qib_pportdata *ppd,\r\nstruct txdds_ent *txdds)\r\n{\r\nu64 deemph;\r\ndeemph = qib_read_kreg_port(ppd, krp_tx_deemph_override);\r\ndeemph &= ~(SYM_MASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0, txampcntl_d2a) |\r\nSYM_MASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0, txc0_ena) |\r\nSYM_MASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0, txcp1_ena) |\r\nSYM_MASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0, txcn1_ena));\r\ndeemph |= SYM_MASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\r\ntx_override_deemphasis_select);\r\ndeemph |= (txdds->amp & SYM_RMASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\r\ntxampcntl_d2a)) << SYM_LSB(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\r\ntxampcntl_d2a);\r\ndeemph |= (txdds->main & SYM_RMASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\r\ntxc0_ena)) << SYM_LSB(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\r\ntxc0_ena);\r\ndeemph |= (txdds->post & SYM_RMASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\r\ntxcp1_ena)) << SYM_LSB(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\r\ntxcp1_ena);\r\ndeemph |= (txdds->pre & SYM_RMASK(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\r\ntxcn1_ena)) << SYM_LSB(IBSD_TX_DEEMPHASIS_OVERRIDE_0,\r\ntxcn1_ena);\r\nqib_write_kreg_port(ppd, krp_tx_deemph_override, deemph);\r\n}\r\nstatic void adj_tx_serdes(struct qib_pportdata *ppd)\r\n{\r\nconst struct txdds_ent *sdr_dds, *ddr_dds, *qdr_dds;\r\nstruct txdds_ent *dds;\r\nfind_best_ent(ppd, &sdr_dds, &ddr_dds, &qdr_dds, 1);\r\ndds = (struct txdds_ent *)(ppd->link_speed_active == QIB_IB_QDR ?\r\nqdr_dds : (ppd->link_speed_active == QIB_IB_DDR ?\r\nddr_dds : sdr_dds));\r\nwrite_tx_serdes_param(ppd, dds);\r\n}\r\nstatic void force_h1(struct qib_pportdata *ppd)\r\n{\r\nint chan;\r\nppd->cpspec->qdr_reforce = 0;\r\nif (!ppd->dd->cspec->r1)\r\nreturn;\r\nfor (chan = 0; chan < SERDES_CHANS; chan++) {\r\nset_man_mode_h1(ppd, chan, 1, 0);\r\nset_man_code(ppd, chan, ppd->cpspec->h1_val);\r\nclock_man(ppd, chan);\r\nset_man_mode_h1(ppd, chan, 0, 0);\r\n}\r\n}\r\nstatic int qib_r_grab(struct qib_devdata *dd)\r\n{\r\nu64 val;\r\nval = SJA_EN;\r\nqib_write_kreg(dd, kr_r_access, val);\r\nqib_read_kreg32(dd, kr_scratch);\r\nreturn 0;\r\n}\r\nstatic int qib_r_wait_for_rdy(struct qib_devdata *dd)\r\n{\r\nu64 val;\r\nint timeout;\r\nfor (timeout = 0; timeout < 100 ; ++timeout) {\r\nval = qib_read_kreg32(dd, kr_r_access);\r\nif (val & R_RDY)\r\nreturn (val >> R_TDO_LSB) & 1;\r\n}\r\nreturn -1;\r\n}\r\nstatic int qib_r_shift(struct qib_devdata *dd, int bisten,\r\nint len, u8 *inp, u8 *outp)\r\n{\r\nu64 valbase, val;\r\nint ret, pos;\r\nvalbase = SJA_EN | (bisten << BISTEN_LSB) |\r\n(R_OP_SHIFT << R_OPCODE_LSB);\r\nret = qib_r_wait_for_rdy(dd);\r\nif (ret < 0)\r\ngoto bail;\r\nfor (pos = 0; pos < len; ++pos) {\r\nval = valbase;\r\nif (outp) {\r\noutp[pos >> 3] &= ~(1 << (pos & 7));\r\noutp[pos >> 3] |= (ret << (pos & 7));\r\n}\r\nif (inp) {\r\nint tdi = inp[pos >> 3] >> (pos & 7);\r\nval |= ((tdi & 1) << R_TDI_LSB);\r\n}\r\nqib_write_kreg(dd, kr_r_access, val);\r\nqib_read_kreg32(dd, kr_scratch);\r\nret = qib_r_wait_for_rdy(dd);\r\nif (ret < 0)\r\nbreak;\r\n}\r\nval = SJA_EN | (bisten << BISTEN_LSB);\r\nqib_write_kreg(dd, kr_r_access, val);\r\nqib_read_kreg32(dd, kr_scratch);\r\nret = qib_r_wait_for_rdy(dd);\r\nif (ret >= 0)\r\nret = pos;\r\nbail:\r\nreturn ret;\r\n}\r\nstatic int qib_r_update(struct qib_devdata *dd, int bisten)\r\n{\r\nu64 val;\r\nint ret;\r\nval = SJA_EN | (bisten << BISTEN_LSB) | (R_OP_UPDATE << R_OPCODE_LSB);\r\nret = qib_r_wait_for_rdy(dd);\r\nif (ret >= 0) {\r\nqib_write_kreg(dd, kr_r_access, val);\r\nqib_read_kreg32(dd, kr_scratch);\r\n}\r\nreturn ret;\r\n}\r\nstatic void setup_7322_link_recovery(struct qib_pportdata *ppd, u32 both)\r\n{\r\nu8 *portsel, *etm;\r\nstruct qib_devdata *dd = ppd->dd;\r\nif (!ppd->dd->cspec->r1)\r\nreturn;\r\nif (!both) {\r\ndd->cspec->recovery_ports_initted++;\r\nppd->cpspec->recovery_init = 1;\r\n}\r\nif (!both && dd->cspec->recovery_ports_initted == 1) {\r\nportsel = ppd->port == 1 ? portsel_port1 : portsel_port2;\r\netm = atetm_1port;\r\n} else {\r\nportsel = portsel_2port;\r\netm = atetm_2port;\r\n}\r\nif (qib_r_grab(dd) < 0 ||\r\nqib_r_shift(dd, BISTEN_ETM, LEN_ETM, reset_atetm, NULL) < 0 ||\r\nqib_r_update(dd, BISTEN_ETM) < 0 ||\r\nqib_r_shift(dd, BISTEN_AT, LEN_AT, reset_at, NULL) < 0 ||\r\nqib_r_update(dd, BISTEN_AT) < 0 ||\r\nqib_r_shift(dd, BISTEN_PORT_SEL, LEN_PORT_SEL,\r\nportsel, NULL) < 0 ||\r\nqib_r_update(dd, BISTEN_PORT_SEL) < 0 ||\r\nqib_r_shift(dd, BISTEN_AT, LEN_AT, at, NULL) < 0 ||\r\nqib_r_update(dd, BISTEN_AT) < 0 ||\r\nqib_r_shift(dd, BISTEN_ETM, LEN_ETM, etm, NULL) < 0 ||\r\nqib_r_update(dd, BISTEN_ETM) < 0)\r\nqib_dev_err(dd, "Failed IB link recovery setup\n");\r\n}\r\nstatic void check_7322_rxe_status(struct qib_pportdata *ppd)\r\n{\r\nstruct qib_devdata *dd = ppd->dd;\r\nu64 fmask;\r\nif (dd->cspec->recovery_ports_initted != 1)\r\nreturn;\r\nqib_write_kreg(dd, kr_control, dd->control |\r\nSYM_MASK(Control, FreezeMode));\r\n(void)qib_read_kreg64(dd, kr_scratch);\r\nudelay(3);\r\nfmask = qib_read_kreg64(dd, kr_act_fmask);\r\nif (!fmask) {\r\nppd->dd->cspec->stay_in_freeze = 1;\r\nqib_7322_set_intr_state(ppd->dd, 0);\r\nqib_write_kreg(dd, kr_fmask, 0ULL);\r\nqib_dev_err(dd, "HCA unusable until powercycled\n");\r\nreturn;\r\n}\r\nqib_write_kreg(ppd->dd, kr_hwerrclear,\r\nSYM_MASK(HwErrClear, IBSerdesPClkNotDetectClear_1));\r\nqib_write_kreg(dd, kr_control, dd->control);\r\nqib_read_kreg32(dd, kr_scratch);\r\nif (ppd->link_speed_supported) {\r\nppd->cpspec->ibcctrl_a &=\r\n~SYM_MASK(IBCCtrlA_0, IBStatIntReductionEn);\r\nqib_write_kreg_port(ppd, krp_ibcctrl_a,\r\nppd->cpspec->ibcctrl_a);\r\nqib_read_kreg32(dd, kr_scratch);\r\nif (ppd->lflags & QIBL_IB_LINK_DISABLED)\r\nqib_set_ib_7322_lstate(ppd, 0,\r\nQLOGIC_IB_IBCC_LINKINITCMD_DISABLE);\r\n}\r\n}
