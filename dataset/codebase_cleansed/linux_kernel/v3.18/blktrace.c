static void trace_note(struct blk_trace *bt, pid_t pid, int action,\r\nconst void *data, size_t len)\r\n{\r\nstruct blk_io_trace *t;\r\nstruct ring_buffer_event *event = NULL;\r\nstruct ring_buffer *buffer = NULL;\r\nint pc = 0;\r\nint cpu = smp_processor_id();\r\nbool blk_tracer = blk_tracer_enabled;\r\nif (blk_tracer) {\r\nbuffer = blk_tr->trace_buffer.buffer;\r\npc = preempt_count();\r\nevent = trace_buffer_lock_reserve(buffer, TRACE_BLK,\r\nsizeof(*t) + len,\r\n0, pc);\r\nif (!event)\r\nreturn;\r\nt = ring_buffer_event_data(event);\r\ngoto record_it;\r\n}\r\nif (!bt->rchan)\r\nreturn;\r\nt = relay_reserve(bt->rchan, sizeof(*t) + len);\r\nif (t) {\r\nt->magic = BLK_IO_TRACE_MAGIC | BLK_IO_TRACE_VERSION;\r\nt->time = ktime_to_ns(ktime_get());\r\nrecord_it:\r\nt->device = bt->dev;\r\nt->action = action;\r\nt->pid = pid;\r\nt->cpu = cpu;\r\nt->pdu_len = len;\r\nmemcpy((void *) t + sizeof(*t), data, len);\r\nif (blk_tracer)\r\ntrace_buffer_unlock_commit(buffer, event, 0, pc);\r\n}\r\n}\r\nstatic void trace_note_tsk(struct task_struct *tsk)\r\n{\r\nunsigned long flags;\r\nstruct blk_trace *bt;\r\ntsk->btrace_seq = blktrace_seq;\r\nspin_lock_irqsave(&running_trace_lock, flags);\r\nlist_for_each_entry(bt, &running_trace_list, running_list) {\r\ntrace_note(bt, tsk->pid, BLK_TN_PROCESS, tsk->comm,\r\nsizeof(tsk->comm));\r\n}\r\nspin_unlock_irqrestore(&running_trace_lock, flags);\r\n}\r\nstatic void trace_note_time(struct blk_trace *bt)\r\n{\r\nstruct timespec now;\r\nunsigned long flags;\r\nu32 words[2];\r\ngetnstimeofday(&now);\r\nwords[0] = now.tv_sec;\r\nwords[1] = now.tv_nsec;\r\nlocal_irq_save(flags);\r\ntrace_note(bt, 0, BLK_TN_TIMESTAMP, words, sizeof(words));\r\nlocal_irq_restore(flags);\r\n}\r\nvoid __trace_note_message(struct blk_trace *bt, const char *fmt, ...)\r\n{\r\nint n;\r\nva_list args;\r\nunsigned long flags;\r\nchar *buf;\r\nif (unlikely(bt->trace_state != Blktrace_running &&\r\n!blk_tracer_enabled))\r\nreturn;\r\nif (!(bt->act_mask & BLK_TC_NOTIFY))\r\nreturn;\r\nlocal_irq_save(flags);\r\nbuf = this_cpu_ptr(bt->msg_data);\r\nva_start(args, fmt);\r\nn = vscnprintf(buf, BLK_TN_MAX_MSG, fmt, args);\r\nva_end(args);\r\ntrace_note(bt, 0, BLK_TN_MESSAGE, buf, n);\r\nlocal_irq_restore(flags);\r\n}\r\nstatic int act_log_check(struct blk_trace *bt, u32 what, sector_t sector,\r\npid_t pid)\r\n{\r\nif (((bt->act_mask << BLK_TC_SHIFT) & what) == 0)\r\nreturn 1;\r\nif (sector && (sector < bt->start_lba || sector > bt->end_lba))\r\nreturn 1;\r\nif (bt->pid && pid != bt->pid)\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic void __blk_add_trace(struct blk_trace *bt, sector_t sector, int bytes,\r\nint rw, u32 what, int error, int pdu_len, void *pdu_data)\r\n{\r\nstruct task_struct *tsk = current;\r\nstruct ring_buffer_event *event = NULL;\r\nstruct ring_buffer *buffer = NULL;\r\nstruct blk_io_trace *t;\r\nunsigned long flags = 0;\r\nunsigned long *sequence;\r\npid_t pid;\r\nint cpu, pc = 0;\r\nbool blk_tracer = blk_tracer_enabled;\r\nif (unlikely(bt->trace_state != Blktrace_running && !blk_tracer))\r\nreturn;\r\nwhat |= ddir_act[rw & WRITE];\r\nwhat |= MASK_TC_BIT(rw, SYNC);\r\nwhat |= MASK_TC_BIT(rw, RAHEAD);\r\nwhat |= MASK_TC_BIT(rw, META);\r\nwhat |= MASK_TC_BIT(rw, DISCARD);\r\nwhat |= MASK_TC_BIT(rw, FLUSH);\r\nwhat |= MASK_TC_BIT(rw, FUA);\r\npid = tsk->pid;\r\nif (act_log_check(bt, what, sector, pid))\r\nreturn;\r\ncpu = raw_smp_processor_id();\r\nif (blk_tracer) {\r\ntracing_record_cmdline(current);\r\nbuffer = blk_tr->trace_buffer.buffer;\r\npc = preempt_count();\r\nevent = trace_buffer_lock_reserve(buffer, TRACE_BLK,\r\nsizeof(*t) + pdu_len,\r\n0, pc);\r\nif (!event)\r\nreturn;\r\nt = ring_buffer_event_data(event);\r\ngoto record_it;\r\n}\r\nif (unlikely(tsk->btrace_seq != blktrace_seq))\r\ntrace_note_tsk(tsk);\r\nlocal_irq_save(flags);\r\nt = relay_reserve(bt->rchan, sizeof(*t) + pdu_len);\r\nif (t) {\r\nsequence = per_cpu_ptr(bt->sequence, cpu);\r\nt->magic = BLK_IO_TRACE_MAGIC | BLK_IO_TRACE_VERSION;\r\nt->sequence = ++(*sequence);\r\nt->time = ktime_to_ns(ktime_get());\r\nrecord_it:\r\nt->cpu = cpu;\r\nt->pid = pid;\r\nt->sector = sector;\r\nt->bytes = bytes;\r\nt->action = what;\r\nt->device = bt->dev;\r\nt->error = error;\r\nt->pdu_len = pdu_len;\r\nif (pdu_len)\r\nmemcpy((void *) t + sizeof(*t), pdu_data, pdu_len);\r\nif (blk_tracer) {\r\ntrace_buffer_unlock_commit(buffer, event, 0, pc);\r\nreturn;\r\n}\r\n}\r\nlocal_irq_restore(flags);\r\n}\r\nstatic void blk_trace_free(struct blk_trace *bt)\r\n{\r\ndebugfs_remove(bt->msg_file);\r\ndebugfs_remove(bt->dropped_file);\r\nrelay_close(bt->rchan);\r\ndebugfs_remove(bt->dir);\r\nfree_percpu(bt->sequence);\r\nfree_percpu(bt->msg_data);\r\nkfree(bt);\r\n}\r\nstatic void blk_trace_cleanup(struct blk_trace *bt)\r\n{\r\nblk_trace_free(bt);\r\nif (atomic_dec_and_test(&blk_probes_ref))\r\nblk_unregister_tracepoints();\r\n}\r\nint blk_trace_remove(struct request_queue *q)\r\n{\r\nstruct blk_trace *bt;\r\nbt = xchg(&q->blk_trace, NULL);\r\nif (!bt)\r\nreturn -EINVAL;\r\nif (bt->trace_state != Blktrace_running)\r\nblk_trace_cleanup(bt);\r\nreturn 0;\r\n}\r\nstatic ssize_t blk_dropped_read(struct file *filp, char __user *buffer,\r\nsize_t count, loff_t *ppos)\r\n{\r\nstruct blk_trace *bt = filp->private_data;\r\nchar buf[16];\r\nsnprintf(buf, sizeof(buf), "%u\n", atomic_read(&bt->dropped));\r\nreturn simple_read_from_buffer(buffer, count, ppos, buf, strlen(buf));\r\n}\r\nstatic ssize_t blk_msg_write(struct file *filp, const char __user *buffer,\r\nsize_t count, loff_t *ppos)\r\n{\r\nchar *msg;\r\nstruct blk_trace *bt;\r\nif (count >= BLK_TN_MAX_MSG)\r\nreturn -EINVAL;\r\nmsg = kmalloc(count + 1, GFP_KERNEL);\r\nif (msg == NULL)\r\nreturn -ENOMEM;\r\nif (copy_from_user(msg, buffer, count)) {\r\nkfree(msg);\r\nreturn -EFAULT;\r\n}\r\nmsg[count] = '\0';\r\nbt = filp->private_data;\r\n__trace_note_message(bt, "%s", msg);\r\nkfree(msg);\r\nreturn count;\r\n}\r\nstatic int blk_subbuf_start_callback(struct rchan_buf *buf, void *subbuf,\r\nvoid *prev_subbuf, size_t prev_padding)\r\n{\r\nstruct blk_trace *bt;\r\nif (!relay_buf_full(buf))\r\nreturn 1;\r\nbt = buf->chan->private_data;\r\natomic_inc(&bt->dropped);\r\nreturn 0;\r\n}\r\nstatic int blk_remove_buf_file_callback(struct dentry *dentry)\r\n{\r\ndebugfs_remove(dentry);\r\nreturn 0;\r\n}\r\nstatic struct dentry *blk_create_buf_file_callback(const char *filename,\r\nstruct dentry *parent,\r\numode_t mode,\r\nstruct rchan_buf *buf,\r\nint *is_global)\r\n{\r\nreturn debugfs_create_file(filename, mode, parent, buf,\r\n&relay_file_operations);\r\n}\r\nstatic void blk_trace_setup_lba(struct blk_trace *bt,\r\nstruct block_device *bdev)\r\n{\r\nstruct hd_struct *part = NULL;\r\nif (bdev)\r\npart = bdev->bd_part;\r\nif (part) {\r\nbt->start_lba = part->start_sect;\r\nbt->end_lba = part->start_sect + part->nr_sects;\r\n} else {\r\nbt->start_lba = 0;\r\nbt->end_lba = -1ULL;\r\n}\r\n}\r\nint do_blk_trace_setup(struct request_queue *q, char *name, dev_t dev,\r\nstruct block_device *bdev,\r\nstruct blk_user_trace_setup *buts)\r\n{\r\nstruct blk_trace *old_bt, *bt = NULL;\r\nstruct dentry *dir = NULL;\r\nint ret, i;\r\nif (!buts->buf_size || !buts->buf_nr)\r\nreturn -EINVAL;\r\nstrncpy(buts->name, name, BLKTRACE_BDEV_SIZE);\r\nbuts->name[BLKTRACE_BDEV_SIZE - 1] = '\0';\r\nfor (i = 0; i < strlen(buts->name); i++)\r\nif (buts->name[i] == '/')\r\nbuts->name[i] = '_';\r\nbt = kzalloc(sizeof(*bt), GFP_KERNEL);\r\nif (!bt)\r\nreturn -ENOMEM;\r\nret = -ENOMEM;\r\nbt->sequence = alloc_percpu(unsigned long);\r\nif (!bt->sequence)\r\ngoto err;\r\nbt->msg_data = __alloc_percpu(BLK_TN_MAX_MSG, __alignof__(char));\r\nif (!bt->msg_data)\r\ngoto err;\r\nret = -ENOENT;\r\nmutex_lock(&blk_tree_mutex);\r\nif (!blk_tree_root) {\r\nblk_tree_root = debugfs_create_dir("block", NULL);\r\nif (!blk_tree_root) {\r\nmutex_unlock(&blk_tree_mutex);\r\ngoto err;\r\n}\r\n}\r\nmutex_unlock(&blk_tree_mutex);\r\ndir = debugfs_create_dir(buts->name, blk_tree_root);\r\nif (!dir)\r\ngoto err;\r\nbt->dir = dir;\r\nbt->dev = dev;\r\natomic_set(&bt->dropped, 0);\r\nINIT_LIST_HEAD(&bt->running_list);\r\nret = -EIO;\r\nbt->dropped_file = debugfs_create_file("dropped", 0444, dir, bt,\r\n&blk_dropped_fops);\r\nif (!bt->dropped_file)\r\ngoto err;\r\nbt->msg_file = debugfs_create_file("msg", 0222, dir, bt, &blk_msg_fops);\r\nif (!bt->msg_file)\r\ngoto err;\r\nbt->rchan = relay_open("trace", dir, buts->buf_size,\r\nbuts->buf_nr, &blk_relay_callbacks, bt);\r\nif (!bt->rchan)\r\ngoto err;\r\nbt->act_mask = buts->act_mask;\r\nif (!bt->act_mask)\r\nbt->act_mask = (u16) -1;\r\nblk_trace_setup_lba(bt, bdev);\r\nif (buts->start_lba)\r\nbt->start_lba = buts->start_lba;\r\nif (buts->end_lba)\r\nbt->end_lba = buts->end_lba;\r\nbt->pid = buts->pid;\r\nbt->trace_state = Blktrace_setup;\r\nret = -EBUSY;\r\nold_bt = xchg(&q->blk_trace, bt);\r\nif (old_bt) {\r\n(void) xchg(&q->blk_trace, old_bt);\r\ngoto err;\r\n}\r\nif (atomic_inc_return(&blk_probes_ref) == 1)\r\nblk_register_tracepoints();\r\nreturn 0;\r\nerr:\r\nblk_trace_free(bt);\r\nreturn ret;\r\n}\r\nint blk_trace_setup(struct request_queue *q, char *name, dev_t dev,\r\nstruct block_device *bdev,\r\nchar __user *arg)\r\n{\r\nstruct blk_user_trace_setup buts;\r\nint ret;\r\nret = copy_from_user(&buts, arg, sizeof(buts));\r\nif (ret)\r\nreturn -EFAULT;\r\nret = do_blk_trace_setup(q, name, dev, bdev, &buts);\r\nif (ret)\r\nreturn ret;\r\nif (copy_to_user(arg, &buts, sizeof(buts))) {\r\nblk_trace_remove(q);\r\nreturn -EFAULT;\r\n}\r\nreturn 0;\r\n}\r\nstatic int compat_blk_trace_setup(struct request_queue *q, char *name,\r\ndev_t dev, struct block_device *bdev,\r\nchar __user *arg)\r\n{\r\nstruct blk_user_trace_setup buts;\r\nstruct compat_blk_user_trace_setup cbuts;\r\nint ret;\r\nif (copy_from_user(&cbuts, arg, sizeof(cbuts)))\r\nreturn -EFAULT;\r\nbuts = (struct blk_user_trace_setup) {\r\n.act_mask = cbuts.act_mask,\r\n.buf_size = cbuts.buf_size,\r\n.buf_nr = cbuts.buf_nr,\r\n.start_lba = cbuts.start_lba,\r\n.end_lba = cbuts.end_lba,\r\n.pid = cbuts.pid,\r\n};\r\nret = do_blk_trace_setup(q, name, dev, bdev, &buts);\r\nif (ret)\r\nreturn ret;\r\nif (copy_to_user(arg, &buts.name, ARRAY_SIZE(buts.name))) {\r\nblk_trace_remove(q);\r\nreturn -EFAULT;\r\n}\r\nreturn 0;\r\n}\r\nint blk_trace_startstop(struct request_queue *q, int start)\r\n{\r\nint ret;\r\nstruct blk_trace *bt = q->blk_trace;\r\nif (bt == NULL)\r\nreturn -EINVAL;\r\nret = -EINVAL;\r\nif (start) {\r\nif (bt->trace_state == Blktrace_setup ||\r\nbt->trace_state == Blktrace_stopped) {\r\nblktrace_seq++;\r\nsmp_mb();\r\nbt->trace_state = Blktrace_running;\r\nspin_lock_irq(&running_trace_lock);\r\nlist_add(&bt->running_list, &running_trace_list);\r\nspin_unlock_irq(&running_trace_lock);\r\ntrace_note_time(bt);\r\nret = 0;\r\n}\r\n} else {\r\nif (bt->trace_state == Blktrace_running) {\r\nbt->trace_state = Blktrace_stopped;\r\nspin_lock_irq(&running_trace_lock);\r\nlist_del_init(&bt->running_list);\r\nspin_unlock_irq(&running_trace_lock);\r\nrelay_flush(bt->rchan);\r\nret = 0;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nint blk_trace_ioctl(struct block_device *bdev, unsigned cmd, char __user *arg)\r\n{\r\nstruct request_queue *q;\r\nint ret, start = 0;\r\nchar b[BDEVNAME_SIZE];\r\nq = bdev_get_queue(bdev);\r\nif (!q)\r\nreturn -ENXIO;\r\nmutex_lock(&bdev->bd_mutex);\r\nswitch (cmd) {\r\ncase BLKTRACESETUP:\r\nbdevname(bdev, b);\r\nret = blk_trace_setup(q, b, bdev->bd_dev, bdev, arg);\r\nbreak;\r\n#if defined(CONFIG_COMPAT) && defined(CONFIG_X86_64)\r\ncase BLKTRACESETUP32:\r\nbdevname(bdev, b);\r\nret = compat_blk_trace_setup(q, b, bdev->bd_dev, bdev, arg);\r\nbreak;\r\n#endif\r\ncase BLKTRACESTART:\r\nstart = 1;\r\ncase BLKTRACESTOP:\r\nret = blk_trace_startstop(q, start);\r\nbreak;\r\ncase BLKTRACETEARDOWN:\r\nret = blk_trace_remove(q);\r\nbreak;\r\ndefault:\r\nret = -ENOTTY;\r\nbreak;\r\n}\r\nmutex_unlock(&bdev->bd_mutex);\r\nreturn ret;\r\n}\r\nvoid blk_trace_shutdown(struct request_queue *q)\r\n{\r\nif (q->blk_trace) {\r\nblk_trace_startstop(q, 0);\r\nblk_trace_remove(q);\r\n}\r\n}\r\nstatic void blk_add_trace_rq(struct request_queue *q, struct request *rq,\r\nunsigned int nr_bytes, u32 what)\r\n{\r\nstruct blk_trace *bt = q->blk_trace;\r\nif (likely(!bt))\r\nreturn;\r\nif (rq->cmd_type == REQ_TYPE_BLOCK_PC) {\r\nwhat |= BLK_TC_ACT(BLK_TC_PC);\r\n__blk_add_trace(bt, 0, nr_bytes, rq->cmd_flags,\r\nwhat, rq->errors, rq->cmd_len, rq->cmd);\r\n} else {\r\nwhat |= BLK_TC_ACT(BLK_TC_FS);\r\n__blk_add_trace(bt, blk_rq_pos(rq), nr_bytes,\r\nrq->cmd_flags, what, rq->errors, 0, NULL);\r\n}\r\n}\r\nstatic void blk_add_trace_rq_abort(void *ignore,\r\nstruct request_queue *q, struct request *rq)\r\n{\r\nblk_add_trace_rq(q, rq, blk_rq_bytes(rq), BLK_TA_ABORT);\r\n}\r\nstatic void blk_add_trace_rq_insert(void *ignore,\r\nstruct request_queue *q, struct request *rq)\r\n{\r\nblk_add_trace_rq(q, rq, blk_rq_bytes(rq), BLK_TA_INSERT);\r\n}\r\nstatic void blk_add_trace_rq_issue(void *ignore,\r\nstruct request_queue *q, struct request *rq)\r\n{\r\nblk_add_trace_rq(q, rq, blk_rq_bytes(rq), BLK_TA_ISSUE);\r\n}\r\nstatic void blk_add_trace_rq_requeue(void *ignore,\r\nstruct request_queue *q,\r\nstruct request *rq)\r\n{\r\nblk_add_trace_rq(q, rq, blk_rq_bytes(rq), BLK_TA_REQUEUE);\r\n}\r\nstatic void blk_add_trace_rq_complete(void *ignore,\r\nstruct request_queue *q,\r\nstruct request *rq,\r\nunsigned int nr_bytes)\r\n{\r\nblk_add_trace_rq(q, rq, nr_bytes, BLK_TA_COMPLETE);\r\n}\r\nstatic void blk_add_trace_bio(struct request_queue *q, struct bio *bio,\r\nu32 what, int error)\r\n{\r\nstruct blk_trace *bt = q->blk_trace;\r\nif (likely(!bt))\r\nreturn;\r\nif (!error && !bio_flagged(bio, BIO_UPTODATE))\r\nerror = EIO;\r\n__blk_add_trace(bt, bio->bi_iter.bi_sector, bio->bi_iter.bi_size,\r\nbio->bi_rw, what, error, 0, NULL);\r\n}\r\nstatic void blk_add_trace_bio_bounce(void *ignore,\r\nstruct request_queue *q, struct bio *bio)\r\n{\r\nblk_add_trace_bio(q, bio, BLK_TA_BOUNCE, 0);\r\n}\r\nstatic void blk_add_trace_bio_complete(void *ignore,\r\nstruct request_queue *q, struct bio *bio,\r\nint error)\r\n{\r\nblk_add_trace_bio(q, bio, BLK_TA_COMPLETE, error);\r\n}\r\nstatic void blk_add_trace_bio_backmerge(void *ignore,\r\nstruct request_queue *q,\r\nstruct request *rq,\r\nstruct bio *bio)\r\n{\r\nblk_add_trace_bio(q, bio, BLK_TA_BACKMERGE, 0);\r\n}\r\nstatic void blk_add_trace_bio_frontmerge(void *ignore,\r\nstruct request_queue *q,\r\nstruct request *rq,\r\nstruct bio *bio)\r\n{\r\nblk_add_trace_bio(q, bio, BLK_TA_FRONTMERGE, 0);\r\n}\r\nstatic void blk_add_trace_bio_queue(void *ignore,\r\nstruct request_queue *q, struct bio *bio)\r\n{\r\nblk_add_trace_bio(q, bio, BLK_TA_QUEUE, 0);\r\n}\r\nstatic void blk_add_trace_getrq(void *ignore,\r\nstruct request_queue *q,\r\nstruct bio *bio, int rw)\r\n{\r\nif (bio)\r\nblk_add_trace_bio(q, bio, BLK_TA_GETRQ, 0);\r\nelse {\r\nstruct blk_trace *bt = q->blk_trace;\r\nif (bt)\r\n__blk_add_trace(bt, 0, 0, rw, BLK_TA_GETRQ, 0, 0, NULL);\r\n}\r\n}\r\nstatic void blk_add_trace_sleeprq(void *ignore,\r\nstruct request_queue *q,\r\nstruct bio *bio, int rw)\r\n{\r\nif (bio)\r\nblk_add_trace_bio(q, bio, BLK_TA_SLEEPRQ, 0);\r\nelse {\r\nstruct blk_trace *bt = q->blk_trace;\r\nif (bt)\r\n__blk_add_trace(bt, 0, 0, rw, BLK_TA_SLEEPRQ,\r\n0, 0, NULL);\r\n}\r\n}\r\nstatic void blk_add_trace_plug(void *ignore, struct request_queue *q)\r\n{\r\nstruct blk_trace *bt = q->blk_trace;\r\nif (bt)\r\n__blk_add_trace(bt, 0, 0, 0, BLK_TA_PLUG, 0, 0, NULL);\r\n}\r\nstatic void blk_add_trace_unplug(void *ignore, struct request_queue *q,\r\nunsigned int depth, bool explicit)\r\n{\r\nstruct blk_trace *bt = q->blk_trace;\r\nif (bt) {\r\n__be64 rpdu = cpu_to_be64(depth);\r\nu32 what;\r\nif (explicit)\r\nwhat = BLK_TA_UNPLUG_IO;\r\nelse\r\nwhat = BLK_TA_UNPLUG_TIMER;\r\n__blk_add_trace(bt, 0, 0, 0, what, 0, sizeof(rpdu), &rpdu);\r\n}\r\n}\r\nstatic void blk_add_trace_split(void *ignore,\r\nstruct request_queue *q, struct bio *bio,\r\nunsigned int pdu)\r\n{\r\nstruct blk_trace *bt = q->blk_trace;\r\nif (bt) {\r\n__be64 rpdu = cpu_to_be64(pdu);\r\n__blk_add_trace(bt, bio->bi_iter.bi_sector,\r\nbio->bi_iter.bi_size, bio->bi_rw, BLK_TA_SPLIT,\r\n!bio_flagged(bio, BIO_UPTODATE),\r\nsizeof(rpdu), &rpdu);\r\n}\r\n}\r\nstatic void blk_add_trace_bio_remap(void *ignore,\r\nstruct request_queue *q, struct bio *bio,\r\ndev_t dev, sector_t from)\r\n{\r\nstruct blk_trace *bt = q->blk_trace;\r\nstruct blk_io_trace_remap r;\r\nif (likely(!bt))\r\nreturn;\r\nr.device_from = cpu_to_be32(dev);\r\nr.device_to = cpu_to_be32(bio->bi_bdev->bd_dev);\r\nr.sector_from = cpu_to_be64(from);\r\n__blk_add_trace(bt, bio->bi_iter.bi_sector, bio->bi_iter.bi_size,\r\nbio->bi_rw, BLK_TA_REMAP,\r\n!bio_flagged(bio, BIO_UPTODATE), sizeof(r), &r);\r\n}\r\nstatic void blk_add_trace_rq_remap(void *ignore,\r\nstruct request_queue *q,\r\nstruct request *rq, dev_t dev,\r\nsector_t from)\r\n{\r\nstruct blk_trace *bt = q->blk_trace;\r\nstruct blk_io_trace_remap r;\r\nif (likely(!bt))\r\nreturn;\r\nr.device_from = cpu_to_be32(dev);\r\nr.device_to = cpu_to_be32(disk_devt(rq->rq_disk));\r\nr.sector_from = cpu_to_be64(from);\r\n__blk_add_trace(bt, blk_rq_pos(rq), blk_rq_bytes(rq),\r\nrq_data_dir(rq), BLK_TA_REMAP, !!rq->errors,\r\nsizeof(r), &r);\r\n}\r\nvoid blk_add_driver_data(struct request_queue *q,\r\nstruct request *rq,\r\nvoid *data, size_t len)\r\n{\r\nstruct blk_trace *bt = q->blk_trace;\r\nif (likely(!bt))\r\nreturn;\r\nif (rq->cmd_type == REQ_TYPE_BLOCK_PC)\r\n__blk_add_trace(bt, 0, blk_rq_bytes(rq), 0,\r\nBLK_TA_DRV_DATA, rq->errors, len, data);\r\nelse\r\n__blk_add_trace(bt, blk_rq_pos(rq), blk_rq_bytes(rq), 0,\r\nBLK_TA_DRV_DATA, rq->errors, len, data);\r\n}\r\nstatic void blk_register_tracepoints(void)\r\n{\r\nint ret;\r\nret = register_trace_block_rq_abort(blk_add_trace_rq_abort, NULL);\r\nWARN_ON(ret);\r\nret = register_trace_block_rq_insert(blk_add_trace_rq_insert, NULL);\r\nWARN_ON(ret);\r\nret = register_trace_block_rq_issue(blk_add_trace_rq_issue, NULL);\r\nWARN_ON(ret);\r\nret = register_trace_block_rq_requeue(blk_add_trace_rq_requeue, NULL);\r\nWARN_ON(ret);\r\nret = register_trace_block_rq_complete(blk_add_trace_rq_complete, NULL);\r\nWARN_ON(ret);\r\nret = register_trace_block_bio_bounce(blk_add_trace_bio_bounce, NULL);\r\nWARN_ON(ret);\r\nret = register_trace_block_bio_complete(blk_add_trace_bio_complete, NULL);\r\nWARN_ON(ret);\r\nret = register_trace_block_bio_backmerge(blk_add_trace_bio_backmerge, NULL);\r\nWARN_ON(ret);\r\nret = register_trace_block_bio_frontmerge(blk_add_trace_bio_frontmerge, NULL);\r\nWARN_ON(ret);\r\nret = register_trace_block_bio_queue(blk_add_trace_bio_queue, NULL);\r\nWARN_ON(ret);\r\nret = register_trace_block_getrq(blk_add_trace_getrq, NULL);\r\nWARN_ON(ret);\r\nret = register_trace_block_sleeprq(blk_add_trace_sleeprq, NULL);\r\nWARN_ON(ret);\r\nret = register_trace_block_plug(blk_add_trace_plug, NULL);\r\nWARN_ON(ret);\r\nret = register_trace_block_unplug(blk_add_trace_unplug, NULL);\r\nWARN_ON(ret);\r\nret = register_trace_block_split(blk_add_trace_split, NULL);\r\nWARN_ON(ret);\r\nret = register_trace_block_bio_remap(blk_add_trace_bio_remap, NULL);\r\nWARN_ON(ret);\r\nret = register_trace_block_rq_remap(blk_add_trace_rq_remap, NULL);\r\nWARN_ON(ret);\r\n}\r\nstatic void blk_unregister_tracepoints(void)\r\n{\r\nunregister_trace_block_rq_remap(blk_add_trace_rq_remap, NULL);\r\nunregister_trace_block_bio_remap(blk_add_trace_bio_remap, NULL);\r\nunregister_trace_block_split(blk_add_trace_split, NULL);\r\nunregister_trace_block_unplug(blk_add_trace_unplug, NULL);\r\nunregister_trace_block_plug(blk_add_trace_plug, NULL);\r\nunregister_trace_block_sleeprq(blk_add_trace_sleeprq, NULL);\r\nunregister_trace_block_getrq(blk_add_trace_getrq, NULL);\r\nunregister_trace_block_bio_queue(blk_add_trace_bio_queue, NULL);\r\nunregister_trace_block_bio_frontmerge(blk_add_trace_bio_frontmerge, NULL);\r\nunregister_trace_block_bio_backmerge(blk_add_trace_bio_backmerge, NULL);\r\nunregister_trace_block_bio_complete(blk_add_trace_bio_complete, NULL);\r\nunregister_trace_block_bio_bounce(blk_add_trace_bio_bounce, NULL);\r\nunregister_trace_block_rq_complete(blk_add_trace_rq_complete, NULL);\r\nunregister_trace_block_rq_requeue(blk_add_trace_rq_requeue, NULL);\r\nunregister_trace_block_rq_issue(blk_add_trace_rq_issue, NULL);\r\nunregister_trace_block_rq_insert(blk_add_trace_rq_insert, NULL);\r\nunregister_trace_block_rq_abort(blk_add_trace_rq_abort, NULL);\r\ntracepoint_synchronize_unregister();\r\n}\r\nstatic void fill_rwbs(char *rwbs, const struct blk_io_trace *t)\r\n{\r\nint i = 0;\r\nint tc = t->action >> BLK_TC_SHIFT;\r\nif (t->action == BLK_TN_MESSAGE) {\r\nrwbs[i++] = 'N';\r\ngoto out;\r\n}\r\nif (tc & BLK_TC_FLUSH)\r\nrwbs[i++] = 'F';\r\nif (tc & BLK_TC_DISCARD)\r\nrwbs[i++] = 'D';\r\nelse if (tc & BLK_TC_WRITE)\r\nrwbs[i++] = 'W';\r\nelse if (t->bytes)\r\nrwbs[i++] = 'R';\r\nelse\r\nrwbs[i++] = 'N';\r\nif (tc & BLK_TC_FUA)\r\nrwbs[i++] = 'F';\r\nif (tc & BLK_TC_AHEAD)\r\nrwbs[i++] = 'A';\r\nif (tc & BLK_TC_SYNC)\r\nrwbs[i++] = 'S';\r\nif (tc & BLK_TC_META)\r\nrwbs[i++] = 'M';\r\nout:\r\nrwbs[i] = '\0';\r\n}\r\nstatic inline\r\nconst struct blk_io_trace *te_blk_io_trace(const struct trace_entry *ent)\r\n{\r\nreturn (const struct blk_io_trace *)ent;\r\n}\r\nstatic inline const void *pdu_start(const struct trace_entry *ent)\r\n{\r\nreturn te_blk_io_trace(ent) + 1;\r\n}\r\nstatic inline u32 t_action(const struct trace_entry *ent)\r\n{\r\nreturn te_blk_io_trace(ent)->action;\r\n}\r\nstatic inline u32 t_bytes(const struct trace_entry *ent)\r\n{\r\nreturn te_blk_io_trace(ent)->bytes;\r\n}\r\nstatic inline u32 t_sec(const struct trace_entry *ent)\r\n{\r\nreturn te_blk_io_trace(ent)->bytes >> 9;\r\n}\r\nstatic inline unsigned long long t_sector(const struct trace_entry *ent)\r\n{\r\nreturn te_blk_io_trace(ent)->sector;\r\n}\r\nstatic inline __u16 t_error(const struct trace_entry *ent)\r\n{\r\nreturn te_blk_io_trace(ent)->error;\r\n}\r\nstatic __u64 get_pdu_int(const struct trace_entry *ent)\r\n{\r\nconst __u64 *val = pdu_start(ent);\r\nreturn be64_to_cpu(*val);\r\n}\r\nstatic void get_pdu_remap(const struct trace_entry *ent,\r\nstruct blk_io_trace_remap *r)\r\n{\r\nconst struct blk_io_trace_remap *__r = pdu_start(ent);\r\n__u64 sector_from = __r->sector_from;\r\nr->device_from = be32_to_cpu(__r->device_from);\r\nr->device_to = be32_to_cpu(__r->device_to);\r\nr->sector_from = be64_to_cpu(sector_from);\r\n}\r\nstatic int blk_log_action_classic(struct trace_iterator *iter, const char *act)\r\n{\r\nchar rwbs[RWBS_LEN];\r\nunsigned long long ts = iter->ts;\r\nunsigned long nsec_rem = do_div(ts, NSEC_PER_SEC);\r\nunsigned secs = (unsigned long)ts;\r\nconst struct blk_io_trace *t = te_blk_io_trace(iter->ent);\r\nfill_rwbs(rwbs, t);\r\nreturn trace_seq_printf(&iter->seq,\r\n"%3d,%-3d %2d %5d.%09lu %5u %2s %3s ",\r\nMAJOR(t->device), MINOR(t->device), iter->cpu,\r\nsecs, nsec_rem, iter->ent->pid, act, rwbs);\r\n}\r\nstatic int blk_log_action(struct trace_iterator *iter, const char *act)\r\n{\r\nchar rwbs[RWBS_LEN];\r\nconst struct blk_io_trace *t = te_blk_io_trace(iter->ent);\r\nfill_rwbs(rwbs, t);\r\nreturn trace_seq_printf(&iter->seq, "%3d,%-3d %2s %3s ",\r\nMAJOR(t->device), MINOR(t->device), act, rwbs);\r\n}\r\nstatic int blk_log_dump_pdu(struct trace_seq *s, const struct trace_entry *ent)\r\n{\r\nconst unsigned char *pdu_buf;\r\nint pdu_len;\r\nint i, end, ret;\r\npdu_buf = pdu_start(ent);\r\npdu_len = te_blk_io_trace(ent)->pdu_len;\r\nif (!pdu_len)\r\nreturn 1;\r\nfor (end = pdu_len - 1; end >= 0; end--)\r\nif (pdu_buf[end])\r\nbreak;\r\nend++;\r\nif (!trace_seq_putc(s, '('))\r\nreturn 0;\r\nfor (i = 0; i < pdu_len; i++) {\r\nret = trace_seq_printf(s, "%s%02x",\r\ni == 0 ? "" : " ", pdu_buf[i]);\r\nif (!ret)\r\nreturn ret;\r\nif (i == end && end != pdu_len - 1)\r\nreturn trace_seq_puts(s, " ..) ");\r\n}\r\nreturn trace_seq_puts(s, ") ");\r\n}\r\nstatic int blk_log_generic(struct trace_seq *s, const struct trace_entry *ent)\r\n{\r\nchar cmd[TASK_COMM_LEN];\r\ntrace_find_cmdline(ent->pid, cmd);\r\nif (t_action(ent) & BLK_TC_ACT(BLK_TC_PC)) {\r\nint ret;\r\nret = trace_seq_printf(s, "%u ", t_bytes(ent));\r\nif (!ret)\r\nreturn 0;\r\nret = blk_log_dump_pdu(s, ent);\r\nif (!ret)\r\nreturn 0;\r\nreturn trace_seq_printf(s, "[%s]\n", cmd);\r\n} else {\r\nif (t_sec(ent))\r\nreturn trace_seq_printf(s, "%llu + %u [%s]\n",\r\nt_sector(ent), t_sec(ent), cmd);\r\nreturn trace_seq_printf(s, "[%s]\n", cmd);\r\n}\r\n}\r\nstatic int blk_log_with_error(struct trace_seq *s,\r\nconst struct trace_entry *ent)\r\n{\r\nif (t_action(ent) & BLK_TC_ACT(BLK_TC_PC)) {\r\nint ret;\r\nret = blk_log_dump_pdu(s, ent);\r\nif (ret)\r\nreturn trace_seq_printf(s, "[%d]\n", t_error(ent));\r\nreturn 0;\r\n} else {\r\nif (t_sec(ent))\r\nreturn trace_seq_printf(s, "%llu + %u [%d]\n",\r\nt_sector(ent),\r\nt_sec(ent), t_error(ent));\r\nreturn trace_seq_printf(s, "%llu [%d]\n",\r\nt_sector(ent), t_error(ent));\r\n}\r\n}\r\nstatic int blk_log_remap(struct trace_seq *s, const struct trace_entry *ent)\r\n{\r\nstruct blk_io_trace_remap r = { .device_from = 0, };\r\nget_pdu_remap(ent, &r);\r\nreturn trace_seq_printf(s, "%llu + %u <- (%d,%d) %llu\n",\r\nt_sector(ent), t_sec(ent),\r\nMAJOR(r.device_from), MINOR(r.device_from),\r\n(unsigned long long)r.sector_from);\r\n}\r\nstatic int blk_log_plug(struct trace_seq *s, const struct trace_entry *ent)\r\n{\r\nchar cmd[TASK_COMM_LEN];\r\ntrace_find_cmdline(ent->pid, cmd);\r\nreturn trace_seq_printf(s, "[%s]\n", cmd);\r\n}\r\nstatic int blk_log_unplug(struct trace_seq *s, const struct trace_entry *ent)\r\n{\r\nchar cmd[TASK_COMM_LEN];\r\ntrace_find_cmdline(ent->pid, cmd);\r\nreturn trace_seq_printf(s, "[%s] %llu\n", cmd, get_pdu_int(ent));\r\n}\r\nstatic int blk_log_split(struct trace_seq *s, const struct trace_entry *ent)\r\n{\r\nchar cmd[TASK_COMM_LEN];\r\ntrace_find_cmdline(ent->pid, cmd);\r\nreturn trace_seq_printf(s, "%llu / %llu [%s]\n", t_sector(ent),\r\nget_pdu_int(ent), cmd);\r\n}\r\nstatic int blk_log_msg(struct trace_seq *s, const struct trace_entry *ent)\r\n{\r\nint ret;\r\nconst struct blk_io_trace *t = te_blk_io_trace(ent);\r\nret = trace_seq_putmem(s, t + 1, t->pdu_len);\r\nif (ret)\r\nreturn trace_seq_putc(s, '\n');\r\nreturn ret;\r\n}\r\nstatic void blk_tracer_print_header(struct seq_file *m)\r\n{\r\nif (!(blk_tracer_flags.val & TRACE_BLK_OPT_CLASSIC))\r\nreturn;\r\nseq_puts(m, "# DEV CPU TIMESTAMP PID ACT FLG\n"\r\n"# | | | | | |\n");\r\n}\r\nstatic void blk_tracer_start(struct trace_array *tr)\r\n{\r\nblk_tracer_enabled = true;\r\n}\r\nstatic int blk_tracer_init(struct trace_array *tr)\r\n{\r\nblk_tr = tr;\r\nblk_tracer_start(tr);\r\nreturn 0;\r\n}\r\nstatic void blk_tracer_stop(struct trace_array *tr)\r\n{\r\nblk_tracer_enabled = false;\r\n}\r\nstatic void blk_tracer_reset(struct trace_array *tr)\r\n{\r\nblk_tracer_stop(tr);\r\n}\r\nstatic enum print_line_t print_one_line(struct trace_iterator *iter,\r\nbool classic)\r\n{\r\nstruct trace_seq *s = &iter->seq;\r\nconst struct blk_io_trace *t;\r\nu16 what;\r\nint ret;\r\nbool long_act;\r\nblk_log_action_t *log_action;\r\nt = te_blk_io_trace(iter->ent);\r\nwhat = t->action & ((1 << BLK_TC_SHIFT) - 1);\r\nlong_act = !!(trace_flags & TRACE_ITER_VERBOSE);\r\nlog_action = classic ? &blk_log_action_classic : &blk_log_action;\r\nif (t->action == BLK_TN_MESSAGE) {\r\nret = log_action(iter, long_act ? "message" : "m");\r\nif (ret)\r\nret = blk_log_msg(s, iter->ent);\r\ngoto out;\r\n}\r\nif (unlikely(what == 0 || what >= ARRAY_SIZE(what2act)))\r\nret = trace_seq_printf(s, "Unknown action %x\n", what);\r\nelse {\r\nret = log_action(iter, what2act[what].act[long_act]);\r\nif (ret)\r\nret = what2act[what].print(s, iter->ent);\r\n}\r\nout:\r\nreturn ret ? TRACE_TYPE_HANDLED : TRACE_TYPE_PARTIAL_LINE;\r\n}\r\nstatic enum print_line_t blk_trace_event_print(struct trace_iterator *iter,\r\nint flags, struct trace_event *event)\r\n{\r\nreturn print_one_line(iter, false);\r\n}\r\nstatic int blk_trace_synthesize_old_trace(struct trace_iterator *iter)\r\n{\r\nstruct trace_seq *s = &iter->seq;\r\nstruct blk_io_trace *t = (struct blk_io_trace *)iter->ent;\r\nconst int offset = offsetof(struct blk_io_trace, sector);\r\nstruct blk_io_trace old = {\r\n.magic = BLK_IO_TRACE_MAGIC | BLK_IO_TRACE_VERSION,\r\n.time = iter->ts,\r\n};\r\nif (!trace_seq_putmem(s, &old, offset))\r\nreturn 0;\r\nreturn trace_seq_putmem(s, &t->sector,\r\nsizeof(old) - offset + t->pdu_len);\r\n}\r\nstatic enum print_line_t\r\nblk_trace_event_print_binary(struct trace_iterator *iter, int flags,\r\nstruct trace_event *event)\r\n{\r\nreturn blk_trace_synthesize_old_trace(iter) ?\r\nTRACE_TYPE_HANDLED : TRACE_TYPE_PARTIAL_LINE;\r\n}\r\nstatic enum print_line_t blk_tracer_print_line(struct trace_iterator *iter)\r\n{\r\nif (!(blk_tracer_flags.val & TRACE_BLK_OPT_CLASSIC))\r\nreturn TRACE_TYPE_UNHANDLED;\r\nreturn print_one_line(iter, true);\r\n}\r\nstatic int\r\nblk_tracer_set_flag(struct trace_array *tr, u32 old_flags, u32 bit, int set)\r\n{\r\nif (bit == TRACE_BLK_OPT_CLASSIC) {\r\nif (set)\r\ntrace_flags &= ~TRACE_ITER_CONTEXT_INFO;\r\nelse\r\ntrace_flags |= TRACE_ITER_CONTEXT_INFO;\r\n}\r\nreturn 0;\r\n}\r\nstatic int __init init_blk_tracer(void)\r\n{\r\nif (!register_ftrace_event(&trace_blk_event)) {\r\npr_warning("Warning: could not register block events\n");\r\nreturn 1;\r\n}\r\nif (register_tracer(&blk_tracer) != 0) {\r\npr_warning("Warning: could not register the block tracer\n");\r\nunregister_ftrace_event(&trace_blk_event);\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int blk_trace_remove_queue(struct request_queue *q)\r\n{\r\nstruct blk_trace *bt;\r\nbt = xchg(&q->blk_trace, NULL);\r\nif (bt == NULL)\r\nreturn -EINVAL;\r\nif (atomic_dec_and_test(&blk_probes_ref))\r\nblk_unregister_tracepoints();\r\nspin_lock_irq(&running_trace_lock);\r\nlist_del(&bt->running_list);\r\nspin_unlock_irq(&running_trace_lock);\r\nblk_trace_free(bt);\r\nreturn 0;\r\n}\r\nstatic int blk_trace_setup_queue(struct request_queue *q,\r\nstruct block_device *bdev)\r\n{\r\nstruct blk_trace *old_bt, *bt = NULL;\r\nint ret = -ENOMEM;\r\nbt = kzalloc(sizeof(*bt), GFP_KERNEL);\r\nif (!bt)\r\nreturn -ENOMEM;\r\nbt->msg_data = __alloc_percpu(BLK_TN_MAX_MSG, __alignof__(char));\r\nif (!bt->msg_data)\r\ngoto free_bt;\r\nbt->dev = bdev->bd_dev;\r\nbt->act_mask = (u16)-1;\r\nblk_trace_setup_lba(bt, bdev);\r\nold_bt = xchg(&q->blk_trace, bt);\r\nif (old_bt != NULL) {\r\n(void)xchg(&q->blk_trace, old_bt);\r\nret = -EBUSY;\r\ngoto free_bt;\r\n}\r\nif (atomic_inc_return(&blk_probes_ref) == 1)\r\nblk_register_tracepoints();\r\nreturn 0;\r\nfree_bt:\r\nblk_trace_free(bt);\r\nreturn ret;\r\n}\r\nstatic int blk_trace_str2mask(const char *str)\r\n{\r\nint i;\r\nint mask = 0;\r\nchar *buf, *s, *token;\r\nbuf = kstrdup(str, GFP_KERNEL);\r\nif (buf == NULL)\r\nreturn -ENOMEM;\r\ns = strstrip(buf);\r\nwhile (1) {\r\ntoken = strsep(&s, ",");\r\nif (token == NULL)\r\nbreak;\r\nif (*token == '\0')\r\ncontinue;\r\nfor (i = 0; i < ARRAY_SIZE(mask_maps); i++) {\r\nif (strcasecmp(token, mask_maps[i].str) == 0) {\r\nmask |= mask_maps[i].mask;\r\nbreak;\r\n}\r\n}\r\nif (i == ARRAY_SIZE(mask_maps)) {\r\nmask = -EINVAL;\r\nbreak;\r\n}\r\n}\r\nkfree(buf);\r\nreturn mask;\r\n}\r\nstatic ssize_t blk_trace_mask2str(char *buf, int mask)\r\n{\r\nint i;\r\nchar *p = buf;\r\nfor (i = 0; i < ARRAY_SIZE(mask_maps); i++) {\r\nif (mask & mask_maps[i].mask) {\r\np += sprintf(p, "%s%s",\r\n(p == buf) ? "" : ",", mask_maps[i].str);\r\n}\r\n}\r\n*p++ = '\n';\r\nreturn p - buf;\r\n}\r\nstatic struct request_queue *blk_trace_get_queue(struct block_device *bdev)\r\n{\r\nif (bdev->bd_disk == NULL)\r\nreturn NULL;\r\nreturn bdev_get_queue(bdev);\r\n}\r\nstatic ssize_t sysfs_blk_trace_attr_show(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct hd_struct *p = dev_to_part(dev);\r\nstruct request_queue *q;\r\nstruct block_device *bdev;\r\nssize_t ret = -ENXIO;\r\nbdev = bdget(part_devt(p));\r\nif (bdev == NULL)\r\ngoto out;\r\nq = blk_trace_get_queue(bdev);\r\nif (q == NULL)\r\ngoto out_bdput;\r\nmutex_lock(&bdev->bd_mutex);\r\nif (attr == &dev_attr_enable) {\r\nret = sprintf(buf, "%u\n", !!q->blk_trace);\r\ngoto out_unlock_bdev;\r\n}\r\nif (q->blk_trace == NULL)\r\nret = sprintf(buf, "disabled\n");\r\nelse if (attr == &dev_attr_act_mask)\r\nret = blk_trace_mask2str(buf, q->blk_trace->act_mask);\r\nelse if (attr == &dev_attr_pid)\r\nret = sprintf(buf, "%u\n", q->blk_trace->pid);\r\nelse if (attr == &dev_attr_start_lba)\r\nret = sprintf(buf, "%llu\n", q->blk_trace->start_lba);\r\nelse if (attr == &dev_attr_end_lba)\r\nret = sprintf(buf, "%llu\n", q->blk_trace->end_lba);\r\nout_unlock_bdev:\r\nmutex_unlock(&bdev->bd_mutex);\r\nout_bdput:\r\nbdput(bdev);\r\nout:\r\nreturn ret;\r\n}\r\nstatic ssize_t sysfs_blk_trace_attr_store(struct device *dev,\r\nstruct device_attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nstruct block_device *bdev;\r\nstruct request_queue *q;\r\nstruct hd_struct *p;\r\nu64 value;\r\nssize_t ret = -EINVAL;\r\nif (count == 0)\r\ngoto out;\r\nif (attr == &dev_attr_act_mask) {\r\nif (sscanf(buf, "%llx", &value) != 1) {\r\nret = blk_trace_str2mask(buf);\r\nif (ret < 0)\r\ngoto out;\r\nvalue = ret;\r\n}\r\n} else if (sscanf(buf, "%llu", &value) != 1)\r\ngoto out;\r\nret = -ENXIO;\r\np = dev_to_part(dev);\r\nbdev = bdget(part_devt(p));\r\nif (bdev == NULL)\r\ngoto out;\r\nq = blk_trace_get_queue(bdev);\r\nif (q == NULL)\r\ngoto out_bdput;\r\nmutex_lock(&bdev->bd_mutex);\r\nif (attr == &dev_attr_enable) {\r\nif (value)\r\nret = blk_trace_setup_queue(q, bdev);\r\nelse\r\nret = blk_trace_remove_queue(q);\r\ngoto out_unlock_bdev;\r\n}\r\nret = 0;\r\nif (q->blk_trace == NULL)\r\nret = blk_trace_setup_queue(q, bdev);\r\nif (ret == 0) {\r\nif (attr == &dev_attr_act_mask)\r\nq->blk_trace->act_mask = value;\r\nelse if (attr == &dev_attr_pid)\r\nq->blk_trace->pid = value;\r\nelse if (attr == &dev_attr_start_lba)\r\nq->blk_trace->start_lba = value;\r\nelse if (attr == &dev_attr_end_lba)\r\nq->blk_trace->end_lba = value;\r\n}\r\nout_unlock_bdev:\r\nmutex_unlock(&bdev->bd_mutex);\r\nout_bdput:\r\nbdput(bdev);\r\nout:\r\nreturn ret ? ret : count;\r\n}\r\nint blk_trace_init_sysfs(struct device *dev)\r\n{\r\nreturn sysfs_create_group(&dev->kobj, &blk_trace_attr_group);\r\n}\r\nvoid blk_trace_remove_sysfs(struct device *dev)\r\n{\r\nsysfs_remove_group(&dev->kobj, &blk_trace_attr_group);\r\n}\r\nvoid blk_dump_cmd(char *buf, struct request *rq)\r\n{\r\nint i, end;\r\nint len = rq->cmd_len;\r\nunsigned char *cmd = rq->cmd;\r\nif (rq->cmd_type != REQ_TYPE_BLOCK_PC) {\r\nbuf[0] = '\0';\r\nreturn;\r\n}\r\nfor (end = len - 1; end >= 0; end--)\r\nif (cmd[end])\r\nbreak;\r\nend++;\r\nfor (i = 0; i < len; i++) {\r\nbuf += sprintf(buf, "%s%02x", i == 0 ? "" : " ", cmd[i]);\r\nif (i == end && end != len - 1) {\r\nsprintf(buf, " ..");\r\nbreak;\r\n}\r\n}\r\n}\r\nvoid blk_fill_rwbs(char *rwbs, u32 rw, int bytes)\r\n{\r\nint i = 0;\r\nif (rw & REQ_FLUSH)\r\nrwbs[i++] = 'F';\r\nif (rw & WRITE)\r\nrwbs[i++] = 'W';\r\nelse if (rw & REQ_DISCARD)\r\nrwbs[i++] = 'D';\r\nelse if (bytes)\r\nrwbs[i++] = 'R';\r\nelse\r\nrwbs[i++] = 'N';\r\nif (rw & REQ_FUA)\r\nrwbs[i++] = 'F';\r\nif (rw & REQ_RAHEAD)\r\nrwbs[i++] = 'A';\r\nif (rw & REQ_SYNC)\r\nrwbs[i++] = 'S';\r\nif (rw & REQ_META)\r\nrwbs[i++] = 'M';\r\nif (rw & REQ_SECURE)\r\nrwbs[i++] = 'E';\r\nrwbs[i] = '\0';\r\n}
