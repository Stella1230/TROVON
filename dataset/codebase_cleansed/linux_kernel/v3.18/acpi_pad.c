static void power_saving_mwait_init(void)\r\n{\r\nunsigned int eax, ebx, ecx, edx;\r\nunsigned int highest_cstate = 0;\r\nunsigned int highest_subcstate = 0;\r\nint i;\r\nif (!boot_cpu_has(X86_FEATURE_MWAIT))\r\nreturn;\r\nif (boot_cpu_data.cpuid_level < CPUID_MWAIT_LEAF)\r\nreturn;\r\ncpuid(CPUID_MWAIT_LEAF, &eax, &ebx, &ecx, &edx);\r\nif (!(ecx & CPUID5_ECX_EXTENSIONS_SUPPORTED) ||\r\n!(ecx & CPUID5_ECX_INTERRUPT_BREAK))\r\nreturn;\r\nedx >>= MWAIT_SUBSTATE_SIZE;\r\nfor (i = 0; i < 7 && edx; i++, edx >>= MWAIT_SUBSTATE_SIZE) {\r\nif (edx & MWAIT_SUBSTATE_MASK) {\r\nhighest_cstate = i;\r\nhighest_subcstate = edx & MWAIT_SUBSTATE_MASK;\r\n}\r\n}\r\npower_saving_mwait_eax = (highest_cstate << MWAIT_SUBSTATE_SIZE) |\r\n(highest_subcstate - 1);\r\n#if defined(CONFIG_X86)\r\nswitch (boot_cpu_data.x86_vendor) {\r\ncase X86_VENDOR_AMD:\r\ncase X86_VENDOR_INTEL:\r\nif (!boot_cpu_has(X86_FEATURE_NONSTOP_TSC))\r\ntsc_detected_unstable = 1;\r\nif (!boot_cpu_has(X86_FEATURE_ARAT))\r\nlapic_detected_unstable = 1;\r\nbreak;\r\ndefault:\r\ntsc_detected_unstable = 1;\r\nlapic_detected_unstable = 1;\r\n}\r\n#endif\r\n}\r\nstatic void round_robin_cpu(unsigned int tsk_index)\r\n{\r\nstruct cpumask *pad_busy_cpus = to_cpumask(pad_busy_cpus_bits);\r\ncpumask_var_t tmp;\r\nint cpu;\r\nunsigned long min_weight = -1;\r\nunsigned long uninitialized_var(preferred_cpu);\r\nif (!alloc_cpumask_var(&tmp, GFP_KERNEL))\r\nreturn;\r\nmutex_lock(&round_robin_lock);\r\ncpumask_clear(tmp);\r\nfor_each_cpu(cpu, pad_busy_cpus)\r\ncpumask_or(tmp, tmp, topology_thread_cpumask(cpu));\r\ncpumask_andnot(tmp, cpu_online_mask, tmp);\r\nif (cpumask_empty(tmp))\r\ncpumask_andnot(tmp, cpu_online_mask, pad_busy_cpus);\r\nif (cpumask_empty(tmp)) {\r\nmutex_unlock(&round_robin_lock);\r\nreturn;\r\n}\r\nfor_each_cpu(cpu, tmp) {\r\nif (cpu_weight[cpu] < min_weight) {\r\nmin_weight = cpu_weight[cpu];\r\npreferred_cpu = cpu;\r\n}\r\n}\r\nif (tsk_in_cpu[tsk_index] != -1)\r\ncpumask_clear_cpu(tsk_in_cpu[tsk_index], pad_busy_cpus);\r\ntsk_in_cpu[tsk_index] = preferred_cpu;\r\ncpumask_set_cpu(preferred_cpu, pad_busy_cpus);\r\ncpu_weight[preferred_cpu]++;\r\nmutex_unlock(&round_robin_lock);\r\nset_cpus_allowed_ptr(current, cpumask_of(preferred_cpu));\r\n}\r\nstatic void exit_round_robin(unsigned int tsk_index)\r\n{\r\nstruct cpumask *pad_busy_cpus = to_cpumask(pad_busy_cpus_bits);\r\ncpumask_clear_cpu(tsk_in_cpu[tsk_index], pad_busy_cpus);\r\ntsk_in_cpu[tsk_index] = -1;\r\n}\r\nstatic int power_saving_thread(void *data)\r\n{\r\nstruct sched_param param = {.sched_priority = 1};\r\nint do_sleep;\r\nunsigned int tsk_index = (unsigned long)data;\r\nu64 last_jiffies = 0;\r\nsched_setscheduler(current, SCHED_RR, &param);\r\nwhile (!kthread_should_stop()) {\r\nint cpu;\r\nunsigned long expire_time;\r\ntry_to_freeze();\r\nexpire_time = last_jiffies + round_robin_time * HZ;\r\nif (time_before(expire_time, jiffies)) {\r\nlast_jiffies = jiffies;\r\nround_robin_cpu(tsk_index);\r\n}\r\ndo_sleep = 0;\r\nexpire_time = jiffies + HZ * (100 - idle_pct) / 100;\r\nwhile (!need_resched()) {\r\nif (tsc_detected_unstable && !tsc_marked_unstable) {\r\nmark_tsc_unstable("TSC halts in idle");\r\ntsc_marked_unstable = 1;\r\n}\r\nif (lapic_detected_unstable && !lapic_marked_unstable) {\r\nint i;\r\nfor_each_online_cpu(i)\r\nclockevents_notify(\r\nCLOCK_EVT_NOTIFY_BROADCAST_ON,\r\n&i);\r\nlapic_marked_unstable = 1;\r\n}\r\nlocal_irq_disable();\r\ncpu = smp_processor_id();\r\nif (lapic_marked_unstable)\r\nclockevents_notify(\r\nCLOCK_EVT_NOTIFY_BROADCAST_ENTER, &cpu);\r\nstop_critical_timings();\r\nmwait_idle_with_hints(power_saving_mwait_eax, 1);\r\nstart_critical_timings();\r\nif (lapic_marked_unstable)\r\nclockevents_notify(\r\nCLOCK_EVT_NOTIFY_BROADCAST_EXIT, &cpu);\r\nlocal_irq_enable();\r\nif (time_before(expire_time, jiffies)) {\r\ndo_sleep = 1;\r\nbreak;\r\n}\r\n}\r\nif (unlikely(do_sleep))\r\nschedule_timeout_killable(HZ * idle_pct / 100);\r\nif (unlikely(need_resched()))\r\nschedule();\r\n}\r\nexit_round_robin(tsk_index);\r\nreturn 0;\r\n}\r\nstatic int create_power_saving_task(void)\r\n{\r\nint rc;\r\nps_tsks[ps_tsk_num] = kthread_run(power_saving_thread,\r\n(void *)(unsigned long)ps_tsk_num,\r\n"acpi_pad/%d", ps_tsk_num);\r\nif (IS_ERR(ps_tsks[ps_tsk_num])) {\r\nrc = PTR_ERR(ps_tsks[ps_tsk_num]);\r\nps_tsks[ps_tsk_num] = NULL;\r\n} else {\r\nrc = 0;\r\nps_tsk_num++;\r\n}\r\nreturn rc;\r\n}\r\nstatic void destroy_power_saving_task(void)\r\n{\r\nif (ps_tsk_num > 0) {\r\nps_tsk_num--;\r\nkthread_stop(ps_tsks[ps_tsk_num]);\r\nps_tsks[ps_tsk_num] = NULL;\r\n}\r\n}\r\nstatic void set_power_saving_task_num(unsigned int num)\r\n{\r\nif (num > ps_tsk_num) {\r\nwhile (ps_tsk_num < num) {\r\nif (create_power_saving_task())\r\nreturn;\r\n}\r\n} else if (num < ps_tsk_num) {\r\nwhile (ps_tsk_num > num)\r\ndestroy_power_saving_task();\r\n}\r\n}\r\nstatic void acpi_pad_idle_cpus(unsigned int num_cpus)\r\n{\r\nget_online_cpus();\r\nnum_cpus = min_t(unsigned int, num_cpus, num_online_cpus());\r\nset_power_saving_task_num(num_cpus);\r\nput_online_cpus();\r\n}\r\nstatic uint32_t acpi_pad_idle_cpus_num(void)\r\n{\r\nreturn ps_tsk_num;\r\n}\r\nstatic ssize_t acpi_pad_rrtime_store(struct device *dev,\r\nstruct device_attribute *attr, const char *buf, size_t count)\r\n{\r\nunsigned long num;\r\nif (kstrtoul(buf, 0, &num))\r\nreturn -EINVAL;\r\nif (num < 1 || num >= 100)\r\nreturn -EINVAL;\r\nmutex_lock(&isolated_cpus_lock);\r\nround_robin_time = num;\r\nmutex_unlock(&isolated_cpus_lock);\r\nreturn count;\r\n}\r\nstatic ssize_t acpi_pad_rrtime_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nreturn scnprintf(buf, PAGE_SIZE, "%d\n", round_robin_time);\r\n}\r\nstatic ssize_t acpi_pad_idlepct_store(struct device *dev,\r\nstruct device_attribute *attr, const char *buf, size_t count)\r\n{\r\nunsigned long num;\r\nif (kstrtoul(buf, 0, &num))\r\nreturn -EINVAL;\r\nif (num < 1 || num >= 100)\r\nreturn -EINVAL;\r\nmutex_lock(&isolated_cpus_lock);\r\nidle_pct = num;\r\nmutex_unlock(&isolated_cpus_lock);\r\nreturn count;\r\n}\r\nstatic ssize_t acpi_pad_idlepct_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nreturn scnprintf(buf, PAGE_SIZE, "%d\n", idle_pct);\r\n}\r\nstatic ssize_t acpi_pad_idlecpus_store(struct device *dev,\r\nstruct device_attribute *attr, const char *buf, size_t count)\r\n{\r\nunsigned long num;\r\nif (kstrtoul(buf, 0, &num))\r\nreturn -EINVAL;\r\nmutex_lock(&isolated_cpus_lock);\r\nacpi_pad_idle_cpus(num);\r\nmutex_unlock(&isolated_cpus_lock);\r\nreturn count;\r\n}\r\nstatic ssize_t acpi_pad_idlecpus_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nint n = 0;\r\nn = cpumask_scnprintf(buf, PAGE_SIZE-2, to_cpumask(pad_busy_cpus_bits));\r\nbuf[n++] = '\n';\r\nbuf[n] = '\0';\r\nreturn n;\r\n}\r\nstatic int acpi_pad_add_sysfs(struct acpi_device *device)\r\n{\r\nint result;\r\nresult = device_create_file(&device->dev, &dev_attr_idlecpus);\r\nif (result)\r\nreturn -ENODEV;\r\nresult = device_create_file(&device->dev, &dev_attr_idlepct);\r\nif (result) {\r\ndevice_remove_file(&device->dev, &dev_attr_idlecpus);\r\nreturn -ENODEV;\r\n}\r\nresult = device_create_file(&device->dev, &dev_attr_rrtime);\r\nif (result) {\r\ndevice_remove_file(&device->dev, &dev_attr_idlecpus);\r\ndevice_remove_file(&device->dev, &dev_attr_idlepct);\r\nreturn -ENODEV;\r\n}\r\nreturn 0;\r\n}\r\nstatic void acpi_pad_remove_sysfs(struct acpi_device *device)\r\n{\r\ndevice_remove_file(&device->dev, &dev_attr_idlecpus);\r\ndevice_remove_file(&device->dev, &dev_attr_idlepct);\r\ndevice_remove_file(&device->dev, &dev_attr_rrtime);\r\n}\r\nstatic int acpi_pad_pur(acpi_handle handle)\r\n{\r\nstruct acpi_buffer buffer = {ACPI_ALLOCATE_BUFFER, NULL};\r\nunion acpi_object *package;\r\nint num = -1;\r\nif (ACPI_FAILURE(acpi_evaluate_object(handle, "_PUR", NULL, &buffer)))\r\nreturn num;\r\nif (!buffer.length || !buffer.pointer)\r\nreturn num;\r\npackage = buffer.pointer;\r\nif (package->type == ACPI_TYPE_PACKAGE &&\r\npackage->package.count == 2 &&\r\npackage->package.elements[0].integer.value == 1)\r\nnum = package->package.elements[1].integer.value;\r\nkfree(buffer.pointer);\r\nreturn num;\r\n}\r\nstatic void acpi_pad_handle_notify(acpi_handle handle)\r\n{\r\nint num_cpus;\r\nuint32_t idle_cpus;\r\nstruct acpi_buffer param = {\r\n.length = 4,\r\n.pointer = (void *)&idle_cpus,\r\n};\r\nmutex_lock(&isolated_cpus_lock);\r\nnum_cpus = acpi_pad_pur(handle);\r\nif (num_cpus < 0) {\r\nmutex_unlock(&isolated_cpus_lock);\r\nreturn;\r\n}\r\nacpi_pad_idle_cpus(num_cpus);\r\nidle_cpus = acpi_pad_idle_cpus_num();\r\nacpi_evaluate_ost(handle, ACPI_PROCESSOR_AGGREGATOR_NOTIFY, 0, &param);\r\nmutex_unlock(&isolated_cpus_lock);\r\n}\r\nstatic void acpi_pad_notify(acpi_handle handle, u32 event,\r\nvoid *data)\r\n{\r\nstruct acpi_device *device = data;\r\nswitch (event) {\r\ncase ACPI_PROCESSOR_AGGREGATOR_NOTIFY:\r\nacpi_pad_handle_notify(handle);\r\nacpi_bus_generate_netlink_event(device->pnp.device_class,\r\ndev_name(&device->dev), event, 0);\r\nbreak;\r\ndefault:\r\npr_warn("Unsupported event [0x%x]\n", event);\r\nbreak;\r\n}\r\n}\r\nstatic int acpi_pad_add(struct acpi_device *device)\r\n{\r\nacpi_status status;\r\nstrcpy(acpi_device_name(device), ACPI_PROCESSOR_AGGREGATOR_DEVICE_NAME);\r\nstrcpy(acpi_device_class(device), ACPI_PROCESSOR_AGGREGATOR_CLASS);\r\nif (acpi_pad_add_sysfs(device))\r\nreturn -ENODEV;\r\nstatus = acpi_install_notify_handler(device->handle,\r\nACPI_DEVICE_NOTIFY, acpi_pad_notify, device);\r\nif (ACPI_FAILURE(status)) {\r\nacpi_pad_remove_sysfs(device);\r\nreturn -ENODEV;\r\n}\r\nreturn 0;\r\n}\r\nstatic int acpi_pad_remove(struct acpi_device *device)\r\n{\r\nmutex_lock(&isolated_cpus_lock);\r\nacpi_pad_idle_cpus(0);\r\nmutex_unlock(&isolated_cpus_lock);\r\nacpi_remove_notify_handler(device->handle,\r\nACPI_DEVICE_NOTIFY, acpi_pad_notify);\r\nacpi_pad_remove_sysfs(device);\r\nreturn 0;\r\n}\r\nstatic int __init acpi_pad_init(void)\r\n{\r\npower_saving_mwait_init();\r\nif (power_saving_mwait_eax == 0)\r\nreturn -EINVAL;\r\nreturn acpi_bus_register_driver(&acpi_pad_driver);\r\n}\r\nstatic void __exit acpi_pad_exit(void)\r\n{\r\nacpi_bus_unregister_driver(&acpi_pad_driver);\r\n}
