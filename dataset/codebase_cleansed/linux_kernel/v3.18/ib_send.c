char *rds_ib_wc_status_str(enum ib_wc_status status)\r\n{\r\nreturn rds_str_array(rds_ib_wc_status_strings,\r\nARRAY_SIZE(rds_ib_wc_status_strings), status);\r\n}\r\nstatic void rds_ib_send_complete(struct rds_message *rm,\r\nint wc_status,\r\nvoid (*complete)(struct rds_message *rm, int status))\r\n{\r\nint notify_status;\r\nswitch (wc_status) {\r\ncase IB_WC_WR_FLUSH_ERR:\r\nreturn;\r\ncase IB_WC_SUCCESS:\r\nnotify_status = RDS_RDMA_SUCCESS;\r\nbreak;\r\ncase IB_WC_REM_ACCESS_ERR:\r\nnotify_status = RDS_RDMA_REMOTE_ERROR;\r\nbreak;\r\ndefault:\r\nnotify_status = RDS_RDMA_OTHER_ERROR;\r\nbreak;\r\n}\r\ncomplete(rm, notify_status);\r\n}\r\nstatic void rds_ib_send_unmap_data(struct rds_ib_connection *ic,\r\nstruct rm_data_op *op,\r\nint wc_status)\r\n{\r\nif (op->op_nents)\r\nib_dma_unmap_sg(ic->i_cm_id->device,\r\nop->op_sg, op->op_nents,\r\nDMA_TO_DEVICE);\r\n}\r\nstatic void rds_ib_send_unmap_rdma(struct rds_ib_connection *ic,\r\nstruct rm_rdma_op *op,\r\nint wc_status)\r\n{\r\nif (op->op_mapped) {\r\nib_dma_unmap_sg(ic->i_cm_id->device,\r\nop->op_sg, op->op_nents,\r\nop->op_write ? DMA_TO_DEVICE : DMA_FROM_DEVICE);\r\nop->op_mapped = 0;\r\n}\r\nrds_ib_send_complete(container_of(op, struct rds_message, rdma),\r\nwc_status, rds_rdma_send_complete);\r\nif (op->op_write)\r\nrds_stats_add(s_send_rdma_bytes, op->op_bytes);\r\nelse\r\nrds_stats_add(s_recv_rdma_bytes, op->op_bytes);\r\n}\r\nstatic void rds_ib_send_unmap_atomic(struct rds_ib_connection *ic,\r\nstruct rm_atomic_op *op,\r\nint wc_status)\r\n{\r\nif (op->op_mapped) {\r\nib_dma_unmap_sg(ic->i_cm_id->device, op->op_sg, 1,\r\nDMA_FROM_DEVICE);\r\nop->op_mapped = 0;\r\n}\r\nrds_ib_send_complete(container_of(op, struct rds_message, atomic),\r\nwc_status, rds_atomic_send_complete);\r\nif (op->op_type == RDS_ATOMIC_TYPE_CSWP)\r\nrds_ib_stats_inc(s_ib_atomic_cswp);\r\nelse\r\nrds_ib_stats_inc(s_ib_atomic_fadd);\r\n}\r\nstatic struct rds_message *rds_ib_send_unmap_op(struct rds_ib_connection *ic,\r\nstruct rds_ib_send_work *send,\r\nint wc_status)\r\n{\r\nstruct rds_message *rm = NULL;\r\nswitch (send->s_wr.opcode) {\r\ncase IB_WR_SEND:\r\nif (send->s_op) {\r\nrm = container_of(send->s_op, struct rds_message, data);\r\nrds_ib_send_unmap_data(ic, send->s_op, wc_status);\r\n}\r\nbreak;\r\ncase IB_WR_RDMA_WRITE:\r\ncase IB_WR_RDMA_READ:\r\nif (send->s_op) {\r\nrm = container_of(send->s_op, struct rds_message, rdma);\r\nrds_ib_send_unmap_rdma(ic, send->s_op, wc_status);\r\n}\r\nbreak;\r\ncase IB_WR_ATOMIC_FETCH_AND_ADD:\r\ncase IB_WR_ATOMIC_CMP_AND_SWP:\r\nif (send->s_op) {\r\nrm = container_of(send->s_op, struct rds_message, atomic);\r\nrds_ib_send_unmap_atomic(ic, send->s_op, wc_status);\r\n}\r\nbreak;\r\ndefault:\r\nprintk_ratelimited(KERN_NOTICE\r\n"RDS/IB: %s: unexpected opcode 0x%x in WR!\n",\r\n__func__, send->s_wr.opcode);\r\nbreak;\r\n}\r\nsend->s_wr.opcode = 0xdead;\r\nreturn rm;\r\n}\r\nvoid rds_ib_send_init_ring(struct rds_ib_connection *ic)\r\n{\r\nstruct rds_ib_send_work *send;\r\nu32 i;\r\nfor (i = 0, send = ic->i_sends; i < ic->i_send_ring.w_nr; i++, send++) {\r\nstruct ib_sge *sge;\r\nsend->s_op = NULL;\r\nsend->s_wr.wr_id = i;\r\nsend->s_wr.sg_list = send->s_sge;\r\nsend->s_wr.ex.imm_data = 0;\r\nsge = &send->s_sge[0];\r\nsge->addr = ic->i_send_hdrs_dma + (i * sizeof(struct rds_header));\r\nsge->length = sizeof(struct rds_header);\r\nsge->lkey = ic->i_mr->lkey;\r\nsend->s_sge[1].lkey = ic->i_mr->lkey;\r\n}\r\n}\r\nvoid rds_ib_send_clear_ring(struct rds_ib_connection *ic)\r\n{\r\nstruct rds_ib_send_work *send;\r\nu32 i;\r\nfor (i = 0, send = ic->i_sends; i < ic->i_send_ring.w_nr; i++, send++) {\r\nif (send->s_op && send->s_wr.opcode != 0xdead)\r\nrds_ib_send_unmap_op(ic, send, IB_WC_WR_FLUSH_ERR);\r\n}\r\n}\r\nstatic void rds_ib_sub_signaled(struct rds_ib_connection *ic, int nr)\r\n{\r\nif ((atomic_sub_return(nr, &ic->i_signaled_sends) == 0) &&\r\nwaitqueue_active(&rds_ib_ring_empty_wait))\r\nwake_up(&rds_ib_ring_empty_wait);\r\nBUG_ON(atomic_read(&ic->i_signaled_sends) < 0);\r\n}\r\nvoid rds_ib_send_cq_comp_handler(struct ib_cq *cq, void *context)\r\n{\r\nstruct rds_connection *conn = context;\r\nstruct rds_ib_connection *ic = conn->c_transport_data;\r\nstruct rds_message *rm = NULL;\r\nstruct ib_wc wc;\r\nstruct rds_ib_send_work *send;\r\nu32 completed;\r\nu32 oldest;\r\nu32 i = 0;\r\nint ret;\r\nint nr_sig = 0;\r\nrdsdebug("cq %p conn %p\n", cq, conn);\r\nrds_ib_stats_inc(s_ib_tx_cq_call);\r\nret = ib_req_notify_cq(cq, IB_CQ_NEXT_COMP);\r\nif (ret)\r\nrdsdebug("ib_req_notify_cq send failed: %d\n", ret);\r\nwhile (ib_poll_cq(cq, 1, &wc) > 0) {\r\nrdsdebug("wc wr_id 0x%llx status %u (%s) byte_len %u imm_data %u\n",\r\n(unsigned long long)wc.wr_id, wc.status,\r\nrds_ib_wc_status_str(wc.status), wc.byte_len,\r\nbe32_to_cpu(wc.ex.imm_data));\r\nrds_ib_stats_inc(s_ib_tx_cq_event);\r\nif (wc.wr_id == RDS_IB_ACK_WR_ID) {\r\nif (time_after(jiffies, ic->i_ack_queued + HZ/2))\r\nrds_ib_stats_inc(s_ib_tx_stalled);\r\nrds_ib_ack_send_complete(ic);\r\ncontinue;\r\n}\r\noldest = rds_ib_ring_oldest(&ic->i_send_ring);\r\ncompleted = rds_ib_ring_completed(&ic->i_send_ring, wc.wr_id, oldest);\r\nfor (i = 0; i < completed; i++) {\r\nsend = &ic->i_sends[oldest];\r\nif (send->s_wr.send_flags & IB_SEND_SIGNALED)\r\nnr_sig++;\r\nrm = rds_ib_send_unmap_op(ic, send, wc.status);\r\nif (time_after(jiffies, send->s_queued + HZ/2))\r\nrds_ib_stats_inc(s_ib_tx_stalled);\r\nif (send->s_op) {\r\nif (send->s_op == rm->m_final_op) {\r\nrds_message_unmapped(rm);\r\n}\r\nrds_message_put(rm);\r\nsend->s_op = NULL;\r\n}\r\noldest = (oldest + 1) % ic->i_send_ring.w_nr;\r\n}\r\nrds_ib_ring_free(&ic->i_send_ring, completed);\r\nrds_ib_sub_signaled(ic, nr_sig);\r\nnr_sig = 0;\r\nif (test_and_clear_bit(RDS_LL_SEND_FULL, &conn->c_flags) ||\r\ntest_bit(0, &conn->c_map_queued))\r\nqueue_delayed_work(rds_wq, &conn->c_send_w, 0);\r\nif (wc.status != IB_WC_SUCCESS && rds_conn_up(conn)) {\r\nrds_ib_conn_error(conn, "send completion on %pI4 had status "\r\n"%u (%s), disconnecting and reconnecting\n",\r\n&conn->c_faddr, wc.status,\r\nrds_ib_wc_status_str(wc.status));\r\n}\r\n}\r\n}\r\nint rds_ib_send_grab_credits(struct rds_ib_connection *ic,\r\nu32 wanted, u32 *adv_credits, int need_posted, int max_posted)\r\n{\r\nunsigned int avail, posted, got = 0, advertise;\r\nlong oldval, newval;\r\n*adv_credits = 0;\r\nif (!ic->i_flowctl)\r\nreturn wanted;\r\ntry_again:\r\nadvertise = 0;\r\noldval = newval = atomic_read(&ic->i_credits);\r\nposted = IB_GET_POST_CREDITS(oldval);\r\navail = IB_GET_SEND_CREDITS(oldval);\r\nrdsdebug("rds_ib_send_grab_credits(%u): credits=%u posted=%u\n",\r\nwanted, avail, posted);\r\nif (avail && !posted)\r\navail--;\r\nif (avail < wanted) {\r\nstruct rds_connection *conn = ic->i_cm_id->context;\r\nset_bit(RDS_LL_SEND_FULL, &conn->c_flags);\r\ngot = avail;\r\n} else {\r\ngot = wanted;\r\n}\r\nnewval -= IB_SET_SEND_CREDITS(got);\r\nif (posted && (got || need_posted)) {\r\nadvertise = min_t(unsigned int, posted, max_posted);\r\nnewval -= IB_SET_POST_CREDITS(advertise);\r\n}\r\nif (atomic_cmpxchg(&ic->i_credits, oldval, newval) != oldval)\r\ngoto try_again;\r\n*adv_credits = advertise;\r\nreturn got;\r\n}\r\nvoid rds_ib_send_add_credits(struct rds_connection *conn, unsigned int credits)\r\n{\r\nstruct rds_ib_connection *ic = conn->c_transport_data;\r\nif (credits == 0)\r\nreturn;\r\nrdsdebug("rds_ib_send_add_credits(%u): current=%u%s\n",\r\ncredits,\r\nIB_GET_SEND_CREDITS(atomic_read(&ic->i_credits)),\r\ntest_bit(RDS_LL_SEND_FULL, &conn->c_flags) ? ", ll_send_full" : "");\r\natomic_add(IB_SET_SEND_CREDITS(credits), &ic->i_credits);\r\nif (test_and_clear_bit(RDS_LL_SEND_FULL, &conn->c_flags))\r\nqueue_delayed_work(rds_wq, &conn->c_send_w, 0);\r\nWARN_ON(IB_GET_SEND_CREDITS(credits) >= 16384);\r\nrds_ib_stats_inc(s_ib_rx_credit_updates);\r\n}\r\nvoid rds_ib_advertise_credits(struct rds_connection *conn, unsigned int posted)\r\n{\r\nstruct rds_ib_connection *ic = conn->c_transport_data;\r\nif (posted == 0)\r\nreturn;\r\natomic_add(IB_SET_POST_CREDITS(posted), &ic->i_credits);\r\nif (IB_GET_POST_CREDITS(atomic_read(&ic->i_credits)) >= 16)\r\nset_bit(IB_ACK_REQUESTED, &ic->i_ack_flags);\r\n}\r\nstatic inline int rds_ib_set_wr_signal_state(struct rds_ib_connection *ic,\r\nstruct rds_ib_send_work *send,\r\nbool notify)\r\n{\r\nif (ic->i_unsignaled_wrs-- == 0 || notify) {\r\nic->i_unsignaled_wrs = rds_ib_sysctl_max_unsig_wrs;\r\nsend->s_wr.send_flags |= IB_SEND_SIGNALED;\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nint rds_ib_xmit(struct rds_connection *conn, struct rds_message *rm,\r\nunsigned int hdr_off, unsigned int sg, unsigned int off)\r\n{\r\nstruct rds_ib_connection *ic = conn->c_transport_data;\r\nstruct ib_device *dev = ic->i_cm_id->device;\r\nstruct rds_ib_send_work *send = NULL;\r\nstruct rds_ib_send_work *first;\r\nstruct rds_ib_send_work *prev;\r\nstruct ib_send_wr *failed_wr;\r\nstruct scatterlist *scat;\r\nu32 pos;\r\nu32 i;\r\nu32 work_alloc;\r\nu32 credit_alloc = 0;\r\nu32 posted;\r\nu32 adv_credits = 0;\r\nint send_flags = 0;\r\nint bytes_sent = 0;\r\nint ret;\r\nint flow_controlled = 0;\r\nint nr_sig = 0;\r\nBUG_ON(off % RDS_FRAG_SIZE);\r\nBUG_ON(hdr_off != 0 && hdr_off != sizeof(struct rds_header));\r\nif (conn->c_loopback\r\n&& rm->m_inc.i_hdr.h_flags & RDS_FLAG_CONG_BITMAP) {\r\nrds_cong_map_updated(conn->c_fcong, ~(u64) 0);\r\nscat = &rm->data.op_sg[sg];\r\nret = max_t(int, RDS_CONG_MAP_BYTES, scat->length);\r\nreturn sizeof(struct rds_header) + ret;\r\n}\r\nif (be32_to_cpu(rm->m_inc.i_hdr.h_len) == 0)\r\ni = 1;\r\nelse\r\ni = ceil(be32_to_cpu(rm->m_inc.i_hdr.h_len), RDS_FRAG_SIZE);\r\nwork_alloc = rds_ib_ring_alloc(&ic->i_send_ring, i, &pos);\r\nif (work_alloc == 0) {\r\nset_bit(RDS_LL_SEND_FULL, &conn->c_flags);\r\nrds_ib_stats_inc(s_ib_tx_ring_full);\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\nif (ic->i_flowctl) {\r\ncredit_alloc = rds_ib_send_grab_credits(ic, work_alloc, &posted, 0, RDS_MAX_ADV_CREDIT);\r\nadv_credits += posted;\r\nif (credit_alloc < work_alloc) {\r\nrds_ib_ring_unalloc(&ic->i_send_ring, work_alloc - credit_alloc);\r\nwork_alloc = credit_alloc;\r\nflow_controlled = 1;\r\n}\r\nif (work_alloc == 0) {\r\nset_bit(RDS_LL_SEND_FULL, &conn->c_flags);\r\nrds_ib_stats_inc(s_ib_tx_throttle);\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\n}\r\nif (!ic->i_data_op) {\r\nif (rm->data.op_nents) {\r\nrm->data.op_count = ib_dma_map_sg(dev,\r\nrm->data.op_sg,\r\nrm->data.op_nents,\r\nDMA_TO_DEVICE);\r\nrdsdebug("ic %p mapping rm %p: %d\n", ic, rm, rm->data.op_count);\r\nif (rm->data.op_count == 0) {\r\nrds_ib_stats_inc(s_ib_tx_sg_mapping_failure);\r\nrds_ib_ring_unalloc(&ic->i_send_ring, work_alloc);\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\n} else {\r\nrm->data.op_count = 0;\r\n}\r\nrds_message_addref(rm);\r\nic->i_data_op = &rm->data;\r\nif (test_bit(RDS_MSG_ACK_REQUIRED, &rm->m_flags))\r\nrm->m_inc.i_hdr.h_flags |= RDS_FLAG_ACK_REQUIRED;\r\nif (test_bit(RDS_MSG_RETRANSMITTED, &rm->m_flags))\r\nrm->m_inc.i_hdr.h_flags |= RDS_FLAG_RETRANSMITTED;\r\nif (rm->rdma.op_active) {\r\nstruct rds_ext_header_rdma ext_hdr;\r\next_hdr.h_rdma_rkey = cpu_to_be32(rm->rdma.op_rkey);\r\nrds_message_add_extension(&rm->m_inc.i_hdr,\r\nRDS_EXTHDR_RDMA, &ext_hdr, sizeof(ext_hdr));\r\n}\r\nif (rm->m_rdma_cookie) {\r\nrds_message_add_rdma_dest_extension(&rm->m_inc.i_hdr,\r\nrds_rdma_cookie_key(rm->m_rdma_cookie),\r\nrds_rdma_cookie_offset(rm->m_rdma_cookie));\r\n}\r\nrm->m_inc.i_hdr.h_ack = cpu_to_be64(rds_ib_piggyb_ack(ic));\r\nrds_message_make_checksum(&rm->m_inc.i_hdr);\r\nif (ic->i_flowctl) {\r\nrds_ib_send_grab_credits(ic, 0, &posted, 1, RDS_MAX_ADV_CREDIT - adv_credits);\r\nadv_credits += posted;\r\nBUG_ON(adv_credits > 255);\r\n}\r\n}\r\nif (rm->rdma.op_active && rm->rdma.op_fence)\r\nsend_flags = IB_SEND_FENCE;\r\nsend = &ic->i_sends[pos];\r\nfirst = send;\r\nprev = NULL;\r\nscat = &ic->i_data_op->op_sg[sg];\r\ni = 0;\r\ndo {\r\nunsigned int len = 0;\r\nsend->s_wr.send_flags = send_flags;\r\nsend->s_wr.opcode = IB_WR_SEND;\r\nsend->s_wr.num_sge = 1;\r\nsend->s_wr.next = NULL;\r\nsend->s_queued = jiffies;\r\nsend->s_op = NULL;\r\nsend->s_sge[0].addr = ic->i_send_hdrs_dma\r\n+ (pos * sizeof(struct rds_header));\r\nsend->s_sge[0].length = sizeof(struct rds_header);\r\nmemcpy(&ic->i_send_hdrs[pos], &rm->m_inc.i_hdr, sizeof(struct rds_header));\r\nif (i < work_alloc\r\n&& scat != &rm->data.op_sg[rm->data.op_count]) {\r\nlen = min(RDS_FRAG_SIZE, ib_sg_dma_len(dev, scat) - off);\r\nsend->s_wr.num_sge = 2;\r\nsend->s_sge[1].addr = ib_sg_dma_address(dev, scat) + off;\r\nsend->s_sge[1].length = len;\r\nbytes_sent += len;\r\noff += len;\r\nif (off == ib_sg_dma_len(dev, scat)) {\r\nscat++;\r\noff = 0;\r\n}\r\n}\r\nrds_ib_set_wr_signal_state(ic, send, 0);\r\nif (ic->i_flowctl && flow_controlled && i == (work_alloc-1))\r\nsend->s_wr.send_flags |= IB_SEND_SIGNALED | IB_SEND_SOLICITED;\r\nif (send->s_wr.send_flags & IB_SEND_SIGNALED)\r\nnr_sig++;\r\nrdsdebug("send %p wr %p num_sge %u next %p\n", send,\r\n&send->s_wr, send->s_wr.num_sge, send->s_wr.next);\r\nif (ic->i_flowctl && adv_credits) {\r\nstruct rds_header *hdr = &ic->i_send_hdrs[pos];\r\nhdr->h_credit = adv_credits;\r\nrds_message_make_checksum(hdr);\r\nadv_credits = 0;\r\nrds_ib_stats_inc(s_ib_tx_credit_updates);\r\n}\r\nif (prev)\r\nprev->s_wr.next = &send->s_wr;\r\nprev = send;\r\npos = (pos + 1) % ic->i_send_ring.w_nr;\r\nsend = &ic->i_sends[pos];\r\ni++;\r\n} while (i < work_alloc\r\n&& scat != &rm->data.op_sg[rm->data.op_count]);\r\nif (hdr_off == 0)\r\nbytes_sent += sizeof(struct rds_header);\r\nif (scat == &rm->data.op_sg[rm->data.op_count]) {\r\nprev->s_op = ic->i_data_op;\r\nprev->s_wr.send_flags |= IB_SEND_SOLICITED;\r\nic->i_data_op = NULL;\r\n}\r\nif (i < work_alloc) {\r\nrds_ib_ring_unalloc(&ic->i_send_ring, work_alloc - i);\r\nwork_alloc = i;\r\n}\r\nif (ic->i_flowctl && i < credit_alloc)\r\nrds_ib_send_add_credits(conn, credit_alloc - i);\r\nif (nr_sig)\r\natomic_add(nr_sig, &ic->i_signaled_sends);\r\nfailed_wr = &first->s_wr;\r\nret = ib_post_send(ic->i_cm_id->qp, &first->s_wr, &failed_wr);\r\nrdsdebug("ic %p first %p (wr %p) ret %d wr %p\n", ic,\r\nfirst, &first->s_wr, ret, failed_wr);\r\nBUG_ON(failed_wr != &first->s_wr);\r\nif (ret) {\r\nprintk(KERN_WARNING "RDS/IB: ib_post_send to %pI4 "\r\n"returned %d\n", &conn->c_faddr, ret);\r\nrds_ib_ring_unalloc(&ic->i_send_ring, work_alloc);\r\nrds_ib_sub_signaled(ic, nr_sig);\r\nif (prev->s_op) {\r\nic->i_data_op = prev->s_op;\r\nprev->s_op = NULL;\r\n}\r\nrds_ib_conn_error(ic->conn, "ib_post_send failed\n");\r\ngoto out;\r\n}\r\nret = bytes_sent;\r\nout:\r\nBUG_ON(adv_credits);\r\nreturn ret;\r\n}\r\nint rds_ib_xmit_atomic(struct rds_connection *conn, struct rm_atomic_op *op)\r\n{\r\nstruct rds_ib_connection *ic = conn->c_transport_data;\r\nstruct rds_ib_send_work *send = NULL;\r\nstruct ib_send_wr *failed_wr;\r\nstruct rds_ib_device *rds_ibdev;\r\nu32 pos;\r\nu32 work_alloc;\r\nint ret;\r\nint nr_sig = 0;\r\nrds_ibdev = ib_get_client_data(ic->i_cm_id->device, &rds_ib_client);\r\nwork_alloc = rds_ib_ring_alloc(&ic->i_send_ring, 1, &pos);\r\nif (work_alloc != 1) {\r\nrds_ib_ring_unalloc(&ic->i_send_ring, work_alloc);\r\nrds_ib_stats_inc(s_ib_tx_ring_full);\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\nsend = &ic->i_sends[pos];\r\nsend->s_queued = jiffies;\r\nif (op->op_type == RDS_ATOMIC_TYPE_CSWP) {\r\nsend->s_wr.opcode = IB_WR_MASKED_ATOMIC_CMP_AND_SWP;\r\nsend->s_wr.wr.atomic.compare_add = op->op_m_cswp.compare;\r\nsend->s_wr.wr.atomic.swap = op->op_m_cswp.swap;\r\nsend->s_wr.wr.atomic.compare_add_mask = op->op_m_cswp.compare_mask;\r\nsend->s_wr.wr.atomic.swap_mask = op->op_m_cswp.swap_mask;\r\n} else {\r\nsend->s_wr.opcode = IB_WR_MASKED_ATOMIC_FETCH_AND_ADD;\r\nsend->s_wr.wr.atomic.compare_add = op->op_m_fadd.add;\r\nsend->s_wr.wr.atomic.swap = 0;\r\nsend->s_wr.wr.atomic.compare_add_mask = op->op_m_fadd.nocarry_mask;\r\nsend->s_wr.wr.atomic.swap_mask = 0;\r\n}\r\nnr_sig = rds_ib_set_wr_signal_state(ic, send, op->op_notify);\r\nsend->s_wr.num_sge = 1;\r\nsend->s_wr.next = NULL;\r\nsend->s_wr.wr.atomic.remote_addr = op->op_remote_addr;\r\nsend->s_wr.wr.atomic.rkey = op->op_rkey;\r\nsend->s_op = op;\r\nrds_message_addref(container_of(send->s_op, struct rds_message, atomic));\r\nret = ib_dma_map_sg(ic->i_cm_id->device, op->op_sg, 1, DMA_FROM_DEVICE);\r\nrdsdebug("ic %p mapping atomic op %p. mapped %d pg\n", ic, op, ret);\r\nif (ret != 1) {\r\nrds_ib_ring_unalloc(&ic->i_send_ring, work_alloc);\r\nrds_ib_stats_inc(s_ib_tx_sg_mapping_failure);\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\nsend->s_sge[0].addr = ib_sg_dma_address(ic->i_cm_id->device, op->op_sg);\r\nsend->s_sge[0].length = ib_sg_dma_len(ic->i_cm_id->device, op->op_sg);\r\nsend->s_sge[0].lkey = ic->i_mr->lkey;\r\nrdsdebug("rva %Lx rpa %Lx len %u\n", op->op_remote_addr,\r\nsend->s_sge[0].addr, send->s_sge[0].length);\r\nif (nr_sig)\r\natomic_add(nr_sig, &ic->i_signaled_sends);\r\nfailed_wr = &send->s_wr;\r\nret = ib_post_send(ic->i_cm_id->qp, &send->s_wr, &failed_wr);\r\nrdsdebug("ic %p send %p (wr %p) ret %d wr %p\n", ic,\r\nsend, &send->s_wr, ret, failed_wr);\r\nBUG_ON(failed_wr != &send->s_wr);\r\nif (ret) {\r\nprintk(KERN_WARNING "RDS/IB: atomic ib_post_send to %pI4 "\r\n"returned %d\n", &conn->c_faddr, ret);\r\nrds_ib_ring_unalloc(&ic->i_send_ring, work_alloc);\r\nrds_ib_sub_signaled(ic, nr_sig);\r\ngoto out;\r\n}\r\nif (unlikely(failed_wr != &send->s_wr)) {\r\nprintk(KERN_WARNING "RDS/IB: atomic ib_post_send() rc=%d, but failed_wqe updated!\n", ret);\r\nBUG_ON(failed_wr != &send->s_wr);\r\n}\r\nout:\r\nreturn ret;\r\n}\r\nint rds_ib_xmit_rdma(struct rds_connection *conn, struct rm_rdma_op *op)\r\n{\r\nstruct rds_ib_connection *ic = conn->c_transport_data;\r\nstruct rds_ib_send_work *send = NULL;\r\nstruct rds_ib_send_work *first;\r\nstruct rds_ib_send_work *prev;\r\nstruct ib_send_wr *failed_wr;\r\nstruct scatterlist *scat;\r\nunsigned long len;\r\nu64 remote_addr = op->op_remote_addr;\r\nu32 max_sge = ic->rds_ibdev->max_sge;\r\nu32 pos;\r\nu32 work_alloc;\r\nu32 i;\r\nu32 j;\r\nint sent;\r\nint ret;\r\nint num_sge;\r\nint nr_sig = 0;\r\nif (!op->op_mapped) {\r\nop->op_count = ib_dma_map_sg(ic->i_cm_id->device,\r\nop->op_sg, op->op_nents, (op->op_write) ?\r\nDMA_TO_DEVICE : DMA_FROM_DEVICE);\r\nrdsdebug("ic %p mapping op %p: %d\n", ic, op, op->op_count);\r\nif (op->op_count == 0) {\r\nrds_ib_stats_inc(s_ib_tx_sg_mapping_failure);\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\nop->op_mapped = 1;\r\n}\r\ni = ceil(op->op_count, max_sge);\r\nwork_alloc = rds_ib_ring_alloc(&ic->i_send_ring, i, &pos);\r\nif (work_alloc != i) {\r\nrds_ib_ring_unalloc(&ic->i_send_ring, work_alloc);\r\nrds_ib_stats_inc(s_ib_tx_ring_full);\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\nsend = &ic->i_sends[pos];\r\nfirst = send;\r\nprev = NULL;\r\nscat = &op->op_sg[0];\r\nsent = 0;\r\nnum_sge = op->op_count;\r\nfor (i = 0; i < work_alloc && scat != &op->op_sg[op->op_count]; i++) {\r\nsend->s_wr.send_flags = 0;\r\nsend->s_queued = jiffies;\r\nsend->s_op = NULL;\r\nnr_sig += rds_ib_set_wr_signal_state(ic, send, op->op_notify);\r\nsend->s_wr.opcode = op->op_write ? IB_WR_RDMA_WRITE : IB_WR_RDMA_READ;\r\nsend->s_wr.wr.rdma.remote_addr = remote_addr;\r\nsend->s_wr.wr.rdma.rkey = op->op_rkey;\r\nif (num_sge > max_sge) {\r\nsend->s_wr.num_sge = max_sge;\r\nnum_sge -= max_sge;\r\n} else {\r\nsend->s_wr.num_sge = num_sge;\r\n}\r\nsend->s_wr.next = NULL;\r\nif (prev)\r\nprev->s_wr.next = &send->s_wr;\r\nfor (j = 0; j < send->s_wr.num_sge && scat != &op->op_sg[op->op_count]; j++) {\r\nlen = ib_sg_dma_len(ic->i_cm_id->device, scat);\r\nsend->s_sge[j].addr =\r\nib_sg_dma_address(ic->i_cm_id->device, scat);\r\nsend->s_sge[j].length = len;\r\nsend->s_sge[j].lkey = ic->i_mr->lkey;\r\nsent += len;\r\nrdsdebug("ic %p sent %d remote_addr %llu\n", ic, sent, remote_addr);\r\nremote_addr += len;\r\nscat++;\r\n}\r\nrdsdebug("send %p wr %p num_sge %u next %p\n", send,\r\n&send->s_wr, send->s_wr.num_sge, send->s_wr.next);\r\nprev = send;\r\nif (++send == &ic->i_sends[ic->i_send_ring.w_nr])\r\nsend = ic->i_sends;\r\n}\r\nif (scat == &op->op_sg[op->op_count]) {\r\nprev->s_op = op;\r\nrds_message_addref(container_of(op, struct rds_message, rdma));\r\n}\r\nif (i < work_alloc) {\r\nrds_ib_ring_unalloc(&ic->i_send_ring, work_alloc - i);\r\nwork_alloc = i;\r\n}\r\nif (nr_sig)\r\natomic_add(nr_sig, &ic->i_signaled_sends);\r\nfailed_wr = &first->s_wr;\r\nret = ib_post_send(ic->i_cm_id->qp, &first->s_wr, &failed_wr);\r\nrdsdebug("ic %p first %p (wr %p) ret %d wr %p\n", ic,\r\nfirst, &first->s_wr, ret, failed_wr);\r\nBUG_ON(failed_wr != &first->s_wr);\r\nif (ret) {\r\nprintk(KERN_WARNING "RDS/IB: rdma ib_post_send to %pI4 "\r\n"returned %d\n", &conn->c_faddr, ret);\r\nrds_ib_ring_unalloc(&ic->i_send_ring, work_alloc);\r\nrds_ib_sub_signaled(ic, nr_sig);\r\ngoto out;\r\n}\r\nif (unlikely(failed_wr != &first->s_wr)) {\r\nprintk(KERN_WARNING "RDS/IB: ib_post_send() rc=%d, but failed_wqe updated!\n", ret);\r\nBUG_ON(failed_wr != &first->s_wr);\r\n}\r\nout:\r\nreturn ret;\r\n}\r\nvoid rds_ib_xmit_complete(struct rds_connection *conn)\r\n{\r\nstruct rds_ib_connection *ic = conn->c_transport_data;\r\nrds_ib_attempt_ack(ic);\r\n}
