static void seqiv_complete2(struct skcipher_givcrypt_request *req, int err)\r\n{\r\nstruct ablkcipher_request *subreq = skcipher_givcrypt_reqctx(req);\r\nstruct crypto_ablkcipher *geniv;\r\nif (err == -EINPROGRESS)\r\nreturn;\r\nif (err)\r\ngoto out;\r\ngeniv = skcipher_givcrypt_reqtfm(req);\r\nmemcpy(req->creq.info, subreq->info, crypto_ablkcipher_ivsize(geniv));\r\nout:\r\nkfree(subreq->info);\r\n}\r\nstatic void seqiv_complete(struct crypto_async_request *base, int err)\r\n{\r\nstruct skcipher_givcrypt_request *req = base->data;\r\nseqiv_complete2(req, err);\r\nskcipher_givcrypt_complete(req, err);\r\n}\r\nstatic void seqiv_aead_complete2(struct aead_givcrypt_request *req, int err)\r\n{\r\nstruct aead_request *subreq = aead_givcrypt_reqctx(req);\r\nstruct crypto_aead *geniv;\r\nif (err == -EINPROGRESS)\r\nreturn;\r\nif (err)\r\ngoto out;\r\ngeniv = aead_givcrypt_reqtfm(req);\r\nmemcpy(req->areq.iv, subreq->iv, crypto_aead_ivsize(geniv));\r\nout:\r\nkfree(subreq->iv);\r\n}\r\nstatic void seqiv_aead_complete(struct crypto_async_request *base, int err)\r\n{\r\nstruct aead_givcrypt_request *req = base->data;\r\nseqiv_aead_complete2(req, err);\r\naead_givcrypt_complete(req, err);\r\n}\r\nstatic void seqiv_geniv(struct seqiv_ctx *ctx, u8 *info, u64 seq,\r\nunsigned int ivsize)\r\n{\r\nunsigned int len = ivsize;\r\nif (ivsize > sizeof(u64)) {\r\nmemset(info, 0, ivsize - sizeof(u64));\r\nlen = sizeof(u64);\r\n}\r\nseq = cpu_to_be64(seq);\r\nmemcpy(info + ivsize - len, &seq, len);\r\ncrypto_xor(info, ctx->salt, ivsize);\r\n}\r\nstatic int seqiv_givencrypt(struct skcipher_givcrypt_request *req)\r\n{\r\nstruct crypto_ablkcipher *geniv = skcipher_givcrypt_reqtfm(req);\r\nstruct seqiv_ctx *ctx = crypto_ablkcipher_ctx(geniv);\r\nstruct ablkcipher_request *subreq = skcipher_givcrypt_reqctx(req);\r\ncrypto_completion_t compl;\r\nvoid *data;\r\nu8 *info;\r\nunsigned int ivsize;\r\nint err;\r\nablkcipher_request_set_tfm(subreq, skcipher_geniv_cipher(geniv));\r\ncompl = req->creq.base.complete;\r\ndata = req->creq.base.data;\r\ninfo = req->creq.info;\r\nivsize = crypto_ablkcipher_ivsize(geniv);\r\nif (unlikely(!IS_ALIGNED((unsigned long)info,\r\ncrypto_ablkcipher_alignmask(geniv) + 1))) {\r\ninfo = kmalloc(ivsize, req->creq.base.flags &\r\nCRYPTO_TFM_REQ_MAY_SLEEP ? GFP_KERNEL:\r\nGFP_ATOMIC);\r\nif (!info)\r\nreturn -ENOMEM;\r\ncompl = seqiv_complete;\r\ndata = req;\r\n}\r\nablkcipher_request_set_callback(subreq, req->creq.base.flags, compl,\r\ndata);\r\nablkcipher_request_set_crypt(subreq, req->creq.src, req->creq.dst,\r\nreq->creq.nbytes, info);\r\nseqiv_geniv(ctx, info, req->seq, ivsize);\r\nmemcpy(req->giv, info, ivsize);\r\nerr = crypto_ablkcipher_encrypt(subreq);\r\nif (unlikely(info != req->creq.info))\r\nseqiv_complete2(req, err);\r\nreturn err;\r\n}\r\nstatic int seqiv_aead_givencrypt(struct aead_givcrypt_request *req)\r\n{\r\nstruct crypto_aead *geniv = aead_givcrypt_reqtfm(req);\r\nstruct seqiv_ctx *ctx = crypto_aead_ctx(geniv);\r\nstruct aead_request *areq = &req->areq;\r\nstruct aead_request *subreq = aead_givcrypt_reqctx(req);\r\ncrypto_completion_t compl;\r\nvoid *data;\r\nu8 *info;\r\nunsigned int ivsize;\r\nint err;\r\naead_request_set_tfm(subreq, aead_geniv_base(geniv));\r\ncompl = areq->base.complete;\r\ndata = areq->base.data;\r\ninfo = areq->iv;\r\nivsize = crypto_aead_ivsize(geniv);\r\nif (unlikely(!IS_ALIGNED((unsigned long)info,\r\ncrypto_aead_alignmask(geniv) + 1))) {\r\ninfo = kmalloc(ivsize, areq->base.flags &\r\nCRYPTO_TFM_REQ_MAY_SLEEP ? GFP_KERNEL:\r\nGFP_ATOMIC);\r\nif (!info)\r\nreturn -ENOMEM;\r\ncompl = seqiv_aead_complete;\r\ndata = req;\r\n}\r\naead_request_set_callback(subreq, areq->base.flags, compl, data);\r\naead_request_set_crypt(subreq, areq->src, areq->dst, areq->cryptlen,\r\ninfo);\r\naead_request_set_assoc(subreq, areq->assoc, areq->assoclen);\r\nseqiv_geniv(ctx, info, req->seq, ivsize);\r\nmemcpy(req->giv, info, ivsize);\r\nerr = crypto_aead_encrypt(subreq);\r\nif (unlikely(info != areq->iv))\r\nseqiv_aead_complete2(req, err);\r\nreturn err;\r\n}\r\nstatic int seqiv_givencrypt_first(struct skcipher_givcrypt_request *req)\r\n{\r\nstruct crypto_ablkcipher *geniv = skcipher_givcrypt_reqtfm(req);\r\nstruct seqiv_ctx *ctx = crypto_ablkcipher_ctx(geniv);\r\nint err = 0;\r\nspin_lock_bh(&ctx->lock);\r\nif (crypto_ablkcipher_crt(geniv)->givencrypt != seqiv_givencrypt_first)\r\ngoto unlock;\r\ncrypto_ablkcipher_crt(geniv)->givencrypt = seqiv_givencrypt;\r\nerr = crypto_rng_get_bytes(crypto_default_rng, ctx->salt,\r\ncrypto_ablkcipher_ivsize(geniv));\r\nunlock:\r\nspin_unlock_bh(&ctx->lock);\r\nif (err)\r\nreturn err;\r\nreturn seqiv_givencrypt(req);\r\n}\r\nstatic int seqiv_aead_givencrypt_first(struct aead_givcrypt_request *req)\r\n{\r\nstruct crypto_aead *geniv = aead_givcrypt_reqtfm(req);\r\nstruct seqiv_ctx *ctx = crypto_aead_ctx(geniv);\r\nint err = 0;\r\nspin_lock_bh(&ctx->lock);\r\nif (crypto_aead_crt(geniv)->givencrypt != seqiv_aead_givencrypt_first)\r\ngoto unlock;\r\ncrypto_aead_crt(geniv)->givencrypt = seqiv_aead_givencrypt;\r\nerr = crypto_rng_get_bytes(crypto_default_rng, ctx->salt,\r\ncrypto_aead_ivsize(geniv));\r\nunlock:\r\nspin_unlock_bh(&ctx->lock);\r\nif (err)\r\nreturn err;\r\nreturn seqiv_aead_givencrypt(req);\r\n}\r\nstatic int seqiv_init(struct crypto_tfm *tfm)\r\n{\r\nstruct crypto_ablkcipher *geniv = __crypto_ablkcipher_cast(tfm);\r\nstruct seqiv_ctx *ctx = crypto_ablkcipher_ctx(geniv);\r\nspin_lock_init(&ctx->lock);\r\ntfm->crt_ablkcipher.reqsize = sizeof(struct ablkcipher_request);\r\nreturn skcipher_geniv_init(tfm);\r\n}\r\nstatic int seqiv_aead_init(struct crypto_tfm *tfm)\r\n{\r\nstruct crypto_aead *geniv = __crypto_aead_cast(tfm);\r\nstruct seqiv_ctx *ctx = crypto_aead_ctx(geniv);\r\nspin_lock_init(&ctx->lock);\r\ntfm->crt_aead.reqsize = sizeof(struct aead_request);\r\nreturn aead_geniv_init(tfm);\r\n}\r\nstatic struct crypto_instance *seqiv_ablkcipher_alloc(struct rtattr **tb)\r\n{\r\nstruct crypto_instance *inst;\r\ninst = skcipher_geniv_alloc(&seqiv_tmpl, tb, 0, 0);\r\nif (IS_ERR(inst))\r\ngoto out;\r\ninst->alg.cra_ablkcipher.givencrypt = seqiv_givencrypt_first;\r\ninst->alg.cra_init = seqiv_init;\r\ninst->alg.cra_exit = skcipher_geniv_exit;\r\ninst->alg.cra_ctxsize += inst->alg.cra_ablkcipher.ivsize;\r\nout:\r\nreturn inst;\r\n}\r\nstatic struct crypto_instance *seqiv_aead_alloc(struct rtattr **tb)\r\n{\r\nstruct crypto_instance *inst;\r\ninst = aead_geniv_alloc(&seqiv_tmpl, tb, 0, 0);\r\nif (IS_ERR(inst))\r\ngoto out;\r\ninst->alg.cra_aead.givencrypt = seqiv_aead_givencrypt_first;\r\ninst->alg.cra_init = seqiv_aead_init;\r\ninst->alg.cra_exit = aead_geniv_exit;\r\ninst->alg.cra_ctxsize = inst->alg.cra_aead.ivsize;\r\nout:\r\nreturn inst;\r\n}\r\nstatic struct crypto_instance *seqiv_alloc(struct rtattr **tb)\r\n{\r\nstruct crypto_attr_type *algt;\r\nstruct crypto_instance *inst;\r\nint err;\r\nalgt = crypto_get_attr_type(tb);\r\nif (IS_ERR(algt))\r\nreturn ERR_CAST(algt);\r\nerr = crypto_get_default_rng();\r\nif (err)\r\nreturn ERR_PTR(err);\r\nif ((algt->type ^ CRYPTO_ALG_TYPE_AEAD) & CRYPTO_ALG_TYPE_MASK)\r\ninst = seqiv_ablkcipher_alloc(tb);\r\nelse\r\ninst = seqiv_aead_alloc(tb);\r\nif (IS_ERR(inst))\r\ngoto put_rng;\r\ninst->alg.cra_alignmask |= __alignof__(u32) - 1;\r\ninst->alg.cra_ctxsize += sizeof(struct seqiv_ctx);\r\nout:\r\nreturn inst;\r\nput_rng:\r\ncrypto_put_default_rng();\r\ngoto out;\r\n}\r\nstatic void seqiv_free(struct crypto_instance *inst)\r\n{\r\nif ((inst->alg.cra_flags ^ CRYPTO_ALG_TYPE_AEAD) & CRYPTO_ALG_TYPE_MASK)\r\nskcipher_geniv_free(inst);\r\nelse\r\naead_geniv_free(inst);\r\ncrypto_put_default_rng();\r\n}\r\nstatic int __init seqiv_module_init(void)\r\n{\r\nreturn crypto_register_template(&seqiv_tmpl);\r\n}\r\nstatic void __exit seqiv_module_exit(void)\r\n{\r\ncrypto_unregister_template(&seqiv_tmpl);\r\n}
