static int sha1_neon_init(struct shash_desc *desc)\r\n{\r\nstruct sha1_state *sctx = shash_desc_ctx(desc);\r\n*sctx = (struct sha1_state){\r\n.state = { SHA1_H0, SHA1_H1, SHA1_H2, SHA1_H3, SHA1_H4 },\r\n};\r\nreturn 0;\r\n}\r\nstatic int __sha1_neon_update(struct shash_desc *desc, const u8 *data,\r\nunsigned int len, unsigned int partial)\r\n{\r\nstruct sha1_state *sctx = shash_desc_ctx(desc);\r\nunsigned int done = 0;\r\nsctx->count += len;\r\nif (partial) {\r\ndone = SHA1_BLOCK_SIZE - partial;\r\nmemcpy(sctx->buffer + partial, data, done);\r\nsha1_transform_neon(sctx->state, sctx->buffer, 1);\r\n}\r\nif (len - done >= SHA1_BLOCK_SIZE) {\r\nconst unsigned int rounds = (len - done) / SHA1_BLOCK_SIZE;\r\nsha1_transform_neon(sctx->state, data + done, rounds);\r\ndone += rounds * SHA1_BLOCK_SIZE;\r\n}\r\nmemcpy(sctx->buffer, data + done, len - done);\r\nreturn 0;\r\n}\r\nstatic int sha1_neon_update(struct shash_desc *desc, const u8 *data,\r\nunsigned int len)\r\n{\r\nstruct sha1_state *sctx = shash_desc_ctx(desc);\r\nunsigned int partial = sctx->count % SHA1_BLOCK_SIZE;\r\nint res;\r\nif (partial + len < SHA1_BLOCK_SIZE) {\r\nsctx->count += len;\r\nmemcpy(sctx->buffer + partial, data, len);\r\nreturn 0;\r\n}\r\nif (!may_use_simd()) {\r\nres = sha1_update_arm(desc, data, len);\r\n} else {\r\nkernel_neon_begin();\r\nres = __sha1_neon_update(desc, data, len, partial);\r\nkernel_neon_end();\r\n}\r\nreturn res;\r\n}\r\nstatic int sha1_neon_final(struct shash_desc *desc, u8 *out)\r\n{\r\nstruct sha1_state *sctx = shash_desc_ctx(desc);\r\nunsigned int i, index, padlen;\r\n__be32 *dst = (__be32 *)out;\r\n__be64 bits;\r\nstatic const u8 padding[SHA1_BLOCK_SIZE] = { 0x80, };\r\nbits = cpu_to_be64(sctx->count << 3);\r\nindex = sctx->count % SHA1_BLOCK_SIZE;\r\npadlen = (index < 56) ? (56 - index) : ((SHA1_BLOCK_SIZE+56) - index);\r\nif (!may_use_simd()) {\r\nsha1_update_arm(desc, padding, padlen);\r\nsha1_update_arm(desc, (const u8 *)&bits, sizeof(bits));\r\n} else {\r\nkernel_neon_begin();\r\nif (padlen <= 56) {\r\nsctx->count += padlen;\r\nmemcpy(sctx->buffer + index, padding, padlen);\r\n} else {\r\n__sha1_neon_update(desc, padding, padlen, index);\r\n}\r\n__sha1_neon_update(desc, (const u8 *)&bits, sizeof(bits), 56);\r\nkernel_neon_end();\r\n}\r\nfor (i = 0; i < 5; i++)\r\ndst[i] = cpu_to_be32(sctx->state[i]);\r\nmemset(sctx, 0, sizeof(*sctx));\r\nreturn 0;\r\n}\r\nstatic int sha1_neon_export(struct shash_desc *desc, void *out)\r\n{\r\nstruct sha1_state *sctx = shash_desc_ctx(desc);\r\nmemcpy(out, sctx, sizeof(*sctx));\r\nreturn 0;\r\n}\r\nstatic int sha1_neon_import(struct shash_desc *desc, const void *in)\r\n{\r\nstruct sha1_state *sctx = shash_desc_ctx(desc);\r\nmemcpy(sctx, in, sizeof(*sctx));\r\nreturn 0;\r\n}\r\nstatic int __init sha1_neon_mod_init(void)\r\n{\r\nif (!cpu_has_neon())\r\nreturn -ENODEV;\r\nreturn crypto_register_shash(&alg);\r\n}\r\nstatic void __exit sha1_neon_mod_fini(void)\r\n{\r\ncrypto_unregister_shash(&alg);\r\n}
