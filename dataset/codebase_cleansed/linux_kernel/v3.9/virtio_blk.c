static inline int virtblk_result(struct virtblk_req *vbr)\r\n{\r\nswitch (vbr->status) {\r\ncase VIRTIO_BLK_S_OK:\r\nreturn 0;\r\ncase VIRTIO_BLK_S_UNSUPP:\r\nreturn -ENOTTY;\r\ndefault:\r\nreturn -EIO;\r\n}\r\n}\r\nstatic inline struct virtblk_req *virtblk_alloc_req(struct virtio_blk *vblk,\r\ngfp_t gfp_mask)\r\n{\r\nstruct virtblk_req *vbr;\r\nvbr = mempool_alloc(vblk->pool, gfp_mask);\r\nif (!vbr)\r\nreturn NULL;\r\nvbr->vblk = vblk;\r\nif (use_bio)\r\nsg_init_table(vbr->sg, vblk->sg_elems);\r\nreturn vbr;\r\n}\r\nstatic void virtblk_add_buf_wait(struct virtio_blk *vblk,\r\nstruct virtblk_req *vbr,\r\nunsigned long out,\r\nunsigned long in)\r\n{\r\nDEFINE_WAIT(wait);\r\nfor (;;) {\r\nprepare_to_wait_exclusive(&vblk->queue_wait, &wait,\r\nTASK_UNINTERRUPTIBLE);\r\nspin_lock_irq(vblk->disk->queue->queue_lock);\r\nif (virtqueue_add_buf(vblk->vq, vbr->sg, out, in, vbr,\r\nGFP_ATOMIC) < 0) {\r\nspin_unlock_irq(vblk->disk->queue->queue_lock);\r\nio_schedule();\r\n} else {\r\nvirtqueue_kick(vblk->vq);\r\nspin_unlock_irq(vblk->disk->queue->queue_lock);\r\nbreak;\r\n}\r\n}\r\nfinish_wait(&vblk->queue_wait, &wait);\r\n}\r\nstatic inline void virtblk_add_req(struct virtblk_req *vbr,\r\nunsigned int out, unsigned int in)\r\n{\r\nstruct virtio_blk *vblk = vbr->vblk;\r\nspin_lock_irq(vblk->disk->queue->queue_lock);\r\nif (unlikely(virtqueue_add_buf(vblk->vq, vbr->sg, out, in, vbr,\r\nGFP_ATOMIC) < 0)) {\r\nspin_unlock_irq(vblk->disk->queue->queue_lock);\r\nvirtblk_add_buf_wait(vblk, vbr, out, in);\r\nreturn;\r\n}\r\nvirtqueue_kick(vblk->vq);\r\nspin_unlock_irq(vblk->disk->queue->queue_lock);\r\n}\r\nstatic int virtblk_bio_send_flush(struct virtblk_req *vbr)\r\n{\r\nunsigned int out = 0, in = 0;\r\nvbr->flags |= VBLK_IS_FLUSH;\r\nvbr->out_hdr.type = VIRTIO_BLK_T_FLUSH;\r\nvbr->out_hdr.sector = 0;\r\nvbr->out_hdr.ioprio = 0;\r\nsg_set_buf(&vbr->sg[out++], &vbr->out_hdr, sizeof(vbr->out_hdr));\r\nsg_set_buf(&vbr->sg[out + in++], &vbr->status, sizeof(vbr->status));\r\nvirtblk_add_req(vbr, out, in);\r\nreturn 0;\r\n}\r\nstatic int virtblk_bio_send_data(struct virtblk_req *vbr)\r\n{\r\nstruct virtio_blk *vblk = vbr->vblk;\r\nunsigned int num, out = 0, in = 0;\r\nstruct bio *bio = vbr->bio;\r\nvbr->flags &= ~VBLK_IS_FLUSH;\r\nvbr->out_hdr.type = 0;\r\nvbr->out_hdr.sector = bio->bi_sector;\r\nvbr->out_hdr.ioprio = bio_prio(bio);\r\nsg_set_buf(&vbr->sg[out++], &vbr->out_hdr, sizeof(vbr->out_hdr));\r\nnum = blk_bio_map_sg(vblk->disk->queue, bio, vbr->sg + out);\r\nsg_set_buf(&vbr->sg[num + out + in++], &vbr->status,\r\nsizeof(vbr->status));\r\nif (num) {\r\nif (bio->bi_rw & REQ_WRITE) {\r\nvbr->out_hdr.type |= VIRTIO_BLK_T_OUT;\r\nout += num;\r\n} else {\r\nvbr->out_hdr.type |= VIRTIO_BLK_T_IN;\r\nin += num;\r\n}\r\n}\r\nvirtblk_add_req(vbr, out, in);\r\nreturn 0;\r\n}\r\nstatic void virtblk_bio_send_data_work(struct work_struct *work)\r\n{\r\nstruct virtblk_req *vbr;\r\nvbr = container_of(work, struct virtblk_req, work);\r\nvirtblk_bio_send_data(vbr);\r\n}\r\nstatic void virtblk_bio_send_flush_work(struct work_struct *work)\r\n{\r\nstruct virtblk_req *vbr;\r\nvbr = container_of(work, struct virtblk_req, work);\r\nvirtblk_bio_send_flush(vbr);\r\n}\r\nstatic inline void virtblk_request_done(struct virtblk_req *vbr)\r\n{\r\nstruct virtio_blk *vblk = vbr->vblk;\r\nstruct request *req = vbr->req;\r\nint error = virtblk_result(vbr);\r\nif (req->cmd_type == REQ_TYPE_BLOCK_PC) {\r\nreq->resid_len = vbr->in_hdr.residual;\r\nreq->sense_len = vbr->in_hdr.sense_len;\r\nreq->errors = vbr->in_hdr.errors;\r\n} else if (req->cmd_type == REQ_TYPE_SPECIAL) {\r\nreq->errors = (error != 0);\r\n}\r\n__blk_end_request_all(req, error);\r\nmempool_free(vbr, vblk->pool);\r\n}\r\nstatic inline void virtblk_bio_flush_done(struct virtblk_req *vbr)\r\n{\r\nstruct virtio_blk *vblk = vbr->vblk;\r\nif (vbr->flags & VBLK_REQ_DATA) {\r\nINIT_WORK(&vbr->work, virtblk_bio_send_data_work);\r\nqueue_work(virtblk_wq, &vbr->work);\r\n} else {\r\nbio_endio(vbr->bio, virtblk_result(vbr));\r\nmempool_free(vbr, vblk->pool);\r\n}\r\n}\r\nstatic inline void virtblk_bio_data_done(struct virtblk_req *vbr)\r\n{\r\nstruct virtio_blk *vblk = vbr->vblk;\r\nif (unlikely(vbr->flags & VBLK_REQ_FUA)) {\r\nvbr->flags &= ~VBLK_REQ_DATA;\r\nINIT_WORK(&vbr->work, virtblk_bio_send_flush_work);\r\nqueue_work(virtblk_wq, &vbr->work);\r\n} else {\r\nbio_endio(vbr->bio, virtblk_result(vbr));\r\nmempool_free(vbr, vblk->pool);\r\n}\r\n}\r\nstatic inline void virtblk_bio_done(struct virtblk_req *vbr)\r\n{\r\nif (unlikely(vbr->flags & VBLK_IS_FLUSH))\r\nvirtblk_bio_flush_done(vbr);\r\nelse\r\nvirtblk_bio_data_done(vbr);\r\n}\r\nstatic void virtblk_done(struct virtqueue *vq)\r\n{\r\nstruct virtio_blk *vblk = vq->vdev->priv;\r\nbool bio_done = false, req_done = false;\r\nstruct virtblk_req *vbr;\r\nunsigned long flags;\r\nunsigned int len;\r\nspin_lock_irqsave(vblk->disk->queue->queue_lock, flags);\r\ndo {\r\nvirtqueue_disable_cb(vq);\r\nwhile ((vbr = virtqueue_get_buf(vblk->vq, &len)) != NULL) {\r\nif (vbr->bio) {\r\nvirtblk_bio_done(vbr);\r\nbio_done = true;\r\n} else {\r\nvirtblk_request_done(vbr);\r\nreq_done = true;\r\n}\r\n}\r\n} while (!virtqueue_enable_cb(vq));\r\nif (req_done)\r\nblk_start_queue(vblk->disk->queue);\r\nspin_unlock_irqrestore(vblk->disk->queue->queue_lock, flags);\r\nif (bio_done)\r\nwake_up(&vblk->queue_wait);\r\n}\r\nstatic bool do_req(struct request_queue *q, struct virtio_blk *vblk,\r\nstruct request *req)\r\n{\r\nunsigned long num, out = 0, in = 0;\r\nstruct virtblk_req *vbr;\r\nvbr = virtblk_alloc_req(vblk, GFP_ATOMIC);\r\nif (!vbr)\r\nreturn false;\r\nvbr->req = req;\r\nvbr->bio = NULL;\r\nif (req->cmd_flags & REQ_FLUSH) {\r\nvbr->out_hdr.type = VIRTIO_BLK_T_FLUSH;\r\nvbr->out_hdr.sector = 0;\r\nvbr->out_hdr.ioprio = req_get_ioprio(vbr->req);\r\n} else {\r\nswitch (req->cmd_type) {\r\ncase REQ_TYPE_FS:\r\nvbr->out_hdr.type = 0;\r\nvbr->out_hdr.sector = blk_rq_pos(vbr->req);\r\nvbr->out_hdr.ioprio = req_get_ioprio(vbr->req);\r\nbreak;\r\ncase REQ_TYPE_BLOCK_PC:\r\nvbr->out_hdr.type = VIRTIO_BLK_T_SCSI_CMD;\r\nvbr->out_hdr.sector = 0;\r\nvbr->out_hdr.ioprio = req_get_ioprio(vbr->req);\r\nbreak;\r\ncase REQ_TYPE_SPECIAL:\r\nvbr->out_hdr.type = VIRTIO_BLK_T_GET_ID;\r\nvbr->out_hdr.sector = 0;\r\nvbr->out_hdr.ioprio = req_get_ioprio(vbr->req);\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\n}\r\nsg_set_buf(&vblk->sg[out++], &vbr->out_hdr, sizeof(vbr->out_hdr));\r\nif (vbr->req->cmd_type == REQ_TYPE_BLOCK_PC)\r\nsg_set_buf(&vblk->sg[out++], vbr->req->cmd, vbr->req->cmd_len);\r\nnum = blk_rq_map_sg(q, vbr->req, vblk->sg + out);\r\nif (vbr->req->cmd_type == REQ_TYPE_BLOCK_PC) {\r\nsg_set_buf(&vblk->sg[num + out + in++], vbr->req->sense, SCSI_SENSE_BUFFERSIZE);\r\nsg_set_buf(&vblk->sg[num + out + in++], &vbr->in_hdr,\r\nsizeof(vbr->in_hdr));\r\n}\r\nsg_set_buf(&vblk->sg[num + out + in++], &vbr->status,\r\nsizeof(vbr->status));\r\nif (num) {\r\nif (rq_data_dir(vbr->req) == WRITE) {\r\nvbr->out_hdr.type |= VIRTIO_BLK_T_OUT;\r\nout += num;\r\n} else {\r\nvbr->out_hdr.type |= VIRTIO_BLK_T_IN;\r\nin += num;\r\n}\r\n}\r\nif (virtqueue_add_buf(vblk->vq, vblk->sg, out, in, vbr,\r\nGFP_ATOMIC) < 0) {\r\nmempool_free(vbr, vblk->pool);\r\nreturn false;\r\n}\r\nreturn true;\r\n}\r\nstatic void virtblk_request(struct request_queue *q)\r\n{\r\nstruct virtio_blk *vblk = q->queuedata;\r\nstruct request *req;\r\nunsigned int issued = 0;\r\nwhile ((req = blk_peek_request(q)) != NULL) {\r\nBUG_ON(req->nr_phys_segments + 2 > vblk->sg_elems);\r\nif (!do_req(q, vblk, req)) {\r\nblk_stop_queue(q);\r\nbreak;\r\n}\r\nblk_start_request(req);\r\nissued++;\r\n}\r\nif (issued)\r\nvirtqueue_kick(vblk->vq);\r\n}\r\nstatic void virtblk_make_request(struct request_queue *q, struct bio *bio)\r\n{\r\nstruct virtio_blk *vblk = q->queuedata;\r\nstruct virtblk_req *vbr;\r\nBUG_ON(bio->bi_phys_segments + 2 > vblk->sg_elems);\r\nvbr = virtblk_alloc_req(vblk, GFP_NOIO);\r\nif (!vbr) {\r\nbio_endio(bio, -ENOMEM);\r\nreturn;\r\n}\r\nvbr->bio = bio;\r\nvbr->flags = 0;\r\nif (bio->bi_rw & REQ_FLUSH)\r\nvbr->flags |= VBLK_REQ_FLUSH;\r\nif (bio->bi_rw & REQ_FUA)\r\nvbr->flags |= VBLK_REQ_FUA;\r\nif (bio->bi_size)\r\nvbr->flags |= VBLK_REQ_DATA;\r\nif (unlikely(vbr->flags & VBLK_REQ_FLUSH))\r\nvirtblk_bio_send_flush(vbr);\r\nelse\r\nvirtblk_bio_send_data(vbr);\r\n}\r\nstatic int virtblk_get_id(struct gendisk *disk, char *id_str)\r\n{\r\nstruct virtio_blk *vblk = disk->private_data;\r\nstruct request *req;\r\nstruct bio *bio;\r\nint err;\r\nbio = bio_map_kern(vblk->disk->queue, id_str, VIRTIO_BLK_ID_BYTES,\r\nGFP_KERNEL);\r\nif (IS_ERR(bio))\r\nreturn PTR_ERR(bio);\r\nreq = blk_make_request(vblk->disk->queue, bio, GFP_KERNEL);\r\nif (IS_ERR(req)) {\r\nbio_put(bio);\r\nreturn PTR_ERR(req);\r\n}\r\nreq->cmd_type = REQ_TYPE_SPECIAL;\r\nerr = blk_execute_rq(vblk->disk->queue, vblk->disk, req, false);\r\nblk_put_request(req);\r\nreturn err;\r\n}\r\nstatic int virtblk_ioctl(struct block_device *bdev, fmode_t mode,\r\nunsigned int cmd, unsigned long data)\r\n{\r\nstruct gendisk *disk = bdev->bd_disk;\r\nstruct virtio_blk *vblk = disk->private_data;\r\nif (!virtio_has_feature(vblk->vdev, VIRTIO_BLK_F_SCSI))\r\nreturn -ENOTTY;\r\nreturn scsi_cmd_blk_ioctl(bdev, mode, cmd,\r\n(void __user *)data);\r\n}\r\nstatic int virtblk_getgeo(struct block_device *bd, struct hd_geometry *geo)\r\n{\r\nstruct virtio_blk *vblk = bd->bd_disk->private_data;\r\nstruct virtio_blk_geometry vgeo;\r\nint err;\r\nerr = virtio_config_val(vblk->vdev, VIRTIO_BLK_F_GEOMETRY,\r\noffsetof(struct virtio_blk_config, geometry),\r\n&vgeo);\r\nif (!err) {\r\ngeo->heads = vgeo.heads;\r\ngeo->sectors = vgeo.sectors;\r\ngeo->cylinders = vgeo.cylinders;\r\n} else {\r\ngeo->heads = 1 << 6;\r\ngeo->sectors = 1 << 5;\r\ngeo->cylinders = get_capacity(bd->bd_disk) >> 11;\r\n}\r\nreturn 0;\r\n}\r\nstatic int index_to_minor(int index)\r\n{\r\nreturn index << PART_BITS;\r\n}\r\nstatic int minor_to_index(int minor)\r\n{\r\nreturn minor >> PART_BITS;\r\n}\r\nstatic ssize_t virtblk_serial_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct gendisk *disk = dev_to_disk(dev);\r\nint err;\r\nBUILD_BUG_ON(PAGE_SIZE < VIRTIO_BLK_ID_BYTES);\r\nbuf[VIRTIO_BLK_ID_BYTES] = '\0';\r\nerr = virtblk_get_id(disk, buf);\r\nif (!err)\r\nreturn strlen(buf);\r\nif (err == -EIO)\r\nreturn 0;\r\nreturn err;\r\n}\r\nstatic void virtblk_config_changed_work(struct work_struct *work)\r\n{\r\nstruct virtio_blk *vblk =\r\ncontainer_of(work, struct virtio_blk, config_work);\r\nstruct virtio_device *vdev = vblk->vdev;\r\nstruct request_queue *q = vblk->disk->queue;\r\nchar cap_str_2[10], cap_str_10[10];\r\nu64 capacity, size;\r\nmutex_lock(&vblk->config_lock);\r\nif (!vblk->config_enable)\r\ngoto done;\r\nvdev->config->get(vdev, offsetof(struct virtio_blk_config, capacity),\r\n&capacity, sizeof(capacity));\r\nif ((sector_t)capacity != capacity) {\r\ndev_warn(&vdev->dev, "Capacity %llu too large: truncating\n",\r\n(unsigned long long)capacity);\r\ncapacity = (sector_t)-1;\r\n}\r\nsize = capacity * queue_logical_block_size(q);\r\nstring_get_size(size, STRING_UNITS_2, cap_str_2, sizeof(cap_str_2));\r\nstring_get_size(size, STRING_UNITS_10, cap_str_10, sizeof(cap_str_10));\r\ndev_notice(&vdev->dev,\r\n"new size: %llu %d-byte logical blocks (%s/%s)\n",\r\n(unsigned long long)capacity,\r\nqueue_logical_block_size(q),\r\ncap_str_10, cap_str_2);\r\nset_capacity(vblk->disk, capacity);\r\nrevalidate_disk(vblk->disk);\r\ndone:\r\nmutex_unlock(&vblk->config_lock);\r\n}\r\nstatic void virtblk_config_changed(struct virtio_device *vdev)\r\n{\r\nstruct virtio_blk *vblk = vdev->priv;\r\nqueue_work(virtblk_wq, &vblk->config_work);\r\n}\r\nstatic int init_vq(struct virtio_blk *vblk)\r\n{\r\nint err = 0;\r\nvblk->vq = virtio_find_single_vq(vblk->vdev, virtblk_done, "requests");\r\nif (IS_ERR(vblk->vq))\r\nerr = PTR_ERR(vblk->vq);\r\nreturn err;\r\n}\r\nstatic int virtblk_name_format(char *prefix, int index, char *buf, int buflen)\r\n{\r\nconst int base = 'z' - 'a' + 1;\r\nchar *begin = buf + strlen(prefix);\r\nchar *end = buf + buflen;\r\nchar *p;\r\nint unit;\r\np = end - 1;\r\n*p = '\0';\r\nunit = base;\r\ndo {\r\nif (p == begin)\r\nreturn -EINVAL;\r\n*--p = 'a' + (index % unit);\r\nindex = (index / unit) - 1;\r\n} while (index >= 0);\r\nmemmove(begin, p, end - p);\r\nmemcpy(buf, prefix, strlen(prefix));\r\nreturn 0;\r\n}\r\nstatic int virtblk_get_cache_mode(struct virtio_device *vdev)\r\n{\r\nu8 writeback;\r\nint err;\r\nerr = virtio_config_val(vdev, VIRTIO_BLK_F_CONFIG_WCE,\r\noffsetof(struct virtio_blk_config, wce),\r\n&writeback);\r\nif (err)\r\nwriteback = virtio_has_feature(vdev, VIRTIO_BLK_F_WCE);\r\nreturn writeback;\r\n}\r\nstatic void virtblk_update_cache_mode(struct virtio_device *vdev)\r\n{\r\nu8 writeback = virtblk_get_cache_mode(vdev);\r\nstruct virtio_blk *vblk = vdev->priv;\r\nif (writeback)\r\nblk_queue_flush(vblk->disk->queue, REQ_FLUSH);\r\nelse\r\nblk_queue_flush(vblk->disk->queue, 0);\r\nrevalidate_disk(vblk->disk);\r\n}\r\nstatic ssize_t\r\nvirtblk_cache_type_store(struct device *dev, struct device_attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nstruct gendisk *disk = dev_to_disk(dev);\r\nstruct virtio_blk *vblk = disk->private_data;\r\nstruct virtio_device *vdev = vblk->vdev;\r\nint i;\r\nu8 writeback;\r\nBUG_ON(!virtio_has_feature(vblk->vdev, VIRTIO_BLK_F_CONFIG_WCE));\r\nfor (i = ARRAY_SIZE(virtblk_cache_types); --i >= 0; )\r\nif (sysfs_streq(buf, virtblk_cache_types[i]))\r\nbreak;\r\nif (i < 0)\r\nreturn -EINVAL;\r\nwriteback = i;\r\nvdev->config->set(vdev,\r\noffsetof(struct virtio_blk_config, wce),\r\n&writeback, sizeof(writeback));\r\nvirtblk_update_cache_mode(vdev);\r\nreturn count;\r\n}\r\nstatic ssize_t\r\nvirtblk_cache_type_show(struct device *dev, struct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct gendisk *disk = dev_to_disk(dev);\r\nstruct virtio_blk *vblk = disk->private_data;\r\nu8 writeback = virtblk_get_cache_mode(vblk->vdev);\r\nBUG_ON(writeback >= ARRAY_SIZE(virtblk_cache_types));\r\nreturn snprintf(buf, 40, "%s\n", virtblk_cache_types[writeback]);\r\n}\r\nstatic int virtblk_probe(struct virtio_device *vdev)\r\n{\r\nstruct virtio_blk *vblk;\r\nstruct request_queue *q;\r\nint err, index;\r\nint pool_size;\r\nu64 cap;\r\nu32 v, blk_size, sg_elems, opt_io_size;\r\nu16 min_io_size;\r\nu8 physical_block_exp, alignment_offset;\r\nerr = ida_simple_get(&vd_index_ida, 0, minor_to_index(1 << MINORBITS),\r\nGFP_KERNEL);\r\nif (err < 0)\r\ngoto out;\r\nindex = err;\r\nerr = virtio_config_val(vdev, VIRTIO_BLK_F_SEG_MAX,\r\noffsetof(struct virtio_blk_config, seg_max),\r\n&sg_elems);\r\nif (err || !sg_elems)\r\nsg_elems = 1;\r\nsg_elems += 2;\r\nvdev->priv = vblk = kmalloc(sizeof(*vblk) +\r\nsizeof(vblk->sg[0]) * sg_elems, GFP_KERNEL);\r\nif (!vblk) {\r\nerr = -ENOMEM;\r\ngoto out_free_index;\r\n}\r\ninit_waitqueue_head(&vblk->queue_wait);\r\nvblk->vdev = vdev;\r\nvblk->sg_elems = sg_elems;\r\nsg_init_table(vblk->sg, vblk->sg_elems);\r\nmutex_init(&vblk->config_lock);\r\nINIT_WORK(&vblk->config_work, virtblk_config_changed_work);\r\nvblk->config_enable = true;\r\nerr = init_vq(vblk);\r\nif (err)\r\ngoto out_free_vblk;\r\npool_size = sizeof(struct virtblk_req);\r\nif (use_bio)\r\npool_size += sizeof(struct scatterlist) * sg_elems;\r\nvblk->pool = mempool_create_kmalloc_pool(1, pool_size);\r\nif (!vblk->pool) {\r\nerr = -ENOMEM;\r\ngoto out_free_vq;\r\n}\r\nvblk->disk = alloc_disk(1 << PART_BITS);\r\nif (!vblk->disk) {\r\nerr = -ENOMEM;\r\ngoto out_mempool;\r\n}\r\nq = vblk->disk->queue = blk_init_queue(virtblk_request, NULL);\r\nif (!q) {\r\nerr = -ENOMEM;\r\ngoto out_put_disk;\r\n}\r\nif (use_bio)\r\nblk_queue_make_request(q, virtblk_make_request);\r\nq->queuedata = vblk;\r\nvirtblk_name_format("vd", index, vblk->disk->disk_name, DISK_NAME_LEN);\r\nvblk->disk->major = major;\r\nvblk->disk->first_minor = index_to_minor(index);\r\nvblk->disk->private_data = vblk;\r\nvblk->disk->fops = &virtblk_fops;\r\nvblk->disk->driverfs_dev = &vdev->dev;\r\nvblk->index = index;\r\nvirtblk_update_cache_mode(vdev);\r\nif (virtio_has_feature(vdev, VIRTIO_BLK_F_RO))\r\nset_disk_ro(vblk->disk, 1);\r\nvdev->config->get(vdev, offsetof(struct virtio_blk_config, capacity),\r\n&cap, sizeof(cap));\r\nif ((sector_t)cap != cap) {\r\ndev_warn(&vdev->dev, "Capacity %llu too large: truncating\n",\r\n(unsigned long long)cap);\r\ncap = (sector_t)-1;\r\n}\r\nset_capacity(vblk->disk, cap);\r\nblk_queue_max_segments(q, vblk->sg_elems-2);\r\nblk_queue_bounce_limit(q, BLK_BOUNCE_ANY);\r\nblk_queue_max_hw_sectors(q, -1U);\r\nerr = virtio_config_val(vdev, VIRTIO_BLK_F_SIZE_MAX,\r\noffsetof(struct virtio_blk_config, size_max),\r\n&v);\r\nif (!err)\r\nblk_queue_max_segment_size(q, v);\r\nelse\r\nblk_queue_max_segment_size(q, -1U);\r\nerr = virtio_config_val(vdev, VIRTIO_BLK_F_BLK_SIZE,\r\noffsetof(struct virtio_blk_config, blk_size),\r\n&blk_size);\r\nif (!err)\r\nblk_queue_logical_block_size(q, blk_size);\r\nelse\r\nblk_size = queue_logical_block_size(q);\r\nerr = virtio_config_val(vdev, VIRTIO_BLK_F_TOPOLOGY,\r\noffsetof(struct virtio_blk_config, physical_block_exp),\r\n&physical_block_exp);\r\nif (!err && physical_block_exp)\r\nblk_queue_physical_block_size(q,\r\nblk_size * (1 << physical_block_exp));\r\nerr = virtio_config_val(vdev, VIRTIO_BLK_F_TOPOLOGY,\r\noffsetof(struct virtio_blk_config, alignment_offset),\r\n&alignment_offset);\r\nif (!err && alignment_offset)\r\nblk_queue_alignment_offset(q, blk_size * alignment_offset);\r\nerr = virtio_config_val(vdev, VIRTIO_BLK_F_TOPOLOGY,\r\noffsetof(struct virtio_blk_config, min_io_size),\r\n&min_io_size);\r\nif (!err && min_io_size)\r\nblk_queue_io_min(q, blk_size * min_io_size);\r\nerr = virtio_config_val(vdev, VIRTIO_BLK_F_TOPOLOGY,\r\noffsetof(struct virtio_blk_config, opt_io_size),\r\n&opt_io_size);\r\nif (!err && opt_io_size)\r\nblk_queue_io_opt(q, blk_size * opt_io_size);\r\nadd_disk(vblk->disk);\r\nerr = device_create_file(disk_to_dev(vblk->disk), &dev_attr_serial);\r\nif (err)\r\ngoto out_del_disk;\r\nif (virtio_has_feature(vdev, VIRTIO_BLK_F_CONFIG_WCE))\r\nerr = device_create_file(disk_to_dev(vblk->disk),\r\n&dev_attr_cache_type_rw);\r\nelse\r\nerr = device_create_file(disk_to_dev(vblk->disk),\r\n&dev_attr_cache_type_ro);\r\nif (err)\r\ngoto out_del_disk;\r\nreturn 0;\r\nout_del_disk:\r\ndel_gendisk(vblk->disk);\r\nblk_cleanup_queue(vblk->disk->queue);\r\nout_put_disk:\r\nput_disk(vblk->disk);\r\nout_mempool:\r\nmempool_destroy(vblk->pool);\r\nout_free_vq:\r\nvdev->config->del_vqs(vdev);\r\nout_free_vblk:\r\nkfree(vblk);\r\nout_free_index:\r\nida_simple_remove(&vd_index_ida, index);\r\nout:\r\nreturn err;\r\n}\r\nstatic void virtblk_remove(struct virtio_device *vdev)\r\n{\r\nstruct virtio_blk *vblk = vdev->priv;\r\nint index = vblk->index;\r\nint refc;\r\nmutex_lock(&vblk->config_lock);\r\nvblk->config_enable = false;\r\nmutex_unlock(&vblk->config_lock);\r\ndel_gendisk(vblk->disk);\r\nblk_cleanup_queue(vblk->disk->queue);\r\nvdev->config->reset(vdev);\r\nflush_work(&vblk->config_work);\r\nrefc = atomic_read(&disk_to_dev(vblk->disk)->kobj.kref.refcount);\r\nput_disk(vblk->disk);\r\nmempool_destroy(vblk->pool);\r\nvdev->config->del_vqs(vdev);\r\nkfree(vblk);\r\nif (refc == 1)\r\nida_simple_remove(&vd_index_ida, index);\r\n}\r\nstatic int virtblk_freeze(struct virtio_device *vdev)\r\n{\r\nstruct virtio_blk *vblk = vdev->priv;\r\nvdev->config->reset(vdev);\r\nmutex_lock(&vblk->config_lock);\r\nvblk->config_enable = false;\r\nmutex_unlock(&vblk->config_lock);\r\nflush_work(&vblk->config_work);\r\nspin_lock_irq(vblk->disk->queue->queue_lock);\r\nblk_stop_queue(vblk->disk->queue);\r\nspin_unlock_irq(vblk->disk->queue->queue_lock);\r\nblk_sync_queue(vblk->disk->queue);\r\nvdev->config->del_vqs(vdev);\r\nreturn 0;\r\n}\r\nstatic int virtblk_restore(struct virtio_device *vdev)\r\n{\r\nstruct virtio_blk *vblk = vdev->priv;\r\nint ret;\r\nvblk->config_enable = true;\r\nret = init_vq(vdev->priv);\r\nif (!ret) {\r\nspin_lock_irq(vblk->disk->queue->queue_lock);\r\nblk_start_queue(vblk->disk->queue);\r\nspin_unlock_irq(vblk->disk->queue->queue_lock);\r\n}\r\nreturn ret;\r\n}\r\nstatic int __init init(void)\r\n{\r\nint error;\r\nvirtblk_wq = alloc_workqueue("virtio-blk", 0, 0);\r\nif (!virtblk_wq)\r\nreturn -ENOMEM;\r\nmajor = register_blkdev(0, "virtblk");\r\nif (major < 0) {\r\nerror = major;\r\ngoto out_destroy_workqueue;\r\n}\r\nerror = register_virtio_driver(&virtio_blk);\r\nif (error)\r\ngoto out_unregister_blkdev;\r\nreturn 0;\r\nout_unregister_blkdev:\r\nunregister_blkdev(major, "virtblk");\r\nout_destroy_workqueue:\r\ndestroy_workqueue(virtblk_wq);\r\nreturn error;\r\n}\r\nstatic void __exit fini(void)\r\n{\r\nunregister_blkdev(major, "virtblk");\r\nunregister_virtio_driver(&virtio_blk);\r\ndestroy_workqueue(virtblk_wq);\r\n}
