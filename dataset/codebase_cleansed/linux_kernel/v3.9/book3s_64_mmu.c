static void kvmppc_mmu_book3s_64_reset_msr(struct kvm_vcpu *vcpu)\r\n{\r\nkvmppc_set_msr(vcpu, MSR_SF);\r\n}\r\nstatic struct kvmppc_slb *kvmppc_mmu_book3s_64_find_slbe(\r\nstruct kvm_vcpu *vcpu,\r\ngva_t eaddr)\r\n{\r\nint i;\r\nu64 esid = GET_ESID(eaddr);\r\nu64 esid_1t = GET_ESID_1T(eaddr);\r\nfor (i = 0; i < vcpu->arch.slb_nr; i++) {\r\nu64 cmp_esid = esid;\r\nif (!vcpu->arch.slb[i].valid)\r\ncontinue;\r\nif (vcpu->arch.slb[i].tb)\r\ncmp_esid = esid_1t;\r\nif (vcpu->arch.slb[i].esid == cmp_esid)\r\nreturn &vcpu->arch.slb[i];\r\n}\r\ndprintk("KVM: No SLB entry found for 0x%lx [%llx | %llx]\n",\r\neaddr, esid, esid_1t);\r\nfor (i = 0; i < vcpu->arch.slb_nr; i++) {\r\nif (vcpu->arch.slb[i].vsid)\r\ndprintk(" %d: %c%c%c %llx %llx\n", i,\r\nvcpu->arch.slb[i].valid ? 'v' : ' ',\r\nvcpu->arch.slb[i].large ? 'l' : ' ',\r\nvcpu->arch.slb[i].tb ? 't' : ' ',\r\nvcpu->arch.slb[i].esid,\r\nvcpu->arch.slb[i].vsid);\r\n}\r\nreturn NULL;\r\n}\r\nstatic u64 kvmppc_mmu_book3s_64_ea_to_vp(struct kvm_vcpu *vcpu, gva_t eaddr,\r\nbool data)\r\n{\r\nstruct kvmppc_slb *slb;\r\nslb = kvmppc_mmu_book3s_64_find_slbe(vcpu, eaddr);\r\nif (!slb)\r\nreturn 0;\r\nif (slb->tb)\r\nreturn (((u64)eaddr >> 12) & 0xfffffff) |\r\n(((u64)slb->vsid) << 28);\r\nreturn (((u64)eaddr >> 12) & 0xffff) | (((u64)slb->vsid) << 16);\r\n}\r\nstatic int kvmppc_mmu_book3s_64_get_pagesize(struct kvmppc_slb *slbe)\r\n{\r\nreturn slbe->large ? 24 : 12;\r\n}\r\nstatic u32 kvmppc_mmu_book3s_64_get_page(struct kvmppc_slb *slbe, gva_t eaddr)\r\n{\r\nint p = kvmppc_mmu_book3s_64_get_pagesize(slbe);\r\nreturn ((eaddr & 0xfffffff) >> p);\r\n}\r\nstatic hva_t kvmppc_mmu_book3s_64_get_pteg(\r\nstruct kvmppc_vcpu_book3s *vcpu_book3s,\r\nstruct kvmppc_slb *slbe, gva_t eaddr,\r\nbool second)\r\n{\r\nu64 hash, pteg, htabsize;\r\nu32 page;\r\nhva_t r;\r\npage = kvmppc_mmu_book3s_64_get_page(slbe, eaddr);\r\nhtabsize = ((1 << ((vcpu_book3s->sdr1 & 0x1f) + 11)) - 1);\r\nhash = slbe->vsid ^ page;\r\nif (second)\r\nhash = ~hash;\r\nhash &= ((1ULL << 39ULL) - 1ULL);\r\nhash &= htabsize;\r\nhash <<= 7ULL;\r\npteg = vcpu_book3s->sdr1 & 0xfffffffffffc0000ULL;\r\npteg |= hash;\r\ndprintk("MMU: page=0x%x sdr1=0x%llx pteg=0x%llx vsid=0x%llx\n",\r\npage, vcpu_book3s->sdr1, pteg, slbe->vsid);\r\nif (vcpu_book3s->vcpu.arch.papr_enabled)\r\nr = pteg;\r\nelse\r\nr = gfn_to_hva(vcpu_book3s->vcpu.kvm, pteg >> PAGE_SHIFT);\r\nif (kvm_is_error_hva(r))\r\nreturn r;\r\nreturn r | (pteg & ~PAGE_MASK);\r\n}\r\nstatic u64 kvmppc_mmu_book3s_64_get_avpn(struct kvmppc_slb *slbe, gva_t eaddr)\r\n{\r\nint p = kvmppc_mmu_book3s_64_get_pagesize(slbe);\r\nu64 avpn;\r\navpn = kvmppc_mmu_book3s_64_get_page(slbe, eaddr);\r\navpn |= slbe->vsid << (28 - p);\r\nif (p < 24)\r\navpn >>= ((80 - p) - 56) - 8;\r\nelse\r\navpn <<= 8;\r\nreturn avpn;\r\n}\r\nstatic int kvmppc_mmu_book3s_64_xlate(struct kvm_vcpu *vcpu, gva_t eaddr,\r\nstruct kvmppc_pte *gpte, bool data)\r\n{\r\nstruct kvmppc_vcpu_book3s *vcpu_book3s = to_book3s(vcpu);\r\nstruct kvmppc_slb *slbe;\r\nhva_t ptegp;\r\nu64 pteg[16];\r\nu64 avpn = 0;\r\nint i;\r\nu8 key = 0;\r\nbool found = false;\r\nbool perm_err = false;\r\nint second = 0;\r\nulong mp_ea = vcpu->arch.magic_page_ea;\r\nif (unlikely(mp_ea) &&\r\nunlikely((eaddr & ~0xfffULL) == (mp_ea & ~0xfffULL)) &&\r\n!(vcpu->arch.shared->msr & MSR_PR)) {\r\ngpte->eaddr = eaddr;\r\ngpte->vpage = kvmppc_mmu_book3s_64_ea_to_vp(vcpu, eaddr, data);\r\ngpte->raddr = vcpu->arch.magic_page_pa | (gpte->raddr & 0xfff);\r\ngpte->raddr &= KVM_PAM;\r\ngpte->may_execute = true;\r\ngpte->may_read = true;\r\ngpte->may_write = true;\r\nreturn 0;\r\n}\r\nslbe = kvmppc_mmu_book3s_64_find_slbe(vcpu, eaddr);\r\nif (!slbe)\r\ngoto no_seg_found;\r\ndo_second:\r\nptegp = kvmppc_mmu_book3s_64_get_pteg(vcpu_book3s, slbe, eaddr, second);\r\nif (kvm_is_error_hva(ptegp))\r\ngoto no_page_found;\r\navpn = kvmppc_mmu_book3s_64_get_avpn(slbe, eaddr);\r\nif(copy_from_user(pteg, (void __user *)ptegp, sizeof(pteg))) {\r\nprintk(KERN_ERR "KVM can't copy data from 0x%lx!\n", ptegp);\r\ngoto no_page_found;\r\n}\r\nif ((vcpu->arch.shared->msr & MSR_PR) && slbe->Kp)\r\nkey = 4;\r\nelse if (!(vcpu->arch.shared->msr & MSR_PR) && slbe->Ks)\r\nkey = 4;\r\nfor (i=0; i<16; i+=2) {\r\nu64 v = pteg[i];\r\nu64 r = pteg[i+1];\r\nif (!(v & HPTE_V_VALID))\r\ncontinue;\r\nif ((v & HPTE_V_SECONDARY) != second)\r\ncontinue;\r\nif (HPTE_V_AVPN_VAL(avpn) == HPTE_V_AVPN_VAL(v)) {\r\nu8 pp = (r & HPTE_R_PP) | key;\r\nint eaddr_mask = 0xFFF;\r\ngpte->eaddr = eaddr;\r\ngpte->vpage = kvmppc_mmu_book3s_64_ea_to_vp(vcpu,\r\neaddr,\r\ndata);\r\nif (slbe->large)\r\neaddr_mask = 0xFFFFFF;\r\ngpte->raddr = (r & HPTE_R_RPN) | (eaddr & eaddr_mask);\r\ngpte->may_execute = ((r & HPTE_R_N) ? false : true);\r\ngpte->may_read = false;\r\ngpte->may_write = false;\r\nswitch (pp) {\r\ncase 0:\r\ncase 1:\r\ncase 2:\r\ncase 6:\r\ngpte->may_write = true;\r\ncase 3:\r\ncase 5:\r\ncase 7:\r\ngpte->may_read = true;\r\nbreak;\r\n}\r\nif (!gpte->may_read) {\r\nperm_err = true;\r\ncontinue;\r\n}\r\ndprintk("KVM MMU: Translated 0x%lx [0x%llx] -> 0x%llx "\r\n"-> 0x%lx\n",\r\neaddr, avpn, gpte->vpage, gpte->raddr);\r\nfound = true;\r\nbreak;\r\n}\r\n}\r\nif (found) {\r\nu32 oldr = pteg[i+1];\r\nif (gpte->may_read) {\r\npteg[i+1] |= HPTE_R_R;\r\n}\r\nif (gpte->may_write) {\r\npteg[i+1] |= HPTE_R_C;\r\n} else {\r\ndprintk("KVM: Mapping read-only page!\n");\r\n}\r\nif (pteg[i+1] != oldr)\r\ncopy_to_user((void __user *)ptegp, pteg, sizeof(pteg));\r\nreturn 0;\r\n} else {\r\ndprintk("KVM MMU: No PTE found (ea=0x%lx sdr1=0x%llx "\r\n"ptegp=0x%lx)\n",\r\neaddr, to_book3s(vcpu)->sdr1, ptegp);\r\nfor (i = 0; i < 16; i += 2)\r\ndprintk(" %02d: 0x%llx - 0x%llx (0x%llx)\n",\r\ni, pteg[i], pteg[i+1], avpn);\r\nif (!second) {\r\nsecond = HPTE_V_SECONDARY;\r\ngoto do_second;\r\n}\r\n}\r\nno_page_found:\r\nif (perm_err)\r\nreturn -EPERM;\r\nreturn -ENOENT;\r\nno_seg_found:\r\ndprintk("KVM MMU: Trigger segment fault\n");\r\nreturn -EINVAL;\r\n}\r\nstatic void kvmppc_mmu_book3s_64_slbmte(struct kvm_vcpu *vcpu, u64 rs, u64 rb)\r\n{\r\nstruct kvmppc_vcpu_book3s *vcpu_book3s;\r\nu64 esid, esid_1t;\r\nint slb_nr;\r\nstruct kvmppc_slb *slbe;\r\ndprintk("KVM MMU: slbmte(0x%llx, 0x%llx)\n", rs, rb);\r\nvcpu_book3s = to_book3s(vcpu);\r\nesid = GET_ESID(rb);\r\nesid_1t = GET_ESID_1T(rb);\r\nslb_nr = rb & 0xfff;\r\nif (slb_nr > vcpu->arch.slb_nr)\r\nreturn;\r\nslbe = &vcpu->arch.slb[slb_nr];\r\nslbe->large = (rs & SLB_VSID_L) ? 1 : 0;\r\nslbe->tb = (rs & SLB_VSID_B_1T) ? 1 : 0;\r\nslbe->esid = slbe->tb ? esid_1t : esid;\r\nslbe->vsid = rs >> 12;\r\nslbe->valid = (rb & SLB_ESID_V) ? 1 : 0;\r\nslbe->Ks = (rs & SLB_VSID_KS) ? 1 : 0;\r\nslbe->Kp = (rs & SLB_VSID_KP) ? 1 : 0;\r\nslbe->nx = (rs & SLB_VSID_N) ? 1 : 0;\r\nslbe->class = (rs & SLB_VSID_C) ? 1 : 0;\r\nslbe->orige = rb & (ESID_MASK | SLB_ESID_V);\r\nslbe->origv = rs;\r\nkvmppc_mmu_map_segment(vcpu, esid << SID_SHIFT);\r\n}\r\nstatic u64 kvmppc_mmu_book3s_64_slbmfee(struct kvm_vcpu *vcpu, u64 slb_nr)\r\n{\r\nstruct kvmppc_slb *slbe;\r\nif (slb_nr > vcpu->arch.slb_nr)\r\nreturn 0;\r\nslbe = &vcpu->arch.slb[slb_nr];\r\nreturn slbe->orige;\r\n}\r\nstatic u64 kvmppc_mmu_book3s_64_slbmfev(struct kvm_vcpu *vcpu, u64 slb_nr)\r\n{\r\nstruct kvmppc_slb *slbe;\r\nif (slb_nr > vcpu->arch.slb_nr)\r\nreturn 0;\r\nslbe = &vcpu->arch.slb[slb_nr];\r\nreturn slbe->origv;\r\n}\r\nstatic void kvmppc_mmu_book3s_64_slbie(struct kvm_vcpu *vcpu, u64 ea)\r\n{\r\nstruct kvmppc_slb *slbe;\r\ndprintk("KVM MMU: slbie(0x%llx)\n", ea);\r\nslbe = kvmppc_mmu_book3s_64_find_slbe(vcpu, ea);\r\nif (!slbe)\r\nreturn;\r\ndprintk("KVM MMU: slbie(0x%llx, 0x%llx)\n", ea, slbe->esid);\r\nslbe->valid = false;\r\nkvmppc_mmu_map_segment(vcpu, ea);\r\n}\r\nstatic void kvmppc_mmu_book3s_64_slbia(struct kvm_vcpu *vcpu)\r\n{\r\nint i;\r\ndprintk("KVM MMU: slbia()\n");\r\nfor (i = 1; i < vcpu->arch.slb_nr; i++)\r\nvcpu->arch.slb[i].valid = false;\r\nif (vcpu->arch.shared->msr & MSR_IR) {\r\nkvmppc_mmu_flush_segments(vcpu);\r\nkvmppc_mmu_map_segment(vcpu, kvmppc_get_pc(vcpu));\r\n}\r\n}\r\nstatic void kvmppc_mmu_book3s_64_mtsrin(struct kvm_vcpu *vcpu, u32 srnum,\r\nulong value)\r\n{\r\nu64 rb = 0, rs = 0;\r\ndprintk("KVM MMU: mtsrin(0x%x, 0x%lx)\n", srnum, value);\r\nrb |= (srnum & 0xf) << 28;\r\nrb |= 1 << 27;\r\nrb |= srnum;\r\nrs |= (value & 0xfffffff) << 12;\r\nrs |= ((value >> 28) & 0x7) << 9;\r\nkvmppc_mmu_book3s_64_slbmte(vcpu, rs, rb);\r\n}\r\nstatic void kvmppc_mmu_book3s_64_tlbie(struct kvm_vcpu *vcpu, ulong va,\r\nbool large)\r\n{\r\nu64 mask = 0xFFFFFFFFFULL;\r\ndprintk("KVM MMU: tlbie(0x%lx)\n", va);\r\nif (large)\r\nmask = 0xFFFFFF000ULL;\r\nkvmppc_mmu_pte_vflush(vcpu, va >> 12, mask);\r\n}\r\nstatic int kvmppc_mmu_book3s_64_esid_to_vsid(struct kvm_vcpu *vcpu, ulong esid,\r\nu64 *vsid)\r\n{\r\nulong ea = esid << SID_SHIFT;\r\nstruct kvmppc_slb *slb;\r\nu64 gvsid = esid;\r\nulong mp_ea = vcpu->arch.magic_page_ea;\r\nif (vcpu->arch.shared->msr & (MSR_DR|MSR_IR)) {\r\nslb = kvmppc_mmu_book3s_64_find_slbe(vcpu, ea);\r\nif (slb)\r\ngvsid = slb->vsid;\r\n}\r\nswitch (vcpu->arch.shared->msr & (MSR_DR|MSR_IR)) {\r\ncase 0:\r\n*vsid = VSID_REAL | esid;\r\nbreak;\r\ncase MSR_IR:\r\n*vsid = VSID_REAL_IR | gvsid;\r\nbreak;\r\ncase MSR_DR:\r\n*vsid = VSID_REAL_DR | gvsid;\r\nbreak;\r\ncase MSR_DR|MSR_IR:\r\nif (!slb)\r\ngoto no_slb;\r\n*vsid = gvsid;\r\nbreak;\r\ndefault:\r\nBUG();\r\nbreak;\r\n}\r\nif (vcpu->arch.shared->msr & MSR_PR)\r\n*vsid |= VSID_PR;\r\nreturn 0;\r\nno_slb:\r\nif (unlikely(mp_ea) &&\r\nunlikely(esid == (mp_ea >> SID_SHIFT)) &&\r\n!(vcpu->arch.shared->msr & MSR_PR)) {\r\n*vsid = VSID_REAL | esid;\r\nreturn 0;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic bool kvmppc_mmu_book3s_64_is_dcbz32(struct kvm_vcpu *vcpu)\r\n{\r\nreturn (to_book3s(vcpu)->hid[5] & 0x80);\r\n}\r\nvoid kvmppc_mmu_book3s_64_init(struct kvm_vcpu *vcpu)\r\n{\r\nstruct kvmppc_mmu *mmu = &vcpu->arch.mmu;\r\nmmu->mfsrin = NULL;\r\nmmu->mtsrin = kvmppc_mmu_book3s_64_mtsrin;\r\nmmu->slbmte = kvmppc_mmu_book3s_64_slbmte;\r\nmmu->slbmfee = kvmppc_mmu_book3s_64_slbmfee;\r\nmmu->slbmfev = kvmppc_mmu_book3s_64_slbmfev;\r\nmmu->slbie = kvmppc_mmu_book3s_64_slbie;\r\nmmu->slbia = kvmppc_mmu_book3s_64_slbia;\r\nmmu->xlate = kvmppc_mmu_book3s_64_xlate;\r\nmmu->reset_msr = kvmppc_mmu_book3s_64_reset_msr;\r\nmmu->tlbie = kvmppc_mmu_book3s_64_tlbie;\r\nmmu->esid_to_vsid = kvmppc_mmu_book3s_64_esid_to_vsid;\r\nmmu->ea_to_vp = kvmppc_mmu_book3s_64_ea_to_vp;\r\nmmu->is_dcbz32 = kvmppc_mmu_book3s_64_is_dcbz32;\r\nvcpu->arch.hflags |= BOOK3S_HFLAG_SLB;\r\n}
