void\r\nxfs_count_page_state(\r\nstruct page *page,\r\nint *delalloc,\r\nint *unwritten)\r\n{\r\nstruct buffer_head *bh, *head;\r\n*delalloc = *unwritten = 0;\r\nbh = head = page_buffers(page);\r\ndo {\r\nif (buffer_unwritten(bh))\r\n(*unwritten) = 1;\r\nelse if (buffer_delay(bh))\r\n(*delalloc) = 1;\r\n} while ((bh = bh->b_this_page) != head);\r\n}\r\nSTATIC struct block_device *\r\nxfs_find_bdev_for_inode(\r\nstruct inode *inode)\r\n{\r\nstruct xfs_inode *ip = XFS_I(inode);\r\nstruct xfs_mount *mp = ip->i_mount;\r\nif (XFS_IS_REALTIME_INODE(ip))\r\nreturn mp->m_rtdev_targp->bt_bdev;\r\nelse\r\nreturn mp->m_ddev_targp->bt_bdev;\r\n}\r\nSTATIC void\r\nxfs_destroy_ioend(\r\nxfs_ioend_t *ioend)\r\n{\r\nstruct buffer_head *bh, *next;\r\nfor (bh = ioend->io_buffer_head; bh; bh = next) {\r\nnext = bh->b_private;\r\nbh->b_end_io(bh, !ioend->io_error);\r\n}\r\nif (ioend->io_iocb) {\r\ninode_dio_done(ioend->io_inode);\r\nif (ioend->io_isasync) {\r\naio_complete(ioend->io_iocb, ioend->io_error ?\r\nioend->io_error : ioend->io_result, 0);\r\n}\r\n}\r\nmempool_free(ioend, xfs_ioend_pool);\r\n}\r\nstatic inline bool xfs_ioend_is_append(struct xfs_ioend *ioend)\r\n{\r\nreturn ioend->io_offset + ioend->io_size >\r\nXFS_I(ioend->io_inode)->i_d.di_size;\r\n}\r\nSTATIC int\r\nxfs_setfilesize_trans_alloc(\r\nstruct xfs_ioend *ioend)\r\n{\r\nstruct xfs_mount *mp = XFS_I(ioend->io_inode)->i_mount;\r\nstruct xfs_trans *tp;\r\nint error;\r\ntp = xfs_trans_alloc(mp, XFS_TRANS_FSYNC_TS);\r\nerror = xfs_trans_reserve(tp, 0, XFS_FSYNC_TS_LOG_RES(mp), 0, 0, 0);\r\nif (error) {\r\nxfs_trans_cancel(tp, 0);\r\nreturn error;\r\n}\r\nioend->io_append_trans = tp;\r\nrwsem_release(&ioend->io_inode->i_sb->s_writers.lock_map[SB_FREEZE_FS-1],\r\n1, _THIS_IP_);\r\ncurrent_restore_flags_nested(&tp->t_pflags, PF_FSTRANS);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_setfilesize(\r\nstruct xfs_ioend *ioend)\r\n{\r\nstruct xfs_inode *ip = XFS_I(ioend->io_inode);\r\nstruct xfs_trans *tp = ioend->io_append_trans;\r\nxfs_fsize_t isize;\r\ncurrent_set_flags_nested(&tp->t_pflags, PF_FSTRANS);\r\nrwsem_acquire_read(&VFS_I(ip)->i_sb->s_writers.lock_map[SB_FREEZE_FS-1],\r\n0, 1, _THIS_IP_);\r\nxfs_ilock(ip, XFS_ILOCK_EXCL);\r\nisize = xfs_new_eof(ip, ioend->io_offset + ioend->io_size);\r\nif (!isize) {\r\nxfs_iunlock(ip, XFS_ILOCK_EXCL);\r\nxfs_trans_cancel(tp, 0);\r\nreturn 0;\r\n}\r\ntrace_xfs_setfilesize(ip, ioend->io_offset, ioend->io_size);\r\nip->i_d.di_size = isize;\r\nxfs_trans_ijoin(tp, ip, XFS_ILOCK_EXCL);\r\nxfs_trans_log_inode(tp, ip, XFS_ILOG_CORE);\r\nreturn xfs_trans_commit(tp, 0);\r\n}\r\nSTATIC void\r\nxfs_finish_ioend(\r\nstruct xfs_ioend *ioend)\r\n{\r\nif (atomic_dec_and_test(&ioend->io_remaining)) {\r\nstruct xfs_mount *mp = XFS_I(ioend->io_inode)->i_mount;\r\nif (ioend->io_type == XFS_IO_UNWRITTEN)\r\nqueue_work(mp->m_unwritten_workqueue, &ioend->io_work);\r\nelse if (ioend->io_append_trans ||\r\n(ioend->io_isdirect && xfs_ioend_is_append(ioend)))\r\nqueue_work(mp->m_data_workqueue, &ioend->io_work);\r\nelse\r\nxfs_destroy_ioend(ioend);\r\n}\r\n}\r\nSTATIC void\r\nxfs_end_io(\r\nstruct work_struct *work)\r\n{\r\nxfs_ioend_t *ioend = container_of(work, xfs_ioend_t, io_work);\r\nstruct xfs_inode *ip = XFS_I(ioend->io_inode);\r\nint error = 0;\r\nif (XFS_FORCED_SHUTDOWN(ip->i_mount)) {\r\nioend->io_error = -EIO;\r\ngoto done;\r\n}\r\nif (ioend->io_error)\r\ngoto done;\r\nif (ioend->io_type == XFS_IO_UNWRITTEN) {\r\nerror = xfs_iomap_write_unwritten(ip, ioend->io_offset,\r\nioend->io_size);\r\n} else if (ioend->io_isdirect && xfs_ioend_is_append(ioend)) {\r\nerror = xfs_setfilesize_trans_alloc(ioend);\r\nif (error)\r\ngoto done;\r\nerror = xfs_setfilesize(ioend);\r\n} else if (ioend->io_append_trans) {\r\nerror = xfs_setfilesize(ioend);\r\n} else {\r\nASSERT(!xfs_ioend_is_append(ioend));\r\n}\r\ndone:\r\nif (error)\r\nioend->io_error = -error;\r\nxfs_destroy_ioend(ioend);\r\n}\r\nSTATIC void\r\nxfs_finish_ioend_sync(\r\nstruct xfs_ioend *ioend)\r\n{\r\nif (atomic_dec_and_test(&ioend->io_remaining))\r\nxfs_end_io(&ioend->io_work);\r\n}\r\nSTATIC xfs_ioend_t *\r\nxfs_alloc_ioend(\r\nstruct inode *inode,\r\nunsigned int type)\r\n{\r\nxfs_ioend_t *ioend;\r\nioend = mempool_alloc(xfs_ioend_pool, GFP_NOFS);\r\natomic_set(&ioend->io_remaining, 1);\r\nioend->io_isasync = 0;\r\nioend->io_isdirect = 0;\r\nioend->io_error = 0;\r\nioend->io_list = NULL;\r\nioend->io_type = type;\r\nioend->io_inode = inode;\r\nioend->io_buffer_head = NULL;\r\nioend->io_buffer_tail = NULL;\r\nioend->io_offset = 0;\r\nioend->io_size = 0;\r\nioend->io_iocb = NULL;\r\nioend->io_result = 0;\r\nioend->io_append_trans = NULL;\r\nINIT_WORK(&ioend->io_work, xfs_end_io);\r\nreturn ioend;\r\n}\r\nSTATIC int\r\nxfs_map_blocks(\r\nstruct inode *inode,\r\nloff_t offset,\r\nstruct xfs_bmbt_irec *imap,\r\nint type,\r\nint nonblocking)\r\n{\r\nstruct xfs_inode *ip = XFS_I(inode);\r\nstruct xfs_mount *mp = ip->i_mount;\r\nssize_t count = 1 << inode->i_blkbits;\r\nxfs_fileoff_t offset_fsb, end_fsb;\r\nint error = 0;\r\nint bmapi_flags = XFS_BMAPI_ENTIRE;\r\nint nimaps = 1;\r\nif (XFS_FORCED_SHUTDOWN(mp))\r\nreturn -XFS_ERROR(EIO);\r\nif (type == XFS_IO_UNWRITTEN)\r\nbmapi_flags |= XFS_BMAPI_IGSTATE;\r\nif (!xfs_ilock_nowait(ip, XFS_ILOCK_SHARED)) {\r\nif (nonblocking)\r\nreturn -XFS_ERROR(EAGAIN);\r\nxfs_ilock(ip, XFS_ILOCK_SHARED);\r\n}\r\nASSERT(ip->i_d.di_format != XFS_DINODE_FMT_BTREE ||\r\n(ip->i_df.if_flags & XFS_IFEXTENTS));\r\nASSERT(offset <= mp->m_super->s_maxbytes);\r\nif (offset + count > mp->m_super->s_maxbytes)\r\ncount = mp->m_super->s_maxbytes - offset;\r\nend_fsb = XFS_B_TO_FSB(mp, (xfs_ufsize_t)offset + count);\r\noffset_fsb = XFS_B_TO_FSBT(mp, offset);\r\nerror = xfs_bmapi_read(ip, offset_fsb, end_fsb - offset_fsb,\r\nimap, &nimaps, bmapi_flags);\r\nxfs_iunlock(ip, XFS_ILOCK_SHARED);\r\nif (error)\r\nreturn -XFS_ERROR(error);\r\nif (type == XFS_IO_DELALLOC &&\r\n(!nimaps || isnullstartblock(imap->br_startblock))) {\r\nerror = xfs_iomap_write_allocate(ip, offset, count, imap);\r\nif (!error)\r\ntrace_xfs_map_blocks_alloc(ip, offset, count, type, imap);\r\nreturn -XFS_ERROR(error);\r\n}\r\n#ifdef DEBUG\r\nif (type == XFS_IO_UNWRITTEN) {\r\nASSERT(nimaps);\r\nASSERT(imap->br_startblock != HOLESTARTBLOCK);\r\nASSERT(imap->br_startblock != DELAYSTARTBLOCK);\r\n}\r\n#endif\r\nif (nimaps)\r\ntrace_xfs_map_blocks_found(ip, offset, count, type, imap);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_imap_valid(\r\nstruct inode *inode,\r\nstruct xfs_bmbt_irec *imap,\r\nxfs_off_t offset)\r\n{\r\noffset >>= inode->i_blkbits;\r\nreturn offset >= imap->br_startoff &&\r\noffset < imap->br_startoff + imap->br_blockcount;\r\n}\r\nSTATIC void\r\nxfs_end_bio(\r\nstruct bio *bio,\r\nint error)\r\n{\r\nxfs_ioend_t *ioend = bio->bi_private;\r\nASSERT(atomic_read(&bio->bi_cnt) >= 1);\r\nioend->io_error = test_bit(BIO_UPTODATE, &bio->bi_flags) ? 0 : error;\r\nbio->bi_private = NULL;\r\nbio->bi_end_io = NULL;\r\nbio_put(bio);\r\nxfs_finish_ioend(ioend);\r\n}\r\nSTATIC void\r\nxfs_submit_ioend_bio(\r\nstruct writeback_control *wbc,\r\nxfs_ioend_t *ioend,\r\nstruct bio *bio)\r\n{\r\natomic_inc(&ioend->io_remaining);\r\nbio->bi_private = ioend;\r\nbio->bi_end_io = xfs_end_bio;\r\nsubmit_bio(wbc->sync_mode == WB_SYNC_ALL ? WRITE_SYNC : WRITE, bio);\r\n}\r\nSTATIC struct bio *\r\nxfs_alloc_ioend_bio(\r\nstruct buffer_head *bh)\r\n{\r\nint nvecs = bio_get_nr_vecs(bh->b_bdev);\r\nstruct bio *bio = bio_alloc(GFP_NOIO, nvecs);\r\nASSERT(bio->bi_private == NULL);\r\nbio->bi_sector = bh->b_blocknr * (bh->b_size >> 9);\r\nbio->bi_bdev = bh->b_bdev;\r\nreturn bio;\r\n}\r\nSTATIC void\r\nxfs_start_buffer_writeback(\r\nstruct buffer_head *bh)\r\n{\r\nASSERT(buffer_mapped(bh));\r\nASSERT(buffer_locked(bh));\r\nASSERT(!buffer_delay(bh));\r\nASSERT(!buffer_unwritten(bh));\r\nmark_buffer_async_write(bh);\r\nset_buffer_uptodate(bh);\r\nclear_buffer_dirty(bh);\r\n}\r\nSTATIC void\r\nxfs_start_page_writeback(\r\nstruct page *page,\r\nint clear_dirty,\r\nint buffers)\r\n{\r\nASSERT(PageLocked(page));\r\nASSERT(!PageWriteback(page));\r\nif (clear_dirty)\r\nclear_page_dirty_for_io(page);\r\nset_page_writeback(page);\r\nunlock_page(page);\r\nif (!buffers)\r\nend_page_writeback(page);\r\n}\r\nstatic inline int bio_add_buffer(struct bio *bio, struct buffer_head *bh)\r\n{\r\nreturn bio_add_page(bio, bh->b_page, bh->b_size, bh_offset(bh));\r\n}\r\nSTATIC void\r\nxfs_submit_ioend(\r\nstruct writeback_control *wbc,\r\nxfs_ioend_t *ioend,\r\nint fail)\r\n{\r\nxfs_ioend_t *head = ioend;\r\nxfs_ioend_t *next;\r\nstruct buffer_head *bh;\r\nstruct bio *bio;\r\nsector_t lastblock = 0;\r\ndo {\r\nnext = ioend->io_list;\r\nfor (bh = ioend->io_buffer_head; bh; bh = bh->b_private)\r\nxfs_start_buffer_writeback(bh);\r\n} while ((ioend = next) != NULL);\r\nioend = head;\r\ndo {\r\nnext = ioend->io_list;\r\nbio = NULL;\r\nif (fail) {\r\nioend->io_error = -fail;\r\nxfs_finish_ioend(ioend);\r\ncontinue;\r\n}\r\nfor (bh = ioend->io_buffer_head; bh; bh = bh->b_private) {\r\nif (!bio) {\r\nretry:\r\nbio = xfs_alloc_ioend_bio(bh);\r\n} else if (bh->b_blocknr != lastblock + 1) {\r\nxfs_submit_ioend_bio(wbc, ioend, bio);\r\ngoto retry;\r\n}\r\nif (bio_add_buffer(bio, bh) != bh->b_size) {\r\nxfs_submit_ioend_bio(wbc, ioend, bio);\r\ngoto retry;\r\n}\r\nlastblock = bh->b_blocknr;\r\n}\r\nif (bio)\r\nxfs_submit_ioend_bio(wbc, ioend, bio);\r\nxfs_finish_ioend(ioend);\r\n} while ((ioend = next) != NULL);\r\n}\r\nSTATIC void\r\nxfs_cancel_ioend(\r\nxfs_ioend_t *ioend)\r\n{\r\nxfs_ioend_t *next;\r\nstruct buffer_head *bh, *next_bh;\r\ndo {\r\nnext = ioend->io_list;\r\nbh = ioend->io_buffer_head;\r\ndo {\r\nnext_bh = bh->b_private;\r\nclear_buffer_async_write(bh);\r\nunlock_buffer(bh);\r\n} while ((bh = next_bh) != NULL);\r\nmempool_free(ioend, xfs_ioend_pool);\r\n} while ((ioend = next) != NULL);\r\n}\r\nSTATIC void\r\nxfs_add_to_ioend(\r\nstruct inode *inode,\r\nstruct buffer_head *bh,\r\nxfs_off_t offset,\r\nunsigned int type,\r\nxfs_ioend_t **result,\r\nint need_ioend)\r\n{\r\nxfs_ioend_t *ioend = *result;\r\nif (!ioend || need_ioend || type != ioend->io_type) {\r\nxfs_ioend_t *previous = *result;\r\nioend = xfs_alloc_ioend(inode, type);\r\nioend->io_offset = offset;\r\nioend->io_buffer_head = bh;\r\nioend->io_buffer_tail = bh;\r\nif (previous)\r\nprevious->io_list = ioend;\r\n*result = ioend;\r\n} else {\r\nioend->io_buffer_tail->b_private = bh;\r\nioend->io_buffer_tail = bh;\r\n}\r\nbh->b_private = NULL;\r\nioend->io_size += bh->b_size;\r\n}\r\nSTATIC void\r\nxfs_map_buffer(\r\nstruct inode *inode,\r\nstruct buffer_head *bh,\r\nstruct xfs_bmbt_irec *imap,\r\nxfs_off_t offset)\r\n{\r\nsector_t bn;\r\nstruct xfs_mount *m = XFS_I(inode)->i_mount;\r\nxfs_off_t iomap_offset = XFS_FSB_TO_B(m, imap->br_startoff);\r\nxfs_daddr_t iomap_bn = xfs_fsb_to_db(XFS_I(inode), imap->br_startblock);\r\nASSERT(imap->br_startblock != HOLESTARTBLOCK);\r\nASSERT(imap->br_startblock != DELAYSTARTBLOCK);\r\nbn = (iomap_bn >> (inode->i_blkbits - BBSHIFT)) +\r\n((offset - iomap_offset) >> inode->i_blkbits);\r\nASSERT(bn || XFS_IS_REALTIME_INODE(XFS_I(inode)));\r\nbh->b_blocknr = bn;\r\nset_buffer_mapped(bh);\r\n}\r\nSTATIC void\r\nxfs_map_at_offset(\r\nstruct inode *inode,\r\nstruct buffer_head *bh,\r\nstruct xfs_bmbt_irec *imap,\r\nxfs_off_t offset)\r\n{\r\nASSERT(imap->br_startblock != HOLESTARTBLOCK);\r\nASSERT(imap->br_startblock != DELAYSTARTBLOCK);\r\nxfs_map_buffer(inode, bh, imap, offset);\r\nset_buffer_mapped(bh);\r\nclear_buffer_delay(bh);\r\nclear_buffer_unwritten(bh);\r\n}\r\nSTATIC int\r\nxfs_check_page_type(\r\nstruct page *page,\r\nunsigned int type)\r\n{\r\nif (PageWriteback(page))\r\nreturn 0;\r\nif (page->mapping && page_has_buffers(page)) {\r\nstruct buffer_head *bh, *head;\r\nint acceptable = 0;\r\nbh = head = page_buffers(page);\r\ndo {\r\nif (buffer_unwritten(bh))\r\nacceptable += (type == XFS_IO_UNWRITTEN);\r\nelse if (buffer_delay(bh))\r\nacceptable += (type == XFS_IO_DELALLOC);\r\nelse if (buffer_dirty(bh) && buffer_mapped(bh))\r\nacceptable += (type == XFS_IO_OVERWRITE);\r\nelse\r\nbreak;\r\n} while ((bh = bh->b_this_page) != head);\r\nif (acceptable)\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_convert_page(\r\nstruct inode *inode,\r\nstruct page *page,\r\nloff_t tindex,\r\nstruct xfs_bmbt_irec *imap,\r\nxfs_ioend_t **ioendp,\r\nstruct writeback_control *wbc)\r\n{\r\nstruct buffer_head *bh, *head;\r\nxfs_off_t end_offset;\r\nunsigned long p_offset;\r\nunsigned int type;\r\nint len, page_dirty;\r\nint count = 0, done = 0, uptodate = 1;\r\nxfs_off_t offset = page_offset(page);\r\nif (page->index != tindex)\r\ngoto fail;\r\nif (!trylock_page(page))\r\ngoto fail;\r\nif (PageWriteback(page))\r\ngoto fail_unlock_page;\r\nif (page->mapping != inode->i_mapping)\r\ngoto fail_unlock_page;\r\nif (!xfs_check_page_type(page, (*ioendp)->io_type))\r\ngoto fail_unlock_page;\r\nend_offset = min_t(unsigned long long,\r\n(xfs_off_t)(page->index + 1) << PAGE_CACHE_SHIFT,\r\ni_size_read(inode));\r\nlen = 1 << inode->i_blkbits;\r\np_offset = min_t(unsigned long, end_offset & (PAGE_CACHE_SIZE - 1),\r\nPAGE_CACHE_SIZE);\r\np_offset = p_offset ? roundup(p_offset, len) : PAGE_CACHE_SIZE;\r\npage_dirty = p_offset / len;\r\nbh = head = page_buffers(page);\r\ndo {\r\nif (offset >= end_offset)\r\nbreak;\r\nif (!buffer_uptodate(bh))\r\nuptodate = 0;\r\nif (!(PageUptodate(page) || buffer_uptodate(bh))) {\r\ndone = 1;\r\ncontinue;\r\n}\r\nif (buffer_unwritten(bh) || buffer_delay(bh) ||\r\nbuffer_mapped(bh)) {\r\nif (buffer_unwritten(bh))\r\ntype = XFS_IO_UNWRITTEN;\r\nelse if (buffer_delay(bh))\r\ntype = XFS_IO_DELALLOC;\r\nelse\r\ntype = XFS_IO_OVERWRITE;\r\nif (!xfs_imap_valid(inode, imap, offset)) {\r\ndone = 1;\r\ncontinue;\r\n}\r\nlock_buffer(bh);\r\nif (type != XFS_IO_OVERWRITE)\r\nxfs_map_at_offset(inode, bh, imap, offset);\r\nxfs_add_to_ioend(inode, bh, offset, type,\r\nioendp, done);\r\npage_dirty--;\r\ncount++;\r\n} else {\r\ndone = 1;\r\n}\r\n} while (offset += len, (bh = bh->b_this_page) != head);\r\nif (uptodate && bh == head)\r\nSetPageUptodate(page);\r\nif (count) {\r\nif (--wbc->nr_to_write <= 0 &&\r\nwbc->sync_mode == WB_SYNC_NONE)\r\ndone = 1;\r\n}\r\nxfs_start_page_writeback(page, !page_dirty, count);\r\nreturn done;\r\nfail_unlock_page:\r\nunlock_page(page);\r\nfail:\r\nreturn 1;\r\n}\r\nSTATIC void\r\nxfs_cluster_write(\r\nstruct inode *inode,\r\npgoff_t tindex,\r\nstruct xfs_bmbt_irec *imap,\r\nxfs_ioend_t **ioendp,\r\nstruct writeback_control *wbc,\r\npgoff_t tlast)\r\n{\r\nstruct pagevec pvec;\r\nint done = 0, i;\r\npagevec_init(&pvec, 0);\r\nwhile (!done && tindex <= tlast) {\r\nunsigned len = min_t(pgoff_t, PAGEVEC_SIZE, tlast - tindex + 1);\r\nif (!pagevec_lookup(&pvec, inode->i_mapping, tindex, len))\r\nbreak;\r\nfor (i = 0; i < pagevec_count(&pvec); i++) {\r\ndone = xfs_convert_page(inode, pvec.pages[i], tindex++,\r\nimap, ioendp, wbc);\r\nif (done)\r\nbreak;\r\n}\r\npagevec_release(&pvec);\r\ncond_resched();\r\n}\r\n}\r\nSTATIC void\r\nxfs_vm_invalidatepage(\r\nstruct page *page,\r\nunsigned long offset)\r\n{\r\ntrace_xfs_invalidatepage(page->mapping->host, page, offset);\r\nblock_invalidatepage(page, offset);\r\n}\r\nSTATIC void\r\nxfs_aops_discard_page(\r\nstruct page *page)\r\n{\r\nstruct inode *inode = page->mapping->host;\r\nstruct xfs_inode *ip = XFS_I(inode);\r\nstruct buffer_head *bh, *head;\r\nloff_t offset = page_offset(page);\r\nif (!xfs_check_page_type(page, XFS_IO_DELALLOC))\r\ngoto out_invalidate;\r\nif (XFS_FORCED_SHUTDOWN(ip->i_mount))\r\ngoto out_invalidate;\r\nxfs_alert(ip->i_mount,\r\n"page discard on page %p, inode 0x%llx, offset %llu.",\r\npage, ip->i_ino, offset);\r\nxfs_ilock(ip, XFS_ILOCK_EXCL);\r\nbh = head = page_buffers(page);\r\ndo {\r\nint error;\r\nxfs_fileoff_t start_fsb;\r\nif (!buffer_delay(bh))\r\ngoto next_buffer;\r\nstart_fsb = XFS_B_TO_FSBT(ip->i_mount, offset);\r\nerror = xfs_bmap_punch_delalloc_range(ip, start_fsb, 1);\r\nif (error) {\r\nif (!XFS_FORCED_SHUTDOWN(ip->i_mount)) {\r\nxfs_alert(ip->i_mount,\r\n"page discard unable to remove delalloc mapping.");\r\n}\r\nbreak;\r\n}\r\nnext_buffer:\r\noffset += 1 << inode->i_blkbits;\r\n} while ((bh = bh->b_this_page) != head);\r\nxfs_iunlock(ip, XFS_ILOCK_EXCL);\r\nout_invalidate:\r\nxfs_vm_invalidatepage(page, 0);\r\nreturn;\r\n}\r\nSTATIC int\r\nxfs_vm_writepage(\r\nstruct page *page,\r\nstruct writeback_control *wbc)\r\n{\r\nstruct inode *inode = page->mapping->host;\r\nstruct buffer_head *bh, *head;\r\nstruct xfs_bmbt_irec imap;\r\nxfs_ioend_t *ioend = NULL, *iohead = NULL;\r\nloff_t offset;\r\nunsigned int type;\r\n__uint64_t end_offset;\r\npgoff_t end_index, last_index;\r\nssize_t len;\r\nint err, imap_valid = 0, uptodate = 1;\r\nint count = 0;\r\nint nonblocking = 0;\r\ntrace_xfs_writepage(inode, page, 0);\r\nASSERT(page_has_buffers(page));\r\nif (WARN_ON_ONCE((current->flags & (PF_MEMALLOC|PF_KSWAPD)) ==\r\nPF_MEMALLOC))\r\ngoto redirty;\r\nif (WARN_ON(current->flags & PF_FSTRANS))\r\ngoto redirty;\r\noffset = i_size_read(inode);\r\nend_index = offset >> PAGE_CACHE_SHIFT;\r\nlast_index = (offset - 1) >> PAGE_CACHE_SHIFT;\r\nif (page->index >= end_index) {\r\nunsigned offset_into_page = offset & (PAGE_CACHE_SIZE - 1);\r\nif (page->index >= end_index + 1 || offset_into_page == 0) {\r\nunlock_page(page);\r\nreturn 0;\r\n}\r\nzero_user_segment(page, offset_into_page, PAGE_CACHE_SIZE);\r\n}\r\nend_offset = min_t(unsigned long long,\r\n(xfs_off_t)(page->index + 1) << PAGE_CACHE_SHIFT,\r\noffset);\r\nlen = 1 << inode->i_blkbits;\r\nbh = head = page_buffers(page);\r\noffset = page_offset(page);\r\ntype = XFS_IO_OVERWRITE;\r\nif (wbc->sync_mode == WB_SYNC_NONE)\r\nnonblocking = 1;\r\ndo {\r\nint new_ioend = 0;\r\nif (offset >= end_offset)\r\nbreak;\r\nif (!buffer_uptodate(bh))\r\nuptodate = 0;\r\nif (!buffer_mapped(bh) && buffer_uptodate(bh)) {\r\nimap_valid = 0;\r\ncontinue;\r\n}\r\nif (buffer_unwritten(bh)) {\r\nif (type != XFS_IO_UNWRITTEN) {\r\ntype = XFS_IO_UNWRITTEN;\r\nimap_valid = 0;\r\n}\r\n} else if (buffer_delay(bh)) {\r\nif (type != XFS_IO_DELALLOC) {\r\ntype = XFS_IO_DELALLOC;\r\nimap_valid = 0;\r\n}\r\n} else if (buffer_uptodate(bh)) {\r\nif (type != XFS_IO_OVERWRITE) {\r\ntype = XFS_IO_OVERWRITE;\r\nimap_valid = 0;\r\n}\r\n} else {\r\nif (PageUptodate(page))\r\nASSERT(buffer_mapped(bh));\r\nimap_valid = 0;\r\ncontinue;\r\n}\r\nif (imap_valid)\r\nimap_valid = xfs_imap_valid(inode, &imap, offset);\r\nif (!imap_valid) {\r\nnew_ioend = 1;\r\nerr = xfs_map_blocks(inode, offset, &imap, type,\r\nnonblocking);\r\nif (err)\r\ngoto error;\r\nimap_valid = xfs_imap_valid(inode, &imap, offset);\r\n}\r\nif (imap_valid) {\r\nlock_buffer(bh);\r\nif (type != XFS_IO_OVERWRITE)\r\nxfs_map_at_offset(inode, bh, &imap, offset);\r\nxfs_add_to_ioend(inode, bh, offset, type, &ioend,\r\nnew_ioend);\r\ncount++;\r\n}\r\nif (!iohead)\r\niohead = ioend;\r\n} while (offset += len, ((bh = bh->b_this_page) != head));\r\nif (uptodate && bh == head)\r\nSetPageUptodate(page);\r\nxfs_start_page_writeback(page, 1, count);\r\nif (!ioend)\r\nreturn 0;\r\nASSERT(iohead);\r\nif (imap_valid) {\r\nxfs_off_t end_index;\r\nend_index = imap.br_startoff + imap.br_blockcount;\r\nend_index <<= inode->i_blkbits;\r\nend_index = (end_index - 1) >> PAGE_CACHE_SHIFT;\r\nif (end_index > last_index)\r\nend_index = last_index;\r\nxfs_cluster_write(inode, page->index + 1, &imap, &ioend,\r\nwbc, end_index);\r\n}\r\nerr = 0;\r\nif (ioend->io_type != XFS_IO_UNWRITTEN && xfs_ioend_is_append(ioend))\r\nerr = xfs_setfilesize_trans_alloc(ioend);\r\nxfs_submit_ioend(wbc, iohead, err);\r\nreturn 0;\r\nerror:\r\nif (iohead)\r\nxfs_cancel_ioend(iohead);\r\nif (err == -EAGAIN)\r\ngoto redirty;\r\nxfs_aops_discard_page(page);\r\nClearPageUptodate(page);\r\nunlock_page(page);\r\nreturn err;\r\nredirty:\r\nredirty_page_for_writepage(wbc, page);\r\nunlock_page(page);\r\nreturn 0;\r\n}\r\nSTATIC int\r\nxfs_vm_writepages(\r\nstruct address_space *mapping,\r\nstruct writeback_control *wbc)\r\n{\r\nxfs_iflags_clear(XFS_I(mapping->host), XFS_ITRUNCATED);\r\nreturn generic_writepages(mapping, wbc);\r\n}\r\nSTATIC int\r\nxfs_vm_releasepage(\r\nstruct page *page,\r\ngfp_t gfp_mask)\r\n{\r\nint delalloc, unwritten;\r\ntrace_xfs_releasepage(page->mapping->host, page, 0);\r\nxfs_count_page_state(page, &delalloc, &unwritten);\r\nif (WARN_ON(delalloc))\r\nreturn 0;\r\nif (WARN_ON(unwritten))\r\nreturn 0;\r\nreturn try_to_free_buffers(page);\r\n}\r\nSTATIC int\r\n__xfs_get_blocks(\r\nstruct inode *inode,\r\nsector_t iblock,\r\nstruct buffer_head *bh_result,\r\nint create,\r\nint direct)\r\n{\r\nstruct xfs_inode *ip = XFS_I(inode);\r\nstruct xfs_mount *mp = ip->i_mount;\r\nxfs_fileoff_t offset_fsb, end_fsb;\r\nint error = 0;\r\nint lockmode = 0;\r\nstruct xfs_bmbt_irec imap;\r\nint nimaps = 1;\r\nxfs_off_t offset;\r\nssize_t size;\r\nint new = 0;\r\nif (XFS_FORCED_SHUTDOWN(mp))\r\nreturn -XFS_ERROR(EIO);\r\noffset = (xfs_off_t)iblock << inode->i_blkbits;\r\nASSERT(bh_result->b_size >= (1 << inode->i_blkbits));\r\nsize = bh_result->b_size;\r\nif (!create && direct && offset >= i_size_read(inode))\r\nreturn 0;\r\nif (create && !direct) {\r\nlockmode = XFS_ILOCK_EXCL;\r\nxfs_ilock(ip, lockmode);\r\n} else {\r\nlockmode = xfs_ilock_map_shared(ip);\r\n}\r\nASSERT(offset <= mp->m_super->s_maxbytes);\r\nif (offset + size > mp->m_super->s_maxbytes)\r\nsize = mp->m_super->s_maxbytes - offset;\r\nend_fsb = XFS_B_TO_FSB(mp, (xfs_ufsize_t)offset + size);\r\noffset_fsb = XFS_B_TO_FSBT(mp, offset);\r\nerror = xfs_bmapi_read(ip, offset_fsb, end_fsb - offset_fsb,\r\n&imap, &nimaps, XFS_BMAPI_ENTIRE);\r\nif (error)\r\ngoto out_unlock;\r\nif (create &&\r\n(!nimaps ||\r\n(imap.br_startblock == HOLESTARTBLOCK ||\r\nimap.br_startblock == DELAYSTARTBLOCK))) {\r\nif (direct || xfs_get_extsz_hint(ip)) {\r\nxfs_iunlock(ip, lockmode);\r\nerror = xfs_iomap_write_direct(ip, offset, size,\r\n&imap, nimaps);\r\nif (error)\r\nreturn -error;\r\nnew = 1;\r\n} else {\r\nif (nimaps && imap.br_startblock == HOLESTARTBLOCK)\r\nnew = 1;\r\nerror = xfs_iomap_write_delay(ip, offset, size, &imap);\r\nif (error)\r\ngoto out_unlock;\r\nxfs_iunlock(ip, lockmode);\r\n}\r\ntrace_xfs_get_blocks_alloc(ip, offset, size, 0, &imap);\r\n} else if (nimaps) {\r\ntrace_xfs_get_blocks_found(ip, offset, size, 0, &imap);\r\nxfs_iunlock(ip, lockmode);\r\n} else {\r\ntrace_xfs_get_blocks_notfound(ip, offset, size);\r\ngoto out_unlock;\r\n}\r\nif (imap.br_startblock != HOLESTARTBLOCK &&\r\nimap.br_startblock != DELAYSTARTBLOCK) {\r\nif (create || !ISUNWRITTEN(&imap))\r\nxfs_map_buffer(inode, bh_result, &imap, offset);\r\nif (create && ISUNWRITTEN(&imap)) {\r\nif (direct)\r\nbh_result->b_private = inode;\r\nset_buffer_unwritten(bh_result);\r\n}\r\n}\r\nbh_result->b_bdev = xfs_find_bdev_for_inode(inode);\r\nif (create &&\r\n((!buffer_mapped(bh_result) && !buffer_uptodate(bh_result)) ||\r\n(offset >= i_size_read(inode)) ||\r\n(new || ISUNWRITTEN(&imap))))\r\nset_buffer_new(bh_result);\r\nif (imap.br_startblock == DELAYSTARTBLOCK) {\r\nBUG_ON(direct);\r\nif (create) {\r\nset_buffer_uptodate(bh_result);\r\nset_buffer_mapped(bh_result);\r\nset_buffer_delay(bh_result);\r\n}\r\n}\r\nif (direct || size > (1 << inode->i_blkbits)) {\r\nxfs_off_t mapping_size;\r\nmapping_size = imap.br_startoff + imap.br_blockcount - iblock;\r\nmapping_size <<= inode->i_blkbits;\r\nASSERT(mapping_size > 0);\r\nif (mapping_size > size)\r\nmapping_size = size;\r\nif (mapping_size > LONG_MAX)\r\nmapping_size = LONG_MAX;\r\nbh_result->b_size = mapping_size;\r\n}\r\nreturn 0;\r\nout_unlock:\r\nxfs_iunlock(ip, lockmode);\r\nreturn -error;\r\n}\r\nint\r\nxfs_get_blocks(\r\nstruct inode *inode,\r\nsector_t iblock,\r\nstruct buffer_head *bh_result,\r\nint create)\r\n{\r\nreturn __xfs_get_blocks(inode, iblock, bh_result, create, 0);\r\n}\r\nSTATIC int\r\nxfs_get_blocks_direct(\r\nstruct inode *inode,\r\nsector_t iblock,\r\nstruct buffer_head *bh_result,\r\nint create)\r\n{\r\nreturn __xfs_get_blocks(inode, iblock, bh_result, create, 1);\r\n}\r\nSTATIC void\r\nxfs_end_io_direct_write(\r\nstruct kiocb *iocb,\r\nloff_t offset,\r\nssize_t size,\r\nvoid *private,\r\nint ret,\r\nbool is_async)\r\n{\r\nstruct xfs_ioend *ioend = iocb->private;\r\nif (offset + size > i_size_read(ioend->io_inode))\r\ni_size_write(ioend->io_inode, offset + size);\r\niocb->private = NULL;\r\nioend->io_offset = offset;\r\nioend->io_size = size;\r\nioend->io_iocb = iocb;\r\nioend->io_result = ret;\r\nif (private && size > 0)\r\nioend->io_type = XFS_IO_UNWRITTEN;\r\nif (is_async) {\r\nioend->io_isasync = 1;\r\nxfs_finish_ioend(ioend);\r\n} else {\r\nxfs_finish_ioend_sync(ioend);\r\n}\r\n}\r\nSTATIC ssize_t\r\nxfs_vm_direct_IO(\r\nint rw,\r\nstruct kiocb *iocb,\r\nconst struct iovec *iov,\r\nloff_t offset,\r\nunsigned long nr_segs)\r\n{\r\nstruct inode *inode = iocb->ki_filp->f_mapping->host;\r\nstruct block_device *bdev = xfs_find_bdev_for_inode(inode);\r\nstruct xfs_ioend *ioend = NULL;\r\nssize_t ret;\r\nif (rw & WRITE) {\r\nsize_t size = iov_length(iov, nr_segs);\r\niocb->private = ioend = xfs_alloc_ioend(inode, XFS_IO_DIRECT);\r\nif (offset + size > XFS_I(inode)->i_d.di_size)\r\nioend->io_isdirect = 1;\r\nret = __blockdev_direct_IO(rw, iocb, inode, bdev, iov,\r\noffset, nr_segs,\r\nxfs_get_blocks_direct,\r\nxfs_end_io_direct_write, NULL, 0);\r\nif (ret != -EIOCBQUEUED && iocb->private)\r\ngoto out_destroy_ioend;\r\n} else {\r\nret = __blockdev_direct_IO(rw, iocb, inode, bdev, iov,\r\noffset, nr_segs,\r\nxfs_get_blocks_direct,\r\nNULL, NULL, 0);\r\n}\r\nreturn ret;\r\nout_destroy_ioend:\r\nxfs_destroy_ioend(ioend);\r\nreturn ret;\r\n}\r\nSTATIC void\r\nxfs_vm_kill_delalloc_range(\r\nstruct inode *inode,\r\nloff_t start,\r\nloff_t end)\r\n{\r\nstruct xfs_inode *ip = XFS_I(inode);\r\nxfs_fileoff_t start_fsb;\r\nxfs_fileoff_t end_fsb;\r\nint error;\r\nstart_fsb = XFS_B_TO_FSB(ip->i_mount, start);\r\nend_fsb = XFS_B_TO_FSB(ip->i_mount, end);\r\nif (end_fsb <= start_fsb)\r\nreturn;\r\nxfs_ilock(ip, XFS_ILOCK_EXCL);\r\nerror = xfs_bmap_punch_delalloc_range(ip, start_fsb,\r\nend_fsb - start_fsb);\r\nif (error) {\r\nif (!XFS_FORCED_SHUTDOWN(ip->i_mount)) {\r\nxfs_alert(ip->i_mount,\r\n"xfs_vm_write_failed: unable to clean up ino %lld",\r\nip->i_ino);\r\n}\r\n}\r\nxfs_iunlock(ip, XFS_ILOCK_EXCL);\r\n}\r\nSTATIC void\r\nxfs_vm_write_failed(\r\nstruct inode *inode,\r\nstruct page *page,\r\nloff_t pos,\r\nunsigned len)\r\n{\r\nloff_t block_offset = pos & PAGE_MASK;\r\nloff_t block_start;\r\nloff_t block_end;\r\nloff_t from = pos & (PAGE_CACHE_SIZE - 1);\r\nloff_t to = from + len;\r\nstruct buffer_head *bh, *head;\r\nASSERT(block_offset + from == pos);\r\nhead = page_buffers(page);\r\nblock_start = 0;\r\nfor (bh = head; bh != head || !block_start;\r\nbh = bh->b_this_page, block_start = block_end,\r\nblock_offset += bh->b_size) {\r\nblock_end = block_start + bh->b_size;\r\nif (block_end <= from)\r\ncontinue;\r\nif (block_start >= to)\r\nbreak;\r\nif (!buffer_delay(bh))\r\ncontinue;\r\nif (!buffer_new(bh) && block_offset < i_size_read(inode))\r\ncontinue;\r\nxfs_vm_kill_delalloc_range(inode, block_offset,\r\nblock_offset + bh->b_size);\r\n}\r\n}\r\nSTATIC int\r\nxfs_vm_write_begin(\r\nstruct file *file,\r\nstruct address_space *mapping,\r\nloff_t pos,\r\nunsigned len,\r\nunsigned flags,\r\nstruct page **pagep,\r\nvoid **fsdata)\r\n{\r\npgoff_t index = pos >> PAGE_CACHE_SHIFT;\r\nstruct page *page;\r\nint status;\r\nASSERT(len <= PAGE_CACHE_SIZE);\r\npage = grab_cache_page_write_begin(mapping, index,\r\nflags | AOP_FLAG_NOFS);\r\nif (!page)\r\nreturn -ENOMEM;\r\nstatus = __block_write_begin(page, pos, len, xfs_get_blocks);\r\nif (unlikely(status)) {\r\nstruct inode *inode = mapping->host;\r\nxfs_vm_write_failed(inode, page, pos, len);\r\nunlock_page(page);\r\nif (pos + len > i_size_read(inode))\r\ntruncate_pagecache(inode, pos + len, i_size_read(inode));\r\npage_cache_release(page);\r\npage = NULL;\r\n}\r\n*pagep = page;\r\nreturn status;\r\n}\r\nSTATIC int\r\nxfs_vm_write_end(\r\nstruct file *file,\r\nstruct address_space *mapping,\r\nloff_t pos,\r\nunsigned len,\r\nunsigned copied,\r\nstruct page *page,\r\nvoid *fsdata)\r\n{\r\nint ret;\r\nASSERT(len <= PAGE_CACHE_SIZE);\r\nret = generic_write_end(file, mapping, pos, len, copied, page, fsdata);\r\nif (unlikely(ret < len)) {\r\nstruct inode *inode = mapping->host;\r\nsize_t isize = i_size_read(inode);\r\nloff_t to = pos + len;\r\nif (to > isize) {\r\ntruncate_pagecache(inode, to, isize);\r\nxfs_vm_kill_delalloc_range(inode, isize, to);\r\n}\r\n}\r\nreturn ret;\r\n}\r\nSTATIC sector_t\r\nxfs_vm_bmap(\r\nstruct address_space *mapping,\r\nsector_t block)\r\n{\r\nstruct inode *inode = (struct inode *)mapping->host;\r\nstruct xfs_inode *ip = XFS_I(inode);\r\ntrace_xfs_vm_bmap(XFS_I(inode));\r\nxfs_ilock(ip, XFS_IOLOCK_SHARED);\r\nfilemap_write_and_wait(mapping);\r\nxfs_iunlock(ip, XFS_IOLOCK_SHARED);\r\nreturn generic_block_bmap(mapping, block, xfs_get_blocks);\r\n}\r\nSTATIC int\r\nxfs_vm_readpage(\r\nstruct file *unused,\r\nstruct page *page)\r\n{\r\nreturn mpage_readpage(page, xfs_get_blocks);\r\n}\r\nSTATIC int\r\nxfs_vm_readpages(\r\nstruct file *unused,\r\nstruct address_space *mapping,\r\nstruct list_head *pages,\r\nunsigned nr_pages)\r\n{\r\nreturn mpage_readpages(mapping, pages, nr_pages, xfs_get_blocks);\r\n}
