static int decode_sector_number(__be32 **rp, sector_t *sp)\r\n{\r\nuint64_t s;\r\n*rp = xdr_decode_hyper(*rp, &s);\r\nif (s & 0x1ff) {\r\nprintk(KERN_WARNING "NFS: %s: sector not aligned\n", __func__);\r\nreturn -1;\r\n}\r\n*sp = s >> SECTOR_SHIFT;\r\nreturn 0;\r\n}\r\nint nfs4_blkdev_put(struct block_device *bdev)\r\n{\r\ndprintk("%s for device %d:%d\n", __func__, MAJOR(bdev->bd_dev),\r\nMINOR(bdev->bd_dev));\r\nreturn blkdev_put(bdev, FMODE_READ);\r\n}\r\nssize_t bl_pipe_downcall(struct file *filp, const char __user *src,\r\nsize_t mlen)\r\n{\r\nstruct nfs_net *nn = net_generic(filp->f_dentry->d_sb->s_fs_info,\r\nnfs_net_id);\r\nif (mlen != sizeof (struct bl_dev_msg))\r\nreturn -EINVAL;\r\nif (copy_from_user(&nn->bl_mount_reply, src, mlen) != 0)\r\nreturn -EFAULT;\r\nwake_up(&nn->bl_wq);\r\nreturn mlen;\r\n}\r\nvoid bl_pipe_destroy_msg(struct rpc_pipe_msg *msg)\r\n{\r\nstruct bl_pipe_msg *bl_pipe_msg = container_of(msg, struct bl_pipe_msg, msg);\r\nif (msg->errno >= 0)\r\nreturn;\r\nwake_up(bl_pipe_msg->bl_wq);\r\n}\r\nstruct pnfs_block_dev *\r\nnfs4_blk_decode_device(struct nfs_server *server,\r\nstruct pnfs_device *dev)\r\n{\r\nstruct pnfs_block_dev *rv;\r\nstruct block_device *bd = NULL;\r\nstruct bl_pipe_msg bl_pipe_msg;\r\nstruct rpc_pipe_msg *msg = &bl_pipe_msg.msg;\r\nstruct bl_msg_hdr bl_msg = {\r\n.type = BL_DEVICE_MOUNT,\r\n.totallen = dev->mincount,\r\n};\r\nuint8_t *dataptr;\r\nDECLARE_WAITQUEUE(wq, current);\r\nint offset, len, i, rc;\r\nstruct net *net = server->nfs_client->cl_net;\r\nstruct nfs_net *nn = net_generic(net, nfs_net_id);\r\nstruct bl_dev_msg *reply = &nn->bl_mount_reply;\r\ndprintk("%s CREATING PIPEFS MESSAGE\n", __func__);\r\ndprintk("%s: deviceid: %s, mincount: %d\n", __func__, dev->dev_id.data,\r\ndev->mincount);\r\nbl_pipe_msg.bl_wq = &nn->bl_wq;\r\nmemset(msg, 0, sizeof(*msg));\r\nmsg->data = kzalloc(sizeof(bl_msg) + dev->mincount, GFP_NOFS);\r\nif (!msg->data) {\r\nrv = ERR_PTR(-ENOMEM);\r\ngoto out;\r\n}\r\nmemcpy(msg->data, &bl_msg, sizeof(bl_msg));\r\ndataptr = (uint8_t *) msg->data;\r\nlen = dev->mincount;\r\noffset = sizeof(bl_msg);\r\nfor (i = 0; len > 0; i++) {\r\nmemcpy(&dataptr[offset], page_address(dev->pages[i]),\r\nlen < PAGE_CACHE_SIZE ? len : PAGE_CACHE_SIZE);\r\nlen -= PAGE_CACHE_SIZE;\r\noffset += PAGE_CACHE_SIZE;\r\n}\r\nmsg->len = sizeof(bl_msg) + dev->mincount;\r\ndprintk("%s CALLING USERSPACE DAEMON\n", __func__);\r\nadd_wait_queue(&nn->bl_wq, &wq);\r\nrc = rpc_queue_upcall(nn->bl_device_pipe, msg);\r\nif (rc < 0) {\r\nremove_wait_queue(&nn->bl_wq, &wq);\r\nrv = ERR_PTR(rc);\r\ngoto out;\r\n}\r\nset_current_state(TASK_UNINTERRUPTIBLE);\r\nschedule();\r\n__set_current_state(TASK_RUNNING);\r\nremove_wait_queue(&nn->bl_wq, &wq);\r\nif (reply->status != BL_DEVICE_REQUEST_PROC) {\r\ndprintk("%s failed to open device: %d\n",\r\n__func__, reply->status);\r\nrv = ERR_PTR(-EINVAL);\r\ngoto out;\r\n}\r\nbd = blkdev_get_by_dev(MKDEV(reply->major, reply->minor),\r\nFMODE_READ, NULL);\r\nif (IS_ERR(bd)) {\r\ndprintk("%s failed to open device : %ld\n", __func__,\r\nPTR_ERR(bd));\r\nrv = ERR_CAST(bd);\r\ngoto out;\r\n}\r\nrv = kzalloc(sizeof(*rv), GFP_NOFS);\r\nif (!rv) {\r\nrv = ERR_PTR(-ENOMEM);\r\ngoto out;\r\n}\r\nrv->bm_mdev = bd;\r\nmemcpy(&rv->bm_mdevid, &dev->dev_id, sizeof(struct nfs4_deviceid));\r\nrv->net = net;\r\ndprintk("%s Created device %s with bd_block_size %u\n",\r\n__func__,\r\nbd->bd_disk->disk_name,\r\nbd->bd_block_size);\r\nout:\r\nkfree(msg->data);\r\nreturn rv;\r\n}\r\nstatic struct block_device *translate_devid(struct pnfs_layout_hdr *lo,\r\nstruct nfs4_deviceid *id)\r\n{\r\nstruct block_device *rv = NULL;\r\nstruct block_mount_id *mid;\r\nstruct pnfs_block_dev *dev;\r\ndprintk("%s enter, lo=%p, id=%p\n", __func__, lo, id);\r\nmid = BLK_ID(lo);\r\nspin_lock(&mid->bm_lock);\r\nlist_for_each_entry(dev, &mid->bm_devlist, bm_node) {\r\nif (memcmp(id->data, dev->bm_mdevid.data,\r\nNFS4_DEVICEID4_SIZE) == 0) {\r\nrv = dev->bm_mdev;\r\ngoto out;\r\n}\r\n}\r\nout:\r\nspin_unlock(&mid->bm_lock);\r\ndprintk("%s returning %p\n", __func__, rv);\r\nreturn rv;\r\n}\r\nstatic int verify_extent(struct pnfs_block_extent *be,\r\nstruct layout_verification *lv)\r\n{\r\nif (lv->mode == IOMODE_READ) {\r\nif (be->be_state == PNFS_BLOCK_READWRITE_DATA ||\r\nbe->be_state == PNFS_BLOCK_INVALID_DATA)\r\nreturn -EIO;\r\nif (be->be_f_offset != lv->start)\r\nreturn -EIO;\r\nlv->start += be->be_length;\r\nreturn 0;\r\n}\r\nif (be->be_state == PNFS_BLOCK_READWRITE_DATA) {\r\nif (be->be_f_offset != lv->start)\r\nreturn -EIO;\r\nif (lv->cowread > lv->start)\r\nreturn -EIO;\r\nlv->start += be->be_length;\r\nlv->inval = lv->start;\r\nreturn 0;\r\n} else if (be->be_state == PNFS_BLOCK_INVALID_DATA) {\r\nif (be->be_f_offset != lv->start)\r\nreturn -EIO;\r\nlv->start += be->be_length;\r\nreturn 0;\r\n} else if (be->be_state == PNFS_BLOCK_READ_DATA) {\r\nif (be->be_f_offset > lv->start)\r\nreturn -EIO;\r\nif (be->be_f_offset < lv->inval)\r\nreturn -EIO;\r\nif (be->be_f_offset < lv->cowread)\r\nreturn -EIO;\r\nlv->inval = lv->inval + be->be_length;\r\nlv->cowread = be->be_f_offset + be->be_length;\r\nreturn 0;\r\n} else\r\nreturn -EIO;\r\n}\r\nint\r\nnfs4_blk_process_layoutget(struct pnfs_layout_hdr *lo,\r\nstruct nfs4_layoutget_res *lgr, gfp_t gfp_flags)\r\n{\r\nstruct pnfs_block_layout *bl = BLK_LO2EXT(lo);\r\nint i, status = -EIO;\r\nuint32_t count;\r\nstruct pnfs_block_extent *be = NULL, *save;\r\nstruct xdr_stream stream;\r\nstruct xdr_buf buf;\r\nstruct page *scratch;\r\n__be32 *p;\r\nstruct layout_verification lv = {\r\n.mode = lgr->range.iomode,\r\n.start = lgr->range.offset >> SECTOR_SHIFT,\r\n.inval = lgr->range.offset >> SECTOR_SHIFT,\r\n.cowread = lgr->range.offset >> SECTOR_SHIFT,\r\n};\r\nLIST_HEAD(extents);\r\ndprintk("---> %s\n", __func__);\r\nscratch = alloc_page(gfp_flags);\r\nif (!scratch)\r\nreturn -ENOMEM;\r\nxdr_init_decode_pages(&stream, &buf, lgr->layoutp->pages, lgr->layoutp->len);\r\nxdr_set_scratch_buffer(&stream, page_address(scratch), PAGE_SIZE);\r\np = xdr_inline_decode(&stream, 4);\r\nif (unlikely(!p))\r\ngoto out_err;\r\ncount = be32_to_cpup(p++);\r\ndprintk("%s enter, number of extents %i\n", __func__, count);\r\np = xdr_inline_decode(&stream, (28 + NFS4_DEVICEID4_SIZE) * count);\r\nif (unlikely(!p))\r\ngoto out_err;\r\nfor (i = 0; i < count; i++) {\r\nbe = bl_alloc_extent();\r\nif (!be) {\r\nstatus = -ENOMEM;\r\ngoto out_err;\r\n}\r\nmemcpy(&be->be_devid, p, NFS4_DEVICEID4_SIZE);\r\np += XDR_QUADLEN(NFS4_DEVICEID4_SIZE);\r\nbe->be_mdev = translate_devid(lo, &be->be_devid);\r\nif (!be->be_mdev)\r\ngoto out_err;\r\nif (decode_sector_number(&p, &be->be_f_offset) < 0)\r\ngoto out_err;\r\nif (decode_sector_number(&p, &be->be_length) < 0)\r\ngoto out_err;\r\nif (decode_sector_number(&p, &be->be_v_offset) < 0)\r\ngoto out_err;\r\nbe->be_state = be32_to_cpup(p++);\r\nif (be->be_state == PNFS_BLOCK_INVALID_DATA)\r\nbe->be_inval = &bl->bl_inval;\r\nif (verify_extent(be, &lv)) {\r\ndprintk("%s verify failed\n", __func__);\r\ngoto out_err;\r\n}\r\nlist_add_tail(&be->be_node, &extents);\r\n}\r\nif (lgr->range.offset + lgr->range.length !=\r\nlv.start << SECTOR_SHIFT) {\r\ndprintk("%s Final length mismatch\n", __func__);\r\nbe = NULL;\r\ngoto out_err;\r\n}\r\nif (lv.start < lv.cowread) {\r\ndprintk("%s Final uncovered COW extent\n", __func__);\r\nbe = NULL;\r\ngoto out_err;\r\n}\r\nspin_lock(&bl->bl_ext_lock);\r\nlist_for_each_entry_safe(be, save, &extents, be_node) {\r\nlist_del(&be->be_node);\r\nstatus = bl_add_merge_extent(bl, be);\r\nif (status) {\r\nspin_unlock(&bl->bl_ext_lock);\r\nbe = NULL;\r\ngoto out_err;\r\n}\r\n}\r\nspin_unlock(&bl->bl_ext_lock);\r\nstatus = 0;\r\nout:\r\n__free_page(scratch);\r\ndprintk("%s returns %i\n", __func__, status);\r\nreturn status;\r\nout_err:\r\nbl_put_extent(be);\r\nwhile (!list_empty(&extents)) {\r\nbe = list_first_entry(&extents, struct pnfs_block_extent,\r\nbe_node);\r\nlist_del(&be->be_node);\r\nbl_put_extent(be);\r\n}\r\ngoto out;\r\n}
