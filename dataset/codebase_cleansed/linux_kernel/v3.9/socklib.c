size_t xdr_skb_read_bits(struct xdr_skb_reader *desc, void *to, size_t len)\r\n{\r\nif (len > desc->count)\r\nlen = desc->count;\r\nif (unlikely(skb_copy_bits(desc->skb, desc->offset, to, len)))\r\nreturn 0;\r\ndesc->count -= len;\r\ndesc->offset += len;\r\nreturn len;\r\n}\r\nstatic size_t xdr_skb_read_and_csum_bits(struct xdr_skb_reader *desc, void *to, size_t len)\r\n{\r\nunsigned int pos;\r\n__wsum csum2;\r\nif (len > desc->count)\r\nlen = desc->count;\r\npos = desc->offset;\r\ncsum2 = skb_copy_and_csum_bits(desc->skb, pos, to, len, 0);\r\ndesc->csum = csum_block_add(desc->csum, csum2, pos);\r\ndesc->count -= len;\r\ndesc->offset += len;\r\nreturn len;\r\n}\r\nssize_t xdr_partial_copy_from_skb(struct xdr_buf *xdr, unsigned int base, struct xdr_skb_reader *desc, xdr_skb_read_actor copy_actor)\r\n{\r\nstruct page **ppage = xdr->pages;\r\nunsigned int len, pglen = xdr->page_len;\r\nssize_t copied = 0;\r\nsize_t ret;\r\nlen = xdr->head[0].iov_len;\r\nif (base < len) {\r\nlen -= base;\r\nret = copy_actor(desc, (char *)xdr->head[0].iov_base + base, len);\r\ncopied += ret;\r\nif (ret != len || !desc->count)\r\ngoto out;\r\nbase = 0;\r\n} else\r\nbase -= len;\r\nif (unlikely(pglen == 0))\r\ngoto copy_tail;\r\nif (unlikely(base >= pglen)) {\r\nbase -= pglen;\r\ngoto copy_tail;\r\n}\r\nif (base || xdr->page_base) {\r\npglen -= base;\r\nbase += xdr->page_base;\r\nppage += base >> PAGE_CACHE_SHIFT;\r\nbase &= ~PAGE_CACHE_MASK;\r\n}\r\ndo {\r\nchar *kaddr;\r\nif (unlikely(*ppage == NULL)) {\r\n*ppage = alloc_page(GFP_ATOMIC);\r\nif (unlikely(*ppage == NULL)) {\r\nif (copied == 0)\r\ncopied = -ENOMEM;\r\ngoto out;\r\n}\r\n}\r\nlen = PAGE_CACHE_SIZE;\r\nkaddr = kmap_atomic(*ppage);\r\nif (base) {\r\nlen -= base;\r\nif (pglen < len)\r\nlen = pglen;\r\nret = copy_actor(desc, kaddr + base, len);\r\nbase = 0;\r\n} else {\r\nif (pglen < len)\r\nlen = pglen;\r\nret = copy_actor(desc, kaddr, len);\r\n}\r\nflush_dcache_page(*ppage);\r\nkunmap_atomic(kaddr);\r\ncopied += ret;\r\nif (ret != len || !desc->count)\r\ngoto out;\r\nppage++;\r\n} while ((pglen -= len) != 0);\r\ncopy_tail:\r\nlen = xdr->tail[0].iov_len;\r\nif (base < len)\r\ncopied += copy_actor(desc, (char *)xdr->tail[0].iov_base + base, len - base);\r\nout:\r\nreturn copied;\r\n}\r\nint csum_partial_copy_to_xdr(struct xdr_buf *xdr, struct sk_buff *skb)\r\n{\r\nstruct xdr_skb_reader desc;\r\ndesc.skb = skb;\r\ndesc.offset = sizeof(struct udphdr);\r\ndesc.count = skb->len - desc.offset;\r\nif (skb_csum_unnecessary(skb))\r\ngoto no_checksum;\r\ndesc.csum = csum_partial(skb->data, desc.offset, skb->csum);\r\nif (xdr_partial_copy_from_skb(xdr, 0, &desc, xdr_skb_read_and_csum_bits) < 0)\r\nreturn -1;\r\nif (desc.offset != skb->len) {\r\n__wsum csum2;\r\ncsum2 = skb_checksum(skb, desc.offset, skb->len - desc.offset, 0);\r\ndesc.csum = csum_block_add(desc.csum, csum2, desc.offset);\r\n}\r\nif (desc.count)\r\nreturn -1;\r\nif (csum_fold(desc.csum))\r\nreturn -1;\r\nif (unlikely(skb->ip_summed == CHECKSUM_COMPLETE))\r\nnetdev_rx_csum_fault(skb->dev);\r\nreturn 0;\r\nno_checksum:\r\nif (xdr_partial_copy_from_skb(xdr, 0, &desc, xdr_skb_read_bits) < 0)\r\nreturn -1;\r\nif (desc.count)\r\nreturn -1;\r\nreturn 0;\r\n}
