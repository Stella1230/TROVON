static struct page *xip_sparse_page(void)\r\n{\r\nif (!__xip_sparse_page) {\r\nstruct page *page = alloc_page(GFP_HIGHUSER | __GFP_ZERO);\r\nif (page)\r\n__xip_sparse_page = page;\r\n}\r\nreturn __xip_sparse_page;\r\n}\r\nstatic ssize_t\r\ndo_xip_mapping_read(struct address_space *mapping,\r\nstruct file_ra_state *_ra,\r\nstruct file *filp,\r\nchar __user *buf,\r\nsize_t len,\r\nloff_t *ppos)\r\n{\r\nstruct inode *inode = mapping->host;\r\npgoff_t index, end_index;\r\nunsigned long offset;\r\nloff_t isize, pos;\r\nsize_t copied = 0, error = 0;\r\nBUG_ON(!mapping->a_ops->get_xip_mem);\r\npos = *ppos;\r\nindex = pos >> PAGE_CACHE_SHIFT;\r\noffset = pos & ~PAGE_CACHE_MASK;\r\nisize = i_size_read(inode);\r\nif (!isize)\r\ngoto out;\r\nend_index = (isize - 1) >> PAGE_CACHE_SHIFT;\r\ndo {\r\nunsigned long nr, left;\r\nvoid *xip_mem;\r\nunsigned long xip_pfn;\r\nint zero = 0;\r\nnr = PAGE_CACHE_SIZE;\r\nif (index >= end_index) {\r\nif (index > end_index)\r\ngoto out;\r\nnr = ((isize - 1) & ~PAGE_CACHE_MASK) + 1;\r\nif (nr <= offset) {\r\ngoto out;\r\n}\r\n}\r\nnr = nr - offset;\r\nif (nr > len - copied)\r\nnr = len - copied;\r\nerror = mapping->a_ops->get_xip_mem(mapping, index, 0,\r\n&xip_mem, &xip_pfn);\r\nif (unlikely(error)) {\r\nif (error == -ENODATA) {\r\nzero = 1;\r\n} else\r\ngoto out;\r\n}\r\nif (mapping_writably_mapped(mapping))\r\n;\r\nif (!zero)\r\nleft = __copy_to_user(buf+copied, xip_mem+offset, nr);\r\nelse\r\nleft = __clear_user(buf + copied, nr);\r\nif (left) {\r\nerror = -EFAULT;\r\ngoto out;\r\n}\r\ncopied += (nr - left);\r\noffset += (nr - left);\r\nindex += offset >> PAGE_CACHE_SHIFT;\r\noffset &= ~PAGE_CACHE_MASK;\r\n} while (copied < len);\r\nout:\r\n*ppos = pos + copied;\r\nif (filp)\r\nfile_accessed(filp);\r\nreturn (copied ? copied : error);\r\n}\r\nssize_t\r\nxip_file_read(struct file *filp, char __user *buf, size_t len, loff_t *ppos)\r\n{\r\nif (!access_ok(VERIFY_WRITE, buf, len))\r\nreturn -EFAULT;\r\nreturn do_xip_mapping_read(filp->f_mapping, &filp->f_ra, filp,\r\nbuf, len, ppos);\r\n}\r\nstatic void\r\n__xip_unmap (struct address_space * mapping,\r\nunsigned long pgoff)\r\n{\r\nstruct vm_area_struct *vma;\r\nstruct mm_struct *mm;\r\nunsigned long address;\r\npte_t *pte;\r\npte_t pteval;\r\nspinlock_t *ptl;\r\nstruct page *page;\r\nunsigned count;\r\nint locked = 0;\r\ncount = read_seqcount_begin(&xip_sparse_seq);\r\npage = __xip_sparse_page;\r\nif (!page)\r\nreturn;\r\nretry:\r\nmutex_lock(&mapping->i_mmap_mutex);\r\nvma_interval_tree_foreach(vma, &mapping->i_mmap, pgoff, pgoff) {\r\nmm = vma->vm_mm;\r\naddress = vma->vm_start +\r\n((pgoff - vma->vm_pgoff) << PAGE_SHIFT);\r\nBUG_ON(address < vma->vm_start || address >= vma->vm_end);\r\npte = page_check_address(page, mm, address, &ptl, 1);\r\nif (pte) {\r\nflush_cache_page(vma, address, pte_pfn(*pte));\r\npteval = ptep_clear_flush(vma, address, pte);\r\npage_remove_rmap(page);\r\ndec_mm_counter(mm, MM_FILEPAGES);\r\nBUG_ON(pte_dirty(pteval));\r\npte_unmap_unlock(pte, ptl);\r\nmmu_notifier_invalidate_page(mm, address);\r\npage_cache_release(page);\r\n}\r\n}\r\nmutex_unlock(&mapping->i_mmap_mutex);\r\nif (locked) {\r\nmutex_unlock(&xip_sparse_mutex);\r\n} else if (read_seqcount_retry(&xip_sparse_seq, count)) {\r\nmutex_lock(&xip_sparse_mutex);\r\nlocked = 1;\r\ngoto retry;\r\n}\r\n}\r\nstatic int xip_file_fault(struct vm_area_struct *vma, struct vm_fault *vmf)\r\n{\r\nstruct file *file = vma->vm_file;\r\nstruct address_space *mapping = file->f_mapping;\r\nstruct inode *inode = mapping->host;\r\npgoff_t size;\r\nvoid *xip_mem;\r\nunsigned long xip_pfn;\r\nstruct page *page;\r\nint error;\r\nagain:\r\nsize = (i_size_read(inode) + PAGE_CACHE_SIZE - 1) >> PAGE_CACHE_SHIFT;\r\nif (vmf->pgoff >= size)\r\nreturn VM_FAULT_SIGBUS;\r\nerror = mapping->a_ops->get_xip_mem(mapping, vmf->pgoff, 0,\r\n&xip_mem, &xip_pfn);\r\nif (likely(!error))\r\ngoto found;\r\nif (error != -ENODATA)\r\nreturn VM_FAULT_OOM;\r\nif ((vma->vm_flags & (VM_WRITE | VM_MAYWRITE)) &&\r\n(vma->vm_flags & (VM_SHARED | VM_MAYSHARE)) &&\r\n(!(mapping->host->i_sb->s_flags & MS_RDONLY))) {\r\nint err;\r\nmutex_lock(&xip_sparse_mutex);\r\nerror = mapping->a_ops->get_xip_mem(mapping, vmf->pgoff, 1,\r\n&xip_mem, &xip_pfn);\r\nmutex_unlock(&xip_sparse_mutex);\r\nif (error)\r\nreturn VM_FAULT_SIGBUS;\r\n__xip_unmap(mapping, vmf->pgoff);\r\nfound:\r\nerr = vm_insert_mixed(vma, (unsigned long)vmf->virtual_address,\r\nxip_pfn);\r\nif (err == -ENOMEM)\r\nreturn VM_FAULT_OOM;\r\nif (err != -EBUSY)\r\nBUG_ON(err);\r\nreturn VM_FAULT_NOPAGE;\r\n} else {\r\nint err, ret = VM_FAULT_OOM;\r\nmutex_lock(&xip_sparse_mutex);\r\nwrite_seqcount_begin(&xip_sparse_seq);\r\nerror = mapping->a_ops->get_xip_mem(mapping, vmf->pgoff, 0,\r\n&xip_mem, &xip_pfn);\r\nif (unlikely(!error)) {\r\nwrite_seqcount_end(&xip_sparse_seq);\r\nmutex_unlock(&xip_sparse_mutex);\r\ngoto again;\r\n}\r\nif (error != -ENODATA)\r\ngoto out;\r\npage = xip_sparse_page();\r\nif (!page)\r\ngoto out;\r\nerr = vm_insert_page(vma, (unsigned long)vmf->virtual_address,\r\npage);\r\nif (err == -ENOMEM)\r\ngoto out;\r\nret = VM_FAULT_NOPAGE;\r\nout:\r\nwrite_seqcount_end(&xip_sparse_seq);\r\nmutex_unlock(&xip_sparse_mutex);\r\nreturn ret;\r\n}\r\n}\r\nint xip_file_mmap(struct file * file, struct vm_area_struct * vma)\r\n{\r\nBUG_ON(!file->f_mapping->a_ops->get_xip_mem);\r\nfile_accessed(file);\r\nvma->vm_ops = &xip_file_vm_ops;\r\nvma->vm_flags |= VM_MIXEDMAP;\r\nreturn 0;\r\n}\r\nstatic ssize_t\r\n__xip_file_write(struct file *filp, const char __user *buf,\r\nsize_t count, loff_t pos, loff_t *ppos)\r\n{\r\nstruct address_space * mapping = filp->f_mapping;\r\nconst struct address_space_operations *a_ops = mapping->a_ops;\r\nstruct inode *inode = mapping->host;\r\nlong status = 0;\r\nsize_t bytes;\r\nssize_t written = 0;\r\nBUG_ON(!mapping->a_ops->get_xip_mem);\r\ndo {\r\nunsigned long index;\r\nunsigned long offset;\r\nsize_t copied;\r\nvoid *xip_mem;\r\nunsigned long xip_pfn;\r\noffset = (pos & (PAGE_CACHE_SIZE -1));\r\nindex = pos >> PAGE_CACHE_SHIFT;\r\nbytes = PAGE_CACHE_SIZE - offset;\r\nif (bytes > count)\r\nbytes = count;\r\nstatus = a_ops->get_xip_mem(mapping, index, 0,\r\n&xip_mem, &xip_pfn);\r\nif (status == -ENODATA) {\r\nmutex_lock(&xip_sparse_mutex);\r\nstatus = a_ops->get_xip_mem(mapping, index, 1,\r\n&xip_mem, &xip_pfn);\r\nmutex_unlock(&xip_sparse_mutex);\r\nif (!status)\r\n__xip_unmap(mapping, index);\r\n}\r\nif (status)\r\nbreak;\r\ncopied = bytes -\r\n__copy_from_user_nocache(xip_mem + offset, buf, bytes);\r\nif (likely(copied > 0)) {\r\nstatus = copied;\r\nif (status >= 0) {\r\nwritten += status;\r\ncount -= status;\r\npos += status;\r\nbuf += status;\r\n}\r\n}\r\nif (unlikely(copied != bytes))\r\nif (status >= 0)\r\nstatus = -EFAULT;\r\nif (status < 0)\r\nbreak;\r\n} while (count);\r\n*ppos = pos;\r\nif (pos > inode->i_size) {\r\ni_size_write(inode, pos);\r\nmark_inode_dirty(inode);\r\n}\r\nreturn written ? written : status;\r\n}\r\nssize_t\r\nxip_file_write(struct file *filp, const char __user *buf, size_t len,\r\nloff_t *ppos)\r\n{\r\nstruct address_space *mapping = filp->f_mapping;\r\nstruct inode *inode = mapping->host;\r\nsize_t count;\r\nloff_t pos;\r\nssize_t ret;\r\nsb_start_write(inode->i_sb);\r\nmutex_lock(&inode->i_mutex);\r\nif (!access_ok(VERIFY_READ, buf, len)) {\r\nret=-EFAULT;\r\ngoto out_up;\r\n}\r\npos = *ppos;\r\ncount = len;\r\ncurrent->backing_dev_info = mapping->backing_dev_info;\r\nret = generic_write_checks(filp, &pos, &count, S_ISBLK(inode->i_mode));\r\nif (ret)\r\ngoto out_backing;\r\nif (count == 0)\r\ngoto out_backing;\r\nret = file_remove_suid(filp);\r\nif (ret)\r\ngoto out_backing;\r\nret = file_update_time(filp);\r\nif (ret)\r\ngoto out_backing;\r\nret = __xip_file_write (filp, buf, count, pos, ppos);\r\nout_backing:\r\ncurrent->backing_dev_info = NULL;\r\nout_up:\r\nmutex_unlock(&inode->i_mutex);\r\nsb_end_write(inode->i_sb);\r\nreturn ret;\r\n}\r\nint\r\nxip_truncate_page(struct address_space *mapping, loff_t from)\r\n{\r\npgoff_t index = from >> PAGE_CACHE_SHIFT;\r\nunsigned offset = from & (PAGE_CACHE_SIZE-1);\r\nunsigned blocksize;\r\nunsigned length;\r\nvoid *xip_mem;\r\nunsigned long xip_pfn;\r\nint err;\r\nBUG_ON(!mapping->a_ops->get_xip_mem);\r\nblocksize = 1 << mapping->host->i_blkbits;\r\nlength = offset & (blocksize - 1);\r\nif (!length)\r\nreturn 0;\r\nlength = blocksize - length;\r\nerr = mapping->a_ops->get_xip_mem(mapping, index, 0,\r\n&xip_mem, &xip_pfn);\r\nif (unlikely(err)) {\r\nif (err == -ENODATA)\r\nreturn 0;\r\nelse\r\nreturn err;\r\n}\r\nmemset(xip_mem + offset, 0, length);\r\nreturn 0;\r\n}
