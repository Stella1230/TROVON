static int __readahead_hook(struct btrfs_root *root, struct extent_buffer *eb,\r\nu64 start, int err)\r\n{\r\nint level = 0;\r\nint nritems;\r\nint i;\r\nu64 bytenr;\r\nu64 generation;\r\nstruct reada_extent *re;\r\nstruct btrfs_fs_info *fs_info = root->fs_info;\r\nstruct list_head list;\r\nunsigned long index = start >> PAGE_CACHE_SHIFT;\r\nstruct btrfs_device *for_dev;\r\nif (eb)\r\nlevel = btrfs_header_level(eb);\r\nspin_lock(&fs_info->reada_lock);\r\nre = radix_tree_lookup(&fs_info->reada_tree, index);\r\nif (re)\r\nre->refcnt++;\r\nspin_unlock(&fs_info->reada_lock);\r\nif (!re)\r\nreturn -1;\r\nspin_lock(&re->lock);\r\nlist_replace_init(&re->extctl, &list);\r\nfor_dev = re->scheduled_for;\r\nre->scheduled_for = NULL;\r\nspin_unlock(&re->lock);\r\nif (err == 0) {\r\nnritems = level ? btrfs_header_nritems(eb) : 0;\r\ngeneration = btrfs_header_generation(eb);\r\n} else {\r\nnritems = 0;\r\ngeneration = 0;\r\n}\r\nfor (i = 0; i < nritems; i++) {\r\nstruct reada_extctl *rec;\r\nu64 n_gen;\r\nstruct btrfs_key key;\r\nstruct btrfs_key next_key;\r\nbtrfs_node_key_to_cpu(eb, &key, i);\r\nif (i + 1 < nritems)\r\nbtrfs_node_key_to_cpu(eb, &next_key, i + 1);\r\nelse\r\nnext_key = re->top;\r\nbytenr = btrfs_node_blockptr(eb, i);\r\nn_gen = btrfs_node_ptr_generation(eb, i);\r\nlist_for_each_entry(rec, &list, list) {\r\nstruct reada_control *rc = rec->rc;\r\n#ifdef DEBUG\r\nif (rec->generation != generation) {\r\nprintk(KERN_DEBUG "generation mismatch for "\r\n"(%llu,%d,%llu) %llu != %llu\n",\r\nkey.objectid, key.type, key.offset,\r\nrec->generation, generation);\r\n}\r\n#endif\r\nif (rec->generation == generation &&\r\nbtrfs_comp_cpu_keys(&key, &rc->key_end) < 0 &&\r\nbtrfs_comp_cpu_keys(&next_key, &rc->key_start) > 0)\r\nreada_add_block(rc, bytenr, &next_key,\r\nlevel - 1, n_gen);\r\n}\r\n}\r\nwhile (!list_empty(&list)) {\r\nstruct reada_control *rc;\r\nstruct reada_extctl *rec;\r\nrec = list_first_entry(&list, struct reada_extctl, list);\r\nlist_del(&rec->list);\r\nrc = rec->rc;\r\nkfree(rec);\r\nkref_get(&rc->refcnt);\r\nif (atomic_dec_and_test(&rc->elems)) {\r\nkref_put(&rc->refcnt, reada_control_release);\r\nwake_up(&rc->wait);\r\n}\r\nkref_put(&rc->refcnt, reada_control_release);\r\nreada_extent_put(fs_info, re);\r\n}\r\nreada_extent_put(fs_info, re);\r\nif (for_dev)\r\natomic_dec(&for_dev->reada_in_flight);\r\nreturn 0;\r\n}\r\nint btree_readahead_hook(struct btrfs_root *root, struct extent_buffer *eb,\r\nu64 start, int err)\r\n{\r\nint ret;\r\nret = __readahead_hook(root, eb, start, err);\r\nreada_start_machine(root->fs_info);\r\nreturn ret;\r\n}\r\nstatic struct reada_zone *reada_find_zone(struct btrfs_fs_info *fs_info,\r\nstruct btrfs_device *dev, u64 logical,\r\nstruct btrfs_bio *bbio)\r\n{\r\nint ret;\r\nstruct reada_zone *zone;\r\nstruct btrfs_block_group_cache *cache = NULL;\r\nu64 start;\r\nu64 end;\r\nint i;\r\nzone = NULL;\r\nspin_lock(&fs_info->reada_lock);\r\nret = radix_tree_gang_lookup(&dev->reada_zones, (void **)&zone,\r\nlogical >> PAGE_CACHE_SHIFT, 1);\r\nif (ret == 1)\r\nkref_get(&zone->refcnt);\r\nspin_unlock(&fs_info->reada_lock);\r\nif (ret == 1) {\r\nif (logical >= zone->start && logical < zone->end)\r\nreturn zone;\r\nspin_lock(&fs_info->reada_lock);\r\nkref_put(&zone->refcnt, reada_zone_release);\r\nspin_unlock(&fs_info->reada_lock);\r\n}\r\ncache = btrfs_lookup_block_group(fs_info, logical);\r\nif (!cache)\r\nreturn NULL;\r\nstart = cache->key.objectid;\r\nend = start + cache->key.offset - 1;\r\nbtrfs_put_block_group(cache);\r\nzone = kzalloc(sizeof(*zone), GFP_NOFS);\r\nif (!zone)\r\nreturn NULL;\r\nzone->start = start;\r\nzone->end = end;\r\nINIT_LIST_HEAD(&zone->list);\r\nspin_lock_init(&zone->lock);\r\nzone->locked = 0;\r\nkref_init(&zone->refcnt);\r\nzone->elems = 0;\r\nzone->device = dev;\r\nfor (i = 0; i < bbio->num_stripes; ++i) {\r\nzone->devs[i] = bbio->stripes[i].dev;\r\n}\r\nzone->ndevs = bbio->num_stripes;\r\nspin_lock(&fs_info->reada_lock);\r\nret = radix_tree_insert(&dev->reada_zones,\r\n(unsigned long)(zone->end >> PAGE_CACHE_SHIFT),\r\nzone);\r\nif (ret == -EEXIST) {\r\nkfree(zone);\r\nret = radix_tree_gang_lookup(&dev->reada_zones, (void **)&zone,\r\nlogical >> PAGE_CACHE_SHIFT, 1);\r\nif (ret == 1)\r\nkref_get(&zone->refcnt);\r\n}\r\nspin_unlock(&fs_info->reada_lock);\r\nreturn zone;\r\n}\r\nstatic struct reada_extent *reada_find_extent(struct btrfs_root *root,\r\nu64 logical,\r\nstruct btrfs_key *top, int level)\r\n{\r\nint ret;\r\nstruct reada_extent *re = NULL;\r\nstruct reada_extent *re_exist = NULL;\r\nstruct btrfs_fs_info *fs_info = root->fs_info;\r\nstruct btrfs_bio *bbio = NULL;\r\nstruct btrfs_device *dev;\r\nstruct btrfs_device *prev_dev;\r\nu32 blocksize;\r\nu64 length;\r\nint nzones = 0;\r\nint i;\r\nunsigned long index = logical >> PAGE_CACHE_SHIFT;\r\nint dev_replace_is_ongoing;\r\nspin_lock(&fs_info->reada_lock);\r\nre = radix_tree_lookup(&fs_info->reada_tree, index);\r\nif (re)\r\nre->refcnt++;\r\nspin_unlock(&fs_info->reada_lock);\r\nif (re)\r\nreturn re;\r\nre = kzalloc(sizeof(*re), GFP_NOFS);\r\nif (!re)\r\nreturn NULL;\r\nblocksize = btrfs_level_size(root, level);\r\nre->logical = logical;\r\nre->blocksize = blocksize;\r\nre->top = *top;\r\nINIT_LIST_HEAD(&re->extctl);\r\nspin_lock_init(&re->lock);\r\nre->refcnt = 1;\r\nlength = blocksize;\r\nret = btrfs_map_block(fs_info, REQ_GET_READ_MIRRORS, logical, &length,\r\n&bbio, 0);\r\nif (ret || !bbio || length < blocksize)\r\ngoto error;\r\nif (bbio->num_stripes > BTRFS_MAX_MIRRORS) {\r\nprintk(KERN_ERR "btrfs readahead: more than %d copies not "\r\n"supported", BTRFS_MAX_MIRRORS);\r\ngoto error;\r\n}\r\nfor (nzones = 0; nzones < bbio->num_stripes; ++nzones) {\r\nstruct reada_zone *zone;\r\ndev = bbio->stripes[nzones].dev;\r\nzone = reada_find_zone(fs_info, dev, logical, bbio);\r\nif (!zone)\r\nbreak;\r\nre->zones[nzones] = zone;\r\nspin_lock(&zone->lock);\r\nif (!zone->elems)\r\nkref_get(&zone->refcnt);\r\n++zone->elems;\r\nspin_unlock(&zone->lock);\r\nspin_lock(&fs_info->reada_lock);\r\nkref_put(&zone->refcnt, reada_zone_release);\r\nspin_unlock(&fs_info->reada_lock);\r\n}\r\nre->nzones = nzones;\r\nif (nzones == 0) {\r\ngoto error;\r\n}\r\nbtrfs_dev_replace_lock(&fs_info->dev_replace);\r\nspin_lock(&fs_info->reada_lock);\r\nret = radix_tree_insert(&fs_info->reada_tree, index, re);\r\nif (ret == -EEXIST) {\r\nre_exist = radix_tree_lookup(&fs_info->reada_tree, index);\r\nBUG_ON(!re_exist);\r\nre_exist->refcnt++;\r\nspin_unlock(&fs_info->reada_lock);\r\nbtrfs_dev_replace_unlock(&fs_info->dev_replace);\r\ngoto error;\r\n}\r\nif (ret) {\r\nspin_unlock(&fs_info->reada_lock);\r\nbtrfs_dev_replace_unlock(&fs_info->dev_replace);\r\ngoto error;\r\n}\r\nprev_dev = NULL;\r\ndev_replace_is_ongoing = btrfs_dev_replace_is_ongoing(\r\n&fs_info->dev_replace);\r\nfor (i = 0; i < nzones; ++i) {\r\ndev = bbio->stripes[i].dev;\r\nif (dev == prev_dev) {\r\ncontinue;\r\n}\r\nif (!dev->bdev) {\r\ncontinue;\r\n}\r\nif (dev_replace_is_ongoing &&\r\ndev == fs_info->dev_replace.tgtdev) {\r\ncontinue;\r\n}\r\nprev_dev = dev;\r\nret = radix_tree_insert(&dev->reada_extents, index, re);\r\nif (ret) {\r\nwhile (--i >= 0) {\r\ndev = bbio->stripes[i].dev;\r\nBUG_ON(dev == NULL);\r\nradix_tree_delete(&dev->reada_extents, index);\r\n}\r\nBUG_ON(fs_info == NULL);\r\nradix_tree_delete(&fs_info->reada_tree, index);\r\nspin_unlock(&fs_info->reada_lock);\r\nbtrfs_dev_replace_unlock(&fs_info->dev_replace);\r\ngoto error;\r\n}\r\n}\r\nspin_unlock(&fs_info->reada_lock);\r\nbtrfs_dev_replace_unlock(&fs_info->dev_replace);\r\nkfree(bbio);\r\nreturn re;\r\nerror:\r\nwhile (nzones) {\r\nstruct reada_zone *zone;\r\n--nzones;\r\nzone = re->zones[nzones];\r\nkref_get(&zone->refcnt);\r\nspin_lock(&zone->lock);\r\n--zone->elems;\r\nif (zone->elems == 0) {\r\nkref_put(&zone->refcnt, reada_zone_release);\r\n}\r\nspin_unlock(&zone->lock);\r\nspin_lock(&fs_info->reada_lock);\r\nkref_put(&zone->refcnt, reada_zone_release);\r\nspin_unlock(&fs_info->reada_lock);\r\n}\r\nkfree(bbio);\r\nkfree(re);\r\nreturn re_exist;\r\n}\r\nstatic void reada_extent_put(struct btrfs_fs_info *fs_info,\r\nstruct reada_extent *re)\r\n{\r\nint i;\r\nunsigned long index = re->logical >> PAGE_CACHE_SHIFT;\r\nspin_lock(&fs_info->reada_lock);\r\nif (--re->refcnt) {\r\nspin_unlock(&fs_info->reada_lock);\r\nreturn;\r\n}\r\nradix_tree_delete(&fs_info->reada_tree, index);\r\nfor (i = 0; i < re->nzones; ++i) {\r\nstruct reada_zone *zone = re->zones[i];\r\nradix_tree_delete(&zone->device->reada_extents, index);\r\n}\r\nspin_unlock(&fs_info->reada_lock);\r\nfor (i = 0; i < re->nzones; ++i) {\r\nstruct reada_zone *zone = re->zones[i];\r\nkref_get(&zone->refcnt);\r\nspin_lock(&zone->lock);\r\n--zone->elems;\r\nif (zone->elems == 0) {\r\nkref_put(&zone->refcnt, reada_zone_release);\r\n}\r\nspin_unlock(&zone->lock);\r\nspin_lock(&fs_info->reada_lock);\r\nkref_put(&zone->refcnt, reada_zone_release);\r\nspin_unlock(&fs_info->reada_lock);\r\n}\r\nif (re->scheduled_for)\r\natomic_dec(&re->scheduled_for->reada_in_flight);\r\nkfree(re);\r\n}\r\nstatic void reada_zone_release(struct kref *kref)\r\n{\r\nstruct reada_zone *zone = container_of(kref, struct reada_zone, refcnt);\r\nradix_tree_delete(&zone->device->reada_zones,\r\nzone->end >> PAGE_CACHE_SHIFT);\r\nkfree(zone);\r\n}\r\nstatic void reada_control_release(struct kref *kref)\r\n{\r\nstruct reada_control *rc = container_of(kref, struct reada_control,\r\nrefcnt);\r\nkfree(rc);\r\n}\r\nstatic int reada_add_block(struct reada_control *rc, u64 logical,\r\nstruct btrfs_key *top, int level, u64 generation)\r\n{\r\nstruct btrfs_root *root = rc->root;\r\nstruct reada_extent *re;\r\nstruct reada_extctl *rec;\r\nre = reada_find_extent(root, logical, top, level);\r\nif (!re)\r\nreturn -1;\r\nrec = kzalloc(sizeof(*rec), GFP_NOFS);\r\nif (!rec) {\r\nreada_extent_put(root->fs_info, re);\r\nreturn -1;\r\n}\r\nrec->rc = rc;\r\nrec->generation = generation;\r\natomic_inc(&rc->elems);\r\nspin_lock(&re->lock);\r\nlist_add_tail(&rec->list, &re->extctl);\r\nspin_unlock(&re->lock);\r\nreturn 0;\r\n}\r\nstatic void reada_peer_zones_set_lock(struct reada_zone *zone, int lock)\r\n{\r\nint i;\r\nunsigned long index = zone->end >> PAGE_CACHE_SHIFT;\r\nfor (i = 0; i < zone->ndevs; ++i) {\r\nstruct reada_zone *peer;\r\npeer = radix_tree_lookup(&zone->devs[i]->reada_zones, index);\r\nif (peer && peer->device != zone->device)\r\npeer->locked = lock;\r\n}\r\n}\r\nstatic int reada_pick_zone(struct btrfs_device *dev)\r\n{\r\nstruct reada_zone *top_zone = NULL;\r\nstruct reada_zone *top_locked_zone = NULL;\r\nu64 top_elems = 0;\r\nu64 top_locked_elems = 0;\r\nunsigned long index = 0;\r\nint ret;\r\nif (dev->reada_curr_zone) {\r\nreada_peer_zones_set_lock(dev->reada_curr_zone, 0);\r\nkref_put(&dev->reada_curr_zone->refcnt, reada_zone_release);\r\ndev->reada_curr_zone = NULL;\r\n}\r\nwhile (1) {\r\nstruct reada_zone *zone;\r\nret = radix_tree_gang_lookup(&dev->reada_zones,\r\n(void **)&zone, index, 1);\r\nif (ret == 0)\r\nbreak;\r\nindex = (zone->end >> PAGE_CACHE_SHIFT) + 1;\r\nif (zone->locked) {\r\nif (zone->elems > top_locked_elems) {\r\ntop_locked_elems = zone->elems;\r\ntop_locked_zone = zone;\r\n}\r\n} else {\r\nif (zone->elems > top_elems) {\r\ntop_elems = zone->elems;\r\ntop_zone = zone;\r\n}\r\n}\r\n}\r\nif (top_zone)\r\ndev->reada_curr_zone = top_zone;\r\nelse if (top_locked_zone)\r\ndev->reada_curr_zone = top_locked_zone;\r\nelse\r\nreturn 0;\r\ndev->reada_next = dev->reada_curr_zone->start;\r\nkref_get(&dev->reada_curr_zone->refcnt);\r\nreada_peer_zones_set_lock(dev->reada_curr_zone, 1);\r\nreturn 1;\r\n}\r\nstatic int reada_start_machine_dev(struct btrfs_fs_info *fs_info,\r\nstruct btrfs_device *dev)\r\n{\r\nstruct reada_extent *re = NULL;\r\nint mirror_num = 0;\r\nstruct extent_buffer *eb = NULL;\r\nu64 logical;\r\nu32 blocksize;\r\nint ret;\r\nint i;\r\nint need_kick = 0;\r\nspin_lock(&fs_info->reada_lock);\r\nif (dev->reada_curr_zone == NULL) {\r\nret = reada_pick_zone(dev);\r\nif (!ret) {\r\nspin_unlock(&fs_info->reada_lock);\r\nreturn 0;\r\n}\r\n}\r\nret = radix_tree_gang_lookup(&dev->reada_extents, (void **)&re,\r\ndev->reada_next >> PAGE_CACHE_SHIFT, 1);\r\nif (ret == 0 || re->logical >= dev->reada_curr_zone->end) {\r\nret = reada_pick_zone(dev);\r\nif (!ret) {\r\nspin_unlock(&fs_info->reada_lock);\r\nreturn 0;\r\n}\r\nre = NULL;\r\nret = radix_tree_gang_lookup(&dev->reada_extents, (void **)&re,\r\ndev->reada_next >> PAGE_CACHE_SHIFT, 1);\r\n}\r\nif (ret == 0) {\r\nspin_unlock(&fs_info->reada_lock);\r\nreturn 0;\r\n}\r\ndev->reada_next = re->logical + re->blocksize;\r\nre->refcnt++;\r\nspin_unlock(&fs_info->reada_lock);\r\nfor (i = 0; i < re->nzones; ++i) {\r\nif (re->zones[i]->device == dev) {\r\nmirror_num = i + 1;\r\nbreak;\r\n}\r\n}\r\nlogical = re->logical;\r\nblocksize = re->blocksize;\r\nspin_lock(&re->lock);\r\nif (re->scheduled_for == NULL) {\r\nre->scheduled_for = dev;\r\nneed_kick = 1;\r\n}\r\nspin_unlock(&re->lock);\r\nreada_extent_put(fs_info, re);\r\nif (!need_kick)\r\nreturn 0;\r\natomic_inc(&dev->reada_in_flight);\r\nret = reada_tree_block_flagged(fs_info->extent_root, logical, blocksize,\r\nmirror_num, &eb);\r\nif (ret)\r\n__readahead_hook(fs_info->extent_root, NULL, logical, ret);\r\nelse if (eb)\r\n__readahead_hook(fs_info->extent_root, eb, eb->start, ret);\r\nif (eb)\r\nfree_extent_buffer(eb);\r\nreturn 1;\r\n}\r\nstatic void reada_start_machine_worker(struct btrfs_work *work)\r\n{\r\nstruct reada_machine_work *rmw;\r\nstruct btrfs_fs_info *fs_info;\r\nint old_ioprio;\r\nrmw = container_of(work, struct reada_machine_work, work);\r\nfs_info = rmw->fs_info;\r\nkfree(rmw);\r\nold_ioprio = IOPRIO_PRIO_VALUE(task_nice_ioclass(current),\r\ntask_nice_ioprio(current));\r\nset_task_ioprio(current, BTRFS_IOPRIO_READA);\r\n__reada_start_machine(fs_info);\r\nset_task_ioprio(current, old_ioprio);\r\n}\r\nstatic void __reada_start_machine(struct btrfs_fs_info *fs_info)\r\n{\r\nstruct btrfs_device *device;\r\nstruct btrfs_fs_devices *fs_devices = fs_info->fs_devices;\r\nu64 enqueued;\r\nu64 total = 0;\r\nint i;\r\ndo {\r\nenqueued = 0;\r\nlist_for_each_entry(device, &fs_devices->devices, dev_list) {\r\nif (atomic_read(&device->reada_in_flight) <\r\nMAX_IN_FLIGHT)\r\nenqueued += reada_start_machine_dev(fs_info,\r\ndevice);\r\n}\r\ntotal += enqueued;\r\n} while (enqueued && total < 10000);\r\nif (enqueued == 0)\r\nreturn;\r\nfor (i = 0; i < 2; ++i)\r\nreada_start_machine(fs_info);\r\n}\r\nstatic void reada_start_machine(struct btrfs_fs_info *fs_info)\r\n{\r\nstruct reada_machine_work *rmw;\r\nrmw = kzalloc(sizeof(*rmw), GFP_NOFS);\r\nif (!rmw) {\r\nBUG();\r\n}\r\nrmw->work.func = reada_start_machine_worker;\r\nrmw->fs_info = fs_info;\r\nbtrfs_queue_worker(&fs_info->readahead_workers, &rmw->work);\r\n}\r\nstatic void dump_devs(struct btrfs_fs_info *fs_info, int all)\r\n{\r\nstruct btrfs_device *device;\r\nstruct btrfs_fs_devices *fs_devices = fs_info->fs_devices;\r\nunsigned long index;\r\nint ret;\r\nint i;\r\nint j;\r\nint cnt;\r\nspin_lock(&fs_info->reada_lock);\r\nlist_for_each_entry(device, &fs_devices->devices, dev_list) {\r\nprintk(KERN_DEBUG "dev %lld has %d in flight\n", device->devid,\r\natomic_read(&device->reada_in_flight));\r\nindex = 0;\r\nwhile (1) {\r\nstruct reada_zone *zone;\r\nret = radix_tree_gang_lookup(&device->reada_zones,\r\n(void **)&zone, index, 1);\r\nif (ret == 0)\r\nbreak;\r\nprintk(KERN_DEBUG " zone %llu-%llu elems %llu locked "\r\n"%d devs", zone->start, zone->end, zone->elems,\r\nzone->locked);\r\nfor (j = 0; j < zone->ndevs; ++j) {\r\nprintk(KERN_CONT " %lld",\r\nzone->devs[j]->devid);\r\n}\r\nif (device->reada_curr_zone == zone)\r\nprintk(KERN_CONT " curr off %llu",\r\ndevice->reada_next - zone->start);\r\nprintk(KERN_CONT "\n");\r\nindex = (zone->end >> PAGE_CACHE_SHIFT) + 1;\r\n}\r\ncnt = 0;\r\nindex = 0;\r\nwhile (all) {\r\nstruct reada_extent *re = NULL;\r\nret = radix_tree_gang_lookup(&device->reada_extents,\r\n(void **)&re, index, 1);\r\nif (ret == 0)\r\nbreak;\r\nprintk(KERN_DEBUG\r\n" re: logical %llu size %u empty %d for %lld",\r\nre->logical, re->blocksize,\r\nlist_empty(&re->extctl), re->scheduled_for ?\r\nre->scheduled_for->devid : -1);\r\nfor (i = 0; i < re->nzones; ++i) {\r\nprintk(KERN_CONT " zone %llu-%llu devs",\r\nre->zones[i]->start,\r\nre->zones[i]->end);\r\nfor (j = 0; j < re->zones[i]->ndevs; ++j) {\r\nprintk(KERN_CONT " %lld",\r\nre->zones[i]->devs[j]->devid);\r\n}\r\n}\r\nprintk(KERN_CONT "\n");\r\nindex = (re->logical >> PAGE_CACHE_SHIFT) + 1;\r\nif (++cnt > 15)\r\nbreak;\r\n}\r\n}\r\nindex = 0;\r\ncnt = 0;\r\nwhile (all) {\r\nstruct reada_extent *re = NULL;\r\nret = radix_tree_gang_lookup(&fs_info->reada_tree, (void **)&re,\r\nindex, 1);\r\nif (ret == 0)\r\nbreak;\r\nif (!re->scheduled_for) {\r\nindex = (re->logical >> PAGE_CACHE_SHIFT) + 1;\r\ncontinue;\r\n}\r\nprintk(KERN_DEBUG\r\n"re: logical %llu size %u list empty %d for %lld",\r\nre->logical, re->blocksize, list_empty(&re->extctl),\r\nre->scheduled_for ? re->scheduled_for->devid : -1);\r\nfor (i = 0; i < re->nzones; ++i) {\r\nprintk(KERN_CONT " zone %llu-%llu devs",\r\nre->zones[i]->start,\r\nre->zones[i]->end);\r\nfor (i = 0; i < re->nzones; ++i) {\r\nprintk(KERN_CONT " zone %llu-%llu devs",\r\nre->zones[i]->start,\r\nre->zones[i]->end);\r\nfor (j = 0; j < re->zones[i]->ndevs; ++j) {\r\nprintk(KERN_CONT " %lld",\r\nre->zones[i]->devs[j]->devid);\r\n}\r\n}\r\n}\r\nprintk(KERN_CONT "\n");\r\nindex = (re->logical >> PAGE_CACHE_SHIFT) + 1;\r\n}\r\nspin_unlock(&fs_info->reada_lock);\r\n}\r\nstruct reada_control *btrfs_reada_add(struct btrfs_root *root,\r\nstruct btrfs_key *key_start, struct btrfs_key *key_end)\r\n{\r\nstruct reada_control *rc;\r\nu64 start;\r\nu64 generation;\r\nint level;\r\nstruct extent_buffer *node;\r\nstatic struct btrfs_key max_key = {\r\n.objectid = (u64)-1,\r\n.type = (u8)-1,\r\n.offset = (u64)-1\r\n};\r\nrc = kzalloc(sizeof(*rc), GFP_NOFS);\r\nif (!rc)\r\nreturn ERR_PTR(-ENOMEM);\r\nrc->root = root;\r\nrc->key_start = *key_start;\r\nrc->key_end = *key_end;\r\natomic_set(&rc->elems, 0);\r\ninit_waitqueue_head(&rc->wait);\r\nkref_init(&rc->refcnt);\r\nkref_get(&rc->refcnt);\r\nnode = btrfs_root_node(root);\r\nstart = node->start;\r\nlevel = btrfs_header_level(node);\r\ngeneration = btrfs_header_generation(node);\r\nfree_extent_buffer(node);\r\nif (reada_add_block(rc, start, &max_key, level, generation)) {\r\nkfree(rc);\r\nreturn ERR_PTR(-ENOMEM);\r\n}\r\nreada_start_machine(root->fs_info);\r\nreturn rc;\r\n}\r\nint btrfs_reada_wait(void *handle)\r\n{\r\nstruct reada_control *rc = handle;\r\nwhile (atomic_read(&rc->elems)) {\r\nwait_event_timeout(rc->wait, atomic_read(&rc->elems) == 0,\r\n5 * HZ);\r\ndump_devs(rc->root->fs_info, rc->elems < 10 ? 1 : 0);\r\n}\r\ndump_devs(rc->root->fs_info, rc->elems < 10 ? 1 : 0);\r\nkref_put(&rc->refcnt, reada_control_release);\r\nreturn 0;\r\n}\r\nint btrfs_reada_wait(void *handle)\r\n{\r\nstruct reada_control *rc = handle;\r\nwhile (atomic_read(&rc->elems)) {\r\nwait_event(rc->wait, atomic_read(&rc->elems) == 0);\r\n}\r\nkref_put(&rc->refcnt, reada_control_release);\r\nreturn 0;\r\n}\r\nvoid btrfs_reada_detach(void *handle)\r\n{\r\nstruct reada_control *rc = handle;\r\nkref_put(&rc->refcnt, reada_control_release);\r\n}
