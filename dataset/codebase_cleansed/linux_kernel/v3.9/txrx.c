static inline u8 ath6kl_get_tid(u8 tid_mux)\r\n{\r\nreturn tid_mux & ATH6KL_TID_MASK;\r\n}\r\nstatic inline u8 ath6kl_get_aid(u8 tid_mux)\r\n{\r\nreturn tid_mux >> ATH6KL_AID_SHIFT;\r\n}\r\nstatic u8 ath6kl_ibss_map_epid(struct sk_buff *skb, struct net_device *dev,\r\nu32 *map_no)\r\n{\r\nstruct ath6kl *ar = ath6kl_priv(dev);\r\nstruct ethhdr *eth_hdr;\r\nu32 i, ep_map = -1;\r\nu8 *datap;\r\n*map_no = 0;\r\ndatap = skb->data;\r\neth_hdr = (struct ethhdr *) (datap + sizeof(struct wmi_data_hdr));\r\nif (is_multicast_ether_addr(eth_hdr->h_dest))\r\nreturn ENDPOINT_2;\r\nfor (i = 0; i < ar->node_num; i++) {\r\nif (memcmp(eth_hdr->h_dest, ar->node_map[i].mac_addr,\r\nETH_ALEN) == 0) {\r\n*map_no = i + 1;\r\nar->node_map[i].tx_pend++;\r\nreturn ar->node_map[i].ep_id;\r\n}\r\nif ((ep_map == -1) && !ar->node_map[i].tx_pend)\r\nep_map = i;\r\n}\r\nif (ep_map == -1) {\r\nep_map = ar->node_num;\r\nar->node_num++;\r\nif (ar->node_num > MAX_NODE_NUM)\r\nreturn ENDPOINT_UNUSED;\r\n}\r\nmemcpy(ar->node_map[ep_map].mac_addr, eth_hdr->h_dest, ETH_ALEN);\r\nfor (i = ENDPOINT_2; i <= ENDPOINT_5; i++) {\r\nif (!ar->tx_pending[i]) {\r\nar->node_map[ep_map].ep_id = i;\r\nbreak;\r\n}\r\nif (i == ENDPOINT_5) {\r\nar->node_map[ep_map].ep_id = ar->next_ep_id;\r\nar->next_ep_id++;\r\nif (ar->next_ep_id > ENDPOINT_5)\r\nar->next_ep_id = ENDPOINT_2;\r\n}\r\n}\r\n*map_no = ep_map + 1;\r\nar->node_map[ep_map].tx_pend++;\r\nreturn ar->node_map[ep_map].ep_id;\r\n}\r\nstatic bool ath6kl_process_uapsdq(struct ath6kl_sta *conn,\r\nstruct ath6kl_vif *vif,\r\nstruct sk_buff *skb,\r\nu32 *flags)\r\n{\r\nstruct ath6kl *ar = vif->ar;\r\nbool is_apsdq_empty = false;\r\nstruct ethhdr *datap = (struct ethhdr *) skb->data;\r\nu8 up = 0, traffic_class, *ip_hdr;\r\nu16 ether_type;\r\nstruct ath6kl_llc_snap_hdr *llc_hdr;\r\nif (conn->sta_flags & STA_PS_APSD_TRIGGER) {\r\nspin_lock_bh(&conn->psq_lock);\r\nif (!skb_queue_empty(&conn->apsdq))\r\n*flags |= WMI_DATA_HDR_FLAGS_MORE;\r\nelse if (conn->sta_flags & STA_PS_APSD_EOSP)\r\n*flags |= WMI_DATA_HDR_FLAGS_EOSP;\r\n*flags |= WMI_DATA_HDR_FLAGS_UAPSD;\r\nspin_unlock_bh(&conn->psq_lock);\r\nreturn false;\r\n} else if (!conn->apsd_info)\r\nreturn false;\r\nif (test_bit(WMM_ENABLED, &vif->flags)) {\r\nether_type = be16_to_cpu(datap->h_proto);\r\nif (is_ethertype(ether_type)) {\r\nip_hdr = (u8 *)(datap + 1);\r\n} else {\r\nllc_hdr = (struct ath6kl_llc_snap_hdr *)\r\n(datap + 1);\r\nether_type = be16_to_cpu(llc_hdr->eth_type);\r\nip_hdr = (u8 *)(llc_hdr + 1);\r\n}\r\nif (ether_type == IP_ETHERTYPE)\r\nup = ath6kl_wmi_determine_user_priority(\r\nip_hdr, 0);\r\n}\r\ntraffic_class = ath6kl_wmi_get_traffic_class(up);\r\nif ((conn->apsd_info & (1 << traffic_class)) == 0)\r\nreturn false;\r\nspin_lock_bh(&conn->psq_lock);\r\nis_apsdq_empty = skb_queue_empty(&conn->apsdq);\r\nskb_queue_tail(&conn->apsdq, skb);\r\nspin_unlock_bh(&conn->psq_lock);\r\nif (is_apsdq_empty) {\r\nath6kl_wmi_set_apsd_bfrd_traf(ar->wmi,\r\nvif->fw_vif_idx,\r\nconn->aid, 1, 0);\r\n}\r\n*flags |= WMI_DATA_HDR_FLAGS_UAPSD;\r\nreturn true;\r\n}\r\nstatic bool ath6kl_process_psq(struct ath6kl_sta *conn,\r\nstruct ath6kl_vif *vif,\r\nstruct sk_buff *skb,\r\nu32 *flags)\r\n{\r\nbool is_psq_empty = false;\r\nstruct ath6kl *ar = vif->ar;\r\nif (conn->sta_flags & STA_PS_POLLED) {\r\nspin_lock_bh(&conn->psq_lock);\r\nif (!skb_queue_empty(&conn->psq))\r\n*flags |= WMI_DATA_HDR_FLAGS_MORE;\r\nspin_unlock_bh(&conn->psq_lock);\r\nreturn false;\r\n}\r\nspin_lock_bh(&conn->psq_lock);\r\nis_psq_empty = skb_queue_empty(&conn->psq);\r\nskb_queue_tail(&conn->psq, skb);\r\nspin_unlock_bh(&conn->psq_lock);\r\nif (is_psq_empty)\r\nath6kl_wmi_set_pvb_cmd(ar->wmi,\r\nvif->fw_vif_idx,\r\nconn->aid, 1);\r\nreturn true;\r\n}\r\nstatic bool ath6kl_powersave_ap(struct ath6kl_vif *vif, struct sk_buff *skb,\r\nu32 *flags)\r\n{\r\nstruct ethhdr *datap = (struct ethhdr *) skb->data;\r\nstruct ath6kl_sta *conn = NULL;\r\nbool ps_queued = false;\r\nstruct ath6kl *ar = vif->ar;\r\nif (is_multicast_ether_addr(datap->h_dest)) {\r\nu8 ctr = 0;\r\nbool q_mcast = false;\r\nfor (ctr = 0; ctr < AP_MAX_NUM_STA; ctr++) {\r\nif (ar->sta_list[ctr].sta_flags & STA_PS_SLEEP) {\r\nq_mcast = true;\r\nbreak;\r\n}\r\n}\r\nif (q_mcast) {\r\nif (!test_bit(DTIM_EXPIRED, &vif->flags)) {\r\nbool is_mcastq_empty = false;\r\nspin_lock_bh(&ar->mcastpsq_lock);\r\nis_mcastq_empty =\r\nskb_queue_empty(&ar->mcastpsq);\r\nskb_queue_tail(&ar->mcastpsq, skb);\r\nspin_unlock_bh(&ar->mcastpsq_lock);\r\nif (is_mcastq_empty)\r\nath6kl_wmi_set_pvb_cmd(ar->wmi,\r\nvif->fw_vif_idx,\r\nMCAST_AID, 1);\r\nps_queued = true;\r\n} else {\r\nspin_lock_bh(&ar->mcastpsq_lock);\r\nif (!skb_queue_empty(&ar->mcastpsq))\r\n*flags |= WMI_DATA_HDR_FLAGS_MORE;\r\nspin_unlock_bh(&ar->mcastpsq_lock);\r\n}\r\n}\r\n} else {\r\nconn = ath6kl_find_sta(vif, datap->h_dest);\r\nif (!conn) {\r\ndev_kfree_skb(skb);\r\nreturn true;\r\n}\r\nif (conn->sta_flags & STA_PS_SLEEP) {\r\nps_queued = ath6kl_process_uapsdq(conn,\r\nvif, skb, flags);\r\nif (!(*flags & WMI_DATA_HDR_FLAGS_UAPSD))\r\nps_queued = ath6kl_process_psq(conn,\r\nvif, skb, flags);\r\n}\r\n}\r\nreturn ps_queued;\r\n}\r\nint ath6kl_control_tx(void *devt, struct sk_buff *skb,\r\nenum htc_endpoint_id eid)\r\n{\r\nstruct ath6kl *ar = devt;\r\nint status = 0;\r\nstruct ath6kl_cookie *cookie = NULL;\r\nif (WARN_ON_ONCE(ar->state == ATH6KL_STATE_WOW)) {\r\ndev_kfree_skb(skb);\r\nreturn -EACCES;\r\n}\r\nif (WARN_ON_ONCE(eid == ENDPOINT_UNUSED ||\r\neid >= ENDPOINT_MAX)) {\r\nstatus = -EINVAL;\r\ngoto fail_ctrl_tx;\r\n}\r\nspin_lock_bh(&ar->lock);\r\nath6kl_dbg(ATH6KL_DBG_WLAN_TX,\r\n"%s: skb=0x%p, len=0x%x eid =%d\n", __func__,\r\nskb, skb->len, eid);\r\nif (test_bit(WMI_CTRL_EP_FULL, &ar->flag) && (eid == ar->ctrl_ep)) {\r\ncookie = NULL;\r\nath6kl_err("wmi ctrl ep full, dropping pkt : 0x%p, len:%d\n",\r\nskb, skb->len);\r\n} else\r\ncookie = ath6kl_alloc_cookie(ar);\r\nif (cookie == NULL) {\r\nspin_unlock_bh(&ar->lock);\r\nstatus = -ENOMEM;\r\ngoto fail_ctrl_tx;\r\n}\r\nar->tx_pending[eid]++;\r\nif (eid != ar->ctrl_ep)\r\nar->total_tx_data_pend++;\r\nspin_unlock_bh(&ar->lock);\r\ncookie->skb = skb;\r\ncookie->map_no = 0;\r\nset_htc_pkt_info(&cookie->htc_pkt, cookie, skb->data, skb->len,\r\neid, ATH6KL_CONTROL_PKT_TAG);\r\ncookie->htc_pkt.skb = skb;\r\nath6kl_htc_tx(ar->htc_target, &cookie->htc_pkt);\r\nreturn 0;\r\nfail_ctrl_tx:\r\ndev_kfree_skb(skb);\r\nreturn status;\r\n}\r\nint ath6kl_data_tx(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct ath6kl *ar = ath6kl_priv(dev);\r\nstruct ath6kl_cookie *cookie = NULL;\r\nenum htc_endpoint_id eid = ENDPOINT_UNUSED;\r\nstruct ath6kl_vif *vif = netdev_priv(dev);\r\nu32 map_no = 0;\r\nu16 htc_tag = ATH6KL_DATA_PKT_TAG;\r\nu8 ac = 99 ;\r\nbool chk_adhoc_ps_mapping = false;\r\nint ret;\r\nstruct wmi_tx_meta_v2 meta_v2;\r\nvoid *meta;\r\nu8 csum_start = 0, csum_dest = 0, csum = skb->ip_summed;\r\nu8 meta_ver = 0;\r\nu32 flags = 0;\r\nath6kl_dbg(ATH6KL_DBG_WLAN_TX,\r\n"%s: skb=0x%p, data=0x%p, len=0x%x\n", __func__,\r\nskb, skb->data, skb->len);\r\nif (!test_bit(CONNECTED, &vif->flags))\r\ngoto fail_tx;\r\nif (WARN_ON_ONCE(ar->state != ATH6KL_STATE_ON))\r\ngoto fail_tx;\r\nif (!test_bit(WMI_READY, &ar->flag))\r\ngoto fail_tx;\r\nif (vif->nw_type == AP_NETWORK) {\r\nif (ath6kl_powersave_ap(vif, skb, &flags))\r\nreturn 0;\r\n}\r\nif (test_bit(WMI_ENABLED, &ar->flag)) {\r\nif ((dev->features & NETIF_F_IP_CSUM) &&\r\n(csum == CHECKSUM_PARTIAL)) {\r\ncsum_start = skb->csum_start -\r\n(skb_network_header(skb) - skb->head) +\r\nsizeof(struct ath6kl_llc_snap_hdr);\r\ncsum_dest = skb->csum_offset + csum_start;\r\n}\r\nif (skb_headroom(skb) < dev->needed_headroom) {\r\nstruct sk_buff *tmp_skb = skb;\r\nskb = skb_realloc_headroom(skb, dev->needed_headroom);\r\nkfree_skb(tmp_skb);\r\nif (skb == NULL) {\r\nvif->net_stats.tx_dropped++;\r\nreturn 0;\r\n}\r\n}\r\nif (ath6kl_wmi_dix_2_dot3(ar->wmi, skb)) {\r\nath6kl_err("ath6kl_wmi_dix_2_dot3 failed\n");\r\ngoto fail_tx;\r\n}\r\nif ((dev->features & NETIF_F_IP_CSUM) &&\r\n(csum == CHECKSUM_PARTIAL)) {\r\nmeta_v2.csum_start = csum_start;\r\nmeta_v2.csum_dest = csum_dest;\r\nmeta_v2.csum_flags = WMI_META_V2_FLAG_CSUM_OFFLOAD;\r\nmeta_ver = WMI_META_VERSION_2;\r\nmeta = &meta_v2;\r\n} else {\r\nmeta_ver = 0;\r\nmeta = NULL;\r\n}\r\nret = ath6kl_wmi_data_hdr_add(ar->wmi, skb,\r\nDATA_MSGTYPE, flags, 0,\r\nmeta_ver,\r\nmeta, vif->fw_vif_idx);\r\nif (ret) {\r\nath6kl_warn("failed to add wmi data header:%d\n"\r\n, ret);\r\ngoto fail_tx;\r\n}\r\nif ((vif->nw_type == ADHOC_NETWORK) &&\r\nar->ibss_ps_enable && test_bit(CONNECTED, &vif->flags))\r\nchk_adhoc_ps_mapping = true;\r\nelse {\r\nret = ath6kl_wmi_implicit_create_pstream(ar->wmi,\r\nvif->fw_vif_idx, skb,\r\n0, test_bit(WMM_ENABLED, &vif->flags), &ac);\r\nif (ret)\r\ngoto fail_tx;\r\n}\r\n} else\r\ngoto fail_tx;\r\nspin_lock_bh(&ar->lock);\r\nif (chk_adhoc_ps_mapping)\r\neid = ath6kl_ibss_map_epid(skb, dev, &map_no);\r\nelse\r\neid = ar->ac2ep_map[ac];\r\nif (eid == 0 || eid == ENDPOINT_UNUSED) {\r\nath6kl_err("eid %d is not mapped!\n", eid);\r\nspin_unlock_bh(&ar->lock);\r\ngoto fail_tx;\r\n}\r\ncookie = ath6kl_alloc_cookie(ar);\r\nif (!cookie) {\r\nspin_unlock_bh(&ar->lock);\r\ngoto fail_tx;\r\n}\r\nar->tx_pending[eid]++;\r\nar->total_tx_data_pend++;\r\nspin_unlock_bh(&ar->lock);\r\nif (!IS_ALIGNED((unsigned long) skb->data - HTC_HDR_LENGTH, 4) &&\r\nskb_cloned(skb)) {\r\nstruct sk_buff *nskb;\r\nnskb = skb_copy_expand(skb, HTC_HDR_LENGTH, 0, GFP_ATOMIC);\r\nif (nskb == NULL)\r\ngoto fail_tx;\r\nkfree_skb(skb);\r\nskb = nskb;\r\n}\r\ncookie->skb = skb;\r\ncookie->map_no = map_no;\r\nset_htc_pkt_info(&cookie->htc_pkt, cookie, skb->data, skb->len,\r\neid, htc_tag);\r\ncookie->htc_pkt.skb = skb;\r\nath6kl_dbg_dump(ATH6KL_DBG_RAW_BYTES, __func__, "tx ",\r\nskb->data, skb->len);\r\nath6kl_htc_tx(ar->htc_target, &cookie->htc_pkt);\r\nreturn 0;\r\nfail_tx:\r\ndev_kfree_skb(skb);\r\nvif->net_stats.tx_dropped++;\r\nvif->net_stats.tx_aborted_errors++;\r\nreturn 0;\r\n}\r\nvoid ath6kl_indicate_tx_activity(void *devt, u8 traffic_class, bool active)\r\n{\r\nstruct ath6kl *ar = devt;\r\nenum htc_endpoint_id eid;\r\nint i;\r\neid = ar->ac2ep_map[traffic_class];\r\nif (!test_bit(WMI_ENABLED, &ar->flag))\r\ngoto notify_htc;\r\nspin_lock_bh(&ar->lock);\r\nar->ac_stream_active[traffic_class] = active;\r\nif (active) {\r\nif (ar->ac_stream_pri_map[traffic_class] >\r\nar->hiac_stream_active_pri)\r\nar->hiac_stream_active_pri =\r\nar->ac_stream_pri_map[traffic_class];\r\n} else {\r\nif (ar->hiac_stream_active_pri ==\r\nar->ac_stream_pri_map[traffic_class]) {\r\nar->hiac_stream_active_pri = 0;\r\nfor (i = 0; i < WMM_NUM_AC; i++) {\r\nif (ar->ac_stream_active[i] &&\r\n(ar->ac_stream_pri_map[i] >\r\nar->hiac_stream_active_pri))\r\nar->hiac_stream_active_pri =\r\nar->ac_stream_pri_map[i];\r\n}\r\n}\r\n}\r\nspin_unlock_bh(&ar->lock);\r\nnotify_htc:\r\nath6kl_htc_activity_changed(ar->htc_target, eid, active);\r\n}\r\nenum htc_send_full_action ath6kl_tx_queue_full(struct htc_target *target,\r\nstruct htc_packet *packet)\r\n{\r\nstruct ath6kl *ar = target->dev->ar;\r\nstruct ath6kl_vif *vif;\r\nenum htc_endpoint_id endpoint = packet->endpoint;\r\nenum htc_send_full_action action = HTC_SEND_FULL_KEEP;\r\nif (endpoint == ar->ctrl_ep) {\r\nset_bit(WMI_CTRL_EP_FULL, &ar->flag);\r\nath6kl_err("wmi ctrl ep is full\n");\r\nath6kl_recovery_err_notify(ar, ATH6KL_FW_EP_FULL);\r\nreturn action;\r\n}\r\nif (packet->info.tx.tag == ATH6KL_CONTROL_PKT_TAG)\r\nreturn action;\r\nif (ar->ac_stream_pri_map[ar->ep2ac_map[endpoint]] <\r\nar->hiac_stream_active_pri &&\r\nar->cookie_count <=\r\ntarget->endpoint[endpoint].tx_drop_packet_threshold)\r\naction = HTC_SEND_FULL_DROP;\r\nspin_lock_bh(&ar->list_lock);\r\nlist_for_each_entry(vif, &ar->vif_list, list) {\r\nif (vif->nw_type == ADHOC_NETWORK ||\r\naction != HTC_SEND_FULL_DROP) {\r\nspin_unlock_bh(&ar->list_lock);\r\nset_bit(NETQ_STOPPED, &vif->flags);\r\nnetif_stop_queue(vif->ndev);\r\nreturn action;\r\n}\r\n}\r\nspin_unlock_bh(&ar->list_lock);\r\nreturn action;\r\n}\r\nstatic void ath6kl_tx_clear_node_map(struct ath6kl_vif *vif,\r\nenum htc_endpoint_id eid, u32 map_no)\r\n{\r\nstruct ath6kl *ar = vif->ar;\r\nu32 i;\r\nif (vif->nw_type != ADHOC_NETWORK)\r\nreturn;\r\nif (!ar->ibss_ps_enable)\r\nreturn;\r\nif (eid == ar->ctrl_ep)\r\nreturn;\r\nif (map_no == 0)\r\nreturn;\r\nmap_no--;\r\nar->node_map[map_no].tx_pend--;\r\nif (ar->node_map[map_no].tx_pend)\r\nreturn;\r\nif (map_no != (ar->node_num - 1))\r\nreturn;\r\nfor (i = ar->node_num; i > 0; i--) {\r\nif (ar->node_map[i - 1].tx_pend)\r\nbreak;\r\nmemset(&ar->node_map[i - 1], 0,\r\nsizeof(struct ath6kl_node_mapping));\r\nar->node_num--;\r\n}\r\n}\r\nvoid ath6kl_tx_complete(struct htc_target *target,\r\nstruct list_head *packet_queue)\r\n{\r\nstruct ath6kl *ar = target->dev->ar;\r\nstruct sk_buff_head skb_queue;\r\nstruct htc_packet *packet;\r\nstruct sk_buff *skb;\r\nstruct ath6kl_cookie *ath6kl_cookie;\r\nu32 map_no = 0;\r\nint status;\r\nenum htc_endpoint_id eid;\r\nbool wake_event = false;\r\nbool flushing[ATH6KL_VIF_MAX] = {false};\r\nu8 if_idx;\r\nstruct ath6kl_vif *vif;\r\nskb_queue_head_init(&skb_queue);\r\nspin_lock_bh(&ar->lock);\r\nwhile (!list_empty(packet_queue)) {\r\npacket = list_first_entry(packet_queue, struct htc_packet,\r\nlist);\r\nlist_del(&packet->list);\r\nif (WARN_ON_ONCE(packet->endpoint == ENDPOINT_UNUSED ||\r\npacket->endpoint >= ENDPOINT_MAX))\r\ncontinue;\r\nath6kl_cookie = (struct ath6kl_cookie *)packet->pkt_cntxt;\r\nif (WARN_ON_ONCE(!ath6kl_cookie))\r\ncontinue;\r\nstatus = packet->status;\r\nskb = ath6kl_cookie->skb;\r\neid = packet->endpoint;\r\nmap_no = ath6kl_cookie->map_no;\r\nif (WARN_ON_ONCE(!skb || !skb->data)) {\r\ndev_kfree_skb(skb);\r\nath6kl_free_cookie(ar, ath6kl_cookie);\r\ncontinue;\r\n}\r\n__skb_queue_tail(&skb_queue, skb);\r\nif (WARN_ON_ONCE(!status && (packet->act_len != skb->len))) {\r\nath6kl_free_cookie(ar, ath6kl_cookie);\r\ncontinue;\r\n}\r\nar->tx_pending[eid]--;\r\nif (eid != ar->ctrl_ep)\r\nar->total_tx_data_pend--;\r\nif (eid == ar->ctrl_ep) {\r\nif (test_bit(WMI_CTRL_EP_FULL, &ar->flag))\r\nclear_bit(WMI_CTRL_EP_FULL, &ar->flag);\r\nif (ar->tx_pending[eid] == 0)\r\nwake_event = true;\r\n}\r\nif (eid == ar->ctrl_ep) {\r\nif_idx = wmi_cmd_hdr_get_if_idx(\r\n(struct wmi_cmd_hdr *) packet->buf);\r\n} else {\r\nif_idx = wmi_data_hdr_get_if_idx(\r\n(struct wmi_data_hdr *) packet->buf);\r\n}\r\nvif = ath6kl_get_vif_by_index(ar, if_idx);\r\nif (!vif) {\r\nath6kl_free_cookie(ar, ath6kl_cookie);\r\ncontinue;\r\n}\r\nif (status) {\r\nif (status == -ECANCELED)\r\nflushing[if_idx] = true;\r\nvif->net_stats.tx_errors++;\r\nif (status != -ENOSPC && status != -ECANCELED)\r\nath6kl_warn("tx complete error: %d\n", status);\r\nath6kl_dbg(ATH6KL_DBG_WLAN_TX,\r\n"%s: skb=0x%p data=0x%p len=0x%x eid=%d %s\n",\r\n__func__, skb, packet->buf, packet->act_len,\r\neid, "error!");\r\n} else {\r\nath6kl_dbg(ATH6KL_DBG_WLAN_TX,\r\n"%s: skb=0x%p data=0x%p len=0x%x eid=%d %s\n",\r\n__func__, skb, packet->buf, packet->act_len,\r\neid, "OK");\r\nflushing[if_idx] = false;\r\nvif->net_stats.tx_packets++;\r\nvif->net_stats.tx_bytes += skb->len;\r\n}\r\nath6kl_tx_clear_node_map(vif, eid, map_no);\r\nath6kl_free_cookie(ar, ath6kl_cookie);\r\nif (test_bit(NETQ_STOPPED, &vif->flags))\r\nclear_bit(NETQ_STOPPED, &vif->flags);\r\n}\r\nspin_unlock_bh(&ar->lock);\r\n__skb_queue_purge(&skb_queue);\r\nspin_lock_bh(&ar->list_lock);\r\nlist_for_each_entry(vif, &ar->vif_list, list) {\r\nif (test_bit(CONNECTED, &vif->flags) &&\r\n!flushing[vif->fw_vif_idx]) {\r\nspin_unlock_bh(&ar->list_lock);\r\nnetif_wake_queue(vif->ndev);\r\nspin_lock_bh(&ar->list_lock);\r\n}\r\n}\r\nspin_unlock_bh(&ar->list_lock);\r\nif (wake_event)\r\nwake_up(&ar->event_wq);\r\nreturn;\r\n}\r\nvoid ath6kl_tx_data_cleanup(struct ath6kl *ar)\r\n{\r\nint i;\r\nfor (i = 0; i < WMM_NUM_AC; i++)\r\nath6kl_htc_flush_txep(ar->htc_target, ar->ac2ep_map[i],\r\nATH6KL_DATA_PKT_TAG);\r\n}\r\nstatic void ath6kl_deliver_frames_to_nw_stack(struct net_device *dev,\r\nstruct sk_buff *skb)\r\n{\r\nif (!skb)\r\nreturn;\r\nskb->dev = dev;\r\nif (!(skb->dev->flags & IFF_UP)) {\r\ndev_kfree_skb(skb);\r\nreturn;\r\n}\r\nskb->protocol = eth_type_trans(skb, skb->dev);\r\nnetif_rx_ni(skb);\r\n}\r\nstatic void ath6kl_alloc_netbufs(struct sk_buff_head *q, u16 num)\r\n{\r\nstruct sk_buff *skb;\r\nwhile (num) {\r\nskb = ath6kl_buf_alloc(ATH6KL_BUFFER_SIZE);\r\nif (!skb) {\r\nath6kl_err("netbuf allocation failed\n");\r\nreturn;\r\n}\r\nskb_queue_tail(q, skb);\r\nnum--;\r\n}\r\n}\r\nstatic struct sk_buff *aggr_get_free_skb(struct aggr_info *p_aggr)\r\n{\r\nstruct sk_buff *skb = NULL;\r\nif (skb_queue_len(&p_aggr->rx_amsdu_freeq) <\r\n(AGGR_NUM_OF_FREE_NETBUFS >> 2))\r\nath6kl_alloc_netbufs(&p_aggr->rx_amsdu_freeq,\r\nAGGR_NUM_OF_FREE_NETBUFS);\r\nskb = skb_dequeue(&p_aggr->rx_amsdu_freeq);\r\nreturn skb;\r\n}\r\nvoid ath6kl_rx_refill(struct htc_target *target, enum htc_endpoint_id endpoint)\r\n{\r\nstruct ath6kl *ar = target->dev->ar;\r\nstruct sk_buff *skb;\r\nint rx_buf;\r\nint n_buf_refill;\r\nstruct htc_packet *packet;\r\nstruct list_head queue;\r\nn_buf_refill = ATH6KL_MAX_RX_BUFFERS -\r\nath6kl_htc_get_rxbuf_num(ar->htc_target, endpoint);\r\nif (n_buf_refill <= 0)\r\nreturn;\r\nINIT_LIST_HEAD(&queue);\r\nath6kl_dbg(ATH6KL_DBG_WLAN_RX,\r\n"%s: providing htc with %d buffers at eid=%d\n",\r\n__func__, n_buf_refill, endpoint);\r\nfor (rx_buf = 0; rx_buf < n_buf_refill; rx_buf++) {\r\nskb = ath6kl_buf_alloc(ATH6KL_BUFFER_SIZE);\r\nif (!skb)\r\nbreak;\r\npacket = (struct htc_packet *) skb->head;\r\nif (!IS_ALIGNED((unsigned long) skb->data, 4)) {\r\nsize_t len = skb_headlen(skb);\r\nskb->data = PTR_ALIGN(skb->data - 4, 4);\r\nskb_set_tail_pointer(skb, len);\r\n}\r\nset_htc_rxpkt_info(packet, skb, skb->data,\r\nATH6KL_BUFFER_SIZE, endpoint);\r\npacket->skb = skb;\r\nlist_add_tail(&packet->list, &queue);\r\n}\r\nif (!list_empty(&queue))\r\nath6kl_htc_add_rxbuf_multiple(ar->htc_target, &queue);\r\n}\r\nvoid ath6kl_refill_amsdu_rxbufs(struct ath6kl *ar, int count)\r\n{\r\nstruct htc_packet *packet;\r\nstruct sk_buff *skb;\r\nwhile (count) {\r\nskb = ath6kl_buf_alloc(ATH6KL_AMSDU_BUFFER_SIZE);\r\nif (!skb)\r\nreturn;\r\npacket = (struct htc_packet *) skb->head;\r\nif (!IS_ALIGNED((unsigned long) skb->data, 4)) {\r\nsize_t len = skb_headlen(skb);\r\nskb->data = PTR_ALIGN(skb->data - 4, 4);\r\nskb_set_tail_pointer(skb, len);\r\n}\r\nset_htc_rxpkt_info(packet, skb, skb->data,\r\nATH6KL_AMSDU_BUFFER_SIZE, 0);\r\npacket->skb = skb;\r\nspin_lock_bh(&ar->lock);\r\nlist_add_tail(&packet->list, &ar->amsdu_rx_buffer_queue);\r\nspin_unlock_bh(&ar->lock);\r\ncount--;\r\n}\r\n}\r\nstruct htc_packet *ath6kl_alloc_amsdu_rxbuf(struct htc_target *target,\r\nenum htc_endpoint_id endpoint,\r\nint len)\r\n{\r\nstruct ath6kl *ar = target->dev->ar;\r\nstruct htc_packet *packet = NULL;\r\nstruct list_head *pkt_pos;\r\nint refill_cnt = 0, depth = 0;\r\nath6kl_dbg(ATH6KL_DBG_WLAN_RX, "%s: eid=%d, len:%d\n",\r\n__func__, endpoint, len);\r\nif ((len <= ATH6KL_BUFFER_SIZE) ||\r\n(len > ATH6KL_AMSDU_BUFFER_SIZE))\r\nreturn NULL;\r\nspin_lock_bh(&ar->lock);\r\nif (list_empty(&ar->amsdu_rx_buffer_queue)) {\r\nspin_unlock_bh(&ar->lock);\r\nrefill_cnt = ATH6KL_MAX_AMSDU_RX_BUFFERS;\r\ngoto refill_buf;\r\n}\r\npacket = list_first_entry(&ar->amsdu_rx_buffer_queue,\r\nstruct htc_packet, list);\r\nlist_del(&packet->list);\r\nlist_for_each(pkt_pos, &ar->amsdu_rx_buffer_queue)\r\ndepth++;\r\nrefill_cnt = ATH6KL_MAX_AMSDU_RX_BUFFERS - depth;\r\nspin_unlock_bh(&ar->lock);\r\npacket->endpoint = endpoint;\r\nrefill_buf:\r\nif (refill_cnt >= ATH6KL_AMSDU_REFILL_THRESHOLD)\r\nath6kl_refill_amsdu_rxbufs(ar, refill_cnt);\r\nreturn packet;\r\n}\r\nstatic void aggr_slice_amsdu(struct aggr_info *p_aggr,\r\nstruct rxtid *rxtid, struct sk_buff *skb)\r\n{\r\nstruct sk_buff *new_skb;\r\nstruct ethhdr *hdr;\r\nu16 frame_8023_len, payload_8023_len, mac_hdr_len, amsdu_len;\r\nu8 *framep;\r\nmac_hdr_len = sizeof(struct ethhdr);\r\nframep = skb->data + mac_hdr_len;\r\namsdu_len = skb->len - mac_hdr_len;\r\nwhile (amsdu_len > mac_hdr_len) {\r\nhdr = (struct ethhdr *) framep;\r\npayload_8023_len = ntohs(hdr->h_proto);\r\nif (payload_8023_len < MIN_MSDU_SUBFRAME_PAYLOAD_LEN ||\r\npayload_8023_len > MAX_MSDU_SUBFRAME_PAYLOAD_LEN) {\r\nath6kl_err("802.3 AMSDU frame bound check failed. len %d\n",\r\npayload_8023_len);\r\nbreak;\r\n}\r\nframe_8023_len = payload_8023_len + mac_hdr_len;\r\nnew_skb = aggr_get_free_skb(p_aggr);\r\nif (!new_skb) {\r\nath6kl_err("no buffer available\n");\r\nbreak;\r\n}\r\nmemcpy(new_skb->data, framep, frame_8023_len);\r\nskb_put(new_skb, frame_8023_len);\r\nif (ath6kl_wmi_dot3_2_dix(new_skb)) {\r\nath6kl_err("dot3_2_dix error\n");\r\ndev_kfree_skb(new_skb);\r\nbreak;\r\n}\r\nskb_queue_tail(&rxtid->q, new_skb);\r\nif ((amsdu_len - frame_8023_len) == 0)\r\nbreak;\r\nframe_8023_len = ALIGN(frame_8023_len, 4);\r\nframep += frame_8023_len;\r\namsdu_len -= frame_8023_len;\r\n}\r\ndev_kfree_skb(skb);\r\n}\r\nstatic void aggr_deque_frms(struct aggr_info_conn *agg_conn, u8 tid,\r\nu16 seq_no, u8 order)\r\n{\r\nstruct sk_buff *skb;\r\nstruct rxtid *rxtid;\r\nstruct skb_hold_q *node;\r\nu16 idx, idx_end, seq_end;\r\nstruct rxtid_stats *stats;\r\nrxtid = &agg_conn->rx_tid[tid];\r\nstats = &agg_conn->stat[tid];\r\nspin_lock_bh(&rxtid->lock);\r\nidx = AGGR_WIN_IDX(rxtid->seq_next, rxtid->hold_q_sz);\r\nseq_end = seq_no ? seq_no : rxtid->seq_next;\r\nidx_end = AGGR_WIN_IDX(seq_end, rxtid->hold_q_sz);\r\ndo {\r\nnode = &rxtid->hold_q[idx];\r\nif ((order == 1) && (!node->skb))\r\nbreak;\r\nif (node->skb) {\r\nif (node->is_amsdu)\r\naggr_slice_amsdu(agg_conn->aggr_info, rxtid,\r\nnode->skb);\r\nelse\r\nskb_queue_tail(&rxtid->q, node->skb);\r\nnode->skb = NULL;\r\n} else\r\nstats->num_hole++;\r\nrxtid->seq_next = ATH6KL_NEXT_SEQ_NO(rxtid->seq_next);\r\nidx = AGGR_WIN_IDX(rxtid->seq_next, rxtid->hold_q_sz);\r\n} while (idx != idx_end);\r\nspin_unlock_bh(&rxtid->lock);\r\nstats->num_delivered += skb_queue_len(&rxtid->q);\r\nwhile ((skb = skb_dequeue(&rxtid->q)))\r\nath6kl_deliver_frames_to_nw_stack(agg_conn->dev, skb);\r\n}\r\nstatic bool aggr_process_recv_frm(struct aggr_info_conn *agg_conn, u8 tid,\r\nu16 seq_no,\r\nbool is_amsdu, struct sk_buff *frame)\r\n{\r\nstruct rxtid *rxtid;\r\nstruct rxtid_stats *stats;\r\nstruct sk_buff *skb;\r\nstruct skb_hold_q *node;\r\nu16 idx, st, cur, end;\r\nbool is_queued = false;\r\nu16 extended_end;\r\nrxtid = &agg_conn->rx_tid[tid];\r\nstats = &agg_conn->stat[tid];\r\nstats->num_into_aggr++;\r\nif (!rxtid->aggr) {\r\nif (is_amsdu) {\r\naggr_slice_amsdu(agg_conn->aggr_info, rxtid, frame);\r\nis_queued = true;\r\nstats->num_amsdu++;\r\nwhile ((skb = skb_dequeue(&rxtid->q)))\r\nath6kl_deliver_frames_to_nw_stack(agg_conn->dev,\r\nskb);\r\n}\r\nreturn is_queued;\r\n}\r\nst = rxtid->seq_next;\r\ncur = seq_no;\r\nend = (st + rxtid->hold_q_sz-1) & ATH6KL_MAX_SEQ_NO;\r\nif (((st < end) && (cur < st || cur > end)) ||\r\n((st > end) && (cur > end) && (cur < st))) {\r\nextended_end = (end + rxtid->hold_q_sz - 1) &\r\nATH6KL_MAX_SEQ_NO;\r\nif (((end < extended_end) &&\r\n(cur < end || cur > extended_end)) ||\r\n((end > extended_end) && (cur > extended_end) &&\r\n(cur < end))) {\r\naggr_deque_frms(agg_conn, tid, 0, 0);\r\nspin_lock_bh(&rxtid->lock);\r\nif (cur >= rxtid->hold_q_sz - 1)\r\nrxtid->seq_next = cur - (rxtid->hold_q_sz - 1);\r\nelse\r\nrxtid->seq_next = ATH6KL_MAX_SEQ_NO -\r\n(rxtid->hold_q_sz - 2 - cur);\r\nspin_unlock_bh(&rxtid->lock);\r\n} else {\r\nif (cur >= rxtid->hold_q_sz - 1)\r\nst = cur - (rxtid->hold_q_sz - 1);\r\nelse\r\nst = ATH6KL_MAX_SEQ_NO -\r\n(rxtid->hold_q_sz - 2 - cur);\r\naggr_deque_frms(agg_conn, tid, st, 0);\r\n}\r\nstats->num_oow++;\r\n}\r\nidx = AGGR_WIN_IDX(seq_no, rxtid->hold_q_sz);\r\nnode = &rxtid->hold_q[idx];\r\nspin_lock_bh(&rxtid->lock);\r\ndev_kfree_skb(node->skb);\r\nstats->num_dups++;\r\nnode->skb = frame;\r\nis_queued = true;\r\nnode->is_amsdu = is_amsdu;\r\nnode->seq_no = seq_no;\r\nif (node->is_amsdu)\r\nstats->num_amsdu++;\r\nelse\r\nstats->num_mpdu++;\r\nspin_unlock_bh(&rxtid->lock);\r\naggr_deque_frms(agg_conn, tid, 0, 1);\r\nif (agg_conn->timer_scheduled)\r\nreturn is_queued;\r\nspin_lock_bh(&rxtid->lock);\r\nfor (idx = 0 ; idx < rxtid->hold_q_sz; idx++) {\r\nif (rxtid->hold_q[idx].skb) {\r\nagg_conn->timer_scheduled = true;\r\nmod_timer(&agg_conn->timer,\r\n(jiffies + (HZ * AGGR_RX_TIMEOUT) / 1000));\r\nrxtid->timer_mon = true;\r\nbreak;\r\n}\r\n}\r\nspin_unlock_bh(&rxtid->lock);\r\nreturn is_queued;\r\n}\r\nstatic void ath6kl_uapsd_trigger_frame_rx(struct ath6kl_vif *vif,\r\nstruct ath6kl_sta *conn)\r\n{\r\nstruct ath6kl *ar = vif->ar;\r\nbool is_apsdq_empty, is_apsdq_empty_at_start;\r\nu32 num_frames_to_deliver, flags;\r\nstruct sk_buff *skb = NULL;\r\nnum_frames_to_deliver = (conn->apsd_info >> ATH6KL_APSD_NUM_OF_AC) &\r\nATH6KL_APSD_FRAME_MASK;\r\nif (!num_frames_to_deliver)\r\nnum_frames_to_deliver = ATH6KL_APSD_ALL_FRAME;\r\nspin_lock_bh(&conn->psq_lock);\r\nis_apsdq_empty = skb_queue_empty(&conn->apsdq);\r\nspin_unlock_bh(&conn->psq_lock);\r\nis_apsdq_empty_at_start = is_apsdq_empty;\r\nwhile ((!is_apsdq_empty) && (num_frames_to_deliver)) {\r\nspin_lock_bh(&conn->psq_lock);\r\nskb = skb_dequeue(&conn->apsdq);\r\nis_apsdq_empty = skb_queue_empty(&conn->apsdq);\r\nspin_unlock_bh(&conn->psq_lock);\r\nconn->sta_flags |= STA_PS_APSD_TRIGGER;\r\nnum_frames_to_deliver--;\r\nif ((is_apsdq_empty) || (!num_frames_to_deliver))\r\nconn->sta_flags |= STA_PS_APSD_EOSP;\r\nath6kl_data_tx(skb, vif->ndev);\r\nconn->sta_flags &= ~(STA_PS_APSD_TRIGGER);\r\nconn->sta_flags &= ~(STA_PS_APSD_EOSP);\r\n}\r\nif (is_apsdq_empty) {\r\nif (is_apsdq_empty_at_start)\r\nflags = WMI_AP_APSD_NO_DELIVERY_FRAMES;\r\nelse\r\nflags = 0;\r\nath6kl_wmi_set_apsd_bfrd_traf(ar->wmi,\r\nvif->fw_vif_idx,\r\nconn->aid, 0, flags);\r\n}\r\nreturn;\r\n}\r\nvoid ath6kl_rx(struct htc_target *target, struct htc_packet *packet)\r\n{\r\nstruct ath6kl *ar = target->dev->ar;\r\nstruct sk_buff *skb = packet->pkt_cntxt;\r\nstruct wmi_rx_meta_v2 *meta;\r\nstruct wmi_data_hdr *dhdr;\r\nint min_hdr_len;\r\nu8 meta_type, dot11_hdr = 0;\r\nu8 pad_before_data_start;\r\nint status = packet->status;\r\nenum htc_endpoint_id ept = packet->endpoint;\r\nbool is_amsdu, prev_ps, ps_state = false;\r\nbool trig_state = false;\r\nstruct ath6kl_sta *conn = NULL;\r\nstruct sk_buff *skb1 = NULL;\r\nstruct ethhdr *datap = NULL;\r\nstruct ath6kl_vif *vif;\r\nstruct aggr_info_conn *aggr_conn;\r\nu16 seq_no, offset;\r\nu8 tid, if_idx;\r\nath6kl_dbg(ATH6KL_DBG_WLAN_RX,\r\n"%s: ar=0x%p eid=%d, skb=0x%p, data=0x%p, len=0x%x status:%d",\r\n__func__, ar, ept, skb, packet->buf,\r\npacket->act_len, status);\r\nif (status || !(skb->data + HTC_HDR_LENGTH)) {\r\ndev_kfree_skb(skb);\r\nreturn;\r\n}\r\nskb_put(skb, packet->act_len + HTC_HDR_LENGTH);\r\nskb_pull(skb, HTC_HDR_LENGTH);\r\nath6kl_dbg_dump(ATH6KL_DBG_RAW_BYTES, __func__, "rx ",\r\nskb->data, skb->len);\r\nif (ept == ar->ctrl_ep) {\r\nif (test_bit(WMI_ENABLED, &ar->flag)) {\r\nath6kl_check_wow_status(ar);\r\nath6kl_wmi_control_rx(ar->wmi, skb);\r\nreturn;\r\n}\r\nif_idx =\r\nwmi_cmd_hdr_get_if_idx((struct wmi_cmd_hdr *) skb->data);\r\n} else {\r\nif_idx =\r\nwmi_data_hdr_get_if_idx((struct wmi_data_hdr *) skb->data);\r\n}\r\nvif = ath6kl_get_vif_by_index(ar, if_idx);\r\nif (!vif) {\r\ndev_kfree_skb(skb);\r\nreturn;\r\n}\r\nspin_lock_bh(&vif->if_lock);\r\nvif->net_stats.rx_packets++;\r\nvif->net_stats.rx_bytes += packet->act_len;\r\nspin_unlock_bh(&vif->if_lock);\r\nskb->dev = vif->ndev;\r\nif (!test_bit(WMI_ENABLED, &ar->flag)) {\r\nif (EPPING_ALIGNMENT_PAD > 0)\r\nskb_pull(skb, EPPING_ALIGNMENT_PAD);\r\nath6kl_deliver_frames_to_nw_stack(vif->ndev, skb);\r\nreturn;\r\n}\r\nath6kl_check_wow_status(ar);\r\nmin_hdr_len = sizeof(struct ethhdr) + sizeof(struct wmi_data_hdr) +\r\nsizeof(struct ath6kl_llc_snap_hdr);\r\ndhdr = (struct wmi_data_hdr *) skb->data;\r\nif (vif->nw_type != AP_NETWORK &&\r\n((packet->act_len < min_hdr_len) ||\r\n(packet->act_len > WMI_MAX_AMSDU_RX_DATA_FRAME_LENGTH))) {\r\nath6kl_info("frame len is too short or too long\n");\r\nvif->net_stats.rx_errors++;\r\nvif->net_stats.rx_length_errors++;\r\ndev_kfree_skb(skb);\r\nreturn;\r\n}\r\nif (vif->nw_type == AP_NETWORK) {\r\nmeta_type = wmi_data_hdr_get_meta(dhdr);\r\nps_state = !!((dhdr->info >> WMI_DATA_HDR_PS_SHIFT) &\r\nWMI_DATA_HDR_PS_MASK);\r\noffset = sizeof(struct wmi_data_hdr);\r\ntrig_state = !!(le16_to_cpu(dhdr->info3) & WMI_DATA_HDR_TRIG);\r\nswitch (meta_type) {\r\ncase 0:\r\nbreak;\r\ncase WMI_META_VERSION_1:\r\noffset += sizeof(struct wmi_rx_meta_v1);\r\nbreak;\r\ncase WMI_META_VERSION_2:\r\noffset += sizeof(struct wmi_rx_meta_v2);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\ndatap = (struct ethhdr *) (skb->data + offset);\r\nconn = ath6kl_find_sta(vif, datap->h_source);\r\nif (!conn) {\r\ndev_kfree_skb(skb);\r\nreturn;\r\n}\r\nprev_ps = !!(conn->sta_flags & STA_PS_SLEEP);\r\nif (ps_state)\r\nconn->sta_flags |= STA_PS_SLEEP;\r\nelse\r\nconn->sta_flags &= ~STA_PS_SLEEP;\r\nif ((conn->sta_flags & STA_PS_SLEEP) && trig_state)\r\nath6kl_uapsd_trigger_frame_rx(vif, conn);\r\nif (prev_ps ^ !!(conn->sta_flags & STA_PS_SLEEP)) {\r\nif (!(conn->sta_flags & STA_PS_SLEEP)) {\r\nstruct sk_buff *skbuff = NULL;\r\nbool is_apsdq_empty;\r\nstruct ath6kl_mgmt_buff *mgmt;\r\nu8 idx;\r\nspin_lock_bh(&conn->psq_lock);\r\nwhile (conn->mgmt_psq_len > 0) {\r\nmgmt = list_first_entry(\r\n&conn->mgmt_psq,\r\nstruct ath6kl_mgmt_buff,\r\nlist);\r\nlist_del(&mgmt->list);\r\nconn->mgmt_psq_len--;\r\nspin_unlock_bh(&conn->psq_lock);\r\nidx = vif->fw_vif_idx;\r\nath6kl_wmi_send_mgmt_cmd(ar->wmi,\r\nidx,\r\nmgmt->id,\r\nmgmt->freq,\r\nmgmt->wait,\r\nmgmt->buf,\r\nmgmt->len,\r\nmgmt->no_cck);\r\nkfree(mgmt);\r\nspin_lock_bh(&conn->psq_lock);\r\n}\r\nconn->mgmt_psq_len = 0;\r\nwhile ((skbuff = skb_dequeue(&conn->psq))) {\r\nspin_unlock_bh(&conn->psq_lock);\r\nath6kl_data_tx(skbuff, vif->ndev);\r\nspin_lock_bh(&conn->psq_lock);\r\n}\r\nis_apsdq_empty = skb_queue_empty(&conn->apsdq);\r\nwhile ((skbuff = skb_dequeue(&conn->apsdq))) {\r\nspin_unlock_bh(&conn->psq_lock);\r\nath6kl_data_tx(skbuff, vif->ndev);\r\nspin_lock_bh(&conn->psq_lock);\r\n}\r\nspin_unlock_bh(&conn->psq_lock);\r\nif (!is_apsdq_empty)\r\nath6kl_wmi_set_apsd_bfrd_traf(\r\nar->wmi,\r\nvif->fw_vif_idx,\r\nconn->aid, 0, 0);\r\nath6kl_wmi_set_pvb_cmd(ar->wmi, vif->fw_vif_idx,\r\nconn->aid, 0);\r\n}\r\n}\r\nif ((packet->act_len < min_hdr_len) ||\r\n(packet->act_len >\r\nWMI_MAX_AMSDU_RX_DATA_FRAME_LENGTH)) {\r\ndev_kfree_skb(skb);\r\nreturn;\r\n}\r\n}\r\nis_amsdu = wmi_data_hdr_is_amsdu(dhdr) ? true : false;\r\ntid = wmi_data_hdr_get_up(dhdr);\r\nseq_no = wmi_data_hdr_get_seqno(dhdr);\r\nmeta_type = wmi_data_hdr_get_meta(dhdr);\r\ndot11_hdr = wmi_data_hdr_get_dot11(dhdr);\r\npad_before_data_start =\r\n(le16_to_cpu(dhdr->info3) >> WMI_DATA_HDR_PAD_BEFORE_DATA_SHIFT)\r\n& WMI_DATA_HDR_PAD_BEFORE_DATA_MASK;\r\nskb_pull(skb, sizeof(struct wmi_data_hdr));\r\nswitch (meta_type) {\r\ncase WMI_META_VERSION_1:\r\nskb_pull(skb, sizeof(struct wmi_rx_meta_v1));\r\nbreak;\r\ncase WMI_META_VERSION_2:\r\nmeta = (struct wmi_rx_meta_v2 *) skb->data;\r\nif (meta->csum_flags & 0x1) {\r\nskb->ip_summed = CHECKSUM_COMPLETE;\r\nskb->csum = (__force __wsum) meta->csum;\r\n}\r\nskb_pull(skb, sizeof(struct wmi_rx_meta_v2));\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nskb_pull(skb, pad_before_data_start);\r\nif (dot11_hdr)\r\nstatus = ath6kl_wmi_dot11_hdr_remove(ar->wmi, skb);\r\nelse if (!is_amsdu)\r\nstatus = ath6kl_wmi_dot3_2_dix(skb);\r\nif (status) {\r\ndev_kfree_skb(skb);\r\nreturn;\r\n}\r\nif (!(vif->ndev->flags & IFF_UP)) {\r\ndev_kfree_skb(skb);\r\nreturn;\r\n}\r\nif (vif->nw_type == AP_NETWORK) {\r\ndatap = (struct ethhdr *) skb->data;\r\nif (is_multicast_ether_addr(datap->h_dest))\r\nskb1 = skb_copy(skb, GFP_ATOMIC);\r\nelse {\r\nconn = ath6kl_find_sta(vif, datap->h_dest);\r\nif (conn && ar->intra_bss) {\r\nskb1 = skb;\r\nskb = NULL;\r\n} else if (conn && !ar->intra_bss) {\r\ndev_kfree_skb(skb);\r\nskb = NULL;\r\n}\r\n}\r\nif (skb1)\r\nath6kl_data_tx(skb1, vif->ndev);\r\nif (skb == NULL) {\r\nreturn;\r\n}\r\n}\r\ndatap = (struct ethhdr *) skb->data;\r\nif (is_unicast_ether_addr(datap->h_dest)) {\r\nif (vif->nw_type == AP_NETWORK) {\r\nconn = ath6kl_find_sta(vif, datap->h_source);\r\nif (!conn)\r\nreturn;\r\naggr_conn = conn->aggr_conn;\r\n} else\r\naggr_conn = vif->aggr_cntxt->aggr_conn;\r\nif (aggr_process_recv_frm(aggr_conn, tid, seq_no,\r\nis_amsdu, skb)) {\r\nreturn;\r\n}\r\n} else if (!is_broadcast_ether_addr(datap->h_dest))\r\nvif->net_stats.multicast++;\r\nath6kl_deliver_frames_to_nw_stack(vif->ndev, skb);\r\n}\r\nstatic void aggr_timeout(unsigned long arg)\r\n{\r\nu8 i, j;\r\nstruct aggr_info_conn *aggr_conn = (struct aggr_info_conn *) arg;\r\nstruct rxtid *rxtid;\r\nstruct rxtid_stats *stats;\r\nfor (i = 0; i < NUM_OF_TIDS; i++) {\r\nrxtid = &aggr_conn->rx_tid[i];\r\nstats = &aggr_conn->stat[i];\r\nif (!rxtid->aggr || !rxtid->timer_mon)\r\ncontinue;\r\nstats->num_timeouts++;\r\nath6kl_dbg(ATH6KL_DBG_AGGR,\r\n"aggr timeout (st %d end %d)\n",\r\nrxtid->seq_next,\r\n((rxtid->seq_next + rxtid->hold_q_sz-1) &\r\nATH6KL_MAX_SEQ_NO));\r\naggr_deque_frms(aggr_conn, i, 0, 0);\r\n}\r\naggr_conn->timer_scheduled = false;\r\nfor (i = 0; i < NUM_OF_TIDS; i++) {\r\nrxtid = &aggr_conn->rx_tid[i];\r\nif (rxtid->aggr && rxtid->hold_q) {\r\nspin_lock_bh(&rxtid->lock);\r\nfor (j = 0; j < rxtid->hold_q_sz; j++) {\r\nif (rxtid->hold_q[j].skb) {\r\naggr_conn->timer_scheduled = true;\r\nrxtid->timer_mon = true;\r\nbreak;\r\n}\r\n}\r\nspin_unlock_bh(&rxtid->lock);\r\nif (j >= rxtid->hold_q_sz)\r\nrxtid->timer_mon = false;\r\n}\r\n}\r\nif (aggr_conn->timer_scheduled)\r\nmod_timer(&aggr_conn->timer,\r\njiffies + msecs_to_jiffies(AGGR_RX_TIMEOUT));\r\n}\r\nstatic void aggr_delete_tid_state(struct aggr_info_conn *aggr_conn, u8 tid)\r\n{\r\nstruct rxtid *rxtid;\r\nstruct rxtid_stats *stats;\r\nif (!aggr_conn || tid >= NUM_OF_TIDS)\r\nreturn;\r\nrxtid = &aggr_conn->rx_tid[tid];\r\nstats = &aggr_conn->stat[tid];\r\nif (rxtid->aggr)\r\naggr_deque_frms(aggr_conn, tid, 0, 0);\r\nrxtid->aggr = false;\r\nrxtid->timer_mon = false;\r\nrxtid->win_sz = 0;\r\nrxtid->seq_next = 0;\r\nrxtid->hold_q_sz = 0;\r\nkfree(rxtid->hold_q);\r\nrxtid->hold_q = NULL;\r\nmemset(stats, 0, sizeof(struct rxtid_stats));\r\n}\r\nvoid aggr_recv_addba_req_evt(struct ath6kl_vif *vif, u8 tid_mux, u16 seq_no,\r\nu8 win_sz)\r\n{\r\nstruct ath6kl_sta *sta;\r\nstruct aggr_info_conn *aggr_conn = NULL;\r\nstruct rxtid *rxtid;\r\nstruct rxtid_stats *stats;\r\nu16 hold_q_size;\r\nu8 tid, aid;\r\nif (vif->nw_type == AP_NETWORK) {\r\naid = ath6kl_get_aid(tid_mux);\r\nsta = ath6kl_find_sta_by_aid(vif->ar, aid);\r\nif (sta)\r\naggr_conn = sta->aggr_conn;\r\n} else\r\naggr_conn = vif->aggr_cntxt->aggr_conn;\r\nif (!aggr_conn)\r\nreturn;\r\ntid = ath6kl_get_tid(tid_mux);\r\nif (tid >= NUM_OF_TIDS)\r\nreturn;\r\nrxtid = &aggr_conn->rx_tid[tid];\r\nstats = &aggr_conn->stat[tid];\r\nif (win_sz < AGGR_WIN_SZ_MIN || win_sz > AGGR_WIN_SZ_MAX)\r\nath6kl_dbg(ATH6KL_DBG_WLAN_RX, "%s: win_sz %d, tid %d\n",\r\n__func__, win_sz, tid);\r\nif (rxtid->aggr)\r\naggr_delete_tid_state(aggr_conn, tid);\r\nrxtid->seq_next = seq_no;\r\nhold_q_size = TID_WINDOW_SZ(win_sz) * sizeof(struct skb_hold_q);\r\nrxtid->hold_q = kzalloc(hold_q_size, GFP_KERNEL);\r\nif (!rxtid->hold_q)\r\nreturn;\r\nrxtid->win_sz = win_sz;\r\nrxtid->hold_q_sz = TID_WINDOW_SZ(win_sz);\r\nif (!skb_queue_empty(&rxtid->q))\r\nreturn;\r\nrxtid->aggr = true;\r\n}\r\nvoid aggr_conn_init(struct ath6kl_vif *vif, struct aggr_info *aggr_info,\r\nstruct aggr_info_conn *aggr_conn)\r\n{\r\nstruct rxtid *rxtid;\r\nu8 i;\r\naggr_conn->aggr_sz = AGGR_SZ_DEFAULT;\r\naggr_conn->dev = vif->ndev;\r\ninit_timer(&aggr_conn->timer);\r\naggr_conn->timer.function = aggr_timeout;\r\naggr_conn->timer.data = (unsigned long) aggr_conn;\r\naggr_conn->aggr_info = aggr_info;\r\naggr_conn->timer_scheduled = false;\r\nfor (i = 0; i < NUM_OF_TIDS; i++) {\r\nrxtid = &aggr_conn->rx_tid[i];\r\nrxtid->aggr = false;\r\nrxtid->timer_mon = false;\r\nskb_queue_head_init(&rxtid->q);\r\nspin_lock_init(&rxtid->lock);\r\n}\r\n}\r\nstruct aggr_info *aggr_init(struct ath6kl_vif *vif)\r\n{\r\nstruct aggr_info *p_aggr = NULL;\r\np_aggr = kzalloc(sizeof(struct aggr_info), GFP_KERNEL);\r\nif (!p_aggr) {\r\nath6kl_err("failed to alloc memory for aggr_node\n");\r\nreturn NULL;\r\n}\r\np_aggr->aggr_conn = kzalloc(sizeof(struct aggr_info_conn), GFP_KERNEL);\r\nif (!p_aggr->aggr_conn) {\r\nath6kl_err("failed to alloc memory for connection specific aggr info\n");\r\nkfree(p_aggr);\r\nreturn NULL;\r\n}\r\naggr_conn_init(vif, p_aggr, p_aggr->aggr_conn);\r\nskb_queue_head_init(&p_aggr->rx_amsdu_freeq);\r\nath6kl_alloc_netbufs(&p_aggr->rx_amsdu_freeq, AGGR_NUM_OF_FREE_NETBUFS);\r\nreturn p_aggr;\r\n}\r\nvoid aggr_recv_delba_req_evt(struct ath6kl_vif *vif, u8 tid_mux)\r\n{\r\nstruct ath6kl_sta *sta;\r\nstruct rxtid *rxtid;\r\nstruct aggr_info_conn *aggr_conn = NULL;\r\nu8 tid, aid;\r\nif (vif->nw_type == AP_NETWORK) {\r\naid = ath6kl_get_aid(tid_mux);\r\nsta = ath6kl_find_sta_by_aid(vif->ar, aid);\r\nif (sta)\r\naggr_conn = sta->aggr_conn;\r\n} else\r\naggr_conn = vif->aggr_cntxt->aggr_conn;\r\nif (!aggr_conn)\r\nreturn;\r\ntid = ath6kl_get_tid(tid_mux);\r\nif (tid >= NUM_OF_TIDS)\r\nreturn;\r\nrxtid = &aggr_conn->rx_tid[tid];\r\nif (rxtid->aggr)\r\naggr_delete_tid_state(aggr_conn, tid);\r\n}\r\nvoid aggr_reset_state(struct aggr_info_conn *aggr_conn)\r\n{\r\nu8 tid;\r\nif (!aggr_conn)\r\nreturn;\r\nif (aggr_conn->timer_scheduled) {\r\ndel_timer(&aggr_conn->timer);\r\naggr_conn->timer_scheduled = false;\r\n}\r\nfor (tid = 0; tid < NUM_OF_TIDS; tid++)\r\naggr_delete_tid_state(aggr_conn, tid);\r\n}\r\nvoid ath6kl_cleanup_amsdu_rxbufs(struct ath6kl *ar)\r\n{\r\nstruct htc_packet *packet, *tmp_pkt;\r\nspin_lock_bh(&ar->lock);\r\nif (list_empty(&ar->amsdu_rx_buffer_queue)) {\r\nspin_unlock_bh(&ar->lock);\r\nreturn;\r\n}\r\nlist_for_each_entry_safe(packet, tmp_pkt, &ar->amsdu_rx_buffer_queue,\r\nlist) {\r\nlist_del(&packet->list);\r\nspin_unlock_bh(&ar->lock);\r\ndev_kfree_skb(packet->pkt_cntxt);\r\nspin_lock_bh(&ar->lock);\r\n}\r\nspin_unlock_bh(&ar->lock);\r\n}\r\nvoid aggr_module_destroy(struct aggr_info *aggr_info)\r\n{\r\nif (!aggr_info)\r\nreturn;\r\naggr_reset_state(aggr_info->aggr_conn);\r\nskb_queue_purge(&aggr_info->rx_amsdu_freeq);\r\nkfree(aggr_info->aggr_conn);\r\nkfree(aggr_info);\r\n}
