static const char * const bank4_names(struct threshold_block *b)\r\n{\r\nswitch (b->address) {\r\ncase 0x00000413:\r\nreturn "dram";\r\ncase 0xc0000408:\r\nreturn "ht_links";\r\ncase 0xc0000409:\r\nreturn "l3_cache";\r\ndefault:\r\nWARN(1, "Funny MSR: 0x%08x\n", b->address);\r\nreturn "";\r\n}\r\n}\r\nstatic bool lvt_interrupt_supported(unsigned int bank, u32 msr_high_bits)\r\n{\r\nif (bank == 4)\r\nreturn true;\r\nreturn msr_high_bits & BIT(28);\r\n}\r\nstatic int lvt_off_valid(struct threshold_block *b, int apic, u32 lo, u32 hi)\r\n{\r\nint msr = (hi & MASK_LVTOFF_HI) >> 20;\r\nif (apic < 0) {\r\npr_err(FW_BUG "cpu %d, failed to setup threshold interrupt "\r\n"for bank %d, block %d (MSR%08X=0x%x%08x)\n", b->cpu,\r\nb->bank, b->block, b->address, hi, lo);\r\nreturn 0;\r\n}\r\nif (apic != msr) {\r\npr_err(FW_BUG "cpu %d, invalid threshold interrupt offset %d "\r\n"for bank %d, block %d (MSR%08X=0x%x%08x)\n",\r\nb->cpu, apic, b->bank, b->block, b->address, hi, lo);\r\nreturn 0;\r\n}\r\nreturn 1;\r\n}\r\nstatic void threshold_restart_bank(void *_tr)\r\n{\r\nstruct thresh_restart *tr = _tr;\r\nu32 hi, lo;\r\nrdmsr(tr->b->address, lo, hi);\r\nif (tr->b->threshold_limit < (hi & THRESHOLD_MAX))\r\ntr->reset = 1;\r\nif (tr->reset) {\r\nhi =\r\n(hi & ~(MASK_ERR_COUNT_HI | MASK_OVERFLOW_HI)) |\r\n(THRESHOLD_MAX - tr->b->threshold_limit);\r\n} else if (tr->old_limit) {\r\nint new_count = (hi & THRESHOLD_MAX) +\r\n(tr->old_limit - tr->b->threshold_limit);\r\nhi = (hi & ~MASK_ERR_COUNT_HI) |\r\n(new_count & THRESHOLD_MAX);\r\n}\r\nhi &= ~MASK_INT_TYPE_HI;\r\nif (!tr->b->interrupt_capable)\r\ngoto done;\r\nif (tr->set_lvt_off) {\r\nif (lvt_off_valid(tr->b, tr->lvt_off, lo, hi)) {\r\nhi &= ~MASK_LVTOFF_HI;\r\nhi |= tr->lvt_off << 20;\r\n}\r\n}\r\nif (tr->b->interrupt_enable)\r\nhi |= INT_TYPE_APIC;\r\ndone:\r\nhi |= MASK_COUNT_EN_HI;\r\nwrmsr(tr->b->address, lo, hi);\r\n}\r\nstatic void mce_threshold_block_init(struct threshold_block *b, int offset)\r\n{\r\nstruct thresh_restart tr = {\r\n.b = b,\r\n.set_lvt_off = 1,\r\n.lvt_off = offset,\r\n};\r\nb->threshold_limit = THRESHOLD_MAX;\r\nthreshold_restart_bank(&tr);\r\n}\r\nstatic int setup_APIC_mce(int reserved, int new)\r\n{\r\nif (reserved < 0 && !setup_APIC_eilvt(new, THRESHOLD_APIC_VECTOR,\r\nAPIC_EILVT_MSG_FIX, 0))\r\nreturn new;\r\nreturn reserved;\r\n}\r\nvoid mce_amd_feature_init(struct cpuinfo_x86 *c)\r\n{\r\nstruct threshold_block b;\r\nunsigned int cpu = smp_processor_id();\r\nu32 low = 0, high = 0, address = 0;\r\nunsigned int bank, block;\r\nint offset = -1;\r\nfor (bank = 0; bank < NR_BANKS; ++bank) {\r\nfor (block = 0; block < NR_BLOCKS; ++block) {\r\nif (block == 0)\r\naddress = MSR_IA32_MC0_MISC + bank * 4;\r\nelse if (block == 1) {\r\naddress = (low & MASK_BLKPTR_LO) >> 21;\r\nif (!address)\r\nbreak;\r\naddress += MCG_XBLK_ADDR;\r\n} else\r\n++address;\r\nif (rdmsr_safe(address, &low, &high))\r\nbreak;\r\nif (!(high & MASK_VALID_HI))\r\ncontinue;\r\nif (!(high & MASK_CNTP_HI) ||\r\n(high & MASK_LOCKED_HI))\r\ncontinue;\r\nif (!block)\r\nper_cpu(bank_map, cpu) |= (1 << bank);\r\nmemset(&b, 0, sizeof(b));\r\nb.cpu = cpu;\r\nb.bank = bank;\r\nb.block = block;\r\nb.address = address;\r\nb.interrupt_capable = lvt_interrupt_supported(bank, high);\r\nif (b.interrupt_capable) {\r\nint new = (high & MASK_LVTOFF_HI) >> 20;\r\noffset = setup_APIC_mce(offset, new);\r\n}\r\nmce_threshold_block_init(&b, offset);\r\nmce_threshold_vector = amd_threshold_interrupt;\r\n}\r\n}\r\n}\r\nstatic void amd_threshold_interrupt(void)\r\n{\r\nu32 low = 0, high = 0, address = 0;\r\nunsigned int bank, block;\r\nstruct mce m;\r\nmce_setup(&m);\r\nfor (bank = 0; bank < NR_BANKS; ++bank) {\r\nif (!(per_cpu(bank_map, m.cpu) & (1 << bank)))\r\ncontinue;\r\nfor (block = 0; block < NR_BLOCKS; ++block) {\r\nif (block == 0) {\r\naddress = MSR_IA32_MC0_MISC + bank * 4;\r\n} else if (block == 1) {\r\naddress = (low & MASK_BLKPTR_LO) >> 21;\r\nif (!address)\r\nbreak;\r\naddress += MCG_XBLK_ADDR;\r\n} else {\r\n++address;\r\n}\r\nif (rdmsr_safe(address, &low, &high))\r\nbreak;\r\nif (!(high & MASK_VALID_HI)) {\r\nif (block)\r\ncontinue;\r\nelse\r\nbreak;\r\n}\r\nif (!(high & MASK_CNTP_HI) ||\r\n(high & MASK_LOCKED_HI))\r\ncontinue;\r\nmachine_check_poll(MCP_TIMESTAMP,\r\n&__get_cpu_var(mce_poll_banks));\r\nif (high & MASK_OVERFLOW_HI) {\r\nrdmsrl(address, m.misc);\r\nrdmsrl(MSR_IA32_MC0_STATUS + bank * 4,\r\nm.status);\r\nm.bank = K8_MCE_THRESHOLD_BASE\r\n+ bank * NR_BLOCKS\r\n+ block;\r\nmce_log(&m);\r\nreturn;\r\n}\r\n}\r\n}\r\n}\r\nstatic ssize_t\r\nstore_interrupt_enable(struct threshold_block *b, const char *buf, size_t size)\r\n{\r\nstruct thresh_restart tr;\r\nunsigned long new;\r\nif (!b->interrupt_capable)\r\nreturn -EINVAL;\r\nif (strict_strtoul(buf, 0, &new) < 0)\r\nreturn -EINVAL;\r\nb->interrupt_enable = !!new;\r\nmemset(&tr, 0, sizeof(tr));\r\ntr.b = b;\r\nsmp_call_function_single(b->cpu, threshold_restart_bank, &tr, 1);\r\nreturn size;\r\n}\r\nstatic ssize_t\r\nstore_threshold_limit(struct threshold_block *b, const char *buf, size_t size)\r\n{\r\nstruct thresh_restart tr;\r\nunsigned long new;\r\nif (strict_strtoul(buf, 0, &new) < 0)\r\nreturn -EINVAL;\r\nif (new > THRESHOLD_MAX)\r\nnew = THRESHOLD_MAX;\r\nif (new < 1)\r\nnew = 1;\r\nmemset(&tr, 0, sizeof(tr));\r\ntr.old_limit = b->threshold_limit;\r\nb->threshold_limit = new;\r\ntr.b = b;\r\nsmp_call_function_single(b->cpu, threshold_restart_bank, &tr, 1);\r\nreturn size;\r\n}\r\nstatic ssize_t show_error_count(struct threshold_block *b, char *buf)\r\n{\r\nu32 lo, hi;\r\nrdmsr_on_cpu(b->cpu, b->address, &lo, &hi);\r\nreturn sprintf(buf, "%u\n", ((hi & THRESHOLD_MAX) -\r\n(THRESHOLD_MAX - b->threshold_limit)));\r\n}\r\nstatic ssize_t show(struct kobject *kobj, struct attribute *attr, char *buf)\r\n{\r\nstruct threshold_block *b = to_block(kobj);\r\nstruct threshold_attr *a = to_attr(attr);\r\nssize_t ret;\r\nret = a->show ? a->show(b, buf) : -EIO;\r\nreturn ret;\r\n}\r\nstatic ssize_t store(struct kobject *kobj, struct attribute *attr,\r\nconst char *buf, size_t count)\r\n{\r\nstruct threshold_block *b = to_block(kobj);\r\nstruct threshold_attr *a = to_attr(attr);\r\nssize_t ret;\r\nret = a->store ? a->store(b, buf, count) : -EIO;\r\nreturn ret;\r\n}\r\nstatic __cpuinit int allocate_threshold_blocks(unsigned int cpu,\r\nunsigned int bank,\r\nunsigned int block,\r\nu32 address)\r\n{\r\nstruct threshold_block *b = NULL;\r\nu32 low, high;\r\nint err;\r\nif ((bank >= NR_BANKS) || (block >= NR_BLOCKS))\r\nreturn 0;\r\nif (rdmsr_safe_on_cpu(cpu, address, &low, &high))\r\nreturn 0;\r\nif (!(high & MASK_VALID_HI)) {\r\nif (block)\r\ngoto recurse;\r\nelse\r\nreturn 0;\r\n}\r\nif (!(high & MASK_CNTP_HI) ||\r\n(high & MASK_LOCKED_HI))\r\ngoto recurse;\r\nb = kzalloc(sizeof(struct threshold_block), GFP_KERNEL);\r\nif (!b)\r\nreturn -ENOMEM;\r\nb->block = block;\r\nb->bank = bank;\r\nb->cpu = cpu;\r\nb->address = address;\r\nb->interrupt_enable = 0;\r\nb->interrupt_capable = lvt_interrupt_supported(bank, high);\r\nb->threshold_limit = THRESHOLD_MAX;\r\nif (b->interrupt_capable)\r\nthreshold_ktype.default_attrs[2] = &interrupt_enable.attr;\r\nelse\r\nthreshold_ktype.default_attrs[2] = NULL;\r\nINIT_LIST_HEAD(&b->miscj);\r\nif (per_cpu(threshold_banks, cpu)[bank]->blocks) {\r\nlist_add(&b->miscj,\r\n&per_cpu(threshold_banks, cpu)[bank]->blocks->miscj);\r\n} else {\r\nper_cpu(threshold_banks, cpu)[bank]->blocks = b;\r\n}\r\nerr = kobject_init_and_add(&b->kobj, &threshold_ktype,\r\nper_cpu(threshold_banks, cpu)[bank]->kobj,\r\n(bank == 4 ? bank4_names(b) : th_names[bank]));\r\nif (err)\r\ngoto out_free;\r\nrecurse:\r\nif (!block) {\r\naddress = (low & MASK_BLKPTR_LO) >> 21;\r\nif (!address)\r\nreturn 0;\r\naddress += MCG_XBLK_ADDR;\r\n} else {\r\n++address;\r\n}\r\nerr = allocate_threshold_blocks(cpu, bank, ++block, address);\r\nif (err)\r\ngoto out_free;\r\nif (b)\r\nkobject_uevent(&b->kobj, KOBJ_ADD);\r\nreturn err;\r\nout_free:\r\nif (b) {\r\nkobject_put(&b->kobj);\r\nlist_del(&b->miscj);\r\nkfree(b);\r\n}\r\nreturn err;\r\n}\r\nstatic __cpuinit int __threshold_add_blocks(struct threshold_bank *b)\r\n{\r\nstruct list_head *head = &b->blocks->miscj;\r\nstruct threshold_block *pos = NULL;\r\nstruct threshold_block *tmp = NULL;\r\nint err = 0;\r\nerr = kobject_add(&b->blocks->kobj, b->kobj, b->blocks->kobj.name);\r\nif (err)\r\nreturn err;\r\nlist_for_each_entry_safe(pos, tmp, head, miscj) {\r\nerr = kobject_add(&pos->kobj, b->kobj, pos->kobj.name);\r\nif (err) {\r\nlist_for_each_entry_safe_reverse(pos, tmp, head, miscj)\r\nkobject_del(&pos->kobj);\r\nreturn err;\r\n}\r\n}\r\nreturn err;\r\n}\r\nstatic __cpuinit int threshold_create_bank(unsigned int cpu, unsigned int bank)\r\n{\r\nstruct device *dev = per_cpu(mce_device, cpu);\r\nstruct amd_northbridge *nb = NULL;\r\nstruct threshold_bank *b = NULL;\r\nconst char *name = th_names[bank];\r\nint err = 0;\r\nif (shared_bank[bank]) {\r\nnb = node_to_amd_nb(amd_get_nb_id(cpu));\r\nif (nb && nb->bank4) {\r\nb = nb->bank4;\r\nerr = kobject_add(b->kobj, &dev->kobj, name);\r\nif (err)\r\ngoto out;\r\nper_cpu(threshold_banks, cpu)[bank] = b;\r\natomic_inc(&b->cpus);\r\nerr = __threshold_add_blocks(b);\r\ngoto out;\r\n}\r\n}\r\nb = kzalloc(sizeof(struct threshold_bank), GFP_KERNEL);\r\nif (!b) {\r\nerr = -ENOMEM;\r\ngoto out;\r\n}\r\nb->kobj = kobject_create_and_add(name, &dev->kobj);\r\nif (!b->kobj) {\r\nerr = -EINVAL;\r\ngoto out_free;\r\n}\r\nper_cpu(threshold_banks, cpu)[bank] = b;\r\nif (shared_bank[bank]) {\r\natomic_set(&b->cpus, 1);\r\nif (nb) {\r\nWARN_ON(nb->bank4);\r\nnb->bank4 = b;\r\n}\r\n}\r\nerr = allocate_threshold_blocks(cpu, bank, 0,\r\nMSR_IA32_MC0_MISC + bank * 4);\r\nif (!err)\r\ngoto out;\r\nout_free:\r\nkfree(b);\r\nout:\r\nreturn err;\r\n}\r\nstatic __cpuinit int threshold_create_device(unsigned int cpu)\r\n{\r\nunsigned int bank;\r\nint err = 0;\r\nfor (bank = 0; bank < NR_BANKS; ++bank) {\r\nif (!(per_cpu(bank_map, cpu) & (1 << bank)))\r\ncontinue;\r\nerr = threshold_create_bank(cpu, bank);\r\nif (err)\r\nreturn err;\r\n}\r\nreturn err;\r\n}\r\nstatic void deallocate_threshold_block(unsigned int cpu,\r\nunsigned int bank)\r\n{\r\nstruct threshold_block *pos = NULL;\r\nstruct threshold_block *tmp = NULL;\r\nstruct threshold_bank *head = per_cpu(threshold_banks, cpu)[bank];\r\nif (!head)\r\nreturn;\r\nlist_for_each_entry_safe(pos, tmp, &head->blocks->miscj, miscj) {\r\nkobject_put(&pos->kobj);\r\nlist_del(&pos->miscj);\r\nkfree(pos);\r\n}\r\nkfree(per_cpu(threshold_banks, cpu)[bank]->blocks);\r\nper_cpu(threshold_banks, cpu)[bank]->blocks = NULL;\r\n}\r\nstatic void __threshold_remove_blocks(struct threshold_bank *b)\r\n{\r\nstruct threshold_block *pos = NULL;\r\nstruct threshold_block *tmp = NULL;\r\nkobject_del(b->kobj);\r\nlist_for_each_entry_safe(pos, tmp, &b->blocks->miscj, miscj)\r\nkobject_del(&pos->kobj);\r\n}\r\nstatic void threshold_remove_bank(unsigned int cpu, int bank)\r\n{\r\nstruct amd_northbridge *nb;\r\nstruct threshold_bank *b;\r\nb = per_cpu(threshold_banks, cpu)[bank];\r\nif (!b)\r\nreturn;\r\nif (!b->blocks)\r\ngoto free_out;\r\nif (shared_bank[bank]) {\r\nif (!atomic_dec_and_test(&b->cpus)) {\r\n__threshold_remove_blocks(b);\r\nper_cpu(threshold_banks, cpu)[bank] = NULL;\r\nreturn;\r\n} else {\r\nnb = node_to_amd_nb(amd_get_nb_id(cpu));\r\nnb->bank4 = NULL;\r\n}\r\n}\r\ndeallocate_threshold_block(cpu, bank);\r\nfree_out:\r\nkobject_del(b->kobj);\r\nkobject_put(b->kobj);\r\nkfree(b);\r\nper_cpu(threshold_banks, cpu)[bank] = NULL;\r\n}\r\nstatic void threshold_remove_device(unsigned int cpu)\r\n{\r\nunsigned int bank;\r\nfor (bank = 0; bank < NR_BANKS; ++bank) {\r\nif (!(per_cpu(bank_map, cpu) & (1 << bank)))\r\ncontinue;\r\nthreshold_remove_bank(cpu, bank);\r\n}\r\n}\r\nstatic void __cpuinit\r\namd_64_threshold_cpu_callback(unsigned long action, unsigned int cpu)\r\n{\r\nswitch (action) {\r\ncase CPU_ONLINE:\r\ncase CPU_ONLINE_FROZEN:\r\nthreshold_create_device(cpu);\r\nbreak;\r\ncase CPU_DEAD:\r\ncase CPU_DEAD_FROZEN:\r\nthreshold_remove_device(cpu);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nstatic __init int threshold_init_device(void)\r\n{\r\nunsigned lcpu = 0;\r\nfor_each_online_cpu(lcpu) {\r\nint err = threshold_create_device(lcpu);\r\nif (err)\r\nreturn err;\r\n}\r\nthreshold_cpu_callback = amd_64_threshold_cpu_callback;\r\nreturn 0;\r\n}
