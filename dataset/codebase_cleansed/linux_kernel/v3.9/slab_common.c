static int kmem_cache_sanity_check(struct mem_cgroup *memcg, const char *name,\r\nsize_t size)\r\n{\r\nstruct kmem_cache *s = NULL;\r\nif (!name || in_interrupt() || size < sizeof(void *) ||\r\nsize > KMALLOC_MAX_SIZE) {\r\npr_err("kmem_cache_create(%s) integrity check failed\n", name);\r\nreturn -EINVAL;\r\n}\r\nlist_for_each_entry(s, &slab_caches, list) {\r\nchar tmp;\r\nint res;\r\nres = probe_kernel_address(s->name, tmp);\r\nif (res) {\r\npr_err("Slab cache with size %d has lost its name\n",\r\ns->object_size);\r\ncontinue;\r\n}\r\nif (!memcg && !strcmp(s->name, name)) {\r\npr_err("%s (%s): Cache name already exists.\n",\r\n__func__, name);\r\ndump_stack();\r\ns = NULL;\r\nreturn -EINVAL;\r\n}\r\n}\r\nWARN_ON(strchr(name, ' '));\r\nreturn 0;\r\n}\r\nstatic inline int kmem_cache_sanity_check(struct mem_cgroup *memcg,\r\nconst char *name, size_t size)\r\n{\r\nreturn 0;\r\n}\r\nint memcg_update_all_caches(int num_memcgs)\r\n{\r\nstruct kmem_cache *s;\r\nint ret = 0;\r\nmutex_lock(&slab_mutex);\r\nlist_for_each_entry(s, &slab_caches, list) {\r\nif (!is_root_cache(s))\r\ncontinue;\r\nret = memcg_update_cache_size(s, num_memcgs);\r\nif (ret)\r\ngoto out;\r\n}\r\nmemcg_update_array_size(num_memcgs);\r\nout:\r\nmutex_unlock(&slab_mutex);\r\nreturn ret;\r\n}\r\nunsigned long calculate_alignment(unsigned long flags,\r\nunsigned long align, unsigned long size)\r\n{\r\nif (flags & SLAB_HWCACHE_ALIGN) {\r\nunsigned long ralign = cache_line_size();\r\nwhile (size <= ralign / 2)\r\nralign /= 2;\r\nalign = max(align, ralign);\r\n}\r\nif (align < ARCH_SLAB_MINALIGN)\r\nalign = ARCH_SLAB_MINALIGN;\r\nreturn ALIGN(align, sizeof(void *));\r\n}\r\nstruct kmem_cache *\r\nkmem_cache_create_memcg(struct mem_cgroup *memcg, const char *name, size_t size,\r\nsize_t align, unsigned long flags, void (*ctor)(void *),\r\nstruct kmem_cache *parent_cache)\r\n{\r\nstruct kmem_cache *s = NULL;\r\nint err = 0;\r\nget_online_cpus();\r\nmutex_lock(&slab_mutex);\r\nif (!kmem_cache_sanity_check(memcg, name, size) == 0)\r\ngoto out_locked;\r\nflags &= CACHE_CREATE_MASK;\r\ns = __kmem_cache_alias(memcg, name, size, align, flags, ctor);\r\nif (s)\r\ngoto out_locked;\r\ns = kmem_cache_zalloc(kmem_cache, GFP_KERNEL);\r\nif (s) {\r\ns->object_size = s->size = size;\r\ns->align = calculate_alignment(flags, align, size);\r\ns->ctor = ctor;\r\nif (memcg_register_cache(memcg, s, parent_cache)) {\r\nkmem_cache_free(kmem_cache, s);\r\nerr = -ENOMEM;\r\ngoto out_locked;\r\n}\r\ns->name = kstrdup(name, GFP_KERNEL);\r\nif (!s->name) {\r\nkmem_cache_free(kmem_cache, s);\r\nerr = -ENOMEM;\r\ngoto out_locked;\r\n}\r\nerr = __kmem_cache_create(s, flags);\r\nif (!err) {\r\ns->refcount = 1;\r\nlist_add(&s->list, &slab_caches);\r\nmemcg_cache_list_add(memcg, s);\r\n} else {\r\nkfree(s->name);\r\nkmem_cache_free(kmem_cache, s);\r\n}\r\n} else\r\nerr = -ENOMEM;\r\nout_locked:\r\nmutex_unlock(&slab_mutex);\r\nput_online_cpus();\r\nif (err) {\r\nif (flags & SLAB_PANIC)\r\npanic("kmem_cache_create: Failed to create slab '%s'. Error %d\n",\r\nname, err);\r\nelse {\r\nprintk(KERN_WARNING "kmem_cache_create(%s) failed with error %d",\r\nname, err);\r\ndump_stack();\r\n}\r\nreturn NULL;\r\n}\r\nreturn s;\r\n}\r\nstruct kmem_cache *\r\nkmem_cache_create(const char *name, size_t size, size_t align,\r\nunsigned long flags, void (*ctor)(void *))\r\n{\r\nreturn kmem_cache_create_memcg(NULL, name, size, align, flags, ctor, NULL);\r\n}\r\nvoid kmem_cache_destroy(struct kmem_cache *s)\r\n{\r\nkmem_cache_destroy_memcg_children(s);\r\nget_online_cpus();\r\nmutex_lock(&slab_mutex);\r\ns->refcount--;\r\nif (!s->refcount) {\r\nlist_del(&s->list);\r\nif (!__kmem_cache_shutdown(s)) {\r\nmutex_unlock(&slab_mutex);\r\nif (s->flags & SLAB_DESTROY_BY_RCU)\r\nrcu_barrier();\r\nmemcg_release_cache(s);\r\nkfree(s->name);\r\nkmem_cache_free(kmem_cache, s);\r\n} else {\r\nlist_add(&s->list, &slab_caches);\r\nmutex_unlock(&slab_mutex);\r\nprintk(KERN_ERR "kmem_cache_destroy %s: Slab cache still has objects\n",\r\ns->name);\r\ndump_stack();\r\n}\r\n} else {\r\nmutex_unlock(&slab_mutex);\r\n}\r\nput_online_cpus();\r\n}\r\nint slab_is_available(void)\r\n{\r\nreturn slab_state >= UP;\r\n}\r\nvoid __init create_boot_cache(struct kmem_cache *s, const char *name, size_t size,\r\nunsigned long flags)\r\n{\r\nint err;\r\ns->name = name;\r\ns->size = s->object_size = size;\r\ns->align = calculate_alignment(flags, ARCH_KMALLOC_MINALIGN, size);\r\nerr = __kmem_cache_create(s, flags);\r\nif (err)\r\npanic("Creation of kmalloc slab %s size=%zd failed. Reason %d\n",\r\nname, size, err);\r\ns->refcount = -1;\r\n}\r\nstruct kmem_cache *__init create_kmalloc_cache(const char *name, size_t size,\r\nunsigned long flags)\r\n{\r\nstruct kmem_cache *s = kmem_cache_zalloc(kmem_cache, GFP_NOWAIT);\r\nif (!s)\r\npanic("Out of memory when creating slab %s\n", name);\r\ncreate_boot_cache(s, name, size, flags);\r\nlist_add(&s->list, &slab_caches);\r\ns->refcount = 1;\r\nreturn s;\r\n}\r\nvoid print_slabinfo_header(struct seq_file *m)\r\n{\r\n#ifdef CONFIG_DEBUG_SLAB\r\nseq_puts(m, "slabinfo - version: 2.1 (statistics)\n");\r\n#else\r\nseq_puts(m, "slabinfo - version: 2.1\n");\r\n#endif\r\nseq_puts(m, "# name <active_objs> <num_objs> <objsize> "\r\n"<objperslab> <pagesperslab>");\r\nseq_puts(m, " : tunables <limit> <batchcount> <sharedfactor>");\r\nseq_puts(m, " : slabdata <active_slabs> <num_slabs> <sharedavail>");\r\n#ifdef CONFIG_DEBUG_SLAB\r\nseq_puts(m, " : globalstat <listallocs> <maxobjs> <grown> <reaped> "\r\n"<error> <maxfreeable> <nodeallocs> <remotefrees> <alienoverflow>");\r\nseq_puts(m, " : cpustat <allochit> <allocmiss> <freehit> <freemiss>");\r\n#endif\r\nseq_putc(m, '\n');\r\n}\r\nstatic void *s_start(struct seq_file *m, loff_t *pos)\r\n{\r\nloff_t n = *pos;\r\nmutex_lock(&slab_mutex);\r\nif (!n)\r\nprint_slabinfo_header(m);\r\nreturn seq_list_start(&slab_caches, *pos);\r\n}\r\nstatic void *s_next(struct seq_file *m, void *p, loff_t *pos)\r\n{\r\nreturn seq_list_next(p, &slab_caches, pos);\r\n}\r\nstatic void s_stop(struct seq_file *m, void *p)\r\n{\r\nmutex_unlock(&slab_mutex);\r\n}\r\nstatic void\r\nmemcg_accumulate_slabinfo(struct kmem_cache *s, struct slabinfo *info)\r\n{\r\nstruct kmem_cache *c;\r\nstruct slabinfo sinfo;\r\nint i;\r\nif (!is_root_cache(s))\r\nreturn;\r\nfor_each_memcg_cache_index(i) {\r\nc = cache_from_memcg(s, i);\r\nif (!c)\r\ncontinue;\r\nmemset(&sinfo, 0, sizeof(sinfo));\r\nget_slabinfo(c, &sinfo);\r\ninfo->active_slabs += sinfo.active_slabs;\r\ninfo->num_slabs += sinfo.num_slabs;\r\ninfo->shared_avail += sinfo.shared_avail;\r\ninfo->active_objs += sinfo.active_objs;\r\ninfo->num_objs += sinfo.num_objs;\r\n}\r\n}\r\nint cache_show(struct kmem_cache *s, struct seq_file *m)\r\n{\r\nstruct slabinfo sinfo;\r\nmemset(&sinfo, 0, sizeof(sinfo));\r\nget_slabinfo(s, &sinfo);\r\nmemcg_accumulate_slabinfo(s, &sinfo);\r\nseq_printf(m, "%-17s %6lu %6lu %6u %4u %4d",\r\ncache_name(s), sinfo.active_objs, sinfo.num_objs, s->size,\r\nsinfo.objects_per_slab, (1 << sinfo.cache_order));\r\nseq_printf(m, " : tunables %4u %4u %4u",\r\nsinfo.limit, sinfo.batchcount, sinfo.shared);\r\nseq_printf(m, " : slabdata %6lu %6lu %6lu",\r\nsinfo.active_slabs, sinfo.num_slabs, sinfo.shared_avail);\r\nslabinfo_show_stats(m, s);\r\nseq_putc(m, '\n');\r\nreturn 0;\r\n}\r\nstatic int s_show(struct seq_file *m, void *p)\r\n{\r\nstruct kmem_cache *s = list_entry(p, struct kmem_cache, list);\r\nif (!is_root_cache(s))\r\nreturn 0;\r\nreturn cache_show(s, m);\r\n}\r\nstatic int slabinfo_open(struct inode *inode, struct file *file)\r\n{\r\nreturn seq_open(file, &slabinfo_op);\r\n}\r\nstatic int __init slab_proc_init(void)\r\n{\r\nproc_create("slabinfo", S_IRUSR, NULL, &proc_slabinfo_operations);\r\nreturn 0;\r\n}
