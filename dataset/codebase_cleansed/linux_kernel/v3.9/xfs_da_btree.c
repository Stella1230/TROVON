static void\r\nxfs_da_node_verify(\r\nstruct xfs_buf *bp)\r\n{\r\nstruct xfs_mount *mp = bp->b_target->bt_mount;\r\nstruct xfs_da_node_hdr *hdr = bp->b_addr;\r\nint block_ok = 0;\r\nblock_ok = hdr->info.magic == cpu_to_be16(XFS_DA_NODE_MAGIC);\r\nblock_ok = block_ok &&\r\nbe16_to_cpu(hdr->level) > 0 &&\r\nbe16_to_cpu(hdr->count) > 0 ;\r\nif (!block_ok) {\r\nXFS_CORRUPTION_ERROR(__func__, XFS_ERRLEVEL_LOW, mp, hdr);\r\nxfs_buf_ioerror(bp, EFSCORRUPTED);\r\n}\r\n}\r\nstatic void\r\nxfs_da_node_write_verify(\r\nstruct xfs_buf *bp)\r\n{\r\nxfs_da_node_verify(bp);\r\n}\r\nstatic void\r\nxfs_da_node_read_verify(\r\nstruct xfs_buf *bp)\r\n{\r\nstruct xfs_mount *mp = bp->b_target->bt_mount;\r\nstruct xfs_da_blkinfo *info = bp->b_addr;\r\nswitch (be16_to_cpu(info->magic)) {\r\ncase XFS_DA_NODE_MAGIC:\r\nxfs_da_node_verify(bp);\r\nbreak;\r\ncase XFS_ATTR_LEAF_MAGIC:\r\nbp->b_ops = &xfs_attr_leaf_buf_ops;\r\nbp->b_ops->verify_read(bp);\r\nreturn;\r\ncase XFS_DIR2_LEAFN_MAGIC:\r\nbp->b_ops = &xfs_dir2_leafn_buf_ops;\r\nbp->b_ops->verify_read(bp);\r\nreturn;\r\ndefault:\r\nXFS_CORRUPTION_ERROR(__func__, XFS_ERRLEVEL_LOW,\r\nmp, info);\r\nxfs_buf_ioerror(bp, EFSCORRUPTED);\r\nbreak;\r\n}\r\n}\r\nint\r\nxfs_da_node_read(\r\nstruct xfs_trans *tp,\r\nstruct xfs_inode *dp,\r\nxfs_dablk_t bno,\r\nxfs_daddr_t mappedbno,\r\nstruct xfs_buf **bpp,\r\nint which_fork)\r\n{\r\nreturn xfs_da_read_buf(tp, dp, bno, mappedbno, bpp,\r\nwhich_fork, &xfs_da_node_buf_ops);\r\n}\r\nint\r\nxfs_da_node_create(xfs_da_args_t *args, xfs_dablk_t blkno, int level,\r\nstruct xfs_buf **bpp, int whichfork)\r\n{\r\nxfs_da_intnode_t *node;\r\nstruct xfs_buf *bp;\r\nint error;\r\nxfs_trans_t *tp;\r\ntrace_xfs_da_node_create(args);\r\ntp = args->trans;\r\nerror = xfs_da_get_buf(tp, args->dp, blkno, -1, &bp, whichfork);\r\nif (error)\r\nreturn(error);\r\nASSERT(bp != NULL);\r\nnode = bp->b_addr;\r\nnode->hdr.info.forw = 0;\r\nnode->hdr.info.back = 0;\r\nnode->hdr.info.magic = cpu_to_be16(XFS_DA_NODE_MAGIC);\r\nnode->hdr.info.pad = 0;\r\nnode->hdr.count = 0;\r\nnode->hdr.level = cpu_to_be16(level);\r\nxfs_trans_log_buf(tp, bp,\r\nXFS_DA_LOGRANGE(node, &node->hdr, sizeof(node->hdr)));\r\nbp->b_ops = &xfs_da_node_buf_ops;\r\n*bpp = bp;\r\nreturn(0);\r\n}\r\nint\r\nxfs_da_split(xfs_da_state_t *state)\r\n{\r\nxfs_da_state_blk_t *oldblk, *newblk, *addblk;\r\nxfs_da_intnode_t *node;\r\nstruct xfs_buf *bp;\r\nint max, action, error, i;\r\ntrace_xfs_da_split(state->args);\r\nmax = state->path.active - 1;\r\nASSERT((max >= 0) && (max < XFS_DA_NODE_MAXDEPTH));\r\nASSERT(state->path.blk[max].magic == XFS_ATTR_LEAF_MAGIC ||\r\nstate->path.blk[max].magic == XFS_DIR2_LEAFN_MAGIC);\r\naddblk = &state->path.blk[max];\r\nfor (i = max; (i >= 0) && addblk; state->path.active--, i--) {\r\noldblk = &state->path.blk[i];\r\nnewblk = &state->altpath.blk[i];\r\nswitch (oldblk->magic) {\r\ncase XFS_ATTR_LEAF_MAGIC:\r\nerror = xfs_attr_leaf_split(state, oldblk, newblk);\r\nif ((error != 0) && (error != ENOSPC)) {\r\nreturn(error);\r\n}\r\nif (!error) {\r\naddblk = newblk;\r\nbreak;\r\n}\r\nstate->extravalid = 1;\r\nif (state->inleaf) {\r\nstate->extraafter = 0;\r\ntrace_xfs_attr_leaf_split_before(state->args);\r\nerror = xfs_attr_leaf_split(state, oldblk,\r\n&state->extrablk);\r\n} else {\r\nstate->extraafter = 1;\r\ntrace_xfs_attr_leaf_split_after(state->args);\r\nerror = xfs_attr_leaf_split(state, newblk,\r\n&state->extrablk);\r\n}\r\nif (error)\r\nreturn(error);\r\naddblk = newblk;\r\nbreak;\r\ncase XFS_DIR2_LEAFN_MAGIC:\r\nerror = xfs_dir2_leafn_split(state, oldblk, newblk);\r\nif (error)\r\nreturn error;\r\naddblk = newblk;\r\nbreak;\r\ncase XFS_DA_NODE_MAGIC:\r\nerror = xfs_da_node_split(state, oldblk, newblk, addblk,\r\nmax - i, &action);\r\naddblk->bp = NULL;\r\nif (error)\r\nreturn(error);\r\nif (action)\r\naddblk = newblk;\r\nelse\r\naddblk = NULL;\r\nbreak;\r\n}\r\nxfs_da_fixhashpath(state, &state->path);\r\n}\r\nif (!addblk)\r\nreturn(0);\r\nASSERT(state->path.active == 0);\r\noldblk = &state->path.blk[0];\r\nerror = xfs_da_root_split(state, oldblk, addblk);\r\nif (error) {\r\naddblk->bp = NULL;\r\nreturn(error);\r\n}\r\nnode = oldblk->bp->b_addr;\r\nif (node->hdr.info.forw) {\r\nif (be32_to_cpu(node->hdr.info.forw) == addblk->blkno) {\r\nbp = addblk->bp;\r\n} else {\r\nASSERT(state->extravalid);\r\nbp = state->extrablk.bp;\r\n}\r\nnode = bp->b_addr;\r\nnode->hdr.info.back = cpu_to_be32(oldblk->blkno);\r\nxfs_trans_log_buf(state->args->trans, bp,\r\nXFS_DA_LOGRANGE(node, &node->hdr.info,\r\nsizeof(node->hdr.info)));\r\n}\r\nnode = oldblk->bp->b_addr;\r\nif (node->hdr.info.back) {\r\nif (be32_to_cpu(node->hdr.info.back) == addblk->blkno) {\r\nbp = addblk->bp;\r\n} else {\r\nASSERT(state->extravalid);\r\nbp = state->extrablk.bp;\r\n}\r\nnode = bp->b_addr;\r\nnode->hdr.info.forw = cpu_to_be32(oldblk->blkno);\r\nxfs_trans_log_buf(state->args->trans, bp,\r\nXFS_DA_LOGRANGE(node, &node->hdr.info,\r\nsizeof(node->hdr.info)));\r\n}\r\naddblk->bp = NULL;\r\nreturn(0);\r\n}\r\nSTATIC int\r\nxfs_da_root_split(xfs_da_state_t *state, xfs_da_state_blk_t *blk1,\r\nxfs_da_state_blk_t *blk2)\r\n{\r\nxfs_da_intnode_t *node, *oldroot;\r\nxfs_da_args_t *args;\r\nxfs_dablk_t blkno;\r\nstruct xfs_buf *bp;\r\nint error, size;\r\nxfs_inode_t *dp;\r\nxfs_trans_t *tp;\r\nxfs_mount_t *mp;\r\nxfs_dir2_leaf_t *leaf;\r\ntrace_xfs_da_root_split(state->args);\r\nargs = state->args;\r\nASSERT(args != NULL);\r\nerror = xfs_da_grow_inode(args, &blkno);\r\nif (error)\r\nreturn(error);\r\ndp = args->dp;\r\ntp = args->trans;\r\nmp = state->mp;\r\nerror = xfs_da_get_buf(tp, dp, blkno, -1, &bp, args->whichfork);\r\nif (error)\r\nreturn(error);\r\nASSERT(bp != NULL);\r\nnode = bp->b_addr;\r\noldroot = blk1->bp->b_addr;\r\nif (oldroot->hdr.info.magic == cpu_to_be16(XFS_DA_NODE_MAGIC)) {\r\nsize = (int)((char *)&oldroot->btree[be16_to_cpu(oldroot->hdr.count)] -\r\n(char *)oldroot);\r\n} else {\r\nASSERT(oldroot->hdr.info.magic == cpu_to_be16(XFS_DIR2_LEAFN_MAGIC));\r\nleaf = (xfs_dir2_leaf_t *)oldroot;\r\nsize = (int)((char *)&leaf->ents[be16_to_cpu(leaf->hdr.count)] -\r\n(char *)leaf);\r\n}\r\nmemcpy(node, oldroot, size);\r\nxfs_trans_log_buf(tp, bp, 0, size - 1);\r\nbp->b_ops = blk1->bp->b_ops;\r\nblk1->bp = bp;\r\nblk1->blkno = blkno;\r\nerror = xfs_da_node_create(args,\r\n(args->whichfork == XFS_DATA_FORK) ? mp->m_dirleafblk : 0,\r\nbe16_to_cpu(node->hdr.level) + 1, &bp, args->whichfork);\r\nif (error)\r\nreturn(error);\r\nnode = bp->b_addr;\r\nnode->btree[0].hashval = cpu_to_be32(blk1->hashval);\r\nnode->btree[0].before = cpu_to_be32(blk1->blkno);\r\nnode->btree[1].hashval = cpu_to_be32(blk2->hashval);\r\nnode->btree[1].before = cpu_to_be32(blk2->blkno);\r\nnode->hdr.count = cpu_to_be16(2);\r\n#ifdef DEBUG\r\nif (oldroot->hdr.info.magic == cpu_to_be16(XFS_DIR2_LEAFN_MAGIC)) {\r\nASSERT(blk1->blkno >= mp->m_dirleafblk &&\r\nblk1->blkno < mp->m_dirfreeblk);\r\nASSERT(blk2->blkno >= mp->m_dirleafblk &&\r\nblk2->blkno < mp->m_dirfreeblk);\r\n}\r\n#endif\r\nxfs_trans_log_buf(tp, bp,\r\nXFS_DA_LOGRANGE(node, node->btree,\r\nsizeof(xfs_da_node_entry_t) * 2));\r\nreturn(0);\r\n}\r\nSTATIC int\r\nxfs_da_node_split(xfs_da_state_t *state, xfs_da_state_blk_t *oldblk,\r\nxfs_da_state_blk_t *newblk,\r\nxfs_da_state_blk_t *addblk,\r\nint treelevel, int *result)\r\n{\r\nxfs_da_intnode_t *node;\r\nxfs_dablk_t blkno;\r\nint newcount, error;\r\nint useextra;\r\ntrace_xfs_da_node_split(state->args);\r\nnode = oldblk->bp->b_addr;\r\nASSERT(node->hdr.info.magic == cpu_to_be16(XFS_DA_NODE_MAGIC));\r\nuseextra = state->extravalid && state->args->whichfork == XFS_ATTR_FORK;\r\nnewcount = 1 + useextra;\r\nif ((be16_to_cpu(node->hdr.count) + newcount) > state->node_ents) {\r\nerror = xfs_da_grow_inode(state->args, &blkno);\r\nif (error)\r\nreturn(error);\r\nerror = xfs_da_node_create(state->args, blkno, treelevel,\r\n&newblk->bp, state->args->whichfork);\r\nif (error)\r\nreturn(error);\r\nnewblk->blkno = blkno;\r\nnewblk->magic = XFS_DA_NODE_MAGIC;\r\nxfs_da_node_rebalance(state, oldblk, newblk);\r\nerror = xfs_da_blk_link(state, oldblk, newblk);\r\nif (error)\r\nreturn(error);\r\n*result = 1;\r\n} else {\r\n*result = 0;\r\n}\r\nnode = oldblk->bp->b_addr;\r\nif (oldblk->index <= be16_to_cpu(node->hdr.count)) {\r\noldblk->index++;\r\nxfs_da_node_add(state, oldblk, addblk);\r\nif (useextra) {\r\nif (state->extraafter)\r\noldblk->index++;\r\nxfs_da_node_add(state, oldblk, &state->extrablk);\r\nstate->extravalid = 0;\r\n}\r\n} else {\r\nnewblk->index++;\r\nxfs_da_node_add(state, newblk, addblk);\r\nif (useextra) {\r\nif (state->extraafter)\r\nnewblk->index++;\r\nxfs_da_node_add(state, newblk, &state->extrablk);\r\nstate->extravalid = 0;\r\n}\r\n}\r\nreturn(0);\r\n}\r\nSTATIC void\r\nxfs_da_node_rebalance(xfs_da_state_t *state, xfs_da_state_blk_t *blk1,\r\nxfs_da_state_blk_t *blk2)\r\n{\r\nxfs_da_intnode_t *node1, *node2, *tmpnode;\r\nxfs_da_node_entry_t *btree_s, *btree_d;\r\nint count, tmp;\r\nxfs_trans_t *tp;\r\ntrace_xfs_da_node_rebalance(state->args);\r\nnode1 = blk1->bp->b_addr;\r\nnode2 = blk2->bp->b_addr;\r\nif ((be16_to_cpu(node1->hdr.count) > 0) && (be16_to_cpu(node2->hdr.count) > 0) &&\r\n((be32_to_cpu(node2->btree[0].hashval) < be32_to_cpu(node1->btree[0].hashval)) ||\r\n(be32_to_cpu(node2->btree[be16_to_cpu(node2->hdr.count)-1].hashval) <\r\nbe32_to_cpu(node1->btree[be16_to_cpu(node1->hdr.count)-1].hashval)))) {\r\ntmpnode = node1;\r\nnode1 = node2;\r\nnode2 = tmpnode;\r\n}\r\nASSERT(node1->hdr.info.magic == cpu_to_be16(XFS_DA_NODE_MAGIC));\r\nASSERT(node2->hdr.info.magic == cpu_to_be16(XFS_DA_NODE_MAGIC));\r\ncount = (be16_to_cpu(node1->hdr.count) - be16_to_cpu(node2->hdr.count)) / 2;\r\nif (count == 0)\r\nreturn;\r\ntp = state->args->trans;\r\nif (count > 0) {\r\nif ((tmp = be16_to_cpu(node2->hdr.count)) > 0) {\r\ntmp *= (uint)sizeof(xfs_da_node_entry_t);\r\nbtree_s = &node2->btree[0];\r\nbtree_d = &node2->btree[count];\r\nmemmove(btree_d, btree_s, tmp);\r\n}\r\nbe16_add_cpu(&node2->hdr.count, count);\r\ntmp = count * (uint)sizeof(xfs_da_node_entry_t);\r\nbtree_s = &node1->btree[be16_to_cpu(node1->hdr.count) - count];\r\nbtree_d = &node2->btree[0];\r\nmemcpy(btree_d, btree_s, tmp);\r\nbe16_add_cpu(&node1->hdr.count, -count);\r\n} else {\r\ncount = -count;\r\ntmp = count * (uint)sizeof(xfs_da_node_entry_t);\r\nbtree_s = &node2->btree[0];\r\nbtree_d = &node1->btree[be16_to_cpu(node1->hdr.count)];\r\nmemcpy(btree_d, btree_s, tmp);\r\nbe16_add_cpu(&node1->hdr.count, count);\r\nxfs_trans_log_buf(tp, blk1->bp,\r\nXFS_DA_LOGRANGE(node1, btree_d, tmp));\r\ntmp = be16_to_cpu(node2->hdr.count) - count;\r\ntmp *= (uint)sizeof(xfs_da_node_entry_t);\r\nbtree_s = &node2->btree[count];\r\nbtree_d = &node2->btree[0];\r\nmemmove(btree_d, btree_s, tmp);\r\nbe16_add_cpu(&node2->hdr.count, -count);\r\n}\r\nxfs_trans_log_buf(tp, blk1->bp,\r\nXFS_DA_LOGRANGE(node1, &node1->hdr, sizeof(node1->hdr)));\r\nxfs_trans_log_buf(tp, blk2->bp,\r\nXFS_DA_LOGRANGE(node2, &node2->hdr,\r\nsizeof(node2->hdr) +\r\nsizeof(node2->btree[0]) * be16_to_cpu(node2->hdr.count)));\r\nnode1 = blk1->bp->b_addr;\r\nnode2 = blk2->bp->b_addr;\r\nblk1->hashval = be32_to_cpu(node1->btree[be16_to_cpu(node1->hdr.count)-1].hashval);\r\nblk2->hashval = be32_to_cpu(node2->btree[be16_to_cpu(node2->hdr.count)-1].hashval);\r\nif (blk1->index >= be16_to_cpu(node1->hdr.count)) {\r\nblk2->index = blk1->index - be16_to_cpu(node1->hdr.count);\r\nblk1->index = be16_to_cpu(node1->hdr.count) + 1;\r\n}\r\n}\r\nSTATIC void\r\nxfs_da_node_add(xfs_da_state_t *state, xfs_da_state_blk_t *oldblk,\r\nxfs_da_state_blk_t *newblk)\r\n{\r\nxfs_da_intnode_t *node;\r\nxfs_da_node_entry_t *btree;\r\nint tmp;\r\ntrace_xfs_da_node_add(state->args);\r\nnode = oldblk->bp->b_addr;\r\nASSERT(node->hdr.info.magic == cpu_to_be16(XFS_DA_NODE_MAGIC));\r\nASSERT((oldblk->index >= 0) && (oldblk->index <= be16_to_cpu(node->hdr.count)));\r\nASSERT(newblk->blkno != 0);\r\nif (state->args->whichfork == XFS_DATA_FORK)\r\nASSERT(newblk->blkno >= state->mp->m_dirleafblk &&\r\nnewblk->blkno < state->mp->m_dirfreeblk);\r\ntmp = 0;\r\nbtree = &node->btree[ oldblk->index ];\r\nif (oldblk->index < be16_to_cpu(node->hdr.count)) {\r\ntmp = (be16_to_cpu(node->hdr.count) - oldblk->index) * (uint)sizeof(*btree);\r\nmemmove(btree + 1, btree, tmp);\r\n}\r\nbtree->hashval = cpu_to_be32(newblk->hashval);\r\nbtree->before = cpu_to_be32(newblk->blkno);\r\nxfs_trans_log_buf(state->args->trans, oldblk->bp,\r\nXFS_DA_LOGRANGE(node, btree, tmp + sizeof(*btree)));\r\nbe16_add_cpu(&node->hdr.count, 1);\r\nxfs_trans_log_buf(state->args->trans, oldblk->bp,\r\nXFS_DA_LOGRANGE(node, &node->hdr, sizeof(node->hdr)));\r\noldblk->hashval = be32_to_cpu(node->btree[be16_to_cpu(node->hdr.count)-1 ].hashval);\r\n}\r\nint\r\nxfs_da_join(xfs_da_state_t *state)\r\n{\r\nxfs_da_state_blk_t *drop_blk, *save_blk;\r\nint action, error;\r\ntrace_xfs_da_join(state->args);\r\naction = 0;\r\ndrop_blk = &state->path.blk[ state->path.active-1 ];\r\nsave_blk = &state->altpath.blk[ state->path.active-1 ];\r\nASSERT(state->path.blk[0].magic == XFS_DA_NODE_MAGIC);\r\nASSERT(drop_blk->magic == XFS_ATTR_LEAF_MAGIC ||\r\ndrop_blk->magic == XFS_DIR2_LEAFN_MAGIC);\r\nfor ( ; state->path.active >= 2; drop_blk--, save_blk--,\r\nstate->path.active--) {\r\nswitch (drop_blk->magic) {\r\ncase XFS_ATTR_LEAF_MAGIC:\r\nerror = xfs_attr_leaf_toosmall(state, &action);\r\nif (error)\r\nreturn(error);\r\nif (action == 0)\r\nreturn(0);\r\nxfs_attr_leaf_unbalance(state, drop_blk, save_blk);\r\nbreak;\r\ncase XFS_DIR2_LEAFN_MAGIC:\r\nerror = xfs_dir2_leafn_toosmall(state, &action);\r\nif (error)\r\nreturn error;\r\nif (action == 0)\r\nreturn 0;\r\nxfs_dir2_leafn_unbalance(state, drop_blk, save_blk);\r\nbreak;\r\ncase XFS_DA_NODE_MAGIC:\r\nxfs_da_node_remove(state, drop_blk);\r\nxfs_da_fixhashpath(state, &state->path);\r\nerror = xfs_da_node_toosmall(state, &action);\r\nif (error)\r\nreturn(error);\r\nif (action == 0)\r\nreturn 0;\r\nxfs_da_node_unbalance(state, drop_blk, save_blk);\r\nbreak;\r\n}\r\nxfs_da_fixhashpath(state, &state->altpath);\r\nerror = xfs_da_blk_unlink(state, drop_blk, save_blk);\r\nxfs_da_state_kill_altpath(state);\r\nif (error)\r\nreturn(error);\r\nerror = xfs_da_shrink_inode(state->args, drop_blk->blkno,\r\ndrop_blk->bp);\r\ndrop_blk->bp = NULL;\r\nif (error)\r\nreturn(error);\r\n}\r\nxfs_da_node_remove(state, drop_blk);\r\nxfs_da_fixhashpath(state, &state->path);\r\nerror = xfs_da_root_join(state, &state->path.blk[0]);\r\nreturn(error);\r\n}\r\nstatic void\r\nxfs_da_blkinfo_onlychild_validate(struct xfs_da_blkinfo *blkinfo, __u16 level)\r\n{\r\n__be16 magic = blkinfo->magic;\r\nif (level == 1) {\r\nASSERT(magic == cpu_to_be16(XFS_DIR2_LEAFN_MAGIC) ||\r\nmagic == cpu_to_be16(XFS_ATTR_LEAF_MAGIC));\r\n} else\r\nASSERT(magic == cpu_to_be16(XFS_DA_NODE_MAGIC));\r\nASSERT(!blkinfo->forw);\r\nASSERT(!blkinfo->back);\r\n}\r\nSTATIC int\r\nxfs_da_root_join(xfs_da_state_t *state, xfs_da_state_blk_t *root_blk)\r\n{\r\nxfs_da_intnode_t *oldroot;\r\nxfs_da_args_t *args;\r\nxfs_dablk_t child;\r\nstruct xfs_buf *bp;\r\nint error;\r\ntrace_xfs_da_root_join(state->args);\r\nargs = state->args;\r\nASSERT(args != NULL);\r\nASSERT(root_blk->magic == XFS_DA_NODE_MAGIC);\r\noldroot = root_blk->bp->b_addr;\r\nASSERT(oldroot->hdr.info.magic == cpu_to_be16(XFS_DA_NODE_MAGIC));\r\nASSERT(!oldroot->hdr.info.forw);\r\nASSERT(!oldroot->hdr.info.back);\r\nif (be16_to_cpu(oldroot->hdr.count) > 1)\r\nreturn(0);\r\nchild = be32_to_cpu(oldroot->btree[0].before);\r\nASSERT(child != 0);\r\nerror = xfs_da_node_read(args->trans, args->dp, child, -1, &bp,\r\nargs->whichfork);\r\nif (error)\r\nreturn(error);\r\nASSERT(bp != NULL);\r\nxfs_da_blkinfo_onlychild_validate(bp->b_addr,\r\nbe16_to_cpu(oldroot->hdr.level));\r\nmemcpy(root_blk->bp->b_addr, bp->b_addr, state->blocksize);\r\nroot_blk->bp->b_ops = bp->b_ops;\r\nxfs_trans_log_buf(args->trans, root_blk->bp, 0, state->blocksize - 1);\r\nerror = xfs_da_shrink_inode(args, child, bp);\r\nreturn(error);\r\n}\r\nSTATIC int\r\nxfs_da_node_toosmall(xfs_da_state_t *state, int *action)\r\n{\r\nxfs_da_intnode_t *node;\r\nxfs_da_state_blk_t *blk;\r\nxfs_da_blkinfo_t *info;\r\nint count, forward, error, retval, i;\r\nxfs_dablk_t blkno;\r\nstruct xfs_buf *bp;\r\ntrace_xfs_da_node_toosmall(state->args);\r\nblk = &state->path.blk[ state->path.active-1 ];\r\ninfo = blk->bp->b_addr;\r\nASSERT(info->magic == cpu_to_be16(XFS_DA_NODE_MAGIC));\r\nnode = (xfs_da_intnode_t *)info;\r\ncount = be16_to_cpu(node->hdr.count);\r\nif (count > (state->node_ents >> 1)) {\r\n*action = 0;\r\nreturn(0);\r\n}\r\nif (count == 0) {\r\nforward = (info->forw != 0);\r\nmemcpy(&state->altpath, &state->path, sizeof(state->path));\r\nerror = xfs_da_path_shift(state, &state->altpath, forward,\r\n0, &retval);\r\nif (error)\r\nreturn(error);\r\nif (retval) {\r\n*action = 0;\r\n} else {\r\n*action = 2;\r\n}\r\nreturn(0);\r\n}\r\nforward = (be32_to_cpu(info->forw) < be32_to_cpu(info->back));\r\nfor (i = 0; i < 2; forward = !forward, i++) {\r\nif (forward)\r\nblkno = be32_to_cpu(info->forw);\r\nelse\r\nblkno = be32_to_cpu(info->back);\r\nif (blkno == 0)\r\ncontinue;\r\nerror = xfs_da_node_read(state->args->trans, state->args->dp,\r\nblkno, -1, &bp, state->args->whichfork);\r\nif (error)\r\nreturn(error);\r\nASSERT(bp != NULL);\r\nnode = (xfs_da_intnode_t *)info;\r\ncount = state->node_ents;\r\ncount -= state->node_ents >> 2;\r\ncount -= be16_to_cpu(node->hdr.count);\r\nnode = bp->b_addr;\r\nASSERT(node->hdr.info.magic == cpu_to_be16(XFS_DA_NODE_MAGIC));\r\ncount -= be16_to_cpu(node->hdr.count);\r\nxfs_trans_brelse(state->args->trans, bp);\r\nif (count >= 0)\r\nbreak;\r\n}\r\nif (i >= 2) {\r\n*action = 0;\r\nreturn(0);\r\n}\r\nmemcpy(&state->altpath, &state->path, sizeof(state->path));\r\nif (blkno < blk->blkno) {\r\nerror = xfs_da_path_shift(state, &state->altpath, forward,\r\n0, &retval);\r\nif (error) {\r\nreturn(error);\r\n}\r\nif (retval) {\r\n*action = 0;\r\nreturn(0);\r\n}\r\n} else {\r\nerror = xfs_da_path_shift(state, &state->path, forward,\r\n0, &retval);\r\nif (error) {\r\nreturn(error);\r\n}\r\nif (retval) {\r\n*action = 0;\r\nreturn(0);\r\n}\r\n}\r\n*action = 1;\r\nreturn(0);\r\n}\r\nvoid\r\nxfs_da_fixhashpath(xfs_da_state_t *state, xfs_da_state_path_t *path)\r\n{\r\nxfs_da_state_blk_t *blk;\r\nxfs_da_intnode_t *node;\r\nxfs_da_node_entry_t *btree;\r\nxfs_dahash_t lasthash=0;\r\nint level, count;\r\ntrace_xfs_da_fixhashpath(state->args);\r\nlevel = path->active-1;\r\nblk = &path->blk[ level ];\r\nswitch (blk->magic) {\r\ncase XFS_ATTR_LEAF_MAGIC:\r\nlasthash = xfs_attr_leaf_lasthash(blk->bp, &count);\r\nif (count == 0)\r\nreturn;\r\nbreak;\r\ncase XFS_DIR2_LEAFN_MAGIC:\r\nlasthash = xfs_dir2_leafn_lasthash(blk->bp, &count);\r\nif (count == 0)\r\nreturn;\r\nbreak;\r\ncase XFS_DA_NODE_MAGIC:\r\nlasthash = xfs_da_node_lasthash(blk->bp, &count);\r\nif (count == 0)\r\nreturn;\r\nbreak;\r\n}\r\nfor (blk--, level--; level >= 0; blk--, level--) {\r\nnode = blk->bp->b_addr;\r\nASSERT(node->hdr.info.magic == cpu_to_be16(XFS_DA_NODE_MAGIC));\r\nbtree = &node->btree[ blk->index ];\r\nif (be32_to_cpu(btree->hashval) == lasthash)\r\nbreak;\r\nblk->hashval = lasthash;\r\nbtree->hashval = cpu_to_be32(lasthash);\r\nxfs_trans_log_buf(state->args->trans, blk->bp,\r\nXFS_DA_LOGRANGE(node, btree, sizeof(*btree)));\r\nlasthash = be32_to_cpu(node->btree[be16_to_cpu(node->hdr.count)-1].hashval);\r\n}\r\n}\r\nSTATIC void\r\nxfs_da_node_remove(xfs_da_state_t *state, xfs_da_state_blk_t *drop_blk)\r\n{\r\nxfs_da_intnode_t *node;\r\nxfs_da_node_entry_t *btree;\r\nint tmp;\r\ntrace_xfs_da_node_remove(state->args);\r\nnode = drop_blk->bp->b_addr;\r\nASSERT(drop_blk->index < be16_to_cpu(node->hdr.count));\r\nASSERT(drop_blk->index >= 0);\r\nbtree = &node->btree[drop_blk->index];\r\nif (drop_blk->index < (be16_to_cpu(node->hdr.count)-1)) {\r\ntmp = be16_to_cpu(node->hdr.count) - drop_blk->index - 1;\r\ntmp *= (uint)sizeof(xfs_da_node_entry_t);\r\nmemmove(btree, btree + 1, tmp);\r\nxfs_trans_log_buf(state->args->trans, drop_blk->bp,\r\nXFS_DA_LOGRANGE(node, btree, tmp));\r\nbtree = &node->btree[be16_to_cpu(node->hdr.count)-1];\r\n}\r\nmemset((char *)btree, 0, sizeof(xfs_da_node_entry_t));\r\nxfs_trans_log_buf(state->args->trans, drop_blk->bp,\r\nXFS_DA_LOGRANGE(node, btree, sizeof(*btree)));\r\nbe16_add_cpu(&node->hdr.count, -1);\r\nxfs_trans_log_buf(state->args->trans, drop_blk->bp,\r\nXFS_DA_LOGRANGE(node, &node->hdr, sizeof(node->hdr)));\r\nbtree--;\r\ndrop_blk->hashval = be32_to_cpu(btree->hashval);\r\n}\r\nSTATIC void\r\nxfs_da_node_unbalance(xfs_da_state_t *state, xfs_da_state_blk_t *drop_blk,\r\nxfs_da_state_blk_t *save_blk)\r\n{\r\nxfs_da_intnode_t *drop_node, *save_node;\r\nxfs_da_node_entry_t *btree;\r\nint tmp;\r\nxfs_trans_t *tp;\r\ntrace_xfs_da_node_unbalance(state->args);\r\ndrop_node = drop_blk->bp->b_addr;\r\nsave_node = save_blk->bp->b_addr;\r\nASSERT(drop_node->hdr.info.magic == cpu_to_be16(XFS_DA_NODE_MAGIC));\r\nASSERT(save_node->hdr.info.magic == cpu_to_be16(XFS_DA_NODE_MAGIC));\r\ntp = state->args->trans;\r\nif ((be32_to_cpu(drop_node->btree[0].hashval) < be32_to_cpu(save_node->btree[ 0 ].hashval)) ||\r\n(be32_to_cpu(drop_node->btree[be16_to_cpu(drop_node->hdr.count)-1].hashval) <\r\nbe32_to_cpu(save_node->btree[be16_to_cpu(save_node->hdr.count)-1].hashval)))\r\n{\r\nbtree = &save_node->btree[be16_to_cpu(drop_node->hdr.count)];\r\ntmp = be16_to_cpu(save_node->hdr.count) * (uint)sizeof(xfs_da_node_entry_t);\r\nmemmove(btree, &save_node->btree[0], tmp);\r\nbtree = &save_node->btree[0];\r\nxfs_trans_log_buf(tp, save_blk->bp,\r\nXFS_DA_LOGRANGE(save_node, btree,\r\n(be16_to_cpu(save_node->hdr.count) + be16_to_cpu(drop_node->hdr.count)) *\r\nsizeof(xfs_da_node_entry_t)));\r\n} else {\r\nbtree = &save_node->btree[be16_to_cpu(save_node->hdr.count)];\r\nxfs_trans_log_buf(tp, save_blk->bp,\r\nXFS_DA_LOGRANGE(save_node, btree,\r\nbe16_to_cpu(drop_node->hdr.count) *\r\nsizeof(xfs_da_node_entry_t)));\r\n}\r\ntmp = be16_to_cpu(drop_node->hdr.count) * (uint)sizeof(xfs_da_node_entry_t);\r\nmemcpy(btree, &drop_node->btree[0], tmp);\r\nbe16_add_cpu(&save_node->hdr.count, be16_to_cpu(drop_node->hdr.count));\r\nxfs_trans_log_buf(tp, save_blk->bp,\r\nXFS_DA_LOGRANGE(save_node, &save_node->hdr,\r\nsizeof(save_node->hdr)));\r\nsave_blk->hashval = be32_to_cpu(save_node->btree[be16_to_cpu(save_node->hdr.count)-1].hashval);\r\n}\r\nint\r\nxfs_da_node_lookup_int(xfs_da_state_t *state, int *result)\r\n{\r\nxfs_da_state_blk_t *blk;\r\nxfs_da_blkinfo_t *curr;\r\nxfs_da_intnode_t *node;\r\nxfs_da_node_entry_t *btree;\r\nxfs_dablk_t blkno;\r\nint probe, span, max, error, retval;\r\nxfs_dahash_t hashval, btreehashval;\r\nxfs_da_args_t *args;\r\nargs = state->args;\r\nblkno = (args->whichfork == XFS_DATA_FORK)? state->mp->m_dirleafblk : 0;\r\nfor (blk = &state->path.blk[0], state->path.active = 1;\r\nstate->path.active <= XFS_DA_NODE_MAXDEPTH;\r\nblk++, state->path.active++) {\r\nblk->blkno = blkno;\r\nerror = xfs_da_node_read(args->trans, args->dp, blkno,\r\n-1, &blk->bp, args->whichfork);\r\nif (error) {\r\nblk->blkno = 0;\r\nstate->path.active--;\r\nreturn(error);\r\n}\r\ncurr = blk->bp->b_addr;\r\nblk->magic = be16_to_cpu(curr->magic);\r\nASSERT(blk->magic == XFS_DA_NODE_MAGIC ||\r\nblk->magic == XFS_DIR2_LEAFN_MAGIC ||\r\nblk->magic == XFS_ATTR_LEAF_MAGIC);\r\nif (blk->magic == XFS_DA_NODE_MAGIC) {\r\nnode = blk->bp->b_addr;\r\nmax = be16_to_cpu(node->hdr.count);\r\nblk->hashval = be32_to_cpu(node->btree[max-1].hashval);\r\nprobe = span = max / 2;\r\nhashval = args->hashval;\r\nfor (btree = &node->btree[probe]; span > 4;\r\nbtree = &node->btree[probe]) {\r\nspan /= 2;\r\nbtreehashval = be32_to_cpu(btree->hashval);\r\nif (btreehashval < hashval)\r\nprobe += span;\r\nelse if (btreehashval > hashval)\r\nprobe -= span;\r\nelse\r\nbreak;\r\n}\r\nASSERT((probe >= 0) && (probe < max));\r\nASSERT((span <= 4) || (be32_to_cpu(btree->hashval) == hashval));\r\nwhile ((probe > 0) && (be32_to_cpu(btree->hashval) >= hashval)) {\r\nbtree--;\r\nprobe--;\r\n}\r\nwhile ((probe < max) && (be32_to_cpu(btree->hashval) < hashval)) {\r\nbtree++;\r\nprobe++;\r\n}\r\nif (probe == max) {\r\nblk->index = max-1;\r\nblkno = be32_to_cpu(node->btree[max-1].before);\r\n} else {\r\nblk->index = probe;\r\nblkno = be32_to_cpu(btree->before);\r\n}\r\n} else if (blk->magic == XFS_ATTR_LEAF_MAGIC) {\r\nblk->hashval = xfs_attr_leaf_lasthash(blk->bp, NULL);\r\nbreak;\r\n} else if (blk->magic == XFS_DIR2_LEAFN_MAGIC) {\r\nblk->hashval = xfs_dir2_leafn_lasthash(blk->bp, NULL);\r\nbreak;\r\n}\r\n}\r\nfor (;;) {\r\nif (blk->magic == XFS_DIR2_LEAFN_MAGIC) {\r\nretval = xfs_dir2_leafn_lookup_int(blk->bp, args,\r\n&blk->index, state);\r\n} else if (blk->magic == XFS_ATTR_LEAF_MAGIC) {\r\nretval = xfs_attr_leaf_lookup_int(blk->bp, args);\r\nblk->index = args->index;\r\nargs->blkno = blk->blkno;\r\n} else {\r\nASSERT(0);\r\nreturn XFS_ERROR(EFSCORRUPTED);\r\n}\r\nif (((retval == ENOENT) || (retval == ENOATTR)) &&\r\n(blk->hashval == args->hashval)) {\r\nerror = xfs_da_path_shift(state, &state->path, 1, 1,\r\n&retval);\r\nif (error)\r\nreturn(error);\r\nif (retval == 0) {\r\ncontinue;\r\n} else if (blk->magic == XFS_ATTR_LEAF_MAGIC) {\r\nretval = XFS_ERROR(ENOATTR);\r\n}\r\n}\r\nbreak;\r\n}\r\n*result = retval;\r\nreturn(0);\r\n}\r\nint\r\nxfs_da_blk_link(xfs_da_state_t *state, xfs_da_state_blk_t *old_blk,\r\nxfs_da_state_blk_t *new_blk)\r\n{\r\nxfs_da_blkinfo_t *old_info, *new_info, *tmp_info;\r\nxfs_da_args_t *args;\r\nint before=0, error;\r\nstruct xfs_buf *bp;\r\nargs = state->args;\r\nASSERT(args != NULL);\r\nold_info = old_blk->bp->b_addr;\r\nnew_info = new_blk->bp->b_addr;\r\nASSERT(old_blk->magic == XFS_DA_NODE_MAGIC ||\r\nold_blk->magic == XFS_DIR2_LEAFN_MAGIC ||\r\nold_blk->magic == XFS_ATTR_LEAF_MAGIC);\r\nASSERT(old_blk->magic == be16_to_cpu(old_info->magic));\r\nASSERT(new_blk->magic == be16_to_cpu(new_info->magic));\r\nASSERT(old_blk->magic == new_blk->magic);\r\nswitch (old_blk->magic) {\r\ncase XFS_ATTR_LEAF_MAGIC:\r\nbefore = xfs_attr_leaf_order(old_blk->bp, new_blk->bp);\r\nbreak;\r\ncase XFS_DIR2_LEAFN_MAGIC:\r\nbefore = xfs_dir2_leafn_order(old_blk->bp, new_blk->bp);\r\nbreak;\r\ncase XFS_DA_NODE_MAGIC:\r\nbefore = xfs_da_node_order(old_blk->bp, new_blk->bp);\r\nbreak;\r\n}\r\nif (before) {\r\ntrace_xfs_da_link_before(args);\r\nnew_info->forw = cpu_to_be32(old_blk->blkno);\r\nnew_info->back = old_info->back;\r\nif (old_info->back) {\r\nerror = xfs_da_node_read(args->trans, args->dp,\r\nbe32_to_cpu(old_info->back),\r\n-1, &bp, args->whichfork);\r\nif (error)\r\nreturn(error);\r\nASSERT(bp != NULL);\r\ntmp_info = bp->b_addr;\r\nASSERT(be16_to_cpu(tmp_info->magic) == be16_to_cpu(old_info->magic));\r\nASSERT(be32_to_cpu(tmp_info->forw) == old_blk->blkno);\r\ntmp_info->forw = cpu_to_be32(new_blk->blkno);\r\nxfs_trans_log_buf(args->trans, bp, 0, sizeof(*tmp_info)-1);\r\n}\r\nold_info->back = cpu_to_be32(new_blk->blkno);\r\n} else {\r\ntrace_xfs_da_link_after(args);\r\nnew_info->forw = old_info->forw;\r\nnew_info->back = cpu_to_be32(old_blk->blkno);\r\nif (old_info->forw) {\r\nerror = xfs_da_node_read(args->trans, args->dp,\r\nbe32_to_cpu(old_info->forw),\r\n-1, &bp, args->whichfork);\r\nif (error)\r\nreturn(error);\r\nASSERT(bp != NULL);\r\ntmp_info = bp->b_addr;\r\nASSERT(tmp_info->magic == old_info->magic);\r\nASSERT(be32_to_cpu(tmp_info->back) == old_blk->blkno);\r\ntmp_info->back = cpu_to_be32(new_blk->blkno);\r\nxfs_trans_log_buf(args->trans, bp, 0, sizeof(*tmp_info)-1);\r\n}\r\nold_info->forw = cpu_to_be32(new_blk->blkno);\r\n}\r\nxfs_trans_log_buf(args->trans, old_blk->bp, 0, sizeof(*tmp_info) - 1);\r\nxfs_trans_log_buf(args->trans, new_blk->bp, 0, sizeof(*tmp_info) - 1);\r\nreturn(0);\r\n}\r\nSTATIC int\r\nxfs_da_node_order(\r\nstruct xfs_buf *node1_bp,\r\nstruct xfs_buf *node2_bp)\r\n{\r\nxfs_da_intnode_t *node1, *node2;\r\nnode1 = node1_bp->b_addr;\r\nnode2 = node2_bp->b_addr;\r\nASSERT(node1->hdr.info.magic == cpu_to_be16(XFS_DA_NODE_MAGIC) &&\r\nnode2->hdr.info.magic == cpu_to_be16(XFS_DA_NODE_MAGIC));\r\nif ((be16_to_cpu(node1->hdr.count) > 0) && (be16_to_cpu(node2->hdr.count) > 0) &&\r\n((be32_to_cpu(node2->btree[0].hashval) <\r\nbe32_to_cpu(node1->btree[0].hashval)) ||\r\n(be32_to_cpu(node2->btree[be16_to_cpu(node2->hdr.count)-1].hashval) <\r\nbe32_to_cpu(node1->btree[be16_to_cpu(node1->hdr.count)-1].hashval)))) {\r\nreturn(1);\r\n}\r\nreturn(0);\r\n}\r\nSTATIC uint\r\nxfs_da_node_lasthash(\r\nstruct xfs_buf *bp,\r\nint *count)\r\n{\r\nxfs_da_intnode_t *node;\r\nnode = bp->b_addr;\r\nASSERT(node->hdr.info.magic == cpu_to_be16(XFS_DA_NODE_MAGIC));\r\nif (count)\r\n*count = be16_to_cpu(node->hdr.count);\r\nif (!node->hdr.count)\r\nreturn(0);\r\nreturn be32_to_cpu(node->btree[be16_to_cpu(node->hdr.count)-1].hashval);\r\n}\r\nSTATIC int\r\nxfs_da_blk_unlink(xfs_da_state_t *state, xfs_da_state_blk_t *drop_blk,\r\nxfs_da_state_blk_t *save_blk)\r\n{\r\nxfs_da_blkinfo_t *drop_info, *save_info, *tmp_info;\r\nxfs_da_args_t *args;\r\nstruct xfs_buf *bp;\r\nint error;\r\nargs = state->args;\r\nASSERT(args != NULL);\r\nsave_info = save_blk->bp->b_addr;\r\ndrop_info = drop_blk->bp->b_addr;\r\nASSERT(save_blk->magic == XFS_DA_NODE_MAGIC ||\r\nsave_blk->magic == XFS_DIR2_LEAFN_MAGIC ||\r\nsave_blk->magic == XFS_ATTR_LEAF_MAGIC);\r\nASSERT(save_blk->magic == be16_to_cpu(save_info->magic));\r\nASSERT(drop_blk->magic == be16_to_cpu(drop_info->magic));\r\nASSERT(save_blk->magic == drop_blk->magic);\r\nASSERT((be32_to_cpu(save_info->forw) == drop_blk->blkno) ||\r\n(be32_to_cpu(save_info->back) == drop_blk->blkno));\r\nASSERT((be32_to_cpu(drop_info->forw) == save_blk->blkno) ||\r\n(be32_to_cpu(drop_info->back) == save_blk->blkno));\r\nif (be32_to_cpu(save_info->back) == drop_blk->blkno) {\r\ntrace_xfs_da_unlink_back(args);\r\nsave_info->back = drop_info->back;\r\nif (drop_info->back) {\r\nerror = xfs_da_node_read(args->trans, args->dp,\r\nbe32_to_cpu(drop_info->back),\r\n-1, &bp, args->whichfork);\r\nif (error)\r\nreturn(error);\r\nASSERT(bp != NULL);\r\ntmp_info = bp->b_addr;\r\nASSERT(tmp_info->magic == save_info->magic);\r\nASSERT(be32_to_cpu(tmp_info->forw) == drop_blk->blkno);\r\ntmp_info->forw = cpu_to_be32(save_blk->blkno);\r\nxfs_trans_log_buf(args->trans, bp, 0,\r\nsizeof(*tmp_info) - 1);\r\n}\r\n} else {\r\ntrace_xfs_da_unlink_forward(args);\r\nsave_info->forw = drop_info->forw;\r\nif (drop_info->forw) {\r\nerror = xfs_da_node_read(args->trans, args->dp,\r\nbe32_to_cpu(drop_info->forw),\r\n-1, &bp, args->whichfork);\r\nif (error)\r\nreturn(error);\r\nASSERT(bp != NULL);\r\ntmp_info = bp->b_addr;\r\nASSERT(tmp_info->magic == save_info->magic);\r\nASSERT(be32_to_cpu(tmp_info->back) == drop_blk->blkno);\r\ntmp_info->back = cpu_to_be32(save_blk->blkno);\r\nxfs_trans_log_buf(args->trans, bp, 0,\r\nsizeof(*tmp_info) - 1);\r\n}\r\n}\r\nxfs_trans_log_buf(args->trans, save_blk->bp, 0, sizeof(*save_info) - 1);\r\nreturn(0);\r\n}\r\nint\r\nxfs_da_path_shift(xfs_da_state_t *state, xfs_da_state_path_t *path,\r\nint forward, int release, int *result)\r\n{\r\nxfs_da_state_blk_t *blk;\r\nxfs_da_blkinfo_t *info;\r\nxfs_da_intnode_t *node;\r\nxfs_da_args_t *args;\r\nxfs_dablk_t blkno=0;\r\nint level, error;\r\ntrace_xfs_da_path_shift(state->args);\r\nargs = state->args;\r\nASSERT(args != NULL);\r\nASSERT(path != NULL);\r\nASSERT((path->active > 0) && (path->active < XFS_DA_NODE_MAXDEPTH));\r\nlevel = (path->active-1) - 1;\r\nfor (blk = &path->blk[level]; level >= 0; blk--, level--) {\r\nASSERT(blk->bp != NULL);\r\nnode = blk->bp->b_addr;\r\nASSERT(node->hdr.info.magic == cpu_to_be16(XFS_DA_NODE_MAGIC));\r\nif (forward && (blk->index < be16_to_cpu(node->hdr.count)-1)) {\r\nblk->index++;\r\nblkno = be32_to_cpu(node->btree[blk->index].before);\r\nbreak;\r\n} else if (!forward && (blk->index > 0)) {\r\nblk->index--;\r\nblkno = be32_to_cpu(node->btree[blk->index].before);\r\nbreak;\r\n}\r\n}\r\nif (level < 0) {\r\n*result = XFS_ERROR(ENOENT);\r\nASSERT(args->op_flags & XFS_DA_OP_OKNOENT);\r\nreturn(0);\r\n}\r\nfor (blk++, level++; level < path->active; blk++, level++) {\r\nif (release)\r\nxfs_trans_brelse(args->trans, blk->bp);\r\nblk->blkno = blkno;\r\nerror = xfs_da_node_read(args->trans, args->dp, blkno, -1,\r\n&blk->bp, args->whichfork);\r\nif (error)\r\nreturn(error);\r\nASSERT(blk->bp != NULL);\r\ninfo = blk->bp->b_addr;\r\nASSERT(info->magic == cpu_to_be16(XFS_DA_NODE_MAGIC) ||\r\ninfo->magic == cpu_to_be16(XFS_DIR2_LEAFN_MAGIC) ||\r\ninfo->magic == cpu_to_be16(XFS_ATTR_LEAF_MAGIC));\r\nblk->magic = be16_to_cpu(info->magic);\r\nif (blk->magic == XFS_DA_NODE_MAGIC) {\r\nnode = (xfs_da_intnode_t *)info;\r\nblk->hashval = be32_to_cpu(node->btree[be16_to_cpu(node->hdr.count)-1].hashval);\r\nif (forward)\r\nblk->index = 0;\r\nelse\r\nblk->index = be16_to_cpu(node->hdr.count)-1;\r\nblkno = be32_to_cpu(node->btree[blk->index].before);\r\n} else {\r\nASSERT(level == path->active-1);\r\nblk->index = 0;\r\nswitch(blk->magic) {\r\ncase XFS_ATTR_LEAF_MAGIC:\r\nblk->hashval = xfs_attr_leaf_lasthash(blk->bp,\r\nNULL);\r\nbreak;\r\ncase XFS_DIR2_LEAFN_MAGIC:\r\nblk->hashval = xfs_dir2_leafn_lasthash(blk->bp,\r\nNULL);\r\nbreak;\r\ndefault:\r\nASSERT(blk->magic == XFS_ATTR_LEAF_MAGIC ||\r\nblk->magic == XFS_DIR2_LEAFN_MAGIC);\r\nbreak;\r\n}\r\n}\r\n}\r\n*result = 0;\r\nreturn(0);\r\n}\r\nxfs_dahash_t\r\nxfs_da_hashname(const __uint8_t *name, int namelen)\r\n{\r\nxfs_dahash_t hash;\r\nfor (hash = 0; namelen >= 4; namelen -= 4, name += 4)\r\nhash = (name[0] << 21) ^ (name[1] << 14) ^ (name[2] << 7) ^\r\n(name[3] << 0) ^ rol32(hash, 7 * 4);\r\nswitch (namelen) {\r\ncase 3:\r\nreturn (name[0] << 14) ^ (name[1] << 7) ^ (name[2] << 0) ^\r\nrol32(hash, 7 * 3);\r\ncase 2:\r\nreturn (name[0] << 7) ^ (name[1] << 0) ^ rol32(hash, 7 * 2);\r\ncase 1:\r\nreturn (name[0] << 0) ^ rol32(hash, 7 * 1);\r\ndefault:\r\nreturn hash;\r\n}\r\n}\r\nenum xfs_dacmp\r\nxfs_da_compname(\r\nstruct xfs_da_args *args,\r\nconst unsigned char *name,\r\nint len)\r\n{\r\nreturn (args->namelen == len && memcmp(args->name, name, len) == 0) ?\r\nXFS_CMP_EXACT : XFS_CMP_DIFFERENT;\r\n}\r\nstatic xfs_dahash_t\r\nxfs_default_hashname(\r\nstruct xfs_name *name)\r\n{\r\nreturn xfs_da_hashname(name->name, name->len);\r\n}\r\nint\r\nxfs_da_grow_inode_int(\r\nstruct xfs_da_args *args,\r\nxfs_fileoff_t *bno,\r\nint count)\r\n{\r\nstruct xfs_trans *tp = args->trans;\r\nstruct xfs_inode *dp = args->dp;\r\nint w = args->whichfork;\r\nxfs_drfsbno_t nblks = dp->i_d.di_nblocks;\r\nstruct xfs_bmbt_irec map, *mapp;\r\nint nmap, error, got, i, mapi;\r\nerror = xfs_bmap_first_unused(tp, dp, count, bno, w);\r\nif (error)\r\nreturn error;\r\nnmap = 1;\r\nASSERT(args->firstblock != NULL);\r\nerror = xfs_bmapi_write(tp, dp, *bno, count,\r\nxfs_bmapi_aflag(w)|XFS_BMAPI_METADATA|XFS_BMAPI_CONTIG,\r\nargs->firstblock, args->total, &map, &nmap,\r\nargs->flist);\r\nif (error)\r\nreturn error;\r\nASSERT(nmap <= 1);\r\nif (nmap == 1) {\r\nmapp = &map;\r\nmapi = 1;\r\n} else if (nmap == 0 && count > 1) {\r\nxfs_fileoff_t b;\r\nint c;\r\nmapp = kmem_alloc(sizeof(*mapp) * count, KM_SLEEP);\r\nfor (b = *bno, mapi = 0; b < *bno + count; ) {\r\nnmap = MIN(XFS_BMAP_MAX_NMAP, count);\r\nc = (int)(*bno + count - b);\r\nerror = xfs_bmapi_write(tp, dp, b, c,\r\nxfs_bmapi_aflag(w)|XFS_BMAPI_METADATA,\r\nargs->firstblock, args->total,\r\n&mapp[mapi], &nmap, args->flist);\r\nif (error)\r\ngoto out_free_map;\r\nif (nmap < 1)\r\nbreak;\r\nmapi += nmap;\r\nb = mapp[mapi - 1].br_startoff +\r\nmapp[mapi - 1].br_blockcount;\r\n}\r\n} else {\r\nmapi = 0;\r\nmapp = NULL;\r\n}\r\nfor (i = 0, got = 0; i < mapi; i++)\r\ngot += mapp[i].br_blockcount;\r\nif (got != count || mapp[0].br_startoff != *bno ||\r\nmapp[mapi - 1].br_startoff + mapp[mapi - 1].br_blockcount !=\r\n*bno + count) {\r\nerror = XFS_ERROR(ENOSPC);\r\ngoto out_free_map;\r\n}\r\nargs->total -= dp->i_d.di_nblocks - nblks;\r\nout_free_map:\r\nif (mapp != &map)\r\nkmem_free(mapp);\r\nreturn error;\r\n}\r\nint\r\nxfs_da_grow_inode(\r\nstruct xfs_da_args *args,\r\nxfs_dablk_t *new_blkno)\r\n{\r\nxfs_fileoff_t bno;\r\nint count;\r\nint error;\r\ntrace_xfs_da_grow_inode(args);\r\nif (args->whichfork == XFS_DATA_FORK) {\r\nbno = args->dp->i_mount->m_dirleafblk;\r\ncount = args->dp->i_mount->m_dirblkfsbs;\r\n} else {\r\nbno = 0;\r\ncount = 1;\r\n}\r\nerror = xfs_da_grow_inode_int(args, &bno, count);\r\nif (!error)\r\n*new_blkno = (xfs_dablk_t)bno;\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_da_swap_lastblock(\r\nxfs_da_args_t *args,\r\nxfs_dablk_t *dead_blknop,\r\nstruct xfs_buf **dead_bufp)\r\n{\r\nxfs_dablk_t dead_blkno, last_blkno, sib_blkno, par_blkno;\r\nstruct xfs_buf *dead_buf, *last_buf, *sib_buf, *par_buf;\r\nxfs_fileoff_t lastoff;\r\nxfs_inode_t *ip;\r\nxfs_trans_t *tp;\r\nxfs_mount_t *mp;\r\nint error, w, entno, level, dead_level;\r\nxfs_da_blkinfo_t *dead_info, *sib_info;\r\nxfs_da_intnode_t *par_node, *dead_node;\r\nxfs_dir2_leaf_t *dead_leaf2;\r\nxfs_dahash_t dead_hash;\r\ntrace_xfs_da_swap_lastblock(args);\r\ndead_buf = *dead_bufp;\r\ndead_blkno = *dead_blknop;\r\ntp = args->trans;\r\nip = args->dp;\r\nw = args->whichfork;\r\nASSERT(w == XFS_DATA_FORK);\r\nmp = ip->i_mount;\r\nlastoff = mp->m_dirfreeblk;\r\nerror = xfs_bmap_last_before(tp, ip, &lastoff, w);\r\nif (error)\r\nreturn error;\r\nif (unlikely(lastoff == 0)) {\r\nXFS_ERROR_REPORT("xfs_da_swap_lastblock(1)", XFS_ERRLEVEL_LOW,\r\nmp);\r\nreturn XFS_ERROR(EFSCORRUPTED);\r\n}\r\nlast_blkno = (xfs_dablk_t)lastoff - mp->m_dirblkfsbs;\r\nerror = xfs_da_node_read(tp, ip, last_blkno, -1, &last_buf, w);\r\nif (error)\r\nreturn error;\r\nmemcpy(dead_buf->b_addr, last_buf->b_addr, mp->m_dirblksize);\r\nxfs_trans_log_buf(tp, dead_buf, 0, mp->m_dirblksize - 1);\r\ndead_info = dead_buf->b_addr;\r\nif (dead_info->magic == cpu_to_be16(XFS_DIR2_LEAFN_MAGIC)) {\r\ndead_leaf2 = (xfs_dir2_leaf_t *)dead_info;\r\ndead_level = 0;\r\ndead_hash = be32_to_cpu(dead_leaf2->ents[be16_to_cpu(dead_leaf2->hdr.count) - 1].hashval);\r\n} else {\r\nASSERT(dead_info->magic == cpu_to_be16(XFS_DA_NODE_MAGIC));\r\ndead_node = (xfs_da_intnode_t *)dead_info;\r\ndead_level = be16_to_cpu(dead_node->hdr.level);\r\ndead_hash = be32_to_cpu(dead_node->btree[be16_to_cpu(dead_node->hdr.count) - 1].hashval);\r\n}\r\nsib_buf = par_buf = NULL;\r\nif ((sib_blkno = be32_to_cpu(dead_info->back))) {\r\nerror = xfs_da_node_read(tp, ip, sib_blkno, -1, &sib_buf, w);\r\nif (error)\r\ngoto done;\r\nsib_info = sib_buf->b_addr;\r\nif (unlikely(\r\nbe32_to_cpu(sib_info->forw) != last_blkno ||\r\nsib_info->magic != dead_info->magic)) {\r\nXFS_ERROR_REPORT("xfs_da_swap_lastblock(2)",\r\nXFS_ERRLEVEL_LOW, mp);\r\nerror = XFS_ERROR(EFSCORRUPTED);\r\ngoto done;\r\n}\r\nsib_info->forw = cpu_to_be32(dead_blkno);\r\nxfs_trans_log_buf(tp, sib_buf,\r\nXFS_DA_LOGRANGE(sib_info, &sib_info->forw,\r\nsizeof(sib_info->forw)));\r\nsib_buf = NULL;\r\n}\r\nif ((sib_blkno = be32_to_cpu(dead_info->forw))) {\r\nerror = xfs_da_node_read(tp, ip, sib_blkno, -1, &sib_buf, w);\r\nif (error)\r\ngoto done;\r\nsib_info = sib_buf->b_addr;\r\nif (unlikely(\r\nbe32_to_cpu(sib_info->back) != last_blkno ||\r\nsib_info->magic != dead_info->magic)) {\r\nXFS_ERROR_REPORT("xfs_da_swap_lastblock(3)",\r\nXFS_ERRLEVEL_LOW, mp);\r\nerror = XFS_ERROR(EFSCORRUPTED);\r\ngoto done;\r\n}\r\nsib_info->back = cpu_to_be32(dead_blkno);\r\nxfs_trans_log_buf(tp, sib_buf,\r\nXFS_DA_LOGRANGE(sib_info, &sib_info->back,\r\nsizeof(sib_info->back)));\r\nsib_buf = NULL;\r\n}\r\npar_blkno = mp->m_dirleafblk;\r\nlevel = -1;\r\nfor (;;) {\r\nerror = xfs_da_node_read(tp, ip, par_blkno, -1, &par_buf, w);\r\nif (error)\r\ngoto done;\r\npar_node = par_buf->b_addr;\r\nif (unlikely(par_node->hdr.info.magic !=\r\ncpu_to_be16(XFS_DA_NODE_MAGIC) ||\r\n(level >= 0 && level != be16_to_cpu(par_node->hdr.level) + 1))) {\r\nXFS_ERROR_REPORT("xfs_da_swap_lastblock(4)",\r\nXFS_ERRLEVEL_LOW, mp);\r\nerror = XFS_ERROR(EFSCORRUPTED);\r\ngoto done;\r\n}\r\nlevel = be16_to_cpu(par_node->hdr.level);\r\nfor (entno = 0;\r\nentno < be16_to_cpu(par_node->hdr.count) &&\r\nbe32_to_cpu(par_node->btree[entno].hashval) < dead_hash;\r\nentno++)\r\ncontinue;\r\nif (unlikely(entno == be16_to_cpu(par_node->hdr.count))) {\r\nXFS_ERROR_REPORT("xfs_da_swap_lastblock(5)",\r\nXFS_ERRLEVEL_LOW, mp);\r\nerror = XFS_ERROR(EFSCORRUPTED);\r\ngoto done;\r\n}\r\npar_blkno = be32_to_cpu(par_node->btree[entno].before);\r\nif (level == dead_level + 1)\r\nbreak;\r\nxfs_trans_brelse(tp, par_buf);\r\npar_buf = NULL;\r\n}\r\nfor (;;) {\r\nfor (;\r\nentno < be16_to_cpu(par_node->hdr.count) &&\r\nbe32_to_cpu(par_node->btree[entno].before) != last_blkno;\r\nentno++)\r\ncontinue;\r\nif (entno < be16_to_cpu(par_node->hdr.count))\r\nbreak;\r\npar_blkno = be32_to_cpu(par_node->hdr.info.forw);\r\nxfs_trans_brelse(tp, par_buf);\r\npar_buf = NULL;\r\nif (unlikely(par_blkno == 0)) {\r\nXFS_ERROR_REPORT("xfs_da_swap_lastblock(6)",\r\nXFS_ERRLEVEL_LOW, mp);\r\nerror = XFS_ERROR(EFSCORRUPTED);\r\ngoto done;\r\n}\r\nerror = xfs_da_node_read(tp, ip, par_blkno, -1, &par_buf, w);\r\nif (error)\r\ngoto done;\r\npar_node = par_buf->b_addr;\r\nif (unlikely(\r\nbe16_to_cpu(par_node->hdr.level) != level ||\r\npar_node->hdr.info.magic != cpu_to_be16(XFS_DA_NODE_MAGIC))) {\r\nXFS_ERROR_REPORT("xfs_da_swap_lastblock(7)",\r\nXFS_ERRLEVEL_LOW, mp);\r\nerror = XFS_ERROR(EFSCORRUPTED);\r\ngoto done;\r\n}\r\nentno = 0;\r\n}\r\npar_node->btree[entno].before = cpu_to_be32(dead_blkno);\r\nxfs_trans_log_buf(tp, par_buf,\r\nXFS_DA_LOGRANGE(par_node, &par_node->btree[entno].before,\r\nsizeof(par_node->btree[entno].before)));\r\n*dead_blknop = last_blkno;\r\n*dead_bufp = last_buf;\r\nreturn 0;\r\ndone:\r\nif (par_buf)\r\nxfs_trans_brelse(tp, par_buf);\r\nif (sib_buf)\r\nxfs_trans_brelse(tp, sib_buf);\r\nxfs_trans_brelse(tp, last_buf);\r\nreturn error;\r\n}\r\nint\r\nxfs_da_shrink_inode(\r\nxfs_da_args_t *args,\r\nxfs_dablk_t dead_blkno,\r\nstruct xfs_buf *dead_buf)\r\n{\r\nxfs_inode_t *dp;\r\nint done, error, w, count;\r\nxfs_trans_t *tp;\r\nxfs_mount_t *mp;\r\ntrace_xfs_da_shrink_inode(args);\r\ndp = args->dp;\r\nw = args->whichfork;\r\ntp = args->trans;\r\nmp = dp->i_mount;\r\nif (w == XFS_DATA_FORK)\r\ncount = mp->m_dirblkfsbs;\r\nelse\r\ncount = 1;\r\nfor (;;) {\r\nif ((error = xfs_bunmapi(tp, dp, dead_blkno, count,\r\nxfs_bmapi_aflag(w)|XFS_BMAPI_METADATA,\r\n0, args->firstblock, args->flist,\r\n&done)) == ENOSPC) {\r\nif (w != XFS_DATA_FORK)\r\nbreak;\r\nif ((error = xfs_da_swap_lastblock(args, &dead_blkno,\r\n&dead_buf)))\r\nbreak;\r\n} else {\r\nbreak;\r\n}\r\n}\r\nxfs_trans_binval(tp, dead_buf);\r\nreturn error;\r\n}\r\nSTATIC int\r\nxfs_da_map_covers_blocks(\r\nint nmap,\r\nxfs_bmbt_irec_t *mapp,\r\nxfs_dablk_t bno,\r\nint count)\r\n{\r\nint i;\r\nxfs_fileoff_t off;\r\nfor (i = 0, off = bno; i < nmap; i++) {\r\nif (mapp[i].br_startblock == HOLESTARTBLOCK ||\r\nmapp[i].br_startblock == DELAYSTARTBLOCK) {\r\nreturn 0;\r\n}\r\nif (off != mapp[i].br_startoff) {\r\nreturn 0;\r\n}\r\noff += mapp[i].br_blockcount;\r\n}\r\nreturn off == bno + count;\r\n}\r\nstatic int\r\nxfs_buf_map_from_irec(\r\nstruct xfs_mount *mp,\r\nstruct xfs_buf_map **mapp,\r\nunsigned int *nmaps,\r\nstruct xfs_bmbt_irec *irecs,\r\nunsigned int nirecs)\r\n{\r\nstruct xfs_buf_map *map;\r\nint i;\r\nASSERT(*nmaps == 1);\r\nASSERT(nirecs >= 1);\r\nif (nirecs > 1) {\r\nmap = kmem_zalloc(nirecs * sizeof(struct xfs_buf_map), KM_SLEEP);\r\nif (!map)\r\nreturn ENOMEM;\r\n*mapp = map;\r\n}\r\n*nmaps = nirecs;\r\nmap = *mapp;\r\nfor (i = 0; i < *nmaps; i++) {\r\nASSERT(irecs[i].br_startblock != DELAYSTARTBLOCK &&\r\nirecs[i].br_startblock != HOLESTARTBLOCK);\r\nmap[i].bm_bn = XFS_FSB_TO_DADDR(mp, irecs[i].br_startblock);\r\nmap[i].bm_len = XFS_FSB_TO_BB(mp, irecs[i].br_blockcount);\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\nxfs_dabuf_map(\r\nstruct xfs_trans *trans,\r\nstruct xfs_inode *dp,\r\nxfs_dablk_t bno,\r\nxfs_daddr_t mappedbno,\r\nint whichfork,\r\nstruct xfs_buf_map **map,\r\nint *nmaps)\r\n{\r\nstruct xfs_mount *mp = dp->i_mount;\r\nint nfsb;\r\nint error = 0;\r\nstruct xfs_bmbt_irec irec;\r\nstruct xfs_bmbt_irec *irecs = &irec;\r\nint nirecs;\r\nASSERT(map && *map);\r\nASSERT(*nmaps == 1);\r\nnfsb = (whichfork == XFS_DATA_FORK) ? mp->m_dirblkfsbs : 1;\r\nif (mappedbno == -1 || mappedbno == -2) {\r\nif (nfsb != 1)\r\nirecs = kmem_zalloc(sizeof(irec) * nfsb, KM_SLEEP);\r\nnirecs = nfsb;\r\nerror = xfs_bmapi_read(dp, (xfs_fileoff_t)bno, nfsb, irecs,\r\n&nirecs, xfs_bmapi_aflag(whichfork));\r\nif (error)\r\ngoto out;\r\n} else {\r\nirecs->br_startblock = XFS_DADDR_TO_FSB(mp, mappedbno);\r\nirecs->br_startoff = (xfs_fileoff_t)bno;\r\nirecs->br_blockcount = nfsb;\r\nirecs->br_state = 0;\r\nnirecs = 1;\r\n}\r\nif (!xfs_da_map_covers_blocks(nirecs, irecs, bno, nfsb)) {\r\nerror = mappedbno == -2 ? -1 : XFS_ERROR(EFSCORRUPTED);\r\nif (unlikely(error == EFSCORRUPTED)) {\r\nif (xfs_error_level >= XFS_ERRLEVEL_LOW) {\r\nint i;\r\nxfs_alert(mp, "%s: bno %lld dir: inode %lld",\r\n__func__, (long long)bno,\r\n(long long)dp->i_ino);\r\nfor (i = 0; i < *nmaps; i++) {\r\nxfs_alert(mp,\r\n"[%02d] br_startoff %lld br_startblock %lld br_blockcount %lld br_state %d",\r\ni,\r\n(long long)irecs[i].br_startoff,\r\n(long long)irecs[i].br_startblock,\r\n(long long)irecs[i].br_blockcount,\r\nirecs[i].br_state);\r\n}\r\n}\r\nXFS_ERROR_REPORT("xfs_da_do_buf(1)",\r\nXFS_ERRLEVEL_LOW, mp);\r\n}\r\ngoto out;\r\n}\r\nerror = xfs_buf_map_from_irec(mp, map, nmaps, irecs, nirecs);\r\nout:\r\nif (irecs != &irec)\r\nkmem_free(irecs);\r\nreturn error;\r\n}\r\nint\r\nxfs_da_get_buf(\r\nstruct xfs_trans *trans,\r\nstruct xfs_inode *dp,\r\nxfs_dablk_t bno,\r\nxfs_daddr_t mappedbno,\r\nstruct xfs_buf **bpp,\r\nint whichfork)\r\n{\r\nstruct xfs_buf *bp;\r\nstruct xfs_buf_map map;\r\nstruct xfs_buf_map *mapp;\r\nint nmap;\r\nint error;\r\n*bpp = NULL;\r\nmapp = &map;\r\nnmap = 1;\r\nerror = xfs_dabuf_map(trans, dp, bno, mappedbno, whichfork,\r\n&mapp, &nmap);\r\nif (error) {\r\nif (error == -1)\r\nerror = 0;\r\ngoto out_free;\r\n}\r\nbp = xfs_trans_get_buf_map(trans, dp->i_mount->m_ddev_targp,\r\nmapp, nmap, 0);\r\nerror = bp ? bp->b_error : XFS_ERROR(EIO);\r\nif (error) {\r\nxfs_trans_brelse(trans, bp);\r\ngoto out_free;\r\n}\r\n*bpp = bp;\r\nout_free:\r\nif (mapp != &map)\r\nkmem_free(mapp);\r\nreturn error;\r\n}\r\nint\r\nxfs_da_read_buf(\r\nstruct xfs_trans *trans,\r\nstruct xfs_inode *dp,\r\nxfs_dablk_t bno,\r\nxfs_daddr_t mappedbno,\r\nstruct xfs_buf **bpp,\r\nint whichfork,\r\nconst struct xfs_buf_ops *ops)\r\n{\r\nstruct xfs_buf *bp;\r\nstruct xfs_buf_map map;\r\nstruct xfs_buf_map *mapp;\r\nint nmap;\r\nint error;\r\n*bpp = NULL;\r\nmapp = &map;\r\nnmap = 1;\r\nerror = xfs_dabuf_map(trans, dp, bno, mappedbno, whichfork,\r\n&mapp, &nmap);\r\nif (error) {\r\nif (error == -1)\r\nerror = 0;\r\ngoto out_free;\r\n}\r\nerror = xfs_trans_read_buf_map(dp->i_mount, trans,\r\ndp->i_mount->m_ddev_targp,\r\nmapp, nmap, 0, &bp, ops);\r\nif (error)\r\ngoto out_free;\r\nif (whichfork == XFS_ATTR_FORK)\r\nxfs_buf_set_ref(bp, XFS_ATTR_BTREE_REF);\r\nelse\r\nxfs_buf_set_ref(bp, XFS_DIR_BTREE_REF);\r\n{\r\nxfs_dir2_data_hdr_t *hdr = bp->b_addr;\r\nxfs_dir2_free_t *free = bp->b_addr;\r\nxfs_da_blkinfo_t *info = bp->b_addr;\r\nuint magic, magic1;\r\nstruct xfs_mount *mp = dp->i_mount;\r\nmagic = be16_to_cpu(info->magic);\r\nmagic1 = be32_to_cpu(hdr->magic);\r\nif (unlikely(\r\nXFS_TEST_ERROR((magic != XFS_DA_NODE_MAGIC) &&\r\n(magic != XFS_ATTR_LEAF_MAGIC) &&\r\n(magic != XFS_DIR2_LEAF1_MAGIC) &&\r\n(magic != XFS_DIR2_LEAFN_MAGIC) &&\r\n(magic1 != XFS_DIR2_BLOCK_MAGIC) &&\r\n(magic1 != XFS_DIR2_DATA_MAGIC) &&\r\n(free->hdr.magic != cpu_to_be32(XFS_DIR2_FREE_MAGIC)),\r\nmp, XFS_ERRTAG_DA_READ_BUF,\r\nXFS_RANDOM_DA_READ_BUF))) {\r\ntrace_xfs_da_btree_corrupt(bp, _RET_IP_);\r\nXFS_CORRUPTION_ERROR("xfs_da_do_buf(2)",\r\nXFS_ERRLEVEL_LOW, mp, info);\r\nerror = XFS_ERROR(EFSCORRUPTED);\r\nxfs_trans_brelse(trans, bp);\r\ngoto out_free;\r\n}\r\n}\r\n*bpp = bp;\r\nout_free:\r\nif (mapp != &map)\r\nkmem_free(mapp);\r\nreturn error;\r\n}\r\nxfs_daddr_t\r\nxfs_da_reada_buf(\r\nstruct xfs_trans *trans,\r\nstruct xfs_inode *dp,\r\nxfs_dablk_t bno,\r\nxfs_daddr_t mappedbno,\r\nint whichfork,\r\nconst struct xfs_buf_ops *ops)\r\n{\r\nstruct xfs_buf_map map;\r\nstruct xfs_buf_map *mapp;\r\nint nmap;\r\nint error;\r\nmapp = &map;\r\nnmap = 1;\r\nerror = xfs_dabuf_map(trans, dp, bno, mappedbno, whichfork,\r\n&mapp, &nmap);\r\nif (error) {\r\nif (error == -1)\r\nerror = 0;\r\ngoto out_free;\r\n}\r\nmappedbno = mapp[0].bm_bn;\r\nxfs_buf_readahead_map(dp->i_mount->m_ddev_targp, mapp, nmap, ops);\r\nout_free:\r\nif (mapp != &map)\r\nkmem_free(mapp);\r\nif (error)\r\nreturn -1;\r\nreturn mappedbno;\r\n}\r\nxfs_da_state_t *\r\nxfs_da_state_alloc(void)\r\n{\r\nreturn kmem_zone_zalloc(xfs_da_state_zone, KM_NOFS);\r\n}\r\nSTATIC void\r\nxfs_da_state_kill_altpath(xfs_da_state_t *state)\r\n{\r\nint i;\r\nfor (i = 0; i < state->altpath.active; i++)\r\nstate->altpath.blk[i].bp = NULL;\r\nstate->altpath.active = 0;\r\n}\r\nvoid\r\nxfs_da_state_free(xfs_da_state_t *state)\r\n{\r\nxfs_da_state_kill_altpath(state);\r\n#ifdef DEBUG\r\nmemset((char *)state, 0, sizeof(*state));\r\n#endif\r\nkmem_zone_free(xfs_da_state_zone, state);\r\n}
