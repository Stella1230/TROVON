static inline int\r\nfetch_robust_entry(compat_uptr_t *uentry, struct robust_list __user **entry,\r\ncompat_uptr_t __user *head, unsigned int *pi)\r\n{\r\nif (get_user(*uentry, head))\r\nreturn -EFAULT;\r\n*entry = compat_ptr((*uentry) & ~1);\r\n*pi = (unsigned int)(*uentry) & 1;\r\nreturn 0;\r\n}\r\nstatic void __user *futex_uaddr(struct robust_list __user *entry,\r\ncompat_long_t futex_offset)\r\n{\r\ncompat_uptr_t base = ptr_to_compat(entry);\r\nvoid __user *uaddr = compat_ptr(base + futex_offset);\r\nreturn uaddr;\r\n}\r\nvoid compat_exit_robust_list(struct task_struct *curr)\r\n{\r\nstruct compat_robust_list_head __user *head = curr->compat_robust_list;\r\nstruct robust_list __user *entry, *next_entry, *pending;\r\nunsigned int limit = ROBUST_LIST_LIMIT, pi, pip;\r\nunsigned int uninitialized_var(next_pi);\r\ncompat_uptr_t uentry, next_uentry, upending;\r\ncompat_long_t futex_offset;\r\nint rc;\r\nif (!futex_cmpxchg_enabled)\r\nreturn;\r\nif (fetch_robust_entry(&uentry, &entry, &head->list.next, &pi))\r\nreturn;\r\nif (get_user(futex_offset, &head->futex_offset))\r\nreturn;\r\nif (fetch_robust_entry(&upending, &pending,\r\n&head->list_op_pending, &pip))\r\nreturn;\r\nnext_entry = NULL;\r\nwhile (entry != (struct robust_list __user *) &head->list) {\r\nrc = fetch_robust_entry(&next_uentry, &next_entry,\r\n(compat_uptr_t __user *)&entry->next, &next_pi);\r\nif (entry != pending) {\r\nvoid __user *uaddr = futex_uaddr(entry, futex_offset);\r\nif (handle_futex_death(uaddr, curr, pi))\r\nreturn;\r\n}\r\nif (rc)\r\nreturn;\r\nuentry = next_uentry;\r\nentry = next_entry;\r\npi = next_pi;\r\nif (!--limit)\r\nbreak;\r\ncond_resched();\r\n}\r\nif (pending) {\r\nvoid __user *uaddr = futex_uaddr(pending, futex_offset);\r\nhandle_futex_death(uaddr, curr, pip);\r\n}\r\n}
