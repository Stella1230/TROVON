void __ath10k_htt_tx_dec_pending(struct ath10k_htt *htt)\r\n{\r\nhtt->num_pending_tx--;\r\nif (htt->num_pending_tx == htt->max_num_pending_tx - 1)\r\nieee80211_wake_queues(htt->ar->hw);\r\n}\r\nstatic void ath10k_htt_tx_dec_pending(struct ath10k_htt *htt)\r\n{\r\nspin_lock_bh(&htt->tx_lock);\r\n__ath10k_htt_tx_dec_pending(htt);\r\nspin_unlock_bh(&htt->tx_lock);\r\n}\r\nstatic int ath10k_htt_tx_inc_pending(struct ath10k_htt *htt)\r\n{\r\nint ret = 0;\r\nspin_lock_bh(&htt->tx_lock);\r\nif (htt->num_pending_tx >= htt->max_num_pending_tx) {\r\nret = -EBUSY;\r\ngoto exit;\r\n}\r\nhtt->num_pending_tx++;\r\nif (htt->num_pending_tx == htt->max_num_pending_tx)\r\nieee80211_stop_queues(htt->ar->hw);\r\nexit:\r\nspin_unlock_bh(&htt->tx_lock);\r\nreturn ret;\r\n}\r\nint ath10k_htt_tx_alloc_msdu_id(struct ath10k_htt *htt, struct sk_buff *skb)\r\n{\r\nstruct ath10k *ar = htt->ar;\r\nint ret;\r\nlockdep_assert_held(&htt->tx_lock);\r\nret = idr_alloc(&htt->pending_tx, skb, 0, 0x10000, GFP_ATOMIC);\r\nath10k_dbg(ar, ATH10K_DBG_HTT, "htt tx alloc msdu_id %d\n", ret);\r\nreturn ret;\r\n}\r\nvoid ath10k_htt_tx_free_msdu_id(struct ath10k_htt *htt, u16 msdu_id)\r\n{\r\nstruct ath10k *ar = htt->ar;\r\nlockdep_assert_held(&htt->tx_lock);\r\nath10k_dbg(ar, ATH10K_DBG_HTT, "htt tx free msdu_id %hu\n", msdu_id);\r\nidr_remove(&htt->pending_tx, msdu_id);\r\n}\r\nint ath10k_htt_tx_alloc(struct ath10k_htt *htt)\r\n{\r\nstruct ath10k *ar = htt->ar;\r\nath10k_dbg(ar, ATH10K_DBG_BOOT, "htt tx max num pending tx %d\n",\r\nhtt->max_num_pending_tx);\r\nspin_lock_init(&htt->tx_lock);\r\nidr_init(&htt->pending_tx);\r\nhtt->tx_pool = dma_pool_create("ath10k htt tx pool", htt->ar->dev,\r\nsizeof(struct ath10k_htt_txbuf), 4, 0);\r\nif (!htt->tx_pool) {\r\nidr_destroy(&htt->pending_tx);\r\nreturn -ENOMEM;\r\n}\r\nreturn 0;\r\n}\r\nstatic int ath10k_htt_tx_clean_up_pending(int msdu_id, void *skb, void *ctx)\r\n{\r\nstruct ath10k *ar = ctx;\r\nstruct ath10k_htt *htt = &ar->htt;\r\nstruct htt_tx_done tx_done = {0};\r\nath10k_dbg(ar, ATH10K_DBG_HTT, "force cleanup msdu_id %hu\n", msdu_id);\r\ntx_done.discard = 1;\r\ntx_done.msdu_id = msdu_id;\r\nspin_lock_bh(&htt->tx_lock);\r\nath10k_txrx_tx_unref(htt, &tx_done);\r\nspin_unlock_bh(&htt->tx_lock);\r\nreturn 0;\r\n}\r\nvoid ath10k_htt_tx_free(struct ath10k_htt *htt)\r\n{\r\nidr_for_each(&htt->pending_tx, ath10k_htt_tx_clean_up_pending, htt->ar);\r\nidr_destroy(&htt->pending_tx);\r\ndma_pool_destroy(htt->tx_pool);\r\n}\r\nvoid ath10k_htt_htc_tx_complete(struct ath10k *ar, struct sk_buff *skb)\r\n{\r\ndev_kfree_skb_any(skb);\r\n}\r\nint ath10k_htt_h2t_ver_req_msg(struct ath10k_htt *htt)\r\n{\r\nstruct ath10k *ar = htt->ar;\r\nstruct sk_buff *skb;\r\nstruct htt_cmd *cmd;\r\nint len = 0;\r\nint ret;\r\nlen += sizeof(cmd->hdr);\r\nlen += sizeof(cmd->ver_req);\r\nskb = ath10k_htc_alloc_skb(ar, len);\r\nif (!skb)\r\nreturn -ENOMEM;\r\nskb_put(skb, len);\r\ncmd = (struct htt_cmd *)skb->data;\r\ncmd->hdr.msg_type = HTT_H2T_MSG_TYPE_VERSION_REQ;\r\nret = ath10k_htc_send(&htt->ar->htc, htt->eid, skb);\r\nif (ret) {\r\ndev_kfree_skb_any(skb);\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nint ath10k_htt_h2t_stats_req(struct ath10k_htt *htt, u8 mask, u64 cookie)\r\n{\r\nstruct ath10k *ar = htt->ar;\r\nstruct htt_stats_req *req;\r\nstruct sk_buff *skb;\r\nstruct htt_cmd *cmd;\r\nint len = 0, ret;\r\nlen += sizeof(cmd->hdr);\r\nlen += sizeof(cmd->stats_req);\r\nskb = ath10k_htc_alloc_skb(ar, len);\r\nif (!skb)\r\nreturn -ENOMEM;\r\nskb_put(skb, len);\r\ncmd = (struct htt_cmd *)skb->data;\r\ncmd->hdr.msg_type = HTT_H2T_MSG_TYPE_STATS_REQ;\r\nreq = &cmd->stats_req;\r\nmemset(req, 0, sizeof(*req));\r\nreq->upload_types[0] = mask;\r\nreq->reset_types[0] = mask;\r\nreq->stat_type = HTT_STATS_REQ_CFG_STAT_TYPE_INVALID;\r\nreq->cookie_lsb = cpu_to_le32(cookie & 0xffffffff);\r\nreq->cookie_msb = cpu_to_le32((cookie & 0xffffffff00000000ULL) >> 32);\r\nret = ath10k_htc_send(&htt->ar->htc, htt->eid, skb);\r\nif (ret) {\r\nath10k_warn(ar, "failed to send htt type stats request: %d",\r\nret);\r\ndev_kfree_skb_any(skb);\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nint ath10k_htt_send_rx_ring_cfg_ll(struct ath10k_htt *htt)\r\n{\r\nstruct ath10k *ar = htt->ar;\r\nstruct sk_buff *skb;\r\nstruct htt_cmd *cmd;\r\nstruct htt_rx_ring_setup_ring *ring;\r\nconst int num_rx_ring = 1;\r\nu16 flags;\r\nu32 fw_idx;\r\nint len;\r\nint ret;\r\nBUILD_BUG_ON(!IS_ALIGNED(HTT_RX_BUF_SIZE, 4));\r\nBUILD_BUG_ON((HTT_RX_BUF_SIZE & HTT_MAX_CACHE_LINE_SIZE_MASK) != 0);\r\nlen = sizeof(cmd->hdr) + sizeof(cmd->rx_setup.hdr)\r\n+ (sizeof(*ring) * num_rx_ring);\r\nskb = ath10k_htc_alloc_skb(ar, len);\r\nif (!skb)\r\nreturn -ENOMEM;\r\nskb_put(skb, len);\r\ncmd = (struct htt_cmd *)skb->data;\r\nring = &cmd->rx_setup.rings[0];\r\ncmd->hdr.msg_type = HTT_H2T_MSG_TYPE_RX_RING_CFG;\r\ncmd->rx_setup.hdr.num_rings = 1;\r\nflags = 0;\r\nflags |= HTT_RX_RING_FLAGS_MAC80211_HDR;\r\nflags |= HTT_RX_RING_FLAGS_MSDU_PAYLOAD;\r\nflags |= HTT_RX_RING_FLAGS_PPDU_START;\r\nflags |= HTT_RX_RING_FLAGS_PPDU_END;\r\nflags |= HTT_RX_RING_FLAGS_MPDU_START;\r\nflags |= HTT_RX_RING_FLAGS_MPDU_END;\r\nflags |= HTT_RX_RING_FLAGS_MSDU_START;\r\nflags |= HTT_RX_RING_FLAGS_MSDU_END;\r\nflags |= HTT_RX_RING_FLAGS_RX_ATTENTION;\r\nflags |= HTT_RX_RING_FLAGS_FRAG_INFO;\r\nflags |= HTT_RX_RING_FLAGS_UNICAST_RX;\r\nflags |= HTT_RX_RING_FLAGS_MULTICAST_RX;\r\nflags |= HTT_RX_RING_FLAGS_CTRL_RX;\r\nflags |= HTT_RX_RING_FLAGS_MGMT_RX;\r\nflags |= HTT_RX_RING_FLAGS_NULL_RX;\r\nflags |= HTT_RX_RING_FLAGS_PHY_DATA_RX;\r\nfw_idx = __le32_to_cpu(*htt->rx_ring.alloc_idx.vaddr);\r\nring->fw_idx_shadow_reg_paddr =\r\n__cpu_to_le32(htt->rx_ring.alloc_idx.paddr);\r\nring->rx_ring_base_paddr = __cpu_to_le32(htt->rx_ring.base_paddr);\r\nring->rx_ring_len = __cpu_to_le16(htt->rx_ring.size);\r\nring->rx_ring_bufsize = __cpu_to_le16(HTT_RX_BUF_SIZE);\r\nring->flags = __cpu_to_le16(flags);\r\nring->fw_idx_init_val = __cpu_to_le16(fw_idx);\r\n#define desc_offset(x) (offsetof(struct htt_rx_desc, x) / 4)\r\nring->mac80211_hdr_offset = __cpu_to_le16(desc_offset(rx_hdr_status));\r\nring->msdu_payload_offset = __cpu_to_le16(desc_offset(msdu_payload));\r\nring->ppdu_start_offset = __cpu_to_le16(desc_offset(ppdu_start));\r\nring->ppdu_end_offset = __cpu_to_le16(desc_offset(ppdu_end));\r\nring->mpdu_start_offset = __cpu_to_le16(desc_offset(mpdu_start));\r\nring->mpdu_end_offset = __cpu_to_le16(desc_offset(mpdu_end));\r\nring->msdu_start_offset = __cpu_to_le16(desc_offset(msdu_start));\r\nring->msdu_end_offset = __cpu_to_le16(desc_offset(msdu_end));\r\nring->rx_attention_offset = __cpu_to_le16(desc_offset(attention));\r\nring->frag_info_offset = __cpu_to_le16(desc_offset(frag_info));\r\n#undef desc_offset\r\nret = ath10k_htc_send(&htt->ar->htc, htt->eid, skb);\r\nif (ret) {\r\ndev_kfree_skb_any(skb);\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nint ath10k_htt_h2t_aggr_cfg_msg(struct ath10k_htt *htt,\r\nu8 max_subfrms_ampdu,\r\nu8 max_subfrms_amsdu)\r\n{\r\nstruct ath10k *ar = htt->ar;\r\nstruct htt_aggr_conf *aggr_conf;\r\nstruct sk_buff *skb;\r\nstruct htt_cmd *cmd;\r\nint len;\r\nint ret;\r\nif (max_subfrms_ampdu == 0 || max_subfrms_ampdu > 64)\r\nreturn -EINVAL;\r\nif (max_subfrms_amsdu == 0 || max_subfrms_amsdu > 31)\r\nreturn -EINVAL;\r\nlen = sizeof(cmd->hdr);\r\nlen += sizeof(cmd->aggr_conf);\r\nskb = ath10k_htc_alloc_skb(ar, len);\r\nif (!skb)\r\nreturn -ENOMEM;\r\nskb_put(skb, len);\r\ncmd = (struct htt_cmd *)skb->data;\r\ncmd->hdr.msg_type = HTT_H2T_MSG_TYPE_AGGR_CFG;\r\naggr_conf = &cmd->aggr_conf;\r\naggr_conf->max_num_ampdu_subframes = max_subfrms_ampdu;\r\naggr_conf->max_num_amsdu_subframes = max_subfrms_amsdu;\r\nath10k_dbg(ar, ATH10K_DBG_HTT, "htt h2t aggr cfg msg amsdu %d ampdu %d",\r\naggr_conf->max_num_amsdu_subframes,\r\naggr_conf->max_num_ampdu_subframes);\r\nret = ath10k_htc_send(&htt->ar->htc, htt->eid, skb);\r\nif (ret) {\r\ndev_kfree_skb_any(skb);\r\nreturn ret;\r\n}\r\nreturn 0;\r\n}\r\nint ath10k_htt_mgmt_tx(struct ath10k_htt *htt, struct sk_buff *msdu)\r\n{\r\nstruct ath10k *ar = htt->ar;\r\nstruct device *dev = ar->dev;\r\nstruct sk_buff *txdesc = NULL;\r\nstruct htt_cmd *cmd;\r\nstruct ath10k_skb_cb *skb_cb = ATH10K_SKB_CB(msdu);\r\nu8 vdev_id = skb_cb->vdev_id;\r\nint len = 0;\r\nint msdu_id = -1;\r\nint res;\r\nres = ath10k_htt_tx_inc_pending(htt);\r\nif (res)\r\ngoto err;\r\nlen += sizeof(cmd->hdr);\r\nlen += sizeof(cmd->mgmt_tx);\r\nspin_lock_bh(&htt->tx_lock);\r\nres = ath10k_htt_tx_alloc_msdu_id(htt, msdu);\r\nif (res < 0) {\r\nspin_unlock_bh(&htt->tx_lock);\r\ngoto err_tx_dec;\r\n}\r\nmsdu_id = res;\r\nspin_unlock_bh(&htt->tx_lock);\r\ntxdesc = ath10k_htc_alloc_skb(ar, len);\r\nif (!txdesc) {\r\nres = -ENOMEM;\r\ngoto err_free_msdu_id;\r\n}\r\nskb_cb->paddr = dma_map_single(dev, msdu->data, msdu->len,\r\nDMA_TO_DEVICE);\r\nres = dma_mapping_error(dev, skb_cb->paddr);\r\nif (res)\r\ngoto err_free_txdesc;\r\nskb_put(txdesc, len);\r\ncmd = (struct htt_cmd *)txdesc->data;\r\ncmd->hdr.msg_type = HTT_H2T_MSG_TYPE_MGMT_TX;\r\ncmd->mgmt_tx.msdu_paddr = __cpu_to_le32(ATH10K_SKB_CB(msdu)->paddr);\r\ncmd->mgmt_tx.len = __cpu_to_le32(msdu->len);\r\ncmd->mgmt_tx.desc_id = __cpu_to_le32(msdu_id);\r\ncmd->mgmt_tx.vdev_id = __cpu_to_le32(vdev_id);\r\nmemcpy(cmd->mgmt_tx.hdr, msdu->data,\r\nmin_t(int, msdu->len, HTT_MGMT_FRM_HDR_DOWNLOAD_LEN));\r\nskb_cb->htt.txbuf = NULL;\r\nres = ath10k_htc_send(&htt->ar->htc, htt->eid, txdesc);\r\nif (res)\r\ngoto err_unmap_msdu;\r\nreturn 0;\r\nerr_unmap_msdu:\r\ndma_unmap_single(dev, skb_cb->paddr, msdu->len, DMA_TO_DEVICE);\r\nerr_free_txdesc:\r\ndev_kfree_skb_any(txdesc);\r\nerr_free_msdu_id:\r\nspin_lock_bh(&htt->tx_lock);\r\nath10k_htt_tx_free_msdu_id(htt, msdu_id);\r\nspin_unlock_bh(&htt->tx_lock);\r\nerr_tx_dec:\r\nath10k_htt_tx_dec_pending(htt);\r\nerr:\r\nreturn res;\r\n}\r\nint ath10k_htt_tx(struct ath10k_htt *htt, struct sk_buff *msdu)\r\n{\r\nstruct ath10k *ar = htt->ar;\r\nstruct device *dev = ar->dev;\r\nstruct ieee80211_hdr *hdr = (struct ieee80211_hdr *)msdu->data;\r\nstruct ath10k_skb_cb *skb_cb = ATH10K_SKB_CB(msdu);\r\nstruct ath10k_hif_sg_item sg_items[2];\r\nstruct htt_data_tx_desc_frag *frags;\r\nu8 vdev_id = skb_cb->vdev_id;\r\nu8 tid = skb_cb->htt.tid;\r\nint prefetch_len;\r\nint res;\r\nu8 flags0 = 0;\r\nu16 msdu_id, flags1 = 0;\r\ndma_addr_t paddr;\r\nu32 frags_paddr;\r\nbool use_frags;\r\nres = ath10k_htt_tx_inc_pending(htt);\r\nif (res)\r\ngoto err;\r\nspin_lock_bh(&htt->tx_lock);\r\nres = ath10k_htt_tx_alloc_msdu_id(htt, msdu);\r\nif (res < 0) {\r\nspin_unlock_bh(&htt->tx_lock);\r\ngoto err_tx_dec;\r\n}\r\nmsdu_id = res;\r\nspin_unlock_bh(&htt->tx_lock);\r\nprefetch_len = min(htt->prefetch_len, msdu->len);\r\nprefetch_len = roundup(prefetch_len, 4);\r\nuse_frags = htt->target_version_major < 3 ||\r\n!ieee80211_is_mgmt(hdr->frame_control);\r\nskb_cb->htt.txbuf = dma_pool_alloc(htt->tx_pool, GFP_ATOMIC,\r\n&paddr);\r\nif (!skb_cb->htt.txbuf) {\r\nres = -ENOMEM;\r\ngoto err_free_msdu_id;\r\n}\r\nskb_cb->htt.txbuf_paddr = paddr;\r\nif ((ieee80211_is_action(hdr->frame_control) ||\r\nieee80211_is_deauth(hdr->frame_control) ||\r\nieee80211_is_disassoc(hdr->frame_control)) &&\r\nieee80211_has_protected(hdr->frame_control))\r\nskb_put(msdu, IEEE80211_CCMP_MIC_LEN);\r\nskb_cb->paddr = dma_map_single(dev, msdu->data, msdu->len,\r\nDMA_TO_DEVICE);\r\nres = dma_mapping_error(dev, skb_cb->paddr);\r\nif (res)\r\ngoto err_free_txbuf;\r\nif (likely(use_frags)) {\r\nfrags = skb_cb->htt.txbuf->frags;\r\nfrags[0].paddr = __cpu_to_le32(skb_cb->paddr);\r\nfrags[0].len = __cpu_to_le32(msdu->len);\r\nfrags[1].paddr = 0;\r\nfrags[1].len = 0;\r\nflags0 |= SM(ATH10K_HW_TXRX_NATIVE_WIFI,\r\nHTT_DATA_TX_DESC_FLAGS0_PKT_TYPE);\r\nfrags_paddr = skb_cb->htt.txbuf_paddr;\r\n} else {\r\nflags0 |= SM(ATH10K_HW_TXRX_MGMT,\r\nHTT_DATA_TX_DESC_FLAGS0_PKT_TYPE);\r\nfrags_paddr = skb_cb->paddr;\r\n}\r\nskb_cb->htt.txbuf->htc_hdr.eid = htt->eid;\r\nskb_cb->htt.txbuf->htc_hdr.len = __cpu_to_le16(\r\nsizeof(skb_cb->htt.txbuf->cmd_hdr) +\r\nsizeof(skb_cb->htt.txbuf->cmd_tx) +\r\nprefetch_len);\r\nskb_cb->htt.txbuf->htc_hdr.flags = 0;\r\nif (!ieee80211_has_protected(hdr->frame_control))\r\nflags0 |= HTT_DATA_TX_DESC_FLAGS0_NO_ENCRYPT;\r\nflags0 |= HTT_DATA_TX_DESC_FLAGS0_MAC_HDR_PRESENT;\r\nflags1 |= SM((u16)vdev_id, HTT_DATA_TX_DESC_FLAGS1_VDEV_ID);\r\nflags1 |= SM((u16)tid, HTT_DATA_TX_DESC_FLAGS1_EXT_TID);\r\nif (msdu->ip_summed == CHECKSUM_PARTIAL) {\r\nflags1 |= HTT_DATA_TX_DESC_FLAGS1_CKSUM_L3_OFFLOAD;\r\nflags1 |= HTT_DATA_TX_DESC_FLAGS1_CKSUM_L4_OFFLOAD;\r\n}\r\nflags1 |= HTT_DATA_TX_DESC_FLAGS1_POSTPONED;\r\nskb_cb->htt.txbuf->cmd_hdr.msg_type = HTT_H2T_MSG_TYPE_TX_FRM;\r\nskb_cb->htt.txbuf->cmd_tx.flags0 = flags0;\r\nskb_cb->htt.txbuf->cmd_tx.flags1 = __cpu_to_le16(flags1);\r\nskb_cb->htt.txbuf->cmd_tx.len = __cpu_to_le16(msdu->len);\r\nskb_cb->htt.txbuf->cmd_tx.id = __cpu_to_le16(msdu_id);\r\nskb_cb->htt.txbuf->cmd_tx.frags_paddr = __cpu_to_le32(frags_paddr);\r\nskb_cb->htt.txbuf->cmd_tx.peerid = __cpu_to_le16(HTT_INVALID_PEERID);\r\nskb_cb->htt.txbuf->cmd_tx.freq = __cpu_to_le16(skb_cb->htt.freq);\r\ntrace_ath10k_htt_tx(ar, msdu_id, msdu->len, vdev_id, tid);\r\nath10k_dbg(ar, ATH10K_DBG_HTT,\r\n"htt tx flags0 %hhu flags1 %hu len %d id %hu frags_paddr %08x, msdu_paddr %08x vdev %hhu tid %hhu freq %hu\n",\r\nflags0, flags1, msdu->len, msdu_id, frags_paddr,\r\n(u32)skb_cb->paddr, vdev_id, tid, skb_cb->htt.freq);\r\nath10k_dbg_dump(ar, ATH10K_DBG_HTT_DUMP, NULL, "htt tx msdu: ",\r\nmsdu->data, msdu->len);\r\ntrace_ath10k_tx_hdr(ar, msdu->data, msdu->len);\r\ntrace_ath10k_tx_payload(ar, msdu->data, msdu->len);\r\nsg_items[0].transfer_id = 0;\r\nsg_items[0].transfer_context = NULL;\r\nsg_items[0].vaddr = &skb_cb->htt.txbuf->htc_hdr;\r\nsg_items[0].paddr = skb_cb->htt.txbuf_paddr +\r\nsizeof(skb_cb->htt.txbuf->frags);\r\nsg_items[0].len = sizeof(skb_cb->htt.txbuf->htc_hdr) +\r\nsizeof(skb_cb->htt.txbuf->cmd_hdr) +\r\nsizeof(skb_cb->htt.txbuf->cmd_tx);\r\nsg_items[1].transfer_id = 0;\r\nsg_items[1].transfer_context = NULL;\r\nsg_items[1].vaddr = msdu->data;\r\nsg_items[1].paddr = skb_cb->paddr;\r\nsg_items[1].len = prefetch_len;\r\nres = ath10k_hif_tx_sg(htt->ar,\r\nhtt->ar->htc.endpoint[htt->eid].ul_pipe_id,\r\nsg_items, ARRAY_SIZE(sg_items));\r\nif (res)\r\ngoto err_unmap_msdu;\r\nreturn 0;\r\nerr_unmap_msdu:\r\ndma_unmap_single(dev, skb_cb->paddr, msdu->len, DMA_TO_DEVICE);\r\nerr_free_txbuf:\r\ndma_pool_free(htt->tx_pool,\r\nskb_cb->htt.txbuf,\r\nskb_cb->htt.txbuf_paddr);\r\nerr_free_msdu_id:\r\nspin_lock_bh(&htt->tx_lock);\r\nath10k_htt_tx_free_msdu_id(htt, msdu_id);\r\nspin_unlock_bh(&htt->tx_lock);\r\nerr_tx_dec:\r\nath10k_htt_tx_dec_pending(htt);\r\nerr:\r\nreturn res;\r\n}
