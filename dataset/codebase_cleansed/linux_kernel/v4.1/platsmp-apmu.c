static int __maybe_unused apmu_power_on(void __iomem *p, int bit)\r\n{\r\nwritel_relaxed(BIT(bit), p + WUPCR_OFFS);\r\nwhile (readl_relaxed(p + WUPCR_OFFS) != 0)\r\n;\r\nreturn 0;\r\n}\r\nstatic int apmu_power_off(void __iomem *p, int bit)\r\n{\r\nwritel_relaxed(3, p + CPUNCR_OFFS(bit));\r\nreturn 0;\r\n}\r\nstatic int __maybe_unused apmu_power_off_poll(void __iomem *p, int bit)\r\n{\r\nint k;\r\nfor (k = 0; k < 1000; k++) {\r\nif (((readl_relaxed(p + PSTR_OFFS) >> (bit * 4)) & 0x03) == 3)\r\nreturn 1;\r\nmdelay(1);\r\n}\r\nreturn 0;\r\n}\r\nstatic int apmu_wrap(int cpu, int (*fn)(void __iomem *p, int cpu))\r\n{\r\nvoid __iomem *p = apmu_cpus[cpu].iomem;\r\nreturn p ? fn(p, apmu_cpus[cpu].bit) : -EINVAL;\r\n}\r\nstatic void apmu_init_cpu(struct resource *res, int cpu, int bit)\r\n{\r\nif ((cpu >= ARRAY_SIZE(apmu_cpus)) || apmu_cpus[cpu].iomem)\r\nreturn;\r\napmu_cpus[cpu].iomem = ioremap_nocache(res->start, resource_size(res));\r\napmu_cpus[cpu].bit = bit;\r\npr_debug("apmu ioremap %d %d %pr\n", cpu, bit, res);\r\n}\r\nstatic void apmu_parse_cfg(void (*fn)(struct resource *res, int cpu, int bit),\r\nstruct rcar_apmu_config *apmu_config, int num)\r\n{\r\nu32 id;\r\nint k;\r\nint bit, index;\r\nbool is_allowed;\r\nfor (k = 0; k < num; k++) {\r\nis_allowed = false;\r\nfor (bit = 0; bit < ARRAY_SIZE(apmu_config[k].cpus); bit++) {\r\nid = apmu_config[k].cpus[bit];\r\nif (id >= 0) {\r\nif (id == cpu_logical_map(0))\r\nis_allowed = true;\r\n}\r\n}\r\nif (!is_allowed)\r\ncontinue;\r\nfor (bit = 0; bit < ARRAY_SIZE(apmu_config[k].cpus); bit++) {\r\nid = apmu_config[k].cpus[bit];\r\nif (id >= 0) {\r\nindex = get_logical_index(id);\r\nif (index >= 0)\r\nfn(&apmu_config[k].iomem, index, bit);\r\n}\r\n}\r\n}\r\n}\r\nvoid __init shmobile_smp_apmu_prepare_cpus(unsigned int max_cpus,\r\nstruct rcar_apmu_config *apmu_config,\r\nint num)\r\n{\r\nshmobile_boot_fn = virt_to_phys(shmobile_smp_boot);\r\nshmobile_boot_arg = MPIDR_HWID_BITMASK;\r\napmu_parse_cfg(apmu_init_cpu, apmu_config, num);\r\n}\r\nint shmobile_smp_apmu_boot_secondary(unsigned int cpu, struct task_struct *idle)\r\n{\r\nshmobile_smp_hook(cpu, virt_to_phys(shmobile_invalidate_start), 0);\r\nreturn apmu_wrap(cpu, apmu_power_on);\r\n}\r\nstatic inline void cpu_enter_lowpower_a15(void)\r\n{\r\nunsigned int v;\r\nasm volatile(\r\n" mrc p15, 0, %0, c1, c0, 0\n"\r\n" bic %0, %0, %1\n"\r\n" mcr p15, 0, %0, c1, c0, 0\n"\r\n: "=&r" (v)\r\n: "Ir" (CR_C)\r\n: "cc");\r\nflush_cache_louis();\r\nasm volatile(\r\n" mrc p15, 0, %0, c1, c0, 1\n"\r\n" bic %0, %0, %1\n"\r\n" mcr p15, 0, %0, c1, c0, 1\n"\r\n: "=&r" (v)\r\n: "Ir" (0x40)\r\n: "cc");\r\nisb();\r\ndsb();\r\n}\r\nvoid shmobile_smp_apmu_cpu_shutdown(unsigned int cpu)\r\n{\r\napmu_wrap(cpu, apmu_power_off);\r\ncpu_enter_lowpower_a15();\r\n}\r\nstatic inline void cpu_leave_lowpower(void)\r\n{\r\nunsigned int v;\r\nasm volatile("mrc p15, 0, %0, c1, c0, 0\n"\r\n" orr %0, %0, %1\n"\r\n" mcr p15, 0, %0, c1, c0, 0\n"\r\n" mrc p15, 0, %0, c1, c0, 1\n"\r\n" orr %0, %0, %2\n"\r\n" mcr p15, 0, %0, c1, c0, 1\n"\r\n: "=&r" (v)\r\n: "Ir" (CR_C), "Ir" (0x40)\r\n: "cc");\r\n}\r\nvoid shmobile_smp_apmu_cpu_die(unsigned int cpu)\r\n{\r\nshmobile_smp_hook(cpu, 0, 0);\r\nshmobile_smp_apmu_cpu_shutdown(cpu);\r\nshmobile_smp_sleep();\r\n}\r\nint shmobile_smp_apmu_cpu_kill(unsigned int cpu)\r\n{\r\nreturn apmu_wrap(cpu, apmu_power_off_poll);\r\n}\r\nstatic int shmobile_smp_apmu_do_suspend(unsigned long cpu)\r\n{\r\nshmobile_smp_hook(cpu, virt_to_phys(cpu_resume), 0);\r\nshmobile_smp_apmu_cpu_shutdown(cpu);\r\ncpu_do_idle();\r\nreturn 1;\r\n}\r\nstatic int shmobile_smp_apmu_enter_suspend(suspend_state_t state)\r\n{\r\ncpu_suspend(smp_processor_id(), shmobile_smp_apmu_do_suspend);\r\ncpu_leave_lowpower();\r\nreturn 0;\r\n}\r\nvoid __init shmobile_smp_apmu_suspend_init(void)\r\n{\r\nshmobile_suspend_ops.enter = shmobile_smp_apmu_enter_suspend;\r\n}
