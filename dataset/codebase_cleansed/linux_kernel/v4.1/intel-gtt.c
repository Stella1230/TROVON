static int intel_gtt_map_memory(struct page **pages,\r\nunsigned int num_entries,\r\nstruct sg_table *st)\r\n{\r\nstruct scatterlist *sg;\r\nint i;\r\nDBG("try mapping %lu pages\n", (unsigned long)num_entries);\r\nif (sg_alloc_table(st, num_entries, GFP_KERNEL))\r\ngoto err;\r\nfor_each_sg(st->sgl, sg, num_entries, i)\r\nsg_set_page(sg, pages[i], PAGE_SIZE, 0);\r\nif (!pci_map_sg(intel_private.pcidev,\r\nst->sgl, st->nents, PCI_DMA_BIDIRECTIONAL))\r\ngoto err;\r\nreturn 0;\r\nerr:\r\nsg_free_table(st);\r\nreturn -ENOMEM;\r\n}\r\nstatic void intel_gtt_unmap_memory(struct scatterlist *sg_list, int num_sg)\r\n{\r\nstruct sg_table st;\r\nDBG("try unmapping %lu pages\n", (unsigned long)mem->page_count);\r\npci_unmap_sg(intel_private.pcidev, sg_list,\r\nnum_sg, PCI_DMA_BIDIRECTIONAL);\r\nst.sgl = sg_list;\r\nst.orig_nents = st.nents = num_sg;\r\nsg_free_table(&st);\r\n}\r\nstatic void intel_fake_agp_enable(struct agp_bridge_data *bridge, u32 mode)\r\n{\r\nreturn;\r\n}\r\nstatic struct page *i8xx_alloc_pages(void)\r\n{\r\nstruct page *page;\r\npage = alloc_pages(GFP_KERNEL | GFP_DMA32, 2);\r\nif (page == NULL)\r\nreturn NULL;\r\nif (set_pages_uc(page, 4) < 0) {\r\nset_pages_wb(page, 4);\r\n__free_pages(page, 2);\r\nreturn NULL;\r\n}\r\natomic_inc(&agp_bridge->current_memory_agp);\r\nreturn page;\r\n}\r\nstatic void i8xx_destroy_pages(struct page *page)\r\n{\r\nif (page == NULL)\r\nreturn;\r\nset_pages_wb(page, 4);\r\n__free_pages(page, 2);\r\natomic_dec(&agp_bridge->current_memory_agp);\r\n}\r\nstatic int i810_setup(void)\r\n{\r\nphys_addr_t reg_addr;\r\nchar *gtt_table;\r\ngtt_table = alloc_gatt_pages(I810_GTT_ORDER);\r\nif (gtt_table == NULL)\r\nreturn -ENOMEM;\r\nintel_private.i81x_gtt_table = gtt_table;\r\nreg_addr = pci_resource_start(intel_private.pcidev, I810_MMADR_BAR);\r\nintel_private.registers = ioremap(reg_addr, KB(64));\r\nif (!intel_private.registers)\r\nreturn -ENOMEM;\r\nwritel(virt_to_phys(gtt_table) | I810_PGETBL_ENABLED,\r\nintel_private.registers+I810_PGETBL_CTL);\r\nintel_private.gtt_phys_addr = reg_addr + I810_PTE_BASE;\r\nif ((readl(intel_private.registers+I810_DRAM_CTL)\r\n& I810_DRAM_ROW_0) == I810_DRAM_ROW_0_SDRAM) {\r\ndev_info(&intel_private.pcidev->dev,\r\n"detected 4MB dedicated video ram\n");\r\nintel_private.num_dcache_entries = 1024;\r\n}\r\nreturn 0;\r\n}\r\nstatic void i810_cleanup(void)\r\n{\r\nwritel(0, intel_private.registers+I810_PGETBL_CTL);\r\nfree_gatt_pages(intel_private.i81x_gtt_table, I810_GTT_ORDER);\r\n}\r\nstatic int i810_insert_dcache_entries(struct agp_memory *mem, off_t pg_start,\r\nint type)\r\n{\r\nint i;\r\nif ((pg_start + mem->page_count)\r\n> intel_private.num_dcache_entries)\r\nreturn -EINVAL;\r\nif (!mem->is_flushed)\r\nglobal_cache_flush();\r\nfor (i = pg_start; i < (pg_start + mem->page_count); i++) {\r\ndma_addr_t addr = i << PAGE_SHIFT;\r\nintel_private.driver->write_entry(addr,\r\ni, type);\r\n}\r\nwmb();\r\nreturn 0;\r\n}\r\nstatic struct agp_memory *alloc_agpphysmem_i8xx(size_t pg_count, int type)\r\n{\r\nstruct agp_memory *new;\r\nstruct page *page;\r\nswitch (pg_count) {\r\ncase 1: page = agp_bridge->driver->agp_alloc_page(agp_bridge);\r\nbreak;\r\ncase 4:\r\npage = i8xx_alloc_pages();\r\nbreak;\r\ndefault:\r\nreturn NULL;\r\n}\r\nif (page == NULL)\r\nreturn NULL;\r\nnew = agp_create_memory(pg_count);\r\nif (new == NULL)\r\nreturn NULL;\r\nnew->pages[0] = page;\r\nif (pg_count == 4) {\r\nnew->pages[1] = new->pages[0] + 1;\r\nnew->pages[2] = new->pages[1] + 1;\r\nnew->pages[3] = new->pages[2] + 1;\r\n}\r\nnew->page_count = pg_count;\r\nnew->num_scratch_pages = pg_count;\r\nnew->type = AGP_PHYS_MEMORY;\r\nnew->physical = page_to_phys(new->pages[0]);\r\nreturn new;\r\n}\r\nstatic void intel_i810_free_by_type(struct agp_memory *curr)\r\n{\r\nagp_free_key(curr->key);\r\nif (curr->type == AGP_PHYS_MEMORY) {\r\nif (curr->page_count == 4)\r\ni8xx_destroy_pages(curr->pages[0]);\r\nelse {\r\nagp_bridge->driver->agp_destroy_page(curr->pages[0],\r\nAGP_PAGE_DESTROY_UNMAP);\r\nagp_bridge->driver->agp_destroy_page(curr->pages[0],\r\nAGP_PAGE_DESTROY_FREE);\r\n}\r\nagp_free_page_array(curr);\r\n}\r\nkfree(curr);\r\n}\r\nstatic int intel_gtt_setup_scratch_page(void)\r\n{\r\nstruct page *page;\r\ndma_addr_t dma_addr;\r\npage = alloc_page(GFP_KERNEL | GFP_DMA32 | __GFP_ZERO);\r\nif (page == NULL)\r\nreturn -ENOMEM;\r\nset_pages_uc(page, 1);\r\nif (intel_private.needs_dmar) {\r\ndma_addr = pci_map_page(intel_private.pcidev, page, 0,\r\nPAGE_SIZE, PCI_DMA_BIDIRECTIONAL);\r\nif (pci_dma_mapping_error(intel_private.pcidev, dma_addr))\r\nreturn -EINVAL;\r\nintel_private.scratch_page_dma = dma_addr;\r\n} else\r\nintel_private.scratch_page_dma = page_to_phys(page);\r\nintel_private.scratch_page = page;\r\nreturn 0;\r\n}\r\nstatic void i810_write_entry(dma_addr_t addr, unsigned int entry,\r\nunsigned int flags)\r\n{\r\nu32 pte_flags = I810_PTE_VALID;\r\nswitch (flags) {\r\ncase AGP_DCACHE_MEMORY:\r\npte_flags |= I810_PTE_LOCAL;\r\nbreak;\r\ncase AGP_USER_CACHED_MEMORY:\r\npte_flags |= I830_PTE_SYSTEM_CACHED;\r\nbreak;\r\n}\r\nwritel_relaxed(addr | pte_flags, intel_private.gtt + entry);\r\n}\r\nstatic unsigned int intel_gtt_stolen_size(void)\r\n{\r\nu16 gmch_ctrl;\r\nu8 rdct;\r\nint local = 0;\r\nstatic const int ddt[4] = { 0, 16, 32, 64 };\r\nunsigned int stolen_size = 0;\r\nif (INTEL_GTT_GEN == 1)\r\nreturn 0;\r\npci_read_config_word(intel_private.bridge_dev,\r\nI830_GMCH_CTRL, &gmch_ctrl);\r\nif (intel_private.bridge_dev->device == PCI_DEVICE_ID_INTEL_82830_HB ||\r\nintel_private.bridge_dev->device == PCI_DEVICE_ID_INTEL_82845G_HB) {\r\nswitch (gmch_ctrl & I830_GMCH_GMS_MASK) {\r\ncase I830_GMCH_GMS_STOLEN_512:\r\nstolen_size = KB(512);\r\nbreak;\r\ncase I830_GMCH_GMS_STOLEN_1024:\r\nstolen_size = MB(1);\r\nbreak;\r\ncase I830_GMCH_GMS_STOLEN_8192:\r\nstolen_size = MB(8);\r\nbreak;\r\ncase I830_GMCH_GMS_LOCAL:\r\nrdct = readb(intel_private.registers+I830_RDRAM_CHANNEL_TYPE);\r\nstolen_size = (I830_RDRAM_ND(rdct) + 1) *\r\nMB(ddt[I830_RDRAM_DDT(rdct)]);\r\nlocal = 1;\r\nbreak;\r\ndefault:\r\nstolen_size = 0;\r\nbreak;\r\n}\r\n} else {\r\nswitch (gmch_ctrl & I855_GMCH_GMS_MASK) {\r\ncase I855_GMCH_GMS_STOLEN_1M:\r\nstolen_size = MB(1);\r\nbreak;\r\ncase I855_GMCH_GMS_STOLEN_4M:\r\nstolen_size = MB(4);\r\nbreak;\r\ncase I855_GMCH_GMS_STOLEN_8M:\r\nstolen_size = MB(8);\r\nbreak;\r\ncase I855_GMCH_GMS_STOLEN_16M:\r\nstolen_size = MB(16);\r\nbreak;\r\ncase I855_GMCH_GMS_STOLEN_32M:\r\nstolen_size = MB(32);\r\nbreak;\r\ncase I915_GMCH_GMS_STOLEN_48M:\r\nstolen_size = MB(48);\r\nbreak;\r\ncase I915_GMCH_GMS_STOLEN_64M:\r\nstolen_size = MB(64);\r\nbreak;\r\ncase G33_GMCH_GMS_STOLEN_128M:\r\nstolen_size = MB(128);\r\nbreak;\r\ncase G33_GMCH_GMS_STOLEN_256M:\r\nstolen_size = MB(256);\r\nbreak;\r\ncase INTEL_GMCH_GMS_STOLEN_96M:\r\nstolen_size = MB(96);\r\nbreak;\r\ncase INTEL_GMCH_GMS_STOLEN_160M:\r\nstolen_size = MB(160);\r\nbreak;\r\ncase INTEL_GMCH_GMS_STOLEN_224M:\r\nstolen_size = MB(224);\r\nbreak;\r\ncase INTEL_GMCH_GMS_STOLEN_352M:\r\nstolen_size = MB(352);\r\nbreak;\r\ndefault:\r\nstolen_size = 0;\r\nbreak;\r\n}\r\n}\r\nif (stolen_size > 0) {\r\ndev_info(&intel_private.bridge_dev->dev, "detected %dK %s memory\n",\r\nstolen_size / KB(1), local ? "local" : "stolen");\r\n} else {\r\ndev_info(&intel_private.bridge_dev->dev,\r\n"no pre-allocated video memory detected\n");\r\nstolen_size = 0;\r\n}\r\nreturn stolen_size;\r\n}\r\nstatic void i965_adjust_pgetbl_size(unsigned int size_flag)\r\n{\r\nu32 pgetbl_ctl, pgetbl_ctl2;\r\npgetbl_ctl2 = readl(intel_private.registers+I965_PGETBL_CTL2);\r\npgetbl_ctl2 &= ~I810_PGETBL_ENABLED;\r\nwritel(pgetbl_ctl2, intel_private.registers+I965_PGETBL_CTL2);\r\npgetbl_ctl = readl(intel_private.registers+I810_PGETBL_CTL);\r\npgetbl_ctl &= ~I965_PGETBL_SIZE_MASK;\r\npgetbl_ctl |= size_flag;\r\nwritel(pgetbl_ctl, intel_private.registers+I810_PGETBL_CTL);\r\n}\r\nstatic unsigned int i965_gtt_total_entries(void)\r\n{\r\nint size;\r\nu32 pgetbl_ctl;\r\nu16 gmch_ctl;\r\npci_read_config_word(intel_private.bridge_dev,\r\nI830_GMCH_CTRL, &gmch_ctl);\r\nif (INTEL_GTT_GEN == 5) {\r\nswitch (gmch_ctl & G4x_GMCH_SIZE_MASK) {\r\ncase G4x_GMCH_SIZE_1M:\r\ncase G4x_GMCH_SIZE_VT_1M:\r\ni965_adjust_pgetbl_size(I965_PGETBL_SIZE_1MB);\r\nbreak;\r\ncase G4x_GMCH_SIZE_VT_1_5M:\r\ni965_adjust_pgetbl_size(I965_PGETBL_SIZE_1_5MB);\r\nbreak;\r\ncase G4x_GMCH_SIZE_2M:\r\ncase G4x_GMCH_SIZE_VT_2M:\r\ni965_adjust_pgetbl_size(I965_PGETBL_SIZE_2MB);\r\nbreak;\r\n}\r\n}\r\npgetbl_ctl = readl(intel_private.registers+I810_PGETBL_CTL);\r\nswitch (pgetbl_ctl & I965_PGETBL_SIZE_MASK) {\r\ncase I965_PGETBL_SIZE_128KB:\r\nsize = KB(128);\r\nbreak;\r\ncase I965_PGETBL_SIZE_256KB:\r\nsize = KB(256);\r\nbreak;\r\ncase I965_PGETBL_SIZE_512KB:\r\nsize = KB(512);\r\nbreak;\r\ncase I965_PGETBL_SIZE_1MB:\r\nsize = KB(1024);\r\nbreak;\r\ncase I965_PGETBL_SIZE_2MB:\r\nsize = KB(2048);\r\nbreak;\r\ncase I965_PGETBL_SIZE_1_5MB:\r\nsize = KB(1024 + 512);\r\nbreak;\r\ndefault:\r\ndev_info(&intel_private.pcidev->dev,\r\n"unknown page table size, assuming 512KB\n");\r\nsize = KB(512);\r\n}\r\nreturn size/4;\r\n}\r\nstatic unsigned int intel_gtt_total_entries(void)\r\n{\r\nif (IS_G33 || INTEL_GTT_GEN == 4 || INTEL_GTT_GEN == 5)\r\nreturn i965_gtt_total_entries();\r\nelse {\r\nreturn intel_private.gtt_mappable_entries;\r\n}\r\n}\r\nstatic unsigned int intel_gtt_mappable_entries(void)\r\n{\r\nunsigned int aperture_size;\r\nif (INTEL_GTT_GEN == 1) {\r\nu32 smram_miscc;\r\npci_read_config_dword(intel_private.bridge_dev,\r\nI810_SMRAM_MISCC, &smram_miscc);\r\nif ((smram_miscc & I810_GFX_MEM_WIN_SIZE)\r\n== I810_GFX_MEM_WIN_32M)\r\naperture_size = MB(32);\r\nelse\r\naperture_size = MB(64);\r\n} else if (INTEL_GTT_GEN == 2) {\r\nu16 gmch_ctrl;\r\npci_read_config_word(intel_private.bridge_dev,\r\nI830_GMCH_CTRL, &gmch_ctrl);\r\nif ((gmch_ctrl & I830_GMCH_MEM_MASK) == I830_GMCH_MEM_64M)\r\naperture_size = MB(64);\r\nelse\r\naperture_size = MB(128);\r\n} else {\r\naperture_size = pci_resource_len(intel_private.pcidev, 2);\r\n}\r\nreturn aperture_size >> PAGE_SHIFT;\r\n}\r\nstatic void intel_gtt_teardown_scratch_page(void)\r\n{\r\nset_pages_wb(intel_private.scratch_page, 1);\r\npci_unmap_page(intel_private.pcidev, intel_private.scratch_page_dma,\r\nPAGE_SIZE, PCI_DMA_BIDIRECTIONAL);\r\n__free_page(intel_private.scratch_page);\r\n}\r\nstatic void intel_gtt_cleanup(void)\r\n{\r\nintel_private.driver->cleanup();\r\niounmap(intel_private.gtt);\r\niounmap(intel_private.registers);\r\nintel_gtt_teardown_scratch_page();\r\n}\r\nstatic inline int needs_ilk_vtd_wa(void)\r\n{\r\n#ifdef CONFIG_INTEL_IOMMU\r\nconst unsigned short gpu_devid = intel_private.pcidev->device;\r\nif ((gpu_devid == PCI_DEVICE_ID_INTEL_IRONLAKE_M_HB ||\r\ngpu_devid == PCI_DEVICE_ID_INTEL_IRONLAKE_M_IG) &&\r\nintel_iommu_gfx_mapped)\r\nreturn 1;\r\n#endif\r\nreturn 0;\r\n}\r\nstatic bool intel_gtt_can_wc(void)\r\n{\r\nif (INTEL_GTT_GEN <= 2)\r\nreturn false;\r\nif (INTEL_GTT_GEN >= 6)\r\nreturn false;\r\nif (needs_ilk_vtd_wa())\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic int intel_gtt_init(void)\r\n{\r\nu32 gtt_map_size;\r\nint ret, bar;\r\nret = intel_private.driver->setup();\r\nif (ret != 0)\r\nreturn ret;\r\nintel_private.gtt_mappable_entries = intel_gtt_mappable_entries();\r\nintel_private.gtt_total_entries = intel_gtt_total_entries();\r\nintel_private.PGETBL_save =\r\nreadl(intel_private.registers+I810_PGETBL_CTL)\r\n& ~I810_PGETBL_ENABLED;\r\nif (HAS_PGTBL_EN)\r\nintel_private.PGETBL_save |= I810_PGETBL_ENABLED;\r\ndev_info(&intel_private.bridge_dev->dev,\r\n"detected gtt size: %dK total, %dK mappable\n",\r\nintel_private.gtt_total_entries * 4,\r\nintel_private.gtt_mappable_entries * 4);\r\ngtt_map_size = intel_private.gtt_total_entries * 4;\r\nintel_private.gtt = NULL;\r\nif (intel_gtt_can_wc())\r\nintel_private.gtt = ioremap_wc(intel_private.gtt_phys_addr,\r\ngtt_map_size);\r\nif (intel_private.gtt == NULL)\r\nintel_private.gtt = ioremap(intel_private.gtt_phys_addr,\r\ngtt_map_size);\r\nif (intel_private.gtt == NULL) {\r\nintel_private.driver->cleanup();\r\niounmap(intel_private.registers);\r\nreturn -ENOMEM;\r\n}\r\n#if IS_ENABLED(CONFIG_AGP_INTEL)\r\nglobal_cache_flush();\r\n#endif\r\nintel_private.stolen_size = intel_gtt_stolen_size();\r\nintel_private.needs_dmar = USE_PCI_DMA_API && INTEL_GTT_GEN > 2;\r\nret = intel_gtt_setup_scratch_page();\r\nif (ret != 0) {\r\nintel_gtt_cleanup();\r\nreturn ret;\r\n}\r\nif (INTEL_GTT_GEN <= 2)\r\nbar = I810_GMADR_BAR;\r\nelse\r\nbar = I915_GMADR_BAR;\r\nintel_private.gma_bus_addr = pci_bus_address(intel_private.pcidev, bar);\r\nreturn 0;\r\n}\r\nstatic int intel_fake_agp_fetch_size(void)\r\n{\r\nint num_sizes = ARRAY_SIZE(intel_fake_agp_sizes);\r\nunsigned int aper_size;\r\nint i;\r\naper_size = (intel_private.gtt_mappable_entries << PAGE_SHIFT) / MB(1);\r\nfor (i = 0; i < num_sizes; i++) {\r\nif (aper_size == intel_fake_agp_sizes[i].size) {\r\nagp_bridge->current_size =\r\n(void *) (intel_fake_agp_sizes + i);\r\nreturn aper_size;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void i830_cleanup(void)\r\n{\r\n}\r\nstatic void i830_chipset_flush(void)\r\n{\r\nunsigned long timeout = jiffies + msecs_to_jiffies(1000);\r\nwbinvd_on_all_cpus();\r\nwritel(readl(intel_private.registers+I830_HIC) | (1<<31),\r\nintel_private.registers+I830_HIC);\r\nwhile (readl(intel_private.registers+I830_HIC) & (1<<31)) {\r\nif (time_after(jiffies, timeout))\r\nbreak;\r\nudelay(50);\r\n}\r\n}\r\nstatic void i830_write_entry(dma_addr_t addr, unsigned int entry,\r\nunsigned int flags)\r\n{\r\nu32 pte_flags = I810_PTE_VALID;\r\nif (flags == AGP_USER_CACHED_MEMORY)\r\npte_flags |= I830_PTE_SYSTEM_CACHED;\r\nwritel_relaxed(addr | pte_flags, intel_private.gtt + entry);\r\n}\r\nbool intel_enable_gtt(void)\r\n{\r\nu8 __iomem *reg;\r\nif (INTEL_GTT_GEN == 2) {\r\nu16 gmch_ctrl;\r\npci_read_config_word(intel_private.bridge_dev,\r\nI830_GMCH_CTRL, &gmch_ctrl);\r\ngmch_ctrl |= I830_GMCH_ENABLED;\r\npci_write_config_word(intel_private.bridge_dev,\r\nI830_GMCH_CTRL, gmch_ctrl);\r\npci_read_config_word(intel_private.bridge_dev,\r\nI830_GMCH_CTRL, &gmch_ctrl);\r\nif ((gmch_ctrl & I830_GMCH_ENABLED) == 0) {\r\ndev_err(&intel_private.pcidev->dev,\r\n"failed to enable the GTT: GMCH_CTRL=%x\n",\r\ngmch_ctrl);\r\nreturn false;\r\n}\r\n}\r\nif (INTEL_GTT_GEN >= 3)\r\nwritel(0, intel_private.registers+GFX_FLSH_CNTL);\r\nreg = intel_private.registers+I810_PGETBL_CTL;\r\nwritel(intel_private.PGETBL_save, reg);\r\nif (HAS_PGTBL_EN && (readl(reg) & I810_PGETBL_ENABLED) == 0) {\r\ndev_err(&intel_private.pcidev->dev,\r\n"failed to enable the GTT: PGETBL=%x [expected %x]\n",\r\nreadl(reg), intel_private.PGETBL_save);\r\nreturn false;\r\n}\r\nif (INTEL_GTT_GEN >= 3)\r\nwritel(0, intel_private.registers+GFX_FLSH_CNTL);\r\nreturn true;\r\n}\r\nstatic int i830_setup(void)\r\n{\r\nphys_addr_t reg_addr;\r\nreg_addr = pci_resource_start(intel_private.pcidev, I810_MMADR_BAR);\r\nintel_private.registers = ioremap(reg_addr, KB(64));\r\nif (!intel_private.registers)\r\nreturn -ENOMEM;\r\nintel_private.gtt_phys_addr = reg_addr + I810_PTE_BASE;\r\nreturn 0;\r\n}\r\nstatic int intel_fake_agp_create_gatt_table(struct agp_bridge_data *bridge)\r\n{\r\nagp_bridge->gatt_table_real = NULL;\r\nagp_bridge->gatt_table = NULL;\r\nagp_bridge->gatt_bus_addr = 0;\r\nreturn 0;\r\n}\r\nstatic int intel_fake_agp_free_gatt_table(struct agp_bridge_data *bridge)\r\n{\r\nreturn 0;\r\n}\r\nstatic int intel_fake_agp_configure(void)\r\n{\r\nif (!intel_enable_gtt())\r\nreturn -EIO;\r\nintel_private.clear_fake_agp = true;\r\nagp_bridge->gart_bus_addr = intel_private.gma_bus_addr;\r\nreturn 0;\r\n}\r\nstatic bool i830_check_flags(unsigned int flags)\r\n{\r\nswitch (flags) {\r\ncase 0:\r\ncase AGP_PHYS_MEMORY:\r\ncase AGP_USER_CACHED_MEMORY:\r\ncase AGP_USER_MEMORY:\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nvoid intel_gtt_insert_sg_entries(struct sg_table *st,\r\nunsigned int pg_start,\r\nunsigned int flags)\r\n{\r\nstruct scatterlist *sg;\r\nunsigned int len, m;\r\nint i, j;\r\nj = pg_start;\r\nfor_each_sg(st->sgl, sg, st->nents, i) {\r\nlen = sg_dma_len(sg) >> PAGE_SHIFT;\r\nfor (m = 0; m < len; m++) {\r\ndma_addr_t addr = sg_dma_address(sg) + (m << PAGE_SHIFT);\r\nintel_private.driver->write_entry(addr, j, flags);\r\nj++;\r\n}\r\n}\r\nwmb();\r\n}\r\nstatic void intel_gtt_insert_pages(unsigned int first_entry,\r\nunsigned int num_entries,\r\nstruct page **pages,\r\nunsigned int flags)\r\n{\r\nint i, j;\r\nfor (i = 0, j = first_entry; i < num_entries; i++, j++) {\r\ndma_addr_t addr = page_to_phys(pages[i]);\r\nintel_private.driver->write_entry(addr,\r\nj, flags);\r\n}\r\nwmb();\r\n}\r\nstatic int intel_fake_agp_insert_entries(struct agp_memory *mem,\r\noff_t pg_start, int type)\r\n{\r\nint ret = -EINVAL;\r\nif (intel_private.clear_fake_agp) {\r\nint start = intel_private.stolen_size / PAGE_SIZE;\r\nint end = intel_private.gtt_mappable_entries;\r\nintel_gtt_clear_range(start, end - start);\r\nintel_private.clear_fake_agp = false;\r\n}\r\nif (INTEL_GTT_GEN == 1 && type == AGP_DCACHE_MEMORY)\r\nreturn i810_insert_dcache_entries(mem, pg_start, type);\r\nif (mem->page_count == 0)\r\ngoto out;\r\nif (pg_start + mem->page_count > intel_private.gtt_total_entries)\r\ngoto out_err;\r\nif (type != mem->type)\r\ngoto out_err;\r\nif (!intel_private.driver->check_flags(type))\r\ngoto out_err;\r\nif (!mem->is_flushed)\r\nglobal_cache_flush();\r\nif (intel_private.needs_dmar) {\r\nstruct sg_table st;\r\nret = intel_gtt_map_memory(mem->pages, mem->page_count, &st);\r\nif (ret != 0)\r\nreturn ret;\r\nintel_gtt_insert_sg_entries(&st, pg_start, type);\r\nmem->sg_list = st.sgl;\r\nmem->num_sg = st.nents;\r\n} else\r\nintel_gtt_insert_pages(pg_start, mem->page_count, mem->pages,\r\ntype);\r\nout:\r\nret = 0;\r\nout_err:\r\nmem->is_flushed = true;\r\nreturn ret;\r\n}\r\nvoid intel_gtt_clear_range(unsigned int first_entry, unsigned int num_entries)\r\n{\r\nunsigned int i;\r\nfor (i = first_entry; i < (first_entry + num_entries); i++) {\r\nintel_private.driver->write_entry(intel_private.scratch_page_dma,\r\ni, 0);\r\n}\r\nwmb();\r\n}\r\nstatic int intel_fake_agp_remove_entries(struct agp_memory *mem,\r\noff_t pg_start, int type)\r\n{\r\nif (mem->page_count == 0)\r\nreturn 0;\r\nintel_gtt_clear_range(pg_start, mem->page_count);\r\nif (intel_private.needs_dmar) {\r\nintel_gtt_unmap_memory(mem->sg_list, mem->num_sg);\r\nmem->sg_list = NULL;\r\nmem->num_sg = 0;\r\n}\r\nreturn 0;\r\n}\r\nstatic struct agp_memory *intel_fake_agp_alloc_by_type(size_t pg_count,\r\nint type)\r\n{\r\nstruct agp_memory *new;\r\nif (type == AGP_DCACHE_MEMORY && INTEL_GTT_GEN == 1) {\r\nif (pg_count != intel_private.num_dcache_entries)\r\nreturn NULL;\r\nnew = agp_create_memory(1);\r\nif (new == NULL)\r\nreturn NULL;\r\nnew->type = AGP_DCACHE_MEMORY;\r\nnew->page_count = pg_count;\r\nnew->num_scratch_pages = 0;\r\nagp_free_page_array(new);\r\nreturn new;\r\n}\r\nif (type == AGP_PHYS_MEMORY)\r\nreturn alloc_agpphysmem_i8xx(pg_count, type);\r\nreturn NULL;\r\n}\r\nstatic int intel_alloc_chipset_flush_resource(void)\r\n{\r\nint ret;\r\nret = pci_bus_alloc_resource(intel_private.bridge_dev->bus, &intel_private.ifp_resource, PAGE_SIZE,\r\nPAGE_SIZE, PCIBIOS_MIN_MEM, 0,\r\npcibios_align_resource, intel_private.bridge_dev);\r\nreturn ret;\r\n}\r\nstatic void intel_i915_setup_chipset_flush(void)\r\n{\r\nint ret;\r\nu32 temp;\r\npci_read_config_dword(intel_private.bridge_dev, I915_IFPADDR, &temp);\r\nif (!(temp & 0x1)) {\r\nintel_alloc_chipset_flush_resource();\r\nintel_private.resource_valid = 1;\r\npci_write_config_dword(intel_private.bridge_dev, I915_IFPADDR, (intel_private.ifp_resource.start & 0xffffffff) | 0x1);\r\n} else {\r\ntemp &= ~1;\r\nintel_private.resource_valid = 1;\r\nintel_private.ifp_resource.start = temp;\r\nintel_private.ifp_resource.end = temp + PAGE_SIZE;\r\nret = request_resource(&iomem_resource, &intel_private.ifp_resource);\r\nif (ret)\r\nintel_private.resource_valid = 0;\r\n}\r\n}\r\nstatic void intel_i965_g33_setup_chipset_flush(void)\r\n{\r\nu32 temp_hi, temp_lo;\r\nint ret;\r\npci_read_config_dword(intel_private.bridge_dev, I965_IFPADDR + 4, &temp_hi);\r\npci_read_config_dword(intel_private.bridge_dev, I965_IFPADDR, &temp_lo);\r\nif (!(temp_lo & 0x1)) {\r\nintel_alloc_chipset_flush_resource();\r\nintel_private.resource_valid = 1;\r\npci_write_config_dword(intel_private.bridge_dev, I965_IFPADDR + 4,\r\nupper_32_bits(intel_private.ifp_resource.start));\r\npci_write_config_dword(intel_private.bridge_dev, I965_IFPADDR, (intel_private.ifp_resource.start & 0xffffffff) | 0x1);\r\n} else {\r\nu64 l64;\r\ntemp_lo &= ~0x1;\r\nl64 = ((u64)temp_hi << 32) | temp_lo;\r\nintel_private.resource_valid = 1;\r\nintel_private.ifp_resource.start = l64;\r\nintel_private.ifp_resource.end = l64 + PAGE_SIZE;\r\nret = request_resource(&iomem_resource, &intel_private.ifp_resource);\r\nif (ret)\r\nintel_private.resource_valid = 0;\r\n}\r\n}\r\nstatic void intel_i9xx_setup_flush(void)\r\n{\r\nif (intel_private.ifp_resource.start)\r\nreturn;\r\nif (INTEL_GTT_GEN == 6)\r\nreturn;\r\nintel_private.ifp_resource.name = "Intel Flush Page";\r\nintel_private.ifp_resource.flags = IORESOURCE_MEM;\r\nif (IS_G33 || INTEL_GTT_GEN >= 4) {\r\nintel_i965_g33_setup_chipset_flush();\r\n} else {\r\nintel_i915_setup_chipset_flush();\r\n}\r\nif (intel_private.ifp_resource.start)\r\nintel_private.i9xx_flush_page = ioremap_nocache(intel_private.ifp_resource.start, PAGE_SIZE);\r\nif (!intel_private.i9xx_flush_page)\r\ndev_err(&intel_private.pcidev->dev,\r\n"can't ioremap flush page - no chipset flushing\n");\r\n}\r\nstatic void i9xx_cleanup(void)\r\n{\r\nif (intel_private.i9xx_flush_page)\r\niounmap(intel_private.i9xx_flush_page);\r\nif (intel_private.resource_valid)\r\nrelease_resource(&intel_private.ifp_resource);\r\nintel_private.ifp_resource.start = 0;\r\nintel_private.resource_valid = 0;\r\n}\r\nstatic void i9xx_chipset_flush(void)\r\n{\r\nif (intel_private.i9xx_flush_page)\r\nwritel(1, intel_private.i9xx_flush_page);\r\n}\r\nstatic void i965_write_entry(dma_addr_t addr,\r\nunsigned int entry,\r\nunsigned int flags)\r\n{\r\nu32 pte_flags;\r\npte_flags = I810_PTE_VALID;\r\nif (flags == AGP_USER_CACHED_MEMORY)\r\npte_flags |= I830_PTE_SYSTEM_CACHED;\r\naddr |= (addr >> 28) & 0xf0;\r\nwritel_relaxed(addr | pte_flags, intel_private.gtt + entry);\r\n}\r\nstatic int i9xx_setup(void)\r\n{\r\nphys_addr_t reg_addr;\r\nint size = KB(512);\r\nreg_addr = pci_resource_start(intel_private.pcidev, I915_MMADR_BAR);\r\nintel_private.registers = ioremap(reg_addr, size);\r\nif (!intel_private.registers)\r\nreturn -ENOMEM;\r\nswitch (INTEL_GTT_GEN) {\r\ncase 3:\r\nintel_private.gtt_phys_addr =\r\npci_resource_start(intel_private.pcidev, I915_PTE_BAR);\r\nbreak;\r\ncase 5:\r\nintel_private.gtt_phys_addr = reg_addr + MB(2);\r\nbreak;\r\ndefault:\r\nintel_private.gtt_phys_addr = reg_addr + KB(512);\r\nbreak;\r\n}\r\nintel_i9xx_setup_flush();\r\nreturn 0;\r\n}\r\nstatic int find_gmch(u16 device)\r\n{\r\nstruct pci_dev *gmch_device;\r\ngmch_device = pci_get_device(PCI_VENDOR_ID_INTEL, device, NULL);\r\nif (gmch_device && PCI_FUNC(gmch_device->devfn) != 0) {\r\ngmch_device = pci_get_device(PCI_VENDOR_ID_INTEL,\r\ndevice, gmch_device);\r\n}\r\nif (!gmch_device)\r\nreturn 0;\r\nintel_private.pcidev = gmch_device;\r\nreturn 1;\r\n}\r\nint intel_gmch_probe(struct pci_dev *bridge_pdev, struct pci_dev *gpu_pdev,\r\nstruct agp_bridge_data *bridge)\r\n{\r\nint i, mask;\r\nif (intel_private.driver) {\r\nintel_private.refcount++;\r\nreturn 1;\r\n}\r\nfor (i = 0; intel_gtt_chipsets[i].name != NULL; i++) {\r\nif (gpu_pdev) {\r\nif (gpu_pdev->device ==\r\nintel_gtt_chipsets[i].gmch_chip_id) {\r\nintel_private.pcidev = pci_dev_get(gpu_pdev);\r\nintel_private.driver =\r\nintel_gtt_chipsets[i].gtt_driver;\r\nbreak;\r\n}\r\n} else if (find_gmch(intel_gtt_chipsets[i].gmch_chip_id)) {\r\nintel_private.driver =\r\nintel_gtt_chipsets[i].gtt_driver;\r\nbreak;\r\n}\r\n}\r\nif (!intel_private.driver)\r\nreturn 0;\r\nintel_private.refcount++;\r\n#if IS_ENABLED(CONFIG_AGP_INTEL)\r\nif (bridge) {\r\nbridge->driver = &intel_fake_agp_driver;\r\nbridge->dev_private_data = &intel_private;\r\nbridge->dev = bridge_pdev;\r\n}\r\n#endif\r\nintel_private.bridge_dev = pci_dev_get(bridge_pdev);\r\ndev_info(&bridge_pdev->dev, "Intel %s Chipset\n", intel_gtt_chipsets[i].name);\r\nmask = intel_private.driver->dma_mask_size;\r\nif (pci_set_dma_mask(intel_private.pcidev, DMA_BIT_MASK(mask)))\r\ndev_err(&intel_private.pcidev->dev,\r\n"set gfx device dma mask %d-bit failed!\n", mask);\r\nelse\r\npci_set_consistent_dma_mask(intel_private.pcidev,\r\nDMA_BIT_MASK(mask));\r\nif (intel_gtt_init() != 0) {\r\nintel_gmch_remove();\r\nreturn 0;\r\n}\r\nreturn 1;\r\n}\r\nvoid intel_gtt_get(size_t *gtt_total, size_t *stolen_size,\r\nphys_addr_t *mappable_base, unsigned long *mappable_end)\r\n{\r\n*gtt_total = intel_private.gtt_total_entries << PAGE_SHIFT;\r\n*stolen_size = intel_private.stolen_size;\r\n*mappable_base = intel_private.gma_bus_addr;\r\n*mappable_end = intel_private.gtt_mappable_entries << PAGE_SHIFT;\r\n}\r\nvoid intel_gtt_chipset_flush(void)\r\n{\r\nif (intel_private.driver->chipset_flush)\r\nintel_private.driver->chipset_flush();\r\n}\r\nvoid intel_gmch_remove(void)\r\n{\r\nif (--intel_private.refcount)\r\nreturn;\r\nif (intel_private.pcidev)\r\npci_dev_put(intel_private.pcidev);\r\nif (intel_private.bridge_dev)\r\npci_dev_put(intel_private.bridge_dev);\r\nintel_private.driver = NULL;\r\n}
