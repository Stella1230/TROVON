static int\r\njme_mdio_read(struct net_device *netdev, int phy, int reg)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nint i, val, again = (reg == MII_BMSR) ? 1 : 0;\r\nread_again:\r\njwrite32(jme, JME_SMI, SMI_OP_REQ |\r\nsmi_phy_addr(phy) |\r\nsmi_reg_addr(reg));\r\nwmb();\r\nfor (i = JME_PHY_TIMEOUT * 50 ; i > 0 ; --i) {\r\nudelay(20);\r\nval = jread32(jme, JME_SMI);\r\nif ((val & SMI_OP_REQ) == 0)\r\nbreak;\r\n}\r\nif (i == 0) {\r\npr_err("phy(%d) read timeout : %d\n", phy, reg);\r\nreturn 0;\r\n}\r\nif (again--)\r\ngoto read_again;\r\nreturn (val & SMI_DATA_MASK) >> SMI_DATA_SHIFT;\r\n}\r\nstatic void\r\njme_mdio_write(struct net_device *netdev,\r\nint phy, int reg, int val)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nint i;\r\njwrite32(jme, JME_SMI, SMI_OP_WRITE | SMI_OP_REQ |\r\n((val << SMI_DATA_SHIFT) & SMI_DATA_MASK) |\r\nsmi_phy_addr(phy) | smi_reg_addr(reg));\r\nwmb();\r\nfor (i = JME_PHY_TIMEOUT * 50 ; i > 0 ; --i) {\r\nudelay(20);\r\nif ((jread32(jme, JME_SMI) & SMI_OP_REQ) == 0)\r\nbreak;\r\n}\r\nif (i == 0)\r\npr_err("phy(%d) write timeout : %d\n", phy, reg);\r\n}\r\nstatic inline void\r\njme_reset_phy_processor(struct jme_adapter *jme)\r\n{\r\nu32 val;\r\njme_mdio_write(jme->dev,\r\njme->mii_if.phy_id,\r\nMII_ADVERTISE, ADVERTISE_ALL |\r\nADVERTISE_PAUSE_CAP | ADVERTISE_PAUSE_ASYM);\r\nif (jme->pdev->device == PCI_DEVICE_ID_JMICRON_JMC250)\r\njme_mdio_write(jme->dev,\r\njme->mii_if.phy_id,\r\nMII_CTRL1000,\r\nADVERTISE_1000FULL | ADVERTISE_1000HALF);\r\nval = jme_mdio_read(jme->dev,\r\njme->mii_if.phy_id,\r\nMII_BMCR);\r\njme_mdio_write(jme->dev,\r\njme->mii_if.phy_id,\r\nMII_BMCR, val | BMCR_RESET);\r\n}\r\nstatic void\r\njme_setup_wakeup_frame(struct jme_adapter *jme,\r\nconst u32 *mask, u32 crc, int fnr)\r\n{\r\nint i;\r\njwrite32(jme, JME_WFOI, WFOI_CRC_SEL | (fnr & WFOI_FRAME_SEL));\r\nwmb();\r\njwrite32(jme, JME_WFODP, crc);\r\nwmb();\r\nfor (i = 0 ; i < WAKEUP_FRAME_MASK_DWNR ; ++i) {\r\njwrite32(jme, JME_WFOI,\r\n((i << WFOI_MASK_SHIFT) & WFOI_MASK_SEL) |\r\n(fnr & WFOI_FRAME_SEL));\r\nwmb();\r\njwrite32(jme, JME_WFODP, mask[i]);\r\nwmb();\r\n}\r\n}\r\nstatic inline void\r\njme_mac_rxclk_off(struct jme_adapter *jme)\r\n{\r\njme->reg_gpreg1 |= GPREG1_RXCLKOFF;\r\njwrite32f(jme, JME_GPREG1, jme->reg_gpreg1);\r\n}\r\nstatic inline void\r\njme_mac_rxclk_on(struct jme_adapter *jme)\r\n{\r\njme->reg_gpreg1 &= ~GPREG1_RXCLKOFF;\r\njwrite32f(jme, JME_GPREG1, jme->reg_gpreg1);\r\n}\r\nstatic inline void\r\njme_mac_txclk_off(struct jme_adapter *jme)\r\n{\r\njme->reg_ghc &= ~(GHC_TO_CLK_SRC | GHC_TXMAC_CLK_SRC);\r\njwrite32f(jme, JME_GHC, jme->reg_ghc);\r\n}\r\nstatic inline void\r\njme_mac_txclk_on(struct jme_adapter *jme)\r\n{\r\nu32 speed = jme->reg_ghc & GHC_SPEED;\r\nif (speed == GHC_SPEED_1000M)\r\njme->reg_ghc |= GHC_TO_CLK_GPHY | GHC_TXMAC_CLK_GPHY;\r\nelse\r\njme->reg_ghc |= GHC_TO_CLK_PCIE | GHC_TXMAC_CLK_PCIE;\r\njwrite32f(jme, JME_GHC, jme->reg_ghc);\r\n}\r\nstatic inline void\r\njme_reset_ghc_speed(struct jme_adapter *jme)\r\n{\r\njme->reg_ghc &= ~(GHC_SPEED | GHC_DPX);\r\njwrite32f(jme, JME_GHC, jme->reg_ghc);\r\n}\r\nstatic inline void\r\njme_reset_250A2_workaround(struct jme_adapter *jme)\r\n{\r\njme->reg_gpreg1 &= ~(GPREG1_HALFMODEPATCH |\r\nGPREG1_RSSPATCH);\r\njwrite32(jme, JME_GPREG1, jme->reg_gpreg1);\r\n}\r\nstatic inline void\r\njme_assert_ghc_reset(struct jme_adapter *jme)\r\n{\r\njme->reg_ghc |= GHC_SWRST;\r\njwrite32f(jme, JME_GHC, jme->reg_ghc);\r\n}\r\nstatic inline void\r\njme_clear_ghc_reset(struct jme_adapter *jme)\r\n{\r\njme->reg_ghc &= ~GHC_SWRST;\r\njwrite32f(jme, JME_GHC, jme->reg_ghc);\r\n}\r\nstatic inline void\r\njme_reset_mac_processor(struct jme_adapter *jme)\r\n{\r\nstatic const u32 mask[WAKEUP_FRAME_MASK_DWNR] = {0, 0, 0, 0};\r\nu32 crc = 0xCDCDCDCD;\r\nu32 gpreg0;\r\nint i;\r\njme_reset_ghc_speed(jme);\r\njme_reset_250A2_workaround(jme);\r\njme_mac_rxclk_on(jme);\r\njme_mac_txclk_on(jme);\r\nudelay(1);\r\njme_assert_ghc_reset(jme);\r\nudelay(1);\r\njme_mac_rxclk_off(jme);\r\njme_mac_txclk_off(jme);\r\nudelay(1);\r\njme_clear_ghc_reset(jme);\r\nudelay(1);\r\njme_mac_rxclk_on(jme);\r\njme_mac_txclk_on(jme);\r\nudelay(1);\r\njme_mac_rxclk_off(jme);\r\njme_mac_txclk_off(jme);\r\njwrite32(jme, JME_RXDBA_LO, 0x00000000);\r\njwrite32(jme, JME_RXDBA_HI, 0x00000000);\r\njwrite32(jme, JME_RXQDC, 0x00000000);\r\njwrite32(jme, JME_RXNDA, 0x00000000);\r\njwrite32(jme, JME_TXDBA_LO, 0x00000000);\r\njwrite32(jme, JME_TXDBA_HI, 0x00000000);\r\njwrite32(jme, JME_TXQDC, 0x00000000);\r\njwrite32(jme, JME_TXNDA, 0x00000000);\r\njwrite32(jme, JME_RXMCHT_LO, 0x00000000);\r\njwrite32(jme, JME_RXMCHT_HI, 0x00000000);\r\nfor (i = 0 ; i < WAKEUP_FRAME_NR ; ++i)\r\njme_setup_wakeup_frame(jme, mask, crc, i);\r\nif (jme->fpgaver)\r\ngpreg0 = GPREG0_DEFAULT | GPREG0_LNKINTPOLL;\r\nelse\r\ngpreg0 = GPREG0_DEFAULT;\r\njwrite32(jme, JME_GPREG0, gpreg0);\r\n}\r\nstatic inline void\r\njme_clear_pm(struct jme_adapter *jme)\r\n{\r\njwrite32(jme, JME_PMCS, PMCS_STMASK | jme->reg_pmcs);\r\n}\r\nstatic int\r\njme_reload_eeprom(struct jme_adapter *jme)\r\n{\r\nu32 val;\r\nint i;\r\nval = jread32(jme, JME_SMBCSR);\r\nif (val & SMBCSR_EEPROMD) {\r\nval |= SMBCSR_CNACK;\r\njwrite32(jme, JME_SMBCSR, val);\r\nval |= SMBCSR_RELOAD;\r\njwrite32(jme, JME_SMBCSR, val);\r\nmdelay(12);\r\nfor (i = JME_EEPROM_RELOAD_TIMEOUT; i > 0; --i) {\r\nmdelay(1);\r\nif ((jread32(jme, JME_SMBCSR) & SMBCSR_RELOAD) == 0)\r\nbreak;\r\n}\r\nif (i == 0) {\r\npr_err("eeprom reload timeout\n");\r\nreturn -EIO;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void\r\njme_load_macaddr(struct net_device *netdev)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nunsigned char macaddr[ETH_ALEN];\r\nu32 val;\r\nspin_lock_bh(&jme->macaddr_lock);\r\nval = jread32(jme, JME_RXUMA_LO);\r\nmacaddr[0] = (val >> 0) & 0xFF;\r\nmacaddr[1] = (val >> 8) & 0xFF;\r\nmacaddr[2] = (val >> 16) & 0xFF;\r\nmacaddr[3] = (val >> 24) & 0xFF;\r\nval = jread32(jme, JME_RXUMA_HI);\r\nmacaddr[4] = (val >> 0) & 0xFF;\r\nmacaddr[5] = (val >> 8) & 0xFF;\r\nmemcpy(netdev->dev_addr, macaddr, ETH_ALEN);\r\nspin_unlock_bh(&jme->macaddr_lock);\r\n}\r\nstatic inline void\r\njme_set_rx_pcc(struct jme_adapter *jme, int p)\r\n{\r\nswitch (p) {\r\ncase PCC_OFF:\r\njwrite32(jme, JME_PCCRX0,\r\n((PCC_OFF_TO << PCCRXTO_SHIFT) & PCCRXTO_MASK) |\r\n((PCC_OFF_CNT << PCCRX_SHIFT) & PCCRX_MASK));\r\nbreak;\r\ncase PCC_P1:\r\njwrite32(jme, JME_PCCRX0,\r\n((PCC_P1_TO << PCCRXTO_SHIFT) & PCCRXTO_MASK) |\r\n((PCC_P1_CNT << PCCRX_SHIFT) & PCCRX_MASK));\r\nbreak;\r\ncase PCC_P2:\r\njwrite32(jme, JME_PCCRX0,\r\n((PCC_P2_TO << PCCRXTO_SHIFT) & PCCRXTO_MASK) |\r\n((PCC_P2_CNT << PCCRX_SHIFT) & PCCRX_MASK));\r\nbreak;\r\ncase PCC_P3:\r\njwrite32(jme, JME_PCCRX0,\r\n((PCC_P3_TO << PCCRXTO_SHIFT) & PCCRXTO_MASK) |\r\n((PCC_P3_CNT << PCCRX_SHIFT) & PCCRX_MASK));\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nwmb();\r\nif (!(test_bit(JME_FLAG_POLL, &jme->flags)))\r\nnetif_info(jme, rx_status, jme->dev, "Switched to PCC_P%d\n", p);\r\n}\r\nstatic void\r\njme_start_irq(struct jme_adapter *jme)\r\n{\r\nregister struct dynpcc_info *dpi = &(jme->dpi);\r\njme_set_rx_pcc(jme, PCC_P1);\r\ndpi->cur = PCC_P1;\r\ndpi->attempt = PCC_P1;\r\ndpi->cnt = 0;\r\njwrite32(jme, JME_PCCTX,\r\n((PCC_TX_TO << PCCTXTO_SHIFT) & PCCTXTO_MASK) |\r\n((PCC_TX_CNT << PCCTX_SHIFT) & PCCTX_MASK) |\r\nPCCTXQ0_EN\r\n);\r\njwrite32(jme, JME_IENS, INTR_ENABLE);\r\n}\r\nstatic inline void\r\njme_stop_irq(struct jme_adapter *jme)\r\n{\r\njwrite32f(jme, JME_IENC, INTR_ENABLE);\r\n}\r\nstatic u32\r\njme_linkstat_from_phy(struct jme_adapter *jme)\r\n{\r\nu32 phylink, bmsr;\r\nphylink = jme_mdio_read(jme->dev, jme->mii_if.phy_id, 17);\r\nbmsr = jme_mdio_read(jme->dev, jme->mii_if.phy_id, MII_BMSR);\r\nif (bmsr & BMSR_ANCOMP)\r\nphylink |= PHY_LINK_AUTONEG_COMPLETE;\r\nreturn phylink;\r\n}\r\nstatic inline void\r\njme_set_phyfifo_5level(struct jme_adapter *jme)\r\n{\r\njme_mdio_write(jme->dev, jme->mii_if.phy_id, 27, 0x0004);\r\n}\r\nstatic inline void\r\njme_set_phyfifo_8level(struct jme_adapter *jme)\r\n{\r\njme_mdio_write(jme->dev, jme->mii_if.phy_id, 27, 0x0000);\r\n}\r\nstatic int\r\njme_check_link(struct net_device *netdev, int testonly)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nu32 phylink, cnt = JME_SPDRSV_TIMEOUT, bmcr;\r\nchar linkmsg[64];\r\nint rc = 0;\r\nlinkmsg[0] = '\0';\r\nif (jme->fpgaver)\r\nphylink = jme_linkstat_from_phy(jme);\r\nelse\r\nphylink = jread32(jme, JME_PHY_LINK);\r\nif (phylink & PHY_LINK_UP) {\r\nif (!(phylink & PHY_LINK_AUTONEG_COMPLETE)) {\r\nphylink = PHY_LINK_UP;\r\nbmcr = jme_mdio_read(jme->dev,\r\njme->mii_if.phy_id,\r\nMII_BMCR);\r\nphylink |= ((bmcr & BMCR_SPEED1000) &&\r\n(bmcr & BMCR_SPEED100) == 0) ?\r\nPHY_LINK_SPEED_1000M :\r\n(bmcr & BMCR_SPEED100) ?\r\nPHY_LINK_SPEED_100M :\r\nPHY_LINK_SPEED_10M;\r\nphylink |= (bmcr & BMCR_FULLDPLX) ?\r\nPHY_LINK_DUPLEX : 0;\r\nstrcat(linkmsg, "Forced: ");\r\n} else {\r\nwhile (!(phylink & PHY_LINK_SPEEDDPU_RESOLVED) &&\r\n--cnt) {\r\nudelay(1);\r\nif (jme->fpgaver)\r\nphylink = jme_linkstat_from_phy(jme);\r\nelse\r\nphylink = jread32(jme, JME_PHY_LINK);\r\n}\r\nif (!cnt)\r\npr_err("Waiting speed resolve timeout\n");\r\nstrcat(linkmsg, "ANed: ");\r\n}\r\nif (jme->phylink == phylink) {\r\nrc = 1;\r\ngoto out;\r\n}\r\nif (testonly)\r\ngoto out;\r\njme->phylink = phylink;\r\nswitch (phylink & PHY_LINK_SPEED_MASK) {\r\ncase PHY_LINK_SPEED_10M:\r\njme->reg_ghc |= GHC_SPEED_10M;\r\nstrcat(linkmsg, "10 Mbps, ");\r\nbreak;\r\ncase PHY_LINK_SPEED_100M:\r\njme->reg_ghc |= GHC_SPEED_100M;\r\nstrcat(linkmsg, "100 Mbps, ");\r\nbreak;\r\ncase PHY_LINK_SPEED_1000M:\r\njme->reg_ghc |= GHC_SPEED_1000M;\r\nstrcat(linkmsg, "1000 Mbps, ");\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nif (phylink & PHY_LINK_DUPLEX) {\r\njwrite32(jme, JME_TXMCS, TXMCS_DEFAULT);\r\njwrite32(jme, JME_TXTRHD, TXTRHD_FULLDUPLEX);\r\njme->reg_ghc |= GHC_DPX;\r\n} else {\r\njwrite32(jme, JME_TXMCS, TXMCS_DEFAULT |\r\nTXMCS_BACKOFF |\r\nTXMCS_CARRIERSENSE |\r\nTXMCS_COLLISION);\r\njwrite32(jme, JME_TXTRHD, TXTRHD_HALFDUPLEX);\r\n}\r\njwrite32(jme, JME_GHC, jme->reg_ghc);\r\nif (is_buggy250(jme->pdev->device, jme->chiprev)) {\r\njme->reg_gpreg1 &= ~(GPREG1_HALFMODEPATCH |\r\nGPREG1_RSSPATCH);\r\nif (!(phylink & PHY_LINK_DUPLEX))\r\njme->reg_gpreg1 |= GPREG1_HALFMODEPATCH;\r\nswitch (phylink & PHY_LINK_SPEED_MASK) {\r\ncase PHY_LINK_SPEED_10M:\r\njme_set_phyfifo_8level(jme);\r\njme->reg_gpreg1 |= GPREG1_RSSPATCH;\r\nbreak;\r\ncase PHY_LINK_SPEED_100M:\r\njme_set_phyfifo_5level(jme);\r\njme->reg_gpreg1 |= GPREG1_RSSPATCH;\r\nbreak;\r\ncase PHY_LINK_SPEED_1000M:\r\njme_set_phyfifo_8level(jme);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\njwrite32(jme, JME_GPREG1, jme->reg_gpreg1);\r\nstrcat(linkmsg, (phylink & PHY_LINK_DUPLEX) ?\r\n"Full-Duplex, " :\r\n"Half-Duplex, ");\r\nstrcat(linkmsg, (phylink & PHY_LINK_MDI_STAT) ?\r\n"MDI-X" :\r\n"MDI");\r\nnetif_info(jme, link, jme->dev, "Link is up at %s\n", linkmsg);\r\nnetif_carrier_on(netdev);\r\n} else {\r\nif (testonly)\r\ngoto out;\r\nnetif_info(jme, link, jme->dev, "Link is down\n");\r\njme->phylink = 0;\r\nnetif_carrier_off(netdev);\r\n}\r\nout:\r\nreturn rc;\r\n}\r\nstatic int\r\njme_setup_tx_resources(struct jme_adapter *jme)\r\n{\r\nstruct jme_ring *txring = &(jme->txring[0]);\r\ntxring->alloc = dma_alloc_coherent(&(jme->pdev->dev),\r\nTX_RING_ALLOC_SIZE(jme->tx_ring_size),\r\n&(txring->dmaalloc),\r\nGFP_ATOMIC);\r\nif (!txring->alloc)\r\ngoto err_set_null;\r\ntxring->desc = (void *)ALIGN((unsigned long)(txring->alloc),\r\nRING_DESC_ALIGN);\r\ntxring->dma = ALIGN(txring->dmaalloc, RING_DESC_ALIGN);\r\ntxring->next_to_use = 0;\r\natomic_set(&txring->next_to_clean, 0);\r\natomic_set(&txring->nr_free, jme->tx_ring_size);\r\ntxring->bufinf = kmalloc(sizeof(struct jme_buffer_info) *\r\njme->tx_ring_size, GFP_ATOMIC);\r\nif (unlikely(!(txring->bufinf)))\r\ngoto err_free_txring;\r\nmemset(txring->alloc, 0, TX_RING_ALLOC_SIZE(jme->tx_ring_size));\r\nmemset(txring->bufinf, 0,\r\nsizeof(struct jme_buffer_info) * jme->tx_ring_size);\r\nreturn 0;\r\nerr_free_txring:\r\ndma_free_coherent(&(jme->pdev->dev),\r\nTX_RING_ALLOC_SIZE(jme->tx_ring_size),\r\ntxring->alloc,\r\ntxring->dmaalloc);\r\nerr_set_null:\r\ntxring->desc = NULL;\r\ntxring->dmaalloc = 0;\r\ntxring->dma = 0;\r\ntxring->bufinf = NULL;\r\nreturn -ENOMEM;\r\n}\r\nstatic void\r\njme_free_tx_resources(struct jme_adapter *jme)\r\n{\r\nint i;\r\nstruct jme_ring *txring = &(jme->txring[0]);\r\nstruct jme_buffer_info *txbi;\r\nif (txring->alloc) {\r\nif (txring->bufinf) {\r\nfor (i = 0 ; i < jme->tx_ring_size ; ++i) {\r\ntxbi = txring->bufinf + i;\r\nif (txbi->skb) {\r\ndev_kfree_skb(txbi->skb);\r\ntxbi->skb = NULL;\r\n}\r\ntxbi->mapping = 0;\r\ntxbi->len = 0;\r\ntxbi->nr_desc = 0;\r\ntxbi->start_xmit = 0;\r\n}\r\nkfree(txring->bufinf);\r\n}\r\ndma_free_coherent(&(jme->pdev->dev),\r\nTX_RING_ALLOC_SIZE(jme->tx_ring_size),\r\ntxring->alloc,\r\ntxring->dmaalloc);\r\ntxring->alloc = NULL;\r\ntxring->desc = NULL;\r\ntxring->dmaalloc = 0;\r\ntxring->dma = 0;\r\ntxring->bufinf = NULL;\r\n}\r\ntxring->next_to_use = 0;\r\natomic_set(&txring->next_to_clean, 0);\r\natomic_set(&txring->nr_free, 0);\r\n}\r\nstatic inline void\r\njme_enable_tx_engine(struct jme_adapter *jme)\r\n{\r\njwrite32(jme, JME_TXCS, TXCS_DEFAULT | TXCS_SELECT_QUEUE0);\r\nwmb();\r\njwrite32(jme, JME_TXDBA_LO, (__u64)jme->txring[0].dma & 0xFFFFFFFFUL);\r\njwrite32(jme, JME_TXDBA_HI, (__u64)(jme->txring[0].dma) >> 32);\r\njwrite32(jme, JME_TXNDA, (__u64)jme->txring[0].dma & 0xFFFFFFFFUL);\r\njwrite32(jme, JME_TXQDC, jme->tx_ring_size);\r\nwmb();\r\njwrite32f(jme, JME_TXCS, jme->reg_txcs |\r\nTXCS_SELECT_QUEUE0 |\r\nTXCS_ENABLE);\r\njme_mac_txclk_on(jme);\r\n}\r\nstatic inline void\r\njme_restart_tx_engine(struct jme_adapter *jme)\r\n{\r\njwrite32(jme, JME_TXCS, jme->reg_txcs |\r\nTXCS_SELECT_QUEUE0 |\r\nTXCS_ENABLE);\r\n}\r\nstatic inline void\r\njme_disable_tx_engine(struct jme_adapter *jme)\r\n{\r\nint i;\r\nu32 val;\r\njwrite32(jme, JME_TXCS, jme->reg_txcs | TXCS_SELECT_QUEUE0);\r\nwmb();\r\nval = jread32(jme, JME_TXCS);\r\nfor (i = JME_TX_DISABLE_TIMEOUT ; (val & TXCS_ENABLE) && i > 0 ; --i) {\r\nmdelay(1);\r\nval = jread32(jme, JME_TXCS);\r\nrmb();\r\n}\r\nif (!i)\r\npr_err("Disable TX engine timeout\n");\r\njme_mac_txclk_off(jme);\r\n}\r\nstatic void\r\njme_set_clean_rxdesc(struct jme_adapter *jme, int i)\r\n{\r\nstruct jme_ring *rxring = &(jme->rxring[0]);\r\nregister struct rxdesc *rxdesc = rxring->desc;\r\nstruct jme_buffer_info *rxbi = rxring->bufinf;\r\nrxdesc += i;\r\nrxbi += i;\r\nrxdesc->dw[0] = 0;\r\nrxdesc->dw[1] = 0;\r\nrxdesc->desc1.bufaddrh = cpu_to_le32((__u64)rxbi->mapping >> 32);\r\nrxdesc->desc1.bufaddrl = cpu_to_le32(\r\n(__u64)rxbi->mapping & 0xFFFFFFFFUL);\r\nrxdesc->desc1.datalen = cpu_to_le16(rxbi->len);\r\nif (jme->dev->features & NETIF_F_HIGHDMA)\r\nrxdesc->desc1.flags = RXFLAG_64BIT;\r\nwmb();\r\nrxdesc->desc1.flags |= RXFLAG_OWN | RXFLAG_INT;\r\n}\r\nstatic int\r\njme_make_new_rx_buf(struct jme_adapter *jme, int i)\r\n{\r\nstruct jme_ring *rxring = &(jme->rxring[0]);\r\nstruct jme_buffer_info *rxbi = rxring->bufinf + i;\r\nstruct sk_buff *skb;\r\ndma_addr_t mapping;\r\nskb = netdev_alloc_skb(jme->dev,\r\njme->dev->mtu + RX_EXTRA_LEN);\r\nif (unlikely(!skb))\r\nreturn -ENOMEM;\r\nmapping = pci_map_page(jme->pdev, virt_to_page(skb->data),\r\noffset_in_page(skb->data), skb_tailroom(skb),\r\nPCI_DMA_FROMDEVICE);\r\nif (unlikely(pci_dma_mapping_error(jme->pdev, mapping))) {\r\ndev_kfree_skb(skb);\r\nreturn -ENOMEM;\r\n}\r\nif (likely(rxbi->mapping))\r\npci_unmap_page(jme->pdev, rxbi->mapping,\r\nrxbi->len, PCI_DMA_FROMDEVICE);\r\nrxbi->skb = skb;\r\nrxbi->len = skb_tailroom(skb);\r\nrxbi->mapping = mapping;\r\nreturn 0;\r\n}\r\nstatic void\r\njme_free_rx_buf(struct jme_adapter *jme, int i)\r\n{\r\nstruct jme_ring *rxring = &(jme->rxring[0]);\r\nstruct jme_buffer_info *rxbi = rxring->bufinf;\r\nrxbi += i;\r\nif (rxbi->skb) {\r\npci_unmap_page(jme->pdev,\r\nrxbi->mapping,\r\nrxbi->len,\r\nPCI_DMA_FROMDEVICE);\r\ndev_kfree_skb(rxbi->skb);\r\nrxbi->skb = NULL;\r\nrxbi->mapping = 0;\r\nrxbi->len = 0;\r\n}\r\n}\r\nstatic void\r\njme_free_rx_resources(struct jme_adapter *jme)\r\n{\r\nint i;\r\nstruct jme_ring *rxring = &(jme->rxring[0]);\r\nif (rxring->alloc) {\r\nif (rxring->bufinf) {\r\nfor (i = 0 ; i < jme->rx_ring_size ; ++i)\r\njme_free_rx_buf(jme, i);\r\nkfree(rxring->bufinf);\r\n}\r\ndma_free_coherent(&(jme->pdev->dev),\r\nRX_RING_ALLOC_SIZE(jme->rx_ring_size),\r\nrxring->alloc,\r\nrxring->dmaalloc);\r\nrxring->alloc = NULL;\r\nrxring->desc = NULL;\r\nrxring->dmaalloc = 0;\r\nrxring->dma = 0;\r\nrxring->bufinf = NULL;\r\n}\r\nrxring->next_to_use = 0;\r\natomic_set(&rxring->next_to_clean, 0);\r\n}\r\nstatic int\r\njme_setup_rx_resources(struct jme_adapter *jme)\r\n{\r\nint i;\r\nstruct jme_ring *rxring = &(jme->rxring[0]);\r\nrxring->alloc = dma_alloc_coherent(&(jme->pdev->dev),\r\nRX_RING_ALLOC_SIZE(jme->rx_ring_size),\r\n&(rxring->dmaalloc),\r\nGFP_ATOMIC);\r\nif (!rxring->alloc)\r\ngoto err_set_null;\r\nrxring->desc = (void *)ALIGN((unsigned long)(rxring->alloc),\r\nRING_DESC_ALIGN);\r\nrxring->dma = ALIGN(rxring->dmaalloc, RING_DESC_ALIGN);\r\nrxring->next_to_use = 0;\r\natomic_set(&rxring->next_to_clean, 0);\r\nrxring->bufinf = kmalloc(sizeof(struct jme_buffer_info) *\r\njme->rx_ring_size, GFP_ATOMIC);\r\nif (unlikely(!(rxring->bufinf)))\r\ngoto err_free_rxring;\r\nmemset(rxring->bufinf, 0,\r\nsizeof(struct jme_buffer_info) * jme->rx_ring_size);\r\nfor (i = 0 ; i < jme->rx_ring_size ; ++i) {\r\nif (unlikely(jme_make_new_rx_buf(jme, i))) {\r\njme_free_rx_resources(jme);\r\nreturn -ENOMEM;\r\n}\r\njme_set_clean_rxdesc(jme, i);\r\n}\r\nreturn 0;\r\nerr_free_rxring:\r\ndma_free_coherent(&(jme->pdev->dev),\r\nRX_RING_ALLOC_SIZE(jme->rx_ring_size),\r\nrxring->alloc,\r\nrxring->dmaalloc);\r\nerr_set_null:\r\nrxring->desc = NULL;\r\nrxring->dmaalloc = 0;\r\nrxring->dma = 0;\r\nrxring->bufinf = NULL;\r\nreturn -ENOMEM;\r\n}\r\nstatic inline void\r\njme_enable_rx_engine(struct jme_adapter *jme)\r\n{\r\njwrite32(jme, JME_RXCS, jme->reg_rxcs |\r\nRXCS_QUEUESEL_Q0);\r\nwmb();\r\njwrite32(jme, JME_RXDBA_LO, (__u64)(jme->rxring[0].dma) & 0xFFFFFFFFUL);\r\njwrite32(jme, JME_RXDBA_HI, (__u64)(jme->rxring[0].dma) >> 32);\r\njwrite32(jme, JME_RXNDA, (__u64)(jme->rxring[0].dma) & 0xFFFFFFFFUL);\r\njwrite32(jme, JME_RXQDC, jme->rx_ring_size);\r\njme_set_unicastaddr(jme->dev);\r\njme_set_multi(jme->dev);\r\nwmb();\r\njwrite32f(jme, JME_RXCS, jme->reg_rxcs |\r\nRXCS_QUEUESEL_Q0 |\r\nRXCS_ENABLE |\r\nRXCS_QST);\r\njme_mac_rxclk_on(jme);\r\n}\r\nstatic inline void\r\njme_restart_rx_engine(struct jme_adapter *jme)\r\n{\r\njwrite32(jme, JME_RXCS, jme->reg_rxcs |\r\nRXCS_QUEUESEL_Q0 |\r\nRXCS_ENABLE |\r\nRXCS_QST);\r\n}\r\nstatic inline void\r\njme_disable_rx_engine(struct jme_adapter *jme)\r\n{\r\nint i;\r\nu32 val;\r\njwrite32(jme, JME_RXCS, jme->reg_rxcs);\r\nwmb();\r\nval = jread32(jme, JME_RXCS);\r\nfor (i = JME_RX_DISABLE_TIMEOUT ; (val & RXCS_ENABLE) && i > 0 ; --i) {\r\nmdelay(1);\r\nval = jread32(jme, JME_RXCS);\r\nrmb();\r\n}\r\nif (!i)\r\npr_err("Disable RX engine timeout\n");\r\njme_mac_rxclk_off(jme);\r\n}\r\nstatic u16\r\njme_udpsum(struct sk_buff *skb)\r\n{\r\nu16 csum = 0xFFFFu;\r\nif (skb->len < (ETH_HLEN + sizeof(struct iphdr)))\r\nreturn csum;\r\nif (skb->protocol != htons(ETH_P_IP))\r\nreturn csum;\r\nskb_set_network_header(skb, ETH_HLEN);\r\nif ((ip_hdr(skb)->protocol != IPPROTO_UDP) ||\r\n(skb->len < (ETH_HLEN +\r\n(ip_hdr(skb)->ihl << 2) +\r\nsizeof(struct udphdr)))) {\r\nskb_reset_network_header(skb);\r\nreturn csum;\r\n}\r\nskb_set_transport_header(skb,\r\nETH_HLEN + (ip_hdr(skb)->ihl << 2));\r\ncsum = udp_hdr(skb)->check;\r\nskb_reset_transport_header(skb);\r\nskb_reset_network_header(skb);\r\nreturn csum;\r\n}\r\nstatic int\r\njme_rxsum_ok(struct jme_adapter *jme, u16 flags, struct sk_buff *skb)\r\n{\r\nif (!(flags & (RXWBFLAG_TCPON | RXWBFLAG_UDPON | RXWBFLAG_IPV4)))\r\nreturn false;\r\nif (unlikely((flags & (RXWBFLAG_MF | RXWBFLAG_TCPON | RXWBFLAG_TCPCS))\r\n== RXWBFLAG_TCPON)) {\r\nif (flags & RXWBFLAG_IPV4)\r\nnetif_err(jme, rx_err, jme->dev, "TCP Checksum error\n");\r\nreturn false;\r\n}\r\nif (unlikely((flags & (RXWBFLAG_MF | RXWBFLAG_UDPON | RXWBFLAG_UDPCS))\r\n== RXWBFLAG_UDPON) && jme_udpsum(skb)) {\r\nif (flags & RXWBFLAG_IPV4)\r\nnetif_err(jme, rx_err, jme->dev, "UDP Checksum error\n");\r\nreturn false;\r\n}\r\nif (unlikely((flags & (RXWBFLAG_IPV4 | RXWBFLAG_IPCS))\r\n== RXWBFLAG_IPV4)) {\r\nnetif_err(jme, rx_err, jme->dev, "IPv4 Checksum error\n");\r\nreturn false;\r\n}\r\nreturn true;\r\n}\r\nstatic void\r\njme_alloc_and_feed_skb(struct jme_adapter *jme, int idx)\r\n{\r\nstruct jme_ring *rxring = &(jme->rxring[0]);\r\nstruct rxdesc *rxdesc = rxring->desc;\r\nstruct jme_buffer_info *rxbi = rxring->bufinf;\r\nstruct sk_buff *skb;\r\nint framesize;\r\nrxdesc += idx;\r\nrxbi += idx;\r\nskb = rxbi->skb;\r\npci_dma_sync_single_for_cpu(jme->pdev,\r\nrxbi->mapping,\r\nrxbi->len,\r\nPCI_DMA_FROMDEVICE);\r\nif (unlikely(jme_make_new_rx_buf(jme, idx))) {\r\npci_dma_sync_single_for_device(jme->pdev,\r\nrxbi->mapping,\r\nrxbi->len,\r\nPCI_DMA_FROMDEVICE);\r\n++(NET_STAT(jme).rx_dropped);\r\n} else {\r\nframesize = le16_to_cpu(rxdesc->descwb.framesize)\r\n- RX_PREPAD_SIZE;\r\nskb_reserve(skb, RX_PREPAD_SIZE);\r\nskb_put(skb, framesize);\r\nskb->protocol = eth_type_trans(skb, jme->dev);\r\nif (jme_rxsum_ok(jme, le16_to_cpu(rxdesc->descwb.flags), skb))\r\nskb->ip_summed = CHECKSUM_UNNECESSARY;\r\nelse\r\nskb_checksum_none_assert(skb);\r\nif (rxdesc->descwb.flags & cpu_to_le16(RXWBFLAG_TAGON)) {\r\nu16 vid = le16_to_cpu(rxdesc->descwb.vlan);\r\n__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vid);\r\nNET_STAT(jme).rx_bytes += 4;\r\n}\r\njme->jme_rx(skb);\r\nif ((rxdesc->descwb.flags & cpu_to_le16(RXWBFLAG_DEST)) ==\r\ncpu_to_le16(RXWBFLAG_DEST_MUL))\r\n++(NET_STAT(jme).multicast);\r\nNET_STAT(jme).rx_bytes += framesize;\r\n++(NET_STAT(jme).rx_packets);\r\n}\r\njme_set_clean_rxdesc(jme, idx);\r\n}\r\nstatic int\r\njme_process_receive(struct jme_adapter *jme, int limit)\r\n{\r\nstruct jme_ring *rxring = &(jme->rxring[0]);\r\nstruct rxdesc *rxdesc = rxring->desc;\r\nint i, j, ccnt, desccnt, mask = jme->rx_ring_mask;\r\nif (unlikely(!atomic_dec_and_test(&jme->rx_cleaning)))\r\ngoto out_inc;\r\nif (unlikely(atomic_read(&jme->link_changing) != 1))\r\ngoto out_inc;\r\nif (unlikely(!netif_carrier_ok(jme->dev)))\r\ngoto out_inc;\r\ni = atomic_read(&rxring->next_to_clean);\r\nwhile (limit > 0) {\r\nrxdesc = rxring->desc;\r\nrxdesc += i;\r\nif ((rxdesc->descwb.flags & cpu_to_le16(RXWBFLAG_OWN)) ||\r\n!(rxdesc->descwb.desccnt & RXWBDCNT_WBCPL))\r\ngoto out;\r\n--limit;\r\nrmb();\r\ndesccnt = rxdesc->descwb.desccnt & RXWBDCNT_DCNT;\r\nif (unlikely(desccnt > 1 ||\r\nrxdesc->descwb.errstat & RXWBERR_ALLERR)) {\r\nif (rxdesc->descwb.errstat & RXWBERR_CRCERR)\r\n++(NET_STAT(jme).rx_crc_errors);\r\nelse if (rxdesc->descwb.errstat & RXWBERR_OVERUN)\r\n++(NET_STAT(jme).rx_fifo_errors);\r\nelse\r\n++(NET_STAT(jme).rx_errors);\r\nif (desccnt > 1)\r\nlimit -= desccnt - 1;\r\nfor (j = i, ccnt = desccnt ; ccnt-- ; ) {\r\njme_set_clean_rxdesc(jme, j);\r\nj = (j + 1) & (mask);\r\n}\r\n} else {\r\njme_alloc_and_feed_skb(jme, i);\r\n}\r\ni = (i + desccnt) & (mask);\r\n}\r\nout:\r\natomic_set(&rxring->next_to_clean, i);\r\nout_inc:\r\natomic_inc(&jme->rx_cleaning);\r\nreturn limit > 0 ? limit : 0;\r\n}\r\nstatic void\r\njme_attempt_pcc(struct dynpcc_info *dpi, int atmp)\r\n{\r\nif (likely(atmp == dpi->cur)) {\r\ndpi->cnt = 0;\r\nreturn;\r\n}\r\nif (dpi->attempt == atmp) {\r\n++(dpi->cnt);\r\n} else {\r\ndpi->attempt = atmp;\r\ndpi->cnt = 0;\r\n}\r\n}\r\nstatic void\r\njme_dynamic_pcc(struct jme_adapter *jme)\r\n{\r\nregister struct dynpcc_info *dpi = &(jme->dpi);\r\nif ((NET_STAT(jme).rx_bytes - dpi->last_bytes) > PCC_P3_THRESHOLD)\r\njme_attempt_pcc(dpi, PCC_P3);\r\nelse if ((NET_STAT(jme).rx_packets - dpi->last_pkts) > PCC_P2_THRESHOLD ||\r\ndpi->intr_cnt > PCC_INTR_THRESHOLD)\r\njme_attempt_pcc(dpi, PCC_P2);\r\nelse\r\njme_attempt_pcc(dpi, PCC_P1);\r\nif (unlikely(dpi->attempt != dpi->cur && dpi->cnt > 5)) {\r\nif (dpi->attempt < dpi->cur)\r\ntasklet_schedule(&jme->rxclean_task);\r\njme_set_rx_pcc(jme, dpi->attempt);\r\ndpi->cur = dpi->attempt;\r\ndpi->cnt = 0;\r\n}\r\n}\r\nstatic void\r\njme_start_pcc_timer(struct jme_adapter *jme)\r\n{\r\nstruct dynpcc_info *dpi = &(jme->dpi);\r\ndpi->last_bytes = NET_STAT(jme).rx_bytes;\r\ndpi->last_pkts = NET_STAT(jme).rx_packets;\r\ndpi->intr_cnt = 0;\r\njwrite32(jme, JME_TMCSR,\r\nTMCSR_EN | ((0xFFFFFF - PCC_INTERVAL_US) & TMCSR_CNT));\r\n}\r\nstatic inline void\r\njme_stop_pcc_timer(struct jme_adapter *jme)\r\n{\r\njwrite32(jme, JME_TMCSR, 0);\r\n}\r\nstatic void\r\njme_shutdown_nic(struct jme_adapter *jme)\r\n{\r\nu32 phylink;\r\nphylink = jme_linkstat_from_phy(jme);\r\nif (!(phylink & PHY_LINK_UP)) {\r\njme_stop_irq(jme);\r\njwrite32(jme, JME_TIMER2, TMCSR_EN | 0xFFFFFE);\r\n}\r\n}\r\nstatic void\r\njme_pcc_tasklet(unsigned long arg)\r\n{\r\nstruct jme_adapter *jme = (struct jme_adapter *)arg;\r\nstruct net_device *netdev = jme->dev;\r\nif (unlikely(test_bit(JME_FLAG_SHUTDOWN, &jme->flags))) {\r\njme_shutdown_nic(jme);\r\nreturn;\r\n}\r\nif (unlikely(!netif_carrier_ok(netdev) ||\r\n(atomic_read(&jme->link_changing) != 1)\r\n)) {\r\njme_stop_pcc_timer(jme);\r\nreturn;\r\n}\r\nif (!(test_bit(JME_FLAG_POLL, &jme->flags)))\r\njme_dynamic_pcc(jme);\r\njme_start_pcc_timer(jme);\r\n}\r\nstatic inline void\r\njme_polling_mode(struct jme_adapter *jme)\r\n{\r\njme_set_rx_pcc(jme, PCC_OFF);\r\n}\r\nstatic inline void\r\njme_interrupt_mode(struct jme_adapter *jme)\r\n{\r\njme_set_rx_pcc(jme, PCC_P1);\r\n}\r\nstatic inline int\r\njme_pseudo_hotplug_enabled(struct jme_adapter *jme)\r\n{\r\nu32 apmc;\r\napmc = jread32(jme, JME_APMC);\r\nreturn apmc & JME_APMC_PSEUDO_HP_EN;\r\n}\r\nstatic void\r\njme_start_shutdown_timer(struct jme_adapter *jme)\r\n{\r\nu32 apmc;\r\napmc = jread32(jme, JME_APMC) | JME_APMC_PCIE_SD_EN;\r\napmc &= ~JME_APMC_EPIEN_CTRL;\r\nif (!no_extplug) {\r\njwrite32f(jme, JME_APMC, apmc | JME_APMC_EPIEN_CTRL_EN);\r\nwmb();\r\n}\r\njwrite32f(jme, JME_APMC, apmc);\r\njwrite32f(jme, JME_TIMER2, 0);\r\nset_bit(JME_FLAG_SHUTDOWN, &jme->flags);\r\njwrite32(jme, JME_TMCSR,\r\nTMCSR_EN | ((0xFFFFFF - APMC_PHP_SHUTDOWN_DELAY) & TMCSR_CNT));\r\n}\r\nstatic void\r\njme_stop_shutdown_timer(struct jme_adapter *jme)\r\n{\r\nu32 apmc;\r\njwrite32f(jme, JME_TMCSR, 0);\r\njwrite32f(jme, JME_TIMER2, 0);\r\nclear_bit(JME_FLAG_SHUTDOWN, &jme->flags);\r\napmc = jread32(jme, JME_APMC);\r\napmc &= ~(JME_APMC_PCIE_SD_EN | JME_APMC_EPIEN_CTRL);\r\njwrite32f(jme, JME_APMC, apmc | JME_APMC_EPIEN_CTRL_DIS);\r\nwmb();\r\njwrite32f(jme, JME_APMC, apmc);\r\n}\r\nstatic void\r\njme_link_change_tasklet(unsigned long arg)\r\n{\r\nstruct jme_adapter *jme = (struct jme_adapter *)arg;\r\nstruct net_device *netdev = jme->dev;\r\nint rc;\r\nwhile (!atomic_dec_and_test(&jme->link_changing)) {\r\natomic_inc(&jme->link_changing);\r\nnetif_info(jme, intr, jme->dev, "Get link change lock failed\n");\r\nwhile (atomic_read(&jme->link_changing) != 1)\r\nnetif_info(jme, intr, jme->dev, "Waiting link change lock\n");\r\n}\r\nif (jme_check_link(netdev, 1) && jme->old_mtu == netdev->mtu)\r\ngoto out;\r\njme->old_mtu = netdev->mtu;\r\nnetif_stop_queue(netdev);\r\nif (jme_pseudo_hotplug_enabled(jme))\r\njme_stop_shutdown_timer(jme);\r\njme_stop_pcc_timer(jme);\r\ntasklet_disable(&jme->txclean_task);\r\ntasklet_disable(&jme->rxclean_task);\r\ntasklet_disable(&jme->rxempty_task);\r\nif (netif_carrier_ok(netdev)) {\r\njme_disable_rx_engine(jme);\r\njme_disable_tx_engine(jme);\r\njme_reset_mac_processor(jme);\r\njme_free_rx_resources(jme);\r\njme_free_tx_resources(jme);\r\nif (test_bit(JME_FLAG_POLL, &jme->flags))\r\njme_polling_mode(jme);\r\nnetif_carrier_off(netdev);\r\n}\r\njme_check_link(netdev, 0);\r\nif (netif_carrier_ok(netdev)) {\r\nrc = jme_setup_rx_resources(jme);\r\nif (rc) {\r\npr_err("Allocating resources for RX error, Device STOPPED!\n");\r\ngoto out_enable_tasklet;\r\n}\r\nrc = jme_setup_tx_resources(jme);\r\nif (rc) {\r\npr_err("Allocating resources for TX error, Device STOPPED!\n");\r\ngoto err_out_free_rx_resources;\r\n}\r\njme_enable_rx_engine(jme);\r\njme_enable_tx_engine(jme);\r\nnetif_start_queue(netdev);\r\nif (test_bit(JME_FLAG_POLL, &jme->flags))\r\njme_interrupt_mode(jme);\r\njme_start_pcc_timer(jme);\r\n} else if (jme_pseudo_hotplug_enabled(jme)) {\r\njme_start_shutdown_timer(jme);\r\n}\r\ngoto out_enable_tasklet;\r\nerr_out_free_rx_resources:\r\njme_free_rx_resources(jme);\r\nout_enable_tasklet:\r\ntasklet_enable(&jme->txclean_task);\r\ntasklet_enable(&jme->rxclean_task);\r\ntasklet_enable(&jme->rxempty_task);\r\nout:\r\natomic_inc(&jme->link_changing);\r\n}\r\nstatic void\r\njme_rx_clean_tasklet(unsigned long arg)\r\n{\r\nstruct jme_adapter *jme = (struct jme_adapter *)arg;\r\nstruct dynpcc_info *dpi = &(jme->dpi);\r\njme_process_receive(jme, jme->rx_ring_size);\r\n++(dpi->intr_cnt);\r\n}\r\nstatic void\r\njme_rx_empty_tasklet(unsigned long arg)\r\n{\r\nstruct jme_adapter *jme = (struct jme_adapter *)arg;\r\nif (unlikely(atomic_read(&jme->link_changing) != 1))\r\nreturn;\r\nif (unlikely(!netif_carrier_ok(jme->dev)))\r\nreturn;\r\nnetif_info(jme, rx_status, jme->dev, "RX Queue Full!\n");\r\njme_rx_clean_tasklet(arg);\r\nwhile (atomic_read(&jme->rx_empty) > 0) {\r\natomic_dec(&jme->rx_empty);\r\n++(NET_STAT(jme).rx_dropped);\r\njme_restart_rx_engine(jme);\r\n}\r\natomic_inc(&jme->rx_empty);\r\n}\r\nstatic void\r\njme_wake_queue_if_stopped(struct jme_adapter *jme)\r\n{\r\nstruct jme_ring *txring = &(jme->txring[0]);\r\nsmp_wmb();\r\nif (unlikely(netif_queue_stopped(jme->dev) &&\r\natomic_read(&txring->nr_free) >= (jme->tx_wake_threshold))) {\r\nnetif_info(jme, tx_done, jme->dev, "TX Queue Waked\n");\r\nnetif_wake_queue(jme->dev);\r\n}\r\n}\r\nstatic void\r\njme_tx_clean_tasklet(unsigned long arg)\r\n{\r\nstruct jme_adapter *jme = (struct jme_adapter *)arg;\r\nstruct jme_ring *txring = &(jme->txring[0]);\r\nstruct txdesc *txdesc = txring->desc;\r\nstruct jme_buffer_info *txbi = txring->bufinf, *ctxbi, *ttxbi;\r\nint i, j, cnt = 0, max, err, mask;\r\ntx_dbg(jme, "Into txclean\n");\r\nif (unlikely(!atomic_dec_and_test(&jme->tx_cleaning)))\r\ngoto out;\r\nif (unlikely(atomic_read(&jme->link_changing) != 1))\r\ngoto out;\r\nif (unlikely(!netif_carrier_ok(jme->dev)))\r\ngoto out;\r\nmax = jme->tx_ring_size - atomic_read(&txring->nr_free);\r\nmask = jme->tx_ring_mask;\r\nfor (i = atomic_read(&txring->next_to_clean) ; cnt < max ; ) {\r\nctxbi = txbi + i;\r\nif (likely(ctxbi->skb &&\r\n!(txdesc[i].descwb.flags & TXWBFLAG_OWN))) {\r\ntx_dbg(jme, "txclean: %d+%d@%lu\n",\r\ni, ctxbi->nr_desc, jiffies);\r\nerr = txdesc[i].descwb.flags & TXWBFLAG_ALLERR;\r\nfor (j = 1 ; j < ctxbi->nr_desc ; ++j) {\r\nttxbi = txbi + ((i + j) & (mask));\r\ntxdesc[(i + j) & (mask)].dw[0] = 0;\r\npci_unmap_page(jme->pdev,\r\nttxbi->mapping,\r\nttxbi->len,\r\nPCI_DMA_TODEVICE);\r\nttxbi->mapping = 0;\r\nttxbi->len = 0;\r\n}\r\ndev_kfree_skb(ctxbi->skb);\r\ncnt += ctxbi->nr_desc;\r\nif (unlikely(err)) {\r\n++(NET_STAT(jme).tx_carrier_errors);\r\n} else {\r\n++(NET_STAT(jme).tx_packets);\r\nNET_STAT(jme).tx_bytes += ctxbi->len;\r\n}\r\nctxbi->skb = NULL;\r\nctxbi->len = 0;\r\nctxbi->start_xmit = 0;\r\n} else {\r\nbreak;\r\n}\r\ni = (i + ctxbi->nr_desc) & mask;\r\nctxbi->nr_desc = 0;\r\n}\r\ntx_dbg(jme, "txclean: done %d@%lu\n", i, jiffies);\r\natomic_set(&txring->next_to_clean, i);\r\natomic_add(cnt, &txring->nr_free);\r\njme_wake_queue_if_stopped(jme);\r\nout:\r\natomic_inc(&jme->tx_cleaning);\r\n}\r\nstatic void\r\njme_intr_msi(struct jme_adapter *jme, u32 intrstat)\r\n{\r\njwrite32f(jme, JME_IENC, INTR_ENABLE);\r\nif (intrstat & (INTR_LINKCH | INTR_SWINTR)) {\r\njwrite32(jme, JME_IEVE, intrstat);\r\ntasklet_schedule(&jme->linkch_task);\r\ngoto out_reenable;\r\n}\r\nif (intrstat & INTR_TMINTR) {\r\njwrite32(jme, JME_IEVE, INTR_TMINTR);\r\ntasklet_schedule(&jme->pcc_task);\r\n}\r\nif (intrstat & (INTR_PCCTXTO | INTR_PCCTX)) {\r\njwrite32(jme, JME_IEVE, INTR_PCCTXTO | INTR_PCCTX | INTR_TX0);\r\ntasklet_schedule(&jme->txclean_task);\r\n}\r\nif ((intrstat & (INTR_PCCRX0TO | INTR_PCCRX0 | INTR_RX0EMP))) {\r\njwrite32(jme, JME_IEVE, (intrstat & (INTR_PCCRX0TO |\r\nINTR_PCCRX0 |\r\nINTR_RX0EMP)) |\r\nINTR_RX0);\r\n}\r\nif (test_bit(JME_FLAG_POLL, &jme->flags)) {\r\nif (intrstat & INTR_RX0EMP)\r\natomic_inc(&jme->rx_empty);\r\nif ((intrstat & (INTR_PCCRX0TO | INTR_PCCRX0 | INTR_RX0EMP))) {\r\nif (likely(JME_RX_SCHEDULE_PREP(jme))) {\r\njme_polling_mode(jme);\r\nJME_RX_SCHEDULE(jme);\r\n}\r\n}\r\n} else {\r\nif (intrstat & INTR_RX0EMP) {\r\natomic_inc(&jme->rx_empty);\r\ntasklet_hi_schedule(&jme->rxempty_task);\r\n} else if (intrstat & (INTR_PCCRX0TO | INTR_PCCRX0)) {\r\ntasklet_hi_schedule(&jme->rxclean_task);\r\n}\r\n}\r\nout_reenable:\r\njwrite32f(jme, JME_IENS, INTR_ENABLE);\r\n}\r\nstatic irqreturn_t\r\njme_intr(int irq, void *dev_id)\r\n{\r\nstruct net_device *netdev = dev_id;\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nu32 intrstat;\r\nintrstat = jread32(jme, JME_IEVE);\r\nif (unlikely((intrstat & INTR_ENABLE) == 0))\r\nreturn IRQ_NONE;\r\nif (unlikely(intrstat == ~((typeof(intrstat))0)))\r\nreturn IRQ_NONE;\r\njme_intr_msi(jme, intrstat);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t\r\njme_msi(int irq, void *dev_id)\r\n{\r\nstruct net_device *netdev = dev_id;\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nu32 intrstat;\r\nintrstat = jread32(jme, JME_IEVE);\r\njme_intr_msi(jme, intrstat);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void\r\njme_reset_link(struct jme_adapter *jme)\r\n{\r\njwrite32(jme, JME_TMCSR, TMCSR_SWIT);\r\n}\r\nstatic void\r\njme_restart_an(struct jme_adapter *jme)\r\n{\r\nu32 bmcr;\r\nspin_lock_bh(&jme->phy_lock);\r\nbmcr = jme_mdio_read(jme->dev, jme->mii_if.phy_id, MII_BMCR);\r\nbmcr |= (BMCR_ANENABLE | BMCR_ANRESTART);\r\njme_mdio_write(jme->dev, jme->mii_if.phy_id, MII_BMCR, bmcr);\r\nspin_unlock_bh(&jme->phy_lock);\r\n}\r\nstatic int\r\njme_request_irq(struct jme_adapter *jme)\r\n{\r\nint rc;\r\nstruct net_device *netdev = jme->dev;\r\nirq_handler_t handler = jme_intr;\r\nint irq_flags = IRQF_SHARED;\r\nif (!pci_enable_msi(jme->pdev)) {\r\nset_bit(JME_FLAG_MSI, &jme->flags);\r\nhandler = jme_msi;\r\nirq_flags = 0;\r\n}\r\nrc = request_irq(jme->pdev->irq, handler, irq_flags, netdev->name,\r\nnetdev);\r\nif (rc) {\r\nnetdev_err(netdev,\r\n"Unable to request %s interrupt (return: %d)\n",\r\ntest_bit(JME_FLAG_MSI, &jme->flags) ? "MSI" : "INTx",\r\nrc);\r\nif (test_bit(JME_FLAG_MSI, &jme->flags)) {\r\npci_disable_msi(jme->pdev);\r\nclear_bit(JME_FLAG_MSI, &jme->flags);\r\n}\r\n} else {\r\nnetdev->irq = jme->pdev->irq;\r\n}\r\nreturn rc;\r\n}\r\nstatic void\r\njme_free_irq(struct jme_adapter *jme)\r\n{\r\nfree_irq(jme->pdev->irq, jme->dev);\r\nif (test_bit(JME_FLAG_MSI, &jme->flags)) {\r\npci_disable_msi(jme->pdev);\r\nclear_bit(JME_FLAG_MSI, &jme->flags);\r\njme->dev->irq = jme->pdev->irq;\r\n}\r\n}\r\nstatic inline void\r\njme_new_phy_on(struct jme_adapter *jme)\r\n{\r\nu32 reg;\r\nreg = jread32(jme, JME_PHY_PWR);\r\nreg &= ~(PHY_PWR_DWN1SEL | PHY_PWR_DWN1SW |\r\nPHY_PWR_DWN2 | PHY_PWR_CLKSEL);\r\njwrite32(jme, JME_PHY_PWR, reg);\r\npci_read_config_dword(jme->pdev, PCI_PRIV_PE1, &reg);\r\nreg &= ~PE1_GPREG0_PBG;\r\nreg |= PE1_GPREG0_ENBG;\r\npci_write_config_dword(jme->pdev, PCI_PRIV_PE1, reg);\r\n}\r\nstatic inline void\r\njme_new_phy_off(struct jme_adapter *jme)\r\n{\r\nu32 reg;\r\nreg = jread32(jme, JME_PHY_PWR);\r\nreg |= PHY_PWR_DWN1SEL | PHY_PWR_DWN1SW |\r\nPHY_PWR_DWN2 | PHY_PWR_CLKSEL;\r\njwrite32(jme, JME_PHY_PWR, reg);\r\npci_read_config_dword(jme->pdev, PCI_PRIV_PE1, &reg);\r\nreg &= ~PE1_GPREG0_PBG;\r\nreg |= PE1_GPREG0_PDD3COLD;\r\npci_write_config_dword(jme->pdev, PCI_PRIV_PE1, reg);\r\n}\r\nstatic inline void\r\njme_phy_on(struct jme_adapter *jme)\r\n{\r\nu32 bmcr;\r\nbmcr = jme_mdio_read(jme->dev, jme->mii_if.phy_id, MII_BMCR);\r\nbmcr &= ~BMCR_PDOWN;\r\njme_mdio_write(jme->dev, jme->mii_if.phy_id, MII_BMCR, bmcr);\r\nif (new_phy_power_ctrl(jme->chip_main_rev))\r\njme_new_phy_on(jme);\r\n}\r\nstatic inline void\r\njme_phy_off(struct jme_adapter *jme)\r\n{\r\nu32 bmcr;\r\nbmcr = jme_mdio_read(jme->dev, jme->mii_if.phy_id, MII_BMCR);\r\nbmcr |= BMCR_PDOWN;\r\njme_mdio_write(jme->dev, jme->mii_if.phy_id, MII_BMCR, bmcr);\r\nif (new_phy_power_ctrl(jme->chip_main_rev))\r\njme_new_phy_off(jme);\r\n}\r\nstatic int\r\njme_phy_specreg_read(struct jme_adapter *jme, u32 specreg)\r\n{\r\nu32 phy_addr;\r\nphy_addr = JM_PHY_SPEC_REG_READ | specreg;\r\njme_mdio_write(jme->dev, jme->mii_if.phy_id, JM_PHY_SPEC_ADDR_REG,\r\nphy_addr);\r\nreturn jme_mdio_read(jme->dev, jme->mii_if.phy_id,\r\nJM_PHY_SPEC_DATA_REG);\r\n}\r\nstatic void\r\njme_phy_specreg_write(struct jme_adapter *jme, u32 ext_reg, u32 phy_data)\r\n{\r\nu32 phy_addr;\r\nphy_addr = JM_PHY_SPEC_REG_WRITE | ext_reg;\r\njme_mdio_write(jme->dev, jme->mii_if.phy_id, JM_PHY_SPEC_DATA_REG,\r\nphy_data);\r\njme_mdio_write(jme->dev, jme->mii_if.phy_id, JM_PHY_SPEC_ADDR_REG,\r\nphy_addr);\r\n}\r\nstatic int\r\njme_phy_calibration(struct jme_adapter *jme)\r\n{\r\nu32 ctrl1000, phy_data;\r\njme_phy_off(jme);\r\njme_phy_on(jme);\r\nctrl1000 = jme_mdio_read(jme->dev, jme->mii_if.phy_id, MII_CTRL1000);\r\nctrl1000 &= ~PHY_GAD_TEST_MODE_MSK;\r\nctrl1000 |= PHY_GAD_TEST_MODE_1;\r\njme_mdio_write(jme->dev, jme->mii_if.phy_id, MII_CTRL1000, ctrl1000);\r\nphy_data = jme_phy_specreg_read(jme, JM_PHY_EXT_COMM_2_REG);\r\nphy_data &= ~JM_PHY_EXT_COMM_2_CALI_MODE_0;\r\nphy_data |= JM_PHY_EXT_COMM_2_CALI_LATCH |\r\nJM_PHY_EXT_COMM_2_CALI_ENABLE;\r\njme_phy_specreg_write(jme, JM_PHY_EXT_COMM_2_REG, phy_data);\r\nmsleep(20);\r\nphy_data = jme_phy_specreg_read(jme, JM_PHY_EXT_COMM_2_REG);\r\nphy_data &= ~(JM_PHY_EXT_COMM_2_CALI_ENABLE |\r\nJM_PHY_EXT_COMM_2_CALI_MODE_0 |\r\nJM_PHY_EXT_COMM_2_CALI_LATCH);\r\njme_phy_specreg_write(jme, JM_PHY_EXT_COMM_2_REG, phy_data);\r\nctrl1000 = jme_mdio_read(jme->dev, jme->mii_if.phy_id, MII_CTRL1000);\r\nctrl1000 &= ~PHY_GAD_TEST_MODE_MSK;\r\njme_mdio_write(jme->dev, jme->mii_if.phy_id, MII_CTRL1000, ctrl1000);\r\nreturn 0;\r\n}\r\nstatic int\r\njme_phy_setEA(struct jme_adapter *jme)\r\n{\r\nu32 phy_comm0 = 0, phy_comm1 = 0;\r\nu8 nic_ctrl;\r\npci_read_config_byte(jme->pdev, PCI_PRIV_SHARE_NICCTRL, &nic_ctrl);\r\nif ((nic_ctrl & 0x3) == JME_FLAG_PHYEA_ENABLE)\r\nreturn 0;\r\nswitch (jme->pdev->device) {\r\ncase PCI_DEVICE_ID_JMICRON_JMC250:\r\nif (((jme->chip_main_rev == 5) &&\r\n((jme->chip_sub_rev == 0) || (jme->chip_sub_rev == 1) ||\r\n(jme->chip_sub_rev == 3))) ||\r\n(jme->chip_main_rev >= 6)) {\r\nphy_comm0 = 0x008A;\r\nphy_comm1 = 0x4109;\r\n}\r\nif ((jme->chip_main_rev == 3) &&\r\n((jme->chip_sub_rev == 1) || (jme->chip_sub_rev == 2)))\r\nphy_comm0 = 0xE088;\r\nbreak;\r\ncase PCI_DEVICE_ID_JMICRON_JMC260:\r\nif (((jme->chip_main_rev == 5) &&\r\n((jme->chip_sub_rev == 0) || (jme->chip_sub_rev == 1) ||\r\n(jme->chip_sub_rev == 3))) ||\r\n(jme->chip_main_rev >= 6)) {\r\nphy_comm0 = 0x008A;\r\nphy_comm1 = 0x4109;\r\n}\r\nif ((jme->chip_main_rev == 3) &&\r\n((jme->chip_sub_rev == 1) || (jme->chip_sub_rev == 2)))\r\nphy_comm0 = 0xE088;\r\nif ((jme->chip_main_rev == 2) && (jme->chip_sub_rev == 0))\r\nphy_comm0 = 0x608A;\r\nif ((jme->chip_main_rev == 2) && (jme->chip_sub_rev == 2))\r\nphy_comm0 = 0x408A;\r\nbreak;\r\ndefault:\r\nreturn -ENODEV;\r\n}\r\nif (phy_comm0)\r\njme_phy_specreg_write(jme, JM_PHY_EXT_COMM_0_REG, phy_comm0);\r\nif (phy_comm1)\r\njme_phy_specreg_write(jme, JM_PHY_EXT_COMM_1_REG, phy_comm1);\r\nreturn 0;\r\n}\r\nstatic int\r\njme_open(struct net_device *netdev)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nint rc;\r\njme_clear_pm(jme);\r\nJME_NAPI_ENABLE(jme);\r\ntasklet_init(&jme->linkch_task, jme_link_change_tasklet,\r\n(unsigned long) jme);\r\ntasklet_init(&jme->txclean_task, jme_tx_clean_tasklet,\r\n(unsigned long) jme);\r\ntasklet_init(&jme->rxclean_task, jme_rx_clean_tasklet,\r\n(unsigned long) jme);\r\ntasklet_init(&jme->rxempty_task, jme_rx_empty_tasklet,\r\n(unsigned long) jme);\r\nrc = jme_request_irq(jme);\r\nif (rc)\r\ngoto err_out;\r\njme_start_irq(jme);\r\njme_phy_on(jme);\r\nif (test_bit(JME_FLAG_SSET, &jme->flags))\r\njme_set_settings(netdev, &jme->old_ecmd);\r\nelse\r\njme_reset_phy_processor(jme);\r\njme_phy_calibration(jme);\r\njme_phy_setEA(jme);\r\njme_reset_link(jme);\r\nreturn 0;\r\nerr_out:\r\nnetif_stop_queue(netdev);\r\nnetif_carrier_off(netdev);\r\nreturn rc;\r\n}\r\nstatic void\r\njme_set_100m_half(struct jme_adapter *jme)\r\n{\r\nu32 bmcr, tmp;\r\njme_phy_on(jme);\r\nbmcr = jme_mdio_read(jme->dev, jme->mii_if.phy_id, MII_BMCR);\r\ntmp = bmcr & ~(BMCR_ANENABLE | BMCR_SPEED100 |\r\nBMCR_SPEED1000 | BMCR_FULLDPLX);\r\ntmp |= BMCR_SPEED100;\r\nif (bmcr != tmp)\r\njme_mdio_write(jme->dev, jme->mii_if.phy_id, MII_BMCR, tmp);\r\nif (jme->fpgaver)\r\njwrite32(jme, JME_GHC, GHC_SPEED_100M | GHC_LINK_POLL);\r\nelse\r\njwrite32(jme, JME_GHC, GHC_SPEED_100M);\r\n}\r\nstatic void\r\njme_wait_link(struct jme_adapter *jme)\r\n{\r\nu32 phylink, to = JME_WAIT_LINK_TIME;\r\nmdelay(1000);\r\nphylink = jme_linkstat_from_phy(jme);\r\nwhile (!(phylink & PHY_LINK_UP) && (to -= 10) > 0) {\r\nmdelay(10);\r\nphylink = jme_linkstat_from_phy(jme);\r\n}\r\n}\r\nstatic void\r\njme_powersave_phy(struct jme_adapter *jme)\r\n{\r\nif (jme->reg_pmcs) {\r\njme_set_100m_half(jme);\r\nif (jme->reg_pmcs & (PMCS_LFEN | PMCS_LREN))\r\njme_wait_link(jme);\r\njme_clear_pm(jme);\r\n} else {\r\njme_phy_off(jme);\r\n}\r\n}\r\nstatic int\r\njme_close(struct net_device *netdev)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nnetif_stop_queue(netdev);\r\nnetif_carrier_off(netdev);\r\njme_stop_irq(jme);\r\njme_free_irq(jme);\r\nJME_NAPI_DISABLE(jme);\r\ntasklet_kill(&jme->linkch_task);\r\ntasklet_kill(&jme->txclean_task);\r\ntasklet_kill(&jme->rxclean_task);\r\ntasklet_kill(&jme->rxempty_task);\r\njme_disable_rx_engine(jme);\r\njme_disable_tx_engine(jme);\r\njme_reset_mac_processor(jme);\r\njme_free_rx_resources(jme);\r\njme_free_tx_resources(jme);\r\njme->phylink = 0;\r\njme_phy_off(jme);\r\nreturn 0;\r\n}\r\nstatic int\r\njme_alloc_txdesc(struct jme_adapter *jme,\r\nstruct sk_buff *skb)\r\n{\r\nstruct jme_ring *txring = &(jme->txring[0]);\r\nint idx, nr_alloc, mask = jme->tx_ring_mask;\r\nidx = txring->next_to_use;\r\nnr_alloc = skb_shinfo(skb)->nr_frags + 2;\r\nif (unlikely(atomic_read(&txring->nr_free) < nr_alloc))\r\nreturn -1;\r\natomic_sub(nr_alloc, &txring->nr_free);\r\ntxring->next_to_use = (txring->next_to_use + nr_alloc) & mask;\r\nreturn idx;\r\n}\r\nstatic int\r\njme_fill_tx_map(struct pci_dev *pdev,\r\nstruct txdesc *txdesc,\r\nstruct jme_buffer_info *txbi,\r\nstruct page *page,\r\nu32 page_offset,\r\nu32 len,\r\nbool hidma)\r\n{\r\ndma_addr_t dmaaddr;\r\ndmaaddr = pci_map_page(pdev,\r\npage,\r\npage_offset,\r\nlen,\r\nPCI_DMA_TODEVICE);\r\nif (unlikely(pci_dma_mapping_error(pdev, dmaaddr)))\r\nreturn -EINVAL;\r\npci_dma_sync_single_for_device(pdev,\r\ndmaaddr,\r\nlen,\r\nPCI_DMA_TODEVICE);\r\ntxdesc->dw[0] = 0;\r\ntxdesc->dw[1] = 0;\r\ntxdesc->desc2.flags = TXFLAG_OWN;\r\ntxdesc->desc2.flags |= (hidma) ? TXFLAG_64BIT : 0;\r\ntxdesc->desc2.datalen = cpu_to_le16(len);\r\ntxdesc->desc2.bufaddrh = cpu_to_le32((__u64)dmaaddr >> 32);\r\ntxdesc->desc2.bufaddrl = cpu_to_le32(\r\n(__u64)dmaaddr & 0xFFFFFFFFUL);\r\ntxbi->mapping = dmaaddr;\r\ntxbi->len = len;\r\nreturn 0;\r\n}\r\nstatic void jme_drop_tx_map(struct jme_adapter *jme, int startidx, int count)\r\n{\r\nstruct jme_ring *txring = &(jme->txring[0]);\r\nstruct jme_buffer_info *txbi = txring->bufinf, *ctxbi;\r\nint mask = jme->tx_ring_mask;\r\nint j;\r\nfor (j = 0 ; j < count ; j++) {\r\nctxbi = txbi + ((startidx + j + 2) & (mask));\r\npci_unmap_page(jme->pdev,\r\nctxbi->mapping,\r\nctxbi->len,\r\nPCI_DMA_TODEVICE);\r\nctxbi->mapping = 0;\r\nctxbi->len = 0;\r\n}\r\n}\r\nstatic int\r\njme_map_tx_skb(struct jme_adapter *jme, struct sk_buff *skb, int idx)\r\n{\r\nstruct jme_ring *txring = &(jme->txring[0]);\r\nstruct txdesc *txdesc = txring->desc, *ctxdesc;\r\nstruct jme_buffer_info *txbi = txring->bufinf, *ctxbi;\r\nbool hidma = jme->dev->features & NETIF_F_HIGHDMA;\r\nint i, nr_frags = skb_shinfo(skb)->nr_frags;\r\nint mask = jme->tx_ring_mask;\r\nconst struct skb_frag_struct *frag;\r\nu32 len;\r\nint ret = 0;\r\nfor (i = 0 ; i < nr_frags ; ++i) {\r\nfrag = &skb_shinfo(skb)->frags[i];\r\nctxdesc = txdesc + ((idx + i + 2) & (mask));\r\nctxbi = txbi + ((idx + i + 2) & (mask));\r\nret = jme_fill_tx_map(jme->pdev, ctxdesc, ctxbi,\r\nskb_frag_page(frag),\r\nfrag->page_offset, skb_frag_size(frag), hidma);\r\nif (ret) {\r\njme_drop_tx_map(jme, idx, i);\r\ngoto out;\r\n}\r\n}\r\nlen = skb_is_nonlinear(skb) ? skb_headlen(skb) : skb->len;\r\nctxdesc = txdesc + ((idx + 1) & (mask));\r\nctxbi = txbi + ((idx + 1) & (mask));\r\nret = jme_fill_tx_map(jme->pdev, ctxdesc, ctxbi, virt_to_page(skb->data),\r\noffset_in_page(skb->data), len, hidma);\r\nif (ret)\r\njme_drop_tx_map(jme, idx, i);\r\nout:\r\nreturn ret;\r\n}\r\nstatic int\r\njme_tx_tso(struct sk_buff *skb, __le16 *mss, u8 *flags)\r\n{\r\n*mss = cpu_to_le16(skb_shinfo(skb)->gso_size << TXDESC_MSS_SHIFT);\r\nif (*mss) {\r\n*flags |= TXFLAG_LSEN;\r\nif (skb->protocol == htons(ETH_P_IP)) {\r\nstruct iphdr *iph = ip_hdr(skb);\r\niph->check = 0;\r\ntcp_hdr(skb)->check = ~csum_tcpudp_magic(iph->saddr,\r\niph->daddr, 0,\r\nIPPROTO_TCP,\r\n0);\r\n} else {\r\nstruct ipv6hdr *ip6h = ipv6_hdr(skb);\r\ntcp_hdr(skb)->check = ~csum_ipv6_magic(&ip6h->saddr,\r\n&ip6h->daddr, 0,\r\nIPPROTO_TCP,\r\n0);\r\n}\r\nreturn 0;\r\n}\r\nreturn 1;\r\n}\r\nstatic void\r\njme_tx_csum(struct jme_adapter *jme, struct sk_buff *skb, u8 *flags)\r\n{\r\nif (skb->ip_summed == CHECKSUM_PARTIAL) {\r\nu8 ip_proto;\r\nswitch (skb->protocol) {\r\ncase htons(ETH_P_IP):\r\nip_proto = ip_hdr(skb)->protocol;\r\nbreak;\r\ncase htons(ETH_P_IPV6):\r\nip_proto = ipv6_hdr(skb)->nexthdr;\r\nbreak;\r\ndefault:\r\nip_proto = 0;\r\nbreak;\r\n}\r\nswitch (ip_proto) {\r\ncase IPPROTO_TCP:\r\n*flags |= TXFLAG_TCPCS;\r\nbreak;\r\ncase IPPROTO_UDP:\r\n*flags |= TXFLAG_UDPCS;\r\nbreak;\r\ndefault:\r\nnetif_err(jme, tx_err, jme->dev, "Error upper layer protocol\n");\r\nbreak;\r\n}\r\n}\r\n}\r\nstatic inline void\r\njme_tx_vlan(struct sk_buff *skb, __le16 *vlan, u8 *flags)\r\n{\r\nif (skb_vlan_tag_present(skb)) {\r\n*flags |= TXFLAG_TAGON;\r\n*vlan = cpu_to_le16(skb_vlan_tag_get(skb));\r\n}\r\n}\r\nstatic int\r\njme_fill_tx_desc(struct jme_adapter *jme, struct sk_buff *skb, int idx)\r\n{\r\nstruct jme_ring *txring = &(jme->txring[0]);\r\nstruct txdesc *txdesc;\r\nstruct jme_buffer_info *txbi;\r\nu8 flags;\r\nint ret = 0;\r\ntxdesc = (struct txdesc *)txring->desc + idx;\r\ntxbi = txring->bufinf + idx;\r\ntxdesc->dw[0] = 0;\r\ntxdesc->dw[1] = 0;\r\ntxdesc->dw[2] = 0;\r\ntxdesc->dw[3] = 0;\r\ntxdesc->desc1.pktsize = cpu_to_le16(skb->len);\r\nwmb();\r\nflags = TXFLAG_OWN | TXFLAG_INT;\r\nif (jme_tx_tso(skb, &txdesc->desc1.mss, &flags))\r\njme_tx_csum(jme, skb, &flags);\r\njme_tx_vlan(skb, &txdesc->desc1.vlan, &flags);\r\nret = jme_map_tx_skb(jme, skb, idx);\r\nif (ret)\r\nreturn ret;\r\ntxdesc->desc1.flags = flags;\r\nwmb();\r\ntxbi->nr_desc = skb_shinfo(skb)->nr_frags + 2;\r\ntxbi->skb = skb;\r\ntxbi->len = skb->len;\r\ntxbi->start_xmit = jiffies;\r\nif (!txbi->start_xmit)\r\ntxbi->start_xmit = (0UL-1);\r\nreturn 0;\r\n}\r\nstatic void\r\njme_stop_queue_if_full(struct jme_adapter *jme)\r\n{\r\nstruct jme_ring *txring = &(jme->txring[0]);\r\nstruct jme_buffer_info *txbi = txring->bufinf;\r\nint idx = atomic_read(&txring->next_to_clean);\r\ntxbi += idx;\r\nsmp_wmb();\r\nif (unlikely(atomic_read(&txring->nr_free) < (MAX_SKB_FRAGS+2))) {\r\nnetif_stop_queue(jme->dev);\r\nnetif_info(jme, tx_queued, jme->dev, "TX Queue Paused\n");\r\nsmp_wmb();\r\nif (atomic_read(&txring->nr_free)\r\n>= (jme->tx_wake_threshold)) {\r\nnetif_wake_queue(jme->dev);\r\nnetif_info(jme, tx_queued, jme->dev, "TX Queue Fast Waked\n");\r\n}\r\n}\r\nif (unlikely(txbi->start_xmit &&\r\n(jiffies - txbi->start_xmit) >= TX_TIMEOUT &&\r\ntxbi->skb)) {\r\nnetif_stop_queue(jme->dev);\r\nnetif_info(jme, tx_queued, jme->dev,\r\n"TX Queue Stopped %d@%lu\n", idx, jiffies);\r\n}\r\n}\r\nstatic netdev_tx_t\r\njme_start_xmit(struct sk_buff *skb, struct net_device *netdev)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nint idx;\r\nif (unlikely(skb_is_gso(skb) && skb_cow_head(skb, 0))) {\r\ndev_kfree_skb_any(skb);\r\n++(NET_STAT(jme).tx_dropped);\r\nreturn NETDEV_TX_OK;\r\n}\r\nidx = jme_alloc_txdesc(jme, skb);\r\nif (unlikely(idx < 0)) {\r\nnetif_stop_queue(netdev);\r\nnetif_err(jme, tx_err, jme->dev,\r\n"BUG! Tx ring full when queue awake!\n");\r\nreturn NETDEV_TX_BUSY;\r\n}\r\nif (jme_fill_tx_desc(jme, skb, idx))\r\nreturn NETDEV_TX_OK;\r\njwrite32(jme, JME_TXCS, jme->reg_txcs |\r\nTXCS_SELECT_QUEUE0 |\r\nTXCS_QUEUE0S |\r\nTXCS_ENABLE);\r\ntx_dbg(jme, "xmit: %d+%d@%lu\n",\r\nidx, skb_shinfo(skb)->nr_frags + 2, jiffies);\r\njme_stop_queue_if_full(jme);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void\r\njme_set_unicastaddr(struct net_device *netdev)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nu32 val;\r\nval = (netdev->dev_addr[3] & 0xff) << 24 |\r\n(netdev->dev_addr[2] & 0xff) << 16 |\r\n(netdev->dev_addr[1] & 0xff) << 8 |\r\n(netdev->dev_addr[0] & 0xff);\r\njwrite32(jme, JME_RXUMA_LO, val);\r\nval = (netdev->dev_addr[5] & 0xff) << 8 |\r\n(netdev->dev_addr[4] & 0xff);\r\njwrite32(jme, JME_RXUMA_HI, val);\r\n}\r\nstatic int\r\njme_set_macaddr(struct net_device *netdev, void *p)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nstruct sockaddr *addr = p;\r\nif (netif_running(netdev))\r\nreturn -EBUSY;\r\nspin_lock_bh(&jme->macaddr_lock);\r\nmemcpy(netdev->dev_addr, addr->sa_data, netdev->addr_len);\r\njme_set_unicastaddr(netdev);\r\nspin_unlock_bh(&jme->macaddr_lock);\r\nreturn 0;\r\n}\r\nstatic void\r\njme_set_multi(struct net_device *netdev)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nu32 mc_hash[2] = {};\r\nspin_lock_bh(&jme->rxmcs_lock);\r\njme->reg_rxmcs |= RXMCS_BRDFRAME | RXMCS_UNIFRAME;\r\nif (netdev->flags & IFF_PROMISC) {\r\njme->reg_rxmcs |= RXMCS_ALLFRAME;\r\n} else if (netdev->flags & IFF_ALLMULTI) {\r\njme->reg_rxmcs |= RXMCS_ALLMULFRAME;\r\n} else if (netdev->flags & IFF_MULTICAST) {\r\nstruct netdev_hw_addr *ha;\r\nint bit_nr;\r\njme->reg_rxmcs |= RXMCS_MULFRAME | RXMCS_MULFILTERED;\r\nnetdev_for_each_mc_addr(ha, netdev) {\r\nbit_nr = ether_crc(ETH_ALEN, ha->addr) & 0x3F;\r\nmc_hash[bit_nr >> 5] |= 1 << (bit_nr & 0x1F);\r\n}\r\njwrite32(jme, JME_RXMCHT_LO, mc_hash[0]);\r\njwrite32(jme, JME_RXMCHT_HI, mc_hash[1]);\r\n}\r\nwmb();\r\njwrite32(jme, JME_RXMCS, jme->reg_rxmcs);\r\nspin_unlock_bh(&jme->rxmcs_lock);\r\n}\r\nstatic int\r\njme_change_mtu(struct net_device *netdev, int new_mtu)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nif (new_mtu == jme->old_mtu)\r\nreturn 0;\r\nif (((new_mtu + ETH_HLEN) > MAX_ETHERNET_JUMBO_PACKET_SIZE) ||\r\n((new_mtu) < IPV6_MIN_MTU))\r\nreturn -EINVAL;\r\nnetdev->mtu = new_mtu;\r\nnetdev_update_features(netdev);\r\njme_restart_rx_engine(jme);\r\njme_reset_link(jme);\r\nreturn 0;\r\n}\r\nstatic void\r\njme_tx_timeout(struct net_device *netdev)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\njme->phylink = 0;\r\njme_reset_phy_processor(jme);\r\nif (test_bit(JME_FLAG_SSET, &jme->flags))\r\njme_set_settings(netdev, &jme->old_ecmd);\r\njme_reset_link(jme);\r\n}\r\nstatic inline void jme_pause_rx(struct jme_adapter *jme)\r\n{\r\natomic_dec(&jme->link_changing);\r\njme_set_rx_pcc(jme, PCC_OFF);\r\nif (test_bit(JME_FLAG_POLL, &jme->flags)) {\r\nJME_NAPI_DISABLE(jme);\r\n} else {\r\ntasklet_disable(&jme->rxclean_task);\r\ntasklet_disable(&jme->rxempty_task);\r\n}\r\n}\r\nstatic inline void jme_resume_rx(struct jme_adapter *jme)\r\n{\r\nstruct dynpcc_info *dpi = &(jme->dpi);\r\nif (test_bit(JME_FLAG_POLL, &jme->flags)) {\r\nJME_NAPI_ENABLE(jme);\r\n} else {\r\ntasklet_enable(&jme->rxclean_task);\r\ntasklet_enable(&jme->rxempty_task);\r\n}\r\ndpi->cur = PCC_P1;\r\ndpi->attempt = PCC_P1;\r\ndpi->cnt = 0;\r\njme_set_rx_pcc(jme, PCC_P1);\r\natomic_inc(&jme->link_changing);\r\n}\r\nstatic void\r\njme_get_drvinfo(struct net_device *netdev,\r\nstruct ethtool_drvinfo *info)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nstrlcpy(info->driver, DRV_NAME, sizeof(info->driver));\r\nstrlcpy(info->version, DRV_VERSION, sizeof(info->version));\r\nstrlcpy(info->bus_info, pci_name(jme->pdev), sizeof(info->bus_info));\r\n}\r\nstatic int\r\njme_get_regs_len(struct net_device *netdev)\r\n{\r\nreturn JME_REG_LEN;\r\n}\r\nstatic void\r\nmmapio_memcpy(struct jme_adapter *jme, u32 *p, u32 reg, int len)\r\n{\r\nint i;\r\nfor (i = 0 ; i < len ; i += 4)\r\np[i >> 2] = jread32(jme, reg + i);\r\n}\r\nstatic void\r\nmdio_memcpy(struct jme_adapter *jme, u32 *p, int reg_nr)\r\n{\r\nint i;\r\nu16 *p16 = (u16 *)p;\r\nfor (i = 0 ; i < reg_nr ; ++i)\r\np16[i] = jme_mdio_read(jme->dev, jme->mii_if.phy_id, i);\r\n}\r\nstatic void\r\njme_get_regs(struct net_device *netdev, struct ethtool_regs *regs, void *p)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nu32 *p32 = (u32 *)p;\r\nmemset(p, 0xFF, JME_REG_LEN);\r\nregs->version = 1;\r\nmmapio_memcpy(jme, p32, JME_MAC, JME_MAC_LEN);\r\np32 += 0x100 >> 2;\r\nmmapio_memcpy(jme, p32, JME_PHY, JME_PHY_LEN);\r\np32 += 0x100 >> 2;\r\nmmapio_memcpy(jme, p32, JME_MISC, JME_MISC_LEN);\r\np32 += 0x100 >> 2;\r\nmmapio_memcpy(jme, p32, JME_RSS, JME_RSS_LEN);\r\np32 += 0x100 >> 2;\r\nmdio_memcpy(jme, p32, JME_PHY_REG_NR);\r\n}\r\nstatic int\r\njme_get_coalesce(struct net_device *netdev, struct ethtool_coalesce *ecmd)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\necmd->tx_coalesce_usecs = PCC_TX_TO;\r\necmd->tx_max_coalesced_frames = PCC_TX_CNT;\r\nif (test_bit(JME_FLAG_POLL, &jme->flags)) {\r\necmd->use_adaptive_rx_coalesce = false;\r\necmd->rx_coalesce_usecs = 0;\r\necmd->rx_max_coalesced_frames = 0;\r\nreturn 0;\r\n}\r\necmd->use_adaptive_rx_coalesce = true;\r\nswitch (jme->dpi.cur) {\r\ncase PCC_P1:\r\necmd->rx_coalesce_usecs = PCC_P1_TO;\r\necmd->rx_max_coalesced_frames = PCC_P1_CNT;\r\nbreak;\r\ncase PCC_P2:\r\necmd->rx_coalesce_usecs = PCC_P2_TO;\r\necmd->rx_max_coalesced_frames = PCC_P2_CNT;\r\nbreak;\r\ncase PCC_P3:\r\necmd->rx_coalesce_usecs = PCC_P3_TO;\r\necmd->rx_max_coalesced_frames = PCC_P3_CNT;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\njme_set_coalesce(struct net_device *netdev, struct ethtool_coalesce *ecmd)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nstruct dynpcc_info *dpi = &(jme->dpi);\r\nif (netif_running(netdev))\r\nreturn -EBUSY;\r\nif (ecmd->use_adaptive_rx_coalesce &&\r\ntest_bit(JME_FLAG_POLL, &jme->flags)) {\r\nclear_bit(JME_FLAG_POLL, &jme->flags);\r\njme->jme_rx = netif_rx;\r\ndpi->cur = PCC_P1;\r\ndpi->attempt = PCC_P1;\r\ndpi->cnt = 0;\r\njme_set_rx_pcc(jme, PCC_P1);\r\njme_interrupt_mode(jme);\r\n} else if (!(ecmd->use_adaptive_rx_coalesce) &&\r\n!(test_bit(JME_FLAG_POLL, &jme->flags))) {\r\nset_bit(JME_FLAG_POLL, &jme->flags);\r\njme->jme_rx = netif_receive_skb;\r\njme_interrupt_mode(jme);\r\n}\r\nreturn 0;\r\n}\r\nstatic void\r\njme_get_pauseparam(struct net_device *netdev,\r\nstruct ethtool_pauseparam *ecmd)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nu32 val;\r\necmd->tx_pause = (jme->reg_txpfc & TXPFC_PF_EN) != 0;\r\necmd->rx_pause = (jme->reg_rxmcs & RXMCS_FLOWCTRL) != 0;\r\nspin_lock_bh(&jme->phy_lock);\r\nval = jme_mdio_read(jme->dev, jme->mii_if.phy_id, MII_ADVERTISE);\r\nspin_unlock_bh(&jme->phy_lock);\r\necmd->autoneg =\r\n(val & (ADVERTISE_PAUSE_CAP | ADVERTISE_PAUSE_ASYM)) != 0;\r\n}\r\nstatic int\r\njme_set_pauseparam(struct net_device *netdev,\r\nstruct ethtool_pauseparam *ecmd)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nu32 val;\r\nif (((jme->reg_txpfc & TXPFC_PF_EN) != 0) ^\r\n(ecmd->tx_pause != 0)) {\r\nif (ecmd->tx_pause)\r\njme->reg_txpfc |= TXPFC_PF_EN;\r\nelse\r\njme->reg_txpfc &= ~TXPFC_PF_EN;\r\njwrite32(jme, JME_TXPFC, jme->reg_txpfc);\r\n}\r\nspin_lock_bh(&jme->rxmcs_lock);\r\nif (((jme->reg_rxmcs & RXMCS_FLOWCTRL) != 0) ^\r\n(ecmd->rx_pause != 0)) {\r\nif (ecmd->rx_pause)\r\njme->reg_rxmcs |= RXMCS_FLOWCTRL;\r\nelse\r\njme->reg_rxmcs &= ~RXMCS_FLOWCTRL;\r\njwrite32(jme, JME_RXMCS, jme->reg_rxmcs);\r\n}\r\nspin_unlock_bh(&jme->rxmcs_lock);\r\nspin_lock_bh(&jme->phy_lock);\r\nval = jme_mdio_read(jme->dev, jme->mii_if.phy_id, MII_ADVERTISE);\r\nif (((val & (ADVERTISE_PAUSE_CAP | ADVERTISE_PAUSE_ASYM)) != 0) ^\r\n(ecmd->autoneg != 0)) {\r\nif (ecmd->autoneg)\r\nval |= (ADVERTISE_PAUSE_CAP | ADVERTISE_PAUSE_ASYM);\r\nelse\r\nval &= ~(ADVERTISE_PAUSE_CAP | ADVERTISE_PAUSE_ASYM);\r\njme_mdio_write(jme->dev, jme->mii_if.phy_id,\r\nMII_ADVERTISE, val);\r\n}\r\nspin_unlock_bh(&jme->phy_lock);\r\nreturn 0;\r\n}\r\nstatic void\r\njme_get_wol(struct net_device *netdev,\r\nstruct ethtool_wolinfo *wol)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nwol->supported = WAKE_MAGIC | WAKE_PHY;\r\nwol->wolopts = 0;\r\nif (jme->reg_pmcs & (PMCS_LFEN | PMCS_LREN))\r\nwol->wolopts |= WAKE_PHY;\r\nif (jme->reg_pmcs & PMCS_MFEN)\r\nwol->wolopts |= WAKE_MAGIC;\r\n}\r\nstatic int\r\njme_set_wol(struct net_device *netdev,\r\nstruct ethtool_wolinfo *wol)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nif (wol->wolopts & (WAKE_MAGICSECURE |\r\nWAKE_UCAST |\r\nWAKE_MCAST |\r\nWAKE_BCAST |\r\nWAKE_ARP))\r\nreturn -EOPNOTSUPP;\r\njme->reg_pmcs = 0;\r\nif (wol->wolopts & WAKE_PHY)\r\njme->reg_pmcs |= PMCS_LFEN | PMCS_LREN;\r\nif (wol->wolopts & WAKE_MAGIC)\r\njme->reg_pmcs |= PMCS_MFEN;\r\njwrite32(jme, JME_PMCS, jme->reg_pmcs);\r\ndevice_set_wakeup_enable(&jme->pdev->dev, !!(jme->reg_pmcs));\r\nreturn 0;\r\n}\r\nstatic int\r\njme_get_settings(struct net_device *netdev,\r\nstruct ethtool_cmd *ecmd)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nint rc;\r\nspin_lock_bh(&jme->phy_lock);\r\nrc = mii_ethtool_gset(&(jme->mii_if), ecmd);\r\nspin_unlock_bh(&jme->phy_lock);\r\nreturn rc;\r\n}\r\nstatic int\r\njme_set_settings(struct net_device *netdev,\r\nstruct ethtool_cmd *ecmd)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nint rc, fdc = 0;\r\nif (ethtool_cmd_speed(ecmd) == SPEED_1000\r\n&& ecmd->autoneg != AUTONEG_ENABLE)\r\nreturn -EINVAL;\r\nif (jme->mii_if.force_media &&\r\necmd->autoneg != AUTONEG_ENABLE &&\r\n(jme->mii_if.full_duplex != ecmd->duplex))\r\nfdc = 1;\r\nspin_lock_bh(&jme->phy_lock);\r\nrc = mii_ethtool_sset(&(jme->mii_if), ecmd);\r\nspin_unlock_bh(&jme->phy_lock);\r\nif (!rc) {\r\nif (fdc)\r\njme_reset_link(jme);\r\njme->old_ecmd = *ecmd;\r\nset_bit(JME_FLAG_SSET, &jme->flags);\r\n}\r\nreturn rc;\r\n}\r\nstatic int\r\njme_ioctl(struct net_device *netdev, struct ifreq *rq, int cmd)\r\n{\r\nint rc;\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nstruct mii_ioctl_data *mii_data = if_mii(rq);\r\nunsigned int duplex_chg;\r\nif (cmd == SIOCSMIIREG) {\r\nu16 val = mii_data->val_in;\r\nif (!(val & (BMCR_RESET|BMCR_ANENABLE)) &&\r\n(val & BMCR_SPEED1000))\r\nreturn -EINVAL;\r\n}\r\nspin_lock_bh(&jme->phy_lock);\r\nrc = generic_mii_ioctl(&jme->mii_if, mii_data, cmd, &duplex_chg);\r\nspin_unlock_bh(&jme->phy_lock);\r\nif (!rc && (cmd == SIOCSMIIREG)) {\r\nif (duplex_chg)\r\njme_reset_link(jme);\r\njme_get_settings(netdev, &jme->old_ecmd);\r\nset_bit(JME_FLAG_SSET, &jme->flags);\r\n}\r\nreturn rc;\r\n}\r\nstatic u32\r\njme_get_link(struct net_device *netdev)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nreturn jread32(jme, JME_PHY_LINK) & PHY_LINK_UP;\r\n}\r\nstatic u32\r\njme_get_msglevel(struct net_device *netdev)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nreturn jme->msg_enable;\r\n}\r\nstatic void\r\njme_set_msglevel(struct net_device *netdev, u32 value)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\njme->msg_enable = value;\r\n}\r\nstatic netdev_features_t\r\njme_fix_features(struct net_device *netdev, netdev_features_t features)\r\n{\r\nif (netdev->mtu > 1900)\r\nfeatures &= ~(NETIF_F_ALL_TSO | NETIF_F_ALL_CSUM);\r\nreturn features;\r\n}\r\nstatic int\r\njme_set_features(struct net_device *netdev, netdev_features_t features)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nspin_lock_bh(&jme->rxmcs_lock);\r\nif (features & NETIF_F_RXCSUM)\r\njme->reg_rxmcs |= RXMCS_CHECKSUM;\r\nelse\r\njme->reg_rxmcs &= ~RXMCS_CHECKSUM;\r\njwrite32(jme, JME_RXMCS, jme->reg_rxmcs);\r\nspin_unlock_bh(&jme->rxmcs_lock);\r\nreturn 0;\r\n}\r\nstatic void jme_netpoll(struct net_device *dev)\r\n{\r\nunsigned long flags;\r\nlocal_irq_save(flags);\r\njme_intr(dev->irq, dev);\r\nlocal_irq_restore(flags);\r\n}\r\nstatic int\r\njme_nway_reset(struct net_device *netdev)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\njme_restart_an(jme);\r\nreturn 0;\r\n}\r\nstatic u8\r\njme_smb_read(struct jme_adapter *jme, unsigned int addr)\r\n{\r\nu32 val;\r\nint to;\r\nval = jread32(jme, JME_SMBCSR);\r\nto = JME_SMB_BUSY_TIMEOUT;\r\nwhile ((val & SMBCSR_BUSY) && --to) {\r\nmsleep(1);\r\nval = jread32(jme, JME_SMBCSR);\r\n}\r\nif (!to) {\r\nnetif_err(jme, hw, jme->dev, "SMB Bus Busy\n");\r\nreturn 0xFF;\r\n}\r\njwrite32(jme, JME_SMBINTF,\r\n((addr << SMBINTF_HWADDR_SHIFT) & SMBINTF_HWADDR) |\r\nSMBINTF_HWRWN_READ |\r\nSMBINTF_HWCMD);\r\nval = jread32(jme, JME_SMBINTF);\r\nto = JME_SMB_BUSY_TIMEOUT;\r\nwhile ((val & SMBINTF_HWCMD) && --to) {\r\nmsleep(1);\r\nval = jread32(jme, JME_SMBINTF);\r\n}\r\nif (!to) {\r\nnetif_err(jme, hw, jme->dev, "SMB Bus Busy\n");\r\nreturn 0xFF;\r\n}\r\nreturn (val & SMBINTF_HWDATR) >> SMBINTF_HWDATR_SHIFT;\r\n}\r\nstatic void\r\njme_smb_write(struct jme_adapter *jme, unsigned int addr, u8 data)\r\n{\r\nu32 val;\r\nint to;\r\nval = jread32(jme, JME_SMBCSR);\r\nto = JME_SMB_BUSY_TIMEOUT;\r\nwhile ((val & SMBCSR_BUSY) && --to) {\r\nmsleep(1);\r\nval = jread32(jme, JME_SMBCSR);\r\n}\r\nif (!to) {\r\nnetif_err(jme, hw, jme->dev, "SMB Bus Busy\n");\r\nreturn;\r\n}\r\njwrite32(jme, JME_SMBINTF,\r\n((data << SMBINTF_HWDATW_SHIFT) & SMBINTF_HWDATW) |\r\n((addr << SMBINTF_HWADDR_SHIFT) & SMBINTF_HWADDR) |\r\nSMBINTF_HWRWN_WRITE |\r\nSMBINTF_HWCMD);\r\nval = jread32(jme, JME_SMBINTF);\r\nto = JME_SMB_BUSY_TIMEOUT;\r\nwhile ((val & SMBINTF_HWCMD) && --to) {\r\nmsleep(1);\r\nval = jread32(jme, JME_SMBINTF);\r\n}\r\nif (!to) {\r\nnetif_err(jme, hw, jme->dev, "SMB Bus Busy\n");\r\nreturn;\r\n}\r\nmdelay(2);\r\n}\r\nstatic int\r\njme_get_eeprom_len(struct net_device *netdev)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nu32 val;\r\nval = jread32(jme, JME_SMBCSR);\r\nreturn (val & SMBCSR_EEPROMD) ? JME_SMB_LEN : 0;\r\n}\r\nstatic int\r\njme_get_eeprom(struct net_device *netdev,\r\nstruct ethtool_eeprom *eeprom, u8 *data)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nint i, offset = eeprom->offset, len = eeprom->len;\r\neeprom->magic = JME_EEPROM_MAGIC;\r\nfor (i = 0 ; i < len ; ++i)\r\ndata[i] = jme_smb_read(jme, i + offset);\r\nreturn 0;\r\n}\r\nstatic int\r\njme_set_eeprom(struct net_device *netdev,\r\nstruct ethtool_eeprom *eeprom, u8 *data)\r\n{\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nint i, offset = eeprom->offset, len = eeprom->len;\r\nif (eeprom->magic != JME_EEPROM_MAGIC)\r\nreturn -EINVAL;\r\nfor (i = 0 ; i < len ; ++i)\r\njme_smb_write(jme, i + offset, data[i]);\r\nreturn 0;\r\n}\r\nstatic int\r\njme_pci_dma64(struct pci_dev *pdev)\r\n{\r\nif (pdev->device == PCI_DEVICE_ID_JMICRON_JMC250 &&\r\n!pci_set_dma_mask(pdev, DMA_BIT_MASK(64)))\r\nif (!pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64)))\r\nreturn 1;\r\nif (pdev->device == PCI_DEVICE_ID_JMICRON_JMC250 &&\r\n!pci_set_dma_mask(pdev, DMA_BIT_MASK(40)))\r\nif (!pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(40)))\r\nreturn 1;\r\nif (!pci_set_dma_mask(pdev, DMA_BIT_MASK(32)))\r\nif (!pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32)))\r\nreturn 0;\r\nreturn -1;\r\n}\r\nstatic inline void\r\njme_phy_init(struct jme_adapter *jme)\r\n{\r\nu16 reg26;\r\nreg26 = jme_mdio_read(jme->dev, jme->mii_if.phy_id, 26);\r\njme_mdio_write(jme->dev, jme->mii_if.phy_id, 26, reg26 | 0x1000);\r\n}\r\nstatic inline void\r\njme_check_hw_ver(struct jme_adapter *jme)\r\n{\r\nu32 chipmode;\r\nchipmode = jread32(jme, JME_CHIPMODE);\r\njme->fpgaver = (chipmode & CM_FPGAVER_MASK) >> CM_FPGAVER_SHIFT;\r\njme->chiprev = (chipmode & CM_CHIPREV_MASK) >> CM_CHIPREV_SHIFT;\r\njme->chip_main_rev = jme->chiprev & 0xF;\r\njme->chip_sub_rev = (jme->chiprev >> 4) & 0xF;\r\n}\r\nstatic int\r\njme_init_one(struct pci_dev *pdev,\r\nconst struct pci_device_id *ent)\r\n{\r\nint rc = 0, using_dac, i;\r\nstruct net_device *netdev;\r\nstruct jme_adapter *jme;\r\nu16 bmcr, bmsr;\r\nu32 apmc;\r\npci_disable_link_state(pdev, PCIE_LINK_STATE_L0S | PCIE_LINK_STATE_L1 |\r\nPCIE_LINK_STATE_CLKPM);\r\nrc = pci_enable_device(pdev);\r\nif (rc) {\r\npr_err("Cannot enable PCI device\n");\r\ngoto err_out;\r\n}\r\nusing_dac = jme_pci_dma64(pdev);\r\nif (using_dac < 0) {\r\npr_err("Cannot set PCI DMA Mask\n");\r\nrc = -EIO;\r\ngoto err_out_disable_pdev;\r\n}\r\nif (!(pci_resource_flags(pdev, 0) & IORESOURCE_MEM)) {\r\npr_err("No PCI resource region found\n");\r\nrc = -ENOMEM;\r\ngoto err_out_disable_pdev;\r\n}\r\nrc = pci_request_regions(pdev, DRV_NAME);\r\nif (rc) {\r\npr_err("Cannot obtain PCI resource region\n");\r\ngoto err_out_disable_pdev;\r\n}\r\npci_set_master(pdev);\r\nnetdev = alloc_etherdev(sizeof(*jme));\r\nif (!netdev) {\r\nrc = -ENOMEM;\r\ngoto err_out_release_regions;\r\n}\r\nnetdev->netdev_ops = &jme_netdev_ops;\r\nnetdev->ethtool_ops = &jme_ethtool_ops;\r\nnetdev->watchdog_timeo = TX_TIMEOUT;\r\nnetdev->hw_features = NETIF_F_IP_CSUM |\r\nNETIF_F_IPV6_CSUM |\r\nNETIF_F_SG |\r\nNETIF_F_TSO |\r\nNETIF_F_TSO6 |\r\nNETIF_F_RXCSUM;\r\nnetdev->features = NETIF_F_IP_CSUM |\r\nNETIF_F_IPV6_CSUM |\r\nNETIF_F_SG |\r\nNETIF_F_TSO |\r\nNETIF_F_TSO6 |\r\nNETIF_F_HW_VLAN_CTAG_TX |\r\nNETIF_F_HW_VLAN_CTAG_RX;\r\nif (using_dac)\r\nnetdev->features |= NETIF_F_HIGHDMA;\r\nSET_NETDEV_DEV(netdev, &pdev->dev);\r\npci_set_drvdata(pdev, netdev);\r\njme = netdev_priv(netdev);\r\njme->pdev = pdev;\r\njme->dev = netdev;\r\njme->jme_rx = netif_rx;\r\njme->old_mtu = netdev->mtu = 1500;\r\njme->phylink = 0;\r\njme->tx_ring_size = 1 << 10;\r\njme->tx_ring_mask = jme->tx_ring_size - 1;\r\njme->tx_wake_threshold = 1 << 9;\r\njme->rx_ring_size = 1 << 9;\r\njme->rx_ring_mask = jme->rx_ring_size - 1;\r\njme->msg_enable = JME_DEF_MSG_ENABLE;\r\njme->regs = ioremap(pci_resource_start(pdev, 0),\r\npci_resource_len(pdev, 0));\r\nif (!(jme->regs)) {\r\npr_err("Mapping PCI resource region error\n");\r\nrc = -ENOMEM;\r\ngoto err_out_free_netdev;\r\n}\r\nif (no_pseudohp) {\r\napmc = jread32(jme, JME_APMC) & ~JME_APMC_PSEUDO_HP_EN;\r\njwrite32(jme, JME_APMC, apmc);\r\n} else if (force_pseudohp) {\r\napmc = jread32(jme, JME_APMC) | JME_APMC_PSEUDO_HP_EN;\r\njwrite32(jme, JME_APMC, apmc);\r\n}\r\nNETIF_NAPI_SET(netdev, &jme->napi, jme_poll, NAPI_POLL_WEIGHT)\r\nspin_lock_init(&jme->phy_lock);\r\nspin_lock_init(&jme->macaddr_lock);\r\nspin_lock_init(&jme->rxmcs_lock);\r\natomic_set(&jme->link_changing, 1);\r\natomic_set(&jme->rx_cleaning, 1);\r\natomic_set(&jme->tx_cleaning, 1);\r\natomic_set(&jme->rx_empty, 1);\r\ntasklet_init(&jme->pcc_task,\r\njme_pcc_tasklet,\r\n(unsigned long) jme);\r\njme->dpi.cur = PCC_P1;\r\njme->reg_ghc = 0;\r\njme->reg_rxcs = RXCS_DEFAULT;\r\njme->reg_rxmcs = RXMCS_DEFAULT;\r\njme->reg_txpfc = 0;\r\njme->reg_pmcs = PMCS_MFEN;\r\njme->reg_gpreg1 = GPREG1_DEFAULT;\r\nif (jme->reg_rxmcs & RXMCS_CHECKSUM)\r\nnetdev->features |= NETIF_F_RXCSUM;\r\npci_read_config_byte(pdev, PCI_DCSR_MRRS, &jme->mrrs);\r\njme->mrrs &= PCI_DCSR_MRRS_MASK;\r\nswitch (jme->mrrs) {\r\ncase MRRS_128B:\r\njme->reg_txcs = TXCS_DEFAULT | TXCS_DMASIZE_128B;\r\nbreak;\r\ncase MRRS_256B:\r\njme->reg_txcs = TXCS_DEFAULT | TXCS_DMASIZE_256B;\r\nbreak;\r\ndefault:\r\njme->reg_txcs = TXCS_DEFAULT | TXCS_DMASIZE_512B;\r\nbreak;\r\n}\r\njme_check_hw_ver(jme);\r\njme->mii_if.dev = netdev;\r\nif (jme->fpgaver) {\r\njme->mii_if.phy_id = 0;\r\nfor (i = 1 ; i < 32 ; ++i) {\r\nbmcr = jme_mdio_read(netdev, i, MII_BMCR);\r\nbmsr = jme_mdio_read(netdev, i, MII_BMSR);\r\nif (bmcr != 0xFFFFU && (bmcr != 0 || bmsr != 0)) {\r\njme->mii_if.phy_id = i;\r\nbreak;\r\n}\r\n}\r\nif (!jme->mii_if.phy_id) {\r\nrc = -EIO;\r\npr_err("Can not find phy_id\n");\r\ngoto err_out_unmap;\r\n}\r\njme->reg_ghc |= GHC_LINK_POLL;\r\n} else {\r\njme->mii_if.phy_id = 1;\r\n}\r\nif (pdev->device == PCI_DEVICE_ID_JMICRON_JMC250)\r\njme->mii_if.supports_gmii = true;\r\nelse\r\njme->mii_if.supports_gmii = false;\r\njme->mii_if.phy_id_mask = 0x1F;\r\njme->mii_if.reg_num_mask = 0x1F;\r\njme->mii_if.mdio_read = jme_mdio_read;\r\njme->mii_if.mdio_write = jme_mdio_write;\r\njme_clear_pm(jme);\r\ndevice_set_wakeup_enable(&pdev->dev, true);\r\njme_set_phyfifo_5level(jme);\r\njme->pcirev = pdev->revision;\r\nif (!jme->fpgaver)\r\njme_phy_init(jme);\r\njme_phy_off(jme);\r\njme_reset_mac_processor(jme);\r\nrc = jme_reload_eeprom(jme);\r\nif (rc) {\r\npr_err("Reload eeprom for reading MAC Address error\n");\r\ngoto err_out_unmap;\r\n}\r\njme_load_macaddr(netdev);\r\nnetif_carrier_off(netdev);\r\nrc = register_netdev(netdev);\r\nif (rc) {\r\npr_err("Cannot register net device\n");\r\ngoto err_out_unmap;\r\n}\r\nnetif_info(jme, probe, jme->dev, "%s%s chiprev:%x pcirev:%x macaddr:%pM\n",\r\n(jme->pdev->device == PCI_DEVICE_ID_JMICRON_JMC250) ?\r\n"JMC250 Gigabit Ethernet" :\r\n(jme->pdev->device == PCI_DEVICE_ID_JMICRON_JMC260) ?\r\n"JMC260 Fast Ethernet" : "Unknown",\r\n(jme->fpgaver != 0) ? " (FPGA)" : "",\r\n(jme->fpgaver != 0) ? jme->fpgaver : jme->chiprev,\r\njme->pcirev, netdev->dev_addr);\r\nreturn 0;\r\nerr_out_unmap:\r\niounmap(jme->regs);\r\nerr_out_free_netdev:\r\nfree_netdev(netdev);\r\nerr_out_release_regions:\r\npci_release_regions(pdev);\r\nerr_out_disable_pdev:\r\npci_disable_device(pdev);\r\nerr_out:\r\nreturn rc;\r\n}\r\nstatic void\r\njme_remove_one(struct pci_dev *pdev)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nunregister_netdev(netdev);\r\niounmap(jme->regs);\r\nfree_netdev(netdev);\r\npci_release_regions(pdev);\r\npci_disable_device(pdev);\r\n}\r\nstatic void\r\njme_shutdown(struct pci_dev *pdev)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\njme_powersave_phy(jme);\r\npci_pme_active(pdev, true);\r\n}\r\nstatic int\r\njme_suspend(struct device *dev)\r\n{\r\nstruct pci_dev *pdev = to_pci_dev(dev);\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nif (!netif_running(netdev))\r\nreturn 0;\r\natomic_dec(&jme->link_changing);\r\nnetif_device_detach(netdev);\r\nnetif_stop_queue(netdev);\r\njme_stop_irq(jme);\r\ntasklet_disable(&jme->txclean_task);\r\ntasklet_disable(&jme->rxclean_task);\r\ntasklet_disable(&jme->rxempty_task);\r\nif (netif_carrier_ok(netdev)) {\r\nif (test_bit(JME_FLAG_POLL, &jme->flags))\r\njme_polling_mode(jme);\r\njme_stop_pcc_timer(jme);\r\njme_disable_rx_engine(jme);\r\njme_disable_tx_engine(jme);\r\njme_reset_mac_processor(jme);\r\njme_free_rx_resources(jme);\r\njme_free_tx_resources(jme);\r\nnetif_carrier_off(netdev);\r\njme->phylink = 0;\r\n}\r\ntasklet_enable(&jme->txclean_task);\r\ntasklet_enable(&jme->rxclean_task);\r\ntasklet_enable(&jme->rxempty_task);\r\njme_powersave_phy(jme);\r\nreturn 0;\r\n}\r\nstatic int\r\njme_resume(struct device *dev)\r\n{\r\nstruct pci_dev *pdev = to_pci_dev(dev);\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct jme_adapter *jme = netdev_priv(netdev);\r\nif (!netif_running(netdev))\r\nreturn 0;\r\njme_clear_pm(jme);\r\njme_phy_on(jme);\r\nif (test_bit(JME_FLAG_SSET, &jme->flags))\r\njme_set_settings(netdev, &jme->old_ecmd);\r\nelse\r\njme_reset_phy_processor(jme);\r\njme_phy_calibration(jme);\r\njme_phy_setEA(jme);\r\njme_start_irq(jme);\r\nnetif_device_attach(netdev);\r\natomic_inc(&jme->link_changing);\r\njme_reset_link(jme);\r\nreturn 0;\r\n}\r\nstatic int __init\r\njme_init_module(void)\r\n{\r\npr_info("JMicron JMC2XX ethernet driver version %s\n", DRV_VERSION);\r\nreturn pci_register_driver(&jme_driver);\r\n}\r\nstatic void __exit\r\njme_cleanup_module(void)\r\n{\r\npci_unregister_driver(&jme_driver);\r\n}
