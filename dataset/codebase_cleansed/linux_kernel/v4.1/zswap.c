static int zswap_comp_op(enum comp_op op, const u8 *src, unsigned int slen,\r\nu8 *dst, unsigned int *dlen)\r\n{\r\nstruct crypto_comp *tfm;\r\nint ret;\r\ntfm = *per_cpu_ptr(zswap_comp_pcpu_tfms, get_cpu());\r\nswitch (op) {\r\ncase ZSWAP_COMPOP_COMPRESS:\r\nret = crypto_comp_compress(tfm, src, slen, dst, dlen);\r\nbreak;\r\ncase ZSWAP_COMPOP_DECOMPRESS:\r\nret = crypto_comp_decompress(tfm, src, slen, dst, dlen);\r\nbreak;\r\ndefault:\r\nret = -EINVAL;\r\n}\r\nput_cpu();\r\nreturn ret;\r\n}\r\nstatic int __init zswap_comp_init(void)\r\n{\r\nif (!crypto_has_comp(zswap_compressor, 0, 0)) {\r\npr_info("%s compressor not available\n", zswap_compressor);\r\nzswap_compressor = ZSWAP_COMPRESSOR_DEFAULT;\r\nif (!crypto_has_comp(zswap_compressor, 0, 0))\r\nreturn -ENODEV;\r\n}\r\npr_info("using %s compressor\n", zswap_compressor);\r\nzswap_comp_pcpu_tfms = alloc_percpu(struct crypto_comp *);\r\nif (!zswap_comp_pcpu_tfms)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nstatic void __init zswap_comp_exit(void)\r\n{\r\nfree_percpu(zswap_comp_pcpu_tfms);\r\n}\r\nstatic int __init zswap_entry_cache_create(void)\r\n{\r\nzswap_entry_cache = KMEM_CACHE(zswap_entry, 0);\r\nreturn zswap_entry_cache == NULL;\r\n}\r\nstatic void __init zswap_entry_cache_destroy(void)\r\n{\r\nkmem_cache_destroy(zswap_entry_cache);\r\n}\r\nstatic struct zswap_entry *zswap_entry_cache_alloc(gfp_t gfp)\r\n{\r\nstruct zswap_entry *entry;\r\nentry = kmem_cache_alloc(zswap_entry_cache, gfp);\r\nif (!entry)\r\nreturn NULL;\r\nentry->refcount = 1;\r\nRB_CLEAR_NODE(&entry->rbnode);\r\nreturn entry;\r\n}\r\nstatic void zswap_entry_cache_free(struct zswap_entry *entry)\r\n{\r\nkmem_cache_free(zswap_entry_cache, entry);\r\n}\r\nstatic struct zswap_entry *zswap_rb_search(struct rb_root *root, pgoff_t offset)\r\n{\r\nstruct rb_node *node = root->rb_node;\r\nstruct zswap_entry *entry;\r\nwhile (node) {\r\nentry = rb_entry(node, struct zswap_entry, rbnode);\r\nif (entry->offset > offset)\r\nnode = node->rb_left;\r\nelse if (entry->offset < offset)\r\nnode = node->rb_right;\r\nelse\r\nreturn entry;\r\n}\r\nreturn NULL;\r\n}\r\nstatic int zswap_rb_insert(struct rb_root *root, struct zswap_entry *entry,\r\nstruct zswap_entry **dupentry)\r\n{\r\nstruct rb_node **link = &root->rb_node, *parent = NULL;\r\nstruct zswap_entry *myentry;\r\nwhile (*link) {\r\nparent = *link;\r\nmyentry = rb_entry(parent, struct zswap_entry, rbnode);\r\nif (myentry->offset > entry->offset)\r\nlink = &(*link)->rb_left;\r\nelse if (myentry->offset < entry->offset)\r\nlink = &(*link)->rb_right;\r\nelse {\r\n*dupentry = myentry;\r\nreturn -EEXIST;\r\n}\r\n}\r\nrb_link_node(&entry->rbnode, parent, link);\r\nrb_insert_color(&entry->rbnode, root);\r\nreturn 0;\r\n}\r\nstatic void zswap_rb_erase(struct rb_root *root, struct zswap_entry *entry)\r\n{\r\nif (!RB_EMPTY_NODE(&entry->rbnode)) {\r\nrb_erase(&entry->rbnode, root);\r\nRB_CLEAR_NODE(&entry->rbnode);\r\n}\r\n}\r\nstatic void zswap_free_entry(struct zswap_entry *entry)\r\n{\r\nzpool_free(zswap_pool, entry->handle);\r\nzswap_entry_cache_free(entry);\r\natomic_dec(&zswap_stored_pages);\r\nzswap_pool_total_size = zpool_get_total_size(zswap_pool);\r\n}\r\nstatic void zswap_entry_get(struct zswap_entry *entry)\r\n{\r\nentry->refcount++;\r\n}\r\nstatic void zswap_entry_put(struct zswap_tree *tree,\r\nstruct zswap_entry *entry)\r\n{\r\nint refcount = --entry->refcount;\r\nBUG_ON(refcount < 0);\r\nif (refcount == 0) {\r\nzswap_rb_erase(&tree->rbroot, entry);\r\nzswap_free_entry(entry);\r\n}\r\n}\r\nstatic struct zswap_entry *zswap_entry_find_get(struct rb_root *root,\r\npgoff_t offset)\r\n{\r\nstruct zswap_entry *entry = NULL;\r\nentry = zswap_rb_search(root, offset);\r\nif (entry)\r\nzswap_entry_get(entry);\r\nreturn entry;\r\n}\r\nstatic int __zswap_cpu_notifier(unsigned long action, unsigned long cpu)\r\n{\r\nstruct crypto_comp *tfm;\r\nu8 *dst;\r\nswitch (action) {\r\ncase CPU_UP_PREPARE:\r\ntfm = crypto_alloc_comp(zswap_compressor, 0, 0);\r\nif (IS_ERR(tfm)) {\r\npr_err("can't allocate compressor transform\n");\r\nreturn NOTIFY_BAD;\r\n}\r\n*per_cpu_ptr(zswap_comp_pcpu_tfms, cpu) = tfm;\r\ndst = kmalloc_node(PAGE_SIZE * 2, GFP_KERNEL, cpu_to_node(cpu));\r\nif (!dst) {\r\npr_err("can't allocate compressor buffer\n");\r\ncrypto_free_comp(tfm);\r\n*per_cpu_ptr(zswap_comp_pcpu_tfms, cpu) = NULL;\r\nreturn NOTIFY_BAD;\r\n}\r\nper_cpu(zswap_dstmem, cpu) = dst;\r\nbreak;\r\ncase CPU_DEAD:\r\ncase CPU_UP_CANCELED:\r\ntfm = *per_cpu_ptr(zswap_comp_pcpu_tfms, cpu);\r\nif (tfm) {\r\ncrypto_free_comp(tfm);\r\n*per_cpu_ptr(zswap_comp_pcpu_tfms, cpu) = NULL;\r\n}\r\ndst = per_cpu(zswap_dstmem, cpu);\r\nkfree(dst);\r\nper_cpu(zswap_dstmem, cpu) = NULL;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn NOTIFY_OK;\r\n}\r\nstatic int zswap_cpu_notifier(struct notifier_block *nb,\r\nunsigned long action, void *pcpu)\r\n{\r\nunsigned long cpu = (unsigned long)pcpu;\r\nreturn __zswap_cpu_notifier(action, cpu);\r\n}\r\nstatic int __init zswap_cpu_init(void)\r\n{\r\nunsigned long cpu;\r\ncpu_notifier_register_begin();\r\nfor_each_online_cpu(cpu)\r\nif (__zswap_cpu_notifier(CPU_UP_PREPARE, cpu) != NOTIFY_OK)\r\ngoto cleanup;\r\n__register_cpu_notifier(&zswap_cpu_notifier_block);\r\ncpu_notifier_register_done();\r\nreturn 0;\r\ncleanup:\r\nfor_each_online_cpu(cpu)\r\n__zswap_cpu_notifier(CPU_UP_CANCELED, cpu);\r\ncpu_notifier_register_done();\r\nreturn -ENOMEM;\r\n}\r\nstatic bool zswap_is_full(void)\r\n{\r\nreturn totalram_pages * zswap_max_pool_percent / 100 <\r\nDIV_ROUND_UP(zswap_pool_total_size, PAGE_SIZE);\r\n}\r\nstatic int zswap_get_swap_cache_page(swp_entry_t entry,\r\nstruct page **retpage)\r\n{\r\nstruct page *found_page, *new_page = NULL;\r\nstruct address_space *swapper_space = swap_address_space(entry);\r\nint err;\r\n*retpage = NULL;\r\ndo {\r\nfound_page = find_get_page(swapper_space, entry.val);\r\nif (found_page)\r\nbreak;\r\nif (!new_page) {\r\nnew_page = alloc_page(GFP_KERNEL);\r\nif (!new_page)\r\nbreak;\r\n}\r\nerr = radix_tree_preload(GFP_KERNEL);\r\nif (err)\r\nbreak;\r\nerr = swapcache_prepare(entry);\r\nif (err == -EEXIST) {\r\nradix_tree_preload_end();\r\ncontinue;\r\n}\r\nif (err) {\r\nradix_tree_preload_end();\r\nbreak;\r\n}\r\n__set_page_locked(new_page);\r\nSetPageSwapBacked(new_page);\r\nerr = __add_to_swap_cache(new_page, entry);\r\nif (likely(!err)) {\r\nradix_tree_preload_end();\r\nlru_cache_add_anon(new_page);\r\n*retpage = new_page;\r\nreturn ZSWAP_SWAPCACHE_NEW;\r\n}\r\nradix_tree_preload_end();\r\nClearPageSwapBacked(new_page);\r\n__clear_page_locked(new_page);\r\nswapcache_free(entry);\r\n} while (err != -ENOMEM);\r\nif (new_page)\r\npage_cache_release(new_page);\r\nif (!found_page)\r\nreturn ZSWAP_SWAPCACHE_FAIL;\r\n*retpage = found_page;\r\nreturn ZSWAP_SWAPCACHE_EXIST;\r\n}\r\nstatic int zswap_writeback_entry(struct zpool *pool, unsigned long handle)\r\n{\r\nstruct zswap_header *zhdr;\r\nswp_entry_t swpentry;\r\nstruct zswap_tree *tree;\r\npgoff_t offset;\r\nstruct zswap_entry *entry;\r\nstruct page *page;\r\nu8 *src, *dst;\r\nunsigned int dlen;\r\nint ret;\r\nstruct writeback_control wbc = {\r\n.sync_mode = WB_SYNC_NONE,\r\n};\r\nzhdr = zpool_map_handle(pool, handle, ZPOOL_MM_RO);\r\nswpentry = zhdr->swpentry;\r\nzpool_unmap_handle(pool, handle);\r\ntree = zswap_trees[swp_type(swpentry)];\r\noffset = swp_offset(swpentry);\r\nspin_lock(&tree->lock);\r\nentry = zswap_entry_find_get(&tree->rbroot, offset);\r\nif (!entry) {\r\nspin_unlock(&tree->lock);\r\nreturn 0;\r\n}\r\nspin_unlock(&tree->lock);\r\nBUG_ON(offset != entry->offset);\r\nswitch (zswap_get_swap_cache_page(swpentry, &page)) {\r\ncase ZSWAP_SWAPCACHE_FAIL:\r\nret = -ENOMEM;\r\ngoto fail;\r\ncase ZSWAP_SWAPCACHE_EXIST:\r\npage_cache_release(page);\r\nret = -EEXIST;\r\ngoto fail;\r\ncase ZSWAP_SWAPCACHE_NEW:\r\ndlen = PAGE_SIZE;\r\nsrc = (u8 *)zpool_map_handle(zswap_pool, entry->handle,\r\nZPOOL_MM_RO) + sizeof(struct zswap_header);\r\ndst = kmap_atomic(page);\r\nret = zswap_comp_op(ZSWAP_COMPOP_DECOMPRESS, src,\r\nentry->length, dst, &dlen);\r\nkunmap_atomic(dst);\r\nzpool_unmap_handle(zswap_pool, entry->handle);\r\nBUG_ON(ret);\r\nBUG_ON(dlen != PAGE_SIZE);\r\nSetPageUptodate(page);\r\n}\r\nSetPageReclaim(page);\r\n__swap_writepage(page, &wbc, end_swap_bio_write);\r\npage_cache_release(page);\r\nzswap_written_back_pages++;\r\nspin_lock(&tree->lock);\r\nzswap_entry_put(tree, entry);\r\nif (entry == zswap_rb_search(&tree->rbroot, offset))\r\nzswap_entry_put(tree, entry);\r\nspin_unlock(&tree->lock);\r\ngoto end;\r\nfail:\r\nspin_lock(&tree->lock);\r\nzswap_entry_put(tree, entry);\r\nspin_unlock(&tree->lock);\r\nend:\r\nreturn ret;\r\n}\r\nstatic int zswap_frontswap_store(unsigned type, pgoff_t offset,\r\nstruct page *page)\r\n{\r\nstruct zswap_tree *tree = zswap_trees[type];\r\nstruct zswap_entry *entry, *dupentry;\r\nint ret;\r\nunsigned int dlen = PAGE_SIZE, len;\r\nunsigned long handle;\r\nchar *buf;\r\nu8 *src, *dst;\r\nstruct zswap_header *zhdr;\r\nif (!tree) {\r\nret = -ENODEV;\r\ngoto reject;\r\n}\r\nif (zswap_is_full()) {\r\nzswap_pool_limit_hit++;\r\nif (zpool_shrink(zswap_pool, 1, NULL)) {\r\nzswap_reject_reclaim_fail++;\r\nret = -ENOMEM;\r\ngoto reject;\r\n}\r\n}\r\nentry = zswap_entry_cache_alloc(GFP_KERNEL);\r\nif (!entry) {\r\nzswap_reject_kmemcache_fail++;\r\nret = -ENOMEM;\r\ngoto reject;\r\n}\r\ndst = get_cpu_var(zswap_dstmem);\r\nsrc = kmap_atomic(page);\r\nret = zswap_comp_op(ZSWAP_COMPOP_COMPRESS, src, PAGE_SIZE, dst, &dlen);\r\nkunmap_atomic(src);\r\nif (ret) {\r\nret = -EINVAL;\r\ngoto freepage;\r\n}\r\nlen = dlen + sizeof(struct zswap_header);\r\nret = zpool_malloc(zswap_pool, len, __GFP_NORETRY | __GFP_NOWARN,\r\n&handle);\r\nif (ret == -ENOSPC) {\r\nzswap_reject_compress_poor++;\r\ngoto freepage;\r\n}\r\nif (ret) {\r\nzswap_reject_alloc_fail++;\r\ngoto freepage;\r\n}\r\nzhdr = zpool_map_handle(zswap_pool, handle, ZPOOL_MM_RW);\r\nzhdr->swpentry = swp_entry(type, offset);\r\nbuf = (u8 *)(zhdr + 1);\r\nmemcpy(buf, dst, dlen);\r\nzpool_unmap_handle(zswap_pool, handle);\r\nput_cpu_var(zswap_dstmem);\r\nentry->offset = offset;\r\nentry->handle = handle;\r\nentry->length = dlen;\r\nspin_lock(&tree->lock);\r\ndo {\r\nret = zswap_rb_insert(&tree->rbroot, entry, &dupentry);\r\nif (ret == -EEXIST) {\r\nzswap_duplicate_entry++;\r\nzswap_rb_erase(&tree->rbroot, dupentry);\r\nzswap_entry_put(tree, dupentry);\r\n}\r\n} while (ret == -EEXIST);\r\nspin_unlock(&tree->lock);\r\natomic_inc(&zswap_stored_pages);\r\nzswap_pool_total_size = zpool_get_total_size(zswap_pool);\r\nreturn 0;\r\nfreepage:\r\nput_cpu_var(zswap_dstmem);\r\nzswap_entry_cache_free(entry);\r\nreject:\r\nreturn ret;\r\n}\r\nstatic int zswap_frontswap_load(unsigned type, pgoff_t offset,\r\nstruct page *page)\r\n{\r\nstruct zswap_tree *tree = zswap_trees[type];\r\nstruct zswap_entry *entry;\r\nu8 *src, *dst;\r\nunsigned int dlen;\r\nint ret;\r\nspin_lock(&tree->lock);\r\nentry = zswap_entry_find_get(&tree->rbroot, offset);\r\nif (!entry) {\r\nspin_unlock(&tree->lock);\r\nreturn -1;\r\n}\r\nspin_unlock(&tree->lock);\r\ndlen = PAGE_SIZE;\r\nsrc = (u8 *)zpool_map_handle(zswap_pool, entry->handle,\r\nZPOOL_MM_RO) + sizeof(struct zswap_header);\r\ndst = kmap_atomic(page);\r\nret = zswap_comp_op(ZSWAP_COMPOP_DECOMPRESS, src, entry->length,\r\ndst, &dlen);\r\nkunmap_atomic(dst);\r\nzpool_unmap_handle(zswap_pool, entry->handle);\r\nBUG_ON(ret);\r\nspin_lock(&tree->lock);\r\nzswap_entry_put(tree, entry);\r\nspin_unlock(&tree->lock);\r\nreturn 0;\r\n}\r\nstatic void zswap_frontswap_invalidate_page(unsigned type, pgoff_t offset)\r\n{\r\nstruct zswap_tree *tree = zswap_trees[type];\r\nstruct zswap_entry *entry;\r\nspin_lock(&tree->lock);\r\nentry = zswap_rb_search(&tree->rbroot, offset);\r\nif (!entry) {\r\nspin_unlock(&tree->lock);\r\nreturn;\r\n}\r\nzswap_rb_erase(&tree->rbroot, entry);\r\nzswap_entry_put(tree, entry);\r\nspin_unlock(&tree->lock);\r\n}\r\nstatic void zswap_frontswap_invalidate_area(unsigned type)\r\n{\r\nstruct zswap_tree *tree = zswap_trees[type];\r\nstruct zswap_entry *entry, *n;\r\nif (!tree)\r\nreturn;\r\nspin_lock(&tree->lock);\r\nrbtree_postorder_for_each_entry_safe(entry, n, &tree->rbroot, rbnode)\r\nzswap_free_entry(entry);\r\ntree->rbroot = RB_ROOT;\r\nspin_unlock(&tree->lock);\r\nkfree(tree);\r\nzswap_trees[type] = NULL;\r\n}\r\nstatic void zswap_frontswap_init(unsigned type)\r\n{\r\nstruct zswap_tree *tree;\r\ntree = kzalloc(sizeof(struct zswap_tree), GFP_KERNEL);\r\nif (!tree) {\r\npr_err("alloc failed, zswap disabled for swap type %d\n", type);\r\nreturn;\r\n}\r\ntree->rbroot = RB_ROOT;\r\nspin_lock_init(&tree->lock);\r\nzswap_trees[type] = tree;\r\n}\r\nstatic int __init zswap_debugfs_init(void)\r\n{\r\nif (!debugfs_initialized())\r\nreturn -ENODEV;\r\nzswap_debugfs_root = debugfs_create_dir("zswap", NULL);\r\nif (!zswap_debugfs_root)\r\nreturn -ENOMEM;\r\ndebugfs_create_u64("pool_limit_hit", S_IRUGO,\r\nzswap_debugfs_root, &zswap_pool_limit_hit);\r\ndebugfs_create_u64("reject_reclaim_fail", S_IRUGO,\r\nzswap_debugfs_root, &zswap_reject_reclaim_fail);\r\ndebugfs_create_u64("reject_alloc_fail", S_IRUGO,\r\nzswap_debugfs_root, &zswap_reject_alloc_fail);\r\ndebugfs_create_u64("reject_kmemcache_fail", S_IRUGO,\r\nzswap_debugfs_root, &zswap_reject_kmemcache_fail);\r\ndebugfs_create_u64("reject_compress_poor", S_IRUGO,\r\nzswap_debugfs_root, &zswap_reject_compress_poor);\r\ndebugfs_create_u64("written_back_pages", S_IRUGO,\r\nzswap_debugfs_root, &zswap_written_back_pages);\r\ndebugfs_create_u64("duplicate_entry", S_IRUGO,\r\nzswap_debugfs_root, &zswap_duplicate_entry);\r\ndebugfs_create_u64("pool_total_size", S_IRUGO,\r\nzswap_debugfs_root, &zswap_pool_total_size);\r\ndebugfs_create_atomic_t("stored_pages", S_IRUGO,\r\nzswap_debugfs_root, &zswap_stored_pages);\r\nreturn 0;\r\n}\r\nstatic void __exit zswap_debugfs_exit(void)\r\n{\r\ndebugfs_remove_recursive(zswap_debugfs_root);\r\n}\r\nstatic int __init zswap_debugfs_init(void)\r\n{\r\nreturn 0;\r\n}\r\nstatic void __exit zswap_debugfs_exit(void) { }\r\nstatic int __init init_zswap(void)\r\n{\r\ngfp_t gfp = __GFP_NORETRY | __GFP_NOWARN;\r\nif (!zswap_enabled)\r\nreturn 0;\r\npr_info("loading zswap\n");\r\nzswap_pool = zpool_create_pool(zswap_zpool_type, "zswap", gfp,\r\n&zswap_zpool_ops);\r\nif (!zswap_pool && strcmp(zswap_zpool_type, ZSWAP_ZPOOL_DEFAULT)) {\r\npr_info("%s zpool not available\n", zswap_zpool_type);\r\nzswap_zpool_type = ZSWAP_ZPOOL_DEFAULT;\r\nzswap_pool = zpool_create_pool(zswap_zpool_type, "zswap", gfp,\r\n&zswap_zpool_ops);\r\n}\r\nif (!zswap_pool) {\r\npr_err("%s zpool not available\n", zswap_zpool_type);\r\npr_err("zpool creation failed\n");\r\ngoto error;\r\n}\r\npr_info("using %s pool\n", zswap_zpool_type);\r\nif (zswap_entry_cache_create()) {\r\npr_err("entry cache creation failed\n");\r\ngoto cachefail;\r\n}\r\nif (zswap_comp_init()) {\r\npr_err("compressor initialization failed\n");\r\ngoto compfail;\r\n}\r\nif (zswap_cpu_init()) {\r\npr_err("per-cpu initialization failed\n");\r\ngoto pcpufail;\r\n}\r\nfrontswap_register_ops(&zswap_frontswap_ops);\r\nif (zswap_debugfs_init())\r\npr_warn("debugfs initialization failed\n");\r\nreturn 0;\r\npcpufail:\r\nzswap_comp_exit();\r\ncompfail:\r\nzswap_entry_cache_destroy();\r\ncachefail:\r\nzpool_destroy_pool(zswap_pool);\r\nerror:\r\nreturn -ENOMEM;\r\n}
