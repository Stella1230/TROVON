static const struct vsp1_format_info *vsp1_get_format_info(u32 fourcc)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < ARRAY_SIZE(vsp1_video_formats); ++i) {\r\nconst struct vsp1_format_info *info = &vsp1_video_formats[i];\r\nif (info->fourcc == fourcc)\r\nreturn info;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct v4l2_subdev *\r\nvsp1_video_remote_subdev(struct media_pad *local, u32 *pad)\r\n{\r\nstruct media_pad *remote;\r\nremote = media_entity_remote_pad(local);\r\nif (remote == NULL ||\r\nmedia_entity_type(remote->entity) != MEDIA_ENT_T_V4L2_SUBDEV)\r\nreturn NULL;\r\nif (pad)\r\n*pad = remote->index;\r\nreturn media_entity_to_v4l2_subdev(remote->entity);\r\n}\r\nstatic int vsp1_video_verify_format(struct vsp1_video *video)\r\n{\r\nstruct v4l2_subdev_format fmt;\r\nstruct v4l2_subdev *subdev;\r\nint ret;\r\nsubdev = vsp1_video_remote_subdev(&video->pad, &fmt.pad);\r\nif (subdev == NULL)\r\nreturn -EINVAL;\r\nfmt.which = V4L2_SUBDEV_FORMAT_ACTIVE;\r\nret = v4l2_subdev_call(subdev, pad, get_fmt, NULL, &fmt);\r\nif (ret < 0)\r\nreturn ret == -ENOIOCTLCMD ? -EINVAL : ret;\r\nif (video->fmtinfo->mbus != fmt.format.code ||\r\nvideo->format.height != fmt.format.height ||\r\nvideo->format.width != fmt.format.width)\r\nreturn -EINVAL;\r\nreturn 0;\r\n}\r\nstatic int __vsp1_video_try_format(struct vsp1_video *video,\r\nstruct v4l2_pix_format_mplane *pix,\r\nconst struct vsp1_format_info **fmtinfo)\r\n{\r\nstatic const u32 xrgb_formats[][2] = {\r\n{ V4L2_PIX_FMT_RGB444, V4L2_PIX_FMT_XRGB444 },\r\n{ V4L2_PIX_FMT_RGB555, V4L2_PIX_FMT_XRGB555 },\r\n{ V4L2_PIX_FMT_BGR32, V4L2_PIX_FMT_XBGR32 },\r\n{ V4L2_PIX_FMT_RGB32, V4L2_PIX_FMT_XRGB32 },\r\n};\r\nconst struct vsp1_format_info *info;\r\nunsigned int width = pix->width;\r\nunsigned int height = pix->height;\r\nunsigned int i;\r\nfor (i = 0; i < ARRAY_SIZE(xrgb_formats); ++i) {\r\nif (xrgb_formats[i][0] == pix->pixelformat) {\r\npix->pixelformat = xrgb_formats[i][1];\r\nbreak;\r\n}\r\n}\r\ninfo = vsp1_get_format_info(pix->pixelformat);\r\nif (info == NULL)\r\ninfo = vsp1_get_format_info(VSP1_VIDEO_DEF_FORMAT);\r\npix->pixelformat = info->fourcc;\r\npix->colorspace = V4L2_COLORSPACE_SRGB;\r\npix->field = V4L2_FIELD_NONE;\r\nmemset(pix->reserved, 0, sizeof(pix->reserved));\r\nwidth = round_down(width, info->hsub);\r\nheight = round_down(height, info->vsub);\r\npix->width = clamp(width, VSP1_VIDEO_MIN_WIDTH, VSP1_VIDEO_MAX_WIDTH);\r\npix->height = clamp(height, VSP1_VIDEO_MIN_HEIGHT,\r\nVSP1_VIDEO_MAX_HEIGHT);\r\nfor (i = 0; i < max(info->planes, 2U); ++i) {\r\nunsigned int hsub = i > 0 ? info->hsub : 1;\r\nunsigned int vsub = i > 0 ? info->vsub : 1;\r\nunsigned int align = 128;\r\nunsigned int bpl;\r\nbpl = clamp_t(unsigned int, pix->plane_fmt[i].bytesperline,\r\npix->width / hsub * info->bpp[i] / 8,\r\nround_down(65535U, align));\r\npix->plane_fmt[i].bytesperline = round_up(bpl, align);\r\npix->plane_fmt[i].sizeimage = pix->plane_fmt[i].bytesperline\r\n* pix->height / vsub;\r\n}\r\nif (info->planes == 3) {\r\npix->plane_fmt[2].bytesperline = pix->plane_fmt[1].bytesperline;\r\npix->plane_fmt[2].sizeimage = pix->plane_fmt[1].sizeimage;\r\n}\r\npix->num_planes = info->planes;\r\nif (fmtinfo)\r\n*fmtinfo = info;\r\nreturn 0;\r\n}\r\nstatic bool\r\nvsp1_video_format_adjust(struct vsp1_video *video,\r\nconst struct v4l2_pix_format_mplane *format,\r\nstruct v4l2_pix_format_mplane *adjust)\r\n{\r\nunsigned int i;\r\n*adjust = *format;\r\n__vsp1_video_try_format(video, adjust, NULL);\r\nif (format->width != adjust->width ||\r\nformat->height != adjust->height ||\r\nformat->pixelformat != adjust->pixelformat ||\r\nformat->num_planes != adjust->num_planes)\r\nreturn false;\r\nfor (i = 0; i < format->num_planes; ++i) {\r\nif (format->plane_fmt[i].bytesperline !=\r\nadjust->plane_fmt[i].bytesperline)\r\nreturn false;\r\nadjust->plane_fmt[i].sizeimage =\r\nmax(adjust->plane_fmt[i].sizeimage,\r\nformat->plane_fmt[i].sizeimage);\r\n}\r\nreturn true;\r\n}\r\nstatic int vsp1_pipeline_validate_branch(struct vsp1_pipeline *pipe,\r\nstruct vsp1_rwpf *input,\r\nstruct vsp1_rwpf *output)\r\n{\r\nstruct vsp1_entity *entity;\r\nunsigned int entities = 0;\r\nstruct media_pad *pad;\r\nbool bru_found = false;\r\ninput->location.left = 0;\r\ninput->location.top = 0;\r\npad = media_entity_remote_pad(&input->entity.pads[RWPF_PAD_SOURCE]);\r\nwhile (1) {\r\nif (pad == NULL)\r\nreturn -EPIPE;\r\nif (media_entity_type(pad->entity) != MEDIA_ENT_T_V4L2_SUBDEV)\r\nreturn -EPIPE;\r\nentity = to_vsp1_entity(media_entity_to_v4l2_subdev(pad->entity));\r\nif (entity->type == VSP1_ENTITY_BRU) {\r\nstruct vsp1_bru *bru = to_bru(&entity->subdev);\r\nstruct v4l2_rect *rect =\r\n&bru->inputs[pad->index].compose;\r\nbru->inputs[pad->index].rpf = input;\r\ninput->location.left = rect->left;\r\ninput->location.top = rect->top;\r\nbru_found = true;\r\n}\r\nif (entity->type == VSP1_ENTITY_WPF)\r\nbreak;\r\nif (entities & (1 << entity->subdev.entity.id))\r\nreturn -EPIPE;\r\nentities |= 1 << entity->subdev.entity.id;\r\nif (entity->type == VSP1_ENTITY_UDS) {\r\nif (pipe->uds)\r\nreturn -EPIPE;\r\npipe->uds = entity;\r\npipe->uds_input = bru_found ? pipe->bru\r\n: &input->entity;\r\n}\r\npad = &entity->pads[entity->source_pad];\r\npad = media_entity_remote_pad(pad);\r\n}\r\nif (entity != &output->entity)\r\nreturn -EPIPE;\r\nreturn 0;\r\n}\r\nstatic void __vsp1_pipeline_cleanup(struct vsp1_pipeline *pipe)\r\n{\r\nif (pipe->bru) {\r\nstruct vsp1_bru *bru = to_bru(&pipe->bru->subdev);\r\nunsigned int i;\r\nfor (i = 0; i < ARRAY_SIZE(bru->inputs); ++i)\r\nbru->inputs[i].rpf = NULL;\r\n}\r\nINIT_LIST_HEAD(&pipe->entities);\r\npipe->state = VSP1_PIPELINE_STOPPED;\r\npipe->buffers_ready = 0;\r\npipe->num_video = 0;\r\npipe->num_inputs = 0;\r\npipe->output = NULL;\r\npipe->bru = NULL;\r\npipe->lif = NULL;\r\npipe->uds = NULL;\r\n}\r\nstatic int vsp1_pipeline_validate(struct vsp1_pipeline *pipe,\r\nstruct vsp1_video *video)\r\n{\r\nstruct media_entity_graph graph;\r\nstruct media_entity *entity = &video->video.entity;\r\nstruct media_device *mdev = entity->parent;\r\nunsigned int i;\r\nint ret;\r\nmutex_lock(&mdev->graph_mutex);\r\nmedia_entity_graph_walk_start(&graph, entity);\r\nwhile ((entity = media_entity_graph_walk_next(&graph))) {\r\nstruct v4l2_subdev *subdev;\r\nstruct vsp1_rwpf *rwpf;\r\nstruct vsp1_entity *e;\r\nif (media_entity_type(entity) != MEDIA_ENT_T_V4L2_SUBDEV) {\r\npipe->num_video++;\r\ncontinue;\r\n}\r\nsubdev = media_entity_to_v4l2_subdev(entity);\r\ne = to_vsp1_entity(subdev);\r\nlist_add_tail(&e->list_pipe, &pipe->entities);\r\nif (e->type == VSP1_ENTITY_RPF) {\r\nrwpf = to_rwpf(subdev);\r\npipe->inputs[pipe->num_inputs++] = rwpf;\r\nrwpf->video.pipe_index = pipe->num_inputs;\r\n} else if (e->type == VSP1_ENTITY_WPF) {\r\nrwpf = to_rwpf(subdev);\r\npipe->output = to_rwpf(subdev);\r\nrwpf->video.pipe_index = 0;\r\n} else if (e->type == VSP1_ENTITY_LIF) {\r\npipe->lif = e;\r\n} else if (e->type == VSP1_ENTITY_BRU) {\r\npipe->bru = e;\r\n}\r\n}\r\nmutex_unlock(&mdev->graph_mutex);\r\nif (pipe->num_inputs == 0 || !pipe->output) {\r\nret = -EPIPE;\r\ngoto error;\r\n}\r\nfor (i = 0; i < pipe->num_inputs; ++i) {\r\nret = vsp1_pipeline_validate_branch(pipe, pipe->inputs[i],\r\npipe->output);\r\nif (ret < 0)\r\ngoto error;\r\n}\r\nreturn 0;\r\nerror:\r\n__vsp1_pipeline_cleanup(pipe);\r\nreturn ret;\r\n}\r\nstatic int vsp1_pipeline_init(struct vsp1_pipeline *pipe,\r\nstruct vsp1_video *video)\r\n{\r\nint ret;\r\nmutex_lock(&pipe->lock);\r\nif (pipe->use_count == 0) {\r\nret = vsp1_pipeline_validate(pipe, video);\r\nif (ret < 0)\r\ngoto done;\r\n}\r\npipe->use_count++;\r\nret = 0;\r\ndone:\r\nmutex_unlock(&pipe->lock);\r\nreturn ret;\r\n}\r\nstatic void vsp1_pipeline_cleanup(struct vsp1_pipeline *pipe)\r\n{\r\nmutex_lock(&pipe->lock);\r\nif (--pipe->use_count == 0)\r\n__vsp1_pipeline_cleanup(pipe);\r\nmutex_unlock(&pipe->lock);\r\n}\r\nstatic void vsp1_pipeline_run(struct vsp1_pipeline *pipe)\r\n{\r\nstruct vsp1_device *vsp1 = pipe->output->entity.vsp1;\r\nvsp1_write(vsp1, VI6_CMD(pipe->output->entity.index), VI6_CMD_STRCMD);\r\npipe->state = VSP1_PIPELINE_RUNNING;\r\npipe->buffers_ready = 0;\r\n}\r\nstatic int vsp1_pipeline_stop(struct vsp1_pipeline *pipe)\r\n{\r\nstruct vsp1_entity *entity;\r\nunsigned long flags;\r\nint ret;\r\nspin_lock_irqsave(&pipe->irqlock, flags);\r\nif (pipe->state == VSP1_PIPELINE_RUNNING)\r\npipe->state = VSP1_PIPELINE_STOPPING;\r\nspin_unlock_irqrestore(&pipe->irqlock, flags);\r\nret = wait_event_timeout(pipe->wq, pipe->state == VSP1_PIPELINE_STOPPED,\r\nmsecs_to_jiffies(500));\r\nret = ret == 0 ? -ETIMEDOUT : 0;\r\nlist_for_each_entry(entity, &pipe->entities, list_pipe) {\r\nif (entity->route && entity->route->reg)\r\nvsp1_write(entity->vsp1, entity->route->reg,\r\nVI6_DPR_NODE_UNUSED);\r\nv4l2_subdev_call(&entity->subdev, video, s_stream, 0);\r\n}\r\nreturn ret;\r\n}\r\nstatic bool vsp1_pipeline_ready(struct vsp1_pipeline *pipe)\r\n{\r\nunsigned int mask;\r\nmask = ((1 << pipe->num_inputs) - 1) << 1;\r\nif (!pipe->lif)\r\nmask |= 1 << 0;\r\nreturn pipe->buffers_ready == mask;\r\n}\r\nstatic struct vsp1_video_buffer *\r\nvsp1_video_complete_buffer(struct vsp1_video *video)\r\n{\r\nstruct vsp1_pipeline *pipe = to_vsp1_pipeline(&video->video.entity);\r\nstruct vsp1_video_buffer *next = NULL;\r\nstruct vsp1_video_buffer *done;\r\nunsigned long flags;\r\nunsigned int i;\r\nspin_lock_irqsave(&video->irqlock, flags);\r\nif (list_empty(&video->irqqueue)) {\r\nspin_unlock_irqrestore(&video->irqlock, flags);\r\nreturn NULL;\r\n}\r\ndone = list_first_entry(&video->irqqueue,\r\nstruct vsp1_video_buffer, queue);\r\nif (pipe->lif && list_is_singular(&video->irqqueue)) {\r\nspin_unlock_irqrestore(&video->irqlock, flags);\r\nreturn done;\r\n}\r\nlist_del(&done->queue);\r\nif (!list_empty(&video->irqqueue))\r\nnext = list_first_entry(&video->irqqueue,\r\nstruct vsp1_video_buffer, queue);\r\nspin_unlock_irqrestore(&video->irqlock, flags);\r\ndone->buf.v4l2_buf.sequence = video->sequence++;\r\nv4l2_get_timestamp(&done->buf.v4l2_buf.timestamp);\r\nfor (i = 0; i < done->buf.num_planes; ++i)\r\nvb2_set_plane_payload(&done->buf, i, done->length[i]);\r\nvb2_buffer_done(&done->buf, VB2_BUF_STATE_DONE);\r\nreturn next;\r\n}\r\nstatic void vsp1_video_frame_end(struct vsp1_pipeline *pipe,\r\nstruct vsp1_video *video)\r\n{\r\nstruct vsp1_video_buffer *buf;\r\nunsigned long flags;\r\nbuf = vsp1_video_complete_buffer(video);\r\nif (buf == NULL)\r\nreturn;\r\nspin_lock_irqsave(&pipe->irqlock, flags);\r\nvideo->ops->queue(video, buf);\r\npipe->buffers_ready |= 1 << video->pipe_index;\r\nspin_unlock_irqrestore(&pipe->irqlock, flags);\r\n}\r\nvoid vsp1_pipeline_frame_end(struct vsp1_pipeline *pipe)\r\n{\r\nenum vsp1_pipeline_state state;\r\nunsigned long flags;\r\nunsigned int i;\r\nif (pipe == NULL)\r\nreturn;\r\nfor (i = 0; i < pipe->num_inputs; ++i)\r\nvsp1_video_frame_end(pipe, &pipe->inputs[i]->video);\r\nif (!pipe->lif)\r\nvsp1_video_frame_end(pipe, &pipe->output->video);\r\nspin_lock_irqsave(&pipe->irqlock, flags);\r\nstate = pipe->state;\r\npipe->state = VSP1_PIPELINE_STOPPED;\r\nif (state == VSP1_PIPELINE_STOPPING) {\r\nwake_up(&pipe->wq);\r\ngoto done;\r\n}\r\nif (vsp1_pipeline_ready(pipe))\r\nvsp1_pipeline_run(pipe);\r\ndone:\r\nspin_unlock_irqrestore(&pipe->irqlock, flags);\r\n}\r\nvoid vsp1_pipeline_propagate_alpha(struct vsp1_pipeline *pipe,\r\nstruct vsp1_entity *input,\r\nunsigned int alpha)\r\n{\r\nstruct vsp1_entity *entity;\r\nstruct media_pad *pad;\r\npad = media_entity_remote_pad(&input->pads[RWPF_PAD_SOURCE]);\r\nwhile (pad) {\r\nif (media_entity_type(pad->entity) != MEDIA_ENT_T_V4L2_SUBDEV)\r\nbreak;\r\nentity = to_vsp1_entity(media_entity_to_v4l2_subdev(pad->entity));\r\nif (entity->type == VSP1_ENTITY_BRU)\r\nalpha = 255;\r\nif (entity->type == VSP1_ENTITY_UDS) {\r\nstruct vsp1_uds *uds = to_uds(&entity->subdev);\r\nvsp1_uds_set_alpha(uds, alpha);\r\nbreak;\r\n}\r\npad = &entity->pads[entity->source_pad];\r\npad = media_entity_remote_pad(pad);\r\n}\r\n}\r\nstatic int\r\nvsp1_video_queue_setup(struct vb2_queue *vq, const struct v4l2_format *fmt,\r\nunsigned int *nbuffers, unsigned int *nplanes,\r\nunsigned int sizes[], void *alloc_ctxs[])\r\n{\r\nstruct vsp1_video *video = vb2_get_drv_priv(vq);\r\nconst struct v4l2_pix_format_mplane *format;\r\nstruct v4l2_pix_format_mplane pix_mp;\r\nunsigned int i;\r\nif (fmt) {\r\nif (!vsp1_video_format_adjust(video, &fmt->fmt.pix_mp, &pix_mp))\r\nreturn -EINVAL;\r\nformat = &pix_mp;\r\n} else {\r\nformat = &video->format;\r\n}\r\n*nplanes = format->num_planes;\r\nfor (i = 0; i < format->num_planes; ++i) {\r\nsizes[i] = format->plane_fmt[i].sizeimage;\r\nalloc_ctxs[i] = video->alloc_ctx;\r\n}\r\nreturn 0;\r\n}\r\nstatic int vsp1_video_buffer_prepare(struct vb2_buffer *vb)\r\n{\r\nstruct vsp1_video *video = vb2_get_drv_priv(vb->vb2_queue);\r\nstruct vsp1_video_buffer *buf = to_vsp1_video_buffer(vb);\r\nconst struct v4l2_pix_format_mplane *format = &video->format;\r\nunsigned int i;\r\nif (vb->num_planes < format->num_planes)\r\nreturn -EINVAL;\r\nfor (i = 0; i < vb->num_planes; ++i) {\r\nbuf->addr[i] = vb2_dma_contig_plane_dma_addr(vb, i);\r\nbuf->length[i] = vb2_plane_size(vb, i);\r\nif (buf->length[i] < format->plane_fmt[i].sizeimage)\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic void vsp1_video_buffer_queue(struct vb2_buffer *vb)\r\n{\r\nstruct vsp1_video *video = vb2_get_drv_priv(vb->vb2_queue);\r\nstruct vsp1_pipeline *pipe = to_vsp1_pipeline(&video->video.entity);\r\nstruct vsp1_video_buffer *buf = to_vsp1_video_buffer(vb);\r\nunsigned long flags;\r\nbool empty;\r\nspin_lock_irqsave(&video->irqlock, flags);\r\nempty = list_empty(&video->irqqueue);\r\nlist_add_tail(&buf->queue, &video->irqqueue);\r\nspin_unlock_irqrestore(&video->irqlock, flags);\r\nif (!empty)\r\nreturn;\r\nspin_lock_irqsave(&pipe->irqlock, flags);\r\nvideo->ops->queue(video, buf);\r\npipe->buffers_ready |= 1 << video->pipe_index;\r\nif (vb2_is_streaming(&video->queue) &&\r\nvsp1_pipeline_ready(pipe))\r\nvsp1_pipeline_run(pipe);\r\nspin_unlock_irqrestore(&pipe->irqlock, flags);\r\n}\r\nstatic void vsp1_entity_route_setup(struct vsp1_entity *source)\r\n{\r\nstruct vsp1_entity *sink;\r\nif (source->route->reg == 0)\r\nreturn;\r\nsink = container_of(source->sink, struct vsp1_entity, subdev.entity);\r\nvsp1_write(source->vsp1, source->route->reg,\r\nsink->route->inputs[source->sink_pad]);\r\n}\r\nstatic int vsp1_video_start_streaming(struct vb2_queue *vq, unsigned int count)\r\n{\r\nstruct vsp1_video *video = vb2_get_drv_priv(vq);\r\nstruct vsp1_pipeline *pipe = to_vsp1_pipeline(&video->video.entity);\r\nstruct vsp1_entity *entity;\r\nunsigned long flags;\r\nint ret;\r\nmutex_lock(&pipe->lock);\r\nif (pipe->stream_count == pipe->num_video - 1) {\r\nif (pipe->uds) {\r\nstruct vsp1_uds *uds = to_uds(&pipe->uds->subdev);\r\nif (pipe->uds_input->type == VSP1_ENTITY_BRU) {\r\nuds->scale_alpha = false;\r\n} else {\r\nstruct vsp1_rwpf *rpf =\r\nto_rwpf(&pipe->uds_input->subdev);\r\nuds->scale_alpha = rpf->video.fmtinfo->alpha;\r\n}\r\n}\r\nlist_for_each_entry(entity, &pipe->entities, list_pipe) {\r\nvsp1_entity_route_setup(entity);\r\nret = v4l2_subdev_call(&entity->subdev, video,\r\ns_stream, 1);\r\nif (ret < 0) {\r\nmutex_unlock(&pipe->lock);\r\nreturn ret;\r\n}\r\n}\r\n}\r\npipe->stream_count++;\r\nmutex_unlock(&pipe->lock);\r\nspin_lock_irqsave(&pipe->irqlock, flags);\r\nif (vsp1_pipeline_ready(pipe))\r\nvsp1_pipeline_run(pipe);\r\nspin_unlock_irqrestore(&pipe->irqlock, flags);\r\nreturn 0;\r\n}\r\nstatic void vsp1_video_stop_streaming(struct vb2_queue *vq)\r\n{\r\nstruct vsp1_video *video = vb2_get_drv_priv(vq);\r\nstruct vsp1_pipeline *pipe = to_vsp1_pipeline(&video->video.entity);\r\nstruct vsp1_video_buffer *buffer;\r\nunsigned long flags;\r\nint ret;\r\nmutex_lock(&pipe->lock);\r\nif (--pipe->stream_count == 0) {\r\nret = vsp1_pipeline_stop(pipe);\r\nif (ret == -ETIMEDOUT)\r\ndev_err(video->vsp1->dev, "pipeline stop timeout\n");\r\n}\r\nmutex_unlock(&pipe->lock);\r\nvsp1_pipeline_cleanup(pipe);\r\nmedia_entity_pipeline_stop(&video->video.entity);\r\nspin_lock_irqsave(&video->irqlock, flags);\r\nlist_for_each_entry(buffer, &video->irqqueue, queue)\r\nvb2_buffer_done(&buffer->buf, VB2_BUF_STATE_ERROR);\r\nINIT_LIST_HEAD(&video->irqqueue);\r\nspin_unlock_irqrestore(&video->irqlock, flags);\r\n}\r\nstatic int\r\nvsp1_video_querycap(struct file *file, void *fh, struct v4l2_capability *cap)\r\n{\r\nstruct v4l2_fh *vfh = file->private_data;\r\nstruct vsp1_video *video = to_vsp1_video(vfh->vdev);\r\ncap->capabilities = V4L2_CAP_DEVICE_CAPS | V4L2_CAP_STREAMING\r\n| V4L2_CAP_VIDEO_CAPTURE_MPLANE\r\n| V4L2_CAP_VIDEO_OUTPUT_MPLANE;\r\nif (video->type == V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE)\r\ncap->device_caps = V4L2_CAP_VIDEO_CAPTURE_MPLANE\r\n| V4L2_CAP_STREAMING;\r\nelse\r\ncap->device_caps = V4L2_CAP_VIDEO_OUTPUT_MPLANE\r\n| V4L2_CAP_STREAMING;\r\nstrlcpy(cap->driver, "vsp1", sizeof(cap->driver));\r\nstrlcpy(cap->card, video->video.name, sizeof(cap->card));\r\nsnprintf(cap->bus_info, sizeof(cap->bus_info), "platform:%s",\r\ndev_name(video->vsp1->dev));\r\nreturn 0;\r\n}\r\nstatic int\r\nvsp1_video_get_format(struct file *file, void *fh, struct v4l2_format *format)\r\n{\r\nstruct v4l2_fh *vfh = file->private_data;\r\nstruct vsp1_video *video = to_vsp1_video(vfh->vdev);\r\nif (format->type != video->queue.type)\r\nreturn -EINVAL;\r\nmutex_lock(&video->lock);\r\nformat->fmt.pix_mp = video->format;\r\nmutex_unlock(&video->lock);\r\nreturn 0;\r\n}\r\nstatic int\r\nvsp1_video_try_format(struct file *file, void *fh, struct v4l2_format *format)\r\n{\r\nstruct v4l2_fh *vfh = file->private_data;\r\nstruct vsp1_video *video = to_vsp1_video(vfh->vdev);\r\nif (format->type != video->queue.type)\r\nreturn -EINVAL;\r\nreturn __vsp1_video_try_format(video, &format->fmt.pix_mp, NULL);\r\n}\r\nstatic int\r\nvsp1_video_set_format(struct file *file, void *fh, struct v4l2_format *format)\r\n{\r\nstruct v4l2_fh *vfh = file->private_data;\r\nstruct vsp1_video *video = to_vsp1_video(vfh->vdev);\r\nconst struct vsp1_format_info *info;\r\nint ret;\r\nif (format->type != video->queue.type)\r\nreturn -EINVAL;\r\nret = __vsp1_video_try_format(video, &format->fmt.pix_mp, &info);\r\nif (ret < 0)\r\nreturn ret;\r\nmutex_lock(&video->lock);\r\nif (vb2_is_busy(&video->queue)) {\r\nret = -EBUSY;\r\ngoto done;\r\n}\r\nvideo->format = format->fmt.pix_mp;\r\nvideo->fmtinfo = info;\r\ndone:\r\nmutex_unlock(&video->lock);\r\nreturn ret;\r\n}\r\nstatic int\r\nvsp1_video_streamon(struct file *file, void *fh, enum v4l2_buf_type type)\r\n{\r\nstruct v4l2_fh *vfh = file->private_data;\r\nstruct vsp1_video *video = to_vsp1_video(vfh->vdev);\r\nstruct vsp1_pipeline *pipe;\r\nint ret;\r\nif (video->queue.owner && video->queue.owner != file->private_data)\r\nreturn -EBUSY;\r\nvideo->sequence = 0;\r\npipe = video->video.entity.pipe\r\n? to_vsp1_pipeline(&video->video.entity) : &video->pipe;\r\nret = media_entity_pipeline_start(&video->video.entity, &pipe->pipe);\r\nif (ret < 0)\r\nreturn ret;\r\nret = vsp1_video_verify_format(video);\r\nif (ret < 0)\r\ngoto err_stop;\r\nret = vsp1_pipeline_init(pipe, video);\r\nif (ret < 0)\r\ngoto err_stop;\r\nret = vb2_streamon(&video->queue, type);\r\nif (ret < 0)\r\ngoto err_cleanup;\r\nreturn 0;\r\nerr_cleanup:\r\nvsp1_pipeline_cleanup(pipe);\r\nerr_stop:\r\nmedia_entity_pipeline_stop(&video->video.entity);\r\nreturn ret;\r\n}\r\nstatic int vsp1_video_open(struct file *file)\r\n{\r\nstruct vsp1_video *video = video_drvdata(file);\r\nstruct v4l2_fh *vfh;\r\nint ret = 0;\r\nvfh = kzalloc(sizeof(*vfh), GFP_KERNEL);\r\nif (vfh == NULL)\r\nreturn -ENOMEM;\r\nv4l2_fh_init(vfh, &video->video);\r\nv4l2_fh_add(vfh);\r\nfile->private_data = vfh;\r\nret = vsp1_device_get(video->vsp1);\r\nif (ret < 0) {\r\nv4l2_fh_del(vfh);\r\nkfree(vfh);\r\n}\r\nreturn ret;\r\n}\r\nstatic int vsp1_video_release(struct file *file)\r\n{\r\nstruct vsp1_video *video = video_drvdata(file);\r\nstruct v4l2_fh *vfh = file->private_data;\r\nmutex_lock(&video->lock);\r\nif (video->queue.owner == vfh) {\r\nvb2_queue_release(&video->queue);\r\nvideo->queue.owner = NULL;\r\n}\r\nmutex_unlock(&video->lock);\r\nvsp1_device_put(video->vsp1);\r\nv4l2_fh_release(file);\r\nfile->private_data = NULL;\r\nreturn 0;\r\n}\r\nint vsp1_video_init(struct vsp1_video *video, struct vsp1_entity *rwpf)\r\n{\r\nconst char *direction;\r\nint ret;\r\nswitch (video->type) {\r\ncase V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE:\r\ndirection = "output";\r\nvideo->pad.flags = MEDIA_PAD_FL_SINK;\r\nbreak;\r\ncase V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE:\r\ndirection = "input";\r\nvideo->pad.flags = MEDIA_PAD_FL_SOURCE;\r\nvideo->video.vfl_dir = VFL_DIR_TX;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nvideo->rwpf = rwpf;\r\nmutex_init(&video->lock);\r\nspin_lock_init(&video->irqlock);\r\nINIT_LIST_HEAD(&video->irqqueue);\r\nmutex_init(&video->pipe.lock);\r\nspin_lock_init(&video->pipe.irqlock);\r\nINIT_LIST_HEAD(&video->pipe.entities);\r\ninit_waitqueue_head(&video->pipe.wq);\r\nvideo->pipe.state = VSP1_PIPELINE_STOPPED;\r\nret = media_entity_init(&video->video.entity, 1, &video->pad, 0);\r\nif (ret < 0)\r\nreturn ret;\r\nvideo->fmtinfo = vsp1_get_format_info(VSP1_VIDEO_DEF_FORMAT);\r\nvideo->format.pixelformat = video->fmtinfo->fourcc;\r\nvideo->format.colorspace = V4L2_COLORSPACE_SRGB;\r\nvideo->format.field = V4L2_FIELD_NONE;\r\nvideo->format.width = VSP1_VIDEO_DEF_WIDTH;\r\nvideo->format.height = VSP1_VIDEO_DEF_HEIGHT;\r\nvideo->format.num_planes = 1;\r\nvideo->format.plane_fmt[0].bytesperline =\r\nvideo->format.width * video->fmtinfo->bpp[0] / 8;\r\nvideo->format.plane_fmt[0].sizeimage =\r\nvideo->format.plane_fmt[0].bytesperline * video->format.height;\r\nvideo->video.v4l2_dev = &video->vsp1->v4l2_dev;\r\nvideo->video.fops = &vsp1_video_fops;\r\nsnprintf(video->video.name, sizeof(video->video.name), "%s %s",\r\nrwpf->subdev.name, direction);\r\nvideo->video.vfl_type = VFL_TYPE_GRABBER;\r\nvideo->video.release = video_device_release_empty;\r\nvideo->video.ioctl_ops = &vsp1_video_ioctl_ops;\r\nvideo_set_drvdata(&video->video, video);\r\nvideo->alloc_ctx = vb2_dma_contig_init_ctx(video->vsp1->dev);\r\nif (IS_ERR(video->alloc_ctx)) {\r\nret = PTR_ERR(video->alloc_ctx);\r\ngoto error;\r\n}\r\nvideo->queue.type = video->type;\r\nvideo->queue.io_modes = VB2_MMAP | VB2_USERPTR | VB2_DMABUF;\r\nvideo->queue.lock = &video->lock;\r\nvideo->queue.drv_priv = video;\r\nvideo->queue.buf_struct_size = sizeof(struct vsp1_video_buffer);\r\nvideo->queue.ops = &vsp1_video_queue_qops;\r\nvideo->queue.mem_ops = &vb2_dma_contig_memops;\r\nvideo->queue.timestamp_flags = V4L2_BUF_FLAG_TIMESTAMP_COPY;\r\nret = vb2_queue_init(&video->queue);\r\nif (ret < 0) {\r\ndev_err(video->vsp1->dev, "failed to initialize vb2 queue\n");\r\ngoto error;\r\n}\r\nvideo->video.queue = &video->queue;\r\nret = video_register_device(&video->video, VFL_TYPE_GRABBER, -1);\r\nif (ret < 0) {\r\ndev_err(video->vsp1->dev, "failed to register video device\n");\r\ngoto error;\r\n}\r\nreturn 0;\r\nerror:\r\nvb2_dma_contig_cleanup_ctx(video->alloc_ctx);\r\nvsp1_video_cleanup(video);\r\nreturn ret;\r\n}\r\nvoid vsp1_video_cleanup(struct vsp1_video *video)\r\n{\r\nif (video_is_registered(&video->video))\r\nvideo_unregister_device(&video->video);\r\nvb2_dma_contig_cleanup_ctx(video->alloc_ctx);\r\nmedia_entity_cleanup(&video->video.entity);\r\n}
