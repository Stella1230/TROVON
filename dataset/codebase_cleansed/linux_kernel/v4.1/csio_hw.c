int csio_is_hw_ready(struct csio_hw *hw)\r\n{\r\nreturn csio_match_state(hw, csio_hws_ready);\r\n}\r\nint csio_is_hw_removing(struct csio_hw *hw)\r\n{\r\nreturn csio_match_state(hw, csio_hws_removing);\r\n}\r\nint\r\ncsio_hw_wait_op_done_val(struct csio_hw *hw, int reg, uint32_t mask,\r\nint polarity, int attempts, int delay, uint32_t *valp)\r\n{\r\nuint32_t val;\r\nwhile (1) {\r\nval = csio_rd_reg32(hw, reg);\r\nif (!!(val & mask) == polarity) {\r\nif (valp)\r\n*valp = val;\r\nreturn 0;\r\n}\r\nif (--attempts == 0)\r\nreturn -EAGAIN;\r\nif (delay)\r\nudelay(delay);\r\n}\r\n}\r\nvoid\r\ncsio_hw_tp_wr_bits_indirect(struct csio_hw *hw, unsigned int addr,\r\nunsigned int mask, unsigned int val)\r\n{\r\ncsio_wr_reg32(hw, addr, TP_PIO_ADDR_A);\r\nval |= csio_rd_reg32(hw, TP_PIO_DATA_A) & ~mask;\r\ncsio_wr_reg32(hw, val, TP_PIO_DATA_A);\r\n}\r\nvoid\r\ncsio_set_reg_field(struct csio_hw *hw, uint32_t reg, uint32_t mask,\r\nuint32_t value)\r\n{\r\nuint32_t val = csio_rd_reg32(hw, reg) & ~mask;\r\ncsio_wr_reg32(hw, val | value, reg);\r\ncsio_rd_reg32(hw, reg);\r\n}\r\nstatic int\r\ncsio_memory_write(struct csio_hw *hw, int mtype, u32 addr, u32 len, u32 *buf)\r\n{\r\nreturn hw->chip_ops->chip_memory_rw(hw, MEMWIN_CSIOSTOR, mtype,\r\naddr, len, buf, 0);\r\n}\r\nstatic int\r\ncsio_hw_seeprom_read(struct csio_hw *hw, uint32_t addr, uint32_t *data)\r\n{\r\nuint16_t val = 0;\r\nint attempts = EEPROM_MAX_RD_POLL;\r\nuint32_t base = hw->params.pci.vpd_cap_addr;\r\nif (addr >= EEPROMVSIZE || (addr & 3))\r\nreturn -EINVAL;\r\npci_write_config_word(hw->pdev, base + PCI_VPD_ADDR, (uint16_t)addr);\r\ndo {\r\nudelay(10);\r\npci_read_config_word(hw->pdev, base + PCI_VPD_ADDR, &val);\r\n} while (!(val & PCI_VPD_ADDR_F) && --attempts);\r\nif (!(val & PCI_VPD_ADDR_F)) {\r\ncsio_err(hw, "reading EEPROM address 0x%x failed\n", addr);\r\nreturn -EINVAL;\r\n}\r\npci_read_config_dword(hw->pdev, base + PCI_VPD_DATA, data);\r\n*data = le32_to_cpu(*(__le32 *)data);\r\nreturn 0;\r\n}\r\nstatic int\r\ncsio_hw_get_vpd_keyword_val(const struct t4_vpd_hdr *v, const char *kw)\r\n{\r\nint32_t i;\r\nint32_t offset , len;\r\nconst uint8_t *buf = &v->id_tag;\r\nconst uint8_t *vpdr_len = &v->vpdr_tag;\r\noffset = sizeof(struct t4_vpd_hdr);\r\nlen = (uint16_t)vpdr_len[1] + ((uint16_t)vpdr_len[2] << 8);\r\nif (len + sizeof(struct t4_vpd_hdr) > VPD_LEN)\r\nreturn -EINVAL;\r\nfor (i = offset; (i + VPD_INFO_FLD_HDR_SIZE) <= (offset + len);) {\r\nif (memcmp(buf + i , kw, 2) == 0) {\r\ni += VPD_INFO_FLD_HDR_SIZE;\r\nreturn i;\r\n}\r\ni += VPD_INFO_FLD_HDR_SIZE + buf[i+2];\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic int\r\ncsio_pci_capability(struct pci_dev *pdev, int cap, int *pos)\r\n{\r\n*pos = pci_find_capability(pdev, cap);\r\nif (*pos)\r\nreturn 0;\r\nreturn -1;\r\n}\r\nstatic int\r\ncsio_hw_get_vpd_params(struct csio_hw *hw, struct csio_vpd *p)\r\n{\r\nint i, ret, ec, sn, addr;\r\nuint8_t *vpd, csum;\r\nconst struct t4_vpd_hdr *v;\r\nchar *s;\r\nif (csio_is_valid_vpd(hw))\r\nreturn 0;\r\nret = csio_pci_capability(hw->pdev, PCI_CAP_ID_VPD,\r\n&hw->params.pci.vpd_cap_addr);\r\nif (ret)\r\nreturn -EINVAL;\r\nvpd = kzalloc(VPD_LEN, GFP_ATOMIC);\r\nif (vpd == NULL)\r\nreturn -ENOMEM;\r\nret = csio_hw_seeprom_read(hw, VPD_BASE, (uint32_t *)(vpd));\r\naddr = *vpd == 0x82 ? VPD_BASE : VPD_BASE_OLD;\r\nfor (i = 0; i < VPD_LEN; i += 4) {\r\nret = csio_hw_seeprom_read(hw, addr + i, (uint32_t *)(vpd + i));\r\nif (ret) {\r\nkfree(vpd);\r\nreturn ret;\r\n}\r\n}\r\nhw->flags &= (~CSIO_HWF_VPD_VALID);\r\nv = (const struct t4_vpd_hdr *)vpd;\r\n#define FIND_VPD_KW(var, name) do { \\r\nvar = csio_hw_get_vpd_keyword_val(v, name); \\r\nif (var < 0) { \\r\ncsio_err(hw, "missing VPD keyword " name "\n"); \\r\nkfree(vpd); \\r\nreturn -EINVAL; \\r\n} \\r\n} while (0)\r\nFIND_VPD_KW(i, "RV");\r\nfor (csum = 0; i >= 0; i--)\r\ncsum += vpd[i];\r\nif (csum) {\r\ncsio_err(hw, "corrupted VPD EEPROM, actual csum %u\n", csum);\r\nkfree(vpd);\r\nreturn -EINVAL;\r\n}\r\nFIND_VPD_KW(ec, "EC");\r\nFIND_VPD_KW(sn, "SN");\r\n#undef FIND_VPD_KW\r\nmemcpy(p->id, v->id_data, ID_LEN);\r\ns = strstrip(p->id);\r\nmemcpy(p->ec, vpd + ec, EC_LEN);\r\ns = strstrip(p->ec);\r\ni = vpd[sn - VPD_INFO_FLD_HDR_SIZE + 2];\r\nmemcpy(p->sn, vpd + sn, min(i, SERNUM_LEN));\r\ns = strstrip(p->sn);\r\ncsio_valid_vpd_copied(hw);\r\nkfree(vpd);\r\nreturn 0;\r\n}\r\nstatic int\r\ncsio_hw_sf1_read(struct csio_hw *hw, uint32_t byte_cnt, int32_t cont,\r\nint32_t lock, uint32_t *valp)\r\n{\r\nint ret;\r\nif (!byte_cnt || byte_cnt > 4)\r\nreturn -EINVAL;\r\nif (csio_rd_reg32(hw, SF_OP_A) & SF_BUSY_F)\r\nreturn -EBUSY;\r\ncsio_wr_reg32(hw, SF_LOCK_V(lock) | SF_CONT_V(cont) |\r\nBYTECNT_V(byte_cnt - 1), SF_OP_A);\r\nret = csio_hw_wait_op_done_val(hw, SF_OP_A, SF_BUSY_F, 0, SF_ATTEMPTS,\r\n10, NULL);\r\nif (!ret)\r\n*valp = csio_rd_reg32(hw, SF_DATA_A);\r\nreturn ret;\r\n}\r\nstatic int\r\ncsio_hw_sf1_write(struct csio_hw *hw, uint32_t byte_cnt, uint32_t cont,\r\nint32_t lock, uint32_t val)\r\n{\r\nif (!byte_cnt || byte_cnt > 4)\r\nreturn -EINVAL;\r\nif (csio_rd_reg32(hw, SF_OP_A) & SF_BUSY_F)\r\nreturn -EBUSY;\r\ncsio_wr_reg32(hw, val, SF_DATA_A);\r\ncsio_wr_reg32(hw, SF_CONT_V(cont) | BYTECNT_V(byte_cnt - 1) |\r\nOP_V(1) | SF_LOCK_V(lock), SF_OP_A);\r\nreturn csio_hw_wait_op_done_val(hw, SF_OP_A, SF_BUSY_F, 0, SF_ATTEMPTS,\r\n10, NULL);\r\n}\r\nstatic int\r\ncsio_hw_flash_wait_op(struct csio_hw *hw, int32_t attempts, int32_t delay)\r\n{\r\nint ret;\r\nuint32_t status;\r\nwhile (1) {\r\nret = csio_hw_sf1_write(hw, 1, 1, 1, SF_RD_STATUS);\r\nif (ret != 0)\r\nreturn ret;\r\nret = csio_hw_sf1_read(hw, 1, 0, 1, &status);\r\nif (ret != 0)\r\nreturn ret;\r\nif (!(status & 1))\r\nreturn 0;\r\nif (--attempts == 0)\r\nreturn -EAGAIN;\r\nif (delay)\r\nmsleep(delay);\r\n}\r\n}\r\nstatic int\r\ncsio_hw_read_flash(struct csio_hw *hw, uint32_t addr, uint32_t nwords,\r\nuint32_t *data, int32_t byte_oriented)\r\n{\r\nint ret;\r\nif (addr + nwords * sizeof(uint32_t) > hw->params.sf_size || (addr & 3))\r\nreturn -EINVAL;\r\naddr = swab32(addr) | SF_RD_DATA_FAST;\r\nret = csio_hw_sf1_write(hw, 4, 1, 0, addr);\r\nif (ret != 0)\r\nreturn ret;\r\nret = csio_hw_sf1_read(hw, 1, 1, 0, data);\r\nif (ret != 0)\r\nreturn ret;\r\nfor ( ; nwords; nwords--, data++) {\r\nret = csio_hw_sf1_read(hw, 4, nwords > 1, nwords == 1, data);\r\nif (nwords == 1)\r\ncsio_wr_reg32(hw, 0, SF_OP_A);\r\nif (ret)\r\nreturn ret;\r\nif (byte_oriented)\r\n*data = (__force __u32) htonl(*data);\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\ncsio_hw_write_flash(struct csio_hw *hw, uint32_t addr,\r\nuint32_t n, const uint8_t *data)\r\n{\r\nint ret = -EINVAL;\r\nuint32_t buf[64];\r\nuint32_t i, c, left, val, offset = addr & 0xff;\r\nif (addr >= hw->params.sf_size || offset + n > SF_PAGE_SIZE)\r\nreturn -EINVAL;\r\nval = swab32(addr) | SF_PROG_PAGE;\r\nret = csio_hw_sf1_write(hw, 1, 0, 1, SF_WR_ENABLE);\r\nif (ret != 0)\r\ngoto unlock;\r\nret = csio_hw_sf1_write(hw, 4, 1, 1, val);\r\nif (ret != 0)\r\ngoto unlock;\r\nfor (left = n; left; left -= c) {\r\nc = min(left, 4U);\r\nfor (val = 0, i = 0; i < c; ++i)\r\nval = (val << 8) + *data++;\r\nret = csio_hw_sf1_write(hw, c, c != left, 1, val);\r\nif (ret)\r\ngoto unlock;\r\n}\r\nret = csio_hw_flash_wait_op(hw, 8, 1);\r\nif (ret)\r\ngoto unlock;\r\ncsio_wr_reg32(hw, 0, SF_OP_A);\r\nret = csio_hw_read_flash(hw, addr & ~0xff, ARRAY_SIZE(buf), buf, 1);\r\nif (ret)\r\nreturn ret;\r\nif (memcmp(data - n, (uint8_t *)buf + offset, n)) {\r\ncsio_err(hw,\r\n"failed to correctly write the flash page at %#x\n",\r\naddr);\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\nunlock:\r\ncsio_wr_reg32(hw, 0, SF_OP_A);\r\nreturn ret;\r\n}\r\nstatic int\r\ncsio_hw_flash_erase_sectors(struct csio_hw *hw, int32_t start, int32_t end)\r\n{\r\nint ret = 0;\r\nwhile (start <= end) {\r\nret = csio_hw_sf1_write(hw, 1, 0, 1, SF_WR_ENABLE);\r\nif (ret != 0)\r\ngoto out;\r\nret = csio_hw_sf1_write(hw, 4, 0, 1,\r\nSF_ERASE_SECTOR | (start << 8));\r\nif (ret != 0)\r\ngoto out;\r\nret = csio_hw_flash_wait_op(hw, 14, 500);\r\nif (ret != 0)\r\ngoto out;\r\nstart++;\r\n}\r\nout:\r\nif (ret)\r\ncsio_err(hw, "erase of flash sector %d failed, error %d\n",\r\nstart, ret);\r\ncsio_wr_reg32(hw, 0, SF_OP_A);\r\nreturn 0;\r\n}\r\nstatic void\r\ncsio_hw_print_fw_version(struct csio_hw *hw, char *str)\r\n{\r\ncsio_info(hw, "%s: %u.%u.%u.%u\n", str,\r\nFW_HDR_FW_VER_MAJOR_G(hw->fwrev),\r\nFW_HDR_FW_VER_MINOR_G(hw->fwrev),\r\nFW_HDR_FW_VER_MICRO_G(hw->fwrev),\r\nFW_HDR_FW_VER_BUILD_G(hw->fwrev));\r\n}\r\nstatic int\r\ncsio_hw_get_fw_version(struct csio_hw *hw, uint32_t *vers)\r\n{\r\nreturn csio_hw_read_flash(hw, FLASH_FW_START +\r\noffsetof(struct fw_hdr, fw_ver), 1,\r\nvers, 0);\r\n}\r\nstatic int\r\ncsio_hw_get_tp_version(struct csio_hw *hw, u32 *vers)\r\n{\r\nreturn csio_hw_read_flash(hw, FLASH_FW_START +\r\noffsetof(struct fw_hdr, tp_microcode_ver), 1,\r\nvers, 0);\r\n}\r\nstatic int\r\ncsio_hw_fw_dload(struct csio_hw *hw, uint8_t *fw_data, uint32_t size)\r\n{\r\nuint32_t csum;\r\nint32_t addr;\r\nint ret;\r\nuint32_t i;\r\nuint8_t first_page[SF_PAGE_SIZE];\r\nconst __be32 *p = (const __be32 *)fw_data;\r\nstruct fw_hdr *hdr = (struct fw_hdr *)fw_data;\r\nuint32_t sf_sec_size;\r\nif ((!hw->params.sf_size) || (!hw->params.sf_nsec)) {\r\ncsio_err(hw, "Serial Flash data invalid\n");\r\nreturn -EINVAL;\r\n}\r\nif (!size) {\r\ncsio_err(hw, "FW image has no data\n");\r\nreturn -EINVAL;\r\n}\r\nif (size & 511) {\r\ncsio_err(hw, "FW image size not multiple of 512 bytes\n");\r\nreturn -EINVAL;\r\n}\r\nif (ntohs(hdr->len512) * 512 != size) {\r\ncsio_err(hw, "FW image size differs from size in FW header\n");\r\nreturn -EINVAL;\r\n}\r\nif (size > FLASH_FW_MAX_SIZE) {\r\ncsio_err(hw, "FW image too large, max is %u bytes\n",\r\nFLASH_FW_MAX_SIZE);\r\nreturn -EINVAL;\r\n}\r\nfor (csum = 0, i = 0; i < size / sizeof(csum); i++)\r\ncsum += ntohl(p[i]);\r\nif (csum != 0xffffffff) {\r\ncsio_err(hw, "corrupted firmware image, checksum %#x\n", csum);\r\nreturn -EINVAL;\r\n}\r\nsf_sec_size = hw->params.sf_size / hw->params.sf_nsec;\r\ni = DIV_ROUND_UP(size, sf_sec_size);\r\ncsio_dbg(hw, "Erasing sectors... start:%d end:%d\n",\r\nFLASH_FW_START_SEC, FLASH_FW_START_SEC + i - 1);\r\nret = csio_hw_flash_erase_sectors(hw, FLASH_FW_START_SEC,\r\nFLASH_FW_START_SEC + i - 1);\r\nif (ret) {\r\ncsio_err(hw, "Flash Erase failed\n");\r\ngoto out;\r\n}\r\nmemcpy(first_page, fw_data, SF_PAGE_SIZE);\r\n((struct fw_hdr *)first_page)->fw_ver = htonl(0xffffffff);\r\nret = csio_hw_write_flash(hw, FLASH_FW_START, SF_PAGE_SIZE, first_page);\r\nif (ret)\r\ngoto out;\r\ncsio_dbg(hw, "Writing Flash .. start:%d end:%d\n",\r\nFW_IMG_START, FW_IMG_START + size);\r\naddr = FLASH_FW_START;\r\nfor (size -= SF_PAGE_SIZE; size; size -= SF_PAGE_SIZE) {\r\naddr += SF_PAGE_SIZE;\r\nfw_data += SF_PAGE_SIZE;\r\nret = csio_hw_write_flash(hw, addr, SF_PAGE_SIZE, fw_data);\r\nif (ret)\r\ngoto out;\r\n}\r\nret = csio_hw_write_flash(hw,\r\nFLASH_FW_START +\r\noffsetof(struct fw_hdr, fw_ver),\r\nsizeof(hdr->fw_ver),\r\n(const uint8_t *)&hdr->fw_ver);\r\nout:\r\nif (ret)\r\ncsio_err(hw, "firmware download failed, error %d\n", ret);\r\nreturn ret;\r\n}\r\nstatic int\r\ncsio_hw_get_flash_params(struct csio_hw *hw)\r\n{\r\nint ret;\r\nuint32_t info = 0;\r\nret = csio_hw_sf1_write(hw, 1, 1, 0, SF_RD_ID);\r\nif (!ret)\r\nret = csio_hw_sf1_read(hw, 3, 0, 1, &info);\r\ncsio_wr_reg32(hw, 0, SF_OP_A);\r\nif (ret != 0)\r\nreturn ret;\r\nif ((info & 0xff) != 0x20)\r\nreturn -EINVAL;\r\ninfo >>= 16;\r\nif (info >= 0x14 && info < 0x18)\r\nhw->params.sf_nsec = 1 << (info - 16);\r\nelse if (info == 0x18)\r\nhw->params.sf_nsec = 64;\r\nelse\r\nreturn -EINVAL;\r\nhw->params.sf_size = 1 << info;\r\nreturn 0;\r\n}\r\nstatic int\r\ncsio_hw_dev_ready(struct csio_hw *hw)\r\n{\r\nuint32_t reg;\r\nint cnt = 6;\r\nwhile (((reg = csio_rd_reg32(hw, PL_WHOAMI_A)) == 0xFFFFFFFF) &&\r\n(--cnt != 0))\r\nmdelay(100);\r\nif ((cnt == 0) && (((int32_t)(SOURCEPF_G(reg)) < 0) ||\r\n(SOURCEPF_G(reg) >= CSIO_MAX_PFN))) {\r\ncsio_err(hw, "PL_WHOAMI returned 0x%x, cnt:%d\n", reg, cnt);\r\nreturn -EIO;\r\n}\r\nhw->pfn = SOURCEPF_G(reg);\r\nreturn 0;\r\n}\r\nstatic int\r\ncsio_do_hello(struct csio_hw *hw, enum csio_dev_state *state)\r\n{\r\nstruct csio_mb *mbp;\r\nint rv = 0;\r\nenum fw_retval retval;\r\nuint8_t mpfn;\r\nchar state_str[16];\r\nint retries = FW_CMD_HELLO_RETRIES;\r\nmemset(state_str, 0, sizeof(state_str));\r\nmbp = mempool_alloc(hw->mb_mempool, GFP_ATOMIC);\r\nif (!mbp) {\r\nrv = -ENOMEM;\r\nCSIO_INC_STATS(hw, n_err_nomem);\r\ngoto out;\r\n}\r\nretry:\r\ncsio_mb_hello(hw, mbp, CSIO_MB_DEFAULT_TMO, hw->pfn,\r\nhw->pfn, CSIO_MASTER_MAY, NULL);\r\nrv = csio_mb_issue(hw, mbp);\r\nif (rv) {\r\ncsio_err(hw, "failed to issue HELLO cmd. ret:%d.\n", rv);\r\ngoto out_free_mb;\r\n}\r\ncsio_mb_process_hello_rsp(hw, mbp, &retval, state, &mpfn);\r\nif (retval != FW_SUCCESS) {\r\ncsio_err(hw, "HELLO cmd failed with ret: %d\n", retval);\r\nrv = -EINVAL;\r\ngoto out_free_mb;\r\n}\r\nif (hw->pfn == mpfn) {\r\nhw->flags |= CSIO_HWF_MASTER;\r\n} else if (*state == CSIO_DEV_STATE_UNINIT) {\r\nint waiting = FW_CMD_HELLO_TIMEOUT;\r\nfor (;;) {\r\nuint32_t pcie_fw;\r\nspin_unlock_irq(&hw->lock);\r\nmsleep(50);\r\nspin_lock_irq(&hw->lock);\r\nwaiting -= 50;\r\npcie_fw = csio_rd_reg32(hw, PCIE_FW_A);\r\nif (!(pcie_fw & (PCIE_FW_ERR_F|PCIE_FW_INIT_F))) {\r\nif (waiting <= 0) {\r\nif (retries-- > 0)\r\ngoto retry;\r\nrv = -ETIMEDOUT;\r\nbreak;\r\n}\r\ncontinue;\r\n}\r\nif (state) {\r\nif (pcie_fw & PCIE_FW_ERR_F) {\r\n*state = CSIO_DEV_STATE_ERR;\r\nrv = -ETIMEDOUT;\r\n} else if (pcie_fw & PCIE_FW_INIT_F)\r\n*state = CSIO_DEV_STATE_INIT;\r\n}\r\nif (mpfn == PCIE_FW_MASTER_M &&\r\n(pcie_fw & PCIE_FW_MASTER_VLD_F))\r\nmpfn = PCIE_FW_MASTER_G(pcie_fw);\r\nbreak;\r\n}\r\nhw->flags &= ~CSIO_HWF_MASTER;\r\n}\r\nswitch (*state) {\r\ncase CSIO_DEV_STATE_UNINIT:\r\nstrcpy(state_str, "Initializing");\r\nbreak;\r\ncase CSIO_DEV_STATE_INIT:\r\nstrcpy(state_str, "Initialized");\r\nbreak;\r\ncase CSIO_DEV_STATE_ERR:\r\nstrcpy(state_str, "Error");\r\nbreak;\r\ndefault:\r\nstrcpy(state_str, "Unknown");\r\nbreak;\r\n}\r\nif (hw->pfn == mpfn)\r\ncsio_info(hw, "PF: %d, Coming up as MASTER, HW state: %s\n",\r\nhw->pfn, state_str);\r\nelse\r\ncsio_info(hw,\r\n"PF: %d, Coming up as SLAVE, Master PF: %d, HW state: %s\n",\r\nhw->pfn, mpfn, state_str);\r\nout_free_mb:\r\nmempool_free(mbp, hw->mb_mempool);\r\nout:\r\nreturn rv;\r\n}\r\nstatic int\r\ncsio_do_bye(struct csio_hw *hw)\r\n{\r\nstruct csio_mb *mbp;\r\nenum fw_retval retval;\r\nmbp = mempool_alloc(hw->mb_mempool, GFP_ATOMIC);\r\nif (!mbp) {\r\nCSIO_INC_STATS(hw, n_err_nomem);\r\nreturn -ENOMEM;\r\n}\r\ncsio_mb_bye(hw, mbp, CSIO_MB_DEFAULT_TMO, NULL);\r\nif (csio_mb_issue(hw, mbp)) {\r\ncsio_err(hw, "Issue of BYE command failed\n");\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn -EINVAL;\r\n}\r\nretval = csio_mb_fw_retval(mbp);\r\nif (retval != FW_SUCCESS) {\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn -EINVAL;\r\n}\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn 0;\r\n}\r\nstatic int\r\ncsio_do_reset(struct csio_hw *hw, bool fw_rst)\r\n{\r\nstruct csio_mb *mbp;\r\nenum fw_retval retval;\r\nif (!fw_rst) {\r\ncsio_wr_reg32(hw, PIORSTMODE_F | PIORST_F, PL_RST_A);\r\nmdelay(2000);\r\nreturn 0;\r\n}\r\nmbp = mempool_alloc(hw->mb_mempool, GFP_ATOMIC);\r\nif (!mbp) {\r\nCSIO_INC_STATS(hw, n_err_nomem);\r\nreturn -ENOMEM;\r\n}\r\ncsio_mb_reset(hw, mbp, CSIO_MB_DEFAULT_TMO,\r\nPIORSTMODE_F | PIORST_F, 0, NULL);\r\nif (csio_mb_issue(hw, mbp)) {\r\ncsio_err(hw, "Issue of RESET command failed.n");\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn -EINVAL;\r\n}\r\nretval = csio_mb_fw_retval(mbp);\r\nif (retval != FW_SUCCESS) {\r\ncsio_err(hw, "RESET cmd failed with ret:0x%x.\n", retval);\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn -EINVAL;\r\n}\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn 0;\r\n}\r\nstatic int\r\ncsio_hw_validate_caps(struct csio_hw *hw, struct csio_mb *mbp)\r\n{\r\nstruct fw_caps_config_cmd *rsp = (struct fw_caps_config_cmd *)mbp->mb;\r\nuint16_t caps;\r\ncaps = ntohs(rsp->fcoecaps);\r\nif (!(caps & FW_CAPS_CONFIG_FCOE_INITIATOR)) {\r\ncsio_err(hw, "No FCoE Initiator capability in the firmware.\n");\r\nreturn -EINVAL;\r\n}\r\nif (!(caps & FW_CAPS_CONFIG_FCOE_CTRL_OFLD)) {\r\ncsio_err(hw, "No FCoE Control Offload capability\n");\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\ncsio_hw_fw_halt(struct csio_hw *hw, uint32_t mbox, int32_t force)\r\n{\r\nenum fw_retval retval = 0;\r\nif (mbox <= PCIE_FW_MASTER_M) {\r\nstruct csio_mb *mbp;\r\nmbp = mempool_alloc(hw->mb_mempool, GFP_ATOMIC);\r\nif (!mbp) {\r\nCSIO_INC_STATS(hw, n_err_nomem);\r\nreturn -ENOMEM;\r\n}\r\ncsio_mb_reset(hw, mbp, CSIO_MB_DEFAULT_TMO,\r\nPIORSTMODE_F | PIORST_F, FW_RESET_CMD_HALT_F,\r\nNULL);\r\nif (csio_mb_issue(hw, mbp)) {\r\ncsio_err(hw, "Issue of RESET command failed!\n");\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn -EINVAL;\r\n}\r\nretval = csio_mb_fw_retval(mbp);\r\nmempool_free(mbp, hw->mb_mempool);\r\n}\r\nif (retval == 0 || force) {\r\ncsio_set_reg_field(hw, CIM_BOOT_CFG_A, UPCRST_F, UPCRST_F);\r\ncsio_set_reg_field(hw, PCIE_FW_A, PCIE_FW_HALT_F,\r\nPCIE_FW_HALT_F);\r\n}\r\nreturn retval ? -EINVAL : 0;\r\n}\r\nstatic int\r\ncsio_hw_fw_restart(struct csio_hw *hw, uint32_t mbox, int32_t reset)\r\n{\r\nif (reset) {\r\ncsio_set_reg_field(hw, PCIE_FW_A, PCIE_FW_HALT_F, 0);\r\nif (mbox <= PCIE_FW_MASTER_M) {\r\ncsio_set_reg_field(hw, CIM_BOOT_CFG_A, UPCRST_F, 0);\r\nmsleep(100);\r\nif (csio_do_reset(hw, true) == 0)\r\nreturn 0;\r\n}\r\ncsio_wr_reg32(hw, PIORSTMODE_F | PIORST_F, PL_RST_A);\r\nmsleep(2000);\r\n} else {\r\nint ms;\r\ncsio_set_reg_field(hw, CIM_BOOT_CFG_A, UPCRST_F, 0);\r\nfor (ms = 0; ms < FW_CMD_MAX_TIMEOUT; ) {\r\nif (!(csio_rd_reg32(hw, PCIE_FW_A) & PCIE_FW_HALT_F))\r\nreturn 0;\r\nmsleep(100);\r\nms += 100;\r\n}\r\nreturn -ETIMEDOUT;\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\ncsio_hw_fw_upgrade(struct csio_hw *hw, uint32_t mbox,\r\nconst u8 *fw_data, uint32_t size, int32_t force)\r\n{\r\nconst struct fw_hdr *fw_hdr = (const struct fw_hdr *)fw_data;\r\nint reset, ret;\r\nret = csio_hw_fw_halt(hw, mbox, force);\r\nif (ret != 0 && !force)\r\nreturn ret;\r\nret = csio_hw_fw_dload(hw, (uint8_t *) fw_data, size);\r\nif (ret != 0)\r\nreturn ret;\r\nreset = ((ntohl(fw_hdr->flags) & FW_HDR_FLAGS_RESET_HALT) == 0);\r\nreturn csio_hw_fw_restart(hw, mbox, reset);\r\n}\r\nstatic int\r\ncsio_get_device_params(struct csio_hw *hw)\r\n{\r\nstruct csio_wrm *wrm = csio_hw_to_wrm(hw);\r\nstruct csio_mb *mbp;\r\nenum fw_retval retval;\r\nu32 param[6];\r\nint i, j = 0;\r\nfor (i = 0; i < CSIO_MAX_PPORTS; i++)\r\nhw->pport[i].portid = -1;\r\nmbp = mempool_alloc(hw->mb_mempool, GFP_ATOMIC);\r\nif (!mbp) {\r\nCSIO_INC_STATS(hw, n_err_nomem);\r\nreturn -ENOMEM;\r\n}\r\nparam[0] = FW_PARAM_DEV(PORTVEC);\r\nparam[1] = FW_PARAM_DEV(CCLK);\r\nparam[2] = FW_PARAM_PFVF(EQ_START);\r\nparam[3] = FW_PARAM_PFVF(EQ_END);\r\nparam[4] = FW_PARAM_PFVF(IQFLINT_START);\r\nparam[5] = FW_PARAM_PFVF(IQFLINT_END);\r\ncsio_mb_params(hw, mbp, CSIO_MB_DEFAULT_TMO, hw->pfn, 0,\r\nARRAY_SIZE(param), param, NULL, false, NULL);\r\nif (csio_mb_issue(hw, mbp)) {\r\ncsio_err(hw, "Issue of FW_PARAMS_CMD(read) failed!\n");\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn -EINVAL;\r\n}\r\ncsio_mb_process_read_params_rsp(hw, mbp, &retval,\r\nARRAY_SIZE(param), param);\r\nif (retval != FW_SUCCESS) {\r\ncsio_err(hw, "FW_PARAMS_CMD(read) failed with ret:0x%x!\n",\r\nretval);\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn -EINVAL;\r\n}\r\nhw->port_vec = param[0];\r\nhw->vpd.cclk = param[1];\r\nwrm->fw_eq_start = param[2];\r\nwrm->fw_iq_start = param[4];\r\nif ((hw->flags & CSIO_HWF_USING_SOFT_PARAMS) ||\r\n!csio_is_hw_master(hw)) {\r\nhw->cfg_niq = param[5] - param[4] + 1;\r\nhw->cfg_neq = param[3] - param[2] + 1;\r\ncsio_dbg(hw, "Using fwconfig max niqs %d neqs %d\n",\r\nhw->cfg_niq, hw->cfg_neq);\r\n}\r\nhw->port_vec &= csio_port_mask;\r\nhw->num_pports = hweight32(hw->port_vec);\r\ncsio_dbg(hw, "Port vector: 0x%x, #ports: %d\n",\r\nhw->port_vec, hw->num_pports);\r\nfor (i = 0; i < hw->num_pports; i++) {\r\nwhile ((hw->port_vec & (1 << j)) == 0)\r\nj++;\r\nhw->pport[i].portid = j++;\r\ncsio_dbg(hw, "Found Port:%d\n", hw->pport[i].portid);\r\n}\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn 0;\r\n}\r\nstatic int\r\ncsio_config_device_caps(struct csio_hw *hw)\r\n{\r\nstruct csio_mb *mbp;\r\nenum fw_retval retval;\r\nint rv = -EINVAL;\r\nmbp = mempool_alloc(hw->mb_mempool, GFP_ATOMIC);\r\nif (!mbp) {\r\nCSIO_INC_STATS(hw, n_err_nomem);\r\nreturn -ENOMEM;\r\n}\r\ncsio_mb_caps_config(hw, mbp, CSIO_MB_DEFAULT_TMO, 0, 0, 0, 0, NULL);\r\nif (csio_mb_issue(hw, mbp)) {\r\ncsio_err(hw, "Issue of FW_CAPS_CONFIG_CMD(r) failed!\n");\r\ngoto out;\r\n}\r\nretval = csio_mb_fw_retval(mbp);\r\nif (retval != FW_SUCCESS) {\r\ncsio_err(hw, "FW_CAPS_CONFIG_CMD(r) returned %d!\n", retval);\r\ngoto out;\r\n}\r\nrv = csio_hw_validate_caps(hw, mbp);\r\nif (rv != 0)\r\ngoto out;\r\nif (hw->fw_state == CSIO_DEV_STATE_INIT) {\r\nrv = 0;\r\ngoto out;\r\n}\r\ncsio_mb_caps_config(hw, mbp, CSIO_MB_DEFAULT_TMO, true, true,\r\nfalse, true, NULL);\r\nif (csio_mb_issue(hw, mbp)) {\r\ncsio_err(hw, "Issue of FW_CAPS_CONFIG_CMD(w) failed!\n");\r\ngoto out;\r\n}\r\nretval = csio_mb_fw_retval(mbp);\r\nif (retval != FW_SUCCESS) {\r\ncsio_err(hw, "FW_CAPS_CONFIG_CMD(w) returned %d!\n", retval);\r\ngoto out;\r\n}\r\nrv = 0;\r\nout:\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn rv;\r\n}\r\nstatic int\r\ncsio_enable_ports(struct csio_hw *hw)\r\n{\r\nstruct csio_mb *mbp;\r\nenum fw_retval retval;\r\nuint8_t portid;\r\nint i;\r\nmbp = mempool_alloc(hw->mb_mempool, GFP_ATOMIC);\r\nif (!mbp) {\r\nCSIO_INC_STATS(hw, n_err_nomem);\r\nreturn -ENOMEM;\r\n}\r\nfor (i = 0; i < hw->num_pports; i++) {\r\nportid = hw->pport[i].portid;\r\ncsio_mb_port(hw, mbp, CSIO_MB_DEFAULT_TMO, portid,\r\nfalse, 0, 0, NULL);\r\nif (csio_mb_issue(hw, mbp)) {\r\ncsio_err(hw, "failed to issue FW_PORT_CMD(r) port:%d\n",\r\nportid);\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn -EINVAL;\r\n}\r\ncsio_mb_process_read_port_rsp(hw, mbp, &retval,\r\n&hw->pport[i].pcap);\r\nif (retval != FW_SUCCESS) {\r\ncsio_err(hw, "FW_PORT_CMD(r) port:%d failed: 0x%x\n",\r\nportid, retval);\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn -EINVAL;\r\n}\r\ncsio_mb_port(hw, mbp, CSIO_MB_DEFAULT_TMO, portid, true,\r\n(PAUSE_RX | PAUSE_TX), hw->pport[i].pcap, NULL);\r\nif (csio_mb_issue(hw, mbp)) {\r\ncsio_err(hw, "failed to issue FW_PORT_CMD(w) port:%d\n",\r\nportid);\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn -EINVAL;\r\n}\r\nretval = csio_mb_fw_retval(mbp);\r\nif (retval != FW_SUCCESS) {\r\ncsio_err(hw, "FW_PORT_CMD(w) port:%d failed :0x%x\n",\r\nportid, retval);\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn -EINVAL;\r\n}\r\n}\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn 0;\r\n}\r\nstatic int\r\ncsio_get_fcoe_resinfo(struct csio_hw *hw)\r\n{\r\nstruct csio_fcoe_res_info *res_info = &hw->fres_info;\r\nstruct fw_fcoe_res_info_cmd *rsp;\r\nstruct csio_mb *mbp;\r\nenum fw_retval retval;\r\nmbp = mempool_alloc(hw->mb_mempool, GFP_ATOMIC);\r\nif (!mbp) {\r\nCSIO_INC_STATS(hw, n_err_nomem);\r\nreturn -ENOMEM;\r\n}\r\ncsio_fcoe_read_res_info_init_mb(hw, mbp, CSIO_MB_DEFAULT_TMO, NULL);\r\nif (csio_mb_issue(hw, mbp)) {\r\ncsio_err(hw, "failed to issue FW_FCOE_RES_INFO_CMD\n");\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn -EINVAL;\r\n}\r\nrsp = (struct fw_fcoe_res_info_cmd *)(mbp->mb);\r\nretval = FW_CMD_RETVAL_G(ntohl(rsp->retval_len16));\r\nif (retval != FW_SUCCESS) {\r\ncsio_err(hw, "FW_FCOE_RES_INFO_CMD failed with ret x%x\n",\r\nretval);\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn -EINVAL;\r\n}\r\nres_info->e_d_tov = ntohs(rsp->e_d_tov);\r\nres_info->r_a_tov_seq = ntohs(rsp->r_a_tov_seq);\r\nres_info->r_a_tov_els = ntohs(rsp->r_a_tov_els);\r\nres_info->r_r_tov = ntohs(rsp->r_r_tov);\r\nres_info->max_xchgs = ntohl(rsp->max_xchgs);\r\nres_info->max_ssns = ntohl(rsp->max_ssns);\r\nres_info->used_xchgs = ntohl(rsp->used_xchgs);\r\nres_info->used_ssns = ntohl(rsp->used_ssns);\r\nres_info->max_fcfs = ntohl(rsp->max_fcfs);\r\nres_info->max_vnps = ntohl(rsp->max_vnps);\r\nres_info->used_fcfs = ntohl(rsp->used_fcfs);\r\nres_info->used_vnps = ntohl(rsp->used_vnps);\r\ncsio_dbg(hw, "max ssns:%d max xchgs:%d\n", res_info->max_ssns,\r\nres_info->max_xchgs);\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn 0;\r\n}\r\nstatic int\r\ncsio_hw_check_fwconfig(struct csio_hw *hw, u32 *param)\r\n{\r\nstruct csio_mb *mbp;\r\nenum fw_retval retval;\r\nu32 _param[1];\r\nmbp = mempool_alloc(hw->mb_mempool, GFP_ATOMIC);\r\nif (!mbp) {\r\nCSIO_INC_STATS(hw, n_err_nomem);\r\nreturn -ENOMEM;\r\n}\r\n_param[0] = (FW_PARAMS_MNEM_V(FW_PARAMS_MNEM_DEV) |\r\nFW_PARAMS_PARAM_X_V(FW_PARAMS_PARAM_DEV_CF));\r\ncsio_mb_params(hw, mbp, CSIO_MB_DEFAULT_TMO, hw->pfn, 0,\r\nARRAY_SIZE(_param), _param, NULL, false, NULL);\r\nif (csio_mb_issue(hw, mbp)) {\r\ncsio_err(hw, "Issue of FW_PARAMS_CMD(read) failed!\n");\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn -EINVAL;\r\n}\r\ncsio_mb_process_read_params_rsp(hw, mbp, &retval,\r\nARRAY_SIZE(_param), _param);\r\nif (retval != FW_SUCCESS) {\r\ncsio_err(hw, "FW_PARAMS_CMD(read) failed with ret:0x%x!\n",\r\nretval);\r\nmempool_free(mbp, hw->mb_mempool);\r\nreturn -EINVAL;\r\n}\r\nmempool_free(mbp, hw->mb_mempool);\r\n*param = _param[0];\r\nreturn 0;\r\n}\r\nstatic int\r\ncsio_hw_flash_config(struct csio_hw *hw, u32 *fw_cfg_param, char *path)\r\n{\r\nint ret = 0;\r\nconst struct firmware *cf;\r\nstruct pci_dev *pci_dev = hw->pdev;\r\nstruct device *dev = &pci_dev->dev;\r\nunsigned int mtype = 0, maddr = 0;\r\nuint32_t *cfg_data;\r\nint value_to_add = 0;\r\nif (request_firmware(&cf, FW_CFG_NAME_T5, dev) < 0) {\r\ncsio_err(hw, "could not find config file %s, err: %d\n",\r\nFW_CFG_NAME_T5, ret);\r\nreturn -ENOENT;\r\n}\r\nif (cf->size%4 != 0)\r\nvalue_to_add = 4 - (cf->size % 4);\r\ncfg_data = kzalloc(cf->size+value_to_add, GFP_KERNEL);\r\nif (cfg_data == NULL) {\r\nret = -ENOMEM;\r\ngoto leave;\r\n}\r\nmemcpy((void *)cfg_data, (const void *)cf->data, cf->size);\r\nif (csio_hw_check_fwconfig(hw, fw_cfg_param) != 0) {\r\nret = -EINVAL;\r\ngoto leave;\r\n}\r\nmtype = FW_PARAMS_PARAM_Y_G(*fw_cfg_param);\r\nmaddr = FW_PARAMS_PARAM_Z_G(*fw_cfg_param) << 16;\r\nret = csio_memory_write(hw, mtype, maddr,\r\ncf->size + value_to_add, cfg_data);\r\nif ((ret == 0) && (value_to_add != 0)) {\r\nunion {\r\nu32 word;\r\nchar buf[4];\r\n} last;\r\nsize_t size = cf->size & ~0x3;\r\nint i;\r\nlast.word = cfg_data[size >> 2];\r\nfor (i = value_to_add; i < 4; i++)\r\nlast.buf[i] = 0;\r\nret = csio_memory_write(hw, mtype, maddr + size, 4, &last.word);\r\n}\r\nif (ret == 0) {\r\ncsio_info(hw, "config file upgraded to %s\n",\r\nFW_CFG_NAME_T5);\r\nsnprintf(path, 64, "%s%s", "/lib/firmware/", FW_CFG_NAME_T5);\r\n}\r\nleave:\r\nkfree(cfg_data);\r\nrelease_firmware(cf);\r\nreturn ret;\r\n}\r\nstatic int\r\ncsio_hw_use_fwconfig(struct csio_hw *hw, int reset, u32 *fw_cfg_param)\r\n{\r\nstruct csio_mb *mbp = NULL;\r\nstruct fw_caps_config_cmd *caps_cmd;\r\nunsigned int mtype, maddr;\r\nint rv = -EINVAL;\r\nuint32_t finiver = 0, finicsum = 0, cfcsum = 0;\r\nchar path[64];\r\nchar *config_name = NULL;\r\nif (reset) {\r\nrv = csio_do_reset(hw, true);\r\nif (rv != 0)\r\ngoto bye;\r\n}\r\nspin_unlock_irq(&hw->lock);\r\nrv = csio_hw_flash_config(hw, fw_cfg_param, path);\r\nspin_lock_irq(&hw->lock);\r\nif (rv != 0) {\r\nconfig_name = "On FLASH";\r\nmtype = FW_MEMTYPE_CF_FLASH;\r\nmaddr = hw->chip_ops->chip_flash_cfg_addr(hw);\r\n} else {\r\nconfig_name = path;\r\nmtype = FW_PARAMS_PARAM_Y_G(*fw_cfg_param);\r\nmaddr = FW_PARAMS_PARAM_Z_G(*fw_cfg_param) << 16;\r\n}\r\nmbp = mempool_alloc(hw->mb_mempool, GFP_ATOMIC);\r\nif (!mbp) {\r\nCSIO_INC_STATS(hw, n_err_nomem);\r\nreturn -ENOMEM;\r\n}\r\ncaps_cmd = (struct fw_caps_config_cmd *)(mbp->mb);\r\nCSIO_INIT_MBP(mbp, caps_cmd, CSIO_MB_DEFAULT_TMO, hw, NULL, 1);\r\ncaps_cmd->op_to_write =\r\nhtonl(FW_CMD_OP_V(FW_CAPS_CONFIG_CMD) |\r\nFW_CMD_REQUEST_F |\r\nFW_CMD_READ_F);\r\ncaps_cmd->cfvalid_to_len16 =\r\nhtonl(FW_CAPS_CONFIG_CMD_CFVALID_F |\r\nFW_CAPS_CONFIG_CMD_MEMTYPE_CF_V(mtype) |\r\nFW_CAPS_CONFIG_CMD_MEMADDR64K_CF_V(maddr >> 16) |\r\nFW_LEN16(*caps_cmd));\r\nif (csio_mb_issue(hw, mbp)) {\r\nrv = -EINVAL;\r\ngoto bye;\r\n}\r\nrv = csio_mb_fw_retval(mbp);\r\nif (rv == ENOENT) {\r\nCSIO_INIT_MBP(mbp, caps_cmd, CSIO_MB_DEFAULT_TMO, hw, NULL, 1);\r\ncaps_cmd->op_to_write = htonl(FW_CMD_OP_V(FW_CAPS_CONFIG_CMD) |\r\nFW_CMD_REQUEST_F |\r\nFW_CMD_READ_F);\r\ncaps_cmd->cfvalid_to_len16 = htonl(FW_LEN16(*caps_cmd));\r\nif (csio_mb_issue(hw, mbp)) {\r\nrv = -EINVAL;\r\ngoto bye;\r\n}\r\nrv = csio_mb_fw_retval(mbp);\r\nconfig_name = "Firmware Default";\r\n}\r\nif (rv != FW_SUCCESS)\r\ngoto bye;\r\nfiniver = ntohl(caps_cmd->finiver);\r\nfinicsum = ntohl(caps_cmd->finicsum);\r\ncfcsum = ntohl(caps_cmd->cfcsum);\r\ncaps_cmd->op_to_write =\r\nhtonl(FW_CMD_OP_V(FW_CAPS_CONFIG_CMD) |\r\nFW_CMD_REQUEST_F |\r\nFW_CMD_WRITE_F);\r\ncaps_cmd->cfvalid_to_len16 = htonl(FW_LEN16(*caps_cmd));\r\nif (csio_mb_issue(hw, mbp)) {\r\nrv = -EINVAL;\r\ngoto bye;\r\n}\r\nrv = csio_mb_fw_retval(mbp);\r\nif (rv != FW_SUCCESS) {\r\ncsio_dbg(hw, "FW_CAPS_CONFIG_CMD returned %d!\n", rv);\r\ngoto bye;\r\n}\r\nmempool_free(mbp, hw->mb_mempool);\r\nif (finicsum != cfcsum) {\r\ncsio_warn(hw,\r\n"Config File checksum mismatch: csum=%#x, computed=%#x\n",\r\nfinicsum, cfcsum);\r\n}\r\nrv = csio_hw_validate_caps(hw, mbp);\r\nif (rv != 0)\r\ngoto bye;\r\nhw->flags |= CSIO_HWF_USING_SOFT_PARAMS;\r\nrv = csio_get_device_params(hw);\r\nif (rv != 0)\r\ngoto bye;\r\ncsio_wr_sge_init(hw);\r\ncsio_post_event(&hw->sm, CSIO_HWE_INIT);\r\ncsio_info(hw, "Successfully configure using Firmware "\r\n"Configuration File %s, version %#x, computed checksum %#x\n",\r\nconfig_name, finiver, cfcsum);\r\nreturn 0;\r\nbye:\r\nif (mbp)\r\nmempool_free(mbp, hw->mb_mempool);\r\nhw->flags &= ~CSIO_HWF_USING_SOFT_PARAMS;\r\ncsio_warn(hw, "Configuration file error %d\n", rv);\r\nreturn rv;\r\n}\r\nstatic int fw_compatible(const struct fw_hdr *hdr1, const struct fw_hdr *hdr2)\r\n{\r\nif (hdr1->chip == hdr2->chip && hdr1->fw_ver == hdr2->fw_ver)\r\nreturn 1;\r\n#define SAME_INTF(x) (hdr1->intfver_##x == hdr2->intfver_##x)\r\nif (hdr1->chip == hdr2->chip && SAME_INTF(nic) && SAME_INTF(vnic) &&\r\nSAME_INTF(ri) && SAME_INTF(iscsi) && SAME_INTF(fcoe))\r\nreturn 1;\r\n#undef SAME_INTF\r\nreturn 0;\r\n}\r\nstatic int csio_should_install_fs_fw(struct csio_hw *hw, int card_fw_usable,\r\nint k, int c)\r\n{\r\nconst char *reason;\r\nif (!card_fw_usable) {\r\nreason = "incompatible or unusable";\r\ngoto install;\r\n}\r\nif (k > c) {\r\nreason = "older than the version supported with this driver";\r\ngoto install;\r\n}\r\nreturn 0;\r\ninstall:\r\ncsio_err(hw, "firmware on card (%u.%u.%u.%u) is %s, "\r\n"installing firmware %u.%u.%u.%u on card.\n",\r\nFW_HDR_FW_VER_MAJOR_G(c), FW_HDR_FW_VER_MINOR_G(c),\r\nFW_HDR_FW_VER_MICRO_G(c), FW_HDR_FW_VER_BUILD_G(c), reason,\r\nFW_HDR_FW_VER_MAJOR_G(k), FW_HDR_FW_VER_MINOR_G(k),\r\nFW_HDR_FW_VER_MICRO_G(k), FW_HDR_FW_VER_BUILD_G(k));\r\nreturn 1;\r\n}\r\nstatic struct fw_info *find_fw_info(int chip)\r\n{\r\nint i;\r\nfor (i = 0; i < ARRAY_SIZE(fw_info_array); i++) {\r\nif (fw_info_array[i].chip == chip)\r\nreturn &fw_info_array[i];\r\n}\r\nreturn NULL;\r\n}\r\nstatic int csio_hw_prep_fw(struct csio_hw *hw, struct fw_info *fw_info,\r\nconst u8 *fw_data, unsigned int fw_size,\r\nstruct fw_hdr *card_fw, enum csio_dev_state state,\r\nint *reset)\r\n{\r\nint ret, card_fw_usable, fs_fw_usable;\r\nconst struct fw_hdr *fs_fw;\r\nconst struct fw_hdr *drv_fw;\r\ndrv_fw = &fw_info->fw_hdr;\r\nret = csio_hw_read_flash(hw, FLASH_FW_START,\r\nsizeof(*card_fw) / sizeof(uint32_t),\r\n(uint32_t *)card_fw, 1);\r\nif (ret == 0) {\r\ncard_fw_usable = fw_compatible(drv_fw, (const void *)card_fw);\r\n} else {\r\ncsio_err(hw,\r\n"Unable to read card's firmware header: %d\n", ret);\r\ncard_fw_usable = 0;\r\n}\r\nif (fw_data != NULL) {\r\nfs_fw = (const void *)fw_data;\r\nfs_fw_usable = fw_compatible(drv_fw, fs_fw);\r\n} else {\r\nfs_fw = NULL;\r\nfs_fw_usable = 0;\r\n}\r\nif (card_fw_usable && card_fw->fw_ver == drv_fw->fw_ver &&\r\n(!fs_fw_usable || fs_fw->fw_ver == drv_fw->fw_ver)) {\r\n} else if (fs_fw_usable && state == CSIO_DEV_STATE_UNINIT &&\r\ncsio_should_install_fs_fw(hw, card_fw_usable,\r\nbe32_to_cpu(fs_fw->fw_ver),\r\nbe32_to_cpu(card_fw->fw_ver))) {\r\nret = csio_hw_fw_upgrade(hw, hw->pfn, fw_data,\r\nfw_size, 0);\r\nif (ret != 0) {\r\ncsio_err(hw,\r\n"failed to install firmware: %d\n", ret);\r\ngoto bye;\r\n}\r\nmemcpy(card_fw, fs_fw, sizeof(*card_fw));\r\ncard_fw_usable = 1;\r\n*reset = 0;\r\n}\r\nif (!card_fw_usable) {\r\nuint32_t d, c, k;\r\nd = be32_to_cpu(drv_fw->fw_ver);\r\nc = be32_to_cpu(card_fw->fw_ver);\r\nk = fs_fw ? be32_to_cpu(fs_fw->fw_ver) : 0;\r\ncsio_err(hw, "Cannot find a usable firmware: "\r\n"chip state %d, "\r\n"driver compiled with %d.%d.%d.%d, "\r\n"card has %d.%d.%d.%d, filesystem has %d.%d.%d.%d\n",\r\nstate,\r\nFW_HDR_FW_VER_MAJOR_G(d), FW_HDR_FW_VER_MINOR_G(d),\r\nFW_HDR_FW_VER_MICRO_G(d), FW_HDR_FW_VER_BUILD_G(d),\r\nFW_HDR_FW_VER_MAJOR_G(c), FW_HDR_FW_VER_MINOR_G(c),\r\nFW_HDR_FW_VER_MICRO_G(c), FW_HDR_FW_VER_BUILD_G(c),\r\nFW_HDR_FW_VER_MAJOR_G(k), FW_HDR_FW_VER_MINOR_G(k),\r\nFW_HDR_FW_VER_MICRO_G(k), FW_HDR_FW_VER_BUILD_G(k));\r\nret = EINVAL;\r\ngoto bye;\r\n}\r\nhw->fwrev = be32_to_cpu(card_fw->fw_ver);\r\nhw->tp_vers = be32_to_cpu(card_fw->tp_microcode_ver);\r\nbye:\r\nreturn ret;\r\n}\r\nstatic int\r\ncsio_hw_flash_fw(struct csio_hw *hw, int *reset)\r\n{\r\nint ret = -ECANCELED;\r\nconst struct firmware *fw;\r\nstruct fw_info *fw_info;\r\nstruct fw_hdr *card_fw;\r\nstruct pci_dev *pci_dev = hw->pdev;\r\nstruct device *dev = &pci_dev->dev ;\r\nconst u8 *fw_data = NULL;\r\nunsigned int fw_size = 0;\r\nfw_info = find_fw_info(CHELSIO_CHIP_VERSION(hw->chip_id));\r\nif (fw_info == NULL) {\r\ncsio_err(hw,\r\n"unable to get firmware info for chip %d.\n",\r\nCHELSIO_CHIP_VERSION(hw->chip_id));\r\nreturn -EINVAL;\r\n}\r\nif (request_firmware(&fw, FW_FNAME_T5, dev) < 0) {\r\ncsio_err(hw, "could not find firmware image %s, err: %d\n",\r\nFW_FNAME_T5, ret);\r\n} else {\r\nfw_data = fw->data;\r\nfw_size = fw->size;\r\n}\r\ncard_fw = kmalloc(sizeof(*card_fw), GFP_KERNEL);\r\nret = csio_hw_prep_fw(hw, fw_info, fw_data, fw_size, card_fw,\r\nhw->fw_state, reset);\r\nif (fw != NULL)\r\nrelease_firmware(fw);\r\nkfree(card_fw);\r\nreturn ret;\r\n}\r\nstatic void\r\ncsio_hw_configure(struct csio_hw *hw)\r\n{\r\nint reset = 1;\r\nint rv;\r\nu32 param[1];\r\nrv = csio_hw_dev_ready(hw);\r\nif (rv != 0) {\r\nCSIO_INC_STATS(hw, n_err_fatal);\r\ncsio_post_event(&hw->sm, CSIO_HWE_FATAL);\r\ngoto out;\r\n}\r\nhw->chip_ver = (char)csio_rd_reg32(hw, PL_REV_A);\r\nrv = csio_hw_get_flash_params(hw);\r\nif (rv != 0) {\r\ncsio_err(hw, "Failed to get serial flash params rv:%d\n", rv);\r\ncsio_post_event(&hw->sm, CSIO_HWE_FATAL);\r\ngoto out;\r\n}\r\nif (pci_is_pcie(hw->pdev))\r\npcie_capability_clear_and_set_word(hw->pdev, PCI_EXP_DEVCTL2,\r\nPCI_EXP_DEVCTL2_COMP_TIMEOUT, 0xd);\r\nhw->chip_ops->chip_set_mem_win(hw, MEMWIN_CSIOSTOR);\r\nrv = csio_hw_get_fw_version(hw, &hw->fwrev);\r\nif (rv != 0)\r\ngoto out;\r\ncsio_hw_print_fw_version(hw, "Firmware revision");\r\nrv = csio_do_hello(hw, &hw->fw_state);\r\nif (rv != 0) {\r\nCSIO_INC_STATS(hw, n_err_fatal);\r\ncsio_post_event(&hw->sm, CSIO_HWE_FATAL);\r\ngoto out;\r\n}\r\nrv = csio_hw_get_vpd_params(hw, &hw->vpd);\r\nif (rv != 0)\r\ngoto out;\r\ncsio_hw_get_fw_version(hw, &hw->fwrev);\r\ncsio_hw_get_tp_version(hw, &hw->tp_vers);\r\nif (csio_is_hw_master(hw) && hw->fw_state != CSIO_DEV_STATE_INIT) {\r\nspin_unlock_irq(&hw->lock);\r\nrv = csio_hw_flash_fw(hw, &reset);\r\nspin_lock_irq(&hw->lock);\r\nif (rv != 0)\r\ngoto out;\r\nrv = csio_hw_check_fwconfig(hw, param);\r\nif (rv != 0) {\r\ncsio_info(hw, "Firmware doesn't support "\r\n"Firmware Configuration files\n");\r\ngoto out;\r\n}\r\nrv = csio_hw_use_fwconfig(hw, reset, param);\r\nif (rv == -ENOENT) {\r\ncsio_info(hw, "Could not initialize "\r\n"adapter, error%d\n", rv);\r\ngoto out;\r\n}\r\nif (rv != 0) {\r\ncsio_info(hw, "Could not initialize "\r\n"adapter, error%d\n", rv);\r\ngoto out;\r\n}\r\n} else {\r\nif (hw->fw_state == CSIO_DEV_STATE_INIT) {\r\nhw->flags |= CSIO_HWF_USING_SOFT_PARAMS;\r\nrv = csio_get_device_params(hw);\r\nif (rv != 0)\r\ngoto out;\r\nrv = csio_config_device_caps(hw);\r\nif (rv != 0)\r\ngoto out;\r\ncsio_wr_sge_init(hw);\r\ncsio_post_event(&hw->sm, CSIO_HWE_INIT);\r\ngoto out;\r\n}\r\n}\r\nout:\r\nreturn;\r\n}\r\nstatic void\r\ncsio_hw_initialize(struct csio_hw *hw)\r\n{\r\nstruct csio_mb *mbp;\r\nenum fw_retval retval;\r\nint rv;\r\nint i;\r\nif (csio_is_hw_master(hw) && hw->fw_state != CSIO_DEV_STATE_INIT) {\r\nmbp = mempool_alloc(hw->mb_mempool, GFP_ATOMIC);\r\nif (!mbp)\r\ngoto out;\r\ncsio_mb_initialize(hw, mbp, CSIO_MB_DEFAULT_TMO, NULL);\r\nif (csio_mb_issue(hw, mbp)) {\r\ncsio_err(hw, "Issue of FW_INITIALIZE_CMD failed!\n");\r\ngoto free_and_out;\r\n}\r\nretval = csio_mb_fw_retval(mbp);\r\nif (retval != FW_SUCCESS) {\r\ncsio_err(hw, "FW_INITIALIZE_CMD returned 0x%x!\n",\r\nretval);\r\ngoto free_and_out;\r\n}\r\nmempool_free(mbp, hw->mb_mempool);\r\n}\r\nrv = csio_get_fcoe_resinfo(hw);\r\nif (rv != 0) {\r\ncsio_err(hw, "Failed to read fcoe resource info: %d\n", rv);\r\ngoto out;\r\n}\r\nspin_unlock_irq(&hw->lock);\r\nrv = csio_config_queues(hw);\r\nspin_lock_irq(&hw->lock);\r\nif (rv != 0) {\r\ncsio_err(hw, "Config of queues failed!: %d\n", rv);\r\ngoto out;\r\n}\r\nfor (i = 0; i < hw->num_pports; i++)\r\nhw->pport[i].mod_type = FW_PORT_MOD_TYPE_NA;\r\nif (csio_is_hw_master(hw) && hw->fw_state != CSIO_DEV_STATE_INIT) {\r\nrv = csio_enable_ports(hw);\r\nif (rv != 0) {\r\ncsio_err(hw, "Failed to enable ports: %d\n", rv);\r\ngoto out;\r\n}\r\n}\r\ncsio_post_event(&hw->sm, CSIO_HWE_INIT_DONE);\r\nreturn;\r\nfree_and_out:\r\nmempool_free(mbp, hw->mb_mempool);\r\nout:\r\nreturn;\r\n}\r\nstatic void\r\ncsio_hw_intr_enable(struct csio_hw *hw)\r\n{\r\nuint16_t vec = (uint16_t)csio_get_mb_intr_idx(csio_hw_to_mbm(hw));\r\nuint32_t pf = SOURCEPF_G(csio_rd_reg32(hw, PL_WHOAMI_A));\r\nuint32_t pl = csio_rd_reg32(hw, PL_INT_ENABLE_A);\r\nif (hw->intr_mode == CSIO_IM_MSIX)\r\ncsio_set_reg_field(hw, MYPF_REG(PCIE_PF_CFG_A),\r\nAIVEC_V(AIVEC_M), vec);\r\nelse if (hw->intr_mode == CSIO_IM_MSI)\r\ncsio_set_reg_field(hw, MYPF_REG(PCIE_PF_CFG_A),\r\nAIVEC_V(AIVEC_M), 0);\r\ncsio_wr_reg32(hw, PF_INTR_MASK, MYPF_REG(PL_PF_INT_ENABLE_A));\r\ncsio_mb_intr_enable(hw);\r\nif (csio_is_hw_master(hw)) {\r\npl &= (~SF_F);\r\ncsio_wr_reg32(hw, pl, PL_INT_ENABLE_A);\r\ncsio_wr_reg32(hw, ERR_CPL_EXCEED_IQE_SIZE_F |\r\nEGRESS_SIZE_ERR_F | ERR_INVALID_CIDX_INC_F |\r\nERR_CPL_OPCODE_0_F | ERR_DROPPED_DB_F |\r\nERR_DATA_CPL_ON_HIGH_QID1_F |\r\nERR_DATA_CPL_ON_HIGH_QID0_F | ERR_BAD_DB_PIDX3_F |\r\nERR_BAD_DB_PIDX2_F | ERR_BAD_DB_PIDX1_F |\r\nERR_BAD_DB_PIDX0_F | ERR_ING_CTXT_PRIO_F |\r\nERR_EGR_CTXT_PRIO_F | INGRESS_SIZE_ERR_F,\r\nSGE_INT_ENABLE3_A);\r\ncsio_set_reg_field(hw, PL_INT_MAP0_A, 0, 1 << pf);\r\n}\r\nhw->flags |= CSIO_HWF_HW_INTR_ENABLED;\r\n}\r\nvoid\r\ncsio_hw_intr_disable(struct csio_hw *hw)\r\n{\r\nuint32_t pf = SOURCEPF_G(csio_rd_reg32(hw, PL_WHOAMI_A));\r\nif (!(hw->flags & CSIO_HWF_HW_INTR_ENABLED))\r\nreturn;\r\nhw->flags &= ~CSIO_HWF_HW_INTR_ENABLED;\r\ncsio_wr_reg32(hw, 0, MYPF_REG(PL_PF_INT_ENABLE_A));\r\nif (csio_is_hw_master(hw))\r\ncsio_set_reg_field(hw, PL_INT_MAP0_A, 1 << pf, 0);\r\ncsio_mb_intr_disable(hw);\r\n}\r\nvoid\r\ncsio_hw_fatal_err(struct csio_hw *hw)\r\n{\r\ncsio_set_reg_field(hw, SGE_CONTROL_A, GLOBALENABLE_F, 0);\r\ncsio_hw_intr_disable(hw);\r\ncsio_fatal(hw, "HW Fatal error encountered!\n");\r\n}\r\nstatic void\r\ncsio_hws_uninit(struct csio_hw *hw, enum csio_hw_ev evt)\r\n{\r\nhw->prev_evt = hw->cur_evt;\r\nhw->cur_evt = evt;\r\nCSIO_INC_STATS(hw, n_evt_sm[evt]);\r\nswitch (evt) {\r\ncase CSIO_HWE_CFG:\r\ncsio_set_state(&hw->sm, csio_hws_configuring);\r\ncsio_hw_configure(hw);\r\nbreak;\r\ndefault:\r\nCSIO_INC_STATS(hw, n_evt_unexp);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\ncsio_hws_configuring(struct csio_hw *hw, enum csio_hw_ev evt)\r\n{\r\nhw->prev_evt = hw->cur_evt;\r\nhw->cur_evt = evt;\r\nCSIO_INC_STATS(hw, n_evt_sm[evt]);\r\nswitch (evt) {\r\ncase CSIO_HWE_INIT:\r\ncsio_set_state(&hw->sm, csio_hws_initializing);\r\ncsio_hw_initialize(hw);\r\nbreak;\r\ncase CSIO_HWE_INIT_DONE:\r\ncsio_set_state(&hw->sm, csio_hws_ready);\r\ncsio_notify_lnodes(hw, CSIO_LN_NOTIFY_HWREADY);\r\nbreak;\r\ncase CSIO_HWE_FATAL:\r\ncsio_set_state(&hw->sm, csio_hws_uninit);\r\nbreak;\r\ncase CSIO_HWE_PCI_REMOVE:\r\ncsio_do_bye(hw);\r\nbreak;\r\ndefault:\r\nCSIO_INC_STATS(hw, n_evt_unexp);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\ncsio_hws_initializing(struct csio_hw *hw, enum csio_hw_ev evt)\r\n{\r\nhw->prev_evt = hw->cur_evt;\r\nhw->cur_evt = evt;\r\nCSIO_INC_STATS(hw, n_evt_sm[evt]);\r\nswitch (evt) {\r\ncase CSIO_HWE_INIT_DONE:\r\ncsio_set_state(&hw->sm, csio_hws_ready);\r\ncsio_notify_lnodes(hw, CSIO_LN_NOTIFY_HWREADY);\r\ncsio_hw_intr_enable(hw);\r\nbreak;\r\ncase CSIO_HWE_FATAL:\r\ncsio_set_state(&hw->sm, csio_hws_uninit);\r\nbreak;\r\ncase CSIO_HWE_PCI_REMOVE:\r\ncsio_do_bye(hw);\r\nbreak;\r\ndefault:\r\nCSIO_INC_STATS(hw, n_evt_unexp);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\ncsio_hws_ready(struct csio_hw *hw, enum csio_hw_ev evt)\r\n{\r\nhw->evtflag = evt;\r\nhw->prev_evt = hw->cur_evt;\r\nhw->cur_evt = evt;\r\nCSIO_INC_STATS(hw, n_evt_sm[evt]);\r\nswitch (evt) {\r\ncase CSIO_HWE_HBA_RESET:\r\ncase CSIO_HWE_FW_DLOAD:\r\ncase CSIO_HWE_SUSPEND:\r\ncase CSIO_HWE_PCI_REMOVE:\r\ncase CSIO_HWE_PCIERR_DETECTED:\r\ncsio_set_state(&hw->sm, csio_hws_quiescing);\r\nif (evt == CSIO_HWE_HBA_RESET ||\r\nevt == CSIO_HWE_PCIERR_DETECTED)\r\ncsio_scsim_cleanup_io(csio_hw_to_scsim(hw), false);\r\nelse\r\ncsio_scsim_cleanup_io(csio_hw_to_scsim(hw), true);\r\ncsio_hw_intr_disable(hw);\r\ncsio_hw_mbm_cleanup(hw);\r\ncsio_evtq_stop(hw);\r\ncsio_notify_lnodes(hw, CSIO_LN_NOTIFY_HWSTOP);\r\ncsio_evtq_flush(hw);\r\ncsio_mgmtm_cleanup(csio_hw_to_mgmtm(hw));\r\ncsio_post_event(&hw->sm, CSIO_HWE_QUIESCED);\r\nbreak;\r\ncase CSIO_HWE_FATAL:\r\ncsio_set_state(&hw->sm, csio_hws_uninit);\r\nbreak;\r\ndefault:\r\nCSIO_INC_STATS(hw, n_evt_unexp);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\ncsio_hws_quiescing(struct csio_hw *hw, enum csio_hw_ev evt)\r\n{\r\nhw->prev_evt = hw->cur_evt;\r\nhw->cur_evt = evt;\r\nCSIO_INC_STATS(hw, n_evt_sm[evt]);\r\nswitch (evt) {\r\ncase CSIO_HWE_QUIESCED:\r\nswitch (hw->evtflag) {\r\ncase CSIO_HWE_FW_DLOAD:\r\ncsio_set_state(&hw->sm, csio_hws_resetting);\r\ncase CSIO_HWE_HBA_RESET:\r\ncsio_set_state(&hw->sm, csio_hws_resetting);\r\ncsio_notify_lnodes(hw, CSIO_LN_NOTIFY_HWRESET);\r\ncsio_wr_destroy_queues(hw, false);\r\ncsio_do_reset(hw, false);\r\ncsio_post_event(&hw->sm, CSIO_HWE_HBA_RESET_DONE);\r\nbreak;\r\ncase CSIO_HWE_PCI_REMOVE:\r\ncsio_set_state(&hw->sm, csio_hws_removing);\r\ncsio_notify_lnodes(hw, CSIO_LN_NOTIFY_HWREMOVE);\r\ncsio_wr_destroy_queues(hw, true);\r\ncsio_do_bye(hw);\r\nbreak;\r\ncase CSIO_HWE_SUSPEND:\r\ncsio_set_state(&hw->sm, csio_hws_quiesced);\r\nbreak;\r\ncase CSIO_HWE_PCIERR_DETECTED:\r\ncsio_set_state(&hw->sm, csio_hws_pcierr);\r\ncsio_wr_destroy_queues(hw, false);\r\nbreak;\r\ndefault:\r\nCSIO_INC_STATS(hw, n_evt_unexp);\r\nbreak;\r\n}\r\nbreak;\r\ndefault:\r\nCSIO_INC_STATS(hw, n_evt_unexp);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\ncsio_hws_quiesced(struct csio_hw *hw, enum csio_hw_ev evt)\r\n{\r\nhw->prev_evt = hw->cur_evt;\r\nhw->cur_evt = evt;\r\nCSIO_INC_STATS(hw, n_evt_sm[evt]);\r\nswitch (evt) {\r\ncase CSIO_HWE_RESUME:\r\ncsio_set_state(&hw->sm, csio_hws_configuring);\r\ncsio_hw_configure(hw);\r\nbreak;\r\ndefault:\r\nCSIO_INC_STATS(hw, n_evt_unexp);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\ncsio_hws_resetting(struct csio_hw *hw, enum csio_hw_ev evt)\r\n{\r\nhw->prev_evt = hw->cur_evt;\r\nhw->cur_evt = evt;\r\nCSIO_INC_STATS(hw, n_evt_sm[evt]);\r\nswitch (evt) {\r\ncase CSIO_HWE_HBA_RESET_DONE:\r\ncsio_evtq_start(hw);\r\ncsio_set_state(&hw->sm, csio_hws_configuring);\r\ncsio_hw_configure(hw);\r\nbreak;\r\ndefault:\r\nCSIO_INC_STATS(hw, n_evt_unexp);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\ncsio_hws_removing(struct csio_hw *hw, enum csio_hw_ev evt)\r\n{\r\nhw->prev_evt = hw->cur_evt;\r\nhw->cur_evt = evt;\r\nCSIO_INC_STATS(hw, n_evt_sm[evt]);\r\nswitch (evt) {\r\ncase CSIO_HWE_HBA_RESET:\r\nif (!csio_is_hw_master(hw))\r\nbreak;\r\ncsio_err(hw, "Resetting HW and waiting 2 seconds...\n");\r\ncsio_wr_reg32(hw, PIORSTMODE_F | PIORST_F, PL_RST_A);\r\nmdelay(2000);\r\nbreak;\r\ndefault:\r\nCSIO_INC_STATS(hw, n_evt_unexp);\r\nbreak;\r\n}\r\n}\r\nstatic void\r\ncsio_hws_pcierr(struct csio_hw *hw, enum csio_hw_ev evt)\r\n{\r\nhw->prev_evt = hw->cur_evt;\r\nhw->cur_evt = evt;\r\nCSIO_INC_STATS(hw, n_evt_sm[evt]);\r\nswitch (evt) {\r\ncase CSIO_HWE_PCIERR_SLOT_RESET:\r\ncsio_evtq_start(hw);\r\ncsio_set_state(&hw->sm, csio_hws_configuring);\r\ncsio_hw_configure(hw);\r\nbreak;\r\ndefault:\r\nCSIO_INC_STATS(hw, n_evt_unexp);\r\nbreak;\r\n}\r\n}\r\nint\r\ncsio_handle_intr_status(struct csio_hw *hw, unsigned int reg,\r\nconst struct intr_info *acts)\r\n{\r\nint fatal = 0;\r\nunsigned int mask = 0;\r\nunsigned int status = csio_rd_reg32(hw, reg);\r\nfor ( ; acts->mask; ++acts) {\r\nif (!(status & acts->mask))\r\ncontinue;\r\nif (acts->fatal) {\r\nfatal++;\r\ncsio_fatal(hw, "Fatal %s (0x%x)\n",\r\nacts->msg, status & acts->mask);\r\n} else if (acts->msg)\r\ncsio_info(hw, "%s (0x%x)\n",\r\nacts->msg, status & acts->mask);\r\nmask |= acts->mask;\r\n}\r\nstatus &= mask;\r\nif (status)\r\ncsio_wr_reg32(hw, status, reg);\r\nreturn fatal;\r\n}\r\nstatic void csio_tp_intr_handler(struct csio_hw *hw)\r\n{\r\nstatic struct intr_info tp_intr_info[] = {\r\n{ 0x3fffffff, "TP parity error", -1, 1 },\r\n{ FLMTXFLSTEMPTY_F, "TP out of Tx pages", -1, 1 },\r\n{ 0, NULL, 0, 0 }\r\n};\r\nif (csio_handle_intr_status(hw, TP_INT_CAUSE_A, tp_intr_info))\r\ncsio_hw_fatal_err(hw);\r\n}\r\nstatic void csio_sge_intr_handler(struct csio_hw *hw)\r\n{\r\nuint64_t v;\r\nstatic struct intr_info sge_intr_info[] = {\r\n{ ERR_CPL_EXCEED_IQE_SIZE_F,\r\n"SGE received CPL exceeding IQE size", -1, 1 },\r\n{ ERR_INVALID_CIDX_INC_F,\r\n"SGE GTS CIDX increment too large", -1, 0 },\r\n{ ERR_CPL_OPCODE_0_F, "SGE received 0-length CPL", -1, 0 },\r\n{ ERR_DROPPED_DB_F, "SGE doorbell dropped", -1, 0 },\r\n{ ERR_DATA_CPL_ON_HIGH_QID1_F | ERR_DATA_CPL_ON_HIGH_QID0_F,\r\n"SGE IQID > 1023 received CPL for FL", -1, 0 },\r\n{ ERR_BAD_DB_PIDX3_F, "SGE DBP 3 pidx increment too large", -1,\r\n0 },\r\n{ ERR_BAD_DB_PIDX2_F, "SGE DBP 2 pidx increment too large", -1,\r\n0 },\r\n{ ERR_BAD_DB_PIDX1_F, "SGE DBP 1 pidx increment too large", -1,\r\n0 },\r\n{ ERR_BAD_DB_PIDX0_F, "SGE DBP 0 pidx increment too large", -1,\r\n0 },\r\n{ ERR_ING_CTXT_PRIO_F,\r\n"SGE too many priority ingress contexts", -1, 0 },\r\n{ ERR_EGR_CTXT_PRIO_F,\r\n"SGE too many priority egress contexts", -1, 0 },\r\n{ INGRESS_SIZE_ERR_F, "SGE illegal ingress QID", -1, 0 },\r\n{ EGRESS_SIZE_ERR_F, "SGE illegal egress QID", -1, 0 },\r\n{ 0, NULL, 0, 0 }\r\n};\r\nv = (uint64_t)csio_rd_reg32(hw, SGE_INT_CAUSE1_A) |\r\n((uint64_t)csio_rd_reg32(hw, SGE_INT_CAUSE2_A) << 32);\r\nif (v) {\r\ncsio_fatal(hw, "SGE parity error (%#llx)\n",\r\n(unsigned long long)v);\r\ncsio_wr_reg32(hw, (uint32_t)(v & 0xFFFFFFFF),\r\nSGE_INT_CAUSE1_A);\r\ncsio_wr_reg32(hw, (uint32_t)(v >> 32), SGE_INT_CAUSE2_A);\r\n}\r\nv |= csio_handle_intr_status(hw, SGE_INT_CAUSE3_A, sge_intr_info);\r\nif (csio_handle_intr_status(hw, SGE_INT_CAUSE3_A, sge_intr_info) ||\r\nv != 0)\r\ncsio_hw_fatal_err(hw);\r\n}\r\nstatic void csio_cim_intr_handler(struct csio_hw *hw)\r\n{\r\nstatic struct intr_info cim_intr_info[] = {\r\n{ PREFDROPINT_F, "CIM control register prefetch drop", -1, 1 },\r\n{ CIM_OBQ_INTR, "CIM OBQ parity error", -1, 1 },\r\n{ CIM_IBQ_INTR, "CIM IBQ parity error", -1, 1 },\r\n{ MBUPPARERR_F, "CIM mailbox uP parity error", -1, 1 },\r\n{ MBHOSTPARERR_F, "CIM mailbox host parity error", -1, 1 },\r\n{ TIEQINPARERRINT_F, "CIM TIEQ outgoing parity error", -1, 1 },\r\n{ TIEQOUTPARERRINT_F, "CIM TIEQ incoming parity error", -1, 1 },\r\n{ 0, NULL, 0, 0 }\r\n};\r\nstatic struct intr_info cim_upintr_info[] = {\r\n{ RSVDSPACEINT_F, "CIM reserved space access", -1, 1 },\r\n{ ILLTRANSINT_F, "CIM illegal transaction", -1, 1 },\r\n{ ILLWRINT_F, "CIM illegal write", -1, 1 },\r\n{ ILLRDINT_F, "CIM illegal read", -1, 1 },\r\n{ ILLRDBEINT_F, "CIM illegal read BE", -1, 1 },\r\n{ ILLWRBEINT_F, "CIM illegal write BE", -1, 1 },\r\n{ SGLRDBOOTINT_F, "CIM single read from boot space", -1, 1 },\r\n{ SGLWRBOOTINT_F, "CIM single write to boot space", -1, 1 },\r\n{ BLKWRBOOTINT_F, "CIM block write to boot space", -1, 1 },\r\n{ SGLRDFLASHINT_F, "CIM single read from flash space", -1, 1 },\r\n{ SGLWRFLASHINT_F, "CIM single write to flash space", -1, 1 },\r\n{ BLKWRFLASHINT_F, "CIM block write to flash space", -1, 1 },\r\n{ SGLRDEEPROMINT_F, "CIM single EEPROM read", -1, 1 },\r\n{ SGLWREEPROMINT_F, "CIM single EEPROM write", -1, 1 },\r\n{ BLKRDEEPROMINT_F, "CIM block EEPROM read", -1, 1 },\r\n{ BLKWREEPROMINT_F, "CIM block EEPROM write", -1, 1 },\r\n{ SGLRDCTLINT_F, "CIM single read from CTL space", -1, 1 },\r\n{ SGLWRCTLINT_F, "CIM single write to CTL space", -1, 1 },\r\n{ BLKRDCTLINT_F, "CIM block read from CTL space", -1, 1 },\r\n{ BLKWRCTLINT_F, "CIM block write to CTL space", -1, 1 },\r\n{ SGLRDPLINT_F, "CIM single read from PL space", -1, 1 },\r\n{ SGLWRPLINT_F, "CIM single write to PL space", -1, 1 },\r\n{ BLKRDPLINT_F, "CIM block read from PL space", -1, 1 },\r\n{ BLKWRPLINT_F, "CIM block write to PL space", -1, 1 },\r\n{ REQOVRLOOKUPINT_F, "CIM request FIFO overwrite", -1, 1 },\r\n{ RSPOVRLOOKUPINT_F, "CIM response FIFO overwrite", -1, 1 },\r\n{ TIMEOUTINT_F, "CIM PIF timeout", -1, 1 },\r\n{ TIMEOUTMAINT_F, "CIM PIF MA timeout", -1, 1 },\r\n{ 0, NULL, 0, 0 }\r\n};\r\nint fat;\r\nfat = csio_handle_intr_status(hw, CIM_HOST_INT_CAUSE_A,\r\ncim_intr_info) +\r\ncsio_handle_intr_status(hw, CIM_HOST_UPACC_INT_CAUSE_A,\r\ncim_upintr_info);\r\nif (fat)\r\ncsio_hw_fatal_err(hw);\r\n}\r\nstatic void csio_ulprx_intr_handler(struct csio_hw *hw)\r\n{\r\nstatic struct intr_info ulprx_intr_info[] = {\r\n{ 0x1800000, "ULPRX context error", -1, 1 },\r\n{ 0x7fffff, "ULPRX parity error", -1, 1 },\r\n{ 0, NULL, 0, 0 }\r\n};\r\nif (csio_handle_intr_status(hw, ULP_RX_INT_CAUSE_A, ulprx_intr_info))\r\ncsio_hw_fatal_err(hw);\r\n}\r\nstatic void csio_ulptx_intr_handler(struct csio_hw *hw)\r\n{\r\nstatic struct intr_info ulptx_intr_info[] = {\r\n{ PBL_BOUND_ERR_CH3_F, "ULPTX channel 3 PBL out of bounds", -1,\r\n0 },\r\n{ PBL_BOUND_ERR_CH2_F, "ULPTX channel 2 PBL out of bounds", -1,\r\n0 },\r\n{ PBL_BOUND_ERR_CH1_F, "ULPTX channel 1 PBL out of bounds", -1,\r\n0 },\r\n{ PBL_BOUND_ERR_CH0_F, "ULPTX channel 0 PBL out of bounds", -1,\r\n0 },\r\n{ 0xfffffff, "ULPTX parity error", -1, 1 },\r\n{ 0, NULL, 0, 0 }\r\n};\r\nif (csio_handle_intr_status(hw, ULP_TX_INT_CAUSE_A, ulptx_intr_info))\r\ncsio_hw_fatal_err(hw);\r\n}\r\nstatic void csio_pmtx_intr_handler(struct csio_hw *hw)\r\n{\r\nstatic struct intr_info pmtx_intr_info[] = {\r\n{ PCMD_LEN_OVFL0_F, "PMTX channel 0 pcmd too large", -1, 1 },\r\n{ PCMD_LEN_OVFL1_F, "PMTX channel 1 pcmd too large", -1, 1 },\r\n{ PCMD_LEN_OVFL2_F, "PMTX channel 2 pcmd too large", -1, 1 },\r\n{ ZERO_C_CMD_ERROR_F, "PMTX 0-length pcmd", -1, 1 },\r\n{ 0xffffff0, "PMTX framing error", -1, 1 },\r\n{ OESPI_PAR_ERROR_F, "PMTX oespi parity error", -1, 1 },\r\n{ DB_OPTIONS_PAR_ERROR_F, "PMTX db_options parity error", -1,\r\n1 },\r\n{ ICSPI_PAR_ERROR_F, "PMTX icspi parity error", -1, 1 },\r\n{ PMTX_C_PCMD_PAR_ERROR_F, "PMTX c_pcmd parity error", -1, 1},\r\n{ 0, NULL, 0, 0 }\r\n};\r\nif (csio_handle_intr_status(hw, PM_TX_INT_CAUSE_A, pmtx_intr_info))\r\ncsio_hw_fatal_err(hw);\r\n}\r\nstatic void csio_pmrx_intr_handler(struct csio_hw *hw)\r\n{\r\nstatic struct intr_info pmrx_intr_info[] = {\r\n{ ZERO_E_CMD_ERROR_F, "PMRX 0-length pcmd", -1, 1 },\r\n{ 0x3ffff0, "PMRX framing error", -1, 1 },\r\n{ OCSPI_PAR_ERROR_F, "PMRX ocspi parity error", -1, 1 },\r\n{ DB_OPTIONS_PAR_ERROR_F, "PMRX db_options parity error", -1,\r\n1 },\r\n{ IESPI_PAR_ERROR_F, "PMRX iespi parity error", -1, 1 },\r\n{ PMRX_E_PCMD_PAR_ERROR_F, "PMRX e_pcmd parity error", -1, 1},\r\n{ 0, NULL, 0, 0 }\r\n};\r\nif (csio_handle_intr_status(hw, PM_RX_INT_CAUSE_A, pmrx_intr_info))\r\ncsio_hw_fatal_err(hw);\r\n}\r\nstatic void csio_cplsw_intr_handler(struct csio_hw *hw)\r\n{\r\nstatic struct intr_info cplsw_intr_info[] = {\r\n{ CIM_OP_MAP_PERR_F, "CPLSW CIM op_map parity error", -1, 1 },\r\n{ CIM_OVFL_ERROR_F, "CPLSW CIM overflow", -1, 1 },\r\n{ TP_FRAMING_ERROR_F, "CPLSW TP framing error", -1, 1 },\r\n{ SGE_FRAMING_ERROR_F, "CPLSW SGE framing error", -1, 1 },\r\n{ CIM_FRAMING_ERROR_F, "CPLSW CIM framing error", -1, 1 },\r\n{ ZERO_SWITCH_ERROR_F, "CPLSW no-switch error", -1, 1 },\r\n{ 0, NULL, 0, 0 }\r\n};\r\nif (csio_handle_intr_status(hw, CPL_INTR_CAUSE_A, cplsw_intr_info))\r\ncsio_hw_fatal_err(hw);\r\n}\r\nstatic void csio_le_intr_handler(struct csio_hw *hw)\r\n{\r\nstatic struct intr_info le_intr_info[] = {\r\n{ LIPMISS_F, "LE LIP miss", -1, 0 },\r\n{ LIP0_F, "LE 0 LIP error", -1, 0 },\r\n{ PARITYERR_F, "LE parity error", -1, 1 },\r\n{ UNKNOWNCMD_F, "LE unknown command", -1, 1 },\r\n{ REQQPARERR_F, "LE request queue parity error", -1, 1 },\r\n{ 0, NULL, 0, 0 }\r\n};\r\nif (csio_handle_intr_status(hw, LE_DB_INT_CAUSE_A, le_intr_info))\r\ncsio_hw_fatal_err(hw);\r\n}\r\nstatic void csio_mps_intr_handler(struct csio_hw *hw)\r\n{\r\nstatic struct intr_info mps_rx_intr_info[] = {\r\n{ 0xffffff, "MPS Rx parity error", -1, 1 },\r\n{ 0, NULL, 0, 0 }\r\n};\r\nstatic struct intr_info mps_tx_intr_info[] = {\r\n{ TPFIFO_V(TPFIFO_M), "MPS Tx TP FIFO parity error", -1, 1 },\r\n{ NCSIFIFO_F, "MPS Tx NC-SI FIFO parity error", -1, 1 },\r\n{ TXDATAFIFO_V(TXDATAFIFO_M), "MPS Tx data FIFO parity error",\r\n-1, 1 },\r\n{ TXDESCFIFO_V(TXDESCFIFO_M), "MPS Tx desc FIFO parity error",\r\n-1, 1 },\r\n{ BUBBLE_F, "MPS Tx underflow", -1, 1 },\r\n{ SECNTERR_F, "MPS Tx SOP/EOP error", -1, 1 },\r\n{ FRMERR_F, "MPS Tx framing error", -1, 1 },\r\n{ 0, NULL, 0, 0 }\r\n};\r\nstatic struct intr_info mps_trc_intr_info[] = {\r\n{ FILTMEM_V(FILTMEM_M), "MPS TRC filter parity error", -1, 1 },\r\n{ PKTFIFO_V(PKTFIFO_M), "MPS TRC packet FIFO parity error",\r\n-1, 1 },\r\n{ MISCPERR_F, "MPS TRC misc parity error", -1, 1 },\r\n{ 0, NULL, 0, 0 }\r\n};\r\nstatic struct intr_info mps_stat_sram_intr_info[] = {\r\n{ 0x1fffff, "MPS statistics SRAM parity error", -1, 1 },\r\n{ 0, NULL, 0, 0 }\r\n};\r\nstatic struct intr_info mps_stat_tx_intr_info[] = {\r\n{ 0xfffff, "MPS statistics Tx FIFO parity error", -1, 1 },\r\n{ 0, NULL, 0, 0 }\r\n};\r\nstatic struct intr_info mps_stat_rx_intr_info[] = {\r\n{ 0xffffff, "MPS statistics Rx FIFO parity error", -1, 1 },\r\n{ 0, NULL, 0, 0 }\r\n};\r\nstatic struct intr_info mps_cls_intr_info[] = {\r\n{ MATCHSRAM_F, "MPS match SRAM parity error", -1, 1 },\r\n{ MATCHTCAM_F, "MPS match TCAM parity error", -1, 1 },\r\n{ HASHSRAM_F, "MPS hash SRAM parity error", -1, 1 },\r\n{ 0, NULL, 0, 0 }\r\n};\r\nint fat;\r\nfat = csio_handle_intr_status(hw, MPS_RX_PERR_INT_CAUSE_A,\r\nmps_rx_intr_info) +\r\ncsio_handle_intr_status(hw, MPS_TX_INT_CAUSE_A,\r\nmps_tx_intr_info) +\r\ncsio_handle_intr_status(hw, MPS_TRC_INT_CAUSE_A,\r\nmps_trc_intr_info) +\r\ncsio_handle_intr_status(hw, MPS_STAT_PERR_INT_CAUSE_SRAM_A,\r\nmps_stat_sram_intr_info) +\r\ncsio_handle_intr_status(hw, MPS_STAT_PERR_INT_CAUSE_TX_FIFO_A,\r\nmps_stat_tx_intr_info) +\r\ncsio_handle_intr_status(hw, MPS_STAT_PERR_INT_CAUSE_RX_FIFO_A,\r\nmps_stat_rx_intr_info) +\r\ncsio_handle_intr_status(hw, MPS_CLS_INT_CAUSE_A,\r\nmps_cls_intr_info);\r\ncsio_wr_reg32(hw, 0, MPS_INT_CAUSE_A);\r\ncsio_rd_reg32(hw, MPS_INT_CAUSE_A);\r\nif (fat)\r\ncsio_hw_fatal_err(hw);\r\n}\r\nstatic void csio_mem_intr_handler(struct csio_hw *hw, int idx)\r\n{\r\nstatic const char name[3][5] = { "EDC0", "EDC1", "MC" };\r\nunsigned int addr, cnt_addr, v;\r\nif (idx <= MEM_EDC1) {\r\naddr = EDC_REG(EDC_INT_CAUSE_A, idx);\r\ncnt_addr = EDC_REG(EDC_ECC_STATUS_A, idx);\r\n} else {\r\naddr = MC_INT_CAUSE_A;\r\ncnt_addr = MC_ECC_STATUS_A;\r\n}\r\nv = csio_rd_reg32(hw, addr) & MEM_INT_MASK;\r\nif (v & PERR_INT_CAUSE_F)\r\ncsio_fatal(hw, "%s FIFO parity error\n", name[idx]);\r\nif (v & ECC_CE_INT_CAUSE_F) {\r\nuint32_t cnt = ECC_CECNT_G(csio_rd_reg32(hw, cnt_addr));\r\ncsio_wr_reg32(hw, ECC_CECNT_V(ECC_CECNT_M), cnt_addr);\r\ncsio_warn(hw, "%u %s correctable ECC data error%s\n",\r\ncnt, name[idx], cnt > 1 ? "s" : "");\r\n}\r\nif (v & ECC_UE_INT_CAUSE_F)\r\ncsio_fatal(hw, "%s uncorrectable ECC data error\n", name[idx]);\r\ncsio_wr_reg32(hw, v, addr);\r\nif (v & (PERR_INT_CAUSE_F | ECC_UE_INT_CAUSE_F))\r\ncsio_hw_fatal_err(hw);\r\n}\r\nstatic void csio_ma_intr_handler(struct csio_hw *hw)\r\n{\r\nuint32_t v, status = csio_rd_reg32(hw, MA_INT_CAUSE_A);\r\nif (status & MEM_PERR_INT_CAUSE_F)\r\ncsio_fatal(hw, "MA parity error, parity status %#x\n",\r\ncsio_rd_reg32(hw, MA_PARITY_ERROR_STATUS_A));\r\nif (status & MEM_WRAP_INT_CAUSE_F) {\r\nv = csio_rd_reg32(hw, MA_INT_WRAP_STATUS_A);\r\ncsio_fatal(hw,\r\n"MA address wrap-around error by client %u to address %#x\n",\r\nMEM_WRAP_CLIENT_NUM_G(v), MEM_WRAP_ADDRESS_G(v) << 4);\r\n}\r\ncsio_wr_reg32(hw, status, MA_INT_CAUSE_A);\r\ncsio_hw_fatal_err(hw);\r\n}\r\nstatic void csio_smb_intr_handler(struct csio_hw *hw)\r\n{\r\nstatic struct intr_info smb_intr_info[] = {\r\n{ MSTTXFIFOPARINT_F, "SMB master Tx FIFO parity error", -1, 1 },\r\n{ MSTRXFIFOPARINT_F, "SMB master Rx FIFO parity error", -1, 1 },\r\n{ SLVFIFOPARINT_F, "SMB slave FIFO parity error", -1, 1 },\r\n{ 0, NULL, 0, 0 }\r\n};\r\nif (csio_handle_intr_status(hw, SMB_INT_CAUSE_A, smb_intr_info))\r\ncsio_hw_fatal_err(hw);\r\n}\r\nstatic void csio_ncsi_intr_handler(struct csio_hw *hw)\r\n{\r\nstatic struct intr_info ncsi_intr_info[] = {\r\n{ CIM_DM_PRTY_ERR_F, "NC-SI CIM parity error", -1, 1 },\r\n{ MPS_DM_PRTY_ERR_F, "NC-SI MPS parity error", -1, 1 },\r\n{ TXFIFO_PRTY_ERR_F, "NC-SI Tx FIFO parity error", -1, 1 },\r\n{ RXFIFO_PRTY_ERR_F, "NC-SI Rx FIFO parity error", -1, 1 },\r\n{ 0, NULL, 0, 0 }\r\n};\r\nif (csio_handle_intr_status(hw, NCSI_INT_CAUSE_A, ncsi_intr_info))\r\ncsio_hw_fatal_err(hw);\r\n}\r\nstatic void csio_xgmac_intr_handler(struct csio_hw *hw, int port)\r\n{\r\nuint32_t v = csio_rd_reg32(hw, T5_PORT_REG(port, MAC_PORT_INT_CAUSE_A));\r\nv &= TXFIFO_PRTY_ERR_F | RXFIFO_PRTY_ERR_F;\r\nif (!v)\r\nreturn;\r\nif (v & TXFIFO_PRTY_ERR_F)\r\ncsio_fatal(hw, "XGMAC %d Tx FIFO parity error\n", port);\r\nif (v & RXFIFO_PRTY_ERR_F)\r\ncsio_fatal(hw, "XGMAC %d Rx FIFO parity error\n", port);\r\ncsio_wr_reg32(hw, v, T5_PORT_REG(port, MAC_PORT_INT_CAUSE_A));\r\ncsio_hw_fatal_err(hw);\r\n}\r\nstatic void csio_pl_intr_handler(struct csio_hw *hw)\r\n{\r\nstatic struct intr_info pl_intr_info[] = {\r\n{ FATALPERR_F, "T4 fatal parity error", -1, 1 },\r\n{ PERRVFID_F, "PL VFID_MAP parity error", -1, 1 },\r\n{ 0, NULL, 0, 0 }\r\n};\r\nif (csio_handle_intr_status(hw, PL_PL_INT_CAUSE_A, pl_intr_info))\r\ncsio_hw_fatal_err(hw);\r\n}\r\nint\r\ncsio_hw_slow_intr_handler(struct csio_hw *hw)\r\n{\r\nuint32_t cause = csio_rd_reg32(hw, PL_INT_CAUSE_A);\r\nif (!(cause & CSIO_GLBL_INTR_MASK)) {\r\nCSIO_INC_STATS(hw, n_plint_unexp);\r\nreturn 0;\r\n}\r\ncsio_dbg(hw, "Slow interrupt! cause: 0x%x\n", cause);\r\nCSIO_INC_STATS(hw, n_plint_cnt);\r\nif (cause & CIM_F)\r\ncsio_cim_intr_handler(hw);\r\nif (cause & MPS_F)\r\ncsio_mps_intr_handler(hw);\r\nif (cause & NCSI_F)\r\ncsio_ncsi_intr_handler(hw);\r\nif (cause & PL_F)\r\ncsio_pl_intr_handler(hw);\r\nif (cause & SMB_F)\r\ncsio_smb_intr_handler(hw);\r\nif (cause & XGMAC0_F)\r\ncsio_xgmac_intr_handler(hw, 0);\r\nif (cause & XGMAC1_F)\r\ncsio_xgmac_intr_handler(hw, 1);\r\nif (cause & XGMAC_KR0_F)\r\ncsio_xgmac_intr_handler(hw, 2);\r\nif (cause & XGMAC_KR1_F)\r\ncsio_xgmac_intr_handler(hw, 3);\r\nif (cause & PCIE_F)\r\nhw->chip_ops->chip_pcie_intr_handler(hw);\r\nif (cause & MC_F)\r\ncsio_mem_intr_handler(hw, MEM_MC);\r\nif (cause & EDC0_F)\r\ncsio_mem_intr_handler(hw, MEM_EDC0);\r\nif (cause & EDC1_F)\r\ncsio_mem_intr_handler(hw, MEM_EDC1);\r\nif (cause & LE_F)\r\ncsio_le_intr_handler(hw);\r\nif (cause & TP_F)\r\ncsio_tp_intr_handler(hw);\r\nif (cause & MA_F)\r\ncsio_ma_intr_handler(hw);\r\nif (cause & PM_TX_F)\r\ncsio_pmtx_intr_handler(hw);\r\nif (cause & PM_RX_F)\r\ncsio_pmrx_intr_handler(hw);\r\nif (cause & ULP_RX_F)\r\ncsio_ulprx_intr_handler(hw);\r\nif (cause & CPL_SWITCH_F)\r\ncsio_cplsw_intr_handler(hw);\r\nif (cause & SGE_F)\r\ncsio_sge_intr_handler(hw);\r\nif (cause & ULP_TX_F)\r\ncsio_ulptx_intr_handler(hw);\r\ncsio_wr_reg32(hw, cause & CSIO_GLBL_INTR_MASK, PL_INT_CAUSE_A);\r\ncsio_rd_reg32(hw, PL_INT_CAUSE_A);\r\nreturn 1;\r\n}\r\nstatic void\r\ncsio_mberr_worker(void *data)\r\n{\r\nstruct csio_hw *hw = (struct csio_hw *)data;\r\nstruct csio_mbm *mbm = &hw->mbm;\r\nLIST_HEAD(cbfn_q);\r\nstruct csio_mb *mbp_next;\r\nint rv;\r\ndel_timer_sync(&mbm->timer);\r\nspin_lock_irq(&hw->lock);\r\nif (list_empty(&mbm->cbfn_q)) {\r\nspin_unlock_irq(&hw->lock);\r\nreturn;\r\n}\r\nlist_splice_tail_init(&mbm->cbfn_q, &cbfn_q);\r\nmbm->stats.n_cbfnq = 0;\r\nif (!list_empty(&mbm->req_q)) {\r\nmbp_next = list_first_entry(&mbm->req_q, struct csio_mb, list);\r\nlist_del_init(&mbp_next->list);\r\nrv = csio_mb_issue(hw, mbp_next);\r\nif (rv != 0)\r\nlist_add_tail(&mbp_next->list, &mbm->req_q);\r\nelse\r\nCSIO_DEC_STATS(mbm, n_activeq);\r\n}\r\nspin_unlock_irq(&hw->lock);\r\ncsio_mb_completions(hw, &cbfn_q);\r\n}\r\nstatic void\r\ncsio_hw_mb_timer(uintptr_t data)\r\n{\r\nstruct csio_hw *hw = (struct csio_hw *)data;\r\nstruct csio_mb *mbp = NULL;\r\nspin_lock_irq(&hw->lock);\r\nmbp = csio_mb_tmo_handler(hw);\r\nspin_unlock_irq(&hw->lock);\r\nif (mbp)\r\nmbp->mb_cbfn(hw, mbp);\r\n}\r\nstatic void\r\ncsio_hw_mbm_cleanup(struct csio_hw *hw)\r\n{\r\nLIST_HEAD(cbfn_q);\r\ncsio_mb_cancel_all(hw, &cbfn_q);\r\nspin_unlock_irq(&hw->lock);\r\ncsio_mb_completions(hw, &cbfn_q);\r\nspin_lock_irq(&hw->lock);\r\n}\r\nint\r\ncsio_enqueue_evt(struct csio_hw *hw, enum csio_evt type, void *evt_msg,\r\nuint16_t len)\r\n{\r\nstruct csio_evt_msg *evt_entry = NULL;\r\nif (type >= CSIO_EVT_MAX)\r\nreturn -EINVAL;\r\nif (len > CSIO_EVT_MSG_SIZE)\r\nreturn -EINVAL;\r\nif (hw->flags & CSIO_HWF_FWEVT_STOP)\r\nreturn -EINVAL;\r\nif (list_empty(&hw->evt_free_q)) {\r\ncsio_err(hw, "Failed to alloc evt entry, msg type %d len %d\n",\r\ntype, len);\r\nreturn -ENOMEM;\r\n}\r\nevt_entry = list_first_entry(&hw->evt_free_q,\r\nstruct csio_evt_msg, list);\r\nlist_del_init(&evt_entry->list);\r\nevt_entry->type = type;\r\nmemcpy((void *)evt_entry->data, evt_msg, len);\r\nlist_add_tail(&evt_entry->list, &hw->evt_active_q);\r\nCSIO_DEC_STATS(hw, n_evt_freeq);\r\nCSIO_INC_STATS(hw, n_evt_activeq);\r\nreturn 0;\r\n}\r\nstatic int\r\ncsio_enqueue_evt_lock(struct csio_hw *hw, enum csio_evt type, void *evt_msg,\r\nuint16_t len, bool msg_sg)\r\n{\r\nstruct csio_evt_msg *evt_entry = NULL;\r\nstruct csio_fl_dma_buf *fl_sg;\r\nuint32_t off = 0;\r\nunsigned long flags;\r\nint n, ret = 0;\r\nif (type >= CSIO_EVT_MAX)\r\nreturn -EINVAL;\r\nif (len > CSIO_EVT_MSG_SIZE)\r\nreturn -EINVAL;\r\nspin_lock_irqsave(&hw->lock, flags);\r\nif (hw->flags & CSIO_HWF_FWEVT_STOP) {\r\nret = -EINVAL;\r\ngoto out;\r\n}\r\nif (list_empty(&hw->evt_free_q)) {\r\ncsio_err(hw, "Failed to alloc evt entry, msg type %d len %d\n",\r\ntype, len);\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\nevt_entry = list_first_entry(&hw->evt_free_q,\r\nstruct csio_evt_msg, list);\r\nlist_del_init(&evt_entry->list);\r\nevt_entry->type = type;\r\nif (msg_sg) {\r\nfl_sg = (struct csio_fl_dma_buf *) evt_msg;\r\nfor (n = 0; (n < CSIO_MAX_FLBUF_PER_IQWR && off < len); n++) {\r\nmemcpy((void *)((uintptr_t)evt_entry->data + off),\r\nfl_sg->flbufs[n].vaddr,\r\nfl_sg->flbufs[n].len);\r\noff += fl_sg->flbufs[n].len;\r\n}\r\n} else\r\nmemcpy((void *)evt_entry->data, evt_msg, len);\r\nlist_add_tail(&evt_entry->list, &hw->evt_active_q);\r\nCSIO_DEC_STATS(hw, n_evt_freeq);\r\nCSIO_INC_STATS(hw, n_evt_activeq);\r\nout:\r\nspin_unlock_irqrestore(&hw->lock, flags);\r\nreturn ret;\r\n}\r\nstatic void\r\ncsio_free_evt(struct csio_hw *hw, struct csio_evt_msg *evt_entry)\r\n{\r\nif (evt_entry) {\r\nspin_lock_irq(&hw->lock);\r\nlist_del_init(&evt_entry->list);\r\nlist_add_tail(&evt_entry->list, &hw->evt_free_q);\r\nCSIO_DEC_STATS(hw, n_evt_activeq);\r\nCSIO_INC_STATS(hw, n_evt_freeq);\r\nspin_unlock_irq(&hw->lock);\r\n}\r\n}\r\nvoid\r\ncsio_evtq_flush(struct csio_hw *hw)\r\n{\r\nuint32_t count;\r\ncount = 30;\r\nwhile (hw->flags & CSIO_HWF_FWEVT_PENDING && count--) {\r\nspin_unlock_irq(&hw->lock);\r\nmsleep(2000);\r\nspin_lock_irq(&hw->lock);\r\n}\r\nCSIO_DB_ASSERT(!(hw->flags & CSIO_HWF_FWEVT_PENDING));\r\n}\r\nstatic void\r\ncsio_evtq_stop(struct csio_hw *hw)\r\n{\r\nhw->flags |= CSIO_HWF_FWEVT_STOP;\r\n}\r\nstatic void\r\ncsio_evtq_start(struct csio_hw *hw)\r\n{\r\nhw->flags &= ~CSIO_HWF_FWEVT_STOP;\r\n}\r\nstatic void\r\ncsio_evtq_cleanup(struct csio_hw *hw)\r\n{\r\nstruct list_head *evt_entry, *next_entry;\r\nif (!list_empty(&hw->evt_active_q))\r\nlist_splice_tail_init(&hw->evt_active_q, &hw->evt_free_q);\r\nhw->stats.n_evt_activeq = 0;\r\nhw->flags &= ~CSIO_HWF_FWEVT_PENDING;\r\nlist_for_each_safe(evt_entry, next_entry, &hw->evt_free_q) {\r\nkfree(evt_entry);\r\nCSIO_DEC_STATS(hw, n_evt_freeq);\r\n}\r\nhw->stats.n_evt_freeq = 0;\r\n}\r\nstatic void\r\ncsio_process_fwevtq_entry(struct csio_hw *hw, void *wr, uint32_t len,\r\nstruct csio_fl_dma_buf *flb, void *priv)\r\n{\r\n__u8 op;\r\nvoid *msg = NULL;\r\nuint32_t msg_len = 0;\r\nbool msg_sg = 0;\r\nop = ((struct rss_header *) wr)->opcode;\r\nif (op == CPL_FW6_PLD) {\r\nCSIO_INC_STATS(hw, n_cpl_fw6_pld);\r\nif (!flb || !flb->totlen) {\r\nCSIO_INC_STATS(hw, n_cpl_unexp);\r\nreturn;\r\n}\r\nmsg = (void *) flb;\r\nmsg_len = flb->totlen;\r\nmsg_sg = 1;\r\n} else if (op == CPL_FW6_MSG || op == CPL_FW4_MSG) {\r\nCSIO_INC_STATS(hw, n_cpl_fw6_msg);\r\nmsg = (void *)((uintptr_t)wr + sizeof(__be64));\r\nmsg_len = (op == CPL_FW6_MSG) ? sizeof(struct cpl_fw6_msg) :\r\nsizeof(struct cpl_fw4_msg);\r\n} else {\r\ncsio_warn(hw, "unexpected CPL %#x on FW event queue\n", op);\r\nCSIO_INC_STATS(hw, n_cpl_unexp);\r\nreturn;\r\n}\r\nif (csio_enqueue_evt_lock(hw, CSIO_EVT_FW, msg,\r\n(uint16_t)msg_len, msg_sg))\r\nCSIO_INC_STATS(hw, n_evt_drop);\r\n}\r\nvoid\r\ncsio_evtq_worker(struct work_struct *work)\r\n{\r\nstruct csio_hw *hw = container_of(work, struct csio_hw, evtq_work);\r\nstruct list_head *evt_entry, *next_entry;\r\nLIST_HEAD(evt_q);\r\nstruct csio_evt_msg *evt_msg;\r\nstruct cpl_fw6_msg *msg;\r\nstruct csio_rnode *rn;\r\nint rv = 0;\r\nuint8_t evtq_stop = 0;\r\ncsio_dbg(hw, "event worker thread active evts#%d\n",\r\nhw->stats.n_evt_activeq);\r\nspin_lock_irq(&hw->lock);\r\nwhile (!list_empty(&hw->evt_active_q)) {\r\nlist_splice_tail_init(&hw->evt_active_q, &evt_q);\r\nspin_unlock_irq(&hw->lock);\r\nlist_for_each_safe(evt_entry, next_entry, &evt_q) {\r\nevt_msg = (struct csio_evt_msg *) evt_entry;\r\nspin_lock_irq(&hw->lock);\r\nif (hw->flags & CSIO_HWF_FWEVT_STOP)\r\nevtq_stop = 1;\r\nspin_unlock_irq(&hw->lock);\r\nif (evtq_stop) {\r\nCSIO_INC_STATS(hw, n_evt_drop);\r\ngoto free_evt;\r\n}\r\nswitch (evt_msg->type) {\r\ncase CSIO_EVT_FW:\r\nmsg = (struct cpl_fw6_msg *)(evt_msg->data);\r\nif ((msg->opcode == CPL_FW6_MSG ||\r\nmsg->opcode == CPL_FW4_MSG) &&\r\n!msg->type) {\r\nrv = csio_mb_fwevt_handler(hw,\r\nmsg->data);\r\nif (!rv)\r\nbreak;\r\ncsio_fcoe_fwevt_handler(hw,\r\nmsg->opcode, msg->data);\r\n} else if (msg->opcode == CPL_FW6_PLD) {\r\ncsio_fcoe_fwevt_handler(hw,\r\nmsg->opcode, msg->data);\r\n} else {\r\ncsio_warn(hw,\r\n"Unhandled FW msg op %x type %x\n",\r\nmsg->opcode, msg->type);\r\nCSIO_INC_STATS(hw, n_evt_drop);\r\n}\r\nbreak;\r\ncase CSIO_EVT_MBX:\r\ncsio_mberr_worker(hw);\r\nbreak;\r\ncase CSIO_EVT_DEV_LOSS:\r\nmemcpy(&rn, evt_msg->data, sizeof(rn));\r\ncsio_rnode_devloss_handler(rn);\r\nbreak;\r\ndefault:\r\ncsio_warn(hw, "Unhandled event %x on evtq\n",\r\nevt_msg->type);\r\nCSIO_INC_STATS(hw, n_evt_unexp);\r\nbreak;\r\n}\r\nfree_evt:\r\ncsio_free_evt(hw, evt_msg);\r\n}\r\nspin_lock_irq(&hw->lock);\r\n}\r\nhw->flags &= ~CSIO_HWF_FWEVT_PENDING;\r\nspin_unlock_irq(&hw->lock);\r\n}\r\nint\r\ncsio_fwevtq_handler(struct csio_hw *hw)\r\n{\r\nint rv;\r\nif (csio_q_iqid(hw, hw->fwevt_iq_idx) == CSIO_MAX_QID) {\r\nCSIO_INC_STATS(hw, n_int_stray);\r\nreturn -EINVAL;\r\n}\r\nrv = csio_wr_process_iq_idx(hw, hw->fwevt_iq_idx,\r\ncsio_process_fwevtq_entry, NULL);\r\nreturn rv;\r\n}\r\nint\r\ncsio_mgmt_req_lookup(struct csio_mgmtm *mgmtm, struct csio_ioreq *io_req)\r\n{\r\nstruct list_head *tmp;\r\nlist_for_each(tmp, &mgmtm->active_q) {\r\nif (io_req == (struct csio_ioreq *)tmp)\r\nreturn 0;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic void\r\ncsio_mgmt_tmo_handler(uintptr_t data)\r\n{\r\nstruct csio_mgmtm *mgmtm = (struct csio_mgmtm *) data;\r\nstruct list_head *tmp;\r\nstruct csio_ioreq *io_req;\r\ncsio_dbg(mgmtm->hw, "Mgmt timer invoked!\n");\r\nspin_lock_irq(&mgmtm->hw->lock);\r\nlist_for_each(tmp, &mgmtm->active_q) {\r\nio_req = (struct csio_ioreq *) tmp;\r\nio_req->tmo -= min_t(uint32_t, io_req->tmo, ECM_MIN_TMO);\r\nif (!io_req->tmo) {\r\ntmp = csio_list_prev(tmp);\r\nlist_del_init(&io_req->sm.sm_list);\r\nif (io_req->io_cbfn) {\r\nio_req->wr_status = -ETIMEDOUT;\r\nio_req->io_cbfn(mgmtm->hw, io_req);\r\n} else {\r\nCSIO_DB_ASSERT(0);\r\n}\r\n}\r\n}\r\nif (!list_empty(&mgmtm->active_q))\r\nmod_timer(&mgmtm->mgmt_timer,\r\njiffies + msecs_to_jiffies(ECM_MIN_TMO));\r\nspin_unlock_irq(&mgmtm->hw->lock);\r\n}\r\nstatic void\r\ncsio_mgmtm_cleanup(struct csio_mgmtm *mgmtm)\r\n{\r\nstruct csio_hw *hw = mgmtm->hw;\r\nstruct csio_ioreq *io_req;\r\nstruct list_head *tmp;\r\nuint32_t count;\r\ncount = 30;\r\nwhile ((!list_empty(&mgmtm->active_q)) && count--) {\r\nspin_unlock_irq(&hw->lock);\r\nmsleep(2000);\r\nspin_lock_irq(&hw->lock);\r\n}\r\nlist_for_each(tmp, &mgmtm->active_q) {\r\nio_req = (struct csio_ioreq *) tmp;\r\ntmp = csio_list_prev(tmp);\r\nlist_del_init(&io_req->sm.sm_list);\r\nmgmtm->stats.n_active--;\r\nif (io_req->io_cbfn) {\r\nio_req->wr_status = -ETIMEDOUT;\r\nio_req->io_cbfn(mgmtm->hw, io_req);\r\n}\r\n}\r\n}\r\nstatic int\r\ncsio_mgmtm_init(struct csio_mgmtm *mgmtm, struct csio_hw *hw)\r\n{\r\nstruct timer_list *timer = &mgmtm->mgmt_timer;\r\ninit_timer(timer);\r\ntimer->function = csio_mgmt_tmo_handler;\r\ntimer->data = (unsigned long)mgmtm;\r\nINIT_LIST_HEAD(&mgmtm->active_q);\r\nINIT_LIST_HEAD(&mgmtm->cbfn_q);\r\nmgmtm->hw = hw;\r\nreturn 0;\r\n}\r\nstatic void\r\ncsio_mgmtm_exit(struct csio_mgmtm *mgmtm)\r\n{\r\ndel_timer_sync(&mgmtm->mgmt_timer);\r\n}\r\nint\r\ncsio_hw_start(struct csio_hw *hw)\r\n{\r\nspin_lock_irq(&hw->lock);\r\ncsio_post_event(&hw->sm, CSIO_HWE_CFG);\r\nspin_unlock_irq(&hw->lock);\r\nif (csio_is_hw_ready(hw))\r\nreturn 0;\r\nelse\r\nreturn -EINVAL;\r\n}\r\nint\r\ncsio_hw_stop(struct csio_hw *hw)\r\n{\r\ncsio_post_event(&hw->sm, CSIO_HWE_PCI_REMOVE);\r\nif (csio_is_hw_removing(hw))\r\nreturn 0;\r\nelse\r\nreturn -EINVAL;\r\n}\r\nint\r\ncsio_hw_reset(struct csio_hw *hw)\r\n{\r\nif (!csio_is_hw_master(hw))\r\nreturn -EPERM;\r\nif (hw->rst_retries >= CSIO_MAX_RESET_RETRIES) {\r\ncsio_dbg(hw, "Max hw reset attempts reached..");\r\nreturn -EINVAL;\r\n}\r\nhw->rst_retries++;\r\ncsio_post_event(&hw->sm, CSIO_HWE_HBA_RESET);\r\nif (csio_is_hw_ready(hw)) {\r\nhw->rst_retries = 0;\r\nhw->stats.n_reset_start = jiffies_to_msecs(jiffies);\r\nreturn 0;\r\n} else\r\nreturn -EINVAL;\r\n}\r\nstatic void\r\ncsio_hw_get_device_id(struct csio_hw *hw)\r\n{\r\nif (csio_is_dev_id_cached(hw))\r\nreturn;\r\npci_read_config_word(hw->pdev, PCI_VENDOR_ID,\r\n&hw->params.pci.vendor_id);\r\npci_read_config_word(hw->pdev, PCI_DEVICE_ID,\r\n&hw->params.pci.device_id);\r\ncsio_dev_id_cached(hw);\r\nhw->chip_id = (hw->params.pci.device_id & CSIO_HW_CHIP_MASK);\r\n}\r\nstatic void\r\ncsio_hw_set_description(struct csio_hw *hw, uint16_t ven_id, uint16_t dev_id)\r\n{\r\nuint32_t adap_type, prot_type;\r\nif (ven_id == CSIO_VENDOR_ID) {\r\nprot_type = (dev_id & CSIO_ASIC_DEVID_PROTO_MASK);\r\nadap_type = (dev_id & CSIO_ASIC_DEVID_TYPE_MASK);\r\nif (prot_type == CSIO_T5_FCOE_ASIC) {\r\nmemcpy(hw->hw_ver,\r\ncsio_t5_fcoe_adapters[adap_type].model_no, 16);\r\nmemcpy(hw->model_desc,\r\ncsio_t5_fcoe_adapters[adap_type].description,\r\n32);\r\n} else {\r\nchar tempName[32] = "Chelsio FCoE Controller";\r\nmemcpy(hw->model_desc, tempName, 32);\r\n}\r\n}\r\n}\r\nint\r\ncsio_hw_init(struct csio_hw *hw)\r\n{\r\nint rv = -EINVAL;\r\nuint32_t i;\r\nuint16_t ven_id, dev_id;\r\nstruct csio_evt_msg *evt_entry;\r\nINIT_LIST_HEAD(&hw->sm.sm_list);\r\ncsio_init_state(&hw->sm, csio_hws_uninit);\r\nspin_lock_init(&hw->lock);\r\nINIT_LIST_HEAD(&hw->sln_head);\r\ncsio_hw_get_device_id(hw);\r\nstrcpy(hw->name, CSIO_HW_NAME);\r\nhw->chip_ops = &t5_ops;\r\nven_id = hw->params.pci.vendor_id;\r\ndev_id = hw->params.pci.device_id;\r\ncsio_hw_set_description(hw, ven_id, dev_id);\r\nhw->params.log_level = (uint32_t) csio_dbg_level;\r\ncsio_set_fwevt_intr_idx(hw, -1);\r\ncsio_set_nondata_intr_idx(hw, -1);\r\nif (csio_mbm_init(csio_hw_to_mbm(hw), hw, csio_hw_mb_timer))\r\ngoto err;\r\nrv = csio_wrm_init(csio_hw_to_wrm(hw), hw);\r\nif (rv)\r\ngoto err_mbm_exit;\r\nrv = csio_scsim_init(csio_hw_to_scsim(hw), hw);\r\nif (rv)\r\ngoto err_wrm_exit;\r\nrv = csio_mgmtm_init(csio_hw_to_mgmtm(hw), hw);\r\nif (rv)\r\ngoto err_scsim_exit;\r\nINIT_LIST_HEAD(&hw->evt_active_q);\r\nINIT_LIST_HEAD(&hw->evt_free_q);\r\nfor (i = 0; i < csio_evtq_sz; i++) {\r\nevt_entry = kzalloc(sizeof(struct csio_evt_msg), GFP_KERNEL);\r\nif (!evt_entry) {\r\ncsio_err(hw, "Failed to initialize eventq");\r\ngoto err_evtq_cleanup;\r\n}\r\nlist_add_tail(&evt_entry->list, &hw->evt_free_q);\r\nCSIO_INC_STATS(hw, n_evt_freeq);\r\n}\r\nhw->dev_num = dev_num;\r\ndev_num++;\r\nreturn 0;\r\nerr_evtq_cleanup:\r\ncsio_evtq_cleanup(hw);\r\ncsio_mgmtm_exit(csio_hw_to_mgmtm(hw));\r\nerr_scsim_exit:\r\ncsio_scsim_exit(csio_hw_to_scsim(hw));\r\nerr_wrm_exit:\r\ncsio_wrm_exit(csio_hw_to_wrm(hw), hw);\r\nerr_mbm_exit:\r\ncsio_mbm_exit(csio_hw_to_mbm(hw));\r\nerr:\r\nreturn rv;\r\n}\r\nvoid\r\ncsio_hw_exit(struct csio_hw *hw)\r\n{\r\ncsio_evtq_cleanup(hw);\r\ncsio_mgmtm_exit(csio_hw_to_mgmtm(hw));\r\ncsio_scsim_exit(csio_hw_to_scsim(hw));\r\ncsio_wrm_exit(csio_hw_to_wrm(hw), hw);\r\ncsio_mbm_exit(csio_hw_to_mbm(hw));\r\n}
