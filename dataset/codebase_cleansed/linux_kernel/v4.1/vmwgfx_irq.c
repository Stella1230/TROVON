irqreturn_t vmw_irq_handler(int irq, void *arg)\r\n{\r\nstruct drm_device *dev = (struct drm_device *)arg;\r\nstruct vmw_private *dev_priv = vmw_priv(dev);\r\nuint32_t status, masked_status;\r\nspin_lock(&dev_priv->irq_lock);\r\nstatus = inl(dev_priv->io_start + VMWGFX_IRQSTATUS_PORT);\r\nmasked_status = status & dev_priv->irq_mask;\r\nspin_unlock(&dev_priv->irq_lock);\r\nif (likely(status))\r\noutl(status, dev_priv->io_start + VMWGFX_IRQSTATUS_PORT);\r\nif (!masked_status)\r\nreturn IRQ_NONE;\r\nif (masked_status & (SVGA_IRQFLAG_ANY_FENCE |\r\nSVGA_IRQFLAG_FENCE_GOAL)) {\r\nvmw_fences_update(dev_priv->fman);\r\nwake_up_all(&dev_priv->fence_queue);\r\n}\r\nif (masked_status & SVGA_IRQFLAG_FIFO_PROGRESS)\r\nwake_up_all(&dev_priv->fifo_queue);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic bool vmw_fifo_idle(struct vmw_private *dev_priv, uint32_t seqno)\r\n{\r\nreturn (vmw_read(dev_priv, SVGA_REG_BUSY) == 0);\r\n}\r\nvoid vmw_update_seqno(struct vmw_private *dev_priv,\r\nstruct vmw_fifo_state *fifo_state)\r\n{\r\n__le32 __iomem *fifo_mem = dev_priv->mmio_virt;\r\nuint32_t seqno = ioread32(fifo_mem + SVGA_FIFO_FENCE);\r\nif (dev_priv->last_read_seqno != seqno) {\r\ndev_priv->last_read_seqno = seqno;\r\nvmw_marker_pull(&fifo_state->marker_queue, seqno);\r\nvmw_fences_update(dev_priv->fman);\r\n}\r\n}\r\nbool vmw_seqno_passed(struct vmw_private *dev_priv,\r\nuint32_t seqno)\r\n{\r\nstruct vmw_fifo_state *fifo_state;\r\nbool ret;\r\nif (likely(dev_priv->last_read_seqno - seqno < VMW_FENCE_WRAP))\r\nreturn true;\r\nfifo_state = &dev_priv->fifo;\r\nvmw_update_seqno(dev_priv, fifo_state);\r\nif (likely(dev_priv->last_read_seqno - seqno < VMW_FENCE_WRAP))\r\nreturn true;\r\nif (!(fifo_state->capabilities & SVGA_FIFO_CAP_FENCE) &&\r\nvmw_fifo_idle(dev_priv, seqno))\r\nreturn true;\r\nret = ((atomic_read(&dev_priv->marker_seq) - seqno)\r\n> VMW_FENCE_WRAP);\r\nreturn ret;\r\n}\r\nint vmw_fallback_wait(struct vmw_private *dev_priv,\r\nbool lazy,\r\nbool fifo_idle,\r\nuint32_t seqno,\r\nbool interruptible,\r\nunsigned long timeout)\r\n{\r\nstruct vmw_fifo_state *fifo_state = &dev_priv->fifo;\r\nuint32_t count = 0;\r\nuint32_t signal_seq;\r\nint ret;\r\nunsigned long end_jiffies = jiffies + timeout;\r\nbool (*wait_condition)(struct vmw_private *, uint32_t);\r\nDEFINE_WAIT(__wait);\r\nwait_condition = (fifo_idle) ? &vmw_fifo_idle :\r\n&vmw_seqno_passed;\r\nif (fifo_idle)\r\ndown_read(&fifo_state->rwsem);\r\nsignal_seq = atomic_read(&dev_priv->marker_seq);\r\nret = 0;\r\nfor (;;) {\r\nprepare_to_wait(&dev_priv->fence_queue, &__wait,\r\n(interruptible) ?\r\nTASK_INTERRUPTIBLE : TASK_UNINTERRUPTIBLE);\r\nif (wait_condition(dev_priv, seqno))\r\nbreak;\r\nif (time_after_eq(jiffies, end_jiffies)) {\r\nDRM_ERROR("SVGA device lockup.\n");\r\nbreak;\r\n}\r\nif (lazy)\r\nschedule_timeout(1);\r\nelse if ((++count & 0x0F) == 0) {\r\n__set_current_state(TASK_RUNNING);\r\nschedule();\r\n__set_current_state((interruptible) ?\r\nTASK_INTERRUPTIBLE :\r\nTASK_UNINTERRUPTIBLE);\r\n}\r\nif (interruptible && signal_pending(current)) {\r\nret = -ERESTARTSYS;\r\nbreak;\r\n}\r\n}\r\nfinish_wait(&dev_priv->fence_queue, &__wait);\r\nif (ret == 0 && fifo_idle) {\r\n__le32 __iomem *fifo_mem = dev_priv->mmio_virt;\r\niowrite32(signal_seq, fifo_mem + SVGA_FIFO_FENCE);\r\n}\r\nwake_up_all(&dev_priv->fence_queue);\r\nif (fifo_idle)\r\nup_read(&fifo_state->rwsem);\r\nreturn ret;\r\n}\r\nvoid vmw_seqno_waiter_add(struct vmw_private *dev_priv)\r\n{\r\nspin_lock(&dev_priv->waiter_lock);\r\nif (dev_priv->fence_queue_waiters++ == 0) {\r\nunsigned long irq_flags;\r\nspin_lock_irqsave(&dev_priv->irq_lock, irq_flags);\r\noutl(SVGA_IRQFLAG_ANY_FENCE,\r\ndev_priv->io_start + VMWGFX_IRQSTATUS_PORT);\r\ndev_priv->irq_mask |= SVGA_IRQFLAG_ANY_FENCE;\r\nvmw_write(dev_priv, SVGA_REG_IRQMASK, dev_priv->irq_mask);\r\nspin_unlock_irqrestore(&dev_priv->irq_lock, irq_flags);\r\n}\r\nspin_unlock(&dev_priv->waiter_lock);\r\n}\r\nvoid vmw_seqno_waiter_remove(struct vmw_private *dev_priv)\r\n{\r\nspin_lock(&dev_priv->waiter_lock);\r\nif (--dev_priv->fence_queue_waiters == 0) {\r\nunsigned long irq_flags;\r\nspin_lock_irqsave(&dev_priv->irq_lock, irq_flags);\r\ndev_priv->irq_mask &= ~SVGA_IRQFLAG_ANY_FENCE;\r\nvmw_write(dev_priv, SVGA_REG_IRQMASK, dev_priv->irq_mask);\r\nspin_unlock_irqrestore(&dev_priv->irq_lock, irq_flags);\r\n}\r\nspin_unlock(&dev_priv->waiter_lock);\r\n}\r\nvoid vmw_goal_waiter_add(struct vmw_private *dev_priv)\r\n{\r\nspin_lock(&dev_priv->waiter_lock);\r\nif (dev_priv->goal_queue_waiters++ == 0) {\r\nunsigned long irq_flags;\r\nspin_lock_irqsave(&dev_priv->irq_lock, irq_flags);\r\noutl(SVGA_IRQFLAG_FENCE_GOAL,\r\ndev_priv->io_start + VMWGFX_IRQSTATUS_PORT);\r\ndev_priv->irq_mask |= SVGA_IRQFLAG_FENCE_GOAL;\r\nvmw_write(dev_priv, SVGA_REG_IRQMASK, dev_priv->irq_mask);\r\nspin_unlock_irqrestore(&dev_priv->irq_lock, irq_flags);\r\n}\r\nspin_unlock(&dev_priv->waiter_lock);\r\n}\r\nvoid vmw_goal_waiter_remove(struct vmw_private *dev_priv)\r\n{\r\nspin_lock(&dev_priv->waiter_lock);\r\nif (--dev_priv->goal_queue_waiters == 0) {\r\nunsigned long irq_flags;\r\nspin_lock_irqsave(&dev_priv->irq_lock, irq_flags);\r\ndev_priv->irq_mask &= ~SVGA_IRQFLAG_FENCE_GOAL;\r\nvmw_write(dev_priv, SVGA_REG_IRQMASK, dev_priv->irq_mask);\r\nspin_unlock_irqrestore(&dev_priv->irq_lock, irq_flags);\r\n}\r\nspin_unlock(&dev_priv->waiter_lock);\r\n}\r\nint vmw_wait_seqno(struct vmw_private *dev_priv,\r\nbool lazy, uint32_t seqno,\r\nbool interruptible, unsigned long timeout)\r\n{\r\nlong ret;\r\nstruct vmw_fifo_state *fifo = &dev_priv->fifo;\r\nif (likely(dev_priv->last_read_seqno - seqno < VMW_FENCE_WRAP))\r\nreturn 0;\r\nif (likely(vmw_seqno_passed(dev_priv, seqno)))\r\nreturn 0;\r\nvmw_fifo_ping_host(dev_priv, SVGA_SYNC_GENERIC);\r\nif (!(fifo->capabilities & SVGA_FIFO_CAP_FENCE))\r\nreturn vmw_fallback_wait(dev_priv, lazy, true, seqno,\r\ninterruptible, timeout);\r\nif (!(dev_priv->capabilities & SVGA_CAP_IRQMASK))\r\nreturn vmw_fallback_wait(dev_priv, lazy, false, seqno,\r\ninterruptible, timeout);\r\nvmw_seqno_waiter_add(dev_priv);\r\nif (interruptible)\r\nret = wait_event_interruptible_timeout\r\n(dev_priv->fence_queue,\r\nvmw_seqno_passed(dev_priv, seqno),\r\ntimeout);\r\nelse\r\nret = wait_event_timeout\r\n(dev_priv->fence_queue,\r\nvmw_seqno_passed(dev_priv, seqno),\r\ntimeout);\r\nvmw_seqno_waiter_remove(dev_priv);\r\nif (unlikely(ret == 0))\r\nret = -EBUSY;\r\nelse if (likely(ret > 0))\r\nret = 0;\r\nreturn ret;\r\n}\r\nvoid vmw_irq_preinstall(struct drm_device *dev)\r\n{\r\nstruct vmw_private *dev_priv = vmw_priv(dev);\r\nuint32_t status;\r\nif (!(dev_priv->capabilities & SVGA_CAP_IRQMASK))\r\nreturn;\r\nspin_lock_init(&dev_priv->irq_lock);\r\nstatus = inl(dev_priv->io_start + VMWGFX_IRQSTATUS_PORT);\r\noutl(status, dev_priv->io_start + VMWGFX_IRQSTATUS_PORT);\r\n}\r\nint vmw_irq_postinstall(struct drm_device *dev)\r\n{\r\nreturn 0;\r\n}\r\nvoid vmw_irq_uninstall(struct drm_device *dev)\r\n{\r\nstruct vmw_private *dev_priv = vmw_priv(dev);\r\nuint32_t status;\r\nif (!(dev_priv->capabilities & SVGA_CAP_IRQMASK))\r\nreturn;\r\nvmw_write(dev_priv, SVGA_REG_IRQMASK, 0);\r\nstatus = inl(dev_priv->io_start + VMWGFX_IRQSTATUS_PORT);\r\noutl(status, dev_priv->io_start + VMWGFX_IRQSTATUS_PORT);\r\n}
