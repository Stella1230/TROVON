static void a4xx_enable_hwcg(struct msm_gpu *gpu)\r\n{\r\nstruct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);\r\nunsigned int i;\r\nfor (i = 0; i < 4; i++)\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_CTL_TP(i), 0x02222202);\r\nfor (i = 0; i < 4; i++)\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_CTL2_TP(i), 0x00002222);\r\nfor (i = 0; i < 4; i++)\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_HYST_TP(i), 0x0E739CE7);\r\nfor (i = 0; i < 4; i++)\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_DELAY_TP(i), 0x00111111);\r\nfor (i = 0; i < 4; i++)\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_CTL_SP(i), 0x22222222);\r\nfor (i = 0; i < 4; i++)\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_CTL2_SP(i), 0x00222222);\r\nfor (i = 0; i < 4; i++)\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_HYST_SP(i), 0x00000104);\r\nfor (i = 0; i < 4; i++)\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_DELAY_SP(i), 0x00000081);\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_CTL_UCHE, 0x22222222);\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_CTL2_UCHE, 0x02222222);\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_CTL3_UCHE, 0x00000000);\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_CTL4_UCHE, 0x00000000);\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_HYST_UCHE, 0x00004444);\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_DELAY_UCHE, 0x00001112);\r\nfor (i = 0; i < 4; i++)\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_CTL_RB(i), 0x22222222);\r\nfor (i = 0; i < 4; i++) {\r\nif (adreno_is_a420(adreno_gpu)) {\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_CTL2_RB(i),\r\n0x00002020);\r\n} else {\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_CTL2_RB(i),\r\n0x00022020);\r\n}\r\n}\r\nfor (i = 0; i < 4; i++) {\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_CTL_MARB_CCU(i),\r\n0x00000922);\r\n}\r\nfor (i = 0; i < 4; i++) {\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_HYST_RB_MARB_CCU(i),\r\n0x00000000);\r\n}\r\nfor (i = 0; i < 4; i++) {\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_DELAY_RB_MARB_CCU_L1(i),\r\n0x00000001);\r\n}\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_MODE_GPC, 0x02222222);\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_HYST_GPC, 0x04100104);\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_DELAY_GPC, 0x00022222);\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_CTL_COM_DCOM, 0x00000022);\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_HYST_COM_DCOM, 0x0000010F);\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_DELAY_COM_DCOM, 0x00000022);\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_CTL_TSE_RAS_RBBM, 0x00222222);\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_HYST_TSE_RAS_RBBM, 0x00004104);\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_DELAY_TSE_RAS_RBBM, 0x00000222);\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_CTL_HLSQ , 0x00000000);\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_HYST_HLSQ, 0x00000000);\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_DELAY_HLSQ, 0x00020000);\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_CTL, 0xAAAAAAAA);\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_CTL2, 0);\r\n}\r\nstatic void a4xx_me_init(struct msm_gpu *gpu)\r\n{\r\nstruct msm_ringbuffer *ring = gpu->rb;\r\nOUT_PKT3(ring, CP_ME_INIT, 17);\r\nOUT_RING(ring, 0x000003f7);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000080);\r\nOUT_RING(ring, 0x00000100);\r\nOUT_RING(ring, 0x00000180);\r\nOUT_RING(ring, 0x00006600);\r\nOUT_RING(ring, 0x00000150);\r\nOUT_RING(ring, 0x0000014e);\r\nOUT_RING(ring, 0x00000154);\r\nOUT_RING(ring, 0x00000001);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000000);\r\nOUT_RING(ring, 0x00000000);\r\ngpu->funcs->flush(gpu);\r\ngpu->funcs->idle(gpu);\r\n}\r\nstatic int a4xx_hw_init(struct msm_gpu *gpu)\r\n{\r\nstruct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);\r\nstruct a4xx_gpu *a4xx_gpu = to_a4xx_gpu(adreno_gpu);\r\nuint32_t *ptr, len;\r\nint i, ret;\r\nif (adreno_is_a4xx(adreno_gpu)) {\r\ngpu_write(gpu, REG_A4XX_VBIF_ABIT_SORT, 0x0001001F);\r\ngpu_write(gpu, REG_A4XX_VBIF_ABIT_SORT_CONF, 0x000000A4);\r\ngpu_write(gpu, REG_A4XX_VBIF_GATE_OFF_WRREQ_EN, 0x00000001);\r\ngpu_write(gpu, REG_A4XX_VBIF_IN_RD_LIM_CONF0, 0x18181818);\r\ngpu_write(gpu, REG_A4XX_VBIF_IN_RD_LIM_CONF1, 0x00000018);\r\ngpu_write(gpu, REG_A4XX_VBIF_IN_WR_LIM_CONF0, 0x18181818);\r\ngpu_write(gpu, REG_A4XX_VBIF_IN_WR_LIM_CONF1, 0x00000018);\r\ngpu_write(gpu, REG_A4XX_VBIF_ROUND_ROBIN_QOS_ARB, 0x00000003);\r\n} else {\r\nBUG();\r\n}\r\ngpu_write(gpu, REG_A4XX_RBBM_GPU_BUSY_MASKED, 0xffffffff);\r\ngpu_write(gpu, REG_A4XX_RBBM_SP_HYST_CNT, 0x10);\r\ngpu_write(gpu, REG_A4XX_RBBM_WAIT_IDLE_CLOCKS_CTL, 0x10);\r\ngpu_write(gpu, REG_A4XX_RBBM_AHB_CTL0, 0x00000001);\r\ngpu_write(gpu, REG_A4XX_RBBM_AHB_CTL1, 0xa6ffffff);\r\ngpu_write(gpu, REG_A4XX_RBBM_RBBM_CTL, 0x00000030);\r\ngpu_write(gpu, REG_A4XX_RBBM_INTERFACE_HANG_INT_CTL,\r\n(1 << 30) | 0xFFFF);\r\ngpu_write(gpu, REG_A4XX_RB_GMEM_BASE_ADDR,\r\n(unsigned int)(a4xx_gpu->ocmem_base >> 14));\r\ngpu_write(gpu, REG_A4XX_RBBM_PERFCTR_CTL, 0x01);\r\ngpu_write(gpu, REG_A4XX_UCHE_TRAP_BASE_LO, 0xffff0000);\r\ngpu_write(gpu, REG_A4XX_UCHE_TRAP_BASE_HI, 0xffff0000);\r\ngpu_write(gpu, REG_A4XX_CP_DEBUG, (1 << 25) |\r\n(adreno_is_a420(adreno_gpu) ? (1 << 29) : 0));\r\na4xx_enable_hwcg(gpu);\r\nif (adreno_is_a420(adreno_gpu)) {\r\nunsigned int val;\r\nval = gpu_read(gpu, REG_A4XX_RBBM_CLOCK_DELAY_HLSQ);\r\nval &= ~A4XX_CGC_HLSQ_EARLY_CYC__MASK;\r\nval |= 2 << A4XX_CGC_HLSQ_EARLY_CYC__SHIFT;\r\ngpu_write(gpu, REG_A4XX_RBBM_CLOCK_DELAY_HLSQ, val);\r\n}\r\nret = adreno_hw_init(gpu);\r\nif (ret)\r\nreturn ret;\r\ngpu_write(gpu, REG_A4XX_CP_PROTECT_CTRL, 0x00000007);\r\ngpu_write(gpu, REG_A4XX_CP_PROTECT(0), 0x62000010);\r\ngpu_write(gpu, REG_A4XX_CP_PROTECT(1), 0x63000020);\r\ngpu_write(gpu, REG_A4XX_CP_PROTECT(2), 0x64000040);\r\ngpu_write(gpu, REG_A4XX_CP_PROTECT(3), 0x65000080);\r\ngpu_write(gpu, REG_A4XX_CP_PROTECT(4), 0x66000100);\r\ngpu_write(gpu, REG_A4XX_CP_PROTECT(5), 0x64000200);\r\ngpu_write(gpu, REG_A4XX_CP_PROTECT(6), 0x67000800);\r\ngpu_write(gpu, REG_A4XX_CP_PROTECT(7), 0x64001600);\r\ngpu_write(gpu, REG_A4XX_CP_PROTECT(8), 0x60003300);\r\ngpu_write(gpu, REG_A4XX_CP_PROTECT(9), 0x60003800);\r\ngpu_write(gpu, REG_A4XX_CP_PROTECT(10), 0x61003980);\r\ngpu_write(gpu, REG_A4XX_CP_PROTECT(11), 0x6e010000);\r\ngpu_write(gpu, REG_A4XX_RBBM_INT_0_MASK, A4XX_INT0_MASK);\r\nret = adreno_hw_init(gpu);\r\nif (ret)\r\nreturn ret;\r\nptr = (uint32_t *)(adreno_gpu->pm4->data);\r\nlen = adreno_gpu->pm4->size / 4;\r\nDBG("loading PM4 ucode version: %u", ptr[0]);\r\ngpu_write(gpu, REG_A4XX_CP_ME_RAM_WADDR, 0);\r\nfor (i = 1; i < len; i++)\r\ngpu_write(gpu, REG_A4XX_CP_ME_RAM_DATA, ptr[i]);\r\nptr = (uint32_t *)(adreno_gpu->pfp->data);\r\nlen = adreno_gpu->pfp->size / 4;\r\nDBG("loading PFP ucode version: %u", ptr[0]);\r\ngpu_write(gpu, REG_A4XX_CP_PFP_UCODE_ADDR, 0);\r\nfor (i = 1; i < len; i++)\r\ngpu_write(gpu, REG_A4XX_CP_PFP_UCODE_DATA, ptr[i]);\r\ngpu_write(gpu, REG_A4XX_CP_ME_CNTL, 0);\r\na4xx_me_init(gpu);\r\nreturn 0;\r\n}\r\nstatic void a4xx_recover(struct msm_gpu *gpu)\r\n{\r\nif (hang_debug)\r\na4xx_dump(gpu);\r\ngpu_write(gpu, REG_A4XX_RBBM_SW_RESET_CMD, 1);\r\ngpu_read(gpu, REG_A4XX_RBBM_SW_RESET_CMD);\r\ngpu_write(gpu, REG_A4XX_RBBM_SW_RESET_CMD, 0);\r\nadreno_recover(gpu);\r\n}\r\nstatic void a4xx_destroy(struct msm_gpu *gpu)\r\n{\r\nstruct adreno_gpu *adreno_gpu = to_adreno_gpu(gpu);\r\nstruct a4xx_gpu *a4xx_gpu = to_a4xx_gpu(adreno_gpu);\r\nDBG("%s", gpu->name);\r\nadreno_gpu_cleanup(adreno_gpu);\r\n#ifdef CONFIG_MSM_OCMEM\r\nif (a4xx_gpu->ocmem_base)\r\nocmem_free(OCMEM_GRAPHICS, a4xx_gpu->ocmem_hdl);\r\n#endif\r\nkfree(a4xx_gpu);\r\n}\r\nstatic void a4xx_idle(struct msm_gpu *gpu)\r\n{\r\nadreno_idle(gpu);\r\nif (spin_until(!(gpu_read(gpu, REG_A4XX_RBBM_STATUS) &\r\nA4XX_RBBM_STATUS_GPU_BUSY)))\r\nDRM_ERROR("%s: timeout waiting for GPU to idle!\n", gpu->name);\r\n}\r\nstatic irqreturn_t a4xx_irq(struct msm_gpu *gpu)\r\n{\r\nuint32_t status;\r\nstatus = gpu_read(gpu, REG_A4XX_RBBM_INT_0_STATUS);\r\nDBG("%s: Int status %08x", gpu->name, status);\r\ngpu_write(gpu, REG_A4XX_RBBM_INT_CLEAR_CMD, status);\r\nmsm_gpu_retire(gpu);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void a4xx_show(struct msm_gpu *gpu, struct seq_file *m)\r\n{\r\ngpu->funcs->pm_resume(gpu);\r\nseq_printf(m, "status: %08x\n",\r\ngpu_read(gpu, REG_A4XX_RBBM_STATUS));\r\ngpu->funcs->pm_suspend(gpu);\r\nadreno_show(gpu, m);\r\n}\r\nstatic void a4xx_dump(struct msm_gpu *gpu)\r\n{\r\nadreno_dump(gpu);\r\nprintk("status: %08x\n",\r\ngpu_read(gpu, REG_A4XX_RBBM_STATUS));\r\nadreno_dump(gpu);\r\n}\r\nstruct msm_gpu *a4xx_gpu_init(struct drm_device *dev)\r\n{\r\nstruct a4xx_gpu *a4xx_gpu = NULL;\r\nstruct adreno_gpu *adreno_gpu;\r\nstruct msm_gpu *gpu;\r\nstruct msm_drm_private *priv = dev->dev_private;\r\nstruct platform_device *pdev = priv->gpu_pdev;\r\nint ret;\r\nif (!pdev) {\r\ndev_err(dev->dev, "no a4xx device\n");\r\nret = -ENXIO;\r\ngoto fail;\r\n}\r\na4xx_gpu = kzalloc(sizeof(*a4xx_gpu), GFP_KERNEL);\r\nif (!a4xx_gpu) {\r\nret = -ENOMEM;\r\ngoto fail;\r\n}\r\nadreno_gpu = &a4xx_gpu->base;\r\ngpu = &adreno_gpu->base;\r\na4xx_gpu->pdev = pdev;\r\ngpu->perfcntrs = NULL;\r\ngpu->num_perfcntrs = 0;\r\nadreno_gpu->registers = a4xx_registers;\r\nadreno_gpu->reg_offsets = a4xx_register_offsets;\r\nret = adreno_gpu_init(dev, pdev, adreno_gpu, &funcs);\r\nif (ret)\r\ngoto fail;\r\nif (adreno_is_a4xx(adreno_gpu)) {\r\n#ifdef CONFIG_MSM_OCMEM\r\nstruct ocmem_buf *ocmem_hdl =\r\nocmem_allocate(OCMEM_GRAPHICS, adreno_gpu->gmem);\r\na4xx_gpu->ocmem_hdl = ocmem_hdl;\r\na4xx_gpu->ocmem_base = ocmem_hdl->addr;\r\nadreno_gpu->gmem = ocmem_hdl->len;\r\nDBG("using %dK of OCMEM at 0x%08x", adreno_gpu->gmem / 1024,\r\na4xx_gpu->ocmem_base);\r\n#endif\r\n}\r\nif (!gpu->mmu) {\r\ndev_err(dev->dev, "No memory protection without IOMMU\n");\r\nret = -ENXIO;\r\ngoto fail;\r\n}\r\nreturn gpu;\r\nfail:\r\nif (a4xx_gpu)\r\na4xx_destroy(&a4xx_gpu->base.base);\r\nreturn ERR_PTR(ret);\r\n}
