static int ctr_aes_nx_set_key(struct crypto_tfm *tfm,\r\nconst u8 *in_key,\r\nunsigned int key_len)\r\n{\r\nstruct nx_crypto_ctx *nx_ctx = crypto_tfm_ctx(tfm);\r\nstruct nx_csbcpb *csbcpb = nx_ctx->csbcpb;\r\nnx_ctx_init(nx_ctx, HCOP_FC_AES);\r\nswitch (key_len) {\r\ncase AES_KEYSIZE_128:\r\nNX_CPB_SET_KEY_SIZE(csbcpb, NX_KS_AES_128);\r\nnx_ctx->ap = &nx_ctx->props[NX_PROPS_AES_128];\r\nbreak;\r\ncase AES_KEYSIZE_192:\r\nNX_CPB_SET_KEY_SIZE(csbcpb, NX_KS_AES_192);\r\nnx_ctx->ap = &nx_ctx->props[NX_PROPS_AES_192];\r\nbreak;\r\ncase AES_KEYSIZE_256:\r\nNX_CPB_SET_KEY_SIZE(csbcpb, NX_KS_AES_256);\r\nnx_ctx->ap = &nx_ctx->props[NX_PROPS_AES_256];\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\ncsbcpb->cpb.hdr.mode = NX_MODE_AES_CTR;\r\nmemcpy(csbcpb->cpb.aes_ctr.key, in_key, key_len);\r\nreturn 0;\r\n}\r\nstatic int ctr3686_aes_nx_set_key(struct crypto_tfm *tfm,\r\nconst u8 *in_key,\r\nunsigned int key_len)\r\n{\r\nstruct nx_crypto_ctx *nx_ctx = crypto_tfm_ctx(tfm);\r\nif (key_len < CTR_RFC3686_NONCE_SIZE)\r\nreturn -EINVAL;\r\nmemcpy(nx_ctx->priv.ctr.iv,\r\nin_key + key_len - CTR_RFC3686_NONCE_SIZE,\r\nCTR_RFC3686_NONCE_SIZE);\r\nkey_len -= CTR_RFC3686_NONCE_SIZE;\r\nreturn ctr_aes_nx_set_key(tfm, in_key, key_len);\r\n}\r\nstatic int ctr_aes_nx_crypt(struct blkcipher_desc *desc,\r\nstruct scatterlist *dst,\r\nstruct scatterlist *src,\r\nunsigned int nbytes)\r\n{\r\nstruct nx_crypto_ctx *nx_ctx = crypto_blkcipher_ctx(desc->tfm);\r\nstruct nx_csbcpb *csbcpb = nx_ctx->csbcpb;\r\nunsigned long irq_flags;\r\nunsigned int processed = 0, to_process;\r\nint rc;\r\nspin_lock_irqsave(&nx_ctx->lock, irq_flags);\r\ndo {\r\nto_process = nbytes - processed;\r\nrc = nx_build_sg_lists(nx_ctx, desc, dst, src, &to_process,\r\nprocessed, csbcpb->cpb.aes_ctr.iv);\r\nif (rc)\r\ngoto out;\r\nif (!nx_ctx->op.inlen || !nx_ctx->op.outlen) {\r\nrc = -EINVAL;\r\ngoto out;\r\n}\r\nrc = nx_hcall_sync(nx_ctx, &nx_ctx->op,\r\ndesc->flags & CRYPTO_TFM_REQ_MAY_SLEEP);\r\nif (rc)\r\ngoto out;\r\nmemcpy(desc->info, csbcpb->cpb.aes_cbc.cv, AES_BLOCK_SIZE);\r\natomic_inc(&(nx_ctx->stats->aes_ops));\r\natomic64_add(csbcpb->csb.processed_byte_count,\r\n&(nx_ctx->stats->aes_bytes));\r\nprocessed += to_process;\r\n} while (processed < nbytes);\r\nout:\r\nspin_unlock_irqrestore(&nx_ctx->lock, irq_flags);\r\nreturn rc;\r\n}\r\nstatic int ctr3686_aes_nx_crypt(struct blkcipher_desc *desc,\r\nstruct scatterlist *dst,\r\nstruct scatterlist *src,\r\nunsigned int nbytes)\r\n{\r\nstruct nx_crypto_ctx *nx_ctx = crypto_blkcipher_ctx(desc->tfm);\r\nu8 *iv = nx_ctx->priv.ctr.iv;\r\nmemcpy(iv + CTR_RFC3686_NONCE_SIZE,\r\ndesc->info, CTR_RFC3686_IV_SIZE);\r\niv[12] = iv[13] = iv[14] = 0;\r\niv[15] = 1;\r\ndesc->info = nx_ctx->priv.ctr.iv;\r\nreturn ctr_aes_nx_crypt(desc, dst, src, nbytes);\r\n}
