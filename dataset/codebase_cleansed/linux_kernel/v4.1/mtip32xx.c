static bool mtip_check_surprise_removal(struct pci_dev *pdev)\r\n{\r\nu16 vendor_id = 0;\r\nstruct driver_data *dd = pci_get_drvdata(pdev);\r\nif (dd->sr)\r\nreturn true;\r\npci_read_config_word(pdev, 0x00, &vendor_id);\r\nif (vendor_id == 0xFFFF) {\r\ndd->sr = true;\r\nif (dd->queue)\r\nset_bit(QUEUE_FLAG_DEAD, &dd->queue->queue_flags);\r\nelse\r\ndev_warn(&dd->pdev->dev,\r\n"%s: dd->queue is NULL\n", __func__);\r\nif (dd->port) {\r\nset_bit(MTIP_PF_SR_CLEANUP_BIT, &dd->port->flags);\r\nwake_up_interruptible(&dd->port->svc_wait);\r\n} else\r\ndev_warn(&dd->pdev->dev,\r\n"%s: dd->port is NULL\n", __func__);\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic struct mtip_cmd *mtip_get_int_command(struct driver_data *dd)\r\n{\r\nstruct request *rq;\r\nrq = blk_mq_alloc_request(dd->queue, 0, __GFP_WAIT, true);\r\nreturn blk_mq_rq_to_pdu(rq);\r\n}\r\nstatic void mtip_put_int_command(struct driver_data *dd, struct mtip_cmd *cmd)\r\n{\r\nblk_put_request(blk_mq_rq_from_pdu(cmd));\r\n}\r\nstatic struct request *mtip_rq_from_tag(struct driver_data *dd,\r\nunsigned int tag)\r\n{\r\nstruct blk_mq_hw_ctx *hctx = dd->queue->queue_hw_ctx[0];\r\nreturn blk_mq_tag_to_rq(hctx->tags, tag);\r\n}\r\nstatic struct mtip_cmd *mtip_cmd_from_tag(struct driver_data *dd,\r\nunsigned int tag)\r\n{\r\nstruct request *rq = mtip_rq_from_tag(dd, tag);\r\nreturn blk_mq_rq_to_pdu(rq);\r\n}\r\nstatic void mtip_async_complete(struct mtip_port *port,\r\nint tag, struct mtip_cmd *cmd, int status)\r\n{\r\nstruct driver_data *dd = port->dd;\r\nstruct request *rq;\r\nif (unlikely(!dd) || unlikely(!port))\r\nreturn;\r\nif (unlikely(status == PORT_IRQ_TF_ERR)) {\r\ndev_warn(&port->dd->pdev->dev,\r\n"Command tag %d failed due to TFE\n", tag);\r\n}\r\ndma_unmap_sg(&dd->pdev->dev, cmd->sg, cmd->scatter_ents, cmd->direction);\r\nrq = mtip_rq_from_tag(dd, tag);\r\nif (unlikely(cmd->unaligned))\r\nup(&port->cmd_slot_unal);\r\nblk_mq_end_request(rq, status ? -EIO : 0);\r\n}\r\nstatic int mtip_hba_reset(struct driver_data *dd)\r\n{\r\nunsigned long timeout;\r\nwritel(HOST_RESET, dd->mmio + HOST_CTL);\r\nreadl(dd->mmio + HOST_CTL);\r\ntimeout = jiffies + msecs_to_jiffies(2000);\r\ndo {\r\nmdelay(10);\r\nif (test_bit(MTIP_DDF_REMOVE_PENDING_BIT, &dd->dd_flag))\r\nreturn -1;\r\n} while ((readl(dd->mmio + HOST_CTL) & HOST_RESET)\r\n&& time_before(jiffies, timeout));\r\nif (readl(dd->mmio + HOST_CTL) & HOST_RESET)\r\nreturn -1;\r\nreturn 0;\r\n}\r\nstatic inline void mtip_issue_ncq_command(struct mtip_port *port, int tag)\r\n{\r\nint group = tag >> 5;\r\nspin_lock(&port->cmd_issue_lock[group]);\r\nwritel((1 << MTIP_TAG_BIT(tag)),\r\nport->s_active[MTIP_TAG_INDEX(tag)]);\r\nwritel((1 << MTIP_TAG_BIT(tag)),\r\nport->cmd_issue[MTIP_TAG_INDEX(tag)]);\r\nspin_unlock(&port->cmd_issue_lock[group]);\r\n}\r\nstatic int mtip_enable_fis(struct mtip_port *port, int enable)\r\n{\r\nu32 tmp;\r\ntmp = readl(port->mmio + PORT_CMD);\r\nif (enable)\r\nwritel(tmp | PORT_CMD_FIS_RX, port->mmio + PORT_CMD);\r\nelse\r\nwritel(tmp & ~PORT_CMD_FIS_RX, port->mmio + PORT_CMD);\r\nreadl(port->mmio + PORT_CMD);\r\nreturn (((tmp & PORT_CMD_FIS_RX) == PORT_CMD_FIS_RX));\r\n}\r\nstatic int mtip_enable_engine(struct mtip_port *port, int enable)\r\n{\r\nu32 tmp;\r\ntmp = readl(port->mmio + PORT_CMD);\r\nif (enable)\r\nwritel(tmp | PORT_CMD_START, port->mmio + PORT_CMD);\r\nelse\r\nwritel(tmp & ~PORT_CMD_START, port->mmio + PORT_CMD);\r\nreadl(port->mmio + PORT_CMD);\r\nreturn (((tmp & PORT_CMD_START) == PORT_CMD_START));\r\n}\r\nstatic inline void mtip_start_port(struct mtip_port *port)\r\n{\r\nmtip_enable_fis(port, 1);\r\nmtip_enable_engine(port, 1);\r\n}\r\nstatic inline void mtip_deinit_port(struct mtip_port *port)\r\n{\r\nwritel(0, port->mmio + PORT_IRQ_MASK);\r\nmtip_enable_engine(port, 0);\r\nmtip_enable_fis(port, 0);\r\n}\r\nstatic void mtip_init_port(struct mtip_port *port)\r\n{\r\nint i;\r\nmtip_deinit_port(port);\r\nif (readl(port->dd->mmio + HOST_CAP) & HOST_CAP_64) {\r\nwritel((port->command_list_dma >> 16) >> 16,\r\nport->mmio + PORT_LST_ADDR_HI);\r\nwritel((port->rxfis_dma >> 16) >> 16,\r\nport->mmio + PORT_FIS_ADDR_HI);\r\n}\r\nwritel(port->command_list_dma & 0xFFFFFFFF,\r\nport->mmio + PORT_LST_ADDR);\r\nwritel(port->rxfis_dma & 0xFFFFFFFF, port->mmio + PORT_FIS_ADDR);\r\nwritel(readl(port->mmio + PORT_SCR_ERR), port->mmio + PORT_SCR_ERR);\r\nfor (i = 0; i < port->dd->slot_groups; i++)\r\nwritel(0xFFFFFFFF, port->completed[i]);\r\nwritel(readl(port->mmio + PORT_IRQ_STAT), port->mmio + PORT_IRQ_STAT);\r\nwritel(readl(port->dd->mmio + HOST_IRQ_STAT),\r\nport->dd->mmio + HOST_IRQ_STAT);\r\nwritel(DEF_PORT_IRQ, port->mmio + PORT_IRQ_MASK);\r\n}\r\nstatic void mtip_restart_port(struct mtip_port *port)\r\n{\r\nunsigned long timeout;\r\nmtip_enable_engine(port, 0);\r\ntimeout = jiffies + msecs_to_jiffies(500);\r\nwhile ((readl(port->mmio + PORT_CMD) & PORT_CMD_LIST_ON)\r\n&& time_before(jiffies, timeout))\r\n;\r\nif (test_bit(MTIP_DDF_REMOVE_PENDING_BIT, &port->dd->dd_flag))\r\nreturn;\r\nif (readl(port->mmio + PORT_CMD) & PORT_CMD_LIST_ON) {\r\ndev_warn(&port->dd->pdev->dev,\r\n"PxCMD.CR not clear, escalating reset\n");\r\nif (mtip_hba_reset(port->dd))\r\ndev_err(&port->dd->pdev->dev,\r\n"HBA reset escalation failed.\n");\r\nmdelay(30);\r\n}\r\ndev_warn(&port->dd->pdev->dev, "Issuing COM reset\n");\r\nwritel(readl(port->mmio + PORT_SCR_CTL) |\r\n1, port->mmio + PORT_SCR_CTL);\r\nreadl(port->mmio + PORT_SCR_CTL);\r\ntimeout = jiffies + msecs_to_jiffies(1);\r\nwhile (time_before(jiffies, timeout))\r\n;\r\nif (test_bit(MTIP_DDF_REMOVE_PENDING_BIT, &port->dd->dd_flag))\r\nreturn;\r\nwritel(readl(port->mmio + PORT_SCR_CTL) & ~1,\r\nport->mmio + PORT_SCR_CTL);\r\nreadl(port->mmio + PORT_SCR_CTL);\r\ntimeout = jiffies + msecs_to_jiffies(500);\r\nwhile (((readl(port->mmio + PORT_SCR_STAT) & 0x01) == 0)\r\n&& time_before(jiffies, timeout))\r\n;\r\nif (test_bit(MTIP_DDF_REMOVE_PENDING_BIT, &port->dd->dd_flag))\r\nreturn;\r\nif ((readl(port->mmio + PORT_SCR_STAT) & 0x01) == 0)\r\ndev_warn(&port->dd->pdev->dev,\r\n"COM reset failed\n");\r\nmtip_init_port(port);\r\nmtip_start_port(port);\r\n}\r\nstatic int mtip_device_reset(struct driver_data *dd)\r\n{\r\nint rv = 0;\r\nif (mtip_check_surprise_removal(dd->pdev))\r\nreturn 0;\r\nif (mtip_hba_reset(dd) < 0)\r\nrv = -EFAULT;\r\nmdelay(1);\r\nmtip_init_port(dd->port);\r\nmtip_start_port(dd->port);\r\nwritel(readl(dd->mmio + HOST_CTL) | HOST_IRQ_EN,\r\ndd->mmio + HOST_CTL);\r\nreturn rv;\r\n}\r\nstatic void print_tags(struct driver_data *dd,\r\nchar *msg,\r\nunsigned long *tagbits,\r\nint cnt)\r\n{\r\nunsigned char tagmap[128];\r\nint group, tagmap_len = 0;\r\nmemset(tagmap, 0, sizeof(tagmap));\r\nfor (group = SLOTBITS_IN_LONGS; group > 0; group--)\r\ntagmap_len += sprintf(tagmap + tagmap_len, "%016lX ",\r\ntagbits[group-1]);\r\ndev_warn(&dd->pdev->dev,\r\n"%d command(s) %s: tagmap [%s]", cnt, msg, tagmap);\r\n}\r\nstatic void mtip_completion(struct mtip_port *port,\r\nint tag, struct mtip_cmd *command, int status)\r\n{\r\nstruct completion *waiting = command->comp_data;\r\nif (unlikely(status == PORT_IRQ_TF_ERR))\r\ndev_warn(&port->dd->pdev->dev,\r\n"Internal command %d completed with TFE\n", tag);\r\ncomplete(waiting);\r\n}\r\nstatic void mtip_null_completion(struct mtip_port *port,\r\nint tag, struct mtip_cmd *command, int status)\r\n{\r\n}\r\nstatic void mtip_handle_tfe(struct driver_data *dd)\r\n{\r\nint group, tag, bit, reissue, rv;\r\nstruct mtip_port *port;\r\nstruct mtip_cmd *cmd;\r\nu32 completed;\r\nstruct host_to_dev_fis *fis;\r\nunsigned long tagaccum[SLOTBITS_IN_LONGS];\r\nunsigned int cmd_cnt = 0;\r\nunsigned char *buf;\r\nchar *fail_reason = NULL;\r\nint fail_all_ncq_write = 0, fail_all_ncq_cmds = 0;\r\ndev_warn(&dd->pdev->dev, "Taskfile error\n");\r\nport = dd->port;\r\nset_bit(MTIP_PF_EH_ACTIVE_BIT, &port->flags);\r\nif (test_bit(MTIP_PF_IC_ACTIVE_BIT, &port->flags) &&\r\ntest_bit(MTIP_TAG_INTERNAL, port->allocated)) {\r\ncmd = mtip_cmd_from_tag(dd, MTIP_TAG_INTERNAL);\r\ndbg_printk(MTIP_DRV_NAME " TFE for the internal command\n");\r\nif (cmd->comp_data && cmd->comp_func) {\r\ncmd->comp_func(port, MTIP_TAG_INTERNAL,\r\ncmd, PORT_IRQ_TF_ERR);\r\n}\r\ngoto handle_tfe_exit;\r\n}\r\nmemset(tagaccum, 0, SLOTBITS_IN_LONGS * sizeof(long));\r\nfor (group = 0; group < dd->slot_groups; group++) {\r\ncompleted = readl(port->completed[group]);\r\ndev_warn(&dd->pdev->dev, "g=%u, comp=%x\n", group, completed);\r\nwritel(completed, port->completed[group]);\r\nfor (bit = 0; bit < 32 && completed; bit++) {\r\nif (!(completed & (1<<bit)))\r\ncontinue;\r\ntag = (group << 5) + bit;\r\nif (tag == MTIP_TAG_INTERNAL)\r\ncontinue;\r\ncmd = mtip_cmd_from_tag(dd, tag);\r\nif (likely(cmd->comp_func)) {\r\nset_bit(tag, tagaccum);\r\ncmd_cnt++;\r\ncmd->comp_func(port, tag, cmd, 0);\r\n} else {\r\ndev_err(&port->dd->pdev->dev,\r\n"Missing completion func for tag %d",\r\ntag);\r\nif (mtip_check_surprise_removal(dd->pdev)) {\r\nreturn;\r\n}\r\n}\r\n}\r\n}\r\nprint_tags(dd, "completed (TFE)", tagaccum, cmd_cnt);\r\nmdelay(20);\r\nmtip_restart_port(port);\r\nrv = mtip_read_log_page(dd->port, ATA_LOG_SATA_NCQ,\r\ndd->port->log_buf,\r\ndd->port->log_buf_dma, 1);\r\nif (rv) {\r\ndev_warn(&dd->pdev->dev,\r\n"Error in READ LOG EXT (10h) command\n");\r\n} else {\r\nbuf = (unsigned char *)dd->port->log_buf;\r\nif (buf[259] & 0x1) {\r\ndev_info(&dd->pdev->dev,\r\n"Write protect bit is set.\n");\r\nset_bit(MTIP_DDF_WRITE_PROTECT_BIT, &dd->dd_flag);\r\nfail_all_ncq_write = 1;\r\nfail_reason = "write protect";\r\n}\r\nif (buf[288] == 0xF7) {\r\ndev_info(&dd->pdev->dev,\r\n"Exceeded Tmax, drive in thermal shutdown.\n");\r\nset_bit(MTIP_DDF_OVER_TEMP_BIT, &dd->dd_flag);\r\nfail_all_ncq_cmds = 1;\r\nfail_reason = "thermal shutdown";\r\n}\r\nif (buf[288] == 0xBF) {\r\nset_bit(MTIP_DDF_SEC_LOCK_BIT, &dd->dd_flag);\r\ndev_info(&dd->pdev->dev,\r\n"Drive indicates rebuild has failed. Secure erase required.\n");\r\nfail_all_ncq_cmds = 1;\r\nfail_reason = "rebuild failed";\r\n}\r\n}\r\nmemset(tagaccum, 0, SLOTBITS_IN_LONGS * sizeof(long));\r\nfor (group = 0; group < dd->slot_groups; group++) {\r\nfor (bit = 0; bit < 32; bit++) {\r\nreissue = 1;\r\ntag = (group << 5) + bit;\r\ncmd = mtip_cmd_from_tag(dd, tag);\r\nfis = (struct host_to_dev_fis *)cmd->command;\r\nif (tag == MTIP_TAG_INTERNAL ||\r\nfis->command == ATA_CMD_SET_FEATURES)\r\nreissue = 0;\r\nelse {\r\nif (fail_all_ncq_cmds ||\r\n(fail_all_ncq_write &&\r\nfis->command == ATA_CMD_FPDMA_WRITE)) {\r\ndev_warn(&dd->pdev->dev,\r\n" Fail: %s w/tag %d [%s].\n",\r\nfis->command == ATA_CMD_FPDMA_WRITE ?\r\n"write" : "read",\r\ntag,\r\nfail_reason != NULL ?\r\nfail_reason : "unknown");\r\nif (cmd->comp_func) {\r\ncmd->comp_func(port, tag,\r\ncmd, -ENODATA);\r\n}\r\ncontinue;\r\n}\r\n}\r\nif (reissue && (cmd->retries-- > 0)) {\r\nset_bit(tag, tagaccum);\r\nmtip_issue_ncq_command(port, tag);\r\ncontinue;\r\n}\r\ndev_warn(&port->dd->pdev->dev,\r\n"retiring tag %d\n", tag);\r\nif (cmd->comp_func)\r\ncmd->comp_func(port, tag, cmd, PORT_IRQ_TF_ERR);\r\nelse\r\ndev_warn(&port->dd->pdev->dev,\r\n"Bad completion for tag %d\n",\r\ntag);\r\n}\r\n}\r\nprint_tags(dd, "reissued (TFE)", tagaccum, cmd_cnt);\r\nhandle_tfe_exit:\r\nclear_bit(MTIP_PF_EH_ACTIVE_BIT, &port->flags);\r\nwake_up_interruptible(&port->svc_wait);\r\n}\r\nstatic inline void mtip_workq_sdbfx(struct mtip_port *port, int group,\r\nu32 completed)\r\n{\r\nstruct driver_data *dd = port->dd;\r\nint tag, bit;\r\nstruct mtip_cmd *command;\r\nif (!completed) {\r\nWARN_ON_ONCE(!completed);\r\nreturn;\r\n}\r\nwritel(completed, port->completed[group]);\r\nfor (bit = 0; (bit < 32) && completed; bit++) {\r\nif (completed & 0x01) {\r\ntag = (group << 5) | bit;\r\nif (unlikely(tag == MTIP_TAG_INTERNAL))\r\ncontinue;\r\ncommand = mtip_cmd_from_tag(dd, tag);\r\nif (likely(command->comp_func))\r\ncommand->comp_func(port, tag, command, 0);\r\nelse {\r\ndev_dbg(&dd->pdev->dev,\r\n"Null completion for tag %d",\r\ntag);\r\nif (mtip_check_surprise_removal(\r\ndd->pdev)) {\r\nreturn;\r\n}\r\n}\r\n}\r\ncompleted >>= 1;\r\n}\r\nif (atomic_dec_return(&dd->irq_workers_active) == 0)\r\nwritel(0xffffffff, dd->mmio + HOST_IRQ_STAT);\r\n}\r\nstatic inline void mtip_process_legacy(struct driver_data *dd, u32 port_stat)\r\n{\r\nstruct mtip_port *port = dd->port;\r\nstruct mtip_cmd *cmd = mtip_cmd_from_tag(dd, MTIP_TAG_INTERNAL);\r\nif (test_bit(MTIP_PF_IC_ACTIVE_BIT, &port->flags) &&\r\n(cmd != NULL) && !(readl(port->cmd_issue[MTIP_TAG_INTERNAL])\r\n& (1 << MTIP_TAG_INTERNAL))) {\r\nif (cmd->comp_func) {\r\ncmd->comp_func(port, MTIP_TAG_INTERNAL, cmd, 0);\r\nreturn;\r\n}\r\n}\r\nreturn;\r\n}\r\nstatic inline void mtip_process_errors(struct driver_data *dd, u32 port_stat)\r\n{\r\nif (unlikely(port_stat & PORT_IRQ_CONNECT)) {\r\ndev_warn(&dd->pdev->dev,\r\n"Clearing PxSERR.DIAG.x\n");\r\nwritel((1 << 26), dd->port->mmio + PORT_SCR_ERR);\r\n}\r\nif (unlikely(port_stat & PORT_IRQ_PHYRDY)) {\r\ndev_warn(&dd->pdev->dev,\r\n"Clearing PxSERR.DIAG.n\n");\r\nwritel((1 << 16), dd->port->mmio + PORT_SCR_ERR);\r\n}\r\nif (unlikely(port_stat & ~PORT_IRQ_HANDLED)) {\r\ndev_warn(&dd->pdev->dev,\r\n"Port stat errors %x unhandled\n",\r\n(port_stat & ~PORT_IRQ_HANDLED));\r\nif (mtip_check_surprise_removal(dd->pdev))\r\nreturn;\r\n}\r\nif (likely(port_stat & (PORT_IRQ_TF_ERR | PORT_IRQ_IF_ERR))) {\r\nset_bit(MTIP_PF_EH_ACTIVE_BIT, &dd->port->flags);\r\nwake_up_interruptible(&dd->port->svc_wait);\r\n}\r\n}\r\nstatic inline irqreturn_t mtip_handle_irq(struct driver_data *data)\r\n{\r\nstruct driver_data *dd = (struct driver_data *) data;\r\nstruct mtip_port *port = dd->port;\r\nu32 hba_stat, port_stat;\r\nint rv = IRQ_NONE;\r\nint do_irq_enable = 1, i, workers;\r\nstruct mtip_work *twork;\r\nhba_stat = readl(dd->mmio + HOST_IRQ_STAT);\r\nif (hba_stat) {\r\nrv = IRQ_HANDLED;\r\nport_stat = readl(port->mmio + PORT_IRQ_STAT);\r\nwritel(port_stat, port->mmio + PORT_IRQ_STAT);\r\nif (likely(port_stat & PORT_IRQ_SDB_FIS)) {\r\ndo_irq_enable = 0;\r\nWARN_ON_ONCE(atomic_read(&dd->irq_workers_active) != 0);\r\nfor (i = 0, workers = 0; i < MTIP_MAX_SLOT_GROUPS;\r\ni++) {\r\ntwork = &dd->work[i];\r\ntwork->completed = readl(port->completed[i]);\r\nif (twork->completed)\r\nworkers++;\r\n}\r\natomic_set(&dd->irq_workers_active, workers);\r\nif (workers) {\r\nfor (i = 1; i < MTIP_MAX_SLOT_GROUPS; i++) {\r\ntwork = &dd->work[i];\r\nif (twork->completed)\r\nqueue_work_on(\r\ntwork->cpu_binding,\r\ndd->isr_workq,\r\n&twork->work);\r\n}\r\nif (likely(dd->work[0].completed))\r\nmtip_workq_sdbfx(port, 0,\r\ndd->work[0].completed);\r\n} else {\r\ndo_irq_enable = 1;\r\n}\r\n}\r\nif (unlikely(port_stat & PORT_IRQ_ERR)) {\r\nif (unlikely(mtip_check_surprise_removal(dd->pdev))) {\r\nreturn IRQ_HANDLED;\r\n}\r\nif (test_bit(MTIP_DDF_REMOVE_PENDING_BIT,\r\n&dd->dd_flag))\r\nreturn rv;\r\nmtip_process_errors(dd, port_stat & PORT_IRQ_ERR);\r\n}\r\nif (unlikely(port_stat & PORT_IRQ_LEGACY))\r\nmtip_process_legacy(dd, port_stat & PORT_IRQ_LEGACY);\r\n}\r\nif (unlikely(do_irq_enable))\r\nwritel(hba_stat, dd->mmio + HOST_IRQ_STAT);\r\nreturn rv;\r\n}\r\nstatic irqreturn_t mtip_irq_handler(int irq, void *instance)\r\n{\r\nstruct driver_data *dd = instance;\r\nreturn mtip_handle_irq(dd);\r\n}\r\nstatic void mtip_issue_non_ncq_command(struct mtip_port *port, int tag)\r\n{\r\nwritel(1 << MTIP_TAG_BIT(tag),\r\nport->cmd_issue[MTIP_TAG_INDEX(tag)]);\r\n}\r\nstatic bool mtip_pause_ncq(struct mtip_port *port,\r\nstruct host_to_dev_fis *fis)\r\n{\r\nstruct host_to_dev_fis *reply;\r\nunsigned long task_file_data;\r\nreply = port->rxfis + RX_FIS_D2H_REG;\r\ntask_file_data = readl(port->mmio+PORT_TFDATA);\r\nif (fis->command == ATA_CMD_SEC_ERASE_UNIT)\r\nclear_bit(MTIP_DDF_SEC_LOCK_BIT, &port->dd->dd_flag);\r\nif ((task_file_data & 1))\r\nreturn false;\r\nif (fis->command == ATA_CMD_SEC_ERASE_PREP) {\r\nset_bit(MTIP_PF_SE_ACTIVE_BIT, &port->flags);\r\nset_bit(MTIP_DDF_SEC_LOCK_BIT, &port->dd->dd_flag);\r\nport->ic_pause_timer = jiffies;\r\nreturn true;\r\n} else if ((fis->command == ATA_CMD_DOWNLOAD_MICRO) &&\r\n(fis->features == 0x03)) {\r\nset_bit(MTIP_PF_DM_ACTIVE_BIT, &port->flags);\r\nport->ic_pause_timer = jiffies;\r\nreturn true;\r\n} else if ((fis->command == ATA_CMD_SEC_ERASE_UNIT) ||\r\n((fis->command == 0xFC) &&\r\n(fis->features == 0x27 || fis->features == 0x72 ||\r\nfis->features == 0x62 || fis->features == 0x26))) {\r\nmtip_restart_port(port);\r\nreturn false;\r\n}\r\nreturn false;\r\n}\r\nstatic int mtip_quiesce_io(struct mtip_port *port, unsigned long timeout)\r\n{\r\nunsigned long to;\r\nunsigned int n;\r\nunsigned int active = 1;\r\nblk_mq_stop_hw_queues(port->dd->queue);\r\nto = jiffies + msecs_to_jiffies(timeout);\r\ndo {\r\nif (test_bit(MTIP_PF_SVC_THD_ACTIVE_BIT, &port->flags) &&\r\ntest_bit(MTIP_PF_ISSUE_CMDS_BIT, &port->flags)) {\r\nmsleep(20);\r\ncontinue;\r\n}\r\nmsleep(100);\r\nif (mtip_check_surprise_removal(port->dd->pdev))\r\ngoto err_fault;\r\nif (test_bit(MTIP_DDF_REMOVE_PENDING_BIT, &port->dd->dd_flag))\r\ngoto err_fault;\r\nactive = readl(port->s_active[0]) & 0xFFFFFFFE;\r\nfor (n = 1; n < port->dd->slot_groups; n++)\r\nactive |= readl(port->s_active[n]);\r\nif (!active)\r\nbreak;\r\n} while (time_before(jiffies, to));\r\nblk_mq_start_stopped_hw_queues(port->dd->queue, true);\r\nreturn active ? -EBUSY : 0;\r\nerr_fault:\r\nblk_mq_start_stopped_hw_queues(port->dd->queue, true);\r\nreturn -EFAULT;\r\n}\r\nstatic int mtip_exec_internal_command(struct mtip_port *port,\r\nstruct host_to_dev_fis *fis,\r\nint fis_len,\r\ndma_addr_t buffer,\r\nint buf_len,\r\nu32 opts,\r\ngfp_t atomic,\r\nunsigned long timeout)\r\n{\r\nstruct mtip_cmd_sg *command_sg;\r\nDECLARE_COMPLETION_ONSTACK(wait);\r\nstruct mtip_cmd *int_cmd;\r\nstruct driver_data *dd = port->dd;\r\nint rv = 0;\r\nif (buffer & 0x00000007) {\r\ndev_err(&dd->pdev->dev, "SG buffer is not 8 byte aligned\n");\r\nreturn -EFAULT;\r\n}\r\nint_cmd = mtip_get_int_command(dd);\r\nset_bit(MTIP_PF_IC_ACTIVE_BIT, &port->flags);\r\nport->ic_pause_timer = 0;\r\nclear_bit(MTIP_PF_SE_ACTIVE_BIT, &port->flags);\r\nclear_bit(MTIP_PF_DM_ACTIVE_BIT, &port->flags);\r\nif (atomic == GFP_KERNEL) {\r\nif (fis->command != ATA_CMD_STANDBYNOW1) {\r\nif (mtip_quiesce_io(port,\r\nMTIP_QUIESCE_IO_TIMEOUT_MS) < 0) {\r\ndev_warn(&dd->pdev->dev,\r\n"Failed to quiesce IO\n");\r\nmtip_put_int_command(dd, int_cmd);\r\nclear_bit(MTIP_PF_IC_ACTIVE_BIT, &port->flags);\r\nwake_up_interruptible(&port->svc_wait);\r\nreturn -EBUSY;\r\n}\r\n}\r\nint_cmd->comp_data = &wait;\r\nint_cmd->comp_func = mtip_completion;\r\n} else {\r\nint_cmd->comp_data = NULL;\r\nint_cmd->comp_func = mtip_null_completion;\r\n}\r\nmemcpy(int_cmd->command, fis, fis_len*4);\r\nint_cmd->command_header->opts =\r\n__force_bit2int cpu_to_le32(opts | fis_len);\r\nif (buf_len) {\r\ncommand_sg = int_cmd->command + AHCI_CMD_TBL_HDR_SZ;\r\ncommand_sg->info =\r\n__force_bit2int cpu_to_le32((buf_len-1) & 0x3FFFFF);\r\ncommand_sg->dba =\r\n__force_bit2int cpu_to_le32(buffer & 0xFFFFFFFF);\r\ncommand_sg->dba_upper =\r\n__force_bit2int cpu_to_le32((buffer >> 16) >> 16);\r\nint_cmd->command_header->opts |=\r\n__force_bit2int cpu_to_le32((1 << 16));\r\n}\r\nint_cmd->command_header->byte_count = 0;\r\nmtip_issue_non_ncq_command(port, MTIP_TAG_INTERNAL);\r\nif (atomic == GFP_KERNEL) {\r\nif ((rv = wait_for_completion_interruptible_timeout(\r\n&wait,\r\nmsecs_to_jiffies(timeout))) <= 0) {\r\nif (rv == -ERESTARTSYS) {\r\ndev_err(&dd->pdev->dev,\r\n"Internal command [%02X] was interrupted after %lu ms\n",\r\nfis->command, timeout);\r\nrv = -EINTR;\r\ngoto exec_ic_exit;\r\n} else if (rv == 0)\r\ndev_err(&dd->pdev->dev,\r\n"Internal command did not complete [%02X] within timeout of %lu ms\n",\r\nfis->command, timeout);\r\nelse\r\ndev_err(&dd->pdev->dev,\r\n"Internal command [%02X] wait returned code [%d] after %lu ms - unhandled\n",\r\nfis->command, rv, timeout);\r\nif (mtip_check_surprise_removal(dd->pdev) ||\r\ntest_bit(MTIP_DDF_REMOVE_PENDING_BIT,\r\n&dd->dd_flag)) {\r\ndev_err(&dd->pdev->dev,\r\n"Internal command [%02X] wait returned due to SR\n",\r\nfis->command);\r\nrv = -ENXIO;\r\ngoto exec_ic_exit;\r\n}\r\nmtip_device_reset(dd);\r\nrv = -EAGAIN;\r\ngoto exec_ic_exit;\r\n}\r\n} else {\r\nu32 hba_stat, port_stat;\r\ntimeout = jiffies + msecs_to_jiffies(timeout);\r\nwhile ((readl(port->cmd_issue[MTIP_TAG_INTERNAL])\r\n& (1 << MTIP_TAG_INTERNAL))\r\n&& time_before(jiffies, timeout)) {\r\nif (mtip_check_surprise_removal(dd->pdev)) {\r\nrv = -ENXIO;\r\ngoto exec_ic_exit;\r\n}\r\nif ((fis->command != ATA_CMD_STANDBYNOW1) &&\r\ntest_bit(MTIP_DDF_REMOVE_PENDING_BIT,\r\n&dd->dd_flag)) {\r\nrv = -ENXIO;\r\ngoto exec_ic_exit;\r\n}\r\nport_stat = readl(port->mmio + PORT_IRQ_STAT);\r\nif (!port_stat)\r\ncontinue;\r\nif (port_stat & PORT_IRQ_ERR) {\r\ndev_err(&dd->pdev->dev,\r\n"Internal command [%02X] failed\n",\r\nfis->command);\r\nmtip_device_reset(dd);\r\nrv = -EIO;\r\ngoto exec_ic_exit;\r\n} else {\r\nwritel(port_stat, port->mmio + PORT_IRQ_STAT);\r\nhba_stat = readl(dd->mmio + HOST_IRQ_STAT);\r\nif (hba_stat)\r\nwritel(hba_stat,\r\ndd->mmio + HOST_IRQ_STAT);\r\n}\r\nbreak;\r\n}\r\n}\r\nif (readl(port->cmd_issue[MTIP_TAG_INTERNAL])\r\n& (1 << MTIP_TAG_INTERNAL)) {\r\nrv = -ENXIO;\r\nif (!test_bit(MTIP_DDF_REMOVE_PENDING_BIT, &dd->dd_flag)) {\r\nmtip_device_reset(dd);\r\nrv = -EAGAIN;\r\n}\r\n}\r\nexec_ic_exit:\r\nmtip_put_int_command(dd, int_cmd);\r\nif (rv >= 0 && mtip_pause_ncq(port, fis)) {\r\nreturn rv;\r\n}\r\nclear_bit(MTIP_PF_IC_ACTIVE_BIT, &port->flags);\r\nwake_up_interruptible(&port->svc_wait);\r\nreturn rv;\r\n}\r\nstatic inline void ata_swap_string(u16 *buf, unsigned int len)\r\n{\r\nint i;\r\nfor (i = 0; i < (len/2); i++)\r\nbe16_to_cpus(&buf[i]);\r\n}\r\nstatic void mtip_set_timeout(struct driver_data *dd,\r\nstruct host_to_dev_fis *fis,\r\nunsigned int *timeout, u8 erasemode)\r\n{\r\nswitch (fis->command) {\r\ncase ATA_CMD_DOWNLOAD_MICRO:\r\n*timeout = 120000;\r\nbreak;\r\ncase ATA_CMD_SEC_ERASE_UNIT:\r\ncase 0xFC:\r\nif (erasemode)\r\n*timeout = ((*(dd->port->identify + 90) * 2) * 60000);\r\nelse\r\n*timeout = ((*(dd->port->identify + 89) * 2) * 60000);\r\nbreak;\r\ncase ATA_CMD_STANDBYNOW1:\r\n*timeout = 120000;\r\nbreak;\r\ncase 0xF7:\r\ncase 0xFA:\r\n*timeout = 60000;\r\nbreak;\r\ncase ATA_CMD_SMART:\r\n*timeout = 15000;\r\nbreak;\r\ndefault:\r\n*timeout = MTIP_IOCTL_CMD_TIMEOUT_MS;\r\nbreak;\r\n}\r\n}\r\nstatic int mtip_get_identify(struct mtip_port *port, void __user *user_buffer)\r\n{\r\nint rv = 0;\r\nstruct host_to_dev_fis fis;\r\nif (test_bit(MTIP_DDF_REMOVE_PENDING_BIT, &port->dd->dd_flag))\r\nreturn -EFAULT;\r\nmemset(&fis, 0, sizeof(struct host_to_dev_fis));\r\nfis.type = 0x27;\r\nfis.opts = 1 << 7;\r\nfis.command = ATA_CMD_ID_ATA;\r\nport->identify_valid = 0;\r\nmemset(port->identify, 0, sizeof(u16) * ATA_ID_WORDS);\r\nif (mtip_exec_internal_command(port,\r\n&fis,\r\n5,\r\nport->identify_dma,\r\nsizeof(u16) * ATA_ID_WORDS,\r\n0,\r\nGFP_KERNEL,\r\nMTIP_INT_CMD_TIMEOUT_MS)\r\n< 0) {\r\nrv = -1;\r\ngoto out;\r\n}\r\n#ifdef __LITTLE_ENDIAN\r\nata_swap_string(port->identify + 27, 40);\r\nata_swap_string(port->identify + 23, 8);\r\nata_swap_string(port->identify + 10, 20);\r\n#else\r\n{\r\nint i;\r\nfor (i = 0; i < ATA_ID_WORDS; i++)\r\nport->identify[i] = le16_to_cpu(port->identify[i]);\r\n}\r\n#endif\r\nif (port->identify[128] & 0x4)\r\nset_bit(MTIP_DDF_SEC_LOCK_BIT, &port->dd->dd_flag);\r\nelse\r\nclear_bit(MTIP_DDF_SEC_LOCK_BIT, &port->dd->dd_flag);\r\n#ifdef MTIP_TRIM\r\nif (port->identify[69] & (1 << 14) && port->identify[69] & (1 << 5))\r\nport->dd->trim_supp = true;\r\nelse\r\n#endif\r\nport->dd->trim_supp = false;\r\nport->identify_valid = 1;\r\nif (user_buffer) {\r\nif (copy_to_user(\r\nuser_buffer,\r\nport->identify,\r\nATA_ID_WORDS * sizeof(u16))) {\r\nrv = -EFAULT;\r\ngoto out;\r\n}\r\n}\r\nout:\r\nreturn rv;\r\n}\r\nstatic int mtip_standby_immediate(struct mtip_port *port)\r\n{\r\nint rv;\r\nstruct host_to_dev_fis fis;\r\nunsigned long start;\r\nunsigned int timeout;\r\nmemset(&fis, 0, sizeof(struct host_to_dev_fis));\r\nfis.type = 0x27;\r\nfis.opts = 1 << 7;\r\nfis.command = ATA_CMD_STANDBYNOW1;\r\nmtip_set_timeout(port->dd, &fis, &timeout, 0);\r\nstart = jiffies;\r\nrv = mtip_exec_internal_command(port,\r\n&fis,\r\n5,\r\n0,\r\n0,\r\n0,\r\nGFP_ATOMIC,\r\ntimeout);\r\ndbg_printk(MTIP_DRV_NAME "Time taken to complete standby cmd: %d ms\n",\r\njiffies_to_msecs(jiffies - start));\r\nif (rv)\r\ndev_warn(&port->dd->pdev->dev,\r\n"STANDBY IMMEDIATE command failed.\n");\r\nreturn rv;\r\n}\r\nstatic int mtip_read_log_page(struct mtip_port *port, u8 page, u16 *buffer,\r\ndma_addr_t buffer_dma, unsigned int sectors)\r\n{\r\nstruct host_to_dev_fis fis;\r\nmemset(&fis, 0, sizeof(struct host_to_dev_fis));\r\nfis.type = 0x27;\r\nfis.opts = 1 << 7;\r\nfis.command = ATA_CMD_READ_LOG_EXT;\r\nfis.sect_count = sectors & 0xFF;\r\nfis.sect_cnt_ex = (sectors >> 8) & 0xFF;\r\nfis.lba_low = page;\r\nfis.lba_mid = 0;\r\nfis.device = ATA_DEVICE_OBS;\r\nmemset(buffer, 0, sectors * ATA_SECT_SIZE);\r\nreturn mtip_exec_internal_command(port,\r\n&fis,\r\n5,\r\nbuffer_dma,\r\nsectors * ATA_SECT_SIZE,\r\n0,\r\nGFP_ATOMIC,\r\nMTIP_INT_CMD_TIMEOUT_MS);\r\n}\r\nstatic int mtip_get_smart_data(struct mtip_port *port, u8 *buffer,\r\ndma_addr_t buffer_dma)\r\n{\r\nstruct host_to_dev_fis fis;\r\nmemset(&fis, 0, sizeof(struct host_to_dev_fis));\r\nfis.type = 0x27;\r\nfis.opts = 1 << 7;\r\nfis.command = ATA_CMD_SMART;\r\nfis.features = 0xD0;\r\nfis.sect_count = 1;\r\nfis.lba_mid = 0x4F;\r\nfis.lba_hi = 0xC2;\r\nfis.device = ATA_DEVICE_OBS;\r\nreturn mtip_exec_internal_command(port,\r\n&fis,\r\n5,\r\nbuffer_dma,\r\nATA_SECT_SIZE,\r\n0,\r\nGFP_ATOMIC,\r\n15000);\r\n}\r\nstatic int mtip_get_smart_attr(struct mtip_port *port, unsigned int id,\r\nstruct smart_attr *attrib)\r\n{\r\nint rv, i;\r\nstruct smart_attr *pattr;\r\nif (!attrib)\r\nreturn -EINVAL;\r\nif (!port->identify_valid) {\r\ndev_warn(&port->dd->pdev->dev, "IDENTIFY DATA not valid\n");\r\nreturn -EPERM;\r\n}\r\nif (!(port->identify[82] & 0x1)) {\r\ndev_warn(&port->dd->pdev->dev, "SMART not supported\n");\r\nreturn -EPERM;\r\n}\r\nif (!(port->identify[85] & 0x1)) {\r\ndev_warn(&port->dd->pdev->dev, "SMART not enabled\n");\r\nreturn -EPERM;\r\n}\r\nmemset(port->smart_buf, 0, ATA_SECT_SIZE);\r\nrv = mtip_get_smart_data(port, port->smart_buf, port->smart_buf_dma);\r\nif (rv) {\r\ndev_warn(&port->dd->pdev->dev, "Failed to ge SMART data\n");\r\nreturn rv;\r\n}\r\npattr = (struct smart_attr *)(port->smart_buf + 2);\r\nfor (i = 0; i < 29; i++, pattr++)\r\nif (pattr->attr_id == id) {\r\nmemcpy(attrib, pattr, sizeof(struct smart_attr));\r\nbreak;\r\n}\r\nif (i == 29) {\r\ndev_warn(&port->dd->pdev->dev,\r\n"Query for invalid SMART attribute ID\n");\r\nrv = -EINVAL;\r\n}\r\nreturn rv;\r\n}\r\nstatic int mtip_send_trim(struct driver_data *dd, unsigned int lba,\r\nunsigned int len)\r\n{\r\nint i, rv = 0;\r\nu64 tlba, tlen, sect_left;\r\nstruct mtip_trim_entry *buf;\r\ndma_addr_t dma_addr;\r\nstruct host_to_dev_fis fis;\r\nif (!len || dd->trim_supp == false)\r\nreturn -EINVAL;\r\nWARN_ON(len > (MTIP_MAX_TRIM_ENTRY_LEN * MTIP_MAX_TRIM_ENTRIES));\r\nWARN_ON(len % 8 != 0);\r\nWARN_ON(sizeof(struct mtip_trim) > ATA_SECT_SIZE);\r\nbuf = dmam_alloc_coherent(&dd->pdev->dev, ATA_SECT_SIZE, &dma_addr,\r\nGFP_KERNEL);\r\nif (!buf)\r\nreturn -ENOMEM;\r\nmemset(buf, 0, ATA_SECT_SIZE);\r\nfor (i = 0, sect_left = len, tlba = lba;\r\ni < MTIP_MAX_TRIM_ENTRIES && sect_left;\r\ni++) {\r\ntlen = (sect_left >= MTIP_MAX_TRIM_ENTRY_LEN ?\r\nMTIP_MAX_TRIM_ENTRY_LEN :\r\nsect_left);\r\nbuf[i].lba = __force_bit2int cpu_to_le32(tlba);\r\nbuf[i].range = __force_bit2int cpu_to_le16(tlen);\r\ntlba += tlen;\r\nsect_left -= tlen;\r\n}\r\nWARN_ON(sect_left != 0);\r\nmemset(&fis, 0, sizeof(struct host_to_dev_fis));\r\nfis.type = 0x27;\r\nfis.opts = 1 << 7;\r\nfis.command = 0xfb;\r\nfis.features = 0x60;\r\nfis.sect_count = 1;\r\nfis.device = ATA_DEVICE_OBS;\r\nif (mtip_exec_internal_command(dd->port,\r\n&fis,\r\n5,\r\ndma_addr,\r\nATA_SECT_SIZE,\r\n0,\r\nGFP_KERNEL,\r\nMTIP_TRIM_TIMEOUT_MS) < 0)\r\nrv = -EIO;\r\ndmam_free_coherent(&dd->pdev->dev, ATA_SECT_SIZE, buf, dma_addr);\r\nreturn rv;\r\n}\r\nstatic bool mtip_hw_get_capacity(struct driver_data *dd, sector_t *sectors)\r\n{\r\nstruct mtip_port *port = dd->port;\r\nu64 total, raw0, raw1, raw2, raw3;\r\nraw0 = port->identify[100];\r\nraw1 = port->identify[101];\r\nraw2 = port->identify[102];\r\nraw3 = port->identify[103];\r\ntotal = raw0 | raw1<<16 | raw2<<32 | raw3<<48;\r\n*sectors = total;\r\nreturn (bool) !!port->identify_valid;\r\n}\r\nstatic void mtip_dump_identify(struct mtip_port *port)\r\n{\r\nsector_t sectors;\r\nunsigned short revid;\r\nchar cbuf[42];\r\nif (!port->identify_valid)\r\nreturn;\r\nstrlcpy(cbuf, (char *)(port->identify+10), 21);\r\ndev_info(&port->dd->pdev->dev,\r\n"Serial No.: %s\n", cbuf);\r\nstrlcpy(cbuf, (char *)(port->identify+23), 9);\r\ndev_info(&port->dd->pdev->dev,\r\n"Firmware Ver.: %s\n", cbuf);\r\nstrlcpy(cbuf, (char *)(port->identify+27), 41);\r\ndev_info(&port->dd->pdev->dev, "Model: %s\n", cbuf);\r\ndev_info(&port->dd->pdev->dev, "Security: %04x %s\n",\r\nport->identify[128],\r\nport->identify[128] & 0x4 ? "(LOCKED)" : "");\r\nif (mtip_hw_get_capacity(port->dd, &sectors))\r\ndev_info(&port->dd->pdev->dev,\r\n"Capacity: %llu sectors (%llu MB)\n",\r\n(u64)sectors,\r\n((u64)sectors) * ATA_SECT_SIZE >> 20);\r\npci_read_config_word(port->dd->pdev, PCI_REVISION_ID, &revid);\r\nswitch (revid & 0xFF) {\r\ncase 0x1:\r\nstrlcpy(cbuf, "A0", 3);\r\nbreak;\r\ncase 0x3:\r\nstrlcpy(cbuf, "A2", 3);\r\nbreak;\r\ndefault:\r\nstrlcpy(cbuf, "?", 2);\r\nbreak;\r\n}\r\ndev_info(&port->dd->pdev->dev,\r\n"Card Type: %s\n", cbuf);\r\n}\r\nstatic inline void fill_command_sg(struct driver_data *dd,\r\nstruct mtip_cmd *command,\r\nint nents)\r\n{\r\nint n;\r\nunsigned int dma_len;\r\nstruct mtip_cmd_sg *command_sg;\r\nstruct scatterlist *sg = command->sg;\r\ncommand_sg = command->command + AHCI_CMD_TBL_HDR_SZ;\r\nfor (n = 0; n < nents; n++) {\r\ndma_len = sg_dma_len(sg);\r\nif (dma_len > 0x400000)\r\ndev_err(&dd->pdev->dev,\r\n"DMA segment length truncated\n");\r\ncommand_sg->info = __force_bit2int\r\ncpu_to_le32((dma_len-1) & 0x3FFFFF);\r\ncommand_sg->dba = __force_bit2int\r\ncpu_to_le32(sg_dma_address(sg));\r\ncommand_sg->dba_upper = __force_bit2int\r\ncpu_to_le32((sg_dma_address(sg) >> 16) >> 16);\r\ncommand_sg++;\r\nsg++;\r\n}\r\n}\r\nstatic int exec_drive_task(struct mtip_port *port, u8 *command)\r\n{\r\nstruct host_to_dev_fis fis;\r\nstruct host_to_dev_fis *reply = (port->rxfis + RX_FIS_D2H_REG);\r\nunsigned int to;\r\nmemset(&fis, 0, sizeof(struct host_to_dev_fis));\r\nfis.type = 0x27;\r\nfis.opts = 1 << 7;\r\nfis.command = command[0];\r\nfis.features = command[1];\r\nfis.sect_count = command[2];\r\nfis.sector = command[3];\r\nfis.cyl_low = command[4];\r\nfis.cyl_hi = command[5];\r\nfis.device = command[6] & ~0x10;\r\nmtip_set_timeout(port->dd, &fis, &to, 0);\r\ndbg_printk(MTIP_DRV_NAME " %s: User Command: cmd %x, feat %x, nsect %x, sect %x, lcyl %x, hcyl %x, sel %x\n",\r\n__func__,\r\ncommand[0],\r\ncommand[1],\r\ncommand[2],\r\ncommand[3],\r\ncommand[4],\r\ncommand[5],\r\ncommand[6]);\r\nif (mtip_exec_internal_command(port,\r\n&fis,\r\n5,\r\n0,\r\n0,\r\n0,\r\nGFP_KERNEL,\r\nto) < 0) {\r\nreturn -1;\r\n}\r\ncommand[0] = reply->command;\r\ncommand[1] = reply->features;\r\ncommand[4] = reply->cyl_low;\r\ncommand[5] = reply->cyl_hi;\r\ndbg_printk(MTIP_DRV_NAME " %s: Completion Status: stat %x, err %x , cyl_lo %x cyl_hi %x\n",\r\n__func__,\r\ncommand[0],\r\ncommand[1],\r\ncommand[4],\r\ncommand[5]);\r\nreturn 0;\r\n}\r\nstatic int exec_drive_command(struct mtip_port *port, u8 *command,\r\nvoid __user *user_buffer)\r\n{\r\nstruct host_to_dev_fis fis;\r\nstruct host_to_dev_fis *reply;\r\nu8 *buf = NULL;\r\ndma_addr_t dma_addr = 0;\r\nint rv = 0, xfer_sz = command[3];\r\nunsigned int to;\r\nif (xfer_sz) {\r\nif (!user_buffer)\r\nreturn -EFAULT;\r\nbuf = dmam_alloc_coherent(&port->dd->pdev->dev,\r\nATA_SECT_SIZE * xfer_sz,\r\n&dma_addr,\r\nGFP_KERNEL);\r\nif (!buf) {\r\ndev_err(&port->dd->pdev->dev,\r\n"Memory allocation failed (%d bytes)\n",\r\nATA_SECT_SIZE * xfer_sz);\r\nreturn -ENOMEM;\r\n}\r\nmemset(buf, 0, ATA_SECT_SIZE * xfer_sz);\r\n}\r\nmemset(&fis, 0, sizeof(struct host_to_dev_fis));\r\nfis.type = 0x27;\r\nfis.opts = 1 << 7;\r\nfis.command = command[0];\r\nfis.features = command[2];\r\nfis.sect_count = command[3];\r\nif (fis.command == ATA_CMD_SMART) {\r\nfis.sector = command[1];\r\nfis.cyl_low = 0x4F;\r\nfis.cyl_hi = 0xC2;\r\n}\r\nmtip_set_timeout(port->dd, &fis, &to, 0);\r\nif (xfer_sz)\r\nreply = (port->rxfis + RX_FIS_PIO_SETUP);\r\nelse\r\nreply = (port->rxfis + RX_FIS_D2H_REG);\r\ndbg_printk(MTIP_DRV_NAME\r\n" %s: User Command: cmd %x, sect %x, "\r\n"feat %x, sectcnt %x\n",\r\n__func__,\r\ncommand[0],\r\ncommand[1],\r\ncommand[2],\r\ncommand[3]);\r\nif (mtip_exec_internal_command(port,\r\n&fis,\r\n5,\r\n(xfer_sz ? dma_addr : 0),\r\n(xfer_sz ? ATA_SECT_SIZE * xfer_sz : 0),\r\n0,\r\nGFP_KERNEL,\r\nto)\r\n< 0) {\r\nrv = -EFAULT;\r\ngoto exit_drive_command;\r\n}\r\ncommand[0] = reply->command;\r\ncommand[1] = reply->features;\r\ncommand[2] = reply->sect_count;\r\ndbg_printk(MTIP_DRV_NAME\r\n" %s: Completion Status: stat %x, "\r\n"err %x, nsect %x\n",\r\n__func__,\r\ncommand[0],\r\ncommand[1],\r\ncommand[2]);\r\nif (xfer_sz) {\r\nif (copy_to_user(user_buffer,\r\nbuf,\r\nATA_SECT_SIZE * command[3])) {\r\nrv = -EFAULT;\r\ngoto exit_drive_command;\r\n}\r\n}\r\nexit_drive_command:\r\nif (buf)\r\ndmam_free_coherent(&port->dd->pdev->dev,\r\nATA_SECT_SIZE * xfer_sz, buf, dma_addr);\r\nreturn rv;\r\n}\r\nstatic unsigned int implicit_sector(unsigned char command,\r\nunsigned char features)\r\n{\r\nunsigned int rv = 0;\r\nswitch (command) {\r\ncase ATA_CMD_SEC_SET_PASS:\r\ncase ATA_CMD_SEC_UNLOCK:\r\ncase ATA_CMD_SEC_ERASE_PREP:\r\ncase ATA_CMD_SEC_ERASE_UNIT:\r\ncase ATA_CMD_SEC_FREEZE_LOCK:\r\ncase ATA_CMD_SEC_DISABLE_PASS:\r\ncase ATA_CMD_PMP_READ:\r\ncase ATA_CMD_PMP_WRITE:\r\nrv = 1;\r\nbreak;\r\ncase ATA_CMD_SET_MAX:\r\nif (features == ATA_SET_MAX_UNLOCK)\r\nrv = 1;\r\nbreak;\r\ncase ATA_CMD_SMART:\r\nif ((features == ATA_SMART_READ_VALUES) ||\r\n(features == ATA_SMART_READ_THRESHOLDS))\r\nrv = 1;\r\nbreak;\r\ncase ATA_CMD_CONF_OVERLAY:\r\nif ((features == ATA_DCO_IDENTIFY) ||\r\n(features == ATA_DCO_SET))\r\nrv = 1;\r\nbreak;\r\n}\r\nreturn rv;\r\n}\r\nstatic int exec_drive_taskfile(struct driver_data *dd,\r\nvoid __user *buf,\r\nide_task_request_t *req_task,\r\nint outtotal)\r\n{\r\nstruct host_to_dev_fis fis;\r\nstruct host_to_dev_fis *reply;\r\nu8 *outbuf = NULL;\r\nu8 *inbuf = NULL;\r\ndma_addr_t outbuf_dma = 0;\r\ndma_addr_t inbuf_dma = 0;\r\ndma_addr_t dma_buffer = 0;\r\nint err = 0;\r\nunsigned int taskin = 0;\r\nunsigned int taskout = 0;\r\nu8 nsect = 0;\r\nunsigned int timeout;\r\nunsigned int force_single_sector;\r\nunsigned int transfer_size;\r\nunsigned long task_file_data;\r\nint intotal = outtotal + req_task->out_size;\r\nint erasemode = 0;\r\ntaskout = req_task->out_size;\r\ntaskin = req_task->in_size;\r\nif (taskin > 130560 || taskout > 130560) {\r\nerr = -EINVAL;\r\ngoto abort;\r\n}\r\nif (taskout) {\r\noutbuf = kzalloc(taskout, GFP_KERNEL);\r\nif (outbuf == NULL) {\r\nerr = -ENOMEM;\r\ngoto abort;\r\n}\r\nif (copy_from_user(outbuf, buf + outtotal, taskout)) {\r\nerr = -EFAULT;\r\ngoto abort;\r\n}\r\noutbuf_dma = pci_map_single(dd->pdev,\r\noutbuf,\r\ntaskout,\r\nDMA_TO_DEVICE);\r\nif (outbuf_dma == 0) {\r\nerr = -ENOMEM;\r\ngoto abort;\r\n}\r\ndma_buffer = outbuf_dma;\r\n}\r\nif (taskin) {\r\ninbuf = kzalloc(taskin, GFP_KERNEL);\r\nif (inbuf == NULL) {\r\nerr = -ENOMEM;\r\ngoto abort;\r\n}\r\nif (copy_from_user(inbuf, buf + intotal, taskin)) {\r\nerr = -EFAULT;\r\ngoto abort;\r\n}\r\ninbuf_dma = pci_map_single(dd->pdev,\r\ninbuf,\r\ntaskin, DMA_FROM_DEVICE);\r\nif (inbuf_dma == 0) {\r\nerr = -ENOMEM;\r\ngoto abort;\r\n}\r\ndma_buffer = inbuf_dma;\r\n}\r\nswitch (req_task->data_phase) {\r\ncase TASKFILE_OUT:\r\nnsect = taskout / ATA_SECT_SIZE;\r\nreply = (dd->port->rxfis + RX_FIS_PIO_SETUP);\r\nbreak;\r\ncase TASKFILE_IN:\r\nreply = (dd->port->rxfis + RX_FIS_PIO_SETUP);\r\nbreak;\r\ncase TASKFILE_NO_DATA:\r\nreply = (dd->port->rxfis + RX_FIS_D2H_REG);\r\nbreak;\r\ndefault:\r\nerr = -EINVAL;\r\ngoto abort;\r\n}\r\nmemset(&fis, 0, sizeof(struct host_to_dev_fis));\r\nfis.type = 0x27;\r\nfis.opts = 1 << 7;\r\nfis.command = req_task->io_ports[7];\r\nfis.features = req_task->io_ports[1];\r\nfis.sect_count = req_task->io_ports[2];\r\nfis.lba_low = req_task->io_ports[3];\r\nfis.lba_mid = req_task->io_ports[4];\r\nfis.lba_hi = req_task->io_ports[5];\r\nfis.device = req_task->io_ports[6] & ~0x10;\r\nif ((req_task->in_flags.all == 0) && (req_task->out_flags.all & 1)) {\r\nreq_task->in_flags.all =\r\nIDE_TASKFILE_STD_IN_FLAGS |\r\n(IDE_HOB_STD_IN_FLAGS << 8);\r\nfis.lba_low_ex = req_task->hob_ports[3];\r\nfis.lba_mid_ex = req_task->hob_ports[4];\r\nfis.lba_hi_ex = req_task->hob_ports[5];\r\nfis.features_ex = req_task->hob_ports[1];\r\nfis.sect_cnt_ex = req_task->hob_ports[2];\r\n} else {\r\nreq_task->in_flags.all = IDE_TASKFILE_STD_IN_FLAGS;\r\n}\r\nforce_single_sector = implicit_sector(fis.command, fis.features);\r\nif ((taskin || taskout) && (!fis.sect_count)) {\r\nif (nsect)\r\nfis.sect_count = nsect;\r\nelse {\r\nif (!force_single_sector) {\r\ndev_warn(&dd->pdev->dev,\r\n"data movement but "\r\n"sect_count is 0\n");\r\nerr = -EINVAL;\r\ngoto abort;\r\n}\r\n}\r\n}\r\ndbg_printk(MTIP_DRV_NAME\r\n" %s: cmd %x, feat %x, nsect %x,"\r\n" sect/lbal %x, lcyl/lbam %x, hcyl/lbah %x,"\r\n" head/dev %x\n",\r\n__func__,\r\nfis.command,\r\nfis.features,\r\nfis.sect_count,\r\nfis.lba_low,\r\nfis.lba_mid,\r\nfis.lba_hi,\r\nfis.device);\r\nif ((fis.command == ATA_CMD_SEC_ERASE_UNIT) && outbuf &&\r\n(outbuf[0] & MTIP_SEC_ERASE_MODE)) {\r\nerasemode = 1;\r\n}\r\nmtip_set_timeout(dd, &fis, &timeout, erasemode);\r\nif (force_single_sector)\r\ntransfer_size = ATA_SECT_SIZE;\r\nelse\r\ntransfer_size = ATA_SECT_SIZE * fis.sect_count;\r\nif (mtip_exec_internal_command(dd->port,\r\n&fis,\r\n5,\r\ndma_buffer,\r\ntransfer_size,\r\n0,\r\nGFP_KERNEL,\r\ntimeout) < 0) {\r\nerr = -EIO;\r\ngoto abort;\r\n}\r\ntask_file_data = readl(dd->port->mmio+PORT_TFDATA);\r\nif ((req_task->data_phase == TASKFILE_IN) && !(task_file_data & 1)) {\r\nreply = dd->port->rxfis + RX_FIS_PIO_SETUP;\r\nreq_task->io_ports[7] = reply->control;\r\n} else {\r\nreply = dd->port->rxfis + RX_FIS_D2H_REG;\r\nreq_task->io_ports[7] = reply->command;\r\n}\r\nif (inbuf_dma)\r\npci_unmap_single(dd->pdev, inbuf_dma,\r\ntaskin, DMA_FROM_DEVICE);\r\nif (outbuf_dma)\r\npci_unmap_single(dd->pdev, outbuf_dma,\r\ntaskout, DMA_TO_DEVICE);\r\ninbuf_dma = 0;\r\noutbuf_dma = 0;\r\nreq_task->io_ports[1] = reply->features;\r\nreq_task->io_ports[2] = reply->sect_count;\r\nreq_task->io_ports[3] = reply->lba_low;\r\nreq_task->io_ports[4] = reply->lba_mid;\r\nreq_task->io_ports[5] = reply->lba_hi;\r\nreq_task->io_ports[6] = reply->device;\r\nif (req_task->out_flags.all & 1) {\r\nreq_task->hob_ports[3] = reply->lba_low_ex;\r\nreq_task->hob_ports[4] = reply->lba_mid_ex;\r\nreq_task->hob_ports[5] = reply->lba_hi_ex;\r\nreq_task->hob_ports[1] = reply->features_ex;\r\nreq_task->hob_ports[2] = reply->sect_cnt_ex;\r\n}\r\ndbg_printk(MTIP_DRV_NAME\r\n" %s: Completion: stat %x,"\r\n"err %x, sect_cnt %x, lbalo %x,"\r\n"lbamid %x, lbahi %x, dev %x\n",\r\n__func__,\r\nreq_task->io_ports[7],\r\nreq_task->io_ports[1],\r\nreq_task->io_ports[2],\r\nreq_task->io_ports[3],\r\nreq_task->io_ports[4],\r\nreq_task->io_ports[5],\r\nreq_task->io_ports[6]);\r\nif (taskout) {\r\nif (copy_to_user(buf + outtotal, outbuf, taskout)) {\r\nerr = -EFAULT;\r\ngoto abort;\r\n}\r\n}\r\nif (taskin) {\r\nif (copy_to_user(buf + intotal, inbuf, taskin)) {\r\nerr = -EFAULT;\r\ngoto abort;\r\n}\r\n}\r\nabort:\r\nif (inbuf_dma)\r\npci_unmap_single(dd->pdev, inbuf_dma,\r\ntaskin, DMA_FROM_DEVICE);\r\nif (outbuf_dma)\r\npci_unmap_single(dd->pdev, outbuf_dma,\r\ntaskout, DMA_TO_DEVICE);\r\nkfree(outbuf);\r\nkfree(inbuf);\r\nreturn err;\r\n}\r\nstatic int mtip_hw_ioctl(struct driver_data *dd, unsigned int cmd,\r\nunsigned long arg)\r\n{\r\nswitch (cmd) {\r\ncase HDIO_GET_IDENTITY:\r\n{\r\nif (copy_to_user((void __user *)arg, dd->port->identify,\r\nsizeof(u16) * ATA_ID_WORDS))\r\nreturn -EFAULT;\r\nbreak;\r\n}\r\ncase HDIO_DRIVE_CMD:\r\n{\r\nu8 drive_command[4];\r\nif (copy_from_user(drive_command,\r\n(void __user *) arg,\r\nsizeof(drive_command)))\r\nreturn -EFAULT;\r\nif (exec_drive_command(dd->port,\r\ndrive_command,\r\n(void __user *) (arg+4)))\r\nreturn -EIO;\r\nif (copy_to_user((void __user *) arg,\r\ndrive_command,\r\nsizeof(drive_command)))\r\nreturn -EFAULT;\r\nbreak;\r\n}\r\ncase HDIO_DRIVE_TASK:\r\n{\r\nu8 drive_command[7];\r\nif (copy_from_user(drive_command,\r\n(void __user *) arg,\r\nsizeof(drive_command)))\r\nreturn -EFAULT;\r\nif (exec_drive_task(dd->port, drive_command))\r\nreturn -EIO;\r\nif (copy_to_user((void __user *) arg,\r\ndrive_command,\r\nsizeof(drive_command)))\r\nreturn -EFAULT;\r\nbreak;\r\n}\r\ncase HDIO_DRIVE_TASKFILE: {\r\nide_task_request_t req_task;\r\nint ret, outtotal;\r\nif (copy_from_user(&req_task, (void __user *) arg,\r\nsizeof(req_task)))\r\nreturn -EFAULT;\r\nouttotal = sizeof(req_task);\r\nret = exec_drive_taskfile(dd, (void __user *) arg,\r\n&req_task, outtotal);\r\nif (copy_to_user((void __user *) arg, &req_task,\r\nsizeof(req_task)))\r\nreturn -EFAULT;\r\nreturn ret;\r\n}\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic void mtip_hw_submit_io(struct driver_data *dd, struct request *rq,\r\nstruct mtip_cmd *command, int nents,\r\nstruct blk_mq_hw_ctx *hctx)\r\n{\r\nstruct host_to_dev_fis *fis;\r\nstruct mtip_port *port = dd->port;\r\nint dma_dir = rq_data_dir(rq) == READ ? DMA_FROM_DEVICE : DMA_TO_DEVICE;\r\nu64 start = blk_rq_pos(rq);\r\nunsigned int nsect = blk_rq_sectors(rq);\r\nnents = dma_map_sg(&dd->pdev->dev, command->sg, nents, dma_dir);\r\nprefetch(&port->flags);\r\ncommand->scatter_ents = nents;\r\ncommand->retries = MTIP_MAX_RETRIES;\r\nfis = command->command;\r\nfis->type = 0x27;\r\nfis->opts = 1 << 7;\r\nif (dma_dir == DMA_FROM_DEVICE)\r\nfis->command = ATA_CMD_FPDMA_READ;\r\nelse\r\nfis->command = ATA_CMD_FPDMA_WRITE;\r\nfis->lba_low = start & 0xFF;\r\nfis->lba_mid = (start >> 8) & 0xFF;\r\nfis->lba_hi = (start >> 16) & 0xFF;\r\nfis->lba_low_ex = (start >> 24) & 0xFF;\r\nfis->lba_mid_ex = (start >> 32) & 0xFF;\r\nfis->lba_hi_ex = (start >> 40) & 0xFF;\r\nfis->device = 1 << 6;\r\nfis->features = nsect & 0xFF;\r\nfis->features_ex = (nsect >> 8) & 0xFF;\r\nfis->sect_count = ((rq->tag << 3) | (rq->tag >> 5));\r\nfis->sect_cnt_ex = 0;\r\nfis->control = 0;\r\nfis->res2 = 0;\r\nfis->res3 = 0;\r\nfill_command_sg(dd, command, nents);\r\nif (unlikely(command->unaligned))\r\nfis->device |= 1 << 7;\r\ncommand->command_header->opts =\r\n__force_bit2int cpu_to_le32(\r\n(nents << 16) | 5 | AHCI_CMD_PREFETCH);\r\ncommand->command_header->byte_count = 0;\r\ncommand->comp_data = dd;\r\ncommand->comp_func = mtip_async_complete;\r\ncommand->direction = dma_dir;\r\nif (unlikely(port->flags & MTIP_PF_PAUSE_IO)) {\r\nset_bit(rq->tag, port->cmds_to_issue);\r\nset_bit(MTIP_PF_ISSUE_CMDS_BIT, &port->flags);\r\nreturn;\r\n}\r\nmtip_issue_ncq_command(port, rq->tag);\r\n}\r\nstatic ssize_t mtip_hw_show_status(struct device *dev,\r\nstruct device_attribute *attr,\r\nchar *buf)\r\n{\r\nstruct driver_data *dd = dev_to_disk(dev)->private_data;\r\nint size = 0;\r\nif (test_bit(MTIP_DDF_OVER_TEMP_BIT, &dd->dd_flag))\r\nsize += sprintf(buf, "%s", "thermal_shutdown\n");\r\nelse if (test_bit(MTIP_DDF_WRITE_PROTECT_BIT, &dd->dd_flag))\r\nsize += sprintf(buf, "%s", "write_protect\n");\r\nelse\r\nsize += sprintf(buf, "%s", "online\n");\r\nreturn size;\r\n}\r\nstatic ssize_t show_device_status(struct device_driver *drv, char *buf)\r\n{\r\nint size = 0;\r\nstruct driver_data *dd, *tmp;\r\nunsigned long flags;\r\nchar id_buf[42];\r\nu16 status = 0;\r\nspin_lock_irqsave(&dev_lock, flags);\r\nsize += sprintf(&buf[size], "Devices Present:\n");\r\nlist_for_each_entry_safe(dd, tmp, &online_list, online_list) {\r\nif (dd->pdev) {\r\nif (dd->port &&\r\ndd->port->identify &&\r\ndd->port->identify_valid) {\r\nstrlcpy(id_buf,\r\n(char *) (dd->port->identify + 10), 21);\r\nstatus = *(dd->port->identify + 141);\r\n} else {\r\nmemset(id_buf, 0, 42);\r\nstatus = 0;\r\n}\r\nif (dd->port &&\r\ntest_bit(MTIP_PF_REBUILD_BIT, &dd->port->flags)) {\r\nsize += sprintf(&buf[size],\r\n" device %s %s (ftl rebuild %d %%)\n",\r\ndev_name(&dd->pdev->dev),\r\nid_buf,\r\nstatus);\r\n} else {\r\nsize += sprintf(&buf[size],\r\n" device %s %s\n",\r\ndev_name(&dd->pdev->dev),\r\nid_buf);\r\n}\r\n}\r\n}\r\nsize += sprintf(&buf[size], "Devices Being Removed:\n");\r\nlist_for_each_entry_safe(dd, tmp, &removing_list, remove_list) {\r\nif (dd->pdev) {\r\nif (dd->port &&\r\ndd->port->identify &&\r\ndd->port->identify_valid) {\r\nstrlcpy(id_buf,\r\n(char *) (dd->port->identify+10), 21);\r\nstatus = *(dd->port->identify + 141);\r\n} else {\r\nmemset(id_buf, 0, 42);\r\nstatus = 0;\r\n}\r\nif (dd->port &&\r\ntest_bit(MTIP_PF_REBUILD_BIT, &dd->port->flags)) {\r\nsize += sprintf(&buf[size],\r\n" device %s %s (ftl rebuild %d %%)\n",\r\ndev_name(&dd->pdev->dev),\r\nid_buf,\r\nstatus);\r\n} else {\r\nsize += sprintf(&buf[size],\r\n" device %s %s\n",\r\ndev_name(&dd->pdev->dev),\r\nid_buf);\r\n}\r\n}\r\n}\r\nspin_unlock_irqrestore(&dev_lock, flags);\r\nreturn size;\r\n}\r\nstatic ssize_t mtip_hw_read_device_status(struct file *f, char __user *ubuf,\r\nsize_t len, loff_t *offset)\r\n{\r\nstruct driver_data *dd = (struct driver_data *)f->private_data;\r\nint size = *offset;\r\nchar *buf;\r\nint rv = 0;\r\nif (!len || *offset)\r\nreturn 0;\r\nbuf = kzalloc(MTIP_DFS_MAX_BUF_SIZE, GFP_KERNEL);\r\nif (!buf) {\r\ndev_err(&dd->pdev->dev,\r\n"Memory allocation: status buffer\n");\r\nreturn -ENOMEM;\r\n}\r\nsize += show_device_status(NULL, buf);\r\n*offset = size <= len ? size : len;\r\nsize = copy_to_user(ubuf, buf, *offset);\r\nif (size)\r\nrv = -EFAULT;\r\nkfree(buf);\r\nreturn rv ? rv : *offset;\r\n}\r\nstatic ssize_t mtip_hw_read_registers(struct file *f, char __user *ubuf,\r\nsize_t len, loff_t *offset)\r\n{\r\nstruct driver_data *dd = (struct driver_data *)f->private_data;\r\nchar *buf;\r\nu32 group_allocated;\r\nint size = *offset;\r\nint n, rv = 0;\r\nif (!len || size)\r\nreturn 0;\r\nbuf = kzalloc(MTIP_DFS_MAX_BUF_SIZE, GFP_KERNEL);\r\nif (!buf) {\r\ndev_err(&dd->pdev->dev,\r\n"Memory allocation: register buffer\n");\r\nreturn -ENOMEM;\r\n}\r\nsize += sprintf(&buf[size], "H/ S ACTive : [ 0x");\r\nfor (n = dd->slot_groups-1; n >= 0; n--)\r\nsize += sprintf(&buf[size], "%08X ",\r\nreadl(dd->port->s_active[n]));\r\nsize += sprintf(&buf[size], "]\n");\r\nsize += sprintf(&buf[size], "H/ Command Issue : [ 0x");\r\nfor (n = dd->slot_groups-1; n >= 0; n--)\r\nsize += sprintf(&buf[size], "%08X ",\r\nreadl(dd->port->cmd_issue[n]));\r\nsize += sprintf(&buf[size], "]\n");\r\nsize += sprintf(&buf[size], "H/ Completed : [ 0x");\r\nfor (n = dd->slot_groups-1; n >= 0; n--)\r\nsize += sprintf(&buf[size], "%08X ",\r\nreadl(dd->port->completed[n]));\r\nsize += sprintf(&buf[size], "]\n");\r\nsize += sprintf(&buf[size], "H/ PORT IRQ STAT : [ 0x%08X ]\n",\r\nreadl(dd->port->mmio + PORT_IRQ_STAT));\r\nsize += sprintf(&buf[size], "H/ HOST IRQ STAT : [ 0x%08X ]\n",\r\nreadl(dd->mmio + HOST_IRQ_STAT));\r\nsize += sprintf(&buf[size], "\n");\r\nsize += sprintf(&buf[size], "L/ Allocated : [ 0x");\r\nfor (n = dd->slot_groups-1; n >= 0; n--) {\r\nif (sizeof(long) > sizeof(u32))\r\ngroup_allocated =\r\ndd->port->allocated[n/2] >> (32*(n&1));\r\nelse\r\ngroup_allocated = dd->port->allocated[n];\r\nsize += sprintf(&buf[size], "%08X ", group_allocated);\r\n}\r\nsize += sprintf(&buf[size], "]\n");\r\nsize += sprintf(&buf[size], "L/ Commands in Q : [ 0x");\r\nfor (n = dd->slot_groups-1; n >= 0; n--) {\r\nif (sizeof(long) > sizeof(u32))\r\ngroup_allocated =\r\ndd->port->cmds_to_issue[n/2] >> (32*(n&1));\r\nelse\r\ngroup_allocated = dd->port->cmds_to_issue[n];\r\nsize += sprintf(&buf[size], "%08X ", group_allocated);\r\n}\r\nsize += sprintf(&buf[size], "]\n");\r\n*offset = size <= len ? size : len;\r\nsize = copy_to_user(ubuf, buf, *offset);\r\nif (size)\r\nrv = -EFAULT;\r\nkfree(buf);\r\nreturn rv ? rv : *offset;\r\n}\r\nstatic ssize_t mtip_hw_read_flags(struct file *f, char __user *ubuf,\r\nsize_t len, loff_t *offset)\r\n{\r\nstruct driver_data *dd = (struct driver_data *)f->private_data;\r\nchar *buf;\r\nint size = *offset;\r\nint rv = 0;\r\nif (!len || size)\r\nreturn 0;\r\nbuf = kzalloc(MTIP_DFS_MAX_BUF_SIZE, GFP_KERNEL);\r\nif (!buf) {\r\ndev_err(&dd->pdev->dev,\r\n"Memory allocation: flag buffer\n");\r\nreturn -ENOMEM;\r\n}\r\nsize += sprintf(&buf[size], "Flag-port : [ %08lX ]\n",\r\ndd->port->flags);\r\nsize += sprintf(&buf[size], "Flag-dd : [ %08lX ]\n",\r\ndd->dd_flag);\r\n*offset = size <= len ? size : len;\r\nsize = copy_to_user(ubuf, buf, *offset);\r\nif (size)\r\nrv = -EFAULT;\r\nkfree(buf);\r\nreturn rv ? rv : *offset;\r\n}\r\nstatic int mtip_hw_sysfs_init(struct driver_data *dd, struct kobject *kobj)\r\n{\r\nif (!kobj || !dd)\r\nreturn -EINVAL;\r\nif (sysfs_create_file(kobj, &dev_attr_status.attr))\r\ndev_warn(&dd->pdev->dev,\r\n"Error creating 'status' sysfs entry\n");\r\nreturn 0;\r\n}\r\nstatic int mtip_hw_sysfs_exit(struct driver_data *dd, struct kobject *kobj)\r\n{\r\nif (!kobj || !dd)\r\nreturn -EINVAL;\r\nsysfs_remove_file(kobj, &dev_attr_status.attr);\r\nreturn 0;\r\n}\r\nstatic int mtip_hw_debugfs_init(struct driver_data *dd)\r\n{\r\nif (!dfs_parent)\r\nreturn -1;\r\ndd->dfs_node = debugfs_create_dir(dd->disk->disk_name, dfs_parent);\r\nif (IS_ERR_OR_NULL(dd->dfs_node)) {\r\ndev_warn(&dd->pdev->dev,\r\n"Error creating node %s under debugfs\n",\r\ndd->disk->disk_name);\r\ndd->dfs_node = NULL;\r\nreturn -1;\r\n}\r\ndebugfs_create_file("flags", S_IRUGO, dd->dfs_node, dd,\r\n&mtip_flags_fops);\r\ndebugfs_create_file("registers", S_IRUGO, dd->dfs_node, dd,\r\n&mtip_regs_fops);\r\nreturn 0;\r\n}\r\nstatic void mtip_hw_debugfs_exit(struct driver_data *dd)\r\n{\r\nif (dd->dfs_node)\r\ndebugfs_remove_recursive(dd->dfs_node);\r\n}\r\nstatic int mtip_free_orphan(struct driver_data *dd)\r\n{\r\nstruct kobject *kobj;\r\nif (dd->bdev) {\r\nif (dd->bdev->bd_holders >= 1)\r\nreturn -2;\r\nbdput(dd->bdev);\r\ndd->bdev = NULL;\r\n}\r\nmtip_hw_debugfs_exit(dd);\r\nspin_lock(&rssd_index_lock);\r\nida_remove(&rssd_index_ida, dd->index);\r\nspin_unlock(&rssd_index_lock);\r\nif (!test_bit(MTIP_DDF_INIT_DONE_BIT, &dd->dd_flag) &&\r\ntest_bit(MTIP_DDF_REBUILD_FAILED_BIT, &dd->dd_flag)) {\r\nput_disk(dd->disk);\r\n} else {\r\nif (dd->disk) {\r\nkobj = kobject_get(&disk_to_dev(dd->disk)->kobj);\r\nif (kobj) {\r\nmtip_hw_sysfs_exit(dd, kobj);\r\nkobject_put(kobj);\r\n}\r\ndel_gendisk(dd->disk);\r\ndd->disk = NULL;\r\n}\r\nif (dd->queue) {\r\ndd->queue->queuedata = NULL;\r\nblk_cleanup_queue(dd->queue);\r\nblk_mq_free_tag_set(&dd->tags);\r\ndd->queue = NULL;\r\n}\r\n}\r\nkfree(dd);\r\nreturn 0;\r\n}\r\nstatic inline void hba_setup(struct driver_data *dd)\r\n{\r\nu32 hwdata;\r\nhwdata = readl(dd->mmio + HOST_HSORG);\r\nwritel(hwdata |\r\nHSORG_DISABLE_SLOTGRP_INTR |\r\nHSORG_DISABLE_SLOTGRP_PXIS,\r\ndd->mmio + HOST_HSORG);\r\n}\r\nstatic int mtip_device_unaligned_constrained(struct driver_data *dd)\r\n{\r\nreturn (dd->pdev->device == P420M_DEVICE_ID ? 1 : 0);\r\n}\r\nstatic void mtip_detect_product(struct driver_data *dd)\r\n{\r\nu32 hwdata;\r\nunsigned int rev, slotgroups;\r\nhwdata = readl(dd->mmio + HOST_HSORG);\r\ndd->product_type = MTIP_PRODUCT_UNKNOWN;\r\ndd->slot_groups = 1;\r\nif (hwdata & 0x8) {\r\ndd->product_type = MTIP_PRODUCT_ASICFPGA;\r\nrev = (hwdata & HSORG_HWREV) >> 8;\r\nslotgroups = (hwdata & HSORG_SLOTGROUPS) + 1;\r\ndev_info(&dd->pdev->dev,\r\n"ASIC-FPGA design, HS rev 0x%x, "\r\n"%i slot groups [%i slots]\n",\r\nrev,\r\nslotgroups,\r\nslotgroups * 32);\r\nif (slotgroups > MTIP_MAX_SLOT_GROUPS) {\r\ndev_warn(&dd->pdev->dev,\r\n"Warning: driver only supports "\r\n"%i slot groups.\n", MTIP_MAX_SLOT_GROUPS);\r\nslotgroups = MTIP_MAX_SLOT_GROUPS;\r\n}\r\ndd->slot_groups = slotgroups;\r\nreturn;\r\n}\r\ndev_warn(&dd->pdev->dev, "Unrecognized product id\n");\r\n}\r\nstatic int mtip_ftl_rebuild_poll(struct driver_data *dd)\r\n{\r\nunsigned long timeout, cnt = 0, start;\r\ndev_warn(&dd->pdev->dev,\r\n"FTL rebuild in progress. Polling for completion.\n");\r\nstart = jiffies;\r\ntimeout = jiffies + msecs_to_jiffies(MTIP_FTL_REBUILD_TIMEOUT_MS);\r\ndo {\r\nif (unlikely(test_bit(MTIP_DDF_REMOVE_PENDING_BIT,\r\n&dd->dd_flag)))\r\nreturn -EFAULT;\r\nif (mtip_check_surprise_removal(dd->pdev))\r\nreturn -EFAULT;\r\nif (mtip_get_identify(dd->port, NULL) < 0)\r\nreturn -EFAULT;\r\nif (*(dd->port->identify + MTIP_FTL_REBUILD_OFFSET) ==\r\nMTIP_FTL_REBUILD_MAGIC) {\r\nssleep(1);\r\nif (cnt++ >= 180) {\r\ndev_warn(&dd->pdev->dev,\r\n"FTL rebuild in progress (%d secs).\n",\r\njiffies_to_msecs(jiffies - start) / 1000);\r\ncnt = 0;\r\n}\r\n} else {\r\ndev_warn(&dd->pdev->dev,\r\n"FTL rebuild complete (%d secs).\n",\r\njiffies_to_msecs(jiffies - start) / 1000);\r\nmtip_block_initialize(dd);\r\nreturn 0;\r\n}\r\nssleep(10);\r\n} while (time_before(jiffies, timeout));\r\ndev_err(&dd->pdev->dev,\r\n"Timed out waiting for FTL rebuild to complete (%d secs).\n",\r\njiffies_to_msecs(jiffies - start) / 1000);\r\nreturn -EFAULT;\r\n}\r\nstatic int mtip_service_thread(void *data)\r\n{\r\nstruct driver_data *dd = (struct driver_data *)data;\r\nunsigned long slot, slot_start, slot_wrap;\r\nunsigned int num_cmd_slots = dd->slot_groups * 32;\r\nstruct mtip_port *port = dd->port;\r\nint ret;\r\nwhile (1) {\r\nif (kthread_should_stop() ||\r\ntest_bit(MTIP_PF_SVC_THD_STOP_BIT, &port->flags))\r\ngoto st_out;\r\nclear_bit(MTIP_PF_SVC_THD_ACTIVE_BIT, &port->flags);\r\nwait_event_interruptible(port->svc_wait, (port->flags) &&\r\n!(port->flags & MTIP_PF_PAUSE_IO));\r\nset_bit(MTIP_PF_SVC_THD_ACTIVE_BIT, &port->flags);\r\nif (kthread_should_stop() ||\r\ntest_bit(MTIP_PF_SVC_THD_STOP_BIT, &port->flags))\r\ngoto st_out;\r\nif (test_bit(MTIP_PF_SR_CLEANUP_BIT, &port->flags))\r\nbreak;\r\nif (unlikely(test_bit(MTIP_DDF_REMOVE_PENDING_BIT,\r\n&dd->dd_flag)))\r\ngoto st_out;\r\nrestart_eh:\r\nif (test_bit(MTIP_PF_EH_ACTIVE_BIT, &port->flags)) {\r\nmtip_handle_tfe(dd);\r\nclear_bit(MTIP_PF_EH_ACTIVE_BIT, &port->flags);\r\n}\r\nif (test_bit(MTIP_PF_EH_ACTIVE_BIT, &port->flags))\r\ngoto restart_eh;\r\nif (test_bit(MTIP_PF_ISSUE_CMDS_BIT, &port->flags)) {\r\nslot = 1;\r\nslot_start = num_cmd_slots;\r\nslot_wrap = 0;\r\nwhile (1) {\r\nslot = find_next_bit(port->cmds_to_issue,\r\nnum_cmd_slots, slot);\r\nif (slot_wrap == 1) {\r\nif ((slot_start >= slot) ||\r\n(slot >= num_cmd_slots))\r\nbreak;\r\n}\r\nif (unlikely(slot_start == num_cmd_slots))\r\nslot_start = slot;\r\nif (unlikely(slot == num_cmd_slots)) {\r\nslot = 1;\r\nslot_wrap = 1;\r\ncontinue;\r\n}\r\nmtip_issue_ncq_command(port, slot);\r\nclear_bit(slot, port->cmds_to_issue);\r\n}\r\nclear_bit(MTIP_PF_ISSUE_CMDS_BIT, &port->flags);\r\n}\r\nif (test_bit(MTIP_PF_REBUILD_BIT, &port->flags)) {\r\nif (mtip_ftl_rebuild_poll(dd) < 0)\r\nset_bit(MTIP_DDF_REBUILD_FAILED_BIT,\r\n&dd->dd_flag);\r\nclear_bit(MTIP_PF_REBUILD_BIT, &port->flags);\r\n}\r\n}\r\nwhile (1) {\r\nif (test_bit(MTIP_DDF_REMOVE_DONE_BIT, &dd->dd_flag))\r\nbreak;\r\nmsleep_interruptible(1000);\r\nif (kthread_should_stop())\r\ngoto st_out;\r\n}\r\nwhile (1) {\r\nret = mtip_free_orphan(dd);\r\nif (!ret) {\r\nreturn 0;\r\n}\r\nmsleep_interruptible(1000);\r\nif (kthread_should_stop())\r\ngoto st_out;\r\n}\r\nst_out:\r\nreturn 0;\r\n}\r\nstatic void mtip_dma_free(struct driver_data *dd)\r\n{\r\nstruct mtip_port *port = dd->port;\r\nif (port->block1)\r\ndmam_free_coherent(&dd->pdev->dev, BLOCK_DMA_ALLOC_SZ,\r\nport->block1, port->block1_dma);\r\nif (port->command_list) {\r\ndmam_free_coherent(&dd->pdev->dev, AHCI_CMD_TBL_SZ,\r\nport->command_list, port->command_list_dma);\r\n}\r\n}\r\nstatic int mtip_dma_alloc(struct driver_data *dd)\r\n{\r\nstruct mtip_port *port = dd->port;\r\nport->block1 =\r\ndmam_alloc_coherent(&dd->pdev->dev, BLOCK_DMA_ALLOC_SZ,\r\n&port->block1_dma, GFP_KERNEL);\r\nif (!port->block1)\r\nreturn -ENOMEM;\r\nmemset(port->block1, 0, BLOCK_DMA_ALLOC_SZ);\r\nport->command_list =\r\ndmam_alloc_coherent(&dd->pdev->dev, AHCI_CMD_TBL_SZ,\r\n&port->command_list_dma, GFP_KERNEL);\r\nif (!port->command_list) {\r\ndmam_free_coherent(&dd->pdev->dev, BLOCK_DMA_ALLOC_SZ,\r\nport->block1, port->block1_dma);\r\nport->block1 = NULL;\r\nport->block1_dma = 0;\r\nreturn -ENOMEM;\r\n}\r\nmemset(port->command_list, 0, AHCI_CMD_TBL_SZ);\r\nport->rxfis = port->block1 + AHCI_RX_FIS_OFFSET;\r\nport->rxfis_dma = port->block1_dma + AHCI_RX_FIS_OFFSET;\r\nport->identify = port->block1 + AHCI_IDFY_OFFSET;\r\nport->identify_dma = port->block1_dma + AHCI_IDFY_OFFSET;\r\nport->log_buf = port->block1 + AHCI_SECTBUF_OFFSET;\r\nport->log_buf_dma = port->block1_dma + AHCI_SECTBUF_OFFSET;\r\nport->smart_buf = port->block1 + AHCI_SMARTBUF_OFFSET;\r\nport->smart_buf_dma = port->block1_dma + AHCI_SMARTBUF_OFFSET;\r\nreturn 0;\r\n}\r\nstatic int mtip_hw_get_identify(struct driver_data *dd)\r\n{\r\nstruct smart_attr attr242;\r\nunsigned char *buf;\r\nint rv;\r\nif (mtip_get_identify(dd->port, NULL) < 0)\r\nreturn -EFAULT;\r\nif (*(dd->port->identify + MTIP_FTL_REBUILD_OFFSET) ==\r\nMTIP_FTL_REBUILD_MAGIC) {\r\nset_bit(MTIP_PF_REBUILD_BIT, &dd->port->flags);\r\nreturn MTIP_FTL_REBUILD_MAGIC;\r\n}\r\nmtip_dump_identify(dd->port);\r\nrv = mtip_read_log_page(dd->port, ATA_LOG_SATA_NCQ,\r\ndd->port->log_buf,\r\ndd->port->log_buf_dma, 1);\r\nif (rv) {\r\ndev_warn(&dd->pdev->dev,\r\n"Error in READ LOG EXT (10h) command\n");\r\n} else {\r\nbuf = (unsigned char *)dd->port->log_buf;\r\nif (buf[259] & 0x1) {\r\ndev_info(&dd->pdev->dev,\r\n"Write protect bit is set.\n");\r\nset_bit(MTIP_DDF_WRITE_PROTECT_BIT, &dd->dd_flag);\r\n}\r\nif (buf[288] == 0xF7) {\r\ndev_info(&dd->pdev->dev,\r\n"Exceeded Tmax, drive in thermal shutdown.\n");\r\nset_bit(MTIP_DDF_OVER_TEMP_BIT, &dd->dd_flag);\r\n}\r\nif (buf[288] == 0xBF) {\r\ndev_info(&dd->pdev->dev,\r\n"Drive indicates rebuild has failed.\n");\r\n}\r\n}\r\nmemset(&attr242, 0, sizeof(struct smart_attr));\r\nif (mtip_get_smart_attr(dd->port, 242, &attr242))\r\ndev_warn(&dd->pdev->dev,\r\n"Unable to check write protect progress\n");\r\nelse\r\ndev_info(&dd->pdev->dev,\r\n"Write protect progress: %u%% (%u blocks)\n",\r\nattr242.cur, le32_to_cpu(attr242.data));\r\nreturn rv;\r\n}\r\nstatic int mtip_hw_init(struct driver_data *dd)\r\n{\r\nint i;\r\nint rv;\r\nunsigned int num_command_slots;\r\nunsigned long timeout, timetaken;\r\ndd->mmio = pcim_iomap_table(dd->pdev)[MTIP_ABAR];\r\nmtip_detect_product(dd);\r\nif (dd->product_type == MTIP_PRODUCT_UNKNOWN) {\r\nrv = -EIO;\r\ngoto out1;\r\n}\r\nnum_command_slots = dd->slot_groups * 32;\r\nhba_setup(dd);\r\ndd->port = kzalloc_node(sizeof(struct mtip_port), GFP_KERNEL,\r\ndd->numa_node);\r\nif (!dd->port) {\r\ndev_err(&dd->pdev->dev,\r\n"Memory allocation: port structure\n");\r\nreturn -ENOMEM;\r\n}\r\nfor (i = 0; i < MTIP_MAX_SLOT_GROUPS; i++)\r\ndd->work[i].port = dd->port;\r\nif (mtip_device_unaligned_constrained(dd))\r\ndd->unal_qdepth = MTIP_MAX_UNALIGNED_SLOTS;\r\nelse\r\ndd->unal_qdepth = 0;\r\nsema_init(&dd->port->cmd_slot_unal, dd->unal_qdepth);\r\nfor (i = 0; i < MTIP_MAX_SLOT_GROUPS; i++)\r\nspin_lock_init(&dd->port->cmd_issue_lock[i]);\r\ndd->port->mmio = dd->mmio + PORT_OFFSET;\r\ndd->port->dd = dd;\r\nrv = mtip_dma_alloc(dd);\r\nif (rv < 0)\r\ngoto out1;\r\nfor (i = 0; i < dd->slot_groups; i++) {\r\ndd->port->s_active[i] =\r\ndd->port->mmio + i*0x80 + PORT_SCR_ACT;\r\ndd->port->cmd_issue[i] =\r\ndd->port->mmio + i*0x80 + PORT_COMMAND_ISSUE;\r\ndd->port->completed[i] =\r\ndd->port->mmio + i*0x80 + PORT_SDBV;\r\n}\r\ntimetaken = jiffies;\r\ntimeout = jiffies + msecs_to_jiffies(30000);\r\nwhile (((readl(dd->port->mmio + PORT_SCR_STAT) & 0x0F) != 0x03) &&\r\ntime_before(jiffies, timeout)) {\r\nmdelay(100);\r\n}\r\nif (unlikely(mtip_check_surprise_removal(dd->pdev))) {\r\ntimetaken = jiffies - timetaken;\r\ndev_warn(&dd->pdev->dev,\r\n"Surprise removal detected at %u ms\n",\r\njiffies_to_msecs(timetaken));\r\nrv = -ENODEV;\r\ngoto out2 ;\r\n}\r\nif (unlikely(test_bit(MTIP_DDF_REMOVE_PENDING_BIT, &dd->dd_flag))) {\r\ntimetaken = jiffies - timetaken;\r\ndev_warn(&dd->pdev->dev,\r\n"Removal detected at %u ms\n",\r\njiffies_to_msecs(timetaken));\r\nrv = -EFAULT;\r\ngoto out2;\r\n}\r\nif (!(readl(dd->mmio + HOST_CAP) & HOST_CAP_NZDMA)) {\r\nif (mtip_hba_reset(dd) < 0) {\r\ndev_err(&dd->pdev->dev,\r\n"Card did not reset within timeout\n");\r\nrv = -EIO;\r\ngoto out2;\r\n}\r\n} else {\r\nwritel(readl(dd->mmio + HOST_IRQ_STAT),\r\ndd->mmio + HOST_IRQ_STAT);\r\n}\r\nmtip_init_port(dd->port);\r\nmtip_start_port(dd->port);\r\nrv = devm_request_irq(&dd->pdev->dev,\r\ndd->pdev->irq,\r\nmtip_irq_handler,\r\nIRQF_SHARED,\r\ndev_driver_string(&dd->pdev->dev),\r\ndd);\r\nif (rv) {\r\ndev_err(&dd->pdev->dev,\r\n"Unable to allocate IRQ %d\n", dd->pdev->irq);\r\ngoto out2;\r\n}\r\nirq_set_affinity_hint(dd->pdev->irq, get_cpu_mask(dd->isr_binding));\r\nwritel(readl(dd->mmio + HOST_CTL) | HOST_IRQ_EN,\r\ndd->mmio + HOST_CTL);\r\ninit_waitqueue_head(&dd->port->svc_wait);\r\nif (test_bit(MTIP_DDF_REMOVE_PENDING_BIT, &dd->dd_flag)) {\r\nrv = -EFAULT;\r\ngoto out3;\r\n}\r\nreturn rv;\r\nout3:\r\nwritel(readl(dd->mmio + HOST_CTL) & ~HOST_IRQ_EN,\r\ndd->mmio + HOST_CTL);\r\nirq_set_affinity_hint(dd->pdev->irq, NULL);\r\ndevm_free_irq(&dd->pdev->dev, dd->pdev->irq, dd);\r\nout2:\r\nmtip_deinit_port(dd->port);\r\nmtip_dma_free(dd);\r\nout1:\r\nkfree(dd->port);\r\nreturn rv;\r\n}\r\nstatic void mtip_standby_drive(struct driver_data *dd)\r\n{\r\nif (dd->sr)\r\nreturn;\r\nif (!test_bit(MTIP_PF_REBUILD_BIT, &dd->port->flags) &&\r\n!test_bit(MTIP_DDF_SEC_LOCK_BIT, &dd->dd_flag))\r\nif (mtip_standby_immediate(dd->port))\r\ndev_warn(&dd->pdev->dev,\r\n"STANDBY IMMEDIATE failed\n");\r\n}\r\nstatic int mtip_hw_exit(struct driver_data *dd)\r\n{\r\nif (!dd->sr) {\r\nmtip_deinit_port(dd->port);\r\nwritel(readl(dd->mmio + HOST_CTL) & ~HOST_IRQ_EN,\r\ndd->mmio + HOST_CTL);\r\n}\r\nirq_set_affinity_hint(dd->pdev->irq, NULL);\r\ndevm_free_irq(&dd->pdev->dev, dd->pdev->irq, dd);\r\nmtip_dma_free(dd);\r\nkfree(dd->port);\r\ndd->port = NULL;\r\nreturn 0;\r\n}\r\nstatic int mtip_hw_shutdown(struct driver_data *dd)\r\n{\r\nif (!dd->sr && dd->port)\r\nmtip_standby_immediate(dd->port);\r\nreturn 0;\r\n}\r\nstatic int mtip_hw_suspend(struct driver_data *dd)\r\n{\r\nif (mtip_standby_immediate(dd->port) != 0) {\r\ndev_err(&dd->pdev->dev,\r\n"Failed standby-immediate command\n");\r\nreturn -EFAULT;\r\n}\r\nwritel(readl(dd->mmio + HOST_CTL) & ~HOST_IRQ_EN,\r\ndd->mmio + HOST_CTL);\r\nmtip_deinit_port(dd->port);\r\nreturn 0;\r\n}\r\nstatic int mtip_hw_resume(struct driver_data *dd)\r\n{\r\nhba_setup(dd);\r\nif (mtip_hba_reset(dd) != 0) {\r\ndev_err(&dd->pdev->dev,\r\n"Unable to reset the HBA\n");\r\nreturn -EFAULT;\r\n}\r\nmtip_init_port(dd->port);\r\nmtip_start_port(dd->port);\r\nwritel(readl(dd->mmio + HOST_CTL) | HOST_IRQ_EN,\r\ndd->mmio + HOST_CTL);\r\nreturn 0;\r\n}\r\nstatic int rssd_disk_name_format(char *prefix,\r\nint index,\r\nchar *buf,\r\nint buflen)\r\n{\r\nconst int base = 'z' - 'a' + 1;\r\nchar *begin = buf + strlen(prefix);\r\nchar *end = buf + buflen;\r\nchar *p;\r\nint unit;\r\np = end - 1;\r\n*p = '\0';\r\nunit = base;\r\ndo {\r\nif (p == begin)\r\nreturn -EINVAL;\r\n*--p = 'a' + (index % unit);\r\nindex = (index / unit) - 1;\r\n} while (index >= 0);\r\nmemmove(begin, p, end - p);\r\nmemcpy(buf, prefix, strlen(prefix));\r\nreturn 0;\r\n}\r\nstatic int mtip_block_ioctl(struct block_device *dev,\r\nfmode_t mode,\r\nunsigned cmd,\r\nunsigned long arg)\r\n{\r\nstruct driver_data *dd = dev->bd_disk->private_data;\r\nif (!capable(CAP_SYS_ADMIN))\r\nreturn -EACCES;\r\nif (!dd)\r\nreturn -ENOTTY;\r\nif (unlikely(test_bit(MTIP_DDF_REMOVE_PENDING_BIT, &dd->dd_flag)))\r\nreturn -ENOTTY;\r\nswitch (cmd) {\r\ncase BLKFLSBUF:\r\nreturn -ENOTTY;\r\ndefault:\r\nreturn mtip_hw_ioctl(dd, cmd, arg);\r\n}\r\n}\r\nstatic int mtip_block_compat_ioctl(struct block_device *dev,\r\nfmode_t mode,\r\nunsigned cmd,\r\nunsigned long arg)\r\n{\r\nstruct driver_data *dd = dev->bd_disk->private_data;\r\nif (!capable(CAP_SYS_ADMIN))\r\nreturn -EACCES;\r\nif (!dd)\r\nreturn -ENOTTY;\r\nif (unlikely(test_bit(MTIP_DDF_REMOVE_PENDING_BIT, &dd->dd_flag)))\r\nreturn -ENOTTY;\r\nswitch (cmd) {\r\ncase BLKFLSBUF:\r\nreturn -ENOTTY;\r\ncase HDIO_DRIVE_TASKFILE: {\r\nstruct mtip_compat_ide_task_request_s __user *compat_req_task;\r\nide_task_request_t req_task;\r\nint compat_tasksize, outtotal, ret;\r\ncompat_tasksize =\r\nsizeof(struct mtip_compat_ide_task_request_s);\r\ncompat_req_task =\r\n(struct mtip_compat_ide_task_request_s __user *) arg;\r\nif (copy_from_user(&req_task, (void __user *) arg,\r\ncompat_tasksize - (2 * sizeof(compat_long_t))))\r\nreturn -EFAULT;\r\nif (get_user(req_task.out_size, &compat_req_task->out_size))\r\nreturn -EFAULT;\r\nif (get_user(req_task.in_size, &compat_req_task->in_size))\r\nreturn -EFAULT;\r\nouttotal = sizeof(struct mtip_compat_ide_task_request_s);\r\nret = exec_drive_taskfile(dd, (void __user *) arg,\r\n&req_task, outtotal);\r\nif (copy_to_user((void __user *) arg, &req_task,\r\ncompat_tasksize -\r\n(2 * sizeof(compat_long_t))))\r\nreturn -EFAULT;\r\nif (put_user(req_task.out_size, &compat_req_task->out_size))\r\nreturn -EFAULT;\r\nif (put_user(req_task.in_size, &compat_req_task->in_size))\r\nreturn -EFAULT;\r\nreturn ret;\r\n}\r\ndefault:\r\nreturn mtip_hw_ioctl(dd, cmd, arg);\r\n}\r\n}\r\nstatic int mtip_block_getgeo(struct block_device *dev,\r\nstruct hd_geometry *geo)\r\n{\r\nstruct driver_data *dd = dev->bd_disk->private_data;\r\nsector_t capacity;\r\nif (!dd)\r\nreturn -ENOTTY;\r\nif (!(mtip_hw_get_capacity(dd, &capacity))) {\r\ndev_warn(&dd->pdev->dev,\r\n"Could not get drive capacity.\n");\r\nreturn -ENOTTY;\r\n}\r\ngeo->heads = 224;\r\ngeo->sectors = 56;\r\nsector_div(capacity, (geo->heads * geo->sectors));\r\ngeo->cylinders = capacity;\r\nreturn 0;\r\n}\r\nstatic int mtip_submit_request(struct blk_mq_hw_ctx *hctx, struct request *rq)\r\n{\r\nstruct driver_data *dd = hctx->queue->queuedata;\r\nstruct mtip_cmd *cmd = blk_mq_rq_to_pdu(rq);\r\nunsigned int nents;\r\nif (unlikely(dd->dd_flag & MTIP_DDF_STOP_IO)) {\r\nif (unlikely(test_bit(MTIP_DDF_REMOVE_PENDING_BIT,\r\n&dd->dd_flag))) {\r\nreturn -ENXIO;\r\n}\r\nif (unlikely(test_bit(MTIP_DDF_OVER_TEMP_BIT, &dd->dd_flag))) {\r\nreturn -ENODATA;\r\n}\r\nif (unlikely(test_bit(MTIP_DDF_WRITE_PROTECT_BIT,\r\n&dd->dd_flag) &&\r\nrq_data_dir(rq))) {\r\nreturn -ENODATA;\r\n}\r\nif (unlikely(test_bit(MTIP_DDF_SEC_LOCK_BIT, &dd->dd_flag)))\r\nreturn -ENODATA;\r\nif (test_bit(MTIP_DDF_REBUILD_FAILED_BIT, &dd->dd_flag))\r\nreturn -ENXIO;\r\n}\r\nif (rq->cmd_flags & REQ_DISCARD) {\r\nint err;\r\nerr = mtip_send_trim(dd, blk_rq_pos(rq), blk_rq_sectors(rq));\r\nblk_mq_end_request(rq, err);\r\nreturn 0;\r\n}\r\nnents = blk_rq_map_sg(hctx->queue, rq, cmd->sg);\r\nmtip_hw_submit_io(dd, rq, cmd, nents, hctx);\r\nreturn 0;\r\n}\r\nstatic bool mtip_check_unal_depth(struct blk_mq_hw_ctx *hctx,\r\nstruct request *rq)\r\n{\r\nstruct driver_data *dd = hctx->queue->queuedata;\r\nstruct mtip_cmd *cmd = blk_mq_rq_to_pdu(rq);\r\nif (rq_data_dir(rq) == READ || !dd->unal_qdepth)\r\nreturn false;\r\nif (blk_rq_sectors(rq) <= 64) {\r\nif ((blk_rq_pos(rq) & 7) || (blk_rq_sectors(rq) & 7))\r\ncmd->unaligned = 1;\r\n}\r\nif (cmd->unaligned && down_trylock(&dd->port->cmd_slot_unal))\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic int mtip_queue_rq(struct blk_mq_hw_ctx *hctx,\r\nconst struct blk_mq_queue_data *bd)\r\n{\r\nstruct request *rq = bd->rq;\r\nint ret;\r\nif (unlikely(mtip_check_unal_depth(hctx, rq)))\r\nreturn BLK_MQ_RQ_QUEUE_BUSY;\r\nblk_mq_start_request(rq);\r\nret = mtip_submit_request(hctx, rq);\r\nif (likely(!ret))\r\nreturn BLK_MQ_RQ_QUEUE_OK;\r\nrq->errors = ret;\r\nreturn BLK_MQ_RQ_QUEUE_ERROR;\r\n}\r\nstatic void mtip_free_cmd(void *data, struct request *rq,\r\nunsigned int hctx_idx, unsigned int request_idx)\r\n{\r\nstruct driver_data *dd = data;\r\nstruct mtip_cmd *cmd = blk_mq_rq_to_pdu(rq);\r\nif (!cmd->command)\r\nreturn;\r\ndmam_free_coherent(&dd->pdev->dev, CMD_DMA_ALLOC_SZ,\r\ncmd->command, cmd->command_dma);\r\n}\r\nstatic int mtip_init_cmd(void *data, struct request *rq, unsigned int hctx_idx,\r\nunsigned int request_idx, unsigned int numa_node)\r\n{\r\nstruct driver_data *dd = data;\r\nstruct mtip_cmd *cmd = blk_mq_rq_to_pdu(rq);\r\nu32 host_cap_64 = readl(dd->mmio + HOST_CAP) & HOST_CAP_64;\r\ncmd->command = dmam_alloc_coherent(&dd->pdev->dev, CMD_DMA_ALLOC_SZ,\r\n&cmd->command_dma, GFP_KERNEL);\r\nif (!cmd->command)\r\nreturn -ENOMEM;\r\nmemset(cmd->command, 0, CMD_DMA_ALLOC_SZ);\r\ncmd->command_header = dd->port->command_list +\r\n(sizeof(struct mtip_cmd_hdr) * request_idx);\r\ncmd->command_header_dma = dd->port->command_list_dma +\r\n(sizeof(struct mtip_cmd_hdr) * request_idx);\r\nif (host_cap_64)\r\ncmd->command_header->ctbau = __force_bit2int cpu_to_le32((cmd->command_dma >> 16) >> 16);\r\ncmd->command_header->ctba = __force_bit2int cpu_to_le32(cmd->command_dma & 0xFFFFFFFF);\r\nsg_init_table(cmd->sg, MTIP_MAX_SG);\r\nreturn 0;\r\n}\r\nstatic int mtip_block_initialize(struct driver_data *dd)\r\n{\r\nint rv = 0, wait_for_rebuild = 0;\r\nsector_t capacity;\r\nunsigned int index = 0;\r\nstruct kobject *kobj;\r\nunsigned char thd_name[16];\r\nif (dd->disk)\r\ngoto skip_create_disk;\r\nif (mtip_hw_init(dd)) {\r\nrv = -EINVAL;\r\ngoto protocol_init_error;\r\n}\r\ndd->disk = alloc_disk_node(MTIP_MAX_MINORS, dd->numa_node);\r\nif (dd->disk == NULL) {\r\ndev_err(&dd->pdev->dev,\r\n"Unable to allocate gendisk structure\n");\r\nrv = -EINVAL;\r\ngoto alloc_disk_error;\r\n}\r\ndo {\r\nif (!ida_pre_get(&rssd_index_ida, GFP_KERNEL))\r\ngoto ida_get_error;\r\nspin_lock(&rssd_index_lock);\r\nrv = ida_get_new(&rssd_index_ida, &index);\r\nspin_unlock(&rssd_index_lock);\r\n} while (rv == -EAGAIN);\r\nif (rv)\r\ngoto ida_get_error;\r\nrv = rssd_disk_name_format("rssd",\r\nindex,\r\ndd->disk->disk_name,\r\nDISK_NAME_LEN);\r\nif (rv)\r\ngoto disk_index_error;\r\ndd->disk->driverfs_dev = &dd->pdev->dev;\r\ndd->disk->major = dd->major;\r\ndd->disk->first_minor = dd->instance * MTIP_MAX_MINORS;\r\ndd->disk->fops = &mtip_block_ops;\r\ndd->disk->private_data = dd;\r\ndd->index = index;\r\nmtip_hw_debugfs_init(dd);\r\nskip_create_disk:\r\nmemset(&dd->tags, 0, sizeof(dd->tags));\r\ndd->tags.ops = &mtip_mq_ops;\r\ndd->tags.nr_hw_queues = 1;\r\ndd->tags.queue_depth = MTIP_MAX_COMMAND_SLOTS;\r\ndd->tags.reserved_tags = 1;\r\ndd->tags.cmd_size = sizeof(struct mtip_cmd);\r\ndd->tags.numa_node = dd->numa_node;\r\ndd->tags.flags = BLK_MQ_F_SHOULD_MERGE;\r\ndd->tags.driver_data = dd;\r\nrv = blk_mq_alloc_tag_set(&dd->tags);\r\nif (rv) {\r\ndev_err(&dd->pdev->dev,\r\n"Unable to allocate request queue\n");\r\ngoto block_queue_alloc_init_error;\r\n}\r\ndd->queue = blk_mq_init_queue(&dd->tags);\r\nif (IS_ERR(dd->queue)) {\r\ndev_err(&dd->pdev->dev,\r\n"Unable to allocate request queue\n");\r\nrv = -ENOMEM;\r\ngoto block_queue_alloc_init_error;\r\n}\r\ndd->disk->queue = dd->queue;\r\ndd->queue->queuedata = dd;\r\nwait_for_rebuild = mtip_hw_get_identify(dd);\r\nif (wait_for_rebuild < 0) {\r\ndev_err(&dd->pdev->dev,\r\n"Protocol layer initialization failed\n");\r\nrv = -EINVAL;\r\ngoto init_hw_cmds_error;\r\n}\r\nif (wait_for_rebuild == MTIP_FTL_REBUILD_MAGIC)\r\ngoto start_service_thread;\r\nset_bit(QUEUE_FLAG_NONROT, &dd->queue->queue_flags);\r\nclear_bit(QUEUE_FLAG_ADD_RANDOM, &dd->queue->queue_flags);\r\nblk_queue_max_segments(dd->queue, MTIP_MAX_SG);\r\nblk_queue_physical_block_size(dd->queue, 4096);\r\nblk_queue_max_hw_sectors(dd->queue, 0xffff);\r\nblk_queue_max_segment_size(dd->queue, 0x400000);\r\nblk_queue_io_min(dd->queue, 4096);\r\nblk_queue_bounce_limit(dd->queue, dd->pdev->dma_mask);\r\nblk_queue_flush(dd->queue, 0);\r\nif (dd->trim_supp == true) {\r\nset_bit(QUEUE_FLAG_DISCARD, &dd->queue->queue_flags);\r\ndd->queue->limits.discard_granularity = 4096;\r\nblk_queue_max_discard_sectors(dd->queue,\r\nMTIP_MAX_TRIM_ENTRY_LEN * MTIP_MAX_TRIM_ENTRIES);\r\ndd->queue->limits.discard_zeroes_data = 0;\r\n}\r\nif (!(mtip_hw_get_capacity(dd, &capacity))) {\r\ndev_warn(&dd->pdev->dev,\r\n"Could not read drive capacity\n");\r\nrv = -EIO;\r\ngoto read_capacity_error;\r\n}\r\nset_capacity(dd->disk, capacity);\r\nadd_disk(dd->disk);\r\ndd->bdev = bdget_disk(dd->disk, 0);\r\nkobj = kobject_get(&disk_to_dev(dd->disk)->kobj);\r\nif (kobj) {\r\nmtip_hw_sysfs_init(dd, kobj);\r\nkobject_put(kobj);\r\n}\r\nif (dd->mtip_svc_handler) {\r\nset_bit(MTIP_DDF_INIT_DONE_BIT, &dd->dd_flag);\r\nreturn rv;\r\n}\r\nstart_service_thread:\r\nsprintf(thd_name, "mtip_svc_thd_%02d", index);\r\ndd->mtip_svc_handler = kthread_create_on_node(mtip_service_thread,\r\ndd, dd->numa_node, "%s",\r\nthd_name);\r\nif (IS_ERR(dd->mtip_svc_handler)) {\r\ndev_err(&dd->pdev->dev, "service thread failed to start\n");\r\ndd->mtip_svc_handler = NULL;\r\nrv = -EFAULT;\r\ngoto kthread_run_error;\r\n}\r\nwake_up_process(dd->mtip_svc_handler);\r\nif (wait_for_rebuild == MTIP_FTL_REBUILD_MAGIC)\r\nrv = wait_for_rebuild;\r\nreturn rv;\r\nkthread_run_error:\r\nbdput(dd->bdev);\r\ndd->bdev = NULL;\r\ndel_gendisk(dd->disk);\r\nread_capacity_error:\r\ninit_hw_cmds_error:\r\nblk_cleanup_queue(dd->queue);\r\nblk_mq_free_tag_set(&dd->tags);\r\nblock_queue_alloc_init_error:\r\nmtip_hw_debugfs_exit(dd);\r\ndisk_index_error:\r\nspin_lock(&rssd_index_lock);\r\nida_remove(&rssd_index_ida, index);\r\nspin_unlock(&rssd_index_lock);\r\nida_get_error:\r\nput_disk(dd->disk);\r\nalloc_disk_error:\r\nmtip_hw_exit(dd);\r\nprotocol_init_error:\r\nreturn rv;\r\n}\r\nstatic int mtip_block_remove(struct driver_data *dd)\r\n{\r\nstruct kobject *kobj;\r\nif (!dd->sr) {\r\nmtip_hw_debugfs_exit(dd);\r\nif (dd->mtip_svc_handler) {\r\nset_bit(MTIP_PF_SVC_THD_STOP_BIT, &dd->port->flags);\r\nwake_up_interruptible(&dd->port->svc_wait);\r\nkthread_stop(dd->mtip_svc_handler);\r\n}\r\nif (test_bit(MTIP_DDF_INIT_DONE_BIT, &dd->dd_flag)) {\r\nkobj = kobject_get(&disk_to_dev(dd->disk)->kobj);\r\nif (kobj) {\r\nmtip_hw_sysfs_exit(dd, kobj);\r\nkobject_put(kobj);\r\n}\r\n}\r\nmtip_standby_drive(dd);\r\nif (dd->bdev) {\r\nbdput(dd->bdev);\r\ndd->bdev = NULL;\r\n}\r\nif (dd->disk) {\r\nif (dd->disk->queue) {\r\ndel_gendisk(dd->disk);\r\nblk_cleanup_queue(dd->queue);\r\nblk_mq_free_tag_set(&dd->tags);\r\ndd->queue = NULL;\r\n} else\r\nput_disk(dd->disk);\r\n}\r\ndd->disk = NULL;\r\nspin_lock(&rssd_index_lock);\r\nida_remove(&rssd_index_ida, dd->index);\r\nspin_unlock(&rssd_index_lock);\r\n} else {\r\ndev_info(&dd->pdev->dev, "device %s surprise removal\n",\r\ndd->disk->disk_name);\r\n}\r\nmtip_hw_exit(dd);\r\nreturn 0;\r\n}\r\nstatic int mtip_block_shutdown(struct driver_data *dd)\r\n{\r\nmtip_hw_shutdown(dd);\r\nif (dd->disk) {\r\ndev_info(&dd->pdev->dev,\r\n"Shutting down %s ...\n", dd->disk->disk_name);\r\nif (dd->disk->queue) {\r\ndel_gendisk(dd->disk);\r\nblk_cleanup_queue(dd->queue);\r\nblk_mq_free_tag_set(&dd->tags);\r\n} else\r\nput_disk(dd->disk);\r\ndd->disk = NULL;\r\ndd->queue = NULL;\r\n}\r\nspin_lock(&rssd_index_lock);\r\nida_remove(&rssd_index_ida, dd->index);\r\nspin_unlock(&rssd_index_lock);\r\nreturn 0;\r\n}\r\nstatic int mtip_block_suspend(struct driver_data *dd)\r\n{\r\ndev_info(&dd->pdev->dev,\r\n"Suspending %s ...\n", dd->disk->disk_name);\r\nmtip_hw_suspend(dd);\r\nreturn 0;\r\n}\r\nstatic int mtip_block_resume(struct driver_data *dd)\r\n{\r\ndev_info(&dd->pdev->dev, "Resuming %s ...\n",\r\ndd->disk->disk_name);\r\nmtip_hw_resume(dd);\r\nreturn 0;\r\n}\r\nstatic void drop_cpu(int cpu)\r\n{\r\ncpu_use[cpu]--;\r\n}\r\nstatic int get_least_used_cpu_on_node(int node)\r\n{\r\nint cpu, least_used_cpu, least_cnt;\r\nconst struct cpumask *node_mask;\r\nnode_mask = cpumask_of_node(node);\r\nleast_used_cpu = cpumask_first(node_mask);\r\nleast_cnt = cpu_use[least_used_cpu];\r\ncpu = least_used_cpu;\r\nfor_each_cpu(cpu, node_mask) {\r\nif (cpu_use[cpu] < least_cnt) {\r\nleast_used_cpu = cpu;\r\nleast_cnt = cpu_use[cpu];\r\n}\r\n}\r\ncpu_use[least_used_cpu]++;\r\nreturn least_used_cpu;\r\n}\r\nstatic inline int mtip_get_next_rr_node(void)\r\n{\r\nstatic int next_node = -1;\r\nif (next_node == -1) {\r\nnext_node = first_online_node;\r\nreturn next_node;\r\n}\r\nnext_node = next_online_node(next_node);\r\nif (next_node == MAX_NUMNODES)\r\nnext_node = first_online_node;\r\nreturn next_node;\r\n}\r\nstatic void mtip_disable_link_opts(struct driver_data *dd, struct pci_dev *pdev)\r\n{\r\nint pos;\r\nunsigned short pcie_dev_ctrl;\r\npos = pci_find_capability(pdev, PCI_CAP_ID_EXP);\r\nif (pos) {\r\npci_read_config_word(pdev,\r\npos + PCI_EXP_DEVCTL,\r\n&pcie_dev_ctrl);\r\nif (pcie_dev_ctrl & (1 << 11) ||\r\npcie_dev_ctrl & (1 << 4)) {\r\ndev_info(&dd->pdev->dev,\r\n"Disabling ERO/No-Snoop on bridge device %04x:%04x\n",\r\npdev->vendor, pdev->device);\r\npcie_dev_ctrl &= ~(PCI_EXP_DEVCTL_NOSNOOP_EN |\r\nPCI_EXP_DEVCTL_RELAX_EN);\r\npci_write_config_word(pdev,\r\npos + PCI_EXP_DEVCTL,\r\npcie_dev_ctrl);\r\n}\r\n}\r\n}\r\nstatic void mtip_fix_ero_nosnoop(struct driver_data *dd, struct pci_dev *pdev)\r\n{\r\nif (pdev->bus && pdev->bus->self) {\r\nif (pdev->bus->self->vendor == PCI_VENDOR_ID_ATI &&\r\n((pdev->bus->self->device & 0xff00) == 0x5a00)) {\r\nmtip_disable_link_opts(dd, pdev->bus->self);\r\n} else {\r\nstruct pci_dev *parent_dev = pdev->bus->self;\r\nif (parent_dev->bus &&\r\nparent_dev->bus->parent &&\r\nparent_dev->bus->parent->self &&\r\nparent_dev->bus->parent->self->vendor ==\r\nPCI_VENDOR_ID_ATI &&\r\n(parent_dev->bus->parent->self->device &\r\n0xff00) == 0x5a00) {\r\nmtip_disable_link_opts(dd,\r\nparent_dev->bus->parent->self);\r\n}\r\n}\r\n}\r\n}\r\nstatic int mtip_pci_probe(struct pci_dev *pdev,\r\nconst struct pci_device_id *ent)\r\n{\r\nint rv = 0;\r\nstruct driver_data *dd = NULL;\r\nchar cpu_list[256];\r\nconst struct cpumask *node_mask;\r\nint cpu, i = 0, j = 0;\r\nint my_node = NUMA_NO_NODE;\r\nunsigned long flags;\r\nmy_node = pcibus_to_node(pdev->bus);\r\nif (my_node != NUMA_NO_NODE) {\r\nif (!node_online(my_node))\r\nmy_node = mtip_get_next_rr_node();\r\n} else {\r\ndev_info(&pdev->dev, "Kernel not reporting proximity, choosing a node\n");\r\nmy_node = mtip_get_next_rr_node();\r\n}\r\ndev_info(&pdev->dev, "NUMA node %d (closest: %d,%d, probe on %d:%d)\n",\r\nmy_node, pcibus_to_node(pdev->bus), dev_to_node(&pdev->dev),\r\ncpu_to_node(raw_smp_processor_id()), raw_smp_processor_id());\r\ndd = kzalloc_node(sizeof(struct driver_data), GFP_KERNEL, my_node);\r\nif (dd == NULL) {\r\ndev_err(&pdev->dev,\r\n"Unable to allocate memory for driver data\n");\r\nreturn -ENOMEM;\r\n}\r\npci_set_drvdata(pdev, dd);\r\nrv = pcim_enable_device(pdev);\r\nif (rv < 0) {\r\ndev_err(&pdev->dev, "Unable to enable device\n");\r\ngoto iomap_err;\r\n}\r\nrv = pcim_iomap_regions(pdev, 1 << MTIP_ABAR, MTIP_DRV_NAME);\r\nif (rv < 0) {\r\ndev_err(&pdev->dev, "Unable to map regions\n");\r\ngoto iomap_err;\r\n}\r\nif (!pci_set_dma_mask(pdev, DMA_BIT_MASK(64))) {\r\nrv = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));\r\nif (rv) {\r\nrv = pci_set_consistent_dma_mask(pdev,\r\nDMA_BIT_MASK(32));\r\nif (rv) {\r\ndev_warn(&pdev->dev,\r\n"64-bit DMA enable failed\n");\r\ngoto setmask_err;\r\n}\r\n}\r\n}\r\ndd->major = mtip_major;\r\ndd->instance = instance;\r\ndd->pdev = pdev;\r\ndd->numa_node = my_node;\r\nINIT_LIST_HEAD(&dd->online_list);\r\nINIT_LIST_HEAD(&dd->remove_list);\r\nmemset(dd->workq_name, 0, 32);\r\nsnprintf(dd->workq_name, 31, "mtipq%d", dd->instance);\r\ndd->isr_workq = create_workqueue(dd->workq_name);\r\nif (!dd->isr_workq) {\r\ndev_warn(&pdev->dev, "Can't create wq %d\n", dd->instance);\r\nrv = -ENOMEM;\r\ngoto block_initialize_err;\r\n}\r\nmemset(cpu_list, 0, sizeof(cpu_list));\r\nnode_mask = cpumask_of_node(dd->numa_node);\r\nif (!cpumask_empty(node_mask)) {\r\nfor_each_cpu(cpu, node_mask)\r\n{\r\nsnprintf(&cpu_list[j], 256 - j, "%d ", cpu);\r\nj = strlen(cpu_list);\r\n}\r\ndev_info(&pdev->dev, "Node %d on package %d has %d cpu(s): %s\n",\r\ndd->numa_node,\r\ntopology_physical_package_id(cpumask_first(node_mask)),\r\nnr_cpus_node(dd->numa_node),\r\ncpu_list);\r\n} else\r\ndev_dbg(&pdev->dev, "mtip32xx: node_mask empty\n");\r\ndd->isr_binding = get_least_used_cpu_on_node(dd->numa_node);\r\ndev_info(&pdev->dev, "Initial IRQ binding node:cpu %d:%d\n",\r\ncpu_to_node(dd->isr_binding), dd->isr_binding);\r\ndd->work[0].cpu_binding = dd->isr_binding;\r\ndd->work[1].cpu_binding = get_least_used_cpu_on_node(dd->numa_node);\r\ndd->work[2].cpu_binding = get_least_used_cpu_on_node(dd->numa_node);\r\ndd->work[3].cpu_binding = dd->work[0].cpu_binding;\r\ndd->work[4].cpu_binding = dd->work[1].cpu_binding;\r\ndd->work[5].cpu_binding = dd->work[2].cpu_binding;\r\ndd->work[6].cpu_binding = dd->work[2].cpu_binding;\r\ndd->work[7].cpu_binding = dd->work[1].cpu_binding;\r\nfor_each_present_cpu(cpu) {\r\nmemset(cpu_list, 0, sizeof(cpu_list));\r\nfor (i = 0, j = 0; i < MTIP_MAX_SLOT_GROUPS; i++) {\r\nif (dd->work[i].cpu_binding == cpu) {\r\nsnprintf(&cpu_list[j], 256 - j, "%d ", i);\r\nj = strlen(cpu_list);\r\n}\r\n}\r\nif (j)\r\ndev_info(&pdev->dev, "CPU %d: WQs %s\n", cpu, cpu_list);\r\n}\r\nINIT_WORK(&dd->work[0].work, mtip_workq_sdbf0);\r\nINIT_WORK(&dd->work[1].work, mtip_workq_sdbf1);\r\nINIT_WORK(&dd->work[2].work, mtip_workq_sdbf2);\r\nINIT_WORK(&dd->work[3].work, mtip_workq_sdbf3);\r\nINIT_WORK(&dd->work[4].work, mtip_workq_sdbf4);\r\nINIT_WORK(&dd->work[5].work, mtip_workq_sdbf5);\r\nINIT_WORK(&dd->work[6].work, mtip_workq_sdbf6);\r\nINIT_WORK(&dd->work[7].work, mtip_workq_sdbf7);\r\npci_set_master(pdev);\r\nrv = pci_enable_msi(pdev);\r\nif (rv) {\r\ndev_warn(&pdev->dev,\r\n"Unable to enable MSI interrupt.\n");\r\ngoto msi_initialize_err;\r\n}\r\nmtip_fix_ero_nosnoop(dd, pdev);\r\nrv = mtip_block_initialize(dd);\r\nif (rv < 0) {\r\ndev_err(&pdev->dev,\r\n"Unable to initialize block layer\n");\r\ngoto block_initialize_err;\r\n}\r\ninstance++;\r\nif (rv != MTIP_FTL_REBUILD_MAGIC)\r\nset_bit(MTIP_DDF_INIT_DONE_BIT, &dd->dd_flag);\r\nelse\r\nrv = 0;\r\nspin_lock_irqsave(&dev_lock, flags);\r\nlist_add(&dd->online_list, &online_list);\r\nspin_unlock_irqrestore(&dev_lock, flags);\r\ngoto done;\r\nblock_initialize_err:\r\npci_disable_msi(pdev);\r\nmsi_initialize_err:\r\nif (dd->isr_workq) {\r\nflush_workqueue(dd->isr_workq);\r\ndestroy_workqueue(dd->isr_workq);\r\ndrop_cpu(dd->work[0].cpu_binding);\r\ndrop_cpu(dd->work[1].cpu_binding);\r\ndrop_cpu(dd->work[2].cpu_binding);\r\n}\r\nsetmask_err:\r\npcim_iounmap_regions(pdev, 1 << MTIP_ABAR);\r\niomap_err:\r\nkfree(dd);\r\npci_set_drvdata(pdev, NULL);\r\nreturn rv;\r\ndone:\r\nreturn rv;\r\n}\r\nstatic void mtip_pci_remove(struct pci_dev *pdev)\r\n{\r\nstruct driver_data *dd = pci_get_drvdata(pdev);\r\nunsigned long flags, to;\r\nset_bit(MTIP_DDF_REMOVE_PENDING_BIT, &dd->dd_flag);\r\nspin_lock_irqsave(&dev_lock, flags);\r\nlist_del_init(&dd->online_list);\r\nlist_add(&dd->remove_list, &removing_list);\r\nspin_unlock_irqrestore(&dev_lock, flags);\r\nmtip_check_surprise_removal(pdev);\r\nsynchronize_irq(dd->pdev->irq);\r\nto = jiffies + msecs_to_jiffies(4000);\r\ndo {\r\nmsleep(20);\r\n} while (atomic_read(&dd->irq_workers_active) != 0 &&\r\ntime_before(jiffies, to));\r\nif (atomic_read(&dd->irq_workers_active) != 0) {\r\ndev_warn(&dd->pdev->dev,\r\n"Completion workers still active!\n");\r\n}\r\nmtip_block_remove(dd);\r\nif (dd->isr_workq) {\r\nflush_workqueue(dd->isr_workq);\r\ndestroy_workqueue(dd->isr_workq);\r\ndrop_cpu(dd->work[0].cpu_binding);\r\ndrop_cpu(dd->work[1].cpu_binding);\r\ndrop_cpu(dd->work[2].cpu_binding);\r\n}\r\npci_disable_msi(pdev);\r\nspin_lock_irqsave(&dev_lock, flags);\r\nlist_del_init(&dd->remove_list);\r\nspin_unlock_irqrestore(&dev_lock, flags);\r\nif (!dd->sr)\r\nkfree(dd);\r\nelse\r\nset_bit(MTIP_DDF_REMOVE_DONE_BIT, &dd->dd_flag);\r\npcim_iounmap_regions(pdev, 1 << MTIP_ABAR);\r\npci_set_drvdata(pdev, NULL);\r\n}\r\nstatic int mtip_pci_suspend(struct pci_dev *pdev, pm_message_t mesg)\r\n{\r\nint rv = 0;\r\nstruct driver_data *dd = pci_get_drvdata(pdev);\r\nif (!dd) {\r\ndev_err(&pdev->dev,\r\n"Driver private datastructure is NULL\n");\r\nreturn -EFAULT;\r\n}\r\nset_bit(MTIP_DDF_RESUME_BIT, &dd->dd_flag);\r\nrv = mtip_block_suspend(dd);\r\nif (rv < 0) {\r\ndev_err(&pdev->dev,\r\n"Failed to suspend controller\n");\r\nreturn rv;\r\n}\r\npci_save_state(pdev);\r\npci_disable_device(pdev);\r\npci_set_power_state(pdev, PCI_D3hot);\r\nreturn rv;\r\n}\r\nstatic int mtip_pci_resume(struct pci_dev *pdev)\r\n{\r\nint rv = 0;\r\nstruct driver_data *dd;\r\ndd = pci_get_drvdata(pdev);\r\nif (!dd) {\r\ndev_err(&pdev->dev,\r\n"Driver private datastructure is NULL\n");\r\nreturn -EFAULT;\r\n}\r\npci_set_power_state(pdev, PCI_D0);\r\npci_restore_state(pdev);\r\nrv = pcim_enable_device(pdev);\r\nif (rv < 0) {\r\ndev_err(&pdev->dev,\r\n"Failed to enable card during resume\n");\r\ngoto err;\r\n}\r\npci_set_master(pdev);\r\nrv = mtip_block_resume(dd);\r\nif (rv < 0)\r\ndev_err(&pdev->dev, "Unable to resume\n");\r\nerr:\r\nclear_bit(MTIP_DDF_RESUME_BIT, &dd->dd_flag);\r\nreturn rv;\r\n}\r\nstatic void mtip_pci_shutdown(struct pci_dev *pdev)\r\n{\r\nstruct driver_data *dd = pci_get_drvdata(pdev);\r\nif (dd)\r\nmtip_block_shutdown(dd);\r\n}\r\nstatic int __init mtip_init(void)\r\n{\r\nint error;\r\npr_info(MTIP_DRV_NAME " Version " MTIP_DRV_VERSION "\n");\r\nspin_lock_init(&dev_lock);\r\nINIT_LIST_HEAD(&online_list);\r\nINIT_LIST_HEAD(&removing_list);\r\nerror = register_blkdev(0, MTIP_DRV_NAME);\r\nif (error <= 0) {\r\npr_err("Unable to register block device (%d)\n",\r\nerror);\r\nreturn -EBUSY;\r\n}\r\nmtip_major = error;\r\ndfs_parent = debugfs_create_dir("rssd", NULL);\r\nif (IS_ERR_OR_NULL(dfs_parent)) {\r\npr_warn("Error creating debugfs parent\n");\r\ndfs_parent = NULL;\r\n}\r\nif (dfs_parent) {\r\ndfs_device_status = debugfs_create_file("device_status",\r\nS_IRUGO, dfs_parent, NULL,\r\n&mtip_device_status_fops);\r\nif (IS_ERR_OR_NULL(dfs_device_status)) {\r\npr_err("Error creating device_status node\n");\r\ndfs_device_status = NULL;\r\n}\r\n}\r\nerror = pci_register_driver(&mtip_pci_driver);\r\nif (error) {\r\ndebugfs_remove(dfs_parent);\r\nunregister_blkdev(mtip_major, MTIP_DRV_NAME);\r\n}\r\nreturn error;\r\n}\r\nstatic void __exit mtip_exit(void)\r\n{\r\nunregister_blkdev(mtip_major, MTIP_DRV_NAME);\r\npci_unregister_driver(&mtip_pci_driver);\r\ndebugfs_remove_recursive(dfs_parent);\r\n}
