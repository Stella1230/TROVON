static inline void regcache_rbtree_get_base_top_reg(\r\nstruct regmap *map,\r\nstruct regcache_rbtree_node *rbnode,\r\nunsigned int *base, unsigned int *top)\r\n{\r\n*base = rbnode->base_reg;\r\n*top = rbnode->base_reg + ((rbnode->blklen - 1) * map->reg_stride);\r\n}\r\nstatic unsigned int regcache_rbtree_get_register(struct regmap *map,\r\nstruct regcache_rbtree_node *rbnode, unsigned int idx)\r\n{\r\nreturn regcache_get_val(map, rbnode->block, idx);\r\n}\r\nstatic void regcache_rbtree_set_register(struct regmap *map,\r\nstruct regcache_rbtree_node *rbnode,\r\nunsigned int idx, unsigned int val)\r\n{\r\nset_bit(idx, rbnode->cache_present);\r\nregcache_set_val(map, rbnode->block, idx, val);\r\n}\r\nstatic struct regcache_rbtree_node *regcache_rbtree_lookup(struct regmap *map,\r\nunsigned int reg)\r\n{\r\nstruct regcache_rbtree_ctx *rbtree_ctx = map->cache;\r\nstruct rb_node *node;\r\nstruct regcache_rbtree_node *rbnode;\r\nunsigned int base_reg, top_reg;\r\nrbnode = rbtree_ctx->cached_rbnode;\r\nif (rbnode) {\r\nregcache_rbtree_get_base_top_reg(map, rbnode, &base_reg,\r\n&top_reg);\r\nif (reg >= base_reg && reg <= top_reg)\r\nreturn rbnode;\r\n}\r\nnode = rbtree_ctx->root.rb_node;\r\nwhile (node) {\r\nrbnode = container_of(node, struct regcache_rbtree_node, node);\r\nregcache_rbtree_get_base_top_reg(map, rbnode, &base_reg,\r\n&top_reg);\r\nif (reg >= base_reg && reg <= top_reg) {\r\nrbtree_ctx->cached_rbnode = rbnode;\r\nreturn rbnode;\r\n} else if (reg > top_reg) {\r\nnode = node->rb_right;\r\n} else if (reg < base_reg) {\r\nnode = node->rb_left;\r\n}\r\n}\r\nreturn NULL;\r\n}\r\nstatic int regcache_rbtree_insert(struct regmap *map, struct rb_root *root,\r\nstruct regcache_rbtree_node *rbnode)\r\n{\r\nstruct rb_node **new, *parent;\r\nstruct regcache_rbtree_node *rbnode_tmp;\r\nunsigned int base_reg_tmp, top_reg_tmp;\r\nunsigned int base_reg;\r\nparent = NULL;\r\nnew = &root->rb_node;\r\nwhile (*new) {\r\nrbnode_tmp = container_of(*new, struct regcache_rbtree_node,\r\nnode);\r\nregcache_rbtree_get_base_top_reg(map, rbnode_tmp, &base_reg_tmp,\r\n&top_reg_tmp);\r\nbase_reg = rbnode->base_reg;\r\nparent = *new;\r\nif (base_reg >= base_reg_tmp &&\r\nbase_reg <= top_reg_tmp)\r\nreturn 0;\r\nelse if (base_reg > top_reg_tmp)\r\nnew = &((*new)->rb_right);\r\nelse if (base_reg < base_reg_tmp)\r\nnew = &((*new)->rb_left);\r\n}\r\nrb_link_node(&rbnode->node, parent, new);\r\nrb_insert_color(&rbnode->node, root);\r\nreturn 1;\r\n}\r\nstatic int rbtree_show(struct seq_file *s, void *ignored)\r\n{\r\nstruct regmap *map = s->private;\r\nstruct regcache_rbtree_ctx *rbtree_ctx = map->cache;\r\nstruct regcache_rbtree_node *n;\r\nstruct rb_node *node;\r\nunsigned int base, top;\r\nsize_t mem_size;\r\nint nodes = 0;\r\nint registers = 0;\r\nint this_registers, average;\r\nmap->lock(map->lock_arg);\r\nmem_size = sizeof(*rbtree_ctx);\r\nfor (node = rb_first(&rbtree_ctx->root); node != NULL;\r\nnode = rb_next(node)) {\r\nn = container_of(node, struct regcache_rbtree_node, node);\r\nmem_size += sizeof(*n);\r\nmem_size += (n->blklen * map->cache_word_size);\r\nmem_size += BITS_TO_LONGS(n->blklen) * sizeof(long);\r\nregcache_rbtree_get_base_top_reg(map, n, &base, &top);\r\nthis_registers = ((top - base) / map->reg_stride) + 1;\r\nseq_printf(s, "%x-%x (%d)\n", base, top, this_registers);\r\nnodes++;\r\nregisters += this_registers;\r\n}\r\nif (nodes)\r\naverage = registers / nodes;\r\nelse\r\naverage = 0;\r\nseq_printf(s, "%d nodes, %d registers, average %d registers, used %zu bytes\n",\r\nnodes, registers, average, mem_size);\r\nmap->unlock(map->lock_arg);\r\nreturn 0;\r\n}\r\nstatic int rbtree_open(struct inode *inode, struct file *file)\r\n{\r\nreturn single_open(file, rbtree_show, inode->i_private);\r\n}\r\nstatic void rbtree_debugfs_init(struct regmap *map)\r\n{\r\ndebugfs_create_file("rbtree", 0400, map->debugfs, map, &rbtree_fops);\r\n}\r\nstatic int regcache_rbtree_init(struct regmap *map)\r\n{\r\nstruct regcache_rbtree_ctx *rbtree_ctx;\r\nint i;\r\nint ret;\r\nmap->cache = kmalloc(sizeof *rbtree_ctx, GFP_KERNEL);\r\nif (!map->cache)\r\nreturn -ENOMEM;\r\nrbtree_ctx = map->cache;\r\nrbtree_ctx->root = RB_ROOT;\r\nrbtree_ctx->cached_rbnode = NULL;\r\nfor (i = 0; i < map->num_reg_defaults; i++) {\r\nret = regcache_rbtree_write(map,\r\nmap->reg_defaults[i].reg,\r\nmap->reg_defaults[i].def);\r\nif (ret)\r\ngoto err;\r\n}\r\nreturn 0;\r\nerr:\r\nregcache_rbtree_exit(map);\r\nreturn ret;\r\n}\r\nstatic int regcache_rbtree_exit(struct regmap *map)\r\n{\r\nstruct rb_node *next;\r\nstruct regcache_rbtree_ctx *rbtree_ctx;\r\nstruct regcache_rbtree_node *rbtree_node;\r\nrbtree_ctx = map->cache;\r\nif (!rbtree_ctx)\r\nreturn 0;\r\nnext = rb_first(&rbtree_ctx->root);\r\nwhile (next) {\r\nrbtree_node = rb_entry(next, struct regcache_rbtree_node, node);\r\nnext = rb_next(&rbtree_node->node);\r\nrb_erase(&rbtree_node->node, &rbtree_ctx->root);\r\nkfree(rbtree_node->cache_present);\r\nkfree(rbtree_node->block);\r\nkfree(rbtree_node);\r\n}\r\nkfree(map->cache);\r\nmap->cache = NULL;\r\nreturn 0;\r\n}\r\nstatic int regcache_rbtree_read(struct regmap *map,\r\nunsigned int reg, unsigned int *value)\r\n{\r\nstruct regcache_rbtree_node *rbnode;\r\nunsigned int reg_tmp;\r\nrbnode = regcache_rbtree_lookup(map, reg);\r\nif (rbnode) {\r\nreg_tmp = (reg - rbnode->base_reg) / map->reg_stride;\r\nif (!test_bit(reg_tmp, rbnode->cache_present))\r\nreturn -ENOENT;\r\n*value = regcache_rbtree_get_register(map, rbnode, reg_tmp);\r\n} else {\r\nreturn -ENOENT;\r\n}\r\nreturn 0;\r\n}\r\nstatic int regcache_rbtree_insert_to_block(struct regmap *map,\r\nstruct regcache_rbtree_node *rbnode,\r\nunsigned int base_reg,\r\nunsigned int top_reg,\r\nunsigned int reg,\r\nunsigned int value)\r\n{\r\nunsigned int blklen;\r\nunsigned int pos, offset;\r\nunsigned long *present;\r\nu8 *blk;\r\nblklen = (top_reg - base_reg) / map->reg_stride + 1;\r\npos = (reg - base_reg) / map->reg_stride;\r\noffset = (rbnode->base_reg - base_reg) / map->reg_stride;\r\nblk = krealloc(rbnode->block,\r\nblklen * map->cache_word_size,\r\nGFP_KERNEL);\r\nif (!blk)\r\nreturn -ENOMEM;\r\npresent = krealloc(rbnode->cache_present,\r\nBITS_TO_LONGS(blklen) * sizeof(*present), GFP_KERNEL);\r\nif (!present) {\r\nkfree(blk);\r\nreturn -ENOMEM;\r\n}\r\nif (pos == 0) {\r\nmemmove(blk + offset * map->cache_word_size,\r\nblk, rbnode->blklen * map->cache_word_size);\r\nbitmap_shift_left(present, present, offset, blklen);\r\n}\r\nrbnode->block = blk;\r\nrbnode->blklen = blklen;\r\nrbnode->base_reg = base_reg;\r\nrbnode->cache_present = present;\r\nregcache_rbtree_set_register(map, rbnode, pos, value);\r\nreturn 0;\r\n}\r\nstatic struct regcache_rbtree_node *\r\nregcache_rbtree_node_alloc(struct regmap *map, unsigned int reg)\r\n{\r\nstruct regcache_rbtree_node *rbnode;\r\nconst struct regmap_range *range;\r\nint i;\r\nrbnode = kzalloc(sizeof(*rbnode), GFP_KERNEL);\r\nif (!rbnode)\r\nreturn NULL;\r\nif (map->rd_table) {\r\nfor (i = 0; i < map->rd_table->n_yes_ranges; i++) {\r\nif (regmap_reg_in_range(reg,\r\n&map->rd_table->yes_ranges[i]))\r\nbreak;\r\n}\r\nif (i != map->rd_table->n_yes_ranges) {\r\nrange = &map->rd_table->yes_ranges[i];\r\nrbnode->blklen = (range->range_max - range->range_min) /\r\nmap->reg_stride + 1;\r\nrbnode->base_reg = range->range_min;\r\n}\r\n}\r\nif (!rbnode->blklen) {\r\nrbnode->blklen = 1;\r\nrbnode->base_reg = reg;\r\n}\r\nrbnode->block = kmalloc(rbnode->blklen * map->cache_word_size,\r\nGFP_KERNEL);\r\nif (!rbnode->block)\r\ngoto err_free;\r\nrbnode->cache_present = kzalloc(BITS_TO_LONGS(rbnode->blklen) *\r\nsizeof(*rbnode->cache_present), GFP_KERNEL);\r\nif (!rbnode->cache_present)\r\ngoto err_free_block;\r\nreturn rbnode;\r\nerr_free_block:\r\nkfree(rbnode->block);\r\nerr_free:\r\nkfree(rbnode);\r\nreturn NULL;\r\n}\r\nstatic int regcache_rbtree_write(struct regmap *map, unsigned int reg,\r\nunsigned int value)\r\n{\r\nstruct regcache_rbtree_ctx *rbtree_ctx;\r\nstruct regcache_rbtree_node *rbnode, *rbnode_tmp;\r\nstruct rb_node *node;\r\nunsigned int reg_tmp;\r\nint ret;\r\nrbtree_ctx = map->cache;\r\nrbnode = regcache_rbtree_lookup(map, reg);\r\nif (rbnode) {\r\nreg_tmp = (reg - rbnode->base_reg) / map->reg_stride;\r\nregcache_rbtree_set_register(map, rbnode, reg_tmp, value);\r\n} else {\r\nunsigned int base_reg, top_reg;\r\nunsigned int new_base_reg, new_top_reg;\r\nunsigned int min, max;\r\nunsigned int max_dist;\r\nmax_dist = map->reg_stride * sizeof(*rbnode_tmp) /\r\nmap->cache_word_size;\r\nif (reg < max_dist)\r\nmin = 0;\r\nelse\r\nmin = reg - max_dist;\r\nmax = reg + max_dist;\r\nfor (node = rb_first(&rbtree_ctx->root); node;\r\nnode = rb_next(node)) {\r\nrbnode_tmp = rb_entry(node, struct regcache_rbtree_node,\r\nnode);\r\nregcache_rbtree_get_base_top_reg(map, rbnode_tmp,\r\n&base_reg, &top_reg);\r\nif (base_reg <= max && top_reg >= min) {\r\nnew_base_reg = min(reg, base_reg);\r\nnew_top_reg = max(reg, top_reg);\r\n} else {\r\ncontinue;\r\n}\r\nret = regcache_rbtree_insert_to_block(map, rbnode_tmp,\r\nnew_base_reg,\r\nnew_top_reg, reg,\r\nvalue);\r\nif (ret)\r\nreturn ret;\r\nrbtree_ctx->cached_rbnode = rbnode_tmp;\r\nreturn 0;\r\n}\r\nrbnode = regcache_rbtree_node_alloc(map, reg);\r\nif (!rbnode)\r\nreturn -ENOMEM;\r\nregcache_rbtree_set_register(map, rbnode,\r\nreg - rbnode->base_reg, value);\r\nregcache_rbtree_insert(map, &rbtree_ctx->root, rbnode);\r\nrbtree_ctx->cached_rbnode = rbnode;\r\n}\r\nreturn 0;\r\n}\r\nstatic int regcache_rbtree_sync(struct regmap *map, unsigned int min,\r\nunsigned int max)\r\n{\r\nstruct regcache_rbtree_ctx *rbtree_ctx;\r\nstruct rb_node *node;\r\nstruct regcache_rbtree_node *rbnode;\r\nunsigned int base_reg, top_reg;\r\nunsigned int start, end;\r\nint ret;\r\nrbtree_ctx = map->cache;\r\nfor (node = rb_first(&rbtree_ctx->root); node; node = rb_next(node)) {\r\nrbnode = rb_entry(node, struct regcache_rbtree_node, node);\r\nregcache_rbtree_get_base_top_reg(map, rbnode, &base_reg,\r\n&top_reg);\r\nif (base_reg > max)\r\nbreak;\r\nif (top_reg < min)\r\ncontinue;\r\nif (min > base_reg)\r\nstart = (min - base_reg) / map->reg_stride;\r\nelse\r\nstart = 0;\r\nif (max < top_reg)\r\nend = (max - base_reg) / map->reg_stride + 1;\r\nelse\r\nend = rbnode->blklen;\r\nret = regcache_sync_block(map, rbnode->block,\r\nrbnode->cache_present,\r\nrbnode->base_reg, start, end);\r\nif (ret != 0)\r\nreturn ret;\r\n}\r\nreturn regmap_async_complete(map);\r\n}\r\nstatic int regcache_rbtree_drop(struct regmap *map, unsigned int min,\r\nunsigned int max)\r\n{\r\nstruct regcache_rbtree_ctx *rbtree_ctx;\r\nstruct regcache_rbtree_node *rbnode;\r\nstruct rb_node *node;\r\nunsigned int base_reg, top_reg;\r\nunsigned int start, end;\r\nrbtree_ctx = map->cache;\r\nfor (node = rb_first(&rbtree_ctx->root); node; node = rb_next(node)) {\r\nrbnode = rb_entry(node, struct regcache_rbtree_node, node);\r\nregcache_rbtree_get_base_top_reg(map, rbnode, &base_reg,\r\n&top_reg);\r\nif (base_reg > max)\r\nbreak;\r\nif (top_reg < min)\r\ncontinue;\r\nif (min > base_reg)\r\nstart = (min - base_reg) / map->reg_stride;\r\nelse\r\nstart = 0;\r\nif (max < top_reg)\r\nend = (max - base_reg) / map->reg_stride + 1;\r\nelse\r\nend = rbnode->blklen;\r\nbitmap_clear(rbnode->cache_present, start, end - start);\r\n}\r\nreturn 0;\r\n}
