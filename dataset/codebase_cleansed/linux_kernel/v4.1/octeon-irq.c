static int octeon_irq_set_ciu_mapping(int irq, int line, int bit, int gpio_line,\r\nstruct irq_chip *chip,\r\nirq_flow_handler_t handler)\r\n{\r\nstruct octeon_ciu_chip_data *cd;\r\ncd = kzalloc(sizeof(*cd), GFP_KERNEL);\r\nif (!cd)\r\nreturn -ENOMEM;\r\nirq_set_chip_and_handler(irq, chip, handler);\r\ncd->line = line;\r\ncd->bit = bit;\r\ncd->gpio_line = gpio_line;\r\nirq_set_chip_data(irq, cd);\r\nocteon_irq_ciu_to_irq[line][bit] = irq;\r\nreturn 0;\r\n}\r\nstatic void octeon_irq_free_cd(struct irq_domain *d, unsigned int irq)\r\n{\r\nstruct irq_data *data = irq_get_irq_data(irq);\r\nstruct octeon_ciu_chip_data *cd = irq_data_get_irq_chip_data(data);\r\nirq_set_chip_data(irq, NULL);\r\nkfree(cd);\r\n}\r\nstatic int octeon_irq_force_ciu_mapping(struct irq_domain *domain,\r\nint irq, int line, int bit)\r\n{\r\nreturn irq_domain_associate(domain, irq, line << 6 | bit);\r\n}\r\nstatic int octeon_coreid_for_cpu(int cpu)\r\n{\r\n#ifdef CONFIG_SMP\r\nreturn cpu_logical_map(cpu);\r\n#else\r\nreturn cvmx_get_core_num();\r\n#endif\r\n}\r\nstatic int octeon_cpu_for_coreid(int coreid)\r\n{\r\n#ifdef CONFIG_SMP\r\nreturn cpu_number_map(coreid);\r\n#else\r\nreturn smp_processor_id();\r\n#endif\r\n}\r\nstatic void octeon_irq_core_ack(struct irq_data *data)\r\n{\r\nstruct octeon_core_chip_data *cd = irq_data_get_irq_chip_data(data);\r\nunsigned int bit = cd->bit;\r\nclear_c0_status(0x100 << bit);\r\nif (bit < 2)\r\nclear_c0_cause(0x100 << bit);\r\n}\r\nstatic void octeon_irq_core_eoi(struct irq_data *data)\r\n{\r\nstruct octeon_core_chip_data *cd = irq_data_get_irq_chip_data(data);\r\nset_c0_status(0x100 << cd->bit);\r\n}\r\nstatic void octeon_irq_core_set_enable_local(void *arg)\r\n{\r\nstruct irq_data *data = arg;\r\nstruct octeon_core_chip_data *cd = irq_data_get_irq_chip_data(data);\r\nunsigned int mask = 0x100 << cd->bit;\r\nif (cd->desired_en)\r\nset_c0_status(mask);\r\nelse\r\nclear_c0_status(mask);\r\n}\r\nstatic void octeon_irq_core_disable(struct irq_data *data)\r\n{\r\nstruct octeon_core_chip_data *cd = irq_data_get_irq_chip_data(data);\r\ncd->desired_en = false;\r\n}\r\nstatic void octeon_irq_core_enable(struct irq_data *data)\r\n{\r\nstruct octeon_core_chip_data *cd = irq_data_get_irq_chip_data(data);\r\ncd->desired_en = true;\r\n}\r\nstatic void octeon_irq_core_bus_lock(struct irq_data *data)\r\n{\r\nstruct octeon_core_chip_data *cd = irq_data_get_irq_chip_data(data);\r\nmutex_lock(&cd->core_irq_mutex);\r\n}\r\nstatic void octeon_irq_core_bus_sync_unlock(struct irq_data *data)\r\n{\r\nstruct octeon_core_chip_data *cd = irq_data_get_irq_chip_data(data);\r\nif (cd->desired_en != cd->current_en) {\r\non_each_cpu(octeon_irq_core_set_enable_local, data, 1);\r\ncd->current_en = cd->desired_en;\r\n}\r\nmutex_unlock(&cd->core_irq_mutex);\r\n}\r\nstatic void __init octeon_irq_init_core(void)\r\n{\r\nint i;\r\nint irq;\r\nstruct octeon_core_chip_data *cd;\r\nfor (i = 0; i < MIPS_CORE_IRQ_LINES; i++) {\r\ncd = &octeon_irq_core_chip_data[i];\r\ncd->current_en = false;\r\ncd->desired_en = false;\r\ncd->bit = i;\r\nmutex_init(&cd->core_irq_mutex);\r\nirq = OCTEON_IRQ_SW0 + i;\r\nirq_set_chip_data(irq, cd);\r\nirq_set_chip_and_handler(irq, &octeon_irq_chip_core,\r\nhandle_percpu_irq);\r\n}\r\n}\r\nstatic int next_cpu_for_irq(struct irq_data *data)\r\n{\r\n#ifdef CONFIG_SMP\r\nint cpu;\r\nint weight = cpumask_weight(data->affinity);\r\nstruct octeon_ciu_chip_data *cd = irq_data_get_irq_chip_data(data);\r\nif (weight > 1) {\r\ncpu = cd->current_cpu;\r\nfor (;;) {\r\ncpu = cpumask_next(cpu, data->affinity);\r\nif (cpu >= nr_cpu_ids) {\r\ncpu = -1;\r\ncontinue;\r\n} else if (cpumask_test_cpu(cpu, cpu_online_mask)) {\r\nbreak;\r\n}\r\n}\r\n} else if (weight == 1) {\r\ncpu = cpumask_first(data->affinity);\r\n} else {\r\ncpu = smp_processor_id();\r\n}\r\ncd->current_cpu = cpu;\r\nreturn cpu;\r\n#else\r\nreturn smp_processor_id();\r\n#endif\r\n}\r\nstatic void octeon_irq_ciu_enable(struct irq_data *data)\r\n{\r\nint cpu = next_cpu_for_irq(data);\r\nint coreid = octeon_coreid_for_cpu(cpu);\r\nunsigned long *pen;\r\nunsigned long flags;\r\nstruct octeon_ciu_chip_data *cd;\r\nraw_spinlock_t *lock = &per_cpu(octeon_irq_ciu_spinlock, cpu);\r\ncd = irq_data_get_irq_chip_data(data);\r\nraw_spin_lock_irqsave(lock, flags);\r\nif (cd->line == 0) {\r\npen = &per_cpu(octeon_irq_ciu0_en_mirror, cpu);\r\n__set_bit(cd->bit, pen);\r\nwmb();\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0(coreid * 2), *pen);\r\n} else {\r\npen = &per_cpu(octeon_irq_ciu1_en_mirror, cpu);\r\n__set_bit(cd->bit, pen);\r\nwmb();\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1(coreid * 2 + 1), *pen);\r\n}\r\nraw_spin_unlock_irqrestore(lock, flags);\r\n}\r\nstatic void octeon_irq_ciu_enable_local(struct irq_data *data)\r\n{\r\nunsigned long *pen;\r\nunsigned long flags;\r\nstruct octeon_ciu_chip_data *cd;\r\nraw_spinlock_t *lock = this_cpu_ptr(&octeon_irq_ciu_spinlock);\r\ncd = irq_data_get_irq_chip_data(data);\r\nraw_spin_lock_irqsave(lock, flags);\r\nif (cd->line == 0) {\r\npen = this_cpu_ptr(&octeon_irq_ciu0_en_mirror);\r\n__set_bit(cd->bit, pen);\r\nwmb();\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0(cvmx_get_core_num() * 2), *pen);\r\n} else {\r\npen = this_cpu_ptr(&octeon_irq_ciu1_en_mirror);\r\n__set_bit(cd->bit, pen);\r\nwmb();\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1(cvmx_get_core_num() * 2 + 1), *pen);\r\n}\r\nraw_spin_unlock_irqrestore(lock, flags);\r\n}\r\nstatic void octeon_irq_ciu_disable_local(struct irq_data *data)\r\n{\r\nunsigned long *pen;\r\nunsigned long flags;\r\nstruct octeon_ciu_chip_data *cd;\r\nraw_spinlock_t *lock = this_cpu_ptr(&octeon_irq_ciu_spinlock);\r\ncd = irq_data_get_irq_chip_data(data);\r\nraw_spin_lock_irqsave(lock, flags);\r\nif (cd->line == 0) {\r\npen = this_cpu_ptr(&octeon_irq_ciu0_en_mirror);\r\n__clear_bit(cd->bit, pen);\r\nwmb();\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0(cvmx_get_core_num() * 2), *pen);\r\n} else {\r\npen = this_cpu_ptr(&octeon_irq_ciu1_en_mirror);\r\n__clear_bit(cd->bit, pen);\r\nwmb();\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1(cvmx_get_core_num() * 2 + 1), *pen);\r\n}\r\nraw_spin_unlock_irqrestore(lock, flags);\r\n}\r\nstatic void octeon_irq_ciu_disable_all(struct irq_data *data)\r\n{\r\nunsigned long flags;\r\nunsigned long *pen;\r\nint cpu;\r\nstruct octeon_ciu_chip_data *cd;\r\nraw_spinlock_t *lock;\r\ncd = irq_data_get_irq_chip_data(data);\r\nfor_each_online_cpu(cpu) {\r\nint coreid = octeon_coreid_for_cpu(cpu);\r\nlock = &per_cpu(octeon_irq_ciu_spinlock, cpu);\r\nif (cd->line == 0)\r\npen = &per_cpu(octeon_irq_ciu0_en_mirror, cpu);\r\nelse\r\npen = &per_cpu(octeon_irq_ciu1_en_mirror, cpu);\r\nraw_spin_lock_irqsave(lock, flags);\r\n__clear_bit(cd->bit, pen);\r\nwmb();\r\nif (cd->line == 0)\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0(coreid * 2), *pen);\r\nelse\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1(coreid * 2 + 1), *pen);\r\nraw_spin_unlock_irqrestore(lock, flags);\r\n}\r\n}\r\nstatic void octeon_irq_ciu_enable_all(struct irq_data *data)\r\n{\r\nunsigned long flags;\r\nunsigned long *pen;\r\nint cpu;\r\nstruct octeon_ciu_chip_data *cd;\r\nraw_spinlock_t *lock;\r\ncd = irq_data_get_irq_chip_data(data);\r\nfor_each_online_cpu(cpu) {\r\nint coreid = octeon_coreid_for_cpu(cpu);\r\nlock = &per_cpu(octeon_irq_ciu_spinlock, cpu);\r\nif (cd->line == 0)\r\npen = &per_cpu(octeon_irq_ciu0_en_mirror, cpu);\r\nelse\r\npen = &per_cpu(octeon_irq_ciu1_en_mirror, cpu);\r\nraw_spin_lock_irqsave(lock, flags);\r\n__set_bit(cd->bit, pen);\r\nwmb();\r\nif (cd->line == 0)\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0(coreid * 2), *pen);\r\nelse\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1(coreid * 2 + 1), *pen);\r\nraw_spin_unlock_irqrestore(lock, flags);\r\n}\r\n}\r\nstatic void octeon_irq_ciu_enable_v2(struct irq_data *data)\r\n{\r\nu64 mask;\r\nint cpu = next_cpu_for_irq(data);\r\nstruct octeon_ciu_chip_data *cd;\r\ncd = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd->bit);\r\nif (cd->line == 0) {\r\nint index = octeon_coreid_for_cpu(cpu) * 2;\r\nset_bit(cd->bit, &per_cpu(octeon_irq_ciu0_en_mirror, cpu));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0_W1S(index), mask);\r\n} else {\r\nint index = octeon_coreid_for_cpu(cpu) * 2 + 1;\r\nset_bit(cd->bit, &per_cpu(octeon_irq_ciu1_en_mirror, cpu));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1_W1S(index), mask);\r\n}\r\n}\r\nstatic void octeon_irq_ciu_enable_sum2(struct irq_data *data)\r\n{\r\nu64 mask;\r\nint cpu = next_cpu_for_irq(data);\r\nint index = octeon_coreid_for_cpu(cpu);\r\nstruct octeon_ciu_chip_data *cd;\r\ncd = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd->bit);\r\ncvmx_write_csr(CVMX_CIU_EN2_PPX_IP4_W1S(index), mask);\r\n}\r\nstatic void octeon_irq_ciu_disable_local_sum2(struct irq_data *data)\r\n{\r\nu64 mask;\r\nint cpu = next_cpu_for_irq(data);\r\nint index = octeon_coreid_for_cpu(cpu);\r\nstruct octeon_ciu_chip_data *cd;\r\ncd = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd->bit);\r\ncvmx_write_csr(CVMX_CIU_EN2_PPX_IP4_W1C(index), mask);\r\n}\r\nstatic void octeon_irq_ciu_ack_sum2(struct irq_data *data)\r\n{\r\nu64 mask;\r\nint cpu = next_cpu_for_irq(data);\r\nint index = octeon_coreid_for_cpu(cpu);\r\nstruct octeon_ciu_chip_data *cd;\r\ncd = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd->bit);\r\ncvmx_write_csr(CVMX_CIU_SUM2_PPX_IP4(index), mask);\r\n}\r\nstatic void octeon_irq_ciu_disable_all_sum2(struct irq_data *data)\r\n{\r\nint cpu;\r\nstruct octeon_ciu_chip_data *cd;\r\nu64 mask;\r\ncd = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd->bit);\r\nfor_each_online_cpu(cpu) {\r\nint coreid = octeon_coreid_for_cpu(cpu);\r\ncvmx_write_csr(CVMX_CIU_EN2_PPX_IP4_W1C(coreid), mask);\r\n}\r\n}\r\nstatic void octeon_irq_ciu_enable_local_v2(struct irq_data *data)\r\n{\r\nu64 mask;\r\nstruct octeon_ciu_chip_data *cd;\r\ncd = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd->bit);\r\nif (cd->line == 0) {\r\nint index = cvmx_get_core_num() * 2;\r\nset_bit(cd->bit, this_cpu_ptr(&octeon_irq_ciu0_en_mirror));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0_W1S(index), mask);\r\n} else {\r\nint index = cvmx_get_core_num() * 2 + 1;\r\nset_bit(cd->bit, this_cpu_ptr(&octeon_irq_ciu1_en_mirror));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1_W1S(index), mask);\r\n}\r\n}\r\nstatic void octeon_irq_ciu_disable_local_v2(struct irq_data *data)\r\n{\r\nu64 mask;\r\nstruct octeon_ciu_chip_data *cd;\r\ncd = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd->bit);\r\nif (cd->line == 0) {\r\nint index = cvmx_get_core_num() * 2;\r\nclear_bit(cd->bit, this_cpu_ptr(&octeon_irq_ciu0_en_mirror));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0_W1C(index), mask);\r\n} else {\r\nint index = cvmx_get_core_num() * 2 + 1;\r\nclear_bit(cd->bit, this_cpu_ptr(&octeon_irq_ciu1_en_mirror));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1_W1C(index), mask);\r\n}\r\n}\r\nstatic void octeon_irq_ciu_ack(struct irq_data *data)\r\n{\r\nu64 mask;\r\nstruct octeon_ciu_chip_data *cd;\r\ncd = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd->bit);\r\nif (cd->line == 0) {\r\nint index = cvmx_get_core_num() * 2;\r\ncvmx_write_csr(CVMX_CIU_INTX_SUM0(index), mask);\r\n} else {\r\ncvmx_write_csr(CVMX_CIU_INT_SUM1, mask);\r\n}\r\n}\r\nstatic void octeon_irq_ciu_disable_all_v2(struct irq_data *data)\r\n{\r\nint cpu;\r\nu64 mask;\r\nstruct octeon_ciu_chip_data *cd;\r\ncd = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd->bit);\r\nif (cd->line == 0) {\r\nfor_each_online_cpu(cpu) {\r\nint index = octeon_coreid_for_cpu(cpu) * 2;\r\nclear_bit(cd->bit,\r\n&per_cpu(octeon_irq_ciu0_en_mirror, cpu));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0_W1C(index), mask);\r\n}\r\n} else {\r\nfor_each_online_cpu(cpu) {\r\nint index = octeon_coreid_for_cpu(cpu) * 2 + 1;\r\nclear_bit(cd->bit,\r\n&per_cpu(octeon_irq_ciu1_en_mirror, cpu));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1_W1C(index), mask);\r\n}\r\n}\r\n}\r\nstatic void octeon_irq_ciu_enable_all_v2(struct irq_data *data)\r\n{\r\nint cpu;\r\nu64 mask;\r\nstruct octeon_ciu_chip_data *cd;\r\ncd = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd->bit);\r\nif (cd->line == 0) {\r\nfor_each_online_cpu(cpu) {\r\nint index = octeon_coreid_for_cpu(cpu) * 2;\r\nset_bit(cd->bit,\r\n&per_cpu(octeon_irq_ciu0_en_mirror, cpu));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0_W1S(index), mask);\r\n}\r\n} else {\r\nfor_each_online_cpu(cpu) {\r\nint index = octeon_coreid_for_cpu(cpu) * 2 + 1;\r\nset_bit(cd->bit,\r\n&per_cpu(octeon_irq_ciu1_en_mirror, cpu));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1_W1S(index), mask);\r\n}\r\n}\r\n}\r\nstatic void octeon_irq_gpio_setup(struct irq_data *data)\r\n{\r\nunion cvmx_gpio_bit_cfgx cfg;\r\nstruct octeon_ciu_chip_data *cd;\r\nu32 t = irqd_get_trigger_type(data);\r\ncd = irq_data_get_irq_chip_data(data);\r\ncfg.u64 = 0;\r\ncfg.s.int_en = 1;\r\ncfg.s.int_type = (t & IRQ_TYPE_EDGE_BOTH) != 0;\r\ncfg.s.rx_xor = (t & (IRQ_TYPE_LEVEL_LOW | IRQ_TYPE_EDGE_FALLING)) != 0;\r\ncfg.s.fil_cnt = 7;\r\ncfg.s.fil_sel = 3;\r\ncvmx_write_csr(CVMX_GPIO_BIT_CFGX(cd->gpio_line), cfg.u64);\r\n}\r\nstatic void octeon_irq_ciu_enable_gpio_v2(struct irq_data *data)\r\n{\r\nocteon_irq_gpio_setup(data);\r\nocteon_irq_ciu_enable_v2(data);\r\n}\r\nstatic void octeon_irq_ciu_enable_gpio(struct irq_data *data)\r\n{\r\nocteon_irq_gpio_setup(data);\r\nocteon_irq_ciu_enable(data);\r\n}\r\nstatic int octeon_irq_ciu_gpio_set_type(struct irq_data *data, unsigned int t)\r\n{\r\nirqd_set_trigger_type(data, t);\r\nocteon_irq_gpio_setup(data);\r\nreturn IRQ_SET_MASK_OK;\r\n}\r\nstatic void octeon_irq_ciu_disable_gpio_v2(struct irq_data *data)\r\n{\r\nstruct octeon_ciu_chip_data *cd;\r\ncd = irq_data_get_irq_chip_data(data);\r\ncvmx_write_csr(CVMX_GPIO_BIT_CFGX(cd->gpio_line), 0);\r\nocteon_irq_ciu_disable_all_v2(data);\r\n}\r\nstatic void octeon_irq_ciu_disable_gpio(struct irq_data *data)\r\n{\r\nstruct octeon_ciu_chip_data *cd;\r\ncd = irq_data_get_irq_chip_data(data);\r\ncvmx_write_csr(CVMX_GPIO_BIT_CFGX(cd->gpio_line), 0);\r\nocteon_irq_ciu_disable_all(data);\r\n}\r\nstatic void octeon_irq_ciu_gpio_ack(struct irq_data *data)\r\n{\r\nstruct octeon_ciu_chip_data *cd;\r\nu64 mask;\r\ncd = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd->gpio_line);\r\ncvmx_write_csr(CVMX_GPIO_INT_CLR, mask);\r\n}\r\nstatic void octeon_irq_handle_trigger(unsigned int irq, struct irq_desc *desc)\r\n{\r\nif (irq_get_trigger_type(irq) & IRQ_TYPE_EDGE_BOTH)\r\nhandle_edge_irq(irq, desc);\r\nelse\r\nhandle_level_irq(irq, desc);\r\n}\r\nstatic void octeon_irq_cpu_offline_ciu(struct irq_data *data)\r\n{\r\nint cpu = smp_processor_id();\r\ncpumask_t new_affinity;\r\nif (!cpumask_test_cpu(cpu, data->affinity))\r\nreturn;\r\nif (cpumask_weight(data->affinity) > 1) {\r\ncpumask_copy(&new_affinity, data->affinity);\r\ncpumask_clear_cpu(cpu, &new_affinity);\r\n} else {\r\ncpumask_clear(&new_affinity);\r\ncpumask_set_cpu(cpumask_first(cpu_online_mask), &new_affinity);\r\n}\r\nirq_set_affinity_locked(data, &new_affinity, false);\r\n}\r\nstatic int octeon_irq_ciu_set_affinity(struct irq_data *data,\r\nconst struct cpumask *dest, bool force)\r\n{\r\nint cpu;\r\nbool enable_one = !irqd_irq_disabled(data) && !irqd_irq_masked(data);\r\nunsigned long flags;\r\nstruct octeon_ciu_chip_data *cd;\r\nunsigned long *pen;\r\nraw_spinlock_t *lock;\r\ncd = irq_data_get_irq_chip_data(data);\r\nif (cpumask_weight(dest) != 1)\r\nreturn -EINVAL;\r\nif (!enable_one)\r\nreturn 0;\r\nfor_each_online_cpu(cpu) {\r\nint coreid = octeon_coreid_for_cpu(cpu);\r\nlock = &per_cpu(octeon_irq_ciu_spinlock, cpu);\r\nraw_spin_lock_irqsave(lock, flags);\r\nif (cd->line == 0)\r\npen = &per_cpu(octeon_irq_ciu0_en_mirror, cpu);\r\nelse\r\npen = &per_cpu(octeon_irq_ciu1_en_mirror, cpu);\r\nif (cpumask_test_cpu(cpu, dest) && enable_one) {\r\nenable_one = 0;\r\n__set_bit(cd->bit, pen);\r\n} else {\r\n__clear_bit(cd->bit, pen);\r\n}\r\nwmb();\r\nif (cd->line == 0)\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0(coreid * 2), *pen);\r\nelse\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1(coreid * 2 + 1), *pen);\r\nraw_spin_unlock_irqrestore(lock, flags);\r\n}\r\nreturn 0;\r\n}\r\nstatic int octeon_irq_ciu_set_affinity_v2(struct irq_data *data,\r\nconst struct cpumask *dest,\r\nbool force)\r\n{\r\nint cpu;\r\nbool enable_one = !irqd_irq_disabled(data) && !irqd_irq_masked(data);\r\nu64 mask;\r\nstruct octeon_ciu_chip_data *cd;\r\nif (!enable_one)\r\nreturn 0;\r\ncd = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << cd->bit;\r\nif (cd->line == 0) {\r\nfor_each_online_cpu(cpu) {\r\nunsigned long *pen = &per_cpu(octeon_irq_ciu0_en_mirror, cpu);\r\nint index = octeon_coreid_for_cpu(cpu) * 2;\r\nif (cpumask_test_cpu(cpu, dest) && enable_one) {\r\nenable_one = false;\r\nset_bit(cd->bit, pen);\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0_W1S(index), mask);\r\n} else {\r\nclear_bit(cd->bit, pen);\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0_W1C(index), mask);\r\n}\r\n}\r\n} else {\r\nfor_each_online_cpu(cpu) {\r\nunsigned long *pen = &per_cpu(octeon_irq_ciu1_en_mirror, cpu);\r\nint index = octeon_coreid_for_cpu(cpu) * 2 + 1;\r\nif (cpumask_test_cpu(cpu, dest) && enable_one) {\r\nenable_one = false;\r\nset_bit(cd->bit, pen);\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1_W1S(index), mask);\r\n} else {\r\nclear_bit(cd->bit, pen);\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1_W1C(index), mask);\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int octeon_irq_ciu_set_affinity_sum2(struct irq_data *data,\r\nconst struct cpumask *dest,\r\nbool force)\r\n{\r\nint cpu;\r\nbool enable_one = !irqd_irq_disabled(data) && !irqd_irq_masked(data);\r\nu64 mask;\r\nstruct octeon_ciu_chip_data *cd;\r\nif (!enable_one)\r\nreturn 0;\r\ncd = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << cd->bit;\r\nfor_each_online_cpu(cpu) {\r\nint index = octeon_coreid_for_cpu(cpu);\r\nif (cpumask_test_cpu(cpu, dest) && enable_one) {\r\nenable_one = false;\r\ncvmx_write_csr(CVMX_CIU_EN2_PPX_IP4_W1S(index), mask);\r\n} else {\r\ncvmx_write_csr(CVMX_CIU_EN2_PPX_IP4_W1C(index), mask);\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void octeon_irq_ciu_wd_enable(struct irq_data *data)\r\n{\r\nunsigned long flags;\r\nunsigned long *pen;\r\nint coreid = data->irq - OCTEON_IRQ_WDOG0;\r\nint cpu = octeon_cpu_for_coreid(coreid);\r\nraw_spinlock_t *lock = &per_cpu(octeon_irq_ciu_spinlock, cpu);\r\nraw_spin_lock_irqsave(lock, flags);\r\npen = &per_cpu(octeon_irq_ciu1_en_mirror, cpu);\r\n__set_bit(coreid, pen);\r\nwmb();\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1(coreid * 2 + 1), *pen);\r\nraw_spin_unlock_irqrestore(lock, flags);\r\n}\r\nstatic void octeon_irq_ciu1_wd_enable_v2(struct irq_data *data)\r\n{\r\nint coreid = data->irq - OCTEON_IRQ_WDOG0;\r\nint cpu = octeon_cpu_for_coreid(coreid);\r\nset_bit(coreid, &per_cpu(octeon_irq_ciu1_en_mirror, cpu));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1_W1S(coreid * 2 + 1), 1ull << coreid);\r\n}\r\nstatic bool octeon_irq_ciu_is_edge(unsigned int line, unsigned int bit)\r\n{\r\nbool edge = false;\r\nif (line == 0)\r\nswitch (bit) {\r\ncase 48 ... 49:\r\ncase 50:\r\ncase 52 ... 55:\r\ncase 58:\r\nedge = true;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nelse\r\nswitch (bit) {\r\ncase 47:\r\nedge = true;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn edge;\r\n}\r\nstatic int octeon_irq_gpio_xlat(struct irq_domain *d,\r\nstruct device_node *node,\r\nconst u32 *intspec,\r\nunsigned int intsize,\r\nunsigned long *out_hwirq,\r\nunsigned int *out_type)\r\n{\r\nunsigned int type;\r\nunsigned int pin;\r\nunsigned int trigger;\r\nif (d->of_node != node)\r\nreturn -EINVAL;\r\nif (intsize < 2)\r\nreturn -EINVAL;\r\npin = intspec[0];\r\nif (pin >= 16)\r\nreturn -EINVAL;\r\ntrigger = intspec[1];\r\nswitch (trigger) {\r\ncase 1:\r\ntype = IRQ_TYPE_EDGE_RISING;\r\nbreak;\r\ncase 2:\r\ntype = IRQ_TYPE_EDGE_FALLING;\r\nbreak;\r\ncase 4:\r\ntype = IRQ_TYPE_LEVEL_HIGH;\r\nbreak;\r\ncase 8:\r\ntype = IRQ_TYPE_LEVEL_LOW;\r\nbreak;\r\ndefault:\r\npr_err("Error: (%s) Invalid irq trigger specification: %x\n",\r\nnode->name,\r\ntrigger);\r\ntype = IRQ_TYPE_LEVEL_LOW;\r\nbreak;\r\n}\r\n*out_type = type;\r\n*out_hwirq = pin;\r\nreturn 0;\r\n}\r\nstatic int octeon_irq_ciu_xlat(struct irq_domain *d,\r\nstruct device_node *node,\r\nconst u32 *intspec,\r\nunsigned int intsize,\r\nunsigned long *out_hwirq,\r\nunsigned int *out_type)\r\n{\r\nunsigned int ciu, bit;\r\nstruct octeon_irq_ciu_domain_data *dd = d->host_data;\r\nciu = intspec[0];\r\nbit = intspec[1];\r\nif (ciu >= dd->num_sum || bit > 63)\r\nreturn -EINVAL;\r\n*out_hwirq = (ciu << 6) | bit;\r\n*out_type = 0;\r\nreturn 0;\r\n}\r\nstatic bool octeon_irq_virq_in_range(unsigned int virq)\r\n{\r\nif (virq < (1ul << 8 * sizeof(octeon_irq_ciu_to_irq[0][0])))\r\nreturn true;\r\nWARN_ONCE(true, "virq out of range %u.\n", virq);\r\nreturn false;\r\n}\r\nstatic int octeon_irq_ciu_map(struct irq_domain *d,\r\nunsigned int virq, irq_hw_number_t hw)\r\n{\r\nint rv;\r\nunsigned int line = hw >> 6;\r\nunsigned int bit = hw & 63;\r\nstruct octeon_irq_ciu_domain_data *dd = d->host_data;\r\nif (!octeon_irq_virq_in_range(virq))\r\nreturn -EINVAL;\r\nif (line == 0 && bit >= 16 && bit <32)\r\nreturn 0;\r\nif (line >= dd->num_sum || octeon_irq_ciu_to_irq[line][bit] != 0)\r\nreturn -EINVAL;\r\nif (line == 2) {\r\nif (octeon_irq_ciu_is_edge(line, bit))\r\nrv = octeon_irq_set_ciu_mapping(virq, line, bit, 0,\r\n&octeon_irq_chip_ciu_sum2_edge,\r\nhandle_edge_irq);\r\nelse\r\nrv = octeon_irq_set_ciu_mapping(virq, line, bit, 0,\r\n&octeon_irq_chip_ciu_sum2,\r\nhandle_level_irq);\r\n} else {\r\nif (octeon_irq_ciu_is_edge(line, bit))\r\nrv = octeon_irq_set_ciu_mapping(virq, line, bit, 0,\r\nocteon_irq_ciu_chip_edge,\r\nhandle_edge_irq);\r\nelse\r\nrv = octeon_irq_set_ciu_mapping(virq, line, bit, 0,\r\nocteon_irq_ciu_chip,\r\nhandle_level_irq);\r\n}\r\nreturn rv;\r\n}\r\nstatic int octeon_irq_gpio_map(struct irq_domain *d,\r\nunsigned int virq, irq_hw_number_t hw)\r\n{\r\nstruct octeon_irq_gpio_domain_data *gpiod = d->host_data;\r\nunsigned int line, bit;\r\nint r;\r\nif (!octeon_irq_virq_in_range(virq))\r\nreturn -EINVAL;\r\nline = (hw + gpiod->base_hwirq) >> 6;\r\nbit = (hw + gpiod->base_hwirq) & 63;\r\nif (line > ARRAY_SIZE(octeon_irq_ciu_to_irq) ||\r\nocteon_irq_ciu_to_irq[line][bit] != 0)\r\nreturn -EINVAL;\r\nr = octeon_irq_set_ciu_mapping(virq, line, bit, hw,\r\nocteon_irq_gpio_chip, octeon_irq_handle_trigger);\r\nreturn r;\r\n}\r\nstatic void octeon_irq_ip2_ciu(void)\r\n{\r\nconst unsigned long core_id = cvmx_get_core_num();\r\nu64 ciu_sum = cvmx_read_csr(CVMX_CIU_INTX_SUM0(core_id * 2));\r\nciu_sum &= __this_cpu_read(octeon_irq_ciu0_en_mirror);\r\nif (likely(ciu_sum)) {\r\nint bit = fls64(ciu_sum) - 1;\r\nint irq = octeon_irq_ciu_to_irq[0][bit];\r\nif (likely(irq))\r\ndo_IRQ(irq);\r\nelse\r\nspurious_interrupt();\r\n} else {\r\nspurious_interrupt();\r\n}\r\n}\r\nstatic void octeon_irq_ip3_ciu(void)\r\n{\r\nu64 ciu_sum = cvmx_read_csr(CVMX_CIU_INT_SUM1);\r\nciu_sum &= __this_cpu_read(octeon_irq_ciu1_en_mirror);\r\nif (likely(ciu_sum)) {\r\nint bit = fls64(ciu_sum) - 1;\r\nint irq = octeon_irq_ciu_to_irq[1][bit];\r\nif (likely(irq))\r\ndo_IRQ(irq);\r\nelse\r\nspurious_interrupt();\r\n} else {\r\nspurious_interrupt();\r\n}\r\n}\r\nstatic void octeon_irq_ip4_ciu(void)\r\n{\r\nint coreid = cvmx_get_core_num();\r\nu64 ciu_sum = cvmx_read_csr(CVMX_CIU_SUM2_PPX_IP4(coreid));\r\nu64 ciu_en = cvmx_read_csr(CVMX_CIU_EN2_PPX_IP4(coreid));\r\nciu_sum &= ciu_en;\r\nif (likely(ciu_sum)) {\r\nint bit = fls64(ciu_sum) - 1;\r\nint irq = octeon_irq_ciu_to_irq[2][bit];\r\nif (likely(irq))\r\ndo_IRQ(irq);\r\nelse\r\nspurious_interrupt();\r\n} else {\r\nspurious_interrupt();\r\n}\r\n}\r\nstatic void octeon_irq_local_enable_ip4(void *arg)\r\n{\r\nset_c0_status(STATUSF_IP4);\r\n}\r\nstatic void octeon_irq_ip4_mask(void)\r\n{\r\nclear_c0_status(STATUSF_IP4);\r\nspurious_interrupt();\r\n}\r\nvoid octeon_irq_set_ip4_handler(octeon_irq_ip4_handler_t h)\r\n{\r\nocteon_irq_ip4 = h;\r\nocteon_irq_use_ip4 = true;\r\non_each_cpu(octeon_irq_local_enable_ip4, NULL, 1);\r\n}\r\nstatic void octeon_irq_percpu_enable(void)\r\n{\r\nirq_cpu_online();\r\n}\r\nstatic void octeon_irq_init_ciu_percpu(void)\r\n{\r\nint coreid = cvmx_get_core_num();\r\n__this_cpu_write(octeon_irq_ciu0_en_mirror, 0);\r\n__this_cpu_write(octeon_irq_ciu1_en_mirror, 0);\r\nwmb();\r\nraw_spin_lock_init(this_cpu_ptr(&octeon_irq_ciu_spinlock));\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0((coreid * 2)), 0);\r\ncvmx_write_csr(CVMX_CIU_INTX_EN0((coreid * 2 + 1)), 0);\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1((coreid * 2)), 0);\r\ncvmx_write_csr(CVMX_CIU_INTX_EN1((coreid * 2 + 1)), 0);\r\ncvmx_read_csr(CVMX_CIU_INTX_SUM0((coreid * 2)));\r\n}\r\nstatic void octeon_irq_init_ciu2_percpu(void)\r\n{\r\nu64 regx, ipx;\r\nint coreid = cvmx_get_core_num();\r\nu64 base = CVMX_CIU2_EN_PPX_IP2_WRKQ(coreid);\r\nfor (regx = 0; regx <= 0x8000; regx += 0x1000) {\r\nfor (ipx = 0; ipx <= 0x400; ipx += 0x200)\r\ncvmx_write_csr(base + regx + ipx, 0);\r\n}\r\ncvmx_read_csr(CVMX_CIU2_SUM_PPX_IP2(coreid));\r\n}\r\nstatic void octeon_irq_setup_secondary_ciu(void)\r\n{\r\nocteon_irq_init_ciu_percpu();\r\nocteon_irq_percpu_enable();\r\nset_c0_status(STATUSF_IP3 | STATUSF_IP2);\r\nif (octeon_irq_use_ip4)\r\nset_c0_status(STATUSF_IP4);\r\nelse\r\nclear_c0_status(STATUSF_IP4);\r\n}\r\nstatic void octeon_irq_setup_secondary_ciu2(void)\r\n{\r\nocteon_irq_init_ciu2_percpu();\r\nocteon_irq_percpu_enable();\r\nset_c0_status(STATUSF_IP3 | STATUSF_IP2);\r\nif (octeon_irq_use_ip4)\r\nset_c0_status(STATUSF_IP4);\r\nelse\r\nclear_c0_status(STATUSF_IP4);\r\n}\r\nstatic int __init octeon_irq_init_ciu(\r\nstruct device_node *ciu_node, struct device_node *parent)\r\n{\r\nunsigned int i, r;\r\nstruct irq_chip *chip;\r\nstruct irq_chip *chip_edge;\r\nstruct irq_chip *chip_mbox;\r\nstruct irq_chip *chip_wd;\r\nstruct irq_domain *ciu_domain = NULL;\r\nstruct octeon_irq_ciu_domain_data *dd;\r\ndd = kzalloc(sizeof(*dd), GFP_KERNEL);\r\nif (!dd)\r\nreturn -ENOMEM;\r\nocteon_irq_init_ciu_percpu();\r\nocteon_irq_setup_secondary = octeon_irq_setup_secondary_ciu;\r\nocteon_irq_ip2 = octeon_irq_ip2_ciu;\r\nocteon_irq_ip3 = octeon_irq_ip3_ciu;\r\nif ((OCTEON_IS_OCTEON2() || OCTEON_IS_OCTEON3())\r\n&& !OCTEON_IS_MODEL(OCTEON_CN63XX)) {\r\nocteon_irq_ip4 = octeon_irq_ip4_ciu;\r\ndd->num_sum = 3;\r\nocteon_irq_use_ip4 = true;\r\n} else {\r\nocteon_irq_ip4 = octeon_irq_ip4_mask;\r\ndd->num_sum = 2;\r\nocteon_irq_use_ip4 = false;\r\n}\r\nif (OCTEON_IS_MODEL(OCTEON_CN58XX_PASS2_X) ||\r\nOCTEON_IS_MODEL(OCTEON_CN56XX_PASS2_X) ||\r\nOCTEON_IS_MODEL(OCTEON_CN52XX_PASS2_X) ||\r\nOCTEON_IS_OCTEON2() || OCTEON_IS_OCTEON3()) {\r\nchip = &octeon_irq_chip_ciu_v2;\r\nchip_edge = &octeon_irq_chip_ciu_v2_edge;\r\nchip_mbox = &octeon_irq_chip_ciu_mbox_v2;\r\nchip_wd = &octeon_irq_chip_ciu_wd_v2;\r\nocteon_irq_gpio_chip = &octeon_irq_chip_ciu_gpio_v2;\r\n} else {\r\nchip = &octeon_irq_chip_ciu;\r\nchip_edge = &octeon_irq_chip_ciu_edge;\r\nchip_mbox = &octeon_irq_chip_ciu_mbox;\r\nchip_wd = &octeon_irq_chip_ciu_wd;\r\nocteon_irq_gpio_chip = &octeon_irq_chip_ciu_gpio;\r\n}\r\nocteon_irq_ciu_chip = chip;\r\nocteon_irq_ciu_chip_edge = chip_edge;\r\nocteon_irq_init_core();\r\nciu_domain = irq_domain_add_tree(\r\nciu_node, &octeon_irq_domain_ciu_ops, dd);\r\nirq_set_default_host(ciu_domain);\r\nfor (i = 0; i < 16; i++) {\r\nr = octeon_irq_force_ciu_mapping(\r\nciu_domain, i + OCTEON_IRQ_WORKQ0, 0, i + 0);\r\nif (r)\r\ngoto err;\r\n}\r\nr = octeon_irq_set_ciu_mapping(\r\nOCTEON_IRQ_MBOX0, 0, 32, 0, chip_mbox, handle_percpu_irq);\r\nif (r)\r\ngoto err;\r\nr = octeon_irq_set_ciu_mapping(\r\nOCTEON_IRQ_MBOX1, 0, 33, 0, chip_mbox, handle_percpu_irq);\r\nif (r)\r\ngoto err;\r\nfor (i = 0; i < 4; i++) {\r\nr = octeon_irq_force_ciu_mapping(\r\nciu_domain, i + OCTEON_IRQ_PCI_INT0, 0, i + 36);\r\nif (r)\r\ngoto err;\r\n}\r\nfor (i = 0; i < 4; i++) {\r\nr = octeon_irq_force_ciu_mapping(\r\nciu_domain, i + OCTEON_IRQ_PCI_MSI0, 0, i + 40);\r\nif (r)\r\ngoto err;\r\n}\r\nr = octeon_irq_force_ciu_mapping(ciu_domain, OCTEON_IRQ_TWSI, 0, 45);\r\nif (r)\r\ngoto err;\r\nr = octeon_irq_force_ciu_mapping(ciu_domain, OCTEON_IRQ_RML, 0, 46);\r\nif (r)\r\ngoto err;\r\nfor (i = 0; i < 4; i++) {\r\nr = octeon_irq_force_ciu_mapping(\r\nciu_domain, i + OCTEON_IRQ_TIMER0, 0, i + 52);\r\nif (r)\r\ngoto err;\r\n}\r\nr = octeon_irq_force_ciu_mapping(ciu_domain, OCTEON_IRQ_USB0, 0, 56);\r\nif (r)\r\ngoto err;\r\nr = octeon_irq_force_ciu_mapping(ciu_domain, OCTEON_IRQ_TWSI2, 0, 59);\r\nif (r)\r\ngoto err;\r\nfor (i = 0; i < 16; i++) {\r\nr = octeon_irq_set_ciu_mapping(\r\ni + OCTEON_IRQ_WDOG0, 1, i + 0, 0, chip_wd,\r\nhandle_level_irq);\r\nif (r)\r\ngoto err;\r\n}\r\nr = octeon_irq_force_ciu_mapping(ciu_domain, OCTEON_IRQ_USB1, 1, 17);\r\nif (r)\r\ngoto err;\r\nset_c0_status(STATUSF_IP3 | STATUSF_IP2);\r\nif (octeon_irq_use_ip4)\r\nset_c0_status(STATUSF_IP4);\r\nelse\r\nclear_c0_status(STATUSF_IP4);\r\nreturn 0;\r\nerr:\r\nreturn r;\r\n}\r\nstatic int __init octeon_irq_init_gpio(\r\nstruct device_node *gpio_node, struct device_node *parent)\r\n{\r\nstruct octeon_irq_gpio_domain_data *gpiod;\r\nu32 interrupt_cells;\r\nunsigned int base_hwirq;\r\nint r;\r\nr = of_property_read_u32(parent, "#interrupt-cells", &interrupt_cells);\r\nif (r)\r\nreturn r;\r\nif (interrupt_cells == 1) {\r\nu32 v;\r\nr = of_property_read_u32_index(gpio_node, "interrupts", 0, &v);\r\nif (r) {\r\npr_warn("No \"interrupts\" property.\n");\r\nreturn r;\r\n}\r\nbase_hwirq = v;\r\n} else if (interrupt_cells == 2) {\r\nu32 v0, v1;\r\nr = of_property_read_u32_index(gpio_node, "interrupts", 0, &v0);\r\nif (r) {\r\npr_warn("No \"interrupts\" property.\n");\r\nreturn r;\r\n}\r\nr = of_property_read_u32_index(gpio_node, "interrupts", 1, &v1);\r\nif (r) {\r\npr_warn("No \"interrupts\" property.\n");\r\nreturn r;\r\n}\r\nbase_hwirq = (v0 << 6) | v1;\r\n} else {\r\npr_warn("Bad \"#interrupt-cells\" property: %u\n",\r\ninterrupt_cells);\r\nreturn -EINVAL;\r\n}\r\ngpiod = kzalloc(sizeof(*gpiod), GFP_KERNEL);\r\nif (gpiod) {\r\ngpiod->base_hwirq = base_hwirq;\r\nirq_domain_add_linear(\r\ngpio_node, 16, &octeon_irq_domain_gpio_ops, gpiod);\r\n} else {\r\npr_warn("Cannot allocate memory for GPIO irq_domain.\n");\r\nreturn -ENOMEM;\r\n}\r\nreturn 0;\r\n}\r\nstatic void octeon_irq_ciu2_wd_enable(struct irq_data *data)\r\n{\r\nu64 mask;\r\nu64 en_addr;\r\nint coreid = data->irq - OCTEON_IRQ_WDOG0;\r\nstruct octeon_ciu_chip_data *cd;\r\ncd = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd->bit);\r\nen_addr = CVMX_CIU2_EN_PPX_IP2_WRKQ_W1S(coreid) +\r\n(0x1000ull * cd->line);\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\nstatic void octeon_irq_ciu2_enable(struct irq_data *data)\r\n{\r\nu64 mask;\r\nu64 en_addr;\r\nint cpu = next_cpu_for_irq(data);\r\nint coreid = octeon_coreid_for_cpu(cpu);\r\nstruct octeon_ciu_chip_data *cd;\r\ncd = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd->bit);\r\nen_addr = CVMX_CIU2_EN_PPX_IP2_WRKQ_W1S(coreid) +\r\n(0x1000ull * cd->line);\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\nstatic void octeon_irq_ciu2_enable_local(struct irq_data *data)\r\n{\r\nu64 mask;\r\nu64 en_addr;\r\nint coreid = cvmx_get_core_num();\r\nstruct octeon_ciu_chip_data *cd;\r\ncd = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd->bit);\r\nen_addr = CVMX_CIU2_EN_PPX_IP2_WRKQ_W1S(coreid) +\r\n(0x1000ull * cd->line);\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\nstatic void octeon_irq_ciu2_disable_local(struct irq_data *data)\r\n{\r\nu64 mask;\r\nu64 en_addr;\r\nint coreid = cvmx_get_core_num();\r\nstruct octeon_ciu_chip_data *cd;\r\ncd = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd->bit);\r\nen_addr = CVMX_CIU2_EN_PPX_IP2_WRKQ_W1C(coreid) +\r\n(0x1000ull * cd->line);\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\nstatic void octeon_irq_ciu2_ack(struct irq_data *data)\r\n{\r\nu64 mask;\r\nu64 en_addr;\r\nint coreid = cvmx_get_core_num();\r\nstruct octeon_ciu_chip_data *cd;\r\ncd = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd->bit);\r\nen_addr = CVMX_CIU2_RAW_PPX_IP2_WRKQ(coreid) + (0x1000ull * cd->line);\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\nstatic void octeon_irq_ciu2_disable_all(struct irq_data *data)\r\n{\r\nint cpu;\r\nu64 mask;\r\nstruct octeon_ciu_chip_data *cd;\r\ncd = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << (cd->bit);\r\nfor_each_online_cpu(cpu) {\r\nu64 en_addr = CVMX_CIU2_EN_PPX_IP2_WRKQ_W1C(\r\nocteon_coreid_for_cpu(cpu)) + (0x1000ull * cd->line);\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\n}\r\nstatic void octeon_irq_ciu2_mbox_enable_all(struct irq_data *data)\r\n{\r\nint cpu;\r\nu64 mask;\r\nmask = 1ull << (data->irq - OCTEON_IRQ_MBOX0);\r\nfor_each_online_cpu(cpu) {\r\nu64 en_addr = CVMX_CIU2_EN_PPX_IP3_MBOX_W1S(\r\nocteon_coreid_for_cpu(cpu));\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\n}\r\nstatic void octeon_irq_ciu2_mbox_disable_all(struct irq_data *data)\r\n{\r\nint cpu;\r\nu64 mask;\r\nmask = 1ull << (data->irq - OCTEON_IRQ_MBOX0);\r\nfor_each_online_cpu(cpu) {\r\nu64 en_addr = CVMX_CIU2_EN_PPX_IP3_MBOX_W1C(\r\nocteon_coreid_for_cpu(cpu));\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\n}\r\nstatic void octeon_irq_ciu2_mbox_enable_local(struct irq_data *data)\r\n{\r\nu64 mask;\r\nu64 en_addr;\r\nint coreid = cvmx_get_core_num();\r\nmask = 1ull << (data->irq - OCTEON_IRQ_MBOX0);\r\nen_addr = CVMX_CIU2_EN_PPX_IP3_MBOX_W1S(coreid);\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\nstatic void octeon_irq_ciu2_mbox_disable_local(struct irq_data *data)\r\n{\r\nu64 mask;\r\nu64 en_addr;\r\nint coreid = cvmx_get_core_num();\r\nmask = 1ull << (data->irq - OCTEON_IRQ_MBOX0);\r\nen_addr = CVMX_CIU2_EN_PPX_IP3_MBOX_W1C(coreid);\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\nstatic int octeon_irq_ciu2_set_affinity(struct irq_data *data,\r\nconst struct cpumask *dest, bool force)\r\n{\r\nint cpu;\r\nbool enable_one = !irqd_irq_disabled(data) && !irqd_irq_masked(data);\r\nu64 mask;\r\nstruct octeon_ciu_chip_data *cd;\r\nif (!enable_one)\r\nreturn 0;\r\ncd = irq_data_get_irq_chip_data(data);\r\nmask = 1ull << cd->bit;\r\nfor_each_online_cpu(cpu) {\r\nu64 en_addr;\r\nif (cpumask_test_cpu(cpu, dest) && enable_one) {\r\nenable_one = false;\r\nen_addr = CVMX_CIU2_EN_PPX_IP2_WRKQ_W1S(\r\nocteon_coreid_for_cpu(cpu)) +\r\n(0x1000ull * cd->line);\r\n} else {\r\nen_addr = CVMX_CIU2_EN_PPX_IP2_WRKQ_W1C(\r\nocteon_coreid_for_cpu(cpu)) +\r\n(0x1000ull * cd->line);\r\n}\r\ncvmx_write_csr(en_addr, mask);\r\n}\r\nreturn 0;\r\n}\r\nstatic void octeon_irq_ciu2_enable_gpio(struct irq_data *data)\r\n{\r\nocteon_irq_gpio_setup(data);\r\nocteon_irq_ciu2_enable(data);\r\n}\r\nstatic void octeon_irq_ciu2_disable_gpio(struct irq_data *data)\r\n{\r\nstruct octeon_ciu_chip_data *cd;\r\ncd = irq_data_get_irq_chip_data(data);\r\ncvmx_write_csr(CVMX_GPIO_BIT_CFGX(cd->gpio_line), 0);\r\nocteon_irq_ciu2_disable_all(data);\r\n}\r\nstatic int octeon_irq_ciu2_xlat(struct irq_domain *d,\r\nstruct device_node *node,\r\nconst u32 *intspec,\r\nunsigned int intsize,\r\nunsigned long *out_hwirq,\r\nunsigned int *out_type)\r\n{\r\nunsigned int ciu, bit;\r\nciu = intspec[0];\r\nbit = intspec[1];\r\n*out_hwirq = (ciu << 6) | bit;\r\n*out_type = 0;\r\nreturn 0;\r\n}\r\nstatic bool octeon_irq_ciu2_is_edge(unsigned int line, unsigned int bit)\r\n{\r\nbool edge = false;\r\nif (line == 3)\r\nswitch (bit) {\r\ncase 2:\r\ncase 8 ... 11:\r\ncase 48:\r\nedge = true;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nelse if (line == 6)\r\nswitch (bit) {\r\ncase 52 ... 53:\r\ncase 8 ... 12:\r\nedge = true;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn edge;\r\n}\r\nstatic int octeon_irq_ciu2_map(struct irq_domain *d,\r\nunsigned int virq, irq_hw_number_t hw)\r\n{\r\nunsigned int line = hw >> 6;\r\nunsigned int bit = hw & 63;\r\nif (!octeon_irq_virq_in_range(virq))\r\nreturn -EINVAL;\r\nif (line == 7)\r\nreturn 0;\r\nif (line > 7 || octeon_irq_ciu_to_irq[line][bit] != 0)\r\nreturn -EINVAL;\r\nif (octeon_irq_ciu2_is_edge(line, bit))\r\nocteon_irq_set_ciu_mapping(virq, line, bit, 0,\r\n&octeon_irq_chip_ciu2_edge,\r\nhandle_edge_irq);\r\nelse\r\nocteon_irq_set_ciu_mapping(virq, line, bit, 0,\r\n&octeon_irq_chip_ciu2,\r\nhandle_level_irq);\r\nreturn 0;\r\n}\r\nstatic void octeon_irq_ciu2(void)\r\n{\r\nint line;\r\nint bit;\r\nint irq;\r\nu64 src_reg, src, sum;\r\nconst unsigned long core_id = cvmx_get_core_num();\r\nsum = cvmx_read_csr(CVMX_CIU2_SUM_PPX_IP2(core_id)) & 0xfful;\r\nif (unlikely(!sum))\r\ngoto spurious;\r\nline = fls64(sum) - 1;\r\nsrc_reg = CVMX_CIU2_SRC_PPX_IP2_WRKQ(core_id) + (0x1000 * line);\r\nsrc = cvmx_read_csr(src_reg);\r\nif (unlikely(!src))\r\ngoto spurious;\r\nbit = fls64(src) - 1;\r\nirq = octeon_irq_ciu_to_irq[line][bit];\r\nif (unlikely(!irq))\r\ngoto spurious;\r\ndo_IRQ(irq);\r\ngoto out;\r\nspurious:\r\nspurious_interrupt();\r\nout:\r\nif (OCTEON_IS_MODEL(OCTEON_CN68XX))\r\ncvmx_read_csr(CVMX_CIU2_INTR_CIU_READY);\r\nelse\r\ncvmx_read_csr(CVMX_CIU2_ACK_PPX_IP2(core_id));\r\nreturn;\r\n}\r\nstatic void octeon_irq_ciu2_mbox(void)\r\n{\r\nint line;\r\nconst unsigned long core_id = cvmx_get_core_num();\r\nu64 sum = cvmx_read_csr(CVMX_CIU2_SUM_PPX_IP3(core_id)) >> 60;\r\nif (unlikely(!sum))\r\ngoto spurious;\r\nline = fls64(sum) - 1;\r\ndo_IRQ(OCTEON_IRQ_MBOX0 + line);\r\ngoto out;\r\nspurious:\r\nspurious_interrupt();\r\nout:\r\nif (OCTEON_IS_MODEL(OCTEON_CN68XX))\r\ncvmx_read_csr(CVMX_CIU2_INTR_CIU_READY);\r\nelse\r\ncvmx_read_csr(CVMX_CIU2_ACK_PPX_IP3(core_id));\r\nreturn;\r\n}\r\nstatic int __init octeon_irq_init_ciu2(\r\nstruct device_node *ciu_node, struct device_node *parent)\r\n{\r\nunsigned int i, r;\r\nstruct irq_domain *ciu_domain = NULL;\r\nocteon_irq_init_ciu2_percpu();\r\nocteon_irq_setup_secondary = octeon_irq_setup_secondary_ciu2;\r\nocteon_irq_gpio_chip = &octeon_irq_chip_ciu2_gpio;\r\nocteon_irq_ip2 = octeon_irq_ciu2;\r\nocteon_irq_ip3 = octeon_irq_ciu2_mbox;\r\nocteon_irq_ip4 = octeon_irq_ip4_mask;\r\nocteon_irq_init_core();\r\nciu_domain = irq_domain_add_tree(\r\nciu_node, &octeon_irq_domain_ciu2_ops, NULL);\r\nirq_set_default_host(ciu_domain);\r\nfor (i = 0; i < 64; i++) {\r\nr = octeon_irq_force_ciu_mapping(\r\nciu_domain, i + OCTEON_IRQ_WORKQ0, 0, i);\r\nif (r)\r\ngoto err;\r\n}\r\nfor (i = 0; i < 32; i++) {\r\nr = octeon_irq_set_ciu_mapping(i + OCTEON_IRQ_WDOG0, 1, i, 0,\r\n&octeon_irq_chip_ciu2_wd, handle_level_irq);\r\nif (r)\r\ngoto err;\r\n}\r\nfor (i = 0; i < 4; i++) {\r\nr = octeon_irq_force_ciu_mapping(\r\nciu_domain, i + OCTEON_IRQ_TIMER0, 3, i + 8);\r\nif (r)\r\ngoto err;\r\n}\r\nr = octeon_irq_force_ciu_mapping(ciu_domain, OCTEON_IRQ_USB0, 3, 44);\r\nif (r)\r\ngoto err;\r\nfor (i = 0; i < 4; i++) {\r\nr = octeon_irq_force_ciu_mapping(\r\nciu_domain, i + OCTEON_IRQ_PCI_INT0, 4, i);\r\nif (r)\r\ngoto err;\r\n}\r\nfor (i = 0; i < 4; i++) {\r\nr = octeon_irq_force_ciu_mapping(\r\nciu_domain, i + OCTEON_IRQ_PCI_MSI0, 4, i + 8);\r\nif (r)\r\ngoto err;\r\n}\r\nirq_set_chip_and_handler(OCTEON_IRQ_MBOX0, &octeon_irq_chip_ciu2_mbox, handle_percpu_irq);\r\nirq_set_chip_and_handler(OCTEON_IRQ_MBOX1, &octeon_irq_chip_ciu2_mbox, handle_percpu_irq);\r\nirq_set_chip_and_handler(OCTEON_IRQ_MBOX2, &octeon_irq_chip_ciu2_mbox, handle_percpu_irq);\r\nirq_set_chip_and_handler(OCTEON_IRQ_MBOX3, &octeon_irq_chip_ciu2_mbox, handle_percpu_irq);\r\nset_c0_status(STATUSF_IP3 | STATUSF_IP2);\r\nclear_c0_status(STATUSF_IP4);\r\nreturn 0;\r\nerr:\r\nreturn r;\r\n}\r\nstatic void octeon_irq_cib_enable(struct irq_data *data)\r\n{\r\nunsigned long flags;\r\nu64 en;\r\nstruct octeon_irq_cib_chip_data *cd = irq_data_get_irq_chip_data(data);\r\nstruct octeon_irq_cib_host_data *host_data = cd->host_data;\r\nraw_spin_lock_irqsave(&host_data->lock, flags);\r\nen = cvmx_read_csr(host_data->en_reg);\r\nen |= 1ull << cd->bit;\r\ncvmx_write_csr(host_data->en_reg, en);\r\nraw_spin_unlock_irqrestore(&host_data->lock, flags);\r\n}\r\nstatic void octeon_irq_cib_disable(struct irq_data *data)\r\n{\r\nunsigned long flags;\r\nu64 en;\r\nstruct octeon_irq_cib_chip_data *cd = irq_data_get_irq_chip_data(data);\r\nstruct octeon_irq_cib_host_data *host_data = cd->host_data;\r\nraw_spin_lock_irqsave(&host_data->lock, flags);\r\nen = cvmx_read_csr(host_data->en_reg);\r\nen &= ~(1ull << cd->bit);\r\ncvmx_write_csr(host_data->en_reg, en);\r\nraw_spin_unlock_irqrestore(&host_data->lock, flags);\r\n}\r\nstatic int octeon_irq_cib_set_type(struct irq_data *data, unsigned int t)\r\n{\r\nirqd_set_trigger_type(data, t);\r\nreturn IRQ_SET_MASK_OK;\r\n}\r\nstatic int octeon_irq_cib_xlat(struct irq_domain *d,\r\nstruct device_node *node,\r\nconst u32 *intspec,\r\nunsigned int intsize,\r\nunsigned long *out_hwirq,\r\nunsigned int *out_type)\r\n{\r\nunsigned int type = 0;\r\nif (intsize == 2)\r\ntype = intspec[1];\r\nswitch (type) {\r\ncase 0:\r\ncase 4:\r\n*out_type = IRQ_TYPE_LEVEL_HIGH;\r\nbreak;\r\ncase 1:\r\n*out_type = IRQ_TYPE_EDGE_RISING;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n*out_hwirq = intspec[0];\r\nreturn 0;\r\n}\r\nstatic int octeon_irq_cib_map(struct irq_domain *d,\r\nunsigned int virq, irq_hw_number_t hw)\r\n{\r\nstruct octeon_irq_cib_host_data *host_data = d->host_data;\r\nstruct octeon_irq_cib_chip_data *cd;\r\nif (hw >= host_data->max_bits) {\r\npr_err("ERROR: %s mapping %u is to big!\n",\r\nd->of_node->name, (unsigned)hw);\r\nreturn -EINVAL;\r\n}\r\ncd = kzalloc(sizeof(*cd), GFP_KERNEL);\r\ncd->host_data = host_data;\r\ncd->bit = hw;\r\nirq_set_chip_and_handler(virq, &octeon_irq_chip_cib,\r\nhandle_simple_irq);\r\nirq_set_chip_data(virq, cd);\r\nreturn 0;\r\n}\r\nstatic irqreturn_t octeon_irq_cib_handler(int my_irq, void *data)\r\n{\r\nu64 en;\r\nu64 raw;\r\nu64 bits;\r\nint i;\r\nint irq;\r\nstruct irq_domain *cib_domain = data;\r\nstruct octeon_irq_cib_host_data *host_data = cib_domain->host_data;\r\nen = cvmx_read_csr(host_data->en_reg);\r\nraw = cvmx_read_csr(host_data->raw_reg);\r\nbits = en & raw;\r\nfor (i = 0; i < host_data->max_bits; i++) {\r\nif ((bits & 1ull << i) == 0)\r\ncontinue;\r\nirq = irq_find_mapping(cib_domain, i);\r\nif (!irq) {\r\nunsigned long flags;\r\npr_err("ERROR: CIB bit %d@%llx IRQ unhandled, disabling\n",\r\ni, host_data->raw_reg);\r\nraw_spin_lock_irqsave(&host_data->lock, flags);\r\nen = cvmx_read_csr(host_data->en_reg);\r\nen &= ~(1ull << i);\r\ncvmx_write_csr(host_data->en_reg, en);\r\ncvmx_write_csr(host_data->raw_reg, 1ull << i);\r\nraw_spin_unlock_irqrestore(&host_data->lock, flags);\r\n} else {\r\nstruct irq_desc *desc = irq_to_desc(irq);\r\nstruct irq_data *irq_data = irq_desc_get_irq_data(desc);\r\nif (irqd_get_trigger_type(irq_data) &\r\nIRQ_TYPE_EDGE_BOTH)\r\ncvmx_write_csr(host_data->raw_reg, 1ull << i);\r\ngeneric_handle_irq_desc(irq, desc);\r\n}\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int __init octeon_irq_init_cib(struct device_node *ciu_node,\r\nstruct device_node *parent)\r\n{\r\nconst __be32 *addr;\r\nu32 val;\r\nstruct octeon_irq_cib_host_data *host_data;\r\nint parent_irq;\r\nint r;\r\nstruct irq_domain *cib_domain;\r\nparent_irq = irq_of_parse_and_map(ciu_node, 0);\r\nif (!parent_irq) {\r\npr_err("ERROR: Couldn't acquire parent_irq for %s\n.",\r\nciu_node->name);\r\nreturn -EINVAL;\r\n}\r\nhost_data = kzalloc(sizeof(*host_data), GFP_KERNEL);\r\nraw_spin_lock_init(&host_data->lock);\r\naddr = of_get_address(ciu_node, 0, NULL, NULL);\r\nif (!addr) {\r\npr_err("ERROR: Couldn't acquire reg(0) %s\n.", ciu_node->name);\r\nreturn -EINVAL;\r\n}\r\nhost_data->raw_reg = (u64)phys_to_virt(\r\nof_translate_address(ciu_node, addr));\r\naddr = of_get_address(ciu_node, 1, NULL, NULL);\r\nif (!addr) {\r\npr_err("ERROR: Couldn't acquire reg(1) %s\n.", ciu_node->name);\r\nreturn -EINVAL;\r\n}\r\nhost_data->en_reg = (u64)phys_to_virt(\r\nof_translate_address(ciu_node, addr));\r\nr = of_property_read_u32(ciu_node, "cavium,max-bits", &val);\r\nif (r) {\r\npr_err("ERROR: Couldn't read cavium,max-bits from %s\n.",\r\nciu_node->name);\r\nreturn r;\r\n}\r\nhost_data->max_bits = val;\r\ncib_domain = irq_domain_add_linear(ciu_node, host_data->max_bits,\r\n&octeon_irq_domain_cib_ops,\r\nhost_data);\r\nif (!cib_domain) {\r\npr_err("ERROR: Couldn't irq_domain_add_linear()\n.");\r\nreturn -ENOMEM;\r\n}\r\ncvmx_write_csr(host_data->en_reg, 0);\r\ncvmx_write_csr(host_data->raw_reg, ~0);\r\nr = request_irq(parent_irq, octeon_irq_cib_handler,\r\nIRQF_NO_THREAD, "cib", cib_domain);\r\nif (r) {\r\npr_err("request_irq cib failed %d\n", r);\r\nreturn r;\r\n}\r\npr_info("CIB interrupt controller probed: %llx %d\n",\r\nhost_data->raw_reg, host_data->max_bits);\r\nreturn 0;\r\n}\r\nvoid __init arch_init_irq(void)\r\n{\r\n#ifdef CONFIG_SMP\r\ncpumask_clear(irq_default_affinity);\r\ncpumask_set_cpu(smp_processor_id(), irq_default_affinity);\r\n#endif\r\nof_irq_init(ciu_types);\r\n}\r\nasmlinkage void plat_irq_dispatch(void)\r\n{\r\nunsigned long cop0_cause;\r\nunsigned long cop0_status;\r\nwhile (1) {\r\ncop0_cause = read_c0_cause();\r\ncop0_status = read_c0_status();\r\ncop0_cause &= cop0_status;\r\ncop0_cause &= ST0_IM;\r\nif (cop0_cause & STATUSF_IP2)\r\nocteon_irq_ip2();\r\nelse if (cop0_cause & STATUSF_IP3)\r\nocteon_irq_ip3();\r\nelse if (cop0_cause & STATUSF_IP4)\r\nocteon_irq_ip4();\r\nelse if (cop0_cause)\r\ndo_IRQ(fls(cop0_cause) - 9 + MIPS_CPU_IRQ_BASE);\r\nelse\r\nbreak;\r\n}\r\n}\r\nvoid octeon_fixup_irqs(void)\r\n{\r\nirq_cpu_offline();\r\n}
