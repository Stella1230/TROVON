static void xgene_enet_ring_init(struct xgene_enet_desc_ring *ring)\r\n{\r\nu32 *ring_cfg = ring->state;\r\nu64 addr = ring->dma;\r\nenum xgene_enet_ring_cfgsize cfgsize = ring->cfgsize;\r\nring_cfg[4] |= (1 << SELTHRSH_POS) &\r\nCREATE_MASK(SELTHRSH_POS, SELTHRSH_LEN);\r\nring_cfg[3] |= ACCEPTLERR;\r\nring_cfg[2] |= QCOHERENT;\r\naddr >>= 8;\r\nring_cfg[2] |= (addr << RINGADDRL_POS) &\r\nCREATE_MASK_ULL(RINGADDRL_POS, RINGADDRL_LEN);\r\naddr >>= RINGADDRL_LEN;\r\nring_cfg[3] |= addr & CREATE_MASK_ULL(RINGADDRH_POS, RINGADDRH_LEN);\r\nring_cfg[3] |= ((u32)cfgsize << RINGSIZE_POS) &\r\nCREATE_MASK(RINGSIZE_POS, RINGSIZE_LEN);\r\n}\r\nstatic void xgene_enet_ring_set_type(struct xgene_enet_desc_ring *ring)\r\n{\r\nu32 *ring_cfg = ring->state;\r\nbool is_bufpool;\r\nu32 val;\r\nis_bufpool = xgene_enet_is_bufpool(ring->id);\r\nval = (is_bufpool) ? RING_BUFPOOL : RING_REGULAR;\r\nring_cfg[4] |= (val << RINGTYPE_POS) &\r\nCREATE_MASK(RINGTYPE_POS, RINGTYPE_LEN);\r\nif (is_bufpool) {\r\nring_cfg[3] |= (BUFPOOL_MODE << RINGMODE_POS) &\r\nCREATE_MASK(RINGMODE_POS, RINGMODE_LEN);\r\n}\r\n}\r\nstatic void xgene_enet_ring_set_recombbuf(struct xgene_enet_desc_ring *ring)\r\n{\r\nu32 *ring_cfg = ring->state;\r\nring_cfg[3] |= RECOMBBUF;\r\nring_cfg[3] |= (0xf << RECOMTIMEOUTL_POS) &\r\nCREATE_MASK(RECOMTIMEOUTL_POS, RECOMTIMEOUTL_LEN);\r\nring_cfg[4] |= 0x7 & CREATE_MASK(RECOMTIMEOUTH_POS, RECOMTIMEOUTH_LEN);\r\n}\r\nstatic void xgene_enet_ring_wr32(struct xgene_enet_desc_ring *ring,\r\nu32 offset, u32 data)\r\n{\r\nstruct xgene_enet_pdata *pdata = netdev_priv(ring->ndev);\r\niowrite32(data, pdata->ring_csr_addr + offset);\r\n}\r\nstatic void xgene_enet_ring_rd32(struct xgene_enet_desc_ring *ring,\r\nu32 offset, u32 *data)\r\n{\r\nstruct xgene_enet_pdata *pdata = netdev_priv(ring->ndev);\r\n*data = ioread32(pdata->ring_csr_addr + offset);\r\n}\r\nstatic void xgene_enet_write_ring_state(struct xgene_enet_desc_ring *ring)\r\n{\r\nint i;\r\nxgene_enet_ring_wr32(ring, CSR_RING_CONFIG, ring->num);\r\nfor (i = 0; i < NUM_RING_CONFIG; i++) {\r\nxgene_enet_ring_wr32(ring, CSR_RING_WR_BASE + (i * 4),\r\nring->state[i]);\r\n}\r\n}\r\nstatic void xgene_enet_clr_ring_state(struct xgene_enet_desc_ring *ring)\r\n{\r\nmemset(ring->state, 0, sizeof(u32) * NUM_RING_CONFIG);\r\nxgene_enet_write_ring_state(ring);\r\n}\r\nstatic void xgene_enet_set_ring_state(struct xgene_enet_desc_ring *ring)\r\n{\r\nxgene_enet_ring_set_type(ring);\r\nif (xgene_enet_ring_owner(ring->id) == RING_OWNER_ETH0)\r\nxgene_enet_ring_set_recombbuf(ring);\r\nxgene_enet_ring_init(ring);\r\nxgene_enet_write_ring_state(ring);\r\n}\r\nstatic void xgene_enet_set_ring_id(struct xgene_enet_desc_ring *ring)\r\n{\r\nu32 ring_id_val, ring_id_buf;\r\nbool is_bufpool;\r\nis_bufpool = xgene_enet_is_bufpool(ring->id);\r\nring_id_val = ring->id & GENMASK(9, 0);\r\nring_id_val |= OVERWRITE;\r\nring_id_buf = (ring->num << 9) & GENMASK(18, 9);\r\nring_id_buf |= PREFETCH_BUF_EN;\r\nif (is_bufpool)\r\nring_id_buf |= IS_BUFFER_POOL;\r\nxgene_enet_ring_wr32(ring, CSR_RING_ID, ring_id_val);\r\nxgene_enet_ring_wr32(ring, CSR_RING_ID_BUF, ring_id_buf);\r\n}\r\nstatic void xgene_enet_clr_desc_ring_id(struct xgene_enet_desc_ring *ring)\r\n{\r\nu32 ring_id;\r\nring_id = ring->id | OVERWRITE;\r\nxgene_enet_ring_wr32(ring, CSR_RING_ID, ring_id);\r\nxgene_enet_ring_wr32(ring, CSR_RING_ID_BUF, 0);\r\n}\r\nstruct xgene_enet_desc_ring *xgene_enet_setup_ring(\r\nstruct xgene_enet_desc_ring *ring)\r\n{\r\nu32 size = ring->size;\r\nu32 i, data;\r\nbool is_bufpool;\r\nxgene_enet_clr_ring_state(ring);\r\nxgene_enet_set_ring_state(ring);\r\nxgene_enet_set_ring_id(ring);\r\nring->slots = xgene_enet_get_numslots(ring->id, size);\r\nis_bufpool = xgene_enet_is_bufpool(ring->id);\r\nif (is_bufpool || xgene_enet_ring_owner(ring->id) != RING_OWNER_CPU)\r\nreturn ring;\r\nfor (i = 0; i < ring->slots; i++)\r\nxgene_enet_mark_desc_slot_empty(&ring->raw_desc[i]);\r\nxgene_enet_ring_rd32(ring, CSR_RING_NE_INT_MODE, &data);\r\ndata |= BIT(31 - xgene_enet_ring_bufnum(ring->id));\r\nxgene_enet_ring_wr32(ring, CSR_RING_NE_INT_MODE, data);\r\nreturn ring;\r\n}\r\nvoid xgene_enet_clear_ring(struct xgene_enet_desc_ring *ring)\r\n{\r\nu32 data;\r\nbool is_bufpool;\r\nis_bufpool = xgene_enet_is_bufpool(ring->id);\r\nif (is_bufpool || xgene_enet_ring_owner(ring->id) != RING_OWNER_CPU)\r\ngoto out;\r\nxgene_enet_ring_rd32(ring, CSR_RING_NE_INT_MODE, &data);\r\ndata &= ~BIT(31 - xgene_enet_ring_bufnum(ring->id));\r\nxgene_enet_ring_wr32(ring, CSR_RING_NE_INT_MODE, data);\r\nout:\r\nxgene_enet_clr_desc_ring_id(ring);\r\nxgene_enet_clr_ring_state(ring);\r\n}\r\nvoid xgene_enet_parse_error(struct xgene_enet_desc_ring *ring,\r\nstruct xgene_enet_pdata *pdata,\r\nenum xgene_enet_err_code status)\r\n{\r\nstruct rtnl_link_stats64 *stats = &pdata->stats;\r\nswitch (status) {\r\ncase INGRESS_CRC:\r\nstats->rx_crc_errors++;\r\nbreak;\r\ncase INGRESS_CHECKSUM:\r\ncase INGRESS_CHECKSUM_COMPUTE:\r\nstats->rx_errors++;\r\nbreak;\r\ncase INGRESS_TRUNC_FRAME:\r\nstats->rx_frame_errors++;\r\nbreak;\r\ncase INGRESS_PKT_LEN:\r\nstats->rx_length_errors++;\r\nbreak;\r\ncase INGRESS_PKT_UNDER:\r\nstats->rx_frame_errors++;\r\nbreak;\r\ncase INGRESS_FIFO_OVERRUN:\r\nstats->rx_fifo_errors++;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\nstatic void xgene_enet_wr_csr(struct xgene_enet_pdata *pdata,\r\nu32 offset, u32 val)\r\n{\r\nvoid __iomem *addr = pdata->eth_csr_addr + offset;\r\niowrite32(val, addr);\r\n}\r\nstatic void xgene_enet_wr_ring_if(struct xgene_enet_pdata *pdata,\r\nu32 offset, u32 val)\r\n{\r\nvoid __iomem *addr = pdata->eth_ring_if_addr + offset;\r\niowrite32(val, addr);\r\n}\r\nstatic void xgene_enet_wr_diag_csr(struct xgene_enet_pdata *pdata,\r\nu32 offset, u32 val)\r\n{\r\nvoid __iomem *addr = pdata->eth_diag_csr_addr + offset;\r\niowrite32(val, addr);\r\n}\r\nstatic void xgene_enet_wr_mcx_csr(struct xgene_enet_pdata *pdata,\r\nu32 offset, u32 val)\r\n{\r\nvoid __iomem *addr = pdata->mcx_mac_csr_addr + offset;\r\niowrite32(val, addr);\r\n}\r\nstatic bool xgene_enet_wr_indirect(void __iomem *addr, void __iomem *wr,\r\nvoid __iomem *cmd, void __iomem *cmd_done,\r\nu32 wr_addr, u32 wr_data)\r\n{\r\nu32 done;\r\nu8 wait = 10;\r\niowrite32(wr_addr, addr);\r\niowrite32(wr_data, wr);\r\niowrite32(XGENE_ENET_WR_CMD, cmd);\r\nwhile (!(done = ioread32(cmd_done)) && wait--)\r\nudelay(1);\r\nif (!done)\r\nreturn false;\r\niowrite32(0, cmd);\r\nreturn true;\r\n}\r\nstatic void xgene_enet_wr_mcx_mac(struct xgene_enet_pdata *pdata,\r\nu32 wr_addr, u32 wr_data)\r\n{\r\nvoid __iomem *addr, *wr, *cmd, *cmd_done;\r\naddr = pdata->mcx_mac_addr + MAC_ADDR_REG_OFFSET;\r\nwr = pdata->mcx_mac_addr + MAC_WRITE_REG_OFFSET;\r\ncmd = pdata->mcx_mac_addr + MAC_COMMAND_REG_OFFSET;\r\ncmd_done = pdata->mcx_mac_addr + MAC_COMMAND_DONE_REG_OFFSET;\r\nif (!xgene_enet_wr_indirect(addr, wr, cmd, cmd_done, wr_addr, wr_data))\r\nnetdev_err(pdata->ndev, "MCX mac write failed, addr: %04x\n",\r\nwr_addr);\r\n}\r\nstatic void xgene_enet_rd_csr(struct xgene_enet_pdata *pdata,\r\nu32 offset, u32 *val)\r\n{\r\nvoid __iomem *addr = pdata->eth_csr_addr + offset;\r\n*val = ioread32(addr);\r\n}\r\nstatic void xgene_enet_rd_diag_csr(struct xgene_enet_pdata *pdata,\r\nu32 offset, u32 *val)\r\n{\r\nvoid __iomem *addr = pdata->eth_diag_csr_addr + offset;\r\n*val = ioread32(addr);\r\n}\r\nstatic void xgene_enet_rd_mcx_csr(struct xgene_enet_pdata *pdata,\r\nu32 offset, u32 *val)\r\n{\r\nvoid __iomem *addr = pdata->mcx_mac_csr_addr + offset;\r\n*val = ioread32(addr);\r\n}\r\nstatic bool xgene_enet_rd_indirect(void __iomem *addr, void __iomem *rd,\r\nvoid __iomem *cmd, void __iomem *cmd_done,\r\nu32 rd_addr, u32 *rd_data)\r\n{\r\nu32 done;\r\nu8 wait = 10;\r\niowrite32(rd_addr, addr);\r\niowrite32(XGENE_ENET_RD_CMD, cmd);\r\nwhile (!(done = ioread32(cmd_done)) && wait--)\r\nudelay(1);\r\nif (!done)\r\nreturn false;\r\n*rd_data = ioread32(rd);\r\niowrite32(0, cmd);\r\nreturn true;\r\n}\r\nstatic void xgene_enet_rd_mcx_mac(struct xgene_enet_pdata *pdata,\r\nu32 rd_addr, u32 *rd_data)\r\n{\r\nvoid __iomem *addr, *rd, *cmd, *cmd_done;\r\naddr = pdata->mcx_mac_addr + MAC_ADDR_REG_OFFSET;\r\nrd = pdata->mcx_mac_addr + MAC_READ_REG_OFFSET;\r\ncmd = pdata->mcx_mac_addr + MAC_COMMAND_REG_OFFSET;\r\ncmd_done = pdata->mcx_mac_addr + MAC_COMMAND_DONE_REG_OFFSET;\r\nif (!xgene_enet_rd_indirect(addr, rd, cmd, cmd_done, rd_addr, rd_data))\r\nnetdev_err(pdata->ndev, "MCX mac read failed, addr: %04x\n",\r\nrd_addr);\r\n}\r\nstatic int xgene_mii_phy_write(struct xgene_enet_pdata *pdata, int phy_id,\r\nu32 reg, u16 data)\r\n{\r\nu32 addr = 0, wr_data = 0;\r\nu32 done;\r\nu8 wait = 10;\r\nPHY_ADDR_SET(&addr, phy_id);\r\nREG_ADDR_SET(&addr, reg);\r\nxgene_enet_wr_mcx_mac(pdata, MII_MGMT_ADDRESS_ADDR, addr);\r\nPHY_CONTROL_SET(&wr_data, data);\r\nxgene_enet_wr_mcx_mac(pdata, MII_MGMT_CONTROL_ADDR, wr_data);\r\ndo {\r\nusleep_range(5, 10);\r\nxgene_enet_rd_mcx_mac(pdata, MII_MGMT_INDICATORS_ADDR, &done);\r\n} while ((done & BUSY_MASK) && wait--);\r\nif (done & BUSY_MASK) {\r\nnetdev_err(pdata->ndev, "MII_MGMT write failed\n");\r\nreturn -EBUSY;\r\n}\r\nreturn 0;\r\n}\r\nstatic int xgene_mii_phy_read(struct xgene_enet_pdata *pdata,\r\nu8 phy_id, u32 reg)\r\n{\r\nu32 addr = 0;\r\nu32 data, done;\r\nu8 wait = 10;\r\nPHY_ADDR_SET(&addr, phy_id);\r\nREG_ADDR_SET(&addr, reg);\r\nxgene_enet_wr_mcx_mac(pdata, MII_MGMT_ADDRESS_ADDR, addr);\r\nxgene_enet_wr_mcx_mac(pdata, MII_MGMT_COMMAND_ADDR, READ_CYCLE_MASK);\r\ndo {\r\nusleep_range(5, 10);\r\nxgene_enet_rd_mcx_mac(pdata, MII_MGMT_INDICATORS_ADDR, &done);\r\n} while ((done & BUSY_MASK) && wait--);\r\nif (done & BUSY_MASK) {\r\nnetdev_err(pdata->ndev, "MII_MGMT read failed\n");\r\nreturn -EBUSY;\r\n}\r\nxgene_enet_rd_mcx_mac(pdata, MII_MGMT_STATUS_ADDR, &data);\r\nxgene_enet_wr_mcx_mac(pdata, MII_MGMT_COMMAND_ADDR, 0);\r\nreturn data;\r\n}\r\nstatic void xgene_gmac_set_mac_addr(struct xgene_enet_pdata *pdata)\r\n{\r\nu32 addr0, addr1;\r\nu8 *dev_addr = pdata->ndev->dev_addr;\r\naddr0 = (dev_addr[3] << 24) | (dev_addr[2] << 16) |\r\n(dev_addr[1] << 8) | dev_addr[0];\r\naddr1 = (dev_addr[5] << 24) | (dev_addr[4] << 16);\r\nxgene_enet_wr_mcx_mac(pdata, STATION_ADDR0_ADDR, addr0);\r\nxgene_enet_wr_mcx_mac(pdata, STATION_ADDR1_ADDR, addr1);\r\n}\r\nstatic int xgene_enet_ecc_init(struct xgene_enet_pdata *pdata)\r\n{\r\nstruct net_device *ndev = pdata->ndev;\r\nu32 data;\r\nu8 wait = 10;\r\nxgene_enet_wr_diag_csr(pdata, ENET_CFG_MEM_RAM_SHUTDOWN_ADDR, 0x0);\r\ndo {\r\nusleep_range(100, 110);\r\nxgene_enet_rd_diag_csr(pdata, ENET_BLOCK_MEM_RDY_ADDR, &data);\r\n} while ((data != 0xffffffff) && wait--);\r\nif (data != 0xffffffff) {\r\nnetdev_err(ndev, "Failed to release memory from shutdown\n");\r\nreturn -ENODEV;\r\n}\r\nreturn 0;\r\n}\r\nstatic void xgene_gmac_reset(struct xgene_enet_pdata *pdata)\r\n{\r\nxgene_enet_wr_mcx_mac(pdata, MAC_CONFIG_1_ADDR, SOFT_RESET1);\r\nxgene_enet_wr_mcx_mac(pdata, MAC_CONFIG_1_ADDR, 0);\r\n}\r\nstatic void xgene_gmac_init(struct xgene_enet_pdata *pdata)\r\n{\r\nu32 value, mc2;\r\nu32 intf_ctl, rgmii;\r\nu32 icm0, icm2;\r\nxgene_gmac_reset(pdata);\r\nxgene_enet_rd_mcx_csr(pdata, ICM_CONFIG0_REG_0_ADDR, &icm0);\r\nxgene_enet_rd_mcx_csr(pdata, ICM_CONFIG2_REG_0_ADDR, &icm2);\r\nxgene_enet_rd_mcx_mac(pdata, MAC_CONFIG_2_ADDR, &mc2);\r\nxgene_enet_rd_mcx_mac(pdata, INTERFACE_CONTROL_ADDR, &intf_ctl);\r\nxgene_enet_rd_csr(pdata, RGMII_REG_0_ADDR, &rgmii);\r\nswitch (pdata->phy_speed) {\r\ncase SPEED_10:\r\nENET_INTERFACE_MODE2_SET(&mc2, 1);\r\nCFG_MACMODE_SET(&icm0, 0);\r\nCFG_WAITASYNCRD_SET(&icm2, 500);\r\nrgmii &= ~CFG_SPEED_1250;\r\nbreak;\r\ncase SPEED_100:\r\nENET_INTERFACE_MODE2_SET(&mc2, 1);\r\nintf_ctl |= ENET_LHD_MODE;\r\nCFG_MACMODE_SET(&icm0, 1);\r\nCFG_WAITASYNCRD_SET(&icm2, 80);\r\nrgmii &= ~CFG_SPEED_1250;\r\nbreak;\r\ndefault:\r\nENET_INTERFACE_MODE2_SET(&mc2, 2);\r\nintf_ctl |= ENET_GHD_MODE;\r\nCFG_TXCLK_MUXSEL0_SET(&rgmii, 4);\r\nxgene_enet_rd_csr(pdata, DEBUG_REG_ADDR, &value);\r\nvalue |= CFG_BYPASS_UNISEC_TX | CFG_BYPASS_UNISEC_RX;\r\nxgene_enet_wr_csr(pdata, DEBUG_REG_ADDR, value);\r\nbreak;\r\n}\r\nmc2 |= FULL_DUPLEX2;\r\nxgene_enet_wr_mcx_mac(pdata, MAC_CONFIG_2_ADDR, mc2);\r\nxgene_enet_wr_mcx_mac(pdata, INTERFACE_CONTROL_ADDR, intf_ctl);\r\nxgene_gmac_set_mac_addr(pdata);\r\nxgene_enet_rd_mcx_mac(pdata, MII_MGMT_CONFIG_ADDR, &value);\r\nMGMT_CLOCK_SEL_SET(&value, 7);\r\nxgene_enet_wr_mcx_mac(pdata, MII_MGMT_CONFIG_ADDR, value);\r\nxgene_enet_rd_csr(pdata, RSIF_CONFIG_REG_ADDR, &value);\r\nvalue |= CFG_RSIF_FPBUFF_TIMEOUT_EN;\r\nxgene_enet_wr_csr(pdata, RSIF_CONFIG_REG_ADDR, value);\r\nxgene_enet_wr_csr(pdata, RSIF_RAM_DBG_REG0_ADDR, 0);\r\nxgene_enet_wr_csr(pdata, RGMII_REG_0_ADDR, rgmii);\r\nxgene_enet_wr_csr(pdata, CFG_LINK_AGGR_RESUME_0_ADDR, TX_PORT0);\r\nxgene_enet_wr_mcx_csr(pdata, ICM_CONFIG0_REG_0_ADDR, icm0);\r\nxgene_enet_wr_mcx_csr(pdata, ICM_CONFIG2_REG_0_ADDR, icm2);\r\nxgene_enet_rd_mcx_csr(pdata, RX_DV_GATE_REG_0_ADDR, &value);\r\nvalue &= ~TX_DV_GATE_EN0;\r\nvalue &= ~RX_DV_GATE_EN0;\r\nvalue |= RESUME_RX0;\r\nxgene_enet_wr_mcx_csr(pdata, RX_DV_GATE_REG_0_ADDR, value);\r\nxgene_enet_wr_csr(pdata, CFG_BYPASS_ADDR, RESUME_TX);\r\n}\r\nstatic void xgene_enet_config_ring_if_assoc(struct xgene_enet_pdata *pdata)\r\n{\r\nu32 val = 0xffffffff;\r\nxgene_enet_wr_ring_if(pdata, ENET_CFGSSQMIWQASSOC_ADDR, val);\r\nxgene_enet_wr_ring_if(pdata, ENET_CFGSSQMIFPQASSOC_ADDR, val);\r\nxgene_enet_wr_ring_if(pdata, ENET_CFGSSQMIQMLITEWQASSOC_ADDR, val);\r\nxgene_enet_wr_ring_if(pdata, ENET_CFGSSQMIQMLITEFPQASSOC_ADDR, val);\r\n}\r\nstatic void xgene_enet_cle_bypass(struct xgene_enet_pdata *pdata,\r\nu32 dst_ring_num, u16 bufpool_id)\r\n{\r\nu32 cb;\r\nu32 fpsel;\r\nfpsel = xgene_enet_ring_bufnum(bufpool_id) - 0x20;\r\nxgene_enet_rd_csr(pdata, CLE_BYPASS_REG0_0_ADDR, &cb);\r\ncb |= CFG_CLE_BYPASS_EN0;\r\nCFG_CLE_IP_PROTOCOL0_SET(&cb, 3);\r\nxgene_enet_wr_csr(pdata, CLE_BYPASS_REG0_0_ADDR, cb);\r\nxgene_enet_rd_csr(pdata, CLE_BYPASS_REG1_0_ADDR, &cb);\r\nCFG_CLE_DSTQID0_SET(&cb, dst_ring_num);\r\nCFG_CLE_FPSEL0_SET(&cb, fpsel);\r\nxgene_enet_wr_csr(pdata, CLE_BYPASS_REG1_0_ADDR, cb);\r\n}\r\nstatic void xgene_gmac_rx_enable(struct xgene_enet_pdata *pdata)\r\n{\r\nu32 data;\r\nxgene_enet_rd_mcx_mac(pdata, MAC_CONFIG_1_ADDR, &data);\r\nxgene_enet_wr_mcx_mac(pdata, MAC_CONFIG_1_ADDR, data | RX_EN);\r\n}\r\nstatic void xgene_gmac_tx_enable(struct xgene_enet_pdata *pdata)\r\n{\r\nu32 data;\r\nxgene_enet_rd_mcx_mac(pdata, MAC_CONFIG_1_ADDR, &data);\r\nxgene_enet_wr_mcx_mac(pdata, MAC_CONFIG_1_ADDR, data | TX_EN);\r\n}\r\nstatic void xgene_gmac_rx_disable(struct xgene_enet_pdata *pdata)\r\n{\r\nu32 data;\r\nxgene_enet_rd_mcx_mac(pdata, MAC_CONFIG_1_ADDR, &data);\r\nxgene_enet_wr_mcx_mac(pdata, MAC_CONFIG_1_ADDR, data & ~RX_EN);\r\n}\r\nstatic void xgene_gmac_tx_disable(struct xgene_enet_pdata *pdata)\r\n{\r\nu32 data;\r\nxgene_enet_rd_mcx_mac(pdata, MAC_CONFIG_1_ADDR, &data);\r\nxgene_enet_wr_mcx_mac(pdata, MAC_CONFIG_1_ADDR, data & ~TX_EN);\r\n}\r\nbool xgene_ring_mgr_init(struct xgene_enet_pdata *p)\r\n{\r\nif (!ioread32(p->ring_csr_addr + CLKEN_ADDR))\r\nreturn false;\r\nif (ioread32(p->ring_csr_addr + SRST_ADDR))\r\nreturn false;\r\nreturn true;\r\n}\r\nstatic int xgene_enet_reset(struct xgene_enet_pdata *pdata)\r\n{\r\nu32 val;\r\nif (!xgene_ring_mgr_init(pdata))\r\nreturn -ENODEV;\r\nif (pdata->clk) {\r\nclk_prepare_enable(pdata->clk);\r\nclk_disable_unprepare(pdata->clk);\r\nclk_prepare_enable(pdata->clk);\r\nxgene_enet_ecc_init(pdata);\r\n}\r\nxgene_enet_config_ring_if_assoc(pdata);\r\nxgene_enet_rd_mcx_mac(pdata, MII_MGMT_CONFIG_ADDR, &val);\r\nval |= SCAN_AUTO_INCR;\r\nMGMT_CLOCK_SEL_SET(&val, 1);\r\nxgene_enet_wr_mcx_mac(pdata, MII_MGMT_CONFIG_ADDR, val);\r\nreturn 0;\r\n}\r\nstatic void xgene_gport_shutdown(struct xgene_enet_pdata *pdata)\r\n{\r\nclk_disable_unprepare(pdata->clk);\r\n}\r\nstatic int xgene_enet_mdio_read(struct mii_bus *bus, int mii_id, int regnum)\r\n{\r\nstruct xgene_enet_pdata *pdata = bus->priv;\r\nu32 val;\r\nval = xgene_mii_phy_read(pdata, mii_id, regnum);\r\nnetdev_dbg(pdata->ndev, "mdio_rd: bus=%d reg=%d val=%x\n",\r\nmii_id, regnum, val);\r\nreturn val;\r\n}\r\nstatic int xgene_enet_mdio_write(struct mii_bus *bus, int mii_id, int regnum,\r\nu16 val)\r\n{\r\nstruct xgene_enet_pdata *pdata = bus->priv;\r\nnetdev_dbg(pdata->ndev, "mdio_wr: bus=%d reg=%d val=%x\n",\r\nmii_id, regnum, val);\r\nreturn xgene_mii_phy_write(pdata, mii_id, regnum, val);\r\n}\r\nstatic void xgene_enet_adjust_link(struct net_device *ndev)\r\n{\r\nstruct xgene_enet_pdata *pdata = netdev_priv(ndev);\r\nstruct phy_device *phydev = pdata->phy_dev;\r\nif (phydev->link) {\r\nif (pdata->phy_speed != phydev->speed) {\r\npdata->phy_speed = phydev->speed;\r\nxgene_gmac_init(pdata);\r\nxgene_gmac_rx_enable(pdata);\r\nxgene_gmac_tx_enable(pdata);\r\nphy_print_status(phydev);\r\n}\r\n} else {\r\nxgene_gmac_rx_disable(pdata);\r\nxgene_gmac_tx_disable(pdata);\r\npdata->phy_speed = SPEED_UNKNOWN;\r\nphy_print_status(phydev);\r\n}\r\n}\r\nstatic int xgene_enet_phy_connect(struct net_device *ndev)\r\n{\r\nstruct xgene_enet_pdata *pdata = netdev_priv(ndev);\r\nstruct device_node *phy_np;\r\nstruct phy_device *phy_dev;\r\nstruct device *dev = &pdata->pdev->dev;\r\nif (dev->of_node) {\r\nphy_np = of_parse_phandle(dev->of_node, "phy-handle", 0);\r\nif (!phy_np) {\r\nnetdev_dbg(ndev, "No phy-handle found in DT\n");\r\nreturn -ENODEV;\r\n}\r\npdata->phy_dev = of_phy_find_device(phy_np);\r\n}\r\nphy_dev = pdata->phy_dev;\r\nif (!phy_dev ||\r\nphy_connect_direct(ndev, phy_dev, &xgene_enet_adjust_link,\r\npdata->phy_mode)) {\r\nnetdev_err(ndev, "Could not connect to PHY\n");\r\nreturn -ENODEV;\r\n}\r\npdata->phy_speed = SPEED_UNKNOWN;\r\nphy_dev->supported &= ~SUPPORTED_10baseT_Half &\r\n~SUPPORTED_100baseT_Half &\r\n~SUPPORTED_1000baseT_Half;\r\nphy_dev->advertising = phy_dev->supported;\r\nreturn 0;\r\n}\r\nstatic int xgene_mdiobus_register(struct xgene_enet_pdata *pdata,\r\nstruct mii_bus *mdio)\r\n{\r\nstruct device *dev = &pdata->pdev->dev;\r\nstruct net_device *ndev = pdata->ndev;\r\nstruct phy_device *phy;\r\nstruct device_node *child_np;\r\nstruct device_node *mdio_np = NULL;\r\nint ret;\r\nu32 phy_id;\r\nif (dev->of_node) {\r\nfor_each_child_of_node(dev->of_node, child_np) {\r\nif (of_device_is_compatible(child_np,\r\n"apm,xgene-mdio")) {\r\nmdio_np = child_np;\r\nbreak;\r\n}\r\n}\r\nif (!mdio_np) {\r\nnetdev_dbg(ndev, "No mdio node in the dts\n");\r\nreturn -ENXIO;\r\n}\r\nreturn of_mdiobus_register(mdio, mdio_np);\r\n}\r\nmdio->phy_mask = ~0;\r\nret = mdiobus_register(mdio);\r\nif (ret)\r\nreturn ret;\r\nret = device_property_read_u32(dev, "phy-channel", &phy_id);\r\nif (ret)\r\nret = device_property_read_u32(dev, "phy-addr", &phy_id);\r\nif (ret)\r\nreturn -EINVAL;\r\nphy = get_phy_device(mdio, phy_id, true);\r\nif (!phy || IS_ERR(phy))\r\nreturn -EIO;\r\nret = phy_device_register(phy);\r\nif (ret)\r\nphy_device_free(phy);\r\nelse\r\npdata->phy_dev = phy;\r\nreturn ret;\r\n}\r\nint xgene_enet_mdio_config(struct xgene_enet_pdata *pdata)\r\n{\r\nstruct net_device *ndev = pdata->ndev;\r\nstruct mii_bus *mdio_bus;\r\nint ret;\r\nmdio_bus = mdiobus_alloc();\r\nif (!mdio_bus)\r\nreturn -ENOMEM;\r\nmdio_bus->name = "APM X-Gene MDIO bus";\r\nmdio_bus->read = xgene_enet_mdio_read;\r\nmdio_bus->write = xgene_enet_mdio_write;\r\nsnprintf(mdio_bus->id, MII_BUS_ID_SIZE, "%s-%s", "xgene-mii",\r\nndev->name);\r\nmdio_bus->priv = pdata;\r\nmdio_bus->parent = &ndev->dev;\r\nret = xgene_mdiobus_register(pdata, mdio_bus);\r\nif (ret) {\r\nnetdev_err(ndev, "Failed to register MDIO bus\n");\r\nmdiobus_free(mdio_bus);\r\nreturn ret;\r\n}\r\npdata->mdio_bus = mdio_bus;\r\nret = xgene_enet_phy_connect(ndev);\r\nif (ret)\r\nxgene_enet_mdio_remove(pdata);\r\nreturn ret;\r\n}\r\nvoid xgene_enet_mdio_remove(struct xgene_enet_pdata *pdata)\r\n{\r\nmdiobus_unregister(pdata->mdio_bus);\r\nmdiobus_free(pdata->mdio_bus);\r\npdata->mdio_bus = NULL;\r\n}
