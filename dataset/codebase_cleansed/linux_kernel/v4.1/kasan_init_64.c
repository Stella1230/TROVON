static int __init map_range(struct range *range)\r\n{\r\nunsigned long start;\r\nunsigned long end;\r\nstart = (unsigned long)kasan_mem_to_shadow(pfn_to_kaddr(range->start));\r\nend = (unsigned long)kasan_mem_to_shadow(pfn_to_kaddr(range->end));\r\nreturn vmemmap_populate(start, end + 1, NUMA_NO_NODE);\r\n}\r\nstatic void __init clear_pgds(unsigned long start,\r\nunsigned long end)\r\n{\r\nfor (; start < end; start += PGDIR_SIZE)\r\npgd_clear(pgd_offset_k(start));\r\n}\r\nvoid __init kasan_map_early_shadow(pgd_t *pgd)\r\n{\r\nint i;\r\nunsigned long start = KASAN_SHADOW_START;\r\nunsigned long end = KASAN_SHADOW_END;\r\nfor (i = pgd_index(start); start < end; i++) {\r\npgd[i] = __pgd(__pa_nodebug(kasan_zero_pud)\r\n| _KERNPG_TABLE);\r\nstart += PGDIR_SIZE;\r\n}\r\n}\r\nstatic int __init zero_pte_populate(pmd_t *pmd, unsigned long addr,\r\nunsigned long end)\r\n{\r\npte_t *pte = pte_offset_kernel(pmd, addr);\r\nwhile (addr + PAGE_SIZE <= end) {\r\nWARN_ON(!pte_none(*pte));\r\nset_pte(pte, __pte(__pa_nodebug(kasan_zero_page)\r\n| __PAGE_KERNEL_RO));\r\naddr += PAGE_SIZE;\r\npte = pte_offset_kernel(pmd, addr);\r\n}\r\nreturn 0;\r\n}\r\nstatic int __init zero_pmd_populate(pud_t *pud, unsigned long addr,\r\nunsigned long end)\r\n{\r\nint ret = 0;\r\npmd_t *pmd = pmd_offset(pud, addr);\r\nwhile (IS_ALIGNED(addr, PMD_SIZE) && addr + PMD_SIZE <= end) {\r\nWARN_ON(!pmd_none(*pmd));\r\nset_pmd(pmd, __pmd(__pa_nodebug(kasan_zero_pte)\r\n| __PAGE_KERNEL_RO));\r\naddr += PMD_SIZE;\r\npmd = pmd_offset(pud, addr);\r\n}\r\nif (addr < end) {\r\nif (pmd_none(*pmd)) {\r\nvoid *p = vmemmap_alloc_block(PAGE_SIZE, NUMA_NO_NODE);\r\nif (!p)\r\nreturn -ENOMEM;\r\nset_pmd(pmd, __pmd(__pa_nodebug(p) | _KERNPG_TABLE));\r\n}\r\nret = zero_pte_populate(pmd, addr, end);\r\n}\r\nreturn ret;\r\n}\r\nstatic int __init zero_pud_populate(pgd_t *pgd, unsigned long addr,\r\nunsigned long end)\r\n{\r\nint ret = 0;\r\npud_t *pud = pud_offset(pgd, addr);\r\nwhile (IS_ALIGNED(addr, PUD_SIZE) && addr + PUD_SIZE <= end) {\r\nWARN_ON(!pud_none(*pud));\r\nset_pud(pud, __pud(__pa_nodebug(kasan_zero_pmd)\r\n| __PAGE_KERNEL_RO));\r\naddr += PUD_SIZE;\r\npud = pud_offset(pgd, addr);\r\n}\r\nif (addr < end) {\r\nif (pud_none(*pud)) {\r\nvoid *p = vmemmap_alloc_block(PAGE_SIZE, NUMA_NO_NODE);\r\nif (!p)\r\nreturn -ENOMEM;\r\nset_pud(pud, __pud(__pa_nodebug(p) | _KERNPG_TABLE));\r\n}\r\nret = zero_pmd_populate(pud, addr, end);\r\n}\r\nreturn ret;\r\n}\r\nstatic int __init zero_pgd_populate(unsigned long addr, unsigned long end)\r\n{\r\nint ret = 0;\r\npgd_t *pgd = pgd_offset_k(addr);\r\nwhile (IS_ALIGNED(addr, PGDIR_SIZE) && addr + PGDIR_SIZE <= end) {\r\nWARN_ON(!pgd_none(*pgd));\r\nset_pgd(pgd, __pgd(__pa_nodebug(kasan_zero_pud)\r\n| __PAGE_KERNEL_RO));\r\naddr += PGDIR_SIZE;\r\npgd = pgd_offset_k(addr);\r\n}\r\nif (addr < end) {\r\nif (pgd_none(*pgd)) {\r\nvoid *p = vmemmap_alloc_block(PAGE_SIZE, NUMA_NO_NODE);\r\nif (!p)\r\nreturn -ENOMEM;\r\nset_pgd(pgd, __pgd(__pa_nodebug(p) | _KERNPG_TABLE));\r\n}\r\nret = zero_pud_populate(pgd, addr, end);\r\n}\r\nreturn ret;\r\n}\r\nstatic void __init populate_zero_shadow(const void *start, const void *end)\r\n{\r\nif (zero_pgd_populate((unsigned long)start, (unsigned long)end))\r\npanic("kasan: unable to map zero shadow!");\r\n}\r\nstatic int kasan_die_handler(struct notifier_block *self,\r\nunsigned long val,\r\nvoid *data)\r\n{\r\nif (val == DIE_GPF) {\r\npr_emerg("CONFIG_KASAN_INLINE enabled");\r\npr_emerg("GPF could be caused by NULL-ptr deref or user memory access");\r\n}\r\nreturn NOTIFY_OK;\r\n}\r\nvoid __init kasan_init(void)\r\n{\r\nint i;\r\n#ifdef CONFIG_KASAN_INLINE\r\nregister_die_notifier(&kasan_die_notifier);\r\n#endif\r\nmemcpy(early_level4_pgt, init_level4_pgt, sizeof(early_level4_pgt));\r\nload_cr3(early_level4_pgt);\r\nclear_pgds(KASAN_SHADOW_START, KASAN_SHADOW_END);\r\npopulate_zero_shadow((void *)KASAN_SHADOW_START,\r\nkasan_mem_to_shadow((void *)PAGE_OFFSET));\r\nfor (i = 0; i < E820_X_MAX; i++) {\r\nif (pfn_mapped[i].end == 0)\r\nbreak;\r\nif (map_range(&pfn_mapped[i]))\r\npanic("kasan: unable to allocate shadow!");\r\n}\r\npopulate_zero_shadow(kasan_mem_to_shadow((void *)PAGE_OFFSET + MAXMEM),\r\nkasan_mem_to_shadow((void *)__START_KERNEL_map));\r\nvmemmap_populate((unsigned long)kasan_mem_to_shadow(_stext),\r\n(unsigned long)kasan_mem_to_shadow(_end),\r\nNUMA_NO_NODE);\r\npopulate_zero_shadow(kasan_mem_to_shadow((void *)MODULES_END),\r\n(void *)KASAN_SHADOW_END);\r\nmemset(kasan_zero_page, 0, PAGE_SIZE);\r\nload_cr3(init_level4_pgt);\r\ninit_task.kasan_depth = 0;\r\n}
