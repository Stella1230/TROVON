static struct xhci_segment *xhci_segment_alloc(struct xhci_hcd *xhci,\r\nunsigned int cycle_state, gfp_t flags)\r\n{\r\nstruct xhci_segment *seg;\r\ndma_addr_t dma;\r\nint i;\r\nseg = kzalloc(sizeof *seg, flags);\r\nif (!seg)\r\nreturn NULL;\r\nseg->trbs = dma_pool_alloc(xhci->segment_pool, flags, &dma);\r\nif (!seg->trbs) {\r\nkfree(seg);\r\nreturn NULL;\r\n}\r\nmemset(seg->trbs, 0, TRB_SEGMENT_SIZE);\r\nif (cycle_state == 0) {\r\nfor (i = 0; i < TRBS_PER_SEGMENT; i++)\r\nseg->trbs[i].link.control |= cpu_to_le32(TRB_CYCLE);\r\n}\r\nseg->dma = dma;\r\nseg->next = NULL;\r\nreturn seg;\r\n}\r\nstatic void xhci_segment_free(struct xhci_hcd *xhci, struct xhci_segment *seg)\r\n{\r\nif (seg->trbs) {\r\ndma_pool_free(xhci->segment_pool, seg->trbs, seg->dma);\r\nseg->trbs = NULL;\r\n}\r\nkfree(seg);\r\n}\r\nstatic void xhci_free_segments_for_ring(struct xhci_hcd *xhci,\r\nstruct xhci_segment *first)\r\n{\r\nstruct xhci_segment *seg;\r\nseg = first->next;\r\nwhile (seg != first) {\r\nstruct xhci_segment *next = seg->next;\r\nxhci_segment_free(xhci, seg);\r\nseg = next;\r\n}\r\nxhci_segment_free(xhci, first);\r\n}\r\nstatic void xhci_link_segments(struct xhci_hcd *xhci, struct xhci_segment *prev,\r\nstruct xhci_segment *next, enum xhci_ring_type type)\r\n{\r\nu32 val;\r\nif (!prev || !next)\r\nreturn;\r\nprev->next = next;\r\nif (type != TYPE_EVENT) {\r\nprev->trbs[TRBS_PER_SEGMENT-1].link.segment_ptr =\r\ncpu_to_le64(next->dma);\r\nval = le32_to_cpu(prev->trbs[TRBS_PER_SEGMENT-1].link.control);\r\nval &= ~TRB_TYPE_BITMASK;\r\nval |= TRB_TYPE(TRB_LINK);\r\nif (xhci_link_trb_quirk(xhci) ||\r\n(type == TYPE_ISOC &&\r\n(xhci->quirks & XHCI_AMD_0x96_HOST)))\r\nval |= TRB_CHAIN;\r\nprev->trbs[TRBS_PER_SEGMENT-1].link.control = cpu_to_le32(val);\r\n}\r\n}\r\nstatic void xhci_link_rings(struct xhci_hcd *xhci, struct xhci_ring *ring,\r\nstruct xhci_segment *first, struct xhci_segment *last,\r\nunsigned int num_segs)\r\n{\r\nstruct xhci_segment *next;\r\nif (!ring || !first || !last)\r\nreturn;\r\nnext = ring->enq_seg->next;\r\nxhci_link_segments(xhci, ring->enq_seg, first, ring->type);\r\nxhci_link_segments(xhci, last, next, ring->type);\r\nring->num_segs += num_segs;\r\nring->num_trbs_free += (TRBS_PER_SEGMENT - 1) * num_segs;\r\nif (ring->type != TYPE_EVENT && ring->enq_seg == ring->last_seg) {\r\nring->last_seg->trbs[TRBS_PER_SEGMENT-1].link.control\r\n&= ~cpu_to_le32(LINK_TOGGLE);\r\nlast->trbs[TRBS_PER_SEGMENT-1].link.control\r\n|= cpu_to_le32(LINK_TOGGLE);\r\nring->last_seg = last;\r\n}\r\n}\r\nstatic int xhci_insert_segment_mapping(struct radix_tree_root *trb_address_map,\r\nstruct xhci_ring *ring,\r\nstruct xhci_segment *seg,\r\ngfp_t mem_flags)\r\n{\r\nunsigned long key;\r\nint ret;\r\nkey = (unsigned long)(seg->dma >> TRB_SEGMENT_SHIFT);\r\nif (radix_tree_lookup(trb_address_map, key))\r\nreturn 0;\r\nret = radix_tree_maybe_preload(mem_flags);\r\nif (ret)\r\nreturn ret;\r\nret = radix_tree_insert(trb_address_map,\r\nkey, ring);\r\nradix_tree_preload_end();\r\nreturn ret;\r\n}\r\nstatic void xhci_remove_segment_mapping(struct radix_tree_root *trb_address_map,\r\nstruct xhci_segment *seg)\r\n{\r\nunsigned long key;\r\nkey = (unsigned long)(seg->dma >> TRB_SEGMENT_SHIFT);\r\nif (radix_tree_lookup(trb_address_map, key))\r\nradix_tree_delete(trb_address_map, key);\r\n}\r\nstatic int xhci_update_stream_segment_mapping(\r\nstruct radix_tree_root *trb_address_map,\r\nstruct xhci_ring *ring,\r\nstruct xhci_segment *first_seg,\r\nstruct xhci_segment *last_seg,\r\ngfp_t mem_flags)\r\n{\r\nstruct xhci_segment *seg;\r\nstruct xhci_segment *failed_seg;\r\nint ret;\r\nif (WARN_ON_ONCE(trb_address_map == NULL))\r\nreturn 0;\r\nseg = first_seg;\r\ndo {\r\nret = xhci_insert_segment_mapping(trb_address_map,\r\nring, seg, mem_flags);\r\nif (ret)\r\ngoto remove_streams;\r\nif (seg == last_seg)\r\nreturn 0;\r\nseg = seg->next;\r\n} while (seg != first_seg);\r\nreturn 0;\r\nremove_streams:\r\nfailed_seg = seg;\r\nseg = first_seg;\r\ndo {\r\nxhci_remove_segment_mapping(trb_address_map, seg);\r\nif (seg == failed_seg)\r\nreturn ret;\r\nseg = seg->next;\r\n} while (seg != first_seg);\r\nreturn ret;\r\n}\r\nstatic void xhci_remove_stream_mapping(struct xhci_ring *ring)\r\n{\r\nstruct xhci_segment *seg;\r\nif (WARN_ON_ONCE(ring->trb_address_map == NULL))\r\nreturn;\r\nseg = ring->first_seg;\r\ndo {\r\nxhci_remove_segment_mapping(ring->trb_address_map, seg);\r\nseg = seg->next;\r\n} while (seg != ring->first_seg);\r\n}\r\nstatic int xhci_update_stream_mapping(struct xhci_ring *ring, gfp_t mem_flags)\r\n{\r\nreturn xhci_update_stream_segment_mapping(ring->trb_address_map, ring,\r\nring->first_seg, ring->last_seg, mem_flags);\r\n}\r\nvoid xhci_ring_free(struct xhci_hcd *xhci, struct xhci_ring *ring)\r\n{\r\nif (!ring)\r\nreturn;\r\nif (ring->first_seg) {\r\nif (ring->type == TYPE_STREAM)\r\nxhci_remove_stream_mapping(ring);\r\nxhci_free_segments_for_ring(xhci, ring->first_seg);\r\n}\r\nkfree(ring);\r\n}\r\nstatic void xhci_initialize_ring_info(struct xhci_ring *ring,\r\nunsigned int cycle_state)\r\n{\r\nring->enqueue = ring->first_seg->trbs;\r\nring->enq_seg = ring->first_seg;\r\nring->dequeue = ring->enqueue;\r\nring->deq_seg = ring->first_seg;\r\nring->cycle_state = cycle_state;\r\nring->enq_updates = 0;\r\nring->deq_updates = 0;\r\nring->num_trbs_free = ring->num_segs * (TRBS_PER_SEGMENT - 1) - 1;\r\n}\r\nstatic int xhci_alloc_segments_for_ring(struct xhci_hcd *xhci,\r\nstruct xhci_segment **first, struct xhci_segment **last,\r\nunsigned int num_segs, unsigned int cycle_state,\r\nenum xhci_ring_type type, gfp_t flags)\r\n{\r\nstruct xhci_segment *prev;\r\nprev = xhci_segment_alloc(xhci, cycle_state, flags);\r\nif (!prev)\r\nreturn -ENOMEM;\r\nnum_segs--;\r\n*first = prev;\r\nwhile (num_segs > 0) {\r\nstruct xhci_segment *next;\r\nnext = xhci_segment_alloc(xhci, cycle_state, flags);\r\nif (!next) {\r\nprev = *first;\r\nwhile (prev) {\r\nnext = prev->next;\r\nxhci_segment_free(xhci, prev);\r\nprev = next;\r\n}\r\nreturn -ENOMEM;\r\n}\r\nxhci_link_segments(xhci, prev, next, type);\r\nprev = next;\r\nnum_segs--;\r\n}\r\nxhci_link_segments(xhci, prev, *first, type);\r\n*last = prev;\r\nreturn 0;\r\n}\r\nstatic struct xhci_ring *xhci_ring_alloc(struct xhci_hcd *xhci,\r\nunsigned int num_segs, unsigned int cycle_state,\r\nenum xhci_ring_type type, gfp_t flags)\r\n{\r\nstruct xhci_ring *ring;\r\nint ret;\r\nring = kzalloc(sizeof *(ring), flags);\r\nif (!ring)\r\nreturn NULL;\r\nring->num_segs = num_segs;\r\nINIT_LIST_HEAD(&ring->td_list);\r\nring->type = type;\r\nif (num_segs == 0)\r\nreturn ring;\r\nret = xhci_alloc_segments_for_ring(xhci, &ring->first_seg,\r\n&ring->last_seg, num_segs, cycle_state, type, flags);\r\nif (ret)\r\ngoto fail;\r\nif (type != TYPE_EVENT) {\r\nring->last_seg->trbs[TRBS_PER_SEGMENT - 1].link.control |=\r\ncpu_to_le32(LINK_TOGGLE);\r\n}\r\nxhci_initialize_ring_info(ring, cycle_state);\r\nreturn ring;\r\nfail:\r\nkfree(ring);\r\nreturn NULL;\r\n}\r\nvoid xhci_free_or_cache_endpoint_ring(struct xhci_hcd *xhci,\r\nstruct xhci_virt_device *virt_dev,\r\nunsigned int ep_index)\r\n{\r\nint rings_cached;\r\nrings_cached = virt_dev->num_rings_cached;\r\nif (rings_cached < XHCI_MAX_RINGS_CACHED) {\r\nvirt_dev->ring_cache[rings_cached] =\r\nvirt_dev->eps[ep_index].ring;\r\nvirt_dev->num_rings_cached++;\r\nxhci_dbg(xhci, "Cached old ring, "\r\n"%d ring%s cached\n",\r\nvirt_dev->num_rings_cached,\r\n(virt_dev->num_rings_cached > 1) ? "s" : "");\r\n} else {\r\nxhci_ring_free(xhci, virt_dev->eps[ep_index].ring);\r\nxhci_dbg(xhci, "Ring cache full (%d rings), "\r\n"freeing ring\n",\r\nvirt_dev->num_rings_cached);\r\n}\r\nvirt_dev->eps[ep_index].ring = NULL;\r\n}\r\nstatic void xhci_reinit_cached_ring(struct xhci_hcd *xhci,\r\nstruct xhci_ring *ring, unsigned int cycle_state,\r\nenum xhci_ring_type type)\r\n{\r\nstruct xhci_segment *seg = ring->first_seg;\r\nint i;\r\ndo {\r\nmemset(seg->trbs, 0,\r\nsizeof(union xhci_trb)*TRBS_PER_SEGMENT);\r\nif (cycle_state == 0) {\r\nfor (i = 0; i < TRBS_PER_SEGMENT; i++)\r\nseg->trbs[i].link.control |=\r\ncpu_to_le32(TRB_CYCLE);\r\n}\r\nxhci_link_segments(xhci, seg, seg->next, type);\r\nseg = seg->next;\r\n} while (seg != ring->first_seg);\r\nring->type = type;\r\nxhci_initialize_ring_info(ring, cycle_state);\r\nINIT_LIST_HEAD(&ring->td_list);\r\n}\r\nint xhci_ring_expansion(struct xhci_hcd *xhci, struct xhci_ring *ring,\r\nunsigned int num_trbs, gfp_t flags)\r\n{\r\nstruct xhci_segment *first;\r\nstruct xhci_segment *last;\r\nunsigned int num_segs;\r\nunsigned int num_segs_needed;\r\nint ret;\r\nnum_segs_needed = (num_trbs + (TRBS_PER_SEGMENT - 1) - 1) /\r\n(TRBS_PER_SEGMENT - 1);\r\nnum_segs = ring->num_segs > num_segs_needed ?\r\nring->num_segs : num_segs_needed;\r\nret = xhci_alloc_segments_for_ring(xhci, &first, &last,\r\nnum_segs, ring->cycle_state, ring->type, flags);\r\nif (ret)\r\nreturn -ENOMEM;\r\nif (ring->type == TYPE_STREAM)\r\nret = xhci_update_stream_segment_mapping(ring->trb_address_map,\r\nring, first, last, flags);\r\nif (ret) {\r\nstruct xhci_segment *next;\r\ndo {\r\nnext = first->next;\r\nxhci_segment_free(xhci, first);\r\nif (first == last)\r\nbreak;\r\nfirst = next;\r\n} while (true);\r\nreturn ret;\r\n}\r\nxhci_link_rings(xhci, ring, first, last, num_segs);\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_ring_expansion,\r\n"ring expansion succeed, now has %d segments",\r\nring->num_segs);\r\nreturn 0;\r\n}\r\nstatic struct xhci_container_ctx *xhci_alloc_container_ctx(struct xhci_hcd *xhci,\r\nint type, gfp_t flags)\r\n{\r\nstruct xhci_container_ctx *ctx;\r\nif ((type != XHCI_CTX_TYPE_DEVICE) && (type != XHCI_CTX_TYPE_INPUT))\r\nreturn NULL;\r\nctx = kzalloc(sizeof(*ctx), flags);\r\nif (!ctx)\r\nreturn NULL;\r\nctx->type = type;\r\nctx->size = HCC_64BYTE_CONTEXT(xhci->hcc_params) ? 2048 : 1024;\r\nif (type == XHCI_CTX_TYPE_INPUT)\r\nctx->size += CTX_SIZE(xhci->hcc_params);\r\nctx->bytes = dma_pool_alloc(xhci->device_pool, flags, &ctx->dma);\r\nif (!ctx->bytes) {\r\nkfree(ctx);\r\nreturn NULL;\r\n}\r\nmemset(ctx->bytes, 0, ctx->size);\r\nreturn ctx;\r\n}\r\nstatic void xhci_free_container_ctx(struct xhci_hcd *xhci,\r\nstruct xhci_container_ctx *ctx)\r\n{\r\nif (!ctx)\r\nreturn;\r\ndma_pool_free(xhci->device_pool, ctx->bytes, ctx->dma);\r\nkfree(ctx);\r\n}\r\nstruct xhci_input_control_ctx *xhci_get_input_control_ctx(\r\nstruct xhci_container_ctx *ctx)\r\n{\r\nif (ctx->type != XHCI_CTX_TYPE_INPUT)\r\nreturn NULL;\r\nreturn (struct xhci_input_control_ctx *)ctx->bytes;\r\n}\r\nstruct xhci_slot_ctx *xhci_get_slot_ctx(struct xhci_hcd *xhci,\r\nstruct xhci_container_ctx *ctx)\r\n{\r\nif (ctx->type == XHCI_CTX_TYPE_DEVICE)\r\nreturn (struct xhci_slot_ctx *)ctx->bytes;\r\nreturn (struct xhci_slot_ctx *)\r\n(ctx->bytes + CTX_SIZE(xhci->hcc_params));\r\n}\r\nstruct xhci_ep_ctx *xhci_get_ep_ctx(struct xhci_hcd *xhci,\r\nstruct xhci_container_ctx *ctx,\r\nunsigned int ep_index)\r\n{\r\nep_index++;\r\nif (ctx->type == XHCI_CTX_TYPE_INPUT)\r\nep_index++;\r\nreturn (struct xhci_ep_ctx *)\r\n(ctx->bytes + (ep_index * CTX_SIZE(xhci->hcc_params)));\r\n}\r\nstatic void xhci_free_stream_ctx(struct xhci_hcd *xhci,\r\nunsigned int num_stream_ctxs,\r\nstruct xhci_stream_ctx *stream_ctx, dma_addr_t dma)\r\n{\r\nstruct device *dev = xhci_to_hcd(xhci)->self.controller;\r\nsize_t size = sizeof(struct xhci_stream_ctx) * num_stream_ctxs;\r\nif (size > MEDIUM_STREAM_ARRAY_SIZE)\r\ndma_free_coherent(dev, size,\r\nstream_ctx, dma);\r\nelse if (size <= SMALL_STREAM_ARRAY_SIZE)\r\nreturn dma_pool_free(xhci->small_streams_pool,\r\nstream_ctx, dma);\r\nelse\r\nreturn dma_pool_free(xhci->medium_streams_pool,\r\nstream_ctx, dma);\r\n}\r\nstatic struct xhci_stream_ctx *xhci_alloc_stream_ctx(struct xhci_hcd *xhci,\r\nunsigned int num_stream_ctxs, dma_addr_t *dma,\r\ngfp_t mem_flags)\r\n{\r\nstruct device *dev = xhci_to_hcd(xhci)->self.controller;\r\nsize_t size = sizeof(struct xhci_stream_ctx) * num_stream_ctxs;\r\nif (size > MEDIUM_STREAM_ARRAY_SIZE)\r\nreturn dma_alloc_coherent(dev, size,\r\ndma, mem_flags);\r\nelse if (size <= SMALL_STREAM_ARRAY_SIZE)\r\nreturn dma_pool_alloc(xhci->small_streams_pool,\r\nmem_flags, dma);\r\nelse\r\nreturn dma_pool_alloc(xhci->medium_streams_pool,\r\nmem_flags, dma);\r\n}\r\nstruct xhci_ring *xhci_dma_to_transfer_ring(\r\nstruct xhci_virt_ep *ep,\r\nu64 address)\r\n{\r\nif (ep->ep_state & EP_HAS_STREAMS)\r\nreturn radix_tree_lookup(&ep->stream_info->trb_address_map,\r\naddress >> TRB_SEGMENT_SHIFT);\r\nreturn ep->ring;\r\n}\r\nstruct xhci_ring *xhci_stream_id_to_ring(\r\nstruct xhci_virt_device *dev,\r\nunsigned int ep_index,\r\nunsigned int stream_id)\r\n{\r\nstruct xhci_virt_ep *ep = &dev->eps[ep_index];\r\nif (stream_id == 0)\r\nreturn ep->ring;\r\nif (!ep->stream_info)\r\nreturn NULL;\r\nif (stream_id > ep->stream_info->num_streams)\r\nreturn NULL;\r\nreturn ep->stream_info->stream_rings[stream_id];\r\n}\r\nstruct xhci_stream_info *xhci_alloc_stream_info(struct xhci_hcd *xhci,\r\nunsigned int num_stream_ctxs,\r\nunsigned int num_streams, gfp_t mem_flags)\r\n{\r\nstruct xhci_stream_info *stream_info;\r\nu32 cur_stream;\r\nstruct xhci_ring *cur_ring;\r\nu64 addr;\r\nint ret;\r\nxhci_dbg(xhci, "Allocating %u streams and %u "\r\n"stream context array entries.\n",\r\nnum_streams, num_stream_ctxs);\r\nif (xhci->cmd_ring_reserved_trbs == MAX_RSVD_CMD_TRBS) {\r\nxhci_dbg(xhci, "Command ring has no reserved TRBs available\n");\r\nreturn NULL;\r\n}\r\nxhci->cmd_ring_reserved_trbs++;\r\nstream_info = kzalloc(sizeof(struct xhci_stream_info), mem_flags);\r\nif (!stream_info)\r\ngoto cleanup_trbs;\r\nstream_info->num_streams = num_streams;\r\nstream_info->num_stream_ctxs = num_stream_ctxs;\r\nstream_info->stream_rings = kzalloc(\r\nsizeof(struct xhci_ring *)*num_streams,\r\nmem_flags);\r\nif (!stream_info->stream_rings)\r\ngoto cleanup_info;\r\nstream_info->stream_ctx_array = xhci_alloc_stream_ctx(xhci,\r\nnum_stream_ctxs, &stream_info->ctx_array_dma,\r\nmem_flags);\r\nif (!stream_info->stream_ctx_array)\r\ngoto cleanup_ctx;\r\nmemset(stream_info->stream_ctx_array, 0,\r\nsizeof(struct xhci_stream_ctx)*num_stream_ctxs);\r\nstream_info->free_streams_command =\r\nxhci_alloc_command(xhci, true, true, mem_flags);\r\nif (!stream_info->free_streams_command)\r\ngoto cleanup_ctx;\r\nINIT_RADIX_TREE(&stream_info->trb_address_map, GFP_ATOMIC);\r\nfor (cur_stream = 1; cur_stream < num_streams; cur_stream++) {\r\nstream_info->stream_rings[cur_stream] =\r\nxhci_ring_alloc(xhci, 2, 1, TYPE_STREAM, mem_flags);\r\ncur_ring = stream_info->stream_rings[cur_stream];\r\nif (!cur_ring)\r\ngoto cleanup_rings;\r\ncur_ring->stream_id = cur_stream;\r\ncur_ring->trb_address_map = &stream_info->trb_address_map;\r\naddr = cur_ring->first_seg->dma |\r\nSCT_FOR_CTX(SCT_PRI_TR) |\r\ncur_ring->cycle_state;\r\nstream_info->stream_ctx_array[cur_stream].stream_ring =\r\ncpu_to_le64(addr);\r\nxhci_dbg(xhci, "Setting stream %d ring ptr to 0x%08llx\n",\r\ncur_stream, (unsigned long long) addr);\r\nret = xhci_update_stream_mapping(cur_ring, mem_flags);\r\nif (ret) {\r\nxhci_ring_free(xhci, cur_ring);\r\nstream_info->stream_rings[cur_stream] = NULL;\r\ngoto cleanup_rings;\r\n}\r\n}\r\nreturn stream_info;\r\ncleanup_rings:\r\nfor (cur_stream = 1; cur_stream < num_streams; cur_stream++) {\r\ncur_ring = stream_info->stream_rings[cur_stream];\r\nif (cur_ring) {\r\nxhci_ring_free(xhci, cur_ring);\r\nstream_info->stream_rings[cur_stream] = NULL;\r\n}\r\n}\r\nxhci_free_command(xhci, stream_info->free_streams_command);\r\ncleanup_ctx:\r\nkfree(stream_info->stream_rings);\r\ncleanup_info:\r\nkfree(stream_info);\r\ncleanup_trbs:\r\nxhci->cmd_ring_reserved_trbs--;\r\nreturn NULL;\r\n}\r\nvoid xhci_setup_streams_ep_input_ctx(struct xhci_hcd *xhci,\r\nstruct xhci_ep_ctx *ep_ctx,\r\nstruct xhci_stream_info *stream_info)\r\n{\r\nu32 max_primary_streams;\r\nmax_primary_streams = fls(stream_info->num_stream_ctxs) - 2;\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_context_change,\r\n"Setting number of stream ctx array entries to %u",\r\n1 << (max_primary_streams + 1));\r\nep_ctx->ep_info &= cpu_to_le32(~EP_MAXPSTREAMS_MASK);\r\nep_ctx->ep_info |= cpu_to_le32(EP_MAXPSTREAMS(max_primary_streams)\r\n| EP_HAS_LSA);\r\nep_ctx->deq = cpu_to_le64(stream_info->ctx_array_dma);\r\n}\r\nvoid xhci_setup_no_streams_ep_input_ctx(struct xhci_ep_ctx *ep_ctx,\r\nstruct xhci_virt_ep *ep)\r\n{\r\ndma_addr_t addr;\r\nep_ctx->ep_info &= cpu_to_le32(~(EP_MAXPSTREAMS_MASK | EP_HAS_LSA));\r\naddr = xhci_trb_virt_to_dma(ep->ring->deq_seg, ep->ring->dequeue);\r\nep_ctx->deq = cpu_to_le64(addr | ep->ring->cycle_state);\r\n}\r\nvoid xhci_free_stream_info(struct xhci_hcd *xhci,\r\nstruct xhci_stream_info *stream_info)\r\n{\r\nint cur_stream;\r\nstruct xhci_ring *cur_ring;\r\nif (!stream_info)\r\nreturn;\r\nfor (cur_stream = 1; cur_stream < stream_info->num_streams;\r\ncur_stream++) {\r\ncur_ring = stream_info->stream_rings[cur_stream];\r\nif (cur_ring) {\r\nxhci_ring_free(xhci, cur_ring);\r\nstream_info->stream_rings[cur_stream] = NULL;\r\n}\r\n}\r\nxhci_free_command(xhci, stream_info->free_streams_command);\r\nxhci->cmd_ring_reserved_trbs--;\r\nif (stream_info->stream_ctx_array)\r\nxhci_free_stream_ctx(xhci,\r\nstream_info->num_stream_ctxs,\r\nstream_info->stream_ctx_array,\r\nstream_info->ctx_array_dma);\r\nkfree(stream_info->stream_rings);\r\nkfree(stream_info);\r\n}\r\nstatic void xhci_init_endpoint_timer(struct xhci_hcd *xhci,\r\nstruct xhci_virt_ep *ep)\r\n{\r\nsetup_timer(&ep->stop_cmd_timer, xhci_stop_endpoint_command_watchdog,\r\n(unsigned long)ep);\r\nep->xhci = xhci;\r\n}\r\nstatic void xhci_free_tt_info(struct xhci_hcd *xhci,\r\nstruct xhci_virt_device *virt_dev,\r\nint slot_id)\r\n{\r\nstruct list_head *tt_list_head;\r\nstruct xhci_tt_bw_info *tt_info, *next;\r\nbool slot_found = false;\r\nif (virt_dev->real_port == 0 ||\r\nvirt_dev->real_port > HCS_MAX_PORTS(xhci->hcs_params1)) {\r\nxhci_dbg(xhci, "Bad real port.\n");\r\nreturn;\r\n}\r\ntt_list_head = &(xhci->rh_bw[virt_dev->real_port - 1].tts);\r\nlist_for_each_entry_safe(tt_info, next, tt_list_head, tt_list) {\r\nif (tt_info->slot_id == slot_id) {\r\nslot_found = true;\r\nlist_del(&tt_info->tt_list);\r\nkfree(tt_info);\r\n} else if (slot_found) {\r\nbreak;\r\n}\r\n}\r\n}\r\nint xhci_alloc_tt_info(struct xhci_hcd *xhci,\r\nstruct xhci_virt_device *virt_dev,\r\nstruct usb_device *hdev,\r\nstruct usb_tt *tt, gfp_t mem_flags)\r\n{\r\nstruct xhci_tt_bw_info *tt_info;\r\nunsigned int num_ports;\r\nint i, j;\r\nif (!tt->multi)\r\nnum_ports = 1;\r\nelse\r\nnum_ports = hdev->maxchild;\r\nfor (i = 0; i < num_ports; i++, tt_info++) {\r\nstruct xhci_interval_bw_table *bw_table;\r\ntt_info = kzalloc(sizeof(*tt_info), mem_flags);\r\nif (!tt_info)\r\ngoto free_tts;\r\nINIT_LIST_HEAD(&tt_info->tt_list);\r\nlist_add(&tt_info->tt_list,\r\n&xhci->rh_bw[virt_dev->real_port - 1].tts);\r\ntt_info->slot_id = virt_dev->udev->slot_id;\r\nif (tt->multi)\r\ntt_info->ttport = i+1;\r\nbw_table = &tt_info->bw_table;\r\nfor (j = 0; j < XHCI_MAX_INTERVAL; j++)\r\nINIT_LIST_HEAD(&bw_table->interval_bw[j].endpoints);\r\n}\r\nreturn 0;\r\nfree_tts:\r\nxhci_free_tt_info(xhci, virt_dev, virt_dev->udev->slot_id);\r\nreturn -ENOMEM;\r\n}\r\nvoid xhci_free_virt_device(struct xhci_hcd *xhci, int slot_id)\r\n{\r\nstruct xhci_virt_device *dev;\r\nint i;\r\nint old_active_eps = 0;\r\nif (slot_id == 0 || !xhci->devs[slot_id])\r\nreturn;\r\ndev = xhci->devs[slot_id];\r\nxhci->dcbaa->dev_context_ptrs[slot_id] = 0;\r\nif (!dev)\r\nreturn;\r\nif (dev->tt_info)\r\nold_active_eps = dev->tt_info->active_eps;\r\nfor (i = 0; i < 31; ++i) {\r\nif (dev->eps[i].ring)\r\nxhci_ring_free(xhci, dev->eps[i].ring);\r\nif (dev->eps[i].stream_info)\r\nxhci_free_stream_info(xhci,\r\ndev->eps[i].stream_info);\r\nif (!list_empty(&dev->eps[i].bw_endpoint_list))\r\nxhci_warn(xhci, "Slot %u endpoint %u "\r\n"not removed from BW list!\n",\r\nslot_id, i);\r\n}\r\nxhci_free_tt_info(xhci, dev, slot_id);\r\nxhci_update_tt_active_eps(xhci, dev, old_active_eps);\r\nif (dev->ring_cache) {\r\nfor (i = 0; i < dev->num_rings_cached; i++)\r\nxhci_ring_free(xhci, dev->ring_cache[i]);\r\nkfree(dev->ring_cache);\r\n}\r\nif (dev->in_ctx)\r\nxhci_free_container_ctx(xhci, dev->in_ctx);\r\nif (dev->out_ctx)\r\nxhci_free_container_ctx(xhci, dev->out_ctx);\r\nkfree(xhci->devs[slot_id]);\r\nxhci->devs[slot_id] = NULL;\r\n}\r\nint xhci_alloc_virt_device(struct xhci_hcd *xhci, int slot_id,\r\nstruct usb_device *udev, gfp_t flags)\r\n{\r\nstruct xhci_virt_device *dev;\r\nint i;\r\nif (slot_id == 0 || xhci->devs[slot_id]) {\r\nxhci_warn(xhci, "Bad Slot ID %d\n", slot_id);\r\nreturn 0;\r\n}\r\nxhci->devs[slot_id] = kzalloc(sizeof(*xhci->devs[slot_id]), flags);\r\nif (!xhci->devs[slot_id])\r\nreturn 0;\r\ndev = xhci->devs[slot_id];\r\ndev->out_ctx = xhci_alloc_container_ctx(xhci, XHCI_CTX_TYPE_DEVICE, flags);\r\nif (!dev->out_ctx)\r\ngoto fail;\r\nxhci_dbg(xhci, "Slot %d output ctx = 0x%llx (dma)\n", slot_id,\r\n(unsigned long long)dev->out_ctx->dma);\r\ndev->in_ctx = xhci_alloc_container_ctx(xhci, XHCI_CTX_TYPE_INPUT, flags);\r\nif (!dev->in_ctx)\r\ngoto fail;\r\nxhci_dbg(xhci, "Slot %d input ctx = 0x%llx (dma)\n", slot_id,\r\n(unsigned long long)dev->in_ctx->dma);\r\nfor (i = 0; i < 31; i++) {\r\nxhci_init_endpoint_timer(xhci, &dev->eps[i]);\r\nINIT_LIST_HEAD(&dev->eps[i].cancelled_td_list);\r\nINIT_LIST_HEAD(&dev->eps[i].bw_endpoint_list);\r\n}\r\ndev->eps[0].ring = xhci_ring_alloc(xhci, 2, 1, TYPE_CTRL, flags);\r\nif (!dev->eps[0].ring)\r\ngoto fail;\r\ndev->ring_cache = kzalloc(\r\nsizeof(struct xhci_ring *)*XHCI_MAX_RINGS_CACHED,\r\nflags);\r\nif (!dev->ring_cache)\r\ngoto fail;\r\ndev->num_rings_cached = 0;\r\ninit_completion(&dev->cmd_completion);\r\ndev->udev = udev;\r\nxhci->dcbaa->dev_context_ptrs[slot_id] = cpu_to_le64(dev->out_ctx->dma);\r\nxhci_dbg(xhci, "Set slot id %d dcbaa entry %p to 0x%llx\n",\r\nslot_id,\r\n&xhci->dcbaa->dev_context_ptrs[slot_id],\r\nle64_to_cpu(xhci->dcbaa->dev_context_ptrs[slot_id]));\r\nreturn 1;\r\nfail:\r\nxhci_free_virt_device(xhci, slot_id);\r\nreturn 0;\r\n}\r\nvoid xhci_copy_ep0_dequeue_into_input_ctx(struct xhci_hcd *xhci,\r\nstruct usb_device *udev)\r\n{\r\nstruct xhci_virt_device *virt_dev;\r\nstruct xhci_ep_ctx *ep0_ctx;\r\nstruct xhci_ring *ep_ring;\r\nvirt_dev = xhci->devs[udev->slot_id];\r\nep0_ctx = xhci_get_ep_ctx(xhci, virt_dev->in_ctx, 0);\r\nep_ring = virt_dev->eps[0].ring;\r\nep0_ctx->deq = cpu_to_le64(xhci_trb_virt_to_dma(ep_ring->enq_seg,\r\nep_ring->enqueue)\r\n| ep_ring->cycle_state);\r\n}\r\nstatic u32 xhci_find_real_port_number(struct xhci_hcd *xhci,\r\nstruct usb_device *udev)\r\n{\r\nstruct usb_device *top_dev;\r\nstruct usb_hcd *hcd;\r\nif (udev->speed == USB_SPEED_SUPER)\r\nhcd = xhci->shared_hcd;\r\nelse\r\nhcd = xhci->main_hcd;\r\nfor (top_dev = udev; top_dev->parent && top_dev->parent->parent;\r\ntop_dev = top_dev->parent)\r\n;\r\nreturn xhci_find_raw_port_number(hcd, top_dev->portnum);\r\n}\r\nint xhci_setup_addressable_virt_dev(struct xhci_hcd *xhci, struct usb_device *udev)\r\n{\r\nstruct xhci_virt_device *dev;\r\nstruct xhci_ep_ctx *ep0_ctx;\r\nstruct xhci_slot_ctx *slot_ctx;\r\nu32 port_num;\r\nu32 max_packets;\r\nstruct usb_device *top_dev;\r\ndev = xhci->devs[udev->slot_id];\r\nif (udev->slot_id == 0 || !dev) {\r\nxhci_warn(xhci, "Slot ID %d is not assigned to this device\n",\r\nudev->slot_id);\r\nreturn -EINVAL;\r\n}\r\nep0_ctx = xhci_get_ep_ctx(xhci, dev->in_ctx, 0);\r\nslot_ctx = xhci_get_slot_ctx(xhci, dev->in_ctx);\r\nslot_ctx->dev_info |= cpu_to_le32(LAST_CTX(1) | udev->route);\r\nswitch (udev->speed) {\r\ncase USB_SPEED_SUPER:\r\nslot_ctx->dev_info |= cpu_to_le32(SLOT_SPEED_SS);\r\nmax_packets = MAX_PACKET(512);\r\nbreak;\r\ncase USB_SPEED_HIGH:\r\nslot_ctx->dev_info |= cpu_to_le32(SLOT_SPEED_HS);\r\nmax_packets = MAX_PACKET(64);\r\nbreak;\r\ncase USB_SPEED_FULL:\r\nslot_ctx->dev_info |= cpu_to_le32(SLOT_SPEED_FS);\r\nmax_packets = MAX_PACKET(64);\r\nbreak;\r\ncase USB_SPEED_LOW:\r\nslot_ctx->dev_info |= cpu_to_le32(SLOT_SPEED_LS);\r\nmax_packets = MAX_PACKET(8);\r\nbreak;\r\ncase USB_SPEED_WIRELESS:\r\nxhci_dbg(xhci, "FIXME xHCI doesn't support wireless speeds\n");\r\nreturn -EINVAL;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nport_num = xhci_find_real_port_number(xhci, udev);\r\nif (!port_num)\r\nreturn -EINVAL;\r\nslot_ctx->dev_info2 |= cpu_to_le32(ROOT_HUB_PORT(port_num));\r\nfor (top_dev = udev; top_dev->parent && top_dev->parent->parent;\r\ntop_dev = top_dev->parent)\r\n;\r\ndev->fake_port = top_dev->portnum;\r\ndev->real_port = port_num;\r\nxhci_dbg(xhci, "Set root hub portnum to %d\n", port_num);\r\nxhci_dbg(xhci, "Set fake root hub portnum to %d\n", dev->fake_port);\r\nif (!udev->tt || !udev->tt->hub->parent) {\r\ndev->bw_table = &xhci->rh_bw[port_num - 1].bw_table;\r\n} else {\r\nstruct xhci_root_port_bw_info *rh_bw;\r\nstruct xhci_tt_bw_info *tt_bw;\r\nrh_bw = &xhci->rh_bw[port_num - 1];\r\nlist_for_each_entry(tt_bw, &rh_bw->tts, tt_list) {\r\nif (tt_bw->slot_id != udev->tt->hub->slot_id)\r\ncontinue;\r\nif (!dev->udev->tt->multi ||\r\n(udev->tt->multi &&\r\ntt_bw->ttport == dev->udev->ttport)) {\r\ndev->bw_table = &tt_bw->bw_table;\r\ndev->tt_info = tt_bw;\r\nbreak;\r\n}\r\n}\r\nif (!dev->tt_info)\r\nxhci_warn(xhci, "WARN: Didn't find a matching TT\n");\r\n}\r\nif (udev->tt && udev->tt->hub->parent) {\r\nslot_ctx->tt_info = cpu_to_le32(udev->tt->hub->slot_id |\r\n(udev->ttport << 8));\r\nif (udev->tt->multi)\r\nslot_ctx->dev_info |= cpu_to_le32(DEV_MTT);\r\n}\r\nxhci_dbg(xhci, "udev->tt = %p\n", udev->tt);\r\nxhci_dbg(xhci, "udev->ttport = 0x%x\n", udev->ttport);\r\nep0_ctx->ep_info2 = cpu_to_le32(EP_TYPE(CTRL_EP));\r\nep0_ctx->ep_info2 |= cpu_to_le32(MAX_BURST(0) | ERROR_COUNT(3) |\r\nmax_packets);\r\nep0_ctx->deq = cpu_to_le64(dev->eps[0].ring->first_seg->dma |\r\ndev->eps[0].ring->cycle_state);\r\nreturn 0;\r\n}\r\nstatic unsigned int xhci_parse_exponent_interval(struct usb_device *udev,\r\nstruct usb_host_endpoint *ep)\r\n{\r\nunsigned int interval;\r\ninterval = clamp_val(ep->desc.bInterval, 1, 16) - 1;\r\nif (interval != ep->desc.bInterval - 1)\r\ndev_warn(&udev->dev,\r\n"ep %#x - rounding interval to %d %sframes\n",\r\nep->desc.bEndpointAddress,\r\n1 << interval,\r\nudev->speed == USB_SPEED_FULL ? "" : "micro");\r\nif (udev->speed == USB_SPEED_FULL) {\r\ninterval += 3;\r\n}\r\nreturn interval;\r\n}\r\nstatic unsigned int xhci_microframes_to_exponent(struct usb_device *udev,\r\nstruct usb_host_endpoint *ep, unsigned int desc_interval,\r\nunsigned int min_exponent, unsigned int max_exponent)\r\n{\r\nunsigned int interval;\r\ninterval = fls(desc_interval) - 1;\r\ninterval = clamp_val(interval, min_exponent, max_exponent);\r\nif ((1 << interval) != desc_interval)\r\ndev_warn(&udev->dev,\r\n"ep %#x - rounding interval to %d microframes, ep desc says %d microframes\n",\r\nep->desc.bEndpointAddress,\r\n1 << interval,\r\ndesc_interval);\r\nreturn interval;\r\n}\r\nstatic unsigned int xhci_parse_microframe_interval(struct usb_device *udev,\r\nstruct usb_host_endpoint *ep)\r\n{\r\nif (ep->desc.bInterval == 0)\r\nreturn 0;\r\nreturn xhci_microframes_to_exponent(udev, ep,\r\nep->desc.bInterval, 0, 15);\r\n}\r\nstatic unsigned int xhci_parse_frame_interval(struct usb_device *udev,\r\nstruct usb_host_endpoint *ep)\r\n{\r\nreturn xhci_microframes_to_exponent(udev, ep,\r\nep->desc.bInterval * 8, 3, 10);\r\n}\r\nstatic unsigned int xhci_get_endpoint_interval(struct usb_device *udev,\r\nstruct usb_host_endpoint *ep)\r\n{\r\nunsigned int interval = 0;\r\nswitch (udev->speed) {\r\ncase USB_SPEED_HIGH:\r\nif (usb_endpoint_xfer_control(&ep->desc) ||\r\nusb_endpoint_xfer_bulk(&ep->desc)) {\r\ninterval = xhci_parse_microframe_interval(udev, ep);\r\nbreak;\r\n}\r\ncase USB_SPEED_SUPER:\r\nif (usb_endpoint_xfer_int(&ep->desc) ||\r\nusb_endpoint_xfer_isoc(&ep->desc)) {\r\ninterval = xhci_parse_exponent_interval(udev, ep);\r\n}\r\nbreak;\r\ncase USB_SPEED_FULL:\r\nif (usb_endpoint_xfer_isoc(&ep->desc)) {\r\ninterval = xhci_parse_exponent_interval(udev, ep);\r\nbreak;\r\n}\r\ncase USB_SPEED_LOW:\r\nif (usb_endpoint_xfer_int(&ep->desc) ||\r\nusb_endpoint_xfer_isoc(&ep->desc)) {\r\ninterval = xhci_parse_frame_interval(udev, ep);\r\n}\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\nreturn EP_INTERVAL(interval);\r\n}\r\nstatic u32 xhci_get_endpoint_mult(struct usb_device *udev,\r\nstruct usb_host_endpoint *ep)\r\n{\r\nif (udev->speed != USB_SPEED_SUPER ||\r\n!usb_endpoint_xfer_isoc(&ep->desc))\r\nreturn 0;\r\nreturn ep->ss_ep_comp.bmAttributes;\r\n}\r\nstatic u32 xhci_get_endpoint_type(struct usb_host_endpoint *ep)\r\n{\r\nint in;\r\nu32 type;\r\nin = usb_endpoint_dir_in(&ep->desc);\r\nif (usb_endpoint_xfer_control(&ep->desc)) {\r\ntype = EP_TYPE(CTRL_EP);\r\n} else if (usb_endpoint_xfer_bulk(&ep->desc)) {\r\nif (in)\r\ntype = EP_TYPE(BULK_IN_EP);\r\nelse\r\ntype = EP_TYPE(BULK_OUT_EP);\r\n} else if (usb_endpoint_xfer_isoc(&ep->desc)) {\r\nif (in)\r\ntype = EP_TYPE(ISOC_IN_EP);\r\nelse\r\ntype = EP_TYPE(ISOC_OUT_EP);\r\n} else if (usb_endpoint_xfer_int(&ep->desc)) {\r\nif (in)\r\ntype = EP_TYPE(INT_IN_EP);\r\nelse\r\ntype = EP_TYPE(INT_OUT_EP);\r\n} else {\r\ntype = 0;\r\n}\r\nreturn type;\r\n}\r\nstatic u32 xhci_get_max_esit_payload(struct usb_device *udev,\r\nstruct usb_host_endpoint *ep)\r\n{\r\nint max_burst;\r\nint max_packet;\r\nif (usb_endpoint_xfer_control(&ep->desc) ||\r\nusb_endpoint_xfer_bulk(&ep->desc))\r\nreturn 0;\r\nif (udev->speed == USB_SPEED_SUPER)\r\nreturn le16_to_cpu(ep->ss_ep_comp.wBytesPerInterval);\r\nmax_packet = GET_MAX_PACKET(usb_endpoint_maxp(&ep->desc));\r\nmax_burst = (usb_endpoint_maxp(&ep->desc) & 0x1800) >> 11;\r\nreturn max_packet * (max_burst + 1);\r\n}\r\nint xhci_endpoint_init(struct xhci_hcd *xhci,\r\nstruct xhci_virt_device *virt_dev,\r\nstruct usb_device *udev,\r\nstruct usb_host_endpoint *ep,\r\ngfp_t mem_flags)\r\n{\r\nunsigned int ep_index;\r\nstruct xhci_ep_ctx *ep_ctx;\r\nstruct xhci_ring *ep_ring;\r\nunsigned int max_packet;\r\nunsigned int max_burst;\r\nenum xhci_ring_type type;\r\nu32 max_esit_payload;\r\nu32 endpoint_type;\r\nep_index = xhci_get_endpoint_index(&ep->desc);\r\nep_ctx = xhci_get_ep_ctx(xhci, virt_dev->in_ctx, ep_index);\r\nendpoint_type = xhci_get_endpoint_type(ep);\r\nif (!endpoint_type)\r\nreturn -EINVAL;\r\nep_ctx->ep_info2 = cpu_to_le32(endpoint_type);\r\ntype = usb_endpoint_type(&ep->desc);\r\nvirt_dev->eps[ep_index].new_ring =\r\nxhci_ring_alloc(xhci, 2, 1, type, mem_flags);\r\nif (!virt_dev->eps[ep_index].new_ring) {\r\nif (virt_dev->num_rings_cached == 0)\r\nreturn -ENOMEM;\r\nvirt_dev->eps[ep_index].new_ring =\r\nvirt_dev->ring_cache[virt_dev->num_rings_cached];\r\nvirt_dev->ring_cache[virt_dev->num_rings_cached] = NULL;\r\nvirt_dev->num_rings_cached--;\r\nxhci_reinit_cached_ring(xhci, virt_dev->eps[ep_index].new_ring,\r\n1, type);\r\n}\r\nvirt_dev->eps[ep_index].skip = false;\r\nep_ring = virt_dev->eps[ep_index].new_ring;\r\nep_ctx->deq = cpu_to_le64(ep_ring->first_seg->dma | ep_ring->cycle_state);\r\nep_ctx->ep_info = cpu_to_le32(xhci_get_endpoint_interval(udev, ep)\r\n| EP_MULT(xhci_get_endpoint_mult(udev, ep)));\r\nif (!usb_endpoint_xfer_isoc(&ep->desc))\r\nep_ctx->ep_info2 |= cpu_to_le32(ERROR_COUNT(3));\r\nelse\r\nep_ctx->ep_info2 |= cpu_to_le32(ERROR_COUNT(0));\r\nmax_packet = GET_MAX_PACKET(usb_endpoint_maxp(&ep->desc));\r\nmax_burst = 0;\r\nswitch (udev->speed) {\r\ncase USB_SPEED_SUPER:\r\nmax_burst = ep->ss_ep_comp.bMaxBurst;\r\nbreak;\r\ncase USB_SPEED_HIGH:\r\nif (usb_endpoint_xfer_bulk(&ep->desc))\r\nmax_packet = 512;\r\nif (usb_endpoint_xfer_isoc(&ep->desc) ||\r\nusb_endpoint_xfer_int(&ep->desc)) {\r\nmax_burst = (usb_endpoint_maxp(&ep->desc)\r\n& 0x1800) >> 11;\r\n}\r\nbreak;\r\ncase USB_SPEED_FULL:\r\ncase USB_SPEED_LOW:\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\nep_ctx->ep_info2 |= cpu_to_le32(MAX_PACKET(max_packet) |\r\nMAX_BURST(max_burst));\r\nmax_esit_payload = xhci_get_max_esit_payload(udev, ep);\r\nep_ctx->tx_info = cpu_to_le32(MAX_ESIT_PAYLOAD_FOR_EP(max_esit_payload));\r\nif (usb_endpoint_xfer_control(&ep->desc) && xhci->hci_version == 0x100)\r\nep_ctx->tx_info |= cpu_to_le32(AVG_TRB_LENGTH_FOR_EP(8));\r\nelse\r\nep_ctx->tx_info |=\r\ncpu_to_le32(AVG_TRB_LENGTH_FOR_EP(max_esit_payload));\r\nreturn 0;\r\n}\r\nvoid xhci_endpoint_zero(struct xhci_hcd *xhci,\r\nstruct xhci_virt_device *virt_dev,\r\nstruct usb_host_endpoint *ep)\r\n{\r\nunsigned int ep_index;\r\nstruct xhci_ep_ctx *ep_ctx;\r\nep_index = xhci_get_endpoint_index(&ep->desc);\r\nep_ctx = xhci_get_ep_ctx(xhci, virt_dev->in_ctx, ep_index);\r\nep_ctx->ep_info = 0;\r\nep_ctx->ep_info2 = 0;\r\nep_ctx->deq = 0;\r\nep_ctx->tx_info = 0;\r\n}\r\nvoid xhci_clear_endpoint_bw_info(struct xhci_bw_info *bw_info)\r\n{\r\nbw_info->ep_interval = 0;\r\nbw_info->mult = 0;\r\nbw_info->num_packets = 0;\r\nbw_info->max_packet_size = 0;\r\nbw_info->type = 0;\r\nbw_info->max_esit_payload = 0;\r\n}\r\nvoid xhci_update_bw_info(struct xhci_hcd *xhci,\r\nstruct xhci_container_ctx *in_ctx,\r\nstruct xhci_input_control_ctx *ctrl_ctx,\r\nstruct xhci_virt_device *virt_dev)\r\n{\r\nstruct xhci_bw_info *bw_info;\r\nstruct xhci_ep_ctx *ep_ctx;\r\nunsigned int ep_type;\r\nint i;\r\nfor (i = 1; i < 31; ++i) {\r\nbw_info = &virt_dev->eps[i].bw_info;\r\nif (!EP_IS_ADDED(ctrl_ctx, i) && EP_IS_DROPPED(ctrl_ctx, i)) {\r\nxhci_clear_endpoint_bw_info(bw_info);\r\ncontinue;\r\n}\r\nif (EP_IS_ADDED(ctrl_ctx, i)) {\r\nep_ctx = xhci_get_ep_ctx(xhci, in_ctx, i);\r\nep_type = CTX_TO_EP_TYPE(le32_to_cpu(ep_ctx->ep_info2));\r\nif (ep_type != ISOC_OUT_EP && ep_type != INT_OUT_EP &&\r\nep_type != ISOC_IN_EP &&\r\nep_type != INT_IN_EP)\r\ncontinue;\r\nbw_info->ep_interval = CTX_TO_EP_INTERVAL(\r\nle32_to_cpu(ep_ctx->ep_info));\r\nbw_info->mult = CTX_TO_EP_MULT(\r\nle32_to_cpu(ep_ctx->ep_info)) + 1;\r\nbw_info->num_packets = CTX_TO_MAX_BURST(\r\nle32_to_cpu(ep_ctx->ep_info2)) + 1;\r\nbw_info->max_packet_size = MAX_PACKET_DECODED(\r\nle32_to_cpu(ep_ctx->ep_info2));\r\nbw_info->type = ep_type;\r\nbw_info->max_esit_payload = CTX_TO_MAX_ESIT_PAYLOAD(\r\nle32_to_cpu(ep_ctx->tx_info));\r\n}\r\n}\r\n}\r\nvoid xhci_endpoint_copy(struct xhci_hcd *xhci,\r\nstruct xhci_container_ctx *in_ctx,\r\nstruct xhci_container_ctx *out_ctx,\r\nunsigned int ep_index)\r\n{\r\nstruct xhci_ep_ctx *out_ep_ctx;\r\nstruct xhci_ep_ctx *in_ep_ctx;\r\nout_ep_ctx = xhci_get_ep_ctx(xhci, out_ctx, ep_index);\r\nin_ep_ctx = xhci_get_ep_ctx(xhci, in_ctx, ep_index);\r\nin_ep_ctx->ep_info = out_ep_ctx->ep_info;\r\nin_ep_ctx->ep_info2 = out_ep_ctx->ep_info2;\r\nin_ep_ctx->deq = out_ep_ctx->deq;\r\nin_ep_ctx->tx_info = out_ep_ctx->tx_info;\r\n}\r\nvoid xhci_slot_copy(struct xhci_hcd *xhci,\r\nstruct xhci_container_ctx *in_ctx,\r\nstruct xhci_container_ctx *out_ctx)\r\n{\r\nstruct xhci_slot_ctx *in_slot_ctx;\r\nstruct xhci_slot_ctx *out_slot_ctx;\r\nin_slot_ctx = xhci_get_slot_ctx(xhci, in_ctx);\r\nout_slot_ctx = xhci_get_slot_ctx(xhci, out_ctx);\r\nin_slot_ctx->dev_info = out_slot_ctx->dev_info;\r\nin_slot_ctx->dev_info2 = out_slot_ctx->dev_info2;\r\nin_slot_ctx->tt_info = out_slot_ctx->tt_info;\r\nin_slot_ctx->dev_state = out_slot_ctx->dev_state;\r\n}\r\nstatic int scratchpad_alloc(struct xhci_hcd *xhci, gfp_t flags)\r\n{\r\nint i;\r\nstruct device *dev = xhci_to_hcd(xhci)->self.controller;\r\nint num_sp = HCS_MAX_SCRATCHPAD(xhci->hcs_params2);\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"Allocating %d scratchpad buffers", num_sp);\r\nif (!num_sp)\r\nreturn 0;\r\nxhci->scratchpad = kzalloc(sizeof(*xhci->scratchpad), flags);\r\nif (!xhci->scratchpad)\r\ngoto fail_sp;\r\nxhci->scratchpad->sp_array = dma_alloc_coherent(dev,\r\nnum_sp * sizeof(u64),\r\n&xhci->scratchpad->sp_dma, flags);\r\nif (!xhci->scratchpad->sp_array)\r\ngoto fail_sp2;\r\nxhci->scratchpad->sp_buffers = kzalloc(sizeof(void *) * num_sp, flags);\r\nif (!xhci->scratchpad->sp_buffers)\r\ngoto fail_sp3;\r\nxhci->scratchpad->sp_dma_buffers =\r\nkzalloc(sizeof(dma_addr_t) * num_sp, flags);\r\nif (!xhci->scratchpad->sp_dma_buffers)\r\ngoto fail_sp4;\r\nxhci->dcbaa->dev_context_ptrs[0] = cpu_to_le64(xhci->scratchpad->sp_dma);\r\nfor (i = 0; i < num_sp; i++) {\r\ndma_addr_t dma;\r\nvoid *buf = dma_alloc_coherent(dev, xhci->page_size, &dma,\r\nflags);\r\nif (!buf)\r\ngoto fail_sp5;\r\nxhci->scratchpad->sp_array[i] = dma;\r\nxhci->scratchpad->sp_buffers[i] = buf;\r\nxhci->scratchpad->sp_dma_buffers[i] = dma;\r\n}\r\nreturn 0;\r\nfail_sp5:\r\nfor (i = i - 1; i >= 0; i--) {\r\ndma_free_coherent(dev, xhci->page_size,\r\nxhci->scratchpad->sp_buffers[i],\r\nxhci->scratchpad->sp_dma_buffers[i]);\r\n}\r\nkfree(xhci->scratchpad->sp_dma_buffers);\r\nfail_sp4:\r\nkfree(xhci->scratchpad->sp_buffers);\r\nfail_sp3:\r\ndma_free_coherent(dev, num_sp * sizeof(u64),\r\nxhci->scratchpad->sp_array,\r\nxhci->scratchpad->sp_dma);\r\nfail_sp2:\r\nkfree(xhci->scratchpad);\r\nxhci->scratchpad = NULL;\r\nfail_sp:\r\nreturn -ENOMEM;\r\n}\r\nstatic void scratchpad_free(struct xhci_hcd *xhci)\r\n{\r\nint num_sp;\r\nint i;\r\nstruct device *dev = xhci_to_hcd(xhci)->self.controller;\r\nif (!xhci->scratchpad)\r\nreturn;\r\nnum_sp = HCS_MAX_SCRATCHPAD(xhci->hcs_params2);\r\nfor (i = 0; i < num_sp; i++) {\r\ndma_free_coherent(dev, xhci->page_size,\r\nxhci->scratchpad->sp_buffers[i],\r\nxhci->scratchpad->sp_dma_buffers[i]);\r\n}\r\nkfree(xhci->scratchpad->sp_dma_buffers);\r\nkfree(xhci->scratchpad->sp_buffers);\r\ndma_free_coherent(dev, num_sp * sizeof(u64),\r\nxhci->scratchpad->sp_array,\r\nxhci->scratchpad->sp_dma);\r\nkfree(xhci->scratchpad);\r\nxhci->scratchpad = NULL;\r\n}\r\nstruct xhci_command *xhci_alloc_command(struct xhci_hcd *xhci,\r\nbool allocate_in_ctx, bool allocate_completion,\r\ngfp_t mem_flags)\r\n{\r\nstruct xhci_command *command;\r\ncommand = kzalloc(sizeof(*command), mem_flags);\r\nif (!command)\r\nreturn NULL;\r\nif (allocate_in_ctx) {\r\ncommand->in_ctx =\r\nxhci_alloc_container_ctx(xhci, XHCI_CTX_TYPE_INPUT,\r\nmem_flags);\r\nif (!command->in_ctx) {\r\nkfree(command);\r\nreturn NULL;\r\n}\r\n}\r\nif (allocate_completion) {\r\ncommand->completion =\r\nkzalloc(sizeof(struct completion), mem_flags);\r\nif (!command->completion) {\r\nxhci_free_container_ctx(xhci, command->in_ctx);\r\nkfree(command);\r\nreturn NULL;\r\n}\r\ninit_completion(command->completion);\r\n}\r\ncommand->status = 0;\r\nINIT_LIST_HEAD(&command->cmd_list);\r\nreturn command;\r\n}\r\nvoid xhci_urb_free_priv(struct urb_priv *urb_priv)\r\n{\r\nif (urb_priv) {\r\nkfree(urb_priv->td[0]);\r\nkfree(urb_priv);\r\n}\r\n}\r\nvoid xhci_free_command(struct xhci_hcd *xhci,\r\nstruct xhci_command *command)\r\n{\r\nxhci_free_container_ctx(xhci,\r\ncommand->in_ctx);\r\nkfree(command->completion);\r\nkfree(command);\r\n}\r\nvoid xhci_mem_cleanup(struct xhci_hcd *xhci)\r\n{\r\nstruct device *dev = xhci_to_hcd(xhci)->self.controller;\r\nint size;\r\nint i, j, num_ports;\r\ndel_timer_sync(&xhci->cmd_timer);\r\nsize = sizeof(struct xhci_erst_entry)*(xhci->erst.num_entries);\r\nif (xhci->erst.entries)\r\ndma_free_coherent(dev, size,\r\nxhci->erst.entries, xhci->erst.erst_dma_addr);\r\nxhci->erst.entries = NULL;\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init, "Freed ERST");\r\nif (xhci->event_ring)\r\nxhci_ring_free(xhci, xhci->event_ring);\r\nxhci->event_ring = NULL;\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init, "Freed event ring");\r\nif (xhci->lpm_command)\r\nxhci_free_command(xhci, xhci->lpm_command);\r\nxhci->lpm_command = NULL;\r\nif (xhci->cmd_ring)\r\nxhci_ring_free(xhci, xhci->cmd_ring);\r\nxhci->cmd_ring = NULL;\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init, "Freed command ring");\r\nxhci_cleanup_command_queue(xhci);\r\nnum_ports = HCS_MAX_PORTS(xhci->hcs_params1);\r\nfor (i = 0; i < num_ports && xhci->rh_bw; i++) {\r\nstruct xhci_interval_bw_table *bwt = &xhci->rh_bw[i].bw_table;\r\nfor (j = 0; j < XHCI_MAX_INTERVAL; j++) {\r\nstruct list_head *ep = &bwt->interval_bw[j].endpoints;\r\nwhile (!list_empty(ep))\r\nlist_del_init(ep->next);\r\n}\r\n}\r\nfor (i = 1; i < MAX_HC_SLOTS; ++i)\r\nxhci_free_virt_device(xhci, i);\r\nif (xhci->segment_pool)\r\ndma_pool_destroy(xhci->segment_pool);\r\nxhci->segment_pool = NULL;\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init, "Freed segment pool");\r\nif (xhci->device_pool)\r\ndma_pool_destroy(xhci->device_pool);\r\nxhci->device_pool = NULL;\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init, "Freed device context pool");\r\nif (xhci->small_streams_pool)\r\ndma_pool_destroy(xhci->small_streams_pool);\r\nxhci->small_streams_pool = NULL;\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"Freed small stream array pool");\r\nif (xhci->medium_streams_pool)\r\ndma_pool_destroy(xhci->medium_streams_pool);\r\nxhci->medium_streams_pool = NULL;\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"Freed medium stream array pool");\r\nif (xhci->dcbaa)\r\ndma_free_coherent(dev, sizeof(*xhci->dcbaa),\r\nxhci->dcbaa, xhci->dcbaa->dma);\r\nxhci->dcbaa = NULL;\r\nscratchpad_free(xhci);\r\nif (!xhci->rh_bw)\r\ngoto no_bw;\r\nfor (i = 0; i < num_ports; i++) {\r\nstruct xhci_tt_bw_info *tt, *n;\r\nlist_for_each_entry_safe(tt, n, &xhci->rh_bw[i].tts, tt_list) {\r\nlist_del(&tt->tt_list);\r\nkfree(tt);\r\n}\r\n}\r\nno_bw:\r\nxhci->cmd_ring_reserved_trbs = 0;\r\nxhci->num_usb2_ports = 0;\r\nxhci->num_usb3_ports = 0;\r\nxhci->num_active_eps = 0;\r\nkfree(xhci->usb2_ports);\r\nkfree(xhci->usb3_ports);\r\nkfree(xhci->port_array);\r\nkfree(xhci->rh_bw);\r\nkfree(xhci->ext_caps);\r\nxhci->page_size = 0;\r\nxhci->page_shift = 0;\r\nxhci->bus_state[0].bus_suspended = 0;\r\nxhci->bus_state[1].bus_suspended = 0;\r\n}\r\nstatic int xhci_test_trb_in_td(struct xhci_hcd *xhci,\r\nstruct xhci_segment *input_seg,\r\nunion xhci_trb *start_trb,\r\nunion xhci_trb *end_trb,\r\ndma_addr_t input_dma,\r\nstruct xhci_segment *result_seg,\r\nchar *test_name, int test_number)\r\n{\r\nunsigned long long start_dma;\r\nunsigned long long end_dma;\r\nstruct xhci_segment *seg;\r\nstart_dma = xhci_trb_virt_to_dma(input_seg, start_trb);\r\nend_dma = xhci_trb_virt_to_dma(input_seg, end_trb);\r\nseg = trb_in_td(xhci, input_seg, start_trb, end_trb, input_dma, false);\r\nif (seg != result_seg) {\r\nxhci_warn(xhci, "WARN: %s TRB math test %d failed!\n",\r\ntest_name, test_number);\r\nxhci_warn(xhci, "Tested TRB math w/ seg %p and "\r\n"input DMA 0x%llx\n",\r\ninput_seg,\r\n(unsigned long long) input_dma);\r\nxhci_warn(xhci, "starting TRB %p (0x%llx DMA), "\r\n"ending TRB %p (0x%llx DMA)\n",\r\nstart_trb, start_dma,\r\nend_trb, end_dma);\r\nxhci_warn(xhci, "Expected seg %p, got seg %p\n",\r\nresult_seg, seg);\r\ntrb_in_td(xhci, input_seg, start_trb, end_trb, input_dma,\r\ntrue);\r\nreturn -1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int xhci_check_trb_in_td_math(struct xhci_hcd *xhci)\r\n{\r\nstruct {\r\ndma_addr_t input_dma;\r\nstruct xhci_segment *result_seg;\r\n} simple_test_vector [] = {\r\n{ 0, NULL },\r\n{ xhci->event_ring->first_seg->dma - 16, NULL },\r\n{ xhci->event_ring->first_seg->dma - 1, NULL },\r\n{ xhci->event_ring->first_seg->dma, xhci->event_ring->first_seg },\r\n{ xhci->event_ring->first_seg->dma + (TRBS_PER_SEGMENT - 1)*16,\r\nxhci->event_ring->first_seg },\r\n{ xhci->event_ring->first_seg->dma + (TRBS_PER_SEGMENT - 1)*16 + 1, NULL },\r\n{ xhci->event_ring->first_seg->dma + (TRBS_PER_SEGMENT)*16, NULL },\r\n{ (dma_addr_t) (~0), NULL },\r\n};\r\nstruct {\r\nstruct xhci_segment *input_seg;\r\nunion xhci_trb *start_trb;\r\nunion xhci_trb *end_trb;\r\ndma_addr_t input_dma;\r\nstruct xhci_segment *result_seg;\r\n} complex_test_vector [] = {\r\n{ .input_seg = xhci->event_ring->first_seg,\r\n.start_trb = xhci->event_ring->first_seg->trbs,\r\n.end_trb = &xhci->event_ring->first_seg->trbs[TRBS_PER_SEGMENT - 1],\r\n.input_dma = xhci->cmd_ring->first_seg->dma,\r\n.result_seg = NULL,\r\n},\r\n{ .input_seg = xhci->event_ring->first_seg,\r\n.start_trb = xhci->event_ring->first_seg->trbs,\r\n.end_trb = &xhci->cmd_ring->first_seg->trbs[TRBS_PER_SEGMENT - 1],\r\n.input_dma = xhci->cmd_ring->first_seg->dma,\r\n.result_seg = NULL,\r\n},\r\n{ .input_seg = xhci->event_ring->first_seg,\r\n.start_trb = xhci->cmd_ring->first_seg->trbs,\r\n.end_trb = &xhci->cmd_ring->first_seg->trbs[TRBS_PER_SEGMENT - 1],\r\n.input_dma = xhci->cmd_ring->first_seg->dma,\r\n.result_seg = NULL,\r\n},\r\n{ .input_seg = xhci->event_ring->first_seg,\r\n.start_trb = &xhci->event_ring->first_seg->trbs[0],\r\n.end_trb = &xhci->event_ring->first_seg->trbs[3],\r\n.input_dma = xhci->event_ring->first_seg->dma + 4*16,\r\n.result_seg = NULL,\r\n},\r\n{ .input_seg = xhci->event_ring->first_seg,\r\n.start_trb = &xhci->event_ring->first_seg->trbs[3],\r\n.end_trb = &xhci->event_ring->first_seg->trbs[6],\r\n.input_dma = xhci->event_ring->first_seg->dma + 2*16,\r\n.result_seg = NULL,\r\n},\r\n{ .input_seg = xhci->event_ring->first_seg,\r\n.start_trb = &xhci->event_ring->first_seg->trbs[TRBS_PER_SEGMENT - 3],\r\n.end_trb = &xhci->event_ring->first_seg->trbs[1],\r\n.input_dma = xhci->event_ring->first_seg->dma + 2*16,\r\n.result_seg = NULL,\r\n},\r\n{ .input_seg = xhci->event_ring->first_seg,\r\n.start_trb = &xhci->event_ring->first_seg->trbs[TRBS_PER_SEGMENT - 3],\r\n.end_trb = &xhci->event_ring->first_seg->trbs[1],\r\n.input_dma = xhci->event_ring->first_seg->dma + (TRBS_PER_SEGMENT - 4)*16,\r\n.result_seg = NULL,\r\n},\r\n{ .input_seg = xhci->event_ring->first_seg,\r\n.start_trb = &xhci->event_ring->first_seg->trbs[TRBS_PER_SEGMENT - 3],\r\n.end_trb = &xhci->event_ring->first_seg->trbs[1],\r\n.input_dma = xhci->cmd_ring->first_seg->dma + 2*16,\r\n.result_seg = NULL,\r\n},\r\n};\r\nunsigned int num_tests;\r\nint i, ret;\r\nnum_tests = ARRAY_SIZE(simple_test_vector);\r\nfor (i = 0; i < num_tests; i++) {\r\nret = xhci_test_trb_in_td(xhci,\r\nxhci->event_ring->first_seg,\r\nxhci->event_ring->first_seg->trbs,\r\n&xhci->event_ring->first_seg->trbs[TRBS_PER_SEGMENT - 1],\r\nsimple_test_vector[i].input_dma,\r\nsimple_test_vector[i].result_seg,\r\n"Simple", i);\r\nif (ret < 0)\r\nreturn ret;\r\n}\r\nnum_tests = ARRAY_SIZE(complex_test_vector);\r\nfor (i = 0; i < num_tests; i++) {\r\nret = xhci_test_trb_in_td(xhci,\r\ncomplex_test_vector[i].input_seg,\r\ncomplex_test_vector[i].start_trb,\r\ncomplex_test_vector[i].end_trb,\r\ncomplex_test_vector[i].input_dma,\r\ncomplex_test_vector[i].result_seg,\r\n"Complex", i);\r\nif (ret < 0)\r\nreturn ret;\r\n}\r\nxhci_dbg(xhci, "TRB math tests passed.\n");\r\nreturn 0;\r\n}\r\nstatic void xhci_set_hc_event_deq(struct xhci_hcd *xhci)\r\n{\r\nu64 temp;\r\ndma_addr_t deq;\r\ndeq = xhci_trb_virt_to_dma(xhci->event_ring->deq_seg,\r\nxhci->event_ring->dequeue);\r\nif (deq == 0 && !in_interrupt())\r\nxhci_warn(xhci, "WARN something wrong with SW event ring "\r\n"dequeue ptr.\n");\r\ntemp = xhci_read_64(xhci, &xhci->ir_set->erst_dequeue);\r\ntemp &= ERST_PTR_MASK;\r\ntemp &= ~ERST_EHB;\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"// Write event ring dequeue pointer, "\r\n"preserving EHB bit");\r\nxhci_write_64(xhci, ((u64) deq & (u64) ~ERST_PTR_MASK) | temp,\r\n&xhci->ir_set->erst_dequeue);\r\n}\r\nstatic void xhci_add_in_port(struct xhci_hcd *xhci, unsigned int num_ports,\r\n__le32 __iomem *addr, u8 major_revision, int max_caps)\r\n{\r\nu32 temp, port_offset, port_count;\r\nint i;\r\nif (major_revision > 0x03) {\r\nxhci_warn(xhci, "Ignoring unknown port speed, "\r\n"Ext Cap %p, revision = 0x%x\n",\r\naddr, major_revision);\r\nreturn;\r\n}\r\ntemp = readl(addr + 2);\r\nport_offset = XHCI_EXT_PORT_OFF(temp);\r\nport_count = XHCI_EXT_PORT_COUNT(temp);\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"Ext Cap %p, port offset = %u, "\r\n"count = %u, revision = 0x%x",\r\naddr, port_offset, port_count, major_revision);\r\nif (port_offset == 0 || (port_offset + port_count - 1) > num_ports)\r\nreturn;\r\nif (major_revision < 0x03 && xhci->num_ext_caps < max_caps)\r\nxhci->ext_caps[xhci->num_ext_caps++] = temp;\r\nif ((xhci->hci_version == 0x96) && (major_revision != 0x03) &&\r\n(temp & XHCI_L1C)) {\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"xHCI 0.96: support USB2 software lpm");\r\nxhci->sw_lpm_support = 1;\r\n}\r\nif ((xhci->hci_version >= 0x100) && (major_revision != 0x03)) {\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"xHCI 1.0: support USB2 software lpm");\r\nxhci->sw_lpm_support = 1;\r\nif (temp & XHCI_HLC) {\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"xHCI 1.0: support USB2 hardware lpm");\r\nxhci->hw_lpm_support = 1;\r\n}\r\n}\r\nport_offset--;\r\nfor (i = port_offset; i < (port_offset + port_count); i++) {\r\nif (xhci->port_array[i] != 0) {\r\nxhci_warn(xhci, "Duplicate port entry, Ext Cap %p,"\r\n" port %u\n", addr, i);\r\nxhci_warn(xhci, "Port was marked as USB %u, "\r\n"duplicated as USB %u\n",\r\nxhci->port_array[i], major_revision);\r\nif (xhci->port_array[i] != major_revision &&\r\nxhci->port_array[i] != DUPLICATE_ENTRY) {\r\nif (xhci->port_array[i] == 0x03)\r\nxhci->num_usb3_ports--;\r\nelse\r\nxhci->num_usb2_ports--;\r\nxhci->port_array[i] = DUPLICATE_ENTRY;\r\n}\r\ncontinue;\r\n}\r\nxhci->port_array[i] = major_revision;\r\nif (major_revision == 0x03)\r\nxhci->num_usb3_ports++;\r\nelse\r\nxhci->num_usb2_ports++;\r\n}\r\n}\r\nstatic int xhci_setup_port_arrays(struct xhci_hcd *xhci, gfp_t flags)\r\n{\r\n__le32 __iomem *addr, *tmp_addr;\r\nu32 offset, tmp_offset;\r\nunsigned int num_ports;\r\nint i, j, port_index;\r\nint cap_count = 0;\r\naddr = &xhci->cap_regs->hcc_params;\r\noffset = XHCI_HCC_EXT_CAPS(readl(addr));\r\nif (offset == 0) {\r\nxhci_err(xhci, "No Extended Capability registers, "\r\n"unable to set up roothub.\n");\r\nreturn -ENODEV;\r\n}\r\nnum_ports = HCS_MAX_PORTS(xhci->hcs_params1);\r\nxhci->port_array = kzalloc(sizeof(*xhci->port_array)*num_ports, flags);\r\nif (!xhci->port_array)\r\nreturn -ENOMEM;\r\nxhci->rh_bw = kzalloc(sizeof(*xhci->rh_bw)*num_ports, flags);\r\nif (!xhci->rh_bw)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < num_ports; i++) {\r\nstruct xhci_interval_bw_table *bw_table;\r\nINIT_LIST_HEAD(&xhci->rh_bw[i].tts);\r\nbw_table = &xhci->rh_bw[i].bw_table;\r\nfor (j = 0; j < XHCI_MAX_INTERVAL; j++)\r\nINIT_LIST_HEAD(&bw_table->interval_bw[j].endpoints);\r\n}\r\naddr = &xhci->cap_regs->hc_capbase + offset;\r\ntmp_addr = addr;\r\ntmp_offset = offset;\r\ndo {\r\nu32 cap_id;\r\ncap_id = readl(tmp_addr);\r\nif (XHCI_EXT_CAPS_ID(cap_id) == XHCI_EXT_CAPS_PROTOCOL)\r\ncap_count++;\r\ntmp_offset = XHCI_EXT_CAPS_NEXT(cap_id);\r\ntmp_addr += tmp_offset;\r\n} while (tmp_offset);\r\nxhci->ext_caps = kzalloc(sizeof(*xhci->ext_caps) * cap_count, flags);\r\nif (!xhci->ext_caps)\r\nreturn -ENOMEM;\r\nwhile (1) {\r\nu32 cap_id;\r\ncap_id = readl(addr);\r\nif (XHCI_EXT_CAPS_ID(cap_id) == XHCI_EXT_CAPS_PROTOCOL)\r\nxhci_add_in_port(xhci, num_ports, addr,\r\n(u8) XHCI_EXT_PORT_MAJOR(cap_id),\r\ncap_count);\r\noffset = XHCI_EXT_CAPS_NEXT(cap_id);\r\nif (!offset || (xhci->num_usb2_ports + xhci->num_usb3_ports)\r\n== num_ports)\r\nbreak;\r\naddr += offset;\r\n}\r\nif (xhci->num_usb2_ports == 0 && xhci->num_usb3_ports == 0) {\r\nxhci_warn(xhci, "No ports on the roothubs?\n");\r\nreturn -ENODEV;\r\n}\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"Found %u USB 2.0 ports and %u USB 3.0 ports.",\r\nxhci->num_usb2_ports, xhci->num_usb3_ports);\r\nif (xhci->num_usb3_ports > 15) {\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"Limiting USB 3.0 roothub ports to 15.");\r\nxhci->num_usb3_ports = 15;\r\n}\r\nif (xhci->num_usb2_ports > USB_MAXCHILDREN) {\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"Limiting USB 2.0 roothub ports to %u.",\r\nUSB_MAXCHILDREN);\r\nxhci->num_usb2_ports = USB_MAXCHILDREN;\r\n}\r\nif (xhci->num_usb2_ports) {\r\nxhci->usb2_ports = kmalloc(sizeof(*xhci->usb2_ports)*\r\nxhci->num_usb2_ports, flags);\r\nif (!xhci->usb2_ports)\r\nreturn -ENOMEM;\r\nport_index = 0;\r\nfor (i = 0; i < num_ports; i++) {\r\nif (xhci->port_array[i] == 0x03 ||\r\nxhci->port_array[i] == 0 ||\r\nxhci->port_array[i] == DUPLICATE_ENTRY)\r\ncontinue;\r\nxhci->usb2_ports[port_index] =\r\n&xhci->op_regs->port_status_base +\r\nNUM_PORT_REGS*i;\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"USB 2.0 port at index %u, "\r\n"addr = %p", i,\r\nxhci->usb2_ports[port_index]);\r\nport_index++;\r\nif (port_index == xhci->num_usb2_ports)\r\nbreak;\r\n}\r\n}\r\nif (xhci->num_usb3_ports) {\r\nxhci->usb3_ports = kmalloc(sizeof(*xhci->usb3_ports)*\r\nxhci->num_usb3_ports, flags);\r\nif (!xhci->usb3_ports)\r\nreturn -ENOMEM;\r\nport_index = 0;\r\nfor (i = 0; i < num_ports; i++)\r\nif (xhci->port_array[i] == 0x03) {\r\nxhci->usb3_ports[port_index] =\r\n&xhci->op_regs->port_status_base +\r\nNUM_PORT_REGS*i;\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"USB 3.0 port at index %u, "\r\n"addr = %p", i,\r\nxhci->usb3_ports[port_index]);\r\nport_index++;\r\nif (port_index == xhci->num_usb3_ports)\r\nbreak;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nint xhci_mem_init(struct xhci_hcd *xhci, gfp_t flags)\r\n{\r\ndma_addr_t dma;\r\nstruct device *dev = xhci_to_hcd(xhci)->self.controller;\r\nunsigned int val, val2;\r\nu64 val_64;\r\nstruct xhci_segment *seg;\r\nu32 page_size, temp;\r\nint i;\r\nINIT_LIST_HEAD(&xhci->cmd_list);\r\npage_size = readl(&xhci->op_regs->page_size);\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"Supported page size register = 0x%x", page_size);\r\nfor (i = 0; i < 16; i++) {\r\nif ((0x1 & page_size) != 0)\r\nbreak;\r\npage_size = page_size >> 1;\r\n}\r\nif (i < 16)\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"Supported page size of %iK", (1 << (i+12)) / 1024);\r\nelse\r\nxhci_warn(xhci, "WARN: no supported page size\n");\r\nxhci->page_shift = 12;\r\nxhci->page_size = 1 << xhci->page_shift;\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"HCD page size set to %iK", xhci->page_size / 1024);\r\nval = HCS_MAX_SLOTS(readl(&xhci->cap_regs->hcs_params1));\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"// xHC can handle at most %d device slots.", val);\r\nval2 = readl(&xhci->op_regs->config_reg);\r\nval |= (val2 & ~HCS_SLOTS_MASK);\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"// Setting Max device slots reg = 0x%x.", val);\r\nwritel(val, &xhci->op_regs->config_reg);\r\nxhci->dcbaa = dma_alloc_coherent(dev, sizeof(*xhci->dcbaa), &dma,\r\nGFP_KERNEL);\r\nif (!xhci->dcbaa)\r\ngoto fail;\r\nmemset(xhci->dcbaa, 0, sizeof *(xhci->dcbaa));\r\nxhci->dcbaa->dma = dma;\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"// Device context base array address = 0x%llx (DMA), %p (virt)",\r\n(unsigned long long)xhci->dcbaa->dma, xhci->dcbaa);\r\nxhci_write_64(xhci, dma, &xhci->op_regs->dcbaa_ptr);\r\nxhci->segment_pool = dma_pool_create("xHCI ring segments", dev,\r\nTRB_SEGMENT_SIZE, TRB_SEGMENT_SIZE, xhci->page_size);\r\nxhci->device_pool = dma_pool_create("xHCI input/output contexts", dev,\r\n2112, 64, xhci->page_size);\r\nif (!xhci->segment_pool || !xhci->device_pool)\r\ngoto fail;\r\nxhci->small_streams_pool =\r\ndma_pool_create("xHCI 256 byte stream ctx arrays",\r\ndev, SMALL_STREAM_ARRAY_SIZE, 16, 0);\r\nxhci->medium_streams_pool =\r\ndma_pool_create("xHCI 1KB stream ctx arrays",\r\ndev, MEDIUM_STREAM_ARRAY_SIZE, 16, 0);\r\nif (!xhci->small_streams_pool || !xhci->medium_streams_pool)\r\ngoto fail;\r\nxhci->cmd_ring = xhci_ring_alloc(xhci, 1, 1, TYPE_COMMAND, flags);\r\nif (!xhci->cmd_ring)\r\ngoto fail;\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"Allocated command ring at %p", xhci->cmd_ring);\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init, "First segment DMA is 0x%llx",\r\n(unsigned long long)xhci->cmd_ring->first_seg->dma);\r\nval_64 = xhci_read_64(xhci, &xhci->op_regs->cmd_ring);\r\nval_64 = (val_64 & (u64) CMD_RING_RSVD_BITS) |\r\n(xhci->cmd_ring->first_seg->dma & (u64) ~CMD_RING_RSVD_BITS) |\r\nxhci->cmd_ring->cycle_state;\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"// Setting command ring address to 0x%x", val);\r\nxhci_write_64(xhci, val_64, &xhci->op_regs->cmd_ring);\r\nxhci_dbg_cmd_ptrs(xhci);\r\nxhci->lpm_command = xhci_alloc_command(xhci, true, true, flags);\r\nif (!xhci->lpm_command)\r\ngoto fail;\r\nxhci->cmd_ring_reserved_trbs++;\r\nval = readl(&xhci->cap_regs->db_off);\r\nval &= DBOFF_MASK;\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"// Doorbell array is located at offset 0x%x"\r\n" from cap regs base addr", val);\r\nxhci->dba = (void __iomem *) xhci->cap_regs + val;\r\nxhci_dbg_regs(xhci);\r\nxhci_print_run_regs(xhci);\r\nxhci->ir_set = &xhci->run_regs->ir_set[0];\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init, "// Allocating event ring");\r\nxhci->event_ring = xhci_ring_alloc(xhci, ERST_NUM_SEGS, 1, TYPE_EVENT,\r\nflags);\r\nif (!xhci->event_ring)\r\ngoto fail;\r\nif (xhci_check_trb_in_td_math(xhci) < 0)\r\ngoto fail;\r\nxhci->erst.entries = dma_alloc_coherent(dev,\r\nsizeof(struct xhci_erst_entry) * ERST_NUM_SEGS, &dma,\r\nGFP_KERNEL);\r\nif (!xhci->erst.entries)\r\ngoto fail;\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"// Allocated event ring segment table at 0x%llx",\r\n(unsigned long long)dma);\r\nmemset(xhci->erst.entries, 0, sizeof(struct xhci_erst_entry)*ERST_NUM_SEGS);\r\nxhci->erst.num_entries = ERST_NUM_SEGS;\r\nxhci->erst.erst_dma_addr = dma;\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"Set ERST to 0; private num segs = %i, virt addr = %p, dma addr = 0x%llx",\r\nxhci->erst.num_entries,\r\nxhci->erst.entries,\r\n(unsigned long long)xhci->erst.erst_dma_addr);\r\nfor (val = 0, seg = xhci->event_ring->first_seg; val < ERST_NUM_SEGS; val++) {\r\nstruct xhci_erst_entry *entry = &xhci->erst.entries[val];\r\nentry->seg_addr = cpu_to_le64(seg->dma);\r\nentry->seg_size = cpu_to_le32(TRBS_PER_SEGMENT);\r\nentry->rsvd = 0;\r\nseg = seg->next;\r\n}\r\nval = readl(&xhci->ir_set->erst_size);\r\nval &= ERST_SIZE_MASK;\r\nval |= ERST_NUM_SEGS;\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"// Write ERST size = %i to ir_set 0 (some bits preserved)",\r\nval);\r\nwritel(val, &xhci->ir_set->erst_size);\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"// Set ERST entries to point to event ring.");\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"// Set ERST base address for ir_set 0 = 0x%llx",\r\n(unsigned long long)xhci->erst.erst_dma_addr);\r\nval_64 = xhci_read_64(xhci, &xhci->ir_set->erst_base);\r\nval_64 &= ERST_PTR_MASK;\r\nval_64 |= (xhci->erst.erst_dma_addr & (u64) ~ERST_PTR_MASK);\r\nxhci_write_64(xhci, val_64, &xhci->ir_set->erst_base);\r\nxhci_set_hc_event_deq(xhci);\r\nxhci_dbg_trace(xhci, trace_xhci_dbg_init,\r\n"Wrote ERST address to ir_set 0.");\r\nxhci_print_ir_set(xhci, 0);\r\nsetup_timer(&xhci->cmd_timer, xhci_handle_command_timeout,\r\n(unsigned long)xhci);\r\ninit_completion(&xhci->addr_dev);\r\nfor (i = 0; i < MAX_HC_SLOTS; ++i)\r\nxhci->devs[i] = NULL;\r\nfor (i = 0; i < USB_MAXCHILDREN; ++i) {\r\nxhci->bus_state[0].resume_done[i] = 0;\r\nxhci->bus_state[1].resume_done[i] = 0;\r\ninit_completion(&xhci->bus_state[1].rexit_done[i]);\r\n}\r\nif (scratchpad_alloc(xhci, flags))\r\ngoto fail;\r\nif (xhci_setup_port_arrays(xhci, flags))\r\ngoto fail;\r\ntemp = readl(&xhci->op_regs->dev_notification);\r\ntemp &= ~DEV_NOTE_MASK;\r\ntemp |= DEV_NOTE_FWAKE;\r\nwritel(temp, &xhci->op_regs->dev_notification);\r\nreturn 0;\r\nfail:\r\nxhci_warn(xhci, "Couldn't initialize memory\n");\r\nxhci_halt(xhci);\r\nxhci_reset(xhci);\r\nxhci_mem_cleanup(xhci);\r\nreturn -ENOMEM;\r\n}
