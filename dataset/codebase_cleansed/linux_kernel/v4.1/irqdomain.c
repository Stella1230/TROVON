struct irq_domain *__irq_domain_add(struct device_node *of_node, int size,\r\nirq_hw_number_t hwirq_max, int direct_max,\r\nconst struct irq_domain_ops *ops,\r\nvoid *host_data)\r\n{\r\nstruct irq_domain *domain;\r\ndomain = kzalloc_node(sizeof(*domain) + (sizeof(unsigned int) * size),\r\nGFP_KERNEL, of_node_to_nid(of_node));\r\nif (WARN_ON(!domain))\r\nreturn NULL;\r\nINIT_RADIX_TREE(&domain->revmap_tree, GFP_KERNEL);\r\ndomain->ops = ops;\r\ndomain->host_data = host_data;\r\ndomain->of_node = of_node_get(of_node);\r\ndomain->hwirq_max = hwirq_max;\r\ndomain->revmap_size = size;\r\ndomain->revmap_direct_max_irq = direct_max;\r\nirq_domain_check_hierarchy(domain);\r\nmutex_lock(&irq_domain_mutex);\r\nlist_add(&domain->link, &irq_domain_list);\r\nmutex_unlock(&irq_domain_mutex);\r\npr_debug("Added domain %s\n", domain->name);\r\nreturn domain;\r\n}\r\nvoid irq_domain_remove(struct irq_domain *domain)\r\n{\r\nmutex_lock(&irq_domain_mutex);\r\nWARN_ON(domain->revmap_tree.height);\r\nlist_del(&domain->link);\r\nif (unlikely(irq_default_domain == domain))\r\nirq_set_default_host(NULL);\r\nmutex_unlock(&irq_domain_mutex);\r\npr_debug("Removed domain %s\n", domain->name);\r\nof_node_put(domain->of_node);\r\nkfree(domain);\r\n}\r\nstruct irq_domain *irq_domain_add_simple(struct device_node *of_node,\r\nunsigned int size,\r\nunsigned int first_irq,\r\nconst struct irq_domain_ops *ops,\r\nvoid *host_data)\r\n{\r\nstruct irq_domain *domain;\r\ndomain = __irq_domain_add(of_node, size, size, 0, ops, host_data);\r\nif (!domain)\r\nreturn NULL;\r\nif (first_irq > 0) {\r\nif (IS_ENABLED(CONFIG_SPARSE_IRQ)) {\r\nint rc = irq_alloc_descs(first_irq, first_irq, size,\r\nof_node_to_nid(of_node));\r\nif (rc < 0)\r\npr_info("Cannot allocate irq_descs @ IRQ%d, assuming pre-allocated\n",\r\nfirst_irq);\r\n}\r\nirq_domain_associate_many(domain, first_irq, 0, size);\r\n}\r\nreturn domain;\r\n}\r\nstruct irq_domain *irq_domain_add_legacy(struct device_node *of_node,\r\nunsigned int size,\r\nunsigned int first_irq,\r\nirq_hw_number_t first_hwirq,\r\nconst struct irq_domain_ops *ops,\r\nvoid *host_data)\r\n{\r\nstruct irq_domain *domain;\r\ndomain = __irq_domain_add(of_node, first_hwirq + size,\r\nfirst_hwirq + size, 0, ops, host_data);\r\nif (domain)\r\nirq_domain_associate_many(domain, first_irq, first_hwirq, size);\r\nreturn domain;\r\n}\r\nstruct irq_domain *irq_find_host(struct device_node *node)\r\n{\r\nstruct irq_domain *h, *found = NULL;\r\nint rc;\r\nmutex_lock(&irq_domain_mutex);\r\nlist_for_each_entry(h, &irq_domain_list, link) {\r\nif (h->ops->match)\r\nrc = h->ops->match(h, node);\r\nelse\r\nrc = (h->of_node != NULL) && (h->of_node == node);\r\nif (rc) {\r\nfound = h;\r\nbreak;\r\n}\r\n}\r\nmutex_unlock(&irq_domain_mutex);\r\nreturn found;\r\n}\r\nvoid irq_set_default_host(struct irq_domain *domain)\r\n{\r\npr_debug("Default domain set to @0x%p\n", domain);\r\nirq_default_domain = domain;\r\n}\r\nvoid irq_domain_disassociate(struct irq_domain *domain, unsigned int irq)\r\n{\r\nstruct irq_data *irq_data = irq_get_irq_data(irq);\r\nirq_hw_number_t hwirq;\r\nif (WARN(!irq_data || irq_data->domain != domain,\r\n"virq%i doesn't exist; cannot disassociate\n", irq))\r\nreturn;\r\nhwirq = irq_data->hwirq;\r\nirq_set_status_flags(irq, IRQ_NOREQUEST);\r\nirq_set_chip_and_handler(irq, NULL, NULL);\r\nsynchronize_irq(irq);\r\nif (domain->ops->unmap)\r\ndomain->ops->unmap(domain, irq);\r\nsmp_mb();\r\nirq_data->domain = NULL;\r\nirq_data->hwirq = 0;\r\nif (hwirq < domain->revmap_size) {\r\ndomain->linear_revmap[hwirq] = 0;\r\n} else {\r\nmutex_lock(&revmap_trees_mutex);\r\nradix_tree_delete(&domain->revmap_tree, hwirq);\r\nmutex_unlock(&revmap_trees_mutex);\r\n}\r\n}\r\nint irq_domain_associate(struct irq_domain *domain, unsigned int virq,\r\nirq_hw_number_t hwirq)\r\n{\r\nstruct irq_data *irq_data = irq_get_irq_data(virq);\r\nint ret;\r\nif (WARN(hwirq >= domain->hwirq_max,\r\n"error: hwirq 0x%x is too large for %s\n", (int)hwirq, domain->name))\r\nreturn -EINVAL;\r\nif (WARN(!irq_data, "error: virq%i is not allocated", virq))\r\nreturn -EINVAL;\r\nif (WARN(irq_data->domain, "error: virq%i is already associated", virq))\r\nreturn -EINVAL;\r\nmutex_lock(&irq_domain_mutex);\r\nirq_data->hwirq = hwirq;\r\nirq_data->domain = domain;\r\nif (domain->ops->map) {\r\nret = domain->ops->map(domain, virq, hwirq);\r\nif (ret != 0) {\r\nif (ret != -EPERM) {\r\npr_info("%s didn't like hwirq-0x%lx to VIRQ%i mapping (rc=%d)\n",\r\ndomain->name, hwirq, virq, ret);\r\n}\r\nirq_data->domain = NULL;\r\nirq_data->hwirq = 0;\r\nmutex_unlock(&irq_domain_mutex);\r\nreturn ret;\r\n}\r\nif (!domain->name && irq_data->chip)\r\ndomain->name = irq_data->chip->name;\r\n}\r\nif (hwirq < domain->revmap_size) {\r\ndomain->linear_revmap[hwirq] = virq;\r\n} else {\r\nmutex_lock(&revmap_trees_mutex);\r\nradix_tree_insert(&domain->revmap_tree, hwirq, irq_data);\r\nmutex_unlock(&revmap_trees_mutex);\r\n}\r\nmutex_unlock(&irq_domain_mutex);\r\nirq_clear_status_flags(virq, IRQ_NOREQUEST);\r\nreturn 0;\r\n}\r\nvoid irq_domain_associate_many(struct irq_domain *domain, unsigned int irq_base,\r\nirq_hw_number_t hwirq_base, int count)\r\n{\r\nint i;\r\npr_debug("%s(%s, irqbase=%i, hwbase=%i, count=%i)\n", __func__,\r\nof_node_full_name(domain->of_node), irq_base, (int)hwirq_base, count);\r\nfor (i = 0; i < count; i++) {\r\nirq_domain_associate(domain, irq_base + i, hwirq_base + i);\r\n}\r\n}\r\nunsigned int irq_create_direct_mapping(struct irq_domain *domain)\r\n{\r\nunsigned int virq;\r\nif (domain == NULL)\r\ndomain = irq_default_domain;\r\nvirq = irq_alloc_desc_from(1, of_node_to_nid(domain->of_node));\r\nif (!virq) {\r\npr_debug("create_direct virq allocation failed\n");\r\nreturn 0;\r\n}\r\nif (virq >= domain->revmap_direct_max_irq) {\r\npr_err("ERROR: no free irqs available below %i maximum\n",\r\ndomain->revmap_direct_max_irq);\r\nirq_free_desc(virq);\r\nreturn 0;\r\n}\r\npr_debug("create_direct obtained virq %d\n", virq);\r\nif (irq_domain_associate(domain, virq, virq)) {\r\nirq_free_desc(virq);\r\nreturn 0;\r\n}\r\nreturn virq;\r\n}\r\nunsigned int irq_create_mapping(struct irq_domain *domain,\r\nirq_hw_number_t hwirq)\r\n{\r\nint virq;\r\npr_debug("irq_create_mapping(0x%p, 0x%lx)\n", domain, hwirq);\r\nif (domain == NULL)\r\ndomain = irq_default_domain;\r\nif (domain == NULL) {\r\nWARN(1, "%s(, %lx) called with NULL domain\n", __func__, hwirq);\r\nreturn 0;\r\n}\r\npr_debug("-> using domain @%p\n", domain);\r\nvirq = irq_find_mapping(domain, hwirq);\r\nif (virq) {\r\npr_debug("-> existing mapping on virq %d\n", virq);\r\nreturn virq;\r\n}\r\nvirq = irq_domain_alloc_descs(-1, 1, hwirq,\r\nof_node_to_nid(domain->of_node));\r\nif (virq <= 0) {\r\npr_debug("-> virq allocation failed\n");\r\nreturn 0;\r\n}\r\nif (irq_domain_associate(domain, virq, hwirq)) {\r\nirq_free_desc(virq);\r\nreturn 0;\r\n}\r\npr_debug("irq %lu on domain %s mapped to virtual irq %u\n",\r\nhwirq, of_node_full_name(domain->of_node), virq);\r\nreturn virq;\r\n}\r\nint irq_create_strict_mappings(struct irq_domain *domain, unsigned int irq_base,\r\nirq_hw_number_t hwirq_base, int count)\r\n{\r\nint ret;\r\nret = irq_alloc_descs(irq_base, irq_base, count,\r\nof_node_to_nid(domain->of_node));\r\nif (unlikely(ret < 0))\r\nreturn ret;\r\nirq_domain_associate_many(domain, irq_base, hwirq_base, count);\r\nreturn 0;\r\n}\r\nunsigned int irq_create_of_mapping(struct of_phandle_args *irq_data)\r\n{\r\nstruct irq_domain *domain;\r\nirq_hw_number_t hwirq;\r\nunsigned int type = IRQ_TYPE_NONE;\r\nint virq;\r\ndomain = irq_data->np ? irq_find_host(irq_data->np) : irq_default_domain;\r\nif (!domain) {\r\npr_warn("no irq domain found for %s !\n",\r\nof_node_full_name(irq_data->np));\r\nreturn 0;\r\n}\r\nif (domain->ops->xlate == NULL)\r\nhwirq = irq_data->args[0];\r\nelse {\r\nif (domain->ops->xlate(domain, irq_data->np, irq_data->args,\r\nirq_data->args_count, &hwirq, &type))\r\nreturn 0;\r\n}\r\nif (irq_domain_is_hierarchy(domain)) {\r\nvirq = irq_find_mapping(domain, hwirq);\r\nif (virq)\r\nreturn virq;\r\nvirq = irq_domain_alloc_irqs(domain, 1, NUMA_NO_NODE, irq_data);\r\nif (virq <= 0)\r\nreturn 0;\r\n} else {\r\nvirq = irq_create_mapping(domain, hwirq);\r\nif (!virq)\r\nreturn virq;\r\n}\r\nif (type != IRQ_TYPE_NONE &&\r\ntype != irq_get_trigger_type(virq))\r\nirq_set_irq_type(virq, type);\r\nreturn virq;\r\n}\r\nvoid irq_dispose_mapping(unsigned int virq)\r\n{\r\nstruct irq_data *irq_data = irq_get_irq_data(virq);\r\nstruct irq_domain *domain;\r\nif (!virq || !irq_data)\r\nreturn;\r\ndomain = irq_data->domain;\r\nif (WARN_ON(domain == NULL))\r\nreturn;\r\nirq_domain_disassociate(domain, virq);\r\nirq_free_desc(virq);\r\n}\r\nunsigned int irq_find_mapping(struct irq_domain *domain,\r\nirq_hw_number_t hwirq)\r\n{\r\nstruct irq_data *data;\r\nif (domain == NULL)\r\ndomain = irq_default_domain;\r\nif (domain == NULL)\r\nreturn 0;\r\nif (hwirq < domain->revmap_direct_max_irq) {\r\ndata = irq_domain_get_irq_data(domain, hwirq);\r\nif (data && data->hwirq == hwirq)\r\nreturn hwirq;\r\n}\r\nif (hwirq < domain->revmap_size)\r\nreturn domain->linear_revmap[hwirq];\r\nrcu_read_lock();\r\ndata = radix_tree_lookup(&domain->revmap_tree, hwirq);\r\nrcu_read_unlock();\r\nreturn data ? data->irq : 0;\r\n}\r\nstatic int virq_debug_show(struct seq_file *m, void *private)\r\n{\r\nunsigned long flags;\r\nstruct irq_desc *desc;\r\nstruct irq_domain *domain;\r\nstruct radix_tree_iter iter;\r\nvoid *data, **slot;\r\nint i;\r\nseq_printf(m, " %-16s %-6s %-10s %-10s %s\n",\r\n"name", "mapped", "linear-max", "direct-max", "devtree-node");\r\nmutex_lock(&irq_domain_mutex);\r\nlist_for_each_entry(domain, &irq_domain_list, link) {\r\nint count = 0;\r\nradix_tree_for_each_slot(slot, &domain->revmap_tree, &iter, 0)\r\ncount++;\r\nseq_printf(m, "%c%-16s %6u %10u %10u %s\n",\r\ndomain == irq_default_domain ? '*' : ' ', domain->name,\r\ndomain->revmap_size + count, domain->revmap_size,\r\ndomain->revmap_direct_max_irq,\r\ndomain->of_node ? of_node_full_name(domain->of_node) : "");\r\n}\r\nmutex_unlock(&irq_domain_mutex);\r\nseq_printf(m, "%-5s %-7s %-15s %-*s %6s %-14s %s\n", "irq", "hwirq",\r\n"chip name", (int)(2 * sizeof(void *) + 2), "chip data",\r\n"active", "type", "domain");\r\nfor (i = 1; i < nr_irqs; i++) {\r\ndesc = irq_to_desc(i);\r\nif (!desc)\r\ncontinue;\r\nraw_spin_lock_irqsave(&desc->lock, flags);\r\ndomain = desc->irq_data.domain;\r\nif (domain) {\r\nstruct irq_chip *chip;\r\nint hwirq = desc->irq_data.hwirq;\r\nbool direct;\r\nseq_printf(m, "%5d ", i);\r\nseq_printf(m, "0x%05x ", hwirq);\r\nchip = irq_desc_get_chip(desc);\r\nseq_printf(m, "%-15s ", (chip && chip->name) ? chip->name : "none");\r\ndata = irq_desc_get_chip_data(desc);\r\nseq_printf(m, data ? "0x%p " : " %p ", data);\r\nseq_printf(m, " %c ", (desc->action && desc->action->handler) ? '*' : ' ');\r\ndirect = (i == hwirq) && (i < domain->revmap_direct_max_irq);\r\nseq_printf(m, "%6s%-8s ",\r\n(hwirq < domain->revmap_size) ? "LINEAR" : "RADIX",\r\ndirect ? "(DIRECT)" : "");\r\nseq_printf(m, "%s\n", desc->irq_data.domain->name);\r\n}\r\nraw_spin_unlock_irqrestore(&desc->lock, flags);\r\n}\r\nreturn 0;\r\n}\r\nstatic int virq_debug_open(struct inode *inode, struct file *file)\r\n{\r\nreturn single_open(file, virq_debug_show, inode->i_private);\r\n}\r\nstatic int __init irq_debugfs_init(void)\r\n{\r\nif (debugfs_create_file("irq_domain_mapping", S_IRUGO, NULL,\r\nNULL, &virq_debug_fops) == NULL)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nint irq_domain_xlate_onecell(struct irq_domain *d, struct device_node *ctrlr,\r\nconst u32 *intspec, unsigned int intsize,\r\nunsigned long *out_hwirq, unsigned int *out_type)\r\n{\r\nif (WARN_ON(intsize < 1))\r\nreturn -EINVAL;\r\n*out_hwirq = intspec[0];\r\n*out_type = IRQ_TYPE_NONE;\r\nreturn 0;\r\n}\r\nint irq_domain_xlate_twocell(struct irq_domain *d, struct device_node *ctrlr,\r\nconst u32 *intspec, unsigned int intsize,\r\nirq_hw_number_t *out_hwirq, unsigned int *out_type)\r\n{\r\nif (WARN_ON(intsize < 2))\r\nreturn -EINVAL;\r\n*out_hwirq = intspec[0];\r\n*out_type = intspec[1] & IRQ_TYPE_SENSE_MASK;\r\nreturn 0;\r\n}\r\nint irq_domain_xlate_onetwocell(struct irq_domain *d,\r\nstruct device_node *ctrlr,\r\nconst u32 *intspec, unsigned int intsize,\r\nunsigned long *out_hwirq, unsigned int *out_type)\r\n{\r\nif (WARN_ON(intsize < 1))\r\nreturn -EINVAL;\r\n*out_hwirq = intspec[0];\r\n*out_type = (intsize > 1) ? intspec[1] : IRQ_TYPE_NONE;\r\nreturn 0;\r\n}\r\nstatic int irq_domain_alloc_descs(int virq, unsigned int cnt,\r\nirq_hw_number_t hwirq, int node)\r\n{\r\nunsigned int hint;\r\nif (virq >= 0) {\r\nvirq = irq_alloc_descs(virq, virq, cnt, node);\r\n} else {\r\nhint = hwirq % nr_irqs;\r\nif (hint == 0)\r\nhint++;\r\nvirq = irq_alloc_descs_from(hint, cnt, node);\r\nif (virq <= 0 && hint > 1)\r\nvirq = irq_alloc_descs_from(1, cnt, node);\r\n}\r\nreturn virq;\r\n}\r\nstruct irq_domain *irq_domain_add_hierarchy(struct irq_domain *parent,\r\nunsigned int flags,\r\nunsigned int size,\r\nstruct device_node *node,\r\nconst struct irq_domain_ops *ops,\r\nvoid *host_data)\r\n{\r\nstruct irq_domain *domain;\r\nif (size)\r\ndomain = irq_domain_add_linear(node, size, ops, host_data);\r\nelse\r\ndomain = irq_domain_add_tree(node, ops, host_data);\r\nif (domain) {\r\ndomain->parent = parent;\r\ndomain->flags |= flags;\r\n}\r\nreturn domain;\r\n}\r\nstatic void irq_domain_insert_irq(int virq)\r\n{\r\nstruct irq_data *data;\r\nfor (data = irq_get_irq_data(virq); data; data = data->parent_data) {\r\nstruct irq_domain *domain = data->domain;\r\nirq_hw_number_t hwirq = data->hwirq;\r\nif (hwirq < domain->revmap_size) {\r\ndomain->linear_revmap[hwirq] = virq;\r\n} else {\r\nmutex_lock(&revmap_trees_mutex);\r\nradix_tree_insert(&domain->revmap_tree, hwirq, data);\r\nmutex_unlock(&revmap_trees_mutex);\r\n}\r\nif (!domain->name && data->chip)\r\ndomain->name = data->chip->name;\r\n}\r\nirq_clear_status_flags(virq, IRQ_NOREQUEST);\r\n}\r\nstatic void irq_domain_remove_irq(int virq)\r\n{\r\nstruct irq_data *data;\r\nirq_set_status_flags(virq, IRQ_NOREQUEST);\r\nirq_set_chip_and_handler(virq, NULL, NULL);\r\nsynchronize_irq(virq);\r\nsmp_mb();\r\nfor (data = irq_get_irq_data(virq); data; data = data->parent_data) {\r\nstruct irq_domain *domain = data->domain;\r\nirq_hw_number_t hwirq = data->hwirq;\r\nif (hwirq < domain->revmap_size) {\r\ndomain->linear_revmap[hwirq] = 0;\r\n} else {\r\nmutex_lock(&revmap_trees_mutex);\r\nradix_tree_delete(&domain->revmap_tree, hwirq);\r\nmutex_unlock(&revmap_trees_mutex);\r\n}\r\n}\r\n}\r\nstatic struct irq_data *irq_domain_insert_irq_data(struct irq_domain *domain,\r\nstruct irq_data *child)\r\n{\r\nstruct irq_data *irq_data;\r\nirq_data = kzalloc_node(sizeof(*irq_data), GFP_KERNEL, child->node);\r\nif (irq_data) {\r\nchild->parent_data = irq_data;\r\nirq_data->irq = child->irq;\r\nirq_data->node = child->node;\r\nirq_data->domain = domain;\r\n}\r\nreturn irq_data;\r\n}\r\nstatic void irq_domain_free_irq_data(unsigned int virq, unsigned int nr_irqs)\r\n{\r\nstruct irq_data *irq_data, *tmp;\r\nint i;\r\nfor (i = 0; i < nr_irqs; i++) {\r\nirq_data = irq_get_irq_data(virq + i);\r\ntmp = irq_data->parent_data;\r\nirq_data->parent_data = NULL;\r\nirq_data->domain = NULL;\r\nwhile (tmp) {\r\nirq_data = tmp;\r\ntmp = tmp->parent_data;\r\nkfree(irq_data);\r\n}\r\n}\r\n}\r\nstatic int irq_domain_alloc_irq_data(struct irq_domain *domain,\r\nunsigned int virq, unsigned int nr_irqs)\r\n{\r\nstruct irq_data *irq_data;\r\nstruct irq_domain *parent;\r\nint i;\r\nfor (i = 0; i < nr_irqs; i++) {\r\nirq_data = irq_get_irq_data(virq + i);\r\nirq_data->domain = domain;\r\nfor (parent = domain->parent; parent; parent = parent->parent) {\r\nirq_data = irq_domain_insert_irq_data(parent, irq_data);\r\nif (!irq_data) {\r\nirq_domain_free_irq_data(virq, i + 1);\r\nreturn -ENOMEM;\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstruct irq_data *irq_domain_get_irq_data(struct irq_domain *domain,\r\nunsigned int virq)\r\n{\r\nstruct irq_data *irq_data;\r\nfor (irq_data = irq_get_irq_data(virq); irq_data;\r\nirq_data = irq_data->parent_data)\r\nif (irq_data->domain == domain)\r\nreturn irq_data;\r\nreturn NULL;\r\n}\r\nint irq_domain_set_hwirq_and_chip(struct irq_domain *domain, unsigned int virq,\r\nirq_hw_number_t hwirq, struct irq_chip *chip,\r\nvoid *chip_data)\r\n{\r\nstruct irq_data *irq_data = irq_domain_get_irq_data(domain, virq);\r\nif (!irq_data)\r\nreturn -ENOENT;\r\nirq_data->hwirq = hwirq;\r\nirq_data->chip = chip ? chip : &no_irq_chip;\r\nirq_data->chip_data = chip_data;\r\nreturn 0;\r\n}\r\nvoid irq_domain_set_info(struct irq_domain *domain, unsigned int virq,\r\nirq_hw_number_t hwirq, struct irq_chip *chip,\r\nvoid *chip_data, irq_flow_handler_t handler,\r\nvoid *handler_data, const char *handler_name)\r\n{\r\nirq_domain_set_hwirq_and_chip(domain, virq, hwirq, chip, chip_data);\r\n__irq_set_handler(virq, handler, 0, handler_name);\r\nirq_set_handler_data(virq, handler_data);\r\n}\r\nvoid irq_domain_reset_irq_data(struct irq_data *irq_data)\r\n{\r\nirq_data->hwirq = 0;\r\nirq_data->chip = &no_irq_chip;\r\nirq_data->chip_data = NULL;\r\n}\r\nvoid irq_domain_free_irqs_common(struct irq_domain *domain, unsigned int virq,\r\nunsigned int nr_irqs)\r\n{\r\nstruct irq_data *irq_data;\r\nint i;\r\nfor (i = 0; i < nr_irqs; i++) {\r\nirq_data = irq_domain_get_irq_data(domain, virq + i);\r\nif (irq_data)\r\nirq_domain_reset_irq_data(irq_data);\r\n}\r\nirq_domain_free_irqs_parent(domain, virq, nr_irqs);\r\n}\r\nvoid irq_domain_free_irqs_top(struct irq_domain *domain, unsigned int virq,\r\nunsigned int nr_irqs)\r\n{\r\nint i;\r\nfor (i = 0; i < nr_irqs; i++) {\r\nirq_set_handler_data(virq + i, NULL);\r\nirq_set_handler(virq + i, NULL);\r\n}\r\nirq_domain_free_irqs_common(domain, virq, nr_irqs);\r\n}\r\nstatic bool irq_domain_is_auto_recursive(struct irq_domain *domain)\r\n{\r\nreturn domain->flags & IRQ_DOMAIN_FLAG_AUTO_RECURSIVE;\r\n}\r\nstatic void irq_domain_free_irqs_recursive(struct irq_domain *domain,\r\nunsigned int irq_base,\r\nunsigned int nr_irqs)\r\n{\r\ndomain->ops->free(domain, irq_base, nr_irqs);\r\nif (irq_domain_is_auto_recursive(domain)) {\r\nBUG_ON(!domain->parent);\r\nirq_domain_free_irqs_recursive(domain->parent, irq_base,\r\nnr_irqs);\r\n}\r\n}\r\nstatic int irq_domain_alloc_irqs_recursive(struct irq_domain *domain,\r\nunsigned int irq_base,\r\nunsigned int nr_irqs, void *arg)\r\n{\r\nint ret = 0;\r\nstruct irq_domain *parent = domain->parent;\r\nbool recursive = irq_domain_is_auto_recursive(domain);\r\nBUG_ON(recursive && !parent);\r\nif (recursive)\r\nret = irq_domain_alloc_irqs_recursive(parent, irq_base,\r\nnr_irqs, arg);\r\nif (ret >= 0)\r\nret = domain->ops->alloc(domain, irq_base, nr_irqs, arg);\r\nif (ret < 0 && recursive)\r\nirq_domain_free_irqs_recursive(parent, irq_base, nr_irqs);\r\nreturn ret;\r\n}\r\nint __irq_domain_alloc_irqs(struct irq_domain *domain, int irq_base,\r\nunsigned int nr_irqs, int node, void *arg,\r\nbool realloc)\r\n{\r\nint i, ret, virq;\r\nif (domain == NULL) {\r\ndomain = irq_default_domain;\r\nif (WARN(!domain, "domain is NULL; cannot allocate IRQ\n"))\r\nreturn -EINVAL;\r\n}\r\nif (!domain->ops->alloc) {\r\npr_debug("domain->ops->alloc() is NULL\n");\r\nreturn -ENOSYS;\r\n}\r\nif (realloc && irq_base >= 0) {\r\nvirq = irq_base;\r\n} else {\r\nvirq = irq_domain_alloc_descs(irq_base, nr_irqs, 0, node);\r\nif (virq < 0) {\r\npr_debug("cannot allocate IRQ(base %d, count %d)\n",\r\nirq_base, nr_irqs);\r\nreturn virq;\r\n}\r\n}\r\nif (irq_domain_alloc_irq_data(domain, virq, nr_irqs)) {\r\npr_debug("cannot allocate memory for IRQ%d\n", virq);\r\nret = -ENOMEM;\r\ngoto out_free_desc;\r\n}\r\nmutex_lock(&irq_domain_mutex);\r\nret = irq_domain_alloc_irqs_recursive(domain, virq, nr_irqs, arg);\r\nif (ret < 0) {\r\nmutex_unlock(&irq_domain_mutex);\r\ngoto out_free_irq_data;\r\n}\r\nfor (i = 0; i < nr_irqs; i++)\r\nirq_domain_insert_irq(virq + i);\r\nmutex_unlock(&irq_domain_mutex);\r\nreturn virq;\r\nout_free_irq_data:\r\nirq_domain_free_irq_data(virq, nr_irqs);\r\nout_free_desc:\r\nirq_free_descs(virq, nr_irqs);\r\nreturn ret;\r\n}\r\nvoid irq_domain_free_irqs(unsigned int virq, unsigned int nr_irqs)\r\n{\r\nstruct irq_data *data = irq_get_irq_data(virq);\r\nint i;\r\nif (WARN(!data || !data->domain || !data->domain->ops->free,\r\n"NULL pointer, cannot free irq\n"))\r\nreturn;\r\nmutex_lock(&irq_domain_mutex);\r\nfor (i = 0; i < nr_irqs; i++)\r\nirq_domain_remove_irq(virq + i);\r\nirq_domain_free_irqs_recursive(data->domain, virq, nr_irqs);\r\nmutex_unlock(&irq_domain_mutex);\r\nirq_domain_free_irq_data(virq, nr_irqs);\r\nirq_free_descs(virq, nr_irqs);\r\n}\r\nint irq_domain_alloc_irqs_parent(struct irq_domain *domain,\r\nunsigned int irq_base, unsigned int nr_irqs,\r\nvoid *arg)\r\n{\r\nif (irq_domain_is_auto_recursive(domain))\r\nreturn 0;\r\ndomain = domain->parent;\r\nif (domain)\r\nreturn irq_domain_alloc_irqs_recursive(domain, irq_base,\r\nnr_irqs, arg);\r\nreturn -ENOSYS;\r\n}\r\nvoid irq_domain_free_irqs_parent(struct irq_domain *domain,\r\nunsigned int irq_base, unsigned int nr_irqs)\r\n{\r\nif (!irq_domain_is_auto_recursive(domain) && domain->parent)\r\nirq_domain_free_irqs_recursive(domain->parent, irq_base,\r\nnr_irqs);\r\n}\r\nvoid irq_domain_activate_irq(struct irq_data *irq_data)\r\n{\r\nif (irq_data && irq_data->domain) {\r\nstruct irq_domain *domain = irq_data->domain;\r\nif (irq_data->parent_data)\r\nirq_domain_activate_irq(irq_data->parent_data);\r\nif (domain->ops->activate)\r\ndomain->ops->activate(domain, irq_data);\r\n}\r\n}\r\nvoid irq_domain_deactivate_irq(struct irq_data *irq_data)\r\n{\r\nif (irq_data && irq_data->domain) {\r\nstruct irq_domain *domain = irq_data->domain;\r\nif (domain->ops->deactivate)\r\ndomain->ops->deactivate(domain, irq_data);\r\nif (irq_data->parent_data)\r\nirq_domain_deactivate_irq(irq_data->parent_data);\r\n}\r\n}\r\nstatic void irq_domain_check_hierarchy(struct irq_domain *domain)\r\n{\r\nif (domain->ops->alloc)\r\ndomain->flags |= IRQ_DOMAIN_FLAG_HIERARCHY;\r\n}\r\nstruct irq_data *irq_domain_get_irq_data(struct irq_domain *domain,\r\nunsigned int virq)\r\n{\r\nstruct irq_data *irq_data = irq_get_irq_data(virq);\r\nreturn (irq_data && irq_data->domain == domain) ? irq_data : NULL;\r\n}\r\nstatic void irq_domain_check_hierarchy(struct irq_domain *domain)\r\n{\r\n}
