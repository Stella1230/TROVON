static int ion_cma_allocate(struct ion_heap *heap, struct ion_buffer *buffer,\r\nunsigned long len, unsigned long align,\r\nunsigned long flags)\r\n{\r\nstruct ion_cma_heap *cma_heap = to_cma_heap(heap);\r\nstruct device *dev = cma_heap->dev;\r\nstruct ion_cma_buffer_info *info;\r\ndev_dbg(dev, "Request buffer allocation len %ld\n", len);\r\nif (buffer->flags & ION_FLAG_CACHED)\r\nreturn -EINVAL;\r\nif (align > PAGE_SIZE)\r\nreturn -EINVAL;\r\ninfo = kzalloc(sizeof(struct ion_cma_buffer_info), GFP_KERNEL);\r\nif (!info)\r\nreturn ION_CMA_ALLOCATE_FAILED;\r\ninfo->cpu_addr = dma_alloc_coherent(dev, len, &(info->handle),\r\nGFP_HIGHUSER | __GFP_ZERO);\r\nif (!info->cpu_addr) {\r\ndev_err(dev, "Fail to allocate buffer\n");\r\ngoto err;\r\n}\r\ninfo->table = kmalloc(sizeof(struct sg_table), GFP_KERNEL);\r\nif (!info->table)\r\ngoto free_mem;\r\nif (dma_common_get_sgtable\r\n(dev, info->table, info->cpu_addr, info->handle, len))\r\ngoto free_table;\r\nbuffer->priv_virt = info;\r\ndev_dbg(dev, "Allocate buffer %p\n", buffer);\r\nreturn 0;\r\nfree_table:\r\nkfree(info->table);\r\nfree_mem:\r\ndma_free_coherent(dev, len, info->cpu_addr, info->handle);\r\nerr:\r\nkfree(info);\r\nreturn ION_CMA_ALLOCATE_FAILED;\r\n}\r\nstatic void ion_cma_free(struct ion_buffer *buffer)\r\n{\r\nstruct ion_cma_heap *cma_heap = to_cma_heap(buffer->heap);\r\nstruct device *dev = cma_heap->dev;\r\nstruct ion_cma_buffer_info *info = buffer->priv_virt;\r\ndev_dbg(dev, "Release buffer %p\n", buffer);\r\ndma_free_coherent(dev, buffer->size, info->cpu_addr, info->handle);\r\nsg_free_table(info->table);\r\nkfree(info->table);\r\nkfree(info);\r\n}\r\nstatic int ion_cma_phys(struct ion_heap *heap, struct ion_buffer *buffer,\r\nion_phys_addr_t *addr, size_t *len)\r\n{\r\nstruct ion_cma_heap *cma_heap = to_cma_heap(buffer->heap);\r\nstruct device *dev = cma_heap->dev;\r\nstruct ion_cma_buffer_info *info = buffer->priv_virt;\r\ndev_dbg(dev, "Return buffer %p physical address %pa\n", buffer,\r\n&info->handle);\r\n*addr = info->handle;\r\n*len = buffer->size;\r\nreturn 0;\r\n}\r\nstatic struct sg_table *ion_cma_heap_map_dma(struct ion_heap *heap,\r\nstruct ion_buffer *buffer)\r\n{\r\nstruct ion_cma_buffer_info *info = buffer->priv_virt;\r\nreturn info->table;\r\n}\r\nstatic void ion_cma_heap_unmap_dma(struct ion_heap *heap,\r\nstruct ion_buffer *buffer)\r\n{\r\n}\r\nstatic int ion_cma_mmap(struct ion_heap *mapper, struct ion_buffer *buffer,\r\nstruct vm_area_struct *vma)\r\n{\r\nstruct ion_cma_heap *cma_heap = to_cma_heap(buffer->heap);\r\nstruct device *dev = cma_heap->dev;\r\nstruct ion_cma_buffer_info *info = buffer->priv_virt;\r\nreturn dma_mmap_coherent(dev, vma, info->cpu_addr, info->handle,\r\nbuffer->size);\r\n}\r\nstatic void *ion_cma_map_kernel(struct ion_heap *heap,\r\nstruct ion_buffer *buffer)\r\n{\r\nstruct ion_cma_buffer_info *info = buffer->priv_virt;\r\nreturn info->cpu_addr;\r\n}\r\nstatic void ion_cma_unmap_kernel(struct ion_heap *heap,\r\nstruct ion_buffer *buffer)\r\n{\r\n}\r\nstruct ion_heap *ion_cma_heap_create(struct ion_platform_heap *data)\r\n{\r\nstruct ion_cma_heap *cma_heap;\r\ncma_heap = kzalloc(sizeof(struct ion_cma_heap), GFP_KERNEL);\r\nif (!cma_heap)\r\nreturn ERR_PTR(-ENOMEM);\r\ncma_heap->heap.ops = &ion_cma_ops;\r\ncma_heap->dev = data->priv;\r\ncma_heap->heap.type = ION_HEAP_TYPE_DMA;\r\nreturn &cma_heap->heap;\r\n}\r\nvoid ion_cma_heap_destroy(struct ion_heap *heap)\r\n{\r\nstruct ion_cma_heap *cma_heap = to_cma_heap(heap);\r\nkfree(cma_heap);\r\n}
