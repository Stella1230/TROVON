static int arm_ccn_node_to_xp(int node)\r\n{\r\nreturn node / CCN_NUM_XP_PORTS;\r\n}\r\nstatic int arm_ccn_node_to_xp_port(int node)\r\n{\r\nreturn node % CCN_NUM_XP_PORTS;\r\n}\r\nstatic void arm_ccn_pmu_config_set(u64 *config, u32 node_xp, u32 type, u32 port)\r\n{\r\n*config &= ~((0xff << 0) | (0xff << 8) | (0xff << 24));\r\n*config |= (node_xp << 0) | (type << 8) | (port << 24);\r\n}\r\nstatic ssize_t arm_ccn_pmu_format_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct dev_ext_attribute *ea = container_of(attr,\r\nstruct dev_ext_attribute, attr);\r\nreturn snprintf(buf, PAGE_SIZE, "%s\n", (char *)ea->var);\r\n}\r\nstatic ssize_t arm_ccn_pmu_event_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct arm_ccn_pmu_event *event = container_of(attr,\r\nstruct arm_ccn_pmu_event, attr);\r\nssize_t res;\r\nres = snprintf(buf, PAGE_SIZE, "type=0x%x", event->type);\r\nif (event->event)\r\nres += snprintf(buf + res, PAGE_SIZE - res, ",event=0x%x",\r\nevent->event);\r\nif (event->def)\r\nres += snprintf(buf + res, PAGE_SIZE - res, ",%s",\r\nevent->def);\r\nif (event->mask)\r\nres += snprintf(buf + res, PAGE_SIZE - res, ",mask=0x%x",\r\nevent->mask);\r\nres += snprintf(buf + res, PAGE_SIZE - res, "\n");\r\nreturn res;\r\n}\r\nstatic umode_t arm_ccn_pmu_events_is_visible(struct kobject *kobj,\r\nstruct attribute *attr, int index)\r\n{\r\nstruct device *dev = kobj_to_dev(kobj);\r\nstruct arm_ccn *ccn = pmu_to_arm_ccn(dev_get_drvdata(dev));\r\nstruct device_attribute *dev_attr = container_of(attr,\r\nstruct device_attribute, attr);\r\nstruct arm_ccn_pmu_event *event = container_of(dev_attr,\r\nstruct arm_ccn_pmu_event, attr);\r\nif (event->type == CCN_TYPE_SBAS && !ccn->sbas_present)\r\nreturn 0;\r\nif (event->type == CCN_TYPE_SBSX && !ccn->sbsx_present)\r\nreturn 0;\r\nreturn attr->mode;\r\n}\r\nstatic u64 *arm_ccn_pmu_get_cmp_mask(struct arm_ccn *ccn, const char *name)\r\n{\r\nunsigned long i;\r\nif (WARN_ON(!name || !name[0] || !isxdigit(name[0]) || !name[1]))\r\nreturn NULL;\r\ni = isdigit(name[0]) ? name[0] - '0' : 0xa + tolower(name[0]) - 'a';\r\nswitch (name[1]) {\r\ncase 'l':\r\nreturn &ccn->dt.cmp_mask[i].l;\r\ncase 'h':\r\nreturn &ccn->dt.cmp_mask[i].h;\r\ndefault:\r\nreturn NULL;\r\n}\r\n}\r\nstatic ssize_t arm_ccn_pmu_cmp_mask_show(struct device *dev,\r\nstruct device_attribute *attr, char *buf)\r\n{\r\nstruct arm_ccn *ccn = pmu_to_arm_ccn(dev_get_drvdata(dev));\r\nu64 *mask = arm_ccn_pmu_get_cmp_mask(ccn, attr->attr.name);\r\nreturn mask ? snprintf(buf, PAGE_SIZE, "0x%016llx\n", *mask) : -EINVAL;\r\n}\r\nstatic ssize_t arm_ccn_pmu_cmp_mask_store(struct device *dev,\r\nstruct device_attribute *attr, const char *buf, size_t count)\r\n{\r\nstruct arm_ccn *ccn = pmu_to_arm_ccn(dev_get_drvdata(dev));\r\nu64 *mask = arm_ccn_pmu_get_cmp_mask(ccn, attr->attr.name);\r\nint err = -EINVAL;\r\nif (mask)\r\nerr = kstrtoull(buf, 0, mask);\r\nreturn err ? err : count;\r\n}\r\nstatic ktime_t arm_ccn_pmu_timer_period(void)\r\n{\r\nreturn ns_to_ktime((u64)arm_ccn_pmu_poll_period_us * 1000);\r\n}\r\nstatic int arm_ccn_pmu_alloc_bit(unsigned long *bitmap, unsigned long size)\r\n{\r\nint bit;\r\ndo {\r\nbit = find_first_zero_bit(bitmap, size);\r\nif (bit >= size)\r\nreturn -EAGAIN;\r\n} while (test_and_set_bit(bit, bitmap));\r\nreturn bit;\r\n}\r\nstatic int arm_ccn_pmu_type_eq(u32 a, u32 b)\r\n{\r\nif (a == b)\r\nreturn 1;\r\nswitch (a) {\r\ncase CCN_TYPE_RNI_1P:\r\ncase CCN_TYPE_RNI_2P:\r\ncase CCN_TYPE_RNI_3P:\r\ncase CCN_TYPE_RND_1P:\r\ncase CCN_TYPE_RND_2P:\r\ncase CCN_TYPE_RND_3P:\r\nswitch (b) {\r\ncase CCN_TYPE_RNI_1P:\r\ncase CCN_TYPE_RNI_2P:\r\ncase CCN_TYPE_RNI_3P:\r\ncase CCN_TYPE_RND_1P:\r\ncase CCN_TYPE_RND_2P:\r\ncase CCN_TYPE_RND_3P:\r\nreturn 1;\r\n}\r\nbreak;\r\n}\r\nreturn 0;\r\n}\r\nstatic void arm_ccn_pmu_event_destroy(struct perf_event *event)\r\n{\r\nstruct arm_ccn *ccn = pmu_to_arm_ccn(event->pmu);\r\nstruct hw_perf_event *hw = &event->hw;\r\nif (hw->idx == CCN_IDX_PMU_CYCLE_COUNTER) {\r\nclear_bit(CCN_IDX_PMU_CYCLE_COUNTER, ccn->dt.pmu_counters_mask);\r\n} else {\r\nstruct arm_ccn_component *source =\r\nccn->dt.pmu_counters[hw->idx].source;\r\nif (CCN_CONFIG_TYPE(event->attr.config) == CCN_TYPE_XP &&\r\nCCN_CONFIG_EVENT(event->attr.config) ==\r\nCCN_EVENT_WATCHPOINT)\r\nclear_bit(hw->config_base, source->xp.dt_cmp_mask);\r\nelse\r\nclear_bit(hw->config_base, source->pmu_events_mask);\r\nclear_bit(hw->idx, ccn->dt.pmu_counters_mask);\r\n}\r\nccn->dt.pmu_counters[hw->idx].source = NULL;\r\nccn->dt.pmu_counters[hw->idx].event = NULL;\r\n}\r\nstatic int arm_ccn_pmu_event_init(struct perf_event *event)\r\n{\r\nstruct arm_ccn *ccn;\r\nstruct hw_perf_event *hw = &event->hw;\r\nu32 node_xp, type, event_id;\r\nint valid, bit;\r\nstruct arm_ccn_component *source;\r\nint i;\r\nif (event->attr.type != event->pmu->type)\r\nreturn -ENOENT;\r\nccn = pmu_to_arm_ccn(event->pmu);\r\nevent->destroy = arm_ccn_pmu_event_destroy;\r\nif (hw->sample_period) {\r\ndev_warn(ccn->dev, "Sampling not supported!\n");\r\nreturn -EOPNOTSUPP;\r\n}\r\nif (has_branch_stack(event) || event->attr.exclude_user ||\r\nevent->attr.exclude_kernel || event->attr.exclude_hv ||\r\nevent->attr.exclude_idle) {\r\ndev_warn(ccn->dev, "Can't exclude execution levels!\n");\r\nreturn -EOPNOTSUPP;\r\n}\r\nif (event->cpu < 0) {\r\ndev_warn(ccn->dev, "Can't provide per-task data!\n");\r\nreturn -EOPNOTSUPP;\r\n}\r\nnode_xp = CCN_CONFIG_NODE(event->attr.config);\r\ntype = CCN_CONFIG_TYPE(event->attr.config);\r\nevent_id = CCN_CONFIG_EVENT(event->attr.config);\r\nswitch (type) {\r\ncase CCN_TYPE_XP:\r\nif (node_xp >= ccn->num_xps) {\r\ndev_warn(ccn->dev, "Invalid XP ID %d!\n", node_xp);\r\nreturn -EINVAL;\r\n}\r\nbreak;\r\ncase CCN_TYPE_CYCLES:\r\nbreak;\r\ndefault:\r\nif (node_xp >= ccn->num_nodes) {\r\ndev_warn(ccn->dev, "Invalid node ID %d!\n", node_xp);\r\nreturn -EINVAL;\r\n}\r\nif (!arm_ccn_pmu_type_eq(type, ccn->node[node_xp].type)) {\r\ndev_warn(ccn->dev, "Invalid type 0x%x for node %d!\n",\r\ntype, node_xp);\r\nreturn -EINVAL;\r\n}\r\nbreak;\r\n}\r\nfor (i = 0, valid = 0; i < ARRAY_SIZE(arm_ccn_pmu_events) && !valid;\r\ni++) {\r\nstruct arm_ccn_pmu_event *e = &arm_ccn_pmu_events[i];\r\nu32 port = CCN_CONFIG_PORT(event->attr.config);\r\nu32 vc = CCN_CONFIG_VC(event->attr.config);\r\nif (!arm_ccn_pmu_type_eq(type, e->type))\r\ncontinue;\r\nif (event_id != e->event)\r\ncontinue;\r\nif (e->num_ports && port >= e->num_ports) {\r\ndev_warn(ccn->dev, "Invalid port %d for node/XP %d!\n",\r\nport, node_xp);\r\nreturn -EINVAL;\r\n}\r\nif (e->num_vcs && vc >= e->num_vcs) {\r\ndev_warn(ccn->dev, "Invalid vc %d for node/XP %d!\n",\r\nvc, node_xp);\r\nreturn -EINVAL;\r\n}\r\nvalid = 1;\r\n}\r\nif (!valid) {\r\ndev_warn(ccn->dev, "Invalid event 0x%x for node/XP %d!\n",\r\nevent_id, node_xp);\r\nreturn -EINVAL;\r\n}\r\nif (event_id == CCN_EVENT_WATCHPOINT && type != CCN_TYPE_XP) {\r\nu32 port;\r\ntype = CCN_TYPE_XP;\r\nport = arm_ccn_node_to_xp_port(node_xp);\r\nnode_xp = arm_ccn_node_to_xp(node_xp);\r\narm_ccn_pmu_config_set(&event->attr.config,\r\nnode_xp, type, port);\r\n}\r\nif (type == CCN_TYPE_CYCLES) {\r\nif (test_and_set_bit(CCN_IDX_PMU_CYCLE_COUNTER,\r\nccn->dt.pmu_counters_mask))\r\nreturn -EAGAIN;\r\nhw->idx = CCN_IDX_PMU_CYCLE_COUNTER;\r\nccn->dt.pmu_counters[CCN_IDX_PMU_CYCLE_COUNTER].event = event;\r\nreturn 0;\r\n}\r\nhw->idx = arm_ccn_pmu_alloc_bit(ccn->dt.pmu_counters_mask,\r\nCCN_NUM_PMU_EVENT_COUNTERS);\r\nif (hw->idx < 0) {\r\ndev_warn(ccn->dev, "No more counters available!\n");\r\nreturn -EAGAIN;\r\n}\r\nif (type == CCN_TYPE_XP)\r\nsource = &ccn->xp[node_xp];\r\nelse\r\nsource = &ccn->node[node_xp];\r\nccn->dt.pmu_counters[hw->idx].source = source;\r\nif (type == CCN_TYPE_XP && event_id == CCN_EVENT_WATCHPOINT)\r\nbit = arm_ccn_pmu_alloc_bit(source->xp.dt_cmp_mask,\r\nCCN_NUM_XP_WATCHPOINTS);\r\nelse\r\nbit = arm_ccn_pmu_alloc_bit(source->pmu_events_mask,\r\nCCN_NUM_PMU_EVENTS);\r\nif (bit < 0) {\r\ndev_warn(ccn->dev, "No more event sources/watchpoints on node/XP %d!\n",\r\nnode_xp);\r\nclear_bit(hw->idx, ccn->dt.pmu_counters_mask);\r\nreturn -EAGAIN;\r\n}\r\nhw->config_base = bit;\r\nccn->dt.pmu_counters[hw->idx].event = event;\r\nreturn 0;\r\n}\r\nstatic u64 arm_ccn_pmu_read_counter(struct arm_ccn *ccn, int idx)\r\n{\r\nu64 res;\r\nif (idx == CCN_IDX_PMU_CYCLE_COUNTER) {\r\n#ifdef readq\r\nres = readq(ccn->dt.base + CCN_DT_PMCCNTR);\r\n#else\r\nwritel(0x1, ccn->dt.base + CCN_DT_PMSR_REQ);\r\nwhile (!(readl(ccn->dt.base + CCN_DT_PMSR) & 0x1))\r\n;\r\nwritel(0x1, ccn->dt.base + CCN_DT_PMSR_CLR);\r\nres = readl(ccn->dt.base + CCN_DT_PMCCNTRSR + 4) & 0xff;\r\nres <<= 32;\r\nres |= readl(ccn->dt.base + CCN_DT_PMCCNTRSR);\r\n#endif\r\n} else {\r\nres = readl(ccn->dt.base + CCN_DT_PMEVCNT(idx));\r\n}\r\nreturn res;\r\n}\r\nstatic void arm_ccn_pmu_event_update(struct perf_event *event)\r\n{\r\nstruct arm_ccn *ccn = pmu_to_arm_ccn(event->pmu);\r\nstruct hw_perf_event *hw = &event->hw;\r\nu64 prev_count, new_count, mask;\r\ndo {\r\nprev_count = local64_read(&hw->prev_count);\r\nnew_count = arm_ccn_pmu_read_counter(ccn, hw->idx);\r\n} while (local64_xchg(&hw->prev_count, new_count) != prev_count);\r\nmask = (1LLU << (hw->idx == CCN_IDX_PMU_CYCLE_COUNTER ? 40 : 32)) - 1;\r\nlocal64_add((new_count - prev_count) & mask, &event->count);\r\n}\r\nstatic void arm_ccn_pmu_xp_dt_config(struct perf_event *event, int enable)\r\n{\r\nstruct arm_ccn *ccn = pmu_to_arm_ccn(event->pmu);\r\nstruct hw_perf_event *hw = &event->hw;\r\nstruct arm_ccn_component *xp;\r\nu32 val, dt_cfg;\r\nif (CCN_CONFIG_TYPE(event->attr.config) == CCN_TYPE_XP)\r\nxp = &ccn->xp[CCN_CONFIG_XP(event->attr.config)];\r\nelse\r\nxp = &ccn->xp[arm_ccn_node_to_xp(\r\nCCN_CONFIG_NODE(event->attr.config))];\r\nif (enable)\r\ndt_cfg = hw->event_base;\r\nelse\r\ndt_cfg = CCN_XP_DT_CONFIG__DT_CFG__PASS_THROUGH;\r\nspin_lock(&ccn->dt.config_lock);\r\nval = readl(xp->base + CCN_XP_DT_CONFIG);\r\nval &= ~(CCN_XP_DT_CONFIG__DT_CFG__MASK <<\r\nCCN_XP_DT_CONFIG__DT_CFG__SHIFT(hw->idx));\r\nval |= dt_cfg << CCN_XP_DT_CONFIG__DT_CFG__SHIFT(hw->idx);\r\nwritel(val, xp->base + CCN_XP_DT_CONFIG);\r\nspin_unlock(&ccn->dt.config_lock);\r\n}\r\nstatic void arm_ccn_pmu_event_start(struct perf_event *event, int flags)\r\n{\r\nstruct arm_ccn *ccn = pmu_to_arm_ccn(event->pmu);\r\nstruct hw_perf_event *hw = &event->hw;\r\nlocal64_set(&event->hw.prev_count,\r\narm_ccn_pmu_read_counter(ccn, hw->idx));\r\nhw->state = 0;\r\nif (!ccn->irq_used)\r\nhrtimer_start(&ccn->dt.hrtimer, arm_ccn_pmu_timer_period(),\r\nHRTIMER_MODE_REL);\r\narm_ccn_pmu_xp_dt_config(event, 1);\r\n}\r\nstatic void arm_ccn_pmu_event_stop(struct perf_event *event, int flags)\r\n{\r\nstruct arm_ccn *ccn = pmu_to_arm_ccn(event->pmu);\r\nstruct hw_perf_event *hw = &event->hw;\r\nu64 timeout;\r\narm_ccn_pmu_xp_dt_config(event, 0);\r\nif (!ccn->irq_used)\r\nhrtimer_cancel(&ccn->dt.hrtimer);\r\ntimeout = arm_ccn_pmu_read_counter(ccn, CCN_IDX_PMU_CYCLE_COUNTER) +\r\nccn->num_xps;\r\nwhile (arm_ccn_pmu_read_counter(ccn, CCN_IDX_PMU_CYCLE_COUNTER) <\r\ntimeout)\r\ncpu_relax();\r\nif (flags & PERF_EF_UPDATE)\r\narm_ccn_pmu_event_update(event);\r\nhw->state |= PERF_HES_STOPPED;\r\n}\r\nstatic void arm_ccn_pmu_xp_watchpoint_config(struct perf_event *event)\r\n{\r\nstruct arm_ccn *ccn = pmu_to_arm_ccn(event->pmu);\r\nstruct hw_perf_event *hw = &event->hw;\r\nstruct arm_ccn_component *source =\r\nccn->dt.pmu_counters[hw->idx].source;\r\nunsigned long wp = hw->config_base;\r\nu32 val;\r\nu64 cmp_l = event->attr.config1;\r\nu64 cmp_h = event->attr.config2;\r\nu64 mask_l = ccn->dt.cmp_mask[CCN_CONFIG_MASK(event->attr.config)].l;\r\nu64 mask_h = ccn->dt.cmp_mask[CCN_CONFIG_MASK(event->attr.config)].h;\r\nhw->event_base = CCN_XP_DT_CONFIG__DT_CFG__WATCHPOINT(wp);\r\nval = readl(source->base + CCN_XP_DT_INTERFACE_SEL);\r\nval &= ~(CCN_XP_DT_INTERFACE_SEL__DT_IO_SEL__MASK <<\r\nCCN_XP_DT_INTERFACE_SEL__DT_IO_SEL__SHIFT(wp));\r\nval |= CCN_CONFIG_DIR(event->attr.config) <<\r\nCCN_XP_DT_INTERFACE_SEL__DT_IO_SEL__SHIFT(wp);\r\nval &= ~(CCN_XP_DT_INTERFACE_SEL__DT_DEV_SEL__MASK <<\r\nCCN_XP_DT_INTERFACE_SEL__DT_DEV_SEL__SHIFT(wp));\r\nval |= CCN_CONFIG_PORT(event->attr.config) <<\r\nCCN_XP_DT_INTERFACE_SEL__DT_DEV_SEL__SHIFT(wp);\r\nval &= ~(CCN_XP_DT_INTERFACE_SEL__DT_VC_SEL__MASK <<\r\nCCN_XP_DT_INTERFACE_SEL__DT_VC_SEL__SHIFT(wp));\r\nval |= CCN_CONFIG_VC(event->attr.config) <<\r\nCCN_XP_DT_INTERFACE_SEL__DT_VC_SEL__SHIFT(wp);\r\nwritel(val, source->base + CCN_XP_DT_INTERFACE_SEL);\r\nwritel(cmp_l & 0xffffffff, source->base + CCN_XP_DT_CMP_VAL_L(wp));\r\nwritel((cmp_l >> 32) & 0xefffffff,\r\nsource->base + CCN_XP_DT_CMP_VAL_L(wp) + 4);\r\nwritel(cmp_h & 0xffffffff, source->base + CCN_XP_DT_CMP_VAL_H(wp));\r\nwritel((cmp_h >> 32) & 0x0fffffff,\r\nsource->base + CCN_XP_DT_CMP_VAL_H(wp) + 4);\r\nwritel(mask_l & 0xffffffff, source->base + CCN_XP_DT_CMP_MASK_L(wp));\r\nwritel((mask_l >> 32) & 0xefffffff,\r\nsource->base + CCN_XP_DT_CMP_MASK_L(wp) + 4);\r\nwritel(mask_h & 0xffffffff, source->base + CCN_XP_DT_CMP_MASK_H(wp));\r\nwritel((mask_h >> 32) & 0x0fffffff,\r\nsource->base + CCN_XP_DT_CMP_MASK_H(wp) + 4);\r\n}\r\nstatic void arm_ccn_pmu_xp_event_config(struct perf_event *event)\r\n{\r\nstruct arm_ccn *ccn = pmu_to_arm_ccn(event->pmu);\r\nstruct hw_perf_event *hw = &event->hw;\r\nstruct arm_ccn_component *source =\r\nccn->dt.pmu_counters[hw->idx].source;\r\nu32 val, id;\r\nhw->event_base = CCN_XP_DT_CONFIG__DT_CFG__XP_PMU_EVENT(hw->config_base);\r\nid = (CCN_CONFIG_VC(event->attr.config) << 4) |\r\n(CCN_CONFIG_PORT(event->attr.config) << 3) |\r\n(CCN_CONFIG_EVENT(event->attr.config) << 0);\r\nval = readl(source->base + CCN_XP_PMU_EVENT_SEL);\r\nval &= ~(CCN_XP_PMU_EVENT_SEL__ID__MASK <<\r\nCCN_XP_PMU_EVENT_SEL__ID__SHIFT(hw->config_base));\r\nval |= id << CCN_XP_PMU_EVENT_SEL__ID__SHIFT(hw->config_base);\r\nwritel(val, source->base + CCN_XP_PMU_EVENT_SEL);\r\n}\r\nstatic void arm_ccn_pmu_node_event_config(struct perf_event *event)\r\n{\r\nstruct arm_ccn *ccn = pmu_to_arm_ccn(event->pmu);\r\nstruct hw_perf_event *hw = &event->hw;\r\nstruct arm_ccn_component *source =\r\nccn->dt.pmu_counters[hw->idx].source;\r\nu32 type = CCN_CONFIG_TYPE(event->attr.config);\r\nu32 val, port;\r\nport = arm_ccn_node_to_xp_port(CCN_CONFIG_NODE(event->attr.config));\r\nhw->event_base = CCN_XP_DT_CONFIG__DT_CFG__DEVICE_PMU_EVENT(port,\r\nhw->config_base);\r\nBUILD_BUG_ON(CCN_HNF_PMU_EVENT_SEL != CCN_SBAS_PMU_EVENT_SEL);\r\nBUILD_BUG_ON(CCN_SBAS_PMU_EVENT_SEL != CCN_RNI_PMU_EVENT_SEL);\r\nBUILD_BUG_ON(CCN_HNF_PMU_EVENT_SEL__ID__SHIFT(1) !=\r\nCCN_SBAS_PMU_EVENT_SEL__ID__SHIFT(1));\r\nBUILD_BUG_ON(CCN_SBAS_PMU_EVENT_SEL__ID__SHIFT(1) !=\r\nCCN_RNI_PMU_EVENT_SEL__ID__SHIFT(1));\r\nBUILD_BUG_ON(CCN_HNF_PMU_EVENT_SEL__ID__MASK !=\r\nCCN_SBAS_PMU_EVENT_SEL__ID__MASK);\r\nBUILD_BUG_ON(CCN_SBAS_PMU_EVENT_SEL__ID__MASK !=\r\nCCN_RNI_PMU_EVENT_SEL__ID__MASK);\r\nif (WARN_ON(type != CCN_TYPE_HNF && type != CCN_TYPE_SBAS &&\r\n!arm_ccn_pmu_type_eq(type, CCN_TYPE_RNI_3P)))\r\nreturn;\r\nval = readl(source->base + CCN_HNF_PMU_EVENT_SEL);\r\nval &= ~(CCN_HNF_PMU_EVENT_SEL__ID__MASK <<\r\nCCN_HNF_PMU_EVENT_SEL__ID__SHIFT(hw->config_base));\r\nval |= CCN_CONFIG_EVENT(event->attr.config) <<\r\nCCN_HNF_PMU_EVENT_SEL__ID__SHIFT(hw->config_base);\r\nwritel(val, source->base + CCN_HNF_PMU_EVENT_SEL);\r\n}\r\nstatic void arm_ccn_pmu_event_config(struct perf_event *event)\r\n{\r\nstruct arm_ccn *ccn = pmu_to_arm_ccn(event->pmu);\r\nstruct hw_perf_event *hw = &event->hw;\r\nu32 xp, offset, val;\r\nif (hw->idx == CCN_IDX_PMU_CYCLE_COUNTER)\r\nreturn;\r\nif (CCN_CONFIG_TYPE(event->attr.config) == CCN_TYPE_XP)\r\nxp = CCN_CONFIG_XP(event->attr.config);\r\nelse\r\nxp = arm_ccn_node_to_xp(CCN_CONFIG_NODE(event->attr.config));\r\nspin_lock(&ccn->dt.config_lock);\r\noffset = (hw->idx / 4) * 4;\r\nval = readl(ccn->dt.base + CCN_DT_ACTIVE_DSM + offset);\r\nval &= ~(CCN_DT_ACTIVE_DSM__DSM_ID__MASK <<\r\nCCN_DT_ACTIVE_DSM__DSM_ID__SHIFT(hw->idx % 4));\r\nval |= xp << CCN_DT_ACTIVE_DSM__DSM_ID__SHIFT(hw->idx % 4);\r\nwritel(val, ccn->dt.base + CCN_DT_ACTIVE_DSM + offset);\r\nif (CCN_CONFIG_TYPE(event->attr.config) == CCN_TYPE_XP) {\r\nif (CCN_CONFIG_EVENT(event->attr.config) ==\r\nCCN_EVENT_WATCHPOINT)\r\narm_ccn_pmu_xp_watchpoint_config(event);\r\nelse\r\narm_ccn_pmu_xp_event_config(event);\r\n} else {\r\narm_ccn_pmu_node_event_config(event);\r\n}\r\nspin_unlock(&ccn->dt.config_lock);\r\n}\r\nstatic int arm_ccn_pmu_event_add(struct perf_event *event, int flags)\r\n{\r\nstruct hw_perf_event *hw = &event->hw;\r\narm_ccn_pmu_event_config(event);\r\nhw->state = PERF_HES_STOPPED;\r\nif (flags & PERF_EF_START)\r\narm_ccn_pmu_event_start(event, PERF_EF_UPDATE);\r\nreturn 0;\r\n}\r\nstatic void arm_ccn_pmu_event_del(struct perf_event *event, int flags)\r\n{\r\narm_ccn_pmu_event_stop(event, PERF_EF_UPDATE);\r\n}\r\nstatic void arm_ccn_pmu_event_read(struct perf_event *event)\r\n{\r\narm_ccn_pmu_event_update(event);\r\n}\r\nstatic irqreturn_t arm_ccn_pmu_overflow_handler(struct arm_ccn_dt *dt)\r\n{\r\nu32 pmovsr = readl(dt->base + CCN_DT_PMOVSR);\r\nint idx;\r\nif (!pmovsr)\r\nreturn IRQ_NONE;\r\nwritel(pmovsr, dt->base + CCN_DT_PMOVSR_CLR);\r\nBUILD_BUG_ON(CCN_IDX_PMU_CYCLE_COUNTER != CCN_NUM_PMU_EVENT_COUNTERS);\r\nfor (idx = 0; idx < CCN_NUM_PMU_EVENT_COUNTERS + 1; idx++) {\r\nstruct perf_event *event = dt->pmu_counters[idx].event;\r\nint overflowed = pmovsr & BIT(idx);\r\nWARN_ON_ONCE(overflowed && !event &&\r\nidx != CCN_IDX_PMU_CYCLE_COUNTER);\r\nif (!event || !overflowed)\r\ncontinue;\r\narm_ccn_pmu_event_update(event);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic enum hrtimer_restart arm_ccn_pmu_timer_handler(struct hrtimer *hrtimer)\r\n{\r\nstruct arm_ccn_dt *dt = container_of(hrtimer, struct arm_ccn_dt,\r\nhrtimer);\r\nunsigned long flags;\r\nlocal_irq_save(flags);\r\narm_ccn_pmu_overflow_handler(dt);\r\nlocal_irq_restore(flags);\r\nhrtimer_forward_now(hrtimer, arm_ccn_pmu_timer_period());\r\nreturn HRTIMER_RESTART;\r\n}\r\nstatic int arm_ccn_pmu_init(struct arm_ccn *ccn)\r\n{\r\nint i;\r\nchar *name;\r\nccn->dt.base = ccn->base + CCN_REGION_SIZE;\r\nspin_lock_init(&ccn->dt.config_lock);\r\nwritel(CCN_DT_PMOVSR_CLR__MASK, ccn->dt.base + CCN_DT_PMOVSR_CLR);\r\nwritel(CCN_DT_CTL__DT_EN, ccn->dt.base + CCN_DT_CTL);\r\nwritel(CCN_DT_PMCR__OVFL_INTR_EN | CCN_DT_PMCR__PMU_EN,\r\nccn->dt.base + CCN_DT_PMCR);\r\nwritel(0x1, ccn->dt.base + CCN_DT_PMSR_CLR);\r\nfor (i = 0; i < ccn->num_xps; i++) {\r\nwritel(0, ccn->xp[i].base + CCN_XP_DT_CONFIG);\r\nwritel((CCN_XP_DT_CONTROL__WP_ARM_SEL__ALWAYS <<\r\nCCN_XP_DT_CONTROL__WP_ARM_SEL__SHIFT(0)) |\r\n(CCN_XP_DT_CONTROL__WP_ARM_SEL__ALWAYS <<\r\nCCN_XP_DT_CONTROL__WP_ARM_SEL__SHIFT(1)) |\r\nCCN_XP_DT_CONTROL__DT_ENABLE,\r\nccn->xp[i].base + CCN_XP_DT_CONTROL);\r\n}\r\nccn->dt.cmp_mask[CCN_IDX_MASK_ANY].l = ~0;\r\nccn->dt.cmp_mask[CCN_IDX_MASK_ANY].h = ~0;\r\nccn->dt.cmp_mask[CCN_IDX_MASK_EXACT].l = 0;\r\nccn->dt.cmp_mask[CCN_IDX_MASK_EXACT].h = 0;\r\nccn->dt.cmp_mask[CCN_IDX_MASK_ORDER].l = ~0;\r\nccn->dt.cmp_mask[CCN_IDX_MASK_ORDER].h = ~(0x1 << 15);\r\nccn->dt.cmp_mask[CCN_IDX_MASK_OPCODE].l = ~0;\r\nccn->dt.cmp_mask[CCN_IDX_MASK_OPCODE].h = ~(0x1f << 9);\r\nccn->dt.id = ida_simple_get(&arm_ccn_pmu_ida, 0, 0, GFP_KERNEL);\r\nif (ccn->dt.id == 0) {\r\nname = "ccn";\r\n} else {\r\nint len = snprintf(NULL, 0, "ccn_%d", ccn->dt.id);\r\nname = devm_kzalloc(ccn->dev, len + 1, GFP_KERNEL);\r\nsnprintf(name, len + 1, "ccn_%d", ccn->dt.id);\r\n}\r\nccn->dt.pmu = (struct pmu) {\r\n.attr_groups = arm_ccn_pmu_attr_groups,\r\n.task_ctx_nr = perf_invalid_context,\r\n.event_init = arm_ccn_pmu_event_init,\r\n.add = arm_ccn_pmu_event_add,\r\n.del = arm_ccn_pmu_event_del,\r\n.start = arm_ccn_pmu_event_start,\r\n.stop = arm_ccn_pmu_event_stop,\r\n.read = arm_ccn_pmu_event_read,\r\n};\r\nif (!ccn->irq_used) {\r\ndev_info(ccn->dev, "No access to interrupts, using timer.\n");\r\nhrtimer_init(&ccn->dt.hrtimer, CLOCK_MONOTONIC,\r\nHRTIMER_MODE_REL);\r\nccn->dt.hrtimer.function = arm_ccn_pmu_timer_handler;\r\n}\r\nreturn perf_pmu_register(&ccn->dt.pmu, name, -1);\r\n}\r\nstatic void arm_ccn_pmu_cleanup(struct arm_ccn *ccn)\r\n{\r\nint i;\r\nfor (i = 0; i < ccn->num_xps; i++)\r\nwritel(0, ccn->xp[i].base + CCN_XP_DT_CONTROL);\r\nwritel(0, ccn->dt.base + CCN_DT_PMCR);\r\nperf_pmu_unregister(&ccn->dt.pmu);\r\nida_simple_remove(&arm_ccn_pmu_ida, ccn->dt.id);\r\n}\r\nstatic int arm_ccn_for_each_valid_region(struct arm_ccn *ccn,\r\nint (*callback)(struct arm_ccn *ccn, int region,\r\nvoid __iomem *base, u32 type, u32 id))\r\n{\r\nint region;\r\nfor (region = 0; region < CCN_NUM_REGIONS; region++) {\r\nu32 val, type, id;\r\nvoid __iomem *base;\r\nint err;\r\nval = readl(ccn->base + CCN_MN_OLY_COMP_LIST_63_0 +\r\n4 * (region / 32));\r\nif (!(val & (1 << (region % 32))))\r\ncontinue;\r\nbase = ccn->base + region * CCN_REGION_SIZE;\r\nval = readl(base + CCN_ALL_OLY_ID);\r\ntype = (val >> CCN_ALL_OLY_ID__OLY_ID__SHIFT) &\r\nCCN_ALL_OLY_ID__OLY_ID__MASK;\r\nid = (val >> CCN_ALL_OLY_ID__NODE_ID__SHIFT) &\r\nCCN_ALL_OLY_ID__NODE_ID__MASK;\r\nerr = callback(ccn, region, base, type, id);\r\nif (err)\r\nreturn err;\r\n}\r\nreturn 0;\r\n}\r\nstatic int arm_ccn_get_nodes_num(struct arm_ccn *ccn, int region,\r\nvoid __iomem *base, u32 type, u32 id)\r\n{\r\nif (type == CCN_TYPE_XP && id >= ccn->num_xps)\r\nccn->num_xps = id + 1;\r\nelse if (id >= ccn->num_nodes)\r\nccn->num_nodes = id + 1;\r\nreturn 0;\r\n}\r\nstatic int arm_ccn_init_nodes(struct arm_ccn *ccn, int region,\r\nvoid __iomem *base, u32 type, u32 id)\r\n{\r\nstruct arm_ccn_component *component;\r\ndev_dbg(ccn->dev, "Region %d: id=%u, type=0x%02x\n", region, id, type);\r\nswitch (type) {\r\ncase CCN_TYPE_MN:\r\ncase CCN_TYPE_DT:\r\nreturn 0;\r\ncase CCN_TYPE_XP:\r\ncomponent = &ccn->xp[id];\r\nbreak;\r\ncase CCN_TYPE_SBSX:\r\nccn->sbsx_present = 1;\r\ncomponent = &ccn->node[id];\r\nbreak;\r\ncase CCN_TYPE_SBAS:\r\nccn->sbas_present = 1;\r\ndefault:\r\ncomponent = &ccn->node[id];\r\nbreak;\r\n}\r\ncomponent->base = base;\r\ncomponent->type = type;\r\nreturn 0;\r\n}\r\nstatic irqreturn_t arm_ccn_error_handler(struct arm_ccn *ccn,\r\nconst u32 *err_sig_val)\r\n{\r\ndev_err(ccn->dev, "Error reported in %08x%08x%08x%08x%08x%08x.\n",\r\nerr_sig_val[5], err_sig_val[4], err_sig_val[3],\r\nerr_sig_val[2], err_sig_val[1], err_sig_val[0]);\r\ndev_err(ccn->dev, "Disabling interrupt generation for all errors.\n");\r\nwritel(CCN_MN_ERRINT_STATUS__ALL_ERRORS__DISABLE,\r\nccn->base + CCN_MN_ERRINT_STATUS);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t arm_ccn_irq_handler(int irq, void *dev_id)\r\n{\r\nirqreturn_t res = IRQ_NONE;\r\nstruct arm_ccn *ccn = dev_id;\r\nu32 err_sig_val[6];\r\nu32 err_or;\r\nint i;\r\nerr_or = err_sig_val[0] = readl(ccn->base + CCN_MN_ERR_SIG_VAL_63_0);\r\nif (err_or & CCN_MN_ERR_SIG_VAL_63_0__DT) {\r\nerr_or &= ~CCN_MN_ERR_SIG_VAL_63_0__DT;\r\nres = arm_ccn_pmu_overflow_handler(&ccn->dt);\r\n}\r\nfor (i = 1; i < ARRAY_SIZE(err_sig_val); i++) {\r\nerr_sig_val[i] = readl(ccn->base +\r\nCCN_MN_ERR_SIG_VAL_63_0 + i * 4);\r\nerr_or |= err_sig_val[i];\r\n}\r\nif (err_or)\r\nres |= arm_ccn_error_handler(ccn, err_sig_val);\r\nif (res != IRQ_NONE)\r\nwritel(CCN_MN_ERRINT_STATUS__INTREQ__DESSERT,\r\nccn->base + CCN_MN_ERRINT_STATUS);\r\nreturn res;\r\n}\r\nstatic int arm_ccn_probe(struct platform_device *pdev)\r\n{\r\nstruct arm_ccn *ccn;\r\nstruct resource *res;\r\nint err;\r\nccn = devm_kzalloc(&pdev->dev, sizeof(*ccn), GFP_KERNEL);\r\nif (!ccn)\r\nreturn -ENOMEM;\r\nccn->dev = &pdev->dev;\r\nplatform_set_drvdata(pdev, ccn);\r\nres = platform_get_resource(pdev, IORESOURCE_MEM, 0);\r\nif (!res)\r\nreturn -EINVAL;\r\nif (!devm_request_mem_region(ccn->dev, res->start,\r\nresource_size(res), pdev->name))\r\nreturn -EBUSY;\r\nccn->base = devm_ioremap(ccn->dev, res->start,\r\nresource_size(res));\r\nif (!ccn->base)\r\nreturn -EFAULT;\r\nres = platform_get_resource(pdev, IORESOURCE_IRQ, 0);\r\nif (!res)\r\nreturn -EINVAL;\r\nwritel(CCN_MN_ERRINT_STATUS__PMU_EVENTS__DISABLE,\r\nccn->base + CCN_MN_ERRINT_STATUS);\r\nif (readl(ccn->base + CCN_MN_ERRINT_STATUS) &\r\nCCN_MN_ERRINT_STATUS__PMU_EVENTS__DISABLED) {\r\nwritel(CCN_MN_ERRINT_STATUS__PMU_EVENTS__ENABLE,\r\nccn->base + CCN_MN_ERRINT_STATUS);\r\nerr = devm_request_irq(ccn->dev, res->start,\r\narm_ccn_irq_handler, 0, dev_name(ccn->dev),\r\nccn);\r\nif (err)\r\nreturn err;\r\nccn->irq_used = 1;\r\n}\r\nerr = arm_ccn_for_each_valid_region(ccn, arm_ccn_get_nodes_num);\r\nif (err)\r\nreturn err;\r\nccn->node = devm_kzalloc(ccn->dev, sizeof(*ccn->node) * ccn->num_nodes,\r\nGFP_KERNEL);\r\nccn->xp = devm_kzalloc(ccn->dev, sizeof(*ccn->node) * ccn->num_xps,\r\nGFP_KERNEL);\r\nif (!ccn->node || !ccn->xp)\r\nreturn -ENOMEM;\r\nerr = arm_ccn_for_each_valid_region(ccn, arm_ccn_init_nodes);\r\nif (err)\r\nreturn err;\r\nreturn arm_ccn_pmu_init(ccn);\r\n}\r\nstatic int arm_ccn_remove(struct platform_device *pdev)\r\n{\r\nstruct arm_ccn *ccn = platform_get_drvdata(pdev);\r\narm_ccn_pmu_cleanup(ccn);\r\nreturn 0;\r\n}\r\nstatic int __init arm_ccn_init(void)\r\n{\r\nint i;\r\nfor (i = 0; i < ARRAY_SIZE(arm_ccn_pmu_events); i++)\r\narm_ccn_pmu_events_attrs[i] = &arm_ccn_pmu_events[i].attr.attr;\r\nreturn platform_driver_register(&arm_ccn_driver);\r\n}\r\nstatic void __exit arm_ccn_exit(void)\r\n{\r\nplatform_driver_unregister(&arm_ccn_driver);\r\n}
