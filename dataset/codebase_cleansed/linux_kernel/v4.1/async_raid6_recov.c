static struct dma_async_tx_descriptor *\r\nasync_sum_product(struct page *dest, struct page **srcs, unsigned char *coef,\r\nsize_t len, struct async_submit_ctl *submit)\r\n{\r\nstruct dma_chan *chan = async_tx_find_channel(submit, DMA_PQ,\r\n&dest, 1, srcs, 2, len);\r\nstruct dma_device *dma = chan ? chan->device : NULL;\r\nstruct dmaengine_unmap_data *unmap = NULL;\r\nconst u8 *amul, *bmul;\r\nu8 ax, bx;\r\nu8 *a, *b, *c;\r\nif (dma)\r\nunmap = dmaengine_get_unmap_data(dma->dev, 3, GFP_NOIO);\r\nif (unmap) {\r\nstruct device *dev = dma->dev;\r\ndma_addr_t pq[2];\r\nstruct dma_async_tx_descriptor *tx;\r\nenum dma_ctrl_flags dma_flags = DMA_PREP_PQ_DISABLE_P;\r\nif (submit->flags & ASYNC_TX_FENCE)\r\ndma_flags |= DMA_PREP_FENCE;\r\nunmap->addr[0] = dma_map_page(dev, srcs[0], 0, len, DMA_TO_DEVICE);\r\nunmap->addr[1] = dma_map_page(dev, srcs[1], 0, len, DMA_TO_DEVICE);\r\nunmap->to_cnt = 2;\r\nunmap->addr[2] = dma_map_page(dev, dest, 0, len, DMA_BIDIRECTIONAL);\r\nunmap->bidi_cnt = 1;\r\npq[1] = unmap->addr[2];\r\nunmap->len = len;\r\ntx = dma->device_prep_dma_pq(chan, pq, unmap->addr, 2, coef,\r\nlen, dma_flags);\r\nif (tx) {\r\ndma_set_unmap(tx, unmap);\r\nasync_tx_submit(chan, tx, submit);\r\ndmaengine_unmap_put(unmap);\r\nreturn tx;\r\n}\r\ndmaengine_unmap_put(unmap);\r\n}\r\nasync_tx_quiesce(&submit->depend_tx);\r\namul = raid6_gfmul[coef[0]];\r\nbmul = raid6_gfmul[coef[1]];\r\na = page_address(srcs[0]);\r\nb = page_address(srcs[1]);\r\nc = page_address(dest);\r\nwhile (len--) {\r\nax = amul[*a++];\r\nbx = bmul[*b++];\r\n*c++ = ax ^ bx;\r\n}\r\nreturn NULL;\r\n}\r\nstatic struct dma_async_tx_descriptor *\r\nasync_mult(struct page *dest, struct page *src, u8 coef, size_t len,\r\nstruct async_submit_ctl *submit)\r\n{\r\nstruct dma_chan *chan = async_tx_find_channel(submit, DMA_PQ,\r\n&dest, 1, &src, 1, len);\r\nstruct dma_device *dma = chan ? chan->device : NULL;\r\nstruct dmaengine_unmap_data *unmap = NULL;\r\nconst u8 *qmul;\r\nu8 *d, *s;\r\nif (dma)\r\nunmap = dmaengine_get_unmap_data(dma->dev, 3, GFP_NOIO);\r\nif (unmap) {\r\ndma_addr_t dma_dest[2];\r\nstruct device *dev = dma->dev;\r\nstruct dma_async_tx_descriptor *tx;\r\nenum dma_ctrl_flags dma_flags = DMA_PREP_PQ_DISABLE_P;\r\nif (submit->flags & ASYNC_TX_FENCE)\r\ndma_flags |= DMA_PREP_FENCE;\r\nunmap->addr[0] = dma_map_page(dev, src, 0, len, DMA_TO_DEVICE);\r\nunmap->to_cnt++;\r\nunmap->addr[1] = dma_map_page(dev, dest, 0, len, DMA_BIDIRECTIONAL);\r\ndma_dest[1] = unmap->addr[1];\r\nunmap->bidi_cnt++;\r\nunmap->len = len;\r\ntx = dma->device_prep_dma_pq(chan, dma_dest, unmap->addr,\r\n1, &coef, len, dma_flags);\r\nif (tx) {\r\ndma_set_unmap(tx, unmap);\r\ndmaengine_unmap_put(unmap);\r\nasync_tx_submit(chan, tx, submit);\r\nreturn tx;\r\n}\r\ndmaengine_unmap_put(unmap);\r\n}\r\nasync_tx_quiesce(&submit->depend_tx);\r\nqmul = raid6_gfmul[coef];\r\nd = page_address(dest);\r\ns = page_address(src);\r\nwhile (len--)\r\n*d++ = qmul[*s++];\r\nreturn NULL;\r\n}\r\nstatic struct dma_async_tx_descriptor *\r\n__2data_recov_4(int disks, size_t bytes, int faila, int failb,\r\nstruct page **blocks, struct async_submit_ctl *submit)\r\n{\r\nstruct dma_async_tx_descriptor *tx = NULL;\r\nstruct page *p, *q, *a, *b;\r\nstruct page *srcs[2];\r\nunsigned char coef[2];\r\nenum async_tx_flags flags = submit->flags;\r\ndma_async_tx_callback cb_fn = submit->cb_fn;\r\nvoid *cb_param = submit->cb_param;\r\nvoid *scribble = submit->scribble;\r\np = blocks[disks-2];\r\nq = blocks[disks-1];\r\na = blocks[faila];\r\nb = blocks[failb];\r\nsrcs[0] = p;\r\nsrcs[1] = q;\r\ncoef[0] = raid6_gfexi[failb-faila];\r\ncoef[1] = raid6_gfinv[raid6_gfexp[faila]^raid6_gfexp[failb]];\r\ninit_async_submit(submit, ASYNC_TX_FENCE, tx, NULL, NULL, scribble);\r\ntx = async_sum_product(b, srcs, coef, bytes, submit);\r\nsrcs[0] = p;\r\nsrcs[1] = b;\r\ninit_async_submit(submit, flags | ASYNC_TX_XOR_ZERO_DST, tx, cb_fn,\r\ncb_param, scribble);\r\ntx = async_xor(a, srcs, 0, 2, bytes, submit);\r\nreturn tx;\r\n}\r\nstatic struct dma_async_tx_descriptor *\r\n__2data_recov_5(int disks, size_t bytes, int faila, int failb,\r\nstruct page **blocks, struct async_submit_ctl *submit)\r\n{\r\nstruct dma_async_tx_descriptor *tx = NULL;\r\nstruct page *p, *q, *g, *dp, *dq;\r\nstruct page *srcs[2];\r\nunsigned char coef[2];\r\nenum async_tx_flags flags = submit->flags;\r\ndma_async_tx_callback cb_fn = submit->cb_fn;\r\nvoid *cb_param = submit->cb_param;\r\nvoid *scribble = submit->scribble;\r\nint good_srcs, good, i;\r\ngood_srcs = 0;\r\ngood = -1;\r\nfor (i = 0; i < disks-2; i++) {\r\nif (blocks[i] == NULL)\r\ncontinue;\r\nif (i == faila || i == failb)\r\ncontinue;\r\ngood = i;\r\ngood_srcs++;\r\n}\r\nBUG_ON(good_srcs > 1);\r\np = blocks[disks-2];\r\nq = blocks[disks-1];\r\ng = blocks[good];\r\ndp = blocks[faila];\r\ndq = blocks[failb];\r\ninit_async_submit(submit, ASYNC_TX_FENCE, tx, NULL, NULL, scribble);\r\ntx = async_memcpy(dp, g, 0, 0, bytes, submit);\r\ninit_async_submit(submit, ASYNC_TX_FENCE, tx, NULL, NULL, scribble);\r\ntx = async_mult(dq, g, raid6_gfexp[good], bytes, submit);\r\nsrcs[0] = dp;\r\nsrcs[1] = p;\r\ninit_async_submit(submit, ASYNC_TX_FENCE|ASYNC_TX_XOR_DROP_DST, tx,\r\nNULL, NULL, scribble);\r\ntx = async_xor(dp, srcs, 0, 2, bytes, submit);\r\nsrcs[0] = dq;\r\nsrcs[1] = q;\r\ninit_async_submit(submit, ASYNC_TX_FENCE|ASYNC_TX_XOR_DROP_DST, tx,\r\nNULL, NULL, scribble);\r\ntx = async_xor(dq, srcs, 0, 2, bytes, submit);\r\nsrcs[0] = dp;\r\nsrcs[1] = dq;\r\ncoef[0] = raid6_gfexi[failb-faila];\r\ncoef[1] = raid6_gfinv[raid6_gfexp[faila]^raid6_gfexp[failb]];\r\ninit_async_submit(submit, ASYNC_TX_FENCE, tx, NULL, NULL, scribble);\r\ntx = async_sum_product(dq, srcs, coef, bytes, submit);\r\nsrcs[0] = dp;\r\nsrcs[1] = dq;\r\ninit_async_submit(submit, flags | ASYNC_TX_XOR_DROP_DST, tx, cb_fn,\r\ncb_param, scribble);\r\ntx = async_xor(dp, srcs, 0, 2, bytes, submit);\r\nreturn tx;\r\n}\r\nstatic struct dma_async_tx_descriptor *\r\n__2data_recov_n(int disks, size_t bytes, int faila, int failb,\r\nstruct page **blocks, struct async_submit_ctl *submit)\r\n{\r\nstruct dma_async_tx_descriptor *tx = NULL;\r\nstruct page *p, *q, *dp, *dq;\r\nstruct page *srcs[2];\r\nunsigned char coef[2];\r\nenum async_tx_flags flags = submit->flags;\r\ndma_async_tx_callback cb_fn = submit->cb_fn;\r\nvoid *cb_param = submit->cb_param;\r\nvoid *scribble = submit->scribble;\r\np = blocks[disks-2];\r\nq = blocks[disks-1];\r\ndp = blocks[faila];\r\nblocks[faila] = NULL;\r\nblocks[disks-2] = dp;\r\ndq = blocks[failb];\r\nblocks[failb] = NULL;\r\nblocks[disks-1] = dq;\r\ninit_async_submit(submit, ASYNC_TX_FENCE, tx, NULL, NULL, scribble);\r\ntx = async_gen_syndrome(blocks, 0, disks, bytes, submit);\r\nblocks[faila] = dp;\r\nblocks[failb] = dq;\r\nblocks[disks-2] = p;\r\nblocks[disks-1] = q;\r\nsrcs[0] = dp;\r\nsrcs[1] = p;\r\ninit_async_submit(submit, ASYNC_TX_FENCE|ASYNC_TX_XOR_DROP_DST, tx,\r\nNULL, NULL, scribble);\r\ntx = async_xor(dp, srcs, 0, 2, bytes, submit);\r\nsrcs[0] = dq;\r\nsrcs[1] = q;\r\ninit_async_submit(submit, ASYNC_TX_FENCE|ASYNC_TX_XOR_DROP_DST, tx,\r\nNULL, NULL, scribble);\r\ntx = async_xor(dq, srcs, 0, 2, bytes, submit);\r\nsrcs[0] = dp;\r\nsrcs[1] = dq;\r\ncoef[0] = raid6_gfexi[failb-faila];\r\ncoef[1] = raid6_gfinv[raid6_gfexp[faila]^raid6_gfexp[failb]];\r\ninit_async_submit(submit, ASYNC_TX_FENCE, tx, NULL, NULL, scribble);\r\ntx = async_sum_product(dq, srcs, coef, bytes, submit);\r\nsrcs[0] = dp;\r\nsrcs[1] = dq;\r\ninit_async_submit(submit, flags | ASYNC_TX_XOR_DROP_DST, tx, cb_fn,\r\ncb_param, scribble);\r\ntx = async_xor(dp, srcs, 0, 2, bytes, submit);\r\nreturn tx;\r\n}\r\nstruct dma_async_tx_descriptor *\r\nasync_raid6_2data_recov(int disks, size_t bytes, int faila, int failb,\r\nstruct page **blocks, struct async_submit_ctl *submit)\r\n{\r\nvoid *scribble = submit->scribble;\r\nint non_zero_srcs, i;\r\nBUG_ON(faila == failb);\r\nif (failb < faila)\r\nswap(faila, failb);\r\npr_debug("%s: disks: %d len: %zu\n", __func__, disks, bytes);\r\nif (!async_dma_find_channel(DMA_PQ) || !scribble) {\r\nvoid **ptrs = scribble ? scribble : (void **) blocks;\r\nasync_tx_quiesce(&submit->depend_tx);\r\nfor (i = 0; i < disks; i++)\r\nif (blocks[i] == NULL)\r\nptrs[i] = (void *) raid6_empty_zero_page;\r\nelse\r\nptrs[i] = page_address(blocks[i]);\r\nraid6_2data_recov(disks, bytes, faila, failb, ptrs);\r\nasync_tx_sync_epilog(submit);\r\nreturn NULL;\r\n}\r\nnon_zero_srcs = 0;\r\nfor (i = 0; i < disks-2 && non_zero_srcs < 4; i++)\r\nif (blocks[i])\r\nnon_zero_srcs++;\r\nswitch (non_zero_srcs) {\r\ncase 0:\r\ncase 1:\r\nBUG();\r\ncase 2:\r\nreturn __2data_recov_4(disks, bytes, faila, failb, blocks, submit);\r\ncase 3:\r\nreturn __2data_recov_5(disks, bytes, faila, failb, blocks, submit);\r\ndefault:\r\nreturn __2data_recov_n(disks, bytes, faila, failb, blocks, submit);\r\n}\r\n}\r\nstruct dma_async_tx_descriptor *\r\nasync_raid6_datap_recov(int disks, size_t bytes, int faila,\r\nstruct page **blocks, struct async_submit_ctl *submit)\r\n{\r\nstruct dma_async_tx_descriptor *tx = NULL;\r\nstruct page *p, *q, *dq;\r\nu8 coef;\r\nenum async_tx_flags flags = submit->flags;\r\ndma_async_tx_callback cb_fn = submit->cb_fn;\r\nvoid *cb_param = submit->cb_param;\r\nvoid *scribble = submit->scribble;\r\nint good_srcs, good, i;\r\nstruct page *srcs[2];\r\npr_debug("%s: disks: %d len: %zu\n", __func__, disks, bytes);\r\nif (!async_dma_find_channel(DMA_PQ) || !scribble) {\r\nvoid **ptrs = scribble ? scribble : (void **) blocks;\r\nasync_tx_quiesce(&submit->depend_tx);\r\nfor (i = 0; i < disks; i++)\r\nif (blocks[i] == NULL)\r\nptrs[i] = (void*)raid6_empty_zero_page;\r\nelse\r\nptrs[i] = page_address(blocks[i]);\r\nraid6_datap_recov(disks, bytes, faila, ptrs);\r\nasync_tx_sync_epilog(submit);\r\nreturn NULL;\r\n}\r\ngood_srcs = 0;\r\ngood = -1;\r\nfor (i = 0; i < disks-2; i++) {\r\nif (i == faila)\r\ncontinue;\r\nif (blocks[i]) {\r\ngood = i;\r\ngood_srcs++;\r\nif (good_srcs > 1)\r\nbreak;\r\n}\r\n}\r\nBUG_ON(good_srcs == 0);\r\np = blocks[disks-2];\r\nq = blocks[disks-1];\r\ndq = blocks[faila];\r\nblocks[faila] = NULL;\r\nblocks[disks-1] = dq;\r\nif (good_srcs == 1) {\r\nstruct page *g = blocks[good];\r\ninit_async_submit(submit, ASYNC_TX_FENCE, tx, NULL, NULL,\r\nscribble);\r\ntx = async_memcpy(p, g, 0, 0, bytes, submit);\r\ninit_async_submit(submit, ASYNC_TX_FENCE, tx, NULL, NULL,\r\nscribble);\r\ntx = async_mult(dq, g, raid6_gfexp[good], bytes, submit);\r\n} else {\r\ninit_async_submit(submit, ASYNC_TX_FENCE, tx, NULL, NULL,\r\nscribble);\r\ntx = async_gen_syndrome(blocks, 0, disks, bytes, submit);\r\n}\r\nblocks[faila] = dq;\r\nblocks[disks-1] = q;\r\ncoef = raid6_gfinv[raid6_gfexp[faila]];\r\nsrcs[0] = dq;\r\nsrcs[1] = q;\r\ninit_async_submit(submit, ASYNC_TX_FENCE|ASYNC_TX_XOR_DROP_DST, tx,\r\nNULL, NULL, scribble);\r\ntx = async_xor(dq, srcs, 0, 2, bytes, submit);\r\ninit_async_submit(submit, ASYNC_TX_FENCE, tx, NULL, NULL, scribble);\r\ntx = async_mult(dq, dq, coef, bytes, submit);\r\nsrcs[0] = p;\r\nsrcs[1] = dq;\r\ninit_async_submit(submit, flags | ASYNC_TX_XOR_DROP_DST, tx, cb_fn,\r\ncb_param, scribble);\r\ntx = async_xor(p, srcs, 0, 2, bytes, submit);\r\nreturn tx;\r\n}
