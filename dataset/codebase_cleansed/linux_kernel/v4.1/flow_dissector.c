static void iph_to_flow_copy_addrs(struct flow_keys *flow, const struct iphdr *iph)\r\n{\r\nBUILD_BUG_ON(offsetof(typeof(*flow), dst) !=\r\noffsetof(typeof(*flow), src) + sizeof(flow->src));\r\nmemcpy(&flow->src, &iph->saddr, sizeof(flow->src) + sizeof(flow->dst));\r\n}\r\n__be32 __skb_flow_get_ports(const struct sk_buff *skb, int thoff, u8 ip_proto,\r\nvoid *data, int hlen)\r\n{\r\nint poff = proto_ports_offset(ip_proto);\r\nif (!data) {\r\ndata = skb->data;\r\nhlen = skb_headlen(skb);\r\n}\r\nif (poff >= 0) {\r\n__be32 *ports, _ports;\r\nports = __skb_header_pointer(skb, thoff + poff,\r\nsizeof(_ports), data, hlen, &_ports);\r\nif (ports)\r\nreturn *ports;\r\n}\r\nreturn 0;\r\n}\r\nbool __skb_flow_dissect(const struct sk_buff *skb, struct flow_keys *flow,\r\nvoid *data, __be16 proto, int nhoff, int hlen)\r\n{\r\nu8 ip_proto;\r\nif (!data) {\r\ndata = skb->data;\r\nproto = skb->protocol;\r\nnhoff = skb_network_offset(skb);\r\nhlen = skb_headlen(skb);\r\n}\r\nmemset(flow, 0, sizeof(*flow));\r\nagain:\r\nswitch (proto) {\r\ncase htons(ETH_P_IP): {\r\nconst struct iphdr *iph;\r\nstruct iphdr _iph;\r\nip:\r\niph = __skb_header_pointer(skb, nhoff, sizeof(_iph), data, hlen, &_iph);\r\nif (!iph || iph->ihl < 5)\r\nreturn false;\r\nnhoff += iph->ihl * 4;\r\nip_proto = iph->protocol;\r\nif (ip_is_fragment(iph))\r\nip_proto = 0;\r\nif (!skb)\r\nbreak;\r\niph_to_flow_copy_addrs(flow, iph);\r\nbreak;\r\n}\r\ncase htons(ETH_P_IPV6): {\r\nconst struct ipv6hdr *iph;\r\nstruct ipv6hdr _iph;\r\n__be32 flow_label;\r\nipv6:\r\niph = __skb_header_pointer(skb, nhoff, sizeof(_iph), data, hlen, &_iph);\r\nif (!iph)\r\nreturn false;\r\nip_proto = iph->nexthdr;\r\nnhoff += sizeof(struct ipv6hdr);\r\nif (!skb)\r\nbreak;\r\nflow->src = (__force __be32)ipv6_addr_hash(&iph->saddr);\r\nflow->dst = (__force __be32)ipv6_addr_hash(&iph->daddr);\r\nflow_label = ip6_flowlabel(iph);\r\nif (flow_label) {\r\nflow->n_proto = proto;\r\nflow->ip_proto = ip_proto;\r\nflow->ports = flow_label;\r\nflow->thoff = (u16)nhoff;\r\nreturn true;\r\n}\r\nbreak;\r\n}\r\ncase htons(ETH_P_8021AD):\r\ncase htons(ETH_P_8021Q): {\r\nconst struct vlan_hdr *vlan;\r\nstruct vlan_hdr _vlan;\r\nvlan = __skb_header_pointer(skb, nhoff, sizeof(_vlan), data, hlen, &_vlan);\r\nif (!vlan)\r\nreturn false;\r\nproto = vlan->h_vlan_encapsulated_proto;\r\nnhoff += sizeof(*vlan);\r\ngoto again;\r\n}\r\ncase htons(ETH_P_PPP_SES): {\r\nstruct {\r\nstruct pppoe_hdr hdr;\r\n__be16 proto;\r\n} *hdr, _hdr;\r\nhdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data, hlen, &_hdr);\r\nif (!hdr)\r\nreturn false;\r\nproto = hdr->proto;\r\nnhoff += PPPOE_SES_HLEN;\r\nswitch (proto) {\r\ncase htons(PPP_IP):\r\ngoto ip;\r\ncase htons(PPP_IPV6):\r\ngoto ipv6;\r\ndefault:\r\nreturn false;\r\n}\r\n}\r\ncase htons(ETH_P_TIPC): {\r\nstruct {\r\n__be32 pre[3];\r\n__be32 srcnode;\r\n} *hdr, _hdr;\r\nhdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data, hlen, &_hdr);\r\nif (!hdr)\r\nreturn false;\r\nflow->src = hdr->srcnode;\r\nflow->dst = 0;\r\nflow->n_proto = proto;\r\nflow->thoff = (u16)nhoff;\r\nreturn true;\r\n}\r\ncase htons(ETH_P_FCOE):\r\nflow->thoff = (u16)(nhoff + FCOE_HEADER_LEN);\r\ndefault:\r\nreturn false;\r\n}\r\nswitch (ip_proto) {\r\ncase IPPROTO_GRE: {\r\nstruct gre_hdr {\r\n__be16 flags;\r\n__be16 proto;\r\n} *hdr, _hdr;\r\nhdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data, hlen, &_hdr);\r\nif (!hdr)\r\nreturn false;\r\nif (!(hdr->flags & (GRE_VERSION|GRE_ROUTING))) {\r\nproto = hdr->proto;\r\nnhoff += 4;\r\nif (hdr->flags & GRE_CSUM)\r\nnhoff += 4;\r\nif (hdr->flags & GRE_KEY)\r\nnhoff += 4;\r\nif (hdr->flags & GRE_SEQ)\r\nnhoff += 4;\r\nif (proto == htons(ETH_P_TEB)) {\r\nconst struct ethhdr *eth;\r\nstruct ethhdr _eth;\r\neth = __skb_header_pointer(skb, nhoff,\r\nsizeof(_eth),\r\ndata, hlen, &_eth);\r\nif (!eth)\r\nreturn false;\r\nproto = eth->h_proto;\r\nnhoff += sizeof(*eth);\r\n}\r\ngoto again;\r\n}\r\nbreak;\r\n}\r\ncase IPPROTO_IPIP:\r\nproto = htons(ETH_P_IP);\r\ngoto ip;\r\ncase IPPROTO_IPV6:\r\nproto = htons(ETH_P_IPV6);\r\ngoto ipv6;\r\ndefault:\r\nbreak;\r\n}\r\nflow->n_proto = proto;\r\nflow->ip_proto = ip_proto;\r\nflow->thoff = (u16) nhoff;\r\nif (skb)\r\nflow->ports = __skb_flow_get_ports(skb, nhoff, ip_proto,\r\ndata, hlen);\r\nreturn true;\r\n}\r\nstatic __always_inline void __flow_hash_secret_init(void)\r\n{\r\nnet_get_random_once(&hashrnd, sizeof(hashrnd));\r\n}\r\nstatic __always_inline u32 __flow_hash_3words(u32 a, u32 b, u32 c)\r\n{\r\n__flow_hash_secret_init();\r\nreturn jhash_3words(a, b, c, hashrnd);\r\n}\r\nstatic inline u32 __flow_hash_from_keys(struct flow_keys *keys)\r\n{\r\nu32 hash;\r\nif (((__force u32)keys->dst < (__force u32)keys->src) ||\r\n(((__force u32)keys->dst == (__force u32)keys->src) &&\r\n((__force u16)keys->port16[1] < (__force u16)keys->port16[0]))) {\r\nswap(keys->dst, keys->src);\r\nswap(keys->port16[0], keys->port16[1]);\r\n}\r\nhash = __flow_hash_3words((__force u32)keys->dst,\r\n(__force u32)keys->src,\r\n(__force u32)keys->ports);\r\nif (!hash)\r\nhash = 1;\r\nreturn hash;\r\n}\r\nu32 flow_hash_from_keys(struct flow_keys *keys)\r\n{\r\nreturn __flow_hash_from_keys(keys);\r\n}\r\nvoid __skb_get_hash(struct sk_buff *skb)\r\n{\r\nstruct flow_keys keys;\r\nif (!skb_flow_dissect(skb, &keys))\r\nreturn;\r\nif (keys.ports)\r\nskb->l4_hash = 1;\r\nskb->sw_hash = 1;\r\nskb->hash = __flow_hash_from_keys(&keys);\r\n}\r\nu16 __skb_tx_hash(const struct net_device *dev, struct sk_buff *skb,\r\nunsigned int num_tx_queues)\r\n{\r\nu32 hash;\r\nu16 qoffset = 0;\r\nu16 qcount = num_tx_queues;\r\nif (skb_rx_queue_recorded(skb)) {\r\nhash = skb_get_rx_queue(skb);\r\nwhile (unlikely(hash >= num_tx_queues))\r\nhash -= num_tx_queues;\r\nreturn hash;\r\n}\r\nif (dev->num_tc) {\r\nu8 tc = netdev_get_prio_tc_map(dev, skb->priority);\r\nqoffset = dev->tc_to_txq[tc].offset;\r\nqcount = dev->tc_to_txq[tc].count;\r\n}\r\nreturn (u16) reciprocal_scale(skb_get_hash(skb), qcount) + qoffset;\r\n}\r\nu32 __skb_get_poff(const struct sk_buff *skb, void *data,\r\nconst struct flow_keys *keys, int hlen)\r\n{\r\nu32 poff = keys->thoff;\r\nswitch (keys->ip_proto) {\r\ncase IPPROTO_TCP: {\r\nconst u8 *doff;\r\nu8 _doff;\r\ndoff = __skb_header_pointer(skb, poff + 12, sizeof(_doff),\r\ndata, hlen, &_doff);\r\nif (!doff)\r\nreturn poff;\r\npoff += max_t(u32, sizeof(struct tcphdr), (*doff & 0xF0) >> 2);\r\nbreak;\r\n}\r\ncase IPPROTO_UDP:\r\ncase IPPROTO_UDPLITE:\r\npoff += sizeof(struct udphdr);\r\nbreak;\r\ncase IPPROTO_ICMP:\r\npoff += sizeof(struct icmphdr);\r\nbreak;\r\ncase IPPROTO_ICMPV6:\r\npoff += sizeof(struct icmp6hdr);\r\nbreak;\r\ncase IPPROTO_IGMP:\r\npoff += sizeof(struct igmphdr);\r\nbreak;\r\ncase IPPROTO_DCCP:\r\npoff += sizeof(struct dccp_hdr);\r\nbreak;\r\ncase IPPROTO_SCTP:\r\npoff += sizeof(struct sctphdr);\r\nbreak;\r\n}\r\nreturn poff;\r\n}\r\nu32 skb_get_poff(const struct sk_buff *skb)\r\n{\r\nstruct flow_keys keys;\r\nif (!skb_flow_dissect(skb, &keys))\r\nreturn 0;\r\nreturn __skb_get_poff(skb, skb->data, &keys, skb_headlen(skb));\r\n}\r\nstatic inline int get_xps_queue(struct net_device *dev, struct sk_buff *skb)\r\n{\r\n#ifdef CONFIG_XPS\r\nstruct xps_dev_maps *dev_maps;\r\nstruct xps_map *map;\r\nint queue_index = -1;\r\nrcu_read_lock();\r\ndev_maps = rcu_dereference(dev->xps_maps);\r\nif (dev_maps) {\r\nmap = rcu_dereference(\r\ndev_maps->cpu_map[skb->sender_cpu - 1]);\r\nif (map) {\r\nif (map->len == 1)\r\nqueue_index = map->queues[0];\r\nelse\r\nqueue_index = map->queues[reciprocal_scale(skb_get_hash(skb),\r\nmap->len)];\r\nif (unlikely(queue_index >= dev->real_num_tx_queues))\r\nqueue_index = -1;\r\n}\r\n}\r\nrcu_read_unlock();\r\nreturn queue_index;\r\n#else\r\nreturn -1;\r\n#endif\r\n}\r\nstatic u16 __netdev_pick_tx(struct net_device *dev, struct sk_buff *skb)\r\n{\r\nstruct sock *sk = skb->sk;\r\nint queue_index = sk_tx_queue_get(sk);\r\nif (queue_index < 0 || skb->ooo_okay ||\r\nqueue_index >= dev->real_num_tx_queues) {\r\nint new_index = get_xps_queue(dev, skb);\r\nif (new_index < 0)\r\nnew_index = skb_tx_hash(dev, skb);\r\nif (queue_index != new_index && sk &&\r\nrcu_access_pointer(sk->sk_dst_cache))\r\nsk_tx_queue_set(sk, new_index);\r\nqueue_index = new_index;\r\n}\r\nreturn queue_index;\r\n}\r\nstruct netdev_queue *netdev_pick_tx(struct net_device *dev,\r\nstruct sk_buff *skb,\r\nvoid *accel_priv)\r\n{\r\nint queue_index = 0;\r\n#ifdef CONFIG_XPS\r\nif (skb->sender_cpu == 0)\r\nskb->sender_cpu = raw_smp_processor_id() + 1;\r\n#endif\r\nif (dev->real_num_tx_queues != 1) {\r\nconst struct net_device_ops *ops = dev->netdev_ops;\r\nif (ops->ndo_select_queue)\r\nqueue_index = ops->ndo_select_queue(dev, skb, accel_priv,\r\n__netdev_pick_tx);\r\nelse\r\nqueue_index = __netdev_pick_tx(dev, skb);\r\nif (!accel_priv)\r\nqueue_index = netdev_cap_txqueue(dev, queue_index);\r\n}\r\nskb_set_queue_mapping(skb, queue_index);\r\nreturn netdev_get_tx_queue(dev, queue_index);\r\n}
