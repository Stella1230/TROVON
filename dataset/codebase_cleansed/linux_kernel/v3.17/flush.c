void flush_cache_range(struct vm_area_struct *vma, unsigned long start,\r\nunsigned long end)\r\n{\r\nif (vma->vm_flags & VM_EXEC)\r\n__flush_icache_all();\r\n}\r\nstatic void flush_ptrace_access(struct vm_area_struct *vma, struct page *page,\r\nunsigned long uaddr, void *kaddr,\r\nunsigned long len)\r\n{\r\nif (vma->vm_flags & VM_EXEC) {\r\nunsigned long addr = (unsigned long)kaddr;\r\nif (icache_is_aliasing()) {\r\n__flush_dcache_area(kaddr, len);\r\n__flush_icache_all();\r\n} else {\r\nflush_icache_range(addr, addr + len);\r\n}\r\n}\r\n}\r\nvoid copy_to_user_page(struct vm_area_struct *vma, struct page *page,\r\nunsigned long uaddr, void *dst, const void *src,\r\nunsigned long len)\r\n{\r\n#ifdef CONFIG_SMP\r\npreempt_disable();\r\n#endif\r\nmemcpy(dst, src, len);\r\nflush_ptrace_access(vma, page, uaddr, dst, len);\r\n#ifdef CONFIG_SMP\r\npreempt_enable();\r\n#endif\r\n}\r\nvoid __sync_icache_dcache(pte_t pte, unsigned long addr)\r\n{\r\nstruct page *page = pte_page(pte);\r\nif (!page_mapping(page))\r\nreturn;\r\nif (!test_and_set_bit(PG_dcache_clean, &page->flags)) {\r\n__flush_dcache_area(page_address(page),\r\nPAGE_SIZE << compound_order(page));\r\n__flush_icache_all();\r\n} else if (icache_is_aivivt()) {\r\n__flush_icache_all();\r\n}\r\n}\r\nvoid flush_dcache_page(struct page *page)\r\n{\r\nif (test_bit(PG_dcache_clean, &page->flags))\r\nclear_bit(PG_dcache_clean, &page->flags);\r\n}
