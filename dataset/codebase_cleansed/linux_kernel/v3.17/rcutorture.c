static u64 notrace rcu_trace_clock_local(void)\r\n{\r\nu64 ts = trace_clock_local();\r\nunsigned long __maybe_unused ts_rem = do_div(ts, NSEC_PER_USEC);\r\nreturn ts;\r\n}\r\nstatic u64 notrace rcu_trace_clock_local(void)\r\n{\r\nreturn 0ULL;\r\n}\r\nstatic struct rcu_torture *\r\nrcu_torture_alloc(void)\r\n{\r\nstruct list_head *p;\r\nspin_lock_bh(&rcu_torture_lock);\r\nif (list_empty(&rcu_torture_freelist)) {\r\natomic_inc(&n_rcu_torture_alloc_fail);\r\nspin_unlock_bh(&rcu_torture_lock);\r\nreturn NULL;\r\n}\r\natomic_inc(&n_rcu_torture_alloc);\r\np = rcu_torture_freelist.next;\r\nlist_del_init(p);\r\nspin_unlock_bh(&rcu_torture_lock);\r\nreturn container_of(p, struct rcu_torture, rtort_free);\r\n}\r\nstatic void\r\nrcu_torture_free(struct rcu_torture *p)\r\n{\r\natomic_inc(&n_rcu_torture_free);\r\nspin_lock_bh(&rcu_torture_lock);\r\nlist_add_tail(&p->rtort_free, &rcu_torture_freelist);\r\nspin_unlock_bh(&rcu_torture_lock);\r\n}\r\nstatic int rcu_torture_read_lock(void) __acquires(RCU)\r\n{\r\nrcu_read_lock();\r\nreturn 0;\r\n}\r\nstatic void rcu_read_delay(struct torture_random_state *rrsp)\r\n{\r\nconst unsigned long shortdelay_us = 200;\r\nconst unsigned long longdelay_ms = 50;\r\nif (!(torture_random(rrsp) % (nrealreaders * 2000 * longdelay_ms)))\r\nmdelay(longdelay_ms);\r\nif (!(torture_random(rrsp) % (nrealreaders * 2 * shortdelay_us)))\r\nudelay(shortdelay_us);\r\n#ifdef CONFIG_PREEMPT\r\nif (!preempt_count() &&\r\n!(torture_random(rrsp) % (nrealreaders * 20000)))\r\npreempt_schedule();\r\n#endif\r\n}\r\nstatic void rcu_torture_read_unlock(int idx) __releases(RCU)\r\n{\r\nrcu_read_unlock();\r\n}\r\nstatic int rcu_torture_completed(void)\r\n{\r\nreturn rcu_batches_completed();\r\n}\r\nstatic bool\r\nrcu_torture_pipe_update_one(struct rcu_torture *rp)\r\n{\r\nint i;\r\ni = rp->rtort_pipe_count;\r\nif (i > RCU_TORTURE_PIPE_LEN)\r\ni = RCU_TORTURE_PIPE_LEN;\r\natomic_inc(&rcu_torture_wcount[i]);\r\nif (++rp->rtort_pipe_count >= RCU_TORTURE_PIPE_LEN) {\r\nrp->rtort_mbtest = 0;\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic void\r\nrcu_torture_pipe_update(struct rcu_torture *old_rp)\r\n{\r\nstruct rcu_torture *rp;\r\nstruct rcu_torture *rp1;\r\nif (old_rp)\r\nlist_add(&old_rp->rtort_free, &rcu_torture_removed);\r\nlist_for_each_entry_safe(rp, rp1, &rcu_torture_removed, rtort_free) {\r\nif (rcu_torture_pipe_update_one(rp)) {\r\nlist_del(&rp->rtort_free);\r\nrcu_torture_free(rp);\r\n}\r\n}\r\n}\r\nstatic void\r\nrcu_torture_cb(struct rcu_head *p)\r\n{\r\nstruct rcu_torture *rp = container_of(p, struct rcu_torture, rtort_rcu);\r\nif (torture_must_stop_irq()) {\r\nreturn;\r\n}\r\nif (rcu_torture_pipe_update_one(rp))\r\nrcu_torture_free(rp);\r\nelse\r\ncur_ops->deferred_free(rp);\r\n}\r\nstatic int rcu_no_completed(void)\r\n{\r\nreturn 0;\r\n}\r\nstatic void rcu_torture_deferred_free(struct rcu_torture *p)\r\n{\r\ncall_rcu(&p->rtort_rcu, rcu_torture_cb);\r\n}\r\nstatic void rcu_sync_torture_init(void)\r\n{\r\nINIT_LIST_HEAD(&rcu_torture_removed);\r\n}\r\nstatic int rcu_bh_torture_read_lock(void) __acquires(RCU_BH)\r\n{\r\nrcu_read_lock_bh();\r\nreturn 0;\r\n}\r\nstatic void rcu_bh_torture_read_unlock(int idx) __releases(RCU_BH)\r\n{\r\nrcu_read_unlock_bh();\r\n}\r\nstatic int rcu_bh_torture_completed(void)\r\n{\r\nreturn rcu_batches_completed_bh();\r\n}\r\nstatic void rcu_bh_torture_deferred_free(struct rcu_torture *p)\r\n{\r\ncall_rcu_bh(&p->rtort_rcu, rcu_torture_cb);\r\n}\r\nstatic void rcu_busted_torture_deferred_free(struct rcu_torture *p)\r\n{\r\nrcu_torture_cb(&p->rtort_rcu);\r\n}\r\nstatic void synchronize_rcu_busted(void)\r\n{\r\n}\r\nstatic void\r\ncall_rcu_busted(struct rcu_head *head, void (*func)(struct rcu_head *rcu))\r\n{\r\nfunc(head);\r\n}\r\nstatic int srcu_torture_read_lock(void) __acquires(&srcu_ctl\r\nstatic void srcu_read_delay(struct torture_random_state *rrsp)\r\n{\r\nlong delay;\r\nconst long uspertick = 1000000 / HZ;\r\nconst long longdelay = 10;\r\ndelay = torture_random(rrsp) %\r\n(nrealreaders * 2 * longdelay * uspertick);\r\nif (!delay)\r\nschedule_timeout_interruptible(longdelay);\r\nelse\r\nrcu_read_delay(rrsp);\r\n}\r\nstatic void srcu_torture_read_unlock(int idx) __releases(&srcu_ctl\r\nstatic int srcu_torture_completed(void)\r\n{\r\nreturn srcu_batches_completed(&srcu_ctl);\r\n}\r\nstatic void srcu_torture_deferred_free(struct rcu_torture *rp)\r\n{\r\ncall_srcu(&srcu_ctl, &rp->rtort_rcu, rcu_torture_cb);\r\n}\r\nstatic void srcu_torture_synchronize(void)\r\n{\r\nsynchronize_srcu(&srcu_ctl);\r\n}\r\nstatic void srcu_torture_call(struct rcu_head *head,\r\nvoid (*func)(struct rcu_head *head))\r\n{\r\ncall_srcu(&srcu_ctl, head, func);\r\n}\r\nstatic void srcu_torture_barrier(void)\r\n{\r\nsrcu_barrier(&srcu_ctl);\r\n}\r\nstatic void srcu_torture_stats(char *page)\r\n{\r\nint cpu;\r\nint idx = srcu_ctl.completed & 0x1;\r\npage += sprintf(page, "%s%s per-CPU(idx=%d):",\r\ntorture_type, TORTURE_FLAG, idx);\r\nfor_each_possible_cpu(cpu) {\r\nlong c0, c1;\r\nc0 = (long)per_cpu_ptr(srcu_ctl.per_cpu_ref, cpu)->c[!idx];\r\nc1 = (long)per_cpu_ptr(srcu_ctl.per_cpu_ref, cpu)->c[idx];\r\npage += sprintf(page, " %d(%ld,%ld)", cpu, c0, c1);\r\n}\r\nsprintf(page, "\n");\r\n}\r\nstatic void srcu_torture_synchronize_expedited(void)\r\n{\r\nsynchronize_srcu_expedited(&srcu_ctl);\r\n}\r\nstatic int sched_torture_read_lock(void)\r\n{\r\npreempt_disable();\r\nreturn 0;\r\n}\r\nstatic void sched_torture_read_unlock(int idx)\r\n{\r\npreempt_enable();\r\n}\r\nstatic void rcu_sched_torture_deferred_free(struct rcu_torture *p)\r\n{\r\ncall_rcu_sched(&p->rtort_rcu, rcu_torture_cb);\r\n}\r\nstatic void rcu_torture_boost_cb(struct rcu_head *head)\r\n{\r\nstruct rcu_boost_inflight *rbip =\r\ncontainer_of(head, struct rcu_boost_inflight, rcu);\r\nsmp_mb();\r\nrbip->inflight = 0;\r\n}\r\nstatic int rcu_torture_boost(void *arg)\r\n{\r\nunsigned long call_rcu_time;\r\nunsigned long endtime;\r\nunsigned long oldstarttime;\r\nstruct rcu_boost_inflight rbi = { .inflight = 0 };\r\nstruct sched_param sp;\r\nVERBOSE_TOROUT_STRING("rcu_torture_boost started");\r\nsp.sched_priority = 1;\r\nif (sched_setscheduler(current, SCHED_FIFO, &sp) < 0) {\r\nVERBOSE_TOROUT_STRING("rcu_torture_boost RT prio failed!");\r\nn_rcu_torture_boost_rterror++;\r\n}\r\ninit_rcu_head_on_stack(&rbi.rcu);\r\ndo {\r\noldstarttime = boost_starttime;\r\nwhile (ULONG_CMP_LT(jiffies, oldstarttime)) {\r\nschedule_timeout_interruptible(oldstarttime - jiffies);\r\nstutter_wait("rcu_torture_boost");\r\nif (torture_must_stop())\r\ngoto checkwait;\r\n}\r\nendtime = oldstarttime + test_boost_duration * HZ;\r\ncall_rcu_time = jiffies;\r\nwhile (ULONG_CMP_LT(jiffies, endtime)) {\r\nif (!rbi.inflight) {\r\nsmp_mb();\r\nrbi.inflight = 1;\r\ncall_rcu(&rbi.rcu, rcu_torture_boost_cb);\r\nif (jiffies - call_rcu_time >\r\ntest_boost_duration * HZ - HZ / 2) {\r\nVERBOSE_TOROUT_STRING("rcu_torture_boost boosting failed");\r\nn_rcu_torture_boost_failure++;\r\n}\r\ncall_rcu_time = jiffies;\r\n}\r\ncond_resched();\r\nstutter_wait("rcu_torture_boost");\r\nif (torture_must_stop())\r\ngoto checkwait;\r\n}\r\nwhile (oldstarttime == boost_starttime &&\r\n!kthread_should_stop()) {\r\nif (mutex_trylock(&boost_mutex)) {\r\nboost_starttime = jiffies +\r\ntest_boost_interval * HZ;\r\nn_rcu_torture_boosts++;\r\nmutex_unlock(&boost_mutex);\r\nbreak;\r\n}\r\nschedule_timeout_uninterruptible(1);\r\n}\r\ncheckwait: stutter_wait("rcu_torture_boost");\r\n} while (!torture_must_stop());\r\nwhile (!kthread_should_stop() || rbi.inflight) {\r\ntorture_shutdown_absorb("rcu_torture_boost");\r\nschedule_timeout_uninterruptible(1);\r\n}\r\nsmp_mb();\r\ndestroy_rcu_head_on_stack(&rbi.rcu);\r\ntorture_kthread_stopping("rcu_torture_boost");\r\nreturn 0;\r\n}\r\nstatic int\r\nrcu_torture_fqs(void *arg)\r\n{\r\nunsigned long fqs_resume_time;\r\nint fqs_burst_remaining;\r\nVERBOSE_TOROUT_STRING("rcu_torture_fqs task started");\r\ndo {\r\nfqs_resume_time = jiffies + fqs_stutter * HZ;\r\nwhile (ULONG_CMP_LT(jiffies, fqs_resume_time) &&\r\n!kthread_should_stop()) {\r\nschedule_timeout_interruptible(1);\r\n}\r\nfqs_burst_remaining = fqs_duration;\r\nwhile (fqs_burst_remaining > 0 &&\r\n!kthread_should_stop()) {\r\ncur_ops->fqs();\r\nudelay(fqs_holdoff);\r\nfqs_burst_remaining -= fqs_holdoff;\r\n}\r\nstutter_wait("rcu_torture_fqs");\r\n} while (!torture_must_stop());\r\ntorture_kthread_stopping("rcu_torture_fqs");\r\nreturn 0;\r\n}\r\nstatic int\r\nrcu_torture_writer(void *arg)\r\n{\r\nunsigned long gp_snap;\r\nbool gp_cond1 = gp_cond, gp_exp1 = gp_exp, gp_normal1 = gp_normal;\r\nbool gp_sync1 = gp_sync;\r\nint i;\r\nstruct rcu_torture *rp;\r\nstruct rcu_torture *old_rp;\r\nstatic DEFINE_TORTURE_RANDOM(rand);\r\nint synctype[] = { RTWS_DEF_FREE, RTWS_EXP_SYNC,\r\nRTWS_COND_GET, RTWS_SYNC };\r\nint nsynctypes = 0;\r\nVERBOSE_TOROUT_STRING("rcu_torture_writer task started");\r\nif (!gp_cond1 && !gp_exp1 && !gp_normal1 && !gp_sync)\r\ngp_cond1 = gp_exp1 = gp_normal1 = gp_sync1 = true;\r\nif (gp_cond1 && cur_ops->get_state && cur_ops->cond_sync)\r\nsynctype[nsynctypes++] = RTWS_COND_GET;\r\nelse if (gp_cond && (!cur_ops->get_state || !cur_ops->cond_sync))\r\npr_alert("rcu_torture_writer: gp_cond without primitives.\n");\r\nif (gp_exp1 && cur_ops->exp_sync)\r\nsynctype[nsynctypes++] = RTWS_EXP_SYNC;\r\nelse if (gp_exp && !cur_ops->exp_sync)\r\npr_alert("rcu_torture_writer: gp_exp without primitives.\n");\r\nif (gp_normal1 && cur_ops->deferred_free)\r\nsynctype[nsynctypes++] = RTWS_DEF_FREE;\r\nelse if (gp_normal && !cur_ops->deferred_free)\r\npr_alert("rcu_torture_writer: gp_normal without primitives.\n");\r\nif (gp_sync1 && cur_ops->sync)\r\nsynctype[nsynctypes++] = RTWS_SYNC;\r\nelse if (gp_sync && !cur_ops->sync)\r\npr_alert("rcu_torture_writer: gp_sync without primitives.\n");\r\nif (WARN_ONCE(nsynctypes == 0,\r\n"rcu_torture_writer: No update-side primitives.\n")) {\r\nrcu_torture_writer_state = RTWS_STOPPING;\r\ntorture_kthread_stopping("rcu_torture_writer");\r\n}\r\ndo {\r\nrcu_torture_writer_state = RTWS_FIXED_DELAY;\r\nschedule_timeout_uninterruptible(1);\r\nrp = rcu_torture_alloc();\r\nif (rp == NULL)\r\ncontinue;\r\nrp->rtort_pipe_count = 0;\r\nrcu_torture_writer_state = RTWS_DELAY;\r\nudelay(torture_random(&rand) & 0x3ff);\r\nrcu_torture_writer_state = RTWS_REPLACE;\r\nold_rp = rcu_dereference_check(rcu_torture_current,\r\ncurrent == writer_task);\r\nrp->rtort_mbtest = 1;\r\nrcu_assign_pointer(rcu_torture_current, rp);\r\nsmp_wmb();\r\nif (old_rp) {\r\ni = old_rp->rtort_pipe_count;\r\nif (i > RCU_TORTURE_PIPE_LEN)\r\ni = RCU_TORTURE_PIPE_LEN;\r\natomic_inc(&rcu_torture_wcount[i]);\r\nold_rp->rtort_pipe_count++;\r\nswitch (synctype[torture_random(&rand) % nsynctypes]) {\r\ncase RTWS_DEF_FREE:\r\nrcu_torture_writer_state = RTWS_DEF_FREE;\r\ncur_ops->deferred_free(old_rp);\r\nbreak;\r\ncase RTWS_EXP_SYNC:\r\nrcu_torture_writer_state = RTWS_EXP_SYNC;\r\ncur_ops->exp_sync();\r\nrcu_torture_pipe_update(old_rp);\r\nbreak;\r\ncase RTWS_COND_GET:\r\nrcu_torture_writer_state = RTWS_COND_GET;\r\ngp_snap = cur_ops->get_state();\r\ni = torture_random(&rand) % 16;\r\nif (i != 0)\r\nschedule_timeout_interruptible(i);\r\nudelay(torture_random(&rand) % 1000);\r\nrcu_torture_writer_state = RTWS_COND_SYNC;\r\ncur_ops->cond_sync(gp_snap);\r\nrcu_torture_pipe_update(old_rp);\r\nbreak;\r\ncase RTWS_SYNC:\r\nrcu_torture_writer_state = RTWS_SYNC;\r\ncur_ops->sync();\r\nrcu_torture_pipe_update(old_rp);\r\nbreak;\r\ndefault:\r\nWARN_ON_ONCE(1);\r\nbreak;\r\n}\r\n}\r\nrcutorture_record_progress(++rcu_torture_current_version);\r\nrcu_torture_writer_state = RTWS_STUTTER;\r\nstutter_wait("rcu_torture_writer");\r\n} while (!torture_must_stop());\r\nrcu_torture_writer_state = RTWS_STOPPING;\r\ntorture_kthread_stopping("rcu_torture_writer");\r\nreturn 0;\r\n}\r\nstatic int\r\nrcu_torture_fakewriter(void *arg)\r\n{\r\nDEFINE_TORTURE_RANDOM(rand);\r\nVERBOSE_TOROUT_STRING("rcu_torture_fakewriter task started");\r\nset_user_nice(current, MAX_NICE);\r\ndo {\r\nschedule_timeout_uninterruptible(1 + torture_random(&rand)%10);\r\nudelay(torture_random(&rand) & 0x3ff);\r\nif (cur_ops->cb_barrier != NULL &&\r\ntorture_random(&rand) % (nfakewriters * 8) == 0) {\r\ncur_ops->cb_barrier();\r\n} else if (gp_normal == gp_exp) {\r\nif (torture_random(&rand) & 0x80)\r\ncur_ops->sync();\r\nelse\r\ncur_ops->exp_sync();\r\n} else if (gp_normal) {\r\ncur_ops->sync();\r\n} else {\r\ncur_ops->exp_sync();\r\n}\r\nstutter_wait("rcu_torture_fakewriter");\r\n} while (!torture_must_stop());\r\ntorture_kthread_stopping("rcu_torture_fakewriter");\r\nreturn 0;\r\n}\r\nstatic void rcutorture_trace_dump(void)\r\n{\r\nstatic atomic_t beenhere = ATOMIC_INIT(0);\r\nif (atomic_read(&beenhere))\r\nreturn;\r\nif (atomic_xchg(&beenhere, 1) != 0)\r\nreturn;\r\nftrace_dump(DUMP_ALL);\r\n}\r\nstatic void rcu_torture_timer(unsigned long unused)\r\n{\r\nint idx;\r\nint completed;\r\nint completed_end;\r\nstatic DEFINE_TORTURE_RANDOM(rand);\r\nstatic DEFINE_SPINLOCK(rand_lock);\r\nstruct rcu_torture *p;\r\nint pipe_count;\r\nunsigned long long ts;\r\nidx = cur_ops->readlock();\r\ncompleted = cur_ops->completed();\r\nts = rcu_trace_clock_local();\r\np = rcu_dereference_check(rcu_torture_current,\r\nrcu_read_lock_bh_held() ||\r\nrcu_read_lock_sched_held() ||\r\nsrcu_read_lock_held(&srcu_ctl));\r\nif (p == NULL) {\r\ncur_ops->readunlock(idx);\r\nreturn;\r\n}\r\nif (p->rtort_mbtest == 0)\r\natomic_inc(&n_rcu_torture_mberror);\r\nspin_lock(&rand_lock);\r\ncur_ops->read_delay(&rand);\r\nn_rcu_torture_timers++;\r\nspin_unlock(&rand_lock);\r\npreempt_disable();\r\npipe_count = p->rtort_pipe_count;\r\nif (pipe_count > RCU_TORTURE_PIPE_LEN) {\r\npipe_count = RCU_TORTURE_PIPE_LEN;\r\n}\r\ncompleted_end = cur_ops->completed();\r\nif (pipe_count > 1) {\r\ndo_trace_rcu_torture_read(cur_ops->name, &p->rtort_rcu, ts,\r\ncompleted, completed_end);\r\nrcutorture_trace_dump();\r\n}\r\n__this_cpu_inc(rcu_torture_count[pipe_count]);\r\ncompleted = completed_end - completed;\r\nif (completed > RCU_TORTURE_PIPE_LEN) {\r\ncompleted = RCU_TORTURE_PIPE_LEN;\r\n}\r\n__this_cpu_inc(rcu_torture_batch[completed]);\r\npreempt_enable();\r\ncur_ops->readunlock(idx);\r\n}\r\nstatic int\r\nrcu_torture_reader(void *arg)\r\n{\r\nint completed;\r\nint completed_end;\r\nint idx;\r\nDEFINE_TORTURE_RANDOM(rand);\r\nstruct rcu_torture *p;\r\nint pipe_count;\r\nstruct timer_list t;\r\nunsigned long long ts;\r\nVERBOSE_TOROUT_STRING("rcu_torture_reader task started");\r\nset_user_nice(current, MAX_NICE);\r\nif (irqreader && cur_ops->irq_capable)\r\nsetup_timer_on_stack(&t, rcu_torture_timer, 0);\r\ndo {\r\nif (irqreader && cur_ops->irq_capable) {\r\nif (!timer_pending(&t))\r\nmod_timer(&t, jiffies + 1);\r\n}\r\nidx = cur_ops->readlock();\r\ncompleted = cur_ops->completed();\r\nts = rcu_trace_clock_local();\r\np = rcu_dereference_check(rcu_torture_current,\r\nrcu_read_lock_bh_held() ||\r\nrcu_read_lock_sched_held() ||\r\nsrcu_read_lock_held(&srcu_ctl));\r\nif (p == NULL) {\r\ncur_ops->readunlock(idx);\r\nschedule_timeout_interruptible(HZ);\r\ncontinue;\r\n}\r\nif (p->rtort_mbtest == 0)\r\natomic_inc(&n_rcu_torture_mberror);\r\ncur_ops->read_delay(&rand);\r\npreempt_disable();\r\npipe_count = p->rtort_pipe_count;\r\nif (pipe_count > RCU_TORTURE_PIPE_LEN) {\r\npipe_count = RCU_TORTURE_PIPE_LEN;\r\n}\r\ncompleted_end = cur_ops->completed();\r\nif (pipe_count > 1) {\r\ndo_trace_rcu_torture_read(cur_ops->name, &p->rtort_rcu,\r\nts, completed, completed_end);\r\nrcutorture_trace_dump();\r\n}\r\n__this_cpu_inc(rcu_torture_count[pipe_count]);\r\ncompleted = completed_end - completed;\r\nif (completed > RCU_TORTURE_PIPE_LEN) {\r\ncompleted = RCU_TORTURE_PIPE_LEN;\r\n}\r\n__this_cpu_inc(rcu_torture_batch[completed]);\r\npreempt_enable();\r\ncur_ops->readunlock(idx);\r\ncond_resched();\r\nstutter_wait("rcu_torture_reader");\r\n} while (!torture_must_stop());\r\nif (irqreader && cur_ops->irq_capable) {\r\ndel_timer_sync(&t);\r\ndestroy_timer_on_stack(&t);\r\n}\r\ntorture_kthread_stopping("rcu_torture_reader");\r\nreturn 0;\r\n}\r\nstatic void\r\nrcu_torture_printk(char *page)\r\n{\r\nint cpu;\r\nint i;\r\nlong pipesummary[RCU_TORTURE_PIPE_LEN + 1] = { 0 };\r\nlong batchsummary[RCU_TORTURE_PIPE_LEN + 1] = { 0 };\r\nstatic unsigned long rtcv_snap = ULONG_MAX;\r\nfor_each_possible_cpu(cpu) {\r\nfor (i = 0; i < RCU_TORTURE_PIPE_LEN + 1; i++) {\r\npipesummary[i] += per_cpu(rcu_torture_count, cpu)[i];\r\nbatchsummary[i] += per_cpu(rcu_torture_batch, cpu)[i];\r\n}\r\n}\r\nfor (i = RCU_TORTURE_PIPE_LEN - 1; i >= 0; i--) {\r\nif (pipesummary[i] != 0)\r\nbreak;\r\n}\r\npage += sprintf(page, "%s%s ", torture_type, TORTURE_FLAG);\r\npage += sprintf(page,\r\n"rtc: %p ver: %lu tfle: %d rta: %d rtaf: %d rtf: %d ",\r\nrcu_torture_current,\r\nrcu_torture_current_version,\r\nlist_empty(&rcu_torture_freelist),\r\natomic_read(&n_rcu_torture_alloc),\r\natomic_read(&n_rcu_torture_alloc_fail),\r\natomic_read(&n_rcu_torture_free));\r\npage += sprintf(page, "rtmbe: %d rtbke: %ld rtbre: %ld ",\r\natomic_read(&n_rcu_torture_mberror),\r\nn_rcu_torture_boost_ktrerror,\r\nn_rcu_torture_boost_rterror);\r\npage += sprintf(page, "rtbf: %ld rtb: %ld nt: %ld ",\r\nn_rcu_torture_boost_failure,\r\nn_rcu_torture_boosts,\r\nn_rcu_torture_timers);\r\npage = torture_onoff_stats(page);\r\npage += sprintf(page, "barrier: %ld/%ld:%ld",\r\nn_barrier_successes,\r\nn_barrier_attempts,\r\nn_rcu_torture_barrier_error);\r\npage += sprintf(page, "\n%s%s ", torture_type, TORTURE_FLAG);\r\nif (atomic_read(&n_rcu_torture_mberror) != 0 ||\r\nn_rcu_torture_barrier_error != 0 ||\r\nn_rcu_torture_boost_ktrerror != 0 ||\r\nn_rcu_torture_boost_rterror != 0 ||\r\nn_rcu_torture_boost_failure != 0 ||\r\ni > 1) {\r\npage += sprintf(page, "!!! ");\r\natomic_inc(&n_rcu_torture_error);\r\nWARN_ON_ONCE(1);\r\n}\r\npage += sprintf(page, "Reader Pipe: ");\r\nfor (i = 0; i < RCU_TORTURE_PIPE_LEN + 1; i++)\r\npage += sprintf(page, " %ld", pipesummary[i]);\r\npage += sprintf(page, "\n%s%s ", torture_type, TORTURE_FLAG);\r\npage += sprintf(page, "Reader Batch: ");\r\nfor (i = 0; i < RCU_TORTURE_PIPE_LEN + 1; i++)\r\npage += sprintf(page, " %ld", batchsummary[i]);\r\npage += sprintf(page, "\n%s%s ", torture_type, TORTURE_FLAG);\r\npage += sprintf(page, "Free-Block Circulation: ");\r\nfor (i = 0; i < RCU_TORTURE_PIPE_LEN + 1; i++) {\r\npage += sprintf(page, " %d",\r\natomic_read(&rcu_torture_wcount[i]));\r\n}\r\npage += sprintf(page, "\n");\r\nif (cur_ops->stats)\r\ncur_ops->stats(page);\r\nif (rtcv_snap == rcu_torture_current_version &&\r\nrcu_torture_current != NULL) {\r\nint __maybe_unused flags;\r\nunsigned long __maybe_unused gpnum;\r\nunsigned long __maybe_unused completed;\r\nrcutorture_get_gp_data(cur_ops->ttype,\r\n&flags, &gpnum, &completed);\r\npage += sprintf(page,\r\n"??? Writer stall state %d g%lu c%lu f%#x\n",\r\nrcu_torture_writer_state,\r\ngpnum, completed, flags);\r\nshow_rcu_gp_kthreads();\r\nrcutorture_trace_dump();\r\n}\r\nrtcv_snap = rcu_torture_current_version;\r\n}\r\nstatic void\r\nrcu_torture_stats_print(void)\r\n{\r\nint size = nr_cpu_ids * 200 + 8192;\r\nchar *buf;\r\nbuf = kmalloc(size, GFP_KERNEL);\r\nif (!buf) {\r\npr_err("rcu-torture: Out of memory, need: %d", size);\r\nreturn;\r\n}\r\nrcu_torture_printk(buf);\r\npr_alert("%s", buf);\r\nkfree(buf);\r\n}\r\nstatic int\r\nrcu_torture_stats(void *arg)\r\n{\r\nVERBOSE_TOROUT_STRING("rcu_torture_stats task started");\r\ndo {\r\nschedule_timeout_interruptible(stat_interval * HZ);\r\nrcu_torture_stats_print();\r\ntorture_shutdown_absorb("rcu_torture_stats");\r\n} while (!torture_must_stop());\r\ntorture_kthread_stopping("rcu_torture_stats");\r\nreturn 0;\r\n}\r\nstatic inline void\r\nrcu_torture_print_module_parms(struct rcu_torture_ops *cur_ops, const char *tag)\r\n{\r\npr_alert("%s" TORTURE_FLAG\r\n"--- %s: nreaders=%d nfakewriters=%d "\r\n"stat_interval=%d verbose=%d test_no_idle_hz=%d "\r\n"shuffle_interval=%d stutter=%d irqreader=%d "\r\n"fqs_duration=%d fqs_holdoff=%d fqs_stutter=%d "\r\n"test_boost=%d/%d test_boost_interval=%d "\r\n"test_boost_duration=%d shutdown_secs=%d "\r\n"stall_cpu=%d stall_cpu_holdoff=%d "\r\n"n_barrier_cbs=%d "\r\n"onoff_interval=%d onoff_holdoff=%d\n",\r\ntorture_type, tag, nrealreaders, nfakewriters,\r\nstat_interval, verbose, test_no_idle_hz, shuffle_interval,\r\nstutter, irqreader, fqs_duration, fqs_holdoff, fqs_stutter,\r\ntest_boost, cur_ops->can_boost,\r\ntest_boost_interval, test_boost_duration, shutdown_secs,\r\nstall_cpu, stall_cpu_holdoff,\r\nn_barrier_cbs,\r\nonoff_interval, onoff_holdoff);\r\n}\r\nstatic void rcutorture_booster_cleanup(int cpu)\r\n{\r\nstruct task_struct *t;\r\nif (boost_tasks[cpu] == NULL)\r\nreturn;\r\nmutex_lock(&boost_mutex);\r\nt = boost_tasks[cpu];\r\nboost_tasks[cpu] = NULL;\r\nmutex_unlock(&boost_mutex);\r\ntorture_stop_kthread(rcu_torture_boost, t);\r\n}\r\nstatic int rcutorture_booster_init(int cpu)\r\n{\r\nint retval;\r\nif (boost_tasks[cpu] != NULL)\r\nreturn 0;\r\nmutex_lock(&boost_mutex);\r\nVERBOSE_TOROUT_STRING("Creating rcu_torture_boost task");\r\nboost_tasks[cpu] = kthread_create_on_node(rcu_torture_boost, NULL,\r\ncpu_to_node(cpu),\r\n"rcu_torture_boost");\r\nif (IS_ERR(boost_tasks[cpu])) {\r\nretval = PTR_ERR(boost_tasks[cpu]);\r\nVERBOSE_TOROUT_STRING("rcu_torture_boost task create failed");\r\nn_rcu_torture_boost_ktrerror++;\r\nboost_tasks[cpu] = NULL;\r\nmutex_unlock(&boost_mutex);\r\nreturn retval;\r\n}\r\nkthread_bind(boost_tasks[cpu], cpu);\r\nwake_up_process(boost_tasks[cpu]);\r\nmutex_unlock(&boost_mutex);\r\nreturn 0;\r\n}\r\nstatic int rcu_torture_stall(void *args)\r\n{\r\nunsigned long stop_at;\r\nVERBOSE_TOROUT_STRING("rcu_torture_stall task started");\r\nif (stall_cpu_holdoff > 0) {\r\nVERBOSE_TOROUT_STRING("rcu_torture_stall begin holdoff");\r\nschedule_timeout_interruptible(stall_cpu_holdoff * HZ);\r\nVERBOSE_TOROUT_STRING("rcu_torture_stall end holdoff");\r\n}\r\nif (!kthread_should_stop()) {\r\nstop_at = get_seconds() + stall_cpu;\r\npr_alert("rcu_torture_stall start.\n");\r\nrcu_read_lock();\r\npreempt_disable();\r\nwhile (ULONG_CMP_LT(get_seconds(), stop_at))\r\ncontinue;\r\npreempt_enable();\r\nrcu_read_unlock();\r\npr_alert("rcu_torture_stall end.\n");\r\n}\r\ntorture_shutdown_absorb("rcu_torture_stall");\r\nwhile (!kthread_should_stop())\r\nschedule_timeout_interruptible(10 * HZ);\r\nreturn 0;\r\n}\r\nstatic int __init rcu_torture_stall_init(void)\r\n{\r\nif (stall_cpu <= 0)\r\nreturn 0;\r\nreturn torture_create_kthread(rcu_torture_stall, NULL, stall_task);\r\n}\r\nstatic void rcu_torture_barrier_cbf(struct rcu_head *rcu)\r\n{\r\natomic_inc(&barrier_cbs_invoked);\r\n}\r\nstatic int rcu_torture_barrier_cbs(void *arg)\r\n{\r\nlong myid = (long)arg;\r\nbool lastphase = 0;\r\nbool newphase;\r\nstruct rcu_head rcu;\r\ninit_rcu_head_on_stack(&rcu);\r\nVERBOSE_TOROUT_STRING("rcu_torture_barrier_cbs task started");\r\nset_user_nice(current, MAX_NICE);\r\ndo {\r\nwait_event(barrier_cbs_wq[myid],\r\n(newphase =\r\nACCESS_ONCE(barrier_phase)) != lastphase ||\r\ntorture_must_stop());\r\nlastphase = newphase;\r\nsmp_mb();\r\nif (torture_must_stop())\r\nbreak;\r\ncur_ops->call(&rcu, rcu_torture_barrier_cbf);\r\nif (atomic_dec_and_test(&barrier_cbs_count))\r\nwake_up(&barrier_wq);\r\n} while (!torture_must_stop());\r\ncur_ops->cb_barrier();\r\ndestroy_rcu_head_on_stack(&rcu);\r\ntorture_kthread_stopping("rcu_torture_barrier_cbs");\r\nreturn 0;\r\n}\r\nstatic int rcu_torture_barrier(void *arg)\r\n{\r\nint i;\r\nVERBOSE_TOROUT_STRING("rcu_torture_barrier task starting");\r\ndo {\r\natomic_set(&barrier_cbs_invoked, 0);\r\natomic_set(&barrier_cbs_count, n_barrier_cbs);\r\nsmp_mb();\r\nbarrier_phase = !barrier_phase;\r\nfor (i = 0; i < n_barrier_cbs; i++)\r\nwake_up(&barrier_cbs_wq[i]);\r\nwait_event(barrier_wq,\r\natomic_read(&barrier_cbs_count) == 0 ||\r\ntorture_must_stop());\r\nif (torture_must_stop())\r\nbreak;\r\nn_barrier_attempts++;\r\ncur_ops->cb_barrier();\r\nif (atomic_read(&barrier_cbs_invoked) != n_barrier_cbs) {\r\nn_rcu_torture_barrier_error++;\r\nWARN_ON_ONCE(1);\r\n}\r\nn_barrier_successes++;\r\nschedule_timeout_interruptible(HZ / 10);\r\n} while (!torture_must_stop());\r\ntorture_kthread_stopping("rcu_torture_barrier");\r\nreturn 0;\r\n}\r\nstatic int rcu_torture_barrier_init(void)\r\n{\r\nint i;\r\nint ret;\r\nif (n_barrier_cbs == 0)\r\nreturn 0;\r\nif (cur_ops->call == NULL || cur_ops->cb_barrier == NULL) {\r\npr_alert("%s" TORTURE_FLAG\r\n" Call or barrier ops missing for %s,\n",\r\ntorture_type, cur_ops->name);\r\npr_alert("%s" TORTURE_FLAG\r\n" RCU barrier testing omitted from run.\n",\r\ntorture_type);\r\nreturn 0;\r\n}\r\natomic_set(&barrier_cbs_count, 0);\r\natomic_set(&barrier_cbs_invoked, 0);\r\nbarrier_cbs_tasks =\r\nkzalloc(n_barrier_cbs * sizeof(barrier_cbs_tasks[0]),\r\nGFP_KERNEL);\r\nbarrier_cbs_wq =\r\nkzalloc(n_barrier_cbs * sizeof(barrier_cbs_wq[0]),\r\nGFP_KERNEL);\r\nif (barrier_cbs_tasks == NULL || !barrier_cbs_wq)\r\nreturn -ENOMEM;\r\nfor (i = 0; i < n_barrier_cbs; i++) {\r\ninit_waitqueue_head(&barrier_cbs_wq[i]);\r\nret = torture_create_kthread(rcu_torture_barrier_cbs,\r\n(void *)(long)i,\r\nbarrier_cbs_tasks[i]);\r\nif (ret)\r\nreturn ret;\r\n}\r\nreturn torture_create_kthread(rcu_torture_barrier, NULL, barrier_task);\r\n}\r\nstatic void rcu_torture_barrier_cleanup(void)\r\n{\r\nint i;\r\ntorture_stop_kthread(rcu_torture_barrier, barrier_task);\r\nif (barrier_cbs_tasks != NULL) {\r\nfor (i = 0; i < n_barrier_cbs; i++)\r\ntorture_stop_kthread(rcu_torture_barrier_cbs,\r\nbarrier_cbs_tasks[i]);\r\nkfree(barrier_cbs_tasks);\r\nbarrier_cbs_tasks = NULL;\r\n}\r\nif (barrier_cbs_wq != NULL) {\r\nkfree(barrier_cbs_wq);\r\nbarrier_cbs_wq = NULL;\r\n}\r\n}\r\nstatic int rcutorture_cpu_notify(struct notifier_block *self,\r\nunsigned long action, void *hcpu)\r\n{\r\nlong cpu = (long)hcpu;\r\nswitch (action) {\r\ncase CPU_ONLINE:\r\ncase CPU_DOWN_FAILED:\r\n(void)rcutorture_booster_init(cpu);\r\nbreak;\r\ncase CPU_DOWN_PREPARE:\r\nrcutorture_booster_cleanup(cpu);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn NOTIFY_OK;\r\n}\r\nstatic void\r\nrcu_torture_cleanup(void)\r\n{\r\nint i;\r\nrcutorture_record_test_transition();\r\nif (torture_cleanup()) {\r\nif (cur_ops->cb_barrier != NULL)\r\ncur_ops->cb_barrier();\r\nreturn;\r\n}\r\nrcu_torture_barrier_cleanup();\r\ntorture_stop_kthread(rcu_torture_stall, stall_task);\r\ntorture_stop_kthread(rcu_torture_writer, writer_task);\r\nif (reader_tasks) {\r\nfor (i = 0; i < nrealreaders; i++)\r\ntorture_stop_kthread(rcu_torture_reader,\r\nreader_tasks[i]);\r\nkfree(reader_tasks);\r\n}\r\nrcu_torture_current = NULL;\r\nif (fakewriter_tasks) {\r\nfor (i = 0; i < nfakewriters; i++) {\r\ntorture_stop_kthread(rcu_torture_fakewriter,\r\nfakewriter_tasks[i]);\r\n}\r\nkfree(fakewriter_tasks);\r\nfakewriter_tasks = NULL;\r\n}\r\ntorture_stop_kthread(rcu_torture_stats, stats_task);\r\ntorture_stop_kthread(rcu_torture_fqs, fqs_task);\r\nif ((test_boost == 1 && cur_ops->can_boost) ||\r\ntest_boost == 2) {\r\nunregister_cpu_notifier(&rcutorture_cpu_nb);\r\nfor_each_possible_cpu(i)\r\nrcutorture_booster_cleanup(i);\r\n}\r\nif (cur_ops->cb_barrier != NULL)\r\ncur_ops->cb_barrier();\r\nrcu_torture_stats_print();\r\nif (atomic_read(&n_rcu_torture_error) || n_rcu_torture_barrier_error)\r\nrcu_torture_print_module_parms(cur_ops, "End of test: FAILURE");\r\nelse if (torture_onoff_failures())\r\nrcu_torture_print_module_parms(cur_ops,\r\n"End of test: RCU_HOTPLUG");\r\nelse\r\nrcu_torture_print_module_parms(cur_ops, "End of test: SUCCESS");\r\n}\r\nstatic void rcu_torture_leak_cb(struct rcu_head *rhp)\r\n{\r\n}\r\nstatic void rcu_torture_err_cb(struct rcu_head *rhp)\r\n{\r\npr_alert("rcutorture: duplicated callback was invoked.\n");\r\n}\r\nstatic void rcu_test_debug_objects(void)\r\n{\r\n#ifdef CONFIG_DEBUG_OBJECTS_RCU_HEAD\r\nstruct rcu_head rh1;\r\nstruct rcu_head rh2;\r\ninit_rcu_head_on_stack(&rh1);\r\ninit_rcu_head_on_stack(&rh2);\r\npr_alert("rcutorture: WARN: Duplicate call_rcu() test starting.\n");\r\npreempt_disable();\r\nrcu_read_lock();\r\ncall_rcu(&rh1, rcu_torture_leak_cb);\r\nlocal_irq_disable();\r\ncall_rcu(&rh2, rcu_torture_leak_cb);\r\ncall_rcu(&rh2, rcu_torture_err_cb);\r\nlocal_irq_enable();\r\nrcu_read_unlock();\r\npreempt_enable();\r\nrcu_barrier();\r\npr_alert("rcutorture: WARN: Duplicate call_rcu() test complete.\n");\r\ndestroy_rcu_head_on_stack(&rh1);\r\ndestroy_rcu_head_on_stack(&rh2);\r\n#else\r\npr_alert("rcutorture: !CONFIG_DEBUG_OBJECTS_RCU_HEAD, not testing duplicate call_rcu()\n");\r\n#endif\r\n}\r\nstatic int __init\r\nrcu_torture_init(void)\r\n{\r\nint i;\r\nint cpu;\r\nint firsterr = 0;\r\nstatic struct rcu_torture_ops *torture_ops[] = {\r\n&rcu_ops, &rcu_bh_ops, &rcu_busted_ops, &srcu_ops, &sched_ops,\r\n};\r\nif (!torture_init_begin(torture_type, verbose, &rcutorture_runnable))\r\nreturn -EBUSY;\r\nfor (i = 0; i < ARRAY_SIZE(torture_ops); i++) {\r\ncur_ops = torture_ops[i];\r\nif (strcmp(torture_type, cur_ops->name) == 0)\r\nbreak;\r\n}\r\nif (i == ARRAY_SIZE(torture_ops)) {\r\npr_alert("rcu-torture: invalid torture type: \"%s\"\n",\r\ntorture_type);\r\npr_alert("rcu-torture types:");\r\nfor (i = 0; i < ARRAY_SIZE(torture_ops); i++)\r\npr_alert(" %s", torture_ops[i]->name);\r\npr_alert("\n");\r\ntorture_init_end();\r\nreturn -EINVAL;\r\n}\r\nif (cur_ops->fqs == NULL && fqs_duration != 0) {\r\npr_alert("rcu-torture: ->fqs NULL and non-zero fqs_duration, fqs disabled.\n");\r\nfqs_duration = 0;\r\n}\r\nif (cur_ops->init)\r\ncur_ops->init();\r\nif (nreaders >= 0) {\r\nnrealreaders = nreaders;\r\n} else {\r\nnrealreaders = num_online_cpus() - 1;\r\nif (nrealreaders <= 0)\r\nnrealreaders = 1;\r\n}\r\nrcu_torture_print_module_parms(cur_ops, "Start of test");\r\nINIT_LIST_HEAD(&rcu_torture_freelist);\r\nfor (i = 0; i < ARRAY_SIZE(rcu_tortures); i++) {\r\nrcu_tortures[i].rtort_mbtest = 0;\r\nlist_add_tail(&rcu_tortures[i].rtort_free,\r\n&rcu_torture_freelist);\r\n}\r\nrcu_torture_current = NULL;\r\nrcu_torture_current_version = 0;\r\natomic_set(&n_rcu_torture_alloc, 0);\r\natomic_set(&n_rcu_torture_alloc_fail, 0);\r\natomic_set(&n_rcu_torture_free, 0);\r\natomic_set(&n_rcu_torture_mberror, 0);\r\natomic_set(&n_rcu_torture_error, 0);\r\nn_rcu_torture_barrier_error = 0;\r\nn_rcu_torture_boost_ktrerror = 0;\r\nn_rcu_torture_boost_rterror = 0;\r\nn_rcu_torture_boost_failure = 0;\r\nn_rcu_torture_boosts = 0;\r\nfor (i = 0; i < RCU_TORTURE_PIPE_LEN + 1; i++)\r\natomic_set(&rcu_torture_wcount[i], 0);\r\nfor_each_possible_cpu(cpu) {\r\nfor (i = 0; i < RCU_TORTURE_PIPE_LEN + 1; i++) {\r\nper_cpu(rcu_torture_count, cpu)[i] = 0;\r\nper_cpu(rcu_torture_batch, cpu)[i] = 0;\r\n}\r\n}\r\nfirsterr = torture_create_kthread(rcu_torture_writer, NULL,\r\nwriter_task);\r\nif (firsterr)\r\ngoto unwind;\r\nfakewriter_tasks = kzalloc(nfakewriters * sizeof(fakewriter_tasks[0]),\r\nGFP_KERNEL);\r\nif (fakewriter_tasks == NULL) {\r\nVERBOSE_TOROUT_ERRSTRING("out of memory");\r\nfirsterr = -ENOMEM;\r\ngoto unwind;\r\n}\r\nfor (i = 0; i < nfakewriters; i++) {\r\nfirsterr = torture_create_kthread(rcu_torture_fakewriter,\r\nNULL, fakewriter_tasks[i]);\r\nif (firsterr)\r\ngoto unwind;\r\n}\r\nreader_tasks = kzalloc(nrealreaders * sizeof(reader_tasks[0]),\r\nGFP_KERNEL);\r\nif (reader_tasks == NULL) {\r\nVERBOSE_TOROUT_ERRSTRING("out of memory");\r\nfirsterr = -ENOMEM;\r\ngoto unwind;\r\n}\r\nfor (i = 0; i < nrealreaders; i++) {\r\nfirsterr = torture_create_kthread(rcu_torture_reader, NULL,\r\nreader_tasks[i]);\r\nif (firsterr)\r\ngoto unwind;\r\n}\r\nif (stat_interval > 0) {\r\nfirsterr = torture_create_kthread(rcu_torture_stats, NULL,\r\nstats_task);\r\nif (firsterr)\r\ngoto unwind;\r\n}\r\nif (test_no_idle_hz) {\r\nfirsterr = torture_shuffle_init(shuffle_interval * HZ);\r\nif (firsterr)\r\ngoto unwind;\r\n}\r\nif (stutter < 0)\r\nstutter = 0;\r\nif (stutter) {\r\nfirsterr = torture_stutter_init(stutter * HZ);\r\nif (firsterr)\r\ngoto unwind;\r\n}\r\nif (fqs_duration < 0)\r\nfqs_duration = 0;\r\nif (fqs_duration) {\r\nfirsterr = torture_create_kthread(rcu_torture_fqs, NULL,\r\nfqs_task);\r\nif (firsterr)\r\ngoto unwind;\r\n}\r\nif (test_boost_interval < 1)\r\ntest_boost_interval = 1;\r\nif (test_boost_duration < 2)\r\ntest_boost_duration = 2;\r\nif ((test_boost == 1 && cur_ops->can_boost) ||\r\ntest_boost == 2) {\r\nboost_starttime = jiffies + test_boost_interval * HZ;\r\nregister_cpu_notifier(&rcutorture_cpu_nb);\r\nfor_each_possible_cpu(i) {\r\nif (cpu_is_offline(i))\r\ncontinue;\r\nfirsterr = rcutorture_booster_init(i);\r\nif (firsterr)\r\ngoto unwind;\r\n}\r\n}\r\nfirsterr = torture_shutdown_init(shutdown_secs, rcu_torture_cleanup);\r\nif (firsterr)\r\ngoto unwind;\r\nfirsterr = torture_onoff_init(onoff_holdoff * HZ, onoff_interval * HZ);\r\nif (firsterr)\r\ngoto unwind;\r\nfirsterr = rcu_torture_stall_init();\r\nif (firsterr)\r\ngoto unwind;\r\nfirsterr = rcu_torture_barrier_init();\r\nif (firsterr)\r\ngoto unwind;\r\nif (object_debug)\r\nrcu_test_debug_objects();\r\nrcutorture_record_test_transition();\r\ntorture_init_end();\r\nreturn 0;\r\nunwind:\r\ntorture_init_end();\r\nrcu_torture_cleanup();\r\nreturn firsterr;\r\n}
