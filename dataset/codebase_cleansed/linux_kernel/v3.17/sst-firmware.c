static void sst_memcpy32(volatile void __iomem *dest, void *src, u32 bytes)\r\n{\r\nu32 i;\r\nfor (i = 0; i < bytes; i += 4)\r\nmemcpy_toio(dest + i, src + i, 4);\r\n}\r\nstruct sst_fw *sst_fw_new(struct sst_dsp *dsp,\r\nconst struct firmware *fw, void *private)\r\n{\r\nstruct sst_fw *sst_fw;\r\nint err;\r\nif (!dsp->ops->parse_fw)\r\nreturn NULL;\r\nsst_fw = kzalloc(sizeof(*sst_fw), GFP_KERNEL);\r\nif (sst_fw == NULL)\r\nreturn NULL;\r\nsst_fw->dsp = dsp;\r\nsst_fw->private = private;\r\nsst_fw->size = fw->size;\r\nsst_fw->dma_buf = dma_alloc_coherent(dsp->dma_dev, sst_fw->size,\r\n&sst_fw->dmable_fw_paddr, GFP_DMA | GFP_KERNEL);\r\nif (!sst_fw->dma_buf) {\r\ndev_err(dsp->dev, "error: DMA alloc failed\n");\r\nkfree(sst_fw);\r\nreturn NULL;\r\n}\r\nmemcpy((void *)sst_fw->dma_buf, (void *)fw->data, fw->size);\r\nerr = dsp->ops->parse_fw(sst_fw);\r\nif (err < 0) {\r\ndev_err(dsp->dev, "error: parse fw failed %d\n", err);\r\ngoto parse_err;\r\n}\r\nmutex_lock(&dsp->mutex);\r\nlist_add(&sst_fw->list, &dsp->fw_list);\r\nmutex_unlock(&dsp->mutex);\r\nreturn sst_fw;\r\nparse_err:\r\ndma_free_coherent(dsp->dev, sst_fw->size,\r\nsst_fw->dma_buf,\r\nsst_fw->dmable_fw_paddr);\r\nkfree(sst_fw);\r\nreturn NULL;\r\n}\r\nint sst_fw_reload(struct sst_fw *sst_fw)\r\n{\r\nstruct sst_dsp *dsp = sst_fw->dsp;\r\nint ret;\r\ndev_dbg(dsp->dev, "reloading firmware\n");\r\nret = dsp->ops->parse_fw(sst_fw);\r\nif (ret < 0)\r\ndev_err(dsp->dev, "error: parse fw failed %d\n", ret);\r\nreturn ret;\r\n}\r\nvoid sst_fw_unload(struct sst_fw *sst_fw)\r\n{\r\nstruct sst_dsp *dsp = sst_fw->dsp;\r\nstruct sst_module *module, *tmp;\r\ndev_dbg(dsp->dev, "unloading firmware\n");\r\nmutex_lock(&dsp->mutex);\r\nlist_for_each_entry_safe(module, tmp, &dsp->module_list, list) {\r\nif (module->sst_fw == sst_fw) {\r\nblock_module_remove(module);\r\nlist_del(&module->list);\r\nkfree(module);\r\n}\r\n}\r\nmutex_unlock(&dsp->mutex);\r\n}\r\nvoid sst_fw_free(struct sst_fw *sst_fw)\r\n{\r\nstruct sst_dsp *dsp = sst_fw->dsp;\r\nmutex_lock(&dsp->mutex);\r\nlist_del(&sst_fw->list);\r\nmutex_unlock(&dsp->mutex);\r\ndma_free_coherent(dsp->dma_dev, sst_fw->size, sst_fw->dma_buf,\r\nsst_fw->dmable_fw_paddr);\r\nkfree(sst_fw);\r\n}\r\nvoid sst_fw_free_all(struct sst_dsp *dsp)\r\n{\r\nstruct sst_fw *sst_fw, *t;\r\nmutex_lock(&dsp->mutex);\r\nlist_for_each_entry_safe(sst_fw, t, &dsp->fw_list, list) {\r\nlist_del(&sst_fw->list);\r\ndma_free_coherent(dsp->dev, sst_fw->size, sst_fw->dma_buf,\r\nsst_fw->dmable_fw_paddr);\r\nkfree(sst_fw);\r\n}\r\nmutex_unlock(&dsp->mutex);\r\n}\r\nstruct sst_module *sst_module_new(struct sst_fw *sst_fw,\r\nstruct sst_module_template *template, void *private)\r\n{\r\nstruct sst_dsp *dsp = sst_fw->dsp;\r\nstruct sst_module *sst_module;\r\nsst_module = kzalloc(sizeof(*sst_module), GFP_KERNEL);\r\nif (sst_module == NULL)\r\nreturn NULL;\r\nsst_module->id = template->id;\r\nsst_module->dsp = dsp;\r\nsst_module->sst_fw = sst_fw;\r\nmemcpy(&sst_module->s, &template->s, sizeof(struct sst_module_data));\r\nmemcpy(&sst_module->p, &template->p, sizeof(struct sst_module_data));\r\nINIT_LIST_HEAD(&sst_module->block_list);\r\nmutex_lock(&dsp->mutex);\r\nlist_add(&sst_module->list, &dsp->module_list);\r\nmutex_unlock(&dsp->mutex);\r\nreturn sst_module;\r\n}\r\nvoid sst_module_free(struct sst_module *sst_module)\r\n{\r\nstruct sst_dsp *dsp = sst_module->dsp;\r\nmutex_lock(&dsp->mutex);\r\nlist_del(&sst_module->list);\r\nmutex_unlock(&dsp->mutex);\r\nkfree(sst_module);\r\n}\r\nstatic struct sst_mem_block *find_block(struct sst_dsp *dsp, int type,\r\nu32 offset)\r\n{\r\nstruct sst_mem_block *block;\r\nlist_for_each_entry(block, &dsp->free_block_list, list) {\r\nif (block->type == type && block->offset == offset)\r\nreturn block;\r\n}\r\nreturn NULL;\r\n}\r\nstatic int block_alloc_contiguous(struct sst_module *module,\r\nstruct sst_module_data *data, u32 offset, int size)\r\n{\r\nstruct list_head tmp = LIST_HEAD_INIT(tmp);\r\nstruct sst_dsp *dsp = module->dsp;\r\nstruct sst_mem_block *block;\r\nwhile (size > 0) {\r\nblock = find_block(dsp, data->type, offset);\r\nif (!block) {\r\nlist_splice(&tmp, &dsp->free_block_list);\r\nreturn -ENOMEM;\r\n}\r\nlist_move_tail(&block->list, &tmp);\r\noffset += block->size;\r\nsize -= block->size;\r\n}\r\nlist_for_each_entry(block, &tmp, list)\r\nlist_add(&block->module_list, &module->block_list);\r\nlist_splice(&tmp, &dsp->used_block_list);\r\nreturn 0;\r\n}\r\nstatic int block_alloc(struct sst_module *module,\r\nstruct sst_module_data *data)\r\n{\r\nstruct sst_dsp *dsp = module->dsp;\r\nstruct sst_mem_block *block, *tmp;\r\nint ret = 0;\r\nif (data->size == 0)\r\nreturn 0;\r\nlist_for_each_entry_safe(block, tmp, &dsp->free_block_list, list) {\r\nif (block->type != data->type)\r\ncontinue;\r\nif (data->size > block->size)\r\ncontinue;\r\ndata->offset = block->offset;\r\nblock->data_type = data->data_type;\r\nblock->bytes_used = data->size % block->size;\r\nlist_add(&block->module_list, &module->block_list);\r\nlist_move(&block->list, &dsp->used_block_list);\r\ndev_dbg(dsp->dev, " *module %d added block %d:%d\n",\r\nmodule->id, block->type, block->index);\r\nreturn 0;\r\n}\r\nlist_for_each_entry_safe(block, tmp, &dsp->free_block_list, list) {\r\nif (block->type != data->type)\r\ncontinue;\r\nif (data->size > block->size) {\r\nret = block_alloc_contiguous(module, data,\r\nblock->offset, data->size);\r\nif (ret == 0)\r\nreturn ret;\r\n}\r\n}\r\nreturn -ENOMEM;\r\n}\r\nstatic void block_module_remove(struct sst_module *module)\r\n{\r\nstruct sst_mem_block *block, *tmp;\r\nstruct sst_dsp *dsp = module->dsp;\r\nint err;\r\nlist_for_each_entry(block, &module->block_list, module_list) {\r\nif (block->ops && block->ops->disable) {\r\nerr = block->ops->disable(block);\r\nif (err < 0)\r\ndev_err(dsp->dev,\r\n"error: cant disable block %d:%d\n",\r\nblock->type, block->index);\r\n}\r\n}\r\nlist_for_each_entry_safe(block, tmp, &module->block_list, module_list) {\r\nlist_del(&block->module_list);\r\nlist_move(&block->list, &dsp->free_block_list);\r\n}\r\n}\r\nstatic int block_module_prepare(struct sst_module *module)\r\n{\r\nstruct sst_mem_block *block;\r\nint ret = 0;\r\nlist_for_each_entry(block, &module->block_list, module_list) {\r\nif (block->ops && block->ops->enable) {\r\nret = block->ops->enable(block);\r\nif (ret < 0) {\r\ndev_err(module->dsp->dev,\r\n"error: cant disable block %d:%d\n",\r\nblock->type, block->index);\r\ngoto err;\r\n}\r\n}\r\n}\r\nreturn ret;\r\nerr:\r\nlist_for_each_entry(block, &module->block_list, module_list) {\r\nif (block->ops && block->ops->disable)\r\nblock->ops->disable(block);\r\n}\r\nreturn ret;\r\n}\r\nstatic int block_alloc_fixed(struct sst_module *module,\r\nstruct sst_module_data *data)\r\n{\r\nstruct sst_dsp *dsp = module->dsp;\r\nstruct sst_mem_block *block, *tmp;\r\nu32 end = data->offset + data->size, block_end;\r\nint err;\r\nif (data->type != SST_MEM_IRAM && data->type != SST_MEM_DRAM)\r\nreturn 0;\r\nlist_for_each_entry_safe(block, tmp, &module->block_list, module_list) {\r\nif (block->data_type != data->data_type)\r\ncontinue;\r\nblock_end = block->offset + block->size;\r\nif (data->offset >= block->offset && end < block_end)\r\nreturn 0;\r\nif (data->offset >= block->offset && data->offset < block_end) {\r\nerr = block_alloc_contiguous(module, data,\r\nblock->offset + block->size,\r\ndata->size - block->size);\r\nif (err < 0)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\n}\r\nlist_for_each_entry_safe(block, tmp, &dsp->free_block_list, list) {\r\nblock_end = block->offset + block->size;\r\nif (data->offset >= block->offset && end < block_end) {\r\nblock->data_type = data->data_type;\r\nlist_move(&block->list, &dsp->used_block_list);\r\nlist_add(&block->module_list, &module->block_list);\r\nreturn 0;\r\n}\r\nif (data->offset >= block->offset && data->offset < block_end) {\r\nerr = block_alloc_contiguous(module, data,\r\nblock->offset, data->size);\r\nif (err < 0)\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\n}\r\nreturn -ENOMEM;\r\n}\r\nint sst_module_insert_fixed_block(struct sst_module *module,\r\nstruct sst_module_data *data)\r\n{\r\nstruct sst_dsp *dsp = module->dsp;\r\nint ret;\r\nmutex_lock(&dsp->mutex);\r\nret = block_alloc_fixed(module, data);\r\nif (ret < 0) {\r\ndev_err(dsp->dev,\r\n"error: no free blocks for section at offset 0x%x size 0x%x\n",\r\ndata->offset, data->size);\r\nmutex_unlock(&dsp->mutex);\r\nreturn -ENOMEM;\r\n}\r\nret = block_module_prepare(module);\r\nif (ret < 0) {\r\ndev_err(dsp->dev, "error: fw module prepare failed\n");\r\ngoto err;\r\n}\r\nsst_memcpy32(dsp->addr.lpe + data->offset, data->data, data->size);\r\nmutex_unlock(&dsp->mutex);\r\nreturn ret;\r\nerr:\r\nblock_module_remove(module);\r\nmutex_unlock(&dsp->mutex);\r\nreturn ret;\r\n}\r\nint sst_block_module_remove(struct sst_module *module)\r\n{\r\nstruct sst_dsp *dsp = module->dsp;\r\nmutex_lock(&dsp->mutex);\r\nblock_module_remove(module);\r\nmutex_unlock(&dsp->mutex);\r\nreturn 0;\r\n}\r\nstruct sst_mem_block *sst_mem_block_register(struct sst_dsp *dsp, u32 offset,\r\nu32 size, enum sst_mem_type type, struct sst_block_ops *ops, u32 index,\r\nvoid *private)\r\n{\r\nstruct sst_mem_block *block;\r\nblock = kzalloc(sizeof(*block), GFP_KERNEL);\r\nif (block == NULL)\r\nreturn NULL;\r\nblock->offset = offset;\r\nblock->size = size;\r\nblock->index = index;\r\nblock->type = type;\r\nblock->dsp = dsp;\r\nblock->private = private;\r\nblock->ops = ops;\r\nmutex_lock(&dsp->mutex);\r\nlist_add(&block->list, &dsp->free_block_list);\r\nmutex_unlock(&dsp->mutex);\r\nreturn block;\r\n}\r\nvoid sst_mem_block_unregister_all(struct sst_dsp *dsp)\r\n{\r\nstruct sst_mem_block *block, *tmp;\r\nmutex_lock(&dsp->mutex);\r\nlist_for_each_entry_safe(block, tmp, &dsp->used_block_list, list) {\r\nlist_del(&block->list);\r\nkfree(block);\r\n}\r\nlist_for_each_entry_safe(block, tmp, &dsp->free_block_list, list) {\r\nlist_del(&block->list);\r\nkfree(block);\r\n}\r\nmutex_unlock(&dsp->mutex);\r\n}\r\nstruct sst_module *sst_mem_block_alloc_scratch(struct sst_dsp *dsp)\r\n{\r\nstruct sst_module *sst_module, *scratch;\r\nstruct sst_mem_block *block, *tmp;\r\nu32 block_size;\r\nint ret = 0;\r\nscratch = kzalloc(sizeof(struct sst_module), GFP_KERNEL);\r\nif (scratch == NULL)\r\nreturn NULL;\r\nmutex_lock(&dsp->mutex);\r\nlist_for_each_entry(sst_module, &dsp->module_list, list) {\r\nif (scratch->s.size < sst_module->s.size)\r\nscratch->s.size = sst_module->s.size;\r\n}\r\ndev_dbg(dsp->dev, "scratch buffer required is %d bytes\n",\r\nscratch->s.size);\r\nscratch->dsp = dsp;\r\nscratch->s.type = SST_MEM_DRAM;\r\nscratch->s.data_type = SST_DATA_S;\r\nINIT_LIST_HEAD(&scratch->block_list);\r\nif (!list_empty(&dsp->free_block_list))\r\nblock = list_first_entry(&dsp->free_block_list,\r\nstruct sst_mem_block, list);\r\nelse\r\nblock = list_first_entry(&dsp->used_block_list,\r\nstruct sst_mem_block, list);\r\nblock_size = block->size;\r\ndev_dbg(dsp->dev, "allocating scratch blocks\n");\r\nret = block_alloc(scratch, &scratch->s);\r\nif (ret < 0) {\r\ndev_err(dsp->dev, "error: can't alloc scratch blocks\n");\r\ngoto err;\r\n}\r\nlist_for_each_entry(sst_module, &dsp->module_list, list)\r\nsst_module->s.offset = scratch->s.offset;\r\nmutex_unlock(&dsp->mutex);\r\nreturn scratch;\r\nerr:\r\nlist_for_each_entry_safe(block, tmp, &scratch->block_list, module_list)\r\nlist_del(&block->module_list);\r\nmutex_unlock(&dsp->mutex);\r\nreturn NULL;\r\n}\r\nvoid sst_mem_block_free_scratch(struct sst_dsp *dsp,\r\nstruct sst_module *scratch)\r\n{\r\nstruct sst_mem_block *block, *tmp;\r\nmutex_lock(&dsp->mutex);\r\nlist_for_each_entry_safe(block, tmp, &scratch->block_list, module_list)\r\nlist_del(&block->module_list);\r\nmutex_unlock(&dsp->mutex);\r\n}\r\nstruct sst_module *sst_module_get_from_id(struct sst_dsp *dsp, u32 id)\r\n{\r\nstruct sst_module *module;\r\nmutex_lock(&dsp->mutex);\r\nlist_for_each_entry(module, &dsp->module_list, list) {\r\nif (module->id == id) {\r\nmutex_unlock(&dsp->mutex);\r\nreturn module;\r\n}\r\n}\r\nmutex_unlock(&dsp->mutex);\r\nreturn NULL;\r\n}
