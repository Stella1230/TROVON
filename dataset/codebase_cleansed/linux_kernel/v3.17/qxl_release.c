static uint64_t\r\nqxl_release_alloc(struct qxl_device *qdev, int type,\r\nstruct qxl_release **ret)\r\n{\r\nstruct qxl_release *release;\r\nint handle;\r\nsize_t size = sizeof(*release);\r\nint idr_ret;\r\nrelease = kmalloc(size, GFP_KERNEL);\r\nif (!release) {\r\nDRM_ERROR("Out of memory\n");\r\nreturn 0;\r\n}\r\nrelease->type = type;\r\nrelease->release_offset = 0;\r\nrelease->surface_release_id = 0;\r\nINIT_LIST_HEAD(&release->bos);\r\nidr_preload(GFP_KERNEL);\r\nspin_lock(&qdev->release_idr_lock);\r\nidr_ret = idr_alloc(&qdev->release_idr, release, 1, 0, GFP_NOWAIT);\r\nspin_unlock(&qdev->release_idr_lock);\r\nidr_preload_end();\r\nhandle = idr_ret;\r\nif (idr_ret < 0)\r\ngoto release_fail;\r\n*ret = release;\r\nQXL_INFO(qdev, "allocated release %lld\n", handle);\r\nrelease->id = handle;\r\nrelease_fail:\r\nreturn handle;\r\n}\r\nvoid\r\nqxl_release_free(struct qxl_device *qdev,\r\nstruct qxl_release *release)\r\n{\r\nstruct qxl_bo_list *entry, *tmp;\r\nQXL_INFO(qdev, "release %d, type %d\n", release->id,\r\nrelease->type);\r\nif (release->surface_release_id)\r\nqxl_surface_id_dealloc(qdev, release->surface_release_id);\r\nlist_for_each_entry_safe(entry, tmp, &release->bos, tv.head) {\r\nstruct qxl_bo *bo = to_qxl_bo(entry->tv.bo);\r\nQXL_INFO(qdev, "release %llx\n",\r\ndrm_vma_node_offset_addr(&entry->tv.bo->vma_node)\r\n- DRM_FILE_OFFSET);\r\nqxl_fence_remove_release(&bo->fence, release->id);\r\nqxl_bo_unref(&bo);\r\nkfree(entry);\r\n}\r\nspin_lock(&qdev->release_idr_lock);\r\nidr_remove(&qdev->release_idr, release->id);\r\nspin_unlock(&qdev->release_idr_lock);\r\nkfree(release);\r\n}\r\nstatic int qxl_release_bo_alloc(struct qxl_device *qdev,\r\nstruct qxl_bo **bo)\r\n{\r\nint ret;\r\nret = qxl_bo_create(qdev, PAGE_SIZE, false, true,\r\nQXL_GEM_DOMAIN_VRAM, NULL,\r\nbo);\r\nreturn ret;\r\n}\r\nint qxl_release_list_add(struct qxl_release *release, struct qxl_bo *bo)\r\n{\r\nstruct qxl_bo_list *entry;\r\nlist_for_each_entry(entry, &release->bos, tv.head) {\r\nif (entry->tv.bo == &bo->tbo)\r\nreturn 0;\r\n}\r\nentry = kmalloc(sizeof(struct qxl_bo_list), GFP_KERNEL);\r\nif (!entry)\r\nreturn -ENOMEM;\r\nqxl_bo_ref(bo);\r\nentry->tv.bo = &bo->tbo;\r\nlist_add_tail(&entry->tv.head, &release->bos);\r\nreturn 0;\r\n}\r\nstatic int qxl_release_validate_bo(struct qxl_bo *bo)\r\n{\r\nint ret;\r\nif (!bo->pin_count) {\r\nqxl_ttm_placement_from_domain(bo, bo->type, false);\r\nret = ttm_bo_validate(&bo->tbo, &bo->placement,\r\ntrue, false);\r\nif (ret)\r\nreturn ret;\r\n}\r\nret = qxl_bo_check_id(bo->gem_base.dev->dev_private, bo);\r\nif (ret)\r\nreturn ret;\r\nreturn 0;\r\n}\r\nint qxl_release_reserve_list(struct qxl_release *release, bool no_intr)\r\n{\r\nint ret;\r\nstruct qxl_bo_list *entry;\r\nif (list_is_singular(&release->bos))\r\nreturn 0;\r\nret = ttm_eu_reserve_buffers(&release->ticket, &release->bos);\r\nif (ret)\r\nreturn ret;\r\nlist_for_each_entry(entry, &release->bos, tv.head) {\r\nstruct qxl_bo *bo = to_qxl_bo(entry->tv.bo);\r\nret = qxl_release_validate_bo(bo);\r\nif (ret) {\r\nttm_eu_backoff_reservation(&release->ticket, &release->bos);\r\nreturn ret;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nvoid qxl_release_backoff_reserve_list(struct qxl_release *release)\r\n{\r\nif (list_is_singular(&release->bos))\r\nreturn;\r\nttm_eu_backoff_reservation(&release->ticket, &release->bos);\r\n}\r\nint qxl_alloc_surface_release_reserved(struct qxl_device *qdev,\r\nenum qxl_surface_cmd_type surface_cmd_type,\r\nstruct qxl_release *create_rel,\r\nstruct qxl_release **release)\r\n{\r\nif (surface_cmd_type == QXL_SURFACE_CMD_DESTROY && create_rel) {\r\nint idr_ret;\r\nstruct qxl_bo_list *entry = list_first_entry(&create_rel->bos, struct qxl_bo_list, tv.head);\r\nstruct qxl_bo *bo;\r\nunion qxl_release_info *info;\r\nidr_ret = qxl_release_alloc(qdev, QXL_RELEASE_SURFACE_CMD, release);\r\nbo = qxl_bo_ref(to_qxl_bo(entry->tv.bo));\r\n(*release)->release_offset = create_rel->release_offset + 64;\r\nqxl_release_list_add(*release, bo);\r\ninfo = qxl_release_map(qdev, *release);\r\ninfo->id = idr_ret;\r\nqxl_release_unmap(qdev, *release, info);\r\nqxl_bo_unref(&bo);\r\nreturn 0;\r\n}\r\nreturn qxl_alloc_release_reserved(qdev, sizeof(struct qxl_surface_cmd),\r\nQXL_RELEASE_SURFACE_CMD, release, NULL);\r\n}\r\nint qxl_alloc_release_reserved(struct qxl_device *qdev, unsigned long size,\r\nint type, struct qxl_release **release,\r\nstruct qxl_bo **rbo)\r\n{\r\nstruct qxl_bo *bo;\r\nint idr_ret;\r\nint ret = 0;\r\nunion qxl_release_info *info;\r\nint cur_idx;\r\nif (type == QXL_RELEASE_DRAWABLE)\r\ncur_idx = 0;\r\nelse if (type == QXL_RELEASE_SURFACE_CMD)\r\ncur_idx = 1;\r\nelse if (type == QXL_RELEASE_CURSOR_CMD)\r\ncur_idx = 2;\r\nelse {\r\nDRM_ERROR("got illegal type: %d\n", type);\r\nreturn -EINVAL;\r\n}\r\nidr_ret = qxl_release_alloc(qdev, type, release);\r\nmutex_lock(&qdev->release_mutex);\r\nif (qdev->current_release_bo_offset[cur_idx] + 1 >= releases_per_bo[cur_idx]) {\r\nqxl_bo_unref(&qdev->current_release_bo[cur_idx]);\r\nqdev->current_release_bo_offset[cur_idx] = 0;\r\nqdev->current_release_bo[cur_idx] = NULL;\r\n}\r\nif (!qdev->current_release_bo[cur_idx]) {\r\nret = qxl_release_bo_alloc(qdev, &qdev->current_release_bo[cur_idx]);\r\nif (ret) {\r\nmutex_unlock(&qdev->release_mutex);\r\nreturn ret;\r\n}\r\n}\r\nbo = qxl_bo_ref(qdev->current_release_bo[cur_idx]);\r\n(*release)->release_offset = qdev->current_release_bo_offset[cur_idx] * release_size_per_bo[cur_idx];\r\nqdev->current_release_bo_offset[cur_idx]++;\r\nif (rbo)\r\n*rbo = bo;\r\nmutex_unlock(&qdev->release_mutex);\r\nqxl_release_list_add(*release, bo);\r\ninfo = qxl_release_map(qdev, *release);\r\ninfo->id = idr_ret;\r\nqxl_release_unmap(qdev, *release, info);\r\nqxl_bo_unref(&bo);\r\nreturn ret;\r\n}\r\nstruct qxl_release *qxl_release_from_id_locked(struct qxl_device *qdev,\r\nuint64_t id)\r\n{\r\nstruct qxl_release *release;\r\nspin_lock(&qdev->release_idr_lock);\r\nrelease = idr_find(&qdev->release_idr, id);\r\nspin_unlock(&qdev->release_idr_lock);\r\nif (!release) {\r\nDRM_ERROR("failed to find id in release_idr\n");\r\nreturn NULL;\r\n}\r\nreturn release;\r\n}\r\nunion qxl_release_info *qxl_release_map(struct qxl_device *qdev,\r\nstruct qxl_release *release)\r\n{\r\nvoid *ptr;\r\nunion qxl_release_info *info;\r\nstruct qxl_bo_list *entry = list_first_entry(&release->bos, struct qxl_bo_list, tv.head);\r\nstruct qxl_bo *bo = to_qxl_bo(entry->tv.bo);\r\nptr = qxl_bo_kmap_atomic_page(qdev, bo, release->release_offset & PAGE_SIZE);\r\nif (!ptr)\r\nreturn NULL;\r\ninfo = ptr + (release->release_offset & ~PAGE_SIZE);\r\nreturn info;\r\n}\r\nvoid qxl_release_unmap(struct qxl_device *qdev,\r\nstruct qxl_release *release,\r\nunion qxl_release_info *info)\r\n{\r\nstruct qxl_bo_list *entry = list_first_entry(&release->bos, struct qxl_bo_list, tv.head);\r\nstruct qxl_bo *bo = to_qxl_bo(entry->tv.bo);\r\nvoid *ptr;\r\nptr = ((void *)info) - (release->release_offset & ~PAGE_SIZE);\r\nqxl_bo_kunmap_atomic_page(qdev, bo, ptr);\r\n}\r\nvoid qxl_release_fence_buffer_objects(struct qxl_release *release)\r\n{\r\nstruct ttm_validate_buffer *entry;\r\nstruct ttm_buffer_object *bo;\r\nstruct ttm_bo_global *glob;\r\nstruct ttm_bo_device *bdev;\r\nstruct ttm_bo_driver *driver;\r\nstruct qxl_bo *qbo;\r\nif (list_is_singular(&release->bos))\r\nreturn;\r\nbo = list_first_entry(&release->bos, struct ttm_validate_buffer, head)->bo;\r\nbdev = bo->bdev;\r\ndriver = bdev->driver;\r\nglob = bo->glob;\r\nspin_lock(&glob->lru_lock);\r\nspin_lock(&bdev->fence_lock);\r\nlist_for_each_entry(entry, &release->bos, head) {\r\nbo = entry->bo;\r\nqbo = to_qxl_bo(bo);\r\nif (!entry->bo->sync_obj)\r\nentry->bo->sync_obj = &qbo->fence;\r\nqxl_fence_add_release_locked(&qbo->fence, release->id);\r\nttm_bo_add_to_lru(bo);\r\n__ttm_bo_unreserve(bo);\r\nentry->reserved = false;\r\n}\r\nspin_unlock(&bdev->fence_lock);\r\nspin_unlock(&glob->lru_lock);\r\nww_acquire_fini(&release->ticket);\r\n}
