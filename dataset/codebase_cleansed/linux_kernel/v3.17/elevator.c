static int elv_iosched_allow_merge(struct request *rq, struct bio *bio)\r\n{\r\nstruct request_queue *q = rq->q;\r\nstruct elevator_queue *e = q->elevator;\r\nif (e->type->ops.elevator_allow_merge_fn)\r\nreturn e->type->ops.elevator_allow_merge_fn(q, rq, bio);\r\nreturn 1;\r\n}\r\nbool elv_rq_merge_ok(struct request *rq, struct bio *bio)\r\n{\r\nif (!blk_rq_merge_ok(rq, bio))\r\nreturn 0;\r\nif (!elv_iosched_allow_merge(rq, bio))\r\nreturn 0;\r\nreturn 1;\r\n}\r\nstatic struct elevator_type *elevator_find(const char *name)\r\n{\r\nstruct elevator_type *e;\r\nlist_for_each_entry(e, &elv_list, list) {\r\nif (!strcmp(e->elevator_name, name))\r\nreturn e;\r\n}\r\nreturn NULL;\r\n}\r\nstatic void elevator_put(struct elevator_type *e)\r\n{\r\nmodule_put(e->elevator_owner);\r\n}\r\nstatic struct elevator_type *elevator_get(const char *name, bool try_loading)\r\n{\r\nstruct elevator_type *e;\r\nspin_lock(&elv_list_lock);\r\ne = elevator_find(name);\r\nif (!e && try_loading) {\r\nspin_unlock(&elv_list_lock);\r\nrequest_module("%s-iosched", name);\r\nspin_lock(&elv_list_lock);\r\ne = elevator_find(name);\r\n}\r\nif (e && !try_module_get(e->elevator_owner))\r\ne = NULL;\r\nspin_unlock(&elv_list_lock);\r\nreturn e;\r\n}\r\nstatic int __init elevator_setup(char *str)\r\n{\r\nstrncpy(chosen_elevator, str, sizeof(chosen_elevator) - 1);\r\nreturn 1;\r\n}\r\nvoid __init load_default_elevator_module(void)\r\n{\r\nstruct elevator_type *e;\r\nif (!chosen_elevator[0])\r\nreturn;\r\nspin_lock(&elv_list_lock);\r\ne = elevator_find(chosen_elevator);\r\nspin_unlock(&elv_list_lock);\r\nif (!e)\r\nrequest_module("%s-iosched", chosen_elevator);\r\n}\r\nstruct elevator_queue *elevator_alloc(struct request_queue *q,\r\nstruct elevator_type *e)\r\n{\r\nstruct elevator_queue *eq;\r\neq = kzalloc_node(sizeof(*eq), GFP_KERNEL, q->node);\r\nif (unlikely(!eq))\r\ngoto err;\r\neq->type = e;\r\nkobject_init(&eq->kobj, &elv_ktype);\r\nmutex_init(&eq->sysfs_lock);\r\nhash_init(eq->hash);\r\nreturn eq;\r\nerr:\r\nkfree(eq);\r\nelevator_put(e);\r\nreturn NULL;\r\n}\r\nstatic void elevator_release(struct kobject *kobj)\r\n{\r\nstruct elevator_queue *e;\r\ne = container_of(kobj, struct elevator_queue, kobj);\r\nelevator_put(e->type);\r\nkfree(e);\r\n}\r\nint elevator_init(struct request_queue *q, char *name)\r\n{\r\nstruct elevator_type *e = NULL;\r\nint err;\r\nlockdep_assert_held(&q->sysfs_lock);\r\nif (unlikely(q->elevator))\r\nreturn 0;\r\nINIT_LIST_HEAD(&q->queue_head);\r\nq->last_merge = NULL;\r\nq->end_sector = 0;\r\nq->boundary_rq = NULL;\r\nif (name) {\r\ne = elevator_get(name, true);\r\nif (!e)\r\nreturn -EINVAL;\r\n}\r\nif (!e && *chosen_elevator) {\r\ne = elevator_get(chosen_elevator, false);\r\nif (!e)\r\nprintk(KERN_ERR "I/O scheduler %s not found\n",\r\nchosen_elevator);\r\n}\r\nif (!e) {\r\ne = elevator_get(CONFIG_DEFAULT_IOSCHED, false);\r\nif (!e) {\r\nprintk(KERN_ERR\r\n"Default I/O scheduler not found. " \\r\n"Using noop.\n");\r\ne = elevator_get("noop", false);\r\n}\r\n}\r\nerr = e->ops.elevator_init_fn(q, e);\r\nreturn 0;\r\n}\r\nvoid elevator_exit(struct elevator_queue *e)\r\n{\r\nmutex_lock(&e->sysfs_lock);\r\nif (e->type->ops.elevator_exit_fn)\r\ne->type->ops.elevator_exit_fn(e);\r\nmutex_unlock(&e->sysfs_lock);\r\nkobject_put(&e->kobj);\r\n}\r\nstatic inline void __elv_rqhash_del(struct request *rq)\r\n{\r\nhash_del(&rq->hash);\r\nrq->cmd_flags &= ~REQ_HASHED;\r\n}\r\nstatic void elv_rqhash_del(struct request_queue *q, struct request *rq)\r\n{\r\nif (ELV_ON_HASH(rq))\r\n__elv_rqhash_del(rq);\r\n}\r\nstatic void elv_rqhash_add(struct request_queue *q, struct request *rq)\r\n{\r\nstruct elevator_queue *e = q->elevator;\r\nBUG_ON(ELV_ON_HASH(rq));\r\nhash_add(e->hash, &rq->hash, rq_hash_key(rq));\r\nrq->cmd_flags |= REQ_HASHED;\r\n}\r\nstatic void elv_rqhash_reposition(struct request_queue *q, struct request *rq)\r\n{\r\n__elv_rqhash_del(rq);\r\nelv_rqhash_add(q, rq);\r\n}\r\nstatic struct request *elv_rqhash_find(struct request_queue *q, sector_t offset)\r\n{\r\nstruct elevator_queue *e = q->elevator;\r\nstruct hlist_node *next;\r\nstruct request *rq;\r\nhash_for_each_possible_safe(e->hash, rq, next, hash, offset) {\r\nBUG_ON(!ELV_ON_HASH(rq));\r\nif (unlikely(!rq_mergeable(rq))) {\r\n__elv_rqhash_del(rq);\r\ncontinue;\r\n}\r\nif (rq_hash_key(rq) == offset)\r\nreturn rq;\r\n}\r\nreturn NULL;\r\n}\r\nvoid elv_rb_add(struct rb_root *root, struct request *rq)\r\n{\r\nstruct rb_node **p = &root->rb_node;\r\nstruct rb_node *parent = NULL;\r\nstruct request *__rq;\r\nwhile (*p) {\r\nparent = *p;\r\n__rq = rb_entry(parent, struct request, rb_node);\r\nif (blk_rq_pos(rq) < blk_rq_pos(__rq))\r\np = &(*p)->rb_left;\r\nelse if (blk_rq_pos(rq) >= blk_rq_pos(__rq))\r\np = &(*p)->rb_right;\r\n}\r\nrb_link_node(&rq->rb_node, parent, p);\r\nrb_insert_color(&rq->rb_node, root);\r\n}\r\nvoid elv_rb_del(struct rb_root *root, struct request *rq)\r\n{\r\nBUG_ON(RB_EMPTY_NODE(&rq->rb_node));\r\nrb_erase(&rq->rb_node, root);\r\nRB_CLEAR_NODE(&rq->rb_node);\r\n}\r\nstruct request *elv_rb_find(struct rb_root *root, sector_t sector)\r\n{\r\nstruct rb_node *n = root->rb_node;\r\nstruct request *rq;\r\nwhile (n) {\r\nrq = rb_entry(n, struct request, rb_node);\r\nif (sector < blk_rq_pos(rq))\r\nn = n->rb_left;\r\nelse if (sector > blk_rq_pos(rq))\r\nn = n->rb_right;\r\nelse\r\nreturn rq;\r\n}\r\nreturn NULL;\r\n}\r\nvoid elv_dispatch_sort(struct request_queue *q, struct request *rq)\r\n{\r\nsector_t boundary;\r\nstruct list_head *entry;\r\nint stop_flags;\r\nif (q->last_merge == rq)\r\nq->last_merge = NULL;\r\nelv_rqhash_del(q, rq);\r\nq->nr_sorted--;\r\nboundary = q->end_sector;\r\nstop_flags = REQ_SOFTBARRIER | REQ_STARTED;\r\nlist_for_each_prev(entry, &q->queue_head) {\r\nstruct request *pos = list_entry_rq(entry);\r\nif ((rq->cmd_flags & REQ_DISCARD) !=\r\n(pos->cmd_flags & REQ_DISCARD))\r\nbreak;\r\nif (rq_data_dir(rq) != rq_data_dir(pos))\r\nbreak;\r\nif (pos->cmd_flags & stop_flags)\r\nbreak;\r\nif (blk_rq_pos(rq) >= boundary) {\r\nif (blk_rq_pos(pos) < boundary)\r\ncontinue;\r\n} else {\r\nif (blk_rq_pos(pos) >= boundary)\r\nbreak;\r\n}\r\nif (blk_rq_pos(rq) >= blk_rq_pos(pos))\r\nbreak;\r\n}\r\nlist_add(&rq->queuelist, entry);\r\n}\r\nvoid elv_dispatch_add_tail(struct request_queue *q, struct request *rq)\r\n{\r\nif (q->last_merge == rq)\r\nq->last_merge = NULL;\r\nelv_rqhash_del(q, rq);\r\nq->nr_sorted--;\r\nq->end_sector = rq_end_sector(rq);\r\nq->boundary_rq = rq;\r\nlist_add_tail(&rq->queuelist, &q->queue_head);\r\n}\r\nint elv_merge(struct request_queue *q, struct request **req, struct bio *bio)\r\n{\r\nstruct elevator_queue *e = q->elevator;\r\nstruct request *__rq;\r\nint ret;\r\nif (blk_queue_nomerges(q))\r\nreturn ELEVATOR_NO_MERGE;\r\nif (q->last_merge && elv_rq_merge_ok(q->last_merge, bio)) {\r\nret = blk_try_merge(q->last_merge, bio);\r\nif (ret != ELEVATOR_NO_MERGE) {\r\n*req = q->last_merge;\r\nreturn ret;\r\n}\r\n}\r\nif (blk_queue_noxmerges(q))\r\nreturn ELEVATOR_NO_MERGE;\r\n__rq = elv_rqhash_find(q, bio->bi_iter.bi_sector);\r\nif (__rq && elv_rq_merge_ok(__rq, bio)) {\r\n*req = __rq;\r\nreturn ELEVATOR_BACK_MERGE;\r\n}\r\nif (e->type->ops.elevator_merge_fn)\r\nreturn e->type->ops.elevator_merge_fn(q, req, bio);\r\nreturn ELEVATOR_NO_MERGE;\r\n}\r\nstatic bool elv_attempt_insert_merge(struct request_queue *q,\r\nstruct request *rq)\r\n{\r\nstruct request *__rq;\r\nbool ret;\r\nif (blk_queue_nomerges(q))\r\nreturn false;\r\nif (q->last_merge && blk_attempt_req_merge(q, q->last_merge, rq))\r\nreturn true;\r\nif (blk_queue_noxmerges(q))\r\nreturn false;\r\nret = false;\r\nwhile (1) {\r\n__rq = elv_rqhash_find(q, blk_rq_pos(rq));\r\nif (!__rq || !blk_attempt_req_merge(q, __rq, rq))\r\nbreak;\r\nret = true;\r\nrq = __rq;\r\n}\r\nreturn ret;\r\n}\r\nvoid elv_merged_request(struct request_queue *q, struct request *rq, int type)\r\n{\r\nstruct elevator_queue *e = q->elevator;\r\nif (e->type->ops.elevator_merged_fn)\r\ne->type->ops.elevator_merged_fn(q, rq, type);\r\nif (type == ELEVATOR_BACK_MERGE)\r\nelv_rqhash_reposition(q, rq);\r\nq->last_merge = rq;\r\n}\r\nvoid elv_merge_requests(struct request_queue *q, struct request *rq,\r\nstruct request *next)\r\n{\r\nstruct elevator_queue *e = q->elevator;\r\nconst int next_sorted = next->cmd_flags & REQ_SORTED;\r\nif (next_sorted && e->type->ops.elevator_merge_req_fn)\r\ne->type->ops.elevator_merge_req_fn(q, rq, next);\r\nelv_rqhash_reposition(q, rq);\r\nif (next_sorted) {\r\nelv_rqhash_del(q, next);\r\nq->nr_sorted--;\r\n}\r\nq->last_merge = rq;\r\n}\r\nvoid elv_bio_merged(struct request_queue *q, struct request *rq,\r\nstruct bio *bio)\r\n{\r\nstruct elevator_queue *e = q->elevator;\r\nif (e->type->ops.elevator_bio_merged_fn)\r\ne->type->ops.elevator_bio_merged_fn(q, rq, bio);\r\n}\r\nstatic void blk_pm_requeue_request(struct request *rq)\r\n{\r\nif (rq->q->dev && !(rq->cmd_flags & REQ_PM))\r\nrq->q->nr_pending--;\r\n}\r\nstatic void blk_pm_add_request(struct request_queue *q, struct request *rq)\r\n{\r\nif (q->dev && !(rq->cmd_flags & REQ_PM) && q->nr_pending++ == 0 &&\r\n(q->rpm_status == RPM_SUSPENDED || q->rpm_status == RPM_SUSPENDING))\r\npm_request_resume(q->dev);\r\n}\r\nstatic inline void blk_pm_requeue_request(struct request *rq) {}\r\nstatic inline void blk_pm_add_request(struct request_queue *q,\r\nstruct request *rq)\r\n{\r\n}\r\nvoid elv_requeue_request(struct request_queue *q, struct request *rq)\r\n{\r\nif (blk_account_rq(rq)) {\r\nq->in_flight[rq_is_sync(rq)]--;\r\nif (rq->cmd_flags & REQ_SORTED)\r\nelv_deactivate_rq(q, rq);\r\n}\r\nrq->cmd_flags &= ~REQ_STARTED;\r\nblk_pm_requeue_request(rq);\r\n__elv_add_request(q, rq, ELEVATOR_INSERT_REQUEUE);\r\n}\r\nvoid elv_drain_elevator(struct request_queue *q)\r\n{\r\nstatic int printed;\r\nlockdep_assert_held(q->queue_lock);\r\nwhile (q->elevator->type->ops.elevator_dispatch_fn(q, 1))\r\n;\r\nif (q->nr_sorted && printed++ < 10) {\r\nprintk(KERN_ERR "%s: forced dispatching is broken "\r\n"(nr_sorted=%u), please report this\n",\r\nq->elevator->type->elevator_name, q->nr_sorted);\r\n}\r\n}\r\nvoid __elv_add_request(struct request_queue *q, struct request *rq, int where)\r\n{\r\ntrace_block_rq_insert(q, rq);\r\nblk_pm_add_request(q, rq);\r\nrq->q = q;\r\nif (rq->cmd_flags & REQ_SOFTBARRIER) {\r\nif (rq->cmd_type == REQ_TYPE_FS) {\r\nq->end_sector = rq_end_sector(rq);\r\nq->boundary_rq = rq;\r\n}\r\n} else if (!(rq->cmd_flags & REQ_ELVPRIV) &&\r\n(where == ELEVATOR_INSERT_SORT ||\r\nwhere == ELEVATOR_INSERT_SORT_MERGE))\r\nwhere = ELEVATOR_INSERT_BACK;\r\nswitch (where) {\r\ncase ELEVATOR_INSERT_REQUEUE:\r\ncase ELEVATOR_INSERT_FRONT:\r\nrq->cmd_flags |= REQ_SOFTBARRIER;\r\nlist_add(&rq->queuelist, &q->queue_head);\r\nbreak;\r\ncase ELEVATOR_INSERT_BACK:\r\nrq->cmd_flags |= REQ_SOFTBARRIER;\r\nelv_drain_elevator(q);\r\nlist_add_tail(&rq->queuelist, &q->queue_head);\r\n__blk_run_queue(q);\r\nbreak;\r\ncase ELEVATOR_INSERT_SORT_MERGE:\r\nif (elv_attempt_insert_merge(q, rq))\r\nbreak;\r\ncase ELEVATOR_INSERT_SORT:\r\nBUG_ON(rq->cmd_type != REQ_TYPE_FS);\r\nrq->cmd_flags |= REQ_SORTED;\r\nq->nr_sorted++;\r\nif (rq_mergeable(rq)) {\r\nelv_rqhash_add(q, rq);\r\nif (!q->last_merge)\r\nq->last_merge = rq;\r\n}\r\nq->elevator->type->ops.elevator_add_req_fn(q, rq);\r\nbreak;\r\ncase ELEVATOR_INSERT_FLUSH:\r\nrq->cmd_flags |= REQ_SOFTBARRIER;\r\nblk_insert_flush(rq);\r\nbreak;\r\ndefault:\r\nprintk(KERN_ERR "%s: bad insertion point %d\n",\r\n__func__, where);\r\nBUG();\r\n}\r\n}\r\nvoid elv_add_request(struct request_queue *q, struct request *rq, int where)\r\n{\r\nunsigned long flags;\r\nspin_lock_irqsave(q->queue_lock, flags);\r\n__elv_add_request(q, rq, where);\r\nspin_unlock_irqrestore(q->queue_lock, flags);\r\n}\r\nstruct request *elv_latter_request(struct request_queue *q, struct request *rq)\r\n{\r\nstruct elevator_queue *e = q->elevator;\r\nif (e->type->ops.elevator_latter_req_fn)\r\nreturn e->type->ops.elevator_latter_req_fn(q, rq);\r\nreturn NULL;\r\n}\r\nstruct request *elv_former_request(struct request_queue *q, struct request *rq)\r\n{\r\nstruct elevator_queue *e = q->elevator;\r\nif (e->type->ops.elevator_former_req_fn)\r\nreturn e->type->ops.elevator_former_req_fn(q, rq);\r\nreturn NULL;\r\n}\r\nint elv_set_request(struct request_queue *q, struct request *rq,\r\nstruct bio *bio, gfp_t gfp_mask)\r\n{\r\nstruct elevator_queue *e = q->elevator;\r\nif (e->type->ops.elevator_set_req_fn)\r\nreturn e->type->ops.elevator_set_req_fn(q, rq, bio, gfp_mask);\r\nreturn 0;\r\n}\r\nvoid elv_put_request(struct request_queue *q, struct request *rq)\r\n{\r\nstruct elevator_queue *e = q->elevator;\r\nif (e->type->ops.elevator_put_req_fn)\r\ne->type->ops.elevator_put_req_fn(rq);\r\n}\r\nint elv_may_queue(struct request_queue *q, int rw)\r\n{\r\nstruct elevator_queue *e = q->elevator;\r\nif (e->type->ops.elevator_may_queue_fn)\r\nreturn e->type->ops.elevator_may_queue_fn(q, rw);\r\nreturn ELV_MQUEUE_MAY;\r\n}\r\nvoid elv_completed_request(struct request_queue *q, struct request *rq)\r\n{\r\nstruct elevator_queue *e = q->elevator;\r\nif (blk_account_rq(rq)) {\r\nq->in_flight[rq_is_sync(rq)]--;\r\nif ((rq->cmd_flags & REQ_SORTED) &&\r\ne->type->ops.elevator_completed_req_fn)\r\ne->type->ops.elevator_completed_req_fn(q, rq);\r\n}\r\n}\r\nstatic ssize_t\r\nelv_attr_show(struct kobject *kobj, struct attribute *attr, char *page)\r\n{\r\nstruct elv_fs_entry *entry = to_elv(attr);\r\nstruct elevator_queue *e;\r\nssize_t error;\r\nif (!entry->show)\r\nreturn -EIO;\r\ne = container_of(kobj, struct elevator_queue, kobj);\r\nmutex_lock(&e->sysfs_lock);\r\nerror = e->type ? entry->show(e, page) : -ENOENT;\r\nmutex_unlock(&e->sysfs_lock);\r\nreturn error;\r\n}\r\nstatic ssize_t\r\nelv_attr_store(struct kobject *kobj, struct attribute *attr,\r\nconst char *page, size_t length)\r\n{\r\nstruct elv_fs_entry *entry = to_elv(attr);\r\nstruct elevator_queue *e;\r\nssize_t error;\r\nif (!entry->store)\r\nreturn -EIO;\r\ne = container_of(kobj, struct elevator_queue, kobj);\r\nmutex_lock(&e->sysfs_lock);\r\nerror = e->type ? entry->store(e, page, length) : -ENOENT;\r\nmutex_unlock(&e->sysfs_lock);\r\nreturn error;\r\n}\r\nint elv_register_queue(struct request_queue *q)\r\n{\r\nstruct elevator_queue *e = q->elevator;\r\nint error;\r\nerror = kobject_add(&e->kobj, &q->kobj, "%s", "iosched");\r\nif (!error) {\r\nstruct elv_fs_entry *attr = e->type->elevator_attrs;\r\nif (attr) {\r\nwhile (attr->attr.name) {\r\nif (sysfs_create_file(&e->kobj, &attr->attr))\r\nbreak;\r\nattr++;\r\n}\r\n}\r\nkobject_uevent(&e->kobj, KOBJ_ADD);\r\ne->registered = 1;\r\n}\r\nreturn error;\r\n}\r\nvoid elv_unregister_queue(struct request_queue *q)\r\n{\r\nif (q) {\r\nstruct elevator_queue *e = q->elevator;\r\nkobject_uevent(&e->kobj, KOBJ_REMOVE);\r\nkobject_del(&e->kobj);\r\ne->registered = 0;\r\n}\r\n}\r\nint elv_register(struct elevator_type *e)\r\n{\r\nchar *def = "";\r\nif (e->icq_size) {\r\nif (WARN_ON(e->icq_size < sizeof(struct io_cq)) ||\r\nWARN_ON(e->icq_align < __alignof__(struct io_cq)))\r\nreturn -EINVAL;\r\nsnprintf(e->icq_cache_name, sizeof(e->icq_cache_name),\r\n"%s_io_cq", e->elevator_name);\r\ne->icq_cache = kmem_cache_create(e->icq_cache_name, e->icq_size,\r\ne->icq_align, 0, NULL);\r\nif (!e->icq_cache)\r\nreturn -ENOMEM;\r\n}\r\nspin_lock(&elv_list_lock);\r\nif (elevator_find(e->elevator_name)) {\r\nspin_unlock(&elv_list_lock);\r\nif (e->icq_cache)\r\nkmem_cache_destroy(e->icq_cache);\r\nreturn -EBUSY;\r\n}\r\nlist_add_tail(&e->list, &elv_list);\r\nspin_unlock(&elv_list_lock);\r\nif (!strcmp(e->elevator_name, chosen_elevator) ||\r\n(!*chosen_elevator &&\r\n!strcmp(e->elevator_name, CONFIG_DEFAULT_IOSCHED)))\r\ndef = " (default)";\r\nprintk(KERN_INFO "io scheduler %s registered%s\n", e->elevator_name,\r\ndef);\r\nreturn 0;\r\n}\r\nvoid elv_unregister(struct elevator_type *e)\r\n{\r\nspin_lock(&elv_list_lock);\r\nlist_del_init(&e->list);\r\nspin_unlock(&elv_list_lock);\r\nif (e->icq_cache) {\r\nrcu_barrier();\r\nkmem_cache_destroy(e->icq_cache);\r\ne->icq_cache = NULL;\r\n}\r\n}\r\nstatic int elevator_switch(struct request_queue *q, struct elevator_type *new_e)\r\n{\r\nstruct elevator_queue *old = q->elevator;\r\nbool registered = old->registered;\r\nint err;\r\nblk_queue_bypass_start(q);\r\nif (registered)\r\nelv_unregister_queue(q);\r\nspin_lock_irq(q->queue_lock);\r\nioc_clear_queue(q);\r\nspin_unlock_irq(q->queue_lock);\r\nerr = new_e->ops.elevator_init_fn(q, new_e);\r\nif (err)\r\ngoto fail_init;\r\nif (registered) {\r\nerr = elv_register_queue(q);\r\nif (err)\r\ngoto fail_register;\r\n}\r\nelevator_exit(old);\r\nblk_queue_bypass_end(q);\r\nblk_add_trace_msg(q, "elv switch: %s", new_e->elevator_name);\r\nreturn 0;\r\nfail_register:\r\nelevator_exit(q->elevator);\r\nfail_init:\r\nq->elevator = old;\r\nelv_register_queue(q);\r\nblk_queue_bypass_end(q);\r\nreturn err;\r\n}\r\nstatic int __elevator_change(struct request_queue *q, const char *name)\r\n{\r\nchar elevator_name[ELV_NAME_MAX];\r\nstruct elevator_type *e;\r\nif (!q->elevator)\r\nreturn -ENXIO;\r\nstrlcpy(elevator_name, name, sizeof(elevator_name));\r\ne = elevator_get(strstrip(elevator_name), true);\r\nif (!e) {\r\nprintk(KERN_ERR "elevator: type %s not found\n", elevator_name);\r\nreturn -EINVAL;\r\n}\r\nif (!strcmp(elevator_name, q->elevator->type->elevator_name)) {\r\nelevator_put(e);\r\nreturn 0;\r\n}\r\nreturn elevator_switch(q, e);\r\n}\r\nint elevator_change(struct request_queue *q, const char *name)\r\n{\r\nint ret;\r\nmutex_lock(&q->sysfs_lock);\r\nret = __elevator_change(q, name);\r\nmutex_unlock(&q->sysfs_lock);\r\nreturn ret;\r\n}\r\nssize_t elv_iosched_store(struct request_queue *q, const char *name,\r\nsize_t count)\r\n{\r\nint ret;\r\nif (!q->elevator)\r\nreturn count;\r\nret = __elevator_change(q, name);\r\nif (!ret)\r\nreturn count;\r\nprintk(KERN_ERR "elevator: switch to %s failed\n", name);\r\nreturn ret;\r\n}\r\nssize_t elv_iosched_show(struct request_queue *q, char *name)\r\n{\r\nstruct elevator_queue *e = q->elevator;\r\nstruct elevator_type *elv;\r\nstruct elevator_type *__e;\r\nint len = 0;\r\nif (!q->elevator || !blk_queue_stackable(q))\r\nreturn sprintf(name, "none\n");\r\nelv = e->type;\r\nspin_lock(&elv_list_lock);\r\nlist_for_each_entry(__e, &elv_list, list) {\r\nif (!strcmp(elv->elevator_name, __e->elevator_name))\r\nlen += sprintf(name+len, "[%s] ", elv->elevator_name);\r\nelse\r\nlen += sprintf(name+len, "%s ", __e->elevator_name);\r\n}\r\nspin_unlock(&elv_list_lock);\r\nlen += sprintf(len+name, "\n");\r\nreturn len;\r\n}\r\nstruct request *elv_rb_former_request(struct request_queue *q,\r\nstruct request *rq)\r\n{\r\nstruct rb_node *rbprev = rb_prev(&rq->rb_node);\r\nif (rbprev)\r\nreturn rb_entry_rq(rbprev);\r\nreturn NULL;\r\n}\r\nstruct request *elv_rb_latter_request(struct request_queue *q,\r\nstruct request *rq)\r\n{\r\nstruct rb_node *rbnext = rb_next(&rq->rb_node);\r\nif (rbnext)\r\nreturn rb_entry_rq(rbnext);\r\nreturn NULL;\r\n}
