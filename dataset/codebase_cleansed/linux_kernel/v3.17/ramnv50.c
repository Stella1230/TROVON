static int\r\nnv50_ram_calc(struct nouveau_fb *pfb, u32 freq)\r\n{\r\nstruct nouveau_bios *bios = nouveau_bios(pfb);\r\nstruct nv50_ram *ram = (void *)pfb->ram;\r\nstruct nv50_ramseq *hwsq = &ram->hwsq;\r\nstruct nvbios_perfE perfE;\r\nstruct nvbios_pll mpll;\r\nstruct {\r\nu32 data;\r\nu8 size;\r\n} ramcfg, timing;\r\nu8 ver, hdr, cnt, len, strap;\r\nint N1, M1, N2, M2, P;\r\nint ret, i;\r\ni = 0;\r\ndo {\r\nramcfg.data = nvbios_perfEp(bios, i++, &ver, &hdr, &cnt,\r\n&ramcfg.size, &perfE);\r\nif (!ramcfg.data || (ver < 0x25 || ver >= 0x40) ||\r\n(ramcfg.size < 2)) {\r\nnv_error(pfb, "invalid/missing perftab entry\n");\r\nreturn -EINVAL;\r\n}\r\n} while (perfE.memory < freq);\r\nstrap = nvbios_ramcfg_index(nv_subdev(pfb));\r\nif (strap >= cnt) {\r\nnv_error(pfb, "invalid ramcfg strap\n");\r\nreturn -EINVAL;\r\n}\r\nramcfg.data += hdr + (strap * ramcfg.size);\r\nstrap = nv_ro08(bios, ramcfg.data + 0x01);\r\nif (strap != 0xff) {\r\ntiming.data = nvbios_timingEe(bios, strap, &ver, &hdr,\r\n&cnt, &len);\r\nif (!timing.data || ver != 0x10 || hdr < 0x12) {\r\nnv_error(pfb, "invalid/missing timing entry "\r\n"%02x %04x %02x %02x\n",\r\nstrap, timing.data, ver, hdr);\r\nreturn -EINVAL;\r\n}\r\n} else {\r\ntiming.data = 0;\r\n}\r\nret = ram_init(hwsq, nv_subdev(pfb));\r\nif (ret)\r\nreturn ret;\r\nram_wait(hwsq, 0x01, 0x00);\r\nram_wait(hwsq, 0x01, 0x01);\r\nram_wr32(hwsq, 0x611200, 0x00003300);\r\nram_wr32(hwsq, 0x002504, 0x00000001);\r\nram_nsec(hwsq, 8000);\r\nram_setf(hwsq, 0x10, 0x00);\r\nram_wait(hwsq, 0x00, 0x01);\r\nram_wr32(hwsq, 0x1002d4, 0x00000001);\r\nram_wr32(hwsq, 0x1002d0, 0x00000001);\r\nram_wr32(hwsq, 0x1002d0, 0x00000001);\r\nram_wr32(hwsq, 0x100210, 0x00000000);\r\nram_wr32(hwsq, 0x1002dc, 0x00000001);\r\nret = nvbios_pll_parse(bios, 0x004008, &mpll);\r\nmpll.vco2.max_freq = 0;\r\nif (ret == 0) {\r\nret = nv04_pll_calc(nv_subdev(pfb), &mpll, freq,\r\n&N1, &M1, &N2, &M2, &P);\r\nif (ret == 0)\r\nret = -EINVAL;\r\n}\r\nif (ret < 0)\r\nreturn ret;\r\nram_mask(hwsq, 0x00c040, 0xc000c000, 0x0000c000);\r\nram_mask(hwsq, 0x004008, 0x00000200, 0x00000200);\r\nram_mask(hwsq, 0x00400c, 0x0000ffff, (N1 << 8) | M1);\r\nram_mask(hwsq, 0x004008, 0x81ff0000, 0x80000000 | (mpll.bias_p << 19) |\r\n(P << 22) | (P << 16));\r\n#if QFX5800NVA0\r\nfor (i = 0; i < 8; i++)\r\nram_mask(hwsq, 0x100da0[i], 0x00000000, 0x00000000);\r\n#endif\r\nram_nsec(hwsq, 96000);\r\nram_mask(hwsq, 0x004008, 0x00002200, 0x00002000);\r\nram_wr32(hwsq, 0x1002dc, 0x00000000);\r\nram_wr32(hwsq, 0x100210, 0x80000000);\r\nram_nsec(hwsq, 12000);\r\nswitch (ram->base.type) {\r\ncase NV_MEM_TYPE_DDR2:\r\nram_nuke(hwsq, mr[0]);\r\nram_mask(hwsq, mr[0], 0x000, 0x000);\r\nbreak;\r\ncase NV_MEM_TYPE_GDDR3:\r\nram_mask(hwsq, mr[2], 0x000, 0x000);\r\nram_nuke(hwsq, mr[0]);\r\nram_mask(hwsq, mr[0], 0x000, 0x000);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nram_mask(hwsq, timing[3], 0x00000000, 0x00000000);\r\nram_mask(hwsq, timing[1], 0x00000000, 0x00000000);\r\nram_mask(hwsq, timing[6], 0x00000000, 0x00000000);\r\nram_mask(hwsq, timing[7], 0x00000000, 0x00000000);\r\nram_mask(hwsq, timing[8], 0x00000000, 0x00000000);\r\nram_mask(hwsq, timing[0], 0x00000000, 0x00000000);\r\nram_mask(hwsq, timing[2], 0x00000000, 0x00000000);\r\nram_mask(hwsq, timing[4], 0x00000000, 0x00000000);\r\nram_mask(hwsq, timing[5], 0x00000000, 0x00000000);\r\nram_mask(hwsq, timing[0], 0x00000000, 0x00000000);\r\n#if QFX5800NVA0\r\nram_nuke(hwsq, 0x100e24);\r\nram_mask(hwsq, 0x100e24, 0x00000000, 0x00000000);\r\nram_nuke(hwsq, 0x100e20);\r\nram_mask(hwsq, 0x100e20, 0x00000000, 0x00000000);\r\n#endif\r\nram_mask(hwsq, mr[0], 0x100, 0x100);\r\nram_mask(hwsq, mr[0], 0x100, 0x000);\r\nram_setf(hwsq, 0x10, 0x01);\r\nram_wait(hwsq, 0x00, 0x00);\r\nram_wr32(hwsq, 0x611200, 0x00003330);\r\nram_wr32(hwsq, 0x002504, 0x00000000);\r\nreturn 0;\r\n}\r\nstatic int\r\nnv50_ram_prog(struct nouveau_fb *pfb)\r\n{\r\nstruct nouveau_device *device = nv_device(pfb);\r\nstruct nv50_ram *ram = (void *)pfb->ram;\r\nstruct nv50_ramseq *hwsq = &ram->hwsq;\r\nram_exec(hwsq, nouveau_boolopt(device->cfgopt, "NvMemExec", true));\r\nreturn 0;\r\n}\r\nstatic void\r\nnv50_ram_tidy(struct nouveau_fb *pfb)\r\n{\r\nstruct nv50_ram *ram = (void *)pfb->ram;\r\nstruct nv50_ramseq *hwsq = &ram->hwsq;\r\nram_exec(hwsq, false);\r\n}\r\nvoid\r\n__nv50_ram_put(struct nouveau_fb *pfb, struct nouveau_mem *mem)\r\n{\r\nstruct nouveau_mm_node *this;\r\nwhile (!list_empty(&mem->regions)) {\r\nthis = list_first_entry(&mem->regions, typeof(*this), rl_entry);\r\nlist_del(&this->rl_entry);\r\nnouveau_mm_free(&pfb->vram, &this);\r\n}\r\nnouveau_mm_free(&pfb->tags, &mem->tag);\r\n}\r\nvoid\r\nnv50_ram_put(struct nouveau_fb *pfb, struct nouveau_mem **pmem)\r\n{\r\nstruct nouveau_mem *mem = *pmem;\r\n*pmem = NULL;\r\nif (unlikely(mem == NULL))\r\nreturn;\r\nmutex_lock(&pfb->base.mutex);\r\n__nv50_ram_put(pfb, mem);\r\nmutex_unlock(&pfb->base.mutex);\r\nkfree(mem);\r\n}\r\nint\r\nnv50_ram_get(struct nouveau_fb *pfb, u64 size, u32 align, u32 ncmin,\r\nu32 memtype, struct nouveau_mem **pmem)\r\n{\r\nstruct nouveau_mm *heap = &pfb->vram;\r\nstruct nouveau_mm *tags = &pfb->tags;\r\nstruct nouveau_mm_node *r;\r\nstruct nouveau_mem *mem;\r\nint comp = (memtype & 0x300) >> 8;\r\nint type = (memtype & 0x07f);\r\nint back = (memtype & 0x800);\r\nint min, max, ret;\r\nmax = (size >> 12);\r\nmin = ncmin ? (ncmin >> 12) : max;\r\nalign >>= 12;\r\nmem = kzalloc(sizeof(*mem), GFP_KERNEL);\r\nif (!mem)\r\nreturn -ENOMEM;\r\nmutex_lock(&pfb->base.mutex);\r\nif (comp) {\r\nif (align == 16) {\r\nint n = (max >> 4) * comp;\r\nret = nouveau_mm_head(tags, 1, n, n, 1, &mem->tag);\r\nif (ret)\r\nmem->tag = NULL;\r\n}\r\nif (unlikely(!mem->tag))\r\ncomp = 0;\r\n}\r\nINIT_LIST_HEAD(&mem->regions);\r\nmem->memtype = (comp << 7) | type;\r\nmem->size = max;\r\ntype = nv50_fb_memtype[type];\r\ndo {\r\nif (back)\r\nret = nouveau_mm_tail(heap, type, max, min, align, &r);\r\nelse\r\nret = nouveau_mm_head(heap, type, max, min, align, &r);\r\nif (ret) {\r\nmutex_unlock(&pfb->base.mutex);\r\npfb->ram->put(pfb, &mem);\r\nreturn ret;\r\n}\r\nlist_add_tail(&r->rl_entry, &mem->regions);\r\nmax -= r->length;\r\n} while (max);\r\nmutex_unlock(&pfb->base.mutex);\r\nr = list_first_entry(&mem->regions, struct nouveau_mm_node, rl_entry);\r\nmem->offset = (u64)r->offset << 12;\r\n*pmem = mem;\r\nreturn 0;\r\n}\r\nstatic u32\r\nnv50_fb_vram_rblock(struct nouveau_fb *pfb, struct nouveau_ram *ram)\r\n{\r\nint i, parts, colbits, rowbitsa, rowbitsb, banks;\r\nu64 rowsize, predicted;\r\nu32 r0, r4, rt, ru, rblock_size;\r\nr0 = nv_rd32(pfb, 0x100200);\r\nr4 = nv_rd32(pfb, 0x100204);\r\nrt = nv_rd32(pfb, 0x100250);\r\nru = nv_rd32(pfb, 0x001540);\r\nnv_debug(pfb, "memcfg 0x%08x 0x%08x 0x%08x 0x%08x\n", r0, r4, rt, ru);\r\nfor (i = 0, parts = 0; i < 8; i++) {\r\nif (ru & (0x00010000 << i))\r\nparts++;\r\n}\r\ncolbits = (r4 & 0x0000f000) >> 12;\r\nrowbitsa = ((r4 & 0x000f0000) >> 16) + 8;\r\nrowbitsb = ((r4 & 0x00f00000) >> 20) + 8;\r\nbanks = 1 << (((r4 & 0x03000000) >> 24) + 2);\r\nrowsize = parts * banks * (1 << colbits) * 8;\r\npredicted = rowsize << rowbitsa;\r\nif (r0 & 0x00000004)\r\npredicted += rowsize << rowbitsb;\r\nif (predicted != ram->size) {\r\nnv_warn(pfb, "memory controller reports %d MiB VRAM\n",\r\n(u32)(ram->size >> 20));\r\n}\r\nrblock_size = rowsize;\r\nif (rt & 1)\r\nrblock_size *= 3;\r\nnv_debug(pfb, "rblock %d bytes\n", rblock_size);\r\nreturn rblock_size;\r\n}\r\nint\r\nnv50_ram_create_(struct nouveau_object *parent, struct nouveau_object *engine,\r\nstruct nouveau_oclass *oclass, int length, void **pobject)\r\n{\r\nconst u32 rsvd_head = ( 256 * 1024) >> 12;\r\nconst u32 rsvd_tail = (1024 * 1024) >> 12;\r\nstruct nouveau_bios *bios = nouveau_bios(parent);\r\nstruct nouveau_fb *pfb = nouveau_fb(parent);\r\nstruct nouveau_ram *ram;\r\nint ret;\r\nret = nouveau_ram_create_(parent, engine, oclass, length, pobject);\r\nram = *pobject;\r\nif (ret)\r\nreturn ret;\r\nram->size = nv_rd32(pfb, 0x10020c);\r\nram->size = (ram->size & 0xffffff00) | ((ram->size & 0x000000ff) << 32);\r\nswitch (nv_rd32(pfb, 0x100714) & 0x00000007) {\r\ncase 0: ram->type = NV_MEM_TYPE_DDR1; break;\r\ncase 1:\r\nif (nouveau_fb_bios_memtype(bios) == NV_MEM_TYPE_DDR3)\r\nram->type = NV_MEM_TYPE_DDR3;\r\nelse\r\nram->type = NV_MEM_TYPE_DDR2;\r\nbreak;\r\ncase 2: ram->type = NV_MEM_TYPE_GDDR3; break;\r\ncase 3: ram->type = NV_MEM_TYPE_GDDR4; break;\r\ncase 4: ram->type = NV_MEM_TYPE_GDDR5; break;\r\ndefault:\r\nbreak;\r\n}\r\nret = nouveau_mm_init(&pfb->vram, rsvd_head, (ram->size >> 12) -\r\n(rsvd_head + rsvd_tail),\r\nnv50_fb_vram_rblock(pfb, ram) >> 12);\r\nif (ret)\r\nreturn ret;\r\nram->ranks = (nv_rd32(pfb, 0x100200) & 0x4) ? 2 : 1;\r\nram->tags = nv_rd32(pfb, 0x100320);\r\nram->get = nv50_ram_get;\r\nram->put = nv50_ram_put;\r\nreturn 0;\r\n}\r\nstatic int\r\nnv50_ram_ctor(struct nouveau_object *parent, struct nouveau_object *engine,\r\nstruct nouveau_oclass *oclass, void *data, u32 datasize,\r\nstruct nouveau_object **pobject)\r\n{\r\nstruct nv50_ram *ram;\r\nint ret, i;\r\nret = nv50_ram_create(parent, engine, oclass, &ram);\r\n*pobject = nv_object(ram);\r\nif (ret)\r\nreturn ret;\r\nswitch (ram->base.type) {\r\ncase NV_MEM_TYPE_DDR2:\r\ncase NV_MEM_TYPE_GDDR3:\r\nram->base.calc = nv50_ram_calc;\r\nram->base.prog = nv50_ram_prog;\r\nram->base.tidy = nv50_ram_tidy;\r\nbreak;\r\ndefault:\r\nnv_warn(ram, "reclocking of this ram type unsupported\n");\r\nreturn 0;\r\n}\r\nram->hwsq.r_0x002504 = hwsq_reg(0x002504);\r\nram->hwsq.r_0x00c040 = hwsq_reg(0x00c040);\r\nram->hwsq.r_0x004008 = hwsq_reg(0x004008);\r\nram->hwsq.r_0x00400c = hwsq_reg(0x00400c);\r\nram->hwsq.r_0x100210 = hwsq_reg(0x100210);\r\nram->hwsq.r_0x1002d0 = hwsq_reg(0x1002d0);\r\nram->hwsq.r_0x1002d4 = hwsq_reg(0x1002d4);\r\nram->hwsq.r_0x1002dc = hwsq_reg(0x1002dc);\r\nfor (i = 0; i < 8; i++)\r\nram->hwsq.r_0x100da0[i] = hwsq_reg(0x100da0 + (i * 0x04));\r\nram->hwsq.r_0x100e20 = hwsq_reg(0x100e20);\r\nram->hwsq.r_0x100e24 = hwsq_reg(0x100e24);\r\nram->hwsq.r_0x611200 = hwsq_reg(0x611200);\r\nfor (i = 0; i < 9; i++)\r\nram->hwsq.r_timing[i] = hwsq_reg(0x100220 + (i * 0x04));\r\nif (ram->base.ranks > 1) {\r\nram->hwsq.r_mr[0] = hwsq_reg2(0x1002c0, 0x1002c8);\r\nram->hwsq.r_mr[1] = hwsq_reg2(0x1002c4, 0x1002cc);\r\nram->hwsq.r_mr[2] = hwsq_reg2(0x1002e0, 0x1002e8);\r\nram->hwsq.r_mr[3] = hwsq_reg2(0x1002e4, 0x1002ec);\r\n} else {\r\nram->hwsq.r_mr[0] = hwsq_reg(0x1002c0);\r\nram->hwsq.r_mr[1] = hwsq_reg(0x1002c4);\r\nram->hwsq.r_mr[2] = hwsq_reg(0x1002e0);\r\nram->hwsq.r_mr[3] = hwsq_reg(0x1002e4);\r\n}\r\nreturn 0;\r\n}
