static void rds_iw_send_rdma_complete(struct rds_message *rm,\r\nint wc_status)\r\n{\r\nint notify_status;\r\nswitch (wc_status) {\r\ncase IB_WC_WR_FLUSH_ERR:\r\nreturn;\r\ncase IB_WC_SUCCESS:\r\nnotify_status = RDS_RDMA_SUCCESS;\r\nbreak;\r\ncase IB_WC_REM_ACCESS_ERR:\r\nnotify_status = RDS_RDMA_REMOTE_ERROR;\r\nbreak;\r\ndefault:\r\nnotify_status = RDS_RDMA_OTHER_ERROR;\r\nbreak;\r\n}\r\nrds_rdma_send_complete(rm, notify_status);\r\n}\r\nstatic void rds_iw_send_unmap_rdma(struct rds_iw_connection *ic,\r\nstruct rm_rdma_op *op)\r\n{\r\nif (op->op_mapped) {\r\nib_dma_unmap_sg(ic->i_cm_id->device,\r\nop->op_sg, op->op_nents,\r\nop->op_write ? DMA_TO_DEVICE : DMA_FROM_DEVICE);\r\nop->op_mapped = 0;\r\n}\r\n}\r\nstatic void rds_iw_send_unmap_rm(struct rds_iw_connection *ic,\r\nstruct rds_iw_send_work *send,\r\nint wc_status)\r\n{\r\nstruct rds_message *rm = send->s_rm;\r\nrdsdebug("ic %p send %p rm %p\n", ic, send, rm);\r\nib_dma_unmap_sg(ic->i_cm_id->device,\r\nrm->data.op_sg, rm->data.op_nents,\r\nDMA_TO_DEVICE);\r\nif (rm->rdma.op_active) {\r\nrds_iw_send_unmap_rdma(ic, &rm->rdma);\r\nrds_iw_send_rdma_complete(rm, wc_status);\r\nif (rm->rdma.op_write)\r\nrds_stats_add(s_send_rdma_bytes, rm->rdma.op_bytes);\r\nelse\r\nrds_stats_add(s_recv_rdma_bytes, rm->rdma.op_bytes);\r\n}\r\nrds_message_unmapped(rm);\r\nrds_message_put(rm);\r\nsend->s_rm = NULL;\r\n}\r\nvoid rds_iw_send_init_ring(struct rds_iw_connection *ic)\r\n{\r\nstruct rds_iw_send_work *send;\r\nu32 i;\r\nfor (i = 0, send = ic->i_sends; i < ic->i_send_ring.w_nr; i++, send++) {\r\nstruct ib_sge *sge;\r\nsend->s_rm = NULL;\r\nsend->s_op = NULL;\r\nsend->s_mapping = NULL;\r\nsend->s_wr.next = NULL;\r\nsend->s_wr.wr_id = i;\r\nsend->s_wr.sg_list = send->s_sge;\r\nsend->s_wr.num_sge = 1;\r\nsend->s_wr.opcode = IB_WR_SEND;\r\nsend->s_wr.send_flags = 0;\r\nsend->s_wr.ex.imm_data = 0;\r\nsge = rds_iw_data_sge(ic, send->s_sge);\r\nsge->lkey = 0;\r\nsge = rds_iw_header_sge(ic, send->s_sge);\r\nsge->addr = ic->i_send_hdrs_dma + (i * sizeof(struct rds_header));\r\nsge->length = sizeof(struct rds_header);\r\nsge->lkey = 0;\r\nsend->s_mr = ib_alloc_fast_reg_mr(ic->i_pd, fastreg_message_size);\r\nif (IS_ERR(send->s_mr)) {\r\nprintk(KERN_WARNING "RDS/IW: ib_alloc_fast_reg_mr failed\n");\r\nbreak;\r\n}\r\nsend->s_page_list = ib_alloc_fast_reg_page_list(\r\nic->i_cm_id->device, fastreg_message_size);\r\nif (IS_ERR(send->s_page_list)) {\r\nprintk(KERN_WARNING "RDS/IW: ib_alloc_fast_reg_page_list failed\n");\r\nbreak;\r\n}\r\n}\r\n}\r\nvoid rds_iw_send_clear_ring(struct rds_iw_connection *ic)\r\n{\r\nstruct rds_iw_send_work *send;\r\nu32 i;\r\nfor (i = 0, send = ic->i_sends; i < ic->i_send_ring.w_nr; i++, send++) {\r\nBUG_ON(!send->s_mr);\r\nib_dereg_mr(send->s_mr);\r\nBUG_ON(!send->s_page_list);\r\nib_free_fast_reg_page_list(send->s_page_list);\r\nif (send->s_wr.opcode == 0xdead)\r\ncontinue;\r\nif (send->s_rm)\r\nrds_iw_send_unmap_rm(ic, send, IB_WC_WR_FLUSH_ERR);\r\nif (send->s_op)\r\nrds_iw_send_unmap_rdma(ic, send->s_op);\r\n}\r\n}\r\nvoid rds_iw_send_cq_comp_handler(struct ib_cq *cq, void *context)\r\n{\r\nstruct rds_connection *conn = context;\r\nstruct rds_iw_connection *ic = conn->c_transport_data;\r\nstruct ib_wc wc;\r\nstruct rds_iw_send_work *send;\r\nu32 completed;\r\nu32 oldest;\r\nu32 i;\r\nint ret;\r\nrdsdebug("cq %p conn %p\n", cq, conn);\r\nrds_iw_stats_inc(s_iw_tx_cq_call);\r\nret = ib_req_notify_cq(cq, IB_CQ_NEXT_COMP);\r\nif (ret)\r\nrdsdebug("ib_req_notify_cq send failed: %d\n", ret);\r\nwhile (ib_poll_cq(cq, 1, &wc) > 0) {\r\nrdsdebug("wc wr_id 0x%llx status %u byte_len %u imm_data %u\n",\r\n(unsigned long long)wc.wr_id, wc.status, wc.byte_len,\r\nbe32_to_cpu(wc.ex.imm_data));\r\nrds_iw_stats_inc(s_iw_tx_cq_event);\r\nif (wc.status != IB_WC_SUCCESS) {\r\nprintk(KERN_ERR "WC Error: status = %d opcode = %d\n", wc.status, wc.opcode);\r\nbreak;\r\n}\r\nif (wc.opcode == IB_WC_LOCAL_INV && wc.wr_id == RDS_IW_LOCAL_INV_WR_ID) {\r\nic->i_fastreg_posted = 0;\r\ncontinue;\r\n}\r\nif (wc.opcode == IB_WC_FAST_REG_MR && wc.wr_id == RDS_IW_FAST_REG_WR_ID) {\r\nic->i_fastreg_posted = 1;\r\ncontinue;\r\n}\r\nif (wc.wr_id == RDS_IW_ACK_WR_ID) {\r\nif (time_after(jiffies, ic->i_ack_queued + HZ/2))\r\nrds_iw_stats_inc(s_iw_tx_stalled);\r\nrds_iw_ack_send_complete(ic);\r\ncontinue;\r\n}\r\noldest = rds_iw_ring_oldest(&ic->i_send_ring);\r\ncompleted = rds_iw_ring_completed(&ic->i_send_ring, wc.wr_id, oldest);\r\nfor (i = 0; i < completed; i++) {\r\nsend = &ic->i_sends[oldest];\r\nswitch (send->s_wr.opcode) {\r\ncase IB_WR_SEND:\r\nif (send->s_rm)\r\nrds_iw_send_unmap_rm(ic, send, wc.status);\r\nbreak;\r\ncase IB_WR_FAST_REG_MR:\r\ncase IB_WR_RDMA_WRITE:\r\ncase IB_WR_RDMA_READ:\r\ncase IB_WR_RDMA_READ_WITH_INV:\r\nbreak;\r\ndefault:\r\nprintk_ratelimited(KERN_NOTICE\r\n"RDS/IW: %s: unexpected opcode 0x%x in WR!\n",\r\n__func__, send->s_wr.opcode);\r\nbreak;\r\n}\r\nsend->s_wr.opcode = 0xdead;\r\nsend->s_wr.num_sge = 1;\r\nif (time_after(jiffies, send->s_queued + HZ/2))\r\nrds_iw_stats_inc(s_iw_tx_stalled);\r\nif (unlikely(wc.status == IB_WC_REM_ACCESS_ERR && send->s_op)) {\r\nstruct rds_message *rm;\r\nrm = rds_send_get_message(conn, send->s_op);\r\nif (rm)\r\nrds_iw_send_rdma_complete(rm, wc.status);\r\n}\r\noldest = (oldest + 1) % ic->i_send_ring.w_nr;\r\n}\r\nrds_iw_ring_free(&ic->i_send_ring, completed);\r\nif (test_and_clear_bit(RDS_LL_SEND_FULL, &conn->c_flags) ||\r\ntest_bit(0, &conn->c_map_queued))\r\nqueue_delayed_work(rds_wq, &conn->c_send_w, 0);\r\nif (wc.status != IB_WC_SUCCESS && rds_conn_up(conn)) {\r\nrds_iw_conn_error(conn,\r\n"send completion on %pI4 "\r\n"had status %u, disconnecting and reconnecting\n",\r\n&conn->c_faddr, wc.status);\r\n}\r\n}\r\n}\r\nint rds_iw_send_grab_credits(struct rds_iw_connection *ic,\r\nu32 wanted, u32 *adv_credits, int need_posted, int max_posted)\r\n{\r\nunsigned int avail, posted, got = 0, advertise;\r\nlong oldval, newval;\r\n*adv_credits = 0;\r\nif (!ic->i_flowctl)\r\nreturn wanted;\r\ntry_again:\r\nadvertise = 0;\r\noldval = newval = atomic_read(&ic->i_credits);\r\nposted = IB_GET_POST_CREDITS(oldval);\r\navail = IB_GET_SEND_CREDITS(oldval);\r\nrdsdebug("rds_iw_send_grab_credits(%u): credits=%u posted=%u\n",\r\nwanted, avail, posted);\r\nif (avail && !posted)\r\navail--;\r\nif (avail < wanted) {\r\nstruct rds_connection *conn = ic->i_cm_id->context;\r\nset_bit(RDS_LL_SEND_FULL, &conn->c_flags);\r\ngot = avail;\r\n} else {\r\ngot = wanted;\r\n}\r\nnewval -= IB_SET_SEND_CREDITS(got);\r\nif (posted && (got || need_posted)) {\r\nadvertise = min_t(unsigned int, posted, max_posted);\r\nnewval -= IB_SET_POST_CREDITS(advertise);\r\n}\r\nif (atomic_cmpxchg(&ic->i_credits, oldval, newval) != oldval)\r\ngoto try_again;\r\n*adv_credits = advertise;\r\nreturn got;\r\n}\r\nvoid rds_iw_send_add_credits(struct rds_connection *conn, unsigned int credits)\r\n{\r\nstruct rds_iw_connection *ic = conn->c_transport_data;\r\nif (credits == 0)\r\nreturn;\r\nrdsdebug("rds_iw_send_add_credits(%u): current=%u%s\n",\r\ncredits,\r\nIB_GET_SEND_CREDITS(atomic_read(&ic->i_credits)),\r\ntest_bit(RDS_LL_SEND_FULL, &conn->c_flags) ? ", ll_send_full" : "");\r\natomic_add(IB_SET_SEND_CREDITS(credits), &ic->i_credits);\r\nif (test_and_clear_bit(RDS_LL_SEND_FULL, &conn->c_flags))\r\nqueue_delayed_work(rds_wq, &conn->c_send_w, 0);\r\nWARN_ON(IB_GET_SEND_CREDITS(credits) >= 16384);\r\nrds_iw_stats_inc(s_iw_rx_credit_updates);\r\n}\r\nvoid rds_iw_advertise_credits(struct rds_connection *conn, unsigned int posted)\r\n{\r\nstruct rds_iw_connection *ic = conn->c_transport_data;\r\nif (posted == 0)\r\nreturn;\r\natomic_add(IB_SET_POST_CREDITS(posted), &ic->i_credits);\r\nif (IB_GET_POST_CREDITS(atomic_read(&ic->i_credits)) >= 16)\r\nset_bit(IB_ACK_REQUESTED, &ic->i_ack_flags);\r\n}\r\nstatic inline void\r\nrds_iw_xmit_populate_wr(struct rds_iw_connection *ic,\r\nstruct rds_iw_send_work *send, unsigned int pos,\r\nunsigned long buffer, unsigned int length,\r\nint send_flags)\r\n{\r\nstruct ib_sge *sge;\r\nWARN_ON(pos != send - ic->i_sends);\r\nsend->s_wr.send_flags = send_flags;\r\nsend->s_wr.opcode = IB_WR_SEND;\r\nsend->s_wr.num_sge = 2;\r\nsend->s_wr.next = NULL;\r\nsend->s_queued = jiffies;\r\nsend->s_op = NULL;\r\nif (length != 0) {\r\nsge = rds_iw_data_sge(ic, send->s_sge);\r\nsge->addr = buffer;\r\nsge->length = length;\r\nsge->lkey = rds_iw_local_dma_lkey(ic);\r\nsge = rds_iw_header_sge(ic, send->s_sge);\r\n} else {\r\nsend->s_wr.num_sge = 1;\r\nsge = &send->s_sge[0];\r\n}\r\nsge->addr = ic->i_send_hdrs_dma + (pos * sizeof(struct rds_header));\r\nsge->length = sizeof(struct rds_header);\r\nsge->lkey = rds_iw_local_dma_lkey(ic);\r\n}\r\nint rds_iw_xmit(struct rds_connection *conn, struct rds_message *rm,\r\nunsigned int hdr_off, unsigned int sg, unsigned int off)\r\n{\r\nstruct rds_iw_connection *ic = conn->c_transport_data;\r\nstruct ib_device *dev = ic->i_cm_id->device;\r\nstruct rds_iw_send_work *send = NULL;\r\nstruct rds_iw_send_work *first;\r\nstruct rds_iw_send_work *prev;\r\nstruct ib_send_wr *failed_wr;\r\nstruct scatterlist *scat;\r\nu32 pos;\r\nu32 i;\r\nu32 work_alloc;\r\nu32 credit_alloc;\r\nu32 posted;\r\nu32 adv_credits = 0;\r\nint send_flags = 0;\r\nint sent;\r\nint ret;\r\nint flow_controlled = 0;\r\nBUG_ON(off % RDS_FRAG_SIZE);\r\nBUG_ON(hdr_off != 0 && hdr_off != sizeof(struct rds_header));\r\nif (rds_rdma_cookie_key(rm->m_rdma_cookie) && !ic->i_fastreg_posted) {\r\nret = -EAGAIN;\r\ngoto out;\r\n}\r\nif (be32_to_cpu(rm->m_inc.i_hdr.h_len) == 0)\r\ni = 1;\r\nelse\r\ni = ceil(be32_to_cpu(rm->m_inc.i_hdr.h_len), RDS_FRAG_SIZE);\r\nwork_alloc = rds_iw_ring_alloc(&ic->i_send_ring, i, &pos);\r\nif (work_alloc == 0) {\r\nset_bit(RDS_LL_SEND_FULL, &conn->c_flags);\r\nrds_iw_stats_inc(s_iw_tx_ring_full);\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\ncredit_alloc = work_alloc;\r\nif (ic->i_flowctl) {\r\ncredit_alloc = rds_iw_send_grab_credits(ic, work_alloc, &posted, 0, RDS_MAX_ADV_CREDIT);\r\nadv_credits += posted;\r\nif (credit_alloc < work_alloc) {\r\nrds_iw_ring_unalloc(&ic->i_send_ring, work_alloc - credit_alloc);\r\nwork_alloc = credit_alloc;\r\nflow_controlled++;\r\n}\r\nif (work_alloc == 0) {\r\nset_bit(RDS_LL_SEND_FULL, &conn->c_flags);\r\nrds_iw_stats_inc(s_iw_tx_throttle);\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\n}\r\nif (!ic->i_rm) {\r\nif (rm->data.op_nents) {\r\nrm->data.op_count = ib_dma_map_sg(dev,\r\nrm->data.op_sg,\r\nrm->data.op_nents,\r\nDMA_TO_DEVICE);\r\nrdsdebug("ic %p mapping rm %p: %d\n", ic, rm, rm->data.op_count);\r\nif (rm->data.op_count == 0) {\r\nrds_iw_stats_inc(s_iw_tx_sg_mapping_failure);\r\nrds_iw_ring_unalloc(&ic->i_send_ring, work_alloc);\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\n} else {\r\nrm->data.op_count = 0;\r\n}\r\nic->i_unsignaled_wrs = rds_iw_sysctl_max_unsig_wrs;\r\nic->i_unsignaled_bytes = rds_iw_sysctl_max_unsig_bytes;\r\nrds_message_addref(rm);\r\nic->i_rm = rm;\r\nif (test_bit(RDS_MSG_ACK_REQUIRED, &rm->m_flags))\r\nrm->m_inc.i_hdr.h_flags |= RDS_FLAG_ACK_REQUIRED;\r\nif (test_bit(RDS_MSG_RETRANSMITTED, &rm->m_flags))\r\nrm->m_inc.i_hdr.h_flags |= RDS_FLAG_RETRANSMITTED;\r\nif (rm->rdma.op_active) {\r\nstruct rds_ext_header_rdma ext_hdr;\r\next_hdr.h_rdma_rkey = cpu_to_be32(rm->rdma.op_rkey);\r\nrds_message_add_extension(&rm->m_inc.i_hdr,\r\nRDS_EXTHDR_RDMA, &ext_hdr, sizeof(ext_hdr));\r\n}\r\nif (rm->m_rdma_cookie) {\r\nrds_message_add_rdma_dest_extension(&rm->m_inc.i_hdr,\r\nrds_rdma_cookie_key(rm->m_rdma_cookie),\r\nrds_rdma_cookie_offset(rm->m_rdma_cookie));\r\n}\r\nrm->m_inc.i_hdr.h_ack = cpu_to_be64(rds_iw_piggyb_ack(ic));\r\nrds_message_make_checksum(&rm->m_inc.i_hdr);\r\nrds_iw_send_grab_credits(ic, 0, &posted, 1, RDS_MAX_ADV_CREDIT - adv_credits);\r\nadv_credits += posted;\r\nBUG_ON(adv_credits > 255);\r\n}\r\nsend = &ic->i_sends[pos];\r\nfirst = send;\r\nprev = NULL;\r\nscat = &rm->data.op_sg[sg];\r\nsent = 0;\r\ni = 0;\r\nif (rm->rdma.op_active && rm->rdma.op_fence)\r\nsend_flags = IB_SEND_FENCE;\r\nif (be32_to_cpu(rm->m_inc.i_hdr.h_len) == 0) {\r\nrds_iw_xmit_populate_wr(ic, send, pos, 0, 0, send_flags);\r\ngoto add_header;\r\n}\r\nfor (; i < work_alloc && scat != &rm->data.op_sg[rm->data.op_count]; i++) {\r\nunsigned int len;\r\nsend = &ic->i_sends[pos];\r\nlen = min(RDS_FRAG_SIZE, ib_sg_dma_len(dev, scat) - off);\r\nrds_iw_xmit_populate_wr(ic, send, pos,\r\nib_sg_dma_address(dev, scat) + off, len,\r\nsend_flags);\r\nif (ic->i_unsignaled_wrs-- == 0) {\r\nic->i_unsignaled_wrs = rds_iw_sysctl_max_unsig_wrs;\r\nsend->s_wr.send_flags |= IB_SEND_SIGNALED | IB_SEND_SOLICITED;\r\n}\r\nic->i_unsignaled_bytes -= len;\r\nif (ic->i_unsignaled_bytes <= 0) {\r\nic->i_unsignaled_bytes = rds_iw_sysctl_max_unsig_bytes;\r\nsend->s_wr.send_flags |= IB_SEND_SIGNALED | IB_SEND_SOLICITED;\r\n}\r\nif (flow_controlled && i == (work_alloc-1))\r\nsend->s_wr.send_flags |= IB_SEND_SIGNALED | IB_SEND_SOLICITED;\r\nrdsdebug("send %p wr %p num_sge %u next %p\n", send,\r\n&send->s_wr, send->s_wr.num_sge, send->s_wr.next);\r\nsent += len;\r\noff += len;\r\nif (off == ib_sg_dma_len(dev, scat)) {\r\nscat++;\r\noff = 0;\r\n}\r\nadd_header:\r\nmemcpy(&ic->i_send_hdrs[pos], &rm->m_inc.i_hdr, sizeof(struct rds_header));\r\nif (0) {\r\nstruct rds_header *hdr = &ic->i_send_hdrs[pos];\r\nprintk(KERN_NOTICE "send WR dport=%u flags=0x%x len=%d\n",\r\nbe16_to_cpu(hdr->h_dport),\r\nhdr->h_flags,\r\nbe32_to_cpu(hdr->h_len));\r\n}\r\nif (adv_credits) {\r\nstruct rds_header *hdr = &ic->i_send_hdrs[pos];\r\nhdr->h_credit = adv_credits;\r\nrds_message_make_checksum(hdr);\r\nadv_credits = 0;\r\nrds_iw_stats_inc(s_iw_tx_credit_updates);\r\n}\r\nif (prev)\r\nprev->s_wr.next = &send->s_wr;\r\nprev = send;\r\npos = (pos + 1) % ic->i_send_ring.w_nr;\r\n}\r\nif (hdr_off == 0)\r\nsent += sizeof(struct rds_header);\r\nif (scat == &rm->data.op_sg[rm->data.op_count]) {\r\nprev->s_rm = ic->i_rm;\r\nprev->s_wr.send_flags |= IB_SEND_SIGNALED | IB_SEND_SOLICITED;\r\nic->i_rm = NULL;\r\n}\r\nif (i < work_alloc) {\r\nrds_iw_ring_unalloc(&ic->i_send_ring, work_alloc - i);\r\nwork_alloc = i;\r\n}\r\nif (ic->i_flowctl && i < credit_alloc)\r\nrds_iw_send_add_credits(conn, credit_alloc - i);\r\nfailed_wr = &first->s_wr;\r\nret = ib_post_send(ic->i_cm_id->qp, &first->s_wr, &failed_wr);\r\nrdsdebug("ic %p first %p (wr %p) ret %d wr %p\n", ic,\r\nfirst, &first->s_wr, ret, failed_wr);\r\nBUG_ON(failed_wr != &first->s_wr);\r\nif (ret) {\r\nprintk(KERN_WARNING "RDS/IW: ib_post_send to %pI4 "\r\n"returned %d\n", &conn->c_faddr, ret);\r\nrds_iw_ring_unalloc(&ic->i_send_ring, work_alloc);\r\nif (prev->s_rm) {\r\nic->i_rm = prev->s_rm;\r\nprev->s_rm = NULL;\r\n}\r\ngoto out;\r\n}\r\nret = sent;\r\nout:\r\nBUG_ON(adv_credits);\r\nreturn ret;\r\n}\r\nstatic void rds_iw_build_send_fastreg(struct rds_iw_device *rds_iwdev, struct rds_iw_connection *ic, struct rds_iw_send_work *send, int nent, int len, u64 sg_addr)\r\n{\r\nBUG_ON(nent > send->s_page_list->max_page_list_len);\r\nsend->s_wr.opcode = IB_WR_FAST_REG_MR;\r\nsend->s_wr.wr.fast_reg.length = len;\r\nsend->s_wr.wr.fast_reg.rkey = send->s_mr->rkey;\r\nsend->s_wr.wr.fast_reg.page_list = send->s_page_list;\r\nsend->s_wr.wr.fast_reg.page_list_len = nent;\r\nsend->s_wr.wr.fast_reg.page_shift = PAGE_SHIFT;\r\nsend->s_wr.wr.fast_reg.access_flags = IB_ACCESS_REMOTE_WRITE;\r\nsend->s_wr.wr.fast_reg.iova_start = sg_addr;\r\nib_update_fast_reg_key(send->s_mr, send->s_remap_count++);\r\n}\r\nint rds_iw_xmit_rdma(struct rds_connection *conn, struct rm_rdma_op *op)\r\n{\r\nstruct rds_iw_connection *ic = conn->c_transport_data;\r\nstruct rds_iw_send_work *send = NULL;\r\nstruct rds_iw_send_work *first;\r\nstruct rds_iw_send_work *prev;\r\nstruct ib_send_wr *failed_wr;\r\nstruct rds_iw_device *rds_iwdev;\r\nstruct scatterlist *scat;\r\nunsigned long len;\r\nu64 remote_addr = op->op_remote_addr;\r\nu32 pos, fr_pos;\r\nu32 work_alloc;\r\nu32 i;\r\nu32 j;\r\nint sent;\r\nint ret;\r\nint num_sge;\r\nrds_iwdev = ib_get_client_data(ic->i_cm_id->device, &rds_iw_client);\r\nif (!op->op_mapped) {\r\nop->op_count = ib_dma_map_sg(ic->i_cm_id->device,\r\nop->op_sg, op->op_nents, (op->op_write) ?\r\nDMA_TO_DEVICE : DMA_FROM_DEVICE);\r\nrdsdebug("ic %p mapping op %p: %d\n", ic, op, op->op_count);\r\nif (op->op_count == 0) {\r\nrds_iw_stats_inc(s_iw_tx_sg_mapping_failure);\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\nop->op_mapped = 1;\r\n}\r\nif (!op->op_write) {\r\nwork_alloc = rds_iw_ring_alloc(&ic->i_send_ring, 1, &fr_pos);\r\nif (work_alloc != 1) {\r\nrds_iw_ring_unalloc(&ic->i_send_ring, work_alloc);\r\nrds_iw_stats_inc(s_iw_tx_ring_full);\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\n}\r\ni = ceil(op->op_count, rds_iwdev->max_sge);\r\nwork_alloc = rds_iw_ring_alloc(&ic->i_send_ring, i, &pos);\r\nif (work_alloc != i) {\r\nrds_iw_ring_unalloc(&ic->i_send_ring, work_alloc);\r\nrds_iw_stats_inc(s_iw_tx_ring_full);\r\nret = -ENOMEM;\r\ngoto out;\r\n}\r\nsend = &ic->i_sends[pos];\r\nif (!op->op_write) {\r\nfirst = prev = &ic->i_sends[fr_pos];\r\n} else {\r\nfirst = send;\r\nprev = NULL;\r\n}\r\nscat = &op->op_sg[0];\r\nsent = 0;\r\nnum_sge = op->op_count;\r\nfor (i = 0; i < work_alloc && scat != &op->op_sg[op->op_count]; i++) {\r\nsend->s_wr.send_flags = 0;\r\nsend->s_queued = jiffies;\r\nif (ic->i_unsignaled_wrs-- == 0) {\r\nic->i_unsignaled_wrs = rds_iw_sysctl_max_unsig_wrs;\r\nsend->s_wr.send_flags = IB_SEND_SIGNALED;\r\n}\r\nif (op->op_write)\r\nsend->s_wr.opcode = IB_WR_RDMA_WRITE;\r\nelse\r\nsend->s_wr.opcode = IB_WR_RDMA_READ_WITH_INV;\r\nsend->s_wr.wr.rdma.remote_addr = remote_addr;\r\nsend->s_wr.wr.rdma.rkey = op->op_rkey;\r\nsend->s_op = op;\r\nif (num_sge > rds_iwdev->max_sge) {\r\nsend->s_wr.num_sge = rds_iwdev->max_sge;\r\nnum_sge -= rds_iwdev->max_sge;\r\n} else\r\nsend->s_wr.num_sge = num_sge;\r\nsend->s_wr.next = NULL;\r\nif (prev)\r\nprev->s_wr.next = &send->s_wr;\r\nfor (j = 0; j < send->s_wr.num_sge && scat != &op->op_sg[op->op_count]; j++) {\r\nlen = ib_sg_dma_len(ic->i_cm_id->device, scat);\r\nif (send->s_wr.opcode == IB_WR_RDMA_READ_WITH_INV)\r\nsend->s_page_list->page_list[j] = ib_sg_dma_address(ic->i_cm_id->device, scat);\r\nelse {\r\nsend->s_sge[j].addr = ib_sg_dma_address(ic->i_cm_id->device, scat);\r\nsend->s_sge[j].length = len;\r\nsend->s_sge[j].lkey = rds_iw_local_dma_lkey(ic);\r\n}\r\nsent += len;\r\nrdsdebug("ic %p sent %d remote_addr %llu\n", ic, sent, remote_addr);\r\nremote_addr += len;\r\nscat++;\r\n}\r\nif (send->s_wr.opcode == IB_WR_RDMA_READ_WITH_INV) {\r\nsend->s_wr.num_sge = 1;\r\nsend->s_sge[0].addr = conn->c_xmit_rm->m_rs->rs_user_addr;\r\nsend->s_sge[0].length = conn->c_xmit_rm->m_rs->rs_user_bytes;\r\nsend->s_sge[0].lkey = ic->i_sends[fr_pos].s_mr->lkey;\r\n}\r\nrdsdebug("send %p wr %p num_sge %u next %p\n", send,\r\n&send->s_wr, send->s_wr.num_sge, send->s_wr.next);\r\nprev = send;\r\nif (++send == &ic->i_sends[ic->i_send_ring.w_nr])\r\nsend = ic->i_sends;\r\n}\r\nif (scat == &op->op_sg[op->op_count])\r\nfirst->s_wr.send_flags = IB_SEND_SIGNALED;\r\nif (i < work_alloc) {\r\nrds_iw_ring_unalloc(&ic->i_send_ring, work_alloc - i);\r\nwork_alloc = i;\r\n}\r\nif (!op->op_write) {\r\nrds_iw_build_send_fastreg(rds_iwdev, ic, &ic->i_sends[fr_pos],\r\nop->op_count, sent, conn->c_xmit_rm->m_rs->rs_user_addr);\r\nwork_alloc++;\r\n}\r\nfailed_wr = &first->s_wr;\r\nret = ib_post_send(ic->i_cm_id->qp, &first->s_wr, &failed_wr);\r\nrdsdebug("ic %p first %p (wr %p) ret %d wr %p\n", ic,\r\nfirst, &first->s_wr, ret, failed_wr);\r\nBUG_ON(failed_wr != &first->s_wr);\r\nif (ret) {\r\nprintk(KERN_WARNING "RDS/IW: rdma ib_post_send to %pI4 "\r\n"returned %d\n", &conn->c_faddr, ret);\r\nrds_iw_ring_unalloc(&ic->i_send_ring, work_alloc);\r\ngoto out;\r\n}\r\nout:\r\nreturn ret;\r\n}\r\nvoid rds_iw_xmit_complete(struct rds_connection *conn)\r\n{\r\nstruct rds_iw_connection *ic = conn->c_transport_data;\r\nrds_iw_attempt_ack(ic);\r\n}
