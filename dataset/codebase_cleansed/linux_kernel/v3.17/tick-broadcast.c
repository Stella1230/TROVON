static inline void tick_broadcast_clear_oneshot(int cpu) { }\r\nstruct tick_device *tick_get_broadcast_device(void)\r\n{\r\nreturn &tick_broadcast_device;\r\n}\r\nstruct cpumask *tick_get_broadcast_mask(void)\r\n{\r\nreturn tick_broadcast_mask;\r\n}\r\nstatic void tick_broadcast_start_periodic(struct clock_event_device *bc)\r\n{\r\nif (bc)\r\ntick_setup_periodic(bc, 1);\r\n}\r\nstatic bool tick_check_broadcast_device(struct clock_event_device *curdev,\r\nstruct clock_event_device *newdev)\r\n{\r\nif ((newdev->features & CLOCK_EVT_FEAT_DUMMY) ||\r\n(newdev->features & CLOCK_EVT_FEAT_PERCPU) ||\r\n(newdev->features & CLOCK_EVT_FEAT_C3STOP))\r\nreturn false;\r\nif (tick_broadcast_device.mode == TICKDEV_MODE_ONESHOT &&\r\n!(newdev->features & CLOCK_EVT_FEAT_ONESHOT))\r\nreturn false;\r\nreturn !curdev || newdev->rating > curdev->rating;\r\n}\r\nvoid tick_install_broadcast_device(struct clock_event_device *dev)\r\n{\r\nstruct clock_event_device *cur = tick_broadcast_device.evtdev;\r\nif (!tick_check_broadcast_device(cur, dev))\r\nreturn;\r\nif (!try_module_get(dev->owner))\r\nreturn;\r\nclockevents_exchange_device(cur, dev);\r\nif (cur)\r\ncur->event_handler = clockevents_handle_noop;\r\ntick_broadcast_device.evtdev = dev;\r\nif (!cpumask_empty(tick_broadcast_mask))\r\ntick_broadcast_start_periodic(dev);\r\nif (dev->features & CLOCK_EVT_FEAT_ONESHOT)\r\ntick_clock_notify();\r\n}\r\nint tick_is_broadcast_device(struct clock_event_device *dev)\r\n{\r\nreturn (dev && tick_broadcast_device.evtdev == dev);\r\n}\r\nint tick_broadcast_update_freq(struct clock_event_device *dev, u32 freq)\r\n{\r\nint ret = -ENODEV;\r\nif (tick_is_broadcast_device(dev)) {\r\nraw_spin_lock(&tick_broadcast_lock);\r\nret = __clockevents_update_freq(dev, freq);\r\nraw_spin_unlock(&tick_broadcast_lock);\r\n}\r\nreturn ret;\r\n}\r\nstatic void err_broadcast(const struct cpumask *mask)\r\n{\r\npr_crit_once("Failed to broadcast timer tick. Some CPUs may be unresponsive.\n");\r\n}\r\nstatic void tick_device_setup_broadcast_func(struct clock_event_device *dev)\r\n{\r\nif (!dev->broadcast)\r\ndev->broadcast = tick_broadcast;\r\nif (!dev->broadcast) {\r\npr_warn_once("%s depends on broadcast, but no broadcast function available\n",\r\ndev->name);\r\ndev->broadcast = err_broadcast;\r\n}\r\n}\r\nint tick_device_uses_broadcast(struct clock_event_device *dev, int cpu)\r\n{\r\nstruct clock_event_device *bc = tick_broadcast_device.evtdev;\r\nunsigned long flags;\r\nint ret;\r\nraw_spin_lock_irqsave(&tick_broadcast_lock, flags);\r\nif (!tick_device_is_functional(dev)) {\r\ndev->event_handler = tick_handle_periodic;\r\ntick_device_setup_broadcast_func(dev);\r\ncpumask_set_cpu(cpu, tick_broadcast_mask);\r\nif (tick_broadcast_device.mode == TICKDEV_MODE_PERIODIC)\r\ntick_broadcast_start_periodic(bc);\r\nelse\r\ntick_broadcast_setup_oneshot(bc);\r\nret = 1;\r\n} else {\r\nif (!(dev->features & CLOCK_EVT_FEAT_C3STOP))\r\ncpumask_clear_cpu(cpu, tick_broadcast_mask);\r\nelse\r\ntick_device_setup_broadcast_func(dev);\r\nif (!cpumask_test_cpu(cpu, tick_broadcast_on))\r\ncpumask_clear_cpu(cpu, tick_broadcast_mask);\r\nswitch (tick_broadcast_device.mode) {\r\ncase TICKDEV_MODE_ONESHOT:\r\ntick_broadcast_clear_oneshot(cpu);\r\nret = 0;\r\nbreak;\r\ncase TICKDEV_MODE_PERIODIC:\r\nif (cpumask_empty(tick_broadcast_mask) && bc)\r\nclockevents_shutdown(bc);\r\nret = cpumask_test_cpu(cpu, tick_broadcast_mask);\r\nbreak;\r\ndefault:\r\nret = 0;\r\nbreak;\r\n}\r\n}\r\nraw_spin_unlock_irqrestore(&tick_broadcast_lock, flags);\r\nreturn ret;\r\n}\r\nint tick_receive_broadcast(void)\r\n{\r\nstruct tick_device *td = this_cpu_ptr(&tick_cpu_device);\r\nstruct clock_event_device *evt = td->evtdev;\r\nif (!evt)\r\nreturn -ENODEV;\r\nif (!evt->event_handler)\r\nreturn -EINVAL;\r\nevt->event_handler(evt);\r\nreturn 0;\r\n}\r\nstatic void tick_do_broadcast(struct cpumask *mask)\r\n{\r\nint cpu = smp_processor_id();\r\nstruct tick_device *td;\r\nif (cpumask_test_cpu(cpu, mask)) {\r\ncpumask_clear_cpu(cpu, mask);\r\ntd = &per_cpu(tick_cpu_device, cpu);\r\ntd->evtdev->event_handler(td->evtdev);\r\n}\r\nif (!cpumask_empty(mask)) {\r\ntd = &per_cpu(tick_cpu_device, cpumask_first(mask));\r\ntd->evtdev->broadcast(mask);\r\n}\r\n}\r\nstatic void tick_do_periodic_broadcast(void)\r\n{\r\ncpumask_and(tmpmask, cpu_online_mask, tick_broadcast_mask);\r\ntick_do_broadcast(tmpmask);\r\n}\r\nstatic void tick_handle_periodic_broadcast(struct clock_event_device *dev)\r\n{\r\nktime_t next;\r\nraw_spin_lock(&tick_broadcast_lock);\r\ntick_do_periodic_broadcast();\r\nif (dev->mode == CLOCK_EVT_MODE_PERIODIC)\r\ngoto unlock;\r\nfor (next = dev->next_event; ;) {\r\nnext = ktime_add(next, tick_period);\r\nif (!clockevents_program_event(dev, next, false))\r\ngoto unlock;\r\ntick_do_periodic_broadcast();\r\n}\r\nunlock:\r\nraw_spin_unlock(&tick_broadcast_lock);\r\n}\r\nstatic void tick_do_broadcast_on_off(unsigned long *reason)\r\n{\r\nstruct clock_event_device *bc, *dev;\r\nstruct tick_device *td;\r\nunsigned long flags;\r\nint cpu, bc_stopped;\r\nraw_spin_lock_irqsave(&tick_broadcast_lock, flags);\r\ncpu = smp_processor_id();\r\ntd = &per_cpu(tick_cpu_device, cpu);\r\ndev = td->evtdev;\r\nbc = tick_broadcast_device.evtdev;\r\nif (!dev || !(dev->features & CLOCK_EVT_FEAT_C3STOP))\r\ngoto out;\r\nif (!tick_device_is_functional(dev))\r\ngoto out;\r\nbc_stopped = cpumask_empty(tick_broadcast_mask);\r\nswitch (*reason) {\r\ncase CLOCK_EVT_NOTIFY_BROADCAST_ON:\r\ncase CLOCK_EVT_NOTIFY_BROADCAST_FORCE:\r\ncpumask_set_cpu(cpu, tick_broadcast_on);\r\nif (!cpumask_test_and_set_cpu(cpu, tick_broadcast_mask)) {\r\nif (tick_broadcast_device.mode ==\r\nTICKDEV_MODE_PERIODIC)\r\nclockevents_shutdown(dev);\r\n}\r\nif (*reason == CLOCK_EVT_NOTIFY_BROADCAST_FORCE)\r\ntick_broadcast_force = 1;\r\nbreak;\r\ncase CLOCK_EVT_NOTIFY_BROADCAST_OFF:\r\nif (tick_broadcast_force)\r\nbreak;\r\ncpumask_clear_cpu(cpu, tick_broadcast_on);\r\nif (!tick_device_is_functional(dev))\r\nbreak;\r\nif (cpumask_test_and_clear_cpu(cpu, tick_broadcast_mask)) {\r\nif (tick_broadcast_device.mode ==\r\nTICKDEV_MODE_PERIODIC)\r\ntick_setup_periodic(dev, 0);\r\n}\r\nbreak;\r\n}\r\nif (cpumask_empty(tick_broadcast_mask)) {\r\nif (!bc_stopped)\r\nclockevents_shutdown(bc);\r\n} else if (bc_stopped) {\r\nif (tick_broadcast_device.mode == TICKDEV_MODE_PERIODIC)\r\ntick_broadcast_start_periodic(bc);\r\nelse\r\ntick_broadcast_setup_oneshot(bc);\r\n}\r\nout:\r\nraw_spin_unlock_irqrestore(&tick_broadcast_lock, flags);\r\n}\r\nvoid tick_broadcast_on_off(unsigned long reason, int *oncpu)\r\n{\r\nif (!cpumask_test_cpu(*oncpu, cpu_online_mask))\r\nprintk(KERN_ERR "tick-broadcast: ignoring broadcast for "\r\n"offline CPU #%d\n", *oncpu);\r\nelse\r\ntick_do_broadcast_on_off(&reason);\r\n}\r\nvoid tick_set_periodic_handler(struct clock_event_device *dev, int broadcast)\r\n{\r\nif (!broadcast)\r\ndev->event_handler = tick_handle_periodic;\r\nelse\r\ndev->event_handler = tick_handle_periodic_broadcast;\r\n}\r\nvoid tick_shutdown_broadcast(unsigned int *cpup)\r\n{\r\nstruct clock_event_device *bc;\r\nunsigned long flags;\r\nunsigned int cpu = *cpup;\r\nraw_spin_lock_irqsave(&tick_broadcast_lock, flags);\r\nbc = tick_broadcast_device.evtdev;\r\ncpumask_clear_cpu(cpu, tick_broadcast_mask);\r\ncpumask_clear_cpu(cpu, tick_broadcast_on);\r\nif (tick_broadcast_device.mode == TICKDEV_MODE_PERIODIC) {\r\nif (bc && cpumask_empty(tick_broadcast_mask))\r\nclockevents_shutdown(bc);\r\n}\r\nraw_spin_unlock_irqrestore(&tick_broadcast_lock, flags);\r\n}\r\nvoid tick_suspend_broadcast(void)\r\n{\r\nstruct clock_event_device *bc;\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&tick_broadcast_lock, flags);\r\nbc = tick_broadcast_device.evtdev;\r\nif (bc)\r\nclockevents_shutdown(bc);\r\nraw_spin_unlock_irqrestore(&tick_broadcast_lock, flags);\r\n}\r\nint tick_resume_broadcast(void)\r\n{\r\nstruct clock_event_device *bc;\r\nunsigned long flags;\r\nint broadcast = 0;\r\nraw_spin_lock_irqsave(&tick_broadcast_lock, flags);\r\nbc = tick_broadcast_device.evtdev;\r\nif (bc) {\r\nclockevents_set_mode(bc, CLOCK_EVT_MODE_RESUME);\r\nswitch (tick_broadcast_device.mode) {\r\ncase TICKDEV_MODE_PERIODIC:\r\nif (!cpumask_empty(tick_broadcast_mask))\r\ntick_broadcast_start_periodic(bc);\r\nbroadcast = cpumask_test_cpu(smp_processor_id(),\r\ntick_broadcast_mask);\r\nbreak;\r\ncase TICKDEV_MODE_ONESHOT:\r\nif (!cpumask_empty(tick_broadcast_mask))\r\nbroadcast = tick_resume_broadcast_oneshot(bc);\r\nbreak;\r\n}\r\n}\r\nraw_spin_unlock_irqrestore(&tick_broadcast_lock, flags);\r\nreturn broadcast;\r\n}\r\nstruct cpumask *tick_get_broadcast_oneshot_mask(void)\r\n{\r\nreturn tick_broadcast_oneshot_mask;\r\n}\r\nint tick_check_broadcast_expired(void)\r\n{\r\nreturn cpumask_test_cpu(smp_processor_id(), tick_broadcast_force_mask);\r\n}\r\nstatic void tick_broadcast_set_affinity(struct clock_event_device *bc,\r\nconst struct cpumask *cpumask)\r\n{\r\nif (!(bc->features & CLOCK_EVT_FEAT_DYNIRQ))\r\nreturn;\r\nif (cpumask_equal(bc->cpumask, cpumask))\r\nreturn;\r\nbc->cpumask = cpumask;\r\nirq_set_affinity(bc->irq, bc->cpumask);\r\n}\r\nstatic int tick_broadcast_set_event(struct clock_event_device *bc, int cpu,\r\nktime_t expires, int force)\r\n{\r\nint ret;\r\nif (bc->mode != CLOCK_EVT_MODE_ONESHOT)\r\nclockevents_set_mode(bc, CLOCK_EVT_MODE_ONESHOT);\r\nret = clockevents_program_event(bc, expires, force);\r\nif (!ret)\r\ntick_broadcast_set_affinity(bc, cpumask_of(cpu));\r\nreturn ret;\r\n}\r\nint tick_resume_broadcast_oneshot(struct clock_event_device *bc)\r\n{\r\nclockevents_set_mode(bc, CLOCK_EVT_MODE_ONESHOT);\r\nreturn 0;\r\n}\r\nvoid tick_check_oneshot_broadcast_this_cpu(void)\r\n{\r\nif (cpumask_test_cpu(smp_processor_id(), tick_broadcast_oneshot_mask)) {\r\nstruct tick_device *td = &__get_cpu_var(tick_cpu_device);\r\nif (td->mode == TICKDEV_MODE_ONESHOT) {\r\nclockevents_set_mode(td->evtdev,\r\nCLOCK_EVT_MODE_ONESHOT);\r\n}\r\n}\r\n}\r\nstatic void tick_handle_oneshot_broadcast(struct clock_event_device *dev)\r\n{\r\nstruct tick_device *td;\r\nktime_t now, next_event;\r\nint cpu, next_cpu = 0;\r\nraw_spin_lock(&tick_broadcast_lock);\r\nagain:\r\ndev->next_event.tv64 = KTIME_MAX;\r\nnext_event.tv64 = KTIME_MAX;\r\ncpumask_clear(tmpmask);\r\nnow = ktime_get();\r\nfor_each_cpu(cpu, tick_broadcast_oneshot_mask) {\r\ntd = &per_cpu(tick_cpu_device, cpu);\r\nif (td->evtdev->next_event.tv64 <= now.tv64) {\r\ncpumask_set_cpu(cpu, tmpmask);\r\ncpumask_set_cpu(cpu, tick_broadcast_pending_mask);\r\n} else if (td->evtdev->next_event.tv64 < next_event.tv64) {\r\nnext_event.tv64 = td->evtdev->next_event.tv64;\r\nnext_cpu = cpu;\r\n}\r\n}\r\ncpumask_clear_cpu(smp_processor_id(), tick_broadcast_pending_mask);\r\ncpumask_or(tmpmask, tmpmask, tick_broadcast_force_mask);\r\ncpumask_clear(tick_broadcast_force_mask);\r\nif (WARN_ON_ONCE(!cpumask_subset(tmpmask, cpu_online_mask)))\r\ncpumask_and(tmpmask, tmpmask, cpu_online_mask);\r\ntick_do_broadcast(tmpmask);\r\nif (next_event.tv64 != KTIME_MAX) {\r\nif (tick_broadcast_set_event(dev, next_cpu, next_event, 0))\r\ngoto again;\r\n}\r\nraw_spin_unlock(&tick_broadcast_lock);\r\n}\r\nstatic int broadcast_needs_cpu(struct clock_event_device *bc, int cpu)\r\n{\r\nif (!(bc->features & CLOCK_EVT_FEAT_HRTIMER))\r\nreturn 0;\r\nif (bc->next_event.tv64 == KTIME_MAX)\r\nreturn 0;\r\nreturn bc->bound_on == cpu ? -EBUSY : 0;\r\n}\r\nstatic void broadcast_shutdown_local(struct clock_event_device *bc,\r\nstruct clock_event_device *dev)\r\n{\r\nif (bc->features & CLOCK_EVT_FEAT_HRTIMER) {\r\nif (broadcast_needs_cpu(bc, smp_processor_id()))\r\nreturn;\r\nif (dev->next_event.tv64 < bc->next_event.tv64)\r\nreturn;\r\n}\r\nclockevents_set_mode(dev, CLOCK_EVT_MODE_SHUTDOWN);\r\n}\r\nstatic void broadcast_move_bc(int deadcpu)\r\n{\r\nstruct clock_event_device *bc = tick_broadcast_device.evtdev;\r\nif (!bc || !broadcast_needs_cpu(bc, deadcpu))\r\nreturn;\r\nclockevents_program_event(bc, bc->next_event, 1);\r\n}\r\nint tick_broadcast_oneshot_control(unsigned long reason)\r\n{\r\nstruct clock_event_device *bc, *dev;\r\nstruct tick_device *td;\r\nunsigned long flags;\r\nktime_t now;\r\nint cpu, ret = 0;\r\nif (tick_broadcast_device.mode == TICKDEV_MODE_PERIODIC)\r\nreturn 0;\r\ncpu = smp_processor_id();\r\ntd = &per_cpu(tick_cpu_device, cpu);\r\ndev = td->evtdev;\r\nif (!(dev->features & CLOCK_EVT_FEAT_C3STOP))\r\nreturn 0;\r\nbc = tick_broadcast_device.evtdev;\r\nraw_spin_lock_irqsave(&tick_broadcast_lock, flags);\r\nif (reason == CLOCK_EVT_NOTIFY_BROADCAST_ENTER) {\r\nif (!cpumask_test_and_set_cpu(cpu, tick_broadcast_oneshot_mask)) {\r\nWARN_ON_ONCE(cpumask_test_cpu(cpu, tick_broadcast_pending_mask));\r\nbroadcast_shutdown_local(bc, dev);\r\nif (!cpumask_test_cpu(cpu, tick_broadcast_force_mask) &&\r\ndev->next_event.tv64 < bc->next_event.tv64)\r\ntick_broadcast_set_event(bc, cpu, dev->next_event, 1);\r\n}\r\nret = broadcast_needs_cpu(bc, cpu);\r\nif (ret)\r\ncpumask_clear_cpu(cpu, tick_broadcast_oneshot_mask);\r\n} else {\r\nif (cpumask_test_and_clear_cpu(cpu, tick_broadcast_oneshot_mask)) {\r\nclockevents_set_mode(dev, CLOCK_EVT_MODE_ONESHOT);\r\nif (cpumask_test_and_clear_cpu(cpu,\r\ntick_broadcast_pending_mask))\r\ngoto out;\r\nif (dev->next_event.tv64 == KTIME_MAX)\r\ngoto out;\r\nnow = ktime_get();\r\nif (dev->next_event.tv64 <= now.tv64) {\r\ncpumask_set_cpu(cpu, tick_broadcast_force_mask);\r\ngoto out;\r\n}\r\ntick_program_event(dev->next_event, 1);\r\n}\r\n}\r\nout:\r\nraw_spin_unlock_irqrestore(&tick_broadcast_lock, flags);\r\nreturn ret;\r\n}\r\nstatic void tick_broadcast_clear_oneshot(int cpu)\r\n{\r\ncpumask_clear_cpu(cpu, tick_broadcast_oneshot_mask);\r\ncpumask_clear_cpu(cpu, tick_broadcast_pending_mask);\r\n}\r\nstatic void tick_broadcast_init_next_event(struct cpumask *mask,\r\nktime_t expires)\r\n{\r\nstruct tick_device *td;\r\nint cpu;\r\nfor_each_cpu(cpu, mask) {\r\ntd = &per_cpu(tick_cpu_device, cpu);\r\nif (td->evtdev)\r\ntd->evtdev->next_event = expires;\r\n}\r\n}\r\nvoid tick_broadcast_setup_oneshot(struct clock_event_device *bc)\r\n{\r\nint cpu = smp_processor_id();\r\nif (bc->event_handler != tick_handle_oneshot_broadcast) {\r\nint was_periodic = bc->mode == CLOCK_EVT_MODE_PERIODIC;\r\nbc->event_handler = tick_handle_oneshot_broadcast;\r\ncpumask_copy(tmpmask, tick_broadcast_mask);\r\ncpumask_clear_cpu(cpu, tmpmask);\r\ncpumask_or(tick_broadcast_oneshot_mask,\r\ntick_broadcast_oneshot_mask, tmpmask);\r\nif (was_periodic && !cpumask_empty(tmpmask)) {\r\nclockevents_set_mode(bc, CLOCK_EVT_MODE_ONESHOT);\r\ntick_broadcast_init_next_event(tmpmask,\r\ntick_next_period);\r\ntick_broadcast_set_event(bc, cpu, tick_next_period, 1);\r\n} else\r\nbc->next_event.tv64 = KTIME_MAX;\r\n} else {\r\ntick_broadcast_clear_oneshot(cpu);\r\n}\r\n}\r\nvoid tick_broadcast_switch_to_oneshot(void)\r\n{\r\nstruct clock_event_device *bc;\r\nunsigned long flags;\r\nraw_spin_lock_irqsave(&tick_broadcast_lock, flags);\r\ntick_broadcast_device.mode = TICKDEV_MODE_ONESHOT;\r\nbc = tick_broadcast_device.evtdev;\r\nif (bc)\r\ntick_broadcast_setup_oneshot(bc);\r\nraw_spin_unlock_irqrestore(&tick_broadcast_lock, flags);\r\n}\r\nvoid tick_shutdown_broadcast_oneshot(unsigned int *cpup)\r\n{\r\nunsigned long flags;\r\nunsigned int cpu = *cpup;\r\nraw_spin_lock_irqsave(&tick_broadcast_lock, flags);\r\ncpumask_clear_cpu(cpu, tick_broadcast_oneshot_mask);\r\ncpumask_clear_cpu(cpu, tick_broadcast_pending_mask);\r\ncpumask_clear_cpu(cpu, tick_broadcast_force_mask);\r\nbroadcast_move_bc(cpu);\r\nraw_spin_unlock_irqrestore(&tick_broadcast_lock, flags);\r\n}\r\nint tick_broadcast_oneshot_active(void)\r\n{\r\nreturn tick_broadcast_device.mode == TICKDEV_MODE_ONESHOT;\r\n}\r\nbool tick_broadcast_oneshot_available(void)\r\n{\r\nstruct clock_event_device *bc = tick_broadcast_device.evtdev;\r\nreturn bc ? bc->features & CLOCK_EVT_FEAT_ONESHOT : false;\r\n}\r\nvoid __init tick_broadcast_init(void)\r\n{\r\nzalloc_cpumask_var(&tick_broadcast_mask, GFP_NOWAIT);\r\nzalloc_cpumask_var(&tick_broadcast_on, GFP_NOWAIT);\r\nzalloc_cpumask_var(&tmpmask, GFP_NOWAIT);\r\n#ifdef CONFIG_TICK_ONESHOT\r\nzalloc_cpumask_var(&tick_broadcast_oneshot_mask, GFP_NOWAIT);\r\nzalloc_cpumask_var(&tick_broadcast_pending_mask, GFP_NOWAIT);\r\nzalloc_cpumask_var(&tick_broadcast_force_mask, GFP_NOWAIT);\r\n#endif\r\n}
