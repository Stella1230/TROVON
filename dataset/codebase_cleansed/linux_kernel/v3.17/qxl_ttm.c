static struct qxl_device *qxl_get_qdev(struct ttm_bo_device *bdev)\r\n{\r\nstruct qxl_mman *mman;\r\nstruct qxl_device *qdev;\r\nmman = container_of(bdev, struct qxl_mman, bdev);\r\nqdev = container_of(mman, struct qxl_device, mman);\r\nreturn qdev;\r\n}\r\nstatic int qxl_ttm_mem_global_init(struct drm_global_reference *ref)\r\n{\r\nreturn ttm_mem_global_init(ref->object);\r\n}\r\nstatic void qxl_ttm_mem_global_release(struct drm_global_reference *ref)\r\n{\r\nttm_mem_global_release(ref->object);\r\n}\r\nstatic int qxl_ttm_global_init(struct qxl_device *qdev)\r\n{\r\nstruct drm_global_reference *global_ref;\r\nint r;\r\nqdev->mman.mem_global_referenced = false;\r\nglobal_ref = &qdev->mman.mem_global_ref;\r\nglobal_ref->global_type = DRM_GLOBAL_TTM_MEM;\r\nglobal_ref->size = sizeof(struct ttm_mem_global);\r\nglobal_ref->init = &qxl_ttm_mem_global_init;\r\nglobal_ref->release = &qxl_ttm_mem_global_release;\r\nr = drm_global_item_ref(global_ref);\r\nif (r != 0) {\r\nDRM_ERROR("Failed setting up TTM memory accounting "\r\n"subsystem.\n");\r\nreturn r;\r\n}\r\nqdev->mman.bo_global_ref.mem_glob =\r\nqdev->mman.mem_global_ref.object;\r\nglobal_ref = &qdev->mman.bo_global_ref.ref;\r\nglobal_ref->global_type = DRM_GLOBAL_TTM_BO;\r\nglobal_ref->size = sizeof(struct ttm_bo_global);\r\nglobal_ref->init = &ttm_bo_global_init;\r\nglobal_ref->release = &ttm_bo_global_release;\r\nr = drm_global_item_ref(global_ref);\r\nif (r != 0) {\r\nDRM_ERROR("Failed setting up TTM BO subsystem.\n");\r\ndrm_global_item_unref(&qdev->mman.mem_global_ref);\r\nreturn r;\r\n}\r\nqdev->mman.mem_global_referenced = true;\r\nreturn 0;\r\n}\r\nstatic void qxl_ttm_global_fini(struct qxl_device *qdev)\r\n{\r\nif (qdev->mman.mem_global_referenced) {\r\ndrm_global_item_unref(&qdev->mman.bo_global_ref.ref);\r\ndrm_global_item_unref(&qdev->mman.mem_global_ref);\r\nqdev->mman.mem_global_referenced = false;\r\n}\r\n}\r\nstatic int qxl_ttm_fault(struct vm_area_struct *vma, struct vm_fault *vmf)\r\n{\r\nstruct ttm_buffer_object *bo;\r\nint r;\r\nbo = (struct ttm_buffer_object *)vma->vm_private_data;\r\nif (bo == NULL)\r\nreturn VM_FAULT_NOPAGE;\r\nr = ttm_vm_ops->fault(vma, vmf);\r\nreturn r;\r\n}\r\nint qxl_mmap(struct file *filp, struct vm_area_struct *vma)\r\n{\r\nstruct drm_file *file_priv;\r\nstruct qxl_device *qdev;\r\nint r;\r\nif (unlikely(vma->vm_pgoff < DRM_FILE_PAGE_OFFSET)) {\r\npr_info("%s: vma->vm_pgoff (%ld) < DRM_FILE_PAGE_OFFSET\n",\r\n__func__, vma->vm_pgoff);\r\nreturn drm_mmap(filp, vma);\r\n}\r\nfile_priv = filp->private_data;\r\nqdev = file_priv->minor->dev->dev_private;\r\nif (qdev == NULL) {\r\nDRM_ERROR(\r\n"filp->private_data->minor->dev->dev_private == NULL\n");\r\nreturn -EINVAL;\r\n}\r\nQXL_INFO(qdev, "%s: filp->private_data = 0x%p, vma->vm_pgoff = %lx\n",\r\n__func__, filp->private_data, vma->vm_pgoff);\r\nr = ttm_bo_mmap(filp, vma, &qdev->mman.bdev);\r\nif (unlikely(r != 0))\r\nreturn r;\r\nif (unlikely(ttm_vm_ops == NULL)) {\r\nttm_vm_ops = vma->vm_ops;\r\nqxl_ttm_vm_ops = *ttm_vm_ops;\r\nqxl_ttm_vm_ops.fault = &qxl_ttm_fault;\r\n}\r\nvma->vm_ops = &qxl_ttm_vm_ops;\r\nreturn 0;\r\n}\r\nstatic int qxl_invalidate_caches(struct ttm_bo_device *bdev, uint32_t flags)\r\n{\r\nreturn 0;\r\n}\r\nstatic int qxl_init_mem_type(struct ttm_bo_device *bdev, uint32_t type,\r\nstruct ttm_mem_type_manager *man)\r\n{\r\nswitch (type) {\r\ncase TTM_PL_SYSTEM:\r\nman->flags = TTM_MEMTYPE_FLAG_MAPPABLE;\r\nman->available_caching = TTM_PL_MASK_CACHING;\r\nman->default_caching = TTM_PL_FLAG_CACHED;\r\nbreak;\r\ncase TTM_PL_VRAM:\r\ncase TTM_PL_PRIV0:\r\nman->func = &ttm_bo_manager_func;\r\nman->gpu_offset = 0;\r\nman->flags = TTM_MEMTYPE_FLAG_FIXED |\r\nTTM_MEMTYPE_FLAG_MAPPABLE;\r\nman->available_caching = TTM_PL_MASK_CACHING;\r\nman->default_caching = TTM_PL_FLAG_CACHED;\r\nbreak;\r\ndefault:\r\nDRM_ERROR("Unsupported memory type %u\n", (unsigned)type);\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic void qxl_evict_flags(struct ttm_buffer_object *bo,\r\nstruct ttm_placement *placement)\r\n{\r\nstruct qxl_bo *qbo;\r\nstatic u32 placements = TTM_PL_MASK_CACHING | TTM_PL_FLAG_SYSTEM;\r\nif (!qxl_ttm_bo_is_qxl_bo(bo)) {\r\nplacement->fpfn = 0;\r\nplacement->lpfn = 0;\r\nplacement->placement = &placements;\r\nplacement->busy_placement = &placements;\r\nplacement->num_placement = 1;\r\nplacement->num_busy_placement = 1;\r\nreturn;\r\n}\r\nqbo = container_of(bo, struct qxl_bo, tbo);\r\nqxl_ttm_placement_from_domain(qbo, QXL_GEM_DOMAIN_CPU, false);\r\n*placement = qbo->placement;\r\n}\r\nstatic int qxl_verify_access(struct ttm_buffer_object *bo, struct file *filp)\r\n{\r\nstruct qxl_bo *qbo = to_qxl_bo(bo);\r\nreturn drm_vma_node_verify_access(&qbo->gem_base.vma_node, filp);\r\n}\r\nstatic int qxl_ttm_io_mem_reserve(struct ttm_bo_device *bdev,\r\nstruct ttm_mem_reg *mem)\r\n{\r\nstruct ttm_mem_type_manager *man = &bdev->man[mem->mem_type];\r\nstruct qxl_device *qdev = qxl_get_qdev(bdev);\r\nmem->bus.addr = NULL;\r\nmem->bus.offset = 0;\r\nmem->bus.size = mem->num_pages << PAGE_SHIFT;\r\nmem->bus.base = 0;\r\nmem->bus.is_iomem = false;\r\nif (!(man->flags & TTM_MEMTYPE_FLAG_MAPPABLE))\r\nreturn -EINVAL;\r\nswitch (mem->mem_type) {\r\ncase TTM_PL_SYSTEM:\r\nreturn 0;\r\ncase TTM_PL_VRAM:\r\nmem->bus.is_iomem = true;\r\nmem->bus.base = qdev->vram_base;\r\nmem->bus.offset = mem->start << PAGE_SHIFT;\r\nbreak;\r\ncase TTM_PL_PRIV0:\r\nmem->bus.is_iomem = true;\r\nmem->bus.base = qdev->surfaceram_base;\r\nmem->bus.offset = mem->start << PAGE_SHIFT;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nstatic void qxl_ttm_io_mem_free(struct ttm_bo_device *bdev,\r\nstruct ttm_mem_reg *mem)\r\n{\r\n}\r\nstatic int qxl_ttm_backend_bind(struct ttm_tt *ttm,\r\nstruct ttm_mem_reg *bo_mem)\r\n{\r\nstruct qxl_ttm_tt *gtt = (void *)ttm;\r\ngtt->offset = (unsigned long)(bo_mem->start << PAGE_SHIFT);\r\nif (!ttm->num_pages) {\r\nWARN(1, "nothing to bind %lu pages for mreg %p back %p!\n",\r\nttm->num_pages, bo_mem, ttm);\r\n}\r\nreturn -1;\r\n}\r\nstatic int qxl_ttm_backend_unbind(struct ttm_tt *ttm)\r\n{\r\nreturn -1;\r\n}\r\nstatic void qxl_ttm_backend_destroy(struct ttm_tt *ttm)\r\n{\r\nstruct qxl_ttm_tt *gtt = (void *)ttm;\r\nttm_dma_tt_fini(&gtt->ttm);\r\nkfree(gtt);\r\n}\r\nstatic int qxl_ttm_tt_populate(struct ttm_tt *ttm)\r\n{\r\nint r;\r\nif (ttm->state != tt_unpopulated)\r\nreturn 0;\r\nr = ttm_pool_populate(ttm);\r\nif (r)\r\nreturn r;\r\nreturn 0;\r\n}\r\nstatic void qxl_ttm_tt_unpopulate(struct ttm_tt *ttm)\r\n{\r\nttm_pool_unpopulate(ttm);\r\n}\r\nstatic struct ttm_tt *qxl_ttm_tt_create(struct ttm_bo_device *bdev,\r\nunsigned long size, uint32_t page_flags,\r\nstruct page *dummy_read_page)\r\n{\r\nstruct qxl_device *qdev;\r\nstruct qxl_ttm_tt *gtt;\r\nqdev = qxl_get_qdev(bdev);\r\ngtt = kzalloc(sizeof(struct qxl_ttm_tt), GFP_KERNEL);\r\nif (gtt == NULL)\r\nreturn NULL;\r\ngtt->ttm.ttm.func = &qxl_backend_func;\r\ngtt->qdev = qdev;\r\nif (ttm_dma_tt_init(&gtt->ttm, bdev, size, page_flags,\r\ndummy_read_page)) {\r\nkfree(gtt);\r\nreturn NULL;\r\n}\r\nreturn &gtt->ttm.ttm;\r\n}\r\nstatic void qxl_move_null(struct ttm_buffer_object *bo,\r\nstruct ttm_mem_reg *new_mem)\r\n{\r\nstruct ttm_mem_reg *old_mem = &bo->mem;\r\nBUG_ON(old_mem->mm_node != NULL);\r\n*old_mem = *new_mem;\r\nnew_mem->mm_node = NULL;\r\n}\r\nstatic int qxl_bo_move(struct ttm_buffer_object *bo,\r\nbool evict, bool interruptible,\r\nbool no_wait_gpu,\r\nstruct ttm_mem_reg *new_mem)\r\n{\r\nstruct ttm_mem_reg *old_mem = &bo->mem;\r\nif (old_mem->mem_type == TTM_PL_SYSTEM && bo->ttm == NULL) {\r\nqxl_move_null(bo, new_mem);\r\nreturn 0;\r\n}\r\nreturn ttm_bo_move_memcpy(bo, evict, no_wait_gpu, new_mem);\r\n}\r\nstatic int qxl_sync_obj_wait(void *sync_obj,\r\nbool lazy, bool interruptible)\r\n{\r\nstruct qxl_fence *qfence = (struct qxl_fence *)sync_obj;\r\nint count = 0, sc = 0;\r\nstruct qxl_bo *bo = container_of(qfence, struct qxl_bo, fence);\r\nif (qfence->num_active_releases == 0)\r\nreturn 0;\r\nretry:\r\nif (sc == 0) {\r\nif (bo->type == QXL_GEM_DOMAIN_SURFACE)\r\nqxl_update_surface(qfence->qdev, bo);\r\n} else if (sc >= 1) {\r\nqxl_io_notify_oom(qfence->qdev);\r\n}\r\nsc++;\r\nfor (count = 0; count < 10; count++) {\r\nbool ret;\r\nret = qxl_queue_garbage_collect(qfence->qdev, true);\r\nif (ret == false)\r\nbreak;\r\nif (qfence->num_active_releases == 0)\r\nreturn 0;\r\n}\r\nif (qfence->num_active_releases) {\r\nbool have_drawable_releases = false;\r\nvoid **slot;\r\nstruct radix_tree_iter iter;\r\nint release_id;\r\nradix_tree_for_each_slot(slot, &qfence->tree, &iter, 0) {\r\nstruct qxl_release *release;\r\nrelease_id = iter.index;\r\nrelease = qxl_release_from_id_locked(qfence->qdev, release_id);\r\nif (release == NULL)\r\ncontinue;\r\nif (release->type == QXL_RELEASE_DRAWABLE)\r\nhave_drawable_releases = true;\r\n}\r\nqxl_queue_garbage_collect(qfence->qdev, true);\r\nif (have_drawable_releases || sc < 4) {\r\nif (sc > 2)\r\nusleep_range(500, 1000);\r\nif (have_drawable_releases && sc > 300) {\r\nWARN(1, "sync obj %d still has outstanding releases %d %d %d %ld %d\n", sc, bo->surface_id, bo->is_primary, bo->pin_count, (unsigned long)bo->gem_base.size, qfence->num_active_releases);\r\nreturn -EBUSY;\r\n}\r\ngoto retry;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int qxl_sync_obj_flush(void *sync_obj)\r\n{\r\nreturn 0;\r\n}\r\nstatic void qxl_sync_obj_unref(void **sync_obj)\r\n{\r\n*sync_obj = NULL;\r\n}\r\nstatic void *qxl_sync_obj_ref(void *sync_obj)\r\n{\r\nreturn sync_obj;\r\n}\r\nstatic bool qxl_sync_obj_signaled(void *sync_obj)\r\n{\r\nstruct qxl_fence *qfence = (struct qxl_fence *)sync_obj;\r\nreturn (qfence->num_active_releases == 0);\r\n}\r\nstatic void qxl_bo_move_notify(struct ttm_buffer_object *bo,\r\nstruct ttm_mem_reg *new_mem)\r\n{\r\nstruct qxl_bo *qbo;\r\nstruct qxl_device *qdev;\r\nif (!qxl_ttm_bo_is_qxl_bo(bo))\r\nreturn;\r\nqbo = container_of(bo, struct qxl_bo, tbo);\r\nqdev = qbo->gem_base.dev->dev_private;\r\nif (bo->mem.mem_type == TTM_PL_PRIV0 && qbo->surface_id)\r\nqxl_surface_evict(qdev, qbo, new_mem ? true : false);\r\n}\r\nint qxl_ttm_init(struct qxl_device *qdev)\r\n{\r\nint r;\r\nint num_io_pages;\r\nr = qxl_ttm_global_init(qdev);\r\nif (r)\r\nreturn r;\r\nr = ttm_bo_device_init(&qdev->mman.bdev,\r\nqdev->mman.bo_global_ref.ref.object,\r\n&qxl_bo_driver,\r\nqdev->ddev->anon_inode->i_mapping,\r\nDRM_FILE_PAGE_OFFSET, 0);\r\nif (r) {\r\nDRM_ERROR("failed initializing buffer object driver(%d).\n", r);\r\nreturn r;\r\n}\r\nnum_io_pages = qdev->rom->ram_header_offset / PAGE_SIZE;\r\nr = ttm_bo_init_mm(&qdev->mman.bdev, TTM_PL_VRAM,\r\nnum_io_pages);\r\nif (r) {\r\nDRM_ERROR("Failed initializing VRAM heap.\n");\r\nreturn r;\r\n}\r\nr = ttm_bo_init_mm(&qdev->mman.bdev, TTM_PL_PRIV0,\r\nqdev->surfaceram_size / PAGE_SIZE);\r\nif (r) {\r\nDRM_ERROR("Failed initializing Surfaces heap.\n");\r\nreturn r;\r\n}\r\nDRM_INFO("qxl: %uM of VRAM memory size\n",\r\n(unsigned)qdev->vram_size / (1024 * 1024));\r\nDRM_INFO("qxl: %luM of IO pages memory ready (VRAM domain)\n",\r\n((unsigned)num_io_pages * PAGE_SIZE) / (1024 * 1024));\r\nDRM_INFO("qxl: %uM of Surface memory size\n",\r\n(unsigned)qdev->surfaceram_size / (1024 * 1024));\r\nr = qxl_ttm_debugfs_init(qdev);\r\nif (r) {\r\nDRM_ERROR("Failed to init debugfs\n");\r\nreturn r;\r\n}\r\nreturn 0;\r\n}\r\nvoid qxl_ttm_fini(struct qxl_device *qdev)\r\n{\r\nttm_bo_clean_mm(&qdev->mman.bdev, TTM_PL_VRAM);\r\nttm_bo_clean_mm(&qdev->mman.bdev, TTM_PL_PRIV0);\r\nttm_bo_device_release(&qdev->mman.bdev);\r\nqxl_ttm_global_fini(qdev);\r\nDRM_INFO("qxl: ttm finalized\n");\r\n}\r\nstatic int qxl_mm_dump_table(struct seq_file *m, void *data)\r\n{\r\nstruct drm_info_node *node = (struct drm_info_node *)m->private;\r\nstruct drm_mm *mm = (struct drm_mm *)node->info_ent->data;\r\nstruct drm_device *dev = node->minor->dev;\r\nstruct qxl_device *rdev = dev->dev_private;\r\nint ret;\r\nstruct ttm_bo_global *glob = rdev->mman.bdev.glob;\r\nspin_lock(&glob->lru_lock);\r\nret = drm_mm_dump_table(m, mm);\r\nspin_unlock(&glob->lru_lock);\r\nreturn ret;\r\n}\r\nstatic int qxl_ttm_debugfs_init(struct qxl_device *qdev)\r\n{\r\n#if defined(CONFIG_DEBUG_FS)\r\nstatic struct drm_info_list qxl_mem_types_list[QXL_DEBUGFS_MEM_TYPES];\r\nstatic char qxl_mem_types_names[QXL_DEBUGFS_MEM_TYPES][32];\r\nunsigned i;\r\nfor (i = 0; i < QXL_DEBUGFS_MEM_TYPES; i++) {\r\nif (i == 0)\r\nsprintf(qxl_mem_types_names[i], "qxl_mem_mm");\r\nelse\r\nsprintf(qxl_mem_types_names[i], "qxl_surf_mm");\r\nqxl_mem_types_list[i].name = qxl_mem_types_names[i];\r\nqxl_mem_types_list[i].show = &qxl_mm_dump_table;\r\nqxl_mem_types_list[i].driver_features = 0;\r\nif (i == 0)\r\nqxl_mem_types_list[i].data = qdev->mman.bdev.man[TTM_PL_VRAM].priv;\r\nelse\r\nqxl_mem_types_list[i].data = qdev->mman.bdev.man[TTM_PL_PRIV0].priv;\r\n}\r\nreturn qxl_debugfs_add_files(qdev, qxl_mem_types_list, i);\r\n#else\r\nreturn 0;\r\n#endif\r\n}
