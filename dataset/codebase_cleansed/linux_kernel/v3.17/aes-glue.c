static int xts_set_key(struct crypto_tfm *tfm, const u8 *in_key,\r\nunsigned int key_len)\r\n{\r\nstruct crypto_aes_xts_ctx *ctx = crypto_tfm_ctx(tfm);\r\nint ret;\r\nret = crypto_aes_expand_key(&ctx->key1, in_key, key_len / 2);\r\nif (!ret)\r\nret = crypto_aes_expand_key(&ctx->key2, &in_key[key_len / 2],\r\nkey_len / 2);\r\nif (!ret)\r\nreturn 0;\r\ntfm->crt_flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\r\nreturn -EINVAL;\r\n}\r\nstatic int ecb_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct crypto_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nint err, first, rounds = 6 + ctx->key_length / 4;\r\nstruct blkcipher_walk walk;\r\nunsigned int blocks;\r\ndesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt(desc, &walk);\r\nkernel_neon_begin();\r\nfor (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {\r\naes_ecb_encrypt(walk.dst.virt.addr, walk.src.virt.addr,\r\n(u8 *)ctx->key_enc, rounds, blocks, first);\r\nerr = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);\r\n}\r\nkernel_neon_end();\r\nreturn err;\r\n}\r\nstatic int ecb_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct crypto_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nint err, first, rounds = 6 + ctx->key_length / 4;\r\nstruct blkcipher_walk walk;\r\nunsigned int blocks;\r\ndesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt(desc, &walk);\r\nkernel_neon_begin();\r\nfor (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {\r\naes_ecb_decrypt(walk.dst.virt.addr, walk.src.virt.addr,\r\n(u8 *)ctx->key_dec, rounds, blocks, first);\r\nerr = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);\r\n}\r\nkernel_neon_end();\r\nreturn err;\r\n}\r\nstatic int cbc_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct crypto_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nint err, first, rounds = 6 + ctx->key_length / 4;\r\nstruct blkcipher_walk walk;\r\nunsigned int blocks;\r\ndesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt(desc, &walk);\r\nkernel_neon_begin();\r\nfor (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {\r\naes_cbc_encrypt(walk.dst.virt.addr, walk.src.virt.addr,\r\n(u8 *)ctx->key_enc, rounds, blocks, walk.iv,\r\nfirst);\r\nerr = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);\r\n}\r\nkernel_neon_end();\r\nreturn err;\r\n}\r\nstatic int cbc_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct crypto_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nint err, first, rounds = 6 + ctx->key_length / 4;\r\nstruct blkcipher_walk walk;\r\nunsigned int blocks;\r\ndesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt(desc, &walk);\r\nkernel_neon_begin();\r\nfor (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {\r\naes_cbc_decrypt(walk.dst.virt.addr, walk.src.virt.addr,\r\n(u8 *)ctx->key_dec, rounds, blocks, walk.iv,\r\nfirst);\r\nerr = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);\r\n}\r\nkernel_neon_end();\r\nreturn err;\r\n}\r\nstatic int ctr_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct crypto_aes_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nint err, first, rounds = 6 + ctx->key_length / 4;\r\nstruct blkcipher_walk walk;\r\nint blocks;\r\ndesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt_block(desc, &walk, AES_BLOCK_SIZE);\r\nfirst = 1;\r\nkernel_neon_begin();\r\nwhile ((blocks = (walk.nbytes / AES_BLOCK_SIZE))) {\r\naes_ctr_encrypt(walk.dst.virt.addr, walk.src.virt.addr,\r\n(u8 *)ctx->key_enc, rounds, blocks, walk.iv,\r\nfirst);\r\nfirst = 0;\r\nnbytes -= blocks * AES_BLOCK_SIZE;\r\nif (nbytes && nbytes == walk.nbytes % AES_BLOCK_SIZE)\r\nbreak;\r\nerr = blkcipher_walk_done(desc, &walk,\r\nwalk.nbytes % AES_BLOCK_SIZE);\r\n}\r\nif (nbytes) {\r\nu8 *tdst = walk.dst.virt.addr + blocks * AES_BLOCK_SIZE;\r\nu8 *tsrc = walk.src.virt.addr + blocks * AES_BLOCK_SIZE;\r\nu8 __aligned(8) tail[AES_BLOCK_SIZE];\r\nblocks = (nbytes <= 8) ? -1 : 1;\r\naes_ctr_encrypt(tail, tsrc, (u8 *)ctx->key_enc, rounds,\r\nblocks, walk.iv, first);\r\nmemcpy(tdst, tail, nbytes);\r\nerr = blkcipher_walk_done(desc, &walk, 0);\r\n}\r\nkernel_neon_end();\r\nreturn err;\r\n}\r\nstatic int xts_encrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct crypto_aes_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nint err, first, rounds = 6 + ctx->key1.key_length / 4;\r\nstruct blkcipher_walk walk;\r\nunsigned int blocks;\r\ndesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt(desc, &walk);\r\nkernel_neon_begin();\r\nfor (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {\r\naes_xts_encrypt(walk.dst.virt.addr, walk.src.virt.addr,\r\n(u8 *)ctx->key1.key_enc, rounds, blocks,\r\n(u8 *)ctx->key2.key_enc, walk.iv, first);\r\nerr = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);\r\n}\r\nkernel_neon_end();\r\nreturn err;\r\n}\r\nstatic int xts_decrypt(struct blkcipher_desc *desc, struct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct crypto_aes_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nint err, first, rounds = 6 + ctx->key1.key_length / 4;\r\nstruct blkcipher_walk walk;\r\nunsigned int blocks;\r\ndesc->flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt(desc, &walk);\r\nkernel_neon_begin();\r\nfor (first = 1; (blocks = (walk.nbytes / AES_BLOCK_SIZE)); first = 0) {\r\naes_xts_decrypt(walk.dst.virt.addr, walk.src.virt.addr,\r\n(u8 *)ctx->key1.key_dec, rounds, blocks,\r\n(u8 *)ctx->key2.key_enc, walk.iv, first);\r\nerr = blkcipher_walk_done(desc, &walk, walk.nbytes % AES_BLOCK_SIZE);\r\n}\r\nkernel_neon_end();\r\nreturn err;\r\n}\r\nstatic int __init aes_init(void)\r\n{\r\nreturn crypto_register_algs(aes_algs, ARRAY_SIZE(aes_algs));\r\n}\r\nstatic void __exit aes_exit(void)\r\n{\r\ncrypto_unregister_algs(aes_algs, ARRAY_SIZE(aes_algs));\r\n}
