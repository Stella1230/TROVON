static int neigh_blackhole(struct neighbour *neigh, struct sk_buff *skb)\r\n{\r\nkfree_skb(skb);\r\nreturn -ENETDOWN;\r\n}\r\nstatic void neigh_cleanup_and_release(struct neighbour *neigh)\r\n{\r\nif (neigh->parms->neigh_cleanup)\r\nneigh->parms->neigh_cleanup(neigh);\r\n__neigh_notify(neigh, RTM_DELNEIGH, 0);\r\nneigh_release(neigh);\r\n}\r\nunsigned long neigh_rand_reach_time(unsigned long base)\r\n{\r\nreturn base ? (prandom_u32() % base) + (base >> 1) : 0;\r\n}\r\nstatic int neigh_forced_gc(struct neigh_table *tbl)\r\n{\r\nint shrunk = 0;\r\nint i;\r\nstruct neigh_hash_table *nht;\r\nNEIGH_CACHE_STAT_INC(tbl, forced_gc_runs);\r\nwrite_lock_bh(&tbl->lock);\r\nnht = rcu_dereference_protected(tbl->nht,\r\nlockdep_is_held(&tbl->lock));\r\nfor (i = 0; i < (1 << nht->hash_shift); i++) {\r\nstruct neighbour *n;\r\nstruct neighbour __rcu **np;\r\nnp = &nht->hash_buckets[i];\r\nwhile ((n = rcu_dereference_protected(*np,\r\nlockdep_is_held(&tbl->lock))) != NULL) {\r\nwrite_lock(&n->lock);\r\nif (atomic_read(&n->refcnt) == 1 &&\r\n!(n->nud_state & NUD_PERMANENT)) {\r\nrcu_assign_pointer(*np,\r\nrcu_dereference_protected(n->next,\r\nlockdep_is_held(&tbl->lock)));\r\nn->dead = 1;\r\nshrunk = 1;\r\nwrite_unlock(&n->lock);\r\nneigh_cleanup_and_release(n);\r\ncontinue;\r\n}\r\nwrite_unlock(&n->lock);\r\nnp = &n->next;\r\n}\r\n}\r\ntbl->last_flush = jiffies;\r\nwrite_unlock_bh(&tbl->lock);\r\nreturn shrunk;\r\n}\r\nstatic void neigh_add_timer(struct neighbour *n, unsigned long when)\r\n{\r\nneigh_hold(n);\r\nif (unlikely(mod_timer(&n->timer, when))) {\r\nprintk("NEIGH: BUG, double timer add, state is %x\n",\r\nn->nud_state);\r\ndump_stack();\r\n}\r\n}\r\nstatic int neigh_del_timer(struct neighbour *n)\r\n{\r\nif ((n->nud_state & NUD_IN_TIMER) &&\r\ndel_timer(&n->timer)) {\r\nneigh_release(n);\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic void pneigh_queue_purge(struct sk_buff_head *list)\r\n{\r\nstruct sk_buff *skb;\r\nwhile ((skb = skb_dequeue(list)) != NULL) {\r\ndev_put(skb->dev);\r\nkfree_skb(skb);\r\n}\r\n}\r\nstatic void neigh_flush_dev(struct neigh_table *tbl, struct net_device *dev)\r\n{\r\nint i;\r\nstruct neigh_hash_table *nht;\r\nnht = rcu_dereference_protected(tbl->nht,\r\nlockdep_is_held(&tbl->lock));\r\nfor (i = 0; i < (1 << nht->hash_shift); i++) {\r\nstruct neighbour *n;\r\nstruct neighbour __rcu **np = &nht->hash_buckets[i];\r\nwhile ((n = rcu_dereference_protected(*np,\r\nlockdep_is_held(&tbl->lock))) != NULL) {\r\nif (dev && n->dev != dev) {\r\nnp = &n->next;\r\ncontinue;\r\n}\r\nrcu_assign_pointer(*np,\r\nrcu_dereference_protected(n->next,\r\nlockdep_is_held(&tbl->lock)));\r\nwrite_lock(&n->lock);\r\nneigh_del_timer(n);\r\nn->dead = 1;\r\nif (atomic_read(&n->refcnt) != 1) {\r\n__skb_queue_purge(&n->arp_queue);\r\nn->arp_queue_len_bytes = 0;\r\nn->output = neigh_blackhole;\r\nif (n->nud_state & NUD_VALID)\r\nn->nud_state = NUD_NOARP;\r\nelse\r\nn->nud_state = NUD_NONE;\r\nneigh_dbg(2, "neigh %p is stray\n", n);\r\n}\r\nwrite_unlock(&n->lock);\r\nneigh_cleanup_and_release(n);\r\n}\r\n}\r\n}\r\nvoid neigh_changeaddr(struct neigh_table *tbl, struct net_device *dev)\r\n{\r\nwrite_lock_bh(&tbl->lock);\r\nneigh_flush_dev(tbl, dev);\r\nwrite_unlock_bh(&tbl->lock);\r\n}\r\nint neigh_ifdown(struct neigh_table *tbl, struct net_device *dev)\r\n{\r\nwrite_lock_bh(&tbl->lock);\r\nneigh_flush_dev(tbl, dev);\r\npneigh_ifdown(tbl, dev);\r\nwrite_unlock_bh(&tbl->lock);\r\ndel_timer_sync(&tbl->proxy_timer);\r\npneigh_queue_purge(&tbl->proxy_queue);\r\nreturn 0;\r\n}\r\nstatic struct neighbour *neigh_alloc(struct neigh_table *tbl, struct net_device *dev)\r\n{\r\nstruct neighbour *n = NULL;\r\nunsigned long now = jiffies;\r\nint entries;\r\nentries = atomic_inc_return(&tbl->entries) - 1;\r\nif (entries >= tbl->gc_thresh3 ||\r\n(entries >= tbl->gc_thresh2 &&\r\ntime_after(now, tbl->last_flush + 5 * HZ))) {\r\nif (!neigh_forced_gc(tbl) &&\r\nentries >= tbl->gc_thresh3)\r\ngoto out_entries;\r\n}\r\nn = kzalloc(tbl->entry_size + dev->neigh_priv_len, GFP_ATOMIC);\r\nif (!n)\r\ngoto out_entries;\r\n__skb_queue_head_init(&n->arp_queue);\r\nrwlock_init(&n->lock);\r\nseqlock_init(&n->ha_lock);\r\nn->updated = n->used = now;\r\nn->nud_state = NUD_NONE;\r\nn->output = neigh_blackhole;\r\nseqlock_init(&n->hh.hh_lock);\r\nn->parms = neigh_parms_clone(&tbl->parms);\r\nsetup_timer(&n->timer, neigh_timer_handler, (unsigned long)n);\r\nNEIGH_CACHE_STAT_INC(tbl, allocs);\r\nn->tbl = tbl;\r\natomic_set(&n->refcnt, 1);\r\nn->dead = 1;\r\nout:\r\nreturn n;\r\nout_entries:\r\natomic_dec(&tbl->entries);\r\ngoto out;\r\n}\r\nstatic void neigh_get_hash_rnd(u32 *x)\r\n{\r\nget_random_bytes(x, sizeof(*x));\r\n*x |= 1;\r\n}\r\nstatic struct neigh_hash_table *neigh_hash_alloc(unsigned int shift)\r\n{\r\nsize_t size = (1 << shift) * sizeof(struct neighbour *);\r\nstruct neigh_hash_table *ret;\r\nstruct neighbour __rcu **buckets;\r\nint i;\r\nret = kmalloc(sizeof(*ret), GFP_ATOMIC);\r\nif (!ret)\r\nreturn NULL;\r\nif (size <= PAGE_SIZE)\r\nbuckets = kzalloc(size, GFP_ATOMIC);\r\nelse\r\nbuckets = (struct neighbour __rcu **)\r\n__get_free_pages(GFP_ATOMIC | __GFP_ZERO,\r\nget_order(size));\r\nif (!buckets) {\r\nkfree(ret);\r\nreturn NULL;\r\n}\r\nret->hash_buckets = buckets;\r\nret->hash_shift = shift;\r\nfor (i = 0; i < NEIGH_NUM_HASH_RND; i++)\r\nneigh_get_hash_rnd(&ret->hash_rnd[i]);\r\nreturn ret;\r\n}\r\nstatic void neigh_hash_free_rcu(struct rcu_head *head)\r\n{\r\nstruct neigh_hash_table *nht = container_of(head,\r\nstruct neigh_hash_table,\r\nrcu);\r\nsize_t size = (1 << nht->hash_shift) * sizeof(struct neighbour *);\r\nstruct neighbour __rcu **buckets = nht->hash_buckets;\r\nif (size <= PAGE_SIZE)\r\nkfree(buckets);\r\nelse\r\nfree_pages((unsigned long)buckets, get_order(size));\r\nkfree(nht);\r\n}\r\nstatic struct neigh_hash_table *neigh_hash_grow(struct neigh_table *tbl,\r\nunsigned long new_shift)\r\n{\r\nunsigned int i, hash;\r\nstruct neigh_hash_table *new_nht, *old_nht;\r\nNEIGH_CACHE_STAT_INC(tbl, hash_grows);\r\nold_nht = rcu_dereference_protected(tbl->nht,\r\nlockdep_is_held(&tbl->lock));\r\nnew_nht = neigh_hash_alloc(new_shift);\r\nif (!new_nht)\r\nreturn old_nht;\r\nfor (i = 0; i < (1 << old_nht->hash_shift); i++) {\r\nstruct neighbour *n, *next;\r\nfor (n = rcu_dereference_protected(old_nht->hash_buckets[i],\r\nlockdep_is_held(&tbl->lock));\r\nn != NULL;\r\nn = next) {\r\nhash = tbl->hash(n->primary_key, n->dev,\r\nnew_nht->hash_rnd);\r\nhash >>= (32 - new_nht->hash_shift);\r\nnext = rcu_dereference_protected(n->next,\r\nlockdep_is_held(&tbl->lock));\r\nrcu_assign_pointer(n->next,\r\nrcu_dereference_protected(\r\nnew_nht->hash_buckets[hash],\r\nlockdep_is_held(&tbl->lock)));\r\nrcu_assign_pointer(new_nht->hash_buckets[hash], n);\r\n}\r\n}\r\nrcu_assign_pointer(tbl->nht, new_nht);\r\ncall_rcu(&old_nht->rcu, neigh_hash_free_rcu);\r\nreturn new_nht;\r\n}\r\nstruct neighbour *neigh_lookup(struct neigh_table *tbl, const void *pkey,\r\nstruct net_device *dev)\r\n{\r\nstruct neighbour *n;\r\nint key_len = tbl->key_len;\r\nu32 hash_val;\r\nstruct neigh_hash_table *nht;\r\nNEIGH_CACHE_STAT_INC(tbl, lookups);\r\nrcu_read_lock_bh();\r\nnht = rcu_dereference_bh(tbl->nht);\r\nhash_val = tbl->hash(pkey, dev, nht->hash_rnd) >> (32 - nht->hash_shift);\r\nfor (n = rcu_dereference_bh(nht->hash_buckets[hash_val]);\r\nn != NULL;\r\nn = rcu_dereference_bh(n->next)) {\r\nif (dev == n->dev && !memcmp(n->primary_key, pkey, key_len)) {\r\nif (!atomic_inc_not_zero(&n->refcnt))\r\nn = NULL;\r\nNEIGH_CACHE_STAT_INC(tbl, hits);\r\nbreak;\r\n}\r\n}\r\nrcu_read_unlock_bh();\r\nreturn n;\r\n}\r\nstruct neighbour *neigh_lookup_nodev(struct neigh_table *tbl, struct net *net,\r\nconst void *pkey)\r\n{\r\nstruct neighbour *n;\r\nint key_len = tbl->key_len;\r\nu32 hash_val;\r\nstruct neigh_hash_table *nht;\r\nNEIGH_CACHE_STAT_INC(tbl, lookups);\r\nrcu_read_lock_bh();\r\nnht = rcu_dereference_bh(tbl->nht);\r\nhash_val = tbl->hash(pkey, NULL, nht->hash_rnd) >> (32 - nht->hash_shift);\r\nfor (n = rcu_dereference_bh(nht->hash_buckets[hash_val]);\r\nn != NULL;\r\nn = rcu_dereference_bh(n->next)) {\r\nif (!memcmp(n->primary_key, pkey, key_len) &&\r\nnet_eq(dev_net(n->dev), net)) {\r\nif (!atomic_inc_not_zero(&n->refcnt))\r\nn = NULL;\r\nNEIGH_CACHE_STAT_INC(tbl, hits);\r\nbreak;\r\n}\r\n}\r\nrcu_read_unlock_bh();\r\nreturn n;\r\n}\r\nstruct neighbour *__neigh_create(struct neigh_table *tbl, const void *pkey,\r\nstruct net_device *dev, bool want_ref)\r\n{\r\nu32 hash_val;\r\nint key_len = tbl->key_len;\r\nint error;\r\nstruct neighbour *n1, *rc, *n = neigh_alloc(tbl, dev);\r\nstruct neigh_hash_table *nht;\r\nif (!n) {\r\nrc = ERR_PTR(-ENOBUFS);\r\ngoto out;\r\n}\r\nmemcpy(n->primary_key, pkey, key_len);\r\nn->dev = dev;\r\ndev_hold(dev);\r\nif (tbl->constructor && (error = tbl->constructor(n)) < 0) {\r\nrc = ERR_PTR(error);\r\ngoto out_neigh_release;\r\n}\r\nif (dev->netdev_ops->ndo_neigh_construct) {\r\nerror = dev->netdev_ops->ndo_neigh_construct(n);\r\nif (error < 0) {\r\nrc = ERR_PTR(error);\r\ngoto out_neigh_release;\r\n}\r\n}\r\nif (n->parms->neigh_setup &&\r\n(error = n->parms->neigh_setup(n)) < 0) {\r\nrc = ERR_PTR(error);\r\ngoto out_neigh_release;\r\n}\r\nn->confirmed = jiffies - (NEIGH_VAR(n->parms, BASE_REACHABLE_TIME) << 1);\r\nwrite_lock_bh(&tbl->lock);\r\nnht = rcu_dereference_protected(tbl->nht,\r\nlockdep_is_held(&tbl->lock));\r\nif (atomic_read(&tbl->entries) > (1 << nht->hash_shift))\r\nnht = neigh_hash_grow(tbl, nht->hash_shift + 1);\r\nhash_val = tbl->hash(pkey, dev, nht->hash_rnd) >> (32 - nht->hash_shift);\r\nif (n->parms->dead) {\r\nrc = ERR_PTR(-EINVAL);\r\ngoto out_tbl_unlock;\r\n}\r\nfor (n1 = rcu_dereference_protected(nht->hash_buckets[hash_val],\r\nlockdep_is_held(&tbl->lock));\r\nn1 != NULL;\r\nn1 = rcu_dereference_protected(n1->next,\r\nlockdep_is_held(&tbl->lock))) {\r\nif (dev == n1->dev && !memcmp(n1->primary_key, pkey, key_len)) {\r\nif (want_ref)\r\nneigh_hold(n1);\r\nrc = n1;\r\ngoto out_tbl_unlock;\r\n}\r\n}\r\nn->dead = 0;\r\nif (want_ref)\r\nneigh_hold(n);\r\nrcu_assign_pointer(n->next,\r\nrcu_dereference_protected(nht->hash_buckets[hash_val],\r\nlockdep_is_held(&tbl->lock)));\r\nrcu_assign_pointer(nht->hash_buckets[hash_val], n);\r\nwrite_unlock_bh(&tbl->lock);\r\nneigh_dbg(2, "neigh %p is created\n", n);\r\nrc = n;\r\nout:\r\nreturn rc;\r\nout_tbl_unlock:\r\nwrite_unlock_bh(&tbl->lock);\r\nout_neigh_release:\r\nneigh_release(n);\r\ngoto out;\r\n}\r\nstatic u32 pneigh_hash(const void *pkey, int key_len)\r\n{\r\nu32 hash_val = *(u32 *)(pkey + key_len - 4);\r\nhash_val ^= (hash_val >> 16);\r\nhash_val ^= hash_val >> 8;\r\nhash_val ^= hash_val >> 4;\r\nhash_val &= PNEIGH_HASHMASK;\r\nreturn hash_val;\r\n}\r\nstatic struct pneigh_entry *__pneigh_lookup_1(struct pneigh_entry *n,\r\nstruct net *net,\r\nconst void *pkey,\r\nint key_len,\r\nstruct net_device *dev)\r\n{\r\nwhile (n) {\r\nif (!memcmp(n->key, pkey, key_len) &&\r\nnet_eq(pneigh_net(n), net) &&\r\n(n->dev == dev || !n->dev))\r\nreturn n;\r\nn = n->next;\r\n}\r\nreturn NULL;\r\n}\r\nstruct pneigh_entry *__pneigh_lookup(struct neigh_table *tbl,\r\nstruct net *net, const void *pkey, struct net_device *dev)\r\n{\r\nint key_len = tbl->key_len;\r\nu32 hash_val = pneigh_hash(pkey, key_len);\r\nreturn __pneigh_lookup_1(tbl->phash_buckets[hash_val],\r\nnet, pkey, key_len, dev);\r\n}\r\nstruct pneigh_entry * pneigh_lookup(struct neigh_table *tbl,\r\nstruct net *net, const void *pkey,\r\nstruct net_device *dev, int creat)\r\n{\r\nstruct pneigh_entry *n;\r\nint key_len = tbl->key_len;\r\nu32 hash_val = pneigh_hash(pkey, key_len);\r\nread_lock_bh(&tbl->lock);\r\nn = __pneigh_lookup_1(tbl->phash_buckets[hash_val],\r\nnet, pkey, key_len, dev);\r\nread_unlock_bh(&tbl->lock);\r\nif (n || !creat)\r\ngoto out;\r\nASSERT_RTNL();\r\nn = kmalloc(sizeof(*n) + key_len, GFP_KERNEL);\r\nif (!n)\r\ngoto out;\r\nwrite_pnet(&n->net, hold_net(net));\r\nmemcpy(n->key, pkey, key_len);\r\nn->dev = dev;\r\nif (dev)\r\ndev_hold(dev);\r\nif (tbl->pconstructor && tbl->pconstructor(n)) {\r\nif (dev)\r\ndev_put(dev);\r\nrelease_net(net);\r\nkfree(n);\r\nn = NULL;\r\ngoto out;\r\n}\r\nwrite_lock_bh(&tbl->lock);\r\nn->next = tbl->phash_buckets[hash_val];\r\ntbl->phash_buckets[hash_val] = n;\r\nwrite_unlock_bh(&tbl->lock);\r\nout:\r\nreturn n;\r\n}\r\nint pneigh_delete(struct neigh_table *tbl, struct net *net, const void *pkey,\r\nstruct net_device *dev)\r\n{\r\nstruct pneigh_entry *n, **np;\r\nint key_len = tbl->key_len;\r\nu32 hash_val = pneigh_hash(pkey, key_len);\r\nwrite_lock_bh(&tbl->lock);\r\nfor (np = &tbl->phash_buckets[hash_val]; (n = *np) != NULL;\r\nnp = &n->next) {\r\nif (!memcmp(n->key, pkey, key_len) && n->dev == dev &&\r\nnet_eq(pneigh_net(n), net)) {\r\n*np = n->next;\r\nwrite_unlock_bh(&tbl->lock);\r\nif (tbl->pdestructor)\r\ntbl->pdestructor(n);\r\nif (n->dev)\r\ndev_put(n->dev);\r\nrelease_net(pneigh_net(n));\r\nkfree(n);\r\nreturn 0;\r\n}\r\n}\r\nwrite_unlock_bh(&tbl->lock);\r\nreturn -ENOENT;\r\n}\r\nstatic int pneigh_ifdown(struct neigh_table *tbl, struct net_device *dev)\r\n{\r\nstruct pneigh_entry *n, **np;\r\nu32 h;\r\nfor (h = 0; h <= PNEIGH_HASHMASK; h++) {\r\nnp = &tbl->phash_buckets[h];\r\nwhile ((n = *np) != NULL) {\r\nif (!dev || n->dev == dev) {\r\n*np = n->next;\r\nif (tbl->pdestructor)\r\ntbl->pdestructor(n);\r\nif (n->dev)\r\ndev_put(n->dev);\r\nrelease_net(pneigh_net(n));\r\nkfree(n);\r\ncontinue;\r\n}\r\nnp = &n->next;\r\n}\r\n}\r\nreturn -ENOENT;\r\n}\r\nstatic inline void neigh_parms_put(struct neigh_parms *parms)\r\n{\r\nif (atomic_dec_and_test(&parms->refcnt))\r\nneigh_parms_destroy(parms);\r\n}\r\nvoid neigh_destroy(struct neighbour *neigh)\r\n{\r\nstruct net_device *dev = neigh->dev;\r\nNEIGH_CACHE_STAT_INC(neigh->tbl, destroys);\r\nif (!neigh->dead) {\r\npr_warn("Destroying alive neighbour %p\n", neigh);\r\ndump_stack();\r\nreturn;\r\n}\r\nif (neigh_del_timer(neigh))\r\npr_warn("Impossible event\n");\r\nwrite_lock_bh(&neigh->lock);\r\n__skb_queue_purge(&neigh->arp_queue);\r\nwrite_unlock_bh(&neigh->lock);\r\nneigh->arp_queue_len_bytes = 0;\r\nif (dev->netdev_ops->ndo_neigh_destroy)\r\ndev->netdev_ops->ndo_neigh_destroy(neigh);\r\ndev_put(dev);\r\nneigh_parms_put(neigh->parms);\r\nneigh_dbg(2, "neigh %p is destroyed\n", neigh);\r\natomic_dec(&neigh->tbl->entries);\r\nkfree_rcu(neigh, rcu);\r\n}\r\nstatic void neigh_suspect(struct neighbour *neigh)\r\n{\r\nneigh_dbg(2, "neigh %p is suspected\n", neigh);\r\nneigh->output = neigh->ops->output;\r\n}\r\nstatic void neigh_connect(struct neighbour *neigh)\r\n{\r\nneigh_dbg(2, "neigh %p is connected\n", neigh);\r\nneigh->output = neigh->ops->connected_output;\r\n}\r\nstatic void neigh_periodic_work(struct work_struct *work)\r\n{\r\nstruct neigh_table *tbl = container_of(work, struct neigh_table, gc_work.work);\r\nstruct neighbour *n;\r\nstruct neighbour __rcu **np;\r\nunsigned int i;\r\nstruct neigh_hash_table *nht;\r\nNEIGH_CACHE_STAT_INC(tbl, periodic_gc_runs);\r\nwrite_lock_bh(&tbl->lock);\r\nnht = rcu_dereference_protected(tbl->nht,\r\nlockdep_is_held(&tbl->lock));\r\nif (time_after(jiffies, tbl->last_rand + 300 * HZ)) {\r\nstruct neigh_parms *p;\r\ntbl->last_rand = jiffies;\r\nfor (p = &tbl->parms; p; p = p->next)\r\np->reachable_time =\r\nneigh_rand_reach_time(NEIGH_VAR(p, BASE_REACHABLE_TIME));\r\n}\r\nif (atomic_read(&tbl->entries) < tbl->gc_thresh1)\r\ngoto out;\r\nfor (i = 0 ; i < (1 << nht->hash_shift); i++) {\r\nnp = &nht->hash_buckets[i];\r\nwhile ((n = rcu_dereference_protected(*np,\r\nlockdep_is_held(&tbl->lock))) != NULL) {\r\nunsigned int state;\r\nwrite_lock(&n->lock);\r\nstate = n->nud_state;\r\nif (state & (NUD_PERMANENT | NUD_IN_TIMER)) {\r\nwrite_unlock(&n->lock);\r\ngoto next_elt;\r\n}\r\nif (time_before(n->used, n->confirmed))\r\nn->used = n->confirmed;\r\nif (atomic_read(&n->refcnt) == 1 &&\r\n(state == NUD_FAILED ||\r\ntime_after(jiffies, n->used + NEIGH_VAR(n->parms, GC_STALETIME)))) {\r\n*np = n->next;\r\nn->dead = 1;\r\nwrite_unlock(&n->lock);\r\nneigh_cleanup_and_release(n);\r\ncontinue;\r\n}\r\nwrite_unlock(&n->lock);\r\nnext_elt:\r\nnp = &n->next;\r\n}\r\nwrite_unlock_bh(&tbl->lock);\r\ncond_resched();\r\nwrite_lock_bh(&tbl->lock);\r\nnht = rcu_dereference_protected(tbl->nht,\r\nlockdep_is_held(&tbl->lock));\r\n}\r\nout:\r\nqueue_delayed_work(system_power_efficient_wq, &tbl->gc_work,\r\nNEIGH_VAR(&tbl->parms, BASE_REACHABLE_TIME) >> 1);\r\nwrite_unlock_bh(&tbl->lock);\r\n}\r\nstatic __inline__ int neigh_max_probes(struct neighbour *n)\r\n{\r\nstruct neigh_parms *p = n->parms;\r\nint max_probes = NEIGH_VAR(p, UCAST_PROBES) + NEIGH_VAR(p, APP_PROBES);\r\nif (!(n->nud_state & NUD_PROBE))\r\nmax_probes += NEIGH_VAR(p, MCAST_PROBES);\r\nreturn max_probes;\r\n}\r\nstatic void neigh_invalidate(struct neighbour *neigh)\r\n__releases(neigh->lock)\r\n__acquires(neigh->lock)\r\n{\r\nstruct sk_buff *skb;\r\nNEIGH_CACHE_STAT_INC(neigh->tbl, res_failed);\r\nneigh_dbg(2, "neigh %p is failed\n", neigh);\r\nneigh->updated = jiffies;\r\nwhile (neigh->nud_state == NUD_FAILED &&\r\n(skb = __skb_dequeue(&neigh->arp_queue)) != NULL) {\r\nwrite_unlock(&neigh->lock);\r\nneigh->ops->error_report(neigh, skb);\r\nwrite_lock(&neigh->lock);\r\n}\r\n__skb_queue_purge(&neigh->arp_queue);\r\nneigh->arp_queue_len_bytes = 0;\r\n}\r\nstatic void neigh_probe(struct neighbour *neigh)\r\n__releases(neigh->lock)\r\n{\r\nstruct sk_buff *skb = skb_peek_tail(&neigh->arp_queue);\r\nif (skb)\r\nskb = skb_copy(skb, GFP_ATOMIC);\r\nwrite_unlock(&neigh->lock);\r\nneigh->ops->solicit(neigh, skb);\r\natomic_inc(&neigh->probes);\r\nkfree_skb(skb);\r\n}\r\nstatic void neigh_timer_handler(unsigned long arg)\r\n{\r\nunsigned long now, next;\r\nstruct neighbour *neigh = (struct neighbour *)arg;\r\nunsigned int state;\r\nint notify = 0;\r\nwrite_lock(&neigh->lock);\r\nstate = neigh->nud_state;\r\nnow = jiffies;\r\nnext = now + HZ;\r\nif (!(state & NUD_IN_TIMER))\r\ngoto out;\r\nif (state & NUD_REACHABLE) {\r\nif (time_before_eq(now,\r\nneigh->confirmed + neigh->parms->reachable_time)) {\r\nneigh_dbg(2, "neigh %p is still alive\n", neigh);\r\nnext = neigh->confirmed + neigh->parms->reachable_time;\r\n} else if (time_before_eq(now,\r\nneigh->used +\r\nNEIGH_VAR(neigh->parms, DELAY_PROBE_TIME))) {\r\nneigh_dbg(2, "neigh %p is delayed\n", neigh);\r\nneigh->nud_state = NUD_DELAY;\r\nneigh->updated = jiffies;\r\nneigh_suspect(neigh);\r\nnext = now + NEIGH_VAR(neigh->parms, DELAY_PROBE_TIME);\r\n} else {\r\nneigh_dbg(2, "neigh %p is suspected\n", neigh);\r\nneigh->nud_state = NUD_STALE;\r\nneigh->updated = jiffies;\r\nneigh_suspect(neigh);\r\nnotify = 1;\r\n}\r\n} else if (state & NUD_DELAY) {\r\nif (time_before_eq(now,\r\nneigh->confirmed +\r\nNEIGH_VAR(neigh->parms, DELAY_PROBE_TIME))) {\r\nneigh_dbg(2, "neigh %p is now reachable\n", neigh);\r\nneigh->nud_state = NUD_REACHABLE;\r\nneigh->updated = jiffies;\r\nneigh_connect(neigh);\r\nnotify = 1;\r\nnext = neigh->confirmed + neigh->parms->reachable_time;\r\n} else {\r\nneigh_dbg(2, "neigh %p is probed\n", neigh);\r\nneigh->nud_state = NUD_PROBE;\r\nneigh->updated = jiffies;\r\natomic_set(&neigh->probes, 0);\r\nnext = now + NEIGH_VAR(neigh->parms, RETRANS_TIME);\r\n}\r\n} else {\r\nnext = now + NEIGH_VAR(neigh->parms, RETRANS_TIME);\r\n}\r\nif ((neigh->nud_state & (NUD_INCOMPLETE | NUD_PROBE)) &&\r\natomic_read(&neigh->probes) >= neigh_max_probes(neigh)) {\r\nneigh->nud_state = NUD_FAILED;\r\nnotify = 1;\r\nneigh_invalidate(neigh);\r\ngoto out;\r\n}\r\nif (neigh->nud_state & NUD_IN_TIMER) {\r\nif (time_before(next, jiffies + HZ/2))\r\nnext = jiffies + HZ/2;\r\nif (!mod_timer(&neigh->timer, next))\r\nneigh_hold(neigh);\r\n}\r\nif (neigh->nud_state & (NUD_INCOMPLETE | NUD_PROBE)) {\r\nneigh_probe(neigh);\r\n} else {\r\nout:\r\nwrite_unlock(&neigh->lock);\r\n}\r\nif (notify)\r\nneigh_update_notify(neigh);\r\nneigh_release(neigh);\r\n}\r\nint __neigh_event_send(struct neighbour *neigh, struct sk_buff *skb)\r\n{\r\nint rc;\r\nbool immediate_probe = false;\r\nwrite_lock_bh(&neigh->lock);\r\nrc = 0;\r\nif (neigh->nud_state & (NUD_CONNECTED | NUD_DELAY | NUD_PROBE))\r\ngoto out_unlock_bh;\r\nif (!(neigh->nud_state & (NUD_STALE | NUD_INCOMPLETE))) {\r\nif (NEIGH_VAR(neigh->parms, MCAST_PROBES) +\r\nNEIGH_VAR(neigh->parms, APP_PROBES)) {\r\nunsigned long next, now = jiffies;\r\natomic_set(&neigh->probes,\r\nNEIGH_VAR(neigh->parms, UCAST_PROBES));\r\nneigh->nud_state = NUD_INCOMPLETE;\r\nneigh->updated = now;\r\nnext = now + max(NEIGH_VAR(neigh->parms, RETRANS_TIME),\r\nHZ/2);\r\nneigh_add_timer(neigh, next);\r\nimmediate_probe = true;\r\n} else {\r\nneigh->nud_state = NUD_FAILED;\r\nneigh->updated = jiffies;\r\nwrite_unlock_bh(&neigh->lock);\r\nkfree_skb(skb);\r\nreturn 1;\r\n}\r\n} else if (neigh->nud_state & NUD_STALE) {\r\nneigh_dbg(2, "neigh %p is delayed\n", neigh);\r\nneigh->nud_state = NUD_DELAY;\r\nneigh->updated = jiffies;\r\nneigh_add_timer(neigh, jiffies +\r\nNEIGH_VAR(neigh->parms, DELAY_PROBE_TIME));\r\n}\r\nif (neigh->nud_state == NUD_INCOMPLETE) {\r\nif (skb) {\r\nwhile (neigh->arp_queue_len_bytes + skb->truesize >\r\nNEIGH_VAR(neigh->parms, QUEUE_LEN_BYTES)) {\r\nstruct sk_buff *buff;\r\nbuff = __skb_dequeue(&neigh->arp_queue);\r\nif (!buff)\r\nbreak;\r\nneigh->arp_queue_len_bytes -= buff->truesize;\r\nkfree_skb(buff);\r\nNEIGH_CACHE_STAT_INC(neigh->tbl, unres_discards);\r\n}\r\nskb_dst_force(skb);\r\n__skb_queue_tail(&neigh->arp_queue, skb);\r\nneigh->arp_queue_len_bytes += skb->truesize;\r\n}\r\nrc = 1;\r\n}\r\nout_unlock_bh:\r\nif (immediate_probe)\r\nneigh_probe(neigh);\r\nelse\r\nwrite_unlock(&neigh->lock);\r\nlocal_bh_enable();\r\nreturn rc;\r\n}\r\nstatic void neigh_update_hhs(struct neighbour *neigh)\r\n{\r\nstruct hh_cache *hh;\r\nvoid (*update)(struct hh_cache*, const struct net_device*, const unsigned char *)\r\n= NULL;\r\nif (neigh->dev->header_ops)\r\nupdate = neigh->dev->header_ops->cache_update;\r\nif (update) {\r\nhh = &neigh->hh;\r\nif (hh->hh_len) {\r\nwrite_seqlock_bh(&hh->hh_lock);\r\nupdate(hh, neigh->dev, neigh->ha);\r\nwrite_sequnlock_bh(&hh->hh_lock);\r\n}\r\n}\r\n}\r\nint neigh_update(struct neighbour *neigh, const u8 *lladdr, u8 new,\r\nu32 flags)\r\n{\r\nu8 old;\r\nint err;\r\nint notify = 0;\r\nstruct net_device *dev;\r\nint update_isrouter = 0;\r\nwrite_lock_bh(&neigh->lock);\r\ndev = neigh->dev;\r\nold = neigh->nud_state;\r\nerr = -EPERM;\r\nif (!(flags & NEIGH_UPDATE_F_ADMIN) &&\r\n(old & (NUD_NOARP | NUD_PERMANENT)))\r\ngoto out;\r\nif (!(new & NUD_VALID)) {\r\nneigh_del_timer(neigh);\r\nif (old & NUD_CONNECTED)\r\nneigh_suspect(neigh);\r\nneigh->nud_state = new;\r\nerr = 0;\r\nnotify = old & NUD_VALID;\r\nif ((old & (NUD_INCOMPLETE | NUD_PROBE)) &&\r\n(new & NUD_FAILED)) {\r\nneigh_invalidate(neigh);\r\nnotify = 1;\r\n}\r\ngoto out;\r\n}\r\nif (!dev->addr_len) {\r\nlladdr = neigh->ha;\r\n} else if (lladdr) {\r\nif ((old & NUD_VALID) &&\r\n!memcmp(lladdr, neigh->ha, dev->addr_len))\r\nlladdr = neigh->ha;\r\n} else {\r\nerr = -EINVAL;\r\nif (!(old & NUD_VALID))\r\ngoto out;\r\nlladdr = neigh->ha;\r\n}\r\nif (new & NUD_CONNECTED)\r\nneigh->confirmed = jiffies;\r\nneigh->updated = jiffies;\r\nerr = 0;\r\nupdate_isrouter = flags & NEIGH_UPDATE_F_OVERRIDE_ISROUTER;\r\nif (old & NUD_VALID) {\r\nif (lladdr != neigh->ha && !(flags & NEIGH_UPDATE_F_OVERRIDE)) {\r\nupdate_isrouter = 0;\r\nif ((flags & NEIGH_UPDATE_F_WEAK_OVERRIDE) &&\r\n(old & NUD_CONNECTED)) {\r\nlladdr = neigh->ha;\r\nnew = NUD_STALE;\r\n} else\r\ngoto out;\r\n} else {\r\nif (lladdr == neigh->ha && new == NUD_STALE &&\r\n((flags & NEIGH_UPDATE_F_WEAK_OVERRIDE) ||\r\n(old & NUD_CONNECTED))\r\n)\r\nnew = old;\r\n}\r\n}\r\nif (new != old) {\r\nneigh_del_timer(neigh);\r\nif (new & NUD_IN_TIMER)\r\nneigh_add_timer(neigh, (jiffies +\r\n((new & NUD_REACHABLE) ?\r\nneigh->parms->reachable_time :\r\n0)));\r\nneigh->nud_state = new;\r\nnotify = 1;\r\n}\r\nif (lladdr != neigh->ha) {\r\nwrite_seqlock(&neigh->ha_lock);\r\nmemcpy(&neigh->ha, lladdr, dev->addr_len);\r\nwrite_sequnlock(&neigh->ha_lock);\r\nneigh_update_hhs(neigh);\r\nif (!(new & NUD_CONNECTED))\r\nneigh->confirmed = jiffies -\r\n(NEIGH_VAR(neigh->parms, BASE_REACHABLE_TIME) << 1);\r\nnotify = 1;\r\n}\r\nif (new == old)\r\ngoto out;\r\nif (new & NUD_CONNECTED)\r\nneigh_connect(neigh);\r\nelse\r\nneigh_suspect(neigh);\r\nif (!(old & NUD_VALID)) {\r\nstruct sk_buff *skb;\r\nwhile (neigh->nud_state & NUD_VALID &&\r\n(skb = __skb_dequeue(&neigh->arp_queue)) != NULL) {\r\nstruct dst_entry *dst = skb_dst(skb);\r\nstruct neighbour *n2, *n1 = neigh;\r\nwrite_unlock_bh(&neigh->lock);\r\nrcu_read_lock();\r\nn2 = NULL;\r\nif (dst) {\r\nn2 = dst_neigh_lookup_skb(dst, skb);\r\nif (n2)\r\nn1 = n2;\r\n}\r\nn1->output(n1, skb);\r\nif (n2)\r\nneigh_release(n2);\r\nrcu_read_unlock();\r\nwrite_lock_bh(&neigh->lock);\r\n}\r\n__skb_queue_purge(&neigh->arp_queue);\r\nneigh->arp_queue_len_bytes = 0;\r\n}\r\nout:\r\nif (update_isrouter) {\r\nneigh->flags = (flags & NEIGH_UPDATE_F_ISROUTER) ?\r\n(neigh->flags | NTF_ROUTER) :\r\n(neigh->flags & ~NTF_ROUTER);\r\n}\r\nwrite_unlock_bh(&neigh->lock);\r\nif (notify)\r\nneigh_update_notify(neigh);\r\nreturn err;\r\n}\r\nvoid __neigh_set_probe_once(struct neighbour *neigh)\r\n{\r\nneigh->updated = jiffies;\r\nif (!(neigh->nud_state & NUD_FAILED))\r\nreturn;\r\nneigh->nud_state = NUD_INCOMPLETE;\r\natomic_set(&neigh->probes, neigh_max_probes(neigh));\r\nneigh_add_timer(neigh,\r\njiffies + NEIGH_VAR(neigh->parms, RETRANS_TIME));\r\n}\r\nstruct neighbour *neigh_event_ns(struct neigh_table *tbl,\r\nu8 *lladdr, void *saddr,\r\nstruct net_device *dev)\r\n{\r\nstruct neighbour *neigh = __neigh_lookup(tbl, saddr, dev,\r\nlladdr || !dev->addr_len);\r\nif (neigh)\r\nneigh_update(neigh, lladdr, NUD_STALE,\r\nNEIGH_UPDATE_F_OVERRIDE);\r\nreturn neigh;\r\n}\r\nstatic void neigh_hh_init(struct neighbour *n, struct dst_entry *dst)\r\n{\r\nstruct net_device *dev = dst->dev;\r\n__be16 prot = dst->ops->protocol;\r\nstruct hh_cache *hh = &n->hh;\r\nwrite_lock_bh(&n->lock);\r\nif (!hh->hh_len)\r\ndev->header_ops->cache(n, hh, prot);\r\nwrite_unlock_bh(&n->lock);\r\n}\r\nint neigh_compat_output(struct neighbour *neigh, struct sk_buff *skb)\r\n{\r\nstruct net_device *dev = skb->dev;\r\n__skb_pull(skb, skb_network_offset(skb));\r\nif (dev_hard_header(skb, dev, ntohs(skb->protocol), NULL, NULL,\r\nskb->len) < 0 &&\r\ndev_rebuild_header(skb))\r\nreturn 0;\r\nreturn dev_queue_xmit(skb);\r\n}\r\nint neigh_resolve_output(struct neighbour *neigh, struct sk_buff *skb)\r\n{\r\nstruct dst_entry *dst = skb_dst(skb);\r\nint rc = 0;\r\nif (!dst)\r\ngoto discard;\r\nif (!neigh_event_send(neigh, skb)) {\r\nint err;\r\nstruct net_device *dev = neigh->dev;\r\nunsigned int seq;\r\nif (dev->header_ops->cache && !neigh->hh.hh_len)\r\nneigh_hh_init(neigh, dst);\r\ndo {\r\n__skb_pull(skb, skb_network_offset(skb));\r\nseq = read_seqbegin(&neigh->ha_lock);\r\nerr = dev_hard_header(skb, dev, ntohs(skb->protocol),\r\nneigh->ha, NULL, skb->len);\r\n} while (read_seqretry(&neigh->ha_lock, seq));\r\nif (err >= 0)\r\nrc = dev_queue_xmit(skb);\r\nelse\r\ngoto out_kfree_skb;\r\n}\r\nout:\r\nreturn rc;\r\ndiscard:\r\nneigh_dbg(1, "%s: dst=%p neigh=%p\n", __func__, dst, neigh);\r\nout_kfree_skb:\r\nrc = -EINVAL;\r\nkfree_skb(skb);\r\ngoto out;\r\n}\r\nint neigh_connected_output(struct neighbour *neigh, struct sk_buff *skb)\r\n{\r\nstruct net_device *dev = neigh->dev;\r\nunsigned int seq;\r\nint err;\r\ndo {\r\n__skb_pull(skb, skb_network_offset(skb));\r\nseq = read_seqbegin(&neigh->ha_lock);\r\nerr = dev_hard_header(skb, dev, ntohs(skb->protocol),\r\nneigh->ha, NULL, skb->len);\r\n} while (read_seqretry(&neigh->ha_lock, seq));\r\nif (err >= 0)\r\nerr = dev_queue_xmit(skb);\r\nelse {\r\nerr = -EINVAL;\r\nkfree_skb(skb);\r\n}\r\nreturn err;\r\n}\r\nint neigh_direct_output(struct neighbour *neigh, struct sk_buff *skb)\r\n{\r\nreturn dev_queue_xmit(skb);\r\n}\r\nstatic void neigh_proxy_process(unsigned long arg)\r\n{\r\nstruct neigh_table *tbl = (struct neigh_table *)arg;\r\nlong sched_next = 0;\r\nunsigned long now = jiffies;\r\nstruct sk_buff *skb, *n;\r\nspin_lock(&tbl->proxy_queue.lock);\r\nskb_queue_walk_safe(&tbl->proxy_queue, skb, n) {\r\nlong tdif = NEIGH_CB(skb)->sched_next - now;\r\nif (tdif <= 0) {\r\nstruct net_device *dev = skb->dev;\r\n__skb_unlink(skb, &tbl->proxy_queue);\r\nif (tbl->proxy_redo && netif_running(dev)) {\r\nrcu_read_lock();\r\ntbl->proxy_redo(skb);\r\nrcu_read_unlock();\r\n} else {\r\nkfree_skb(skb);\r\n}\r\ndev_put(dev);\r\n} else if (!sched_next || tdif < sched_next)\r\nsched_next = tdif;\r\n}\r\ndel_timer(&tbl->proxy_timer);\r\nif (sched_next)\r\nmod_timer(&tbl->proxy_timer, jiffies + sched_next);\r\nspin_unlock(&tbl->proxy_queue.lock);\r\n}\r\nvoid pneigh_enqueue(struct neigh_table *tbl, struct neigh_parms *p,\r\nstruct sk_buff *skb)\r\n{\r\nunsigned long now = jiffies;\r\nunsigned long sched_next = now + (prandom_u32() %\r\nNEIGH_VAR(p, PROXY_DELAY));\r\nif (tbl->proxy_queue.qlen > NEIGH_VAR(p, PROXY_QLEN)) {\r\nkfree_skb(skb);\r\nreturn;\r\n}\r\nNEIGH_CB(skb)->sched_next = sched_next;\r\nNEIGH_CB(skb)->flags |= LOCALLY_ENQUEUED;\r\nspin_lock(&tbl->proxy_queue.lock);\r\nif (del_timer(&tbl->proxy_timer)) {\r\nif (time_before(tbl->proxy_timer.expires, sched_next))\r\nsched_next = tbl->proxy_timer.expires;\r\n}\r\nskb_dst_drop(skb);\r\ndev_hold(skb->dev);\r\n__skb_queue_tail(&tbl->proxy_queue, skb);\r\nmod_timer(&tbl->proxy_timer, sched_next);\r\nspin_unlock(&tbl->proxy_queue.lock);\r\n}\r\nstatic inline struct neigh_parms *lookup_neigh_parms(struct neigh_table *tbl,\r\nstruct net *net, int ifindex)\r\n{\r\nstruct neigh_parms *p;\r\nfor (p = &tbl->parms; p; p = p->next) {\r\nif ((p->dev && p->dev->ifindex == ifindex && net_eq(neigh_parms_net(p), net)) ||\r\n(!p->dev && !ifindex && net_eq(net, &init_net)))\r\nreturn p;\r\n}\r\nreturn NULL;\r\n}\r\nstruct neigh_parms *neigh_parms_alloc(struct net_device *dev,\r\nstruct neigh_table *tbl)\r\n{\r\nstruct neigh_parms *p;\r\nstruct net *net = dev_net(dev);\r\nconst struct net_device_ops *ops = dev->netdev_ops;\r\np = kmemdup(&tbl->parms, sizeof(*p), GFP_KERNEL);\r\nif (p) {\r\np->tbl = tbl;\r\natomic_set(&p->refcnt, 1);\r\np->reachable_time =\r\nneigh_rand_reach_time(NEIGH_VAR(p, BASE_REACHABLE_TIME));\r\ndev_hold(dev);\r\np->dev = dev;\r\nwrite_pnet(&p->net, hold_net(net));\r\np->sysctl_table = NULL;\r\nif (ops->ndo_neigh_setup && ops->ndo_neigh_setup(dev, p)) {\r\nrelease_net(net);\r\ndev_put(dev);\r\nkfree(p);\r\nreturn NULL;\r\n}\r\nwrite_lock_bh(&tbl->lock);\r\np->next = tbl->parms.next;\r\ntbl->parms.next = p;\r\nwrite_unlock_bh(&tbl->lock);\r\nneigh_parms_data_state_cleanall(p);\r\n}\r\nreturn p;\r\n}\r\nstatic void neigh_rcu_free_parms(struct rcu_head *head)\r\n{\r\nstruct neigh_parms *parms =\r\ncontainer_of(head, struct neigh_parms, rcu_head);\r\nneigh_parms_put(parms);\r\n}\r\nvoid neigh_parms_release(struct neigh_table *tbl, struct neigh_parms *parms)\r\n{\r\nstruct neigh_parms **p;\r\nif (!parms || parms == &tbl->parms)\r\nreturn;\r\nwrite_lock_bh(&tbl->lock);\r\nfor (p = &tbl->parms.next; *p; p = &(*p)->next) {\r\nif (*p == parms) {\r\n*p = parms->next;\r\nparms->dead = 1;\r\nwrite_unlock_bh(&tbl->lock);\r\nif (parms->dev)\r\ndev_put(parms->dev);\r\ncall_rcu(&parms->rcu_head, neigh_rcu_free_parms);\r\nreturn;\r\n}\r\n}\r\nwrite_unlock_bh(&tbl->lock);\r\nneigh_dbg(1, "%s: not found\n", __func__);\r\n}\r\nstatic void neigh_parms_destroy(struct neigh_parms *parms)\r\n{\r\nrelease_net(neigh_parms_net(parms));\r\nkfree(parms);\r\n}\r\nstatic void neigh_table_init_no_netlink(struct neigh_table *tbl)\r\n{\r\nunsigned long now = jiffies;\r\nunsigned long phsize;\r\nwrite_pnet(&tbl->parms.net, &init_net);\r\natomic_set(&tbl->parms.refcnt, 1);\r\ntbl->parms.reachable_time =\r\nneigh_rand_reach_time(NEIGH_VAR(&tbl->parms, BASE_REACHABLE_TIME));\r\ntbl->stats = alloc_percpu(struct neigh_statistics);\r\nif (!tbl->stats)\r\npanic("cannot create neighbour cache statistics");\r\n#ifdef CONFIG_PROC_FS\r\nif (!proc_create_data(tbl->id, 0, init_net.proc_net_stat,\r\n&neigh_stat_seq_fops, tbl))\r\npanic("cannot create neighbour proc dir entry");\r\n#endif\r\nRCU_INIT_POINTER(tbl->nht, neigh_hash_alloc(3));\r\nphsize = (PNEIGH_HASHMASK + 1) * sizeof(struct pneigh_entry *);\r\ntbl->phash_buckets = kzalloc(phsize, GFP_KERNEL);\r\nif (!tbl->nht || !tbl->phash_buckets)\r\npanic("cannot allocate neighbour cache hashes");\r\nif (!tbl->entry_size)\r\ntbl->entry_size = ALIGN(offsetof(struct neighbour, primary_key) +\r\ntbl->key_len, NEIGH_PRIV_ALIGN);\r\nelse\r\nWARN_ON(tbl->entry_size % NEIGH_PRIV_ALIGN);\r\nrwlock_init(&tbl->lock);\r\nINIT_DEFERRABLE_WORK(&tbl->gc_work, neigh_periodic_work);\r\nqueue_delayed_work(system_power_efficient_wq, &tbl->gc_work,\r\ntbl->parms.reachable_time);\r\nsetup_timer(&tbl->proxy_timer, neigh_proxy_process, (unsigned long)tbl);\r\nskb_queue_head_init_class(&tbl->proxy_queue,\r\n&neigh_table_proxy_queue_class);\r\ntbl->last_flush = now;\r\ntbl->last_rand = now + tbl->parms.reachable_time * 20;\r\n}\r\nvoid neigh_table_init(struct neigh_table *tbl)\r\n{\r\nstruct neigh_table *tmp;\r\nneigh_table_init_no_netlink(tbl);\r\nwrite_lock(&neigh_tbl_lock);\r\nfor (tmp = neigh_tables; tmp; tmp = tmp->next) {\r\nif (tmp->family == tbl->family)\r\nbreak;\r\n}\r\ntbl->next = neigh_tables;\r\nneigh_tables = tbl;\r\nwrite_unlock(&neigh_tbl_lock);\r\nif (unlikely(tmp)) {\r\npr_err("Registering multiple tables for family %d\n",\r\ntbl->family);\r\ndump_stack();\r\n}\r\n}\r\nint neigh_table_clear(struct neigh_table *tbl)\r\n{\r\nstruct neigh_table **tp;\r\ncancel_delayed_work_sync(&tbl->gc_work);\r\ndel_timer_sync(&tbl->proxy_timer);\r\npneigh_queue_purge(&tbl->proxy_queue);\r\nneigh_ifdown(tbl, NULL);\r\nif (atomic_read(&tbl->entries))\r\npr_crit("neighbour leakage\n");\r\nwrite_lock(&neigh_tbl_lock);\r\nfor (tp = &neigh_tables; *tp; tp = &(*tp)->next) {\r\nif (*tp == tbl) {\r\n*tp = tbl->next;\r\nbreak;\r\n}\r\n}\r\nwrite_unlock(&neigh_tbl_lock);\r\ncall_rcu(&rcu_dereference_protected(tbl->nht, 1)->rcu,\r\nneigh_hash_free_rcu);\r\ntbl->nht = NULL;\r\nkfree(tbl->phash_buckets);\r\ntbl->phash_buckets = NULL;\r\nremove_proc_entry(tbl->id, init_net.proc_net_stat);\r\nfree_percpu(tbl->stats);\r\ntbl->stats = NULL;\r\nreturn 0;\r\n}\r\nstatic int neigh_delete(struct sk_buff *skb, struct nlmsghdr *nlh)\r\n{\r\nstruct net *net = sock_net(skb->sk);\r\nstruct ndmsg *ndm;\r\nstruct nlattr *dst_attr;\r\nstruct neigh_table *tbl;\r\nstruct net_device *dev = NULL;\r\nint err = -EINVAL;\r\nASSERT_RTNL();\r\nif (nlmsg_len(nlh) < sizeof(*ndm))\r\ngoto out;\r\ndst_attr = nlmsg_find_attr(nlh, sizeof(*ndm), NDA_DST);\r\nif (dst_attr == NULL)\r\ngoto out;\r\nndm = nlmsg_data(nlh);\r\nif (ndm->ndm_ifindex) {\r\ndev = __dev_get_by_index(net, ndm->ndm_ifindex);\r\nif (dev == NULL) {\r\nerr = -ENODEV;\r\ngoto out;\r\n}\r\n}\r\nread_lock(&neigh_tbl_lock);\r\nfor (tbl = neigh_tables; tbl; tbl = tbl->next) {\r\nstruct neighbour *neigh;\r\nif (tbl->family != ndm->ndm_family)\r\ncontinue;\r\nread_unlock(&neigh_tbl_lock);\r\nif (nla_len(dst_attr) < tbl->key_len)\r\ngoto out;\r\nif (ndm->ndm_flags & NTF_PROXY) {\r\nerr = pneigh_delete(tbl, net, nla_data(dst_attr), dev);\r\ngoto out;\r\n}\r\nif (dev == NULL)\r\ngoto out;\r\nneigh = neigh_lookup(tbl, nla_data(dst_attr), dev);\r\nif (neigh == NULL) {\r\nerr = -ENOENT;\r\ngoto out;\r\n}\r\nerr = neigh_update(neigh, NULL, NUD_FAILED,\r\nNEIGH_UPDATE_F_OVERRIDE |\r\nNEIGH_UPDATE_F_ADMIN);\r\nneigh_release(neigh);\r\ngoto out;\r\n}\r\nread_unlock(&neigh_tbl_lock);\r\nerr = -EAFNOSUPPORT;\r\nout:\r\nreturn err;\r\n}\r\nstatic int neigh_add(struct sk_buff *skb, struct nlmsghdr *nlh)\r\n{\r\nstruct net *net = sock_net(skb->sk);\r\nstruct ndmsg *ndm;\r\nstruct nlattr *tb[NDA_MAX+1];\r\nstruct neigh_table *tbl;\r\nstruct net_device *dev = NULL;\r\nint err;\r\nASSERT_RTNL();\r\nerr = nlmsg_parse(nlh, sizeof(*ndm), tb, NDA_MAX, NULL);\r\nif (err < 0)\r\ngoto out;\r\nerr = -EINVAL;\r\nif (tb[NDA_DST] == NULL)\r\ngoto out;\r\nndm = nlmsg_data(nlh);\r\nif (ndm->ndm_ifindex) {\r\ndev = __dev_get_by_index(net, ndm->ndm_ifindex);\r\nif (dev == NULL) {\r\nerr = -ENODEV;\r\ngoto out;\r\n}\r\nif (tb[NDA_LLADDR] && nla_len(tb[NDA_LLADDR]) < dev->addr_len)\r\ngoto out;\r\n}\r\nread_lock(&neigh_tbl_lock);\r\nfor (tbl = neigh_tables; tbl; tbl = tbl->next) {\r\nint flags = NEIGH_UPDATE_F_ADMIN | NEIGH_UPDATE_F_OVERRIDE;\r\nstruct neighbour *neigh;\r\nvoid *dst, *lladdr;\r\nif (tbl->family != ndm->ndm_family)\r\ncontinue;\r\nread_unlock(&neigh_tbl_lock);\r\nif (nla_len(tb[NDA_DST]) < tbl->key_len)\r\ngoto out;\r\ndst = nla_data(tb[NDA_DST]);\r\nlladdr = tb[NDA_LLADDR] ? nla_data(tb[NDA_LLADDR]) : NULL;\r\nif (ndm->ndm_flags & NTF_PROXY) {\r\nstruct pneigh_entry *pn;\r\nerr = -ENOBUFS;\r\npn = pneigh_lookup(tbl, net, dst, dev, 1);\r\nif (pn) {\r\npn->flags = ndm->ndm_flags;\r\nerr = 0;\r\n}\r\ngoto out;\r\n}\r\nif (dev == NULL)\r\ngoto out;\r\nneigh = neigh_lookup(tbl, dst, dev);\r\nif (neigh == NULL) {\r\nif (!(nlh->nlmsg_flags & NLM_F_CREATE)) {\r\nerr = -ENOENT;\r\ngoto out;\r\n}\r\nneigh = __neigh_lookup_errno(tbl, dst, dev);\r\nif (IS_ERR(neigh)) {\r\nerr = PTR_ERR(neigh);\r\ngoto out;\r\n}\r\n} else {\r\nif (nlh->nlmsg_flags & NLM_F_EXCL) {\r\nerr = -EEXIST;\r\nneigh_release(neigh);\r\ngoto out;\r\n}\r\nif (!(nlh->nlmsg_flags & NLM_F_REPLACE))\r\nflags &= ~NEIGH_UPDATE_F_OVERRIDE;\r\n}\r\nif (ndm->ndm_flags & NTF_USE) {\r\nneigh_event_send(neigh, NULL);\r\nerr = 0;\r\n} else\r\nerr = neigh_update(neigh, lladdr, ndm->ndm_state, flags);\r\nneigh_release(neigh);\r\ngoto out;\r\n}\r\nread_unlock(&neigh_tbl_lock);\r\nerr = -EAFNOSUPPORT;\r\nout:\r\nreturn err;\r\n}\r\nstatic int neightbl_fill_parms(struct sk_buff *skb, struct neigh_parms *parms)\r\n{\r\nstruct nlattr *nest;\r\nnest = nla_nest_start(skb, NDTA_PARMS);\r\nif (nest == NULL)\r\nreturn -ENOBUFS;\r\nif ((parms->dev &&\r\nnla_put_u32(skb, NDTPA_IFINDEX, parms->dev->ifindex)) ||\r\nnla_put_u32(skb, NDTPA_REFCNT, atomic_read(&parms->refcnt)) ||\r\nnla_put_u32(skb, NDTPA_QUEUE_LENBYTES,\r\nNEIGH_VAR(parms, QUEUE_LEN_BYTES)) ||\r\nnla_put_u32(skb, NDTPA_QUEUE_LEN,\r\nNEIGH_VAR(parms, QUEUE_LEN_BYTES) / SKB_TRUESIZE(ETH_FRAME_LEN)) ||\r\nnla_put_u32(skb, NDTPA_PROXY_QLEN, NEIGH_VAR(parms, PROXY_QLEN)) ||\r\nnla_put_u32(skb, NDTPA_APP_PROBES, NEIGH_VAR(parms, APP_PROBES)) ||\r\nnla_put_u32(skb, NDTPA_UCAST_PROBES,\r\nNEIGH_VAR(parms, UCAST_PROBES)) ||\r\nnla_put_u32(skb, NDTPA_MCAST_PROBES,\r\nNEIGH_VAR(parms, MCAST_PROBES)) ||\r\nnla_put_msecs(skb, NDTPA_REACHABLE_TIME, parms->reachable_time) ||\r\nnla_put_msecs(skb, NDTPA_BASE_REACHABLE_TIME,\r\nNEIGH_VAR(parms, BASE_REACHABLE_TIME)) ||\r\nnla_put_msecs(skb, NDTPA_GC_STALETIME,\r\nNEIGH_VAR(parms, GC_STALETIME)) ||\r\nnla_put_msecs(skb, NDTPA_DELAY_PROBE_TIME,\r\nNEIGH_VAR(parms, DELAY_PROBE_TIME)) ||\r\nnla_put_msecs(skb, NDTPA_RETRANS_TIME,\r\nNEIGH_VAR(parms, RETRANS_TIME)) ||\r\nnla_put_msecs(skb, NDTPA_ANYCAST_DELAY,\r\nNEIGH_VAR(parms, ANYCAST_DELAY)) ||\r\nnla_put_msecs(skb, NDTPA_PROXY_DELAY,\r\nNEIGH_VAR(parms, PROXY_DELAY)) ||\r\nnla_put_msecs(skb, NDTPA_LOCKTIME,\r\nNEIGH_VAR(parms, LOCKTIME)))\r\ngoto nla_put_failure;\r\nreturn nla_nest_end(skb, nest);\r\nnla_put_failure:\r\nnla_nest_cancel(skb, nest);\r\nreturn -EMSGSIZE;\r\n}\r\nstatic int neightbl_fill_info(struct sk_buff *skb, struct neigh_table *tbl,\r\nu32 pid, u32 seq, int type, int flags)\r\n{\r\nstruct nlmsghdr *nlh;\r\nstruct ndtmsg *ndtmsg;\r\nnlh = nlmsg_put(skb, pid, seq, type, sizeof(*ndtmsg), flags);\r\nif (nlh == NULL)\r\nreturn -EMSGSIZE;\r\nndtmsg = nlmsg_data(nlh);\r\nread_lock_bh(&tbl->lock);\r\nndtmsg->ndtm_family = tbl->family;\r\nndtmsg->ndtm_pad1 = 0;\r\nndtmsg->ndtm_pad2 = 0;\r\nif (nla_put_string(skb, NDTA_NAME, tbl->id) ||\r\nnla_put_msecs(skb, NDTA_GC_INTERVAL, tbl->gc_interval) ||\r\nnla_put_u32(skb, NDTA_THRESH1, tbl->gc_thresh1) ||\r\nnla_put_u32(skb, NDTA_THRESH2, tbl->gc_thresh2) ||\r\nnla_put_u32(skb, NDTA_THRESH3, tbl->gc_thresh3))\r\ngoto nla_put_failure;\r\n{\r\nunsigned long now = jiffies;\r\nunsigned int flush_delta = now - tbl->last_flush;\r\nunsigned int rand_delta = now - tbl->last_rand;\r\nstruct neigh_hash_table *nht;\r\nstruct ndt_config ndc = {\r\n.ndtc_key_len = tbl->key_len,\r\n.ndtc_entry_size = tbl->entry_size,\r\n.ndtc_entries = atomic_read(&tbl->entries),\r\n.ndtc_last_flush = jiffies_to_msecs(flush_delta),\r\n.ndtc_last_rand = jiffies_to_msecs(rand_delta),\r\n.ndtc_proxy_qlen = tbl->proxy_queue.qlen,\r\n};\r\nrcu_read_lock_bh();\r\nnht = rcu_dereference_bh(tbl->nht);\r\nndc.ndtc_hash_rnd = nht->hash_rnd[0];\r\nndc.ndtc_hash_mask = ((1 << nht->hash_shift) - 1);\r\nrcu_read_unlock_bh();\r\nif (nla_put(skb, NDTA_CONFIG, sizeof(ndc), &ndc))\r\ngoto nla_put_failure;\r\n}\r\n{\r\nint cpu;\r\nstruct ndt_stats ndst;\r\nmemset(&ndst, 0, sizeof(ndst));\r\nfor_each_possible_cpu(cpu) {\r\nstruct neigh_statistics *st;\r\nst = per_cpu_ptr(tbl->stats, cpu);\r\nndst.ndts_allocs += st->allocs;\r\nndst.ndts_destroys += st->destroys;\r\nndst.ndts_hash_grows += st->hash_grows;\r\nndst.ndts_res_failed += st->res_failed;\r\nndst.ndts_lookups += st->lookups;\r\nndst.ndts_hits += st->hits;\r\nndst.ndts_rcv_probes_mcast += st->rcv_probes_mcast;\r\nndst.ndts_rcv_probes_ucast += st->rcv_probes_ucast;\r\nndst.ndts_periodic_gc_runs += st->periodic_gc_runs;\r\nndst.ndts_forced_gc_runs += st->forced_gc_runs;\r\n}\r\nif (nla_put(skb, NDTA_STATS, sizeof(ndst), &ndst))\r\ngoto nla_put_failure;\r\n}\r\nBUG_ON(tbl->parms.dev);\r\nif (neightbl_fill_parms(skb, &tbl->parms) < 0)\r\ngoto nla_put_failure;\r\nread_unlock_bh(&tbl->lock);\r\nreturn nlmsg_end(skb, nlh);\r\nnla_put_failure:\r\nread_unlock_bh(&tbl->lock);\r\nnlmsg_cancel(skb, nlh);\r\nreturn -EMSGSIZE;\r\n}\r\nstatic int neightbl_fill_param_info(struct sk_buff *skb,\r\nstruct neigh_table *tbl,\r\nstruct neigh_parms *parms,\r\nu32 pid, u32 seq, int type,\r\nunsigned int flags)\r\n{\r\nstruct ndtmsg *ndtmsg;\r\nstruct nlmsghdr *nlh;\r\nnlh = nlmsg_put(skb, pid, seq, type, sizeof(*ndtmsg), flags);\r\nif (nlh == NULL)\r\nreturn -EMSGSIZE;\r\nndtmsg = nlmsg_data(nlh);\r\nread_lock_bh(&tbl->lock);\r\nndtmsg->ndtm_family = tbl->family;\r\nndtmsg->ndtm_pad1 = 0;\r\nndtmsg->ndtm_pad2 = 0;\r\nif (nla_put_string(skb, NDTA_NAME, tbl->id) < 0 ||\r\nneightbl_fill_parms(skb, parms) < 0)\r\ngoto errout;\r\nread_unlock_bh(&tbl->lock);\r\nreturn nlmsg_end(skb, nlh);\r\nerrout:\r\nread_unlock_bh(&tbl->lock);\r\nnlmsg_cancel(skb, nlh);\r\nreturn -EMSGSIZE;\r\n}\r\nstatic int neightbl_set(struct sk_buff *skb, struct nlmsghdr *nlh)\r\n{\r\nstruct net *net = sock_net(skb->sk);\r\nstruct neigh_table *tbl;\r\nstruct ndtmsg *ndtmsg;\r\nstruct nlattr *tb[NDTA_MAX+1];\r\nint err;\r\nerr = nlmsg_parse(nlh, sizeof(*ndtmsg), tb, NDTA_MAX,\r\nnl_neightbl_policy);\r\nif (err < 0)\r\ngoto errout;\r\nif (tb[NDTA_NAME] == NULL) {\r\nerr = -EINVAL;\r\ngoto errout;\r\n}\r\nndtmsg = nlmsg_data(nlh);\r\nread_lock(&neigh_tbl_lock);\r\nfor (tbl = neigh_tables; tbl; tbl = tbl->next) {\r\nif (ndtmsg->ndtm_family && tbl->family != ndtmsg->ndtm_family)\r\ncontinue;\r\nif (nla_strcmp(tb[NDTA_NAME], tbl->id) == 0)\r\nbreak;\r\n}\r\nif (tbl == NULL) {\r\nerr = -ENOENT;\r\ngoto errout_locked;\r\n}\r\nwrite_lock_bh(&tbl->lock);\r\nif (tb[NDTA_PARMS]) {\r\nstruct nlattr *tbp[NDTPA_MAX+1];\r\nstruct neigh_parms *p;\r\nint i, ifindex = 0;\r\nerr = nla_parse_nested(tbp, NDTPA_MAX, tb[NDTA_PARMS],\r\nnl_ntbl_parm_policy);\r\nif (err < 0)\r\ngoto errout_tbl_lock;\r\nif (tbp[NDTPA_IFINDEX])\r\nifindex = nla_get_u32(tbp[NDTPA_IFINDEX]);\r\np = lookup_neigh_parms(tbl, net, ifindex);\r\nif (p == NULL) {\r\nerr = -ENOENT;\r\ngoto errout_tbl_lock;\r\n}\r\nfor (i = 1; i <= NDTPA_MAX; i++) {\r\nif (tbp[i] == NULL)\r\ncontinue;\r\nswitch (i) {\r\ncase NDTPA_QUEUE_LEN:\r\nNEIGH_VAR_SET(p, QUEUE_LEN_BYTES,\r\nnla_get_u32(tbp[i]) *\r\nSKB_TRUESIZE(ETH_FRAME_LEN));\r\nbreak;\r\ncase NDTPA_QUEUE_LENBYTES:\r\nNEIGH_VAR_SET(p, QUEUE_LEN_BYTES,\r\nnla_get_u32(tbp[i]));\r\nbreak;\r\ncase NDTPA_PROXY_QLEN:\r\nNEIGH_VAR_SET(p, PROXY_QLEN,\r\nnla_get_u32(tbp[i]));\r\nbreak;\r\ncase NDTPA_APP_PROBES:\r\nNEIGH_VAR_SET(p, APP_PROBES,\r\nnla_get_u32(tbp[i]));\r\nbreak;\r\ncase NDTPA_UCAST_PROBES:\r\nNEIGH_VAR_SET(p, UCAST_PROBES,\r\nnla_get_u32(tbp[i]));\r\nbreak;\r\ncase NDTPA_MCAST_PROBES:\r\nNEIGH_VAR_SET(p, MCAST_PROBES,\r\nnla_get_u32(tbp[i]));\r\nbreak;\r\ncase NDTPA_BASE_REACHABLE_TIME:\r\nNEIGH_VAR_SET(p, BASE_REACHABLE_TIME,\r\nnla_get_msecs(tbp[i]));\r\nbreak;\r\ncase NDTPA_GC_STALETIME:\r\nNEIGH_VAR_SET(p, GC_STALETIME,\r\nnla_get_msecs(tbp[i]));\r\nbreak;\r\ncase NDTPA_DELAY_PROBE_TIME:\r\nNEIGH_VAR_SET(p, DELAY_PROBE_TIME,\r\nnla_get_msecs(tbp[i]));\r\nbreak;\r\ncase NDTPA_RETRANS_TIME:\r\nNEIGH_VAR_SET(p, RETRANS_TIME,\r\nnla_get_msecs(tbp[i]));\r\nbreak;\r\ncase NDTPA_ANYCAST_DELAY:\r\nNEIGH_VAR_SET(p, ANYCAST_DELAY,\r\nnla_get_msecs(tbp[i]));\r\nbreak;\r\ncase NDTPA_PROXY_DELAY:\r\nNEIGH_VAR_SET(p, PROXY_DELAY,\r\nnla_get_msecs(tbp[i]));\r\nbreak;\r\ncase NDTPA_LOCKTIME:\r\nNEIGH_VAR_SET(p, LOCKTIME,\r\nnla_get_msecs(tbp[i]));\r\nbreak;\r\n}\r\n}\r\n}\r\nerr = -ENOENT;\r\nif ((tb[NDTA_THRESH1] || tb[NDTA_THRESH2] ||\r\ntb[NDTA_THRESH3] || tb[NDTA_GC_INTERVAL]) &&\r\n!net_eq(net, &init_net))\r\ngoto errout_tbl_lock;\r\nif (tb[NDTA_THRESH1])\r\ntbl->gc_thresh1 = nla_get_u32(tb[NDTA_THRESH1]);\r\nif (tb[NDTA_THRESH2])\r\ntbl->gc_thresh2 = nla_get_u32(tb[NDTA_THRESH2]);\r\nif (tb[NDTA_THRESH3])\r\ntbl->gc_thresh3 = nla_get_u32(tb[NDTA_THRESH3]);\r\nif (tb[NDTA_GC_INTERVAL])\r\ntbl->gc_interval = nla_get_msecs(tb[NDTA_GC_INTERVAL]);\r\nerr = 0;\r\nerrout_tbl_lock:\r\nwrite_unlock_bh(&tbl->lock);\r\nerrout_locked:\r\nread_unlock(&neigh_tbl_lock);\r\nerrout:\r\nreturn err;\r\n}\r\nstatic int neightbl_dump_info(struct sk_buff *skb, struct netlink_callback *cb)\r\n{\r\nstruct net *net = sock_net(skb->sk);\r\nint family, tidx, nidx = 0;\r\nint tbl_skip = cb->args[0];\r\nint neigh_skip = cb->args[1];\r\nstruct neigh_table *tbl;\r\nfamily = ((struct rtgenmsg *) nlmsg_data(cb->nlh))->rtgen_family;\r\nread_lock(&neigh_tbl_lock);\r\nfor (tbl = neigh_tables, tidx = 0; tbl; tbl = tbl->next, tidx++) {\r\nstruct neigh_parms *p;\r\nif (tidx < tbl_skip || (family && tbl->family != family))\r\ncontinue;\r\nif (neightbl_fill_info(skb, tbl, NETLINK_CB(cb->skb).portid,\r\ncb->nlh->nlmsg_seq, RTM_NEWNEIGHTBL,\r\nNLM_F_MULTI) <= 0)\r\nbreak;\r\nfor (nidx = 0, p = tbl->parms.next; p; p = p->next) {\r\nif (!net_eq(neigh_parms_net(p), net))\r\ncontinue;\r\nif (nidx < neigh_skip)\r\ngoto next;\r\nif (neightbl_fill_param_info(skb, tbl, p,\r\nNETLINK_CB(cb->skb).portid,\r\ncb->nlh->nlmsg_seq,\r\nRTM_NEWNEIGHTBL,\r\nNLM_F_MULTI) <= 0)\r\ngoto out;\r\nnext:\r\nnidx++;\r\n}\r\nneigh_skip = 0;\r\n}\r\nout:\r\nread_unlock(&neigh_tbl_lock);\r\ncb->args[0] = tidx;\r\ncb->args[1] = nidx;\r\nreturn skb->len;\r\n}\r\nstatic int neigh_fill_info(struct sk_buff *skb, struct neighbour *neigh,\r\nu32 pid, u32 seq, int type, unsigned int flags)\r\n{\r\nunsigned long now = jiffies;\r\nstruct nda_cacheinfo ci;\r\nstruct nlmsghdr *nlh;\r\nstruct ndmsg *ndm;\r\nnlh = nlmsg_put(skb, pid, seq, type, sizeof(*ndm), flags);\r\nif (nlh == NULL)\r\nreturn -EMSGSIZE;\r\nndm = nlmsg_data(nlh);\r\nndm->ndm_family = neigh->ops->family;\r\nndm->ndm_pad1 = 0;\r\nndm->ndm_pad2 = 0;\r\nndm->ndm_flags = neigh->flags;\r\nndm->ndm_type = neigh->type;\r\nndm->ndm_ifindex = neigh->dev->ifindex;\r\nif (nla_put(skb, NDA_DST, neigh->tbl->key_len, neigh->primary_key))\r\ngoto nla_put_failure;\r\nread_lock_bh(&neigh->lock);\r\nndm->ndm_state = neigh->nud_state;\r\nif (neigh->nud_state & NUD_VALID) {\r\nchar haddr[MAX_ADDR_LEN];\r\nneigh_ha_snapshot(haddr, neigh, neigh->dev);\r\nif (nla_put(skb, NDA_LLADDR, neigh->dev->addr_len, haddr) < 0) {\r\nread_unlock_bh(&neigh->lock);\r\ngoto nla_put_failure;\r\n}\r\n}\r\nci.ndm_used = jiffies_to_clock_t(now - neigh->used);\r\nci.ndm_confirmed = jiffies_to_clock_t(now - neigh->confirmed);\r\nci.ndm_updated = jiffies_to_clock_t(now - neigh->updated);\r\nci.ndm_refcnt = atomic_read(&neigh->refcnt) - 1;\r\nread_unlock_bh(&neigh->lock);\r\nif (nla_put_u32(skb, NDA_PROBES, atomic_read(&neigh->probes)) ||\r\nnla_put(skb, NDA_CACHEINFO, sizeof(ci), &ci))\r\ngoto nla_put_failure;\r\nreturn nlmsg_end(skb, nlh);\r\nnla_put_failure:\r\nnlmsg_cancel(skb, nlh);\r\nreturn -EMSGSIZE;\r\n}\r\nstatic int pneigh_fill_info(struct sk_buff *skb, struct pneigh_entry *pn,\r\nu32 pid, u32 seq, int type, unsigned int flags,\r\nstruct neigh_table *tbl)\r\n{\r\nstruct nlmsghdr *nlh;\r\nstruct ndmsg *ndm;\r\nnlh = nlmsg_put(skb, pid, seq, type, sizeof(*ndm), flags);\r\nif (nlh == NULL)\r\nreturn -EMSGSIZE;\r\nndm = nlmsg_data(nlh);\r\nndm->ndm_family = tbl->family;\r\nndm->ndm_pad1 = 0;\r\nndm->ndm_pad2 = 0;\r\nndm->ndm_flags = pn->flags | NTF_PROXY;\r\nndm->ndm_type = RTN_UNICAST;\r\nndm->ndm_ifindex = pn->dev->ifindex;\r\nndm->ndm_state = NUD_NONE;\r\nif (nla_put(skb, NDA_DST, tbl->key_len, pn->key))\r\ngoto nla_put_failure;\r\nreturn nlmsg_end(skb, nlh);\r\nnla_put_failure:\r\nnlmsg_cancel(skb, nlh);\r\nreturn -EMSGSIZE;\r\n}\r\nstatic void neigh_update_notify(struct neighbour *neigh)\r\n{\r\ncall_netevent_notifiers(NETEVENT_NEIGH_UPDATE, neigh);\r\n__neigh_notify(neigh, RTM_NEWNEIGH, 0);\r\n}\r\nstatic int neigh_dump_table(struct neigh_table *tbl, struct sk_buff *skb,\r\nstruct netlink_callback *cb)\r\n{\r\nstruct net *net = sock_net(skb->sk);\r\nstruct neighbour *n;\r\nint rc, h, s_h = cb->args[1];\r\nint idx, s_idx = idx = cb->args[2];\r\nstruct neigh_hash_table *nht;\r\nrcu_read_lock_bh();\r\nnht = rcu_dereference_bh(tbl->nht);\r\nfor (h = s_h; h < (1 << nht->hash_shift); h++) {\r\nif (h > s_h)\r\ns_idx = 0;\r\nfor (n = rcu_dereference_bh(nht->hash_buckets[h]), idx = 0;\r\nn != NULL;\r\nn = rcu_dereference_bh(n->next)) {\r\nif (!net_eq(dev_net(n->dev), net))\r\ncontinue;\r\nif (idx < s_idx)\r\ngoto next;\r\nif (neigh_fill_info(skb, n, NETLINK_CB(cb->skb).portid,\r\ncb->nlh->nlmsg_seq,\r\nRTM_NEWNEIGH,\r\nNLM_F_MULTI) <= 0) {\r\nrc = -1;\r\ngoto out;\r\n}\r\nnext:\r\nidx++;\r\n}\r\n}\r\nrc = skb->len;\r\nout:\r\nrcu_read_unlock_bh();\r\ncb->args[1] = h;\r\ncb->args[2] = idx;\r\nreturn rc;\r\n}\r\nstatic int pneigh_dump_table(struct neigh_table *tbl, struct sk_buff *skb,\r\nstruct netlink_callback *cb)\r\n{\r\nstruct pneigh_entry *n;\r\nstruct net *net = sock_net(skb->sk);\r\nint rc, h, s_h = cb->args[3];\r\nint idx, s_idx = idx = cb->args[4];\r\nread_lock_bh(&tbl->lock);\r\nfor (h = s_h; h <= PNEIGH_HASHMASK; h++) {\r\nif (h > s_h)\r\ns_idx = 0;\r\nfor (n = tbl->phash_buckets[h], idx = 0; n; n = n->next) {\r\nif (dev_net(n->dev) != net)\r\ncontinue;\r\nif (idx < s_idx)\r\ngoto next;\r\nif (pneigh_fill_info(skb, n, NETLINK_CB(cb->skb).portid,\r\ncb->nlh->nlmsg_seq,\r\nRTM_NEWNEIGH,\r\nNLM_F_MULTI, tbl) <= 0) {\r\nread_unlock_bh(&tbl->lock);\r\nrc = -1;\r\ngoto out;\r\n}\r\nnext:\r\nidx++;\r\n}\r\n}\r\nread_unlock_bh(&tbl->lock);\r\nrc = skb->len;\r\nout:\r\ncb->args[3] = h;\r\ncb->args[4] = idx;\r\nreturn rc;\r\n}\r\nstatic int neigh_dump_info(struct sk_buff *skb, struct netlink_callback *cb)\r\n{\r\nstruct neigh_table *tbl;\r\nint t, family, s_t;\r\nint proxy = 0;\r\nint err;\r\nread_lock(&neigh_tbl_lock);\r\nfamily = ((struct rtgenmsg *) nlmsg_data(cb->nlh))->rtgen_family;\r\nif (nlmsg_len(cb->nlh) >= sizeof(struct ndmsg) &&\r\n((struct ndmsg *) nlmsg_data(cb->nlh))->ndm_flags == NTF_PROXY)\r\nproxy = 1;\r\ns_t = cb->args[0];\r\nfor (tbl = neigh_tables, t = 0; tbl;\r\ntbl = tbl->next, t++) {\r\nif (t < s_t || (family && tbl->family != family))\r\ncontinue;\r\nif (t > s_t)\r\nmemset(&cb->args[1], 0, sizeof(cb->args) -\r\nsizeof(cb->args[0]));\r\nif (proxy)\r\nerr = pneigh_dump_table(tbl, skb, cb);\r\nelse\r\nerr = neigh_dump_table(tbl, skb, cb);\r\nif (err < 0)\r\nbreak;\r\n}\r\nread_unlock(&neigh_tbl_lock);\r\ncb->args[0] = t;\r\nreturn skb->len;\r\n}\r\nvoid neigh_for_each(struct neigh_table *tbl, void (*cb)(struct neighbour *, void *), void *cookie)\r\n{\r\nint chain;\r\nstruct neigh_hash_table *nht;\r\nrcu_read_lock_bh();\r\nnht = rcu_dereference_bh(tbl->nht);\r\nread_lock(&tbl->lock);\r\nfor (chain = 0; chain < (1 << nht->hash_shift); chain++) {\r\nstruct neighbour *n;\r\nfor (n = rcu_dereference_bh(nht->hash_buckets[chain]);\r\nn != NULL;\r\nn = rcu_dereference_bh(n->next))\r\ncb(n, cookie);\r\n}\r\nread_unlock(&tbl->lock);\r\nrcu_read_unlock_bh();\r\n}\r\nvoid __neigh_for_each_release(struct neigh_table *tbl,\r\nint (*cb)(struct neighbour *))\r\n{\r\nint chain;\r\nstruct neigh_hash_table *nht;\r\nnht = rcu_dereference_protected(tbl->nht,\r\nlockdep_is_held(&tbl->lock));\r\nfor (chain = 0; chain < (1 << nht->hash_shift); chain++) {\r\nstruct neighbour *n;\r\nstruct neighbour __rcu **np;\r\nnp = &nht->hash_buckets[chain];\r\nwhile ((n = rcu_dereference_protected(*np,\r\nlockdep_is_held(&tbl->lock))) != NULL) {\r\nint release;\r\nwrite_lock(&n->lock);\r\nrelease = cb(n);\r\nif (release) {\r\nrcu_assign_pointer(*np,\r\nrcu_dereference_protected(n->next,\r\nlockdep_is_held(&tbl->lock)));\r\nn->dead = 1;\r\n} else\r\nnp = &n->next;\r\nwrite_unlock(&n->lock);\r\nif (release)\r\nneigh_cleanup_and_release(n);\r\n}\r\n}\r\n}\r\nstatic struct neighbour *neigh_get_first(struct seq_file *seq)\r\n{\r\nstruct neigh_seq_state *state = seq->private;\r\nstruct net *net = seq_file_net(seq);\r\nstruct neigh_hash_table *nht = state->nht;\r\nstruct neighbour *n = NULL;\r\nint bucket = state->bucket;\r\nstate->flags &= ~NEIGH_SEQ_IS_PNEIGH;\r\nfor (bucket = 0; bucket < (1 << nht->hash_shift); bucket++) {\r\nn = rcu_dereference_bh(nht->hash_buckets[bucket]);\r\nwhile (n) {\r\nif (!net_eq(dev_net(n->dev), net))\r\ngoto next;\r\nif (state->neigh_sub_iter) {\r\nloff_t fakep = 0;\r\nvoid *v;\r\nv = state->neigh_sub_iter(state, n, &fakep);\r\nif (!v)\r\ngoto next;\r\n}\r\nif (!(state->flags & NEIGH_SEQ_SKIP_NOARP))\r\nbreak;\r\nif (n->nud_state & ~NUD_NOARP)\r\nbreak;\r\nnext:\r\nn = rcu_dereference_bh(n->next);\r\n}\r\nif (n)\r\nbreak;\r\n}\r\nstate->bucket = bucket;\r\nreturn n;\r\n}\r\nstatic struct neighbour *neigh_get_next(struct seq_file *seq,\r\nstruct neighbour *n,\r\nloff_t *pos)\r\n{\r\nstruct neigh_seq_state *state = seq->private;\r\nstruct net *net = seq_file_net(seq);\r\nstruct neigh_hash_table *nht = state->nht;\r\nif (state->neigh_sub_iter) {\r\nvoid *v = state->neigh_sub_iter(state, n, pos);\r\nif (v)\r\nreturn n;\r\n}\r\nn = rcu_dereference_bh(n->next);\r\nwhile (1) {\r\nwhile (n) {\r\nif (!net_eq(dev_net(n->dev), net))\r\ngoto next;\r\nif (state->neigh_sub_iter) {\r\nvoid *v = state->neigh_sub_iter(state, n, pos);\r\nif (v)\r\nreturn n;\r\ngoto next;\r\n}\r\nif (!(state->flags & NEIGH_SEQ_SKIP_NOARP))\r\nbreak;\r\nif (n->nud_state & ~NUD_NOARP)\r\nbreak;\r\nnext:\r\nn = rcu_dereference_bh(n->next);\r\n}\r\nif (n)\r\nbreak;\r\nif (++state->bucket >= (1 << nht->hash_shift))\r\nbreak;\r\nn = rcu_dereference_bh(nht->hash_buckets[state->bucket]);\r\n}\r\nif (n && pos)\r\n--(*pos);\r\nreturn n;\r\n}\r\nstatic struct neighbour *neigh_get_idx(struct seq_file *seq, loff_t *pos)\r\n{\r\nstruct neighbour *n = neigh_get_first(seq);\r\nif (n) {\r\n--(*pos);\r\nwhile (*pos) {\r\nn = neigh_get_next(seq, n, pos);\r\nif (!n)\r\nbreak;\r\n}\r\n}\r\nreturn *pos ? NULL : n;\r\n}\r\nstatic struct pneigh_entry *pneigh_get_first(struct seq_file *seq)\r\n{\r\nstruct neigh_seq_state *state = seq->private;\r\nstruct net *net = seq_file_net(seq);\r\nstruct neigh_table *tbl = state->tbl;\r\nstruct pneigh_entry *pn = NULL;\r\nint bucket = state->bucket;\r\nstate->flags |= NEIGH_SEQ_IS_PNEIGH;\r\nfor (bucket = 0; bucket <= PNEIGH_HASHMASK; bucket++) {\r\npn = tbl->phash_buckets[bucket];\r\nwhile (pn && !net_eq(pneigh_net(pn), net))\r\npn = pn->next;\r\nif (pn)\r\nbreak;\r\n}\r\nstate->bucket = bucket;\r\nreturn pn;\r\n}\r\nstatic struct pneigh_entry *pneigh_get_next(struct seq_file *seq,\r\nstruct pneigh_entry *pn,\r\nloff_t *pos)\r\n{\r\nstruct neigh_seq_state *state = seq->private;\r\nstruct net *net = seq_file_net(seq);\r\nstruct neigh_table *tbl = state->tbl;\r\ndo {\r\npn = pn->next;\r\n} while (pn && !net_eq(pneigh_net(pn), net));\r\nwhile (!pn) {\r\nif (++state->bucket > PNEIGH_HASHMASK)\r\nbreak;\r\npn = tbl->phash_buckets[state->bucket];\r\nwhile (pn && !net_eq(pneigh_net(pn), net))\r\npn = pn->next;\r\nif (pn)\r\nbreak;\r\n}\r\nif (pn && pos)\r\n--(*pos);\r\nreturn pn;\r\n}\r\nstatic struct pneigh_entry *pneigh_get_idx(struct seq_file *seq, loff_t *pos)\r\n{\r\nstruct pneigh_entry *pn = pneigh_get_first(seq);\r\nif (pn) {\r\n--(*pos);\r\nwhile (*pos) {\r\npn = pneigh_get_next(seq, pn, pos);\r\nif (!pn)\r\nbreak;\r\n}\r\n}\r\nreturn *pos ? NULL : pn;\r\n}\r\nstatic void *neigh_get_idx_any(struct seq_file *seq, loff_t *pos)\r\n{\r\nstruct neigh_seq_state *state = seq->private;\r\nvoid *rc;\r\nloff_t idxpos = *pos;\r\nrc = neigh_get_idx(seq, &idxpos);\r\nif (!rc && !(state->flags & NEIGH_SEQ_NEIGH_ONLY))\r\nrc = pneigh_get_idx(seq, &idxpos);\r\nreturn rc;\r\n}\r\nvoid *neigh_seq_start(struct seq_file *seq, loff_t *pos, struct neigh_table *tbl, unsigned int neigh_seq_flags)\r\n__acquires(rcu_bh)\r\n{\r\nstruct neigh_seq_state *state = seq->private;\r\nstate->tbl = tbl;\r\nstate->bucket = 0;\r\nstate->flags = (neigh_seq_flags & ~NEIGH_SEQ_IS_PNEIGH);\r\nrcu_read_lock_bh();\r\nstate->nht = rcu_dereference_bh(tbl->nht);\r\nreturn *pos ? neigh_get_idx_any(seq, pos) : SEQ_START_TOKEN;\r\n}\r\nvoid *neigh_seq_next(struct seq_file *seq, void *v, loff_t *pos)\r\n{\r\nstruct neigh_seq_state *state;\r\nvoid *rc;\r\nif (v == SEQ_START_TOKEN) {\r\nrc = neigh_get_first(seq);\r\ngoto out;\r\n}\r\nstate = seq->private;\r\nif (!(state->flags & NEIGH_SEQ_IS_PNEIGH)) {\r\nrc = neigh_get_next(seq, v, NULL);\r\nif (rc)\r\ngoto out;\r\nif (!(state->flags & NEIGH_SEQ_NEIGH_ONLY))\r\nrc = pneigh_get_first(seq);\r\n} else {\r\nBUG_ON(state->flags & NEIGH_SEQ_NEIGH_ONLY);\r\nrc = pneigh_get_next(seq, v, NULL);\r\n}\r\nout:\r\n++(*pos);\r\nreturn rc;\r\n}\r\nvoid neigh_seq_stop(struct seq_file *seq, void *v)\r\n__releases(rcu_bh)\r\n{\r\nrcu_read_unlock_bh();\r\n}\r\nstatic void *neigh_stat_seq_start(struct seq_file *seq, loff_t *pos)\r\n{\r\nstruct neigh_table *tbl = seq->private;\r\nint cpu;\r\nif (*pos == 0)\r\nreturn SEQ_START_TOKEN;\r\nfor (cpu = *pos-1; cpu < nr_cpu_ids; ++cpu) {\r\nif (!cpu_possible(cpu))\r\ncontinue;\r\n*pos = cpu+1;\r\nreturn per_cpu_ptr(tbl->stats, cpu);\r\n}\r\nreturn NULL;\r\n}\r\nstatic void *neigh_stat_seq_next(struct seq_file *seq, void *v, loff_t *pos)\r\n{\r\nstruct neigh_table *tbl = seq->private;\r\nint cpu;\r\nfor (cpu = *pos; cpu < nr_cpu_ids; ++cpu) {\r\nif (!cpu_possible(cpu))\r\ncontinue;\r\n*pos = cpu+1;\r\nreturn per_cpu_ptr(tbl->stats, cpu);\r\n}\r\nreturn NULL;\r\n}\r\nstatic void neigh_stat_seq_stop(struct seq_file *seq, void *v)\r\n{\r\n}\r\nstatic int neigh_stat_seq_show(struct seq_file *seq, void *v)\r\n{\r\nstruct neigh_table *tbl = seq->private;\r\nstruct neigh_statistics *st = v;\r\nif (v == SEQ_START_TOKEN) {\r\nseq_printf(seq, "entries allocs destroys hash_grows lookups hits res_failed rcv_probes_mcast rcv_probes_ucast periodic_gc_runs forced_gc_runs unresolved_discards\n");\r\nreturn 0;\r\n}\r\nseq_printf(seq, "%08x %08lx %08lx %08lx %08lx %08lx %08lx "\r\n"%08lx %08lx %08lx %08lx %08lx\n",\r\natomic_read(&tbl->entries),\r\nst->allocs,\r\nst->destroys,\r\nst->hash_grows,\r\nst->lookups,\r\nst->hits,\r\nst->res_failed,\r\nst->rcv_probes_mcast,\r\nst->rcv_probes_ucast,\r\nst->periodic_gc_runs,\r\nst->forced_gc_runs,\r\nst->unres_discards\r\n);\r\nreturn 0;\r\n}\r\nstatic int neigh_stat_seq_open(struct inode *inode, struct file *file)\r\n{\r\nint ret = seq_open(file, &neigh_stat_seq_ops);\r\nif (!ret) {\r\nstruct seq_file *sf = file->private_data;\r\nsf->private = PDE_DATA(inode);\r\n}\r\nreturn ret;\r\n}\r\nstatic inline size_t neigh_nlmsg_size(void)\r\n{\r\nreturn NLMSG_ALIGN(sizeof(struct ndmsg))\r\n+ nla_total_size(MAX_ADDR_LEN)\r\n+ nla_total_size(MAX_ADDR_LEN)\r\n+ nla_total_size(sizeof(struct nda_cacheinfo))\r\n+ nla_total_size(4);\r\n}\r\nstatic void __neigh_notify(struct neighbour *n, int type, int flags)\r\n{\r\nstruct net *net = dev_net(n->dev);\r\nstruct sk_buff *skb;\r\nint err = -ENOBUFS;\r\nskb = nlmsg_new(neigh_nlmsg_size(), GFP_ATOMIC);\r\nif (skb == NULL)\r\ngoto errout;\r\nerr = neigh_fill_info(skb, n, 0, 0, type, flags);\r\nif (err < 0) {\r\nWARN_ON(err == -EMSGSIZE);\r\nkfree_skb(skb);\r\ngoto errout;\r\n}\r\nrtnl_notify(skb, net, 0, RTNLGRP_NEIGH, NULL, GFP_ATOMIC);\r\nreturn;\r\nerrout:\r\nif (err < 0)\r\nrtnl_set_sk_err(net, RTNLGRP_NEIGH, err);\r\n}\r\nvoid neigh_app_ns(struct neighbour *n)\r\n{\r\n__neigh_notify(n, RTM_GETNEIGH, NLM_F_REQUEST);\r\n}\r\nstatic int proc_unres_qlen(struct ctl_table *ctl, int write,\r\nvoid __user *buffer, size_t *lenp, loff_t *ppos)\r\n{\r\nint size, ret;\r\nstruct ctl_table tmp = *ctl;\r\ntmp.extra1 = &zero;\r\ntmp.extra2 = &unres_qlen_max;\r\ntmp.data = &size;\r\nsize = *(int *)ctl->data / SKB_TRUESIZE(ETH_FRAME_LEN);\r\nret = proc_dointvec_minmax(&tmp, write, buffer, lenp, ppos);\r\nif (write && !ret)\r\n*(int *)ctl->data = size * SKB_TRUESIZE(ETH_FRAME_LEN);\r\nreturn ret;\r\n}\r\nstatic struct neigh_parms *neigh_get_dev_parms_rcu(struct net_device *dev,\r\nint family)\r\n{\r\nswitch (family) {\r\ncase AF_INET:\r\nreturn __in_dev_arp_parms_get_rcu(dev);\r\ncase AF_INET6:\r\nreturn __in6_dev_nd_parms_get_rcu(dev);\r\n}\r\nreturn NULL;\r\n}\r\nstatic void neigh_copy_dflt_parms(struct net *net, struct neigh_parms *p,\r\nint index)\r\n{\r\nstruct net_device *dev;\r\nint family = neigh_parms_family(p);\r\nrcu_read_lock();\r\nfor_each_netdev_rcu(net, dev) {\r\nstruct neigh_parms *dst_p =\r\nneigh_get_dev_parms_rcu(dev, family);\r\nif (dst_p && !test_bit(index, dst_p->data_state))\r\ndst_p->data[index] = p->data[index];\r\n}\r\nrcu_read_unlock();\r\n}\r\nstatic void neigh_proc_update(struct ctl_table *ctl, int write)\r\n{\r\nstruct net_device *dev = ctl->extra1;\r\nstruct neigh_parms *p = ctl->extra2;\r\nstruct net *net = neigh_parms_net(p);\r\nint index = (int *) ctl->data - p->data;\r\nif (!write)\r\nreturn;\r\nset_bit(index, p->data_state);\r\nif (!dev)\r\nneigh_copy_dflt_parms(net, p, index);\r\n}\r\nstatic int neigh_proc_dointvec_zero_intmax(struct ctl_table *ctl, int write,\r\nvoid __user *buffer,\r\nsize_t *lenp, loff_t *ppos)\r\n{\r\nstruct ctl_table tmp = *ctl;\r\nint ret;\r\ntmp.extra1 = &zero;\r\ntmp.extra2 = &int_max;\r\nret = proc_dointvec_minmax(&tmp, write, buffer, lenp, ppos);\r\nneigh_proc_update(ctl, write);\r\nreturn ret;\r\n}\r\nint neigh_proc_dointvec(struct ctl_table *ctl, int write,\r\nvoid __user *buffer, size_t *lenp, loff_t *ppos)\r\n{\r\nint ret = proc_dointvec(ctl, write, buffer, lenp, ppos);\r\nneigh_proc_update(ctl, write);\r\nreturn ret;\r\n}\r\nint neigh_proc_dointvec_jiffies(struct ctl_table *ctl, int write,\r\nvoid __user *buffer,\r\nsize_t *lenp, loff_t *ppos)\r\n{\r\nint ret = proc_dointvec_jiffies(ctl, write, buffer, lenp, ppos);\r\nneigh_proc_update(ctl, write);\r\nreturn ret;\r\n}\r\nstatic int neigh_proc_dointvec_userhz_jiffies(struct ctl_table *ctl, int write,\r\nvoid __user *buffer,\r\nsize_t *lenp, loff_t *ppos)\r\n{\r\nint ret = proc_dointvec_userhz_jiffies(ctl, write, buffer, lenp, ppos);\r\nneigh_proc_update(ctl, write);\r\nreturn ret;\r\n}\r\nint neigh_proc_dointvec_ms_jiffies(struct ctl_table *ctl, int write,\r\nvoid __user *buffer,\r\nsize_t *lenp, loff_t *ppos)\r\n{\r\nint ret = proc_dointvec_ms_jiffies(ctl, write, buffer, lenp, ppos);\r\nneigh_proc_update(ctl, write);\r\nreturn ret;\r\n}\r\nstatic int neigh_proc_dointvec_unres_qlen(struct ctl_table *ctl, int write,\r\nvoid __user *buffer,\r\nsize_t *lenp, loff_t *ppos)\r\n{\r\nint ret = proc_unres_qlen(ctl, write, buffer, lenp, ppos);\r\nneigh_proc_update(ctl, write);\r\nreturn ret;\r\n}\r\nint neigh_sysctl_register(struct net_device *dev, struct neigh_parms *p,\r\nproc_handler *handler)\r\n{\r\nint i;\r\nstruct neigh_sysctl_table *t;\r\nconst char *dev_name_source;\r\nchar neigh_path[ sizeof("net//neigh/") + IFNAMSIZ + IFNAMSIZ ];\r\nchar *p_name;\r\nt = kmemdup(&neigh_sysctl_template, sizeof(*t), GFP_KERNEL);\r\nif (!t)\r\ngoto err;\r\nfor (i = 0; i < NEIGH_VAR_GC_INTERVAL; i++) {\r\nt->neigh_vars[i].data += (long) p;\r\nt->neigh_vars[i].extra1 = dev;\r\nt->neigh_vars[i].extra2 = p;\r\n}\r\nif (dev) {\r\ndev_name_source = dev->name;\r\nmemset(&t->neigh_vars[NEIGH_VAR_GC_INTERVAL], 0,\r\nsizeof(t->neigh_vars[NEIGH_VAR_GC_INTERVAL]));\r\n} else {\r\nstruct neigh_table *tbl = p->tbl;\r\ndev_name_source = "default";\r\nt->neigh_vars[NEIGH_VAR_GC_INTERVAL].data = &tbl->gc_interval;\r\nt->neigh_vars[NEIGH_VAR_GC_THRESH1].data = &tbl->gc_thresh1;\r\nt->neigh_vars[NEIGH_VAR_GC_THRESH2].data = &tbl->gc_thresh2;\r\nt->neigh_vars[NEIGH_VAR_GC_THRESH3].data = &tbl->gc_thresh3;\r\n}\r\nif (handler) {\r\nt->neigh_vars[NEIGH_VAR_RETRANS_TIME].proc_handler = handler;\r\nt->neigh_vars[NEIGH_VAR_BASE_REACHABLE_TIME].proc_handler = handler;\r\nt->neigh_vars[NEIGH_VAR_RETRANS_TIME_MS].proc_handler = handler;\r\nt->neigh_vars[NEIGH_VAR_BASE_REACHABLE_TIME_MS].proc_handler = handler;\r\n}\r\nif (neigh_parms_net(p)->user_ns != &init_user_ns)\r\nt->neigh_vars[0].procname = NULL;\r\nswitch (neigh_parms_family(p)) {\r\ncase AF_INET:\r\np_name = "ipv4";\r\nbreak;\r\ncase AF_INET6:\r\np_name = "ipv6";\r\nbreak;\r\ndefault:\r\nBUG();\r\n}\r\nsnprintf(neigh_path, sizeof(neigh_path), "net/%s/neigh/%s",\r\np_name, dev_name_source);\r\nt->sysctl_header =\r\nregister_net_sysctl(neigh_parms_net(p), neigh_path, t->neigh_vars);\r\nif (!t->sysctl_header)\r\ngoto free;\r\np->sysctl_table = t;\r\nreturn 0;\r\nfree:\r\nkfree(t);\r\nerr:\r\nreturn -ENOBUFS;\r\n}\r\nvoid neigh_sysctl_unregister(struct neigh_parms *p)\r\n{\r\nif (p->sysctl_table) {\r\nstruct neigh_sysctl_table *t = p->sysctl_table;\r\np->sysctl_table = NULL;\r\nunregister_net_sysctl_table(t->sysctl_header);\r\nkfree(t);\r\n}\r\n}\r\nstatic int __init neigh_init(void)\r\n{\r\nrtnl_register(PF_UNSPEC, RTM_NEWNEIGH, neigh_add, NULL, NULL);\r\nrtnl_register(PF_UNSPEC, RTM_DELNEIGH, neigh_delete, NULL, NULL);\r\nrtnl_register(PF_UNSPEC, RTM_GETNEIGH, NULL, neigh_dump_info, NULL);\r\nrtnl_register(PF_UNSPEC, RTM_GETNEIGHTBL, NULL, neightbl_dump_info,\r\nNULL);\r\nrtnl_register(PF_UNSPEC, RTM_SETNEIGHTBL, neightbl_set, NULL, NULL);\r\nreturn 0;\r\n}
