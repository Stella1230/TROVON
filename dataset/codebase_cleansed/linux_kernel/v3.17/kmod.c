static void free_modprobe_argv(struct subprocess_info *info)\r\n{\r\nkfree(info->argv[3]);\r\nkfree(info->argv);\r\n}\r\nstatic int call_modprobe(char *module_name, int wait)\r\n{\r\nstruct subprocess_info *info;\r\nstatic char *envp[] = {\r\n"HOME=/",\r\n"TERM=linux",\r\n"PATH=/sbin:/usr/sbin:/bin:/usr/bin",\r\nNULL\r\n};\r\nchar **argv = kmalloc(sizeof(char *[5]), GFP_KERNEL);\r\nif (!argv)\r\ngoto out;\r\nmodule_name = kstrdup(module_name, GFP_KERNEL);\r\nif (!module_name)\r\ngoto free_argv;\r\nargv[0] = modprobe_path;\r\nargv[1] = "-q";\r\nargv[2] = "--";\r\nargv[3] = module_name;\r\nargv[4] = NULL;\r\ninfo = call_usermodehelper_setup(modprobe_path, argv, envp, GFP_KERNEL,\r\nNULL, free_modprobe_argv, NULL);\r\nif (!info)\r\ngoto free_module_name;\r\nreturn call_usermodehelper_exec(info, wait | UMH_KILLABLE);\r\nfree_module_name:\r\nkfree(module_name);\r\nfree_argv:\r\nkfree(argv);\r\nout:\r\nreturn -ENOMEM;\r\n}\r\nint __request_module(bool wait, const char *fmt, ...)\r\n{\r\nva_list args;\r\nchar module_name[MODULE_NAME_LEN];\r\nunsigned int max_modprobes;\r\nint ret;\r\nstatic atomic_t kmod_concurrent = ATOMIC_INIT(0);\r\n#define MAX_KMOD_CONCURRENT 50\r\nstatic int kmod_loop_msg;\r\nWARN_ON_ONCE(wait && current_is_async());\r\nif (!modprobe_path[0])\r\nreturn 0;\r\nva_start(args, fmt);\r\nret = vsnprintf(module_name, MODULE_NAME_LEN, fmt, args);\r\nva_end(args);\r\nif (ret >= MODULE_NAME_LEN)\r\nreturn -ENAMETOOLONG;\r\nret = security_kernel_module_request(module_name);\r\nif (ret)\r\nreturn ret;\r\nmax_modprobes = min(max_threads/2, MAX_KMOD_CONCURRENT);\r\natomic_inc(&kmod_concurrent);\r\nif (atomic_read(&kmod_concurrent) > max_modprobes) {\r\nif (kmod_loop_msg < 5) {\r\nprintk(KERN_ERR\r\n"request_module: runaway loop modprobe %s\n",\r\nmodule_name);\r\nkmod_loop_msg++;\r\n}\r\natomic_dec(&kmod_concurrent);\r\nreturn -ENOMEM;\r\n}\r\ntrace_module_request(module_name, wait, _RET_IP_);\r\nret = call_modprobe(module_name, wait ? UMH_WAIT_PROC : UMH_WAIT_EXEC);\r\natomic_dec(&kmod_concurrent);\r\nreturn ret;\r\n}\r\nstatic int ____call_usermodehelper(void *data)\r\n{\r\nstruct subprocess_info *sub_info = data;\r\nstruct cred *new;\r\nint retval;\r\nspin_lock_irq(&current->sighand->siglock);\r\nflush_signal_handlers(current, 1);\r\nspin_unlock_irq(&current->sighand->siglock);\r\nset_cpus_allowed_ptr(current, cpu_all_mask);\r\nset_user_nice(current, 0);\r\nretval = -ENOMEM;\r\nnew = prepare_kernel_cred(current);\r\nif (!new)\r\ngoto fail;\r\nspin_lock(&umh_sysctl_lock);\r\nnew->cap_bset = cap_intersect(usermodehelper_bset, new->cap_bset);\r\nnew->cap_inheritable = cap_intersect(usermodehelper_inheritable,\r\nnew->cap_inheritable);\r\nspin_unlock(&umh_sysctl_lock);\r\nif (sub_info->init) {\r\nretval = sub_info->init(sub_info, new);\r\nif (retval) {\r\nabort_creds(new);\r\ngoto fail;\r\n}\r\n}\r\ncommit_creds(new);\r\nretval = do_execve(getname_kernel(sub_info->path),\r\n(const char __user *const __user *)sub_info->argv,\r\n(const char __user *const __user *)sub_info->envp);\r\nif (!retval)\r\nreturn 0;\r\nfail:\r\nsub_info->retval = retval;\r\ndo_exit(0);\r\n}\r\nstatic int call_helper(void *data)\r\n{\r\nkmod_thread_locker = current;\r\nreturn ____call_usermodehelper(data);\r\n}\r\nstatic void call_usermodehelper_freeinfo(struct subprocess_info *info)\r\n{\r\nif (info->cleanup)\r\n(*info->cleanup)(info);\r\nkfree(info);\r\n}\r\nstatic void umh_complete(struct subprocess_info *sub_info)\r\n{\r\nstruct completion *comp = xchg(&sub_info->complete, NULL);\r\nif (comp)\r\ncomplete(comp);\r\nelse\r\ncall_usermodehelper_freeinfo(sub_info);\r\n}\r\nstatic int wait_for_helper(void *data)\r\n{\r\nstruct subprocess_info *sub_info = data;\r\npid_t pid;\r\nkernel_sigaction(SIGCHLD, SIG_DFL);\r\npid = kernel_thread(____call_usermodehelper, sub_info, SIGCHLD);\r\nif (pid < 0) {\r\nsub_info->retval = pid;\r\n} else {\r\nint ret = -ECHILD;\r\nsys_wait4(pid, (int __user *)&ret, 0, NULL);\r\nif (ret)\r\nsub_info->retval = ret;\r\n}\r\numh_complete(sub_info);\r\ndo_exit(0);\r\n}\r\nstatic void __call_usermodehelper(struct work_struct *work)\r\n{\r\nstruct subprocess_info *sub_info =\r\ncontainer_of(work, struct subprocess_info, work);\r\nint wait = sub_info->wait & ~UMH_KILLABLE;\r\npid_t pid;\r\nif (wait == UMH_WAIT_PROC)\r\npid = kernel_thread(wait_for_helper, sub_info,\r\nCLONE_FS | CLONE_FILES | SIGCHLD);\r\nelse {\r\npid = kernel_thread(call_helper, sub_info,\r\nCLONE_VFORK | SIGCHLD);\r\nkmod_thread_locker = NULL;\r\n}\r\nswitch (wait) {\r\ncase UMH_NO_WAIT:\r\ncall_usermodehelper_freeinfo(sub_info);\r\nbreak;\r\ncase UMH_WAIT_PROC:\r\nif (pid > 0)\r\nbreak;\r\ncase UMH_WAIT_EXEC:\r\nif (pid < 0)\r\nsub_info->retval = pid;\r\numh_complete(sub_info);\r\n}\r\n}\r\nint usermodehelper_read_trylock(void)\r\n{\r\nDEFINE_WAIT(wait);\r\nint ret = 0;\r\ndown_read(&umhelper_sem);\r\nfor (;;) {\r\nprepare_to_wait(&usermodehelper_disabled_waitq, &wait,\r\nTASK_INTERRUPTIBLE);\r\nif (!usermodehelper_disabled)\r\nbreak;\r\nif (usermodehelper_disabled == UMH_DISABLED)\r\nret = -EAGAIN;\r\nup_read(&umhelper_sem);\r\nif (ret)\r\nbreak;\r\nschedule();\r\ntry_to_freeze();\r\ndown_read(&umhelper_sem);\r\n}\r\nfinish_wait(&usermodehelper_disabled_waitq, &wait);\r\nreturn ret;\r\n}\r\nlong usermodehelper_read_lock_wait(long timeout)\r\n{\r\nDEFINE_WAIT(wait);\r\nif (timeout < 0)\r\nreturn -EINVAL;\r\ndown_read(&umhelper_sem);\r\nfor (;;) {\r\nprepare_to_wait(&usermodehelper_disabled_waitq, &wait,\r\nTASK_UNINTERRUPTIBLE);\r\nif (!usermodehelper_disabled)\r\nbreak;\r\nup_read(&umhelper_sem);\r\ntimeout = schedule_timeout(timeout);\r\nif (!timeout)\r\nbreak;\r\ndown_read(&umhelper_sem);\r\n}\r\nfinish_wait(&usermodehelper_disabled_waitq, &wait);\r\nreturn timeout;\r\n}\r\nvoid usermodehelper_read_unlock(void)\r\n{\r\nup_read(&umhelper_sem);\r\n}\r\nvoid __usermodehelper_set_disable_depth(enum umh_disable_depth depth)\r\n{\r\ndown_write(&umhelper_sem);\r\nusermodehelper_disabled = depth;\r\nwake_up(&usermodehelper_disabled_waitq);\r\nup_write(&umhelper_sem);\r\n}\r\nint __usermodehelper_disable(enum umh_disable_depth depth)\r\n{\r\nlong retval;\r\nif (!depth)\r\nreturn -EINVAL;\r\ndown_write(&umhelper_sem);\r\nusermodehelper_disabled = depth;\r\nup_write(&umhelper_sem);\r\nretval = wait_event_timeout(running_helpers_waitq,\r\natomic_read(&running_helpers) == 0,\r\nRUNNING_HELPERS_TIMEOUT);\r\nif (retval)\r\nreturn 0;\r\n__usermodehelper_set_disable_depth(UMH_ENABLED);\r\nreturn -EAGAIN;\r\n}\r\nstatic void helper_lock(void)\r\n{\r\natomic_inc(&running_helpers);\r\nsmp_mb__after_atomic();\r\n}\r\nstatic void helper_unlock(void)\r\n{\r\nif (atomic_dec_and_test(&running_helpers))\r\nwake_up(&running_helpers_waitq);\r\n}\r\nstruct subprocess_info *call_usermodehelper_setup(char *path, char **argv,\r\nchar **envp, gfp_t gfp_mask,\r\nint (*init)(struct subprocess_info *info, struct cred *new),\r\nvoid (*cleanup)(struct subprocess_info *info),\r\nvoid *data)\r\n{\r\nstruct subprocess_info *sub_info;\r\nsub_info = kzalloc(sizeof(struct subprocess_info), gfp_mask);\r\nif (!sub_info)\r\ngoto out;\r\nINIT_WORK(&sub_info->work, __call_usermodehelper);\r\nsub_info->path = path;\r\nsub_info->argv = argv;\r\nsub_info->envp = envp;\r\nsub_info->cleanup = cleanup;\r\nsub_info->init = init;\r\nsub_info->data = data;\r\nout:\r\nreturn sub_info;\r\n}\r\nint call_usermodehelper_exec(struct subprocess_info *sub_info, int wait)\r\n{\r\nDECLARE_COMPLETION_ONSTACK(done);\r\nint retval = 0;\r\nif (!sub_info->path) {\r\ncall_usermodehelper_freeinfo(sub_info);\r\nreturn -EINVAL;\r\n}\r\nhelper_lock();\r\nif (!khelper_wq || usermodehelper_disabled) {\r\nretval = -EBUSY;\r\ngoto out;\r\n}\r\nif (wait != UMH_NO_WAIT && current == kmod_thread_locker) {\r\nretval = -EBUSY;\r\ngoto out;\r\n}\r\nsub_info->complete = &done;\r\nsub_info->wait = wait;\r\nqueue_work(khelper_wq, &sub_info->work);\r\nif (wait == UMH_NO_WAIT)\r\ngoto unlock;\r\nif (wait & UMH_KILLABLE) {\r\nretval = wait_for_completion_killable(&done);\r\nif (!retval)\r\ngoto wait_done;\r\nif (xchg(&sub_info->complete, NULL))\r\ngoto unlock;\r\n}\r\nwait_for_completion(&done);\r\nwait_done:\r\nretval = sub_info->retval;\r\nout:\r\ncall_usermodehelper_freeinfo(sub_info);\r\nunlock:\r\nhelper_unlock();\r\nreturn retval;\r\n}\r\nint call_usermodehelper(char *path, char **argv, char **envp, int wait)\r\n{\r\nstruct subprocess_info *info;\r\ngfp_t gfp_mask = (wait == UMH_NO_WAIT) ? GFP_ATOMIC : GFP_KERNEL;\r\ninfo = call_usermodehelper_setup(path, argv, envp, gfp_mask,\r\nNULL, NULL, NULL);\r\nif (info == NULL)\r\nreturn -ENOMEM;\r\nreturn call_usermodehelper_exec(info, wait);\r\n}\r\nstatic int proc_cap_handler(struct ctl_table *table, int write,\r\nvoid __user *buffer, size_t *lenp, loff_t *ppos)\r\n{\r\nstruct ctl_table t;\r\nunsigned long cap_array[_KERNEL_CAPABILITY_U32S];\r\nkernel_cap_t new_cap;\r\nint err, i;\r\nif (write && (!capable(CAP_SETPCAP) ||\r\n!capable(CAP_SYS_MODULE)))\r\nreturn -EPERM;\r\nspin_lock(&umh_sysctl_lock);\r\nfor (i = 0; i < _KERNEL_CAPABILITY_U32S; i++) {\r\nif (table->data == CAP_BSET)\r\ncap_array[i] = usermodehelper_bset.cap[i];\r\nelse if (table->data == CAP_PI)\r\ncap_array[i] = usermodehelper_inheritable.cap[i];\r\nelse\r\nBUG();\r\n}\r\nspin_unlock(&umh_sysctl_lock);\r\nt = *table;\r\nt.data = &cap_array;\r\nerr = proc_doulongvec_minmax(&t, write, buffer, lenp, ppos);\r\nif (err < 0)\r\nreturn err;\r\nfor (i = 0; i < _KERNEL_CAPABILITY_U32S; i++)\r\nnew_cap.cap[i] = cap_array[i];\r\nspin_lock(&umh_sysctl_lock);\r\nif (write) {\r\nif (table->data == CAP_BSET)\r\nusermodehelper_bset = cap_intersect(usermodehelper_bset, new_cap);\r\nif (table->data == CAP_PI)\r\nusermodehelper_inheritable = cap_intersect(usermodehelper_inheritable, new_cap);\r\n}\r\nspin_unlock(&umh_sysctl_lock);\r\nreturn 0;\r\n}\r\nvoid __init usermodehelper_init(void)\r\n{\r\nkhelper_wq = create_singlethread_workqueue("khelper");\r\nBUG_ON(!khelper_wq);\r\n}
