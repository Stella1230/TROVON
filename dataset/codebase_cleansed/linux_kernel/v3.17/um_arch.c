static void __init add_arg(char *arg)\r\n{\r\nif (strlen(command_line) + strlen(arg) + 1 > COMMAND_LINE_SIZE) {\r\nprintf("add_arg: Too many command line arguments!\n");\r\nexit(1);\r\n}\r\nif (strlen(command_line) > 0)\r\nstrcat(command_line, " ");\r\nstrcat(command_line, arg);\r\n}\r\nunsigned long thread_saved_pc(struct task_struct *task)\r\n{\r\nreturn os_process_pc(userspace_pid[0]);\r\n}\r\nstatic int show_cpuinfo(struct seq_file *m, void *v)\r\n{\r\nint index = 0;\r\n#ifdef CONFIG_SMP\r\nindex = (struct cpuinfo_um *) v - cpu_data;\r\nif (!cpu_online(index))\r\nreturn 0;\r\n#endif\r\nseq_printf(m, "processor\t: %d\n", index);\r\nseq_printf(m, "vendor_id\t: User Mode Linux\n");\r\nseq_printf(m, "model name\t: UML\n");\r\nseq_printf(m, "mode\t\t: skas\n");\r\nseq_printf(m, "host\t\t: %s\n", host_info);\r\nseq_printf(m, "bogomips\t: %lu.%02lu\n\n",\r\nloops_per_jiffy/(500000/HZ),\r\n(loops_per_jiffy/(5000/HZ)) % 100);\r\nreturn 0;\r\n}\r\nstatic void *c_start(struct seq_file *m, loff_t *pos)\r\n{\r\nreturn *pos < NR_CPUS ? cpu_data + *pos : NULL;\r\n}\r\nstatic void *c_next(struct seq_file *m, void *v, loff_t *pos)\r\n{\r\n++*pos;\r\nreturn c_start(m, pos);\r\n}\r\nstatic void c_stop(struct seq_file *m, void *v)\r\n{\r\n}\r\nstatic int __init uml_version_setup(char *line, int *add)\r\n{\r\nprintf("%s\n", init_utsname()->release);\r\nexit(0);\r\nreturn 0;\r\n}\r\nstatic int __init uml_root_setup(char *line, int *add)\r\n{\r\nhave_root = 1;\r\nreturn 0;\r\n}\r\nstatic int __init no_skas_debug_setup(char *line, int *add)\r\n{\r\nprintf("'debug' is not necessary to gdb UML in skas mode - run \n");\r\nprintf("'gdb linux'\n");\r\nreturn 0;\r\n}\r\nstatic int __init uml_ncpus_setup(char *line, int *add)\r\n{\r\nif (!sscanf(line, "%d", &ncpus)) {\r\nprintf("Couldn't parse [%s]\n", line);\r\nreturn -1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int __init Usage(char *line, int *add)\r\n{\r\nconst char **p;\r\nprintf(usage_string, init_utsname()->release);\r\np = &__uml_help_start;\r\nwhile (p < &__uml_help_end) {\r\nprintf("%s", *p);\r\np++;\r\n}\r\nexit(0);\r\nreturn 0;\r\n}\r\nstatic void __init uml_checksetup(char *line, int *add)\r\n{\r\nstruct uml_param *p;\r\np = &__uml_setup_start;\r\nwhile (p < &__uml_setup_end) {\r\nsize_t n;\r\nn = strlen(p->str);\r\nif (!strncmp(line, p->str, n) && p->setup_func(line + n, add))\r\nreturn;\r\np++;\r\n}\r\n}\r\nstatic void __init uml_postsetup(void)\r\n{\r\ninitcall_t *p;\r\np = &__uml_postsetup_start;\r\nwhile (p < &__uml_postsetup_end) {\r\n(*p)();\r\np++;\r\n}\r\nreturn;\r\n}\r\nstatic int panic_exit(struct notifier_block *self, unsigned long unused1,\r\nvoid *unused2)\r\n{\r\nbust_spinlocks(1);\r\nbust_spinlocks(0);\r\numl_exitcode = 1;\r\nos_dump_core();\r\nreturn 0;\r\n}\r\nint __init linux_main(int argc, char **argv)\r\n{\r\nunsigned long avail, diff;\r\nunsigned long virtmem_size, max_physmem;\r\nunsigned long stack;\r\nunsigned int i;\r\nint add;\r\nchar * mode;\r\nfor (i = 1; i < argc; i++) {\r\nif ((i == 1) && (argv[i][0] == ' '))\r\ncontinue;\r\nadd = 1;\r\numl_checksetup(argv[i], &add);\r\nif (add)\r\nadd_arg(argv[i]);\r\n}\r\nif (have_root == 0)\r\nadd_arg(DEFAULT_COMMAND_LINE);\r\nhost_task_size = os_get_top_address();\r\ntask_size = host_task_size & PGDIR_MASK;\r\nos_early_checks();\r\ncan_do_skas();\r\nif (proc_mm && ptrace_faultinfo)\r\nmode = "SKAS3";\r\nelse\r\nmode = "SKAS0";\r\nprintf("UML running in %s mode\n", mode);\r\nbrk_start = (unsigned long) sbrk(0);\r\ndiff = UML_ROUND_UP(brk_start) - UML_ROUND_UP(&_end);\r\nif (diff > 1024 * 1024) {\r\nprintf("Adding %ld bytes to physical memory to account for "\r\n"exec-shield gap\n", diff);\r\nphysmem_size += UML_ROUND_UP(brk_start) - UML_ROUND_UP(&_end);\r\n}\r\numl_physmem = (unsigned long) &__binary_start & PAGE_MASK;\r\numl_reserved = ROUND_4M(brk_start) + (1 << 22);\r\nsetup_machinename(init_utsname()->machine);\r\nhighmem = 0;\r\niomem_size = (iomem_size + PAGE_SIZE - 1) & PAGE_MASK;\r\nmax_physmem = TASK_SIZE - uml_physmem - iomem_size - MIN_VMALLOC;\r\nmax_physmem &= ~((1 << (PAGE_SHIFT + MAX_ORDER)) - 1);\r\nif (physmem_size + iomem_size > max_physmem) {\r\nhighmem = physmem_size + iomem_size - max_physmem;\r\nphysmem_size -= highmem;\r\n#ifndef CONFIG_HIGHMEM\r\nhighmem = 0;\r\nprintf("CONFIG_HIGHMEM not enabled - physical memory shrunk "\r\n"to %Lu bytes\n", physmem_size);\r\n#endif\r\n}\r\nhigh_physmem = uml_physmem + physmem_size;\r\nend_iomem = high_physmem + iomem_size;\r\nhigh_memory = (void *) end_iomem;\r\nstart_vm = VMALLOC_START;\r\nsetup_physmem(uml_physmem, uml_reserved, physmem_size, highmem);\r\nif (init_maps(physmem_size, iomem_size, highmem)) {\r\nprintf("Failed to allocate mem_map for %Lu bytes of physical "\r\n"memory and %Lu bytes of highmem\n", physmem_size,\r\nhighmem);\r\nexit(1);\r\n}\r\nvirtmem_size = physmem_size;\r\nstack = (unsigned long) argv;\r\nstack &= ~(1024 * 1024 - 1);\r\navail = stack - start_vm;\r\nif (physmem_size > avail)\r\nvirtmem_size = avail;\r\nend_vm = start_vm + virtmem_size;\r\nif (virtmem_size < physmem_size)\r\nprintf("Kernel virtual memory size shrunk to %lu bytes\n",\r\nvirtmem_size);\r\natomic_notifier_chain_register(&panic_notifier_list,\r\n&panic_exit_notifier);\r\numl_postsetup();\r\nstack_protections((unsigned long) &init_thread_info);\r\nos_flush_stdout();\r\nreturn start_uml();\r\n}\r\nvoid __init setup_arch(char **cmdline_p)\r\n{\r\npaging_init();\r\nstrlcpy(boot_command_line, command_line, COMMAND_LINE_SIZE);\r\n*cmdline_p = command_line;\r\nsetup_hostinfo(host_info, sizeof host_info);\r\n}\r\nvoid __init check_bugs(void)\r\n{\r\narch_check_bugs();\r\nos_check_bugs();\r\n}\r\nvoid apply_alternatives(struct alt_instr *start, struct alt_instr *end)\r\n{\r\n}\r\nvoid alternatives_smp_module_add(struct module *mod, char *name,\r\nvoid *locks, void *locks_end,\r\nvoid *text, void *text_end)\r\n{\r\n}\r\nvoid alternatives_smp_module_del(struct module *mod)\r\n{\r\n}
