static int emulate_dcbz(struct pt_regs *regs, unsigned char __user *addr)\r\n{\r\nlong __user *p;\r\nint i, size;\r\n#ifdef __powerpc64__\r\nsize = ppc64_caches.dline_size;\r\n#else\r\nsize = L1_CACHE_BYTES;\r\n#endif\r\np = (long __user *) (regs->dar & -size);\r\nif (user_mode(regs) && !access_ok(VERIFY_WRITE, p, size))\r\nreturn -EFAULT;\r\nfor (i = 0; i < size / sizeof(long); ++i)\r\nif (__put_user_inatomic(0, p+i))\r\nreturn -EFAULT;\r\nreturn 1;\r\n}\r\nstatic int emulate_multiple(struct pt_regs *regs, unsigned char __user *addr,\r\nunsigned int reg, unsigned int nb,\r\nunsigned int flags, unsigned int instr,\r\nunsigned long swiz)\r\n{\r\nunsigned long *rptr;\r\nunsigned int nb0, i, bswiz;\r\nunsigned long p;\r\nif (unlikely((nb > 4) || !user_mode(regs)))\r\nreturn 0;\r\nnb0 = 0;\r\nif (flags & HARD) {\r\nif (flags & SX) {\r\nnb = regs->xer & 127;\r\nif (nb == 0)\r\nreturn 1;\r\n} else {\r\nunsigned long pc = regs->nip ^ (swiz & 4);\r\nif (__get_user_inatomic(instr,\r\n(unsigned int __user *)pc))\r\nreturn -EFAULT;\r\nif (swiz == 0 && (flags & SW))\r\ninstr = cpu_to_le32(instr);\r\nnb = (instr >> 11) & 0x1f;\r\nif (nb == 0)\r\nnb = 32;\r\n}\r\nif (nb + reg * 4 > 128) {\r\nnb0 = nb + reg * 4 - 128;\r\nnb = 128 - reg * 4;\r\n}\r\n#ifdef __LITTLE_ENDIAN__\r\nflags ^= SW;\r\n#endif\r\n} else {\r\nnb = (32 - reg) * 4;\r\n}\r\nif (!access_ok((flags & ST ? VERIFY_WRITE: VERIFY_READ), addr, nb+nb0))\r\nreturn -EFAULT;\r\nrptr = &regs->gpr[reg];\r\np = (unsigned long) addr;\r\nbswiz = (flags & SW)? 3: 0;\r\nif (!(flags & ST)) {\r\nmemset(rptr, 0, ((nb + 3) / 4) * sizeof(unsigned long));\r\nif (nb0 > 0)\r\nmemset(&regs->gpr[0], 0,\r\n((nb0 + 3) / 4) * sizeof(unsigned long));\r\nfor (i = 0; i < nb; ++i, ++p)\r\nif (__get_user_inatomic(REG_BYTE(rptr, i ^ bswiz),\r\nSWIZ_PTR(p)))\r\nreturn -EFAULT;\r\nif (nb0 > 0) {\r\nrptr = &regs->gpr[0];\r\naddr += nb;\r\nfor (i = 0; i < nb0; ++i, ++p)\r\nif (__get_user_inatomic(REG_BYTE(rptr,\r\ni ^ bswiz),\r\nSWIZ_PTR(p)))\r\nreturn -EFAULT;\r\n}\r\n} else {\r\nfor (i = 0; i < nb; ++i, ++p)\r\nif (__put_user_inatomic(REG_BYTE(rptr, i ^ bswiz),\r\nSWIZ_PTR(p)))\r\nreturn -EFAULT;\r\nif (nb0 > 0) {\r\nrptr = &regs->gpr[0];\r\naddr += nb;\r\nfor (i = 0; i < nb0; ++i, ++p)\r\nif (__put_user_inatomic(REG_BYTE(rptr,\r\ni ^ bswiz),\r\nSWIZ_PTR(p)))\r\nreturn -EFAULT;\r\n}\r\n}\r\nreturn 1;\r\n}\r\nstatic int emulate_fp_pair(unsigned char __user *addr, unsigned int reg,\r\nunsigned int flags)\r\n{\r\nchar *ptr0 = (char *) &current->thread.TS_FPR(reg);\r\nchar *ptr1 = (char *) &current->thread.TS_FPR(reg+1);\r\nint i, ret, sw = 0;\r\nif (reg & 1)\r\nreturn 0;\r\nif (flags & SW)\r\nsw = 7;\r\nret = 0;\r\nfor (i = 0; i < 8; ++i) {\r\nif (!(flags & ST)) {\r\nret |= __get_user(ptr0[i^sw], addr + i);\r\nret |= __get_user(ptr1[i^sw], addr + i + 8);\r\n} else {\r\nret |= __put_user(ptr0[i^sw], addr + i);\r\nret |= __put_user(ptr1[i^sw], addr + i + 8);\r\n}\r\n}\r\nif (ret)\r\nreturn -EFAULT;\r\nreturn 1;\r\n}\r\nstatic int emulate_lq_stq(struct pt_regs *regs, unsigned char __user *addr,\r\nunsigned int reg, unsigned int flags)\r\n{\r\nchar *ptr0 = (char *)&regs->gpr[reg];\r\nchar *ptr1 = (char *)&regs->gpr[reg+1];\r\nint i, ret, sw = 0;\r\nif (reg & 1)\r\nreturn 0;\r\nif (flags & SW)\r\nsw = 7;\r\nret = 0;\r\nfor (i = 0; i < 8; ++i) {\r\nif (!(flags & ST)) {\r\nret |= __get_user(ptr0[i^sw], addr + i);\r\nret |= __get_user(ptr1[i^sw], addr + i + 8);\r\n} else {\r\nret |= __put_user(ptr0[i^sw], addr + i);\r\nret |= __put_user(ptr1[i^sw], addr + i + 8);\r\n}\r\n}\r\nif (ret)\r\nreturn -EFAULT;\r\nreturn 1;\r\n}\r\nstatic int emulate_spe(struct pt_regs *regs, unsigned int reg,\r\nunsigned int instr)\r\n{\r\nint ret;\r\nunion {\r\nu64 ll;\r\nu32 w[2];\r\nu16 h[4];\r\nu8 v[8];\r\n} data, temp;\r\nunsigned char __user *p, *addr;\r\nunsigned long *evr = &current->thread.evr[reg];\r\nunsigned int nb, flags;\r\ninstr = (instr >> 1) & 0x1f;\r\naddr = (unsigned char __user *)regs->dar;\r\nnb = spe_aligninfo[instr].len;\r\nflags = spe_aligninfo[instr].flags;\r\nif (unlikely(user_mode(regs) &&\r\n!access_ok((flags & ST ? VERIFY_WRITE : VERIFY_READ),\r\naddr, nb)))\r\nreturn -EFAULT;\r\nif (unlikely(!user_mode(regs)))\r\nreturn 0;\r\nflush_spe_to_thread(current);\r\nif (flags & ST) {\r\ndata.ll = 0;\r\nswitch (instr) {\r\ncase EVSTDD:\r\ncase EVSTDW:\r\ncase EVSTDH:\r\ndata.w[0] = *evr;\r\ndata.w[1] = regs->gpr[reg];\r\nbreak;\r\ncase EVSTWHE:\r\ndata.h[2] = *evr >> 16;\r\ndata.h[3] = regs->gpr[reg] >> 16;\r\nbreak;\r\ncase EVSTWHO:\r\ndata.h[2] = *evr & 0xffff;\r\ndata.h[3] = regs->gpr[reg] & 0xffff;\r\nbreak;\r\ncase EVSTWWE:\r\ndata.w[1] = *evr;\r\nbreak;\r\ncase EVSTWWO:\r\ndata.w[1] = regs->gpr[reg];\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n} else {\r\ntemp.ll = data.ll = 0;\r\nret = 0;\r\np = addr;\r\nswitch (nb) {\r\ncase 8:\r\nret |= __get_user_inatomic(temp.v[0], p++);\r\nret |= __get_user_inatomic(temp.v[1], p++);\r\nret |= __get_user_inatomic(temp.v[2], p++);\r\nret |= __get_user_inatomic(temp.v[3], p++);\r\ncase 4:\r\nret |= __get_user_inatomic(temp.v[4], p++);\r\nret |= __get_user_inatomic(temp.v[5], p++);\r\ncase 2:\r\nret |= __get_user_inatomic(temp.v[6], p++);\r\nret |= __get_user_inatomic(temp.v[7], p++);\r\nif (unlikely(ret))\r\nreturn -EFAULT;\r\n}\r\nswitch (instr) {\r\ncase EVLDD:\r\ncase EVLDW:\r\ncase EVLDH:\r\ndata.ll = temp.ll;\r\nbreak;\r\ncase EVLHHESPLAT:\r\ndata.h[0] = temp.h[3];\r\ndata.h[2] = temp.h[3];\r\nbreak;\r\ncase EVLHHOUSPLAT:\r\ncase EVLHHOSSPLAT:\r\ndata.h[1] = temp.h[3];\r\ndata.h[3] = temp.h[3];\r\nbreak;\r\ncase EVLWHE:\r\ndata.h[0] = temp.h[2];\r\ndata.h[2] = temp.h[3];\r\nbreak;\r\ncase EVLWHOU:\r\ncase EVLWHOS:\r\ndata.h[1] = temp.h[2];\r\ndata.h[3] = temp.h[3];\r\nbreak;\r\ncase EVLWWSPLAT:\r\ndata.w[0] = temp.w[1];\r\ndata.w[1] = temp.w[1];\r\nbreak;\r\ncase EVLWHSPLAT:\r\ndata.h[0] = temp.h[2];\r\ndata.h[1] = temp.h[2];\r\ndata.h[2] = temp.h[3];\r\ndata.h[3] = temp.h[3];\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\n}\r\nif (flags & SW) {\r\nswitch (flags & 0xf0) {\r\ncase E8:\r\ndata.ll = swab64(data.ll);\r\nbreak;\r\ncase E4:\r\ndata.w[0] = swab32(data.w[0]);\r\ndata.w[1] = swab32(data.w[1]);\r\nbreak;\r\ndefault:\r\ndata.h[0] = swab16(data.h[0]);\r\ndata.h[1] = swab16(data.h[1]);\r\ndata.h[2] = swab16(data.h[2]);\r\ndata.h[3] = swab16(data.h[3]);\r\nbreak;\r\n}\r\n}\r\nif (flags & SE) {\r\ndata.w[0] = (s16)data.h[1];\r\ndata.w[1] = (s16)data.h[3];\r\n}\r\nif (flags & ST) {\r\nret = 0;\r\np = addr;\r\nswitch (nb) {\r\ncase 8:\r\nret |= __put_user_inatomic(data.v[0], p++);\r\nret |= __put_user_inatomic(data.v[1], p++);\r\nret |= __put_user_inatomic(data.v[2], p++);\r\nret |= __put_user_inatomic(data.v[3], p++);\r\ncase 4:\r\nret |= __put_user_inatomic(data.v[4], p++);\r\nret |= __put_user_inatomic(data.v[5], p++);\r\ncase 2:\r\nret |= __put_user_inatomic(data.v[6], p++);\r\nret |= __put_user_inatomic(data.v[7], p++);\r\n}\r\nif (unlikely(ret))\r\nreturn -EFAULT;\r\n} else {\r\n*evr = data.w[0];\r\nregs->gpr[reg] = data.w[1];\r\n}\r\nreturn 1;\r\n}\r\nstatic int emulate_vsx(unsigned char __user *addr, unsigned int reg,\r\nunsigned int areg, struct pt_regs *regs,\r\nunsigned int flags, unsigned int length,\r\nunsigned int elsize)\r\n{\r\nchar *ptr;\r\nunsigned long *lptr;\r\nint ret = 0;\r\nint sw = 0;\r\nint i, j;\r\nif (unlikely(!user_mode(regs)))\r\nreturn 0;\r\nflush_vsx_to_thread(current);\r\nif (reg < 32)\r\nptr = (char *) &current->thread.fp_state.fpr[reg][0];\r\nelse\r\nptr = (char *) &current->thread.vr_state.vr[reg - 32];\r\nlptr = (unsigned long *) ptr;\r\n#ifdef __LITTLE_ENDIAN__\r\nif (flags & SW) {\r\nelsize = length;\r\nsw = length-1;\r\n} else {\r\naddr += length - elsize;\r\nif (length == 8)\r\nptr += 8;\r\n}\r\n#else\r\nif (flags & SW)\r\nsw = elsize-1;\r\n#endif\r\nfor (j = 0; j < length; j += elsize) {\r\nfor (i = 0; i < elsize; ++i) {\r\nif (flags & ST)\r\nret |= __put_user(ptr[i^sw], addr + i);\r\nelse\r\nret |= __get_user(ptr[i^sw], addr + i);\r\n}\r\nptr += elsize;\r\n#ifdef __LITTLE_ENDIAN__\r\naddr -= elsize;\r\n#else\r\naddr += elsize;\r\n#endif\r\n}\r\n#ifdef __BIG_ENDIAN__\r\n#define VSX_HI 0\r\n#define VSX_LO 1\r\n#else\r\n#define VSX_HI 1\r\n#define VSX_LO 0\r\n#endif\r\nif (!ret) {\r\nif (flags & U)\r\nregs->gpr[areg] = regs->dar;\r\nif (flags & SPLT)\r\nlptr[VSX_LO] = lptr[VSX_HI];\r\nelse if (!(flags & ST) && (8 == length))\r\nlptr[VSX_LO] = 0;\r\n} else\r\nreturn -EFAULT;\r\nreturn 1;\r\n}\r\nint fix_alignment(struct pt_regs *regs)\r\n{\r\nunsigned int instr, nb, flags, instruction = 0;\r\nunsigned int reg, areg;\r\nunsigned int dsisr;\r\nunsigned char __user *addr;\r\nunsigned long p, swiz;\r\nint ret, i;\r\nunion data {\r\nu64 ll;\r\ndouble dd;\r\nunsigned char v[8];\r\nstruct {\r\n#ifdef __LITTLE_ENDIAN__\r\nint low32;\r\nunsigned hi32;\r\n#else\r\nunsigned hi32;\r\nint low32;\r\n#endif\r\n} x32;\r\nstruct {\r\n#ifdef __LITTLE_ENDIAN__\r\nshort low16;\r\nunsigned char hi48[6];\r\n#else\r\nunsigned char hi48[6];\r\nshort low16;\r\n#endif\r\n} x16;\r\n} data;\r\nCHECK_FULL_REGS(regs);\r\ndsisr = regs->dsisr;\r\nif (cpu_has_feature(CPU_FTR_NODSISRALIGN)) {\r\nunsigned long pc = regs->nip;\r\nif (cpu_has_feature(CPU_FTR_PPC_LE) && (regs->msr & MSR_LE))\r\npc ^= 4;\r\nif (unlikely(__get_user_inatomic(instr,\r\n(unsigned int __user *)pc)))\r\nreturn -EFAULT;\r\nif (cpu_has_feature(CPU_FTR_REAL_LE) && (regs->msr & MSR_LE))\r\ninstr = cpu_to_le32(instr);\r\ndsisr = make_dsisr(instr);\r\ninstruction = instr;\r\n}\r\nreg = (dsisr >> 5) & 0x1f;\r\nareg = dsisr & 0x1f;\r\n#ifdef CONFIG_SPE\r\nif ((instr >> 26) == 0x4) {\r\nPPC_WARN_ALIGNMENT(spe, regs);\r\nreturn emulate_spe(regs, reg, instr);\r\n}\r\n#endif\r\ninstr = (dsisr >> 10) & 0x7f;\r\ninstr |= (dsisr >> 13) & 0x60;\r\nnb = aligninfo[instr].len;\r\nflags = aligninfo[instr].flags;\r\nif (IS_XFORM(instruction) && ((instruction >> 1) & 0x3ff) == 532) {\r\nnb = 8;\r\nflags = LD+SW;\r\n} else if (IS_XFORM(instruction) &&\r\n((instruction >> 1) & 0x3ff) == 660) {\r\nnb = 8;\r\nflags = ST+SW;\r\n}\r\nswiz = 0;\r\nif ((regs->msr & MSR_LE) != (MSR_KERNEL & MSR_LE)) {\r\nflags ^= SW;\r\n#ifdef __BIG_ENDIAN__\r\nif (cpu_has_feature(CPU_FTR_PPC_LE))\r\nswiz = 7;\r\n#endif\r\n}\r\naddr = (unsigned char __user *)regs->dar;\r\n#ifdef CONFIG_VSX\r\nif ((instruction & 0xfc00003e) == 0x7c000018) {\r\nunsigned int elsize;\r\nreg |= (instruction & 0x1) << 5;\r\nnb = 8;\r\nif (instruction & 0x200)\r\nnb = 16;\r\nelsize = 4;\r\nif (instruction & 0x80)\r\nelsize = 8;\r\nflags = 0;\r\nif ((regs->msr & MSR_LE) != (MSR_KERNEL & MSR_LE))\r\nflags |= SW;\r\nif (instruction & 0x100)\r\nflags |= ST;\r\nif (instruction & 0x040)\r\nflags |= U;\r\nif ((instruction & 0x400) == 0){\r\nflags |= SPLT;\r\nnb = 8;\r\n}\r\nPPC_WARN_ALIGNMENT(vsx, regs);\r\nreturn emulate_vsx(addr, reg, areg, regs, flags, nb, elsize);\r\n}\r\n#endif\r\nif (instr == DCBZ) {\r\nPPC_WARN_ALIGNMENT(dcbz, regs);\r\nreturn emulate_dcbz(regs, addr);\r\n}\r\nif (unlikely(nb == 0))\r\nreturn 0;\r\nif (flags & M) {\r\nPPC_WARN_ALIGNMENT(multiple, regs);\r\nreturn emulate_multiple(regs, addr, reg, nb,\r\nflags, instr, swiz);\r\n}\r\nif (unlikely(user_mode(regs) &&\r\n!access_ok((flags & ST ? VERIFY_WRITE : VERIFY_READ),\r\naddr, nb)))\r\nreturn -EFAULT;\r\nif (flags & F) {\r\nif (unlikely(!user_mode(regs)))\r\nreturn 0;\r\nflush_fp_to_thread(current);\r\n}\r\nif ((nb == 16)) {\r\nif (flags & F) {\r\nPPC_WARN_ALIGNMENT(fp_pair, regs);\r\nreturn emulate_fp_pair(addr, reg, flags);\r\n} else {\r\n#ifdef CONFIG_PPC64\r\nPPC_WARN_ALIGNMENT(lq_stq, regs);\r\nreturn emulate_lq_stq(regs, addr, reg, flags);\r\n#else\r\nreturn 0;\r\n#endif\r\n}\r\n}\r\nPPC_WARN_ALIGNMENT(unaligned, regs);\r\nif (!(flags & ST)) {\r\nunsigned int start = 0;\r\nswitch (nb) {\r\ncase 4:\r\nstart = offsetof(union data, x32.low32);\r\nbreak;\r\ncase 2:\r\nstart = offsetof(union data, x16.low16);\r\nbreak;\r\n}\r\ndata.ll = 0;\r\nret = 0;\r\np = (unsigned long)addr;\r\nfor (i = 0; i < nb; i++)\r\nret |= __get_user_inatomic(data.v[start + i],\r\nSWIZ_PTR(p++));\r\nif (unlikely(ret))\r\nreturn -EFAULT;\r\n} else if (flags & F) {\r\ndata.ll = current->thread.TS_FPR(reg);\r\nif (flags & S) {\r\n#ifdef CONFIG_PPC_FPU\r\npreempt_disable();\r\nenable_kernel_fp();\r\ncvt_df(&data.dd, (float *)&data.x32.low32);\r\npreempt_enable();\r\n#else\r\nreturn 0;\r\n#endif\r\n}\r\n} else\r\ndata.ll = regs->gpr[reg];\r\nif (flags & SW) {\r\nswitch (nb) {\r\ncase 8:\r\ndata.ll = swab64(data.ll);\r\nbreak;\r\ncase 4:\r\ndata.x32.low32 = swab32(data.x32.low32);\r\nbreak;\r\ncase 2:\r\ndata.x16.low16 = swab16(data.x16.low16);\r\nbreak;\r\n}\r\n}\r\nswitch (flags & ~(U|SW)) {\r\ncase LD+SE:\r\ncase LD+F+SE:\r\nif ( nb == 2 )\r\ndata.ll = data.x16.low16;\r\nelse\r\ndata.ll = data.x32.low32;\r\nbreak;\r\ncase LD+F+S:\r\n#ifdef CONFIG_PPC_FPU\r\npreempt_disable();\r\nenable_kernel_fp();\r\ncvt_fd((float *)&data.x32.low32, &data.dd);\r\npreempt_enable();\r\n#else\r\nreturn 0;\r\n#endif\r\nbreak;\r\n}\r\nif (flags & ST) {\r\nunsigned int start = 0;\r\nswitch (nb) {\r\ncase 4:\r\nstart = offsetof(union data, x32.low32);\r\nbreak;\r\ncase 2:\r\nstart = offsetof(union data, x16.low16);\r\nbreak;\r\n}\r\nret = 0;\r\np = (unsigned long)addr;\r\nfor (i = 0; i < nb; i++)\r\nret |= __put_user_inatomic(data.v[start + i],\r\nSWIZ_PTR(p++));\r\nif (unlikely(ret))\r\nreturn -EFAULT;\r\n} else if (flags & F)\r\ncurrent->thread.TS_FPR(reg) = data.ll;\r\nelse\r\nregs->gpr[reg] = data.ll;\r\nif (flags & U)\r\nregs->gpr[areg] = regs->dar;\r\nreturn 1;\r\n}
