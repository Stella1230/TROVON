static inline struct ceph_snap_context *page_snap_context(struct page *page)\r\n{\r\nif (PagePrivate(page))\r\nreturn (void *)page->private;\r\nreturn NULL;\r\n}\r\nstatic int ceph_set_page_dirty(struct page *page)\r\n{\r\nstruct address_space *mapping = page->mapping;\r\nstruct inode *inode;\r\nstruct ceph_inode_info *ci;\r\nstruct ceph_snap_context *snapc;\r\nint ret;\r\nif (unlikely(!mapping))\r\nreturn !TestSetPageDirty(page);\r\nif (PageDirty(page)) {\r\ndout("%p set_page_dirty %p idx %lu -- already dirty\n",\r\nmapping->host, page, page->index);\r\nBUG_ON(!PagePrivate(page));\r\nreturn 0;\r\n}\r\ninode = mapping->host;\r\nci = ceph_inode(inode);\r\nsnapc = ceph_get_snap_context(ci->i_snap_realm->cached_context);\r\nspin_lock(&ci->i_ceph_lock);\r\nif (ci->i_head_snapc == NULL)\r\nci->i_head_snapc = ceph_get_snap_context(snapc);\r\n++ci->i_wrbuffer_ref_head;\r\nif (ci->i_wrbuffer_ref == 0)\r\nihold(inode);\r\n++ci->i_wrbuffer_ref;\r\ndout("%p set_page_dirty %p idx %lu head %d/%d -> %d/%d "\r\n"snapc %p seq %lld (%d snaps)\n",\r\nmapping->host, page, page->index,\r\nci->i_wrbuffer_ref-1, ci->i_wrbuffer_ref_head-1,\r\nci->i_wrbuffer_ref, ci->i_wrbuffer_ref_head,\r\nsnapc, snapc->seq, snapc->num_snaps);\r\nspin_unlock(&ci->i_ceph_lock);\r\nBUG_ON(PagePrivate(page));\r\npage->private = (unsigned long)snapc;\r\nSetPagePrivate(page);\r\nret = __set_page_dirty_nobuffers(page);\r\nWARN_ON(!PageLocked(page));\r\nWARN_ON(!page->mapping);\r\nreturn ret;\r\n}\r\nstatic void ceph_invalidatepage(struct page *page, unsigned int offset,\r\nunsigned int length)\r\n{\r\nstruct inode *inode;\r\nstruct ceph_inode_info *ci;\r\nstruct ceph_snap_context *snapc = page_snap_context(page);\r\ninode = page->mapping->host;\r\nci = ceph_inode(inode);\r\nif (offset != 0 || length != PAGE_CACHE_SIZE) {\r\ndout("%p invalidatepage %p idx %lu partial dirty page %u~%u\n",\r\ninode, page, page->index, offset, length);\r\nreturn;\r\n}\r\nceph_invalidate_fscache_page(inode, page);\r\nif (!PagePrivate(page))\r\nreturn;\r\nif (!PageDirty(page))\r\npr_err("%p invalidatepage %p page not dirty\n", inode, page);\r\nClearPageChecked(page);\r\ndout("%p invalidatepage %p idx %lu full dirty page\n",\r\ninode, page, page->index);\r\nceph_put_wrbuffer_cap_refs(ci, 1, snapc);\r\nceph_put_snap_context(snapc);\r\npage->private = 0;\r\nClearPagePrivate(page);\r\n}\r\nstatic int ceph_releasepage(struct page *page, gfp_t g)\r\n{\r\nstruct inode *inode = page->mapping ? page->mapping->host : NULL;\r\ndout("%p releasepage %p idx %lu\n", inode, page, page->index);\r\nWARN_ON(PageDirty(page));\r\nif (!ceph_release_fscache_page(page, g))\r\nreturn 0;\r\nreturn !PagePrivate(page);\r\n}\r\nstatic int readpage_nounlock(struct file *filp, struct page *page)\r\n{\r\nstruct inode *inode = file_inode(filp);\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_osd_client *osdc =\r\n&ceph_inode_to_client(inode)->client->osdc;\r\nint err = 0;\r\nu64 len = PAGE_CACHE_SIZE;\r\nerr = ceph_readpage_from_fscache(inode, page);\r\nif (err == 0)\r\ngoto out;\r\ndout("readpage inode %p file %p page %p index %lu\n",\r\ninode, filp, page, page->index);\r\nerr = ceph_osdc_readpages(osdc, ceph_vino(inode), &ci->i_layout,\r\n(u64) page_offset(page), &len,\r\nci->i_truncate_seq, ci->i_truncate_size,\r\n&page, 1, 0);\r\nif (err == -ENOENT)\r\nerr = 0;\r\nif (err < 0) {\r\nSetPageError(page);\r\nceph_fscache_readpage_cancel(inode, page);\r\ngoto out;\r\n}\r\nif (err < PAGE_CACHE_SIZE)\r\nzero_user_segment(page, err, PAGE_CACHE_SIZE);\r\nelse\r\nflush_dcache_page(page);\r\nSetPageUptodate(page);\r\nceph_readpage_to_fscache(inode, page);\r\nout:\r\nreturn err < 0 ? err : 0;\r\n}\r\nstatic int ceph_readpage(struct file *filp, struct page *page)\r\n{\r\nint r = readpage_nounlock(filp, page);\r\nunlock_page(page);\r\nreturn r;\r\n}\r\nstatic void finish_read(struct ceph_osd_request *req, struct ceph_msg *msg)\r\n{\r\nstruct inode *inode = req->r_inode;\r\nstruct ceph_osd_data *osd_data;\r\nint rc = req->r_result;\r\nint bytes = le32_to_cpu(msg->hdr.data_len);\r\nint num_pages;\r\nint i;\r\ndout("finish_read %p req %p rc %d bytes %d\n", inode, req, rc, bytes);\r\nosd_data = osd_req_op_extent_osd_data(req, 0);\r\nBUG_ON(osd_data->type != CEPH_OSD_DATA_TYPE_PAGES);\r\nnum_pages = calc_pages_for((u64)osd_data->alignment,\r\n(u64)osd_data->length);\r\nfor (i = 0; i < num_pages; i++) {\r\nstruct page *page = osd_data->pages[i];\r\nif (rc < 0)\r\ngoto unlock;\r\nif (bytes < (int)PAGE_CACHE_SIZE) {\r\nint s = bytes < 0 ? 0 : bytes;\r\nzero_user_segment(page, s, PAGE_CACHE_SIZE);\r\n}\r\ndout("finish_read %p uptodate %p idx %lu\n", inode, page,\r\npage->index);\r\nflush_dcache_page(page);\r\nSetPageUptodate(page);\r\nceph_readpage_to_fscache(inode, page);\r\nunlock:\r\nunlock_page(page);\r\npage_cache_release(page);\r\nbytes -= PAGE_CACHE_SIZE;\r\n}\r\nkfree(osd_data->pages);\r\n}\r\nstatic void ceph_unlock_page_vector(struct page **pages, int num_pages)\r\n{\r\nint i;\r\nfor (i = 0; i < num_pages; i++)\r\nunlock_page(pages[i]);\r\n}\r\nstatic int start_read(struct inode *inode, struct list_head *page_list, int max)\r\n{\r\nstruct ceph_osd_client *osdc =\r\n&ceph_inode_to_client(inode)->client->osdc;\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct page *page = list_entry(page_list->prev, struct page, lru);\r\nstruct ceph_vino vino;\r\nstruct ceph_osd_request *req;\r\nu64 off;\r\nu64 len;\r\nint i;\r\nstruct page **pages;\r\npgoff_t next_index;\r\nint nr_pages = 0;\r\nint ret;\r\noff = (u64) page_offset(page);\r\nnext_index = page->index;\r\nlist_for_each_entry_reverse(page, page_list, lru) {\r\nif (page->index != next_index)\r\nbreak;\r\nnr_pages++;\r\nnext_index++;\r\nif (max && nr_pages == max)\r\nbreak;\r\n}\r\nlen = nr_pages << PAGE_CACHE_SHIFT;\r\ndout("start_read %p nr_pages %d is %lld~%lld\n", inode, nr_pages,\r\noff, len);\r\nvino = ceph_vino(inode);\r\nreq = ceph_osdc_new_request(osdc, &ci->i_layout, vino, off, &len,\r\n1, CEPH_OSD_OP_READ,\r\nCEPH_OSD_FLAG_READ, NULL,\r\nci->i_truncate_seq, ci->i_truncate_size,\r\nfalse);\r\nif (IS_ERR(req))\r\nreturn PTR_ERR(req);\r\nnr_pages = calc_pages_for(0, len);\r\npages = kmalloc(sizeof(*pages) * nr_pages, GFP_NOFS);\r\nret = -ENOMEM;\r\nif (!pages)\r\ngoto out;\r\nfor (i = 0; i < nr_pages; ++i) {\r\npage = list_entry(page_list->prev, struct page, lru);\r\nBUG_ON(PageLocked(page));\r\nlist_del(&page->lru);\r\ndout("start_read %p adding %p idx %lu\n", inode, page,\r\npage->index);\r\nif (add_to_page_cache_lru(page, &inode->i_data, page->index,\r\nGFP_NOFS)) {\r\nceph_fscache_uncache_page(inode, page);\r\npage_cache_release(page);\r\ndout("start_read %p add_to_page_cache failed %p\n",\r\ninode, page);\r\nnr_pages = i;\r\ngoto out_pages;\r\n}\r\npages[i] = page;\r\n}\r\nosd_req_op_extent_osd_data_pages(req, 0, pages, len, 0, false, false);\r\nreq->r_callback = finish_read;\r\nreq->r_inode = inode;\r\nceph_osdc_build_request(req, off, NULL, vino.snap, NULL);\r\ndout("start_read %p starting %p %lld~%lld\n", inode, req, off, len);\r\nret = ceph_osdc_start_request(osdc, req, false);\r\nif (ret < 0)\r\ngoto out_pages;\r\nceph_osdc_put_request(req);\r\nreturn nr_pages;\r\nout_pages:\r\nceph_unlock_page_vector(pages, nr_pages);\r\nceph_release_page_vector(pages, nr_pages);\r\nout:\r\nceph_osdc_put_request(req);\r\nreturn ret;\r\n}\r\nstatic int ceph_readpages(struct file *file, struct address_space *mapping,\r\nstruct list_head *page_list, unsigned nr_pages)\r\n{\r\nstruct inode *inode = file_inode(file);\r\nstruct ceph_fs_client *fsc = ceph_inode_to_client(inode);\r\nint rc = 0;\r\nint max = 0;\r\nrc = ceph_readpages_from_fscache(mapping->host, mapping, page_list,\r\n&nr_pages);\r\nif (rc == 0)\r\ngoto out;\r\nif (fsc->mount_options->rsize >= PAGE_CACHE_SIZE)\r\nmax = (fsc->mount_options->rsize + PAGE_CACHE_SIZE - 1)\r\n>> PAGE_SHIFT;\r\ndout("readpages %p file %p nr_pages %d max %d\n", inode,\r\nfile, nr_pages,\r\nmax);\r\nwhile (!list_empty(page_list)) {\r\nrc = start_read(inode, page_list, max);\r\nif (rc < 0)\r\ngoto out;\r\nBUG_ON(rc == 0);\r\n}\r\nout:\r\nceph_fscache_readpages_cancel(inode, page_list);\r\ndout("readpages %p file %p ret %d\n", inode, file, rc);\r\nreturn rc;\r\n}\r\nstatic struct ceph_snap_context *get_oldest_context(struct inode *inode,\r\nu64 *snap_size)\r\n{\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_snap_context *snapc = NULL;\r\nstruct ceph_cap_snap *capsnap = NULL;\r\nspin_lock(&ci->i_ceph_lock);\r\nlist_for_each_entry(capsnap, &ci->i_cap_snaps, ci_item) {\r\ndout(" cap_snap %p snapc %p has %d dirty pages\n", capsnap,\r\ncapsnap->context, capsnap->dirty_pages);\r\nif (capsnap->dirty_pages) {\r\nsnapc = ceph_get_snap_context(capsnap->context);\r\nif (snap_size)\r\n*snap_size = capsnap->size;\r\nbreak;\r\n}\r\n}\r\nif (!snapc && ci->i_wrbuffer_ref_head) {\r\nsnapc = ceph_get_snap_context(ci->i_head_snapc);\r\ndout(" head snapc %p has %d dirty pages\n",\r\nsnapc, ci->i_wrbuffer_ref_head);\r\n}\r\nspin_unlock(&ci->i_ceph_lock);\r\nreturn snapc;\r\n}\r\nstatic int writepage_nounlock(struct page *page, struct writeback_control *wbc)\r\n{\r\nstruct inode *inode;\r\nstruct ceph_inode_info *ci;\r\nstruct ceph_fs_client *fsc;\r\nstruct ceph_osd_client *osdc;\r\nstruct ceph_snap_context *snapc, *oldest;\r\nloff_t page_off = page_offset(page);\r\nlong writeback_stat;\r\nu64 truncate_size, snap_size = 0;\r\nu32 truncate_seq;\r\nint err = 0, len = PAGE_CACHE_SIZE;\r\ndout("writepage %p idx %lu\n", page, page->index);\r\nif (!page->mapping || !page->mapping->host) {\r\ndout("writepage %p - no mapping\n", page);\r\nreturn -EFAULT;\r\n}\r\ninode = page->mapping->host;\r\nci = ceph_inode(inode);\r\nfsc = ceph_inode_to_client(inode);\r\nosdc = &fsc->client->osdc;\r\nsnapc = page_snap_context(page);\r\nif (snapc == NULL) {\r\ndout("writepage %p page %p not dirty?\n", inode, page);\r\ngoto out;\r\n}\r\noldest = get_oldest_context(inode, &snap_size);\r\nif (snapc->seq > oldest->seq) {\r\ndout("writepage %p page %p snapc %p not writeable - noop\n",\r\ninode, page, snapc);\r\nWARN_ON((current->flags & PF_MEMALLOC) == 0);\r\nceph_put_snap_context(oldest);\r\ngoto out;\r\n}\r\nceph_put_snap_context(oldest);\r\nspin_lock(&ci->i_ceph_lock);\r\ntruncate_seq = ci->i_truncate_seq;\r\ntruncate_size = ci->i_truncate_size;\r\nif (!snap_size)\r\nsnap_size = i_size_read(inode);\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (page_off >= snap_size) {\r\ndout("%p page eof %llu\n", page, snap_size);\r\ngoto out;\r\n}\r\nif (snap_size < page_off + len)\r\nlen = snap_size - page_off;\r\ndout("writepage %p page %p index %lu on %llu~%u snapc %p\n",\r\ninode, page, page->index, page_off, len, snapc);\r\nwriteback_stat = atomic_long_inc_return(&fsc->writeback_count);\r\nif (writeback_stat >\r\nCONGESTION_ON_THRESH(fsc->mount_options->congestion_kb))\r\nset_bdi_congested(&fsc->backing_dev_info, BLK_RW_ASYNC);\r\nceph_readpage_to_fscache(inode, page);\r\nset_page_writeback(page);\r\nerr = ceph_osdc_writepages(osdc, ceph_vino(inode),\r\n&ci->i_layout, snapc,\r\npage_off, len,\r\ntruncate_seq, truncate_size,\r\n&inode->i_mtime, &page, 1);\r\nif (err < 0) {\r\ndout("writepage setting page/mapping error %d %p\n", err, page);\r\nSetPageError(page);\r\nmapping_set_error(&inode->i_data, err);\r\nif (wbc)\r\nwbc->pages_skipped++;\r\n} else {\r\ndout("writepage cleaned page %p\n", page);\r\nerr = 0;\r\n}\r\npage->private = 0;\r\nClearPagePrivate(page);\r\nend_page_writeback(page);\r\nceph_put_wrbuffer_cap_refs(ci, 1, snapc);\r\nceph_put_snap_context(snapc);\r\nout:\r\nreturn err;\r\n}\r\nstatic int ceph_writepage(struct page *page, struct writeback_control *wbc)\r\n{\r\nint err;\r\nstruct inode *inode = page->mapping->host;\r\nBUG_ON(!inode);\r\nihold(inode);\r\nerr = writepage_nounlock(page, wbc);\r\nunlock_page(page);\r\niput(inode);\r\nreturn err;\r\n}\r\nstatic void ceph_release_pages(struct page **pages, int num)\r\n{\r\nstruct pagevec pvec;\r\nint i;\r\npagevec_init(&pvec, 0);\r\nfor (i = 0; i < num; i++) {\r\nif (pagevec_add(&pvec, pages[i]) == 0)\r\npagevec_release(&pvec);\r\n}\r\npagevec_release(&pvec);\r\n}\r\nstatic void writepages_finish(struct ceph_osd_request *req,\r\nstruct ceph_msg *msg)\r\n{\r\nstruct inode *inode = req->r_inode;\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_osd_data *osd_data;\r\nunsigned wrote;\r\nstruct page *page;\r\nint num_pages;\r\nint i;\r\nstruct ceph_snap_context *snapc = req->r_snapc;\r\nstruct address_space *mapping = inode->i_mapping;\r\nint rc = req->r_result;\r\nu64 bytes = req->r_ops[0].extent.length;\r\nstruct ceph_fs_client *fsc = ceph_inode_to_client(inode);\r\nlong writeback_stat;\r\nunsigned issued = ceph_caps_issued(ci);\r\nosd_data = osd_req_op_extent_osd_data(req, 0);\r\nBUG_ON(osd_data->type != CEPH_OSD_DATA_TYPE_PAGES);\r\nnum_pages = calc_pages_for((u64)osd_data->alignment,\r\n(u64)osd_data->length);\r\nif (rc >= 0) {\r\nwrote = num_pages;\r\n} else {\r\nwrote = 0;\r\nmapping_set_error(mapping, rc);\r\n}\r\ndout("writepages_finish %p rc %d bytes %llu wrote %d (pages)\n",\r\ninode, rc, bytes, wrote);\r\nfor (i = 0; i < num_pages; i++) {\r\npage = osd_data->pages[i];\r\nBUG_ON(!page);\r\nWARN_ON(!PageUptodate(page));\r\nwriteback_stat =\r\natomic_long_dec_return(&fsc->writeback_count);\r\nif (writeback_stat <\r\nCONGESTION_OFF_THRESH(fsc->mount_options->congestion_kb))\r\nclear_bdi_congested(&fsc->backing_dev_info,\r\nBLK_RW_ASYNC);\r\nceph_put_snap_context(page_snap_context(page));\r\npage->private = 0;\r\nClearPagePrivate(page);\r\ndout("unlocking %d %p\n", i, page);\r\nend_page_writeback(page);\r\nif ((issued & (CEPH_CAP_FILE_CACHE|CEPH_CAP_FILE_LAZYIO)) == 0)\r\ngeneric_error_remove_page(inode->i_mapping, page);\r\nunlock_page(page);\r\n}\r\ndout("%p wrote+cleaned %d pages\n", inode, wrote);\r\nceph_put_wrbuffer_cap_refs(ci, num_pages, snapc);\r\nceph_release_pages(osd_data->pages, num_pages);\r\nif (osd_data->pages_from_pool)\r\nmempool_free(osd_data->pages,\r\nceph_sb_to_client(inode->i_sb)->wb_pagevec_pool);\r\nelse\r\nkfree(osd_data->pages);\r\nceph_osdc_put_request(req);\r\n}\r\nstatic int ceph_writepages_start(struct address_space *mapping,\r\nstruct writeback_control *wbc)\r\n{\r\nstruct inode *inode = mapping->host;\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_fs_client *fsc = ceph_inode_to_client(inode);\r\nstruct ceph_vino vino = ceph_vino(inode);\r\npgoff_t index, start, end;\r\nint range_whole = 0;\r\nint should_loop = 1;\r\npgoff_t max_pages = 0, max_pages_ever = 0;\r\nstruct ceph_snap_context *snapc = NULL, *last_snapc = NULL, *pgsnapc;\r\nstruct pagevec pvec;\r\nint done = 0;\r\nint rc = 0;\r\nunsigned wsize = 1 << inode->i_blkbits;\r\nstruct ceph_osd_request *req = NULL;\r\nint do_sync;\r\nu64 truncate_size, snap_size;\r\nu32 truncate_seq;\r\nif ((wbc->sync_mode == WB_SYNC_ALL) ||\r\nceph_caps_revoking(ci, CEPH_CAP_FILE_BUFFER))\r\ndo_sync = 1;\r\ndout("writepages_start %p dosync=%d (mode=%s)\n",\r\ninode, do_sync,\r\nwbc->sync_mode == WB_SYNC_NONE ? "NONE" :\r\n(wbc->sync_mode == WB_SYNC_ALL ? "ALL" : "HOLD"));\r\nif (fsc->mount_state == CEPH_MOUNT_SHUTDOWN) {\r\npr_warn("writepage_start %p on forced umount\n", inode);\r\nreturn -EIO;\r\n}\r\nif (fsc->mount_options->wsize && fsc->mount_options->wsize < wsize)\r\nwsize = fsc->mount_options->wsize;\r\nif (wsize < PAGE_CACHE_SIZE)\r\nwsize = PAGE_CACHE_SIZE;\r\nmax_pages_ever = wsize >> PAGE_CACHE_SHIFT;\r\npagevec_init(&pvec, 0);\r\nif (wbc->range_cyclic) {\r\nstart = mapping->writeback_index;\r\nend = -1;\r\ndout(" cyclic, start at %lu\n", start);\r\n} else {\r\nstart = wbc->range_start >> PAGE_CACHE_SHIFT;\r\nend = wbc->range_end >> PAGE_CACHE_SHIFT;\r\nif (wbc->range_start == 0 && wbc->range_end == LLONG_MAX)\r\nrange_whole = 1;\r\nshould_loop = 0;\r\ndout(" not cyclic, %lu to %lu\n", start, end);\r\n}\r\nindex = start;\r\nretry:\r\nceph_put_snap_context(snapc);\r\nsnap_size = 0;\r\nsnapc = get_oldest_context(inode, &snap_size);\r\nif (!snapc) {\r\ndout(" no snap context with dirty data?\n");\r\ngoto out;\r\n}\r\nif (snap_size == 0)\r\nsnap_size = i_size_read(inode);\r\ndout(" oldest snapc is %p seq %lld (%d snaps)\n",\r\nsnapc, snapc->seq, snapc->num_snaps);\r\nspin_lock(&ci->i_ceph_lock);\r\ntruncate_seq = ci->i_truncate_seq;\r\ntruncate_size = ci->i_truncate_size;\r\nif (!snap_size)\r\nsnap_size = i_size_read(inode);\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (last_snapc && snapc != last_snapc) {\r\ndout(" snapc differs from last pass, restarting at %lu\n",\r\nindex);\r\nindex = start;\r\n}\r\nlast_snapc = snapc;\r\nwhile (!done && index <= end) {\r\nint num_ops = do_sync ? 2 : 1;\r\nunsigned i;\r\nint first;\r\npgoff_t next;\r\nint pvec_pages, locked_pages;\r\nstruct page **pages = NULL;\r\nmempool_t *pool = NULL;\r\nstruct page *page;\r\nint want;\r\nu64 offset, len;\r\nlong writeback_stat;\r\nnext = 0;\r\nlocked_pages = 0;\r\nmax_pages = max_pages_ever;\r\nget_more_pages:\r\nfirst = -1;\r\nwant = min(end - index,\r\nmin((pgoff_t)PAGEVEC_SIZE,\r\nmax_pages - (pgoff_t)locked_pages) - 1)\r\n+ 1;\r\npvec_pages = pagevec_lookup_tag(&pvec, mapping, &index,\r\nPAGECACHE_TAG_DIRTY,\r\nwant);\r\ndout("pagevec_lookup_tag got %d\n", pvec_pages);\r\nif (!pvec_pages && !locked_pages)\r\nbreak;\r\nfor (i = 0; i < pvec_pages && locked_pages < max_pages; i++) {\r\npage = pvec.pages[i];\r\ndout("? %p idx %lu\n", page, page->index);\r\nif (locked_pages == 0)\r\nlock_page(page);\r\nelse if (!trylock_page(page))\r\nbreak;\r\nif (unlikely(!PageDirty(page)) ||\r\nunlikely(page->mapping != mapping)) {\r\ndout("!dirty or !mapping %p\n", page);\r\nunlock_page(page);\r\nbreak;\r\n}\r\nif (!wbc->range_cyclic && page->index > end) {\r\ndout("end of range %p\n", page);\r\ndone = 1;\r\nunlock_page(page);\r\nbreak;\r\n}\r\nif (next && (page->index != next)) {\r\ndout("not consecutive %p\n", page);\r\nunlock_page(page);\r\nbreak;\r\n}\r\nif (wbc->sync_mode != WB_SYNC_NONE) {\r\ndout("waiting on writeback %p\n", page);\r\nwait_on_page_writeback(page);\r\n}\r\nif (page_offset(page) >= snap_size) {\r\ndout("%p page eof %llu\n", page, snap_size);\r\ndone = 1;\r\nunlock_page(page);\r\nbreak;\r\n}\r\nif (PageWriteback(page)) {\r\ndout("%p under writeback\n", page);\r\nunlock_page(page);\r\nbreak;\r\n}\r\npgsnapc = page_snap_context(page);\r\nif (pgsnapc->seq > snapc->seq) {\r\ndout("page snapc %p %lld > oldest %p %lld\n",\r\npgsnapc, pgsnapc->seq, snapc, snapc->seq);\r\nunlock_page(page);\r\nif (!locked_pages)\r\ncontinue;\r\nbreak;\r\n}\r\nif (!clear_page_dirty_for_io(page)) {\r\ndout("%p !clear_page_dirty_for_io\n", page);\r\nunlock_page(page);\r\nbreak;\r\n}\r\nif (locked_pages == 0) {\r\nBUG_ON(pages);\r\noffset = (u64)page_offset(page);\r\nlen = wsize;\r\nreq = ceph_osdc_new_request(&fsc->client->osdc,\r\n&ci->i_layout, vino,\r\noffset, &len, num_ops,\r\nCEPH_OSD_OP_WRITE,\r\nCEPH_OSD_FLAG_WRITE |\r\nCEPH_OSD_FLAG_ONDISK,\r\nsnapc, truncate_seq,\r\ntruncate_size, true);\r\nif (IS_ERR(req)) {\r\nrc = PTR_ERR(req);\r\nunlock_page(page);\r\nbreak;\r\n}\r\nreq->r_callback = writepages_finish;\r\nreq->r_inode = inode;\r\nmax_pages = calc_pages_for(0, (u64)len);\r\npages = kmalloc(max_pages * sizeof (*pages),\r\nGFP_NOFS);\r\nif (!pages) {\r\npool = fsc->wb_pagevec_pool;\r\npages = mempool_alloc(pool, GFP_NOFS);\r\nBUG_ON(!pages);\r\n}\r\n}\r\nif (first < 0)\r\nfirst = i;\r\ndout("%p will write page %p idx %lu\n",\r\ninode, page, page->index);\r\nwriteback_stat =\r\natomic_long_inc_return(&fsc->writeback_count);\r\nif (writeback_stat > CONGESTION_ON_THRESH(\r\nfsc->mount_options->congestion_kb)) {\r\nset_bdi_congested(&fsc->backing_dev_info,\r\nBLK_RW_ASYNC);\r\n}\r\nset_page_writeback(page);\r\npages[locked_pages] = page;\r\nlocked_pages++;\r\nnext = page->index + 1;\r\n}\r\nif (!locked_pages)\r\ngoto release_pvec_pages;\r\nif (i) {\r\nint j;\r\nBUG_ON(!locked_pages || first < 0);\r\nif (pvec_pages && i == pvec_pages &&\r\nlocked_pages < max_pages) {\r\ndout("reached end pvec, trying for more\n");\r\npagevec_reinit(&pvec);\r\ngoto get_more_pages;\r\n}\r\nfor (j = i; j < pvec_pages; j++) {\r\ndout(" pvec leftover page %p\n",\r\npvec.pages[j]);\r\npvec.pages[j-i+first] = pvec.pages[j];\r\n}\r\npvec.nr -= i-first;\r\n}\r\noffset = page_offset(pages[0]);\r\nlen = min(snap_size - offset,\r\n(u64)locked_pages << PAGE_CACHE_SHIFT);\r\ndout("writepages got %d pages at %llu~%llu\n",\r\nlocked_pages, offset, len);\r\nosd_req_op_extent_osd_data_pages(req, 0, pages, len, 0,\r\n!!pool, false);\r\npages = NULL;\r\npool = NULL;\r\nosd_req_op_extent_update(req, 0, len);\r\nvino = ceph_vino(inode);\r\nceph_osdc_build_request(req, offset, snapc, vino.snap,\r\n&inode->i_mtime);\r\nrc = ceph_osdc_start_request(&fsc->client->osdc, req, true);\r\nBUG_ON(rc);\r\nreq = NULL;\r\nindex = next;\r\nwbc->nr_to_write -= locked_pages;\r\nif (wbc->nr_to_write <= 0)\r\ndone = 1;\r\nrelease_pvec_pages:\r\ndout("pagevec_release on %d pages (%p)\n", (int)pvec.nr,\r\npvec.nr ? pvec.pages[0] : NULL);\r\npagevec_release(&pvec);\r\nif (locked_pages && !done)\r\ngoto retry;\r\n}\r\nif (should_loop && !done) {\r\ndout("writepages looping back to beginning of file\n");\r\nshould_loop = 0;\r\nindex = 0;\r\ngoto retry;\r\n}\r\nif (wbc->range_cyclic || (range_whole && wbc->nr_to_write > 0))\r\nmapping->writeback_index = index;\r\nout:\r\nif (req)\r\nceph_osdc_put_request(req);\r\nceph_put_snap_context(snapc);\r\ndout("writepages done, rc = %d\n", rc);\r\nreturn rc;\r\n}\r\nstatic int context_is_writeable_or_written(struct inode *inode,\r\nstruct ceph_snap_context *snapc)\r\n{\r\nstruct ceph_snap_context *oldest = get_oldest_context(inode, NULL);\r\nint ret = !oldest || snapc->seq <= oldest->seq;\r\nceph_put_snap_context(oldest);\r\nreturn ret;\r\n}\r\nstatic int ceph_update_writeable_page(struct file *file,\r\nloff_t pos, unsigned len,\r\nstruct page *page)\r\n{\r\nstruct inode *inode = file_inode(file);\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_mds_client *mdsc = ceph_inode_to_client(inode)->mdsc;\r\nloff_t page_off = pos & PAGE_CACHE_MASK;\r\nint pos_in_page = pos & ~PAGE_CACHE_MASK;\r\nint end_in_page = pos_in_page + len;\r\nloff_t i_size;\r\nint r;\r\nstruct ceph_snap_context *snapc, *oldest;\r\nretry_locked:\r\nwait_on_page_writeback(page);\r\nBUG_ON(!ci->i_snap_realm);\r\ndown_read(&mdsc->snap_rwsem);\r\nBUG_ON(!ci->i_snap_realm->cached_context);\r\nsnapc = page_snap_context(page);\r\nif (snapc && snapc != ci->i_head_snapc) {\r\noldest = get_oldest_context(inode, NULL);\r\nup_read(&mdsc->snap_rwsem);\r\nif (snapc->seq > oldest->seq) {\r\nceph_put_snap_context(oldest);\r\ndout(" page %p snapc %p not current or oldest\n",\r\npage, snapc);\r\nsnapc = ceph_get_snap_context(snapc);\r\nunlock_page(page);\r\nceph_queue_writeback(inode);\r\nr = wait_event_interruptible(ci->i_cap_wq,\r\ncontext_is_writeable_or_written(inode, snapc));\r\nceph_put_snap_context(snapc);\r\nif (r == -ERESTARTSYS)\r\nreturn r;\r\nreturn -EAGAIN;\r\n}\r\nceph_put_snap_context(oldest);\r\ndout(" page %p snapc %p not current, but oldest\n",\r\npage, snapc);\r\nif (!clear_page_dirty_for_io(page))\r\ngoto retry_locked;\r\nr = writepage_nounlock(page, NULL);\r\nif (r < 0)\r\ngoto fail_nosnap;\r\ngoto retry_locked;\r\n}\r\nif (PageUptodate(page)) {\r\ndout(" page %p already uptodate\n", page);\r\nreturn 0;\r\n}\r\nif (pos_in_page == 0 && len == PAGE_CACHE_SIZE)\r\nreturn 0;\r\ni_size = inode->i_size;\r\nif (i_size + len > inode->i_sb->s_maxbytes) {\r\nr = -EINVAL;\r\ngoto fail;\r\n}\r\nif (page_off >= i_size ||\r\n(pos_in_page == 0 && (pos+len) >= i_size &&\r\nend_in_page - pos_in_page != PAGE_CACHE_SIZE)) {\r\ndout(" zeroing %p 0 - %d and %d - %d\n",\r\npage, pos_in_page, end_in_page, (int)PAGE_CACHE_SIZE);\r\nzero_user_segments(page,\r\n0, pos_in_page,\r\nend_in_page, PAGE_CACHE_SIZE);\r\nreturn 0;\r\n}\r\nup_read(&mdsc->snap_rwsem);\r\nr = readpage_nounlock(file, page);\r\nif (r < 0)\r\ngoto fail_nosnap;\r\ngoto retry_locked;\r\nfail:\r\nup_read(&mdsc->snap_rwsem);\r\nfail_nosnap:\r\nunlock_page(page);\r\nreturn r;\r\n}\r\nstatic int ceph_write_begin(struct file *file, struct address_space *mapping,\r\nloff_t pos, unsigned len, unsigned flags,\r\nstruct page **pagep, void **fsdata)\r\n{\r\nstruct inode *inode = file_inode(file);\r\nstruct page *page;\r\npgoff_t index = pos >> PAGE_CACHE_SHIFT;\r\nint r;\r\ndo {\r\npage = grab_cache_page_write_begin(mapping, index, 0);\r\nif (!page)\r\nreturn -ENOMEM;\r\n*pagep = page;\r\ndout("write_begin file %p inode %p page %p %d~%d\n", file,\r\ninode, page, (int)pos, (int)len);\r\nr = ceph_update_writeable_page(file, pos, len, page);\r\n} while (r == -EAGAIN);\r\nreturn r;\r\n}\r\nstatic int ceph_write_end(struct file *file, struct address_space *mapping,\r\nloff_t pos, unsigned len, unsigned copied,\r\nstruct page *page, void *fsdata)\r\n{\r\nstruct inode *inode = file_inode(file);\r\nstruct ceph_fs_client *fsc = ceph_inode_to_client(inode);\r\nstruct ceph_mds_client *mdsc = fsc->mdsc;\r\nunsigned from = pos & (PAGE_CACHE_SIZE - 1);\r\nint check_cap = 0;\r\ndout("write_end file %p inode %p page %p %d~%d (%d)\n", file,\r\ninode, page, (int)pos, (int)copied, (int)len);\r\nif (copied < len)\r\nzero_user_segment(page, from+copied, len);\r\nif (pos+copied > inode->i_size)\r\ncheck_cap = ceph_inode_set_size(inode, pos+copied);\r\nif (!PageUptodate(page))\r\nSetPageUptodate(page);\r\nset_page_dirty(page);\r\nunlock_page(page);\r\nup_read(&mdsc->snap_rwsem);\r\npage_cache_release(page);\r\nif (check_cap)\r\nceph_check_caps(ceph_inode(inode), CHECK_CAPS_AUTHONLY, NULL);\r\nreturn copied;\r\n}\r\nstatic ssize_t ceph_direct_io(int rw, struct kiocb *iocb,\r\nstruct iov_iter *iter,\r\nloff_t pos)\r\n{\r\nWARN_ON(1);\r\nreturn -EINVAL;\r\n}\r\nstatic int ceph_filemap_fault(struct vm_area_struct *vma, struct vm_fault *vmf)\r\n{\r\nstruct inode *inode = file_inode(vma->vm_file);\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_file_info *fi = vma->vm_file->private_data;\r\nloff_t off = vmf->pgoff << PAGE_CACHE_SHIFT;\r\nint want, got, ret;\r\ndout("filemap_fault %p %llx.%llx %llu~%zd trying to get caps\n",\r\ninode, ceph_vinop(inode), off, (size_t)PAGE_CACHE_SIZE);\r\nif (fi->fmode & CEPH_FILE_MODE_LAZY)\r\nwant = CEPH_CAP_FILE_CACHE | CEPH_CAP_FILE_LAZYIO;\r\nelse\r\nwant = CEPH_CAP_FILE_CACHE;\r\nwhile (1) {\r\ngot = 0;\r\nret = ceph_get_caps(ci, CEPH_CAP_FILE_RD, want, &got, -1);\r\nif (ret == 0)\r\nbreak;\r\nif (ret != -ERESTARTSYS) {\r\nWARN_ON(1);\r\nreturn VM_FAULT_SIGBUS;\r\n}\r\n}\r\ndout("filemap_fault %p %llu~%zd got cap refs on %s\n",\r\ninode, off, (size_t)PAGE_CACHE_SIZE, ceph_cap_string(got));\r\nret = filemap_fault(vma, vmf);\r\ndout("filemap_fault %p %llu~%zd dropping cap refs on %s ret %d\n",\r\ninode, off, (size_t)PAGE_CACHE_SIZE, ceph_cap_string(got), ret);\r\nceph_put_cap_refs(ci, got);\r\nreturn ret;\r\n}\r\nstatic int ceph_page_mkwrite(struct vm_area_struct *vma, struct vm_fault *vmf)\r\n{\r\nstruct inode *inode = file_inode(vma->vm_file);\r\nstruct ceph_inode_info *ci = ceph_inode(inode);\r\nstruct ceph_file_info *fi = vma->vm_file->private_data;\r\nstruct ceph_mds_client *mdsc = ceph_inode_to_client(inode)->mdsc;\r\nstruct page *page = vmf->page;\r\nloff_t off = page_offset(page);\r\nloff_t size = i_size_read(inode);\r\nsize_t len;\r\nint want, got, ret;\r\nif (off + PAGE_CACHE_SIZE <= size)\r\nlen = PAGE_CACHE_SIZE;\r\nelse\r\nlen = size & ~PAGE_CACHE_MASK;\r\ndout("page_mkwrite %p %llx.%llx %llu~%zd getting caps i_size %llu\n",\r\ninode, ceph_vinop(inode), off, len, size);\r\nif (fi->fmode & CEPH_FILE_MODE_LAZY)\r\nwant = CEPH_CAP_FILE_BUFFER | CEPH_CAP_FILE_LAZYIO;\r\nelse\r\nwant = CEPH_CAP_FILE_BUFFER;\r\nwhile (1) {\r\ngot = 0;\r\nret = ceph_get_caps(ci, CEPH_CAP_FILE_WR, want, &got, off + len);\r\nif (ret == 0)\r\nbreak;\r\nif (ret != -ERESTARTSYS) {\r\nWARN_ON(1);\r\nreturn VM_FAULT_SIGBUS;\r\n}\r\n}\r\ndout("page_mkwrite %p %llu~%zd got cap refs on %s\n",\r\ninode, off, len, ceph_cap_string(got));\r\nfile_update_time(vma->vm_file);\r\nlock_page(page);\r\nret = VM_FAULT_NOPAGE;\r\nif ((off > size) ||\r\n(page->mapping != inode->i_mapping))\r\ngoto out;\r\nret = ceph_update_writeable_page(vma->vm_file, off, len, page);\r\nif (ret == 0) {\r\nset_page_dirty(page);\r\nup_read(&mdsc->snap_rwsem);\r\nret = VM_FAULT_LOCKED;\r\n} else {\r\nif (ret == -ENOMEM)\r\nret = VM_FAULT_OOM;\r\nelse\r\nret = VM_FAULT_SIGBUS;\r\n}\r\nout:\r\nif (ret != VM_FAULT_LOCKED) {\r\nunlock_page(page);\r\n} else {\r\nint dirty;\r\nspin_lock(&ci->i_ceph_lock);\r\ndirty = __ceph_mark_dirty_caps(ci, CEPH_CAP_FILE_WR);\r\nspin_unlock(&ci->i_ceph_lock);\r\nif (dirty)\r\n__mark_inode_dirty(inode, dirty);\r\n}\r\ndout("page_mkwrite %p %llu~%zd dropping cap refs on %s ret %d\n",\r\ninode, off, len, ceph_cap_string(got), ret);\r\nceph_put_cap_refs(ci, got);\r\nreturn ret;\r\n}\r\nint ceph_mmap(struct file *file, struct vm_area_struct *vma)\r\n{\r\nstruct address_space *mapping = file->f_mapping;\r\nif (!mapping->a_ops->readpage)\r\nreturn -ENOEXEC;\r\nfile_accessed(file);\r\nvma->vm_ops = &ceph_vmops;\r\nreturn 0;\r\n}
