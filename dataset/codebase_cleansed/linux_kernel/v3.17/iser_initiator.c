static int iser_prepare_read_cmd(struct iscsi_task *task)\r\n{\r\nstruct iscsi_iser_task *iser_task = task->dd_data;\r\nstruct iser_device *device = iser_task->ib_conn->device;\r\nstruct iser_regd_buf *regd_buf;\r\nint err;\r\nstruct iser_hdr *hdr = &iser_task->desc.iser_header;\r\nstruct iser_data_buf *buf_in = &iser_task->data[ISER_DIR_IN];\r\nerr = iser_dma_map_task_data(iser_task,\r\nbuf_in,\r\nISER_DIR_IN,\r\nDMA_FROM_DEVICE);\r\nif (err)\r\nreturn err;\r\nif (scsi_prot_sg_count(iser_task->sc)) {\r\nstruct iser_data_buf *pbuf_in = &iser_task->prot[ISER_DIR_IN];\r\nerr = iser_dma_map_task_data(iser_task,\r\npbuf_in,\r\nISER_DIR_IN,\r\nDMA_FROM_DEVICE);\r\nif (err)\r\nreturn err;\r\n}\r\nerr = device->iser_reg_rdma_mem(iser_task, ISER_DIR_IN);\r\nif (err) {\r\niser_err("Failed to set up Data-IN RDMA\n");\r\nreturn err;\r\n}\r\nregd_buf = &iser_task->rdma_regd[ISER_DIR_IN];\r\nhdr->flags |= ISER_RSV;\r\nhdr->read_stag = cpu_to_be32(regd_buf->reg.rkey);\r\nhdr->read_va = cpu_to_be64(regd_buf->reg.va);\r\niser_dbg("Cmd itt:%d READ tags RKEY:%#.4X VA:%#llX\n",\r\ntask->itt, regd_buf->reg.rkey,\r\n(unsigned long long)regd_buf->reg.va);\r\nreturn 0;\r\n}\r\nstatic int\r\niser_prepare_write_cmd(struct iscsi_task *task,\r\nunsigned int imm_sz,\r\nunsigned int unsol_sz,\r\nunsigned int edtl)\r\n{\r\nstruct iscsi_iser_task *iser_task = task->dd_data;\r\nstruct iser_device *device = iser_task->ib_conn->device;\r\nstruct iser_regd_buf *regd_buf;\r\nint err;\r\nstruct iser_hdr *hdr = &iser_task->desc.iser_header;\r\nstruct iser_data_buf *buf_out = &iser_task->data[ISER_DIR_OUT];\r\nstruct ib_sge *tx_dsg = &iser_task->desc.tx_sg[1];\r\nerr = iser_dma_map_task_data(iser_task,\r\nbuf_out,\r\nISER_DIR_OUT,\r\nDMA_TO_DEVICE);\r\nif (err)\r\nreturn err;\r\nif (scsi_prot_sg_count(iser_task->sc)) {\r\nstruct iser_data_buf *pbuf_out = &iser_task->prot[ISER_DIR_OUT];\r\nerr = iser_dma_map_task_data(iser_task,\r\npbuf_out,\r\nISER_DIR_OUT,\r\nDMA_TO_DEVICE);\r\nif (err)\r\nreturn err;\r\n}\r\nerr = device->iser_reg_rdma_mem(iser_task, ISER_DIR_OUT);\r\nif (err != 0) {\r\niser_err("Failed to register write cmd RDMA mem\n");\r\nreturn err;\r\n}\r\nregd_buf = &iser_task->rdma_regd[ISER_DIR_OUT];\r\nif (unsol_sz < edtl) {\r\nhdr->flags |= ISER_WSV;\r\nhdr->write_stag = cpu_to_be32(regd_buf->reg.rkey);\r\nhdr->write_va = cpu_to_be64(regd_buf->reg.va + unsol_sz);\r\niser_dbg("Cmd itt:%d, WRITE tags, RKEY:%#.4X "\r\n"VA:%#llX + unsol:%d\n",\r\ntask->itt, regd_buf->reg.rkey,\r\n(unsigned long long)regd_buf->reg.va, unsol_sz);\r\n}\r\nif (imm_sz > 0) {\r\niser_dbg("Cmd itt:%d, WRITE, adding imm.data sz: %d\n",\r\ntask->itt, imm_sz);\r\ntx_dsg->addr = regd_buf->reg.va;\r\ntx_dsg->length = imm_sz;\r\ntx_dsg->lkey = regd_buf->reg.lkey;\r\niser_task->desc.num_sge = 2;\r\n}\r\nreturn 0;\r\n}\r\nstatic void iser_create_send_desc(struct iser_conn *ib_conn,\r\nstruct iser_tx_desc *tx_desc)\r\n{\r\nstruct iser_device *device = ib_conn->device;\r\nib_dma_sync_single_for_cpu(device->ib_device,\r\ntx_desc->dma_addr, ISER_HEADERS_LEN, DMA_TO_DEVICE);\r\nmemset(&tx_desc->iser_header, 0, sizeof(struct iser_hdr));\r\ntx_desc->iser_header.flags = ISER_VER;\r\ntx_desc->num_sge = 1;\r\nif (tx_desc->tx_sg[0].lkey != device->mr->lkey) {\r\ntx_desc->tx_sg[0].lkey = device->mr->lkey;\r\niser_dbg("sdesc %p lkey mismatch, fixing\n", tx_desc);\r\n}\r\n}\r\nstatic void iser_free_login_buf(struct iser_conn *ib_conn)\r\n{\r\nif (!ib_conn->login_buf)\r\nreturn;\r\nif (ib_conn->login_req_dma)\r\nib_dma_unmap_single(ib_conn->device->ib_device,\r\nib_conn->login_req_dma,\r\nISCSI_DEF_MAX_RECV_SEG_LEN, DMA_TO_DEVICE);\r\nif (ib_conn->login_resp_dma)\r\nib_dma_unmap_single(ib_conn->device->ib_device,\r\nib_conn->login_resp_dma,\r\nISER_RX_LOGIN_SIZE, DMA_FROM_DEVICE);\r\nkfree(ib_conn->login_buf);\r\nib_conn->login_req_dma = 0;\r\nib_conn->login_resp_dma = 0;\r\nib_conn->login_buf = NULL;\r\n}\r\nstatic int iser_alloc_login_buf(struct iser_conn *ib_conn)\r\n{\r\nstruct iser_device *device;\r\nint req_err, resp_err;\r\nBUG_ON(ib_conn->device == NULL);\r\ndevice = ib_conn->device;\r\nib_conn->login_buf = kmalloc(ISCSI_DEF_MAX_RECV_SEG_LEN +\r\nISER_RX_LOGIN_SIZE, GFP_KERNEL);\r\nif (!ib_conn->login_buf)\r\ngoto out_err;\r\nib_conn->login_req_buf = ib_conn->login_buf;\r\nib_conn->login_resp_buf = ib_conn->login_buf +\r\nISCSI_DEF_MAX_RECV_SEG_LEN;\r\nib_conn->login_req_dma = ib_dma_map_single(ib_conn->device->ib_device,\r\n(void *)ib_conn->login_req_buf,\r\nISCSI_DEF_MAX_RECV_SEG_LEN, DMA_TO_DEVICE);\r\nib_conn->login_resp_dma = ib_dma_map_single(ib_conn->device->ib_device,\r\n(void *)ib_conn->login_resp_buf,\r\nISER_RX_LOGIN_SIZE, DMA_FROM_DEVICE);\r\nreq_err = ib_dma_mapping_error(device->ib_device,\r\nib_conn->login_req_dma);\r\nresp_err = ib_dma_mapping_error(device->ib_device,\r\nib_conn->login_resp_dma);\r\nif (req_err || resp_err) {\r\nif (req_err)\r\nib_conn->login_req_dma = 0;\r\nif (resp_err)\r\nib_conn->login_resp_dma = 0;\r\ngoto free_login_buf;\r\n}\r\nreturn 0;\r\nfree_login_buf:\r\niser_free_login_buf(ib_conn);\r\nout_err:\r\niser_err("unable to alloc or map login buf\n");\r\nreturn -ENOMEM;\r\n}\r\nint iser_alloc_rx_descriptors(struct iser_conn *ib_conn, struct iscsi_session *session)\r\n{\r\nint i, j;\r\nu64 dma_addr;\r\nstruct iser_rx_desc *rx_desc;\r\nstruct ib_sge *rx_sg;\r\nstruct iser_device *device = ib_conn->device;\r\nib_conn->qp_max_recv_dtos = session->cmds_max;\r\nib_conn->qp_max_recv_dtos_mask = session->cmds_max - 1;\r\nib_conn->min_posted_rx = ib_conn->qp_max_recv_dtos >> 2;\r\nif (device->iser_alloc_rdma_reg_res(ib_conn, session->scsi_cmds_max))\r\ngoto create_rdma_reg_res_failed;\r\nif (iser_alloc_login_buf(ib_conn))\r\ngoto alloc_login_buf_fail;\r\nib_conn->rx_descs = kmalloc(session->cmds_max *\r\nsizeof(struct iser_rx_desc), GFP_KERNEL);\r\nif (!ib_conn->rx_descs)\r\ngoto rx_desc_alloc_fail;\r\nrx_desc = ib_conn->rx_descs;\r\nfor (i = 0; i < ib_conn->qp_max_recv_dtos; i++, rx_desc++) {\r\ndma_addr = ib_dma_map_single(device->ib_device, (void *)rx_desc,\r\nISER_RX_PAYLOAD_SIZE, DMA_FROM_DEVICE);\r\nif (ib_dma_mapping_error(device->ib_device, dma_addr))\r\ngoto rx_desc_dma_map_failed;\r\nrx_desc->dma_addr = dma_addr;\r\nrx_sg = &rx_desc->rx_sg;\r\nrx_sg->addr = rx_desc->dma_addr;\r\nrx_sg->length = ISER_RX_PAYLOAD_SIZE;\r\nrx_sg->lkey = device->mr->lkey;\r\n}\r\nib_conn->rx_desc_head = 0;\r\nreturn 0;\r\nrx_desc_dma_map_failed:\r\nrx_desc = ib_conn->rx_descs;\r\nfor (j = 0; j < i; j++, rx_desc++)\r\nib_dma_unmap_single(device->ib_device, rx_desc->dma_addr,\r\nISER_RX_PAYLOAD_SIZE, DMA_FROM_DEVICE);\r\nkfree(ib_conn->rx_descs);\r\nib_conn->rx_descs = NULL;\r\nrx_desc_alloc_fail:\r\niser_free_login_buf(ib_conn);\r\nalloc_login_buf_fail:\r\ndevice->iser_free_rdma_reg_res(ib_conn);\r\ncreate_rdma_reg_res_failed:\r\niser_err("failed allocating rx descriptors / data buffers\n");\r\nreturn -ENOMEM;\r\n}\r\nvoid iser_free_rx_descriptors(struct iser_conn *ib_conn)\r\n{\r\nint i;\r\nstruct iser_rx_desc *rx_desc;\r\nstruct iser_device *device = ib_conn->device;\r\nif (!ib_conn->rx_descs)\r\ngoto free_login_buf;\r\nif (device->iser_free_rdma_reg_res)\r\ndevice->iser_free_rdma_reg_res(ib_conn);\r\nrx_desc = ib_conn->rx_descs;\r\nfor (i = 0; i < ib_conn->qp_max_recv_dtos; i++, rx_desc++)\r\nib_dma_unmap_single(device->ib_device, rx_desc->dma_addr,\r\nISER_RX_PAYLOAD_SIZE, DMA_FROM_DEVICE);\r\nkfree(ib_conn->rx_descs);\r\nib_conn->rx_descs = NULL;\r\nfree_login_buf:\r\niser_free_login_buf(ib_conn);\r\n}\r\nstatic int iser_post_rx_bufs(struct iscsi_conn *conn, struct iscsi_hdr *req)\r\n{\r\nstruct iser_conn *ib_conn = conn->dd_data;\r\nstruct iscsi_session *session = conn->session;\r\niser_dbg("req op %x flags %x\n", req->opcode, req->flags);\r\nif ((req->flags & ISCSI_FULL_FEATURE_PHASE) != ISCSI_FULL_FEATURE_PHASE)\r\nreturn 0;\r\nWARN_ON(ib_conn->post_recv_buf_count != 1);\r\nWARN_ON(atomic_read(&ib_conn->post_send_buf_count) != 0);\r\nif (session->discovery_sess) {\r\niser_info("Discovery session, re-using login RX buffer\n");\r\nreturn 0;\r\n} else\r\niser_info("Normal session, posting batch of RX %d buffers\n",\r\nib_conn->min_posted_rx);\r\nif (iser_post_recvm(ib_conn, ib_conn->min_posted_rx))\r\nreturn -ENOMEM;\r\nreturn 0;\r\n}\r\nint iser_send_command(struct iscsi_conn *conn,\r\nstruct iscsi_task *task)\r\n{\r\nstruct iser_conn *ib_conn = conn->dd_data;\r\nstruct iscsi_iser_task *iser_task = task->dd_data;\r\nunsigned long edtl;\r\nint err;\r\nstruct iser_data_buf *data_buf, *prot_buf;\r\nstruct iscsi_scsi_req *hdr = (struct iscsi_scsi_req *)task->hdr;\r\nstruct scsi_cmnd *sc = task->sc;\r\nstruct iser_tx_desc *tx_desc = &iser_task->desc;\r\nedtl = ntohl(hdr->data_length);\r\ntx_desc->type = ISCSI_TX_SCSI_COMMAND;\r\niser_create_send_desc(ib_conn, tx_desc);\r\nif (hdr->flags & ISCSI_FLAG_CMD_READ) {\r\ndata_buf = &iser_task->data[ISER_DIR_IN];\r\nprot_buf = &iser_task->prot[ISER_DIR_IN];\r\n} else {\r\ndata_buf = &iser_task->data[ISER_DIR_OUT];\r\nprot_buf = &iser_task->prot[ISER_DIR_OUT];\r\n}\r\nif (scsi_sg_count(sc)) {\r\ndata_buf->buf = scsi_sglist(sc);\r\ndata_buf->size = scsi_sg_count(sc);\r\n}\r\ndata_buf->data_len = scsi_bufflen(sc);\r\nif (scsi_prot_sg_count(sc)) {\r\nprot_buf->buf = scsi_prot_sglist(sc);\r\nprot_buf->size = scsi_prot_sg_count(sc);\r\nprot_buf->data_len = data_buf->data_len >>\r\nilog2(sc->device->sector_size) * 8;\r\n}\r\nif (hdr->flags & ISCSI_FLAG_CMD_READ) {\r\nerr = iser_prepare_read_cmd(task);\r\nif (err)\r\ngoto send_command_error;\r\n}\r\nif (hdr->flags & ISCSI_FLAG_CMD_WRITE) {\r\nerr = iser_prepare_write_cmd(task,\r\ntask->imm_count,\r\ntask->imm_count +\r\ntask->unsol_r2t.data_length,\r\nedtl);\r\nif (err)\r\ngoto send_command_error;\r\n}\r\niser_task->status = ISER_TASK_STATUS_STARTED;\r\nerr = iser_post_send(ib_conn, tx_desc);\r\nif (!err)\r\nreturn 0;\r\nsend_command_error:\r\niser_err("conn %p failed task->itt %d err %d\n",conn, task->itt, err);\r\nreturn err;\r\n}\r\nint iser_send_data_out(struct iscsi_conn *conn,\r\nstruct iscsi_task *task,\r\nstruct iscsi_data *hdr)\r\n{\r\nstruct iser_conn *ib_conn = conn->dd_data;\r\nstruct iscsi_iser_task *iser_task = task->dd_data;\r\nstruct iser_tx_desc *tx_desc = NULL;\r\nstruct iser_regd_buf *regd_buf;\r\nunsigned long buf_offset;\r\nunsigned long data_seg_len;\r\nuint32_t itt;\r\nint err = 0;\r\nstruct ib_sge *tx_dsg;\r\nitt = (__force uint32_t)hdr->itt;\r\ndata_seg_len = ntoh24(hdr->dlength);\r\nbuf_offset = ntohl(hdr->offset);\r\niser_dbg("%s itt %d dseg_len %d offset %d\n",\r\n__func__,(int)itt,(int)data_seg_len,(int)buf_offset);\r\ntx_desc = kmem_cache_zalloc(ig.desc_cache, GFP_ATOMIC);\r\nif (tx_desc == NULL) {\r\niser_err("Failed to alloc desc for post dataout\n");\r\nreturn -ENOMEM;\r\n}\r\ntx_desc->type = ISCSI_TX_DATAOUT;\r\ntx_desc->iser_header.flags = ISER_VER;\r\nmemcpy(&tx_desc->iscsi_header, hdr, sizeof(struct iscsi_hdr));\r\niser_initialize_task_headers(task, tx_desc);\r\nregd_buf = &iser_task->rdma_regd[ISER_DIR_OUT];\r\ntx_dsg = &tx_desc->tx_sg[1];\r\ntx_dsg->addr = regd_buf->reg.va + buf_offset;\r\ntx_dsg->length = data_seg_len;\r\ntx_dsg->lkey = regd_buf->reg.lkey;\r\ntx_desc->num_sge = 2;\r\nif (buf_offset + data_seg_len > iser_task->data[ISER_DIR_OUT].data_len) {\r\niser_err("Offset:%ld & DSL:%ld in Data-Out "\r\n"inconsistent with total len:%ld, itt:%d\n",\r\nbuf_offset, data_seg_len,\r\niser_task->data[ISER_DIR_OUT].data_len, itt);\r\nerr = -EINVAL;\r\ngoto send_data_out_error;\r\n}\r\niser_dbg("data-out itt: %d, offset: %ld, sz: %ld\n",\r\nitt, buf_offset, data_seg_len);\r\nerr = iser_post_send(ib_conn, tx_desc);\r\nif (!err)\r\nreturn 0;\r\nsend_data_out_error:\r\nkmem_cache_free(ig.desc_cache, tx_desc);\r\niser_err("conn %p failed err %d\n",conn, err);\r\nreturn err;\r\n}\r\nint iser_send_control(struct iscsi_conn *conn,\r\nstruct iscsi_task *task)\r\n{\r\nstruct iser_conn *ib_conn = conn->dd_data;\r\nstruct iscsi_iser_task *iser_task = task->dd_data;\r\nstruct iser_tx_desc *mdesc = &iser_task->desc;\r\nunsigned long data_seg_len;\r\nint err = 0;\r\nstruct iser_device *device;\r\nmdesc->type = ISCSI_TX_CONTROL;\r\niser_create_send_desc(ib_conn, mdesc);\r\ndevice = ib_conn->device;\r\ndata_seg_len = ntoh24(task->hdr->dlength);\r\nif (data_seg_len > 0) {\r\nstruct ib_sge *tx_dsg = &mdesc->tx_sg[1];\r\nif (task != conn->login_task) {\r\niser_err("data present on non login task!!!\n");\r\ngoto send_control_error;\r\n}\r\nib_dma_sync_single_for_cpu(device->ib_device,\r\nib_conn->login_req_dma, task->data_count,\r\nDMA_TO_DEVICE);\r\nmemcpy(ib_conn->login_req_buf, task->data, task->data_count);\r\nib_dma_sync_single_for_device(device->ib_device,\r\nib_conn->login_req_dma, task->data_count,\r\nDMA_TO_DEVICE);\r\ntx_dsg->addr = ib_conn->login_req_dma;\r\ntx_dsg->length = task->data_count;\r\ntx_dsg->lkey = device->mr->lkey;\r\nmdesc->num_sge = 2;\r\n}\r\nif (task == conn->login_task) {\r\niser_dbg("op %x dsl %lx, posting login rx buffer\n",\r\ntask->hdr->opcode, data_seg_len);\r\nerr = iser_post_recvl(ib_conn);\r\nif (err)\r\ngoto send_control_error;\r\nerr = iser_post_rx_bufs(conn, task->hdr);\r\nif (err)\r\ngoto send_control_error;\r\n}\r\nerr = iser_post_send(ib_conn, mdesc);\r\nif (!err)\r\nreturn 0;\r\nsend_control_error:\r\niser_err("conn %p failed err %d\n",conn, err);\r\nreturn err;\r\n}\r\nvoid iser_rcv_completion(struct iser_rx_desc *rx_desc,\r\nunsigned long rx_xfer_len,\r\nstruct iser_conn *ib_conn)\r\n{\r\nstruct iscsi_hdr *hdr;\r\nu64 rx_dma;\r\nint rx_buflen, outstanding, count, err;\r\nif ((char *)rx_desc == ib_conn->login_resp_buf) {\r\nrx_dma = ib_conn->login_resp_dma;\r\nrx_buflen = ISER_RX_LOGIN_SIZE;\r\n} else {\r\nrx_dma = rx_desc->dma_addr;\r\nrx_buflen = ISER_RX_PAYLOAD_SIZE;\r\n}\r\nib_dma_sync_single_for_cpu(ib_conn->device->ib_device, rx_dma,\r\nrx_buflen, DMA_FROM_DEVICE);\r\nhdr = &rx_desc->iscsi_header;\r\niser_dbg("op 0x%x itt 0x%x dlen %d\n", hdr->opcode,\r\nhdr->itt, (int)(rx_xfer_len - ISER_HEADERS_LEN));\r\niscsi_iser_recv(ib_conn->iscsi_conn, hdr, rx_desc->data,\r\nrx_xfer_len - ISER_HEADERS_LEN);\r\nib_dma_sync_single_for_device(ib_conn->device->ib_device, rx_dma,\r\nrx_buflen, DMA_FROM_DEVICE);\r\nib_conn->post_recv_buf_count--;\r\nif (rx_dma == ib_conn->login_resp_dma)\r\nreturn;\r\noutstanding = ib_conn->post_recv_buf_count;\r\nif (outstanding + ib_conn->min_posted_rx <= ib_conn->qp_max_recv_dtos) {\r\ncount = min(ib_conn->qp_max_recv_dtos - outstanding,\r\nib_conn->min_posted_rx);\r\nerr = iser_post_recvm(ib_conn, count);\r\nif (err)\r\niser_err("posting %d rx bufs err %d\n", count, err);\r\n}\r\n}\r\nvoid iser_snd_completion(struct iser_tx_desc *tx_desc,\r\nstruct iser_conn *ib_conn)\r\n{\r\nstruct iscsi_task *task;\r\nstruct iser_device *device = ib_conn->device;\r\nif (tx_desc->type == ISCSI_TX_DATAOUT) {\r\nib_dma_unmap_single(device->ib_device, tx_desc->dma_addr,\r\nISER_HEADERS_LEN, DMA_TO_DEVICE);\r\nkmem_cache_free(ig.desc_cache, tx_desc);\r\ntx_desc = NULL;\r\n}\r\natomic_dec(&ib_conn->post_send_buf_count);\r\nif (tx_desc && tx_desc->type == ISCSI_TX_CONTROL) {\r\ntask = (void *) ((long)(void *)tx_desc -\r\nsizeof(struct iscsi_task));\r\nif (task->hdr->itt == RESERVED_ITT)\r\niscsi_put_task(task);\r\n}\r\n}\r\nvoid iser_task_rdma_init(struct iscsi_iser_task *iser_task)\r\n{\r\niser_task->status = ISER_TASK_STATUS_INIT;\r\niser_task->dir[ISER_DIR_IN] = 0;\r\niser_task->dir[ISER_DIR_OUT] = 0;\r\niser_task->data[ISER_DIR_IN].data_len = 0;\r\niser_task->data[ISER_DIR_OUT].data_len = 0;\r\niser_task->prot[ISER_DIR_IN].data_len = 0;\r\niser_task->prot[ISER_DIR_OUT].data_len = 0;\r\nmemset(&iser_task->rdma_regd[ISER_DIR_IN], 0,\r\nsizeof(struct iser_regd_buf));\r\nmemset(&iser_task->rdma_regd[ISER_DIR_OUT], 0,\r\nsizeof(struct iser_regd_buf));\r\n}\r\nvoid iser_task_rdma_finalize(struct iscsi_iser_task *iser_task)\r\n{\r\nstruct iser_device *device = iser_task->ib_conn->device;\r\nint is_rdma_data_aligned = 1;\r\nint is_rdma_prot_aligned = 1;\r\nint prot_count = scsi_prot_sg_count(iser_task->sc);\r\nif (iser_task->data_copy[ISER_DIR_IN].copy_buf != NULL) {\r\nis_rdma_data_aligned = 0;\r\niser_finalize_rdma_unaligned_sg(iser_task,\r\n&iser_task->data[ISER_DIR_IN],\r\n&iser_task->data_copy[ISER_DIR_IN],\r\nISER_DIR_IN);\r\n}\r\nif (iser_task->data_copy[ISER_DIR_OUT].copy_buf != NULL) {\r\nis_rdma_data_aligned = 0;\r\niser_finalize_rdma_unaligned_sg(iser_task,\r\n&iser_task->data[ISER_DIR_OUT],\r\n&iser_task->data_copy[ISER_DIR_OUT],\r\nISER_DIR_OUT);\r\n}\r\nif (iser_task->prot_copy[ISER_DIR_IN].copy_buf != NULL) {\r\nis_rdma_prot_aligned = 0;\r\niser_finalize_rdma_unaligned_sg(iser_task,\r\n&iser_task->prot[ISER_DIR_IN],\r\n&iser_task->prot_copy[ISER_DIR_IN],\r\nISER_DIR_IN);\r\n}\r\nif (iser_task->prot_copy[ISER_DIR_OUT].copy_buf != NULL) {\r\nis_rdma_prot_aligned = 0;\r\niser_finalize_rdma_unaligned_sg(iser_task,\r\n&iser_task->prot[ISER_DIR_OUT],\r\n&iser_task->prot_copy[ISER_DIR_OUT],\r\nISER_DIR_OUT);\r\n}\r\nif (iser_task->dir[ISER_DIR_IN]) {\r\ndevice->iser_unreg_rdma_mem(iser_task, ISER_DIR_IN);\r\nif (is_rdma_data_aligned)\r\niser_dma_unmap_task_data(iser_task,\r\n&iser_task->data[ISER_DIR_IN]);\r\nif (prot_count && is_rdma_prot_aligned)\r\niser_dma_unmap_task_data(iser_task,\r\n&iser_task->prot[ISER_DIR_IN]);\r\n}\r\nif (iser_task->dir[ISER_DIR_OUT]) {\r\ndevice->iser_unreg_rdma_mem(iser_task, ISER_DIR_OUT);\r\nif (is_rdma_data_aligned)\r\niser_dma_unmap_task_data(iser_task,\r\n&iser_task->data[ISER_DIR_OUT]);\r\nif (prot_count && is_rdma_prot_aligned)\r\niser_dma_unmap_task_data(iser_task,\r\n&iser_task->prot[ISER_DIR_OUT]);\r\n}\r\n}
