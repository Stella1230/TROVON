static int ccp_aes_cmac_complete(struct crypto_async_request *async_req,\r\nint ret)\r\n{\r\nstruct ahash_request *req = ahash_request_cast(async_req);\r\nstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\r\nstruct ccp_aes_cmac_req_ctx *rctx = ahash_request_ctx(req);\r\nunsigned int digest_size = crypto_ahash_digestsize(tfm);\r\nif (ret)\r\ngoto e_free;\r\nif (rctx->hash_rem) {\r\nunsigned int offset = rctx->nbytes - rctx->hash_rem;\r\nscatterwalk_map_and_copy(rctx->buf, rctx->src,\r\noffset, rctx->hash_rem, 0);\r\nrctx->buf_count = rctx->hash_rem;\r\n} else\r\nrctx->buf_count = 0;\r\nif (req->result)\r\nmemcpy(req->result, rctx->iv, digest_size);\r\ne_free:\r\nsg_free_table(&rctx->data_sg);\r\nreturn ret;\r\n}\r\nstatic int ccp_do_cmac_update(struct ahash_request *req, unsigned int nbytes,\r\nunsigned int final)\r\n{\r\nstruct crypto_ahash *tfm = crypto_ahash_reqtfm(req);\r\nstruct ccp_ctx *ctx = crypto_ahash_ctx(tfm);\r\nstruct ccp_aes_cmac_req_ctx *rctx = ahash_request_ctx(req);\r\nstruct scatterlist *sg, *cmac_key_sg = NULL;\r\nunsigned int block_size =\r\ncrypto_tfm_alg_blocksize(crypto_ahash_tfm(tfm));\r\nunsigned int need_pad, sg_count;\r\ngfp_t gfp;\r\nu64 len;\r\nint ret;\r\nif (!ctx->u.aes.key_len)\r\nreturn -EINVAL;\r\nif (nbytes)\r\nrctx->null_msg = 0;\r\nlen = (u64)rctx->buf_count + (u64)nbytes;\r\nif (!final && (len <= block_size)) {\r\nscatterwalk_map_and_copy(rctx->buf + rctx->buf_count, req->src,\r\n0, nbytes, 0);\r\nrctx->buf_count += nbytes;\r\nreturn 0;\r\n}\r\nrctx->src = req->src;\r\nrctx->nbytes = nbytes;\r\nrctx->final = final;\r\nrctx->hash_rem = final ? 0 : len & (block_size - 1);\r\nrctx->hash_cnt = len - rctx->hash_rem;\r\nif (!final && !rctx->hash_rem) {\r\nrctx->hash_cnt -= block_size;\r\nrctx->hash_rem = block_size;\r\n}\r\nif (final && (rctx->null_msg || (len & (block_size - 1))))\r\nneed_pad = 1;\r\nelse\r\nneed_pad = 0;\r\nsg_init_one(&rctx->iv_sg, rctx->iv, sizeof(rctx->iv));\r\nsg_count = (nbytes) ? sg_nents(req->src) + 2 : 2;\r\ngfp = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP ?\r\nGFP_KERNEL : GFP_ATOMIC;\r\nret = sg_alloc_table(&rctx->data_sg, sg_count, gfp);\r\nif (ret)\r\nreturn ret;\r\nsg = NULL;\r\nif (rctx->buf_count) {\r\nsg_init_one(&rctx->buf_sg, rctx->buf, rctx->buf_count);\r\nsg = ccp_crypto_sg_table_add(&rctx->data_sg, &rctx->buf_sg);\r\n}\r\nif (nbytes)\r\nsg = ccp_crypto_sg_table_add(&rctx->data_sg, req->src);\r\nif (need_pad) {\r\nint pad_length = block_size - (len & (block_size - 1));\r\nrctx->hash_cnt += pad_length;\r\nmemset(rctx->pad, 0, sizeof(rctx->pad));\r\nrctx->pad[0] = 0x80;\r\nsg_init_one(&rctx->pad_sg, rctx->pad, pad_length);\r\nsg = ccp_crypto_sg_table_add(&rctx->data_sg, &rctx->pad_sg);\r\n}\r\nif (sg) {\r\nsg_mark_end(sg);\r\nsg = rctx->data_sg.sgl;\r\n}\r\nif (final)\r\ncmac_key_sg = (need_pad) ? &ctx->u.aes.k2_sg\r\n: &ctx->u.aes.k1_sg;\r\nmemset(&rctx->cmd, 0, sizeof(rctx->cmd));\r\nINIT_LIST_HEAD(&rctx->cmd.entry);\r\nrctx->cmd.engine = CCP_ENGINE_AES;\r\nrctx->cmd.u.aes.type = ctx->u.aes.type;\r\nrctx->cmd.u.aes.mode = ctx->u.aes.mode;\r\nrctx->cmd.u.aes.action = CCP_AES_ACTION_ENCRYPT;\r\nrctx->cmd.u.aes.key = &ctx->u.aes.key_sg;\r\nrctx->cmd.u.aes.key_len = ctx->u.aes.key_len;\r\nrctx->cmd.u.aes.iv = &rctx->iv_sg;\r\nrctx->cmd.u.aes.iv_len = AES_BLOCK_SIZE;\r\nrctx->cmd.u.aes.src = sg;\r\nrctx->cmd.u.aes.src_len = rctx->hash_cnt;\r\nrctx->cmd.u.aes.dst = NULL;\r\nrctx->cmd.u.aes.cmac_key = cmac_key_sg;\r\nrctx->cmd.u.aes.cmac_key_len = ctx->u.aes.kn_len;\r\nrctx->cmd.u.aes.cmac_final = final;\r\nret = ccp_crypto_enqueue_request(&req->base, &rctx->cmd);\r\nreturn ret;\r\n}\r\nstatic int ccp_aes_cmac_init(struct ahash_request *req)\r\n{\r\nstruct ccp_aes_cmac_req_ctx *rctx = ahash_request_ctx(req);\r\nmemset(rctx, 0, sizeof(*rctx));\r\nrctx->null_msg = 1;\r\nreturn 0;\r\n}\r\nstatic int ccp_aes_cmac_update(struct ahash_request *req)\r\n{\r\nreturn ccp_do_cmac_update(req, req->nbytes, 0);\r\n}\r\nstatic int ccp_aes_cmac_final(struct ahash_request *req)\r\n{\r\nreturn ccp_do_cmac_update(req, 0, 1);\r\n}\r\nstatic int ccp_aes_cmac_finup(struct ahash_request *req)\r\n{\r\nreturn ccp_do_cmac_update(req, req->nbytes, 1);\r\n}\r\nstatic int ccp_aes_cmac_digest(struct ahash_request *req)\r\n{\r\nint ret;\r\nret = ccp_aes_cmac_init(req);\r\nif (ret)\r\nreturn ret;\r\nreturn ccp_aes_cmac_finup(req);\r\n}\r\nstatic int ccp_aes_cmac_setkey(struct crypto_ahash *tfm, const u8 *key,\r\nunsigned int key_len)\r\n{\r\nstruct ccp_ctx *ctx = crypto_tfm_ctx(crypto_ahash_tfm(tfm));\r\nstruct ccp_crypto_ahash_alg *alg =\r\nccp_crypto_ahash_alg(crypto_ahash_tfm(tfm));\r\nu64 k0_hi, k0_lo, k1_hi, k1_lo, k2_hi, k2_lo;\r\nu64 rb_hi = 0x00, rb_lo = 0x87;\r\n__be64 *gk;\r\nint ret;\r\nswitch (key_len) {\r\ncase AES_KEYSIZE_128:\r\nctx->u.aes.type = CCP_AES_TYPE_128;\r\nbreak;\r\ncase AES_KEYSIZE_192:\r\nctx->u.aes.type = CCP_AES_TYPE_192;\r\nbreak;\r\ncase AES_KEYSIZE_256:\r\nctx->u.aes.type = CCP_AES_TYPE_256;\r\nbreak;\r\ndefault:\r\ncrypto_ahash_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);\r\nreturn -EINVAL;\r\n}\r\nctx->u.aes.mode = alg->mode;\r\nctx->u.aes.key_len = 0;\r\nret = crypto_cipher_setkey(ctx->u.aes.tfm_cipher, key, key_len);\r\nif (ret)\r\nreturn ret;\r\nmemset(ctx->u.aes.key, 0, sizeof(ctx->u.aes.key));\r\ncrypto_cipher_encrypt_one(ctx->u.aes.tfm_cipher, ctx->u.aes.key,\r\nctx->u.aes.key);\r\nk0_hi = be64_to_cpu(*((__be64 *)ctx->u.aes.key));\r\nk0_lo = be64_to_cpu(*((__be64 *)ctx->u.aes.key + 1));\r\nk1_hi = (k0_hi << 1) | (k0_lo >> 63);\r\nk1_lo = k0_lo << 1;\r\nif (ctx->u.aes.key[0] & 0x80) {\r\nk1_hi ^= rb_hi;\r\nk1_lo ^= rb_lo;\r\n}\r\ngk = (__be64 *)ctx->u.aes.k1;\r\n*gk = cpu_to_be64(k1_hi);\r\ngk++;\r\n*gk = cpu_to_be64(k1_lo);\r\nk2_hi = (k1_hi << 1) | (k1_lo >> 63);\r\nk2_lo = k1_lo << 1;\r\nif (ctx->u.aes.k1[0] & 0x80) {\r\nk2_hi ^= rb_hi;\r\nk2_lo ^= rb_lo;\r\n}\r\ngk = (__be64 *)ctx->u.aes.k2;\r\n*gk = cpu_to_be64(k2_hi);\r\ngk++;\r\n*gk = cpu_to_be64(k2_lo);\r\nctx->u.aes.kn_len = sizeof(ctx->u.aes.k1);\r\nsg_init_one(&ctx->u.aes.k1_sg, ctx->u.aes.k1, sizeof(ctx->u.aes.k1));\r\nsg_init_one(&ctx->u.aes.k2_sg, ctx->u.aes.k2, sizeof(ctx->u.aes.k2));\r\nmemset(ctx->u.aes.key, 0, sizeof(ctx->u.aes.key));\r\nmemcpy(ctx->u.aes.key, key, key_len);\r\nctx->u.aes.key_len = key_len;\r\nsg_init_one(&ctx->u.aes.key_sg, ctx->u.aes.key, key_len);\r\nreturn ret;\r\n}\r\nstatic int ccp_aes_cmac_cra_init(struct crypto_tfm *tfm)\r\n{\r\nstruct ccp_ctx *ctx = crypto_tfm_ctx(tfm);\r\nstruct crypto_ahash *ahash = __crypto_ahash_cast(tfm);\r\nstruct crypto_cipher *cipher_tfm;\r\nctx->complete = ccp_aes_cmac_complete;\r\nctx->u.aes.key_len = 0;\r\ncrypto_ahash_set_reqsize(ahash, sizeof(struct ccp_aes_cmac_req_ctx));\r\ncipher_tfm = crypto_alloc_cipher("aes", 0,\r\nCRYPTO_ALG_ASYNC | CRYPTO_ALG_NEED_FALLBACK);\r\nif (IS_ERR(cipher_tfm)) {\r\npr_warn("could not load aes cipher driver\n");\r\nreturn PTR_ERR(cipher_tfm);\r\n}\r\nctx->u.aes.tfm_cipher = cipher_tfm;\r\nreturn 0;\r\n}\r\nstatic void ccp_aes_cmac_cra_exit(struct crypto_tfm *tfm)\r\n{\r\nstruct ccp_ctx *ctx = crypto_tfm_ctx(tfm);\r\nif (ctx->u.aes.tfm_cipher)\r\ncrypto_free_cipher(ctx->u.aes.tfm_cipher);\r\nctx->u.aes.tfm_cipher = NULL;\r\n}\r\nint ccp_register_aes_cmac_algs(struct list_head *head)\r\n{\r\nstruct ccp_crypto_ahash_alg *ccp_alg;\r\nstruct ahash_alg *alg;\r\nstruct hash_alg_common *halg;\r\nstruct crypto_alg *base;\r\nint ret;\r\nccp_alg = kzalloc(sizeof(*ccp_alg), GFP_KERNEL);\r\nif (!ccp_alg)\r\nreturn -ENOMEM;\r\nINIT_LIST_HEAD(&ccp_alg->entry);\r\nccp_alg->mode = CCP_AES_MODE_CMAC;\r\nalg = &ccp_alg->alg;\r\nalg->init = ccp_aes_cmac_init;\r\nalg->update = ccp_aes_cmac_update;\r\nalg->final = ccp_aes_cmac_final;\r\nalg->finup = ccp_aes_cmac_finup;\r\nalg->digest = ccp_aes_cmac_digest;\r\nalg->setkey = ccp_aes_cmac_setkey;\r\nhalg = &alg->halg;\r\nhalg->digestsize = AES_BLOCK_SIZE;\r\nbase = &halg->base;\r\nsnprintf(base->cra_name, CRYPTO_MAX_ALG_NAME, "cmac(aes)");\r\nsnprintf(base->cra_driver_name, CRYPTO_MAX_ALG_NAME, "cmac-aes-ccp");\r\nbase->cra_flags = CRYPTO_ALG_TYPE_AHASH | CRYPTO_ALG_ASYNC |\r\nCRYPTO_ALG_KERN_DRIVER_ONLY |\r\nCRYPTO_ALG_NEED_FALLBACK;\r\nbase->cra_blocksize = AES_BLOCK_SIZE;\r\nbase->cra_ctxsize = sizeof(struct ccp_ctx);\r\nbase->cra_priority = CCP_CRA_PRIORITY;\r\nbase->cra_type = &crypto_ahash_type;\r\nbase->cra_init = ccp_aes_cmac_cra_init;\r\nbase->cra_exit = ccp_aes_cmac_cra_exit;\r\nbase->cra_module = THIS_MODULE;\r\nret = crypto_register_ahash(alg);\r\nif (ret) {\r\npr_err("%s ahash algorithm registration error (%d)\n",\r\nbase->cra_name, ret);\r\nkfree(ccp_alg);\r\nreturn ret;\r\n}\r\nlist_add(&ccp_alg->entry, head);\r\nreturn 0;\r\n}
