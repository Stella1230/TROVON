static int gru_user_copy_handle(void __user **dp, void *s)\r\n{\r\nif (copy_to_user(*dp, s, GRU_HANDLE_BYTES))\r\nreturn -1;\r\n*dp += GRU_HANDLE_BYTES;\r\nreturn 0;\r\n}\r\nstatic int gru_dump_context_data(void *grubase,\r\nstruct gru_context_configuration_handle *cch,\r\nvoid __user *ubuf, int ctxnum, int dsrcnt,\r\nint flush_cbrs)\r\n{\r\nvoid *cb, *cbe, *tfh, *gseg;\r\nint i, scr;\r\ngseg = grubase + ctxnum * GRU_GSEG_STRIDE;\r\ncb = gseg + GRU_CB_BASE;\r\ncbe = grubase + GRU_CBE_BASE;\r\ntfh = grubase + GRU_TFH_BASE;\r\nfor_each_cbr_in_allocation_map(i, &cch->cbr_allocation_map, scr) {\r\nif (flush_cbrs)\r\ngru_flush_cache(cb);\r\nif (gru_user_copy_handle(&ubuf, cb))\r\ngoto fail;\r\nif (gru_user_copy_handle(&ubuf, tfh + i * GRU_HANDLE_STRIDE))\r\ngoto fail;\r\nif (gru_user_copy_handle(&ubuf, cbe + i * GRU_HANDLE_STRIDE))\r\ngoto fail;\r\ncb += GRU_HANDLE_STRIDE;\r\n}\r\nif (dsrcnt)\r\nmemcpy(ubuf, gseg + GRU_DS_BASE, dsrcnt * GRU_HANDLE_STRIDE);\r\nreturn 0;\r\nfail:\r\nreturn -EFAULT;\r\n}\r\nstatic int gru_dump_tfm(struct gru_state *gru,\r\nvoid __user *ubuf, void __user *ubufend)\r\n{\r\nstruct gru_tlb_fault_map *tfm;\r\nint i, ret, bytes;\r\nbytes = GRU_NUM_TFM * GRU_CACHE_LINE_BYTES;\r\nif (bytes > ubufend - ubuf)\r\nret = -EFBIG;\r\nfor (i = 0; i < GRU_NUM_TFM; i++) {\r\ntfm = get_tfm(gru->gs_gru_base_vaddr, i);\r\nif (gru_user_copy_handle(&ubuf, tfm))\r\ngoto fail;\r\n}\r\nreturn GRU_NUM_TFM * GRU_CACHE_LINE_BYTES;\r\nfail:\r\nreturn -EFAULT;\r\n}\r\nstatic int gru_dump_tgh(struct gru_state *gru,\r\nvoid __user *ubuf, void __user *ubufend)\r\n{\r\nstruct gru_tlb_global_handle *tgh;\r\nint i, ret, bytes;\r\nbytes = GRU_NUM_TGH * GRU_CACHE_LINE_BYTES;\r\nif (bytes > ubufend - ubuf)\r\nret = -EFBIG;\r\nfor (i = 0; i < GRU_NUM_TGH; i++) {\r\ntgh = get_tgh(gru->gs_gru_base_vaddr, i);\r\nif (gru_user_copy_handle(&ubuf, tgh))\r\ngoto fail;\r\n}\r\nreturn GRU_NUM_TGH * GRU_CACHE_LINE_BYTES;\r\nfail:\r\nreturn -EFAULT;\r\n}\r\nstatic int gru_dump_context(struct gru_state *gru, int ctxnum,\r\nvoid __user *ubuf, void __user *ubufend, char data_opt,\r\nchar lock_cch, char flush_cbrs)\r\n{\r\nstruct gru_dump_context_header hdr;\r\nstruct gru_dump_context_header __user *uhdr = ubuf;\r\nstruct gru_context_configuration_handle *cch, *ubufcch;\r\nstruct gru_thread_state *gts;\r\nint try, cch_locked, cbrcnt = 0, dsrcnt = 0, bytes = 0, ret = 0;\r\nvoid *grubase;\r\nmemset(&hdr, 0, sizeof(hdr));\r\ngrubase = gru->gs_gru_base_vaddr;\r\ncch = get_cch(grubase, ctxnum);\r\nfor (try = 0; try < CCH_LOCK_ATTEMPTS; try++) {\r\ncch_locked = trylock_cch_handle(cch);\r\nif (cch_locked)\r\nbreak;\r\nmsleep(1);\r\n}\r\nubuf += sizeof(hdr);\r\nubufcch = ubuf;\r\nif (gru_user_copy_handle(&ubuf, cch)) {\r\nif (cch_locked)\r\nunlock_cch_handle(cch);\r\nreturn -EFAULT;\r\n}\r\nif (cch_locked)\r\nubufcch->delresp = 0;\r\nbytes = sizeof(hdr) + GRU_CACHE_LINE_BYTES;\r\nif (cch_locked || !lock_cch) {\r\ngts = gru->gs_gts[ctxnum];\r\nif (gts && gts->ts_vma) {\r\nhdr.pid = gts->ts_tgid_owner;\r\nhdr.vaddr = gts->ts_vma->vm_start;\r\n}\r\nif (cch->state != CCHSTATE_INACTIVE) {\r\ncbrcnt = hweight64(cch->cbr_allocation_map) *\r\nGRU_CBR_AU_SIZE;\r\ndsrcnt = data_opt ? hweight32(cch->dsr_allocation_map) *\r\nGRU_DSR_AU_CL : 0;\r\n}\r\nbytes += (3 * cbrcnt + dsrcnt) * GRU_CACHE_LINE_BYTES;\r\nif (bytes > ubufend - ubuf)\r\nret = -EFBIG;\r\nelse\r\nret = gru_dump_context_data(grubase, cch, ubuf, ctxnum,\r\ndsrcnt, flush_cbrs);\r\n}\r\nif (cch_locked)\r\nunlock_cch_handle(cch);\r\nif (ret)\r\nreturn ret;\r\nhdr.magic = GRU_DUMP_MAGIC;\r\nhdr.gid = gru->gs_gid;\r\nhdr.ctxnum = ctxnum;\r\nhdr.cbrcnt = cbrcnt;\r\nhdr.dsrcnt = dsrcnt;\r\nhdr.cch_locked = cch_locked;\r\nif (copy_to_user(uhdr, &hdr, sizeof(hdr)))\r\nreturn -EFAULT;\r\nreturn bytes;\r\n}\r\nint gru_dump_chiplet_request(unsigned long arg)\r\n{\r\nstruct gru_state *gru;\r\nstruct gru_dump_chiplet_state_req req;\r\nvoid __user *ubuf;\r\nvoid __user *ubufend;\r\nint ctxnum, ret, cnt = 0;\r\nif (copy_from_user(&req, (void __user *)arg, sizeof(req)))\r\nreturn -EFAULT;\r\nif (req.gid >= gru_max_gids || req.gid < 0)\r\nreturn -EINVAL;\r\ngru = GID_TO_GRU(req.gid);\r\nubuf = req.buf;\r\nubufend = req.buf + req.buflen;\r\nret = gru_dump_tfm(gru, ubuf, ubufend);\r\nif (ret < 0)\r\ngoto fail;\r\nubuf += ret;\r\nret = gru_dump_tgh(gru, ubuf, ubufend);\r\nif (ret < 0)\r\ngoto fail;\r\nubuf += ret;\r\nfor (ctxnum = 0; ctxnum < GRU_NUM_CCH; ctxnum++) {\r\nif (req.ctxnum == ctxnum || req.ctxnum < 0) {\r\nret = gru_dump_context(gru, ctxnum, ubuf, ubufend,\r\nreq.data_opt, req.lock_cch,\r\nreq.flush_cbrs);\r\nif (ret < 0)\r\ngoto fail;\r\nubuf += ret;\r\ncnt++;\r\n}\r\n}\r\nif (copy_to_user((void __user *)arg, &req, sizeof(req)))\r\nreturn -EFAULT;\r\nreturn cnt;\r\nfail:\r\nreturn ret;\r\n}
