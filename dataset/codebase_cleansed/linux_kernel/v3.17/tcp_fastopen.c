void tcp_fastopen_init_key_once(bool publish)\r\n{\r\nstatic u8 key[TCP_FASTOPEN_KEY_LENGTH];\r\nif (net_get_random_once(key, sizeof(key)) && publish)\r\ntcp_fastopen_reset_cipher(key, sizeof(key));\r\n}\r\nstatic void tcp_fastopen_ctx_free(struct rcu_head *head)\r\n{\r\nstruct tcp_fastopen_context *ctx =\r\ncontainer_of(head, struct tcp_fastopen_context, rcu);\r\ncrypto_free_cipher(ctx->tfm);\r\nkfree(ctx);\r\n}\r\nint tcp_fastopen_reset_cipher(void *key, unsigned int len)\r\n{\r\nint err;\r\nstruct tcp_fastopen_context *ctx, *octx;\r\nctx = kmalloc(sizeof(*ctx), GFP_KERNEL);\r\nif (!ctx)\r\nreturn -ENOMEM;\r\nctx->tfm = crypto_alloc_cipher("aes", 0, 0);\r\nif (IS_ERR(ctx->tfm)) {\r\nerr = PTR_ERR(ctx->tfm);\r\nerror: kfree(ctx);\r\npr_err("TCP: TFO aes cipher alloc error: %d\n", err);\r\nreturn err;\r\n}\r\nerr = crypto_cipher_setkey(ctx->tfm, key, len);\r\nif (err) {\r\npr_err("TCP: TFO cipher key error: %d\n", err);\r\ncrypto_free_cipher(ctx->tfm);\r\ngoto error;\r\n}\r\nmemcpy(ctx->key, key, len);\r\nspin_lock(&tcp_fastopen_ctx_lock);\r\noctx = rcu_dereference_protected(tcp_fastopen_ctx,\r\nlockdep_is_held(&tcp_fastopen_ctx_lock));\r\nrcu_assign_pointer(tcp_fastopen_ctx, ctx);\r\nspin_unlock(&tcp_fastopen_ctx_lock);\r\nif (octx)\r\ncall_rcu(&octx->rcu, tcp_fastopen_ctx_free);\r\nreturn err;\r\n}\r\nstatic bool __tcp_fastopen_cookie_gen(const void *path,\r\nstruct tcp_fastopen_cookie *foc)\r\n{\r\nstruct tcp_fastopen_context *ctx;\r\nbool ok = false;\r\ntcp_fastopen_init_key_once(true);\r\nrcu_read_lock();\r\nctx = rcu_dereference(tcp_fastopen_ctx);\r\nif (ctx) {\r\ncrypto_cipher_encrypt_one(ctx->tfm, foc->val, path);\r\nfoc->len = TCP_FASTOPEN_COOKIE_SIZE;\r\nok = true;\r\n}\r\nrcu_read_unlock();\r\nreturn ok;\r\n}\r\nstatic bool tcp_fastopen_cookie_gen(struct request_sock *req,\r\nstruct sk_buff *syn,\r\nstruct tcp_fastopen_cookie *foc)\r\n{\r\nif (req->rsk_ops->family == AF_INET) {\r\nconst struct iphdr *iph = ip_hdr(syn);\r\n__be32 path[4] = { iph->saddr, iph->daddr, 0, 0 };\r\nreturn __tcp_fastopen_cookie_gen(path, foc);\r\n}\r\n#if IS_ENABLED(CONFIG_IPV6)\r\nif (req->rsk_ops->family == AF_INET6) {\r\nconst struct ipv6hdr *ip6h = ipv6_hdr(syn);\r\nstruct tcp_fastopen_cookie tmp;\r\nif (__tcp_fastopen_cookie_gen(&ip6h->saddr, &tmp)) {\r\nstruct in6_addr *buf = (struct in6_addr *) tmp.val;\r\nint i = 4;\r\nfor (i = 0; i < 4; i++)\r\nbuf->s6_addr32[i] ^= ip6h->daddr.s6_addr32[i];\r\nreturn __tcp_fastopen_cookie_gen(buf, foc);\r\n}\r\n}\r\n#endif\r\nreturn false;\r\n}\r\nstatic bool tcp_fastopen_create_child(struct sock *sk,\r\nstruct sk_buff *skb,\r\nstruct dst_entry *dst,\r\nstruct request_sock *req)\r\n{\r\nstruct tcp_sock *tp;\r\nstruct request_sock_queue *queue = &inet_csk(sk)->icsk_accept_queue;\r\nstruct sock *child;\r\nreq->num_retrans = 0;\r\nreq->num_timeout = 0;\r\nreq->sk = NULL;\r\nchild = inet_csk(sk)->icsk_af_ops->syn_recv_sock(sk, skb, req, NULL);\r\nif (child == NULL)\r\nreturn false;\r\nspin_lock(&queue->fastopenq->lock);\r\nqueue->fastopenq->qlen++;\r\nspin_unlock(&queue->fastopenq->lock);\r\ntp = tcp_sk(child);\r\ntp->fastopen_rsk = req;\r\nsock_hold(sk);\r\ntcp_rsk(req)->listener = sk;\r\ntp->snd_wnd = ntohs(tcp_hdr(skb)->window);\r\ninet_csk_reset_xmit_timer(child, ICSK_TIME_RETRANS,\r\nTCP_TIMEOUT_INIT, TCP_RTO_MAX);\r\ninet_csk_reqsk_queue_add(sk, req, child);\r\ninet_csk(child)->icsk_af_ops->rebuild_header(child);\r\ntcp_init_congestion_control(child);\r\ntcp_mtup_init(child);\r\ntcp_init_metrics(child);\r\ntcp_init_buffer_space(child);\r\nif (TCP_SKB_CB(skb)->end_seq != TCP_SKB_CB(skb)->seq + 1) {\r\nskb = skb_get(skb);\r\nskb_dst_drop(skb);\r\n__skb_pull(skb, tcp_hdr(skb)->doff * 4);\r\nskb_set_owner_r(skb, child);\r\n__skb_queue_tail(&child->sk_receive_queue, skb);\r\ntp->syn_data_acked = 1;\r\n}\r\ntcp_rsk(req)->rcv_nxt = tp->rcv_nxt = TCP_SKB_CB(skb)->end_seq;\r\nsk->sk_data_ready(sk);\r\nbh_unlock_sock(child);\r\nsock_put(child);\r\nWARN_ON(req->sk == NULL);\r\nreturn true;\r\n}\r\nstatic bool tcp_fastopen_queue_check(struct sock *sk)\r\n{\r\nstruct fastopen_queue *fastopenq;\r\nfastopenq = inet_csk(sk)->icsk_accept_queue.fastopenq;\r\nif (fastopenq == NULL || fastopenq->max_qlen == 0)\r\nreturn false;\r\nif (fastopenq->qlen >= fastopenq->max_qlen) {\r\nstruct request_sock *req1;\r\nspin_lock(&fastopenq->lock);\r\nreq1 = fastopenq->rskq_rst_head;\r\nif ((req1 == NULL) || time_after(req1->expires, jiffies)) {\r\nspin_unlock(&fastopenq->lock);\r\nNET_INC_STATS_BH(sock_net(sk),\r\nLINUX_MIB_TCPFASTOPENLISTENOVERFLOW);\r\nreturn false;\r\n}\r\nfastopenq->rskq_rst_head = req1->dl_next;\r\nfastopenq->qlen--;\r\nspin_unlock(&fastopenq->lock);\r\nreqsk_free(req1);\r\n}\r\nreturn true;\r\n}\r\nbool tcp_try_fastopen(struct sock *sk, struct sk_buff *skb,\r\nstruct request_sock *req,\r\nstruct tcp_fastopen_cookie *foc,\r\nstruct dst_entry *dst)\r\n{\r\nstruct tcp_fastopen_cookie valid_foc = { .len = -1 };\r\nbool syn_data = TCP_SKB_CB(skb)->end_seq != TCP_SKB_CB(skb)->seq + 1;\r\nif (!((sysctl_tcp_fastopen & TFO_SERVER_ENABLE) &&\r\n(syn_data || foc->len >= 0) &&\r\ntcp_fastopen_queue_check(sk))) {\r\nfoc->len = -1;\r\nreturn false;\r\n}\r\nif (syn_data && (sysctl_tcp_fastopen & TFO_SERVER_COOKIE_NOT_REQD))\r\ngoto fastopen;\r\nif (tcp_fastopen_cookie_gen(req, skb, &valid_foc) &&\r\nfoc->len == TCP_FASTOPEN_COOKIE_SIZE &&\r\nfoc->len == valid_foc.len &&\r\n!memcmp(foc->val, valid_foc.val, foc->len)) {\r\nfastopen:\r\nif (tcp_fastopen_create_child(sk, skb, dst, req)) {\r\nfoc->len = -1;\r\nNET_INC_STATS_BH(sock_net(sk),\r\nLINUX_MIB_TCPFASTOPENPASSIVE);\r\nreturn true;\r\n}\r\n}\r\nNET_INC_STATS_BH(sock_net(sk), foc->len ?\r\nLINUX_MIB_TCPFASTOPENPASSIVEFAIL :\r\nLINUX_MIB_TCPFASTOPENCOOKIEREQD);\r\n*foc = valid_foc;\r\nreturn false;\r\n}
