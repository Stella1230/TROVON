static void dict_reset(struct dictionary *dict, struct xz_buf *b)\r\n{\r\nif (DEC_IS_SINGLE(dict->mode)) {\r\ndict->buf = b->out + b->out_pos;\r\ndict->end = b->out_size - b->out_pos;\r\n}\r\ndict->start = 0;\r\ndict->pos = 0;\r\ndict->limit = 0;\r\ndict->full = 0;\r\n}\r\nstatic void dict_limit(struct dictionary *dict, size_t out_max)\r\n{\r\nif (dict->end - dict->pos <= out_max)\r\ndict->limit = dict->end;\r\nelse\r\ndict->limit = dict->pos + out_max;\r\n}\r\nstatic inline bool dict_has_space(const struct dictionary *dict)\r\n{\r\nreturn dict->pos < dict->limit;\r\n}\r\nstatic inline uint32_t dict_get(const struct dictionary *dict, uint32_t dist)\r\n{\r\nsize_t offset = dict->pos - dist - 1;\r\nif (dist >= dict->pos)\r\noffset += dict->end;\r\nreturn dict->full > 0 ? dict->buf[offset] : 0;\r\n}\r\nstatic inline void dict_put(struct dictionary *dict, uint8_t byte)\r\n{\r\ndict->buf[dict->pos++] = byte;\r\nif (dict->full < dict->pos)\r\ndict->full = dict->pos;\r\n}\r\nstatic bool dict_repeat(struct dictionary *dict, uint32_t *len, uint32_t dist)\r\n{\r\nsize_t back;\r\nuint32_t left;\r\nif (dist >= dict->full || dist >= dict->size)\r\nreturn false;\r\nleft = min_t(size_t, dict->limit - dict->pos, *len);\r\n*len -= left;\r\nback = dict->pos - dist - 1;\r\nif (dist >= dict->pos)\r\nback += dict->end;\r\ndo {\r\ndict->buf[dict->pos++] = dict->buf[back++];\r\nif (back == dict->end)\r\nback = 0;\r\n} while (--left > 0);\r\nif (dict->full < dict->pos)\r\ndict->full = dict->pos;\r\nreturn true;\r\n}\r\nstatic void dict_uncompressed(struct dictionary *dict, struct xz_buf *b,\r\nuint32_t *left)\r\n{\r\nsize_t copy_size;\r\nwhile (*left > 0 && b->in_pos < b->in_size\r\n&& b->out_pos < b->out_size) {\r\ncopy_size = min(b->in_size - b->in_pos,\r\nb->out_size - b->out_pos);\r\nif (copy_size > dict->end - dict->pos)\r\ncopy_size = dict->end - dict->pos;\r\nif (copy_size > *left)\r\ncopy_size = *left;\r\n*left -= copy_size;\r\nmemcpy(dict->buf + dict->pos, b->in + b->in_pos, copy_size);\r\ndict->pos += copy_size;\r\nif (dict->full < dict->pos)\r\ndict->full = dict->pos;\r\nif (DEC_IS_MULTI(dict->mode)) {\r\nif (dict->pos == dict->end)\r\ndict->pos = 0;\r\nmemcpy(b->out + b->out_pos, b->in + b->in_pos,\r\ncopy_size);\r\n}\r\ndict->start = dict->pos;\r\nb->out_pos += copy_size;\r\nb->in_pos += copy_size;\r\n}\r\n}\r\nstatic uint32_t dict_flush(struct dictionary *dict, struct xz_buf *b)\r\n{\r\nsize_t copy_size = dict->pos - dict->start;\r\nif (DEC_IS_MULTI(dict->mode)) {\r\nif (dict->pos == dict->end)\r\ndict->pos = 0;\r\nmemcpy(b->out + b->out_pos, dict->buf + dict->start,\r\ncopy_size);\r\n}\r\ndict->start = dict->pos;\r\nb->out_pos += copy_size;\r\nreturn copy_size;\r\n}\r\nstatic void rc_reset(struct rc_dec *rc)\r\n{\r\nrc->range = (uint32_t)-1;\r\nrc->code = 0;\r\nrc->init_bytes_left = RC_INIT_BYTES;\r\n}\r\nstatic bool rc_read_init(struct rc_dec *rc, struct xz_buf *b)\r\n{\r\nwhile (rc->init_bytes_left > 0) {\r\nif (b->in_pos == b->in_size)\r\nreturn false;\r\nrc->code = (rc->code << 8) + b->in[b->in_pos++];\r\n--rc->init_bytes_left;\r\n}\r\nreturn true;\r\n}\r\nstatic inline bool rc_limit_exceeded(const struct rc_dec *rc)\r\n{\r\nreturn rc->in_pos > rc->in_limit;\r\n}\r\nstatic inline bool rc_is_finished(const struct rc_dec *rc)\r\n{\r\nreturn rc->code == 0;\r\n}\r\nstatic __always_inline void rc_normalize(struct rc_dec *rc)\r\n{\r\nif (rc->range < RC_TOP_VALUE) {\r\nrc->range <<= RC_SHIFT_BITS;\r\nrc->code = (rc->code << RC_SHIFT_BITS) + rc->in[rc->in_pos++];\r\n}\r\n}\r\nstatic __always_inline int rc_bit(struct rc_dec *rc, uint16_t *prob)\r\n{\r\nuint32_t bound;\r\nint bit;\r\nrc_normalize(rc);\r\nbound = (rc->range >> RC_BIT_MODEL_TOTAL_BITS) * *prob;\r\nif (rc->code < bound) {\r\nrc->range = bound;\r\n*prob += (RC_BIT_MODEL_TOTAL - *prob) >> RC_MOVE_BITS;\r\nbit = 0;\r\n} else {\r\nrc->range -= bound;\r\nrc->code -= bound;\r\n*prob -= *prob >> RC_MOVE_BITS;\r\nbit = 1;\r\n}\r\nreturn bit;\r\n}\r\nstatic __always_inline uint32_t rc_bittree(struct rc_dec *rc,\r\nuint16_t *probs, uint32_t limit)\r\n{\r\nuint32_t symbol = 1;\r\ndo {\r\nif (rc_bit(rc, &probs[symbol]))\r\nsymbol = (symbol << 1) + 1;\r\nelse\r\nsymbol <<= 1;\r\n} while (symbol < limit);\r\nreturn symbol;\r\n}\r\nstatic __always_inline void rc_bittree_reverse(struct rc_dec *rc,\r\nuint16_t *probs,\r\nuint32_t *dest, uint32_t limit)\r\n{\r\nuint32_t symbol = 1;\r\nuint32_t i = 0;\r\ndo {\r\nif (rc_bit(rc, &probs[symbol])) {\r\nsymbol = (symbol << 1) + 1;\r\n*dest += 1 << i;\r\n} else {\r\nsymbol <<= 1;\r\n}\r\n} while (++i < limit);\r\n}\r\nstatic inline void rc_direct(struct rc_dec *rc, uint32_t *dest, uint32_t limit)\r\n{\r\nuint32_t mask;\r\ndo {\r\nrc_normalize(rc);\r\nrc->range >>= 1;\r\nrc->code -= rc->range;\r\nmask = (uint32_t)0 - (rc->code >> 31);\r\nrc->code += rc->range & mask;\r\n*dest = (*dest << 1) + (mask + 1);\r\n} while (--limit > 0);\r\n}\r\nstatic uint16_t *lzma_literal_probs(struct xz_dec_lzma2 *s)\r\n{\r\nuint32_t prev_byte = dict_get(&s->dict, 0);\r\nuint32_t low = prev_byte >> (8 - s->lzma.lc);\r\nuint32_t high = (s->dict.pos & s->lzma.literal_pos_mask) << s->lzma.lc;\r\nreturn s->lzma.literal[low + high];\r\n}\r\nstatic void lzma_literal(struct xz_dec_lzma2 *s)\r\n{\r\nuint16_t *probs;\r\nuint32_t symbol;\r\nuint32_t match_byte;\r\nuint32_t match_bit;\r\nuint32_t offset;\r\nuint32_t i;\r\nprobs = lzma_literal_probs(s);\r\nif (lzma_state_is_literal(s->lzma.state)) {\r\nsymbol = rc_bittree(&s->rc, probs, 0x100);\r\n} else {\r\nsymbol = 1;\r\nmatch_byte = dict_get(&s->dict, s->lzma.rep0) << 1;\r\noffset = 0x100;\r\ndo {\r\nmatch_bit = match_byte & offset;\r\nmatch_byte <<= 1;\r\ni = offset + match_bit + symbol;\r\nif (rc_bit(&s->rc, &probs[i])) {\r\nsymbol = (symbol << 1) + 1;\r\noffset &= match_bit;\r\n} else {\r\nsymbol <<= 1;\r\noffset &= ~match_bit;\r\n}\r\n} while (symbol < 0x100);\r\n}\r\ndict_put(&s->dict, (uint8_t)symbol);\r\nlzma_state_literal(&s->lzma.state);\r\n}\r\nstatic void lzma_len(struct xz_dec_lzma2 *s, struct lzma_len_dec *l,\r\nuint32_t pos_state)\r\n{\r\nuint16_t *probs;\r\nuint32_t limit;\r\nif (!rc_bit(&s->rc, &l->choice)) {\r\nprobs = l->low[pos_state];\r\nlimit = LEN_LOW_SYMBOLS;\r\ns->lzma.len = MATCH_LEN_MIN;\r\n} else {\r\nif (!rc_bit(&s->rc, &l->choice2)) {\r\nprobs = l->mid[pos_state];\r\nlimit = LEN_MID_SYMBOLS;\r\ns->lzma.len = MATCH_LEN_MIN + LEN_LOW_SYMBOLS;\r\n} else {\r\nprobs = l->high;\r\nlimit = LEN_HIGH_SYMBOLS;\r\ns->lzma.len = MATCH_LEN_MIN + LEN_LOW_SYMBOLS\r\n+ LEN_MID_SYMBOLS;\r\n}\r\n}\r\ns->lzma.len += rc_bittree(&s->rc, probs, limit) - limit;\r\n}\r\nstatic void lzma_match(struct xz_dec_lzma2 *s, uint32_t pos_state)\r\n{\r\nuint16_t *probs;\r\nuint32_t dist_slot;\r\nuint32_t limit;\r\nlzma_state_match(&s->lzma.state);\r\ns->lzma.rep3 = s->lzma.rep2;\r\ns->lzma.rep2 = s->lzma.rep1;\r\ns->lzma.rep1 = s->lzma.rep0;\r\nlzma_len(s, &s->lzma.match_len_dec, pos_state);\r\nprobs = s->lzma.dist_slot[lzma_get_dist_state(s->lzma.len)];\r\ndist_slot = rc_bittree(&s->rc, probs, DIST_SLOTS) - DIST_SLOTS;\r\nif (dist_slot < DIST_MODEL_START) {\r\ns->lzma.rep0 = dist_slot;\r\n} else {\r\nlimit = (dist_slot >> 1) - 1;\r\ns->lzma.rep0 = 2 + (dist_slot & 1);\r\nif (dist_slot < DIST_MODEL_END) {\r\ns->lzma.rep0 <<= limit;\r\nprobs = s->lzma.dist_special + s->lzma.rep0\r\n- dist_slot - 1;\r\nrc_bittree_reverse(&s->rc, probs,\r\n&s->lzma.rep0, limit);\r\n} else {\r\nrc_direct(&s->rc, &s->lzma.rep0, limit - ALIGN_BITS);\r\ns->lzma.rep0 <<= ALIGN_BITS;\r\nrc_bittree_reverse(&s->rc, s->lzma.dist_align,\r\n&s->lzma.rep0, ALIGN_BITS);\r\n}\r\n}\r\n}\r\nstatic void lzma_rep_match(struct xz_dec_lzma2 *s, uint32_t pos_state)\r\n{\r\nuint32_t tmp;\r\nif (!rc_bit(&s->rc, &s->lzma.is_rep0[s->lzma.state])) {\r\nif (!rc_bit(&s->rc, &s->lzma.is_rep0_long[\r\ns->lzma.state][pos_state])) {\r\nlzma_state_short_rep(&s->lzma.state);\r\ns->lzma.len = 1;\r\nreturn;\r\n}\r\n} else {\r\nif (!rc_bit(&s->rc, &s->lzma.is_rep1[s->lzma.state])) {\r\ntmp = s->lzma.rep1;\r\n} else {\r\nif (!rc_bit(&s->rc, &s->lzma.is_rep2[s->lzma.state])) {\r\ntmp = s->lzma.rep2;\r\n} else {\r\ntmp = s->lzma.rep3;\r\ns->lzma.rep3 = s->lzma.rep2;\r\n}\r\ns->lzma.rep2 = s->lzma.rep1;\r\n}\r\ns->lzma.rep1 = s->lzma.rep0;\r\ns->lzma.rep0 = tmp;\r\n}\r\nlzma_state_long_rep(&s->lzma.state);\r\nlzma_len(s, &s->lzma.rep_len_dec, pos_state);\r\n}\r\nstatic bool lzma_main(struct xz_dec_lzma2 *s)\r\n{\r\nuint32_t pos_state;\r\nif (dict_has_space(&s->dict) && s->lzma.len > 0)\r\ndict_repeat(&s->dict, &s->lzma.len, s->lzma.rep0);\r\nwhile (dict_has_space(&s->dict) && !rc_limit_exceeded(&s->rc)) {\r\npos_state = s->dict.pos & s->lzma.pos_mask;\r\nif (!rc_bit(&s->rc, &s->lzma.is_match[\r\ns->lzma.state][pos_state])) {\r\nlzma_literal(s);\r\n} else {\r\nif (rc_bit(&s->rc, &s->lzma.is_rep[s->lzma.state]))\r\nlzma_rep_match(s, pos_state);\r\nelse\r\nlzma_match(s, pos_state);\r\nif (!dict_repeat(&s->dict, &s->lzma.len, s->lzma.rep0))\r\nreturn false;\r\n}\r\n}\r\nrc_normalize(&s->rc);\r\nreturn true;\r\n}\r\nstatic void lzma_reset(struct xz_dec_lzma2 *s)\r\n{\r\nuint16_t *probs;\r\nsize_t i;\r\ns->lzma.state = STATE_LIT_LIT;\r\ns->lzma.rep0 = 0;\r\ns->lzma.rep1 = 0;\r\ns->lzma.rep2 = 0;\r\ns->lzma.rep3 = 0;\r\nprobs = s->lzma.is_match[0];\r\nfor (i = 0; i < PROBS_TOTAL; ++i)\r\nprobs[i] = RC_BIT_MODEL_TOTAL / 2;\r\nrc_reset(&s->rc);\r\n}\r\nstatic bool lzma_props(struct xz_dec_lzma2 *s, uint8_t props)\r\n{\r\nif (props > (4 * 5 + 4) * 9 + 8)\r\nreturn false;\r\ns->lzma.pos_mask = 0;\r\nwhile (props >= 9 * 5) {\r\nprops -= 9 * 5;\r\n++s->lzma.pos_mask;\r\n}\r\ns->lzma.pos_mask = (1 << s->lzma.pos_mask) - 1;\r\ns->lzma.literal_pos_mask = 0;\r\nwhile (props >= 9) {\r\nprops -= 9;\r\n++s->lzma.literal_pos_mask;\r\n}\r\ns->lzma.lc = props;\r\nif (s->lzma.lc + s->lzma.literal_pos_mask > 4)\r\nreturn false;\r\ns->lzma.literal_pos_mask = (1 << s->lzma.literal_pos_mask) - 1;\r\nlzma_reset(s);\r\nreturn true;\r\n}\r\nstatic bool lzma2_lzma(struct xz_dec_lzma2 *s, struct xz_buf *b)\r\n{\r\nsize_t in_avail;\r\nuint32_t tmp;\r\nin_avail = b->in_size - b->in_pos;\r\nif (s->temp.size > 0 || s->lzma2.compressed == 0) {\r\ntmp = 2 * LZMA_IN_REQUIRED - s->temp.size;\r\nif (tmp > s->lzma2.compressed - s->temp.size)\r\ntmp = s->lzma2.compressed - s->temp.size;\r\nif (tmp > in_avail)\r\ntmp = in_avail;\r\nmemcpy(s->temp.buf + s->temp.size, b->in + b->in_pos, tmp);\r\nif (s->temp.size + tmp == s->lzma2.compressed) {\r\nmemzero(s->temp.buf + s->temp.size + tmp,\r\nsizeof(s->temp.buf)\r\n- s->temp.size - tmp);\r\ns->rc.in_limit = s->temp.size + tmp;\r\n} else if (s->temp.size + tmp < LZMA_IN_REQUIRED) {\r\ns->temp.size += tmp;\r\nb->in_pos += tmp;\r\nreturn true;\r\n} else {\r\ns->rc.in_limit = s->temp.size + tmp - LZMA_IN_REQUIRED;\r\n}\r\ns->rc.in = s->temp.buf;\r\ns->rc.in_pos = 0;\r\nif (!lzma_main(s) || s->rc.in_pos > s->temp.size + tmp)\r\nreturn false;\r\ns->lzma2.compressed -= s->rc.in_pos;\r\nif (s->rc.in_pos < s->temp.size) {\r\ns->temp.size -= s->rc.in_pos;\r\nmemmove(s->temp.buf, s->temp.buf + s->rc.in_pos,\r\ns->temp.size);\r\nreturn true;\r\n}\r\nb->in_pos += s->rc.in_pos - s->temp.size;\r\ns->temp.size = 0;\r\n}\r\nin_avail = b->in_size - b->in_pos;\r\nif (in_avail >= LZMA_IN_REQUIRED) {\r\ns->rc.in = b->in;\r\ns->rc.in_pos = b->in_pos;\r\nif (in_avail >= s->lzma2.compressed + LZMA_IN_REQUIRED)\r\ns->rc.in_limit = b->in_pos + s->lzma2.compressed;\r\nelse\r\ns->rc.in_limit = b->in_size - LZMA_IN_REQUIRED;\r\nif (!lzma_main(s))\r\nreturn false;\r\nin_avail = s->rc.in_pos - b->in_pos;\r\nif (in_avail > s->lzma2.compressed)\r\nreturn false;\r\ns->lzma2.compressed -= in_avail;\r\nb->in_pos = s->rc.in_pos;\r\n}\r\nin_avail = b->in_size - b->in_pos;\r\nif (in_avail < LZMA_IN_REQUIRED) {\r\nif (in_avail > s->lzma2.compressed)\r\nin_avail = s->lzma2.compressed;\r\nmemcpy(s->temp.buf, b->in + b->in_pos, in_avail);\r\ns->temp.size = in_avail;\r\nb->in_pos += in_avail;\r\n}\r\nreturn true;\r\n}\r\nXZ_EXTERN enum xz_ret xz_dec_lzma2_run(struct xz_dec_lzma2 *s,\r\nstruct xz_buf *b)\r\n{\r\nuint32_t tmp;\r\nwhile (b->in_pos < b->in_size || s->lzma2.sequence == SEQ_LZMA_RUN) {\r\nswitch (s->lzma2.sequence) {\r\ncase SEQ_CONTROL:\r\ntmp = b->in[b->in_pos++];\r\nif (tmp == 0x00)\r\nreturn XZ_STREAM_END;\r\nif (tmp >= 0xE0 || tmp == 0x01) {\r\ns->lzma2.need_props = true;\r\ns->lzma2.need_dict_reset = false;\r\ndict_reset(&s->dict, b);\r\n} else if (s->lzma2.need_dict_reset) {\r\nreturn XZ_DATA_ERROR;\r\n}\r\nif (tmp >= 0x80) {\r\ns->lzma2.uncompressed = (tmp & 0x1F) << 16;\r\ns->lzma2.sequence = SEQ_UNCOMPRESSED_1;\r\nif (tmp >= 0xC0) {\r\ns->lzma2.need_props = false;\r\ns->lzma2.next_sequence\r\n= SEQ_PROPERTIES;\r\n} else if (s->lzma2.need_props) {\r\nreturn XZ_DATA_ERROR;\r\n} else {\r\ns->lzma2.next_sequence\r\n= SEQ_LZMA_PREPARE;\r\nif (tmp >= 0xA0)\r\nlzma_reset(s);\r\n}\r\n} else {\r\nif (tmp > 0x02)\r\nreturn XZ_DATA_ERROR;\r\ns->lzma2.sequence = SEQ_COMPRESSED_0;\r\ns->lzma2.next_sequence = SEQ_COPY;\r\n}\r\nbreak;\r\ncase SEQ_UNCOMPRESSED_1:\r\ns->lzma2.uncompressed\r\n+= (uint32_t)b->in[b->in_pos++] << 8;\r\ns->lzma2.sequence = SEQ_UNCOMPRESSED_2;\r\nbreak;\r\ncase SEQ_UNCOMPRESSED_2:\r\ns->lzma2.uncompressed\r\n+= (uint32_t)b->in[b->in_pos++] + 1;\r\ns->lzma2.sequence = SEQ_COMPRESSED_0;\r\nbreak;\r\ncase SEQ_COMPRESSED_0:\r\ns->lzma2.compressed\r\n= (uint32_t)b->in[b->in_pos++] << 8;\r\ns->lzma2.sequence = SEQ_COMPRESSED_1;\r\nbreak;\r\ncase SEQ_COMPRESSED_1:\r\ns->lzma2.compressed\r\n+= (uint32_t)b->in[b->in_pos++] + 1;\r\ns->lzma2.sequence = s->lzma2.next_sequence;\r\nbreak;\r\ncase SEQ_PROPERTIES:\r\nif (!lzma_props(s, b->in[b->in_pos++]))\r\nreturn XZ_DATA_ERROR;\r\ns->lzma2.sequence = SEQ_LZMA_PREPARE;\r\ncase SEQ_LZMA_PREPARE:\r\nif (s->lzma2.compressed < RC_INIT_BYTES)\r\nreturn XZ_DATA_ERROR;\r\nif (!rc_read_init(&s->rc, b))\r\nreturn XZ_OK;\r\ns->lzma2.compressed -= RC_INIT_BYTES;\r\ns->lzma2.sequence = SEQ_LZMA_RUN;\r\ncase SEQ_LZMA_RUN:\r\ndict_limit(&s->dict, min_t(size_t,\r\nb->out_size - b->out_pos,\r\ns->lzma2.uncompressed));\r\nif (!lzma2_lzma(s, b))\r\nreturn XZ_DATA_ERROR;\r\ns->lzma2.uncompressed -= dict_flush(&s->dict, b);\r\nif (s->lzma2.uncompressed == 0) {\r\nif (s->lzma2.compressed > 0 || s->lzma.len > 0\r\n|| !rc_is_finished(&s->rc))\r\nreturn XZ_DATA_ERROR;\r\nrc_reset(&s->rc);\r\ns->lzma2.sequence = SEQ_CONTROL;\r\n} else if (b->out_pos == b->out_size\r\n|| (b->in_pos == b->in_size\r\n&& s->temp.size\r\n< s->lzma2.compressed)) {\r\nreturn XZ_OK;\r\n}\r\nbreak;\r\ncase SEQ_COPY:\r\ndict_uncompressed(&s->dict, b, &s->lzma2.compressed);\r\nif (s->lzma2.compressed > 0)\r\nreturn XZ_OK;\r\ns->lzma2.sequence = SEQ_CONTROL;\r\nbreak;\r\n}\r\n}\r\nreturn XZ_OK;\r\n}\r\nXZ_EXTERN struct xz_dec_lzma2 *xz_dec_lzma2_create(enum xz_mode mode,\r\nuint32_t dict_max)\r\n{\r\nstruct xz_dec_lzma2 *s = kmalloc(sizeof(*s), GFP_KERNEL);\r\nif (s == NULL)\r\nreturn NULL;\r\ns->dict.mode = mode;\r\ns->dict.size_max = dict_max;\r\nif (DEC_IS_PREALLOC(mode)) {\r\ns->dict.buf = vmalloc(dict_max);\r\nif (s->dict.buf == NULL) {\r\nkfree(s);\r\nreturn NULL;\r\n}\r\n} else if (DEC_IS_DYNALLOC(mode)) {\r\ns->dict.buf = NULL;\r\ns->dict.allocated = 0;\r\n}\r\nreturn s;\r\n}\r\nXZ_EXTERN enum xz_ret xz_dec_lzma2_reset(struct xz_dec_lzma2 *s, uint8_t props)\r\n{\r\nif (props > 39)\r\nreturn XZ_OPTIONS_ERROR;\r\ns->dict.size = 2 + (props & 1);\r\ns->dict.size <<= (props >> 1) + 11;\r\nif (DEC_IS_MULTI(s->dict.mode)) {\r\nif (s->dict.size > s->dict.size_max)\r\nreturn XZ_MEMLIMIT_ERROR;\r\ns->dict.end = s->dict.size;\r\nif (DEC_IS_DYNALLOC(s->dict.mode)) {\r\nif (s->dict.allocated < s->dict.size) {\r\nvfree(s->dict.buf);\r\ns->dict.buf = vmalloc(s->dict.size);\r\nif (s->dict.buf == NULL) {\r\ns->dict.allocated = 0;\r\nreturn XZ_MEM_ERROR;\r\n}\r\n}\r\n}\r\n}\r\ns->lzma.len = 0;\r\ns->lzma2.sequence = SEQ_CONTROL;\r\ns->lzma2.need_dict_reset = true;\r\ns->temp.size = 0;\r\nreturn XZ_OK;\r\n}\r\nXZ_EXTERN void xz_dec_lzma2_end(struct xz_dec_lzma2 *s)\r\n{\r\nif (DEC_IS_MULTI(s->dict.mode))\r\nvfree(s->dict.buf);\r\nkfree(s);\r\n}
