static void kvmppc_mmu_book3s_64_reset_msr(struct kvm_vcpu *vcpu)\r\n{\r\nkvmppc_set_msr(vcpu, MSR_SF);\r\n}\r\nstatic struct kvmppc_slb *kvmppc_mmu_book3s_64_find_slbe(\r\nstruct kvm_vcpu *vcpu,\r\ngva_t eaddr)\r\n{\r\nint i;\r\nu64 esid = GET_ESID(eaddr);\r\nu64 esid_1t = GET_ESID_1T(eaddr);\r\nfor (i = 0; i < vcpu->arch.slb_nr; i++) {\r\nu64 cmp_esid = esid;\r\nif (!vcpu->arch.slb[i].valid)\r\ncontinue;\r\nif (vcpu->arch.slb[i].tb)\r\ncmp_esid = esid_1t;\r\nif (vcpu->arch.slb[i].esid == cmp_esid)\r\nreturn &vcpu->arch.slb[i];\r\n}\r\ndprintk("KVM: No SLB entry found for 0x%lx [%llx | %llx]\n",\r\neaddr, esid, esid_1t);\r\nfor (i = 0; i < vcpu->arch.slb_nr; i++) {\r\nif (vcpu->arch.slb[i].vsid)\r\ndprintk(" %d: %c%c%c %llx %llx\n", i,\r\nvcpu->arch.slb[i].valid ? 'v' : ' ',\r\nvcpu->arch.slb[i].large ? 'l' : ' ',\r\nvcpu->arch.slb[i].tb ? 't' : ' ',\r\nvcpu->arch.slb[i].esid,\r\nvcpu->arch.slb[i].vsid);\r\n}\r\nreturn NULL;\r\n}\r\nstatic int kvmppc_slb_sid_shift(struct kvmppc_slb *slbe)\r\n{\r\nreturn slbe->tb ? SID_SHIFT_1T : SID_SHIFT;\r\n}\r\nstatic u64 kvmppc_slb_offset_mask(struct kvmppc_slb *slbe)\r\n{\r\nreturn (1ul << kvmppc_slb_sid_shift(slbe)) - 1;\r\n}\r\nstatic u64 kvmppc_slb_calc_vpn(struct kvmppc_slb *slb, gva_t eaddr)\r\n{\r\neaddr &= kvmppc_slb_offset_mask(slb);\r\nreturn (eaddr >> VPN_SHIFT) |\r\n((slb->vsid) << (kvmppc_slb_sid_shift(slb) - VPN_SHIFT));\r\n}\r\nstatic u64 kvmppc_mmu_book3s_64_ea_to_vp(struct kvm_vcpu *vcpu, gva_t eaddr,\r\nbool data)\r\n{\r\nstruct kvmppc_slb *slb;\r\nslb = kvmppc_mmu_book3s_64_find_slbe(vcpu, eaddr);\r\nif (!slb)\r\nreturn 0;\r\nreturn kvmppc_slb_calc_vpn(slb, eaddr);\r\n}\r\nstatic int mmu_pagesize(int mmu_pg)\r\n{\r\nswitch (mmu_pg) {\r\ncase MMU_PAGE_64K:\r\nreturn 16;\r\ncase MMU_PAGE_16M:\r\nreturn 24;\r\n}\r\nreturn 12;\r\n}\r\nstatic int kvmppc_mmu_book3s_64_get_pagesize(struct kvmppc_slb *slbe)\r\n{\r\nreturn mmu_pagesize(slbe->base_page_size);\r\n}\r\nstatic u32 kvmppc_mmu_book3s_64_get_page(struct kvmppc_slb *slbe, gva_t eaddr)\r\n{\r\nint p = kvmppc_mmu_book3s_64_get_pagesize(slbe);\r\nreturn ((eaddr & kvmppc_slb_offset_mask(slbe)) >> p);\r\n}\r\nstatic hva_t kvmppc_mmu_book3s_64_get_pteg(struct kvm_vcpu *vcpu,\r\nstruct kvmppc_slb *slbe, gva_t eaddr,\r\nbool second)\r\n{\r\nstruct kvmppc_vcpu_book3s *vcpu_book3s = to_book3s(vcpu);\r\nu64 hash, pteg, htabsize;\r\nu32 ssize;\r\nhva_t r;\r\nu64 vpn;\r\nhtabsize = ((1 << ((vcpu_book3s->sdr1 & 0x1f) + 11)) - 1);\r\nvpn = kvmppc_slb_calc_vpn(slbe, eaddr);\r\nssize = slbe->tb ? MMU_SEGSIZE_1T : MMU_SEGSIZE_256M;\r\nhash = hpt_hash(vpn, kvmppc_mmu_book3s_64_get_pagesize(slbe), ssize);\r\nif (second)\r\nhash = ~hash;\r\nhash &= ((1ULL << 39ULL) - 1ULL);\r\nhash &= htabsize;\r\nhash <<= 7ULL;\r\npteg = vcpu_book3s->sdr1 & 0xfffffffffffc0000ULL;\r\npteg |= hash;\r\ndprintk("MMU: page=0x%x sdr1=0x%llx pteg=0x%llx vsid=0x%llx\n",\r\npage, vcpu_book3s->sdr1, pteg, slbe->vsid);\r\nif (vcpu->arch.papr_enabled)\r\nr = pteg;\r\nelse\r\nr = gfn_to_hva(vcpu->kvm, pteg >> PAGE_SHIFT);\r\nif (kvm_is_error_hva(r))\r\nreturn r;\r\nreturn r | (pteg & ~PAGE_MASK);\r\n}\r\nstatic u64 kvmppc_mmu_book3s_64_get_avpn(struct kvmppc_slb *slbe, gva_t eaddr)\r\n{\r\nint p = kvmppc_mmu_book3s_64_get_pagesize(slbe);\r\nu64 avpn;\r\navpn = kvmppc_mmu_book3s_64_get_page(slbe, eaddr);\r\navpn |= slbe->vsid << (kvmppc_slb_sid_shift(slbe) - p);\r\nif (p < 16)\r\navpn >>= ((80 - p) - 56) - 8;\r\nelse\r\navpn <<= p - 16;\r\nreturn avpn;\r\n}\r\nstatic int decode_pagesize(struct kvmppc_slb *slbe, u64 r)\r\n{\r\nswitch (slbe->base_page_size) {\r\ncase MMU_PAGE_64K:\r\nif ((r & 0xf000) == 0x1000)\r\nreturn MMU_PAGE_64K;\r\nbreak;\r\ncase MMU_PAGE_16M:\r\nif ((r & 0xff000) == 0)\r\nreturn MMU_PAGE_16M;\r\nbreak;\r\n}\r\nreturn -1;\r\n}\r\nstatic int kvmppc_mmu_book3s_64_xlate(struct kvm_vcpu *vcpu, gva_t eaddr,\r\nstruct kvmppc_pte *gpte, bool data,\r\nbool iswrite)\r\n{\r\nstruct kvmppc_slb *slbe;\r\nhva_t ptegp;\r\nu64 pteg[16];\r\nu64 avpn = 0;\r\nu64 v, r;\r\nu64 v_val, v_mask;\r\nu64 eaddr_mask;\r\nint i;\r\nu8 pp, key = 0;\r\nbool found = false;\r\nbool second = false;\r\nint pgsize;\r\nulong mp_ea = vcpu->arch.magic_page_ea;\r\nif (unlikely(mp_ea) &&\r\nunlikely((eaddr & ~0xfffULL) == (mp_ea & ~0xfffULL)) &&\r\n!(vcpu->arch.shared->msr & MSR_PR)) {\r\ngpte->eaddr = eaddr;\r\ngpte->vpage = kvmppc_mmu_book3s_64_ea_to_vp(vcpu, eaddr, data);\r\ngpte->raddr = vcpu->arch.magic_page_pa | (gpte->raddr & 0xfff);\r\ngpte->raddr &= KVM_PAM;\r\ngpte->may_execute = true;\r\ngpte->may_read = true;\r\ngpte->may_write = true;\r\ngpte->page_size = MMU_PAGE_4K;\r\nreturn 0;\r\n}\r\nslbe = kvmppc_mmu_book3s_64_find_slbe(vcpu, eaddr);\r\nif (!slbe)\r\ngoto no_seg_found;\r\navpn = kvmppc_mmu_book3s_64_get_avpn(slbe, eaddr);\r\nv_val = avpn & HPTE_V_AVPN;\r\nif (slbe->tb)\r\nv_val |= SLB_VSID_B_1T;\r\nif (slbe->large)\r\nv_val |= HPTE_V_LARGE;\r\nv_val |= HPTE_V_VALID;\r\nv_mask = SLB_VSID_B | HPTE_V_AVPN | HPTE_V_LARGE | HPTE_V_VALID |\r\nHPTE_V_SECONDARY;\r\npgsize = slbe->large ? MMU_PAGE_16M : MMU_PAGE_4K;\r\nmutex_lock(&vcpu->kvm->arch.hpt_mutex);\r\ndo_second:\r\nptegp = kvmppc_mmu_book3s_64_get_pteg(vcpu, slbe, eaddr, second);\r\nif (kvm_is_error_hva(ptegp))\r\ngoto no_page_found;\r\nif(copy_from_user(pteg, (void __user *)ptegp, sizeof(pteg))) {\r\nprintk(KERN_ERR "KVM can't copy data from 0x%lx!\n", ptegp);\r\ngoto no_page_found;\r\n}\r\nif ((vcpu->arch.shared->msr & MSR_PR) && slbe->Kp)\r\nkey = 4;\r\nelse if (!(vcpu->arch.shared->msr & MSR_PR) && slbe->Ks)\r\nkey = 4;\r\nfor (i=0; i<16; i+=2) {\r\nif ((pteg[i] & v_mask) == v_val) {\r\nif (slbe->large &&\r\n(vcpu->arch.hflags & BOOK3S_HFLAG_MULTI_PGSIZE)) {\r\npgsize = decode_pagesize(slbe, pteg[i+1]);\r\nif (pgsize < 0)\r\ncontinue;\r\n}\r\nfound = true;\r\nbreak;\r\n}\r\n}\r\nif (!found) {\r\nif (second)\r\ngoto no_page_found;\r\nv_val |= HPTE_V_SECONDARY;\r\nsecond = true;\r\ngoto do_second;\r\n}\r\nv = pteg[i];\r\nr = pteg[i+1];\r\npp = (r & HPTE_R_PP) | key;\r\nif (r & HPTE_R_PP0)\r\npp |= 8;\r\ngpte->eaddr = eaddr;\r\ngpte->vpage = kvmppc_mmu_book3s_64_ea_to_vp(vcpu, eaddr, data);\r\neaddr_mask = (1ull << mmu_pagesize(pgsize)) - 1;\r\ngpte->raddr = (r & HPTE_R_RPN & ~eaddr_mask) | (eaddr & eaddr_mask);\r\ngpte->page_size = pgsize;\r\ngpte->may_execute = ((r & HPTE_R_N) ? false : true);\r\ngpte->may_read = false;\r\ngpte->may_write = false;\r\nswitch (pp) {\r\ncase 0:\r\ncase 1:\r\ncase 2:\r\ncase 6:\r\ngpte->may_write = true;\r\ncase 3:\r\ncase 5:\r\ncase 7:\r\ncase 10:\r\ngpte->may_read = true;\r\nbreak;\r\n}\r\ndprintk("KVM MMU: Translated 0x%lx [0x%llx] -> 0x%llx "\r\n"-> 0x%lx\n",\r\neaddr, avpn, gpte->vpage, gpte->raddr);\r\nif (gpte->may_read && !(r & HPTE_R_R)) {\r\nchar __user *addr = (char __user *) &pteg[i+1];\r\nr |= HPTE_R_R;\r\nput_user(r >> 8, addr + 6);\r\n}\r\nif (iswrite && gpte->may_write && !(r & HPTE_R_C)) {\r\nchar __user *addr = (char __user *) &pteg[i+1];\r\nr |= HPTE_R_C;\r\nput_user(r, addr + 7);\r\n}\r\nmutex_unlock(&vcpu->kvm->arch.hpt_mutex);\r\nif (!gpte->may_read || (iswrite && !gpte->may_write))\r\nreturn -EPERM;\r\nreturn 0;\r\nno_page_found:\r\nmutex_unlock(&vcpu->kvm->arch.hpt_mutex);\r\nreturn -ENOENT;\r\nno_seg_found:\r\ndprintk("KVM MMU: Trigger segment fault\n");\r\nreturn -EINVAL;\r\n}\r\nstatic void kvmppc_mmu_book3s_64_slbmte(struct kvm_vcpu *vcpu, u64 rs, u64 rb)\r\n{\r\nstruct kvmppc_vcpu_book3s *vcpu_book3s;\r\nu64 esid, esid_1t;\r\nint slb_nr;\r\nstruct kvmppc_slb *slbe;\r\ndprintk("KVM MMU: slbmte(0x%llx, 0x%llx)\n", rs, rb);\r\nvcpu_book3s = to_book3s(vcpu);\r\nesid = GET_ESID(rb);\r\nesid_1t = GET_ESID_1T(rb);\r\nslb_nr = rb & 0xfff;\r\nif (slb_nr > vcpu->arch.slb_nr)\r\nreturn;\r\nslbe = &vcpu->arch.slb[slb_nr];\r\nslbe->large = (rs & SLB_VSID_L) ? 1 : 0;\r\nslbe->tb = (rs & SLB_VSID_B_1T) ? 1 : 0;\r\nslbe->esid = slbe->tb ? esid_1t : esid;\r\nslbe->vsid = (rs & ~SLB_VSID_B) >> (kvmppc_slb_sid_shift(slbe) - 16);\r\nslbe->valid = (rb & SLB_ESID_V) ? 1 : 0;\r\nslbe->Ks = (rs & SLB_VSID_KS) ? 1 : 0;\r\nslbe->Kp = (rs & SLB_VSID_KP) ? 1 : 0;\r\nslbe->nx = (rs & SLB_VSID_N) ? 1 : 0;\r\nslbe->class = (rs & SLB_VSID_C) ? 1 : 0;\r\nslbe->base_page_size = MMU_PAGE_4K;\r\nif (slbe->large) {\r\nif (vcpu->arch.hflags & BOOK3S_HFLAG_MULTI_PGSIZE) {\r\nswitch (rs & SLB_VSID_LP) {\r\ncase SLB_VSID_LP_00:\r\nslbe->base_page_size = MMU_PAGE_16M;\r\nbreak;\r\ncase SLB_VSID_LP_01:\r\nslbe->base_page_size = MMU_PAGE_64K;\r\nbreak;\r\n}\r\n} else\r\nslbe->base_page_size = MMU_PAGE_16M;\r\n}\r\nslbe->orige = rb & (ESID_MASK | SLB_ESID_V);\r\nslbe->origv = rs;\r\nkvmppc_mmu_map_segment(vcpu, esid << SID_SHIFT);\r\n}\r\nstatic u64 kvmppc_mmu_book3s_64_slbmfee(struct kvm_vcpu *vcpu, u64 slb_nr)\r\n{\r\nstruct kvmppc_slb *slbe;\r\nif (slb_nr > vcpu->arch.slb_nr)\r\nreturn 0;\r\nslbe = &vcpu->arch.slb[slb_nr];\r\nreturn slbe->orige;\r\n}\r\nstatic u64 kvmppc_mmu_book3s_64_slbmfev(struct kvm_vcpu *vcpu, u64 slb_nr)\r\n{\r\nstruct kvmppc_slb *slbe;\r\nif (slb_nr > vcpu->arch.slb_nr)\r\nreturn 0;\r\nslbe = &vcpu->arch.slb[slb_nr];\r\nreturn slbe->origv;\r\n}\r\nstatic void kvmppc_mmu_book3s_64_slbie(struct kvm_vcpu *vcpu, u64 ea)\r\n{\r\nstruct kvmppc_slb *slbe;\r\nu64 seg_size;\r\ndprintk("KVM MMU: slbie(0x%llx)\n", ea);\r\nslbe = kvmppc_mmu_book3s_64_find_slbe(vcpu, ea);\r\nif (!slbe)\r\nreturn;\r\ndprintk("KVM MMU: slbie(0x%llx, 0x%llx)\n", ea, slbe->esid);\r\nslbe->valid = false;\r\nslbe->orige = 0;\r\nslbe->origv = 0;\r\nseg_size = 1ull << kvmppc_slb_sid_shift(slbe);\r\nkvmppc_mmu_flush_segment(vcpu, ea & ~(seg_size - 1), seg_size);\r\n}\r\nstatic void kvmppc_mmu_book3s_64_slbia(struct kvm_vcpu *vcpu)\r\n{\r\nint i;\r\ndprintk("KVM MMU: slbia()\n");\r\nfor (i = 1; i < vcpu->arch.slb_nr; i++) {\r\nvcpu->arch.slb[i].valid = false;\r\nvcpu->arch.slb[i].orige = 0;\r\nvcpu->arch.slb[i].origv = 0;\r\n}\r\nif (vcpu->arch.shared->msr & MSR_IR) {\r\nkvmppc_mmu_flush_segments(vcpu);\r\nkvmppc_mmu_map_segment(vcpu, kvmppc_get_pc(vcpu));\r\n}\r\n}\r\nstatic void kvmppc_mmu_book3s_64_mtsrin(struct kvm_vcpu *vcpu, u32 srnum,\r\nulong value)\r\n{\r\nu64 rb = 0, rs = 0;\r\ndprintk("KVM MMU: mtsrin(0x%x, 0x%lx)\n", srnum, value);\r\nrb |= (srnum & 0xf) << 28;\r\nrb |= 1 << 27;\r\nrb |= srnum;\r\nrs |= (value & 0xfffffff) << 12;\r\nrs |= ((value >> 28) & 0x7) << 9;\r\nkvmppc_mmu_book3s_64_slbmte(vcpu, rs, rb);\r\n}\r\nstatic void kvmppc_mmu_book3s_64_tlbie(struct kvm_vcpu *vcpu, ulong va,\r\nbool large)\r\n{\r\nu64 mask = 0xFFFFFFFFFULL;\r\nlong i;\r\nstruct kvm_vcpu *v;\r\ndprintk("KVM MMU: tlbie(0x%lx)\n", va);\r\nif (vcpu->arch.hflags & BOOK3S_HFLAG_NEW_TLBIE) {\r\nif (va & 1) {\r\nif ((va & 0xf000) == 0x1000)\r\nmask = 0xFFFFFFFF0ULL;\r\nelse\r\nmask = 0xFFFFFF000ULL;\r\n}\r\n} else {\r\nif (large)\r\nmask = 0xFFFFFF000ULL;\r\n}\r\nkvm_for_each_vcpu(i, v, vcpu->kvm)\r\nkvmppc_mmu_pte_vflush(v, va >> 12, mask);\r\n}\r\nstatic int segment_contains_magic_page(struct kvm_vcpu *vcpu, ulong esid)\r\n{\r\nulong mp_ea = vcpu->arch.magic_page_ea;\r\nreturn mp_ea && !(vcpu->arch.shared->msr & MSR_PR) &&\r\n(mp_ea >> SID_SHIFT) == esid;\r\n}\r\nstatic int kvmppc_mmu_book3s_64_esid_to_vsid(struct kvm_vcpu *vcpu, ulong esid,\r\nu64 *vsid)\r\n{\r\nulong ea = esid << SID_SHIFT;\r\nstruct kvmppc_slb *slb;\r\nu64 gvsid = esid;\r\nulong mp_ea = vcpu->arch.magic_page_ea;\r\nint pagesize = MMU_PAGE_64K;\r\nif (vcpu->arch.shared->msr & (MSR_DR|MSR_IR)) {\r\nslb = kvmppc_mmu_book3s_64_find_slbe(vcpu, ea);\r\nif (slb) {\r\ngvsid = slb->vsid;\r\npagesize = slb->base_page_size;\r\nif (slb->tb) {\r\ngvsid <<= SID_SHIFT_1T - SID_SHIFT;\r\ngvsid |= esid & ((1ul << (SID_SHIFT_1T - SID_SHIFT)) - 1);\r\ngvsid |= VSID_1T;\r\n}\r\n}\r\n}\r\nswitch (vcpu->arch.shared->msr & (MSR_DR|MSR_IR)) {\r\ncase 0:\r\ngvsid = VSID_REAL | esid;\r\nbreak;\r\ncase MSR_IR:\r\ngvsid |= VSID_REAL_IR;\r\nbreak;\r\ncase MSR_DR:\r\ngvsid |= VSID_REAL_DR;\r\nbreak;\r\ncase MSR_DR|MSR_IR:\r\nif (!slb)\r\ngoto no_slb;\r\nbreak;\r\ndefault:\r\nBUG();\r\nbreak;\r\n}\r\n#ifdef CONFIG_PPC_64K_PAGES\r\nif (pagesize >= MMU_PAGE_64K &&\r\nmmu_psize_defs[MMU_PAGE_64K].shift &&\r\n!segment_contains_magic_page(vcpu, esid))\r\ngvsid |= VSID_64K;\r\n#endif\r\nif (vcpu->arch.shared->msr & MSR_PR)\r\ngvsid |= VSID_PR;\r\n*vsid = gvsid;\r\nreturn 0;\r\nno_slb:\r\nif (unlikely(mp_ea) &&\r\nunlikely(esid == (mp_ea >> SID_SHIFT)) &&\r\n!(vcpu->arch.shared->msr & MSR_PR)) {\r\n*vsid = VSID_REAL | esid;\r\nreturn 0;\r\n}\r\nreturn -EINVAL;\r\n}\r\nstatic bool kvmppc_mmu_book3s_64_is_dcbz32(struct kvm_vcpu *vcpu)\r\n{\r\nreturn (to_book3s(vcpu)->hid[5] & 0x80);\r\n}\r\nvoid kvmppc_mmu_book3s_64_init(struct kvm_vcpu *vcpu)\r\n{\r\nstruct kvmppc_mmu *mmu = &vcpu->arch.mmu;\r\nmmu->mfsrin = NULL;\r\nmmu->mtsrin = kvmppc_mmu_book3s_64_mtsrin;\r\nmmu->slbmte = kvmppc_mmu_book3s_64_slbmte;\r\nmmu->slbmfee = kvmppc_mmu_book3s_64_slbmfee;\r\nmmu->slbmfev = kvmppc_mmu_book3s_64_slbmfev;\r\nmmu->slbie = kvmppc_mmu_book3s_64_slbie;\r\nmmu->slbia = kvmppc_mmu_book3s_64_slbia;\r\nmmu->xlate = kvmppc_mmu_book3s_64_xlate;\r\nmmu->reset_msr = kvmppc_mmu_book3s_64_reset_msr;\r\nmmu->tlbie = kvmppc_mmu_book3s_64_tlbie;\r\nmmu->esid_to_vsid = kvmppc_mmu_book3s_64_esid_to_vsid;\r\nmmu->ea_to_vp = kvmppc_mmu_book3s_64_ea_to_vp;\r\nmmu->is_dcbz32 = kvmppc_mmu_book3s_64_is_dcbz32;\r\nvcpu->arch.hflags |= BOOK3S_HFLAG_SLB;\r\n}
