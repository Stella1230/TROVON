u32 mega_mod64(u64 dividend, u32 divisor)\r\n{\r\nu64 d;\r\nu32 remainder;\r\nif (!divisor)\r\nprintk(KERN_ERR "megasas : DIVISOR is zero, in div fn\n");\r\nd = dividend;\r\nremainder = do_div(d, divisor);\r\nreturn remainder;\r\n}\r\nu64 mega_div64_32(uint64_t dividend, uint32_t divisor)\r\n{\r\nu32 remainder;\r\nu64 d;\r\nif (!divisor)\r\nprintk(KERN_ERR "megasas : DIVISOR is zero in mod fn\n");\r\nd = dividend;\r\nremainder = do_div(d, divisor);\r\nreturn d;\r\n}\r\nstruct MR_LD_RAID *MR_LdRaidGet(u32 ld, struct MR_FW_RAID_MAP_ALL *map)\r\n{\r\nreturn &map->raidMap.ldSpanMap[ld].ldRaid;\r\n}\r\nstatic struct MR_SPAN_BLOCK_INFO *MR_LdSpanInfoGet(u32 ld,\r\nstruct MR_FW_RAID_MAP_ALL\r\n*map)\r\n{\r\nreturn &map->raidMap.ldSpanMap[ld].spanBlock[0];\r\n}\r\nstatic u8 MR_LdDataArmGet(u32 ld, u32 armIdx, struct MR_FW_RAID_MAP_ALL *map)\r\n{\r\nreturn map->raidMap.ldSpanMap[ld].dataArmMap[armIdx];\r\n}\r\nu16 MR_ArPdGet(u32 ar, u32 arm, struct MR_FW_RAID_MAP_ALL *map)\r\n{\r\nreturn le16_to_cpu(map->raidMap.arMapInfo[ar].pd[arm]);\r\n}\r\nu16 MR_LdSpanArrayGet(u32 ld, u32 span, struct MR_FW_RAID_MAP_ALL *map)\r\n{\r\nreturn le16_to_cpu(map->raidMap.ldSpanMap[ld].spanBlock[span].span.arrayRef);\r\n}\r\nu16 MR_PdDevHandleGet(u32 pd, struct MR_FW_RAID_MAP_ALL *map)\r\n{\r\nreturn map->raidMap.devHndlInfo[pd].curDevHdl;\r\n}\r\nu16 MR_GetLDTgtId(u32 ld, struct MR_FW_RAID_MAP_ALL *map)\r\n{\r\nreturn map->raidMap.ldSpanMap[ld].ldRaid.targetId;\r\n}\r\nu16 MR_TargetIdToLdGet(u32 ldTgtId, struct MR_FW_RAID_MAP_ALL *map)\r\n{\r\nreturn le16_to_cpu(map->raidMap.ldTgtIdToLd[ldTgtId]);\r\n}\r\nstatic struct MR_LD_SPAN *MR_LdSpanPtrGet(u32 ld, u32 span,\r\nstruct MR_FW_RAID_MAP_ALL *map)\r\n{\r\nreturn &map->raidMap.ldSpanMap[ld].spanBlock[span].span;\r\n}\r\nu8 MR_ValidateMapInfo(struct megasas_instance *instance)\r\n{\r\nstruct fusion_context *fusion = instance->ctrl_context;\r\nstruct MR_FW_RAID_MAP_ALL *map = fusion->ld_map[(instance->map_id & 1)];\r\nstruct LD_LOAD_BALANCE_INFO *lbInfo = fusion->load_balance_info;\r\nPLD_SPAN_INFO ldSpanInfo = fusion->log_to_span;\r\nstruct MR_FW_RAID_MAP *pFwRaidMap = &map->raidMap;\r\nstruct MR_LD_RAID *raid;\r\nint ldCount, num_lds;\r\nu16 ld;\r\nif (le32_to_cpu(pFwRaidMap->totalSize) !=\r\n(sizeof(struct MR_FW_RAID_MAP) -sizeof(struct MR_LD_SPAN_MAP) +\r\n(sizeof(struct MR_LD_SPAN_MAP) * le32_to_cpu(pFwRaidMap->ldCount)))) {\r\nprintk(KERN_ERR "megasas: map info structure size 0x%x is not matching with ld count\n",\r\n(unsigned int)((sizeof(struct MR_FW_RAID_MAP) -\r\nsizeof(struct MR_LD_SPAN_MAP)) +\r\n(sizeof(struct MR_LD_SPAN_MAP) *\r\nle32_to_cpu(pFwRaidMap->ldCount))));\r\nprintk(KERN_ERR "megasas: span map %x, pFwRaidMap->totalSize "\r\n": %x\n", (unsigned int)sizeof(struct MR_LD_SPAN_MAP),\r\nle32_to_cpu(pFwRaidMap->totalSize));\r\nreturn 0;\r\n}\r\nif (instance->UnevenSpanSupport)\r\nmr_update_span_set(map, ldSpanInfo);\r\nmr_update_load_balance_params(map, lbInfo);\r\nnum_lds = le32_to_cpu(map->raidMap.ldCount);\r\nfor (ldCount = 0; ldCount < num_lds; ldCount++) {\r\nld = MR_TargetIdToLdGet(ldCount, map);\r\nraid = MR_LdRaidGet(ld, map);\r\nle32_to_cpus((u32 *)&raid->capability);\r\n}\r\nreturn 1;\r\n}\r\nu32 MR_GetSpanBlock(u32 ld, u64 row, u64 *span_blk,\r\nstruct MR_FW_RAID_MAP_ALL *map)\r\n{\r\nstruct MR_SPAN_BLOCK_INFO *pSpanBlock = MR_LdSpanInfoGet(ld, map);\r\nstruct MR_QUAD_ELEMENT *quad;\r\nstruct MR_LD_RAID *raid = MR_LdRaidGet(ld, map);\r\nu32 span, j;\r\nfor (span = 0; span < raid->spanDepth; span++, pSpanBlock++) {\r\nfor (j = 0; j < le32_to_cpu(pSpanBlock->block_span_info.noElements); j++) {\r\nquad = &pSpanBlock->block_span_info.quad[j];\r\nif (le32_to_cpu(quad->diff) == 0)\r\nreturn SPAN_INVALID;\r\nif (le64_to_cpu(quad->logStart) <= row && row <=\r\nle64_to_cpu(quad->logEnd) && (mega_mod64(row - le64_to_cpu(quad->logStart),\r\nle32_to_cpu(quad->diff))) == 0) {\r\nif (span_blk != NULL) {\r\nu64 blk, debugBlk;\r\nblk = mega_div64_32((row-le64_to_cpu(quad->logStart)), le32_to_cpu(quad->diff));\r\ndebugBlk = blk;\r\nblk = (blk + le64_to_cpu(quad->offsetInSpan)) << raid->stripeShift;\r\n*span_blk = blk;\r\n}\r\nreturn span;\r\n}\r\n}\r\n}\r\nreturn SPAN_INVALID;\r\n}\r\nstatic int getSpanInfo(struct MR_FW_RAID_MAP_ALL *map, PLD_SPAN_INFO ldSpanInfo)\r\n{\r\nu8 span;\r\nu32 element;\r\nstruct MR_LD_RAID *raid;\r\nLD_SPAN_SET *span_set;\r\nstruct MR_QUAD_ELEMENT *quad;\r\nint ldCount;\r\nu16 ld;\r\nfor (ldCount = 0; ldCount < MAX_LOGICAL_DRIVES; ldCount++) {\r\nld = MR_TargetIdToLdGet(ldCount, map);\r\nif (ld >= MAX_LOGICAL_DRIVES)\r\ncontinue;\r\nraid = MR_LdRaidGet(ld, map);\r\ndev_dbg(&instance->pdev->dev, "LD %x: span_depth=%x\n",\r\nld, raid->spanDepth);\r\nfor (span = 0; span < raid->spanDepth; span++)\r\ndev_dbg(&instance->pdev->dev, "Span=%x,"\r\n" number of quads=%x\n", span,\r\nle32_to_cpu(map->raidMap.ldSpanMap[ld].spanBlock[span].\r\nblock_span_info.noElements));\r\nfor (element = 0; element < MAX_QUAD_DEPTH; element++) {\r\nspan_set = &(ldSpanInfo[ld].span_set[element]);\r\nif (span_set->span_row_data_width == 0)\r\nbreak;\r\ndev_dbg(&instance->pdev->dev, "Span Set %x:"\r\n"width=%x, diff=%x\n", element,\r\n(unsigned int)span_set->span_row_data_width,\r\n(unsigned int)span_set->diff);\r\ndev_dbg(&instance->pdev->dev, "logical LBA"\r\n"start=0x%08lx, end=0x%08lx\n",\r\n(long unsigned int)span_set->log_start_lba,\r\n(long unsigned int)span_set->log_end_lba);\r\ndev_dbg(&instance->pdev->dev, "span row start=0x%08lx,"\r\n" end=0x%08lx\n",\r\n(long unsigned int)span_set->span_row_start,\r\n(long unsigned int)span_set->span_row_end);\r\ndev_dbg(&instance->pdev->dev, "data row start=0x%08lx,"\r\n" end=0x%08lx\n",\r\n(long unsigned int)span_set->data_row_start,\r\n(long unsigned int)span_set->data_row_end);\r\ndev_dbg(&instance->pdev->dev, "data strip start=0x%08lx,"\r\n" end=0x%08lx\n",\r\n(long unsigned int)span_set->data_strip_start,\r\n(long unsigned int)span_set->data_strip_end);\r\nfor (span = 0; span < raid->spanDepth; span++) {\r\nif (le32_to_cpu(map->raidMap.ldSpanMap[ld].spanBlock[span].\r\nblock_span_info.noElements) >=\r\nelement + 1) {\r\nquad = &map->raidMap.ldSpanMap[ld].\r\nspanBlock[span].block_span_info.\r\nquad[element];\r\ndev_dbg(&instance->pdev->dev, "Span=%x,"\r\n"Quad=%x, diff=%x\n", span,\r\nelement, le32_to_cpu(quad->diff));\r\ndev_dbg(&instance->pdev->dev,\r\n"offset_in_span=0x%08lx\n",\r\n(long unsigned int)le64_to_cpu(quad->offsetInSpan));\r\ndev_dbg(&instance->pdev->dev,\r\n"logical start=0x%08lx, end=0x%08lx\n",\r\n(long unsigned int)le64_to_cpu(quad->logStart),\r\n(long unsigned int)le64_to_cpu(quad->logEnd));\r\n}\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nu32 mr_spanset_get_span_block(struct megasas_instance *instance,\r\nu32 ld, u64 row, u64 *span_blk, struct MR_FW_RAID_MAP_ALL *map)\r\n{\r\nstruct fusion_context *fusion = instance->ctrl_context;\r\nstruct MR_LD_RAID *raid = MR_LdRaidGet(ld, map);\r\nLD_SPAN_SET *span_set;\r\nstruct MR_QUAD_ELEMENT *quad;\r\nu32 span, info;\r\nPLD_SPAN_INFO ldSpanInfo = fusion->log_to_span;\r\nfor (info = 0; info < MAX_QUAD_DEPTH; info++) {\r\nspan_set = &(ldSpanInfo[ld].span_set[info]);\r\nif (span_set->span_row_data_width == 0)\r\nbreak;\r\nif (row > span_set->data_row_end)\r\ncontinue;\r\nfor (span = 0; span < raid->spanDepth; span++)\r\nif (le32_to_cpu(map->raidMap.ldSpanMap[ld].spanBlock[span].\r\nblock_span_info.noElements) >= info+1) {\r\nquad = &map->raidMap.ldSpanMap[ld].\r\nspanBlock[span].\r\nblock_span_info.quad[info];\r\nif (le32_to_cpu(quad->diff == 0))\r\nreturn SPAN_INVALID;\r\nif (le64_to_cpu(quad->logStart) <= row &&\r\nrow <= le64_to_cpu(quad->logEnd) &&\r\n(mega_mod64(row - le64_to_cpu(quad->logStart),\r\nle32_to_cpu(quad->diff))) == 0) {\r\nif (span_blk != NULL) {\r\nu64 blk;\r\nblk = mega_div64_32\r\n((row - le64_to_cpu(quad->logStart)),\r\nle32_to_cpu(quad->diff));\r\nblk = (blk + le64_to_cpu(quad->offsetInSpan))\r\n<< raid->stripeShift;\r\n*span_blk = blk;\r\n}\r\nreturn span;\r\n}\r\n}\r\n}\r\nreturn SPAN_INVALID;\r\n}\r\nstatic u64 get_row_from_strip(struct megasas_instance *instance,\r\nu32 ld, u64 strip, struct MR_FW_RAID_MAP_ALL *map)\r\n{\r\nstruct fusion_context *fusion = instance->ctrl_context;\r\nstruct MR_LD_RAID *raid = MR_LdRaidGet(ld, map);\r\nLD_SPAN_SET *span_set;\r\nPLD_SPAN_INFO ldSpanInfo = fusion->log_to_span;\r\nu32 info, strip_offset, span, span_offset;\r\nu64 span_set_Strip, span_set_Row, retval;\r\nfor (info = 0; info < MAX_QUAD_DEPTH; info++) {\r\nspan_set = &(ldSpanInfo[ld].span_set[info]);\r\nif (span_set->span_row_data_width == 0)\r\nbreak;\r\nif (strip > span_set->data_strip_end)\r\ncontinue;\r\nspan_set_Strip = strip - span_set->data_strip_start;\r\nstrip_offset = mega_mod64(span_set_Strip,\r\nspan_set->span_row_data_width);\r\nspan_set_Row = mega_div64_32(span_set_Strip,\r\nspan_set->span_row_data_width) * span_set->diff;\r\nfor (span = 0, span_offset = 0; span < raid->spanDepth; span++)\r\nif (le32_to_cpu(map->raidMap.ldSpanMap[ld].spanBlock[span].\r\nblock_span_info.noElements >= info+1)) {\r\nif (strip_offset >=\r\nspan_set->strip_offset[span])\r\nspan_offset++;\r\nelse\r\nbreak;\r\n}\r\n#if SPAN_DEBUG\r\ndev_info(&instance->pdev->dev, "Strip 0x%llx,"\r\n"span_set_Strip 0x%llx, span_set_Row 0x%llx"\r\n"data width 0x%llx span offset 0x%x\n", strip,\r\n(unsigned long long)span_set_Strip,\r\n(unsigned long long)span_set_Row,\r\n(unsigned long long)span_set->span_row_data_width,\r\nspan_offset);\r\ndev_info(&instance->pdev->dev, "For strip 0x%llx"\r\n"row is 0x%llx\n", strip,\r\n(unsigned long long) span_set->data_row_start +\r\n(unsigned long long) span_set_Row + (span_offset - 1));\r\n#endif\r\nretval = (span_set->data_row_start + span_set_Row +\r\n(span_offset - 1));\r\nreturn retval;\r\n}\r\nreturn -1LLU;\r\n}\r\nstatic u64 get_strip_from_row(struct megasas_instance *instance,\r\nu32 ld, u64 row, struct MR_FW_RAID_MAP_ALL *map)\r\n{\r\nstruct fusion_context *fusion = instance->ctrl_context;\r\nstruct MR_LD_RAID *raid = MR_LdRaidGet(ld, map);\r\nLD_SPAN_SET *span_set;\r\nstruct MR_QUAD_ELEMENT *quad;\r\nPLD_SPAN_INFO ldSpanInfo = fusion->log_to_span;\r\nu32 span, info;\r\nu64 strip;\r\nfor (info = 0; info < MAX_QUAD_DEPTH; info++) {\r\nspan_set = &(ldSpanInfo[ld].span_set[info]);\r\nif (span_set->span_row_data_width == 0)\r\nbreak;\r\nif (row > span_set->data_row_end)\r\ncontinue;\r\nfor (span = 0; span < raid->spanDepth; span++)\r\nif (le32_to_cpu(map->raidMap.ldSpanMap[ld].spanBlock[span].\r\nblock_span_info.noElements) >= info+1) {\r\nquad = &map->raidMap.ldSpanMap[ld].\r\nspanBlock[span].block_span_info.quad[info];\r\nif (le64_to_cpu(quad->logStart) <= row &&\r\nrow <= le64_to_cpu(quad->logEnd) &&\r\nmega_mod64((row - le64_to_cpu(quad->logStart)),\r\nle32_to_cpu(quad->diff)) == 0) {\r\nstrip = mega_div64_32\r\n(((row - span_set->data_row_start)\r\n- le64_to_cpu(quad->logStart)),\r\nle32_to_cpu(quad->diff));\r\nstrip *= span_set->span_row_data_width;\r\nstrip += span_set->data_strip_start;\r\nstrip += span_set->strip_offset[span];\r\nreturn strip;\r\n}\r\n}\r\n}\r\ndev_err(&instance->pdev->dev, "get_strip_from_row"\r\n"returns invalid strip for ld=%x, row=%lx\n",\r\nld, (long unsigned int)row);\r\nreturn -1;\r\n}\r\nstatic u32 get_arm_from_strip(struct megasas_instance *instance,\r\nu32 ld, u64 strip, struct MR_FW_RAID_MAP_ALL *map)\r\n{\r\nstruct fusion_context *fusion = instance->ctrl_context;\r\nstruct MR_LD_RAID *raid = MR_LdRaidGet(ld, map);\r\nLD_SPAN_SET *span_set;\r\nPLD_SPAN_INFO ldSpanInfo = fusion->log_to_span;\r\nu32 info, strip_offset, span, span_offset, retval;\r\nfor (info = 0 ; info < MAX_QUAD_DEPTH; info++) {\r\nspan_set = &(ldSpanInfo[ld].span_set[info]);\r\nif (span_set->span_row_data_width == 0)\r\nbreak;\r\nif (strip > span_set->data_strip_end)\r\ncontinue;\r\nstrip_offset = (uint)mega_mod64\r\n((strip - span_set->data_strip_start),\r\nspan_set->span_row_data_width);\r\nfor (span = 0, span_offset = 0; span < raid->spanDepth; span++)\r\nif (le32_to_cpu(map->raidMap.ldSpanMap[ld].spanBlock[span].\r\nblock_span_info.noElements) >= info+1) {\r\nif (strip_offset >=\r\nspan_set->strip_offset[span])\r\nspan_offset =\r\nspan_set->strip_offset[span];\r\nelse\r\nbreak;\r\n}\r\n#if SPAN_DEBUG\r\ndev_info(&instance->pdev->dev, "get_arm_from_strip:"\r\n"for ld=0x%x strip=0x%lx arm is 0x%x\n", ld,\r\n(long unsigned int)strip, (strip_offset - span_offset));\r\n#endif\r\nretval = (strip_offset - span_offset);\r\nreturn retval;\r\n}\r\ndev_err(&instance->pdev->dev, "get_arm_from_strip"\r\n"returns invalid arm for ld=%x strip=%lx\n",\r\nld, (long unsigned int)strip);\r\nreturn -1;\r\n}\r\nu8 get_arm(struct megasas_instance *instance, u32 ld, u8 span, u64 stripe,\r\nstruct MR_FW_RAID_MAP_ALL *map)\r\n{\r\nstruct MR_LD_RAID *raid = MR_LdRaidGet(ld, map);\r\nu32 arm = 0;\r\nswitch (raid->level) {\r\ncase 0:\r\ncase 5:\r\ncase 6:\r\narm = mega_mod64(stripe, SPAN_ROW_SIZE(map, ld, span));\r\nbreak;\r\ncase 1:\r\narm = get_arm_from_strip(instance, ld, stripe, map);\r\nif (arm != -1U)\r\narm *= 2;\r\nbreak;\r\n}\r\nreturn arm;\r\n}\r\nstatic u8 mr_spanset_get_phy_params(struct megasas_instance *instance, u32 ld,\r\nu64 stripRow, u16 stripRef, struct IO_REQUEST_INFO *io_info,\r\nstruct RAID_CONTEXT *pRAID_Context,\r\nstruct MR_FW_RAID_MAP_ALL *map)\r\n{\r\nstruct MR_LD_RAID *raid = MR_LdRaidGet(ld, map);\r\nu32 pd, arRef;\r\nu8 physArm, span;\r\nu64 row;\r\nu8 retval = TRUE;\r\nu8 do_invader = 0;\r\nu64 *pdBlock = &io_info->pdBlock;\r\nu16 *pDevHandle = &io_info->devHandle;\r\nu32 logArm, rowMod, armQ, arm;\r\nif ((instance->pdev->device == PCI_DEVICE_ID_LSI_INVADER ||\r\ninstance->pdev->device == PCI_DEVICE_ID_LSI_FURY))\r\ndo_invader = 1;\r\nrow = io_info->start_row;\r\nspan = io_info->start_span;\r\nif (raid->level == 6) {\r\nlogArm = get_arm_from_strip(instance, ld, stripRow, map);\r\nif (logArm == -1U)\r\nreturn FALSE;\r\nrowMod = mega_mod64(row, SPAN_ROW_SIZE(map, ld, span));\r\narmQ = SPAN_ROW_SIZE(map, ld, span) - 1 - rowMod;\r\narm = armQ + 1 + logArm;\r\nif (arm >= SPAN_ROW_SIZE(map, ld, span))\r\narm -= SPAN_ROW_SIZE(map, ld, span);\r\nphysArm = (u8)arm;\r\n} else\r\nphysArm = get_arm(instance, ld, span, stripRow, map);\r\nif (physArm == 0xFF)\r\nreturn FALSE;\r\narRef = MR_LdSpanArrayGet(ld, span, map);\r\npd = MR_ArPdGet(arRef, physArm, map);\r\nif (pd != MR_PD_INVALID)\r\n*pDevHandle = MR_PdDevHandleGet(pd, map);\r\nelse {\r\n*pDevHandle = MR_PD_INVALID;\r\nif ((raid->level >= 5) &&\r\n(!do_invader || (do_invader &&\r\n(raid->regTypeReqOnRead != REGION_TYPE_UNUSED))))\r\npRAID_Context->regLockFlags = REGION_TYPE_EXCLUSIVE;\r\nelse if (raid->level == 1) {\r\npd = MR_ArPdGet(arRef, physArm + 1, map);\r\nif (pd != MR_PD_INVALID)\r\n*pDevHandle = MR_PdDevHandleGet(pd, map);\r\n}\r\n}\r\n*pdBlock += stripRef + le64_to_cpu(MR_LdSpanPtrGet(ld, span, map)->startBlk);\r\npRAID_Context->spanArm = (span << RAID_CTX_SPANARM_SPAN_SHIFT) |\r\nphysArm;\r\nreturn retval;\r\n}\r\nu8 MR_GetPhyParams(struct megasas_instance *instance, u32 ld, u64 stripRow,\r\nu16 stripRef, struct IO_REQUEST_INFO *io_info,\r\nstruct RAID_CONTEXT *pRAID_Context,\r\nstruct MR_FW_RAID_MAP_ALL *map)\r\n{\r\nstruct MR_LD_RAID *raid = MR_LdRaidGet(ld, map);\r\nu32 pd, arRef;\r\nu8 physArm, span;\r\nu64 row;\r\nu8 retval = TRUE;\r\nu8 do_invader = 0;\r\nu64 *pdBlock = &io_info->pdBlock;\r\nu16 *pDevHandle = &io_info->devHandle;\r\nif ((instance->pdev->device == PCI_DEVICE_ID_LSI_INVADER ||\r\ninstance->pdev->device == PCI_DEVICE_ID_LSI_FURY))\r\ndo_invader = 1;\r\nrow = mega_div64_32(stripRow, raid->rowDataSize);\r\nif (raid->level == 6) {\r\nu32 logArm = mega_mod64(stripRow, raid->rowDataSize);\r\nu32 rowMod, armQ, arm;\r\nif (raid->rowSize == 0)\r\nreturn FALSE;\r\nrowMod = mega_mod64(row, raid->rowSize);\r\narmQ = raid->rowSize-1-rowMod;\r\narm = armQ+1+logArm;\r\nif (arm >= raid->rowSize)\r\narm -= raid->rowSize;\r\nphysArm = (u8)arm;\r\n} else {\r\nif (raid->modFactor == 0)\r\nreturn FALSE;\r\nphysArm = MR_LdDataArmGet(ld, mega_mod64(stripRow,\r\nraid->modFactor),\r\nmap);\r\n}\r\nif (raid->spanDepth == 1) {\r\nspan = 0;\r\n*pdBlock = row << raid->stripeShift;\r\n} else {\r\nspan = (u8)MR_GetSpanBlock(ld, row, pdBlock, map);\r\nif (span == SPAN_INVALID)\r\nreturn FALSE;\r\n}\r\narRef = MR_LdSpanArrayGet(ld, span, map);\r\npd = MR_ArPdGet(arRef, physArm, map);\r\nif (pd != MR_PD_INVALID)\r\n*pDevHandle = MR_PdDevHandleGet(pd, map);\r\nelse {\r\n*pDevHandle = MR_PD_INVALID;\r\nif ((raid->level >= 5) &&\r\n(!do_invader || (do_invader &&\r\n(raid->regTypeReqOnRead != REGION_TYPE_UNUSED))))\r\npRAID_Context->regLockFlags = REGION_TYPE_EXCLUSIVE;\r\nelse if (raid->level == 1) {\r\npd = MR_ArPdGet(arRef, physArm + 1, map);\r\nif (pd != MR_PD_INVALID)\r\n*pDevHandle = MR_PdDevHandleGet(pd, map);\r\n}\r\n}\r\n*pdBlock += stripRef + le64_to_cpu(MR_LdSpanPtrGet(ld, span, map)->startBlk);\r\npRAID_Context->spanArm = (span << RAID_CTX_SPANARM_SPAN_SHIFT) |\r\nphysArm;\r\nreturn retval;\r\n}\r\nu8\r\nMR_BuildRaidContext(struct megasas_instance *instance,\r\nstruct IO_REQUEST_INFO *io_info,\r\nstruct RAID_CONTEXT *pRAID_Context,\r\nstruct MR_FW_RAID_MAP_ALL *map, u8 **raidLUN)\r\n{\r\nstruct MR_LD_RAID *raid;\r\nu32 ld, stripSize, stripe_mask;\r\nu64 endLba, endStrip, endRow, start_row, start_strip;\r\nu64 regStart;\r\nu32 regSize;\r\nu8 num_strips, numRows;\r\nu16 ref_in_start_stripe, ref_in_end_stripe;\r\nu64 ldStartBlock;\r\nu32 numBlocks, ldTgtId;\r\nu8 isRead;\r\nu8 retval = 0;\r\nu8 startlba_span = SPAN_INVALID;\r\nu64 *pdBlock = &io_info->pdBlock;\r\nldStartBlock = io_info->ldStartBlock;\r\nnumBlocks = io_info->numBlocks;\r\nldTgtId = io_info->ldTgtId;\r\nisRead = io_info->isRead;\r\nio_info->IoforUnevenSpan = 0;\r\nio_info->start_span = SPAN_INVALID;\r\nld = MR_TargetIdToLdGet(ldTgtId, map);\r\nraid = MR_LdRaidGet(ld, map);\r\nif (raid->rowDataSize == 0) {\r\nif (MR_LdSpanPtrGet(ld, 0, map)->spanRowDataSize == 0)\r\nreturn FALSE;\r\nelse if (instance->UnevenSpanSupport) {\r\nio_info->IoforUnevenSpan = 1;\r\n} else {\r\ndev_info(&instance->pdev->dev,\r\n"raid->rowDataSize is 0, but has SPAN[0]"\r\n"rowDataSize = 0x%0x,"\r\n"but there is _NO_ UnevenSpanSupport\n",\r\nMR_LdSpanPtrGet(ld, 0, map)->spanRowDataSize);\r\nreturn FALSE;\r\n}\r\n}\r\nstripSize = 1 << raid->stripeShift;\r\nstripe_mask = stripSize-1;\r\nstart_strip = ldStartBlock >> raid->stripeShift;\r\nref_in_start_stripe = (u16)(ldStartBlock & stripe_mask);\r\nendLba = ldStartBlock + numBlocks - 1;\r\nref_in_end_stripe = (u16)(endLba & stripe_mask);\r\nendStrip = endLba >> raid->stripeShift;\r\nnum_strips = (u8)(endStrip - start_strip + 1);\r\nif (io_info->IoforUnevenSpan) {\r\nstart_row = get_row_from_strip(instance, ld, start_strip, map);\r\nendRow = get_row_from_strip(instance, ld, endStrip, map);\r\nif (start_row == -1ULL || endRow == -1ULL) {\r\ndev_info(&instance->pdev->dev, "return from %s %d."\r\n"Send IO w/o region lock.\n",\r\n__func__, __LINE__);\r\nreturn FALSE;\r\n}\r\nif (raid->spanDepth == 1) {\r\nstartlba_span = 0;\r\n*pdBlock = start_row << raid->stripeShift;\r\n} else\r\nstartlba_span = (u8)mr_spanset_get_span_block(instance,\r\nld, start_row, pdBlock, map);\r\nif (startlba_span == SPAN_INVALID) {\r\ndev_info(&instance->pdev->dev, "return from %s %d"\r\n"for row 0x%llx,start strip %llx"\r\n"endSrip %llx\n", __func__, __LINE__,\r\n(unsigned long long)start_row,\r\n(unsigned long long)start_strip,\r\n(unsigned long long)endStrip);\r\nreturn FALSE;\r\n}\r\nio_info->start_span = startlba_span;\r\nio_info->start_row = start_row;\r\n#if SPAN_DEBUG\r\ndev_dbg(&instance->pdev->dev, "Check Span number from %s %d"\r\n"for row 0x%llx, start strip 0x%llx end strip 0x%llx"\r\n" span 0x%x\n", __func__, __LINE__,\r\n(unsigned long long)start_row,\r\n(unsigned long long)start_strip,\r\n(unsigned long long)endStrip, startlba_span);\r\ndev_dbg(&instance->pdev->dev, "start_row 0x%llx endRow 0x%llx"\r\n"Start span 0x%x\n", (unsigned long long)start_row,\r\n(unsigned long long)endRow, startlba_span);\r\n#endif\r\n} else {\r\nstart_row = mega_div64_32(start_strip, raid->rowDataSize);\r\nendRow = mega_div64_32(endStrip, raid->rowDataSize);\r\n}\r\nnumRows = (u8)(endRow - start_row + 1);\r\nregStart = start_row << raid->stripeShift;\r\nregSize = stripSize;\r\nif (raid->capability.fpCapable) {\r\nif (isRead)\r\nio_info->fpOkForIo = (raid->capability.fpReadCapable &&\r\n((num_strips == 1) ||\r\nraid->capability.\r\nfpReadAcrossStripe));\r\nelse\r\nio_info->fpOkForIo = (raid->capability.fpWriteCapable &&\r\n((num_strips == 1) ||\r\nraid->capability.\r\nfpWriteAcrossStripe));\r\n} else\r\nio_info->fpOkForIo = FALSE;\r\nif (numRows == 1) {\r\nif (num_strips == 1) {\r\nregStart += ref_in_start_stripe;\r\nregSize = numBlocks;\r\n}\r\n} else if (io_info->IoforUnevenSpan == 0) {\r\nif (start_strip == (start_row + 1) * raid->rowDataSize - 1) {\r\nregStart += ref_in_start_stripe;\r\nregSize = stripSize - ref_in_start_stripe;\r\n}\r\nif (numRows > 2)\r\nregSize += (numRows-2) << raid->stripeShift;\r\nif (endStrip == endRow*raid->rowDataSize)\r\nregSize += ref_in_end_stripe+1;\r\nelse\r\nregSize += stripSize;\r\n} else {\r\nif (start_strip == (get_strip_from_row(instance, ld, start_row, map) +\r\nSPAN_ROW_DATA_SIZE(map, ld, startlba_span) - 1)) {\r\nregStart += ref_in_start_stripe;\r\nregSize = stripSize - ref_in_start_stripe;\r\n}\r\nif (numRows > 2)\r\nregSize += (numRows-2) << raid->stripeShift;\r\nif (endStrip == get_strip_from_row(instance, ld, endRow, map))\r\nregSize += ref_in_end_stripe + 1;\r\nelse\r\nregSize += stripSize;\r\n}\r\npRAID_Context->timeoutValue = cpu_to_le16(map->raidMap.fpPdIoTimeoutSec);\r\nif ((instance->pdev->device == PCI_DEVICE_ID_LSI_INVADER) ||\r\n(instance->pdev->device == PCI_DEVICE_ID_LSI_FURY))\r\npRAID_Context->regLockFlags = (isRead) ?\r\nraid->regTypeReqOnRead : raid->regTypeReqOnWrite;\r\nelse\r\npRAID_Context->regLockFlags = (isRead) ?\r\nREGION_TYPE_SHARED_READ : raid->regTypeReqOnWrite;\r\npRAID_Context->VirtualDiskTgtId = raid->targetId;\r\npRAID_Context->regLockRowLBA = cpu_to_le64(regStart);\r\npRAID_Context->regLockLength = cpu_to_le32(regSize);\r\npRAID_Context->configSeqNum = raid->seqNum;\r\n*raidLUN = raid->LUN;\r\nif (io_info->fpOkForIo) {\r\nretval = io_info->IoforUnevenSpan ?\r\nmr_spanset_get_phy_params(instance, ld,\r\nstart_strip, ref_in_start_stripe,\r\nio_info, pRAID_Context, map) :\r\nMR_GetPhyParams(instance, ld, start_strip,\r\nref_in_start_stripe, io_info,\r\npRAID_Context, map);\r\nif (io_info->devHandle == MR_PD_INVALID)\r\nio_info->fpOkForIo = FALSE;\r\nreturn retval;\r\n} else if (isRead) {\r\nuint stripIdx;\r\nfor (stripIdx = 0; stripIdx < num_strips; stripIdx++) {\r\nretval = io_info->IoforUnevenSpan ?\r\nmr_spanset_get_phy_params(instance, ld,\r\nstart_strip + stripIdx,\r\nref_in_start_stripe, io_info,\r\npRAID_Context, map) :\r\nMR_GetPhyParams(instance, ld,\r\nstart_strip + stripIdx, ref_in_start_stripe,\r\nio_info, pRAID_Context, map);\r\nif (!retval)\r\nreturn TRUE;\r\n}\r\n}\r\n#if SPAN_DEBUG\r\nif (io_info->IoforUnevenSpan)\r\nget_arm_from_strip(instance, ld, start_strip, map);\r\n#endif\r\nreturn TRUE;\r\n}\r\nvoid mr_update_span_set(struct MR_FW_RAID_MAP_ALL *map,\r\nPLD_SPAN_INFO ldSpanInfo)\r\n{\r\nu8 span, count;\r\nu32 element, span_row_width;\r\nu64 span_row;\r\nstruct MR_LD_RAID *raid;\r\nLD_SPAN_SET *span_set, *span_set_prev;\r\nstruct MR_QUAD_ELEMENT *quad;\r\nint ldCount;\r\nu16 ld;\r\nfor (ldCount = 0; ldCount < MAX_LOGICAL_DRIVES; ldCount++) {\r\nld = MR_TargetIdToLdGet(ldCount, map);\r\nif (ld >= MAX_LOGICAL_DRIVES)\r\ncontinue;\r\nraid = MR_LdRaidGet(ld, map);\r\nfor (element = 0; element < MAX_QUAD_DEPTH; element++) {\r\nfor (span = 0; span < raid->spanDepth; span++) {\r\nif (le32_to_cpu(map->raidMap.ldSpanMap[ld].spanBlock[span].\r\nblock_span_info.noElements) <\r\nelement + 1)\r\ncontinue;\r\nspan_set = &(ldSpanInfo[ld].span_set[element]);\r\nquad = &map->raidMap.ldSpanMap[ld].\r\nspanBlock[span].block_span_info.\r\nquad[element];\r\nspan_set->diff = le32_to_cpu(quad->diff);\r\nfor (count = 0, span_row_width = 0;\r\ncount < raid->spanDepth; count++) {\r\nif (le32_to_cpu(map->raidMap.ldSpanMap[ld].\r\nspanBlock[count].\r\nblock_span_info.\r\nnoElements) >= element + 1) {\r\nspan_set->strip_offset[count] =\r\nspan_row_width;\r\nspan_row_width +=\r\nMR_LdSpanPtrGet\r\n(ld, count, map)->spanRowDataSize;\r\nprintk(KERN_INFO "megasas:"\r\n"span %x rowDataSize %x\n",\r\ncount, MR_LdSpanPtrGet\r\n(ld, count, map)->spanRowDataSize);\r\n}\r\n}\r\nspan_set->span_row_data_width = span_row_width;\r\nspan_row = mega_div64_32(((le64_to_cpu(quad->logEnd) -\r\nle64_to_cpu(quad->logStart)) + le32_to_cpu(quad->diff)),\r\nle32_to_cpu(quad->diff));\r\nif (element == 0) {\r\nspan_set->log_start_lba = 0;\r\nspan_set->log_end_lba =\r\n((span_row << raid->stripeShift)\r\n* span_row_width) - 1;\r\nspan_set->span_row_start = 0;\r\nspan_set->span_row_end = span_row - 1;\r\nspan_set->data_strip_start = 0;\r\nspan_set->data_strip_end =\r\n(span_row * span_row_width) - 1;\r\nspan_set->data_row_start = 0;\r\nspan_set->data_row_end =\r\n(span_row * le32_to_cpu(quad->diff)) - 1;\r\n} else {\r\nspan_set_prev = &(ldSpanInfo[ld].\r\nspan_set[element - 1]);\r\nspan_set->log_start_lba =\r\nspan_set_prev->log_end_lba + 1;\r\nspan_set->log_end_lba =\r\nspan_set->log_start_lba +\r\n((span_row << raid->stripeShift)\r\n* span_row_width) - 1;\r\nspan_set->span_row_start =\r\nspan_set_prev->span_row_end + 1;\r\nspan_set->span_row_end =\r\nspan_set->span_row_start + span_row - 1;\r\nspan_set->data_strip_start =\r\nspan_set_prev->data_strip_end + 1;\r\nspan_set->data_strip_end =\r\nspan_set->data_strip_start +\r\n(span_row * span_row_width) - 1;\r\nspan_set->data_row_start =\r\nspan_set_prev->data_row_end + 1;\r\nspan_set->data_row_end =\r\nspan_set->data_row_start +\r\n(span_row * le32_to_cpu(quad->diff)) - 1;\r\n}\r\nbreak;\r\n}\r\nif (span == raid->spanDepth)\r\nbreak;\r\n}\r\n}\r\n#if SPAN_DEBUG\r\ngetSpanInfo(map, ldSpanInfo);\r\n#endif\r\n}\r\nvoid\r\nmr_update_load_balance_params(struct MR_FW_RAID_MAP_ALL *map,\r\nstruct LD_LOAD_BALANCE_INFO *lbInfo)\r\n{\r\nint ldCount;\r\nu16 ld;\r\nstruct MR_LD_RAID *raid;\r\nfor (ldCount = 0; ldCount < MAX_LOGICAL_DRIVES; ldCount++) {\r\nld = MR_TargetIdToLdGet(ldCount, map);\r\nif (ld >= MAX_LOGICAL_DRIVES) {\r\nlbInfo[ldCount].loadBalanceFlag = 0;\r\ncontinue;\r\n}\r\nraid = MR_LdRaidGet(ld, map);\r\nif ((raid->level == 1) && (raid->rowSize == 2) &&\r\n(raid->spanDepth == 1) && raid->ldState ==\r\nMR_LD_STATE_OPTIMAL) {\r\nu32 pd, arRef;\r\nlbInfo[ldCount].loadBalanceFlag = 1;\r\narRef = MR_LdSpanArrayGet(ld, 0, map);\r\npd = MR_ArPdGet(arRef, 0, map);\r\nlbInfo[ldCount].raid1DevHandle[0] =\r\nMR_PdDevHandleGet(pd, map);\r\npd = MR_ArPdGet(arRef, 1, map);\r\nlbInfo[ldCount].raid1DevHandle[1] =\r\nMR_PdDevHandleGet(pd, map);\r\n} else\r\nlbInfo[ldCount].loadBalanceFlag = 0;\r\n}\r\n}\r\nu8 megasas_get_best_arm(struct LD_LOAD_BALANCE_INFO *lbInfo, u8 arm, u64 block,\r\nu32 count)\r\n{\r\nu16 pend0, pend1;\r\nu64 diff0, diff1;\r\nu8 bestArm;\r\npend0 = atomic_read(&lbInfo->scsi_pending_cmds[0]);\r\npend1 = atomic_read(&lbInfo->scsi_pending_cmds[1]);\r\ndiff0 = ABS_DIFF(block, lbInfo->last_accessed_block[0]);\r\ndiff1 = ABS_DIFF(block, lbInfo->last_accessed_block[1]);\r\nbestArm = (diff0 <= diff1 ? 0 : 1);\r\nif ((bestArm == arm && pend0 > pend1 + 4) ||\r\n(bestArm != arm && pend1 > pend0 + 4))\r\nbestArm ^= 1;\r\nlbInfo->last_accessed_block[bestArm] = block + count - 1;\r\nreturn bestArm;\r\n}\r\nu16 get_updated_dev_handle(struct LD_LOAD_BALANCE_INFO *lbInfo,\r\nstruct IO_REQUEST_INFO *io_info)\r\n{\r\nu8 arm, old_arm;\r\nu16 devHandle;\r\nold_arm = lbInfo->raid1DevHandle[0] == io_info->devHandle ? 0 : 1;\r\narm = megasas_get_best_arm(lbInfo, old_arm, io_info->ldStartBlock,\r\nio_info->numBlocks);\r\ndevHandle = lbInfo->raid1DevHandle[arm];\r\natomic_inc(&lbInfo->scsi_pending_cmds[arm]);\r\nreturn devHandle;\r\n}
