static inline void __iomem *ipg_ioaddr(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nreturn sp->ioaddr;\r\n}\r\nstatic void ipg_dump_rfdlist(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = sp->ioaddr;\r\nunsigned int i;\r\nu32 offset;\r\nIPG_DEBUG_MSG("_dump_rfdlist\n");\r\nnetdev_info(dev, "rx_current = %02x\n", sp->rx_current);\r\nnetdev_info(dev, "rx_dirty = %02x\n", sp->rx_dirty);\r\nnetdev_info(dev, "RFDList start address = %016lx\n",\r\n(unsigned long)sp->rxd_map);\r\nnetdev_info(dev, "RFDListPtr register = %08x%08x\n",\r\nipg_r32(IPG_RFDLISTPTR1), ipg_r32(IPG_RFDLISTPTR0));\r\nfor (i = 0; i < IPG_RFDLIST_LENGTH; i++) {\r\noffset = (u32) &sp->rxd[i].next_desc - (u32) sp->rxd;\r\nnetdev_info(dev, "%02x %04x RFDNextPtr = %016lx\n",\r\ni, offset, (unsigned long)sp->rxd[i].next_desc);\r\noffset = (u32) &sp->rxd[i].rfs - (u32) sp->rxd;\r\nnetdev_info(dev, "%02x %04x RFS = %016lx\n",\r\ni, offset, (unsigned long)sp->rxd[i].rfs);\r\noffset = (u32) &sp->rxd[i].frag_info - (u32) sp->rxd;\r\nnetdev_info(dev, "%02x %04x frag_info = %016lx\n",\r\ni, offset, (unsigned long)sp->rxd[i].frag_info);\r\n}\r\n}\r\nstatic void ipg_dump_tfdlist(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = sp->ioaddr;\r\nunsigned int i;\r\nu32 offset;\r\nIPG_DEBUG_MSG("_dump_tfdlist\n");\r\nnetdev_info(dev, "tx_current = %02x\n", sp->tx_current);\r\nnetdev_info(dev, "tx_dirty = %02x\n", sp->tx_dirty);\r\nnetdev_info(dev, "TFDList start address = %016lx\n",\r\n(unsigned long) sp->txd_map);\r\nnetdev_info(dev, "TFDListPtr register = %08x%08x\n",\r\nipg_r32(IPG_TFDLISTPTR1), ipg_r32(IPG_TFDLISTPTR0));\r\nfor (i = 0; i < IPG_TFDLIST_LENGTH; i++) {\r\noffset = (u32) &sp->txd[i].next_desc - (u32) sp->txd;\r\nnetdev_info(dev, "%02x %04x TFDNextPtr = %016lx\n",\r\ni, offset, (unsigned long)sp->txd[i].next_desc);\r\noffset = (u32) &sp->txd[i].tfc - (u32) sp->txd;\r\nnetdev_info(dev, "%02x %04x TFC = %016lx\n",\r\ni, offset, (unsigned long) sp->txd[i].tfc);\r\noffset = (u32) &sp->txd[i].frag_info - (u32) sp->txd;\r\nnetdev_info(dev, "%02x %04x frag_info = %016lx\n",\r\ni, offset, (unsigned long) sp->txd[i].frag_info);\r\n}\r\n}\r\nstatic void ipg_write_phy_ctl(void __iomem *ioaddr, u8 data)\r\n{\r\nipg_w8(IPG_PC_RSVD_MASK & data, PHY_CTRL);\r\nndelay(IPG_PC_PHYCTRLWAIT_NS);\r\n}\r\nstatic void ipg_drive_phy_ctl_low_high(void __iomem *ioaddr, u8 data)\r\n{\r\nipg_write_phy_ctl(ioaddr, IPG_PC_MGMTCLK_LO | data);\r\nipg_write_phy_ctl(ioaddr, IPG_PC_MGMTCLK_HI | data);\r\n}\r\nstatic void send_three_state(void __iomem *ioaddr, u8 phyctrlpolarity)\r\n{\r\nphyctrlpolarity |= (IPG_PC_MGMTDATA & 0) | IPG_PC_MGMTDIR;\r\nipg_drive_phy_ctl_low_high(ioaddr, phyctrlpolarity);\r\n}\r\nstatic void send_end(void __iomem *ioaddr, u8 phyctrlpolarity)\r\n{\r\nipg_w8((IPG_PC_MGMTCLK_LO | (IPG_PC_MGMTDATA & 0) | IPG_PC_MGMTDIR |\r\nphyctrlpolarity) & IPG_PC_RSVD_MASK, PHY_CTRL);\r\n}\r\nstatic u16 read_phy_bit(void __iomem *ioaddr, u8 phyctrlpolarity)\r\n{\r\nu16 bit_data;\r\nipg_write_phy_ctl(ioaddr, IPG_PC_MGMTCLK_LO | phyctrlpolarity);\r\nbit_data = ((ipg_r8(PHY_CTRL) & IPG_PC_MGMTDATA) >> 1) & 1;\r\nipg_write_phy_ctl(ioaddr, IPG_PC_MGMTCLK_HI | phyctrlpolarity);\r\nreturn bit_data;\r\n}\r\nstatic int mdio_read(struct net_device *dev, int phy_id, int phy_reg)\r\n{\r\nvoid __iomem *ioaddr = ipg_ioaddr(dev);\r\nstruct {\r\nu32 field;\r\nunsigned int len;\r\n} p[] = {\r\n{ GMII_PREAMBLE, 32 },\r\n{ GMII_ST, 2 },\r\n{ GMII_READ, 2 },\r\n{ phy_id, 5 },\r\n{ phy_reg, 5 },\r\n{ 0x0000, 2 },\r\n{ 0x0000, 16 },\r\n{ 0x0000, 1 }\r\n};\r\nunsigned int i, j;\r\nu8 polarity, data;\r\npolarity = ipg_r8(PHY_CTRL);\r\npolarity &= (IPG_PC_DUPLEX_POLARITY | IPG_PC_LINK_POLARITY);\r\nfor (j = 0; j < 5; j++) {\r\nfor (i = 0; i < p[j].len; i++) {\r\ndata = (p[j].field >> (p[j].len - 1 - i)) << 1;\r\ndata &= IPG_PC_MGMTDATA;\r\ndata |= polarity | IPG_PC_MGMTDIR;\r\nipg_drive_phy_ctl_low_high(ioaddr, data);\r\n}\r\n}\r\nsend_three_state(ioaddr, polarity);\r\nread_phy_bit(ioaddr, polarity);\r\nfor (i = 0; i < p[6].len; i++) {\r\np[6].field |=\r\n(read_phy_bit(ioaddr, polarity) << (p[6].len - 1 - i));\r\n}\r\nsend_three_state(ioaddr, polarity);\r\nsend_three_state(ioaddr, polarity);\r\nsend_three_state(ioaddr, polarity);\r\nsend_end(ioaddr, polarity);\r\nreturn p[6].field;\r\n}\r\nstatic void mdio_write(struct net_device *dev, int phy_id, int phy_reg, int val)\r\n{\r\nvoid __iomem *ioaddr = ipg_ioaddr(dev);\r\nstruct {\r\nu32 field;\r\nunsigned int len;\r\n} p[] = {\r\n{ GMII_PREAMBLE, 32 },\r\n{ GMII_ST, 2 },\r\n{ GMII_WRITE, 2 },\r\n{ phy_id, 5 },\r\n{ phy_reg, 5 },\r\n{ 0x0002, 2 },\r\n{ val & 0xffff, 16 },\r\n{ 0x0000, 1 }\r\n};\r\nunsigned int i, j;\r\nu8 polarity, data;\r\npolarity = ipg_r8(PHY_CTRL);\r\npolarity &= (IPG_PC_DUPLEX_POLARITY | IPG_PC_LINK_POLARITY);\r\nfor (j = 0; j < 7; j++) {\r\nfor (i = 0; i < p[j].len; i++) {\r\ndata = (p[j].field >> (p[j].len - 1 - i)) << 1;\r\ndata &= IPG_PC_MGMTDATA;\r\ndata |= polarity | IPG_PC_MGMTDIR;\r\nipg_drive_phy_ctl_low_high(ioaddr, data);\r\n}\r\n}\r\nipg_write_phy_ctl(ioaddr, IPG_PC_MGMTCLK_LO | polarity);\r\nipg_r8(PHY_CTRL);\r\nipg_write_phy_ctl(ioaddr, IPG_PC_MGMTCLK_HI | polarity);\r\n}\r\nstatic void ipg_set_led_mode(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = sp->ioaddr;\r\nu32 mode;\r\nmode = ipg_r32(ASIC_CTRL);\r\nmode &= ~(IPG_AC_LED_MODE_BIT_1 | IPG_AC_LED_MODE | IPG_AC_LED_SPEED);\r\nif ((sp->led_mode & 0x03) > 1)\r\nmode |= IPG_AC_LED_MODE_BIT_1;\r\nif ((sp->led_mode & 0x01) == 1)\r\nmode |= IPG_AC_LED_MODE;\r\nif ((sp->led_mode & 0x08) == 8)\r\nmode |= IPG_AC_LED_SPEED;\r\nipg_w32(mode, ASIC_CTRL);\r\n}\r\nstatic void ipg_set_phy_set(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = sp->ioaddr;\r\nint physet;\r\nphyset = ipg_r8(PHY_SET);\r\nphyset &= ~(IPG_PS_MEM_LENB9B | IPG_PS_MEM_LEN9 | IPG_PS_NON_COMPDET);\r\nphyset |= ((sp->led_mode & 0x70) >> 4);\r\nipg_w8(physet, PHY_SET);\r\n}\r\nstatic int ipg_reset(struct net_device *dev, u32 resetflags)\r\n{\r\nvoid __iomem *ioaddr = ipg_ioaddr(dev);\r\nunsigned int timeout_count = 0;\r\nIPG_DEBUG_MSG("_reset\n");\r\nipg_w32(ipg_r32(ASIC_CTRL) | resetflags, ASIC_CTRL);\r\nmdelay(IPG_AC_RESETWAIT);\r\nwhile (IPG_AC_RESET_BUSY & ipg_r32(ASIC_CTRL)) {\r\nmdelay(IPG_AC_RESETWAIT);\r\nif (++timeout_count > IPG_AC_RESET_TIMEOUT)\r\nreturn -ETIME;\r\n}\r\nipg_set_led_mode(dev);\r\nipg_set_phy_set(dev);\r\nreturn 0;\r\n}\r\nstatic int ipg_find_phyaddr(struct net_device *dev)\r\n{\r\nunsigned int phyaddr, i;\r\nfor (i = 0; i < 32; i++) {\r\nu32 status;\r\nphyaddr = (IPG_NIC_PHY_ADDRESS + i) % 32;\r\nstatus = mdio_read(dev, phyaddr, MII_BMSR);\r\nif ((status != 0xFFFF) && (status != 0))\r\nreturn phyaddr;\r\n}\r\nreturn 0x1f;\r\n}\r\nstatic int ipg_config_autoneg(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = sp->ioaddr;\r\nunsigned int txflowcontrol;\r\nunsigned int rxflowcontrol;\r\nunsigned int fullduplex;\r\nu32 mac_ctrl_val;\r\nu32 asicctrl;\r\nu8 phyctrl;\r\nconst char *speed;\r\nconst char *duplex;\r\nconst char *tx_desc;\r\nconst char *rx_desc;\r\nIPG_DEBUG_MSG("_config_autoneg\n");\r\nasicctrl = ipg_r32(ASIC_CTRL);\r\nphyctrl = ipg_r8(PHY_CTRL);\r\nmac_ctrl_val = ipg_r32(MAC_CTRL);\r\nfullduplex = 0;\r\ntxflowcontrol = 0;\r\nrxflowcontrol = 0;\r\nsp->tenmbpsmode = 0;\r\nswitch (phyctrl & IPG_PC_LINK_SPEED) {\r\ncase IPG_PC_LINK_SPEED_10MBPS:\r\nspeed = "10Mbps";\r\nsp->tenmbpsmode = 1;\r\nbreak;\r\ncase IPG_PC_LINK_SPEED_100MBPS:\r\nspeed = "100Mbps";\r\nbreak;\r\ncase IPG_PC_LINK_SPEED_1000MBPS:\r\nspeed = "1000Mbps";\r\nbreak;\r\ndefault:\r\nspeed = "undefined!";\r\nreturn 0;\r\n}\r\nnetdev_info(dev, "Link speed = %s\n", speed);\r\nif (sp->tenmbpsmode == 1)\r\nnetdev_info(dev, "10Mbps operational mode enabled\n");\r\nif (phyctrl & IPG_PC_DUPLEX_STATUS) {\r\nfullduplex = 1;\r\ntxflowcontrol = 1;\r\nrxflowcontrol = 1;\r\n}\r\nif (fullduplex == 1) {\r\nduplex = "full";\r\nmac_ctrl_val |= IPG_MC_DUPLEX_SELECT_FD;\r\nif (txflowcontrol == 1) {\r\ntx_desc = "";\r\nmac_ctrl_val |= IPG_MC_TX_FLOW_CONTROL_ENABLE;\r\n} else {\r\ntx_desc = "no ";\r\nmac_ctrl_val &= ~IPG_MC_TX_FLOW_CONTROL_ENABLE;\r\n}\r\nif (rxflowcontrol == 1) {\r\nrx_desc = "";\r\nmac_ctrl_val |= IPG_MC_RX_FLOW_CONTROL_ENABLE;\r\n} else {\r\nrx_desc = "no ";\r\nmac_ctrl_val &= ~IPG_MC_RX_FLOW_CONTROL_ENABLE;\r\n}\r\n} else {\r\nduplex = "half";\r\ntx_desc = "no ";\r\nrx_desc = "no ";\r\nmac_ctrl_val &= (~IPG_MC_DUPLEX_SELECT_FD &\r\n~IPG_MC_TX_FLOW_CONTROL_ENABLE &\r\n~IPG_MC_RX_FLOW_CONTROL_ENABLE);\r\n}\r\nnetdev_info(dev, "setting %s duplex, %sTX, %sRX flow control\n",\r\nduplex, tx_desc, rx_desc);\r\nipg_w32(mac_ctrl_val, MAC_CTRL);\r\nreturn 0;\r\n}\r\nstatic void ipg_nic_set_multicast_list(struct net_device *dev)\r\n{\r\nvoid __iomem *ioaddr = ipg_ioaddr(dev);\r\nstruct netdev_hw_addr *ha;\r\nunsigned int hashindex;\r\nu32 hashtable[2];\r\nu8 receivemode;\r\nIPG_DEBUG_MSG("_nic_set_multicast_list\n");\r\nreceivemode = IPG_RM_RECEIVEUNICAST | IPG_RM_RECEIVEBROADCAST;\r\nif (dev->flags & IFF_PROMISC) {\r\nreceivemode = IPG_RM_RECEIVEALLFRAMES;\r\n} else if ((dev->flags & IFF_ALLMULTI) ||\r\n((dev->flags & IFF_MULTICAST) &&\r\n(netdev_mc_count(dev) > IPG_MULTICAST_HASHTABLE_SIZE))) {\r\nreceivemode |= IPG_RM_RECEIVEMULTICAST;\r\n} else if ((dev->flags & IFF_MULTICAST) && !netdev_mc_empty(dev)) {\r\nreceivemode |= IPG_RM_RECEIVEMULTICASTHASH;\r\n}\r\nhashtable[0] = 0x00000000;\r\nhashtable[1] = 0x00000000;\r\nnetdev_for_each_mc_addr(ha, dev) {\r\nhashindex = crc32_le(0xffffffff, ha->addr,\r\nETH_ALEN);\r\nhashindex = hashindex & 0x3F;\r\nset_bit(hashindex, (void *)hashtable);\r\n}\r\nipg_w32(hashtable[0], HASHTABLE_0);\r\nipg_w32(hashtable[1], HASHTABLE_1);\r\nipg_w8(IPG_RM_RSVD_MASK & receivemode, RECEIVE_MODE);\r\nIPG_DEBUG_MSG("ReceiveMode = %x\n", ipg_r8(RECEIVE_MODE));\r\n}\r\nstatic int ipg_io_config(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = ipg_ioaddr(dev);\r\nu32 origmacctrl;\r\nu32 restoremacctrl;\r\nIPG_DEBUG_MSG("_io_config\n");\r\norigmacctrl = ipg_r32(MAC_CTRL);\r\nrestoremacctrl = origmacctrl | IPG_MC_STATISTICS_ENABLE;\r\nif (!IPG_STRIP_FCS_ON_RX)\r\nrestoremacctrl |= IPG_MC_RCV_FCS;\r\nif (origmacctrl & IPG_MC_TX_ENABLED)\r\nrestoremacctrl |= IPG_MC_TX_ENABLE;\r\nif (origmacctrl & IPG_MC_RX_ENABLED)\r\nrestoremacctrl |= IPG_MC_RX_ENABLE;\r\nipg_w32((origmacctrl & (IPG_MC_RX_DISABLE | IPG_MC_TX_DISABLE)) &\r\nIPG_MC_RSVD_MASK, MAC_CTRL);\r\nipg_w32((origmacctrl & IPG_MC_IFS_96BIT) & IPG_MC_RSVD_MASK, MAC_CTRL);\r\nipg_nic_set_multicast_list(dev);\r\nipg_w16(sp->max_rxframe_size, MAX_FRAME_SIZE);\r\nipg_w8(IPG_RXDMAPOLLPERIOD_VALUE, RX_DMA_POLL_PERIOD);\r\nipg_w8(IPG_RXDMAURGENTTHRESH_VALUE, RX_DMA_URGENT_THRESH);\r\nipg_w8(IPG_RXDMABURSTTHRESH_VALUE, RX_DMA_BURST_THRESH);\r\nipg_w8(IPG_TXDMAPOLLPERIOD_VALUE, TX_DMA_POLL_PERIOD);\r\nipg_w8(IPG_TXDMAURGENTTHRESH_VALUE, TX_DMA_URGENT_THRESH);\r\nipg_w8(IPG_TXDMABURSTTHRESH_VALUE, TX_DMA_BURST_THRESH);\r\nipg_w16((IPG_IE_HOST_ERROR | IPG_IE_TX_DMA_COMPLETE |\r\nIPG_IE_TX_COMPLETE | IPG_IE_INT_REQUESTED |\r\nIPG_IE_UPDATE_STATS | IPG_IE_LINK_EVENT |\r\nIPG_IE_RX_DMA_COMPLETE | IPG_IE_RX_DMA_PRIORITY), INT_ENABLE);\r\nipg_w16(IPG_FLOWONTHRESH_VALUE, FLOW_ON_THRESH);\r\nipg_w16(IPG_FLOWOFFTHRESH_VALUE, FLOW_OFF_THRESH);\r\nipg_w16(ipg_r16(DEBUG_CTRL) | 0x0200, DEBUG_CTRL);\r\nipg_w16(ipg_r16(DEBUG_CTRL) | 0x0010, DEBUG_CTRL);\r\nipg_w16(ipg_r16(DEBUG_CTRL) | 0x0020, DEBUG_CTRL);\r\nipg_w32(IPG_MC_RSVD_MASK & restoremacctrl, MAC_CTRL);\r\nipg_w32(IPG_RZ_ALL, RMON_STATISTICS_MASK);\r\nipg_w32(IPG_SM_MACCONTROLFRAMESXMTD | IPG_SM_MACCONTROLFRAMESRCVD |\r\nIPG_SM_BCSTOCTETXMTOK_BCSTFRAMESXMTDOK | IPG_SM_TXJUMBOFRAMES |\r\nIPG_SM_MCSTOCTETXMTOK_MCSTFRAMESXMTDOK | IPG_SM_RXJUMBOFRAMES |\r\nIPG_SM_BCSTOCTETRCVDOK_BCSTFRAMESRCVDOK |\r\nIPG_SM_UDPCHECKSUMERRORS | IPG_SM_TCPCHECKSUMERRORS |\r\nIPG_SM_IPCHECKSUMERRORS, STATISTICS_MASK);\r\nreturn 0;\r\n}\r\nstatic int ipg_get_rxbuff(struct net_device *dev, int entry)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nstruct ipg_rx *rxfd = sp->rxd + entry;\r\nstruct sk_buff *skb;\r\nu64 rxfragsize;\r\nIPG_DEBUG_MSG("_get_rxbuff\n");\r\nskb = netdev_alloc_skb_ip_align(dev, sp->rxsupport_size);\r\nif (!skb) {\r\nsp->rx_buff[entry] = NULL;\r\nreturn -ENOMEM;\r\n}\r\nsp->rx_buff[entry] = skb;\r\nrxfd->frag_info = cpu_to_le64(pci_map_single(sp->pdev, skb->data,\r\nsp->rx_buf_sz, PCI_DMA_FROMDEVICE));\r\nrxfragsize = sp->rxfrag_size;\r\nrxfd->frag_info |= cpu_to_le64((rxfragsize << 48) & IPG_RFI_FRAGLEN);\r\nreturn 0;\r\n}\r\nstatic int init_rfdlist(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = sp->ioaddr;\r\nunsigned int i;\r\nIPG_DEBUG_MSG("_init_rfdlist\n");\r\nfor (i = 0; i < IPG_RFDLIST_LENGTH; i++) {\r\nstruct ipg_rx *rxfd = sp->rxd + i;\r\nif (sp->rx_buff[i]) {\r\npci_unmap_single(sp->pdev,\r\nle64_to_cpu(rxfd->frag_info) & ~IPG_RFI_FRAGLEN,\r\nsp->rx_buf_sz, PCI_DMA_FROMDEVICE);\r\ndev_kfree_skb_irq(sp->rx_buff[i]);\r\nsp->rx_buff[i] = NULL;\r\n}\r\nrxfd->rfs = 0x0000000000000000;\r\nif (ipg_get_rxbuff(dev, i) < 0) {\r\nIPG_DEBUG_MSG("Cannot allocate Rx buffer\n");\r\nif (i == 0) {\r\nnetdev_err(dev, "No memory available for RFD list\n");\r\nreturn -ENOMEM;\r\n}\r\n}\r\nrxfd->next_desc = cpu_to_le64(sp->rxd_map +\r\nsizeof(struct ipg_rx)*(i + 1));\r\n}\r\nsp->rxd[i - 1].next_desc = cpu_to_le64(sp->rxd_map);\r\nsp->rx_current = 0;\r\nsp->rx_dirty = 0;\r\nipg_w32((u32) sp->rxd_map, RFD_LIST_PTR_0);\r\nipg_w32(0x00000000, RFD_LIST_PTR_1);\r\nreturn 0;\r\n}\r\nstatic void init_tfdlist(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = sp->ioaddr;\r\nunsigned int i;\r\nIPG_DEBUG_MSG("_init_tfdlist\n");\r\nfor (i = 0; i < IPG_TFDLIST_LENGTH; i++) {\r\nstruct ipg_tx *txfd = sp->txd + i;\r\ntxfd->tfc = cpu_to_le64(IPG_TFC_TFDDONE);\r\nif (sp->tx_buff[i]) {\r\ndev_kfree_skb_irq(sp->tx_buff[i]);\r\nsp->tx_buff[i] = NULL;\r\n}\r\ntxfd->next_desc = cpu_to_le64(sp->txd_map +\r\nsizeof(struct ipg_tx)*(i + 1));\r\n}\r\nsp->txd[i - 1].next_desc = cpu_to_le64(sp->txd_map);\r\nsp->tx_current = 0;\r\nsp->tx_dirty = 0;\r\nIPG_DDEBUG_MSG("Starting TFDListPtr = %08x\n",\r\n(u32) sp->txd_map);\r\nipg_w32((u32) sp->txd_map, TFD_LIST_PTR_0);\r\nipg_w32(0x00000000, TFD_LIST_PTR_1);\r\nsp->reset_current_tfd = 1;\r\n}\r\nstatic void ipg_nic_txfree(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nunsigned int released, pending, dirty;\r\nIPG_DEBUG_MSG("_nic_txfree\n");\r\npending = sp->tx_current - sp->tx_dirty;\r\ndirty = sp->tx_dirty % IPG_TFDLIST_LENGTH;\r\nfor (released = 0; released < pending; released++) {\r\nstruct sk_buff *skb = sp->tx_buff[dirty];\r\nstruct ipg_tx *txfd = sp->txd + dirty;\r\nIPG_DEBUG_MSG("TFC = %016lx\n", (unsigned long) txfd->tfc);\r\nif (!(txfd->tfc & cpu_to_le64(IPG_TFC_TFDDONE)))\r\nbreak;\r\nif (skb) {\r\npci_unmap_single(sp->pdev,\r\nle64_to_cpu(txfd->frag_info) & ~IPG_TFI_FRAGLEN,\r\nskb->len, PCI_DMA_TODEVICE);\r\ndev_kfree_skb_irq(skb);\r\nsp->tx_buff[dirty] = NULL;\r\n}\r\ndirty = (dirty + 1) % IPG_TFDLIST_LENGTH;\r\n}\r\nsp->tx_dirty += released;\r\nif (netif_queue_stopped(dev) &&\r\n(sp->tx_current != (sp->tx_dirty + IPG_TFDLIST_LENGTH))) {\r\nnetif_wake_queue(dev);\r\n}\r\n}\r\nstatic void ipg_tx_timeout(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = sp->ioaddr;\r\nipg_reset(dev, IPG_AC_TX_RESET | IPG_AC_DMA | IPG_AC_NETWORK |\r\nIPG_AC_FIFO);\r\nspin_lock_irq(&sp->lock);\r\nif (ipg_io_config(dev) < 0)\r\nnetdev_info(dev, "Error during re-configuration\n");\r\ninit_tfdlist(dev);\r\nspin_unlock_irq(&sp->lock);\r\nipg_w32((ipg_r32(MAC_CTRL) | IPG_MC_TX_ENABLE) & IPG_MC_RSVD_MASK,\r\nMAC_CTRL);\r\n}\r\nstatic void ipg_nic_txcleanup(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = sp->ioaddr;\r\nunsigned int i;\r\nIPG_DEBUG_MSG("_nic_txcleanup\n");\r\nfor (i = 0; i < IPG_TFDLIST_LENGTH; i++) {\r\nu32 txstatusdword = ipg_r32(TX_STATUS);\r\nIPG_DEBUG_MSG("TxStatus = %08x\n", txstatusdword);\r\nif (!(txstatusdword & IPG_TS_TX_COMPLETE))\r\nbreak;\r\nif (sp->tenmbpsmode) {\r\nnetif_wake_queue(dev);\r\n}\r\nif (txstatusdword & IPG_TS_TX_ERROR) {\r\nIPG_DEBUG_MSG("Transmit error\n");\r\nsp->stats.tx_errors++;\r\n}\r\nif (txstatusdword & IPG_TS_LATE_COLLISION) {\r\nIPG_DEBUG_MSG("Late collision on transmit\n");\r\nipg_w32((ipg_r32(MAC_CTRL) | IPG_MC_TX_ENABLE) &\r\nIPG_MC_RSVD_MASK, MAC_CTRL);\r\n}\r\nif (txstatusdword & IPG_TS_TX_MAX_COLL) {\r\nIPG_DEBUG_MSG("Maximum collisions on transmit\n");\r\nipg_w32((ipg_r32(MAC_CTRL) | IPG_MC_TX_ENABLE) &\r\nIPG_MC_RSVD_MASK, MAC_CTRL);\r\n}\r\nif (txstatusdword & IPG_TS_TX_UNDERRUN) {\r\nIPG_DEBUG_MSG("Transmitter underrun\n");\r\nsp->stats.tx_fifo_errors++;\r\nipg_reset(dev, IPG_AC_TX_RESET | IPG_AC_DMA |\r\nIPG_AC_NETWORK | IPG_AC_FIFO);\r\nif (ipg_io_config(dev) < 0) {\r\nnetdev_info(dev, "Error during re-configuration\n");\r\n}\r\ninit_tfdlist(dev);\r\nipg_w32((ipg_r32(MAC_CTRL) | IPG_MC_TX_ENABLE) &\r\nIPG_MC_RSVD_MASK, MAC_CTRL);\r\n}\r\n}\r\nipg_nic_txfree(dev);\r\n}\r\nstatic struct net_device_stats *ipg_nic_get_stats(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = sp->ioaddr;\r\nu16 temp1;\r\nu16 temp2;\r\nIPG_DEBUG_MSG("_nic_get_stats\n");\r\nif (!netif_running(dev))\r\nreturn &sp->stats;\r\nsp->stats.rx_packets += ipg_r32(IPG_FRAMESRCVDOK);\r\nsp->stats.tx_packets += ipg_r32(IPG_FRAMESXMTDOK);\r\nsp->stats.rx_bytes += ipg_r32(IPG_OCTETRCVOK);\r\nsp->stats.tx_bytes += ipg_r32(IPG_OCTETXMTOK);\r\ntemp1 = ipg_r16(IPG_FRAMESLOSTRXERRORS);\r\nsp->stats.rx_errors += temp1;\r\nsp->stats.rx_missed_errors += temp1;\r\ntemp1 = ipg_r32(IPG_SINGLECOLFRAMES) + ipg_r32(IPG_MULTICOLFRAMES) +\r\nipg_r32(IPG_LATECOLLISIONS);\r\ntemp2 = ipg_r16(IPG_CARRIERSENSEERRORS);\r\nsp->stats.collisions += temp1;\r\nsp->stats.tx_dropped += ipg_r16(IPG_FRAMESABORTXSCOLLS);\r\nsp->stats.tx_errors += ipg_r16(IPG_FRAMESWEXDEFERRAL) +\r\nipg_r32(IPG_FRAMESWDEFERREDXMT) + temp1 + temp2;\r\nsp->stats.multicast += ipg_r32(IPG_MCSTOCTETRCVDOK);\r\nsp->stats.tx_carrier_errors += temp2;\r\nsp->stats.rx_length_errors += ipg_r16(IPG_INRANGELENGTHERRORS) +\r\nipg_r16(IPG_FRAMETOOLONGERRRORS);\r\nsp->stats.rx_crc_errors += ipg_r16(IPG_FRAMECHECKSEQERRORS);\r\nipg_r32(IPG_MCSTFRAMESRCVDOK);\r\nreturn &sp->stats;\r\n}\r\nstatic int ipg_nic_rxrestore(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nconst unsigned int curr = sp->rx_current;\r\nunsigned int dirty = sp->rx_dirty;\r\nIPG_DEBUG_MSG("_nic_rxrestore\n");\r\nfor (dirty = sp->rx_dirty; curr - dirty > 0; dirty++) {\r\nunsigned int entry = dirty % IPG_RFDLIST_LENGTH;\r\nif (sp->rx_buff[entry])\r\ncontinue;\r\nif (ipg_get_rxbuff(dev, entry) < 0) {\r\nIPG_DEBUG_MSG("Cannot allocate new Rx buffer\n");\r\nbreak;\r\n}\r\nsp->rxd[entry].rfs = 0x0000000000000000;\r\n}\r\nsp->rx_dirty = dirty;\r\nreturn 0;\r\n}\r\nstatic void ipg_nic_rx_free_skb(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nunsigned int entry = sp->rx_current % IPG_RFDLIST_LENGTH;\r\nif (sp->rx_buff[entry]) {\r\nstruct ipg_rx *rxfd = sp->rxd + entry;\r\npci_unmap_single(sp->pdev,\r\nle64_to_cpu(rxfd->frag_info) & ~IPG_RFI_FRAGLEN,\r\nsp->rx_buf_sz, PCI_DMA_FROMDEVICE);\r\ndev_kfree_skb_irq(sp->rx_buff[entry]);\r\nsp->rx_buff[entry] = NULL;\r\n}\r\n}\r\nstatic int ipg_nic_rx_check_frame_type(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nstruct ipg_rx *rxfd = sp->rxd + (sp->rx_current % IPG_RFDLIST_LENGTH);\r\nint type = FRAME_NO_START_NO_END;\r\nif (le64_to_cpu(rxfd->rfs) & IPG_RFS_FRAMESTART)\r\ntype += FRAME_WITH_START;\r\nif (le64_to_cpu(rxfd->rfs) & IPG_RFS_FRAMEEND)\r\ntype += FRAME_WITH_END;\r\nreturn type;\r\n}\r\nstatic int ipg_nic_rx_check_error(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nunsigned int entry = sp->rx_current % IPG_RFDLIST_LENGTH;\r\nstruct ipg_rx *rxfd = sp->rxd + entry;\r\nif (IPG_DROP_ON_RX_ETH_ERRORS && (le64_to_cpu(rxfd->rfs) &\r\n(IPG_RFS_RXFIFOOVERRUN | IPG_RFS_RXRUNTFRAME |\r\nIPG_RFS_RXALIGNMENTERROR | IPG_RFS_RXFCSERROR |\r\nIPG_RFS_RXOVERSIZEDFRAME | IPG_RFS_RXLENGTHERROR))) {\r\nIPG_DEBUG_MSG("Rx error, RFS = %016lx\n",\r\n(unsigned long) rxfd->rfs);\r\nsp->stats.rx_errors++;\r\nif (le64_to_cpu(rxfd->rfs) & IPG_RFS_RXFIFOOVERRUN) {\r\nIPG_DEBUG_MSG("RX FIFO overrun occurred\n");\r\nsp->stats.rx_fifo_errors++;\r\n}\r\nif (le64_to_cpu(rxfd->rfs) & IPG_RFS_RXRUNTFRAME) {\r\nIPG_DEBUG_MSG("RX runt occurred\n");\r\nsp->stats.rx_length_errors++;\r\n}\r\nif (le64_to_cpu(rxfd->rfs) & IPG_RFS_RXALIGNMENTERROR) {\r\nIPG_DEBUG_MSG("RX alignment error occurred\n");\r\nsp->stats.rx_frame_errors++;\r\n}\r\nif (sp->rx_buff[entry]) {\r\npci_unmap_single(sp->pdev,\r\nle64_to_cpu(rxfd->frag_info) & ~IPG_RFI_FRAGLEN,\r\nsp->rx_buf_sz, PCI_DMA_FROMDEVICE);\r\ndev_kfree_skb_irq(sp->rx_buff[entry]);\r\nsp->rx_buff[entry] = NULL;\r\n}\r\nreturn ERROR_PACKET;\r\n}\r\nreturn NORMAL_PACKET;\r\n}\r\nstatic void ipg_nic_rx_with_start_and_end(struct net_device *dev,\r\nstruct ipg_nic_private *sp,\r\nstruct ipg_rx *rxfd, unsigned entry)\r\n{\r\nstruct ipg_jumbo *jumbo = &sp->jumbo;\r\nstruct sk_buff *skb;\r\nint framelen;\r\nif (jumbo->found_start) {\r\ndev_kfree_skb_irq(jumbo->skb);\r\njumbo->found_start = 0;\r\njumbo->current_size = 0;\r\njumbo->skb = NULL;\r\n}\r\nif (ipg_nic_rx_check_error(dev) != NORMAL_PACKET)\r\nreturn;\r\nskb = sp->rx_buff[entry];\r\nif (!skb)\r\nreturn;\r\nframelen = le64_to_cpu(rxfd->rfs) & IPG_RFS_RXFRAMELEN;\r\nif (framelen > sp->rxfrag_size)\r\nframelen = sp->rxfrag_size;\r\nskb_put(skb, framelen);\r\nskb->protocol = eth_type_trans(skb, dev);\r\nskb_checksum_none_assert(skb);\r\nnetif_rx(skb);\r\nsp->rx_buff[entry] = NULL;\r\n}\r\nstatic void ipg_nic_rx_with_start(struct net_device *dev,\r\nstruct ipg_nic_private *sp,\r\nstruct ipg_rx *rxfd, unsigned entry)\r\n{\r\nstruct ipg_jumbo *jumbo = &sp->jumbo;\r\nstruct pci_dev *pdev = sp->pdev;\r\nstruct sk_buff *skb;\r\nif (ipg_nic_rx_check_error(dev) != NORMAL_PACKET)\r\nreturn;\r\nskb = sp->rx_buff[entry];\r\nif (!skb)\r\nreturn;\r\nif (jumbo->found_start)\r\ndev_kfree_skb_irq(jumbo->skb);\r\npci_unmap_single(pdev, le64_to_cpu(rxfd->frag_info) & ~IPG_RFI_FRAGLEN,\r\nsp->rx_buf_sz, PCI_DMA_FROMDEVICE);\r\nskb_put(skb, sp->rxfrag_size);\r\njumbo->found_start = 1;\r\njumbo->current_size = sp->rxfrag_size;\r\njumbo->skb = skb;\r\nsp->rx_buff[entry] = NULL;\r\n}\r\nstatic void ipg_nic_rx_with_end(struct net_device *dev,\r\nstruct ipg_nic_private *sp,\r\nstruct ipg_rx *rxfd, unsigned entry)\r\n{\r\nstruct ipg_jumbo *jumbo = &sp->jumbo;\r\nif (ipg_nic_rx_check_error(dev) == NORMAL_PACKET) {\r\nstruct sk_buff *skb = sp->rx_buff[entry];\r\nif (!skb)\r\nreturn;\r\nif (jumbo->found_start) {\r\nint framelen, endframelen;\r\nframelen = le64_to_cpu(rxfd->rfs) & IPG_RFS_RXFRAMELEN;\r\nendframelen = framelen - jumbo->current_size;\r\nif (framelen > sp->rxsupport_size)\r\ndev_kfree_skb_irq(jumbo->skb);\r\nelse {\r\nmemcpy(skb_put(jumbo->skb, endframelen),\r\nskb->data, endframelen);\r\njumbo->skb->protocol =\r\neth_type_trans(jumbo->skb, dev);\r\nskb_checksum_none_assert(jumbo->skb);\r\nnetif_rx(jumbo->skb);\r\n}\r\n}\r\njumbo->found_start = 0;\r\njumbo->current_size = 0;\r\njumbo->skb = NULL;\r\nipg_nic_rx_free_skb(dev);\r\n} else {\r\ndev_kfree_skb_irq(jumbo->skb);\r\njumbo->found_start = 0;\r\njumbo->current_size = 0;\r\njumbo->skb = NULL;\r\n}\r\n}\r\nstatic void ipg_nic_rx_no_start_no_end(struct net_device *dev,\r\nstruct ipg_nic_private *sp,\r\nstruct ipg_rx *rxfd, unsigned entry)\r\n{\r\nstruct ipg_jumbo *jumbo = &sp->jumbo;\r\nif (ipg_nic_rx_check_error(dev) == NORMAL_PACKET) {\r\nstruct sk_buff *skb = sp->rx_buff[entry];\r\nif (skb) {\r\nif (jumbo->found_start) {\r\njumbo->current_size += sp->rxfrag_size;\r\nif (jumbo->current_size <= sp->rxsupport_size) {\r\nmemcpy(skb_put(jumbo->skb,\r\nsp->rxfrag_size),\r\nskb->data, sp->rxfrag_size);\r\n}\r\n}\r\nipg_nic_rx_free_skb(dev);\r\n}\r\n} else {\r\ndev_kfree_skb_irq(jumbo->skb);\r\njumbo->found_start = 0;\r\njumbo->current_size = 0;\r\njumbo->skb = NULL;\r\n}\r\n}\r\nstatic int ipg_nic_rx_jumbo(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nunsigned int curr = sp->rx_current;\r\nvoid __iomem *ioaddr = sp->ioaddr;\r\nunsigned int i;\r\nIPG_DEBUG_MSG("_nic_rx\n");\r\nfor (i = 0; i < IPG_MAXRFDPROCESS_COUNT; i++, curr++) {\r\nunsigned int entry = curr % IPG_RFDLIST_LENGTH;\r\nstruct ipg_rx *rxfd = sp->rxd + entry;\r\nif (!(rxfd->rfs & cpu_to_le64(IPG_RFS_RFDDONE)))\r\nbreak;\r\nswitch (ipg_nic_rx_check_frame_type(dev)) {\r\ncase FRAME_WITH_START_WITH_END:\r\nipg_nic_rx_with_start_and_end(dev, sp, rxfd, entry);\r\nbreak;\r\ncase FRAME_WITH_START:\r\nipg_nic_rx_with_start(dev, sp, rxfd, entry);\r\nbreak;\r\ncase FRAME_WITH_END:\r\nipg_nic_rx_with_end(dev, sp, rxfd, entry);\r\nbreak;\r\ncase FRAME_NO_START_NO_END:\r\nipg_nic_rx_no_start_no_end(dev, sp, rxfd, entry);\r\nbreak;\r\n}\r\n}\r\nsp->rx_current = curr;\r\nif (i == IPG_MAXRFDPROCESS_COUNT) {\r\nipg_w32(ipg_r32(ASIC_CTRL) | IPG_AC_INT_REQUEST, ASIC_CTRL);\r\n}\r\nipg_nic_rxrestore(dev);\r\nreturn 0;\r\n}\r\nstatic int ipg_nic_rx(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nunsigned int curr = sp->rx_current;\r\nvoid __iomem *ioaddr = sp->ioaddr;\r\nstruct ipg_rx *rxfd;\r\nunsigned int i;\r\nIPG_DEBUG_MSG("_nic_rx\n");\r\n#define __RFS_MASK \\r\ncpu_to_le64(IPG_RFS_RFDDONE | IPG_RFS_FRAMESTART | IPG_RFS_FRAMEEND)\r\nfor (i = 0; i < IPG_MAXRFDPROCESS_COUNT; i++, curr++) {\r\nunsigned int entry = curr % IPG_RFDLIST_LENGTH;\r\nstruct sk_buff *skb = sp->rx_buff[entry];\r\nunsigned int framelen;\r\nrxfd = sp->rxd + entry;\r\nif (((rxfd->rfs & __RFS_MASK) != __RFS_MASK) || !skb)\r\nbreak;\r\nframelen = le64_to_cpu(rxfd->rfs) & IPG_RFS_RXFRAMELEN;\r\nif (framelen > sp->rxfrag_size) {\r\nIPG_DEBUG_MSG\r\n("RFS FrameLen > allocated fragment size\n");\r\nframelen = sp->rxfrag_size;\r\n}\r\nif ((IPG_DROP_ON_RX_ETH_ERRORS && (le64_to_cpu(rxfd->rfs) &\r\n(IPG_RFS_RXFIFOOVERRUN | IPG_RFS_RXRUNTFRAME |\r\nIPG_RFS_RXALIGNMENTERROR | IPG_RFS_RXFCSERROR |\r\nIPG_RFS_RXOVERSIZEDFRAME | IPG_RFS_RXLENGTHERROR)))) {\r\nIPG_DEBUG_MSG("Rx error, RFS = %016lx\n",\r\n(unsigned long int) rxfd->rfs);\r\nsp->stats.rx_errors++;\r\nif (le64_to_cpu(rxfd->rfs) & IPG_RFS_RXFIFOOVERRUN) {\r\nIPG_DEBUG_MSG("RX FIFO overrun occurred\n");\r\nsp->stats.rx_fifo_errors++;\r\n}\r\nif (le64_to_cpu(rxfd->rfs) & IPG_RFS_RXRUNTFRAME) {\r\nIPG_DEBUG_MSG("RX runt occurred\n");\r\nsp->stats.rx_length_errors++;\r\n}\r\nif (le64_to_cpu(rxfd->rfs) & IPG_RFS_RXOVERSIZEDFRAME) ;\r\nif (le64_to_cpu(rxfd->rfs) & IPG_RFS_RXALIGNMENTERROR) {\r\nIPG_DEBUG_MSG("RX alignment error occurred\n");\r\nsp->stats.rx_frame_errors++;\r\n}\r\nif (le64_to_cpu(rxfd->rfs) & IPG_RFS_RXFCSERROR) ;\r\nif (skb) {\r\n__le64 info = rxfd->frag_info;\r\npci_unmap_single(sp->pdev,\r\nle64_to_cpu(info) & ~IPG_RFI_FRAGLEN,\r\nsp->rx_buf_sz, PCI_DMA_FROMDEVICE);\r\ndev_kfree_skb_irq(skb);\r\n}\r\n} else {\r\nskb_put(skb, framelen);\r\nskb->protocol = eth_type_trans(skb, dev);\r\nskb_checksum_none_assert(skb);\r\nnetif_rx(skb);\r\n}\r\nsp->rx_buff[entry] = NULL;\r\n}\r\nif (i == IPG_MAXRFDPROCESS_COUNT)\r\nipg_w32(ipg_r32(ASIC_CTRL) | IPG_AC_INT_REQUEST, ASIC_CTRL);\r\n#ifdef IPG_DEBUG\r\nif (!i)\r\nsp->EmptyRFDListCount++;\r\n#endif\r\nwhile ((le64_to_cpu(rxfd->rfs) & IPG_RFS_RFDDONE) &&\r\n!((le64_to_cpu(rxfd->rfs) & IPG_RFS_FRAMESTART) &&\r\n(le64_to_cpu(rxfd->rfs) & IPG_RFS_FRAMEEND))) {\r\nunsigned int entry = curr++ % IPG_RFDLIST_LENGTH;\r\nrxfd = sp->rxd + entry;\r\nIPG_DEBUG_MSG("Frame requires multiple RFDs\n");\r\nif (sp->rx_buff[entry]) {\r\npci_unmap_single(sp->pdev,\r\nle64_to_cpu(rxfd->frag_info) & ~IPG_RFI_FRAGLEN,\r\nsp->rx_buf_sz, PCI_DMA_FROMDEVICE);\r\ndev_kfree_skb_irq(sp->rx_buff[entry]);\r\n}\r\nsp->rx_buff[entry] = NULL;\r\n}\r\nsp->rx_current = curr;\r\nif ((curr - sp->rx_dirty) >= IPG_MINUSEDRFDSTOFREE)\r\nipg_nic_rxrestore(dev);\r\nreturn 0;\r\n}\r\nstatic void ipg_reset_after_host_error(struct work_struct *work)\r\n{\r\nstruct ipg_nic_private *sp =\r\ncontainer_of(work, struct ipg_nic_private, task.work);\r\nstruct net_device *dev = sp->dev;\r\nipg_reset(dev, IPG_AC_GLOBAL_RESET | IPG_AC_HOST | IPG_AC_DMA);\r\ninit_rfdlist(dev);\r\ninit_tfdlist(dev);\r\nif (ipg_io_config(dev) < 0) {\r\nnetdev_info(dev, "Cannot recover from PCI error\n");\r\nschedule_delayed_work(&sp->task, HZ);\r\n}\r\n}\r\nstatic irqreturn_t ipg_interrupt_handler(int irq, void *dev_inst)\r\n{\r\nstruct net_device *dev = dev_inst;\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = sp->ioaddr;\r\nunsigned int handled = 0;\r\nu16 status;\r\nIPG_DEBUG_MSG("_interrupt_handler\n");\r\nif (sp->is_jumbo)\r\nipg_nic_rxrestore(dev);\r\nspin_lock(&sp->lock);\r\nstatus = ipg_r16(INT_STATUS_ACK);\r\nIPG_DEBUG_MSG("IntStatusAck = %04x\n", status);\r\nif (!(status & IPG_IS_RSVD_MASK))\r\ngoto out_enable;\r\nhandled = 1;\r\nif (unlikely(!netif_running(dev)))\r\ngoto out_unlock;\r\nif (status & IPG_IS_RFD_LIST_END) {\r\nIPG_DEBUG_MSG("RFDListEnd Interrupt\n");\r\nipg_nic_rxrestore(dev);\r\n#ifdef IPG_DEBUG\r\nsp->RFDlistendCount++;\r\n#endif\r\n}\r\nif ((status & IPG_IS_RX_DMA_PRIORITY) ||\r\n(status & IPG_IS_RFD_LIST_END) ||\r\n(status & IPG_IS_RX_DMA_COMPLETE) ||\r\n(status & IPG_IS_INT_REQUESTED)) {\r\n#ifdef IPG_DEBUG\r\nif (status & (~(IPG_IS_RX_DMA_PRIORITY | IPG_IS_RFD_LIST_END |\r\nIPG_IS_RX_DMA_COMPLETE | IPG_IS_INT_REQUESTED) &\r\n(IPG_IS_HOST_ERROR | IPG_IS_TX_DMA_COMPLETE |\r\nIPG_IS_LINK_EVENT | IPG_IS_TX_COMPLETE |\r\nIPG_IS_UPDATE_STATS)))\r\nsp->RFDListCheckedCount++;\r\n#endif\r\nif (sp->is_jumbo)\r\nipg_nic_rx_jumbo(dev);\r\nelse\r\nipg_nic_rx(dev);\r\n}\r\nif (status & IPG_IS_TX_DMA_COMPLETE)\r\nipg_nic_txfree(dev);\r\nif (status & IPG_IS_TX_COMPLETE)\r\nipg_nic_txcleanup(dev);\r\nif (status & IPG_IS_UPDATE_STATS)\r\nipg_nic_get_stats(dev);\r\nif (status & IPG_IS_HOST_ERROR) {\r\nIPG_DDEBUG_MSG("HostError Interrupt\n");\r\nschedule_delayed_work(&sp->task, 0);\r\n}\r\nif (status & IPG_IS_LINK_EVENT) {\r\nif (ipg_config_autoneg(dev) < 0)\r\nnetdev_info(dev, "Auto-negotiation error\n");\r\n}\r\nif (status & IPG_IS_MAC_CTRL_FRAME)\r\nIPG_DEBUG_MSG("MACCtrlFrame interrupt\n");\r\nif (status & IPG_IS_RX_COMPLETE)\r\nIPG_DEBUG_MSG("RxComplete interrupt\n");\r\nif (status & IPG_IS_RX_EARLY)\r\nIPG_DEBUG_MSG("RxEarly interrupt\n");\r\nout_enable:\r\nipg_w16(IPG_IE_TX_DMA_COMPLETE | IPG_IE_RX_DMA_COMPLETE |\r\nIPG_IE_HOST_ERROR | IPG_IE_INT_REQUESTED | IPG_IE_TX_COMPLETE |\r\nIPG_IE_LINK_EVENT | IPG_IE_UPDATE_STATS, INT_ENABLE);\r\nout_unlock:\r\nspin_unlock(&sp->lock);\r\nreturn IRQ_RETVAL(handled);\r\n}\r\nstatic void ipg_rx_clear(struct ipg_nic_private *sp)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < IPG_RFDLIST_LENGTH; i++) {\r\nif (sp->rx_buff[i]) {\r\nstruct ipg_rx *rxfd = sp->rxd + i;\r\ndev_kfree_skb_irq(sp->rx_buff[i]);\r\nsp->rx_buff[i] = NULL;\r\npci_unmap_single(sp->pdev,\r\nle64_to_cpu(rxfd->frag_info) & ~IPG_RFI_FRAGLEN,\r\nsp->rx_buf_sz, PCI_DMA_FROMDEVICE);\r\n}\r\n}\r\n}\r\nstatic void ipg_tx_clear(struct ipg_nic_private *sp)\r\n{\r\nunsigned int i;\r\nfor (i = 0; i < IPG_TFDLIST_LENGTH; i++) {\r\nif (sp->tx_buff[i]) {\r\nstruct ipg_tx *txfd = sp->txd + i;\r\npci_unmap_single(sp->pdev,\r\nle64_to_cpu(txfd->frag_info) & ~IPG_TFI_FRAGLEN,\r\nsp->tx_buff[i]->len, PCI_DMA_TODEVICE);\r\ndev_kfree_skb_irq(sp->tx_buff[i]);\r\nsp->tx_buff[i] = NULL;\r\n}\r\n}\r\n}\r\nstatic int ipg_nic_open(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = sp->ioaddr;\r\nstruct pci_dev *pdev = sp->pdev;\r\nint rc;\r\nIPG_DEBUG_MSG("_nic_open\n");\r\nsp->rx_buf_sz = sp->rxsupport_size;\r\nipg_w16(0x0000, INT_ENABLE);\r\nrc = request_irq(pdev->irq, ipg_interrupt_handler, IRQF_SHARED,\r\ndev->name, dev);\r\nif (rc < 0) {\r\nnetdev_info(dev, "Error when requesting interrupt\n");\r\ngoto out;\r\n}\r\ndev->irq = pdev->irq;\r\nrc = -ENOMEM;\r\nsp->rxd = dma_alloc_coherent(&pdev->dev, IPG_RX_RING_BYTES,\r\n&sp->rxd_map, GFP_KERNEL);\r\nif (!sp->rxd)\r\ngoto err_free_irq_0;\r\nsp->txd = dma_alloc_coherent(&pdev->dev, IPG_TX_RING_BYTES,\r\n&sp->txd_map, GFP_KERNEL);\r\nif (!sp->txd)\r\ngoto err_free_rx_1;\r\nrc = init_rfdlist(dev);\r\nif (rc < 0) {\r\nnetdev_info(dev, "Error during configuration\n");\r\ngoto err_free_tx_2;\r\n}\r\ninit_tfdlist(dev);\r\nrc = ipg_io_config(dev);\r\nif (rc < 0) {\r\nnetdev_info(dev, "Error during configuration\n");\r\ngoto err_release_tfdlist_3;\r\n}\r\nif (ipg_config_autoneg(dev) < 0)\r\nnetdev_info(dev, "Auto-negotiation error\n");\r\nsp->jumbo.found_start = 0;\r\nsp->jumbo.current_size = 0;\r\nsp->jumbo.skb = NULL;\r\nipg_w32((ipg_r32(MAC_CTRL) | IPG_MC_RX_ENABLE | IPG_MC_TX_ENABLE) &\r\nIPG_MC_RSVD_MASK, MAC_CTRL);\r\nnetif_start_queue(dev);\r\nout:\r\nreturn rc;\r\nerr_release_tfdlist_3:\r\nipg_tx_clear(sp);\r\nipg_rx_clear(sp);\r\nerr_free_tx_2:\r\ndma_free_coherent(&pdev->dev, IPG_TX_RING_BYTES, sp->txd, sp->txd_map);\r\nerr_free_rx_1:\r\ndma_free_coherent(&pdev->dev, IPG_RX_RING_BYTES, sp->rxd, sp->rxd_map);\r\nerr_free_irq_0:\r\nfree_irq(pdev->irq, dev);\r\ngoto out;\r\n}\r\nstatic int ipg_nic_stop(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = sp->ioaddr;\r\nstruct pci_dev *pdev = sp->pdev;\r\nIPG_DEBUG_MSG("_nic_stop\n");\r\nnetif_stop_queue(dev);\r\nIPG_DUMPTFDLIST(dev);\r\ndo {\r\n(void) ipg_r16(INT_STATUS_ACK);\r\nipg_reset(dev, IPG_AC_GLOBAL_RESET | IPG_AC_HOST | IPG_AC_DMA);\r\nsynchronize_irq(pdev->irq);\r\n} while (ipg_r16(INT_ENABLE) & IPG_IE_RSVD_MASK);\r\nipg_rx_clear(sp);\r\nipg_tx_clear(sp);\r\npci_free_consistent(pdev, IPG_RX_RING_BYTES, sp->rxd, sp->rxd_map);\r\npci_free_consistent(pdev, IPG_TX_RING_BYTES, sp->txd, sp->txd_map);\r\nfree_irq(pdev->irq, dev);\r\nreturn 0;\r\n}\r\nstatic netdev_tx_t ipg_nic_hard_start_xmit(struct sk_buff *skb,\r\nstruct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = sp->ioaddr;\r\nunsigned int entry = sp->tx_current % IPG_TFDLIST_LENGTH;\r\nunsigned long flags;\r\nstruct ipg_tx *txfd;\r\nIPG_DDEBUG_MSG("_nic_hard_start_xmit\n");\r\nif (sp->tenmbpsmode)\r\nnetif_stop_queue(dev);\r\nif (sp->reset_current_tfd) {\r\nsp->reset_current_tfd = 0;\r\nentry = 0;\r\n}\r\ntxfd = sp->txd + entry;\r\nsp->tx_buff[entry] = skb;\r\ntxfd->tfc = cpu_to_le64(IPG_TFC_TFDDONE);\r\ntxfd->tfc |= cpu_to_le64(IPG_TFC_WORDALIGNDISABLED |\r\n(IPG_TFC_FRAMEID & sp->tx_current) |\r\n(IPG_TFC_FRAGCOUNT & (1 << 24)));\r\nif (sp->tenmbpsmode)\r\ntxfd->tfc |= cpu_to_le64(IPG_TFC_TXINDICATE);\r\ntxfd->tfc |= cpu_to_le64(IPG_TFC_TXDMAINDICATE);\r\nif (!(IPG_APPEND_FCS_ON_TX))\r\ntxfd->tfc |= cpu_to_le64(IPG_TFC_FCSAPPENDDISABLE);\r\nif (IPG_ADD_IPCHECKSUM_ON_TX)\r\ntxfd->tfc |= cpu_to_le64(IPG_TFC_IPCHECKSUMENABLE);\r\nif (IPG_ADD_TCPCHECKSUM_ON_TX)\r\ntxfd->tfc |= cpu_to_le64(IPG_TFC_TCPCHECKSUMENABLE);\r\nif (IPG_ADD_UDPCHECKSUM_ON_TX)\r\ntxfd->tfc |= cpu_to_le64(IPG_TFC_UDPCHECKSUMENABLE);\r\nif (IPG_INSERT_MANUAL_VLAN_TAG) {\r\ntxfd->tfc |= cpu_to_le64(IPG_TFC_VLANTAGINSERT |\r\n((u64) IPG_MANUAL_VLAN_VID << 32) |\r\n((u64) IPG_MANUAL_VLAN_CFI << 44) |\r\n((u64) IPG_MANUAL_VLAN_USERPRIORITY << 45));\r\n}\r\ntxfd->frag_info = cpu_to_le64(pci_map_single(sp->pdev, skb->data,\r\nskb->len, PCI_DMA_TODEVICE));\r\ntxfd->frag_info |= cpu_to_le64(IPG_TFI_FRAGLEN &\r\n((u64) (skb->len & 0xffff) << 48));\r\ntxfd->tfc &= cpu_to_le64(~IPG_TFC_TFDDONE);\r\nspin_lock_irqsave(&sp->lock, flags);\r\nsp->tx_current++;\r\nmmiowb();\r\nipg_w32(IPG_DC_TX_DMA_POLL_NOW, DMA_CTRL);\r\nif (sp->tx_current == (sp->tx_dirty + IPG_TFDLIST_LENGTH))\r\nnetif_stop_queue(dev);\r\nspin_unlock_irqrestore(&sp->lock, flags);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void ipg_set_phy_default_param(unsigned char rev,\r\nstruct net_device *dev, int phy_address)\r\n{\r\nunsigned short length;\r\nunsigned char revision;\r\nconst unsigned short *phy_param;\r\nunsigned short address, value;\r\nphy_param = &DefaultPhyParam[0];\r\nlength = *phy_param & 0x00FF;\r\nrevision = (unsigned char)((*phy_param) >> 8);\r\nphy_param++;\r\nwhile (length != 0) {\r\nif (rev == revision) {\r\nwhile (length > 1) {\r\naddress = *phy_param;\r\nvalue = *(phy_param + 1);\r\nphy_param += 2;\r\nmdio_write(dev, phy_address, address, value);\r\nlength -= 4;\r\n}\r\nbreak;\r\n} else {\r\nphy_param += length / 2;\r\nlength = *phy_param & 0x00FF;\r\nrevision = (unsigned char)((*phy_param) >> 8);\r\nphy_param++;\r\n}\r\n}\r\n}\r\nstatic int read_eeprom(struct net_device *dev, int eep_addr)\r\n{\r\nvoid __iomem *ioaddr = ipg_ioaddr(dev);\r\nunsigned int i;\r\nint ret = 0;\r\nu16 value;\r\nvalue = IPG_EC_EEPROM_READOPCODE | (eep_addr & 0xff);\r\nipg_w16(value, EEPROM_CTRL);\r\nfor (i = 0; i < 1000; i++) {\r\nu16 data;\r\nmdelay(10);\r\ndata = ipg_r16(EEPROM_CTRL);\r\nif (!(data & IPG_EC_EEPROM_BUSY)) {\r\nret = ipg_r16(EEPROM_DATA);\r\nbreak;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic void ipg_init_mii(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nstruct mii_if_info *mii_if = &sp->mii_if;\r\nint phyaddr;\r\nmii_if->dev = dev;\r\nmii_if->mdio_read = mdio_read;\r\nmii_if->mdio_write = mdio_write;\r\nmii_if->phy_id_mask = 0x1f;\r\nmii_if->reg_num_mask = 0x1f;\r\nmii_if->phy_id = phyaddr = ipg_find_phyaddr(dev);\r\nif (phyaddr != 0x1f) {\r\nu16 mii_phyctrl, mii_1000cr;\r\nmii_1000cr = mdio_read(dev, phyaddr, MII_CTRL1000);\r\nmii_1000cr |= ADVERTISE_1000FULL | ADVERTISE_1000HALF |\r\nGMII_PHY_1000BASETCONTROL_PreferMaster;\r\nmdio_write(dev, phyaddr, MII_CTRL1000, mii_1000cr);\r\nmii_phyctrl = mdio_read(dev, phyaddr, MII_BMCR);\r\nipg_set_phy_default_param(sp->pdev->revision, dev, phyaddr);\r\nmii_phyctrl |= BMCR_RESET | BMCR_ANRESTART;\r\nmdio_write(dev, phyaddr, MII_BMCR, mii_phyctrl);\r\n}\r\n}\r\nstatic int ipg_hw_init(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nvoid __iomem *ioaddr = sp->ioaddr;\r\nunsigned int i;\r\nint rc;\r\nsp->led_mode = read_eeprom(dev, 6);\r\nrc = ipg_reset(dev, IPG_RESET_MASK);\r\nif (rc < 0)\r\ngoto out;\r\nipg_init_mii(dev);\r\nfor (i = 0; i < 3; i++)\r\nsp->station_addr[i] = read_eeprom(dev, 16 + i);\r\nfor (i = 0; i < 3; i++)\r\nipg_w16(sp->station_addr[i], STATION_ADDRESS_0 + 2*i);\r\ndev->dev_addr[0] = ipg_r16(STATION_ADDRESS_0) & 0x00ff;\r\ndev->dev_addr[1] = (ipg_r16(STATION_ADDRESS_0) & 0xff00) >> 8;\r\ndev->dev_addr[2] = ipg_r16(STATION_ADDRESS_1) & 0x00ff;\r\ndev->dev_addr[3] = (ipg_r16(STATION_ADDRESS_1) & 0xff00) >> 8;\r\ndev->dev_addr[4] = ipg_r16(STATION_ADDRESS_2) & 0x00ff;\r\ndev->dev_addr[5] = (ipg_r16(STATION_ADDRESS_2) & 0xff00) >> 8;\r\nout:\r\nreturn rc;\r\n}\r\nstatic int ipg_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nint rc;\r\nmutex_lock(&sp->mii_mutex);\r\nrc = generic_mii_ioctl(&sp->mii_if, if_mii(ifr), cmd, NULL);\r\nmutex_unlock(&sp->mii_mutex);\r\nreturn rc;\r\n}\r\nstatic int ipg_nic_change_mtu(struct net_device *dev, int new_mtu)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nint err;\r\nIPG_DEBUG_MSG("_nic_change_mtu\n");\r\nif (new_mtu < 68 || new_mtu > 10240)\r\nreturn -EINVAL;\r\nerr = ipg_nic_stop(dev);\r\nif (err)\r\nreturn err;\r\ndev->mtu = new_mtu;\r\nsp->max_rxframe_size = new_mtu;\r\nsp->rxfrag_size = new_mtu;\r\nif (sp->rxfrag_size > 4088)\r\nsp->rxfrag_size = 4088;\r\nsp->rxsupport_size = sp->max_rxframe_size;\r\nif (new_mtu > 0x0600)\r\nsp->is_jumbo = true;\r\nelse\r\nsp->is_jumbo = false;\r\nreturn ipg_nic_open(dev);\r\n}\r\nstatic int ipg_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nint rc;\r\nmutex_lock(&sp->mii_mutex);\r\nrc = mii_ethtool_gset(&sp->mii_if, cmd);\r\nmutex_unlock(&sp->mii_mutex);\r\nreturn rc;\r\n}\r\nstatic int ipg_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nint rc;\r\nmutex_lock(&sp->mii_mutex);\r\nrc = mii_ethtool_sset(&sp->mii_if, cmd);\r\nmutex_unlock(&sp->mii_mutex);\r\nreturn rc;\r\n}\r\nstatic int ipg_nway_reset(struct net_device *dev)\r\n{\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nint rc;\r\nmutex_lock(&sp->mii_mutex);\r\nrc = mii_nway_restart(&sp->mii_if);\r\nmutex_unlock(&sp->mii_mutex);\r\nreturn rc;\r\n}\r\nstatic void ipg_remove(struct pci_dev *pdev)\r\n{\r\nstruct net_device *dev = pci_get_drvdata(pdev);\r\nstruct ipg_nic_private *sp = netdev_priv(dev);\r\nIPG_DEBUG_MSG("_remove\n");\r\nunregister_netdev(dev);\r\npci_iounmap(pdev, sp->ioaddr);\r\npci_release_regions(pdev);\r\nfree_netdev(dev);\r\npci_disable_device(pdev);\r\n}\r\nstatic int ipg_probe(struct pci_dev *pdev, const struct pci_device_id *id)\r\n{\r\nunsigned int i = id->driver_data;\r\nstruct ipg_nic_private *sp;\r\nstruct net_device *dev;\r\nvoid __iomem *ioaddr;\r\nint rc;\r\nrc = pci_enable_device(pdev);\r\nif (rc < 0)\r\ngoto out;\r\npr_info("%s: %s\n", pci_name(pdev), ipg_brand_name[i]);\r\npci_set_master(pdev);\r\nrc = pci_set_dma_mask(pdev, DMA_BIT_MASK(40));\r\nif (rc < 0) {\r\nrc = pci_set_dma_mask(pdev, DMA_BIT_MASK(32));\r\nif (rc < 0) {\r\npr_err("%s: DMA config failed\n", pci_name(pdev));\r\ngoto err_disable_0;\r\n}\r\n}\r\ndev = alloc_etherdev(sizeof(struct ipg_nic_private));\r\nif (!dev) {\r\nrc = -ENOMEM;\r\ngoto err_disable_0;\r\n}\r\nsp = netdev_priv(dev);\r\nspin_lock_init(&sp->lock);\r\nmutex_init(&sp->mii_mutex);\r\nsp->is_jumbo = IPG_IS_JUMBO;\r\nsp->rxfrag_size = IPG_RXFRAG_SIZE;\r\nsp->rxsupport_size = IPG_RXSUPPORT_SIZE;\r\nsp->max_rxframe_size = IPG_MAX_RXFRAME_SIZE;\r\ndev->netdev_ops = &ipg_netdev_ops;\r\nSET_NETDEV_DEV(dev, &pdev->dev);\r\nSET_ETHTOOL_OPS(dev, &ipg_ethtool_ops);\r\nrc = pci_request_regions(pdev, DRV_NAME);\r\nif (rc)\r\ngoto err_free_dev_1;\r\nioaddr = pci_iomap(pdev, 1, pci_resource_len(pdev, 1));\r\nif (!ioaddr) {\r\npr_err("%s: cannot map MMIO\n", pci_name(pdev));\r\nrc = -EIO;\r\ngoto err_release_regions_2;\r\n}\r\nsp->ioaddr = ioaddr;\r\nsp->pdev = pdev;\r\nsp->dev = dev;\r\nINIT_DELAYED_WORK(&sp->task, ipg_reset_after_host_error);\r\npci_set_drvdata(pdev, dev);\r\nrc = ipg_hw_init(dev);\r\nif (rc < 0)\r\ngoto err_unmap_3;\r\nrc = register_netdev(dev);\r\nif (rc < 0)\r\ngoto err_unmap_3;\r\nnetdev_info(dev, "Ethernet device registered\n");\r\nout:\r\nreturn rc;\r\nerr_unmap_3:\r\npci_iounmap(pdev, ioaddr);\r\nerr_release_regions_2:\r\npci_release_regions(pdev);\r\nerr_free_dev_1:\r\nfree_netdev(dev);\r\nerr_disable_0:\r\npci_disable_device(pdev);\r\ngoto out;\r\n}
