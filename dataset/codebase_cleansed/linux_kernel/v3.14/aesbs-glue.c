static int aesbs_cbc_set_key(struct crypto_tfm *tfm, const u8 *in_key,\r\nunsigned int key_len)\r\n{\r\nstruct aesbs_cbc_ctx *ctx = crypto_tfm_ctx(tfm);\r\nint bits = key_len * 8;\r\nif (private_AES_set_encrypt_key(in_key, bits, &ctx->enc)) {\r\ntfm->crt_flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\r\nreturn -EINVAL;\r\n}\r\nctx->dec.rk = ctx->enc;\r\nprivate_AES_set_decrypt_key(in_key, bits, &ctx->dec.rk);\r\nctx->dec.converted = 0;\r\nreturn 0;\r\n}\r\nstatic int aesbs_ctr_set_key(struct crypto_tfm *tfm, const u8 *in_key,\r\nunsigned int key_len)\r\n{\r\nstruct aesbs_ctr_ctx *ctx = crypto_tfm_ctx(tfm);\r\nint bits = key_len * 8;\r\nif (private_AES_set_encrypt_key(in_key, bits, &ctx->enc.rk)) {\r\ntfm->crt_flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\r\nreturn -EINVAL;\r\n}\r\nctx->enc.converted = 0;\r\nreturn 0;\r\n}\r\nstatic int aesbs_xts_set_key(struct crypto_tfm *tfm, const u8 *in_key,\r\nunsigned int key_len)\r\n{\r\nstruct aesbs_xts_ctx *ctx = crypto_tfm_ctx(tfm);\r\nint bits = key_len * 4;\r\nif (private_AES_set_encrypt_key(in_key, bits, &ctx->enc.rk)) {\r\ntfm->crt_flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;\r\nreturn -EINVAL;\r\n}\r\nctx->dec.rk = ctx->enc.rk;\r\nprivate_AES_set_decrypt_key(in_key, bits, &ctx->dec.rk);\r\nprivate_AES_set_encrypt_key(in_key + key_len / 2, bits, &ctx->twkey);\r\nctx->enc.converted = ctx->dec.converted = 0;\r\nreturn 0;\r\n}\r\nstatic int aesbs_cbc_encrypt(struct blkcipher_desc *desc,\r\nstruct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct aesbs_cbc_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nstruct blkcipher_walk walk;\r\nint err;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt(desc, &walk);\r\nwhile (walk.nbytes) {\r\nu32 blocks = walk.nbytes / AES_BLOCK_SIZE;\r\nu8 *src = walk.src.virt.addr;\r\nif (walk.dst.virt.addr == walk.src.virt.addr) {\r\nu8 *iv = walk.iv;\r\ndo {\r\ncrypto_xor(src, iv, AES_BLOCK_SIZE);\r\nAES_encrypt(src, src, &ctx->enc);\r\niv = src;\r\nsrc += AES_BLOCK_SIZE;\r\n} while (--blocks);\r\nmemcpy(walk.iv, iv, AES_BLOCK_SIZE);\r\n} else {\r\nu8 *dst = walk.dst.virt.addr;\r\ndo {\r\ncrypto_xor(walk.iv, src, AES_BLOCK_SIZE);\r\nAES_encrypt(walk.iv, dst, &ctx->enc);\r\nmemcpy(walk.iv, dst, AES_BLOCK_SIZE);\r\nsrc += AES_BLOCK_SIZE;\r\ndst += AES_BLOCK_SIZE;\r\n} while (--blocks);\r\n}\r\nerr = blkcipher_walk_done(desc, &walk, 0);\r\n}\r\nreturn err;\r\n}\r\nstatic int aesbs_cbc_decrypt(struct blkcipher_desc *desc,\r\nstruct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct aesbs_cbc_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nstruct blkcipher_walk walk;\r\nint err;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt_block(desc, &walk, 8 * AES_BLOCK_SIZE);\r\nwhile ((walk.nbytes / AES_BLOCK_SIZE) >= 8) {\r\nkernel_neon_begin();\r\nbsaes_cbc_encrypt(walk.src.virt.addr, walk.dst.virt.addr,\r\nwalk.nbytes, &ctx->dec, walk.iv);\r\nkernel_neon_end();\r\nerr = blkcipher_walk_done(desc, &walk, 0);\r\n}\r\nwhile (walk.nbytes) {\r\nu32 blocks = walk.nbytes / AES_BLOCK_SIZE;\r\nu8 *dst = walk.dst.virt.addr;\r\nu8 *src = walk.src.virt.addr;\r\nu8 bk[2][AES_BLOCK_SIZE];\r\nu8 *iv = walk.iv;\r\ndo {\r\nif (walk.dst.virt.addr == walk.src.virt.addr)\r\nmemcpy(bk[blocks & 1], src, AES_BLOCK_SIZE);\r\nAES_decrypt(src, dst, &ctx->dec.rk);\r\ncrypto_xor(dst, iv, AES_BLOCK_SIZE);\r\nif (walk.dst.virt.addr == walk.src.virt.addr)\r\niv = bk[blocks & 1];\r\nelse\r\niv = src;\r\ndst += AES_BLOCK_SIZE;\r\nsrc += AES_BLOCK_SIZE;\r\n} while (--blocks);\r\nerr = blkcipher_walk_done(desc, &walk, 0);\r\n}\r\nreturn err;\r\n}\r\nstatic void inc_be128_ctr(__be32 ctr[], u32 addend)\r\n{\r\nint i;\r\nfor (i = 3; i >= 0; i--, addend = 1) {\r\nu32 n = be32_to_cpu(ctr[i]) + addend;\r\nctr[i] = cpu_to_be32(n);\r\nif (n >= addend)\r\nbreak;\r\n}\r\n}\r\nstatic int aesbs_ctr_encrypt(struct blkcipher_desc *desc,\r\nstruct scatterlist *dst, struct scatterlist *src,\r\nunsigned int nbytes)\r\n{\r\nstruct aesbs_ctr_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nstruct blkcipher_walk walk;\r\nu32 blocks;\r\nint err;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt_block(desc, &walk, 8 * AES_BLOCK_SIZE);\r\nwhile ((blocks = walk.nbytes / AES_BLOCK_SIZE)) {\r\nu32 tail = walk.nbytes % AES_BLOCK_SIZE;\r\n__be32 *ctr = (__be32 *)walk.iv;\r\nu32 headroom = UINT_MAX - be32_to_cpu(ctr[3]);\r\nif (unlikely(headroom < blocks)) {\r\nblocks = headroom + 1;\r\ntail = walk.nbytes - blocks * AES_BLOCK_SIZE;\r\n}\r\nkernel_neon_begin();\r\nbsaes_ctr32_encrypt_blocks(walk.src.virt.addr,\r\nwalk.dst.virt.addr, blocks,\r\n&ctx->enc, walk.iv);\r\nkernel_neon_end();\r\ninc_be128_ctr(ctr, blocks);\r\nnbytes -= blocks * AES_BLOCK_SIZE;\r\nif (nbytes && nbytes == tail && nbytes <= AES_BLOCK_SIZE)\r\nbreak;\r\nerr = blkcipher_walk_done(desc, &walk, tail);\r\n}\r\nif (walk.nbytes) {\r\nu8 *tdst = walk.dst.virt.addr + blocks * AES_BLOCK_SIZE;\r\nu8 *tsrc = walk.src.virt.addr + blocks * AES_BLOCK_SIZE;\r\nu8 ks[AES_BLOCK_SIZE];\r\nAES_encrypt(walk.iv, ks, &ctx->enc.rk);\r\nif (tdst != tsrc)\r\nmemcpy(tdst, tsrc, nbytes);\r\ncrypto_xor(tdst, ks, nbytes);\r\nerr = blkcipher_walk_done(desc, &walk, 0);\r\n}\r\nreturn err;\r\n}\r\nstatic int aesbs_xts_encrypt(struct blkcipher_desc *desc,\r\nstruct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct aesbs_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nstruct blkcipher_walk walk;\r\nint err;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt_block(desc, &walk, 8 * AES_BLOCK_SIZE);\r\nAES_encrypt(walk.iv, walk.iv, &ctx->twkey);\r\nwhile (walk.nbytes) {\r\nkernel_neon_begin();\r\nbsaes_xts_encrypt(walk.src.virt.addr, walk.dst.virt.addr,\r\nwalk.nbytes, &ctx->enc, walk.iv);\r\nkernel_neon_end();\r\nerr = blkcipher_walk_done(desc, &walk, 0);\r\n}\r\nreturn err;\r\n}\r\nstatic int aesbs_xts_decrypt(struct blkcipher_desc *desc,\r\nstruct scatterlist *dst,\r\nstruct scatterlist *src, unsigned int nbytes)\r\n{\r\nstruct aesbs_xts_ctx *ctx = crypto_blkcipher_ctx(desc->tfm);\r\nstruct blkcipher_walk walk;\r\nint err;\r\nblkcipher_walk_init(&walk, dst, src, nbytes);\r\nerr = blkcipher_walk_virt_block(desc, &walk, 8 * AES_BLOCK_SIZE);\r\nAES_encrypt(walk.iv, walk.iv, &ctx->twkey);\r\nwhile (walk.nbytes) {\r\nkernel_neon_begin();\r\nbsaes_xts_decrypt(walk.src.virt.addr, walk.dst.virt.addr,\r\nwalk.nbytes, &ctx->dec, walk.iv);\r\nkernel_neon_end();\r\nerr = blkcipher_walk_done(desc, &walk, 0);\r\n}\r\nreturn err;\r\n}\r\nstatic int __init aesbs_mod_init(void)\r\n{\r\nif (!cpu_has_neon())\r\nreturn -ENODEV;\r\nreturn crypto_register_algs(aesbs_algs, ARRAY_SIZE(aesbs_algs));\r\n}\r\nstatic void __exit aesbs_mod_exit(void)\r\n{\r\ncrypto_unregister_algs(aesbs_algs, ARRAY_SIZE(aesbs_algs));\r\n}
