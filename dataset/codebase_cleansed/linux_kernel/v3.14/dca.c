static inline int dca2_tag_map_valid(u8 *tag_map)\r\n{\r\nreturn ((tag_map[0] == DCA2_TAG_MAP_BYTE0) &&\r\n(tag_map[1] == DCA2_TAG_MAP_BYTE1) &&\r\n(tag_map[2] == DCA2_TAG_MAP_BYTE2) &&\r\n(tag_map[3] == DCA2_TAG_MAP_BYTE3) &&\r\n(tag_map[4] == DCA2_TAG_MAP_BYTE4));\r\n}\r\nstatic inline u16 dcaid_from_pcidev(struct pci_dev *pci)\r\n{\r\nreturn (pci->bus->number << 8) | pci->devfn;\r\n}\r\nstatic int dca_enabled_in_bios(struct pci_dev *pdev)\r\n{\r\nunsigned long cpuid_level_9;\r\nint res;\r\ncpuid_level_9 = cpuid_eax(9);\r\nres = test_bit(0, &cpuid_level_9);\r\nif (!res)\r\ndev_dbg(&pdev->dev, "DCA is disabled in BIOS\n");\r\nreturn res;\r\n}\r\nint system_has_dca_enabled(struct pci_dev *pdev)\r\n{\r\nif (boot_cpu_has(X86_FEATURE_DCA))\r\nreturn dca_enabled_in_bios(pdev);\r\ndev_dbg(&pdev->dev, "boot cpu doesn't have X86_FEATURE_DCA\n");\r\nreturn 0;\r\n}\r\nstatic int ioat_dca_add_requester(struct dca_provider *dca, struct device *dev)\r\n{\r\nstruct ioat_dca_priv *ioatdca = dca_priv(dca);\r\nstruct pci_dev *pdev;\r\nint i;\r\nu16 id;\r\nif (dev->bus != &pci_bus_type)\r\nreturn -ENODEV;\r\npdev = to_pci_dev(dev);\r\nid = dcaid_from_pcidev(pdev);\r\nif (ioatdca->requester_count == ioatdca->max_requesters)\r\nreturn -ENODEV;\r\nfor (i = 0; i < ioatdca->max_requesters; i++) {\r\nif (ioatdca->req_slots[i].pdev == NULL) {\r\nioatdca->requester_count++;\r\nioatdca->req_slots[i].pdev = pdev;\r\nioatdca->req_slots[i].rid = id;\r\nwritew(id, ioatdca->dca_base + (i * 4));\r\nwriteb(0, ioatdca->dca_base + (i * 4) + 2);\r\nreturn i;\r\n}\r\n}\r\nreturn -EFAULT;\r\n}\r\nstatic int ioat_dca_remove_requester(struct dca_provider *dca,\r\nstruct device *dev)\r\n{\r\nstruct ioat_dca_priv *ioatdca = dca_priv(dca);\r\nstruct pci_dev *pdev;\r\nint i;\r\nif (dev->bus != &pci_bus_type)\r\nreturn -ENODEV;\r\npdev = to_pci_dev(dev);\r\nfor (i = 0; i < ioatdca->max_requesters; i++) {\r\nif (ioatdca->req_slots[i].pdev == pdev) {\r\nwritew(0, ioatdca->dca_base + (i * 4));\r\nioatdca->req_slots[i].pdev = NULL;\r\nioatdca->req_slots[i].rid = 0;\r\nioatdca->requester_count--;\r\nreturn i;\r\n}\r\n}\r\nreturn -ENODEV;\r\n}\r\nstatic u8 ioat_dca_get_tag(struct dca_provider *dca,\r\nstruct device *dev,\r\nint cpu)\r\n{\r\nstruct ioat_dca_priv *ioatdca = dca_priv(dca);\r\nint i, apic_id, bit, value;\r\nu8 entry, tag;\r\ntag = 0;\r\napic_id = cpu_physical_id(cpu);\r\nfor (i = 0; i < IOAT_TAG_MAP_LEN; i++) {\r\nentry = ioatdca->tag_map[i];\r\nif (entry & DCA_TAG_MAP_VALID) {\r\nbit = entry & ~DCA_TAG_MAP_VALID;\r\nvalue = (apic_id & (1 << bit)) ? 1 : 0;\r\n} else {\r\nvalue = entry ? 1 : 0;\r\n}\r\ntag |= (value << i);\r\n}\r\nreturn tag;\r\n}\r\nstatic int ioat_dca_dev_managed(struct dca_provider *dca,\r\nstruct device *dev)\r\n{\r\nstruct ioat_dca_priv *ioatdca = dca_priv(dca);\r\nstruct pci_dev *pdev;\r\nint i;\r\npdev = to_pci_dev(dev);\r\nfor (i = 0; i < ioatdca->max_requesters; i++) {\r\nif (ioatdca->req_slots[i].pdev == pdev)\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstruct dca_provider *ioat_dca_init(struct pci_dev *pdev, void __iomem *iobase)\r\n{\r\nstruct dca_provider *dca;\r\nstruct ioat_dca_priv *ioatdca;\r\nu8 *tag_map = NULL;\r\nint i;\r\nint err;\r\nu8 version;\r\nu8 max_requesters;\r\nif (!system_has_dca_enabled(pdev))\r\nreturn NULL;\r\nswitch (pdev->vendor) {\r\ncase PCI_VENDOR_ID_INTEL:\r\nswitch (pdev->device) {\r\ncase PCI_DEVICE_ID_INTEL_IOAT:\r\ntag_map = ioat_tag_map_BNB;\r\nbreak;\r\ncase PCI_DEVICE_ID_INTEL_IOAT_CNB:\r\ntag_map = ioat_tag_map_CNB;\r\nbreak;\r\ncase PCI_DEVICE_ID_INTEL_IOAT_SCNB:\r\ntag_map = ioat_tag_map_SCNB;\r\nbreak;\r\n}\r\nbreak;\r\ncase PCI_VENDOR_ID_UNISYS:\r\nswitch (pdev->device) {\r\ncase PCI_DEVICE_ID_UNISYS_DMA_DIRECTOR:\r\ntag_map = ioat_tag_map_UNISYS;\r\nbreak;\r\n}\r\nbreak;\r\n}\r\nif (tag_map == NULL)\r\nreturn NULL;\r\nversion = readb(iobase + IOAT_VER_OFFSET);\r\nif (version == IOAT_VER_3_0)\r\nmax_requesters = IOAT3_DCA_MAX_REQ;\r\nelse\r\nmax_requesters = IOAT_DCA_MAX_REQ;\r\ndca = alloc_dca_provider(&ioat_dca_ops,\r\nsizeof(*ioatdca) +\r\n(sizeof(struct ioat_dca_slot) * max_requesters));\r\nif (!dca)\r\nreturn NULL;\r\nioatdca = dca_priv(dca);\r\nioatdca->max_requesters = max_requesters;\r\nioatdca->dca_base = iobase + 0x54;\r\nfor (i = 0; i < IOAT_TAG_MAP_LEN; i++)\r\nioatdca->tag_map[i] = tag_map[i];\r\nerr = register_dca_provider(dca, &pdev->dev);\r\nif (err) {\r\nfree_dca_provider(dca);\r\nreturn NULL;\r\n}\r\nreturn dca;\r\n}\r\nstatic int ioat2_dca_add_requester(struct dca_provider *dca, struct device *dev)\r\n{\r\nstruct ioat_dca_priv *ioatdca = dca_priv(dca);\r\nstruct pci_dev *pdev;\r\nint i;\r\nu16 id;\r\nu16 global_req_table;\r\nif (dev->bus != &pci_bus_type)\r\nreturn -ENODEV;\r\npdev = to_pci_dev(dev);\r\nid = dcaid_from_pcidev(pdev);\r\nif (ioatdca->requester_count == ioatdca->max_requesters)\r\nreturn -ENODEV;\r\nfor (i = 0; i < ioatdca->max_requesters; i++) {\r\nif (ioatdca->req_slots[i].pdev == NULL) {\r\nioatdca->requester_count++;\r\nioatdca->req_slots[i].pdev = pdev;\r\nioatdca->req_slots[i].rid = id;\r\nglobal_req_table =\r\nreadw(ioatdca->dca_base + IOAT_DCA_GREQID_OFFSET);\r\nwritel(id | IOAT_DCA_GREQID_VALID,\r\nioatdca->iobase + global_req_table + (i * 4));\r\nreturn i;\r\n}\r\n}\r\nreturn -EFAULT;\r\n}\r\nstatic int ioat2_dca_remove_requester(struct dca_provider *dca,\r\nstruct device *dev)\r\n{\r\nstruct ioat_dca_priv *ioatdca = dca_priv(dca);\r\nstruct pci_dev *pdev;\r\nint i;\r\nu16 global_req_table;\r\nif (dev->bus != &pci_bus_type)\r\nreturn -ENODEV;\r\npdev = to_pci_dev(dev);\r\nfor (i = 0; i < ioatdca->max_requesters; i++) {\r\nif (ioatdca->req_slots[i].pdev == pdev) {\r\nglobal_req_table =\r\nreadw(ioatdca->dca_base + IOAT_DCA_GREQID_OFFSET);\r\nwritel(0, ioatdca->iobase + global_req_table + (i * 4));\r\nioatdca->req_slots[i].pdev = NULL;\r\nioatdca->req_slots[i].rid = 0;\r\nioatdca->requester_count--;\r\nreturn i;\r\n}\r\n}\r\nreturn -ENODEV;\r\n}\r\nstatic u8 ioat2_dca_get_tag(struct dca_provider *dca,\r\nstruct device *dev,\r\nint cpu)\r\n{\r\nu8 tag;\r\ntag = ioat_dca_get_tag(dca, dev, cpu);\r\ntag = (~tag) & 0x1F;\r\nreturn tag;\r\n}\r\nstatic int ioat2_dca_count_dca_slots(void __iomem *iobase, u16 dca_offset)\r\n{\r\nint slots = 0;\r\nu32 req;\r\nu16 global_req_table;\r\nglobal_req_table = readw(iobase + dca_offset + IOAT_DCA_GREQID_OFFSET);\r\nif (global_req_table == 0)\r\nreturn 0;\r\ndo {\r\nreq = readl(iobase + global_req_table + (slots * sizeof(u32)));\r\nslots++;\r\n} while ((req & IOAT_DCA_GREQID_LASTID) == 0);\r\nreturn slots;\r\n}\r\nstruct dca_provider *ioat2_dca_init(struct pci_dev *pdev, void __iomem *iobase)\r\n{\r\nstruct dca_provider *dca;\r\nstruct ioat_dca_priv *ioatdca;\r\nint slots;\r\nint i;\r\nint err;\r\nu32 tag_map;\r\nu16 dca_offset;\r\nu16 csi_fsb_control;\r\nu16 pcie_control;\r\nu8 bit;\r\nif (!system_has_dca_enabled(pdev))\r\nreturn NULL;\r\ndca_offset = readw(iobase + IOAT_DCAOFFSET_OFFSET);\r\nif (dca_offset == 0)\r\nreturn NULL;\r\nslots = ioat2_dca_count_dca_slots(iobase, dca_offset);\r\nif (slots == 0)\r\nreturn NULL;\r\ndca = alloc_dca_provider(&ioat2_dca_ops,\r\nsizeof(*ioatdca)\r\n+ (sizeof(struct ioat_dca_slot) * slots));\r\nif (!dca)\r\nreturn NULL;\r\nioatdca = dca_priv(dca);\r\nioatdca->iobase = iobase;\r\nioatdca->dca_base = iobase + dca_offset;\r\nioatdca->max_requesters = slots;\r\ncsi_fsb_control = readw(ioatdca->dca_base + IOAT_FSB_CAP_ENABLE_OFFSET);\r\nif ((csi_fsb_control & IOAT_FSB_CAP_ENABLE_PREFETCH) == 0) {\r\ncsi_fsb_control |= IOAT_FSB_CAP_ENABLE_PREFETCH;\r\nwritew(csi_fsb_control,\r\nioatdca->dca_base + IOAT_FSB_CAP_ENABLE_OFFSET);\r\n}\r\npcie_control = readw(ioatdca->dca_base + IOAT_PCI_CAP_ENABLE_OFFSET);\r\nif ((pcie_control & IOAT_PCI_CAP_ENABLE_MEMWR) == 0) {\r\npcie_control |= IOAT_PCI_CAP_ENABLE_MEMWR;\r\nwritew(pcie_control,\r\nioatdca->dca_base + IOAT_PCI_CAP_ENABLE_OFFSET);\r\n}\r\ntag_map = readl(ioatdca->dca_base + IOAT_APICID_TAG_MAP_OFFSET);\r\nfor (i = 0; i < 5; i++) {\r\nbit = (tag_map >> (4 * i)) & 0x0f;\r\nif (bit < 8)\r\nioatdca->tag_map[i] = bit | DCA_TAG_MAP_VALID;\r\nelse\r\nioatdca->tag_map[i] = 0;\r\n}\r\nif (!dca2_tag_map_valid(ioatdca->tag_map)) {\r\nWARN_TAINT_ONCE(1, TAINT_FIRMWARE_WORKAROUND,\r\n"%s %s: APICID_TAG_MAP set incorrectly by BIOS, disabling DCA\n",\r\ndev_driver_string(&pdev->dev),\r\ndev_name(&pdev->dev));\r\nfree_dca_provider(dca);\r\nreturn NULL;\r\n}\r\nerr = register_dca_provider(dca, &pdev->dev);\r\nif (err) {\r\nfree_dca_provider(dca);\r\nreturn NULL;\r\n}\r\nreturn dca;\r\n}\r\nstatic int ioat3_dca_add_requester(struct dca_provider *dca, struct device *dev)\r\n{\r\nstruct ioat_dca_priv *ioatdca = dca_priv(dca);\r\nstruct pci_dev *pdev;\r\nint i;\r\nu16 id;\r\nu16 global_req_table;\r\nif (dev->bus != &pci_bus_type)\r\nreturn -ENODEV;\r\npdev = to_pci_dev(dev);\r\nid = dcaid_from_pcidev(pdev);\r\nif (ioatdca->requester_count == ioatdca->max_requesters)\r\nreturn -ENODEV;\r\nfor (i = 0; i < ioatdca->max_requesters; i++) {\r\nif (ioatdca->req_slots[i].pdev == NULL) {\r\nioatdca->requester_count++;\r\nioatdca->req_slots[i].pdev = pdev;\r\nioatdca->req_slots[i].rid = id;\r\nglobal_req_table =\r\nreadw(ioatdca->dca_base + IOAT3_DCA_GREQID_OFFSET);\r\nwritel(id | IOAT_DCA_GREQID_VALID,\r\nioatdca->iobase + global_req_table + (i * 4));\r\nreturn i;\r\n}\r\n}\r\nreturn -EFAULT;\r\n}\r\nstatic int ioat3_dca_remove_requester(struct dca_provider *dca,\r\nstruct device *dev)\r\n{\r\nstruct ioat_dca_priv *ioatdca = dca_priv(dca);\r\nstruct pci_dev *pdev;\r\nint i;\r\nu16 global_req_table;\r\nif (dev->bus != &pci_bus_type)\r\nreturn -ENODEV;\r\npdev = to_pci_dev(dev);\r\nfor (i = 0; i < ioatdca->max_requesters; i++) {\r\nif (ioatdca->req_slots[i].pdev == pdev) {\r\nglobal_req_table =\r\nreadw(ioatdca->dca_base + IOAT3_DCA_GREQID_OFFSET);\r\nwritel(0, ioatdca->iobase + global_req_table + (i * 4));\r\nioatdca->req_slots[i].pdev = NULL;\r\nioatdca->req_slots[i].rid = 0;\r\nioatdca->requester_count--;\r\nreturn i;\r\n}\r\n}\r\nreturn -ENODEV;\r\n}\r\nstatic u8 ioat3_dca_get_tag(struct dca_provider *dca,\r\nstruct device *dev,\r\nint cpu)\r\n{\r\nu8 tag;\r\nstruct ioat_dca_priv *ioatdca = dca_priv(dca);\r\nint i, apic_id, bit, value;\r\nu8 entry;\r\ntag = 0;\r\napic_id = cpu_physical_id(cpu);\r\nfor (i = 0; i < IOAT_TAG_MAP_LEN; i++) {\r\nentry = ioatdca->tag_map[i];\r\nif (entry & DCA3_TAG_MAP_BIT_TO_SEL) {\r\nbit = entry &\r\n~(DCA3_TAG_MAP_BIT_TO_SEL | DCA3_TAG_MAP_BIT_TO_INV);\r\nvalue = (apic_id & (1 << bit)) ? 1 : 0;\r\n} else if (entry & DCA3_TAG_MAP_BIT_TO_INV) {\r\nbit = entry & ~DCA3_TAG_MAP_BIT_TO_INV;\r\nvalue = (apic_id & (1 << bit)) ? 0 : 1;\r\n} else {\r\nvalue = (entry & DCA3_TAG_MAP_LITERAL_VAL) ? 1 : 0;\r\n}\r\ntag |= (value << i);\r\n}\r\nreturn tag;\r\n}\r\nstatic int ioat3_dca_count_dca_slots(void *iobase, u16 dca_offset)\r\n{\r\nint slots = 0;\r\nu32 req;\r\nu16 global_req_table;\r\nglobal_req_table = readw(iobase + dca_offset + IOAT3_DCA_GREQID_OFFSET);\r\nif (global_req_table == 0)\r\nreturn 0;\r\ndo {\r\nreq = readl(iobase + global_req_table + (slots * sizeof(u32)));\r\nslots++;\r\n} while ((req & IOAT_DCA_GREQID_LASTID) == 0);\r\nreturn slots;\r\n}\r\nstatic inline int dca3_tag_map_invalid(u8 *tag_map)\r\n{\r\nreturn ((tag_map[0] == DCA_TAG_MAP_VALID) &&\r\n(tag_map[1] == DCA_TAG_MAP_VALID) &&\r\n(tag_map[2] == DCA_TAG_MAP_VALID) &&\r\n(tag_map[3] == DCA_TAG_MAP_VALID) &&\r\n(tag_map[4] == DCA_TAG_MAP_VALID));\r\n}\r\nstruct dca_provider *ioat3_dca_init(struct pci_dev *pdev, void __iomem *iobase)\r\n{\r\nstruct dca_provider *dca;\r\nstruct ioat_dca_priv *ioatdca;\r\nint slots;\r\nint i;\r\nint err;\r\nu16 dca_offset;\r\nu16 csi_fsb_control;\r\nu16 pcie_control;\r\nu8 bit;\r\nunion {\r\nu64 full;\r\nstruct {\r\nu32 low;\r\nu32 high;\r\n};\r\n} tag_map;\r\nif (!system_has_dca_enabled(pdev))\r\nreturn NULL;\r\ndca_offset = readw(iobase + IOAT_DCAOFFSET_OFFSET);\r\nif (dca_offset == 0)\r\nreturn NULL;\r\nslots = ioat3_dca_count_dca_slots(iobase, dca_offset);\r\nif (slots == 0)\r\nreturn NULL;\r\ndca = alloc_dca_provider(&ioat3_dca_ops,\r\nsizeof(*ioatdca)\r\n+ (sizeof(struct ioat_dca_slot) * slots));\r\nif (!dca)\r\nreturn NULL;\r\nioatdca = dca_priv(dca);\r\nioatdca->iobase = iobase;\r\nioatdca->dca_base = iobase + dca_offset;\r\nioatdca->max_requesters = slots;\r\ncsi_fsb_control = readw(ioatdca->dca_base + IOAT3_CSI_CONTROL_OFFSET);\r\nif ((csi_fsb_control & IOAT3_CSI_CONTROL_PREFETCH) == 0) {\r\ncsi_fsb_control |= IOAT3_CSI_CONTROL_PREFETCH;\r\nwritew(csi_fsb_control,\r\nioatdca->dca_base + IOAT3_CSI_CONTROL_OFFSET);\r\n}\r\npcie_control = readw(ioatdca->dca_base + IOAT3_PCI_CONTROL_OFFSET);\r\nif ((pcie_control & IOAT3_PCI_CONTROL_MEMWR) == 0) {\r\npcie_control |= IOAT3_PCI_CONTROL_MEMWR;\r\nwritew(pcie_control,\r\nioatdca->dca_base + IOAT3_PCI_CONTROL_OFFSET);\r\n}\r\ntag_map.low =\r\nreadl(ioatdca->dca_base + IOAT3_APICID_TAG_MAP_OFFSET_LOW);\r\ntag_map.high =\r\nreadl(ioatdca->dca_base + IOAT3_APICID_TAG_MAP_OFFSET_HIGH);\r\nfor (i = 0; i < 8; i++) {\r\nbit = tag_map.full >> (8 * i);\r\nioatdca->tag_map[i] = bit & DCA_TAG_MAP_MASK;\r\n}\r\nif (dca3_tag_map_invalid(ioatdca->tag_map)) {\r\nWARN_TAINT_ONCE(1, TAINT_FIRMWARE_WORKAROUND,\r\n"%s %s: APICID_TAG_MAP set incorrectly by BIOS, disabling DCA\n",\r\ndev_driver_string(&pdev->dev),\r\ndev_name(&pdev->dev));\r\nfree_dca_provider(dca);\r\nreturn NULL;\r\n}\r\nerr = register_dca_provider(dca, &pdev->dev);\r\nif (err) {\r\nfree_dca_provider(dca);\r\nreturn NULL;\r\n}\r\nreturn dca;\r\n}
