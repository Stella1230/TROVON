static int chainiv_givencrypt(struct skcipher_givcrypt_request *req)\r\n{\r\nstruct crypto_ablkcipher *geniv = skcipher_givcrypt_reqtfm(req);\r\nstruct chainiv_ctx *ctx = crypto_ablkcipher_ctx(geniv);\r\nstruct ablkcipher_request *subreq = skcipher_givcrypt_reqctx(req);\r\nunsigned int ivsize;\r\nint err;\r\nablkcipher_request_set_tfm(subreq, skcipher_geniv_cipher(geniv));\r\nablkcipher_request_set_callback(subreq, req->creq.base.flags &\r\n~CRYPTO_TFM_REQ_MAY_SLEEP,\r\nreq->creq.base.complete,\r\nreq->creq.base.data);\r\nablkcipher_request_set_crypt(subreq, req->creq.src, req->creq.dst,\r\nreq->creq.nbytes, req->creq.info);\r\nspin_lock_bh(&ctx->lock);\r\nivsize = crypto_ablkcipher_ivsize(geniv);\r\nmemcpy(req->giv, ctx->iv, ivsize);\r\nmemcpy(subreq->info, ctx->iv, ivsize);\r\nerr = crypto_ablkcipher_encrypt(subreq);\r\nif (err)\r\ngoto unlock;\r\nmemcpy(ctx->iv, subreq->info, ivsize);\r\nunlock:\r\nspin_unlock_bh(&ctx->lock);\r\nreturn err;\r\n}\r\nstatic int chainiv_givencrypt_first(struct skcipher_givcrypt_request *req)\r\n{\r\nstruct crypto_ablkcipher *geniv = skcipher_givcrypt_reqtfm(req);\r\nstruct chainiv_ctx *ctx = crypto_ablkcipher_ctx(geniv);\r\nint err = 0;\r\nspin_lock_bh(&ctx->lock);\r\nif (crypto_ablkcipher_crt(geniv)->givencrypt !=\r\nchainiv_givencrypt_first)\r\ngoto unlock;\r\ncrypto_ablkcipher_crt(geniv)->givencrypt = chainiv_givencrypt;\r\nerr = crypto_rng_get_bytes(crypto_default_rng, ctx->iv,\r\ncrypto_ablkcipher_ivsize(geniv));\r\nunlock:\r\nspin_unlock_bh(&ctx->lock);\r\nif (err)\r\nreturn err;\r\nreturn chainiv_givencrypt(req);\r\n}\r\nstatic int chainiv_init_common(struct crypto_tfm *tfm)\r\n{\r\ntfm->crt_ablkcipher.reqsize = sizeof(struct ablkcipher_request);\r\nreturn skcipher_geniv_init(tfm);\r\n}\r\nstatic int chainiv_init(struct crypto_tfm *tfm)\r\n{\r\nstruct chainiv_ctx *ctx = crypto_tfm_ctx(tfm);\r\nspin_lock_init(&ctx->lock);\r\nreturn chainiv_init_common(tfm);\r\n}\r\nstatic int async_chainiv_schedule_work(struct async_chainiv_ctx *ctx)\r\n{\r\nint queued;\r\nint err = ctx->err;\r\nif (!ctx->queue.qlen) {\r\nsmp_mb__before_clear_bit();\r\nclear_bit(CHAINIV_STATE_INUSE, &ctx->state);\r\nif (!ctx->queue.qlen ||\r\ntest_and_set_bit(CHAINIV_STATE_INUSE, &ctx->state))\r\ngoto out;\r\n}\r\nqueued = queue_work(kcrypto_wq, &ctx->postponed);\r\nBUG_ON(!queued);\r\nout:\r\nreturn err;\r\n}\r\nstatic int async_chainiv_postpone_request(struct skcipher_givcrypt_request *req)\r\n{\r\nstruct crypto_ablkcipher *geniv = skcipher_givcrypt_reqtfm(req);\r\nstruct async_chainiv_ctx *ctx = crypto_ablkcipher_ctx(geniv);\r\nint err;\r\nspin_lock_bh(&ctx->lock);\r\nerr = skcipher_enqueue_givcrypt(&ctx->queue, req);\r\nspin_unlock_bh(&ctx->lock);\r\nif (test_and_set_bit(CHAINIV_STATE_INUSE, &ctx->state))\r\nreturn err;\r\nctx->err = err;\r\nreturn async_chainiv_schedule_work(ctx);\r\n}\r\nstatic int async_chainiv_givencrypt_tail(struct skcipher_givcrypt_request *req)\r\n{\r\nstruct crypto_ablkcipher *geniv = skcipher_givcrypt_reqtfm(req);\r\nstruct async_chainiv_ctx *ctx = crypto_ablkcipher_ctx(geniv);\r\nstruct ablkcipher_request *subreq = skcipher_givcrypt_reqctx(req);\r\nunsigned int ivsize = crypto_ablkcipher_ivsize(geniv);\r\nmemcpy(req->giv, ctx->iv, ivsize);\r\nmemcpy(subreq->info, ctx->iv, ivsize);\r\nctx->err = crypto_ablkcipher_encrypt(subreq);\r\nif (ctx->err)\r\ngoto out;\r\nmemcpy(ctx->iv, subreq->info, ivsize);\r\nout:\r\nreturn async_chainiv_schedule_work(ctx);\r\n}\r\nstatic int async_chainiv_givencrypt(struct skcipher_givcrypt_request *req)\r\n{\r\nstruct crypto_ablkcipher *geniv = skcipher_givcrypt_reqtfm(req);\r\nstruct async_chainiv_ctx *ctx = crypto_ablkcipher_ctx(geniv);\r\nstruct ablkcipher_request *subreq = skcipher_givcrypt_reqctx(req);\r\nablkcipher_request_set_tfm(subreq, skcipher_geniv_cipher(geniv));\r\nablkcipher_request_set_callback(subreq, req->creq.base.flags,\r\nreq->creq.base.complete,\r\nreq->creq.base.data);\r\nablkcipher_request_set_crypt(subreq, req->creq.src, req->creq.dst,\r\nreq->creq.nbytes, req->creq.info);\r\nif (test_and_set_bit(CHAINIV_STATE_INUSE, &ctx->state))\r\ngoto postpone;\r\nif (ctx->queue.qlen) {\r\nclear_bit(CHAINIV_STATE_INUSE, &ctx->state);\r\ngoto postpone;\r\n}\r\nreturn async_chainiv_givencrypt_tail(req);\r\npostpone:\r\nreturn async_chainiv_postpone_request(req);\r\n}\r\nstatic int async_chainiv_givencrypt_first(struct skcipher_givcrypt_request *req)\r\n{\r\nstruct crypto_ablkcipher *geniv = skcipher_givcrypt_reqtfm(req);\r\nstruct async_chainiv_ctx *ctx = crypto_ablkcipher_ctx(geniv);\r\nint err = 0;\r\nif (test_and_set_bit(CHAINIV_STATE_INUSE, &ctx->state))\r\ngoto out;\r\nif (crypto_ablkcipher_crt(geniv)->givencrypt !=\r\nasync_chainiv_givencrypt_first)\r\ngoto unlock;\r\ncrypto_ablkcipher_crt(geniv)->givencrypt = async_chainiv_givencrypt;\r\nerr = crypto_rng_get_bytes(crypto_default_rng, ctx->iv,\r\ncrypto_ablkcipher_ivsize(geniv));\r\nunlock:\r\nclear_bit(CHAINIV_STATE_INUSE, &ctx->state);\r\nif (err)\r\nreturn err;\r\nout:\r\nreturn async_chainiv_givencrypt(req);\r\n}\r\nstatic void async_chainiv_do_postponed(struct work_struct *work)\r\n{\r\nstruct async_chainiv_ctx *ctx = container_of(work,\r\nstruct async_chainiv_ctx,\r\npostponed);\r\nstruct skcipher_givcrypt_request *req;\r\nstruct ablkcipher_request *subreq;\r\nint err;\r\nspin_lock_bh(&ctx->lock);\r\nreq = skcipher_dequeue_givcrypt(&ctx->queue);\r\nspin_unlock_bh(&ctx->lock);\r\nif (!req) {\r\nasync_chainiv_schedule_work(ctx);\r\nreturn;\r\n}\r\nsubreq = skcipher_givcrypt_reqctx(req);\r\nsubreq->base.flags |= CRYPTO_TFM_REQ_MAY_SLEEP;\r\nerr = async_chainiv_givencrypt_tail(req);\r\nlocal_bh_disable();\r\nskcipher_givcrypt_complete(req, err);\r\nlocal_bh_enable();\r\n}\r\nstatic int async_chainiv_init(struct crypto_tfm *tfm)\r\n{\r\nstruct async_chainiv_ctx *ctx = crypto_tfm_ctx(tfm);\r\nspin_lock_init(&ctx->lock);\r\ncrypto_init_queue(&ctx->queue, 100);\r\nINIT_WORK(&ctx->postponed, async_chainiv_do_postponed);\r\nreturn chainiv_init_common(tfm);\r\n}\r\nstatic void async_chainiv_exit(struct crypto_tfm *tfm)\r\n{\r\nstruct async_chainiv_ctx *ctx = crypto_tfm_ctx(tfm);\r\nBUG_ON(test_bit(CHAINIV_STATE_INUSE, &ctx->state) || ctx->queue.qlen);\r\nskcipher_geniv_exit(tfm);\r\n}\r\nstatic struct crypto_instance *chainiv_alloc(struct rtattr **tb)\r\n{\r\nstruct crypto_attr_type *algt;\r\nstruct crypto_instance *inst;\r\nint err;\r\nalgt = crypto_get_attr_type(tb);\r\nif (IS_ERR(algt))\r\nreturn ERR_CAST(algt);\r\nerr = crypto_get_default_rng();\r\nif (err)\r\nreturn ERR_PTR(err);\r\ninst = skcipher_geniv_alloc(&chainiv_tmpl, tb, 0, 0);\r\nif (IS_ERR(inst))\r\ngoto put_rng;\r\ninst->alg.cra_ablkcipher.givencrypt = chainiv_givencrypt_first;\r\ninst->alg.cra_init = chainiv_init;\r\ninst->alg.cra_exit = skcipher_geniv_exit;\r\ninst->alg.cra_ctxsize = sizeof(struct chainiv_ctx);\r\nif (!crypto_requires_sync(algt->type, algt->mask)) {\r\ninst->alg.cra_flags |= CRYPTO_ALG_ASYNC;\r\ninst->alg.cra_ablkcipher.givencrypt =\r\nasync_chainiv_givencrypt_first;\r\ninst->alg.cra_init = async_chainiv_init;\r\ninst->alg.cra_exit = async_chainiv_exit;\r\ninst->alg.cra_ctxsize = sizeof(struct async_chainiv_ctx);\r\n}\r\ninst->alg.cra_ctxsize += inst->alg.cra_ablkcipher.ivsize;\r\nout:\r\nreturn inst;\r\nput_rng:\r\ncrypto_put_default_rng();\r\ngoto out;\r\n}\r\nstatic void chainiv_free(struct crypto_instance *inst)\r\n{\r\nskcipher_geniv_free(inst);\r\ncrypto_put_default_rng();\r\n}\r\nstatic int __init chainiv_module_init(void)\r\n{\r\nreturn crypto_register_template(&chainiv_tmpl);\r\n}\r\nstatic void chainiv_module_exit(void)\r\n{\r\ncrypto_unregister_template(&chainiv_tmpl);\r\n}
