void\r\nlpfc_terminate_rport_io(struct fc_rport *rport)\r\n{\r\nstruct lpfc_rport_data *rdata;\r\nstruct lpfc_nodelist * ndlp;\r\nstruct lpfc_hba *phba;\r\nrdata = rport->dd_data;\r\nndlp = rdata->pnode;\r\nif (!ndlp || !NLP_CHK_NODE_ACT(ndlp)) {\r\nif (rport->roles & FC_RPORT_ROLE_FCP_TARGET)\r\nprintk(KERN_ERR "Cannot find remote node"\r\n" to terminate I/O Data x%x\n",\r\nrport->port_id);\r\nreturn;\r\n}\r\nphba = ndlp->phba;\r\nlpfc_debugfs_disc_trc(ndlp->vport, LPFC_DISC_TRC_RPORT,\r\n"rport terminate: sid:x%x did:x%x flg:x%x",\r\nndlp->nlp_sid, ndlp->nlp_DID, ndlp->nlp_flag);\r\nif (ndlp->nlp_sid != NLP_NO_SID) {\r\nlpfc_sli_abort_iocb(ndlp->vport,\r\n&phba->sli.ring[phba->sli.fcp_ring],\r\nndlp->nlp_sid, 0, LPFC_CTX_TGT);\r\n}\r\n}\r\nvoid\r\nlpfc_dev_loss_tmo_callbk(struct fc_rport *rport)\r\n{\r\nstruct lpfc_rport_data *rdata;\r\nstruct lpfc_nodelist * ndlp;\r\nstruct lpfc_vport *vport;\r\nstruct lpfc_hba *phba;\r\nstruct lpfc_work_evt *evtp;\r\nint put_node;\r\nint put_rport;\r\nrdata = rport->dd_data;\r\nndlp = rdata->pnode;\r\nif (!ndlp || !NLP_CHK_NODE_ACT(ndlp))\r\nreturn;\r\nvport = ndlp->vport;\r\nphba = vport->phba;\r\nlpfc_debugfs_disc_trc(vport, LPFC_DISC_TRC_RPORT,\r\n"rport devlosscb: sid:x%x did:x%x flg:x%x",\r\nndlp->nlp_sid, ndlp->nlp_DID, ndlp->nlp_flag);\r\nlpfc_printf_vlog(ndlp->vport, KERN_INFO, LOG_NODE,\r\n"3181 dev_loss_callbk x%06x, rport %p flg x%x\n",\r\nndlp->nlp_DID, ndlp->rport, ndlp->nlp_flag);\r\nif (vport->load_flag & FC_UNLOADING) {\r\nput_node = rdata->pnode != NULL;\r\nput_rport = ndlp->rport != NULL;\r\nrdata->pnode = NULL;\r\nndlp->rport = NULL;\r\nif (put_node)\r\nlpfc_nlp_put(ndlp);\r\nif (put_rport)\r\nput_device(&rport->dev);\r\nreturn;\r\n}\r\nif (ndlp->nlp_state == NLP_STE_MAPPED_NODE)\r\nreturn;\r\nif (ndlp->nlp_type & NLP_FABRIC) {\r\nif (rport->port_name != wwn_to_u64(ndlp->nlp_portname.u.wwn)) {\r\nput_device(&rport->dev);\r\nreturn;\r\n}\r\n}\r\nevtp = &ndlp->dev_loss_evt;\r\nif (!list_empty(&evtp->evt_listp))\r\nreturn;\r\nevtp->evt_arg1 = lpfc_nlp_get(ndlp);\r\nspin_lock_irq(&phba->hbalock);\r\nif (evtp->evt_arg1) {\r\nevtp->evt = LPFC_EVT_DEV_LOSS;\r\nlist_add_tail(&evtp->evt_listp, &phba->work_list);\r\nlpfc_worker_wake_up(phba);\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn;\r\n}\r\nstatic int\r\nlpfc_dev_loss_tmo_handler(struct lpfc_nodelist *ndlp)\r\n{\r\nstruct lpfc_rport_data *rdata;\r\nstruct fc_rport *rport;\r\nstruct lpfc_vport *vport;\r\nstruct lpfc_hba *phba;\r\nuint8_t *name;\r\nint put_node;\r\nint put_rport;\r\nint warn_on = 0;\r\nint fcf_inuse = 0;\r\nrport = ndlp->rport;\r\nif (!rport)\r\nreturn fcf_inuse;\r\nrdata = rport->dd_data;\r\nname = (uint8_t *) &ndlp->nlp_portname;\r\nvport = ndlp->vport;\r\nphba = vport->phba;\r\nif (phba->sli_rev == LPFC_SLI_REV4)\r\nfcf_inuse = lpfc_fcf_inuse(phba);\r\nlpfc_debugfs_disc_trc(vport, LPFC_DISC_TRC_RPORT,\r\n"rport devlosstmo:did:x%x type:x%x id:x%x",\r\nndlp->nlp_DID, ndlp->nlp_type, rport->scsi_target_id);\r\nlpfc_printf_vlog(ndlp->vport, KERN_INFO, LOG_NODE,\r\n"3182 dev_loss_tmo_handler x%06x, rport %p flg x%x\n",\r\nndlp->nlp_DID, ndlp->rport, ndlp->nlp_flag);\r\nif (vport->load_flag & FC_UNLOADING) {\r\nif (ndlp->nlp_sid != NLP_NO_SID) {\r\nlpfc_sli_abort_iocb(vport,\r\n&phba->sli.ring[phba->sli.fcp_ring],\r\nndlp->nlp_sid, 0, LPFC_CTX_TGT);\r\n}\r\nput_node = rdata->pnode != NULL;\r\nput_rport = ndlp->rport != NULL;\r\nrdata->pnode = NULL;\r\nndlp->rport = NULL;\r\nif (put_node)\r\nlpfc_nlp_put(ndlp);\r\nif (put_rport)\r\nput_device(&rport->dev);\r\nreturn fcf_inuse;\r\n}\r\nif (ndlp->nlp_state == NLP_STE_MAPPED_NODE) {\r\nlpfc_printf_vlog(vport, KERN_INFO, LOG_DISCOVERY,\r\n"0284 Devloss timeout Ignored on "\r\n"WWPN %x:%x:%x:%x:%x:%x:%x:%x "\r\n"NPort x%x\n",\r\n*name, *(name+1), *(name+2), *(name+3),\r\n*(name+4), *(name+5), *(name+6), *(name+7),\r\nndlp->nlp_DID);\r\nreturn fcf_inuse;\r\n}\r\nif (ndlp->nlp_type & NLP_FABRIC) {\r\nput_node = rdata->pnode != NULL;\r\nput_rport = ndlp->rport != NULL;\r\nrdata->pnode = NULL;\r\nndlp->rport = NULL;\r\nif (put_node)\r\nlpfc_nlp_put(ndlp);\r\nif (put_rport)\r\nput_device(&rport->dev);\r\nreturn fcf_inuse;\r\n}\r\nif (ndlp->nlp_sid != NLP_NO_SID) {\r\nwarn_on = 1;\r\nlpfc_sli_abort_iocb(vport, &phba->sli.ring[phba->sli.fcp_ring],\r\nndlp->nlp_sid, 0, LPFC_CTX_TGT);\r\n}\r\nif (warn_on) {\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_DISCOVERY,\r\n"0203 Devloss timeout on "\r\n"WWPN %02x:%02x:%02x:%02x:%02x:%02x:%02x:%02x "\r\n"NPort x%06x Data: x%x x%x x%x\n",\r\n*name, *(name+1), *(name+2), *(name+3),\r\n*(name+4), *(name+5), *(name+6), *(name+7),\r\nndlp->nlp_DID, ndlp->nlp_flag,\r\nndlp->nlp_state, ndlp->nlp_rpi);\r\n} else {\r\nlpfc_printf_vlog(vport, KERN_INFO, LOG_DISCOVERY,\r\n"0204 Devloss timeout on "\r\n"WWPN %02x:%02x:%02x:%02x:%02x:%02x:%02x:%02x "\r\n"NPort x%06x Data: x%x x%x x%x\n",\r\n*name, *(name+1), *(name+2), *(name+3),\r\n*(name+4), *(name+5), *(name+6), *(name+7),\r\nndlp->nlp_DID, ndlp->nlp_flag,\r\nndlp->nlp_state, ndlp->nlp_rpi);\r\n}\r\nput_node = rdata->pnode != NULL;\r\nput_rport = ndlp->rport != NULL;\r\nrdata->pnode = NULL;\r\nndlp->rport = NULL;\r\nif (put_node)\r\nlpfc_nlp_put(ndlp);\r\nif (put_rport)\r\nput_device(&rport->dev);\r\nif (!(vport->load_flag & FC_UNLOADING) &&\r\n!(ndlp->nlp_flag & NLP_DELAY_TMO) &&\r\n!(ndlp->nlp_flag & NLP_NPR_2B_DISC) &&\r\n(ndlp->nlp_state != NLP_STE_UNMAPPED_NODE) &&\r\n(ndlp->nlp_state != NLP_STE_REG_LOGIN_ISSUE) &&\r\n(ndlp->nlp_state != NLP_STE_PRLI_ISSUE))\r\nlpfc_disc_state_machine(vport, ndlp, NULL, NLP_EVT_DEVICE_RM);\r\nreturn fcf_inuse;\r\n}\r\nstatic void\r\nlpfc_sli4_post_dev_loss_tmo_handler(struct lpfc_hba *phba, int fcf_inuse,\r\nuint32_t nlp_did)\r\n{\r\nif (!fcf_inuse)\r\nreturn;\r\nif ((phba->hba_flag & HBA_FIP_SUPPORT) && !lpfc_fcf_inuse(phba)) {\r\nspin_lock_irq(&phba->hbalock);\r\nif (phba->fcf.fcf_flag & FCF_DISCOVERY) {\r\nif (phba->hba_flag & HBA_DEVLOSS_TMO) {\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn;\r\n}\r\nphba->hba_flag |= HBA_DEVLOSS_TMO;\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2847 Last remote node (x%x) using "\r\n"FCF devloss tmo\n", nlp_did);\r\n}\r\nif (phba->fcf.fcf_flag & FCF_REDISC_PROG) {\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2868 Devloss tmo to FCF rediscovery "\r\n"in progress\n");\r\nreturn;\r\n}\r\nif (!(phba->hba_flag & (FCF_TS_INPROG | FCF_RR_INPROG))) {\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2869 Devloss tmo to idle FIP engine, "\r\n"unreg in-use FCF and rescan.\n");\r\nlpfc_unregister_fcf_rescan(phba);\r\nreturn;\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\nif (phba->hba_flag & FCF_TS_INPROG)\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2870 FCF table scan in progress\n");\r\nif (phba->hba_flag & FCF_RR_INPROG)\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2871 FLOGI roundrobin FCF failover "\r\n"in progress\n");\r\n}\r\nlpfc_unregister_unused_fcf(phba);\r\n}\r\nstruct lpfc_fast_path_event *\r\nlpfc_alloc_fast_evt(struct lpfc_hba *phba) {\r\nstruct lpfc_fast_path_event *ret;\r\nif (atomic_read(&phba->fast_event_count) > LPFC_MAX_EVT_COUNT)\r\nreturn NULL;\r\nret = kzalloc(sizeof(struct lpfc_fast_path_event),\r\nGFP_ATOMIC);\r\nif (ret) {\r\natomic_inc(&phba->fast_event_count);\r\nINIT_LIST_HEAD(&ret->work_evt.evt_listp);\r\nret->work_evt.evt = LPFC_EVT_FASTPATH_MGMT_EVT;\r\n}\r\nreturn ret;\r\n}\r\nvoid\r\nlpfc_free_fast_evt(struct lpfc_hba *phba,\r\nstruct lpfc_fast_path_event *evt) {\r\natomic_dec(&phba->fast_event_count);\r\nkfree(evt);\r\n}\r\nstatic void\r\nlpfc_send_fastpath_evt(struct lpfc_hba *phba,\r\nstruct lpfc_work_evt *evtp)\r\n{\r\nunsigned long evt_category, evt_sub_category;\r\nstruct lpfc_fast_path_event *fast_evt_data;\r\nchar *evt_data;\r\nuint32_t evt_data_size;\r\nstruct Scsi_Host *shost;\r\nfast_evt_data = container_of(evtp, struct lpfc_fast_path_event,\r\nwork_evt);\r\nevt_category = (unsigned long) fast_evt_data->un.fabric_evt.event_type;\r\nevt_sub_category = (unsigned long) fast_evt_data->un.\r\nfabric_evt.subcategory;\r\nshost = lpfc_shost_from_vport(fast_evt_data->vport);\r\nif (evt_category == FC_REG_FABRIC_EVENT) {\r\nif (evt_sub_category == LPFC_EVENT_FCPRDCHKERR) {\r\nevt_data = (char *) &fast_evt_data->un.read_check_error;\r\nevt_data_size = sizeof(fast_evt_data->un.\r\nread_check_error);\r\n} else if ((evt_sub_category == LPFC_EVENT_FABRIC_BUSY) ||\r\n(evt_sub_category == LPFC_EVENT_PORT_BUSY)) {\r\nevt_data = (char *) &fast_evt_data->un.fabric_evt;\r\nevt_data_size = sizeof(fast_evt_data->un.fabric_evt);\r\n} else {\r\nlpfc_free_fast_evt(phba, fast_evt_data);\r\nreturn;\r\n}\r\n} else if (evt_category == FC_REG_SCSI_EVENT) {\r\nswitch (evt_sub_category) {\r\ncase LPFC_EVENT_QFULL:\r\ncase LPFC_EVENT_DEVBSY:\r\nevt_data = (char *) &fast_evt_data->un.scsi_evt;\r\nevt_data_size = sizeof(fast_evt_data->un.scsi_evt);\r\nbreak;\r\ncase LPFC_EVENT_CHECK_COND:\r\nevt_data = (char *) &fast_evt_data->un.check_cond_evt;\r\nevt_data_size = sizeof(fast_evt_data->un.\r\ncheck_cond_evt);\r\nbreak;\r\ncase LPFC_EVENT_VARQUEDEPTH:\r\nevt_data = (char *) &fast_evt_data->un.queue_depth_evt;\r\nevt_data_size = sizeof(fast_evt_data->un.\r\nqueue_depth_evt);\r\nbreak;\r\ndefault:\r\nlpfc_free_fast_evt(phba, fast_evt_data);\r\nreturn;\r\n}\r\n} else {\r\nlpfc_free_fast_evt(phba, fast_evt_data);\r\nreturn;\r\n}\r\nfc_host_post_vendor_event(shost,\r\nfc_get_event_number(),\r\nevt_data_size,\r\nevt_data,\r\nLPFC_NL_VENDOR_ID);\r\nlpfc_free_fast_evt(phba, fast_evt_data);\r\nreturn;\r\n}\r\nstatic void\r\nlpfc_work_list_done(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_work_evt *evtp = NULL;\r\nstruct lpfc_nodelist *ndlp;\r\nint free_evt;\r\nint fcf_inuse;\r\nuint32_t nlp_did;\r\nspin_lock_irq(&phba->hbalock);\r\nwhile (!list_empty(&phba->work_list)) {\r\nlist_remove_head((&phba->work_list), evtp, typeof(*evtp),\r\nevt_listp);\r\nspin_unlock_irq(&phba->hbalock);\r\nfree_evt = 1;\r\nswitch (evtp->evt) {\r\ncase LPFC_EVT_ELS_RETRY:\r\nndlp = (struct lpfc_nodelist *) (evtp->evt_arg1);\r\nlpfc_els_retry_delay_handler(ndlp);\r\nfree_evt = 0;\r\nlpfc_nlp_put(ndlp);\r\nbreak;\r\ncase LPFC_EVT_DEV_LOSS:\r\nndlp = (struct lpfc_nodelist *)(evtp->evt_arg1);\r\nfcf_inuse = lpfc_dev_loss_tmo_handler(ndlp);\r\nfree_evt = 0;\r\nnlp_did = ndlp->nlp_DID;\r\nlpfc_nlp_put(ndlp);\r\nif (phba->sli_rev == LPFC_SLI_REV4)\r\nlpfc_sli4_post_dev_loss_tmo_handler(phba,\r\nfcf_inuse,\r\nnlp_did);\r\nbreak;\r\ncase LPFC_EVT_ONLINE:\r\nif (phba->link_state < LPFC_LINK_DOWN)\r\n*(int *) (evtp->evt_arg1) = lpfc_online(phba);\r\nelse\r\n*(int *) (evtp->evt_arg1) = 0;\r\ncomplete((struct completion *)(evtp->evt_arg2));\r\nbreak;\r\ncase LPFC_EVT_OFFLINE_PREP:\r\nif (phba->link_state >= LPFC_LINK_DOWN)\r\nlpfc_offline_prep(phba, LPFC_MBX_WAIT);\r\n*(int *)(evtp->evt_arg1) = 0;\r\ncomplete((struct completion *)(evtp->evt_arg2));\r\nbreak;\r\ncase LPFC_EVT_OFFLINE:\r\nlpfc_offline(phba);\r\nlpfc_sli_brdrestart(phba);\r\n*(int *)(evtp->evt_arg1) =\r\nlpfc_sli_brdready(phba, HS_FFRDY | HS_MBRDY);\r\nlpfc_unblock_mgmt_io(phba);\r\ncomplete((struct completion *)(evtp->evt_arg2));\r\nbreak;\r\ncase LPFC_EVT_WARM_START:\r\nlpfc_offline(phba);\r\nlpfc_reset_barrier(phba);\r\nlpfc_sli_brdreset(phba);\r\nlpfc_hba_down_post(phba);\r\n*(int *)(evtp->evt_arg1) =\r\nlpfc_sli_brdready(phba, HS_MBRDY);\r\nlpfc_unblock_mgmt_io(phba);\r\ncomplete((struct completion *)(evtp->evt_arg2));\r\nbreak;\r\ncase LPFC_EVT_KILL:\r\nlpfc_offline(phba);\r\n*(int *)(evtp->evt_arg1)\r\n= (phba->pport->stopped)\r\n? 0 : lpfc_sli_brdkill(phba);\r\nlpfc_unblock_mgmt_io(phba);\r\ncomplete((struct completion *)(evtp->evt_arg2));\r\nbreak;\r\ncase LPFC_EVT_FASTPATH_MGMT_EVT:\r\nlpfc_send_fastpath_evt(phba, evtp);\r\nfree_evt = 0;\r\nbreak;\r\ncase LPFC_EVT_RESET_HBA:\r\nif (!(phba->pport->load_flag & FC_UNLOADING))\r\nlpfc_reset_hba(phba);\r\nbreak;\r\n}\r\nif (free_evt)\r\nkfree(evtp);\r\nspin_lock_irq(&phba->hbalock);\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\n}\r\nstatic void\r\nlpfc_work_done(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_sli_ring *pring;\r\nuint32_t ha_copy, status, control, work_port_events;\r\nstruct lpfc_vport **vports;\r\nstruct lpfc_vport *vport;\r\nint i;\r\nspin_lock_irq(&phba->hbalock);\r\nha_copy = phba->work_ha;\r\nphba->work_ha = 0;\r\nspin_unlock_irq(&phba->hbalock);\r\nif (phba->pci_dev_grp == LPFC_PCI_DEV_OC)\r\nlpfc_sli4_post_async_mbox(phba);\r\nif (ha_copy & HA_ERATT)\r\nlpfc_handle_eratt(phba);\r\nif (ha_copy & HA_MBATT)\r\nlpfc_sli_handle_mb_event(phba);\r\nif (ha_copy & HA_LATT)\r\nlpfc_handle_latt(phba);\r\nif (phba->pci_dev_grp == LPFC_PCI_DEV_OC) {\r\nif (phba->hba_flag & HBA_RRQ_ACTIVE)\r\nlpfc_handle_rrq_active(phba);\r\nif (phba->hba_flag & FCP_XRI_ABORT_EVENT)\r\nlpfc_sli4_fcp_xri_abort_event_proc(phba);\r\nif (phba->hba_flag & ELS_XRI_ABORT_EVENT)\r\nlpfc_sli4_els_xri_abort_event_proc(phba);\r\nif (phba->hba_flag & ASYNC_EVENT)\r\nlpfc_sli4_async_event_proc(phba);\r\nif (phba->hba_flag & HBA_POST_RECEIVE_BUFFER) {\r\nspin_lock_irq(&phba->hbalock);\r\nphba->hba_flag &= ~HBA_POST_RECEIVE_BUFFER;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_sli_hbqbuf_add_hbqs(phba, LPFC_ELS_HBQ);\r\n}\r\nif (phba->fcf.fcf_flag & FCF_REDISC_EVT)\r\nlpfc_sli4_fcf_redisc_event_proc(phba);\r\n}\r\nvports = lpfc_create_vport_work_array(phba);\r\nif (vports != NULL)\r\nfor (i = 0; i <= phba->max_vports; i++) {\r\nif (vports[i] == NULL && i == 0)\r\nvport = phba->pport;\r\nelse\r\nvport = vports[i];\r\nif (vport == NULL)\r\nbreak;\r\nspin_lock_irq(&vport->work_port_lock);\r\nwork_port_events = vport->work_port_events;\r\nvport->work_port_events &= ~work_port_events;\r\nspin_unlock_irq(&vport->work_port_lock);\r\nif (work_port_events & WORKER_DISC_TMO)\r\nlpfc_disc_timeout_handler(vport);\r\nif (work_port_events & WORKER_ELS_TMO)\r\nlpfc_els_timeout_handler(vport);\r\nif (work_port_events & WORKER_HB_TMO)\r\nlpfc_hb_timeout_handler(phba);\r\nif (work_port_events & WORKER_MBOX_TMO)\r\nlpfc_mbox_timeout_handler(phba);\r\nif (work_port_events & WORKER_FABRIC_BLOCK_TMO)\r\nlpfc_unblock_fabric_iocbs(phba);\r\nif (work_port_events & WORKER_FDMI_TMO)\r\nlpfc_fdmi_timeout_handler(vport);\r\nif (work_port_events & WORKER_RAMP_DOWN_QUEUE)\r\nlpfc_ramp_down_queue_handler(phba);\r\nif (work_port_events & WORKER_RAMP_UP_QUEUE)\r\nlpfc_ramp_up_queue_handler(phba);\r\nif (work_port_events & WORKER_DELAYED_DISC_TMO)\r\nlpfc_delayed_disc_timeout_handler(vport);\r\n}\r\nlpfc_destroy_vport_work_array(phba, vports);\r\npring = &phba->sli.ring[LPFC_ELS_RING];\r\nstatus = (ha_copy & (HA_RXMASK << (4*LPFC_ELS_RING)));\r\nstatus >>= (4*LPFC_ELS_RING);\r\nif ((status & HA_RXMASK) ||\r\n(pring->flag & LPFC_DEFERRED_RING_EVENT) ||\r\n(phba->hba_flag & HBA_SP_QUEUE_EVT)) {\r\nif (pring->flag & LPFC_STOP_IOCB_EVENT) {\r\npring->flag |= LPFC_DEFERRED_RING_EVENT;\r\nset_bit(LPFC_DATA_READY, &phba->data_flags);\r\n} else {\r\nif (phba->link_state >= LPFC_LINK_UP) {\r\npring->flag &= ~LPFC_DEFERRED_RING_EVENT;\r\nlpfc_sli_handle_slow_ring_event(phba, pring,\r\n(status &\r\nHA_RXMASK));\r\n}\r\n}\r\nif ((phba->sli_rev == LPFC_SLI_REV4) &\r\n(!list_empty(&pring->txq)))\r\nlpfc_drain_txq(phba);\r\nif (phba->sli_rev <= LPFC_SLI_REV3) {\r\nspin_lock_irq(&phba->hbalock);\r\ncontrol = readl(phba->HCregaddr);\r\nif (!(control & (HC_R0INT_ENA << LPFC_ELS_RING))) {\r\nlpfc_debugfs_slow_ring_trc(phba,\r\n"WRK Enable ring: cntl:x%x hacopy:x%x",\r\ncontrol, ha_copy, 0);\r\ncontrol |= (HC_R0INT_ENA << LPFC_ELS_RING);\r\nwritel(control, phba->HCregaddr);\r\nreadl(phba->HCregaddr);\r\n} else {\r\nlpfc_debugfs_slow_ring_trc(phba,\r\n"WRK Ring ok: cntl:x%x hacopy:x%x",\r\ncontrol, ha_copy, 0);\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\n}\r\n}\r\nlpfc_work_list_done(phba);\r\n}\r\nint\r\nlpfc_do_work(void *p)\r\n{\r\nstruct lpfc_hba *phba = p;\r\nint rc;\r\nset_user_nice(current, -20);\r\ncurrent->flags |= PF_NOFREEZE;\r\nphba->data_flags = 0;\r\nwhile (!kthread_should_stop()) {\r\nrc = wait_event_interruptible(phba->work_waitq,\r\n(test_and_clear_bit(LPFC_DATA_READY,\r\n&phba->data_flags)\r\n|| kthread_should_stop()));\r\nif (rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_ELS,\r\n"0433 Wakeup on signal: rc=x%x\n", rc);\r\nbreak;\r\n}\r\nlpfc_work_done(phba);\r\n}\r\nphba->worker_thread = NULL;\r\nlpfc_printf_log(phba, KERN_INFO, LOG_ELS,\r\n"0432 Worker thread stopped.\n");\r\nreturn 0;\r\n}\r\nint\r\nlpfc_workq_post_event(struct lpfc_hba *phba, void *arg1, void *arg2,\r\nuint32_t evt)\r\n{\r\nstruct lpfc_work_evt *evtp;\r\nunsigned long flags;\r\nevtp = kmalloc(sizeof(struct lpfc_work_evt), GFP_ATOMIC);\r\nif (!evtp)\r\nreturn 0;\r\nevtp->evt_arg1 = arg1;\r\nevtp->evt_arg2 = arg2;\r\nevtp->evt = evt;\r\nspin_lock_irqsave(&phba->hbalock, flags);\r\nlist_add_tail(&evtp->evt_listp, &phba->work_list);\r\nspin_unlock_irqrestore(&phba->hbalock, flags);\r\nlpfc_worker_wake_up(phba);\r\nreturn 1;\r\n}\r\nvoid\r\nlpfc_cleanup_rpis(struct lpfc_vport *vport, int remove)\r\n{\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nstruct lpfc_hba *phba = vport->phba;\r\nstruct lpfc_nodelist *ndlp, *next_ndlp;\r\nint rc;\r\nlist_for_each_entry_safe(ndlp, next_ndlp, &vport->fc_nodes, nlp_listp) {\r\nif (!NLP_CHK_NODE_ACT(ndlp))\r\ncontinue;\r\nif (ndlp->nlp_state == NLP_STE_UNUSED_NODE)\r\ncontinue;\r\nif ((phba->sli3_options & LPFC_SLI3_VPORT_TEARDOWN) ||\r\n((vport->port_type == LPFC_NPIV_PORT) &&\r\n(ndlp->nlp_DID == NameServer_DID)))\r\nlpfc_unreg_rpi(vport, ndlp);\r\nif ((phba->sli_rev < LPFC_SLI_REV4) &&\r\n(!remove && ndlp->nlp_type & NLP_FABRIC))\r\ncontinue;\r\nrc = lpfc_disc_state_machine(vport, ndlp, NULL,\r\nremove\r\n? NLP_EVT_DEVICE_RM\r\n: NLP_EVT_DEVICE_RECOVERY);\r\n}\r\nif (phba->sli3_options & LPFC_SLI3_VPORT_TEARDOWN) {\r\nif (phba->sli_rev == LPFC_SLI_REV4)\r\nlpfc_sli4_unreg_all_rpis(vport);\r\nlpfc_mbx_unreg_vpi(vport);\r\nspin_lock_irq(shost->host_lock);\r\nvport->fc_flag |= FC_VPORT_NEEDS_REG_VPI;\r\nspin_unlock_irq(shost->host_lock);\r\n}\r\n}\r\nvoid\r\nlpfc_port_link_failure(struct lpfc_vport *vport)\r\n{\r\nlpfc_vport_set_state(vport, FC_VPORT_LINKDOWN);\r\nlpfc_cleanup_rcv_buffers(vport);\r\nlpfc_els_flush_rscn(vport);\r\nlpfc_els_flush_cmd(vport);\r\nlpfc_cleanup_rpis(vport, 0);\r\nlpfc_can_disctmo(vport);\r\n}\r\nvoid\r\nlpfc_linkdown_port(struct lpfc_vport *vport)\r\n{\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nfc_host_post_event(shost, fc_get_event_number(), FCH_EVT_LINKDOWN, 0);\r\nlpfc_debugfs_disc_trc(vport, LPFC_DISC_TRC_ELS_CMD,\r\n"Link Down: state:x%x rtry:x%x flg:x%x",\r\nvport->port_state, vport->fc_ns_retry, vport->fc_flag);\r\nlpfc_port_link_failure(vport);\r\nspin_lock_irq(shost->host_lock);\r\nvport->fc_flag &= ~FC_DISC_DELAYED;\r\nspin_unlock_irq(shost->host_lock);\r\ndel_timer_sync(&vport->delayed_disc_tmo);\r\n}\r\nint\r\nlpfc_linkdown(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_vport *vport = phba->pport;\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nstruct lpfc_vport **vports;\r\nLPFC_MBOXQ_t *mb;\r\nint i;\r\nif (phba->link_state == LPFC_LINK_DOWN)\r\nreturn 0;\r\nlpfc_scsi_dev_block(phba);\r\nspin_lock_irq(&phba->hbalock);\r\nphba->fcf.fcf_flag &= ~(FCF_AVAILABLE | FCF_SCAN_DONE);\r\nspin_unlock_irq(&phba->hbalock);\r\nif (phba->link_state > LPFC_LINK_DOWN) {\r\nphba->link_state = LPFC_LINK_DOWN;\r\nspin_lock_irq(shost->host_lock);\r\nphba->pport->fc_flag &= ~FC_LBIT;\r\nspin_unlock_irq(shost->host_lock);\r\n}\r\nvports = lpfc_create_vport_work_array(phba);\r\nif (vports != NULL)\r\nfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++) {\r\nlpfc_linkdown_port(vports[i]);\r\n}\r\nlpfc_destroy_vport_work_array(phba, vports);\r\nmb = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (mb) {\r\nlpfc_unreg_did(phba, 0xffff, LPFC_UNREG_ALL_DFLT_RPIS, mb);\r\nmb->vport = vport;\r\nmb->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\nif (lpfc_sli_issue_mbox(phba, mb, MBX_NOWAIT)\r\n== MBX_NOT_FINISHED) {\r\nmempool_free(mb, phba->mbox_mem_pool);\r\n}\r\n}\r\nif (phba->pport->fc_flag & FC_PT2PT) {\r\nphba->pport->fc_myDID = 0;\r\nmb = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (mb) {\r\nlpfc_config_link(phba, mb);\r\nmb->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\nmb->vport = vport;\r\nif (lpfc_sli_issue_mbox(phba, mb, MBX_NOWAIT)\r\n== MBX_NOT_FINISHED) {\r\nmempool_free(mb, phba->mbox_mem_pool);\r\n}\r\n}\r\nspin_lock_irq(shost->host_lock);\r\nphba->pport->fc_flag &= ~(FC_PT2PT | FC_PT2PT_PLOGI);\r\nspin_unlock_irq(shost->host_lock);\r\n}\r\nreturn 0;\r\n}\r\nstatic void\r\nlpfc_linkup_cleanup_nodes(struct lpfc_vport *vport)\r\n{\r\nstruct lpfc_nodelist *ndlp;\r\nlist_for_each_entry(ndlp, &vport->fc_nodes, nlp_listp) {\r\nif (!NLP_CHK_NODE_ACT(ndlp))\r\ncontinue;\r\nif (ndlp->nlp_state == NLP_STE_UNUSED_NODE)\r\ncontinue;\r\nif (ndlp->nlp_type & NLP_FABRIC) {\r\nif (ndlp->nlp_DID != Fabric_DID)\r\nlpfc_unreg_rpi(vport, ndlp);\r\nlpfc_nlp_set_state(vport, ndlp, NLP_STE_NPR_NODE);\r\n} else if (!(ndlp->nlp_flag & NLP_NPR_ADISC)) {\r\nlpfc_unreg_rpi(vport, ndlp);\r\n}\r\n}\r\n}\r\nstatic void\r\nlpfc_linkup_port(struct lpfc_vport *vport)\r\n{\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nstruct lpfc_hba *phba = vport->phba;\r\nif ((vport->load_flag & FC_UNLOADING) != 0)\r\nreturn;\r\nlpfc_debugfs_disc_trc(vport, LPFC_DISC_TRC_ELS_CMD,\r\n"Link Up: top:x%x speed:x%x flg:x%x",\r\nphba->fc_topology, phba->fc_linkspeed, phba->link_flag);\r\nif (!(phba->sli3_options & LPFC_SLI3_NPIV_ENABLED) &&\r\n(vport != phba->pport))\r\nreturn;\r\nfc_host_post_event(shost, fc_get_event_number(), FCH_EVT_LINKUP, 0);\r\nspin_lock_irq(shost->host_lock);\r\nvport->fc_flag &= ~(FC_PT2PT | FC_PT2PT_PLOGI | FC_ABORT_DISCOVERY |\r\nFC_RSCN_MODE | FC_NLP_MORE | FC_RSCN_DISCOVERY);\r\nvport->fc_flag |= FC_NDISC_ACTIVE;\r\nvport->fc_ns_retry = 0;\r\nspin_unlock_irq(shost->host_lock);\r\nif (vport->fc_flag & FC_LBIT)\r\nlpfc_linkup_cleanup_nodes(vport);\r\n}\r\nstatic int\r\nlpfc_linkup(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_vport **vports;\r\nint i;\r\nlpfc_cleanup_wt_rrqs(phba);\r\nphba->link_state = LPFC_LINK_UP;\r\nclear_bit(FABRIC_COMANDS_BLOCKED, &phba->bit_flags);\r\ndel_timer_sync(&phba->fabric_block_timer);\r\nvports = lpfc_create_vport_work_array(phba);\r\nif (vports != NULL)\r\nfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++)\r\nlpfc_linkup_port(vports[i]);\r\nlpfc_destroy_vport_work_array(phba, vports);\r\nreturn 0;\r\n}\r\nstatic void\r\nlpfc_mbx_cmpl_clear_la(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)\r\n{\r\nstruct lpfc_vport *vport = pmb->vport;\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nstruct lpfc_sli *psli = &phba->sli;\r\nMAILBOX_t *mb = &pmb->u.mb;\r\nuint32_t control;\r\npsli->ring[psli->extra_ring].flag &= ~LPFC_STOP_IOCB_EVENT;\r\npsli->ring[psli->fcp_ring].flag &= ~LPFC_STOP_IOCB_EVENT;\r\npsli->ring[psli->next_ring].flag &= ~LPFC_STOP_IOCB_EVENT;\r\nif ((mb->mbxStatus) && (mb->mbxStatus != 0x1601)) {\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_MBOX,\r\n"0320 CLEAR_LA mbxStatus error x%x hba "\r\n"state x%x\n",\r\nmb->mbxStatus, vport->port_state);\r\nphba->link_state = LPFC_HBA_ERROR;\r\ngoto out;\r\n}\r\nif (vport->port_type == LPFC_PHYSICAL_PORT)\r\nphba->link_state = LPFC_HBA_READY;\r\nspin_lock_irq(&phba->hbalock);\r\npsli->sli_flag |= LPFC_PROCESS_LA;\r\ncontrol = readl(phba->HCregaddr);\r\ncontrol |= HC_LAINT_ENA;\r\nwritel(control, phba->HCregaddr);\r\nreadl(phba->HCregaddr);\r\nspin_unlock_irq(&phba->hbalock);\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nreturn;\r\nout:\r\nlpfc_printf_vlog(vport, KERN_INFO, LOG_DISCOVERY,\r\n"0225 Device Discovery completes\n");\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nspin_lock_irq(shost->host_lock);\r\nvport->fc_flag &= ~FC_ABORT_DISCOVERY;\r\nspin_unlock_irq(shost->host_lock);\r\nlpfc_can_disctmo(vport);\r\nspin_lock_irq(&phba->hbalock);\r\npsli->sli_flag |= LPFC_PROCESS_LA;\r\ncontrol = readl(phba->HCregaddr);\r\ncontrol |= HC_LAINT_ENA;\r\nwritel(control, phba->HCregaddr);\r\nreadl(phba->HCregaddr);\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn;\r\n}\r\nstatic void\r\nlpfc_mbx_cmpl_local_config_link(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)\r\n{\r\nstruct lpfc_vport *vport = pmb->vport;\r\nif (pmb->u.mb.mbxStatus)\r\ngoto out;\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nif ((phba->sli_rev == LPFC_SLI_REV4) &&\r\n!(phba->hba_flag & HBA_FCOE_MODE) &&\r\n(phba->link_flag & LS_LOOPBACK_MODE))\r\nreturn;\r\nif (phba->fc_topology == LPFC_TOPOLOGY_LOOP &&\r\nvport->fc_flag & FC_PUBLIC_LOOP &&\r\n!(vport->fc_flag & FC_LBIT)) {\r\nlpfc_set_disctmo(vport);\r\nreturn;\r\n}\r\nif (vport->port_state != LPFC_FLOGI || vport->fc_flag & FC_PT2PT_PLOGI)\r\nlpfc_initial_flogi(vport);\r\nreturn;\r\nout:\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_MBOX,\r\n"0306 CONFIG_LINK mbxStatus error x%x "\r\n"HBA state x%x\n",\r\npmb->u.mb.mbxStatus, vport->port_state);\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nlpfc_linkdown(phba);\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_DISCOVERY,\r\n"0200 CONFIG_LINK bad hba state x%x\n",\r\nvport->port_state);\r\nlpfc_issue_clear_la(phba, vport);\r\nreturn;\r\n}\r\nvoid\r\nlpfc_sli4_clear_fcf_rr_bmask(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_fcf_pri *fcf_pri;\r\nstruct lpfc_fcf_pri *next_fcf_pri;\r\nmemset(phba->fcf.fcf_rr_bmask, 0, sizeof(*phba->fcf.fcf_rr_bmask));\r\nspin_lock_irq(&phba->hbalock);\r\nlist_for_each_entry_safe(fcf_pri, next_fcf_pri,\r\n&phba->fcf.fcf_pri_list, list) {\r\nlist_del_init(&fcf_pri->list);\r\nfcf_pri->fcf_rec.flag = 0;\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\n}\r\nstatic void\r\nlpfc_mbx_cmpl_reg_fcfi(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq)\r\n{\r\nstruct lpfc_vport *vport = mboxq->vport;\r\nif (mboxq->u.mb.mbxStatus) {\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_MBOX,\r\n"2017 REG_FCFI mbxStatus error x%x "\r\n"HBA state x%x\n",\r\nmboxq->u.mb.mbxStatus, vport->port_state);\r\ngoto fail_out;\r\n}\r\nphba->fcf.fcfi = bf_get(lpfc_reg_fcfi_fcfi, &mboxq->u.mqe.un.reg_fcfi);\r\nspin_lock_irq(&phba->hbalock);\r\nphba->fcf.fcf_flag |= FCF_REGISTERED;\r\nspin_unlock_irq(&phba->hbalock);\r\nif ((!(phba->hba_flag & FCF_RR_INPROG)) &&\r\nlpfc_check_pending_fcoe_event(phba, LPFC_UNREG_FCF))\r\ngoto fail_out;\r\nspin_lock_irq(&phba->hbalock);\r\nphba->fcf.fcf_flag |= (FCF_SCAN_DONE | FCF_IN_USE);\r\nphba->hba_flag &= ~FCF_TS_INPROG;\r\nif (vport->port_state != LPFC_FLOGI) {\r\nphba->hba_flag |= FCF_RR_INPROG;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_issue_init_vfi(vport);\r\ngoto out;\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\ngoto out;\r\nfail_out:\r\nspin_lock_irq(&phba->hbalock);\r\nphba->hba_flag &= ~FCF_RR_INPROG;\r\nspin_unlock_irq(&phba->hbalock);\r\nout:\r\nmempool_free(mboxq, phba->mbox_mem_pool);\r\n}\r\nstatic uint32_t\r\nlpfc_fab_name_match(uint8_t *fab_name, struct fcf_record *new_fcf_record)\r\n{\r\nif (fab_name[0] != bf_get(lpfc_fcf_record_fab_name_0, new_fcf_record))\r\nreturn 0;\r\nif (fab_name[1] != bf_get(lpfc_fcf_record_fab_name_1, new_fcf_record))\r\nreturn 0;\r\nif (fab_name[2] != bf_get(lpfc_fcf_record_fab_name_2, new_fcf_record))\r\nreturn 0;\r\nif (fab_name[3] != bf_get(lpfc_fcf_record_fab_name_3, new_fcf_record))\r\nreturn 0;\r\nif (fab_name[4] != bf_get(lpfc_fcf_record_fab_name_4, new_fcf_record))\r\nreturn 0;\r\nif (fab_name[5] != bf_get(lpfc_fcf_record_fab_name_5, new_fcf_record))\r\nreturn 0;\r\nif (fab_name[6] != bf_get(lpfc_fcf_record_fab_name_6, new_fcf_record))\r\nreturn 0;\r\nif (fab_name[7] != bf_get(lpfc_fcf_record_fab_name_7, new_fcf_record))\r\nreturn 0;\r\nreturn 1;\r\n}\r\nstatic uint32_t\r\nlpfc_sw_name_match(uint8_t *sw_name, struct fcf_record *new_fcf_record)\r\n{\r\nif (sw_name[0] != bf_get(lpfc_fcf_record_switch_name_0, new_fcf_record))\r\nreturn 0;\r\nif (sw_name[1] != bf_get(lpfc_fcf_record_switch_name_1, new_fcf_record))\r\nreturn 0;\r\nif (sw_name[2] != bf_get(lpfc_fcf_record_switch_name_2, new_fcf_record))\r\nreturn 0;\r\nif (sw_name[3] != bf_get(lpfc_fcf_record_switch_name_3, new_fcf_record))\r\nreturn 0;\r\nif (sw_name[4] != bf_get(lpfc_fcf_record_switch_name_4, new_fcf_record))\r\nreturn 0;\r\nif (sw_name[5] != bf_get(lpfc_fcf_record_switch_name_5, new_fcf_record))\r\nreturn 0;\r\nif (sw_name[6] != bf_get(lpfc_fcf_record_switch_name_6, new_fcf_record))\r\nreturn 0;\r\nif (sw_name[7] != bf_get(lpfc_fcf_record_switch_name_7, new_fcf_record))\r\nreturn 0;\r\nreturn 1;\r\n}\r\nstatic uint32_t\r\nlpfc_mac_addr_match(uint8_t *mac_addr, struct fcf_record *new_fcf_record)\r\n{\r\nif (mac_addr[0] != bf_get(lpfc_fcf_record_mac_0, new_fcf_record))\r\nreturn 0;\r\nif (mac_addr[1] != bf_get(lpfc_fcf_record_mac_1, new_fcf_record))\r\nreturn 0;\r\nif (mac_addr[2] != bf_get(lpfc_fcf_record_mac_2, new_fcf_record))\r\nreturn 0;\r\nif (mac_addr[3] != bf_get(lpfc_fcf_record_mac_3, new_fcf_record))\r\nreturn 0;\r\nif (mac_addr[4] != bf_get(lpfc_fcf_record_mac_4, new_fcf_record))\r\nreturn 0;\r\nif (mac_addr[5] != bf_get(lpfc_fcf_record_mac_5, new_fcf_record))\r\nreturn 0;\r\nreturn 1;\r\n}\r\nstatic bool\r\nlpfc_vlan_id_match(uint16_t curr_vlan_id, uint16_t new_vlan_id)\r\n{\r\nreturn (curr_vlan_id == new_vlan_id);\r\n}\r\nstatic void\r\n__lpfc_update_fcf_record_pri(struct lpfc_hba *phba, uint16_t fcf_index,\r\nstruct fcf_record *new_fcf_record\r\n)\r\n{\r\nstruct lpfc_fcf_pri *fcf_pri;\r\nfcf_pri = &phba->fcf.fcf_pri[fcf_index];\r\nfcf_pri->fcf_rec.fcf_index = fcf_index;\r\nfcf_pri->fcf_rec.priority = new_fcf_record->fip_priority;\r\n}\r\nstatic void\r\nlpfc_copy_fcf_record(struct lpfc_fcf_rec *fcf_rec,\r\nstruct fcf_record *new_fcf_record)\r\n{\r\nfcf_rec->fabric_name[0] =\r\nbf_get(lpfc_fcf_record_fab_name_0, new_fcf_record);\r\nfcf_rec->fabric_name[1] =\r\nbf_get(lpfc_fcf_record_fab_name_1, new_fcf_record);\r\nfcf_rec->fabric_name[2] =\r\nbf_get(lpfc_fcf_record_fab_name_2, new_fcf_record);\r\nfcf_rec->fabric_name[3] =\r\nbf_get(lpfc_fcf_record_fab_name_3, new_fcf_record);\r\nfcf_rec->fabric_name[4] =\r\nbf_get(lpfc_fcf_record_fab_name_4, new_fcf_record);\r\nfcf_rec->fabric_name[5] =\r\nbf_get(lpfc_fcf_record_fab_name_5, new_fcf_record);\r\nfcf_rec->fabric_name[6] =\r\nbf_get(lpfc_fcf_record_fab_name_6, new_fcf_record);\r\nfcf_rec->fabric_name[7] =\r\nbf_get(lpfc_fcf_record_fab_name_7, new_fcf_record);\r\nfcf_rec->mac_addr[0] = bf_get(lpfc_fcf_record_mac_0, new_fcf_record);\r\nfcf_rec->mac_addr[1] = bf_get(lpfc_fcf_record_mac_1, new_fcf_record);\r\nfcf_rec->mac_addr[2] = bf_get(lpfc_fcf_record_mac_2, new_fcf_record);\r\nfcf_rec->mac_addr[3] = bf_get(lpfc_fcf_record_mac_3, new_fcf_record);\r\nfcf_rec->mac_addr[4] = bf_get(lpfc_fcf_record_mac_4, new_fcf_record);\r\nfcf_rec->mac_addr[5] = bf_get(lpfc_fcf_record_mac_5, new_fcf_record);\r\nfcf_rec->fcf_indx = bf_get(lpfc_fcf_record_fcf_index, new_fcf_record);\r\nfcf_rec->priority = new_fcf_record->fip_priority;\r\nfcf_rec->switch_name[0] =\r\nbf_get(lpfc_fcf_record_switch_name_0, new_fcf_record);\r\nfcf_rec->switch_name[1] =\r\nbf_get(lpfc_fcf_record_switch_name_1, new_fcf_record);\r\nfcf_rec->switch_name[2] =\r\nbf_get(lpfc_fcf_record_switch_name_2, new_fcf_record);\r\nfcf_rec->switch_name[3] =\r\nbf_get(lpfc_fcf_record_switch_name_3, new_fcf_record);\r\nfcf_rec->switch_name[4] =\r\nbf_get(lpfc_fcf_record_switch_name_4, new_fcf_record);\r\nfcf_rec->switch_name[5] =\r\nbf_get(lpfc_fcf_record_switch_name_5, new_fcf_record);\r\nfcf_rec->switch_name[6] =\r\nbf_get(lpfc_fcf_record_switch_name_6, new_fcf_record);\r\nfcf_rec->switch_name[7] =\r\nbf_get(lpfc_fcf_record_switch_name_7, new_fcf_record);\r\n}\r\nstatic void\r\n__lpfc_update_fcf_record(struct lpfc_hba *phba, struct lpfc_fcf_rec *fcf_rec,\r\nstruct fcf_record *new_fcf_record, uint32_t addr_mode,\r\nuint16_t vlan_id, uint32_t flag)\r\n{\r\nlpfc_copy_fcf_record(fcf_rec, new_fcf_record);\r\nfcf_rec->addr_mode = addr_mode;\r\nfcf_rec->vlan_id = vlan_id;\r\nfcf_rec->flag |= (flag | RECORD_VALID);\r\n__lpfc_update_fcf_record_pri(phba,\r\nbf_get(lpfc_fcf_record_fcf_index, new_fcf_record),\r\nnew_fcf_record);\r\n}\r\nstatic void\r\nlpfc_register_fcf(struct lpfc_hba *phba)\r\n{\r\nLPFC_MBOXQ_t *fcf_mbxq;\r\nint rc;\r\nspin_lock_irq(&phba->hbalock);\r\nif (!(phba->fcf.fcf_flag & FCF_AVAILABLE)) {\r\nphba->hba_flag &= ~(FCF_TS_INPROG | FCF_RR_INPROG);\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn;\r\n}\r\nif (phba->fcf.fcf_flag & FCF_REGISTERED) {\r\nphba->fcf.fcf_flag |= (FCF_SCAN_DONE | FCF_IN_USE);\r\nphba->hba_flag &= ~FCF_TS_INPROG;\r\nif (phba->pport->port_state != LPFC_FLOGI &&\r\nphba->pport->fc_flag & FC_FABRIC) {\r\nphba->hba_flag |= FCF_RR_INPROG;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_initial_flogi(phba->pport);\r\nreturn;\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn;\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\nfcf_mbxq = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!fcf_mbxq) {\r\nspin_lock_irq(&phba->hbalock);\r\nphba->hba_flag &= ~(FCF_TS_INPROG | FCF_RR_INPROG);\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn;\r\n}\r\nlpfc_reg_fcfi(phba, fcf_mbxq);\r\nfcf_mbxq->vport = phba->pport;\r\nfcf_mbxq->mbox_cmpl = lpfc_mbx_cmpl_reg_fcfi;\r\nrc = lpfc_sli_issue_mbox(phba, fcf_mbxq, MBX_NOWAIT);\r\nif (rc == MBX_NOT_FINISHED) {\r\nspin_lock_irq(&phba->hbalock);\r\nphba->hba_flag &= ~(FCF_TS_INPROG | FCF_RR_INPROG);\r\nspin_unlock_irq(&phba->hbalock);\r\nmempool_free(fcf_mbxq, phba->mbox_mem_pool);\r\n}\r\nreturn;\r\n}\r\nstatic int\r\nlpfc_match_fcf_conn_list(struct lpfc_hba *phba,\r\nstruct fcf_record *new_fcf_record,\r\nuint32_t *boot_flag, uint32_t *addr_mode,\r\nuint16_t *vlan_id)\r\n{\r\nstruct lpfc_fcf_conn_entry *conn_entry;\r\nint i, j, fcf_vlan_id = 0;\r\nfor (i = 0; i < 512; i++) {\r\nif (new_fcf_record->vlan_bitmap[i]) {\r\nfcf_vlan_id = i * 8;\r\nj = 0;\r\nwhile (!((new_fcf_record->vlan_bitmap[i] >> j) & 1)) {\r\nj++;\r\nfcf_vlan_id++;\r\n}\r\nbreak;\r\n}\r\n}\r\nif (!bf_get(lpfc_fcf_record_fcf_avail, new_fcf_record) ||\r\n!bf_get(lpfc_fcf_record_fcf_valid, new_fcf_record) ||\r\nbf_get(lpfc_fcf_record_fcf_sol, new_fcf_record))\r\nreturn 0;\r\nif (!(phba->hba_flag & HBA_FIP_SUPPORT)) {\r\n*boot_flag = 0;\r\n*addr_mode = bf_get(lpfc_fcf_record_mac_addr_prov,\r\nnew_fcf_record);\r\nif (phba->valid_vlan)\r\n*vlan_id = phba->vlan_id;\r\nelse\r\n*vlan_id = LPFC_FCOE_NULL_VID;\r\nreturn 1;\r\n}\r\nif (list_empty(&phba->fcf_conn_rec_list)) {\r\n*boot_flag = 0;\r\n*addr_mode = bf_get(lpfc_fcf_record_mac_addr_prov,\r\nnew_fcf_record);\r\nif (*addr_mode & LPFC_FCF_FPMA)\r\n*addr_mode = LPFC_FCF_FPMA;\r\nif (fcf_vlan_id)\r\n*vlan_id = fcf_vlan_id;\r\nelse\r\n*vlan_id = LPFC_FCOE_NULL_VID;\r\nreturn 1;\r\n}\r\nlist_for_each_entry(conn_entry,\r\n&phba->fcf_conn_rec_list, list) {\r\nif (!(conn_entry->conn_rec.flags & FCFCNCT_VALID))\r\ncontinue;\r\nif ((conn_entry->conn_rec.flags & FCFCNCT_FBNM_VALID) &&\r\n!lpfc_fab_name_match(conn_entry->conn_rec.fabric_name,\r\nnew_fcf_record))\r\ncontinue;\r\nif ((conn_entry->conn_rec.flags & FCFCNCT_SWNM_VALID) &&\r\n!lpfc_sw_name_match(conn_entry->conn_rec.switch_name,\r\nnew_fcf_record))\r\ncontinue;\r\nif (conn_entry->conn_rec.flags & FCFCNCT_VLAN_VALID) {\r\nif (!(new_fcf_record->vlan_bitmap\r\n[conn_entry->conn_rec.vlan_tag / 8] &\r\n(1 << (conn_entry->conn_rec.vlan_tag % 8))))\r\ncontinue;\r\n}\r\nif (!(bf_get(lpfc_fcf_record_mac_addr_prov, new_fcf_record)\r\n& (LPFC_FCF_FPMA | LPFC_FCF_SPMA)))\r\ncontinue;\r\nif ((conn_entry->conn_rec.flags & FCFCNCT_AM_VALID) &&\r\n!(conn_entry->conn_rec.flags & FCFCNCT_AM_PREFERRED)) {\r\nif ((conn_entry->conn_rec.flags & FCFCNCT_AM_SPMA) &&\r\n!(bf_get(lpfc_fcf_record_mac_addr_prov,\r\nnew_fcf_record) & LPFC_FCF_SPMA))\r\ncontinue;\r\nif (!(conn_entry->conn_rec.flags & FCFCNCT_AM_SPMA) &&\r\n!(bf_get(lpfc_fcf_record_mac_addr_prov,\r\nnew_fcf_record) & LPFC_FCF_FPMA))\r\ncontinue;\r\n}\r\nif (conn_entry->conn_rec.flags & FCFCNCT_BOOT)\r\n*boot_flag = 1;\r\nelse\r\n*boot_flag = 0;\r\n*addr_mode = bf_get(lpfc_fcf_record_mac_addr_prov,\r\nnew_fcf_record);\r\nif ((conn_entry->conn_rec.flags & FCFCNCT_AM_VALID) &&\r\n(!(conn_entry->conn_rec.flags & FCFCNCT_AM_PREFERRED)))\r\n*addr_mode = (conn_entry->conn_rec.flags &\r\nFCFCNCT_AM_SPMA) ?\r\nLPFC_FCF_SPMA : LPFC_FCF_FPMA;\r\nelse if ((conn_entry->conn_rec.flags & FCFCNCT_AM_VALID) &&\r\n(conn_entry->conn_rec.flags & FCFCNCT_AM_PREFERRED) &&\r\n(conn_entry->conn_rec.flags & FCFCNCT_AM_SPMA) &&\r\n(*addr_mode & LPFC_FCF_SPMA))\r\n*addr_mode = LPFC_FCF_SPMA;\r\nelse if ((conn_entry->conn_rec.flags & FCFCNCT_AM_VALID) &&\r\n(conn_entry->conn_rec.flags & FCFCNCT_AM_PREFERRED) &&\r\n!(conn_entry->conn_rec.flags & FCFCNCT_AM_SPMA) &&\r\n(*addr_mode & LPFC_FCF_FPMA))\r\n*addr_mode = LPFC_FCF_FPMA;\r\nif (conn_entry->conn_rec.flags & FCFCNCT_VLAN_VALID)\r\n*vlan_id = conn_entry->conn_rec.vlan_tag;\r\nelse if (fcf_vlan_id)\r\n*vlan_id = fcf_vlan_id;\r\nelse\r\n*vlan_id = LPFC_FCOE_NULL_VID;\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nint\r\nlpfc_check_pending_fcoe_event(struct lpfc_hba *phba, uint8_t unreg_fcf)\r\n{\r\nif ((phba->link_state >= LPFC_LINK_UP) &&\r\n(phba->fcoe_eventtag == phba->fcoe_eventtag_at_fcf_scan))\r\nreturn 0;\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2768 Pending link or FCF event during current "\r\n"handling of the previous event: link_state:x%x, "\r\n"evt_tag_at_scan:x%x, evt_tag_current:x%x\n",\r\nphba->link_state, phba->fcoe_eventtag_at_fcf_scan,\r\nphba->fcoe_eventtag);\r\nspin_lock_irq(&phba->hbalock);\r\nphba->fcf.fcf_flag &= ~FCF_AVAILABLE;\r\nspin_unlock_irq(&phba->hbalock);\r\nif (phba->link_state >= LPFC_LINK_UP) {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP | LOG_DISCOVERY,\r\n"2780 Restart FCF table scan due to "\r\n"pending FCF event:evt_tag_at_scan:x%x, "\r\n"evt_tag_current:x%x\n",\r\nphba->fcoe_eventtag_at_fcf_scan,\r\nphba->fcoe_eventtag);\r\nlpfc_sli4_fcf_scan_read_fcf_rec(phba, LPFC_FCOE_FCF_GET_FIRST);\r\n} else {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP | LOG_DISCOVERY,\r\n"2833 Stop FCF discovery process due to link "\r\n"state change (x%x)\n", phba->link_state);\r\nspin_lock_irq(&phba->hbalock);\r\nphba->hba_flag &= ~(FCF_TS_INPROG | FCF_RR_INPROG);\r\nphba->fcf.fcf_flag &= ~(FCF_REDISC_FOV | FCF_DISCOVERY);\r\nspin_unlock_irq(&phba->hbalock);\r\n}\r\nif (unreg_fcf) {\r\nspin_lock_irq(&phba->hbalock);\r\nphba->fcf.fcf_flag &= ~FCF_REGISTERED;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_sli4_unregister_fcf(phba);\r\n}\r\nreturn 1;\r\n}\r\nstatic bool\r\nlpfc_sli4_new_fcf_random_select(struct lpfc_hba *phba, uint32_t fcf_cnt)\r\n{\r\nuint32_t rand_num;\r\nrand_num = 0xFFFF & prandom_u32();\r\nif ((fcf_cnt * rand_num) < 0xFFFF)\r\nreturn true;\r\nelse\r\nreturn false;\r\n}\r\nstatic struct fcf_record *\r\nlpfc_sli4_fcf_rec_mbox_parse(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq,\r\nuint16_t *next_fcf_index)\r\n{\r\nvoid *virt_addr;\r\ndma_addr_t phys_addr;\r\nstruct lpfc_mbx_sge sge;\r\nstruct lpfc_mbx_read_fcf_tbl *read_fcf;\r\nuint32_t shdr_status, shdr_add_status;\r\nunion lpfc_sli4_cfg_shdr *shdr;\r\nstruct fcf_record *new_fcf_record;\r\nlpfc_sli4_mbx_sge_get(mboxq, 0, &sge);\r\nphys_addr = getPaddr(sge.pa_hi, sge.pa_lo);\r\nif (unlikely(!mboxq->sge_array)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_MBOX,\r\n"2524 Failed to get the non-embedded SGE "\r\n"virtual address\n");\r\nreturn NULL;\r\n}\r\nvirt_addr = mboxq->sge_array->addr[0];\r\nshdr = (union lpfc_sli4_cfg_shdr *)virt_addr;\r\nlpfc_sli_pcimem_bcopy(shdr, shdr,\r\nsizeof(union lpfc_sli4_cfg_shdr));\r\nshdr_status = bf_get(lpfc_mbox_hdr_status, &shdr->response);\r\nshdr_add_status = bf_get(lpfc_mbox_hdr_add_status, &shdr->response);\r\nif (shdr_status || shdr_add_status) {\r\nif (shdr_status == STATUS_FCF_TABLE_EMPTY)\r\nlpfc_printf_log(phba, KERN_ERR, LOG_FIP,\r\n"2726 READ_FCF_RECORD Indicates empty "\r\n"FCF table.\n");\r\nelse\r\nlpfc_printf_log(phba, KERN_ERR, LOG_FIP,\r\n"2521 READ_FCF_RECORD mailbox failed "\r\n"with status x%x add_status x%x, "\r\n"mbx\n", shdr_status, shdr_add_status);\r\nreturn NULL;\r\n}\r\nread_fcf = (struct lpfc_mbx_read_fcf_tbl *)virt_addr;\r\nlpfc_sli_pcimem_bcopy(read_fcf, read_fcf,\r\nsizeof(struct lpfc_mbx_read_fcf_tbl));\r\n*next_fcf_index = bf_get(lpfc_mbx_read_fcf_tbl_nxt_vindx, read_fcf);\r\nnew_fcf_record = (struct fcf_record *)(virt_addr +\r\nsizeof(struct lpfc_mbx_read_fcf_tbl));\r\nlpfc_sli_pcimem_bcopy(new_fcf_record, new_fcf_record,\r\noffsetof(struct fcf_record, vlan_bitmap));\r\nnew_fcf_record->word137 = le32_to_cpu(new_fcf_record->word137);\r\nnew_fcf_record->word138 = le32_to_cpu(new_fcf_record->word138);\r\nreturn new_fcf_record;\r\n}\r\nstatic void\r\nlpfc_sli4_log_fcf_record_info(struct lpfc_hba *phba,\r\nstruct fcf_record *fcf_record,\r\nuint16_t vlan_id,\r\nuint16_t next_fcf_index)\r\n{\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2764 READ_FCF_RECORD:\n"\r\n"\tFCF_Index : x%x\n"\r\n"\tFCF_Avail : x%x\n"\r\n"\tFCF_Valid : x%x\n"\r\n"\tFCF_SOL : x%x\n"\r\n"\tFIP_Priority : x%x\n"\r\n"\tMAC_Provider : x%x\n"\r\n"\tLowest VLANID : x%x\n"\r\n"\tFCF_MAC Addr : x%x:%x:%x:%x:%x:%x\n"\r\n"\tFabric_Name : x%x:%x:%x:%x:%x:%x:%x:%x\n"\r\n"\tSwitch_Name : x%x:%x:%x:%x:%x:%x:%x:%x\n"\r\n"\tNext_FCF_Index: x%x\n",\r\nbf_get(lpfc_fcf_record_fcf_index, fcf_record),\r\nbf_get(lpfc_fcf_record_fcf_avail, fcf_record),\r\nbf_get(lpfc_fcf_record_fcf_valid, fcf_record),\r\nbf_get(lpfc_fcf_record_fcf_sol, fcf_record),\r\nfcf_record->fip_priority,\r\nbf_get(lpfc_fcf_record_mac_addr_prov, fcf_record),\r\nvlan_id,\r\nbf_get(lpfc_fcf_record_mac_0, fcf_record),\r\nbf_get(lpfc_fcf_record_mac_1, fcf_record),\r\nbf_get(lpfc_fcf_record_mac_2, fcf_record),\r\nbf_get(lpfc_fcf_record_mac_3, fcf_record),\r\nbf_get(lpfc_fcf_record_mac_4, fcf_record),\r\nbf_get(lpfc_fcf_record_mac_5, fcf_record),\r\nbf_get(lpfc_fcf_record_fab_name_0, fcf_record),\r\nbf_get(lpfc_fcf_record_fab_name_1, fcf_record),\r\nbf_get(lpfc_fcf_record_fab_name_2, fcf_record),\r\nbf_get(lpfc_fcf_record_fab_name_3, fcf_record),\r\nbf_get(lpfc_fcf_record_fab_name_4, fcf_record),\r\nbf_get(lpfc_fcf_record_fab_name_5, fcf_record),\r\nbf_get(lpfc_fcf_record_fab_name_6, fcf_record),\r\nbf_get(lpfc_fcf_record_fab_name_7, fcf_record),\r\nbf_get(lpfc_fcf_record_switch_name_0, fcf_record),\r\nbf_get(lpfc_fcf_record_switch_name_1, fcf_record),\r\nbf_get(lpfc_fcf_record_switch_name_2, fcf_record),\r\nbf_get(lpfc_fcf_record_switch_name_3, fcf_record),\r\nbf_get(lpfc_fcf_record_switch_name_4, fcf_record),\r\nbf_get(lpfc_fcf_record_switch_name_5, fcf_record),\r\nbf_get(lpfc_fcf_record_switch_name_6, fcf_record),\r\nbf_get(lpfc_fcf_record_switch_name_7, fcf_record),\r\nnext_fcf_index);\r\n}\r\nstatic bool\r\nlpfc_sli4_fcf_record_match(struct lpfc_hba *phba,\r\nstruct lpfc_fcf_rec *fcf_rec,\r\nstruct fcf_record *new_fcf_record,\r\nuint16_t new_vlan_id)\r\n{\r\nif (new_vlan_id != LPFC_FCOE_IGNORE_VID)\r\nif (!lpfc_vlan_id_match(fcf_rec->vlan_id, new_vlan_id))\r\nreturn false;\r\nif (!lpfc_mac_addr_match(fcf_rec->mac_addr, new_fcf_record))\r\nreturn false;\r\nif (!lpfc_sw_name_match(fcf_rec->switch_name, new_fcf_record))\r\nreturn false;\r\nif (!lpfc_fab_name_match(fcf_rec->fabric_name, new_fcf_record))\r\nreturn false;\r\nif (fcf_rec->priority != new_fcf_record->fip_priority)\r\nreturn false;\r\nreturn true;\r\n}\r\nint lpfc_sli4_fcf_rr_next_proc(struct lpfc_vport *vport, uint16_t fcf_index)\r\n{\r\nstruct lpfc_hba *phba = vport->phba;\r\nint rc;\r\nif (fcf_index == LPFC_FCOE_FCF_NEXT_NONE) {\r\nspin_lock_irq(&phba->hbalock);\r\nif (phba->hba_flag & HBA_DEVLOSS_TMO) {\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2872 Devloss tmo with no eligible "\r\n"FCF, unregister in-use FCF (x%x) "\r\n"and rescan FCF table\n",\r\nphba->fcf.current_rec.fcf_indx);\r\nlpfc_unregister_fcf_rescan(phba);\r\ngoto stop_flogi_current_fcf;\r\n}\r\nphba->hba_flag &= ~FCF_RR_INPROG;\r\nphba->fcf.fcf_flag &= ~(FCF_AVAILABLE | FCF_SCAN_DONE);\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2865 No FCF available, stop roundrobin FCF "\r\n"failover and change port state:x%x/x%x\n",\r\nphba->pport->port_state, LPFC_VPORT_UNKNOWN);\r\nphba->pport->port_state = LPFC_VPORT_UNKNOWN;\r\ngoto stop_flogi_current_fcf;\r\n} else {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP | LOG_ELS,\r\n"2794 Try FLOGI roundrobin FCF failover to "\r\n"(x%x)\n", fcf_index);\r\nrc = lpfc_sli4_fcf_rr_read_fcf_rec(phba, fcf_index);\r\nif (rc)\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_FIP | LOG_ELS,\r\n"2761 FLOGI roundrobin FCF failover "\r\n"failed (rc:x%x) to read FCF (x%x)\n",\r\nrc, phba->fcf.current_rec.fcf_indx);\r\nelse\r\ngoto stop_flogi_current_fcf;\r\n}\r\nreturn 0;\r\nstop_flogi_current_fcf:\r\nlpfc_can_disctmo(vport);\r\nreturn 1;\r\n}\r\nstatic void lpfc_sli4_fcf_pri_list_del(struct lpfc_hba *phba,\r\nuint16_t fcf_index)\r\n{\r\nstruct lpfc_fcf_pri *new_fcf_pri;\r\nnew_fcf_pri = &phba->fcf.fcf_pri[fcf_index];\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"3058 deleting idx x%x pri x%x flg x%x\n",\r\nfcf_index, new_fcf_pri->fcf_rec.priority,\r\nnew_fcf_pri->fcf_rec.flag);\r\nspin_lock_irq(&phba->hbalock);\r\nif (new_fcf_pri->fcf_rec.flag & LPFC_FCF_ON_PRI_LIST) {\r\nif (phba->fcf.current_rec.priority ==\r\nnew_fcf_pri->fcf_rec.priority)\r\nphba->fcf.eligible_fcf_cnt--;\r\nlist_del_init(&new_fcf_pri->list);\r\nnew_fcf_pri->fcf_rec.flag &= ~LPFC_FCF_ON_PRI_LIST;\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\n}\r\nvoid\r\nlpfc_sli4_set_fcf_flogi_fail(struct lpfc_hba *phba, uint16_t fcf_index)\r\n{\r\nstruct lpfc_fcf_pri *new_fcf_pri;\r\nnew_fcf_pri = &phba->fcf.fcf_pri[fcf_index];\r\nspin_lock_irq(&phba->hbalock);\r\nnew_fcf_pri->fcf_rec.flag |= LPFC_FCF_FLOGI_FAILED;\r\nspin_unlock_irq(&phba->hbalock);\r\n}\r\nint lpfc_sli4_fcf_pri_list_add(struct lpfc_hba *phba, uint16_t fcf_index,\r\nstruct fcf_record *new_fcf_record)\r\n{\r\nuint16_t current_fcf_pri;\r\nuint16_t last_index;\r\nstruct lpfc_fcf_pri *fcf_pri;\r\nstruct lpfc_fcf_pri *next_fcf_pri;\r\nstruct lpfc_fcf_pri *new_fcf_pri;\r\nint ret;\r\nnew_fcf_pri = &phba->fcf.fcf_pri[fcf_index];\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"3059 adding idx x%x pri x%x flg x%x\n",\r\nfcf_index, new_fcf_record->fip_priority,\r\nnew_fcf_pri->fcf_rec.flag);\r\nspin_lock_irq(&phba->hbalock);\r\nif (new_fcf_pri->fcf_rec.flag & LPFC_FCF_ON_PRI_LIST)\r\nlist_del_init(&new_fcf_pri->list);\r\nnew_fcf_pri->fcf_rec.fcf_index = fcf_index;\r\nnew_fcf_pri->fcf_rec.priority = new_fcf_record->fip_priority;\r\nif (list_empty(&phba->fcf.fcf_pri_list)) {\r\nlist_add(&new_fcf_pri->list, &phba->fcf.fcf_pri_list);\r\nret = lpfc_sli4_fcf_rr_index_set(phba,\r\nnew_fcf_pri->fcf_rec.fcf_index);\r\ngoto out;\r\n}\r\nlast_index = find_first_bit(phba->fcf.fcf_rr_bmask,\r\nLPFC_SLI4_FCF_TBL_INDX_MAX);\r\nif (last_index >= LPFC_SLI4_FCF_TBL_INDX_MAX) {\r\nret = 0;\r\ngoto out;\r\n}\r\ncurrent_fcf_pri = phba->fcf.fcf_pri[last_index].fcf_rec.priority;\r\nif (new_fcf_pri->fcf_rec.priority <= current_fcf_pri) {\r\nlist_add(&new_fcf_pri->list, &phba->fcf.fcf_pri_list);\r\nif (new_fcf_pri->fcf_rec.priority < current_fcf_pri) {\r\nmemset(phba->fcf.fcf_rr_bmask, 0,\r\nsizeof(*phba->fcf.fcf_rr_bmask));\r\nphba->fcf.eligible_fcf_cnt = 1;\r\n} else\r\nphba->fcf.eligible_fcf_cnt++;\r\nret = lpfc_sli4_fcf_rr_index_set(phba,\r\nnew_fcf_pri->fcf_rec.fcf_index);\r\ngoto out;\r\n}\r\nlist_for_each_entry_safe(fcf_pri, next_fcf_pri,\r\n&phba->fcf.fcf_pri_list, list) {\r\nif (new_fcf_pri->fcf_rec.priority <=\r\nfcf_pri->fcf_rec.priority) {\r\nif (fcf_pri->list.prev == &phba->fcf.fcf_pri_list)\r\nlist_add(&new_fcf_pri->list,\r\n&phba->fcf.fcf_pri_list);\r\nelse\r\nlist_add(&new_fcf_pri->list,\r\n&((struct lpfc_fcf_pri *)\r\nfcf_pri->list.prev)->list);\r\nret = 0;\r\ngoto out;\r\n} else if (fcf_pri->list.next == &phba->fcf.fcf_pri_list\r\n|| new_fcf_pri->fcf_rec.priority <\r\nnext_fcf_pri->fcf_rec.priority) {\r\nlist_add(&new_fcf_pri->list, &fcf_pri->list);\r\nret = 0;\r\ngoto out;\r\n}\r\nif (new_fcf_pri->fcf_rec.priority > fcf_pri->fcf_rec.priority)\r\ncontinue;\r\n}\r\nret = 1;\r\nout:\r\nnew_fcf_pri->fcf_rec.flag = LPFC_FCF_ON_PRI_LIST;\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn ret;\r\n}\r\nvoid\r\nlpfc_mbx_cmpl_fcf_scan_read_fcf_rec(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq)\r\n{\r\nstruct fcf_record *new_fcf_record;\r\nuint32_t boot_flag, addr_mode;\r\nuint16_t fcf_index, next_fcf_index;\r\nstruct lpfc_fcf_rec *fcf_rec = NULL;\r\nuint16_t vlan_id;\r\nuint32_t seed;\r\nbool select_new_fcf;\r\nint rc;\r\nif (lpfc_check_pending_fcoe_event(phba, LPFC_SKIP_UNREG_FCF)) {\r\nlpfc_sli4_mbox_cmd_free(phba, mboxq);\r\nreturn;\r\n}\r\nnew_fcf_record = lpfc_sli4_fcf_rec_mbox_parse(phba, mboxq,\r\n&next_fcf_index);\r\nif (!new_fcf_record) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_FIP,\r\n"2765 Mailbox command READ_FCF_RECORD "\r\n"failed to retrieve a FCF record.\n");\r\nspin_lock_irq(&phba->hbalock);\r\nphba->hba_flag &= ~FCF_TS_INPROG;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_sli4_mbox_cmd_free(phba, mboxq);\r\nreturn;\r\n}\r\nrc = lpfc_match_fcf_conn_list(phba, new_fcf_record, &boot_flag,\r\n&addr_mode, &vlan_id);\r\nlpfc_sli4_log_fcf_record_info(phba, new_fcf_record, vlan_id,\r\nnext_fcf_index);\r\nif (!rc) {\r\nlpfc_sli4_fcf_pri_list_del(phba,\r\nbf_get(lpfc_fcf_record_fcf_index,\r\nnew_fcf_record));\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_FIP,\r\n"2781 FCF (x%x) failed connection "\r\n"list check: (x%x/x%x/%x)\n",\r\nbf_get(lpfc_fcf_record_fcf_index,\r\nnew_fcf_record),\r\nbf_get(lpfc_fcf_record_fcf_avail,\r\nnew_fcf_record),\r\nbf_get(lpfc_fcf_record_fcf_valid,\r\nnew_fcf_record),\r\nbf_get(lpfc_fcf_record_fcf_sol,\r\nnew_fcf_record));\r\nif ((phba->fcf.fcf_flag & FCF_IN_USE) &&\r\nlpfc_sli4_fcf_record_match(phba, &phba->fcf.current_rec,\r\nnew_fcf_record, LPFC_FCOE_IGNORE_VID)) {\r\nif (bf_get(lpfc_fcf_record_fcf_index, new_fcf_record) !=\r\nphba->fcf.current_rec.fcf_indx) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_FIP,\r\n"2862 FCF (x%x) matches property "\r\n"of in-use FCF (x%x)\n",\r\nbf_get(lpfc_fcf_record_fcf_index,\r\nnew_fcf_record),\r\nphba->fcf.current_rec.fcf_indx);\r\ngoto read_next_fcf;\r\n}\r\nif (!(phba->fcf.fcf_flag & FCF_REDISC_PEND) &&\r\n!(phba->fcf.fcf_flag & FCF_REDISC_FOV)) {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_FIP,\r\n"2835 Invalid in-use FCF "\r\n"(x%x), enter FCF failover "\r\n"table scan.\n",\r\nphba->fcf.current_rec.fcf_indx);\r\nspin_lock_irq(&phba->hbalock);\r\nphba->fcf.fcf_flag |= FCF_REDISC_FOV;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_sli4_mbox_cmd_free(phba, mboxq);\r\nlpfc_sli4_fcf_scan_read_fcf_rec(phba,\r\nLPFC_FCOE_FCF_GET_FIRST);\r\nreturn;\r\n}\r\n}\r\ngoto read_next_fcf;\r\n} else {\r\nfcf_index = bf_get(lpfc_fcf_record_fcf_index, new_fcf_record);\r\nrc = lpfc_sli4_fcf_pri_list_add(phba, fcf_index,\r\nnew_fcf_record);\r\nif (rc)\r\ngoto read_next_fcf;\r\n}\r\nspin_lock_irq(&phba->hbalock);\r\nif (phba->fcf.fcf_flag & FCF_IN_USE) {\r\nif (phba->cfg_fcf_failover_policy == LPFC_FCF_FOV &&\r\nlpfc_sli4_fcf_record_match(phba, &phba->fcf.current_rec,\r\nnew_fcf_record, vlan_id)) {\r\nif (bf_get(lpfc_fcf_record_fcf_index, new_fcf_record) ==\r\nphba->fcf.current_rec.fcf_indx) {\r\nphba->fcf.fcf_flag |= FCF_AVAILABLE;\r\nif (phba->fcf.fcf_flag & FCF_REDISC_PEND)\r\n__lpfc_sli4_stop_fcf_redisc_wait_timer(\r\nphba);\r\nelse if (phba->fcf.fcf_flag & FCF_REDISC_FOV)\r\nphba->fcf.fcf_flag &= ~FCF_REDISC_FOV;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2836 New FCF matches in-use "\r\n"FCF (x%x), port_state:x%x, "\r\n"fc_flag:x%x\n",\r\nphba->fcf.current_rec.fcf_indx,\r\nphba->pport->port_state,\r\nphba->pport->fc_flag);\r\ngoto out;\r\n} else\r\nlpfc_printf_log(phba, KERN_ERR, LOG_FIP,\r\n"2863 New FCF (x%x) matches "\r\n"property of in-use FCF (x%x)\n",\r\nbf_get(lpfc_fcf_record_fcf_index,\r\nnew_fcf_record),\r\nphba->fcf.current_rec.fcf_indx);\r\n}\r\nif (!(phba->fcf.fcf_flag & FCF_REDISC_FOV)) {\r\nspin_unlock_irq(&phba->hbalock);\r\ngoto read_next_fcf;\r\n}\r\n}\r\nif (phba->fcf.fcf_flag & FCF_REDISC_FOV)\r\nfcf_rec = &phba->fcf.failover_rec;\r\nelse\r\nfcf_rec = &phba->fcf.current_rec;\r\nif (phba->fcf.fcf_flag & FCF_AVAILABLE) {\r\nif (boot_flag && !(fcf_rec->flag & BOOT_ENABLE)) {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2837 Update current FCF record "\r\n"(x%x) with new FCF record (x%x)\n",\r\nfcf_rec->fcf_indx,\r\nbf_get(lpfc_fcf_record_fcf_index,\r\nnew_fcf_record));\r\n__lpfc_update_fcf_record(phba, fcf_rec, new_fcf_record,\r\naddr_mode, vlan_id, BOOT_ENABLE);\r\nspin_unlock_irq(&phba->hbalock);\r\ngoto read_next_fcf;\r\n}\r\nif (!boot_flag && (fcf_rec->flag & BOOT_ENABLE)) {\r\nspin_unlock_irq(&phba->hbalock);\r\ngoto read_next_fcf;\r\n}\r\nif (new_fcf_record->fip_priority < fcf_rec->priority) {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2838 Update current FCF record "\r\n"(x%x) with new FCF record (x%x)\n",\r\nfcf_rec->fcf_indx,\r\nbf_get(lpfc_fcf_record_fcf_index,\r\nnew_fcf_record));\r\n__lpfc_update_fcf_record(phba, fcf_rec, new_fcf_record,\r\naddr_mode, vlan_id, 0);\r\nphba->fcf.eligible_fcf_cnt = 1;\r\n} else if (new_fcf_record->fip_priority == fcf_rec->priority) {\r\nphba->fcf.eligible_fcf_cnt++;\r\nselect_new_fcf = lpfc_sli4_new_fcf_random_select(phba,\r\nphba->fcf.eligible_fcf_cnt);\r\nif (select_new_fcf) {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2839 Update current FCF record "\r\n"(x%x) with new FCF record (x%x)\n",\r\nfcf_rec->fcf_indx,\r\nbf_get(lpfc_fcf_record_fcf_index,\r\nnew_fcf_record));\r\n__lpfc_update_fcf_record(phba, fcf_rec,\r\nnew_fcf_record,\r\naddr_mode, vlan_id, 0);\r\n}\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\ngoto read_next_fcf;\r\n}\r\nif (fcf_rec) {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2840 Update initial FCF candidate "\r\n"with FCF (x%x)\n",\r\nbf_get(lpfc_fcf_record_fcf_index,\r\nnew_fcf_record));\r\n__lpfc_update_fcf_record(phba, fcf_rec, new_fcf_record,\r\naddr_mode, vlan_id, (boot_flag ?\r\nBOOT_ENABLE : 0));\r\nphba->fcf.fcf_flag |= FCF_AVAILABLE;\r\nphba->fcf.eligible_fcf_cnt = 1;\r\nseed = (uint32_t)(0xFFFFFFFF & jiffies);\r\nprandom_seed(seed);\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\ngoto read_next_fcf;\r\nread_next_fcf:\r\nlpfc_sli4_mbox_cmd_free(phba, mboxq);\r\nif (next_fcf_index == LPFC_FCOE_FCF_NEXT_NONE || next_fcf_index == 0) {\r\nif (phba->fcf.fcf_flag & FCF_REDISC_FOV) {\r\nif (!(phba->fcf.failover_rec.flag & RECORD_VALID)) {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_FIP,\r\n"2782 No suitable FCF found: "\r\n"(x%x/x%x)\n",\r\nphba->fcoe_eventtag_at_fcf_scan,\r\nbf_get(lpfc_fcf_record_fcf_index,\r\nnew_fcf_record));\r\nspin_lock_irq(&phba->hbalock);\r\nif (phba->hba_flag & HBA_DEVLOSS_TMO) {\r\nphba->hba_flag &= ~FCF_TS_INPROG;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_printf_log(phba, KERN_INFO,\r\nLOG_FIP,\r\n"2864 On devloss tmo "\r\n"unreg in-use FCF and "\r\n"rescan FCF table\n");\r\nlpfc_unregister_fcf_rescan(phba);\r\nreturn;\r\n}\r\nphba->hba_flag &= ~FCF_TS_INPROG;\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn;\r\n}\r\nlpfc_unregister_fcf(phba);\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2842 Replace in-use FCF (x%x) "\r\n"with failover FCF (x%x)\n",\r\nphba->fcf.current_rec.fcf_indx,\r\nphba->fcf.failover_rec.fcf_indx);\r\nmemcpy(&phba->fcf.current_rec,\r\n&phba->fcf.failover_rec,\r\nsizeof(struct lpfc_fcf_rec));\r\nspin_lock_irq(&phba->hbalock);\r\nphba->fcf.fcf_flag &= ~FCF_REDISC_FOV;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_register_fcf(phba);\r\n} else {\r\nif ((phba->fcf.fcf_flag & FCF_REDISC_EVT) ||\r\n(phba->fcf.fcf_flag & FCF_REDISC_PEND))\r\nreturn;\r\nif (phba->cfg_fcf_failover_policy == LPFC_FCF_FOV &&\r\nphba->fcf.fcf_flag & FCF_IN_USE) {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2841 In-use FCF record (x%x) "\r\n"not reported, entering fast "\r\n"FCF failover mode scanning.\n",\r\nphba->fcf.current_rec.fcf_indx);\r\nspin_lock_irq(&phba->hbalock);\r\nphba->fcf.fcf_flag |= FCF_REDISC_FOV;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_sli4_fcf_scan_read_fcf_rec(phba,\r\nLPFC_FCOE_FCF_GET_FIRST);\r\nreturn;\r\n}\r\nlpfc_register_fcf(phba);\r\n}\r\n} else\r\nlpfc_sli4_fcf_scan_read_fcf_rec(phba, next_fcf_index);\r\nreturn;\r\nout:\r\nlpfc_sli4_mbox_cmd_free(phba, mboxq);\r\nlpfc_register_fcf(phba);\r\nreturn;\r\n}\r\nvoid\r\nlpfc_mbx_cmpl_fcf_rr_read_fcf_rec(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq)\r\n{\r\nstruct fcf_record *new_fcf_record;\r\nuint32_t boot_flag, addr_mode;\r\nuint16_t next_fcf_index, fcf_index;\r\nuint16_t current_fcf_index;\r\nuint16_t vlan_id;\r\nint rc;\r\nif (phba->link_state < LPFC_LINK_UP) {\r\nspin_lock_irq(&phba->hbalock);\r\nphba->fcf.fcf_flag &= ~FCF_DISCOVERY;\r\nphba->hba_flag &= ~FCF_RR_INPROG;\r\nspin_unlock_irq(&phba->hbalock);\r\ngoto out;\r\n}\r\nnew_fcf_record = lpfc_sli4_fcf_rec_mbox_parse(phba, mboxq,\r\n&next_fcf_index);\r\nif (!new_fcf_record) {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_FIP,\r\n"2766 Mailbox command READ_FCF_RECORD "\r\n"failed to retrieve a FCF record.\n");\r\ngoto error_out;\r\n}\r\nrc = lpfc_match_fcf_conn_list(phba, new_fcf_record, &boot_flag,\r\n&addr_mode, &vlan_id);\r\nlpfc_sli4_log_fcf_record_info(phba, new_fcf_record, vlan_id,\r\nnext_fcf_index);\r\nfcf_index = bf_get(lpfc_fcf_record_fcf_index, new_fcf_record);\r\nif (!rc) {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2848 Remove ineligible FCF (x%x) from "\r\n"from roundrobin bmask\n", fcf_index);\r\nlpfc_sli4_fcf_rr_index_clear(phba, fcf_index);\r\nfcf_index = lpfc_sli4_fcf_rr_next_index_get(phba);\r\nrc = lpfc_sli4_fcf_rr_next_proc(phba->pport, fcf_index);\r\nif (rc)\r\ngoto out;\r\ngoto error_out;\r\n}\r\nif (fcf_index == phba->fcf.current_rec.fcf_indx) {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2760 Perform FLOGI roundrobin FCF failover: "\r\n"FCF (x%x) back to FCF (x%x)\n",\r\nphba->fcf.current_rec.fcf_indx, fcf_index);\r\nmsleep(500);\r\nlpfc_issue_init_vfi(phba->pport);\r\ngoto out;\r\n}\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2834 Update current FCF (x%x) with new FCF (x%x)\n",\r\nphba->fcf.failover_rec.fcf_indx, fcf_index);\r\nspin_lock_irq(&phba->hbalock);\r\n__lpfc_update_fcf_record(phba, &phba->fcf.failover_rec,\r\nnew_fcf_record, addr_mode, vlan_id,\r\n(boot_flag ? BOOT_ENABLE : 0));\r\nspin_unlock_irq(&phba->hbalock);\r\ncurrent_fcf_index = phba->fcf.current_rec.fcf_indx;\r\nlpfc_unregister_fcf(phba);\r\nmemcpy(&phba->fcf.current_rec, &phba->fcf.failover_rec,\r\nsizeof(struct lpfc_fcf_rec));\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2783 Perform FLOGI roundrobin FCF failover: FCF "\r\n"(x%x) to FCF (x%x)\n", current_fcf_index, fcf_index);\r\nerror_out:\r\nlpfc_register_fcf(phba);\r\nout:\r\nlpfc_sli4_mbox_cmd_free(phba, mboxq);\r\n}\r\nvoid\r\nlpfc_mbx_cmpl_read_fcf_rec(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq)\r\n{\r\nstruct fcf_record *new_fcf_record;\r\nuint32_t boot_flag, addr_mode;\r\nuint16_t fcf_index, next_fcf_index;\r\nuint16_t vlan_id;\r\nint rc;\r\nif (phba->link_state < LPFC_LINK_UP)\r\ngoto out;\r\nif (!(phba->fcf.fcf_flag & FCF_DISCOVERY))\r\ngoto out;\r\nnew_fcf_record = lpfc_sli4_fcf_rec_mbox_parse(phba, mboxq,\r\n&next_fcf_index);\r\nif (!new_fcf_record) {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP,\r\n"2767 Mailbox command READ_FCF_RECORD "\r\n"failed to retrieve a FCF record.\n");\r\ngoto out;\r\n}\r\nrc = lpfc_match_fcf_conn_list(phba, new_fcf_record, &boot_flag,\r\n&addr_mode, &vlan_id);\r\nlpfc_sli4_log_fcf_record_info(phba, new_fcf_record, vlan_id,\r\nnext_fcf_index);\r\nif (!rc)\r\ngoto out;\r\nfcf_index = bf_get(lpfc_fcf_record_fcf_index, new_fcf_record);\r\nrc = lpfc_sli4_fcf_pri_list_add(phba, fcf_index, new_fcf_record);\r\nout:\r\nlpfc_sli4_mbox_cmd_free(phba, mboxq);\r\n}\r\nvoid\r\nlpfc_init_vfi_cmpl(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq)\r\n{\r\nstruct lpfc_vport *vport = mboxq->vport;\r\nif (mboxq->u.mb.mbxStatus &&\r\n(bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf) !=\r\nLPFC_SLI_INTF_IF_TYPE_0) &&\r\nmboxq->u.mb.mbxStatus != MBX_VFI_IN_USE) {\r\nlpfc_printf_vlog(vport, KERN_ERR,\r\nLOG_MBOX,\r\n"2891 Init VFI mailbox failed 0x%x\n",\r\nmboxq->u.mb.mbxStatus);\r\nmempool_free(mboxq, phba->mbox_mem_pool);\r\nlpfc_vport_set_state(vport, FC_VPORT_FAILED);\r\nreturn;\r\n}\r\nlpfc_initial_flogi(vport);\r\nmempool_free(mboxq, phba->mbox_mem_pool);\r\nreturn;\r\n}\r\nvoid\r\nlpfc_issue_init_vfi(struct lpfc_vport *vport)\r\n{\r\nLPFC_MBOXQ_t *mboxq;\r\nint rc;\r\nstruct lpfc_hba *phba = vport->phba;\r\nmboxq = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mboxq) {\r\nlpfc_printf_vlog(vport, KERN_ERR,\r\nLOG_MBOX, "2892 Failed to allocate "\r\n"init_vfi mailbox\n");\r\nreturn;\r\n}\r\nlpfc_init_vfi(mboxq, vport);\r\nmboxq->mbox_cmpl = lpfc_init_vfi_cmpl;\r\nrc = lpfc_sli_issue_mbox(phba, mboxq, MBX_NOWAIT);\r\nif (rc == MBX_NOT_FINISHED) {\r\nlpfc_printf_vlog(vport, KERN_ERR,\r\nLOG_MBOX, "2893 Failed to issue init_vfi mailbox\n");\r\nmempool_free(mboxq, vport->phba->mbox_mem_pool);\r\n}\r\n}\r\nvoid\r\nlpfc_init_vpi_cmpl(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq)\r\n{\r\nstruct lpfc_vport *vport = mboxq->vport;\r\nstruct lpfc_nodelist *ndlp;\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nif (mboxq->u.mb.mbxStatus) {\r\nlpfc_printf_vlog(vport, KERN_ERR,\r\nLOG_MBOX,\r\n"2609 Init VPI mailbox failed 0x%x\n",\r\nmboxq->u.mb.mbxStatus);\r\nmempool_free(mboxq, phba->mbox_mem_pool);\r\nlpfc_vport_set_state(vport, FC_VPORT_FAILED);\r\nreturn;\r\n}\r\nspin_lock_irq(shost->host_lock);\r\nvport->fc_flag &= ~FC_VPORT_NEEDS_INIT_VPI;\r\nspin_unlock_irq(shost->host_lock);\r\nif ((phba->pport == vport) || (vport->port_state == LPFC_FDISC)) {\r\nndlp = lpfc_findnode_did(vport, Fabric_DID);\r\nif (!ndlp)\r\nlpfc_printf_vlog(vport, KERN_ERR,\r\nLOG_DISCOVERY,\r\n"2731 Cannot find fabric "\r\n"controller node\n");\r\nelse\r\nlpfc_register_new_vport(phba, vport, ndlp);\r\nmempool_free(mboxq, phba->mbox_mem_pool);\r\nreturn;\r\n}\r\nif (phba->link_flag & LS_NPIV_FAB_SUPPORTED)\r\nlpfc_initial_fdisc(vport);\r\nelse {\r\nlpfc_vport_set_state(vport, FC_VPORT_NO_FABRIC_SUPP);\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_ELS,\r\n"2606 No NPIV Fabric support\n");\r\n}\r\nmempool_free(mboxq, phba->mbox_mem_pool);\r\nreturn;\r\n}\r\nvoid\r\nlpfc_issue_init_vpi(struct lpfc_vport *vport)\r\n{\r\nLPFC_MBOXQ_t *mboxq;\r\nint rc, vpi;\r\nif ((vport->port_type != LPFC_PHYSICAL_PORT) && (!vport->vpi)) {\r\nvpi = lpfc_alloc_vpi(vport->phba);\r\nif (!vpi) {\r\nlpfc_printf_vlog(vport, KERN_ERR,\r\nLOG_MBOX,\r\n"3303 Failed to obtain vport vpi\n");\r\nlpfc_vport_set_state(vport, FC_VPORT_FAILED);\r\nreturn;\r\n}\r\nvport->vpi = vpi;\r\n}\r\nmboxq = mempool_alloc(vport->phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mboxq) {\r\nlpfc_printf_vlog(vport, KERN_ERR,\r\nLOG_MBOX, "2607 Failed to allocate "\r\n"init_vpi mailbox\n");\r\nreturn;\r\n}\r\nlpfc_init_vpi(vport->phba, mboxq, vport->vpi);\r\nmboxq->vport = vport;\r\nmboxq->mbox_cmpl = lpfc_init_vpi_cmpl;\r\nrc = lpfc_sli_issue_mbox(vport->phba, mboxq, MBX_NOWAIT);\r\nif (rc == MBX_NOT_FINISHED) {\r\nlpfc_printf_vlog(vport, KERN_ERR,\r\nLOG_MBOX, "2608 Failed to issue init_vpi mailbox\n");\r\nmempool_free(mboxq, vport->phba->mbox_mem_pool);\r\n}\r\n}\r\nvoid\r\nlpfc_start_fdiscs(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_vport **vports;\r\nint i;\r\nvports = lpfc_create_vport_work_array(phba);\r\nif (vports != NULL) {\r\nfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++) {\r\nif (vports[i]->port_type == LPFC_PHYSICAL_PORT)\r\ncontinue;\r\nif (vports[i]->vpi > phba->max_vpi) {\r\nlpfc_vport_set_state(vports[i],\r\nFC_VPORT_FAILED);\r\ncontinue;\r\n}\r\nif (phba->fc_topology == LPFC_TOPOLOGY_LOOP) {\r\nlpfc_vport_set_state(vports[i],\r\nFC_VPORT_LINKDOWN);\r\ncontinue;\r\n}\r\nif (vports[i]->fc_flag & FC_VPORT_NEEDS_INIT_VPI) {\r\nlpfc_issue_init_vpi(vports[i]);\r\ncontinue;\r\n}\r\nif (phba->link_flag & LS_NPIV_FAB_SUPPORTED)\r\nlpfc_initial_fdisc(vports[i]);\r\nelse {\r\nlpfc_vport_set_state(vports[i],\r\nFC_VPORT_NO_FABRIC_SUPP);\r\nlpfc_printf_vlog(vports[i], KERN_ERR,\r\nLOG_ELS,\r\n"0259 No NPIV "\r\n"Fabric support\n");\r\n}\r\n}\r\n}\r\nlpfc_destroy_vport_work_array(phba, vports);\r\n}\r\nvoid\r\nlpfc_mbx_cmpl_reg_vfi(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq)\r\n{\r\nstruct lpfc_dmabuf *dmabuf = mboxq->context1;\r\nstruct lpfc_vport *vport = mboxq->vport;\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nif (mboxq->u.mb.mbxStatus &&\r\n(bf_get(lpfc_sli_intf_if_type, &phba->sli4_hba.sli_intf) !=\r\nLPFC_SLI_INTF_IF_TYPE_0) &&\r\nmboxq->u.mb.mbxStatus != MBX_VFI_IN_USE) {\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_MBOX,\r\n"2018 REG_VFI mbxStatus error x%x "\r\n"HBA state x%x\n",\r\nmboxq->u.mb.mbxStatus, vport->port_state);\r\nif (phba->fc_topology == LPFC_TOPOLOGY_LOOP) {\r\nlpfc_disc_list_loopmap(vport);\r\nlpfc_disc_start(vport);\r\ngoto out_free_mem;\r\n}\r\nlpfc_vport_set_state(vport, FC_VPORT_FAILED);\r\ngoto out_free_mem;\r\n}\r\nif (vport->fc_flag & FC_VFI_REGISTERED)\r\nif (!(phba->sli_rev == LPFC_SLI_REV4 &&\r\nvport->fc_flag & FC_PT2PT))\r\ngoto out_free_mem;\r\nspin_lock_irq(shost->host_lock);\r\nvport->vpi_state |= LPFC_VPI_REGISTERED;\r\nvport->fc_flag |= FC_VFI_REGISTERED;\r\nvport->fc_flag &= ~FC_VPORT_NEEDS_REG_VPI;\r\nvport->fc_flag &= ~FC_VPORT_NEEDS_INIT_VPI;\r\nspin_unlock_irq(shost->host_lock);\r\nif ((phba->sli_rev == LPFC_SLI_REV4) &&\r\n(phba->link_flag & LS_LOOPBACK_MODE)) {\r\nphba->link_state = LPFC_HBA_READY;\r\ngoto out_free_mem;\r\n}\r\nlpfc_printf_vlog(vport, KERN_INFO, LOG_SLI,\r\n"3313 cmpl reg vfi port_state:%x fc_flag:%x myDid:%x "\r\n"alpacnt:%d LinkState:%x topology:%x\n",\r\nvport->port_state, vport->fc_flag, vport->fc_myDID,\r\nvport->phba->alpa_map[0],\r\nphba->link_state, phba->fc_topology);\r\nif (vport->port_state == LPFC_FABRIC_CFG_LINK) {\r\nif ((vport->fc_flag & FC_PT2PT) ||\r\n((phba->fc_topology == LPFC_TOPOLOGY_LOOP) &&\r\n!(vport->fc_flag & FC_PUBLIC_LOOP))) {\r\nlpfc_disc_list_loopmap(vport);\r\nif (vport->fc_flag & FC_PT2PT)\r\nvport->port_state = LPFC_VPORT_READY;\r\nelse\r\nlpfc_disc_start(vport);\r\n} else {\r\nlpfc_start_fdiscs(phba);\r\nlpfc_do_scr_ns_plogi(phba, vport);\r\n}\r\n}\r\nout_free_mem:\r\nmempool_free(mboxq, phba->mbox_mem_pool);\r\nlpfc_mbuf_free(phba, dmabuf->virt, dmabuf->phys);\r\nkfree(dmabuf);\r\nreturn;\r\n}\r\nstatic void\r\nlpfc_mbx_cmpl_read_sparam(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)\r\n{\r\nMAILBOX_t *mb = &pmb->u.mb;\r\nstruct lpfc_dmabuf *mp = (struct lpfc_dmabuf *) pmb->context1;\r\nstruct lpfc_vport *vport = pmb->vport;\r\nif (mb->mbxStatus) {\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_MBOX,\r\n"0319 READ_SPARAM mbxStatus error x%x "\r\n"hba state x%x>\n",\r\nmb->mbxStatus, vport->port_state);\r\nlpfc_linkdown(phba);\r\ngoto out;\r\n}\r\nmemcpy((uint8_t *) &vport->fc_sparam, (uint8_t *) mp->virt,\r\nsizeof (struct serv_parm));\r\nlpfc_update_vport_wwn(vport);\r\nif (vport->port_type == LPFC_PHYSICAL_PORT) {\r\nmemcpy(&phba->wwnn, &vport->fc_nodename, sizeof(phba->wwnn));\r\nmemcpy(&phba->wwpn, &vport->fc_portname, sizeof(phba->wwnn));\r\n}\r\nlpfc_mbuf_free(phba, mp->virt, mp->phys);\r\nkfree(mp);\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nreturn;\r\nout:\r\npmb->context1 = NULL;\r\nlpfc_mbuf_free(phba, mp->virt, mp->phys);\r\nkfree(mp);\r\nlpfc_issue_clear_la(phba, vport);\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nreturn;\r\n}\r\nstatic void\r\nlpfc_mbx_process_link_up(struct lpfc_hba *phba, struct lpfc_mbx_read_top *la)\r\n{\r\nstruct lpfc_vport *vport = phba->pport;\r\nLPFC_MBOXQ_t *sparam_mbox, *cfglink_mbox = NULL;\r\nstruct Scsi_Host *shost;\r\nint i;\r\nstruct lpfc_dmabuf *mp;\r\nint rc;\r\nstruct fcf_record *fcf_record;\r\nuint32_t fc_flags = 0;\r\nspin_lock_irq(&phba->hbalock);\r\nswitch (bf_get(lpfc_mbx_read_top_link_spd, la)) {\r\ncase LPFC_LINK_SPEED_1GHZ:\r\ncase LPFC_LINK_SPEED_2GHZ:\r\ncase LPFC_LINK_SPEED_4GHZ:\r\ncase LPFC_LINK_SPEED_8GHZ:\r\ncase LPFC_LINK_SPEED_10GHZ:\r\ncase LPFC_LINK_SPEED_16GHZ:\r\nphba->fc_linkspeed = bf_get(lpfc_mbx_read_top_link_spd, la);\r\nbreak;\r\ndefault:\r\nphba->fc_linkspeed = LPFC_LINK_SPEED_UNKNOWN;\r\nbreak;\r\n}\r\nif (phba->fc_topology &&\r\nphba->fc_topology != bf_get(lpfc_mbx_read_top_topology, la)) {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_SLI,\r\n"3314 Toplogy changed was 0x%x is 0x%x\n",\r\nphba->fc_topology,\r\nbf_get(lpfc_mbx_read_top_topology, la));\r\nphba->fc_topology_changed = 1;\r\n}\r\nphba->fc_topology = bf_get(lpfc_mbx_read_top_topology, la);\r\nphba->link_flag &= ~LS_NPIV_FAB_SUPPORTED;\r\nshost = lpfc_shost_from_vport(vport);\r\nif (phba->fc_topology == LPFC_TOPOLOGY_LOOP) {\r\nphba->sli3_options &= ~LPFC_SLI3_NPIV_ENABLED;\r\nif (phba->cfg_enable_npiv && phba->max_vpi)\r\nlpfc_printf_log(phba, KERN_ERR, LOG_LINK_EVENT,\r\n"1309 Link Up Event npiv not supported in loop "\r\n"topology\n");\r\nif (bf_get(lpfc_mbx_read_top_il, la))\r\nfc_flags |= FC_LBIT;\r\nvport->fc_myDID = bf_get(lpfc_mbx_read_top_alpa_granted, la);\r\ni = la->lilpBde64.tus.f.bdeSize;\r\nif (i == 0) {\r\nphba->alpa_map[0] = 0;\r\n} else {\r\nif (vport->cfg_log_verbose & LOG_LINK_EVENT) {\r\nint numalpa, j, k;\r\nunion {\r\nuint8_t pamap[16];\r\nstruct {\r\nuint32_t wd1;\r\nuint32_t wd2;\r\nuint32_t wd3;\r\nuint32_t wd4;\r\n} pa;\r\n} un;\r\nnumalpa = phba->alpa_map[0];\r\nj = 0;\r\nwhile (j < numalpa) {\r\nmemset(un.pamap, 0, 16);\r\nfor (k = 1; j < numalpa; k++) {\r\nun.pamap[k - 1] =\r\nphba->alpa_map[j + 1];\r\nj++;\r\nif (k == 16)\r\nbreak;\r\n}\r\nlpfc_printf_log(phba,\r\nKERN_WARNING,\r\nLOG_LINK_EVENT,\r\n"1304 Link Up Event "\r\n"ALPA map Data: x%x "\r\n"x%x x%x x%x\n",\r\nun.pa.wd1, un.pa.wd2,\r\nun.pa.wd3, un.pa.wd4);\r\n}\r\n}\r\n}\r\n} else {\r\nif (!(phba->sli3_options & LPFC_SLI3_NPIV_ENABLED)) {\r\nif (phba->max_vpi && phba->cfg_enable_npiv &&\r\n(phba->sli_rev >= LPFC_SLI_REV3))\r\nphba->sli3_options |= LPFC_SLI3_NPIV_ENABLED;\r\n}\r\nvport->fc_myDID = phba->fc_pref_DID;\r\nfc_flags |= FC_LBIT;\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\nif (fc_flags) {\r\nspin_lock_irq(shost->host_lock);\r\nvport->fc_flag |= fc_flags;\r\nspin_unlock_irq(shost->host_lock);\r\n}\r\nlpfc_linkup(phba);\r\nsparam_mbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!sparam_mbox)\r\ngoto out;\r\nrc = lpfc_read_sparam(phba, sparam_mbox, 0);\r\nif (rc) {\r\nmempool_free(sparam_mbox, phba->mbox_mem_pool);\r\ngoto out;\r\n}\r\nsparam_mbox->vport = vport;\r\nsparam_mbox->mbox_cmpl = lpfc_mbx_cmpl_read_sparam;\r\nrc = lpfc_sli_issue_mbox(phba, sparam_mbox, MBX_NOWAIT);\r\nif (rc == MBX_NOT_FINISHED) {\r\nmp = (struct lpfc_dmabuf *) sparam_mbox->context1;\r\nlpfc_mbuf_free(phba, mp->virt, mp->phys);\r\nkfree(mp);\r\nmempool_free(sparam_mbox, phba->mbox_mem_pool);\r\ngoto out;\r\n}\r\nif (!(phba->hba_flag & HBA_FCOE_MODE)) {\r\ncfglink_mbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!cfglink_mbox)\r\ngoto out;\r\nvport->port_state = LPFC_LOCAL_CFG_LINK;\r\nlpfc_config_link(phba, cfglink_mbox);\r\ncfglink_mbox->vport = vport;\r\ncfglink_mbox->mbox_cmpl = lpfc_mbx_cmpl_local_config_link;\r\nrc = lpfc_sli_issue_mbox(phba, cfglink_mbox, MBX_NOWAIT);\r\nif (rc == MBX_NOT_FINISHED) {\r\nmempool_free(cfglink_mbox, phba->mbox_mem_pool);\r\ngoto out;\r\n}\r\n} else {\r\nvport->port_state = LPFC_VPORT_UNKNOWN;\r\nif (!(phba->hba_flag & HBA_FIP_SUPPORT)) {\r\nfcf_record = kzalloc(sizeof(struct fcf_record),\r\nGFP_KERNEL);\r\nif (unlikely(!fcf_record)) {\r\nlpfc_printf_log(phba, KERN_ERR,\r\nLOG_MBOX | LOG_SLI,\r\n"2554 Could not allocate memory for "\r\n"fcf record\n");\r\nrc = -ENODEV;\r\ngoto out;\r\n}\r\nlpfc_sli4_build_dflt_fcf_record(phba, fcf_record,\r\nLPFC_FCOE_FCF_DEF_INDEX);\r\nrc = lpfc_sli4_add_fcf_record(phba, fcf_record);\r\nif (unlikely(rc)) {\r\nlpfc_printf_log(phba, KERN_ERR,\r\nLOG_MBOX | LOG_SLI,\r\n"2013 Could not manually add FCF "\r\n"record 0, status %d\n", rc);\r\nrc = -ENODEV;\r\nkfree(fcf_record);\r\ngoto out;\r\n}\r\nkfree(fcf_record);\r\n}\r\nspin_lock_irq(&phba->hbalock);\r\nif (phba->hba_flag & FCF_TS_INPROG) {\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn;\r\n}\r\nphba->fcf.fcf_flag |= FCF_INIT_DISC;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_printf_log(phba, KERN_INFO, LOG_FIP | LOG_DISCOVERY,\r\n"2778 Start FCF table scan at linkup\n");\r\nrc = lpfc_sli4_fcf_scan_read_fcf_rec(phba,\r\nLPFC_FCOE_FCF_GET_FIRST);\r\nif (rc) {\r\nspin_lock_irq(&phba->hbalock);\r\nphba->fcf.fcf_flag &= ~FCF_INIT_DISC;\r\nspin_unlock_irq(&phba->hbalock);\r\ngoto out;\r\n}\r\nlpfc_sli4_clear_fcf_rr_bmask(phba);\r\n}\r\nreturn;\r\nout:\r\nlpfc_vport_set_state(vport, FC_VPORT_FAILED);\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_MBOX,\r\n"0263 Discovery Mailbox error: state: 0x%x : %p %p\n",\r\nvport->port_state, sparam_mbox, cfglink_mbox);\r\nlpfc_issue_clear_la(phba, vport);\r\nreturn;\r\n}\r\nstatic void\r\nlpfc_enable_la(struct lpfc_hba *phba)\r\n{\r\nuint32_t control;\r\nstruct lpfc_sli *psli = &phba->sli;\r\nspin_lock_irq(&phba->hbalock);\r\npsli->sli_flag |= LPFC_PROCESS_LA;\r\nif (phba->sli_rev <= LPFC_SLI_REV3) {\r\ncontrol = readl(phba->HCregaddr);\r\ncontrol |= HC_LAINT_ENA;\r\nwritel(control, phba->HCregaddr);\r\nreadl(phba->HCregaddr);\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\n}\r\nstatic void\r\nlpfc_mbx_issue_link_down(struct lpfc_hba *phba)\r\n{\r\nlpfc_linkdown(phba);\r\nlpfc_enable_la(phba);\r\nlpfc_unregister_unused_fcf(phba);\r\n}\r\nvoid\r\nlpfc_mbx_cmpl_read_topology(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)\r\n{\r\nstruct lpfc_vport *vport = pmb->vport;\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nstruct lpfc_mbx_read_top *la;\r\nMAILBOX_t *mb = &pmb->u.mb;\r\nstruct lpfc_dmabuf *mp = (struct lpfc_dmabuf *) (pmb->context1);\r\nphba->sli.ring[LPFC_ELS_RING].flag &= ~LPFC_STOP_IOCB_EVENT;\r\nif (mb->mbxStatus) {\r\nlpfc_printf_log(phba, KERN_INFO, LOG_LINK_EVENT,\r\n"1307 READ_LA mbox error x%x state x%x\n",\r\nmb->mbxStatus, vport->port_state);\r\nlpfc_mbx_issue_link_down(phba);\r\nphba->link_state = LPFC_HBA_ERROR;\r\ngoto lpfc_mbx_cmpl_read_topology_free_mbuf;\r\n}\r\nla = (struct lpfc_mbx_read_top *) &pmb->u.mb.un.varReadTop;\r\nmemcpy(&phba->alpa_map[0], mp->virt, 128);\r\nspin_lock_irq(shost->host_lock);\r\nif (bf_get(lpfc_mbx_read_top_pb, la))\r\nvport->fc_flag |= FC_BYPASSED_MODE;\r\nelse\r\nvport->fc_flag &= ~FC_BYPASSED_MODE;\r\nspin_unlock_irq(shost->host_lock);\r\nif (phba->fc_eventTag <= la->eventTag) {\r\nphba->fc_stat.LinkMultiEvent++;\r\nif (bf_get(lpfc_mbx_read_top_att_type, la) == LPFC_ATT_LINK_UP)\r\nif (phba->fc_eventTag != 0)\r\nlpfc_linkdown(phba);\r\n}\r\nphba->fc_eventTag = la->eventTag;\r\nif (phba->sli_rev < LPFC_SLI_REV4) {\r\nspin_lock_irq(&phba->hbalock);\r\nif (bf_get(lpfc_mbx_read_top_mm, la))\r\nphba->sli.sli_flag |= LPFC_MENLO_MAINT;\r\nelse\r\nphba->sli.sli_flag &= ~LPFC_MENLO_MAINT;\r\nspin_unlock_irq(&phba->hbalock);\r\n}\r\nphba->link_events++;\r\nif ((bf_get(lpfc_mbx_read_top_att_type, la) == LPFC_ATT_LINK_UP) &&\r\n!(phba->sli.sli_flag & LPFC_MENLO_MAINT)) {\r\nphba->fc_stat.LinkUp++;\r\nif (phba->link_flag & LS_LOOPBACK_MODE) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_LINK_EVENT,\r\n"1306 Link Up Event in loop back mode "\r\n"x%x received Data: x%x x%x x%x x%x\n",\r\nla->eventTag, phba->fc_eventTag,\r\nbf_get(lpfc_mbx_read_top_alpa_granted,\r\nla),\r\nbf_get(lpfc_mbx_read_top_link_spd, la),\r\nphba->alpa_map[0]);\r\n} else {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_LINK_EVENT,\r\n"1303 Link Up Event x%x received "\r\n"Data: x%x x%x x%x x%x x%x x%x %d\n",\r\nla->eventTag, phba->fc_eventTag,\r\nbf_get(lpfc_mbx_read_top_alpa_granted,\r\nla),\r\nbf_get(lpfc_mbx_read_top_link_spd, la),\r\nphba->alpa_map[0],\r\nbf_get(lpfc_mbx_read_top_mm, la),\r\nbf_get(lpfc_mbx_read_top_fa, la),\r\nphba->wait_4_mlo_maint_flg);\r\n}\r\nlpfc_mbx_process_link_up(phba, la);\r\n} else if (bf_get(lpfc_mbx_read_top_att_type, la) ==\r\nLPFC_ATT_LINK_DOWN) {\r\nphba->fc_stat.LinkDown++;\r\nif (phba->link_flag & LS_LOOPBACK_MODE)\r\nlpfc_printf_log(phba, KERN_ERR, LOG_LINK_EVENT,\r\n"1308 Link Down Event in loop back mode "\r\n"x%x received "\r\n"Data: x%x x%x x%x\n",\r\nla->eventTag, phba->fc_eventTag,\r\nphba->pport->port_state, vport->fc_flag);\r\nelse\r\nlpfc_printf_log(phba, KERN_ERR, LOG_LINK_EVENT,\r\n"1305 Link Down Event x%x received "\r\n"Data: x%x x%x x%x x%x x%x\n",\r\nla->eventTag, phba->fc_eventTag,\r\nphba->pport->port_state, vport->fc_flag,\r\nbf_get(lpfc_mbx_read_top_mm, la),\r\nbf_get(lpfc_mbx_read_top_fa, la));\r\nlpfc_mbx_issue_link_down(phba);\r\n}\r\nif ((phba->sli.sli_flag & LPFC_MENLO_MAINT) &&\r\n((bf_get(lpfc_mbx_read_top_att_type, la) == LPFC_ATT_LINK_UP))) {\r\nif (phba->link_state != LPFC_LINK_DOWN) {\r\nphba->fc_stat.LinkDown++;\r\nlpfc_printf_log(phba, KERN_ERR, LOG_LINK_EVENT,\r\n"1312 Link Down Event x%x received "\r\n"Data: x%x x%x x%x\n",\r\nla->eventTag, phba->fc_eventTag,\r\nphba->pport->port_state, vport->fc_flag);\r\nlpfc_mbx_issue_link_down(phba);\r\n} else\r\nlpfc_enable_la(phba);\r\nlpfc_printf_log(phba, KERN_ERR, LOG_LINK_EVENT,\r\n"1310 Menlo Maint Mode Link up Event x%x rcvd "\r\n"Data: x%x x%x x%x\n",\r\nla->eventTag, phba->fc_eventTag,\r\nphba->pport->port_state, vport->fc_flag);\r\nif (phba->wait_4_mlo_maint_flg) {\r\nphba->wait_4_mlo_maint_flg = 0;\r\nwake_up_interruptible(&phba->wait_4_mlo_m_q);\r\n}\r\n}\r\nif ((phba->sli_rev < LPFC_SLI_REV4) &&\r\nbf_get(lpfc_mbx_read_top_fa, la)) {\r\nif (phba->sli.sli_flag & LPFC_MENLO_MAINT)\r\nlpfc_issue_clear_la(phba, vport);\r\nlpfc_printf_log(phba, KERN_INFO, LOG_LINK_EVENT,\r\n"1311 fa %d\n",\r\nbf_get(lpfc_mbx_read_top_fa, la));\r\n}\r\nlpfc_mbx_cmpl_read_topology_free_mbuf:\r\nlpfc_mbuf_free(phba, mp->virt, mp->phys);\r\nkfree(mp);\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nreturn;\r\n}\r\nvoid\r\nlpfc_mbx_cmpl_reg_login(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)\r\n{\r\nstruct lpfc_vport *vport = pmb->vport;\r\nstruct lpfc_dmabuf *mp = (struct lpfc_dmabuf *) (pmb->context1);\r\nstruct lpfc_nodelist *ndlp = (struct lpfc_nodelist *) pmb->context2;\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\npmb->context1 = NULL;\r\npmb->context2 = NULL;\r\nif (ndlp->nlp_flag & NLP_REG_LOGIN_SEND)\r\nndlp->nlp_flag &= ~NLP_REG_LOGIN_SEND;\r\nif (ndlp->nlp_flag & NLP_IGNR_REG_CMPL ||\r\nndlp->nlp_state != NLP_STE_REG_LOGIN_ISSUE) {\r\nspin_lock_irq(shost->host_lock);\r\nndlp->nlp_flag &= ~NLP_IGNR_REG_CMPL;\r\nspin_unlock_irq(shost->host_lock);\r\n} else\r\nlpfc_disc_state_machine(vport, ndlp, pmb,\r\nNLP_EVT_CMPL_REG_LOGIN);\r\nlpfc_mbuf_free(phba, mp->virt, mp->phys);\r\nkfree(mp);\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nlpfc_nlp_put(ndlp);\r\nreturn;\r\n}\r\nstatic void\r\nlpfc_mbx_cmpl_unreg_vpi(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)\r\n{\r\nMAILBOX_t *mb = &pmb->u.mb;\r\nstruct lpfc_vport *vport = pmb->vport;\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nswitch (mb->mbxStatus) {\r\ncase 0x0011:\r\ncase 0x0020:\r\nlpfc_printf_vlog(vport, KERN_INFO, LOG_NODE,\r\n"0911 cmpl_unreg_vpi, mb status = 0x%x\n",\r\nmb->mbxStatus);\r\nbreak;\r\ncase 0x9700:\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_NODE,\r\n"2798 Unreg_vpi failed vpi 0x%x, mb status = 0x%x\n",\r\nvport->vpi, mb->mbxStatus);\r\nif (!(phba->pport->load_flag & FC_UNLOADING))\r\nlpfc_workq_post_event(phba, NULL, NULL,\r\nLPFC_EVT_RESET_HBA);\r\n}\r\nspin_lock_irq(shost->host_lock);\r\nvport->vpi_state &= ~LPFC_VPI_REGISTERED;\r\nvport->fc_flag |= FC_VPORT_NEEDS_REG_VPI;\r\nspin_unlock_irq(shost->host_lock);\r\nvport->unreg_vpi_cmpl = VPORT_OK;\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nlpfc_cleanup_vports_rrqs(vport, NULL);\r\nif ((vport->load_flag & FC_UNLOADING) && (vport != phba->pport))\r\nscsi_host_put(shost);\r\n}\r\nint\r\nlpfc_mbx_unreg_vpi(struct lpfc_vport *vport)\r\n{\r\nstruct lpfc_hba *phba = vport->phba;\r\nLPFC_MBOXQ_t *mbox;\r\nint rc;\r\nmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox)\r\nreturn 1;\r\nlpfc_unreg_vpi(phba, vport->vpi, mbox);\r\nmbox->vport = vport;\r\nmbox->mbox_cmpl = lpfc_mbx_cmpl_unreg_vpi;\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_NOWAIT);\r\nif (rc == MBX_NOT_FINISHED) {\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_MBOX | LOG_VPORT,\r\n"1800 Could not issue unreg_vpi\n");\r\nmempool_free(mbox, phba->mbox_mem_pool);\r\nvport->unreg_vpi_cmpl = VPORT_ERROR;\r\nreturn rc;\r\n}\r\nreturn 0;\r\n}\r\nstatic void\r\nlpfc_mbx_cmpl_reg_vpi(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)\r\n{\r\nstruct lpfc_vport *vport = pmb->vport;\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nMAILBOX_t *mb = &pmb->u.mb;\r\nswitch (mb->mbxStatus) {\r\ncase 0x0011:\r\ncase 0x9601:\r\ncase 0x9602:\r\nlpfc_printf_vlog(vport, KERN_INFO, LOG_NODE,\r\n"0912 cmpl_reg_vpi, mb status = 0x%x\n",\r\nmb->mbxStatus);\r\nlpfc_vport_set_state(vport, FC_VPORT_FAILED);\r\nspin_lock_irq(shost->host_lock);\r\nvport->fc_flag &= ~(FC_FABRIC | FC_PUBLIC_LOOP);\r\nspin_unlock_irq(shost->host_lock);\r\nvport->fc_myDID = 0;\r\ngoto out;\r\n}\r\nspin_lock_irq(shost->host_lock);\r\nvport->vpi_state |= LPFC_VPI_REGISTERED;\r\nvport->fc_flag &= ~FC_VPORT_NEEDS_REG_VPI;\r\nspin_unlock_irq(shost->host_lock);\r\nvport->num_disc_nodes = 0;\r\nif (vport->fc_npr_cnt)\r\nlpfc_els_disc_plogi(vport);\r\nif (!vport->num_disc_nodes) {\r\nspin_lock_irq(shost->host_lock);\r\nvport->fc_flag &= ~FC_NDISC_ACTIVE;\r\nspin_unlock_irq(shost->host_lock);\r\nlpfc_can_disctmo(vport);\r\n}\r\nvport->port_state = LPFC_VPORT_READY;\r\nout:\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nreturn;\r\n}\r\nvoid\r\nlpfc_create_static_vport(struct lpfc_hba *phba)\r\n{\r\nLPFC_MBOXQ_t *pmb = NULL;\r\nMAILBOX_t *mb;\r\nstruct static_vport_info *vport_info;\r\nint mbx_wait_rc = 0, i;\r\nstruct fc_vport_identifiers vport_id;\r\nstruct fc_vport *new_fc_vport;\r\nstruct Scsi_Host *shost;\r\nstruct lpfc_vport *vport;\r\nuint16_t offset = 0;\r\nuint8_t *vport_buff;\r\nstruct lpfc_dmabuf *mp;\r\nuint32_t byte_count = 0;\r\npmb = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!pmb) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"0542 lpfc_create_static_vport failed to"\r\n" allocate mailbox memory\n");\r\nreturn;\r\n}\r\nmemset(pmb, 0, sizeof(LPFC_MBOXQ_t));\r\nmb = &pmb->u.mb;\r\nvport_info = kzalloc(sizeof(struct static_vport_info), GFP_KERNEL);\r\nif (!vport_info) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"0543 lpfc_create_static_vport failed to"\r\n" allocate vport_info\n");\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nreturn;\r\n}\r\nvport_buff = (uint8_t *) vport_info;\r\ndo {\r\nif (pmb->context1) {\r\nmp = (struct lpfc_dmabuf *)pmb->context1;\r\nlpfc_mbuf_free(phba, mp->virt, mp->phys);\r\nkfree(mp);\r\n}\r\nif (lpfc_dump_static_vport(phba, pmb, offset))\r\ngoto out;\r\npmb->vport = phba->pport;\r\nmbx_wait_rc = lpfc_sli_issue_mbox_wait(phba, pmb,\r\nLPFC_MBOX_TMO);\r\nif ((mbx_wait_rc != MBX_SUCCESS) || mb->mbxStatus) {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\r\n"0544 lpfc_create_static_vport failed to"\r\n" issue dump mailbox command ret 0x%x "\r\n"status 0x%x\n",\r\nmbx_wait_rc, mb->mbxStatus);\r\ngoto out;\r\n}\r\nif (phba->sli_rev == LPFC_SLI_REV4) {\r\nbyte_count = pmb->u.mqe.un.mb_words[5];\r\nmp = (struct lpfc_dmabuf *)pmb->context1;\r\nif (byte_count > sizeof(struct static_vport_info) -\r\noffset)\r\nbyte_count = sizeof(struct static_vport_info)\r\n- offset;\r\nmemcpy(vport_buff + offset, mp->virt, byte_count);\r\noffset += byte_count;\r\n} else {\r\nif (mb->un.varDmp.word_cnt >\r\nsizeof(struct static_vport_info) - offset)\r\nmb->un.varDmp.word_cnt =\r\nsizeof(struct static_vport_info)\r\n- offset;\r\nbyte_count = mb->un.varDmp.word_cnt;\r\nlpfc_sli_pcimem_bcopy(((uint8_t *)mb) + DMP_RSP_OFFSET,\r\nvport_buff + offset,\r\nbyte_count);\r\noffset += byte_count;\r\n}\r\n} while (byte_count &&\r\noffset < sizeof(struct static_vport_info));\r\nif ((le32_to_cpu(vport_info->signature) != VPORT_INFO_SIG) ||\r\n((le32_to_cpu(vport_info->rev) & VPORT_INFO_REV_MASK)\r\n!= VPORT_INFO_REV)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"0545 lpfc_create_static_vport bad"\r\n" information header 0x%x 0x%x\n",\r\nle32_to_cpu(vport_info->signature),\r\nle32_to_cpu(vport_info->rev) & VPORT_INFO_REV_MASK);\r\ngoto out;\r\n}\r\nshost = lpfc_shost_from_vport(phba->pport);\r\nfor (i = 0; i < MAX_STATIC_VPORT_COUNT; i++) {\r\nmemset(&vport_id, 0, sizeof(vport_id));\r\nvport_id.port_name = wwn_to_u64(vport_info->vport_list[i].wwpn);\r\nvport_id.node_name = wwn_to_u64(vport_info->vport_list[i].wwnn);\r\nif (!vport_id.port_name || !vport_id.node_name)\r\ncontinue;\r\nvport_id.roles = FC_PORT_ROLE_FCP_INITIATOR;\r\nvport_id.vport_type = FC_PORTTYPE_NPIV;\r\nvport_id.disable = false;\r\nnew_fc_vport = fc_vport_create(shost, 0, &vport_id);\r\nif (!new_fc_vport) {\r\nlpfc_printf_log(phba, KERN_WARNING, LOG_INIT,\r\n"0546 lpfc_create_static_vport failed to"\r\n" create vport\n");\r\ncontinue;\r\n}\r\nvport = *(struct lpfc_vport **)new_fc_vport->dd_data;\r\nvport->vport_flag |= STATIC_VPORT;\r\n}\r\nout:\r\nkfree(vport_info);\r\nif (mbx_wait_rc != MBX_TIMEOUT) {\r\nif (pmb->context1) {\r\nmp = (struct lpfc_dmabuf *)pmb->context1;\r\nlpfc_mbuf_free(phba, mp->virt, mp->phys);\r\nkfree(mp);\r\n}\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\n}\r\nreturn;\r\n}\r\nvoid\r\nlpfc_mbx_cmpl_fabric_reg_login(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)\r\n{\r\nstruct lpfc_vport *vport = pmb->vport;\r\nMAILBOX_t *mb = &pmb->u.mb;\r\nstruct lpfc_dmabuf *mp = (struct lpfc_dmabuf *) (pmb->context1);\r\nstruct lpfc_nodelist *ndlp;\r\nstruct Scsi_Host *shost;\r\nndlp = (struct lpfc_nodelist *) pmb->context2;\r\npmb->context1 = NULL;\r\npmb->context2 = NULL;\r\nif (mb->mbxStatus) {\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_MBOX,\r\n"0258 Register Fabric login error: 0x%x\n",\r\nmb->mbxStatus);\r\nlpfc_mbuf_free(phba, mp->virt, mp->phys);\r\nkfree(mp);\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nif (phba->fc_topology == LPFC_TOPOLOGY_LOOP) {\r\nlpfc_disc_list_loopmap(vport);\r\nlpfc_disc_start(vport);\r\nlpfc_nlp_put(ndlp);\r\nreturn;\r\n}\r\nlpfc_vport_set_state(vport, FC_VPORT_FAILED);\r\nlpfc_nlp_put(ndlp);\r\nreturn;\r\n}\r\nif (phba->sli_rev < LPFC_SLI_REV4)\r\nndlp->nlp_rpi = mb->un.varWords[0];\r\nndlp->nlp_flag |= NLP_RPI_REGISTERED;\r\nndlp->nlp_type |= NLP_FABRIC;\r\nlpfc_nlp_set_state(vport, ndlp, NLP_STE_UNMAPPED_NODE);\r\nif (vport->port_state == LPFC_FABRIC_CFG_LINK) {\r\nif (!(vport->fc_flag & FC_LOGO_RCVD_DID_CHNG))\r\nlpfc_start_fdiscs(phba);\r\nelse {\r\nshost = lpfc_shost_from_vport(vport);\r\nspin_lock_irq(shost->host_lock);\r\nvport->fc_flag &= ~FC_LOGO_RCVD_DID_CHNG ;\r\nspin_unlock_irq(shost->host_lock);\r\n}\r\nlpfc_do_scr_ns_plogi(phba, vport);\r\n}\r\nlpfc_mbuf_free(phba, mp->virt, mp->phys);\r\nkfree(mp);\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nlpfc_nlp_put(ndlp);\r\nreturn;\r\n}\r\nvoid\r\nlpfc_mbx_cmpl_ns_reg_login(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)\r\n{\r\nMAILBOX_t *mb = &pmb->u.mb;\r\nstruct lpfc_dmabuf *mp = (struct lpfc_dmabuf *) (pmb->context1);\r\nstruct lpfc_nodelist *ndlp = (struct lpfc_nodelist *) pmb->context2;\r\nstruct lpfc_vport *vport = pmb->vport;\r\npmb->context1 = NULL;\r\npmb->context2 = NULL;\r\nif (mb->mbxStatus) {\r\nout:\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_ELS,\r\n"0260 Register NameServer error: 0x%x\n",\r\nmb->mbxStatus);\r\nlpfc_nlp_put(ndlp);\r\nlpfc_mbuf_free(phba, mp->virt, mp->phys);\r\nkfree(mp);\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nlpfc_nlp_not_used(ndlp);\r\nif (phba->fc_topology == LPFC_TOPOLOGY_LOOP) {\r\nlpfc_disc_list_loopmap(vport);\r\nlpfc_disc_start(vport);\r\nreturn;\r\n}\r\nlpfc_vport_set_state(vport, FC_VPORT_FAILED);\r\nreturn;\r\n}\r\nif (phba->sli_rev < LPFC_SLI_REV4)\r\nndlp->nlp_rpi = mb->un.varWords[0];\r\nndlp->nlp_flag |= NLP_RPI_REGISTERED;\r\nndlp->nlp_type |= NLP_FABRIC;\r\nlpfc_nlp_set_state(vport, ndlp, NLP_STE_UNMAPPED_NODE);\r\nif (vport->port_state < LPFC_VPORT_READY) {\r\nlpfc_ns_cmd(vport, SLI_CTNS_RFF_ID, 0, 0);\r\nlpfc_ns_cmd(vport, SLI_CTNS_RNN_ID, 0, 0);\r\nlpfc_ns_cmd(vport, SLI_CTNS_RSNN_NN, 0, 0);\r\nlpfc_ns_cmd(vport, SLI_CTNS_RSPN_ID, 0, 0);\r\nlpfc_ns_cmd(vport, SLI_CTNS_RFT_ID, 0, 0);\r\nlpfc_issue_els_scr(vport, SCR_DID, 0);\r\n}\r\nvport->fc_ns_retry = 0;\r\nif (lpfc_ns_cmd(vport, SLI_CTNS_GID_FT, 0, 0)) {\r\ngoto out;\r\n}\r\nlpfc_nlp_put(ndlp);\r\nlpfc_mbuf_free(phba, mp->virt, mp->phys);\r\nkfree(mp);\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nreturn;\r\n}\r\nstatic void\r\nlpfc_register_remote_port(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp)\r\n{\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nstruct fc_rport *rport;\r\nstruct lpfc_rport_data *rdata;\r\nstruct fc_rport_identifiers rport_ids;\r\nstruct lpfc_hba *phba = vport->phba;\r\nrport_ids.node_name = wwn_to_u64(ndlp->nlp_nodename.u.wwn);\r\nrport_ids.port_name = wwn_to_u64(ndlp->nlp_portname.u.wwn);\r\nrport_ids.port_id = ndlp->nlp_DID;\r\nrport_ids.roles = FC_RPORT_ROLE_UNKNOWN;\r\nif (ndlp->rport && ndlp->rport->dd_data &&\r\n((struct lpfc_rport_data *) ndlp->rport->dd_data)->pnode == ndlp)\r\nlpfc_nlp_put(ndlp);\r\nlpfc_debugfs_disc_trc(vport, LPFC_DISC_TRC_RPORT,\r\n"rport add: did:x%x flg:x%x type x%x",\r\nndlp->nlp_DID, ndlp->nlp_flag, ndlp->nlp_type);\r\nif (vport->load_flag & FC_UNLOADING)\r\nreturn;\r\nndlp->rport = rport = fc_remote_port_add(shost, 0, &rport_ids);\r\nif (!rport || !get_device(&rport->dev)) {\r\ndev_printk(KERN_WARNING, &phba->pcidev->dev,\r\n"Warning: fc_remote_port_add failed\n");\r\nreturn;\r\n}\r\nrport->maxframe_size = ndlp->nlp_maxframe;\r\nrport->supported_classes = ndlp->nlp_class_sup;\r\nrdata = rport->dd_data;\r\nrdata->pnode = lpfc_nlp_get(ndlp);\r\nif (ndlp->nlp_type & NLP_FCP_TARGET)\r\nrport_ids.roles |= FC_RPORT_ROLE_FCP_TARGET;\r\nif (ndlp->nlp_type & NLP_FCP_INITIATOR)\r\nrport_ids.roles |= FC_RPORT_ROLE_FCP_INITIATOR;\r\nif (rport_ids.roles != FC_RPORT_ROLE_UNKNOWN)\r\nfc_remote_port_rolechg(rport, rport_ids.roles);\r\nlpfc_printf_vlog(ndlp->vport, KERN_INFO, LOG_NODE,\r\n"3183 rport register x%06x, rport %p role x%x\n",\r\nndlp->nlp_DID, rport, rport_ids.roles);\r\nif ((rport->scsi_target_id != -1) &&\r\n(rport->scsi_target_id < LPFC_MAX_TARGET)) {\r\nndlp->nlp_sid = rport->scsi_target_id;\r\n}\r\nreturn;\r\n}\r\nstatic void\r\nlpfc_unregister_remote_port(struct lpfc_nodelist *ndlp)\r\n{\r\nstruct fc_rport *rport = ndlp->rport;\r\nlpfc_debugfs_disc_trc(ndlp->vport, LPFC_DISC_TRC_RPORT,\r\n"rport delete: did:x%x flg:x%x type x%x",\r\nndlp->nlp_DID, ndlp->nlp_flag, ndlp->nlp_type);\r\nlpfc_printf_vlog(ndlp->vport, KERN_INFO, LOG_NODE,\r\n"3184 rport unregister x%06x, rport %p\n",\r\nndlp->nlp_DID, rport);\r\nfc_remote_port_delete(rport);\r\nreturn;\r\n}\r\nstatic void\r\nlpfc_nlp_counters(struct lpfc_vport *vport, int state, int count)\r\n{\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nspin_lock_irq(shost->host_lock);\r\nswitch (state) {\r\ncase NLP_STE_UNUSED_NODE:\r\nvport->fc_unused_cnt += count;\r\nbreak;\r\ncase NLP_STE_PLOGI_ISSUE:\r\nvport->fc_plogi_cnt += count;\r\nbreak;\r\ncase NLP_STE_ADISC_ISSUE:\r\nvport->fc_adisc_cnt += count;\r\nbreak;\r\ncase NLP_STE_REG_LOGIN_ISSUE:\r\nvport->fc_reglogin_cnt += count;\r\nbreak;\r\ncase NLP_STE_PRLI_ISSUE:\r\nvport->fc_prli_cnt += count;\r\nbreak;\r\ncase NLP_STE_UNMAPPED_NODE:\r\nvport->fc_unmap_cnt += count;\r\nbreak;\r\ncase NLP_STE_MAPPED_NODE:\r\nvport->fc_map_cnt += count;\r\nbreak;\r\ncase NLP_STE_NPR_NODE:\r\nvport->fc_npr_cnt += count;\r\nbreak;\r\n}\r\nspin_unlock_irq(shost->host_lock);\r\n}\r\nstatic void\r\nlpfc_nlp_state_cleanup(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp,\r\nint old_state, int new_state)\r\n{\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nif (new_state == NLP_STE_UNMAPPED_NODE) {\r\nndlp->nlp_flag &= ~NLP_NODEV_REMOVE;\r\nndlp->nlp_type |= NLP_FC_NODE;\r\n}\r\nif (new_state == NLP_STE_MAPPED_NODE)\r\nndlp->nlp_flag &= ~NLP_NODEV_REMOVE;\r\nif (new_state == NLP_STE_NPR_NODE)\r\nndlp->nlp_flag &= ~NLP_RCV_PLOGI;\r\nif (ndlp->rport && (old_state == NLP_STE_MAPPED_NODE ||\r\nold_state == NLP_STE_UNMAPPED_NODE)) {\r\nvport->phba->nport_event_cnt++;\r\nlpfc_unregister_remote_port(ndlp);\r\n}\r\nif (new_state == NLP_STE_MAPPED_NODE ||\r\nnew_state == NLP_STE_UNMAPPED_NODE) {\r\nvport->phba->nport_event_cnt++;\r\nlpfc_register_remote_port(vport, ndlp);\r\n}\r\nif ((new_state == NLP_STE_MAPPED_NODE) &&\r\n(vport->stat_data_enabled)) {\r\nndlp->lat_data = kcalloc(LPFC_MAX_BUCKET_COUNT,\r\nsizeof(struct lpfc_scsicmd_bkt),\r\nGFP_KERNEL);\r\nif (!ndlp->lat_data)\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_NODE,\r\n"0286 lpfc_nlp_state_cleanup failed to "\r\n"allocate statistical data buffer DID "\r\n"0x%x\n", ndlp->nlp_DID);\r\n}\r\nif (new_state == NLP_STE_MAPPED_NODE &&\r\n(!ndlp->rport ||\r\nndlp->rport->scsi_target_id == -1 ||\r\nndlp->rport->scsi_target_id >= LPFC_MAX_TARGET)) {\r\nspin_lock_irq(shost->host_lock);\r\nndlp->nlp_flag |= NLP_TGT_NO_SCSIID;\r\nspin_unlock_irq(shost->host_lock);\r\nlpfc_nlp_set_state(vport, ndlp, NLP_STE_UNMAPPED_NODE);\r\n}\r\n}\r\nstatic char *\r\nlpfc_nlp_state_name(char *buffer, size_t size, int state)\r\n{\r\nstatic char *states[] = {\r\n[NLP_STE_UNUSED_NODE] = "UNUSED",\r\n[NLP_STE_PLOGI_ISSUE] = "PLOGI",\r\n[NLP_STE_ADISC_ISSUE] = "ADISC",\r\n[NLP_STE_REG_LOGIN_ISSUE] = "REGLOGIN",\r\n[NLP_STE_PRLI_ISSUE] = "PRLI",\r\n[NLP_STE_LOGO_ISSUE] = "LOGO",\r\n[NLP_STE_UNMAPPED_NODE] = "UNMAPPED",\r\n[NLP_STE_MAPPED_NODE] = "MAPPED",\r\n[NLP_STE_NPR_NODE] = "NPR",\r\n};\r\nif (state < NLP_STE_MAX_STATE && states[state])\r\nstrlcpy(buffer, states[state], size);\r\nelse\r\nsnprintf(buffer, size, "unknown (%d)", state);\r\nreturn buffer;\r\n}\r\nvoid\r\nlpfc_nlp_set_state(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp,\r\nint state)\r\n{\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nint old_state = ndlp->nlp_state;\r\nchar name1[16], name2[16];\r\nlpfc_printf_vlog(vport, KERN_INFO, LOG_NODE,\r\n"0904 NPort state transition x%06x, %s -> %s\n",\r\nndlp->nlp_DID,\r\nlpfc_nlp_state_name(name1, sizeof(name1), old_state),\r\nlpfc_nlp_state_name(name2, sizeof(name2), state));\r\nlpfc_debugfs_disc_trc(vport, LPFC_DISC_TRC_NODE,\r\n"node statechg did:x%x old:%d ste:%d",\r\nndlp->nlp_DID, old_state, state);\r\nif (old_state == NLP_STE_NPR_NODE &&\r\nstate != NLP_STE_NPR_NODE)\r\nlpfc_cancel_retry_delay_tmo(vport, ndlp);\r\nif (old_state == NLP_STE_UNMAPPED_NODE) {\r\nndlp->nlp_flag &= ~NLP_TGT_NO_SCSIID;\r\nndlp->nlp_type &= ~NLP_FC_NODE;\r\n}\r\nif (list_empty(&ndlp->nlp_listp)) {\r\nspin_lock_irq(shost->host_lock);\r\nlist_add_tail(&ndlp->nlp_listp, &vport->fc_nodes);\r\nspin_unlock_irq(shost->host_lock);\r\n} else if (old_state)\r\nlpfc_nlp_counters(vport, old_state, -1);\r\nndlp->nlp_state = state;\r\nlpfc_nlp_counters(vport, state, 1);\r\nlpfc_nlp_state_cleanup(vport, ndlp, old_state, state);\r\n}\r\nvoid\r\nlpfc_enqueue_node(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp)\r\n{\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nif (list_empty(&ndlp->nlp_listp)) {\r\nspin_lock_irq(shost->host_lock);\r\nlist_add_tail(&ndlp->nlp_listp, &vport->fc_nodes);\r\nspin_unlock_irq(shost->host_lock);\r\n}\r\n}\r\nvoid\r\nlpfc_dequeue_node(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp)\r\n{\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nlpfc_cancel_retry_delay_tmo(vport, ndlp);\r\nif (ndlp->nlp_state && !list_empty(&ndlp->nlp_listp))\r\nlpfc_nlp_counters(vport, ndlp->nlp_state, -1);\r\nspin_lock_irq(shost->host_lock);\r\nlist_del_init(&ndlp->nlp_listp);\r\nspin_unlock_irq(shost->host_lock);\r\nlpfc_nlp_state_cleanup(vport, ndlp, ndlp->nlp_state,\r\nNLP_STE_UNUSED_NODE);\r\n}\r\nstatic void\r\nlpfc_disable_node(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp)\r\n{\r\nlpfc_cancel_retry_delay_tmo(vport, ndlp);\r\nif (ndlp->nlp_state && !list_empty(&ndlp->nlp_listp))\r\nlpfc_nlp_counters(vport, ndlp->nlp_state, -1);\r\nlpfc_nlp_state_cleanup(vport, ndlp, ndlp->nlp_state,\r\nNLP_STE_UNUSED_NODE);\r\n}\r\nstatic inline void\r\nlpfc_initialize_node(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp,\r\nuint32_t did)\r\n{\r\nINIT_LIST_HEAD(&ndlp->els_retry_evt.evt_listp);\r\nINIT_LIST_HEAD(&ndlp->dev_loss_evt.evt_listp);\r\ninit_timer(&ndlp->nlp_delayfunc);\r\nndlp->nlp_delayfunc.function = lpfc_els_retry_delay;\r\nndlp->nlp_delayfunc.data = (unsigned long)ndlp;\r\nndlp->nlp_DID = did;\r\nndlp->vport = vport;\r\nndlp->phba = vport->phba;\r\nndlp->nlp_sid = NLP_NO_SID;\r\nkref_init(&ndlp->kref);\r\nNLP_INT_NODE_ACT(ndlp);\r\natomic_set(&ndlp->cmd_pending, 0);\r\nndlp->cmd_qdepth = vport->cfg_tgt_queue_depth;\r\n}\r\nstruct lpfc_nodelist *\r\nlpfc_enable_node(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp,\r\nint state)\r\n{\r\nstruct lpfc_hba *phba = vport->phba;\r\nuint32_t did;\r\nunsigned long flags;\r\nif (!ndlp)\r\nreturn NULL;\r\nspin_lock_irqsave(&phba->ndlp_lock, flags);\r\nif (NLP_CHK_FREE_REQ(ndlp)) {\r\nspin_unlock_irqrestore(&phba->ndlp_lock, flags);\r\nlpfc_printf_vlog(vport, KERN_WARNING, LOG_NODE,\r\n"0277 lpfc_enable_node: ndlp:x%p "\r\n"usgmap:x%x refcnt:%d\n",\r\n(void *)ndlp, ndlp->nlp_usg_map,\r\natomic_read(&ndlp->kref.refcount));\r\nreturn NULL;\r\n}\r\nif (NLP_CHK_NODE_ACT(ndlp)) {\r\nspin_unlock_irqrestore(&phba->ndlp_lock, flags);\r\nlpfc_printf_vlog(vport, KERN_WARNING, LOG_NODE,\r\n"0278 lpfc_enable_node: ndlp:x%p "\r\n"usgmap:x%x refcnt:%d\n",\r\n(void *)ndlp, ndlp->nlp_usg_map,\r\natomic_read(&ndlp->kref.refcount));\r\nreturn NULL;\r\n}\r\ndid = ndlp->nlp_DID;\r\nmemset((((char *)ndlp) + sizeof (struct list_head)), 0,\r\nsizeof (struct lpfc_nodelist) - sizeof (struct list_head));\r\nlpfc_initialize_node(vport, ndlp, did);\r\nspin_unlock_irqrestore(&phba->ndlp_lock, flags);\r\nif (vport->phba->sli_rev == LPFC_SLI_REV4)\r\nndlp->nlp_rpi = lpfc_sli4_alloc_rpi(vport->phba);\r\nif (state != NLP_STE_UNUSED_NODE)\r\nlpfc_nlp_set_state(vport, ndlp, state);\r\nlpfc_debugfs_disc_trc(vport, LPFC_DISC_TRC_NODE,\r\n"node enable: did:x%x",\r\nndlp->nlp_DID, 0, 0);\r\nreturn ndlp;\r\n}\r\nvoid\r\nlpfc_drop_node(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp)\r\n{\r\nif (ndlp->nlp_state == NLP_STE_UNUSED_NODE)\r\nreturn;\r\nlpfc_nlp_set_state(vport, ndlp, NLP_STE_UNUSED_NODE);\r\nif (vport->phba->sli_rev == LPFC_SLI_REV4)\r\nlpfc_cleanup_vports_rrqs(vport, ndlp);\r\nlpfc_nlp_put(ndlp);\r\nreturn;\r\n}\r\nvoid\r\nlpfc_set_disctmo(struct lpfc_vport *vport)\r\n{\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nstruct lpfc_hba *phba = vport->phba;\r\nuint32_t tmo;\r\nif (vport->port_state == LPFC_LOCAL_CFG_LINK) {\r\ntmo = (((phba->fc_edtov + 999) / 1000) + 1);\r\n} else {\r\ntmo = ((phba->fc_ratov * 3) + 3);\r\n}\r\nif (!timer_pending(&vport->fc_disctmo)) {\r\nlpfc_debugfs_disc_trc(vport, LPFC_DISC_TRC_ELS_CMD,\r\n"set disc timer: tmo:x%x state:x%x flg:x%x",\r\ntmo, vport->port_state, vport->fc_flag);\r\n}\r\nmod_timer(&vport->fc_disctmo, jiffies + msecs_to_jiffies(1000 * tmo));\r\nspin_lock_irq(shost->host_lock);\r\nvport->fc_flag |= FC_DISC_TMO;\r\nspin_unlock_irq(shost->host_lock);\r\nlpfc_printf_vlog(vport, KERN_INFO, LOG_DISCOVERY,\r\n"0247 Start Discovery Timer state x%x "\r\n"Data: x%x x%lx x%x x%x\n",\r\nvport->port_state, tmo,\r\n(unsigned long)&vport->fc_disctmo, vport->fc_plogi_cnt,\r\nvport->fc_adisc_cnt);\r\nreturn;\r\n}\r\nint\r\nlpfc_can_disctmo(struct lpfc_vport *vport)\r\n{\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nunsigned long iflags;\r\nlpfc_debugfs_disc_trc(vport, LPFC_DISC_TRC_ELS_CMD,\r\n"can disc timer: state:x%x rtry:x%x flg:x%x",\r\nvport->port_state, vport->fc_ns_retry, vport->fc_flag);\r\nif (vport->fc_flag & FC_DISC_TMO) {\r\nspin_lock_irqsave(shost->host_lock, iflags);\r\nvport->fc_flag &= ~FC_DISC_TMO;\r\nspin_unlock_irqrestore(shost->host_lock, iflags);\r\ndel_timer_sync(&vport->fc_disctmo);\r\nspin_lock_irqsave(&vport->work_port_lock, iflags);\r\nvport->work_port_events &= ~WORKER_DISC_TMO;\r\nspin_unlock_irqrestore(&vport->work_port_lock, iflags);\r\n}\r\nlpfc_printf_vlog(vport, KERN_INFO, LOG_DISCOVERY,\r\n"0248 Cancel Discovery Timer state x%x "\r\n"Data: x%x x%x x%x\n",\r\nvport->port_state, vport->fc_flag,\r\nvport->fc_plogi_cnt, vport->fc_adisc_cnt);\r\nreturn 0;\r\n}\r\nint\r\nlpfc_check_sli_ndlp(struct lpfc_hba *phba,\r\nstruct lpfc_sli_ring *pring,\r\nstruct lpfc_iocbq *iocb,\r\nstruct lpfc_nodelist *ndlp)\r\n{\r\nstruct lpfc_sli *psli = &phba->sli;\r\nIOCB_t *icmd = &iocb->iocb;\r\nstruct lpfc_vport *vport = ndlp->vport;\r\nif (iocb->vport != vport)\r\nreturn 0;\r\nif (pring->ringno == LPFC_ELS_RING) {\r\nswitch (icmd->ulpCommand) {\r\ncase CMD_GEN_REQUEST64_CR:\r\nif (iocb->context_un.ndlp == ndlp)\r\nreturn 1;\r\ncase CMD_ELS_REQUEST64_CR:\r\nif (icmd->un.elsreq64.remoteID == ndlp->nlp_DID)\r\nreturn 1;\r\ncase CMD_XMIT_ELS_RSP64_CX:\r\nif (iocb->context1 == (uint8_t *) ndlp)\r\nreturn 1;\r\n}\r\n} else if (pring->ringno == psli->extra_ring) {\r\n} else if (pring->ringno == psli->fcp_ring) {\r\nif ((ndlp->nlp_type & NLP_FCP_TARGET) &&\r\n(ndlp->nlp_flag & NLP_DELAY_TMO)) {\r\nreturn 0;\r\n}\r\nif (icmd->ulpContext == (volatile ushort)ndlp->nlp_rpi) {\r\nreturn 1;\r\n}\r\n} else if (pring->ringno == psli->next_ring) {\r\n}\r\nreturn 0;\r\n}\r\nstatic int\r\nlpfc_no_rpi(struct lpfc_hba *phba, struct lpfc_nodelist *ndlp)\r\n{\r\nLIST_HEAD(completions);\r\nstruct lpfc_sli *psli;\r\nstruct lpfc_sli_ring *pring;\r\nstruct lpfc_iocbq *iocb, *next_iocb;\r\nuint32_t i;\r\nlpfc_fabric_abort_nport(ndlp);\r\npsli = &phba->sli;\r\nif (ndlp->nlp_flag & NLP_RPI_REGISTERED) {\r\nfor (i = 0; i < psli->num_rings; i++) {\r\npring = &psli->ring[i];\r\nspin_lock_irq(&phba->hbalock);\r\nlist_for_each_entry_safe(iocb, next_iocb, &pring->txq,\r\nlist) {\r\nif ((lpfc_check_sli_ndlp(phba, pring, iocb,\r\nndlp))) {\r\nlist_move_tail(&iocb->list,\r\n&completions);\r\n}\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\n}\r\n}\r\nlpfc_sli_cancel_iocbs(phba, &completions, IOSTAT_LOCAL_REJECT,\r\nIOERR_SLI_ABORTED);\r\nreturn 0;\r\n}\r\nvoid\r\nlpfc_nlp_logo_unreg(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)\r\n{\r\nstruct lpfc_vport *vport = pmb->vport;\r\nstruct lpfc_nodelist *ndlp;\r\nndlp = (struct lpfc_nodelist *)(pmb->context1);\r\nif (!ndlp)\r\nreturn;\r\nlpfc_issue_els_logo(vport, ndlp, 0);\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\n}\r\nint\r\nlpfc_unreg_rpi(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp)\r\n{\r\nstruct lpfc_hba *phba = vport->phba;\r\nLPFC_MBOXQ_t *mbox;\r\nint rc;\r\nuint16_t rpi;\r\nif (ndlp->nlp_flag & NLP_RPI_REGISTERED ||\r\nndlp->nlp_flag & NLP_REG_LOGIN_SEND) {\r\nif (ndlp->nlp_flag & NLP_REG_LOGIN_SEND)\r\nlpfc_printf_vlog(vport, KERN_INFO, LOG_SLI,\r\n"3366 RPI x%x needs to be "\r\n"unregistered nlp_flag x%x "\r\n"did x%x\n",\r\nndlp->nlp_rpi, ndlp->nlp_flag,\r\nndlp->nlp_DID);\r\nmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (mbox) {\r\nrpi = ndlp->nlp_rpi;\r\nif (phba->sli_rev == LPFC_SLI_REV4)\r\nrpi = phba->sli4_hba.rpi_ids[ndlp->nlp_rpi];\r\nlpfc_unreg_login(phba, vport->vpi, rpi, mbox);\r\nmbox->vport = vport;\r\nif (ndlp->nlp_flag & NLP_ISSUE_LOGO) {\r\nmbox->context1 = ndlp;\r\nmbox->mbox_cmpl = lpfc_nlp_logo_unreg;\r\n} else {\r\nmbox->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\n}\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_NOWAIT);\r\nif (rc == MBX_NOT_FINISHED)\r\nmempool_free(mbox, phba->mbox_mem_pool);\r\n}\r\nlpfc_no_rpi(phba, ndlp);\r\nif (phba->sli_rev != LPFC_SLI_REV4)\r\nndlp->nlp_rpi = 0;\r\nndlp->nlp_flag &= ~NLP_RPI_REGISTERED;\r\nndlp->nlp_flag &= ~NLP_NPR_ADISC;\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nvoid\r\nlpfc_unreg_hba_rpis(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_vport **vports;\r\nstruct lpfc_nodelist *ndlp;\r\nstruct Scsi_Host *shost;\r\nint i;\r\nvports = lpfc_create_vport_work_array(phba);\r\nif (!vports) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_DISCOVERY,\r\n"2884 Vport array allocation failed \n");\r\nreturn;\r\n}\r\nfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++) {\r\nshost = lpfc_shost_from_vport(vports[i]);\r\nspin_lock_irq(shost->host_lock);\r\nlist_for_each_entry(ndlp, &vports[i]->fc_nodes, nlp_listp) {\r\nif (ndlp->nlp_flag & NLP_RPI_REGISTERED) {\r\nspin_unlock_irq(shost->host_lock);\r\nlpfc_unreg_rpi(vports[i], ndlp);\r\nspin_lock_irq(shost->host_lock);\r\n}\r\n}\r\nspin_unlock_irq(shost->host_lock);\r\n}\r\nlpfc_destroy_vport_work_array(phba, vports);\r\n}\r\nvoid\r\nlpfc_unreg_all_rpis(struct lpfc_vport *vport)\r\n{\r\nstruct lpfc_hba *phba = vport->phba;\r\nLPFC_MBOXQ_t *mbox;\r\nint rc;\r\nif (phba->sli_rev == LPFC_SLI_REV4) {\r\nlpfc_sli4_unreg_all_rpis(vport);\r\nreturn;\r\n}\r\nmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (mbox) {\r\nlpfc_unreg_login(phba, vport->vpi, LPFC_UNREG_ALL_RPIS_VPORT,\r\nmbox);\r\nmbox->vport = vport;\r\nmbox->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\nmbox->context1 = NULL;\r\nrc = lpfc_sli_issue_mbox_wait(phba, mbox, LPFC_MBOX_TMO);\r\nif (rc != MBX_TIMEOUT)\r\nmempool_free(mbox, phba->mbox_mem_pool);\r\nif ((rc == MBX_TIMEOUT) || (rc == MBX_NOT_FINISHED))\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_MBOX | LOG_VPORT,\r\n"1836 Could not issue "\r\n"unreg_login(all_rpis) status %d\n", rc);\r\n}\r\n}\r\nvoid\r\nlpfc_unreg_default_rpis(struct lpfc_vport *vport)\r\n{\r\nstruct lpfc_hba *phba = vport->phba;\r\nLPFC_MBOXQ_t *mbox;\r\nint rc;\r\nmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (mbox) {\r\nlpfc_unreg_did(phba, vport->vpi, LPFC_UNREG_ALL_DFLT_RPIS,\r\nmbox);\r\nmbox->vport = vport;\r\nmbox->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\nmbox->context1 = NULL;\r\nrc = lpfc_sli_issue_mbox_wait(phba, mbox, LPFC_MBOX_TMO);\r\nif (rc != MBX_TIMEOUT)\r\nmempool_free(mbox, phba->mbox_mem_pool);\r\nif ((rc == MBX_TIMEOUT) || (rc == MBX_NOT_FINISHED))\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_MBOX | LOG_VPORT,\r\n"1815 Could not issue "\r\n"unreg_did (default rpis) status %d\n",\r\nrc);\r\n}\r\n}\r\nstatic int\r\nlpfc_cleanup_node(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp)\r\n{\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nstruct lpfc_hba *phba = vport->phba;\r\nLPFC_MBOXQ_t *mb, *nextmb;\r\nstruct lpfc_dmabuf *mp;\r\nlpfc_printf_vlog(vport, KERN_INFO, LOG_NODE,\r\n"0900 Cleanup node for NPort x%x "\r\n"Data: x%x x%x x%x\n",\r\nndlp->nlp_DID, ndlp->nlp_flag,\r\nndlp->nlp_state, ndlp->nlp_rpi);\r\nif (NLP_CHK_FREE_REQ(ndlp)) {\r\nlpfc_printf_vlog(vport, KERN_WARNING, LOG_NODE,\r\n"0280 lpfc_cleanup_node: ndlp:x%p "\r\n"usgmap:x%x refcnt:%d\n",\r\n(void *)ndlp, ndlp->nlp_usg_map,\r\natomic_read(&ndlp->kref.refcount));\r\nlpfc_dequeue_node(vport, ndlp);\r\n} else {\r\nlpfc_printf_vlog(vport, KERN_WARNING, LOG_NODE,\r\n"0281 lpfc_cleanup_node: ndlp:x%p "\r\n"usgmap:x%x refcnt:%d\n",\r\n(void *)ndlp, ndlp->nlp_usg_map,\r\natomic_read(&ndlp->kref.refcount));\r\nlpfc_disable_node(vport, ndlp);\r\n}\r\nif ((mb = phba->sli.mbox_active)) {\r\nif ((mb->u.mb.mbxCommand == MBX_REG_LOGIN64) &&\r\n!(mb->mbox_flag & LPFC_MBX_IMED_UNREG) &&\r\n(ndlp == (struct lpfc_nodelist *) mb->context2)) {\r\nmb->context2 = NULL;\r\nmb->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\n}\r\n}\r\nspin_lock_irq(&phba->hbalock);\r\nlist_for_each_entry(mb, &phba->sli.mboxq_cmpl, list) {\r\nif ((mb->u.mb.mbxCommand != MBX_REG_LOGIN64) ||\r\n(mb->mbox_flag & LPFC_MBX_IMED_UNREG) ||\r\n(ndlp != (struct lpfc_nodelist *) mb->context2))\r\ncontinue;\r\nmb->context2 = NULL;\r\nmb->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\n}\r\nlist_for_each_entry_safe(mb, nextmb, &phba->sli.mboxq, list) {\r\nif ((mb->u.mb.mbxCommand == MBX_REG_LOGIN64) &&\r\n!(mb->mbox_flag & LPFC_MBX_IMED_UNREG) &&\r\n(ndlp == (struct lpfc_nodelist *) mb->context2)) {\r\nmp = (struct lpfc_dmabuf *) (mb->context1);\r\nif (mp) {\r\n__lpfc_mbuf_free(phba, mp->virt, mp->phys);\r\nkfree(mp);\r\n}\r\nlist_del(&mb->list);\r\nmempool_free(mb, phba->mbox_mem_pool);\r\n}\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_els_abort(phba, ndlp);\r\nspin_lock_irq(shost->host_lock);\r\nndlp->nlp_flag &= ~NLP_DELAY_TMO;\r\nspin_unlock_irq(shost->host_lock);\r\nndlp->nlp_last_elscmd = 0;\r\ndel_timer_sync(&ndlp->nlp_delayfunc);\r\nlist_del_init(&ndlp->els_retry_evt.evt_listp);\r\nlist_del_init(&ndlp->dev_loss_evt.evt_listp);\r\nlpfc_cleanup_vports_rrqs(vport, ndlp);\r\nlpfc_unreg_rpi(vport, ndlp);\r\nreturn 0;\r\n}\r\nstatic void\r\nlpfc_nlp_remove(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp)\r\n{\r\nstruct lpfc_hba *phba = vport->phba;\r\nstruct lpfc_rport_data *rdata;\r\nLPFC_MBOXQ_t *mbox;\r\nint rc;\r\nlpfc_cancel_retry_delay_tmo(vport, ndlp);\r\nif ((ndlp->nlp_flag & NLP_DEFER_RM) &&\r\n!(ndlp->nlp_flag & NLP_REG_LOGIN_SEND) &&\r\n!(ndlp->nlp_flag & NLP_RPI_REGISTERED)) {\r\nif ((mbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL))\r\n!= NULL) {\r\nrc = lpfc_reg_rpi(phba, vport->vpi, ndlp->nlp_DID,\r\n(uint8_t *) &vport->fc_sparam, mbox, ndlp->nlp_rpi);\r\nif (rc) {\r\nmempool_free(mbox, phba->mbox_mem_pool);\r\n}\r\nelse {\r\nmbox->mbox_flag |= LPFC_MBX_IMED_UNREG;\r\nmbox->mbox_cmpl = lpfc_mbx_cmpl_dflt_rpi;\r\nmbox->vport = vport;\r\nmbox->context2 = ndlp;\r\nrc =lpfc_sli_issue_mbox(phba, mbox, MBX_NOWAIT);\r\nif (rc == MBX_NOT_FINISHED) {\r\nmempool_free(mbox, phba->mbox_mem_pool);\r\n}\r\n}\r\n}\r\n}\r\nlpfc_cleanup_node(vport, ndlp);\r\nif (ndlp->rport) {\r\nrdata = ndlp->rport->dd_data;\r\nrdata->pnode = NULL;\r\nndlp->rport = NULL;\r\n}\r\n}\r\nstatic int\r\nlpfc_matchdid(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp,\r\nuint32_t did)\r\n{\r\nD_ID mydid, ndlpdid, matchdid;\r\nif (did == Bcast_DID)\r\nreturn 0;\r\nif (ndlp->nlp_DID == did)\r\nreturn 1;\r\nmydid.un.word = vport->fc_myDID;\r\nif ((mydid.un.b.domain == 0) && (mydid.un.b.area == 0)) {\r\nreturn 0;\r\n}\r\nmatchdid.un.word = did;\r\nndlpdid.un.word = ndlp->nlp_DID;\r\nif (matchdid.un.b.id == ndlpdid.un.b.id) {\r\nif ((mydid.un.b.domain == matchdid.un.b.domain) &&\r\n(mydid.un.b.area == matchdid.un.b.area)) {\r\nif ((ndlpdid.un.b.domain == 0) &&\r\n(ndlpdid.un.b.area == 0)) {\r\nif (ndlpdid.un.b.id)\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nmatchdid.un.word = ndlp->nlp_DID;\r\nif ((mydid.un.b.domain == ndlpdid.un.b.domain) &&\r\n(mydid.un.b.area == ndlpdid.un.b.area)) {\r\nif ((matchdid.un.b.domain == 0) &&\r\n(matchdid.un.b.area == 0)) {\r\nif (matchdid.un.b.id)\r\nreturn 1;\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic struct lpfc_nodelist *\r\n__lpfc_findnode_did(struct lpfc_vport *vport, uint32_t did)\r\n{\r\nstruct lpfc_nodelist *ndlp;\r\nuint32_t data1;\r\nlist_for_each_entry(ndlp, &vport->fc_nodes, nlp_listp) {\r\nif (lpfc_matchdid(vport, ndlp, did)) {\r\ndata1 = (((uint32_t) ndlp->nlp_state << 24) |\r\n((uint32_t) ndlp->nlp_xri << 16) |\r\n((uint32_t) ndlp->nlp_type << 8) |\r\n((uint32_t) ndlp->nlp_rpi & 0xff));\r\nlpfc_printf_vlog(vport, KERN_INFO, LOG_NODE,\r\n"0929 FIND node DID "\r\n"Data: x%p x%x x%x x%x\n",\r\nndlp, ndlp->nlp_DID,\r\nndlp->nlp_flag, data1);\r\nreturn ndlp;\r\n}\r\n}\r\nlpfc_printf_vlog(vport, KERN_INFO, LOG_NODE,\r\n"0932 FIND node did x%x NOT FOUND.\n", did);\r\nreturn NULL;\r\n}\r\nstruct lpfc_nodelist *\r\nlpfc_findnode_did(struct lpfc_vport *vport, uint32_t did)\r\n{\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nstruct lpfc_nodelist *ndlp;\r\nunsigned long iflags;\r\nspin_lock_irqsave(shost->host_lock, iflags);\r\nndlp = __lpfc_findnode_did(vport, did);\r\nspin_unlock_irqrestore(shost->host_lock, iflags);\r\nreturn ndlp;\r\n}\r\nstruct lpfc_nodelist *\r\nlpfc_setup_disc_node(struct lpfc_vport *vport, uint32_t did)\r\n{\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nstruct lpfc_nodelist *ndlp;\r\nndlp = lpfc_findnode_did(vport, did);\r\nif (!ndlp) {\r\nif ((vport->fc_flag & FC_RSCN_MODE) != 0 &&\r\nlpfc_rscn_payload_check(vport, did) == 0)\r\nreturn NULL;\r\nndlp = (struct lpfc_nodelist *)\r\nmempool_alloc(vport->phba->nlp_mem_pool, GFP_KERNEL);\r\nif (!ndlp)\r\nreturn NULL;\r\nlpfc_nlp_init(vport, ndlp, did);\r\nlpfc_nlp_set_state(vport, ndlp, NLP_STE_NPR_NODE);\r\nspin_lock_irq(shost->host_lock);\r\nndlp->nlp_flag |= NLP_NPR_2B_DISC;\r\nspin_unlock_irq(shost->host_lock);\r\nreturn ndlp;\r\n} else if (!NLP_CHK_NODE_ACT(ndlp)) {\r\nndlp = lpfc_enable_node(vport, ndlp, NLP_STE_NPR_NODE);\r\nif (!ndlp)\r\nreturn NULL;\r\nspin_lock_irq(shost->host_lock);\r\nndlp->nlp_flag |= NLP_NPR_2B_DISC;\r\nspin_unlock_irq(shost->host_lock);\r\nreturn ndlp;\r\n}\r\nif ((vport->fc_flag & FC_RSCN_MODE) &&\r\n!(vport->fc_flag & FC_NDISC_ACTIVE)) {\r\nif (lpfc_rscn_payload_check(vport, did)) {\r\nif (ndlp->nlp_flag & NLP_RCV_PLOGI)\r\nreturn NULL;\r\nlpfc_cancel_retry_delay_tmo(vport, ndlp);\r\nspin_lock_irq(shost->host_lock);\r\nndlp->nlp_flag |= NLP_NPR_2B_DISC;\r\nspin_unlock_irq(shost->host_lock);\r\n} else\r\nndlp = NULL;\r\n} else {\r\nif (ndlp->nlp_state == NLP_STE_ADISC_ISSUE ||\r\nndlp->nlp_state == NLP_STE_PLOGI_ISSUE ||\r\nndlp->nlp_flag & NLP_RCV_PLOGI)\r\nreturn NULL;\r\nlpfc_nlp_set_state(vport, ndlp, NLP_STE_NPR_NODE);\r\nspin_lock_irq(shost->host_lock);\r\nndlp->nlp_flag |= NLP_NPR_2B_DISC;\r\nspin_unlock_irq(shost->host_lock);\r\n}\r\nreturn ndlp;\r\n}\r\nvoid\r\nlpfc_disc_list_loopmap(struct lpfc_vport *vport)\r\n{\r\nstruct lpfc_hba *phba = vport->phba;\r\nint j;\r\nuint32_t alpa, index;\r\nif (!lpfc_is_link_up(phba))\r\nreturn;\r\nif (phba->fc_topology != LPFC_TOPOLOGY_LOOP)\r\nreturn;\r\nif (phba->alpa_map[0]) {\r\nfor (j = 1; j <= phba->alpa_map[0]; j++) {\r\nalpa = phba->alpa_map[j];\r\nif (((vport->fc_myDID & 0xff) == alpa) || (alpa == 0))\r\ncontinue;\r\nlpfc_setup_disc_node(vport, alpa);\r\n}\r\n} else {\r\nfor (j = 0; j < FC_MAXLOOP; j++) {\r\nif (vport->cfg_scan_down)\r\nindex = j;\r\nelse\r\nindex = FC_MAXLOOP - j - 1;\r\nalpa = lpfcAlpaArray[index];\r\nif ((vport->fc_myDID & 0xff) == alpa)\r\ncontinue;\r\nlpfc_setup_disc_node(vport, alpa);\r\n}\r\n}\r\nreturn;\r\n}\r\nvoid\r\nlpfc_issue_clear_la(struct lpfc_hba *phba, struct lpfc_vport *vport)\r\n{\r\nLPFC_MBOXQ_t *mbox;\r\nstruct lpfc_sli *psli = &phba->sli;\r\nstruct lpfc_sli_ring *extra_ring = &psli->ring[psli->extra_ring];\r\nstruct lpfc_sli_ring *fcp_ring = &psli->ring[psli->fcp_ring];\r\nstruct lpfc_sli_ring *next_ring = &psli->ring[psli->next_ring];\r\nint rc;\r\nif ((phba->link_state >= LPFC_CLEAR_LA) ||\r\n(vport->port_type != LPFC_PHYSICAL_PORT) ||\r\n(phba->sli_rev == LPFC_SLI_REV4))\r\nreturn;\r\nif ((mbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL)) != NULL) {\r\nphba->link_state = LPFC_CLEAR_LA;\r\nlpfc_clear_la(phba, mbox);\r\nmbox->mbox_cmpl = lpfc_mbx_cmpl_clear_la;\r\nmbox->vport = vport;\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_NOWAIT);\r\nif (rc == MBX_NOT_FINISHED) {\r\nmempool_free(mbox, phba->mbox_mem_pool);\r\nlpfc_disc_flush_list(vport);\r\nextra_ring->flag &= ~LPFC_STOP_IOCB_EVENT;\r\nfcp_ring->flag &= ~LPFC_STOP_IOCB_EVENT;\r\nnext_ring->flag &= ~LPFC_STOP_IOCB_EVENT;\r\nphba->link_state = LPFC_HBA_ERROR;\r\n}\r\n}\r\n}\r\nvoid\r\nlpfc_issue_reg_vpi(struct lpfc_hba *phba, struct lpfc_vport *vport)\r\n{\r\nLPFC_MBOXQ_t *regvpimbox;\r\nregvpimbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (regvpimbox) {\r\nlpfc_reg_vpi(vport, regvpimbox);\r\nregvpimbox->mbox_cmpl = lpfc_mbx_cmpl_reg_vpi;\r\nregvpimbox->vport = vport;\r\nif (lpfc_sli_issue_mbox(phba, regvpimbox, MBX_NOWAIT)\r\n== MBX_NOT_FINISHED) {\r\nmempool_free(regvpimbox, phba->mbox_mem_pool);\r\n}\r\n}\r\n}\r\nvoid\r\nlpfc_disc_start(struct lpfc_vport *vport)\r\n{\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nstruct lpfc_hba *phba = vport->phba;\r\nuint32_t num_sent;\r\nuint32_t clear_la_pending;\r\nint did_changed;\r\nif (!lpfc_is_link_up(phba)) {\r\nlpfc_printf_vlog(vport, KERN_INFO, LOG_SLI,\r\n"3315 Link is not up %x\n",\r\nphba->link_state);\r\nreturn;\r\n}\r\nif (phba->link_state == LPFC_CLEAR_LA)\r\nclear_la_pending = 1;\r\nelse\r\nclear_la_pending = 0;\r\nif (vport->port_state < LPFC_VPORT_READY)\r\nvport->port_state = LPFC_DISC_AUTH;\r\nlpfc_set_disctmo(vport);\r\nif (vport->fc_prevDID == vport->fc_myDID)\r\ndid_changed = 0;\r\nelse\r\ndid_changed = 1;\r\nvport->fc_prevDID = vport->fc_myDID;\r\nvport->num_disc_nodes = 0;\r\nlpfc_printf_vlog(vport, KERN_INFO, LOG_DISCOVERY,\r\n"0202 Start Discovery hba state x%x "\r\n"Data: x%x x%x x%x\n",\r\nvport->port_state, vport->fc_flag, vport->fc_plogi_cnt,\r\nvport->fc_adisc_cnt);\r\nnum_sent = lpfc_els_disc_adisc(vport);\r\nif (num_sent)\r\nreturn;\r\nif ((phba->sli3_options & LPFC_SLI3_NPIV_ENABLED) &&\r\n!(vport->fc_flag & FC_PT2PT) &&\r\n!(vport->fc_flag & FC_RSCN_MODE) &&\r\n(phba->sli_rev < LPFC_SLI_REV4)) {\r\nif (vport->port_type == LPFC_PHYSICAL_PORT)\r\nlpfc_issue_clear_la(phba, vport);\r\nlpfc_issue_reg_vpi(phba, vport);\r\nreturn;\r\n}\r\nif (vport->port_state < LPFC_VPORT_READY && !clear_la_pending) {\r\nif (vport->port_type == LPFC_PHYSICAL_PORT)\r\nlpfc_issue_clear_la(phba, vport);\r\nif (!(vport->fc_flag & FC_ABORT_DISCOVERY)) {\r\nvport->num_disc_nodes = 0;\r\nif (vport->fc_npr_cnt)\r\nlpfc_els_disc_plogi(vport);\r\nif (!vport->num_disc_nodes) {\r\nspin_lock_irq(shost->host_lock);\r\nvport->fc_flag &= ~FC_NDISC_ACTIVE;\r\nspin_unlock_irq(shost->host_lock);\r\nlpfc_can_disctmo(vport);\r\n}\r\n}\r\nvport->port_state = LPFC_VPORT_READY;\r\n} else {\r\nnum_sent = lpfc_els_disc_plogi(vport);\r\nif (num_sent)\r\nreturn;\r\nif (vport->fc_flag & FC_RSCN_MODE) {\r\nif ((vport->fc_rscn_id_cnt == 0) &&\r\n(!(vport->fc_flag & FC_RSCN_DISCOVERY))) {\r\nspin_lock_irq(shost->host_lock);\r\nvport->fc_flag &= ~FC_RSCN_MODE;\r\nspin_unlock_irq(shost->host_lock);\r\nlpfc_can_disctmo(vport);\r\n} else\r\nlpfc_els_handle_rscn(vport);\r\n}\r\n}\r\nreturn;\r\n}\r\nstatic void\r\nlpfc_free_tx(struct lpfc_hba *phba, struct lpfc_nodelist *ndlp)\r\n{\r\nLIST_HEAD(completions);\r\nstruct lpfc_sli *psli;\r\nIOCB_t *icmd;\r\nstruct lpfc_iocbq *iocb, *next_iocb;\r\nstruct lpfc_sli_ring *pring;\r\npsli = &phba->sli;\r\npring = &psli->ring[LPFC_ELS_RING];\r\nspin_lock_irq(&phba->hbalock);\r\nlist_for_each_entry_safe(iocb, next_iocb, &pring->txq, list) {\r\nif (iocb->context1 != ndlp) {\r\ncontinue;\r\n}\r\nicmd = &iocb->iocb;\r\nif ((icmd->ulpCommand == CMD_ELS_REQUEST64_CR) ||\r\n(icmd->ulpCommand == CMD_XMIT_ELS_RSP64_CX)) {\r\nlist_move_tail(&iocb->list, &completions);\r\n}\r\n}\r\nlist_for_each_entry_safe(iocb, next_iocb, &pring->txcmplq, list) {\r\nif (iocb->context1 != ndlp) {\r\ncontinue;\r\n}\r\nicmd = &iocb->iocb;\r\nif (icmd->ulpCommand == CMD_ELS_REQUEST64_CR ||\r\nicmd->ulpCommand == CMD_XMIT_ELS_RSP64_CX) {\r\nlpfc_sli_issue_abort_iotag(phba, pring, iocb);\r\n}\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_sli_cancel_iocbs(phba, &completions, IOSTAT_LOCAL_REJECT,\r\nIOERR_SLI_ABORTED);\r\n}\r\nstatic void\r\nlpfc_disc_flush_list(struct lpfc_vport *vport)\r\n{\r\nstruct lpfc_nodelist *ndlp, *next_ndlp;\r\nstruct lpfc_hba *phba = vport->phba;\r\nif (vport->fc_plogi_cnt || vport->fc_adisc_cnt) {\r\nlist_for_each_entry_safe(ndlp, next_ndlp, &vport->fc_nodes,\r\nnlp_listp) {\r\nif (!NLP_CHK_NODE_ACT(ndlp))\r\ncontinue;\r\nif (ndlp->nlp_state == NLP_STE_PLOGI_ISSUE ||\r\nndlp->nlp_state == NLP_STE_ADISC_ISSUE) {\r\nlpfc_free_tx(phba, ndlp);\r\n}\r\n}\r\n}\r\n}\r\nvoid\r\nlpfc_cleanup_discovery_resources(struct lpfc_vport *vport)\r\n{\r\nlpfc_els_flush_rscn(vport);\r\nlpfc_els_flush_cmd(vport);\r\nlpfc_disc_flush_list(vport);\r\n}\r\nvoid\r\nlpfc_disc_timeout(unsigned long ptr)\r\n{\r\nstruct lpfc_vport *vport = (struct lpfc_vport *) ptr;\r\nstruct lpfc_hba *phba = vport->phba;\r\nuint32_t tmo_posted;\r\nunsigned long flags = 0;\r\nif (unlikely(!phba))\r\nreturn;\r\nspin_lock_irqsave(&vport->work_port_lock, flags);\r\ntmo_posted = vport->work_port_events & WORKER_DISC_TMO;\r\nif (!tmo_posted)\r\nvport->work_port_events |= WORKER_DISC_TMO;\r\nspin_unlock_irqrestore(&vport->work_port_lock, flags);\r\nif (!tmo_posted)\r\nlpfc_worker_wake_up(phba);\r\nreturn;\r\n}\r\nstatic void\r\nlpfc_disc_timeout_handler(struct lpfc_vport *vport)\r\n{\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nstruct lpfc_hba *phba = vport->phba;\r\nstruct lpfc_sli *psli = &phba->sli;\r\nstruct lpfc_nodelist *ndlp, *next_ndlp;\r\nLPFC_MBOXQ_t *initlinkmbox;\r\nint rc, clrlaerr = 0;\r\nif (!(vport->fc_flag & FC_DISC_TMO))\r\nreturn;\r\nspin_lock_irq(shost->host_lock);\r\nvport->fc_flag &= ~FC_DISC_TMO;\r\nspin_unlock_irq(shost->host_lock);\r\nlpfc_debugfs_disc_trc(vport, LPFC_DISC_TRC_ELS_CMD,\r\n"disc timeout: state:x%x rtry:x%x flg:x%x",\r\nvport->port_state, vport->fc_ns_retry, vport->fc_flag);\r\nswitch (vport->port_state) {\r\ncase LPFC_LOCAL_CFG_LINK:\r\nlpfc_printf_vlog(vport, KERN_WARNING, LOG_DISCOVERY,\r\n"0221 FAN timeout\n");\r\nlist_for_each_entry_safe(ndlp, next_ndlp, &vport->fc_nodes,\r\nnlp_listp) {\r\nif (!NLP_CHK_NODE_ACT(ndlp))\r\ncontinue;\r\nif (ndlp->nlp_state != NLP_STE_NPR_NODE)\r\ncontinue;\r\nif (ndlp->nlp_type & NLP_FABRIC) {\r\nlpfc_drop_node(vport, ndlp);\r\n} else if (!(ndlp->nlp_flag & NLP_NPR_ADISC)) {\r\nlpfc_unreg_rpi(vport, ndlp);\r\n}\r\n}\r\nif (vport->port_state != LPFC_FLOGI) {\r\nif (phba->sli_rev <= LPFC_SLI_REV3)\r\nlpfc_initial_flogi(vport);\r\nelse\r\nlpfc_issue_init_vfi(vport);\r\nreturn;\r\n}\r\nbreak;\r\ncase LPFC_FDISC:\r\ncase LPFC_FLOGI:\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_DISCOVERY,\r\n"0222 Initial %s timeout\n",\r\nvport->vpi ? "FDISC" : "FLOGI");\r\nlpfc_disc_list_loopmap(vport);\r\nlpfc_disc_start(vport);\r\nbreak;\r\ncase LPFC_FABRIC_CFG_LINK:\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_DISCOVERY,\r\n"0223 Timeout while waiting for "\r\n"NameServer login\n");\r\nndlp = lpfc_findnode_did(vport, NameServer_DID);\r\nif (ndlp && NLP_CHK_NODE_ACT(ndlp))\r\nlpfc_els_abort(phba, ndlp);\r\ngoto restart_disc;\r\ncase LPFC_NS_QRY:\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_DISCOVERY,\r\n"0224 NameServer Query timeout "\r\n"Data: x%x x%x\n",\r\nvport->fc_ns_retry, LPFC_MAX_NS_RETRY);\r\nif (vport->fc_ns_retry < LPFC_MAX_NS_RETRY) {\r\nvport->fc_ns_retry++;\r\nrc = lpfc_ns_cmd(vport, SLI_CTNS_GID_FT,\r\nvport->fc_ns_retry, 0);\r\nif (rc == 0)\r\nbreak;\r\n}\r\nvport->fc_ns_retry = 0;\r\nrestart_disc:\r\nif (phba->sli_rev < LPFC_SLI_REV4) {\r\nif (phba->sli3_options & LPFC_SLI3_NPIV_ENABLED)\r\nlpfc_issue_reg_vpi(phba, vport);\r\nelse {\r\nlpfc_issue_clear_la(phba, vport);\r\nvport->port_state = LPFC_VPORT_READY;\r\n}\r\n}\r\ninitlinkmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!initlinkmbox) {\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_DISCOVERY,\r\n"0206 Device Discovery "\r\n"completion error\n");\r\nphba->link_state = LPFC_HBA_ERROR;\r\nbreak;\r\n}\r\nlpfc_linkdown(phba);\r\nlpfc_init_link(phba, initlinkmbox, phba->cfg_topology,\r\nphba->cfg_link_speed);\r\ninitlinkmbox->u.mb.un.varInitLnk.lipsr_AL_PA = 0;\r\ninitlinkmbox->vport = vport;\r\ninitlinkmbox->mbox_cmpl = lpfc_sli_def_mbox_cmpl;\r\nrc = lpfc_sli_issue_mbox(phba, initlinkmbox, MBX_NOWAIT);\r\nlpfc_set_loopback_flag(phba);\r\nif (rc == MBX_NOT_FINISHED)\r\nmempool_free(initlinkmbox, phba->mbox_mem_pool);\r\nbreak;\r\ncase LPFC_DISC_AUTH:\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_DISCOVERY,\r\n"0227 Node Authentication timeout\n");\r\nlpfc_disc_flush_list(vport);\r\nif (phba->sli_rev < LPFC_SLI_REV4) {\r\nif (phba->sli3_options & LPFC_SLI3_NPIV_ENABLED)\r\nlpfc_issue_reg_vpi(phba, vport);\r\nelse {\r\nlpfc_issue_clear_la(phba, vport);\r\nvport->port_state = LPFC_VPORT_READY;\r\n}\r\n}\r\nbreak;\r\ncase LPFC_VPORT_READY:\r\nif (vport->fc_flag & FC_RSCN_MODE) {\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_DISCOVERY,\r\n"0231 RSCN timeout Data: x%x "\r\n"x%x\n",\r\nvport->fc_ns_retry, LPFC_MAX_NS_RETRY);\r\nlpfc_els_flush_cmd(vport);\r\nlpfc_els_flush_rscn(vport);\r\nlpfc_disc_flush_list(vport);\r\n}\r\nbreak;\r\ndefault:\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_DISCOVERY,\r\n"0273 Unexpected discovery timeout, "\r\n"vport State x%x\n", vport->port_state);\r\nbreak;\r\n}\r\nswitch (phba->link_state) {\r\ncase LPFC_CLEAR_LA:\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_DISCOVERY,\r\n"0228 CLEAR LA timeout\n");\r\nclrlaerr = 1;\r\nbreak;\r\ncase LPFC_LINK_UP:\r\nlpfc_issue_clear_la(phba, vport);\r\ncase LPFC_LINK_UNKNOWN:\r\ncase LPFC_WARM_START:\r\ncase LPFC_INIT_START:\r\ncase LPFC_INIT_MBX_CMDS:\r\ncase LPFC_LINK_DOWN:\r\ncase LPFC_HBA_ERROR:\r\nlpfc_printf_vlog(vport, KERN_ERR, LOG_DISCOVERY,\r\n"0230 Unexpected timeout, hba link "\r\n"state x%x\n", phba->link_state);\r\nclrlaerr = 1;\r\nbreak;\r\ncase LPFC_HBA_READY:\r\nbreak;\r\n}\r\nif (clrlaerr) {\r\nlpfc_disc_flush_list(vport);\r\npsli->ring[(psli->extra_ring)].flag &= ~LPFC_STOP_IOCB_EVENT;\r\npsli->ring[(psli->fcp_ring)].flag &= ~LPFC_STOP_IOCB_EVENT;\r\npsli->ring[(psli->next_ring)].flag &= ~LPFC_STOP_IOCB_EVENT;\r\nvport->port_state = LPFC_VPORT_READY;\r\n}\r\nreturn;\r\n}\r\nvoid\r\nlpfc_mbx_cmpl_fdmi_reg_login(struct lpfc_hba *phba, LPFC_MBOXQ_t *pmb)\r\n{\r\nMAILBOX_t *mb = &pmb->u.mb;\r\nstruct lpfc_dmabuf *mp = (struct lpfc_dmabuf *) (pmb->context1);\r\nstruct lpfc_nodelist *ndlp = (struct lpfc_nodelist *) pmb->context2;\r\nstruct lpfc_vport *vport = pmb->vport;\r\npmb->context1 = NULL;\r\npmb->context2 = NULL;\r\nif (phba->sli_rev < LPFC_SLI_REV4)\r\nndlp->nlp_rpi = mb->un.varWords[0];\r\nndlp->nlp_flag |= NLP_RPI_REGISTERED;\r\nndlp->nlp_type |= NLP_FABRIC;\r\nlpfc_nlp_set_state(vport, ndlp, NLP_STE_UNMAPPED_NODE);\r\nif (vport->cfg_fdmi_on == 1)\r\nlpfc_fdmi_cmd(vport, ndlp, SLI_MGMT_DHBA);\r\nelse\r\nmod_timer(&vport->fc_fdmitmo,\r\njiffies + msecs_to_jiffies(1000 * 60));\r\nlpfc_nlp_put(ndlp);\r\nlpfc_mbuf_free(phba, mp->virt, mp->phys);\r\nkfree(mp);\r\nmempool_free(pmb, phba->mbox_mem_pool);\r\nreturn;\r\n}\r\nstatic int\r\nlpfc_filter_by_rpi(struct lpfc_nodelist *ndlp, void *param)\r\n{\r\nuint16_t *rpi = param;\r\nif (!NLP_CHK_NODE_ACT(ndlp))\r\nreturn 0;\r\nreturn ndlp->nlp_rpi == *rpi;\r\n}\r\nstatic int\r\nlpfc_filter_by_wwpn(struct lpfc_nodelist *ndlp, void *param)\r\n{\r\nreturn memcmp(&ndlp->nlp_portname, param,\r\nsizeof(ndlp->nlp_portname)) == 0;\r\n}\r\nstatic struct lpfc_nodelist *\r\n__lpfc_find_node(struct lpfc_vport *vport, node_filter filter, void *param)\r\n{\r\nstruct lpfc_nodelist *ndlp;\r\nlist_for_each_entry(ndlp, &vport->fc_nodes, nlp_listp) {\r\nif (filter(ndlp, param)) {\r\nlpfc_printf_vlog(vport, KERN_INFO, LOG_NODE,\r\n"3185 FIND node filter %p DID "\r\n"Data: x%p x%x x%x\n",\r\nfilter, ndlp, ndlp->nlp_DID,\r\nndlp->nlp_flag);\r\nreturn ndlp;\r\n}\r\n}\r\nlpfc_printf_vlog(vport, KERN_INFO, LOG_NODE,\r\n"3186 FIND node filter %p NOT FOUND.\n", filter);\r\nreturn NULL;\r\n}\r\nstruct lpfc_nodelist *\r\n__lpfc_findnode_rpi(struct lpfc_vport *vport, uint16_t rpi)\r\n{\r\nreturn __lpfc_find_node(vport, lpfc_filter_by_rpi, &rpi);\r\n}\r\nstruct lpfc_nodelist *\r\nlpfc_findnode_wwpn(struct lpfc_vport *vport, struct lpfc_name *wwpn)\r\n{\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nstruct lpfc_nodelist *ndlp;\r\nspin_lock_irq(shost->host_lock);\r\nndlp = __lpfc_find_node(vport, lpfc_filter_by_wwpn, wwpn);\r\nspin_unlock_irq(shost->host_lock);\r\nreturn ndlp;\r\n}\r\nstruct lpfc_nodelist *\r\nlpfc_findnode_rpi(struct lpfc_vport *vport, uint16_t rpi)\r\n{\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nstruct lpfc_nodelist *ndlp;\r\nspin_lock_irq(shost->host_lock);\r\nndlp = __lpfc_findnode_rpi(vport, rpi);\r\nspin_unlock_irq(shost->host_lock);\r\nreturn ndlp;\r\n}\r\nstruct lpfc_vport *\r\nlpfc_find_vport_by_vpid(struct lpfc_hba *phba, uint16_t vpi)\r\n{\r\nstruct lpfc_vport *vport;\r\nunsigned long flags;\r\nint i = 0;\r\nif (vpi > 0) {\r\nfor (i = 0; i < phba->max_vpi; i++) {\r\nif (vpi == phba->vpi_ids[i])\r\nbreak;\r\n}\r\nif (i >= phba->max_vpi) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_ELS,\r\n"2936 Could not find Vport mapped "\r\n"to vpi %d\n", vpi);\r\nreturn NULL;\r\n}\r\n}\r\nspin_lock_irqsave(&phba->hbalock, flags);\r\nlist_for_each_entry(vport, &phba->port_list, listentry) {\r\nif (vport->vpi == i) {\r\nspin_unlock_irqrestore(&phba->hbalock, flags);\r\nreturn vport;\r\n}\r\n}\r\nspin_unlock_irqrestore(&phba->hbalock, flags);\r\nreturn NULL;\r\n}\r\nvoid\r\nlpfc_nlp_init(struct lpfc_vport *vport, struct lpfc_nodelist *ndlp,\r\nuint32_t did)\r\n{\r\nmemset(ndlp, 0, sizeof (struct lpfc_nodelist));\r\nlpfc_initialize_node(vport, ndlp, did);\r\nINIT_LIST_HEAD(&ndlp->nlp_listp);\r\nif (vport->phba->sli_rev == LPFC_SLI_REV4)\r\nndlp->nlp_rpi = lpfc_sli4_alloc_rpi(vport->phba);\r\nlpfc_debugfs_disc_trc(vport, LPFC_DISC_TRC_NODE,\r\n"node init: did:x%x",\r\nndlp->nlp_DID, 0, 0);\r\nreturn;\r\n}\r\nstatic void\r\nlpfc_nlp_release(struct kref *kref)\r\n{\r\nstruct lpfc_hba *phba;\r\nunsigned long flags;\r\nstruct lpfc_nodelist *ndlp = container_of(kref, struct lpfc_nodelist,\r\nkref);\r\nlpfc_debugfs_disc_trc(ndlp->vport, LPFC_DISC_TRC_NODE,\r\n"node release: did:x%x flg:x%x type:x%x",\r\nndlp->nlp_DID, ndlp->nlp_flag, ndlp->nlp_type);\r\nlpfc_printf_vlog(ndlp->vport, KERN_INFO, LOG_NODE,\r\n"0279 lpfc_nlp_release: ndlp:x%p did %x "\r\n"usgmap:x%x refcnt:%d\n",\r\n(void *)ndlp, ndlp->nlp_DID, ndlp->nlp_usg_map,\r\natomic_read(&ndlp->kref.refcount));\r\nlpfc_nlp_remove(ndlp->vport, ndlp);\r\nphba = ndlp->phba;\r\nspin_lock_irqsave(&phba->ndlp_lock, flags);\r\nNLP_CLR_NODE_ACT(ndlp);\r\nspin_unlock_irqrestore(&phba->ndlp_lock, flags);\r\nif (phba->sli_rev == LPFC_SLI_REV4)\r\nlpfc_sli4_free_rpi(phba, ndlp->nlp_rpi);\r\nif (NLP_CHK_FREE_REQ(ndlp)) {\r\nkfree(ndlp->lat_data);\r\nmempool_free(ndlp, ndlp->phba->nlp_mem_pool);\r\n}\r\n}\r\nstruct lpfc_nodelist *\r\nlpfc_nlp_get(struct lpfc_nodelist *ndlp)\r\n{\r\nstruct lpfc_hba *phba;\r\nunsigned long flags;\r\nif (ndlp) {\r\nlpfc_debugfs_disc_trc(ndlp->vport, LPFC_DISC_TRC_NODE,\r\n"node get: did:x%x flg:x%x refcnt:x%x",\r\nndlp->nlp_DID, ndlp->nlp_flag,\r\natomic_read(&ndlp->kref.refcount));\r\nphba = ndlp->phba;\r\nspin_lock_irqsave(&phba->ndlp_lock, flags);\r\nif (!NLP_CHK_NODE_ACT(ndlp) || NLP_CHK_FREE_ACK(ndlp)) {\r\nspin_unlock_irqrestore(&phba->ndlp_lock, flags);\r\nlpfc_printf_vlog(ndlp->vport, KERN_WARNING, LOG_NODE,\r\n"0276 lpfc_nlp_get: ndlp:x%p "\r\n"usgmap:x%x refcnt:%d\n",\r\n(void *)ndlp, ndlp->nlp_usg_map,\r\natomic_read(&ndlp->kref.refcount));\r\nreturn NULL;\r\n} else\r\nkref_get(&ndlp->kref);\r\nspin_unlock_irqrestore(&phba->ndlp_lock, flags);\r\n}\r\nreturn ndlp;\r\n}\r\nint\r\nlpfc_nlp_put(struct lpfc_nodelist *ndlp)\r\n{\r\nstruct lpfc_hba *phba;\r\nunsigned long flags;\r\nif (!ndlp)\r\nreturn 1;\r\nlpfc_debugfs_disc_trc(ndlp->vport, LPFC_DISC_TRC_NODE,\r\n"node put: did:x%x flg:x%x refcnt:x%x",\r\nndlp->nlp_DID, ndlp->nlp_flag,\r\natomic_read(&ndlp->kref.refcount));\r\nphba = ndlp->phba;\r\nspin_lock_irqsave(&phba->ndlp_lock, flags);\r\nif (NLP_CHK_FREE_ACK(ndlp)) {\r\nspin_unlock_irqrestore(&phba->ndlp_lock, flags);\r\nlpfc_printf_vlog(ndlp->vport, KERN_WARNING, LOG_NODE,\r\n"0274 lpfc_nlp_put: ndlp:x%p "\r\n"usgmap:x%x refcnt:%d\n",\r\n(void *)ndlp, ndlp->nlp_usg_map,\r\natomic_read(&ndlp->kref.refcount));\r\nreturn 1;\r\n}\r\nif (NLP_CHK_IACT_REQ(ndlp)) {\r\nspin_unlock_irqrestore(&phba->ndlp_lock, flags);\r\nlpfc_printf_vlog(ndlp->vport, KERN_WARNING, LOG_NODE,\r\n"0275 lpfc_nlp_put: ndlp:x%p "\r\n"usgmap:x%x refcnt:%d\n",\r\n(void *)ndlp, ndlp->nlp_usg_map,\r\natomic_read(&ndlp->kref.refcount));\r\nreturn 1;\r\n}\r\nif (atomic_read(&ndlp->kref.refcount) == 1) {\r\nNLP_SET_IACT_REQ(ndlp);\r\nif (NLP_CHK_FREE_REQ(ndlp))\r\nNLP_SET_FREE_ACK(ndlp);\r\n}\r\nspin_unlock_irqrestore(&phba->ndlp_lock, flags);\r\nreturn kref_put(&ndlp->kref, lpfc_nlp_release);\r\n}\r\nint\r\nlpfc_nlp_not_used(struct lpfc_nodelist *ndlp)\r\n{\r\nlpfc_debugfs_disc_trc(ndlp->vport, LPFC_DISC_TRC_NODE,\r\n"node not used: did:x%x flg:x%x refcnt:x%x",\r\nndlp->nlp_DID, ndlp->nlp_flag,\r\natomic_read(&ndlp->kref.refcount));\r\nif (atomic_read(&ndlp->kref.refcount) == 1)\r\nif (lpfc_nlp_put(ndlp))\r\nreturn 1;\r\nreturn 0;\r\n}\r\nstatic int\r\nlpfc_fcf_inuse(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_vport **vports;\r\nint i, ret = 0;\r\nstruct lpfc_nodelist *ndlp;\r\nstruct Scsi_Host *shost;\r\nvports = lpfc_create_vport_work_array(phba);\r\nif (!vports)\r\nreturn 1;\r\nfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++) {\r\nshost = lpfc_shost_from_vport(vports[i]);\r\nspin_lock_irq(shost->host_lock);\r\nif (!(vports[i]->fc_flag & FC_VPORT_CVL_RCVD)) {\r\nspin_unlock_irq(shost->host_lock);\r\nret = 1;\r\ngoto out;\r\n}\r\nlist_for_each_entry(ndlp, &vports[i]->fc_nodes, nlp_listp) {\r\nif (NLP_CHK_NODE_ACT(ndlp) && ndlp->rport &&\r\n(ndlp->rport->roles & FC_RPORT_ROLE_FCP_TARGET)) {\r\nret = 1;\r\nspin_unlock_irq(shost->host_lock);\r\ngoto out;\r\n} else if (ndlp->nlp_flag & NLP_RPI_REGISTERED) {\r\nret = 1;\r\nlpfc_printf_log(phba, KERN_INFO, LOG_ELS,\r\n"2624 RPI %x DID %x flag %x "\r\n"still logged in\n",\r\nndlp->nlp_rpi, ndlp->nlp_DID,\r\nndlp->nlp_flag);\r\n}\r\n}\r\nspin_unlock_irq(shost->host_lock);\r\n}\r\nout:\r\nlpfc_destroy_vport_work_array(phba, vports);\r\nreturn ret;\r\n}\r\nvoid\r\nlpfc_unregister_vfi_cmpl(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq)\r\n{\r\nstruct lpfc_vport *vport = mboxq->vport;\r\nstruct Scsi_Host *shost = lpfc_shost_from_vport(vport);\r\nif (mboxq->u.mb.mbxStatus) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_DISCOVERY|LOG_MBOX,\r\n"2555 UNREG_VFI mbxStatus error x%x "\r\n"HBA state x%x\n",\r\nmboxq->u.mb.mbxStatus, vport->port_state);\r\n}\r\nspin_lock_irq(shost->host_lock);\r\nphba->pport->fc_flag &= ~FC_VFI_REGISTERED;\r\nspin_unlock_irq(shost->host_lock);\r\nmempool_free(mboxq, phba->mbox_mem_pool);\r\nreturn;\r\n}\r\nstatic void\r\nlpfc_unregister_fcfi_cmpl(struct lpfc_hba *phba, LPFC_MBOXQ_t *mboxq)\r\n{\r\nstruct lpfc_vport *vport = mboxq->vport;\r\nif (mboxq->u.mb.mbxStatus) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_DISCOVERY|LOG_MBOX,\r\n"2550 UNREG_FCFI mbxStatus error x%x "\r\n"HBA state x%x\n",\r\nmboxq->u.mb.mbxStatus, vport->port_state);\r\n}\r\nmempool_free(mboxq, phba->mbox_mem_pool);\r\nreturn;\r\n}\r\nint\r\nlpfc_unregister_fcf_prep(struct lpfc_hba *phba)\r\n{\r\nstruct lpfc_vport **vports;\r\nstruct lpfc_nodelist *ndlp;\r\nstruct Scsi_Host *shost;\r\nint i = 0, rc;\r\nif (lpfc_fcf_inuse(phba))\r\nlpfc_unreg_hba_rpis(phba);\r\nphba->pport->port_state = LPFC_VPORT_UNKNOWN;\r\nvports = lpfc_create_vport_work_array(phba);\r\nif (vports && (phba->sli3_options & LPFC_SLI3_NPIV_ENABLED))\r\nfor (i = 0; i <= phba->max_vports && vports[i] != NULL; i++) {\r\nndlp = lpfc_findnode_did(vports[i], Fabric_DID);\r\nif (ndlp)\r\nlpfc_cancel_retry_delay_tmo(vports[i], ndlp);\r\nlpfc_cleanup_pending_mbox(vports[i]);\r\nif (phba->sli_rev == LPFC_SLI_REV4)\r\nlpfc_sli4_unreg_all_rpis(vports[i]);\r\nlpfc_mbx_unreg_vpi(vports[i]);\r\nshost = lpfc_shost_from_vport(vports[i]);\r\nspin_lock_irq(shost->host_lock);\r\nvports[i]->fc_flag |= FC_VPORT_NEEDS_INIT_VPI;\r\nvports[i]->vpi_state &= ~LPFC_VPI_REGISTERED;\r\nspin_unlock_irq(shost->host_lock);\r\n}\r\nlpfc_destroy_vport_work_array(phba, vports);\r\nif (i == 0 && (!(phba->sli3_options & LPFC_SLI3_NPIV_ENABLED))) {\r\nndlp = lpfc_findnode_did(phba->pport, Fabric_DID);\r\nif (ndlp)\r\nlpfc_cancel_retry_delay_tmo(phba->pport, ndlp);\r\nlpfc_cleanup_pending_mbox(phba->pport);\r\nif (phba->sli_rev == LPFC_SLI_REV4)\r\nlpfc_sli4_unreg_all_rpis(phba->pport);\r\nlpfc_mbx_unreg_vpi(phba->pport);\r\nshost = lpfc_shost_from_vport(phba->pport);\r\nspin_lock_irq(shost->host_lock);\r\nphba->pport->fc_flag |= FC_VPORT_NEEDS_INIT_VPI;\r\nphba->pport->vpi_state &= ~LPFC_VPI_REGISTERED;\r\nspin_unlock_irq(shost->host_lock);\r\n}\r\nlpfc_els_flush_all_cmd(phba);\r\nrc = lpfc_issue_unreg_vfi(phba->pport);\r\nreturn rc;\r\n}\r\nint\r\nlpfc_sli4_unregister_fcf(struct lpfc_hba *phba)\r\n{\r\nLPFC_MBOXQ_t *mbox;\r\nint rc;\r\nmbox = mempool_alloc(phba->mbox_mem_pool, GFP_KERNEL);\r\nif (!mbox) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_DISCOVERY|LOG_MBOX,\r\n"2551 UNREG_FCFI mbox allocation failed"\r\n"HBA state x%x\n", phba->pport->port_state);\r\nreturn -ENOMEM;\r\n}\r\nlpfc_unreg_fcfi(mbox, phba->fcf.fcfi);\r\nmbox->vport = phba->pport;\r\nmbox->mbox_cmpl = lpfc_unregister_fcfi_cmpl;\r\nrc = lpfc_sli_issue_mbox(phba, mbox, MBX_NOWAIT);\r\nif (rc == MBX_NOT_FINISHED) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_SLI,\r\n"2552 Unregister FCFI command failed rc x%x "\r\n"HBA state x%x\n",\r\nrc, phba->pport->port_state);\r\nreturn -EINVAL;\r\n}\r\nreturn 0;\r\n}\r\nvoid\r\nlpfc_unregister_fcf_rescan(struct lpfc_hba *phba)\r\n{\r\nint rc;\r\nrc = lpfc_unregister_fcf_prep(phba);\r\nif (rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_DISCOVERY,\r\n"2748 Failed to prepare for unregistering "\r\n"HBA's FCF record: rc=%d\n", rc);\r\nreturn;\r\n}\r\nrc = lpfc_sli4_unregister_fcf(phba);\r\nif (rc)\r\nreturn;\r\nphba->fcf.fcf_flag = 0;\r\nphba->fcf.current_rec.flag = 0;\r\nif ((phba->pport->load_flag & FC_UNLOADING) ||\r\n(phba->link_state < LPFC_LINK_UP))\r\nreturn;\r\nspin_lock_irq(&phba->hbalock);\r\nphba->fcf.fcf_flag |= FCF_INIT_DISC;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_sli4_clear_fcf_rr_bmask(phba);\r\nrc = lpfc_sli4_fcf_scan_read_fcf_rec(phba, LPFC_FCOE_FCF_GET_FIRST);\r\nif (rc) {\r\nspin_lock_irq(&phba->hbalock);\r\nphba->fcf.fcf_flag &= ~FCF_INIT_DISC;\r\nspin_unlock_irq(&phba->hbalock);\r\nlpfc_printf_log(phba, KERN_ERR, LOG_DISCOVERY|LOG_MBOX,\r\n"2553 lpfc_unregister_unused_fcf failed "\r\n"to read FCF record HBA state x%x\n",\r\nphba->pport->port_state);\r\n}\r\n}\r\nvoid\r\nlpfc_unregister_fcf(struct lpfc_hba *phba)\r\n{\r\nint rc;\r\nrc = lpfc_unregister_fcf_prep(phba);\r\nif (rc) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_DISCOVERY,\r\n"2749 Failed to prepare for unregistering "\r\n"HBA's FCF record: rc=%d\n", rc);\r\nreturn;\r\n}\r\nrc = lpfc_sli4_unregister_fcf(phba);\r\nif (rc)\r\nreturn;\r\nspin_lock_irq(&phba->hbalock);\r\nphba->fcf.fcf_flag &= ~FCF_REGISTERED;\r\nspin_unlock_irq(&phba->hbalock);\r\n}\r\nvoid\r\nlpfc_unregister_unused_fcf(struct lpfc_hba *phba)\r\n{\r\nspin_lock_irq(&phba->hbalock);\r\nif (!(phba->hba_flag & HBA_FCOE_MODE) ||\r\n!(phba->fcf.fcf_flag & FCF_REGISTERED) ||\r\n!(phba->hba_flag & HBA_FIP_SUPPORT) ||\r\n(phba->fcf.fcf_flag & FCF_DISCOVERY) ||\r\n(phba->pport->port_state == LPFC_FLOGI)) {\r\nspin_unlock_irq(&phba->hbalock);\r\nreturn;\r\n}\r\nspin_unlock_irq(&phba->hbalock);\r\nif (lpfc_fcf_inuse(phba))\r\nreturn;\r\nlpfc_unregister_fcf_rescan(phba);\r\n}\r\nstatic void\r\nlpfc_read_fcf_conn_tbl(struct lpfc_hba *phba,\r\nuint8_t *buff)\r\n{\r\nstruct lpfc_fcf_conn_entry *conn_entry, *next_conn_entry;\r\nstruct lpfc_fcf_conn_hdr *conn_hdr;\r\nstruct lpfc_fcf_conn_rec *conn_rec;\r\nuint32_t record_count;\r\nint i;\r\nlist_for_each_entry_safe(conn_entry, next_conn_entry,\r\n&phba->fcf_conn_rec_list, list) {\r\nlist_del_init(&conn_entry->list);\r\nkfree(conn_entry);\r\n}\r\nconn_hdr = (struct lpfc_fcf_conn_hdr *) buff;\r\nrecord_count = conn_hdr->length * sizeof(uint32_t)/\r\nsizeof(struct lpfc_fcf_conn_rec);\r\nconn_rec = (struct lpfc_fcf_conn_rec *)\r\n(buff + sizeof(struct lpfc_fcf_conn_hdr));\r\nfor (i = 0; i < record_count; i++) {\r\nif (!(conn_rec[i].flags & FCFCNCT_VALID))\r\ncontinue;\r\nconn_entry = kzalloc(sizeof(struct lpfc_fcf_conn_entry),\r\nGFP_KERNEL);\r\nif (!conn_entry) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2566 Failed to allocate connection"\r\n" table entry\n");\r\nreturn;\r\n}\r\nmemcpy(&conn_entry->conn_rec, &conn_rec[i],\r\nsizeof(struct lpfc_fcf_conn_rec));\r\nconn_entry->conn_rec.vlan_tag =\r\nconn_entry->conn_rec.vlan_tag;\r\nconn_entry->conn_rec.flags =\r\nconn_entry->conn_rec.flags;\r\nlist_add_tail(&conn_entry->list,\r\n&phba->fcf_conn_rec_list);\r\n}\r\nif (!list_empty(&phba->fcf_conn_rec_list)) {\r\ni = 0;\r\nlist_for_each_entry(conn_entry, &phba->fcf_conn_rec_list,\r\nlist) {\r\nconn_rec = &conn_entry->conn_rec;\r\nlpfc_printf_log(phba, KERN_INFO, LOG_INIT,\r\n"3345 FCF connection list rec[%02d]: "\r\n"flags:x%04x, vtag:x%04x, "\r\n"fabric_name:x%02x:%02x:%02x:%02x:"\r\n"%02x:%02x:%02x:%02x, "\r\n"switch_name:x%02x:%02x:%02x:%02x:"\r\n"%02x:%02x:%02x:%02x\n", i++,\r\nconn_rec->flags, conn_rec->vlan_tag,\r\nconn_rec->fabric_name[0],\r\nconn_rec->fabric_name[1],\r\nconn_rec->fabric_name[2],\r\nconn_rec->fabric_name[3],\r\nconn_rec->fabric_name[4],\r\nconn_rec->fabric_name[5],\r\nconn_rec->fabric_name[6],\r\nconn_rec->fabric_name[7],\r\nconn_rec->switch_name[0],\r\nconn_rec->switch_name[1],\r\nconn_rec->switch_name[2],\r\nconn_rec->switch_name[3],\r\nconn_rec->switch_name[4],\r\nconn_rec->switch_name[5],\r\nconn_rec->switch_name[6],\r\nconn_rec->switch_name[7]);\r\n}\r\n}\r\n}\r\nstatic void\r\nlpfc_read_fcoe_param(struct lpfc_hba *phba,\r\nuint8_t *buff)\r\n{\r\nstruct lpfc_fip_param_hdr *fcoe_param_hdr;\r\nstruct lpfc_fcoe_params *fcoe_param;\r\nfcoe_param_hdr = (struct lpfc_fip_param_hdr *)\r\nbuff;\r\nfcoe_param = (struct lpfc_fcoe_params *)\r\n(buff + sizeof(struct lpfc_fip_param_hdr));\r\nif ((fcoe_param_hdr->parm_version != FIPP_VERSION) ||\r\n(fcoe_param_hdr->length != FCOE_PARAM_LENGTH))\r\nreturn;\r\nif (fcoe_param_hdr->parm_flags & FIPP_VLAN_VALID) {\r\nphba->valid_vlan = 1;\r\nphba->vlan_id = le16_to_cpu(fcoe_param->vlan_tag) &\r\n0xFFF;\r\n}\r\nphba->fc_map[0] = fcoe_param->fc_map[0];\r\nphba->fc_map[1] = fcoe_param->fc_map[1];\r\nphba->fc_map[2] = fcoe_param->fc_map[2];\r\nreturn;\r\n}\r\nstatic uint8_t *\r\nlpfc_get_rec_conf23(uint8_t *buff, uint32_t size, uint8_t rec_type)\r\n{\r\nuint32_t offset = 0, rec_length;\r\nif ((buff[0] == LPFC_REGION23_LAST_REC) ||\r\n(size < sizeof(uint32_t)))\r\nreturn NULL;\r\nrec_length = buff[offset + 1];\r\nwhile ((offset + rec_length * sizeof(uint32_t) + sizeof(uint32_t))\r\n<= size) {\r\nif (buff[offset] == rec_type)\r\nreturn &buff[offset];\r\nif (buff[offset] == LPFC_REGION23_LAST_REC)\r\nreturn NULL;\r\noffset += rec_length * sizeof(uint32_t) + sizeof(uint32_t);\r\nrec_length = buff[offset + 1];\r\n}\r\nreturn NULL;\r\n}\r\nvoid\r\nlpfc_parse_fcoe_conf(struct lpfc_hba *phba,\r\nuint8_t *buff,\r\nuint32_t size)\r\n{\r\nuint32_t offset = 0, rec_length;\r\nuint8_t *rec_ptr;\r\nif (size < 2*sizeof(uint32_t))\r\nreturn;\r\nif (memcmp(buff, LPFC_REGION23_SIGNATURE, 4)) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2567 Config region 23 has bad signature\n");\r\nreturn;\r\n}\r\noffset += 4;\r\nif (buff[offset] != LPFC_REGION23_VERSION) {\r\nlpfc_printf_log(phba, KERN_ERR, LOG_INIT,\r\n"2568 Config region 23 has bad version\n");\r\nreturn;\r\n}\r\noffset += 4;\r\nrec_length = buff[offset + 1];\r\nrec_ptr = lpfc_get_rec_conf23(&buff[offset],\r\nsize - offset, FCOE_PARAM_TYPE);\r\nif (rec_ptr)\r\nlpfc_read_fcoe_param(phba, rec_ptr);\r\nrec_ptr = lpfc_get_rec_conf23(&buff[offset],\r\nsize - offset, FCOE_CONN_TBL_TYPE);\r\nif (rec_ptr)\r\nlpfc_read_fcf_conn_tbl(phba, rec_ptr);\r\n}
