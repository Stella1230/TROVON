static void *alloc_pgt_page(void *context)\r\n{\r\nreturn (void *)get_safe_page(GFP_ATOMIC);\r\n}\r\nstatic int set_up_temporary_mappings(void)\r\n{\r\nstruct x86_mapping_info info = {\r\n.alloc_pgt_page = alloc_pgt_page,\r\n.pmd_flag = __PAGE_KERNEL_LARGE_EXEC,\r\n.kernel_mapping = true,\r\n};\r\nunsigned long mstart, mend;\r\nint result;\r\nint i;\r\ntemp_level4_pgt = (pgd_t *)get_safe_page(GFP_ATOMIC);\r\nif (!temp_level4_pgt)\r\nreturn -ENOMEM;\r\nset_pgd(temp_level4_pgt + pgd_index(__START_KERNEL_map),\r\ninit_level4_pgt[pgd_index(__START_KERNEL_map)]);\r\nfor (i = 0; i < nr_pfn_mapped; i++) {\r\nmstart = pfn_mapped[i].start << PAGE_SHIFT;\r\nmend = pfn_mapped[i].end << PAGE_SHIFT;\r\nresult = kernel_ident_mapping_init(&info, temp_level4_pgt,\r\nmstart, mend);\r\nif (result)\r\nreturn result;\r\n}\r\nreturn 0;\r\n}\r\nint swsusp_arch_resume(void)\r\n{\r\nint error;\r\nif ((error = set_up_temporary_mappings()))\r\nreturn error;\r\nrelocated_restore_code = (void *)get_safe_page(GFP_ATOMIC);\r\nif (!relocated_restore_code)\r\nreturn -ENOMEM;\r\nmemcpy(relocated_restore_code, &core_restore_code,\r\n&restore_registers - &core_restore_code);\r\nrestore_image();\r\nreturn 0;\r\n}\r\nint pfn_is_nosave(unsigned long pfn)\r\n{\r\nunsigned long nosave_begin_pfn = __pa_symbol(&__nosave_begin) >> PAGE_SHIFT;\r\nunsigned long nosave_end_pfn = PAGE_ALIGN(__pa_symbol(&__nosave_end)) >> PAGE_SHIFT;\r\nreturn (pfn >= nosave_begin_pfn) && (pfn < nosave_end_pfn);\r\n}\r\nint arch_hibernation_header_save(void *addr, unsigned int max_size)\r\n{\r\nstruct restore_data_record *rdr = addr;\r\nif (max_size < sizeof(struct restore_data_record))\r\nreturn -EOVERFLOW;\r\nrdr->jump_address = restore_jump_address;\r\nrdr->cr3 = restore_cr3;\r\nrdr->magic = RESTORE_MAGIC;\r\nreturn 0;\r\n}\r\nint arch_hibernation_header_restore(void *addr)\r\n{\r\nstruct restore_data_record *rdr = addr;\r\nrestore_jump_address = rdr->jump_address;\r\nrestore_cr3 = rdr->cr3;\r\nreturn (rdr->magic == RESTORE_MAGIC) ? 0 : -EINVAL;\r\n}
