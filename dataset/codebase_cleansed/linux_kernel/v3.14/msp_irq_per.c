static inline void per_wmb(void)\r\n{\r\nconst volatile void __iomem *per_mem = PER_INT_MSK_REG;\r\nvolatile u32 dummy_read;\r\nwmb();\r\ndummy_read = __raw_readl(per_mem);\r\ndummy_read++;\r\n}\r\nstatic inline void unmask_per_irq(struct irq_data *d)\r\n{\r\n#ifdef CONFIG_SMP\r\nunsigned long flags;\r\nspin_lock_irqsave(&per_lock, flags);\r\n*PER_INT_MSK_REG |= (1 << (d->irq - MSP_PER_INTBASE));\r\nspin_unlock_irqrestore(&per_lock, flags);\r\n#else\r\n*PER_INT_MSK_REG |= (1 << (d->irq - MSP_PER_INTBASE));\r\n#endif\r\nper_wmb();\r\n}\r\nstatic inline void mask_per_irq(struct irq_data *d)\r\n{\r\n#ifdef CONFIG_SMP\r\nunsigned long flags;\r\nspin_lock_irqsave(&per_lock, flags);\r\n*PER_INT_MSK_REG &= ~(1 << (d->irq - MSP_PER_INTBASE));\r\nspin_unlock_irqrestore(&per_lock, flags);\r\n#else\r\n*PER_INT_MSK_REG &= ~(1 << (d->irq - MSP_PER_INTBASE));\r\n#endif\r\nper_wmb();\r\n}\r\nstatic inline void msp_per_irq_ack(struct irq_data *d)\r\n{\r\nmask_per_irq(d);\r\n*PER_INT_STS_REG = (1 << (d->irq - MSP_PER_INTBASE));\r\n}\r\nstatic int msp_per_irq_set_affinity(struct irq_data *d,\r\nconst struct cpumask *affinity, bool force)\r\n{\r\nunmask_per_irq(d);\r\nreturn 0;\r\n}\r\nvoid __init msp_per_irq_init(void)\r\n{\r\nint i;\r\n*PER_INT_MSK_REG = 0x00000000;\r\n*PER_INT_STS_REG = 0xFFFFFFFF;\r\nfor (i = MSP_PER_INTBASE; i < MSP_PER_INTBASE + 32; i++) {\r\nirq_set_chip(i, &msp_per_irq_controller);\r\n#ifdef CONFIG_MIPS_MT_SMTC\r\nirq_hwmask[i] = C_IRQ4;\r\n#endif\r\n}\r\n}\r\nvoid msp_per_irq_dispatch(void)\r\n{\r\nu32 per_mask = *PER_INT_MSK_REG;\r\nu32 per_status = *PER_INT_STS_REG;\r\nu32 pending;\r\npending = per_status & per_mask;\r\nif (pending) {\r\ndo_IRQ(ffs(pending) + MSP_PER_INTBASE - 1);\r\n} else {\r\nspurious_interrupt();\r\n}\r\n}
