struct net_device *e1000_get_hw_dev(struct e1000_hw *hw)\r\n{\r\nstruct e1000_adapter *adapter = hw->back;\r\nreturn adapter->netdev;\r\n}\r\nstatic int __init e1000_init_module(void)\r\n{\r\nint ret;\r\npr_info("%s - version %s\n", e1000_driver_string, e1000_driver_version);\r\npr_info("%s\n", e1000_copyright);\r\nret = pci_register_driver(&e1000_driver);\r\nif (copybreak != COPYBREAK_DEFAULT) {\r\nif (copybreak == 0)\r\npr_info("copybreak disabled\n");\r\nelse\r\npr_info("copybreak enabled for "\r\n"packets <= %u bytes\n", copybreak);\r\n}\r\nreturn ret;\r\n}\r\nstatic void __exit e1000_exit_module(void)\r\n{\r\npci_unregister_driver(&e1000_driver);\r\n}\r\nstatic int e1000_request_irq(struct e1000_adapter *adapter)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nirq_handler_t handler = e1000_intr;\r\nint irq_flags = IRQF_SHARED;\r\nint err;\r\nerr = request_irq(adapter->pdev->irq, handler, irq_flags, netdev->name,\r\nnetdev);\r\nif (err) {\r\ne_err(probe, "Unable to allocate interrupt Error: %d\n", err);\r\n}\r\nreturn err;\r\n}\r\nstatic void e1000_free_irq(struct e1000_adapter *adapter)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nfree_irq(adapter->pdev->irq, netdev);\r\n}\r\nstatic void e1000_irq_disable(struct e1000_adapter *adapter)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\new32(IMC, ~0);\r\nE1000_WRITE_FLUSH();\r\nsynchronize_irq(adapter->pdev->irq);\r\n}\r\nstatic void e1000_irq_enable(struct e1000_adapter *adapter)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\new32(IMS, IMS_ENABLE_MASK);\r\nE1000_WRITE_FLUSH();\r\n}\r\nstatic void e1000_update_mng_vlan(struct e1000_adapter *adapter)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nstruct net_device *netdev = adapter->netdev;\r\nu16 vid = hw->mng_cookie.vlan_id;\r\nu16 old_vid = adapter->mng_vlan_id;\r\nif (!e1000_vlan_used(adapter))\r\nreturn;\r\nif (!test_bit(vid, adapter->active_vlans)) {\r\nif (hw->mng_cookie.status &\r\nE1000_MNG_DHCP_COOKIE_STATUS_VLAN_SUPPORT) {\r\ne1000_vlan_rx_add_vid(netdev, htons(ETH_P_8021Q), vid);\r\nadapter->mng_vlan_id = vid;\r\n} else {\r\nadapter->mng_vlan_id = E1000_MNG_VLAN_NONE;\r\n}\r\nif ((old_vid != (u16)E1000_MNG_VLAN_NONE) &&\r\n(vid != old_vid) &&\r\n!test_bit(old_vid, adapter->active_vlans))\r\ne1000_vlan_rx_kill_vid(netdev, htons(ETH_P_8021Q),\r\nold_vid);\r\n} else {\r\nadapter->mng_vlan_id = vid;\r\n}\r\n}\r\nstatic void e1000_init_manageability(struct e1000_adapter *adapter)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nif (adapter->en_mng_pt) {\r\nu32 manc = er32(MANC);\r\nmanc &= ~(E1000_MANC_ARP_EN);\r\new32(MANC, manc);\r\n}\r\n}\r\nstatic void e1000_release_manageability(struct e1000_adapter *adapter)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nif (adapter->en_mng_pt) {\r\nu32 manc = er32(MANC);\r\nmanc |= E1000_MANC_ARP_EN;\r\new32(MANC, manc);\r\n}\r\n}\r\nstatic void e1000_configure(struct e1000_adapter *adapter)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nint i;\r\ne1000_set_rx_mode(netdev);\r\ne1000_restore_vlan(adapter);\r\ne1000_init_manageability(adapter);\r\ne1000_configure_tx(adapter);\r\ne1000_setup_rctl(adapter);\r\ne1000_configure_rx(adapter);\r\nfor (i = 0; i < adapter->num_rx_queues; i++) {\r\nstruct e1000_rx_ring *ring = &adapter->rx_ring[i];\r\nadapter->alloc_rx_buf(adapter, ring,\r\nE1000_DESC_UNUSED(ring));\r\n}\r\n}\r\nint e1000_up(struct e1000_adapter *adapter)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\ne1000_configure(adapter);\r\nclear_bit(__E1000_DOWN, &adapter->flags);\r\nnapi_enable(&adapter->napi);\r\ne1000_irq_enable(adapter);\r\nnetif_wake_queue(adapter->netdev);\r\new32(ICS, E1000_ICS_LSC);\r\nreturn 0;\r\n}\r\nvoid e1000_power_up_phy(struct e1000_adapter *adapter)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nu16 mii_reg = 0;\r\nif (hw->media_type == e1000_media_type_copper) {\r\ne1000_read_phy_reg(hw, PHY_CTRL, &mii_reg);\r\nmii_reg &= ~MII_CR_POWER_DOWN;\r\ne1000_write_phy_reg(hw, PHY_CTRL, mii_reg);\r\n}\r\n}\r\nstatic void e1000_power_down_phy(struct e1000_adapter *adapter)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nif (!adapter->wol && hw->mac_type >= e1000_82540 &&\r\nhw->media_type == e1000_media_type_copper) {\r\nu16 mii_reg = 0;\r\nswitch (hw->mac_type) {\r\ncase e1000_82540:\r\ncase e1000_82545:\r\ncase e1000_82545_rev_3:\r\ncase e1000_82546:\r\ncase e1000_ce4100:\r\ncase e1000_82546_rev_3:\r\ncase e1000_82541:\r\ncase e1000_82541_rev_2:\r\ncase e1000_82547:\r\ncase e1000_82547_rev_2:\r\nif (er32(MANC) & E1000_MANC_SMBUS_EN)\r\ngoto out;\r\nbreak;\r\ndefault:\r\ngoto out;\r\n}\r\ne1000_read_phy_reg(hw, PHY_CTRL, &mii_reg);\r\nmii_reg |= MII_CR_POWER_DOWN;\r\ne1000_write_phy_reg(hw, PHY_CTRL, mii_reg);\r\nmsleep(1);\r\n}\r\nout:\r\nreturn;\r\n}\r\nstatic void e1000_down_and_stop(struct e1000_adapter *adapter)\r\n{\r\nset_bit(__E1000_DOWN, &adapter->flags);\r\ncancel_delayed_work_sync(&adapter->watchdog_task);\r\ncancel_delayed_work_sync(&adapter->phy_info_task);\r\ncancel_delayed_work_sync(&adapter->fifo_stall_task);\r\nif (!test_bit(__E1000_RESETTING, &adapter->flags))\r\ncancel_work_sync(&adapter->reset_task);\r\n}\r\nvoid e1000_down(struct e1000_adapter *adapter)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nstruct net_device *netdev = adapter->netdev;\r\nu32 rctl, tctl;\r\nrctl = er32(RCTL);\r\new32(RCTL, rctl & ~E1000_RCTL_EN);\r\nnetif_tx_disable(netdev);\r\ntctl = er32(TCTL);\r\ntctl &= ~E1000_TCTL_EN;\r\new32(TCTL, tctl);\r\nE1000_WRITE_FLUSH();\r\nmsleep(10);\r\nnapi_disable(&adapter->napi);\r\ne1000_irq_disable(adapter);\r\ne1000_down_and_stop(adapter);\r\nadapter->link_speed = 0;\r\nadapter->link_duplex = 0;\r\nnetif_carrier_off(netdev);\r\ne1000_reset(adapter);\r\ne1000_clean_all_tx_rings(adapter);\r\ne1000_clean_all_rx_rings(adapter);\r\n}\r\nvoid e1000_reinit_locked(struct e1000_adapter *adapter)\r\n{\r\nWARN_ON(in_interrupt());\r\nwhile (test_and_set_bit(__E1000_RESETTING, &adapter->flags))\r\nmsleep(1);\r\ne1000_down(adapter);\r\ne1000_up(adapter);\r\nclear_bit(__E1000_RESETTING, &adapter->flags);\r\n}\r\nvoid e1000_reset(struct e1000_adapter *adapter)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nu32 pba = 0, tx_space, min_tx_space, min_rx_space;\r\nbool legacy_pba_adjust = false;\r\nu16 hwm;\r\nswitch (hw->mac_type) {\r\ncase e1000_82542_rev2_0:\r\ncase e1000_82542_rev2_1:\r\ncase e1000_82543:\r\ncase e1000_82544:\r\ncase e1000_82540:\r\ncase e1000_82541:\r\ncase e1000_82541_rev_2:\r\nlegacy_pba_adjust = true;\r\npba = E1000_PBA_48K;\r\nbreak;\r\ncase e1000_82545:\r\ncase e1000_82545_rev_3:\r\ncase e1000_82546:\r\ncase e1000_ce4100:\r\ncase e1000_82546_rev_3:\r\npba = E1000_PBA_48K;\r\nbreak;\r\ncase e1000_82547:\r\ncase e1000_82547_rev_2:\r\nlegacy_pba_adjust = true;\r\npba = E1000_PBA_30K;\r\nbreak;\r\ncase e1000_undefined:\r\ncase e1000_num_macs:\r\nbreak;\r\n}\r\nif (legacy_pba_adjust) {\r\nif (hw->max_frame_size > E1000_RXBUFFER_8192)\r\npba -= 8;\r\nif (hw->mac_type == e1000_82547) {\r\nadapter->tx_fifo_head = 0;\r\nadapter->tx_head_addr = pba << E1000_TX_HEAD_ADDR_SHIFT;\r\nadapter->tx_fifo_size =\r\n(E1000_PBA_40K - pba) << E1000_PBA_BYTES_SHIFT;\r\natomic_set(&adapter->tx_fifo_stall, 0);\r\n}\r\n} else if (hw->max_frame_size > ETH_FRAME_LEN + ETH_FCS_LEN) {\r\new32(PBA, pba);\r\npba = er32(PBA);\r\ntx_space = pba >> 16;\r\npba &= 0xffff;\r\nmin_tx_space = (hw->max_frame_size +\r\nsizeof(struct e1000_tx_desc) -\r\nETH_FCS_LEN) * 2;\r\nmin_tx_space = ALIGN(min_tx_space, 1024);\r\nmin_tx_space >>= 10;\r\nmin_rx_space = hw->max_frame_size;\r\nmin_rx_space = ALIGN(min_rx_space, 1024);\r\nmin_rx_space >>= 10;\r\nif (tx_space < min_tx_space &&\r\n((min_tx_space - tx_space) < pba)) {\r\npba = pba - (min_tx_space - tx_space);\r\nswitch (hw->mac_type) {\r\ncase e1000_82545 ... e1000_82546_rev_3:\r\npba &= ~(E1000_PBA_8K - 1);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nif (pba < min_rx_space)\r\npba = min_rx_space;\r\n}\r\n}\r\new32(PBA, pba);\r\nhwm = min(((pba << 10) * 9 / 10),\r\n((pba << 10) - hw->max_frame_size));\r\nhw->fc_high_water = hwm & 0xFFF8;\r\nhw->fc_low_water = hw->fc_high_water - 8;\r\nhw->fc_pause_time = E1000_FC_PAUSE_TIME;\r\nhw->fc_send_xon = 1;\r\nhw->fc = hw->original_fc;\r\ne1000_reset_hw(hw);\r\nif (hw->mac_type >= e1000_82544)\r\new32(WUC, 0);\r\nif (e1000_init_hw(hw))\r\ne_dev_err("Hardware Error\n");\r\ne1000_update_mng_vlan(adapter);\r\nif (hw->mac_type >= e1000_82544 &&\r\nhw->autoneg == 1 &&\r\nhw->autoneg_advertised == ADVERTISE_1000_FULL) {\r\nu32 ctrl = er32(CTRL);\r\nctrl &= ~E1000_CTRL_SWDPIN3;\r\new32(CTRL, ctrl);\r\n}\r\new32(VET, ETHERNET_IEEE_VLAN_TYPE);\r\ne1000_reset_adaptive(hw);\r\ne1000_phy_get_info(hw, &adapter->phy_info);\r\ne1000_release_manageability(adapter);\r\n}\r\nstatic void e1000_dump_eeprom(struct e1000_adapter *adapter)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct ethtool_eeprom eeprom;\r\nconst struct ethtool_ops *ops = netdev->ethtool_ops;\r\nu8 *data;\r\nint i;\r\nu16 csum_old, csum_new = 0;\r\neeprom.len = ops->get_eeprom_len(netdev);\r\neeprom.offset = 0;\r\ndata = kmalloc(eeprom.len, GFP_KERNEL);\r\nif (!data)\r\nreturn;\r\nops->get_eeprom(netdev, &eeprom, data);\r\ncsum_old = (data[EEPROM_CHECKSUM_REG * 2]) +\r\n(data[EEPROM_CHECKSUM_REG * 2 + 1] << 8);\r\nfor (i = 0; i < EEPROM_CHECKSUM_REG * 2; i += 2)\r\ncsum_new += data[i] + (data[i + 1] << 8);\r\ncsum_new = EEPROM_SUM - csum_new;\r\npr_err("/*********************/\n");\r\npr_err("Current EEPROM Checksum : 0x%04x\n", csum_old);\r\npr_err("Calculated : 0x%04x\n", csum_new);\r\npr_err("Offset Values\n");\r\npr_err("======== ======\n");\r\nprint_hex_dump(KERN_ERR, "", DUMP_PREFIX_OFFSET, 16, 1, data, 128, 0);\r\npr_err("Include this output when contacting your support provider.\n");\r\npr_err("This is not a software error! Something bad happened to\n");\r\npr_err("your hardware or EEPROM image. Ignoring this problem could\n");\r\npr_err("result in further problems, possibly loss of data,\n");\r\npr_err("corruption or system hangs!\n");\r\npr_err("The MAC Address will be reset to 00:00:00:00:00:00,\n");\r\npr_err("which is invalid and requires you to set the proper MAC\n");\r\npr_err("address manually before continuing to enable this network\n");\r\npr_err("device. Please inspect the EEPROM dump and report the\n");\r\npr_err("issue to your hardware vendor or Intel Customer Support.\n");\r\npr_err("/*********************/\n");\r\nkfree(data);\r\n}\r\nstatic int e1000_is_need_ioport(struct pci_dev *pdev)\r\n{\r\nswitch (pdev->device) {\r\ncase E1000_DEV_ID_82540EM:\r\ncase E1000_DEV_ID_82540EM_LOM:\r\ncase E1000_DEV_ID_82540EP:\r\ncase E1000_DEV_ID_82540EP_LOM:\r\ncase E1000_DEV_ID_82540EP_LP:\r\ncase E1000_DEV_ID_82541EI:\r\ncase E1000_DEV_ID_82541EI_MOBILE:\r\ncase E1000_DEV_ID_82541ER:\r\ncase E1000_DEV_ID_82541ER_LOM:\r\ncase E1000_DEV_ID_82541GI:\r\ncase E1000_DEV_ID_82541GI_LF:\r\ncase E1000_DEV_ID_82541GI_MOBILE:\r\ncase E1000_DEV_ID_82544EI_COPPER:\r\ncase E1000_DEV_ID_82544EI_FIBER:\r\ncase E1000_DEV_ID_82544GC_COPPER:\r\ncase E1000_DEV_ID_82544GC_LOM:\r\ncase E1000_DEV_ID_82545EM_COPPER:\r\ncase E1000_DEV_ID_82545EM_FIBER:\r\ncase E1000_DEV_ID_82546EB_COPPER:\r\ncase E1000_DEV_ID_82546EB_FIBER:\r\ncase E1000_DEV_ID_82546EB_QUAD_COPPER:\r\nreturn true;\r\ndefault:\r\nreturn false;\r\n}\r\n}\r\nstatic netdev_features_t e1000_fix_features(struct net_device *netdev,\r\nnetdev_features_t features)\r\n{\r\nif (features & NETIF_F_HW_VLAN_CTAG_RX)\r\nfeatures |= NETIF_F_HW_VLAN_CTAG_TX;\r\nelse\r\nfeatures &= ~NETIF_F_HW_VLAN_CTAG_TX;\r\nreturn features;\r\n}\r\nstatic int e1000_set_features(struct net_device *netdev,\r\nnetdev_features_t features)\r\n{\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\nnetdev_features_t changed = features ^ netdev->features;\r\nif (changed & NETIF_F_HW_VLAN_CTAG_RX)\r\ne1000_vlan_mode(netdev, features);\r\nif (!(changed & (NETIF_F_RXCSUM | NETIF_F_RXALL)))\r\nreturn 0;\r\nnetdev->features = features;\r\nadapter->rx_csum = !!(features & NETIF_F_RXCSUM);\r\nif (netif_running(netdev))\r\ne1000_reinit_locked(adapter);\r\nelse\r\ne1000_reset(adapter);\r\nreturn 0;\r\n}\r\nstatic int e1000_init_hw_struct(struct e1000_adapter *adapter,\r\nstruct e1000_hw *hw)\r\n{\r\nstruct pci_dev *pdev = adapter->pdev;\r\nhw->vendor_id = pdev->vendor;\r\nhw->device_id = pdev->device;\r\nhw->subsystem_vendor_id = pdev->subsystem_vendor;\r\nhw->subsystem_id = pdev->subsystem_device;\r\nhw->revision_id = pdev->revision;\r\npci_read_config_word(pdev, PCI_COMMAND, &hw->pci_cmd_word);\r\nhw->max_frame_size = adapter->netdev->mtu +\r\nENET_HEADER_SIZE + ETHERNET_FCS_SIZE;\r\nhw->min_frame_size = MINIMUM_ETHERNET_FRAME_SIZE;\r\nif (e1000_set_mac_type(hw)) {\r\ne_err(probe, "Unknown MAC Type\n");\r\nreturn -EIO;\r\n}\r\nswitch (hw->mac_type) {\r\ndefault:\r\nbreak;\r\ncase e1000_82541:\r\ncase e1000_82547:\r\ncase e1000_82541_rev_2:\r\ncase e1000_82547_rev_2:\r\nhw->phy_init_script = 1;\r\nbreak;\r\n}\r\ne1000_set_media_type(hw);\r\ne1000_get_bus_info(hw);\r\nhw->wait_autoneg_complete = false;\r\nhw->tbi_compatibility_en = true;\r\nhw->adaptive_ifs = true;\r\nif (hw->media_type == e1000_media_type_copper) {\r\nhw->mdix = AUTO_ALL_MODES;\r\nhw->disable_polarity_correction = false;\r\nhw->master_slave = E1000_MASTER_SLAVE;\r\n}\r\nreturn 0;\r\n}\r\nstatic int e1000_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\r\n{\r\nstruct net_device *netdev;\r\nstruct e1000_adapter *adapter;\r\nstruct e1000_hw *hw;\r\nstatic int cards_found = 0;\r\nstatic int global_quad_port_a = 0;\r\nint i, err, pci_using_dac;\r\nu16 eeprom_data = 0;\r\nu16 tmp = 0;\r\nu16 eeprom_apme_mask = E1000_EEPROM_APME;\r\nint bars, need_ioport;\r\nneed_ioport = e1000_is_need_ioport(pdev);\r\nif (need_ioport) {\r\nbars = pci_select_bars(pdev, IORESOURCE_MEM | IORESOURCE_IO);\r\nerr = pci_enable_device(pdev);\r\n} else {\r\nbars = pci_select_bars(pdev, IORESOURCE_MEM);\r\nerr = pci_enable_device_mem(pdev);\r\n}\r\nif (err)\r\nreturn err;\r\nerr = pci_request_selected_regions(pdev, bars, e1000_driver_name);\r\nif (err)\r\ngoto err_pci_reg;\r\npci_set_master(pdev);\r\nerr = pci_save_state(pdev);\r\nif (err)\r\ngoto err_alloc_etherdev;\r\nerr = -ENOMEM;\r\nnetdev = alloc_etherdev(sizeof(struct e1000_adapter));\r\nif (!netdev)\r\ngoto err_alloc_etherdev;\r\nSET_NETDEV_DEV(netdev, &pdev->dev);\r\npci_set_drvdata(pdev, netdev);\r\nadapter = netdev_priv(netdev);\r\nadapter->netdev = netdev;\r\nadapter->pdev = pdev;\r\nadapter->msg_enable = netif_msg_init(debug, DEFAULT_MSG_ENABLE);\r\nadapter->bars = bars;\r\nadapter->need_ioport = need_ioport;\r\nhw = &adapter->hw;\r\nhw->back = adapter;\r\nerr = -EIO;\r\nhw->hw_addr = pci_ioremap_bar(pdev, BAR_0);\r\nif (!hw->hw_addr)\r\ngoto err_ioremap;\r\nif (adapter->need_ioport) {\r\nfor (i = BAR_1; i <= BAR_5; i++) {\r\nif (pci_resource_len(pdev, i) == 0)\r\ncontinue;\r\nif (pci_resource_flags(pdev, i) & IORESOURCE_IO) {\r\nhw->io_base = pci_resource_start(pdev, i);\r\nbreak;\r\n}\r\n}\r\n}\r\nerr = e1000_init_hw_struct(adapter, hw);\r\nif (err)\r\ngoto err_sw_init;\r\npci_using_dac = 0;\r\nif ((hw->bus_type == e1000_bus_type_pcix) &&\r\n!dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(64))) {\r\npci_using_dac = 1;\r\n} else {\r\nerr = dma_set_mask_and_coherent(&pdev->dev, DMA_BIT_MASK(32));\r\nif (err) {\r\npr_err("No usable DMA config, aborting\n");\r\ngoto err_dma;\r\n}\r\n}\r\nnetdev->netdev_ops = &e1000_netdev_ops;\r\ne1000_set_ethtool_ops(netdev);\r\nnetdev->watchdog_timeo = 5 * HZ;\r\nnetif_napi_add(netdev, &adapter->napi, e1000_clean, 64);\r\nstrncpy(netdev->name, pci_name(pdev), sizeof(netdev->name) - 1);\r\nadapter->bd_number = cards_found;\r\nerr = e1000_sw_init(adapter);\r\nif (err)\r\ngoto err_sw_init;\r\nerr = -EIO;\r\nif (hw->mac_type == e1000_ce4100) {\r\nhw->ce4100_gbe_mdio_base_virt =\r\nioremap(pci_resource_start(pdev, BAR_1),\r\npci_resource_len(pdev, BAR_1));\r\nif (!hw->ce4100_gbe_mdio_base_virt)\r\ngoto err_mdio_ioremap;\r\n}\r\nif (hw->mac_type >= e1000_82543) {\r\nnetdev->hw_features = NETIF_F_SG |\r\nNETIF_F_HW_CSUM |\r\nNETIF_F_HW_VLAN_CTAG_RX;\r\nnetdev->features = NETIF_F_HW_VLAN_CTAG_TX |\r\nNETIF_F_HW_VLAN_CTAG_FILTER;\r\n}\r\nif ((hw->mac_type >= e1000_82544) &&\r\n(hw->mac_type != e1000_82547))\r\nnetdev->hw_features |= NETIF_F_TSO;\r\nnetdev->priv_flags |= IFF_SUPP_NOFCS;\r\nnetdev->features |= netdev->hw_features;\r\nnetdev->hw_features |= (NETIF_F_RXCSUM |\r\nNETIF_F_RXALL |\r\nNETIF_F_RXFCS);\r\nif (pci_using_dac) {\r\nnetdev->features |= NETIF_F_HIGHDMA;\r\nnetdev->vlan_features |= NETIF_F_HIGHDMA;\r\n}\r\nnetdev->vlan_features |= (NETIF_F_TSO |\r\nNETIF_F_HW_CSUM |\r\nNETIF_F_SG);\r\nnetdev->priv_flags |= IFF_UNICAST_FLT;\r\nadapter->en_mng_pt = e1000_enable_mng_pass_thru(hw);\r\nif (e1000_init_eeprom_params(hw)) {\r\ne_err(probe, "EEPROM initialization failed\n");\r\ngoto err_eeprom;\r\n}\r\ne1000_reset_hw(hw);\r\nif (e1000_validate_eeprom_checksum(hw) < 0) {\r\ne_err(probe, "The EEPROM Checksum Is Not Valid\n");\r\ne1000_dump_eeprom(adapter);\r\nmemset(hw->mac_addr, 0, netdev->addr_len);\r\n} else {\r\nif (e1000_read_mac_addr(hw))\r\ne_err(probe, "EEPROM Read Error\n");\r\n}\r\nmemcpy(netdev->dev_addr, hw->mac_addr, netdev->addr_len);\r\nif (!is_valid_ether_addr(netdev->dev_addr))\r\ne_err(probe, "Invalid MAC Address\n");\r\nINIT_DELAYED_WORK(&adapter->watchdog_task, e1000_watchdog);\r\nINIT_DELAYED_WORK(&adapter->fifo_stall_task,\r\ne1000_82547_tx_fifo_stall_task);\r\nINIT_DELAYED_WORK(&adapter->phy_info_task, e1000_update_phy_info_task);\r\nINIT_WORK(&adapter->reset_task, e1000_reset_task);\r\ne1000_check_options(adapter);\r\nswitch (hw->mac_type) {\r\ncase e1000_82542_rev2_0:\r\ncase e1000_82542_rev2_1:\r\ncase e1000_82543:\r\nbreak;\r\ncase e1000_82544:\r\ne1000_read_eeprom(hw,\r\nEEPROM_INIT_CONTROL2_REG, 1, &eeprom_data);\r\neeprom_apme_mask = E1000_EEPROM_82544_APM;\r\nbreak;\r\ncase e1000_82546:\r\ncase e1000_82546_rev_3:\r\nif (er32(STATUS) & E1000_STATUS_FUNC_1){\r\ne1000_read_eeprom(hw,\r\nEEPROM_INIT_CONTROL3_PORT_B, 1, &eeprom_data);\r\nbreak;\r\n}\r\ndefault:\r\ne1000_read_eeprom(hw,\r\nEEPROM_INIT_CONTROL3_PORT_A, 1, &eeprom_data);\r\nbreak;\r\n}\r\nif (eeprom_data & eeprom_apme_mask)\r\nadapter->eeprom_wol |= E1000_WUFC_MAG;\r\nswitch (pdev->device) {\r\ncase E1000_DEV_ID_82546GB_PCIE:\r\nadapter->eeprom_wol = 0;\r\nbreak;\r\ncase E1000_DEV_ID_82546EB_FIBER:\r\ncase E1000_DEV_ID_82546GB_FIBER:\r\nif (er32(STATUS) & E1000_STATUS_FUNC_1)\r\nadapter->eeprom_wol = 0;\r\nbreak;\r\ncase E1000_DEV_ID_82546GB_QUAD_COPPER_KSP3:\r\nif (global_quad_port_a != 0)\r\nadapter->eeprom_wol = 0;\r\nelse\r\nadapter->quad_port_a = true;\r\nif (++global_quad_port_a == 4)\r\nglobal_quad_port_a = 0;\r\nbreak;\r\n}\r\nadapter->wol = adapter->eeprom_wol;\r\ndevice_set_wakeup_enable(&adapter->pdev->dev, adapter->wol);\r\nif (hw->mac_type == e1000_ce4100) {\r\nfor (i = 0; i < 32; i++) {\r\nhw->phy_addr = i;\r\ne1000_read_phy_reg(hw, PHY_ID2, &tmp);\r\nif (tmp == 0 || tmp == 0xFF) {\r\nif (i == 31)\r\ngoto err_eeprom;\r\ncontinue;\r\n} else\r\nbreak;\r\n}\r\n}\r\ne1000_reset(adapter);\r\nstrcpy(netdev->name, "eth%d");\r\nerr = register_netdev(netdev);\r\nif (err)\r\ngoto err_register;\r\ne1000_vlan_filter_on_off(adapter, false);\r\ne_info(probe, "(PCI%s:%dMHz:%d-bit) %pM\n",\r\n((hw->bus_type == e1000_bus_type_pcix) ? "-X" : ""),\r\n((hw->bus_speed == e1000_bus_speed_133) ? 133 :\r\n(hw->bus_speed == e1000_bus_speed_120) ? 120 :\r\n(hw->bus_speed == e1000_bus_speed_100) ? 100 :\r\n(hw->bus_speed == e1000_bus_speed_66) ? 66 : 33),\r\n((hw->bus_width == e1000_bus_width_64) ? 64 : 32),\r\nnetdev->dev_addr);\r\nnetif_carrier_off(netdev);\r\ne_info(probe, "Intel(R) PRO/1000 Network Connection\n");\r\ncards_found++;\r\nreturn 0;\r\nerr_register:\r\nerr_eeprom:\r\ne1000_phy_hw_reset(hw);\r\nif (hw->flash_address)\r\niounmap(hw->flash_address);\r\nkfree(adapter->tx_ring);\r\nkfree(adapter->rx_ring);\r\nerr_dma:\r\nerr_sw_init:\r\nerr_mdio_ioremap:\r\niounmap(hw->ce4100_gbe_mdio_base_virt);\r\niounmap(hw->hw_addr);\r\nerr_ioremap:\r\nfree_netdev(netdev);\r\nerr_alloc_etherdev:\r\npci_release_selected_regions(pdev, bars);\r\nerr_pci_reg:\r\npci_disable_device(pdev);\r\nreturn err;\r\n}\r\nstatic void e1000_remove(struct pci_dev *pdev)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\nstruct e1000_hw *hw = &adapter->hw;\r\ne1000_down_and_stop(adapter);\r\ne1000_release_manageability(adapter);\r\nunregister_netdev(netdev);\r\ne1000_phy_hw_reset(hw);\r\nkfree(adapter->tx_ring);\r\nkfree(adapter->rx_ring);\r\nif (hw->mac_type == e1000_ce4100)\r\niounmap(hw->ce4100_gbe_mdio_base_virt);\r\niounmap(hw->hw_addr);\r\nif (hw->flash_address)\r\niounmap(hw->flash_address);\r\npci_release_selected_regions(pdev, adapter->bars);\r\nfree_netdev(netdev);\r\npci_disable_device(pdev);\r\n}\r\nstatic int e1000_sw_init(struct e1000_adapter *adapter)\r\n{\r\nadapter->rx_buffer_len = MAXIMUM_ETHERNET_VLAN_SIZE;\r\nadapter->num_tx_queues = 1;\r\nadapter->num_rx_queues = 1;\r\nif (e1000_alloc_queues(adapter)) {\r\ne_err(probe, "Unable to allocate memory for queues\n");\r\nreturn -ENOMEM;\r\n}\r\ne1000_irq_disable(adapter);\r\nspin_lock_init(&adapter->stats_lock);\r\nset_bit(__E1000_DOWN, &adapter->flags);\r\nreturn 0;\r\n}\r\nstatic int e1000_alloc_queues(struct e1000_adapter *adapter)\r\n{\r\nadapter->tx_ring = kcalloc(adapter->num_tx_queues,\r\nsizeof(struct e1000_tx_ring), GFP_KERNEL);\r\nif (!adapter->tx_ring)\r\nreturn -ENOMEM;\r\nadapter->rx_ring = kcalloc(adapter->num_rx_queues,\r\nsizeof(struct e1000_rx_ring), GFP_KERNEL);\r\nif (!adapter->rx_ring) {\r\nkfree(adapter->tx_ring);\r\nreturn -ENOMEM;\r\n}\r\nreturn E1000_SUCCESS;\r\n}\r\nstatic int e1000_open(struct net_device *netdev)\r\n{\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\nstruct e1000_hw *hw = &adapter->hw;\r\nint err;\r\nif (test_bit(__E1000_TESTING, &adapter->flags))\r\nreturn -EBUSY;\r\nnetif_carrier_off(netdev);\r\nerr = e1000_setup_all_tx_resources(adapter);\r\nif (err)\r\ngoto err_setup_tx;\r\nerr = e1000_setup_all_rx_resources(adapter);\r\nif (err)\r\ngoto err_setup_rx;\r\ne1000_power_up_phy(adapter);\r\nadapter->mng_vlan_id = E1000_MNG_VLAN_NONE;\r\nif ((hw->mng_cookie.status &\r\nE1000_MNG_DHCP_COOKIE_STATUS_VLAN_SUPPORT)) {\r\ne1000_update_mng_vlan(adapter);\r\n}\r\ne1000_configure(adapter);\r\nerr = e1000_request_irq(adapter);\r\nif (err)\r\ngoto err_req_irq;\r\nclear_bit(__E1000_DOWN, &adapter->flags);\r\nnapi_enable(&adapter->napi);\r\ne1000_irq_enable(adapter);\r\nnetif_start_queue(netdev);\r\new32(ICS, E1000_ICS_LSC);\r\nreturn E1000_SUCCESS;\r\nerr_req_irq:\r\ne1000_power_down_phy(adapter);\r\ne1000_free_all_rx_resources(adapter);\r\nerr_setup_rx:\r\ne1000_free_all_tx_resources(adapter);\r\nerr_setup_tx:\r\ne1000_reset(adapter);\r\nreturn err;\r\n}\r\nstatic int e1000_close(struct net_device *netdev)\r\n{\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\nstruct e1000_hw *hw = &adapter->hw;\r\nint count = E1000_CHECK_RESET_COUNT;\r\nwhile (test_bit(__E1000_RESETTING, &adapter->flags) && count--)\r\nusleep_range(10000, 20000);\r\nWARN_ON(test_bit(__E1000_RESETTING, &adapter->flags));\r\ne1000_down(adapter);\r\ne1000_power_down_phy(adapter);\r\ne1000_free_irq(adapter);\r\ne1000_free_all_tx_resources(adapter);\r\ne1000_free_all_rx_resources(adapter);\r\nif ((hw->mng_cookie.status &\r\nE1000_MNG_DHCP_COOKIE_STATUS_VLAN_SUPPORT) &&\r\n!test_bit(adapter->mng_vlan_id, adapter->active_vlans)) {\r\ne1000_vlan_rx_kill_vid(netdev, htons(ETH_P_8021Q),\r\nadapter->mng_vlan_id);\r\n}\r\nreturn 0;\r\n}\r\nstatic bool e1000_check_64k_bound(struct e1000_adapter *adapter, void *start,\r\nunsigned long len)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nunsigned long begin = (unsigned long)start;\r\nunsigned long end = begin + len;\r\nif (hw->mac_type == e1000_82545 ||\r\nhw->mac_type == e1000_ce4100 ||\r\nhw->mac_type == e1000_82546) {\r\nreturn ((begin ^ (end - 1)) >> 16) != 0 ? false : true;\r\n}\r\nreturn true;\r\n}\r\nstatic int e1000_setup_tx_resources(struct e1000_adapter *adapter,\r\nstruct e1000_tx_ring *txdr)\r\n{\r\nstruct pci_dev *pdev = adapter->pdev;\r\nint size;\r\nsize = sizeof(struct e1000_buffer) * txdr->count;\r\ntxdr->buffer_info = vzalloc(size);\r\nif (!txdr->buffer_info)\r\nreturn -ENOMEM;\r\ntxdr->size = txdr->count * sizeof(struct e1000_tx_desc);\r\ntxdr->size = ALIGN(txdr->size, 4096);\r\ntxdr->desc = dma_alloc_coherent(&pdev->dev, txdr->size, &txdr->dma,\r\nGFP_KERNEL);\r\nif (!txdr->desc) {\r\nsetup_tx_desc_die:\r\nvfree(txdr->buffer_info);\r\nreturn -ENOMEM;\r\n}\r\nif (!e1000_check_64k_bound(adapter, txdr->desc, txdr->size)) {\r\nvoid *olddesc = txdr->desc;\r\ndma_addr_t olddma = txdr->dma;\r\ne_err(tx_err, "txdr align check failed: %u bytes at %p\n",\r\ntxdr->size, txdr->desc);\r\ntxdr->desc = dma_alloc_coherent(&pdev->dev, txdr->size,\r\n&txdr->dma, GFP_KERNEL);\r\nif (!txdr->desc) {\r\ndma_free_coherent(&pdev->dev, txdr->size, olddesc,\r\nolddma);\r\ngoto setup_tx_desc_die;\r\n}\r\nif (!e1000_check_64k_bound(adapter, txdr->desc, txdr->size)) {\r\ndma_free_coherent(&pdev->dev, txdr->size, txdr->desc,\r\ntxdr->dma);\r\ndma_free_coherent(&pdev->dev, txdr->size, olddesc,\r\nolddma);\r\ne_err(probe, "Unable to allocate aligned memory "\r\n"for the transmit descriptor ring\n");\r\nvfree(txdr->buffer_info);\r\nreturn -ENOMEM;\r\n} else {\r\ndma_free_coherent(&pdev->dev, txdr->size, olddesc,\r\nolddma);\r\n}\r\n}\r\nmemset(txdr->desc, 0, txdr->size);\r\ntxdr->next_to_use = 0;\r\ntxdr->next_to_clean = 0;\r\nreturn 0;\r\n}\r\nint e1000_setup_all_tx_resources(struct e1000_adapter *adapter)\r\n{\r\nint i, err = 0;\r\nfor (i = 0; i < adapter->num_tx_queues; i++) {\r\nerr = e1000_setup_tx_resources(adapter, &adapter->tx_ring[i]);\r\nif (err) {\r\ne_err(probe, "Allocation for Tx Queue %u failed\n", i);\r\nfor (i-- ; i >= 0; i--)\r\ne1000_free_tx_resources(adapter,\r\n&adapter->tx_ring[i]);\r\nbreak;\r\n}\r\n}\r\nreturn err;\r\n}\r\nstatic void e1000_configure_tx(struct e1000_adapter *adapter)\r\n{\r\nu64 tdba;\r\nstruct e1000_hw *hw = &adapter->hw;\r\nu32 tdlen, tctl, tipg;\r\nu32 ipgr1, ipgr2;\r\nswitch (adapter->num_tx_queues) {\r\ncase 1:\r\ndefault:\r\ntdba = adapter->tx_ring[0].dma;\r\ntdlen = adapter->tx_ring[0].count *\r\nsizeof(struct e1000_tx_desc);\r\new32(TDLEN, tdlen);\r\new32(TDBAH, (tdba >> 32));\r\new32(TDBAL, (tdba & 0x00000000ffffffffULL));\r\new32(TDT, 0);\r\new32(TDH, 0);\r\nadapter->tx_ring[0].tdh = ((hw->mac_type >= e1000_82543) ?\r\nE1000_TDH : E1000_82542_TDH);\r\nadapter->tx_ring[0].tdt = ((hw->mac_type >= e1000_82543) ?\r\nE1000_TDT : E1000_82542_TDT);\r\nbreak;\r\n}\r\nif ((hw->media_type == e1000_media_type_fiber ||\r\nhw->media_type == e1000_media_type_internal_serdes))\r\ntipg = DEFAULT_82543_TIPG_IPGT_FIBER;\r\nelse\r\ntipg = DEFAULT_82543_TIPG_IPGT_COPPER;\r\nswitch (hw->mac_type) {\r\ncase e1000_82542_rev2_0:\r\ncase e1000_82542_rev2_1:\r\ntipg = DEFAULT_82542_TIPG_IPGT;\r\nipgr1 = DEFAULT_82542_TIPG_IPGR1;\r\nipgr2 = DEFAULT_82542_TIPG_IPGR2;\r\nbreak;\r\ndefault:\r\nipgr1 = DEFAULT_82543_TIPG_IPGR1;\r\nipgr2 = DEFAULT_82543_TIPG_IPGR2;\r\nbreak;\r\n}\r\ntipg |= ipgr1 << E1000_TIPG_IPGR1_SHIFT;\r\ntipg |= ipgr2 << E1000_TIPG_IPGR2_SHIFT;\r\new32(TIPG, tipg);\r\new32(TIDV, adapter->tx_int_delay);\r\nif (hw->mac_type >= e1000_82540)\r\new32(TADV, adapter->tx_abs_int_delay);\r\ntctl = er32(TCTL);\r\ntctl &= ~E1000_TCTL_CT;\r\ntctl |= E1000_TCTL_PSP | E1000_TCTL_RTLC |\r\n(E1000_COLLISION_THRESHOLD << E1000_CT_SHIFT);\r\ne1000_config_collision_dist(hw);\r\nadapter->txd_cmd = E1000_TXD_CMD_EOP | E1000_TXD_CMD_IFCS;\r\nif (adapter->tx_int_delay)\r\nadapter->txd_cmd |= E1000_TXD_CMD_IDE;\r\nif (hw->mac_type < e1000_82543)\r\nadapter->txd_cmd |= E1000_TXD_CMD_RPS;\r\nelse\r\nadapter->txd_cmd |= E1000_TXD_CMD_RS;\r\nif (hw->mac_type == e1000_82544 &&\r\nhw->bus_type == e1000_bus_type_pcix)\r\nadapter->pcix_82544 = true;\r\new32(TCTL, tctl);\r\n}\r\nstatic int e1000_setup_rx_resources(struct e1000_adapter *adapter,\r\nstruct e1000_rx_ring *rxdr)\r\n{\r\nstruct pci_dev *pdev = adapter->pdev;\r\nint size, desc_len;\r\nsize = sizeof(struct e1000_buffer) * rxdr->count;\r\nrxdr->buffer_info = vzalloc(size);\r\nif (!rxdr->buffer_info)\r\nreturn -ENOMEM;\r\ndesc_len = sizeof(struct e1000_rx_desc);\r\nrxdr->size = rxdr->count * desc_len;\r\nrxdr->size = ALIGN(rxdr->size, 4096);\r\nrxdr->desc = dma_alloc_coherent(&pdev->dev, rxdr->size, &rxdr->dma,\r\nGFP_KERNEL);\r\nif (!rxdr->desc) {\r\nsetup_rx_desc_die:\r\nvfree(rxdr->buffer_info);\r\nreturn -ENOMEM;\r\n}\r\nif (!e1000_check_64k_bound(adapter, rxdr->desc, rxdr->size)) {\r\nvoid *olddesc = rxdr->desc;\r\ndma_addr_t olddma = rxdr->dma;\r\ne_err(rx_err, "rxdr align check failed: %u bytes at %p\n",\r\nrxdr->size, rxdr->desc);\r\nrxdr->desc = dma_alloc_coherent(&pdev->dev, rxdr->size,\r\n&rxdr->dma, GFP_KERNEL);\r\nif (!rxdr->desc) {\r\ndma_free_coherent(&pdev->dev, rxdr->size, olddesc,\r\nolddma);\r\ngoto setup_rx_desc_die;\r\n}\r\nif (!e1000_check_64k_bound(adapter, rxdr->desc, rxdr->size)) {\r\ndma_free_coherent(&pdev->dev, rxdr->size, rxdr->desc,\r\nrxdr->dma);\r\ndma_free_coherent(&pdev->dev, rxdr->size, olddesc,\r\nolddma);\r\ne_err(probe, "Unable to allocate aligned memory for "\r\n"the Rx descriptor ring\n");\r\ngoto setup_rx_desc_die;\r\n} else {\r\ndma_free_coherent(&pdev->dev, rxdr->size, olddesc,\r\nolddma);\r\n}\r\n}\r\nmemset(rxdr->desc, 0, rxdr->size);\r\nrxdr->next_to_clean = 0;\r\nrxdr->next_to_use = 0;\r\nrxdr->rx_skb_top = NULL;\r\nreturn 0;\r\n}\r\nint e1000_setup_all_rx_resources(struct e1000_adapter *adapter)\r\n{\r\nint i, err = 0;\r\nfor (i = 0; i < adapter->num_rx_queues; i++) {\r\nerr = e1000_setup_rx_resources(adapter, &adapter->rx_ring[i]);\r\nif (err) {\r\ne_err(probe, "Allocation for Rx Queue %u failed\n", i);\r\nfor (i-- ; i >= 0; i--)\r\ne1000_free_rx_resources(adapter,\r\n&adapter->rx_ring[i]);\r\nbreak;\r\n}\r\n}\r\nreturn err;\r\n}\r\nstatic void e1000_setup_rctl(struct e1000_adapter *adapter)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nu32 rctl;\r\nrctl = er32(RCTL);\r\nrctl &= ~(3 << E1000_RCTL_MO_SHIFT);\r\nrctl |= E1000_RCTL_BAM | E1000_RCTL_LBM_NO |\r\nE1000_RCTL_RDMTS_HALF |\r\n(hw->mc_filter_type << E1000_RCTL_MO_SHIFT);\r\nif (hw->tbi_compatibility_on == 1)\r\nrctl |= E1000_RCTL_SBP;\r\nelse\r\nrctl &= ~E1000_RCTL_SBP;\r\nif (adapter->netdev->mtu <= ETH_DATA_LEN)\r\nrctl &= ~E1000_RCTL_LPE;\r\nelse\r\nrctl |= E1000_RCTL_LPE;\r\nrctl &= ~E1000_RCTL_SZ_4096;\r\nrctl |= E1000_RCTL_BSEX;\r\nswitch (adapter->rx_buffer_len) {\r\ncase E1000_RXBUFFER_2048:\r\ndefault:\r\nrctl |= E1000_RCTL_SZ_2048;\r\nrctl &= ~E1000_RCTL_BSEX;\r\nbreak;\r\ncase E1000_RXBUFFER_4096:\r\nrctl |= E1000_RCTL_SZ_4096;\r\nbreak;\r\ncase E1000_RXBUFFER_8192:\r\nrctl |= E1000_RCTL_SZ_8192;\r\nbreak;\r\ncase E1000_RXBUFFER_16384:\r\nrctl |= E1000_RCTL_SZ_16384;\r\nbreak;\r\n}\r\nif (adapter->netdev->features & NETIF_F_RXALL) {\r\nrctl |= (E1000_RCTL_SBP |\r\nE1000_RCTL_BAM |\r\nE1000_RCTL_PMCF);\r\nrctl &= ~(E1000_RCTL_VFE |\r\nE1000_RCTL_DPF |\r\nE1000_RCTL_CFIEN);\r\n}\r\new32(RCTL, rctl);\r\n}\r\nstatic void e1000_configure_rx(struct e1000_adapter *adapter)\r\n{\r\nu64 rdba;\r\nstruct e1000_hw *hw = &adapter->hw;\r\nu32 rdlen, rctl, rxcsum;\r\nif (adapter->netdev->mtu > ETH_DATA_LEN) {\r\nrdlen = adapter->rx_ring[0].count *\r\nsizeof(struct e1000_rx_desc);\r\nadapter->clean_rx = e1000_clean_jumbo_rx_irq;\r\nadapter->alloc_rx_buf = e1000_alloc_jumbo_rx_buffers;\r\n} else {\r\nrdlen = adapter->rx_ring[0].count *\r\nsizeof(struct e1000_rx_desc);\r\nadapter->clean_rx = e1000_clean_rx_irq;\r\nadapter->alloc_rx_buf = e1000_alloc_rx_buffers;\r\n}\r\nrctl = er32(RCTL);\r\new32(RCTL, rctl & ~E1000_RCTL_EN);\r\new32(RDTR, adapter->rx_int_delay);\r\nif (hw->mac_type >= e1000_82540) {\r\new32(RADV, adapter->rx_abs_int_delay);\r\nif (adapter->itr_setting != 0)\r\new32(ITR, 1000000000 / (adapter->itr * 256));\r\n}\r\nswitch (adapter->num_rx_queues) {\r\ncase 1:\r\ndefault:\r\nrdba = adapter->rx_ring[0].dma;\r\new32(RDLEN, rdlen);\r\new32(RDBAH, (rdba >> 32));\r\new32(RDBAL, (rdba & 0x00000000ffffffffULL));\r\new32(RDT, 0);\r\new32(RDH, 0);\r\nadapter->rx_ring[0].rdh = ((hw->mac_type >= e1000_82543) ?\r\nE1000_RDH : E1000_82542_RDH);\r\nadapter->rx_ring[0].rdt = ((hw->mac_type >= e1000_82543) ?\r\nE1000_RDT : E1000_82542_RDT);\r\nbreak;\r\n}\r\nif (hw->mac_type >= e1000_82543) {\r\nrxcsum = er32(RXCSUM);\r\nif (adapter->rx_csum)\r\nrxcsum |= E1000_RXCSUM_TUOFL;\r\nelse\r\nrxcsum &= ~E1000_RXCSUM_TUOFL;\r\new32(RXCSUM, rxcsum);\r\n}\r\new32(RCTL, rctl | E1000_RCTL_EN);\r\n}\r\nstatic void e1000_free_tx_resources(struct e1000_adapter *adapter,\r\nstruct e1000_tx_ring *tx_ring)\r\n{\r\nstruct pci_dev *pdev = adapter->pdev;\r\ne1000_clean_tx_ring(adapter, tx_ring);\r\nvfree(tx_ring->buffer_info);\r\ntx_ring->buffer_info = NULL;\r\ndma_free_coherent(&pdev->dev, tx_ring->size, tx_ring->desc,\r\ntx_ring->dma);\r\ntx_ring->desc = NULL;\r\n}\r\nvoid e1000_free_all_tx_resources(struct e1000_adapter *adapter)\r\n{\r\nint i;\r\nfor (i = 0; i < adapter->num_tx_queues; i++)\r\ne1000_free_tx_resources(adapter, &adapter->tx_ring[i]);\r\n}\r\nstatic void e1000_unmap_and_free_tx_resource(struct e1000_adapter *adapter,\r\nstruct e1000_buffer *buffer_info)\r\n{\r\nif (buffer_info->dma) {\r\nif (buffer_info->mapped_as_page)\r\ndma_unmap_page(&adapter->pdev->dev, buffer_info->dma,\r\nbuffer_info->length, DMA_TO_DEVICE);\r\nelse\r\ndma_unmap_single(&adapter->pdev->dev, buffer_info->dma,\r\nbuffer_info->length,\r\nDMA_TO_DEVICE);\r\nbuffer_info->dma = 0;\r\n}\r\nif (buffer_info->skb) {\r\ndev_kfree_skb_any(buffer_info->skb);\r\nbuffer_info->skb = NULL;\r\n}\r\nbuffer_info->time_stamp = 0;\r\n}\r\nstatic void e1000_clean_tx_ring(struct e1000_adapter *adapter,\r\nstruct e1000_tx_ring *tx_ring)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nstruct e1000_buffer *buffer_info;\r\nunsigned long size;\r\nunsigned int i;\r\nfor (i = 0; i < tx_ring->count; i++) {\r\nbuffer_info = &tx_ring->buffer_info[i];\r\ne1000_unmap_and_free_tx_resource(adapter, buffer_info);\r\n}\r\nnetdev_reset_queue(adapter->netdev);\r\nsize = sizeof(struct e1000_buffer) * tx_ring->count;\r\nmemset(tx_ring->buffer_info, 0, size);\r\nmemset(tx_ring->desc, 0, tx_ring->size);\r\ntx_ring->next_to_use = 0;\r\ntx_ring->next_to_clean = 0;\r\ntx_ring->last_tx_tso = false;\r\nwritel(0, hw->hw_addr + tx_ring->tdh);\r\nwritel(0, hw->hw_addr + tx_ring->tdt);\r\n}\r\nstatic void e1000_clean_all_tx_rings(struct e1000_adapter *adapter)\r\n{\r\nint i;\r\nfor (i = 0; i < adapter->num_tx_queues; i++)\r\ne1000_clean_tx_ring(adapter, &adapter->tx_ring[i]);\r\n}\r\nstatic void e1000_free_rx_resources(struct e1000_adapter *adapter,\r\nstruct e1000_rx_ring *rx_ring)\r\n{\r\nstruct pci_dev *pdev = adapter->pdev;\r\ne1000_clean_rx_ring(adapter, rx_ring);\r\nvfree(rx_ring->buffer_info);\r\nrx_ring->buffer_info = NULL;\r\ndma_free_coherent(&pdev->dev, rx_ring->size, rx_ring->desc,\r\nrx_ring->dma);\r\nrx_ring->desc = NULL;\r\n}\r\nvoid e1000_free_all_rx_resources(struct e1000_adapter *adapter)\r\n{\r\nint i;\r\nfor (i = 0; i < adapter->num_rx_queues; i++)\r\ne1000_free_rx_resources(adapter, &adapter->rx_ring[i]);\r\n}\r\nstatic void e1000_clean_rx_ring(struct e1000_adapter *adapter,\r\nstruct e1000_rx_ring *rx_ring)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nstruct e1000_buffer *buffer_info;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nunsigned long size;\r\nunsigned int i;\r\nfor (i = 0; i < rx_ring->count; i++) {\r\nbuffer_info = &rx_ring->buffer_info[i];\r\nif (buffer_info->dma &&\r\nadapter->clean_rx == e1000_clean_rx_irq) {\r\ndma_unmap_single(&pdev->dev, buffer_info->dma,\r\nbuffer_info->length,\r\nDMA_FROM_DEVICE);\r\n} else if (buffer_info->dma &&\r\nadapter->clean_rx == e1000_clean_jumbo_rx_irq) {\r\ndma_unmap_page(&pdev->dev, buffer_info->dma,\r\nbuffer_info->length,\r\nDMA_FROM_DEVICE);\r\n}\r\nbuffer_info->dma = 0;\r\nif (buffer_info->page) {\r\nput_page(buffer_info->page);\r\nbuffer_info->page = NULL;\r\n}\r\nif (buffer_info->skb) {\r\ndev_kfree_skb(buffer_info->skb);\r\nbuffer_info->skb = NULL;\r\n}\r\n}\r\nif (rx_ring->rx_skb_top) {\r\ndev_kfree_skb(rx_ring->rx_skb_top);\r\nrx_ring->rx_skb_top = NULL;\r\n}\r\nsize = sizeof(struct e1000_buffer) * rx_ring->count;\r\nmemset(rx_ring->buffer_info, 0, size);\r\nmemset(rx_ring->desc, 0, rx_ring->size);\r\nrx_ring->next_to_clean = 0;\r\nrx_ring->next_to_use = 0;\r\nwritel(0, hw->hw_addr + rx_ring->rdh);\r\nwritel(0, hw->hw_addr + rx_ring->rdt);\r\n}\r\nstatic void e1000_clean_all_rx_rings(struct e1000_adapter *adapter)\r\n{\r\nint i;\r\nfor (i = 0; i < adapter->num_rx_queues; i++)\r\ne1000_clean_rx_ring(adapter, &adapter->rx_ring[i]);\r\n}\r\nstatic void e1000_enter_82542_rst(struct e1000_adapter *adapter)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nstruct net_device *netdev = adapter->netdev;\r\nu32 rctl;\r\ne1000_pci_clear_mwi(hw);\r\nrctl = er32(RCTL);\r\nrctl |= E1000_RCTL_RST;\r\new32(RCTL, rctl);\r\nE1000_WRITE_FLUSH();\r\nmdelay(5);\r\nif (netif_running(netdev))\r\ne1000_clean_all_rx_rings(adapter);\r\n}\r\nstatic void e1000_leave_82542_rst(struct e1000_adapter *adapter)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nstruct net_device *netdev = adapter->netdev;\r\nu32 rctl;\r\nrctl = er32(RCTL);\r\nrctl &= ~E1000_RCTL_RST;\r\new32(RCTL, rctl);\r\nE1000_WRITE_FLUSH();\r\nmdelay(5);\r\nif (hw->pci_cmd_word & PCI_COMMAND_INVALIDATE)\r\ne1000_pci_set_mwi(hw);\r\nif (netif_running(netdev)) {\r\nstruct e1000_rx_ring *ring = &adapter->rx_ring[0];\r\ne1000_configure_rx(adapter);\r\nadapter->alloc_rx_buf(adapter, ring, E1000_DESC_UNUSED(ring));\r\n}\r\n}\r\nstatic int e1000_set_mac(struct net_device *netdev, void *p)\r\n{\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\nstruct e1000_hw *hw = &adapter->hw;\r\nstruct sockaddr *addr = p;\r\nif (!is_valid_ether_addr(addr->sa_data))\r\nreturn -EADDRNOTAVAIL;\r\nif (hw->mac_type == e1000_82542_rev2_0)\r\ne1000_enter_82542_rst(adapter);\r\nmemcpy(netdev->dev_addr, addr->sa_data, netdev->addr_len);\r\nmemcpy(hw->mac_addr, addr->sa_data, netdev->addr_len);\r\ne1000_rar_set(hw, hw->mac_addr, 0);\r\nif (hw->mac_type == e1000_82542_rev2_0)\r\ne1000_leave_82542_rst(adapter);\r\nreturn 0;\r\n}\r\nstatic void e1000_set_rx_mode(struct net_device *netdev)\r\n{\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\nstruct e1000_hw *hw = &adapter->hw;\r\nstruct netdev_hw_addr *ha;\r\nbool use_uc = false;\r\nu32 rctl;\r\nu32 hash_value;\r\nint i, rar_entries = E1000_RAR_ENTRIES;\r\nint mta_reg_count = E1000_NUM_MTA_REGISTERS;\r\nu32 *mcarray = kcalloc(mta_reg_count, sizeof(u32), GFP_ATOMIC);\r\nif (!mcarray)\r\nreturn;\r\nrctl = er32(RCTL);\r\nif (netdev->flags & IFF_PROMISC) {\r\nrctl |= (E1000_RCTL_UPE | E1000_RCTL_MPE);\r\nrctl &= ~E1000_RCTL_VFE;\r\n} else {\r\nif (netdev->flags & IFF_ALLMULTI)\r\nrctl |= E1000_RCTL_MPE;\r\nelse\r\nrctl &= ~E1000_RCTL_MPE;\r\nif (e1000_vlan_used(adapter))\r\nrctl |= E1000_RCTL_VFE;\r\n}\r\nif (netdev_uc_count(netdev) > rar_entries - 1) {\r\nrctl |= E1000_RCTL_UPE;\r\n} else if (!(netdev->flags & IFF_PROMISC)) {\r\nrctl &= ~E1000_RCTL_UPE;\r\nuse_uc = true;\r\n}\r\new32(RCTL, rctl);\r\nif (hw->mac_type == e1000_82542_rev2_0)\r\ne1000_enter_82542_rst(adapter);\r\ni = 1;\r\nif (use_uc)\r\nnetdev_for_each_uc_addr(ha, netdev) {\r\nif (i == rar_entries)\r\nbreak;\r\ne1000_rar_set(hw, ha->addr, i++);\r\n}\r\nnetdev_for_each_mc_addr(ha, netdev) {\r\nif (i == rar_entries) {\r\nu32 hash_reg, hash_bit, mta;\r\nhash_value = e1000_hash_mc_addr(hw, ha->addr);\r\nhash_reg = (hash_value >> 5) & 0x7F;\r\nhash_bit = hash_value & 0x1F;\r\nmta = (1 << hash_bit);\r\nmcarray[hash_reg] |= mta;\r\n} else {\r\ne1000_rar_set(hw, ha->addr, i++);\r\n}\r\n}\r\nfor (; i < rar_entries; i++) {\r\nE1000_WRITE_REG_ARRAY(hw, RA, i << 1, 0);\r\nE1000_WRITE_FLUSH();\r\nE1000_WRITE_REG_ARRAY(hw, RA, (i << 1) + 1, 0);\r\nE1000_WRITE_FLUSH();\r\n}\r\nfor (i = mta_reg_count - 1; i >= 0 ; i--) {\r\nE1000_WRITE_REG_ARRAY(hw, MTA, i, mcarray[i]);\r\n}\r\nE1000_WRITE_FLUSH();\r\nif (hw->mac_type == e1000_82542_rev2_0)\r\ne1000_leave_82542_rst(adapter);\r\nkfree(mcarray);\r\n}\r\nstatic void e1000_update_phy_info_task(struct work_struct *work)\r\n{\r\nstruct e1000_adapter *adapter = container_of(work,\r\nstruct e1000_adapter,\r\nphy_info_task.work);\r\ne1000_phy_get_info(&adapter->hw, &adapter->phy_info);\r\n}\r\nstatic void e1000_82547_tx_fifo_stall_task(struct work_struct *work)\r\n{\r\nstruct e1000_adapter *adapter = container_of(work,\r\nstruct e1000_adapter,\r\nfifo_stall_task.work);\r\nstruct e1000_hw *hw = &adapter->hw;\r\nstruct net_device *netdev = adapter->netdev;\r\nu32 tctl;\r\nif (atomic_read(&adapter->tx_fifo_stall)) {\r\nif ((er32(TDT) == er32(TDH)) &&\r\n(er32(TDFT) == er32(TDFH)) &&\r\n(er32(TDFTS) == er32(TDFHS))) {\r\ntctl = er32(TCTL);\r\new32(TCTL, tctl & ~E1000_TCTL_EN);\r\new32(TDFT, adapter->tx_head_addr);\r\new32(TDFH, adapter->tx_head_addr);\r\new32(TDFTS, adapter->tx_head_addr);\r\new32(TDFHS, adapter->tx_head_addr);\r\new32(TCTL, tctl);\r\nE1000_WRITE_FLUSH();\r\nadapter->tx_fifo_head = 0;\r\natomic_set(&adapter->tx_fifo_stall, 0);\r\nnetif_wake_queue(netdev);\r\n} else if (!test_bit(__E1000_DOWN, &adapter->flags)) {\r\nschedule_delayed_work(&adapter->fifo_stall_task, 1);\r\n}\r\n}\r\n}\r\nbool e1000_has_link(struct e1000_adapter *adapter)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nbool link_active = false;\r\nswitch (hw->media_type) {\r\ncase e1000_media_type_copper:\r\nif (hw->mac_type == e1000_ce4100)\r\nhw->get_link_status = 1;\r\nif (hw->get_link_status) {\r\ne1000_check_for_link(hw);\r\nlink_active = !hw->get_link_status;\r\n} else {\r\nlink_active = true;\r\n}\r\nbreak;\r\ncase e1000_media_type_fiber:\r\ne1000_check_for_link(hw);\r\nlink_active = !!(er32(STATUS) & E1000_STATUS_LU);\r\nbreak;\r\ncase e1000_media_type_internal_serdes:\r\ne1000_check_for_link(hw);\r\nlink_active = hw->serdes_has_link;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nreturn link_active;\r\n}\r\nstatic void e1000_watchdog(struct work_struct *work)\r\n{\r\nstruct e1000_adapter *adapter = container_of(work,\r\nstruct e1000_adapter,\r\nwatchdog_task.work);\r\nstruct e1000_hw *hw = &adapter->hw;\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct e1000_tx_ring *txdr = adapter->tx_ring;\r\nu32 link, tctl;\r\nlink = e1000_has_link(adapter);\r\nif ((netif_carrier_ok(netdev)) && link)\r\ngoto link_up;\r\nif (link) {\r\nif (!netif_carrier_ok(netdev)) {\r\nu32 ctrl;\r\nbool txb2b = true;\r\ne1000_get_speed_and_duplex(hw,\r\n&adapter->link_speed,\r\n&adapter->link_duplex);\r\nctrl = er32(CTRL);\r\npr_info("%s NIC Link is Up %d Mbps %s, "\r\n"Flow Control: %s\n",\r\nnetdev->name,\r\nadapter->link_speed,\r\nadapter->link_duplex == FULL_DUPLEX ?\r\n"Full Duplex" : "Half Duplex",\r\n((ctrl & E1000_CTRL_TFCE) && (ctrl &\r\nE1000_CTRL_RFCE)) ? "RX/TX" : ((ctrl &\r\nE1000_CTRL_RFCE) ? "RX" : ((ctrl &\r\nE1000_CTRL_TFCE) ? "TX" : "None")));\r\nadapter->tx_timeout_factor = 1;\r\nswitch (adapter->link_speed) {\r\ncase SPEED_10:\r\ntxb2b = false;\r\nadapter->tx_timeout_factor = 16;\r\nbreak;\r\ncase SPEED_100:\r\ntxb2b = false;\r\nbreak;\r\n}\r\ntctl = er32(TCTL);\r\ntctl |= E1000_TCTL_EN;\r\new32(TCTL, tctl);\r\nnetif_carrier_on(netdev);\r\nif (!test_bit(__E1000_DOWN, &adapter->flags))\r\nschedule_delayed_work(&adapter->phy_info_task,\r\n2 * HZ);\r\nadapter->smartspeed = 0;\r\n}\r\n} else {\r\nif (netif_carrier_ok(netdev)) {\r\nadapter->link_speed = 0;\r\nadapter->link_duplex = 0;\r\npr_info("%s NIC Link is Down\n",\r\nnetdev->name);\r\nnetif_carrier_off(netdev);\r\nif (!test_bit(__E1000_DOWN, &adapter->flags))\r\nschedule_delayed_work(&adapter->phy_info_task,\r\n2 * HZ);\r\n}\r\ne1000_smartspeed(adapter);\r\n}\r\nlink_up:\r\ne1000_update_stats(adapter);\r\nhw->tx_packet_delta = adapter->stats.tpt - adapter->tpt_old;\r\nadapter->tpt_old = adapter->stats.tpt;\r\nhw->collision_delta = adapter->stats.colc - adapter->colc_old;\r\nadapter->colc_old = adapter->stats.colc;\r\nadapter->gorcl = adapter->stats.gorcl - adapter->gorcl_old;\r\nadapter->gorcl_old = adapter->stats.gorcl;\r\nadapter->gotcl = adapter->stats.gotcl - adapter->gotcl_old;\r\nadapter->gotcl_old = adapter->stats.gotcl;\r\ne1000_update_adaptive(hw);\r\nif (!netif_carrier_ok(netdev)) {\r\nif (E1000_DESC_UNUSED(txdr) + 1 < txdr->count) {\r\nadapter->tx_timeout_count++;\r\nschedule_work(&adapter->reset_task);\r\nreturn;\r\n}\r\n}\r\nif (hw->mac_type >= e1000_82540 && adapter->itr_setting == 4) {\r\nu32 goc = (adapter->gotcl + adapter->gorcl) / 10000;\r\nu32 dif = (adapter->gotcl > adapter->gorcl ?\r\nadapter->gotcl - adapter->gorcl :\r\nadapter->gorcl - adapter->gotcl) / 10000;\r\nu32 itr = goc > 0 ? (dif * 6000 / goc + 2000) : 8000;\r\new32(ITR, 1000000000 / (itr * 256));\r\n}\r\new32(ICS, E1000_ICS_RXDMT0);\r\nadapter->detect_tx_hung = true;\r\nif (!test_bit(__E1000_DOWN, &adapter->flags))\r\nschedule_delayed_work(&adapter->watchdog_task, 2 * HZ);\r\n}\r\nstatic unsigned int e1000_update_itr(struct e1000_adapter *adapter,\r\nu16 itr_setting, int packets, int bytes)\r\n{\r\nunsigned int retval = itr_setting;\r\nstruct e1000_hw *hw = &adapter->hw;\r\nif (unlikely(hw->mac_type < e1000_82540))\r\ngoto update_itr_done;\r\nif (packets == 0)\r\ngoto update_itr_done;\r\nswitch (itr_setting) {\r\ncase lowest_latency:\r\nif (bytes/packets > 8000)\r\nretval = bulk_latency;\r\nelse if ((packets < 5) && (bytes > 512))\r\nretval = low_latency;\r\nbreak;\r\ncase low_latency:\r\nif (bytes > 10000) {\r\nif (bytes/packets > 8000)\r\nretval = bulk_latency;\r\nelse if ((packets < 10) || ((bytes/packets) > 1200))\r\nretval = bulk_latency;\r\nelse if ((packets > 35))\r\nretval = lowest_latency;\r\n} else if (bytes/packets > 2000)\r\nretval = bulk_latency;\r\nelse if (packets <= 2 && bytes < 512)\r\nretval = lowest_latency;\r\nbreak;\r\ncase bulk_latency:\r\nif (bytes > 25000) {\r\nif (packets > 35)\r\nretval = low_latency;\r\n} else if (bytes < 6000) {\r\nretval = low_latency;\r\n}\r\nbreak;\r\n}\r\nupdate_itr_done:\r\nreturn retval;\r\n}\r\nstatic void e1000_set_itr(struct e1000_adapter *adapter)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nu16 current_itr;\r\nu32 new_itr = adapter->itr;\r\nif (unlikely(hw->mac_type < e1000_82540))\r\nreturn;\r\nif (unlikely(adapter->link_speed != SPEED_1000)) {\r\ncurrent_itr = 0;\r\nnew_itr = 4000;\r\ngoto set_itr_now;\r\n}\r\nadapter->tx_itr = e1000_update_itr(adapter, adapter->tx_itr,\r\nadapter->total_tx_packets,\r\nadapter->total_tx_bytes);\r\nif (adapter->itr_setting == 3 && adapter->tx_itr == lowest_latency)\r\nadapter->tx_itr = low_latency;\r\nadapter->rx_itr = e1000_update_itr(adapter, adapter->rx_itr,\r\nadapter->total_rx_packets,\r\nadapter->total_rx_bytes);\r\nif (adapter->itr_setting == 3 && adapter->rx_itr == lowest_latency)\r\nadapter->rx_itr = low_latency;\r\ncurrent_itr = max(adapter->rx_itr, adapter->tx_itr);\r\nswitch (current_itr) {\r\ncase lowest_latency:\r\nnew_itr = 70000;\r\nbreak;\r\ncase low_latency:\r\nnew_itr = 20000;\r\nbreak;\r\ncase bulk_latency:\r\nnew_itr = 4000;\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nset_itr_now:\r\nif (new_itr != adapter->itr) {\r\nnew_itr = new_itr > adapter->itr ?\r\nmin(adapter->itr + (new_itr >> 2), new_itr) :\r\nnew_itr;\r\nadapter->itr = new_itr;\r\new32(ITR, 1000000000 / (new_itr * 256));\r\n}\r\n}\r\nstatic int e1000_tso(struct e1000_adapter *adapter,\r\nstruct e1000_tx_ring *tx_ring, struct sk_buff *skb)\r\n{\r\nstruct e1000_context_desc *context_desc;\r\nstruct e1000_buffer *buffer_info;\r\nunsigned int i;\r\nu32 cmd_length = 0;\r\nu16 ipcse = 0, tucse, mss;\r\nu8 ipcss, ipcso, tucss, tucso, hdr_len;\r\nint err;\r\nif (skb_is_gso(skb)) {\r\nif (skb_header_cloned(skb)) {\r\nerr = pskb_expand_head(skb, 0, 0, GFP_ATOMIC);\r\nif (err)\r\nreturn err;\r\n}\r\nhdr_len = skb_transport_offset(skb) + tcp_hdrlen(skb);\r\nmss = skb_shinfo(skb)->gso_size;\r\nif (skb->protocol == htons(ETH_P_IP)) {\r\nstruct iphdr *iph = ip_hdr(skb);\r\niph->tot_len = 0;\r\niph->check = 0;\r\ntcp_hdr(skb)->check = ~csum_tcpudp_magic(iph->saddr,\r\niph->daddr, 0,\r\nIPPROTO_TCP,\r\n0);\r\ncmd_length = E1000_TXD_CMD_IP;\r\nipcse = skb_transport_offset(skb) - 1;\r\n} else if (skb->protocol == htons(ETH_P_IPV6)) {\r\nipv6_hdr(skb)->payload_len = 0;\r\ntcp_hdr(skb)->check =\r\n~csum_ipv6_magic(&ipv6_hdr(skb)->saddr,\r\n&ipv6_hdr(skb)->daddr,\r\n0, IPPROTO_TCP, 0);\r\nipcse = 0;\r\n}\r\nipcss = skb_network_offset(skb);\r\nipcso = (void *)&(ip_hdr(skb)->check) - (void *)skb->data;\r\ntucss = skb_transport_offset(skb);\r\ntucso = (void *)&(tcp_hdr(skb)->check) - (void *)skb->data;\r\ntucse = 0;\r\ncmd_length |= (E1000_TXD_CMD_DEXT | E1000_TXD_CMD_TSE |\r\nE1000_TXD_CMD_TCP | (skb->len - (hdr_len)));\r\ni = tx_ring->next_to_use;\r\ncontext_desc = E1000_CONTEXT_DESC(*tx_ring, i);\r\nbuffer_info = &tx_ring->buffer_info[i];\r\ncontext_desc->lower_setup.ip_fields.ipcss = ipcss;\r\ncontext_desc->lower_setup.ip_fields.ipcso = ipcso;\r\ncontext_desc->lower_setup.ip_fields.ipcse = cpu_to_le16(ipcse);\r\ncontext_desc->upper_setup.tcp_fields.tucss = tucss;\r\ncontext_desc->upper_setup.tcp_fields.tucso = tucso;\r\ncontext_desc->upper_setup.tcp_fields.tucse = cpu_to_le16(tucse);\r\ncontext_desc->tcp_seg_setup.fields.mss = cpu_to_le16(mss);\r\ncontext_desc->tcp_seg_setup.fields.hdr_len = hdr_len;\r\ncontext_desc->cmd_and_length = cpu_to_le32(cmd_length);\r\nbuffer_info->time_stamp = jiffies;\r\nbuffer_info->next_to_watch = i;\r\nif (++i == tx_ring->count) i = 0;\r\ntx_ring->next_to_use = i;\r\nreturn true;\r\n}\r\nreturn false;\r\n}\r\nstatic bool e1000_tx_csum(struct e1000_adapter *adapter,\r\nstruct e1000_tx_ring *tx_ring, struct sk_buff *skb)\r\n{\r\nstruct e1000_context_desc *context_desc;\r\nstruct e1000_buffer *buffer_info;\r\nunsigned int i;\r\nu8 css;\r\nu32 cmd_len = E1000_TXD_CMD_DEXT;\r\nif (skb->ip_summed != CHECKSUM_PARTIAL)\r\nreturn false;\r\nswitch (skb->protocol) {\r\ncase cpu_to_be16(ETH_P_IP):\r\nif (ip_hdr(skb)->protocol == IPPROTO_TCP)\r\ncmd_len |= E1000_TXD_CMD_TCP;\r\nbreak;\r\ncase cpu_to_be16(ETH_P_IPV6):\r\nif (ipv6_hdr(skb)->nexthdr == IPPROTO_TCP)\r\ncmd_len |= E1000_TXD_CMD_TCP;\r\nbreak;\r\ndefault:\r\nif (unlikely(net_ratelimit()))\r\ne_warn(drv, "checksum_partial proto=%x!\n",\r\nskb->protocol);\r\nbreak;\r\n}\r\ncss = skb_checksum_start_offset(skb);\r\ni = tx_ring->next_to_use;\r\nbuffer_info = &tx_ring->buffer_info[i];\r\ncontext_desc = E1000_CONTEXT_DESC(*tx_ring, i);\r\ncontext_desc->lower_setup.ip_config = 0;\r\ncontext_desc->upper_setup.tcp_fields.tucss = css;\r\ncontext_desc->upper_setup.tcp_fields.tucso =\r\ncss + skb->csum_offset;\r\ncontext_desc->upper_setup.tcp_fields.tucse = 0;\r\ncontext_desc->tcp_seg_setup.data = 0;\r\ncontext_desc->cmd_and_length = cpu_to_le32(cmd_len);\r\nbuffer_info->time_stamp = jiffies;\r\nbuffer_info->next_to_watch = i;\r\nif (unlikely(++i == tx_ring->count)) i = 0;\r\ntx_ring->next_to_use = i;\r\nreturn true;\r\n}\r\nstatic int e1000_tx_map(struct e1000_adapter *adapter,\r\nstruct e1000_tx_ring *tx_ring,\r\nstruct sk_buff *skb, unsigned int first,\r\nunsigned int max_per_txd, unsigned int nr_frags,\r\nunsigned int mss)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nstruct e1000_buffer *buffer_info;\r\nunsigned int len = skb_headlen(skb);\r\nunsigned int offset = 0, size, count = 0, i;\r\nunsigned int f, bytecount, segs;\r\ni = tx_ring->next_to_use;\r\nwhile (len) {\r\nbuffer_info = &tx_ring->buffer_info[i];\r\nsize = min(len, max_per_txd);\r\nif (!skb->data_len && tx_ring->last_tx_tso &&\r\n!skb_is_gso(skb)) {\r\ntx_ring->last_tx_tso = false;\r\nsize -= 4;\r\n}\r\nif (unlikely(mss && !nr_frags && size == len && size > 8))\r\nsize -= 4;\r\nif (unlikely((hw->bus_type == e1000_bus_type_pcix) &&\r\n(size > 2015) && count == 0))\r\nsize = 2015;\r\nif (unlikely(adapter->pcix_82544 &&\r\n!((unsigned long)(skb->data + offset + size - 1) & 4) &&\r\nsize > 4))\r\nsize -= 4;\r\nbuffer_info->length = size;\r\nbuffer_info->time_stamp = jiffies;\r\nbuffer_info->mapped_as_page = false;\r\nbuffer_info->dma = dma_map_single(&pdev->dev,\r\nskb->data + offset,\r\nsize, DMA_TO_DEVICE);\r\nif (dma_mapping_error(&pdev->dev, buffer_info->dma))\r\ngoto dma_error;\r\nbuffer_info->next_to_watch = i;\r\nlen -= size;\r\noffset += size;\r\ncount++;\r\nif (len) {\r\ni++;\r\nif (unlikely(i == tx_ring->count))\r\ni = 0;\r\n}\r\n}\r\nfor (f = 0; f < nr_frags; f++) {\r\nconst struct skb_frag_struct *frag;\r\nfrag = &skb_shinfo(skb)->frags[f];\r\nlen = skb_frag_size(frag);\r\noffset = 0;\r\nwhile (len) {\r\nunsigned long bufend;\r\ni++;\r\nif (unlikely(i == tx_ring->count))\r\ni = 0;\r\nbuffer_info = &tx_ring->buffer_info[i];\r\nsize = min(len, max_per_txd);\r\nif (unlikely(mss && f == (nr_frags-1) &&\r\nsize == len && size > 8))\r\nsize -= 4;\r\nbufend = (unsigned long)\r\npage_to_phys(skb_frag_page(frag));\r\nbufend += offset + size - 1;\r\nif (unlikely(adapter->pcix_82544 &&\r\n!(bufend & 4) &&\r\nsize > 4))\r\nsize -= 4;\r\nbuffer_info->length = size;\r\nbuffer_info->time_stamp = jiffies;\r\nbuffer_info->mapped_as_page = true;\r\nbuffer_info->dma = skb_frag_dma_map(&pdev->dev, frag,\r\noffset, size, DMA_TO_DEVICE);\r\nif (dma_mapping_error(&pdev->dev, buffer_info->dma))\r\ngoto dma_error;\r\nbuffer_info->next_to_watch = i;\r\nlen -= size;\r\noffset += size;\r\ncount++;\r\n}\r\n}\r\nsegs = skb_shinfo(skb)->gso_segs ?: 1;\r\nbytecount = ((segs - 1) * skb_headlen(skb)) + skb->len;\r\ntx_ring->buffer_info[i].skb = skb;\r\ntx_ring->buffer_info[i].segs = segs;\r\ntx_ring->buffer_info[i].bytecount = bytecount;\r\ntx_ring->buffer_info[first].next_to_watch = i;\r\nreturn count;\r\ndma_error:\r\ndev_err(&pdev->dev, "TX DMA map failed\n");\r\nbuffer_info->dma = 0;\r\nif (count)\r\ncount--;\r\nwhile (count--) {\r\nif (i==0)\r\ni += tx_ring->count;\r\ni--;\r\nbuffer_info = &tx_ring->buffer_info[i];\r\ne1000_unmap_and_free_tx_resource(adapter, buffer_info);\r\n}\r\nreturn 0;\r\n}\r\nstatic void e1000_tx_queue(struct e1000_adapter *adapter,\r\nstruct e1000_tx_ring *tx_ring, int tx_flags,\r\nint count)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nstruct e1000_tx_desc *tx_desc = NULL;\r\nstruct e1000_buffer *buffer_info;\r\nu32 txd_upper = 0, txd_lower = E1000_TXD_CMD_IFCS;\r\nunsigned int i;\r\nif (likely(tx_flags & E1000_TX_FLAGS_TSO)) {\r\ntxd_lower |= E1000_TXD_CMD_DEXT | E1000_TXD_DTYP_D |\r\nE1000_TXD_CMD_TSE;\r\ntxd_upper |= E1000_TXD_POPTS_TXSM << 8;\r\nif (likely(tx_flags & E1000_TX_FLAGS_IPV4))\r\ntxd_upper |= E1000_TXD_POPTS_IXSM << 8;\r\n}\r\nif (likely(tx_flags & E1000_TX_FLAGS_CSUM)) {\r\ntxd_lower |= E1000_TXD_CMD_DEXT | E1000_TXD_DTYP_D;\r\ntxd_upper |= E1000_TXD_POPTS_TXSM << 8;\r\n}\r\nif (unlikely(tx_flags & E1000_TX_FLAGS_VLAN)) {\r\ntxd_lower |= E1000_TXD_CMD_VLE;\r\ntxd_upper |= (tx_flags & E1000_TX_FLAGS_VLAN_MASK);\r\n}\r\nif (unlikely(tx_flags & E1000_TX_FLAGS_NO_FCS))\r\ntxd_lower &= ~(E1000_TXD_CMD_IFCS);\r\ni = tx_ring->next_to_use;\r\nwhile (count--) {\r\nbuffer_info = &tx_ring->buffer_info[i];\r\ntx_desc = E1000_TX_DESC(*tx_ring, i);\r\ntx_desc->buffer_addr = cpu_to_le64(buffer_info->dma);\r\ntx_desc->lower.data =\r\ncpu_to_le32(txd_lower | buffer_info->length);\r\ntx_desc->upper.data = cpu_to_le32(txd_upper);\r\nif (unlikely(++i == tx_ring->count)) i = 0;\r\n}\r\ntx_desc->lower.data |= cpu_to_le32(adapter->txd_cmd);\r\nif (unlikely(tx_flags & E1000_TX_FLAGS_NO_FCS))\r\ntx_desc->lower.data &= ~(cpu_to_le32(E1000_TXD_CMD_IFCS));\r\nwmb();\r\ntx_ring->next_to_use = i;\r\nwritel(i, hw->hw_addr + tx_ring->tdt);\r\nmmiowb();\r\n}\r\nstatic int e1000_82547_fifo_workaround(struct e1000_adapter *adapter,\r\nstruct sk_buff *skb)\r\n{\r\nu32 fifo_space = adapter->tx_fifo_size - adapter->tx_fifo_head;\r\nu32 skb_fifo_len = skb->len + E1000_FIFO_HDR;\r\nskb_fifo_len = ALIGN(skb_fifo_len, E1000_FIFO_HDR);\r\nif (adapter->link_duplex != HALF_DUPLEX)\r\ngoto no_fifo_stall_required;\r\nif (atomic_read(&adapter->tx_fifo_stall))\r\nreturn 1;\r\nif (skb_fifo_len >= (E1000_82547_PAD_LEN + fifo_space)) {\r\natomic_set(&adapter->tx_fifo_stall, 1);\r\nreturn 1;\r\n}\r\nno_fifo_stall_required:\r\nadapter->tx_fifo_head += skb_fifo_len;\r\nif (adapter->tx_fifo_head >= adapter->tx_fifo_size)\r\nadapter->tx_fifo_head -= adapter->tx_fifo_size;\r\nreturn 0;\r\n}\r\nstatic int __e1000_maybe_stop_tx(struct net_device *netdev, int size)\r\n{\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\nstruct e1000_tx_ring *tx_ring = adapter->tx_ring;\r\nnetif_stop_queue(netdev);\r\nsmp_mb();\r\nif (likely(E1000_DESC_UNUSED(tx_ring) < size))\r\nreturn -EBUSY;\r\nnetif_start_queue(netdev);\r\n++adapter->restart_queue;\r\nreturn 0;\r\n}\r\nstatic int e1000_maybe_stop_tx(struct net_device *netdev,\r\nstruct e1000_tx_ring *tx_ring, int size)\r\n{\r\nif (likely(E1000_DESC_UNUSED(tx_ring) >= size))\r\nreturn 0;\r\nreturn __e1000_maybe_stop_tx(netdev, size);\r\n}\r\nstatic netdev_tx_t e1000_xmit_frame(struct sk_buff *skb,\r\nstruct net_device *netdev)\r\n{\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\nstruct e1000_hw *hw = &adapter->hw;\r\nstruct e1000_tx_ring *tx_ring;\r\nunsigned int first, max_per_txd = E1000_MAX_DATA_PER_TXD;\r\nunsigned int max_txd_pwr = E1000_MAX_TXD_PWR;\r\nunsigned int tx_flags = 0;\r\nunsigned int len = skb_headlen(skb);\r\nunsigned int nr_frags;\r\nunsigned int mss;\r\nint count = 0;\r\nint tso;\r\nunsigned int f;\r\ntx_ring = adapter->tx_ring;\r\nif (unlikely(skb->len <= 0)) {\r\ndev_kfree_skb_any(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nif (skb->len < ETH_ZLEN) {\r\nif (skb_pad(skb, ETH_ZLEN - skb->len))\r\nreturn NETDEV_TX_OK;\r\nskb->len = ETH_ZLEN;\r\nskb_set_tail_pointer(skb, ETH_ZLEN);\r\n}\r\nmss = skb_shinfo(skb)->gso_size;\r\nif (mss) {\r\nu8 hdr_len;\r\nmax_per_txd = min(mss << 2, max_per_txd);\r\nmax_txd_pwr = fls(max_per_txd) - 1;\r\nhdr_len = skb_transport_offset(skb) + tcp_hdrlen(skb);\r\nif (skb->data_len && hdr_len == len) {\r\nswitch (hw->mac_type) {\r\nunsigned int pull_size;\r\ncase e1000_82544:\r\nif ((unsigned long)(skb_tail_pointer(skb) - 1)\r\n& 4)\r\nbreak;\r\npull_size = min((unsigned int)4, skb->data_len);\r\nif (!__pskb_pull_tail(skb, pull_size)) {\r\ne_err(drv, "__pskb_pull_tail "\r\n"failed.\n");\r\ndev_kfree_skb_any(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nlen = skb_headlen(skb);\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\n}\r\n}\r\nif ((mss) || (skb->ip_summed == CHECKSUM_PARTIAL))\r\ncount++;\r\ncount++;\r\nif (!skb->data_len && tx_ring->last_tx_tso && !skb_is_gso(skb))\r\ncount++;\r\ncount += TXD_USE_COUNT(len, max_txd_pwr);\r\nif (adapter->pcix_82544)\r\ncount++;\r\nif (unlikely((hw->bus_type == e1000_bus_type_pcix) &&\r\n(len > 2015)))\r\ncount++;\r\nnr_frags = skb_shinfo(skb)->nr_frags;\r\nfor (f = 0; f < nr_frags; f++)\r\ncount += TXD_USE_COUNT(skb_frag_size(&skb_shinfo(skb)->frags[f]),\r\nmax_txd_pwr);\r\nif (adapter->pcix_82544)\r\ncount += nr_frags;\r\nif (unlikely(e1000_maybe_stop_tx(netdev, tx_ring, count + 2)))\r\nreturn NETDEV_TX_BUSY;\r\nif (unlikely((hw->mac_type == e1000_82547) &&\r\n(e1000_82547_fifo_workaround(adapter, skb)))) {\r\nnetif_stop_queue(netdev);\r\nif (!test_bit(__E1000_DOWN, &adapter->flags))\r\nschedule_delayed_work(&adapter->fifo_stall_task, 1);\r\nreturn NETDEV_TX_BUSY;\r\n}\r\nif (vlan_tx_tag_present(skb)) {\r\ntx_flags |= E1000_TX_FLAGS_VLAN;\r\ntx_flags |= (vlan_tx_tag_get(skb) << E1000_TX_FLAGS_VLAN_SHIFT);\r\n}\r\nfirst = tx_ring->next_to_use;\r\ntso = e1000_tso(adapter, tx_ring, skb);\r\nif (tso < 0) {\r\ndev_kfree_skb_any(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nif (likely(tso)) {\r\nif (likely(hw->mac_type != e1000_82544))\r\ntx_ring->last_tx_tso = true;\r\ntx_flags |= E1000_TX_FLAGS_TSO;\r\n} else if (likely(e1000_tx_csum(adapter, tx_ring, skb)))\r\ntx_flags |= E1000_TX_FLAGS_CSUM;\r\nif (likely(skb->protocol == htons(ETH_P_IP)))\r\ntx_flags |= E1000_TX_FLAGS_IPV4;\r\nif (unlikely(skb->no_fcs))\r\ntx_flags |= E1000_TX_FLAGS_NO_FCS;\r\ncount = e1000_tx_map(adapter, tx_ring, skb, first, max_per_txd,\r\nnr_frags, mss);\r\nif (count) {\r\nnetdev_sent_queue(netdev, skb->len);\r\nskb_tx_timestamp(skb);\r\ne1000_tx_queue(adapter, tx_ring, tx_flags, count);\r\ne1000_maybe_stop_tx(netdev, tx_ring, MAX_SKB_FRAGS + 2);\r\n} else {\r\ndev_kfree_skb_any(skb);\r\ntx_ring->buffer_info[first].time_stamp = 0;\r\ntx_ring->next_to_use = first;\r\n}\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void e1000_regdump(struct e1000_adapter *adapter)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nu32 regs[NUM_REGS];\r\nu32 *regs_buff = regs;\r\nint i = 0;\r\nstatic const char * const reg_name[] = {\r\n"CTRL", "STATUS",\r\n"RCTL", "RDLEN", "RDH", "RDT", "RDTR",\r\n"TCTL", "TDBAL", "TDBAH", "TDLEN", "TDH", "TDT",\r\n"TIDV", "TXDCTL", "TADV", "TARC0",\r\n"TDBAL1", "TDBAH1", "TDLEN1", "TDH1", "TDT1",\r\n"TXDCTL1", "TARC1",\r\n"CTRL_EXT", "ERT", "RDBAL", "RDBAH",\r\n"TDFH", "TDFT", "TDFHS", "TDFTS", "TDFPC",\r\n"RDFH", "RDFT", "RDFHS", "RDFTS", "RDFPC"\r\n};\r\nregs_buff[0] = er32(CTRL);\r\nregs_buff[1] = er32(STATUS);\r\nregs_buff[2] = er32(RCTL);\r\nregs_buff[3] = er32(RDLEN);\r\nregs_buff[4] = er32(RDH);\r\nregs_buff[5] = er32(RDT);\r\nregs_buff[6] = er32(RDTR);\r\nregs_buff[7] = er32(TCTL);\r\nregs_buff[8] = er32(TDBAL);\r\nregs_buff[9] = er32(TDBAH);\r\nregs_buff[10] = er32(TDLEN);\r\nregs_buff[11] = er32(TDH);\r\nregs_buff[12] = er32(TDT);\r\nregs_buff[13] = er32(TIDV);\r\nregs_buff[14] = er32(TXDCTL);\r\nregs_buff[15] = er32(TADV);\r\nregs_buff[16] = er32(TARC0);\r\nregs_buff[17] = er32(TDBAL1);\r\nregs_buff[18] = er32(TDBAH1);\r\nregs_buff[19] = er32(TDLEN1);\r\nregs_buff[20] = er32(TDH1);\r\nregs_buff[21] = er32(TDT1);\r\nregs_buff[22] = er32(TXDCTL1);\r\nregs_buff[23] = er32(TARC1);\r\nregs_buff[24] = er32(CTRL_EXT);\r\nregs_buff[25] = er32(ERT);\r\nregs_buff[26] = er32(RDBAL0);\r\nregs_buff[27] = er32(RDBAH0);\r\nregs_buff[28] = er32(TDFH);\r\nregs_buff[29] = er32(TDFT);\r\nregs_buff[30] = er32(TDFHS);\r\nregs_buff[31] = er32(TDFTS);\r\nregs_buff[32] = er32(TDFPC);\r\nregs_buff[33] = er32(RDFH);\r\nregs_buff[34] = er32(RDFT);\r\nregs_buff[35] = er32(RDFHS);\r\nregs_buff[36] = er32(RDFTS);\r\nregs_buff[37] = er32(RDFPC);\r\npr_info("Register dump\n");\r\nfor (i = 0; i < NUM_REGS; i++)\r\npr_info("%-15s %08x\n", reg_name[i], regs_buff[i]);\r\n}\r\nstatic void e1000_dump(struct e1000_adapter *adapter)\r\n{\r\nstruct e1000_tx_ring *tx_ring = adapter->tx_ring;\r\nstruct e1000_rx_ring *rx_ring = adapter->rx_ring;\r\nint i;\r\nif (!netif_msg_hw(adapter))\r\nreturn;\r\ne1000_regdump(adapter);\r\npr_info("TX Desc ring0 dump\n");\r\npr_info("Tc[desc] [Ce CoCsIpceCoS] [MssHlRSCm0Plen] [bi->dma ] leng ntw timestmp bi->skb\n");\r\npr_info("Td[desc] [address 63:0 ] [VlaPoRSCm1Dlen] [bi->dma ] leng ntw timestmp bi->skb\n");\r\nif (!netif_msg_tx_done(adapter))\r\ngoto rx_ring_summary;\r\nfor (i = 0; tx_ring->desc && (i < tx_ring->count); i++) {\r\nstruct e1000_tx_desc *tx_desc = E1000_TX_DESC(*tx_ring, i);\r\nstruct e1000_buffer *buffer_info = &tx_ring->buffer_info[i];\r\nstruct my_u { __le64 a; __le64 b; };\r\nstruct my_u *u = (struct my_u *)tx_desc;\r\nconst char *type;\r\nif (i == tx_ring->next_to_use && i == tx_ring->next_to_clean)\r\ntype = "NTC/U";\r\nelse if (i == tx_ring->next_to_use)\r\ntype = "NTU";\r\nelse if (i == tx_ring->next_to_clean)\r\ntype = "NTC";\r\nelse\r\ntype = "";\r\npr_info("T%c[0x%03X] %016llX %016llX %016llX %04X %3X %016llX %p %s\n",\r\n((le64_to_cpu(u->b) & (1<<20)) ? 'd' : 'c'), i,\r\nle64_to_cpu(u->a), le64_to_cpu(u->b),\r\n(u64)buffer_info->dma, buffer_info->length,\r\nbuffer_info->next_to_watch,\r\n(u64)buffer_info->time_stamp, buffer_info->skb, type);\r\n}\r\nrx_ring_summary:\r\npr_info("\nRX Desc ring dump\n");\r\npr_info("R[desc] [address 63:0 ] [vl er S cks ln] [bi->dma ] [bi->skb]\n");\r\nif (!netif_msg_rx_status(adapter))\r\ngoto exit;\r\nfor (i = 0; rx_ring->desc && (i < rx_ring->count); i++) {\r\nstruct e1000_rx_desc *rx_desc = E1000_RX_DESC(*rx_ring, i);\r\nstruct e1000_buffer *buffer_info = &rx_ring->buffer_info[i];\r\nstruct my_u { __le64 a; __le64 b; };\r\nstruct my_u *u = (struct my_u *)rx_desc;\r\nconst char *type;\r\nif (i == rx_ring->next_to_use)\r\ntype = "NTU";\r\nelse if (i == rx_ring->next_to_clean)\r\ntype = "NTC";\r\nelse\r\ntype = "";\r\npr_info("R[0x%03X] %016llX %016llX %016llX %p %s\n",\r\ni, le64_to_cpu(u->a), le64_to_cpu(u->b),\r\n(u64)buffer_info->dma, buffer_info->skb, type);\r\n}\r\npr_info("Rx descriptor cache in 64bit format\n");\r\nfor (i = 0x6000; i <= 0x63FF ; i += 0x10) {\r\npr_info("R%04X: %08X|%08X %08X|%08X\n",\r\ni,\r\nreadl(adapter->hw.hw_addr + i+4),\r\nreadl(adapter->hw.hw_addr + i),\r\nreadl(adapter->hw.hw_addr + i+12),\r\nreadl(adapter->hw.hw_addr + i+8));\r\n}\r\npr_info("Tx descriptor cache in 64bit format\n");\r\nfor (i = 0x7000; i <= 0x73FF ; i += 0x10) {\r\npr_info("T%04X: %08X|%08X %08X|%08X\n",\r\ni,\r\nreadl(adapter->hw.hw_addr + i+4),\r\nreadl(adapter->hw.hw_addr + i),\r\nreadl(adapter->hw.hw_addr + i+12),\r\nreadl(adapter->hw.hw_addr + i+8));\r\n}\r\nexit:\r\nreturn;\r\n}\r\nstatic void e1000_tx_timeout(struct net_device *netdev)\r\n{\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\nadapter->tx_timeout_count++;\r\nschedule_work(&adapter->reset_task);\r\n}\r\nstatic void e1000_reset_task(struct work_struct *work)\r\n{\r\nstruct e1000_adapter *adapter =\r\ncontainer_of(work, struct e1000_adapter, reset_task);\r\ne_err(drv, "Reset adapter\n");\r\ne1000_reinit_locked(adapter);\r\n}\r\nstatic struct net_device_stats *e1000_get_stats(struct net_device *netdev)\r\n{\r\nreturn &netdev->stats;\r\n}\r\nstatic int e1000_change_mtu(struct net_device *netdev, int new_mtu)\r\n{\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\nstruct e1000_hw *hw = &adapter->hw;\r\nint max_frame = new_mtu + ENET_HEADER_SIZE + ETHERNET_FCS_SIZE;\r\nif ((max_frame < MINIMUM_ETHERNET_FRAME_SIZE) ||\r\n(max_frame > MAX_JUMBO_FRAME_SIZE)) {\r\ne_err(probe, "Invalid MTU setting\n");\r\nreturn -EINVAL;\r\n}\r\nswitch (hw->mac_type) {\r\ncase e1000_undefined ... e1000_82542_rev2_1:\r\nif (max_frame > (ETH_FRAME_LEN + ETH_FCS_LEN)) {\r\ne_err(probe, "Jumbo Frames not supported.\n");\r\nreturn -EINVAL;\r\n}\r\nbreak;\r\ndefault:\r\nbreak;\r\n}\r\nwhile (test_and_set_bit(__E1000_RESETTING, &adapter->flags))\r\nmsleep(1);\r\nhw->max_frame_size = max_frame;\r\nif (netif_running(netdev))\r\ne1000_down(adapter);\r\nif (max_frame <= E1000_RXBUFFER_2048)\r\nadapter->rx_buffer_len = E1000_RXBUFFER_2048;\r\nelse\r\n#if (PAGE_SIZE >= E1000_RXBUFFER_16384)\r\nadapter->rx_buffer_len = E1000_RXBUFFER_16384;\r\n#elif (PAGE_SIZE >= E1000_RXBUFFER_4096)\r\nadapter->rx_buffer_len = PAGE_SIZE;\r\n#endif\r\nif (!hw->tbi_compatibility_on &&\r\n((max_frame == (ETH_FRAME_LEN + ETH_FCS_LEN)) ||\r\n(max_frame == MAXIMUM_ETHERNET_VLAN_SIZE)))\r\nadapter->rx_buffer_len = MAXIMUM_ETHERNET_VLAN_SIZE;\r\npr_info("%s changing MTU from %d to %d\n",\r\nnetdev->name, netdev->mtu, new_mtu);\r\nnetdev->mtu = new_mtu;\r\nif (netif_running(netdev))\r\ne1000_up(adapter);\r\nelse\r\ne1000_reset(adapter);\r\nclear_bit(__E1000_RESETTING, &adapter->flags);\r\nreturn 0;\r\n}\r\nvoid e1000_update_stats(struct e1000_adapter *adapter)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct e1000_hw *hw = &adapter->hw;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nunsigned long flags;\r\nu16 phy_tmp;\r\n#define PHY_IDLE_ERROR_COUNT_MASK 0x00FF\r\nif (adapter->link_speed == 0)\r\nreturn;\r\nif (pci_channel_offline(pdev))\r\nreturn;\r\nspin_lock_irqsave(&adapter->stats_lock, flags);\r\nadapter->stats.crcerrs += er32(CRCERRS);\r\nadapter->stats.gprc += er32(GPRC);\r\nadapter->stats.gorcl += er32(GORCL);\r\nadapter->stats.gorch += er32(GORCH);\r\nadapter->stats.bprc += er32(BPRC);\r\nadapter->stats.mprc += er32(MPRC);\r\nadapter->stats.roc += er32(ROC);\r\nadapter->stats.prc64 += er32(PRC64);\r\nadapter->stats.prc127 += er32(PRC127);\r\nadapter->stats.prc255 += er32(PRC255);\r\nadapter->stats.prc511 += er32(PRC511);\r\nadapter->stats.prc1023 += er32(PRC1023);\r\nadapter->stats.prc1522 += er32(PRC1522);\r\nadapter->stats.symerrs += er32(SYMERRS);\r\nadapter->stats.mpc += er32(MPC);\r\nadapter->stats.scc += er32(SCC);\r\nadapter->stats.ecol += er32(ECOL);\r\nadapter->stats.mcc += er32(MCC);\r\nadapter->stats.latecol += er32(LATECOL);\r\nadapter->stats.dc += er32(DC);\r\nadapter->stats.sec += er32(SEC);\r\nadapter->stats.rlec += er32(RLEC);\r\nadapter->stats.xonrxc += er32(XONRXC);\r\nadapter->stats.xontxc += er32(XONTXC);\r\nadapter->stats.xoffrxc += er32(XOFFRXC);\r\nadapter->stats.xofftxc += er32(XOFFTXC);\r\nadapter->stats.fcruc += er32(FCRUC);\r\nadapter->stats.gptc += er32(GPTC);\r\nadapter->stats.gotcl += er32(GOTCL);\r\nadapter->stats.gotch += er32(GOTCH);\r\nadapter->stats.rnbc += er32(RNBC);\r\nadapter->stats.ruc += er32(RUC);\r\nadapter->stats.rfc += er32(RFC);\r\nadapter->stats.rjc += er32(RJC);\r\nadapter->stats.torl += er32(TORL);\r\nadapter->stats.torh += er32(TORH);\r\nadapter->stats.totl += er32(TOTL);\r\nadapter->stats.toth += er32(TOTH);\r\nadapter->stats.tpr += er32(TPR);\r\nadapter->stats.ptc64 += er32(PTC64);\r\nadapter->stats.ptc127 += er32(PTC127);\r\nadapter->stats.ptc255 += er32(PTC255);\r\nadapter->stats.ptc511 += er32(PTC511);\r\nadapter->stats.ptc1023 += er32(PTC1023);\r\nadapter->stats.ptc1522 += er32(PTC1522);\r\nadapter->stats.mptc += er32(MPTC);\r\nadapter->stats.bptc += er32(BPTC);\r\nhw->tx_packet_delta = er32(TPT);\r\nadapter->stats.tpt += hw->tx_packet_delta;\r\nhw->collision_delta = er32(COLC);\r\nadapter->stats.colc += hw->collision_delta;\r\nif (hw->mac_type >= e1000_82543) {\r\nadapter->stats.algnerrc += er32(ALGNERRC);\r\nadapter->stats.rxerrc += er32(RXERRC);\r\nadapter->stats.tncrs += er32(TNCRS);\r\nadapter->stats.cexterr += er32(CEXTERR);\r\nadapter->stats.tsctc += er32(TSCTC);\r\nadapter->stats.tsctfc += er32(TSCTFC);\r\n}\r\nnetdev->stats.multicast = adapter->stats.mprc;\r\nnetdev->stats.collisions = adapter->stats.colc;\r\nnetdev->stats.rx_errors = adapter->stats.rxerrc +\r\nadapter->stats.crcerrs + adapter->stats.algnerrc +\r\nadapter->stats.ruc + adapter->stats.roc +\r\nadapter->stats.cexterr;\r\nadapter->stats.rlerrc = adapter->stats.ruc + adapter->stats.roc;\r\nnetdev->stats.rx_length_errors = adapter->stats.rlerrc;\r\nnetdev->stats.rx_crc_errors = adapter->stats.crcerrs;\r\nnetdev->stats.rx_frame_errors = adapter->stats.algnerrc;\r\nnetdev->stats.rx_missed_errors = adapter->stats.mpc;\r\nadapter->stats.txerrc = adapter->stats.ecol + adapter->stats.latecol;\r\nnetdev->stats.tx_errors = adapter->stats.txerrc;\r\nnetdev->stats.tx_aborted_errors = adapter->stats.ecol;\r\nnetdev->stats.tx_window_errors = adapter->stats.latecol;\r\nnetdev->stats.tx_carrier_errors = adapter->stats.tncrs;\r\nif (hw->bad_tx_carr_stats_fd &&\r\nadapter->link_duplex == FULL_DUPLEX) {\r\nnetdev->stats.tx_carrier_errors = 0;\r\nadapter->stats.tncrs = 0;\r\n}\r\nif (hw->media_type == e1000_media_type_copper) {\r\nif ((adapter->link_speed == SPEED_1000) &&\r\n(!e1000_read_phy_reg(hw, PHY_1000T_STATUS, &phy_tmp))) {\r\nphy_tmp &= PHY_IDLE_ERROR_COUNT_MASK;\r\nadapter->phy_stats.idle_errors += phy_tmp;\r\n}\r\nif ((hw->mac_type <= e1000_82546) &&\r\n(hw->phy_type == e1000_phy_m88) &&\r\n!e1000_read_phy_reg(hw, M88E1000_RX_ERR_CNTR, &phy_tmp))\r\nadapter->phy_stats.receive_errors += phy_tmp;\r\n}\r\nif (hw->has_smbus) {\r\nadapter->stats.mgptc += er32(MGTPTC);\r\nadapter->stats.mgprc += er32(MGTPRC);\r\nadapter->stats.mgpdc += er32(MGTPDC);\r\n}\r\nspin_unlock_irqrestore(&adapter->stats_lock, flags);\r\n}\r\nstatic irqreturn_t e1000_intr(int irq, void *data)\r\n{\r\nstruct net_device *netdev = data;\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\nstruct e1000_hw *hw = &adapter->hw;\r\nu32 icr = er32(ICR);\r\nif (unlikely((!icr)))\r\nreturn IRQ_NONE;\r\nif (unlikely(test_bit(__E1000_DOWN, &adapter->flags)))\r\nreturn IRQ_HANDLED;\r\nif (unlikely(icr & (E1000_ICR_RXSEQ | E1000_ICR_LSC))) {\r\nhw->get_link_status = 1;\r\nif (!test_bit(__E1000_DOWN, &adapter->flags))\r\nschedule_delayed_work(&adapter->watchdog_task, 1);\r\n}\r\new32(IMC, ~0);\r\nE1000_WRITE_FLUSH();\r\nif (likely(napi_schedule_prep(&adapter->napi))) {\r\nadapter->total_tx_bytes = 0;\r\nadapter->total_tx_packets = 0;\r\nadapter->total_rx_bytes = 0;\r\nadapter->total_rx_packets = 0;\r\n__napi_schedule(&adapter->napi);\r\n} else {\r\nif (!test_bit(__E1000_DOWN, &adapter->flags))\r\ne1000_irq_enable(adapter);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int e1000_clean(struct napi_struct *napi, int budget)\r\n{\r\nstruct e1000_adapter *adapter = container_of(napi, struct e1000_adapter,\r\nnapi);\r\nint tx_clean_complete = 0, work_done = 0;\r\ntx_clean_complete = e1000_clean_tx_irq(adapter, &adapter->tx_ring[0]);\r\nadapter->clean_rx(adapter, &adapter->rx_ring[0], &work_done, budget);\r\nif (!tx_clean_complete)\r\nwork_done = budget;\r\nif (work_done < budget) {\r\nif (likely(adapter->itr_setting & 3))\r\ne1000_set_itr(adapter);\r\nnapi_complete(napi);\r\nif (!test_bit(__E1000_DOWN, &adapter->flags))\r\ne1000_irq_enable(adapter);\r\n}\r\nreturn work_done;\r\n}\r\nstatic bool e1000_clean_tx_irq(struct e1000_adapter *adapter,\r\nstruct e1000_tx_ring *tx_ring)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct e1000_tx_desc *tx_desc, *eop_desc;\r\nstruct e1000_buffer *buffer_info;\r\nunsigned int i, eop;\r\nunsigned int count = 0;\r\nunsigned int total_tx_bytes=0, total_tx_packets=0;\r\nunsigned int bytes_compl = 0, pkts_compl = 0;\r\ni = tx_ring->next_to_clean;\r\neop = tx_ring->buffer_info[i].next_to_watch;\r\neop_desc = E1000_TX_DESC(*tx_ring, eop);\r\nwhile ((eop_desc->upper.data & cpu_to_le32(E1000_TXD_STAT_DD)) &&\r\n(count < tx_ring->count)) {\r\nbool cleaned = false;\r\nrmb();\r\nfor ( ; !cleaned; count++) {\r\ntx_desc = E1000_TX_DESC(*tx_ring, i);\r\nbuffer_info = &tx_ring->buffer_info[i];\r\ncleaned = (i == eop);\r\nif (cleaned) {\r\ntotal_tx_packets += buffer_info->segs;\r\ntotal_tx_bytes += buffer_info->bytecount;\r\nif (buffer_info->skb) {\r\nbytes_compl += buffer_info->skb->len;\r\npkts_compl++;\r\n}\r\n}\r\ne1000_unmap_and_free_tx_resource(adapter, buffer_info);\r\ntx_desc->upper.data = 0;\r\nif (unlikely(++i == tx_ring->count)) i = 0;\r\n}\r\neop = tx_ring->buffer_info[i].next_to_watch;\r\neop_desc = E1000_TX_DESC(*tx_ring, eop);\r\n}\r\ntx_ring->next_to_clean = i;\r\nnetdev_completed_queue(netdev, pkts_compl, bytes_compl);\r\n#define TX_WAKE_THRESHOLD 32\r\nif (unlikely(count && netif_carrier_ok(netdev) &&\r\nE1000_DESC_UNUSED(tx_ring) >= TX_WAKE_THRESHOLD)) {\r\nsmp_mb();\r\nif (netif_queue_stopped(netdev) &&\r\n!(test_bit(__E1000_DOWN, &adapter->flags))) {\r\nnetif_wake_queue(netdev);\r\n++adapter->restart_queue;\r\n}\r\n}\r\nif (adapter->detect_tx_hung) {\r\nadapter->detect_tx_hung = false;\r\nif (tx_ring->buffer_info[eop].time_stamp &&\r\ntime_after(jiffies, tx_ring->buffer_info[eop].time_stamp +\r\n(adapter->tx_timeout_factor * HZ)) &&\r\n!(er32(STATUS) & E1000_STATUS_TXOFF)) {\r\ne_err(drv, "Detected Tx Unit Hang\n"\r\n" Tx Queue <%lu>\n"\r\n" TDH <%x>\n"\r\n" TDT <%x>\n"\r\n" next_to_use <%x>\n"\r\n" next_to_clean <%x>\n"\r\n"buffer_info[next_to_clean]\n"\r\n" time_stamp <%lx>\n"\r\n" next_to_watch <%x>\n"\r\n" jiffies <%lx>\n"\r\n" next_to_watch.status <%x>\n",\r\n(unsigned long)(tx_ring - adapter->tx_ring),\r\nreadl(hw->hw_addr + tx_ring->tdh),\r\nreadl(hw->hw_addr + tx_ring->tdt),\r\ntx_ring->next_to_use,\r\ntx_ring->next_to_clean,\r\ntx_ring->buffer_info[eop].time_stamp,\r\neop,\r\njiffies,\r\neop_desc->upper.fields.status);\r\ne1000_dump(adapter);\r\nnetif_stop_queue(netdev);\r\n}\r\n}\r\nadapter->total_tx_bytes += total_tx_bytes;\r\nadapter->total_tx_packets += total_tx_packets;\r\nnetdev->stats.tx_bytes += total_tx_bytes;\r\nnetdev->stats.tx_packets += total_tx_packets;\r\nreturn count < tx_ring->count;\r\n}\r\nstatic void e1000_rx_checksum(struct e1000_adapter *adapter, u32 status_err,\r\nu32 csum, struct sk_buff *skb)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nu16 status = (u16)status_err;\r\nu8 errors = (u8)(status_err >> 24);\r\nskb_checksum_none_assert(skb);\r\nif (unlikely(hw->mac_type < e1000_82543)) return;\r\nif (unlikely(status & E1000_RXD_STAT_IXSM)) return;\r\nif (unlikely(errors & E1000_RXD_ERR_TCPE)) {\r\nadapter->hw_csum_err++;\r\nreturn;\r\n}\r\nif (!(status & E1000_RXD_STAT_TCPCS))\r\nreturn;\r\nif (likely(status & E1000_RXD_STAT_TCPCS)) {\r\nskb->ip_summed = CHECKSUM_UNNECESSARY;\r\n}\r\nadapter->hw_csum_good++;\r\n}\r\nstatic void e1000_consume_page(struct e1000_buffer *bi, struct sk_buff *skb,\r\nu16 length)\r\n{\r\nbi->page = NULL;\r\nskb->len += length;\r\nskb->data_len += length;\r\nskb->truesize += PAGE_SIZE;\r\n}\r\nstatic void e1000_receive_skb(struct e1000_adapter *adapter, u8 status,\r\n__le16 vlan, struct sk_buff *skb)\r\n{\r\nskb->protocol = eth_type_trans(skb, adapter->netdev);\r\nif (status & E1000_RXD_STAT_VP) {\r\nu16 vid = le16_to_cpu(vlan) & E1000_RXD_SPC_VLAN_MASK;\r\n__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vid);\r\n}\r\nnapi_gro_receive(&adapter->napi, skb);\r\n}\r\nstatic bool e1000_clean_jumbo_rx_irq(struct e1000_adapter *adapter,\r\nstruct e1000_rx_ring *rx_ring,\r\nint *work_done, int work_to_do)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nstruct e1000_rx_desc *rx_desc, *next_rxd;\r\nstruct e1000_buffer *buffer_info, *next_buffer;\r\nunsigned long irq_flags;\r\nu32 length;\r\nunsigned int i;\r\nint cleaned_count = 0;\r\nbool cleaned = false;\r\nunsigned int total_rx_bytes=0, total_rx_packets=0;\r\ni = rx_ring->next_to_clean;\r\nrx_desc = E1000_RX_DESC(*rx_ring, i);\r\nbuffer_info = &rx_ring->buffer_info[i];\r\nwhile (rx_desc->status & E1000_RXD_STAT_DD) {\r\nstruct sk_buff *skb;\r\nu8 status;\r\nif (*work_done >= work_to_do)\r\nbreak;\r\n(*work_done)++;\r\nrmb();\r\nstatus = rx_desc->status;\r\nskb = buffer_info->skb;\r\nbuffer_info->skb = NULL;\r\nif (++i == rx_ring->count) i = 0;\r\nnext_rxd = E1000_RX_DESC(*rx_ring, i);\r\nprefetch(next_rxd);\r\nnext_buffer = &rx_ring->buffer_info[i];\r\ncleaned = true;\r\ncleaned_count++;\r\ndma_unmap_page(&pdev->dev, buffer_info->dma,\r\nbuffer_info->length, DMA_FROM_DEVICE);\r\nbuffer_info->dma = 0;\r\nlength = le16_to_cpu(rx_desc->length);\r\nif (unlikely((status & E1000_RXD_STAT_EOP) &&\r\n(rx_desc->errors & E1000_RXD_ERR_FRAME_ERR_MASK))) {\r\nu8 *mapped;\r\nu8 last_byte;\r\nmapped = page_address(buffer_info->page);\r\nlast_byte = *(mapped + length - 1);\r\nif (TBI_ACCEPT(hw, status, rx_desc->errors, length,\r\nlast_byte)) {\r\nspin_lock_irqsave(&adapter->stats_lock,\r\nirq_flags);\r\ne1000_tbi_adjust_stats(hw, &adapter->stats,\r\nlength, mapped);\r\nspin_unlock_irqrestore(&adapter->stats_lock,\r\nirq_flags);\r\nlength--;\r\n} else {\r\nif (netdev->features & NETIF_F_RXALL)\r\ngoto process_skb;\r\nbuffer_info->skb = skb;\r\nif (rx_ring->rx_skb_top)\r\ndev_kfree_skb(rx_ring->rx_skb_top);\r\nrx_ring->rx_skb_top = NULL;\r\ngoto next_desc;\r\n}\r\n}\r\n#define rxtop rx_ring->rx_skb_top\r\nprocess_skb:\r\nif (!(status & E1000_RXD_STAT_EOP)) {\r\nif (!rxtop) {\r\nrxtop = skb;\r\nskb_fill_page_desc(rxtop, 0, buffer_info->page,\r\n0, length);\r\n} else {\r\nskb_fill_page_desc(rxtop,\r\nskb_shinfo(rxtop)->nr_frags,\r\nbuffer_info->page, 0, length);\r\nbuffer_info->skb = skb;\r\n}\r\ne1000_consume_page(buffer_info, rxtop, length);\r\ngoto next_desc;\r\n} else {\r\nif (rxtop) {\r\nskb_fill_page_desc(rxtop,\r\nskb_shinfo(rxtop)->nr_frags,\r\nbuffer_info->page, 0, length);\r\nbuffer_info->skb = skb;\r\nskb = rxtop;\r\nrxtop = NULL;\r\ne1000_consume_page(buffer_info, skb, length);\r\n} else {\r\nif (length <= copybreak &&\r\nskb_tailroom(skb) >= length) {\r\nu8 *vaddr;\r\nvaddr = kmap_atomic(buffer_info->page);\r\nmemcpy(skb_tail_pointer(skb), vaddr,\r\nlength);\r\nkunmap_atomic(vaddr);\r\nskb_put(skb, length);\r\n} else {\r\nskb_fill_page_desc(skb, 0,\r\nbuffer_info->page, 0,\r\nlength);\r\ne1000_consume_page(buffer_info, skb,\r\nlength);\r\n}\r\n}\r\n}\r\ne1000_rx_checksum(adapter,\r\n(u32)(status) |\r\n((u32)(rx_desc->errors) << 24),\r\nle16_to_cpu(rx_desc->csum), skb);\r\ntotal_rx_bytes += (skb->len - 4);\r\nif (likely(!(netdev->features & NETIF_F_RXFCS)))\r\npskb_trim(skb, skb->len - 4);\r\ntotal_rx_packets++;\r\nif (!pskb_may_pull(skb, ETH_HLEN)) {\r\ne_err(drv, "pskb_may_pull failed.\n");\r\ndev_kfree_skb(skb);\r\ngoto next_desc;\r\n}\r\ne1000_receive_skb(adapter, status, rx_desc->special, skb);\r\nnext_desc:\r\nrx_desc->status = 0;\r\nif (unlikely(cleaned_count >= E1000_RX_BUFFER_WRITE)) {\r\nadapter->alloc_rx_buf(adapter, rx_ring, cleaned_count);\r\ncleaned_count = 0;\r\n}\r\nrx_desc = next_rxd;\r\nbuffer_info = next_buffer;\r\n}\r\nrx_ring->next_to_clean = i;\r\ncleaned_count = E1000_DESC_UNUSED(rx_ring);\r\nif (cleaned_count)\r\nadapter->alloc_rx_buf(adapter, rx_ring, cleaned_count);\r\nadapter->total_rx_packets += total_rx_packets;\r\nadapter->total_rx_bytes += total_rx_bytes;\r\nnetdev->stats.rx_bytes += total_rx_bytes;\r\nnetdev->stats.rx_packets += total_rx_packets;\r\nreturn cleaned;\r\n}\r\nstatic void e1000_check_copybreak(struct net_device *netdev,\r\nstruct e1000_buffer *buffer_info,\r\nu32 length, struct sk_buff **skb)\r\n{\r\nstruct sk_buff *new_skb;\r\nif (length > copybreak)\r\nreturn;\r\nnew_skb = netdev_alloc_skb_ip_align(netdev, length);\r\nif (!new_skb)\r\nreturn;\r\nskb_copy_to_linear_data_offset(new_skb, -NET_IP_ALIGN,\r\n(*skb)->data - NET_IP_ALIGN,\r\nlength + NET_IP_ALIGN);\r\nbuffer_info->skb = *skb;\r\n*skb = new_skb;\r\n}\r\nstatic bool e1000_clean_rx_irq(struct e1000_adapter *adapter,\r\nstruct e1000_rx_ring *rx_ring,\r\nint *work_done, int work_to_do)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nstruct e1000_rx_desc *rx_desc, *next_rxd;\r\nstruct e1000_buffer *buffer_info, *next_buffer;\r\nunsigned long flags;\r\nu32 length;\r\nunsigned int i;\r\nint cleaned_count = 0;\r\nbool cleaned = false;\r\nunsigned int total_rx_bytes=0, total_rx_packets=0;\r\ni = rx_ring->next_to_clean;\r\nrx_desc = E1000_RX_DESC(*rx_ring, i);\r\nbuffer_info = &rx_ring->buffer_info[i];\r\nwhile (rx_desc->status & E1000_RXD_STAT_DD) {\r\nstruct sk_buff *skb;\r\nu8 status;\r\nif (*work_done >= work_to_do)\r\nbreak;\r\n(*work_done)++;\r\nrmb();\r\nstatus = rx_desc->status;\r\nskb = buffer_info->skb;\r\nbuffer_info->skb = NULL;\r\nprefetch(skb->data - NET_IP_ALIGN);\r\nif (++i == rx_ring->count) i = 0;\r\nnext_rxd = E1000_RX_DESC(*rx_ring, i);\r\nprefetch(next_rxd);\r\nnext_buffer = &rx_ring->buffer_info[i];\r\ncleaned = true;\r\ncleaned_count++;\r\ndma_unmap_single(&pdev->dev, buffer_info->dma,\r\nbuffer_info->length, DMA_FROM_DEVICE);\r\nbuffer_info->dma = 0;\r\nlength = le16_to_cpu(rx_desc->length);\r\nif (unlikely(!(status & E1000_RXD_STAT_EOP)))\r\nadapter->discarding = true;\r\nif (adapter->discarding) {\r\ne_dbg("Receive packet consumed multiple buffers\n");\r\nbuffer_info->skb = skb;\r\nif (status & E1000_RXD_STAT_EOP)\r\nadapter->discarding = false;\r\ngoto next_desc;\r\n}\r\nif (unlikely(rx_desc->errors & E1000_RXD_ERR_FRAME_ERR_MASK)) {\r\nu8 last_byte = *(skb->data + length - 1);\r\nif (TBI_ACCEPT(hw, status, rx_desc->errors, length,\r\nlast_byte)) {\r\nspin_lock_irqsave(&adapter->stats_lock, flags);\r\ne1000_tbi_adjust_stats(hw, &adapter->stats,\r\nlength, skb->data);\r\nspin_unlock_irqrestore(&adapter->stats_lock,\r\nflags);\r\nlength--;\r\n} else {\r\nif (netdev->features & NETIF_F_RXALL)\r\ngoto process_skb;\r\nbuffer_info->skb = skb;\r\ngoto next_desc;\r\n}\r\n}\r\nprocess_skb:\r\ntotal_rx_bytes += (length - 4);\r\ntotal_rx_packets++;\r\nif (likely(!(netdev->features & NETIF_F_RXFCS)))\r\nlength -= 4;\r\ne1000_check_copybreak(netdev, buffer_info, length, &skb);\r\nskb_put(skb, length);\r\ne1000_rx_checksum(adapter,\r\n(u32)(status) |\r\n((u32)(rx_desc->errors) << 24),\r\nle16_to_cpu(rx_desc->csum), skb);\r\ne1000_receive_skb(adapter, status, rx_desc->special, skb);\r\nnext_desc:\r\nrx_desc->status = 0;\r\nif (unlikely(cleaned_count >= E1000_RX_BUFFER_WRITE)) {\r\nadapter->alloc_rx_buf(adapter, rx_ring, cleaned_count);\r\ncleaned_count = 0;\r\n}\r\nrx_desc = next_rxd;\r\nbuffer_info = next_buffer;\r\n}\r\nrx_ring->next_to_clean = i;\r\ncleaned_count = E1000_DESC_UNUSED(rx_ring);\r\nif (cleaned_count)\r\nadapter->alloc_rx_buf(adapter, rx_ring, cleaned_count);\r\nadapter->total_rx_packets += total_rx_packets;\r\nadapter->total_rx_bytes += total_rx_bytes;\r\nnetdev->stats.rx_bytes += total_rx_bytes;\r\nnetdev->stats.rx_packets += total_rx_packets;\r\nreturn cleaned;\r\n}\r\nstatic void\r\ne1000_alloc_jumbo_rx_buffers(struct e1000_adapter *adapter,\r\nstruct e1000_rx_ring *rx_ring, int cleaned_count)\r\n{\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nstruct e1000_rx_desc *rx_desc;\r\nstruct e1000_buffer *buffer_info;\r\nstruct sk_buff *skb;\r\nunsigned int i;\r\nunsigned int bufsz = 256 - 16 ;\r\ni = rx_ring->next_to_use;\r\nbuffer_info = &rx_ring->buffer_info[i];\r\nwhile (cleaned_count--) {\r\nskb = buffer_info->skb;\r\nif (skb) {\r\nskb_trim(skb, 0);\r\ngoto check_page;\r\n}\r\nskb = netdev_alloc_skb_ip_align(netdev, bufsz);\r\nif (unlikely(!skb)) {\r\nadapter->alloc_rx_buff_failed++;\r\nbreak;\r\n}\r\nbuffer_info->skb = skb;\r\nbuffer_info->length = adapter->rx_buffer_len;\r\ncheck_page:\r\nif (!buffer_info->page) {\r\nbuffer_info->page = alloc_page(GFP_ATOMIC);\r\nif (unlikely(!buffer_info->page)) {\r\nadapter->alloc_rx_buff_failed++;\r\nbreak;\r\n}\r\n}\r\nif (!buffer_info->dma) {\r\nbuffer_info->dma = dma_map_page(&pdev->dev,\r\nbuffer_info->page, 0,\r\nbuffer_info->length,\r\nDMA_FROM_DEVICE);\r\nif (dma_mapping_error(&pdev->dev, buffer_info->dma)) {\r\nput_page(buffer_info->page);\r\ndev_kfree_skb(skb);\r\nbuffer_info->page = NULL;\r\nbuffer_info->skb = NULL;\r\nbuffer_info->dma = 0;\r\nadapter->alloc_rx_buff_failed++;\r\nbreak;\r\n}\r\n}\r\nrx_desc = E1000_RX_DESC(*rx_ring, i);\r\nrx_desc->buffer_addr = cpu_to_le64(buffer_info->dma);\r\nif (unlikely(++i == rx_ring->count))\r\ni = 0;\r\nbuffer_info = &rx_ring->buffer_info[i];\r\n}\r\nif (likely(rx_ring->next_to_use != i)) {\r\nrx_ring->next_to_use = i;\r\nif (unlikely(i-- == 0))\r\ni = (rx_ring->count - 1);\r\nwmb();\r\nwritel(i, adapter->hw.hw_addr + rx_ring->rdt);\r\n}\r\n}\r\nstatic void e1000_alloc_rx_buffers(struct e1000_adapter *adapter,\r\nstruct e1000_rx_ring *rx_ring,\r\nint cleaned_count)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nstruct net_device *netdev = adapter->netdev;\r\nstruct pci_dev *pdev = adapter->pdev;\r\nstruct e1000_rx_desc *rx_desc;\r\nstruct e1000_buffer *buffer_info;\r\nstruct sk_buff *skb;\r\nunsigned int i;\r\nunsigned int bufsz = adapter->rx_buffer_len;\r\ni = rx_ring->next_to_use;\r\nbuffer_info = &rx_ring->buffer_info[i];\r\nwhile (cleaned_count--) {\r\nskb = buffer_info->skb;\r\nif (skb) {\r\nskb_trim(skb, 0);\r\ngoto map_skb;\r\n}\r\nskb = netdev_alloc_skb_ip_align(netdev, bufsz);\r\nif (unlikely(!skb)) {\r\nadapter->alloc_rx_buff_failed++;\r\nbreak;\r\n}\r\nif (!e1000_check_64k_bound(adapter, skb->data, bufsz)) {\r\nstruct sk_buff *oldskb = skb;\r\ne_err(rx_err, "skb align check failed: %u bytes at "\r\n"%p\n", bufsz, skb->data);\r\nskb = netdev_alloc_skb_ip_align(netdev, bufsz);\r\nif (!skb) {\r\ndev_kfree_skb(oldskb);\r\nadapter->alloc_rx_buff_failed++;\r\nbreak;\r\n}\r\nif (!e1000_check_64k_bound(adapter, skb->data, bufsz)) {\r\ndev_kfree_skb(skb);\r\ndev_kfree_skb(oldskb);\r\nadapter->alloc_rx_buff_failed++;\r\nbreak;\r\n}\r\ndev_kfree_skb(oldskb);\r\n}\r\nbuffer_info->skb = skb;\r\nbuffer_info->length = adapter->rx_buffer_len;\r\nmap_skb:\r\nbuffer_info->dma = dma_map_single(&pdev->dev,\r\nskb->data,\r\nbuffer_info->length,\r\nDMA_FROM_DEVICE);\r\nif (dma_mapping_error(&pdev->dev, buffer_info->dma)) {\r\ndev_kfree_skb(skb);\r\nbuffer_info->skb = NULL;\r\nbuffer_info->dma = 0;\r\nadapter->alloc_rx_buff_failed++;\r\nbreak;\r\n}\r\nif (!e1000_check_64k_bound(adapter,\r\n(void *)(unsigned long)buffer_info->dma,\r\nadapter->rx_buffer_len)) {\r\ne_err(rx_err, "dma align check failed: %u bytes at "\r\n"%p\n", adapter->rx_buffer_len,\r\n(void *)(unsigned long)buffer_info->dma);\r\ndev_kfree_skb(skb);\r\nbuffer_info->skb = NULL;\r\ndma_unmap_single(&pdev->dev, buffer_info->dma,\r\nadapter->rx_buffer_len,\r\nDMA_FROM_DEVICE);\r\nbuffer_info->dma = 0;\r\nadapter->alloc_rx_buff_failed++;\r\nbreak;\r\n}\r\nrx_desc = E1000_RX_DESC(*rx_ring, i);\r\nrx_desc->buffer_addr = cpu_to_le64(buffer_info->dma);\r\nif (unlikely(++i == rx_ring->count))\r\ni = 0;\r\nbuffer_info = &rx_ring->buffer_info[i];\r\n}\r\nif (likely(rx_ring->next_to_use != i)) {\r\nrx_ring->next_to_use = i;\r\nif (unlikely(i-- == 0))\r\ni = (rx_ring->count - 1);\r\nwmb();\r\nwritel(i, hw->hw_addr + rx_ring->rdt);\r\n}\r\n}\r\nstatic void e1000_smartspeed(struct e1000_adapter *adapter)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nu16 phy_status;\r\nu16 phy_ctrl;\r\nif ((hw->phy_type != e1000_phy_igp) || !hw->autoneg ||\r\n!(hw->autoneg_advertised & ADVERTISE_1000_FULL))\r\nreturn;\r\nif (adapter->smartspeed == 0) {\r\ne1000_read_phy_reg(hw, PHY_1000T_STATUS, &phy_status);\r\nif (!(phy_status & SR_1000T_MS_CONFIG_FAULT)) return;\r\ne1000_read_phy_reg(hw, PHY_1000T_STATUS, &phy_status);\r\nif (!(phy_status & SR_1000T_MS_CONFIG_FAULT)) return;\r\ne1000_read_phy_reg(hw, PHY_1000T_CTRL, &phy_ctrl);\r\nif (phy_ctrl & CR_1000T_MS_ENABLE) {\r\nphy_ctrl &= ~CR_1000T_MS_ENABLE;\r\ne1000_write_phy_reg(hw, PHY_1000T_CTRL,\r\nphy_ctrl);\r\nadapter->smartspeed++;\r\nif (!e1000_phy_setup_autoneg(hw) &&\r\n!e1000_read_phy_reg(hw, PHY_CTRL,\r\n&phy_ctrl)) {\r\nphy_ctrl |= (MII_CR_AUTO_NEG_EN |\r\nMII_CR_RESTART_AUTO_NEG);\r\ne1000_write_phy_reg(hw, PHY_CTRL,\r\nphy_ctrl);\r\n}\r\n}\r\nreturn;\r\n} else if (adapter->smartspeed == E1000_SMARTSPEED_DOWNSHIFT) {\r\ne1000_read_phy_reg(hw, PHY_1000T_CTRL, &phy_ctrl);\r\nphy_ctrl |= CR_1000T_MS_ENABLE;\r\ne1000_write_phy_reg(hw, PHY_1000T_CTRL, phy_ctrl);\r\nif (!e1000_phy_setup_autoneg(hw) &&\r\n!e1000_read_phy_reg(hw, PHY_CTRL, &phy_ctrl)) {\r\nphy_ctrl |= (MII_CR_AUTO_NEG_EN |\r\nMII_CR_RESTART_AUTO_NEG);\r\ne1000_write_phy_reg(hw, PHY_CTRL, phy_ctrl);\r\n}\r\n}\r\nif (adapter->smartspeed++ == E1000_SMARTSPEED_MAX)\r\nadapter->smartspeed = 0;\r\n}\r\nstatic int e1000_ioctl(struct net_device *netdev, struct ifreq *ifr, int cmd)\r\n{\r\nswitch (cmd) {\r\ncase SIOCGMIIPHY:\r\ncase SIOCGMIIREG:\r\ncase SIOCSMIIREG:\r\nreturn e1000_mii_ioctl(netdev, ifr, cmd);\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nstatic int e1000_mii_ioctl(struct net_device *netdev, struct ifreq *ifr,\r\nint cmd)\r\n{\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\nstruct e1000_hw *hw = &adapter->hw;\r\nstruct mii_ioctl_data *data = if_mii(ifr);\r\nint retval;\r\nu16 mii_reg;\r\nunsigned long flags;\r\nif (hw->media_type != e1000_media_type_copper)\r\nreturn -EOPNOTSUPP;\r\nswitch (cmd) {\r\ncase SIOCGMIIPHY:\r\ndata->phy_id = hw->phy_addr;\r\nbreak;\r\ncase SIOCGMIIREG:\r\nspin_lock_irqsave(&adapter->stats_lock, flags);\r\nif (e1000_read_phy_reg(hw, data->reg_num & 0x1F,\r\n&data->val_out)) {\r\nspin_unlock_irqrestore(&adapter->stats_lock, flags);\r\nreturn -EIO;\r\n}\r\nspin_unlock_irqrestore(&adapter->stats_lock, flags);\r\nbreak;\r\ncase SIOCSMIIREG:\r\nif (data->reg_num & ~(0x1F))\r\nreturn -EFAULT;\r\nmii_reg = data->val_in;\r\nspin_lock_irqsave(&adapter->stats_lock, flags);\r\nif (e1000_write_phy_reg(hw, data->reg_num,\r\nmii_reg)) {\r\nspin_unlock_irqrestore(&adapter->stats_lock, flags);\r\nreturn -EIO;\r\n}\r\nspin_unlock_irqrestore(&adapter->stats_lock, flags);\r\nif (hw->media_type == e1000_media_type_copper) {\r\nswitch (data->reg_num) {\r\ncase PHY_CTRL:\r\nif (mii_reg & MII_CR_POWER_DOWN)\r\nbreak;\r\nif (mii_reg & MII_CR_AUTO_NEG_EN) {\r\nhw->autoneg = 1;\r\nhw->autoneg_advertised = 0x2F;\r\n} else {\r\nu32 speed;\r\nif (mii_reg & 0x40)\r\nspeed = SPEED_1000;\r\nelse if (mii_reg & 0x2000)\r\nspeed = SPEED_100;\r\nelse\r\nspeed = SPEED_10;\r\nretval = e1000_set_spd_dplx(\r\nadapter, speed,\r\n((mii_reg & 0x100)\r\n? DUPLEX_FULL :\r\nDUPLEX_HALF));\r\nif (retval)\r\nreturn retval;\r\n}\r\nif (netif_running(adapter->netdev))\r\ne1000_reinit_locked(adapter);\r\nelse\r\ne1000_reset(adapter);\r\nbreak;\r\ncase M88E1000_PHY_SPEC_CTRL:\r\ncase M88E1000_EXT_PHY_SPEC_CTRL:\r\nif (e1000_phy_reset(hw))\r\nreturn -EIO;\r\nbreak;\r\n}\r\n} else {\r\nswitch (data->reg_num) {\r\ncase PHY_CTRL:\r\nif (mii_reg & MII_CR_POWER_DOWN)\r\nbreak;\r\nif (netif_running(adapter->netdev))\r\ne1000_reinit_locked(adapter);\r\nelse\r\ne1000_reset(adapter);\r\nbreak;\r\n}\r\n}\r\nbreak;\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\nreturn E1000_SUCCESS;\r\n}\r\nvoid e1000_pci_set_mwi(struct e1000_hw *hw)\r\n{\r\nstruct e1000_adapter *adapter = hw->back;\r\nint ret_val = pci_set_mwi(adapter->pdev);\r\nif (ret_val)\r\ne_err(probe, "Error in setting MWI\n");\r\n}\r\nvoid e1000_pci_clear_mwi(struct e1000_hw *hw)\r\n{\r\nstruct e1000_adapter *adapter = hw->back;\r\npci_clear_mwi(adapter->pdev);\r\n}\r\nint e1000_pcix_get_mmrbc(struct e1000_hw *hw)\r\n{\r\nstruct e1000_adapter *adapter = hw->back;\r\nreturn pcix_get_mmrbc(adapter->pdev);\r\n}\r\nvoid e1000_pcix_set_mmrbc(struct e1000_hw *hw, int mmrbc)\r\n{\r\nstruct e1000_adapter *adapter = hw->back;\r\npcix_set_mmrbc(adapter->pdev, mmrbc);\r\n}\r\nvoid e1000_io_write(struct e1000_hw *hw, unsigned long port, u32 value)\r\n{\r\noutl(value, port);\r\n}\r\nstatic bool e1000_vlan_used(struct e1000_adapter *adapter)\r\n{\r\nu16 vid;\r\nfor_each_set_bit(vid, adapter->active_vlans, VLAN_N_VID)\r\nreturn true;\r\nreturn false;\r\n}\r\nstatic void __e1000_vlan_mode(struct e1000_adapter *adapter,\r\nnetdev_features_t features)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nu32 ctrl;\r\nctrl = er32(CTRL);\r\nif (features & NETIF_F_HW_VLAN_CTAG_RX) {\r\nctrl |= E1000_CTRL_VME;\r\n} else {\r\nctrl &= ~E1000_CTRL_VME;\r\n}\r\new32(CTRL, ctrl);\r\n}\r\nstatic void e1000_vlan_filter_on_off(struct e1000_adapter *adapter,\r\nbool filter_on)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nu32 rctl;\r\nif (!test_bit(__E1000_DOWN, &adapter->flags))\r\ne1000_irq_disable(adapter);\r\n__e1000_vlan_mode(adapter, adapter->netdev->features);\r\nif (filter_on) {\r\nrctl = er32(RCTL);\r\nrctl &= ~E1000_RCTL_CFIEN;\r\nif (!(adapter->netdev->flags & IFF_PROMISC))\r\nrctl |= E1000_RCTL_VFE;\r\new32(RCTL, rctl);\r\ne1000_update_mng_vlan(adapter);\r\n} else {\r\nrctl = er32(RCTL);\r\nrctl &= ~E1000_RCTL_VFE;\r\new32(RCTL, rctl);\r\n}\r\nif (!test_bit(__E1000_DOWN, &adapter->flags))\r\ne1000_irq_enable(adapter);\r\n}\r\nstatic void e1000_vlan_mode(struct net_device *netdev,\r\nnetdev_features_t features)\r\n{\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\nif (!test_bit(__E1000_DOWN, &adapter->flags))\r\ne1000_irq_disable(adapter);\r\n__e1000_vlan_mode(adapter, features);\r\nif (!test_bit(__E1000_DOWN, &adapter->flags))\r\ne1000_irq_enable(adapter);\r\n}\r\nstatic int e1000_vlan_rx_add_vid(struct net_device *netdev,\r\n__be16 proto, u16 vid)\r\n{\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\nstruct e1000_hw *hw = &adapter->hw;\r\nu32 vfta, index;\r\nif ((hw->mng_cookie.status &\r\nE1000_MNG_DHCP_COOKIE_STATUS_VLAN_SUPPORT) &&\r\n(vid == adapter->mng_vlan_id))\r\nreturn 0;\r\nif (!e1000_vlan_used(adapter))\r\ne1000_vlan_filter_on_off(adapter, true);\r\nindex = (vid >> 5) & 0x7F;\r\nvfta = E1000_READ_REG_ARRAY(hw, VFTA, index);\r\nvfta |= (1 << (vid & 0x1F));\r\ne1000_write_vfta(hw, index, vfta);\r\nset_bit(vid, adapter->active_vlans);\r\nreturn 0;\r\n}\r\nstatic int e1000_vlan_rx_kill_vid(struct net_device *netdev,\r\n__be16 proto, u16 vid)\r\n{\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\nstruct e1000_hw *hw = &adapter->hw;\r\nu32 vfta, index;\r\nif (!test_bit(__E1000_DOWN, &adapter->flags))\r\ne1000_irq_disable(adapter);\r\nif (!test_bit(__E1000_DOWN, &adapter->flags))\r\ne1000_irq_enable(adapter);\r\nindex = (vid >> 5) & 0x7F;\r\nvfta = E1000_READ_REG_ARRAY(hw, VFTA, index);\r\nvfta &= ~(1 << (vid & 0x1F));\r\ne1000_write_vfta(hw, index, vfta);\r\nclear_bit(vid, adapter->active_vlans);\r\nif (!e1000_vlan_used(adapter))\r\ne1000_vlan_filter_on_off(adapter, false);\r\nreturn 0;\r\n}\r\nstatic void e1000_restore_vlan(struct e1000_adapter *adapter)\r\n{\r\nu16 vid;\r\nif (!e1000_vlan_used(adapter))\r\nreturn;\r\ne1000_vlan_filter_on_off(adapter, true);\r\nfor_each_set_bit(vid, adapter->active_vlans, VLAN_N_VID)\r\ne1000_vlan_rx_add_vid(adapter->netdev, htons(ETH_P_8021Q), vid);\r\n}\r\nint e1000_set_spd_dplx(struct e1000_adapter *adapter, u32 spd, u8 dplx)\r\n{\r\nstruct e1000_hw *hw = &adapter->hw;\r\nhw->autoneg = 0;\r\nif ((spd & 1) || (dplx & ~1))\r\ngoto err_inval;\r\nif ((hw->media_type == e1000_media_type_fiber) &&\r\nspd != SPEED_1000 &&\r\ndplx != DUPLEX_FULL)\r\ngoto err_inval;\r\nswitch (spd + dplx) {\r\ncase SPEED_10 + DUPLEX_HALF:\r\nhw->forced_speed_duplex = e1000_10_half;\r\nbreak;\r\ncase SPEED_10 + DUPLEX_FULL:\r\nhw->forced_speed_duplex = e1000_10_full;\r\nbreak;\r\ncase SPEED_100 + DUPLEX_HALF:\r\nhw->forced_speed_duplex = e1000_100_half;\r\nbreak;\r\ncase SPEED_100 + DUPLEX_FULL:\r\nhw->forced_speed_duplex = e1000_100_full;\r\nbreak;\r\ncase SPEED_1000 + DUPLEX_FULL:\r\nhw->autoneg = 1;\r\nhw->autoneg_advertised = ADVERTISE_1000_FULL;\r\nbreak;\r\ncase SPEED_1000 + DUPLEX_HALF:\r\ndefault:\r\ngoto err_inval;\r\n}\r\nhw->mdix = AUTO_ALL_MODES;\r\nreturn 0;\r\nerr_inval:\r\ne_err(probe, "Unsupported Speed/Duplex configuration\n");\r\nreturn -EINVAL;\r\n}\r\nstatic int __e1000_shutdown(struct pci_dev *pdev, bool *enable_wake)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\nstruct e1000_hw *hw = &adapter->hw;\r\nu32 ctrl, ctrl_ext, rctl, status;\r\nu32 wufc = adapter->wol;\r\n#ifdef CONFIG_PM\r\nint retval = 0;\r\n#endif\r\nnetif_device_detach(netdev);\r\nif (netif_running(netdev)) {\r\nint count = E1000_CHECK_RESET_COUNT;\r\nwhile (test_bit(__E1000_RESETTING, &adapter->flags) && count--)\r\nusleep_range(10000, 20000);\r\nWARN_ON(test_bit(__E1000_RESETTING, &adapter->flags));\r\ne1000_down(adapter);\r\n}\r\n#ifdef CONFIG_PM\r\nretval = pci_save_state(pdev);\r\nif (retval)\r\nreturn retval;\r\n#endif\r\nstatus = er32(STATUS);\r\nif (status & E1000_STATUS_LU)\r\nwufc &= ~E1000_WUFC_LNKC;\r\nif (wufc) {\r\ne1000_setup_rctl(adapter);\r\ne1000_set_rx_mode(netdev);\r\nrctl = er32(RCTL);\r\nif (wufc & E1000_WUFC_MC)\r\nrctl |= E1000_RCTL_MPE;\r\new32(RCTL, rctl | E1000_RCTL_EN);\r\nif (hw->mac_type >= e1000_82540) {\r\nctrl = er32(CTRL);\r\n#define E1000_CTRL_ADVD3WUC 0x00100000\r\n#define E1000_CTRL_EN_PHY_PWR_MGMT 0x00200000\r\nctrl |= E1000_CTRL_ADVD3WUC |\r\nE1000_CTRL_EN_PHY_PWR_MGMT;\r\new32(CTRL, ctrl);\r\n}\r\nif (hw->media_type == e1000_media_type_fiber ||\r\nhw->media_type == e1000_media_type_internal_serdes) {\r\nctrl_ext = er32(CTRL_EXT);\r\nctrl_ext |= E1000_CTRL_EXT_SDP7_DATA;\r\new32(CTRL_EXT, ctrl_ext);\r\n}\r\new32(WUC, E1000_WUC_PME_EN);\r\new32(WUFC, wufc);\r\n} else {\r\new32(WUC, 0);\r\new32(WUFC, 0);\r\n}\r\ne1000_release_manageability(adapter);\r\n*enable_wake = !!wufc;\r\nif (adapter->en_mng_pt)\r\n*enable_wake = true;\r\nif (netif_running(netdev))\r\ne1000_free_irq(adapter);\r\npci_disable_device(pdev);\r\nreturn 0;\r\n}\r\nstatic int e1000_suspend(struct pci_dev *pdev, pm_message_t state)\r\n{\r\nint retval;\r\nbool wake;\r\nretval = __e1000_shutdown(pdev, &wake);\r\nif (retval)\r\nreturn retval;\r\nif (wake) {\r\npci_prepare_to_sleep(pdev);\r\n} else {\r\npci_wake_from_d3(pdev, false);\r\npci_set_power_state(pdev, PCI_D3hot);\r\n}\r\nreturn 0;\r\n}\r\nstatic int e1000_resume(struct pci_dev *pdev)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\nstruct e1000_hw *hw = &adapter->hw;\r\nu32 err;\r\npci_set_power_state(pdev, PCI_D0);\r\npci_restore_state(pdev);\r\npci_save_state(pdev);\r\nif (adapter->need_ioport)\r\nerr = pci_enable_device(pdev);\r\nelse\r\nerr = pci_enable_device_mem(pdev);\r\nif (err) {\r\npr_err("Cannot enable PCI device from suspend\n");\r\nreturn err;\r\n}\r\npci_set_master(pdev);\r\npci_enable_wake(pdev, PCI_D3hot, 0);\r\npci_enable_wake(pdev, PCI_D3cold, 0);\r\nif (netif_running(netdev)) {\r\nerr = e1000_request_irq(adapter);\r\nif (err)\r\nreturn err;\r\n}\r\ne1000_power_up_phy(adapter);\r\ne1000_reset(adapter);\r\new32(WUS, ~0);\r\ne1000_init_manageability(adapter);\r\nif (netif_running(netdev))\r\ne1000_up(adapter);\r\nnetif_device_attach(netdev);\r\nreturn 0;\r\n}\r\nstatic void e1000_shutdown(struct pci_dev *pdev)\r\n{\r\nbool wake;\r\n__e1000_shutdown(pdev, &wake);\r\nif (system_state == SYSTEM_POWER_OFF) {\r\npci_wake_from_d3(pdev, wake);\r\npci_set_power_state(pdev, PCI_D3hot);\r\n}\r\n}\r\nstatic void e1000_netpoll(struct net_device *netdev)\r\n{\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\ndisable_irq(adapter->pdev->irq);\r\ne1000_intr(adapter->pdev->irq, netdev);\r\nenable_irq(adapter->pdev->irq);\r\n}\r\nstatic pci_ers_result_t e1000_io_error_detected(struct pci_dev *pdev,\r\npci_channel_state_t state)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\nnetif_device_detach(netdev);\r\nif (state == pci_channel_io_perm_failure)\r\nreturn PCI_ERS_RESULT_DISCONNECT;\r\nif (netif_running(netdev))\r\ne1000_down(adapter);\r\npci_disable_device(pdev);\r\nreturn PCI_ERS_RESULT_NEED_RESET;\r\n}\r\nstatic pci_ers_result_t e1000_io_slot_reset(struct pci_dev *pdev)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\nstruct e1000_hw *hw = &adapter->hw;\r\nint err;\r\nif (adapter->need_ioport)\r\nerr = pci_enable_device(pdev);\r\nelse\r\nerr = pci_enable_device_mem(pdev);\r\nif (err) {\r\npr_err("Cannot re-enable PCI device after reset.\n");\r\nreturn PCI_ERS_RESULT_DISCONNECT;\r\n}\r\npci_set_master(pdev);\r\npci_enable_wake(pdev, PCI_D3hot, 0);\r\npci_enable_wake(pdev, PCI_D3cold, 0);\r\ne1000_reset(adapter);\r\new32(WUS, ~0);\r\nreturn PCI_ERS_RESULT_RECOVERED;\r\n}\r\nstatic void e1000_io_resume(struct pci_dev *pdev)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct e1000_adapter *adapter = netdev_priv(netdev);\r\ne1000_init_manageability(adapter);\r\nif (netif_running(netdev)) {\r\nif (e1000_up(adapter)) {\r\npr_info("can't bring device back up after reset\n");\r\nreturn;\r\n}\r\n}\r\nnetif_device_attach(netdev);\r\n}
