static inline bool is_genesis(const struct skge_hw *hw)\r\n{\r\n#ifdef CONFIG_SKGE_GENESIS\r\nreturn hw->chip_id == CHIP_ID_GENESIS;\r\n#else\r\nreturn false;\r\n#endif\r\n}\r\nstatic int skge_get_regs_len(struct net_device *dev)\r\n{\r\nreturn 0x4000;\r\n}\r\nstatic void skge_get_regs(struct net_device *dev, struct ethtool_regs *regs,\r\nvoid *p)\r\n{\r\nconst struct skge_port *skge = netdev_priv(dev);\r\nconst void __iomem *io = skge->hw->regs;\r\nregs->version = 1;\r\nmemset(p, 0, regs->len);\r\nmemcpy_fromio(p, io, B3_RAM_ADDR);\r\nmemcpy_fromio(p + B3_RI_WTO_R1, io + B3_RI_WTO_R1,\r\nregs->len - B3_RI_WTO_R1);\r\n}\r\nstatic u32 wol_supported(const struct skge_hw *hw)\r\n{\r\nif (is_genesis(hw))\r\nreturn 0;\r\nif (hw->chip_id == CHIP_ID_YUKON && hw->chip_rev == 0)\r\nreturn 0;\r\nreturn WAKE_MAGIC | WAKE_PHY;\r\n}\r\nstatic void skge_wol_init(struct skge_port *skge)\r\n{\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nu16 ctrl;\r\nskge_write16(hw, B0_CTST, CS_RST_CLR);\r\nskge_write16(hw, SK_REG(port, GMAC_LINK_CTRL), GMLC_RST_CLR);\r\nskge_write8(hw, B0_POWER_CTRL,\r\nPC_VAUX_ENA | PC_VCC_ENA | PC_VAUX_ON | PC_VCC_OFF);\r\nif (hw->chip_id == CHIP_ID_YUKON_LITE &&\r\nhw->chip_rev >= CHIP_REV_YU_LITE_A3) {\r\nu32 reg = skge_read32(hw, B2_GP_IO);\r\nreg |= GP_DIR_9;\r\nreg &= ~GP_IO_9;\r\nskge_write32(hw, B2_GP_IO, reg);\r\n}\r\nskge_write32(hw, SK_REG(port, GPHY_CTRL),\r\nGPC_DIS_SLEEP |\r\nGPC_HWCFG_M_3 | GPC_HWCFG_M_2 | GPC_HWCFG_M_1 | GPC_HWCFG_M_0 |\r\nGPC_ANEG_1 | GPC_RST_SET);\r\nskge_write32(hw, SK_REG(port, GPHY_CTRL),\r\nGPC_DIS_SLEEP |\r\nGPC_HWCFG_M_3 | GPC_HWCFG_M_2 | GPC_HWCFG_M_1 | GPC_HWCFG_M_0 |\r\nGPC_ANEG_1 | GPC_RST_CLR);\r\nskge_write32(hw, SK_REG(port, GMAC_CTRL), GMC_RST_CLR);\r\ngm_phy_write(hw, port, PHY_MARV_AUNE_ADV,\r\n(PHY_AN_100FULL | PHY_AN_100HALF |\r\nPHY_AN_10FULL | PHY_AN_10HALF | PHY_AN_CSMA));\r\ngm_phy_write(hw, port, PHY_MARV_1000T_CTRL, 0);\r\ngm_phy_write(hw, port, PHY_MARV_CTRL,\r\nPHY_CT_RESET | PHY_CT_SPS_LSB | PHY_CT_ANE |\r\nPHY_CT_RE_CFG | PHY_CT_DUP_MD);\r\ngma_write16(hw, port, GM_GP_CTRL,\r\nGM_GPCR_FC_TX_DIS|GM_GPCR_TX_ENA|GM_GPCR_RX_ENA|\r\nGM_GPCR_DUP_FULL|GM_GPCR_FC_RX_DIS|GM_GPCR_AU_FCT_DIS);\r\nmemcpy_toio(hw->regs + WOL_REGS(port, WOL_MAC_ADDR),\r\nskge->netdev->dev_addr, ETH_ALEN);\r\nskge_write16(hw, WOL_REGS(port, WOL_CTRL_STAT), WOL_CTL_CLEAR_RESULT);\r\nctrl = 0;\r\nif (skge->wol & WAKE_PHY)\r\nctrl |= WOL_CTL_ENA_PME_ON_LINK_CHG|WOL_CTL_ENA_LINK_CHG_UNIT;\r\nelse\r\nctrl |= WOL_CTL_DIS_PME_ON_LINK_CHG|WOL_CTL_DIS_LINK_CHG_UNIT;\r\nif (skge->wol & WAKE_MAGIC)\r\nctrl |= WOL_CTL_ENA_PME_ON_MAGIC_PKT|WOL_CTL_ENA_MAGIC_PKT_UNIT;\r\nelse\r\nctrl |= WOL_CTL_DIS_PME_ON_MAGIC_PKT|WOL_CTL_DIS_MAGIC_PKT_UNIT;\r\nctrl |= WOL_CTL_DIS_PME_ON_PATTERN|WOL_CTL_DIS_PATTERN_UNIT;\r\nskge_write16(hw, WOL_REGS(port, WOL_CTRL_STAT), ctrl);\r\nskge_write8(hw, SK_REG(port, RX_GMF_CTRL_T), GMF_RST_SET);\r\n}\r\nstatic void skge_get_wol(struct net_device *dev, struct ethtool_wolinfo *wol)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nwol->supported = wol_supported(skge->hw);\r\nwol->wolopts = skge->wol;\r\n}\r\nstatic int skge_set_wol(struct net_device *dev, struct ethtool_wolinfo *wol)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nstruct skge_hw *hw = skge->hw;\r\nif ((wol->wolopts & ~wol_supported(hw)) ||\r\n!device_can_wakeup(&hw->pdev->dev))\r\nreturn -EOPNOTSUPP;\r\nskge->wol = wol->wolopts;\r\ndevice_set_wakeup_enable(&hw->pdev->dev, skge->wol);\r\nreturn 0;\r\n}\r\nstatic u32 skge_supported_modes(const struct skge_hw *hw)\r\n{\r\nu32 supported;\r\nif (hw->copper) {\r\nsupported = (SUPPORTED_10baseT_Half |\r\nSUPPORTED_10baseT_Full |\r\nSUPPORTED_100baseT_Half |\r\nSUPPORTED_100baseT_Full |\r\nSUPPORTED_1000baseT_Half |\r\nSUPPORTED_1000baseT_Full |\r\nSUPPORTED_Autoneg |\r\nSUPPORTED_TP);\r\nif (is_genesis(hw))\r\nsupported &= ~(SUPPORTED_10baseT_Half |\r\nSUPPORTED_10baseT_Full |\r\nSUPPORTED_100baseT_Half |\r\nSUPPORTED_100baseT_Full);\r\nelse if (hw->chip_id == CHIP_ID_YUKON)\r\nsupported &= ~SUPPORTED_1000baseT_Half;\r\n} else\r\nsupported = (SUPPORTED_1000baseT_Full |\r\nSUPPORTED_1000baseT_Half |\r\nSUPPORTED_FIBRE |\r\nSUPPORTED_Autoneg);\r\nreturn supported;\r\n}\r\nstatic int skge_get_settings(struct net_device *dev,\r\nstruct ethtool_cmd *ecmd)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nstruct skge_hw *hw = skge->hw;\r\necmd->transceiver = XCVR_INTERNAL;\r\necmd->supported = skge_supported_modes(hw);\r\nif (hw->copper) {\r\necmd->port = PORT_TP;\r\necmd->phy_address = hw->phy_addr;\r\n} else\r\necmd->port = PORT_FIBRE;\r\necmd->advertising = skge->advertising;\r\necmd->autoneg = skge->autoneg;\r\nethtool_cmd_speed_set(ecmd, skge->speed);\r\necmd->duplex = skge->duplex;\r\nreturn 0;\r\n}\r\nstatic int skge_set_settings(struct net_device *dev, struct ethtool_cmd *ecmd)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nconst struct skge_hw *hw = skge->hw;\r\nu32 supported = skge_supported_modes(hw);\r\nint err = 0;\r\nif (ecmd->autoneg == AUTONEG_ENABLE) {\r\necmd->advertising = supported;\r\nskge->duplex = -1;\r\nskge->speed = -1;\r\n} else {\r\nu32 setting;\r\nu32 speed = ethtool_cmd_speed(ecmd);\r\nswitch (speed) {\r\ncase SPEED_1000:\r\nif (ecmd->duplex == DUPLEX_FULL)\r\nsetting = SUPPORTED_1000baseT_Full;\r\nelse if (ecmd->duplex == DUPLEX_HALF)\r\nsetting = SUPPORTED_1000baseT_Half;\r\nelse\r\nreturn -EINVAL;\r\nbreak;\r\ncase SPEED_100:\r\nif (ecmd->duplex == DUPLEX_FULL)\r\nsetting = SUPPORTED_100baseT_Full;\r\nelse if (ecmd->duplex == DUPLEX_HALF)\r\nsetting = SUPPORTED_100baseT_Half;\r\nelse\r\nreturn -EINVAL;\r\nbreak;\r\ncase SPEED_10:\r\nif (ecmd->duplex == DUPLEX_FULL)\r\nsetting = SUPPORTED_10baseT_Full;\r\nelse if (ecmd->duplex == DUPLEX_HALF)\r\nsetting = SUPPORTED_10baseT_Half;\r\nelse\r\nreturn -EINVAL;\r\nbreak;\r\ndefault:\r\nreturn -EINVAL;\r\n}\r\nif ((setting & supported) == 0)\r\nreturn -EINVAL;\r\nskge->speed = speed;\r\nskge->duplex = ecmd->duplex;\r\n}\r\nskge->autoneg = ecmd->autoneg;\r\nskge->advertising = ecmd->advertising;\r\nif (netif_running(dev)) {\r\nskge_down(dev);\r\nerr = skge_up(dev);\r\nif (err) {\r\ndev_close(dev);\r\nreturn err;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void skge_get_drvinfo(struct net_device *dev,\r\nstruct ethtool_drvinfo *info)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nstrlcpy(info->driver, DRV_NAME, sizeof(info->driver));\r\nstrlcpy(info->version, DRV_VERSION, sizeof(info->version));\r\nstrlcpy(info->bus_info, pci_name(skge->hw->pdev),\r\nsizeof(info->bus_info));\r\n}\r\nstatic int skge_get_sset_count(struct net_device *dev, int sset)\r\n{\r\nswitch (sset) {\r\ncase ETH_SS_STATS:\r\nreturn ARRAY_SIZE(skge_stats);\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nstatic void skge_get_ethtool_stats(struct net_device *dev,\r\nstruct ethtool_stats *stats, u64 *data)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nif (is_genesis(skge->hw))\r\ngenesis_get_stats(skge, data);\r\nelse\r\nyukon_get_stats(skge, data);\r\n}\r\nstatic struct net_device_stats *skge_get_stats(struct net_device *dev)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nu64 data[ARRAY_SIZE(skge_stats)];\r\nif (is_genesis(skge->hw))\r\ngenesis_get_stats(skge, data);\r\nelse\r\nyukon_get_stats(skge, data);\r\ndev->stats.tx_bytes = data[0];\r\ndev->stats.rx_bytes = data[1];\r\ndev->stats.tx_packets = data[2] + data[4] + data[6];\r\ndev->stats.rx_packets = data[3] + data[5] + data[7];\r\ndev->stats.multicast = data[3] + data[5];\r\ndev->stats.collisions = data[10];\r\ndev->stats.tx_aborted_errors = data[12];\r\nreturn &dev->stats;\r\n}\r\nstatic void skge_get_strings(struct net_device *dev, u32 stringset, u8 *data)\r\n{\r\nint i;\r\nswitch (stringset) {\r\ncase ETH_SS_STATS:\r\nfor (i = 0; i < ARRAY_SIZE(skge_stats); i++)\r\nmemcpy(data + i * ETH_GSTRING_LEN,\r\nskge_stats[i].name, ETH_GSTRING_LEN);\r\nbreak;\r\n}\r\n}\r\nstatic void skge_get_ring_param(struct net_device *dev,\r\nstruct ethtool_ringparam *p)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\np->rx_max_pending = MAX_RX_RING_SIZE;\r\np->tx_max_pending = MAX_TX_RING_SIZE;\r\np->rx_pending = skge->rx_ring.count;\r\np->tx_pending = skge->tx_ring.count;\r\n}\r\nstatic int skge_set_ring_param(struct net_device *dev,\r\nstruct ethtool_ringparam *p)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nint err = 0;\r\nif (p->rx_pending == 0 || p->rx_pending > MAX_RX_RING_SIZE ||\r\np->tx_pending < TX_LOW_WATER || p->tx_pending > MAX_TX_RING_SIZE)\r\nreturn -EINVAL;\r\nskge->rx_ring.count = p->rx_pending;\r\nskge->tx_ring.count = p->tx_pending;\r\nif (netif_running(dev)) {\r\nskge_down(dev);\r\nerr = skge_up(dev);\r\nif (err)\r\ndev_close(dev);\r\n}\r\nreturn err;\r\n}\r\nstatic u32 skge_get_msglevel(struct net_device *netdev)\r\n{\r\nstruct skge_port *skge = netdev_priv(netdev);\r\nreturn skge->msg_enable;\r\n}\r\nstatic void skge_set_msglevel(struct net_device *netdev, u32 value)\r\n{\r\nstruct skge_port *skge = netdev_priv(netdev);\r\nskge->msg_enable = value;\r\n}\r\nstatic int skge_nway_reset(struct net_device *dev)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nif (skge->autoneg != AUTONEG_ENABLE || !netif_running(dev))\r\nreturn -EINVAL;\r\nskge_phy_reset(skge);\r\nreturn 0;\r\n}\r\nstatic void skge_get_pauseparam(struct net_device *dev,\r\nstruct ethtool_pauseparam *ecmd)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\necmd->rx_pause = ((skge->flow_control == FLOW_MODE_SYMMETRIC) ||\r\n(skge->flow_control == FLOW_MODE_SYM_OR_REM));\r\necmd->tx_pause = (ecmd->rx_pause ||\r\n(skge->flow_control == FLOW_MODE_LOC_SEND));\r\necmd->autoneg = ecmd->rx_pause || ecmd->tx_pause;\r\n}\r\nstatic int skge_set_pauseparam(struct net_device *dev,\r\nstruct ethtool_pauseparam *ecmd)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nstruct ethtool_pauseparam old;\r\nint err = 0;\r\nskge_get_pauseparam(dev, &old);\r\nif (ecmd->autoneg != old.autoneg)\r\nskge->flow_control = ecmd->autoneg ? FLOW_MODE_NONE : FLOW_MODE_SYMMETRIC;\r\nelse {\r\nif (ecmd->rx_pause && ecmd->tx_pause)\r\nskge->flow_control = FLOW_MODE_SYMMETRIC;\r\nelse if (ecmd->rx_pause && !ecmd->tx_pause)\r\nskge->flow_control = FLOW_MODE_SYM_OR_REM;\r\nelse if (!ecmd->rx_pause && ecmd->tx_pause)\r\nskge->flow_control = FLOW_MODE_LOC_SEND;\r\nelse\r\nskge->flow_control = FLOW_MODE_NONE;\r\n}\r\nif (netif_running(dev)) {\r\nskge_down(dev);\r\nerr = skge_up(dev);\r\nif (err) {\r\ndev_close(dev);\r\nreturn err;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic inline u32 hwkhz(const struct skge_hw *hw)\r\n{\r\nreturn is_genesis(hw) ? 53125 : 78125;\r\n}\r\nstatic inline u32 skge_clk2usec(const struct skge_hw *hw, u32 ticks)\r\n{\r\nreturn (ticks * 1000) / hwkhz(hw);\r\n}\r\nstatic inline u32 skge_usecs2clk(const struct skge_hw *hw, u32 usec)\r\n{\r\nreturn hwkhz(hw) * usec / 1000;\r\n}\r\nstatic int skge_get_coalesce(struct net_device *dev,\r\nstruct ethtool_coalesce *ecmd)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\necmd->rx_coalesce_usecs = 0;\r\necmd->tx_coalesce_usecs = 0;\r\nif (skge_read32(hw, B2_IRQM_CTRL) & TIM_START) {\r\nu32 delay = skge_clk2usec(hw, skge_read32(hw, B2_IRQM_INI));\r\nu32 msk = skge_read32(hw, B2_IRQM_MSK);\r\nif (msk & rxirqmask[port])\r\necmd->rx_coalesce_usecs = delay;\r\nif (msk & txirqmask[port])\r\necmd->tx_coalesce_usecs = delay;\r\n}\r\nreturn 0;\r\n}\r\nstatic int skge_set_coalesce(struct net_device *dev,\r\nstruct ethtool_coalesce *ecmd)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nu32 msk = skge_read32(hw, B2_IRQM_MSK);\r\nu32 delay = 25;\r\nif (ecmd->rx_coalesce_usecs == 0)\r\nmsk &= ~rxirqmask[port];\r\nelse if (ecmd->rx_coalesce_usecs < 25 ||\r\necmd->rx_coalesce_usecs > 33333)\r\nreturn -EINVAL;\r\nelse {\r\nmsk |= rxirqmask[port];\r\ndelay = ecmd->rx_coalesce_usecs;\r\n}\r\nif (ecmd->tx_coalesce_usecs == 0)\r\nmsk &= ~txirqmask[port];\r\nelse if (ecmd->tx_coalesce_usecs < 25 ||\r\necmd->tx_coalesce_usecs > 33333)\r\nreturn -EINVAL;\r\nelse {\r\nmsk |= txirqmask[port];\r\ndelay = min(delay, ecmd->rx_coalesce_usecs);\r\n}\r\nskge_write32(hw, B2_IRQM_MSK, msk);\r\nif (msk == 0)\r\nskge_write32(hw, B2_IRQM_CTRL, TIM_STOP);\r\nelse {\r\nskge_write32(hw, B2_IRQM_INI, skge_usecs2clk(hw, delay));\r\nskge_write32(hw, B2_IRQM_CTRL, TIM_START);\r\n}\r\nreturn 0;\r\n}\r\nstatic void skge_led(struct skge_port *skge, enum led_mode mode)\r\n{\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nspin_lock_bh(&hw->phy_lock);\r\nif (is_genesis(hw)) {\r\nswitch (mode) {\r\ncase LED_MODE_OFF:\r\nif (hw->phy_type == SK_PHY_BCOM)\r\nxm_phy_write(hw, port, PHY_BCOM_P_EXT_CTRL, PHY_B_PEC_LED_OFF);\r\nelse {\r\nskge_write32(hw, SK_REG(port, TX_LED_VAL), 0);\r\nskge_write8(hw, SK_REG(port, TX_LED_CTRL), LED_T_OFF);\r\n}\r\nskge_write8(hw, SK_REG(port, LNK_LED_REG), LINKLED_OFF);\r\nskge_write32(hw, SK_REG(port, RX_LED_VAL), 0);\r\nskge_write8(hw, SK_REG(port, RX_LED_CTRL), LED_T_OFF);\r\nbreak;\r\ncase LED_MODE_ON:\r\nskge_write8(hw, SK_REG(port, LNK_LED_REG), LINKLED_ON);\r\nskge_write8(hw, SK_REG(port, LNK_LED_REG), LINKLED_LINKSYNC_ON);\r\nskge_write8(hw, SK_REG(port, RX_LED_CTRL), LED_START);\r\nskge_write8(hw, SK_REG(port, TX_LED_CTRL), LED_START);\r\nbreak;\r\ncase LED_MODE_TST:\r\nskge_write8(hw, SK_REG(port, RX_LED_TST), LED_T_ON);\r\nskge_write32(hw, SK_REG(port, RX_LED_VAL), 100);\r\nskge_write8(hw, SK_REG(port, RX_LED_CTRL), LED_START);\r\nif (hw->phy_type == SK_PHY_BCOM)\r\nxm_phy_write(hw, port, PHY_BCOM_P_EXT_CTRL, PHY_B_PEC_LED_ON);\r\nelse {\r\nskge_write8(hw, SK_REG(port, TX_LED_TST), LED_T_ON);\r\nskge_write32(hw, SK_REG(port, TX_LED_VAL), 100);\r\nskge_write8(hw, SK_REG(port, TX_LED_CTRL), LED_START);\r\n}\r\n}\r\n} else {\r\nswitch (mode) {\r\ncase LED_MODE_OFF:\r\ngm_phy_write(hw, port, PHY_MARV_LED_CTRL, 0);\r\ngm_phy_write(hw, port, PHY_MARV_LED_OVER,\r\nPHY_M_LED_MO_DUP(MO_LED_OFF) |\r\nPHY_M_LED_MO_10(MO_LED_OFF) |\r\nPHY_M_LED_MO_100(MO_LED_OFF) |\r\nPHY_M_LED_MO_1000(MO_LED_OFF) |\r\nPHY_M_LED_MO_RX(MO_LED_OFF));\r\nbreak;\r\ncase LED_MODE_ON:\r\ngm_phy_write(hw, port, PHY_MARV_LED_CTRL,\r\nPHY_M_LED_PULS_DUR(PULS_170MS) |\r\nPHY_M_LED_BLINK_RT(BLINK_84MS) |\r\nPHY_M_LEDC_TX_CTRL |\r\nPHY_M_LEDC_DP_CTRL);\r\ngm_phy_write(hw, port, PHY_MARV_LED_OVER,\r\nPHY_M_LED_MO_RX(MO_LED_OFF) |\r\n(skge->speed == SPEED_100 ?\r\nPHY_M_LED_MO_100(MO_LED_ON) : 0));\r\nbreak;\r\ncase LED_MODE_TST:\r\ngm_phy_write(hw, port, PHY_MARV_LED_CTRL, 0);\r\ngm_phy_write(hw, port, PHY_MARV_LED_OVER,\r\nPHY_M_LED_MO_DUP(MO_LED_ON) |\r\nPHY_M_LED_MO_10(MO_LED_ON) |\r\nPHY_M_LED_MO_100(MO_LED_ON) |\r\nPHY_M_LED_MO_1000(MO_LED_ON) |\r\nPHY_M_LED_MO_RX(MO_LED_ON));\r\n}\r\n}\r\nspin_unlock_bh(&hw->phy_lock);\r\n}\r\nstatic int skge_set_phys_id(struct net_device *dev,\r\nenum ethtool_phys_id_state state)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nswitch (state) {\r\ncase ETHTOOL_ID_ACTIVE:\r\nreturn 2;\r\ncase ETHTOOL_ID_ON:\r\nskge_led(skge, LED_MODE_TST);\r\nbreak;\r\ncase ETHTOOL_ID_OFF:\r\nskge_led(skge, LED_MODE_OFF);\r\nbreak;\r\ncase ETHTOOL_ID_INACTIVE:\r\nskge_led(skge, netif_running(dev) ? LED_MODE_ON : LED_MODE_OFF);\r\n}\r\nreturn 0;\r\n}\r\nstatic int skge_get_eeprom_len(struct net_device *dev)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nu32 reg2;\r\npci_read_config_dword(skge->hw->pdev, PCI_DEV_REG2, &reg2);\r\nreturn 1 << (((reg2 & PCI_VPD_ROM_SZ) >> 14) + 8);\r\n}\r\nstatic u32 skge_vpd_read(struct pci_dev *pdev, int cap, u16 offset)\r\n{\r\nu32 val;\r\npci_write_config_word(pdev, cap + PCI_VPD_ADDR, offset);\r\ndo {\r\npci_read_config_word(pdev, cap + PCI_VPD_ADDR, &offset);\r\n} while (!(offset & PCI_VPD_ADDR_F));\r\npci_read_config_dword(pdev, cap + PCI_VPD_DATA, &val);\r\nreturn val;\r\n}\r\nstatic void skge_vpd_write(struct pci_dev *pdev, int cap, u16 offset, u32 val)\r\n{\r\npci_write_config_dword(pdev, cap + PCI_VPD_DATA, val);\r\npci_write_config_word(pdev, cap + PCI_VPD_ADDR,\r\noffset | PCI_VPD_ADDR_F);\r\ndo {\r\npci_read_config_word(pdev, cap + PCI_VPD_ADDR, &offset);\r\n} while (offset & PCI_VPD_ADDR_F);\r\n}\r\nstatic int skge_get_eeprom(struct net_device *dev, struct ethtool_eeprom *eeprom,\r\nu8 *data)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nstruct pci_dev *pdev = skge->hw->pdev;\r\nint cap = pci_find_capability(pdev, PCI_CAP_ID_VPD);\r\nint length = eeprom->len;\r\nu16 offset = eeprom->offset;\r\nif (!cap)\r\nreturn -EINVAL;\r\neeprom->magic = SKGE_EEPROM_MAGIC;\r\nwhile (length > 0) {\r\nu32 val = skge_vpd_read(pdev, cap, offset);\r\nint n = min_t(int, length, sizeof(val));\r\nmemcpy(data, &val, n);\r\nlength -= n;\r\ndata += n;\r\noffset += n;\r\n}\r\nreturn 0;\r\n}\r\nstatic int skge_set_eeprom(struct net_device *dev, struct ethtool_eeprom *eeprom,\r\nu8 *data)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nstruct pci_dev *pdev = skge->hw->pdev;\r\nint cap = pci_find_capability(pdev, PCI_CAP_ID_VPD);\r\nint length = eeprom->len;\r\nu16 offset = eeprom->offset;\r\nif (!cap)\r\nreturn -EINVAL;\r\nif (eeprom->magic != SKGE_EEPROM_MAGIC)\r\nreturn -EINVAL;\r\nwhile (length > 0) {\r\nu32 val;\r\nint n = min_t(int, length, sizeof(val));\r\nif (n < sizeof(val))\r\nval = skge_vpd_read(pdev, cap, offset);\r\nmemcpy(&val, data, n);\r\nskge_vpd_write(pdev, cap, offset, val);\r\nlength -= n;\r\ndata += n;\r\noffset += n;\r\n}\r\nreturn 0;\r\n}\r\nstatic int skge_ring_alloc(struct skge_ring *ring, void *vaddr, u32 base)\r\n{\r\nstruct skge_tx_desc *d;\r\nstruct skge_element *e;\r\nint i;\r\nring->start = kcalloc(ring->count, sizeof(*e), GFP_KERNEL);\r\nif (!ring->start)\r\nreturn -ENOMEM;\r\nfor (i = 0, e = ring->start, d = vaddr; i < ring->count; i++, e++, d++) {\r\ne->desc = d;\r\nif (i == ring->count - 1) {\r\ne->next = ring->start;\r\nd->next_offset = base;\r\n} else {\r\ne->next = e + 1;\r\nd->next_offset = base + (i+1) * sizeof(*d);\r\n}\r\n}\r\nring->to_use = ring->to_clean = ring->start;\r\nreturn 0;\r\n}\r\nstatic int skge_rx_setup(struct skge_port *skge, struct skge_element *e,\r\nstruct sk_buff *skb, unsigned int bufsize)\r\n{\r\nstruct skge_rx_desc *rd = e->desc;\r\ndma_addr_t map;\r\nmap = pci_map_single(skge->hw->pdev, skb->data, bufsize,\r\nPCI_DMA_FROMDEVICE);\r\nif (pci_dma_mapping_error(skge->hw->pdev, map))\r\nreturn -1;\r\nrd->dma_lo = lower_32_bits(map);\r\nrd->dma_hi = upper_32_bits(map);\r\ne->skb = skb;\r\nrd->csum1_start = ETH_HLEN;\r\nrd->csum2_start = ETH_HLEN;\r\nrd->csum1 = 0;\r\nrd->csum2 = 0;\r\nwmb();\r\nrd->control = BMU_OWN | BMU_STF | BMU_IRQ_EOF | BMU_TCP_CHECK | bufsize;\r\ndma_unmap_addr_set(e, mapaddr, map);\r\ndma_unmap_len_set(e, maplen, bufsize);\r\nreturn 0;\r\n}\r\nstatic inline void skge_rx_reuse(struct skge_element *e, unsigned int size)\r\n{\r\nstruct skge_rx_desc *rd = e->desc;\r\nrd->csum2 = 0;\r\nrd->csum2_start = ETH_HLEN;\r\nwmb();\r\nrd->control = BMU_OWN | BMU_STF | BMU_IRQ_EOF | BMU_TCP_CHECK | size;\r\n}\r\nstatic void skge_rx_clean(struct skge_port *skge)\r\n{\r\nstruct skge_hw *hw = skge->hw;\r\nstruct skge_ring *ring = &skge->rx_ring;\r\nstruct skge_element *e;\r\ne = ring->start;\r\ndo {\r\nstruct skge_rx_desc *rd = e->desc;\r\nrd->control = 0;\r\nif (e->skb) {\r\npci_unmap_single(hw->pdev,\r\ndma_unmap_addr(e, mapaddr),\r\ndma_unmap_len(e, maplen),\r\nPCI_DMA_FROMDEVICE);\r\ndev_kfree_skb(e->skb);\r\ne->skb = NULL;\r\n}\r\n} while ((e = e->next) != ring->start);\r\n}\r\nstatic int skge_rx_fill(struct net_device *dev)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nstruct skge_ring *ring = &skge->rx_ring;\r\nstruct skge_element *e;\r\ne = ring->start;\r\ndo {\r\nstruct sk_buff *skb;\r\nskb = __netdev_alloc_skb(dev, skge->rx_buf_size + NET_IP_ALIGN,\r\nGFP_KERNEL);\r\nif (!skb)\r\nreturn -ENOMEM;\r\nskb_reserve(skb, NET_IP_ALIGN);\r\nif (skge_rx_setup(skge, e, skb, skge->rx_buf_size) < 0) {\r\ndev_kfree_skb(skb);\r\nreturn -EIO;\r\n}\r\n} while ((e = e->next) != ring->start);\r\nring->to_clean = ring->start;\r\nreturn 0;\r\n}\r\nstatic const char *skge_pause(enum pause_status status)\r\n{\r\nswitch (status) {\r\ncase FLOW_STAT_NONE:\r\nreturn "none";\r\ncase FLOW_STAT_REM_SEND:\r\nreturn "rx only";\r\ncase FLOW_STAT_LOC_SEND:\r\nreturn "tx_only";\r\ncase FLOW_STAT_SYMMETRIC:\r\nreturn "both";\r\ndefault:\r\nreturn "indeterminated";\r\n}\r\n}\r\nstatic void skge_link_up(struct skge_port *skge)\r\n{\r\nskge_write8(skge->hw, SK_REG(skge->port, LNK_LED_REG),\r\nLED_BLK_OFF|LED_SYNC_OFF|LED_ON);\r\nnetif_carrier_on(skge->netdev);\r\nnetif_wake_queue(skge->netdev);\r\nnetif_info(skge, link, skge->netdev,\r\n"Link is up at %d Mbps, %s duplex, flow control %s\n",\r\nskge->speed,\r\nskge->duplex == DUPLEX_FULL ? "full" : "half",\r\nskge_pause(skge->flow_status));\r\n}\r\nstatic void skge_link_down(struct skge_port *skge)\r\n{\r\nskge_write8(skge->hw, SK_REG(skge->port, LNK_LED_REG), LED_OFF);\r\nnetif_carrier_off(skge->netdev);\r\nnetif_stop_queue(skge->netdev);\r\nnetif_info(skge, link, skge->netdev, "Link is down\n");\r\n}\r\nstatic void xm_link_down(struct skge_hw *hw, int port)\r\n{\r\nstruct net_device *dev = hw->dev[port];\r\nstruct skge_port *skge = netdev_priv(dev);\r\nxm_write16(hw, port, XM_IMSK, XM_IMSK_DISABLE);\r\nif (netif_carrier_ok(dev))\r\nskge_link_down(skge);\r\n}\r\nstatic int __xm_phy_read(struct skge_hw *hw, int port, u16 reg, u16 *val)\r\n{\r\nint i;\r\nxm_write16(hw, port, XM_PHY_ADDR, reg | hw->phy_addr);\r\n*val = xm_read16(hw, port, XM_PHY_DATA);\r\nif (hw->phy_type == SK_PHY_XMAC)\r\ngoto ready;\r\nfor (i = 0; i < PHY_RETRIES; i++) {\r\nif (xm_read16(hw, port, XM_MMU_CMD) & XM_MMU_PHY_RDY)\r\ngoto ready;\r\nudelay(1);\r\n}\r\nreturn -ETIMEDOUT;\r\nready:\r\n*val = xm_read16(hw, port, XM_PHY_DATA);\r\nreturn 0;\r\n}\r\nstatic u16 xm_phy_read(struct skge_hw *hw, int port, u16 reg)\r\n{\r\nu16 v = 0;\r\nif (__xm_phy_read(hw, port, reg, &v))\r\npr_warning("%s: phy read timed out\n", hw->dev[port]->name);\r\nreturn v;\r\n}\r\nstatic int xm_phy_write(struct skge_hw *hw, int port, u16 reg, u16 val)\r\n{\r\nint i;\r\nxm_write16(hw, port, XM_PHY_ADDR, reg | hw->phy_addr);\r\nfor (i = 0; i < PHY_RETRIES; i++) {\r\nif (!(xm_read16(hw, port, XM_MMU_CMD) & XM_MMU_PHY_BUSY))\r\ngoto ready;\r\nudelay(1);\r\n}\r\nreturn -EIO;\r\nready:\r\nxm_write16(hw, port, XM_PHY_DATA, val);\r\nfor (i = 0; i < PHY_RETRIES; i++) {\r\nif (!(xm_read16(hw, port, XM_MMU_CMD) & XM_MMU_PHY_BUSY))\r\nreturn 0;\r\nudelay(1);\r\n}\r\nreturn -ETIMEDOUT;\r\n}\r\nstatic void genesis_init(struct skge_hw *hw)\r\n{\r\nskge_write32(hw, B2_BSC_INI, (SK_BLK_DUR * SK_FACT_53) / 100);\r\nskge_write8(hw, B2_BSC_CTRL, BSC_START);\r\nskge_write16(hw, B3_MA_TO_CTRL, MA_RST_CLR);\r\nskge_write8(hw, B3_MA_TOINI_RX1, SK_MAC_TO_53);\r\nskge_write8(hw, B3_MA_TOINI_RX2, SK_MAC_TO_53);\r\nskge_write8(hw, B3_MA_TOINI_TX1, SK_MAC_TO_53);\r\nskge_write8(hw, B3_MA_TOINI_TX2, SK_MAC_TO_53);\r\nskge_write8(hw, B3_MA_RCINI_RX1, 0);\r\nskge_write8(hw, B3_MA_RCINI_RX2, 0);\r\nskge_write8(hw, B3_MA_RCINI_TX1, 0);\r\nskge_write8(hw, B3_MA_RCINI_TX2, 0);\r\nskge_write16(hw, B3_PA_CTRL, PA_RST_CLR);\r\nskge_write16(hw, B3_PA_TOINI_RX1, SK_PKT_TO_MAX);\r\nskge_write16(hw, B3_PA_TOINI_TX1, SK_PKT_TO_MAX);\r\nskge_write16(hw, B3_PA_TOINI_RX2, SK_PKT_TO_MAX);\r\nskge_write16(hw, B3_PA_TOINI_TX2, SK_PKT_TO_MAX);\r\n}\r\nstatic void genesis_reset(struct skge_hw *hw, int port)\r\n{\r\nstatic const u8 zero[8] = { 0 };\r\nu32 reg;\r\nskge_write8(hw, SK_REG(port, GMAC_IRQ_MSK), 0);\r\nxm_write32(hw, port, XM_GP_PORT, XM_GP_RES_STAT);\r\nxm_write16(hw, port, XM_IMSK, XM_IMSK_DISABLE);\r\nxm_write32(hw, port, XM_MODE, 0);\r\nxm_write16(hw, port, XM_TX_CMD, 0);\r\nxm_write16(hw, port, XM_RX_CMD, 0);\r\nif (hw->phy_type == SK_PHY_BCOM)\r\nxm_write16(hw, port, PHY_BCOM_INT_MASK, 0xffff);\r\nxm_outhash(hw, port, XM_HSM, zero);\r\nreg = xm_read32(hw, port, XM_MODE);\r\nxm_write32(hw, port, XM_MODE, reg | XM_MD_FTF);\r\nxm_write32(hw, port, XM_MODE, reg | XM_MD_FRF);\r\n}\r\nstatic void bcom_check_link(struct skge_hw *hw, int port)\r\n{\r\nstruct net_device *dev = hw->dev[port];\r\nstruct skge_port *skge = netdev_priv(dev);\r\nu16 status;\r\nxm_phy_read(hw, port, PHY_BCOM_STAT);\r\nstatus = xm_phy_read(hw, port, PHY_BCOM_STAT);\r\nif ((status & PHY_ST_LSYNC) == 0) {\r\nxm_link_down(hw, port);\r\nreturn;\r\n}\r\nif (skge->autoneg == AUTONEG_ENABLE) {\r\nu16 lpa, aux;\r\nif (!(status & PHY_ST_AN_OVER))\r\nreturn;\r\nlpa = xm_phy_read(hw, port, PHY_XMAC_AUNE_LP);\r\nif (lpa & PHY_B_AN_RF) {\r\nnetdev_notice(dev, "remote fault\n");\r\nreturn;\r\n}\r\naux = xm_phy_read(hw, port, PHY_BCOM_AUX_STAT);\r\nswitch (aux & PHY_B_AS_AN_RES_MSK) {\r\ncase PHY_B_RES_1000FD:\r\nskge->duplex = DUPLEX_FULL;\r\nbreak;\r\ncase PHY_B_RES_1000HD:\r\nskge->duplex = DUPLEX_HALF;\r\nbreak;\r\ndefault:\r\nnetdev_notice(dev, "duplex mismatch\n");\r\nreturn;\r\n}\r\nswitch (aux & PHY_B_AS_PAUSE_MSK) {\r\ncase PHY_B_AS_PAUSE_MSK:\r\nskge->flow_status = FLOW_STAT_SYMMETRIC;\r\nbreak;\r\ncase PHY_B_AS_PRR:\r\nskge->flow_status = FLOW_STAT_REM_SEND;\r\nbreak;\r\ncase PHY_B_AS_PRT:\r\nskge->flow_status = FLOW_STAT_LOC_SEND;\r\nbreak;\r\ndefault:\r\nskge->flow_status = FLOW_STAT_NONE;\r\n}\r\nskge->speed = SPEED_1000;\r\n}\r\nif (!netif_carrier_ok(dev))\r\ngenesis_link_up(skge);\r\n}\r\nstatic void bcom_phy_init(struct skge_port *skge)\r\n{\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nint i;\r\nu16 id1, r, ext, ctl;\r\nstatic const struct {\r\nu16 reg;\r\nu16 val;\r\n} A1hack[] = {\r\n{ 0x18, 0x0c20 }, { 0x17, 0x0012 }, { 0x15, 0x1104 },\r\n{ 0x17, 0x0013 }, { 0x15, 0x0404 }, { 0x17, 0x8006 },\r\n{ 0x15, 0x0132 }, { 0x17, 0x8006 }, { 0x15, 0x0232 },\r\n{ 0x17, 0x800D }, { 0x15, 0x000F }, { 0x18, 0x0420 },\r\n}, C0hack[] = {\r\n{ 0x18, 0x0c20 }, { 0x17, 0x0012 }, { 0x15, 0x1204 },\r\n{ 0x17, 0x0013 }, { 0x15, 0x0A04 }, { 0x18, 0x0420 },\r\n};\r\nid1 = xm_phy_read(hw, port, PHY_XMAC_ID1);\r\nr = xm_read16(hw, port, XM_MMU_CMD);\r\nr |= XM_MMU_NO_PRE;\r\nxm_write16(hw, port, XM_MMU_CMD, r);\r\nswitch (id1) {\r\ncase PHY_BCOM_ID1_C0:\r\nfor (i = 0; i < ARRAY_SIZE(C0hack); i++)\r\nxm_phy_write(hw, port,\r\nC0hack[i].reg, C0hack[i].val);\r\nbreak;\r\ncase PHY_BCOM_ID1_A1:\r\nfor (i = 0; i < ARRAY_SIZE(A1hack); i++)\r\nxm_phy_write(hw, port,\r\nA1hack[i].reg, A1hack[i].val);\r\nbreak;\r\n}\r\nr = xm_phy_read(hw, port, PHY_BCOM_AUX_CTRL);\r\nr |= PHY_B_AC_DIS_PM;\r\nxm_phy_write(hw, port, PHY_BCOM_AUX_CTRL, r);\r\nxm_read16(hw, port, XM_ISRC);\r\next = PHY_B_PEC_EN_LTR;\r\nctl = PHY_CT_SP1000;\r\nif (skge->autoneg == AUTONEG_ENABLE) {\r\nu16 adv = PHY_B_1000C_RD;\r\nif (skge->advertising & ADVERTISED_1000baseT_Half)\r\nadv |= PHY_B_1000C_AHD;\r\nif (skge->advertising & ADVERTISED_1000baseT_Full)\r\nadv |= PHY_B_1000C_AFD;\r\nxm_phy_write(hw, port, PHY_BCOM_1000T_CTRL, adv);\r\nctl |= PHY_CT_ANE | PHY_CT_RE_CFG;\r\n} else {\r\nif (skge->duplex == DUPLEX_FULL)\r\nctl |= PHY_CT_DUP_MD;\r\nxm_phy_write(hw, port, PHY_BCOM_1000T_CTRL, PHY_B_1000C_MSE);\r\n}\r\nxm_phy_write(hw, port, PHY_BCOM_AUNE_ADV,\r\nphy_pause_map[skge->flow_control] | PHY_AN_CSMA);\r\nif (hw->dev[port]->mtu > ETH_DATA_LEN) {\r\nxm_phy_write(hw, port, PHY_BCOM_AUX_CTRL,\r\nPHY_B_AC_TX_TST | PHY_B_AC_LONG_PACK);\r\next |= PHY_B_PEC_HIGH_LA;\r\n}\r\nxm_phy_write(hw, port, PHY_BCOM_P_EXT_CTRL, ext);\r\nxm_phy_write(hw, port, PHY_BCOM_CTRL, ctl);\r\nxm_phy_write(hw, port, PHY_BCOM_INT_MASK, PHY_B_DEF_MSK);\r\n}\r\nstatic void xm_phy_init(struct skge_port *skge)\r\n{\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nu16 ctrl = 0;\r\nif (skge->autoneg == AUTONEG_ENABLE) {\r\nif (skge->advertising & ADVERTISED_1000baseT_Half)\r\nctrl |= PHY_X_AN_HD;\r\nif (skge->advertising & ADVERTISED_1000baseT_Full)\r\nctrl |= PHY_X_AN_FD;\r\nctrl |= fiber_pause_map[skge->flow_control];\r\nxm_phy_write(hw, port, PHY_XMAC_AUNE_ADV, ctrl);\r\nctrl = PHY_CT_ANE | PHY_CT_RE_CFG;\r\n} else {\r\nif (skge->duplex == DUPLEX_FULL)\r\nctrl |= PHY_CT_DUP_MD;\r\n}\r\nxm_phy_write(hw, port, PHY_XMAC_CTRL, ctrl);\r\nmod_timer(&skge->link_timer, jiffies + LINK_HZ);\r\n}\r\nstatic int xm_check_link(struct net_device *dev)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nu16 status;\r\nxm_phy_read(hw, port, PHY_XMAC_STAT);\r\nstatus = xm_phy_read(hw, port, PHY_XMAC_STAT);\r\nif ((status & PHY_ST_LSYNC) == 0) {\r\nxm_link_down(hw, port);\r\nreturn 0;\r\n}\r\nif (skge->autoneg == AUTONEG_ENABLE) {\r\nu16 lpa, res;\r\nif (!(status & PHY_ST_AN_OVER))\r\nreturn 0;\r\nlpa = xm_phy_read(hw, port, PHY_XMAC_AUNE_LP);\r\nif (lpa & PHY_B_AN_RF) {\r\nnetdev_notice(dev, "remote fault\n");\r\nreturn 0;\r\n}\r\nres = xm_phy_read(hw, port, PHY_XMAC_RES_ABI);\r\nswitch (res & (PHY_X_RS_HD | PHY_X_RS_FD)) {\r\ncase PHY_X_RS_FD:\r\nskge->duplex = DUPLEX_FULL;\r\nbreak;\r\ncase PHY_X_RS_HD:\r\nskge->duplex = DUPLEX_HALF;\r\nbreak;\r\ndefault:\r\nnetdev_notice(dev, "duplex mismatch\n");\r\nreturn 0;\r\n}\r\nif ((skge->flow_control == FLOW_MODE_SYMMETRIC ||\r\nskge->flow_control == FLOW_MODE_SYM_OR_REM) &&\r\n(lpa & PHY_X_P_SYM_MD))\r\nskge->flow_status = FLOW_STAT_SYMMETRIC;\r\nelse if (skge->flow_control == FLOW_MODE_SYM_OR_REM &&\r\n(lpa & PHY_X_RS_PAUSE) == PHY_X_P_ASYM_MD)\r\nskge->flow_status = FLOW_STAT_REM_SEND;\r\nelse if (skge->flow_control == FLOW_MODE_LOC_SEND &&\r\n(lpa & PHY_X_RS_PAUSE) == PHY_X_P_BOTH_MD)\r\nskge->flow_status = FLOW_STAT_LOC_SEND;\r\nelse\r\nskge->flow_status = FLOW_STAT_NONE;\r\nskge->speed = SPEED_1000;\r\n}\r\nif (!netif_carrier_ok(dev))\r\ngenesis_link_up(skge);\r\nreturn 1;\r\n}\r\nstatic void xm_link_timer(unsigned long arg)\r\n{\r\nstruct skge_port *skge = (struct skge_port *) arg;\r\nstruct net_device *dev = skge->netdev;\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nint i;\r\nunsigned long flags;\r\nif (!netif_running(dev))\r\nreturn;\r\nspin_lock_irqsave(&hw->phy_lock, flags);\r\nfor (i = 0; i < 3; i++) {\r\nif (xm_read16(hw, port, XM_GP_PORT) & XM_GP_INP_ASS)\r\ngoto link_down;\r\n}\r\nif (xm_check_link(dev)) {\r\nu16 msk = xm_read16(hw, port, XM_IMSK);\r\nmsk &= ~XM_IS_INP_ASS;\r\nxm_write16(hw, port, XM_IMSK, msk);\r\nxm_read16(hw, port, XM_ISRC);\r\n} else {\r\nlink_down:\r\nmod_timer(&skge->link_timer,\r\nround_jiffies(jiffies + LINK_HZ));\r\n}\r\nspin_unlock_irqrestore(&hw->phy_lock, flags);\r\n}\r\nstatic void genesis_mac_init(struct skge_hw *hw, int port)\r\n{\r\nstruct net_device *dev = hw->dev[port];\r\nstruct skge_port *skge = netdev_priv(dev);\r\nint jumbo = hw->dev[port]->mtu > ETH_DATA_LEN;\r\nint i;\r\nu32 r;\r\nstatic const u8 zero[6] = { 0 };\r\nfor (i = 0; i < 10; i++) {\r\nskge_write16(hw, SK_REG(port, TX_MFF_CTRL1),\r\nMFF_SET_MAC_RST);\r\nif (skge_read16(hw, SK_REG(port, TX_MFF_CTRL1)) & MFF_SET_MAC_RST)\r\ngoto reset_ok;\r\nudelay(1);\r\n}\r\nnetdev_warn(dev, "genesis reset failed\n");\r\nreset_ok:\r\nskge_write16(hw, SK_REG(port, TX_MFF_CTRL1), MFF_CLR_MAC_RST);\r\nif (hw->phy_type != SK_PHY_XMAC) {\r\nr = skge_read32(hw, B2_GP_IO);\r\nif (port == 0)\r\nr |= GP_DIR_0|GP_IO_0;\r\nelse\r\nr |= GP_DIR_2|GP_IO_2;\r\nskge_write32(hw, B2_GP_IO, r);\r\nxm_write16(hw, port, XM_HW_CFG, XM_HW_GMII_MD);\r\n}\r\nswitch (hw->phy_type) {\r\ncase SK_PHY_XMAC:\r\nxm_phy_init(skge);\r\nbreak;\r\ncase SK_PHY_BCOM:\r\nbcom_phy_init(skge);\r\nbcom_check_link(hw, port);\r\n}\r\nxm_outaddr(hw, port, XM_SA, dev->dev_addr);\r\nfor (i = 1; i < 16; i++)\r\nxm_outaddr(hw, port, XM_EXM(i), zero);\r\nxm_write16(hw, port, XM_STAT_CMD,\r\nXM_SC_CLR_RXC | XM_SC_CLR_TXC);\r\nxm_write16(hw, port, XM_STAT_CMD,\r\nXM_SC_CLR_RXC | XM_SC_CLR_TXC);\r\nxm_write16(hw, port, XM_RX_HI_WM, 1450);\r\nr = XM_RX_LENERR_OK | XM_RX_STRIP_FCS;\r\nif (jumbo)\r\nr |= XM_RX_BIG_PK_OK;\r\nif (skge->duplex == DUPLEX_HALF) {\r\nr |= XM_RX_DIS_CEXT;\r\n}\r\nxm_write16(hw, port, XM_RX_CMD, r);\r\nxm_write16(hw, port, XM_TX_CMD, XM_TX_AUTO_PAD);\r\nif (hw->ports > 1 && jumbo)\r\nxm_write16(hw, port, XM_TX_THR, 1020);\r\nelse\r\nxm_write16(hw, port, XM_TX_THR, 512);\r\nxm_write32(hw, port, XM_MODE, XM_DEF_MODE);\r\nxm_write32(hw, port, XM_RX_EV_MSK, XMR_DEF_MSK);\r\nxm_write32(hw, port, XM_TX_EV_MSK, XMT_DEF_MSK);\r\nskge_write16(hw, B3_MA_TO_CTRL, MA_RST_CLR);\r\nskge_write8(hw, B3_MA_TOINI_RX1, 72);\r\nskge_write8(hw, B3_MA_TOINI_RX2, 72);\r\nskge_write8(hw, B3_MA_TOINI_TX1, 72);\r\nskge_write8(hw, B3_MA_TOINI_TX2, 72);\r\nskge_write8(hw, B3_MA_RCINI_RX1, 0);\r\nskge_write8(hw, B3_MA_RCINI_RX2, 0);\r\nskge_write8(hw, B3_MA_RCINI_TX1, 0);\r\nskge_write8(hw, B3_MA_RCINI_TX2, 0);\r\nskge_write8(hw, SK_REG(port, RX_MFF_CTRL2), MFF_RST_CLR);\r\nskge_write16(hw, SK_REG(port, RX_MFF_CTRL1), MFF_ENA_TIM_PAT);\r\nskge_write8(hw, SK_REG(port, RX_MFF_CTRL2), MFF_ENA_OP_MD);\r\nskge_write8(hw, SK_REG(port, TX_MFF_CTRL2), MFF_RST_CLR);\r\nskge_write16(hw, SK_REG(port, TX_MFF_CTRL1), MFF_TX_CTRL_DEF);\r\nskge_write8(hw, SK_REG(port, TX_MFF_CTRL2), MFF_ENA_OP_MD);\r\nif (jumbo) {\r\nskge_write16(hw, SK_REG(port, RX_MFF_CTRL1), MFF_ENA_FLUSH);\r\n} else {\r\nskge_write16(hw, B3_PA_CTRL,\r\n(port == 0) ? PA_ENA_TO_TX1 : PA_ENA_TO_TX2);\r\n}\r\n}\r\nstatic void genesis_stop(struct skge_port *skge)\r\n{\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nunsigned retries = 1000;\r\nu16 cmd;\r\ncmd = xm_read16(hw, port, XM_MMU_CMD);\r\ncmd &= ~(XM_MMU_ENA_RX | XM_MMU_ENA_TX);\r\nxm_write16(hw, port, XM_MMU_CMD, cmd);\r\ngenesis_reset(hw, port);\r\nskge_write16(hw, B3_PA_CTRL,\r\nport == 0 ? PA_CLR_TO_TX1 : PA_CLR_TO_TX2);\r\nskge_write16(hw, SK_REG(port, TX_MFF_CTRL1), MFF_CLR_MAC_RST);\r\ndo {\r\nskge_write16(hw, SK_REG(port, TX_MFF_CTRL1), MFF_SET_MAC_RST);\r\nif (!(skge_read16(hw, SK_REG(port, TX_MFF_CTRL1)) & MFF_SET_MAC_RST))\r\nbreak;\r\n} while (--retries > 0);\r\nif (hw->phy_type != SK_PHY_XMAC) {\r\nu32 reg = skge_read32(hw, B2_GP_IO);\r\nif (port == 0) {\r\nreg |= GP_DIR_0;\r\nreg &= ~GP_IO_0;\r\n} else {\r\nreg |= GP_DIR_2;\r\nreg &= ~GP_IO_2;\r\n}\r\nskge_write32(hw, B2_GP_IO, reg);\r\nskge_read32(hw, B2_GP_IO);\r\n}\r\nxm_write16(hw, port, XM_MMU_CMD,\r\nxm_read16(hw, port, XM_MMU_CMD)\r\n& ~(XM_MMU_ENA_RX | XM_MMU_ENA_TX));\r\nxm_read16(hw, port, XM_MMU_CMD);\r\n}\r\nstatic void genesis_get_stats(struct skge_port *skge, u64 *data)\r\n{\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nint i;\r\nunsigned long timeout = jiffies + HZ;\r\nxm_write16(hw, port,\r\nXM_STAT_CMD, XM_SC_SNP_TXC | XM_SC_SNP_RXC);\r\nwhile (xm_read16(hw, port, XM_STAT_CMD)\r\n& (XM_SC_SNP_TXC | XM_SC_SNP_RXC)) {\r\nif (time_after(jiffies, timeout))\r\nbreak;\r\nudelay(10);\r\n}\r\ndata[0] = (u64) xm_read32(hw, port, XM_TXO_OK_HI) << 32\r\n| xm_read32(hw, port, XM_TXO_OK_LO);\r\ndata[1] = (u64) xm_read32(hw, port, XM_RXO_OK_HI) << 32\r\n| xm_read32(hw, port, XM_RXO_OK_LO);\r\nfor (i = 2; i < ARRAY_SIZE(skge_stats); i++)\r\ndata[i] = xm_read32(hw, port, skge_stats[i].xmac_offset);\r\n}\r\nstatic void genesis_mac_intr(struct skge_hw *hw, int port)\r\n{\r\nstruct net_device *dev = hw->dev[port];\r\nstruct skge_port *skge = netdev_priv(dev);\r\nu16 status = xm_read16(hw, port, XM_ISRC);\r\nnetif_printk(skge, intr, KERN_DEBUG, skge->netdev,\r\n"mac interrupt status 0x%x\n", status);\r\nif (hw->phy_type == SK_PHY_XMAC && (status & XM_IS_INP_ASS)) {\r\nxm_link_down(hw, port);\r\nmod_timer(&skge->link_timer, jiffies + 1);\r\n}\r\nif (status & XM_IS_TXF_UR) {\r\nxm_write32(hw, port, XM_MODE, XM_MD_FTF);\r\n++dev->stats.tx_fifo_errors;\r\n}\r\n}\r\nstatic void genesis_link_up(struct skge_port *skge)\r\n{\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nu16 cmd, msk;\r\nu32 mode;\r\ncmd = xm_read16(hw, port, XM_MMU_CMD);\r\nif (skge->flow_status == FLOW_STAT_NONE ||\r\nskge->flow_status == FLOW_STAT_LOC_SEND)\r\ncmd |= XM_MMU_IGN_PF;\r\nelse\r\ncmd &= ~XM_MMU_IGN_PF;\r\nxm_write16(hw, port, XM_MMU_CMD, cmd);\r\nmode = xm_read32(hw, port, XM_MODE);\r\nif (skge->flow_status == FLOW_STAT_SYMMETRIC ||\r\nskge->flow_status == FLOW_STAT_LOC_SEND) {\r\nxm_write16(hw, port, XM_MAC_PTIME, 0xffff);\r\nmode |= XM_PAUSE_MODE;\r\nskge_write16(hw, SK_REG(port, RX_MFF_CTRL1), MFF_ENA_PAUSE);\r\n} else {\r\nmode &= ~XM_PAUSE_MODE;\r\nskge_write16(hw, SK_REG(port, RX_MFF_CTRL1), MFF_DIS_PAUSE);\r\n}\r\nxm_write32(hw, port, XM_MODE, mode);\r\nmsk = xm_read16(hw, port, XM_IMSK);\r\nmsk &= ~XM_IS_TXF_UR;\r\nxm_write16(hw, port, XM_IMSK, msk);\r\nxm_read16(hw, port, XM_ISRC);\r\ncmd = xm_read16(hw, port, XM_MMU_CMD);\r\nif (hw->phy_type != SK_PHY_XMAC && skge->duplex == DUPLEX_FULL)\r\ncmd |= XM_MMU_GMII_FD;\r\nif (hw->phy_type == SK_PHY_BCOM) {\r\nxm_phy_write(hw, port, PHY_BCOM_AUX_CTRL,\r\nxm_phy_read(hw, port, PHY_BCOM_AUX_CTRL)\r\n& ~PHY_B_AC_DIS_PM);\r\nxm_phy_write(hw, port, PHY_BCOM_INT_MASK, PHY_B_DEF_MSK);\r\n}\r\nxm_write16(hw, port, XM_MMU_CMD,\r\ncmd | XM_MMU_ENA_RX | XM_MMU_ENA_TX);\r\nskge_link_up(skge);\r\n}\r\nstatic inline void bcom_phy_intr(struct skge_port *skge)\r\n{\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nu16 isrc;\r\nisrc = xm_phy_read(hw, port, PHY_BCOM_INT_STAT);\r\nnetif_printk(skge, intr, KERN_DEBUG, skge->netdev,\r\n"phy interrupt status 0x%x\n", isrc);\r\nif (isrc & PHY_B_IS_PSE)\r\npr_err("%s: uncorrectable pair swap error\n",\r\nhw->dev[port]->name);\r\nif (isrc & PHY_B_IS_NO_HDCL) {\r\nu16 ctrl = xm_phy_read(hw, port, PHY_BCOM_CTRL);\r\nxm_phy_write(hw, port, PHY_BCOM_CTRL,\r\nctrl | PHY_CT_LOOP);\r\nxm_phy_write(hw, port, PHY_BCOM_CTRL,\r\nctrl & ~PHY_CT_LOOP);\r\n}\r\nif (isrc & (PHY_B_IS_AN_PR | PHY_B_IS_LST_CHANGE))\r\nbcom_check_link(hw, port);\r\n}\r\nstatic int gm_phy_write(struct skge_hw *hw, int port, u16 reg, u16 val)\r\n{\r\nint i;\r\ngma_write16(hw, port, GM_SMI_DATA, val);\r\ngma_write16(hw, port, GM_SMI_CTRL,\r\nGM_SMI_CT_PHY_AD(hw->phy_addr) | GM_SMI_CT_REG_AD(reg));\r\nfor (i = 0; i < PHY_RETRIES; i++) {\r\nudelay(1);\r\nif (!(gma_read16(hw, port, GM_SMI_CTRL) & GM_SMI_CT_BUSY))\r\nreturn 0;\r\n}\r\npr_warning("%s: phy write timeout\n", hw->dev[port]->name);\r\nreturn -EIO;\r\n}\r\nstatic int __gm_phy_read(struct skge_hw *hw, int port, u16 reg, u16 *val)\r\n{\r\nint i;\r\ngma_write16(hw, port, GM_SMI_CTRL,\r\nGM_SMI_CT_PHY_AD(hw->phy_addr)\r\n| GM_SMI_CT_REG_AD(reg) | GM_SMI_CT_OP_RD);\r\nfor (i = 0; i < PHY_RETRIES; i++) {\r\nudelay(1);\r\nif (gma_read16(hw, port, GM_SMI_CTRL) & GM_SMI_CT_RD_VAL)\r\ngoto ready;\r\n}\r\nreturn -ETIMEDOUT;\r\nready:\r\n*val = gma_read16(hw, port, GM_SMI_DATA);\r\nreturn 0;\r\n}\r\nstatic u16 gm_phy_read(struct skge_hw *hw, int port, u16 reg)\r\n{\r\nu16 v = 0;\r\nif (__gm_phy_read(hw, port, reg, &v))\r\npr_warning("%s: phy read timeout\n", hw->dev[port]->name);\r\nreturn v;\r\n}\r\nstatic void yukon_init(struct skge_hw *hw, int port)\r\n{\r\nstruct skge_port *skge = netdev_priv(hw->dev[port]);\r\nu16 ctrl, ct1000, adv;\r\nif (skge->autoneg == AUTONEG_ENABLE) {\r\nu16 ectrl = gm_phy_read(hw, port, PHY_MARV_EXT_CTRL);\r\nectrl &= ~(PHY_M_EC_M_DSC_MSK | PHY_M_EC_S_DSC_MSK |\r\nPHY_M_EC_MAC_S_MSK);\r\nectrl |= PHY_M_EC_MAC_S(MAC_TX_CLK_25_MHZ);\r\nectrl |= PHY_M_EC_M_DSC(0) | PHY_M_EC_S_DSC(1);\r\ngm_phy_write(hw, port, PHY_MARV_EXT_CTRL, ectrl);\r\n}\r\nctrl = gm_phy_read(hw, port, PHY_MARV_CTRL);\r\nif (skge->autoneg == AUTONEG_DISABLE)\r\nctrl &= ~PHY_CT_ANE;\r\nctrl |= PHY_CT_RESET;\r\ngm_phy_write(hw, port, PHY_MARV_CTRL, ctrl);\r\nctrl = 0;\r\nct1000 = 0;\r\nadv = PHY_AN_CSMA;\r\nif (skge->autoneg == AUTONEG_ENABLE) {\r\nif (hw->copper) {\r\nif (skge->advertising & ADVERTISED_1000baseT_Full)\r\nct1000 |= PHY_M_1000C_AFD;\r\nif (skge->advertising & ADVERTISED_1000baseT_Half)\r\nct1000 |= PHY_M_1000C_AHD;\r\nif (skge->advertising & ADVERTISED_100baseT_Full)\r\nadv |= PHY_M_AN_100_FD;\r\nif (skge->advertising & ADVERTISED_100baseT_Half)\r\nadv |= PHY_M_AN_100_HD;\r\nif (skge->advertising & ADVERTISED_10baseT_Full)\r\nadv |= PHY_M_AN_10_FD;\r\nif (skge->advertising & ADVERTISED_10baseT_Half)\r\nadv |= PHY_M_AN_10_HD;\r\nadv |= phy_pause_map[skge->flow_control];\r\n} else {\r\nif (skge->advertising & ADVERTISED_1000baseT_Full)\r\nadv |= PHY_M_AN_1000X_AFD;\r\nif (skge->advertising & ADVERTISED_1000baseT_Half)\r\nadv |= PHY_M_AN_1000X_AHD;\r\nadv |= fiber_pause_map[skge->flow_control];\r\n}\r\nctrl |= PHY_CT_ANE | PHY_CT_RE_CFG;\r\n} else {\r\nct1000 = PHY_M_1000C_MSE;\r\nif (skge->duplex == DUPLEX_FULL)\r\nctrl |= PHY_CT_DUP_MD;\r\nswitch (skge->speed) {\r\ncase SPEED_1000:\r\nctrl |= PHY_CT_SP1000;\r\nbreak;\r\ncase SPEED_100:\r\nctrl |= PHY_CT_SP100;\r\nbreak;\r\n}\r\nctrl |= PHY_CT_RESET;\r\n}\r\ngm_phy_write(hw, port, PHY_MARV_1000T_CTRL, ct1000);\r\ngm_phy_write(hw, port, PHY_MARV_AUNE_ADV, adv);\r\ngm_phy_write(hw, port, PHY_MARV_CTRL, ctrl);\r\nif (skge->autoneg == AUTONEG_ENABLE)\r\ngm_phy_write(hw, port, PHY_MARV_INT_MASK, PHY_M_IS_AN_MSK);\r\nelse\r\ngm_phy_write(hw, port, PHY_MARV_INT_MASK, PHY_M_IS_DEF_MSK);\r\n}\r\nstatic void yukon_reset(struct skge_hw *hw, int port)\r\n{\r\ngm_phy_write(hw, port, PHY_MARV_INT_MASK, 0);\r\ngma_write16(hw, port, GM_MC_ADDR_H1, 0);\r\ngma_write16(hw, port, GM_MC_ADDR_H2, 0);\r\ngma_write16(hw, port, GM_MC_ADDR_H3, 0);\r\ngma_write16(hw, port, GM_MC_ADDR_H4, 0);\r\ngma_write16(hw, port, GM_RX_CTRL,\r\ngma_read16(hw, port, GM_RX_CTRL)\r\n| GM_RXCR_UCF_ENA | GM_RXCR_MCF_ENA);\r\n}\r\nstatic int is_yukon_lite_a0(struct skge_hw *hw)\r\n{\r\nu32 reg;\r\nint ret;\r\nif (hw->chip_id != CHIP_ID_YUKON)\r\nreturn 0;\r\nreg = skge_read32(hw, B2_FAR);\r\nskge_write8(hw, B2_FAR + 3, 0xff);\r\nret = (skge_read8(hw, B2_FAR + 3) != 0);\r\nskge_write32(hw, B2_FAR, reg);\r\nreturn ret;\r\n}\r\nstatic void yukon_mac_init(struct skge_hw *hw, int port)\r\n{\r\nstruct skge_port *skge = netdev_priv(hw->dev[port]);\r\nint i;\r\nu32 reg;\r\nconst u8 *addr = hw->dev[port]->dev_addr;\r\nif (hw->chip_id == CHIP_ID_YUKON_LITE &&\r\nhw->chip_rev >= CHIP_REV_YU_LITE_A3) {\r\nreg = skge_read32(hw, B2_GP_IO);\r\nreg |= GP_DIR_9 | GP_IO_9;\r\nskge_write32(hw, B2_GP_IO, reg);\r\n}\r\nskge_write32(hw, SK_REG(port, GPHY_CTRL), GPC_RST_SET);\r\nskge_write32(hw, SK_REG(port, GMAC_CTRL), GMC_RST_SET);\r\nif (hw->chip_id == CHIP_ID_YUKON_LITE &&\r\nhw->chip_rev >= CHIP_REV_YU_LITE_A3) {\r\nreg = skge_read32(hw, B2_GP_IO);\r\nreg |= GP_DIR_9;\r\nreg &= ~GP_IO_9;\r\nskge_write32(hw, B2_GP_IO, reg);\r\n}\r\nreg = GPC_INT_POL_HI | GPC_DIS_FC | GPC_DIS_SLEEP |\r\nGPC_ENA_XC | GPC_ANEG_ADV_ALL_M | GPC_ENA_PAUSE;\r\nreg |= hw->copper ? GPC_HWCFG_GMII_COP : GPC_HWCFG_GMII_FIB;\r\nskge_write32(hw, SK_REG(port, GPHY_CTRL), reg | GPC_RST_SET);\r\nskge_write32(hw, SK_REG(port, GPHY_CTRL), reg | GPC_RST_CLR);\r\nskge_write32(hw, SK_REG(port, GMAC_CTRL), GMC_PAUSE_ON | GMC_RST_CLR);\r\nif (skge->autoneg == AUTONEG_DISABLE) {\r\nreg = GM_GPCR_AU_ALL_DIS;\r\ngma_write16(hw, port, GM_GP_CTRL,\r\ngma_read16(hw, port, GM_GP_CTRL) | reg);\r\nswitch (skge->speed) {\r\ncase SPEED_1000:\r\nreg &= ~GM_GPCR_SPEED_100;\r\nreg |= GM_GPCR_SPEED_1000;\r\nbreak;\r\ncase SPEED_100:\r\nreg &= ~GM_GPCR_SPEED_1000;\r\nreg |= GM_GPCR_SPEED_100;\r\nbreak;\r\ncase SPEED_10:\r\nreg &= ~(GM_GPCR_SPEED_1000 | GM_GPCR_SPEED_100);\r\nbreak;\r\n}\r\nif (skge->duplex == DUPLEX_FULL)\r\nreg |= GM_GPCR_DUP_FULL;\r\n} else\r\nreg = GM_GPCR_SPEED_1000 | GM_GPCR_SPEED_100 | GM_GPCR_DUP_FULL;\r\nswitch (skge->flow_control) {\r\ncase FLOW_MODE_NONE:\r\nskge_write32(hw, SK_REG(port, GMAC_CTRL), GMC_PAUSE_OFF);\r\nreg |= GM_GPCR_FC_TX_DIS | GM_GPCR_FC_RX_DIS | GM_GPCR_AU_FCT_DIS;\r\nbreak;\r\ncase FLOW_MODE_LOC_SEND:\r\nreg |= GM_GPCR_FC_RX_DIS | GM_GPCR_AU_FCT_DIS;\r\nbreak;\r\ncase FLOW_MODE_SYMMETRIC:\r\ncase FLOW_MODE_SYM_OR_REM:\r\nbreak;\r\n}\r\ngma_write16(hw, port, GM_GP_CTRL, reg);\r\nskge_read16(hw, SK_REG(port, GMAC_IRQ_SRC));\r\nyukon_init(hw, port);\r\nreg = gma_read16(hw, port, GM_PHY_ADDR);\r\ngma_write16(hw, port, GM_PHY_ADDR, reg | GM_PAR_MIB_CLR);\r\nfor (i = 0; i < GM_MIB_CNT_SIZE; i++)\r\ngma_read16(hw, port, GM_MIB_CNT_BASE + 8*i);\r\ngma_write16(hw, port, GM_PHY_ADDR, reg);\r\ngma_write16(hw, port, GM_TX_CTRL, TX_COL_THR(TX_COL_DEF));\r\ngma_write16(hw, port, GM_RX_CTRL,\r\nGM_RXCR_UCF_ENA | GM_RXCR_CRC_DIS | GM_RXCR_MCF_ENA);\r\ngma_write16(hw, port, GM_TX_FLOW_CTRL, 0xffff);\r\ngma_write16(hw, port, GM_TX_PARAM,\r\nTX_JAM_LEN_VAL(TX_JAM_LEN_DEF) |\r\nTX_JAM_IPG_VAL(TX_JAM_IPG_DEF) |\r\nTX_IPG_JAM_DATA(TX_IPG_JAM_DEF));\r\nreg = DATA_BLIND_VAL(DATA_BLIND_DEF)\r\n| GM_SMOD_VLAN_ENA\r\n| IPG_DATA_VAL(IPG_DATA_DEF);\r\nif (hw->dev[port]->mtu > ETH_DATA_LEN)\r\nreg |= GM_SMOD_JUMBO_ENA;\r\ngma_write16(hw, port, GM_SERIAL_MODE, reg);\r\ngma_set_addr(hw, port, GM_SRC_ADDR_1L, addr);\r\ngma_set_addr(hw, port, GM_SRC_ADDR_2L, addr);\r\ngma_write16(hw, port, GM_TX_IRQ_MSK, 0);\r\ngma_write16(hw, port, GM_RX_IRQ_MSK, 0);\r\ngma_write16(hw, port, GM_TR_IRQ_MSK, 0);\r\nskge_write16(hw, SK_REG(port, RX_GMF_FL_MSK), RX_FF_FL_DEF_MSK);\r\nreg = GMF_OPER_ON | GMF_RX_F_FL_ON;\r\nif (is_yukon_lite_a0(hw))\r\nreg &= ~GMF_RX_F_FL_ON;\r\nskge_write8(hw, SK_REG(port, RX_GMF_CTRL_T), GMF_RST_CLR);\r\nskge_write16(hw, SK_REG(port, RX_GMF_CTRL_T), reg);\r\nskge_write16(hw, SK_REG(port, RX_GMF_FL_THR), RX_GMF_FL_THR_DEF+1);\r\nskge_write8(hw, SK_REG(port, TX_GMF_CTRL_T), GMF_RST_CLR);\r\nskge_write16(hw, SK_REG(port, TX_GMF_CTRL_T), GMF_OPER_ON);\r\n}\r\nstatic void yukon_suspend(struct skge_hw *hw, int port)\r\n{\r\nu16 ctrl;\r\nctrl = gm_phy_read(hw, port, PHY_MARV_PHY_CTRL);\r\nctrl |= PHY_M_PC_POL_R_DIS;\r\ngm_phy_write(hw, port, PHY_MARV_PHY_CTRL, ctrl);\r\nctrl = gm_phy_read(hw, port, PHY_MARV_CTRL);\r\nctrl |= PHY_CT_RESET;\r\ngm_phy_write(hw, port, PHY_MARV_CTRL, ctrl);\r\nctrl = gm_phy_read(hw, port, PHY_MARV_CTRL);\r\nctrl |= PHY_CT_PDOWN;\r\ngm_phy_write(hw, port, PHY_MARV_CTRL, ctrl);\r\n}\r\nstatic void yukon_stop(struct skge_port *skge)\r\n{\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nskge_write8(hw, SK_REG(port, GMAC_IRQ_MSK), 0);\r\nyukon_reset(hw, port);\r\ngma_write16(hw, port, GM_GP_CTRL,\r\ngma_read16(hw, port, GM_GP_CTRL)\r\n& ~(GM_GPCR_TX_ENA|GM_GPCR_RX_ENA));\r\ngma_read16(hw, port, GM_GP_CTRL);\r\nyukon_suspend(hw, port);\r\nskge_write8(hw, SK_REG(port, GPHY_CTRL), GPC_RST_SET);\r\nskge_write8(hw, SK_REG(port, GMAC_CTRL), GMC_RST_SET);\r\n}\r\nstatic void yukon_get_stats(struct skge_port *skge, u64 *data)\r\n{\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nint i;\r\ndata[0] = (u64) gma_read32(hw, port, GM_TXO_OK_HI) << 32\r\n| gma_read32(hw, port, GM_TXO_OK_LO);\r\ndata[1] = (u64) gma_read32(hw, port, GM_RXO_OK_HI) << 32\r\n| gma_read32(hw, port, GM_RXO_OK_LO);\r\nfor (i = 2; i < ARRAY_SIZE(skge_stats); i++)\r\ndata[i] = gma_read32(hw, port,\r\nskge_stats[i].gma_offset);\r\n}\r\nstatic void yukon_mac_intr(struct skge_hw *hw, int port)\r\n{\r\nstruct net_device *dev = hw->dev[port];\r\nstruct skge_port *skge = netdev_priv(dev);\r\nu8 status = skge_read8(hw, SK_REG(port, GMAC_IRQ_SRC));\r\nnetif_printk(skge, intr, KERN_DEBUG, skge->netdev,\r\n"mac interrupt status 0x%x\n", status);\r\nif (status & GM_IS_RX_FF_OR) {\r\n++dev->stats.rx_fifo_errors;\r\nskge_write8(hw, SK_REG(port, RX_GMF_CTRL_T), GMF_CLI_RX_FO);\r\n}\r\nif (status & GM_IS_TX_FF_UR) {\r\n++dev->stats.tx_fifo_errors;\r\nskge_write8(hw, SK_REG(port, TX_GMF_CTRL_T), GMF_CLI_TX_FU);\r\n}\r\n}\r\nstatic u16 yukon_speed(const struct skge_hw *hw, u16 aux)\r\n{\r\nswitch (aux & PHY_M_PS_SPEED_MSK) {\r\ncase PHY_M_PS_SPEED_1000:\r\nreturn SPEED_1000;\r\ncase PHY_M_PS_SPEED_100:\r\nreturn SPEED_100;\r\ndefault:\r\nreturn SPEED_10;\r\n}\r\n}\r\nstatic void yukon_link_up(struct skge_port *skge)\r\n{\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nu16 reg;\r\nskge_write8(hw, SK_REG(port, GMAC_IRQ_MSK), GMAC_DEF_MSK);\r\nreg = gma_read16(hw, port, GM_GP_CTRL);\r\nif (skge->duplex == DUPLEX_FULL || skge->autoneg == AUTONEG_ENABLE)\r\nreg |= GM_GPCR_DUP_FULL;\r\nreg |= GM_GPCR_RX_ENA | GM_GPCR_TX_ENA;\r\ngma_write16(hw, port, GM_GP_CTRL, reg);\r\ngm_phy_write(hw, port, PHY_MARV_INT_MASK, PHY_M_IS_DEF_MSK);\r\nskge_link_up(skge);\r\n}\r\nstatic void yukon_link_down(struct skge_port *skge)\r\n{\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nu16 ctrl;\r\nctrl = gma_read16(hw, port, GM_GP_CTRL);\r\nctrl &= ~(GM_GPCR_RX_ENA | GM_GPCR_TX_ENA);\r\ngma_write16(hw, port, GM_GP_CTRL, ctrl);\r\nif (skge->flow_status == FLOW_STAT_REM_SEND) {\r\nctrl = gm_phy_read(hw, port, PHY_MARV_AUNE_ADV);\r\nctrl |= PHY_M_AN_ASP;\r\ngm_phy_write(hw, port, PHY_MARV_AUNE_ADV, ctrl);\r\n}\r\nskge_link_down(skge);\r\nyukon_init(hw, port);\r\n}\r\nstatic void yukon_phy_intr(struct skge_port *skge)\r\n{\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nconst char *reason = NULL;\r\nu16 istatus, phystat;\r\nistatus = gm_phy_read(hw, port, PHY_MARV_INT_STAT);\r\nphystat = gm_phy_read(hw, port, PHY_MARV_PHY_STAT);\r\nnetif_printk(skge, intr, KERN_DEBUG, skge->netdev,\r\n"phy interrupt status 0x%x 0x%x\n", istatus, phystat);\r\nif (istatus & PHY_M_IS_AN_COMPL) {\r\nif (gm_phy_read(hw, port, PHY_MARV_AUNE_LP)\r\n& PHY_M_AN_RF) {\r\nreason = "remote fault";\r\ngoto failed;\r\n}\r\nif (gm_phy_read(hw, port, PHY_MARV_1000T_STAT) & PHY_B_1000S_MSF) {\r\nreason = "master/slave fault";\r\ngoto failed;\r\n}\r\nif (!(phystat & PHY_M_PS_SPDUP_RES)) {\r\nreason = "speed/duplex";\r\ngoto failed;\r\n}\r\nskge->duplex = (phystat & PHY_M_PS_FULL_DUP)\r\n? DUPLEX_FULL : DUPLEX_HALF;\r\nskge->speed = yukon_speed(hw, phystat);\r\nswitch (phystat & PHY_M_PS_PAUSE_MSK) {\r\ncase PHY_M_PS_PAUSE_MSK:\r\nskge->flow_status = FLOW_STAT_SYMMETRIC;\r\nbreak;\r\ncase PHY_M_PS_RX_P_EN:\r\nskge->flow_status = FLOW_STAT_REM_SEND;\r\nbreak;\r\ncase PHY_M_PS_TX_P_EN:\r\nskge->flow_status = FLOW_STAT_LOC_SEND;\r\nbreak;\r\ndefault:\r\nskge->flow_status = FLOW_STAT_NONE;\r\n}\r\nif (skge->flow_status == FLOW_STAT_NONE ||\r\n(skge->speed < SPEED_1000 && skge->duplex == DUPLEX_HALF))\r\nskge_write8(hw, SK_REG(port, GMAC_CTRL), GMC_PAUSE_OFF);\r\nelse\r\nskge_write8(hw, SK_REG(port, GMAC_CTRL), GMC_PAUSE_ON);\r\nyukon_link_up(skge);\r\nreturn;\r\n}\r\nif (istatus & PHY_M_IS_LSP_CHANGE)\r\nskge->speed = yukon_speed(hw, phystat);\r\nif (istatus & PHY_M_IS_DUP_CHANGE)\r\nskge->duplex = (phystat & PHY_M_PS_FULL_DUP) ? DUPLEX_FULL : DUPLEX_HALF;\r\nif (istatus & PHY_M_IS_LST_CHANGE) {\r\nif (phystat & PHY_M_PS_LINK_UP)\r\nyukon_link_up(skge);\r\nelse\r\nyukon_link_down(skge);\r\n}\r\nreturn;\r\nfailed:\r\npr_err("%s: autonegotiation failed (%s)\n", skge->netdev->name, reason);\r\n}\r\nstatic void skge_phy_reset(struct skge_port *skge)\r\n{\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nstruct net_device *dev = hw->dev[port];\r\nnetif_stop_queue(skge->netdev);\r\nnetif_carrier_off(skge->netdev);\r\nspin_lock_bh(&hw->phy_lock);\r\nif (is_genesis(hw)) {\r\ngenesis_reset(hw, port);\r\ngenesis_mac_init(hw, port);\r\n} else {\r\nyukon_reset(hw, port);\r\nyukon_init(hw, port);\r\n}\r\nspin_unlock_bh(&hw->phy_lock);\r\nskge_set_multicast(dev);\r\n}\r\nstatic int skge_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)\r\n{\r\nstruct mii_ioctl_data *data = if_mii(ifr);\r\nstruct skge_port *skge = netdev_priv(dev);\r\nstruct skge_hw *hw = skge->hw;\r\nint err = -EOPNOTSUPP;\r\nif (!netif_running(dev))\r\nreturn -ENODEV;\r\nswitch (cmd) {\r\ncase SIOCGMIIPHY:\r\ndata->phy_id = hw->phy_addr;\r\ncase SIOCGMIIREG: {\r\nu16 val = 0;\r\nspin_lock_bh(&hw->phy_lock);\r\nif (is_genesis(hw))\r\nerr = __xm_phy_read(hw, skge->port, data->reg_num & 0x1f, &val);\r\nelse\r\nerr = __gm_phy_read(hw, skge->port, data->reg_num & 0x1f, &val);\r\nspin_unlock_bh(&hw->phy_lock);\r\ndata->val_out = val;\r\nbreak;\r\n}\r\ncase SIOCSMIIREG:\r\nspin_lock_bh(&hw->phy_lock);\r\nif (is_genesis(hw))\r\nerr = xm_phy_write(hw, skge->port, data->reg_num & 0x1f,\r\ndata->val_in);\r\nelse\r\nerr = gm_phy_write(hw, skge->port, data->reg_num & 0x1f,\r\ndata->val_in);\r\nspin_unlock_bh(&hw->phy_lock);\r\nbreak;\r\n}\r\nreturn err;\r\n}\r\nstatic void skge_ramset(struct skge_hw *hw, u16 q, u32 start, size_t len)\r\n{\r\nu32 end;\r\nstart /= 8;\r\nlen /= 8;\r\nend = start + len - 1;\r\nskge_write8(hw, RB_ADDR(q, RB_CTRL), RB_RST_CLR);\r\nskge_write32(hw, RB_ADDR(q, RB_START), start);\r\nskge_write32(hw, RB_ADDR(q, RB_WP), start);\r\nskge_write32(hw, RB_ADDR(q, RB_RP), start);\r\nskge_write32(hw, RB_ADDR(q, RB_END), end);\r\nif (q == Q_R1 || q == Q_R2) {\r\nskge_write32(hw, RB_ADDR(q, RB_RX_UTPP),\r\nstart + (2*len)/3);\r\nskge_write32(hw, RB_ADDR(q, RB_RX_LTPP),\r\nstart + (len/3));\r\n} else {\r\nskge_write8(hw, RB_ADDR(q, RB_CTRL), RB_ENA_STFWD);\r\n}\r\nskge_write8(hw, RB_ADDR(q, RB_CTRL), RB_ENA_OP_MD);\r\n}\r\nstatic void skge_qset(struct skge_port *skge, u16 q,\r\nconst struct skge_element *e)\r\n{\r\nstruct skge_hw *hw = skge->hw;\r\nu32 watermark = 0x600;\r\nu64 base = skge->dma + (e->desc - skge->mem);\r\nif ((skge_read16(hw, B0_CTST) & (CS_BUS_CLOCK | CS_BUS_SLOT_SZ)) == 0)\r\nwatermark /= 2;\r\nskge_write32(hw, Q_ADDR(q, Q_CSR), CSR_CLR_RESET);\r\nskge_write32(hw, Q_ADDR(q, Q_F), watermark);\r\nskge_write32(hw, Q_ADDR(q, Q_DA_H), (u32)(base >> 32));\r\nskge_write32(hw, Q_ADDR(q, Q_DA_L), (u32)base);\r\n}\r\nstatic int skge_up(struct net_device *dev)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nu32 chunk, ram_addr;\r\nsize_t rx_size, tx_size;\r\nint err;\r\nif (!is_valid_ether_addr(dev->dev_addr))\r\nreturn -EINVAL;\r\nnetif_info(skge, ifup, skge->netdev, "enabling interface\n");\r\nif (dev->mtu > RX_BUF_SIZE)\r\nskge->rx_buf_size = dev->mtu + ETH_HLEN;\r\nelse\r\nskge->rx_buf_size = RX_BUF_SIZE;\r\nrx_size = skge->rx_ring.count * sizeof(struct skge_rx_desc);\r\ntx_size = skge->tx_ring.count * sizeof(struct skge_tx_desc);\r\nskge->mem_size = tx_size + rx_size;\r\nskge->mem = pci_alloc_consistent(hw->pdev, skge->mem_size, &skge->dma);\r\nif (!skge->mem)\r\nreturn -ENOMEM;\r\nBUG_ON(skge->dma & 7);\r\nif (upper_32_bits(skge->dma) != upper_32_bits(skge->dma + skge->mem_size)) {\r\ndev_err(&hw->pdev->dev, "pci_alloc_consistent region crosses 4G boundary\n");\r\nerr = -EINVAL;\r\ngoto free_pci_mem;\r\n}\r\nmemset(skge->mem, 0, skge->mem_size);\r\nerr = skge_ring_alloc(&skge->rx_ring, skge->mem, skge->dma);\r\nif (err)\r\ngoto free_pci_mem;\r\nerr = skge_rx_fill(dev);\r\nif (err)\r\ngoto free_rx_ring;\r\nerr = skge_ring_alloc(&skge->tx_ring, skge->mem + rx_size,\r\nskge->dma + rx_size);\r\nif (err)\r\ngoto free_rx_ring;\r\nif (hw->ports == 1) {\r\nerr = request_irq(hw->pdev->irq, skge_intr, IRQF_SHARED,\r\ndev->name, hw);\r\nif (err) {\r\nnetdev_err(dev, "Unable to allocate interrupt %d error: %d\n",\r\nhw->pdev->irq, err);\r\ngoto free_tx_ring;\r\n}\r\n}\r\nnetif_carrier_off(dev);\r\nspin_lock_bh(&hw->phy_lock);\r\nif (is_genesis(hw))\r\ngenesis_mac_init(hw, port);\r\nelse\r\nyukon_mac_init(hw, port);\r\nspin_unlock_bh(&hw->phy_lock);\r\nchunk = (hw->ram_size - hw->ram_offset) / (hw->ports * 2);\r\nram_addr = hw->ram_offset + 2 * chunk * port;\r\nskge_ramset(hw, rxqaddr[port], ram_addr, chunk);\r\nskge_qset(skge, rxqaddr[port], skge->rx_ring.to_clean);\r\nBUG_ON(skge->tx_ring.to_use != skge->tx_ring.to_clean);\r\nskge_ramset(hw, txqaddr[port], ram_addr+chunk, chunk);\r\nskge_qset(skge, txqaddr[port], skge->tx_ring.to_use);\r\nwmb();\r\nskge_write8(hw, Q_ADDR(rxqaddr[port], Q_CSR), CSR_START | CSR_IRQ_CL_F);\r\nskge_led(skge, LED_MODE_ON);\r\nspin_lock_irq(&hw->hw_lock);\r\nhw->intr_mask |= portmask[port];\r\nskge_write32(hw, B0_IMSK, hw->intr_mask);\r\nskge_read32(hw, B0_IMSK);\r\nspin_unlock_irq(&hw->hw_lock);\r\nnapi_enable(&skge->napi);\r\nskge_set_multicast(dev);\r\nreturn 0;\r\nfree_tx_ring:\r\nkfree(skge->tx_ring.start);\r\nfree_rx_ring:\r\nskge_rx_clean(skge);\r\nkfree(skge->rx_ring.start);\r\nfree_pci_mem:\r\npci_free_consistent(hw->pdev, skge->mem_size, skge->mem, skge->dma);\r\nskge->mem = NULL;\r\nreturn err;\r\n}\r\nstatic void skge_rx_stop(struct skge_hw *hw, int port)\r\n{\r\nskge_write8(hw, Q_ADDR(rxqaddr[port], Q_CSR), CSR_STOP);\r\nskge_write32(hw, RB_ADDR(port ? Q_R2 : Q_R1, RB_CTRL),\r\nRB_RST_SET|RB_DIS_OP_MD);\r\nskge_write32(hw, Q_ADDR(rxqaddr[port], Q_CSR), CSR_SET_RESET);\r\n}\r\nstatic int skge_down(struct net_device *dev)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nif (skge->mem == NULL)\r\nreturn 0;\r\nnetif_info(skge, ifdown, skge->netdev, "disabling interface\n");\r\nnetif_tx_disable(dev);\r\nif (is_genesis(hw) && hw->phy_type == SK_PHY_XMAC)\r\ndel_timer_sync(&skge->link_timer);\r\nnapi_disable(&skge->napi);\r\nnetif_carrier_off(dev);\r\nspin_lock_irq(&hw->hw_lock);\r\nhw->intr_mask &= ~portmask[port];\r\nskge_write32(hw, B0_IMSK, (hw->ports == 1) ? 0 : hw->intr_mask);\r\nskge_read32(hw, B0_IMSK);\r\nspin_unlock_irq(&hw->hw_lock);\r\nif (hw->ports == 1)\r\nfree_irq(hw->pdev->irq, hw);\r\nskge_write8(skge->hw, SK_REG(skge->port, LNK_LED_REG), LED_OFF);\r\nif (is_genesis(hw))\r\ngenesis_stop(skge);\r\nelse\r\nyukon_stop(skge);\r\nskge_write8(hw, Q_ADDR(txqaddr[port], Q_CSR), CSR_STOP);\r\nskge_write32(hw, RB_ADDR(txqaddr[port], RB_CTRL),\r\nRB_RST_SET|RB_DIS_OP_MD);\r\nskge_write8(hw, SK_REG(port, TXA_CTRL),\r\nTXA_DIS_FSYNC | TXA_DIS_ALLOC | TXA_STOP_RC);\r\nskge_write32(hw, SK_REG(port, TXA_ITI_INI), 0L);\r\nskge_write32(hw, SK_REG(port, TXA_LIM_INI), 0L);\r\nskge_write32(hw, Q_ADDR(txqaddr[port], Q_CSR), CSR_SET_RESET);\r\nskge_write32(hw, RB_ADDR(txqaddr[port], RB_CTRL), RB_RST_SET);\r\nskge_write8(hw, RB_ADDR(port == 0 ? Q_XA1 : Q_XA2, RB_CTRL), RB_RST_SET);\r\nskge_rx_stop(hw, port);\r\nif (is_genesis(hw)) {\r\nskge_write8(hw, SK_REG(port, TX_MFF_CTRL2), MFF_RST_SET);\r\nskge_write8(hw, SK_REG(port, RX_MFF_CTRL2), MFF_RST_SET);\r\n} else {\r\nskge_write8(hw, SK_REG(port, RX_GMF_CTRL_T), GMF_RST_SET);\r\nskge_write8(hw, SK_REG(port, TX_GMF_CTRL_T), GMF_RST_SET);\r\n}\r\nskge_led(skge, LED_MODE_OFF);\r\nnetif_tx_lock_bh(dev);\r\nskge_tx_clean(dev);\r\nnetif_tx_unlock_bh(dev);\r\nskge_rx_clean(skge);\r\nkfree(skge->rx_ring.start);\r\nkfree(skge->tx_ring.start);\r\npci_free_consistent(hw->pdev, skge->mem_size, skge->mem, skge->dma);\r\nskge->mem = NULL;\r\nreturn 0;\r\n}\r\nstatic inline int skge_avail(const struct skge_ring *ring)\r\n{\r\nsmp_mb();\r\nreturn ((ring->to_clean > ring->to_use) ? 0 : ring->count)\r\n+ (ring->to_clean - ring->to_use) - 1;\r\n}\r\nstatic netdev_tx_t skge_xmit_frame(struct sk_buff *skb,\r\nstruct net_device *dev)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nstruct skge_hw *hw = skge->hw;\r\nstruct skge_element *e;\r\nstruct skge_tx_desc *td;\r\nint i;\r\nu32 control, len;\r\ndma_addr_t map;\r\nif (skb_padto(skb, ETH_ZLEN))\r\nreturn NETDEV_TX_OK;\r\nif (unlikely(skge_avail(&skge->tx_ring) < skb_shinfo(skb)->nr_frags + 1))\r\nreturn NETDEV_TX_BUSY;\r\ne = skge->tx_ring.to_use;\r\ntd = e->desc;\r\nBUG_ON(td->control & BMU_OWN);\r\ne->skb = skb;\r\nlen = skb_headlen(skb);\r\nmap = pci_map_single(hw->pdev, skb->data, len, PCI_DMA_TODEVICE);\r\nif (pci_dma_mapping_error(hw->pdev, map))\r\ngoto mapping_error;\r\ndma_unmap_addr_set(e, mapaddr, map);\r\ndma_unmap_len_set(e, maplen, len);\r\ntd->dma_lo = lower_32_bits(map);\r\ntd->dma_hi = upper_32_bits(map);\r\nif (skb->ip_summed == CHECKSUM_PARTIAL) {\r\nconst int offset = skb_checksum_start_offset(skb);\r\nif (ipip_hdr(skb)->protocol == IPPROTO_UDP &&\r\nhw->chip_rev == 0 && hw->chip_id == CHIP_ID_YUKON)\r\ncontrol = BMU_TCP_CHECK;\r\nelse\r\ncontrol = BMU_UDP_CHECK;\r\ntd->csum_offs = 0;\r\ntd->csum_start = offset;\r\ntd->csum_write = offset + skb->csum_offset;\r\n} else\r\ncontrol = BMU_CHECK;\r\nif (!skb_shinfo(skb)->nr_frags)\r\ncontrol |= BMU_EOF | BMU_IRQ_EOF;\r\nelse {\r\nstruct skge_tx_desc *tf = td;\r\ncontrol |= BMU_STFWD;\r\nfor (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {\r\nconst skb_frag_t *frag = &skb_shinfo(skb)->frags[i];\r\nmap = skb_frag_dma_map(&hw->pdev->dev, frag, 0,\r\nskb_frag_size(frag), DMA_TO_DEVICE);\r\nif (dma_mapping_error(&hw->pdev->dev, map))\r\ngoto mapping_unwind;\r\ne = e->next;\r\ne->skb = skb;\r\ntf = e->desc;\r\nBUG_ON(tf->control & BMU_OWN);\r\ntf->dma_lo = lower_32_bits(map);\r\ntf->dma_hi = upper_32_bits(map);\r\ndma_unmap_addr_set(e, mapaddr, map);\r\ndma_unmap_len_set(e, maplen, skb_frag_size(frag));\r\ntf->control = BMU_OWN | BMU_SW | control | skb_frag_size(frag);\r\n}\r\ntf->control |= BMU_EOF | BMU_IRQ_EOF;\r\n}\r\nwmb();\r\ntd->control = BMU_OWN | BMU_SW | BMU_STF | control | len;\r\nwmb();\r\nnetdev_sent_queue(dev, skb->len);\r\nskge_write8(hw, Q_ADDR(txqaddr[skge->port], Q_CSR), CSR_START);\r\nnetif_printk(skge, tx_queued, KERN_DEBUG, skge->netdev,\r\n"tx queued, slot %td, len %d\n",\r\ne - skge->tx_ring.start, skb->len);\r\nskge->tx_ring.to_use = e->next;\r\nsmp_wmb();\r\nif (skge_avail(&skge->tx_ring) <= TX_LOW_WATER) {\r\nnetdev_dbg(dev, "transmit queue full\n");\r\nnetif_stop_queue(dev);\r\n}\r\nreturn NETDEV_TX_OK;\r\nmapping_unwind:\r\ne = skge->tx_ring.to_use;\r\npci_unmap_single(hw->pdev,\r\ndma_unmap_addr(e, mapaddr),\r\ndma_unmap_len(e, maplen),\r\nPCI_DMA_TODEVICE);\r\nwhile (i-- > 0) {\r\ne = e->next;\r\npci_unmap_page(hw->pdev,\r\ndma_unmap_addr(e, mapaddr),\r\ndma_unmap_len(e, maplen),\r\nPCI_DMA_TODEVICE);\r\n}\r\nmapping_error:\r\nif (net_ratelimit())\r\ndev_warn(&hw->pdev->dev, "%s: tx mapping error\n", dev->name);\r\ndev_kfree_skb(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic inline void skge_tx_unmap(struct pci_dev *pdev, struct skge_element *e,\r\nu32 control)\r\n{\r\nif (control & BMU_STF)\r\npci_unmap_single(pdev, dma_unmap_addr(e, mapaddr),\r\ndma_unmap_len(e, maplen),\r\nPCI_DMA_TODEVICE);\r\nelse\r\npci_unmap_page(pdev, dma_unmap_addr(e, mapaddr),\r\ndma_unmap_len(e, maplen),\r\nPCI_DMA_TODEVICE);\r\n}\r\nstatic void skge_tx_clean(struct net_device *dev)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nstruct skge_element *e;\r\nfor (e = skge->tx_ring.to_clean; e != skge->tx_ring.to_use; e = e->next) {\r\nstruct skge_tx_desc *td = e->desc;\r\nskge_tx_unmap(skge->hw->pdev, e, td->control);\r\nif (td->control & BMU_EOF)\r\ndev_kfree_skb(e->skb);\r\ntd->control = 0;\r\n}\r\nnetdev_reset_queue(dev);\r\nskge->tx_ring.to_clean = e;\r\n}\r\nstatic void skge_tx_timeout(struct net_device *dev)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nnetif_printk(skge, timer, KERN_DEBUG, skge->netdev, "tx timeout\n");\r\nskge_write8(skge->hw, Q_ADDR(txqaddr[skge->port], Q_CSR), CSR_STOP);\r\nskge_tx_clean(dev);\r\nnetif_wake_queue(dev);\r\n}\r\nstatic int skge_change_mtu(struct net_device *dev, int new_mtu)\r\n{\r\nint err;\r\nif (new_mtu < ETH_ZLEN || new_mtu > ETH_JUMBO_MTU)\r\nreturn -EINVAL;\r\nif (!netif_running(dev)) {\r\ndev->mtu = new_mtu;\r\nreturn 0;\r\n}\r\nskge_down(dev);\r\ndev->mtu = new_mtu;\r\nerr = skge_up(dev);\r\nif (err)\r\ndev_close(dev);\r\nreturn err;\r\n}\r\nstatic void genesis_add_filter(u8 filter[8], const u8 *addr)\r\n{\r\nu32 crc, bit;\r\ncrc = ether_crc_le(ETH_ALEN, addr);\r\nbit = ~crc & 0x3f;\r\nfilter[bit/8] |= 1 << (bit%8);\r\n}\r\nstatic void genesis_set_multicast(struct net_device *dev)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nstruct netdev_hw_addr *ha;\r\nu32 mode;\r\nu8 filter[8];\r\nmode = xm_read32(hw, port, XM_MODE);\r\nmode |= XM_MD_ENA_HASH;\r\nif (dev->flags & IFF_PROMISC)\r\nmode |= XM_MD_ENA_PROM;\r\nelse\r\nmode &= ~XM_MD_ENA_PROM;\r\nif (dev->flags & IFF_ALLMULTI)\r\nmemset(filter, 0xff, sizeof(filter));\r\nelse {\r\nmemset(filter, 0, sizeof(filter));\r\nif (skge->flow_status == FLOW_STAT_REM_SEND ||\r\nskge->flow_status == FLOW_STAT_SYMMETRIC)\r\ngenesis_add_filter(filter, pause_mc_addr);\r\nnetdev_for_each_mc_addr(ha, dev)\r\ngenesis_add_filter(filter, ha->addr);\r\n}\r\nxm_write32(hw, port, XM_MODE, mode);\r\nxm_outhash(hw, port, XM_HSM, filter);\r\n}\r\nstatic void yukon_add_filter(u8 filter[8], const u8 *addr)\r\n{\r\nu32 bit = ether_crc(ETH_ALEN, addr) & 0x3f;\r\nfilter[bit/8] |= 1 << (bit%8);\r\n}\r\nstatic void yukon_set_multicast(struct net_device *dev)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nstruct skge_hw *hw = skge->hw;\r\nint port = skge->port;\r\nstruct netdev_hw_addr *ha;\r\nint rx_pause = (skge->flow_status == FLOW_STAT_REM_SEND ||\r\nskge->flow_status == FLOW_STAT_SYMMETRIC);\r\nu16 reg;\r\nu8 filter[8];\r\nmemset(filter, 0, sizeof(filter));\r\nreg = gma_read16(hw, port, GM_RX_CTRL);\r\nreg |= GM_RXCR_UCF_ENA;\r\nif (dev->flags & IFF_PROMISC)\r\nreg &= ~(GM_RXCR_UCF_ENA | GM_RXCR_MCF_ENA);\r\nelse if (dev->flags & IFF_ALLMULTI)\r\nmemset(filter, 0xff, sizeof(filter));\r\nelse if (netdev_mc_empty(dev) && !rx_pause)\r\nreg &= ~GM_RXCR_MCF_ENA;\r\nelse {\r\nreg |= GM_RXCR_MCF_ENA;\r\nif (rx_pause)\r\nyukon_add_filter(filter, pause_mc_addr);\r\nnetdev_for_each_mc_addr(ha, dev)\r\nyukon_add_filter(filter, ha->addr);\r\n}\r\ngma_write16(hw, port, GM_MC_ADDR_H1,\r\n(u16)filter[0] | ((u16)filter[1] << 8));\r\ngma_write16(hw, port, GM_MC_ADDR_H2,\r\n(u16)filter[2] | ((u16)filter[3] << 8));\r\ngma_write16(hw, port, GM_MC_ADDR_H3,\r\n(u16)filter[4] | ((u16)filter[5] << 8));\r\ngma_write16(hw, port, GM_MC_ADDR_H4,\r\n(u16)filter[6] | ((u16)filter[7] << 8));\r\ngma_write16(hw, port, GM_RX_CTRL, reg);\r\n}\r\nstatic inline u16 phy_length(const struct skge_hw *hw, u32 status)\r\n{\r\nif (is_genesis(hw))\r\nreturn status >> XMR_FS_LEN_SHIFT;\r\nelse\r\nreturn status >> GMR_FS_LEN_SHIFT;\r\n}\r\nstatic inline int bad_phy_status(const struct skge_hw *hw, u32 status)\r\n{\r\nif (is_genesis(hw))\r\nreturn (status & (XMR_FS_ERR | XMR_FS_2L_VLAN)) != 0;\r\nelse\r\nreturn (status & GMR_FS_ANY_ERR) ||\r\n(status & GMR_FS_RX_OK) == 0;\r\n}\r\nstatic void skge_set_multicast(struct net_device *dev)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nif (is_genesis(skge->hw))\r\ngenesis_set_multicast(dev);\r\nelse\r\nyukon_set_multicast(dev);\r\n}\r\nstatic struct sk_buff *skge_rx_get(struct net_device *dev,\r\nstruct skge_element *e,\r\nu32 control, u32 status, u16 csum)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nstruct sk_buff *skb;\r\nu16 len = control & BMU_BBC;\r\nnetif_printk(skge, rx_status, KERN_DEBUG, skge->netdev,\r\n"rx slot %td status 0x%x len %d\n",\r\ne - skge->rx_ring.start, status, len);\r\nif (len > skge->rx_buf_size)\r\ngoto error;\r\nif ((control & (BMU_EOF|BMU_STF)) != (BMU_STF|BMU_EOF))\r\ngoto error;\r\nif (bad_phy_status(skge->hw, status))\r\ngoto error;\r\nif (phy_length(skge->hw, status) != len)\r\ngoto error;\r\nif (len < RX_COPY_THRESHOLD) {\r\nskb = netdev_alloc_skb_ip_align(dev, len);\r\nif (!skb)\r\ngoto resubmit;\r\npci_dma_sync_single_for_cpu(skge->hw->pdev,\r\ndma_unmap_addr(e, mapaddr),\r\ndma_unmap_len(e, maplen),\r\nPCI_DMA_FROMDEVICE);\r\nskb_copy_from_linear_data(e->skb, skb->data, len);\r\npci_dma_sync_single_for_device(skge->hw->pdev,\r\ndma_unmap_addr(e, mapaddr),\r\ndma_unmap_len(e, maplen),\r\nPCI_DMA_FROMDEVICE);\r\nskge_rx_reuse(e, skge->rx_buf_size);\r\n} else {\r\nstruct skge_element ee;\r\nstruct sk_buff *nskb;\r\nnskb = netdev_alloc_skb_ip_align(dev, skge->rx_buf_size);\r\nif (!nskb)\r\ngoto resubmit;\r\nee = *e;\r\nskb = ee.skb;\r\nprefetch(skb->data);\r\nif (skge_rx_setup(skge, e, nskb, skge->rx_buf_size) < 0) {\r\ndev_kfree_skb(nskb);\r\ngoto resubmit;\r\n}\r\npci_unmap_single(skge->hw->pdev,\r\ndma_unmap_addr(&ee, mapaddr),\r\ndma_unmap_len(&ee, maplen),\r\nPCI_DMA_FROMDEVICE);\r\n}\r\nskb_put(skb, len);\r\nif (dev->features & NETIF_F_RXCSUM) {\r\nskb->csum = csum;\r\nskb->ip_summed = CHECKSUM_COMPLETE;\r\n}\r\nskb->protocol = eth_type_trans(skb, dev);\r\nreturn skb;\r\nerror:\r\nnetif_printk(skge, rx_err, KERN_DEBUG, skge->netdev,\r\n"rx err, slot %td control 0x%x status 0x%x\n",\r\ne - skge->rx_ring.start, control, status);\r\nif (is_genesis(skge->hw)) {\r\nif (status & (XMR_FS_RUNT|XMR_FS_LNG_ERR))\r\ndev->stats.rx_length_errors++;\r\nif (status & XMR_FS_FRA_ERR)\r\ndev->stats.rx_frame_errors++;\r\nif (status & XMR_FS_FCS_ERR)\r\ndev->stats.rx_crc_errors++;\r\n} else {\r\nif (status & (GMR_FS_LONG_ERR|GMR_FS_UN_SIZE))\r\ndev->stats.rx_length_errors++;\r\nif (status & GMR_FS_FRAGMENT)\r\ndev->stats.rx_frame_errors++;\r\nif (status & GMR_FS_CRC_ERR)\r\ndev->stats.rx_crc_errors++;\r\n}\r\nresubmit:\r\nskge_rx_reuse(e, skge->rx_buf_size);\r\nreturn NULL;\r\n}\r\nstatic void skge_tx_done(struct net_device *dev)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nstruct skge_ring *ring = &skge->tx_ring;\r\nstruct skge_element *e;\r\nunsigned int bytes_compl = 0, pkts_compl = 0;\r\nskge_write8(skge->hw, Q_ADDR(txqaddr[skge->port], Q_CSR), CSR_IRQ_CL_F);\r\nfor (e = ring->to_clean; e != ring->to_use; e = e->next) {\r\nu32 control = ((const struct skge_tx_desc *) e->desc)->control;\r\nif (control & BMU_OWN)\r\nbreak;\r\nskge_tx_unmap(skge->hw->pdev, e, control);\r\nif (control & BMU_EOF) {\r\nnetif_printk(skge, tx_done, KERN_DEBUG, skge->netdev,\r\n"tx done slot %td\n",\r\ne - skge->tx_ring.start);\r\npkts_compl++;\r\nbytes_compl += e->skb->len;\r\ndev_kfree_skb(e->skb);\r\n}\r\n}\r\nnetdev_completed_queue(dev, pkts_compl, bytes_compl);\r\nskge->tx_ring.to_clean = e;\r\nsmp_mb();\r\nif (unlikely(netif_queue_stopped(dev) &&\r\nskge_avail(&skge->tx_ring) > TX_LOW_WATER)) {\r\nnetif_tx_lock(dev);\r\nif (unlikely(netif_queue_stopped(dev) &&\r\nskge_avail(&skge->tx_ring) > TX_LOW_WATER)) {\r\nnetif_wake_queue(dev);\r\n}\r\nnetif_tx_unlock(dev);\r\n}\r\n}\r\nstatic int skge_poll(struct napi_struct *napi, int to_do)\r\n{\r\nstruct skge_port *skge = container_of(napi, struct skge_port, napi);\r\nstruct net_device *dev = skge->netdev;\r\nstruct skge_hw *hw = skge->hw;\r\nstruct skge_ring *ring = &skge->rx_ring;\r\nstruct skge_element *e;\r\nint work_done = 0;\r\nskge_tx_done(dev);\r\nskge_write8(hw, Q_ADDR(rxqaddr[skge->port], Q_CSR), CSR_IRQ_CL_F);\r\nfor (e = ring->to_clean; prefetch(e->next), work_done < to_do; e = e->next) {\r\nstruct skge_rx_desc *rd = e->desc;\r\nstruct sk_buff *skb;\r\nu32 control;\r\nrmb();\r\ncontrol = rd->control;\r\nif (control & BMU_OWN)\r\nbreak;\r\nskb = skge_rx_get(dev, e, control, rd->status, rd->csum2);\r\nif (likely(skb)) {\r\nnapi_gro_receive(napi, skb);\r\n++work_done;\r\n}\r\n}\r\nring->to_clean = e;\r\nwmb();\r\nskge_write8(hw, Q_ADDR(rxqaddr[skge->port], Q_CSR), CSR_START);\r\nif (work_done < to_do) {\r\nunsigned long flags;\r\nnapi_gro_flush(napi, false);\r\nspin_lock_irqsave(&hw->hw_lock, flags);\r\n__napi_complete(napi);\r\nhw->intr_mask |= napimask[skge->port];\r\nskge_write32(hw, B0_IMSK, hw->intr_mask);\r\nskge_read32(hw, B0_IMSK);\r\nspin_unlock_irqrestore(&hw->hw_lock, flags);\r\n}\r\nreturn work_done;\r\n}\r\nstatic void skge_mac_parity(struct skge_hw *hw, int port)\r\n{\r\nstruct net_device *dev = hw->dev[port];\r\n++dev->stats.tx_heartbeat_errors;\r\nif (is_genesis(hw))\r\nskge_write16(hw, SK_REG(port, TX_MFF_CTRL1),\r\nMFF_CLR_PERR);\r\nelse\r\nskge_write8(hw, SK_REG(port, TX_GMF_CTRL_T),\r\n(hw->chip_id == CHIP_ID_YUKON && hw->chip_rev == 0)\r\n? GMF_CLI_TX_FC : GMF_CLI_TX_PE);\r\n}\r\nstatic void skge_mac_intr(struct skge_hw *hw, int port)\r\n{\r\nif (is_genesis(hw))\r\ngenesis_mac_intr(hw, port);\r\nelse\r\nyukon_mac_intr(hw, port);\r\n}\r\nstatic void skge_error_irq(struct skge_hw *hw)\r\n{\r\nstruct pci_dev *pdev = hw->pdev;\r\nu32 hwstatus = skge_read32(hw, B0_HWE_ISRC);\r\nif (is_genesis(hw)) {\r\nif (hwstatus & (IS_NO_STAT_M1|IS_NO_TIST_M1))\r\nskge_write16(hw, RX_MFF_CTRL1, MFF_CLR_INSTAT);\r\nif (hwstatus & (IS_NO_STAT_M2|IS_NO_TIST_M2))\r\nskge_write16(hw, RX_MFF_CTRL2, MFF_CLR_INSTAT);\r\n} else {\r\nif (hwstatus & IS_IRQ_TIST_OV)\r\nskge_write8(hw, GMAC_TI_ST_CTRL, GMT_ST_CLR_IRQ);\r\n}\r\nif (hwstatus & IS_RAM_RD_PAR) {\r\ndev_err(&pdev->dev, "Ram read data parity error\n");\r\nskge_write16(hw, B3_RI_CTRL, RI_CLR_RD_PERR);\r\n}\r\nif (hwstatus & IS_RAM_WR_PAR) {\r\ndev_err(&pdev->dev, "Ram write data parity error\n");\r\nskge_write16(hw, B3_RI_CTRL, RI_CLR_WR_PERR);\r\n}\r\nif (hwstatus & IS_M1_PAR_ERR)\r\nskge_mac_parity(hw, 0);\r\nif (hwstatus & IS_M2_PAR_ERR)\r\nskge_mac_parity(hw, 1);\r\nif (hwstatus & IS_R1_PAR_ERR) {\r\ndev_err(&pdev->dev, "%s: receive queue parity error\n",\r\nhw->dev[0]->name);\r\nskge_write32(hw, B0_R1_CSR, CSR_IRQ_CL_P);\r\n}\r\nif (hwstatus & IS_R2_PAR_ERR) {\r\ndev_err(&pdev->dev, "%s: receive queue parity error\n",\r\nhw->dev[1]->name);\r\nskge_write32(hw, B0_R2_CSR, CSR_IRQ_CL_P);\r\n}\r\nif (hwstatus & (IS_IRQ_MST_ERR|IS_IRQ_STAT)) {\r\nu16 pci_status, pci_cmd;\r\npci_read_config_word(pdev, PCI_COMMAND, &pci_cmd);\r\npci_read_config_word(pdev, PCI_STATUS, &pci_status);\r\ndev_err(&pdev->dev, "PCI error cmd=%#x status=%#x\n",\r\npci_cmd, pci_status);\r\npci_status &= PCI_STATUS_ERROR_BITS;\r\nskge_write8(hw, B2_TST_CTRL1, TST_CFG_WRITE_ON);\r\npci_write_config_word(pdev, PCI_COMMAND,\r\npci_cmd | PCI_COMMAND_SERR | PCI_COMMAND_PARITY);\r\npci_write_config_word(pdev, PCI_STATUS, pci_status);\r\nskge_write8(hw, B2_TST_CTRL1, TST_CFG_WRITE_OFF);\r\nhwstatus = skge_read32(hw, B0_HWE_ISRC);\r\nif (hwstatus & IS_IRQ_STAT) {\r\ndev_warn(&hw->pdev->dev, "unable to clear error (so ignoring them)\n");\r\nhw->intr_mask &= ~IS_HW_ERR;\r\n}\r\n}\r\n}\r\nstatic void skge_extirq(unsigned long arg)\r\n{\r\nstruct skge_hw *hw = (struct skge_hw *) arg;\r\nint port;\r\nfor (port = 0; port < hw->ports; port++) {\r\nstruct net_device *dev = hw->dev[port];\r\nif (netif_running(dev)) {\r\nstruct skge_port *skge = netdev_priv(dev);\r\nspin_lock(&hw->phy_lock);\r\nif (!is_genesis(hw))\r\nyukon_phy_intr(skge);\r\nelse if (hw->phy_type == SK_PHY_BCOM)\r\nbcom_phy_intr(skge);\r\nspin_unlock(&hw->phy_lock);\r\n}\r\n}\r\nspin_lock_irq(&hw->hw_lock);\r\nhw->intr_mask |= IS_EXT_REG;\r\nskge_write32(hw, B0_IMSK, hw->intr_mask);\r\nskge_read32(hw, B0_IMSK);\r\nspin_unlock_irq(&hw->hw_lock);\r\n}\r\nstatic irqreturn_t skge_intr(int irq, void *dev_id)\r\n{\r\nstruct skge_hw *hw = dev_id;\r\nu32 status;\r\nint handled = 0;\r\nspin_lock(&hw->hw_lock);\r\nstatus = skge_read32(hw, B0_SP_ISRC);\r\nif (status == 0 || status == ~0)\r\ngoto out;\r\nhandled = 1;\r\nstatus &= hw->intr_mask;\r\nif (status & IS_EXT_REG) {\r\nhw->intr_mask &= ~IS_EXT_REG;\r\ntasklet_schedule(&hw->phy_task);\r\n}\r\nif (status & (IS_XA1_F|IS_R1_F)) {\r\nstruct skge_port *skge = netdev_priv(hw->dev[0]);\r\nhw->intr_mask &= ~(IS_XA1_F|IS_R1_F);\r\nnapi_schedule(&skge->napi);\r\n}\r\nif (status & IS_PA_TO_TX1)\r\nskge_write16(hw, B3_PA_CTRL, PA_CLR_TO_TX1);\r\nif (status & IS_PA_TO_RX1) {\r\n++hw->dev[0]->stats.rx_over_errors;\r\nskge_write16(hw, B3_PA_CTRL, PA_CLR_TO_RX1);\r\n}\r\nif (status & IS_MAC1)\r\nskge_mac_intr(hw, 0);\r\nif (hw->dev[1]) {\r\nstruct skge_port *skge = netdev_priv(hw->dev[1]);\r\nif (status & (IS_XA2_F|IS_R2_F)) {\r\nhw->intr_mask &= ~(IS_XA2_F|IS_R2_F);\r\nnapi_schedule(&skge->napi);\r\n}\r\nif (status & IS_PA_TO_RX2) {\r\n++hw->dev[1]->stats.rx_over_errors;\r\nskge_write16(hw, B3_PA_CTRL, PA_CLR_TO_RX2);\r\n}\r\nif (status & IS_PA_TO_TX2)\r\nskge_write16(hw, B3_PA_CTRL, PA_CLR_TO_TX2);\r\nif (status & IS_MAC2)\r\nskge_mac_intr(hw, 1);\r\n}\r\nif (status & IS_HW_ERR)\r\nskge_error_irq(hw);\r\nskge_write32(hw, B0_IMSK, hw->intr_mask);\r\nskge_read32(hw, B0_IMSK);\r\nout:\r\nspin_unlock(&hw->hw_lock);\r\nreturn IRQ_RETVAL(handled);\r\n}\r\nstatic void skge_netpoll(struct net_device *dev)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\ndisable_irq(dev->irq);\r\nskge_intr(dev->irq, skge->hw);\r\nenable_irq(dev->irq);\r\n}\r\nstatic int skge_set_mac_address(struct net_device *dev, void *p)\r\n{\r\nstruct skge_port *skge = netdev_priv(dev);\r\nstruct skge_hw *hw = skge->hw;\r\nunsigned port = skge->port;\r\nconst struct sockaddr *addr = p;\r\nu16 ctrl;\r\nif (!is_valid_ether_addr(addr->sa_data))\r\nreturn -EADDRNOTAVAIL;\r\nmemcpy(dev->dev_addr, addr->sa_data, ETH_ALEN);\r\nif (!netif_running(dev)) {\r\nmemcpy_toio(hw->regs + B2_MAC_1 + port*8, dev->dev_addr, ETH_ALEN);\r\nmemcpy_toio(hw->regs + B2_MAC_2 + port*8, dev->dev_addr, ETH_ALEN);\r\n} else {\r\nspin_lock_bh(&hw->phy_lock);\r\nctrl = gma_read16(hw, port, GM_GP_CTRL);\r\ngma_write16(hw, port, GM_GP_CTRL, ctrl & ~GM_GPCR_RX_ENA);\r\nmemcpy_toio(hw->regs + B2_MAC_1 + port*8, dev->dev_addr, ETH_ALEN);\r\nmemcpy_toio(hw->regs + B2_MAC_2 + port*8, dev->dev_addr, ETH_ALEN);\r\nif (is_genesis(hw))\r\nxm_outaddr(hw, port, XM_SA, dev->dev_addr);\r\nelse {\r\ngma_set_addr(hw, port, GM_SRC_ADDR_1L, dev->dev_addr);\r\ngma_set_addr(hw, port, GM_SRC_ADDR_2L, dev->dev_addr);\r\n}\r\ngma_write16(hw, port, GM_GP_CTRL, ctrl);\r\nspin_unlock_bh(&hw->phy_lock);\r\n}\r\nreturn 0;\r\n}\r\nstatic const char *skge_board_name(const struct skge_hw *hw)\r\n{\r\nint i;\r\nstatic char buf[16];\r\nfor (i = 0; i < ARRAY_SIZE(skge_chips); i++)\r\nif (skge_chips[i].id == hw->chip_id)\r\nreturn skge_chips[i].name;\r\nsnprintf(buf, sizeof buf, "chipid 0x%x", hw->chip_id);\r\nreturn buf;\r\n}\r\nstatic int skge_reset(struct skge_hw *hw)\r\n{\r\nu32 reg;\r\nu16 ctst, pci_status;\r\nu8 t8, mac_cfg, pmd_type;\r\nint i;\r\nctst = skge_read16(hw, B0_CTST);\r\nskge_write8(hw, B0_CTST, CS_RST_SET);\r\nskge_write8(hw, B0_CTST, CS_RST_CLR);\r\nskge_write8(hw, B2_TST_CTRL1, TST_CFG_WRITE_ON);\r\nskge_write8(hw, B2_TST_CTRL2, 0);\r\npci_read_config_word(hw->pdev, PCI_STATUS, &pci_status);\r\npci_write_config_word(hw->pdev, PCI_STATUS,\r\npci_status | PCI_STATUS_ERROR_BITS);\r\nskge_write8(hw, B2_TST_CTRL1, TST_CFG_WRITE_OFF);\r\nskge_write8(hw, B0_CTST, CS_MRST_CLR);\r\nskge_write16(hw, B0_CTST,\r\nctst & (CS_CLK_RUN_HOT|CS_CLK_RUN_RST|CS_CLK_RUN_ENA));\r\nhw->chip_id = skge_read8(hw, B2_CHIP_ID);\r\nhw->phy_type = skge_read8(hw, B2_E_1) & 0xf;\r\npmd_type = skge_read8(hw, B2_PMD_TYP);\r\nhw->copper = (pmd_type == 'T' || pmd_type == '1');\r\nswitch (hw->chip_id) {\r\ncase CHIP_ID_GENESIS:\r\n#ifdef CONFIG_SKGE_GENESIS\r\nswitch (hw->phy_type) {\r\ncase SK_PHY_XMAC:\r\nhw->phy_addr = PHY_ADDR_XMAC;\r\nbreak;\r\ncase SK_PHY_BCOM:\r\nhw->phy_addr = PHY_ADDR_BCOM;\r\nbreak;\r\ndefault:\r\ndev_err(&hw->pdev->dev, "unsupported phy type 0x%x\n",\r\nhw->phy_type);\r\nreturn -EOPNOTSUPP;\r\n}\r\nbreak;\r\n#else\r\ndev_err(&hw->pdev->dev, "Genesis chip detected but not configured\n");\r\nreturn -EOPNOTSUPP;\r\n#endif\r\ncase CHIP_ID_YUKON:\r\ncase CHIP_ID_YUKON_LITE:\r\ncase CHIP_ID_YUKON_LP:\r\nif (hw->phy_type < SK_PHY_MARV_COPPER && pmd_type != 'S')\r\nhw->copper = 1;\r\nhw->phy_addr = PHY_ADDR_MARV;\r\nbreak;\r\ndefault:\r\ndev_err(&hw->pdev->dev, "unsupported chip type 0x%x\n",\r\nhw->chip_id);\r\nreturn -EOPNOTSUPP;\r\n}\r\nmac_cfg = skge_read8(hw, B2_MAC_CFG);\r\nhw->ports = (mac_cfg & CFG_SNG_MAC) ? 1 : 2;\r\nhw->chip_rev = (mac_cfg & CFG_CHIP_R_MSK) >> 4;\r\nt8 = skge_read8(hw, B2_E_0);\r\nif (is_genesis(hw)) {\r\nif (t8 == 3) {\r\nhw->ram_size = 0x100000;\r\nhw->ram_offset = 0x80000;\r\n} else\r\nhw->ram_size = t8 * 512;\r\n} else if (t8 == 0)\r\nhw->ram_size = 0x20000;\r\nelse\r\nhw->ram_size = t8 * 4096;\r\nhw->intr_mask = IS_HW_ERR;\r\nif (!(is_genesis(hw) && hw->phy_type == SK_PHY_XMAC))\r\nhw->intr_mask |= IS_EXT_REG;\r\nif (is_genesis(hw))\r\ngenesis_init(hw);\r\nelse {\r\nskge_write8(hw, B0_POWER_CTRL,\r\nPC_VAUX_ENA | PC_VCC_ENA | PC_VAUX_OFF | PC_VCC_ON);\r\nif ((skge_read32(hw, B0_ISRC) & IS_HW_ERR) &&\r\n(skge_read32(hw, B0_HWE_ISRC) & IS_IRQ_SENSOR)) {\r\ndev_warn(&hw->pdev->dev, "stuck hardware sensor bit\n");\r\nhw->intr_mask &= ~IS_HW_ERR;\r\n}\r\nskge_write8(hw, B2_TST_CTRL1, TST_CFG_WRITE_ON);\r\npci_read_config_dword(hw->pdev, PCI_DEV_REG1, &reg);\r\nreg &= ~PCI_PHY_COMA;\r\npci_write_config_dword(hw->pdev, PCI_DEV_REG1, reg);\r\nskge_write8(hw, B2_TST_CTRL1, TST_CFG_WRITE_OFF);\r\nfor (i = 0; i < hw->ports; i++) {\r\nskge_write16(hw, SK_REG(i, GMAC_LINK_CTRL), GMLC_RST_SET);\r\nskge_write16(hw, SK_REG(i, GMAC_LINK_CTRL), GMLC_RST_CLR);\r\n}\r\n}\r\nskge_write8(hw, B2_TI_CTRL, TIM_STOP);\r\nskge_write8(hw, B2_TI_CTRL, TIM_CLR_IRQ);\r\nskge_write8(hw, B0_LED, LED_STAT_ON);\r\nfor (i = 0; i < hw->ports; i++)\r\nskge_write8(hw, SK_REG(i, TXA_CTRL), TXA_ENA_ARB);\r\nskge_write16(hw, B3_RI_CTRL, RI_RST_CLR);\r\nskge_write8(hw, B3_RI_WTO_R1, SK_RI_TO_53);\r\nskge_write8(hw, B3_RI_WTO_XA1, SK_RI_TO_53);\r\nskge_write8(hw, B3_RI_WTO_XS1, SK_RI_TO_53);\r\nskge_write8(hw, B3_RI_RTO_R1, SK_RI_TO_53);\r\nskge_write8(hw, B3_RI_RTO_XA1, SK_RI_TO_53);\r\nskge_write8(hw, B3_RI_RTO_XS1, SK_RI_TO_53);\r\nskge_write8(hw, B3_RI_WTO_R2, SK_RI_TO_53);\r\nskge_write8(hw, B3_RI_WTO_XA2, SK_RI_TO_53);\r\nskge_write8(hw, B3_RI_WTO_XS2, SK_RI_TO_53);\r\nskge_write8(hw, B3_RI_RTO_R2, SK_RI_TO_53);\r\nskge_write8(hw, B3_RI_RTO_XA2, SK_RI_TO_53);\r\nskge_write8(hw, B3_RI_RTO_XS2, SK_RI_TO_53);\r\nskge_write32(hw, B0_HWE_IMSK, IS_ERR_MSK);\r\nskge_write32(hw, B2_IRQM_MSK, IS_XA1_F|IS_XA2_F);\r\nskge_write32(hw, B2_IRQM_INI, skge_usecs2clk(hw, 100));\r\nskge_write32(hw, B2_IRQM_CTRL, TIM_START);\r\nskge_write32(hw, B0_IMSK, 0);\r\nfor (i = 0; i < hw->ports; i++) {\r\nif (is_genesis(hw))\r\ngenesis_reset(hw, i);\r\nelse\r\nyukon_reset(hw, i);\r\n}\r\nreturn 0;\r\n}\r\nstatic int skge_debug_show(struct seq_file *seq, void *v)\r\n{\r\nstruct net_device *dev = seq->private;\r\nconst struct skge_port *skge = netdev_priv(dev);\r\nconst struct skge_hw *hw = skge->hw;\r\nconst struct skge_element *e;\r\nif (!netif_running(dev))\r\nreturn -ENETDOWN;\r\nseq_printf(seq, "IRQ src=%x mask=%x\n", skge_read32(hw, B0_ISRC),\r\nskge_read32(hw, B0_IMSK));\r\nseq_printf(seq, "Tx Ring: (%d)\n", skge_avail(&skge->tx_ring));\r\nfor (e = skge->tx_ring.to_clean; e != skge->tx_ring.to_use; e = e->next) {\r\nconst struct skge_tx_desc *t = e->desc;\r\nseq_printf(seq, "%#x dma=%#x%08x %#x csum=%#x/%x/%x\n",\r\nt->control, t->dma_hi, t->dma_lo, t->status,\r\nt->csum_offs, t->csum_write, t->csum_start);\r\n}\r\nseq_printf(seq, "\nRx Ring:\n");\r\nfor (e = skge->rx_ring.to_clean; ; e = e->next) {\r\nconst struct skge_rx_desc *r = e->desc;\r\nif (r->control & BMU_OWN)\r\nbreak;\r\nseq_printf(seq, "%#x dma=%#x%08x %#x %#x csum=%#x/%x\n",\r\nr->control, r->dma_hi, r->dma_lo, r->status,\r\nr->timestamp, r->csum1, r->csum1_start);\r\n}\r\nreturn 0;\r\n}\r\nstatic int skge_debug_open(struct inode *inode, struct file *file)\r\n{\r\nreturn single_open(file, skge_debug_show, inode->i_private);\r\n}\r\nstatic int skge_device_event(struct notifier_block *unused,\r\nunsigned long event, void *ptr)\r\n{\r\nstruct net_device *dev = netdev_notifier_info_to_dev(ptr);\r\nstruct skge_port *skge;\r\nstruct dentry *d;\r\nif (dev->netdev_ops->ndo_open != &skge_up || !skge_debug)\r\ngoto done;\r\nskge = netdev_priv(dev);\r\nswitch (event) {\r\ncase NETDEV_CHANGENAME:\r\nif (skge->debugfs) {\r\nd = debugfs_rename(skge_debug, skge->debugfs,\r\nskge_debug, dev->name);\r\nif (d)\r\nskge->debugfs = d;\r\nelse {\r\nnetdev_info(dev, "rename failed\n");\r\ndebugfs_remove(skge->debugfs);\r\n}\r\n}\r\nbreak;\r\ncase NETDEV_GOING_DOWN:\r\nif (skge->debugfs) {\r\ndebugfs_remove(skge->debugfs);\r\nskge->debugfs = NULL;\r\n}\r\nbreak;\r\ncase NETDEV_UP:\r\nd = debugfs_create_file(dev->name, S_IRUGO,\r\nskge_debug, dev,\r\n&skge_debug_fops);\r\nif (!d || IS_ERR(d))\r\nnetdev_info(dev, "debugfs create failed\n");\r\nelse\r\nskge->debugfs = d;\r\nbreak;\r\n}\r\ndone:\r\nreturn NOTIFY_DONE;\r\n}\r\nstatic __init void skge_debug_init(void)\r\n{\r\nstruct dentry *ent;\r\nent = debugfs_create_dir("skge", NULL);\r\nif (!ent || IS_ERR(ent)) {\r\npr_info("debugfs create directory failed\n");\r\nreturn;\r\n}\r\nskge_debug = ent;\r\nregister_netdevice_notifier(&skge_notifier);\r\n}\r\nstatic __exit void skge_debug_cleanup(void)\r\n{\r\nif (skge_debug) {\r\nunregister_netdevice_notifier(&skge_notifier);\r\ndebugfs_remove(skge_debug);\r\nskge_debug = NULL;\r\n}\r\n}\r\nstatic struct net_device *skge_devinit(struct skge_hw *hw, int port,\r\nint highmem)\r\n{\r\nstruct skge_port *skge;\r\nstruct net_device *dev = alloc_etherdev(sizeof(*skge));\r\nif (!dev)\r\nreturn NULL;\r\nSET_NETDEV_DEV(dev, &hw->pdev->dev);\r\ndev->netdev_ops = &skge_netdev_ops;\r\ndev->ethtool_ops = &skge_ethtool_ops;\r\ndev->watchdog_timeo = TX_WATCHDOG;\r\ndev->irq = hw->pdev->irq;\r\nif (highmem)\r\ndev->features |= NETIF_F_HIGHDMA;\r\nskge = netdev_priv(dev);\r\nnetif_napi_add(dev, &skge->napi, skge_poll, NAPI_WEIGHT);\r\nskge->netdev = dev;\r\nskge->hw = hw;\r\nskge->msg_enable = netif_msg_init(debug, default_msg);\r\nskge->tx_ring.count = DEFAULT_TX_RING_SIZE;\r\nskge->rx_ring.count = DEFAULT_RX_RING_SIZE;\r\nskge->autoneg = AUTONEG_ENABLE;\r\nskge->flow_control = FLOW_MODE_SYM_OR_REM;\r\nskge->duplex = -1;\r\nskge->speed = -1;\r\nskge->advertising = skge_supported_modes(hw);\r\nif (device_can_wakeup(&hw->pdev->dev)) {\r\nskge->wol = wol_supported(hw) & WAKE_MAGIC;\r\ndevice_set_wakeup_enable(&hw->pdev->dev, skge->wol);\r\n}\r\nhw->dev[port] = dev;\r\nskge->port = port;\r\nif (is_genesis(hw))\r\nsetup_timer(&skge->link_timer, xm_link_timer, (unsigned long) skge);\r\nelse {\r\ndev->hw_features = NETIF_F_IP_CSUM | NETIF_F_SG |\r\nNETIF_F_RXCSUM;\r\ndev->features |= dev->hw_features;\r\n}\r\nmemcpy_fromio(dev->dev_addr, hw->regs + B2_MAC_1 + port*8, ETH_ALEN);\r\nreturn dev;\r\n}\r\nstatic void skge_show_addr(struct net_device *dev)\r\n{\r\nconst struct skge_port *skge = netdev_priv(dev);\r\nnetif_info(skge, probe, skge->netdev, "addr %pM\n", dev->dev_addr);\r\n}\r\nstatic int skge_probe(struct pci_dev *pdev, const struct pci_device_id *ent)\r\n{\r\nstruct net_device *dev, *dev1;\r\nstruct skge_hw *hw;\r\nint err, using_dac = 0;\r\nerr = pci_enable_device(pdev);\r\nif (err) {\r\ndev_err(&pdev->dev, "cannot enable PCI device\n");\r\ngoto err_out;\r\n}\r\nerr = pci_request_regions(pdev, DRV_NAME);\r\nif (err) {\r\ndev_err(&pdev->dev, "cannot obtain PCI resources\n");\r\ngoto err_out_disable_pdev;\r\n}\r\npci_set_master(pdev);\r\nif (!only_32bit_dma && !pci_set_dma_mask(pdev, DMA_BIT_MASK(64))) {\r\nusing_dac = 1;\r\nerr = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64));\r\n} else if (!(err = pci_set_dma_mask(pdev, DMA_BIT_MASK(32)))) {\r\nusing_dac = 0;\r\nerr = pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(32));\r\n}\r\nif (err) {\r\ndev_err(&pdev->dev, "no usable DMA configuration\n");\r\ngoto err_out_free_regions;\r\n}\r\n#ifdef __BIG_ENDIAN\r\n{\r\nu32 reg;\r\npci_read_config_dword(pdev, PCI_DEV_REG2, &reg);\r\nreg |= PCI_REV_DESC;\r\npci_write_config_dword(pdev, PCI_DEV_REG2, reg);\r\n}\r\n#endif\r\nerr = -ENOMEM;\r\nhw = kzalloc(sizeof(*hw) + strlen(DRV_NAME "@pci:")\r\n+ strlen(pci_name(pdev)) + 1, GFP_KERNEL);\r\nif (!hw)\r\ngoto err_out_free_regions;\r\nsprintf(hw->irq_name, DRV_NAME "@pci:%s", pci_name(pdev));\r\nhw->pdev = pdev;\r\nspin_lock_init(&hw->hw_lock);\r\nspin_lock_init(&hw->phy_lock);\r\ntasklet_init(&hw->phy_task, skge_extirq, (unsigned long) hw);\r\nhw->regs = ioremap_nocache(pci_resource_start(pdev, 0), 0x4000);\r\nif (!hw->regs) {\r\ndev_err(&pdev->dev, "cannot map device registers\n");\r\ngoto err_out_free_hw;\r\n}\r\nerr = skge_reset(hw);\r\nif (err)\r\ngoto err_out_iounmap;\r\npr_info("%s addr 0x%llx irq %d chip %s rev %d\n",\r\nDRV_VERSION,\r\n(unsigned long long)pci_resource_start(pdev, 0), pdev->irq,\r\nskge_board_name(hw), hw->chip_rev);\r\ndev = skge_devinit(hw, 0, using_dac);\r\nif (!dev) {\r\nerr = -ENOMEM;\r\ngoto err_out_led_off;\r\n}\r\nif (!is_valid_ether_addr(dev->dev_addr))\r\ndev_warn(&pdev->dev, "bad (zero?) ethernet address in rom\n");\r\nerr = register_netdev(dev);\r\nif (err) {\r\ndev_err(&pdev->dev, "cannot register net device\n");\r\ngoto err_out_free_netdev;\r\n}\r\nskge_show_addr(dev);\r\nif (hw->ports > 1) {\r\ndev1 = skge_devinit(hw, 1, using_dac);\r\nif (!dev1) {\r\nerr = -ENOMEM;\r\ngoto err_out_unregister;\r\n}\r\nerr = register_netdev(dev1);\r\nif (err) {\r\ndev_err(&pdev->dev, "cannot register second net device\n");\r\ngoto err_out_free_dev1;\r\n}\r\nerr = request_irq(pdev->irq, skge_intr, IRQF_SHARED,\r\nhw->irq_name, hw);\r\nif (err) {\r\ndev_err(&pdev->dev, "cannot assign irq %d\n",\r\npdev->irq);\r\ngoto err_out_unregister_dev1;\r\n}\r\nskge_show_addr(dev1);\r\n}\r\npci_set_drvdata(pdev, hw);\r\nreturn 0;\r\nerr_out_unregister_dev1:\r\nunregister_netdev(dev1);\r\nerr_out_free_dev1:\r\nfree_netdev(dev1);\r\nerr_out_unregister:\r\nunregister_netdev(dev);\r\nerr_out_free_netdev:\r\nfree_netdev(dev);\r\nerr_out_led_off:\r\nskge_write16(hw, B0_LED, LED_STAT_OFF);\r\nerr_out_iounmap:\r\niounmap(hw->regs);\r\nerr_out_free_hw:\r\nkfree(hw);\r\nerr_out_free_regions:\r\npci_release_regions(pdev);\r\nerr_out_disable_pdev:\r\npci_disable_device(pdev);\r\nerr_out:\r\nreturn err;\r\n}\r\nstatic void skge_remove(struct pci_dev *pdev)\r\n{\r\nstruct skge_hw *hw = pci_get_drvdata(pdev);\r\nstruct net_device *dev0, *dev1;\r\nif (!hw)\r\nreturn;\r\ndev1 = hw->dev[1];\r\nif (dev1)\r\nunregister_netdev(dev1);\r\ndev0 = hw->dev[0];\r\nunregister_netdev(dev0);\r\ntasklet_kill(&hw->phy_task);\r\nspin_lock_irq(&hw->hw_lock);\r\nhw->intr_mask = 0;\r\nif (hw->ports > 1) {\r\nskge_write32(hw, B0_IMSK, 0);\r\nskge_read32(hw, B0_IMSK);\r\nfree_irq(pdev->irq, hw);\r\n}\r\nspin_unlock_irq(&hw->hw_lock);\r\nskge_write16(hw, B0_LED, LED_STAT_OFF);\r\nskge_write8(hw, B0_CTST, CS_RST_SET);\r\nif (hw->ports > 1)\r\nfree_irq(pdev->irq, hw);\r\npci_release_regions(pdev);\r\npci_disable_device(pdev);\r\nif (dev1)\r\nfree_netdev(dev1);\r\nfree_netdev(dev0);\r\niounmap(hw->regs);\r\nkfree(hw);\r\n}\r\nstatic int skge_suspend(struct device *dev)\r\n{\r\nstruct pci_dev *pdev = to_pci_dev(dev);\r\nstruct skge_hw *hw = pci_get_drvdata(pdev);\r\nint i;\r\nif (!hw)\r\nreturn 0;\r\nfor (i = 0; i < hw->ports; i++) {\r\nstruct net_device *dev = hw->dev[i];\r\nstruct skge_port *skge = netdev_priv(dev);\r\nif (netif_running(dev))\r\nskge_down(dev);\r\nif (skge->wol)\r\nskge_wol_init(skge);\r\n}\r\nskge_write32(hw, B0_IMSK, 0);\r\nreturn 0;\r\n}\r\nstatic int skge_resume(struct device *dev)\r\n{\r\nstruct pci_dev *pdev = to_pci_dev(dev);\r\nstruct skge_hw *hw = pci_get_drvdata(pdev);\r\nint i, err;\r\nif (!hw)\r\nreturn 0;\r\nerr = skge_reset(hw);\r\nif (err)\r\ngoto out;\r\nfor (i = 0; i < hw->ports; i++) {\r\nstruct net_device *dev = hw->dev[i];\r\nif (netif_running(dev)) {\r\nerr = skge_up(dev);\r\nif (err) {\r\nnetdev_err(dev, "could not up: %d\n", err);\r\ndev_close(dev);\r\ngoto out;\r\n}\r\n}\r\n}\r\nout:\r\nreturn err;\r\n}\r\nstatic void skge_shutdown(struct pci_dev *pdev)\r\n{\r\nstruct skge_hw *hw = pci_get_drvdata(pdev);\r\nint i;\r\nif (!hw)\r\nreturn;\r\nfor (i = 0; i < hw->ports; i++) {\r\nstruct net_device *dev = hw->dev[i];\r\nstruct skge_port *skge = netdev_priv(dev);\r\nif (skge->wol)\r\nskge_wol_init(skge);\r\n}\r\npci_wake_from_d3(pdev, device_may_wakeup(&pdev->dev));\r\npci_set_power_state(pdev, PCI_D3hot);\r\n}\r\nstatic int __init skge_init_module(void)\r\n{\r\nif (dmi_check_system(skge_32bit_dma_boards))\r\nonly_32bit_dma = 1;\r\nskge_debug_init();\r\nreturn pci_register_driver(&skge_driver);\r\n}\r\nstatic void __exit skge_cleanup_module(void)\r\n{\r\npci_unregister_driver(&skge_driver);\r\nskge_debug_cleanup();\r\n}
