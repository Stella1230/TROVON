static inline int RXD_IS_UP2DT(struct RxD_t *rxdp)\r\n{\r\nint ret;\r\nret = ((!(rxdp->Control_1 & RXD_OWN_XENA)) &&\r\n(GET_RXD_MARKER(rxdp->Control_2) != THE_RXD_MARK));\r\nreturn ret;\r\n}\r\nstatic inline int is_s2io_card_up(const struct s2io_nic *sp)\r\n{\r\nreturn test_bit(__S2IO_STATE_CARD_UP, &sp->state);\r\n}\r\nstatic void do_s2io_copy_mac_addr(struct s2io_nic *sp, int offset, u64 mac_addr)\r\n{\r\nsp->def_mac_addr[offset].mac_addr[5] = (u8) (mac_addr);\r\nsp->def_mac_addr[offset].mac_addr[4] = (u8) (mac_addr >> 8);\r\nsp->def_mac_addr[offset].mac_addr[3] = (u8) (mac_addr >> 16);\r\nsp->def_mac_addr[offset].mac_addr[2] = (u8) (mac_addr >> 24);\r\nsp->def_mac_addr[offset].mac_addr[1] = (u8) (mac_addr >> 32);\r\nsp->def_mac_addr[offset].mac_addr[0] = (u8) (mac_addr >> 40);\r\n}\r\nstatic inline void s2io_stop_all_tx_queue(struct s2io_nic *sp)\r\n{\r\nif (!sp->config.multiq) {\r\nint i;\r\nfor (i = 0; i < sp->config.tx_fifo_num; i++)\r\nsp->mac_control.fifos[i].queue_state = FIFO_QUEUE_STOP;\r\n}\r\nnetif_tx_stop_all_queues(sp->dev);\r\n}\r\nstatic inline void s2io_stop_tx_queue(struct s2io_nic *sp, int fifo_no)\r\n{\r\nif (!sp->config.multiq)\r\nsp->mac_control.fifos[fifo_no].queue_state =\r\nFIFO_QUEUE_STOP;\r\nnetif_tx_stop_all_queues(sp->dev);\r\n}\r\nstatic inline void s2io_start_all_tx_queue(struct s2io_nic *sp)\r\n{\r\nif (!sp->config.multiq) {\r\nint i;\r\nfor (i = 0; i < sp->config.tx_fifo_num; i++)\r\nsp->mac_control.fifos[i].queue_state = FIFO_QUEUE_START;\r\n}\r\nnetif_tx_start_all_queues(sp->dev);\r\n}\r\nstatic inline void s2io_start_tx_queue(struct s2io_nic *sp, int fifo_no)\r\n{\r\nif (!sp->config.multiq)\r\nsp->mac_control.fifos[fifo_no].queue_state =\r\nFIFO_QUEUE_START;\r\nnetif_tx_start_all_queues(sp->dev);\r\n}\r\nstatic inline void s2io_wake_all_tx_queue(struct s2io_nic *sp)\r\n{\r\nif (!sp->config.multiq) {\r\nint i;\r\nfor (i = 0; i < sp->config.tx_fifo_num; i++)\r\nsp->mac_control.fifos[i].queue_state = FIFO_QUEUE_START;\r\n}\r\nnetif_tx_wake_all_queues(sp->dev);\r\n}\r\nstatic inline void s2io_wake_tx_queue(\r\nstruct fifo_info *fifo, int cnt, u8 multiq)\r\n{\r\nif (multiq) {\r\nif (cnt && __netif_subqueue_stopped(fifo->dev, fifo->fifo_no))\r\nnetif_wake_subqueue(fifo->dev, fifo->fifo_no);\r\n} else if (cnt && (fifo->queue_state == FIFO_QUEUE_STOP)) {\r\nif (netif_queue_stopped(fifo->dev)) {\r\nfifo->queue_state = FIFO_QUEUE_START;\r\nnetif_wake_queue(fifo->dev);\r\n}\r\n}\r\n}\r\nstatic int init_shared_mem(struct s2io_nic *nic)\r\n{\r\nu32 size;\r\nvoid *tmp_v_addr, *tmp_v_addr_next;\r\ndma_addr_t tmp_p_addr, tmp_p_addr_next;\r\nstruct RxD_block *pre_rxd_blk = NULL;\r\nint i, j, blk_cnt;\r\nint lst_size, lst_per_page;\r\nstruct net_device *dev = nic->dev;\r\nunsigned long tmp;\r\nstruct buffAdd *ba;\r\nstruct config_param *config = &nic->config;\r\nstruct mac_info *mac_control = &nic->mac_control;\r\nunsigned long long mem_allocated = 0;\r\nsize = 0;\r\nfor (i = 0; i < config->tx_fifo_num; i++) {\r\nstruct tx_fifo_config *tx_cfg = &config->tx_cfg[i];\r\nsize += tx_cfg->fifo_len;\r\n}\r\nif (size > MAX_AVAILABLE_TXDS) {\r\nDBG_PRINT(ERR_DBG,\r\n"Too many TxDs requested: %d, max supported: %d\n",\r\nsize, MAX_AVAILABLE_TXDS);\r\nreturn -EINVAL;\r\n}\r\nsize = 0;\r\nfor (i = 0; i < config->tx_fifo_num; i++) {\r\nstruct tx_fifo_config *tx_cfg = &config->tx_cfg[i];\r\nsize = tx_cfg->fifo_len;\r\nif (size < 2) {\r\nDBG_PRINT(ERR_DBG, "Fifo %d: Invalid length (%d) - "\r\n"Valid lengths are 2 through 8192\n",\r\ni, size);\r\nreturn -EINVAL;\r\n}\r\n}\r\nlst_size = (sizeof(struct TxD) * config->max_txds);\r\nlst_per_page = PAGE_SIZE / lst_size;\r\nfor (i = 0; i < config->tx_fifo_num; i++) {\r\nstruct fifo_info *fifo = &mac_control->fifos[i];\r\nstruct tx_fifo_config *tx_cfg = &config->tx_cfg[i];\r\nint fifo_len = tx_cfg->fifo_len;\r\nint list_holder_size = fifo_len * sizeof(struct list_info_hold);\r\nfifo->list_info = kzalloc(list_holder_size, GFP_KERNEL);\r\nif (!fifo->list_info) {\r\nDBG_PRINT(INFO_DBG, "Malloc failed for list_info\n");\r\nreturn -ENOMEM;\r\n}\r\nmem_allocated += list_holder_size;\r\n}\r\nfor (i = 0; i < config->tx_fifo_num; i++) {\r\nint page_num = TXD_MEM_PAGE_CNT(config->tx_cfg[i].fifo_len,\r\nlst_per_page);\r\nstruct fifo_info *fifo = &mac_control->fifos[i];\r\nstruct tx_fifo_config *tx_cfg = &config->tx_cfg[i];\r\nfifo->tx_curr_put_info.offset = 0;\r\nfifo->tx_curr_put_info.fifo_len = tx_cfg->fifo_len - 1;\r\nfifo->tx_curr_get_info.offset = 0;\r\nfifo->tx_curr_get_info.fifo_len = tx_cfg->fifo_len - 1;\r\nfifo->fifo_no = i;\r\nfifo->nic = nic;\r\nfifo->max_txds = MAX_SKB_FRAGS + 2;\r\nfifo->dev = dev;\r\nfor (j = 0; j < page_num; j++) {\r\nint k = 0;\r\ndma_addr_t tmp_p;\r\nvoid *tmp_v;\r\ntmp_v = pci_alloc_consistent(nic->pdev,\r\nPAGE_SIZE, &tmp_p);\r\nif (!tmp_v) {\r\nDBG_PRINT(INFO_DBG,\r\n"pci_alloc_consistent failed for TxDL\n");\r\nreturn -ENOMEM;\r\n}\r\nif (!tmp_p) {\r\nmac_control->zerodma_virt_addr = tmp_v;\r\nDBG_PRINT(INIT_DBG,\r\n"%s: Zero DMA address for TxDL. "\r\n"Virtual address %p\n",\r\ndev->name, tmp_v);\r\ntmp_v = pci_alloc_consistent(nic->pdev,\r\nPAGE_SIZE, &tmp_p);\r\nif (!tmp_v) {\r\nDBG_PRINT(INFO_DBG,\r\n"pci_alloc_consistent failed for TxDL\n");\r\nreturn -ENOMEM;\r\n}\r\nmem_allocated += PAGE_SIZE;\r\n}\r\nwhile (k < lst_per_page) {\r\nint l = (j * lst_per_page) + k;\r\nif (l == tx_cfg->fifo_len)\r\nbreak;\r\nfifo->list_info[l].list_virt_addr =\r\ntmp_v + (k * lst_size);\r\nfifo->list_info[l].list_phy_addr =\r\ntmp_p + (k * lst_size);\r\nk++;\r\n}\r\n}\r\n}\r\nfor (i = 0; i < config->tx_fifo_num; i++) {\r\nstruct fifo_info *fifo = &mac_control->fifos[i];\r\nstruct tx_fifo_config *tx_cfg = &config->tx_cfg[i];\r\nsize = tx_cfg->fifo_len;\r\nfifo->ufo_in_band_v = kcalloc(size, sizeof(u64), GFP_KERNEL);\r\nif (!fifo->ufo_in_band_v)\r\nreturn -ENOMEM;\r\nmem_allocated += (size * sizeof(u64));\r\n}\r\nsize = 0;\r\nfor (i = 0; i < config->rx_ring_num; i++) {\r\nstruct rx_ring_config *rx_cfg = &config->rx_cfg[i];\r\nstruct ring_info *ring = &mac_control->rings[i];\r\nif (rx_cfg->num_rxd % (rxd_count[nic->rxd_mode] + 1)) {\r\nDBG_PRINT(ERR_DBG, "%s: Ring%d RxD count is not a "\r\n"multiple of RxDs per Block\n",\r\ndev->name, i);\r\nreturn FAILURE;\r\n}\r\nsize += rx_cfg->num_rxd;\r\nring->block_count = rx_cfg->num_rxd /\r\n(rxd_count[nic->rxd_mode] + 1);\r\nring->pkt_cnt = rx_cfg->num_rxd - ring->block_count;\r\n}\r\nif (nic->rxd_mode == RXD_MODE_1)\r\nsize = (size * (sizeof(struct RxD1)));\r\nelse\r\nsize = (size * (sizeof(struct RxD3)));\r\nfor (i = 0; i < config->rx_ring_num; i++) {\r\nstruct rx_ring_config *rx_cfg = &config->rx_cfg[i];\r\nstruct ring_info *ring = &mac_control->rings[i];\r\nring->rx_curr_get_info.block_index = 0;\r\nring->rx_curr_get_info.offset = 0;\r\nring->rx_curr_get_info.ring_len = rx_cfg->num_rxd - 1;\r\nring->rx_curr_put_info.block_index = 0;\r\nring->rx_curr_put_info.offset = 0;\r\nring->rx_curr_put_info.ring_len = rx_cfg->num_rxd - 1;\r\nring->nic = nic;\r\nring->ring_no = i;\r\nblk_cnt = rx_cfg->num_rxd / (rxd_count[nic->rxd_mode] + 1);\r\nfor (j = 0; j < blk_cnt; j++) {\r\nstruct rx_block_info *rx_blocks;\r\nint l;\r\nrx_blocks = &ring->rx_blocks[j];\r\nsize = SIZE_OF_BLOCK;\r\ntmp_v_addr = pci_alloc_consistent(nic->pdev, size,\r\n&tmp_p_addr);\r\nif (tmp_v_addr == NULL) {\r\nrx_blocks->block_virt_addr = tmp_v_addr;\r\nreturn -ENOMEM;\r\n}\r\nmem_allocated += size;\r\nmemset(tmp_v_addr, 0, size);\r\nsize = sizeof(struct rxd_info) *\r\nrxd_count[nic->rxd_mode];\r\nrx_blocks->block_virt_addr = tmp_v_addr;\r\nrx_blocks->block_dma_addr = tmp_p_addr;\r\nrx_blocks->rxds = kmalloc(size, GFP_KERNEL);\r\nif (!rx_blocks->rxds)\r\nreturn -ENOMEM;\r\nmem_allocated += size;\r\nfor (l = 0; l < rxd_count[nic->rxd_mode]; l++) {\r\nrx_blocks->rxds[l].virt_addr =\r\nrx_blocks->block_virt_addr +\r\n(rxd_size[nic->rxd_mode] * l);\r\nrx_blocks->rxds[l].dma_addr =\r\nrx_blocks->block_dma_addr +\r\n(rxd_size[nic->rxd_mode] * l);\r\n}\r\n}\r\nfor (j = 0; j < blk_cnt; j++) {\r\nint next = (j + 1) % blk_cnt;\r\ntmp_v_addr = ring->rx_blocks[j].block_virt_addr;\r\ntmp_v_addr_next = ring->rx_blocks[next].block_virt_addr;\r\ntmp_p_addr = ring->rx_blocks[j].block_dma_addr;\r\ntmp_p_addr_next = ring->rx_blocks[next].block_dma_addr;\r\npre_rxd_blk = tmp_v_addr;\r\npre_rxd_blk->reserved_2_pNext_RxD_block =\r\n(unsigned long)tmp_v_addr_next;\r\npre_rxd_blk->pNext_RxD_Blk_physical =\r\n(u64)tmp_p_addr_next;\r\n}\r\n}\r\nif (nic->rxd_mode == RXD_MODE_3B) {\r\nfor (i = 0; i < config->rx_ring_num; i++) {\r\nstruct rx_ring_config *rx_cfg = &config->rx_cfg[i];\r\nstruct ring_info *ring = &mac_control->rings[i];\r\nblk_cnt = rx_cfg->num_rxd /\r\n(rxd_count[nic->rxd_mode] + 1);\r\nsize = sizeof(struct buffAdd *) * blk_cnt;\r\nring->ba = kmalloc(size, GFP_KERNEL);\r\nif (!ring->ba)\r\nreturn -ENOMEM;\r\nmem_allocated += size;\r\nfor (j = 0; j < blk_cnt; j++) {\r\nint k = 0;\r\nsize = sizeof(struct buffAdd) *\r\n(rxd_count[nic->rxd_mode] + 1);\r\nring->ba[j] = kmalloc(size, GFP_KERNEL);\r\nif (!ring->ba[j])\r\nreturn -ENOMEM;\r\nmem_allocated += size;\r\nwhile (k != rxd_count[nic->rxd_mode]) {\r\nba = &ring->ba[j][k];\r\nsize = BUF0_LEN + ALIGN_SIZE;\r\nba->ba_0_org = kmalloc(size, GFP_KERNEL);\r\nif (!ba->ba_0_org)\r\nreturn -ENOMEM;\r\nmem_allocated += size;\r\ntmp = (unsigned long)ba->ba_0_org;\r\ntmp += ALIGN_SIZE;\r\ntmp &= ~((unsigned long)ALIGN_SIZE);\r\nba->ba_0 = (void *)tmp;\r\nsize = BUF1_LEN + ALIGN_SIZE;\r\nba->ba_1_org = kmalloc(size, GFP_KERNEL);\r\nif (!ba->ba_1_org)\r\nreturn -ENOMEM;\r\nmem_allocated += size;\r\ntmp = (unsigned long)ba->ba_1_org;\r\ntmp += ALIGN_SIZE;\r\ntmp &= ~((unsigned long)ALIGN_SIZE);\r\nba->ba_1 = (void *)tmp;\r\nk++;\r\n}\r\n}\r\n}\r\n}\r\nsize = sizeof(struct stat_block);\r\nmac_control->stats_mem =\r\npci_alloc_consistent(nic->pdev, size,\r\n&mac_control->stats_mem_phy);\r\nif (!mac_control->stats_mem) {\r\nreturn -ENOMEM;\r\n}\r\nmem_allocated += size;\r\nmac_control->stats_mem_sz = size;\r\ntmp_v_addr = mac_control->stats_mem;\r\nmac_control->stats_info = tmp_v_addr;\r\nmemset(tmp_v_addr, 0, size);\r\nDBG_PRINT(INIT_DBG, "%s: Ring Mem PHY: 0x%llx\n",\r\ndev_name(&nic->pdev->dev), (unsigned long long)tmp_p_addr);\r\nmac_control->stats_info->sw_stat.mem_allocated += mem_allocated;\r\nreturn SUCCESS;\r\n}\r\nstatic void free_shared_mem(struct s2io_nic *nic)\r\n{\r\nint i, j, blk_cnt, size;\r\nvoid *tmp_v_addr;\r\ndma_addr_t tmp_p_addr;\r\nint lst_size, lst_per_page;\r\nstruct net_device *dev;\r\nint page_num = 0;\r\nstruct config_param *config;\r\nstruct mac_info *mac_control;\r\nstruct stat_block *stats;\r\nstruct swStat *swstats;\r\nif (!nic)\r\nreturn;\r\ndev = nic->dev;\r\nconfig = &nic->config;\r\nmac_control = &nic->mac_control;\r\nstats = mac_control->stats_info;\r\nswstats = &stats->sw_stat;\r\nlst_size = sizeof(struct TxD) * config->max_txds;\r\nlst_per_page = PAGE_SIZE / lst_size;\r\nfor (i = 0; i < config->tx_fifo_num; i++) {\r\nstruct fifo_info *fifo = &mac_control->fifos[i];\r\nstruct tx_fifo_config *tx_cfg = &config->tx_cfg[i];\r\npage_num = TXD_MEM_PAGE_CNT(tx_cfg->fifo_len, lst_per_page);\r\nfor (j = 0; j < page_num; j++) {\r\nint mem_blks = (j * lst_per_page);\r\nstruct list_info_hold *fli;\r\nif (!fifo->list_info)\r\nreturn;\r\nfli = &fifo->list_info[mem_blks];\r\nif (!fli->list_virt_addr)\r\nbreak;\r\npci_free_consistent(nic->pdev, PAGE_SIZE,\r\nfli->list_virt_addr,\r\nfli->list_phy_addr);\r\nswstats->mem_freed += PAGE_SIZE;\r\n}\r\nif (mac_control->zerodma_virt_addr) {\r\npci_free_consistent(nic->pdev, PAGE_SIZE,\r\nmac_control->zerodma_virt_addr,\r\n(dma_addr_t)0);\r\nDBG_PRINT(INIT_DBG,\r\n"%s: Freeing TxDL with zero DMA address. "\r\n"Virtual address %p\n",\r\ndev->name, mac_control->zerodma_virt_addr);\r\nswstats->mem_freed += PAGE_SIZE;\r\n}\r\nkfree(fifo->list_info);\r\nswstats->mem_freed += tx_cfg->fifo_len *\r\nsizeof(struct list_info_hold);\r\n}\r\nsize = SIZE_OF_BLOCK;\r\nfor (i = 0; i < config->rx_ring_num; i++) {\r\nstruct ring_info *ring = &mac_control->rings[i];\r\nblk_cnt = ring->block_count;\r\nfor (j = 0; j < blk_cnt; j++) {\r\ntmp_v_addr = ring->rx_blocks[j].block_virt_addr;\r\ntmp_p_addr = ring->rx_blocks[j].block_dma_addr;\r\nif (tmp_v_addr == NULL)\r\nbreak;\r\npci_free_consistent(nic->pdev, size,\r\ntmp_v_addr, tmp_p_addr);\r\nswstats->mem_freed += size;\r\nkfree(ring->rx_blocks[j].rxds);\r\nswstats->mem_freed += sizeof(struct rxd_info) *\r\nrxd_count[nic->rxd_mode];\r\n}\r\n}\r\nif (nic->rxd_mode == RXD_MODE_3B) {\r\nfor (i = 0; i < config->rx_ring_num; i++) {\r\nstruct rx_ring_config *rx_cfg = &config->rx_cfg[i];\r\nstruct ring_info *ring = &mac_control->rings[i];\r\nblk_cnt = rx_cfg->num_rxd /\r\n(rxd_count[nic->rxd_mode] + 1);\r\nfor (j = 0; j < blk_cnt; j++) {\r\nint k = 0;\r\nif (!ring->ba[j])\r\ncontinue;\r\nwhile (k != rxd_count[nic->rxd_mode]) {\r\nstruct buffAdd *ba = &ring->ba[j][k];\r\nkfree(ba->ba_0_org);\r\nswstats->mem_freed +=\r\nBUF0_LEN + ALIGN_SIZE;\r\nkfree(ba->ba_1_org);\r\nswstats->mem_freed +=\r\nBUF1_LEN + ALIGN_SIZE;\r\nk++;\r\n}\r\nkfree(ring->ba[j]);\r\nswstats->mem_freed += sizeof(struct buffAdd) *\r\n(rxd_count[nic->rxd_mode] + 1);\r\n}\r\nkfree(ring->ba);\r\nswstats->mem_freed += sizeof(struct buffAdd *) *\r\nblk_cnt;\r\n}\r\n}\r\nfor (i = 0; i < nic->config.tx_fifo_num; i++) {\r\nstruct fifo_info *fifo = &mac_control->fifos[i];\r\nstruct tx_fifo_config *tx_cfg = &config->tx_cfg[i];\r\nif (fifo->ufo_in_band_v) {\r\nswstats->mem_freed += tx_cfg->fifo_len *\r\nsizeof(u64);\r\nkfree(fifo->ufo_in_band_v);\r\n}\r\n}\r\nif (mac_control->stats_mem) {\r\nswstats->mem_freed += mac_control->stats_mem_sz;\r\npci_free_consistent(nic->pdev,\r\nmac_control->stats_mem_sz,\r\nmac_control->stats_mem,\r\nmac_control->stats_mem_phy);\r\n}\r\n}\r\nstatic int s2io_verify_pci_mode(struct s2io_nic *nic)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = nic->bar0;\r\nregister u64 val64 = 0;\r\nint mode;\r\nval64 = readq(&bar0->pci_mode);\r\nmode = (u8)GET_PCI_MODE(val64);\r\nif (val64 & PCI_MODE_UNKNOWN_MODE)\r\nreturn -1;\r\nreturn mode;\r\n}\r\nstatic int s2io_on_nec_bridge(struct pci_dev *s2io_pdev)\r\n{\r\nstruct pci_dev *tdev = NULL;\r\nfor_each_pci_dev(tdev) {\r\nif (tdev->vendor == NEC_VENID && tdev->device == NEC_DEVID) {\r\nif (tdev->bus == s2io_pdev->bus->parent) {\r\npci_dev_put(tdev);\r\nreturn 1;\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int s2io_print_pci_mode(struct s2io_nic *nic)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = nic->bar0;\r\nregister u64 val64 = 0;\r\nint mode;\r\nstruct config_param *config = &nic->config;\r\nconst char *pcimode;\r\nval64 = readq(&bar0->pci_mode);\r\nmode = (u8)GET_PCI_MODE(val64);\r\nif (val64 & PCI_MODE_UNKNOWN_MODE)\r\nreturn -1;\r\nconfig->bus_speed = bus_speed[mode];\r\nif (s2io_on_nec_bridge(nic->pdev)) {\r\nDBG_PRINT(ERR_DBG, "%s: Device is on PCI-E bus\n",\r\nnic->dev->name);\r\nreturn mode;\r\n}\r\nswitch (mode) {\r\ncase PCI_MODE_PCI_33:\r\npcimode = "33MHz PCI bus";\r\nbreak;\r\ncase PCI_MODE_PCI_66:\r\npcimode = "66MHz PCI bus";\r\nbreak;\r\ncase PCI_MODE_PCIX_M1_66:\r\npcimode = "66MHz PCIX(M1) bus";\r\nbreak;\r\ncase PCI_MODE_PCIX_M1_100:\r\npcimode = "100MHz PCIX(M1) bus";\r\nbreak;\r\ncase PCI_MODE_PCIX_M1_133:\r\npcimode = "133MHz PCIX(M1) bus";\r\nbreak;\r\ncase PCI_MODE_PCIX_M2_66:\r\npcimode = "133MHz PCIX(M2) bus";\r\nbreak;\r\ncase PCI_MODE_PCIX_M2_100:\r\npcimode = "200MHz PCIX(M2) bus";\r\nbreak;\r\ncase PCI_MODE_PCIX_M2_133:\r\npcimode = "266MHz PCIX(M2) bus";\r\nbreak;\r\ndefault:\r\npcimode = "unsupported bus!";\r\nmode = -1;\r\n}\r\nDBG_PRINT(ERR_DBG, "%s: Device is on %d bit %s\n",\r\nnic->dev->name, val64 & PCI_MODE_32_BITS ? 32 : 64, pcimode);\r\nreturn mode;\r\n}\r\nstatic int init_tti(struct s2io_nic *nic, int link)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = nic->bar0;\r\nregister u64 val64 = 0;\r\nint i;\r\nstruct config_param *config = &nic->config;\r\nfor (i = 0; i < config->tx_fifo_num; i++) {\r\nif (nic->device_type == XFRAME_II_DEVICE) {\r\nint count = (nic->config.bus_speed * 125)/2;\r\nval64 = TTI_DATA1_MEM_TX_TIMER_VAL(count);\r\n} else\r\nval64 = TTI_DATA1_MEM_TX_TIMER_VAL(0x2078);\r\nval64 |= TTI_DATA1_MEM_TX_URNG_A(0xA) |\r\nTTI_DATA1_MEM_TX_URNG_B(0x10) |\r\nTTI_DATA1_MEM_TX_URNG_C(0x30) |\r\nTTI_DATA1_MEM_TX_TIMER_AC_EN;\r\nif (i == 0)\r\nif (use_continuous_tx_intrs && (link == LINK_UP))\r\nval64 |= TTI_DATA1_MEM_TX_TIMER_CI_EN;\r\nwriteq(val64, &bar0->tti_data1_mem);\r\nif (nic->config.intr_type == MSI_X) {\r\nval64 = TTI_DATA2_MEM_TX_UFC_A(0x10) |\r\nTTI_DATA2_MEM_TX_UFC_B(0x100) |\r\nTTI_DATA2_MEM_TX_UFC_C(0x200) |\r\nTTI_DATA2_MEM_TX_UFC_D(0x300);\r\n} else {\r\nif ((nic->config.tx_steering_type ==\r\nTX_DEFAULT_STEERING) &&\r\n(config->tx_fifo_num > 1) &&\r\n(i >= nic->udp_fifo_idx) &&\r\n(i < (nic->udp_fifo_idx +\r\nnic->total_udp_fifos)))\r\nval64 = TTI_DATA2_MEM_TX_UFC_A(0x50) |\r\nTTI_DATA2_MEM_TX_UFC_B(0x80) |\r\nTTI_DATA2_MEM_TX_UFC_C(0x100) |\r\nTTI_DATA2_MEM_TX_UFC_D(0x120);\r\nelse\r\nval64 = TTI_DATA2_MEM_TX_UFC_A(0x10) |\r\nTTI_DATA2_MEM_TX_UFC_B(0x20) |\r\nTTI_DATA2_MEM_TX_UFC_C(0x40) |\r\nTTI_DATA2_MEM_TX_UFC_D(0x80);\r\n}\r\nwriteq(val64, &bar0->tti_data2_mem);\r\nval64 = TTI_CMD_MEM_WE |\r\nTTI_CMD_MEM_STROBE_NEW_CMD |\r\nTTI_CMD_MEM_OFFSET(i);\r\nwriteq(val64, &bar0->tti_command_mem);\r\nif (wait_for_cmd_complete(&bar0->tti_command_mem,\r\nTTI_CMD_MEM_STROBE_NEW_CMD,\r\nS2IO_BIT_RESET) != SUCCESS)\r\nreturn FAILURE;\r\n}\r\nreturn SUCCESS;\r\n}\r\nstatic int init_nic(struct s2io_nic *nic)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = nic->bar0;\r\nstruct net_device *dev = nic->dev;\r\nregister u64 val64 = 0;\r\nvoid __iomem *add;\r\nu32 time;\r\nint i, j;\r\nint dtx_cnt = 0;\r\nunsigned long long mem_share;\r\nint mem_size;\r\nstruct config_param *config = &nic->config;\r\nstruct mac_info *mac_control = &nic->mac_control;\r\nif (s2io_set_swapper(nic)) {\r\nDBG_PRINT(ERR_DBG, "ERROR: Setting Swapper failed\n");\r\nreturn -EIO;\r\n}\r\nif (nic->device_type & XFRAME_II_DEVICE) {\r\nval64 = 0xA500000000ULL;\r\nwriteq(val64, &bar0->sw_reset);\r\nmsleep(500);\r\nval64 = readq(&bar0->sw_reset);\r\n}\r\nval64 = 0;\r\nwriteq(val64, &bar0->sw_reset);\r\nmsleep(500);\r\nval64 = readq(&bar0->sw_reset);\r\nif (nic->device_type == XFRAME_II_DEVICE) {\r\nfor (i = 0; i < 50; i++) {\r\nval64 = readq(&bar0->adapter_status);\r\nif (!(val64 & ADAPTER_STATUS_RIC_RUNNING))\r\nbreak;\r\nmsleep(10);\r\n}\r\nif (i == 50)\r\nreturn -ENODEV;\r\n}\r\nadd = &bar0->mac_cfg;\r\nval64 = readq(&bar0->mac_cfg);\r\nval64 |= MAC_RMAC_BCAST_ENABLE;\r\nwriteq(RMAC_CFG_KEY(0x4C0D), &bar0->rmac_cfg_key);\r\nwritel((u32)val64, add);\r\nwriteq(RMAC_CFG_KEY(0x4C0D), &bar0->rmac_cfg_key);\r\nwritel((u32) (val64 >> 32), (add + 4));\r\nval64 = readq(&bar0->mac_int_mask);\r\nval64 = readq(&bar0->mc_int_mask);\r\nval64 = readq(&bar0->xgxs_int_mask);\r\nval64 = dev->mtu;\r\nwriteq(vBIT(val64, 2, 14), &bar0->rmac_max_pyld_len);\r\nif (nic->device_type & XFRAME_II_DEVICE) {\r\nwhile (herc_act_dtx_cfg[dtx_cnt] != END_SIGN) {\r\nSPECIAL_REG_WRITE(herc_act_dtx_cfg[dtx_cnt],\r\n&bar0->dtx_control, UF);\r\nif (dtx_cnt & 0x1)\r\nmsleep(1);\r\ndtx_cnt++;\r\n}\r\n} else {\r\nwhile (xena_dtx_cfg[dtx_cnt] != END_SIGN) {\r\nSPECIAL_REG_WRITE(xena_dtx_cfg[dtx_cnt],\r\n&bar0->dtx_control, UF);\r\nval64 = readq(&bar0->dtx_control);\r\ndtx_cnt++;\r\n}\r\n}\r\nval64 = 0;\r\nwriteq(val64, &bar0->tx_fifo_partition_0);\r\nwriteq(val64, &bar0->tx_fifo_partition_1);\r\nwriteq(val64, &bar0->tx_fifo_partition_2);\r\nwriteq(val64, &bar0->tx_fifo_partition_3);\r\nfor (i = 0, j = 0; i < config->tx_fifo_num; i++) {\r\nstruct tx_fifo_config *tx_cfg = &config->tx_cfg[i];\r\nval64 |= vBIT(tx_cfg->fifo_len - 1, ((j * 32) + 19), 13) |\r\nvBIT(tx_cfg->fifo_priority, ((j * 32) + 5), 3);\r\nif (i == (config->tx_fifo_num - 1)) {\r\nif (i % 2 == 0)\r\ni++;\r\n}\r\nswitch (i) {\r\ncase 1:\r\nwriteq(val64, &bar0->tx_fifo_partition_0);\r\nval64 = 0;\r\nj = 0;\r\nbreak;\r\ncase 3:\r\nwriteq(val64, &bar0->tx_fifo_partition_1);\r\nval64 = 0;\r\nj = 0;\r\nbreak;\r\ncase 5:\r\nwriteq(val64, &bar0->tx_fifo_partition_2);\r\nval64 = 0;\r\nj = 0;\r\nbreak;\r\ncase 7:\r\nwriteq(val64, &bar0->tx_fifo_partition_3);\r\nval64 = 0;\r\nj = 0;\r\nbreak;\r\ndefault:\r\nj++;\r\nbreak;\r\n}\r\n}\r\nif ((nic->device_type == XFRAME_I_DEVICE) && (nic->pdev->revision < 4))\r\nwriteq(PCC_ENABLE_FOUR, &bar0->pcc_enable);\r\nval64 = readq(&bar0->tx_fifo_partition_0);\r\nDBG_PRINT(INIT_DBG, "Fifo partition at: 0x%p is: 0x%llx\n",\r\n&bar0->tx_fifo_partition_0, (unsigned long long)val64);\r\nval64 = readq(&bar0->tx_pa_cfg);\r\nval64 |= TX_PA_CFG_IGNORE_FRM_ERR |\r\nTX_PA_CFG_IGNORE_SNAP_OUI |\r\nTX_PA_CFG_IGNORE_LLC_CTRL |\r\nTX_PA_CFG_IGNORE_L2_ERR;\r\nwriteq(val64, &bar0->tx_pa_cfg);\r\nval64 = 0;\r\nfor (i = 0; i < config->rx_ring_num; i++) {\r\nstruct rx_ring_config *rx_cfg = &config->rx_cfg[i];\r\nval64 |= vBIT(rx_cfg->ring_priority, (5 + (i * 8)), 3);\r\n}\r\nwriteq(val64, &bar0->rx_queue_priority);\r\nval64 = 0;\r\nif (nic->device_type & XFRAME_II_DEVICE)\r\nmem_size = 32;\r\nelse\r\nmem_size = 64;\r\nfor (i = 0; i < config->rx_ring_num; i++) {\r\nswitch (i) {\r\ncase 0:\r\nmem_share = (mem_size / config->rx_ring_num +\r\nmem_size % config->rx_ring_num);\r\nval64 |= RX_QUEUE_CFG_Q0_SZ(mem_share);\r\ncontinue;\r\ncase 1:\r\nmem_share = (mem_size / config->rx_ring_num);\r\nval64 |= RX_QUEUE_CFG_Q1_SZ(mem_share);\r\ncontinue;\r\ncase 2:\r\nmem_share = (mem_size / config->rx_ring_num);\r\nval64 |= RX_QUEUE_CFG_Q2_SZ(mem_share);\r\ncontinue;\r\ncase 3:\r\nmem_share = (mem_size / config->rx_ring_num);\r\nval64 |= RX_QUEUE_CFG_Q3_SZ(mem_share);\r\ncontinue;\r\ncase 4:\r\nmem_share = (mem_size / config->rx_ring_num);\r\nval64 |= RX_QUEUE_CFG_Q4_SZ(mem_share);\r\ncontinue;\r\ncase 5:\r\nmem_share = (mem_size / config->rx_ring_num);\r\nval64 |= RX_QUEUE_CFG_Q5_SZ(mem_share);\r\ncontinue;\r\ncase 6:\r\nmem_share = (mem_size / config->rx_ring_num);\r\nval64 |= RX_QUEUE_CFG_Q6_SZ(mem_share);\r\ncontinue;\r\ncase 7:\r\nmem_share = (mem_size / config->rx_ring_num);\r\nval64 |= RX_QUEUE_CFG_Q7_SZ(mem_share);\r\ncontinue;\r\n}\r\n}\r\nwriteq(val64, &bar0->rx_queue_cfg);\r\nswitch (config->tx_fifo_num) {\r\ncase 1:\r\nval64 = 0x0;\r\nwriteq(val64, &bar0->tx_w_round_robin_0);\r\nwriteq(val64, &bar0->tx_w_round_robin_1);\r\nwriteq(val64, &bar0->tx_w_round_robin_2);\r\nwriteq(val64, &bar0->tx_w_round_robin_3);\r\nwriteq(val64, &bar0->tx_w_round_robin_4);\r\nbreak;\r\ncase 2:\r\nval64 = 0x0001000100010001ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_0);\r\nwriteq(val64, &bar0->tx_w_round_robin_1);\r\nwriteq(val64, &bar0->tx_w_round_robin_2);\r\nwriteq(val64, &bar0->tx_w_round_robin_3);\r\nval64 = 0x0001000100000000ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_4);\r\nbreak;\r\ncase 3:\r\nval64 = 0x0001020001020001ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_0);\r\nval64 = 0x0200010200010200ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_1);\r\nval64 = 0x0102000102000102ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_2);\r\nval64 = 0x0001020001020001ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_3);\r\nval64 = 0x0200010200000000ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_4);\r\nbreak;\r\ncase 4:\r\nval64 = 0x0001020300010203ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_0);\r\nwriteq(val64, &bar0->tx_w_round_robin_1);\r\nwriteq(val64, &bar0->tx_w_round_robin_2);\r\nwriteq(val64, &bar0->tx_w_round_robin_3);\r\nval64 = 0x0001020300000000ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_4);\r\nbreak;\r\ncase 5:\r\nval64 = 0x0001020304000102ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_0);\r\nval64 = 0x0304000102030400ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_1);\r\nval64 = 0x0102030400010203ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_2);\r\nval64 = 0x0400010203040001ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_3);\r\nval64 = 0x0203040000000000ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_4);\r\nbreak;\r\ncase 6:\r\nval64 = 0x0001020304050001ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_0);\r\nval64 = 0x0203040500010203ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_1);\r\nval64 = 0x0405000102030405ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_2);\r\nval64 = 0x0001020304050001ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_3);\r\nval64 = 0x0203040500000000ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_4);\r\nbreak;\r\ncase 7:\r\nval64 = 0x0001020304050600ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_0);\r\nval64 = 0x0102030405060001ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_1);\r\nval64 = 0x0203040506000102ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_2);\r\nval64 = 0x0304050600010203ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_3);\r\nval64 = 0x0405060000000000ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_4);\r\nbreak;\r\ncase 8:\r\nval64 = 0x0001020304050607ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_0);\r\nwriteq(val64, &bar0->tx_w_round_robin_1);\r\nwriteq(val64, &bar0->tx_w_round_robin_2);\r\nwriteq(val64, &bar0->tx_w_round_robin_3);\r\nval64 = 0x0001020300000000ULL;\r\nwriteq(val64, &bar0->tx_w_round_robin_4);\r\nbreak;\r\n}\r\nval64 = readq(&bar0->tx_fifo_partition_0);\r\nval64 |= (TX_FIFO_PARTITION_EN);\r\nwriteq(val64, &bar0->tx_fifo_partition_0);\r\nswitch (config->rx_ring_num) {\r\ncase 1:\r\nval64 = 0x0;\r\nwriteq(val64, &bar0->rx_w_round_robin_0);\r\nwriteq(val64, &bar0->rx_w_round_robin_1);\r\nwriteq(val64, &bar0->rx_w_round_robin_2);\r\nwriteq(val64, &bar0->rx_w_round_robin_3);\r\nwriteq(val64, &bar0->rx_w_round_robin_4);\r\nval64 = 0x8080808080808080ULL;\r\nwriteq(val64, &bar0->rts_qos_steering);\r\nbreak;\r\ncase 2:\r\nval64 = 0x0001000100010001ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_0);\r\nwriteq(val64, &bar0->rx_w_round_robin_1);\r\nwriteq(val64, &bar0->rx_w_round_robin_2);\r\nwriteq(val64, &bar0->rx_w_round_robin_3);\r\nval64 = 0x0001000100000000ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_4);\r\nval64 = 0x8080808040404040ULL;\r\nwriteq(val64, &bar0->rts_qos_steering);\r\nbreak;\r\ncase 3:\r\nval64 = 0x0001020001020001ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_0);\r\nval64 = 0x0200010200010200ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_1);\r\nval64 = 0x0102000102000102ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_2);\r\nval64 = 0x0001020001020001ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_3);\r\nval64 = 0x0200010200000000ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_4);\r\nval64 = 0x8080804040402020ULL;\r\nwriteq(val64, &bar0->rts_qos_steering);\r\nbreak;\r\ncase 4:\r\nval64 = 0x0001020300010203ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_0);\r\nwriteq(val64, &bar0->rx_w_round_robin_1);\r\nwriteq(val64, &bar0->rx_w_round_robin_2);\r\nwriteq(val64, &bar0->rx_w_round_robin_3);\r\nval64 = 0x0001020300000000ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_4);\r\nval64 = 0x8080404020201010ULL;\r\nwriteq(val64, &bar0->rts_qos_steering);\r\nbreak;\r\ncase 5:\r\nval64 = 0x0001020304000102ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_0);\r\nval64 = 0x0304000102030400ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_1);\r\nval64 = 0x0102030400010203ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_2);\r\nval64 = 0x0400010203040001ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_3);\r\nval64 = 0x0203040000000000ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_4);\r\nval64 = 0x8080404020201008ULL;\r\nwriteq(val64, &bar0->rts_qos_steering);\r\nbreak;\r\ncase 6:\r\nval64 = 0x0001020304050001ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_0);\r\nval64 = 0x0203040500010203ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_1);\r\nval64 = 0x0405000102030405ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_2);\r\nval64 = 0x0001020304050001ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_3);\r\nval64 = 0x0203040500000000ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_4);\r\nval64 = 0x8080404020100804ULL;\r\nwriteq(val64, &bar0->rts_qos_steering);\r\nbreak;\r\ncase 7:\r\nval64 = 0x0001020304050600ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_0);\r\nval64 = 0x0102030405060001ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_1);\r\nval64 = 0x0203040506000102ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_2);\r\nval64 = 0x0304050600010203ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_3);\r\nval64 = 0x0405060000000000ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_4);\r\nval64 = 0x8080402010080402ULL;\r\nwriteq(val64, &bar0->rts_qos_steering);\r\nbreak;\r\ncase 8:\r\nval64 = 0x0001020304050607ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_0);\r\nwriteq(val64, &bar0->rx_w_round_robin_1);\r\nwriteq(val64, &bar0->rx_w_round_robin_2);\r\nwriteq(val64, &bar0->rx_w_round_robin_3);\r\nval64 = 0x0001020300000000ULL;\r\nwriteq(val64, &bar0->rx_w_round_robin_4);\r\nval64 = 0x8040201008040201ULL;\r\nwriteq(val64, &bar0->rts_qos_steering);\r\nbreak;\r\n}\r\nval64 = 0;\r\nfor (i = 0; i < 8; i++)\r\nwriteq(val64, &bar0->rts_frm_len_n[i]);\r\nval64 = MAC_RTS_FRM_LEN_SET(dev->mtu+22);\r\nfor (i = 0 ; i < config->rx_ring_num ; i++)\r\nwriteq(val64, &bar0->rts_frm_len_n[i]);\r\nfor (i = 0; i < config->rx_ring_num; i++) {\r\nif (rts_frm_len[i] != 0) {\r\nwriteq(MAC_RTS_FRM_LEN_SET(rts_frm_len[i]),\r\n&bar0->rts_frm_len_n[i]);\r\n}\r\n}\r\nfor (i = 0; i < 64; i++) {\r\nif (rts_ds_steer(nic, i, 0) == FAILURE) {\r\nDBG_PRINT(ERR_DBG,\r\n"%s: rts_ds_steer failed on codepoint %d\n",\r\ndev->name, i);\r\nreturn -ENODEV;\r\n}\r\n}\r\nwriteq(mac_control->stats_mem_phy, &bar0->stat_addr);\r\nif (nic->device_type == XFRAME_II_DEVICE) {\r\nval64 = STAT_BC(0x320);\r\nwriteq(val64, &bar0->stat_byte_cnt);\r\n}\r\nval64 = MAC_TX_LINK_UTIL_VAL(tmac_util_period) |\r\nMAC_RX_LINK_UTIL_VAL(rmac_util_period);\r\nwriteq(val64, &bar0->mac_link_util);\r\nif (SUCCESS != init_tti(nic, nic->last_link_state))\r\nreturn -ENODEV;\r\nif (nic->device_type == XFRAME_II_DEVICE) {\r\nint count = (nic->config.bus_speed * 125)/4;\r\nval64 = RTI_DATA1_MEM_RX_TIMER_VAL(count);\r\n} else\r\nval64 = RTI_DATA1_MEM_RX_TIMER_VAL(0xFFF);\r\nval64 |= RTI_DATA1_MEM_RX_URNG_A(0xA) |\r\nRTI_DATA1_MEM_RX_URNG_B(0x10) |\r\nRTI_DATA1_MEM_RX_URNG_C(0x30) |\r\nRTI_DATA1_MEM_RX_TIMER_AC_EN;\r\nwriteq(val64, &bar0->rti_data1_mem);\r\nval64 = RTI_DATA2_MEM_RX_UFC_A(0x1) |\r\nRTI_DATA2_MEM_RX_UFC_B(0x2) ;\r\nif (nic->config.intr_type == MSI_X)\r\nval64 |= (RTI_DATA2_MEM_RX_UFC_C(0x20) |\r\nRTI_DATA2_MEM_RX_UFC_D(0x40));\r\nelse\r\nval64 |= (RTI_DATA2_MEM_RX_UFC_C(0x40) |\r\nRTI_DATA2_MEM_RX_UFC_D(0x80));\r\nwriteq(val64, &bar0->rti_data2_mem);\r\nfor (i = 0; i < config->rx_ring_num; i++) {\r\nval64 = RTI_CMD_MEM_WE |\r\nRTI_CMD_MEM_STROBE_NEW_CMD |\r\nRTI_CMD_MEM_OFFSET(i);\r\nwriteq(val64, &bar0->rti_command_mem);\r\ntime = 0;\r\nwhile (true) {\r\nval64 = readq(&bar0->rti_command_mem);\r\nif (!(val64 & RTI_CMD_MEM_STROBE_NEW_CMD))\r\nbreak;\r\nif (time > 10) {\r\nDBG_PRINT(ERR_DBG, "%s: RTI init failed\n",\r\ndev->name);\r\nreturn -ENODEV;\r\n}\r\ntime++;\r\nmsleep(50);\r\n}\r\n}\r\nwriteq(0xffbbffbbffbbffbbULL, &bar0->mc_pause_thresh_q0q3);\r\nwriteq(0xffbbffbbffbbffbbULL, &bar0->mc_pause_thresh_q4q7);\r\nadd = &bar0->mac_cfg;\r\nval64 = readq(&bar0->mac_cfg);\r\nval64 &= ~(MAC_CFG_RMAC_STRIP_PAD);\r\nwriteq(RMAC_CFG_KEY(0x4C0D), &bar0->rmac_cfg_key);\r\nwritel((u32) (val64), add);\r\nwriteq(RMAC_CFG_KEY(0x4C0D), &bar0->rmac_cfg_key);\r\nwritel((u32) (val64 >> 32), (add + 4));\r\nval64 = readq(&bar0->mac_cfg);\r\nadd = &bar0->mac_cfg;\r\nval64 = readq(&bar0->mac_cfg);\r\nval64 |= MAC_CFG_RMAC_STRIP_FCS;\r\nif (nic->device_type == XFRAME_II_DEVICE)\r\nwriteq(val64, &bar0->mac_cfg);\r\nelse {\r\nwriteq(RMAC_CFG_KEY(0x4C0D), &bar0->rmac_cfg_key);\r\nwritel((u32) (val64), add);\r\nwriteq(RMAC_CFG_KEY(0x4C0D), &bar0->rmac_cfg_key);\r\nwritel((u32) (val64 >> 32), (add + 4));\r\n}\r\nval64 = readq(&bar0->rmac_pause_cfg);\r\nval64 &= ~(RMAC_PAUSE_HG_PTIME(0xffff));\r\nval64 |= RMAC_PAUSE_HG_PTIME(nic->mac_control.rmac_pause_time);\r\nwriteq(val64, &bar0->rmac_pause_cfg);\r\nval64 = 0;\r\nfor (i = 0; i < 4; i++) {\r\nval64 |= (((u64)0xFF00 |\r\nnic->mac_control.mc_pause_threshold_q0q3)\r\n<< (i * 2 * 8));\r\n}\r\nwriteq(val64, &bar0->mc_pause_thresh_q0q3);\r\nval64 = 0;\r\nfor (i = 0; i < 4; i++) {\r\nval64 |= (((u64)0xFF00 |\r\nnic->mac_control.mc_pause_threshold_q4q7)\r\n<< (i * 2 * 8));\r\n}\r\nwriteq(val64, &bar0->mc_pause_thresh_q4q7);\r\nval64 = readq(&bar0->pic_control);\r\nval64 |= PIC_CNTL_SHARED_SPLITS(shared_splits);\r\nwriteq(val64, &bar0->pic_control);\r\nif (nic->config.bus_speed == 266) {\r\nwriteq(TXREQTO_VAL(0x7f) | TXREQTO_EN, &bar0->txreqtimeout);\r\nwriteq(0x0, &bar0->read_retry_delay);\r\nwriteq(0x0, &bar0->write_retry_delay);\r\n}\r\nif (nic->device_type == XFRAME_II_DEVICE) {\r\nval64 = FAULT_BEHAVIOUR | EXT_REQ_EN |\r\nMISC_LINK_STABILITY_PRD(3);\r\nwriteq(val64, &bar0->misc_control);\r\nval64 = readq(&bar0->pic_control2);\r\nval64 &= ~(s2BIT(13)|s2BIT(14)|s2BIT(15));\r\nwriteq(val64, &bar0->pic_control2);\r\n}\r\nif (strstr(nic->product_name, "CX4")) {\r\nval64 = TMAC_AVG_IPG(0x17);\r\nwriteq(val64, &bar0->tmac_avg_ipg);\r\n}\r\nreturn SUCCESS;\r\n}\r\nstatic int s2io_link_fault_indication(struct s2io_nic *nic)\r\n{\r\nif (nic->device_type == XFRAME_II_DEVICE)\r\nreturn LINK_UP_DOWN_INTERRUPT;\r\nelse\r\nreturn MAC_RMAC_ERR_TIMER;\r\n}\r\nstatic void do_s2io_write_bits(u64 value, int flag, void __iomem *addr)\r\n{\r\nu64 temp64;\r\ntemp64 = readq(addr);\r\nif (flag == ENABLE_INTRS)\r\ntemp64 &= ~((u64)value);\r\nelse\r\ntemp64 |= ((u64)value);\r\nwriteq(temp64, addr);\r\n}\r\nstatic void en_dis_err_alarms(struct s2io_nic *nic, u16 mask, int flag)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = nic->bar0;\r\nregister u64 gen_int_mask = 0;\r\nu64 interruptible;\r\nwriteq(DISABLE_ALL_INTRS, &bar0->general_int_mask);\r\nif (mask & TX_DMA_INTR) {\r\ngen_int_mask |= TXDMA_INT_M;\r\ndo_s2io_write_bits(TXDMA_TDA_INT | TXDMA_PFC_INT |\r\nTXDMA_PCC_INT | TXDMA_TTI_INT |\r\nTXDMA_LSO_INT | TXDMA_TPA_INT |\r\nTXDMA_SM_INT, flag, &bar0->txdma_int_mask);\r\ndo_s2io_write_bits(PFC_ECC_DB_ERR | PFC_SM_ERR_ALARM |\r\nPFC_MISC_0_ERR | PFC_MISC_1_ERR |\r\nPFC_PCIX_ERR | PFC_ECC_SG_ERR, flag,\r\n&bar0->pfc_err_mask);\r\ndo_s2io_write_bits(TDA_Fn_ECC_DB_ERR | TDA_SM0_ERR_ALARM |\r\nTDA_SM1_ERR_ALARM | TDA_Fn_ECC_SG_ERR |\r\nTDA_PCIX_ERR, flag, &bar0->tda_err_mask);\r\ndo_s2io_write_bits(PCC_FB_ECC_DB_ERR | PCC_TXB_ECC_DB_ERR |\r\nPCC_SM_ERR_ALARM | PCC_WR_ERR_ALARM |\r\nPCC_N_SERR | PCC_6_COF_OV_ERR |\r\nPCC_7_COF_OV_ERR | PCC_6_LSO_OV_ERR |\r\nPCC_7_LSO_OV_ERR | PCC_FB_ECC_SG_ERR |\r\nPCC_TXB_ECC_SG_ERR,\r\nflag, &bar0->pcc_err_mask);\r\ndo_s2io_write_bits(TTI_SM_ERR_ALARM | TTI_ECC_SG_ERR |\r\nTTI_ECC_DB_ERR, flag, &bar0->tti_err_mask);\r\ndo_s2io_write_bits(LSO6_ABORT | LSO7_ABORT |\r\nLSO6_SM_ERR_ALARM | LSO7_SM_ERR_ALARM |\r\nLSO6_SEND_OFLOW | LSO7_SEND_OFLOW,\r\nflag, &bar0->lso_err_mask);\r\ndo_s2io_write_bits(TPA_SM_ERR_ALARM | TPA_TX_FRM_DROP,\r\nflag, &bar0->tpa_err_mask);\r\ndo_s2io_write_bits(SM_SM_ERR_ALARM, flag, &bar0->sm_err_mask);\r\n}\r\nif (mask & TX_MAC_INTR) {\r\ngen_int_mask |= TXMAC_INT_M;\r\ndo_s2io_write_bits(MAC_INT_STATUS_TMAC_INT, flag,\r\n&bar0->mac_int_mask);\r\ndo_s2io_write_bits(TMAC_TX_BUF_OVRN | TMAC_TX_SM_ERR |\r\nTMAC_ECC_SG_ERR | TMAC_ECC_DB_ERR |\r\nTMAC_DESC_ECC_SG_ERR | TMAC_DESC_ECC_DB_ERR,\r\nflag, &bar0->mac_tmac_err_mask);\r\n}\r\nif (mask & TX_XGXS_INTR) {\r\ngen_int_mask |= TXXGXS_INT_M;\r\ndo_s2io_write_bits(XGXS_INT_STATUS_TXGXS, flag,\r\n&bar0->xgxs_int_mask);\r\ndo_s2io_write_bits(TXGXS_ESTORE_UFLOW | TXGXS_TX_SM_ERR |\r\nTXGXS_ECC_SG_ERR | TXGXS_ECC_DB_ERR,\r\nflag, &bar0->xgxs_txgxs_err_mask);\r\n}\r\nif (mask & RX_DMA_INTR) {\r\ngen_int_mask |= RXDMA_INT_M;\r\ndo_s2io_write_bits(RXDMA_INT_RC_INT_M | RXDMA_INT_RPA_INT_M |\r\nRXDMA_INT_RDA_INT_M | RXDMA_INT_RTI_INT_M,\r\nflag, &bar0->rxdma_int_mask);\r\ndo_s2io_write_bits(RC_PRCn_ECC_DB_ERR | RC_FTC_ECC_DB_ERR |\r\nRC_PRCn_SM_ERR_ALARM | RC_FTC_SM_ERR_ALARM |\r\nRC_PRCn_ECC_SG_ERR | RC_FTC_ECC_SG_ERR |\r\nRC_RDA_FAIL_WR_Rn, flag, &bar0->rc_err_mask);\r\ndo_s2io_write_bits(PRC_PCI_AB_RD_Rn | PRC_PCI_AB_WR_Rn |\r\nPRC_PCI_AB_F_WR_Rn | PRC_PCI_DP_RD_Rn |\r\nPRC_PCI_DP_WR_Rn | PRC_PCI_DP_F_WR_Rn, flag,\r\n&bar0->prc_pcix_err_mask);\r\ndo_s2io_write_bits(RPA_SM_ERR_ALARM | RPA_CREDIT_ERR |\r\nRPA_ECC_SG_ERR | RPA_ECC_DB_ERR, flag,\r\n&bar0->rpa_err_mask);\r\ndo_s2io_write_bits(RDA_RXDn_ECC_DB_ERR | RDA_FRM_ECC_DB_N_AERR |\r\nRDA_SM1_ERR_ALARM | RDA_SM0_ERR_ALARM |\r\nRDA_RXD_ECC_DB_SERR | RDA_RXDn_ECC_SG_ERR |\r\nRDA_FRM_ECC_SG_ERR |\r\nRDA_MISC_ERR|RDA_PCIX_ERR,\r\nflag, &bar0->rda_err_mask);\r\ndo_s2io_write_bits(RTI_SM_ERR_ALARM |\r\nRTI_ECC_SG_ERR | RTI_ECC_DB_ERR,\r\nflag, &bar0->rti_err_mask);\r\n}\r\nif (mask & RX_MAC_INTR) {\r\ngen_int_mask |= RXMAC_INT_M;\r\ndo_s2io_write_bits(MAC_INT_STATUS_RMAC_INT, flag,\r\n&bar0->mac_int_mask);\r\ninterruptible = (RMAC_RX_BUFF_OVRN | RMAC_RX_SM_ERR |\r\nRMAC_UNUSED_INT | RMAC_SINGLE_ECC_ERR |\r\nRMAC_DOUBLE_ECC_ERR);\r\nif (s2io_link_fault_indication(nic) == MAC_RMAC_ERR_TIMER)\r\ninterruptible |= RMAC_LINK_STATE_CHANGE_INT;\r\ndo_s2io_write_bits(interruptible,\r\nflag, &bar0->mac_rmac_err_mask);\r\n}\r\nif (mask & RX_XGXS_INTR) {\r\ngen_int_mask |= RXXGXS_INT_M;\r\ndo_s2io_write_bits(XGXS_INT_STATUS_RXGXS, flag,\r\n&bar0->xgxs_int_mask);\r\ndo_s2io_write_bits(RXGXS_ESTORE_OFLOW | RXGXS_RX_SM_ERR, flag,\r\n&bar0->xgxs_rxgxs_err_mask);\r\n}\r\nif (mask & MC_INTR) {\r\ngen_int_mask |= MC_INT_M;\r\ndo_s2io_write_bits(MC_INT_MASK_MC_INT,\r\nflag, &bar0->mc_int_mask);\r\ndo_s2io_write_bits(MC_ERR_REG_SM_ERR | MC_ERR_REG_ECC_ALL_SNG |\r\nMC_ERR_REG_ECC_ALL_DBL | PLL_LOCK_N, flag,\r\n&bar0->mc_err_mask);\r\n}\r\nnic->general_int_mask = gen_int_mask;\r\nnic->general_int_mask = 0;\r\n}\r\nstatic void en_dis_able_nic_intrs(struct s2io_nic *nic, u16 mask, int flag)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = nic->bar0;\r\nregister u64 temp64 = 0, intr_mask = 0;\r\nintr_mask = nic->general_int_mask;\r\nif (mask & TX_PIC_INTR) {\r\nintr_mask |= TXPIC_INT_M;\r\nif (flag == ENABLE_INTRS) {\r\nif (s2io_link_fault_indication(nic) ==\r\nLINK_UP_DOWN_INTERRUPT) {\r\ndo_s2io_write_bits(PIC_INT_GPIO, flag,\r\n&bar0->pic_int_mask);\r\ndo_s2io_write_bits(GPIO_INT_MASK_LINK_UP, flag,\r\n&bar0->gpio_int_mask);\r\n} else\r\nwriteq(DISABLE_ALL_INTRS, &bar0->pic_int_mask);\r\n} else if (flag == DISABLE_INTRS) {\r\nwriteq(DISABLE_ALL_INTRS, &bar0->pic_int_mask);\r\n}\r\n}\r\nif (mask & TX_TRAFFIC_INTR) {\r\nintr_mask |= TXTRAFFIC_INT_M;\r\nif (flag == ENABLE_INTRS) {\r\nwriteq(0x0, &bar0->tx_traffic_mask);\r\n} else if (flag == DISABLE_INTRS) {\r\nwriteq(DISABLE_ALL_INTRS, &bar0->tx_traffic_mask);\r\n}\r\n}\r\nif (mask & RX_TRAFFIC_INTR) {\r\nintr_mask |= RXTRAFFIC_INT_M;\r\nif (flag == ENABLE_INTRS) {\r\nwriteq(0x0, &bar0->rx_traffic_mask);\r\n} else if (flag == DISABLE_INTRS) {\r\nwriteq(DISABLE_ALL_INTRS, &bar0->rx_traffic_mask);\r\n}\r\n}\r\ntemp64 = readq(&bar0->general_int_mask);\r\nif (flag == ENABLE_INTRS)\r\ntemp64 &= ~((u64)intr_mask);\r\nelse\r\ntemp64 = DISABLE_ALL_INTRS;\r\nwriteq(temp64, &bar0->general_int_mask);\r\nnic->general_int_mask = readq(&bar0->general_int_mask);\r\n}\r\nstatic int verify_pcc_quiescent(struct s2io_nic *sp, int flag)\r\n{\r\nint ret = 0, herc;\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nu64 val64 = readq(&bar0->adapter_status);\r\nherc = (sp->device_type == XFRAME_II_DEVICE);\r\nif (flag == false) {\r\nif ((!herc && (sp->pdev->revision >= 4)) || herc) {\r\nif (!(val64 & ADAPTER_STATUS_RMAC_PCC_IDLE))\r\nret = 1;\r\n} else {\r\nif (!(val64 & ADAPTER_STATUS_RMAC_PCC_FOUR_IDLE))\r\nret = 1;\r\n}\r\n} else {\r\nif ((!herc && (sp->pdev->revision >= 4)) || herc) {\r\nif (((val64 & ADAPTER_STATUS_RMAC_PCC_IDLE) ==\r\nADAPTER_STATUS_RMAC_PCC_IDLE))\r\nret = 1;\r\n} else {\r\nif (((val64 & ADAPTER_STATUS_RMAC_PCC_FOUR_IDLE) ==\r\nADAPTER_STATUS_RMAC_PCC_FOUR_IDLE))\r\nret = 1;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic int verify_xena_quiescence(struct s2io_nic *sp)\r\n{\r\nint mode;\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nu64 val64 = readq(&bar0->adapter_status);\r\nmode = s2io_verify_pci_mode(sp);\r\nif (!(val64 & ADAPTER_STATUS_TDMA_READY)) {\r\nDBG_PRINT(ERR_DBG, "TDMA is not ready!\n");\r\nreturn 0;\r\n}\r\nif (!(val64 & ADAPTER_STATUS_RDMA_READY)) {\r\nDBG_PRINT(ERR_DBG, "RDMA is not ready!\n");\r\nreturn 0;\r\n}\r\nif (!(val64 & ADAPTER_STATUS_PFC_READY)) {\r\nDBG_PRINT(ERR_DBG, "PFC is not ready!\n");\r\nreturn 0;\r\n}\r\nif (!(val64 & ADAPTER_STATUS_TMAC_BUF_EMPTY)) {\r\nDBG_PRINT(ERR_DBG, "TMAC BUF is not empty!\n");\r\nreturn 0;\r\n}\r\nif (!(val64 & ADAPTER_STATUS_PIC_QUIESCENT)) {\r\nDBG_PRINT(ERR_DBG, "PIC is not QUIESCENT!\n");\r\nreturn 0;\r\n}\r\nif (!(val64 & ADAPTER_STATUS_MC_DRAM_READY)) {\r\nDBG_PRINT(ERR_DBG, "MC_DRAM is not ready!\n");\r\nreturn 0;\r\n}\r\nif (!(val64 & ADAPTER_STATUS_MC_QUEUES_READY)) {\r\nDBG_PRINT(ERR_DBG, "MC_QUEUES is not ready!\n");\r\nreturn 0;\r\n}\r\nif (!(val64 & ADAPTER_STATUS_M_PLL_LOCK)) {\r\nDBG_PRINT(ERR_DBG, "M_PLL is not locked!\n");\r\nreturn 0;\r\n}\r\nif (!(val64 & ADAPTER_STATUS_P_PLL_LOCK) &&\r\nsp->device_type == XFRAME_II_DEVICE &&\r\nmode != PCI_MODE_PCI_33) {\r\nDBG_PRINT(ERR_DBG, "P_PLL is not locked!\n");\r\nreturn 0;\r\n}\r\nif (!((val64 & ADAPTER_STATUS_RC_PRC_QUIESCENT) ==\r\nADAPTER_STATUS_RC_PRC_QUIESCENT)) {\r\nDBG_PRINT(ERR_DBG, "RC_PRC is not QUIESCENT!\n");\r\nreturn 0;\r\n}\r\nreturn 1;\r\n}\r\nstatic void fix_mac_address(struct s2io_nic *sp)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nint i = 0;\r\nwhile (fix_mac[i] != END_SIGN) {\r\nwriteq(fix_mac[i++], &bar0->gpio_control);\r\nudelay(10);\r\n(void) readq(&bar0->gpio_control);\r\n}\r\n}\r\nstatic int start_nic(struct s2io_nic *nic)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = nic->bar0;\r\nstruct net_device *dev = nic->dev;\r\nregister u64 val64 = 0;\r\nu16 subid, i;\r\nstruct config_param *config = &nic->config;\r\nstruct mac_info *mac_control = &nic->mac_control;\r\nfor (i = 0; i < config->rx_ring_num; i++) {\r\nstruct ring_info *ring = &mac_control->rings[i];\r\nwriteq((u64)ring->rx_blocks[0].block_dma_addr,\r\n&bar0->prc_rxd0_n[i]);\r\nval64 = readq(&bar0->prc_ctrl_n[i]);\r\nif (nic->rxd_mode == RXD_MODE_1)\r\nval64 |= PRC_CTRL_RC_ENABLED;\r\nelse\r\nval64 |= PRC_CTRL_RC_ENABLED | PRC_CTRL_RING_MODE_3;\r\nif (nic->device_type == XFRAME_II_DEVICE)\r\nval64 |= PRC_CTRL_GROUP_READS;\r\nval64 &= ~PRC_CTRL_RXD_BACKOFF_INTERVAL(0xFFFFFF);\r\nval64 |= PRC_CTRL_RXD_BACKOFF_INTERVAL(0x1000);\r\nwriteq(val64, &bar0->prc_ctrl_n[i]);\r\n}\r\nif (nic->rxd_mode == RXD_MODE_3B) {\r\nval64 = readq(&bar0->rx_pa_cfg);\r\nval64 |= RX_PA_CFG_IGNORE_L2_ERR;\r\nwriteq(val64, &bar0->rx_pa_cfg);\r\n}\r\nif (vlan_tag_strip == 0) {\r\nval64 = readq(&bar0->rx_pa_cfg);\r\nval64 &= ~RX_PA_CFG_STRIP_VLAN_TAG;\r\nwriteq(val64, &bar0->rx_pa_cfg);\r\nnic->vlan_strip_flag = 0;\r\n}\r\nval64 = readq(&bar0->mc_rldram_mrs);\r\nval64 |= MC_RLDRAM_QUEUE_SIZE_ENABLE | MC_RLDRAM_MRS_ENABLE;\r\nSPECIAL_REG_WRITE(val64, &bar0->mc_rldram_mrs, UF);\r\nval64 = readq(&bar0->mc_rldram_mrs);\r\nmsleep(100);\r\nval64 = readq(&bar0->adapter_control);\r\nval64 &= ~ADAPTER_ECC_EN;\r\nwriteq(val64, &bar0->adapter_control);\r\nval64 = readq(&bar0->adapter_status);\r\nif (!verify_xena_quiescence(nic)) {\r\nDBG_PRINT(ERR_DBG, "%s: device is not ready, "\r\n"Adapter status reads: 0x%llx\n",\r\ndev->name, (unsigned long long)val64);\r\nreturn FAILURE;\r\n}\r\nval64 = readq(&bar0->adapter_control);\r\nval64 |= ADAPTER_EOI_TX_ON;\r\nwriteq(val64, &bar0->adapter_control);\r\nif (s2io_link_fault_indication(nic) == MAC_RMAC_ERR_TIMER) {\r\nschedule_work(&nic->set_link_task);\r\n}\r\nsubid = nic->pdev->subsystem_device;\r\nif (((subid & 0xFF) >= 0x07) &&\r\n(nic->device_type == XFRAME_I_DEVICE)) {\r\nval64 = readq(&bar0->gpio_control);\r\nval64 |= 0x0000800000000000ULL;\r\nwriteq(val64, &bar0->gpio_control);\r\nval64 = 0x0411040400000000ULL;\r\nwriteq(val64, (void __iomem *)bar0 + 0x2700);\r\n}\r\nreturn SUCCESS;\r\n}\r\nstatic struct sk_buff *s2io_txdl_getskb(struct fifo_info *fifo_data,\r\nstruct TxD *txdlp, int get_off)\r\n{\r\nstruct s2io_nic *nic = fifo_data->nic;\r\nstruct sk_buff *skb;\r\nstruct TxD *txds;\r\nu16 j, frg_cnt;\r\ntxds = txdlp;\r\nif (txds->Host_Control == (u64)(long)fifo_data->ufo_in_band_v) {\r\npci_unmap_single(nic->pdev, (dma_addr_t)txds->Buffer_Pointer,\r\nsizeof(u64), PCI_DMA_TODEVICE);\r\ntxds++;\r\n}\r\nskb = (struct sk_buff *)((unsigned long)txds->Host_Control);\r\nif (!skb) {\r\nmemset(txdlp, 0, (sizeof(struct TxD) * fifo_data->max_txds));\r\nreturn NULL;\r\n}\r\npci_unmap_single(nic->pdev, (dma_addr_t)txds->Buffer_Pointer,\r\nskb_headlen(skb), PCI_DMA_TODEVICE);\r\nfrg_cnt = skb_shinfo(skb)->nr_frags;\r\nif (frg_cnt) {\r\ntxds++;\r\nfor (j = 0; j < frg_cnt; j++, txds++) {\r\nconst skb_frag_t *frag = &skb_shinfo(skb)->frags[j];\r\nif (!txds->Buffer_Pointer)\r\nbreak;\r\npci_unmap_page(nic->pdev,\r\n(dma_addr_t)txds->Buffer_Pointer,\r\nskb_frag_size(frag), PCI_DMA_TODEVICE);\r\n}\r\n}\r\nmemset(txdlp, 0, (sizeof(struct TxD) * fifo_data->max_txds));\r\nreturn skb;\r\n}\r\nstatic void free_tx_buffers(struct s2io_nic *nic)\r\n{\r\nstruct net_device *dev = nic->dev;\r\nstruct sk_buff *skb;\r\nstruct TxD *txdp;\r\nint i, j;\r\nint cnt = 0;\r\nstruct config_param *config = &nic->config;\r\nstruct mac_info *mac_control = &nic->mac_control;\r\nstruct stat_block *stats = mac_control->stats_info;\r\nstruct swStat *swstats = &stats->sw_stat;\r\nfor (i = 0; i < config->tx_fifo_num; i++) {\r\nstruct tx_fifo_config *tx_cfg = &config->tx_cfg[i];\r\nstruct fifo_info *fifo = &mac_control->fifos[i];\r\nunsigned long flags;\r\nspin_lock_irqsave(&fifo->tx_lock, flags);\r\nfor (j = 0; j < tx_cfg->fifo_len; j++) {\r\ntxdp = fifo->list_info[j].list_virt_addr;\r\nskb = s2io_txdl_getskb(&mac_control->fifos[i], txdp, j);\r\nif (skb) {\r\nswstats->mem_freed += skb->truesize;\r\ndev_kfree_skb(skb);\r\ncnt++;\r\n}\r\n}\r\nDBG_PRINT(INTR_DBG,\r\n"%s: forcibly freeing %d skbs on FIFO%d\n",\r\ndev->name, cnt, i);\r\nfifo->tx_curr_get_info.offset = 0;\r\nfifo->tx_curr_put_info.offset = 0;\r\nspin_unlock_irqrestore(&fifo->tx_lock, flags);\r\n}\r\n}\r\nstatic void stop_nic(struct s2io_nic *nic)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = nic->bar0;\r\nregister u64 val64 = 0;\r\nu16 interruptible;\r\nen_dis_err_alarms(nic, ENA_ALL_INTRS, DISABLE_INTRS);\r\ninterruptible = TX_TRAFFIC_INTR | RX_TRAFFIC_INTR;\r\ninterruptible |= TX_PIC_INTR;\r\nen_dis_able_nic_intrs(nic, interruptible, DISABLE_INTRS);\r\nval64 = readq(&bar0->adapter_control);\r\nval64 &= ~(ADAPTER_CNTL_EN);\r\nwriteq(val64, &bar0->adapter_control);\r\n}\r\nstatic int fill_rx_buffers(struct s2io_nic *nic, struct ring_info *ring,\r\nint from_card_up)\r\n{\r\nstruct sk_buff *skb;\r\nstruct RxD_t *rxdp;\r\nint off, size, block_no, block_no1;\r\nu32 alloc_tab = 0;\r\nu32 alloc_cnt;\r\nu64 tmp;\r\nstruct buffAdd *ba;\r\nstruct RxD_t *first_rxdp = NULL;\r\nu64 Buffer0_ptr = 0, Buffer1_ptr = 0;\r\nint rxd_index = 0;\r\nstruct RxD1 *rxdp1;\r\nstruct RxD3 *rxdp3;\r\nstruct swStat *swstats = &ring->nic->mac_control.stats_info->sw_stat;\r\nalloc_cnt = ring->pkt_cnt - ring->rx_bufs_left;\r\nblock_no1 = ring->rx_curr_get_info.block_index;\r\nwhile (alloc_tab < alloc_cnt) {\r\nblock_no = ring->rx_curr_put_info.block_index;\r\noff = ring->rx_curr_put_info.offset;\r\nrxdp = ring->rx_blocks[block_no].rxds[off].virt_addr;\r\nrxd_index = off + 1;\r\nif (block_no)\r\nrxd_index += (block_no * ring->rxd_count);\r\nif ((block_no == block_no1) &&\r\n(off == ring->rx_curr_get_info.offset) &&\r\n(rxdp->Host_Control)) {\r\nDBG_PRINT(INTR_DBG, "%s: Get and Put info equated\n",\r\nring->dev->name);\r\ngoto end;\r\n}\r\nif (off && (off == ring->rxd_count)) {\r\nring->rx_curr_put_info.block_index++;\r\nif (ring->rx_curr_put_info.block_index ==\r\nring->block_count)\r\nring->rx_curr_put_info.block_index = 0;\r\nblock_no = ring->rx_curr_put_info.block_index;\r\noff = 0;\r\nring->rx_curr_put_info.offset = off;\r\nrxdp = ring->rx_blocks[block_no].block_virt_addr;\r\nDBG_PRINT(INTR_DBG, "%s: Next block at: %p\n",\r\nring->dev->name, rxdp);\r\n}\r\nif ((rxdp->Control_1 & RXD_OWN_XENA) &&\r\n((ring->rxd_mode == RXD_MODE_3B) &&\r\n(rxdp->Control_2 & s2BIT(0)))) {\r\nring->rx_curr_put_info.offset = off;\r\ngoto end;\r\n}\r\nsize = ring->mtu +\r\nHEADER_ETHERNET_II_802_3_SIZE +\r\nHEADER_802_2_SIZE + HEADER_SNAP_SIZE;\r\nif (ring->rxd_mode == RXD_MODE_1)\r\nsize += NET_IP_ALIGN;\r\nelse\r\nsize = ring->mtu + ALIGN_SIZE + BUF0_LEN + 4;\r\nskb = netdev_alloc_skb(nic->dev, size);\r\nif (!skb) {\r\nDBG_PRINT(INFO_DBG, "%s: Could not allocate skb\n",\r\nring->dev->name);\r\nif (first_rxdp) {\r\nwmb();\r\nfirst_rxdp->Control_1 |= RXD_OWN_XENA;\r\n}\r\nswstats->mem_alloc_fail_cnt++;\r\nreturn -ENOMEM ;\r\n}\r\nswstats->mem_allocated += skb->truesize;\r\nif (ring->rxd_mode == RXD_MODE_1) {\r\nrxdp1 = (struct RxD1 *)rxdp;\r\nmemset(rxdp, 0, sizeof(struct RxD1));\r\nskb_reserve(skb, NET_IP_ALIGN);\r\nrxdp1->Buffer0_ptr =\r\npci_map_single(ring->pdev, skb->data,\r\nsize - NET_IP_ALIGN,\r\nPCI_DMA_FROMDEVICE);\r\nif (pci_dma_mapping_error(nic->pdev,\r\nrxdp1->Buffer0_ptr))\r\ngoto pci_map_failed;\r\nrxdp->Control_2 =\r\nSET_BUFFER0_SIZE_1(size - NET_IP_ALIGN);\r\nrxdp->Host_Control = (unsigned long)skb;\r\n} else if (ring->rxd_mode == RXD_MODE_3B) {\r\nrxdp3 = (struct RxD3 *)rxdp;\r\nBuffer0_ptr = rxdp3->Buffer0_ptr;\r\nBuffer1_ptr = rxdp3->Buffer1_ptr;\r\nmemset(rxdp, 0, sizeof(struct RxD3));\r\nrxdp3->Buffer0_ptr = Buffer0_ptr;\r\nrxdp3->Buffer1_ptr = Buffer1_ptr;\r\nba = &ring->ba[block_no][off];\r\nskb_reserve(skb, BUF0_LEN);\r\ntmp = (u64)(unsigned long)skb->data;\r\ntmp += ALIGN_SIZE;\r\ntmp &= ~ALIGN_SIZE;\r\nskb->data = (void *) (unsigned long)tmp;\r\nskb_reset_tail_pointer(skb);\r\nif (from_card_up) {\r\nrxdp3->Buffer0_ptr =\r\npci_map_single(ring->pdev, ba->ba_0,\r\nBUF0_LEN,\r\nPCI_DMA_FROMDEVICE);\r\nif (pci_dma_mapping_error(nic->pdev,\r\nrxdp3->Buffer0_ptr))\r\ngoto pci_map_failed;\r\n} else\r\npci_dma_sync_single_for_device(ring->pdev,\r\n(dma_addr_t)rxdp3->Buffer0_ptr,\r\nBUF0_LEN,\r\nPCI_DMA_FROMDEVICE);\r\nrxdp->Control_2 = SET_BUFFER0_SIZE_3(BUF0_LEN);\r\nif (ring->rxd_mode == RXD_MODE_3B) {\r\nrxdp3->Buffer2_ptr = pci_map_single(ring->pdev,\r\nskb->data,\r\nring->mtu + 4,\r\nPCI_DMA_FROMDEVICE);\r\nif (pci_dma_mapping_error(nic->pdev,\r\nrxdp3->Buffer2_ptr))\r\ngoto pci_map_failed;\r\nif (from_card_up) {\r\nrxdp3->Buffer1_ptr =\r\npci_map_single(ring->pdev,\r\nba->ba_1,\r\nBUF1_LEN,\r\nPCI_DMA_FROMDEVICE);\r\nif (pci_dma_mapping_error(nic->pdev,\r\nrxdp3->Buffer1_ptr)) {\r\npci_unmap_single(ring->pdev,\r\n(dma_addr_t)(unsigned long)\r\nskb->data,\r\nring->mtu + 4,\r\nPCI_DMA_FROMDEVICE);\r\ngoto pci_map_failed;\r\n}\r\n}\r\nrxdp->Control_2 |= SET_BUFFER1_SIZE_3(1);\r\nrxdp->Control_2 |= SET_BUFFER2_SIZE_3\r\n(ring->mtu + 4);\r\n}\r\nrxdp->Control_2 |= s2BIT(0);\r\nrxdp->Host_Control = (unsigned long) (skb);\r\n}\r\nif (alloc_tab & ((1 << rxsync_frequency) - 1))\r\nrxdp->Control_1 |= RXD_OWN_XENA;\r\noff++;\r\nif (off == (ring->rxd_count + 1))\r\noff = 0;\r\nring->rx_curr_put_info.offset = off;\r\nrxdp->Control_2 |= SET_RXD_MARKER;\r\nif (!(alloc_tab & ((1 << rxsync_frequency) - 1))) {\r\nif (first_rxdp) {\r\nwmb();\r\nfirst_rxdp->Control_1 |= RXD_OWN_XENA;\r\n}\r\nfirst_rxdp = rxdp;\r\n}\r\nring->rx_bufs_left += 1;\r\nalloc_tab++;\r\n}\r\nend:\r\nif (first_rxdp) {\r\nwmb();\r\nfirst_rxdp->Control_1 |= RXD_OWN_XENA;\r\n}\r\nreturn SUCCESS;\r\npci_map_failed:\r\nswstats->pci_map_fail_cnt++;\r\nswstats->mem_freed += skb->truesize;\r\ndev_kfree_skb_irq(skb);\r\nreturn -ENOMEM;\r\n}\r\nstatic void free_rxd_blk(struct s2io_nic *sp, int ring_no, int blk)\r\n{\r\nstruct net_device *dev = sp->dev;\r\nint j;\r\nstruct sk_buff *skb;\r\nstruct RxD_t *rxdp;\r\nstruct RxD1 *rxdp1;\r\nstruct RxD3 *rxdp3;\r\nstruct mac_info *mac_control = &sp->mac_control;\r\nstruct stat_block *stats = mac_control->stats_info;\r\nstruct swStat *swstats = &stats->sw_stat;\r\nfor (j = 0 ; j < rxd_count[sp->rxd_mode]; j++) {\r\nrxdp = mac_control->rings[ring_no].\r\nrx_blocks[blk].rxds[j].virt_addr;\r\nskb = (struct sk_buff *)((unsigned long)rxdp->Host_Control);\r\nif (!skb)\r\ncontinue;\r\nif (sp->rxd_mode == RXD_MODE_1) {\r\nrxdp1 = (struct RxD1 *)rxdp;\r\npci_unmap_single(sp->pdev,\r\n(dma_addr_t)rxdp1->Buffer0_ptr,\r\ndev->mtu +\r\nHEADER_ETHERNET_II_802_3_SIZE +\r\nHEADER_802_2_SIZE + HEADER_SNAP_SIZE,\r\nPCI_DMA_FROMDEVICE);\r\nmemset(rxdp, 0, sizeof(struct RxD1));\r\n} else if (sp->rxd_mode == RXD_MODE_3B) {\r\nrxdp3 = (struct RxD3 *)rxdp;\r\npci_unmap_single(sp->pdev,\r\n(dma_addr_t)rxdp3->Buffer0_ptr,\r\nBUF0_LEN,\r\nPCI_DMA_FROMDEVICE);\r\npci_unmap_single(sp->pdev,\r\n(dma_addr_t)rxdp3->Buffer1_ptr,\r\nBUF1_LEN,\r\nPCI_DMA_FROMDEVICE);\r\npci_unmap_single(sp->pdev,\r\n(dma_addr_t)rxdp3->Buffer2_ptr,\r\ndev->mtu + 4,\r\nPCI_DMA_FROMDEVICE);\r\nmemset(rxdp, 0, sizeof(struct RxD3));\r\n}\r\nswstats->mem_freed += skb->truesize;\r\ndev_kfree_skb(skb);\r\nmac_control->rings[ring_no].rx_bufs_left -= 1;\r\n}\r\n}\r\nstatic void free_rx_buffers(struct s2io_nic *sp)\r\n{\r\nstruct net_device *dev = sp->dev;\r\nint i, blk = 0, buf_cnt = 0;\r\nstruct config_param *config = &sp->config;\r\nstruct mac_info *mac_control = &sp->mac_control;\r\nfor (i = 0; i < config->rx_ring_num; i++) {\r\nstruct ring_info *ring = &mac_control->rings[i];\r\nfor (blk = 0; blk < rx_ring_sz[i]; blk++)\r\nfree_rxd_blk(sp, i, blk);\r\nring->rx_curr_put_info.block_index = 0;\r\nring->rx_curr_get_info.block_index = 0;\r\nring->rx_curr_put_info.offset = 0;\r\nring->rx_curr_get_info.offset = 0;\r\nring->rx_bufs_left = 0;\r\nDBG_PRINT(INIT_DBG, "%s: Freed 0x%x Rx Buffers on ring%d\n",\r\ndev->name, buf_cnt, i);\r\n}\r\n}\r\nstatic int s2io_chk_rx_buffers(struct s2io_nic *nic, struct ring_info *ring)\r\n{\r\nif (fill_rx_buffers(nic, ring, 0) == -ENOMEM) {\r\nDBG_PRINT(INFO_DBG, "%s: Out of memory in Rx Intr!!\n",\r\nring->dev->name);\r\n}\r\nreturn 0;\r\n}\r\nstatic int s2io_poll_msix(struct napi_struct *napi, int budget)\r\n{\r\nstruct ring_info *ring = container_of(napi, struct ring_info, napi);\r\nstruct net_device *dev = ring->dev;\r\nint pkts_processed = 0;\r\nu8 __iomem *addr = NULL;\r\nu8 val8 = 0;\r\nstruct s2io_nic *nic = netdev_priv(dev);\r\nstruct XENA_dev_config __iomem *bar0 = nic->bar0;\r\nint budget_org = budget;\r\nif (unlikely(!is_s2io_card_up(nic)))\r\nreturn 0;\r\npkts_processed = rx_intr_handler(ring, budget);\r\ns2io_chk_rx_buffers(nic, ring);\r\nif (pkts_processed < budget_org) {\r\nnapi_complete(napi);\r\naddr = (u8 __iomem *)&bar0->xmsi_mask_reg;\r\naddr += 7 - ring->ring_no;\r\nval8 = (ring->ring_no == 0) ? 0x3f : 0xbf;\r\nwriteb(val8, addr);\r\nval8 = readb(addr);\r\n}\r\nreturn pkts_processed;\r\n}\r\nstatic int s2io_poll_inta(struct napi_struct *napi, int budget)\r\n{\r\nstruct s2io_nic *nic = container_of(napi, struct s2io_nic, napi);\r\nint pkts_processed = 0;\r\nint ring_pkts_processed, i;\r\nstruct XENA_dev_config __iomem *bar0 = nic->bar0;\r\nint budget_org = budget;\r\nstruct config_param *config = &nic->config;\r\nstruct mac_info *mac_control = &nic->mac_control;\r\nif (unlikely(!is_s2io_card_up(nic)))\r\nreturn 0;\r\nfor (i = 0; i < config->rx_ring_num; i++) {\r\nstruct ring_info *ring = &mac_control->rings[i];\r\nring_pkts_processed = rx_intr_handler(ring, budget);\r\ns2io_chk_rx_buffers(nic, ring);\r\npkts_processed += ring_pkts_processed;\r\nbudget -= ring_pkts_processed;\r\nif (budget <= 0)\r\nbreak;\r\n}\r\nif (pkts_processed < budget_org) {\r\nnapi_complete(napi);\r\nwriteq(0, &bar0->rx_traffic_mask);\r\nreadl(&bar0->rx_traffic_mask);\r\n}\r\nreturn pkts_processed;\r\n}\r\nstatic void s2io_netpoll(struct net_device *dev)\r\n{\r\nstruct s2io_nic *nic = netdev_priv(dev);\r\nconst int irq = nic->pdev->irq;\r\nstruct XENA_dev_config __iomem *bar0 = nic->bar0;\r\nu64 val64 = 0xFFFFFFFFFFFFFFFFULL;\r\nint i;\r\nstruct config_param *config = &nic->config;\r\nstruct mac_info *mac_control = &nic->mac_control;\r\nif (pci_channel_offline(nic->pdev))\r\nreturn;\r\ndisable_irq(irq);\r\nwriteq(val64, &bar0->rx_traffic_int);\r\nwriteq(val64, &bar0->tx_traffic_int);\r\nfor (i = 0; i < config->tx_fifo_num; i++)\r\ntx_intr_handler(&mac_control->fifos[i]);\r\nfor (i = 0; i < config->rx_ring_num; i++) {\r\nstruct ring_info *ring = &mac_control->rings[i];\r\nrx_intr_handler(ring, 0);\r\n}\r\nfor (i = 0; i < config->rx_ring_num; i++) {\r\nstruct ring_info *ring = &mac_control->rings[i];\r\nif (fill_rx_buffers(nic, ring, 0) == -ENOMEM) {\r\nDBG_PRINT(INFO_DBG,\r\n"%s: Out of memory in Rx Netpoll!!\n",\r\ndev->name);\r\nbreak;\r\n}\r\n}\r\nenable_irq(irq);\r\n}\r\nstatic int rx_intr_handler(struct ring_info *ring_data, int budget)\r\n{\r\nint get_block, put_block;\r\nstruct rx_curr_get_info get_info, put_info;\r\nstruct RxD_t *rxdp;\r\nstruct sk_buff *skb;\r\nint pkt_cnt = 0, napi_pkts = 0;\r\nint i;\r\nstruct RxD1 *rxdp1;\r\nstruct RxD3 *rxdp3;\r\nget_info = ring_data->rx_curr_get_info;\r\nget_block = get_info.block_index;\r\nmemcpy(&put_info, &ring_data->rx_curr_put_info, sizeof(put_info));\r\nput_block = put_info.block_index;\r\nrxdp = ring_data->rx_blocks[get_block].rxds[get_info.offset].virt_addr;\r\nwhile (RXD_IS_UP2DT(rxdp)) {\r\nif ((get_block == put_block) &&\r\n(get_info.offset + 1) == put_info.offset) {\r\nDBG_PRINT(INTR_DBG, "%s: Ring Full\n",\r\nring_data->dev->name);\r\nbreak;\r\n}\r\nskb = (struct sk_buff *)((unsigned long)rxdp->Host_Control);\r\nif (skb == NULL) {\r\nDBG_PRINT(ERR_DBG, "%s: NULL skb in Rx Intr\n",\r\nring_data->dev->name);\r\nreturn 0;\r\n}\r\nif (ring_data->rxd_mode == RXD_MODE_1) {\r\nrxdp1 = (struct RxD1 *)rxdp;\r\npci_unmap_single(ring_data->pdev, (dma_addr_t)\r\nrxdp1->Buffer0_ptr,\r\nring_data->mtu +\r\nHEADER_ETHERNET_II_802_3_SIZE +\r\nHEADER_802_2_SIZE +\r\nHEADER_SNAP_SIZE,\r\nPCI_DMA_FROMDEVICE);\r\n} else if (ring_data->rxd_mode == RXD_MODE_3B) {\r\nrxdp3 = (struct RxD3 *)rxdp;\r\npci_dma_sync_single_for_cpu(ring_data->pdev,\r\n(dma_addr_t)rxdp3->Buffer0_ptr,\r\nBUF0_LEN,\r\nPCI_DMA_FROMDEVICE);\r\npci_unmap_single(ring_data->pdev,\r\n(dma_addr_t)rxdp3->Buffer2_ptr,\r\nring_data->mtu + 4,\r\nPCI_DMA_FROMDEVICE);\r\n}\r\nprefetch(skb->data);\r\nrx_osm_handler(ring_data, rxdp);\r\nget_info.offset++;\r\nring_data->rx_curr_get_info.offset = get_info.offset;\r\nrxdp = ring_data->rx_blocks[get_block].\r\nrxds[get_info.offset].virt_addr;\r\nif (get_info.offset == rxd_count[ring_data->rxd_mode]) {\r\nget_info.offset = 0;\r\nring_data->rx_curr_get_info.offset = get_info.offset;\r\nget_block++;\r\nif (get_block == ring_data->block_count)\r\nget_block = 0;\r\nring_data->rx_curr_get_info.block_index = get_block;\r\nrxdp = ring_data->rx_blocks[get_block].block_virt_addr;\r\n}\r\nif (ring_data->nic->config.napi) {\r\nbudget--;\r\nnapi_pkts++;\r\nif (!budget)\r\nbreak;\r\n}\r\npkt_cnt++;\r\nif ((indicate_max_pkts) && (pkt_cnt > indicate_max_pkts))\r\nbreak;\r\n}\r\nif (ring_data->lro) {\r\nfor (i = 0; i < MAX_LRO_SESSIONS; i++) {\r\nstruct lro *lro = &ring_data->lro0_n[i];\r\nif (lro->in_use) {\r\nupdate_L3L4_header(ring_data->nic, lro);\r\nqueue_rx_frame(lro->parent, lro->vlan_tag);\r\nclear_lro_session(lro);\r\n}\r\n}\r\n}\r\nreturn napi_pkts;\r\n}\r\nstatic void tx_intr_handler(struct fifo_info *fifo_data)\r\n{\r\nstruct s2io_nic *nic = fifo_data->nic;\r\nstruct tx_curr_get_info get_info, put_info;\r\nstruct sk_buff *skb = NULL;\r\nstruct TxD *txdlp;\r\nint pkt_cnt = 0;\r\nunsigned long flags = 0;\r\nu8 err_mask;\r\nstruct stat_block *stats = nic->mac_control.stats_info;\r\nstruct swStat *swstats = &stats->sw_stat;\r\nif (!spin_trylock_irqsave(&fifo_data->tx_lock, flags))\r\nreturn;\r\nget_info = fifo_data->tx_curr_get_info;\r\nmemcpy(&put_info, &fifo_data->tx_curr_put_info, sizeof(put_info));\r\ntxdlp = fifo_data->list_info[get_info.offset].list_virt_addr;\r\nwhile ((!(txdlp->Control_1 & TXD_LIST_OWN_XENA)) &&\r\n(get_info.offset != put_info.offset) &&\r\n(txdlp->Host_Control)) {\r\nif (txdlp->Control_1 & TXD_T_CODE) {\r\nunsigned long long err;\r\nerr = txdlp->Control_1 & TXD_T_CODE;\r\nif (err & 0x1) {\r\nswstats->parity_err_cnt++;\r\n}\r\nerr_mask = err >> 48;\r\nswitch (err_mask) {\r\ncase 2:\r\nswstats->tx_buf_abort_cnt++;\r\nbreak;\r\ncase 3:\r\nswstats->tx_desc_abort_cnt++;\r\nbreak;\r\ncase 7:\r\nswstats->tx_parity_err_cnt++;\r\nbreak;\r\ncase 10:\r\nswstats->tx_link_loss_cnt++;\r\nbreak;\r\ncase 15:\r\nswstats->tx_list_proc_err_cnt++;\r\nbreak;\r\n}\r\n}\r\nskb = s2io_txdl_getskb(fifo_data, txdlp, get_info.offset);\r\nif (skb == NULL) {\r\nspin_unlock_irqrestore(&fifo_data->tx_lock, flags);\r\nDBG_PRINT(ERR_DBG, "%s: NULL skb in Tx Free Intr\n",\r\n__func__);\r\nreturn;\r\n}\r\npkt_cnt++;\r\nswstats->mem_freed += skb->truesize;\r\ndev_kfree_skb_irq(skb);\r\nget_info.offset++;\r\nif (get_info.offset == get_info.fifo_len + 1)\r\nget_info.offset = 0;\r\ntxdlp = fifo_data->list_info[get_info.offset].list_virt_addr;\r\nfifo_data->tx_curr_get_info.offset = get_info.offset;\r\n}\r\ns2io_wake_tx_queue(fifo_data, pkt_cnt, nic->config.multiq);\r\nspin_unlock_irqrestore(&fifo_data->tx_lock, flags);\r\n}\r\nstatic void s2io_mdio_write(u32 mmd_type, u64 addr, u16 value,\r\nstruct net_device *dev)\r\n{\r\nu64 val64;\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nval64 = MDIO_MMD_INDX_ADDR(addr) |\r\nMDIO_MMD_DEV_ADDR(mmd_type) |\r\nMDIO_MMS_PRT_ADDR(0x0);\r\nwriteq(val64, &bar0->mdio_control);\r\nval64 = val64 | MDIO_CTRL_START_TRANS(0xE);\r\nwriteq(val64, &bar0->mdio_control);\r\nudelay(100);\r\nval64 = MDIO_MMD_INDX_ADDR(addr) |\r\nMDIO_MMD_DEV_ADDR(mmd_type) |\r\nMDIO_MMS_PRT_ADDR(0x0) |\r\nMDIO_MDIO_DATA(value) |\r\nMDIO_OP(MDIO_OP_WRITE_TRANS);\r\nwriteq(val64, &bar0->mdio_control);\r\nval64 = val64 | MDIO_CTRL_START_TRANS(0xE);\r\nwriteq(val64, &bar0->mdio_control);\r\nudelay(100);\r\nval64 = MDIO_MMD_INDX_ADDR(addr) |\r\nMDIO_MMD_DEV_ADDR(mmd_type) |\r\nMDIO_MMS_PRT_ADDR(0x0) |\r\nMDIO_OP(MDIO_OP_READ_TRANS);\r\nwriteq(val64, &bar0->mdio_control);\r\nval64 = val64 | MDIO_CTRL_START_TRANS(0xE);\r\nwriteq(val64, &bar0->mdio_control);\r\nudelay(100);\r\n}\r\nstatic u64 s2io_mdio_read(u32 mmd_type, u64 addr, struct net_device *dev)\r\n{\r\nu64 val64 = 0x0;\r\nu64 rval64 = 0x0;\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nval64 = val64 | (MDIO_MMD_INDX_ADDR(addr)\r\n| MDIO_MMD_DEV_ADDR(mmd_type)\r\n| MDIO_MMS_PRT_ADDR(0x0));\r\nwriteq(val64, &bar0->mdio_control);\r\nval64 = val64 | MDIO_CTRL_START_TRANS(0xE);\r\nwriteq(val64, &bar0->mdio_control);\r\nudelay(100);\r\nval64 = MDIO_MMD_INDX_ADDR(addr) |\r\nMDIO_MMD_DEV_ADDR(mmd_type) |\r\nMDIO_MMS_PRT_ADDR(0x0) |\r\nMDIO_OP(MDIO_OP_READ_TRANS);\r\nwriteq(val64, &bar0->mdio_control);\r\nval64 = val64 | MDIO_CTRL_START_TRANS(0xE);\r\nwriteq(val64, &bar0->mdio_control);\r\nudelay(100);\r\nrval64 = readq(&bar0->mdio_control);\r\nrval64 = rval64 & 0xFFFF0000;\r\nrval64 = rval64 >> 16;\r\nreturn rval64;\r\n}\r\nstatic void s2io_chk_xpak_counter(u64 *counter, u64 * regs_stat, u32 index,\r\nu16 flag, u16 type)\r\n{\r\nu64 mask = 0x3;\r\nu64 val64;\r\nint i;\r\nfor (i = 0; i < index; i++)\r\nmask = mask << 0x2;\r\nif (flag > 0) {\r\n*counter = *counter + 1;\r\nval64 = *regs_stat & mask;\r\nval64 = val64 >> (index * 0x2);\r\nval64 = val64 + 1;\r\nif (val64 == 3) {\r\nswitch (type) {\r\ncase 1:\r\nDBG_PRINT(ERR_DBG,\r\n"Take Xframe NIC out of service.\n");\r\nDBG_PRINT(ERR_DBG,\r\n"Excessive temperatures may result in premature transceiver failure.\n");\r\nbreak;\r\ncase 2:\r\nDBG_PRINT(ERR_DBG,\r\n"Take Xframe NIC out of service.\n");\r\nDBG_PRINT(ERR_DBG,\r\n"Excessive bias currents may indicate imminent laser diode failure.\n");\r\nbreak;\r\ncase 3:\r\nDBG_PRINT(ERR_DBG,\r\n"Take Xframe NIC out of service.\n");\r\nDBG_PRINT(ERR_DBG,\r\n"Excessive laser output power may saturate far-end receiver.\n");\r\nbreak;\r\ndefault:\r\nDBG_PRINT(ERR_DBG,\r\n"Incorrect XPAK Alarm type\n");\r\n}\r\nval64 = 0x0;\r\n}\r\nval64 = val64 << (index * 0x2);\r\n*regs_stat = (*regs_stat & (~mask)) | (val64);\r\n} else {\r\n*regs_stat = *regs_stat & (~mask);\r\n}\r\n}\r\nstatic void s2io_updt_xpak_counter(struct net_device *dev)\r\n{\r\nu16 flag = 0x0;\r\nu16 type = 0x0;\r\nu16 val16 = 0x0;\r\nu64 val64 = 0x0;\r\nu64 addr = 0x0;\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nstruct stat_block *stats = sp->mac_control.stats_info;\r\nstruct xpakStat *xstats = &stats->xpak_stat;\r\naddr = MDIO_CTRL1;\r\nval64 = 0x0;\r\nval64 = s2io_mdio_read(MDIO_MMD_PMAPMD, addr, dev);\r\nif ((val64 == 0xFFFF) || (val64 == 0x0000)) {\r\nDBG_PRINT(ERR_DBG,\r\n"ERR: MDIO slave access failed - Returned %llx\n",\r\n(unsigned long long)val64);\r\nreturn;\r\n}\r\nif (val64 != MDIO_CTRL1_SPEED10G) {\r\nDBG_PRINT(ERR_DBG, "Incorrect value at PMA address 0x0000 - "\r\n"Returned: %llx- Expected: 0x%x\n",\r\n(unsigned long long)val64, MDIO_CTRL1_SPEED10G);\r\nreturn;\r\n}\r\naddr = 0xA100;\r\ns2io_mdio_write(MDIO_MMD_PMAPMD, addr, val16, dev);\r\nval64 = s2io_mdio_read(MDIO_MMD_PMAPMD, addr, dev);\r\naddr = 0xA070;\r\nval64 = 0x0;\r\nval64 = s2io_mdio_read(MDIO_MMD_PMAPMD, addr, dev);\r\nflag = CHECKBIT(val64, 0x7);\r\ntype = 1;\r\ns2io_chk_xpak_counter(&xstats->alarm_transceiver_temp_high,\r\n&xstats->xpak_regs_stat,\r\n0x0, flag, type);\r\nif (CHECKBIT(val64, 0x6))\r\nxstats->alarm_transceiver_temp_low++;\r\nflag = CHECKBIT(val64, 0x3);\r\ntype = 2;\r\ns2io_chk_xpak_counter(&xstats->alarm_laser_bias_current_high,\r\n&xstats->xpak_regs_stat,\r\n0x2, flag, type);\r\nif (CHECKBIT(val64, 0x2))\r\nxstats->alarm_laser_bias_current_low++;\r\nflag = CHECKBIT(val64, 0x1);\r\ntype = 3;\r\ns2io_chk_xpak_counter(&xstats->alarm_laser_output_power_high,\r\n&xstats->xpak_regs_stat,\r\n0x4, flag, type);\r\nif (CHECKBIT(val64, 0x0))\r\nxstats->alarm_laser_output_power_low++;\r\naddr = 0xA074;\r\nval64 = 0x0;\r\nval64 = s2io_mdio_read(MDIO_MMD_PMAPMD, addr, dev);\r\nif (CHECKBIT(val64, 0x7))\r\nxstats->warn_transceiver_temp_high++;\r\nif (CHECKBIT(val64, 0x6))\r\nxstats->warn_transceiver_temp_low++;\r\nif (CHECKBIT(val64, 0x3))\r\nxstats->warn_laser_bias_current_high++;\r\nif (CHECKBIT(val64, 0x2))\r\nxstats->warn_laser_bias_current_low++;\r\nif (CHECKBIT(val64, 0x1))\r\nxstats->warn_laser_output_power_high++;\r\nif (CHECKBIT(val64, 0x0))\r\nxstats->warn_laser_output_power_low++;\r\n}\r\nstatic int wait_for_cmd_complete(void __iomem *addr, u64 busy_bit,\r\nint bit_state)\r\n{\r\nint ret = FAILURE, cnt = 0, delay = 1;\r\nu64 val64;\r\nif ((bit_state != S2IO_BIT_RESET) && (bit_state != S2IO_BIT_SET))\r\nreturn FAILURE;\r\ndo {\r\nval64 = readq(addr);\r\nif (bit_state == S2IO_BIT_RESET) {\r\nif (!(val64 & busy_bit)) {\r\nret = SUCCESS;\r\nbreak;\r\n}\r\n} else {\r\nif (val64 & busy_bit) {\r\nret = SUCCESS;\r\nbreak;\r\n}\r\n}\r\nif (in_interrupt())\r\nmdelay(delay);\r\nelse\r\nmsleep(delay);\r\nif (++cnt >= 10)\r\ndelay = 50;\r\n} while (cnt < 20);\r\nreturn ret;\r\n}\r\nstatic u16 check_pci_device_id(u16 id)\r\n{\r\nswitch (id) {\r\ncase PCI_DEVICE_ID_HERC_WIN:\r\ncase PCI_DEVICE_ID_HERC_UNI:\r\nreturn XFRAME_II_DEVICE;\r\ncase PCI_DEVICE_ID_S2IO_UNI:\r\ncase PCI_DEVICE_ID_S2IO_WIN:\r\nreturn XFRAME_I_DEVICE;\r\ndefault:\r\nreturn PCI_ANY_ID;\r\n}\r\n}\r\nstatic void s2io_reset(struct s2io_nic *sp)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nu64 val64;\r\nu16 subid, pci_cmd;\r\nint i;\r\nu16 val16;\r\nunsigned long long up_cnt, down_cnt, up_time, down_time, reset_cnt;\r\nunsigned long long mem_alloc_cnt, mem_free_cnt, watchdog_cnt;\r\nstruct stat_block *stats;\r\nstruct swStat *swstats;\r\nDBG_PRINT(INIT_DBG, "%s: Resetting XFrame card %s\n",\r\n__func__, pci_name(sp->pdev));\r\npci_read_config_word(sp->pdev, PCIX_COMMAND_REGISTER, &(pci_cmd));\r\nval64 = SW_RESET_ALL;\r\nwriteq(val64, &bar0->sw_reset);\r\nif (strstr(sp->product_name, "CX4"))\r\nmsleep(750);\r\nmsleep(250);\r\nfor (i = 0; i < S2IO_MAX_PCI_CONFIG_SPACE_REINIT; i++) {\r\npci_restore_state(sp->pdev);\r\npci_save_state(sp->pdev);\r\npci_read_config_word(sp->pdev, 0x2, &val16);\r\nif (check_pci_device_id(val16) != (u16)PCI_ANY_ID)\r\nbreak;\r\nmsleep(200);\r\n}\r\nif (check_pci_device_id(val16) == (u16)PCI_ANY_ID)\r\nDBG_PRINT(ERR_DBG, "%s SW_Reset failed!\n", __func__);\r\npci_write_config_word(sp->pdev, PCIX_COMMAND_REGISTER, pci_cmd);\r\ns2io_init_pci(sp);\r\ns2io_set_swapper(sp);\r\ndo_s2io_restore_unicast_mc(sp);\r\nrestore_xmsi_data(sp);\r\nif (sp->device_type == XFRAME_II_DEVICE) {\r\npci_write_config_word(sp->pdev, PCI_STATUS, 0x8000);\r\npci_write_config_dword(sp->pdev, 0x68, 0x7C);\r\nwriteq(s2BIT(62), &bar0->txpic_int_reg);\r\n}\r\nmemset(&sp->stats, 0, sizeof(struct net_device_stats));\r\nstats = sp->mac_control.stats_info;\r\nswstats = &stats->sw_stat;\r\nup_cnt = swstats->link_up_cnt;\r\ndown_cnt = swstats->link_down_cnt;\r\nup_time = swstats->link_up_time;\r\ndown_time = swstats->link_down_time;\r\nreset_cnt = swstats->soft_reset_cnt;\r\nmem_alloc_cnt = swstats->mem_allocated;\r\nmem_free_cnt = swstats->mem_freed;\r\nwatchdog_cnt = swstats->watchdog_timer_cnt;\r\nmemset(stats, 0, sizeof(struct stat_block));\r\nswstats->link_up_cnt = up_cnt;\r\nswstats->link_down_cnt = down_cnt;\r\nswstats->link_up_time = up_time;\r\nswstats->link_down_time = down_time;\r\nswstats->soft_reset_cnt = reset_cnt;\r\nswstats->mem_allocated = mem_alloc_cnt;\r\nswstats->mem_freed = mem_free_cnt;\r\nswstats->watchdog_timer_cnt = watchdog_cnt;\r\nsubid = sp->pdev->subsystem_device;\r\nif (((subid & 0xFF) >= 0x07) &&\r\n(sp->device_type == XFRAME_I_DEVICE)) {\r\nval64 = readq(&bar0->gpio_control);\r\nval64 |= 0x0000800000000000ULL;\r\nwriteq(val64, &bar0->gpio_control);\r\nval64 = 0x0411040400000000ULL;\r\nwriteq(val64, (void __iomem *)bar0 + 0x2700);\r\n}\r\nif (sp->device_type == XFRAME_II_DEVICE) {\r\nval64 = readq(&bar0->pcc_err_reg);\r\nwriteq(val64, &bar0->pcc_err_reg);\r\n}\r\nsp->device_enabled_once = false;\r\n}\r\nstatic int s2io_set_swapper(struct s2io_nic *sp)\r\n{\r\nstruct net_device *dev = sp->dev;\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nu64 val64, valt, valr;\r\nval64 = readq(&bar0->pif_rd_swapper_fb);\r\nif (val64 != 0x0123456789ABCDEFULL) {\r\nint i = 0;\r\nstatic const u64 value[] = {\r\n0xC30000C3C30000C3ULL,\r\n0x8100008181000081ULL,\r\n0x4200004242000042ULL,\r\n0\r\n};\r\nwhile (i < 4) {\r\nwriteq(value[i], &bar0->swapper_ctrl);\r\nval64 = readq(&bar0->pif_rd_swapper_fb);\r\nif (val64 == 0x0123456789ABCDEFULL)\r\nbreak;\r\ni++;\r\n}\r\nif (i == 4) {\r\nDBG_PRINT(ERR_DBG, "%s: Endian settings are wrong, "\r\n"feedback read %llx\n",\r\ndev->name, (unsigned long long)val64);\r\nreturn FAILURE;\r\n}\r\nvalr = value[i];\r\n} else {\r\nvalr = readq(&bar0->swapper_ctrl);\r\n}\r\nvalt = 0x0123456789ABCDEFULL;\r\nwriteq(valt, &bar0->xmsi_address);\r\nval64 = readq(&bar0->xmsi_address);\r\nif (val64 != valt) {\r\nint i = 0;\r\nstatic const u64 value[] = {\r\n0x00C3C30000C3C300ULL,\r\n0x0081810000818100ULL,\r\n0x0042420000424200ULL,\r\n0\r\n};\r\nwhile (i < 4) {\r\nwriteq((value[i] | valr), &bar0->swapper_ctrl);\r\nwriteq(valt, &bar0->xmsi_address);\r\nval64 = readq(&bar0->xmsi_address);\r\nif (val64 == valt)\r\nbreak;\r\ni++;\r\n}\r\nif (i == 4) {\r\nunsigned long long x = val64;\r\nDBG_PRINT(ERR_DBG,\r\n"Write failed, Xmsi_addr reads:0x%llx\n", x);\r\nreturn FAILURE;\r\n}\r\n}\r\nval64 = readq(&bar0->swapper_ctrl);\r\nval64 &= 0xFFFF000000000000ULL;\r\n#ifdef __BIG_ENDIAN\r\nval64 |= (SWAPPER_CTRL_TXP_FE |\r\nSWAPPER_CTRL_TXP_SE |\r\nSWAPPER_CTRL_TXD_R_FE |\r\nSWAPPER_CTRL_TXD_W_FE |\r\nSWAPPER_CTRL_TXF_R_FE |\r\nSWAPPER_CTRL_RXD_R_FE |\r\nSWAPPER_CTRL_RXD_W_FE |\r\nSWAPPER_CTRL_RXF_W_FE |\r\nSWAPPER_CTRL_XMSI_FE |\r\nSWAPPER_CTRL_STATS_FE |\r\nSWAPPER_CTRL_STATS_SE);\r\nif (sp->config.intr_type == INTA)\r\nval64 |= SWAPPER_CTRL_XMSI_SE;\r\nwriteq(val64, &bar0->swapper_ctrl);\r\n#else\r\nval64 |= (SWAPPER_CTRL_TXP_FE |\r\nSWAPPER_CTRL_TXP_SE |\r\nSWAPPER_CTRL_TXD_R_FE |\r\nSWAPPER_CTRL_TXD_R_SE |\r\nSWAPPER_CTRL_TXD_W_FE |\r\nSWAPPER_CTRL_TXD_W_SE |\r\nSWAPPER_CTRL_TXF_R_FE |\r\nSWAPPER_CTRL_RXD_R_FE |\r\nSWAPPER_CTRL_RXD_R_SE |\r\nSWAPPER_CTRL_RXD_W_FE |\r\nSWAPPER_CTRL_RXD_W_SE |\r\nSWAPPER_CTRL_RXF_W_FE |\r\nSWAPPER_CTRL_XMSI_FE |\r\nSWAPPER_CTRL_STATS_FE |\r\nSWAPPER_CTRL_STATS_SE);\r\nif (sp->config.intr_type == INTA)\r\nval64 |= SWAPPER_CTRL_XMSI_SE;\r\nwriteq(val64, &bar0->swapper_ctrl);\r\n#endif\r\nval64 = readq(&bar0->swapper_ctrl);\r\nval64 = readq(&bar0->pif_rd_swapper_fb);\r\nif (val64 != 0x0123456789ABCDEFULL) {\r\nDBG_PRINT(ERR_DBG,\r\n"%s: Endian settings are wrong, feedback read %llx\n",\r\ndev->name, (unsigned long long)val64);\r\nreturn FAILURE;\r\n}\r\nreturn SUCCESS;\r\n}\r\nstatic int wait_for_msix_trans(struct s2io_nic *nic, int i)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = nic->bar0;\r\nu64 val64;\r\nint ret = 0, cnt = 0;\r\ndo {\r\nval64 = readq(&bar0->xmsi_access);\r\nif (!(val64 & s2BIT(15)))\r\nbreak;\r\nmdelay(1);\r\ncnt++;\r\n} while (cnt < 5);\r\nif (cnt == 5) {\r\nDBG_PRINT(ERR_DBG, "XMSI # %d Access failed\n", i);\r\nret = 1;\r\n}\r\nreturn ret;\r\n}\r\nstatic void restore_xmsi_data(struct s2io_nic *nic)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = nic->bar0;\r\nu64 val64;\r\nint i, msix_index;\r\nif (nic->device_type == XFRAME_I_DEVICE)\r\nreturn;\r\nfor (i = 0; i < MAX_REQUESTED_MSI_X; i++) {\r\nmsix_index = (i) ? ((i-1) * 8 + 1) : 0;\r\nwriteq(nic->msix_info[i].addr, &bar0->xmsi_address);\r\nwriteq(nic->msix_info[i].data, &bar0->xmsi_data);\r\nval64 = (s2BIT(7) | s2BIT(15) | vBIT(msix_index, 26, 6));\r\nwriteq(val64, &bar0->xmsi_access);\r\nif (wait_for_msix_trans(nic, msix_index)) {\r\nDBG_PRINT(ERR_DBG, "%s: index: %d failed\n",\r\n__func__, msix_index);\r\ncontinue;\r\n}\r\n}\r\n}\r\nstatic void store_xmsi_data(struct s2io_nic *nic)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = nic->bar0;\r\nu64 val64, addr, data;\r\nint i, msix_index;\r\nif (nic->device_type == XFRAME_I_DEVICE)\r\nreturn;\r\nfor (i = 0; i < MAX_REQUESTED_MSI_X; i++) {\r\nmsix_index = (i) ? ((i-1) * 8 + 1) : 0;\r\nval64 = (s2BIT(15) | vBIT(msix_index, 26, 6));\r\nwriteq(val64, &bar0->xmsi_access);\r\nif (wait_for_msix_trans(nic, msix_index)) {\r\nDBG_PRINT(ERR_DBG, "%s: index: %d failed\n",\r\n__func__, msix_index);\r\ncontinue;\r\n}\r\naddr = readq(&bar0->xmsi_address);\r\ndata = readq(&bar0->xmsi_data);\r\nif (addr && data) {\r\nnic->msix_info[i].addr = addr;\r\nnic->msix_info[i].data = data;\r\n}\r\n}\r\n}\r\nstatic int s2io_enable_msi_x(struct s2io_nic *nic)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = nic->bar0;\r\nu64 rx_mat;\r\nu16 msi_control;\r\nint ret, i, j, msix_indx = 1;\r\nint size;\r\nstruct stat_block *stats = nic->mac_control.stats_info;\r\nstruct swStat *swstats = &stats->sw_stat;\r\nsize = nic->num_entries * sizeof(struct msix_entry);\r\nnic->entries = kzalloc(size, GFP_KERNEL);\r\nif (!nic->entries) {\r\nDBG_PRINT(INFO_DBG, "%s: Memory allocation failed\n",\r\n__func__);\r\nswstats->mem_alloc_fail_cnt++;\r\nreturn -ENOMEM;\r\n}\r\nswstats->mem_allocated += size;\r\nsize = nic->num_entries * sizeof(struct s2io_msix_entry);\r\nnic->s2io_entries = kzalloc(size, GFP_KERNEL);\r\nif (!nic->s2io_entries) {\r\nDBG_PRINT(INFO_DBG, "%s: Memory allocation failed\n",\r\n__func__);\r\nswstats->mem_alloc_fail_cnt++;\r\nkfree(nic->entries);\r\nswstats->mem_freed\r\n+= (nic->num_entries * sizeof(struct msix_entry));\r\nreturn -ENOMEM;\r\n}\r\nswstats->mem_allocated += size;\r\nnic->entries[0].entry = 0;\r\nnic->s2io_entries[0].entry = 0;\r\nnic->s2io_entries[0].in_use = MSIX_FLG;\r\nnic->s2io_entries[0].type = MSIX_ALARM_TYPE;\r\nnic->s2io_entries[0].arg = &nic->mac_control.fifos;\r\nfor (i = 1; i < nic->num_entries; i++) {\r\nnic->entries[i].entry = ((i - 1) * 8) + 1;\r\nnic->s2io_entries[i].entry = ((i - 1) * 8) + 1;\r\nnic->s2io_entries[i].arg = NULL;\r\nnic->s2io_entries[i].in_use = 0;\r\n}\r\nrx_mat = readq(&bar0->rx_mat);\r\nfor (j = 0; j < nic->config.rx_ring_num; j++) {\r\nrx_mat |= RX_MAT_SET(j, msix_indx);\r\nnic->s2io_entries[j+1].arg = &nic->mac_control.rings[j];\r\nnic->s2io_entries[j+1].type = MSIX_RING_TYPE;\r\nnic->s2io_entries[j+1].in_use = MSIX_FLG;\r\nmsix_indx += 8;\r\n}\r\nwriteq(rx_mat, &bar0->rx_mat);\r\nreadq(&bar0->rx_mat);\r\nret = pci_enable_msix(nic->pdev, nic->entries, nic->num_entries);\r\nif (ret) {\r\nDBG_PRINT(ERR_DBG, "Enabling MSI-X failed\n");\r\nkfree(nic->entries);\r\nswstats->mem_freed += nic->num_entries *\r\nsizeof(struct msix_entry);\r\nkfree(nic->s2io_entries);\r\nswstats->mem_freed += nic->num_entries *\r\nsizeof(struct s2io_msix_entry);\r\nnic->entries = NULL;\r\nnic->s2io_entries = NULL;\r\nreturn -ENOMEM;\r\n}\r\npci_read_config_word(nic->pdev, 0x42, &msi_control);\r\nmsi_control |= 0x1;\r\npci_write_config_word(nic->pdev, 0x42, msi_control);\r\nreturn 0;\r\n}\r\nstatic irqreturn_t s2io_test_intr(int irq, void *dev_id)\r\n{\r\nstruct s2io_nic *sp = dev_id;\r\nsp->msi_detected = 1;\r\nwake_up(&sp->msi_wait);\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic int s2io_test_msi(struct s2io_nic *sp)\r\n{\r\nstruct pci_dev *pdev = sp->pdev;\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nint err;\r\nu64 val64, saved64;\r\nerr = request_irq(sp->entries[1].vector, s2io_test_intr, 0,\r\nsp->name, sp);\r\nif (err) {\r\nDBG_PRINT(ERR_DBG, "%s: PCI %s: cannot assign irq %d\n",\r\nsp->dev->name, pci_name(pdev), pdev->irq);\r\nreturn err;\r\n}\r\ninit_waitqueue_head(&sp->msi_wait);\r\nsp->msi_detected = 0;\r\nsaved64 = val64 = readq(&bar0->scheduled_int_ctrl);\r\nval64 |= SCHED_INT_CTRL_ONE_SHOT;\r\nval64 |= SCHED_INT_CTRL_TIMER_EN;\r\nval64 |= SCHED_INT_CTRL_INT2MSI(1);\r\nwriteq(val64, &bar0->scheduled_int_ctrl);\r\nwait_event_timeout(sp->msi_wait, sp->msi_detected, HZ/10);\r\nif (!sp->msi_detected) {\r\nDBG_PRINT(ERR_DBG, "%s: PCI %s: No interrupt was generated "\r\n"using MSI(X) during test\n",\r\nsp->dev->name, pci_name(pdev));\r\nerr = -EOPNOTSUPP;\r\n}\r\nfree_irq(sp->entries[1].vector, sp);\r\nwriteq(saved64, &bar0->scheduled_int_ctrl);\r\nreturn err;\r\n}\r\nstatic void remove_msix_isr(struct s2io_nic *sp)\r\n{\r\nint i;\r\nu16 msi_control;\r\nfor (i = 0; i < sp->num_entries; i++) {\r\nif (sp->s2io_entries[i].in_use == MSIX_REGISTERED_SUCCESS) {\r\nint vector = sp->entries[i].vector;\r\nvoid *arg = sp->s2io_entries[i].arg;\r\nfree_irq(vector, arg);\r\n}\r\n}\r\nkfree(sp->entries);\r\nkfree(sp->s2io_entries);\r\nsp->entries = NULL;\r\nsp->s2io_entries = NULL;\r\npci_read_config_word(sp->pdev, 0x42, &msi_control);\r\nmsi_control &= 0xFFFE;\r\npci_write_config_word(sp->pdev, 0x42, msi_control);\r\npci_disable_msix(sp->pdev);\r\n}\r\nstatic void remove_inta_isr(struct s2io_nic *sp)\r\n{\r\nfree_irq(sp->pdev->irq, sp->dev);\r\n}\r\nstatic int s2io_open(struct net_device *dev)\r\n{\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nstruct swStat *swstats = &sp->mac_control.stats_info->sw_stat;\r\nint err = 0;\r\nnetif_carrier_off(dev);\r\nsp->last_link_state = 0;\r\nerr = s2io_card_up(sp);\r\nif (err) {\r\nDBG_PRINT(ERR_DBG, "%s: H/W initialization failed\n",\r\ndev->name);\r\ngoto hw_init_failed;\r\n}\r\nif (do_s2io_prog_unicast(dev, dev->dev_addr) == FAILURE) {\r\nDBG_PRINT(ERR_DBG, "Set Mac Address Failed\n");\r\ns2io_card_down(sp);\r\nerr = -ENODEV;\r\ngoto hw_init_failed;\r\n}\r\ns2io_start_all_tx_queue(sp);\r\nreturn 0;\r\nhw_init_failed:\r\nif (sp->config.intr_type == MSI_X) {\r\nif (sp->entries) {\r\nkfree(sp->entries);\r\nswstats->mem_freed += sp->num_entries *\r\nsizeof(struct msix_entry);\r\n}\r\nif (sp->s2io_entries) {\r\nkfree(sp->s2io_entries);\r\nswstats->mem_freed += sp->num_entries *\r\nsizeof(struct s2io_msix_entry);\r\n}\r\n}\r\nreturn err;\r\n}\r\nstatic int s2io_close(struct net_device *dev)\r\n{\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nstruct config_param *config = &sp->config;\r\nu64 tmp64;\r\nint offset;\r\nif (!is_s2io_card_up(sp))\r\nreturn 0;\r\ns2io_stop_all_tx_queue(sp);\r\nfor (offset = 1; offset < config->max_mc_addr; offset++) {\r\ntmp64 = do_s2io_read_unicast_mc(sp, offset);\r\nif (tmp64 != S2IO_DISABLE_MAC_ENTRY)\r\ndo_s2io_delete_unicast_mc(sp, tmp64);\r\n}\r\ns2io_card_down(sp);\r\nreturn 0;\r\n}\r\nstatic netdev_tx_t s2io_xmit(struct sk_buff *skb, struct net_device *dev)\r\n{\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nu16 frg_cnt, frg_len, i, queue, queue_len, put_off, get_off;\r\nregister u64 val64;\r\nstruct TxD *txdp;\r\nstruct TxFIFO_element __iomem *tx_fifo;\r\nunsigned long flags = 0;\r\nu16 vlan_tag = 0;\r\nstruct fifo_info *fifo = NULL;\r\nint do_spin_lock = 1;\r\nint offload_type;\r\nint enable_per_list_interrupt = 0;\r\nstruct config_param *config = &sp->config;\r\nstruct mac_info *mac_control = &sp->mac_control;\r\nstruct stat_block *stats = mac_control->stats_info;\r\nstruct swStat *swstats = &stats->sw_stat;\r\nDBG_PRINT(TX_DBG, "%s: In Neterion Tx routine\n", dev->name);\r\nif (unlikely(skb->len <= 0)) {\r\nDBG_PRINT(TX_DBG, "%s: Buffer has no data..\n", dev->name);\r\ndev_kfree_skb_any(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nif (!is_s2io_card_up(sp)) {\r\nDBG_PRINT(TX_DBG, "%s: Card going down for reset\n",\r\ndev->name);\r\ndev_kfree_skb(skb);\r\nreturn NETDEV_TX_OK;\r\n}\r\nqueue = 0;\r\nif (vlan_tx_tag_present(skb))\r\nvlan_tag = vlan_tx_tag_get(skb);\r\nif (sp->config.tx_steering_type == TX_DEFAULT_STEERING) {\r\nif (skb->protocol == htons(ETH_P_IP)) {\r\nstruct iphdr *ip;\r\nstruct tcphdr *th;\r\nip = ip_hdr(skb);\r\nif (!ip_is_fragment(ip)) {\r\nth = (struct tcphdr *)(((unsigned char *)ip) +\r\nip->ihl*4);\r\nif (ip->protocol == IPPROTO_TCP) {\r\nqueue_len = sp->total_tcp_fifos;\r\nqueue = (ntohs(th->source) +\r\nntohs(th->dest)) &\r\nsp->fifo_selector[queue_len - 1];\r\nif (queue >= queue_len)\r\nqueue = queue_len - 1;\r\n} else if (ip->protocol == IPPROTO_UDP) {\r\nqueue_len = sp->total_udp_fifos;\r\nqueue = (ntohs(th->source) +\r\nntohs(th->dest)) &\r\nsp->fifo_selector[queue_len - 1];\r\nif (queue >= queue_len)\r\nqueue = queue_len - 1;\r\nqueue += sp->udp_fifo_idx;\r\nif (skb->len > 1024)\r\nenable_per_list_interrupt = 1;\r\ndo_spin_lock = 0;\r\n}\r\n}\r\n}\r\n} else if (sp->config.tx_steering_type == TX_PRIORITY_STEERING)\r\nqueue = config->fifo_mapping\r\n[skb->priority & (MAX_TX_FIFOS - 1)];\r\nfifo = &mac_control->fifos[queue];\r\nif (do_spin_lock)\r\nspin_lock_irqsave(&fifo->tx_lock, flags);\r\nelse {\r\nif (unlikely(!spin_trylock_irqsave(&fifo->tx_lock, flags)))\r\nreturn NETDEV_TX_LOCKED;\r\n}\r\nif (sp->config.multiq) {\r\nif (__netif_subqueue_stopped(dev, fifo->fifo_no)) {\r\nspin_unlock_irqrestore(&fifo->tx_lock, flags);\r\nreturn NETDEV_TX_BUSY;\r\n}\r\n} else if (unlikely(fifo->queue_state == FIFO_QUEUE_STOP)) {\r\nif (netif_queue_stopped(dev)) {\r\nspin_unlock_irqrestore(&fifo->tx_lock, flags);\r\nreturn NETDEV_TX_BUSY;\r\n}\r\n}\r\nput_off = (u16)fifo->tx_curr_put_info.offset;\r\nget_off = (u16)fifo->tx_curr_get_info.offset;\r\ntxdp = fifo->list_info[put_off].list_virt_addr;\r\nqueue_len = fifo->tx_curr_put_info.fifo_len + 1;\r\nif (txdp->Host_Control ||\r\n((put_off+1) == queue_len ? 0 : (put_off+1)) == get_off) {\r\nDBG_PRINT(TX_DBG, "Error in xmit, No free TXDs.\n");\r\ns2io_stop_tx_queue(sp, fifo->fifo_no);\r\ndev_kfree_skb(skb);\r\nspin_unlock_irqrestore(&fifo->tx_lock, flags);\r\nreturn NETDEV_TX_OK;\r\n}\r\noffload_type = s2io_offload_type(skb);\r\nif (offload_type & (SKB_GSO_TCPV4 | SKB_GSO_TCPV6)) {\r\ntxdp->Control_1 |= TXD_TCP_LSO_EN;\r\ntxdp->Control_1 |= TXD_TCP_LSO_MSS(s2io_tcp_mss(skb));\r\n}\r\nif (skb->ip_summed == CHECKSUM_PARTIAL) {\r\ntxdp->Control_2 |= (TXD_TX_CKO_IPV4_EN |\r\nTXD_TX_CKO_TCP_EN |\r\nTXD_TX_CKO_UDP_EN);\r\n}\r\ntxdp->Control_1 |= TXD_GATHER_CODE_FIRST;\r\ntxdp->Control_1 |= TXD_LIST_OWN_XENA;\r\ntxdp->Control_2 |= TXD_INT_NUMBER(fifo->fifo_no);\r\nif (enable_per_list_interrupt)\r\nif (put_off & (queue_len >> 5))\r\ntxdp->Control_2 |= TXD_INT_TYPE_PER_LIST;\r\nif (vlan_tag) {\r\ntxdp->Control_2 |= TXD_VLAN_ENABLE;\r\ntxdp->Control_2 |= TXD_VLAN_TAG(vlan_tag);\r\n}\r\nfrg_len = skb_headlen(skb);\r\nif (offload_type == SKB_GSO_UDP) {\r\nint ufo_size;\r\nufo_size = s2io_udp_mss(skb);\r\nufo_size &= ~7;\r\ntxdp->Control_1 |= TXD_UFO_EN;\r\ntxdp->Control_1 |= TXD_UFO_MSS(ufo_size);\r\ntxdp->Control_1 |= TXD_BUFFER0_SIZE(8);\r\n#ifdef __BIG_ENDIAN\r\nfifo->ufo_in_band_v[put_off] =\r\n(__force u64)skb_shinfo(skb)->ip6_frag_id;\r\n#else\r\nfifo->ufo_in_band_v[put_off] =\r\n(__force u64)skb_shinfo(skb)->ip6_frag_id << 32;\r\n#endif\r\ntxdp->Host_Control = (unsigned long)fifo->ufo_in_band_v;\r\ntxdp->Buffer_Pointer = pci_map_single(sp->pdev,\r\nfifo->ufo_in_band_v,\r\nsizeof(u64),\r\nPCI_DMA_TODEVICE);\r\nif (pci_dma_mapping_error(sp->pdev, txdp->Buffer_Pointer))\r\ngoto pci_map_failed;\r\ntxdp++;\r\n}\r\ntxdp->Buffer_Pointer = pci_map_single(sp->pdev, skb->data,\r\nfrg_len, PCI_DMA_TODEVICE);\r\nif (pci_dma_mapping_error(sp->pdev, txdp->Buffer_Pointer))\r\ngoto pci_map_failed;\r\ntxdp->Host_Control = (unsigned long)skb;\r\ntxdp->Control_1 |= TXD_BUFFER0_SIZE(frg_len);\r\nif (offload_type == SKB_GSO_UDP)\r\ntxdp->Control_1 |= TXD_UFO_EN;\r\nfrg_cnt = skb_shinfo(skb)->nr_frags;\r\nfor (i = 0; i < frg_cnt; i++) {\r\nconst skb_frag_t *frag = &skb_shinfo(skb)->frags[i];\r\nif (!skb_frag_size(frag))\r\ncontinue;\r\ntxdp++;\r\ntxdp->Buffer_Pointer = (u64)skb_frag_dma_map(&sp->pdev->dev,\r\nfrag, 0,\r\nskb_frag_size(frag),\r\nDMA_TO_DEVICE);\r\ntxdp->Control_1 = TXD_BUFFER0_SIZE(skb_frag_size(frag));\r\nif (offload_type == SKB_GSO_UDP)\r\ntxdp->Control_1 |= TXD_UFO_EN;\r\n}\r\ntxdp->Control_1 |= TXD_GATHER_CODE_LAST;\r\nif (offload_type == SKB_GSO_UDP)\r\nfrg_cnt++;\r\ntx_fifo = mac_control->tx_FIFO_start[queue];\r\nval64 = fifo->list_info[put_off].list_phy_addr;\r\nwriteq(val64, &tx_fifo->TxDL_Pointer);\r\nval64 = (TX_FIFO_LAST_TXD_NUM(frg_cnt) | TX_FIFO_FIRST_LIST |\r\nTX_FIFO_LAST_LIST);\r\nif (offload_type)\r\nval64 |= TX_FIFO_SPECIAL_FUNC;\r\nwriteq(val64, &tx_fifo->List_Control);\r\nmmiowb();\r\nput_off++;\r\nif (put_off == fifo->tx_curr_put_info.fifo_len + 1)\r\nput_off = 0;\r\nfifo->tx_curr_put_info.offset = put_off;\r\nif (((put_off+1) == queue_len ? 0 : (put_off+1)) == get_off) {\r\nswstats->fifo_full_cnt++;\r\nDBG_PRINT(TX_DBG,\r\n"No free TxDs for xmit, Put: 0x%x Get:0x%x\n",\r\nput_off, get_off);\r\ns2io_stop_tx_queue(sp, fifo->fifo_no);\r\n}\r\nswstats->mem_allocated += skb->truesize;\r\nspin_unlock_irqrestore(&fifo->tx_lock, flags);\r\nif (sp->config.intr_type == MSI_X)\r\ntx_intr_handler(fifo);\r\nreturn NETDEV_TX_OK;\r\npci_map_failed:\r\nswstats->pci_map_fail_cnt++;\r\ns2io_stop_tx_queue(sp, fifo->fifo_no);\r\nswstats->mem_freed += skb->truesize;\r\ndev_kfree_skb(skb);\r\nspin_unlock_irqrestore(&fifo->tx_lock, flags);\r\nreturn NETDEV_TX_OK;\r\n}\r\nstatic void\r\ns2io_alarm_handle(unsigned long data)\r\n{\r\nstruct s2io_nic *sp = (struct s2io_nic *)data;\r\nstruct net_device *dev = sp->dev;\r\ns2io_handle_errors(dev);\r\nmod_timer(&sp->alarm_timer, jiffies + HZ / 2);\r\n}\r\nstatic irqreturn_t s2io_msix_ring_handle(int irq, void *dev_id)\r\n{\r\nstruct ring_info *ring = (struct ring_info *)dev_id;\r\nstruct s2io_nic *sp = ring->nic;\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nif (unlikely(!is_s2io_card_up(sp)))\r\nreturn IRQ_HANDLED;\r\nif (sp->config.napi) {\r\nu8 __iomem *addr = NULL;\r\nu8 val8 = 0;\r\naddr = (u8 __iomem *)&bar0->xmsi_mask_reg;\r\naddr += (7 - ring->ring_no);\r\nval8 = (ring->ring_no == 0) ? 0x7f : 0xff;\r\nwriteb(val8, addr);\r\nval8 = readb(addr);\r\nnapi_schedule(&ring->napi);\r\n} else {\r\nrx_intr_handler(ring, 0);\r\ns2io_chk_rx_buffers(sp, ring);\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic irqreturn_t s2io_msix_fifo_handle(int irq, void *dev_id)\r\n{\r\nint i;\r\nstruct fifo_info *fifos = (struct fifo_info *)dev_id;\r\nstruct s2io_nic *sp = fifos->nic;\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nstruct config_param *config = &sp->config;\r\nu64 reason;\r\nif (unlikely(!is_s2io_card_up(sp)))\r\nreturn IRQ_NONE;\r\nreason = readq(&bar0->general_int_status);\r\nif (unlikely(reason == S2IO_MINUS_ONE))\r\nreturn IRQ_HANDLED;\r\nif (reason & (GEN_INTR_TXPIC | GEN_INTR_TXTRAFFIC)) {\r\nwriteq(S2IO_MINUS_ONE, &bar0->general_int_mask);\r\nif (reason & GEN_INTR_TXPIC)\r\ns2io_txpic_intr_handle(sp);\r\nif (reason & GEN_INTR_TXTRAFFIC)\r\nwriteq(S2IO_MINUS_ONE, &bar0->tx_traffic_int);\r\nfor (i = 0; i < config->tx_fifo_num; i++)\r\ntx_intr_handler(&fifos[i]);\r\nwriteq(sp->general_int_mask, &bar0->general_int_mask);\r\nreadl(&bar0->general_int_status);\r\nreturn IRQ_HANDLED;\r\n}\r\nreturn IRQ_NONE;\r\n}\r\nstatic void s2io_txpic_intr_handle(struct s2io_nic *sp)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nu64 val64;\r\nval64 = readq(&bar0->pic_int_status);\r\nif (val64 & PIC_INT_GPIO) {\r\nval64 = readq(&bar0->gpio_int_reg);\r\nif ((val64 & GPIO_INT_REG_LINK_DOWN) &&\r\n(val64 & GPIO_INT_REG_LINK_UP)) {\r\nval64 |= GPIO_INT_REG_LINK_DOWN;\r\nval64 |= GPIO_INT_REG_LINK_UP;\r\nwriteq(val64, &bar0->gpio_int_reg);\r\nval64 = readq(&bar0->gpio_int_mask);\r\nval64 &= ~(GPIO_INT_MASK_LINK_UP |\r\nGPIO_INT_MASK_LINK_DOWN);\r\nwriteq(val64, &bar0->gpio_int_mask);\r\n} else if (val64 & GPIO_INT_REG_LINK_UP) {\r\nval64 = readq(&bar0->adapter_status);\r\nval64 = readq(&bar0->adapter_control);\r\nval64 |= ADAPTER_CNTL_EN;\r\nwriteq(val64, &bar0->adapter_control);\r\nval64 |= ADAPTER_LED_ON;\r\nwriteq(val64, &bar0->adapter_control);\r\nif (!sp->device_enabled_once)\r\nsp->device_enabled_once = 1;\r\ns2io_link(sp, LINK_UP);\r\nval64 = readq(&bar0->gpio_int_mask);\r\nval64 &= ~GPIO_INT_MASK_LINK_DOWN;\r\nval64 |= GPIO_INT_MASK_LINK_UP;\r\nwriteq(val64, &bar0->gpio_int_mask);\r\n} else if (val64 & GPIO_INT_REG_LINK_DOWN) {\r\nval64 = readq(&bar0->adapter_status);\r\ns2io_link(sp, LINK_DOWN);\r\nval64 = readq(&bar0->gpio_int_mask);\r\nval64 &= ~GPIO_INT_MASK_LINK_UP;\r\nval64 |= GPIO_INT_MASK_LINK_DOWN;\r\nwriteq(val64, &bar0->gpio_int_mask);\r\nval64 = readq(&bar0->adapter_control);\r\nval64 = val64 & (~ADAPTER_LED_ON);\r\nwriteq(val64, &bar0->adapter_control);\r\n}\r\n}\r\nval64 = readq(&bar0->gpio_int_mask);\r\n}\r\nstatic int do_s2io_chk_alarm_bit(u64 value, void __iomem *addr,\r\nunsigned long long *cnt)\r\n{\r\nu64 val64;\r\nval64 = readq(addr);\r\nif (val64 & value) {\r\nwriteq(val64, addr);\r\n(*cnt)++;\r\nreturn 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic void s2io_handle_errors(void *dev_id)\r\n{\r\nstruct net_device *dev = (struct net_device *)dev_id;\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nu64 temp64 = 0, val64 = 0;\r\nint i = 0;\r\nstruct swStat *sw_stat = &sp->mac_control.stats_info->sw_stat;\r\nstruct xpakStat *stats = &sp->mac_control.stats_info->xpak_stat;\r\nif (!is_s2io_card_up(sp))\r\nreturn;\r\nif (pci_channel_offline(sp->pdev))\r\nreturn;\r\nmemset(&sw_stat->ring_full_cnt, 0,\r\nsizeof(sw_stat->ring_full_cnt));\r\nif (stats->xpak_timer_count < 72000) {\r\nstats->xpak_timer_count++;\r\n} else {\r\ns2io_updt_xpak_counter(dev);\r\nstats->xpak_timer_count = 0;\r\n}\r\nif (s2io_link_fault_indication(sp) == MAC_RMAC_ERR_TIMER) {\r\nval64 = readq(&bar0->mac_rmac_err_reg);\r\nwriteq(val64, &bar0->mac_rmac_err_reg);\r\nif (val64 & RMAC_LINK_STATE_CHANGE_INT)\r\nschedule_work(&sp->set_link_task);\r\n}\r\nif (do_s2io_chk_alarm_bit(SERR_SOURCE_ANY, &bar0->serr_source,\r\n&sw_stat->serious_err_cnt))\r\ngoto reset;\r\nif (do_s2io_chk_alarm_bit(GPIO_INT_REG_DP_ERR_INT, &bar0->gpio_int_reg,\r\n&sw_stat->parity_err_cnt))\r\ngoto reset;\r\nif (sp->device_type == XFRAME_II_DEVICE) {\r\nval64 = readq(&bar0->ring_bump_counter1);\r\nfor (i = 0; i < 4; i++) {\r\ntemp64 = (val64 & vBIT(0xFFFF, (i*16), 16));\r\ntemp64 >>= 64 - ((i+1)*16);\r\nsw_stat->ring_full_cnt[i] += temp64;\r\n}\r\nval64 = readq(&bar0->ring_bump_counter2);\r\nfor (i = 0; i < 4; i++) {\r\ntemp64 = (val64 & vBIT(0xFFFF, (i*16), 16));\r\ntemp64 >>= 64 - ((i+1)*16);\r\nsw_stat->ring_full_cnt[i+4] += temp64;\r\n}\r\n}\r\nval64 = readq(&bar0->txdma_int_status);\r\nif (val64 & TXDMA_PFC_INT) {\r\nif (do_s2io_chk_alarm_bit(PFC_ECC_DB_ERR | PFC_SM_ERR_ALARM |\r\nPFC_MISC_0_ERR | PFC_MISC_1_ERR |\r\nPFC_PCIX_ERR,\r\n&bar0->pfc_err_reg,\r\n&sw_stat->pfc_err_cnt))\r\ngoto reset;\r\ndo_s2io_chk_alarm_bit(PFC_ECC_SG_ERR,\r\n&bar0->pfc_err_reg,\r\n&sw_stat->pfc_err_cnt);\r\n}\r\nif (val64 & TXDMA_TDA_INT) {\r\nif (do_s2io_chk_alarm_bit(TDA_Fn_ECC_DB_ERR |\r\nTDA_SM0_ERR_ALARM |\r\nTDA_SM1_ERR_ALARM,\r\n&bar0->tda_err_reg,\r\n&sw_stat->tda_err_cnt))\r\ngoto reset;\r\ndo_s2io_chk_alarm_bit(TDA_Fn_ECC_SG_ERR | TDA_PCIX_ERR,\r\n&bar0->tda_err_reg,\r\n&sw_stat->tda_err_cnt);\r\n}\r\nif (val64 & TXDMA_PCC_INT) {\r\nif (do_s2io_chk_alarm_bit(PCC_SM_ERR_ALARM | PCC_WR_ERR_ALARM |\r\nPCC_N_SERR | PCC_6_COF_OV_ERR |\r\nPCC_7_COF_OV_ERR | PCC_6_LSO_OV_ERR |\r\nPCC_7_LSO_OV_ERR | PCC_FB_ECC_DB_ERR |\r\nPCC_TXB_ECC_DB_ERR,\r\n&bar0->pcc_err_reg,\r\n&sw_stat->pcc_err_cnt))\r\ngoto reset;\r\ndo_s2io_chk_alarm_bit(PCC_FB_ECC_SG_ERR | PCC_TXB_ECC_SG_ERR,\r\n&bar0->pcc_err_reg,\r\n&sw_stat->pcc_err_cnt);\r\n}\r\nif (val64 & TXDMA_TTI_INT) {\r\nif (do_s2io_chk_alarm_bit(TTI_SM_ERR_ALARM,\r\n&bar0->tti_err_reg,\r\n&sw_stat->tti_err_cnt))\r\ngoto reset;\r\ndo_s2io_chk_alarm_bit(TTI_ECC_SG_ERR | TTI_ECC_DB_ERR,\r\n&bar0->tti_err_reg,\r\n&sw_stat->tti_err_cnt);\r\n}\r\nif (val64 & TXDMA_LSO_INT) {\r\nif (do_s2io_chk_alarm_bit(LSO6_ABORT | LSO7_ABORT |\r\nLSO6_SM_ERR_ALARM | LSO7_SM_ERR_ALARM,\r\n&bar0->lso_err_reg,\r\n&sw_stat->lso_err_cnt))\r\ngoto reset;\r\ndo_s2io_chk_alarm_bit(LSO6_SEND_OFLOW | LSO7_SEND_OFLOW,\r\n&bar0->lso_err_reg,\r\n&sw_stat->lso_err_cnt);\r\n}\r\nif (val64 & TXDMA_TPA_INT) {\r\nif (do_s2io_chk_alarm_bit(TPA_SM_ERR_ALARM,\r\n&bar0->tpa_err_reg,\r\n&sw_stat->tpa_err_cnt))\r\ngoto reset;\r\ndo_s2io_chk_alarm_bit(TPA_TX_FRM_DROP,\r\n&bar0->tpa_err_reg,\r\n&sw_stat->tpa_err_cnt);\r\n}\r\nif (val64 & TXDMA_SM_INT) {\r\nif (do_s2io_chk_alarm_bit(SM_SM_ERR_ALARM,\r\n&bar0->sm_err_reg,\r\n&sw_stat->sm_err_cnt))\r\ngoto reset;\r\n}\r\nval64 = readq(&bar0->mac_int_status);\r\nif (val64 & MAC_INT_STATUS_TMAC_INT) {\r\nif (do_s2io_chk_alarm_bit(TMAC_TX_BUF_OVRN | TMAC_TX_SM_ERR,\r\n&bar0->mac_tmac_err_reg,\r\n&sw_stat->mac_tmac_err_cnt))\r\ngoto reset;\r\ndo_s2io_chk_alarm_bit(TMAC_ECC_SG_ERR | TMAC_ECC_DB_ERR |\r\nTMAC_DESC_ECC_SG_ERR |\r\nTMAC_DESC_ECC_DB_ERR,\r\n&bar0->mac_tmac_err_reg,\r\n&sw_stat->mac_tmac_err_cnt);\r\n}\r\nval64 = readq(&bar0->xgxs_int_status);\r\nif (val64 & XGXS_INT_STATUS_TXGXS) {\r\nif (do_s2io_chk_alarm_bit(TXGXS_ESTORE_UFLOW | TXGXS_TX_SM_ERR,\r\n&bar0->xgxs_txgxs_err_reg,\r\n&sw_stat->xgxs_txgxs_err_cnt))\r\ngoto reset;\r\ndo_s2io_chk_alarm_bit(TXGXS_ECC_SG_ERR | TXGXS_ECC_DB_ERR,\r\n&bar0->xgxs_txgxs_err_reg,\r\n&sw_stat->xgxs_txgxs_err_cnt);\r\n}\r\nval64 = readq(&bar0->rxdma_int_status);\r\nif (val64 & RXDMA_INT_RC_INT_M) {\r\nif (do_s2io_chk_alarm_bit(RC_PRCn_ECC_DB_ERR |\r\nRC_FTC_ECC_DB_ERR |\r\nRC_PRCn_SM_ERR_ALARM |\r\nRC_FTC_SM_ERR_ALARM,\r\n&bar0->rc_err_reg,\r\n&sw_stat->rc_err_cnt))\r\ngoto reset;\r\ndo_s2io_chk_alarm_bit(RC_PRCn_ECC_SG_ERR |\r\nRC_FTC_ECC_SG_ERR |\r\nRC_RDA_FAIL_WR_Rn, &bar0->rc_err_reg,\r\n&sw_stat->rc_err_cnt);\r\nif (do_s2io_chk_alarm_bit(PRC_PCI_AB_RD_Rn |\r\nPRC_PCI_AB_WR_Rn |\r\nPRC_PCI_AB_F_WR_Rn,\r\n&bar0->prc_pcix_err_reg,\r\n&sw_stat->prc_pcix_err_cnt))\r\ngoto reset;\r\ndo_s2io_chk_alarm_bit(PRC_PCI_DP_RD_Rn |\r\nPRC_PCI_DP_WR_Rn |\r\nPRC_PCI_DP_F_WR_Rn,\r\n&bar0->prc_pcix_err_reg,\r\n&sw_stat->prc_pcix_err_cnt);\r\n}\r\nif (val64 & RXDMA_INT_RPA_INT_M) {\r\nif (do_s2io_chk_alarm_bit(RPA_SM_ERR_ALARM | RPA_CREDIT_ERR,\r\n&bar0->rpa_err_reg,\r\n&sw_stat->rpa_err_cnt))\r\ngoto reset;\r\ndo_s2io_chk_alarm_bit(RPA_ECC_SG_ERR | RPA_ECC_DB_ERR,\r\n&bar0->rpa_err_reg,\r\n&sw_stat->rpa_err_cnt);\r\n}\r\nif (val64 & RXDMA_INT_RDA_INT_M) {\r\nif (do_s2io_chk_alarm_bit(RDA_RXDn_ECC_DB_ERR |\r\nRDA_FRM_ECC_DB_N_AERR |\r\nRDA_SM1_ERR_ALARM |\r\nRDA_SM0_ERR_ALARM |\r\nRDA_RXD_ECC_DB_SERR,\r\n&bar0->rda_err_reg,\r\n&sw_stat->rda_err_cnt))\r\ngoto reset;\r\ndo_s2io_chk_alarm_bit(RDA_RXDn_ECC_SG_ERR |\r\nRDA_FRM_ECC_SG_ERR |\r\nRDA_MISC_ERR |\r\nRDA_PCIX_ERR,\r\n&bar0->rda_err_reg,\r\n&sw_stat->rda_err_cnt);\r\n}\r\nif (val64 & RXDMA_INT_RTI_INT_M) {\r\nif (do_s2io_chk_alarm_bit(RTI_SM_ERR_ALARM,\r\n&bar0->rti_err_reg,\r\n&sw_stat->rti_err_cnt))\r\ngoto reset;\r\ndo_s2io_chk_alarm_bit(RTI_ECC_SG_ERR | RTI_ECC_DB_ERR,\r\n&bar0->rti_err_reg,\r\n&sw_stat->rti_err_cnt);\r\n}\r\nval64 = readq(&bar0->mac_int_status);\r\nif (val64 & MAC_INT_STATUS_RMAC_INT) {\r\nif (do_s2io_chk_alarm_bit(RMAC_RX_BUFF_OVRN | RMAC_RX_SM_ERR,\r\n&bar0->mac_rmac_err_reg,\r\n&sw_stat->mac_rmac_err_cnt))\r\ngoto reset;\r\ndo_s2io_chk_alarm_bit(RMAC_UNUSED_INT |\r\nRMAC_SINGLE_ECC_ERR |\r\nRMAC_DOUBLE_ECC_ERR,\r\n&bar0->mac_rmac_err_reg,\r\n&sw_stat->mac_rmac_err_cnt);\r\n}\r\nval64 = readq(&bar0->xgxs_int_status);\r\nif (val64 & XGXS_INT_STATUS_RXGXS) {\r\nif (do_s2io_chk_alarm_bit(RXGXS_ESTORE_OFLOW | RXGXS_RX_SM_ERR,\r\n&bar0->xgxs_rxgxs_err_reg,\r\n&sw_stat->xgxs_rxgxs_err_cnt))\r\ngoto reset;\r\n}\r\nval64 = readq(&bar0->mc_int_status);\r\nif (val64 & MC_INT_STATUS_MC_INT) {\r\nif (do_s2io_chk_alarm_bit(MC_ERR_REG_SM_ERR,\r\n&bar0->mc_err_reg,\r\n&sw_stat->mc_err_cnt))\r\ngoto reset;\r\nif (val64 & (MC_ERR_REG_ECC_ALL_SNG | MC_ERR_REG_ECC_ALL_DBL)) {\r\nwriteq(val64, &bar0->mc_err_reg);\r\nif (val64 & MC_ERR_REG_ECC_ALL_DBL) {\r\nsw_stat->double_ecc_errs++;\r\nif (sp->device_type != XFRAME_II_DEVICE) {\r\nif (val64 &\r\n(MC_ERR_REG_MIRI_ECC_DB_ERR_0 |\r\nMC_ERR_REG_MIRI_ECC_DB_ERR_1))\r\ngoto reset;\r\n}\r\n} else\r\nsw_stat->single_ecc_errs++;\r\n}\r\n}\r\nreturn;\r\nreset:\r\ns2io_stop_all_tx_queue(sp);\r\nschedule_work(&sp->rst_timer_task);\r\nsw_stat->soft_reset_cnt++;\r\n}\r\nstatic irqreturn_t s2io_isr(int irq, void *dev_id)\r\n{\r\nstruct net_device *dev = (struct net_device *)dev_id;\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nint i;\r\nu64 reason = 0;\r\nstruct mac_info *mac_control;\r\nstruct config_param *config;\r\nif (pci_channel_offline(sp->pdev))\r\nreturn IRQ_NONE;\r\nif (!is_s2io_card_up(sp))\r\nreturn IRQ_NONE;\r\nconfig = &sp->config;\r\nmac_control = &sp->mac_control;\r\nreason = readq(&bar0->general_int_status);\r\nif (unlikely(reason == S2IO_MINUS_ONE))\r\nreturn IRQ_HANDLED;\r\nif (reason &\r\n(GEN_INTR_RXTRAFFIC | GEN_INTR_TXTRAFFIC | GEN_INTR_TXPIC)) {\r\nwriteq(S2IO_MINUS_ONE, &bar0->general_int_mask);\r\nif (config->napi) {\r\nif (reason & GEN_INTR_RXTRAFFIC) {\r\nnapi_schedule(&sp->napi);\r\nwriteq(S2IO_MINUS_ONE, &bar0->rx_traffic_mask);\r\nwriteq(S2IO_MINUS_ONE, &bar0->rx_traffic_int);\r\nreadl(&bar0->rx_traffic_int);\r\n}\r\n} else {\r\nif (reason & GEN_INTR_RXTRAFFIC)\r\nwriteq(S2IO_MINUS_ONE, &bar0->rx_traffic_int);\r\nfor (i = 0; i < config->rx_ring_num; i++) {\r\nstruct ring_info *ring = &mac_control->rings[i];\r\nrx_intr_handler(ring, 0);\r\n}\r\n}\r\nif (reason & GEN_INTR_TXTRAFFIC)\r\nwriteq(S2IO_MINUS_ONE, &bar0->tx_traffic_int);\r\nfor (i = 0; i < config->tx_fifo_num; i++)\r\ntx_intr_handler(&mac_control->fifos[i]);\r\nif (reason & GEN_INTR_TXPIC)\r\ns2io_txpic_intr_handle(sp);\r\nif (!config->napi) {\r\nfor (i = 0; i < config->rx_ring_num; i++) {\r\nstruct ring_info *ring = &mac_control->rings[i];\r\ns2io_chk_rx_buffers(sp, ring);\r\n}\r\n}\r\nwriteq(sp->general_int_mask, &bar0->general_int_mask);\r\nreadl(&bar0->general_int_status);\r\nreturn IRQ_HANDLED;\r\n} else if (!reason) {\r\nreturn IRQ_NONE;\r\n}\r\nreturn IRQ_HANDLED;\r\n}\r\nstatic void s2io_updt_stats(struct s2io_nic *sp)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nu64 val64;\r\nint cnt = 0;\r\nif (is_s2io_card_up(sp)) {\r\nval64 = SET_UPDT_CLICKS(10) |\r\nSTAT_CFG_ONE_SHOT_EN | STAT_CFG_STAT_EN;\r\nwriteq(val64, &bar0->stat_cfg);\r\ndo {\r\nudelay(100);\r\nval64 = readq(&bar0->stat_cfg);\r\nif (!(val64 & s2BIT(0)))\r\nbreak;\r\ncnt++;\r\nif (cnt == 5)\r\nbreak;\r\n} while (1);\r\n}\r\n}\r\nstatic struct net_device_stats *s2io_get_stats(struct net_device *dev)\r\n{\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nstruct mac_info *mac_control = &sp->mac_control;\r\nstruct stat_block *stats = mac_control->stats_info;\r\nu64 delta;\r\ns2io_updt_stats(sp);\r\ndelta = ((u64) le32_to_cpu(stats->rmac_vld_frms_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_vld_frms)) - sp->stats.rx_packets;\r\nsp->stats.rx_packets += delta;\r\ndev->stats.rx_packets += delta;\r\ndelta = ((u64) le32_to_cpu(stats->tmac_frms_oflow) << 32 |\r\nle32_to_cpu(stats->tmac_frms)) - sp->stats.tx_packets;\r\nsp->stats.tx_packets += delta;\r\ndev->stats.tx_packets += delta;\r\ndelta = ((u64) le32_to_cpu(stats->rmac_data_octets_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_data_octets)) - sp->stats.rx_bytes;\r\nsp->stats.rx_bytes += delta;\r\ndev->stats.rx_bytes += delta;\r\ndelta = ((u64) le32_to_cpu(stats->tmac_data_octets_oflow) << 32 |\r\nle32_to_cpu(stats->tmac_data_octets)) - sp->stats.tx_bytes;\r\nsp->stats.tx_bytes += delta;\r\ndev->stats.tx_bytes += delta;\r\ndelta = le64_to_cpu(stats->rmac_drop_frms) - sp->stats.rx_errors;\r\nsp->stats.rx_errors += delta;\r\ndev->stats.rx_errors += delta;\r\ndelta = ((u64) le32_to_cpu(stats->tmac_any_err_frms_oflow) << 32 |\r\nle32_to_cpu(stats->tmac_any_err_frms)) - sp->stats.tx_errors;\r\nsp->stats.tx_errors += delta;\r\ndev->stats.tx_errors += delta;\r\ndelta = le64_to_cpu(stats->rmac_drop_frms) - sp->stats.rx_dropped;\r\nsp->stats.rx_dropped += delta;\r\ndev->stats.rx_dropped += delta;\r\ndelta = le64_to_cpu(stats->tmac_drop_frms) - sp->stats.tx_dropped;\r\nsp->stats.tx_dropped += delta;\r\ndev->stats.tx_dropped += delta;\r\ndelta = (u64) le32_to_cpu(stats->rmac_vld_mcst_frms_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_vld_mcst_frms);\r\ndelta -= le64_to_cpu(stats->rmac_pause_ctrl_frms);\r\ndelta -= sp->stats.multicast;\r\nsp->stats.multicast += delta;\r\ndev->stats.multicast += delta;\r\ndelta = ((u64) le32_to_cpu(stats->rmac_usized_frms_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_usized_frms)) +\r\nle64_to_cpu(stats->rmac_long_frms) - sp->stats.rx_length_errors;\r\nsp->stats.rx_length_errors += delta;\r\ndev->stats.rx_length_errors += delta;\r\ndelta = le64_to_cpu(stats->rmac_fcs_err_frms) - sp->stats.rx_crc_errors;\r\nsp->stats.rx_crc_errors += delta;\r\ndev->stats.rx_crc_errors += delta;\r\nreturn &dev->stats;\r\n}\r\nstatic void s2io_set_multicast(struct net_device *dev)\r\n{\r\nint i, j, prev_cnt;\r\nstruct netdev_hw_addr *ha;\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nu64 val64 = 0, multi_mac = 0x010203040506ULL, mask =\r\n0xfeffffffffffULL;\r\nu64 dis_addr = S2IO_DISABLE_MAC_ENTRY, mac_addr = 0;\r\nvoid __iomem *add;\r\nstruct config_param *config = &sp->config;\r\nif ((dev->flags & IFF_ALLMULTI) && (!sp->m_cast_flg)) {\r\nwriteq(RMAC_ADDR_DATA0_MEM_ADDR(multi_mac),\r\n&bar0->rmac_addr_data0_mem);\r\nwriteq(RMAC_ADDR_DATA1_MEM_MASK(mask),\r\n&bar0->rmac_addr_data1_mem);\r\nval64 = RMAC_ADDR_CMD_MEM_WE |\r\nRMAC_ADDR_CMD_MEM_STROBE_NEW_CMD |\r\nRMAC_ADDR_CMD_MEM_OFFSET(config->max_mc_addr - 1);\r\nwriteq(val64, &bar0->rmac_addr_cmd_mem);\r\nwait_for_cmd_complete(&bar0->rmac_addr_cmd_mem,\r\nRMAC_ADDR_CMD_MEM_STROBE_CMD_EXECUTING,\r\nS2IO_BIT_RESET);\r\nsp->m_cast_flg = 1;\r\nsp->all_multi_pos = config->max_mc_addr - 1;\r\n} else if ((dev->flags & IFF_ALLMULTI) && (sp->m_cast_flg)) {\r\nwriteq(RMAC_ADDR_DATA0_MEM_ADDR(dis_addr),\r\n&bar0->rmac_addr_data0_mem);\r\nwriteq(RMAC_ADDR_DATA1_MEM_MASK(0x0),\r\n&bar0->rmac_addr_data1_mem);\r\nval64 = RMAC_ADDR_CMD_MEM_WE |\r\nRMAC_ADDR_CMD_MEM_STROBE_NEW_CMD |\r\nRMAC_ADDR_CMD_MEM_OFFSET(sp->all_multi_pos);\r\nwriteq(val64, &bar0->rmac_addr_cmd_mem);\r\nwait_for_cmd_complete(&bar0->rmac_addr_cmd_mem,\r\nRMAC_ADDR_CMD_MEM_STROBE_CMD_EXECUTING,\r\nS2IO_BIT_RESET);\r\nsp->m_cast_flg = 0;\r\nsp->all_multi_pos = 0;\r\n}\r\nif ((dev->flags & IFF_PROMISC) && (!sp->promisc_flg)) {\r\nadd = &bar0->mac_cfg;\r\nval64 = readq(&bar0->mac_cfg);\r\nval64 |= MAC_CFG_RMAC_PROM_ENABLE;\r\nwriteq(RMAC_CFG_KEY(0x4C0D), &bar0->rmac_cfg_key);\r\nwritel((u32)val64, add);\r\nwriteq(RMAC_CFG_KEY(0x4C0D), &bar0->rmac_cfg_key);\r\nwritel((u32) (val64 >> 32), (add + 4));\r\nif (vlan_tag_strip != 1) {\r\nval64 = readq(&bar0->rx_pa_cfg);\r\nval64 &= ~RX_PA_CFG_STRIP_VLAN_TAG;\r\nwriteq(val64, &bar0->rx_pa_cfg);\r\nsp->vlan_strip_flag = 0;\r\n}\r\nval64 = readq(&bar0->mac_cfg);\r\nsp->promisc_flg = 1;\r\nDBG_PRINT(INFO_DBG, "%s: entered promiscuous mode\n",\r\ndev->name);\r\n} else if (!(dev->flags & IFF_PROMISC) && (sp->promisc_flg)) {\r\nadd = &bar0->mac_cfg;\r\nval64 = readq(&bar0->mac_cfg);\r\nval64 &= ~MAC_CFG_RMAC_PROM_ENABLE;\r\nwriteq(RMAC_CFG_KEY(0x4C0D), &bar0->rmac_cfg_key);\r\nwritel((u32)val64, add);\r\nwriteq(RMAC_CFG_KEY(0x4C0D), &bar0->rmac_cfg_key);\r\nwritel((u32) (val64 >> 32), (add + 4));\r\nif (vlan_tag_strip != 0) {\r\nval64 = readq(&bar0->rx_pa_cfg);\r\nval64 |= RX_PA_CFG_STRIP_VLAN_TAG;\r\nwriteq(val64, &bar0->rx_pa_cfg);\r\nsp->vlan_strip_flag = 1;\r\n}\r\nval64 = readq(&bar0->mac_cfg);\r\nsp->promisc_flg = 0;\r\nDBG_PRINT(INFO_DBG, "%s: left promiscuous mode\n", dev->name);\r\n}\r\nif ((!sp->m_cast_flg) && netdev_mc_count(dev)) {\r\nif (netdev_mc_count(dev) >\r\n(config->max_mc_addr - config->max_mac_addr)) {\r\nDBG_PRINT(ERR_DBG,\r\n"%s: No more Rx filters can be added - "\r\n"please enable ALL_MULTI instead\n",\r\ndev->name);\r\nreturn;\r\n}\r\nprev_cnt = sp->mc_addr_count;\r\nsp->mc_addr_count = netdev_mc_count(dev);\r\nfor (i = 0; i < prev_cnt; i++) {\r\nwriteq(RMAC_ADDR_DATA0_MEM_ADDR(dis_addr),\r\n&bar0->rmac_addr_data0_mem);\r\nwriteq(RMAC_ADDR_DATA1_MEM_MASK(0ULL),\r\n&bar0->rmac_addr_data1_mem);\r\nval64 = RMAC_ADDR_CMD_MEM_WE |\r\nRMAC_ADDR_CMD_MEM_STROBE_NEW_CMD |\r\nRMAC_ADDR_CMD_MEM_OFFSET\r\n(config->mc_start_offset + i);\r\nwriteq(val64, &bar0->rmac_addr_cmd_mem);\r\nif (wait_for_cmd_complete(&bar0->rmac_addr_cmd_mem,\r\nRMAC_ADDR_CMD_MEM_STROBE_CMD_EXECUTING,\r\nS2IO_BIT_RESET)) {\r\nDBG_PRINT(ERR_DBG,\r\n"%s: Adding Multicasts failed\n",\r\ndev->name);\r\nreturn;\r\n}\r\n}\r\ni = 0;\r\nnetdev_for_each_mc_addr(ha, dev) {\r\nmac_addr = 0;\r\nfor (j = 0; j < ETH_ALEN; j++) {\r\nmac_addr |= ha->addr[j];\r\nmac_addr <<= 8;\r\n}\r\nmac_addr >>= 8;\r\nwriteq(RMAC_ADDR_DATA0_MEM_ADDR(mac_addr),\r\n&bar0->rmac_addr_data0_mem);\r\nwriteq(RMAC_ADDR_DATA1_MEM_MASK(0ULL),\r\n&bar0->rmac_addr_data1_mem);\r\nval64 = RMAC_ADDR_CMD_MEM_WE |\r\nRMAC_ADDR_CMD_MEM_STROBE_NEW_CMD |\r\nRMAC_ADDR_CMD_MEM_OFFSET\r\n(i + config->mc_start_offset);\r\nwriteq(val64, &bar0->rmac_addr_cmd_mem);\r\nif (wait_for_cmd_complete(&bar0->rmac_addr_cmd_mem,\r\nRMAC_ADDR_CMD_MEM_STROBE_CMD_EXECUTING,\r\nS2IO_BIT_RESET)) {\r\nDBG_PRINT(ERR_DBG,\r\n"%s: Adding Multicasts failed\n",\r\ndev->name);\r\nreturn;\r\n}\r\ni++;\r\n}\r\n}\r\n}\r\nstatic void do_s2io_store_unicast_mc(struct s2io_nic *sp)\r\n{\r\nint offset;\r\nu64 mac_addr = 0x0;\r\nstruct config_param *config = &sp->config;\r\nfor (offset = 0; offset < config->max_mc_addr; offset++) {\r\nmac_addr = do_s2io_read_unicast_mc(sp, offset);\r\nif (mac_addr == FAILURE)\r\nmac_addr = S2IO_DISABLE_MAC_ENTRY;\r\ndo_s2io_copy_mac_addr(sp, offset, mac_addr);\r\n}\r\n}\r\nstatic void do_s2io_restore_unicast_mc(struct s2io_nic *sp)\r\n{\r\nint offset;\r\nstruct config_param *config = &sp->config;\r\nfor (offset = 0; offset < config->max_mac_addr; offset++)\r\ndo_s2io_prog_unicast(sp->dev,\r\nsp->def_mac_addr[offset].mac_addr);\r\nfor (offset = config->mc_start_offset;\r\noffset < config->max_mc_addr; offset++)\r\ndo_s2io_add_mc(sp, sp->def_mac_addr[offset].mac_addr);\r\n}\r\nstatic int do_s2io_add_mc(struct s2io_nic *sp, u8 *addr)\r\n{\r\nint i;\r\nu64 mac_addr = 0;\r\nstruct config_param *config = &sp->config;\r\nfor (i = 0; i < ETH_ALEN; i++) {\r\nmac_addr <<= 8;\r\nmac_addr |= addr[i];\r\n}\r\nif ((0ULL == mac_addr) || (mac_addr == S2IO_DISABLE_MAC_ENTRY))\r\nreturn SUCCESS;\r\nfor (i = config->mc_start_offset; i < config->max_mc_addr; i++) {\r\nu64 tmp64;\r\ntmp64 = do_s2io_read_unicast_mc(sp, i);\r\nif (tmp64 == S2IO_DISABLE_MAC_ENTRY)\r\nbreak;\r\nif (tmp64 == mac_addr)\r\nreturn SUCCESS;\r\n}\r\nif (i == config->max_mc_addr) {\r\nDBG_PRINT(ERR_DBG,\r\n"CAM full no space left for multicast MAC\n");\r\nreturn FAILURE;\r\n}\r\ndo_s2io_copy_mac_addr(sp, i, mac_addr);\r\nreturn do_s2io_add_mac(sp, mac_addr, i);\r\n}\r\nstatic int do_s2io_add_mac(struct s2io_nic *sp, u64 addr, int off)\r\n{\r\nu64 val64;\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nwriteq(RMAC_ADDR_DATA0_MEM_ADDR(addr),\r\n&bar0->rmac_addr_data0_mem);\r\nval64 = RMAC_ADDR_CMD_MEM_WE | RMAC_ADDR_CMD_MEM_STROBE_NEW_CMD |\r\nRMAC_ADDR_CMD_MEM_OFFSET(off);\r\nwriteq(val64, &bar0->rmac_addr_cmd_mem);\r\nif (wait_for_cmd_complete(&bar0->rmac_addr_cmd_mem,\r\nRMAC_ADDR_CMD_MEM_STROBE_CMD_EXECUTING,\r\nS2IO_BIT_RESET)) {\r\nDBG_PRINT(INFO_DBG, "do_s2io_add_mac failed\n");\r\nreturn FAILURE;\r\n}\r\nreturn SUCCESS;\r\n}\r\nstatic int do_s2io_delete_unicast_mc(struct s2io_nic *sp, u64 addr)\r\n{\r\nint offset;\r\nu64 dis_addr = S2IO_DISABLE_MAC_ENTRY, tmp64;\r\nstruct config_param *config = &sp->config;\r\nfor (offset = 1;\r\noffset < config->max_mc_addr; offset++) {\r\ntmp64 = do_s2io_read_unicast_mc(sp, offset);\r\nif (tmp64 == addr) {\r\nif (do_s2io_add_mac(sp, dis_addr, offset) == FAILURE)\r\nreturn FAILURE;\r\ndo_s2io_store_unicast_mc(sp);\r\nreturn SUCCESS;\r\n}\r\n}\r\nDBG_PRINT(ERR_DBG, "MAC address 0x%llx not found in CAM\n",\r\n(unsigned long long)addr);\r\nreturn FAILURE;\r\n}\r\nstatic u64 do_s2io_read_unicast_mc(struct s2io_nic *sp, int offset)\r\n{\r\nu64 tmp64 = 0xffffffffffff0000ULL, val64;\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nval64 = RMAC_ADDR_CMD_MEM_RD | RMAC_ADDR_CMD_MEM_STROBE_NEW_CMD |\r\nRMAC_ADDR_CMD_MEM_OFFSET(offset);\r\nwriteq(val64, &bar0->rmac_addr_cmd_mem);\r\nif (wait_for_cmd_complete(&bar0->rmac_addr_cmd_mem,\r\nRMAC_ADDR_CMD_MEM_STROBE_CMD_EXECUTING,\r\nS2IO_BIT_RESET)) {\r\nDBG_PRINT(INFO_DBG, "do_s2io_read_unicast_mc failed\n");\r\nreturn FAILURE;\r\n}\r\ntmp64 = readq(&bar0->rmac_addr_data0_mem);\r\nreturn tmp64 >> 16;\r\n}\r\nstatic int s2io_set_mac_addr(struct net_device *dev, void *p)\r\n{\r\nstruct sockaddr *addr = p;\r\nif (!is_valid_ether_addr(addr->sa_data))\r\nreturn -EADDRNOTAVAIL;\r\nmemcpy(dev->dev_addr, addr->sa_data, dev->addr_len);\r\nreturn do_s2io_prog_unicast(dev, dev->dev_addr);\r\n}\r\nstatic int do_s2io_prog_unicast(struct net_device *dev, u8 *addr)\r\n{\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nregister u64 mac_addr = 0, perm_addr = 0;\r\nint i;\r\nu64 tmp64;\r\nstruct config_param *config = &sp->config;\r\nfor (i = 0; i < ETH_ALEN; i++) {\r\nmac_addr <<= 8;\r\nmac_addr |= addr[i];\r\nperm_addr <<= 8;\r\nperm_addr |= sp->def_mac_addr[0].mac_addr[i];\r\n}\r\nif (mac_addr == perm_addr)\r\nreturn SUCCESS;\r\nfor (i = 1; i < config->max_mac_addr; i++) {\r\ntmp64 = do_s2io_read_unicast_mc(sp, i);\r\nif (tmp64 == S2IO_DISABLE_MAC_ENTRY)\r\nbreak;\r\nif (tmp64 == mac_addr) {\r\nDBG_PRINT(INFO_DBG,\r\n"MAC addr:0x%llx already present in CAM\n",\r\n(unsigned long long)mac_addr);\r\nreturn SUCCESS;\r\n}\r\n}\r\nif (i == config->max_mac_addr) {\r\nDBG_PRINT(ERR_DBG, "CAM full no space left for Unicast MAC\n");\r\nreturn FAILURE;\r\n}\r\ndo_s2io_copy_mac_addr(sp, i, mac_addr);\r\nreturn do_s2io_add_mac(sp, mac_addr, i);\r\n}\r\nstatic int s2io_ethtool_sset(struct net_device *dev,\r\nstruct ethtool_cmd *info)\r\n{\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nif ((info->autoneg == AUTONEG_ENABLE) ||\r\n(ethtool_cmd_speed(info) != SPEED_10000) ||\r\n(info->duplex != DUPLEX_FULL))\r\nreturn -EINVAL;\r\nelse {\r\ns2io_close(sp->dev);\r\ns2io_open(sp->dev);\r\n}\r\nreturn 0;\r\n}\r\nstatic int s2io_ethtool_gset(struct net_device *dev, struct ethtool_cmd *info)\r\n{\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\ninfo->supported = (SUPPORTED_10000baseT_Full | SUPPORTED_FIBRE);\r\ninfo->advertising = (SUPPORTED_10000baseT_Full | SUPPORTED_FIBRE);\r\ninfo->port = PORT_FIBRE;\r\ninfo->transceiver = XCVR_EXTERNAL;\r\nif (netif_carrier_ok(sp->dev)) {\r\nethtool_cmd_speed_set(info, SPEED_10000);\r\ninfo->duplex = DUPLEX_FULL;\r\n} else {\r\nethtool_cmd_speed_set(info, -1);\r\ninfo->duplex = -1;\r\n}\r\ninfo->autoneg = AUTONEG_DISABLE;\r\nreturn 0;\r\n}\r\nstatic void s2io_ethtool_gdrvinfo(struct net_device *dev,\r\nstruct ethtool_drvinfo *info)\r\n{\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nstrlcpy(info->driver, s2io_driver_name, sizeof(info->driver));\r\nstrlcpy(info->version, s2io_driver_version, sizeof(info->version));\r\nstrlcpy(info->bus_info, pci_name(sp->pdev), sizeof(info->bus_info));\r\ninfo->regdump_len = XENA_REG_SPACE;\r\ninfo->eedump_len = XENA_EEPROM_SPACE;\r\n}\r\nstatic void s2io_ethtool_gregs(struct net_device *dev,\r\nstruct ethtool_regs *regs, void *space)\r\n{\r\nint i;\r\nu64 reg;\r\nu8 *reg_space = (u8 *)space;\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nregs->len = XENA_REG_SPACE;\r\nregs->version = sp->pdev->subsystem_device;\r\nfor (i = 0; i < regs->len; i += 8) {\r\nreg = readq(sp->bar0 + i);\r\nmemcpy((reg_space + i), &reg, 8);\r\n}\r\n}\r\nstatic void s2io_set_led(struct s2io_nic *sp, bool on)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nu16 subid = sp->pdev->subsystem_device;\r\nu64 val64;\r\nif ((sp->device_type == XFRAME_II_DEVICE) ||\r\n((subid & 0xFF) >= 0x07)) {\r\nval64 = readq(&bar0->gpio_control);\r\nif (on)\r\nval64 |= GPIO_CTRL_GPIO_0;\r\nelse\r\nval64 &= ~GPIO_CTRL_GPIO_0;\r\nwriteq(val64, &bar0->gpio_control);\r\n} else {\r\nval64 = readq(&bar0->adapter_control);\r\nif (on)\r\nval64 |= ADAPTER_LED_ON;\r\nelse\r\nval64 &= ~ADAPTER_LED_ON;\r\nwriteq(val64, &bar0->adapter_control);\r\n}\r\n}\r\nstatic int s2io_ethtool_set_led(struct net_device *dev,\r\nenum ethtool_phys_id_state state)\r\n{\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nu16 subid = sp->pdev->subsystem_device;\r\nif ((sp->device_type == XFRAME_I_DEVICE) && ((subid & 0xFF) < 0x07)) {\r\nu64 val64 = readq(&bar0->adapter_control);\r\nif (!(val64 & ADAPTER_CNTL_EN)) {\r\npr_err("Adapter Link down, cannot blink LED\n");\r\nreturn -EAGAIN;\r\n}\r\n}\r\nswitch (state) {\r\ncase ETHTOOL_ID_ACTIVE:\r\nsp->adapt_ctrl_org = readq(&bar0->gpio_control);\r\nreturn 1;\r\ncase ETHTOOL_ID_ON:\r\ns2io_set_led(sp, true);\r\nbreak;\r\ncase ETHTOOL_ID_OFF:\r\ns2io_set_led(sp, false);\r\nbreak;\r\ncase ETHTOOL_ID_INACTIVE:\r\nif (CARDS_WITH_FAULTY_LINK_INDICATORS(sp->device_type, subid))\r\nwriteq(sp->adapt_ctrl_org, &bar0->gpio_control);\r\n}\r\nreturn 0;\r\n}\r\nstatic void s2io_ethtool_gringparam(struct net_device *dev,\r\nstruct ethtool_ringparam *ering)\r\n{\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nint i, tx_desc_count = 0, rx_desc_count = 0;\r\nif (sp->rxd_mode == RXD_MODE_1) {\r\nering->rx_max_pending = MAX_RX_DESC_1;\r\nering->rx_jumbo_max_pending = MAX_RX_DESC_1;\r\n} else {\r\nering->rx_max_pending = MAX_RX_DESC_2;\r\nering->rx_jumbo_max_pending = MAX_RX_DESC_2;\r\n}\r\nering->tx_max_pending = MAX_TX_DESC;\r\nfor (i = 0; i < sp->config.rx_ring_num; i++)\r\nrx_desc_count += sp->config.rx_cfg[i].num_rxd;\r\nering->rx_pending = rx_desc_count;\r\nering->rx_jumbo_pending = rx_desc_count;\r\nfor (i = 0; i < sp->config.tx_fifo_num; i++)\r\ntx_desc_count += sp->config.tx_cfg[i].fifo_len;\r\nering->tx_pending = tx_desc_count;\r\nDBG_PRINT(INFO_DBG, "max txds: %d\n", sp->config.max_txds);\r\n}\r\nstatic void s2io_ethtool_getpause_data(struct net_device *dev,\r\nstruct ethtool_pauseparam *ep)\r\n{\r\nu64 val64;\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nval64 = readq(&bar0->rmac_pause_cfg);\r\nif (val64 & RMAC_PAUSE_GEN_ENABLE)\r\nep->tx_pause = true;\r\nif (val64 & RMAC_PAUSE_RX_ENABLE)\r\nep->rx_pause = true;\r\nep->autoneg = false;\r\n}\r\nstatic int s2io_ethtool_setpause_data(struct net_device *dev,\r\nstruct ethtool_pauseparam *ep)\r\n{\r\nu64 val64;\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nval64 = readq(&bar0->rmac_pause_cfg);\r\nif (ep->tx_pause)\r\nval64 |= RMAC_PAUSE_GEN_ENABLE;\r\nelse\r\nval64 &= ~RMAC_PAUSE_GEN_ENABLE;\r\nif (ep->rx_pause)\r\nval64 |= RMAC_PAUSE_RX_ENABLE;\r\nelse\r\nval64 &= ~RMAC_PAUSE_RX_ENABLE;\r\nwriteq(val64, &bar0->rmac_pause_cfg);\r\nreturn 0;\r\n}\r\nstatic int read_eeprom(struct s2io_nic *sp, int off, u64 *data)\r\n{\r\nint ret = -1;\r\nu32 exit_cnt = 0;\r\nu64 val64;\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nif (sp->device_type == XFRAME_I_DEVICE) {\r\nval64 = I2C_CONTROL_DEV_ID(S2IO_DEV_ID) |\r\nI2C_CONTROL_ADDR(off) |\r\nI2C_CONTROL_BYTE_CNT(0x3) |\r\nI2C_CONTROL_READ |\r\nI2C_CONTROL_CNTL_START;\r\nSPECIAL_REG_WRITE(val64, &bar0->i2c_control, LF);\r\nwhile (exit_cnt < 5) {\r\nval64 = readq(&bar0->i2c_control);\r\nif (I2C_CONTROL_CNTL_END(val64)) {\r\n*data = I2C_CONTROL_GET_DATA(val64);\r\nret = 0;\r\nbreak;\r\n}\r\nmsleep(50);\r\nexit_cnt++;\r\n}\r\n}\r\nif (sp->device_type == XFRAME_II_DEVICE) {\r\nval64 = SPI_CONTROL_KEY(0x9) | SPI_CONTROL_SEL1 |\r\nSPI_CONTROL_BYTECNT(0x3) |\r\nSPI_CONTROL_CMD(0x3) | SPI_CONTROL_ADDR(off);\r\nSPECIAL_REG_WRITE(val64, &bar0->spi_control, LF);\r\nval64 |= SPI_CONTROL_REQ;\r\nSPECIAL_REG_WRITE(val64, &bar0->spi_control, LF);\r\nwhile (exit_cnt < 5) {\r\nval64 = readq(&bar0->spi_control);\r\nif (val64 & SPI_CONTROL_NACK) {\r\nret = 1;\r\nbreak;\r\n} else if (val64 & SPI_CONTROL_DONE) {\r\n*data = readq(&bar0->spi_data);\r\n*data &= 0xffffff;\r\nret = 0;\r\nbreak;\r\n}\r\nmsleep(50);\r\nexit_cnt++;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic int write_eeprom(struct s2io_nic *sp, int off, u64 data, int cnt)\r\n{\r\nint exit_cnt = 0, ret = -1;\r\nu64 val64;\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nif (sp->device_type == XFRAME_I_DEVICE) {\r\nval64 = I2C_CONTROL_DEV_ID(S2IO_DEV_ID) |\r\nI2C_CONTROL_ADDR(off) |\r\nI2C_CONTROL_BYTE_CNT(cnt) |\r\nI2C_CONTROL_SET_DATA((u32)data) |\r\nI2C_CONTROL_CNTL_START;\r\nSPECIAL_REG_WRITE(val64, &bar0->i2c_control, LF);\r\nwhile (exit_cnt < 5) {\r\nval64 = readq(&bar0->i2c_control);\r\nif (I2C_CONTROL_CNTL_END(val64)) {\r\nif (!(val64 & I2C_CONTROL_NACK))\r\nret = 0;\r\nbreak;\r\n}\r\nmsleep(50);\r\nexit_cnt++;\r\n}\r\n}\r\nif (sp->device_type == XFRAME_II_DEVICE) {\r\nint write_cnt = (cnt == 8) ? 0 : cnt;\r\nwriteq(SPI_DATA_WRITE(data, (cnt << 3)), &bar0->spi_data);\r\nval64 = SPI_CONTROL_KEY(0x9) | SPI_CONTROL_SEL1 |\r\nSPI_CONTROL_BYTECNT(write_cnt) |\r\nSPI_CONTROL_CMD(0x2) | SPI_CONTROL_ADDR(off);\r\nSPECIAL_REG_WRITE(val64, &bar0->spi_control, LF);\r\nval64 |= SPI_CONTROL_REQ;\r\nSPECIAL_REG_WRITE(val64, &bar0->spi_control, LF);\r\nwhile (exit_cnt < 5) {\r\nval64 = readq(&bar0->spi_control);\r\nif (val64 & SPI_CONTROL_NACK) {\r\nret = 1;\r\nbreak;\r\n} else if (val64 & SPI_CONTROL_DONE) {\r\nret = 0;\r\nbreak;\r\n}\r\nmsleep(50);\r\nexit_cnt++;\r\n}\r\n}\r\nreturn ret;\r\n}\r\nstatic void s2io_vpd_read(struct s2io_nic *nic)\r\n{\r\nu8 *vpd_data;\r\nu8 data;\r\nint i = 0, cnt, len, fail = 0;\r\nint vpd_addr = 0x80;\r\nstruct swStat *swstats = &nic->mac_control.stats_info->sw_stat;\r\nif (nic->device_type == XFRAME_II_DEVICE) {\r\nstrcpy(nic->product_name, "Xframe II 10GbE network adapter");\r\nvpd_addr = 0x80;\r\n} else {\r\nstrcpy(nic->product_name, "Xframe I 10GbE network adapter");\r\nvpd_addr = 0x50;\r\n}\r\nstrcpy(nic->serial_num, "NOT AVAILABLE");\r\nvpd_data = kmalloc(256, GFP_KERNEL);\r\nif (!vpd_data) {\r\nswstats->mem_alloc_fail_cnt++;\r\nreturn;\r\n}\r\nswstats->mem_allocated += 256;\r\nfor (i = 0; i < 256; i += 4) {\r\npci_write_config_byte(nic->pdev, (vpd_addr + 2), i);\r\npci_read_config_byte(nic->pdev, (vpd_addr + 2), &data);\r\npci_write_config_byte(nic->pdev, (vpd_addr + 3), 0);\r\nfor (cnt = 0; cnt < 5; cnt++) {\r\nmsleep(2);\r\npci_read_config_byte(nic->pdev, (vpd_addr + 3), &data);\r\nif (data == 0x80)\r\nbreak;\r\n}\r\nif (cnt >= 5) {\r\nDBG_PRINT(ERR_DBG, "Read of VPD data failed\n");\r\nfail = 1;\r\nbreak;\r\n}\r\npci_read_config_dword(nic->pdev, (vpd_addr + 4),\r\n(u32 *)&vpd_data[i]);\r\n}\r\nif (!fail) {\r\nfor (cnt = 0; cnt < 252; cnt++) {\r\nif ((vpd_data[cnt] == 'S') &&\r\n(vpd_data[cnt+1] == 'N')) {\r\nlen = vpd_data[cnt+2];\r\nif (len < min(VPD_STRING_LEN, 256-cnt-2)) {\r\nmemcpy(nic->serial_num,\r\n&vpd_data[cnt + 3],\r\nlen);\r\nmemset(nic->serial_num+len,\r\n0,\r\nVPD_STRING_LEN-len);\r\nbreak;\r\n}\r\n}\r\n}\r\n}\r\nif ((!fail) && (vpd_data[1] < VPD_STRING_LEN)) {\r\nlen = vpd_data[1];\r\nmemcpy(nic->product_name, &vpd_data[3], len);\r\nnic->product_name[len] = 0;\r\n}\r\nkfree(vpd_data);\r\nswstats->mem_freed += 256;\r\n}\r\nstatic int s2io_ethtool_geeprom(struct net_device *dev,\r\nstruct ethtool_eeprom *eeprom, u8 * data_buf)\r\n{\r\nu32 i, valid;\r\nu64 data;\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\neeprom->magic = sp->pdev->vendor | (sp->pdev->device << 16);\r\nif ((eeprom->offset + eeprom->len) > (XENA_EEPROM_SPACE))\r\neeprom->len = XENA_EEPROM_SPACE - eeprom->offset;\r\nfor (i = 0; i < eeprom->len; i += 4) {\r\nif (read_eeprom(sp, (eeprom->offset + i), &data)) {\r\nDBG_PRINT(ERR_DBG, "Read of EEPROM failed\n");\r\nreturn -EFAULT;\r\n}\r\nvalid = INV(data);\r\nmemcpy((data_buf + i), &valid, 4);\r\n}\r\nreturn 0;\r\n}\r\nstatic int s2io_ethtool_seeprom(struct net_device *dev,\r\nstruct ethtool_eeprom *eeprom,\r\nu8 *data_buf)\r\n{\r\nint len = eeprom->len, cnt = 0;\r\nu64 valid = 0, data;\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nif (eeprom->magic != (sp->pdev->vendor | (sp->pdev->device << 16))) {\r\nDBG_PRINT(ERR_DBG,\r\n"ETHTOOL_WRITE_EEPROM Err: "\r\n"Magic value is wrong, it is 0x%x should be 0x%x\n",\r\n(sp->pdev->vendor | (sp->pdev->device << 16)),\r\neeprom->magic);\r\nreturn -EFAULT;\r\n}\r\nwhile (len) {\r\ndata = (u32)data_buf[cnt] & 0x000000FF;\r\nif (data)\r\nvalid = (u32)(data << 24);\r\nelse\r\nvalid = data;\r\nif (write_eeprom(sp, (eeprom->offset + cnt), valid, 0)) {\r\nDBG_PRINT(ERR_DBG,\r\n"ETHTOOL_WRITE_EEPROM Err: "\r\n"Cannot write into the specified offset\n");\r\nreturn -EFAULT;\r\n}\r\ncnt++;\r\nlen--;\r\n}\r\nreturn 0;\r\n}\r\nstatic int s2io_register_test(struct s2io_nic *sp, uint64_t *data)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nu64 val64 = 0, exp_val;\r\nint fail = 0;\r\nval64 = readq(&bar0->pif_rd_swapper_fb);\r\nif (val64 != 0x123456789abcdefULL) {\r\nfail = 1;\r\nDBG_PRINT(INFO_DBG, "Read Test level %d fails\n", 1);\r\n}\r\nval64 = readq(&bar0->rmac_pause_cfg);\r\nif (val64 != 0xc000ffff00000000ULL) {\r\nfail = 1;\r\nDBG_PRINT(INFO_DBG, "Read Test level %d fails\n", 2);\r\n}\r\nval64 = readq(&bar0->rx_queue_cfg);\r\nif (sp->device_type == XFRAME_II_DEVICE)\r\nexp_val = 0x0404040404040404ULL;\r\nelse\r\nexp_val = 0x0808080808080808ULL;\r\nif (val64 != exp_val) {\r\nfail = 1;\r\nDBG_PRINT(INFO_DBG, "Read Test level %d fails\n", 3);\r\n}\r\nval64 = readq(&bar0->xgxs_efifo_cfg);\r\nif (val64 != 0x000000001923141EULL) {\r\nfail = 1;\r\nDBG_PRINT(INFO_DBG, "Read Test level %d fails\n", 4);\r\n}\r\nval64 = 0x5A5A5A5A5A5A5A5AULL;\r\nwriteq(val64, &bar0->xmsi_data);\r\nval64 = readq(&bar0->xmsi_data);\r\nif (val64 != 0x5A5A5A5A5A5A5A5AULL) {\r\nfail = 1;\r\nDBG_PRINT(ERR_DBG, "Write Test level %d fails\n", 1);\r\n}\r\nval64 = 0xA5A5A5A5A5A5A5A5ULL;\r\nwriteq(val64, &bar0->xmsi_data);\r\nval64 = readq(&bar0->xmsi_data);\r\nif (val64 != 0xA5A5A5A5A5A5A5A5ULL) {\r\nfail = 1;\r\nDBG_PRINT(ERR_DBG, "Write Test level %d fails\n", 2);\r\n}\r\n*data = fail;\r\nreturn fail;\r\n}\r\nstatic int s2io_eeprom_test(struct s2io_nic *sp, uint64_t *data)\r\n{\r\nint fail = 0;\r\nu64 ret_data, org_4F0, org_7F0;\r\nu8 saved_4F0 = 0, saved_7F0 = 0;\r\nstruct net_device *dev = sp->dev;\r\nif (sp->device_type == XFRAME_I_DEVICE)\r\nif (!write_eeprom(sp, 0, 0, 3))\r\nfail = 1;\r\nif (!read_eeprom(sp, 0x4F0, &org_4F0))\r\nsaved_4F0 = 1;\r\nif (!read_eeprom(sp, 0x7F0, &org_7F0))\r\nsaved_7F0 = 1;\r\nif (write_eeprom(sp, 0x4F0, 0x012345, 3))\r\nfail = 1;\r\nif (read_eeprom(sp, 0x4F0, &ret_data))\r\nfail = 1;\r\nif (ret_data != 0x012345) {\r\nDBG_PRINT(ERR_DBG, "%s: eeprom test error at offset 0x4F0. "\r\n"Data written %llx Data read %llx\n",\r\ndev->name, (unsigned long long)0x12345,\r\n(unsigned long long)ret_data);\r\nfail = 1;\r\n}\r\nwrite_eeprom(sp, 0x4F0, 0xFFFFFF, 3);\r\nif (sp->device_type == XFRAME_I_DEVICE)\r\nif (!write_eeprom(sp, 0x07C, 0, 3))\r\nfail = 1;\r\nif (write_eeprom(sp, 0x7F0, 0x012345, 3))\r\nfail = 1;\r\nif (read_eeprom(sp, 0x7F0, &ret_data))\r\nfail = 1;\r\nif (ret_data != 0x012345) {\r\nDBG_PRINT(ERR_DBG, "%s: eeprom test error at offset 0x7F0. "\r\n"Data written %llx Data read %llx\n",\r\ndev->name, (unsigned long long)0x12345,\r\n(unsigned long long)ret_data);\r\nfail = 1;\r\n}\r\nwrite_eeprom(sp, 0x7F0, 0xFFFFFF, 3);\r\nif (sp->device_type == XFRAME_I_DEVICE) {\r\nif (!write_eeprom(sp, 0x080, 0, 3))\r\nfail = 1;\r\nif (!write_eeprom(sp, 0x0FC, 0, 3))\r\nfail = 1;\r\nif (!write_eeprom(sp, 0x100, 0, 3))\r\nfail = 1;\r\nif (!write_eeprom(sp, 0x4EC, 0, 3))\r\nfail = 1;\r\n}\r\nif (saved_4F0)\r\nwrite_eeprom(sp, 0x4F0, org_4F0, 3);\r\nif (saved_7F0)\r\nwrite_eeprom(sp, 0x7F0, org_7F0, 3);\r\n*data = fail;\r\nreturn fail;\r\n}\r\nstatic int s2io_bist_test(struct s2io_nic *sp, uint64_t *data)\r\n{\r\nu8 bist = 0;\r\nint cnt = 0, ret = -1;\r\npci_read_config_byte(sp->pdev, PCI_BIST, &bist);\r\nbist |= PCI_BIST_START;\r\npci_write_config_word(sp->pdev, PCI_BIST, bist);\r\nwhile (cnt < 20) {\r\npci_read_config_byte(sp->pdev, PCI_BIST, &bist);\r\nif (!(bist & PCI_BIST_START)) {\r\n*data = (bist & PCI_BIST_CODE_MASK);\r\nret = 0;\r\nbreak;\r\n}\r\nmsleep(100);\r\ncnt++;\r\n}\r\nreturn ret;\r\n}\r\nstatic int s2io_link_test(struct s2io_nic *sp, uint64_t *data)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nu64 val64;\r\nval64 = readq(&bar0->adapter_status);\r\nif (!(LINK_IS_UP(val64)))\r\n*data = 1;\r\nelse\r\n*data = 0;\r\nreturn *data;\r\n}\r\nstatic int s2io_rldram_test(struct s2io_nic *sp, uint64_t *data)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nu64 val64;\r\nint cnt, iteration = 0, test_fail = 0;\r\nval64 = readq(&bar0->adapter_control);\r\nval64 &= ~ADAPTER_ECC_EN;\r\nwriteq(val64, &bar0->adapter_control);\r\nval64 = readq(&bar0->mc_rldram_test_ctrl);\r\nval64 |= MC_RLDRAM_TEST_MODE;\r\nSPECIAL_REG_WRITE(val64, &bar0->mc_rldram_test_ctrl, LF);\r\nval64 = readq(&bar0->mc_rldram_mrs);\r\nval64 |= MC_RLDRAM_QUEUE_SIZE_ENABLE;\r\nSPECIAL_REG_WRITE(val64, &bar0->mc_rldram_mrs, UF);\r\nval64 |= MC_RLDRAM_MRS_ENABLE;\r\nSPECIAL_REG_WRITE(val64, &bar0->mc_rldram_mrs, UF);\r\nwhile (iteration < 2) {\r\nval64 = 0x55555555aaaa0000ULL;\r\nif (iteration == 1)\r\nval64 ^= 0xFFFFFFFFFFFF0000ULL;\r\nwriteq(val64, &bar0->mc_rldram_test_d0);\r\nval64 = 0xaaaa5a5555550000ULL;\r\nif (iteration == 1)\r\nval64 ^= 0xFFFFFFFFFFFF0000ULL;\r\nwriteq(val64, &bar0->mc_rldram_test_d1);\r\nval64 = 0x55aaaaaaaa5a0000ULL;\r\nif (iteration == 1)\r\nval64 ^= 0xFFFFFFFFFFFF0000ULL;\r\nwriteq(val64, &bar0->mc_rldram_test_d2);\r\nval64 = (u64) (0x0000003ffffe0100ULL);\r\nwriteq(val64, &bar0->mc_rldram_test_add);\r\nval64 = MC_RLDRAM_TEST_MODE |\r\nMC_RLDRAM_TEST_WRITE |\r\nMC_RLDRAM_TEST_GO;\r\nSPECIAL_REG_WRITE(val64, &bar0->mc_rldram_test_ctrl, LF);\r\nfor (cnt = 0; cnt < 5; cnt++) {\r\nval64 = readq(&bar0->mc_rldram_test_ctrl);\r\nif (val64 & MC_RLDRAM_TEST_DONE)\r\nbreak;\r\nmsleep(200);\r\n}\r\nif (cnt == 5)\r\nbreak;\r\nval64 = MC_RLDRAM_TEST_MODE | MC_RLDRAM_TEST_GO;\r\nSPECIAL_REG_WRITE(val64, &bar0->mc_rldram_test_ctrl, LF);\r\nfor (cnt = 0; cnt < 5; cnt++) {\r\nval64 = readq(&bar0->mc_rldram_test_ctrl);\r\nif (val64 & MC_RLDRAM_TEST_DONE)\r\nbreak;\r\nmsleep(500);\r\n}\r\nif (cnt == 5)\r\nbreak;\r\nval64 = readq(&bar0->mc_rldram_test_ctrl);\r\nif (!(val64 & MC_RLDRAM_TEST_PASS))\r\ntest_fail = 1;\r\niteration++;\r\n}\r\n*data = test_fail;\r\nSPECIAL_REG_WRITE(0, &bar0->mc_rldram_test_ctrl, LF);\r\nreturn test_fail;\r\n}\r\nstatic void s2io_ethtool_test(struct net_device *dev,\r\nstruct ethtool_test *ethtest,\r\nuint64_t *data)\r\n{\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nint orig_state = netif_running(sp->dev);\r\nif (ethtest->flags == ETH_TEST_FL_OFFLINE) {\r\nif (orig_state)\r\ns2io_close(sp->dev);\r\nif (s2io_register_test(sp, &data[0]))\r\nethtest->flags |= ETH_TEST_FL_FAILED;\r\ns2io_reset(sp);\r\nif (s2io_rldram_test(sp, &data[3]))\r\nethtest->flags |= ETH_TEST_FL_FAILED;\r\ns2io_reset(sp);\r\nif (s2io_eeprom_test(sp, &data[1]))\r\nethtest->flags |= ETH_TEST_FL_FAILED;\r\nif (s2io_bist_test(sp, &data[4]))\r\nethtest->flags |= ETH_TEST_FL_FAILED;\r\nif (orig_state)\r\ns2io_open(sp->dev);\r\ndata[2] = 0;\r\n} else {\r\nif (!orig_state) {\r\nDBG_PRINT(ERR_DBG, "%s: is not up, cannot run test\n",\r\ndev->name);\r\ndata[0] = -1;\r\ndata[1] = -1;\r\ndata[2] = -1;\r\ndata[3] = -1;\r\ndata[4] = -1;\r\n}\r\nif (s2io_link_test(sp, &data[2]))\r\nethtest->flags |= ETH_TEST_FL_FAILED;\r\ndata[0] = 0;\r\ndata[1] = 0;\r\ndata[3] = 0;\r\ndata[4] = 0;\r\n}\r\n}\r\nstatic void s2io_get_ethtool_stats(struct net_device *dev,\r\nstruct ethtool_stats *estats,\r\nu64 *tmp_stats)\r\n{\r\nint i = 0, k;\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nstruct stat_block *stats = sp->mac_control.stats_info;\r\nstruct swStat *swstats = &stats->sw_stat;\r\nstruct xpakStat *xstats = &stats->xpak_stat;\r\ns2io_updt_stats(sp);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->tmac_frms_oflow) << 32 |\r\nle32_to_cpu(stats->tmac_frms);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->tmac_data_octets_oflow) << 32 |\r\nle32_to_cpu(stats->tmac_data_octets);\r\ntmp_stats[i++] = le64_to_cpu(stats->tmac_drop_frms);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->tmac_mcst_frms_oflow) << 32 |\r\nle32_to_cpu(stats->tmac_mcst_frms);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->tmac_bcst_frms_oflow) << 32 |\r\nle32_to_cpu(stats->tmac_bcst_frms);\r\ntmp_stats[i++] = le64_to_cpu(stats->tmac_pause_ctrl_frms);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->tmac_ttl_octets_oflow) << 32 |\r\nle32_to_cpu(stats->tmac_ttl_octets);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->tmac_ucst_frms_oflow) << 32 |\r\nle32_to_cpu(stats->tmac_ucst_frms);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->tmac_nucst_frms_oflow) << 32 |\r\nle32_to_cpu(stats->tmac_nucst_frms);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->tmac_any_err_frms_oflow) << 32 |\r\nle32_to_cpu(stats->tmac_any_err_frms);\r\ntmp_stats[i++] = le64_to_cpu(stats->tmac_ttl_less_fb_octets);\r\ntmp_stats[i++] = le64_to_cpu(stats->tmac_vld_ip_octets);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->tmac_vld_ip_oflow) << 32 |\r\nle32_to_cpu(stats->tmac_vld_ip);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->tmac_drop_ip_oflow) << 32 |\r\nle32_to_cpu(stats->tmac_drop_ip);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->tmac_icmp_oflow) << 32 |\r\nle32_to_cpu(stats->tmac_icmp);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->tmac_rst_tcp_oflow) << 32 |\r\nle32_to_cpu(stats->tmac_rst_tcp);\r\ntmp_stats[i++] = le64_to_cpu(stats->tmac_tcp);\r\ntmp_stats[i++] = (u64)le32_to_cpu(stats->tmac_udp_oflow) << 32 |\r\nle32_to_cpu(stats->tmac_udp);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->rmac_vld_frms_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_vld_frms);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->rmac_data_octets_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_data_octets);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_fcs_err_frms);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_drop_frms);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->rmac_vld_mcst_frms_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_vld_mcst_frms);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->rmac_vld_bcst_frms_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_vld_bcst_frms);\r\ntmp_stats[i++] = le32_to_cpu(stats->rmac_in_rng_len_err_frms);\r\ntmp_stats[i++] = le32_to_cpu(stats->rmac_out_rng_len_err_frms);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_long_frms);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_pause_ctrl_frms);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_unsup_ctrl_frms);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->rmac_ttl_octets_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_ttl_octets);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->rmac_accepted_ucst_frms_oflow) << 32\r\n| le32_to_cpu(stats->rmac_accepted_ucst_frms);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->rmac_accepted_nucst_frms_oflow)\r\n<< 32 | le32_to_cpu(stats->rmac_accepted_nucst_frms);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->rmac_discarded_frms_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_discarded_frms);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->rmac_drop_events_oflow)\r\n<< 32 | le32_to_cpu(stats->rmac_drop_events);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_ttl_less_fb_octets);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_ttl_frms);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->rmac_usized_frms_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_usized_frms);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->rmac_osized_frms_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_osized_frms);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->rmac_frag_frms_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_frag_frms);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->rmac_jabber_frms_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_jabber_frms);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_ttl_64_frms);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_ttl_65_127_frms);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_ttl_128_255_frms);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_ttl_256_511_frms);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_ttl_512_1023_frms);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_ttl_1024_1518_frms);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->rmac_ip_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_ip);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_ip_octets);\r\ntmp_stats[i++] = le32_to_cpu(stats->rmac_hdr_err_ip);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->rmac_drop_ip_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_drop_ip);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->rmac_icmp_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_icmp);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_tcp);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->rmac_udp_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_udp);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->rmac_err_drp_udp_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_err_drp_udp);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_xgmii_err_sym);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_frms_q0);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_frms_q1);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_frms_q2);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_frms_q3);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_frms_q4);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_frms_q5);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_frms_q6);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_frms_q7);\r\ntmp_stats[i++] = le16_to_cpu(stats->rmac_full_q0);\r\ntmp_stats[i++] = le16_to_cpu(stats->rmac_full_q1);\r\ntmp_stats[i++] = le16_to_cpu(stats->rmac_full_q2);\r\ntmp_stats[i++] = le16_to_cpu(stats->rmac_full_q3);\r\ntmp_stats[i++] = le16_to_cpu(stats->rmac_full_q4);\r\ntmp_stats[i++] = le16_to_cpu(stats->rmac_full_q5);\r\ntmp_stats[i++] = le16_to_cpu(stats->rmac_full_q6);\r\ntmp_stats[i++] = le16_to_cpu(stats->rmac_full_q7);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->rmac_pause_cnt_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_pause_cnt);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_xgmii_data_err_cnt);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_xgmii_ctrl_err_cnt);\r\ntmp_stats[i++] =\r\n(u64)le32_to_cpu(stats->rmac_accepted_ip_oflow) << 32 |\r\nle32_to_cpu(stats->rmac_accepted_ip);\r\ntmp_stats[i++] = le32_to_cpu(stats->rmac_err_tcp);\r\ntmp_stats[i++] = le32_to_cpu(stats->rd_req_cnt);\r\ntmp_stats[i++] = le32_to_cpu(stats->new_rd_req_cnt);\r\ntmp_stats[i++] = le32_to_cpu(stats->new_rd_req_rtry_cnt);\r\ntmp_stats[i++] = le32_to_cpu(stats->rd_rtry_cnt);\r\ntmp_stats[i++] = le32_to_cpu(stats->wr_rtry_rd_ack_cnt);\r\ntmp_stats[i++] = le32_to_cpu(stats->wr_req_cnt);\r\ntmp_stats[i++] = le32_to_cpu(stats->new_wr_req_cnt);\r\ntmp_stats[i++] = le32_to_cpu(stats->new_wr_req_rtry_cnt);\r\ntmp_stats[i++] = le32_to_cpu(stats->wr_rtry_cnt);\r\ntmp_stats[i++] = le32_to_cpu(stats->wr_disc_cnt);\r\ntmp_stats[i++] = le32_to_cpu(stats->rd_rtry_wr_ack_cnt);\r\ntmp_stats[i++] = le32_to_cpu(stats->txp_wr_cnt);\r\ntmp_stats[i++] = le32_to_cpu(stats->txd_rd_cnt);\r\ntmp_stats[i++] = le32_to_cpu(stats->txd_wr_cnt);\r\ntmp_stats[i++] = le32_to_cpu(stats->rxd_rd_cnt);\r\ntmp_stats[i++] = le32_to_cpu(stats->rxd_wr_cnt);\r\ntmp_stats[i++] = le32_to_cpu(stats->txf_rd_cnt);\r\ntmp_stats[i++] = le32_to_cpu(stats->rxf_wr_cnt);\r\nif (sp->device_type == XFRAME_II_DEVICE) {\r\ntmp_stats[i++] =\r\nle64_to_cpu(stats->rmac_ttl_1519_4095_frms);\r\ntmp_stats[i++] =\r\nle64_to_cpu(stats->rmac_ttl_4096_8191_frms);\r\ntmp_stats[i++] =\r\nle64_to_cpu(stats->rmac_ttl_8192_max_frms);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_ttl_gt_max_frms);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_osized_alt_frms);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_jabber_alt_frms);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_gt_max_alt_frms);\r\ntmp_stats[i++] = le64_to_cpu(stats->rmac_vlan_frms);\r\ntmp_stats[i++] = le32_to_cpu(stats->rmac_len_discard);\r\ntmp_stats[i++] = le32_to_cpu(stats->rmac_fcs_discard);\r\ntmp_stats[i++] = le32_to_cpu(stats->rmac_pf_discard);\r\ntmp_stats[i++] = le32_to_cpu(stats->rmac_da_discard);\r\ntmp_stats[i++] = le32_to_cpu(stats->rmac_red_discard);\r\ntmp_stats[i++] = le32_to_cpu(stats->rmac_rts_discard);\r\ntmp_stats[i++] = le32_to_cpu(stats->rmac_ingm_full_discard);\r\ntmp_stats[i++] = le32_to_cpu(stats->link_fault_cnt);\r\n}\r\ntmp_stats[i++] = 0;\r\ntmp_stats[i++] = swstats->single_ecc_errs;\r\ntmp_stats[i++] = swstats->double_ecc_errs;\r\ntmp_stats[i++] = swstats->parity_err_cnt;\r\ntmp_stats[i++] = swstats->serious_err_cnt;\r\ntmp_stats[i++] = swstats->soft_reset_cnt;\r\ntmp_stats[i++] = swstats->fifo_full_cnt;\r\nfor (k = 0; k < MAX_RX_RINGS; k++)\r\ntmp_stats[i++] = swstats->ring_full_cnt[k];\r\ntmp_stats[i++] = xstats->alarm_transceiver_temp_high;\r\ntmp_stats[i++] = xstats->alarm_transceiver_temp_low;\r\ntmp_stats[i++] = xstats->alarm_laser_bias_current_high;\r\ntmp_stats[i++] = xstats->alarm_laser_bias_current_low;\r\ntmp_stats[i++] = xstats->alarm_laser_output_power_high;\r\ntmp_stats[i++] = xstats->alarm_laser_output_power_low;\r\ntmp_stats[i++] = xstats->warn_transceiver_temp_high;\r\ntmp_stats[i++] = xstats->warn_transceiver_temp_low;\r\ntmp_stats[i++] = xstats->warn_laser_bias_current_high;\r\ntmp_stats[i++] = xstats->warn_laser_bias_current_low;\r\ntmp_stats[i++] = xstats->warn_laser_output_power_high;\r\ntmp_stats[i++] = xstats->warn_laser_output_power_low;\r\ntmp_stats[i++] = swstats->clubbed_frms_cnt;\r\ntmp_stats[i++] = swstats->sending_both;\r\ntmp_stats[i++] = swstats->outof_sequence_pkts;\r\ntmp_stats[i++] = swstats->flush_max_pkts;\r\nif (swstats->num_aggregations) {\r\nu64 tmp = swstats->sum_avg_pkts_aggregated;\r\nint count = 0;\r\nwhile (tmp >= swstats->num_aggregations) {\r\ntmp -= swstats->num_aggregations;\r\ncount++;\r\n}\r\ntmp_stats[i++] = count;\r\n} else\r\ntmp_stats[i++] = 0;\r\ntmp_stats[i++] = swstats->mem_alloc_fail_cnt;\r\ntmp_stats[i++] = swstats->pci_map_fail_cnt;\r\ntmp_stats[i++] = swstats->watchdog_timer_cnt;\r\ntmp_stats[i++] = swstats->mem_allocated;\r\ntmp_stats[i++] = swstats->mem_freed;\r\ntmp_stats[i++] = swstats->link_up_cnt;\r\ntmp_stats[i++] = swstats->link_down_cnt;\r\ntmp_stats[i++] = swstats->link_up_time;\r\ntmp_stats[i++] = swstats->link_down_time;\r\ntmp_stats[i++] = swstats->tx_buf_abort_cnt;\r\ntmp_stats[i++] = swstats->tx_desc_abort_cnt;\r\ntmp_stats[i++] = swstats->tx_parity_err_cnt;\r\ntmp_stats[i++] = swstats->tx_link_loss_cnt;\r\ntmp_stats[i++] = swstats->tx_list_proc_err_cnt;\r\ntmp_stats[i++] = swstats->rx_parity_err_cnt;\r\ntmp_stats[i++] = swstats->rx_abort_cnt;\r\ntmp_stats[i++] = swstats->rx_parity_abort_cnt;\r\ntmp_stats[i++] = swstats->rx_rda_fail_cnt;\r\ntmp_stats[i++] = swstats->rx_unkn_prot_cnt;\r\ntmp_stats[i++] = swstats->rx_fcs_err_cnt;\r\ntmp_stats[i++] = swstats->rx_buf_size_err_cnt;\r\ntmp_stats[i++] = swstats->rx_rxd_corrupt_cnt;\r\ntmp_stats[i++] = swstats->rx_unkn_err_cnt;\r\ntmp_stats[i++] = swstats->tda_err_cnt;\r\ntmp_stats[i++] = swstats->pfc_err_cnt;\r\ntmp_stats[i++] = swstats->pcc_err_cnt;\r\ntmp_stats[i++] = swstats->tti_err_cnt;\r\ntmp_stats[i++] = swstats->tpa_err_cnt;\r\ntmp_stats[i++] = swstats->sm_err_cnt;\r\ntmp_stats[i++] = swstats->lso_err_cnt;\r\ntmp_stats[i++] = swstats->mac_tmac_err_cnt;\r\ntmp_stats[i++] = swstats->mac_rmac_err_cnt;\r\ntmp_stats[i++] = swstats->xgxs_txgxs_err_cnt;\r\ntmp_stats[i++] = swstats->xgxs_rxgxs_err_cnt;\r\ntmp_stats[i++] = swstats->rc_err_cnt;\r\ntmp_stats[i++] = swstats->prc_pcix_err_cnt;\r\ntmp_stats[i++] = swstats->rpa_err_cnt;\r\ntmp_stats[i++] = swstats->rda_err_cnt;\r\ntmp_stats[i++] = swstats->rti_err_cnt;\r\ntmp_stats[i++] = swstats->mc_err_cnt;\r\n}\r\nstatic int s2io_ethtool_get_regs_len(struct net_device *dev)\r\n{\r\nreturn XENA_REG_SPACE;\r\n}\r\nstatic int s2io_get_eeprom_len(struct net_device *dev)\r\n{\r\nreturn XENA_EEPROM_SPACE;\r\n}\r\nstatic int s2io_get_sset_count(struct net_device *dev, int sset)\r\n{\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nswitch (sset) {\r\ncase ETH_SS_TEST:\r\nreturn S2IO_TEST_LEN;\r\ncase ETH_SS_STATS:\r\nswitch (sp->device_type) {\r\ncase XFRAME_I_DEVICE:\r\nreturn XFRAME_I_STAT_LEN;\r\ncase XFRAME_II_DEVICE:\r\nreturn XFRAME_II_STAT_LEN;\r\ndefault:\r\nreturn 0;\r\n}\r\ndefault:\r\nreturn -EOPNOTSUPP;\r\n}\r\n}\r\nstatic void s2io_ethtool_get_strings(struct net_device *dev,\r\nu32 stringset, u8 *data)\r\n{\r\nint stat_size = 0;\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nswitch (stringset) {\r\ncase ETH_SS_TEST:\r\nmemcpy(data, s2io_gstrings, S2IO_STRINGS_LEN);\r\nbreak;\r\ncase ETH_SS_STATS:\r\nstat_size = sizeof(ethtool_xena_stats_keys);\r\nmemcpy(data, &ethtool_xena_stats_keys, stat_size);\r\nif (sp->device_type == XFRAME_II_DEVICE) {\r\nmemcpy(data + stat_size,\r\n&ethtool_enhanced_stats_keys,\r\nsizeof(ethtool_enhanced_stats_keys));\r\nstat_size += sizeof(ethtool_enhanced_stats_keys);\r\n}\r\nmemcpy(data + stat_size, &ethtool_driver_stats_keys,\r\nsizeof(ethtool_driver_stats_keys));\r\n}\r\n}\r\nstatic int s2io_set_features(struct net_device *dev, netdev_features_t features)\r\n{\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nnetdev_features_t changed = (features ^ dev->features) & NETIF_F_LRO;\r\nif (changed && netif_running(dev)) {\r\nint rc;\r\ns2io_stop_all_tx_queue(sp);\r\ns2io_card_down(sp);\r\ndev->features = features;\r\nrc = s2io_card_up(sp);\r\nif (rc)\r\ns2io_reset(sp);\r\nelse\r\ns2io_start_all_tx_queue(sp);\r\nreturn rc ? rc : 1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int s2io_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)\r\n{\r\nreturn -EOPNOTSUPP;\r\n}\r\nstatic int s2io_change_mtu(struct net_device *dev, int new_mtu)\r\n{\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nint ret = 0;\r\nif ((new_mtu < MIN_MTU) || (new_mtu > S2IO_JUMBO_SIZE)) {\r\nDBG_PRINT(ERR_DBG, "%s: MTU size is invalid.\n", dev->name);\r\nreturn -EPERM;\r\n}\r\ndev->mtu = new_mtu;\r\nif (netif_running(dev)) {\r\ns2io_stop_all_tx_queue(sp);\r\ns2io_card_down(sp);\r\nret = s2io_card_up(sp);\r\nif (ret) {\r\nDBG_PRINT(ERR_DBG, "%s: Device bring up failed\n",\r\n__func__);\r\nreturn ret;\r\n}\r\ns2io_wake_all_tx_queue(sp);\r\n} else {\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nu64 val64 = new_mtu;\r\nwriteq(vBIT(val64, 2, 14), &bar0->rmac_max_pyld_len);\r\n}\r\nreturn ret;\r\n}\r\nstatic void s2io_set_link(struct work_struct *work)\r\n{\r\nstruct s2io_nic *nic = container_of(work, struct s2io_nic,\r\nset_link_task);\r\nstruct net_device *dev = nic->dev;\r\nstruct XENA_dev_config __iomem *bar0 = nic->bar0;\r\nregister u64 val64;\r\nu16 subid;\r\nrtnl_lock();\r\nif (!netif_running(dev))\r\ngoto out_unlock;\r\nif (test_and_set_bit(__S2IO_STATE_LINK_TASK, &(nic->state))) {\r\ngoto out_unlock;\r\n}\r\nsubid = nic->pdev->subsystem_device;\r\nif (s2io_link_fault_indication(nic) == MAC_RMAC_ERR_TIMER) {\r\nmsleep(100);\r\n}\r\nval64 = readq(&bar0->adapter_status);\r\nif (LINK_IS_UP(val64)) {\r\nif (!(readq(&bar0->adapter_control) & ADAPTER_CNTL_EN)) {\r\nif (verify_xena_quiescence(nic)) {\r\nval64 = readq(&bar0->adapter_control);\r\nval64 |= ADAPTER_CNTL_EN;\r\nwriteq(val64, &bar0->adapter_control);\r\nif (CARDS_WITH_FAULTY_LINK_INDICATORS(\r\nnic->device_type, subid)) {\r\nval64 = readq(&bar0->gpio_control);\r\nval64 |= GPIO_CTRL_GPIO_0;\r\nwriteq(val64, &bar0->gpio_control);\r\nval64 = readq(&bar0->gpio_control);\r\n} else {\r\nval64 |= ADAPTER_LED_ON;\r\nwriteq(val64, &bar0->adapter_control);\r\n}\r\nnic->device_enabled_once = true;\r\n} else {\r\nDBG_PRINT(ERR_DBG,\r\n"%s: Error: device is not Quiescent\n",\r\ndev->name);\r\ns2io_stop_all_tx_queue(nic);\r\n}\r\n}\r\nval64 = readq(&bar0->adapter_control);\r\nval64 |= ADAPTER_LED_ON;\r\nwriteq(val64, &bar0->adapter_control);\r\ns2io_link(nic, LINK_UP);\r\n} else {\r\nif (CARDS_WITH_FAULTY_LINK_INDICATORS(nic->device_type,\r\nsubid)) {\r\nval64 = readq(&bar0->gpio_control);\r\nval64 &= ~GPIO_CTRL_GPIO_0;\r\nwriteq(val64, &bar0->gpio_control);\r\nval64 = readq(&bar0->gpio_control);\r\n}\r\nval64 = readq(&bar0->adapter_control);\r\nval64 = val64 & (~ADAPTER_LED_ON);\r\nwriteq(val64, &bar0->adapter_control);\r\ns2io_link(nic, LINK_DOWN);\r\n}\r\nclear_bit(__S2IO_STATE_LINK_TASK, &(nic->state));\r\nout_unlock:\r\nrtnl_unlock();\r\n}\r\nstatic int set_rxd_buffer_pointer(struct s2io_nic *sp, struct RxD_t *rxdp,\r\nstruct buffAdd *ba,\r\nstruct sk_buff **skb, u64 *temp0, u64 *temp1,\r\nu64 *temp2, int size)\r\n{\r\nstruct net_device *dev = sp->dev;\r\nstruct swStat *stats = &sp->mac_control.stats_info->sw_stat;\r\nif ((sp->rxd_mode == RXD_MODE_1) && (rxdp->Host_Control == 0)) {\r\nstruct RxD1 *rxdp1 = (struct RxD1 *)rxdp;\r\nif (*skb) {\r\nDBG_PRINT(INFO_DBG, "SKB is not NULL\n");\r\nrxdp1->Buffer0_ptr = *temp0;\r\n} else {\r\n*skb = netdev_alloc_skb(dev, size);\r\nif (!(*skb)) {\r\nDBG_PRINT(INFO_DBG,\r\n"%s: Out of memory to allocate %s\n",\r\ndev->name, "1 buf mode SKBs");\r\nstats->mem_alloc_fail_cnt++;\r\nreturn -ENOMEM ;\r\n}\r\nstats->mem_allocated += (*skb)->truesize;\r\nrxdp1->Buffer0_ptr = *temp0 =\r\npci_map_single(sp->pdev, (*skb)->data,\r\nsize - NET_IP_ALIGN,\r\nPCI_DMA_FROMDEVICE);\r\nif (pci_dma_mapping_error(sp->pdev, rxdp1->Buffer0_ptr))\r\ngoto memalloc_failed;\r\nrxdp->Host_Control = (unsigned long) (*skb);\r\n}\r\n} else if ((sp->rxd_mode == RXD_MODE_3B) && (rxdp->Host_Control == 0)) {\r\nstruct RxD3 *rxdp3 = (struct RxD3 *)rxdp;\r\nif (*skb) {\r\nrxdp3->Buffer2_ptr = *temp2;\r\nrxdp3->Buffer0_ptr = *temp0;\r\nrxdp3->Buffer1_ptr = *temp1;\r\n} else {\r\n*skb = netdev_alloc_skb(dev, size);\r\nif (!(*skb)) {\r\nDBG_PRINT(INFO_DBG,\r\n"%s: Out of memory to allocate %s\n",\r\ndev->name,\r\n"2 buf mode SKBs");\r\nstats->mem_alloc_fail_cnt++;\r\nreturn -ENOMEM;\r\n}\r\nstats->mem_allocated += (*skb)->truesize;\r\nrxdp3->Buffer2_ptr = *temp2 =\r\npci_map_single(sp->pdev, (*skb)->data,\r\ndev->mtu + 4,\r\nPCI_DMA_FROMDEVICE);\r\nif (pci_dma_mapping_error(sp->pdev, rxdp3->Buffer2_ptr))\r\ngoto memalloc_failed;\r\nrxdp3->Buffer0_ptr = *temp0 =\r\npci_map_single(sp->pdev, ba->ba_0, BUF0_LEN,\r\nPCI_DMA_FROMDEVICE);\r\nif (pci_dma_mapping_error(sp->pdev,\r\nrxdp3->Buffer0_ptr)) {\r\npci_unmap_single(sp->pdev,\r\n(dma_addr_t)rxdp3->Buffer2_ptr,\r\ndev->mtu + 4,\r\nPCI_DMA_FROMDEVICE);\r\ngoto memalloc_failed;\r\n}\r\nrxdp->Host_Control = (unsigned long) (*skb);\r\nrxdp3->Buffer1_ptr = *temp1 =\r\npci_map_single(sp->pdev, ba->ba_1, BUF1_LEN,\r\nPCI_DMA_FROMDEVICE);\r\nif (pci_dma_mapping_error(sp->pdev,\r\nrxdp3->Buffer1_ptr)) {\r\npci_unmap_single(sp->pdev,\r\n(dma_addr_t)rxdp3->Buffer0_ptr,\r\nBUF0_LEN, PCI_DMA_FROMDEVICE);\r\npci_unmap_single(sp->pdev,\r\n(dma_addr_t)rxdp3->Buffer2_ptr,\r\ndev->mtu + 4,\r\nPCI_DMA_FROMDEVICE);\r\ngoto memalloc_failed;\r\n}\r\n}\r\n}\r\nreturn 0;\r\nmemalloc_failed:\r\nstats->pci_map_fail_cnt++;\r\nstats->mem_freed += (*skb)->truesize;\r\ndev_kfree_skb(*skb);\r\nreturn -ENOMEM;\r\n}\r\nstatic void set_rxd_buffer_size(struct s2io_nic *sp, struct RxD_t *rxdp,\r\nint size)\r\n{\r\nstruct net_device *dev = sp->dev;\r\nif (sp->rxd_mode == RXD_MODE_1) {\r\nrxdp->Control_2 = SET_BUFFER0_SIZE_1(size - NET_IP_ALIGN);\r\n} else if (sp->rxd_mode == RXD_MODE_3B) {\r\nrxdp->Control_2 = SET_BUFFER0_SIZE_3(BUF0_LEN);\r\nrxdp->Control_2 |= SET_BUFFER1_SIZE_3(1);\r\nrxdp->Control_2 |= SET_BUFFER2_SIZE_3(dev->mtu + 4);\r\n}\r\n}\r\nstatic int rxd_owner_bit_reset(struct s2io_nic *sp)\r\n{\r\nint i, j, k, blk_cnt = 0, size;\r\nstruct config_param *config = &sp->config;\r\nstruct mac_info *mac_control = &sp->mac_control;\r\nstruct net_device *dev = sp->dev;\r\nstruct RxD_t *rxdp = NULL;\r\nstruct sk_buff *skb = NULL;\r\nstruct buffAdd *ba = NULL;\r\nu64 temp0_64 = 0, temp1_64 = 0, temp2_64 = 0;\r\nsize = dev->mtu + HEADER_ETHERNET_II_802_3_SIZE +\r\nHEADER_802_2_SIZE + HEADER_SNAP_SIZE;\r\nif (sp->rxd_mode == RXD_MODE_1)\r\nsize += NET_IP_ALIGN;\r\nelse if (sp->rxd_mode == RXD_MODE_3B)\r\nsize = dev->mtu + ALIGN_SIZE + BUF0_LEN + 4;\r\nfor (i = 0; i < config->rx_ring_num; i++) {\r\nstruct rx_ring_config *rx_cfg = &config->rx_cfg[i];\r\nstruct ring_info *ring = &mac_control->rings[i];\r\nblk_cnt = rx_cfg->num_rxd / (rxd_count[sp->rxd_mode] + 1);\r\nfor (j = 0; j < blk_cnt; j++) {\r\nfor (k = 0; k < rxd_count[sp->rxd_mode]; k++) {\r\nrxdp = ring->rx_blocks[j].rxds[k].virt_addr;\r\nif (sp->rxd_mode == RXD_MODE_3B)\r\nba = &ring->ba[j][k];\r\nif (set_rxd_buffer_pointer(sp, rxdp, ba, &skb,\r\n&temp0_64,\r\n&temp1_64,\r\n&temp2_64,\r\nsize) == -ENOMEM) {\r\nreturn 0;\r\n}\r\nset_rxd_buffer_size(sp, rxdp, size);\r\nwmb();\r\nrxdp->Control_1 |= RXD_OWN_XENA;\r\n}\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic int s2io_add_isr(struct s2io_nic *sp)\r\n{\r\nint ret = 0;\r\nstruct net_device *dev = sp->dev;\r\nint err = 0;\r\nif (sp->config.intr_type == MSI_X)\r\nret = s2io_enable_msi_x(sp);\r\nif (ret) {\r\nDBG_PRINT(ERR_DBG, "%s: Defaulting to INTA\n", dev->name);\r\nsp->config.intr_type = INTA;\r\n}\r\nstore_xmsi_data(sp);\r\nif (sp->config.intr_type == MSI_X) {\r\nint i, msix_rx_cnt = 0;\r\nfor (i = 0; i < sp->num_entries; i++) {\r\nif (sp->s2io_entries[i].in_use == MSIX_FLG) {\r\nif (sp->s2io_entries[i].type ==\r\nMSIX_RING_TYPE) {\r\nsprintf(sp->desc[i], "%s:MSI-X-%d-RX",\r\ndev->name, i);\r\nerr = request_irq(sp->entries[i].vector,\r\ns2io_msix_ring_handle,\r\n0,\r\nsp->desc[i],\r\nsp->s2io_entries[i].arg);\r\n} else if (sp->s2io_entries[i].type ==\r\nMSIX_ALARM_TYPE) {\r\nsprintf(sp->desc[i], "%s:MSI-X-%d-TX",\r\ndev->name, i);\r\nerr = request_irq(sp->entries[i].vector,\r\ns2io_msix_fifo_handle,\r\n0,\r\nsp->desc[i],\r\nsp->s2io_entries[i].arg);\r\n}\r\nif (!(sp->msix_info[i].addr &&\r\nsp->msix_info[i].data)) {\r\nDBG_PRINT(ERR_DBG,\r\n"%s @Addr:0x%llx Data:0x%llx\n",\r\nsp->desc[i],\r\n(unsigned long long)\r\nsp->msix_info[i].addr,\r\n(unsigned long long)\r\nntohl(sp->msix_info[i].data));\r\n} else\r\nmsix_rx_cnt++;\r\nif (err) {\r\nremove_msix_isr(sp);\r\nDBG_PRINT(ERR_DBG,\r\n"%s:MSI-X-%d registration "\r\n"failed\n", dev->name, i);\r\nDBG_PRINT(ERR_DBG,\r\n"%s: Defaulting to INTA\n",\r\ndev->name);\r\nsp->config.intr_type = INTA;\r\nbreak;\r\n}\r\nsp->s2io_entries[i].in_use =\r\nMSIX_REGISTERED_SUCCESS;\r\n}\r\n}\r\nif (!err) {\r\npr_info("MSI-X-RX %d entries enabled\n", --msix_rx_cnt);\r\nDBG_PRINT(INFO_DBG,\r\n"MSI-X-TX entries enabled through alarm vector\n");\r\n}\r\n}\r\nif (sp->config.intr_type == INTA) {\r\nerr = request_irq(sp->pdev->irq, s2io_isr, IRQF_SHARED,\r\nsp->name, dev);\r\nif (err) {\r\nDBG_PRINT(ERR_DBG, "%s: ISR registration failed\n",\r\ndev->name);\r\nreturn -1;\r\n}\r\n}\r\nreturn 0;\r\n}\r\nstatic void s2io_rem_isr(struct s2io_nic *sp)\r\n{\r\nif (sp->config.intr_type == MSI_X)\r\nremove_msix_isr(sp);\r\nelse\r\nremove_inta_isr(sp);\r\n}\r\nstatic void do_s2io_card_down(struct s2io_nic *sp, int do_io)\r\n{\r\nint cnt = 0;\r\nstruct XENA_dev_config __iomem *bar0 = sp->bar0;\r\nregister u64 val64 = 0;\r\nstruct config_param *config;\r\nconfig = &sp->config;\r\nif (!is_s2io_card_up(sp))\r\nreturn;\r\ndel_timer_sync(&sp->alarm_timer);\r\nwhile (test_and_set_bit(__S2IO_STATE_LINK_TASK, &(sp->state)))\r\nmsleep(50);\r\nclear_bit(__S2IO_STATE_CARD_UP, &sp->state);\r\nif (sp->config.napi) {\r\nint off = 0;\r\nif (config->intr_type == MSI_X) {\r\nfor (; off < sp->config.rx_ring_num; off++)\r\nnapi_disable(&sp->mac_control.rings[off].napi);\r\n}\r\nelse\r\nnapi_disable(&sp->napi);\r\n}\r\nif (do_io)\r\nstop_nic(sp);\r\ns2io_rem_isr(sp);\r\ns2io_link(sp, LINK_DOWN);\r\nwhile (do_io) {\r\nrxd_owner_bit_reset(sp);\r\nval64 = readq(&bar0->adapter_status);\r\nif (verify_xena_quiescence(sp)) {\r\nif (verify_pcc_quiescent(sp, sp->device_enabled_once))\r\nbreak;\r\n}\r\nmsleep(50);\r\ncnt++;\r\nif (cnt == 10) {\r\nDBG_PRINT(ERR_DBG, "Device not Quiescent - "\r\n"adapter status reads 0x%llx\n",\r\n(unsigned long long)val64);\r\nbreak;\r\n}\r\n}\r\nif (do_io)\r\ns2io_reset(sp);\r\nfree_tx_buffers(sp);\r\nfree_rx_buffers(sp);\r\nclear_bit(__S2IO_STATE_LINK_TASK, &(sp->state));\r\n}\r\nstatic void s2io_card_down(struct s2io_nic *sp)\r\n{\r\ndo_s2io_card_down(sp, 1);\r\n}\r\nstatic int s2io_card_up(struct s2io_nic *sp)\r\n{\r\nint i, ret = 0;\r\nstruct config_param *config;\r\nstruct mac_info *mac_control;\r\nstruct net_device *dev = sp->dev;\r\nu16 interruptible;\r\nret = init_nic(sp);\r\nif (ret != 0) {\r\nDBG_PRINT(ERR_DBG, "%s: H/W initialization failed\n",\r\ndev->name);\r\nif (ret != -EIO)\r\ns2io_reset(sp);\r\nreturn ret;\r\n}\r\nconfig = &sp->config;\r\nmac_control = &sp->mac_control;\r\nfor (i = 0; i < config->rx_ring_num; i++) {\r\nstruct ring_info *ring = &mac_control->rings[i];\r\nring->mtu = dev->mtu;\r\nring->lro = !!(dev->features & NETIF_F_LRO);\r\nret = fill_rx_buffers(sp, ring, 1);\r\nif (ret) {\r\nDBG_PRINT(ERR_DBG, "%s: Out of memory in Open\n",\r\ndev->name);\r\ns2io_reset(sp);\r\nfree_rx_buffers(sp);\r\nreturn -ENOMEM;\r\n}\r\nDBG_PRINT(INFO_DBG, "Buf in ring:%d is %d:\n", i,\r\nring->rx_bufs_left);\r\n}\r\nif (config->napi) {\r\nif (config->intr_type == MSI_X) {\r\nfor (i = 0; i < sp->config.rx_ring_num; i++)\r\nnapi_enable(&sp->mac_control.rings[i].napi);\r\n} else {\r\nnapi_enable(&sp->napi);\r\n}\r\n}\r\nif (sp->promisc_flg)\r\nsp->promisc_flg = 0;\r\nif (sp->m_cast_flg) {\r\nsp->m_cast_flg = 0;\r\nsp->all_multi_pos = 0;\r\n}\r\ns2io_set_multicast(dev);\r\nif (dev->features & NETIF_F_LRO) {\r\nsp->lro_max_aggr_per_sess = ((1<<16) - 1) / dev->mtu;\r\nif (lro_max_pkts < sp->lro_max_aggr_per_sess)\r\nsp->lro_max_aggr_per_sess = lro_max_pkts;\r\n}\r\nif (start_nic(sp)) {\r\nDBG_PRINT(ERR_DBG, "%s: Starting NIC failed\n", dev->name);\r\ns2io_reset(sp);\r\nfree_rx_buffers(sp);\r\nreturn -ENODEV;\r\n}\r\nif (s2io_add_isr(sp) != 0) {\r\nif (sp->config.intr_type == MSI_X)\r\ns2io_rem_isr(sp);\r\ns2io_reset(sp);\r\nfree_rx_buffers(sp);\r\nreturn -ENODEV;\r\n}\r\nS2IO_TIMER_CONF(sp->alarm_timer, s2io_alarm_handle, sp, (HZ/2));\r\nset_bit(__S2IO_STATE_CARD_UP, &sp->state);\r\nen_dis_err_alarms(sp, ENA_ALL_INTRS, ENABLE_INTRS);\r\nif (sp->config.intr_type != INTA) {\r\ninterruptible = TX_TRAFFIC_INTR | TX_PIC_INTR;\r\nen_dis_able_nic_intrs(sp, interruptible, ENABLE_INTRS);\r\n} else {\r\ninterruptible = TX_TRAFFIC_INTR | RX_TRAFFIC_INTR;\r\ninterruptible |= TX_PIC_INTR;\r\nen_dis_able_nic_intrs(sp, interruptible, ENABLE_INTRS);\r\n}\r\nreturn 0;\r\n}\r\nstatic void s2io_restart_nic(struct work_struct *work)\r\n{\r\nstruct s2io_nic *sp = container_of(work, struct s2io_nic, rst_timer_task);\r\nstruct net_device *dev = sp->dev;\r\nrtnl_lock();\r\nif (!netif_running(dev))\r\ngoto out_unlock;\r\ns2io_card_down(sp);\r\nif (s2io_card_up(sp)) {\r\nDBG_PRINT(ERR_DBG, "%s: Device bring up failed\n", dev->name);\r\n}\r\ns2io_wake_all_tx_queue(sp);\r\nDBG_PRINT(ERR_DBG, "%s: was reset by Tx watchdog timer\n", dev->name);\r\nout_unlock:\r\nrtnl_unlock();\r\n}\r\nstatic void s2io_tx_watchdog(struct net_device *dev)\r\n{\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nstruct swStat *swstats = &sp->mac_control.stats_info->sw_stat;\r\nif (netif_carrier_ok(dev)) {\r\nswstats->watchdog_timer_cnt++;\r\nschedule_work(&sp->rst_timer_task);\r\nswstats->soft_reset_cnt++;\r\n}\r\n}\r\nstatic int rx_osm_handler(struct ring_info *ring_data, struct RxD_t * rxdp)\r\n{\r\nstruct s2io_nic *sp = ring_data->nic;\r\nstruct net_device *dev = ring_data->dev;\r\nstruct sk_buff *skb = (struct sk_buff *)\r\n((unsigned long)rxdp->Host_Control);\r\nint ring_no = ring_data->ring_no;\r\nu16 l3_csum, l4_csum;\r\nunsigned long long err = rxdp->Control_1 & RXD_T_CODE;\r\nstruct lro *uninitialized_var(lro);\r\nu8 err_mask;\r\nstruct swStat *swstats = &sp->mac_control.stats_info->sw_stat;\r\nskb->dev = dev;\r\nif (err) {\r\nif (err & 0x1)\r\nswstats->parity_err_cnt++;\r\nerr_mask = err >> 48;\r\nswitch (err_mask) {\r\ncase 1:\r\nswstats->rx_parity_err_cnt++;\r\nbreak;\r\ncase 2:\r\nswstats->rx_abort_cnt++;\r\nbreak;\r\ncase 3:\r\nswstats->rx_parity_abort_cnt++;\r\nbreak;\r\ncase 4:\r\nswstats->rx_rda_fail_cnt++;\r\nbreak;\r\ncase 5:\r\nswstats->rx_unkn_prot_cnt++;\r\nbreak;\r\ncase 6:\r\nswstats->rx_fcs_err_cnt++;\r\nbreak;\r\ncase 7:\r\nswstats->rx_buf_size_err_cnt++;\r\nbreak;\r\ncase 8:\r\nswstats->rx_rxd_corrupt_cnt++;\r\nbreak;\r\ncase 15:\r\nswstats->rx_unkn_err_cnt++;\r\nbreak;\r\n}\r\nif (err_mask != 0x5) {\r\nDBG_PRINT(ERR_DBG, "%s: Rx error Value: 0x%x\n",\r\ndev->name, err_mask);\r\ndev->stats.rx_crc_errors++;\r\nswstats->mem_freed\r\n+= skb->truesize;\r\ndev_kfree_skb(skb);\r\nring_data->rx_bufs_left -= 1;\r\nrxdp->Host_Control = 0;\r\nreturn 0;\r\n}\r\n}\r\nrxdp->Host_Control = 0;\r\nif (sp->rxd_mode == RXD_MODE_1) {\r\nint len = RXD_GET_BUFFER0_SIZE_1(rxdp->Control_2);\r\nskb_put(skb, len);\r\n} else if (sp->rxd_mode == RXD_MODE_3B) {\r\nint get_block = ring_data->rx_curr_get_info.block_index;\r\nint get_off = ring_data->rx_curr_get_info.offset;\r\nint buf0_len = RXD_GET_BUFFER0_SIZE_3(rxdp->Control_2);\r\nint buf2_len = RXD_GET_BUFFER2_SIZE_3(rxdp->Control_2);\r\nunsigned char *buff = skb_push(skb, buf0_len);\r\nstruct buffAdd *ba = &ring_data->ba[get_block][get_off];\r\nmemcpy(buff, ba->ba_0, buf0_len);\r\nskb_put(skb, buf2_len);\r\n}\r\nif ((rxdp->Control_1 & TCP_OR_UDP_FRAME) &&\r\n((!ring_data->lro) ||\r\n(ring_data->lro && (!(rxdp->Control_1 & RXD_FRAME_IP_FRAG)))) &&\r\n(dev->features & NETIF_F_RXCSUM)) {\r\nl3_csum = RXD_GET_L3_CKSUM(rxdp->Control_1);\r\nl4_csum = RXD_GET_L4_CKSUM(rxdp->Control_1);\r\nif ((l3_csum == L3_CKSUM_OK) && (l4_csum == L4_CKSUM_OK)) {\r\nskb->ip_summed = CHECKSUM_UNNECESSARY;\r\nif (ring_data->lro) {\r\nu32 tcp_len = 0;\r\nu8 *tcp;\r\nint ret = 0;\r\nret = s2io_club_tcp_session(ring_data,\r\nskb->data, &tcp,\r\n&tcp_len, &lro,\r\nrxdp, sp);\r\nswitch (ret) {\r\ncase 3:\r\nlro->parent = skb;\r\ngoto aggregate;\r\ncase 1:\r\nlro_append_pkt(sp, lro, skb, tcp_len);\r\ngoto aggregate;\r\ncase 4:\r\nlro_append_pkt(sp, lro, skb, tcp_len);\r\nqueue_rx_frame(lro->parent,\r\nlro->vlan_tag);\r\nclear_lro_session(lro);\r\nswstats->flush_max_pkts++;\r\ngoto aggregate;\r\ncase 2:\r\nlro->parent->data_len = lro->frags_len;\r\nswstats->sending_both++;\r\nqueue_rx_frame(lro->parent,\r\nlro->vlan_tag);\r\nclear_lro_session(lro);\r\ngoto send_up;\r\ncase 0:\r\ncase -1:\r\ncase 5:\r\nbreak;\r\ndefault:\r\nDBG_PRINT(ERR_DBG,\r\n"%s: Samadhana!!\n",\r\n__func__);\r\nBUG();\r\n}\r\n}\r\n} else {\r\nskb_checksum_none_assert(skb);\r\n}\r\n} else\r\nskb_checksum_none_assert(skb);\r\nswstats->mem_freed += skb->truesize;\r\nsend_up:\r\nskb_record_rx_queue(skb, ring_no);\r\nqueue_rx_frame(skb, RXD_GET_VLAN_TAG(rxdp->Control_2));\r\naggregate:\r\nsp->mac_control.rings[ring_no].rx_bufs_left -= 1;\r\nreturn SUCCESS;\r\n}\r\nstatic void s2io_link(struct s2io_nic *sp, int link)\r\n{\r\nstruct net_device *dev = sp->dev;\r\nstruct swStat *swstats = &sp->mac_control.stats_info->sw_stat;\r\nif (link != sp->last_link_state) {\r\ninit_tti(sp, link);\r\nif (link == LINK_DOWN) {\r\nDBG_PRINT(ERR_DBG, "%s: Link down\n", dev->name);\r\ns2io_stop_all_tx_queue(sp);\r\nnetif_carrier_off(dev);\r\nif (swstats->link_up_cnt)\r\nswstats->link_up_time =\r\njiffies - sp->start_time;\r\nswstats->link_down_cnt++;\r\n} else {\r\nDBG_PRINT(ERR_DBG, "%s: Link Up\n", dev->name);\r\nif (swstats->link_down_cnt)\r\nswstats->link_down_time =\r\njiffies - sp->start_time;\r\nswstats->link_up_cnt++;\r\nnetif_carrier_on(dev);\r\ns2io_wake_all_tx_queue(sp);\r\n}\r\n}\r\nsp->last_link_state = link;\r\nsp->start_time = jiffies;\r\n}\r\nstatic void s2io_init_pci(struct s2io_nic *sp)\r\n{\r\nu16 pci_cmd = 0, pcix_cmd = 0;\r\npci_read_config_word(sp->pdev, PCIX_COMMAND_REGISTER,\r\n&(pcix_cmd));\r\npci_write_config_word(sp->pdev, PCIX_COMMAND_REGISTER,\r\n(pcix_cmd | 1));\r\npci_read_config_word(sp->pdev, PCIX_COMMAND_REGISTER,\r\n&(pcix_cmd));\r\npci_read_config_word(sp->pdev, PCI_COMMAND, &pci_cmd);\r\npci_write_config_word(sp->pdev, PCI_COMMAND,\r\n(pci_cmd | PCI_COMMAND_PARITY));\r\npci_read_config_word(sp->pdev, PCI_COMMAND, &pci_cmd);\r\n}\r\nstatic int s2io_verify_parm(struct pci_dev *pdev, u8 *dev_intr_type,\r\nu8 *dev_multiq)\r\n{\r\nint i;\r\nif ((tx_fifo_num > MAX_TX_FIFOS) || (tx_fifo_num < 1)) {\r\nDBG_PRINT(ERR_DBG, "Requested number of tx fifos "\r\n"(%d) not supported\n", tx_fifo_num);\r\nif (tx_fifo_num < 1)\r\ntx_fifo_num = 1;\r\nelse\r\ntx_fifo_num = MAX_TX_FIFOS;\r\nDBG_PRINT(ERR_DBG, "Default to %d tx fifos\n", tx_fifo_num);\r\n}\r\nif (multiq)\r\n*dev_multiq = multiq;\r\nif (tx_steering_type && (1 == tx_fifo_num)) {\r\nif (tx_steering_type != TX_DEFAULT_STEERING)\r\nDBG_PRINT(ERR_DBG,\r\n"Tx steering is not supported with "\r\n"one fifo. Disabling Tx steering.\n");\r\ntx_steering_type = NO_STEERING;\r\n}\r\nif ((tx_steering_type < NO_STEERING) ||\r\n(tx_steering_type > TX_DEFAULT_STEERING)) {\r\nDBG_PRINT(ERR_DBG,\r\n"Requested transmit steering not supported\n");\r\nDBG_PRINT(ERR_DBG, "Disabling transmit steering\n");\r\ntx_steering_type = NO_STEERING;\r\n}\r\nif (rx_ring_num > MAX_RX_RINGS) {\r\nDBG_PRINT(ERR_DBG,\r\n"Requested number of rx rings not supported\n");\r\nDBG_PRINT(ERR_DBG, "Default to %d rx rings\n",\r\nMAX_RX_RINGS);\r\nrx_ring_num = MAX_RX_RINGS;\r\n}\r\nif ((*dev_intr_type != INTA) && (*dev_intr_type != MSI_X)) {\r\nDBG_PRINT(ERR_DBG, "Wrong intr_type requested. "\r\n"Defaulting to INTA\n");\r\n*dev_intr_type = INTA;\r\n}\r\nif ((*dev_intr_type == MSI_X) &&\r\n((pdev->device != PCI_DEVICE_ID_HERC_WIN) &&\r\n(pdev->device != PCI_DEVICE_ID_HERC_UNI))) {\r\nDBG_PRINT(ERR_DBG, "Xframe I does not support MSI_X. "\r\n"Defaulting to INTA\n");\r\n*dev_intr_type = INTA;\r\n}\r\nif ((rx_ring_mode != 1) && (rx_ring_mode != 2)) {\r\nDBG_PRINT(ERR_DBG, "Requested ring mode not supported\n");\r\nDBG_PRINT(ERR_DBG, "Defaulting to 1-buffer mode\n");\r\nrx_ring_mode = 1;\r\n}\r\nfor (i = 0; i < MAX_RX_RINGS; i++)\r\nif (rx_ring_sz[i] > MAX_RX_BLOCKS_PER_RING) {\r\nDBG_PRINT(ERR_DBG, "Requested rx ring size not "\r\n"supported\nDefaulting to %d\n",\r\nMAX_RX_BLOCKS_PER_RING);\r\nrx_ring_sz[i] = MAX_RX_BLOCKS_PER_RING;\r\n}\r\nreturn SUCCESS;\r\n}\r\nstatic int rts_ds_steer(struct s2io_nic *nic, u8 ds_codepoint, u8 ring)\r\n{\r\nstruct XENA_dev_config __iomem *bar0 = nic->bar0;\r\nregister u64 val64 = 0;\r\nif (ds_codepoint > 63)\r\nreturn FAILURE;\r\nval64 = RTS_DS_MEM_DATA(ring);\r\nwriteq(val64, &bar0->rts_ds_mem_data);\r\nval64 = RTS_DS_MEM_CTRL_WE |\r\nRTS_DS_MEM_CTRL_STROBE_NEW_CMD |\r\nRTS_DS_MEM_CTRL_OFFSET(ds_codepoint);\r\nwriteq(val64, &bar0->rts_ds_mem_ctrl);\r\nreturn wait_for_cmd_complete(&bar0->rts_ds_mem_ctrl,\r\nRTS_DS_MEM_CTRL_STROBE_CMD_BEING_EXECUTED,\r\nS2IO_BIT_RESET);\r\n}\r\nstatic int\r\ns2io_init_nic(struct pci_dev *pdev, const struct pci_device_id *pre)\r\n{\r\nstruct s2io_nic *sp;\r\nstruct net_device *dev;\r\nint i, j, ret;\r\nint dma_flag = false;\r\nu32 mac_up, mac_down;\r\nu64 val64 = 0, tmp64 = 0;\r\nstruct XENA_dev_config __iomem *bar0 = NULL;\r\nu16 subid;\r\nstruct config_param *config;\r\nstruct mac_info *mac_control;\r\nint mode;\r\nu8 dev_intr_type = intr_type;\r\nu8 dev_multiq = 0;\r\nret = s2io_verify_parm(pdev, &dev_intr_type, &dev_multiq);\r\nif (ret)\r\nreturn ret;\r\nret = pci_enable_device(pdev);\r\nif (ret) {\r\nDBG_PRINT(ERR_DBG,\r\n"%s: pci_enable_device failed\n", __func__);\r\nreturn ret;\r\n}\r\nif (!pci_set_dma_mask(pdev, DMA_BIT_MASK(64))) {\r\nDBG_PRINT(INIT_DBG, "%s: Using 64bit DMA\n", __func__);\r\ndma_flag = true;\r\nif (pci_set_consistent_dma_mask(pdev, DMA_BIT_MASK(64))) {\r\nDBG_PRINT(ERR_DBG,\r\n"Unable to obtain 64bit DMA "\r\n"for consistent allocations\n");\r\npci_disable_device(pdev);\r\nreturn -ENOMEM;\r\n}\r\n} else if (!pci_set_dma_mask(pdev, DMA_BIT_MASK(32))) {\r\nDBG_PRINT(INIT_DBG, "%s: Using 32bit DMA\n", __func__);\r\n} else {\r\npci_disable_device(pdev);\r\nreturn -ENOMEM;\r\n}\r\nret = pci_request_regions(pdev, s2io_driver_name);\r\nif (ret) {\r\nDBG_PRINT(ERR_DBG, "%s: Request Regions failed - %x\n",\r\n__func__, ret);\r\npci_disable_device(pdev);\r\nreturn -ENODEV;\r\n}\r\nif (dev_multiq)\r\ndev = alloc_etherdev_mq(sizeof(struct s2io_nic), tx_fifo_num);\r\nelse\r\ndev = alloc_etherdev(sizeof(struct s2io_nic));\r\nif (dev == NULL) {\r\npci_disable_device(pdev);\r\npci_release_regions(pdev);\r\nreturn -ENODEV;\r\n}\r\npci_set_master(pdev);\r\npci_set_drvdata(pdev, dev);\r\nSET_NETDEV_DEV(dev, &pdev->dev);\r\nsp = netdev_priv(dev);\r\nsp->dev = dev;\r\nsp->pdev = pdev;\r\nsp->high_dma_flag = dma_flag;\r\nsp->device_enabled_once = false;\r\nif (rx_ring_mode == 1)\r\nsp->rxd_mode = RXD_MODE_1;\r\nif (rx_ring_mode == 2)\r\nsp->rxd_mode = RXD_MODE_3B;\r\nsp->config.intr_type = dev_intr_type;\r\nif ((pdev->device == PCI_DEVICE_ID_HERC_WIN) ||\r\n(pdev->device == PCI_DEVICE_ID_HERC_UNI))\r\nsp->device_type = XFRAME_II_DEVICE;\r\nelse\r\nsp->device_type = XFRAME_I_DEVICE;\r\ns2io_init_pci(sp);\r\nconfig = &sp->config;\r\nmac_control = &sp->mac_control;\r\nconfig->napi = napi;\r\nconfig->tx_steering_type = tx_steering_type;\r\nif (config->tx_steering_type == TX_PRIORITY_STEERING)\r\nconfig->tx_fifo_num = MAX_TX_FIFOS;\r\nelse\r\nconfig->tx_fifo_num = tx_fifo_num;\r\nif (config->tx_fifo_num < 5) {\r\nif (config->tx_fifo_num == 1)\r\nsp->total_tcp_fifos = 1;\r\nelse\r\nsp->total_tcp_fifos = config->tx_fifo_num - 1;\r\nsp->udp_fifo_idx = config->tx_fifo_num - 1;\r\nsp->total_udp_fifos = 1;\r\nsp->other_fifo_idx = sp->total_tcp_fifos - 1;\r\n} else {\r\nsp->total_tcp_fifos = (tx_fifo_num - FIFO_UDP_MAX_NUM -\r\nFIFO_OTHER_MAX_NUM);\r\nsp->udp_fifo_idx = sp->total_tcp_fifos;\r\nsp->total_udp_fifos = FIFO_UDP_MAX_NUM;\r\nsp->other_fifo_idx = sp->udp_fifo_idx + FIFO_UDP_MAX_NUM;\r\n}\r\nconfig->multiq = dev_multiq;\r\nfor (i = 0; i < config->tx_fifo_num; i++) {\r\nstruct tx_fifo_config *tx_cfg = &config->tx_cfg[i];\r\ntx_cfg->fifo_len = tx_fifo_len[i];\r\ntx_cfg->fifo_priority = i;\r\n}\r\nfor (i = 0; i < MAX_TX_FIFOS; i++)\r\nconfig->fifo_mapping[i] = fifo_map[config->tx_fifo_num - 1][i];\r\nfor (i = 0; i < config->tx_fifo_num; i++)\r\nsp->fifo_selector[i] = fifo_selector[i];\r\nconfig->tx_intr_type = TXD_INT_TYPE_UTILZ;\r\nfor (i = 0; i < config->tx_fifo_num; i++) {\r\nstruct tx_fifo_config *tx_cfg = &config->tx_cfg[i];\r\ntx_cfg->f_no_snoop = (NO_SNOOP_TXD | NO_SNOOP_TXD_BUFFER);\r\nif (tx_cfg->fifo_len < 65) {\r\nconfig->tx_intr_type = TXD_INT_TYPE_PER_LIST;\r\nbreak;\r\n}\r\n}\r\nconfig->max_txds = MAX_SKB_FRAGS + 2;\r\nconfig->rx_ring_num = rx_ring_num;\r\nfor (i = 0; i < config->rx_ring_num; i++) {\r\nstruct rx_ring_config *rx_cfg = &config->rx_cfg[i];\r\nstruct ring_info *ring = &mac_control->rings[i];\r\nrx_cfg->num_rxd = rx_ring_sz[i] * (rxd_count[sp->rxd_mode] + 1);\r\nrx_cfg->ring_priority = i;\r\nring->rx_bufs_left = 0;\r\nring->rxd_mode = sp->rxd_mode;\r\nring->rxd_count = rxd_count[sp->rxd_mode];\r\nring->pdev = sp->pdev;\r\nring->dev = sp->dev;\r\n}\r\nfor (i = 0; i < rx_ring_num; i++) {\r\nstruct rx_ring_config *rx_cfg = &config->rx_cfg[i];\r\nrx_cfg->ring_org = RING_ORG_BUFF1;\r\nrx_cfg->f_no_snoop = (NO_SNOOP_RXD | NO_SNOOP_RXD_BUFFER);\r\n}\r\nmac_control->rmac_pause_time = rmac_pause_time;\r\nmac_control->mc_pause_threshold_q0q3 = mc_pause_threshold_q0q3;\r\nmac_control->mc_pause_threshold_q4q7 = mc_pause_threshold_q4q7;\r\nif (init_shared_mem(sp)) {\r\nDBG_PRINT(ERR_DBG, "%s: Memory allocation failed\n", dev->name);\r\nret = -ENOMEM;\r\ngoto mem_alloc_failed;\r\n}\r\nsp->bar0 = pci_ioremap_bar(pdev, 0);\r\nif (!sp->bar0) {\r\nDBG_PRINT(ERR_DBG, "%s: Neterion: cannot remap io mem1\n",\r\ndev->name);\r\nret = -ENOMEM;\r\ngoto bar0_remap_failed;\r\n}\r\nsp->bar1 = pci_ioremap_bar(pdev, 2);\r\nif (!sp->bar1) {\r\nDBG_PRINT(ERR_DBG, "%s: Neterion: cannot remap io mem2\n",\r\ndev->name);\r\nret = -ENOMEM;\r\ngoto bar1_remap_failed;\r\n}\r\nfor (j = 0; j < MAX_TX_FIFOS; j++) {\r\nmac_control->tx_FIFO_start[j] = sp->bar1 + (j * 0x00020000);\r\n}\r\ndev->netdev_ops = &s2io_netdev_ops;\r\nSET_ETHTOOL_OPS(dev, &netdev_ethtool_ops);\r\ndev->hw_features = NETIF_F_SG | NETIF_F_IP_CSUM |\r\nNETIF_F_TSO | NETIF_F_TSO6 |\r\nNETIF_F_RXCSUM | NETIF_F_LRO;\r\ndev->features |= dev->hw_features |\r\nNETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_CTAG_RX;\r\nif (sp->device_type & XFRAME_II_DEVICE) {\r\ndev->hw_features |= NETIF_F_UFO;\r\nif (ufo)\r\ndev->features |= NETIF_F_UFO;\r\n}\r\nif (sp->high_dma_flag == true)\r\ndev->features |= NETIF_F_HIGHDMA;\r\ndev->watchdog_timeo = WATCH_DOG_TIMEOUT;\r\nINIT_WORK(&sp->rst_timer_task, s2io_restart_nic);\r\nINIT_WORK(&sp->set_link_task, s2io_set_link);\r\npci_save_state(sp->pdev);\r\nif (s2io_set_swapper(sp)) {\r\nDBG_PRINT(ERR_DBG, "%s: swapper settings are wrong\n",\r\ndev->name);\r\nret = -EAGAIN;\r\ngoto set_swap_failed;\r\n}\r\nif (sp->device_type & XFRAME_II_DEVICE) {\r\nmode = s2io_verify_pci_mode(sp);\r\nif (mode < 0) {\r\nDBG_PRINT(ERR_DBG, "%s: Unsupported PCI bus mode\n",\r\n__func__);\r\nret = -EBADSLT;\r\ngoto set_swap_failed;\r\n}\r\n}\r\nif (sp->config.intr_type == MSI_X) {\r\nsp->num_entries = config->rx_ring_num + 1;\r\nret = s2io_enable_msi_x(sp);\r\nif (!ret) {\r\nret = s2io_test_msi(sp);\r\nremove_msix_isr(sp);\r\n}\r\nif (ret) {\r\nDBG_PRINT(ERR_DBG,\r\n"MSI-X requested but failed to enable\n");\r\nsp->config.intr_type = INTA;\r\n}\r\n}\r\nif (config->intr_type == MSI_X) {\r\nfor (i = 0; i < config->rx_ring_num ; i++) {\r\nstruct ring_info *ring = &mac_control->rings[i];\r\nnetif_napi_add(dev, &ring->napi, s2io_poll_msix, 64);\r\n}\r\n} else {\r\nnetif_napi_add(dev, &sp->napi, s2io_poll_inta, 64);\r\n}\r\nif (sp->device_type & XFRAME_I_DEVICE) {\r\nfix_mac_address(sp);\r\ns2io_reset(sp);\r\n}\r\nbar0 = sp->bar0;\r\nval64 = RMAC_ADDR_CMD_MEM_RD | RMAC_ADDR_CMD_MEM_STROBE_NEW_CMD |\r\nRMAC_ADDR_CMD_MEM_OFFSET(0 + S2IO_MAC_ADDR_START_OFFSET);\r\nwriteq(val64, &bar0->rmac_addr_cmd_mem);\r\nwait_for_cmd_complete(&bar0->rmac_addr_cmd_mem,\r\nRMAC_ADDR_CMD_MEM_STROBE_CMD_EXECUTING,\r\nS2IO_BIT_RESET);\r\ntmp64 = readq(&bar0->rmac_addr_data0_mem);\r\nmac_down = (u32)tmp64;\r\nmac_up = (u32) (tmp64 >> 32);\r\nsp->def_mac_addr[0].mac_addr[3] = (u8) (mac_up);\r\nsp->def_mac_addr[0].mac_addr[2] = (u8) (mac_up >> 8);\r\nsp->def_mac_addr[0].mac_addr[1] = (u8) (mac_up >> 16);\r\nsp->def_mac_addr[0].mac_addr[0] = (u8) (mac_up >> 24);\r\nsp->def_mac_addr[0].mac_addr[5] = (u8) (mac_down >> 16);\r\nsp->def_mac_addr[0].mac_addr[4] = (u8) (mac_down >> 24);\r\ndev->addr_len = ETH_ALEN;\r\nmemcpy(dev->dev_addr, sp->def_mac_addr, ETH_ALEN);\r\nif (sp->device_type == XFRAME_I_DEVICE) {\r\nconfig->max_mc_addr = S2IO_XENA_MAX_MC_ADDRESSES;\r\nconfig->max_mac_addr = S2IO_XENA_MAX_MAC_ADDRESSES;\r\nconfig->mc_start_offset = S2IO_XENA_MC_ADDR_START_OFFSET;\r\n} else if (sp->device_type == XFRAME_II_DEVICE) {\r\nconfig->max_mc_addr = S2IO_HERC_MAX_MC_ADDRESSES;\r\nconfig->max_mac_addr = S2IO_HERC_MAX_MAC_ADDRESSES;\r\nconfig->mc_start_offset = S2IO_HERC_MC_ADDR_START_OFFSET;\r\n}\r\ndo_s2io_store_unicast_mc(sp);\r\nif ((sp->device_type == XFRAME_II_DEVICE) &&\r\n(config->intr_type == MSI_X))\r\nsp->num_entries = config->rx_ring_num + 1;\r\nstore_xmsi_data(sp);\r\ns2io_reset(sp);\r\nsp->state = 0;\r\nfor (i = 0; i < sp->config.tx_fifo_num; i++) {\r\nstruct fifo_info *fifo = &mac_control->fifos[i];\r\nspin_lock_init(&fifo->tx_lock);\r\n}\r\nsubid = sp->pdev->subsystem_device;\r\nif ((subid & 0xFF) >= 0x07) {\r\nval64 = readq(&bar0->gpio_control);\r\nval64 |= 0x0000800000000000ULL;\r\nwriteq(val64, &bar0->gpio_control);\r\nval64 = 0x0411040400000000ULL;\r\nwriteq(val64, (void __iomem *)bar0 + 0x2700);\r\nval64 = readq(&bar0->gpio_control);\r\n}\r\nsp->rx_csum = 1;\r\nif (register_netdev(dev)) {\r\nDBG_PRINT(ERR_DBG, "Device registration failed\n");\r\nret = -ENODEV;\r\ngoto register_failed;\r\n}\r\ns2io_vpd_read(sp);\r\nDBG_PRINT(ERR_DBG, "Copyright(c) 2002-2010 Exar Corp.\n");\r\nDBG_PRINT(ERR_DBG, "%s: Neterion %s (rev %d)\n", dev->name,\r\nsp->product_name, pdev->revision);\r\nDBG_PRINT(ERR_DBG, "%s: Driver version %s\n", dev->name,\r\ns2io_driver_version);\r\nDBG_PRINT(ERR_DBG, "%s: MAC Address: %pM\n", dev->name, dev->dev_addr);\r\nDBG_PRINT(ERR_DBG, "Serial number: %s\n", sp->serial_num);\r\nif (sp->device_type & XFRAME_II_DEVICE) {\r\nmode = s2io_print_pci_mode(sp);\r\nif (mode < 0) {\r\nret = -EBADSLT;\r\nunregister_netdev(dev);\r\ngoto set_swap_failed;\r\n}\r\n}\r\nswitch (sp->rxd_mode) {\r\ncase RXD_MODE_1:\r\nDBG_PRINT(ERR_DBG, "%s: 1-Buffer receive mode enabled\n",\r\ndev->name);\r\nbreak;\r\ncase RXD_MODE_3B:\r\nDBG_PRINT(ERR_DBG, "%s: 2-Buffer receive mode enabled\n",\r\ndev->name);\r\nbreak;\r\n}\r\nswitch (sp->config.napi) {\r\ncase 0:\r\nDBG_PRINT(ERR_DBG, "%s: NAPI disabled\n", dev->name);\r\nbreak;\r\ncase 1:\r\nDBG_PRINT(ERR_DBG, "%s: NAPI enabled\n", dev->name);\r\nbreak;\r\n}\r\nDBG_PRINT(ERR_DBG, "%s: Using %d Tx fifo(s)\n", dev->name,\r\nsp->config.tx_fifo_num);\r\nDBG_PRINT(ERR_DBG, "%s: Using %d Rx ring(s)\n", dev->name,\r\nsp->config.rx_ring_num);\r\nswitch (sp->config.intr_type) {\r\ncase INTA:\r\nDBG_PRINT(ERR_DBG, "%s: Interrupt type INTA\n", dev->name);\r\nbreak;\r\ncase MSI_X:\r\nDBG_PRINT(ERR_DBG, "%s: Interrupt type MSI-X\n", dev->name);\r\nbreak;\r\n}\r\nif (sp->config.multiq) {\r\nfor (i = 0; i < sp->config.tx_fifo_num; i++) {\r\nstruct fifo_info *fifo = &mac_control->fifos[i];\r\nfifo->multiq = config->multiq;\r\n}\r\nDBG_PRINT(ERR_DBG, "%s: Multiqueue support enabled\n",\r\ndev->name);\r\n} else\r\nDBG_PRINT(ERR_DBG, "%s: Multiqueue support disabled\n",\r\ndev->name);\r\nswitch (sp->config.tx_steering_type) {\r\ncase NO_STEERING:\r\nDBG_PRINT(ERR_DBG, "%s: No steering enabled for transmit\n",\r\ndev->name);\r\nbreak;\r\ncase TX_PRIORITY_STEERING:\r\nDBG_PRINT(ERR_DBG,\r\n"%s: Priority steering enabled for transmit\n",\r\ndev->name);\r\nbreak;\r\ncase TX_DEFAULT_STEERING:\r\nDBG_PRINT(ERR_DBG,\r\n"%s: Default steering enabled for transmit\n",\r\ndev->name);\r\n}\r\nDBG_PRINT(ERR_DBG, "%s: Large receive offload enabled\n",\r\ndev->name);\r\nif (ufo)\r\nDBG_PRINT(ERR_DBG,\r\n"%s: UDP Fragmentation Offload(UFO) enabled\n",\r\ndev->name);\r\nsprintf(sp->name, "%s Neterion %s", dev->name, sp->product_name);\r\nif (vlan_tag_strip)\r\nsp->vlan_strip_flag = 1;\r\nelse\r\nsp->vlan_strip_flag = 0;\r\nnetif_carrier_off(dev);\r\nreturn 0;\r\nregister_failed:\r\nset_swap_failed:\r\niounmap(sp->bar1);\r\nbar1_remap_failed:\r\niounmap(sp->bar0);\r\nbar0_remap_failed:\r\nmem_alloc_failed:\r\nfree_shared_mem(sp);\r\npci_disable_device(pdev);\r\npci_release_regions(pdev);\r\nfree_netdev(dev);\r\nreturn ret;\r\n}\r\nstatic void s2io_rem_nic(struct pci_dev *pdev)\r\n{\r\nstruct net_device *dev = pci_get_drvdata(pdev);\r\nstruct s2io_nic *sp;\r\nif (dev == NULL) {\r\nDBG_PRINT(ERR_DBG, "Driver Data is NULL!!\n");\r\nreturn;\r\n}\r\nsp = netdev_priv(dev);\r\ncancel_work_sync(&sp->rst_timer_task);\r\ncancel_work_sync(&sp->set_link_task);\r\nunregister_netdev(dev);\r\nfree_shared_mem(sp);\r\niounmap(sp->bar0);\r\niounmap(sp->bar1);\r\npci_release_regions(pdev);\r\nfree_netdev(dev);\r\npci_disable_device(pdev);\r\n}\r\nstatic int __init s2io_starter(void)\r\n{\r\nreturn pci_register_driver(&s2io_driver);\r\n}\r\nstatic __exit void s2io_closer(void)\r\n{\r\npci_unregister_driver(&s2io_driver);\r\nDBG_PRINT(INIT_DBG, "cleanup done\n");\r\n}\r\nstatic int check_L2_lro_capable(u8 *buffer, struct iphdr **ip,\r\nstruct tcphdr **tcp, struct RxD_t *rxdp,\r\nstruct s2io_nic *sp)\r\n{\r\nint ip_off;\r\nu8 l2_type = (u8)((rxdp->Control_1 >> 37) & 0x7), ip_len;\r\nif (!(rxdp->Control_1 & RXD_FRAME_PROTO_TCP)) {\r\nDBG_PRINT(INIT_DBG,\r\n"%s: Non-TCP frames not supported for LRO\n",\r\n__func__);\r\nreturn -1;\r\n}\r\nif ((l2_type == 0) || (l2_type == 4)) {\r\nip_off = HEADER_ETHERNET_II_802_3_SIZE;\r\nif ((!sp->vlan_strip_flag) &&\r\n(rxdp->Control_1 & RXD_FRAME_VLAN_TAG))\r\nip_off += HEADER_VLAN_SIZE;\r\n} else {\r\nreturn -1;\r\n}\r\n*ip = (struct iphdr *)(buffer + ip_off);\r\nip_len = (u8)((*ip)->ihl);\r\nip_len <<= 2;\r\n*tcp = (struct tcphdr *)((unsigned long)*ip + ip_len);\r\nreturn 0;\r\n}\r\nstatic int check_for_socket_match(struct lro *lro, struct iphdr *ip,\r\nstruct tcphdr *tcp)\r\n{\r\nDBG_PRINT(INFO_DBG, "%s: Been here...\n", __func__);\r\nif ((lro->iph->saddr != ip->saddr) ||\r\n(lro->iph->daddr != ip->daddr) ||\r\n(lro->tcph->source != tcp->source) ||\r\n(lro->tcph->dest != tcp->dest))\r\nreturn -1;\r\nreturn 0;\r\n}\r\nstatic inline int get_l4_pyld_length(struct iphdr *ip, struct tcphdr *tcp)\r\n{\r\nreturn ntohs(ip->tot_len) - (ip->ihl << 2) - (tcp->doff << 2);\r\n}\r\nstatic void initiate_new_session(struct lro *lro, u8 *l2h,\r\nstruct iphdr *ip, struct tcphdr *tcp,\r\nu32 tcp_pyld_len, u16 vlan_tag)\r\n{\r\nDBG_PRINT(INFO_DBG, "%s: Been here...\n", __func__);\r\nlro->l2h = l2h;\r\nlro->iph = ip;\r\nlro->tcph = tcp;\r\nlro->tcp_next_seq = tcp_pyld_len + ntohl(tcp->seq);\r\nlro->tcp_ack = tcp->ack_seq;\r\nlro->sg_num = 1;\r\nlro->total_len = ntohs(ip->tot_len);\r\nlro->frags_len = 0;\r\nlro->vlan_tag = vlan_tag;\r\nif (tcp->doff == 8) {\r\n__be32 *ptr;\r\nptr = (__be32 *)(tcp+1);\r\nlro->saw_ts = 1;\r\nlro->cur_tsval = ntohl(*(ptr+1));\r\nlro->cur_tsecr = *(ptr+2);\r\n}\r\nlro->in_use = 1;\r\n}\r\nstatic void update_L3L4_header(struct s2io_nic *sp, struct lro *lro)\r\n{\r\nstruct iphdr *ip = lro->iph;\r\nstruct tcphdr *tcp = lro->tcph;\r\nstruct swStat *swstats = &sp->mac_control.stats_info->sw_stat;\r\nDBG_PRINT(INFO_DBG, "%s: Been here...\n", __func__);\r\ncsum_replace2(&ip->check, ip->tot_len, htons(lro->total_len));\r\nip->tot_len = htons(lro->total_len);\r\ntcp->ack_seq = lro->tcp_ack;\r\ntcp->window = lro->window;\r\nif (lro->saw_ts) {\r\n__be32 *ptr = (__be32 *)(tcp + 1);\r\n*(ptr+2) = lro->cur_tsecr;\r\n}\r\nswstats->sum_avg_pkts_aggregated += lro->sg_num;\r\nswstats->num_aggregations++;\r\n}\r\nstatic void aggregate_new_rx(struct lro *lro, struct iphdr *ip,\r\nstruct tcphdr *tcp, u32 l4_pyld)\r\n{\r\nDBG_PRINT(INFO_DBG, "%s: Been here...\n", __func__);\r\nlro->total_len += l4_pyld;\r\nlro->frags_len += l4_pyld;\r\nlro->tcp_next_seq += l4_pyld;\r\nlro->sg_num++;\r\nlro->tcp_ack = tcp->ack_seq;\r\nlro->window = tcp->window;\r\nif (lro->saw_ts) {\r\n__be32 *ptr;\r\nptr = (__be32 *)(tcp+1);\r\nlro->cur_tsval = ntohl(*(ptr+1));\r\nlro->cur_tsecr = *(ptr + 2);\r\n}\r\n}\r\nstatic int verify_l3_l4_lro_capable(struct lro *l_lro, struct iphdr *ip,\r\nstruct tcphdr *tcp, u32 tcp_pyld_len)\r\n{\r\nu8 *ptr;\r\nDBG_PRINT(INFO_DBG, "%s: Been here...\n", __func__);\r\nif (!tcp_pyld_len) {\r\nreturn -1;\r\n}\r\nif (ip->ihl != 5)\r\nreturn -1;\r\nif (INET_ECN_is_ce(ipv4_get_dsfield(ip)))\r\nreturn -1;\r\nif (tcp->urg || tcp->psh || tcp->rst ||\r\ntcp->syn || tcp->fin ||\r\ntcp->ece || tcp->cwr || !tcp->ack) {\r\nreturn -1;\r\n}\r\nif (tcp->doff != 5 && tcp->doff != 8)\r\nreturn -1;\r\nif (tcp->doff == 8) {\r\nptr = (u8 *)(tcp + 1);\r\nwhile (*ptr == TCPOPT_NOP)\r\nptr++;\r\nif (*ptr != TCPOPT_TIMESTAMP || *(ptr+1) != TCPOLEN_TIMESTAMP)\r\nreturn -1;\r\nif (l_lro)\r\nif (l_lro->cur_tsval > ntohl(*((__be32 *)(ptr+2))))\r\nreturn -1;\r\nif (*((__be32 *)(ptr+6)) == 0)\r\nreturn -1;\r\n}\r\nreturn 0;\r\n}\r\nstatic int s2io_club_tcp_session(struct ring_info *ring_data, u8 *buffer,\r\nu8 **tcp, u32 *tcp_len, struct lro **lro,\r\nstruct RxD_t *rxdp, struct s2io_nic *sp)\r\n{\r\nstruct iphdr *ip;\r\nstruct tcphdr *tcph;\r\nint ret = 0, i;\r\nu16 vlan_tag = 0;\r\nstruct swStat *swstats = &sp->mac_control.stats_info->sw_stat;\r\nret = check_L2_lro_capable(buffer, &ip, (struct tcphdr **)tcp,\r\nrxdp, sp);\r\nif (ret)\r\nreturn ret;\r\nDBG_PRINT(INFO_DBG, "IP Saddr: %x Daddr: %x\n", ip->saddr, ip->daddr);\r\nvlan_tag = RXD_GET_VLAN_TAG(rxdp->Control_2);\r\ntcph = (struct tcphdr *)*tcp;\r\n*tcp_len = get_l4_pyld_length(ip, tcph);\r\nfor (i = 0; i < MAX_LRO_SESSIONS; i++) {\r\nstruct lro *l_lro = &ring_data->lro0_n[i];\r\nif (l_lro->in_use) {\r\nif (check_for_socket_match(l_lro, ip, tcph))\r\ncontinue;\r\n*lro = l_lro;\r\nif ((*lro)->tcp_next_seq != ntohl(tcph->seq)) {\r\nDBG_PRINT(INFO_DBG, "%s: Out of sequence. "\r\n"expected 0x%x, actual 0x%x\n",\r\n__func__,\r\n(*lro)->tcp_next_seq,\r\nntohl(tcph->seq));\r\nswstats->outof_sequence_pkts++;\r\nret = 2;\r\nbreak;\r\n}\r\nif (!verify_l3_l4_lro_capable(l_lro, ip, tcph,\r\n*tcp_len))\r\nret = 1;\r\nelse\r\nret = 2;\r\nbreak;\r\n}\r\n}\r\nif (ret == 0) {\r\nif (verify_l3_l4_lro_capable(NULL, ip, tcph, *tcp_len))\r\nreturn 5;\r\nfor (i = 0; i < MAX_LRO_SESSIONS; i++) {\r\nstruct lro *l_lro = &ring_data->lro0_n[i];\r\nif (!(l_lro->in_use)) {\r\n*lro = l_lro;\r\nret = 3;\r\nbreak;\r\n}\r\n}\r\n}\r\nif (ret == 0) {\r\nDBG_PRINT(INFO_DBG, "%s: All LRO sessions already in use\n",\r\n__func__);\r\n*lro = NULL;\r\nreturn ret;\r\n}\r\nswitch (ret) {\r\ncase 3:\r\ninitiate_new_session(*lro, buffer, ip, tcph, *tcp_len,\r\nvlan_tag);\r\nbreak;\r\ncase 2:\r\nupdate_L3L4_header(sp, *lro);\r\nbreak;\r\ncase 1:\r\naggregate_new_rx(*lro, ip, tcph, *tcp_len);\r\nif ((*lro)->sg_num == sp->lro_max_aggr_per_sess) {\r\nupdate_L3L4_header(sp, *lro);\r\nret = 4;\r\n}\r\nbreak;\r\ndefault:\r\nDBG_PRINT(ERR_DBG, "%s: Don't know, can't say!!\n", __func__);\r\nbreak;\r\n}\r\nreturn ret;\r\n}\r\nstatic void clear_lro_session(struct lro *lro)\r\n{\r\nstatic u16 lro_struct_size = sizeof(struct lro);\r\nmemset(lro, 0, lro_struct_size);\r\n}\r\nstatic void queue_rx_frame(struct sk_buff *skb, u16 vlan_tag)\r\n{\r\nstruct net_device *dev = skb->dev;\r\nstruct s2io_nic *sp = netdev_priv(dev);\r\nskb->protocol = eth_type_trans(skb, dev);\r\nif (vlan_tag && sp->vlan_strip_flag)\r\n__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), vlan_tag);\r\nif (sp->config.napi)\r\nnetif_receive_skb(skb);\r\nelse\r\nnetif_rx(skb);\r\n}\r\nstatic void lro_append_pkt(struct s2io_nic *sp, struct lro *lro,\r\nstruct sk_buff *skb, u32 tcp_len)\r\n{\r\nstruct sk_buff *first = lro->parent;\r\nstruct swStat *swstats = &sp->mac_control.stats_info->sw_stat;\r\nfirst->len += tcp_len;\r\nfirst->data_len = lro->frags_len;\r\nskb_pull(skb, (skb->len - tcp_len));\r\nif (skb_shinfo(first)->frag_list)\r\nlro->last_frag->next = skb;\r\nelse\r\nskb_shinfo(first)->frag_list = skb;\r\nfirst->truesize += skb->truesize;\r\nlro->last_frag = skb;\r\nswstats->clubbed_frms_cnt++;\r\n}\r\nstatic pci_ers_result_t s2io_io_error_detected(struct pci_dev *pdev,\r\npci_channel_state_t state)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct s2io_nic *sp = netdev_priv(netdev);\r\nnetif_device_detach(netdev);\r\nif (state == pci_channel_io_perm_failure)\r\nreturn PCI_ERS_RESULT_DISCONNECT;\r\nif (netif_running(netdev)) {\r\ndo_s2io_card_down(sp, 0);\r\n}\r\npci_disable_device(pdev);\r\nreturn PCI_ERS_RESULT_NEED_RESET;\r\n}\r\nstatic pci_ers_result_t s2io_io_slot_reset(struct pci_dev *pdev)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct s2io_nic *sp = netdev_priv(netdev);\r\nif (pci_enable_device(pdev)) {\r\npr_err("Cannot re-enable PCI device after reset.\n");\r\nreturn PCI_ERS_RESULT_DISCONNECT;\r\n}\r\npci_set_master(pdev);\r\ns2io_reset(sp);\r\nreturn PCI_ERS_RESULT_RECOVERED;\r\n}\r\nstatic void s2io_io_resume(struct pci_dev *pdev)\r\n{\r\nstruct net_device *netdev = pci_get_drvdata(pdev);\r\nstruct s2io_nic *sp = netdev_priv(netdev);\r\nif (netif_running(netdev)) {\r\nif (s2io_card_up(sp)) {\r\npr_err("Can't bring device back up after reset.\n");\r\nreturn;\r\n}\r\nif (s2io_set_mac_addr(netdev, netdev->dev_addr) == FAILURE) {\r\ns2io_card_down(sp);\r\npr_err("Can't restore mac addr after reset.\n");\r\nreturn;\r\n}\r\n}\r\nnetif_device_attach(netdev);\r\nnetif_tx_wake_all_queues(netdev);\r\n}
