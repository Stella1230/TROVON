static struct cbe_regs_map *cbe_find_map(struct device_node *np)\r\n{\r\nint i;\r\nstruct device_node *tmp_np;\r\nif (strcasecmp(np->type, "spe")) {\r\nfor (i = 0; i < cbe_regs_map_count; i++)\r\nif (cbe_regs_maps[i].cpu_node == np ||\r\ncbe_regs_maps[i].be_node == np)\r\nreturn &cbe_regs_maps[i];\r\nreturn NULL;\r\n}\r\nif (np->data)\r\nreturn np->data;\r\ntmp_np = np;\r\ndo {\r\ntmp_np = tmp_np->parent;\r\nBUG_ON(!tmp_np);\r\n} while (strcasecmp(tmp_np->type, "cpu") &&\r\nstrcasecmp(tmp_np->type, "be"));\r\nnp->data = cbe_find_map(tmp_np);\r\nreturn np->data;\r\n}\r\nstruct cbe_pmd_regs __iomem *cbe_get_pmd_regs(struct device_node *np)\r\n{\r\nstruct cbe_regs_map *map = cbe_find_map(np);\r\nif (map == NULL)\r\nreturn NULL;\r\nreturn map->pmd_regs;\r\n}\r\nstruct cbe_pmd_regs __iomem *cbe_get_cpu_pmd_regs(int cpu)\r\n{\r\nstruct cbe_regs_map *map = cbe_thread_map[cpu].regs;\r\nif (map == NULL)\r\nreturn NULL;\r\nreturn map->pmd_regs;\r\n}\r\nstruct cbe_pmd_shadow_regs *cbe_get_pmd_shadow_regs(struct device_node *np)\r\n{\r\nstruct cbe_regs_map *map = cbe_find_map(np);\r\nif (map == NULL)\r\nreturn NULL;\r\nreturn &map->pmd_shadow_regs;\r\n}\r\nstruct cbe_pmd_shadow_regs *cbe_get_cpu_pmd_shadow_regs(int cpu)\r\n{\r\nstruct cbe_regs_map *map = cbe_thread_map[cpu].regs;\r\nif (map == NULL)\r\nreturn NULL;\r\nreturn &map->pmd_shadow_regs;\r\n}\r\nstruct cbe_iic_regs __iomem *cbe_get_iic_regs(struct device_node *np)\r\n{\r\nstruct cbe_regs_map *map = cbe_find_map(np);\r\nif (map == NULL)\r\nreturn NULL;\r\nreturn map->iic_regs;\r\n}\r\nstruct cbe_iic_regs __iomem *cbe_get_cpu_iic_regs(int cpu)\r\n{\r\nstruct cbe_regs_map *map = cbe_thread_map[cpu].regs;\r\nif (map == NULL)\r\nreturn NULL;\r\nreturn map->iic_regs;\r\n}\r\nstruct cbe_mic_tm_regs __iomem *cbe_get_mic_tm_regs(struct device_node *np)\r\n{\r\nstruct cbe_regs_map *map = cbe_find_map(np);\r\nif (map == NULL)\r\nreturn NULL;\r\nreturn map->mic_tm_regs;\r\n}\r\nstruct cbe_mic_tm_regs __iomem *cbe_get_cpu_mic_tm_regs(int cpu)\r\n{\r\nstruct cbe_regs_map *map = cbe_thread_map[cpu].regs;\r\nif (map == NULL)\r\nreturn NULL;\r\nreturn map->mic_tm_regs;\r\n}\r\nu32 cbe_get_hw_thread_id(int cpu)\r\n{\r\nreturn cbe_thread_map[cpu].thread_id;\r\n}\r\nu32 cbe_cpu_to_node(int cpu)\r\n{\r\nreturn cbe_thread_map[cpu].cbe_id;\r\n}\r\nu32 cbe_node_to_cpu(int node)\r\n{\r\nreturn cpumask_first(&cbe_local_mask[node]);\r\n}\r\nstatic struct device_node *cbe_get_be_node(int cpu_id)\r\n{\r\nstruct device_node *np;\r\nfor_each_node_by_type (np, "be") {\r\nint len,i;\r\nconst phandle *cpu_handle;\r\ncpu_handle = of_get_property(np, "cpus", &len);\r\nif (WARN_ON_ONCE(!cpu_handle))\r\nreturn np;\r\nfor (i=0; i<len; i++)\r\nif (of_find_node_by_phandle(cpu_handle[i]) == of_get_cpu_node(cpu_id, NULL))\r\nreturn np;\r\n}\r\nreturn NULL;\r\n}\r\nvoid __init cbe_fill_regs_map(struct cbe_regs_map *map)\r\n{\r\nif(map->be_node) {\r\nstruct device_node *be, *np;\r\nbe = map->be_node;\r\nfor_each_node_by_type(np, "pervasive")\r\nif (of_get_parent(np) == be)\r\nmap->pmd_regs = of_iomap(np, 0);\r\nfor_each_node_by_type(np, "CBEA-Internal-Interrupt-Controller")\r\nif (of_get_parent(np) == be)\r\nmap->iic_regs = of_iomap(np, 2);\r\nfor_each_node_by_type(np, "mic-tm")\r\nif (of_get_parent(np) == be)\r\nmap->mic_tm_regs = of_iomap(np, 0);\r\n} else {\r\nstruct device_node *cpu;\r\nconst struct address_prop {\r\nunsigned long address;\r\nunsigned int len;\r\n} __attribute__((packed)) *prop;\r\ncpu = map->cpu_node;\r\nprop = of_get_property(cpu, "pervasive", NULL);\r\nif (prop != NULL)\r\nmap->pmd_regs = ioremap(prop->address, prop->len);\r\nprop = of_get_property(cpu, "iic", NULL);\r\nif (prop != NULL)\r\nmap->iic_regs = ioremap(prop->address, prop->len);\r\nprop = of_get_property(cpu, "mic-tm", NULL);\r\nif (prop != NULL)\r\nmap->mic_tm_regs = ioremap(prop->address, prop->len);\r\n}\r\n}\r\nvoid __init cbe_regs_init(void)\r\n{\r\nint i;\r\nunsigned int thread_id;\r\nstruct device_node *cpu;\r\nfor_each_possible_cpu(i) {\r\ncbe_thread_map[i].cpu_node = of_get_cpu_node(i, &thread_id);\r\ncbe_thread_map[i].be_node = cbe_get_be_node(i);\r\ncbe_thread_map[i].thread_id = thread_id;\r\n}\r\nfor_each_node_by_type(cpu, "cpu") {\r\nstruct cbe_regs_map *map;\r\nunsigned int cbe_id;\r\ncbe_id = cbe_regs_map_count++;\r\nmap = &cbe_regs_maps[cbe_id];\r\nif (cbe_regs_map_count > MAX_CBE) {\r\nprintk(KERN_ERR "cbe_regs: More BE chips than supported"\r\n"!\n");\r\ncbe_regs_map_count--;\r\nof_node_put(cpu);\r\nreturn;\r\n}\r\nmap->cpu_node = cpu;\r\nfor_each_possible_cpu(i) {\r\nstruct cbe_thread_map *thread = &cbe_thread_map[i];\r\nif (thread->cpu_node == cpu) {\r\nthread->regs = map;\r\nthread->cbe_id = cbe_id;\r\nmap->be_node = thread->be_node;\r\ncpumask_set_cpu(i, &cbe_local_mask[cbe_id]);\r\nif(thread->thread_id == 0)\r\ncpumask_set_cpu(i, &cbe_first_online_cpu);\r\n}\r\n}\r\ncbe_fill_regs_map(map);\r\n}\r\n}
